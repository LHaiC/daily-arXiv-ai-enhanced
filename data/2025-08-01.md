<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 95]
- [cs.CL](#cs.CL) [Total: 68]
- [cs.DS](#cs.DS) [Total: 4]
- [physics.app-ph](#physics.app-ph) [Total: 3]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.GT](#cs.GT) [Total: 2]
- [eess.IV](#eess.IV) [Total: 2]
- [cs.NE](#cs.NE) [Total: 3]
- [quant-ph](#quant-ph) [Total: 48]
- [cs.RO](#cs.RO) [Total: 25]
- [cs.DC](#cs.DC) [Total: 4]
- [cs.ET](#cs.ET) [Total: 2]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 22]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.LG](#cs.LG) [Total: 64]
- [eess.SP](#eess.SP) [Total: 12]
- [eess.SY](#eess.SY) [Total: 12]
- [cs.AI](#cs.AI) [Total: 23]
- [cs.SI](#cs.SI) [Total: 5]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 23]
- [cs.MA](#cs.MA) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [CHECK-MAT: Checking Hand-Written Mathematical Answers for the Russian Unified State Exam](https://arxiv.org/abs/2507.22958)
*Ruslan Khrulev*

Main category: cs.CV

TL;DR: 一项新的基准测试显示，目前的视觉-语言模型在评估手写数学题方面存在不足，尤其是在理解学生解题过程和遵循评分标准方面。


<details>
  <summary>Details</summary>
Motivation: 旨在评估视觉-语言模型在评估手写数学解决方案方面的能力，重点在于理解学生解决方案、识别错误和根据固定标准评分，以解决现有基准侧重于问题解决而忽略对学生解的评估的问题。

Method: 本研究提出了一个名为EGE-Math Solutions Assessment Benchmark的新基准，用于评估视觉-语言模型（VLMs）对潦草数学解的评估能力。该基准包含122份来自俄罗斯统一国家考试（EGE）的扫描解决方案及官方专家评分。研究评估了来自Google、OpenAI、Arcee AI和阿里巴巴云的七个现代VLMs在三种推理模式下的表现。

Result: 评估结果显示，当前的VLMs在数学推理能力和人类评分标准对齐方面存在局限性。

Conclusion: 该研究揭示了当前视觉-语言模型在数学推理和与人类评分标准对齐方面存在的局限性，并为人工智能辅助评估开辟了新的研究途径。

Abstract: This paper introduces a novel benchmark, EGE-Math Solutions Assessment
Benchmark, for evaluating Vision-Language Models (VLMs) on their ability to
assess hand-written mathematical solutions. Unlike existing benchmarks that
focus on problem solving, our approach centres on understanding student
solutions, identifying mistakes, and assigning grades according to fixed
criteria. We compile 122 scanned solutions from the Russian Unified State Exam
(EGE) together with official expert grades, and evaluate seven modern VLMs from
Google, OpenAI, Arcee AI, and Alibaba Cloud in three inference modes. The
results reveal current limitations in mathematical reasoning and human-rubric
alignment, opening new research avenues in AI-assisted assessment. You can find
code in https://github.com/Karifannaa/Auto-check-EGE-math

</details>


### [2] [Robust and Efficient 3D Gaussian Splatting for Urban Scene Reconstruction](https://arxiv.org/abs/2507.23006)
*Zhensheng Yuan,Haozhi Huang,Zhen Xiong,Di Wang,Guanghua Yang*

Main category: cs.CV

TL;DR: 提出了一种用于城市规模场景重建和实时渲染的框架，该框架通过场景分区、基于可见性的图像选择、可控的细节层次（LOD）策略、外观变换模块以及深度/尺度正则化和抗锯齿等增强模块，实现了高效的训练和渲染，同时保持了高视觉保真度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 旨在实现城市规模场景的快速重建和实时渲染，同时保持对多视图捕获中外观变化的鲁棒性。

Method: 提出了一种框架，该框架能够实现城市规模场景的快速重建和实时渲染，同时保持对多视图捕获中的外观变化的鲁棒性。该方法首先进行场景分区以进行并行训练，并采用基于可见性的图像选择策略来优化训练效率。可控的细节层次（LOD）策略在用户定义的预算下显式地调节高斯密度，从而在保持高视觉保真度的同时实现高效的训练和渲染。外观变换模块减轻了图像间外观不一致的负面影响，同时实现了灵活的调整。此外，还利用了深度正则化、尺度正则化和抗锯齿等增强模块来提高重建保真度。

Result: 实验结果表明，该方法能够有效地重建城市规模的场景，并在效率和质量方面优于以前的方法。

Conclusion: 该方法能够有效地重建城市规模的场景，并在效率和质量方面优于以前的方法。

Abstract: We present a framework that enables fast reconstruction and real-time
rendering of urban-scale scenes while maintaining robustness against appearance
variations across multi-view captures. Our approach begins with scene
partitioning for parallel training, employing a visibility-based image
selection strategy to optimize training efficiency. A controllable
level-of-detail (LOD) strategy explicitly regulates Gaussian density under a
user-defined budget, enabling efficient training and rendering while
maintaining high visual fidelity. The appearance transformation module
mitigates the negative effects of appearance inconsistencies across images
while enabling flexible adjustments. Additionally, we utilize enhancement
modules, such as depth regularization, scale regularization, and antialiasing,
to improve reconstruction fidelity. Experimental results demonstrate that our
method effectively reconstructs urban-scale scenes and outperforms previous
approaches in both efficiency and quality. The source code is available at:
https://yzslab.github.io/REUrbanGS.

</details>


### [3] [Modeling Human Gaze Behavior with Diffusion Models for Unified Scanpath Prediction](https://arxiv.org/abs/2507.23021)
*Giuseppe Cartella,Vittorio Cuculo,Alessandro D'Amelio,Marcella Cornia,Giuseppe Boccignone,Rita Cucchiara*

Main category: cs.CV

TL;DR: ScanDiff, a new architecture combining diffusion models and Vision Transformers, generates diverse and realistic human gaze scanpaths by modeling variability and enabling task-driven generation, outperforming previous methods.


<details>
  <summary>Details</summary>
Motivation: Existing deep learning models for scanpath prediction often generate averaged behaviors and fail to capture the variability of human visual exploration.

Method: ScanDiff combines diffusion models with Vision Transformers to generate diverse and realistic scanpaths. It explicitly models scanpath variability using the stochastic nature of diffusion models and incorporates textual conditioning for task-driven generation.

Result: Experiments on benchmark datasets show that ScanDiff produces more diverse and accurate scanpaths compared to existing methods in both free-viewing and task-driven scenarios.

Conclusion: ScanDiff surpasses state-of-the-art methods in both free-viewing and task-driven scenarios, producing more diverse and accurate scanpaths. It better captures the complexity of human visual behavior, advancing gaze prediction research.

Abstract: Predicting human gaze scanpaths is crucial for understanding visual
attention, with applications in human-computer interaction, autonomous systems,
and cognitive robotics. While deep learning models have advanced scanpath
prediction, most existing approaches generate averaged behaviors, failing to
capture the variability of human visual exploration. In this work, we present
ScanDiff, a novel architecture that combines diffusion models with Vision
Transformers to generate diverse and realistic scanpaths. Our method explicitly
models scanpath variability by leveraging the stochastic nature of diffusion
models, producing a wide range of plausible gaze trajectories. Additionally, we
introduce textual conditioning to enable task-driven scanpath generation,
allowing the model to adapt to different visual search objectives. Experiments
on benchmark datasets show that ScanDiff surpasses state-of-the-art methods in
both free-viewing and task-driven scenarios, producing more diverse and
accurate scanpaths. These results highlight its ability to better capture the
complexity of human visual behavior, pushing forward gaze prediction research.
Source code and models are publicly available at
https://aimagelab.github.io/ScanDiff.

</details>


### [4] [Adaptive Time-step Training for Enhancing Spike-Based Neural Radiance Fields](https://arxiv.org/abs/2507.23033)
*Ranxi Lin,Canming Yao,Jiayi Li,Weihang Liu,Xin Lou,Pingqiang Zhou*

Main category: cs.CV

TL;DR: PATA is a spike-based NeRF framework that uses dynamic time steps to reduce computation and power consumption for resource-constrained scenarios.


<details>
  <summary>Details</summary>
Motivation: NeRF models are computationally expensive due to dense point sampling, limiting their use in resource-constrained environments. SNNs offer an energy-efficient alternative.

Method: Spiking Neural Networks (SNNs) combined with Neural Radiance Fields (NeRF) and a dynamic time step training strategy called Pretrain-Adaptive Time-step Adjustment (PATA).

Result: PATA reduces inference time steps by 64% and running power by 61.55% while maintaining rendering quality.

Conclusion: PATA can preserve rendering fidelity while reducing inference time steps by 64% and running power by 61.55%.

Abstract: Neural Radiance Fields (NeRF)-based models have achieved remarkable success
in 3D reconstruction and rendering tasks. However, during both training and
inference, these models rely heavily on dense point sampling along rays from
multiple viewpoints, resulting in a surge in floating-point operations and
severely limiting their use in resource-constrained scenarios like edge
computing. Spiking Neural Networks (SNNs), which communicate via binary spikes
over discrete time steps, offer a promising alternative due to their
energy-efficient nature. Given the inherent variability in scene scale and
texture complexity in neural rendering and the prevailing practice of training
separate models per scene, we propose a spike-based NeRF framework with a
dynamic time step training strategy, termed Pretrain-Adaptive Time-step
Adjustment (PATA). This approach automatically explores the trade-off between
rendering quality and time step length during training. Consequently, it
enables scene-adaptive inference with variable time steps and reduces the
additional consumption of computational resources in the inference process.
Anchoring to the established Instant-NGP architecture, we evaluate our method
across diverse datasets. The experimental results show that PATA can preserve
rendering fidelity while reducing inference time steps by 64\% and running
power by 61.55\%.

</details>


### [5] [Recovering Diagnostic Value: Super-Resolution-Aided Echocardiographic Classification in Resource-Constrained Imaging](https://arxiv.org/abs/2507.23027)
*Krishan Agyakari Raja Babu,Om Prabhu,Annu,Mohanasankar Sivaprakasam*

Main category: cs.CV

TL;DR: 本研究表明，SR技术可以提升低质量超声心动图的质量，从而提高AI诊断的准确性，尤其在资源受限环境中具有应用前景。SRResNet模型效果显著且效率高。


<details>
  <summary>Details</summary>
Motivation: 资源受限环境（RCS）中的超声心动图质量普遍不高，限制了下游诊断模型的效果。本研究旨在探索深度学习超分辨率技术在提升低质量超声心动图分类准确性方面的潜力。

Method: 本研究采用SRGAN和SRResNet两种超分辨率模型，对CAMUS数据集中的低质量2D超声心动图进行增强，并评估其在二腔心与四腔心视图分类和舒张末期与收缩末期分类任务上的表现。

Result: SRResNet在低质量超声心动图的分类任务上取得了显著的性能提升，并且计算效率更高。研究表明，SR技术能够有效恢复退化超声心动图的诊断价值。

Conclusion: 深度学习超分辨率（SR）技术可以有效恢复低质量超声心动图的诊断价值，是资源受限环境（RCS）中人工智能辅助医疗的可行工具。

Abstract: Automated cardiac interpretation in resource-constrained settings (RCS) is
often hindered by poor-quality echocardiographic imaging, limiting the
effectiveness of downstream diagnostic models. While super-resolution (SR)
techniques have shown promise in enhancing magnetic resonance imaging (MRI) and
computed tomography (CT) scans, their application to echocardiography-a widely
accessible but noise-prone modality-remains underexplored. In this work, we
investigate the potential of deep learning-based SR to improve classification
accuracy on low-quality 2D echocardiograms. Using the publicly available CAMUS
dataset, we stratify samples by image quality and evaluate two clinically
relevant tasks of varying complexity: a relatively simple Two-Chamber vs.
Four-Chamber (2CH vs. 4CH) view classification and a more complex End-Diastole
vs. End-Systole (ED vs. ES) phase classification. We apply two widely used SR
models-Super-Resolution Generative Adversarial Network (SRGAN) and
Super-Resolution Residual Network (SRResNet), to enhance poor-quality images
and observe significant gains in performance metric-particularly with SRResNet,
which also offers computational efficiency. Our findings demonstrate that SR
can effectively recover diagnostic value in degraded echo scans, making it a
viable tool for AI-assisted care in RCS, achieving more with less.

</details>


### [6] [Early Goal-Guided Multi-Scale Fusion for Real-Time Vision-Language Driving](https://arxiv.org/abs/2507.23042)
*Santosh Patapati,Trisanth Srinivasan*

Main category: cs.CV

TL;DR: NovaDrive是一个用于自动驾驶的视觉-语言模型，通过融合多模态数据和优化损失函数，提高了安全性和效率，实现了实时推理。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶汽车需要在复杂的交通环境中，以毫秒级的速度对道路几何和交通意图进行推理。现有的方法在处理多模态信息和保证实时性方面存在挑战。因此，需要一种能够高效融合多模态数据并实现实时推理的架构，以提高自动驾驶的安全性和效率。

Method: NovaDrive采用单分支视觉-语言架构，处理前置摄像头图像、高清地图瓦片、激光雷达深度和文本航点。其核心是一个轻量级、两阶段的交叉注意力模块，首先对齐航点标记与高清地图，然后对图像和深度斑块进行细粒度注意力精炼。此外，引入了新颖的平滑度损失函数，以减少急剧的转向和速度变化，从而无需循环记忆。该模型通过微调11B LLaMA-3.2视觉-语言骨干网络的前15层来实现实时推理。

Result: 在MD-NEX Outdoor基准测试的nuScenes / Waymo子集上，NovaDrive将成功率提高了4%，达到84%，路径效率（SPL）提升了0.11，达到0.66，并将碰撞频率从2.6%降低到1.2%。消融实验表明，航点标记、部分视觉语言模型微调和交叉注意力融合是提升性能的关键因素。

Conclusion: NovaDrive是一个创新的单分支视觉-语言模型，通过融合摄像头图像、高清地图、激光雷达深度和文本航点信息，实现了自动驾驶的实时推理。该模型通过轻量级交叉注意力机制和新颖的平滑度损失函数，提高了路径效率和安全性，同时减少了突然的转向和速度变化。实验结果表明，NovaDrive在性能上超越了现有技术，并且有望应用于其他具身智能领域。

Abstract: Autonomous vehicles must react in milliseconds while reasoning about road
geometry and traffic intent to navigate complex situations. We introduce
NovaDrive, a single-branch vision-language architecture that processes
front-camera images, HD-map tiles, LiDAR depth, and textual waypoints in a
single branch. A lightweight, two-stage cross-attention block first aligns
waypoint tokens with the HD map, then refines attention over fine-grained image
and depth patches. Coupled with a novel smoothness loss that discourages abrupt
steering and speed changes, this design eliminates the need for recurrent
memory. We fine-tune the top 15 layers of an 11B LLaMA-3.2 vision-language
backbone, enabling real-time inference. On the nuScenes / Waymo subset of the
MD-NEX Outdoor benchmark, NovaDrive raises success rate to 84% (+4%), boosts
path-efficiency (SPL) to 0.66 (+0.11), and reduces collision frequency from
2.6% to 1.2% (-1.4%) relative to the previous state-of-the-art. Our ablations
confirm that waypoint tokens, partial VLM fine-tuning, and the cross-attention
fusion each contribute the most to these gains. Beyond safety, NovaDrive's
shorter routes (resulting from the novel smoothness loss) translate to lower
fuel or battery usage, pointing toward leaner, more easily updated driving
stacks. NovaDrive can be extended to other embodied-AI domains as well.

</details>


### [7] [Reference-Guided Diffusion Inpainting For Multimodal Counterfactual Generation](https://arxiv.org/abs/2507.23058)
*Alexandru Buburuzan*

Main category: cs.CV

TL;DR: MObI和AnydoorMed是用于自动驾驶和医学影像分析的两种新颖的合成数据生成方法，它们利用扩散模型进行参考引导修复，以实现高真实感和可控性，并展示了基础模型跨模态应用的潜力。


<details>
  <summary>Details</summary>
Motivation: 安全关键型应用（如自动驾驶和医学影像分析）需要大量多模态数据进行严格测试。由于真实世界数据的收集成本高昂且复杂，合成数据方法日益受到关注，但它们需要高度的真实感和可控性。

Method: MObI使用扩散模型进行多模态物体修复，通过3D边界框引导，在指定的3D位置进行物体插入，同时保持语义一致性和多模态连贯性。AnydoorMed将此范式应用于医学影像，利用基于扩散的模型对乳腺X线照片中的异常进行参考引导修复。

Result: MObI能够无缝地将物体插入到现有的多模态场景中，并能在相机和激光雷达图像中同时实现。AnydoorMed能够以惊人的细节保留能力修复异常，同时在结构完整性上保持参考异常，并将其与周围组织语义融合。

Conclusion: MObI和AnydoorMed的开创性工作表明，用于自然图像中参考引导修复的基础模型可以轻松地适应不同的感知模式，为下一代能够构建高度真实、可控和多模态的“假想”场景的系统铺平了道路。

Abstract: Safety-critical applications, such as autonomous driving and medical image
analysis, require extensive multimodal data for rigorous testing. Synthetic
data methods are gaining prominence due to the cost and complexity of gathering
real-world data, but they demand a high degree of realism and controllability
to be useful. This work introduces two novel methods for synthetic data
generation in autonomous driving and medical image analysis, namely MObI and
AnydoorMed, respectively. MObI is a first-of-its-kind framework for Multimodal
Object Inpainting that leverages a diffusion model to produce realistic and
controllable object inpaintings across perceptual modalities, demonstrated
simultaneously for camera and lidar. Given a single reference RGB image, MObI
enables seamless object insertion into existing multimodal scenes at a
specified 3D location, guided by a bounding box, while maintaining semantic
consistency and multimodal coherence. Unlike traditional inpainting methods
that rely solely on edit masks, this approach uses 3D bounding box conditioning
to ensure accurate spatial positioning and realistic scaling. AnydoorMed
extends this paradigm to the medical imaging domain, focusing on
reference-guided inpainting for mammography scans. It leverages a
diffusion-based model to inpaint anomalies with impressive detail preservation,
maintaining the reference anomaly's structural integrity while semantically
blending it with the surrounding tissue. Together, these methods demonstrate
that foundation models for reference-guided inpainting in natural images can be
readily adapted to diverse perceptual modalities, paving the way for the next
generation of systems capable of constructing highly realistic, controllable
and multimodal counterfactual scenarios.

</details>


### [8] [Vision-Language Fusion for Real-Time Autonomous Driving: Goal-Centered Cross-Attention of Camera, HD-Map, & Waypoints](https://arxiv.org/abs/2507.23064)
*Santosh Patapati,Trisanth Srinivasan,Murari Ambati*

Main category: cs.CV

TL;DR: XYZ-Drive 是一个单一的视觉-语言模型，它融合了摄像头、地图和航路点信息，实现了更准确、更高效的自动驾驶，并在基准测试中取得了领先的性能。


<details>
  <summary>Details</summary>
Motivation: 目前自动驾驶汽车的解决方案通常分别处理几何精度和语义理解，而 XYZ-Drive 旨在通过一个单一的视觉-语言模型来统一这两个方面。

Method: 该模型名为 XYZ-Drive，是一个单一的视觉-语言模型，接收前置摄像头帧、25m x 25m 的顶视地图和下一个航路点作为输入，并输出转向和速度。它利用一个以目标为中心的轻量级交叉注意力层，让航路点 token 突出显示相关的图像和地图块，并支持行动和文本解释。然后，融合后的 token 输入到一个部分微调的 LLaMA-3.2 11B 模型中。

Result: 在 MD-NEX Outdoor-Driving 基准测试中，XYZ-Drive 达到了 95% 的成功率和 0.80 的路径长度加权成功率 (SPL)，相比 PhysNav-DG 提高了 15%，并使碰撞次数减少了一半，同时显著提高了效率。消融实验表明，移除任何模态（视觉、航路点、地图）都会导致成功率下降高达 11%，这证实了它们各自的作用和丰富的联系。将以目标为中心的注意力替换为简单的拼接会将性能降低 3%，表明基于查询的融合能更有效地注入地图知识。保持 Transformer 冻结会损失 5% 的性能，这表明在将 VLM 应用于自动驾驶等特定任务时微调的重要性。将地图分辨率从 10 厘米提高到 40 厘米会模糊车道边缘并增加碰撞率。

Conclusion: 这项工作表明，早期、token 级别的意图和地图布局融合可以实现准确、透明、实时的驾驶。

Abstract: Autonomous cars need geometric accuracy and semantic understanding to
navigate complex environments, yet most stacks handle them separately. We
present XYZ-Drive, a single vision-language model that reads a front-camera
frame, a 25m $\times$ 25m overhead map, and the next waypoint, then outputs
steering and speed. A lightweight goal-centered cross-attention layer lets
waypoint tokens highlight relevant image and map patches, supporting both
action and textual explanations, before the fused tokens enter a partially
fine-tuned LLaMA-3.2 11B model.
  On the MD-NEX Outdoor-Driving benchmark XYZ-Drive attains 95% success and
0.80 Success weighted by Path Length (SPL), surpassing PhysNav-DG by 15%. and
halving collisions, all while significantly improving efficiency by using only
a single branch. Sixteen ablations explain the gains. Removing any modality
(vision, waypoint, map) drops success by up to 11%, confirming their
complementary roles and rich connections. Replacing goal-centered attention
with simple concatenation cuts 3% in performance, showing query-based fusion
injects map knowledge more effectively. Keeping the transformer frozen loses
5%, showing the importance of fine-tuning when applying VLMs for specific tasks
such as autonomous driving. Coarsening map resolution from 10 cm to 40 cm blurs
lane edges and raises crash rate.
  Overall, these results demonstrate that early, token-level fusion of intent
and map layout enables accurate, transparent, real-time driving.

</details>


### [9] [Consistent Point Matching](https://arxiv.org/abs/2507.23609)
*Halid Ziya Yerebakan,Gerardo Hermosillo Valadez*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This study demonstrates that incorporating a consistency heuristic into the
point-matching algorithm \cite{yerebakan2023hierarchical} improves robustness
in matching anatomical locations across pairs of medical images. We validated
our approach on diverse longitudinal internal and public datasets spanning CT
and MRI modalities. Notably, it surpasses state-of-the-art results on the Deep
Lesion Tracking dataset. Additionally, we show that the method effectively
addresses landmark localization. The algorithm operates efficiently on standard
CPU hardware and allows configurable trade-offs between speed and robustness.
The method enables high-precision navigation between medical images without
requiring a machine learning model or training data.

</details>


### [10] [Vocabulary-free Fine-grained Visual Recognition via Enriched Contextually Grounded Vision-Language Model](https://arxiv.org/abs/2507.23070)
*Dmitry Demidov,Zaigham Zaheer,Omkar Thawakar,Salman Khan,Fahad Shahbaz Khan*

Main category: cs.CV

TL;DR: 提出了一种名为 E-FineR 的训练无关方法，用于细粒度图像分类，克服了现有方法的局限性，并在零样本和少样本场景下取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在利用 LLM 进行分类阶段的能力方面受到限制，并且依赖于 LLM 提供的、未经充分分析和完善的猜测类别名称。

Method: 提出了一种名为 Enriched-FineR (E-FineR) 的训练无关方法，该方法在细粒度视觉识别方面取得了最先进的结果，同时还提供了更强的可解释性。

Result: 在细粒度视觉识别方面取得了最先进的结果，并展示了其在零样本和少样本分类中的应用，性能与现有最先进方法相当，同时无需训练且无需人工干预。

Conclusion: 该框架支持从僵硬的标签预测到灵活的、由语言驱动的理解的图像分类转变，从而实现可扩展且可泛化的现实世界应用系统。

Abstract: Fine-grained image classification, the task of distinguishing between
visually similar subcategories within a broader category (e.g., bird species,
car models, flower types), is a challenging computer vision problem.
Traditional approaches rely heavily on fixed vocabularies and closed-set
classification paradigms, limiting their scalability and adaptability in
real-world settings where novel classes frequently emerge. Recent research has
demonstrated that combining large language models (LLMs) with vision-language
models (VLMs) makes open-set recognition possible without the need for
predefined class labels. However, the existing methods are often limited in
harnessing the power of LLMs at the classification phase, and also rely heavily
on the guessed class names provided by an LLM without thorough analysis and
refinement. To address these bottlenecks, we propose our training-free method,
Enriched-FineR (or E-FineR for short), which demonstrates state-of-the-art
results in fine-grained visual recognition while also offering greater
interpretability, highlighting its strong potential in real-world scenarios and
new domains where expert annotations are difficult to obtain. Additionally, we
demonstrate the application of our proposed approach to zero-shot and few-shot
classification, where it demonstrated performance on par with the existing SOTA
while being training-free and not requiring human interventions. Overall, our
vocabulary-free framework supports the shift in image classification from rigid
label prediction to flexible, language-driven understanding, enabling scalable
and generalizable systems for real-world applications. Well-documented code is
available on https://github.com/demidovd98/e-finer.

</details>


### [11] [Details Matter for Indoor Open-vocabulary 3D Instance Segmentation](https://arxiv.org/abs/2507.23134)
*Sanghun Jung,Jingjing Zheng,Ke Zhang,Nan Qiao,Albert Y. C. Chen,Lu Xia,Chi Liu,Yuyin Sun,Xiao Zeng,Hsiang-Wei Huang,Byron Boots,Min Sun,Cheng-Hao Kuo*

Main category: cs.CV

TL;DR: 通过结合和改进现有技术，并采用Alpha-CLIP和SMS分数，该研究在开放词汇3D实例分割任务上取得了新的最先进成果。


<details>
  <summary>Details</summary>
Motivation: 研究者观察到，现有的开放词汇3D实例分割（OV-3DIS）方法虽然提出了各种概念，但这些概念并非相互排斥，而是可以互补的。

Method: 该研究提出了一种新的解决方案，通过结合各种概念并加以改进来解决关键挑战。该解决方案遵循两阶段方案：3D提议生成和实例分类。采用基于3D跟踪的提议聚合来生成3D提议，并通过迭代合并/移除来去除重叠或部分提议。在分类阶段，使用Alpha-CLIP替换标准的CLIP模型，该模型将对象掩码合并为Alpha通道，以减少背景噪声并获得以对象为中心的表示。此外，还引入了标准化最大相似度（SMS）得分来对文本到提议的相似度进行标准化，从而有效地滤除假阳性和提高精度。

Result: 该研究提出了一种新的开放词汇3D实例分割（OV-3DIS）解决方案，该方案在ScanNet200和S3DIS数据集上取得了最先进的性能。

Conclusion: 该框架在ScanNet200和S3DIS上取得了最先进的性能，在所有AP和AR指标上都超越了端到端的闭词汇方法。

Abstract: Unlike closed-vocabulary 3D instance segmentation that is often trained
end-to-end, open-vocabulary 3D instance segmentation (OV-3DIS) often leverages
vision-language models (VLMs) to generate 3D instance proposals and classify
them. While various concepts have been proposed from existing research, we
observe that these individual concepts are not mutually exclusive but
complementary. In this paper, we propose a new state-of-the-art solution for
OV-3DIS by carefully designing a recipe to combine the concepts together and
refining them to address key challenges. Our solution follows the two-stage
scheme: 3D proposal generation and instance classification. We employ robust 3D
tracking-based proposal aggregation to generate 3D proposals and remove
overlapped or partial proposals by iterative merging/removal. For the
classification stage, we replace the standard CLIP model with Alpha-CLIP, which
incorporates object masks as an alpha channel to reduce background noise and
obtain object-centric representation. Additionally, we introduce the
standardized maximum similarity (SMS) score to normalize text-to-proposal
similarity, effectively filtering out false positives and boosting precision.
Our framework achieves state-of-the-art performance on ScanNet200 and S3DIS
across all AP and AR metrics, even surpassing an end-to-end closed-vocabulary
method.

</details>


### [12] [X-NeMo: Expressive Neural Motion Reenactment via Disentangled Latent Attention](https://arxiv.org/abs/2507.23143)
*Xiaochen Zhao,Hongyi Xu,Guoxian Song,You Xie,Chenxu Zhang,Xiu Li,Linjie Luo,Jinli Suo,Yebin Liu*

Main category: cs.CV

TL;DR: X-NeMo is a new AI method for animating static portraits using facial movements from a different person's video. It fixes common problems like 'identity leakage' and improves expression accuracy by using a novel training approach with a special latent motion descriptor and dual GAN decoders. Experiments show it works better than existing methods.


<details>
  <summary>Details</summary>
Motivation: Prior approaches suffer from identity leakage and difficulty in capturing subtle and extreme expressions. X-NeMo aims to address these challenges.

Method: X-NeMo is a zero-shot diffusion-based portrait animation pipeline that animates a static portrait using facial movements from a driving video of a different individual. It uses a fully end-to-end training framework to distill a 1D identity-agnostic latent motion descriptor from the driving image, controlling motion through cross-attention during image generation. A dual GAN decoder, alongside spatial and color augmentations, enhances expressiveness and disentangles motion latents from identity cues. By embedding driving motion into a 1D latent vector and controlling motion via cross-attention, identity leakage is mitigated.

Result: X-NeMo produces highly expressive animations with superior identity resemblance, surpassing state-of-the-art baselines.

Conclusion: X-NeMo surpasses state-of-the-art baselines, producing highly expressive animations with superior identity resemblance.

Abstract: We propose X-NeMo, a novel zero-shot diffusion-based portrait animation
pipeline that animates a static portrait using facial movements from a driving
video of a different individual. Our work first identifies the root causes of
the key issues in prior approaches, such as identity leakage and difficulty in
capturing subtle and extreme expressions. To address these challenges, we
introduce a fully end-to-end training framework that distills a 1D
identity-agnostic latent motion descriptor from driving image, effectively
controlling motion through cross-attention during image generation. Our
implicit motion descriptor captures expressive facial motion in fine detail,
learned end-to-end from a diverse video dataset without reliance on pretrained
motion detectors. We further enhance expressiveness and disentangle motion
latents from identity cues by supervising their learning with a dual GAN
decoder, alongside spatial and color augmentations. By embedding the driving
motion into a 1D latent vector and controlling motion via cross-attention
rather than additive spatial guidance, our design eliminates the transmission
of spatial-aligned structural clues from the driving condition to the diffusion
backbone, substantially mitigating identity leakage. Extensive experiments
demonstrate that X-NeMo surpasses state-of-the-art baselines, producing highly
expressive animations with superior identity resemblance. Our code and models
are available for research.

</details>


### [13] [Neural Multi-View Self-Calibrated Photometric Stereo without Photometric Stereo Cues](https://arxiv.org/abs/2507.23162)
*Xu Cao,Takafumi Taketomi*

Main category: cs.CV

TL;DR: 一种新的神经渲染方法，可以从多视图图像中重建几何、反射率和光照，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 与需要光照校准或每个视图法线图等中间线索的多视图光度立体法不同，该方法从原始图像中一次性联合优化所有场景参数。

Method: 提出了一种神经逆渲染方法，该方法联合从不同方向光照下的多视图图像中重建几何、空间变化的反射率和光照条件。该方法将几何和反射率表示为神经隐式场，并应用了阴影感知体积渲染。空间网络首先预测每个场景点的符号距离和反射率潜在代码。反射率网络然后根据潜在代码和角度编码的表面法线、视图和光照方向来估计反射率值。

Result: 与其他方法相比，在形状和光照估计方面表现更好，并且能够处理具有挑战性的几何形状和反射率。

Conclusion: 该方法在形状和光照估计精度上优于最先进的法线引导方法，并且能够泛化到未对齐视角的多个光照图像，处理具有挑战性的几何和反射对象。

Abstract: We propose a neural inverse rendering approach that jointly reconstructs
geometry, spatially varying reflectance, and lighting conditions from
multi-view images captured under varying directional lighting. Unlike prior
multi-view photometric stereo methods that require light calibration or
intermediate cues such as per-view normal maps, our method jointly optimizes
all scene parameters from raw images in a single stage. We represent both
geometry and reflectance as neural implicit fields and apply shadow-aware
volume rendering. A spatial network first predicts the signed distance and a
reflectance latent code for each scene point. A reflectance network then
estimates reflectance values conditioned on the latent code and angularly
encoded surface normal, view, and light directions. The proposed method
outperforms state-of-the-art normal-guided approaches in shape and lighting
estimation accuracy, generalizes to view-unaligned multi-light images, and
handles objects with challenging geometry and reflectance.

</details>


### [14] [CNN-based solution for mango classification in agricultural environments](https://arxiv.org/abs/2507.23174)
*Beatriz Díaz Peón,Jorge Torres Gómez,Ariel Fajardo Márquez*

Main category: cs.CV

TL;DR: 本研究设计了一个基于CNN的水果（特别是芒果）检测和分类系统，利用Resnet-18和级联检测器，并通过MatLab App Designer实现了可视化界面，旨在提高农场库存管理中的水果质量评估效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在开发一个能够自动评估水果质量的系统，以应用于农场库存管理，特别是针对芒果水果进行分类。

Method: 本研究采用卷积神经网络（CNN）设计了一个水果检测和分类系统，并选择了Resnet-18作为分类的初步架构，同时使用级联检测器进行检测，以平衡执行速度和计算资源消耗。检测和分类结果通过在MatLab App Designer中开发的图形界面进行展示。

Result: 研究成功开发了一个水果检测和分类系统，能够自动评估水果质量，并通过图形界面展示检测和分类结果。

Conclusion: 该研究提出的结合卷积神经网络和级联检测器的水果检测和分类系统为农业质量控制提供了一个可靠的解决方案。

Abstract: This article exemplifies the design of a fruit detection and classification
system using Convolutional
  Neural Networks (CNN). The goal is to develop a system that automatically
assesses fruit quality for
  farm inventory management. Specifically, a method for mango fruit
classification was developed using
  image processing, ensuring both accuracy and efficiency. Resnet-18 was
selected as the preliminary
  architecture for classification, while a cascade detector was used for
detection, balancing execution speed
  and computational resource consumption. Detection and classification results
were displayed through a
  graphical interface developed in MatLab App Designer, streamlining system
interaction. The integration
  of convolutional neural networks and cascade detectors proffers a reliable
solution for fruit classification
  and detection, with potential applications in agricultural quality control.

</details>


### [15] [Single Image Rain Streak Removal Using Harris Corner Loss and R-CBAM Network](https://arxiv.org/abs/2507.23185)
*Jongwook Si,Sungyoung Kim*

Main category: cs.CV

TL;DR: 通过引入Corner Loss和R-CBAM模块，提出了一种新的雨条去除网络，提高了恢复精度和细节保留能力。


<details>
  <summary>Details</summary>
Motivation: 单张图像的雨条去除问题不仅是简单的去噪，还需要同时保留精细的结构细节和整体视觉质量。

Method: 提出了一种新颖的图像恢复网络，通过引入Corner Loss来约束恢复过程，防止在恢复过程中丢失物体边界和详细纹理信息。此外，在编码器和解码器中引入了残差卷积块注意模块（R-CBAM）来动态调整空间和通道维度上特征的重要性，使网络能够更有效地关注受雨条影响严重的区域。

Result: 提出的方法在Rain100L和Rain100H数据集上取得了显著的性能提升，分别达到了33.29 dB和26.16 dB的PSNR。

Conclusion: 提出的方法在Rain100L和Rain100H数据集上显著优于先前的方法，分别在Rain100L上达到了33.29 dB的PSNR，在Rain100H上达到了26.16 dB。

Abstract: The problem of single-image rain streak removal goes beyond simple noise
suppression, requiring the simultaneous preservation of fine structural details
and overall visual quality. In this study, we propose a novel image restoration
network that effectively constrains the restoration process by introducing a
Corner Loss, which prevents the loss of object boundaries and detailed texture
information during restoration. Furthermore, we propose a Residual
Convolutional Block Attention Module (R-CBAM) Block into the encoder and
decoder to dynamically adjust the importance of features in both spatial and
channel dimensions, enabling the network to focus more effectively on regions
heavily affected by rain streaks. Quantitative evaluations conducted on the
Rain100L and Rain100H datasets demonstrate that the proposed method
significantly outperforms previous approaches, achieving a PSNR of 33.29 dB on
Rain100L and 26.16 dB on Rain100H.

</details>


### [16] [Multi-Modal Motion Retrieval by Learning a Fine-Grained Joint Embedding Space](https://arxiv.org/abs/2507.23188)
*Shiyao Yu,Zi-An Wang,Kangning Yin,Zheng Tian,Mingyuan Zhang,Weixin Si,Shihao Zou*

Main category: cs.CV

TL;DR: 提出了一种包含文本、音频、视频和动作四种模态的动作检索框架，通过细粒度的联合嵌入和序列级对比学习，实现了更直观、用户友好的交互和更优越的检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏直观且用户友好的交互模式，并且常常忽略大多数模态的序列表示以提高检索性能。

Method: 通过序列级对比学习将文本、音频、视频和动作四种模态映射到一个细粒度的联合嵌入空间中，以捕捉跨模态的关键细节。

Result: 在HumanML3D数据集的文本到动作检索任务中，R@10提升了10.16%，在视频到动作检索任务中，R@1提升了25.43%，优于最先进的方法。

Conclusion: 所提出的四模态框架显著优于其三模态对应物，强调了多模态动作检索在推进动作采集方面的潜力。

Abstract: Motion retrieval is crucial for motion acquisition, offering superior
precision, realism, controllability, and editability compared to motion
generation. Existing approaches leverage contrastive learning to construct a
unified embedding space for motion retrieval from text or visual modality.
However, these methods lack a more intuitive and user-friendly interaction mode
and often overlook the sequential representation of most modalities for
improved retrieval performance. To address these limitations, we propose a
framework that aligns four modalities -- text, audio, video, and motion --
within a fine-grained joint embedding space, incorporating audio for the first
time in motion retrieval to enhance user immersion and convenience. This
fine-grained space is achieved through a sequence-level contrastive learning
approach, which captures critical details across modalities for better
alignment. To evaluate our framework, we augment existing text-motion datasets
with synthetic but diverse audio recordings, creating two multi-modal motion
retrieval datasets. Experimental results demonstrate superior performance over
state-of-the-art methods across multiple sub-tasks, including an 10.16%
improvement in R@10 for text-to-motion retrieval and a 25.43% improvement in
R@1 for video-to-motion retrieval on the HumanML3D dataset. Furthermore, our
results show that our 4-modal framework significantly outperforms its 3-modal
counterpart, underscoring the potential of multi-modal motion retrieval for
advancing motion acquisition.

</details>


### [17] [A Novel Dataset for Flood Detection Robust to Seasonal Changes in Satellite Imagery](https://arxiv.org/abs/2507.23193)
*Youngsun Jang,Dongyoun Kim,Chulwoo Pack,Kwanghee Won*

Main category: cs.CV

TL;DR: 介绍了一个新的洪水区域卫星图像分割数据集，并评估了现有模型在该数据集上的表现，结果显示需要改进。


<details>
  <summary>Details</summary>
Motivation: 现有用于卫星图像洪水区域分割的数据集不足，需要一个专门的数据集来填补这一空白。

Method: 收集了2019年中西部美国洪水事件的卫星图像，构建了一个包含10个位置、每个位置10张图像的数据集，并确保了统一的分辨率。在数据集上评估了最先进的语义分割模型，并进行了一项改变窗口大小以捕捉时间特征的消融研究。

Result: 所选模型在该数据集上取得了适度的结果，表明需要进一步的研究。

Conclusion: 现有模型在处理该数据集时表现一般，表明未来需要多模态和时间学习策略来改进洪水区域分割。

Abstract: This study introduces a novel dataset for segmenting flooded areas in
satellite images. After reviewing 77 existing benchmarks utilizing satellite
imagery, we identified a shortage of suitable datasets for this specific task.
To fill this gap, we collected satellite imagery of the 2019 Midwestern USA
floods from Planet Explorer by Planet Labs (Image \c{opyright} 2024 Planet Labs
PBC). The dataset consists of 10 satellite images per location, each containing
both flooded and non-flooded areas. We selected ten locations from each of the
five states: Iowa, Kansas, Montana, Nebraska, and South Dakota. The dataset
ensures uniform resolution and resizing during data processing. For evaluating
semantic segmentation performance, we tested state-of-the-art models in
computer vision and remote sensing on our dataset. Additionally, we conducted
an ablation study varying window sizes to capture temporal characteristics.
Overall, the models demonstrated modest results, suggesting a requirement for
future multimodal and temporal learning strategies. The dataset will be
publicly available on
<https://github.com/youngsunjang/SDSU_MidWest_Flood_2019>.

</details>


### [18] [Adversarial-Guided Diffusion for Multimodal LLM Attacks](https://arxiv.org/abs/2507.23202)
*Chengwei Xia,Fan Ma,Ruijie Quan,Kun Zhan,Yi Yang*

Main category: cs.CV

TL;DR: A new method called AGD can create adversarial images using diffusion models to fool AI, and it's better at it than current methods, even against defenses.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of generating adversarial images using diffusion models to deceive MLLMs, while avoiding significant distortion of the clean image.

Method: AGD injects target semantics into the noise component of the reverse diffusion process, creating adversarial images as a linear combination of the clean image and noise. This inherent full-spectrum property makes it robust to defenses like low-pass filtering.

Result: Extensive experiments demonstrate that AGD outperforms state-of-the-art methods in attack performance and model robustness to some defenses.

Conclusion: The proposed AGD approach outperforms state-of-the-art methods in attack performance and robustness to defenses.

Abstract: This paper addresses the challenge of generating adversarial image using a
diffusion model to deceive multimodal large language models (MLLMs) into
generating the targeted responses, while avoiding significant distortion of the
clean image. To address the above challenges, we propose an adversarial-guided
diffusion (AGD) approach for adversarial attack MLLMs. We introduce
adversarial-guided noise to ensure attack efficacy. A key observation in our
design is that, unlike most traditional adversarial attacks which embed
high-frequency perturbations directly into the clean image, AGD injects target
semantics into the noise component of the reverse diffusion. Since the added
noise in a diffusion model spans the entire frequency spectrum, the adversarial
signal embedded within it also inherits this full-spectrum property.
Importantly, during reverse diffusion, the adversarial image is formed as a
linear combination of the clean image and the noise. Thus, when applying
defenses such as a simple low-pass filtering, which act independently on each
component, the adversarial image within the noise component is less likely to
be suppressed, as it is not confined to the high-frequency band. This makes AGD
inherently robust to variety defenses. Extensive experiments demonstrate that
our AGD outperforms state-of-the-art methods in attack performance as well as
in model robustness to some defenses.

</details>


### [19] [Confidence-aware agglomeration classification and segmentation of 2D microscopic food crystal images](https://arxiv.org/abs/2507.23206)
*Xiaoyu Ji,Ali Shakouri,Fengqing Zhu*

Main category: cs.CV

TL;DR: 提出了一种结合分类和分割的监督学习方法，用于分析食品晶体团聚，解决了手动标注的挑战，并提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 解决手动标注2D显微图像中的食品晶体团聚困难的问题，这种现象会影响食品质量。

Method: 提出了一种监督基线模型来为粗略标记的分类数据集生成分割伪标签，然后训练了一个同时执行像素级分割的实例分类模型。在推理阶段结合了两个模型在分类和分割方面的优势，并通过后处理模块来保留晶体属性。

Result: 该方法在真实阳性团聚分类准确性和尺寸分布预测方面优于现有方法。

Conclusion: 该方法在两个置信度级别下进行评估，并成功分类了潜在的团聚实例。

Abstract: Food crystal agglomeration is a phenomenon occurs during crystallization
which traps water between crystals and affects food product quality. Manual
annotation of agglomeration in 2D microscopic images is particularly difficult
due to the transparency of water bonding and the limited perspective focusing
on a single slide of the imaged sample. To address this challenge, we first
propose a supervised baseline model to generate segmentation pseudo-labels for
the coarsely labeled classification dataset. Next, an instance classification
model that simultaneously performs pixel-wise segmentation is trained. Both
models are used in the inference stage to combine their respective strengths in
classification and segmentation. To preserve crystal properties, a post
processing module is designed and included to both steps. Our method improves
true positive agglomeration classification accuracy and size distribution
predictions compared to other existing methods. Given the variability in
confidence levels of manual annotations, our proposed method is evaluated under
two confidence levels and successfully classifies potential agglomerated
instances.

</details>


### [20] [YOLO-ROC: A High-Precision and Ultra-Lightweight Model for Real-Time Road Damage Detection](https://arxiv.org/abs/2507.23225)
*Zicheng Lin,Weichao Pan*

Main category: cs.CV

TL;DR: 该研究提出了一种轻量化、高精度的道路损伤检测模型YOLO-ROC，通过改进特征提取和压缩模型参数，有效解决了小目标检测难和计算量大的问题，并在多个数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的道路损伤检测方法在多尺度特征提取（尤其小目标）和模型参数量/计算需求方面存在挑战，这阻碍了其在实际应用中的高效、实时部署。

Method: 提出了一种名为YOLO-ROC（YOLO - Road Orthogonal Compact）的高精度轻量化模型，设计了双向多尺度空间金字塔池化快速（BMS-SPPF）模块来增强多尺度特征提取，并采用分层通道压缩策略来降低计算复杂度。BMS-SPPF模块利用双向空间通道注意力机制来提升小目标检测性能，通道压缩策略将参数量从3.01M减少到0.89M，GFLOPs从8.1降低到2.6。

Result: YOLO-ROC模型参数量从3.01M减少到0.89M，GFLOPs从8.1降低到2.6。在RDD2022_China_Drone数据集上，mAP50达到了67.6%，比YOLOv8n高2.11%。小目标D40类别的mAP50提升了16.8%，模型大小为2.0MB，并在RDD2022_China_Motorbike数据集上验证了泛化能力。

Conclusion: YOLO-ROC在RDD2022_China_Drone数据集上实现了67.6%的mAP50，超过了基线YOLOv8n约2.11%，尤其在小目标D40类别上mAP50提升了16.8%，模型大小仅为2.0MB，并在RDD2022_China_Motorbike数据集上表现出良好的泛化性能。

Abstract: Road damage detection is a critical task for ensuring traffic safety and
maintaining infrastructure integrity. While deep learning-based detection
methods are now widely adopted, they still face two core challenges: first, the
inadequate multi-scale feature extraction capabilities of existing networks for
diverse targets like cracks and potholes, leading to high miss rates for
small-scale damage; and second, the substantial parameter counts and
computational demands of mainstream models, which hinder their deployment for
efficient, real-time detection in practical applications. To address these
issues, this paper proposes a high-precision and lightweight model, YOLO - Road
Orthogonal Compact (YOLO-ROC). We designed a Bidirectional Multi-scale Spatial
Pyramid Pooling Fast (BMS-SPPF) module to enhance multi-scale feature
extraction and implemented a hierarchical channel compression strategy to
reduce computational complexity. The BMS-SPPF module leverages a bidirectional
spatial-channel attention mechanism to improve the detection of small targets.
Concurrently, the channel compression strategy reduces the parameter count from
3.01M to 0.89M and GFLOPs from 8.1 to 2.6. Experiments on the
RDD2022_China_Drone dataset demonstrate that YOLO-ROC achieves a mAP50 of
67.6%, surpassing the baseline YOLOv8n by 2.11%. Notably, the mAP50 for the
small-target D40 category improved by 16.8%, and the final model size is only
2.0 MB. Furthermore, the model exhibits excellent generalization performance on
the RDD2022_China_Motorbike dataset.

</details>


### [21] [Toward Safe, Trustworthy and Realistic Augmented Reality User Experience](https://arxiv.org/abs/2507.23226)
*Yanming Xiu*

Main category: cs.CV

TL;DR: 本研究通过ViDDAR和VIM-Sense系统，利用视觉-语言模型检测有害AR内容，并提出未来在AR安全性、感知质量评估和模型部署方面的研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着AR日益融入日常生活，确保其虚拟内容的安全性与可信度至关重要，特别是要应对那些会阻碍关键信息或微妙操纵用户感知的AR内容所带来的风险。

Method: 开发了ViDDAR和VIM-Sense两个系统，利用视觉-语言模型（VLMs）和多模态推理模块来检测任务有害的AR内容，例如阻碍关键信息或操纵用户感知的AR内容。

Result: 提出了三个未来研究方向：虚拟内容的自动化、感知对齐的质量评估；多模态攻击的检测；以及适应VLMs以在AR设备上进行高效且以用户为中心部署。

Conclusion: 本研究旨在建立一个可扩展的、与人类对齐的框架，用于保障增强现实（AR）体验，并就感知建模、多模态AR内容实现和轻量级模型适应性寻求反馈。

Abstract: As augmented reality (AR) becomes increasingly integrated into everyday life,
ensuring the safety and trustworthiness of its virtual content is critical. Our
research addresses the risks of task-detrimental AR content, particularly that
which obstructs critical information or subtly manipulates user perception. We
developed two systems, ViDDAR and VIM-Sense, to detect such attacks using
vision-language models (VLMs) and multimodal reasoning modules. Building on
this foundation, we propose three future directions: automated, perceptually
aligned quality assessment of virtual content; detection of multimodal attacks;
and adaptation of VLMs for efficient and user-centered deployment on AR
devices. Overall, our work aims to establish a scalable, human-aligned
framework for safeguarding AR experiences and seeks feedback on perceptual
modeling, multimodal AR content implementation, and lightweight model
adaptation.

</details>


### [22] [Ambiguity-Guided Learnable Distribution Calibration for Semi-Supervised Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2507.23237)
*Fan Lyu,Linglan Zhao,Chengyan Liu,Yinying Mei,Zhang Zhang,Jian Zhang,Fuyuan Hu,Liang Wang*

Main category: cs.CV

TL;DR: 该研究重新定义了半监督少样本增量学习，并提出了一种名为ALDC的策略来解决包含基类和新类的无标签数据带来的挑战，取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究在半监督少样本增量学习（Semi-FSCIL）中，通常假设无标签数据仅来自当前会话的新类，这与实际情况不符。为了更好地反映现实场景，研究将Semi-FSCIL重新定义为广义半监督少样本增量学习（GSemi-FSCIL），将基类和所有以往的新类都纳入无标签数据集中，这带来了新的挑战，即如何区分无标签数据中来自基类和新类的样本。

Method: 提出了一种名为ALDC（Ambiguity-guided Learnable Distribution Calibration）的策略，该策略动态地利用大量的基类样本来校正少样本新类的有偏特征分布。

Result: 实验结果表明，所提出的ALDC方法在三个基准数据集上取得了优于现有方法（state-of-the-art）的性能。

Conclusion: 该研究提出了ALDC策略，成功解决了无标签数据包含基类和新类时模型特征分布偏差的问题，并在三个基准数据集上取得了优于现有方法的性能，达到了新的最先进水平。

Abstract: Few-Shot Class-Incremental Learning (FSCIL) focuses on models learning new
concepts from limited data while retaining knowledge of previous classes.
Recently, many studies have started to leverage unlabeled samples to assist
models in learning from few-shot samples, giving rise to the field of
Semi-supervised Few-shot Class-Incremental Learning (Semi-FSCIL). However,
these studies often assume that the source of unlabeled data is only confined
to novel classes of the current session, which presents a narrow perspective
and cannot align well with practical scenarios. To better reflect real-world
scenarios, we redefine Semi-FSCIL as Generalized Semi-FSCIL (GSemi-FSCIL) by
incorporating both base and all the ever-seen novel classes in the unlabeled
set. This change in the composition of unlabeled samples poses a new challenge
for existing methods, as they struggle to distinguish between unlabeled samples
from base and novel classes. To address this issue, we propose an
Ambiguity-guided Learnable Distribution Calibration (ALDC) strategy. ALDC
dynamically uses abundant base samples to correct biased feature distributions
for few-shot novel classes. Experiments on three benchmark datasets show that
our method outperforms existing works, setting new state-of-the-art results.

</details>


### [23] [Generalized Reinforcement Learning for Retriever-Specific Query Rewriter with Unstructured Real-World Documents](https://arxiv.org/abs/2507.23242)
*Sungguk Cha,DongWook Kim,Taeseung Hahn,Mintae Kim,Youngsub Han,Byoung-Ki Jeon*

Main category: cs.CV

TL;DR: RL-QR是一种基于强化学习的框架，用于优化RAG系统的查询，无需人工标注，并可用于多模态数据库，在词汇检索方面取得了显著效果，但在语义检索方面仍需改进。


<details>
  <summary>Details</summary>
Motivation: 现实世界中，非结构化文档的多样性给RAG系统的查询优化带来了挑战，需要更有效的方法来改进查询以解锁外部知识。

Method: RL-QR框架利用强化学习和广义奖励策略优化（GRPO）来训练特定检索器的查询重写器，通过合成场景-问题对进行训练，无需人工标注数据集。

Result: RL-QR在工业内部数据上进行了实验，其中RL-QR_multi-modal在多模态RAG的NDCG@3方面实现了11%的相对提升，RL-QR_lexical在词汇检索器方面实现了9%的提升。然而，在语义和混合检索器方面，性能未能得到改善。

Conclusion: RL-QR框架在检索增强生成（RAG）系统的查询优化方面展现出巨大潜力，特别是在消除对人工标注数据集的需求和扩展到多模态数据库方面。尽管在语义和混合检索器方面仍面临挑战，但该方法为提高各种领域检索性能提供了一个可扩展、无需标注的解决方案。

Abstract: Retrieval-Augmented Generation (RAG) systems rely heavily on effective query
formulation to unlock external knowledge, yet optimizing queries for diverse,
unstructured real-world documents remains a challenge. We introduce
\textbf{RL-QR}, a reinforcement learning framework for retriever-specific query
rewriting that eliminates the need for human-annotated datasets and extends
applicability to both text-only and multi-modal databases. By synthesizing
scenario-question pairs and leveraging Generalized Reward Policy Optimization
(GRPO), RL-QR trains query rewriters tailored to specific retrievers, enhancing
retrieval performance across varied domains. Experiments on industrial in-house
data demonstrate significant improvements, with
$\text{RL-QR}_{\text{multi-modal}}$ achieving an 11\% relative gain in NDCG@3
for multi-modal RAG and $\text{RL-QR}_{\text{lexical}}$ yielding a 9\% gain for
lexical retrievers. However, challenges persist with semantic and hybrid
retrievers, where rewriters failed to improve performance, likely due to
training misalignments. Our findings highlight RL-QR's potential to
revolutionize query optimization for RAG systems, offering a scalable,
annotation-free solution for real-world retrieval tasks, while identifying
avenues for further refinement in semantic retrieval contexts.

</details>


### [24] [Automated Mapping the Pathways of Cranial Nerve II, III, V, and VII/VIII: A Multi-Parametric Multi-Stage Diffusion Tractography Atlas](https://arxiv.org/abs/2507.23245)
*Lei Xie,Jiahao Huang,Jiawei Zhang,Jianzhong He,Yiang Pan,Guoqiang Xie,Mengjun Li,Qingrun Zeng,Mingchu Li,Yuanjing Feng*

Main category: cs.CV

TL;DR: 本研究开发了首个自动化颅神经通路映射的dMRI图谱，通过多阶段纤维聚类技术，实现了对多对颅神经的精确识别和空间关系分析，为神经外科规划和脑科学研究提供了有力工具。


<details>
  <summary>Details</summary>
Motivation: 颅神经（CNs）在人脑的各项功能中起着至关重要的作用。通过弥散MRI（dMRI）映射其通路，可以为术前提供宝贵的空间关系信息。然而，由于颅神经独特的解剖结构和颅底环境的复杂性，绘制详尽的颅神经图谱具有挑战性。

Method: 本研究提出了一种新颖的多阶段纤维聚类策略，用于分析来自50名受试者的约1,000,000条纤维束，以生成颅神经图谱。通过对生成的多参数纤维追踪结果进行聚类，实现了对特定颅神经（如视神经、动眼神经、三叉神经、面听神经）纤维束的自动化映射。

Result: 定量和视觉实验表明，所提出的颅神经图谱在HCP数据集、多层弥散MRI（MDM）数据集以及两个垂体瘤患者的临床病例等多个采集位点上，与专家手动标注均实现了高度的空间对应。该图谱能够自动识别与5对颅神经相关的8个纤维束，包括视神经（CN II）、动眼神经（CN III）、三叉神经（CN V）和面听神经（CN VII/VIII），其实验验证了其鲁棒性。

Conclusion: 该研究提出了首个用于自动化映射人脑颅神经通路的三维纤维追踪图谱。该图谱通过对来自50名人类连接组计划（HCP）受试者的多参数纤维追踪生成的大约1,000,000条纤维束进行多阶段纤维聚类来生成，实现了对8个颅神经纤维束（包括视神经（II）、动眼神经（III）、三叉神经（V）和面听神经（VII/VIII））的自动识别。实验证明，该图谱在多个数据集（包括HCP、MDM以及两个垂体瘤临床病例）上与专家手动标注具有高度空间一致性，并验证了其鲁棒性。这项工作通过促进对多对颅神经通路更有效、更自动化的映射，有助于扩散成像领域的发展，并通过可视化其与周围解剖结构的空间关系来增强对复杂大脑结构的分析和理解。

Abstract: Cranial nerves (CNs) play a crucial role in various essential functions of
the human brain, and mapping their pathways from diffusion MRI (dMRI) provides
valuable preoperative insights into the spatial relationships between
individual CNs and key tissues. However, mapping a comprehensive and detailed
CN atlas is challenging because of the unique anatomical structures of each CN
pair and the complexity of the skull base environment.In this work, we present
what we believe to be the first study to develop a comprehensive diffusion
tractography atlas for automated mapping of CN pathways in the human brain. The
CN atlas is generated by fiber clustering by using the streamlines generated by
multi-parametric fiber tractography for each pair of CNs. Instead of disposable
clustering, we explore a new strategy of multi-stage fiber clustering for
multiple analysis of approximately 1,000,000 streamlines generated from the 50
subjects from the Human Connectome Project (HCP). Quantitative and visual
experiments demonstrate that our CN atlas achieves high spatial correspondence
with expert manual annotations on multiple acquisition sites, including the HCP
dataset, the Multi-shell Diffusion MRI (MDM) dataset and two clinical cases of
pituitary adenoma patients. The proposed CN atlas can automatically identify 8
fiber bundles associated with 5 pairs of CNs, including the optic nerve CN II,
oculomotor nerve CN III, trigeminal nerve CN V and facial-vestibulocochlear
nerve CN VII/VIII, and its robustness is demonstrated experimentally. This work
contributes to the field of diffusion imaging by facilitating more efficient
and automated mapping the pathways of multiple pairs of CNs, thereby enhancing
the analysis and understanding of complex brain structures through
visualization of their spatial relationships with nearby anatomy.

</details>


### [25] [A Deep Dive into Generic Object Tracking: A Survey](https://arxiv.org/abs/2507.23251)
*Fereshteh Aghaee Meibodi,Shadi Alijani,Homayoun Najjaran*

Main category: cs.CV

TL;DR: This paper reviews generic object tracking methods, focusing on transformer-based approaches, and provides comparisons and benchmarks.


<details>
  <summary>Details</summary>
Motivation: To address the challenges in generic object tracking, such as complex spatio-temporal dynamics, occlusions, similar distractors, and appearance variations, this paper reviews various tracking paradigms including Siamese-based, discriminative, and transformer-based approaches.

Method: This paper presents a comprehensive review of generic object tracking methods, analyzing core design principles, innovations, and limitations through qualitative and quantitative comparisons. It introduces a novel categorization and offers unified visual and tabular comparisons of representative methods, organizing existing trackers from multiple perspectives and summarizing evaluation benchmarks.

Result: The paper provides a comprehensive review of generic object tracking methods, with a particular emphasis on transformer-based methods. It includes qualitative and quantitative comparisons, a novel categorization, unified visual and tabular comparisons of representative methods, and a summary of evaluation benchmarks, highlighting the advancements in transformer-based tracking.

Conclusion: Transformer-based tracking methods are advancing rapidly due to their robust spatio-temporal modeling capabilities, and this paper provides a comprehensive review of tracking paradigms including Siamese-based, discriminative, and transformer-based approaches, with a novel categorization and comparisons of representative methods.

Abstract: Generic object tracking remains an important yet challenging task in computer
vision due to complex spatio-temporal dynamics, especially in the presence of
occlusions, similar distractors, and appearance variations. Over the past two
decades, a wide range of tracking paradigms, including Siamese-based trackers,
discriminative trackers, and, more recently, prominent transformer-based
approaches, have been introduced to address these challenges. While a few
existing survey papers in this field have either concentrated on a single
category or widely covered multiple ones to capture progress, our paper
presents a comprehensive review of all three categories, with particular
emphasis on the rapidly evolving transformer-based methods. We analyze the core
design principles, innovations, and limitations of each approach through both
qualitative and quantitative comparisons. Our study introduces a novel
categorization and offers a unified visual and tabular comparison of
representative methods. Additionally, we organize existing trackers from
multiple perspectives and summarize the major evaluation benchmarks,
highlighting the fast-paced advancements in transformer-based tracking driven
by their robust spatio-temporal modeling capabilities.

</details>


### [26] [Towards Measuring and Modeling Geometric Structures in Time Series Forecasting via Image Modality](https://arxiv.org/abs/2507.23253)
*Mingyang Yu,Xiahui Guo,Peng chen,Zhenkai Li,Yang Shu*

Main category: cs.CV

TL;DR: 提出TGSI和SATL来评估和优化时间序列的几何结构，实验证明SATL效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统数值指标（如MSE）无法评估时间序列的几何结构，而几何结构对于理解时间动态至关重要。

Method: 提出时间序列几何结构索引（TGSI）来评估时间序列的几何结构，并引入形状感知时间损失（SATL）作为训练损失，SATL包含一阶差分损失、频域损失和感知特征损失。

Result: 实验结果表明，使用SATL训练的模型在MSE和TGSI指标上均优于基线方法。

Conclusion: SATL（Shape-Aware Temporal Loss）通过结合一阶差分损失、频域损失和感知特征损失，能够有效地捕捉时间序列的几何结构，并在MSE和TGSI指标上均优于基线方法，且在推理阶段无额外计算成本。

Abstract: Time Series forecasting is critical in diverse domains such as weather
forecasting, financial investment, and traffic management. While traditional
numerical metrics like mean squared error (MSE) can quantify point-wise
accuracy, they fail to evaluate the geometric structure of time series data,
which is essential to understand temporal dynamics. To address this issue, we
propose the time series Geometric Structure Index (TGSI), a novel evaluation
metric that transforms time series into images to leverage their inherent
two-dimensional geometric representations. However, since the image
transformation process is non-differentiable, TGSI cannot be directly
integrated as a training loss. We further introduce the Shape-Aware Temporal
Loss (SATL), a multi-component loss function operating in the time series
modality to bridge this gap and enhance structure modeling during training.
SATL combines three components: a first-order difference loss that measures
structural consistency through the MSE between first-order differences, a
frequency domain loss that captures essential periodic patterns using the Fast
Fourier Transform while minimizing noise, and a perceptual feature loss that
measures geometric structure difference in time-series by aligning temporal
features with geometric structure features through a pre-trained temporal
feature extractor and time-series image autoencoder. Experiments across
multiple datasets demonstrate that models trained with SATL achieve superior
performance in both MSE and the proposed TGSI metrics compared to baseline
methods, without additional computational cost during inference.

</details>


### [27] [Learning Semantic-Aware Threshold for Multi-Label Image Recognition with Partial Labels](https://arxiv.org/abs/2507.23263)
*Haoxian Ruan,Zhihua Xu,Zhijing Yang,Guang Ma,Jieming Xie,Changxiang Fan,Tianshui Chen*

Main category: cs.CV

TL;DR: SATL算法通过自适应阈值和差异化秩次损失，解决了多标签图像识别中部分标签问题的伪标签质量问题，在标签受限时表现更优。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖语义或特征相关性，使用预设阈值生成伪标签，但忽略了类别间得分分布的差异，导致伪标签不准确不完整，影响模型性能。

Method: SATL算法，计算正负样本得分分布，确定类别特定阈值，并动态更新。引入差异化秩次损失，以拉开正负样本得分分布的差距，增强阈值的区分能力。

Result: 在Microsoft COCO和VG-200等大规模多标签数据集上的实验证明，SATL算法显著提高了标签受限场景下的性能。

Conclusion: SATL算法通过计算正负样本在每个类别上的得分分布并动态更新类别特定阈值，同时引入差异化秩次损失以增强区分度，在标签受限场景下显著提升了多标签图像识别性能。

Abstract: Multi-label image recognition with partial labels (MLR-PL) is designed to
train models using a mix of known and unknown labels. Traditional methods rely
on semantic or feature correlations to create pseudo-labels for unidentified
labels using pre-set thresholds. This approach often overlooks the varying
score distributions across categories, resulting in inaccurate and incomplete
pseudo-labels, thereby affecting performance. In our study, we introduce the
Semantic-Aware Threshold Learning (SATL) algorithm. This innovative approach
calculates the score distribution for both positive and negative samples within
each category and determines category-specific thresholds based on these
distributions. These distributions and thresholds are dynamically updated
throughout the learning process. Additionally, we implement a differential
ranking loss to establish a significant gap between the score distributions of
positive and negative samples, enhancing the discrimination of the thresholds.
Comprehensive experiments and analysis on large-scale multi-label datasets,
such as Microsoft COCO and VG-200, demonstrate that our method significantly
improves performance in scenarios with limited labels.

</details>


### [28] [PixNerd: Pixel Neural Field Diffusion](https://arxiv.org/abs/2507.23268)
*Shuai Wang,Ziteng Gao,Chenhui Zhu,Weilin Huang,Limin Wang*

Main category: cs.CV

TL;DR: PixelNerd 是一种创新的扩散模型，使用神经场直接在像素空间进行补丁解码，无需 VAE，并取得了优异的图像生成结果。


<details>
  <summary>Details</summary>
Motivation: 解决了现有基于 VAE 的扩散 Transformer 中存在的累积误差和解码伪影问题，以及其他像素空间方法带来的复杂级联管道和增加的 token 复杂度。

Method: 提出了一种名为 PixelNerd 的单尺度、单阶段、高效、端到端的解决方案，通过神经场对补丁进行解码。

Result: 在 ImageNet $256	imes256$ 上实现了 2.15 FID，在 ImageNet $512	imes512$ 上实现了 2.84 FID。PixNerd-XXL/16 在 GenEval 基准测试上获得了 0.73 的总体分数，在 DPG 基准测试上获得了 80.9 的总体分数。

Conclusion: PixNerd 框架通过使用神经场进行补丁式解码，实现了无需 VAE 或复杂级联管道的端到端解决方案，在 ImageNet $256	imes256$ 上达到了 2.15 FID，在 ImageNet $512	imes512$ 上达到了 2.84 FID。此外，PixNerd-XXL/16 在 GenEval 基准测试中获得了 0.73 的总体分数，在 DPG 基准测试中获得了 80.9 的总体分数。

Abstract: The current success of diffusion transformers heavily depends on the
compressed latent space shaped by the pre-trained variational autoencoder(VAE).
However, this two-stage training paradigm inevitably introduces accumulated
errors and decoding artifacts. To address the aforementioned problems,
researchers return to pixel space at the cost of complicated cascade pipelines
and increased token complexity. In contrast to their efforts, we propose to
model the patch-wise decoding with neural field and present a single-scale,
single-stage, efficient, end-to-end solution, coined as pixel neural field
diffusion~(PixelNerd). Thanks to the efficient neural field representation in
PixNerd, we directly achieved 2.15 FID on ImageNet $256\times256$ and 2.84 FID
on ImageNet $512\times512$ without any complex cascade pipeline or VAE. We also
extend our PixNerd framework to text-to-image applications. Our PixNerd-XXL/16
achieved a competitive 0.73 overall score on the GenEval benchmark and 80.9
overall score on the DPG benchmark.

</details>


### [29] [Towards Affordable Tumor Segmentation and Visualization for 3D Breast MRI Using SAM2](https://arxiv.org/abs/2507.23272)
*Solha Kang,Eugene Kim,Joris Vankerschaver,Utku Ozbulak*

Main category: cs.CV

TL;DR: 通用基础模型SAM2可以在最少监督的情况下用于3D乳腺MRI肿瘤分割，为资源受限的环境提供了一种可及且经济的替代方案。


<details>
  <summary>Details</summary>
Motivation: 手动解释3D扫描的乳腺MRI仍然耗时且主观，而人工智能工具的商业化采用在低收入和中等收入国家受到高昂的许可证成本、专有软件和基础设施需求的限制。

Method: 研究是否可以将分割任何模型2（SAM2）改编为低成本、最少输入的3D乳腺MRI肿瘤分割。使用单个切片上的单个边界框注释，通过三种不同的切片方式传播分割预测：自顶向下、自底向上和从中心向外。

Result: 在大量患者队列中，从中心向外的传播产生了最一致和最准确的分割。SAM2在最少监督的情况下实现了强大的分割性能，并分析了分割性能与肿瘤大小、位置和形状的关系，确定了关键的失败模式。

Conclusion: 通用基础模型（如SAM2）可以在最少监督的情况下支持3D医学图像分析，为资源受限的环境提供了一种可及且经济的替代方案。

Abstract: Breast MRI provides high-resolution volumetric imaging critical for tumor
assessment and treatment planning, yet manual interpretation of 3D scans
remains labor-intensive and subjective. While AI-powered tools hold promise for
accelerating medical image analysis, adoption of commercial medical AI products
remains limited in low- and middle-income countries due to high license costs,
proprietary software, and infrastructure demands. In this work, we investigate
whether the Segment Anything Model 2 (SAM2) can be adapted for low-cost,
minimal-input 3D tumor segmentation in breast MRI. Using a single bounding box
annotation on one slice, we propagate segmentation predictions across the 3D
volume using three different slice-wise tracking strategies: top-to-bottom,
bottom-to-top, and center-outward. We evaluate these strategies across a large
cohort of patients and find that center-outward propagation yields the most
consistent and accurate segmentations. Despite being a zero-shot model not
trained for volumetric medical data, SAM2 achieves strong segmentation
performance under minimal supervision. We further analyze how segmentation
performance relates to tumor size, location, and shape, identifying key failure
modes. Our results suggest that general-purpose foundation models such as SAM2
can support 3D medical image analysis with minimal supervision, offering an
accessible and affordable alternative for resource-constrained settings.

</details>


### [30] [Online Estimation of Table-Top Grown Strawberry Mass in Field Conditions with Occlusions](https://arxiv.org/abs/2507.23487)
*Jinshan Zhen,Yuanyue Ge,Tianxiao Zhu,Hui Zhao,Ya Xiong*

Main category: cs.CV

TL;DR: 提出了一种基于视觉的管道，集成RGB-D传感和深度学习，用于对田间草莓进行无损、实时和在线的质量估算，特别解决了遮挡和姿态变化的问题。


<details>
  <summary>Details</summary>
Motivation: 在田间条件下，由于频繁的遮挡和姿态变化，对草莓进行精确的质量估算仍然是一个挑战。

Method: 采用YOLOv8-Seg进行实例分割，CycleGAN进行遮挡区域补全，并进行倾斜角度校正以优化正面投影面积计算，最后使用多项式回归模型将几何特征映射到质量。

Result: 实验证明，对于孤立的草莓，平均质量估算误差为8.11%；对于被遮挡的草莓，误差为10.47%。CycleGAN在遮挡恢复方面优于LaMa模型，在像素面积比（PAR）和交并比（IoU）得分方面均表现更佳。

Conclusion: 该方法通过集成RGB-D传感和深度学习，实现了对草莓在复杂遮挡和姿态变化下的无损、实时和在线称重，解决了传统方法的局限性，为自动化收获和产量监测提供了鲁棒的解决方案。

Abstract: Accurate mass estimation of table-top grown strawberries under field
conditions remains challenging due to frequent occlusions and pose variations.
This study proposes a vision-based pipeline integrating RGB-D sensing and deep
learning to enable non-destructive, real-time and online mass estimation. The
method employed YOLOv8-Seg for instance segmentation, Cycle-consistent
generative adversarial network (CycleGAN) for occluded region completion, and
tilt-angle correction to refine frontal projection area calculations. A
polynomial regression model then mapped the geometric features to mass.
Experiments demonstrated mean mass estimation errors of 8.11% for isolated
strawberries and 10.47% for occluded cases. CycleGAN outperformed large mask
inpainting (LaMa) model in occlusion recovery, achieving superior pixel area
ratios (PAR) (mean: 0.978 vs. 1.112) and higher intersection over union (IoU)
scores (92.3% vs. 47.7% in the [0.9-1] range). This approach addresses critical
limitations of traditional methods, offering a robust solution for automated
harvesting and yield monitoring with complex occlusion patterns.

</details>


### [31] [iLRM: An Iterative Large 3D Reconstruction Model](https://arxiv.org/abs/2507.23277)
*Gyeongjin Kang,Seungtae Nam,Xiangyu Sun,Sameh Khamis,Abdelrahman Mohamed,Eunbyung Park*

Main category: cs.CV

TL;DR: iLRM是一种新型的3D建模方法，通过迭代和分阶段注意力机制，解决了现有方法的可扩展性问题，在保证重建质量的同时提高了效率和速度。


<details>
  <summary>Details</summary>
Motivation: 为了实现可扩展且高效的前馈3D重建，克服现有基于Transformer的方法在处理多视图时面临的可扩展性问题。

Method: iLRM通过迭代细化机制生成3D高斯表示，并将全注意力多视图交互分解为两个阶段的注意力方案，同时在每一层注入高分辨率信息，以实现高保真重建。

Result: iLRM在RE10K和DL3DV数据集上，在重建质量和速度上均超越了现有方法，并且在可比的计算成本下，利用更多的输入视图能够获得更高的重建质量。

Conclusion: iLRM在RE10K和DL3DV等常用数据集上的实验结果表明，iLRM在重建质量和速度方面均优于现有方法。值得注意的是，iLRM表现出卓越的可扩展性，通过有效地利用更多的输入视图，在可比的计算成本下显著提高了重建质量。

Abstract: Feed-forward 3D modeling has emerged as a promising approach for rapid and
high-quality 3D reconstruction. In particular, directly generating explicit 3D
representations, such as 3D Gaussian splatting, has attracted significant
attention due to its fast and high-quality rendering, as well as numerous
applications. However, many state-of-the-art methods, primarily based on
transformer architectures, suffer from severe scalability issues because they
rely on full attention across image tokens from multiple input views, resulting
in prohibitive computational costs as the number of views or image resolution
increases. Toward a scalable and efficient feed-forward 3D reconstruction, we
introduce an iterative Large 3D Reconstruction Model (iLRM) that generates 3D
Gaussian representations through an iterative refinement mechanism, guided by
three core principles: (1) decoupling the scene representation from input-view
images to enable compact 3D representations; (2) decomposing fully-attentional
multi-view interactions into a two-stage attention scheme to reduce
computational costs; and (3) injecting high-resolution information at every
layer to achieve high-fidelity reconstruction. Experimental results on widely
used datasets, such as RE10K and DL3DV, demonstrate that iLRM outperforms
existing methods in both reconstruction quality and speed. Notably, iLRM
exhibits superior scalability, delivering significantly higher reconstruction
quality under comparable computational cost by efficiently leveraging a larger
number of input views.

</details>


### [32] [RAGNet: Large-scale Reasoning-based Affordance Segmentation Benchmark towards General Grasping](https://arxiv.org/abs/2507.23734)
*Dongming Wu,Yanping Fu,Saike Huang,Yingfei Liu,Fan Jia,Nian Liu,Feng Dai,Tiancai Wang,Rao Muhammad Anwer,Fahad Shahbaz Khan,Jianbing Shen*

Main category: cs.CV

TL;DR: RAGNet 和 AffordanceNet 解决了机器人抓取中开放世界泛化能力不足的问题。RAGNet 是一个大规模数据集，包含抓取导向的 Affordance 分割和人类指令；AffordanceNet 是一个抓取框架，利用 VLM 和 Affordance 地图进行抓取。实验表明该模型具有强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前的通用机器人抓取系统在多样化的开放世界场景下，需要准确的对象 Affordance 感知，但现有研究缺乏基于推理的大规模 Affordance 预测数据，影响了其在开放世界中的有效性。

Method: 提出了一种名为 RAGNet 的大规模抓取导向的 Affordance 分割基准，其中包含 273k 张图像、180 个类别和 26k 条推理指令。该模型 AffordanceNet 由在 RAGNet 数据上预训练的视觉语言模型 (VLM) 和基于 Affordance 地图的抓取网络组成。

Result: RAGNet 基准包含多样化的数据域，并对图像进行了 Affordance 映射注释，语言指令移除了类别名称，仅提供功能描述。实验证明 AffordanceNet 具有强大的开放世界泛化能力。

Conclusion: 提出的 AffordanceNet 模型在抓取分割基准和真实机器人操作任务上展示了强大的开放世界泛化能力。

Abstract: General robotic grasping systems require accurate object affordance
perception in diverse open-world scenarios following human instructions.
However, current studies suffer from the problem of lacking reasoning-based
large-scale affordance prediction data, leading to considerable concern about
open-world effectiveness. To address this limitation, we build a large-scale
grasping-oriented affordance segmentation benchmark with human-like
instructions, named RAGNet. It contains 273k images, 180 categories, and 26k
reasoning instructions. The images cover diverse embodied data domains, such as
wild, robot, ego-centric, and even simulation data. They are carefully
annotated with an affordance map, while the difficulty of language instructions
is largely increased by removing their category name and only providing
functional descriptions. Furthermore, we propose a comprehensive
affordance-based grasping framework, named AffordanceNet, which consists of a
VLM pre-trained on our massive affordance data and a grasping network that
conditions an affordance map to grasp the target. Extensive experiments on
affordance segmentation benchmarks and real-robot manipulation tasks show that
our model has a powerful open-world generalization ability. Our data and code
is available at https://github.com/wudongming97/AffordanceNet.

</details>


### [33] [UniLiP: Adapting CLIP for Unified Multimodal Understanding, Generation and Editing](https://arxiv.org/abs/2507.23278)
*Hao Tang,Chenwei Xie,Xiaoyi Bao,Tingyu Weng,Pandeng Li,Yun Zheng,Liwei Wang*

Main category: cs.CV

TL;DR: UniLIP enhances CLIP for image reconstruction, generation, and editing using a novel training scheme and architecture, achieving state-of-the-art results without performance degradation.


<details>
  <summary>Details</summary>
Motivation: To extend CLIP's capabilities beyond comprehension to reconstruction, generation, and editing, creating a unified tokenizer without compromising original performance.

Method: UniLIP extends CLIP to reconstruction, generation, and editing by building a unified tokenizer. It uses a two-stage training scheme and a self-distillation strategy to integrate reconstruction capabilities into CLIP without degrading comprehension performance. A dual-condition architecture connects the MLLM and diffusion transformer using learnable queries and the last layer multimodal hidden states.

Result: UniLIP achieves scores of 0.87 (GenEval) and 0.53 (WISE benchmark) in text-to-image generation, surpassing previous unified models. In image editing, it scores 3.62 on the ImgEdit Benchmark, outperforming models like BAGEL and UniWorld-V1.

Conclusion: UniLIP effectively expands the application scope of CLIP, enabling continuous CLIP features to serve not only as the optimal choice for understanding tasks but also achieve highly competitive performance in generation and editing tasks.

Abstract: In this paper, we propose UniLIP, which extends CLIP to reconstruction,
generation and editing, thereby building a unified tokenizer upon its
exceptional comprehension capabilities. Previous CLIP-based unified methods
often require additional diffusion decoders or quantization to support
reconstruction and generation tasks, leading to inconsistent reconstruction or
degradation of original comprehension performance.In contrast, we introduce a
two-stage training scheme and a self-distillation strategy that progressively
integrates reconstruction capabilities into CLIP, allowing it to maintain
original comprehension performance while achieving effective image
reconstruction. Furthermore, we propose a dual-condition architecture to
connect the MLLM and diffusion transformer, using both learnable queries and
the last layer multimodal hidden states as joint conditions. This method not
only enables the utilization of the MLLM's strong reasoning capabilities in
generation tasks, but also maximizes the exploitation of the rich information
in UniLIP features during editing tasks. In text-to-image generation tasks,
UniLIP obtains scores of 0.87 and 0.53 on GenEval and WISE benchmark
respectively, surpassing all previous unified models of similar scale. In image
editing, UniLIP also achieves a score of 3.62 on the ImgEdit Benchmark,
surpassing recent state-of-the-art models such as BAGEL and UniWorld-V1. UniLIP
effectively expand the application scope of CLIP, enabling continuous CLIP
features to not only serve as the optimal choice for understanding tasks but
also achieve highly competitive performance in generation and editing tasks.

</details>


### [34] [Bidirectional Likelihood Estimation with Multi-Modal Large Language Models for Text-Video Retrieval](https://arxiv.org/abs/2507.23284)
*Dohwan Ko,Ji Soo Lee,Minhyuk Choi,Zihang Meng,Hyunwoo J. Kim*

Main category: cs.CV

TL;DR: 该研究提出了一种名为BLiM的新型文本-视频检索框架，通过双向似然估计来解决现有方法中的候选先验偏差问题。同时引入CPN模块进一步校准评分，提升了检索效果和视觉理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于多模态大语言模型（MLLMs）的文本-视频检索方法，在应用MLLMs于长或复杂的查询-候选对时，会引入候选先验偏差，优先考虑那些本身具有更高先验概率的候选，而不是与查询更相关的候选。

Method: 提出了一种新颖的检索框架BLiM（Bidirectional Likelihood Estimation with MLLM），该框架通过训练模型根据给定的视频生成文本，以及根据给定的文本生成视频特征，来同时利用查询和候选的似然性。此外，还引入了一个名为CPN（Candidate Prior Normalization）的训练无关评分校准模块，以缓解候选先验偏差。

Result: BLiM框架结合CPN模块在四个文本-视频检索基准上平均R@1提升6.4，有效缓解了候选先验偏差，并强调了查询-候选相关性。CPN还增强了视觉理解能力，减少了对文本先验的依赖。

Conclusion: BLiM框架结合CPN模块在四个文本-视频检索基准上平均R@1提升6.4，有效缓解了候选先验偏差，并强调了查询-候选相关性。CPN的广泛适用性也通过减少对文本先验的依赖，增强了视觉理解能力。

Abstract: Text-Video Retrieval aims to find the most relevant text (or video) candidate
given a video (or text) query from large-scale online databases. Recent work
leverages multi-modal large language models (MLLMs) to improve retrieval,
especially for long or complex query-candidate pairs. However, we observe that
the naive application of MLLMs, i.e., retrieval based on candidate likelihood,
introduces candidate prior bias, favoring candidates with inherently higher
priors over those more relevant to the query. To this end, we propose a novel
retrieval framework, Bidirectional Likelihood Estimation with MLLM (BLiM),
which leverages both query and candidate likelihoods by training the model to
generate text from a given video as well as video features from a given text.
Furthermore, we introduce Candidate Prior Normalization (CPN), a simple yet
effective training-free score calibration module designed to mitigate candidate
prior bias in candidate likelihood. On four Text-Video Retrieval benchmarks,
our BLiM equipped with CPN outperforms previous state-of-the-art models by 6.4
R@1 on average, effectively alleviating candidate prior bias and emphasizing
query-candidate relevance. Our in-depth analysis across various multi-modal
tasks beyond retrieval highlights the broad applicability of CPN which enhances
visual understanding by reducing reliance on textual priors. Code is available
at https://github.com/mlvlab/BLiM.

</details>


### [35] [LED Benchmark: Diagnosing Structural Layout Errors for Document Layout Analysis](https://arxiv.org/abs/2507.23295)
*Inbum Heo,Taewook Hwang,Jeesu Jung,Sangkeun Jung*

Main category: cs.CV

TL;DR: A new benchmark, LED, evaluates document layout analysis by detecting structural errors, outperforming traditional metrics like IoU and mAP.


<details>
  <summary>Details</summary>
Motivation: Conventional evaluation metrics like IoU and mAP are insufficient for detecting critical structural errors (region merging, splitting, missing content) in document layout analysis.

Method: Propose Layout Error Detection (LED), a novel benchmark for evaluating structural robustness. LED defines eight error types and formulates three tasks: error existence detection, error type classification, and element-wise error type classification. Construct LED-Dataset by injecting realistic structural errors based on empirical distributions from DLA models.

Result: Experiments with LMMs show LED effectively differentiates structural understanding capabilities, exposing modality biases and performance trade-offs.

Conclusion: LED effectively differentiates structural understanding capabilities and reveals modality biases and performance trade-offs not evident in traditional metrics.

Abstract: Recent advancements in Document Layout Analysis through Large Language Models
and Multimodal Models have significantly improved layout detection. However,
despite these improvements, challenges remain in addressing critical structural
errors, such as region merging, splitting, and missing content. Conventional
evaluation metrics like IoU and mAP, which focus primarily on spatial overlap,
are insufficient for detecting these errors. To address this limitation, we
propose Layout Error Detection (LED), a novel benchmark designed to evaluate
the structural robustness of document layout predictions. LED defines eight
standardized error types, and formulates three complementary tasks: error
existence detection, error type classification, and element-wise error type
classification. Furthermore, we construct LED-Dataset, a synthetic dataset
generated by injecting realistic structural errors based on empirical
distributions from DLA models. Experimental results across a range of LMMs
reveal that LED effectively differentiates structural understanding
capabilities, exposing modality biases and performance trade-offs not visible
through traditional metrics.

</details>


### [36] [Training-free Geometric Image Editing on Diffusion Models](https://arxiv.org/abs/2507.23300)
*Hanshen Zhu,Zhen Zhu,Kaile Zhang,Yiming Gong,Yuliang Liu,Xiang Bai*

Main category: cs.CV

TL;DR: 提出了一种名为FreeFine的解耦扩散方法，用于几何图像编辑，在图像保真度和编辑精度方面表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 解决以前基于扩散的编辑方法在处理大尺寸或结构复杂的变换时遇到的困难，这些方法通常尝试一次性处理所有相关的子任务。

Method: 提出了一种解耦流程，将物体变换、源区域修复和目标区域细化分开。修复和细化均采用无需训练的扩散方法FreeFine实现。

Result: 在新的GeoBench基准测试（包含2D和3D编辑场景）上进行的实验表明，FreeFine在图像保真度和编辑精度方面优于最先进的替代方案，尤其是在要求严苛的变换下。

Conclusion: 所提出的解耦流程在图像保真度和编辑精度方面优于最先进的替代方案，尤其是在要求严苛的转换下。

Abstract: We tackle the task of geometric image editing, where an object within an
image is repositioned, reoriented, or reshaped while preserving overall scene
coherence. Previous diffusion-based editing methods often attempt to handle all
relevant subtasks in a single step, proving difficult when transformations
become large or structurally complex. We address this by proposing a decoupled
pipeline that separates object transformation, source region inpainting, and
target region refinement. Both inpainting and refinement are implemented using
a training-free diffusion approach, FreeFine. In experiments on our new
GeoBench benchmark, which contains both 2D and 3D editing scenarios, FreeFine
outperforms state-of-the-art alternatives in image fidelity, and edit
precision, especially under demanding transformations. Code and benchmark are
available at: https://github.com/CIawevy/FreeFine

</details>


### [37] [ST-SAM: SAM-Driven Self-Training Framework for Semi-Supervised Camouflaged Object Detection](https://arxiv.org/abs/2507.23307)
*Xihang Hu,Fuming Sun,Jiazhe Liu,Feilong Xu,Xiaoli Zhang*

Main category: cs.CV

TL;DR: ST-SAM 是一种高效的半监督伪装目标检测框架，通过自训练和混合提示来提高性能，同时减少对标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有的基于教师-学生框架的半监督伪装目标检测方法在稀疏监督下存在严重的预测偏差和错误传播问题，而它们的多网络架构则带来了高计算开销和有限的可扩展性。为了克服这些局限性，我们提出了 ST-SAM，一个高效且简洁的框架。

Method: ST-SAM 框架使用一种动态过滤和扩展高置信度伪标签的自训练策略，以增强单一模型架构，从而规避了模型间的预测偏差。此外，通过将伪标签转化为包含领域特定知识的混合提示，ST-SAM 有效地利用了分割模型（Segment Anything Model）的潜力，以减轻自训练中的错误累积。

Result: ST-SAM 在 COD 基准数据集上的实验表明，仅使用 1% 的标注数据就能实现最先进的性能，优于现有的半监督伪装目标检测方法，甚至能媲美全监督方法。值得注意的是，ST-SAM 仅需训练单一网络，且不依赖于特定的模型或损失函数。

Conclusion: ST-SAM 建立了一种新的、高效的、免标注的半监督伪装目标检测范例。

Abstract: Semi-supervised Camouflaged Object Detection (SSCOD) aims to reduce reliance
on costly pixel-level annotations by leveraging limited annotated data and
abundant unlabeled data. However, existing SSCOD methods based on
Teacher-Student frameworks suffer from severe prediction bias and error
propagation under scarce supervision, while their multi-network architectures
incur high computational overhead and limited scalability. To overcome these
limitations, we propose ST-SAM, a highly annotation-efficient yet concise
framework that breaks away from conventional SSCOD constraints. Specifically,
ST-SAM employs Self-Training strategy that dynamically filters and expands
high-confidence pseudo-labels to enhance a single-model architecture, thereby
fundamentally circumventing inter-model prediction bias. Furthermore, by
transforming pseudo-labels into hybrid prompts containing domain-specific
knowledge, ST-SAM effectively harnesses the Segment Anything Model's potential
for specialized tasks to mitigate error accumulation in self-training.
Experiments on COD benchmark datasets demonstrate that ST-SAM achieves
state-of-the-art performance with only 1\% labeled data, outperforming existing
SSCOD methods and even matching fully supervised methods. Remarkably, ST-SAM
requires training only a single network, without relying on specific models or
loss functions. This work establishes a new paradigm for annotation-efficient
SSCOD. Codes will be available at https://github.com/hu-xh/ST-SAM.

</details>


### [38] [PriorFusion: Unified Integration of Priors for Robust Road Perception in Autonomous Driving](https://arxiv.org/abs/2507.23309)
*Xuewei Tang,Mengmeng Yang,Tuopu Wen,Peijin Jia,Le Cui,Mingshang Luo,Kehua Sheng,Bo Zhang,Diange Yang,Kun Jiang*

Main category: cs.CV

TL;DR: PriorFusion是一种创新的框架，通过融合多种先验信息，显著提高了自动驾驶中复杂道路环境的感知能力，解决了现有方法预测不准的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂、无高清地图支持的自动驾驶场景下，由于未能充分利用道路元素固有的结构化先验，导致预测结果不规则、不准确。为了解决这一挑战，需要一种能有效融合各种先验信息来提升道路元素感知的技术。

Method: 提出了一种名为PriorFusion的统一框架，该框架整合了语义、几何和生成先验来增强道路元素的感知。具体方法包括：引入由形状先验特征引导的实例感知注意力机制；构建了一个编码道路元素低维表示的数据驱动形状模板空间，并通过聚类生成作为参考先验的锚点；设计了一个基于扩散的框架，利用这些先验锚点生成准确且完整的预测。

Result: 在大型自动驾驶数据集上的实验表明，PriorFusion在感知准确性方面取得了显著提升，尤其是在严峻条件下。可视化结果也证实了该方法能够生成更准确、更规则、更连贯的道路元素预测。

Conclusion: PriorFusion通过整合语义、几何和生成先验，显著提高了道路元素感知的准确性，尤其是在具有挑战性的条件下，并生成了更准确、更规则、更连贯的预测。

Abstract: With the growing interest in autonomous driving, there is an increasing
demand for accurate and reliable road perception technologies. In complex
environments without high-definition map support, autonomous vehicles must
independently interpret their surroundings to ensure safe and robust
decision-making. However, these scenarios pose significant challenges due to
the large number, complex geometries, and frequent occlusions of road elements.
A key limitation of existing approaches lies in their insufficient exploitation
of the structured priors inherently present in road elements, resulting in
irregular, inaccurate predictions. To address this, we propose PriorFusion, a
unified framework that effectively integrates semantic, geometric, and
generative priors to enhance road element perception. We introduce an
instance-aware attention mechanism guided by shape-prior features, then
construct a data-driven shape template space that encodes low-dimensional
representations of road elements, enabling clustering to generate anchor points
as reference priors. We design a diffusion-based framework that leverages these
prior anchors to generate accurate and complete predictions. Experiments on
large-scale autonomous driving datasets demonstrate that our method
significantly improves perception accuracy, particularly under challenging
conditions. Visualization results further confirm that our approach produces
more accurate, regular, and coherent predictions of road elements.

</details>


### [39] [Forgetting of task-specific knowledge in model merging-based continual learning](https://arxiv.org/abs/2507.23311)
*Timm Hess,Gido M van de Ven,Tinne Tuytelaars*

Main category: cs.CV

TL;DR: merging models in continual learning preserves shared knowledge but degrades task-specific knowledge, with incremental training being superior.


<details>
  <summary>Details</summary>
Motivation: investigate the linear merging of models in continual learning

Method: linear merging of models

Result: merging models from incremental training outperforms parallel training

Conclusion: merged models preserve or enhance shared knowledge but unshared knowledge degrades

Abstract: This paper investigates the linear merging of models in the context of
continual learning (CL). Using controlled visual cues in computer vision
experiments, we demonstrate that merging largely preserves or enhances shared
knowledge, while unshared task-specific knowledge rapidly degrades. We further
find that merging models from an incremental training process consistently
outperforms merging models trained in parallel.

</details>


### [40] [The Cow of Rembrandt - Analyzing Artistic Prompt Interpretation in Text-to-Image Models](https://arxiv.org/abs/2507.23313)
*Alfio Ferrara,Sergio Picascia,Elisabetta Rocchetti*

Main category: cs.CV

TL;DR: 该研究利用交叉注意力热图分析了文本到图像扩散模型如何区分和表征艺术品中的内容与风格，发现模型在一定程度上能够分离两者，但分离程度因提示和风格而异。


<details>
  <summary>Details</summary>
Motivation: 探究基于transformer的文本到图像扩散模型在生成艺术品时如何内在表征内容和风格概念，因为传统计算机视觉假设内容和风格是正交的，而扩散模型在训练过程中没有收到关于这种区分的明确指导。

Method: 利用交叉注意力热图将生成图像中的像素归因于特定的提示令牌，从而分离受内容描述性与风格描述性令牌影响的图像区域。

Result: 研究发现，扩散模型在内容-风格分离方面表现出不同程度的显现，这取决于具体的艺术提示和所请求的风格。在许多情况下，内容令牌主要影响与对象相关的区域，而风格令牌影响背景和纹理区域。

Conclusion: 该研究揭示了文本到图像扩散模型在没有明确监督的情况下，如何内在表征复杂的艺术概念，并展示了内容和风格的特定分离。

Abstract: Text-to-image diffusion models have demonstrated remarkable capabilities in
generating artistic content by learning from billions of images, including
popular artworks. However, the fundamental question of how these models
internally represent concepts, such as content and style in paintings, remains
unexplored. Traditional computer vision assumes content and style are
orthogonal, but diffusion models receive no explicit guidance about this
distinction during training. In this work, we investigate how transformer-based
text-to-image diffusion models encode content and style concepts when
generating artworks. We leverage cross-attention heatmaps to attribute pixels
in generated images to specific prompt tokens, enabling us to isolate image
regions influenced by content-describing versus style-describing tokens. Our
findings reveal that diffusion models demonstrate varying degrees of
content-style separation depending on the specific artistic prompt and style
requested. In many cases, content tokens primarily influence object-related
regions while style tokens affect background and texture areas, suggesting an
emergent understanding of the content-style distinction. These insights
contribute to our understanding of how large-scale generative models internally
represent complex artistic concepts without explicit supervision. We share the
code and dataset, together with an exploratory tool for visualizing attention
maps at https://github.com/umilISLab/artistic-prompt-interpretation.

</details>


### [41] [Impact of Hyperparameter Optimization on the Accuracy of Lightweight Deep Learning Models for Real-Time Image Classification](https://arxiv.org/abs/2507.23315)
*Vineet Kumar Rakesh,Soumya Mazumdar,Tapas Samanta,Sarbajit Pal,Amitabha Das*

Main category: cs.CV

TL;DR: 本研究分析了超参数调整对七种高效深度学习模型在资源受限环境下的准确性和收敛性的影响，为实时图像分类提供了实用指导。


<details>
  <summary>Details</summary>
Motivation: 为了在资源受限的应用（如嵌入式系统和边缘设备）中实现实时图像分类，研究轻量级卷积和基于 Transformer 的模型，并分析超参数调整对其性能的影响。

Method: 通过在 ImageNet-1K 数据集上进行训练，并对七种高效的深度学习架构（EfficientNetV2-S、ConvNeXt-T、MobileViT v2 (XXS/XS/S)、MobileNetV3-L、TinyViT-21M 和 RepVGG-A2）进行超参数调整，来分析其准确性和收敛行为。研究进行了全面的消融研究，以分离关键超参数（学习率计划、批大小、输入分辨率、数据增强、正则化方法和优化器选择）的影响。

Result: 余弦学习率衰减和可调批大小可显著提高准确性和收敛速度，同时保持低延迟和内存成本。RepVGG-A2 在保持高效推理性能的同时，实现了超过 80% 的 Top-1 准确率。在 GPU 加速的边缘部署模拟中，研究评估了模型的推理时间、参数数量、模型大小和每秒帧数 (FPS)。

Conclusion: 研究结果为在资源受限的应用中构建适用于实时图像处理的资源高效深度学习模型提供了实用的指导，RepVGG-A2 在效率和准确性之间取得了良好的平衡。

Abstract: Lightweight convolutional and transformer-based models have become vital for
real-time image classification in resource-constrained applications, such as
embedded systems and edge devices. This work analyzes the influence of
hyperparameter adjustment on the accuracy and convergence behavior of seven
efficient deep learning architectures: EfficientNetV2-S, ConvNeXt-T, MobileViT
v2 (XXS/XS/S), MobileNetV3-L, TinyViT-21M, and RepVGG-A2. All models are
trained on the ImageNet-1K dataset under consistent training settings, with an
emphasis on real-time practicality. An comprehensive ablation study is
undertaken to separate the effect of critical hyperparameters, including
learning rate schedules, batch sizes, input resolution, data augmentation,
regularization approaches, and optimizer choice. To assess appropriateness for
real-time applications, each model is assessed not only in terms of Top-1 and
Top-5 classification accuracy, but also in terms of inference time, parameter
count, model size, and frames-per-second (FPS) on a GPU-accelerated edge
deployment simulation. Results demonstrate that cosine learning rate decay and
adjustable batch size may greatly boost both accuracy and convergence speed,
while keeping low latency and memory cost. Notably, RepVGG-A2 achieves over 80%
Top-1 accuracy with efficient inference performance, offering a compelling
balance between accuracy and deployment cost for VGG-style models. The results
give practical guidance for constructing resource-efficient deep learning
models appropriate for real-time image processing pipelines. All code and
training logs are publicly accessible at
https://github.com/VineetKumarRakesh/lcnn-opt.

</details>


### [42] [FastDriveVLA: Efficient End-to-End Driving via Plug-and-Play Reconstruction-based Token Pruning](https://arxiv.org/abs/2507.23318)
*Jiajun Cao,Qizhe Zhang,Peidong Jia,Xuhui Zhao,Bo Lan,Xiaoan Zhang,Xiaobao Wei,Sixiang Chen,Zhuo Li,Yang Wang,Liyun Li,Xianming Liu,Ming Lu,Shanghang Zhang*

Main category: cs.CV

TL;DR: FastDriveVLA是一种用于自动驾驶的新型视觉标记剪枝框架，通过MAE风格的像素重建优先考虑前景信息，并在nuScenes闭环规划基准测试中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型的长视觉标记导致计算成本增加。当前VLM的视觉标记剪枝方法（依赖视觉标记相似性或视觉-文本注意力）在自动驾驶场景中表现不佳。人类驾驶员在驾驶时会关注相关的前景区域，因此保留包含前景信息的视觉标记对有效决策至关重要。

Method: 本文提出了一种名为FastDriveVLA的新型重建式视觉标记剪枝框架，专为自动驾驶设计。该框架包含一个即插即用的视觉标记剪枝器ReconPruner，它通过MAE风格的像素重建来优先处理前景信息。为了训练ReconPruner，我们还引入了一个名为nuScenes-FG的大规模数据集，其中包含241K的图像-掩码对，并标注了前景区域。

Result: FastDriveVLA在nuScenes闭环规划基准测试中，在不同的剪枝率下均取得了最先进的成果。

Conclusion: FastDriveVLA在nuScenes闭环规划基准测试中，在不同的剪枝率下均取得了最先进的成果。

Abstract: Vision-Language-Action (VLA) models have demonstrated significant potential
in complex scene understanding and action reasoning, leading to their
increasing adoption in end-to-end autonomous driving systems. However, the long
visual tokens of VLA models greatly increase computational costs. Current
visual token pruning methods in Vision-Language Models (VLM) rely on either
visual token similarity or visual-text attention, but both have shown poor
performance in autonomous driving scenarios. Given that human drivers
concentrate on relevant foreground areas while driving, we assert that
retaining visual tokens containing this foreground information is essential for
effective decision-making. Inspired by this, we propose FastDriveVLA, a novel
reconstruction-based vision token pruning framework designed specifically for
autonomous driving. FastDriveVLA includes a plug-and-play visual token pruner
called ReconPruner, which prioritizes foreground information through MAE-style
pixel reconstruction. A novel adversarial foreground-background reconstruction
strategy is designed to train ReconPruner for the visual encoder of VLA models.
Once trained, ReconPruner can be seamlessly applied to different VLA models
with the same visual encoder without retraining. To train ReconPruner, we also
introduce a large-scale dataset called nuScenes-FG, consisting of 241K
image-mask pairs with annotated foreground regions. Our approach achieves
state-of-the-art results on the nuScenes closed-loop planning benchmark across
different pruning ratios.

</details>


### [43] [FASTopoWM: Fast-Slow Lane Segment Topology Reasoning with Latent World Models](https://arxiv.org/abs/2507.23325)
*Yiming Yang,Hongbin Lin,Yueru Luo,Suzhong Fu,Chao Zheng,Xinrui Yan,Shuqi Mei,Kun Tang,Shuguang Cui,Zhen Li*

Main category: cs.CV

TL;DR: FASTopoWM是一个创新的车道线拓扑推理框架，通过结合快速-慢速系统和潜在世界模型，有效利用时间信息，并增强了对姿态估计失败的鲁棒性，在各项指标上均取得了领先成果。


<details>
  <summary>Details</summary>
Motivation: 现有的车道线拓扑推理方法在利用时间信息方面存在不足，并且容易受到姿态估计失败的影响，时间传播能力也不足。FASTopoWM旨在克服这些限制。

Method: 提出了一种名为FASTopoWM的新型快速-慢速车道线拓扑推理框架，并加入了潜在世界模型。该框架通过并行监督历史和新初始化的查询来减少姿态估计失败的影响，并通过引入潜在查询和BEV世界模型来传播状态表示，增强了时间感知能力。

Result: 在OpenLane-V2基准测试中，FASTopoWM在车道线分割检测（mAP为37.4% vs 33.6%）和中心线感知（OLS为46.3% vs 41.5%）方面均优于最先进的方法。

Conclusion: FASTopoWM框架通过并行监督历史查询和新初始查询，并引入了基于动作隐变量的查询和BEV世界模型，在OpenLane-V2基准测试中，车道线分割检测和中心线感知的性能均优于现有方法。

Abstract: Lane segment topology reasoning provides comprehensive bird's-eye view (BEV)
road scene understanding, which can serve as a key perception module in
planning-oriented end-to-end autonomous driving systems. Existing lane topology
reasoning methods often fall short in effectively leveraging temporal
information to enhance detection and reasoning performance. Recently,
stream-based temporal propagation method has demonstrated promising results by
incorporating temporal cues at both the query and BEV levels. However, it
remains limited by over-reliance on historical queries, vulnerability to pose
estimation failures, and insufficient temporal propagation. To overcome these
limitations, we propose FASTopoWM, a novel fast-slow lane segment topology
reasoning framework augmented with latent world models. To reduce the impact of
pose estimation failures, this unified framework enables parallel supervision
of both historical and newly initialized queries, facilitating mutual
reinforcement between the fast and slow systems. Furthermore, we introduce
latent query and BEV world models conditioned on the action latent to propagate
the state representations from past observations to the current timestep. This
design substantially improves the performance of temporal perception within the
slow pipeline. Extensive experiments on the OpenLane-V2 benchmark demonstrate
that FASTopoWM outperforms state-of-the-art methods in both lane segment
detection (37.4% v.s. 33.6% on mAP) and centerline perception (46.3% v.s. 41.5%
on OLS).

</details>


### [44] [Learning Semantic Directions for Feature Augmentation in Domain-Generalized Medical Segmentation](https://arxiv.org/abs/2507.23326)
*Yingkai Wang,Yaoyao Zhu,Xiuding Cai,Yuhao Xiao,Haotian Wu,Yu Yao*

Main category: cs.CV

TL;DR: 通过隐式特征扰动和自适应一致性约束来提高医学图像分割的域泛化能力，实验证明该方法优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 解决领域转移问题，即模型应用于未见过的临床领域时，由于成像条件、扫描仪类型和采集协议的变化而导致的性能下降，这限制了分割模型的实际部署。

Method: 提出了一种针对医学图像分割的域泛化框架，通过引入由域统计引导的隐式特征扰动来提高对域特定变化的鲁棒性。具体来说，采用可学习的语义方向选择器和基于协方差的语义强度采样器来调节域变特征，同时保持任务相关的解剖一致性。此外，设计了一个适应性一致性约束，仅在特征调整导致分割性能下降时才应用，以稳定特征选择并提高分割的可靠性。

Result: 提出的框架在两个公开的多中心基准上进行了广泛的实验，结果显示其性能优于现有的域泛化方法，实现了跨不同临床域的稳健且可泛化的分割性能。

Conclusion: 该框架在两个公开的多中心基准的广泛实验中，始终优于现有的域泛化方法，在不同临床域实现了稳健且可泛化的分割性能。

Abstract: Medical image segmentation plays a crucial role in clinical workflows, but
domain shift often leads to performance degradation when models are applied to
unseen clinical domains. This challenge arises due to variations in imaging
conditions, scanner types, and acquisition protocols, limiting the practical
deployment of segmentation models. Unlike natural images, medical images
typically exhibit consistent anatomical structures across patients, with
domain-specific variations mainly caused by imaging conditions. This unique
characteristic makes medical image segmentation particularly challenging.
  To address this challenge, we propose a domain generalization framework
tailored for medical image segmentation. Our approach improves robustness to
domain-specific variations by introducing implicit feature perturbations guided
by domain statistics. Specifically, we employ a learnable semantic direction
selector and a covariance-based semantic intensity sampler to modulate
domain-variant features while preserving task-relevant anatomical consistency.
Furthermore, we design an adaptive consistency constraint that is selectively
applied only when feature adjustment leads to degraded segmentation
performance. This constraint encourages the adjusted features to align with the
original predictions, thereby stabilizing feature selection and improving the
reliability of the segmentation.
  Extensive experiments on two public multi-center benchmarks show that our
framework consistently outperforms existing domain generalization approaches,
achieving robust and generalizable segmentation performance across diverse
clinical domains.

</details>


### [45] [Contrastive Learning-Driven Traffic Sign Perception: Multi-Modal Fusion of Text and Vision](https://arxiv.org/abs/2507.23331)
*Qiang Lu,Waikit Xiu,Xiying Li,Shenyu Hu,Shengbo Sun*

Main category: cs.CV

TL;DR: 针对自动驾驶中交通标志识别的长尾分布和小目标挑战，提出了一种结合开放词汇检测（NanoVerse YOLO）和跨模态学习（TSR-MCL）的两阶段框架。该方法通过改进特征提取和对比学习，有效提升了对低频类别和小尺度目标的识别能力，在TT100K数据集上取得了优异的检测和识别性能，准确率和泛化能力均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 解决交通标志识别中存在的两个主要挑战：1. 交通标志数据集的长尾分布问题，导致传统卷积网络在处理低频和分布外类别时识别性能显著下降。2. 真实场景中交通标志多为小目标且尺度变化大，难以提取多尺度特征。

Method: 提出了一种结合开放词汇检测和跨模态学习的新型两阶段框架。使用NanoVerse YOLO模型（包含RepVL-PAN和SPD-Conv模块）来增强对小型、多尺度目标的特征提取。设计了交通标志识别多模态对比学习模型（TSR-MCL），通过对比Vision Transformer的视觉特征和基于规则的BERT的语义特征，学习鲁棒的、与频率无关的表示，有效缓解数据不平衡导致的类别混淆。

Result: 在TT100K数据集上，该方法在长尾检测任务的全局识别中达到了78.4%的mAP，创下最先进水平。同时，模型实现了91.8%的准确率和88.9%的召回率，性能显著优于主流算法，在复杂、开放世界场景中展现出卓越的准确性和泛化能力。

Conclusion: 该方法在TT100K数据集上实现了78.4%的mAP，在长尾检测任务的全局识别中达到了最先进水平，并获得了91.8%的准确率和88.9%的召回率，显著优于主流算法，在复杂、开放世界场景中展现出卓越的准确性和泛化能力。

Abstract: Traffic sign recognition, as a core component of autonomous driving
perception systems, directly influences vehicle environmental awareness and
driving safety. Current technologies face two significant challenges: first,
the traffic sign dataset exhibits a pronounced long-tail distribution,
resulting in a substantial decline in recognition performance of traditional
convolutional networks when processing low-frequency and out-of-distribution
classes; second, traffic signs in real-world scenarios are predominantly small
targets with significant scale variations, making it difficult to extract
multi-scale features.To overcome these issues, we propose a novel two-stage
framework combining open-vocabulary detection and cross-modal learning. For
traffic sign detection, our NanoVerse YOLO model integrates a reparameterizable
vision-language path aggregation network (RepVL-PAN) and an SPD-Conv module to
specifically enhance feature extraction for small, multi-scale targets. For
traffic sign classification, we designed a Traffic Sign Recognition Multimodal
Contrastive Learning model (TSR-MCL). By contrasting visual features from a
Vision Transformer with semantic features from a rule-based BERT, TSR-MCL
learns robust, frequency-independent representations, effectively mitigating
class confusion caused by data imbalance. On the TT100K dataset, our method
achieves a state-of-the-art 78.4% mAP in the long-tail detection task for
all-class recognition. The model also obtains 91.8% accuracy and 88.9% recall,
significantly outperforming mainstream algorithms and demonstrating superior
accuracy and generalization in complex, open-world scenarios.

</details>


### [46] [MagicRoad: Semantic-Aware 3D Road Surface Reconstruction via Obstacle Inpainting](https://arxiv.org/abs/2507.23340)
*Xingyue Peng,Yuandong Lyu,Lang Zhang,Jian Zhu,Songtao Wang,Jiaxin Deng,Songxin Lu,Weiliang Ma,Dangen She,Peng Jia,XianPeng Lang*

Main category: cs.CV

TL;DR: 提出了一种结合了遮挡感知2D高斯曲面和语义引导颜色增强的鲁棒重建框架，用于在复杂城市场景中准确重建路面。


<details>
  <summary>Details</summary>
Motivation: 为了在动态障碍物的遮挡、静态障碍物的视觉混乱以及光照和天气变化引起的外观退化等复杂城市场景中，实现自动驾驶所需的路面感知和高精度地图构建。

Method: 本方法利用平面适应的高斯表示进行高效的大规模建模，采用分割引导的视频修复来移除动态和静态前景对象，并通过在HSV空间中进行语义感知校正来增强颜色一致性。

Result: 在城市规模数据集上的大量实验表明，该框架在真实世界条件下，能够生成视觉上连贯且几何上保真的重建，显著优于现有方法。

Conclusion: 该框架在真实世界条件下显著优于先前方法，能够生成视觉上连贯且几何上忠实的重建。

Abstract: Road surface reconstruction is essential for autonomous driving, supporting
centimeter-accurate lane perception and high-definition mapping in complex
urban environments.While recent methods based on mesh rendering or 3D Gaussian
splatting (3DGS) achieve promising results under clean and static conditions,
they remain vulnerable to occlusions from dynamic agents, visual clutter from
static obstacles, and appearance degradation caused by lighting and weather
changes. We present a robust reconstruction framework that integrates
occlusion-aware 2D Gaussian surfels with semantic-guided color enhancement to
recover clean, consistent road surfaces. Our method leverages a planar-adapted
Gaussian representation for efficient large-scale modeling, employs
segmentation-guided video inpainting to remove both dynamic and static
foreground objects, and enhances color coherence via semantic-aware correction
in HSV space. Extensive experiments on urban-scale datasets demonstrate that
our framework produces visually coherent and geometrically faithful
reconstructions, significantly outperforming prior methods under real-world
conditions.

</details>


### [47] [The Impact of Image Resolution on Face Detection: A Comparative Analysis of MTCNN, YOLOv XI and YOLOv XII models](https://arxiv.org/abs/2507.23341)
*Ahmet Can Ömercikoğlu,Mustafa Mansur Yönügül,Pakize Erdoğmuş*

Main category: cs.CV

TL;DR: 研究了输入分辨率对YOLOv11、YOLOv12和MTCNN人脸检测器准确性和鲁棒性的影响，发现YOLOv11在高分辨率下精度最佳。


<details>
  <summary>Details</summary>
Motivation: 解决低分辨率图像等现实世界条件对人脸检测性能造成的挑战，并为不同操作限制选择适合分辨率感知的人脸检测模型提供可行的见解。

Method: 通过在WIDER FACE数据集上，针对YOLOv11、YOLOv12和MTCNN这三种主流的基于深度学习的人脸检测器，在160x160、320x320和640x640等多种图像分辨率下进行系统的评估，并使用精度、召回率、mAP50、mAP50-95和推理时间等指标进行衡量。

Result: YOLOv11在检测精度方面优于YOLOv12和MTCNN，尤其是在更高分辨率下；YOLOv12的召回率略好；MTCNN在关键点定位方面具有竞争力，但在实时推理速度方面存在不足。

Conclusion: YOLOv11在更高分辨率下表现出最佳的检测精度，YOLOv12具有稍好的召回率，而MTCNN在实时推理速度方面表现不佳。

Abstract: Face detection is a crucial component in many AI-driven applications such as
surveillance, biometric authentication, and human-computer interaction.
However, real-world conditions like low-resolution imagery present significant
challenges that degrade detection performance. In this study, we systematically
investigate the impact of input resolution on the accuracy and robustness of
three prominent deep learning-based face detectors: YOLOv11, YOLOv12, and
MTCNN. Using the WIDER FACE dataset, we conduct extensive evaluations across
multiple image resolutions (160x160, 320x320, and 640x640) and assess each
model's performance using metrics such as precision, recall, mAP50, mAP50-95,
and inference time. Results indicate that YOLOv11 outperforms YOLOv12 and MTCNN
in terms of detection accuracy, especially at higher resolutions, while YOLOv12
exhibits slightly better recall. MTCNN, although competitive in landmark
localization, lags in real-time inference speed. Our findings provide
actionable insights for selecting resolution-aware face detection models
suitable for varying operational constraints.

</details>


### [48] [Who is a Better Talker: Subjective and Objective Quality Assessment for AI-Generated Talking Heads](https://arxiv.org/abs/2507.23343)
*Yingjie Zhou,Jiezhang Cao,Zicheng Zhang,Farong Wen,Yanwei Jiang,Jun Jia,Xiaohong Liu,Xiongkuo Min,Guangtao Zhai*

Main category: cs.CV

TL;DR: 本研究提出了THQA-10K数据集和一种新的目标质量评估方法，以解决AI生成说话头像（AGTH）的质量问题，并在评估方面取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的AI生成说话头像（AGTH）在质量方面仍存在挑战，并且缺乏全面的研究来解决这些问题。因此，本研究旨在通过构建大规模数据集和提出新的评估方法来解决这一差距。

Method: 本研究提出了一个名为THQA-10K的数据集，包含了10,457个AGTH。通过招募志愿者对AGTH进行主观评分和失真类别标注，并分析了说话者的泛化能力和质量，暴露了现有AGTH的失真问题。最后，提出了一种基于第一帧、Y-T切片和音唇一致性的目标质量评估方法。

Result: 本研究构建了THQA-10K数据集，这是迄今为止最大的AGTH质量评估数据集。通过主观评估，分析了说话者的性能并暴露了现有AGTH的失真。提出的目标质量评估方法在实验中表现出最先进（SOTA）的性能。

Conclusion: 该研究提出了一个评估AI生成说话头像（AGTH）质量的目标评估方法，该方法基于第一帧、Y-T切片和音唇一致性，并在AGTH质量评估方面达到了最先进（SOTA）的性能。

Abstract: Speech-driven methods for portraits are figuratively known as "Talkers"
because of their capability to synthesize speaking mouth shapes and facial
movements. Especially with the rapid development of the Text-to-Image (T2I)
models, AI-Generated Talking Heads (AGTHs) have gradually become an emerging
digital human media. However, challenges persist regarding the quality of these
talkers and AGTHs they generate, and comprehensive studies addressing these
issues remain limited. To address this gap, this paper presents the largest
AGTH quality assessment dataset THQA-10K to date, which selects 12 prominent
T2I models and 14 advanced talkers to generate AGTHs for 14 prompts. After
excluding instances where AGTH generation is unsuccessful, the THQA-10K dataset
contains 10,457 AGTHs. Then, volunteers are recruited to subjectively rate the
AGTHs and give the corresponding distortion categories. In our analysis for
subjective experimental results, we evaluate the performance of talkers in
terms of generalizability and quality, and also expose the distortions of
existing AGTHs. Finally, an objective quality assessment method based on the
first frame, Y-T slice and tone-lip consistency is proposed. Experimental
results show that this method can achieve state-of-the-art (SOTA) performance
in AGTH quality assessment. The work is released at
https://github.com/zyj-2000/Talker.

</details>


### [49] [IN45023 Neural Network Design Patterns in Computer Vision Seminar Report, Summer 2025](https://arxiv.org/abs/2507.23357)
*Radu-Andrei Bourceanu,Neil De La Fuente,Jan Grimm,Andrei Jardan,Andriy Manucharyan,Cornelius Weiss,Roman Pflugfelder*

Main category: cs.CV

TL;DR: 计算机视觉领域的设计模式在不断演变，从 ResNet 的残差连接到 ViT 的 Transformer 架构，再到 GAN 和 LDM 的生成能力，以及 DINO 和 MAE 的自监督学习方法。


<details>
  <summary>Details</summary>
Motivation: 本报告旨在分析计算机视觉领域关键设计模式的演变，涵盖了从图像识别到生成模型和自监督学习的里程碑式进展。

Method: 通过审查六篇有影响力的论文，分析了从图像识别的基础架构到生成模型和自监督学习技术的关键设计模式的演变。

Result: 该分析涵盖了 ResNet、ViT、GAN、LDM、DINO 和 MAE 等模型，重点介绍了它们在深度学习、注意力机制、生成能力和自监督学习方面的创新。

Conclusion: 该报告分析了计算机视觉关键设计模式的演变，重点介绍了 ResNet、Vision Transformer (ViT)、生成对抗网络 (GAN)、潜在扩散模型 (LDM)、DINO 和掩码自动编码器 (MAE) 等模型。

Abstract: This report analyzes the evolution of key design patterns in computer vision
by examining six influential papers. The analy- sis begins with foundational
architectures for image recognition. We review ResNet, which introduced
residual connections to overcome the vanishing gradient problem and enable
effective training of significantly deeper convolutional networks.
Subsequently, we examine the Vision Transformer (ViT), which established a new
paradigm by applying the Transformer ar- chitecture to sequences of image
patches, demonstrating the efficacy of attention-based models for large-scale
image recogni- tion. Building on these visual representation backbones, we
investigate generative models. Generative Adversarial Networks (GANs) are
analyzed for their novel adversarial training process, which challenges a
generator against a discriminator to learn complex data distributions. Then,
Latent Diffusion Models (LDMs) are covered, which improve upon prior generative
methods by performing a sequential denoising process in a perceptually
compressed latent space. LDMs achieve high-fidelity synthesis with greater
computational efficiency, representing the current state-of-the-art for image
generation. Finally, we explore self-supervised learning techniques that reduce
dependency on labeled data. DINO is a self-distillation framework in which a
student network learns to match the output of a momentum-updated teacher,
yielding features with strong k-NN classification performance. We conclude with
Masked Autoencoders (MAE), which utilize an asymmetric encoder-decoder design
to reconstruct heavily masked inputs, providing a highly scalable and effective
method for pre-training large-scale vision models.

</details>


### [50] [Short-LVLM: Compressing and Accelerating Large Vision-Language Models by Pruning Redundant Layers](https://arxiv.org/abs/2507.23362)
*Ji Ma,Wei Suo,Peng Wang,Yanning Zhang*

Main category: cs.CV

TL;DR: 该研究发现，直接将NLP中的层剪枝技术应用于LVLMs是无效的，因为存在非必需的VL令牌和层间特征差距。为此，研究人员提出了Short-LVLM（SVL）框架，通过利用重要的VL令牌和缩小层间特征差距来压缩模型，该框架在效率和性能之间取得了良好的平衡，并且具有无需训练、模型无关和高度兼容的优点。


<details>
  <summary>Details</summary>
Motivation: 尽管大型视觉语言模型（LVLMs）在多模态理解和推理方面展现出强大的能力，但它们庞大的模型参数和高昂的计算成本仍然限制了其实际应用。因此，需要一种有效的模型压缩解决方案。

Method: 通过实验证明直接将NLP中的层剪枝方法应用于LVLMs是无效的。发现非必需的视觉-语言（VL）令牌和层间特征差距对LVLMs中的层剪枝构成了关键挑战。基于这些见解，提出了一种名为Short-LVLM（SVL）的新颖框架，该框架可以利用重要的VL令牌并缩小层间特征差距。

Result: SVL框架在性能和效率之间实现了卓越的权衡，并展现出无需训练、模型无关和高度兼容性等优势。

Conclusion: 所提出的Short-LVLM（SVL）框架不仅在性能和效率之间实现了卓越的权衡，而且还展现出一些潜在优势，例如无需训练、模型无关和高度兼容性。

Abstract: Although large vision-language models (LVLMs) have demonstrated impressive
capabilities in multi-modal understanding and reasoning, their practical
applications are still limited by massive model parameters and high
computational costs. Recent efforts from natural language processing (NLP) have
shown the effectiveness of layer pruning, offering a plausible training-free
compression solution. However, due to the modality divergence between vision
and language, it is unclear whether these NLP techniques are still effective in
LVLMs. In this paper, we empirically prove that directly applying these layer
pruning methods to LVLMs is ineffective. Through extensive experiments, we find
that non-essential vision-language (VL) tokens and inter-layer feature gaps
pose critical challenges to pruning layers in LVLMs. Based on these insights,
we propose a novel framework Short-LVLM (SVL) that can utilize important VL
tokens and mitigate the layer-wise feature gaps. Notably, Short-LVLM not only
achieves a superior trade-off between performance and efficiency but also
exhibits several potential advantages, i.e., training-free, model-agnostic, and
highly compatible. The code for this work is publicly available at
https://github.com/ASGO-MM/Short-LVLM.

</details>


### [51] [VMatcher: State-Space Semi-Dense Local Feature Matching](https://arxiv.org/abs/2507.23371)
*Ali Youssef*

Main category: cs.CV

TL;DR: VMatcher 是一种结合 Mamba 和 Transformer 的新方法，用于图像特征匹配，它比纯 Transformer 方法更高效，性能相当或更好，并且适用于实时应用。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有基于 Transformer 的特征匹配方法计算成本高（二次复杂度）的问题，VMatcher 引入了 Mamba 的选择性状态空间模型（SSM），该模型具有线性复杂度，可实现相当或更优的性能并带来显著的效率提升。

Method: VMatcher 采用混合方法，结合了 Mamba 的选择性状态空间模型（SSM）和 Transformer 的注意力机制，以实现高效的长序列处理。

Result: VMatcher 在半密集特征匹配方面设定了新的基准，展示了其在效率、鲁棒性和实用性方面的优势，能够满足实时应用的需求。

Conclusion: VMatcher 是一种混合 Mamba-Transformer 网络，在半密集特征匹配方面设定了新的效率和性能基准，适用于需要快速推理的实时应用。

Abstract: This paper introduces VMatcher, a hybrid Mamba-Transformer network for
semi-dense feature matching between image pairs. Learning-based feature
matching methods, whether detector-based or detector-free, achieve
state-of-the-art performance but depend heavily on the Transformer's attention
mechanism, which, while effective, incurs high computational costs due to its
quadratic complexity. In contrast, Mamba introduces a Selective State-Space
Model (SSM) that achieves comparable or superior performance with linear
complexity, offering significant efficiency gains. VMatcher leverages a hybrid
approach, integrating Mamba's highly efficient long-sequence processing with
the Transformer's attention mechanism. Multiple VMatcher configurations are
proposed, including hierarchical architectures, demonstrating their
effectiveness in setting new benchmarks efficiently while ensuring robustness
and practicality for real-time applications where rapid inference is crucial.
Source Code is available at: https://github.com/ayoussf/VMatcher

</details>


### [52] [UniEmo: Unifying Emotional Understanding and Generation with Learnable Expert Queries](https://arxiv.org/abs/2507.23372)
*Yijie Zhu,Lingsen Zhang,Zitong Yu,Rui Shao,Tao Tan,Liqiang Nie*

Main category: cs.CV

TL;DR: UniEmo是一个统一框架，通过结合情感理解和生成任务，利用双向反馈机制提升了情感理解和生成的效果。


<details>
  <summary>Details</summary>
Motivation: 情感理解和生成任务通常被分开处理，但它们是互补的，可以相互促进。现有方法未充分利用这种互补性。

Method: 提出了一种名为UniEmo的统一框架，通过分层情感理解链和可学习专家查询来提取多尺度情感特征，并将其与情感表示融合，以指导扩散模型生成情感图像。引入情感相关系数和情感条件损失来增强生成图像的多样性和保真度。通过联合训练和数据过滤算法实现生成到理解的双向反馈，提升模型的情感理解能力。

Result: UniEmo在情感理解和生成任务上均取得了显著的性能提升，优于现有最先进方法。

Conclusion: UniEmo框架在情感理解和生成任务上均显著优于现有最先进方法。

Abstract: Emotional understanding and generation are often treated as separate tasks,
yet they are inherently complementary and can mutually enhance each other. In
this paper, we propose the UniEmo, a unified framework that seamlessly
integrates these two tasks. The key challenge lies in the abstract nature of
emotions, necessitating the extraction of visual representations beneficial for
both tasks. To address this, we propose a hierarchical emotional understanding
chain with learnable expert queries that progressively extracts multi-scale
emotional features, thereby serving as a foundational step for unification.
Simultaneously, we fuse these expert queries and emotional representations to
guide the diffusion model in generating emotion-evoking images. To enhance the
diversity and fidelity of the generated emotional images, we further introduce
the emotional correlation coefficient and emotional condition loss into the
fusion process. This step facilitates fusion and alignment for emotional
generation guided by the understanding. In turn, we demonstrate that joint
training allows the generation component to provide implicit feedback to the
understanding part. Furthermore, we propose a novel data filtering algorithm to
select high-quality and diverse emotional images generated by the well-trained
model, which explicitly feedback into the understanding part. Together, these
generation-driven dual feedback processes enhance the model's understanding
capacity. Extensive experiments show that UniEmo significantly outperforms
state-of-the-art methods in both emotional understanding and generation tasks.
The code for the proposed method is available at
https://github.com/JiuTian-VL/UniEmo.

</details>


### [53] [Multi-Prompt Progressive Alignment for Multi-Source Unsupervised Domain Adaptation](https://arxiv.org/abs/2507.23373)
*Haoran Chen,Zexiao Wang,Haidong Cao,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: MP^2A improves CLIP-based UDA by progressively aligning domains, starting with high-confidence samples and gradually including harder ones to prevent errors and learn better features.


<details>
  <summary>Details</summary>
Motivation: Existing methods for Unsupervised Domain Adaptation (UDA) using CLIP struggle with noisy and hard-to-classify samples, leading to error propagation and suboptimal feature learning, especially in multi-source scenarios. This work aims to address this issue by proposing a more stable and effective alignment strategy.

Method: The proposed method, MP^2A, employs a progressive alignment strategy. It begins by training on high-confidence target samples and gradually incorporates more challenging samples to refine the model's understanding, mitigating confirmation bias and promoting robust convergence.

Result: Experiments on ImageCLEF, Office-Home, and DomainNet benchmarks show that MP^2A achieves state-of-the-art performance.

Conclusion: MP^2A achieved state-of-the-art performance compared to recent CLIP-based MS-UDA approaches, demonstrating its effectiveness.

Abstract: Large Vision-Language Models like CLIP have become a powerful foundation for
Unsupervised Domain Adaptation due to their strong zero-shot generalization.
State-of-the-art methods typically leverage CLIP to generate pseudo-labels for
the target domain, then fine-tune the model to learn domain-invariant features.
However, these methods attempt to align source and target domains using all
pseudo-labeled data simultaneously. This one-shot alignment struggles with
noisy, hard-to-classify samples, leading to error propagation and suboptimal
feature learning. The problem is even more amplified in the multi-source
scenario, where diverse domain gaps and varying noise levels across multiple
source domains further destabilize the alignment process. To address this
issue, in this work, we propose a progressive alignment strategy for adapting
CLIP to unlabeled downstream task. Our method begins by training the model on a
high-confidence subset of target samples, allowing it to first learn a
well-aligned representation from the most reliable data. As training
progresses, it gradually incorporates more challenging samples, guiding the
model to refine its understanding without being overwhelmed by initial label
noise. This progressive approach effectively mitigates confirmation bias and
promotes a more robust convergence, allowing for the learning of genuinely
domain-invariant features. We name our approach MP^2A and test it on three
popular UDA benchmarks, namely ImageCLEF, Office-Home, and the most challenging
DomainNet. Experiments showcase that MP^2A achieves state-of-the-art
performance when compared with most recent CLIP-based MS-UDA approaches,
demonstrating the effectiveness of our approach.

</details>


### [54] [NeRF Is a Valuable Assistant for 3D Gaussian Splatting](https://arxiv.org/abs/2507.23374)
*Shuangkang Fang,I-Chao Shen,Takeo Igarashi,Yufeng Wang,ZeSheng Wang,Yi Yang,Wenrui Ding,Shuchang Zhou*

Main category: cs.CV

TL;DR: NeRF-GS框架联合优化NeRF和3DGS，利用NeRF的连续空间表示克服3DGS的局限性，并通过优化残差向量增强个性化能力。实验证明该方法性能优越，表明NeRF和3DGS的结合具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 为了克服3DGS在初始化敏感性、空间意识和类间相关性方面的局限性，并探索NeRF和3DGS的互补性以实现更高效的3D场景表示。

Method: 提出了一种名为NeRF-GS的新框架，该框架可同时优化神经辐射场（NeRF）和3D高斯泼溅（3DGS）。NeRF-GS利用NeRF固有的连续空间表示来克服3DGS的局限性，例如对高斯初始化的敏感性、有限的空间意识和较弱的类间相关性。通过共享3D空间信息，该框架可以同时优化两种表示。此外，通过优化隐式特征和高斯位置的残差向量，NeRF-GS解决了两种方法之间的形式差异，从而提高了3DGS的个性化能力。

Result: 实验结果表明，NeRF-GS在基准数据集上超越了现有方法，达到了最先进的性能。

Conclusion: NeRF和3DGS是互补的，而不是相互竞争的，这为结合3DGS和NeRF进行高效3D场景表示的混合方法提供了新的见解。

Abstract: We introduce NeRF-GS, a novel framework that jointly optimizes Neural
Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS). This framework
leverages the inherent continuous spatial representation of NeRF to mitigate
several limitations of 3DGS, including sensitivity to Gaussian initialization,
limited spatial awareness, and weak inter-Gaussian correlations, thereby
enhancing its performance. In NeRF-GS, we revisit the design of 3DGS and
progressively align its spatial features with NeRF, enabling both
representations to be optimized within the same scene through shared 3D spatial
information. We further address the formal distinctions between the two
approaches by optimizing residual vectors for both implicit features and
Gaussian positions to enhance the personalized capabilities of 3DGS.
Experimental results on benchmark datasets show that NeRF-GS surpasses existing
methods and achieves state-of-the-art performance. This outcome confirms that
NeRF and 3DGS are complementary rather than competing, offering new insights
into hybrid approaches that combine 3DGS and NeRF for efficient 3D scene
representation.

</details>


### [55] [AGA: An adaptive group alignment framework for structured medical cross-modal representation learning](https://arxiv.org/abs/2507.23402)
*Wei Li,Xun Gong,Jiao Li,Xiaobin Sun*

Main category: cs.CV

TL;DR:  AGA框架通过引入双向分组机制和实例感知对齐来解决医学图像和报告的预训练问题，无需负样本，并在检索和分类任务上表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前的医学领域视觉语言预训练方法在处理临床报告时存在简化报告结构、缺乏细粒度信息以及对比学习框架需要大量难负样本（在医学数据集上不切实际）等问题。

Method: 提出了一种名为自适应分组对齐（AGA）的新框架，该框架包含双向分组机制、稀疏相似性矩阵、语言分组阈值门控和视觉分组阈值门控，以及实例感知分组对齐损失和双向跨模态分组对齐模块。

Result: AGA框架能够捕获医学图像和报告的结构化语义，并且在各种设置下都能取得优异的性能。

Conclusion: 该方法在图像-文本检索和分类任务中取得了强大的性能，并且在微调和零样本设置下都表现优异。

Abstract: Learning medical visual representations from paired images and reports is a
promising direction in representation learning. However, current
vision-language pretraining methods in the medical domain often simplify
clinical reports into single entities or fragmented tokens, ignoring their
inherent structure. In addition, contrastive learning frameworks typically
depend on large quantities of hard negative samples, which is impractical for
small-scale medical datasets. To tackle these challenges, we propose Adaptive
Grouped Alignment (AGA), a new framework that captures structured semantics
from paired medical images and reports. AGA introduces a bidirectional grouping
mechanism based on a sparse similarity matrix. For each image-report pair, we
compute fine-grained similarities between text tokens and image patches. Each
token selects its top-matching patches to form a visual group, and each patch
selects its most related tokens to form a language group. To enable adaptive
grouping, we design two threshold gating modules, called Language Grouped
Threshold Gate and Vision Grouped Threshold Gate, which learn grouping
thresholds dynamically. Group representations are computed as weighted averages
based on similarity scores. To align each token with its group representation,
we introduce an Instance Aware Group Alignment loss that operates within each
image-text pair, removing the need for external negatives. Finally, a
Bidirectional Cross-modal Grouped Alignment module is applied to enhance
fine-grained alignment between visual and linguistic group representations.
Extensive experiments on public and private datasets show that our method
achieves strong performance on image-text retrieval and classification tasks
under both fine-tuning and zero-shot settings.

</details>


### [56] [Out-of-Distribution Detection in Medical Imaging via Diffusion Trajectories](https://arxiv.org/abs/2507.23411)
*Lemar Abdi,Francisco Caetano,Amaan Valiuddin,Christiaan Viviers,Hamdi Joudeh,Fons van der Sommen*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In medical imaging, unsupervised out-of-distribution (OOD) detection offers
an attractive approach for identifying pathological cases with extremely low
incidence rates. In contrast to supervised methods, OOD-based approaches
function without labels and are inherently robust to data imbalances. Current
generative approaches often rely on likelihood estimation or reconstruction
error, but these methods can be computationally expensive, unreliable, and
require retraining if the inlier data changes. These limitations hinder their
ability to distinguish nominal from anomalous inputs efficiently, consistently,
and robustly. We propose a reconstruction-free OOD detection method that
leverages the forward diffusion trajectories of a Stein score-based denoising
diffusion model (SBDDM). By capturing trajectory curvature via the estimated
Stein score, our approach enables accurate anomaly scoring with only five
diffusion steps. A single SBDDM pre-trained on a large, semantically aligned
medical dataset generalizes effectively across multiple Near-OOD and Far-OOD
benchmarks, achieving state-of-the-art performance while drastically reducing
computational cost during inference. Compared to existing methods, SBDDM
achieves a relative improvement of up to 10.43% and 18.10% for Near-OOD and
Far-OOD detection, making it a practical building block for real-time, reliable
computer-aided diagnosis.

</details>


### [57] [Honey Adulteration Detection using Hyperspectral Imaging and Machine Learning](https://arxiv.org/abs/2507.23416)
*Mokhtar A. Al-Awadhi,Ratnadeep R. Deshmukh*

Main category: cs.CV

TL;DR: 该研究开发了一种基于高光谱成像和KNN/LDA的机器学习系统，可高精度（96.39%）检测蜂蜜掺糖浆。


<details>
  <summary>Details</summary>
Motivation: 开发一种基于机器学习的系统，利用蜂蜜高光谱成像数据自动检测掺糖浆的掺假行为。

Method: 1. 提取特征：使用线性判别分析（LDA）从蜂蜜样本中提取相关特征。
2. 分类/识别：
   - 植物来源识别子系统：使用K-近邻（KNN）模型对蜂蜜的植物来源进行分类。
   - 掺假检测子系统：使用KNN模型识别掺假水平。

Result: 所提出的系统在公共蜂蜜高光谱图像数据集上进行了评估，在蜂蜜掺假检测方面达到了96.39%的整体交叉验证准确率。

Conclusion: 该研究提出的基于高光谱成像和机器学习的系统能够准确检测蜂蜜掺糖浆的掺假行为，准确率高达96.39%，可替代现有的化学检测方法。

Abstract: This paper aims to develop a machine learning-based system for automatically
detecting honey adulteration with sugar syrup, based on honey hyperspectral
imaging data. First, the floral source of a honey sample is classified by a
botanical origin identification subsystem. Then, the sugar syrup adulteration
is identified, and its concentration is quantified by an adulteration detection
subsystem. Both subsystems consist of two steps. The first step involves
extracting relevant features from the honey sample using Linear Discriminant
Analysis (LDA). In the second step, we utilize the K-Nearest Neighbors (KNN)
model to classify the honey botanical origin in the first subsystem and
identify the adulteration level in the second subsystem. We assess the proposed
system performance on a public honey hyperspectral image dataset. The result
indicates that the proposed system can detect adulteration in honey with an
overall cross-validation accuracy of 96.39%, making it an appropriate
alternative to the current chemical-based detection methods.

</details>


### [58] [Beyond Linear Bottlenecks: Spline-Based Knowledge Distillation for Culturally Diverse Art Style Classification](https://arxiv.org/abs/2507.23436)
*Abdellah Zakaria Sellam,Salah Eddine Bekhouche,Cosimo Distante,Abdelmalik Taleb-Ahmed*

Main category: cs.CV

TL;DR: 通过使用Kolmogorov-Arnold Networks (KANs)替换传统的MLP投影和预测头，改进了双教师自监督框架，以更精确地模拟非线性特征相关性，从而在艺术风格分类任务中取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的双教师自监督框架虽然减少了对标记数据的依赖，但其线性和局部关注的投影层难以模拟全局组合上下文和复杂的风格特征交互。

Method: 通过将传统的MLP投影和预测头替换为Kolmogorov-Arnold Networks (KANs)来增强双教师知识蒸馏框架。该方法保留了两个教师网络的互补指导，一个强调局部纹理和笔触模式，另一个捕捉更广泛的风格层次结构，同时利用KANs的基于样条的激活来精确地模拟非线性特征相关性。

Result: 在WikiArt和Pandora18k上的实验表明，该方法在Top-1准确率上优于基础双教师架构。

Conclusion: KANs在解开复杂的风格流形方面的重要性，其线性探测准确性优于MLP投影。

Abstract: Art style classification remains a formidable challenge in computational
aesthetics due to the scarcity of expertly labeled datasets and the intricate,
often nonlinear interplay of stylistic elements. While recent dual-teacher
self-supervised frameworks reduce reliance on labeled data, their linear
projection layers and localized focus struggle to model global compositional
context and complex style-feature interactions. We enhance the dual-teacher
knowledge distillation framework to address these limitations by replacing
conventional MLP projection and prediction heads with Kolmogorov-Arnold
Networks (KANs). Our approach retains complementary guidance from two teacher
networks, one emphasizing localized texture and brushstroke patterns, the other
capturing broader stylistic hierarchies while leveraging KANs' spline-based
activations to model nonlinear feature correlations with mathematical
precision. Experiments on WikiArt and Pandora18k demonstrate that our approach
outperforms the base dual teacher architecture in Top-1 accuracy. Our findings
highlight the importance of KANs in disentangling complex style manifolds,
leading to better linear probe accuracy than MLP projections.

</details>


### [59] [Adjustable Spatio-Spectral Hyperspectral Image Compression Network](https://arxiv.org/abs/2507.23447)
*Martin Hermann Paul Fuchs,Behnood Rasti,Begüm Demir*

Main category: cs.CV

TL;DR: HyCASS是一种新的高光谱图像压缩方法，可以同时调整光谱和空间压缩，以提高效率并提供指导方针。


<details>
  <summary>Details</summary>
Motivation: 随着遥感高光谱数据量的快速增长，对高效存储的需求日益增加，推动了基于学习的高光谱图像压缩的研究。然而，光谱和空间压缩对基于学习的高光谱图像压缩的单独和联合效应尚未得到充分研究，因此需要进行此类分析以理解时空冗余利用对高光谱图像压缩的影响。

Method: 提出了一种名为HyCASS的可调光谱-空间高光谱图像压缩网络，该网络包含光谱编码器、空间编码器、压缩率适配器编码器、压缩率适配器解码器、空间解码器和光谱解码器模块，并利用卷积层和Transformer块来捕捉时空冗余。

Result: 实验结果表明，HyCASS在两个高光谱图像基准数据集上优于现有的基于学习的压缩模型，并根据压缩率和高光谱图像的空间分辨率，为有效平衡光谱和空间压缩建立了指导方针。

Conclusion: HyCASS通过在不同压缩率下平衡光谱和空间压缩，为高光谱图像压缩提供了有效的指导方针，并在两个基准数据集上证明了其优于现有方法的有效性。

Abstract: With the rapid growth of hyperspectral data archives in remote sensing (RS),
the need for efficient storage has become essential, driving significant
attention toward learning-based hyperspectral image (HSI) compression. However,
a comprehensive investigation of the individual and joint effects of spectral
and spatial compression on learning-based HSI compression has not been
thoroughly examined yet. Conducting such an analysis is crucial for
understanding how the exploitation of spectral, spatial, and joint
spatio-spectral redundancies affects HSI compression. To address this issue, we
propose Adjustable Spatio-Spectral Hyperspectral Image Compression Network
(HyCASS), a learning-based model designed for adjustable HSI compression in
both spectral and spatial dimensions. HyCASS consists of six main modules: 1)
spectral encoder; 2) spatial encoder; 3) compression ratio (CR) adapter
encoder; 4) CR adapter decoder; 5) spatial decoder; and 6) spectral decoder
module. The modules employ convolutional layers and transformer blocks to
capture both short-range and long-range redundancies. Experimental results on
two HSI benchmark datasets demonstrate the effectiveness of our proposed
adjustable model compared to existing learning-based compression models. Based
on our results, we establish a guideline for effectively balancing spectral and
spatial compression across different CRs, taking into account the spatial
resolution of the HSIs. Our code and pre-trained model weights are publicly
available at https://git.tu-berlin.de/rsim/hycass .

</details>


### [60] [Machine learning and machine learned prediction in chest X-ray images](https://arxiv.org/abs/2507.23455)
*Shereiff Garrett,Abhinav Adhikari,Sarina Gautam,DaShawn Marquis Morris,Chandra Mani Adhikari*

Main category: cs.CV

TL;DR: 研究比较了基线CNN和DenseNet-121在胸部X光图像疾病预测中的表现，DenseNet-121因能更好关注关键区域而表现更优。


<details>
  <summary>Details</summary>
Motivation: 利用机器学习和人工智能技术，通过分析胸部X光图像数据，实现对患者疾病的准确预测，以解决复杂的医疗诊断问题。

Method: 使用5824张胸部X光图像，分别实现和比较了基线卷积神经网络（CNN）和DenseNet-121两种机器学习算法在疾病预测方面的表现，并利用梯度加权类激活映射（Grad-CAM）技术可视化分析了模型的决策过程。

Result: 基线CNN和DenseNet-121在预测患者疾病的二元分类问题上均表现优异，其中DenseNet-121通过Grad-CAM分析显示，其决策过程比基线CNN更关注胸部X光图像的关键区域。

Conclusion: DenseNet-121在胸部X光图像的二元分类问题上，相较于基线CNN，能更好地识别图像关键区域，做出更可靠的预测。

Abstract: Machine learning and artificial intelligence are fast-growing fields of
research in which data is used to train algorithms, learn patterns, and make
predictions. This approach helps to solve seemingly intricate problems with
significant accuracy without explicit programming by recognizing complex
relationships in data. Taking an example of 5824 chest X-ray images, we
implement two machine learning algorithms, namely, a baseline convolutional
neural network (CNN) and a DenseNet-121, and present our analysis in making
machine-learned predictions in predicting patients with ailments. Both baseline
CNN and DenseNet-121 perform very well in the binary classification problem
presented in this work. Gradient-weighted class activation mapping shows that
DenseNet-121 correctly focuses on essential parts of the input chest X-ray
images in its decision-making more than the baseline CNN.

</details>


### [61] [Mitigating Resolution-Drift in Federated Learning: Case of Keypoint Detection](https://arxiv.org/abs/2507.23461)
*Taeheon Lim,Joohyung Lee,Kyungjae Lee,Jungchan Cho*

Main category: cs.CV

TL;DR: 本研究解决了联邦学习在处理人类姿态估计等任务时因客户端分辨率不一致导致性能下降的“分辨率漂移”问题，提出了一种名为RAF的自适应方法，通过知识蒸馏技术有效提升了模型的鲁棒性和性能，并证明了其在其他类似任务上的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习（FL）研究主要关注统计异质性和通信效率，在分类任务上取得了成功，但其在人类姿态估计等非分类任务上的应用仍未得到充分探索。特别是“分辨率漂移”问题，即由于客户端之间分辨率的差异导致性能显著下降，这一问题在此前研究中被忽视。

Method: 提出了一种名为RAF（Resolution-Adaptive Federated Learning）的方法，该方法利用基于热图的知识蒸馏，通过高分辨率输出（教师）和低分辨率输出（学生）之间的多分辨率知识蒸馏来增强模型对分辨率的鲁棒性，同时避免过拟合。

Result: 实验和理论分析表明，RAF能有效减轻分辨率漂移，显著提升性能，并能无缝集成到现有的FL框架中。t-SNE分析还揭示了分类任务和高分辨率表示任务在特征表示上的差异，支持了RAF的泛化能力。

Conclusion: RAF可以有效缓解分辨率漂移，在现有联邦学习框架中实现性能提升，并且具有良好的泛化能力，可应用于其他依赖空间细节的任务。

Abstract: The Federated Learning (FL) approach enables effective learning across
distributed systems, while preserving user data privacy. To date, research has
primarily focused on addressing statistical heterogeneity and communication
efficiency, through which FL has achieved success in classification tasks.
However, its application to non-classification tasks, such as human pose
estimation, remains underexplored. This paper identifies and investigates a
critical issue termed ``resolution-drift,'' where performance degrades
significantly due to resolution variability across clients. Unlike class-level
heterogeneity, resolution drift highlights the importance of resolution as
another axis of not independent or identically distributed (non-IID) data. To
address this issue, we present resolution-adaptive federated learning (RAF), a
method that leverages heatmap-based knowledge distillation. Through
multi-resolution knowledge distillation between higher-resolution outputs
(teachers) and lower-resolution outputs (students), our approach enhances
resolution robustness without overfitting. Extensive experiments and
theoretical analysis demonstrate that RAF not only effectively mitigates
resolution drift and achieves significant performance improvements, but also
can be integrated seamlessly into existing FL frameworks. Furthermore, although
this paper focuses on human pose estimation, our t-SNE analysis reveals
distinct characteristics between classification and high-resolution
representation tasks, supporting the generalizability of RAF to other tasks
that rely on preserving spatial detail.

</details>


### [62] [CST Anti-UAV: A Thermal Infrared Benchmark for Tiny UAV Tracking in Complex Scenes](https://arxiv.org/abs/2507.23473)
*Bin Xie,Congxuan Zhang,Fagan Wang,Peng Liu,Feng Lu,Zhen Chen,Weiming Hu*

Main category: cs.CV

TL;DR: CST Anti-UAV是一个新的热红外数据集，用于在复杂场景下跟踪微小无人机，解决了现有数据集的局限性，并揭示了当前跟踪技术的不足。


<details>
  <summary>Details</summary>
Motivation: 解决现有无人机跟踪数据集在应对复杂场景和多样化目标属性方面的不足，以满足真实世界反无人机任务的需求。

Method: 提出CST Anti-UAV数据集，包含220个视频序列和超过24万个高质量边界框标注，重点关注微小尺寸的无人机目标和多样复杂的场景，并进行了手动帧级属性标注。在所提出的CST Anti-UAV数据集上评估了20种现有的单目标跟踪方法。

Result: 现有最先进的方法在CST Anti-UAV数据集上的跟踪精度仅为35.92%，远低于在Anti-UAV410数据集上的67.69%，表明在复杂环境中跟踪微小无人机仍然是一个挑战。

Conclusion: 现有的无人机跟踪数据集在真实场景下的应用性有限，主要因为它们主要关注显眼的物体，并且在场景复杂性和属性表示方面缺乏多样性。CST Anti-UAV 数据集旨在通过包含大量微小尺寸的无人机目标和多样化的复杂场景，并提供手动帧级属性标注，来克服这些局限性，从而促进更鲁棒的单目标跟踪方法和反无人机系统的发展。

Abstract: The widespread application of Unmanned Aerial Vehicles (UAVs) has raised
serious public safety and privacy concerns, making UAV perception crucial for
anti-UAV tasks. However, existing UAV tracking datasets predominantly feature
conspicuous objects and lack diversity in scene complexity and attribute
representation, limiting their applicability to real-world scenarios. To
overcome these limitations, we present the CST Anti-UAV, a new thermal infrared
dataset specifically designed for Single Object Tracking (SOT) in Complex
Scenes with Tiny UAVs (CST). It contains 220 video sequences with over 240k
high-quality bounding box annotations, highlighting two key properties: a
significant number of tiny-sized UAV targets and the diverse and complex
scenes. To the best of our knowledge, CST Anti-UAV is the first dataset to
incorporate complete manual frame-level attribute annotations, enabling precise
evaluations under varied challenges. To conduct an in-depth performance
analysis for CST Anti-UAV, we evaluate 20 existing SOT methods on the proposed
dataset. Experimental results demonstrate that tracking tiny UAVs in complex
environments remains a challenge, as the state-of-the-art method achieves only
35.92% state accuracy, much lower than the 67.69% observed on the Anti-UAV410
dataset. These findings underscore the limitations of existing benchmarks and
the need for further advancements in UAV tracking research. The CST Anti-UAV
benchmark is about to be publicly released, which not only fosters the
development of more robust SOT methods but also drives innovation in anti-UAV
systems.

</details>


### [63] [3D-R1: Enhancing Reasoning in 3D VLMs for Unified Scene Understanding](https://arxiv.org/abs/2507.23478)
*Ting Huang,Zeyu Zhang,Hao Tang*

Main category: cs.CV

TL;DR: 3D-R1通过结合高质量数据集、强化学习和动态视角选择，显著提高了3D视觉语言模型的推理和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决当前3D视觉语言模型（VLMs）在鲁棒推理和泛化方面存在的问题，这些问题源于高质量空间数据的缺乏和视角假设的静态性。

Method: 提出了一种名为3D-R1的基础模型，通过构建包含思维链（CoT）的合成数据集Scene-30K，并利用Gemini 2.5 Pro和GRPO等强化学习技术进行训练。引入了感知奖励、语义相似性奖励和格式奖励，并采用动态视角选择策略。

Result: 3D-R1在多个3D场景理解基准测试中取得了平均10%的提升。

Conclusion: 3D-R1在多个3D场景理解基准测试中平均提高了10%，有效提升了3D场景理解中的推理和泛化能力。

Abstract: Large vision-language models (VLMs) have made significant strides in 2D
visual understanding tasks, sparking interest in extending these capabilities
to 3D scene understanding. However, current 3D VLMs often struggle with robust
reasoning and generalization due to limitations in high-quality spatial data
and the static nature of viewpoint assumptions. To address these challenges, we
propose 3D-R1, a foundation model that enhances the reasoning capabilities of
3D VLMs. Specifically, we first construct a high-quality synthetic dataset with
CoT, named Scene-30K, leveraging existing 3D-VL datasets and a data engine
based on Gemini 2.5 Pro. It serves as cold-start initialization data for 3D-R1.
Moreover, we leverage RLHF policy such as GRPO in the reinforcement learning
training process to enhance reasoning capabilities and introduce three reward
functions: a perception reward, a semantic similarity reward and a format
reward to maintain detection accuracy and answer semantic precision.
Furthermore, we introduce a dynamic view selection strategy that adaptively
chooses the most informative perspectives for 3D scene understanding. Extensive
experiments demonstrate that 3D-R1 delivers an average improvement of 10%
across various 3D scene benchmarks, highlighting its effectiveness in enhancing
reasoning and generalization in 3D scene understanding. Code:
https://github.com/AIGeeksGroup/3D-R1. Website:
https://aigeeksgroup.github.io/3D-R1.

</details>


### [64] [Seeing More with Less: Video Capsule Endoscopy with Multi-Task Learning](https://arxiv.org/abs/2507.23479)
*Julia Werner,Oliver Bause,Julius Oexle,Maxime Le Floch,Franz Brinkmann,Jochen Hampe,Oliver Bringmann*

Main category: cs.CV

TL;DR: 这项研究开发了一个高效的多任务AI模型，用于视频胶囊内窥镜的精确定位和异常检测，参数量少，性能优于现有技术，解决了电池寿命和资源限制问题。


<details>
  <summary>Details</summary>
Motivation: 为了克服视频胶囊内窥镜电池寿命短的挑战，本研究旨在通过集成人工智能技术，实现智能实时决策，从而降低能耗并延长电池寿命。尽管面临数据稀疏和设备资源有限的挑战，但研究致力于在有限的模型规模内实现高效功能。

Method: 本研究引入了一个多任务神经网络，结合了精确的自我定位和异常检测功能，并限制参数总量以适应小型胶囊设备。该模型集成了多任务学习方法和Viterbi解码技术，用于后续的时间序列分析。

Result: 本研究提出的多任务模型在Galar数据集上取得了优异成果，定位任务准确率为93.63%，异常检测任务准确率为87.48%。该模型仅需100万参数，性能超越了现有的单任务模型，是该领域基于人工智能方法的重大进展。

Conclusion: 该研究成功地开发了一个多任务神经网络，能够同时实现小肠的精确定位和异常检测。该模型参数量仅为100万，优于当前基线，将准确率分别提升至93.63%和87.48%，为解决胶囊内窥镜电池寿命和资源限制问题提供了有效途径。

Abstract: Video capsule endoscopy has become increasingly important for investigating
the small intestine within the gastrointestinal tract. However, a persistent
challenge remains the short battery lifetime of such compact sensor edge
devices. Integrating artificial intelligence can help overcome this limitation
by enabling intelligent real-time decision- making, thereby reducing the energy
consumption and prolonging the battery life. However, this remains challenging
due to data sparsity and the limited resources of the device restricting the
overall model size. In this work, we introduce a multi-task neural network that
combines the functionalities of precise self-localization within the
gastrointestinal tract with the ability to detect anomalies in the small
intestine within a single model. Throughout the development process, we
consistently restricted the total number of parameters to ensure the
feasibility to deploy such model in a small capsule. We report the first
multi-task results using the recently published Galar dataset, integrating
established multi-task methods and Viterbi decoding for subsequent time-series
analysis. This outperforms current single-task models and represents a
significant ad- vance in AI-based approaches in this field. Our model achieves
an accu- racy of 93.63% on the localization task and an accuracy of 87.48% on
the anomaly detection task. The approach requires only 1 million parameters
while surpassing the current baselines.

</details>


### [65] [FastPoint: Accelerating 3D Point Cloud Model Inference via Sample Point Distance Prediction](https://arxiv.org/abs/2507.23480)
*Donghyun Lee,Dawoon Jeong,Jae W. Lee,Hongil Yoon*

Main category: cs.CV

TL;DR: FastPoint accelerates 3D point cloud processing by predicting distances in farthest point sampling, achieving significant speedups without accuracy loss.


<details>
  <summary>Details</summary>
Motivation: Handling large and irregular 3D point clouds efficiently remains challenging for deep neural networks.

Method: FastPoint leverages the predictable distance trend between sampled points during farthest point sampling to predict the distance curve and efficiently identify subsequent sample points without exhaustively computing all pairwise distances.

Result: FastPoint achieves 2.55x end-to-end speedup on NVIDIA RTX 3090 GPU when integrated into state-of-the-art 3D point cloud models, while preserving sampling quality and model performance.

Conclusion: FastPoint is a software-based acceleration technique that significantly speeds up farthest point sampling and neighbor search operations in 3D point cloud processing without sacrificing accuracy, achieving 2.55x end-to-end speedup on NVIDIA RTX 3090 GPU.

Abstract: Deep neural networks have revolutionized 3D point cloud processing, yet
efficiently handling large and irregular point clouds remains challenging. To
tackle this problem, we introduce FastPoint, a novel software-based
acceleration technique that leverages the predictable distance trend between
sampled points during farthest point sampling. By predicting the distance
curve, we can efficiently identify subsequent sample points without
exhaustively computing all pairwise distances. Our proposal substantially
accelerates farthest point sampling and neighbor search operations while
preserving sampling quality and model performance. By integrating FastPoint
into state-of-the-art 3D point cloud models, we achieve 2.55x end-to-end
speedup on NVIDIA RTX 3090 GPU without sacrificing accuracy.

</details>


### [66] [Stable-Sim2Real: Exploring Simulation of Real-Captured 3D Data with Two-Stage Depth Diffusion](https://arxiv.org/abs/2507.23483)
*Mutian Xu,Chongjie Ye,Haolin Liu,Yushuang Wu,Jiahao Chang,Xiaoguang Han*

Main category: cs.CV

TL;DR: 本研究提出 Stable-Sim2Real，一种两阶段扩散模型，用于生成更逼真的 3D 数据，以提高 3D 视觉任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 3D 数据模拟方法通常依赖于预定义的物理先验，难以捕捉真实数据的全部复杂性。尽管数据驱动的方法被认为是理想解决方案，但近期研究进展缓慢。本研究旨在探索数据驱动的 3D 模拟新途径。

Method: 提出了一种名为 Stable-Sim2Real 的新颖数据驱动的 3D 数据模拟方法，该方法基于两阶段深度扩散模型。第一阶段微调 Stable-Diffusion 以生成真实和合成深度之间的残差，产生稳定但粗糙的深度图。第二阶段将合成深度和初始输出深度输入到调整了扩散损失的扩散模型中，以优先处理由 3D 判别器识别出的特定区域。

Result: 所提出的方法在真实世界 3D 视觉任务中显著提升了性能，并且生成的 3D 数据与真实捕获的模式高度相似。

Conclusion: Stable-Sim2Real 显著提升了在真实世界 3D 视觉任务中的性能，并且生成的 3D 数据与真实捕获的模式高度相似。

Abstract: 3D data simulation aims to bridge the gap between simulated and real-captured
3D data, which is a fundamental problem for real-world 3D visual tasks. Most 3D
data simulation methods inject predefined physical priors but struggle to
capture the full complexity of real data. An optimal approach involves learning
an implicit mapping from synthetic to realistic data in a data-driven manner,
but progress in this solution has met stagnation in recent studies. This work
explores a new solution path of data-driven 3D simulation, called
Stable-Sim2Real, based on a novel two-stage depth diffusion model. The initial
stage finetunes Stable-Diffusion to generate the residual between the real and
synthetic paired depth, producing a stable but coarse depth, where some local
regions may deviate from realistic patterns. To enhance this, both the
synthetic and initial output depth are fed into a second-stage diffusion, where
diffusion loss is adjusted to prioritize these distinct areas identified by a
3D discriminator. We provide a new benchmark scheme to evaluate 3D data
simulation methods. Extensive experiments show that training the network with
the 3D simulated data derived from our method significantly enhances
performance in real-world 3D visual tasks. Moreover, the evaluation
demonstrates the high similarity between our 3D simulated data and
real-captured patterns. Project page:
https://mutianxu.github.io/stable-sim2real/.

</details>


### [67] [Hyperbolic Cycle Alignment for Infrared-Visible Image Fusion](https://arxiv.org/abs/2507.23508)
*Timing Li,Bing Cao,Jiahe Feng,Haifang Cao,Qinghau Hu,Pengfei Zhu*

Main category: cs.CV

TL;DR: 提出了一种新颖的双曲空间图像配准方法Hy-CycleAlign，解决了跨模态未对齐问题，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于欧氏空间的图像配准方法难以有效处理跨模态未对齐问题，导致配准和融合质量不佳。

Method: 提出了一种基于双路径交叉模态循环配准框架的Hy-CycleAlign网络，该网络将图像映射到双曲空间，并引入了H$^{2}$CA模块来施加配准约束，以处理跨模态未对齐问题。

Result: Hy-CycleAlign网络在配准的准确性和融合的质量上均表现出优于现有方法的性能。

Conclusion: 提出的Hy-CycleAlign网络在图像配准和融合方面显著优于现有方法。

Abstract: Image fusion synthesizes complementary information from multiple sources,
mitigating the inherent limitations of unimodal imaging systems. Accurate image
registration is essential for effective multi-source data fusion. However,
existing registration methods, often based on image translation in Euclidean
space, fail to handle cross-modal misalignment effectively, resulting in
suboptimal alignment and fusion quality. To overcome this limitation, we
explore image alignment in non-Euclidean space and propose a Hyperbolic Cycle
Alignment Network (Hy-CycleAlign). To the best of our knowledge, Hy-CycleAlign
is the first image registration method based on hyperbolic space. It introduces
a dual-path cross-modal cyclic registration framework, in which a forward
registration network aligns cross-modal inputs, while a backward registration
network reconstructs the original image, forming a closed-loop registration
structure with geometric consistency. Additionally, we design a Hyperbolic
Hierarchy Contrastive Alignment (H$^{2}$CA) module, which maps images into
hyperbolic space and imposes registration constraints, effectively reducing
interference caused by modality discrepancies. We further analyze image
registration in both Euclidean and hyperbolic spaces, demonstrating that
hyperbolic space enables more sensitive and effective multi-modal image
registration. Extensive experiments on misaligned multi-modal images
demonstrate that our method significantly outperforms existing approaches in
both image alignment and fusion. Our code will be publicly available.

</details>


### [68] [I Am Big, You Are Little; I Am Right, You Are Wrong](https://arxiv.org/abs/2507.23509)
*David A. Kelly,Akchunya Chanchal,Nathan Blake*

Main category: cs.CV

TL;DR: 提出使用最小充分像素集来分析图像分类模型，发现不同模型架构和分类正确与否与像素集大小和位置有关。


<details>
  <summary>Details</summary>
Motivation: 随着不同尺寸和架构的分类器激增，选择合适的模型变得越来越重要。尽管我们可以统计评估模型的分类准确性，但我们对其工作原理的理解仍然有限。为了深入了解不同视觉模型的决策过程，需要一种新的分析方法。

Method: 提出使用最小充分像素集来衡量模型的“注意力机制”，即模型视角下捕捉图像本质的像素集合。通过比较像素集的位置、重叠和大小来进行分析。

Result: 发现了不同模型架构在像素集的大小和位置上存在统计学上的显著差异，ConvNext和EVA模型与其他模型差异明显。错误分类的图像与更大的像素集相关联。

Conclusion: 不同模型架构在像素集大小和位置上存在统计学上的显著差异，其中ConvNext和EVA模型与其他模型差异明显。此外，错误分类的图像与更大的像素集相关联。

Abstract: Machine learning for image classification is an active and rapidly developing
field. With the proliferation of classifiers of different sizes and different
architectures, the problem of choosing the right model becomes more and more
important.
  While we can assess a model's classification accuracy statistically, our
understanding of the way these models work is unfortunately limited. In order
to gain insight into the decision-making process of different vision models, we
propose using minimal sufficient pixels sets to gauge a model's
`concentration': the pixels that capture the essence of an image through the
lens of the model. By comparing position, overlap, and size of sets of pixels,
we identify that different architectures have statistically different
concentration, in both size and position. In particular, ConvNext and EVA
models differ markedly from the others. We also identify that images which are
misclassified are associated with larger pixels sets than correct
classifications.

</details>


### [69] [ART: Adaptive Relation Tuning for Generalized Relation Prediction](https://arxiv.org/abs/2507.23543)
*Gopika Sudhakaran,Hikaru Shindo,Patrick Schramowski,Simone Schaub-Meyer,Kristian Kersting,Stefan Roth*

Main category: cs.CV

TL;DR: ART通过指令调优和实例选择，提升了VRD模型处理新颖关系的能力，并能在实际应用中用于场景分割。


<details>
  <summary>Details</summary>
Motivation: 现有的VRD模型在脱离训练关系后泛化能力较差，而基于提示调优的方法在处理新颖或复杂关系时存在局限性。作者认为指令调优是更有效的解决方案。

Method: ART框架通过将VRD数据集转换为指令调优格式，并采用自适应采样算法，指导视觉语言模型（VLM）关注信息丰富的关系，从而实现对VLM的自适应关系调优。

Result: ART框架在多个不同复杂度的测试数据集上，相比基线方法取得了显著的性能提升，并且能够推断出未见过关系的概念，这是主流VRD方法所不具备的能力。

Conclusion: ART框架通过指令调优和实例选择，显著提高了视觉关系检测（VRD）模型在处理新颖和复杂关系上的泛化能力，并且能够推断未见过关系概念，在场景分割等实际应用中展现了其价值。

Abstract: Visual relation detection (VRD) is the task of identifying the relationships
between objects in a scene. VRD models trained solely on relation detection
data struggle to generalize beyond the relations on which they are trained.
While prompt tuning has been used to adapt vision-language models (VLMs) for
VRD, it uses handcrafted prompts and struggles with novel or complex relations.
We argue that instruction tuning offers a more effective solution by
fine-tuning VLMs on diverse instructional data. We thus introduce ART, an
Adaptive Relation Tuning framework that adapts VLMs for VRD through instruction
tuning and strategic instance selection. By converting VRD datasets into an
instruction tuning format and employing an adaptive sampling algorithm, ART
directs the VLM to focus on informative relations while maintaining
generalizability. Specifically, we focus on the relation classification, where
subject-object boxes are given and the model predicts the predicate between
them. We tune on a held-in set and evaluate across multiple held-out datasets
of varying complexity. Our approach strongly improves over its baselines and
can infer unseen relation concepts, a capability absent in mainstream VRD
methods. We demonstrate ART's practical value by using the predicted relations
for segmenting complex scenes.

</details>


### [70] [3D-MOOD: Lifting 2D to 3D for Monocular Open-Set Object Detection](https://arxiv.org/abs/2507.23567)
*Yung-Hsu Yang,Luigi Piccinelli,Mattia Segu,Siyuan Li,Rui Huang,Yuqian Fu,Marc Pollefeys,Hermann Blum,Zuria Bauer*

Main category: cs.CV

TL;DR: 本研究提出了 3D-MOOD，一种用于单目 3D 对象检测的开集方法，通过联合 2D/3D 训练和几何先验提升了性能，并在各种基准测试中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的单目 3D 对象检测方法局限于闭集设置，无法处理真实世界应用中出现的新环境和新对象类别。为了解决这个问题，本研究旨在解决单目 3D 对象检测中的开集问题。

Method: 提出了一种名为 3D-MOOD 的端到端模型，通过 3D 边界框头部将开集 2D 检测提升到 3D 空间，实现了 2D 和 3D 任务的联合训练，并引入了几何先验和规范图像空间以提高泛化性和跨数据集训练效率。

Result: 3D-MOOD 在 Omni3D（闭集）和 Omni3D 到 Argoverse 2、ScanNet（开集）上均取得了新的 state-of-the-art 结果。

Conclusion: 3D-MOOD 在闭集和开集设置下均达到了新的 state-of-the-art 结果。

Abstract: Monocular 3D object detection is valuable for various applications such as
robotics and AR/VR. Existing methods are confined to closed-set settings, where
the training and testing sets consist of the same scenes and/or object
categories. However, real-world applications often introduce new environments
and novel object categories, posing a challenge to these methods. In this
paper, we address monocular 3D object detection in an open-set setting and
introduce the first end-to-end 3D Monocular Open-set Object Detector (3D-MOOD).
We propose to lift the open-set 2D detection into 3D space through our designed
3D bounding box head, enabling end-to-end joint training for both 2D and 3D
tasks to yield better overall performance. We condition the object queries with
geometry prior and overcome the generalization for 3D estimation across diverse
scenes. To further improve performance, we design the canonical image space for
more efficient cross-dataset training. We evaluate 3D-MOOD on both closed-set
settings (Omni3D) and open-set settings (Omni3D to Argoverse 2, ScanNet), and
achieve new state-of-the-art results. Code and models are available at
royyang0714.github.io/3D-MOOD.

</details>


### [71] [Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization](https://arxiv.org/abs/2507.23569)
*Maxime Pietrantoni,Gabriela Csurka,Torsten Sattler*

Main category: cs.CV

TL;DR: 提出GSFFs，结合3DGS和隐式特征场，实现准确且保护隐私的视觉定位。


<details>
  <summary>Details</summary>
Motivation: 为了实现准确且保护隐私的视觉定位，利用3D高斯喷溅（3DGS）技术。

Method: 利用3D高斯喷溅（3DGS）和隐式特征场相结合的GSFFs场景表示方法。通过对比学习框架对齐3D尺度感知特征场和2D特征编码器，并利用3D结构感知聚类进行正则化，将特征转换为分割图。最后，通过对齐查询图像的特征图或分割图与GSFFs渲染图来实现姿态精炼和定位。

Result: 提出的GSFFs场景表示方法在多个真实世界数据集上实现了先进的（state-of-the-art）定位性能，同时支持隐私保护和非隐私保护的定位流程。

Conclusion: 该研究提出了高斯喷溅特征场（GSFF），一种结合了显式几何模型（3DGS）和隐式特征场的新型场景表示方法，用于视觉定位。通过对比学习框架和3D结构感知聚类过程，GSFF能够学习到基于3D的鲁棒特征表示，并可转换为用于隐私保护视觉定位的分割图。最终，通过将查询图像的特征图或分割图与GSFFs场景表示的渲染图对齐来进行姿态精炼，实现了先进的视觉定位性能，并在多个真实世界数据集上得到了验证。

Abstract: Visual localization is the task of estimating a camera pose in a known
environment. In this paper, we utilize 3D Gaussian Splatting (3DGS)-based
representations for accurate and privacy-preserving visual localization. We
propose Gaussian Splatting Feature Fields (GSFFs), a scene representation for
visual localization that combines an explicit geometry model (3DGS) with an
implicit feature field. We leverage the dense geometric information and
differentiable rasterization algorithm from 3DGS to learn robust feature
representations grounded in 3D. In particular, we align a 3D scale-aware
feature field and a 2D feature encoder in a common embedding space through a
contrastive framework. Using a 3D structure-informed clustering procedure, we
further regularize the representation learning and seamlessly convert the
features to segmentations, which can be used for privacy-preserving visual
localization. Pose refinement, which involves aligning either feature maps or
segmentations from a query image with those rendered from the GSFFs scene
representation, is used to achieve localization. The resulting privacy- and
non-privacy-preserving localization pipelines, evaluated on multiple real-world
datasets, show state-of-the-art performances.

</details>


### [72] [Beyond Gloss: A Hand-Centric Framework for Gloss-Free Sign Language Translation](https://arxiv.org/abs/2507.23575)
*Sobhan Asasi,Mohamed Ilyas Lakhal,Ozge Mercanoglu Sincan,Richard Bowden*

Main category: cs.CV

TL;DR: BeyondGloss is a new framework for Sign Language Translation that uses Video Large Language Models and fine-grained textual descriptions of hand motion to improve accuracy, achieving state-of-the-art results.


<details>
  <summary>Details</summary>
Motivation: Sign Language Translation (SLT) is challenging due to the modality gap between visual and linguistic information and the need to capture subtle variations in hand shapes and movements. Existing VideoLLMs struggle to model long videos in detail.

Method: BeyondGloss is a novel gloss-free SLT framework that leverages the spatio-temporal reasoning capabilities of Video Large Language Models (VideoLLMs). It generates fine-grained, temporally-aware textual descriptions of hand motion, aligning them with video features using a contrastive alignment module. Features from HaMeR are distilled to enrich hand-specific representations, and a contrastive loss reduces the modality gap during pre-training.

Result: The framework achieves state-of-the-art performance on the Phoenix14T and CSL-Daily benchmarks.

Conclusion: BeyondGloss achieves state-of-the-art performance on the Phoenix14T and CSL-Daily benchmarks, demonstrating the effectiveness of the proposed framework.

Abstract: Sign Language Translation (SLT) is a challenging task that requires bridging
the modality gap between visual and linguistic information while capturing
subtle variations in hand shapes and movements. To address these challenges, we
introduce \textbf{BeyondGloss}, a novel gloss-free SLT framework that leverages
the spatio-temporal reasoning capabilities of Video Large Language Models
(VideoLLMs). Since existing VideoLLMs struggle to model long videos in detail,
we propose a novel approach to generate fine-grained, temporally-aware textual
descriptions of hand motion. A contrastive alignment module aligns these
descriptions with video features during pre-training, encouraging the model to
focus on hand-centric temporal dynamics and distinguish signs more effectively.
To further enrich hand-specific representations, we distill fine-grained
features from HaMeR. Additionally, we apply a contrastive loss between sign
video representations and target language embeddings to reduce the modality gap
in pre-training. \textbf{BeyondGloss} achieves state-of-the-art performance on
the Phoenix14T and CSL-Daily benchmarks, demonstrating the effectiveness of the
proposed framework. We will release the code upon acceptance of the paper.

</details>


### [73] [MamV2XCalib: V2X-based Target-less Infrastructure Camera Calibration with State Space Model](https://arxiv.org/abs/2507.23595)
*Yaoye Zhu,Zhe Wang,Yan Wang*

Main category: cs.CV

TL;DR: A new method, MamV2XCalib, uses autonomous vehicles with LiDAR to calibrate roadside cameras automatically, eliminating the need for manual work or specific targets. It handles data issues and viewpoint changes effectively, showing superior performance in real-world tests.


<details>
  <summary>Details</summary>
Motivation: As cooperative systems using roadside cameras for autonomous vehicle perception become more common, large-scale precise calibration of infrastructure cameras is crucial. Traditional manual calibration is time-consuming, labor-intensive, and may require road closures.

Method: MamV2XCalib is a V2X-based infrastructure camera calibration method that utilizes vehicle-side LiDAR. It employs a targetless LiDAR-camera calibration method combining multi-scale features and a 4D correlation volume. Temporal information is modeled, and rotation angles are estimated using Mamba to handle data defects and viewpoint differences.

Result: Evaluated on V2X-Seq and TUMTraf-V2X datasets, MamV2XCalib demonstrates effectiveness and robustness. It achieves better and more stable calibration performance in V2X scenarios compared to previous methods designed for single-car calibration, with fewer parameters.

Conclusion: MamV2XCalib is an effective and robust V2X-based automatic calibration approach for infrastructure cameras, outperforming previous LiDAR-camera methods in V2X scenarios with fewer parameters.

Abstract: As cooperative systems that leverage roadside cameras to assist autonomous
vehicle perception become increasingly widespread, large-scale precise
calibration of infrastructure cameras has become a critical issue. Traditional
manual calibration methods are often time-consuming, labor-intensive, and may
require road closures. This paper proposes MamV2XCalib, the first V2X-based
infrastructure camera calibration method with the assistance of vehicle-side
LiDAR. MamV2XCalib only requires autonomous vehicles equipped with LiDAR to
drive near the cameras to be calibrated in the infrastructure, without the need
for specific reference objects or manual intervention. We also introduce a new
targetless LiDAR-camera calibration method, which combines multi-scale features
and a 4D correlation volume to estimate the correlation between vehicle-side
point clouds and roadside images. We model the temporal information and
estimate the rotation angles with Mamba, effectively addressing calibration
failures in V2X scenarios caused by defects in the vehicle-side data (such as
occlusions) and large differences in viewpoint. We evaluate MamV2XCalib on the
V2X-Seq and TUMTraf-V2X real-world datasets, demonstrating the effectiveness
and robustness of our V2X-based automatic calibration approach. Compared to
previous LiDAR-camera methods designed for calibration on one car, our approach
achieves better and more stable calibration performance in V2X scenarios with
fewer parameters. The code is available at
https://github.com/zhuyaoye/MamV2XCalib.

</details>


### [74] [MoGA: 3D Generative Avatar Prior for Monocular Gaussian Avatar Reconstruction](https://arxiv.org/abs/2507.23597)
*Zijian Dong,Longteng Duan,Jie Song,Michael J. Black,Andreas Geiger*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We present MoGA, a novel method to reconstruct high-fidelity 3D Gaussian
avatars from a single-view image. The main challenge lies in inferring unseen
appearance and geometric details while ensuring 3D consistency and realism.
Most previous methods rely on 2D diffusion models to synthesize unseen views;
however, these generated views are sparse and inconsistent, resulting in
unrealistic 3D artifacts and blurred appearance. To address these limitations,
we leverage a generative avatar model, that can generate diverse 3D avatars by
sampling deformed Gaussians from a learned prior distribution. Due to the
limited amount of 3D training data such a 3D model alone cannot capture all
image details of unseen identities. Consequently, we integrate it as a prior,
ensuring 3D consistency by projecting input images into its latent space and
enforcing additional 3D appearance and geometric constraints. Our novel
approach formulates Gaussian avatar creation as a model inversion process by
fitting the generative avatar to synthetic views from 2D diffusion models. The
generative avatar provides a meaningful initialization for model fitting,
enforces 3D regularization, and helps in refining pose estimation. Experiments
show that our method surpasses state-of-the-art techniques and generalizes well
to real-world scenarios. Our Gaussian avatars are also inherently animatable

</details>


### [75] [DA-Occ: Efficient 3D Voxel Occupancy Prediction via Directional 2D for Geometric Structure Preservation](https://arxiv.org/abs/2507.23599)
*Yuchen Zhou,Yan Luo,Xiangang Wang,Xingjian Gu,Mingzhou Lu*

Main category: cs.CV

TL;DR: 一种在准确性和速度之间取得良好平衡的3D占用预测方法，通过2D方法和定向注意力机制保留3D几何信息。


<details>
  <summary>Details</summary>
Motivation: 解决当前3D占用预测方法在准确性和实时性之间难以平衡的问题，即许多方法牺牲了推理速度以追求高准确性。

Method: 提出一种定向纯2D方法，通过切片3D体素特征来保留垂直几何信息，并采用定向注意力机制提取几何特征。

Result: 在Occ3D-nuScenes数据集上，实现了39.3%的mIoU和27.7 FPS的推理速度；在边缘设备上，推理速度达到14.8 FPS。

Conclusion: 该方法通过定向纯2D方法，利用切片3D体素特征来保留完整的垂直几何信息，有效弥补了BEV表示中高度线索的损失，从而保持了3D几何结构的完整性。通过使用定向注意力机制，能够有效地从不同方向提取几何特征，在准确性和计算效率之间取得了良好的平衡。在Occ3D-nuScenes数据集上，该方法实现了39.3%的mIoU和27.7 FPS的推理速度，证明了其在平衡准确性和效率方面的优势。在边缘设备模拟中，推理速度达到了14.8 FPS，进一步展示了该方法在资源受限环境中进行实时部署的适用性。

Abstract: Efficient and high-accuracy 3D occupancy prediction is crucial for ensuring
the performance of autonomous driving (AD) systems. However, many current
methods focus on high accuracy at the expense of real-time processing needs. To
address this challenge of balancing accuracy and inference speed, we propose a
directional pure 2D approach. Our method involves slicing 3D voxel features to
preserve complete vertical geometric information. This strategy compensates for
the loss of height cues in Bird's-Eye View (BEV) representations, thereby
maintaining the integrity of the 3D geometric structure. By employing a
directional attention mechanism, we efficiently extract geometric features from
different orientations, striking a balance between accuracy and computational
efficiency. Experimental results highlight the significant advantages of our
approach for autonomous driving. On the Occ3D-nuScenes, the proposed method
achieves an mIoU of 39.3% and an inference speed of 27.7 FPS, effectively
balancing accuracy and efficiency. In simulations on edge devices, the
inference speed reaches 14.8 FPS, further demonstrating the method's
applicability for real-time deployment in resource-constrained environments.

</details>


### [76] [Mamba-based Efficient Spatio-Frequency Motion Perception for Video Camouflaged Object Detection](https://arxiv.org/abs/2507.23601)
*Xin Li,Keren Fu,Qijun Zhao*

Main category: cs.CV

TL;DR: Vcamba是一种利用Mamba模型进行视频伪装目标检测的新方法，通过融合时空频率特征来提高检测精度和效率。


<details>
  <summary>Details</summary>
Motivation: 现有视频伪装目标检测（VCOD）方法主要依赖空间外观特征来感知运动线索以打破伪装，但前景和背景的高度相似性限制了空间外观特征的区分能力。频率特征可以增强特征表示，弥补外观的不足，并通过频率能量的动态变化感知运动。同时，Mamba模型具有线性的长序列建模能力，能够有效感知帧序列中的运动线索。因此，提出一种结合频率和空间特征，利用Mamba模型进行时空频率运动感知的Vcamba模型。

Method: 提出了一种名为Vcamba的新型视觉伪装Mamba模型，该模型基于时空频率运动感知，整合了频率和空间特征。具体包括：1. 感受野视觉状态空间（RFVSS）模块：在序列建模后提取多尺度空间特征。2. 自适应频域分量增强（AFE）模块：采用新颖的频域序列扫描策略进行频率学习，以保持语义一致性。3. 基于空间的远程运动感知（SLMP）模块和基于频率的远程运动感知（FLMP）模块：分别在空间和频率域对时空和频域序列进行建模。4. 空间频率运动融合（SFMF）模块：融合双域特征以实现统一的运动表示。

Result: Vcamba在2个数据集的6个评估指标上均优于现有最先进的方法，并具有较低的计算成本，验证了其优越性。

Conclusion: Vcamba通过融合空间特征和频率特征，利用Mamba模型强大的长序列建模能力，实现了高效准确的视频伪装目标检测，并在6个评估指标和2个数据集上超越了现有最先进的方法，同时计算成本更低。

Abstract: Existing video camouflaged object detection (VCOD) methods primarily rely on
spatial appearance features to perceive motion cues for breaking camouflage.
However, the high similarity between foreground and background in VCOD results
in limited discriminability of spatial appearance features (e.g., color and
texture), restricting detection accuracy and completeness. Recent studies
demonstrate that frequency features can not only enhance feature representation
to compensate for appearance limitations but also perceive motion through
dynamic variations in frequency energy. Furthermore, the emerging state space
model called Mamba, enables efficient perception of motion cues in frame
sequences due to its linear-time long-sequence modeling capability. Motivated
by this, we propose a novel visual camouflage Mamba (Vcamba) based on
spatio-frequency motion perception that integrates frequency and spatial
features for efficient and accurate VCOD. Specifically, we propose a receptive
field visual state space (RFVSS) module to extract multi-scale spatial features
after sequence modeling. For frequency learning, we introduce an adaptive
frequency component enhancement (AFE) module with a novel frequency-domain
sequential scanning strategy to maintain semantic consistency. Then we propose
a space-based long-range motion perception (SLMP) module and a frequency-based
long-range motion perception (FLMP) module to model spatio-temporal and
frequency-temporal sequences in spatial and frequency phase domains. Finally,
the space and frequency motion fusion module (SFMF) integrates dual-domain
features for unified motion representation. Experimental results show that our
Vcamba outperforms state-of-the-art methods across 6 evaluation metrics on 2
datasets with lower computation cost, confirming the superiority of Vcamba. Our
code is available at: https://github.com/BoydeLi/Vcamba.

</details>


### [77] [Medical Image De-Identification Benchmark Challenge](https://arxiv.org/abs/2507.23608)
*Linmin Pei,Granger Sutton,Michael Rutherford,Ulrike Wagner,Tracy Nolan,Kirk Smith,Phillip Farmer,Peter Gu,Ambar Rana,Kailing Chen,Thomas Ferleman,Brian Park,Ye Wu,Jordan Kojouharov,Gargi Singh,Jon Lemon,Tyler Willis,Milos Vukadinovic,Grant Duffy,Bryan He,David Ouyang,Marco Pereanez,Daniel Samber,Derek A. Smith,Christopher Cannistraci,Zahi Fayad,David S. Mendelson,Michele Bufano,Elmar Kotter,Hamideh Haghiri,Rajesh Baidya,Stefan Dvoretskii,Klaus H. Maier-Hein,Marco Nolden,Christopher Ablett,Silvia Siggillino,Sandeep Kaushik,Hongzhu Jiang,Sihan Xie,Zhiyu Wan,Alex Michie,Simon J Doran,Angeline Aurelia Waly,Felix A. Nathaniel Liang,Humam Arshad Mustagfirin,Michelle Grace Felicia,Kuo Po Chih,Rahul Krish,Ghulam Rasool,Nidhal Bouaynaya,Nikolas Koutsoubis,Kyle Naddeo,Kartik Pandit,Tony O'Sullivan,Raj Krish,Qinyan Pan,Scott Gustafson,Benjamin Kopchick,Laura Opsahl-Ong,Andrea Olvera-Morales,Jonathan Pinney,Kathryn Johnson,Theresa Do,Juergen Klenk,Maria Diaz,Arti Singh,Rong Chai,David A. Clunie,Fred Prior,Keyvan Farahani*

Main category: cs.CV

TL;DR: MIDI-B挑战赛是一个关于医疗图像去标识化的比赛，旨在在保护隐私的同时保留有用的元数据。比赛结果显示，参与者的去标识化准确率很高（97.91%-99.93%）。


<details>
  <summary>Details</summary>
Motivation: 本次研究的动机是为医疗图像的去标识化（deID）提供一个标准化的基准平台，以确保遵守患者隐私法，并尽可能地保留对下游医学影像人工智能（AI）开发至关重要的非PHI元数据。MIDI-B挑战赛旨在解决这一需求，并评估基于规则的去标识化方法的有效性。

Method: MIDI-B挑战赛采用了一个包含三个阶段（训练、验证和测试）的框架。该比赛使用了一组真实DICOM图像，并插入了合成的PHI/PII。参与者被要求根据HIPAA安全港规定、DICOM属性保密配置文件和TCIA定义的元数据保留最佳实践来开发去标识化工具。评估指标是正确操作的百分比。

Result: MIDI-B挑战赛吸引了80名注册者，其中10个团队成功完成了测试阶段。在去标识化任务中，参与者使用的工具的得分范围为97.91%至99.93%。这表明所提出的方法在去除PHI/PII的同时，有效地保留了研究关键的元数据。

Conclusion: MIDI-B挑战赛成功地提供了一个标准化的平台，用于评估DICOM图像去标识化工具。该挑战赛的评分范围从97.91%到99.93%，表明参与者在保留研究关键元数据方面取得了高水平的准确性。该研究为改进医疗图像的隐私保护和AI开发提供了宝贵的经验和见解。

Abstract: The de-identification (deID) of protected health information (PHI) and
personally identifiable information (PII) is a fundamental requirement for
sharing medical images, particularly through public repositories, to ensure
compliance with patient privacy laws. In addition, preservation of non-PHI
metadata to inform and enable downstream development of imaging artificial
intelligence (AI) is an important consideration in biomedical research. The
goal of MIDI-B was to provide a standardized platform for benchmarking of DICOM
image deID tools based on a set of rules conformant to the HIPAA Safe Harbor
regulation, the DICOM Attribute Confidentiality Profiles, and best practices in
preservation of research-critical metadata, as defined by The Cancer Imaging
Archive (TCIA). The challenge employed a large, diverse, multi-center, and
multi-modality set of real de-identified radiology images with synthetic
PHI/PII inserted.
  The MIDI-B Challenge consisted of three phases: training, validation, and
test. Eighty individuals registered for the challenge. In the training phase,
we encouraged participants to tune their algorithms using their in-house or
public data. The validation and test phases utilized the DICOM images
containing synthetic identifiers (of 216 and 322 subjects, respectively). Ten
teams successfully completed the test phase of the challenge. To measure
success of a rule-based approach to image deID, scores were computed as the
percentage of correct actions from the total number of required actions. The
scores ranged from 97.91% to 99.93%. Participants employed a variety of
open-source and proprietary tools with customized configurations, large
language models, and optical character recognition (OCR). In this paper we
provide a comprehensive report on the MIDI-B Challenge's design,
implementation, results, and lessons learned.

</details>


### [78] [DivControl: Knowledge Diversion for Controllable Image Generation](https://arxiv.org/abs/2507.23620)
*Yucheng Xie,Fu Feng,Ruixiao Shi,Jing Wang,Yong Rui,Xin Geng*

Main category: cs.CV

TL;DR: DivControl是一种可分解的预训练框架，用于统一的可控生成和高效适应。它通过SVD分解ControlNet，并将条件解耦，实现了更好的泛化能力和更低的适应成本。


<details>
  <summary>Details</summary>
Motivation: 现有的可控图像生成方法，如ControlNet，要么需要为每个条件训练独立的模型，要么使用参数纠缠的统一架构，这导致在面对新条件时泛化能力差且适应成本高。

Method: DivControl框架通过SVD分解ControlNet，将条件分解为与条件无关的基因（learngenes）和条件特定的剪刀（tailors）。在多条件训练中，利用知识引导（knowledge diversion）和动态门控（dynamic gate）机制，根据条件指令的语义对剪刀进行软路由，实现零样本泛化和参数高效适应。同时，引入表示对齐损失（representation alignment loss）来对齐条件嵌入和早期扩散特征。

Result: DivControl在可控性方面达到了最先进的水平，训练成本降低了36.4倍，同时在基本条件上平均性能有所提升。在未见过的条件下，它还表现出强大的零样本和少样本性能，证明了其优越的可扩展性、模块化和可转移性。

Conclusion: DivControl通过SVD分解ControlNet，利用知识引导将条件解耦为与条件无关的基因和条件特定的剪刀，从而实现了可控生成和高效的适应。通过动态门控和表示对齐损失，DivControl在保持基本条件性能的同时，实现了最先进的可控性，并显著降低了训练成本。此外，它在未见过的条件上表现出强大的零样本和少样本性能，证明了其优越的可扩展性、模块化和可转移性。

Abstract: Diffusion models have advanced from text-to-image (T2I) to image-to-image
(I2I) generation by incorporating structured inputs such as depth maps,
enabling fine-grained spatial control. However, existing methods either train
separate models for each condition or rely on unified architectures with
entangled representations, resulting in poor generalization and high adaptation
costs for novel conditions. To this end, we propose DivControl, a decomposable
pretraining framework for unified controllable generation and efficient
adaptation. DivControl factorizes ControlNet via SVD into basic
components-pairs of singular vectors-which are disentangled into
condition-agnostic learngenes and condition-specific tailors through knowledge
diversion during multi-condition training. Knowledge diversion is implemented
via a dynamic gate that performs soft routing over tailors based on the
semantics of condition instructions, enabling zero-shot generalization and
parameter-efficient adaptation to novel conditions. To further improve
condition fidelity and training efficiency, we introduce a representation
alignment loss that aligns condition embeddings with early diffusion features.
Extensive experiments demonstrate that DivControl achieves state-of-the-art
controllability with 36.4$\times$ less training cost, while simultaneously
improving average performance on basic conditions. It also delivers strong
zero-shot and few-shot performance on unseen conditions, demonstrating superior
scalability, modularity, and transferability.

</details>


### [79] [Efficient Masked Attention Transformer for Few-Shot Classification and Segmentation](https://arxiv.org/abs/2507.23642)
*Dustin Carrión-Ojeda,Stefan Roth,Simone Schaub-Meyer*

Main category: cs.CV

TL;DR: EMAT是一种用于少样本分类和分割（FS-CS）的Transformer模型，通过改进的注意力机制、下采样策略和参数效率，显著提高了小目标的性能，并减少了训练参数。同时提出了新的评估指标。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有FS-CS方法在小目标分割上表现不佳的问题。

Method: EMAT引入了一种新颖的记忆高效掩码注意机制、一种可学习的下采样策略和参数效率增强。

Result: EMAT提高了分类和分割的准确性，尤其是在小目标方面。

Conclusion: EMAT在PASCAL-5$^i$和COCO-20$^i$数据集上超越了所有FS-CS方法，并且可训练参数减少了至少四倍。此外，提出了两个新的评估设置，以更好地反映实际场景。

Abstract: Few-shot classification and segmentation (FS-CS) focuses on jointly
performing multi-label classification and multi-class segmentation using few
annotated examples. Although the current state of the art (SOTA) achieves high
accuracy in both tasks, it struggles with small objects. To overcome this, we
propose the Efficient Masked Attention Transformer (EMAT), which improves
classification and segmentation accuracy, especially for small objects. EMAT
introduces three modifications: a novel memory-efficient masked attention
mechanism, a learnable downscaling strategy, and parameter-efficiency
enhancements. EMAT outperforms all FS-CS methods on the PASCAL-5$^i$ and
COCO-20$^i$ datasets, using at least four times fewer trainable parameters.
Moreover, as the current FS-CS evaluation setting discards available
annotations, despite their costly collection, we introduce two novel evaluation
settings that consider these annotations to better reflect practical scenarios.

</details>


### [80] [FFGAF-SNN: The Forward-Forward Based Gradient Approximation Free Training Framework for Spiking Neural Networks](https://arxiv.org/abs/2507.23643)
*Changqing Xu,Ziqiang Yang,Yi Liu,Xinfang Liao,Guiqi Mo,Hao Zeng,Yintang Yang*

Main category: cs.CV

TL;DR: 提出了一种新的FF训练框架，用于SNN，无需梯度近似，提高了准确性，降低了计算复杂性，并在MNIST、Fashion-MNIST和CIFAR-10上取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有SNN训练中梯度近似带来的准确率牺牲和部署限制问题，以及反向传播的计算复杂性问题。

Method: 提出了一种基于前向前向（FF）的无梯度近似训练框架，将脉冲激活视为黑盒模块，无需梯度近似，并引入了一个类别感知复杂度自适应机制，根据类别间难度指标动态优化损失函数。

Result: 在MNIST、Fashion-MNIST和CIFAR-10数据集上取得了99.58%、92.13%和75.64%的测试准确率，优于现有的FF-SNN方法，并在内存访问和计算功耗方面具有优势。

Conclusion: 所提出的基于前向前向（FF）的无梯度近似训练框架在MNIST、Fashion-MNIST和CIFAR-10数据集上达到了99.58%、92.13%和75.64%的测试准确率，超越了所有现有的基于FF的SNN方法，并在内存访问和计算功耗方面表现出显著优势。

Abstract: Spiking Neural Networks (SNNs) offer a biologically plausible framework for
energy-efficient neuromorphic computing. However, it is a challenge to train
SNNs due to their non-differentiability, efficiently. Existing gradient
approximation approaches frequently sacrifice accuracy and face deployment
limitations on edge devices due to the substantial computational requirements
of backpropagation. To address these challenges, we propose a Forward-Forward
(FF) based gradient approximation-free training framework for Spiking Neural
Networks, which treats spiking activations as black-box modules, thereby
eliminating the need for gradient approximation while significantly reducing
computational complexity. Furthermore, we introduce a class-aware complexity
adaptation mechanism that dynamically optimizes the loss function based on
inter-class difficulty metrics, enabling efficient allocation of network
resources across different categories. Experimental results demonstrate that
our proposed training framework achieves test accuracies of 99.58%, 92.13%, and
75.64% on the MNIST, Fashion-MNIST, and CIFAR-10 datasets, respectively,
surpassing all existing FF-based SNN approaches. Additionally, our proposed
method exhibits significant advantages in terms of memory access and
computational power consumption.

</details>


### [81] [Adaptively Distilled ControlNet: Accelerated Training and Superior Sampling for Medical Image Synthesis](https://arxiv.org/abs/2507.23652)
*Kunpeng Qiu,Zhiying Zhou,Yongxin Guo*

Main category: cs.CV

TL;DR: 一种名为 Adaptively Distilled ControlNet 的新框架，通过双模型蒸馏技术，解决了医学图像分割中的隐私和标注效率问题，并在两个医学数据集上取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像标注的隐私顾虑和劳动密集型问题，这些问题严重限制了分割模型的性能和泛化能力。同时，也为了改进现有的掩码可控扩散模型在精确病变掩码对齐方面的不足。

Method: 提出了一种名为 Adaptively Distilled ControlNet 的任务无关框架，通过双模型蒸馏来加速训练和优化。在训练过程中，一个以掩码-图像对为条件的教师模型，通过在参数空间中对预测噪声进行对齐来正则化一个仅包含掩码的学生模型，并基于病变-背景比率进行自适应正则化。在采样过程中，仅使用学生模型，实现了隐私保护的医学图像生成。

Result: 在 KiTS19 数据集上，TransUNet 模型的 mDice/mIoU 分别提高了 2.4%/4.2%；在 Polyps 数据集上，SANet 模型的 mDice/mIoU 分别提高了 2.6%/3.5%。

Conclusion: Adaptively Distilled ControlNet 框架在医学图像分割任务中展现了卓越的性能和优越性，显著提高了 TransUNet 和 SANet 等模型的性能。

Abstract: Medical image annotation is constrained by privacy concerns and
labor-intensive labeling, significantly limiting the performance and
generalization of segmentation models. While mask-controllable diffusion models
excel in synthesis, they struggle with precise lesion-mask alignment. We
propose \textbf{Adaptively Distilled ControlNet}, a task-agnostic framework
that accelerates training and optimization through dual-model distillation.
Specifically, during training, a teacher model, conditioned on mask-image
pairs, regularizes a mask-only student model via predicted noise alignment in
parameter space, further enhanced by adaptive regularization based on
lesion-background ratios. During sampling, only the student model is used,
enabling privacy-preserving medical image generation. Comprehensive evaluations
on two distinct medical datasets demonstrate state-of-the-art performance:
TransUNet improves mDice/mIoU by 2.4%/4.2% on KiTS19, while SANet achieves
2.6%/3.5% gains on Polyps, highlighting its effectiveness and superiority. Code
is available at GitHub.

</details>


### [82] [OmniTraj: Pre-Training on Heterogeneous Data for Adaptive and Zero-Shot Human Trajectory Prediction](https://arxiv.org/abs/2507.23657)
*Yang Gao,Po-Chien Luan,Kaouther Messaoud,Lan Feng,Alexandre Alahi*

Main category: cs.CV

TL;DR: OmniTraj 透過顯式時間元數據條件化，克服了預訓練模型在遷移到具有不同時間動態的數據集時的挑戰，在零樣本遷移和微調性能上均取得了最先進的結果。


<details>
  <summary>Details</summary>
Motivation: 現有的預訓練模型在遷移到具有不同時間動態（例如幀率或觀察範圍）的未見數據集時，通常需要進行微調，這限制了它們的可擴展性和實用性。本研究旨在解決此挑戰，並提高模型在不同時間設置下的零樣本遷移能力。

Method: 提出了一種基於 Transformer 的模型 OmniTraj，該模型在一個大規模、異質的數據集上進行了預訓練，並透過顯式條件化時間元數據（例如幀率）來解決零樣本遷移問題。

Result: OmniTraj 在零樣本遷移方面表現出色，將預測誤差降低了 70% 以上。在微調後，OmniTraj 在四個數據集上取得了最先進的結果。

Conclusion: 所提出的 OmniTraj 模型透過顯式時間元數據條件化，在零樣本遷移方面取得了最先進的性能，在具有挑戰性的跨設置場景中將預測誤差降低了 70% 以上。此外，在微調後，OmniTraj 在 NBA、JTA、WorldPose 和 ETH-UCY 四個數據集上均取得了最先進的結果。

Abstract: While large-scale pre-training has advanced human trajectory prediction, a
critical challenge remains: zero-shot transfer to unseen dataset with varying
temporal dynamics. State-of-the-art pre-trained models often require
fine-tuning to adapt to new datasets with different frame rates or observation
horizons, limiting their scalability and practical utility. In this work, we
systematically investigate this limitation and propose a robust solution. We
first demonstrate that existing data-aware discrete models struggle when
transferred to new scenarios with shifted temporal setups. We then isolate the
temporal generalization from dataset shift, revealing that a simple, explicit
conditioning mechanism for temporal metadata is a highly effective solution.
Based on this insight, we present OmniTraj, a Transformer-based model
pre-trained on a large-scale, heterogeneous dataset. Our experiments show that
explicitly conditioning on the frame rate enables OmniTraj to achieve
state-of-the-art zero-shot transfer performance, reducing prediction error by
over 70\% in challenging cross-setup scenarios. After fine-tuning, OmniTraj
achieves state-of-the-art results on four datasets, including NBA, JTA,
WorldPose, and ETH-UCY. The code is publicly available:
https://github.com/vita-epfl/omnitraj

</details>


### [83] [SAMSA: Segment Anything Model Enhanced with Spectral Angles for Hyperspectral Interactive Medical Image Segmentation](https://arxiv.org/abs/2507.23673)
*Alfie Roddan,Tobias Czempiel,Chi Xu,Daniel S. Elson,Stamatia Giannarou*

Main category: cs.CV

TL;DR: SAMSA是一个交互式高光谱医学图像分割框架，利用用户点击结合RGB基础模型和光谱分析，实现了高效分割，尤其在数据有限的情况下表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决高光谱成像（HSI）在医学成像中面临的数据限制和硬件差异的挑战，并实现高效的交互式分割。

Method: SAMSA框架结合了RGB基础模型和光谱分析，利用用户点击来指导RGB分割和光谱相似性计算，并通过独特的光谱特征融合策略解决了高光谱图像分割的局限性。

Result: 在神经外科和猪体内高光谱数据集上，SAMSA分别实现了81.0%和81.1%的1-点击DICE，以及93.4%和89.2%的5-点击DICE。该方法在少样本和零样本学习场景下表现出有效性，且仅需少量训练样本。

Conclusion: SAMSA框架能够有效地进行高光谱医学图像分析，即使在数据有限的情况下，也能通过用户交互实现高效分割，并且能够适应不同光谱特征的数据集。

Abstract: Hyperspectral imaging (HSI) provides rich spectral information for medical
imaging, yet encounters significant challenges due to data limitations and
hardware variations. We introduce SAMSA, a novel interactive segmentation
framework that combines an RGB foundation model with spectral analysis. SAMSA
efficiently utilizes user clicks to guide both RGB segmentation and spectral
similarity computations. The method addresses key limitations in HSI
segmentation through a unique spectral feature fusion strategy that operates
independently of spectral band count and resolution. Performance evaluation on
publicly available datasets has shown 81.0% 1-click and 93.4% 5-click DICE on a
neurosurgical and 81.1% 1-click and 89.2% 5-click DICE on an intraoperative
porcine hyperspectral dataset. Experimental results demonstrate SAMSA's
effectiveness in few-shot and zero-shot learning scenarios and using minimal
training examples. Our approach enables seamless integration of datasets with
different spectral characteristics, providing a flexible framework for
hyperspectral medical image analysis.

</details>


### [84] [I2V-GS: Infrastructure-to-Vehicle View Transformation with Gaussian Splatting for Autonomous Driving Data Generation](https://arxiv.org/abs/2507.23683)
*Jialei Chen,Wuhao Xu,Sipeng He,Baoru Huang,Dongchun Ren*

Main category: cs.CV

TL;DR: I2V-GS是一种创新的自动驾驶数据生成框架，通过高斯泼溅技术实现基础设施视角到车辆视角的转换，并引入了自适应深度扭曲、级联修复和置信度引导优化等技术，同时发布了RoadSight数据集，显著提升了合成数据的质量和视角转换能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前自动驾驶系统所需的大量高质量数据主要通过成本高昂且效率低下的车辆采集方式获取的问题，探索利用真实世界图像合成数据作为一种潜在解决方案。特别是利用3D重建技术在真实道路图像上生成驾驶数据的潜力。

Method: 提出I2V-GS方法，利用高斯泼溅技术实现基础设施视角到车辆视角的转换。为解决稀疏视角重建和视角大范围变换的渲染难题，采用了自适应深度扭曲生成密集训练视角，并通过级联策略修复扭曲图像以扩展视角范围并保证内容一致性。此外，利用跨视角信息进行置信度引导优化，以提高扩散模型的可靠性。同时，推出了包含真实场景基础设施视角多模态、多视角的RoadSight数据集。

Result: I2V-GS在车辆视角下显著提高了合成质量，在NTA-Iou、NTL-Iou和FID指标上分别比StreetGaussian提高了45.7%、34.2%和14.9%。

Conclusion: I2V-GS是首个实现基础设施视角到车辆视角转换的自动驾驶数据集生成框架，实验结果证明了其在合成质量上的优越性，在NTA-Iou、NTL-Iou和FID指标上分别超越StreetGaussian 45.7%、34.2%和14.9%。

Abstract: Vast and high-quality data are essential for end-to-end autonomous driving
systems. However, current driving data is mainly collected by vehicles, which
is expensive and inefficient. A potential solution lies in synthesizing data
from real-world images. Recent advancements in 3D reconstruction demonstrate
photorealistic novel view synthesis, highlighting the potential of generating
driving data from images captured on the road. This paper introduces a novel
method, I2V-GS, to transfer the Infrastructure view To the Vehicle view with
Gaussian Splatting. Reconstruction from sparse infrastructure viewpoints and
rendering under large view transformations is a challenging problem. We adopt
the adaptive depth warp to generate dense training views. To further expand the
range of views, we employ a cascade strategy to inpaint warped images, which
also ensures inpainting content is consistent across views. To further ensure
the reliability of the diffusion model, we utilize the cross-view information
to perform a confidenceguided optimization. Moreover, we introduce RoadSight, a
multi-modality, multi-view dataset from real scenarios in infrastructure views.
To our knowledge, I2V-GS is the first framework to generate autonomous driving
datasets with infrastructure-vehicle view transformation. Experimental results
demonstrate that I2V-GS significantly improves synthesis quality under vehicle
view, outperforming StreetGaussian in NTA-Iou, NTL-Iou, and FID by 45.7%,
34.2%, and 14.9%, respectively.

</details>


### [85] [UniLDiff: Unlocking the Power of Diffusion Priors for All-in-One Image Restoration](https://arxiv.org/abs/2507.23685)
*Zihan Cheng,Liangtai Zhou,Dian Chen,Ni Tang,Xiaotong Luo,Yanyun Qu*

Main category: cs.CV

TL;DR: 提出了一种基于LDMs的AiOIR新框架，通过DAFF和DAEM模块处理各种退化并恢复细节，实验证明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决All-in-One图像恢复（AiOIR）面临的核心挑战，并利用扩散模型的强大生成能力来处理各种退化。

Method: 提出了一种新颖的统一图像恢复框架，该框架基于潜在扩散模型（LDMs），并设计了降解感知特征融合（DAFF）模块来适应不同类型的降解，以及细节感知专家模块（DAEM）来恢复纹理和精细结构。

Result: 所提出的方法在多任务和混合退化设置下持续 achieves state-of-the-art 性能，有效恢复了纹理和精细结构，并展示了扩散先验在统一图像恢复中的实际应用潜力。

Conclusion: 本研究提出的基于潜在扩散模型（LDMs）的统一图像恢复框架在多任务和混合退化设置下均取得了最先进的性能，证明了扩散模型在统一图像恢复中的潜力。

Abstract: All-in-One Image Restoration (AiOIR) has emerged as a promising yet
challenging research direction. To address its core challenges, we propose a
novel unified image restoration framework based on latent diffusion models
(LDMs). Our approach structurally integrates low-quality visual priors into the
diffusion process, unlocking the powerful generative capacity of diffusion
models for diverse degradations. Specifically, we design a Degradation-Aware
Feature Fusion (DAFF) module to enable adaptive handling of diverse degradation
types. Furthermore, to mitigate detail loss caused by the high compression and
iterative sampling of LDMs, we design a Detail-Aware Expert Module (DAEM) in
the decoder to enhance texture and fine-structure recovery. Extensive
experiments across multi-task and mixed degradation settings demonstrate that
our method consistently achieves state-of-the-art performance, highlighting the
practical potential of diffusion priors for unified image restoration. Our code
will be released.

</details>


### [86] [Enhanced Velocity Field Modeling for Gaussian Video Reconstruction](https://arxiv.org/abs/2507.23704)
*Zhenyang Li,Xiaoyang Bai,Tongchen Zhang,Pengfei Shen,Weiwei Xu,Yifan Peng*

Main category: cs.CV

TL;DR: FlowGaussian-VR通过流引导的速度场建模，解决了3D高斯视频重建中复杂运动和动态内容处理的难题，实现了更高的视觉质量和更稳定的轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯泼溅技术在处理具有复杂运动和尺度变化的视频时，其变形网络容易过拟合，导致视觉质量下降；同时，针对静态场景设计的梯度下降策略不适用于动态场景。为了解决这些问题，提出FlowGaussian-VR。

Method: FlowGaussian-VR提出了一种流引导的速度场建模方案，包括：1. 速度场渲染（VFR）流水线，实现基于光流的优化；2. 流辅助自适应密度（FAD）策略，根据动态区域调整高斯数量和大小。

Result: FlowGaussian-VR在多视图动态重建和新视角合成方面表现出色，在包含挑战性运动场景的真实世界数据集上，PSNR提高了2.5 dB以上，减少了动态纹理的模糊伪影，并且轨迹更加规则和可追踪。

Conclusion: FlowGaussian-VR通过引入基于光流的优化和自适应密度调整策略，在处理复杂运动和尺度变化方面显著优于现有方法，实现了更高保真度的视频重建，减少了模糊伪影，并产生了更规则、可追踪的高斯轨迹。

Abstract: High-fidelity 3D video reconstruction is essential for enabling real-time
rendering of dynamic scenes with realistic motion in virtual and augmented
reality (VR/AR). The deformation field paradigm of 3D Gaussian splatting has
achieved near-photorealistic results in video reconstruction due to the great
representation capability of deep deformation networks. However, in videos with
complex motion and significant scale variations, deformation networks often
overfit to irregular Gaussian trajectories, leading to suboptimal visual
quality. Moreover, the gradient-based densification strategy designed for
static scene reconstruction proves inadequate to address the absence of dynamic
content. In light of these challenges, we propose a flow-empowered velocity
field modeling scheme tailored for Gaussian video reconstruction, dubbed
FlowGaussian-VR. It consists of two core components: a velocity field rendering
(VFR) pipeline which enables optical flow-based optimization, and a
flow-assisted adaptive densification (FAD) strategy that adjusts the number and
size of Gaussians in dynamic regions. We validate our model's effectiveness on
multi-view dynamic reconstruction and novel view synthesis with multiple
real-world datasets containing challenging motion scenarios, demonstrating not
only notable visual improvements (over 2.5 dB gain in PSNR) and less blurry
artifacts in dynamic textures, but also regularized and trackable per-Gaussian
trajectories.

</details>


### [87] [Explainable Image Classification with Reduced Overconfidence for Tissue Characterisation](https://arxiv.org/abs/2507.23709)
*Alfie Roddan,Chi Xu,Serine Ajlouni,Irini Kakaletri,Patra Charalampaki,Stamatia Giannarou*

Main category: cs.CV

TL;DR: 提出了一种结合风险估计的像素归因方法，用于提高机器学习模型在组织分类中的可解释性，尤其是在术语切除的背景下。该方法通过生成像素归因图的像素分布，并估计其风险，从而提供更可靠的解释。实验证明该方法优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在术语分类中的应用可以辅助决策并指导肿瘤切除。然而，深度学习模型预测的过度自信会转化为像素归因的过度自信。为了解决这个问题，需要一种能够整合风险估计以提高像素归因可解释性的方法。

Method: 提出了一种将风险估计纳入像素归因方法以改进图像分类可解释性的方法。该方法迭代地应用分类模型和像素归因方法来创建像素归因图卷，并首次使用该图卷生成像素归因值的像素分布。通过估计像素归因值分布的期望值来生成增强的像素归因图。此外，使用变异系数（CV）来估计增强像素归因图的像素风险。

Result: 所提出的方法能够生成增强的像素归因图，并提供像素归因值（PA值）的像素级风险估计。在pCLE数据和ImageNet上的实验证明，该方法优于现有技术。

Conclusion: 所提出的方法不仅提供了改进的像素归因图，还对输出的像素归因值产生了风险估计，并且在pCLE数据和ImageNet上的性能评估验证了我们改进的可解释性方法优于现有技术。

Abstract: The deployment of Machine Learning models intraoperatively for tissue
characterisation can assist decision making and guide safe tumour resections.
For image classification models, pixel attribution methods are popular to infer
explainability. However, overconfidence in deep learning model's predictions
translates to overconfidence in pixel attribution. In this paper, we propose
the first approach which incorporates risk estimation into a pixel attribution
method for improved image classification explainability. The proposed method
iteratively applies a classification model with a pixel attribution method to
create a volume of PA maps. This volume is used for the first time, to generate
a pixel-wise distribution of PA values. We introduce a method to generate an
enhanced PA map by estimating the expectation values of the pixel-wise
distributions. In addition, the coefficient of variation (CV) is used to
estimate pixel-wise risk of this enhanced PA map. Hence, the proposed method
not only provides an improved PA map but also produces an estimation of risk on
the output PA values. Performance evaluation on probe-based Confocal Laser
Endomicroscopy (pCLE) data and ImageNet verifies that our improved
explainability method outperforms the state-of-the-art.

</details>


### [88] [DiffuMatch: Category-Agnostic Spectral Diffusion Priors for Robust Non-rigid Shape Matching](https://arxiv.org/abs/2507.23715)
*Emery Pierson,Lei Li,Angela Dai,Maks Ovsjanikov*

Main category: cs.CV

TL;DR: 深度函数图方法通过引入基于分数的生成模型和新颖的蒸馏策略，实现了函数图谱的训练和正则化的数据驱动，从而在非刚性形状匹配任务上超越了传统公理化方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度函数图的方法将学习能力局限于特征函数，而将训练损失和正则化依赖于公理化模型，这限制了方法的准确性和适用性。

Method: 本文提出了一种在谱域训练生成模型的新方法，利用基于分数的生成模型来学习函数图谱，并提出了一种新颖的蒸馏策略，将扩散模型从谱域中提取出来，用于函数图谱的训练和正则化。

Result: 实验证明，所提出的学习方法可以完全取代常用的策略，如强制拉普拉斯算子交换律或函数图谱的正交性，并且在零样本非刚性形状匹配任务上取得了比公理化方法更好的结果。所提出的方法具有类别无关性。

Conclusion: 本文提出的基于扩散模型的学习方法在零样本非刚性形状匹配任务上取得了优于传统公理化方法的性能。

Abstract: Deep functional maps have recently emerged as a powerful tool for solving
non-rigid shape correspondence tasks. Methods that use this approach combine
the power and flexibility of the functional map framework, with data-driven
learning for improved accuracy and generality. However, most existing methods
in this area restrict the learning aspect only to the feature functions and
still rely on axiomatic modeling for formulating the training loss or for
functional map regularization inside the networks. This limits both the
accuracy and the applicability of the resulting approaches only to scenarios
where assumptions of the axiomatic models hold. In this work, we show, for the
first time, that both in-network regularization and functional map training can
be replaced with data-driven methods. For this, we first train a generative
model of functional maps in the spectral domain using score-based generative
modeling, built from a large collection of high-quality maps. We then exploit
the resulting model to promote the structural properties of ground truth
functional maps on new shape collections. Remarkably, we demonstrate that the
learned models are category-agnostic, and can fully replace commonly used
strategies such as enforcing Laplacian commutativity or orthogonality of
functional maps. Our key technical contribution is a novel distillation
strategy from diffusion models in the spectral domain. Experiments demonstrate
that our learned regularization leads to better results than axiomatic
approaches for zero-shot non-rigid shape matching. Our code is available at:
https://github.com/daidedou/diffumatch/

</details>


### [89] [Slot Attention with Re-Initialization and Self-Distillation](https://arxiv.org/abs/2507.23755)
*Rongzhen Zhao,Yi Zhao,Juho Kannala,Joni Pajarinen*

Main category: cs.CV

TL;DR: DIAS通过重新初始化和自我蒸馏来改进对象中心学习，减少了冗余并提高了性能。


<details>
  <summary>Details</summary>
Motivation: 与基于密集特征图的流行解决方案不同，对象中心学习（OCL）将视觉场景表示为子符号对象级特征向量（称为槽），这对于涉及视觉模态的任务非常有用。OCL通常通过迭代地应用竞争性交叉注意力（称为槽注意力），以槽作为查询，将对象超像素聚合成槽。然而，一旦初始化，这些槽就会被粗暴地重复使用，导致冗余槽与信息槽竞争表示对象。这通常会导致对象被错误地分割成部分。此外，主流方法仅从将槽解码为输入的重建中获得监督信号，而忽略了基于内部信息的潜在监督。

Method: DIAS通过以下方式解决这些问题：i）减少聚合槽中的冗余，并重新初始化额外的聚合以更新剩余的槽；ii）驱动第一次聚合迭代中的差注意力图以逼近最后一次迭代中的好注意力图，以实现自我蒸馏。

Result: DIAS在对象发现和识别等OCL任务方面取得了最先进的成果，同时还改进了高级视觉预测和推理。

Conclusion: DIAS在对象发现和识别等OCL任务以及高级视觉预测和推理方面均取得了最先进的成果。

Abstract: Unlike popular solutions based on dense feature maps, Object-Centric Learning
(OCL) represents visual scenes as sub-symbolic object-level feature vectors,
termed slots, which are highly versatile for tasks involving visual modalities.
OCL typically aggregates object superpixels into slots by iteratively applying
competitive cross attention, known as Slot Attention, with the slots as the
query. However, once initialized, these slots are reused naively, causing
redundant slots to compete with informative ones for representing objects. This
often results in objects being erroneously segmented into parts. Additionally,
mainstream methods derive supervision signals solely from decoding slots into
the input's reconstruction, overlooking potential supervision based on internal
information. To address these issues, we propose Slot Attention with
re-Initialization and self-Distillation (DIAS): $\emph{i)}$ We reduce
redundancy in the aggregated slots and re-initialize extra aggregation to
update the remaining slots; $\emph{ii)}$ We drive the bad attention map at the
first aggregation iteration to approximate the good at the last iteration to
enable self-distillation. Experiments demonstrate that DIAS achieves
state-of-the-art on OCL tasks like object discovery and recognition, while also
improving advanced visual prediction and reasoning. Our code is available on
https://github.com/Genera1Z/DIAS.

</details>


### [90] [SeqAffordSplat: Scene-level Sequential Affordance Reasoning on 3D Gaussian Splatting](https://arxiv.org/abs/2507.23772)
*Di Li,Jie Feng,Jiahao Chen,Weisheng Dong,Guanbin Li,Yuhui Zheng,Mingtao Feng,Guangming Shi*

Main category: cs.CV

TL;DR: This paper introduces sequential 3D affordance reasoning for embodied agents, proposing a benchmark (SeqAffordSplat) and a framework (SeqSplatNet) that uses LLMs and geometric/semantic feature fusion to handle complex, multi-step interactions in 3D scenes.


<details>
  <summary>Details</summary>
Motivation: Current 3DGS methods for affordance reasoning are limited to single-object, single-step interactions, which is insufficient for complex, long-horizon, multi-object real-world applications. This work aims to bridge this gap.

Method: SeqSplatNet, an end-to-end framework that maps instructions to sequential 3D affordance masks using an LLM for text generation with segmentation tokens to guide a conditional decoder. It includes a pre-training strategy (Conditional Geometric Reconstruction) for geometric priors and a feature injection mechanism to fuse semantic features from 2D VFMs.

Result: The proposed method, SeqSplatNet, sets a new state-of-the-art on the SeqAffordSplat benchmark, demonstrating effective advancement of affordance reasoning for sequential, scene-level tasks.

Conclusion: SeqSplatNet, incorporating an LLM for autoregressive mask generation and a novel pre-training strategy for geometric priors, advances 3D affordance reasoning from single-step to sequential, scene-level tasks, achieving state-of-the-art results on the new SeqAffordSplat benchmark.

Abstract: 3D affordance reasoning, the task of associating human instructions with the
functional regions of 3D objects, is a critical capability for embodied agents.
Current methods based on 3D Gaussian Splatting (3DGS) are fundamentally limited
to single-object, single-step interactions, a paradigm that falls short of
addressing the long-horizon, multi-object tasks required for complex real-world
applications. To bridge this gap, we introduce the novel task of Sequential 3D
Gaussian Affordance Reasoning and establish SeqAffordSplat, a large-scale
benchmark featuring 1800+ scenes to support research on long-horizon affordance
understanding in complex 3DGS environments. We then propose SeqSplatNet, an
end-to-end framework that directly maps an instruction to a sequence of 3D
affordance masks. SeqSplatNet employs a large language model that
autoregressively generates text interleaved with special segmentation tokens,
guiding a conditional decoder to produce the corresponding 3D mask. To handle
complex scene geometry, we introduce a pre-training strategy, Conditional
Geometric Reconstruction, where the model learns to reconstruct complete
affordance region masks from known geometric observations, thereby building a
robust geometric prior. Furthermore, to resolve semantic ambiguities, we design
a feature injection mechanism that lifts rich semantic features from 2D Vision
Foundation Models (VFM) and fuses them into the 3D decoder at multiple scales.
Extensive experiments demonstrate that our method sets a new state-of-the-art
on our challenging benchmark, effectively advancing affordance reasoning from
single-step interactions to complex, sequential tasks at the scene level.

</details>


### [91] [Half-Physics: Enabling Kinematic 3D Human Model with Physical Interactions](https://arxiv.org/abs/2507.23778)
*Li Siyao,Yao Feng,Omid Tehari,Chen Change Loy,Michael J. Black*

Main category: cs.CV

TL;DR: 提出了一种“半物理”方法，将SMPL-X嵌入到具有物理交互能力的新型3D人体模型中，解决了现有模型的穿透和不切实际的动力学问题，且该方法无需学习即可实时运行。


<details>
  <summary>Details</summary>
Motivation: 现有的3D人体模型（如SMPL-X）虽然能高效表示精确的人体形状和姿势，但由于其运动学性质，缺乏与环境进行物理交互的能力，导致基于运动学的方法在交互时常出现穿透和不切实际的物体动力学问题。

Method: 提出了一种“半物理”机制，将3D运动转换为物理模拟，在保持SMPL-X固有姿势的运动控制的同时，确保了与场景和物体的物理上合理的交互。

Result: 该方法能够实现物理上合理的交互，有效消除穿透和不切实际的物体动力学。与基于强化学习的方法不同，该方法是无学习的，并且可以推广到任何体型和运动。同时，它可以在实时运行，并保留了原始运动的保真度，同时无缝地集成物理交互。

Conclusion: 该方法通过将SMPL-X嵌入到能够与环境进行动态物理交互的有形实体中，解决了现有3D人体模型（如SMPL-X）缺乏物理交互能力的问题。通过引入“半物理”机制，将3D运动转换为物理模拟，在保持SMPL-X固有姿势的运动控制的同时，确保了与场景和物体的物理上合理的交互，有效消除了穿透和不切实际的物体动力学。

Abstract: While current general-purpose 3D human models (e.g., SMPL-X) efficiently
represent accurate human shape and pose, they lacks the ability to physically
interact with the environment due to the kinematic nature. As a result,
kinematic-based interaction models often suffer from issues such as
interpenetration and unrealistic object dynamics. To address this limitation,
we introduce a novel approach that embeds SMPL-X into a tangible entity capable
of dynamic physical interactions with its surroundings. Specifically, we
propose a "half-physics" mechanism that transforms 3D kinematic motion into a
physics simulation. Our approach maintains kinematic control over inherent
SMPL-X poses while ensuring physically plausible interactions with scenes and
objects, effectively eliminating penetration and unrealistic object dynamics.
Unlike reinforcement learning-based methods, which demand extensive and complex
training, our half-physics method is learning-free and generalizes to any body
shape and motion; meanwhile, it operates in real time. Moreover, it preserves
the fidelity of the original kinematic motion while seamlessly integrating
physical interactions

</details>


### [92] [Phi-Ground Tech Report: Advancing Perception in GUI Grounding](https://arxiv.org/abs/2507.23779)
*Miaosen Zhang,Ziqiang Xu,Jialiang Zhu,Qi Dai,Kai Qiu,Yifan Yang,Chong Luo,Tianyi Chen,Justin Wagle,Tim Franklin,Baining Guo*

Main category: cs.CV

TL;DR: 本研究对GUI基础模型进行了全面的实证研究，开发了Phi-Ground模型家族，并在各项基础模型任务中取得了SOTA的成绩。


<details>
  <summary>Details</summary>
Motivation: 当前端到端的GUI基础模型在ScreenSpot-pro和UI-Vision等具有挑战性的benchmark上准确率低于65%，距离实际部署仍有差距，需要对基础模型进行训练研究。

Method: 对GUI基础模型进行了从数据收集到模型训练的详细实证研究，并开发了Phi-Ground模型家族。

Result: Phi-Ground模型家族在所有五个基础模型benchmark上取得了当前最优的性能，在ScreenSpot-pro和UI-Vision上的得分分别为43.2和27.2。

Conclusion: 该研究通过对GUI基础模型进行详细的实证研究，开发了Phi-Ground模型家族，并在五个基础模型benchmark上取得了当前最优的性能。

Abstract: With the development of multimodal reasoning models, Computer Use Agents
(CUAs), akin to Jarvis from \textit{"Iron Man"}, are becoming a reality. GUI
grounding is a core component for CUAs to execute actual actions, similar to
mechanical control in robotics, and it directly leads to the success or failure
of the system. It determines actions such as clicking and typing, as well as
related parameters like the coordinates for clicks. Current end-to-end
grounding models still achieve less than 65\% accuracy on challenging
benchmarks like ScreenSpot-pro and UI-Vision, indicating they are far from
being ready for deployment. % , as a single misclick can result in unacceptable
consequences. In this work, we conduct an empirical study on the training of
grounding models, examining details from data collection to model training.
Ultimately, we developed the \textbf{Phi-Ground} model family, which achieves
state-of-the-art performance across all five grounding benchmarks for models
under $10B$ parameters in agent settings. In the end-to-end model setting, our
model still achieves SOTA results with scores of \textit{\textbf{43.2}} on
ScreenSpot-pro and \textit{\textbf{27.2}} on UI-Vision. We believe that the
various details discussed in this paper, along with our successes and failures,
not only clarify the construction of grounding models but also benefit other
perception tasks. Project homepage:
\href{https://zhangmiaosen2000.github.io/Phi-Ground/}{https://zhangmiaosen2000.github.io/Phi-Ground/}

</details>


### [93] [MonoFusion: Sparse-View 4D Reconstruction via Monocular Fusion](https://arxiv.org/abs/2507.23782)
*Zihan Wang,Jeff Tan,Tarasha Khurana,Neehar Peri,Deva Ramanan*

Main category: cs.CV

TL;DR: 该研究提出了一种从稀疏视角视频进行动态场景重建的新方法，解决了现有技术需要昂贵密集多视角捕获的限制，并在实验中取得了更好的效果。


<details>
  <summary>Details</summary>
Motivation: 旨在从稀疏视角的摄像机（例如四个等距向内照射的静态摄像机）中重建动态人体行为，例如修理自行车或跳舞，以解决现有方法需要昂贵且难以捕捉野外多样化场景的密集多视角捕获（例如具有数百个校准摄像机的全景工作室）的问题。

Method: 通过仔细对齐每个摄像机的独立单目重建，以产生时间一致和视图一致的动态场景重建。

Result: 所提出的方法实现了比现有技术更高的重建质量，尤其是在渲染新视图时。

Conclusion: 该方法在PanopticStudio和Ego-Exo4D数据集上的大量实验表明，与现有技术相比，该方法在生成新视图时具有更高的重建质量。

Abstract: We address the problem of dynamic scene reconstruction from sparse-view
videos. Prior work often requires dense multi-view captures with hundreds of
calibrated cameras (e.g. Panoptic Studio). Such multi-view setups are
prohibitively expensive to build and cannot capture diverse scenes in-the-wild.
In contrast, we aim to reconstruct dynamic human behaviors, such as repairing a
bike or dancing, from a small set of sparse-view cameras with complete scene
coverage (e.g. four equidistant inward-facing static cameras). We find that
dense multi-view reconstruction methods struggle to adapt to this sparse-view
setup due to limited overlap between viewpoints. To address these limitations,
we carefully align independent monocular reconstructions of each camera to
produce time- and view-consistent dynamic scene reconstructions. Extensive
experiments on PanopticStudio and Ego-Exo4D demonstrate that our method
achieves higher quality reconstructions than prior art, particularly when
rendering novel views. Code, data, and data-processing scripts are available on
https://github.com/ImNotPrepared/MonoFusion.

</details>


### [94] [SUB: Benchmarking CBM Generalization via Synthetic Attribute Substitutions](https://arxiv.org/abs/2507.23784)
*Jessica Bader,Leander Girrbach,Stephan Alaniz,Zeynep Akata*

Main category: cs.CV

TL;DR: CBMs在分布偏移下识别概念不可靠。我们提出了SUB基准和TDG方法来解决这个问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有概念瓶颈模型（CBMs）在分布偏移下识别概念的可靠性问题，以及评估CBMs对概念变化的鲁棒性。

Method: 提出了一种名为Tied Diffusion Guidance (TDG) 的新方法，利用噪声共享和并行去噪过程来精确控制生成图像，确保生成正确的鸟类类别和属性。同时，构建了一个名为SUB的细粒度图像和概念基准，包含38,400张基于CUB数据集的合成图像，通过替换特定概念（如翅膀颜色或腹部图案）来评估CBMs对概念变化的鲁棒性。

Result: SUB基准和TDG方法为评估和改进CBMs等可解释模型提供了新的工具和方向，有助于开发更鲁棒的方法。

Conclusion: CBMs在分布偏移下识别概念的可靠性需要提高，SUB基准和TDG方法为评估和改进CBMs提供了新的途径。

Abstract: Concept Bottleneck Models (CBMs) and other concept-based interpretable models
show great promise for making AI applications more transparent, which is
essential in fields like medicine. Despite their success, we demonstrate that
CBMs struggle to reliably identify the correct concepts under distribution
shifts. To assess the robustness of CBMs to concept variations, we introduce
SUB: a fine-grained image and concept benchmark containing 38,400 synthetic
images based on the CUB dataset. To create SUB, we select a CUB subset of 33
bird classes and 45 concepts to generate images which substitute a specific
concept, such as wing color or belly pattern. We introduce a novel Tied
Diffusion Guidance (TDG) method to precisely control generated images, where
noise sharing for two parallel denoising processes ensures that both the
correct bird class and the correct attribute are generated. This novel
benchmark enables rigorous evaluation of CBMs and similar interpretable models,
contributing to the development of more robust methods. Our code is available
at https://github.com/ExplainableML/sub and the dataset at
http://huggingface.co/datasets/Jessica-bader/SUB.

</details>


### [95] [Gaussian Variation Field Diffusion for High-fidelity Video-to-4D Synthesis](https://arxiv.org/abs/2507.23785)
*Bowen Zhang,Sicheng Xu,Chuxin Wang,Jiaolong Yang,Feng Zhao,Dong Chen,Baining Guo*

Main category: cs.CV

TL;DR: 提出了一种新颖的视频到4D生成框架，使用一种高效的表示方法和扩散模型，从单个视频输入生成高质量的动态3D内容。


<details>
  <summary>Details</summary>
Motivation: 直接进行4D扩散建模因其成本高昂的数据构建和联合表示3D形状、外观和运动的高维特性而极具挑战性。本研究旨在解决这些挑战。

Method: 提出了一种直接的4D网格到高斯散点（GS）变异场变分自编码器（VAE），直接编码高斯散点（GS）及其时间变异，用于从3D动画数据生成4D内容，并将高维动画压缩到紧凑的潜在空间。在此基础上，训练了一个高斯变异场扩散模型，并使用时间感知的Diffusion Transformer对输入视频和规范GS进行条件约束。

Result: 所提出的模型在Objaverse数据集上进行了训练，展示了优于现有方法的生成质量，并且能够很好地泛化到实际的视频输入。

Conclusion: 该模型展示了与现有方法相比优越的生成质量，并能很好地泛化到实际视频输入，为生成高质量的动画3D内容开辟了道路。

Abstract: In this paper, we present a novel framework for video-to-4D generation that
creates high-quality dynamic 3D content from single video inputs. Direct 4D
diffusion modeling is extremely challenging due to costly data construction and
the high-dimensional nature of jointly representing 3D shape, appearance, and
motion. We address these challenges by introducing a Direct 4DMesh-to-GS
Variation Field VAE that directly encodes canonical Gaussian Splats (GS) and
their temporal variations from 3D animation data without per-instance fitting,
and compresses high-dimensional animations into a compact latent space.
Building upon this efficient representation, we train a Gaussian Variation
Field diffusion model with temporal-aware Diffusion Transformer conditioned on
input videos and canonical GS. Trained on carefully-curated animatable 3D
objects from the Objaverse dataset, our model demonstrates superior generation
quality compared to existing methods. It also exhibits remarkable
generalization to in-the-wild video inputs despite being trained exclusively on
synthetic data, paving the way for generating high-quality animated 3D content.
Project page: https://gvfdiffusion.github.io/.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [96] [Large Language Models in the Travel Domain: An Industrial Experience](https://arxiv.org/abs/2507.22910)
*Sergio Di Meglio,Aniello Somma,Luigi Libero Lucio Starace,Fabio Scippacercola,Giancarlo Sperlì,Sergio Di Martino*

Main category: cs.CL

TL;DR: 本研究评估了两种大型语言模型（Mistral 7B 和 Mixtral 8x7B）在房产预订平台数据一致性方面的表现。Mixtral 8x7B 效果更好但成本更高，研究为 LLM 部署提供了关于质量和成本的实用见解。


<details>
  <summary>Details</summary>
Motivation: 在线房产预订平台严重依赖第三方提供商提供的信息，但这些信息经常不完整或不一致，导致用户体验不佳和市场损失。因此，本研究旨在通过整合大型语言模型来提高数据的一致性和可靠性。

Method: 本研究通过集成和评估两种大型语言模型（Mistral 7B，使用 QLoRA 进行微调；Mixtral 8x7B，使用精炼的系统提示）来解决在线房产预订平台数据不一致的问题。评估指标包括生成一致性和同质性描述的能力以及幻觉率。

Result: Mixtral 8x7B 在完整性（99.6% vs. 93%）、精确度（98.8% vs. 96%）和幻觉率（1.2% vs. 4%）方面优于 Mistral 7B，生成的内容更简洁（平均 249 字 vs. 277 字）。然而，Mixtral 8x7B 的计算成本更高（50GB 显存和 1.61 美元/小时 vs. Mistral 7B 的 5GB 和 0.16 美元/小时）。

Conclusion: 该研究通过在 CALEIDOHOTELS 平台集成和评估 Mistral 7B 和 Mixtral 8x7B 大型语言模型，为在生产环境中部署 LLM 提供了实用的见解，重点关注模型质量和资源效率之间的权衡，并证明了 LLM 在提高住宿数据一致性和可靠性方面的有效性。

Abstract: Online property booking platforms are widely used and rely heavily on
consistent, up-to-date information about accommodation facilities, often
sourced from third-party providers. However, these external data sources are
frequently affected by incomplete or inconsistent details, which can frustrate
users and result in a loss of market. In response to these challenges, we
present an industrial case study involving the integration of Large Language
Models (LLMs) into CALEIDOHOTELS, a property reservation platform developed by
FERVENTO. We evaluate two well-known LLMs in this context: Mistral 7B,
fine-tuned with QLoRA, and Mixtral 8x7B, utilized with a refined system prompt.
Both models were assessed based on their ability to generate consistent and
homogeneous descriptions while minimizing hallucinations. Mixtral 8x7B
outperformed Mistral 7B in terms of completeness (99.6% vs. 93%), precision
(98.8% vs. 96%), and hallucination rate (1.2% vs. 4%), producing shorter yet
more concise content (249 vs. 277 words on average). However, this came at a
significantly higher computational cost: 50GB VRAM and $1.61/hour versus 5GB
and $0.16/hour for Mistral 7B. Our findings provide practical insights into the
trade-offs between model quality and resource efficiency, offering guidance for
deploying LLMs in production environments and demonstrating their effectiveness
in enhancing the consistency and reliability of accommodation data.

</details>


### [97] [ElectriQ: A Benchmark for Assessing the Response Capability of Large Language Models in Power Marketing](https://arxiv.org/abs/2507.22911)
*Jinzhi Wang,Qingke Peng,Haozhou Li,Zeyuan Zeng,Qinfeng Song,Kaixuan Yang,Jiangbo Zhang,Yaoying Wang,Ruimeng Li,Biyi Zhou*

Main category: cs.CL

TL;DR: ElectriQ是一个用于评估和改进电力营销场景下大型语言模型（LLM）的新基准。它包含一个包含六种服务类别和四个评估指标（专业性、受欢迎程度、可读性和用户友好性）的对话数据集，并结合了领域知识库和知识增强方法。实验证明，经过优化的Llama3-8B等小型模型在某些方面优于GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 现有电力营销客户服务系统（如中国的95598热线）存在响应缓慢、流程僵化和领域任务准确性有限等问题。尽管GPT-4o和Claude 3等大型语言模型（LLM）具有强大的通用能力，但在电力营销领域缺乏专业知识和同理心。

Method: 该研究提出了ElectriQ基准，包含一个涵盖六种关键服务类别的对话数据集，并引入了专业性、受欢迎程度、可读性和用户友好性四个评估指标。此外，研究还整合了领域特定的知识库，并提出了一种知识增强方法来提高模型性能。

Result: 在13个LLM上的实验结果表明，经过微调和知识增强的Llama3-8B等小型模型，在专业性和用户友好性方面能够超越GPT-4o。

Conclusion: ElectriQ为电力营销服务的LLM发展奠定了基础，旨在解决当前客服系统效率低下、缺乏领域专业性和同理心的问题。通过引入包含六种服务类别和四种评估指标（专业性、受欢迎程度、可读性和用户友好性）的对话数据集，并结合领域知识库和知识增强方法，ElectriQ能够提升模型在电力营销场景下的表现。实验表明，经过微调和知识增强的Llama3-8B等小型模型，在专业性和用户友好性方面优于GPT-4o，为开发满足电力营销服务需求的定制化LLM提供了全面支持。

Abstract: Electric power marketing customer service plays a critical role in addressing
inquiries, complaints, and service requests. However, current systems, such as
China's 95598 hotline, often struggle with slow response times, inflexible
procedures, and limited accuracy in domain-specific tasks. While large language
models (LLMs) like GPT-4o and Claude 3 demonstrate strong general capabilities,
they lack the domain expertise and empathy required in this field. To bridge
this gap, we introduce ElectriQ, the first benchmark designed to evaluate and
enhance LLMs in electric power marketing scenarios. ElectriQ consists of a
dialogue dataset covering six key service categories and introduces four
evaluation metrics: professionalism, popularity, readability, and
user-friendliness. We further incorporate a domain-specific knowledge base and
propose a knowledge augmentation method to boost model performance. Experiments
on 13 LLMs reveal that smaller models such as LLama3-8B, when fine-tuned and
augmented, can surpass GPT-4o in terms of professionalism and
user-friendliness. ElectriQ establishes a comprehensive foundation for
developing LLMs tailored to the needs of power marketing services.

</details>


### [98] [A Language Model-Driven Semi-Supervised Ensemble Framework for Illicit Market Detection Across Deep/Dark Web and Social Platforms](https://arxiv.org/abs/2507.22912)
*Navid Yazdanjue,Morteza Rakhshaninejad,Hossein Yazdanjouei,Mohammad Sadegh Khorshidi,Mikko S. Niemela,Fang Chen,Amir H. Gandomi*

Main category: cs.CL

TL;DR: 该研究提出了一种结合ModernBERT和半监督集成学习的框架，用于检测和分类来自不同平台的非法市场内容，并在准确率、F1分数和TMCC方面取得了优于基线模型的成果。


<details>
  <summary>Details</summary>
Motivation: 非法市场已越来越多地转移到互联网的隐蔽部分（如深度和黑暗网络、Telegram、Reddit、Pastebin），用于交易毒品、武器和被盗凭证等非法商品。然而，由于标记数据有限、非法语言不断演变以及在线来源的结构异质性，检测和分类此类内容仍然是一个挑战。

Method: 本研究提出了一种分层分类框架，结合了使用ModernBERT提取的语义表示和手动设计的特征。该框架分为两个阶段：第一阶段使用XGBoost、Random Forest和SVM的半监督集成模型来检测销售相关文档；第二阶段则将这些文档进一步分类为毒品、武器或凭证销售。

Result: 实验结果表明，该模型在准确率方面达到了0.96489，F1分数达到了0.93467，TMCC达到了0.95388。与BERT、ModernBERT、DarkBERT、ALBERT、Longformer和BigBird等多个基线模型相比，该模型表现更优，显示出强大的泛化能力、在有限监督下的鲁棒性以及在真实世界非法内容检测中的有效性。

Conclusion: 本研究提出的分层分类框架结合了微调语言模型和半监督集成学习策略，能够有效检测和分类来自不同平台（如深度和黑暗网络、Telegram、Reddit、Pastebin）的非法市场内容。实验结果表明，该模型在准确率、F1分数和TMCC方面均优于多个基线模型，证明了其在有限监督下的泛化能力、鲁棒性以及在真实世界非法内容检测中的有效性。

Abstract: Illegal marketplaces have increasingly shifted to concealed parts of the
internet, including the deep and dark web, as well as platforms such as
Telegram, Reddit, and Pastebin. These channels enable the anonymous trade of
illicit goods including drugs, weapons, and stolen credentials. Detecting and
categorizing such content remains challenging due to limited labeled data, the
evolving nature of illicit language, and the structural heterogeneity of online
sources. This paper presents a hierarchical classification framework that
combines fine-tuned language models with a semi-supervised ensemble learning
strategy to detect and classify illicit marketplace content across diverse
platforms. We extract semantic representations using ModernBERT, a transformer
model for long documents, finetuned on domain-specific data from deep and dark
web pages, Telegram channels, Subreddits, and Pastebin pastes to capture
specialized jargon and ambiguous linguistic patterns. In addition, we
incorporate manually engineered features such as document structure, embedded
patterns including Bitcoin addresses, emails, and IPs, and metadata, which
complement language model embeddings. The classification pipeline operates in
two stages. The first stage uses a semi-supervised ensemble of XGBoost, Random
Forest, and SVM with entropy-based weighted voting to detect sales-related
documents. The second stage further classifies these into drug, weapon, or
credential sales. Experiments on three datasets, including our multi-source
corpus, DUTA, and CoDA, show that our model outperforms several baselines,
including BERT, ModernBERT, DarkBERT, ALBERT, Longformer, and BigBird. The
model achieves an accuracy of 0.96489, an F1-score of 0.93467, and a TMCC of
0.95388, demonstrating strong generalization, robustness under limited
supervision, and effectiveness in real-world illicit content detection.

</details>


### [99] [A Hybrid Framework for Subject Analysis: Integrating Embedding-Based Regression Models with Large Language Models](https://arxiv.org/abs/2507.22913)
*Jinyu Liu,Xiaoying Song,Diana Zhang,Jason Thomale,Daqing He,Lingzi Hong*

Main category: cs.CL

TL;DR: 本研究提出了一种混合框架，结合机器学习模型和大型语言模型进行图书主题分析，通过指导LLM生成和后编辑来提高输出的准确性和可控性。


<details>
  <summary>Details</summary>
Motivation: 尽管机器学习模型在多标签分类用于主题分析方面有应用，但它们在处理未见过的数据时存在困难。大型语言模型虽然提供了一种替代方案，但容易过度生成和产生幻觉。因此，本研究旨在探索一种结合两者优点的混合方法。

Method: 本研究提出了一种混合框架，该框架结合了基于嵌入的机器学习模型和大型语言模型（LLMs）。具体来说，机器学习模型用于（1）预测最适合的LCSH标签数量以指导LLM的预测，以及（2）对LLM预测的术语进行后编辑，使用实际的LCSH术语来减少幻觉。

Result: 实验结果表明，通过使用机器学习模型来指导LLM的生成并进行后编辑，能够产生更受控且与词汇表一致的主题分析结果，优于单独使用LLM的方法。

Conclusion: 本研究提出的混合框架通过结合基于嵌入的机器学习模型和大型语言模型，在图书主题分析任务上取得了比单独使用大型语言模型更可控、更符合词汇的输出结果。

Abstract: Providing subject access to information resources is an essential function of
any library management system. Large language models (LLMs) have been widely
used in classification and summarization tasks, but their capability to perform
subject analysis is underexplored. Multi-label classification with traditional
machine learning (ML) models has been used for subject analysis but struggles
with unseen cases. LLMs offer an alternative but often over-generate and
hallucinate. Therefore, we propose a hybrid framework that integrates
embedding-based ML models with LLMs. This approach uses ML models to (1)
predict the optimal number of LCSH labels to guide LLM predictions and (2)
post-edit the predicted terms with actual LCSH terms to mitigate
hallucinations. We experimented with LLMs and the hybrid framework to predict
the subject terms of books using the Library of Congress Subject Headings
(LCSH). Experiment results show that providing initial predictions to guide LLM
generations and imposing post-edits result in more controlled and
vocabulary-aligned outputs.

</details>


### [100] [Full Triple Matcher: Integrating all triple elements between heterogeneous Knowledge Graphs](https://arxiv.org/abs/2507.22914)
*Victor Eiti Yamamoto,Hideaki Takeda*

Main category: cs.CL

TL;DR: 为解决知识图谱上下文匹配的不足，提出一种包含标签匹配和三元组匹配的新方法，该方法在OAEI竞赛和监督方法中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的实体匹配方法主要关注模式和标识符匹配，而忽略了上下文匹配。然而，现实世界的知识图谱在来源、大小和信息密度上存在显著差异，这些因素影响了匹配效果，现有方法在整合多样化和复杂的上下文信息时表现不佳。

Method: 提出了一种新颖的知识图谱（KG）集成方法，包括标签匹配和三元组匹配。利用字符串操作、模糊匹配和向量相似性技术对实体和谓词标签进行对齐，并识别传达可比信息的य（triples）之间的映射关系，以提高实体匹配的准确性。

Result: 该方法在OAEI竞赛和监督方法中均取得了有竞争力且高精度的性能，并在包含新引入数据集的测试用例中得到了验证。

Conclusion: 现有实体匹配方法在处理多样化和复杂的上下文信息时存在不足，本研究提出的新方法在OAEI竞赛和监督方法中表现出有竞争力且高精度的性能。

Abstract: Knowledge graphs (KGs) are powerful tools for representing and reasoning over
structured information. Their main components include schema, identity, and
context. While schema and identity matching are well-established in ontology
and entity matching research, context matching remains largely unexplored. This
is particularly important because real-world KGs often vary significantly in
source, size, and information density - factors not typically represented in
the datasets on which current entity matching methods are evaluated. As a
result, existing approaches may fall short in scenarios where diverse and
complex contexts need to be integrated.
  To address this gap, we propose a novel KG integration method consisting of
label matching and triple matching. We use string manipulation, fuzzy matching,
and vector similarity techniques to align entity and predicate labels. Next, we
identify mappings between triples that convey comparable information, using
these mappings to improve entity-matching accuracy. Our approach demonstrates
competitive performance compared to leading systems in the OAEI competition and
against supervised methods, achieving high accuracy across diverse test cases.
Additionally, we introduce a new dataset derived from the benchmark dataset to
evaluate the triple-matching step more comprehensively.

</details>


### [101] [Theoretical Foundations and Mitigation of Hallucination in Large Language Models](https://arxiv.org/abs/2507.22915)
*Esmail Gumaan*

Main category: cs.CL

TL;DR: 本文分析了大语言模型中的幻觉问题，提出了理论分析、检测和缓解方法，并给出了评估协议。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）中的幻觉现象，即生成内容与输入或现实世界事实不符，是一个关键挑战。

Method: 本文区分了内在幻觉和外在幻觉，定义了模型的“幻觉风险”，并使用学习理论框架（PAC-Bayes和Rademacher复杂性）推导了该风险的界限。此外，本文还调研了幻觉的检测策略（如token级不确定性估计、置信度校准、注意力对齐检查）和缓解方法（如检索增强生成、面向幻觉的微调、logit校准、事实核查模块的结合）。

Result: 本文对LLMs中的幻觉进行了理论分析和检测、缓解策略的调研，并提出了一个统一的工作流程和评估协议。

Conclusion: 本文为大语言模型中的幻觉问题提供了严格的处理，包括形式化定义和理论分析，并提出了统一的检测和缓解工作流程，以及评估协议，为解决大语言模型中的幻觉问题奠定了理论基础和实践指导。

Abstract: Hallucination in Large Language Models (LLMs) refers to the generation of
content that is not faithful to the input or the real-world facts. This paper
provides a rigorous treatment of hallucination in LLMs, including formal
definitions and theoretical analyses. We distinguish between intrinsic and
extrinsic hallucinations, and define a \textit{hallucination risk} for models.
We derive bounds on this risk using learning-theoretic frameworks (PAC-Bayes
and Rademacher complexity). We then survey detection strategies for
hallucinations, such as token-level uncertainty estimation, confidence
calibration, and attention alignment checks. On the mitigation side, we discuss
approaches including retrieval-augmented generation, hallucination-aware
fine-tuning, logit calibration, and the incorporation of fact-verification
modules. We propose a unified detection and mitigation workflow, illustrated
with a diagram, to integrate these strategies. Finally, we outline evaluation
protocols for hallucination, recommending datasets, metrics, and experimental
setups to quantify and reduce hallucinations. Our work lays a theoretical
foundation and practical guidelines for addressing the crucial challenge of
hallucination in LLMs.

</details>


### [102] [Reading Between the Timelines: RAG for Answering Diachronic Questions](https://arxiv.org/abs/2507.22917)
*Kwun Hang Lau,Ruiyuan Zhang,Weijie Shi,Xiaofang Zhou,Xiaojun Cheng*

Main category: cs.CL

TL;DR: 为了应对 RAG 在处理需要跨时间跟踪实体和现象的纵向查询方面的不足，我们提出了一种新的框架，通过将用户的查询分解为其核心主题和时间窗口，并采用一种将语义匹配与时间相关性相结合的专用检索器来解决这一挑战。我们还提出了 ADQAB 基准来评估我们的方法。实验结果表明，我们的方法在答案准确性方面比标准 RAG 方法有了显著提高。


<details>
  <summary>Details</summary>
Motivation: 在检索增强生成 (RAG) 擅长将静态、事实知识注入大型语言模型 (LLM) 的同时，它在处理需要跨时间跟踪实体和现象的纵向查询方面存在明显的缺陷。这种盲点之所以出现，是因为传统的、由语义驱动的检索方法无法收集与特定持续时间相关的主题相关且在时间上连贯的证据。

Method: 我们提出了一种新的框架，从根本上重新设计了 RAG 管道以注入时间逻辑。我们的方法首先将用户的查询分解为其核心主题和时间窗口。然后，我们采用一种专门的检索器，将语义匹配与时间相关性进行校准，确保收集一套连续的证据，涵盖整个查询期间。

Result: 在 ADQAB 上的实证结果表明，我们的方法在答案准确性方面取得了显著的收益，比标准的 RAG 实现提高了 13% 到 27%。

Conclusion: 这项工作为能够执行复杂、现实世界问题所需细致、演进式分析的 RAG 系统提供了一条经过验证的途径。

Abstract: While Retrieval-Augmented Generation (RAG) excels at injecting static,
factual knowledge into Large Language Models (LLMs), it exhibits a critical
deficit in handling longitudinal queries that require tracking entities and
phenomena across time. This blind spot arises because conventional,
semantically-driven retrieval methods are not equipped to gather evidence that
is both topically relevant and temporally coherent for a specified duration. We
address this challenge by proposing a new framework that fundamentally
redesigns the RAG pipeline to infuse temporal logic. Our methodology begins by
disentangling a user's query into its core subject and its temporal window. It
then employs a specialized retriever that calibrates semantic matching against
temporal relevance, ensuring the collection of a contiguous evidence set that
spans the entire queried period. To enable rigorous evaluation of this
capability, we also introduce the Analytical Diachronic Question Answering
Benchmark (ADQAB), a challenging evaluation suite grounded in a hybrid corpus
of real and synthetic financial news. Empirical results on ADQAB show that our
approach yields substantial gains in answer accuracy, surpassing standard RAG
implementations by 13% to 27%. This work provides a validated pathway toward
RAG systems capable of performing the nuanced, evolutionary analysis required
for complex, real-world questions. The dataset and code for this study are
publicly available at https://github.com/kwunhang/TA-RAG.

</details>


### [103] [EH-Benchmark Ophthalmic Hallucination Benchmark and Agent-Driven Top-Down Traceable Reasoning Workflow](https://arxiv.org/abs/2507.22929)
*Xiaoyu Pan,Yang Bai,Ke Zou,Yang Zhou,Jun Zhou,Huazhu Fu,Yih-Chung Tham,Yong Liu*

Main category: cs.CL

TL;DR: EH-Benchmark是一个评估眼科MLLM幻觉的新基准，引入了基于智能体的三阶段框架，通过知识检索、案例研究和结果验证来解决幻觉问题，并已在实验中证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的MLLMs在眼科诊断中存在幻觉问题，其准确性受到眼科知识限制、视觉定位和推理能力不足以及多模态眼科数据稀缺等因素的制约，这些因素共同阻碍了病变检测和疾病诊断的精确性。此外，现有的医学基准测试未能有效评估各类幻觉或提供缓解措施。

Method: 提出了一种名为EH-Benchmark的新型基准测试，用于评估MLLMs在眼科诊断中的幻觉问题。该基准测试将幻觉分为视觉理解和逻辑构成两大类，并包含多个子类。为解决MLLMs在视觉处理方面的不足，提出了一种以智能体为中心的三阶段框架，包括知识级检索、任务级案例研究和结果级验证。

Result: 实验结果表明，所提出的多智能体框架显著减轻了两种类型的幻觉，提高了准确性、可解释性和可靠性。

Conclusion: EH-Benchmark通过引入多智能体框架，有效缓解了视觉理解和逻辑构成两类幻觉，提高了MLLMs在眼科诊断中的准确性、可解释性和可靠性。

Abstract: Medical Large Language Models (MLLMs) play a crucial role in ophthalmic
diagnosis, holding significant potential to address vision-threatening
diseases. However, their accuracy is constrained by hallucinations stemming
from limited ophthalmic knowledge, insufficient visual localization and
reasoning capabilities, and a scarcity of multimodal ophthalmic data, which
collectively impede precise lesion detection and disease diagnosis.
Furthermore, existing medical benchmarks fail to effectively evaluate various
types of hallucinations or provide actionable solutions to mitigate them. To
address the above challenges, we introduce EH-Benchmark, a novel ophthalmology
benchmark designed to evaluate hallucinations in MLLMs. We categorize MLLMs'
hallucinations based on specific tasks and error types into two primary
classes: Visual Understanding and Logical Composition, each comprising multiple
subclasses. Given that MLLMs predominantly rely on language-based reasoning
rather than visual processing, we propose an agent-centric, three-phase
framework, including the Knowledge-Level Retrieval stage, the Task-Level Case
Studies stage, and the Result-Level Validation stage. Experimental results show
that our multi-agent framework significantly mitigates both types of
hallucinations, enhancing accuracy, interpretability, and reliability. Our
project is available at https://github.com/ppxy1/EH-Benchmark.

</details>


### [104] [Semantic Convergence: Investigating Shared Representations Across Scaled LLMs](https://arxiv.org/abs/2507.22918)
*Daniel Son,Sanjana Rathore,Andrew Rufail,Adrian Simon,Daniel Zhang,Soham Dave,Cole Blondin,Kevin Zhu,Sean O'Brien*

Main category: cs.CL

TL;DR: Despite scale differences, Gemma-2 models develop similar internal concepts, especially in middle layers, supporting cross-model interpretability.


<details>
  <summary>Details</summary>
Motivation: Investigate feature universality in language models with different scales, specifically whether models with a four-fold difference in scale converge on comparable internal concepts.

Method: Utilized Sparse Autoencoders (SAEs) on residual-stream activations of Gemma-2-2B and Gemma-2-9B models, aligned features via activation correlation, and compared feature spaces using SVCCA and RSA.

Result: Middle layers showed the strongest overlap in feature spaces between the two models, while early and late layers exhibited less similarity. Preliminary experiments indicated that semantically similar multi-token subspaces interact similarly with the models.

Conclusion: Gemma-2-2B and Gemma-2-9B models, despite a four-fold difference in scale, converge on comparable internal concepts, particularly in the middle layers. Semantically similar multi-token subspaces also interact similarly with the models.

Abstract: We investigate feature universality in Gemma-2 language models (Gemma-2-2B
and Gemma-2-9B), asking whether models with a four-fold difference in scale
still converge on comparable internal concepts. Using the Sparse Autoencoder
(SAE) dictionary-learning pipeline, we utilize SAEs on each model's
residual-stream activations, align the resulting monosemantic features via
activation correlation, and compare the matched feature spaces with SVCCA and
RSA. Middle layers yield the strongest overlap, while early and late layers
show far less similarity. Preliminary experiments extend the analysis from
single tokens to multi-token subspaces, showing that semantically similar
subspaces interact similarly with language models. These results strengthen the
case that large language models carve the world into broadly similar,
interpretable features despite size differences, reinforcing universality as a
foundation for cross-model interpretability.

</details>


### [105] [LENS: Learning Ensemble Confidence from Neural States for Multi-LLM Answer Integration](https://arxiv.org/abs/2507.23167)
*Jizhou Guo*

Main category: cs.CL

TL;DR: LENS通过分析LLM的内部状态来学习模型置信度，从而改进集成LLM的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM集成方法（如投票或logits集成）往往忽略了模型在不同情境下信心和可靠性的差异。

Method: 提出了一种名为LENS（Learning ENsemble confidence from Neural States）的新方法，该方法通过分析内部表示来学习模型置信度。具体来说，为每个LLM训练一个轻量级的线性置信度预测器，该预测器利用层级隐藏状态和归一化概率作为输入，从而可以根据模型在不同上下文中的可靠性对模型预测进行更细致的加权。

Result: 实验结果表明，LENS在多项选择题和布尔问答任务上的表现优于传统集成方法。

Conclusion: LLM集成方法可以通过分析内部表示来学习模型置信度，LENS在该方法上表现优于传统方法。

Abstract: Large Language Models (LLMs) have demonstrated impressive performance across
various tasks, with different models excelling in distinct domains and specific
abilities. Effectively combining the predictions of multiple LLMs is crucial
for enhancing system robustness and performance. However, existing ensemble
methods often rely on simple techniques like voting or logits ensembling, which
overlook the varying confidence and reliability of models in different
contexts. In this work, we propose LENS (Learning ENsemble confidence from
Neural States), a novel approach that learns to estimate model confidence by
analyzing internal representations. For each LLM, we train a lightweight linear
confidence predictor that leverages layer-wise hidden states and normalized
probabilities as inputs. This allows for more nuanced weighting of model
predictions based on their context-dependent reliability. Our method does not
require modifying the model parameters and requires negligible additional
computation. Experimental results on multiple-choice and boolean
question-answering tasks demonstrate that LENS outperforms traditional ensemble
methods by a substantial margin. Our findings suggest that internal
representations provide valuable signals for determining model confidence and
can be effectively leveraged for ensemble learning.

</details>


### [106] [A novel language model for predicting serious adverse event results in clinical trials from their prospective registrations](https://arxiv.org/abs/2507.22919)
*Qixuan Hu,Xumou Zhang,Jinman Kim,Florence Bourgeois,Adam G. Dunn*

Main category: cs.CL

TL;DR: This paper presents a method using AI and pre-trial data to predict safety risks in clinical trials, aiming to improve trial design and participant safety. The developed models show promising accuracy in predicting higher rates of serious adverse events and the proportion of participants experiencing them.


<details>
  <summary>Details</summary>
Motivation: Accurate estimates of expected safety outcomes could lead to clinical trial designs that avoid terminations and minimize the exposure of participants to unnecessary risks. The study aimed to evaluate methods for predicting SAE results in clinical trials using only information from their pre-trial registrations.

Method: Two prediction models were developed: a classifier to predict whether the experimental arm will have higher serious adverse event (SAE) rates than the control arm (AUC), and a regression model to predict the proportion of SAEs in control arms (RMSE). A transfer learning approach using pre-trained language models (ClinicalT5, BioBERT) was employed for feature extraction, coupled with a downstream prediction model. A sliding window method was developed for embedding extraction to maintain semantic representation in long trial texts exceeding the input limits of localized language models.

Result: The best model (ClinicalT5+Transformer+MLP) achieved an AUC of 77.6% in predicting which trial arm would have a higher proportion of patients with SAEs. The same model obtained an RMSE of 18.6% when predicting the proportion of participants experiencing SAEs in the control arm. The sliding window approach consistently outperformed methods that did not use it, leading to an average AUC increase of 2.00% across 12 classifiers and an average RMSE reduction of 1.58% across 12 regressors.

Conclusion: Summary results data in ClinicalTrials.gov is underutilized, and the ability to estimate trial outcomes before they begin presents an opportunity to enhance trial design and identify discrepancies between anticipated and reported safety results.

Abstract: Objectives: With accurate estimates of expected safety results, clinical
trials could be designed to avoid terminations and limit exposing participants
to unnecessary risks. We evaluated methods for predicting serious adverse event
(SAE) results in clinical trials using information only from their
registrations prior to the trial. Material and Methods: We analysed 22,107
two-arm parallel interventional clinical trials from ClinicalTrials.gov with
structured summary results. Two prediction models were developed: a classifier
predicting will experimental arm have higher SAE rates (area under the receiver
operating characteristic curve; AUC) than control arm, and a regression model
to predict the proportion of SAEs in control arms (root mean squared error;
RMSE). A transfer learning approach using pretrained language models (e.g.,
ClinicalT5, BioBERT) was used for feature extraction, combined with downstream
model for prediction. To maintain semantic representation in long trial texts
exceeding localised language model input limits, a sliding window method was
developed for embedding extraction. Results: The best model
(ClinicalT5+Transformer+MLP) had 77.6% AUC predicting which trial arm has a
higher proportion of patients with SAEs. When predicting proportion of
participants experiencing SAE in the control arm, the same model achieved RMSE
of 18.6%. The sliding window approach consistently outperformed methods without
it. Across 12 classifiers, the average absolute AUC increase was 2.00%; across
12 regressors, the average absolute RMSE reduction was 1.58%. Discussion:
Summary results data available at ClinicalTrials.gov remains underutilised. The
potential to estimate results of trials before they start is an opportunity to
improve trial design and flag discrepancies between expected and reported
safety results.

</details>


### [107] [Predicting stock prices with ChatGPT-annotated Reddit sentiment](https://arxiv.org/abs/2507.22922)
*Mateusz Kmak,Kamil Chmurzyński,Kamil Matejuk,Paweł Kotzbach,Jan Kocoń*

Main category: cs.CL

TL;DR: 社交媒体情绪对股价的预测能力有限，评论量和搜索趋势等指标更具预测性。


<details>
  <summary>Details</summary>
Motivation: 探讨源自社交媒体的情绪是否能有效预测股票市场波动，尤其是在零售投资者活动激增的背景下。

Method: 使用两种现有的基于文本的情感分析方法，并引入一种基于ChatGPT注释和微调的RoBERTa模型来分析r/wallstreetbets中与GameStop和AMC相关的帖子情绪，然后使用相关性和因果关系指标来评估预测能力。

Result: 社交媒体情绪与股价之间仅存在弱相关性，而评论量和谷歌搜索趋势等更简单的指标则表现出更强的预测信号。

Conclusion: 社交媒体情绪与股价之间仅存在弱相关性，而评论量和谷歌搜索趋势等更简单的指标则表现出更强的预测信号。

Abstract: The surge of retail investor activity on social media, exemplified by the
2021 GameStop short squeeze, raised questions about the influence of online
sentiment on stock prices. This paper explores whether sentiment derived from
social media discussions can meaningfully predict stock market movements. We
focus on Reddit's r/wallstreetbets and analyze sentiment related to two
companies: GameStop (GME) and AMC Entertainment (AMC). To assess sentiment's
role, we employ two existing text-based sentiment analysis methods and
introduce a third, a ChatGPT-annotated and fine-tuned RoBERTa-based model
designed to better interpret the informal language and emojis prevalent in
social media discussions. We use correlation and causality metrics to determine
these models' predictive power. Surprisingly, our findings suggest that social
media sentiment has only a weak correlation with stock prices. At the same
time, simpler metrics, such as the volume of comments and Google search trends,
exhibit stronger predictive signals. These results highlight the complexity of
retail investor behavior and suggest that traditional sentiment analysis may
not fully capture the nuances of market-moving online discussions.

</details>


### [108] [Discrete Tokenization for Multimodal LLMs: A Comprehensive Survey](https://arxiv.org/abs/2507.22920)
*Jindong Li,Yali Fu,Jiahong Liu,Linxiao Cao,Wei Ji,Menglin Yang,Irwin King,Ming-Hsuan Yang*

Main category: cs.CL

TL;DR: 该论文是首个对 LLM 中离散 tokenization 方法（特别是 VQ）进行全面 survey 的工作，对现有技术进行了分类、分析和讨论，并指出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 弥补当前缺乏对 LLM 中 VQ 技术进行系统性 survey 的空白，为将连续多模态数据转化为 LLM 可处理的离散表示提供指导。

Method: 通过对 8 种代表性 VQ 变体进行分类和分析，涵盖了算法原理、训练动态和与 LLM 的集成挑战，并从三个方面（不包含 LLM 的经典应用、基于 LLM 的单模态系统、基于 LLM 的多模态系统）讨论了现有研究。

Result: 提出了一种结构化的分类和分析方法，讨论了 VQ 在多模态 LLM 应用中的影响，并识别了代码本坍塌、梯度估计不稳定等关键挑战，同时展望了动态量化、统一 tokenization 框架等未来研究方向。

Conclusion: 本篇论文全面 survey 了 LLM 中离散 tokenization 方法，为相关领域的研究和应用提供了参考。

Abstract: The rapid advancement of large language models (LLMs) has intensified the
need for effective mechanisms to transform continuous multimodal data into
discrete representations suitable for language-based processing. Discrete
tokenization, with vector quantization (VQ) as a central approach, offers both
computational efficiency and compatibility with LLM architectures. Despite its
growing importance, there is a lack of a comprehensive survey that
systematically examines VQ techniques in the context of LLM-based systems. This
work fills this gap by presenting the first structured taxonomy and analysis of
discrete tokenization methods designed for LLMs. We categorize 8 representative
VQ variants that span classical and modern paradigms and analyze their
algorithmic principles, training dynamics, and integration challenges with LLM
pipelines. Beyond algorithm-level investigation, we discuss existing research
in terms of classical applications without LLMs, LLM-based single-modality
systems, and LLM-based multimodal systems, highlighting how quantization
strategies influence alignment, reasoning, and generation performance. In
addition, we identify key challenges including codebook collapse, unstable
gradient estimation, and modality-specific encoding constraints. Finally, we
discuss emerging research directions such as dynamic and task-adaptive
quantization, unified tokenization frameworks, and biologically inspired
codebook learning. This survey bridges the gap between traditional vector
quantization and modern LLM applications, serving as a foundational reference
for the development of efficient and generalizable multimodal systems. A
continuously updated version is available at:
https://github.com/jindongli-Ai/LLM-Discrete-Tokenization-Survey.

</details>


### [109] [Protecting Vulnerable Voices: Synthetic Dataset Generation for Self-Disclosure Detection](https://arxiv.org/abs/2507.22930)
*Shalini Jangra,Suparna De,Nishanth Sastry,Saeed Fadaei*

Main category: cs.CL

TL;DR: 研究者们创建了一个合成的 PII 透露数据集，用于研究社交媒体隐私风险，并发布了数据集和代码以促进研究。


<details>
  <summary>Details</summary>
Motivation: 社交平台（如 Reddit）上的用户帖子和评论中存在个人身份信息 (PII)，这些信息可能带来隐私风险和在线危害。然而，由于缺乏开源标记数据集，对这些 PII 透露信息的识别和检索研究受到阻碍。

Method: 该研究提出了一种创建合成 PII 透露数据的方法，该数据可安全共享，并生成了一个包含 19 类 PII 透露类别（针对弱势群体）的合成 PII 标记多文本跨度数据集。数据集由三个大型语言模型（Llama2-7B、Llama3-8B 和 zephyr-7b-beta）通过顺序指令提示生成，以模仿原始 Reddit 帖子。

Result: 研究者们通过三个指标评估了生成合成数据集的方法的有效性：1. 可复现性等效性：在合成数据上训练的模型应能获得与在原始数据上训练的模型相当的结果。2. 不可链接性：合成数据应无法通过常用机制（如谷歌搜索）与原始用户相关联。3. 难以区分性：人类应无法区分合成数据和原始数据。研究者们在指定网址发布了数据集和代码，以促进 PII 隐私风险研究。

Conclusion: 为了促进对 PII 透露文本检测的可复现研究，研究者们开发了一种生成合成 PII 透露数据的新方法，并发布了一个包含 19 类 PII 透露类别的 PII 标记多文本跨度数据集，该数据集由 Llama2-7B、Llama3-8B 和 zephyr-7b-beta 三个大型语言模型生成。

Abstract: Social platforms such as Reddit have a network of communities of shared
interests, with a prevalence of posts and comments from which one can infer
users' Personal Information Identifiers (PIIs). While such self-disclosures can
lead to rewarding social interactions, they pose privacy risks and the threat
of online harms. Research into the identification and retrieval of such risky
self-disclosures of PIIs is hampered by the lack of open-source labeled
datasets. To foster reproducible research into PII-revealing text detection, we
develop a novel methodology to create synthetic equivalents of PII-revealing
data that can be safely shared. Our contributions include creating a taxonomy
of 19 PII-revealing categories for vulnerable populations and the creation and
release of a synthetic PII-labeled multi-text span dataset generated from 3
text generation Large Language Models (LLMs), Llama2-7B, Llama3-8B, and
zephyr-7b-beta, with sequential instruction prompting to resemble the original
Reddit posts. The utility of our methodology to generate this synthetic dataset
is evaluated with three metrics: First, we require reproducibility equivalence,
i.e., results from training a model on the synthetic data should be comparable
to those obtained by training the same models on the original posts. Second, we
require that the synthetic data be unlinkable to the original users, through
common mechanisms such as Google Search. Third, we wish to ensure that the
synthetic data be indistinguishable from the original, i.e., trained humans
should not be able to tell them apart. We release our dataset and code at
https://netsys.surrey.ac.uk/datasets/synthetic-self-disclosure/ to foster
reproducible research into PII privacy risks in online social media.

</details>


### [110] [Fast and Accurate Contextual Knowledge Extraction Using Cascading Language Model Chains and Candidate Answers](https://arxiv.org/abs/2507.22921)
*Lee Harris*

Main category: cs.CL

TL;DR: LMC算法通过多阶段级联，提高语言模型提取信息的准确性和速度，并减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 为了解决语言模型成本高昂和产生幻觉（即生成不存在的信息）的问题，以及防止因错误信息而浪费资源。

Method: 提出、实现并应用了语言模型链（LMC）算法。LMC算法通过一个多阶段级联过程，将语言模型的响应限制在候选答案的集合内，并将不正确的响应信息反馈给更具预测性但更慢的语言模型，直至所有预测都正确。

Result: 通过将一系列语言模型结合到多阶段级联中，与单个语言模型相比，LMC算法显著提高了预测速度和准确性，并大大减少了相应的幻觉。

Conclusion: LMC算法显著提高了知识提取领域的预测速度和准确性，同时大大减少了幻觉。

Abstract: Language models can capture complex relationships in given text, but these
are notorious for being costly and for producing information that does not
exist (i.e., hallucinations). Furthermore, the resources invested into
producing this information would be wasted if it were incorrect. We address
these issues by proposing, implementing, and applying the Language Model Chain
(LMC) algorithm. In this, a language model's response to a given prompt about
given text is only correct if it exists in the collection of possible (i.e.,
candidate) answers, and text corresponding to incorrect responses is fed into a
more predictive (but slower) language model. This process is repeated for a
collection of language models, or until all predictions about the text are
correct. We used the LMC algorithm to extract patient dates of birth from
medical documents, and combining a collection of language models in a
multi-stage cascade significantly increased prediction speed and accuracy over
individual language models, while greatly reducing the number of corresponding
hallucinations. We believe that the novel LMC algorithm significantly
contributes to the knowledge extraction field, and that this should be explored
much further in the future.

</details>


### [111] [How and Where to Translate? The Impact of Translation Strategies in Cross-lingual LLM Prompting](https://arxiv.org/abs/2507.22923)
*Aman Gupta,Yingying Zhuang,Zhou Yu,Ziji Zhang,Anurag Beniwal*

Main category: cs.CL

TL;DR: 对 RAG 系统中多语言提示翻译策略进行评估，发现优化策略能提升低资源语言的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管 LLM 的多语言能力有所提升，但在不同语言和任务上的表现存在差异。尤其是在多语言检索增强生成（RAG）系统中，跨语言知识共享（例如，高资源语言到低资源语言）可能导致检索到的信息与上下文语言不一致，而现有的处理方式（预翻译或跨语言提示）效果尚不明确。

Method: 通过实验评估不同提示翻译策略对 RAG 增强 LLM 在多语言分类任务中的影响。

Result: 实验结果表明，一种优化的提示策略能够显著改善跨语言知识共享，进而提升下游分类任务的性能。

Conclusion: 优化 RAG 系统中的跨语言提示策略可以显著改善知识共享和低资源语言的下游任务性能。

Abstract: Despite advances in the multilingual capabilities of Large Language Models
(LLMs), their performance varies substantially across different languages and
tasks. In multilingual retrieval-augmented generation (RAG)-based systems,
knowledge bases (KB) are often shared from high-resource languages (such as
English) to low-resource ones, resulting in retrieved information from the KB
being in a different language than the rest of the context. In such scenarios,
two common practices are pre-translation to create a mono-lingual prompt and
cross-lingual prompting for direct inference. However, the impact of these
choices remains unclear. In this paper, we systematically evaluate the impact
of different prompt translation strategies for classification tasks with
RAG-enhanced LLMs in multilingual systems. Experimental results show that an
optimized prompting strategy can significantly improve knowledge sharing across
languages, therefore improve the performance on the downstream classification
task. The findings advocate for a broader utilization of multilingual resource
sharing and cross-lingual prompt optimization for non-English languages,
especially the low-resource ones.

</details>


### [112] [Using Sentiment Analysis to Investigate Peer Feedback by Native and Non-Native English Speakers](https://arxiv.org/abs/2507.22924)
*Brittney Exline,Melanie Duffin,Brittany Harbison,Chrissa da Gomez,David Joyner*

Main category: cs.CL

TL;DR: 母语非英语的学生在在线课程中给予更积极的同行反馈，但收到的反馈情绪却不那么积极，这表明语言背景在同行反馈体验中起着复杂的作用。


<details>
  <summary>Details</summary>
Motivation: 研究了母语为英语和非母语为英语的学生在使用在线同行反馈系统时在情绪、评级和接受度方面的差异，以了解语言背景如何影响这些因素。

Method: 使用基于Twitter-roBERTa的模型分析了500名学生的同行评论，并分析了情绪得分和同行反馈评级与学生语言背景的关系。

Result: 与母语为英语的学生相比，母语非英语的学生在同行反馈方面给予了更积极的评价，但收到的反馈的情绪却不那么积极。此外，在控制了性别和年龄之后，语言背景与情绪和评级之间存在显著的交互作用，表明语言背景在塑造同行反馈体验方面起着微妙而复杂的作用。

Conclusion: 母语非英语的学生在在线课程的同行反馈中扮演着复杂但重要的角色，尽管他们倾向于给出更积极的反馈，但他们收到的反馈情绪却不那么积极。

Abstract: Graduate-level CS programs in the U.S. increasingly enroll international
students, with 60.2 percent of master's degrees in 2023 awarded to non-U.S.
students. Many of these students take online courses, where peer feedback is
used to engage students and improve pedagogy in a scalable manner. Since these
courses are conducted in English, many students study in a language other than
their first. This paper examines how native versus non-native English speaker
status affects three metrics of peer feedback experience in online U.S.-based
computing courses. Using the Twitter-roBERTa-based model, we analyze the
sentiment of peer reviews written by and to a random sample of 500 students. We
then relate sentiment scores and peer feedback ratings to students' language
background. Results show that native English speakers rate feedback less
favorably, while non-native speakers write more positively but receive less
positive sentiment in return. When controlling for sex and age, significant
interactions emerge, suggesting that language background plays a modest but
complex role in shaping peer feedback experiences.

</details>


### [113] [Hierarchical Memory for High-Efficiency Long-Term Reasoning in LLM Agents](https://arxiv.org/abs/2507.22925)
*Haoran Sun,Shaoning Zeng*

Main category: cs.CL

TL;DR: H-MEM是一种新的LLM代理记忆架构，通过分层组织和基于索引的检索，提高了长期记忆的组织和检索效率，并在实验中表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM代理在记忆存储和检索方面虽然取得进展，但往往在结构化记忆组织和高效检索方面存在不足。本文旨在解决这些限制，通过提出一种新的记忆架构来增强LLM代理的决策制定和上下文连贯性。

Method: 提出了一种分层记忆（H-MEM）架构，该架构基于语义抽象的程度以多层级方式组织和更新记忆。每个记忆向量都嵌入了一个位置索引编码，指向其在下一层中语义相关的子记忆。在推理阶段，基于索引的路由机制能够实现高效、逐层的检索，无需进行详尽的相似性计算。

Result: 实验结果表明，该方法在LoCoMo数据集的五个任务设置中，一致优于五个基线方法，证明了其在长期对话场景中的有效性。

Conclusion: 所提出的分层记忆（H-MEM）架构通过多层级语义抽象和基于索引的路由机制，有效地组织和检索长期记忆，在LoCoMo数据集的五个任务设置中一致优于五个基线方法，证明了其在长期对话场景中的有效性。

Abstract: Long-term memory is one of the key factors influencing the reasoning
capabilities of Large Language Model Agents (LLM Agents). Incorporating a
memory mechanism that effectively integrates past interactions can
significantly enhance decision-making and contextual coherence of LLM Agents.
While recent works have made progress in memory storage and retrieval, such as
encoding memory into dense vectors for similarity-based search or organizing
knowledge in the form of graph, these approaches often fall short in structured
memory organization and efficient retrieval. To address these limitations, we
propose a Hierarchical Memory (H-MEM) architecture for LLM Agents that
organizes and updates memory in a multi-level fashion based on the degree of
semantic abstraction. Each memory vector is embedded with a positional index
encoding pointing to its semantically related sub-memories in the next layer.
During the reasoning phase, an index-based routing mechanism enables efficient,
layer-by-layer retrieval without performing exhaustive similarity computations.
We evaluate our method on five task settings from the LoCoMo dataset.
Experimental results show that our approach consistently outperforms five
baseline methods, demonstrating its effectiveness in long-term dialogue
scenarios.

</details>


### [114] [Multi-Relation Extraction in Entity Pairs using Global Context](https://arxiv.org/abs/2507.22926)
*Nilesh,Atul Gupta,Avinash C Panday*

Main category: cs.CL

TL;DR: 提出了一种新的方法来改进文档级关系提取，通过考虑实体在整个文档中的位置，而不是只关注它们出现的句子，从而提高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 文档级关系提取需要构建跨越所有相关句子的全局上下文，而先前的方法只关注提及实体的句子，未能捕捉准确提取关系所需的完整文档上下文。

Method: 提出了一种新颖的输入嵌入方法，该方法捕获实体在整个文档中的位置，而不是仅仅关注它们出现的范围。所提出的输入编码方法通过将实体表示为独立的片段来利用全局关系和多句子推理，而与它们在文档中的位置无关。

Result: 所提出的方法在三个基准关系提取数据集（DocRED、Re-DocRED 和 REBEL）上进行了测试，实验结果表明该方法能够准确预测文档级设置中实体之间的关系。

Conclusion: 该方法在文档级关系提取方面提高了关系检测的性能，具有理论和实践意义。

Abstract: In document-level relation extraction, entities may appear multiple times in
a document, and their relationships can shift from one context to another.
Accurate prediction of the relationship between two entities across an entire
document requires building a global context spanning all relevant sentences.
Previous approaches have focused only on the sentences where entities are
mentioned, which fails to capture the complete document context necessary for
accurate relation extraction. Therefore, this paper introduces a novel input
embedding approach to capture the positions of mentioned entities throughout
the document rather than focusing solely on the span where they appear. The
proposed input encoding approach leverages global relationships and
multi-sentence reasoning by representing entities as standalone segments,
independent of their positions within the document. The performance of the
proposed method has been tested on three benchmark relation extraction
datasets, namely DocRED, Re-DocRED, and REBEL. The experimental results
demonstrated that the proposed method accurately predicts relationships between
entities in a document-level setting. The proposed research also has
theoretical and practical implications. Theoretically, it advances global
context modeling and multi-sentence reasoning in document-level relation
extraction. Practically, it enhances relationship detection, enabling improved
performance in real-world NLP applications requiring comprehensive entity-level
insights and interpretability.

</details>


### [115] [PRGB Benchmark: A Robust Placeholder-Assisted Algorithm for Benchmarking Retrieval-Augmented Generation](https://arxiv.org/abs/2507.22927)
*Zhehao Tan,Yihan Jiao,Dan Yang,Lei Liu,Jie Feng,Duolin Sun,Yue Shen,Jian Wang,Peng Wei,Jinjie Gu*

Main category: cs.CL

TL;DR: 我们提出了Placeholder-RAG-Benchmark，一个多层次、细粒度的基准测试，用于评估语言模型（LLM）在检索增强生成（RAG）系统中的文档利用能力，通过一种基于占位符的方法将LLM知识与外部知识分离，实验揭示了LLM在错误恢复和上下文忠实度方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前大多数检索增强生成（RAG）基准测试主要关注整个系统的性能，而忽略了对LLM自身在RAG能力中的作用进行系统性、细粒度的评估。

Method: 提出了一种创新的、基于占位符的方法，将LLM的参数化知识和外部知识分离开来，以更细粒度地评估LLM在RAG系统中的能力，重点关注多层次过滤、组合和引用推理能力。

Result: 实验证明，代表性LLM在RAG系统的生成能力方面存在局限性，尤其是在错误恢复能力和上下文忠实度方面。

Conclusion: 该基准测试提供了一个可重现的框架，用于开发更可靠、更高效的检索增强生成（RAG）系统，并揭示了代表性语言模型（LLM）在RAG系统中的局限性，特别是在错误恢复能力和上下文忠实度方面。

Abstract: Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by
integrating external knowledge, where the LLM's ability to generate responses
based on the combination of a given query and retrieved documents is crucial.
However, most benchmarks focus on overall RAG system performance, rarely
assessing LLM-specific capabilities. Current benchmarks emphasize broad aspects
such as noise robustness, but lack a systematic and granular evaluation
framework on document utilization. To this end, we introduce
\textit{Placeholder-RAG-Benchmark}, a multi-level fine-grained benchmark,
emphasizing the following progressive dimensions: (1) multi-level filtering
abilities, (2) combination abilities, and (3) reference reasoning. To provide a
more nuanced understanding of LLMs' roles in RAG systems, we formulate an
innovative placeholder-based approach to decouple the contributions of the
LLM's parametric knowledge and the external knowledge. Experiments demonstrate
the limitations of representative LLMs in the RAG system's generation
capabilities, particularly in error resilience and context faithfulness. Our
benchmark provides a reproducible framework for developing more reliable and
efficient RAG systems. Our code is available in
https://github.com/Alipay-Med/PRGB.

</details>


### [116] [How does Chain of Thought Think? Mechanistic Interpretability of Chain-of-Thought Reasoning with Sparse Autoencoding](https://arxiv.org/abs/2507.22928)
*Xi Chen,Aske Plaat,Niki van Stein*

Main category: cs.CL

TL;DR: Chain-of-thought (CoT) 提示能提升大模型（如 Pythia-2.8B）在数学推理任务中的表现，并使其内部机制更易解释。该效果在大模型上更明显，而在小模型（如 Pythia-70M）上不显著。CoT 提示通过优化模型内部特征的稀疏性和可解释性来提高推理能力。


<details>
  <summary>Details</summary>
Motivation: 探究 Chain-of-thought (CoT) 提示生成的“思考”内容是否真实反映了模型内部的推理过程，以及这种方法在不同模型规模下的效果差异。

Method: 结合稀疏自编码器和激活探测技术，从 Pythia-70M 和 Pythia-2.8B 模型在处理 GSM8K 数学问题时提取了单义特征，并对 CoT 和非 CoT 提示下的模型进行了对比分析。引入了 patch-curves 和随机特征探测基线。

Result: 在 Pythia-2.8B 模型中，将少量 CoT 推理特征替换到非 CoT 运行中，能够显著提高答案的对数概率；而在 Pythia-70M 模型中则没有明显效果，表明存在一个模型规模的阈值。CoT 还能提高大模型的激活稀疏性和特征可解释性，例如，模型生成正确答案的置信度从 1.2 提高到 4.3。CoT 信息广泛分布，并非只存在于 top-K 补丁中。

Conclusion: Chain-of-thought (CoT) 提示能够提高大语言模型在多步任务上的准确性，并且可以促进高容量语言模型内部结构的可解释性，验证了其作为一种结构化提示方法的有效性。

Abstract: Chain-of-thought (CoT) prompting boosts Large Language Models accuracy on
multi-step tasks, yet whether the generated "thoughts" reflect the true
internal reasoning process is unresolved. We present the first feature-level
causal study of CoT faithfulness. Combining sparse autoencoders with activation
patching, we extract monosemantic features from Pythia-70M and Pythia-2.8B
while they tackle GSM8K math problems under CoT and plain (noCoT) prompting.
Swapping a small set of CoT-reasoning features into a noCoT run raises answer
log-probabilities significantly in the 2.8B model, but has no reliable effect
in 70M, revealing a clear scale threshold. CoT also leads to significantly
higher activation sparsity and feature interpretability scores in the larger
model, signalling more modular internal computation. For example, the model's
confidence in generating correct answers improves from 1.2 to 4.3. We introduce
patch-curves and random-feature patching baselines, showing that useful CoT
information is not only present in the top-K patches but widely distributed.
Overall, our results indicate that CoT can induce more interpretable internal
structures in high-capacity LLMs, validating its role as a structured prompting
method.

</details>


### [117] [Enhancing RAG Efficiency with Adaptive Context Compression](https://arxiv.org/abs/2507.22931)
*Shuyu Guo,Zhaochun Ren*

Main category: cs.CL

TL;DR: ACC-RAG是一种新的RAG框架，通过自适应上下文压缩技术，根据输入复杂性动态调整压缩率，从而在不牺牲准确性的前提下，显著提高推理效率。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）虽然增强了大型语言模型（LLMs）的外部知识，但由于检索到的上下文过长，会带来显著的推理成本。现有方法采用固定的压缩率，对于简单查询会过度压缩，对于复杂查询则压缩不足。

Method: ACC-RAG框架结合了分层压缩器（用于多粒度嵌入）和上下文选择器，以保留最少但足够的信息，类似于人类的略读。

Result: 在维基百科和五个问答数据集上的评估结果显示，ACC-RAG的表现优于固定速率方法，并且实现了与标准RAG相当或更高的准确性，同时推理速度提高了4倍以上。

Conclusion: ACC-RAG框架通过动态调整压缩率，在保持或提高准确性的同时，实现了比标准RAG快4倍以上的推理速度，解决了现有固定压缩率方法的不足。

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs)
with external knowledge but incurs significant inference costs due to lengthy
retrieved contexts. While context compression mitigates this issue, existing
methods apply fixed compression rates, over-compressing simple queries or
under-compressing complex ones. We propose Adaptive Context Compression for RAG
(ACC-RAG), a framework that dynamically adjusts compression rates based on
input complexity, optimizing inference efficiency without sacrificing accuracy.
ACC-RAG combines a hierarchical compressor (for multi-granular embeddings) with
a context selector to retain minimal sufficient information, akin to human
skimming. Evaluated on Wikipedia and five QA datasets, ACC-RAG outperforms
fixed-rate methods and matches/unlocks over 4 times faster inference versus
standard RAG while maintaining or improving accuracy.

</details>


### [118] [FinMarBa: A Market-Informed Dataset for Financial Sentiment Classification](https://arxiv.org/abs/2507.22932)
*Baptiste Lefort,Eric Benhamou,Beatrice Guez,Jean-Jacques Ohana,Ethan Setrouk,Alban Etienne*

Main category: cs.CL

TL;DR: 本论文提出了一种结合大语言模型和深度强化学习的投资组合优化框架，通过整合金融新闻情感信号和传统市场指标，实现了优于基准的投资回报。


<details>
  <summary>Details</summary>
Motivation: 整合来自金融新闻的情感信号与传统市场指标，以改进投资组合优化。

Method: 提出了一种新颖的层次化框架，将轻量级大语言模型（LLMs）与深度强化学习（DRL）相结合，用于投资组合优化。该框架采用三层结构：基础RL智能体处理混合数据，元智能体聚合其决策，超级智能体则基于市场数据和情感分析合并决策。

Result: 实现了26%的年化回报率和1.2的夏普比率，优于等权重和标普500基准。

Conclusion: 该框架在2018年至2024年的数据上表现出色，实现了26%的年化回报率和1.2的夏普比率，优于等权重和标普500基准。

Abstract: This paper presents a novel hierarchical framework for portfolio
optimization, integrating lightweight Large Language Models (LLMs) with Deep
Reinforcement Learning (DRL) to combine sentiment signals from financial news
with traditional market indicators. Our three-tier architecture employs base RL
agents to process hybrid data, meta-agents to aggregate their decisions, and a
super-agent to merge decisions based on market data and sentiment analysis.
Evaluated on data from 2018 to 2024, after training on 2000-2017, the framework
achieves a 26% annualized return and a Sharpe ratio of 1.2, outperforming
equal-weighted and S&P 500 benchmarks. Key contributions include scalable
cross-modal integration, a hierarchical RL structure for enhanced stability,
and open-source reproducibility.

</details>


### [119] [Augmented Vision-Language Models: A Systematic Review](https://arxiv.org/abs/2507.22933)
*Anthony C Davis,Burhan Sadiq,Tianmin Shu,Chien-Ming Huang*

Main category: cs.CL

TL;DR: 本篇论文对利用外部符号信息系统增强视觉语言模型进行了综述，旨在解决现有模型的解释性、信息集成和推理能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉语言模型虽然能力强大，但在可解释性、信息集成和逻辑推理方面存在局限。神经符号系统通过结合神经网络和外部符号系统，有望克服这些挑战。

Method: 通过对现有文献进行系统性分类和分析，研究如何利用外部符号信息系统来改进视觉语言理解。

Result: 该研究旨在对通过与外部符号信息系统交互来改进视觉语言理解的技术进行分类。

Conclusion: 未来研究可以集中在进一步融合和优化神经符号系统，以提高视觉语言模型的解释性、适应性和推理能力。

Abstract: Recent advances in visual-language machine learning models have demonstrated
exceptional ability to use natural language and understand visual scenes by
training on large, unstructured datasets. However, this training paradigm
cannot produce interpretable explanations for its outputs, requires retraining
to integrate new information, is highly resource-intensive, and struggles with
certain forms of logical reasoning. One promising solution involves integrating
neural networks with external symbolic information systems, forming neural
symbolic systems that can enhance reasoning and memory abilities. These neural
symbolic systems provide more interpretable explanations to their outputs and
the capacity to assimilate new information without extensive retraining.
Utilizing powerful pre-trained Vision-Language Models (VLMs) as the core neural
component, augmented by external systems, offers a pragmatic approach to
realizing the benefits of neural-symbolic integration. This systematic
literature review aims to categorize techniques through which visual-language
understanding can be improved by interacting with external symbolic information
systems.

</details>


### [120] [Deep Learning Approaches for Multimodal Intent Recognition: A Survey](https://arxiv.org/abs/2507.22934)
*Jingwei Zhao,Yuhua Wen,Qifei Li,Minchi Hu,Yingying Zhou,Jingyao Xue,Junyang Wu,Yingming Gao,Zhengqi Wen,Jianhua Tao,Ya Li*

Main category: cs.CL

TL;DR: 该文对意图识别的深度学习方法进行了全面概述，重点关注多模态技术的最新进展和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着对自然人机交互需求的增长，意图识别领域通过深度学习和多模态方法得到了发展，该文旨在为研究人员提供多模态意图识别的最新进展和未来研究方向。

Method: 对意图识别的深度学习方法进行了全面概述，包括其从单模态到多模态技术的演变，并讨论了相关的数据集、方法、应用和挑战。

Result: 本文对意图识别领域的深度学习方法进行了全面的调查，重点关注从单模态到多模态方法的演变，并讨论了相关数据集、方法、应用和挑战，为未来的研究提供了见解。

Conclusion: 本文总结了用于意图识别的深度学习方法，涵盖了从单模态到多模态技术的转变、相关数据集、方法学、应用和当前挑战。

Abstract: Intent recognition aims to identify users' underlying intentions,
traditionally focusing on text in natural language processing. With growing
demands for natural human-computer interaction, the field has evolved through
deep learning and multimodal approaches, incorporating data from audio, vision,
and physiological signals. Recently, the introduction of Transformer-based
models has led to notable breakthroughs in this domain. This article surveys
deep learning methods for intent recognition, covering the shift from unimodal
to multimodal techniques, relevant datasets, methodologies, applications, and
current challenges. It provides researchers with insights into the latest
developments in multimodal intent recognition (MIR) and directions for future
research.

</details>


### [121] [Trusted Knowledge Extraction for Operations and Maintenance Intelligence](https://arxiv.org/abs/2507.22935)
*Kathleen Mealey,Jonathan A. Karr Jr.,Priscila Saboia Moreira,Paul R. Brenner,Charles F. Vardeman II*

Main category: cs.CL

TL;DR: 该研究评估了 NLP 和 LLM 工具在航空运维领域的知识提取能力，发现存在性能限制，并为提高其在关键任务行业中的可信度提出了建议。


<details>
  <summary>Details</summary>
Motivation: 解决组织数据存储库中的操作情报的获取问题，以及数据机密性与数据集成目标之间的冲突，还有自然语言处理（NLP）工具在特定领域（如运维）知识结构方面的局限性。

Method: 通过命名实体识别、共指消解、命名实体链接和关系提取等功能组件来构建知识图谱和知识提取过程。

Result: 通过在零样本场景下评估 16 种 NLP 和 LLM 工具，发现在特定领域知识提取方面存在显著的性能限制。

Conclusion: 基于在航空业领域的操作和维护智能用例，评估了十六种自然语言处理（NLP）和大型语言模型（LLM）工具的零样本性能，并讨论了在关键任务行业（如航空业）中值得信赖的 NLP 和 LLM 工具的挑战和技术准备水平。

Abstract: Deriving operational intelligence from organizational data repositories is a
key challenge due to the dichotomy of data confidentiality vs data integration
objectives, as well as the limitations of Natural Language Processing (NLP)
tools relative to the specific knowledge structure of domains such as
operations and maintenance. In this work, we discuss Knowledge Graph
construction and break down the Knowledge Extraction process into its Named
Entity Recognition, Coreference Resolution, Named Entity Linking, and Relation
Extraction functional components. We then evaluate sixteen NLP tools in concert
with or in comparison to the rapidly advancing capabilities of Large Language
Models (LLMs). We focus on the operational and maintenance intelligence use
case for trusted applications in the aircraft industry. A baseline dataset is
derived from a rich public domain US Federal Aviation Administration dataset
focused on equipment failures or maintenance requirements. We assess the
zero-shot performance of NLP and LLM tools that can be operated within a
controlled, confidential environment (no data is sent to third parties). Based
on our observation of significant performance limitations, we discuss the
challenges related to trusted NLP and LLM tools as well as their Technical
Readiness Level for wider use in mission-critical industries such as aviation.
We conclude with recommendations to enhance trust and provide our open-source
curated dataset to support further baseline testing and evaluation.

</details>


### [122] [Evaluating Large Language Models (LLMs) in Financial NLP: A Comparative Study on Financial Report Analysis](https://arxiv.org/abs/2507.22936)
*Md Talha Mohsin*

Main category: cs.CL

TL;DR: 本研究评估了五种主流大语言模型在金融文本处理任务中的表现，发现GPT表现最佳，而Gemini和DeepSeek表现不稳定。


<details>
  <summary>Details</summary>
Motivation: 鉴于大语言模型在金融分析中日益增长的影响力及其快速发展，本研究旨在对广泛使用的大语言模型进行系统的比较评估，填补现有研究的不足。

Method: 研究选取了GPT、Claude、Perplexity、Gemini和DeepSeek五种主流大语言模型，利用'Magnificent Seven'科技公司的10-K文件，设计了特定领域提示词，并采用人类标注、自动化词汇语义指标（ROUGE、余弦相似度、Jaccard）以及模型行为诊断（提示词级别方差和跨模型相似性）三种方法进行性能评估。

Result: GPT在连贯性、语义对齐和上下文相关性方面表现最优，Claude和Perplexity次之。Gemini和DeepSeek的输出变异性更大、一致性较低。模型输出的相似性和稳定性会随着公司和时间的推移而变化，对提示词的编写方式和使用的源材料敏感。

Conclusion: GPT在金融文本处理任务中表现出最佳的连贯性、语义对齐和上下文相关性，Claude和Perplexity紧随其后。Gemini和DeepSeek的输出变异性较大，一致性较差。此外，模型输出的相似性和稳定性因公司和时间而异，表明其对提示词编写和源材料敏感。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
a wide variety of Financial Natural Language Processing (FinNLP) tasks.
However, systematic comparisons among widely used LLMs remain underexplored.
Given the rapid advancement and growing influence of LLMs in financial
analysis, this study conducts a thorough comparative evaluation of five leading
LLMs, GPT, Claude, Perplexity, Gemini and DeepSeek, using 10-K filings from the
'Magnificent Seven' technology companies. We create a set of domain-specific
prompts and then use three methodologies to evaluate model performance: human
annotation, automated lexical-semantic metrics (ROUGE, Cosine Similarity,
Jaccard), and model behavior diagnostics (prompt-level variance and
across-model similarity). The results show that GPT gives the most coherent,
semantically aligned, and contextually relevant answers; followed by Claude and
Perplexity. Gemini and DeepSeek, on the other hand, have more variability and
less agreement. Also, the similarity and stability of outputs change from
company to company and over time, showing that they are sensitive to how
prompts are written and what source material is used.

</details>


### [123] [CoE-Ops: Collaboration of LLM-based Experts for AIOps Question-Answering](https://arxiv.org/abs/2507.22937)
*Jinkun Zhao,Yuanshuai Wang,Xingjian Zhang,Ruibo Chen,Xingchuang Liao,Junle Wang,Lei Huang,Kui Zhang,Wenjun Wu*

Main category: cs.CL

TL;DR: 本文提出了CoE-Ops框架，利用大语言模型和检索增强生成技术，提高了AIOps任务处理的准确性和效率，并在多项评估中超越了现有方法和模型。


<details>
  <summary>Details</summary>
Motivation: 当前的AIOps模型受限于特定领域的知识，单个模型只能处理特定任务。为了解决此问题，受集成学习和大型语言模型训练的启发，提出了一种结合多个模型的框架，以期在AIOps领域实现更高效的结果。

Method: 提出了一种名为CoE-Ops的协作专家框架，该框架包含一个通用的、任务分类的大语言模型。通过引入检索增强生成机制，增强了框架处理高层级（如代码、构建、测试等）和低层级（如故障分析、异常检测等）问答任务的能力。

Result: CoE-Ops框架在DevOps-EVAL数据集上的实验结果显示，其在高层级AIOps任务的路由准确性方面比现有的CoE方法提高了72%，在DevOps问题解决方面比单一AIOps模型提高了8%的准确性，并且比大规模的MoE模型提高了高达14%的准确性。

Conclusion: CoE-Ops框架在AIOps领域通过引入通用大语言模型任务分类器，并结合检索增强生成机制，在处理高层级和低层级任务方面表现出色。实验结果表明，与现有方法相比，CoE-Ops在AIOps任务的路由准确性方面提高了72%，在DevOps问题解决方面提高了8%的准确性，并且在准确性方面优于大规模混合专家（MoE）模型高达14%。

Abstract: With the rapid evolution of artificial intelligence, AIOps has emerged as a
prominent paradigm in DevOps. Lots of work has been proposed to improve the
performance of different AIOps phases. However, constrained by domain-specific
knowledge, a single model can only handle the operation requirement of a
specific task,such as log parser,root cause analysis. Meanwhile, combining
multiple models can achieve more efficient results, which have been proved in
both previous ensemble learning and the recent LLM training domain. Inspired by
these works,to address the similar challenges in AIOPS, this paper first
proposes a collaboration-of-expert framework(CoE-Ops) incorporating a
general-purpose large language model task classifier. A retrieval-augmented
generation mechanism is introduced to improve the framework's capability in
handling both Question-Answering tasks with high-level(Code,build,Test,etc.)
and low-level(fault analysis,anomaly detection,etc.). Finally, the proposed
method is implemented in the AIOps domain, and extensive experiments are
conducted on the DevOps-EVAL dataset. Experimental results demonstrate that
CoE-Ops achieves a 72% improvement in routing accuracy for high-level AIOps
tasks compared to existing CoE methods, delivers up to 8% accuracy enhancement
over single AIOps models in DevOps problem resolution, and outperforms
larger-scale Mixture-of-Experts (MoE) models by up to 14% in accuracy.

</details>


### [124] [OAEI-LLM-T: A TBox Benchmark Dataset for Understanding Large Language Model Hallucinations in Ontology Matching](https://arxiv.org/abs/2503.21813)
*Zhangcheng Qiang,Kerry Taylor,Weiqing Wang,Jing Jiang*

Main category: cs.CL

TL;DR: LLM在本体匹配任务中会产生幻觉。我们创建了一个名为OAEI-LLM-T的新数据集，其中包含LLM产生的本体匹配幻觉。该数据集可用于评估和改进LLM在本体匹配任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLM）在本体匹配（OM）任务中普遍存在的幻觉问题。由于幻觉会影响LLM在下游任务中的表现，因此需要专门的数据集来研究和解决OM任务中的幻觉。

Method: 创建了一个名为OAEI-LLM-T的新基准数据集，该数据集源自七个本体匹配（OM）TBox数据集，并捕捉了十种不同LLM在OM任务中产生的幻觉，这些幻觉分为两个主要类别和六个子类别。

Result: OAEI-LLM-T数据集可用于构建OM任务的LLM排行榜，并为用于OM任务的LLM进行微调。

Conclusion: LLM在本体匹配任务中存在幻觉问题，OAEI-LLM-T数据集有助于构建LLM排行榜和微调LLM以解决该问题。

Abstract: Hallucinations are often inevitable in downstream tasks using large language
models (LLMs). To tackle the substantial challenge of addressing hallucinations
for LLM-based ontology matching (OM) systems, we introduce a new benchmark
dataset OAEI-LLM-T. The dataset evolves from seven TBox datasets in the
Ontology Alignment Evaluation Initiative (OAEI), capturing hallucinations of
ten different LLMs performing OM tasks. These OM-specific hallucinations are
organised into two primary categories and six sub-categories. We showcase the
usefulness of the dataset in constructing an LLM leaderboard for OM tasks and
for fine-tuning LLMs used in OM tasks.

</details>


### [125] [A Graph-based Approach for Multi-Modal Question Answering from Flowcharts in Telecom Documents](https://arxiv.org/abs/2507.22938)
*Sumit Soman,H. G. Ranjani,Sujoy Roychowdhury,Venkata Dharma Surya Narayana Sastry,Akshat Jain,Pranav Gangrade,Ayaaz Khan*

Main category: cs.CL

TL;DR: 为解决技术文档问答中的图像理解难题，提出一种结合VLM提取的流程图图表示与文本RAG系统的方法，实现了高效的问答检索，并降低了推理成本。


<details>
  <summary>Details</summary>
Motivation: 解决基于文本的检索增强生成（RAG）系统在回答技术文档中涉及如图表或流程图等图像内容的问题时可能存在的不足。

Method: 提出一种端到端的方法，包括处理技术文档、分类图像类型、构建图表示，并将其与文本嵌入管道整合以实现高效检索。

Result: 通过在电信产品信息文档问答数据集上的基准测试表明，使用微调VLM模型获得的图表示与地面真实值相比具有较低的编辑距离，证明了其对流程图图像的鲁棒性。此外，使用这些表示的问答方法，包括针对电信域的适配模型，在文本嵌入检索方面表现良好。

Conclusion: 通过使用视觉语言模型（VLM）提取的流程图图表示，并将其整合到基于文本的检索增强生成（RAG）系统中，可以实现电信领域图像的问答检索。该方法通过文本嵌入管道实现高效检索，并可在推理阶段无需VLM，从而带来显著的成本效益。

Abstract: Question-Answering (QA) from technical documents often involves questions
whose answers are present in figures, such as flowcharts or flow diagrams.
Text-based Retrieval Augmented Generation (RAG) systems may fail to answer such
questions. We leverage graph representations of flowcharts obtained from Visual
large Language Models (VLMs) and incorporate them in a text-based RAG system to
show that this approach can enable image retrieval for QA in the telecom
domain. We present the end-to-end approach from processing technical documents,
classifying image types, building graph representations, and incorporating them
with the text embedding pipeline for efficient retrieval. We benchmark the same
on a QA dataset created based on proprietary telecom product information
documents. Results show that the graph representations obtained using a
fine-tuned VLM model have lower edit distance with respect to the ground truth,
which illustrate the robustness of these representations for flowchart images.
Further, the approach for QA using these representations gives good retrieval
performance using text-based embedding models, including a telecom-domain
adapted one. Our approach also alleviates the need for a VLM in inference,
which is an important cost benefit for deployed QA systems.

</details>


### [126] [PARROT: An Open Multilingual Radiology Reports Dataset](https://arxiv.org/abs/2507.22939)
*Bastien Le Guellec,Kokou Adambounou,Lisa C Adams,Thibault Agripnidis,Sung Soo Ahn,Radhia Ait Chalal,Tugba Akinci D Antonoli,Philippe Amouyel,Henrik Andersson,Raphael Bentegeac,Claudio Benzoni,Antonino Andrea Blandino,Felix Busch,Elif Can,Riccardo Cau,Armando Ugo Cavallo,Christelle Chavihot,Erwin Chiquete,Renato Cuocolo,Eugen Divjak,Gordana Ivanac,Barbara Dziadkowiec Macek,Armel Elogne,Salvatore Claudio Fanni,Carlos Ferrarotti,Claudia Fossataro,Federica Fossataro,Katarzyna Fulek,Michal Fulek,Pawel Gac,Martyna Gachowska,Ignacio Garcia Juarez,Marco Gatti,Natalia Gorelik,Alexia Maria Goulianou,Aghiles Hamroun,Nicolas Herinirina,Krzysztof Kraik,Dominik Krupka,Quentin Holay,Felipe Kitamura,Michail E Klontzas,Anna Kompanowska,Rafal Kompanowski,Alexandre Lefevre,Tristan Lemke,Maximilian Lindholz,Lukas Muller,Piotr Macek,Marcus Makowski,Luigi Mannacio,Aymen Meddeb,Antonio Natale,Beatrice Nguema Edzang,Adriana Ojeda,Yae Won Park,Federica Piccione,Andrea Ponsiglione,Malgorzata Poreba,Rafal Poreba,Philipp Prucker,Jean Pierre Pruvo,Rosa Alba Pugliesi,Feno Hasina Rabemanorintsoa,Vasileios Rafailidis,Katarzyna Resler,Jan Rotkegel,Luca Saba,Ezann Siebert,Arnaldo Stanzione,Ali Fuat Tekin,Liz Toapanta Yanchapaxi,Matthaios Triantafyllou,Ekaterini Tsaoulia,Evangelia Vassalou,Federica Vernuccio,Johan Wasselius,Weilang Wang,Szymon Urban,Adrian Wlodarczak,Szymon Wlodarczak,Andrzej Wysocki,Lina Xu,Tomasz Zatonski,Shuhang Zhang,Sebastian Ziegelmayer,Gregory Kuchcinski,Keno K Bressem*

Main category: cs.CL

TL;DR: 开发了一个名为 PARROT 的大型多语言放射学报告数据集，并进行了一项研究，发现人类（尤其是放射科医生）在区分人工智能生成的报告方面比随机猜测好不了多少。


<details>
  <summary>Details</summary>
Motivation: 为了开发和验证 PARROT（Polyglottal Annotated Radiology Reports for Open Testing），一个大型、多中心、开放访问的虚构放射学报告数据集，涵盖多种语言，用于放射学中的自然语言处理应用程序测试。

Method: 招募了放射科医生，要求他们提供虚构的放射学报告（包括英文翻译），并附带相关的元数据（如解剖区域、影像模式、临床背景）。所有报告均分配了 ICD-10 编码。然后进行了一项人类与人工智能报告区分研究，有 154 名参与者（包括放射科医生、医疗保健专业人员和非医疗保健专业人员）评估报告是由人类还是人工智能生成的。

Result: 该数据集包含来自 21 个国家/地区的 76 位作者的 2,658 份放射学报告，涵盖 13 种语言。报告涵盖多种影像模式（CT：36.1%，MRI：22.8%，X 光摄影：19.0%，超声：16.8%）和解剖区域。在区分研究中，参与者在区分人类和人工智能生成的报告方面的准确率为 53.9%，其中放射科医生表现明显优于其他组（56.9%）。

Conclusion: PARROT 是最大的开放多语言放射学报告数据集，能够跨越语言、地理和临床界限，在没有隐私限制的情况下开发和验证自然语言处理应用程序。

Abstract: Rationale and Objectives: To develop and validate PARROT (Polyglottal
Annotated Radiology Reports for Open Testing), a large, multicentric,
open-access dataset of fictional radiology reports spanning multiple languages
for testing natural language processing applications in radiology. Materials
and Methods: From May to September 2024, radiologists were invited to
contribute fictional radiology reports following their standard reporting
practices. Contributors provided at least 20 reports with associated metadata
including anatomical region, imaging modality, clinical context, and for
non-English reports, English translations. All reports were assigned ICD-10
codes. A human vs. AI report differentiation study was conducted with 154
participants (radiologists, healthcare professionals, and non-healthcare
professionals) assessing whether reports were human-authored or AI-generated.
Results: The dataset comprises 2,658 radiology reports from 76 authors across
21 countries and 13 languages. Reports cover multiple imaging modalities (CT:
36.1%, MRI: 22.8%, radiography: 19.0%, ultrasound: 16.8%) and anatomical
regions, with chest (19.9%), abdomen (18.6%), head (17.3%), and pelvis (14.1%)
being most prevalent. In the differentiation study, participants achieved 53.9%
accuracy (95% CI: 50.7%-57.1%) in distinguishing between human and AI-generated
reports, with radiologists performing significantly better (56.9%, 95% CI:
53.3%-60.6%, p<0.05) than other groups. Conclusion: PARROT represents the
largest open multilingual radiology report dataset, enabling development and
validation of natural language processing applications across linguistic,
geographic, and clinical boundaries without privacy constraints.

</details>


### [127] [Trustworthy Reasoning: Evaluating and Enhancing Factual Accuracy in LLM Intermediate Thought Processes](https://arxiv.org/abs/2507.22940)
*Rui Jiao,Yue Zhang,Jinku Li*

Main category: cs.CL

TL;DR: 提出RELIANCE框架，通过事实核查、强化学习和可解释性模块，大幅提高LLM推理过程中的事实准确性，解决了现有模型易在中间步骤出错的问题。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）在推理过程中的中间步骤存在事实错误但最终答案可能正确的问题，这种现象在高风险领域（如医疗、法律、科研）可能误导用户。

Method: 提出名为RELIANCE的框架，包含三个核心组件：1) 专门的事实核查分类器，用于检测推理链中的事实不一致性；2) 结合事实性、连贯性和结构正确性的GRPO强化学习方法；3) 机制可解释性模块，用于分析事实性提升如何影响模型激活。

Result: 在包括Math-500、AIME-2024和GPQA在内的基准测试中，RELIANCE框架显著提高了推理事实的准确性（最高提升49.90%），同时保持或提升了模型性能。即使是Claude-3.7和GPT-o1等领先模型，其推理事实准确率也仅为81.93%和82.57%。

Conclusion: RELIANCE框架通过结合事实核查分类器、GRPO强化学习方法和机制可解释性模块，显著提升了LLM的推理事实准确性，并为未来的模型训练提供了新方向。

Abstract: We present RELIANCE (Reasoning Evaluation with Logical Integrity and Accuracy
for Confidence Enhancement), a novel framework addressing a critical
vulnerability in Large Language Models (LLMs): the prevalence of factual
inaccuracies within intermediate reasoning steps despite correct final answers.
This phenomenon poses substantial risks in high-stakes domains including
healthcare, legal analysis, and scientific research, where erroneous yet
confidently presented reasoning can mislead users into dangerous decisions. Our
framework integrates three core components: (1) a specialized fact-checking
classifier trained on counterfactually augmented data to detect subtle factual
inconsistencies within reasoning chains; (2) a Group Relative Policy
Optimization (GRPO) reinforcement learning approach that balances factuality,
coherence, and structural correctness through multi-dimensional rewards; and
(3) a mechanistic interpretability module examining how factuality improvements
manifest in model activations during reasoning processes. Extensive evaluation
across ten state-of-the-art models reveals concerning patterns: even leading
models like Claude-3.7 and GPT-o1 demonstrate reasoning factual accuracy of
only 81.93% and 82.57% respectively. RELIANCE significantly enhances factual
robustness (up to 49.90% improvement) while maintaining or improving
performance on challenging benchmarks including Math-500, AIME-2024, and GPQA.
Furthermore, our activation-level analysis provides actionable insights into
how factual enhancements reshape reasoning trajectories within model
architectures, establishing foundations for future training methodologies that
explicitly target factual robustness through activation-guided optimization.

</details>


### [128] [SigBERT: Combining Narrative Medical Reports and Rough Path Signature Theory for Survival Risk Estimation in Oncology](https://arxiv.org/abs/2507.22941)
*Paul Minchella,Loïc Verlingue,Stéphane Chrétien,Rémi Vaucher,Guillaume Metzler*

Main category: cs.CL

TL;DR: SigBERT是一个创新的时间生存分析框架，它利用粗糙路径理论中的签名提取来从序列化医疗报告中捕获时间动态，从而提高生存模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的生存分析方法在有效处理文本数据的复杂性（尤其是其序列形式）方面常常遇到困难。本研究旨在解决这一挑战，以更有效地利用电子健康记录（EHR）中的丰富信息。

Method: SigBERT处理带有时间戳的医疗报告，通过提取和平均词嵌入到句子嵌入中。为了从句子嵌入坐标的时间序列中捕获时间动态，我们从粗糙路径理论中应用签名提取，为每位患者提取几何特征。然后，将这些特征整合到LASSO惩罚的Cox模型中，以估计患者特异性风险评分。

Result: 在从 L'eon B'erard 中心语料库获得的真实世界肿瘤学数据集上对模型进行了训练和评估，在独立的测试队列中获得了 0.75（标准差 0.014）的 C 指数得分。

Conclusion: SigBERT集成了序贯医疗数据以增强风险估计，推进了基于叙述的生存分析。

Abstract: Electronic medical reports (EHR) contain a vast amount of information that
can be leveraged for machine learning applications in healthcare. However,
existing survival analysis methods often struggle to effectively handle the
complexity of textual data, particularly in its sequential form. Here, we
propose SigBERT, an innovative temporal survival analysis framework designed to
efficiently process a large number of clinical reports per patient. SigBERT
processes timestamped medical reports by extracting and averaging word
embeddings into sentence embeddings. To capture temporal dynamics from the time
series of sentence embedding coordinates, we apply signature extraction from
rough path theory to derive geometric features for each patient, which
significantly enhance survival model performance by capturing complex temporal
dynamics. These features are then integrated into a LASSO-penalized Cox model
to estimate patient-specific risk scores. The model was trained and evaluated
on a real-world oncology dataset from the L\'eon B\'erard Center corpus, with a
C-index score of 0.75 (sd 0.014) on the independent test cohort. SigBERT
integrates sequential medical data to enhance risk estimation, advancing
narrative-based survival analysis.

</details>


### [129] [A chart review process aided by natural language processing and multi-wave adaptive sampling to expedite validation of code-based algorithms for large database studies](https://arxiv.org/abs/2507.22943)
*Shirley V Wang,Georg Hahn,Sushama Kattinakere Sreedhara,Mufaddal Mahesri,Haritha S. Pillai,Rajendra Aldis,Joyce Lii,Sarah K. Dutcher,Rhoda Eniafe,Jamal T. Jones,Keewan Kim,Jiwei He,Hana Lee,Sengwee Toh,Rishi J Desai,Jie Yang*

Main category: cs.CL

TL;DR: 一种通过使用自然语言处理（NLP）和多波自适应采样方法来加速验证索赔数据库中算法性能的过程。


<details>
  <summary>Details</summary>
Motivation: 为了提高对大型索赔数据库进行的分析的准确性，需要验证用于识别健康结果或其他关键研究参数的代码算法的测量特征。

Method: 描述了一种通过两种不同机制提高验证研究效率的流程：1）使用自然语言处理（NLP）来减少人工审阅者审阅每份图表所花费的时间，以及 2）使用预定标准的多波自适应采样方法，一旦以足够的精度识别出性能特征就停止验证研究。

Result: NLP辅助标注过程将每份图表的审阅时间减少了40%，并且使用具有多波样本的预定停止规则本可以防止审阅77%的患者图表，而对导出的测量特征的精度的影响却很小。

Conclusion: 该方法可以促进对用于定义关键研究参数的代码算法进行更常规的验证，最终增强对数据库研究结果可靠性的理解。

Abstract: Background: One of the ways to enhance analyses conducted with large claims
databases is by validating the measurement characteristics of code-based
algorithms used to identify health outcomes or other key study parameters of
interest. These metrics can be used in quantitative bias analyses to assess the
robustness of results for an inferential study given potential bias from
outcome misclassification. However, extensive time and resource allocation are
typically re-quired to create reference-standard labels through manual chart
review of free-text notes from linked electronic health records. Methods: We
describe an expedited process that introduces efficiency in a validation study
us-ing two distinct mechanisms: 1) use of natural language processing (NLP) to
reduce time spent by human reviewers to review each chart, and 2) a multi-wave
adaptive sampling approach with pre-defined criteria to stop the validation
study once performance characteristics are identified with sufficient
precision. We illustrate this process in a case study that validates the
performance of a claims-based outcome algorithm for intentional self-harm in
patients with obesity. Results: We empirically demonstrate that the
NLP-assisted annotation process reduced the time spent on review per chart by
40% and use of the pre-defined stopping rule with multi-wave samples would have
prevented review of 77% of patient charts with limited compromise to precision
in derived measurement characteristics. Conclusion: This approach could
facilitate more routine validation of code-based algorithms used to define key
study parameters, ultimately enhancing understanding of the reliability of
find-ings derived from database studies.

</details>


### [130] [Opacity as Authority: Arbitrariness and the Preclusion of Contestation](https://arxiv.org/abs/2507.22944)
*Naomi Omeonga wa Kayembe*

Main category: cs.CL

TL;DR: 本文将任意性定义为一种功能机制，而非缺陷，并提出一个新框架来分析其在人类系统（包括法律、社会和AI）中的作用。


<details>
  <summary>Details</summary>
Motivation: 本文旨在重新定义任意性，将其从规范性缺陷或统治的症状，转变为理解人类系统和互动的关键功能机制，并探讨其在法律、社会动态和人工智能领域中的应用。

Method: 通过将任意性视为一种符号学特征，并引入“动机 -> 可确认性 -> 可争论性”链条，结合香农的熵模型（A = H(L|M)）来形式化任意性，以分析其在法律、社会动态和人工智能系统中的作用。

Result: 本文认为，任意性作为一种结构不透明性，是保护权威免受问责的故意设计，并且可以作为控制和关怀的中立操作符，为分析人工智能系统的可解释性提供了新途径。

Conclusion: 本文提出一种将任意性视为人类系统的基础功能机制的现代理论，并将其应用于分析法律、社会动态和人工智能系统中的可解释性。

Abstract: This article redefines arbitrariness not as a normative flaw or a symptom of
domination, but as a foundational functional mechanism structuring human
systems and interactions. Diverging from critical traditions that conflate
arbitrariness with injustice, it posits arbitrariness as a semiotic trait: a
property enabling systems - linguistic, legal, or social - to operate
effectively while withholding their internal rationale. Building on Ferdinand
de Saussure's concept of l'arbitraire du signe, the analysis extends this
principle beyond language to demonstrate its cross-domain applicability,
particularly in law and social dynamics. The paper introduces the "Motivation
-> Constatability -> Contestability" chain, arguing that motivation functions
as a crucial interface rendering an act's logic vulnerable to intersubjective
contestation. When this chain is broken through mechanisms like
"immotivization" or "Conflict Lateralization" (exemplified by "the blur of the
wolf drowned in the fish"), acts produce binding effects without exposing their
rationale, thus precluding justiciability. This structural opacity, while
appearing illogical, is a deliberate design protecting authority from
accountability. Drawing on Shannon's entropy model, the paper formalizes
arbitrariness as A = H(L|M) (conditional entropy). It thereby proposes a modern
theory of arbitrariness as a neutral operator central to control as well as
care, an overlooked dimension of interpersonal relations. While primarily
developed through human social systems, this framework also illuminates a new
pathway for analyzing explainability in advanced artificial intelligence
systems.

</details>


### [131] [C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring Challenges in Complex Conversations](https://arxiv.org/abs/2507.22968)
*Chengqian Ma,Wei Tao,Yiwen Guo*

Main category: cs.CL

TL;DR: 本文提出了一个包含英汉对话数据的基准数据集和一套LLM评估方法，用于衡量口语对话模型在理解和模仿人类对话方面的能力，特别是针对语音对话的歧义性和上下文依赖性等挑战。


<details>
  <summary>Details</summary>
Motivation: 为了全面理解和评估口语对话模型（SDM）在理解和模仿人类对话方面的实际效果，弥补其在基准测试方面相较于文本模型（LLM）的不足，并解决语音对话中固有的歧义性和上下文依赖性等复杂性。

Method: 提出了一种包含1079个英汉实例的基准数据集，并设计了一种与人类判断高度一致的LLM评估方法。

Result: 构建了一个包含1079个英汉实例的基准数据集，并开发了一种LLM评估方法，能够较好地模拟人类的判断，用于评估SDM在处理实际对话挑战方面的性能。

Conclusion: 本文提出了一种包含1079个英汉实例的基准数据集，并结合了与人类判断高度一致的基于LLM的评估方法，旨在全面探索SDM在应对语音对话中的歧义性和上下文依赖性等实际挑战方面的表现。

Abstract: Spoken Dialogue Models (SDMs) have recently attracted significant attention
for their ability to generate voice responses directly to users' spoken
queries. Despite their increasing popularity, there exists a gap in research
focused on comprehensively understanding their practical effectiveness in
comprehending and emulating human conversations. This is especially true
compared to text-based Large Language Models (LLMs), which benefit from
extensive benchmarking. Human voice interactions are inherently more complex
than text due to characteristics unique to spoken dialogue. Ambiguity poses one
challenge, stemming from semantic factors like polysemy, as well as
phonological aspects such as heterograph, heteronyms, and stress patterns.
Additionally, context-dependency, like omission, coreference, and multi-turn
interaction, adds further complexity to human conversational dynamics. To
illuminate the current state of SDM development and to address these
challenges, we present a benchmark dataset in this paper, which comprises 1,079
instances in English and Chinese. Accompanied by an LLM-based evaluation method
that closely aligns with human judgment, this dataset facilitates a
comprehensive exploration of the performance of SDMs in tackling these
practical challenges.

</details>


### [132] [Math Natural Language Inference: this should be easy!](https://arxiv.org/abs/2507.23063)
*Valeria de Paiva,Qiyue Gao,Hai Hu,Pavel Kovalev,Yikang Liu,Lawrence S. Moss,Zhiheng Qian*

Main category: cs.CL

TL;DR: LLM在数学文本NLI任务上表现不佳，但多数投票机制有潜力。LLM在理解数学语言和基本推断方面仍需改进。


<details>
  <summary>Details</summary>
Motivation: 探究当代大型语言模型（LLM）在处理数学文本的自然语言推断（NLI）任务上的能力。

Method: 构建了一个包含数学文本的Math NLI语料库，并使用具有数学和NLI领域经验的人员进行标注。同时，也使用了LLM生成的假设来评估语料库质量。研究了LLM在Math NLI任务上的表现和跨模型一致性。

Result: LLM在数学语言理解和基本推断方面仍存在困难，但多数投票机制在某些设置下表现接近人类水平。新一代LLM在假设驱动的“推断”方面比上一代有所改善。

Conclusion: LLM在数学文本上的自然语言推断（NLI）任务表现不佳，尤其是在处理数学语言和进行基本推断时。然而，在某些情况下，LLM的多数投票结果可以接近于人类标注数据。

Abstract: We ask whether contemporary LLMs are able to perform natural language
inference (NLI) tasks on mathematical texts. We call this the Math NLI problem.
We construct a corpus of Math NLI pairs whose premises are from extant
mathematical text and whose hypotheses and gold labels were provided by people
with experience in both research-level mathematics and also in the NLI field.
We also investigate the quality of corpora using the same premises but whose
hypotheses are provided by LLMs themselves. We not only investigate the
performance but also the inter-group consistency of the diverse group of LLMs.
We have both positive and negative findings. Among our positive findings: in
some settings, using a majority vote of LLMs is approximately equivalent to
using human-labeled data in the Math NLI area. On the negative side: LLMs still
struggle with mathematical language. They occasionally fail at even basic
inferences. Current models are not as prone to hypothesis-only "inference" in
our data the way the previous generation had been. In addition to our findings,
we also provide our corpora as data to support future work on Math NLI.

</details>


### [133] [Exploring In-Context Learning for Frame-Semantic Parsing](https://arxiv.org/abs/2507.23082)
*Diego Garat,Guillermo Moncecchi,Dina Wonsever*

Main category: cs.CL

TL;DR: This paper explores using LLMs with in-context learning for Frame Semantic Parsing, achieving strong results without fine-tuning by generating specific prompts from the FrameNet database.


<details>
  <summary>Details</summary>
Motivation: Investigate the use of In-Context Learning (ICL) with Large Language Models (LLMs) to perform Frame Semantic Parsing (FSP) without model fine-tuning.

Method: This paper proposes a method that automatically generates task-specific prompts for Frame Identification (FI) and Frame Semantic Role Labeling (FSRL) subtasks using only the FrameNet database. These prompts, built from frame definitions and annotated examples, are used to guide six different LLMs. Experiments were conducted on a subset of frames related to violent events.

Result: The method achieves competitive results, with F1 scores of 94.3% for FI and 77.4% for FSRL.

Conclusion: In-context learning (ICL) with large language models (LLMs) offers a practical and effective alternative to traditional fine-tuning for domain-specific Frame Semantic Parsing (FSP) tasks.

Abstract: Frame Semantic Parsing (FSP) entails identifying predicates and labeling
their arguments according to Frame Semantics. This paper investigates the use
of In-Context Learning (ICL) with Large Language Models (LLMs) to perform FSP
without model fine-tuning. We propose a method that automatically generates
task-specific prompts for the Frame Identification (FI) and Frame Semantic Role
Labeling (FSRL) subtasks, relying solely on the FrameNet database. These
prompts, constructed from frame definitions and annotated examples, are used to
guide six different LLMs. Experiments are conducted on a subset of frames
related to violent events. The method achieves competitive results, with F1
scores of 94.3% for FI and 77.4% for FSRL. The findings suggest that ICL offers
a practical and effective alternative to traditional fine-tuning for
domain-specific FSP tasks.

</details>


### [134] [Context-aware Rotary Position Embedding](https://arxiv.org/abs/2507.23083)
*Ali Veisi,Delaram Fartoot,Hamidreza Amirzadeh*

Main category: cs.CL

TL;DR: CARoPE是一种新的上下文感知旋转位置嵌入方法，它通过动态调整位置编码来提高Transformer处理长序列的能力，并在实验中表现出更好的性能和训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有的旋转位置嵌入（RoPE）依赖于静态的、与输入无关的正弦频率模式，这限制了其对上下文敏感关系建模的能力。

Method: 提出了一种名为CARoPE（Context-Aware Rotary Positional Embedding）的旋转位置嵌入新方法，它通过动态生成与token嵌入条件相关的、针对不同注意力头的频率模式，实现了上下文感知的位置表示。

Result: 在FineWeb-Edu-10B数据集上的实验表明，CARoPE在GPT-2模型上持续优于RoPE和其他位置编码基线，实现了更低的困惑度，尤其是在更长的上下文长度下。此外，CARoPE在不牺牲模型稳定性的前提下，能够实现更快的训练吞吐量。

Conclusion: CARoPE通过引入依赖于token的动态频率模式，在保持效率和简单性的同时，提高了Transformer模型处理长序列的能力，并在实验中展现出优于RoPE的性能和更快的训练速度。

Abstract: Positional encoding is a vital component of Transformer architectures,
enabling models to incorporate sequence order into self-attention mechanisms.
Rotary Positional Embeddings (RoPE) have become a widely adopted solution due
to their compatibility with relative position encoding and computational
efficiency. However, RoPE relies on static, input-independent sinusoidal
frequency patterns, limiting its ability to model context-sensitive
relationships. In this work, we propose CARoPE (Context-Aware Rotary Positional
Embedding), a novel generalization of RoPE that dynamically generates
head-specific frequency patterns conditioned on token embeddings. This design
introduces token- and context-sensitive positional representations while
preserving RoPE efficiency and architectural simplicity. CARoPE computes
input-dependent phase shifts using a bounded transformation of token embeddings
and integrates them into the rotary mechanism across attention heads. We
evaluate CARoPE on the FineWeb-Edu-10B dataset using GPT-2 variants trained on
next-token prediction tasks. Experimental results show that CARoPE consistently
outperforms RoPE and other common positional encoding baselines, achieving
significantly lower perplexity, even at longer context lengths. Additionally,
CARoPE enables faster training throughput without sacrificing model stability.
These findings demonstrate that CARoPE offers a scalable, expressive, and
efficient upgrade to existing positional encoding strategies in Transformer
models.

</details>


### [135] [SMART-Editor: A Multi-Agent Framework for Human-Like Design Editing with Structural Integrity](https://arxiv.org/abs/2507.23095)
*Ishani Mondal,Meera Bharadwaj,Ayush Roy,Aparna Garimella,Jordan Lee Boyd-Graber*

Main category: cs.CL

TL;DR: SMART-Editor是一个用于跨领域（结构化和非结构化）布局和内容编辑的框架，通过Reward-Refine和RewardDPO策略保持全局一致性，并在SMARTEdit-Bench上取得了优于现有模型的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有模型进行局部编辑时无法保持全局一致性的问题，实现跨结构化和非结构化域的组合式布局和内容编辑。

Method: SMART-Editor使用奖励-精炼（推理时）和奖励DPO（训练时）来优化编辑，并引入了SMARTEdit-Bench基准来评估模型性能。

Result: SMART-Editor在SMARTEdit-Bench上超越了InstructPix2Pix和HIVE等强基线，其中RewardDPO在结构化设置中提升了15%，Reward-Refine在自然图像上表现出优势。

Conclusion: SMART-Editor通过奖励引导的规划在结构化和非结构化域中生成语义一致且视觉对齐的编辑，并在SMARTEdit-Bench上超越了强基线。

Abstract: We present SMART-Editor, a framework for compositional layout and content
editing across structured (posters, websites) and unstructured (natural images)
domains. Unlike prior models that perform local edits, SMART-Editor preserves
global coherence through two strategies: Reward-Refine, an inference-time
rewardguided refinement method, and RewardDPO, a training-time preference
optimization approach using reward-aligned layout pairs. To evaluate model
performance, we introduce SMARTEdit-Bench, a benchmark covering multi-domain,
cascading edit scenarios. SMART-Editor outperforms strong baselines like
InstructPix2Pix and HIVE, with RewardDPO achieving up to 15% gains in
structured settings and Reward-Refine showing advantages on natural images.
Automatic and human evaluations confirm the value of reward-guided planning in
producing semantically consistent and visually aligned edits.

</details>


### [136] [RASL: Retrieval Augmented Schema Linking for Massive Database Text-to-SQL](https://arxiv.org/abs/2507.23104)
*Jeffrey Eben,Aitzaz Ahmad,Stephen Lau*

Main category: cs.CL

TL;DR: 我们提出了一种新的基于组件的检索架构，用于数据库的自然语言接口，它分解元数据、有效识别表并利用列信息，在大型数据库上实现了高精度和可扩展性，无需特定领域微调。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有基于LLM的数据库语言接口在扩展到企业级数据目录时面临的挑战，特别是现有方法依赖于域特定的微调（使部署复杂化）并且未能利用数据库元数据中包含的重要语义上下文的限制。

Method: 提出了一种基于组件的检索架构，将数据库模式和元数据分解为离散的语义单元，并分别进行索引以进行定向检索。该方法优先考虑有效的表识别，同时利用列级信息，确保检索到的表总数保持在可管理的上下文预算内。

Result: 实验证明，该方法在保持高召回率和准确性的同时，在具有不同结构和可用元数据的海量数据库上，其系统性能优于基线方法。

Conclusion: 该方法支持在各种企业环境中的实际text-to-SQL系统部署，无需专门的微调，解决了自然语言数据库接口中的关键可扩展性差距。

Abstract: Despite advances in large language model (LLM)-based natural language
interfaces for databases, scaling to enterprise-level data catalogs remains an
under-explored challenge. Prior works addressing this challenge rely on
domain-specific fine-tuning - complicating deployment - and fail to leverage
important semantic context contained within database metadata. To address these
limitations, we introduce a component-based retrieval architecture that
decomposes database schemas and metadata into discrete semantic units, each
separately indexed for targeted retrieval. Our approach prioritizes effective
table identification while leveraging column-level information, ensuring the
total number of retrieved tables remains within a manageable context budget.
Experiments demonstrate that our method maintains high recall and accuracy,
with our system outperforming baselines over massive databases with varying
structure and available metadata. Our solution enables practical text-to-SQL
systems deployable across diverse enterprise settings without specialized
fine-tuning, addressing a critical scalability gap in natural language database
interfaces.

</details>


### [137] [Uncovering the Fragility of Trustworthy LLMs through Chinese Textual Ambiguity](https://arxiv.org/abs/2507.23121)
*Xinwei Wu,Haojie Li,Hongyu Liu,Xinyu Ji,Ruohan Li,Yule Chen,Yigeng Zhang*

Main category: cs.CL

TL;DR: 本研究创建了一个中文歧义文本数据集，发现LLM在处理歧义时表现脆弱，与人类行为不同，这表明LLM在理解不确定性方面存在局限。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在处理歧义（特别关注中文文本歧义）时的行为，以解决LLM的可信度问题。

Method: 创建了一个包含歧义句子及其对应消歧对的基准数据集，这些样本被系统地分为3个主要类别和9个子类别。

Result: LLM在处理歧义时存在显著的脆弱性，不能可靠地区分歧义文本，对歧义的解释表现出过度自信，并倾向于过度思考。

Conclusion: LLM在处理歧义文本时表现出显著的脆弱性，与人类行为存在巨大差异，无法可靠地区分歧义文本，在解释歧义时表现出过度自信，并可能过度思考。这揭示了当前LLM在理解不确定性方面的根本性局限，对在实际应用中的部署具有重要意义。

Abstract: In this work, we study a critical research problem regarding the
trustworthiness of large language models (LLMs): how LLMs behave when
encountering ambiguous narrative text, with a particular focus on Chinese
textual ambiguity. We created a benchmark dataset by collecting and generating
ambiguous sentences with context and their corresponding disambiguated pairs,
representing multiple possible interpretations. These annotated examples are
systematically categorized into 3 main categories and 9 subcategories. Through
experiments, we discovered significant fragility in LLMs when handling
ambiguity, revealing behavior that differs substantially from humans.
Specifically, LLMs cannot reliably distinguish ambiguous text from unambiguous
text, show overconfidence in interpreting ambiguous text as having a single
meaning rather than multiple meanings, and exhibit overthinking when attempting
to understand the various possible meanings. Our findings highlight a
fundamental limitation in current LLMs that has significant implications for
their deployment in real-world applications where linguistic ambiguity is
common, calling for improved approaches to handle uncertainty in language
understanding. The dataset and code are publicly available at this GitHub
repository: https://github.com/ictup/LLM-Chinese-Textual-Disambiguation.

</details>


### [138] [ISO-Bench: Benchmarking Multimodal Causal Reasoning in Visual-Language Models through Procedural Plans](https://arxiv.org/abs/2507.23135)
*Ananya Sadana,Yash Kumar Lal,Jiawei Zhou*

Main category: cs.CL

TL;DR: ISO-Bench 基准评估多模态因果关系，现有模型表现欠佳。


<details>
  <summary>Details</summary>
Motivation: 解决多模态模型在现实环境中理解跨模态因果关系的核心挑战。

Method: 提出 ISO-Bench 基准，通过图像和文本片段的因果判断来评估模型。

Result: 在十个前沿视觉-语言模型上的评估结果不理想，最佳零样本 F1 仅为 0.57，思维链推理仅提升至 0.62 F1，远低于人类的 0.98 F1。

Conclusion: ISO-Bench 评估了模型在视觉观察和程序化文本之间推断因果关系的能力，结果显示当前模型表现不佳，但指出了改进方向。

Abstract: Understanding causal relationships across modalities is a core challenge for
multimodal models operating in real-world environments. We introduce ISO-Bench,
a benchmark for evaluating whether models can infer causal dependencies between
visual observations and procedural text. Each example presents an image of a
task step and a text snippet from a plan, with the goal of deciding whether the
visual step occurs before or after the referenced text step. Evaluation results
on ten frontier vision-language models show underwhelming performance: the best
zero-shot F1 is only 0.57, and chain-of-thought reasoning yields only modest
gains (up to 0.62 F1), largely behind humans (0.98 F1). Our analysis further
highlights concrete directions for improving causal understanding in multimodal
models.

</details>


### [139] [User Feedback in Human-LLM Dialogues: A Lens to Understand Users But Noisy as a Learning Signal](https://arxiv.org/abs/2507.23158)
*Yuhan Liu,Michael J. Q. Zhang,Eunsol Choi*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Once language models (LMs) are deployed, they can interact with users
long-term, ideally evolving continuously based on their feedback. Asking for
direct user feedback can be disruptive; thus, we study harvesting user feedback
from user-LM interaction logs. We study implicit user feedback in two user-LM
interaction datasets (WildChat and LMSYS). First, we analyze user feedback in
the user-LLM conversation trajectory, providing insights into when and why such
feedback occurs. Second, we study harvesting learning signals from such
implicit user feedback. We find that the contents of user feedback (e.g., user
wanted clarification), not just the polarity (e.g., users were unhappy with the
previous model response), can improve model performance in short human-designed
questions (MTBench) but not on longer and more complex questions (WildBench).
We also find that the usefulness of user feedback is largely tied to the
quality of the user's initial prompt. Together, we provide an in-depth study of
implicit user feedback, showing its potential and limitations.

</details>


### [140] [Geak: Introducing Triton Kernel AI Agent & Evaluation Benchmarks](https://arxiv.org/abs/2507.23194)
*Jianghui Wang,Vinay Joshi,Saptarshi Majumder,Xu Chao,Bin Ding,Ziqiong Liu,Pratik Prabhanjan Brahma,Dong Li,Zicheng Liu,Emad Barsoum*

Main category: cs.CL

TL;DR: GEAK是一个LLM驱动的框架，可以为AMD GPU生成高性能Triton内核，其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了满足行业和学术界对可扩展、硬件优化解决方案的需求，以及应对日益复杂的深度学习工作负载，需要自动化低级内核开发，以满足性能和生产力要求。

Method: GEAK是一个利用前沿LLM生成高性能Triton代码的框架，特别针对AMD GPU（包括MI300X和MI250）。GEAK利用推理时计算扩展，通过Adapted from Reflexion风格的反馈机制中的推理循环来生成基于Triton的GPU内核。

Result: 在两个评估基准上，GEAK的正确性最高达到63%，执行速度提升最高达到2.59倍，显著优于直接提示前沿LLM以及基于Reflexion的生成管道。

Conclusion: GEAK等代理式代码生成技术有望加速多样化硬件平台的采用，并普及专家级内核性能的访问。

Abstract: The demand for AI-generated GPU kernels is rapidly growing, influenced by the
need for scalable, hardware-optimized solutions in both industry and academia.
As deep learning workloads grow in complexity and diversity, it is imperative
to automate low-level kernel development to meet performance and productivity
demands. Major cloud providers, semiconductor companies, and research
institutions are now investing heavily in AI-driven code generation for GPUs,
aiming to reduce manual optimization efforts while achieving near-expert
performance on hardware like AMD MI300X. The Triton language, a Python-based
DSL for GPU programming, has emerged as a popular target for such AI-generated
kernels due to its balance of performance and ease-of-coding. In this work, we
present an evaluation suite for Triton-based GPU kernels and GEAK (Generating
Efficient AI-centric GPU Kernels)-a framework that leverages cutting-edge LLMs
to generate performant Triton code specifically for AMD GPUs, including the AMD
MI300X and MI250. GEAK leverages inference-time compute scaling to produce
Triton-based GPU kernels using a reasoning loop adapted from Reflexion-style
feedback mechanisms. On two evaluation benchmarks, GEAK significantly
outperformed the baselines of directly prompting frontier LLMs as well as
Reflexion-based generation pipelines by achieving correctness up to $63$% and
execution speed up of up to $2.59$X. These results highlight the promise of
GEAK-like agentic code generation for accelerating the adoption of diverse
hardware platforms and democratizing access to expert-level kernel performance.

</details>


### [141] [Failures Are the Stepping Stones to Success: Enhancing Few-Shot In-Context Learning by Leveraging Negative Samples](https://arxiv.org/abs/2507.23211)
*Yunhao Liang,Ruixuan Ying,Takuya Taniguchi,Zhe Cui*

Main category: cs.CL

TL;DR: 本研究提出了一种利用负样本来改进正样本选择的新方法，以增强大语言模型少样本在情境学习（ICL）任务上的表现。实验证明，该方法优于仅使用正样本的方法，表明负样本信息有助于提升ICL性能。


<details>
  <summary>Details</summary>
Motivation: 现有的检索式ICL研究主要关注正样本，而忽略了负样本在情境学习中包含的额外信息。本研究旨在利用负样本来改善正样本的选择，以增强ICL的表现。

Method: 提出了一种新颖的方法，该方法利用负样本来选择正样本示例，以增强少样本ICL的表现。首先，基于Zero-Shot-Cot构建正负样本语料库。然后在推理时，采用基于语义相似度的方法，为给定的查询从正负样本语料库中选择最相似的示例。随后，基于查询与负样本的语义相似度，从正样本语料库中检索正样本，并将其与先前选择的正样本合并，作为ICL演示。

Result: 实验结果表明，所提出的方法在ICL表现上优于仅依赖最相似正样本的方法，证明了负样本的额外信息通过改善正样本选择有助于提升ICL的表现。

Conclusion: 通过利用负样本来选择更优的正样本，能够提升大语言模型少样本在情境学习（ICL）任务上的表现，验证了负样本中包含的额外信息有助于改善正样本的选择。

Abstract: Large Language Models exhibit powerful few-shot in-context learning (ICL)
capabilities, but the performance is highly sensitive to provided examples.
  Recent research has focused on retrieving corresponding examples for each
input query, not only enhancing the efficiency and scalability of the learning
process but also mitigating inherent biases in manual example selection.
  However, these studies have primarily emphasized leveraging Positive samples
while overlooking the additional information within Negative samples for
contextual learning.
  We propose a novel method that utilizes Negative samples to better select
Positive sample examples, thereby enhancing the performance of few-shot ICL.
Initially, we construct Positive and Negative sample corpora based on
Zero-Shot-Cot. Then, during inference, we employ a semantic similarity-based
approach to select the most similar examples from both the Positive and
Negative corpora for a given query. Subsequently, we further retrieve Positive
examples from the Positive sample corpus based on semantic similarity to the
Negative examples, then concatenating them with the previously selected
Positive examples to serve as ICL demonstrations. Experimental results
demonstrate that our approach surpasses methods solely relying on the most
similar positive examples for context, validating that the additional
information in negative samples aids in enhancing ICL performance through
improved Positive sample selection.

</details>


### [142] [Model Directions, Not Words: Mechanistic Topic Models Using Sparse Autoencoders](https://arxiv.org/abs/2507.23220)
*Carolina Zheng,Nicolas Beltran-Velez,Sweta Karlekar,Claudia Shi,Achille Nazaret,Asif Mallik,Amir Feder,David M. Blei*

Main category: cs.CL

TL;DR: Mechanistic Topic Models (MTMs) use interpretable features from sparse autoencoders to uncover deeper conceptual themes, overcoming limitations of bag-of-words models. MTMs enable controllable text generation and are preferred over baselines in evaluations using a novel LLM-based framework called topic judge.


<details>
  <summary>Details</summary>
Motivation: Traditional topic models struggle to capture semantically abstract features due to their reliance on bag-of-words representations. Neural variants are similarly constrained by expressing topics as word lists, limiting their ability to articulate complex topics.

Method: MTMs operate on interpretable features learned by sparse autoencoders (SAEs). Topics are defined over this semantically rich space. An LLM-based pairwise comparison evaluation framework, topic judge, is proposed to evaluate MTM topics against word-list-based approaches.

Result: MTMs reveal deeper conceptual themes with expressive feature descriptions. MTMs enable controllable text generation using topic-based steering vectors. Across five datasets, MTMs match or exceed traditional and neural baselines on coherence metrics, are consistently preferred by topic judge, and enable effective steering of LLM outputs.

Conclusion: MTMs matches or exceeds traditional and neural baselines on coherence metrics, are consistently preferred by topic judge, and enable effective steering of LLM outputs.

Abstract: Traditional topic models are effective at uncovering latent themes in large
text collections. However, due to their reliance on bag-of-words
representations, they struggle to capture semantically abstract features. While
some neural variants use richer representations, they are similarly constrained
by expressing topics as word lists, which limits their ability to articulate
complex topics. We introduce Mechanistic Topic Models (MTMs), a class of topic
models that operate on interpretable features learned by sparse autoencoders
(SAEs). By defining topics over this semantically rich space, MTMs can reveal
deeper conceptual themes with expressive feature descriptions. Moreover,
uniquely among topic models, MTMs enable controllable text generation using
topic-based steering vectors. To properly evaluate MTM topics against
word-list-based approaches, we propose \textit{topic judge}, an LLM-based
pairwise comparison evaluation framework. Across five datasets, MTMs match or
exceed traditional and neural baselines on coherence metrics, are consistently
preferred by topic judge, and enable effective steering of LLM outputs.

</details>


### [143] [Enabling Few-Shot Alzheimer's Disease Diagnosis on Tabular Biomarker Data with LLMs](https://arxiv.org/abs/2507.23227)
*Sophie Kearney,Shu Yang,Zixuan Wen,Bojian Hou,Duy Duong-Tran,Tianlong Chen,Jason Moore,Marylyn Ritchie,Li Shen*

Main category: cs.CL

TL;DR: TAP-GPT是一个新框架，它利用LLM来诊断阿尔茨海默病，通过微调TableGPT2并使用少样本表格提示，在处理结构化生物标志物数据时表现出色。


<details>
  <summary>Details</summary>
Motivation: 早期、准确地诊断阿尔茨海默病（AD）需要分析通常以表格形式表示的异构生物标志物，而大型语言模型（LLMs）在处理结构化生物医学数据方面具有巨大潜力。

Method: TAP-GPT框架通过构建包含来自结构化生物医学数据的上下文学习示例的少样本表格提示，并使用参数高效的qLoRA适配对TableGPT2进行微调，以用于AD或认知正常（CN）的临床二元分类任务。

Result: TAP-GPT框架在AD诊断的预测任务中，其表现优于更先进的通用LLMs和为预测任务开发的表格基础模型（TFM）。

Conclusion: TAP-GPT框架在阿尔茨海默病诊断方面表现优于其他先进模型，为生物医学信息学中LLM驱动的多主体框架奠定了基础。

Abstract: Early and accurate diagnosis of Alzheimer's disease (AD), a complex
neurodegenerative disorder, requires analysis of heterogeneous biomarkers
(e.g., neuroimaging, genetic risk factors, cognitive tests, and cerebrospinal
fluid proteins) typically represented in a tabular format. With flexible
few-shot reasoning, multimodal integration, and natural-language-based
interpretability, large language models (LLMs) offer unprecedented
opportunities for prediction with structured biomedical data. We propose a
novel framework called TAP-GPT, Tabular Alzheimer's Prediction GPT, that adapts
TableGPT2, a multimodal tabular-specialized LLM originally developed for
business intelligence tasks, for AD diagnosis using structured biomarker data
with small sample sizes. Our approach constructs few-shot tabular prompts using
in-context learning examples from structured biomedical data and finetunes
TableGPT2 using the parameter-efficient qLoRA adaption for a clinical binary
classification task of AD or cognitively normal (CN). The TAP-GPT framework
harnesses the powerful tabular understanding ability of TableGPT2 and the
encoded prior knowledge of LLMs to outperform more advanced general-purpose
LLMs and a tabular foundation model (TFM) developed for prediction tasks. To
our knowledge, this is the first application of LLMs to the prediction task
using tabular biomarker data, paving the way for future LLM-driven multi-agent
frameworks in biomedical informatics.

</details>


### [144] [P-ReMIS: Pragmatic Reasoning in Mental Health and a Social Implication](https://arxiv.org/abs/2507.23247)
*Sneha Oram,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: 本研究通过P-ReMe数据集和StiPRompts，评估了大型语言模型在心理健康领域的语用推理和污名化处理能力，发现Mistral和Qwen在推理方面表现出色，而Claude-3.5-haiku在处理污名化方面更为负责。


<details>
  <summary>Details</summary>
Motivation: 尽管在个性化心理健康聊天机器人方面取得了进展，但该领域在可解释性和对话语篇的推理方面仍未被充分探索。因此，本研究旨在调查大型语言模型（LLMs）在心理健康领域的语用推理能力，并研究其处理心理健康污名化的能力。

Method: 提出P-ReMe数据集，并为心理健康领域的隐含意义和预设现象提出了修改后的定义。在此定义下，研究人员制定了三个任务（隐含意义两个，预设一个），并使用Llama3.1、Mistral、MentaLLaMa和Qwen四个模型对数据集和任务进行了基准测试。此外，还提出了StiPRompts来研究心理健康污名化问题，并使用了GPT-4o mini、Deepseek-chat和Claude-3.5-haiku模型进行评估。

Result: Mistral和Qwen在心理健康领域的语用推理任务中表现出显著的能力。在处理心理健康污名化方面，Claude-3.5-haiku比GPT-4o mini和Deepseek-chat更负责任。

Conclusion: Claude-3.5-haiku在处理心理健康污名化方面比GPT-4o mini和Deepseek-chat更负责任。Mistral和Qwen在心理健康领域表现出相当大的推理能力。

Abstract: There has been an increase in recent advancements in the explainability and
development of personalized chatbots for mental health. However, the reasoning
aspects for explainability and dialogue discourse have not been explored
previously for mental health. Hence, we are investigating the pragmatic
reasoning capability of large language models (LLMs) in this domain. We
introduce P-ReMe dataset, and propose a modified definition for the pragmatic
phenomena of implicature (implied meaning) and presupposition (implicit
assumption) in mental health. Following the definition, we formulate two tasks
in implicature and one task in presupposition. To benchmark the dataset and the
presented tasks, we consider four models - Llama3.1, Mistral, MentaLLaMa, and
Qwen. The results of the experiments suggest that Mistral and Qwen show
substantial reasoning capabilities in the domain. In addition, we also propose
StiPRompts to study the stigma around mental health with the state-of-the-art
LLMs, GPT-4o mini, Deepseek-chat, and Claude-3.5-haiku. Our evaluated findings
show that Claude-3.5-haiku deals with the stigma more responsibly compared to
the other two LLMs.

</details>


### [145] [Evaluating LLMs' Multilingual Capabilities for Bengali: Benchmark Creation and Performance Analysis](https://arxiv.org/abs/2507.23248)
*Shimanto Bhowmik,Tawsif Tashwar Dipto,Md Sazzad Islam,Sheryl Hsu,Tahsin Reasat*

Main category: cs.CL

TL;DR: 本研究评估了10个大型语言模型在孟加拉语上的表现，发现与英语相比存在性能差距，并指出了分词效率对模型准确性的影响。研究强调了改进数据集和评估方法以促进孟加拉语NLP发展的重要性。


<details>
  <summary>Details</summary>
Motivation: 由于孟加拉语在NLP研究中代表性不足，并且其独特的语言结构和计算限制带来了挑战，因此有必要系统地研究阻碍孟加拉语NLP性能的因素。

Method: 本研究通过评估10个开源大型语言模型在8个翻译数据集上的表现，并进行全面的错误分析，来系统地研究阻碍孟加拉语NLP性能的挑战。

Result: 研究发现，与英语相比，孟加拉语在性能上存在持续的差距，特别是对于较小的模型和像Mistral这样的模型系列。DeepSeek等某些模型架构表现出较好的跨语言稳定性。此外，分词效率与大型语言模型准确性之间存在反比关系，分词过度会导致性能下降，而更有效和简洁的分词则能提高性能。

Conclusion: 本研究揭示了当前大型语言模型在处理孟加拉语时存在的性能差距，特别是在缺乏标准化评估基准的情况下。研究强调了提高数据集质量和开发针对多语言环境的评估方法的重要性，并指出了模型在分词效率和准确性之间的反比关系。

Abstract: Bengali is an underrepresented language in NLP research. However, it remains
a challenge due to its unique linguistic structure and computational
constraints. In this work, we systematically investigate the challenges that
hinder Bengali NLP performance by focusing on the absence of standardized
evaluation benchmarks. We then evaluated 10 recent open source Large Language
Models (LLMs) in 8 of the translated datasets and performed a comprehensive
error analysis to pinpoint their primary failure modes. Our findings reveal
consistent performance gaps for Bengali compared to English, particularly for
smaller models and specific model families like Mistral. We also identified
promising robustness in certain architectures, such as DeepSeek, that maintain
more stable performance across languages. Our analysis reveals an inverse
relationship between tokenization efficiency and LLM accuracy where models tend
to perform worse when inputs are excessively tokenized, whereas more efficient
\& concise tokenization results in improved performance. These findings
highlight critical areas where current models fall short and underscore the
need for improved dataset quality and evaluation methodologies tailored to
multilingual contexts. This work will catalyze further research on NLP for
underrepresented languages, helping to democratize access to advanced language
technologies worldwide. The code and dataset used in this research is publicly
available at https://github.com/BengaliAI/bn-llm-benchmark.

</details>


### [146] [Unveiling Super Experts in Mixture-of-Experts Large Language Models](https://arxiv.org/abs/2507.23279)
*Zunhai Su,Qingyuan Li,Hao Zhang,YuLei Qian,Yuchen Xie,Kehong Yuan*

Main category: cs.CL

TL;DR: 本研究发现了“超级专家”（SEs），它们是MoE LLM中数量虽少但至关重要的专家，对模型性能和注意力机制有显著影响。


<details>
  <summary>Details</summary>
Motivation: 现有MoE LLM效率提升方法多依赖经验标准选择专家，缺乏对专家异质重要性的深入理解。本研究旨在发现和探究在模型推理中起关键作用的特定专家子集，以改进MoE LLM的效率。

Method: 通过分析专家激活的离群值特征，识别并定义了“超级专家”（SEs）。通过剪枝SEs来评估其对模型性能的影响，并进一步研究了SEs对注意力汇聚机制的作用。

Result: 发现了一类名为“超级专家”（SEs）的专家，它们在MoE LLM中数量稀少但至关重要，剪枝可能导致模型性能显著下降（如Qwen3-30B-A3B剪枝三个SEs后输出重复且无效）。SEs的特征是激活离群值，且分布是模型特定的。剪枝SEs会严重影响数学推理等任务的性能，并破坏注意力汇聚机制。

Conclusion: 本研究首次发现了“超级专家”（SEs）——一类在MoE LLM前向推理中起关键作用的特定专家子集。研究表明，SEs的数量虽少，但对模型性能有显著影响，尤其是在数学推理任务上。SEs的特点是其在down_proj输出中表现出稀有但极端的激活离群值，并对模型内部的注意力分数分布至关重要，其压缩会严重破坏注意力汇聚机制。

Abstract: Sparsely activated Mixture-of-Experts (MoE) models have shown promise in
enhancing the learning capacity of large language models (LLMs). Leveraging the
intrinsic importance differences among experts, recent research has explored
expert-level compression techniques to improve the efficiency of MoE LLMs.
However, existing approaches often rely on empirical criteria to identify
critical experts, lacking a deeper exploration and understanding of the
heterogeneous importance of experts. In this study, we present the first
discovery and investigation of a distinct subset of experts that play a crucial
role in the underlying mechanisms during the model's forward inference. These
experts are prevalent in open-source MoE LLMs, and despite their limited
number, pruning them leads to a significant decline in model performance (e.g.,
pruning three causes Qwen3-30B-A3B to produce repetitive and uninformative
outputs). We refer to these experts as Super Experts (SEs). Our comprehensive
analysis provides progressively deeper insights into SEs. (i) SEs are
characterized by rare but extreme activation outliers in the output of the
down_proj, which give rise to massive activations in the hidden states between
decoder layers. Moreover, the distribution of SEs remains model-specific and is
unaffected by post-training processes. (ii) By pruning SEs, we assess their
significance across a variety of tasks, revealing their considerable impact on
the model's overall performance, particularly in mathematical reasoning. (iii)
We further enhance our understanding of the influence of SEs compression. Our
findings confirm that MoE LLMs rely on SEs to induce attention sinks, which are
crucial for the distribution of attention scores but are significantly
disrupted by SE pruning. The code is available at
https://github.com/ZunhaiSu/Super-Experts-Profilling.

</details>


### [147] [What's Taboo for You? - An Empirical Evaluation of LLMs Behavior Toward Sensitive Content](https://arxiv.org/abs/2507.23319)
*Alfio Ferrara,Sergio Picascia,Laura Pinnavaia,Vojimir Ranitovic,Elisabetta Rocchetti,Alice Tuveri*

Main category: cs.CL

TL;DR: GPT-4o-mini在处理敏感内容时会进行隐式的内容审核，减少不当语言。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在无明确指令的情况下是否会隐式地净化语言，以及评估其隐式内容审核行为。

Method: 通过实验分析GPT-4o-mini在释义敏感内容时的隐式审核行为，并评估敏感度变化程度。同时，评估LLM在句子敏感性分类方面的零样本能力，并与传统方法进行比较。

Result: GPT-4o-mini在释义敏感内容时，会系统性地将内容向不敏感方向审核，显著减少贬损性和禁忌语。LLM在句子敏感性分类方面也展现了其零样本能力。

Conclusion: LLM的隐式内容审核能力，特别是GPT-4o-mini在释义敏感内容时，会系统性地将内容向不敏感方向审核，显著减少贬损性和禁忌语。

Abstract: Proprietary Large Language Models (LLMs) have shown tendencies toward
politeness, formality, and implicit content moderation. While previous research
has primarily focused on explicitly training models to moderate and detoxify
sensitive content, there has been limited exploration of whether LLMs
implicitly sanitize language without explicit instructions. This study
empirically analyzes the implicit moderation behavior of GPT-4o-mini when
paraphrasing sensitive content and evaluates the extent of sensitivity shifts.
Our experiments indicate that GPT-4o-mini systematically moderates content
toward less sensitive classes, with substantial reductions in derogatory and
taboo language. Also, we evaluate the zero-shot capabilities of LLMs in
classifying sentence sensitivity, comparing their performances against
traditional methods.

</details>


### [148] [MUST-RAG: MUSical Text Question Answering with Retrieval Augmented Generation](https://arxiv.org/abs/2507.23334)
*Daeyong Kwon,SeungHeon Doh,Juhan Nam*

Main category: cs.CL

TL;DR: MusT-RAG 是一个结合了音乐向量数据库 MusWikiDB 的 RAG 框架，能有效提升 LLM 在音乐问答任务上的表现，优于传统微调方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决通用 LLM 在音乐领域知识相对较少，导致其在音乐相关应用中表现受限的问题。

Method: 提出了一种名为 MusT-RAG 的框架，该框架基于检索增强生成（RAG）技术，通过（1）提出一个专门的音乐向量数据库 MusWikiDB，以及（2）在推理和微调过程中利用上下文信息，来将通用的 LLM 适配于纯文本音乐问答任务。

Result: MusT-RAG 显著提高了 LLM 在音乐领域的适应能力，在音乐问答任务上表现优于传统微调方法，并且 MusWikiDB 相比通用维基百科语料库在性能和效率上更优。

Conclusion: MusT-RAG 框架在音乐问答任务上显著优于传统的微调方法，并在领域内和领域外的 MQA 基准测试中展现出持续的改进。此外，MusWikiDB 比通用的维基百科语料库更有效，在性能和计算效率方面都更胜一筹。

Abstract: Recent advancements in Large language models (LLMs) have demonstrated
remarkable capabilities across diverse domains. While they exhibit strong
zero-shot performance on various tasks, LLMs' effectiveness in music-related
applications remains limited due to the relatively small proportion of
music-specific knowledge in their training data. To address this limitation, we
propose MusT-RAG, a comprehensive framework based on Retrieval Augmented
Generation (RAG) to adapt general-purpose LLMs for text-only music question
answering (MQA) tasks. RAG is a technique that provides external knowledge to
LLMs by retrieving relevant context information when generating answers to
questions. To optimize RAG for the music domain, we (1) propose MusWikiDB, a
music-specialized vector database for the retrieval stage, and (2) utilizes
context information during both inference and fine-tuning processes to
effectively transform general-purpose LLMs into music-specific models. Our
experiment demonstrates that MusT-RAG significantly outperforms traditional
fine-tuning approaches in enhancing LLMs' music domain adaptation capabilities,
showing consistent improvements across both in-domain and out-of-domain MQA
benchmarks. Additionally, our MusWikiDB proves substantially more effective
than general Wikipedia corpora, delivering superior performance and
computational efficiency.

</details>


### [149] [Text-to-SQL Task-oriented Dialogue Ontology Construction](https://arxiv.org/abs/2507.23358)
*Renato Vukovic,Carel van Niekerk,Michael Heck,Benjamin Ruppik,Hsien-Chin Lin,Shutong Feng,Nurul Lubis,Milica Gasic*

Main category: cs.CL

TL;DR: TeQoDO 是一种无需监督的 LLM 方法，可自动构建面向任务的对话本体，提高了 LLM 的可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统的面向任务对话系统依赖外部数据库和显式本体来保证可解释性和可控性，但本体的构建需要手动标注或监督训练。

Method: TeQoDO 是一种文本到 SQL 的面向任务对话本体构建方法，它利用 LLM 的 SQL 编程能力和提示中提供的对话理论，在没有监督的情况下从头开始自主构建面向任务对话本体。

Result: TeQoDO 的性能优于迁移学习方法，并且其构建的本体在下游对话状态跟踪任务中具有竞争力。模型规模化能力也得到了验证，可以在包含维基百科和 arXiv 数据集的更大本体上进行构建。

Conclusion: TeQoDO 的研究是朝着提高 LLM 可解释性更广泛地应用本体迈出的一步。

Abstract: Large language models (LLMs) are widely used as general-purpose knowledge
sources, but they rely on parametric knowledge, limiting explainability and
trustworthiness. In task-oriented dialogue (TOD) systems, this separation is
explicit, using an external database structured by an explicit ontology to
ensure explainability and controllability. However, building such ontologies
requires manual labels or supervised training. We introduce TeQoDO: a
Text-to-SQL task-oriented Dialogue Ontology construction method. Here, an LLM
autonomously builds a TOD ontology from scratch without supervision using its
inherent SQL programming capabilities combined with dialogue theory provided in
the prompt. We show that TeQoDO outperforms transfer learning approaches, and
its constructed ontology is competitive on a downstream dialogue state tracking
task. Ablation studies demonstrate the key role of dialogue theory. TeQoDO also
scales to allow construction of much larger ontologies, which we investigate on
a Wikipedia and ArXiv dataset. We view this as a step towards broader
application of ontologies to increase LLM explainability.

</details>


### [150] [MPCC: A Novel Benchmark for Multimodal Planning with Complex Constraints in Multimodal Large Language Models](https://arxiv.org/abs/2507.23382)
*Yiyan Ji,Haoran Chen,Qiguang Chen,Chengyue Wu,Libo Qin,Wanxiang Che*

Main category: cs.CL

TL;DR: MPCC基准旨在评估多模态语言模型在具有复杂约束（如预算、时间、空间）的现实世界规划任务中的能力，结果显示现有模型表现不佳，尤其是在处理复杂约束时。


<details>
  <summary>Details</summary>
Motivation: 现有的基准无法直接评估多模态现实世界规划能力，并且缺乏跨模态的约束或隐式约束。为了解决这些问题，需要一个能够系统评估MLLMs处理多模态约束能力的基准。

Method: 提出了一种名为MPCC（Multimodal Planning with Complex Constraints）的新基准，该基准专注于三个现实世界的任务：飞行规划、日历规划和会议规划。MPCC引入了包含预算、时间、空间等复杂约束，并设定了EASY、MEDIUM、HARD三个难度等级，以系统地评估MLLMs处理多模态约束的能力。

Result: 在13个先进的MLLMs上进行的实验表明，模型在MPCC基准上面临显著挑战。封闭源代码模型的可行计划成功率仅为21.3%，开源模型平均低于11%。此外，MLLMs对约束复杂性高度敏感，传统的多模态提示策略在多约束场景下失效。

Conclusion: 目前的多模态语言模型（MLLMs）在处理现实世界中涉及多模态约束的规划任务时面临巨大挑战。封闭源代码模型的可行计划成功率仅为21.3%，而开源模型平均低于11%。模型对约束复杂性的敏感度很高，传统的多模态提示策略在多约束场景下效果不佳。未来的工作需要专注于提升MLLMs的约束感知推理能力，以满足现实世界应用的需求。

Abstract: Multimodal planning capabilities refer to the ability to predict, reason, and
design steps for task execution with multimodal context, which is essential for
complex reasoning and decision-making across multiple steps. However, current
benchmarks face two key challenges: (1) they cannot directly assess multimodal
real-world planning capabilities, and (2) they lack constraints or implicit
constraints across modalities. To address these issues, we introduce Multimodal
Planning with Complex Constraints (MPCC), the first benchmark to systematically
evaluate MLLMs' ability to handle multimodal constraints in planning. To
address the first challenge, MPCC focuses on three real-world tasks: Flight
Planning, Calendar Planning, and Meeting Planning. To solve the second
challenge, we introduce complex constraints (e.g. budget, temporal, and
spatial) in these tasks, with graded difficulty levels (EASY, MEDIUM, HARD) to
separate constraint complexity from search space expansion. Experiments on 13
advanced MLLMs reveal significant challenges: closed-source models achieve only
21.3% feasible plans, while open-source models average below 11%. Additionally,
we observe that MLLMs are highly sensitive to constraint complexity and that
traditional multimodal prompting strategies fail in multi-constraint scenarios.
Our work formalizes multimodal constraints in planning, provides a rigorous
evaluation framework, and highlights the need for advancements in
constraint-aware reasoning for real-world MLLM applications.

</details>


### [151] [Causal2Vec: Improving Decoder-only LLMs as Versatile Embedding Models](https://arxiv.org/abs/2507.23386)
*Ailiang Lin,Zhuoyun Li,Kotaro Funakoshi*

Main category: cs.CL

TL;DR: Causal2Vec 是一种新的 embedding 模型，它通过向 decoder-only LLM 的输入添加预编码的上下文标记来提高性能，并结合上下文和 EOS 标记的输出来生成最终嵌入。它在 MTEB 上实现了最先进的性能，同时大大降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的 embedding 模型要么通过移除因果注意力掩码来破坏 LLM 在预训练期间获得的语义信息，要么依赖额外的输入文本来克服因果注意力的固有局限性，从而增加计算成本。Causal2Vec 旨在解决这些问题。

Method: Causal2Vec 通过以下方式工作：1. 使用轻量级的 BERT 风格模型预编码输入文本，生成单个上下文标记。2. 将上下文标记添加到 LLM 的输入序列的开头。3. 连接上下文标记和 EOS 标记的最后隐藏状态，作为最终的文本嵌入。

Result: Causal2Vec 在 MTEB 基准测试中取得了最先进的性能，在仅使用公开可用的检索数据集进行训练的模型中表现最佳。与性能最佳的方法相比，它将所需的序列长度减少了高达 85%，并将推理时间减少了高达 82%。

Conclusion: Causal2Vec 是一种通用的嵌入模型，可以增强 decoder-only LLM 的性能，而无需更改其原始架构或引入显著的计算开销。它通过预编码输入文本以生成上下文标记，并将其添加到 LLM 的输入序列中，使每个标记都能捕获上下文信息。此外，通过连接上下文标记和 EOS 标记的最后隐藏状态，可以缓解最后标记池化引入的近因效应，并更好地利用上下文标记中编码的语义信息。Causal2Vec 在 MTEB 基准测试中取得了最先进的性能，同时显著减少了序列长度和推理时间。

Abstract: Decoder-only large language models (LLMs) are increasingly used to build
embedding models that effectively encode the semantic information of natural
language texts into dense vector representations for various embedding tasks.
However, many existing methods primarily focus on removing the causal attention
mask in LLMs to enable bidirectional attention, potentially undermining the
model's ability to extract semantic information acquired during pretraining.
Additionally, leading unidirectional approaches often rely on extra input text
to overcome the inherent limitations of causal attention, inevitably increasing
computational costs. In this work, we propose Causal2Vec, a general-purpose
embedding model tailored to enhance the performance of decoder-only LLMs
without altering their original architectures or introducing significant
computational overhead. Specifically, we first employ a lightweight BERT-style
model to pre-encode the input text into a single Contextual token, which is
then prepended to the LLM's input sequence, allowing each token to capture
contextualized information even without attending to future tokens.
Furthermore, to mitigate the recency bias introduced by last-token pooling and
help LLMs better leverage the semantic information encoded in the Contextual
token, we concatenate the last hidden states of Contextual and EOS tokens as
the final text embedding. In practice, Causal2Vec achieves state-of-the-art
performance on the Massive Text Embeddings Benchmark (MTEB) among models
trained solely on publicly available retrieval datasets, while reducing the
required sequence length by up to 85% and inference time by up to 82% compared
to best-performing methods.

</details>


### [152] [Beyond the Cloud: Assessing the Benefits and Drawbacks of Local LLM Deployment for Translators](https://arxiv.org/abs/2507.23399)
*Peter Sandrini*

Main category: cs.CL

TL;DR: 本研究探讨了本地部署的免费语言模型作为专有云端人工智能解决方案的可行性和性能，重点关注数据控制、隐私和可访问性，特别是对个体翻译者和小型企业而言。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在翻译领域的快速发展带来了机遇和挑战。虽然商业、云端人工智能聊天机器人已引起翻译研究的极大关注，但对数据隐私、安全和公平访问的担忧，使得探索替代部署模式成为必要。

Method: 本研究评估了安装在基于 CPU 的平台上的三个开源模型，并与商业在线聊天机器人进行了比较。评估侧重于功能性能，而不是对人类机器翻译质量进行比较分析，这已是广泛研究的领域。

Result: 评估的平台因其在各种操作系统上的可访问性和易用性而被选中。

Conclusion: 虽然本地部署引入了其自身的挑战，但增强数据控制、改善隐私和减少对云服务的依赖等好处是显而易见的。本研究结果有助于加强关于人工智能技术民主化的知识体系，并为未来旨在使更广泛的用户能够更方便、更实用地使用大型语言模型的研究和开发工作提供信息，特别是关注个体翻译者和小型企业的需求。

Abstract: The rapid proliferation of Large Language Models presents both opportunities
and challenges for the translation field. While commercial, cloud-based AI
chatbots have garnered significant attention in translation studies, concerns
regarding data privacy, security, and equitable access necessitate exploration
of alternative deployment models. This paper investigates the feasibility and
performance of locally deployable, free language models as a viable alternative
to proprietary, cloud-based AI solutions. This study evaluates three
open-source models installed on CPU-based platforms and compared against
commercially available online chat-bots. The evaluation focuses on functional
performance rather than a comparative analysis of human-machine translation
quality, an area already subject to extensive research. The platforms assessed
were chosen for their accessibility and ease of use across various operating
systems. While local deployment introduces its own challenges, the benefits of
enhanced data control, improved privacy, and reduced dependency on cloud
services are compelling. The findings of this study contribute to a growing
body of knowledge concerning the democratization of AI technology and inform
future research and development efforts aimed at making LLMs more accessible
and practical for a wider range of users, specifically focusing on the needs of
individual translators and small businesses.

</details>


### [153] [MRGSEM-Sum: An Unsupervised Multi-document Summarization Framework based on Multi-Relational Graphs and Structural Entropy Minimization](https://arxiv.org/abs/2507.23400)
*Yongbing Zhang,Fang Nan,Shengxiang Gao,Yuxin Huang,Kaiwen Tan,Zhengtao Yu*

Main category: cs.CL

TL;DR: MRGSEM-Sum 是一种新的无监督多文档摘要方法，通过多关系图和结构熵最小化来克服现有方法的局限性，并在实验中取得了优于其他无监督方法和媲美监督模型的成果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多文档摘要中存在只考虑单关系图和需要预定义聚类数量的局限性，无法充分表达丰富的关系信息和自适应地划分句子分组以减少冗余。MRGSEM-Sum 旨在克服这些限制。

Method: 提出了一种基于多关系图和结构熵最小化的无监督多文档摘要框架 MRGSEM-Sum。该框架首先构建一个整合了句子间语义和语篇关系的多关系图，然后使用二维结构熵最小化算法进行聚类，自动确定最优聚类数量并将句子分组，最后引入了位置感知压缩机制来生成摘要。

Result: 在 Multi-News、DUC-2004、PubMed 和 WikiSum 四个基准数据集上的广泛实验表明，MRGSEM-Sum 的性能持续优于以往的无监督方法，并在某些情况下达到了与监督模型和大型语言模型相媲美的性能。人类评估结果显示，MRGSEM-Sum 生成的摘要具有高一致性和高覆盖率，接近人类水平。

Conclusion: MRGSEM-Sum 框架在多篇文档摘要任务上表现出色，能够生成高质量、高一致性和高覆盖率的摘要，性能可媲美监督模型甚至达到人类水平。

Abstract: The core challenge faced by multi-document summarization is the complexity of
relationships among documents and the presence of information redundancy. Graph
clustering is an effective paradigm for addressing this issue, as it models the
complex relationships among documents using graph structures and reduces
information redundancy through clustering, achieving significant research
progress. However, existing methods often only consider single-relational
graphs and require a predefined number of clusters, which hinders their ability
to fully represent rich relational information and adaptively partition
sentence groups to reduce redundancy. To overcome these limitations, we propose
MRGSEM-Sum, an unsupervised multi-document summarization framework based on
multi-relational graphs and structural entropy minimization. Specifically, we
construct a multi-relational graph that integrates semantic and discourse
relations between sentences, comprehensively modeling the intricate and dynamic
connections among sentences across documents. We then apply a two-dimensional
structural entropy minimization algorithm for clustering, automatically
determining the optimal number of clusters and effectively organizing sentences
into coherent groups. Finally, we introduce a position-aware compression
mechanism to distill each cluster, generating concise and informative
summaries. Extensive experiments on four benchmark datasets (Multi-News,
DUC-2004, PubMed, and WikiSum) demonstrate that our approach consistently
outperforms previous unsupervised methods and, in several cases, achieves
performance comparable to supervised models and large language models. Human
evaluation demonstrates that the summaries generated by MRGSEM-Sum exhibit high
consistency and coverage, approaching human-level quality.

</details>


### [154] [Enhanced Arabic Text Retrieval with Attentive Relevance Scoring](https://arxiv.org/abs/2507.23404)
*Salah Eddine Bekhouche,Azeddine Benlamoudi,Yazid Bounab,Fadi Dornaika,Abdenour Hadid*

Main category: cs.CL

TL;DR: 本文提出了一种名为APR的阿拉伯语增强型密集检索框架，通过新颖的注意力相关性评分（ARS）机制和预训练模型优化，提升了阿拉伯语问答的准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管阿拉伯语在全球的重要性日益增长，但在自然语言处理（NLP）和信息检索（IR）领域，它仍然面临挑战且资源不足。本文旨在解决阿拉伯语在NLP和IR研究中的代表性不足问题，并提出一个专门针对阿拉伯语的增强型检索框架。

Method: 本文提出了一种新颖的注意力相关性评分（ARS）机制，以取代标准的交互机制，并将其应用于密集检索框架（DPR）。该方法集成了预训练的阿拉伯语语言模型和架构优化，以提高检索性能和排名准确性。

Result: 所提出的APR框架通过ARS机制和集成预训练模型及架构优化，显著提高了在阿拉伯语问答任务中的检索性能和排名准确性。

Conclusion: 本文提出了一个针对阿拉伯语的增强型密集检索框架（APR），该框架通过引入新颖的注意力相关性评分（ARS）机制，并结合预训练的阿拉伯语语言模型和架构优化，显著提高了阿拉伯语问答的检索性能和排名准确性。

Abstract: Arabic poses a particular challenge for natural language processing (NLP) and
information retrieval (IR) due to its complex morphology, optional diacritics
and the coexistence of Modern Standard Arabic (MSA) and various dialects.
Despite the growing global significance of Arabic, it is still underrepresented
in NLP research and benchmark resources. In this paper, we present an enhanced
Dense Passage Retrieval (DPR) framework developed specifically for Arabic. At
the core of our approach is a novel Attentive Relevance Scoring (ARS) that
replaces standard interaction mechanisms with an adaptive scoring function that
more effectively models the semantic relevance between questions and passages.
Our method integrates pre-trained Arabic language models and architectural
refinements to improve retrieval performance and significantly increase ranking
accuracy when answering Arabic questions. The code is made publicly available
at \href{https://github.com/Bekhouche/APR}{GitHub}.

</details>


### [155] [Beyond Passive Critical Thinking: Fostering Proactive Questioning to Enhance Human-AI Collaboration](https://arxiv.org/abs/2507.23407)
*Ante Wang,Yujie Lin,Jingyao Liu,Suhang Wu,Hao Liu,Xinyan Xiao,Jinsong Su*

Main category: cs.CL

TL;DR: AI系统需要具备主动批判性思维，主动向用户索要缺失信息以更好地解决问题。本研究提出了主动批判性思维范式，并创建了新的基准和强化学习方法，显著提升了模型在该能力上的表现。


<details>
  <summary>Details</summary>
Motivation: 解决现有AI系统仅能被动拒绝有缺陷查询而不能主动寻求澄清信息以更好地解决用户请求的问题。

Method: 提出主动批判性思维范式，创建了基于GSM8K的GSM-MC和GSM-MCE基准，并使用强化学习来提升模型的能力。

Result: 在GSM-MC基准上，通过改进的强化学习算法，将Qwen3-1.7B模型的准确率从0.15%提升到73.98%，证明了主动批判性思维的可行性和强化学习的有效性。

Conclusion: 本研究提出了主动批判性思维的范式，并创建了GSM-MC和GSM-MCE基准来评估和改进这种能力。通过强化学习，显著提升了模型在不完整或误导性数学推理任务上的表现，尤其是在处理缺失信息方面。

Abstract: Critical thinking is essential for building robust AI systems, preventing
them from blindly accepting flawed data or biased reasoning. However, prior
work has primarily focused on passive critical thinking, where models simply
reject problematic queries without taking constructive steps to address user
requests. In this work, we introduce proactive critical thinking, a paradigm
where models actively seek missing or clarifying information from users to
resolve their queries better. To evaluate this capability, we present GSM-MC
and GSM-MCE, two novel benchmarks based on GSM8K for assessing mathematical
reasoning under incomplete or misleading conditions. GSM-MC contains 1,368 math
problems with a key variable deliberately removed, requiring models to identify
and request the missing information. GSM-MCE further increases the difficulty
by introducing irrelevant details to test robustness against distractions.
Experiments on Qwen3 and Llama series models show that, while these models
excel in traditional reasoning tasks due to extensive post-training and
inference-time scaling, they struggle with proactive critical thinking,
especially smaller ones. However, we demonstrate that reinforcement learning
(RL) can significantly improve this ability. Using our enhanced RL algorithm,
we achieve substantial gains, boosting the Qwen3-1.7B's accuracy from 0.15% to
73.98% on GSM-MC. We hope this work advances models that collaborate more
effectively with users in problem-solving through proactive critical thinking.

</details>


### [156] [Role-Aware Language Models for Secure and Contextualized Access Control in Organizations](https://arxiv.org/abs/2507.23465)
*Saeed Almheiri,Yerulan Kongrat,Adrian Santosh,Ruslan Tasmukhanov,Josemaria Vera,Muhammad Dehan Al Kautsar,Fajri Koto*

Main category: cs.CL

TL;DR: LLMs can be taught to respect user roles in enterprise settings, a crucial step for safe deployment.


<details>
  <summary>Details</summary>
Motivation: Existing LLM safety methods do not address role-specific access constraints, which are essential for enterprise deployment.

Method: Investigated three modeling strategies: BERT-based classifier, LLM-based classifier, and role-conditioned generation. Constructed two datasets (adapted and synthetic) for evaluation. Assessed performance across organizational structures and robustness to prompt injection, role mismatch, and jailbreaks.

Result: The study demonstrates the feasibility of fine-tuning LLMs for role-based access control, with performance evaluated against various challenges.

Conclusion: LLMs can be fine-tuned to generate role-specific responses, addressing a key requirement for enterprise deployment.

Abstract: As large language models (LLMs) are increasingly deployed in enterprise
settings, controlling model behavior based on user roles becomes an essential
requirement. Existing safety methods typically assume uniform access and focus
on preventing harmful or toxic outputs, without addressing role-specific access
constraints. In this work, we investigate whether LLMs can be fine-tuned to
generate responses that reflect the access privileges associated with different
organizational roles. We explore three modeling strategies: a BERT-based
classifier, an LLM-based classifier, and role-conditioned generation. To
evaluate these approaches, we construct two complementary datasets. The first
is adapted from existing instruction-tuning corpora through clustering and role
labeling, while the second is synthetically generated to reflect realistic,
role-sensitive enterprise scenarios. We assess model performance across varying
organizational structures and analyze robustness to prompt injection, role
mismatch, and jailbreak attempts.

</details>


### [157] [A Novel Evaluation Benchmark for Medical LLMs: Illuminating Safety and Effectiveness in Clinical Domains](https://arxiv.org/abs/2507.23486)
*Shirui Wang,Zhihui Tang,Huaxia Yang,Qiuhong Gong,Tiantian Gu,Hongyang Ma,Yongxin Wang,Wubin Sun,Zeliang Lian,Kehang Mao,Yinan Jiang,Zhicheng Huang,Lingyun Ma,Wenjie Shen,Yajie Ji,Yunhui Tan,Chunbo Wang,Yunlu Gao,Qianling Ye,Rui Lin,Mingyu Chen,Lijuan Niu,Zhihao Wang,Peng Yu,Mengran Lang,Yue Liu,Huimin Zhang,Haitao Shen,Long Chen,Qiguang Zhao,Si-Xuan Liu,Lina Zhou,Hua Gao,Dongqiang Ye,Lingmin Meng,Youtao Yu,Naixin Liang,Jianxiong Wu*

Main category: cs.CL

TL;DR: 该研究提出了CSEDB基准，用于评估临床LLM的安全性与有效性。结果显示，LLM在临床应用中表现尚可但有待提高，尤其在高风险场景下。领域特定模型优于通用模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型（LLM）在临床决策支持中的安全评估和有效性验证所面临的挑战。

Method: 开发了一个包含30项标准、由32名医生参与创建的2,069个问答对的CSEDB多维度框架，用于评估LLM在临床决策支持中的安全性与有效性。

Result: 测试了六种LLM，显示总体平均得分为57.2%（安全54.7%，有效性62.3%），高风险场景下性能显著下降13.3%（p < 0.0001）。领域特定模型在安全性和有效性方面表现优于通用模型。

Conclusion: 该研究提出了CSEDB基准，为评估医疗LLM的临床安全性和有效性提供了一个标准化的方法，并揭示了当前LLM在临床应用中面临的挑战，特别是高风险场景下的表现下降，同时强调了领域特定模型相比通用模型的优势。

Abstract: Large language models (LLMs) hold promise in clinical decision support but
face major challenges in safety evaluation and effectiveness validation. We
developed the Clinical Safety-Effectiveness Dual-Track Benchmark (CSEDB), a
multidimensional framework built on clinical expert consensus, encompassing 30
criteria covering critical areas like critical illness recognition, guideline
adherence, and medication safety, with weighted consequence measures.
Thirty-two specialist physicians developed and reviewed 2,069 open-ended Q&A
items aligned with these criteria, spanning 26 clinical departments to simulate
real-world scenarios. Benchmark testing of six LLMs revealed moderate overall
performance (average total score 57.2%, safety 54.7%, effectiveness 62.3%),
with a significant 13.3% performance drop in high-risk scenarios (p < 0.0001).
Domain-specific medical LLMs showed consistent performance advantages over
general-purpose models, with relatively higher top scores in safety (0.912) and
effectiveness (0.861). The findings of this study not only provide a
standardized metric for evaluating the clinical application of medical LLMs,
facilitating comparative analyses, risk exposure identification, and
improvement directions across different scenarios, but also hold the potential
to promote safer and more effective deployment of large language models in
healthcare environments.

</details>


### [158] [Med-R$^3$: Enhancing Medical Retrieval-Augmented Reasoning of LLMs via Progressive Reinforcement Learning](https://arxiv.org/abs/2507.23541)
*Keer Lu,Zheng Liang,Youquan Li,Jiejun Tan,Da Pan,Shusen Zhang,Guosheng Dong,Huang Leng*

Main category: cs.CL

TL;DR: Med-R$^3$通过渐进式强化学习，联合优化医疗检索与推理能力，在相关任务上取得了优于GPT-4o-mini等先进模型的效果。


<details>
  <summary>Details</summary>
Motivation: 现有模型在医疗场景中，检索与推理能力是孤立的，缺乏联合优化，导致协调性有限。此外，现有方法依赖监督微调，限制了泛化能力。强化学习奖励函数设计未能充分满足医疗领域的特定需求。

Method: 提出了一种名为Med-R$^3$的医疗检索增强推理框架，该框架采用渐进式强化学习。首先优化模型的逻辑推理能力，然后在此基础上自适应地优化检索能力，最后进行检索与推理的联合优化。

Result: Med-R$^3$框架在医疗检索增强推理任务上取得了最先进的性能。LLaMA3.1-8B-Instruct + Med-R$^3$在相似参数规模下，性能超越了GPT-4o-mini 3.93%；Qwen2.5-14B + Med-R$^3$则取得了13.53%的显著提升。

Conclusion: Med-R$^3$框架在医疗检索增强推理任务上取得了最先进的性能，LLaMA3.1-8B-Instruct + Med-R$^3$ 的表现优于GPT-4o-mini，Qwen2.5-14B + Med-R$^3$的提升更为显著。

Abstract: In medical scenarios, effectively retrieving external knowledge and
leveraging it for rigorous logical reasoning is of significant importance.
Despite their potential, existing work has predominantly focused on enhancing
either retrieval or reasoning capabilities of the models in isolation, with
little attention given to their joint optimization, which leads to limited
coordination between the two processes. Additionally, current methods rely
heavily on supervised fine-tuning (SFT), which can cause models to memorize
existing problem-solving pathways, thereby restricting their generalization
ability when confronted with novel problem contexts. Furthermore, while some
studies have explored to improve retrieval-augmented reasoning in general
domains via reinforcement learning, their reward function designs do not
adequately capture the specific demands of the medical domain. To address these
challenges, we introduce **Med-R$^3$**, a **Med**ical **R**etrieval-augmented
**R**easoning framework driven by progressive **R**einforcement learning. In
this framework, we first develop the model's ability to perform logical
reasoning over medical problems. Subsequently, on the basis of this foundation,
we adaptively optimize the retrieval capability to better align with the
characteristics of knowledge corpus and external information utilization
throughout the reasoning process. Finally, we conduct joint optimization of the
model's retrieval and reasoning coordination. Extensive experiments indicate
that **Med-R$^3$** could achieve state-of-the-art performances, with
LLaMA3.1-8B-Instruct + Med-R$^3$ surpassing closed-sourced GPT-4o-mini by
3.93\% at a comparable parameter scale, while Qwen2.5-14B augmented with
Med-R$^3$ shows a more substantial gain of 13.53\%.

</details>


### [159] [T-Detect: Tail-Aware Statistical Normalization for Robust Detection of Adversarial Machine-Generated Text](https://arxiv.org/abs/2507.23577)
*Alva West,Luodan Zhang,Liuliu Zhang,Minjun Zhu,Yixuan Weng,Yue Zhang*

Main category: cs.CL

TL;DR: T-Detect是一种新的文本检测方法，使用t分布的重尾特性来提高对对抗性扰动的鲁棒性，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本检测器依赖于隐性假设高斯分布的统计量，但这种假设在面对对抗性或非母语英语文本的重尾统计伪影时会失效。因此，有必要开发能够识别机器生成内容（特别是旨在通过对抗性扰动逃避检测的文本）的鲁棒检测方法。

Method: T-Detect通过将基于曲率检测器的统计核心重新设计，使用源自t分布的重尾差异分数取代标准的斯皮尔曼归一化，并计算通过相对于t分布期望矩进行对数似然来获得检测分数。

Result: T-Detect在RAID和HART数据集上的实验表明，该方法在目标域上将AUROC提高了高达3.9%，在RAID数据集的Books域上达到了0.926的AUROC。

Conclusion: T-Detect方法在RAID和HART数据集上均表现出比现有基线方法更优越的性能，在RAID数据集的Books域上AUROC达到0.926，并且对逃避检测的对抗性扰动具有更强的鲁棒性。

Abstract: The proliferation of sophisticated text generation models necessitates the
development of robust detection methods capable of identifying
machine-generated content, particularly text designed to evade detection
through adversarial perturbations. Existing zero-shot detectors often rely on
statistical measures that implicitly assume Gaussian distributions, a premise
that falters when confronted with the heavy-tailed statistical artifacts
characteristic of adversarial or non-native English texts. This paper
introduces T-Detect, a novel detection method that fundamentally redesigns the
statistical core of curvature-based detectors. Our primary innovation is the
replacement of standard Gaussian normalization with a heavy-tailed discrepancy
score derived from the Student's t-distribution. This approach is theoretically
grounded in the empirical observation that adversarial texts exhibit
significant leptokurtosis, rendering traditional statistical assumptions
inadequate. T-Detect computes a detection score by normalizing the
log-likelihood of a passage against the expected moments of a t-distribution,
providing superior resilience to statistical outliers. We validate our approach
on the challenging RAID benchmark for adversarial text and the comprehensive
HART dataset. Experiments show that T-Detect provides a consistent performance
uplift over strong baselines, improving AUROC by up to 3.9\% in targeted
domains. When integrated into a two-dimensional detection framework (CT), our
method achieves state-of-the-art performance, with an AUROC of 0.926 on the
Books domain of RAID. Our contributions are a new, theoretically-justified
statistical foundation for text detection, an ablation-validated method that
demonstrates superior robustness, and a comprehensive analysis of its
performance under adversarial conditions. Ours code are released at
https://github.com/ResearAI/t-detect.

</details>


### [160] [DiffLoRA: Differential Low-Rank Adapters for Large Language Models](https://arxiv.org/abs/2507.23588)
*Alexandre Misrahi,Nadezhda Chirkova,Maxime Louis,Vassilina Nikoulina*

Main category: cs.CL

TL;DR: DiffLoRA 是差分 Transformer 的一种参数高效适配，结合了 LoRA 的效率和差分注意力的性能优势，但在大多数任务上表现不及其他方法，但在某些特定领域有潜力。


<details>
  <summary>Details</summary>
Motivation: 为了在 Transformer 模型中通过差分注意力机制抵消噪声来提高性能，并结合 LoRA 的效率。

Method: 提出了一种名为 DiffLoRA 的参数高效方法，它是差分注意力机制的一种适配，在正负注意力项上都使用了低秩适配器。

Result: DiffLoRA 在包括通用基准、多样本 in-context learning、RAG 和长上下文测试在内的广泛 NLP 任务中进行了评估。

Conclusion: DiffLoRA 在大多数评估任务中的表现不及其他参数高效微调方法，但在某些领域（如 HumanEval 上比 LoRA 提高 11 分）取得了有趣的结果。对微调后注意力模式的分析旨在找出这种行为的原因。

Abstract: Differential Transformer has recently been proposed to improve performance in
Transformer models by canceling out noise through a denoiser attention
mechanism. In this work, we introduce DiffLoRA, a parameter-efficient
adaptation of the differential attention mechanism, with low-rank adapters on
both positive and negative attention terms. This approach retains the
efficiency of LoRA while aiming to benefit from the performance gains of
differential attention. We evaluate DiffLoRA across a broad range of NLP tasks,
including general benchmarks, many-shot in-context learning, RAG, and
long-context tests. We observe that, although DiffLoRA falls short of other
parameter-efficient fine-tuning methods in most evaluation tasks, it shows
interesting results in certain domains (+11 pts on LoRA for HumanEval). We
analyze the attention patterns post-finetuning to identify the reasons for this
behavior.

</details>


### [161] [Arabic Hate Speech Identification and Masking in Social Media using Deep Learning Models and Pre-trained Models Fine-tuning](https://arxiv.org/abs/2507.23661)
*Salam Thabet Doghmash,Motaz Saad*

Main category: cs.CL

TL;DR: 本研究提出了一种使用深度学习和Transformer模型来检测阿拉伯语仇恨言论并清理文本的方法，取得了良好的效果。


<details>
  <summary>Details</summary>
Motivation: 随着社交媒体的普及，仇恨言论的识别变得越来越重要。本研究旨在解决阿拉伯语文本中的仇恨言论检测和清理问题。

Method: 研究采用了深度学习模型和Transformer来解决仇恨言论检测问题，并将其视为一个机器翻译任务来解决文本清理问题，即用星号替换脏文本中的单词。

Result: 在仇恨言论检测方面，模型达到了92%的宏观F1分数和95%的准确率。在文本清理方面，模型达到了0.3的BLEU分数（1-gram）。

Conclusion: 本研究成功解决了在社交媒体中检测阿拉伯语仇恨言论以及清理（即用星号替换仇恨言论中的单词）这两个问题。所提出的方法在仇恨言论检测方面达到了92%的宏观F1分数和95%的准确率，在文本清理方面，仇恨言论掩蔽模型达到了0.3的BLEU分数（1-gram），与现有的机器翻译系统相比是一个不错的结果。

Abstract: Hate speech identification in social media has become an increasingly
important issue in recent years. In this research, we address two problems: 1)
to detect hate speech in Arabic text, 2) to clean a given text from hate
speech. The meaning of cleaning here is replacing each bad word with stars
based on the number of letters for each word. Regarding the first problem, we
conduct several experiments using deep learning models and transformers to
determine the best model in terms of the F1 score. Regarding second problem, we
consider it as a machine translation task, where the input is a sentence
containing dirty text and the output is the same sentence with masking the
dirty text. The presented methods achieve the best model in hate speech
detection with a 92\% Macro F1 score and 95\% accuracy. Regarding the text
cleaning experiment, the best result in the hate speech masking model reached
0.3 in BLEU score with 1-gram, which is a good result compared with the state
of the art machine translation systems.

</details>


### [162] [Rule2Text: Natural Language Explanation of Logical Rules in Knowledge Graphs](https://arxiv.org/abs/2507.23740)
*Nasim Shirvani-Mahdavi,Devin Wingfield,Amin Ghasemi,Chengkai Li*

Main category: cs.CL

TL;DR: 本研究旨在探索利用大型语言模型生成知识图谱逻辑规则的自然语言解释，以克服人工理解的困难。研究人员使用AMIE算法提取规则，并测试了不同的提示策略，通过人工评估验证了模型的有效性，结果显示模型在解释的正确性和清晰度方面表现良好，但仍需进一步研究以克服现有挑战。


<details>
  <summary>Details</summary>
Motivation: 知识图谱中的逻辑规则有助于提高其完整性、检测错误、揭示数据模式和增强推理能力。然而，这些规则的复杂性和特定知识图谱的标签约定给人类理解带来了困难。

Method: 利用AMIE 3.5.1规则发现算法从FB15k-237、FB-CVT-REV和FB+CVT-REV数据集中提取逻辑规则，并探索了包括零样本、少样本、变量实体类型和思维链推理在内的各种提示策略，最后进行了基于正确性、清晰度和幻觉的人工评估，并评估了大型语言模型作为自动评估者。

Result: 研究结果表明，大型语言模型在生成逻辑规则的自然语言解释方面取得了有希望的性能，尤其是在解释的正确性和清晰度方面，尽管仍存在一些挑战。

Conclusion: 大型语言模型在生成逻辑规则的自然语言解释方面展现出有前景的性能，尤其是在解释的正确性和清晰度方面，但仍有挑战有待未来研究。

Abstract: Knowledge graphs (KGs) often contain sufficient information to support the
inference of new facts. Identifying logical rules not only improves the
completeness of a knowledge graph but also enables the detection of potential
errors, reveals subtle data patterns, and enhances the overall capacity for
reasoning and interpretation. However, the complexity of such rules, combined
with the unique labeling conventions of each KG, can make them difficult for
humans to understand. In this paper, we explore the potential of large language
models to generate natural language explanations for logical rules.
Specifically, we extract logical rules using the AMIE 3.5.1 rule discovery
algorithm from the benchmark dataset FB15k-237 and two large-scale datasets,
FB-CVT-REV and FB+CVT-REV. We examine various prompting strategies, including
zero- and few-shot prompting, including variable entity types, and
chain-of-thought reasoning. We conduct a comprehensive human evaluation of the
generated explanations based on correctness, clarity, and hallucination, and
also assess the use of large language models as automatic judges. Our results
demonstrate promising performance in terms of explanation correctness and
clarity, although several challenges remain for future research. All scripts
and data used in this study are publicly available at
https://github.com/idirlab/KGRule2NL}{https://github.com/idirlab/KGRule2NL.

</details>


### [163] [Cascaded Information Disclosure for Generalized Evaluation of Problem Solving Capabilities](https://arxiv.org/abs/2507.23776)
*Yunxiang Yan,Tomohiro Sawada,Kartik Goyal*

Main category: cs.CL

TL;DR: 提出了一种名为“级联问题披露”的新框架，通过逐步揭示信息来评估语言模型的真实问题解决能力，而不是仅仅依赖问答基准测试。实验表明，该框架能更准确地比较模型，并减少模型间的性能差异估计。


<details>
  <summary>Details</summary>
Motivation: 传统的问答基准测试虽然能自动、可扩展地比较语言模型，但它是评估其潜在解决问题能力的间接方法。因此，需要一种更准确、更具可扩展性和自动化性的评估框架。

Method: 提出了一种基于“级联问题披露”的整体且可推广的框架，通过分阶段收集模型响应，每个阶段逐步揭示关于问题的部分信息，以引发语言模型中的泛化推理，从而更准确地估计模型的解决问题能力，同时保持了可扩展性和自动化。

Result: 该方法在各种推理和知识密集型问答数据集上进行了实证验证，通过比较不同大小和系列的语言模型，发现与标准问答评估相比，该方法不仅提供了更好的语言模型比较，还能诱导出更好的中间跟踪，并缩小了性能差距。

Conclusion: 该方法不仅能更好地比较语言模型，还能在模型中诱导出比标准问答范例更好的中间跟踪。该方法缩小了在标准问答评估设置中观察到的性能差距，表明普遍存在的评估范例高估了模型之间的性能差异。

Abstract: While question-answering~(QA) benchmark performance is an automatic and
scalable method to compare LLMs, it is an indirect method of evaluating their
underlying problem-solving capabilities. Therefore, we propose a holistic and
generalizable framework based on \emph{cascaded question disclosure} that
provides a more accurate estimate of the models' problem-solving capabilities
while maintaining the scalability and automation. This approach collects model
responses in a stagewise manner with each stage revealing partial information
about the question designed to elicit generalized reasoning in LLMs. We find
that our approach not only provides a better comparison between LLMs, but also
induces better intermediate traces in models compared to the standard QA
paradigm. We empirically verify this behavior on diverse reasoning and
knowledge-heavy QA datasets by comparing LLMs of varying sizes and families.
Our approach narrows the performance gap observed in the standard QA evaluation
settings, indicating that the prevalent indirect QA paradigm of evaluation
overestimates the differences in performance between models. We further
validate our findings by extensive ablation studies.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [164] [Competitive Bundle Trading](https://arxiv.org/abs/2507.23047)
*Yossi Azar,Niv Buchbinder,Roie Levin,Or Vardi*

Main category: cs.DS

TL;DR: 商家在线交易，有库存限制，能通过动态定价最大化利润。


<details>
  <summary>Details</summary>
Motivation: 研究在线交易问题中商家的利润最大化问题，特别是商家有库存限制且供应商和客户在线到达的情况。

Method: 提出了一种指数权重更新的动态定价方案，并通过与线性规划模型相结合进行分析。

Result: 设计了一种具有对数竞争比的算法，该算法几乎匹配了已知的下界，并将其扩展到激励兼容机制。

Conclusion: 本研究为商家提供了一种在线交易问题的算法，该算法在有库存限制的情况下，能够通过动态定价最大化利润。

Abstract: A retailer is purchasing goods in bundles from suppliers and then selling
these goods in bundles to customers; her goal is to maximize profit, which is
the revenue obtained from selling goods minus the cost of purchasing those
goods. In this paper, we study this general trading problem from the retailer's
perspective, where both suppliers and customers arrive online. The retailer has
inventory constraints on the number of goods from each type that she can store,
and she must decide upon arrival of each supplier/customer which goods to
buy/sell in order to maximize profit.
  We design an algorithm with logarithmic competitive ratio compared to an
optimal offline solution. We achieve this via an exponential-weight-update
dynamic pricing scheme, and our analysis dual fits the retailer's profit with
respect to a linear programming formulation upper bounding the optimal offline
profit. We prove (almost) matching lower bounds, and we also extend our result
to an incentive compatible mechanism. Prior to our work, algorithms for trading
bundles were known only for the special case of selling an initial inventory.

</details>


### [165] [Efficient algorithm for linear diophantine equations in two variables](https://arxiv.org/abs/2507.23216)
*Mayank Deora,Pinakpani Pal*

Main category: cs.DS

TL;DR: This paper optimizes an algorithm (DEA-R) for solving linear diophantine equations in two variables, resulting in DEA-OPTD and its iterative version DEA-OPTDI. DEA-OPTDI shows superior performance, outperforming existing methods on over 96% of tested inputs.


<details>
  <summary>Details</summary>
Motivation: The paper aims to take advantage of the fewer number of recursive calls in the DEA-R algorithm by proposing an optimized version (DEA-OPTD) and improving the efficiency of its recursive function calls.

Method: The paper proposes an optimized version of the DEA-R algorithm, called DEA-OPTD, which involves a sequence of more efficient computations in its recursive function calls. It also implements an iterative version, DEA-OPTDI, and compares it with two versions of a widely used algorithm on a specific input setting.

Result: A theoretical comparison of execution times between DEA-OPTD and DEA-R is performed to find bounds on the value of c for which DEA-OPTD is better. Empirical comparison shows DEA-OPTDI outperforms the other algorithm for at least 96% of inputs in a specific setting.

Conclusion: DEA-OPTDI outperforms the other algorithm against at least 96% of the inputs in the specific input setting.

Abstract: Solving linear diophantine equations in two variables have applications in
computer science and mathematics. In this paper, we revisit an algorithm for
solving linear diophantine equations in two variables, which we refer as DEA-R
algorithm. The DEA-R algorithm always incurs equal or less number of recursions
or recursive calls as compared to extended euclidean algorithm. With the
objective of taking advantage of the less number of recursive calls , we
propose an optimized version of the DEA-R algorithm as DEA-OPTD. In the
recursive function calls in DEA-OPTD, we propose a sequence of more efficient
computations. We do a theoretical comparison of the execution times of DEA-OPTD
algorithm and DEA-R algorithm to find any possible bound on the value of $c$
for DEA-OPTD being better than DEA-R. We implement and compare an iterative
version of DEA-OPTD (DEA-OPTDI) with two versions of a widely used algorithm on
an specific input setting. In this comparison, we find out that our algorithm
outperforms on the other algorithm against atleast 96% of the inputs.

</details>


### [166] [Scalable contribution bounding to achieve privacy](https://arxiv.org/abs/2507.23432)
*Vincent Cohen-Addad,Alessandro Epasto,Jason Lee,Morteza Zadimoghaddam*

Main category: cs.DS

TL;DR: 为了解决用户级差分隐私中的组合挑战，提出了一种新的分布式算法，将用户和记录建模为超图，并以轮次方式并行提议记录，以确保不违反用户的贡献限制。


<details>
  <summary>Details</summary>
Motivation: 在现代数据集中，单个记录可以有多个所有者，强制执行用户级差分隐私需要限制每个用户的总贡献。这种“贡献上限”成为一个重要的组合挑战。现有的顺序算法计算密集且无法扩展到当今普遍存在的大规模数据集。

Method: 将用户和记录分别建模为超图的顶点和超边，并采用分布式算法。该算法分轮进行，允许用户并行提议记录，仅当所有所有者一致同意时才将记录添加到最终数据集中，以确保任何用户的预定义贡献限制均不被违反。

Result: 提出了一种新颖高效的分布式算法，解决了可扩展性瓶颈。

Conclusion: 该方法旨在最大化结果数据集的大小以获得高实用性，同时为在大型、真实系统实现用户级隐私提供实用、可扩展的解决方案。

Abstract: In modern datasets, where single records can have multiple owners, enforcing
user-level differential privacy requires capping each user's total
contribution. This "contribution bounding" becomes a significant combinatorial
challenge. Existing sequential algorithms for this task are computationally
intensive and do not scale to the massive datasets prevalent today. To address
this scalability bottleneck, we propose a novel and efficient distributed
algorithm. Our approach models the complex ownership structure as a hypergraph,
where users are vertices and records are hyperedges. The algorithm proceeds in
rounds, allowing users to propose records in parallel. A record is added to the
final dataset only if all its owners unanimously agree, thereby ensuring that
no user's predefined contribution limit is violated. This method aims to
maximize the size of the resulting dataset for high utility while providing a
practical, scalable solution for implementing user-level privacy in large,
real-world systems.

</details>


### [167] [Nyldon Factorization of Thue-Morse Words and Fibonacci Words](https://arxiv.org/abs/2507.23659)
*Kaisei Kishi,Kazuki Kai,Yuto Nakashima,Shunsuke Inenaga,Hideo Bannai*

Main category: cs.DS

TL;DR: Nyldon 因子分解是受 Lyndon 因子分解启发的组合对象。该论文研究了斐波那契词和 Thue-Morse 词的 Nyldon 因子分解，并发现无限 Thue-Morse 词存在 Nyldon 因子分解。


<details>
  <summary>Details</summary>
Motivation: 受到 Lyndon 词和 Lyndon 因子分解的启发，研究新定义的组合对象 Nyldon 词和 Nyldon 因子分解。

Method: 通过研究斐波那契词和 Thue-Morse 词的 Nyldon 因子分解来表征它们，并证明了无限 Thue-Morse 词的 Nyldon 因子分解的存在性。

Result: 完全表征了斐波那契词和 Thue-Morse 词的 Nyldon 因子分解；证明了无限 Thue-Morse 词存在 Nyldon 词的非递减乘积因子分解。

Conclusion: 该论文研究了 Nyldon 因子分解，这是一种受著名 Lyndon 词和 Lyndon 因子分解启发的组合对象。研究人员对斐波那契词和 Thue-Morse 词的 Nyldon 因子分解进行了表征，并证明了无限 Thue-Morse 词存在 Nyldon 词的非递减乘积因子分解。

Abstract: The Nyldon factorization is a string factorization that is a non-decreasing
product of Nyldon words. Nyldon words and Nyldon factorizations are recently
defined combinatorial objects inspired by the well-known Lyndon words and
Lyndon factorizations. In this paper, we investigate the Nyldon factorization
of several words. First, we fully characterize the Nyldon factorizations of the
(finite) Fibonacci and the (finite) Thue-Morse words. Moreover, we show that
there exists a non-decreasing product of Nyldon words that is a factorization
of the infinite Thue-Morse word.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [168] [Clock Pulling Enables Maximum-Efficiency Wireless Power Transfer](https://arxiv.org/abs/2507.22907)
*Xianglin Hao,Xiaosheng Wang,ke Yin,Sheng Ren,Chaoqiang Jiang,Jianlong Zou,Tianyu Dong,Chi Kong Tse*

Main category: physics.app-ph

TL;DR: 非线性PT对称无线能量传输系统存在稳定性问题，新发现的时钟牵制机制可用于稳定系统并提高效率。


<details>
  <summary>Details</summary>
Motivation: 为了应对非线性PT对称无线能量传输（WPT）系统中存在的复杂动力学机制带来的理论和实践挑战。

Method: 研究方法包括重新审视非线性非厄米系统中的多稳态现象，并发现一种新的非线性时钟牵制机制。

Result: 成功发现了一种非线性时钟牵制机制，该机制能够强制打破PT对称性，并可调控系统稳定性，以稳定具有最大传输效率的传统不稳定状态。

Conclusion: 该研究揭示了非线性PT对称状态并非总是在PT对称相位中稳定，并发现了一种可以强制打破PT对称性的非线性时钟牵制机制。通过实现该机制，可以有效调控系统稳定性，特别是稳定具有最大传输效率的传统不稳定状态。

Abstract: Nonlinear parity-time (PT) symmetry in non-Hermitian wireless power transfer
(WPT) systems, while attracting significant attention from both physics and
engineering communities, have posed formidable theoretical and practical
challenges due to their complex dynamical mechanisms. Here, we revisit
multistability in nonlinear non-Hermitian systems and find that the PT-symmetry
state is not always stable even in PT-symmetry phase. We report a discovery on
a nonlinear clock-pulling mechanism, which can forcibly break the PT symmetry.
Proper implementation of this mechanism can switch the system stability,
particularly in stabilizing the conventional unstable state which has the
maximum transfer efficiency for WPT. Our work offers new tools for
non-Hermitian physics and is expected to drive technological progress.

</details>


### [169] [Characterisation of commercial SiC MOSFETs at deep-cryogenic temperatures](https://arxiv.org/abs/2507.23109)
*Megan Powell,Euan Parry,Conor McGeough,Alexander Zotov,Alessandro Rossi*

Main category: physics.app-ph

TL;DR: 碳化硅MOSFET在低温下性能下降，可能不适用于量子电子学。


<details>
  <summary>Details</summary>
Motivation: 碳化硅作为一种宽禁带半导体，在电力电子和恶劣环境电子学中有广泛应用，并且其晶体缺陷可作为量子技术中的自旋量子比特或单光子源。本研究旨在评估商用功率MOSFETs在低温下的性能，以确定其在兼容CMOS的量子电子学中的适用性。

Method: 本研究通过统计学方法，在300 K至650 mK的温度范围内，对商用碳化硅功率MOSFETs的阈值电压和亚阈值摆幅进行了评估，重点关注其可重复性和变异性。

Result: 结果显示，在低温下，这些MOSFETs的性能出现显著下降，具体表现为大的栅极滞后、阈值电压的显著偏移以及亚阈值摆幅的恶化。

Conclusion: 本工作评估了商用碳化硅功率MOSFETs在低温下的性能，发现在低至650 mK时，器件表现出显著的性能下降，包括栅极滞后、阈值电压漂移和亚阈值摆幅恶化。这些现象表明器件的静电控制不稳定，可能是由于载流子冻结和高界面陷阱密度引起，这给该晶体管技术在量子器件或低温CMOS电子学中的可靠应用带来了挑战。

Abstract: Silicon carbide is a wide-bandgap semiconductor with an emerging CMOS
technology platform and it is widely deployed in high power and harsh
environment electronics. This material is also attracting interest for quantum
technologies through its crystal defects, which can act as spin-based qubits or
single-photon sources. In this work, we assess the cryogenic performance of
commercial power MOSFETs to evaluate their suitability for CMOS-compatible
quantum electronics. We perform a statistical study of threshold voltage and
subthreshold swing from 300 K down to 650 mK, focusing on reproducibility and
variability. Our results show significant performance degradation at low
temperatures, including large gate hysteresis, threshold voltage shifts, and
subthreshold swing deterioration. These effects suggest instability in
electrostatic control, likely due to carrier freeze-out and high interface trap
density, which may pose challenges for the reliable use of this transistor
technology towards the realisation of quantum devices or cryo-CMOS electronics.

</details>


### [170] [Wave propagation in an elastic lattice with non-reciprocal stiffness and engineered damping](https://arxiv.org/abs/2507.23761)
*Harshit Kumar Sandhu,Saurav Dutta,Rajesh Chaunsali*

Main category: physics.app-ph

TL;DR: 研究了弹性格栅中的非互易波传播，发现非互易刚度和非互易阻尼可以分离控制波的放大率、群速度和频率，并观察到增强放大率和波混合等现象，为设计有源超材料提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 研究非互易波传播以实现定向能量传输，并探索非互易刚度与非互易阻尼共存对波动力学的影响。

Method: 系统研究了结合了非互易刚度和粘性阻尼的弹性格栅中的波动力学，并引入了陀螺阻尼这一非耗散形式的非互易阻尼。

Result: 发现非互易刚度控制时间放大率，非互易阻尼独立调节波的群速度和振荡频率，实现了分离控制，并出现了净放大率随慢速传播波增强以及边界诱导波混合等现象。

Conclusion: 本研究为设计具有更灵活波传播特性控制的有源超材料提供了理论框架。

Abstract: Nonreciprocal wave propagation allows for directional energy transport. In
this work, we systematically investigate wave dynamics in an elastic lattice
that combines nonreciprocal stiffness with viscous damping. After establishing
how conventional damping counteracts the system's gain, we introduce a
non-dissipative form of nonreciprocal damping in the form of gyroscopic
damping. We find that the coexistence of nonreciprocal stiffness and
nonreciprocal damping results in a decoupled control mechanism. The
nonreciprocal stiffness is shown to govern the temporal amplification rate,
while the nonreciprocal damper independently tunes the wave's group velocity
and oscillation frequency. This decoupling gives rise to phenomena such as the
enhancement of net amplification for slower-propagating waves and
boundary-induced wave mixing. These findings provide a theoretical framework
for designing active metamaterials with more versatile control over their wave
propagation characteristics.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [171] [Noise-Coded Illumination for Forensic and Photometric Video Analysis](https://arxiv.org/abs/2507.23002)
*Peter F. Michael,Zekun Hao,Serge Belongie,Abe Davis*

Main category: cs.GR

TL;DR: Subtle modulations in scene illumination act as temporal watermarks, encoding the scene's appearance under that illumination. This helps verify video authenticity by creating an information asymmetry that hinders malicious manipulation, even when adversaries know the technique is in use.


<details>
  <summary>Details</summary>
Motivation: The proliferation of advanced video manipulation tools has led to an arms race where fake videos are becoming increasingly difficult to distinguish from real ones. Manipulators have an advantage due to equal access to authentic video distributions. This work aims to combat this by creating an information asymmetry that favors verification.

Method: Our approach involves coding very subtle, noise-like modulations into the illumination of a scene. This creates a temporal watermark that encodes an image of the unmanipulated scene as it would appear lit only by the coded illumination.

Result: We show that our technique makes it significantly harder for adversaries to create plausible fake videos, even if they are aware of the method. Creating a fake video becomes a more difficult problem with an information disadvantage.

Conclusion: Our approach effectively adds a temporal watermark to any video recorded under coded illumination, encoding an image of the unmanipulated scene as it would appear lit only by the coded illumination. This technique creates an information asymmetry that favors verification, making it difficult for adversaries to create plausible fake videos even if they know the technique is being used. This is a promising avenue for protecting high-stakes settings where video manipulation is a concern and illumination can be controlled.

Abstract: The proliferation of advanced tools for manipulating video has led to an arms
race, pitting those who wish to sow disinformation against those who want to
detect and expose it. Unfortunately, time favors the ill-intentioned in this
race, with fake videos growing increasingly difficult to distinguish from real
ones. At the root of this trend is a fundamental advantage held by those
manipulating media: equal access to a distribution of what we consider
authentic (i.e., "natural") video. In this paper, we show how coding very
subtle, noise-like modulations into the illumination of a scene can help combat
this advantage by creating an information asymmetry that favors verification.
Our approach effectively adds a temporal watermark to any video recorded under
coded illumination. However, rather than encoding a specific message, this
watermark encodes an image of the unmanipulated scene as it would appear lit
only by the coded illumination. We show that even when an adversary knows that
our technique is being used, creating a plausible coded fake video amounts to
solving a second, more difficult version of the original adversarial content
creation problem at an information disadvantage. This is a promising avenue for
protecting high-stakes settings like public events and interviews, where the
content on display is a likely target for manipulation, and while the
illumination can be controlled, the cameras capturing video cannot.

</details>


### [172] [XSpecMesh: Quality-Preserving Auto-Regressive Mesh Generation Acceleration via Multi-Head Speculative Decoding](https://arxiv.org/abs/2507.23777)
*Dian Chen,Yansong Qu,Xinyang Li,Ming Li,Shengchuan Zhang*

Main category: cs.GR

TL;DR: XSpecMesh通过推测解码和验证/重采样策略加速了自回归网格生成，实现了1.7倍的速度提升，且不影响质量。


<details>
  <summary>Details</summary>
Motivation: 当前的自回归模型在生成高质量、拓扑精确的网格时，需要数千甚至数万次next-token预测，导致显著的延迟。

Method: XSpecMesh采用轻量级的多头推测解码方案，在单次前向传播中并行预测多个token以加速推理。此外，还提出了一种验证和重采样策略，主干模型会验证每个预测的token，并对不满足质量标准的token进行重采样。同时，还提出了一种蒸馏策略，通过主干模型蒸馏来训练轻量级的解码头，以提高推测预测的成功率。

Result: 实验证明，XSpecMesh实现了1.7倍的加速，且生成质量没有下降。

Conclusion: XSpecMesh实现了1.7倍的加速，同时不牺牲生成质量。

Abstract: Current auto-regressive models can generate high-quality, topologically
precise meshes; however, they necessitate thousands-or even tens of
thousands-of next-token predictions during inference, resulting in substantial
latency. We introduce XSpecMesh, a quality-preserving acceleration method for
auto-regressive mesh generation models. XSpecMesh employs a lightweight,
multi-head speculative decoding scheme to predict multiple tokens in parallel
within a single forward pass, thereby accelerating inference. We further
propose a verification and resampling strategy: the backbone model verifies
each predicted token and resamples any tokens that do not meet the quality
criteria. In addition, we propose a distillation strategy that trains the
lightweight decoding heads by distilling from the backbone model, encouraging
their prediction distributions to align and improving the success rate of
speculative predictions. Extensive experiments demonstrate that our method
achieves a 1.7x speedup without sacrificing generation quality. Our code will
be released.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [173] [Learning with Episodic Hypothesis Testing in General Games: A Framework for Equilibrium Selection](https://arxiv.org/abs/2507.23149)
*Ruifan Yang,Manxi Wu*

Main category: cs.GT

TL;DR: 一种新的基于假设检验的学习动态，可收敛于近似纳什均衡，并选择最大化最小效用的均衡。


<details>
  <summary>Details</summary>
Motivation: 为了研究一种新的学习动态，其中玩家结合假设检验和由效用驱动的探索来更新策略。

Method: 提出一种基于假设检验的学习动态，玩家结合假设检验和由效用驱动的探索来更新策略。在该动态中，每个玩家对对手的策略形成信念，并使用经验观察来 episodio地检验这些信念。当假设检验被拒绝或通过探索（其探索概率随着玩家的（转换后）效用而降低）时，信念会被重新采样。

Result: 在一般有限博弈中，证明了学习过程收敛于一组近似纳什均衡，并且能够选择最大化所有玩家最小（转换后）效用的均衡。

Conclusion: 该学习过程收敛于一组近似纳什均衡，更重要的是，收敛于一个选择最大化所有玩家最小（转换后）效用的均衡的精细化。结果证明了在一般有限博弈中收敛到均衡，并揭示了由学习动态结构引起的均衡选择的新机制。

Abstract: We introduce a new hypothesis testing-based learning dynamics in which
players update their strategies by combining hypothesis testing with
utility-driven exploration. In this dynamics, each player forms beliefs about
opponents' strategies and episodically tests these beliefs using empirical
observations. Beliefs are resampled either when the hypothesis test is rejected
or through exploration, where the probability of exploration decreases with the
player's (transformed) utility. In general finite normal-form games, we show
that the learning process converges to a set of approximate Nash equilibria
and, more importantly, to a refinement that selects equilibria maximizing the
minimum (transformed) utility across all players. Our result establishes
convergence to equilibrium in general finite games and reveals a novel
mechanism for equilibrium selection induced by the structure of the learning
dynamics.

</details>


### [174] [Online Combinatorial Allocation with Interdependent Values](https://arxiv.org/abs/2507.23500)
*Michal Feldman,Simon Mauras,Divyarthi Mohan,Rebecca Reiffenhäuser*

Main category: cs.GT

TL;DR: 本文将秘书分配问题扩展到组合分配和相互依赖价值，提供了$2e$-竞争性算法，并为在线二分匹配设计了$4e$-竞争性机制。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决在线组合分配问题，尤其是在秘书设置和相互依赖价值的框架下。研究人员希望在保留现有算法近似保证的同时，将这些模型扩展到更复杂的组合结构和相互依赖性。

Method: 研究探索了在线组合分配问题，特别是在秘书设置和相互依赖价值的背景下。研究人员提供了$2e$-竞争性算法，适用于次模和XOS函数等估值函数。他们还将研究扩展到战略设定，并针对具有相互依赖价值的在线二分匹配问题设计了一个$4e$-竞争性公平机制。

Result: 研究提出了$2e$-竞争性算法，适用于次模和XOS等估值函数，在组合秘书问题中实现了与单一选择情况相匹配的近似保证。对于在线二分匹配问题，该研究还提供了一个$4e$-竞争性的公平机制，证明了相互依赖性引入的额外挑战可以通过先进的算法来应对。

Conclusion: 该研究将秘书设定下的在线组合分配问题扩展到具有相互依赖价值的情况，并为广泛的估值函数（包括次模和XOS函数）提供了$2e$-竞争性算法，这与单一选择的秘书设定的近似保证相匹配。此外，该研究还将结果扩展到战略设定，并为具有相互依赖价值的在线二分匹配问题提供了一个$4e$-竞争性的公平机制。

Abstract: We study online combinatorial allocation problems in the secretary setting,
under interdependent values. In the interdependent model, introduced by Milgrom
and Weber (1982), each agent possesses a private signal that captures her
information about an item for sale, and the value of every agent depends on the
signals held by all agents. Mauras, Mohan, and Reiffenh\"auser (2024) were the
first to study interdependent values in online settings, providing
constant-approximation guarantees for secretary settings, where agents arrive
online along with their signals and values, and the goal is to select the agent
with the highest value.
  In this work, we extend this framework to {\em combinatorial} secretary
problems, where agents have interdependent valuations over {\em bundles} of
items, introducing additional challenges due to both combinatorial structure
and interdependence. We provide $2e$-competitive algorithms for a broad class
of valuation functions, including submodular and XOS functions, matching the
approximation guarantees in the single-choice secretary setting. Furthermore,
our results cover the same range of valuation classes for which constant-factor
algorithms exist in classical (non-interdependent) secretary settings, while
incurring only an additional factor of $2$ due to interdependence. Finally, we
extend our study to strategic settings, and provide a $4e$-competitive truthful
mechanism for online bipartite matching with interdependent valuations, again
meeting the frontier of what is known, even without interdependence.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [175] [Rethink Domain Generalization in Heterogeneous Sequence MRI Segmentation](https://arxiv.org/abs/2507.23110)
*Zheyuan Zhang,Linkai Peng,Wanying Dou,Cuiling Sun,Halil Ertugrul Aktas,Andrea M. Bejar,Elif Keles,Gorkem Durak,Ulas Bagci*

Main category: eess.IV

TL;DR: PancreasDG是一个大规模多中心3D MRI胰腺分割数据集，用于研究医学影像中的域泛化。研究发现跨序列变化是主要挑战，并提出了一个半监督方法，显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有医学影像域泛化研究中对跨序列变化考虑不足的问题，以及胰腺分割在腹部成像中的挑战性，提出PancreasDG数据集和相应的模型。

Method: 提出了一种半监督方法，该方法利用了解剖不变性，并在跨序列分割方面取得了61.63%的Dice分数提升和87.00%的测试中心性能。

Result: 研究结果表明，有限的采样会引入显著的方差，可能被误认为是分布变化；在相同序列下，跨中心性能与源域性能相关；跨序列变化需要专门的解决方案。

Conclusion: PancreasDG数据集为医学影像中的域泛化设定了新基准，并提出了一个半监督方法，在跨序列分割方面取得了显著的改进。

Abstract: Clinical magnetic-resonance (MR) protocols generate many T1 and T2 sequences
whose appearance differs more than the acquisition sites that produce them.
Existing domain-generalization benchmarks focus almost on cross-center shifts
and overlook this dominant source of variability. Pancreas segmentation remains
a major challenge in abdominal imaging: the gland is small, irregularly,
surrounded by organs and fat, and often suffers from low T1 contrast.
State-of-the-art deep networks that already achieve >90% Dice on the liver or
kidneys still miss 20-30% of the pancreas. The organ is also systematically
under-represented in public cross-domain benchmarks, despite its clinical
importance in early cancer detection, surgery, and diabetes research. To close
this gap, we present PancreasDG, a large-scale multi-center 3D MRI pancreas
segmentation dataset for investigating domain generalization in medical
imaging. The dataset comprises 563 MRI scans from six institutions, spanning
both venous phase and out-of-phase sequences, enabling study of both
cross-center and cross-sequence variations with pixel-accurate pancreas masks
created by a double-blind, two-pass protocol. Through comprehensive analysis,
we reveal three insights: (i) limited sampling introduces significant variance
that may be mistaken for distribution shifts, (ii) cross-center performance
correlates with source domain performance for identical sequences, and (iii)
cross-sequence shifts require specialized solutions. We also propose a
semi-supervised approach that leverages anatomical invariances, significantly
outperforming state-of-the-art domain generalization techniques with 61.63%
Dice score improvements and 87.00% on two test centers for cross-sequence
segmentation. PancreasDG sets a new benchmark for domain generalization in
medical imaging. Dataset, code, and models will be available at
https://pancreasdg.netlify.app.

</details>


### [176] [Towards High-Resolution Alignment and Super-Resolution of Multi-Sensor Satellite Imagery](https://arxiv.org/abs/2507.23150)
*Philip Wootaek Shin,Vishal Gaur,Rahul Ramachandran,Manil Maskey,Jack Sampson,Vijaykrishnan Narayanan,Sujit Roy*

Main category: eess.IV

TL;DR: 提出了一种利用 HLS10 影像提高 HLS30 影像分辨率和质量的框架，以应对异构卫星传感器之间的挑战。


<details>
  <summary>Details</summary>
Motivation: 为了解决高分辨率卫星图像中不同传感器之间空间分辨率差异带来的数据融合和下游应用挑战。

Method: 开发了一个框架，以 10 米 HLS（HLS10）为参考，对齐和融合 30 米 HLS（HLS 30）影像，以解决不同传感器之间的分辨率差距。

Result: 提出的方法在定量和定性评估中被证明是有效的，展示了其在增强卫星传感应用方面的潜力。

Conclusion: 该研究为异构卫星图像超分辨率的可行性提供了见解，并强调了该领域未来发展的关键考虑因素。

Abstract: High-resolution satellite imagery is essential for geospatial analysis, yet
differences in spatial resolution across satellite sensors present challenges
for data fusion and downstream applications. Super-resolution techniques can
help bridge this gap, but existing methods rely on artificially downscaled
images rather than real sensor data and are not well suited for heterogeneous
satellite sensors with differing spectral, temporal characteristics. In this
work, we develop a preliminary framework to align and Harmonized Landsat
Sentinel 30m(HLS 30) imagery using Harmonized Landsat Sentinel 10m(HLS10) as a
reference from the HLS dataset. Our approach aims to bridge the resolution gap
between these sensors and improve the quality of super-resolved Landsat
imagery. Quantitative and qualitative evaluations demonstrate the effectiveness
of our method, showing its potential for enhancing satellite-based sensing
applications. This study provides insights into the feasibility of
heterogeneous satellite image super-resolution and highlights key
considerations for future advancements in the field.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [177] [From Propagator to Oscillator: The Dual Role of Symmetric Differential Equations in Neural Systems](https://arxiv.org/abs/2507.22916)
*Kun Jiang*

Main category: cs.NE

TL;DR: 本研究基于先前提出的对称微分方程神经元模型，通过参数空间探索和数学分析，揭示了其功能双重性（信号传播和信号生成）。引入了“on-road energy”度量来监控状态，并展示了模式转换和振荡抑制的可控性，该模型可应用于神经形态工程。


<details>
  <summary>Details</summary>
Motivation: 在先前工作的基础上，深入研究了该模型（基于对称微分方程）的内在动力学和功能多样性。

Method: 通过系统地探索参数空间并利用一系列数学分析工具，揭示了模型的功能双重性。

Result: 模型表现出两种不同的轨迹行为：一种是渐近稳定（可靠的信号传播器），另一种是李亚普诺夫稳定（具有持续的自激振荡，作为信号发生器）。引入了“on-road energy”作为中间状态度量。通过调整参数、连接结构或引入外部信号，可以诱导模式转换并抑制振荡。

Conclusion: 该模型具有双重功能，即信号传播和信号生成，并提供了一种新的中间状态度量“on-road energy”以进行监控和预测。通过调整参数或连接结构，或通过引入外部信号，可以控制模型的状态转换和振荡，这与生物神经元的双重作用相似，为神经形态工程中的模型应用奠定了基础。

Abstract: In our previous work, we proposed a novel neuron model based on symmetric
differential equations and demonstrated its potential as an efficient signal
propagator. Building upon that foundation, the present study delves deeper into
the intrinsic dynamics and functional diversity of this model. By
systematically exploring the parameter space and employing a range of
mathematical analysis tools, we theoretically reveal the system 's core
property of functional duality. Specifically, the model exhibits two distinct
trajectory behaviors: one is asymptotically stable, corresponding to a reliable
signal propagator; the other is Lyapunov stable, characterized by sustained
self-excited oscillations, functioning as a signal generator. To enable
effective monitoring and prediction of system states during simulations, we
introduce a novel intermediate-state metric termed on-road energy. Simulation
results confirm that transitions between the two functional modes can be
induced through parameter adjustments or modifications to the connection
structure. Moreover, we show that oscillations can be effectively suppressed by
introducing external signals. These findings draw a compelling parallel to the
dual roles of biological neurons in both information transmission and rhythm
generation, thereby establishing a solid theoretical basis and a clear
functional roadmap for the broader application of this model in neuromorphic
engineering.

</details>


### [178] [Hybrid Particle Swarm Optimization for Fast and Reliable Parameter Extraction in Thermoreflectance](https://arxiv.org/abs/2507.22960)
*Bingjia Xiao,Tao Chen,Wenbin Zhang,Xin Qian,Puqing Jiang*

Main category: cs.NE

TL;DR: FDTR参数提取是一个复杂的非线性逆问题。本研究提出了结合全局和局部优化算法的混合方法，其中HPSO表现出最佳性能，收敛速度快且鲁棒性强，为热测量逆问题提供了一个通用的解决方案。


<details>
  <summary>Details</summary>
Motivation: 光频域热反射率（FDTR）是一种广泛用于表征多层薄膜热性质的技术。然而，由于其高维度以及多模态、非凸解空间，从FDTR测量中提取多个参数是一个非线性逆问题。

Method: 本研究评估了四种流行的全局优化算法（遗传算法、量子遗传算法、粒子群优化和烟花算法）在从GaN/Si异质结构的光频域热反射率测量中提取参数方面的性能。为了提高收敛速度和精度，提出了一种人工智能驱动的混合优化框架，将每种全局算法与准牛顿局部优化方法相结合，产生了四种混合变体：HGA、HQGA、HPSO和HFWA。

Result: HPSO在所有方法中表现最佳，80%的试验在60秒内达到目标适应度值，表现出更强的鲁棒性，并且过早收敛的风险更低。相比之下，只有30%的HGA和HQGA试验以及20%的HFWA试验达到了这个阈值。当试验时间延长至1000秒时，只有HPSO、PSO和HGA能够持续达到目标精度，其中HPSO的收敛速度是其他算法的五倍。

Conclusion: HPSO在逆问题热学测量中是一种通用的解决方案，并且可以轻松地扩展到其他模型拟合技术。

Abstract: Frequency-domain thermoreflectance (FDTR) is a widely used technique for
characterizing thermal properties of multilayer thin films. However, extracting
multiple parameters from FDTR measurements presents a nonlinear inverse problem
due to its high dimensionality and multimodal, non-convex solution space. This
study evaluates four popular global optimization algorithms: Genetic Algorithm
(GA), Quantum Genetic Algorithm (QGA), Particle Swarm Optimization (PSO), and
Fireworks Algorithm (FWA), for extracting parameters from FDTR measurements of
a GaN/Si heterostructure. However, none achieve reliable convergence within 60
seconds. To improve convergence speed and accuracy, we propose an AI-driven
hybrid optimization framework that combines each global algorithm with a
Quasi-Newton local refinement method, resulting in four hybrid variants: HGA,
HQGA, HPSO, and HFWA. Among these, HPSO outperforms all other methods, with 80%
of trials reaching the target fitness value within 60 seconds, showing greater
robustness and a lower risk of premature convergence. In contrast, only 30% of
HGA and HQGA trials and 20% of HFWA trials achieve this threshold. We then
evaluate the worst-case performance across 100 independent trials for each
algorithm when the time is extended to 1000 seconds. Only HPSO, PSO, and HGA
consistently reach the target accuracy, with HPSO converging five times faster
than the others. HPSO provides a general-purpose solution for inverse problems
in thermal metrology and can be readily extended to other model-fitting
techniques.

</details>


### [179] [Finger Force Decoding from Motor Units Activity on Neuromorphic Hardware](https://arxiv.org/abs/2507.23474)
*Farah Baracat,Giacomo Indiveri,Elisa Donati*

Main category: cs.NE

TL;DR: 一种新的基于运动神经元脉冲序列的低功耗、实时手指力回归方法，在神经形态硬件上实现了准确预测。


<details>
  <summary>Details</summary>
Motivation: 传统基于深度学习的肌电图解码方法需要大量数据集和高计算资源，限制了其在实时嵌入式系统中的应用。

Method: 提出一种新方法，使用从高密度肌电图中提取的单个运动神经元的脉冲发放序列进行手指力回归，并将该方法在混合信号神经形态处理器上实现的脉冲神经网络。

Result: 在神经形态硬件上实现了基于运动神经元的连续回归，手指力预测准确，能耗低。

Conclusion: 通过单个运动神经元的脉冲发放序列，可以实现低功耗、实时的手指力回归，这为假肢和可穿戴神经技术中的嵌入式解码提供了新的可能性。

Abstract: Accurate finger force estimation is critical for next-generation
human-machine interfaces. Traditional electromyography (EMG)-based decoding
methods using deep learning require large datasets and high computational
resources, limiting their use in real-time, embedded systems. Here, we propose
a novel approach that performs finger force regression using spike trains from
individual motor neurons, extracted from high-density EMG. These biologically
grounded signals drive a spiking neural network implemented on a mixed-signal
neuromorphic processor. Unlike prior work that encodes EMG into events, our
method exploits spike timing on motor units to perform low-power, real-time
inference. This is the first demonstration of motor neuron-based continuous
regression computed directly on neuromorphic hardware. Our results confirm
accurate finger-specific force prediction with minimal energy use, opening new
possibilities for embedded decoding in prosthetics and wearable
neurotechnology.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [180] [Dynamical freezing and enhanced magnetometry in an interacting spin ensemble](https://arxiv.org/abs/2507.22982)
*Ya-Nan Lu,Dong Yuan,Yixuan Ma,Yan-Qing Liu,Si Jiang,Xiang-Qian Meng,Yi-Jie Xu,Xiu-Ying Chang,Chong Zu,Hong-Zheng Zhao,Dong-Ling Deng,Lu-Ming Duan,Pan-Yu Hou*

Main category: quant-ph

TL;DR: 量子多体系统中的非平衡动力学研究对于量子技术至关重要。本研究首次在实验中观察到一种名为“动力学冻结”的现象，该现象可以阻止系统热化。利用此现象，我们开发了一种新的量子传感技术（交流磁力测量），其性能超越了现有技术。


<details>
  <summary>Details</summary>
Motivation: 为了在量子多体系统中理解和控制非平衡动力学，特别是在周期性驱动系统中，以克服热化到“无限温度”状态的普遍现象。

Method: 通过精确控制驱动频率和失谐，在约 $10^4$ 个相互作用的金刚石氮空位自旋系综中，实验观察并利用了动力学冻结现象。

Result: 观察到动力学冻结，表现为长寿命自旋磁化和相干振荡微运动，其持续时间是相互作用限制相干时间（$T_2$）的十倍以上，并成功开发出一种超越 $T_2$ 的动力学冻结增强交流磁力测量技术，灵敏度比常规动力学解耦磁力测量提高了 4.3 dB。

Conclusion: 本研究在量子传感领域取得了显著进展，开发了一种基于动力学冻结的交流磁力测量技术，其传感时间超越了相干时间 $T_2$，并将灵敏度提高了 4.3 dB。

Abstract: Understanding and controlling non-equilibrium dynamics in quantum many-body
systems is a fundamental challenge in modern physics, with profound
implications for advancing quantum technologies. Typically, periodically driven
systems in the absence of conservation laws thermalize to a featureless
"infinite-temperature" state, erasing all memory of their initial conditions.
However, this paradigm can break down through mechanisms such as integrability,
many-body localization, quantum many-body scars, and Hilbert space
fragmentation. Here, we report the experimental observation of dynamical
freezing, a distinct mechanism of thermalization breakdown in driven systems,
and demonstrate its application in quantum sensing using an ensemble of
approximately $10^4$ interacting nitrogen-vacancy spins in diamond. By
precisely controlling the driving frequency and detuning, we observe emergent
long-lived spin magnetization and coherent oscillatory micromotions, persisting
over timescales exceeding the interaction-limited coherence time ($T_2$) by
more than an order of magnitude. Leveraging these unconventional dynamics, we
develop a dynamical-freezing-enhanced ac magnetometry that extends optimal
sensing times far beyond $T_2$, outperforming conventional dynamical decoupling
magnetometry with a 4.3 dB sensitivity enhancement. Our results not only
provide clear experimental observation of dynamical freezing -- a peculiar
mechanism defying thermalization through emergent conservation laws -- but also
establish a robust control method generally applicable to diverse physical
platforms, with broad implications in quantum metrology and beyond.

</details>


### [181] [Field digitization scaling in a $\mathbb{Z}_N \subset U(1)$ symmetric model](https://arxiv.org/abs/2507.22984)
*Gabriele Calliari,Robert Ott,Hannes Pichler,Torsten V. Zache*

Main category: quant-ph

TL;DR: 本研究提出了场数码化缩减（FD）的重整化群（RG）分析框架，引入了场数码化缩减标度（FDS）方法，实现了不同N正则化模型数据的关联，并成功应用于分析了RG诱导的非传统普适交叉现象，为量子模拟应用开辟了道路。


<details>
  <summary>Details</summary>
Motivation: 为了解决场数码化（FD）——一种将局部场截断为N个离散值的方法——在获取连续性结果方面缺乏全面框架的问题，本研究旨在提出一种分析FD的方法。

Method: 该研究使用张量网络计算（有限键维度χ）结合有效场论和重整化群（RG）方法，推导了涉及场数码化缩减参数N的广义标度假设，并提出了场数码化缩减标度（FDS）方法来分析FD模型。

Result: 研究通过数值张量网络计算揭示了由有限N引起的低温相变的非传统普适交叉现象，并证明了FDS可以扩展到描述χ和N的相互作用。同时，证明了2D经典统计Z_N时钟模型与(2+1)D Z_N格点规范场论基态量子物理的直接联系。

Conclusion: 该研究提出了场数码化缩减（FD）的框架，将参数N解释为重整化群（RG）中的耦合，并引入了场数码化缩减标度（FDS）方法，实现了不同N正则化模型数据的关联，并成功应用于分析了RG诱导的非传统普适交叉现象，以及证明了2D经典统计Z_N时钟模型与(2+1)D Z_N格点规范场论基态量子物理的直接联系，为FDS在更高空间维度和更复杂模型中的量子模拟应用开辟了道路。

Abstract: The simulation of quantum field theories, both classical and quantum,
requires regularization of infinitely many degrees of freedom. However, in the
context of field digitization (FD) -- a truncation of the local fields to $N$
discrete values -- a comprehensive framework to obtain continuum results is
currently missing. Here, we propose to analyze FD by interpreting the parameter
$N$ as a coupling in the renormalization group (RG) sense. As a first example,
we investigate the two-dimensional classical $N$-state clock model as a
$\mathbb{Z}_N$ FD of the $U(1)$-symmetric $XY$-model. Using effective field
theory, we employ the RG to derive generalized scaling hypotheses involving the
FD parameter $N$, which allows us to relate data obtained for different
$N$-regularized models in a procedure that we term $\textit{field digitization
scaling}$ (FDS). Using numerical tensor-network calculations at finite bond
dimension $\chi$, we further uncover an unconventional universal crossover
around a low-temperature phase transition induced by finite $N$, demonstrating
that FDS can be extended to describe the interplay of $\chi$ and $N$. Finally,
we analytically prove that our calculations for the 2D classical-statistical
$\mathbb{Z}_N$ clock model are directly related to the quantum physics in the
ground state of a (2+1)D $\mathbb{Z}_N$ lattice gauge theory which serves as a
FD of compact quantum electrodynamics. Our study thus paves the way for
applications of FDS to quantum simulations of more complex models in higher
spatial dimensions, where it could serve as a tool to analyze the continuum
limit of digitized quantum field theories.

</details>


### [182] [Majorization theory for quasiprobabilities](https://arxiv.org/abs/2507.22986)
*Twesh Upadhyaya,Zacharie Van Herstraeten,Jack Davis,Oliver Hahn,Nikolaos Koukoulekidis,Ulysse Chabaud*

Main category: quant-ph

TL;DR: 我们成功地将优代理论扩展到连续类概率分布和无限测度空间，其在量子信息科学等领域有潜在应用。


<details>
  <summary>Details</summary>
Motivation: 为了将优代理论（一种用于比较分布混乱度的数学工具）扩展到量子力学、量子信息和信号处理等领域中至关重要的类概率分布，并将其应用于量子资源理论。

Method: 通过将 Hardy、Littlewood 和 P´olya 的经典定理推广到连续类概率分布和无限测度空间，我们证明了四种关于优代和相对优代定义的等价性。

Result: 在量子资源理论的背景下，我们得到了新的资源单调量和量子态转换的“no-go”结果。一个突出的例子是我们探索的量子光学中的 Wigner 函数。

Conclusion: 该研究为评估无限测度空间上可积函数的混乱度提供了广泛的优代框架。

Abstract: Majorization theory is a powerful mathematical tool to compare the disorder
in distributions, with wide-ranging applications in many fields including
mathematics, physics, information theory, and economics. While majorization
theory typically focuses on probability distributions, quasiprobability
distributions provide a pivotal framework for advancing our understanding of
quantum mechanics, quantum information, and signal processing. Here, we
introduce a notion of majorization for continuous quasiprobability
distributions over infinite measure spaces. Generalizing a seminal theorem by
Hardy, Littlewood, and P\'olya, we prove the equivalence of four definitions
for both majorization and relative majorization in this setting. We give
several applications of our results in the context of quantum resource
theories, obtaining new families of resource monotones and no-goes for quantum
state conversions. A prominent example we explore is the Wigner function in
quantum optics. More generally, our results provide an extensive majorization
framework for assessing the disorder of integrable functions over infinite
measure spaces.

</details>


### [183] [Probing Bound State Relaxation Dynamics in Systems Out-of-Equilibrium on Quantum Computers](https://arxiv.org/abs/2507.22988)
*Heba A. Labib,Goksu Can Toga,J. K. Freericks,A. F. Kemper*

Main category: quant-ph

TL;DR: 量子计算机可用于模拟混合场伊辛模型的泵浦-探测实验，研究 Bloch 振荡等非平衡现象。


<details>
  <summary>Details</summary>
Motivation: 利用量子计算机模拟量子多体系统（特别是混合场伊辛模型）的非平衡响应动力学，以理解其中出现的离散束缚态和假真空衰变现象。

Method: 使用量子计算机模拟泵浦-探测实验，研究混合场伊辛模型。通过激发系统、演化和测量观测量来研究离散束缚态的演化和假真空衰变，并分析 Bloch 振荡的出现。

Result: 在混合场伊辛模型中，发现了由纵向场引起的离散束缚态，并通过泵浦-探测实验研究了它们的演化。在假真空衰变的研究中，观察到了 Bloch 振荡，这解释了模型中长寿命的振荡现象。

Conclusion: 该研究展示了如何使用量子计算机模拟混合场伊辛模型中的泵浦-探测实验，并研究了离散束缚态的演化和假真空衰变现象，特别是 Bloch 振荡的出现及其对模型长寿命振荡的影响。研究结果表明，在没有辅助量子比特的情况下，量子计算机可以有效地模拟此类非平衡系统。

Abstract: Pump-probe spectroscopy is a powerful tool for probing response dynamics of
quantum many-body systems in and out-of-equilibrium. Quantum computers have
proved useful in simulating such experiments by exciting the system, evolving,
and then measuring observables to first order, all in one setting. Here, we use
this approach to investigate the mixed-field Ising model, where the
longitudinal field plays the role of a confining potential that prohibits the
spread of the excitations, spinons, or domain walls into space. We study the
discrete bound states that arise from such a setting and their evolution under
different quench dynamics by initially pumping the chain out of equilibrium and
then probing various non-equal time correlation functions. Finally, we study
false vacuum decay, where initially one expects unhindered propagation of the
ground state, or true vacuum, bubbles into the lattice, but instead sees the
emergence of Bloch oscillations that are directly the reason for the long-lived
oscillations in this finite-size model. Our work sets the stage for simulating
systems out-of-equilibrium on classical and quantum computers using pump-probe
experiments without needing ancillary qubits.

</details>


### [184] [Improved Simulation of Asynchronous Entanglement Distribution in Noisy Quantum Networks](https://arxiv.org/abs/2507.22992)
*Emma Hughes,William Munizzi,Prineha Narang*

Main category: quant-ph

TL;DR: A new simulation framework shows parallel entanglement distribution is better than sequential for a future quantum internet.


<details>
  <summary>Details</summary>
Motivation: To provide a lightweight and scalable simulation framework for evaluating the performance of asynchronous entanglement distribution protocols under realistic conditions, aiding in the development of a quantum Internet.

Method: A lightweight simulation framework was developed to evaluate asynchronous entanglement distribution protocols under realistic error models. The performance of sequential and parallel protocols was assessed using state fidelity and hashing rate across various network sizes and noise parameters. The simulation simplifies complex quantum processes into memory time calculations.

Result: The parallel entanglement distribution protocol demonstrated superior performance compared to the sequential protocol, particularly in terms of hashing rate, attributed to its shorter runtime. The simulation framework effectively reduced the complexity of evaluating quantum processes.

Conclusion: Asynchronous entanglement distribution protocols can be effectively evaluated using a lightweight simulation framework. The parallel protocol consistently outperforms the sequential protocol, especially in the hashing rate, due to reduced runtime, indicating its potential for a future quantum Internet. The proposed framework simplifies the simulation of complex quantum processes.

Abstract: This work introduces a lightweight simulation framework for evaluating
asynchronous entanglement distribution protocols under realistic error models.
We focus on two contemporary protocols: sequential, where entanglement is
established one node at a time, and parallel, where all nodes attempt to
generate entanglement simultaneously. We evaluate the performance of each
protocol using two key metrics: the fidelity of distributed entangled states,
and the hashing rate, a measure of entanglement efficiency. These metrics are
compared between both protocols across a range of network sizes and noise
parameters. We demonstrate that the parallel protocol consistently outperforms
the sequential, particularly in the hashing rate metric due to reduced runtime,
suggesting that parallel protocols are a strong candidate for a realizable
quantum Internet. Our framework offers an accessible and scalable tool for
evaluating entanglement distribution strategies, by reducing the simulation of
complex quantum processes to simple memory time calculations.

</details>


### [185] [Local-available quantum correlation swapping in one-parameter X states](https://arxiv.org/abs/2507.23142)
*Hermann L. Albrecht Q*

Main category: quant-ph

TL;DR: 研究了双量子比特X态的局域可用量子关联（LAQC）交换，发现当初始状态与用于投影测量的状态相关时，最终态的LAQC非零。


<details>
  <summary>Details</summary>
Motivation: 研究量子关联（QC），特别是局域可用量子关联（LAQC），及其在量子中继和交换协议中的应用。

Method: 分析了五类单参数双量子比特X态的LAQC交换过程。

Result: 找到了当初始状态和用于投影测量的状态相关时，最终状态的LAQC非零。

Conclusion: 通过对初始状态和用于投影测量的状态进行相关性分析，我们发现最终状态具有非零的局域可用量子关联（LAQC）。

Abstract: Although introduced originally for entanglement, quantum repeaters and
swapping protocols have been analyzed for other quantum correlations (QC), such
as quantum discord. Introduced by Mundarain and Ladr\'on de Guevara,
local-available quantum correlations (LAQC) are a promising yet understudied
quantum correlation. Recently, Bellor\'{\i}n et al. obtained exact analytical
results for the LAQC quantifier of general 2-qubit X states. Starting from
those previous results, we analyzed the LAQC swapping for five families of
one-parameter 2-qubit X states. As expected, we find that if the initial state
and the one used for the projective measurement are correlated, the final state
will have non-zero LAQC.

</details>


### [186] [Asymptotically optimal joint phase and dephasing strength estimation using spin-squeezed states](https://arxiv.org/abs/2507.22997)
*Arkadiusz Kobus,Rafał Demkowicz-Dobrzański*

Main category: quant-ph

TL;DR: 一项量子协议，可实现信号和信号衰减的同时估计，精度达到量子限制。


<details>
  <summary>Details</summary>
Motivation: 旨在实现信号和信号衰减的同时估计，以达到量子计量法的基本限制。

Method: 提出了一种涉及单轴扭转自旋压缩状态的显式N量子比特协议。

Result: 该协议实现了精度渐近匹配基本量子计量法限制的同步相位和去相干强度估计。

Conclusion: 该协议允许在信号和信号衰减的同时进行估计，并且精度渐近地匹配基本量子计量法的限制。此外，该协议的适用性超出了该特定模型，因为任何允许最多恒定渐近量子增强的不相关噪声量子计量模型都可以通过适当定制的量子误差校正程序简化为该问题。

Abstract: We show an explicit $N$-qubit protocol involving one-axis-twisted spin
squeezed states, that allows for simultaneous phase and dephasing strength
estimation with precision that asymptotically matches fundamental quantum
metrological bounds. The relevance of the protocol goes beyond this particular
model, since any uncorrelated noise quantum metrological model, that allows for
at most constant asymptotic quantum enhancement, can be reduced to this problem
via an appropriately tailored quantum error-correction procedure.

</details>


### [187] [Detecting quantum non-Gaussianity with a single quadrature](https://arxiv.org/abs/2507.23005)
*Clara Wassner,Jack Davis,Sacha Cerf,Ulysse Chabaud,Francesco Arzani*

Main category: quant-ph

TL;DR: 无需进行复杂的量子态重构，只需通过单正交测量即可检测玻色子系统中的非高斯性。


<details>
  <summary>Details</summary>
Motivation: 为了简化从测量样本中完全重构量子状态的复杂性，研究了仅使用不完全代表性的测量来认证特定应用的量，特别是关注简化认证玻色子系统中非高斯性所需的测量。

Method: 利用单正交测量统计数据和哈德逊定理的一个版本来证明非高斯性，并分析了样本复杂性、噪声鲁棒性和实验前景。

Result: 证明了单正交测量统计数据可以证明任意程度的非高斯性（以星状秩量化），并且具有有界能量和有限星状秩的状态集是紧致的，这为所提出的检测方法提供了理论支持。

Conclusion: 该研究表明，仅通过单正交测量统计数据即可证明玻色子系统中的非高斯性，从而大大简化了检测量子非高斯性的实验设置。

Abstract: Full reconstruction of quantum states from measurement samples is often a
prohibitively complex task, both in terms of the experimental setup and the
scaling of the sample size with the system. This motivates the relatively
easier task of certifying application-specific quantities using measurements
that are not tomographically complete, i.e. that provide only partial
information about the state related to the application of interest. Here, we
focus on simplifying the measurements needed to certify non-Gaussianity in
bosonic systems, a resource related to quantum advantage in various information
processing tasks. We show that the statistics of a single quadrature
measurement, corresponding to standard homodyne detection in quantum optics,
can witness arbitrary degrees of non-Gaussianity as quantified by stellar rank.
Our results are based on a version of Hudson's theorem for wavefunctions,
proved in a companion paper [1], revealing that the zeros in a homodyne
distribution are signatures of quantum non-Gaussianity and higher stellar
ranks. The validity of our witnesses is supported by a technical result showing
that sets of states with bounded energy and finite stellar rank are compact. We
provide an analysis of sample complexity, noise robustness, and experimental
prospects. Our work drastically simplifies the setup required to detect quantum
non-Gaussianity in bosonic quantum states. and experimental prospects. Our work
drastically simplifies the setup required to detect quantum non-Gaussianity in
bosonic quantum states.

</details>


### [188] [Amplitude amplification and estimation require inverses](https://arxiv.org/abs/2507.23787)
*Ewin Tang,John Wright*

Main category: quant-ph

TL;DR: 量子算法中的通用二次加速需要可逆过程。对于像量子学习和传感这样难以逆转的过程，量子加速可能不存在，除非可以访问逆过程。


<details>
  <summary>Details</summary>
Motivation: 探究量子搜索和计数问题的通用量子加速的适用范围，特别是当过程无法有效逆转时的情况。

Method: 利用 Zhandry 引入的压缩 Oracle 方法证明。

Result: 在基于迹估计的问题实例中，没有算法能在仅使用 $U$ 的情况下超越朴素的二次加速方法。这表明，在量子学习、计量学和传感等领域，由于 $U^	ä$ 的实现难度（等同于逆转时间），量子加速可能更难获得。

Conclusion: 量子算法中的二次加速（如 Grover 算法）在需要高效可逆过程的情况下才能实现。对于无法有效逆转过程（例如模拟现实世界系统演化）的问题，量子加速可能不存在。

Abstract: We prove that the generic quantum speedups for brute-force search and
counting only hold when the process we apply them to can be efficiently
inverted. The algorithms speeding up these problems, amplitude amplification
and amplitude estimation, assume the ability to apply a state preparation
unitary $U$ and its inverse $U^\dagger$; we give problem instances based on
trace estimation where no algorithm which uses only $U$ beats the naive,
quadratically slower approach. Our proof of this is simple and goes through the
compressed oracle method introduced by Zhandry. Since these two subroutines are
responsible for the ubiquity of the quadratic "Grover" speedup in quantum
algorithms, our result explains why such speedups are far harder to come by in
the settings of quantum learning, metrology, and sensing. In these settings,
$U$ models the evolution of an experimental system, so implementing $U^\dagger$
can be much harder -- tantamount to reversing time within the system. Our
result suggests a dichotomy: without inverse access, quantum speedups are
scarce; with it, quantum speedups abound.

</details>


### [189] [Neural Network Architectures for Scalable Quantum State Tomography: Benchmarking and Memristor-Based Acceleration](https://arxiv.org/abs/2507.23007)
*Erbing Hua,Steven van Ommen,King Yiu Yu,Jim van Leeuven,Rajendra Bishnoi,Heba Abunahla,Salahuddin Nur,Sebastian Feld,Ryoichi Ishihara*

Main category: quant-ph

TL;DR: 与CNN和CGAN相比，SVAE的保真度中等，但更适合嵌入式、低功耗硬件；CiM平台可以加速这些模型。


<details>
  <summary>Details</summary>
Motivation: 量子态层析成像（QST）对于表征和验证量子系统至关重要，但其在希尔伯特空间的指数增长和信息完备性所需的测量数量方面存在实际限制。许多先前声称的性能依赖于架构假设，而不是系统验证。

Method: 对各种神经网络架构以及两种量子测量策略进行了全面基准测试，以评估它们在重建纯态和混合量子态方面的有效性。

Result: CNN和CGAN的扩展性更强，保真度更高，而脉冲变分自编码器（SVAE）表现出中等保真度，是嵌入式、低功耗硬件实现的有力候选者。此外，还讨论了基于忆阻器的内存计算（CiM）平台如何在硬件中加速这些模型，以实现可扩展的原位QST。

Conclusion: 本文确定了哪些网络架构有利于未来的量子系统，并为计算上和物理上可扩展的量子-经典协同设计奠定了基础。

Abstract: Quantum State Tomography (QST) is essential for characterizing and validating
quantum systems, but its practical use is severely limited by the exponential
growth of the Hilbert space and the number of measurements required for
informational completeness. Many prior claims of performance have relied on
architectural assumptions rather than systematic validation. We benchmark
several neural network architectures to determine which scale effectively with
qubit number and which fail to maintain high fidelity as system size
increases.To address this, we perform a comprehensive benchmarking of diverse
neural architectures across two quantum measurement strategies to evaluate
their effectiveness in reconstructing both pure and mixed quantum states. Our
results reveal that CNN and CGAN scale more robustly and achieve the highest
fidelities, while Spiking Variational Autoencoder (SVAE) demonstrates moderate
fidelity performance, making it a strong candidate for embedded, low-power
hardware implementations.Recognizing that practical quantum diagnostics will
require embedded, energy-efficient computation, we also discuss how
memristor-based Computation-in-Memory (CiM) platforms can accelerate these
models in hardware, mitigating memory bottlenecks and reducing energy
consumption to enable scalable in-situ QST. This work identifies which
architectures scale favorably for future quantum systems and lays the
groundwork for quantum-classical co-design that is both computationally and
physically scalable.

</details>


### [190] [Placing and Routing Non-Local Quantum Error Correcting Codes in Multi-Layer Superconducting Qubit Hardware](https://arxiv.org/abs/2507.23011)
*Melvin Mathews,Lukas Pahl,David Pahl,Vaishnavi L. Addala,Catherine Tang,William D. Oliver,Jeffrey A. Grover*

Main category: quant-ph

TL;DR: HAL是一种用于优化量子纠错码（QECC）在超导量子比特硬件上布局的算法，它能有效评估QECC的硬件成本和逻辑效率，并指导新QECC的设计。


<details>
  <summary>Details</summary>
Motivation: QECC的开销与非局部连接性有关，需要优化硬件布局。

Method: 开发了名为HAL（Hardware-Aware Layout）的启发式算法，利用超导量子比特硬件的多层布线和长程耦合能力，自动化并优化任意QECC的放置和布线。

Result: HAL生成的布局证实了开放边界显著降低了硬件成本，但也降低了逻辑效率。低权重的径向码表现最佳，尽管它们缺乏拓扑结构。

Conclusion: HAL算法为评估现有QECC的硬件可行性以及指导兼容实际硬件约束的新QECC的发现提供了一个有价值的框架。

Abstract: Quantum error correcting codes (QECCs) with asymptotically lower overheads
than the surface code require non-local connectivity. Leveraging multi-layer
routing and long-range coupling capabilities in superconducting qubit hardware,
we develop Hardware-Aware Layout, HAL: a robust, runtime-efficient heuristic
algorithm that automates and optimizes the placement and routing of arbitrary
QECCs. Using HAL, we perform a comparative study of hardware cost across
various families of QECCs, including the bivariate bicycle codes, the
open-boundary tile codes, and the constant-depth-decodable radial codes. The
layouts produced by HAL confirm that open boundaries significantly reduce the
hardware cost, while incurring reductions in logical efficiency. Among the
best-performing codes were low-weight radial codes, despite lacking topological
structure. Overall, HAL provides a valuable framework for evaluating the
hardware feasibility of existing QECCs and guiding the discovery of new codes
compatible with realistic hardware constraints.

</details>


### [191] [Context-Dependent Time-Energy Uncertainty Relations from Projective Quantum Measurements](https://arxiv.org/abs/2507.23059)
*Mathieu Beau*

Main category: quant-ph

TL;DR: 提出TF框架，用于量子系统的时间测量，并得到新的时间-能量不确定性关系。


<details>
  <summary>Details</summary>
Motivation: 为了在量子系统中定义上下文相关的时间分布，并探索其时间-能量不确定性关系。

Method: 提出了一种使用投影测量定义上下文相关时间分布的通用框架，并推导了 TF 分布，得到了时间-能量不确定性关系式。

Result: 推导了 TF 分布，得到了时间-能量不确定性关系式 $\Delta \mathcal{T} \cdot \Delta H \geq \hbar / (6\sqrt{3}) \cdot \delta\theta$，其中 $\delta\theta$ 量化净布居转移。该关系式适用于任意投影算符在幺正动力学下的情况。展示了该框架在 TOA-能量不确定性关系和驱动三能级系统中的应用。

Conclusion: 该框架为量子系统中的时间测量提供了一个统一的、可实验验证的途径，并揭示了时间不确定性与测量选择的内在联系。

Abstract: We introduce a general framework for defining context-dependent time
distributions in quantum systems using projective measurements. The
time-of-flow (TF) distribution, derived from population transfer rates into a
measurement subspace, yields a time--energy uncertainty relation of the form
$\Delta \mathcal{T} \cdot \Delta H \geq \hbar / (6\sqrt{3}) \cdot
\delta\theta$, where $\delta\theta$ quantifies net population transfer. This
bound applies to arbitrary projectors under unitary dynamics and reveals that
time uncertainty is inherently measurement-dependent. We demonstrate the
framework with two applications: a general time-of-arrival (TOA)-energy
uncertainty relation and a driven three-level system under detuned coherent
driving. The TF framework unifies timing observables across spin, atomic, and
matter-wave systems, and offers an experimentally accessible route to probing
quantum timing in controlled measurements.

</details>


### [192] [Scalable Ion Fluorescence Collection Using a Trap-Integrated Metalens](https://arxiv.org/abs/2507.23071)
*Hae Lim,Johannes E. Fröch,Christian M. Pluchar,Arka Majumdar,Sara L. Mouradian*

Main category: quant-ph

TL;DR: 一种集成金属透镜的表面离子阱，可实现高效荧光收集，为可扩展的量子计算机提供解决方案。


<details>
  <summary>Details</summary>
Motivation: 扩展的离子阱量子计算机需要跨越广大区域的高效荧光收集能力。

Method: 提出并演示了一个紧凑的单片集成系统，该系统在表面离子阱的背面制造了一个金属透镜，以实现高效的荧光收集。

Result: 在40x100微米的孔径下，模拟的点源收集效率为0.91%，测得的点源检测效率为0.58%。将孔径增大到40x600微米，模拟的收集效率提升至3.17%，与数值孔径为0.35的传统物镜相当。通过优化电极和孔径几何结构，以及在孔径处对电极基底进行刻蚀，可以进一步提高收集效率，同时保持离子与介电基底的大距离。

Conclusion: 所提出的紧凑型单片集成系统通过在表面离子阱的背面制造金属透镜，为离子阱量子计算机实现了高效的荧光收集。该系统具有可扩展的并行读取潜力。

Abstract: A scaled trapped-ion quantum computer will require efficient fluorescence
collection across a large area. Here we propose and demonstrate a compact
monolithically integrated system featuring a metalens fabricated on the
backside of a surface ion trap. A 40$\times$100 $\mu$m aperture enables a
simulated point-source collection efficiency of 0.91% and a measured
point-source detection efficiency of 0.58%. Increasing the aperture area to
40$\times$600 $\mu$m boosts the simulated collection efficiency to
3.17%$-$comparable to that of a conventional objective with a numerical
aperture of 0.35. Further improvements are possible by co-optimizing the
electrode and aperture geometry. An undercut of the electrode substrate at the
aperture ensures a large distance between the ion and dielectric substrate
without compromising collection efficiency. The metalens directly collimates
the collected fluorescence, eliminating the need for a high numerical aperture
objective. An array of such readout zones will offer a compact, scalable
solution for high-fidelity parallel readout in next-generation trapped-ion
quantum processors.

</details>


### [193] [Harnessing Bayesian Statistics to Accelerate Iterative Quantum Amplitude Estimation](https://arxiv.org/abs/2507.23074)
*Qilin Li,Atharva Vidwans,Yazhen Wang,Micheline B. Soley*

Main category: quant-ph

TL;DR: 该研究提出了一种名为BIQAE的新方法，通过结合贝叶斯统计和量子幅度估算，提高了估算的准确性和效率，尤其是在分子基态能量的计算方面。


<details>
  <summary>Details</summary>
Motivation: 为了在量子幅度估算（QAE）这一对化学、金融和机器学习等领域至关重要的任务中，提高测量效率并获得严格的置信区间，尤其是在迭代过程中。

Method: 提出了一种统一的统计框架，并利用贝叶斯统计改进了迭代量子幅度估计算法（IQAE）的测量效率和收敛性，从而开发出贝叶斯迭代量子幅度估计算法（BIQAE）。

Result: BIQAE能够精确高效地估算量子幅度和分子的基态能量，并且在样本复杂度分析中表现优于其他QAE方法，这归功于贝叶斯统计的优势。

Conclusion: 该研究证明了贝叶斯统计在加速量子效用研究中的潜力。

Abstract: We establish a unified statistical framework that underscores the crucial
role statistical inference plays in Quantum Amplitude Estimation (QAE), a task
essential to fields ranging from chemistry to finance and machine learning. We
use this framework to harness Bayesian statistics for improved measurement
efficiency with rigorous interval estimates at all iterations of Iterative
Quantum Amplitude Estimation. We demonstrate the resulting method, Bayesian
Iterative Quantum Amplitude Estimation (BIQAE), accurately and efficiently
estimates both quantum amplitudes and molecular ground-state energies to high
accuracy, and show in analytic and numerical sample complexity analyses that
BIQAE outperforms all other QAE approaches considered. Both rigorous
mathematical proofs and numerical simulations conclusively indicate Bayesian
statistics is the source of this advantage, a finding that invites further
inquiry into the power of statistics to expedite the search for quantum
utility.

</details>


### [194] [A Classical-Quantum Adder with Constant Workspace and Linear Gates](https://arxiv.org/abs/2507.23079)
*Craig Gidney*

Main category: quant-ph

TL;DR: 经典量子加法器达到了与量子-量子加法器相同的渐近复杂性。


<details>
  <summary>Details</summary>
Motivation: 在2004年，Cuccaro等人发现了一种量子-量子加法器，其门成本为$O(n)$，辅助量子比特为$O(1)$。从那时起，经典量子加法器是否能达到相同的渐近复杂性就一直是一个悬而未决的问题。这些成本与模运算电路尤其相关，这些电路经常被经典已知的模数抵消。

Method: 提出了一种使用3个干净的辅助量子比特和$4n \pm O(1)$个Toffoli门将经典偏移量加到量子寄存器中的加法器，以及一种使用2个干净的辅助量子比特和$n-2$个脏辅助量子比特、Toffoli成本为$3n \pm O(1)$的加法器。还表明，在控制量子比特的条件下应用这些加法器不需要额外的空间或Toffoli门。

Result: 成功构建了具有$O(n)$门成本和$O(1)$辅助量子比特的经典量子加法器，达到了与量子-量子加法器相同的渐近复杂性。

Conclusion: 量子加法器和经典量子加法器可以达到相同的渐近复杂性。

Abstract: In 2004, Cuccaro et al found a quantum-quantum adder with $O(n)$ gate cost
and $O(1)$ ancilla qubits. Since then, it's been an open question whether
classical-quantum adders can achieve the same asymptotic complexity. These
costs are particularly relevant to modular arithmetic circuits, which often
offset by the classically known modulus.
  In this paper, I construct an adder that uses 3 clean ancillae and $4n \pm
O(1)$ Toffoli gates to add a classical offset into a quantum register. I also
present an adder with a Toffoli cost of $3n \pm O(1)$ that uses 2 clean
ancillae and $n-2$ dirty ancillae. I further show that applying the presented
adders conditioned on a control qubit requires no additional workspace or
Toffolis.

</details>


### [195] [Proximity-measurement induced random localization in quantum fluids](https://arxiv.org/abs/2507.23085)
*Pushkar Mohile,Paul M. Goldbart*

Main category: quant-ph

TL;DR: Random proximity measurements on quantum fluids cause particles to localize spatially, with the localization scale depending on the measurement rate.


<details>
  <summary>Details</summary>
Motivation: The research aims to understand how proximity measurements affect a quantum fluid and the resulting particle behavior, specifically spatial localization and homogeneity.

Method: The paper analyzes the impact of post-selected random proximity measurements on a quantum fluid of many distinguishable particles.

Result: The measurements induce random spatial localization in a fraction of the particles while maintaining macroscopic homogeneity. Ultimately, all particles become localized, with a distribution of localization lengths that stabilizes at a scale influenced by the measurement rate. The steady-state distribution exhibits a recognizable scaling form.

Conclusion: The study demonstrates that post-selected random proximity measurements on a quantum fluid of distinguishable particles lead to random spatial localization of a fraction of particles, eventually localizing all particles. The distribution of localization lengths saturates at a scale determined by the measurement rate and follows a specific scaling form in the steady state.

Abstract: Proximity measurements probe whether pairs of particles are close to one
another. We consider the impact of post-selected random proximity measurements
on a quantum fluid of many distinguishable particles. We show that such
measurements induce random spatial localization of a fraction of the particles,
and yet preserve homogeneity macroscopically. Eventually, all particles
localize, with a distribution of localization lengths that saturates at a scale
controlled by the typical measurement rate. The steady-state distribution of
these lengths is governed by a familiar scaling form.

</details>


### [196] [Quantification of the energy consumption of entanglement distribution](https://arxiv.org/abs/2507.23108)
*Karol Horodecki,Marek Winczewski,Leonard Sikorski,Paweł Mazurek,Mikołaj Czechlewski,Raja Yehia*

Main category: quant-ph

TL;DR: 本研究提出了一个框架，用于计算通过有噪声量子信道生成量子纠缠所需的能量成本，并为未来的量子网络提供了量化估计。研究发现，纠缠的不可逆性导致实际能量消耗远高于理论最小值。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是量化通过有噪声量子信道生成量子纠缠所需的能量，重点关注与硬件无关的根本成本，并为未来的量子网络提供量化的能量投资估计。

Method: 本研究受环境科学启发，开发了一个框架来量化通过有噪声量子信道生成量子纠缠所需的能量，重点关注与硬件无关的根本成本。在该框架内，定义了一个衡量每分布式纠缠的最小根本能量消耗率（以焦耳/ebit为单位）的指标。推导出了通过量子信道分发最大纠缠态的能量成本下界。此外，还通过确定实现量子操作的最小能量来确定纠缠分发的根本能量消耗率的上限。为此，制定了能量成本度量的公理，并为经典控制的量子操作引入了哈密顿量模型。根本成本被定义为所有此类哈密顿量协议（无论是否有特定的硬件限制）的能量下确界。

Result: 研究推导出了通过量子信道分发最大纠缠态的能量成本下界，证明了纠缠理论中的不可逆性意味着在标准的纠缠分发协议中存在非零能量成本。此外，还确定了纠缠分发的根本能量消耗率的上限。研究发现，由于纠缠的不可逆性，三个纠缠提纯协议所需的能量比根本下界高出许多数量级。

Conclusion: 这项研究为量化通过有噪声量子信道生成量子纠缠所需的能量提供了一个框架，并定义了一个衡量每分布式纠缠的最小基本能量消耗率的指标。研究推导出了通过量子信道分发最大纠缠态的能量成本下界，并证明了纠缠理论中的不可逆性意味着在标准的纠缠分发协议中存在非零能量成本。此外，研究还通过确定实现经典控制的量子操作所需的最小能量，为纠缠分发的根本能量消耗率设定了上限。该框架适用于量子计算，并已应用于光子偏振量子比特的纠缠提纯协议，显示出其所需能量远超根本下界。

Abstract: Inspired by environmental sciences, we develop a framework to quantify the
energy needed to generate quantum entanglement via noisy quantum channels,
focusing on the hardware-independent, i.e. fundamental cost. Within this
framework, we define a measure of the minimal fundamental energy consumption
rate per distributed entanglement (expressed in Joule per ebit). We then derive
a lower bound on the energy cost of distributing a maximally entangled state
via a quantum channel, which yields a quantitative estimate of energy
investment per entangled bit for future quantum networks. We thereby show that
irreversibility in entanglement theory implies a non-zero energy cost in
standard entanglement distribution protocols. We further establish an upper
bound on the fundamental energy consumption rate of entanglement distribution
by determining the minimal energy required to implement quantum operations via
classical control. To this end, we formulate the axioms for an energy cost
measure and introduce a Hamiltonian model for classically-controlled quantum
operations. The fundamental cost is then defined as the infimum energy over all
such Hamiltonian protocols, with or without specific hardware constraints. The
study of the energy cost of a quantum operation is general enough to be
naturally applicable to quantum computing and is of independent interest.
Finally, we evaluate the energy demands of three entanglement distillation
protocols for photonic polarization qubits, finding that, due to entanglement
irreversibility, their required energy exceeds the fundamental lower bound by
many orders of magnitude. The introduced paradigm can be applied to other
quantum resources, with appropriate changes depending on their nature.

</details>


### [197] [Neural network for excess noise estimation in continuous-variable quantum key distribution under composable finite-size security](https://arxiv.org/abs/2507.23117)
*Lucas Q. Galvão,Davi Juvêncio G. de Sousa,Micael Andrade Dias,Nelson Alves Ferreira Neto*

Main category: quant-ph

TL;DR: 神经网络可用于CV-QKD中的参数估计，提供更严格的置信区间和更高的密钥速率，尤其是在资源受限的情况下。


<details>
  <summary>Details</summary>
Motivation: 在有限制的CV-QKD中，参数估计是关键，因为最坏情况下的置信区间会显著降低可实现的密钥速率。

Method: 使用神经网络进行参数估计，并进行有限安全分析，证明了其在CV-QKD中的可靠性，并具有可量化的失败概率和可组合的安全保证。

Result: 该方法产生了比标准方法更严格的置信区间，从而在集体高斯攻击下实现了更高的密钥速率。

Conclusion: 参数估计可以可靠地用于CV-QKD，具有可量化的失败概率，并提供可组合的安全保证。该方法产生更严格的置信区间，从而在集体高斯攻击下实现更高的密钥速率，为将机器学习技术集成到量子密码协议中开辟了新视角。

Abstract: Parameter estimation is a critical step in continuous-variable quantum key
distribution (CV-QKD), especially in the finite-size regime where worst-case
confidence intervals can significantly reduce the achievable secret-key rate.
We provide a finite-size security analysis demonstrating that neural networks
can be reliably employed for parameter estimation in CV-QKD with quantifiable
failure probabilities $\epsilon_{PE}$, endowed with an operational
interpretation and composable security guarantees. Using a protocol that is
operationally equivalent to standard approaches, our method produces
significantly tighter confidence intervals, unlocking higher key rates even
under collective Gaussian attacks. The proposed approach yields tighter
confidence intervals, leading to a quantifiable increase in the secret-key rate
under collective Gaussian attacks. These results open up new perspectives for
integrating modern machine learning techniques into quantum cryptographic
protocols, particularly in practical resource-constrained scenarios.

</details>


### [198] [A multi-dimensional quantum estimation and model learning framework based on variational Bayesian inference](https://arxiv.org/abs/2507.23130)
*Federico Belliardo,Erik M. Gauger,Tim H. Taminiau,Yoann Altmann,Cristian Bonato*

Main category: quant-ph

TL;DR: 介绍了一种基于变分贝叶斯推断的联合模型选择和参数估计算法，该算法能够快速处理高维参数空间中的量子系统识别问题，并在模拟和实验数据上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 量子技术的发展和扩展使得在高度多维参数空间中学习和识别量子系统和设备成为一项紧迫的任务，尤其是在需要实时反馈控制和自适应测量设置的场景下，这对任务的速度提出了严格要求。

Method: 使用变分贝叶斯推断（VBI）来近似目标后验分布，通过优化一个易于处理的分布族来估计模型参数，并引入正则化先验来选择模型。

Result: 该算法能够快速处理大量模型参数，并且能够选择最简单的模型来解释实验数据，还能区分对主要特征有贡献的自由度和耦合较小的背景自由度。

Conclusion: 该算法能够准确识别模型（即自旋数量及其耦合），并在模拟和实验数据上进行了基准测试，证明了其在高维空间中的可扩展性和效率。

Abstract: The advancement and scaling of quantum technology has made the learning and
identification of quantum systems and devices in highly-multidimensional
parameter spaces a pressing task for a variety of applications. In many cases,
the integration of real-time feedback control and adaptive choice of
measurement settings places strict demands on the speed of this task. Here we
present a joint model selection and parameter estimation algorithm that is fast
and operable on a large number of model parameters. The algorithm is based on
variational Bayesian inference (VBI), which approximates the target posterior
distribution by optimizing a tractable family of distributions, making it more
scalable than exact inference methods relying on sampling and that generally
suffer from high variance and computational cost in high-dimensional spaces. We
show how a regularizing prior can be used to select between competing models,
each comprising a different number of parameters, identifying the simplest
model that explains the experimental data. The regularization can further
separate the degrees of freedom, e.g. quantum systems in the environment or
processes, which contribute to major features in the observed dynamics, with
respect to others featuring small coupling, which only contribute to a
background. As an application of the introduced framework, we consider the
problem of the identification of multiple individual nuclear spins with a
single electron spin quantum sensor, relevant for nanoscale nuclear magnetic
resonance. With the number of environmental spins unknown a priori, our
Bayesian approach is able to correctly identify the model, i.e. the number of
spins and their couplings. We benchmark the algorithm on both simulated and
experimental data, using standard figures of merit, and demonstrating that we
can estimate dozens of parameters within minutes.

</details>


### [199] [Reformulating Chemical Equilibrium in Reacting Quantum Gas Mixtures: Particle Number Conservation, Correlations and Fluctuations](https://arxiv.org/abs/2507.23132)
*Diogo J. L. Rodrigues*

Main category: quant-ph

TL;DR: 通过引入粒子数守恒约束来重新制定反应量子气体混合物的系综描述，取代了化学势相等。该方法将成分波动纳入统计描述，并可还原为经典理想气体极限。


<details>
  <summary>Details</summary>
Motivation: 为具有成分波动的反应混合物中的量子化学平衡提供新的见解，并通过推广经典化学平衡处理的扩展配分函数，可以顺利地还原为经典理想气体极限。

Method: 通过结合跨越相互转化物种的组合光谱的单一全局粒子数守恒约束来重新制定反应量子气体混合物的经典系综描述，该约束取代了常规的化学势相等。

Result: 费米-狄拉克或玻色-爱因斯坦相关性自然地出现在共享相同自旋统计的物种的单粒子能量本征态中，这在遍历的单系统中表现为平衡状态的内在特征。

Conclusion: 该框架为具有成分波动的反应混合物中的量子化学平衡提供了新的见解，并通过推广经典化学平衡处理的扩展配分函数，可以顺利地还原为经典理想气体极限。

Abstract: The canonical-ensemble description of reactive quantum gas mixtures is
reformulated by incorporating a single global particle-number-conservation
constraint over the combined spectra of inter-converting species. This
constraint replaces the conventional equality of chemical potentials.
Fermi-Dirac or Bose-Einstein correlations naturally emerge across one-particle
energy eigenstates of species sharing identical spin-statistics, which in
ergodic single-systems manifest as intrinsic features of the equilibrium state.
By embedding all microstates linked by conversion pathways, the framework
incorporates concentration fluctuations in the statistical description. The
formalism offers fresh insights into quantum chemical equilibrium in reactive
mixtures with composition fluctuations and smoothly reduces to the classical
ideal gas limit via an extended partition function that generalizes classical
chemical-equilibrium treatments.

</details>


### [200] [Geometric phase in anisotropic Kepler problem: Perspective for realization in Rydberg atoms](https://arxiv.org/abs/2507.23144)
*Nikolai A. Sinitsyn,Fumika Suzuki*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We predict a gyroscopic effect that can be demonstrated with Rydberg atoms
following the dynamics of a Kepler Hamiltonian with an additional uniaxial
anisotropy induced by optical ponderomotive force. This effect is analogous to
the rotation of the Foucault pendulum in response to the Earth's rotation. We
argue that in Rydberg states a similar geometric angle can be generated by
mechanical rotations of an atomic-optical setup on time scales between $1~\mu$s
and $1~$ms.

</details>


### [201] [A Practical Open-Source Software Stack for a Cloud-Based Quantum Computing System](https://arxiv.org/abs/2507.23165)
*Norihiro Kakuko,Shun Gokita,Naoyuki Masumoto,Keita Matsumoto,Kosuke Miyaji,Takafumi Miyanaga,Toshio Mori,Haruki Nakayama,Keita Sasada,Yasuhito Takamiya,Satoyuki Tsukano,Ryo Uchida,Masaomi Yamaguchi*

Main category: quant-ph

TL;DR: OQTOPUS是一个开源的全栈量子计算系统，旨在降低量子计算的门槛，促进社区发展。


<details>
  <summary>Details</summary>
Motivation: 量子计算系统的设计，特别是量子计算机附近的区域，仍然很大程度上未公开，这对进入量子计算领域造成了重大障碍，阻碍了标准化和实际量子计算系统的发展。

Method: 提出了一种名为OQTOPUS的全栈量子计算系统，该系统涵盖了从云执行环境构建到系统操作的运行软件。

Result: OQTOPUS已在GitHub上公开，并实现了诸如编译器、多编程和错误缓解等关键功能，这些功能位于尽可能靠近量子计算机的区域，而系统供应商很少公开这些区域。

Conclusion: OQTOPUS将显著降低量子计算领域的门槛，并通过开放讨论促进量子计算开发者社区的形成。

Abstract: Since the late 2010s, quantum computers have become commercially available,
and the number of services that users can run remotely via cloud servers is
increasing. In Japan, several domestic superconducting quantum computing
systems, including our own, began operation in 2023. However, the design of
quantum computing systems, especially in the most critical areas near quantum
computers, remains largely undisclosed, creating a significant barrier to entry
into the quantum computing field. If this situation continues, progress toward
standardization, which is essential for guiding quantum computer development,
will stall, and it will be difficult to develop a practical quantum computing
system that can perform calculations on a supercomputer scale. To address this
issue, we propose Open Quantum Toolchain for OPerators and USers (OQTOPUS), a
full-stack quantum computing system developed from research with real quantum
computers. OQTOPUS is one of the world's largest open-source software projects,
covering operational software from cloud-based execution environment
construction to system operation. Furthermore, to perform quantum computing
effectively and efficiently, it implements key features, such as transpilers,
multiprogramming, and error mitigation, in an area as close as possible to a
quantum computer, an area that system vendors rarely disclose. Finally, this
study presents experimental results of applying OQTOPUS to a real quantum
computer. OQTOPUS is publicly available on GitHub and will notably lower the
barrier to entry into the quantum computing field, contributing to the
formation of a quantum computing developer community through open discussion.

</details>


### [202] [Quantum Key Distribution](https://arxiv.org/abs/2507.23192)
*Sebastian Kish,Josef Pieprzyk,Seyit Camtepe*

Main category: quant-ph

TL;DR: QKD技术利用量子力学原理确保通信安全，在单光子源和探测技术方面取得进展，正逐步走向广泛应用，并将作为量子安全的关键组成部分。


<details>
  <summary>Details</summary>
Motivation: 强调了QKD在抵御未来量子威胁方面对于保护关键任务通信日益增长的重要性。

Method: 通过概述量子密钥分发技术（QKD）的成熟度和趋势，强调了单光子源和探测技术在推动QKD广泛应用方面取得的重大进展，并讨论了成本、集成、标准化和量子中继器的需求等挑战。

Result: QKD技术通过实际部署和行业领导者的应用，正在逐步走向广泛应用。

Conclusion: 量子密钥分发（QKD）凭借其独特的信息论安全性，将在未来的量子安全密码算法和协议中发挥至关重要的作用。

Abstract: Quantum Key Distribution (QKD) is a technology that ensures secure
communication by leveraging the principles of quantum mechanics, such as the
no-cloning theorem and quantum uncertainty. This chapter provides an overview
of this quantum technology's maturity and trends. It highlights significant
advancements in single-photon sources and detection technologies that have
brought QKD closer to widespread adoption, including real-world deployments by
industry leaders. While addressing challenges such as cost, integration,
standardization, and the need for quantum repeaters, the chapter emphasizes the
growing importance of QKD in securing mission-critical communications against
future quantum threats. Through its unique ability to achieve
information-theoretic security, QKD is poised to play a vital role in
quantum-safe cryptographic algorithms and protocols.

</details>


### [203] [Long-range photonic device-independent quantum key distribution using SPDC sources and linear optics](https://arxiv.org/abs/2507.23254)
*Morteza Moradi,Maryam Afsary,Piotr Mironowicz,Enky Oudot,Magdalena Stobińska*

Main category: quant-ph

TL;DR: 提出并验证了长距离DIQKD的光学方案，解决了速率限制问题，提高了安全性和实用性。


<details>
  <summary>Details</summary>
Motivation: 解决长距离DIQKD的速率限制问题，使其在实际中可用，同时保持最高的安全保证。

Method: 提出两种全光学的DIQKD方案，利用SPDC光源进行受激纠缠分发，并使用熵积累定理进行安全分析，通过数值优化获得定制贝尔不等式。

Result: 实现了与双场协议相匹配的密钥速率（与信道透过率$\eta_t$的平方根成正比），在83%的探测器效率下实现了正密钥率，并获得了比标准方法优越2-3倍的贝尔不等式。

Conclusion: 该研究为长距离设备无关量子密钥分发（DIQKD）提出了首个实验上可行的方案，利用了自发参量下转换（SPDC）光源的受激纠缠分发。

Abstract: Device-independent quantum key distribution (DI QKD) offers unparalleled
cryptographic security by eliminating trust requirements for quantum devices,
yet has remained impractical for long-distance implementation due to
fundamental rate limitations. Here, we propose the first experimentally viable
schemes for long-distance DI QKD using two fully photonic approaches with
heralded entanglement distribution using spontaneous parametric down-conversion
(SPDC) sources. Both schemes achieve key rate scaling with the square root of
channel transmissivity $\eta_t$, matching the twin-field protocol advantage
rather than the prohibitive linear decay of conventional QKD. We demonstrate
positive key rates at detector efficiencies as low as 83\%, bringing DI QKD
within reach of the current superconducting detector technology. Our security
analysis employs the Entropy Accumulation Theorem to establish rigorous
finite-size bounds, while numerical optimization yields custom Bell
certificates that surpass standard approaches by 2--3 times at maximum
transmission distances. This work represents a critical milestone toward
device-independent security in quantum communication networks, providing
experimentalists with practical implementation pathways while maintaining the
strongest possible security guarantees against quantum adversaries.

</details>


### [204] [Deterministic and Scalable Coupling of Single 4H-SiC Spin Defects into Bullseye Cavities](https://arxiv.org/abs/2507.23258)
*Tongyuan Bao,Qi Luo,Ailun Yi,Yingjie Li,Haibo Hu,Xin Ou,Yu Zhou,Qinghai Song*

Main category: quant-ph

TL;DR: 本研究在 4H-SiCOI 平台上成功地将单晶硅中的单自旋缺陷（PL6）和系综缺陷（PL4）确定性地耦合到牛眼谐振腔中，实现了性能的大幅提升，为构建可扩展的量子光子电路铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 尽管 SiC 材料具有作为量子材料的潜力，但将其单自旋缺陷确定性地集成到高性能光子腔中一直是一个关键挑战。

Method: 本研究利用 4H-SiCOI 平台，通过调整谐振腔共振，实现了 PL4 和 PL6 两种自旋缺陷（包括系综和单缺陷）与单片牛眼谐振腔的确定性耦合。

Result: 研究实现了 PL4 系综缺陷的零声子线 (ZPL) 强度 40 倍的增强（Purcell 因子约为 5.0），并对确定性耦合的 PL6 单自旋缺陷实现了饱和光子计数率的三倍提升，同时确认了单光子发射，并通过光探测磁共振 (ODMR)、共振激发和拉比振荡证明了自旋状态的相干控制。

Conclusion: 该研究通过将单晶硅 (SiC) 材料与集成量子光子学相结合，为可扩展、高性能的基于 SiC 的量子光子电路奠定了基础。

Abstract: Silicon carbide (SiC) has attracted significant attention as a promising
quantum material due to its ability to host long-lived, optically addressable
color centers with solid-state photonic interfaces. The CMOS compatibility of
4H-SiCOI (silicon-carbide-on-insulator) makes it an ideal platform for
integrated quantum photonic devices and circuits. However, the deterministic
integration of single spin defects into high-performance photonic cavities on
this platform has remained a key challenge. In this work, we demonstrate the
deterministic and scalable coupling of both ensemble (PL4) and single PL6 spin
defects into monolithic bullseye cavities on the 4H-SiCOI platform. By tuning
the cavity resonance, we achieve a 40-fold enhancement of the zero-phonon line
(ZPL) intensity from ensemble PL4 defects, corresponding to a Purcell factor of
approximately 5.0. For deterministically coupled single PL6 defects, we observe
a threefold increase in the saturated photon count rate, confirm single-photon
emission, and demonstrate coherent control of the spin state through optically
detected magnetic resonance (ODMR), resonant excitation, and Rabi oscillations.
These advancements establish a viable pathway for developing scalable,
high-performance SiC-based quantum photonic circuits.

</details>


### [205] [Environment-assisted and weak measurement strategies for robust bidirectional quantum teleportation](https://arxiv.org/abs/2507.23274)
*Javid Ahmad Malik,Muzaffar Qadir Lone,Prince A Ganai*

Main category: quant-ph

TL;DR: 本研究提出了一种增强双向量子态传送（BQT）鲁棒性的方法，通过结合环境辅助测量和弱测量技术来对抗幅度衰减信道（ADC）的影响。研究发现，通过优化弱测量强度与ADC衰减率的匹配关系，可以在保真度和成功率之间取得平衡，并在特定条件下实现完美的量子态传送。所提出的安全协议相比未受保护的方案具有明显优势。


<details>
  <summary>Details</summary>
Motivation: 双向量子态传送（BQT）是分布式量子网络的重要组成部分，但其性能受到量子比特退相干和幅度衰减信道（ADC）的影响。因此，需要提出策略来增强 BQT 的鲁棒性。

Method: 提出了一种双向量子态传送（BQT）方案，利用环境辅助测量（EAM）和弱测量技术来提高其鲁棒性。该方案旨在通过在过程的最后阶段优化弱测量来提高保真度，以处理通过幅度衰减信道（ADC）传输的任意量子比特。研究了两种情况：(I) 仅恢复量子比特通过 ADC，(II) 整个四量子比特通道（由两个贝尔态组成）都受到 ADC 的影响。

Result: 研究结果表明，当弱测量强度（qw）与衰减率（p）满足 qw ∈ [0,p] 时，可以在平均保真度和成功率之间取得平衡。当 qw = p 时，可以实现完美的 BQT，完全抑制 ADC 的影响。当 qw > p 时，平均保真度和成功率会下降。在两种情况下，提出的安全 BQT 协议都比未受保护的方案表现更好。

Conclusion: 该研究提出了一种通过环境辅助和弱测量技术增强双向量子态传送（BQT）鲁棒性的方案。研究发现，当弱测量强度（qw）受限于衰减率（p），即 qw ∈ [0,p] 时，可以在平均保真度和成功率之间取得平衡。当 qw = p 时，可以实现完美的 BQT，完全抑制了幅度衰减信道（ADC）的影响。相反，当弱测量强度超过 ADC 强度时（qw ∈ (p,1]），平均保真度和成功率都会下降。此外，在两种考虑的情况下，所提出的安全 BQT 协议均优于未受保护的方案。

Abstract: This paper presents strategies for enhancing the robustness of bidirectional
quantum teleportation (BQT) through environment-assisted and weak measurement
techniques. BQT is a crucial component of distributed quantum networks,
allowing for the bilateral transfer of quantum information between two nodes.
While perfect teleportation necessitates maximally entangled states, these are
vulnerable to degradation due to inherent decoherence. We propose a BQT scheme
that enables the bilateral transfer of arbitrary qubits between nodes via
amplitude damping channels (ADC), aiming to optimize fidelity using weak
measurements in the final step of the process. Environment-assisted
measurements (EAM) are used to establish a four-qubit channel composed of two
Bell states. We explore two situations: (I) where only the recovery qubits pass
through amplitude damping channels and (II) where the entire four-qubit channel
is subjected to ADC. Our findings demonstrate a balance between average
fidelity and success probability when the weak measurement strength ($q_w$) is
constrained by the decay rate ($p$), specifically $q_w \in {[0,p]}$. Perfect
BQT is achieved when $q_w = p$, indicating complete suppression of ADC effects.
On the other hand, a decline in both average fidelity and success probability
is noted when the weak measurement strength surpasses the ADC strength, marking
the prohibited domain as $q_w \in {(p,1]}$. Additionally, our secured BQT
protocol consistently outperforms the unprotected scheme in both scenarios,
highlighting the effectiveness of the proposed protection strategies.

</details>


### [206] [Time-Dependent Parameters in Quantum Systems: Revisiting Berry Phase, Curvature and Gauge Connections](https://arxiv.org/abs/2507.23347)
*Georgios Konstantinou*

Main category: quant-ph

TL;DR: 本文将量子绝热理论重构为电磁学框架，引入贝里电场和贝里麦克斯韦方程组，揭示了参数空间中的几何结构和拓扑特性。


<details>
  <summary>Details</summary>
Motivation: 量子绝热理论的重构，以及静态和动力学方法之间的联系，以更深入地理解规范结构在量子系统中的体现。

Method: 通过使用全时间依赖波函数定义规范势，推导了散发贝里电场的系统，并构建了贝里麦克斯韦方程组，明确了其拓扑荷、单极结构和规范流。

Result: 建立了基于场的形式，可以清晰地解释拓扑荷、单极结构和规范流，并推导了广义连续性和涡旋关系，以及贝里曲率如何影响动力学量。

Conclusion: 本文提出了一种基于量子绝热理论的电磁学新框架，将几何结构与动力学过程联系起来，揭示了参数空间中的拓扑特性和规范电流。

Abstract: We present a reformulation of quantum adiabatic theory in terms of an
emergent electromagnetic framework, emphasizing the physical consequences of
geometric structures in parameter space. Contrary to conventional approaches,
we demonstrate that a Berry electric field naturally arises in systems with
dynamic Hamiltonian, when the full time-dependent wavefunction is used to
define the gauge potentials. This surprising result bridges the gap between
static and dynamical formulations and leads to a deeper understanding of how
gauge structures manifest in quantum systems. Building on this, we construct
Berry Maxwell equations by analogy with classical electrodynamics, defining
Berry electric and magnetic fields as derivatives of scalar and vector
potentials obtained from the full quantum state. We verify these equations
explicitly and derive field-theoretic identities such as generalized continuity
and vorticity relations. This field-based formulation reveals the topological
charges, monopole structures, and gauge currents that underlie parameter space,
and clarifies how Berry curvature corrections enter dynamical quantities like
expectation values and particle velocities. Our results establish a new regime
of emergent electromagnetism in parameter space, unifying time-independent and
time-dependent geometric phases within a covariant formalism. The implications
extend to quantum transport, polarization, and topological classification of
phases, providing a robust and generalizable framework for quantum systems
driven by adiabatic or nonadiabatic evolution.

</details>


### [207] [Novel Quantum Circuit Designs of Random Injection and Payoff Computation for Financial Risk Assessment](https://arxiv.org/abs/2507.23310)
*Yu-Ting Kao,Yeong-Jar Chang,Ying-Wei Tseng*

Main category: quant-ph

TL;DR: 本研究提出了一种集成的量子电路，用于金融分析中的随机数生成和支付计算，并成功在IBM Qiskit上实现和验证，展示了其可扩展性和潜在的量子优势。


<details>
  <summary>Details</summary>
Motivation: 尽管量子计算在理论上能够支持大规模并行计算，但将其应用于金融分析，特别是在随机数生成和支付计算方面，仍然面临挑战。现有方法（如JP Morgan的PWL方法）可能依赖于经典预处理。因此，有必要开发一种能够直接处理随机数注入和支付计算的集成量子电路。

Method: 本研究提出了一个集成的量子电路，包含两个关键部分：一个用于随机数注入（适用于风险评估），另一个用于直接支付计算（适用于金融定价）。该电路利用量子幅度估计算法（QAE）实现二次加速，并可在可扩展的框架内利用大规模并行性。

Result: 实验结果证实了所提出量子电路的随机数生成能力和支付计算的准确性。

Conclusion: 该研究提出了一个集成了随机数注入和直接支付计算的量子电路，并使用IBM Qiskit在8个并行线程和1600次测量样本上进行了实现和评估。结果证实了该电路的随机性和支付计算的正确性，并展示了其可扩展至2的n次方线程的潜力，为实现量子霸权提供了一条可行路径。

Abstract: Quantum entanglement enables exponential computational states, while
superposition provides inherent parallelism. Consequently, quantum circuits are
theoretically capable of supporting large scale parallel computation. However,
applying them to financial analysis particularly in the areas of random number
generation and payoff computation remains a significant challenge. Experts
generally believe that quantum computing relies on matrix operations, which are
deterministic in nature without randomness. This inherent determinism makes it
particularly challenging to design quantum circuits that require random number
injection. JP Morgan[1] introduced the piecewise linear (PWL) approach for
modeling payoff computations but did not disclose a quantum circuit capable of
identifying values exceeding the strike price, suggesting a possible reliance
on classical pre processing for interval classification. This paper presents an
integrated quantum circuit with two key components: one for random number
injection, applicable to risk assessment, and the other for direct payoff
computation, relevant to financial pricing. These components are compatible
with a scalable framework that leverages large scale parallelism and Quantum
Amplitude Estimation (QAE) to achieve quadratic speedup. The circuit was
implemented on IBM Qiskit and evaluated using 8 parallel threads and 1600
measurement shots. Results confirmed both the presence of randomness and the
correctness of payoff computation. While the current implementation uses 8
threads, the design scales to 2 to the power of n threads, for arbitrarily
large n, offering a potential path toward demonstrating quantum supremacy.

</details>


### [208] [Enhanced Extrapolation-Based Quantum Error Mitigation Using Repetitive Structure in Quantum Algorithms](https://arxiv.org/abs/2507.23314)
*Boseon Kim,Wooyeong Song,Kwangil Bae,Wonhyuk Lee,IlKwon Sohn*

Main category: quant-ph

TL;DR: 一种新的量子错误缓解方法，通过关注算法中的重复块来改进ZNE，在高噪声下表现优于传统ZNE。


<details>
  <summary>Details</summary>
Motivation: 量子纠错对于在嘈杂的中型量子设备中抑制错误至关重要，可以在没有完全纠错的开销的情况下实现更可靠的量子计算。零噪声外推（ZNE）是其中一种重要的量子错误缓解方法。然而，对于具有深度电路的算法，例如涉及多次预言调用的迭代量子算法，ZNE的有效性在高噪声下会显著降低。

Method: 提出了一种轻量级、基于外推的错误缓解框架，适用于由重复操作块构成的结构化量子算法。该方法通过使用浅层电路来表征重复的核心操作块的错误，而不是整个算法。使用外推法估计块保真度，然后重建缓解后的成功概率。

Result: 通过在IBM Aer模拟器上模拟6量子比特的Grover算法，并在Eagle r3上对127量子比特的IBM量子系统进行评估。结果表明，核心块的错误遵循高度一致的指数衰减，实现了鲁棒的错误缓解，克服了传统ZNE的限制。

Conclusion: 该方法在低噪声条件下接近理论成功概率，优于ZNE；在高噪声条件下，ZNE因过拟合其外推数据而无法缓解错误，而该方法实现了超过20%的成功率。

Abstract: Quantum error mitigation is a crucial technique for suppressing errors
especially in noisy intermediate-scale quantum devices, enabling more reliable
quantum computation without the overhead of full error correction. Zero-Noise
Extrapolation (ZNE), which we mainly consider in this work, is one of prominent
quantum error mitigation methods. For algorithms with deep circuits - such as
iterative quantum algorithms involving multiple oracle calls - ZNE's
effectiveness is significantly degraded under high noise. Extrapolation based
on such low-fidelity data often yields inaccurate estimates and requires
substantial overhead. In this study, we propose a lightweight,
extrapolation-based error mitigation framework tailored for structured quantum
algorithms composed of repeating operational blocks. The proposed method
characterizes the error of the repeated core operational block, rather than the
full algorithm, using shallow circuits. Extrapolation is used to estimate the
block fidelity, followed by a reconstruction of the mitigated success
probability. We validate our method via simulations of the 6-qubit Grover's
algorithm on IBM's Aer simulator, then further evaluating it on the real
127-qubit IBM Quantum system based on Eagle r3 under a physical noise
environment. Our results, particularly those from Aer simulator, demonstrate
that the core block's error follows a highly consistent exponential decay. This
allows our technique to achieve robust error mitigation, overcoming the
limitations of conventional ZNE which is often compromised by statistically
unreliable data from near-random behavior under heavy noise. In low-noise
conditions, our method approaches theoretical success probability, outperforms
ZNE. In high-noise conditions, ZNE fails to mitigate errors due to overfitting
of its extrapolation data, whereas our method achieves over a 20% higher
success probability.

</details>


### [209] [Transport-Induced Decoherence of the Entangled Triplet Exciton Pair](https://arxiv.org/abs/2507.23770)
*Gerald Curran III,Luke J. Weaver,Zachary Rex,Ivan Biaggio*

Main category: quant-ph

TL;DR: 研究了有机分子晶体中纠缠三线态对的退相干效应，发现量子拍的出现和衰减与激子跳跃速率、磁场强度有关。


<details>
  <summary>Details</summary>
Motivation: 为了分析激子在不等价晶格位点之间跳跃时，有机分子晶体中纠缠三线态对的退相干效应。

Method: 采用蒙特卡洛分析方法，研究了有机分子晶体中纠缠三线态对的退相干效应，并考虑了激子在不等价晶格位点之间跳跃的情况。

Result: 在零磁场下，根据激子跳跃速率的不同，可能会出现完全的全局退相干和荧光量子拍的抑制。此外，量子拍的衰减速率会随着磁场强度的变化而变化。

Conclusion: 本研究预测了由量子干涉引起的荧光量子拍，这种干涉发生在三线态-三线态复合到发光单线态时。这些量子拍作为跳跃时间和磁场的函数，基于蒙特卡洛分析。根据激子跳跃速率的不同，在零磁场极限下可能出现完全的全局退相干和荧光量子拍的抑制，并且量子拍的衰减速率会随着磁场强度的变化而变化。

Abstract: Decoherence effects for entangled triplet pairs in organic molecular crystals
are analyzed for the case when excitons can hop between inequivalent lattice
sites. The fluorescence quantum beats caused by quantum interference upon
triplet-triplet recombination into an emissive singlet state are predicted as a
function of hopping time and magnetic field based on a Monte Carlo analysis.
Depending on exciton hopping rates, it is possible to have complete global
decoherence and suppression of fluorescence quantum beats in the limit of zero
magnetic field, and to have quantum beats that decay at different rates
depending on magnetic field strength.

</details>


### [210] [Non-equilibrium thermodynamics of the quantum Brownian motion: Anomalous non-equilibrium currents arising from complete positivity](https://arxiv.org/abs/2507.23322)
*Simone Artini,Gabriele Lo Monaco,Alberto Imparato,Mauro Paternostro,Sandro Donadi*

Main category: quant-ph

TL;DR: 量子布朗运动的CPTP扩展在保证量子一致性的同时，在热力学上引入了非平衡效应，揭示了量子一致性与热力学平衡之间的矛盾。


<details>
  <summary>Details</summary>
Motivation: 广泛使用的Caldeira-Leggett主方程虽然表现出理想的热力学特征（如满足详细平衡），但未能保证完全正性。相反，几个完全正且保持迹的（CPTP）扩展在热力学上存在争议。

Method: 利用随机热力学框架，严格分析了量子布朗运动（QBM）各种形式的非平衡热力学行为。

Result: 研究表明，CPTP扩展引入了异常相空间结构，在稳态下违反详细平衡，导致熵产生和有效的非平衡电流出现，但其物理起源尚不明确。

Conclusion: 该研究揭示了开放量子系统中量子一致性与热力学平衡之间的根本性矛盾。

Abstract: We rigorously analyze the non-equilibrium thermodynamic behavior of various
formulations of quantum Brownian motion (QBM) using the framework of stochastic
thermodynamics. While the widely used Caldeira-Leggett master equation exhibits
desirable thermodynamic features, such as the fulfilment of a detailed balance,
it fails to ensure complete positivity. In contrast, several completely
positive and trace-preserving (CPTP) extensions turn out to be
thermodynamically controversial. We show that such extensions introduce
anomalous phase-space structures that violate detailed balance at the steady
state, leading to non-vanishing entropy production and effective
non-equilibrium current of unclear physical origins. Our results highlight a
fundamental tension between quantum consistency and thermodynamic equilibration
in open quantum systems.

</details>


### [211] [High-Performance Fully Passive Discrete-State Continuous-Variable Quantum Key Distribution With Local Local Oscillator](https://arxiv.org/abs/2507.23327)
*Yu Zhang,Xuyang Wang,Chenyang Li,Jie Yun,Qiang Zeng,Zhiliang Yuan,Zhenguo Lu,Yongmin Li*

Main category: quant-ph

TL;DR: 提出了一种全无源离散态连续变量量子密钥分发（CV-QKD）协议，使用本地本地振荡器（LLO）消除了源端调制器侧信道。该协议在100公里传输距离和1 GHz重复频率下，实现了127 kbps的密钥比特率，性能优于现有协议，有望用于量子城域网和量子接入网。


<details>
  <summary>Details</summary>
Motivation: 为了在量子密钥分发中消除源端调制器侧信道，并为量子城域网和量子接入网提供高现实安全性。

Method: 提出并演示了一种全无源离散态连续变量量子密钥分发（CV-QKD），它使用本地本地振荡器（LLO）消除了源端的所有调制器侧信道。

Result: 该CV-QKD系统实现了100公里的最大传输长度和1 GHz的重复频率，采用了特殊设计的相位旋转和离散化方法。基于发送端的制备状态幅度以及接收端的测量值的第一和第二阶矩，并采用凸优化方法，在不施加任何量子信道假设的情况下，估计的相应密钥比特率为127 kbps。该协议的性能与调制CV LLO协议相当，优于无源离散变量和CV协议。

Conclusion: 该协议有望在高现实安全性方面在量子城域网和量子接入网中发挥重要作用。

Abstract: We propose and demonstrate a fully passive discrete-state continuous-variable
quantum key distribution (CV-QKD), which can eliminate all modulator side
channels on the source side, using a local local oscillator (LLO). The CV-QKD
system achieves a maximum transmission length of 100 km with a repetition rate
of 1 GHz using specially designed phase rotation and discretization methods,
and the corresponding secret key bit rate is 127 kbps, as estimated based on
the amplitude of prepared states at the transmitter, as well as the first- and
second-order moments of quadratures at the receiver by employing the convex
optimization without imposing any assumptions on the quantum channel. The
performance of the protocol is similar to that of modulated CV LLO protocols
and better than those of passive discrete-variable and CV protocols. Our
protocol is expected to play an important role in the quantum metropolitan area
networks and quantum access networks with high realistic security.

</details>


### [212] [Transfer entropy and O-information to detect grokking in tensor network multi-class classification problems](https://arxiv.org/abs/2507.23346)
*Domenico Pomarico,Roberto Cilli,Alfonso Monaco,Loredana Bellantuono,Marianna La Rocca,Tommaso Maggipinto,Giuseppe Magnifico,Marlis Ontivero Ortega,Ester Pantaleo,Sabina Tangaro,Sebastiano Stramaglia,Roberto Bellotti,Nicola Amoroso*

Main category: quant-ph

TL;DR: 量子启发式机器学习（如 MPS 分类器）通过追踪纠缠和信息动力学，在理解和解释泛化现象方面展现出潜力，并揭示了多类分类中不同的学习行为。


<details>
  <summary>Details</summary>
Motivation: 为了研究量子增强机器学习（包括量子算法和张量网络等量子启发式经典方法）在从复杂、高维数据中提取结构方面的潜力。

Method: 采用张量网络（特别是矩阵乘积态 MPS）作为量子启发式机器学习方法。通过追踪纠缠熵、局部磁化强度和模型性能来研究 MPS 分类器在训练过程中的动力学。利用信息论工具，如迁移熵和 O-信息，来分析标签特定的量子掩码之间的因果依赖关系以及类输出之间的相关性。

Result: 研究发现，在 fashion MNIST 数据集上，“grokking”现象（即在记忆之后突然出现泛化）与急剧的纠缠转变和冗余信息峰值同时发生。而过拟合的高光谱模型则保持着协同的、无序的行为。

Conclusion: 研究结果强调了高阶信息动力学在量子启发学习中的相关性，并强调了多类分类中出现的可区分学习行为，为解释量子机器学习架构中的泛化提供了一个原则性框架。

Abstract: Quantum-enhanced machine learning, encompassing both quantum algorithms and
quantum-inspired classical methods such as tensor networks, offers promising
tools for extracting structure from complex, high-dimensional data. In this
work, we study the training dynamics of Matrix Product State (MPS) classifiers
applied to three-class problems, using both fashion MNIST and hyper-spectral
satellite imagery as representative datasets. We investigate the phenomenon of
grokking, where generalization emerges suddenly after memorization, by tracking
entanglement entropy, local magnetization, and model performance across
training sweeps. Additionally, we employ information theory tools to gain
deeper insights: transfer entropy is used to reveal causal dependencies between
label-specific quantum masks, while O-information captures the shift from
synergistic to redundant correlations among class outputs. Our results show
that grokking in the fashion MNIST task coincides with a sharp entanglement
transition and a peak in redundant information, whereas the overfitted
hyper-spectral model retains synergistic, disordered behavior. These findings
highlight the relevance of high-order information dynamics in quantum-inspired
learning and emphasize the distinct learning behaviors that emerge in
multi-class classification, offering a principled framework to interpret
generalization in quantum machine learning architectures.

</details>


### [213] [Measure of entanglement production by quantum operations](https://arxiv.org/abs/2507.23366)
*V. I. Yukalov,E. P. Yukalova*

Main category: quant-ph

TL;DR: A new, general measure quantifies entanglement production from quantum operations, working for all states and systems.


<details>
  <summary>Details</summary>
Motivation: The motivation is to provide a general and versatile measure for quantifying entanglement production by quantum operations, applicable across various types of states (pure/mixed) and processes (equilibrium/nonequilibrium), and accommodating diverse physical systems.

Method: The paper suggests a measure for entanglement production by quantum operations. It defines generalized correlation matrices to handle systems described by field operators, spin operators, or any other operators, making the measure applicable to systems of arbitrary nature.

Result: The proposed measure is general, valid for pure and mixed states, equilibrium and nonequilibrium processes, and systems of arbitrary nature. It satisfies all typical properties of such a characteristic. Particular cases of entanglement production are considered.

Conclusion: A general measure for entanglement production by quantum operations is proposed, applicable to both pure and mixed states, as well as equilibrium and nonequilibrium processes. It satisfies typical characteristics of such measures and can handle systems of arbitrary nature through generalized correlation matrices. Specific cases of entanglement production are also examined.

Abstract: A measure of entanglement production by quantum operations is suggested. This
measure is general, being valid for operations over pure states as well as over
mixed states, for equilibrium as well as for nonequilibrium processes. The
measure of entanglement production satisfies all properties typical of such a
characteristic. Systems of arbitrary nature can be treated, described by field
operators, spin operators, or any other operators, which is realized by
defining generalized correlation matrices. Particular cases of entanglement
production are considered.

</details>


### [214] [Analysis of untrusted-node quantum key distribution from a geostationary satellite](https://arxiv.org/abs/2507.23466)
*Thomas Liege,Perrine Lognone,Matteo Schiavon,Caroline B. Lim,Jean-Marc Conan,Eleni Diamanti,Daniele Dequal*

Main category: quant-ph

TL;DR: 研究人员模拟了星载和地面望远镜的量子密钥分发（QKD）性能，发现双场（TF）和模式配对（MP）QKD协议在具有挑战性的高损耗渠道中表现出高弹性，即使使用20厘米的地面望远镜，也有可能生成秘密密钥，显示出良好的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 为了实现全球量子密钥分发（QKD）网络，基于不可信节点（包括地静地卫星）的服务可以提供比可信节点替代方案更广泛的覆盖范围、持续运行和增强的安全性。

Method: 通过深入模拟并结合自适应光学校正的通信渠道，评估了在涉及星载50厘米望远镜和地面20厘米至1米望远镜的配置中，双场（TF）和模式配对（MP）QKD协议的预期秘密密钥速率。

Result: 在最佳情况下，并考虑到现实的探测器，TF-QKD和MP-QKD均可实现约几百比特/秒的秘密密钥速率。

Conclusion: 该研究表明，即使使用20厘米口径的地面望远镜，也可能实现量子密钥分发（QKD）的秘密密钥生成，这突显了这种配置的高可扩展性潜力。

Abstract: In pursuit of a global quantum key distribution (QKD) network, a service
based on untrusted nodes on geostationary satellites could offer wide coverage,
continuous operation, and enhanced security compared to the trusted node
alternative. Although this scenario has been studied for entanglement-based
protocols, such an approach would require large-area telescopes both on the
ground and in space. In this work, we analyze the performance of two QKD
protocols well adapted to this scenario, namely twin-field (TF) and
mode-pairing (MP) QKD, which exhibit high resilience to high-loss channels.
Leveraging an in-depth simulation of communication channels corrected with
adaptive optics, we assess the expected secret key rates for both protocols in
a configuration involving two 50 cm telescopes on board the satellite and
ground-based telescopes ranging from 20 cm to 1 m in aperture. Our results show
that, in the best case and considering realistic detectors, it is possible to
achieve secret key rates on the order of a few hundred bit/s for both TF and
MP-QKD. We show, notably, that secret key generation is potentially feasible
even with 20 cm ground telescopes, highlighting the high scalability potential
of such a configuration.

</details>


### [215] [On the complex zeros of the wavefunction](https://arxiv.org/abs/2507.23468)
*Sacha Cerf,Clara Wassner,Jack Davis,Francesco Arzani,Ulysse Chabaud*

Main category: quant-ph

TL;DR: 研究了玻色子量子系统的薛定谔波函数零点，并给出了信息论解释。证明了其波函数可扩展为复平面上的全纯函数，并推导了哈德逊定理的一个版本。研究结果表明，非高斯性可通过测量电磁场的一个二次方来检测。


<details>
  <summary>Details</summary>
Motivation: 研究量子力学、量子化学和玻色子量子信息论中普遍存在的薛定谔波函数，特别是对于玻色子系统，零集的理解较少，尤其是在刻画非经典性方面。

Method: 研究波函数的零点，并赋予它们新颖的信息论解释。证明了大多数玻色子量子系统的波函数可以扩展到复平面上的全纯函数，从而应用复分析技术。证明了哈德逊定理的一个版本，并将高斯动力学描述为波函数零点的经典运动。

Result: 证明了哈德逊定理的一个版本，并将高斯动力学描述为波函数零点的经典运动。研究结果表明，量子光学态的非高斯性可以通过测量电磁场的单个二次方来检测。

Conclusion: 研究结果表明，量子光学态的非高斯性可以通过测量电磁场的单个二次方来检测，并在另一篇论文[1]中进行了演示。更广泛地说，我们的结果表明，玻色子量子系统的非高斯特征被编码在其波函数的零点中。

Abstract: The Schr\"odinger wavefunction is ubiquitous in quantum mechanics, quantum
chemistry, and bosonic quantum information theory. Its zero-set for fermionic
systems is well-studied and central for determining chemical properties, yet
for bosonic systems the zero-set is less understood, especially in the context
of characterizing non-classicality. Here we study the zeros of such
wavefunctions and give them a novel information-theoretic interpretation. Our
main technical result is showing that the wavefunction of most bosonic quantum
systems can be extended to a holomorphic function over the complex plane,
allowing the application of powerful techniques from complex analysis. As a
consequence, we prove a version of Hudson's theorem for the wavefunction and
characterize Gaussian dynamics as classical motion of the wavefunction zeros.
Our findings suggest that the non-Gaussianity of quantum optical states can be
detected by measuring a single quadrature of the electromagnetic field, which
we demonstrate in a companion paper [1]. More generally, our results show that
the non-Gaussian features of bosonic quantum systems are encoded in the zeros
of their wavefunction.

</details>


### [216] [Classification of coined quantum walks on the line and comparison to correlated classical random walks](https://arxiv.org/abs/2507.23524)
*Lukas Hantzko,Lennart Binkowski*

Main category: quant-ph

TL;DR: 该研究对一维量子行走进行了分类，找到了对称行走条件，并提供了行走及其极限分布的参数化方法。研究还修正了行走振幅的计算，并将量子行走与经典随机行走进行了比较，发现了量子行走具有二次扩散特征，而经典行走具有线性行为。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在对一维量子行走进行全面的分类，特别关注其诱导的空间概率分布。研究的目标是识别导致对称量子行走的初始条件，并提供一种参数化方法来描述所有对称和非对称的量子行走及其极限分布。此外，研究还旨在解决先前文献中关于行走振幅的不准确之处，并将量子行走与经典随机行走进行比较，以揭示量子和经典动力学之间的异同。

Method: 该研究通过识别所有能导致对称量子行走（对于任意硬币）的初始硬币状态，并提供对称量子行走（模分布等价）的双射参数化，对一维量子行走进行了分类。此外，研究还通过提供所有量子行走（模等价）的满射参数化以及行走极限分布（模等价）的双射参数化，扩展了研究范围。研究推导了行走振幅的修正闭合形式表达式，并将该方法推广到相关经典随机行走。最后，通过比较量子行走与经典随机行走的方差渐近标度和极限分布，对两者进行了对比。

Result: 该研究对一维量子行走进行了分类，确定了导致对称量子行走的所有初始硬币状态，并提供了对称量子行走（模分布等价）的双射参数化。此外，还提供了所有量子行走（模等价）的满射参数化以及行走极限分布（模等价）的双射参数化。研究推导了行走振幅的修正闭合形式表达式，并将方法推广到相关经典随机行走，实现了量子和经典动力学的直接比较。研究还发现，非平凡量子行走以二次扩散为特征，而经典行走则表现出线性行为（在最大相关性的极值点除外），并对量子行走产生的极限分布与经典情况下的分布进行了比较。

Conclusion: 该研究对一维量子行走进行了全面的分类，特别是其诱导的空间概率分布。研究确定了所有能导致对称量子行走（对于任意硬币）的初始硬币状态，并提供了对称量子行走（模分布等价）的双射参数化。此外，还提供了所有量子行走（模等价）的满射参数化以及行走极限分布（模等价）的双射参数化。研究还推导了行走振幅的修正闭合形式表达式，解决了先前文献中的不准确之处，并将该方法推广到相关经典随机行走。该统一框架能够直接比较量子和经典动力学。此外，研究还讨论了两种模型的方差渐近标度，将二次扩散识别为非平凡量子行走的标志，并将其与经典行走（除了在最大相关性的极值点）的线性行为进行对比。最后，研究比较了量子行走产生的极限分布与经典情况下的分布。

Abstract: We present a comprehensive classification of one-dimensional coined quantum
walks on the infinite line, focusing on the spatial probability distributions
they induce. Building on prior results, we identify all initial coin states
that lead to symmetric quantum walks for arbitrary coins, and provide a
bijective parametrisation of all symmetric quantum walks modulo distributional
equivalence. Extending beyond the symmetric case, we also give a surjective
parametrisation of all coined quantum walks under the same equivalence relation
and a bijective parametrisation modulo equivalence of the walks' limiting
distributions.
  Furthermore, we derive corrected closed-form expressions for the walk
amplitudes, resolving inaccuracies in previous literature, and generalise the
approach to the correlated classical random walk. This unified framework
enables a direct comparison between quantum and classical dynamics.
Additionally, we discuss the asymptotic scaling of variances for both models,
identifying quadratic spreading as a hallmark of non-trivial quantum walks and
contrasting it with the linear behaviour of classical walks, except at the
extremal points of maximal correlation. Finally, we compare the limiting
distributions arising from quantum walks with the ones in the classical case.

</details>


### [217] [Quantum-enhanced dark matter detection using Schrödinger cat states](https://arxiv.org/abs/2507.23538)
*Pan Zheng,Yanyan Cai,Bin Xu,Shengcheng Wen,Libo Zhang,Zhongchu Ni,Jiasheng Mai,Yanjie Zeng,Lin Lin,Ling Hu,Xiaowei Deng,Song Liu,Jing Shu,Yuan Xu,Dapeng Yu*

Main category: quant-ph

TL;DR: 该研究利用薛定谔猫态提高了暗光子探测的灵敏度，达到了10$^{-16}$量级，并将暗光子动量混合角限制在$
u < 7.32 	imes 10^{-16}$。


<details>
  <summary>Details</summary>
Motivation: 利用量子计量学，特别是非经典态（如薛定谔猫态），来提高暗物质探测的灵敏度，并探索潜在的暗物质候选者——暗光子。

Method: 采用包含薛定谔猫态的超导微波腔，并结合参数化边带驱动技术，实现了对暗光子的探测。

Result: 实现了8.1倍的信号光子率提升，并将暗光子动量混合角限制在$
u < 7.32 	imes 10^{-16}$，在100 kHz带宽内达到了10$^{-16}$量级的灵敏度。

Conclusion: 该研究首次将四组分薛定谔猫态应用于超导微波腔中的暗光子探测，并通过参数化边带驱动实现了跨多个频率箱的暗光子搜索和背景扣除，达到了10$^{-16}$量级的灵敏度，并将暗光子动量混合角限制在$
u < 7.32 	imes 10^{-16}$。

Abstract: Quantum metrology enables sensitive dark matter detection, particularly using
nonclassical states, such as Schr\"odinger cat states featuring sub-Planck
interference structures in microwave cavities. Here, we report the first
experimental application of four-component Schr\"odinger cat states within a
high-quality superconducting microwave cavity to detect dark photons, a
potential dark matter candidate. We demonstrate an 8.1-fold enhancement in the
signal photon rate and constrain the dark photon kinetic mixing angle to an
unprecedented $\epsilon < 7.32 \times 10^{-16}$ near 6.44~GHz (26.6~$\mu$eV).
By employing a parametric sideband drive to actively tune the cavity frequency,
we achieve dark photon searches and background subtraction across multiple
frequency bins, yielding a sensitivity at the $10^{-16}$ level within a 100~kHz
bandwidth. Our Schr\"odinger's cat-assisted detection (SCaD) scheme
demonstrates a substantial improvement over previous results, promising
potential implications in quantum-enhanced searches for new physics.

</details>


### [218] [Hybrid Quasi-Bound State in the Continuum at Topological Quantum Optics Interface](https://arxiv.org/abs/2507.23582)
*Yue-Zhi Zhang,Leong-Chuan Kwek,Wei Nie*

Main category: quant-ph

TL;DR: 拓扑原子阵列通过光-物质相互作用在波导中诱导光局域化，发现了新的拓扑准BIC，并展示了其在超窄放大器中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 拓扑光操控为光子技术提供了一个通用的工具箱。

Method: 通过对称性保护的光-物质相互作用，在波导中诱导光局域化。

Result: 发现了由集体诱导吸收产生的、位于临界耦合条件下的混合光-物质准BIC，这是由边缘态和体态之间的量子干涉产生的。揭示了拓扑准BIC和光放大之间的逆时衅关系，并发现可以通过临界耦合实现定向超窄放大器。

Conclusion: 本文展示了一种在拓扑量子光学界面处具有潜在量子器件应用的非常规准BIC。

Abstract: Topological manipulation of light provides a versatile toolbox for photonic
technologies. Here, we show that a topological atom array can induce photon
localization in a waveguide via symmetry-protected light-matter interaction.
Long-lived photon-atom entanglement reveals the existence of a novel
topological quasi-bound state in the continuum (quasi-BIC). This hybrid
light-matter quasi-BIC is formed at a critical coupling condition via
collectively induced absorption, which is produced by quantum interference
between edge and bulk states. We uncover the time-reversed relation between
topological quasi-BIC and light amplification. Interestingly, one can realize a
directional ultranarrow amplifier by means of critical coupling. Our work
demonstrates an unconventional quasi-BIC at a topological quantum optics
interface with potential applications in quantum devices.

</details>


### [219] [Characterizing the Kirkwood-Dirac positivity on second countable LCA groups](https://arxiv.org/abs/2507.23628)
*Matéo Spriet*

Main category: quant-ph

TL;DR: Introduced an abstract Kirkwood-Dirac quasiprobability representation for quantum mechanics, linked it to Wigner-Weyl quantization, identified specific states with positive distributions, and characterized the classical fragment's properties and geometry for certain groups.


<details>
  <summary>Details</summary>
Motivation: To define and analyze the Kirkwood-Dirac quasiprobability representation in an abstract setting and identify generalized pure states with positive distributions.

Method: Define the Kirkwood-Dirac quasiprobability representation associated with Fourier transform over second countable locally compact abelian groups, discuss its link with Kohn-Nirenberg quantization, and use it to interpret Wigner-Weyl quantization as a symmetric ordering.

Result: Identified generalized pure states with positive Kirkwood-Dirac distributions as Haar measures on closed subgroups (up to Weyl-Heisenberg group action), established conditions for a non-trivial classical fragment, and provided a geometric description for connected compact abelian groups.

Conclusion: We provide a complete geometric description of the classical fragment for connected compact abelian groups, generalizing results for finite abelian groups and showing that the classical fragment is non-trivial if and only if the group has a compact connected component.

Abstract: We define the Kirkwood-Dirac quasiprobability representation of quantum
mechanics associated with the Fourier transform over second countable locally
compact abelian groups. We discuss its link with the Kohn-Nirenberg
quantization of the phase space $G\times \widehat{G}$. We use it to argue that
in this abstract setting the Wigner-Weyl quantization, when it exists, can
still be interpreted as a symmetric ordering. Then, we identify all generalized
(non-normalizable) pure states having a positive Kirkwood-Dirac distribution.
They are, up to the natural action of the Weyl-Heisenberg group, Haar measures
on closed subgroups. This generalizes a result known for finite abelian groups.
We then show that the classical fragment of quantum mechanics associated with
the Kirkwood-Dirac distribution is non-trivial if and only if the group has a
compact connected component. Finally, we provide for connected compact abelian
groups a complete geometric description of this classical fragment.

</details>


### [220] [Probing electronic state-dependent conformational changes in a trapped Rydberg ion Wigner crystal](https://arxiv.org/abs/2507.23631)
*Marion Mallweger,Natalia Kuk,Vinay Shankar,Robin Thomm,Harry Parke,Ivo Straka,Weibin Li,Igor Lesanovsky,Markus Hennrich*

Main category: quant-ph

TL;DR: 首次在实验中观测到里德堡离子诱导的构象变化，为研究人工分子系统提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 分子动力学中的状态依赖的构象变化难以观察或模拟，提出使用冷、囚禁离子进行量子模拟来模拟这些现象。

Method: 通过激光将三离子晶体中心的单个离子耦合到里德堡态，并调谐系统接近结构相变点。

Result: 观测到里德堡态激发诱导了状态依赖的构象变化，将维格纳晶体从线性构型转变为之字形构型，并产生了清晰的光谱信号。

Conclusion: 该研究首次通过实验观测到里德堡离子诱导的、与电子激发相关的状态依赖的构象变化，为使用里德堡离子构建和研究人工分子系统奠定了实验基础。

Abstract: State-dependent conformational changes play a central role in molecular
dynamics, yet they are often difficult to observe or simulate due to their
complexity and ultrafast nature. One alternative approach is to emulate such
phenomena using quantum simulations with cold, trapped ions. In their
electronic ground state, these ions form long-lived Wigner crystals. When
excited to high-lying electronic Rydberg states, the ions experience a modified
trapping potential, resulting in a strong coupling between their electronic and
vibrational degrees of freedom. In an ion crystal, this vibronic coupling
creates electronic state-dependent potential energy surfaces that can support
distinct crystal structures -- closely resembling the conformational changes of
molecules driven by electronic excitations. Here, we present the first
experimental observation of this effect, by laser-coupling a single ion at the
centre of a three-ion crystal to a Rydberg state. By tuning the system close to
a structural phase transition, the excitation induces a state-dependent
conformational change, transforming the Wigner crystal from a linear to a
zigzag configuration. This structural change leads to a strong hybridisation
between vibrational and electronic states, producing a clear spectroscopic
signature in the Rydberg excitation. Our findings mark the first experimental
step towards using Rydberg ions to create and study artificial molecular
systems. change leads to a strong hybridisation between vibrational and
electronic states, producing a clear spectroscopic signature in the Rydberg
excitation. Our findings mark the first experimental step towards using Rydberg
ions to create and study artificial molecular systems.

</details>


### [221] [Charge acceleration without radiation](https://arxiv.org/abs/2507.23650)
*Yakir Aharonov,Daniel Collins,Sandu Popescu*

Main category: quant-ph

TL;DR: 量子力学允许电荷在没有力的作用下被加速，从而在特定条件下可以不辐射，这可能需要重新审视辐射的基本概念。


<details>
  <summary>Details</summary>
Motivation: 本文旨在证明量子力学中电荷在被加速时可以不辐射，挑战了以往普遍的认知。

Method: 通过论证量子力学允许粒子在没有力的作用下被加速（通过Aharonov-Bohm效应）来证明电荷在被加速时可以不辐射。

Result: 展示了电荷在特定量子力学条件下（通过Aharonov-Bohm效应）可以被加速而不产生电磁辐射。

Conclusion: 量子力学允许在没有力的作用下加速电荷，这可能意味着需要重新考虑辐射的基本理解，并且该效应可能超越电磁学，适用于任何类型的辐射。

Abstract: The existence of electromagnetic radiation - radio-waves, microwaves, light,
x-rays and so on - is one of the most important physical phenomena, and our
ability to manipulate them is one of the most significant technological
achievement of humankind. Underlying this ability is our understanding of how
radiation is produced: whenever an electric charge is accelerated, it radiates.
Or, at least, this is how it has been hitherto universally thought. Here we
prove that quantum mechanically electric charges can be accelerated without
radiating. The physical setup leading to this behavior is relatively simple
(once one knows what to do) but its reasons are deep: it relies on the fact
that quantum mechanically particles can be accelerated even when no forces act
on them, via the Aharonov-Bohm effect. As we argue, the effect presented here
is just them tip of an iceberg - it implies the need to reconsider the basic
understanding of radiation. Finally, it seems clear that the effect goes far
beyond electromagnetism and applies to any kind of radiation.

</details>


### [222] [Swap Network Augmented Ansätze on Arbitrary Connectivity](https://arxiv.org/abs/2507.23679)
*Teodor Parella-Dilmé*

Main category: quant-ph

TL;DR: This paper presents a method to improve quantum algorithms by optimizing qubit routing with swap networks and embedding them into circuit layers. This leads to better performance with fewer resources, especially on quantum processors with limited connectivity.


<details>
  <summary>Details</summary>
Motivation: Efficient parametrizations of quantum states are crucial for trainable hybrid classical-quantum algorithms. A major challenge is adapting to the qubit connectivity of quantum processors, which restricts the ability to generate correlations between distant qubits efficiently and trainably.

Method: Introduce an algorithm that optimizes qubit routing for arbitrary connectivity graphs, creating a swap network for direct interactions between any pair of qubits. Propose a co-design of circuit layers and qubit routing by embedding these swap networks within layered, connectivity-aware ansätze.

Result: The swap-enhanced ansatz consistently achieves lower energy errors with fewer entangling gates, shallower circuits, and fewer parameters than standard baselines across various connectivities. This is demonstrated through ground-state simulations of strongly correlated systems like spin-glass and molecular electronic structure models.

Conclusion: The proposed swap network augmented ansätze enhance trainability and offer resource-efficient design for capturing complex correlations on devices with constrained qubit connectivity.

Abstract: Efficient parametrizations of quantum states are essential for trainable
hybrid classical-quantum algorithms. A key challenge in their design consists
in adapting to the available qubit connectivity of the quantum processor, which
limits the capacity to generate correlations between distant qubits in a
resource-efficient and trainable manner. In this work we first introduce an
algorithm that optimizes qubit routing for arbitrary connectivity graphs,
resulting in a swap network that enables direct interactions between any pair
of qubits. We then propose a co-design of circuit layers and qubit routing by
embedding the derived swap networks within layered, connectivity-aware
ans\"atze. This construction significantly improves the trainability of the
ansatz, leading to enhanced performance with reduced resources. We showcase
these improvements through ground-state simulations of strongly correlated
systems, including spin-glass and molecular electronic structure models. Across
exemplified connectivities, the swap-enhanced ansatz consistently achieves
lower energy errors using fewer entangling gates, shallower circuits, and fewer
parameters than standard layered-structured baselines. Our results indicate
that swap network augmented ans\"atze provide enhanced trainability and
resource-efficient design to capture complex correlations on devices with
constrained qubit connectivity.

</details>


### [223] [Probing graph topology from local quantum measurements](https://arxiv.org/abs/2507.23689)
*F. Romeo,J. Settino*

Main category: quant-ph

TL;DR: 通过本地量子测量可以推断出量子网络的全局属性，例如平均度、中心节点密度和闭合路径数。此方法可能有助于量子互联网的入侵检测和结构诊断。


<details>
  <summary>Details</summary>
Motivation: 为了推断未知量子网络的全局属性，例如平均度、中心节点密度以及固定长度闭合路径的数量。

Method: 该方法结合了极短时间的量子演化和可训练权重的非迭代线性读出，该方法受到极端学习和量子储层计算的启发。

Result: 通过仅本地化的量子测量，可以推断出未知量子网络的全局属性，例如平均度、中心节点密度以及固定长度闭合路径的数量。即使恶意行为者仅能访问一小部分节点，他们也可以通过初始化本地量子态和重复的短时测量来提取有关整个网络的敏感结构信息。

Conclusion: 所提出的方法可以通过仅本地化的量子测量来推断未知量子网络的全局属性，这可能为量子互联网基础设施中的入侵检测和结构诊断提供新的策略。

Abstract: We show that global properties of an unknown quantum network, such as the
average degree, hub density, and the number of closed paths of fixed length,
can be inferred from strictly local quantum measurements. In particular, we
demonstrate that a malicious agent with access to only a small subset of nodes
can initialize quantum states locally and, through repeated short-time
measurements, extract sensitive structural information about the entire
network. The intrusion strategy is inspired by extreme learning and quantum
reservoir computing and combines short-time quantum evolution with a
non-iterative linear readout with trainable weights. These results suggest new
strategies for intrusion detection and structural diagnostics in future quantum
Internet infrastructures.

</details>


### [224] [Sandwich test for Quantum Phase Estimation](https://arxiv.org/abs/2507.23716)
*Avatar Tulsi*

Main category: quant-ph

TL;DR: 量子相位估计（QPE）的新算法SANDWICH测试，解决了现有SHT算法因$\\|\langle \psi|U^{k'}|\psi\rangle|\,k' \leq k$的最小值$r_{m min}$过小导致效率低下的问题，将运行时间复杂度从$\\(mathcal{O}(k^{3}/\epsilon^{2}r_{m min}^{2})$降低到$\\(mathcal{O}(k^{2}\ln k/ \epsilon^{2} s_{m min}^{6})$，提高了QPE在科学研究中的实际应用效率。


<details>
  <summary>Details</summary>
Motivation: 量子相位估计（QPE）在药物发现、材料科学等领域具有革命性潜力。然而，传统Hadamard测试需要受控的$U^k$操作，难以实现。顺序Hadamard测试（SHT）虽然只需要受控的$U$操作，但其运行时间$T_{\rm tot}$随$r_{m min}$（$\\|\langle \psi|U^{k'}|\psi\rangle|\,k' \leq k$的最小值）的减小而急剧增加，而$r_{m min}$通常呈指数级减小，使得SHT在实际应用中效率低下。

Method: 提出了一种新的SANDWICH测试算法，该算法利用初始态$\\|\psi\rangle$的有效制备来高效实现SPROTIS算符$R_{\psi}^{\phi}$，并通过将SPROTIS算符置于$U^{a}$和$U^{b}$之间（其中$\\{a,b\}\\$为$\\<k$)来估计$\\<\psi|U^{k}|\psi\rangle$。

Result: SANDWICH测试算法将总运行时间$T_{\rm tot}$复杂度从SHT的$\\(mathcal{O}(k^{3}/\epsilon^{2}r_{m min}^{2})$降低到$\\(mathcal{O}(k^{2}\ln k/ \epsilon^{2} s_{m min}^{6})$，其中$s_{m min}$是随机二叉和树的节点值的绝对最小值。由于随机二叉和树的选择具有很大的自由度，可以预期$s_{m min} \not\ll 1$，从而显著提高了算法效率。

Conclusion: 该研究提出了SANDWICH测试算法，有效解决了顺序Hadamard测试（SHT）中$r_{m min}$值过小导致的运行时间过长的问题，将总运行时间复杂度从$\\(mathcal{O}(k^{3}/\epsilon^{2}r_{m min}^{2})$降低到$\\(mathcal{O}(k^{2}\ln k/ \epsilon^{2} s_{m min}^{6})$，并且在典型情况下$s_{m min} \not\ll 1$，具有良好的应用前景。

Abstract: Quantum Phase Estimation (QPE) has potential for a scientific revolution
through numerous practical applications like finding better medicines,
batteries, materials, catalysts etc. Many QPE algorithms use the Hadamard test
to estimate $\langle \psi|U^{k}|\psi\rangle$ for a large integer $k$ for an
efficiently preparable initial state $|\psi\rangle$ and an efficiently
implementable unitary operator $U$. The Hadamard test is hard to implement
because it requires controlled applications of $U^{k}$. Recently, a Sequential
Hadamard test (SHT) was proposed (arXiv:2506.18765) which requires controlled
application of $U$ only but its total run time $T_{\rm tot}$ scales as
$\mathcal{O}(k^{3}/\epsilon^{2}r_{\rm min}^{2})$ where $r_{\rm min}$ is the
minimum value of $|\langle \psi|U^{k'}|\psi\rangle|$ among all integers $k'
\leq k$. Typically $r_{\rm min}$ is exponentially low and SHT becomes too slow.
We present a new algorithm, the SANDWICH test to address this bottleneck. Our
algorithm uses efficient preparation of the initial state $|\psi\rangle$ to
efficiently implement the SPROTIS operator $R_{\psi}^{\phi}$ where SPROTIS
stands for the Selective Phase Rotation of the Initial State. It sandwiches the
SPROTIS operator between $U^{a}$ and $U^{b}$ for integers $\{a,b\} \leq k$ to
estimate $\langle \psi|U^{k}|\psi\rangle$. The total run time $T_{\rm tot}$ is
$\mathcal{O}(k^{2}\ln k/ \epsilon^{2} s_{\rm min}^{6})$. Here $s_{\rm min}$ is
the minimum value of $|\langle \psi|U^{\hat{k}}|\psi\rangle$ among all integers
$\hat{k}$ which are values of the nodes of a random binary sum tree whose root
node value is $k$ and leaf nodes' values are $1$ or $0$. It can be reasonably
expected that $s_{\rm min} \not\ll 1$ in typical cases because there is wide
freedom in choosing the random binary sum tree.

</details>


### [225] [Quantum scarring enhances non-Markovianity of subsystem dynamics](https://arxiv.org/abs/2507.23757)
*Aditya Banerjee*

Main category: quant-ph

TL;DR: 量子疤痕增强了量子系统的非马尔可夫性。


<details>
  <summary>Details</summary>
Motivation: 任何封闭非平衡量子系统的子系统都是开放量子系统，其动力学可以是马尔可夫性的（无记忆）或非马尔可夫性的（有记忆），后者会阻碍弛豫和热化过程。非遍历动力学发生在初始状态具有所谓的量子疤痕态的谱权重时，这些量子疤痕态是嵌入在热态谱中的非热化态。

Method: 通过数值证据，在PXP模型及其形变中，通过探测信息回溯和子系统动力学行为来展示量子疤痕的存在。

Result: 量子疤痕的存在增强了子系统动力学的非马尔可夫性。疤痕增强（擦除）的形变也分别表现出增强（减弱）的子系统非马尔可夫性。PXP模型及其形变展示了系统疤痕动力学的系统性特征。

Conclusion: 量子疤痕是实现和增强子系统动力学非马尔可夫性的微观成分，这为理解量子疤痕的动力学记忆开辟了新的途径。

Abstract: Given that any subsystem of a closed out-of-equilibrium quantum system is an
open quantum system, its dynamics (reduced from the full system's unitary
evolution) can be either Markovian (memory-less) or non-Markovian, with the
latter necessarily impeding the process of relaxation and thermalization.
Seemingly independently, such non-ergodic dynamics occurs when an initial state
has spectral weight on the so-called quantum scar states, which are
non-thermalizing states embedded deep in the spectrum of otherwise thermal
states. In this article, we present numerical evidence that the presence of
quantum scars is a microscopic ingredient that enables and enhances
non-Markovianity of the dynamics of subsystems. We exemplify this with the PXP
model and its deformations which either enhance or erase the signatures of
scarred dynamics when quenched from a simple product state that is known to
have significant overlaps with the scarred subspace in the spectrum. By probing
information backflows with the dynamical behaviour of the distances between
temporally-separated states of small subsystems, systematic signatures of
subsystem non-Markovianity in these models are presented, and it is seen that
scarring-enhancing (erasing) deformations also exhibit enhanced (diminished)
subsystem non-Markovianity. This sheds new light on the dynamical memories
associated with quantum scarring, and opens interesting new questions at the
interface of quantum scarring and an open quantum systems approach to
investigating far-from-equilibrium and non-thermalizing isolated quantum
many-body systems.

</details>


### [226] [Universal tradeoff relations between resource cost and irreversibility of channels: General-resource Wigner-Araki-Yanase theorems and beyond](https://arxiv.org/abs/2507.23760)
*Hiroyasu Tajima,Koji Yamaguchi,Ryuji Takagi,Yui Kuramochi*

Main category: quant-ph

TL;DR: 量子过程的不可逆性越低，其所需的资源成本就越高。本研究提出了一个普遍的权衡定律，并将其实例化为能量-误差权衡、自由能和功耗的扩展，以及在资源理论中测量失败概率与资源成本的反比关系。


<details>
  <summary>Details</summary>
Motivation: 设计下一代量子设备需要确定实现所需量子过程所需的物理资源的类型和数量。

Method: 通过将量子资源理论应用于量子过程，证明了普遍的成本-不可逆性权衡定律，该定律适用于能量、魔力、不对称性、相干性、非热性等多种资源，并为任何量子信道提供了资源成本的下界。

Result: 1. 证明了能量成本与不可逆性之间的普遍关系，涵盖了任何测量或酉门（unitary gate）的能量-误差权衡；2. 将能量-误差权衡扩展到自由能和功耗；3. 将Wigner-Araki-Yanase定理（测量下守恒定律的普遍限制）扩展到多种资源理论，即通过测量区分资源态的失败概率与其资源成本成反比；4. 证明了无限多个非增加资源的操作实际上需要无限的实现成本。

Conclusion: 本研究揭示了量子性与不可逆性之间的普遍关系，为解释量子性何时以及如何抑制不可逆性提供了初步的理论基础。

Abstract: Quantum technologies offer exceptional -- sometimes almost magical -- speed
and performance, yet every quantum process costs physical resources. Designing
next-generation quantum devices, therefore, depends on solving the following
question: which resources, and in what amount, are required to implement a
desired quantum process? Casting the problem in the language of quantum
resource theories, we prove a universal cost-irreversibility tradeoff: the
lower the irreversibility of a quantum process, the greater the required
resource cost for its realization. The trade-off law holds for a broad range of
resources -- energy, magic, asymmetry, coherence, athermality, and others --
yielding lower bounds on resource cost of any quantum channel. Its broad scope
positions this result as a foundation for deriving the following key results:
(1) we show a universal relation between the energetic cost and the
irreversibility for arbitrary channels, encompassing the energy-error tradeoff
for any measurement or unitary gate; (2) we extend the energy-error tradeoff to
free energy and work costs; (3) we extend the Wigner-Araki-Yanase theorem,
which is the universal limitation on measurements under conservation laws, to a
wide class of resource theories: the probability of failure in distinguishing
resourceful states via a measurement is inversely proportional to its resource
cost; (4) we prove that infinitely many resource-non-increasing operations in
fact require an infinite implementation cost. These findings reveal a universal
relationship between quantumness and irreversibility, providing a first step
toward a general theory that explains when -- and how -- quantumness can
suppress irreversibility.

</details>


### [227] [Intrinsic Heralding and Optimal Decoders for Non-Abelian Topological Order](https://arxiv.org/abs/2507.23765)
*Dian Jing,Pablo Sala,Liang Jiang,Ruben Verresen*

Main category: quant-ph

TL;DR: 该研究利用非阿贝尔任意子的特性来提高量子信息的稳定性和容错能力，特别是在噪声环境下。


<details>
  <summary>Details</summary>
Motivation: 拓扑序（TO）为存储和操纵量子信息提供了一个自然的平台，但其对噪声的稳定性仅对阿贝尔 TO 得到了系统的理解。

Method: 利用非阿贝尔任意子的非确定性融合来指导主动纠错和设计解码器，其中融合产物而非标志量子位来宣告噪声。。

Result: 在噪声主要由单一非阿贝尔任意子类型引起的情况下，这种内在宣告可以提高阈值。此外，还提出了一种利用贝叶斯推断将统计力学模型制作为任意噪声模型的非阿贝尔 TO 完美任意子综合症的最优阈值确定方法。对于非阿贝尔电荷噪声和完美的综合症测量，最优阈值 $p_c=0.218(1)$，而固有的宣告的最小权重完美匹配（MWPM）解码器已给出 $p_c=0.20842(2)$，优于标准的 MWPM $p_c = 0.15860(1)$。

Conclusion: 该工作展示了非阿贝尔拓扑序（TO）如何通过固有宣告来增强稳定性，而非降低稳定性，并讨论了实现容错的潜在通用方法。

Abstract: Topological order (TO) provides a natural platform for storing and
manipulating quantum information. However, its stability to noise has only been
systematically understood for Abelian TOs. In this work, we exploit the
non-deterministic fusion of non-Abelian anyons to inform active error
correction and design decoders where the fusion products, instead of flag
qubits, herald the noise. This intrinsic heralding enhances thresholds over
those of Abelian counterparts when noise is dominated by a single non-Abelian
anyon type. Furthermore, we present an approach for determining the optimal
threshold for non-Abelian TOs with perfect anyon syndromes for any noise model,
formulated as a statistical mechanics model using Bayesian inference. We
numerically illustrate these results for $D_4 \cong \mathbb Z_4 \rtimes \mathbb
Z_2$ TO. In particular, for non-Abelian charge noise and perfect syndrome
measurement, we find an optimal threshold $p_c=0.218(1)$, whereas an
intrinsically heralded minimal-weight perfect-matching (MWPM) decoder already
gives $p_c=0.20842(2)$, outperforming standard MWPM with $p_c = 0.15860(1)$.
Our work highlights how non-Abelian properties can enhance stability, rather
than reduce it, and discusses potential generalizations for achieving fault
tolerance.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [228] [Learning to Prune Branches in Modern Tree-Fruit Orchards](https://arxiv.org/abs/2507.23015)
*Abhinav Jain,Cindy Grimm,Stefan Lee*

Main category: cs.RO

TL;DR: 机器人通过视觉-运动控制器进行果树修剪，使用光流图像而非3D重建，在模拟和现实世界中均有应用，成功率为30%。


<details>
  <summary>Details</summary>
Motivation: 休眠期树木修剪是现代高产果园维护的关键环节，但非常耗费人力。

Method: 本研究提出了一种闭环视觉-运动控制器，用于指导机器人进行修剪。该控制器利用腕部摄像头的光流图像，在复杂的树木环境中引导切割器到达指定的切割点，并确保切割器垂直于树枝。研究人员使用了一种新颖的果园模拟器来训练控制器，该模拟器能够捕捉目标苹果园的几何分支分布。

Result: 与需要完整3D重建的传统方法不同，该控制器仅使用来自腕部摄像头的光流图像，并实现了30%的成功率，约为神谕规划器性能的一半。

Conclusion: 该控制器在模拟和现实世界中都得到了部署，并针对一个V型栅栏苹果树进行了测试，实现了30%的成功率，但性能约为神谕规划器的一半。

Abstract: Dormant tree pruning is labor-intensive but essential to maintaining modern
highly-productive fruit orchards. In this work we present a closed-loop
visuomotor controller for robotic pruning. The controller guides the cutter
through a cluttered tree environment to reach a specified cut point and ensures
the cutters are perpendicular to the branch. We train the controller using a
novel orchard simulation that captures the geometric distribution of branches
in a target apple orchard configuration. Unlike traditional methods requiring
full 3D reconstruction, our controller uses just optical flow images from a
wrist-mounted camera. We deploy our learned policy in simulation and the
real-world for an example V-Trellis envy tree with zero-shot transfer,
achieving a 30% success rate -- approximately half the performance of an oracle
planner.

</details>


### [229] [A Certifably Correct Algorithm for Generalized Robot-World and Hand-Eye Calibration](https://arxiv.org/abs/2507.23045)
*Emmett Wise,Pushyami Kaveti,Qilong Chen,Wenhao Wang,Hanumant Singh,Jonathan Kelly,David M. Rosen,Matthew Giamou*

Main category: cs.RO

TL;DR: 提出了一种高效且可证明全局最优的广义机器人-世界和手眼校准（RWHEC）算法，该算法对环境假设少，操作员付出少，并提供了性能优势和理论保证。


<details>
  <summary>Details</summary>
Motivation: 机器人外参标定是多传感器平台的一个基本问题。为了满足机器人研究中对计算效率、对环境结构假设少以及操作员付出少的需求，本研究旨在解决机器人-世界和手眼校准（RWHEC）问题。

Method: 提出了一种快速且可认证全局最优的算法来解决广义的机器人-世界和手眼校准（RWHEC）问题。该方法支持同时估计多个传感器和目标位姿，并允许使用单目相机。此外，还引入了一个互补的李代数局部求解器，并与全局方法和现有技术进行了比较。

Result: 提出的算法在性能上优于现有解决方案，并推导了新颖的可识别性标准，为具有有界测量误差的问题实例建立了先验全局最优性保证。此外，还对局部求解器的性能进行了比较。

Conclusion: 该研究提出了一种新颖的、可认证全局最优的算法，用于解决广义的机器人-世界和手眼校准（RWHEC）问题。该方法在计算效率、对环境结构假设少以及操作员付出少等方面表现优于现有解决方案，并提供了新颖的可识别性标准和全局最优性保证。

Abstract: Automatic extrinsic sensor calibration is a fundamental problem for
multi-sensor platforms. Reliable and general-purpose solutions should be
computationally efficient, require few assumptions about the structure of the
sensing environment, and demand little effort from human operators. Since the
engineering effort required to obtain accurate calibration parameters increases
with the number of sensors deployed, robotics researchers have pursued methods
requiring few assumptions about the sensing environment and minimal effort from
human operators. In this work, we introduce a fast and certifiably globally
optimal algorithm for solving a generalized formulation of the
$\textit{robot-world and hand-eye calibration}$ (RWHEC) problem. The
formulation of RWHEC presented is "generalized" in that it supports the
simultaneous estimation of multiple sensor and target poses, and permits the
use of monocular cameras that, alone, are unable to measure the scale of their
environments. In addition to demonstrating our method's superior performance
over existing solutions, we derive novel identifiability criteria and establish
$\textit{a priori}$ guarantees of global optimality for problem instances with
bounded measurement errors. We also introduce a complementary Lie-algebraic
local solver for RWHEC and compare its performance with our global method and
prior art. Finally, we provide a free and open-source implementation of our
algorithms and experiments.

</details>


### [230] [In-between Motion Generation Based Multi-Style Quadruped Robot Locomotion](https://arxiv.org/abs/2507.23053)
*Yuanhao Chen,Liu Zhao,Ji Ma,Peng Lu*

Main category: cs.RO

TL;DR: 提出了一种新的四足机器人运动框架，通过结合CVAE运动生成和对抗性运动先验，能够合成多风格、动态可行的运动，并成功应用于真实机器人，提高了运动性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决四足机器人在实现通用运动性方面因参考运动数据多样性不足而面临的持续挑战。

Method: 提出了一种基于条件变分自编码器（CVAE）的运动生成器，用于合成任意起始和终止状态之间的多风格动态可行运动序列，并结合了对抗性运动先验算法。

Result: 生成的运动数据在增强控制器稳定性和改善速度跟踪性能方面非常有效，在速度跟踪和部署稳定性方面取得了显著改进。

Conclusion: 该框架在真实世界的四足机器人上成功部署，实验验证证实了其生成和执行包括疾跑、三足、小跑和踱步在内的复杂运动配置文件的能力。

Abstract: Quadruped robots face persistent challenges in achieving versatile locomotion
due to limitations in reference motion data diversity. To address these
challenges, this approach introduces an in-between motion generation based
multi-style quadruped robot locomotion framework, integrating synergistic
advances in motion generation and imitation learning. Our approach establishes
a unified pipeline addressing two fundamental aspects: First, we propose a CVAE
based motion generator, synthesizing multi-style dynamically feasible
locomotion sequences between arbitrary start and end states. By embedding
physical constraints and leveraging joint poses based phase manifold
continuity, this component produces physically plausible motions spanning
multiple gait modalities while ensuring kinematic compatibility with robotic
morphologies. Second, we adopt the adversarial motion priors algorithm. We
validate the effectiveness of generated motion data in enhancing controller
stability and improving velocity tracking performance. The proposed framework
demonstrates significant improvements in velocity tracking and deployment
stability. We successfully deploy the framework on a real-world quadruped
robot, and the experimental validation confirms the framework's capability to
generate and execute complex motion profiles, including gallop, tripod,
trotting and pacing.

</details>


### [231] [Beyond Rigid AI: Towards Natural Human-Machine Symbiosis for Interoperative Surgical Assistance](https://arxiv.org/abs/2507.23088)
*Lalithkumar Seenivasan,Jiru Xu,Roger D. Soberanis Mukul,Hao Ding,Grayson Byrd,Yu-Chun Ku,Jose L. Porras,Masaru Ishii,Mathias Unberath*

Main category: cs.RO

TL;DR: 该研究提出了一种新的人机交互感知代理，使用LLM、SAM和跟踪模型，能够分割已知和未知物体，并记忆新物体，在手术辅助中表现出灵活性和与手动提示相当的性能，使AI手术辅助更接近现实。


<details>
  <summary>Details</summary>
Motivation: 当前AI驱动的手术辅助解决方案存在僵化、灵活性差、依赖特定任务预训练、固定物体类别和手动提示等问题，限制了在动态手术环境中提供适应性和直观辅助的能力，需要更自然的人机交互。

Method: 提出了一种新颖的感知代理（Perception Agent），该代理利用语音集成的大型语言模型（LLMs）、分割任何模型（SAM）和任何点跟踪基础模型，并结合了记忆库和两种分割未知元素的新机制。

Result: 通过在公开数据集上的定量分析表明，该代理的性能与劳动密集型的手动提示策略相当；通过在自定义数据集上的定性分析，展示了该代理在分割未知元素（如器械、假移植物和纱布）方面的灵活性。

Conclusion: 该研究提出的感知代理通过利用语音集成的大型语言模型、分割任何模型和任何点跟踪基础模型，为实时术中手术辅助提供了更自然的人机交互，克服了现有方法的僵化性，并在分割未知元素方面表现出灵活性，其性能与劳动密集型的手动提示策略相当，有望使基于AI的实时辅助在动态手术环境中更加普及。

Abstract: Emerging surgical data science and robotics solutions, especially those
designed to provide assistance in situ, require natural human-machine
interfaces to fully unlock their potential in providing adaptive and intuitive
aid. Contemporary AI-driven solutions remain inherently rigid, offering limited
flexibility and restricting natural human-machine interaction in dynamic
surgical environments. These solutions rely heavily on extensive task-specific
pre-training, fixed object categories, and explicit manual-prompting. This work
introduces a novel Perception Agent that leverages speech-integrated
prompt-engineered large language models (LLMs), segment anything model (SAM),
and any-point tracking foundation models to enable a more natural human-machine
interaction in real-time intraoperative surgical assistance. Incorporating a
memory repository and two novel mechanisms for segmenting unseen elements,
Perception Agent offers the flexibility to segment both known and unseen
elements in the surgical scene through intuitive interaction. Incorporating the
ability to memorize novel elements for use in future surgeries, this work takes
a marked step towards human-machine symbiosis in surgical procedures. Through
quantitative analysis on a public dataset, we show that the performance of our
agent is on par with considerably more labor-intensive manual-prompting
strategies. Qualitatively, we show the flexibility of our agent in segmenting
novel elements (instruments, phantom grafts, and gauze) in a custom-curated
dataset. By offering natural human-machine interaction and overcoming rigidity,
our Perception Agent potentially brings AI-based real-time assistance in
dynamic surgical environments closer to reality.

</details>


### [232] [Benchmarking Massively Parallelized Multi-Task Reinforcement Learning for Robotics Tasks](https://arxiv.org/abs/2507.23172)
*Vira Joshi,Zifan Xu,Bo Liu,Peter Stone,Amy Zhang*

Main category: cs.RO

TL;DR: 本研究提出了 MTBench，一个包含 70 个机器人任务的大规模并行化多任务强化学习基准，以加速和改进 MTRL 方法的评估。


<details>
  <summary>Details</summary>
Motivation: 现有 MTRL 研究主要局限于低并行化设置下的离策略方法，而忽略了大规模并行化训练（通过 GPU 加速模拟）在数据收集和多样化数据收集方面的潜力。本文旨在弥合这一差距，使 MTRL 能够利用具有更高渐近性能的在策略算法。

Method: 本研究提出了一个名为 MTBench 的多任务强化学习基准，该基准利用 GPU 加速模拟器 IsaacGym，包含 50 个机器人操控任务和 20 个机器人运动任务，并集成了四种基础强化学习算法和七种先进的多任务强化学习算法及架构。

Result: 通过大规模实验，验证了 MTBench 在评估 MTRL 方法上的速度优势，并发现了大规模并行化与 MTRL 结合所带来的新挑战。

Conclusion: 研究表明，MTBench 可以加速 MTRL 方法的评估，并揭示了将大规模并行与 MTRL 相结合时出现的独特挑战。

Abstract: Multi-task Reinforcement Learning (MTRL) has emerged as a critical training
paradigm for applying reinforcement learning (RL) to a set of complex
real-world robotic tasks, which demands a generalizable and robust policy. At
the same time, \emph{massively parallelized training} has gained popularity,
not only for significantly accelerating data collection through GPU-accelerated
simulation but also for enabling diverse data collection across multiple tasks
by simulating heterogeneous scenes in parallel. However, existing MTRL research
has largely been limited to off-policy methods like SAC in the
low-parallelization regime. MTRL could capitalize on the higher asymptotic
performance of on-policy algorithms, whose batches require data from the
current policy, and as a result, take advantage of massive parallelization
offered by GPU-accelerated simulation. To bridge this gap, we introduce a
massively parallelized $\textbf{M}$ulti-$\textbf{T}$ask $\textbf{Bench}$mark
for robotics (MTBench), an open-sourced benchmark featuring a broad
distribution of 50 manipulation tasks and 20 locomotion tasks, implemented
using the GPU-accelerated simulator IsaacGym. MTBench also includes four base
RL algorithms combined with seven state-of-the-art MTRL algorithms and
architectures, providing a unified framework for evaluating their performance.
Our extensive experiments highlight the superior speed of evaluating MTRL
approaches using MTBench, while also uncovering unique challenges that arise
from combining massive parallelism with MTRL. Code is available at
$\href{https://github.com/Viraj-Joshi/MTBench}{
https://github.com/Viraj-Joshi/MTBench}$

</details>


### [233] [Quadratic Programming-Based Posture Manipulation and Thrust-vectoring for Agile Dynamic Walking on Narrow Pathways](https://arxiv.org/abs/2507.23203)
*Chenghao Wang,Eric Sihite,Kaushik Venkatesh Krishnamurthy,Shreyansh Pitroda,Adarsh Salagame,Alireza Ramezani,Morteza Gharib*

Main category: cs.RO

TL;DR: Legged robots can walk more stably on narrow paths and recover from pushes using thruster-assisted walking, as shown in simulations of the Husky Beta platform.


<details>
  <summary>Details</summary>
Motivation: To expand the stability and locomotion plasticity of legged robots, this work explores the multi-modal ability of a legged-aerial platform (Husky Beta) by utilizing thrusters for stabilization during walking.

Method: A model predictive control framework using a QP solver to regulate centroidal dynamics, incorporating thruster and foot ground contact forces as inputs, was designed for the Husky Beta platform.

Result: Simulations show that the Husky Beta can stably walk on a narrow path using its thrusters. The paper also includes a lateral push-recovery simulation to study the thrusters' stabilizing effect on frontal dynamics.

Conclusion: The paper demonstrates the effectiveness of thruster-assisted walking for enhancing stability and locomotion plasticity in legged robots, specifically on narrow paths and during push recovery.

Abstract: There has been significant advancement in legged robot's agility where they
can show impressive acrobatic maneuvers, such as parkour. These maneuvers rely
heavily on posture manipulation. To expand the stability and locomotion
plasticity, we use the multi-modal ability in our legged-aerial platform, the
Husky Beta, to perform thruster-assisted walking. This robot has thrusters on
each of its sagittal knee joints which can be used to stabilize its frontal
dynamic as it walks. In this work, we perform a simulation study of quadruped
narrow-path walking with Husky $\beta$, where the robot will utilize its
thrusters to stably walk on a narrow path. The controller is designed based on
a centroidal dynamics model with thruster and foot ground contact forces as
inputs. These inputs are regulated using a QP solver to be used in a model
predictive control framework. In addition to narrow-path walking, we also
perform a lateral push-recovery simulation to study how the thrusters can be
used to stabilize the frontal dynamics.

</details>


### [234] [Simulation-based planning of Motion Sequences for Automated Procedure Optimization in Multi-Robot Assembly Cells](https://arxiv.org/abs/2507.23270)
*Loris Schneider,Marc Ungen,Elias Huber,Jan-Felix Klein*

Main category: cs.RO

TL;DR: 提出一种通过分解操作和优化调度来生成优化的、协调的多机器人运动序列，以最小化装配时间的方法。


<details>
  <summary>Details</summary>
Motivation: 为了应对重构多机器人单元以满足波动的装配需求所带来的挑战，特别是优化和协调多机器人运动序列以最小化装配时间。

Method: 提出了一种基于仿真的序列生成方法，将装配步骤分解为任务相关的核心操作和连接遍历操作。核心操作受到约束且预先确定，而遍历操作提供了显著的优化潜力。核心操作的调度被表述为一个优化问题，需要使用基于分解的运动规划策略来整合可行的遍历操作。探索了几种求解技术，包括采样启发式、基于树的搜索和无梯度优化。对于运动规划，提出了一种分解方法，该方法识别出调度中的特定区域，这些区域可以通过修改后的集中式路径规划算法独立求解。

Result: 模拟实验证明了该方法的有效性，生成的程序比基线方法更优。

Conclusion: 该方法能够生成高效且无碰撞的多机器人装配程序，并且优于依赖于分布式、机器人个体运动规划的基线方法。

Abstract: Reconfigurable multi-robot cells offer a promising approach to meet
fluctuating assembly demands. However, the recurrent planning of their
configurations introduces new challenges, particularly in generating optimized,
coordinated multi-robot motion sequences that minimize the assembly duration.
This work presents a simulation-based method for generating such optimized
sequences. The approach separates assembly steps into task-related core
operations and connecting traverse operations. While core operations are
constrained and predetermined, traverse operations offer substantial
optimization potential. Scheduling the core operations is formulated as an
optimization problem, requiring feasible traverse operations to be integrated
using a decomposition-based motion planning strategy. Several solution
techniques are explored, including a sampling heuristic, tree-based search and
gradient-free optimization. For motion planning, a decomposition method is
proposed that identifies specific areas in the schedule, which can be solved
independently with modified centralized path planning algorithms. The proposed
method generates efficient and collision-free multi-robot assembly procedures
that outperform a baseline relying on decentralized, robot-individual motion
planning. Its effectiveness is demonstrated through simulation experiments.

</details>


### [235] [GSFusion:Globally Optimized LiDAR-Inertial-Visual Mapping for Gaussian Splatting](https://arxiv.org/abs/2507.23273)
*Jaeseok Park,Chanoh Park,Minsu Kim,Soohwan Kim*

Main category: cs.RO

TL;DR: GSFusion 是一种新的在线激光雷达-惯性-视觉建图系统，通过创新的约束和初始化策略解决了传统 3DGS 方法的局限性，并在渲染质量和效率方面取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有基于相机传感器的 3DGS 方法在计算负载、纹理/光照不佳环境下的失败以及操作范围短等基本限制，并克服将激光雷达与 3DGS 集成时遇到的全局对齐和稀疏数据优化时间长等新挑战。

Method: 提出了一种名为 GSFusion 的在线激光雷达-惯性-视觉建图系统，通过在全局姿态图优化中引入 surfel-to-surfel 约束来确保高精度的地图一致性。为处理稀疏数据，该系统采用了像素感知的高斯初始化策略以实现高效表示，并通过有界 sigmoid 约束来防止高斯发散。

Result: 实验结果表明，GSFusion 系统在渲染质量和地图构建效率方面优于现有的 3DGS SLAM 系统。

Conclusion: GSFusion 系统在渲染质量和地图构建效率方面优于现有的 3DGS SLAM 系统。

Abstract: While 3D Gaussian Splatting (3DGS) has revolutionized photorealistic mapping,
conventional approaches based on camera sensor, even RGB-D, suffer from
fundamental limitations such as high computational load, failure in
environments with poor texture or illumination, and short operational ranges.
LiDAR emerges as a robust alternative, but its integration with 3DGS introduces
new challenges, such as the need for exceptional global alignment for
photorealistic quality and prolonged optimization times caused by sparse data.
To address these challenges, we propose GSFusion, an online
LiDAR-Inertial-Visual mapping system that ensures high-precision map
consistency through a surfel-to-surfel constraint in the global pose-graph
optimization. To handle sparse data, our system employs a pixel-aware Gaussian
initialization strategy for efficient representation and a bounded sigmoid
constraint to prevent uncontrolled Gaussian growth. Experiments on public and
our datasets demonstrate our system outperforms existing 3DGS SLAM systems in
terms of rendering quality and map-building efficiency.

</details>


### [236] [Whisker-based Active Tactile Perception for Contour Reconstruction](https://arxiv.org/abs/2507.23305)
*Yixuan Dang,Qinyang Xu,Yu Zhang,Xiangtong Yao,Liding Zhang,Zhenshan Bing,Florian Roehrbein,Alois Knoll*

Main category: cs.RO

TL;DR: 提出了一种新的触须传感器和控制策略，实现了高精度的物体表面跟踪和轮廓重建。


<details>
  <summary>Details</summary>
Motivation: 为了在机器人操作中实现高精度的物体轮廓重建，需要一种能够主动控制触须传感器的策略，以在与物体表面接触时保持最佳相对姿态，从而克服现有技术中缺乏直接触觉信息反馈的挑战。

Method: 提出了一种利用磁致伸缩触须传感器的位移来提取触须尖端接触位置的方法，并采用梯度下降和贝叶斯滤波器来提高精度和鲁棒性。此外，还提出了一种主动运动控制策略，利用 B 样条曲线预测局部表面曲率并确定传感器方向，以在触须传感器与物体表面之间保持最佳的相对姿态。

Result: 开发了一种紧凑而坚固的磁致伸缩触须传感器，并提出了一种基于触须位移的梯度下降和贝叶斯滤波方法，可以直接提取触须尖端的位置。主动运动控制策略能够有效跟踪物体并以低于毫米的精度重建轮廓。

Conclusion: 该方法能够以低于毫米的精度有效地跟踪物体和重建轮廓。最后，我们在仿真和真实世界实验中验证了该方法，其中机器人手臂驱动触须传感器跟踪三个不同物体的表面。

Abstract: Perception using whisker-inspired tactile sensors currently faces a major
challenge: the lack of active control in robots based on direct contact
information from the whisker. To accurately reconstruct object contours, it is
crucial for the whisker sensor to continuously follow and maintain an
appropriate relative touch pose on the surface. This is especially important
for localization based on tip contact, which has a low tolerance for sharp
surfaces and must avoid slipping into tangential contact. In this paper, we
first construct a magnetically transduced whisker sensor featuring a compact
and robust suspension system composed of three flexible spiral arms. We develop
a method that leverages a characterized whisker deflection profile to directly
extract the tip contact position using gradient descent, with a Bayesian filter
applied to reduce fluctuations. We then propose an active motion control policy
to maintain the optimal relative pose of the whisker sensor against the object
surface. A B-Spline curve is employed to predict the local surface curvature
and determine the sensor orientation. Results demonstrate that our algorithm
can effectively track objects and reconstruct contours with sub-millimeter
accuracy. Finally, we validate the method in simulations and real-world
experiments where a robot arm drives the whisker sensor to follow the surfaces
of three different objects.

</details>


### [237] [Distributed AI Agents for Cognitive Underwater Robot Autonomy](https://arxiv.org/abs/2507.23735)
*Markus Buchholz,Ignacio Carlucho,Michele Grimaldi,Yvan R. Petillot*

Main category: cs.RO

TL;DR: UROSA是一个创新的水下机器人认知自主架构，利用分布式大型语言模型AI代理和ROS 2框架，提高了机器人在复杂水下环境中的适应性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 应对水下机器人（AUV）在复杂、不可预测环境中实现鲁棒认知自主性的挑战。

Method: UROSA架构利用分布式大型语言模型AI代理，集成在ROS 2框架中，实现多模态感知、自适应推理、动态任务规划和实时决策。其创新之处在于灵活的代理角色调整、利用向量数据库的检索增强生成、强化学习驱动的行为优化以及自主生成的ROS 2节点。

Result: UROSA架构在模拟和实际部署的各种水下任务中展现了良好的适应性和可靠性，与传统的基于规则的架构相比，在处理意外情况、环境不确定性和新颖任务目标方面具有显著优势。

Conclusion: 该研究提出了UROSA架构，一种利用分布式大型语言模型AI代理的创新方法，用于增强水下机器人的认知能力，并在模拟和实际部署中得到了验证，显示出在处理不可预见情况和环境不确定性方面的显著优势。

Abstract: Achieving robust cognitive autonomy in robots navigating complex,
unpredictable environments remains a fundamental challenge in robotics. This
paper presents Underwater Robot Self-Organizing Autonomy (UROSA), a
groundbreaking architecture leveraging distributed Large Language Model AI
agents integrated within the Robot Operating System 2 (ROS 2) framework to
enable advanced cognitive capabilities in Autonomous Underwater Vehicles. UROSA
decentralises cognition into specialised AI agents responsible for multimodal
perception, adaptive reasoning, dynamic mission planning, and real-time
decision-making. Central innovations include flexible agents dynamically
adapting their roles, retrieval-augmented generation utilising vector databases
for efficient knowledge management, reinforcement learning-driven behavioural
optimisation, and autonomous on-the-fly ROS 2 node generation for runtime
functional extensibility. Extensive empirical validation demonstrates UROSA's
promising adaptability and reliability through realistic underwater missions in
simulation and real-world deployments, showing significant advantages over
traditional rule-based architectures in handling unforeseen scenarios,
environmental uncertainties, and novel mission objectives. This work not only
advances underwater autonomy but also establishes a scalable, safe, and
versatile cognitive robotics framework capable of generalising to a diverse
array of real-world applications.

</details>


### [238] [Assessing the Alignment of Automated Vehicle Decisions with Human Reasons](https://arxiv.org/abs/2507.23324)
*Lucas Elbert Suryana,Saeed Rahmani,Simeon Craig Calvert,Arkady Zgonnikov,Bart van Arem*

Main category: cs.RO

TL;DR: 自动驾驶汽车的规划系统需要处理日常驾驶中的伦理困境，但目前的系统过于僵化。本文提出了一个基于原因的轨迹评估框架，该框架通过量化和权衡不同行为者的考量因素（如合规性、效率、舒适性），来评估自动驾驶汽车轨迹的伦理一致性，并为实现有意义的人类控制提供了一个实用工具。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶汽车（AVs）部署的一个关键挑战是确保它们在伦理上具有挑战性的日常驾驶情境中做出适当的决策。虽然人们对很少发生的、高风险的困境（如电车难题）给予了很大关注，但在日常场景（如在空旷的交叉路口行驶）中也出现了类似的紧张关系，其中合法性和舒适性等多人文考量因素经常发生冲突。目前的自动驾驶汽车规划系统通常依赖于僵化的规则，这些规则难以平衡这些相互竞争的考量因素，并可能导致行为与人类期望不一致。

Method: 提出了一种新颖的基于原因的轨迹评估框架，该框架将有意义的人类控制（MHC）的可追溯性条件操作化。该框架将人类行为者的原因（如合规性）建模为可量化的函数，并评估候选自动驾驶汽车轨迹与这些原因的对齐程度。通过为行为者优先级分配可调权重并集成一个平衡函数来阻止任何行为者的排除，该框架支持可解释的决策评估。

Result: 通过一个受现实世界启发的超车场景，展示了该方法如何揭示紧张关系，例如在合规性、效率和舒适性之间的紧张关系。

Conclusion: 该框架作为现有规划算法之上的模块化评估层，为评估日常场景中的伦理一致性提供了一个透明的工具，并为在实际自动驾驶汽车部署中实施有意义的人类控制提供了切实可行的步骤。

Abstract: A key challenge in deploying automated vehicles (AVs) is ensuring they make
appropriate decisions in ethically challenging everyday driving situations.
While much attention has been paid to rare, high-stakes dilemmas such as
trolley problems, similar tensions also arise in routine scenarios, such as
navigating empty intersections, where multiple human considerations, including
legality and comfort, often conflict. Current AV planning systems typically
rely on rigid rules, which struggle to balance these competing considerations
and can lead to behaviour that misaligns with human expectations. This paper
proposes a novel reasons-based trajectory evaluation framework that
operationalises the tracking condition of Meaningful Human Control (MHC). The
framework models the reasons of human agents, such as regulatory compliance, as
quantifiable functions and evaluates how well candidate AV trajectories align
with these reasons. By assigning adjustable weights to agent priorities and
integrating a balance function to discourage the exclusion of any agent, the
framework supports interpretable decision evaluation. Through a
real-world-inspired overtaking scenario, we show how this approach reveals
tensions, for instance between regulatory compliance, efficiency, and comfort.
The framework functions as a modular evaluation layer over existing planning
algorithms. It offers a transparent tool for assessing ethical alignment in
everyday scenarios and provides a practical step toward implementing MHC in
real-world AV deployment.

</details>


### [239] [Learning to Drift with Individual Wheel Drive: Maneuvering Autonomous Vehicle at the Handling Limits](https://arxiv.org/abs/2507.23339)
*Yihan Zhou,Yiwen Lu,Bo Yang,Jiayun Li,Yilin Mo*

Main category: cs.RO

TL;DR: 提出了一种强化学习框架，通过GPU加速仿真和域随机化来解决模拟到现实的差距，并在模拟和真实RC车上成功实现了漂移控制。


<details>
  <summary>Details</summary>
Motivation: 为了在摩擦极限下安全处理紧急情况，需要对车辆在高侧滑角下的运动进行控制，而现有的强化学习方法在模拟到现实的转移方面存在差距。

Method: 提出了一种具有GPU加速并行仿真和系统域随机化的强化学习框架，以解决模拟到现实的差距问题。

Result: 在模拟和1/10比例的IWD RC车平台上进行了验证，实验结果表明该方法能够精确跟踪轨迹并控制侧滑角。

Conclusion: 该方法在模拟和真实世界的环境中都实现了精确的轨迹跟踪，并在复杂机动中全程保持了受控的侧滑角。

Abstract: Drifting, characterized by controlled vehicle motion at high sideslip angles,
is crucial for safely handling emergency scenarios at the friction limits.
While recent reinforcement learning approaches show promise for drifting
control, they struggle with the significant simulation-to-reality gap, as
policies that perform well in simulation often fail when transferred to
physical systems. In this paper, we present a reinforcement learning framework
with GPU-accelerated parallel simulation and systematic domain randomization
that effectively bridges the gap. The proposed approach is validated on both
simulation and a custom-designed and open-sourced 1/10 scale Individual Wheel
Drive (IWD) RC car platform featuring independent wheel speed control.
Experiments across various scenarios from steady-state circular drifting to
direction transitions and variable-curvature path following demonstrate that
our approach achieves precise trajectory tracking while maintaining controlled
sideslip angles throughout complex maneuvers in both simulated and real-world
environments.

</details>


### [240] [Multi-Waypoint Path Planning and Motion Control for Non-holonomic Mobile Robots in Agricultural Applications](https://arxiv.org/abs/2507.23350)
*Mahmoud Ghorab,Matthias Lorenzen*

Main category: cs.RO

TL;DR: 提出了一种结合DTSP和NMPC的导航框架，用于在农业环境中进行高效自主导航，与分离式方法相比，路径更短、更平滑。


<details>
  <summary>Details</summary>
Motivation: 为了满足在非结构化农业环境中导航的自主移动机器人的增长需求，例如在草地上进行杂草控制，需要一种能够有效规划穿越无序坐标集的路径的方法，同时最大限度地减少行驶距离并遵守曲率限制以防止土壤破坏和保护植被。

Method: 提出了一种结合了基于Dubins旅行商问题（DTSP）的全局路径规划器和非线性模型预测控制（NMPC）的局部路径规划与控制的集成导航框架。

Result: 与分离式方法相比，所提出的DTSP为基础的规划器在模拟中产生了更平滑、更短的路径，在所提供的情况下减少了约16%的路径长度。NMPC控制器有效地将机器人引导至目标航点，同时在局部优化轨迹并确保遵守约束。

Conclusion: 该框架有潜力在农业环境中实现高效的自主导航。

Abstract: There is a growing demand for autonomous mobile robots capable of navigating
unstructured agricultural environments. Tasks such as weed control in meadows
require efficient path planning through an unordered set of coordinates while
minimizing travel distance and adhering to curvature constraints to prevent
soil damage and protect vegetation. This paper presents an integrated
navigation framework combining a global path planner based on the Dubins
Traveling Salesman Problem (DTSP) with a Nonlinear Model Predictive Control
(NMPC) strategy for local path planning and control. The DTSP generates a
minimum-length, curvature-constrained path that efficiently visits all targets,
while the NMPC leverages this path to compute control signals to accurately
reach each waypoint. The system's performance was validated through comparative
simulation analysis on real-world field datasets, demonstrating that the
coupled DTSP-based planner produced smoother and shorter paths, with a
reduction of about 16% in the provided scenario, compared to decoupled methods.
Based thereon, the NMPC controller effectively steered the robot to the desired
waypoints, while locally optimizing the trajectory and ensuring adherence to
constraints. These findings demonstrate the potential of the proposed framework
for efficient autonomous navigation in agricultural environments.

</details>


### [241] [Quantifying and Visualizing Sim-to-Real Gaps: Physics-Guided Regularization for Reproducibility](https://arxiv.org/abs/2507.23445)
*Yuta Kawachi*

Main category: cs.RO

TL;DR: 通过物理引导的增益正则化和参数条件化，在机器人控制中缩小了仿真到现实的差距，特别是在具有高齿轮比的硬件上，效果优于传统的域随机化方法。


<details>
  <summary>Details</summary>
Motivation: 尽管使用域随机化进行机器人控制的仿真到现实迁移通常依赖于低齿轮比、可反向驱动的执行器，但当仿真到现实的差距扩大时，这些方法就会失效。受到传统PID控制器的启发，将增益重新解释为复杂、未建模植物动力学的代理。

Method: 通过物理引导的增益正则化方案，利用简单的现实世界实验来衡量机器人的有效比例增益，并在训练过程中惩罚神经网络控制器局部输入输出灵敏度与这些值的偏差。为了避免朴素域随机化的保守偏差，还根据当前植物参数来调整控制器。

Result: 在实际的二轮平衡机器人上，所提出的增益正则化、参数条件化RNN在硬件上的角度稳定时间与仿真结果非常接近，而仅使用域随机化的策略则表现出持续振荡和显著的仿真到现实差距。

Conclusion: 本研究提出了一个轻量级、可复现的框架，用于缩小具有成本效益的机器人硬件上的仿真到现实（sim-to-real）差距。

Abstract: Simulation-to-real transfer using domain randomization for robot control
often relies on low-gear-ratio, backdrivable actuators, but these approaches
break down when the sim-to-real gap widens. Inspired by the traditional PID
controller, we reinterpret its gains as surrogates for complex, unmodeled plant
dynamics. We then introduce a physics-guided gain regularization scheme that
measures a robot's effective proportional gains via simple real-world
experiments. Then, we penalize any deviation of a neural controller's local
input-output sensitivities from these values during training. To avoid the
overly conservative bias of naive domain randomization, we also condition the
controller on the current plant parameters. On an off-the-shelf two-wheeled
balancing robot with a 110:1 gearbox, our gain-regularized,
parameter-conditioned RNN achieves angular settling times in hardware that
closely match simulation. At the same time, a purely domain-randomized policy
exhibits persistent oscillations and a substantial sim-to-real gap. These
results demonstrate a lightweight, reproducible framework for closing
sim-to-real gaps on affordable robotic hardware.

</details>


### [242] [H-RDT: Human Manipulation Enhanced Bimanual Robotic Manipulation](https://arxiv.org/abs/2507.23523)
*Hongzhe Bi,Lingxuan Wu,Tianwei Lin,Hengkai Tan,Zhizhong Su,Hang Su,Jun Zhu*

Main category: cs.RO

TL;DR: H-RDT利用人类操作数据，通过两阶段训练（人类数据预训练+机器人数据微调），在机器人操作任务中取得了显著成果，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 模仿学习在机器人操作领域面临数据稀缺的挑战。现有的方法通过在跨具身机器人数据集上进行预训练来扩大数据规模，但面临不同机器人形态和动作空间带来的统一训练困难。该研究旨在利用大规模、高质量的人类操作数据来克服这些限制。

Method: H-RDT采用了一种两阶段训练范式：首先在大规模以自我为中心的人类操作数据上进行预训练，然后利用模块化的动作编码器和解码器在机器人特定数据上进行跨具身微调。该模型基于拥有20亿参数的Diffusion Transformer架构，并使用流匹配来模拟复杂的动作分布。

Result: H-RDT在模拟和真实世界实验、单任务和多任务场景、少样本学习和鲁棒性评估中均表现出色，显著优于从头训练（分别提高了13.9%和40.5%）以及Pi0和RDT等现有方法。

Conclusion: H-RDT通过利用大规模的以自我为中心的人类操作视频数据，并在机器人特定数据上进行跨具身微调，成功地提升了机器人操作能力。实验证明，H-RDT在模拟和真实世界环境中均优于从头训练以及现有的最先进方法（如Pi0和RDT），验证了人类操作数据是学习双臂机器人操作策略的有效基础。

Abstract: Imitation learning for robotic manipulation faces a fundamental challenge:
the scarcity of large-scale, high-quality robot demonstration data. Recent
robotic foundation models often pre-train on cross-embodiment robot datasets to
increase data scale, while they face significant limitations as the diverse
morphologies and action spaces across different robot embodiments make unified
training challenging. In this paper, we present H-RDT (Human to Robotics
Diffusion Transformer), a novel approach that leverages human manipulation data
to enhance robot manipulation capabilities. Our key insight is that large-scale
egocentric human manipulation videos with paired 3D hand pose annotations
provide rich behavioral priors that capture natural manipulation strategies and
can benefit robotic policy learning. We introduce a two-stage training
paradigm: (1) pre-training on large-scale egocentric human manipulation data,
and (2) cross-embodiment fine-tuning on robot-specific data with modular action
encoders and decoders. Built on a diffusion transformer architecture with 2B
parameters, H-RDT uses flow matching to model complex action distributions.
Extensive evaluations encompassing both simulation and real-world experiments,
single-task and multitask scenarios, as well as few-shot learning and
robustness assessments, demonstrate that H-RDT outperforms training from
scratch and existing state-of-the-art methods, including Pi0 and RDT, achieving
significant improvements of 13.9% and 40.5% over training from scratch in
simulation and real-world experiments, respectively. The results validate our
core hypothesis that human manipulation data can serve as a powerful foundation
for learning bimanual robotic manipulation policies.

</details>


### [243] [A Unified Perception-Language-Action Framework for Adaptive Autonomous Driving](https://arxiv.org/abs/2507.23540)
*Yi Zhang,Erik Leo Haß,Kuo-Yi Chao,Nenad Petrovic,Yinglei Song,Chengdong Wu,Alois Knoll*

Main category: cs.RO

TL;DR: 提出了一种结合多传感器融合和GPT-4.1的PLA框架，以提高自动驾驶系统的适应性、鲁棒性和可解释性，并在城市交叉口场景的评估中取得了优越性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决自动驾驶系统在复杂、开放世界环境中实现类人适应性、鲁棒性和可解释性方面面临的挑战，这些挑战源于碎片化的架构、对新场景的泛化能力有限以及感知方面语义提取不足。

Method: 提出了一种统一的感知-语言-动作（PLA）框架，该框架集成了多传感器融合（摄像头、LiDAR、雷达）和一个大型语言模型（LLM）增强的视觉-语言-动作（VLA）架构，特别是由GPT-4.1驱动的推理核心。

Result: 在城市交叉口场景（包含施工区）的评估中，该框架在轨迹跟踪、速度预测和自适应规划方面表现优越。

Conclusion: 该框架通过语言增强的认知框架有潜力提高自动驾驶系统的安全性、可解释性和可扩展性。

Abstract: Autonomous driving systems face significant challenges in achieving
human-like adaptability, robustness, and interpretability in complex,
open-world environments. These challenges stem from fragmented architectures,
limited generalization to novel scenarios, and insufficient semantic extraction
from perception. To address these limitations, we propose a unified
Perception-Language-Action (PLA) framework that integrates multi-sensor fusion
(cameras, LiDAR, radar) with a large language model (LLM)-augmented
Vision-Language-Action (VLA) architecture, specifically a GPT-4.1-powered
reasoning core. This framework unifies low-level sensory processing with
high-level contextual reasoning, tightly coupling perception with natural
language-based semantic understanding and decision-making to enable
context-aware, explainable, and safety-bounded autonomous driving. Evaluations
on an urban intersection scenario with a construction zone demonstrate superior
performance in trajectory tracking, speed prediction, and adaptive planning.
The results highlight the potential of language-augmented cognitive frameworks
for advancing the safety, interpretability, and scalability of autonomous
driving systems.

</details>


### [244] [User Experience Estimation in Human-Robot Interaction Via Multi-Instance Learning of Multimodal Social Signals](https://arxiv.org/abs/2507.23544)
*Ryo Miyoshi,Yuki Okafuji,Takuya Iwamoto,Junya Nakanishi,Jun Baba*

Main category: cs.RO

TL;DR: 本研究提出了一种基于Transformer和多实例学习的方法，利用面部表情和语音来估计人机交互中的用户体验，并在实验中取得了优于人类评估者的结果。


<details>
  <summary>Details</summary>
Motivation: 为了使社交机器人在与用户交互时能够适应用户状态，需要准确评估用户体验（UX）。

Method: 研究人员提出了一种基于Transformer的模型，该模型利用面部表情和语音，并采用多实例学习框架来捕捉交互模式的短期和长期模式，以实现UX估计。

Result: 实验结果表明，所提出的方法在UX估计方面优于第三方人类评估者。

Conclusion: 该研究提出了一种利用多模态社交信号来估计人机交互（HRI）中用户体验（UX）的方法，并通过实验证明其优于人类评估者。

Abstract: In recent years, the demand for social robots has grown, requiring them to
adapt their behaviors based on users' states. Accurately assessing user
experience (UX) in human-robot interaction (HRI) is crucial for achieving this
adaptability. UX is a multi-faceted measure encompassing aspects such as
sentiment and engagement, yet existing methods often focus on these
individually. This study proposes a UX estimation method for HRI by leveraging
multimodal social signals. We construct a UX dataset and develop a
Transformer-based model that utilizes facial expressions and voice for
estimation. Unlike conventional models that rely on momentary observations, our
approach captures both short- and long-term interaction patterns using a
multi-instance learning framework. This enables the model to capture temporal
dynamics in UX, providing a more holistic representation. Experimental results
demonstrate that our method outperforms third-party human evaluators in UX
estimation.

</details>


### [245] [Can LLM-Reasoning Models Replace Classical Planning? A Benchmark Study](https://arxiv.org/abs/2507.23589)
*Kai Goebel,Patrik Zips*

Main category: cs.RO

TL;DR: 本研究评估了语言模型在机器人任务规划中的表现，发现它们在简单任务上表现良好，但在复杂任务上存在挑战，这表明需要结合传统规划器来提高可靠性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在机器人任务规划中的有效性，特别是它们生成结构化和可执行计划的能力。

Method: 通过直接使用规划领域定义语言（PDDL）域和问题文件提示一系列当前最先进的语言模型，并将其规划性能与 Fast Downward 规划器在各种基准测试中进行比较。

Result: 尽管语言模型在较简单的规划任务上表现良好，但在更复杂的场景中，它们在资源管理、状态跟踪和约束遵守方面仍有不足。研究结果指出了将语言模型应用于机器人规划的优势和局限性。

Conclusion: 大型语言模型在处理需要精确资源管理、一致状态跟踪和严格约束遵守的复杂场景时仍然存在挑战。这些发现强调了将语言模型应用于真实世界机器人规划的基本挑战。

Abstract: Recent advancements in Large Language Models have sparked interest in their
potential for robotic task planning. While these models demonstrate strong
generative capabilities, their effectiveness in producing structured and
executable plans remains uncertain. This paper presents a systematic evaluation
of a broad spectrum of current state of the art language models, each directly
prompted using Planning Domain Definition Language domain and problem files,
and compares their planning performance with the Fast Downward planner across a
variety of benchmarks. In addition to measuring success rates, we assess how
faithfully the generated plans translate into sequences of actions that can
actually be executed, identifying both strengths and limitations of using these
models in this setting. Our findings show that while the models perform well on
simpler planning tasks, they continue to struggle with more complex scenarios
that require precise resource management, consistent state tracking, and strict
constraint compliance. These results underscore fundamental challenges in
applying language models to robotic planning in real world environments. By
outlining the gaps that emerge during execution, we aim to guide future
research toward combined approaches that integrate language models with
classical planners in order to enhance the reliability and scalability of
planning in autonomous robotics.

</details>


### [246] [Human-Exoskeleton Kinematic Calibration to Improve Hand Tracking for Dexterous Teleoperation](https://arxiv.org/abs/2507.23592)
*Haiyun Zhang,Stefano Dalla Gasperina,Saad N. Yousaf,Toshimitsu Tsuboi,Tetsuya Narita,Ashish D. Deshpande*

Main category: cs.RO

TL;DR: 通过使用冗余关节传感和残差加权优化策略来校准手部外骨骼，以提高跟踪精度并减少用户之间的差异。


<details>
  <summary>Details</summary>
Motivation: 为了解决由于用户特定的解剖结构变异和穿戴不一致而导致的准确手部跟踪挑战，这些问题会导致运动学失准，从而降低跟踪性能并限制在精确任务中的适用性。

Method: 提出了一种特定于对象的校准框架，用于基于外骨骼的手部跟踪，该框架使用冗余关节传感和残差加权优化策略来估计虚拟连杆参数。通过运动捕捉地面真值引入了一种数据驱动的方法来经验性地调整成本函数权重，从而在不同参与者之间实现更准确、更一致的校准。

Result: 在 Maestro 外骨骼上实现的方法，在不同手部几何形状的用户中，关节角度和指尖位置估计得到了改善。与未校准和均匀加权的型号相比，七名受试者的定量结果显示关节和指尖跟踪误差有了显著减少。使用基于 Unity 的虚拟手进行的定性可视化进一步证实了运动保真度的提高。

Conclusion: 该框架可推广到具有闭环运动学和最小传感功能的外骨骼设计，并为高保真遥操作和从演示中学习的应用奠定了基础。

Abstract: Hand exoskeletons are critical tools for dexterous teleoperation and
immersive manipulation interfaces, but achieving accurate hand tracking remains
a challenge due to user-specific anatomical variability and donning
inconsistencies. These issues lead to kinematic misalignments that degrade
tracking performance and limit applicability in precision tasks. We propose a
subject-specific calibration framework for exoskeleton-based hand tracking that
uses redundant joint sensing and a residual-weighted optimization strategy to
estimate virtual link parameters. Implemented on the Maestro exoskeleton, our
method improves joint angle and fingertip position estimation across users with
varying hand geometries. We introduce a data-driven approach to empirically
tune cost function weights using motion capture ground truth, enabling more
accurate and consistent calibration across participants. Quantitative results
from seven subjects show substantial reductions in joint and fingertip tracking
errors compared to uncalibrated and evenly weighted models. Qualitative
visualizations using a Unity-based virtual hand further confirm improvements in
motion fidelity. The proposed framework generalizes across exoskeleton designs
with closed-loop kinematics and minimal sensing, and lays the foundation for
high-fidelity teleoperation and learning-from-demonstration applications.

</details>


### [247] [DRACo-SLAM2: Distributed Robust Acoustic Communication-efficient SLAM for Imaging Sonar EquippedUnderwater Robot Teams with Object Graph Matching](https://arxiv.org/abs/2507.23629)
*Yewei Huang,John McConnell,Xi Lin,Brendan Englot*

Main category: cs.RO

TL;DR: DRACo-SLAM2是一个用于水下机器人团队的分布式SLAM框架，通过对象图和GCM改进了地图表示和闭环检测。


<details>
  <summary>Details</summary>
Motivation: 提高水下机器人团队的SLAM框架性能，特别是通过新颖的地图表示和改进的闭环检测方法，以应对水下环境的挑战。

Method: DRACo-SLAM2框架，将声纳地图表示为对象图，并利用对象图匹配来实现时间高效的机器人间闭环检测，提出增量式分组一致测量集最大化（GCM）。

Result: 在模拟和真实世界数据集上的广泛比较分析验证了该方法。

Conclusion: DRACo-SLAM2通过将声纳地图表示为对象图并利用对象图匹配来实现高效的机器人间闭环检测，并提出增量式分组一致测量集最大化（GCM）以更好地适应水下扫描匹配的需求，在模拟和真实世界数据集上进行了验证。

Abstract: We present DRACo-SLAM2, a distributed SLAM framework for underwater robot
teams equipped with multibeam imaging sonar. This framework improves upon the
original DRACo-SLAM by introducing a novel representation of sonar maps as
object graphs and utilizing object graph matching to achieve time-efficient
inter-robot loop closure detection without relying on prior geometric
information. To better-accommodate the needs and characteristics of underwater
scan matching, we propose incremental Group-wise Consistent Measurement Set
Maximization (GCM), a modification of Pairwise Consistent Measurement Set
Maximization (PCM), which effectively handles scenarios where nearby
inter-robot loop closures share similar registration errors. The proposed
approach is validated through extensive comparative analyses on simulated and
real-world datasets.

</details>


### [248] [DuLoc: Life-Long Dual-Layer Localization in Changing and Dynamic Expansive Scenarios](https://arxiv.org/abs/2507.23660)
*Haoxuan Jiang,Peicong Qian,Yusen Xie,Xiaocong Li,Ming Liu,Jun Ma*

Main category: cs.RO

TL;DR: DuLoc enhances LiDAR localization for autonomous systems by combining LiDAR-inertial odometry with map-based localization and dynamic maps, improving robustness in changing environments. It outperforms existing methods in large-scale outdoor tests.


<details>
  <summary>Details</summary>
Motivation: Existing LiDAR-based localization methods lack robustness against environmental changes, leading to drift and reliability degradation. DuLoc aims to address these challenges by improving repeatability, accuracy, and environmental adaptability.

Method: DuLoc integrates LiDAR-inertial odometry with offline map-based localization using a constant-velocity motion model and a framework combining global and dynamic local maps.

Result: Extensive experiments show DuLoc outperforms other state-of-the-art LiDAR localization systems in large-scale changing outdoor environments, validated by 2,856 hours of operational data from 32 IGVs.

Conclusion: LiDAR-based localization is critical for autonomous systems but faces challenges in repeatability, accuracy, and environmental adaptability. Existing methods using offline maps struggle with long-term environmental changes, causing drift and reliability issues. The proposed DuLoc method tightly couples LiDAR-inertial odometry with offline map-based localization, using a constant-velocity motion model to handle outliers. It integrates global and dynamic local maps for robust localization in changing environments. Experiments with 32 IGVs over 2,856 hours in a large-scale outdoor port show DuLoc outperforms state-of-the-art LiDAR localization systems.

Abstract: LiDAR-based localization serves as a critical component in autonomous
systems, yet existing approaches face persistent challenges in balancing
repeatability, accuracy, and environmental adaptability. Traditional point
cloud registration methods relying solely on offline maps often exhibit limited
robustness against long-term environmental changes, leading to localization
drift and reliability degradation in dynamic real-world scenarios. To address
these challenges, this paper proposes DuLoc, a robust and accurate localization
method that tightly couples LiDAR-inertial odometry with offline map-based
localization, incorporating a constant-velocity motion model to mitigate
outlier noise in real-world scenarios. Specifically, we develop a LiDAR-based
localization framework that seamlessly integrates a prior global map with
dynamic real-time local maps, enabling robust localization in unbounded and
changing environments. Extensive real-world experiments in ultra unbounded port
that involve 2,856 hours of operational data across 32 Intelligent Guided
Vehicles (IGVs) are conducted and reported in this study. The results attained
demonstrate that our system outperforms other state-of-the-art LiDAR
localization systems in large-scale changing outdoor environments.

</details>


### [249] [Stereo 3D Gaussian Splatting SLAM for Outdoor Urban Scenes](https://arxiv.org/abs/2507.23677)
*Xiaohan Li,Ziren Gong,Fabio Tosi,Matteo Poggi,Stefano Mattoccia,Dong Liu,Jun Wu*

Main category: cs.RO

TL;DR: BGS-SLAM是首个用于户外场景的双目3D高斯泼溅SLAM系统，仅使用RGB立体图像对，无需激光雷达或主动传感器，在复杂户外环境中实现了优于其他3DGS方法的跟踪和建图性能。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS-SLAM系统主要关注室内环境并依赖主动深度传感器，存在适用于大规模室外应用的空白。

Method: BGS-SLAM 利用预训练的深度立体网络进行深度估计，并通过多损失策略指导3D高斯优化，以增强几何一致性和视觉质量。

Result: 实验证明，BGS-SLAM在多个数据集上取得了优于其他3DGS方法的跟踪精度和建图性能。

Conclusion: BGS-SLAM是首个用于户外场景的双目3D高斯泼溅SLAM系统，仅使用RGB立体图像对，无需激光雷达或主动传感器，在复杂户外环境中实现了优于其他3DGS方法的跟踪和建图性能。

Abstract: 3D Gaussian Splatting (3DGS) has recently gained popularity in SLAM
applications due to its fast rendering and high-fidelity representation.
However, existing 3DGS-SLAM systems have predominantly focused on indoor
environments and relied on active depth sensors, leaving a gap for large-scale
outdoor applications. We present BGS-SLAM, the first binocular 3D Gaussian
Splatting SLAM system designed for outdoor scenarios. Our approach uses only
RGB stereo pairs without requiring LiDAR or active sensors. BGS-SLAM leverages
depth estimates from pre-trained deep stereo networks to guide 3D Gaussian
optimization with a multi-loss strategy enhancing both geometric consistency
and visual quality. Experiments on multiple datasets demonstrate that BGS-SLAM
achieves superior tracking accuracy and mapping performance compared to other
3DGS-based solutions in complex outdoor environments.

</details>


### [250] [villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models](https://arxiv.org/abs/2507.23682)
*Xiaoyu Chen,Hangxing Wei,Pushi Zhang,Chuheng Zhang,Kaixin Wang,Yanjiang Guo,Rushuai Yang,Yucen Wang,Xinquan Xiao,Li Zhao,Jianyu Chen,Jiang Bian*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Visual-Language-Action (VLA) models have emerged as a popular paradigm for
learning robot manipulation policies that can follow language instructions and
generalize to novel scenarios. Recent work has begun to explore the
incorporation of latent actions, an abstract representation of visual change
between two frames, into VLA pre-training. In this paper, we introduce villa-X,
a novel Visual-Language-Latent-Action (ViLLA) framework that advances latent
action modeling for learning generalizable robot manipulation policies. Our
approach improves both how latent actions are learned and how they are
incorporated into VLA pre-training. Together, these contributions enable
villa-X to achieve superior performance across simulated environments including
SIMPLER and LIBERO, as well as on two real-world robot setups including gripper
and dexterous hand manipulation. We believe the ViLLA paradigm holds
significant promise, and that our villa-X provides a strong foundation for
future research.

</details>


### [251] [Scalable Multi-Task Reinforcement Learning for Generalizable Spatial Intelligence in Visuomotor Agents](https://arxiv.org/abs/2507.23698)
*Shaofei Cai,Zhancun Mu,Haiwen Xia,Bowei Zhang,Anji Liu,Yitao Liang*

Main category: cs.RO

TL;DR: 本文研究了如何在Minecraft中利用强化学习（RL）来提高视觉运动代理的泛化能力。通过自动化任务合成和跨视图目标规范，RL微调的代理在面对新环境时展现出零样本泛化能力，并将交互成功率提高了4倍，显著提升了空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 强化学习（RL）在语言建模方面取得了显著成功，但尚未完全应用于视觉运动代理。RL模型的一个主要挑战是它们容易过度拟合特定任务或环境，从而阻碍了在不同环境中获得可泛化的行为。本文旨在解决这一挑战，展示RL微调的视觉运动代理在Minecraft中可以实现对未见过的世界的零样本泛化。

Method: 本文通过在Minecraft中进行强化学习（RL）微调视觉运动代理，实现了对未见过的世界的零样本泛化。为了解决多任务RL表示的挑战，本文分析并建立了跨视图目标规范作为视觉运动策略的统一多任务目标空间。此外，为了克服手动任务设计的瓶颈，本文提出了在高度可定制的Minecraft环境中进行自动化任务合成，以支持大规模多任务RL训练，并构建了一个高效的分布式RL框架。

Result: 实验结果表明，RL将交互成功率显著提高了4倍，并实现了跨不同环境（包括真实世界设置）的空间推理的零样本泛化。

Conclusion: RL训练在3D模拟环境，特别是那些易于大规模生成任务的环境中，具有巨大潜力，能够显著推进视觉运动代理的空间推理能力。

Abstract: While Reinforcement Learning (RL) has achieved remarkable success in language
modeling, its triumph hasn't yet fully translated to visuomotor agents. A
primary challenge in RL models is their tendency to overfit specific tasks or
environments, thereby hindering the acquisition of generalizable behaviors
across diverse settings. This paper provides a preliminary answer to this
challenge by demonstrating that RL-finetuned visuomotor agents in Minecraft can
achieve zero-shot generalization to unseen worlds. Specifically, we explore
RL's potential to enhance generalizable spatial reasoning and interaction
capabilities in 3D worlds. To address challenges in multi-task RL
representation, we analyze and establish cross-view goal specification as a
unified multi-task goal space for visuomotor policies. Furthermore, to overcome
the significant bottleneck of manual task design, we propose automated task
synthesis within the highly customizable Minecraft environment for large-scale
multi-task RL training, and we construct an efficient distributed RL framework
to support this. Experimental results show RL significantly boosts interaction
success rates by $4\times$ and enables zero-shot generalization of spatial
reasoning across diverse environments, including real-world settings. Our
findings underscore the immense potential of RL training in 3D simulated
environments, especially those amenable to large-scale task generation, for
significantly advancing visuomotor agents' spatial reasoning.

</details>


### [252] [Design of a bioinspired robophysical antenna for insect-scale tactile perception and navigation](https://arxiv.org/abs/2507.23719)
*Parker McDonnell,Lingsheng Meng,Hari Krishna Hariprasad,Alexander Hedrick,Eduardo Miscles,Samuel Gilinsky,Jean-Michel Mongeau,Kaushik Jayaram*

Main category: cs.RO

TL;DR: CITRAS 是一种受蟑螂启发的微型触觉传感器，可以集成到昆虫机器人中，用于导航和环境感知。


<details>
  <summary>Details</summary>
Motivation: 虽然触觉传感器能够实现自然系统中的鲁棒、自主感知和导航，但由于现有传感技术的严格尺寸、重量和功率限制，在昆虫尺度机器人中复制这些能力仍然具有挑战性。

Method: CITRAS（蟑螂启发式触觉机器人天线传感器）是一种受生物启发的、多节的、柔性层压传感器，具有嵌入式电容角度传感器。

Result: CITRAS 尺寸小巧（73.7x15.6x2.1 毫米）、重量轻（491 毫克）、功耗低（32 毫瓦），能够与微型机器人平台无缝集成。实验评估证明了 CITRAS 的多功能触觉感知能力：以 7.75% 的误差预测基端距离，以 6.73% 的误差估计环境间隙宽度，并通过差异化传感器响应区分表面纹理。

Conclusion: CITRAS 的未来整合将解决昆虫尺度机器人中的关键传感缺口，有望在复杂、受限的环境中增强自主探索、避障和环境绘图能力。

Abstract: The American cockroach (Periplaneta americana) uses its soft antennae to
guide decision making by extracting rich tactile information from tens of
thousands of distributed mechanosensors. Although tactile sensors enable
robust, autonomous perception and navigation in natural systems, replicating
these capabilities in insect-scale robots remains challenging due to stringent
size, weight, and power constraints that limit existing sensor technologies. To
overcome these limitations, we introduce CITRAS (Cockroach Inspired Tactile
Robotic Antenna Sensor), a bioinspired, multi-segmented, compliant laminate
sensor with embedded capacitive angle sensors. CITRAS is compact (73.7x15.6x2.1
mm), lightweight (491 mg), and low-power (32 mW), enabling seamless integration
with miniature robotic platforms. The segmented compliant structure passively
bends in response to environmental stimuli, achieving accurate hinge angle
measurements with maximum errors of just 0.79 degree (quasistatic bending) and
3.58 degree (dynamic bending). Experimental evaluations demonstrate CITRAS'
multifunctional tactile perception capabilities: predicting base-to-tip
distances with 7.75 % error, estimating environmental gap widths with 6.73 %
error, and distinguishing surface textures through differential sensor
response. The future integration of this bioinspired tactile antenna in
insect-scale robots addresses critical sensing gaps, promising enhanced
autonomous exploration, obstacle avoidance, and environmental mapping in
complex, confined environments.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [253] [H2SGEMM: Emulating FP32 GEMM on Ascend NPUs using FP16 Units with Precision Recovery and Cache-Aware Optimization](https://arxiv.org/abs/2507.23387)
*Weicheng Xue,Baisong Xu,Kai Yang,Yongxiang Liu,Dengdeng Fan,Pengxiang Xu,Yonghong Tian*

Main category: cs.DC

TL;DR: H2SGEMM利用FP16单元模拟FP32矩阵乘法，通过分解、缩放和优化计算顺序，在性能和精度上均表现出色，尤其在特定条件下数值稳定性更佳。


<details>
  <summary>Details</summary>
Motivation: 低精度矩阵计算单元（如FP16）虽然吞吐量高，但缺乏全精度计算能力。为了在仅支持FP16计算的AI加速器上高效执行FP32通用矩阵乘法（GEMM），需要一种新的算法。

Method: H2SGEMM算法通过将FP32矩阵分解为两个FP16矩阵，利用FP16计算单元进行计算，并通过可调缩放策略补偿数值误差。采用分项累加方案提高数值稳定性，并结合缓存感知阻塞策略和双缓冲流水线实现内存传输与计算的重叠。

Result: H2SGEMM算法能够恢复原生FP32 GEMM的精度，并在低指数范围内表现出优于传统FP32 GEMM的数值稳定性。在Ascend 910A NPU上，该算法实现了高达理论FP32等效峰值性能77%的实际性能。

Conclusion: H2SGEMM算法在缺乏原生FP32支持的AI加速器上，通过利用FP16计算单元实现了高性能的FP32通用矩阵乘法（GEMM）仿真。该方法通过将FP32操作数分解为两个FP16值，并采用可调缩放策略补偿数值误差，同时通过分项累加方案提高了数值稳定性。实验证明，H2SGEMM能恢复原生FP32 GEMM的精度，并在特定条件下表现出更优的数值稳定性，同时实现了高达理论FP32峰值性能77%的实际性能。

Abstract: Low-precision matrix engines, such as FP16 cube, offer high throughput but
lack support for full-precision computation. In this work, we propose H2SGEMM,
a high-performance algorithm for emulating FP32 general matrix-matrix
multiplication (GEMM) using only FP16 computation units on a representative AI
accelerator. The method decomposes each FP32 operand into two FP16 values and
compensates for numerical errors through a tunable scaling strategy. A detailed
analysis of numerical errors, including underflow conditions and precision
loss, guides the selection of scaling parameters to preserve up to 22 bits of
mantissa accuracy. We further investigate the effect of computation order on
accuracy and demonstrate that a term-wise accumulation scheme improves
numerical stability over conventional FP32 GEMM in low-exponent regimes.
Finally, a cache-aware blocking strategy and double-buffered pipeline are
introduced to overlap memory transfers with computation, enabling H2SGEMM to
achieve up to 77% of the theoretical FP32-equivalent peak performance on Ascend
910A NPU lacking native FP32 support. Extensive numerical experiments confirm
that our method not only recovers the accuracy of native FP32 GEMM but also
exhibits superior numerical stability under certain conditions, due to its
structured and error-aware computation order.

</details>


### [254] [Towards a Testbed for Scalable FaaS Platforms](https://arxiv.org/abs/2507.23431)
*Trever Schirmer,David Bermbach*

Main category: cs.DC

TL;DR: A testbed was developed to evaluate FaaS platform architectures and technologies for scalability.


<details>
  <summary>Details</summary>
Motivation: To better understand how the platform's architecture impacts its performance in highly scalable applications offered by FaaS.

Method: A research-focused testbed was presented to evaluate the impact of different architectures and technologies on FaaS platforms.

Result: The presented testbed allows for the evaluation of different architectures and technologies on FaaS platforms.

Conclusion: The research-focused testbed can be adapted to quickly evaluate the impact of different architectures and technologies on the characteristics of scalability-focused FaaS platforms.

Abstract: Most cloud platforms have a Function-as-a-Service (FaaS) offering that
enables users to easily write highly scalable applications. To better
understand how the platform's architecture impacts its performance, we present
a research-focused testbed that can be adapted to quickly evaluate the impact
of different architectures and technologies on the characteristics of
scalability-focused FaaS platforms.

</details>


### [255] [Threshold-Driven Streaming Graph: Expansion and Rumor Spreading](https://arxiv.org/abs/2507.23533)
*Flora Angileri,Andrea Clementi,Emanuele Natale,Michele Salvi,Isabella Ziccardi*

Main category: cs.DC

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: A randomized distributed algorithm called RAES was introduced in [Becchetti
et al., SODA 2020] to extract a bounded-degree expander from a dense $n$-vertex
expander graph $G = (V, E)$. The algorithm relies on a simple threshold-based
procedure. A key assumption in [Becchetti et al., SODA 2020] is that the input
graph $G$ is static - i.e., both its vertex set $V$ and edge set $E$ remain
unchanged throughout the process - while the analysis of RAES in dynamic models
is left as a major open question.
  In this work, we investigate the behavior of RAES under a dynamic graph model
induced by a streaming node-churn process (also known as the sliding window
model), where, at each discrete round, a new node joins the graph and the
oldest node departs. This process yields a bounded-degree dynamic graph
$\mathcal{G} =\{ G_t = (V_t, E_t) : t \in \mathbb{N}\}$ that captures essential
characteristics of peer-to-peer networks -- specifically, node churn and
threshold on the number of connections each node can manage. We prove that
every snapshot $G_t$ in the dynamic graph sequence has good expansion
properties with high probability. Furthermore, we leverage this property to
establish a logarithmic upper bound on the completion time of the well-known
PUSH and PULL rumor spreading protocols over the dynamic graph $\mathcal{G}$.

</details>


### [256] [The ArborX library: version 2.0](https://arxiv.org/abs/2507.23700)
*Andrey Prokopenko,Daniel Arndt,Damien Lebrun-Grandié,Bruno Turcksin*

Main category: cs.DC

TL;DR: ArborX 2.0 库发布，带来新接口、分布式支持、回调函数和更多算法。


<details>
  <summary>Details</summary>
Motivation: 本论文旨在概述 ArborX 库的 2.0 版本发布。

Method: ArborX 2.0 版本基于 Kokkos，一个性能可移植的几何搜索库。

Result: ArborX 2.0 引入了新的库接口、支持分布式数据结构、支持回调函数以及扩展的算法集。

Conclusion: ArborX 2.0 提供了更广泛的用户问题支持、新的搜索数据结构（蛮力、分布式）、用户函数执行支持（回调）以及扩展的算法集（射线追踪、聚类）。

Abstract: This paper provides an overview of the 2.0 release of the ArborX library, a
performance portable geometric search library based on Kokkos. We describe the
major changes in ArborX 2.0 including a new interface for the library to
support a wider range of user problems, new search data structures (brute
force, distributed), support for user functions to be executed on the results
(callbacks), and an expanded set of the supported algorithms (ray tracing,
clustering).

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [257] [WiRM: Wireless Respiration Monitoring Using Conjugate Multiple Channel State Information and Fast Iterative Filtering in Wi-Fi Systems](https://arxiv.org/abs/2507.23419)
*James Rhodes,Lawrence Ong,Duy T. Ngo*

Main category: cs.ET

TL;DR: WiRM是一种创新的两阶段呼吸监测方法，通过相位归一化和自适应多跟踪划分提高了呼吸频率估计的精度，并通过利用呼吸频率信息改进了呼吸波形的监测。该方法在各种噪声条件下均表现出良好的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于信道状态信息（CSI）的呼吸健康监测方法大多只关注呼吸频率或胸部运动（呼吸波形）。本研究旨在提出一种能够同时精确监测呼吸频率和呼吸波形的方法，并评估其在不同噪声环境下的鲁棒性。

Method: WiRM是一种两阶段的方法。第一阶段采用共轭乘法进行相位归一化和自适应多跟踪划分（AMTC）来跟踪呼吸频率随时间的变化。第二阶段利用改进的呼吸频率估计来分解和选择CSI数据中的呼吸波形。此外，研究还开发了一个专门的仿真工具包，用于评估各种噪声条件下的呼吸监测解决方案的鲁棒性。

Result: 与三种现有技术相比，WiRM在呼吸频率估计方面的均方根误差（RMSE）平均降低了38%。WiRM在呼吸波形与真实值的平均绝对相关性方面提高了178.3%。在噪声环境下，WiRM表现出与现有技术相当或更好的鲁棒性。

Conclusion: WiRM在呼吸监测方面表现出色，在呼吸频率估计方面将RMSE平均降低了38%，在呼吸波形相关性方面提高了178.3%。WiRM在模拟的各种噪声环境下也表现出良好的鲁棒性。

Abstract: Monitoring respiratory health with the use of channel state information (CSI)
has shown promising results. Many existing methods focus on monitoring only the
respiratory rate, while others focus on monitoring the motion of the chest as a
patient breathes, which is referred to as the respiratory waveform. This paper
presents WiRM, a two-staged approach to contactless respiration monitoring. In
the first stage, WiRM improves upon existing respiratory rate estimation
techniques by using conjugate multiplication for phase sanitisation and
adaptive multi-trace carving (AMTC) for tracing how the respiratory rate
changes over time. When compared against three state-of-the-art methods, WiRM
has achieved an average reduction of $38\%$ in respiratory rate root mean
squared error (RMSE). In the second stage, WiRM uses this improved respiratory
rate estimate to inform the decomposition and selection of the respiratory
waveform from the CSI data. Remarkably, WiRM delivers a $178.3\%$ improvement
in average absolute correlation with the ground truth respiratory waveform.
Within the literature, it is difficult to compare the robustness of existing
algorithms in noisy environments. In this paper, we develop a purpose-built
simulation toolkit to evaluate the robustness of respiration monitoring
solutions under various noise conditions, including thermal, multiplicative,
and phase noise. Our results show that WiRM demonstrates improved or comparable
resilience to these common noise sources.

</details>


### [258] [SOME: Symmetric One-Hot Matching Elector -- A Lightweight Microsecond Decoder for Quantum Error Correction](https://arxiv.org/abs/2507.23618)
*Xinyi Guo,Geguang Miao,Shinichi Nishizawa,Hiromitsu Awano,Shinji Kimura,Takashi Sato*

Main category: cs.ET

TL;DR: SOME是一种新型量子纠错解码器，通过将解码任务表示为“独热QUBO”问题，实现了变量数量和解码时间的显著降低，同时保持了高解码性能。


<details>
  <summary>Details</summary>
Motivation: 传统的量子纠错（QEC）解码器（如最小权重完美匹配（MWPM）和并查集（UF））虽然具有高阈值和快速解码的优点，但存在高拓扑复杂性的问题。而基于Ising模型的解码器虽然降低了拓扑复杂性，但解码时间却很长。需要一种新的解码方法来解决这些问题。

Method: 将QEC解码任务重构为二次无约束二元优化（QUBO）问题，即“独热QUBO”（OHQ），并提出了一种名为SOME（对称独热匹配选举器）的新型解码器来有效解决OHQ。

Result: SOME实现了高达99.9倍的变量数量减少，并将解码时间从毫秒缩短到微秒级（在单线程CPU上）。OHQ的性能在高达10.5%的物理错误率下依然保持，超过了目前已知的MWPM的最高阈值。

Conclusion: SOME在降低变量数量和解码时间方面表现出色，同时保持了高竞争力的QEC性能。

Abstract: Conventional quantum error correction (QEC) decoders such as Minimum-Weight
Perfect Matching (MWPM) and Union-Find (UF) offer high thresholds and fast
decoding, respectively, but both suffer from high topological complexity. In
contrast, Ising model-based decoders reduce topological complexity but demand
considerable decoding time. We propose the Symmetric One-Hot Matching Elector
(SOME), a novel decoder that reformulates the QEC decoding task as a Quadratic
Unconstrained Binary Optimization (QUBO) problem -- termed the One-Hot QUBO
(OHQ). Each variable in the QUBO represents whether a given pair of flipped
syndromes is matched, while the error probabilities between the pair are
encoded as interaction coefficients (weight). Constraints ensure that each
flipped syndrome is matched exactly once. Valid solutions of OHQ correspond to
self-inverse permutation matrices, characterized by symmetric one-hot encoding.
To solve the OHQ efficiently, SOME reformulates the decoding task as the
construction of permutation matrices that minimize the total weight. It
initializes each candidate matrix from one of the minimum-weight syndrome
pairs, then iteratively appends additional pairs in ascending order of weight,
and finally selects the permutation matrix with the lowest total energy. SOME
achieves up to a 99.9x reduction in variable count and reduces decoding times
from milliseconds to microseconds on a single-threaded commodity CPU. OHQ also
maintains performance up to a 10.5% physical error rate, surpassing the highest
known threshold of MWPM@.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [259] [Exciton Berryology](https://arxiv.org/abs/2507.22983)
*Henry Davenport,Johannes Knolle,Frank Schindler*

Main category: cond-mat.mes-hall

TL;DR: 本文提出了一种新的理论框架，用于理解和计算半导体中的激子 Berry 相和激子极化。该理论将移位激子的概念推广到对称指示器之外，并为分析激子能带的拓扑特性提供了新的工具。


<details>
  <summary>Details</summary>
Motivation: 为了在具有激子束缚态的平移不变半导体中定义无限数量的可能激子 Berry 连接，并澄清这些激子 Berry 相的物理意义。

Method: 通过定义激子投影算子来选择激子 Berry 相和相关的 Berry 连接，并提出离散 Wilson 环公式以在没有平滑规范的情况下进行数值计算。

Result: 提出了激子投影算子，该算子可以选择两种唯一的激子 Berry 相和相关的 Berry 连接（一种用于电子，一种用于空穴），并推导出了激子极化的规范不变表达式。当存在晶体反演对称性时，电子和空穴激子 Berry 相被量化为相同的值。对于晶体 $C_2 \mathcal{T}$ 对称性，即使没有对称性特征值，激子 Berry 相仍然是量化的，并且可以诊断拓扑上不同的激子带。

Conclusion: 该理论将移位激子（其激子 Wannier 态与非相互作用带的量化量不同）的概念推广到对称指示器之外。

Abstract: In translationally invariant semiconductors that host exciton bound states,
one can define an infinite number of possible exciton Berry connections. These
correspond to the different ways in which a many-body exciton state, at fixed
total momentum, can be decomposed into free electron and hole Bloch states that
are entangled by an exciton envelope wave function. Inspired by the modern
theory of polarization, we define an exciton projected position operator whose
eigenvalues single out two unique choices of exciton Berry phase and associated
Berry connection - one for electrons, and one for holes. We clarify the
physical meaning of these exciton Berry phases and provide a discrete Wilson
loop formulation that allows for their numerical calculation without a smooth
gauge. As a corollary, we obtain a gauge-invariant expression for the exciton
polarisation at a given total momentum, i.e. the mean separation of the
electron and hole within the exciton wave function. In the presence of
crystalline inversion symmetry, the electron and hole exciton Berry phases are
quantized to the same value and we derive how this value can be expressed in
terms of inversion eigenvalues of the many-body exciton state. We then consider
crystalline $C_2 \mathcal{T}$ symmetry, for which no symmetry eigenvalues are
available as it is anti-unitary, and confirm that the exciton Berry phase
remains quantized and still diagnoses topologically distinct exciton bands. Our
theory thereby generalizes the notion of shift excitons, whose exciton Wannier
states are displaced from those of the non-interacting bands by a quantized
amount, beyond symmetry indicators.

</details>


### [260] [Higher-order Topological States in Chiral Split Magnons of Honeycomb Altermagnets](https://arxiv.org/abs/2507.22996)
*Xuan Guo,Meng-Han Zhang,Dao-Xin Yao*

Main category: cond-mat.mes-hall

TL;DR: 该研究理论探索了共线反转子系统中的高阶拓扑磁振子，发现了铰链模式，并为磁振子量子信息处理提供了一个潜在的平台。


<details>
  <summary>Details</summary>
Motivation: 理论探索了共线反转子系统中的高阶拓扑磁振子，涵盖了从局域角模式到传播铰链激发的维度层次。

Method: 通过利用反铁磁层间耦合的玻色子Bogoliubov-de Gennes (BdG)哈密顿量，研究揭示了AA型堆叠结构中的各向异性表面态和空间分布的铰链模式。我们通过追踪Wannier中心的绝热演化来识别具有二阶拓扑磁振子绝缘体(SOTMI)的体极化，其中各种磁振子能谱展示了超越常规拓扑的对称保护能带结构。

Result: 研究揭示了AA型堆叠结构中的各向异性表面态和空间分布的铰链模式，并识别了二阶拓扑磁振子绝缘体(SOTMI)。

Conclusion: 该研究为反转子系统中的磁振子量子信息处理提供了一个潜在的平台，用于执行节能逻辑操作。

Abstract: We theoretically explore higher-order topological magnons in collinear
altermagnets, encompassing a dimensional hierarchy ranging from localized
corner modes to propagating hinge excitations. By employing antiferromagnetic
interlayer coupling in bosonic Bogoliubov-de Gennes (BdG) Hamiltonian, our work
reveals anisotropic surface states and spatially distributed hinge modes within
AA-type stacking configurations. We track the adiabatic evolution of Wannier
centers to identify the bulk-polarization with second-order topological magnon
insulator (SOTMI), where various magnon spectra demonstrate symmetry-protected
band structure beyond conventional topology. Harnessing the stability and
propagative properties of hinge modes, our study offers a potential platform
for magnonic quantum information processing in altermagnetic systems that
performs energy-efficient logic operation.

</details>


### [261] [Quantum confinement effect in Sb thin films](https://arxiv.org/abs/2507.23014)
*Anuradha Wijesinghe,Yongxi Ou,Anjali Rathore,Chandima Edirisinghe,Pradip Adhikari,An-Hsi Chen,Dustin Gilbert,Anthony Richardella,Nitin Samarth,Joon Sue Lee*

Main category: cond-mat.mes-hall

TL;DR: 通过 MBE 生长 Sb 薄膜，并结合电输运和 ARPES 测量，证实了 Sb 维度接近二维时，由于量子限制效应，其能带结构会发生演化，支持了从拓扑半金属到拓扑绝缘体的相变理论。这为开发新型拓扑材料和量子器件提供了基础。


<details>
  <summary>Details</summary>
Motivation: 锑（Sb）作为一种具有强自旋-orbit耦合的元素，在维度接近二维极限时，理论预测会因量子限制效应发生从拓扑半金属到拓扑绝缘体的相变。本研究旨在通过实验手段（生长Sb薄膜并进行表征）来探索和验证这一理论预测。

Method: 本研究采用分子束外延技术生长锑薄膜，并通过电学输运测量（包括霍尔效应、纵向电阻曲率分析、温度依赖性磁阻）和角分辨光电子能谱（ARPES）来研究其拓扑性质。

Result: 电学输运测量揭示了锑薄膜在厚度减小过程中，霍尔效应表现出多载流子特性，载流子浓度下降，纵向电阻曲率从二次变为线性。低温下的弱反局域化现象表明存在强自旋-轨道耦合和非平凡拓扑态。ARPES测量证实了随着厚度减小，M点的导带上移，并出现带隙，与量子限制效应驱动的能带结构演化一致。

Conclusion: 这项研究通过实验证实了锑（Sb）薄膜的厚度依赖性能带结构演化，这是由量子限制效应驱动的，并支持了其从拓扑半金属到拓扑绝缘体相变的理论预测。锑作为一种具有强自旋-轨道耦合的元素，其二维化过程为探索拓扑相变和开发下一代自旋电子学及量子技术器件提供了基础。

Abstract: Antimony (Sb), an element with strong spin-orbit coupling, is predicted to
undergo a topological phase transition from a topological semimetal to a
topological insulator as its dimensionality approaches the two-dimensional
limit, driven by the quantum confinement effect. In this study, we investigate
this transition in Sb thin films grown by molecular beam epitaxy, employing
electrical transport measurements and angle-resolved photoemission spectroscopy
(ARPES). Electrical transport measurements revealed signatures of a modified
electronic band structure, including a Hall response with multiple carrier
types, a decreasing carrier concentration, and a transition in the curvature of
the longitudinal resistance from quadratic to linear with decreasing film
thickness. Temperature-dependent magnetoresistance further showed weak
antilocalization below 16 K, indicating strong spin-orbit coupling and
suggesting the presence of non-trivial topological states. Analysis of the WAL
characteristics revealed a single coherent conducting channel and a
thickness-dependent change in the phase decoherence mechanism. Complementary
ARPES measurements confirmed that reducing the film thickness lifts the
conduction band at the M-point, consistent with the emergence of a band gap.
These findings support theoretical predictions of a thickness-dependent band
structure evolution driven by the quantum confinement effect, providing a
foundation for further exploration of topological phase transitions in Sb as
well as Bi1-xSbx. The realization of an elemental topological material with
simplified stoichiometry and semiconductor compatibility presents a promising
avenue for next-generation hybrid systems and applications in spintronics and
quantum technologies.

</details>


### [262] [Exploring Many-Body Quantum Geometry Beyond the Quantum Metric with Correlation Functions: A Time-Dependent Perspective](https://arxiv.org/abs/2507.23028)
*Yuntao Guan,Barry Bradlyn*

Main category: cond-mat.mes-hall

TL;DR: 该论文提出了一种新的时间依赖量子几何框架，用于描述多体系统的非线性响应，并将Bures距离推广到高阶微扰，为研究量子几何提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对高阶微扰现象（如非线性响应）的统一几何描述，而量子几何张量和量子Fisher信息仅限于线性响应。

Method: 通过将外部扰动场视为密度矩阵空间的坐标，并利用Bures距离及其微扰展开来定义时间依赖的量子几何量，包括Bures度量和Bures-Levi-Civita联络。

Result: 推导了时间依赖的Bures度量，并统一了不同极限下的量子度量结果，为费米黄金定则提供了几何解释。定义了时间依赖的Bures-Levi-Civita联络，并展示了其与二阶非线性响应函数以及一阶微扰理论的几何结构相关。在特定条件下，该联络可化为已知的布里渊带理论中的克里斯托费尔符号。

Conclusion: 该研究为理解和计算多体量子系统的几何性质提供了新的途径，特别是在高阶微扰和非线性响应方面。

Abstract: The quantum geometric tensor and quantum Fisher information have recently
been shown to provide a unified geometric description of the linear response of
many-body systems. However, a similar geometric description of higher-order
perturbative phenomena including nonlinear response in generic quantum systems
is lacking. In this work, we develop a general framework for the time-dependent
quantum geometry of many-body systems by treating external perturbing fields as
coordinates on the space of density matrices. We use the Bures distance between
the initial and time-evolved density matrix to define geometric quantities
through a perturbative expansion. To lowest order, we derive a time-dependent
generalization of the Bures metric related to the spectral density of linear
response functions, unifying previous results for the quantum metric in various
limits and providing a geometric interpretation of Fermi's golden rule. At next
order in the expansion, we define a time-dependent Bures-Levi-Civita connection
for general many-body systems. We show that the connection is the sum of one
contribution that is related to a second-order nonlinear response function, and
a second contribution that captures the higher geometric structure of
first-order perturbation theory. We show that in the quasistatic,
zero-temperature limit for noninteracting fermions, this Bures connection
reduces to the known expression for band-theoretic Christoffel symbols. Our
work provides a systematic framework to explore many-body quantum geometry
beyond the quantum metric and highlights how higher-order correlation functions
can probe this geometry.

</details>


### [263] [Model Hamiltonian for Altermagnetic Topological Insulators](https://arxiv.org/abs/2507.23173)
*Rafael Gonzalez-Hernandez,Bernardo Uribe*

Main category: cond-mat.mes-hall

TL;DR: 研究了具有反常磁性的拓扑绝缘体，利用对称性保护边界态，并为设计新型自旋电子拓扑系统提供了理论框架。


<details>
  <summary>Details</summary>
Motivation: 探索结合反常磁性与拓扑量子物质领域，并为设计新型自旋电子拓扑系统提供理论框架。

Method: 提出了具有内在反常磁性特征的拓扑绝缘体哈密顿量模型，并结合了三重或四重旋转对称性和时间反转对称性进行保护。利用自旋陈数作为二维系统的拓扑不变量，并利用 $k_z$=0 和 $k_z$=$	extpi$ 平面对三维结构进行拓扑表征。

Result: 所提出的模型支持对称性保护的边界态，包括角态、铰链态和表面态，其具体结构由磁对称性和局部磁矩决定。

Conclusion: 这项研究为设计不具有净磁化的、开关型自旋电子拓扑系统提供了理论基础。

Abstract: We present models of topological insulating Hamiltonians exhibiting intrinsic
altermagnetic features, protected by combined three-fold or four-fold
rotational symmetries with time-reversal. We demonstrate that the spin Chern
number serves as a robust topological invariant in two-dimensional systems,
while for three-dimensional structures, the topological nature is characterized
by the spin Chern numbers computed on the $k_z$=$0$ and $k_z$=$\pi$ planes. The
resulting phases support symmetry-protected boundary modes, including corner,
hinges and surface states, whose structure is determined by the magnetic
symmetry and the local magnetic moments. Our findings bridge the fields of
altermagnetism and topological quantum matter, and establish a theoretical
framework for engineering spintronic topological systems without net
magnetization.

</details>


### [264] [Spin-State Engineering of Single Titanium Adsorbates on Ultrathin Magnesium Oxide](https://arxiv.org/abs/2507.23299)
*Soo-hyon Phark,Hong Thi Bui,We-hyo Seo,Yaowu Liu,Valeria Sheina,Curie Lee,Christoph Wolf,Andreas J. Heinrich,Roberto Robles,Nicolas Lorente*

Main category: cond-mat.mes-hall

TL;DR: 本研究利用扫描隧道显微镜和电子自旋共振研究了超薄绝缘薄膜上的单钛（Ti）吸附原子，发现了两种不同的自旋状态（S=1/2和S=1），这取决于局域吸附位点和MgO薄膜的厚度。研究结果表明，表面负载的单原子具有作为自旋量子比特的潜力，并且其自旋和电荷状态可调，能够实现表面多功能量子平台的逐原子控制。


<details>
  <summary>Details</summary>
Motivation: 为了构建基于原子尺度上相同但可单独寻址的自旋量子比特的自上而下量子架构，理解和控制单个吸附原子的自旋状态是一个关键挑战。

Method: 利用扫描隧道显微镜和电子自旋共振研究了超薄绝缘薄膜上的单钛（Ti）吸附原子，并通过密度泛函理论计算和多轨道原子多重态计算进行理论分析。

Result: 测量发现了两种不同的自旋状态，S=1/2和S=1，具体取决于局域吸附位点和MgO薄膜的厚度。理论计算表明，Ti吸附原子为Ti+构型，其4s和3d价电子数约为3个。这种自旋的位点依赖性可以解释为自旋极化轨道和反极化轨道之间的电荷重新分布。

Conclusion: 研究结果表明，表面负载的单原子具有作为自旋量子比特的潜力，并且其自旋和电荷状态可调，能够实现表面多功能量子平台的逐原子控制。

Abstract: Single atomic adsorbates on ultrathin insulating films provide a promising
route toward bottom-up quantum architectures based on atomically identical yet
individually addressable spin qubits on solid surfaces. A key challenge in
engineering quantum-coherent spin nanostructures lies in understanding and
controlling the spin state of individual adsorbates. In this work, we
investigate single titanium (Ti) atoms adsorbed on MgO/Ag(100) surfaces using a
combined scanning tunneling microscopy and electron spin resonance. Our
measurements reveal two distinct spin states, $S = 1/2$ and $S = 1$, depending
on the local adsorption site and the thickness of the MgO film. Density
functional theory calculations suggest a Ti$^+$ configuration for the Ti
adsorbates with approximately 3 electrons in the 4$s$ and 3$d$ valence shells.
Using a multi-orbital atomic multiplet calculations the site dependence of the
spin can be rationalized as a charge redistribution between spin-polarizing and
depolarizing orbitals. These findings underscore the potential of
surface-supported single atoms as spin qubits with tunable spin and charge
states, enabling atom-by-atom control in the realization of a versatile quantum
platform on surfaces.

</details>


### [265] [Printable Nanocomposites with Superparamagnetic Maghemite ($γ$-Fe$_2$O$_3$) Particles for Microinductor-core Applications](https://arxiv.org/abs/2507.23522)
*Mathias Zambach,Miriam Varón,Thomas Veile,Bima N. Sanusi,Matti Knaapila,Anders M. Jørgensen,László Almásy,Christer Johansson,Ziwei Ouyang,M. Beleggia,Cathrine Frandsen*

Main category: cond-mat.mes-hall

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We here present printable and castable magnetic nanocomposites containing
superparamagnetic 11$\pm$3 nm $\gamma$-Fe$_2$O$_3$ particles in an insulating
poly-vinyl alcohol polymer matrix. The nanocomposites feature well-dispersed
particles with volume fractions between 10 and 45 \%, as confirmed by
small-angle neutron scattering. The magnetic volume susceptibility is as high
as 17, together with negligible hysteresis at low frequency, and constant
AC-response up to the high-kHz range. Measured hysteresis curves at 100-900 kHz
with up to 110 mT induced $B$-fields in the nanocomposite show that power
losses depend on $B$-field squared, and frequency to the power of 1-1.3. The
only loss mechanism in the nanocomposite is hysteresis losses at $>$100 kHz
frequencies, where the largest particles in the 11$\pm$3 nm distribution
transition from the superparamagnetic to blocked regime. To mitigate the
resulting hysteresis losses (up 10$^2$-10$^5$ kW/m$^3$) a more narrow particle
size distribution could be used for future materials. The presented material is
eddy current-free and easily integrated into micro-fabrication protocols, as we
demonstrate by fabrication of 3-turn print circuit board based inductors with
cast/manual printed nanocomposite inductor cores, on which induction has been
measured up to 100 MHz.

</details>


### [266] [Magnetic order dependent photoluminescence from high energy excitons in hBN protected few-layer CrSBr](https://arxiv.org/abs/2507.23301)
*Xiaohua Wu,Junyang Chen,Mingqiang Gu,Yujun Zhang,Shanmin Wang,Yanan Dai,Qihang Liu,Yue Zhao,Mingyuan Huang*

Main category: cond-mat.mes-hall

TL;DR: 少层CrSBr的光致发光特性与其磁序相关，可用于探测自旋构型，是研究激子-磁性相互作用的理想材料。


<details>
  <summary>Details</summary>
Motivation: 为了在二维极限下开发自旋电子器件，需要检测和操控层状磁性半导体中的自旋构型。

Method: 通过光致发光（PL）谱和第一性原理计算，系统地研究了少层CrSBr中的激子发光及其在探测自旋构型中的应用。

Result: 观察到CrSBr中存在两个激子发光峰（Xl和Xh），其中Xh峰的位置和强度与层间磁序密切相关，并且在施加磁场时观察到除了反铁磁和铁磁状态之外的中间磁态。

Conclusion: 该研究揭示了少层CrSBr是研究激子与磁性相互作用的理想平台。

Abstract: The detection and manipulation of the spin configurations in layered magnetic
semiconductors hold significant interest for developing spintronic devices in
two-dimensional limit. In this letter, we report a systematical study on the
photoluminescence (PL) from the high energy excitons in few-layer CrSBr and its
application on detecting the spin configurations. Besides the broad excitonic
emission peak (Xl) at around 1.34 eV, we also observed another strong excitonic
emission peak (Xh) at around 1.37 eV in hBN encapsulated 2L sample, which
splits into two peaks in 3L and 4L samples. With help of the first principles
calculations, we conclude that the Xh peak is associated with the transition
between the top valence band and the second lowest conduction band, which is
forbidden by the inversion symmetry in 1L CrSBr. Furthermore, the position and
intensity of the Xh peak are strongly dependent on the interlayer magnetic
order of the CrSBr samples, which provides an efficient way to probe their spin
configurations. In addition, when the magnetic field is applied at the easy
axis direction, we resolve an intermediate magnetic state besides the
antiferromagnetic and ferromagnetic states in 3L and 4L samples. Our results
reveal few-layer CrSBr as an ideal platform to study the interaction between
the excitons and magnetism.

</details>


### [267] [Implementing Pseudofractal Designs in Graphene-Based Quantum Hall Arrays using Minkowski-Bouligand Algorithms](https://arxiv.org/abs/2507.23625)
*Dominick S. Scaletta,Ngoc Thanh Mai Tran,Marta Musso,Dean G. Jarrett,Heather M. Hill,Massimo Ortolano,David B. Newell,Albert F. Rigosi*

Main category: cond-mat.mes-hall

TL;DR: 研究利用伪分形分析和星网变换优化量子霍尔电阻标准，通过分析不同递归设计的维度和元件数量，发现部分递归设计提供了更大的灵活性，但元件数量有所增加。


<details>
  <summary>Details</summary>
Motivation: 为了优化高阻石墨烯基量子霍尔阵列电阻标准（QHARS）的设计，提出了一种伪分形分析方法，旨在通过星网变换最小化元件数量，并探索不同递归设计在实现特定电阻值方面的灵活性。

Method: 本研究采用伪分形分析，并结合星网变换和闵可夫斯基-布里渊算法，来优化石墨烯基量子霍尔阵列电阻标准（QHARS）的设计，通过分析不同递归案例的维度和元件数量，评估其在实现特定电阻值方面的灵活性。

Result: 通过闵可夫斯基-布里渊算法分析了三种不同的部分递归案例和全递归设计的维度和元件数量。研究表明，部分递归设计在实现特定电阻值邻域方面提供了更大的灵活性，但需要更多的元件。

Conclusion: 该研究提出的伪分形分析方法为优化基于石墨烯的量子霍尔阵列电阻标准（QHARS）的设计提供了新的途径，通过星网变换和伪分形概念，可以更灵活地实现特定的电阻值，尽管可能需要更多的元件数量。

Abstract: This work introduces a pseudofractal analysis for optimizing high-resistance
graphene-based quantized Hall array resistance standards (QHARS). The
development of resistance standard device designs through star-mesh
transformations is detailed, aimed at minimizing element count. Building on a
recent mathematical framework, the approach presented herein refines QHARS
device concepts by considering designs incorporating pseudofractals (which may
be expressed as star-mesh transformations). To understand how future QHARS
pseudofractal designs enable varying sizes of neighborhoods of available
quantized resistance, Minkowski-Bouligand algorithms are used to analyze
fractal dimensions of the device design topologies. Three distinct partial
recursion cases are explored in addition to the original full recursion design,
and expressions for their total element counts are derived. These partial
recursions, assessed through their fractal dimensions, offer enhanced
flexibility in achieving specific resistance values within a desired
neighborhood compared to full recursion methods, albeit with an increased
number of required elements. The formalisms presented are material-independent,
making them broadly applicable to other quantum Hall systems and artifact
standards.

</details>


### [268] [Graphene-based quantum heterospin graphs](https://arxiv.org/abs/2507.23360)
*Gabriel Martínez-Carracedo,Amador García-Fuente,László Oroszlány,László Szunyogh,Jaime Ferrer*

Main category: cond-mat.mes-hall

TL;DR: 研究了磁性纳米石墨烯的量子自旋系统，发现了其在特定结构下（如三腿自旋图）的自旋简并现象。


<details>
  <summary>Details</summary>
Motivation: 研究了具有自旋1/2和自旋1三角烯和/或奥林匹克烯的低维开放量子自旋系统。

Method: 利用第一性原理研究了基于磁性纳米石墨烯结构的低维开放量子自旋系统，计算了能量谱和低能特征态的量子数。

Result: 提出了反铁磁交替自旋链的实验实现，产生了亚铁磁系统，其基态自旋和简并度取决于链的长度。发现了三腿自旋图（3-LSG）的第一激发态中自旋量子数S的双重简并。

Conclusion: 发现了三腿自旋图（3-LSG）基态的自旋量子数S存在双重简并，该简并度取决于构成3-LSG的位点数量和自旋种类。

Abstract: We investigate from first principles a variety of low-dimensional open
quantum spin systems based on magnetic nanographene structures that contain
spin-1/2 and spin-1 triangulenes and/or olympicenes. These graphene
nanostructures behave as localized spins and can be effectively described by a
quantum bilinear-biquadratic Heisenberg Hamiltonian, for which we will compute
the energy spectrum and the quantum numbers associated with the low-energy
eigenstates. We propose the experimental realization of antiferromagnetic
alternating spin chains using these graphene nanostructures, which result in
ferrimagnetic systems whose ground state spin and degeneracy depend on the
length of the chain. We also identify a double degeneracy in the total spin
quantum number $S$ in the first excited state for three-leg spin graphs
(3-LSGs). This degeneracy depends on both the number of sites and the spin
species that compose the 3-LSG. We identify the double degeneracy of the first
excited state as a consequence of swapping transformation symmetry of the
Hamiltonian.

</details>


### [269] [Influences of the Minkowski-Bouligand Dimension on Graphene-Based Quantum Hall Array Designs](https://arxiv.org/abs/2507.23630)
*Dominick S. Scaletta,Ngoc Thanh Mai Tran,Marta Musso,Valery Ortiz Jimenez,Heather M. Hill,Dean G. Jarrett,Massimo Ortolano,Curt A. Richter,David B. Newell,Albert F. Rigosi*

Main category: cond-mat.mes-hall

TL;DR: This paper optimizes high-resistance quantized Hall array resistance standards (QHARS) using star-mesh transformations and recursion, exploring fractal dimensions and partial recursions for design flexibility, which allows access to desired resistance values at the expense of a higher number of devices.


<details>
  <summary>Details</summary>
Motivation: To develop high-resistance quantized Hall array resistance standards (QHARS) by optimizing device designs and exploring the benefits of full and partial recursions, including the concept of fractal dimension.

Method: Utilizes star-mesh transformations for element count minimization and a mathematical framework optimizing QHARS designs based on full, symmetric recursion, reconciling approximate device values with exact effective quantized resistances. Explores fractal dimension and three distinct partial recursion cases for a near-1 Gigaohm QHARS device.

Result: Identified benefits of both full and partial recursions in QHARS devices. Analyzed three distinct partial recursion cases for a near-1 Gigaohm QHARS device, showing increased flexibility in accessing desired resistance values compared to full recursion methods, but requiring more devices.

Conclusion: The paper explores fractal dimensions and partial recursions for designing high-resistance QHARS devices, offering flexibility in accessing desired resistance values at the cost of more devices.

Abstract: This work elaborates on how one may develop high-resistance quantized Hall
array resistance standards (QHARS) by using star-mesh transformations for
element count minimization. Refinements are made on a recently developed
mathematical framework optimizing QHARS device designs based on full, symmetric
recursion by reconciling approximate device values with exact effective
quantized resistances found by simulation and measurement. Furthermore, this
work explores the concept of fractal dimension, clarifying the benefits of both
full and partial recursions in QHARS devices. Three distinct partial recursion
cases are visited for a near-1 Gigaohm QHARS device. These partial recursions,
analyzed in the context of their fractal dimensions, offer increased
flexibility in accessing desired resistance values within a specific
neighborhood compared to full recursion methods, though at the cost of the
number of required devices.

</details>


### [270] [Multilayer Cryogenic Powder Filters with Low Parasitic Capacitance](https://arxiv.org/abs/2507.23388)
*Itishree Pradhan,Hao Li,Alina Rupp,Yosuke Sato,Henri Vo Van Qui,Miuko Tanaka,Toshiya Ideue,Erwann Bocquillon,Masayuki Hashisaka*

Main category: cond-mat.mes-hall

TL;DR: Developed a new multilayer powder filter that blocks GHz RF signals effectively and has lower parasitic capacitance, preventing sample heating in sensitive experiments.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of conventional powder filters, which suffer from significant parasitic capacitance that compromises sensitive measurement setups, and to suppress sample heating caused by RF signal intrusion.

Method: Development of a cryogenic powder filter with a multilayer design to improve RF signal attenuation and reduce parasitic capacitance to ground.

Result: The multilayer powder filter design effectively achieves high RF attenuation in the GHz range and minimized parasitic capacitance to ground.

Conclusion: A multilayer powder filter design effectively achieves both high RF attenuation and reduced parasitic capacitance, suppressing sample heating without degrading measurement setup performance.

Abstract: We report the development of a cryogenic powder filter that simultaneously
offers high attenuation of radio-frequency (RF) signals in the gigahertz (GHz)
range and minimized parasitic capacitance to ground. Conventional powder
filters, which consist of a signal line passing through a metal powder-filled
housing, attenuate high-frequency signals via the skin effect. However, these
designs often suffer from significant parasitic capacitance between the signal
line and the grounded chassis, which can compromise the performance of
sensitive measurement setups by limiting their frequency bandwidth. In this
work, we demonstrate that a multilayer powder filter design effectively
achieves both high RF attenuation and reduced parasitic capacitance. This
solution suppresses sample heating due to the unintentional intrusion of RF
signals through the wiring, without degrading the performance of the
measurement setup.

</details>


### [271] [Nonlinear Magnetoelectric Edelstein Effect](https://arxiv.org/abs/2507.23415)
*Jinxiong Jia,Longjun Xiang,Zhenhua Qiao,Jian Wang*

Main category: cond-mat.mes-hall

TL;DR: 研究提出了一种新的非线性磁电埃德尔斯坦效应，它源于磁场和电场的相互作用，并能在时间反演对称但缺乏反演对称性的材料中产生自旋磁化，同时也可用于检测反铁磁序。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在探索非线性埃德尔斯坦效应，特别是提出一种新的机制，即非线性磁电埃德尔斯坦效应，该效应能够克服时间反演对称性材料中自旋磁化产生的限制，并为反铁磁序的检测提供新途径。

Method: 该研究利用双带狄拉克模型和蜂窝晶格上的紧束缚模型进行了理论推导和计算，验证了所提出的非线性磁电埃德尔斯坦效应能够产生显著的自旋磁化。

Result: 通过理论计算，该研究表明非线性磁电埃德尔斯坦效应的本征和非本征部分都能产生显著的自旋磁化，并能灵敏地指示反铁磁材料中的涅尔矢量翻转。

Conclusion: 该研究提出了非线性磁电埃德尔斯坦效应，该效应源于磁场和电场的相互作用，并能在时间反演对称但缺乏反演对称性的材料（包括绝缘体）中产生自旋磁化。此外，该效应的非本征部分可用于检测反铁磁材料中的涅尔矢量翻转。

Abstract: The linear Edelstein effect is a cornerstone phenomenon in spintronics that
describes the generation of spin magnetization in response to an applied
electric field. Recent theoretical advances have reignited interest in its
nonlinear counterpart, the nonlinear Edelstein effect, in which spin
magnetization is induced by a second-order electric field. However, the
intrinsic contribution to both effects is generally forbidden in systems
preserving time-reversal symmetry ($\mathcal{T}$) or composite symmetries such
as $\mathcal{T}\tau_{1/2}$, where $\tau_{1/2}$ denotes a half-lattice
translation. In such systems, spin magnetization typically emerges either from
extrinsic mechanisms but limited to metals due to their Fermi-surface property,
or from dynamical electric fields with a terahertz driving frequency. Here, we
propose a new mechanism for spin magnetization, arising from the interplay of
magnetic and electric fields, termed the nonlinear magnetoelectric Edelstein
effect. Remarkably, its intrinsic component, determined purely by the
material's band structure, can appear even in $\mathcal{T}$-invariant
materials, but lacking inversion symmetry ($\mathcal{P}$), including
insulators. On the other hand, we illustrate that its extrinsic component can
serve as a sensitive indicator of the N\'eel vector reversal in
$\mathcal{P}\mathcal{T}$-symmetric antiferromagnetic materials, offering a
novel route for antiferromagnetic order detection. To validate our theory, we
perform explicit calculations using a two-band Dirac model and a tight-binding
model on a honeycomb lattice, finding that both effects yield sizable spin
magnetization. Our findings establish the nonlinear magnetoelectric Edelstein
effect as a versatile platform for both exploring nonlinear spin physics and
enabling symmetry-based detection of antiferromagnetic order.

</details>


### [272] [Floquet Non-Bloch Formalism for a Non-Hermitian Ladder: From Theoretical Framework to Topolectrical Circuits](https://arxiv.org/abs/2507.23744)
*Koustav Roy,Dipendu Halder,Koustabh Gogoi,B. Tanatar,Saurabh Basu*

Main category: cond-mat.mes-hall

TL;DR: 本研究提出了一个用于研究非厄米驱动系统的广义Floquet非Bloch框架，并设计了一个拓扑电路实验，以在实验室中实现这些现象。


<details>
  <summary>Details</summary>
Motivation: 旨在解决静态非厄米系统中已得到充分研究的体边对应问题，但在驱动场景下仍然难以捉摸，为非厄米驱动系统提供理论框架。

Method: 利用高频Magnus展开，解析推导了有效Floquet哈密顿量，并为周期性驱动的准一维系统（Creutz梯子与交错复势）构建了广义布里渊区。通过对称时间框架方法生成了手性伴侣哈密顿量，其不变量组合起来可以解释完整的边缘态结构。

Result: 证明了在没有非互易跳变的情况下，皮肤效应在广泛的驱动参数范围内保持鲁棒性，并在低频区域由于新兴的长程耦合而显著增强。提出的拓扑电路设计忠实地再现了皮肤模式和不同的Floquet边缘态。

Conclusion: 该研究提出了一个广义的Floquet非Bloch框架，用于解析地捕捉时间周期性非厄米系统的谱和拓扑性质，并提出了一个可行的拓扑电路实验设计，以在实验室中实现这些现象。

Abstract: Periodically driven systems intertwined with non-Hermiticity opens a rich
arena for topological phases that transcend conventional Hermitian limits. The
physical significance of these phases hinges on obtaining the topological
invariants that restore the bulk-boundary correspondence, a task well explored
for static non-Hermitian (NH) systems, while it remains elusive for the driven
scenario. Here, we address this problem by constructing a generalized Floquet
non-Bloch framework that analytically captures the spectral and topological
properties of time-periodic NH systems. Em- ploying a high-frequency Magnus
expansion, we analytically derive an effective Floquet Hamiltonian and
formulate the generalized Brillouin zone for a periodically driven
quasi-one-dimensional system, namely, the Creutz ladder with a staggered
complex potential. Our study demonstrates that the skin effect remains robust
(despite the absence of non-reciprocal hopping) across a broad range of driving
parameters, and is notably amplified in the low-frequency regime due to
emergent longer- range couplings. We further employ a symmetric time frame
approach that generates chiral-partner Hamiltonians, whose invariants, when
appropriately combined, account for the full edge-state struc- ture. To
substantiate the theoretical framework, we propose a topolectrical circuit
(TEC) that serves as a viable experimental setting. Apart from capturing the
skin modes, the proposed TEC design faithfully reproduces the presence of
distinct Floquet edge states, as revealed through the voltage and impedance
profiles, respectively. Thus, our work not only offers a theoretical framework
for exploring NH-driven systems, but also provides an experimentally feasible
TEC architecture for realizing these phenomena stated above in a laboratory.

</details>


### [273] [Spintronic temperature nanosensor based on the resonance response of a skyrmion-hosting magnetic tunnel junction](https://arxiv.org/abs/2507.23430)
*Michail Lianeris,Davi Rodrigues,Andrea Meo,Dimitris Kechrakos,Anna Giordano,Mario Carpentieri,Giovanni Finocchio,Riccardo Tomasello*

Main category: cond-mat.mes-hall

TL;DR: 斯格明子可用于制造高灵敏度、线性响应的纳米级温度传感器，克服了传统传感器的缺点，并在多个领域具有应用潜力。


<details>
  <summary>Details</summary>
Motivation: 传统传感器在响应的非线性、低灵敏度和复杂的校准方面存在不足，而提高纳米电子学中热管理的效率需要创新的热传感解决方案。

Method: 提出并预测了利用现有基于斯格明子的自旋电子二极管的响应温度依赖性，并提出将其用作纳米级热传感器。

Result: 基于斯格明子的二极管在宽温度范围内表现出高热灵敏度和线性响应，这种线性响应在幅度与斯格明子激励频率中均有体现，确保了精确可靠的温度测量具有冗余性。使用多层系统可进一步提高器件的灵敏度和鲁棒性。

Conclusion: 该研究为基于斯格明子的热电器件奠定了基础，在自旋电子传感器、热管理、纳电子学和斯格明子热电子学等领域具有应用前景。

Abstract: The increasing need for efficient thermal management in nanoelectronics
requires innovative thermal sensing solutions, as conventional sensors often
exhibit nonlinear responses, low sensitivity, and complex calibration. We
predict a temperature dependence in the response of existing skyrmion based
spintronic diodes and propose their use as nanoscale thermal sensors. These
devices leverage magnetic skyrmions topologically protected spin textures known
for their robustness, nanoscale dimensions, and low power dynamics. We
demonstrate high thermal sensitivity with a linear temperature response over a
wide range. This linearity, observed in both the amplitude and frequency of the
skyrmion excitation, ensures redundancy that enables precise and reliable
temperature measurement. In addition, the use of multilayer systems enhances
the sensitivity and robustness of the device. These results provide a
foundation for skyrmion-based caloritronic devices with promising applications
in spintronic sensors, thermal management, nanoelectronics, and
skyrmion-caloritronics.

</details>


### [274] [Magnetically Programmable Surface Acoustic Wave Filters: Device Concept and Predictive Modeling](https://arxiv.org/abs/2507.23456)
*Michael K. Steinbauer,Peter Flauger,Matthias Küß,Stephan Glamsch,Emeline D. S. Nysten,Matthias Weiß,Dieter Suess,Hubert J. Krenner,Manfred Albrecht,Claas Abert*

Main category: cond-mat.mes-hall

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Filtering surface acoustic wave (SAW) signals of specified frequencies
depending on the strength of an external magnetic field in a magnetostrictive
material has garnered significant interest due to its potential scientific and
industrial applications. Here, we propose a device that achieves selective SAW
attenuation by instead programming its internal magnetic state. To this end, we
perform micromagnetic simulations for the magnetoelastic interaction of the
Rayleigh SAW mode with spin waves (SWs) in exchange-decoupled Co/Ni islets on a
piezoelectric LiTaO$_3$ substrate. Due to the islets exhibiting perpendicular
magnetic anisotropy, the stray-field interaction between them leads to a shift
in the SW dispersion depending on the magnetic alignment of neighboring islets.
This significantly changes the efficiency of the magnetoelastic interaction at
specified frequencies. We predict changes in SAW transmission of 28.9 dB/mm at
3.8 GHz depending on the state of the device. For the efficient simulation of
the device, we extend a prior energy conservation argument based on analytical
solutions of the SW to finite-difference numerical calculations, enabling the
modeling of arbitrary magnetization patterns like the proposed islet-based
design.

</details>


### [275] [Theory of ultrafast conductance modulation in electrochemical protonic synapses by multiphase polarization](https://arxiv.org/abs/2507.23576)
*Michael L. Li,Dingyu Shen,Jesus A. del Alamo,Martin Z. Bazant*

Main category: cond-mat.mes-hall

TL;DR: 本研究为EIoS的导电性调制提供了理论基础，证明了相分离系统能克服扩散限制，实现高速率、线性、对称的导电性调制。


<details>
  <summary>Details</summary>
Motivation: 理解EIoS器件导电性调制的内在机制，以克服扩散时间尺度限制，提高器件性能。

Method: 通过理论解释和对比分析WO3通道的结晶度来研究EIoS的导电性调制现象。

Result: 证明了相分离系统有潜力克服限制EIoS性能的传统扩散势垒，实现了纳秒时间尺度的线性、对称导电性调制。

Conclusion: 本研究提供了一个理论解释，说明线性、对称的电化学离子突触（EIoS）的导电性调制如何源于电解质-WO3界面的持续控制。研究发现，WO3通道结晶度的变化会影响器件的材料热力学。实现纳秒时间尺度的器件经历了相分离，这使得器件能够克服传统EIoS性能的扩散限制。

Abstract: Three-terminal electrochemical ionic synapses (EIoS) have recently attracted
interest for in-memory computing applications. These devices utilize
electrochemical ion intercalation to modulate the ion concentration in the
channel material. The electrical conductance, which is concentration dependent,
can be read separately and mapped to a non-volatile memory state. To compete
with other random access memory technologies, linear and symmetric conductance
modulation is often sought after, properties typically thought to be limited by
the slow ion diffusion timescale. A recent study by Onen et al.[1] examining
protonic EIoS with a tungsten oxide (WO3) channel revealed that this limiting
timescale seemed irrelevant, and linear conductance modulation was achieved
over nanosecond timescales, much faster than the bulk ion diffusion. This
contrasts with previous studies that have shown similar conductance modulation
with pulse timescales of milliseconds to seconds. Understanding the phenomena
behind these conductance modulation properties in EIoS systems remains a
crucial question gating technological improvements to these devices. Here, we
provide a theoretical explanation that demonstrates how linearity and symmetry
arise from consistent control over the electrolyte-WO3 interface. Comparing
these past works, changes in the WO3 channel crystallinity were identified,
affecting material thermodynamics and revealing that the device achieving
nanosecond pulse timescales underwent phase separation. Coupling of electric
field polarizatino and increased electron conductivity in high-concentration
filaments, the reaction environment at the gate electrode can be controlled,
resulting in ideal conductance modulation within the diffusion-limited regime.
This work highlights the potential for phase-separating systems to overcome the
traditional diffusion barriers that limit EIoS performance.

</details>


### [276] [Milli-Tesla Quantization enabled by Tuneable Coulomb Screening in Large-Angle Twisted Graphene](https://arxiv.org/abs/2507.23626)
*I. Babich,I. Reznikov,I. Begichev,A. E. Kazantsev,S. Slizovskiy,D. Baranov,M. Siskins,Z. Zhan,P. A. Pantaleon,M. Trushin,J. Zhao,S. Grebenchuk,K. S. Novoselov,K. Watanabe,T. Taniguchi,V. I. Falko,A. Principi,A. I. Berdyugin*

Main category: cond-mat.mes-hall

TL;DR: 本研究通过石墨烯封装解决了电荷不均匀性问题，显著提升了石墨烯器件质量，在低磁场下即可观察到朗道量子化。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有器件中由封装层带电缺陷引起的空间电荷波动问题，本研究提出了一种新的石墨烯封装方法，以提升器件性能。

Method: 本研究采用石墨烯封装策略，利用大角度扭曲（~10-30度）的石墨烯层对器件进行电子解耦封装，并通过掺杂封装层引入库仑筛选效应，以减少石墨烯层中的电荷不均匀性。

Result: 研究结果表明，该封装方法能将石墨烯层中的电荷不均匀性降低至每平方微米仅几个载流子，使得器件在低至约5毫特斯拉的磁场下就能观察到朗道量子化，并能分辨出狄拉克点附近的一个小能量隙。

Conclusion: 该研究通过石墨烯封装策略，有效减少了器件中的空间电荷波动，提升了石墨烯的电子质量，为研究超纯器件的电子性质提供了新的途径。

Abstract: The electronic quality of graphene has improved significantly over the past
two decades, revealing novel phenomena. However, even state-of-the-art devices
exhibit substantial spatial charge fluctuations originating from charged
defects inside the encapsulating crystals, limiting their performance. Here, we
overcome this issue by assembling devices in which graphene is encapsulated by
other graphene layers while remaining electronically decoupled from them via a
large twist angle (~10-30{\deg}). Doping of the encapsulating graphene layer
introduces strong Coulomb screening, maximized by the sub-nanometer distance
between the layers, and reduces the inhomogeneity in the adjacent layer to just
a few carriers per square micrometre. The enhanced quality manifests in Landau
quantization emerging at magnetic fields as low as ~5 milli-Tesla and enables
resolution of a small energy gap at the Dirac point. Our encapsulation approach
can be extended to other two-dimensional systems, enabling further exploration
of the electronic properties of ultrapure devices.

</details>


### [277] [Current-induced spin-orbit torque on the surface of a transition metal dichalcogenide connected to a two-dimensional ferromagnet CrI$_3$: Effects of twisting and gating](https://arxiv.org/abs/2507.23655)
*Leyla Majidi,Azadeh Faridi,Reza Asgari*

Main category: cond-mat.mes-hall

TL;DR: 本研究利用稳态玻尔兹曼方程，在 TMDC/CrI$_3$ 双层结构中研究了电流诱导的自旋极化和 SOT。结果表明，场滞型扭矩和阻尼型扭矩对掺杂、扭转角和栅极电场敏感，其中 n 型掺杂的 MoSe$_2$ 可显著增强阻尼型扭矩，扭转角和栅极电场也能有效调控 SOT 的大小和符号。


<details>
  <summary>Details</summary>
Motivation: 近期二维材料（拓扑绝缘体和 TMDCs）在作为生成 SOT 的自旋源方面取得了进展，促使我们研究 TMDC/CrI$_3$ 双层结构中的 SOT。

Method: 利用稳态玻尔兹曼方程研究了 TMDC（WSe$_2$ 或 MoSe$_2$）和磁性 CrI$_3$ 双层结构中电流诱导的自旋极化和由此产生的 SOT。

Result: 研究发现了场滞型扭矩和阻尼型扭矩的存在，并量化了它们的大小和对掺杂、扭转角和栅极电场的依赖性。其中，n 型掺杂的 MoSe$_2$ 显著增强了阻尼型扭矩，使其强度可与场滞型扭矩相媲美。扭转角和横向栅极电场也对 SOT 表现出显著的调制作用，甚至可以反转 SOT 的符号。totalSupply generated a too long; didn't read summary: 本研究利用稳态玻尔兹曼方程，在 TMDC/CrI$_3$ 双层结构中研究了电流诱导的自旋极化和 SOT。结果表明，场滞型扭矩和阻尼型扭矩对掺杂、扭转角和栅极电场敏感，其中 n 型掺杂的 MoSe$_2$ 可显著增强阻尼型扭矩，扭转角和栅极电场也能有效调控 SOT 的大小和符号。

Conclusion: 研究表明，TMDC/CrI$_3$ 双层结构中的 SOT 对掺杂类型、扭转角和栅极电场具有高度可调性。特别是，n 型掺杂的 MoSe$_2$ 能够将阻尼型扭矩增强高达三个数量级，其强度与场滞型扭矩相当。

Abstract: Motivated by recent progress in employing two key classes of two-dimensional
materials-topological insulators and transition-metal dichalcogenides
(TMDCs)-as spin sources for generating spin-orbit torque (SOT), we investigate
current-induced spin polarization and the resulting SOT in bilayers composed of
a TMDC (WSe$_2$ or MoSe$_2$) and ferromagnetic chromium iodide (CrI$_3$),
beyond the linear response regime. Using the steady-state Boltzmann equation,
we find that intra-band transitions yield a strong field-like torque on the
CrI$_3$ layer, while inter-band transitions give rise to a comparatively weaker
damping-like torque in the WSe$_2$/CrI$_3$ system. Remarkably, the damping-like
component is enhanced by up to three orders of magnitude in n-doped MoSe$_2$,
reaching a strength comparable to the field-like torque, which itself is an
order of magnitude larger than that in the WSe$_2$-based bilayer. Both torque
components exhibit strong asymmetry between n-type and p-type doping in WSe$_2$
and MoSe$_2$ systems. Furthermore, we demonstrate that the twist angle plays a
crucial role: depending on the TMDC and chemical potential, twisting can
reverse the sign of the SOT and significantly modulate its magnitude. Finally,
we show that a transverse gate electric field enables substantial tunability of
the SOT, by nearly one order of magnitude, and induces a sign reversal at a
twist angle of $10.16^{\circ}$.

</details>


### [278] [Particle localization on helical nanoribbons: Quantum analog of the Coriolis effect](https://arxiv.org/abs/2507.23745)
*Radha Balakrishnan,Rossen Dandoloff,Victor Atanasov,Avadh Saxena*

Main category: cond-mat.mes-hall

TL;DR: Quantum effects analogous to Coriolis and Hall effects observed in helical nanoribbons due to their geometry, with potential for nanoscale device applications.


<details>
  <summary>Details</summary>
Motivation: To investigate the quantum mechanical behavior of particles confined to the curved surfaces of helical nanoribbons and explore potential physical phenomena and applications arising from these geometries.

Method: Derivation of the Schr"odinger equation for a particle confined to the surface of normal and binormal helical nanoribbons, analysis of quantum potentials and localized states, and application of Ehrenfest's theorem.

Result: Particles localize differently on normal (inner edge) and binormal (central helix) ribbons due to a pseudo-force. This effect is analogous to the Coriolis effect. Quantized angular velocities were identified. Electron localization leads to a Hall-like voltage without an external magnetic field. Periodic flipping of a normal ribbon to a binormal configuration induces a quantum AC voltage, enabling potential electromechanical device applications.

Conclusion: Helical nanoribbons with specific geometric configurations can induce quantum effects analogous to the Coriolis effect and Hall effect, leading to potential applications in nanoscale electromechanical devices and nanotechnology.

Abstract: We derive the Schr\"odinger equation for a particle confined to the surface
of a normal and a binormal helical nanoribbon, obtain the quantum potentials
induced by their respective curved surface geometries, and study the localized
states of the particle for each ribbon. When the particle momentum satisfies a
certain geometric condition, the particle localizes near the inner edge for a
normal ribbon, and on the central helix for a binormal ribbon. This result
suggests the presence of a pseudo-force that pushes the particle transversely
along the width of the ribbon. We show that this phenomenon can be interpreted
as a quantum analog of the Coriolis effect, which causes a transverse
deflection of a classical particle moving in a rotating frame. We invoke
Ehrenfest's theorem applicable to localized states and identify the quantized
angular velocities of the rotating frames for the two ribbons. If the particle
is an electron, its localization at a specific width gives rise to a Hall-like
voltage difference across the ribbon's width. However, unlike in the Hall
effect, its origin is not an applied magnetic field, but the ribbon's curved
surface geometry. When a normal helical ribbon is mechanically flipped to a
binormal configuration in a periodic fashion, it results in a periodic electron
transport from the inner edge to the center, giving rise to a quantum AC
voltage. This can be used for designing nanoscale electromechanical devices.
Quantum transport on a helical nanoribbon can be controlled by tuning the bends
and twists of its surface, suggesting diverse applications in biopolymers and
nanotechnology.

</details>


### [279] [Projected branes as platforms for crystalline, superconducting, and higher-order topological phases](https://arxiv.org/abs/2507.23783)
*Archisman Panigrahi,Bitan Roy*

Main category: cond-mat.mes-hall

TL;DR: 本研究展示了一维投影晶格如何保留高维拓扑绝缘体和超导体的特性，包括零能模式和拓扑标记。


<details>
  <summary>Details</summary>
Motivation: 旨在研究高维晶格的投影晶格（projected branes）如何保留高维拓扑相的特性，特别关注其在作为一维准晶或晶体时表现出的鲁棒性端点零能模式、量化拓扑标记和边界模式。

Method: 通过系统地积分掉父晶格中位于超平面之外的位点来构建有效哈密顿量。

Result: 一维投影晶格能够编码拓扑晶体绝缘体和拓扑超导体的关键特征，包括零能模式、量化拓扑标记和与位错相关的边界模式。此外，还展示了如何构建具有角定域零模式的二阶拓扑绝缘体。

Conclusion: 论文展示了如何从高维晶格构建一维投影晶格，并证明了这些一维晶格能够保留高维晶格的拓扑特性，例如在端点和晶格缺陷处出现零能模式。

Abstract: Projected branes are constituted by only a small subset of sites of a
higher-dimensional crystal, otherwise placed on a hyperplane oriented at an
irrational or a rational slope therein, for which the effective Hamiltonian is
constructed by systematically integrating out the sites of the parent lattice
that fall outside such branes [Commun. Phys. 5, 230 (2022)]. Specifically, when
such a brane is constructed from a square lattice, it gives rise to an
aperiodic Fibonacci quasi-crystal or its rational approximant in one dimension.
In this work, starting from square lattice-based models for topological
crystalline insulators, protected by the discrete four-fold rotational ($C_4$)
symmetry, we show that the resulting one-dimensional projected topological
branes encode all the salient signatures of such phases in terms of robust
endpoint zero-energy modes, quantized local topological markers, and mid-gap
modes bound to dislocation lattice defects, despite such linear branes being
devoid of the $C_4$ symmetry of the original lattice. Furthermore, we show that
such branes can also feature all the hallmarks of two-dimensional strong and
weak topological superconductors through Majorana zero-energy bound states
residing near their endpoints and at the core of dislocation lattice defects,
besides possessing suitable quantized local topological markers. Finally, we
showcase a successful incarnation of a square lattice-based second-order
topological insulator with the characteristic corner-localized zero modes in
its geometric descendant one-dimensional quasi-crystalline or crystalline
branes that feature a quantized localizer index and endpoint zero-energy modes
only when one of its end points passes through a corner of the parent crystal.
Possible designer quantum and meta material-based platforms to experimentally
harness our theoretically proposed topological branes are discussed.

</details>


### [280] [The persistence of spin coherence in a crystalline environment](https://arxiv.org/abs/2406.02703)
*Gerald Curran III,Zachary Rex,Casper X. Wilson,Luke J. Weaver,Ivan Biaggio*

Main category: cond-mat.mes-hall

TL;DR: Quantum interference in triplet-exciton pairs generated by singlet exciton fission in molecular crystals can be suppressed by transport-induced dephasing (TID), which depends on exciton hopping rates and energy shifts. Experiments in rubrene single crystals confirm this, showing suppressed quantum beats within nanoseconds due to TID. The study also determines molecular parameters and an exciton hopping rate of approximately 150 ps.


<details>
  <summary>Details</summary>
Motivation: Analyze quantum interference in the triplet-exciton pair generated by singlet exciton fission in a molecular crystal.

Method: We analyze quantum interference in the triplet-exciton pair generated by singlet exciton fission in a molecular crystal, and introduce transport-induced dephasing (TID) as a key effect that can suppress the expected fluorescence quantum beats when the triplet-exciton wavefunction can localize on inequivalent sites. TID depends on the triplet-exciton hopping rate between inequivalent sites and on the energy-shifts among the stationary states of the entangled triplet pair in different spatial configurations.

Result: Quantum beats are suppressed by TID within a few nanoseconds when the magnetic field is misaligned by just a few degrees from specific symmetric directions. The triplet-exciton hopping rate between inequivalent sites is evaluated to be of the order of 150 ps in rubrene.

Conclusion: The theoretical model is confirmed by experiments in rubrene single crystals, where triplet pairs remain entangled for more than 50 ns but quantum beats are suppressed by TID within a few nanoseconds when the magnetic field is misaligned by just a few degrees from specific symmetric directions. Our experiments deliver the zero-field parameters for the rubrene molecule in its orthorhombic lattice and information on triplet-exciton transport, in particular the triplet-exciton hopping rate between inequivalent sites, which we evaluate to be of the order of 150 ps in rubrene.

Abstract: We analyze quantum interference in the triplet-exciton pair generated by
singlet exciton fission in a molecular crystal, and introduce transport-induced
dephasing (TID) as a key effect that can suppress the expected fluorescence
quantum beats when the triplet-exciton wavefunction can localize on
inequivalent sites. TID depends on the triplet-exciton hopping rate between
inequivalent sites and on the energy-shifts among the stationary states of the
entangled triplet pair in different spatial configurations. The theoretical
model is confirmed by experiments in rubrene single crystals, where triplet
pairs remain entangled for more than 50 ns but quantum beats are suppressed by
TID within a few nanoseconds when the magnetic field is misaligned by just a
few degrees from specific symmetric directions. Our experiments deliver the
zero-field parameters for the rubrene molecule in its orthorhombic lattice and
information on triplet-exciton transport, in particular the triplet-exciton
hopping rate between inequivalent sites, which we evaluate to be of the order
of 150 ps in rubrene.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [281] [Explanations for Unrealizability of Infinite-State Safety Shields](https://arxiv.org/abs/2507.23603)
*Andoni Rodriguez,Irfansha Shaik,Davide Corsi,Roy Fox,Cesar Sanchez*

Main category: cs.LO

TL;DR: We present a method to obtain simple unconditional and conditional explanations that witness unrealizability, which goes by temporal formula unrolling.


<details>
  <summary>Details</summary>
Motivation: Safe Reinforcement Learning focuses on developing optimal policies while ensuring safety. A popular method to address such task is shielding, in which a correct-by-construction safety component is synthesized from logical specifications. Recently, shield synthesis has been extended to infinite-state domains, such as continuous environments. This makes shielding more applicable to realistic scenarios. However, often shields might be unrealizable because the specification is inconsistent (e.g., contradictory).

Method: temporal formula unrolling

Result: We show different variants of the technique and its applicability.

Conclusion:  shields might be unrealizable because the specification is inconsistent (e.g., contradictory). In order to address this gap, we present a method to obtain simple unconditional and conditional explanations that witness unrealizability, which goes by temporal formula unrolling.

Abstract: Safe Reinforcement Learning focuses on developing optimal policies while
ensuring safety. A popular method to address such task is shielding, in which a
correct-by-construction safety component is synthesized from logical
specifications. Recently, shield synthesis has been extended to infinite-state
domains, such as continuous environments. This makes shielding more applicable
to realistic scenarios. However, often shields might be unrealizable because
the specification is inconsistent (e.g., contradictory). In order to address
this gap, we present a method to obtain simple unconditional and conditional
explanations that witness unrealizability, which goes by temporal formula
unrolling. In this paper, we show different variants of the technique and its
applicability.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [282] [KLLM: Fast LLM Inference with K-Means Quantization](https://arxiv.org/abs/2507.23035)
*Xueying Wu,Baijun Zhou,Zhihui Gao,Yuzhe Fu,Qilin Zheng,Yintao He,Hai Li*

Main category: cs.LG

TL;DR: KLLM是一种针对LLM推理的硬件软件协同设计框架，通过优化的K-Means量化和离群点检测技术，显著提高了推理速度和能效。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）推理方法在内存和计算方面存在显著挑战。权重和激活量化（WAQ）是一种有前景的解决方案，但传统方法在低精度下会严重降低模型精度，并且难以在硬件上高效执行。此外，激活离群点问题进一步阻碍了低精度WAQ的有效性。本研究旨在解决这些问题，充分发挥K-Means量化在LLM推理中的潜力。

Method: KLLM框架提出了一种基于索引的计算方案，用于高效执行K-Means量化数据的矩阵乘法和非线性运算，从而避免了大部分反量化和全精度计算。此外，KLLM还引入了一个名为Orizuru的新颖离群点检测引擎，能够在在线推理过程中高效识别激活数据流中的最大和最小元素。

Result: 与A100 GPU和Atom相比，KLLM分别实现了平均9.67倍和7.03倍的加速，以及229.50倍和150.21倍的能效提升。

Conclusion: KLLM通过硬件软件协同设计，解决了现有量化技术在处理大型语言模型（LLM）时存在的精度下降和运行开销大的问题，实现了显著的加速和能效提升。

Abstract: Large language model (LLM) inference poses significant challenges due to its
intensive memory and computation demands. Weight and activation quantization
(WAQ) offers a promising solution by reducing both memory footprint and
arithmetic complexity. However, two key challenges remain in the existing WAQ
designs. (1) Traditional WAQ designs rely on uniform integer-based quantization
for hardware efficiency, but this often results in significant accuracy
degradation at low precision. K-Means-based quantization, a non-uniform
quantization technique, achieves higher accuracy by matching the Gaussian-like
distributions of weights and activations in LLMs. However, its non-uniform
nature prevents direct execution on low-precision compute units, requiring
dequantization and floating-point matrix multiplications (MatMuls) during
inference. (2) Activation outliers further hinder effective low-precision WAQ.
Offline thresholding methods for outlier detection can lead to significant
model performance degradation, while existing online detection techniques
introduce substantial runtime overhead.
  To address the aforementioned challenges and fully unleash the potential of
WAQ with K-Means quantization for LLM inference, in this paper, we propose
KLLM, a hardware-software co-design framework. KLLM features an index-based
computation scheme for efficient execution of MatMuls and nonlinear operations
on K-Means-quantized data, which avoids most of the dequantization and
full-precision computations. Moreover, KLLM incorporates a novel outlier
detection engine, Orizuru, that efficiently identifies the top-$k$ largest and
smallest elements in the activation data stream during online inference.
  Extensive experiments show that, on average, KLLM achieves speedups of 9.67x,
7.03x and energy efficiency improvements of 229.50x, 150.21x compared to the
A100 GPU and Atom, respectively.

</details>


### [283] [Neural Autoregressive Modeling of Brain Aging](https://arxiv.org/abs/2507.22954)
*Ridvan Yesiloglu,Wei Peng,Md Tauhidul Islam,Ehsan Adeli*

Main category: cs.LG

TL;DR: NeuroAR是一种基于生成式自回归Transformer的新型大脑衰老模拟模型，通过自回归地估计未来扫描的离散标记图来合成衰老的大脑，并成功地以高保真度模拟了大脑衰老轨迹，在图像保真度方面优于LDM和GAN等模型。


<details>
  <summary>Details</summary>
Motivation: 大脑衰老合成是一个关键任务，具有广泛的临床和计算神经科学应用。从早期MRI扫描预测受试者大脑的未来结构演变的能力，为了解衰老轨迹提供了宝贵的见解。然而，数据的高维性、跨年龄结构变化的细微差别以及受试者特定的模式，给大脑衰老合成带来了挑战。

Method: 提出了一种名为NeuroAR的新颖的大脑衰老模拟模型，该模型基于生成式自回归Transformer。NeuroAR通过自回归地估计未来扫描的离散标记图来合成衰老的大脑。它将先前扫描和未来扫描的标记嵌入连接起来，并在每个尺度上连接受试者的先前扫描，并通过交叉注意力机制在每个块中利用其获取年龄和目标年龄，以指导生成。

Result: 在老年和青少年受试者上对NeuroAR进行了评估，结果表明其在图像保真度方面优于包括潜在扩散模型（LDM）和生成对抗网络（GAN）在内的现有最先进生成模型。此外，使用预训练的年龄预测器进一步验证了合成图像在预期的衰老模式方面的一致性和真实性。NeuroAR在关键模型（包括LDM）上的表现显著优于它们，证明了其以高保真度模拟个体化大脑衰老轨迹的能力。

Conclusion: NeuroAR在模拟大脑衰老方面表现出色，能够高保真地模拟个体化的大脑衰老轨迹，并在图像保真度方面优于包括潜在扩散模型（LDM）和生成对抗网络（GAN）在内的现有最先进模型。

Abstract: Brain aging synthesis is a critical task with broad applications in clinical
and computational neuroscience. The ability to predict the future structural
evolution of a subject's brain from an earlier MRI scan provides valuable
insights into aging trajectories. Yet, the high-dimensionality of data, subtle
changes of structure across ages, and subject-specific patterns constitute
challenges in the synthesis of the aging brain. To overcome these challenges,
we propose NeuroAR, a novel brain aging simulation model based on generative
autoregressive transformers. NeuroAR synthesizes the aging brain by
autoregressively estimating the discrete token maps of a future scan from a
convenient space of concatenated token embeddings of a previous and future
scan. To guide the generation, it concatenates into each scale the subject's
previous scan, and uses its acquisition age and the target age at each block
via cross-attention. We evaluate our approach on both the elderly population
and adolescent subjects, demonstrating superior performance over
state-of-the-art generative models, including latent diffusion models (LDM) and
generative adversarial networks, in terms of image fidelity. Furthermore, we
employ a pre-trained age predictor to further validate the consistency and
realism of the synthesized images with respect to expected aging patterns.
NeuroAR significantly outperforms key models, including LDM, demonstrating its
ability to model subject-specific brain aging trajectories with high fidelity.

</details>


### [284] [Hardware-Aware Fine-Tuning of Spiking Q-Networks on the SpiNNaker2 Neuromorphic Platform](https://arxiv.org/abs/2507.23562)
*Sirine Arfa,Bernhard Vogginger,Christian Mayr*

Main category: cs.LG

TL;DR: 这项工作提出了一种使用量化SNN和Q学习算法的节能强化学习实现，该算法可在SpiNNaker2神经形态芯片上解决控制任务，与GPU相比，能耗显著降低，延迟相当。


<details>
  <summary>Details</summary>
Motivation: 旨在探索脉冲神经网络（SNN）在解决机器人任务方面的低功耗和低延迟潜力，并将其应用于嵌入式部署。

Method: 使用量化脉冲神经网络（SNN）和Q学习算法来解决控制任务，并在SpiNNaker2神经形态芯片上进行微调和量化。

Result: 与GTX 1650 GPU相比，SpiNNaker2在能耗方面实现了高达32倍的降低，并且在某些任务设置中观察到了推理延迟的改善。

Conclusion: SpiNNaker2在低能耗和低延迟方面具有巨大潜力，可用于实时神经形态控制，并使神经形态方法成为高效深度Q学习的有吸引力的方向。

Abstract: Spiking Neural Networks (SNNs) promise orders-of-magnitude lower power
consumption and low-latency inference on neuromorphic hardware for a wide range
of robotic tasks. In this work, we present an energy-efficient implementation
of a reinforcement learning (RL) algorithm using quantized SNNs to solve two
classical control tasks. The network is trained using the Q-learning algorithm,
then fine-tuned and quantized to low-bit (8-bit) precision for embedded
deployment on the SpiNNaker2 neuromorphic chip. To evaluate the comparative
advantage of SpiNNaker2 over conventional computing platforms, we analyze
inference latency, dynamic power consumption, and energy cost per inference for
our SNN models, comparing performance against a GTX 1650 GPU baseline. Our
results demonstrate SpiNNaker2's strong potential for scalable, low-energy
neuromorphic computing, achieving up to 32x reduction in energy consumption.
Inference latency remains on par with GPU-based execution, with improvements
observed in certain task settings, reinforcing SpiNNaker2's viability for
real-time neuromorphic control and making the neuromorphic approach a
compelling direction for efficient deep Q-learning.

</details>


### [285] [LLM-Assisted Cheating Detection in Korean Language via Keystrokes](https://arxiv.org/abs/2507.22956)
*Dong Hyun Roh,Rajesh Kumar,An Ngo*

Main category: cs.LG

TL;DR: 该研究提出了一种基于击键动力学的新方法来检测韩语中的 AI 辅助作弊，该方法考虑了认知过程和 LLM 参与的细微差别。模型在检测抄写响应方面优于人类，并且在不同认知负荷下均表现出可靠的检测能力。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在弥补现有研究在语言覆盖、认知背景和 LLM 参与粒度方面存在的不足，提出了一种用于检测韩语中 LLM 辅助作弊的基于击键的框架。

Method: 提出了一种基于击键的框架，并构建了一个包含 69 名参与者在三种条件（真实写作、释义 ChatGPT 响应、抄写 ChatGPT 响应）下完成写作任务的数据集。提取了解和可解释的时间和节奏特征，并在认知感知和认知无关的设置下评估了多种分类器。

Result: 时间特征在认知感知评估场景中表现良好，而节奏特征在跨认知场景中具有更好的泛化性。此外，模型在检测真实和抄写响应方面比释义响应更容易，并且模型在这方面的表现明显优于人类。

Conclusion: 本文的研究结果表明，击键动力学能够可靠地检测不同认知需求和写作策略（包括释义和抄写）下的 AI 辅助写作，并且模型在检测抄写响应方面明显优于人类评估者。

Abstract: This paper presents a keystroke-based framework for detecting LLM-assisted
cheating in Korean, addressing key gaps in prior research regarding language
coverage, cognitive context, and the granularity of LLM involvement. Our
proposed dataset includes 69 participants who completed writing tasks under
three conditions: Bona fide writing, paraphrasing ChatGPT responses, and
transcribing ChatGPT responses. Each task spans six cognitive processes defined
in Bloom's Taxonomy (remember, understand, apply, analyze, evaluate, and
create). We extract interpretable temporal and rhythmic features and evaluate
multiple classifiers under both Cognition-Aware and Cognition-Unaware settings.
Temporal features perform well under Cognition-Aware evaluation scenarios,
while rhythmic features generalize better under cross-cognition scenarios.
Moreover, detecting bona fide and transcribed responses was easier than
paraphrased ones for both the proposed models and human evaluators, with the
models significantly outperforming the humans. Our findings affirm that
keystroke dynamics facilitate reliable detection of LLM-assisted writing across
varying cognitive demands and writing strategies, including paraphrasing and
transcribing LLM-generated responses.

</details>


### [286] [Scientific Machine Learning with Kolmogorov-Arnold Networks](https://arxiv.org/abs/2507.22959)
*Salah A. Faroughi,Farinaz Mostajeran,Amin Hamed Mashhadzadeh,Shirko Faroughi*

Main category: cs.LG

TL;DR: 本综述介绍了科学机器学习领域中KANs相对于MLPs的优势，包括更好的可解释性、灵活性和学习效果，并讨论了KANs在数据学习、物理信息建模和算子学习中的应用。尽管KANs在多个方面优于MLPs，但在计算效率和理论保证等方面仍需改进，未来的研究将集中于提高其鲁棒性、可扩展性和物理一致性。


<details>
  <summary>Details</summary>
Motivation: MLPs存在可解释性差、激活函数固定以及难以捕捉局部或高频特征等局限性。KANs通过增强可解释性和灵活性，能够更有效地模拟复杂的非线性相互作用，克服了传统MLP架构的限制，因此在科学机器学习领域得到日益广泛的应用。

Method: 本篇综述通过对KANs模型在数据驱动学习、物理信息建模和深度算子学习三个方面的最新进展进行分类和审视，并从架构设计、训练策略、应用效果以及与MLP的比较评估等角度进行分析，最终对KANs与MLPs进行了基准测试。

Result: KANs在准确性、收敛性和谱表示方面一致优于MLPs，在捕捉复杂动态和有效学习方面显示出优势。

Conclusion: KANs在准确性、收敛性和谱表示方面一致优于MLPs，在捕捉复杂动态和有效学习方面显示出优势。然而，KANs在计算效率、理论保证、超参数调整和算法复杂性方面仍面临挑战，未来的研究方向包括提高其鲁棒性、可扩展性和物理一致性。

Abstract: The field of scientific machine learning, which originally utilized
multilayer perceptrons (MLPs), is increasingly adopting Kolmogorov-Arnold
Networks (KANs) for data encoding. This shift is driven by the limitations of
MLPs, including poor interpretability, fixed activation functions, and
difficulty capturing localized or high-frequency features. KANs address these
issues with enhanced interpretability and flexibility, enabling more efficient
modeling of complex nonlinear interactions and effectively overcoming the
constraints associated with conventional MLP architectures. This review
categorizes recent progress in KAN-based models across three distinct
perspectives: (i) data-driven learning, (ii) physics-informed modeling, and
(iii) deep operator learning. Each perspective is examined through the lens of
architectural design, training strategies, application efficacy, and
comparative evaluation against MLP-based counterparts. By benchmarking KANs
against MLPs, we highlight consistent improvements in accuracy, convergence,
and spectral representation, clarifying KANs' advantages in capturing complex
dynamics while learning more effectively. Finally, this review identifies
critical challenges and open research questions in KAN development,
particularly regarding computational efficiency, theoretical guarantees,
hyperparameter tuning, and algorithm complexity. We also outline future
research directions aimed at improving the robustness, scalability, and
physical consistency of KAN-based frameworks.

</details>


### [287] [Multi-Hazard Early Warning Systems for Agriculture with Featural-Temporal Explanations](https://arxiv.org/abs/2507.22962)
*Boyuan Zheng,Victor W. Chu*

Main category: cs.LG

TL;DR: 利用深度学习和XAI技术，开发了一个能预测和解释农业多重气候灾害（如极端寒冷、洪水、霜冻、冰雹、热浪和强降雨）的多灾种预警系统，并验证了其在实际数据中的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了应对日益严峻的气候变化对农业造成的风险，需要能够学习近期气候行为的智能多灾种预警系统，而传统单灾种预测方法无法捕捉并发气候事件间的复杂相互作用。

Method: 本研究结合了序列深度学习模型和先进的可解释人工智能（XAI）技术，利用时间注意力机制和时间SHAP（一种用于时间序列的递归XAI解释器）来预测和解释农业面临的多种气候灾害。

Result: 实验结果表明，该框架（特别是BiLSTM架构）具有强大的预测准确性，能够揭示哪些气候特征以及何时产生影响，从而为细致、主动的风险管理策略提供信息。

Conclusion: 该研究显著提高了多灾种预警系统的可解释性和适用性，促进了跨学科的信任和农业气候风险管理中有效决策过程。

Abstract: Climate extremes present escalating risks to agriculture intensifying the
need for reliable multi-hazard early warning systems (EWS). The situation is
evolving due to climate change and hence such systems should have the
intelligent to continue to learn from recent climate behaviours. However,
traditional single-hazard forecasting methods fall short in capturing complex
interactions among concurrent climatic events. To address this deficiency, in
this paper, we combine sequential deep learning models and advanced Explainable
Artificial Intelligence (XAI) techniques to introduce a multi-hazard
forecasting framework for agriculture. In our experiments, we utilize
meteorological data from four prominent agricultural regions in the United
States (between 2010 and 2023) to validate the predictive accuracy of our
framework on multiple severe event types, which are extreme cold, floods,
frost, hail, heatwaves, and heavy rainfall, with tailored models for each area.
The framework uniquely integrates attention mechanisms with TimeSHAP (a
recurrent XAI explainer for time series) to provide comprehensive temporal
explanations revealing not only which climatic features are influential but
precisely when their impacts occur. Our results demonstrate strong predictive
accuracy, particularly with the BiLSTM architecture, and highlight the system's
capacity to inform nuanced, proactive risk management strategies. This research
significantly advances the explainability and applicability of multi-hazard
EWS, fostering interdisciplinary trust and effective decision-making process
for climate risk management in the agricultural industry.

</details>


### [288] [FedCVD++: Communication-Efficient Federated Learning for Cardiovascular Risk Prediction with Parametric and Non-Parametric Model Optimization](https://arxiv.org/abs/2507.22963)
*Abdelrhman Gaber,Hassan Abd-Eltawab,John Elgallab,Youssif Abuzied,Dineo Mpanya,Turgay Celik,Swarun Kumar,Tamer ElBatt*

Main category: cs.LG

TL;DR: FedCVD++ 通过集成参数和非参数模型，并采用创新的通信效率技术（如树子集采样和基于 XGBoost 的特征提取），显著提高了联邦学习在心血管疾病风险预测中的性能和效率，同时解决了类别不平衡问题，并在实际数据集上取得了优于现有方法的成果。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病 (CVD) 每年在全球范围内导致超过 1700 万人死亡，凸显了对隐私保护预测系统的迫切需求。

Method: FedCVD++ 是一个增强的联邦学习 (FL) 框架，它结合了参数模型（逻辑回归、SVM、神经网络）和非参数模型（随机森林、XGBoost）来进行冠心病风险预测。主要技术包括：(1) 树子集采样，将随机森林的通信开销减少了 70%；(2) 基于 XGBoost 的特征提取，实现了轻量级的联邦集成；(3) 联邦 SMOTE 同步，用于解决跨机构的类别不平衡问题。

Result: FedCVD++ 在 Framingham 数据集上实现了最先进的结果：联邦 XGBoost (F1 = 0.80) 优于其集中式对应物 (F1 = 0.78)，联邦随机森林 (F1 = 0.81) 与非联邦性能相当。此外，通信效率策略将带宽消耗减少了 3.2 倍，同时保留了 95% 的准确率。与现有的 FL 框架相比，FedCVD++ 的 F1 分数高出 15%，并且在多机构部署方面具有更优越的可扩展性。

Conclusion: FedCVD++ 是第一个将非参数模型集成到联邦医疗保健系统中的实用解决方案，在真实世界的临床约束下得到验证，可提供经过验证的隐私保护解决方案。

Abstract: Cardiovascular diseases (CVD) cause over 17 million deaths annually
worldwide, highlighting the urgent need for privacy-preserving predictive
systems. We introduce FedCVD++, an enhanced federated learning (FL) framework
that integrates both parametric models (logistic regression, SVM, neural
networks) and non-parametric models (Random Forest, XGBoost) for coronary heart
disease risk prediction. To address key FL challenges, we propose: (1)
tree-subset sampling that reduces Random Forest communication overhead by 70%,
(2) XGBoost-based feature extraction enabling lightweight federated ensembles,
and (3) federated SMOTE synchronization for resolving cross-institutional class
imbalance.
  Evaluated on the Framingham dataset (4,238 records), FedCVD++ achieves
state-of-the-art results: federated XGBoost (F1 = 0.80) surpasses its
centralized counterpart (F1 = 0.78), and federated Random Forest (F1 = 0.81)
matches non-federated performance. Additionally, our communication-efficient
strategies reduce bandwidth consumption by 3.2X while preserving 95% accuracy.
  Compared to existing FL frameworks, FedCVD++ delivers up to 15% higher
F1-scores and superior scalability for multi-institutional deployment. This
work represents the first practical integration of non-parametric models into
federated healthcare systems, providing a privacy-preserving solution validated
under real-world clinical constraints.

</details>


### [289] [DynaSwarm: Dynamically Graph Structure Selection for LLM-based Multi-agent System](https://arxiv.org/abs/2507.23261)
*Hui Yi Leong,Yuqing Wu*

Main category: cs.LG

TL;DR: DynaSwarm is a dynamic framework for LLM-based MAS that uses A2C and a dynamic graph selector to optimize collaboration graph structures based on input samples, improving adaptability and performance over static methods.


<details>
  <summary>Details</summary>
Motivation: Existing multi-agent systems (MAS) frameworks lack adaptability and performance due to manually designed, static collaboration graph structures.

Method: DynaSwarm utilizes an actor-critic reinforcement learning (A2C) mechanism for optimizing dynamic graph structures and a dynamic graph selector with parameter-efficient LLM fine-tuning to adaptively choose optimal graph structures for each input sample. It also fine-tunes the demonstration retriever to leverage in-context learning.

Result: Extensive experiments on question answering, mathematical reasoning, and coding tasks show DynaSwarm consistently outperforms state-of-the-art single-agent and MAS baselines across multiple LLM backbones.

Conclusion: DynaSwarm's sample-aware structural flexibility is crucial for LLM MAS designs, outperforming state-of-the-art baselines.

Abstract: Current multi-agent systems (MAS) frameworks often rely on manually designed
and static collaboration graph structures, limiting adaptability and
performance. To address these limitations, we propose DynaSwarm, a dynamic
framework that enhances LLM-based MAS through two key innovations: (1) an
actor-critic reinforcement learning (A2C) mechanism to optimize graph
structures with improved stability over prior RL methods, and (2) a dynamic
graph selector that adaptively chooses the optimal graph structure for each
input sample via parameter-efficient LLM fine-tuning. DynaSwarm eliminates the
need for rigid, one-fits-all graph architectures, instead leveraging
sample-specific idiosyncrasies to dynamically route queries through specialized
agent networks. (c) We propose to fine-tune the demonstration retriever to
fully exploit the power of in-context learning (ICL). Extensive experiments on
question answering, mathematical reasoning, and coding tasks demonstrate that
DynaSwarm consistently outperforms state-of-the-art single-agent and MAS
baselines across multiple LLM backbones. Our findings highlight the importance
of sample-aware structural flexibility in LLM MAS designs.

</details>


### [290] [Improved Algorithms for Kernel Matrix-Vector Multiplication Under Sparsity Assumptions](https://arxiv.org/abs/2507.23539)
*Piotr Indyk,Michael Kapralov,Kshiteej Sheth,Tal Wagner*

Main category: cs.LG

TL;DR: 提出了一种新的算法，可以在子二次方时间内计算高斯核矩阵与向量的乘积。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是解决注意力矩阵的快速处理问题，特别是针对非对称高斯核矩阵（K）的矩阵向量乘积的计算。

Method: 研究提出了一种基于对矩阵K的建模假设（即K的列的内积和是线性的而不是二次方的）的新算法。

Result: 该研究提出了一种新的算法，可以在子二次方时间内计算高斯核矩阵与向量的乘积，其时间复杂度与n成亚线性关系，与d成线性关系。

Conclusion: 该研究首次提出了一个在子二次方时间内计算高斯核矩阵与向量乘积的算法，该算法适用于未受限制的向量。

Abstract: Motivated by the problem of fast processing of attention matrices, we study
fast algorithms for computing matrix-vector products for asymmetric Gaussian
Kernel matrices $K\in \mathbb{R}^{n\times n}$. $K$'s columns are indexed by a
set of $n$ keys $k_1,k_2\ldots, k_n\in \mathbb{R}^d$, rows by a set of $n$
queries $q_1,q_2,\ldots,q_n\in \mathbb{R}^d $, and its $i,j$ entry is $K_{ij} =
e^{-\|q_i-k_j\|_2^2/2\sigma^2}$ for some bandwidth parameter $\sigma>0$. Given
a vector $x\in \mathbb{R}^n$ and error parameter $\epsilon>0$, our task is to
output a $y\in \mathbb{R}^n$ such that $\|Kx-y\|_2\leq \epsilon \|x\|_2$ in
time subquadratic in $n$ and linear in $d$. Our algorithms rely on the
following modelling assumption about the matrices $K$: the sum of the entries
of $K$ scales linearly in $n$, as opposed to worst case quadratic growth. We
validate this assumption experimentally, for Gaussian kernel matrices
encountered in various settings such as fast attention computation in LLMs. We
obtain the first subquadratic-time algorithm that works under this assumption,
for unrestricted vectors.

</details>


### [291] [Planning for Cooler Cities: A Multimodal AI Framework for Predicting and Mitigating Urban Heat Stress through Urban Landscape Transformation](https://arxiv.org/abs/2507.23000)
*Shengao Yi,Xiaojiang Li,Wei Tu,Tianhong Zhao*

Main category: cs.LG

TL;DR: GSM-UTCI是一个深度学习模型，可以快速准确地预测城市热暴露，为城市规划提供支持。


<details>
  <summary>Details</summary>
Motivation: 为了应对气候变化和城市化加剧的极端高温事件，城市在减缓户外热应力方面面临日益严峻的挑战。传统的物理模型计算成本高，难以在城市规划中大规模应用。

Method: 提出了一种多模态深度学习框架GSM-UTCI，该框架融合了地表形态、高分辨率土地覆盖数据和每小时气象条件，并利用FiLM架构动态调节空间特征，以预测1米超本地分辨率的日间平均普遍热气候指数（UTCI）。

Result: GSM-UTCI模型在SOLWEIG衍生的UTCI图上进行训练，在接近物理精度的情况下，R2达到0.9151，平均绝对误差（MAE）为0.41°C，并将城市范围的推理时间从几小时缩短到不到五分钟。在费城进行景观改造模拟显示，将裸土、草地和不透水地面转变为树冠具有显著的降温效果，其中不透水地面转变为树冠的降温效果最强（平均UTCI变化为-4.18°C，覆盖面积达270.7平方公里）。

Conclusion: GSM-UTCI是一个可扩展、细粒度的城市气候适应决策支持工具，能够进行基于场景的城市绿化策略评估。

Abstract: As extreme heat events intensify due to climate change and urbanization,
cities face increasing challenges in mitigating outdoor heat stress. While
traditional physical models such as SOLWEIG and ENVI-met provide detailed
assessments of human-perceived heat exposure, their computational demands limit
scalability for city-wide planning. In this study, we propose GSM-UTCI, a
multimodal deep learning framework designed to predict daytime average
Universal Thermal Climate Index (UTCI) at 1-meter hyperlocal resolution. The
model fuses surface morphology (nDSM), high-resolution land cover data, and
hourly meteorological conditions using a feature-wise linear modulation (FiLM)
architecture that dynamically conditions spatial features on atmospheric
context. Trained on SOLWEIG-derived UTCI maps, GSM-UTCI achieves near-physical
accuracy, with an R2 of 0.9151 and a mean absolute error (MAE) of 0.41{\deg}C,
while reducing inference time from hours to under five minutes for an entire
city. To demonstrate its planning relevance, we apply GSM-UTCI to simulate
systematic landscape transformation scenarios in Philadelphia, replacing bare
earth, grass, and impervious surfaces with tree canopy. Results show spatially
heterogeneous but consistently strong cooling effects, with impervious-to-tree
conversion producing the highest aggregated benefit (-4.18{\deg}C average
change in UTCI across 270.7 km2). Tract-level bivariate analysis further
reveals strong alignment between thermal reduction potential and land cover
proportions. These findings underscore the utility of GSM-UTCI as a scalable,
fine-grained decision support tool for urban climate adaptation, enabling
scenario-based evaluation of greening strategies across diverse urban
environments.

</details>


### [292] [Stop Evaluating AI with Human Tests, Develop Principled, AI-specific Tests instead](https://arxiv.org/abs/2507.23009)
*Tom Sühr,Florian E. Dorner,Olawale Salaudeen,Augustin Kelava,Samira Samadi*

Main category: cs.LG

TL;DR: 停止使用人类测试评估人工智能，应开发人工智能专属测试。


<details>
  <summary>Details</summary>
Motivation: 当前人工智能评估基准测试的局限性，以及将人类心理和教育测试应用于人工智能可能导致的误解，促使研究者提出开发新评估方法。

Method: 通过论证将人类心理和教育测试应用于非人类主体（如大型语言模型）存在本体论错误，并指出当前评估人工智能的基准测试存在有效性、数据污染、文化偏见和对提示词敏感等问题。

Result: 论证了将人类测试用于评估人工智能缺乏足够的理论和经验依据，并呼吁开发专门针对人工智能的、有原则的评估框架。

Conclusion: 应停止使用人类测试评估人工智能，并开发专门针对人工智能的、有原则的测试框架。

Abstract: Large Language Models (LLMs) have achieved remarkable results on a range of
standardized tests originally designed to assess human cognitive and
psychological traits, such as intelligence and personality. While these results
are often interpreted as strong evidence of human-like characteristics in LLMs,
this paper argues that such interpretations constitute an ontological error.
Human psychological and educational tests are theory-driven measurement
instruments, calibrated to a specific human population. Applying these tests to
non-human subjects without empirical validation, risks mischaracterizing what
is being measured. Furthermore, a growing trend frames AI performance on
benchmarks as measurements of traits such as ``intelligence'', despite known
issues with validity, data contamination, cultural bias and sensitivity to
superficial prompt changes. We argue that interpreting benchmark performance as
measurements of human-like traits, lacks sufficient theoretical and empirical
justification. This leads to our position: Stop Evaluating AI with Human Tests,
Develop Principled, AI-specific Tests instead. We call for the development of
principled, AI-specific evaluation frameworks tailored to AI systems. Such
frameworks might build on existing frameworks for constructing and validating
psychometrics tests, or could be created entirely from scratch to fit the
unique context of AI.

</details>


### [293] [Designing Dynamic Pricing for Bike-sharing Systems via Differentiable Agent-based Simulation](https://arxiv.org/abs/2507.23344)
*Tatsuya Mitomi,Fumiyasu Makinoshima,Fumiya Makihara,Eigo Segawa*

Main category: cs.LG

TL;DR: 提出一种新的动态定价方法，通过可微分的模拟器，有效解决了共享单车供需不平衡问题，并提高了效率。


<details>
  <summary>Details</summary>
Motivation: 城市共享单车系统因其环保性而日益普及，但用户需求时空变化导致车辆在站点间分布不均，增加了调度成本。因此，需要通过优化动态定价来管理用户需求，但用户行为的复杂性和概率性使得最优定价设计面临挑战。

Method: 开发了一种可微分的、基于代理的模拟方法，用于快速设计动态定价策略。

Result: 与传统方法相比，该方法在数值实验（25个站点，5个时间段）中，损失减少了73%至78%，收敛速度提高了100多倍。在大规模城市共享单车系统（289个站点）的模拟中，优化的定价策略能有效均衡车辆库存，无需人工调度，并能通过设置合适的初始条件来最小化折扣成本。

Conclusion: 通过优化动态定价策略，可以有效解决城市共享单车系统中的供需不平衡问题，无需人工干预即可实现车辆的均衡分布，并能通过调整初始条件最小化折扣成本。

Abstract: Bike-sharing systems are emerging in various cities as a new ecofriendly
transportation system. In these systems, spatiotemporally varying user demands
lead to imbalanced inventory at bicycle stations, resulting in additional
relocation costs. Therefore, it is essential to manage user demand through
optimal dynamic pricing for the system. However, optimal pricing design for
such a system is challenging because the system involves users with diverse
backgrounds and their probabilistic choices. To address this problem, we
develop a differentiable agent-based simulation to rapidly design dynamic
pricing in bike-sharing systems, achieving balanced bicycle inventory despite
spatiotemporally heterogeneous trips and probabilistic user decisions. We first
validate our approach against conventional methods through numerical
experiments involving 25 bicycle stations and five time slots, yielding 100
parameters. Compared to the conventional methods, our approach obtains a more
accurate solution with a 73% to 78% reduction in loss while achieving more than
a 100-fold increase in convergence speed. We further validate our approach on a
large-scale urban bike-sharing system scenario involving 289 bicycle stations,
resulting in a total of 1156 parameters. Through simulations using the obtained
pricing policies, we confirm that these policies can naturally induce balanced
inventory without any manual relocation. Additionally, we find that the cost of
discounts to induce the balanced inventory can be minimized by setting
appropriate initial conditions.

</details>


### [294] [Investigating the Invertibility of Multimodal Latent Spaces: Limitations of Optimization-Based Methods](https://arxiv.org/abs/2507.23010)
*Siwoo Park*

Main category: cs.LG

TL;DR: 多模态潜在空间无法支持可靠的逆向映射。


<details>
  <summary>Details</summary>
Motivation: 研究多模态潜在空间在任务特定人工智能模型中的逆向能力和更广泛的效用，因为这些模型的前向任务能力（例如文本到图像生成）虽然表现出色，但其逆向映射的潜力在很大程度上仍未被探索。

Method: 提出一个基于优化的框架，将文本-图像和文本-音频模态进行双向应用，以推断输入特征。

Result: 实验结果一致地表明，虽然优化可以迫使模型生成在文本上与目标一致的输出（例如，文本到图像模型生成图像描述模型能够正确描述的图像，或自动语音识别模型准确转录优化后的音频），但这些逆向映射的感知质量是混乱且不连贯的。此外，在尝试从生成模型推断原始语义输入时，重构的潜在空间嵌入通常缺乏语义可解释性。

Conclusion: 多模态潜在空间主要针对特定的前向任务进行了优化，因此不具备支持稳健且可解释的逆向映射所需的内在结构。这项工作强调了开发真正具有丰富语义且可逆的多模态潜在空间的研究需求。

Abstract: This paper investigates the inverse capabilities and broader utility of
multimodal latent spaces within task-specific AI (Artificial Intelligence)
models. While these models excel at their designed forward tasks (e.g.,
text-to-image generation, audio-to-text transcription), their potential for
inverse mappings remains largely unexplored. We propose an optimization-based
framework to infer input characteristics from desired outputs, applying it
bidirectionally across Text-Image (BLIP, Flux.1-dev) and Text-Audio
(Whisper-Large-V3, Chatterbox-TTS) modalities.
  Our central hypothesis posits that while optimization can guide models
towards inverse tasks, their multimodal latent spaces will not consistently
support semantically meaningful and perceptually coherent inverse mappings.
Experimental results consistently validate this hypothesis. We demonstrate that
while optimization can force models to produce outputs that align textually
with targets (e.g., a text-to-image model generating an image that an image
captioning model describes correctly, or an ASR model transcribing optimized
audio accurately), the perceptual quality of these inversions is chaotic and
incoherent. Furthermore, when attempting to infer the original semantic input
from generative models, the reconstructed latent space embeddings frequently
lack semantic interpretability, aligning with nonsensical vocabulary tokens.
  These findings highlight a critical limitation. multimodal latent spaces,
primarily optimized for specific forward tasks, do not inherently possess the
structure required for robust and interpretable inverse mappings. Our work
underscores the need for further research into developing truly semantically
rich and invertible multimodal latent spaces.

</details>


### [295] [Linking Actor Behavior to Process Performance Over Time](https://arxiv.org/abs/2507.23037)
*Aurélie Leribaux,Rafael Oyamada,Johannes De Smedt,Zahra Dasht Bozorgi,Artem Polyvyanyy,Jochen De Weerdt*

Main category: cs.LG

TL;DR: actor behavior influences process outcomes by analyzing time series data of actor interactions and process outcomes using Granger causality and Group Lasso.


<details>
  <summary>Details</summary>
Motivation: Traditional approaches often use aggregate and static process data, overlooking the temporal and causal dynamics that arise from individual actor behavior. This limits the ability to accurately capture the complexity of real-world processes, where individual actor behavior and interactions between actors significantly shape performance.

Method: integrating actor behavior analysis with Granger causality to identify correlating links in time series data. We apply this approach to realworld event logs, constructing time series for actor interactions, i.e. continuation, interruption, and handovers, and process outcomes. Using Group Lasso for lag selection, we identify a small but consistently influential set of lags that capture the majority of causal influence.

Result: actor behavior has direct and measurable impacts on process performance, particularly throughput time.

Conclusion: actor behavior has direct and measurable impacts on process performance, particularly throughput time.

Abstract: Understanding how actor behavior influences process outcomes is a critical
aspect of process mining. Traditional approaches often use aggregate and static
process data, overlooking the temporal and causal dynamics that arise from
individual actor behavior. This limits the ability to accurately capture the
complexity of real-world processes, where individual actor behavior and
interactions between actors significantly shape performance. In this work, we
address this gap by integrating actor behavior analysis with Granger causality
to identify correlating links in time series data. We apply this approach to
realworld event logs, constructing time series for actor interactions, i.e.
continuation, interruption, and handovers, and process outcomes. Using Group
Lasso for lag selection, we identify a small but consistently influential set
of lags that capture the majority of causal influence, revealing that actor
behavior has direct and measurable impacts on process performance, particularly
throughput time. These findings demonstrate the potential of actor-centric,
time series-based methods for uncovering the temporal dependencies that drive
process outcomes, offering a more nuanced understanding of how individual
behaviors impact overall process efficiency.

</details>


### [296] [Prediction of Significant Creatinine Elevation in First ICU Stays with Vancomycin Use: A retrospective study through Catboost](https://arxiv.org/abs/2507.23043)
*Junyi Fan,Li Sun,Shuheng Chen,Yong Si,Minoo Ahmadi,Greg Placencia,Elham Pishgar,Kamiar Alaei,Maryam Pishgar*

Main category: cs.LG

TL;DR: 使用机器学习模型（CatBoost）预测ICU患者万古霉素引起的肾损伤，准确率高，且模型具有可解释性。


<details>
  <summary>Details</summary>
Motivation: 重症监护室（ICU）万古霉素的使用与高肾毒性风险相关，早期预测危重患者的肾脏损伤具有挑战性。本研究旨在开发一个机器学习模型，利用常规ICU数据预测万古霉素相关的肌酐升高。

Method: 本研究利用MIMIC-IV数据库中10,288名接受万古霉素治疗的ICU患者数据。采用SelectKBest和随机森林方法进行特征选择（最终15个），并测试了六种机器学习算法（包括CatBoost），使用5倍交叉验证。利用SHAP、ALE和贝叶斯后验采样评估模型的可解释性。

Result: 在10,288名患者中，2,903名（28.2%）出现肌酐升高。CatBoost模型表现最佳（AUROC 0.818），主要预测因子包括磷酸盐、总胆红素、镁、Charlson指数和APSIII。SHAP分析确认磷酸盐是主要风险因素，ALE分析显示了剂量反应模式。

Conclusion: 机器学习模型能够根据常规ICU数据准确预测万古霉素相关的肌酐升高，从而实现早期风险检测并支持危重监护中的及时干预。

Abstract: Background: Vancomycin, a key antibiotic for severe Gram-positive infections
in ICUs, poses a high nephrotoxicity risk. Early prediction of kidney injury in
critically ill patients is challenging. This study aimed to develop a machine
learning model to predict vancomycin-related creatinine elevation using routine
ICU data.
  Methods: We analyzed 10,288 ICU patients (aged 18-80) from the MIMIC-IV
database who received vancomycin. Kidney injury was defined by KDIGO criteria
(creatinine rise >=0.3 mg/dL within 48h or >=50% within 7d). Features were
selected via SelectKBest (top 30) and Random Forest ranking (final 15). Six
algorithms were tested with 5-fold cross-validation. Interpretability was
evaluated using SHAP, Accumulated Local Effects (ALE), and Bayesian posterior
sampling.
  Results: Of 10,288 patients, 2,903 (28.2%) developed creatinine elevation.
CatBoost performed best (AUROC 0.818 [95% CI: 0.801-0.834], sensitivity 0.800,
specificity 0.681, negative predictive value 0.900). Key predictors were
phosphate, total bilirubin, magnesium, Charlson index, and APSIII. SHAP
confirmed phosphate as a major risk factor. ALE showed dose-response patterns.
Bayesian analysis estimated mean risk 60.5% (95% credible interval: 16.8-89.4%)
in high-risk cases.
  Conclusions: This machine learning model predicts vancomycin-associated
creatinine elevation from routine ICU data with strong accuracy and
interpretability, enabling early risk detection and supporting timely
interventions in critical care.

</details>


### [297] [Locally Differentially Private Thresholding Bandits](https://arxiv.org/abs/2507.23073)
*Annalisa Barbara,Joseph Lazzaro,Ciara Pike-Burke*

Main category: cs.LG

TL;DR: 本研究提出了在阈值强盗问题中实现本地差分隐私的方法，并在理论上证明了其性能界限和隐私保证，证明了算法的高效性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在调查在阈值强盗问题中确保本地差分隐私的影响。

Method: 本研究提出了一种利用私有响应（通过基于伯努利的差分隐私机制获得）来识别臂的期望奖励超过预定阈值的方法。

Result: 本研究推导了所提出算法的理论性能界限，并给出了与下界匹配（在多对数因子内）的算法，证明了其有效性。

Conclusion: 本研究提出的方法在固定预算和固定置信度设置下均能有效识别期望奖励超过预定阈值的臂，并提供了强大的隐私保证和理论性能界限。此外，我们还提出了通用的下界，刻画了任何差分隐私机制的额外损失，并证明了所提出算法在多对数因子内匹配这些下界。

Abstract: This work investigates the impact of ensuring local differential privacy in
the thresholding bandit problem. We consider both the fixed budget and fixed
confidence settings. We propose methods that utilize private responses,
obtained through a Bernoulli-based differentially private mechanism, to
identify arms with expected rewards exceeding a predefined threshold. We show
that this procedure provides strong privacy guarantees and derive theoretical
performance bounds on the proposed algorithms. Additionally, we present general
lower bounds that characterize the additional loss incurred by any
differentially private mechanism, and show that the presented algorithms match
these lower bounds up to poly-logarithmic factors. Our results provide valuable
insights into privacy-preserving decision-making frameworks in bandit problems.

</details>


### [298] [A Foundation Model for Material Fracture Prediction](https://arxiv.org/abs/2507.23077)
*Agnese Marcato,Aleksandra Pachalieva,Ryley G. Hill,Kai Gao,Xiaoyu Wang,Esteban Rougier,Zhou Lei,Vinamra Agrawal,Janel Chua,Qinjun Kang,Jeffrey D. Hyman,Abigail Hunter,Nathan DeBardeleben,Earl Lawrence,Hari Viswanathan,Daniel O'Malley,Javier E. Santos*

Main category: cs.LG

TL;DR: 提出了一种基于 Transformer 的数据驱动基础模型，用于预测各种材料和加载条件下的断裂行为。该模型能够处理结构化和非结构化网格，并结合文本描述，具有良好的泛化能力和数据效率，可替代特定模拟器的工作流程。


<details>
  <summary>Details</summary>
Motivation: 准确预测材料失效的时间和方式对于设计在应力下运行的安全、可靠的结构、机械系统和工程部件至关重要。然而，断裂行为在实际应用中材料、几何形状和加载条件的各种情况下仍然难以建模。现有的机器学习（ML）模型通常在狭窄的数据集上进行训练，鲁棒性差且泛化能力弱，而基于物理的模拟器虽然能提供高保真度预测，但存在方法碎片化且需要大量计算资源的问题。

Method: 提出了一种基于 Transformer 的数据驱动基础模型，该模型可以跨越不同的模拟器、多种材料（包括塑料粘合炸药、钢、铝、页岩和钨）以及各种加载条件。该模型支持结构化和非结构化网格，并结合了文本输入文件的语言模型嵌入，用于指定材料属性、边界条件和求解器设置。

Result: 该模型可以针对各种下游任务进行微调，包括故障时间估计、断裂演化建模以及适应有限-离散元方法模拟。它还可以泛化到未见过的新材料（如钛和混凝土），只需少量数据（最少一个样本），即可显著减少数据需求。

Conclusion: 该模型能够统一地预测不同材料、几何形状和加载条件下的断裂行为，提供了一种可扩展、可扩展的替代特定模拟器工作流程的方案。

Abstract: Accurately predicting when and how materials fail is critical to designing
safe, reliable structures, mechanical systems, and engineered components that
operate under stress. Yet, fracture behavior remains difficult to model across
the diversity of materials, geometries, and loading conditions in real-world
applications. While machine learning (ML) methods show promise, most models are
trained on narrow datasets, lack robustness, and struggle to generalize.
Meanwhile, physics-based simulators offer high-fidelity predictions but are
fragmented across specialized methods and require substantial high-performance
computing resources to explore the input space. To address these limitations,
we present a data-driven foundation model for fracture prediction, a
transformer-based architecture that operates across simulators, a wide range of
materials (including plastic-bonded explosives, steel, aluminum, shale, and
tungsten), and diverse loading conditions. The model supports both structured
and unstructured meshes, combining them with large language model embeddings of
textual input decks specifying material properties, boundary conditions, and
solver settings. This multimodal input design enables flexible adaptation
across simulation scenarios without changes to the model architecture. The
trained model can be fine-tuned with minimal data on diverse downstream tasks,
including time-to-failure estimation, modeling fracture evolution, and adapting
to combined finite-discrete element method simulations. It also generalizes to
unseen materials such as titanium and concrete, requiring as few as a single
sample, dramatically reducing data needs compared to standard ML. Our results
show that fracture prediction can be unified under a single model architecture,
offering a scalable, extensible alternative to simulator-specific workflows.

</details>


### [299] [On the Sustainability of AI Inferences in the Edge](https://arxiv.org/abs/2507.23093)
*Ghazal Sobhani,Md. Monzurul Amin Ifath,Tushar Sharma,Israat Haque*

Main category: cs.LG

TL;DR: This study analyzes the performance and energy usage of different AI models on various edge devices to help select the best combination for AI-enabled IoT applications.


<details>
  <summary>Details</summary>
Motivation: The proliferation of AI-enabled IoT applications requires informed decision-making on device and model selection for resource-constrained edge devices, considering both performance and energy usage.

Method: This study rigorously characterizes the performance of traditional, neural networks, and large language models on edge devices like Raspberry Pi (RPi), Intel Neural Compute Stick (INCS), NVIDIA Jetson nano (NJn), and Google Coral USB (GCU), analyzing trade-offs among model F1 score, inference time, inference power, and memory usage.

Result: The study analyzes trade-offs among model F1 score, inference time, inference power, and memory usage for various AI models on different edge devices.

Conclusion: Hardware and framework optimization, along with external parameter tuning of AI models, can balance between model performance and resource usage to realize practical edge AI deployments.

Abstract: The proliferation of the Internet of Things (IoT) and its cutting-edge
AI-enabled applications (e.g., autonomous vehicles and smart industries)
combine two paradigms: data-driven systems and their deployment on the edge.
Usually, edge devices perform inferences to support latency-critical
applications. In addition to the performance of these resource-constrained edge
devices, their energy usage is a critical factor in adopting and deploying edge
applications. Examples of such devices include Raspberry Pi (RPi), Intel Neural
Compute Stick (INCS), NVIDIA Jetson nano (NJn), and Google Coral USB (GCU).
Despite their adoption in edge deployment for AI inferences, there is no study
on their performance and energy usage for informed decision-making on the
device and model selection to meet the demands of applications. This study
fills the gap by rigorously characterizing the performance of traditional,
neural networks, and large language models on the above-edge devices.
Specifically, we analyze trade-offs among model F1 score, inference time,
inference power, and memory usage. Hardware and framework optimization, along
with external parameter tuning of AI models, can balance between model
performance and resource usage to realize practical edge AI deployments.

</details>


### [300] [Scalable Generative Modeling of Weighted Graphs](https://arxiv.org/abs/2507.23111)
*Richard Williams,Eric Nalisnick,Andrew Holbrook*

Main category: cs.LG

TL;DR: BiGG-E 是一种新的自回归模型，可以高效地生成加权图，解决了现有模型在处理加权图时的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的深度生成模型要么是为无权图设计的，并且不易扩展到加权拓扑，要么在不考虑与拓扑的联合分布的情况下纳入边权重。此外，加权图上的学习分布必须同时考虑图的边以及每条边的相应权重之间复杂的非局部依赖关系。

Method: 开发了一种自回归模型 BiGG-E，它是 BiGG 模型的非平凡扩展，用于学习加权图的联合分布。

Result: BiGG-E 在生成加权图方面表现出色，能够处理复杂的非局部依赖关系，并且在保持可扩展性和计算效率的同时，最能捕捉加权图的分布。

Conclusion: BiGG-E 成功地学习了加权图的联合分布，同时利用稀疏性，在 O((n + m)logn) 时间内生成具有 n 个节点和 m 个边的加权图。 模拟研究和在各种基准数据集上的实验证明，BiGG-E 在保持可扩展性和计算效率的同时，最能捕捉加权图的分布。

Abstract: Weighted graphs are ubiquitous throughout biology, chemistry, and the social
sciences, motivating the development of generative models for abstract weighted
graph data using deep neural networks. However, most current deep generative
models are either designed for unweighted graphs and are not easily extended to
weighted topologies or incorporate edge weights without consideration of a
joint distribution with topology. Furthermore, learning a distribution over
weighted graphs must account for complex nonlocal dependencies between both the
edges of the graph and corresponding weights of each edge. We develop an
autoregressive model BiGG-E, a nontrivial extension of the BiGG model, that
learns a joint distribution over weighted graphs while still exploiting
sparsity to generate a weighted graph with $n$ nodes and $m$ edges in $O((n +
m)\log n)$ time. Simulation studies and experiments on a variety of benchmark
datasets demonstrate that BiGG-E best captures distributions over weighted
graphs while remaining scalable and computationally efficient.

</details>


### [301] [FLOSS: Federated Learning with Opt-Out and Straggler Support](https://arxiv.org/abs/2507.23115)
*David J Goetze,Dahlia J Felten,Jeannie R Albrecht,Rohit Bhattacharya*

Main category: cs.LG

TL;DR: FLOSS addresses missing data in federated learning caused by user opt-out and stragglers to improve model performance.


<details>
  <summary>Details</summary>
Motivation: Modern data privacy agreements empower users to opt-out of sharing data, and stragglers arise from heterogeneous device capabilities, leading to missing data that introduces bias and degrades model performance.

Method: FLOSS system that mitigates the impacts of missing data.

Result: Empirically demonstrate FLOSS's performance in simulations.

Conclusion: FLOSS mitigates the impacts of missing data on federated learning in the presence of stragglers and user opt-out.

Abstract: Previous work on data privacy in federated learning systems focuses on
privacy-preserving operations for data from users who have agreed to share
their data for training. However, modern data privacy agreements also empower
users to use the system while opting out of sharing their data as desired. When
combined with stragglers that arise from heterogeneous device capabilities, the
result is missing data from a variety of sources that introduces bias and
degrades model performance. In this paper, we present FLOSS, a system that
mitigates the impacts of such missing data on federated learning in the
presence of stragglers and user opt-out, and empirically demonstrate its
performance in simulations.

</details>


### [302] [Evaluating and Improving the Robustness of Speech Command Recognition Models to Noise and Distribution Shifts](https://arxiv.org/abs/2507.23128)
*Anaïs Baranger,Lucas Maison*

Main category: cs.LG

TL;DR: 研究了训练条件和输入特征对语音关键词分类器在分布外（OOD）条件下的鲁棒性和泛化能力的影响，并提出了公平性（F）和鲁棒性（R）两个新指标。部分结果表明，面向噪声的训练在某些情况下可以提高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 探究训练条件和输入特征如何影响语音关键词分类器在分布外（OOD）条件下的鲁棒性和泛化能力。

Method: 通过评估几种神经网络结构在多种评估集上的表现来评估噪声对泛化的影响，并使用公平性（F）和鲁棒性（R）两个指标量化。

Result: 在某些配置下，面向噪声的训练可以提高鲁棒性，并且对基于噪声的数据增强在语音模型泛化中的益处和局限性提供了新的见解。

Conclusion: 研究结果表明，在某些配置下，面向噪声的训练可以提高鲁棒性。这些发现为了解基于噪声的数据增强在语音模型泛化中的益处和局限性提供了新的视角。

Abstract: Although prior work in computer vision has shown strong correlations between
in-distribution (ID) and out-of-distribution (OOD) accuracies, such
relationships remain underexplored in audio-based models. In this study, we
investigate how training conditions and input features affect the robustness
and generalization abilities of spoken keyword classifiers under OOD
conditions. We benchmark several neural architectures across a variety of
evaluation sets. To quantify the impact of noise on generalization, we make use
of two metrics: Fairness (F), which measures overall accuracy gains compared to
a baseline model, and Robustness (R), which assesses the convergence between ID
and OOD performance. Our results suggest that noise-aware training improves
robustness in some configurations. These findings shed new light on the
benefits and limitations of noise-based augmentation for generalization in
speech models.

</details>


### [303] [Observational Multiplicity](https://arxiv.org/abs/2507.23136)
*Erin George,Deanna Needell,Berk Ustun*

Main category: cs.LG

TL;DR: 研究了概率分类任务中的任意性问题，提出了一种名为“回归”的度量标准来评估模型预测的稳定性，并展示了其在提高模型安全性和可解释性方面的应用。


<details>
  <summary>Details</summary>
Motivation: 许多预测任务可以有多个表现几乎同样好的模型，这可能会破坏可解释性和安全性，因为竞争模型会对个体做出冲突的预测。

Method: 提出了一种度量回归的方法，并提供了一种估计回归的通用方法。

Result: 该方法可以量化回归，并用于识别回归较高的群体，从而促进安全。

Conclusion: 研究表明，在某些群体中，回归值更高，并讨论了回归的潜在应用。通过弃权和数据收集，估计回归可以提高现实世界应用中的安全性。

Abstract: Many prediction tasks can admit multiple models that can perform almost
equally well. This phenomenon can can undermine interpretability and safety
when competing models assign conflicting predictions to individuals. In this
work, we study how arbitrariness can arise in probabilistic classification
tasks as a result of an effect that we call \emph{observational multiplicity}.
We discuss how this effect arises in a broad class of practical applications
where we learn a classifier to predict probabilities $p_i \in [0,1]$ but are
given a dataset of observations $y_i \in \{0,1\}$. We propose to evaluate the
arbitrariness of individual probability predictions through the lens of
\emph{regret}. We introduce a measure of regret for probabilistic
classification tasks, which measures how the predictions of a model could
change as a result of different training labels change. We present a
general-purpose method to estimate the regret in a probabilistic classification
task. We use our measure to show that regret is higher for certain groups in
the dataset and discuss potential applications of regret. We demonstrate how
estimating regret promote safety in real-world applications by abstention and
data collection.

</details>


### [304] [AI paradigm for solving differential equations: first-principles data generation and scale-dilation operator AI solver](https://arxiv.org/abs/2507.23141)
*Xiangshu Gong,Zhiqiang Xie,Xiaowei Jin,Chen Wang,Yanling Qu,Wangmeng Zuo,Hui Li*

Main category: cs.LG

TL;DR: 一种新的AI方法，通过生成数据和使用SDO Transformer求解器，解决了DEs数据稀疏和高频分量近似的问题，并在各种DEs上取得了优于现有方法的精度。


<details>
  <summary>Details</summary>
Motivation: 现有AI求解器在处理稀疏数据和近似高频分量方面存在困难。本研究旨在克服这些限制，提供一个更通用、更准确的AI求解DEs的方法。

Method: 提出了一种新颖的AI范式，包括基于DE的先验数据生成方法和尺度扩张算子（SDO）AI求解器。该方法利用傅里叶变换和基于Transformer的架构来解决高频分量近似问题，并通过理论证明了SDO能够改善损失函数的景观。

Result: 所提出的AI范式在包括DE规则的先验数据生成方法和SDO AI求解器在内的多样化DEs上，实现了始终优于最先进方法的精度。

Conclusion: 该AI范式在多样化的微分方程（DE）上实现了始终优于最先进方法的精度，使得DE的AI求解器在自然和工程领域真正可用。

Abstract: Many problems are governed by differential equations (DEs). Artificial
intelligence (AI) is a new path for solving DEs. However, data is very scarce
and existing AI solvers struggle with approximation of high frequency
components (AHFC). We propose an AI paradigm for solving diverse DEs, including
DE-ruled first-principles data generation methodology and scale-dilation
operator (SDO) AI solver. Using either prior knowledge or random fields, we
generate solutions and then substitute them into the DEs to derive the sources
and initial/boundary conditions through balancing DEs, thus producing
arbitrarily vast amount of, first-principles-consistent training datasets at
extremely low computational cost. We introduce a reversible SDO that leverages
the Fourier transform of the multiscale solutions to fix AHFC, and design a
spatiotemporally coupled, attention-based Transformer AI solver of DEs with
SDO. An upper bound on the Hessian condition number of the loss function is
proven to be proportional to the squared 2-norm of the solution gradient,
revealing that SDO yields a smoother loss landscape, consequently fixing AHFC
with efficient training. Extensive tests on diverse DEs demonstrate that our AI
paradigm achieves consistently superior accuracy over state-of-the-art methods.
This work makes AI solver of DEs to be truly usable in broad nature and
engineering fields.

</details>


### [305] [FuseTen: A Generative Model for Daily 10 m Land Surface Temperature Estimation from Spatio-Temporal Satellite Observations](https://arxiv.org/abs/2507.23154)
*Sofiane Bouaziz,Adel Hafiane,Raphael Canals,Rachid Nedjai*

Main category: cs.LG

TL;DR: FuseTen通过融合多源卫星数据，生成了每日10米分辨率的地表温度数据，解决了卫星数据在空间和时间分辨率上的限制，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 城市热浪、干旱和土地退化是气候变化背景下日益严峻的挑战。为了有效研究这些现象，需要精确的时空土地表面状况信息。地表温度（LST）是评估和理解这些现象的最重要变量之一，它能提供地球表面热状态的关键信息。然而，卫星平台在空间和时间分辨率之间存在固有的权衡。为了解决这个差距，本研究提出了FuseTen。

Method: FuseTen框架采用生成架构，并结合了注意力机制和归一化模块进行数据融合。它使用基于平均的监督策略，该策略以物理原理为基础进行训练，并利用PatchGAN判别器来保证生成数据的真实性。

Result: FuseTen能够生成每日10米分辨率的LST数据，实验结果表明，与线性基线相比，FuseTen在定量指标上平均提高了32.06%，在视觉保真度上提高了31.42%。

Conclusion: FuseTen是一种新颖的生成框架，通过融合来自Sentinel-2、Landsat 8和Terra MODIS的时空观测数据，生成精细的10米空间分辨率的每日地表温度（LST）观测数据。该方法在多个日期进行了实验，在定量指标和视觉保真度方面均优于线性基线，分别提高了32.06%和31.42%。FuseTen是首个能够生成如此精细空间分辨率的每日LST估算值的非线性方法。

Abstract: Urban heatwaves, droughts, and land degradation are pressing and growing
challenges in the context of climate change. A valuable approach to studying
them requires accurate spatio-temporal information on land surface conditions.
One of the most important variables for assessing and understanding these
phenomena is Land Surface Temperature (LST), which is derived from satellites
and provides essential information about the thermal state of the Earth's
surface. However, satellite platforms inherently face a trade-off between
spatial and temporal resolutions. To bridge this gap, we propose FuseTen, a
novel generative framework that produces daily LST observations at a fine 10 m
spatial resolution by fusing spatio-temporal observations derived from
Sentinel-2, Landsat 8, and Terra MODIS. FuseTen employs a generative
architecture trained using an averaging-based supervision strategy grounded in
physical principles. It incorporates attention and normalization modules within
the fusion process and uses a PatchGAN discriminator to enforce realism.
Experiments across multiple dates show that FuseTen outperforms linear
baselines, with an average 32.06% improvement in quantitative metrics and
31.42% in visual fidelity. To the best of our knowledge, this is the first
non-linear method to generate daily LST estimates at such fine spatial
resolution.

</details>


### [306] [BAR Conjecture: the Feasibility of Inference Budget-Constrained LLM Services with Authenticity and Reasoning](https://arxiv.org/abs/2507.23170)
*Jinan Zhou,Rajat Ghosh,Vaishnavi Bhargava,Debojyoti Dutta,Aryan Singhal*

Main category: cs.LG

TL;DR: LLM 服务设计中，推理时间、事实真实性和推理能力三者不可兼得，The BAR Theorem 为 LLM 应用设计提供了原则性框架。


<details>
  <summary>Details</summary>
Motivation: 在设计 LLM 服务时，从业者关心三个关键属性：推理时间预算、事实真实性和推理能力。

Method: 提出一个名为 The BAR Theorem 的原则性框架，用于 LLM 应用程序设计。

Result: 证明了不存在可以同时优化这三个属性的模型。

Conclusion: 没有模型可以同时优化推理时间预算、事实真实性和推理能力这三个关键属性。

Abstract: When designing LLM services, practitioners care about three key properties:
inference-time budget, factual authenticity, and reasoning capacity. However,
our analysis shows that no model can simultaneously optimize for all three. We
formally prove this trade-off and propose a principled framework named The BAR
Theorem for LLM-application design.

</details>


### [307] [NaN-Propagation: A Novel Method for Sparsity Detection in Black-Box Computational Functions](https://arxiv.org/abs/2507.23186)
*Peter Sharpe*

Main category: cs.LG

TL;DR: 提出了一种基于NaN传播的新方法，用于检测黑盒函数中的稀疏性，解决了现有方法的假阴性问题，并在实际应用中取得了显著的加速效果。


<details>
  <summary>Details</summary>
Motivation: 现有有限差分法在检测黑盒函数稀疏性时存在假阴性问题，可能导致梯度计算错误且难以诊断。

Method: 提出了一种名为NaN传播（NaN-propagation）的新方法，该方法通过系统性地污染输入值（使其变为NaN）并观察哪些输出值也变为NaN，来重建保守的稀疏性模式。

Result: 在航空航天翼重模型上实现了1.52倍的加速，并检测出许多传统方法未能发现的依赖关系。该方法利用IEEE 754标准，无需修改现有黑盒代码，并可通过NaN payload encoding等高级策略实现优于现有方法的稀疏性检测速度。

Conclusion: 该方法通过利用IEEE 754的NaN（Not-a-Number）属性来追踪输入-输出依赖关系，可以有效检测黑盒函数中的稀疏性，消除现有有限差分法中的假阴性问题，并在航空航天翼重模型上实现了1.52倍的加速，同时发现了许多传统方法忽略的依赖关系。

Abstract: Sparsity detection in black-box functions enables significant computational
speedups in gradient-based optimization through Jacobian compression, but
existing finite-difference methods suffer from false negatives due to
coincidental zero gradients. These false negatives can silently corrupt
gradient calculations, leading to difficult-to-diagnose errors. We introduce
NaN-propagation, which exploits the universal contamination property of IEEE
754 Not-a-Number floating-point values to trace input-output dependencies
through floating-point numerical computations. By systematically contaminating
inputs with NaN and observing which outputs become NaN, the method reconstructs
conservative sparsity patterns that eliminate false negatives. We demonstrate
the approach on an aerospace wing weight model, achieving a 1.52x speedup while
detecting dozens of dependencies missed by conventional methods -- a
significant improvement since gradient computation is the bottleneck in many
optimization workflows. The technique leverages IEEE 754 compliance to work
across programming languages and math libraries without modifying existing
black-box codes. Advanced strategies including NaN payload encoding enable
faster-than-linear time complexity, improving upon existing black-box sparsity
detection methods. Practical algorithms are also proposed to mitigate
challenges from branching code execution common in engineering applications.

</details>


### [308] [Zero-Shot Document Understanding using Pseudo Table of Contents-Guided Retrieval-Augmented Generation](https://arxiv.org/abs/2507.23217)
*Hyeon Seong Jeong,Sangwoo Jo,Byeong Hyun Yoon,Yoonseok Heo,Haedong Jeong,Taehoon Kim*

Main category: cs.LG

TL;DR: DocsRay是一个无需训练的多模态文档理解系统，通过伪目录和分层RAG提高了处理效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 为了应对复杂多模态文档在结构不一致和训练数据有限方面的挑战。

Method: DocsRay系统整合了伪目录生成和分层检索增强生成（RAG）。它利用多模态大语言模型（LLMs）的原生能力，通过提示驱动的LLM交互生成伪目录，并使用零样本多模态分析将各种文档元素转换为以文本为中心的统一表示。此外，它采用了一个高效的两阶段分层检索系统。

Result: DocsRay将查询延迟从3.89秒减少到2.12秒，实现了45%的效率提升。在MMLongBench-Doc基准测试中，DocsRay-Pro的准确率为64.7%，大幅超越了之前的最先进水平。

Conclusion: DocsRay是一个创新的、无需训练的文档理解系统，通过伪目录生成和分层检索增强生成（RAG）的结合，能够有效处理包含文本、图像、图表和表格等多种元素的多模态文档。该系统在MMLongBench-Doc基准测试中取得了64.7%的准确率，显著优于现有技术。

Abstract: Understanding complex multimodal documents remains challenging due to their
structural inconsistencies and limited training data availability. We introduce
\textit{DocsRay}, a training-free document understanding system that integrates
pseudo Table of Contents (TOC) generation with hierarchical Retrieval-Augmented
Generation (RAG). Our approach leverages multimodal Large Language Models'
(LLMs) native capabilities to seamlessly process documents containing diverse
elements such as text, images, charts, and tables without requiring specialized
models or additional training. DocsRay's framework synergistically combines
three key techniques: (1) a semantic structuring module using prompt-based LLM
interactions to generate a hierarchical pseudo-TOC, (2) zero-shot multimodal
analysis that converts diverse document elements into unified, text-centric
representations using the inherent capabilities of multimodal LLMs, and (3) an
efficient two-stage hierarchical retrieval system that reduces retrieval
complexity from $O(N)$ to $O(S + k_1 \cdot N_s)$. Evaluated on documents
averaging 49.4 pages and 20,971 textual tokens, DocsRay reduced query latency
from 3.89 to 2.12 seconds, achieving a 45% efficiency improvement. On the
MMLongBench-Doc benchmark, DocsRay-Pro attains an accuracy of 64.7%,
substantially surpassing previous state-of-the-art results.

</details>


### [309] [A Single Direction of Truth: An Observer Model's Linear Residual Probe Exposes and Steers Contextual Hallucinations](https://arxiv.org/abs/2507.23221)
*Charles O'Neill,Slava Chalnev,Chi Chi Zhao,Max Kirkby,Mudith Jayasekara*

Main category: cs.LG

TL;DR: 研究提出了一种通过线性探针检测AI幻觉的新方法，该方法在Gemma-2模型上表现优异，并能因果地控制幻觉率，同时发布了ContraTales数据集。


<details>
  <summary>Details</summary>
Motivation: 幻觉（即AI生成的、不支持给定上下文的陈述）仍然是AI领域的一个重大挑战。本研究旨在提供一个实际的可解释性见解，以检测和缓解AI中的幻觉问题。

Method: 研究提出了一种利用生成器无关的观察模型，通过在模型残差流上进行线性探测来检测幻觉。该方法通过梯度-激活（gradient-times-activation）将信号定位到稀疏的、晚期MLP活动。最后，通过操纵这个检测到的线性方向来因果地影响生成器的幻觉率。

Result: 该研究提出的线性探针方法在检测幻觉方面比基线方法提高了5-27个百分点，并且在Gemma-2模型（2B到27B）上表现出稳健的中间层性能。研究还发现了幻觉信号与稀疏的、晚期MLP活动相关，并且通过操纵该信号可以因果地改变幻觉率。此外，研究发布了一个包含2000个样本的ContraTales基准数据集，用于评估相关解决方案。

Conclusion: 该研究为AI中的幻觉问题提供了一个可解释的见解，即可以通过一个与生成器无关的观察模型，利用其残差流上的线性探针来检测幻觉。该探针能够分离出幻觉和忠实文本的单一、可转移的线性方向，并且在Gemma-2模型上表现出稳健的性能。梯度激活时间定位了信号到稀疏的、晚期MLP活动。更重要的是，通过操纵这个方向可以因果地影响生成器的幻觉率，证明了其可操作性。研究结果为幻觉的内部、低维追踪提供了新的证据，并将其与特定的MLP子电路联系起来，可用于检测和缓解。

Abstract: Contextual hallucinations -- statements unsupported by given context --
remain a significant challenge in AI. We demonstrate a practical
interpretability insight: a generator-agnostic observer model detects
hallucinations via a single forward pass and a linear probe on its residual
stream. This probe isolates a single, transferable linear direction separating
hallucinated from faithful text, outperforming baselines by 5-27 points and
showing robust mid-layer performance across Gemma-2 models (2B to 27B).
Gradient-times-activation localises this signal to sparse, late-layer MLP
activity. Critically, manipulating this direction causally steers generator
hallucination rates, proving its actionability. Our results offer novel
evidence of internal, low-dimensional hallucination tracking linked to specific
MLP sub-circuits, exploitable for detection and mitigation. We release the
2000-example ContraTales benchmark for realistic assessment of such solutions.

</details>


### [310] [Efficient Machine Unlearning via Influence Approximation](https://arxiv.org/abs/2507.23257)
*Jiawei Liu,Chenwang Wu,Defu Lian,Enhong Chen*

Main category: cs.LG

TL;DR: 本研究提出了一种名为IAU的机器遗忘算法，该算法受认知科学启发，通过将遗忘与增量学习联系起来，大大降低了计算成本，同时在遗忘效果和模型性能上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于影响的机器遗忘方法计算成本高昂，难以应用于大规模模型和频繁数据删除的场景。

Method: 受认知科学启发，将遗忘（机器遗忘）问题与记忆（增量学习）联系起来，提出IAU算法，该算法从增量学习的角度解决机器遗忘问题，避免了计算Hessian矩阵及其逆的计算开销，使用更高效的梯度优化方法。

Result: IAU算法在移除保证、遗忘效率和模型效用方面取得了优于现有方法的平衡，并在各种数据集和模型架构上得到了验证。

Conclusion: 本研究通过建立增量学习与遗忘之间的理论联系，提出了IAU算法，该算法在保证移除效果、遗忘效率和模型效用之间取得了更好的平衡，并且在各种数据集和模型架构上均优于现有方法。

Abstract: Due to growing privacy concerns, machine unlearning, which aims at enabling
machine learning models to ``forget" specific training data, has received
increasing attention. Among existing methods, influence-based unlearning has
emerged as a prominent approach due to its ability to estimate the impact of
individual training samples on model parameters without retraining. However,
this approach suffers from prohibitive computational overhead arising from the
necessity to compute the Hessian matrix and its inverse across all training
samples and parameters, rendering it impractical for large-scale models and
scenarios involving frequent data deletion requests. This highlights the
difficulty of forgetting. Inspired by cognitive science, which suggests that
memorizing is easier than forgetting, this paper establishes a theoretical link
between memorizing (incremental learning) and forgetting (unlearning). This
connection allows machine unlearning to be addressed from the perspective of
incremental learning. Unlike the time-consuming Hessian computations in
unlearning (forgetting), incremental learning (memorizing) typically relies on
more efficient gradient optimization, which supports the aforementioned
cognitive theory. Based on this connection, we introduce the Influence
Approximation Unlearning (IAU) algorithm for efficient machine unlearning from
the incremental perspective. Extensive empirical evaluations demonstrate that
IAU achieves a superior balance among removal guarantee, unlearning efficiency,
and comparable model utility, while outperforming state-of-the-art methods
across diverse datasets and model architectures. Our code is available at
https://github.com/Lolo1222/IAU.

</details>


### [311] [Evaluating the Dynamics of Membership Privacy in Deep Learning](https://arxiv.org/abs/2507.23291)
*Yuetian Chen,Zhiqi Wang,Nathalie Baracaldo,Swanand Ravindra Kadhe,Lei Yu*

Main category: cs.LG

TL;DR: 该研究提出了一个分析框架，用于在训练过程中量化单个样本的隐私泄露。研究发现，样本的学习难度与其隐私风险相关，而风险主要在早期训练阶段确定，这有助于制定更主动的隐私保护策略。


<details>
  <summary>Details</summary>
Motivation: 虽然在攻击方法方面取得了重大进展，但我们对于模型在训练过程中何时以及如何编码成员信息仍然知之甚少。

Method: 提出一个动态分析框架，用于在单个样本级别剖析和量化隐私泄露动态。通过在训练过程中跟踪FPR-TPR平面上每个样本的漏洞，该框架系统地测量数据集复杂性、模型架构和优化器选择等因素如何影响样本易受攻击的比率和严重程度。

Result: 研究发现样本的内在学习难度与隐私风险之间存在稳健的相关性，并且在最终训练模型中高度易受攻击的样本的隐私风险在很大程度上由训练早期决定。

Conclusion: 该研究结果提供了对隐私风险在训练过程中动态出现的更深入的理解，为主动、注重隐私的模型训练策略奠定了基础。

Abstract: Membership inference attacks (MIAs) pose a critical threat to the privacy of
training data in deep learning. Despite significant progress in attack
methodologies, our understanding of when and how models encode membership
information during training remains limited. This paper presents a dynamic
analytical framework for dissecting and quantifying privacy leakage dynamics at
the individual sample level. By tracking per-sample vulnerabilities on an
FPR-TPR plane throughout training, our framework systematically measures how
factors such as dataset complexity, model architecture, and optimizer choice
influence the rate and severity at which samples become vulnerable. Crucially,
we discover a robust correlation between a sample's intrinsic learning
difficulty, and find that the privacy risk of samples highly vulnerable in the
final trained model is largely determined early during training. Our results
thus provide a deeper understanding of how privacy risks dynamically emerge
during training, laying the groundwork for proactive, privacy-aware model
training strategies.

</details>


### [312] [SequenceLayers: Sequence Processing and Streaming Neural Networks Made Easy](https://arxiv.org/abs/2507.23292)
*RJ Skerry-Ryan,Julian Salazar,Soroosh Mariooryad,David Kao,Daisy Stanton,Eric Battenberg,Matt Shannon,Ron J. Weiss,Robin Scheibler,Jonas Rothfuss,Tom Bagby*

Main category: cs.LG

TL;DR: A new API and library (SequenceLayers) for building sequence models that are easier to create, streamable, and less buggy, usable in any deep learning framework.


<details>
  <summary>Details</summary>
Motivation: To facilitate the easy creation of sequence models that can be executed both layer-by-layer (e.g., teacher-forced training) and step-by-step (e.g., autoregressive sampling), while mitigating common bugs in sequence processing.

Method: Introduces a neural network layer API and library for sequence modeling, defining explicit state representations and a step method for time evolution, allowing both layer-by-layer and step-by-step execution.

Result: Enables complex models to be immediately streamable, mitigates a wide range of common bugs, and streamlines the construction of production-scale models with strong correctness guarantees.

Conclusion: SequenceLayers API and library enables easy creation, streamable execution, and bug mitigation for sequence models, applicable to any deep learning library.

Abstract: We introduce a neural network layer API and library for sequence modeling,
designed for easy creation of sequence models that can be executed both
layer-by-layer (e.g., teacher-forced training) and step-by-step (e.g.,
autoregressive sampling). To achieve this, layers define an explicit
representation of their state over time (e.g., a Transformer KV cache, a
convolution buffer, an RNN hidden state), and a step method that evolves that
state, tested to give identical results to a stateless layer-wise invocation.
This and other aspects of the SequenceLayers contract enables complex models to
be immediately streamable, mitigates a wide range of common bugs arising in
both streaming and parallel sequence processing, and can be implemented in any
deep learning library. A composable and declarative API, along with a
comprehensive suite of layers and combinators, streamlines the construction of
production-scale models from simple streamable components while preserving
strong correctness guarantees. Our current implementations of SequenceLayers
(JAX, TensorFlow 2) are available at https://github.com/google/sequence-layers.

</details>


### [313] [Policy Learning from Large Vision-Language Model Feedback without Reward Modeling](https://arxiv.org/abs/2507.23391)
*Tung M. Luu,Donghoon Lee,Younghwan Lee,Chang D. Yoo*

Main category: cs.LG

TL;DR: PLARE”是一种新颖的离线强化学习方法，它利用视觉-语言模型（VLMs）来提供奖励信号，无需手动设计奖励函数。实验证明，PLARE在机器人操作任务上取得了优越的性能。


<details>
  <summary>Details</summary>
Motivation: 由于手动设计奖励函数成本高昂、耗时且需要专业知识，因此离线强化学习（RL）在机器人领域面临挑战。需要一种无需手动设计奖励函数的方法。

Method: PLARE”利用大型视觉-语言模型（VLMs）为代理训练提供引导信号。它不依赖于手动设计的奖励函数，而是根据语言任务描述，从VLM查询视觉轨迹片段对的偏好标签。然后，策略直接从这些偏好标签使用监督对比偏好学习目标进行训练，绕过了学习显式奖励模型的需求。

Result: PLARE”在MetaWorld的机器人操作任务上取得了与最先进的基于VLM的奖励生成方法相当或更优的性能。此外，PLARE在物理机器人的实际操作任务中也显示了其有效性。

Conclusion: PLARE”在MetaWorld的机器人操作任务上取得了与最先进的基于VLM的奖励生成方法相当或更优的性能。此外，PLARE在物理机器人的实际操作任务中也显示了其有效性，进一步验证了其实际适用性。

Abstract: Offline reinforcement learning (RL) provides a powerful framework for
training robotic agents using pre-collected, suboptimal datasets, eliminating
the need for costly, time-consuming, and potentially hazardous online
interactions. This is particularly useful in safety-critical real-world
applications, where online data collection is expensive and impractical.
However, existing offline RL algorithms typically require reward labeled data,
which introduces an additional bottleneck: reward function design is itself
costly, labor-intensive, and requires significant domain expertise. In this
paper, we introduce PLARE, a novel approach that leverages large
vision-language models (VLMs) to provide guidance signals for agent training.
Instead of relying on manually designed reward functions, PLARE queries a VLM
for preference labels on pairs of visual trajectory segments based on a
language task description. The policy is then trained directly from these
preference labels using a supervised contrastive preference learning objective,
bypassing the need to learn explicit reward models. Through extensive
experiments on robotic manipulation tasks from the MetaWorld, PLARE achieves
performance on par with or surpassing existing state-of-the-art VLM-based
reward generation methods. Furthermore, we demonstrate the effectiveness of
PLARE in real-world manipulation tasks with a physical robot, further
validating its practical applicability.

</details>


### [314] [An Interpretable Data-Driven Unsupervised Approach for the Prevention of Forgotten Items](https://arxiv.org/abs/2507.23303)
*Luca Corbucci,Javier Alejandro Borges Legrottaglie,Francesco Spinnato,Anna Monreale,Riccardo Guidotti*

Main category: cs.LG

TL;DR: 该研究提出了被遗忘物品预测任务，并设计了可解释的算法，在真实数据集上效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有NBP方法未能解决被遗忘物品的识别和解释问题，且缺乏包含被遗忘物品信息的真实数据集。

Method: 提出两种新颖的可解释算法来识别被遗忘物品并提供解释。

Result: 提出的算法在真实零售数据集上，在多个评估指标上均优于最先进的NBP基线10-15%。

Conclusion: 该研究首次提出了被遗忘物品预测任务，并提供了两种新颖的可解释算法，在真实零售数据集上，实验结果显示该算法在多个评估指标上均优于最先进的NBP基线10-15%。

Abstract: Accurately identifying items forgotten during a supermarket visit and
providing clear, interpretable explanations for recommending them remains an
underexplored problem within the Next Basket Prediction (NBP) domain. Existing
NBP approaches typically only focus on forecasting future purchases, without
explicitly addressing the detection of unintentionally omitted items. This gap
is partly due to the scarcity of real-world datasets that allow for the
reliable estimation of forgotten items. Furthermore, most current NBP methods
rely on black-box models, which lack transparency and limit the ability to
justify recommendations to end users. In this paper, we formally introduce the
forgotten item prediction task and propose two novel interpretable-by-design
algorithms. These methods are tailored to identify forgotten items while
offering intuitive, human-understandable explanations. Experiments on a
real-world retail dataset show our algorithms outperform state-of-the-art NBP
baselines by 10-15% across multiple evaluation metrics.

</details>


### [315] [Good Learners Think Their Thinking: Generative PRM Makes Large Reasoning Model More Efficient Math Learner](https://arxiv.org/abs/2507.23317)
*Tao He,Rongchuan Mu,Lizi Liao,Yixin Cao,Ming Liu,Bing Qin*

Main category: cs.LG

TL;DR: 通过引入基于思想过程的奖励和能力自适应奖励机制，加速了大型推理模型（LRM）在数学推理任务上的优化过程，提高了训练效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于RL的优化方法依赖于结果奖励，这种奖励提供的反馈稀疏，导致优化效率低下。

Method: 提出了一种新颖的、由内在信号驱动的生成过程评估机制，该机制在思想层面运行，以解决基于RL的训练中的主要瓶颈。该方法不要求PRM知道如何解决问题，而是利用解决方案中的内在信号来判断步骤的正确性，并将连续的正确/不正确步骤聚合成连贯的“思想”单元。此外，还引入了一种能力自适应奖励机制，该机制根据LRM的当前熟练程度动态地平衡探索和利用。这些创新被集成到一个新的非策略RL算法TP-GRPO中，该算法扩展了具有基于过程的奖励的分组近邻优化。

Result: 实验表明，所提出的方法在1.5B和7B参数的LRM上，实现了更高的解决问题准确性，并且所需的训练样本显著少于仅基于结果奖励的基线方法。

Conclusion: 通过在数学推理任务中引入结构化的、基于思想过程的奖励和能力自适应奖励机制，显著加速了大型推理模型（LRM）的优化过程。

Abstract: Large reasoning models (LRMs) have recently shown promise in solving complex
math problems when optimized with Reinforcement Learning (RL). But conventional
approaches rely on outcome-only rewards that provide sparse feedback, resulting
in inefficient optimization process. In this work, we investigate the function
of process reward models (PRMs) to accelerate the RL training for LRMs. We
propose a novel intrinsic signal-driven generative process evaluation mechanism
operating at the thought level to address major bottlenecks in RL-based
training. Specifically, instead of requiring PRMs to know how to solve
problems, our method uses intrinsic signals in solutions to judge stepwise
correctness and aggregate contiguous correct/incorrect steps into coherent
'thought' units. This structured, thought-level rewards enable more reliable
credit assignment by reducing ambiguity in step segmentation and alleviating
reward hacking. We further introduce a capability-adaptive reward mechanism
that dynamically balances exploration and exploitation based on the LRM's
current proficiency, guiding learning without stifling creative
trial-and-error. These innovations are integrated into a new off-policy RL
algorithm, TP-GRPO, which extends grouped proximal optimization with
process-based rewards and improves training efficiency. Experiments on 1.5B and
7B parameter LRMs demonstrate that our method achieves higher problem-solving
accuracy with significantly fewer training samples than outcome-only reward
baselines. The results validate that well-structured process rewards can
substantially accelerate LRM optimization in math reasoning tasks. Code is
available at https://github.com/cs-holder/tp_grpo.

</details>


### [316] [Scalable and Precise Patch Robustness Certification for Deep Learning Models with Top-k Predictions](https://arxiv.org/abs/2507.23335)
*Qilin Zhou,Haipeng Wang,Zhengyuan Wei,W. K. Chan*

Main category: cs.LG

TL;DR: CostCert 是一种新的、可扩展的、精确的基于投票的认证恢复防御方法，可以解决现有方法在处理顶级 k 个预测时的不足之处，并在实验中表现出优于 PatchGuard 的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的认证恢复技术在应用于顶级 k 个预测时，通常会比较标签之间的投票数，但这种方法容易受到攻击者操纵投票数的影响，并且穷举所有投票组合会导致组合爆炸问题。

Method: CostCert 通过检查攻击预算是否不足以覆盖排除真实标签所需的最小额外投票数来实现这一点。

Result: 实验表明，CostCert 的性能显著优于现有的 PatchGuard  वापरा，例如在补丁大小为 96 时，其认证准确率最高可达 57.3%，而 PatchGuard 的准确率已降至零。

Conclusion: CostCert 能够为深度学习系统提供一种新颖、可扩展且精确的基于投票的认证恢复防御方法，该方法可以准确地在顶级 k 个预测标签中验证真实标签，而无需进行成对比较或处理组合爆炸问题。

Abstract: Patch robustness certification is an emerging verification approach for
defending against adversarial patch attacks with provable guarantees for deep
learning systems. Certified recovery techniques guarantee the prediction of the
sole true label of a certified sample. However, existing techniques, if
applicable to top-k predictions, commonly conduct pairwise comparisons on those
votes between labels, failing to certify the sole true label within the top k
prediction labels precisely due to the inflation on the number of votes
controlled by the attacker (i.e., attack budget); yet enumerating all
combinations of vote allocation suffers from the combinatorial explosion
problem. We propose CostCert, a novel, scalable, and precise voting-based
certified recovery defender. CostCert verifies the true label of a sample
within the top k predictions without pairwise comparisons and combinatorial
explosion through a novel design: whether the attack budget on the sample is
infeasible to cover the smallest total additional votes on top of the votes
uncontrollable by the attacker to exclude the true labels from the top k
prediction labels. Experiments show that CostCert significantly outperforms the
current state-of-the-art defender PatchGuard, such as retaining up to 57.3% in
certified accuracy when the patch size is 96, whereas PatchGuard has already
dropped to zero.

</details>


### [317] [Causal Explanation of Concept Drift -- A Truly Actionable Approach](https://arxiv.org/abs/2507.23389)
*David Komnick,Kathrin Lammers,Barbara Hammer,Valerie Vaquet,Fabian Hinder*

Main category: cs.LG

TL;DR: 提出了一种将基于模型的漂移解释扩展为因果解释的方法，以更好地理解和干预概念漂移对工业制造和关键基础设施等系统的影响。


<details>
  <summary>Details</summary>
Motivation: 解释机器学习中的概念漂移对于实现针对性干预至关重要，以避免模型故障以及物理世界中的故障和错误。

Method: 将基于模型的漂移解释扩展到因果解释，以提高解释的可操作性。

Result: 在多个用例上评估了因果解释策略，证明了其在隔离因果相关特征和实现有针对性干预方面的实用性。

Conclusion: 通过隔离受概念漂移影响的因果相关特征，该框架能够实现有针对性的干预。

Abstract: In a world that constantly changes, it is crucial to understand how those
changes impact different systems, such as industrial manufacturing or critical
infrastructure. Explaining critical changes, referred to as concept drift in
the field of machine learning, is the first step towards enabling targeted
interventions to avoid or correct model failures, as well as malfunctions and
errors in the physical world. Therefore, in this work, we extend model-based
drift explanations towards causal explanations, which increases the
actionability of the provided explanations. We evaluate our explanation
strategy on a number of use cases, demonstrating the practical usefulness of
our framework, which isolates the causally relevant features impacted by
concept drift and, thus, allows for targeted intervention.

</details>


### [318] [A Machine Learning Approach for Honey Adulteration Detection using Mineral Element Profiles](https://arxiv.org/abs/2507.23412)
*Mokhtar A. Al-Awadhi,Ratnadeep R. Deshmukh*

Main category: cs.LG

TL;DR: 本文利用机器学习技术，通过分析蜂蜜的矿物质元素含量，成功开发出一种蜂蜜掺假检测系统。该系统在区分纯净蜂蜜和掺假蜂蜜方面表现出色，其中随机森林模型准确率高达98.37%。


<details>
  <summary>Details</summary>
Motivation: 本文旨在开发一个基于机器学习（ML）的系统，利用蜂蜜矿物质元素特征来检测蜂蜜掺假。

Method: 该系统包含预处理和分类两个阶段。预处理阶段包括缺失值属性处理和归一化。分类阶段使用三种监督学习模型：逻辑回归、决策树和随机森林，以区分纯净蜂蜜和掺假蜂蜜。

Result: 实验结果表明，蜂蜜的矿物质元素含量为检测蜂蜜掺假提供了可靠的区分信息。结果还表明，基于随机森林的分类器在该数据集上表现优于其他分类器，实现了98.37%的最高交叉验证准确率。

Conclusion: 研究结果表明，蜂蜜的矿物质元素含量为检测蜂蜜掺假提供了可靠的区分信息，并且随机森林分类器在该数据集上表现优于其他分类器，实现了98.37%的最高交叉验证准确率。

Abstract: This paper aims to develop a Machine Learning (ML)-based system for detecting
honey adulteration utilizing honey mineral element profiles. The proposed
system comprises two phases: preprocessing and classification. The
preprocessing phase involves the treatment of missing-value attributes and
normalization. In the classifica-tion phase, we use three supervised ML models:
logistic regression, decision tree, and random forest, to dis-criminate between
authentic and adulterated honey. To evaluate the performance of the ML models,
we use a public dataset comprising measurements of mineral element content of
authentic honey, sugar syrups, and adul-terated honey. Experimental findings
show that mineral element content in honey provides robust discriminative
information for detecting honey adulteration. Results also demonstrate that the
random forest-based classifier outperforms other classifiers on this dataset,
achieving the highest cross-validation accuracy of 98.37%.

</details>


### [319] [Detection of Adulteration in Coconut Milk using Infrared Spectroscopy and Machine Learning](https://arxiv.org/abs/2507.23418)
*Mokhtar A. Al-Awadhi,Ratnadeep R. Deshmukh*

Main category: cs.LG

TL;DR: 使用红外光谱和机器学习（LDA、KNN）检测椰奶掺假，准确率达 93.33%。


<details>
  <summary>Details</summary>
Motivation: 提出一个利用红外光谱检测椰奶掺假的系统。

Method: 该系统包括三个阶段：预处理、特征提取和分类。第一阶段涉及从椰奶光谱信号中去除不相关数据。第二阶段，我们采用线性判别分析（LDA）算法提取最具区分性的特征。第三阶段，我们使用 K 最近邻（KNN）模型将椰奶样品分为纯品或掺假品。

Result: 使用包含纯椰奶和受污染椰奶样品傅里叶变换红外（FTIR）光谱信息的公共数据集评估了该系统的性能。

Conclusion: 该方法成功检测到掺假，交叉验证准确率为 93.33%。

Abstract: In this paper, we propose a system for detecting adulteration in coconut
milk, utilizing infrared spectroscopy. The machine learning-based proposed
system comprises three phases: preprocessing, feature extraction, and
classification. The first phase involves removing irrelevant data from coconut
milk spectral signals. In the second phase, we employ the Linear Discriminant
Analysis (LDA) algorithm for extracting the most discriminating features. In
the third phase, we use the K-Nearest Neighbor (KNN) model to classify coconut
milk samples into authentic or adulterated. We evaluate the performance of the
proposed system using a public dataset comprising Fourier Transform Infrared
(FTIR) spectral information of pure and contaminated coconut milk samples.
Findings show that the proposed method successfully detects adulteration with a
cross-validation accuracy of 93.33%.

</details>


### [320] [Merging Memory and Space: A Spatiotemporal State Space Neural Operator](https://arxiv.org/abs/2507.23428)
*Nodens F. Koren,Samuel Lanthaler*

Main category: cs.LG

TL;DR: 提出了一种名为ST-SSM的新型紧凑型架构，用于学习时变偏微分方程的解算子。该架构通过分解时空维度并使用结构化状态空间模型，实现了参数效率和对长程时空动力学的灵活建模。理论上，ST-SSM与神经算子之间建立了联系，并证明了一个统一的普遍性定理。实验证明，ST-SSM在多个偏微分方程基准测试中优于现有方法，并且在参数量减少的情况下表现出色，同时在部分可观测性下也显示出性能提升。


<details>
  <summary>Details</summary>
Motivation: 为了学习时变偏微分方程的解算子，并克服现有方法的局限性。

Method: 提出了一种新颖的Spatiotemporal State Space Neural Operator (ST-SSM)架构，通过对时空维度进行分解，并利用结构化状态空间模型独立建模时间演化和空间相互作用，实现了参数高效和长程时空动力学的灵活建模。

Result: 在1D Burgers方程、1D Kuramoto-Sivashinsky方程和2D Navier-Stokes方程等多个偏微分方程基准测试中，ST-SSM的因子化方法优于其他方案，并且在参数量显著减少的情况下，表现与现有基线模型相当。此外，该模型在部分可观测性下表现出性能提升，验证了时间记忆的优势。

Conclusion: ST-SSM架构在参数效率、可扩展性和准确性方面表现出色，能够处理各种时变偏微分方程。

Abstract: We propose the Spatiotemporal State Space Neural Operator (ST-SSM), a compact
architecture for learning solution operators of time-dependent partial
differential equations (PDEs). ST-SSM introduces a novel factorization of the
spatial and temporal dimensions, using structured state-space models to
independently model temporal evolution and spatial interactions. This design
enables parameter efficiency and flexible modeling of long-range spatiotemporal
dynamics. A theoretical connection is established between SSMs and neural
operators, and a unified universality theorem is proved for the resulting class
of architectures. Empirically, we demonstrate that our factorized formulation
outperforms alternative schemes such as zigzag scanning and parallel
independent processing on several PDE benchmarks, including 1D Burgers'
equation, 1D Kuramoto-Sivashinsky equation, and 2D Navier-Stokes equations
under varying physical conditions. Our model performs competitively with
existing baselines while using significantly fewer parameters. In addition, our
results reinforce previous findings on the benefits of temporal memory by
showing improved performance under partial observability. Our results highlight
the advantages of dimensionally factorized operator learning for efficient and
generalizable PDE modeling, and put this approach on a firm theoretical
footing.

</details>


### [321] [Coflex: Enhancing HW-NAS with Sparse Gaussian Processes for Efficient and Scalable DNN Accelerator Design](https://arxiv.org/abs/2507.23437)
*Yinhui Ma,Tomomasa Yamasaki,Zhehui Wang,Tao Luo,Bo Wang*

Main category: cs.LG

TL;DR: Coflex是一个新的HW-NAS框架，通过使用稀疏高斯过程（SGP）和多目标贝叶斯优化来降低计算成本，同时保持高性能。


<details>
  <summary>Details</summary>
Motivation: 解决HW-NAS搜索空间大和计算成本高的问题，以实现边缘深度神经网络加速器的实际应用。

Method: 通过集成稀疏高斯过程（SGP）和多目标贝叶斯优化来解决硬件感知神经架构搜索（HW-NAS）的计算成本挑战。

Result: Coflex在网络精度和能耗延迟积方面优于最先进的方法，并实现了1.9倍到9.5倍的计算加速。

Conclusion: Coflex框架在网络精度和能耗延迟积方面优于最先进的方法，同时实现了1.9倍到9.5倍的计算加速。

Abstract: Hardware-Aware Neural Architecture Search (HW-NAS) is an efficient approach
to automatically co-optimizing neural network performance and hardware energy
efficiency, making it particularly useful for the development of Deep Neural
Network accelerators on the edge. However, the extensive search space and high
computational cost pose significant challenges to its practical adoption. To
address these limitations, we propose Coflex, a novel HW-NAS framework that
integrates the Sparse Gaussian Process (SGP) with multi-objective Bayesian
optimization. By leveraging sparse inducing points, Coflex reduces the GP
kernel complexity from cubic to near-linear with respect to the number of
training samples, without compromising optimization performance. This enables
scalable approximation of large-scale search space, substantially decreasing
computational overhead while preserving high predictive accuracy. We evaluate
the efficacy of Coflex across various benchmarks, focusing on
accelerator-specific architecture. Our experi- mental results show that Coflex
outperforms state-of-the-art methods in terms of network accuracy and
Energy-Delay-Product, while achieving a computational speed-up ranging from
1.9x to 9.5x.

</details>


### [322] [Manifold-regularised Signature Kernel Large-Margin $\ell_p$-SVDD for Multidimensional Time Series Anomaly Detection](https://arxiv.org/abs/2507.23449)
*Shervin Rahimzadeh Arashloo*

Main category: cs.LG

TL;DR: 提出了一种改进的时间序列异常检测方法，结合了流行正则化和签名核，并在实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 利用数据分布的几何结构，通过流行正则化和签名核表示来改进时间序列异常检测。

Method: 提出了一种流行正则化变体$\\ell_p$-SVDD，并利用其签名核表示来捕获时间序列的复杂性，以进行异常检测。

Result: 提出的方法利用签名核来捕获时间序列的复杂性，以提高异常检测的性能。

Conclusion: 该方法通过Rademacher复杂度进行理论分析，并在各种数据集上进行实验评估，与其他方法进行性能比较。

Abstract: We generalise the recently introduced large-margin $\ell_p$-SVDD approach to
exploit the geometry of data distribution via manifold regularising and a
signature kernel representation for time series anomaly detection.
Specifically, we formulate a manifold-regularised variant of the $\ell_p$-SVDD
method to encourage label smoothness on the underlying manifold to capture
structural information for improved detection performance. Drawing on an
existing Representer theorem, we then provide an effective optimisation
technique for the proposed method and show that it can benefit from the
signature kernel to capture time series complexities for anomaly detection.
  We theoretically study the proposed approach using Rademacher complexities to
analyse its generalisation performance and also provide an experimental
assessment of the proposed method across various data sets to compare its
performance against other methods.

</details>


### [323] [Explainable artificial intelligence model predicting the risk of all-cause mortality in patients with type 2 diabetes mellitus](https://arxiv.org/abs/2507.23491)
*Olga Vershinina,Jacopo Sabbatinelli,Anna Rita Bonfigli,Dalila Colombaretti,Angelica Giuliani,Mikhail Krivonosov,Arseniy Trukhanov,Claudio Franceschi,Mikhail Ivanchenko,Fabiola Olivieri*

Main category: cs.LG

TL;DR: 这项研究开发了一个结合机器学习和SHAP的2型糖尿病全因死亡风险预测模型，结果显示该模型具有良好的预测能力和临床应用潜力。


<details>
  <summary>Details</summary>
Motivation: 2型糖尿病（T2DM）是一种高度流行的非传染性慢性病，显著降低了预期寿命。准确估计T2DM患者的全因死亡风险对于个性化和优化治疗策略至关重要。

Method: 本研究分析了一个包含554名（年龄40-87岁）已确诊的2型糖尿病患者的队列，随访期最长可达16.8年。研究确定了关键的生存相关特征，并训练和验证了多个机器学习（ML）模型来预测全因死亡风险。为了提高模型的可解释性，对表现最佳的模型应用了Shapley Additive Explanations（SHAP）。

Result: 结合十个关键特征的额外生存树（EST）模型表现出最佳的预测性能，C统计量为0.776，在5年、10年、15年和16.8年全因死亡风险预测中的AUC值分别为0.86、0.80、0.841和0.826。SHAP方法被用于解释模型个体化的决策过程。

Conclusion: 该模型在评估死亡风险方面表现出强大的预测能力。其临床可解释的输出有望应用于临床，改善高危患者的识别，并支持及时的治疗优化。

Abstract: Objective. Type 2 diabetes mellitus (T2DM) is a highly prevalent
non-communicable chronic disease that substantially reduces life expectancy.
Accurate estimation of all-cause mortality risk in T2DM patients is crucial for
personalizing and optimizing treatment strategies. Research Design and Methods.
This study analyzed a cohort of 554 patients (aged 40-87 years) with diagnosed
T2DM over a maximum follow-up period of 16.8 years, during which 202 patients
(36%) died. Key survival-associated features were identified, and multiple
machine learning (ML) models were trained and validated to predict all-cause
mortality risk. To improve model interpretability, Shapley additive
explanations (SHAP) was applied to the best-performing model. Results. The
extra survival trees (EST) model, incorporating ten key features, demonstrated
the best predictive performance. The model achieved a C-statistic of 0.776,
with the area under the receiver operating characteristic curve (AUC) values of
0.86, 0.80, 0.841, and 0.826 for 5-, 10-, 15-, and 16.8-year all-cause
mortality predictions, respectively. The SHAP approach was employed to
interpret the model's individual decision-making processes. Conclusions. The
developed model exhibited strong predictive performance for mortality risk
assessment. Its clinically interpretable outputs enable potential bedside
application, improving the identification of high-risk patients and supporting
timely treatment optimization.

</details>


### [324] [Incorporating structural uncertainty in causal decision making](https://arxiv.org/abs/2507.23495)
*Maurits Kaptein*

Main category: cs.LG

TL;DR: 从业者在做因果推断时，往往会忽略结构不确定性。本研究提出通过贝叶斯模型平均来解决这个问题，特别是在不确定性较高、因果效应差异较大且损失函数对效应敏感的情况下，这种方法能提高决策的准确性。


<details>
  <summary>Details</summary>
Motivation: 从业者在基于因果效应进行决策时，常常忽略结构不确定性。本研究旨在分析这种不确定性在多大程度上会产生重大影响，从而需要方法论上的解决方案。

Method: 通过对竞争性因果结构进行贝叶斯模型平均来解决结构不确定性问题，特别关注双变量关系（X → Y vs. X ← Y）。

Result: 研究表明，当结构不确定性中等到较高、因果效应在不同结构之间存在显著差异，并且损失函数对因果效应的大小足够敏感时，模型平均是有益的。通过仿真证明，现代因果发现方法在一定程度上可以提供必要量化。

Conclusion: 该方法论为现有鲁棒因果推断方法提供了补充，解决了实践中通常被忽视的一个独特的 But. 我们的框架提供了对通常被忽视的结构性不确定性的解决方案。

Abstract: Practitioners making decisions based on causal effects typically ignore
structural uncertainty. We analyze when this uncertainty is consequential
enough to warrant methodological solutions (Bayesian model averaging over
competing causal structures). Focusing on bivariate relationships ($X
\rightarrow Y$ vs. $X \leftarrow Y$), we establish that model averaging is
beneficial when: (1) structural uncertainty is moderate to high, (2) causal
effects differ substantially between structures, and (3) loss functions are
sufficiently sensitive to the size of the causal effect. We prove optimality
results of our suggested methodological solution under regularity conditions
and demonstrate through simulations that modern causal discovery methods can
provide, within limits, the necessary quantification. Our framework complements
existing robust causal inference approaches by addressing a distinct source of
uncertainty typically overlooked in practice.

</details>


### [325] [Directional Ensemble Aggregation for Actor-Critics](https://arxiv.org/abs/2507.23501)
*Nicklas Werge,Yi-Shan Wu,Bahareh Tasdighi,Melih Kandemir*

Main category: cs.LG

TL;DR: DEA 是一种新的 Q 值估计聚合方法，通过学习方向参数来适应保守性和探索性，从而提高了 off-policy 强化学习在连续控制任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 静态的 Q 值估计聚合方法（如取最小值）会丢弃有用的信息，并且无法适应特定任务或不同的学习范式。

Method: DEA 引入了两个可学习的方向参数：一个用于调节 critic 的保守性，另一个用于指导 actor 的策略探索。这两个参数都使用 ensemble 不一致加权的 Bellman 误差来学习。

Result: DEA 在连续控制基准和不同的学习范式（从交互式到样本高效）中均表现优于静态 ensemble 策略。

Conclusion: DEA 通过使用由 ensemble 不一致加权的 Bellman 误差学习的两个完全可学习的方向参数，能够自适应地结合 Q 值估计，从而克服了静态聚合规则的局限性。

Abstract: Off-policy reinforcement learning in continuous control tasks depends
critically on accurate $Q$-value estimates. Conservative aggregation over
ensembles, such as taking the minimum, is commonly used to mitigate
overestimation bias. However, these static rules are coarse, discard valuable
information from the ensemble, and cannot adapt to task-specific needs or
different learning regimes. We propose Directional Ensemble Aggregation (DEA),
an aggregation method that adaptively combines $Q$-value estimates in
actor-critic frameworks. DEA introduces two fully learnable directional
parameters: one that modulates critic-side conservatism and another that guides
actor-side policy exploration. Both parameters are learned using ensemble
disagreement-weighted Bellman errors, which weight each sample solely by the
direction of its Bellman error. This directional learning mechanism allows DEA
to adjust conservatism and exploration in a data-driven way, adapting
aggregation to both uncertainty levels and the phase of training. We evaluate
DEA across continuous control benchmarks and learning regimes - from
interactive to sample-efficient - and demonstrate its effectiveness over static
ensemble strategies.

</details>


### [326] [A Verifier Hierarchy](https://arxiv.org/abs/2507.23504)
*Maurits Kaptein*

Main category: cs.LG

TL;DR: 本研究提出了“验证者权衡定理”，揭示了证书长度与验证时间的关系，并将其应用于复杂性理论分析，为 NP 等问题提供了新视角。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探究证书长度和验证者运行时间之间的权衡关系，并为理解计算复杂性理论中的一些核心问题提供新的工具和视角。

Method: 本研究通过证明“验证者权衡定理”来分析证书长度和验证者运行时间之间的权衡。该定理表明，将语言的固有验证时间从 f(n) 减少到 g(n)（其中 f(n) ≥ g(n)）需要至少 Ω(log(f(n) / g(n))) 长度的证书。

Result: 研究证明了“验证者权衡定理”，该定理量化了减少验证时间所需的证书长度。研究还展示了该定理在分析复杂性类别分离和特定计算问题（如字符串周期性）中的应用，并对 P vs. NP 问题提出了新的见解。

Conclusion: 该研究通过证明“验证者权衡定理”揭示了证书长度和验证者运行时间之间的权衡关系，并提出了一个基于证书复杂度的自然层级结构。该定理已被应用于分析复杂性类别之间的分离猜想（如 NP 和 EXPTIME 之间的关系）以及字符串周期性和旋转检测等自然问题。此外，研究还通过将 P vs. NP 问题与是否存在子线性证书联系起来，为理解该问题提供了新的视角。

Abstract: We investigate the trade-off between certificate length and verifier runtime.
We prove a Verifier Trade-off Theorem showing that reducing the inherent
verification time of a language from \(f(n)\) to \(g(n)\), where \(f(n) \ge
g(n)\), requires certificates of length at least \(\Omega(\log(f(n) / g(n)))\).
This theorem induces a natural hierarchy based on certificate complexity. We
demonstrate its applicability to analyzing conjectured separations between
complexity classes (e.g., \(\np\) and \(\exptime\)) and to studying natural
problems such as string periodicity and rotation detection. Additionally, we
provide perspectives on the \(\p\) vs. \(\np\) problem by relating it to the
existence of sub-linear certificates.

</details>


### [327] [Differentially Private Clipped-SGD: High-Probability Convergence with Arbitrary Clipping Level](https://arxiv.org/abs/2507.23512)
*Saleh Vatan Khah,Savelii Chezhegov,Shahrokh Farahmand,Samuel Horváth,Eduard Gorbunov*

Main category: cs.LG

TL;DR: 本研究首次提出了一种差分隐私裁剪SGD的固定裁剪级别收敛性分析，并证明了其在收敛速度和隐私保证方面的优势。


<details>
  <summary>Details</summary>
Motivation: 现有梯度裁剪的收敛性分析通常需要裁剪阈值随优化步数增加，这与标准的差分隐私机制（如高斯机制）不兼容。本研究旨在解决此问题，为差分隐私裁剪SGD提供固定裁剪级别的收敛性分析。

Method: 提出了一种适用于凸和非凸光滑优化以及重尾噪声（由有界中心α-矩假设表征，α∈(1,2]）的差分隐私裁剪SGD（DP-Clipped-SGD）的固定裁剪级别的高概率收敛性分析。

Result: 研究结果表明，使用固定的裁剪级别，DP-Clipped-SGD可以比现有方法更快地收敛到最优解的邻域，并且可以在收敛速度和隐私保证之间实现更精细的权衡。

Conclusion: 该研究首次为具有固定裁剪级别的差分隐私裁剪SGD提供了高概率收敛性分析，该分析适用于凸和非凸光滑优化以及重尾噪声。结果表明，与现有方法相比，具有固定裁剪级别的该方法可以更快地收敛到最优解的邻域，并且可以在收敛速度和隐私保证之间实现更精细的权衡。

Abstract: Gradient clipping is a fundamental tool in Deep Learning, improving the
high-probability convergence of stochastic first-order methods like SGD,
AdaGrad, and Adam under heavy-tailed noise, which is common in training large
language models. It is also a crucial component of Differential Privacy (DP)
mechanisms. However, existing high-probability convergence analyses typically
require the clipping threshold to increase with the number of optimization
steps, which is incompatible with standard DP mechanisms like the Gaussian
mechanism. In this work, we close this gap by providing the first
high-probability convergence analysis for DP-Clipped-SGD with a fixed clipping
level, applicable to both convex and non-convex smooth optimization under
heavy-tailed noise, characterized by a bounded central $\alpha$-th moment
assumption, $\alpha \in (1,2]$. Our results show that, with a fixed clipping
level, the method converges to a neighborhood of the optimal solution with a
faster rate than the existing ones. The neighborhood can be balanced against
the noise introduced by DP, providing a refined trade-off between convergence
speed and privacy guarantees.

</details>


### [328] [Continual Learning with Synthetic Boundary Experience Blending](https://arxiv.org/abs/2507.23534)
*Chih-Fan Hsu,Ming-Ching Chang,Wei-Chao Chen*

Main category: cs.LG

TL;DR: 该研究提出了一种名为“经验混合”的持续学习方法，通过在训练中加入决策边界附近的合成数据来缓解模型遗忘问题，并在多个数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 持续学习（CL）旨在解决模型在多个任务上顺序训练时出现的灾难性遗忘问题。虽然经验回放已被证明有效，但其效果常常受到存储的关键样本分布稀疏的限制，导致决策边界过于简化。我们假设在训练过程中引入决策边界附近的合成数据（SBD）作为隐式正则化器，可以提高边界稳定性并缓解遗忘。

Method: 提出了一种名为“经验混合”的新颖训练框架，该框架包含两个核心组件：1.一种多变量差分隐私（DP）噪声机制，用于在低维特征表示中注入批次噪声，生成SBD；2.一种端到端的训练策略，该策略联合利用存储的关键样本和SBD。

Result: 在CIFAR-10、CIFAR-100和Tiny ImageNet上的大量实验表明，该方法在准确率上分别比九种持续学习基线方法提高了10%、6%和13%。

Conclusion: 所提出的经验混合框架通过引入决策边界附近的合成数据（SBD）作为隐式正则化器，改善了边界稳定性和缓解了遗忘，在CIFAR-10、CIFAR-100和Tiny ImageNet上的实验结果优于九种持续学习基线方法，准确率分别提高了10%、6%和13%。

Abstract: Continual learning (CL) aims to address catastrophic forgetting in models
trained sequentially on multiple tasks. While experience replay has shown
promise, its effectiveness is often limited by the sparse distribution of
stored key samples, leading to overly simplified decision boundaries. We
hypothesize that introducing synthetic data near the decision boundary
(Synthetic Boundary Data, or SBD) during training serves as an implicit
regularizer, improving boundary stability and mitigating forgetting. To
validate this hypothesis, we propose a novel training framework, {\bf
Experience Blending}, which integrates knowledge from both stored key samples
and synthetic, boundary-adjacent data. Experience blending consists of two core
components: (1) a multivariate Differential Privacy (DP) noise mechanism that
injects batch-wise noise into low-dimensional feature representations,
generating SBD; and (2) an end-to-end training strategy that jointly leverages
both stored key samples and SBD. Extensive experiments on CIFAR-10, CIFAR-100,
and Tiny ImageNet demonstrate that our method outperforms nine CL baselines,
achieving accuracy improvements of 10%, 6%, and 13%, respectively.

</details>


### [329] [Transparent AI: The Case for Interpretability and Explainability](https://arxiv.org/abs/2507.23535)
*Dhanesh Ramachandram,Himanshu Joshi,Judy Zhu,Dhari Gandhi,Lucas Hartman,Ananya Raval*

Main category: cs.LG

TL;DR: AI interpretability is crucial for trustworthy AI. This paper provides practical strategies for integrating it early in the design process, applicable to organizations at all stages of AI adoption.


<details>
  <summary>Details</summary>
Motivation: Ensuring transparency for responsible and trustworthy AI implementation as AI systems increasingly inform high-stakes decisions.

Method: Practical interpretability applications across diverse domains.

Result: Actionable strategies and implementation guidance tailored to organizations at varying stages of AI maturity.

Conclusion: The paper emphasizes integrating interpretability as a core design principle for responsible AI, offering practical guidance for organizations.

Abstract: As artificial intelligence systems increasingly inform high-stakes decisions
across sectors, transparency has become foundational to responsible and
trustworthy AI implementation. Leveraging our role as a leading institute in
advancing AI research and enabling industry adoption, we present key insights
and lessons learned from practical interpretability applications across diverse
domains. This paper offers actionable strategies and implementation guidance
tailored to organizations at varying stages of AI maturity, emphasizing the
integration of interpretability as a core design principle rather than a
retrospective add-on.

</details>


### [330] [From LLMs to Edge: Parameter-Efficient Fine-Tuning on Edge Devices](https://arxiv.org/abs/2507.23536)
*Georg Slamanig,Francesco Corti,Olga Saukh*

Main category: cs.LG

TL;DR: 该研究评估了PEFT方法在边缘设备的卷积网络上的应用，发现它们在内存效率方面不如LLMs，但在减少计算成本方面（尤其是适配器方法）表现出色，为边缘AI应用提供了选择依据。


<details>
  <summary>Details</summary>
Motivation: 尽管PEFT方法在大语言模型（LLMs）中得到了广泛研究，但其在资源受限的边缘设备上运行的小型模型（如卷积神经网络）上的应用仍未得到充分探索。

Method: 该研究通过基准测试和分析了LoRA、DoRA和GaLore等流行的PEFT方法在标准和深度卷积架构上的应用，并利用PyTorch profilers来比较PEFT方法与传统微调方法的性能和计算成本，特别关注了不同秩维度下的更新行为。

Result: 研究发现，在应用于深度可分离卷积架构时，PEFT方法的内存效率仅为在大语言模型上的应用时的一半。然而，当针对边缘部署优化的卷积架构时，基于适配器的PEFT方法可以将模型更新过程中的浮点运算（FLOPs）减少高达95%。

Conclusion: PEFT方法在卷积网络上的应用为资源受限的边缘设备提供了有价值的指导，其中基于适配器的PEFT方法在减少模型更新的浮点运算方面表现出色。

Abstract: Parameter-efficient fine-tuning (PEFT) methods reduce the computational costs
of updating deep learning models by minimizing the number of additional
parameters used to adapt a model to a down- stream task. While extensively
researched in large language models (LLMs), their application to smaller models
used on edge devices, such as convolutional neural networks, remains
underexplored. This paper benchmarks and analyzes popular PEFT methods on
convolutional architectures typically deployed in resource-constrained edge
environments. We evaluate LoRA, DoRA, and GaLore for updating standard and
depthwise convolutional architectures to handle distribution shifts and
accommodate unseen classes. We utilize recently proposed PyTorch profilers to
compare the updated model performance and computational costs of these PEFT
methods with traditional fine-tuning approaches. With resource efficiency in
mind, we investigate their update behavior across different rank dimensions. We
find that the evaluated PEFT methods are only half as memory-efficient when
applied to depthwise-separable convolution architectures, compared to their
efficiency with LLMs. Conversely, when targeting convolu- tional architectures
optimized for edge deployment, adapter-based PEFT methods can reduce floating
point operations (FLOPs) during model updates by up to 95%. These insights
offer valuable guidance for selecting PEFT methods based on hardware
constraints, performance requirements, and application needs. Our code is
online.

</details>


### [331] [Optimised Feature Subset Selection via Simulated Annealing](https://arxiv.org/abs/2507.23568)
*Fernando Martínez-García,Álvaro Rubio-García,Samuel Fernández-Lorenzo,Juan José García-Ripoll,Diego Porras*

Main category: cs.LG

TL;DR: SA-FDR 是一种新的 $\ell_0$-范数特征选择算法，它将特征选择视为组合优化问题，并使用模拟退火和 Fisher 判别比进行全局搜索，以选择更紧凑、信息更丰富的特征子集，从而提高可解释性和性能。


<details>
  <summary>Details</summary>
Motivation: 为了在高维设置中选择更紧凑的特征子集，同时保持高预测准确性，并捕捉被贪婪优化方法遗漏的特征间依赖性。

Method: SA-FDR 将 $\ell_0$-范数特征选择视为一个组合优化问题，并使用模拟退火来解决它，通过对特征子集空间进行全局搜索。该优化过程以 Fisher 判别比作为指导，这是一种计算高效的模型质量代理。

Result: SA-FDR 能够选择更紧凑的特征子集，同时实现高预测准确性，并且能够捕捉贪婪优化方法通常会忽略的特征间依赖性。

Conclusion: SA-FDR 提供了一个灵活有效的解决方案，用于在高维环境中设计可解释模型，特别是在模型稀疏性、可解释性和性能至关重要时。

Abstract: We introduce SA-FDR, a novel algorithm for $\ell_0$-norm feature selection
that considers this task as a combinatorial optimisation problem and solves it
by using simulated annealing to perform a global search over the space of
feature subsets. The optimisation is guided by the Fisher discriminant ratio,
which we use as a computationally efficient proxy for model quality in
classification tasks. Our experiments, conducted on datasets with up to
hundreds of thousands of samples and hundreds of features, demonstrate that
SA-FDR consistently selects more compact feature subsets while achieving a high
predictive accuracy. This ability to recover informative yet minimal sets of
features stems from its capacity to capture inter-feature dependencies often
missed by greedy optimisation approaches. As a result, SA-FDR provides a
flexible and effective solution for designing interpretable models in
high-dimensional settings, particularly when model sparsity, interpretability,
and performance are crucial.

</details>


### [332] [GraphRAG-R1: Graph Retrieval-Augmented Generation with Process-Constrained Reinforcement Learning](https://arxiv.org/abs/2507.23581)
*Chuanyue Yu,Kuo Zhao,Yuhan Li,Heng Chang,Mingjian Feng,Xiangzhe Jiang,Yufei Sun,Jia Li,Yuzhi Zhang,Jianxin Li,Ziwei Zhang*

Main category: cs.LG

TL;DR: 本文提出GraphRAG-R1，利用RL增强LLM的多跳推理能力，通过改进的GRPO、PRA和CAF奖励函数及阶段性训练，解决了现有方法的瓶颈，并在实验中表现优于SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有的GraphRAG方法在处理需要多跳推理的复杂问题时存在瓶颈，因为它们主要依赖预定义的启发式方法进行查询和检索，未能充分利用LLM的推理潜力。

Method: 本文提出了一种名为GraphRAG-R1的自适应GraphRAG框架，通过训练LLM来增强多跳推理能力。具体方法包括：使用支持“带思考回滚”的GRPO算法；设计了PRA奖励函数以促进必要检索，解决浅层检索问题；设计了CAF奖励函数以平衡模型性能和计算成本，解决过度思考问题；采用包含冷启动、PRA和CAF三个阶段的阶段性训练策略；以及结合混合图-文本检索以提升推理能力。

Result: 实验结果表明，GraphRAG-R1在处理复杂推理问题时，相较于最先进的GraphRAG方法，在in-domain和out-of-domain数据集上均能提升LLM的能力。此外，该框架能灵活集成各种现有检索方法，并持续带来性能提升。

Conclusion: GraphRAG-R1通过引入基于RL的自适应框架、改进的GRPO、PRA和CAF奖励函数以及阶段性训练策略，显著提升了LLM在复杂多跳推理任务上的能力，并在in-domain和out-of-domain数据集上均优于现有方法，同时还能灵活集成其他检索方法。

Abstract: Graph Retrieval-Augmented Generation (GraphRAG) has shown great effectiveness
in enhancing the reasoning abilities of LLMs by leveraging graph structures for
knowledge representation and modeling complex real-world relationships.
However, existing GraphRAG methods still face significant bottlenecks when
handling complex problems that require multi-hop reasoning, as their query and
retrieval phases are largely based on pre-defined heuristics and do not fully
utilize the reasoning potentials of LLMs. To address this problem, we propose
GraphRAG-R1, an adaptive GraphRAG framework by training LLMs with
process-constrained outcome-based reinforcement learning (RL) to enhance the
multi-hop reasoning ability. Our method can decompose complex problems,
autonomously invoke retrieval tools to acquire necessary information, and
perform effective reasoning. Specifically, we utilize a modified version of
Group Relative Policy Optimization (GRPO) that supports rollout-with-thinking
capability. Next, we design two process-constrained reward functions. To handle
the shallow retrieval problem, we design a Progressive Retrieval Attenuation
(PRA) reward to encourage essential retrievals. Then, to handle the
over-thinking problem, we design Cost-Aware F1 (CAF) reward to balance the
model performance with computational costs. We further design a phase-dependent
training strategy, containing three training stages corresponding to cold start
and these two rewards. Lastly, our method adopts a hybrid graph-textual
retrieval to improve the reasoning capacity. Extensive experimental results
demonstrate that GraphRAG-R1 boosts LLM capabilities in solving complex
reasoning problems compared to state-of-the-art GraphRAG methods on both
in-domain and out-of-domain datasets. Furthermore, our framework can be
flexibly integrated with various existing retrieval methods, consistently
delivering performance improvements.

</details>


### [333] [EB-gMCR: Energy-Based Generative Modeling for Signal Unmixing and Multivariate Curve Resolution](https://arxiv.org/abs/2507.23600)
*Yu-Tang Chang,Shih-Fang Chen*

Main category: cs.LG

TL;DR: EB-gMCR是一种新的深度学习方法，可以自动从混合信号中发现和分离基本模式，解决了传统方法在处理大型数据集和未知组件数量时的可扩展性和可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 经典MCR通常被表述为矩阵分解（MF），需要用户指定通常在实际数据中未知的组件数量。随着数据集大小或组件数量的增加，基于MF的MCR的可扩展性和可靠性面临严峻挑战。

Method: 本研究将MCR重新表述为生成过程（gMCR），并引入了基于能量的深度学习求解器EB-gMCR，该求解器可以自动发现能够忠实重建数据的最小组件集。EB-gMCR从一个大的候选池（例如1024个光谱）开始，并采用可微分的门控网络，在估计其浓度的同时只保留活动的组件。

Result: 在包含多达256个潜在源的噪声合成数据集上，EB-gMCR保持了R^2 >= 0.98，并将恢复的组件数量估计在真实值的5%以内；在较低噪声下，它实现了R^2 >= 0.99，并实现了接近精确的组件估计。

Conclusion: EB-gMCR通过结合高容量生成模型和硬组件选择，为包括化学库驱动场景在内的大规模信号解混分析提供了一条实用的途径。

Abstract: Signal unmixing analysis decomposes data into basic patterns and is widely
applied in chemical and biological research. Multivariate curve resolution
(MCR), a branch of signal unmixing, separates mixed chemical signals into base
patterns (components) and their concentrations, playing a key role in
understanding composition. Classical MCR is typically framed as matrix
factorization (MF) and requires a user-specified component count, usually
unknown in real data. As dataset size or component count increases, the
scalability and reliability of MF-based MCR face significant challenges. This
study reformulates MCR as a generative process (gMCR), and introduces an
energy-based deep learning solver, EB-gMCR, that automatically discovers the
smallest component set able to reconstruct the data faithfully. EB-gMCR starts
from a large candidate pool (e.g., 1024 spectra) and employs a differentiable
gating network to retain only active components while estimating their
concentrations. On noisy synthetic datasets containing up to 256 latent
sources, EB-gMCR maintained R^2 >= 0.98 and recovered the component count
within 5% of the ground truth; at lower noise it achieved R^2 >= 0.99 with near
exact component estimation. Additional chemical priors, such as non-negativity
or nonlinear mixing, enter as simple plug-in functions, enabling adaptation to
other instruments or domains without altering the core learning process. By
uniting high-capacity generative modeling and hard component selection, EB-gMCR
offers a practical route to large-scale signal unmixing analysis, including
chemical library-driven scenarios. The source code is available at
https://github.com/b05611038/ebgmcr_solver.

</details>


### [334] [Hierarchical Message-Passing Policies for Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2507.23604)
*Tommaso Marzi,Cesare Alippi,Andrea Cini*

Main category: cs.LG

TL;DR: 提出了一种结合通信和分层强化学习的方法，用于解决去中心化多智能体强化学习中的协调和规划问题。


<details>
  <summary>Details</summary>
Motivation: 去中心化多智能体强化学习（MARL）方法虽然可扩展，但存在部分可观测性和非平稳性问题，需要引入协调和高级规划机制。分层强化学习（HRL）和通信（如消息传递）可以实现协调和时间抽象，但优化问题限制了其在多智能体系统中的应用，因此该方法的结合具有探索价值。

Method: 提出了一种新颖有效的方法，用于学习消息传递策略的多智能体层次结构，采用了封建分层强化学习框架，并依靠分层图结构进行智能体之间的规划与协调。较低层次的智能体从上层接收目标，并与同一层次的邻近智能体进行消息交换。通过设计一种基于训练较低层次策略以最大化上层相关优势函数的新颖奖励分配方法来学习分层多智能体策略。

Result: 该方法在相关基准测试中表现优于现有技术。

Conclusion: 该方法在相关基准测试中表现优于现有技术。

Abstract: Decentralized Multi-Agent Reinforcement Learning (MARL) methods allow for
learning scalable multi-agent policies, but suffer from partial observability
and induced non-stationarity. These challenges can be addressed by introducing
mechanisms that facilitate coordination and high-level planning. Specifically,
coordination and temporal abstraction can be achieved through communication
(e.g., message passing) and Hierarchical Reinforcement Learning (HRL)
approaches to decision-making. However, optimization issues limit the
applicability of hierarchical policies to multi-agent systems. As such, the
combination of these approaches has not been fully explored. To fill this void,
we propose a novel and effective methodology for learning multi-agent
hierarchies of message-passing policies. We adopt the feudal HRL framework and
rely on a hierarchical graph structure for planning and coordination among
agents. Agents at lower levels in the hierarchy receive goals from the upper
levels and exchange messages with neighboring agents at the same level. To
learn hierarchical multi-agent policies, we design a novel reward-assignment
method based on training the lower-level policies to maximize the advantage
function associated with the upper levels. Results on relevant benchmarks show
that our method performs favorably compared to the state of the art.

</details>


### [335] [Deep Learning-based Prediction of Clinical Trial Enrollment with Uncertainty Estimates](https://arxiv.org/abs/2507.23607)
*Tien Huu Do,Antoine Masquelier,Nae Eoun Lee,Jonathan Crowther*

Main category: cs.LG

TL;DR: 该研究提出了一种基于深度学习和概率建模的新方法，用于更准确地预测临床试验的患者招募情况，并在真实数据实验中取得了优于现有方法的成果。


<details>
  <summary>Details</summary>
Motivation: 临床试验需要大量的资金和细致的规划，因此准确预测试验结果至关重要。其中，准确预测患者招募是规划阶段面临的主要挑战之一。

Method: 提出了一种新颖的深度学习方法，该方法首先利用预训练语言模型（PLMs）处理临床文件，提取表达性表示，然后结合编码的表格特征，并通过注意力机制整合。为了处理招募预测中的不确定性，模型还加入了一个基于Gamma分布的概率层以支持范围估计。在预测临床试验持续时间时，假设站点级别的招募遵循泊松-Gamma过程。

Result: 在真实世界临床试验数据上进行的广泛实验表明，该方法能够有效预测给定临床试验中多个站点的患者招募数量，并且其表现优于现有的基线模型。

Conclusion: 该研究提出了一种新颖的深度学习方法，利用预训练语言模型和注意力机制来预测临床试验的患者招募情况，并通过基于Gamma分布的概率层来处理不确定性，在真实世界临床试验数据上进行了广泛的实验，证明了该方法在预测多站点患者招募数量方面优于现有基线模型。

Abstract: Clinical trials are a systematic endeavor to assess the safety and efficacy
of new drugs or treatments. Conducting such trials typically demands
significant financial investment and meticulous planning, highlighting the need
for accurate predictions of trial outcomes. Accurately predicting patient
enrollment, a key factor in trial success, is one of the primary challenges
during the planning phase. In this work, we propose a novel deep learning-based
method to address this critical challenge. Our method, implemented as a neural
network model, leverages pre-trained language models (PLMs) to capture the
complexities and nuances of clinical documents, transforming them into
expressive representations. These representations are then combined with
encoded tabular features via an attention mechanism. To account for
uncertainties in enrollment prediction, we enhance the model with a
probabilistic layer based on the Gamma distribution, which enables range
estimation. We apply the proposed model to predict clinical trial duration,
assuming site-level enrollment follows a Poisson-Gamma process. We carry out
extensive experiments on real-world clinical trial data, and show that the
proposed method can effectively predict the number of patients enrolled at a
number of sites for a given clinical trial, outperforming established baseline
models.

</details>


### [336] [L-GTA: Latent Generative Modeling for Time Series Augmentation](https://arxiv.org/abs/2507.23615)
*Luis Roque,Carlos Soares,Vitor Cerqueira,Luis Torgo*

Main category: cs.LG

TL;DR: L-GTA是一种新的时间序列数据增强方法，它使用Transformer自动编码器在潜在空间中进行变换，以生成更可靠、可控的合成数据，并提高预测性能。


<details>
  <summary>Details</summary>
Motivation: 数据增强在时间序列分析的各个方面（从预测到分类和异常检测）都越来越重要。

Method: L-GTA模型采用基于Transformer的变分循环自动编码器，通过在潜在空间中进行受控变换来生成新的时间序列。

Result: L-GTA在真实世界数据集上的评估表明，与直接变换方法相比，它能够生成更可靠、一致且可控的增强数据，并在预测准确性和相似性度量方面带来显著改进。

Conclusion: L-GTA模型能够生成更可靠、一致且可控的增强数据，并在预测准确性和相似性度量方面带来显著改进。

Abstract: Data augmentation is gaining importance across various aspects of time series
analysis, from forecasting to classification and anomaly detection tasks. We
introduce the Latent Generative Transformer Augmentation (L-GTA) model, a
generative approach using a transformer-based variational recurrent
autoencoder. This model uses controlled transformations within the latent space
of the model to generate new time series that preserve the intrinsic properties
of the original dataset. L-GTA enables the application of diverse
transformations, ranging from simple jittering to magnitude warping, and
combining these basic transformations to generate more complex synthetic time
series datasets. Our evaluation of several real-world datasets demonstrates the
ability of L-GTA to produce more reliable, consistent, and controllable
augmented data. This translates into significant improvements in predictive
accuracy and similarity measures compared to direct transformation methods.

</details>


### [337] [On the Expressiveness of Softmax Attention: A Recurrent Neural Network Perspective](https://arxiv.org/abs/2507.23632)
*Gabriel Mongaras,Eric C. Larson*

Main category: cs.LG

TL;DR: Softmax attention is better than linear attention because its recurrent form reveals key properties.


<details>
  <summary>Details</summary>
Motivation: To understand why linear attention methods, despite being derived from softmax attention, lag in downstream accuracy and to explain the discrepancy in expressiveness between softmax and linear attention.

Method: Deriving the recurrent form of softmax attention and analyzing its components in the context of recurrent neural networks (RNNs).

Result: Demonstrated that linear attention is an approximation of softmax attention by deriving its recurrent form, enabling component ablation and interaction analysis to explain softmax attention's superior expressiveness.

Conclusion: Softmax attention is more expressive than its linear counterparts due to its inherent properties, which are better understood by analyzing its recurrent form, allowing for component ablation and interaction analysis.

Abstract: Since its introduction, softmax attention has become the backbone of modern
transformer architectures due to its expressiveness and scalability across a
wide range of tasks. However, the main drawback of softmax attention is the
quadratic memory requirement and computational complexity with respect to the
sequence length. By replacing the softmax nonlinearity, linear attention and
similar methods have been introduced to avoid the quadratic bottleneck of
softmax attention. Despite these linear forms of attention being derived from
the original softmax formulation, they typically lag in terms of downstream
accuracy. While strong intuition of the softmax nonlinearity on the query and
key inner product suggests that it has desirable properties compared to other
nonlinearities, the question of why this discrepancy exists still remains
unanswered. This work demonstrates that linear attention is an approximation of
softmax attention by deriving the recurrent form of softmax attention. Using
this form, each part of softmax attention can be described in the language of
recurrent neural networks (RNNs). Describing softmax attention as an RNN allows
for the ablation of the components of softmax attention to understand the
importance of each part and how they interact. In this way, our work helps
explain why softmax attention is more expressive than its counterparts.

</details>


### [338] [OptiGradTrust: Byzantine-Robust Federated Learning with Multi-Feature Gradient Analysis and Reinforcement Learning-Based Trust Weighting](https://arxiv.org/abs/2507.23638)
*Mohammad Karami,Fatemeh Ghassemi,Hamed Kebriaei,Hamid Azadegan*

Main category: cs.LG

TL;DR: 提出OptiGradTrust和FedBN-Prox来防御联邦学习中的拜占庭攻击和数据异质性问题，在多个数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决联邦学习（FL）在医学领域应用中面临的拜占庭攻击和统计异质性问题，同时保持患者隐私。

Method: 提出了一种名为OptiGradTrust的防御框架，该框架通过包含VAE重建误差、余弦相似度、L2范数、符号一致性比率和蒙特卡洛Shapley值等六个维度的指纹来评估梯度更新，并利用混合强化学习-注意力模块进行自适应信任评分。同时，引入了FedBN-Prox（FedBN-P）机制，结合了联邦批量归一化和近端正则化，以优化数据异质性下的准确性和收敛性。

Result: 在MNIST、CIFAR-10和阿尔茨海默氏症MRI数据集上进行了广泛评估，在多种拜占庭攻击场景下，OptiGradTrust和FedBN-Prox的组合相比现有最佳防御方法（如FLGuard）在非独立同分布（non-IID）条件下，准确率最高可提升1.6个百分点，并能有效应对多种攻击模式。

Conclusion: OptiGradTrust框架通过六维指纹和混合RL-注意力模块有效防御了拜占庭攻击，FedBN-Prox结合了联邦批量归一化和近端正则化，解决了数据异质性带来的收敛挑战，在多种数据集和攻击场景下均显著优于现有防御方法。

Abstract: Federated Learning (FL) enables collaborative model training across
distributed medical institutions while preserving patient privacy, but remains
vulnerable to Byzantine attacks and statistical heterogeneity. We present
OptiGradTrust, a comprehensive defense framework that evaluates gradient
updates through a novel six-dimensional fingerprint including VAE
reconstruction error, cosine similarity metrics, $L_2$ norm, sign-consistency
ratio, and Monte Carlo Shapley value, which drive a hybrid RL-attention module
for adaptive trust scoring. To address convergence challenges under data
heterogeneity, we develop FedBN-Prox (FedBN-P), combining Federated Batch
Normalization with proximal regularization for optimal accuracy-convergence
trade-offs. Extensive evaluation across MNIST, CIFAR-10, and Alzheimer's MRI
datasets under various Byzantine attack scenarios demonstrates significant
improvements over state-of-the-art defenses, achieving up to +1.6 percentage
points over FLGuard under non-IID conditions while maintaining robust
performance against diverse attack patterns through our adaptive learning
approach.

</details>


### [339] [SHAP-Guided Regularization in Machine Learning Models](https://arxiv.org/abs/2507.23665)
*Amal Saadallah*

Main category: cs.LG

TL;DR: 提出了一种SHAP引导的正则化框架，通过将特征重要性约束整合到模型训练中，提高机器学习模型的预测性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有研究较少探索特征归因方法（如SHAP）在指导模型优化中的作用，而本研究旨在解决这一问题，以增强模型的预测性能和可解释性。

Method: 提出了一种结合SHAP（SHapley Additive exPlanations）的正则化框架，该框架将特征重要性约束纳入模型训练中，通过熵基惩罚鼓励稀疏、集中的特征归因，并促进跨样本的稳定性。该框架适用于回归和分类任务，并以TreeSHAP为例对基于树的模型进行了正则化。

Result: 通过在标准的回归和分类数据集上进行的大量实验，证明了该方法在提高泛化性能的同时，能够确保鲁棒且可解释的特征归因。

Conclusion: 该方法为机器学习模型提供了新颖的、由可解释性驱动的正则化方法，提高了模型的准确性和可靠性。

Abstract: Feature attribution methods such as SHapley Additive exPlanations (SHAP) have
become instrumental in understanding machine learning models, but their role in
guiding model optimization remains underexplored. In this paper, we propose a
SHAP-guided regularization framework that incorporates feature importance
constraints into model training to enhance both predictive performance and
interpretability. Our approach applies entropy-based penalties to encourage
sparse, concentrated feature attributions while promoting stability across
samples. The framework is applicable to both regression and classification
tasks. Our first exploration started with investigating a tree-based model
regularization using TreeSHAP. Through extensive experiments on benchmark
regression and classification datasets, we demonstrate that our method improves
generalization performance while ensuring robust and interpretable feature
attributions. The proposed technique offers a novel, explainability-driven
regularization approach, making machine learning models both more accurate and
more reliable.

</details>


### [340] [TweakLLM: A Routing Architecture for Dynamic Tailoring of Cached Responses](https://arxiv.org/abs/2507.23674)
*Muhammad Taha Cheema,Abeer Aamir,Khawaja Gul Muhammad,Naveed Anwar Bhatti,Ihsan Ayyub Qazi,Zafar Ayyub Qazi*

Main category: cs.LG

TL;DR: TweakLLM通过使用轻量级LLM动态调整缓存响应来提高LLM缓存效率，从而在不损害用户体验的情况下降低成本和延迟。


<details>
  <summary>Details</summary>
Motivation: 为了解决LLM缓存中的相关性问题，由用户个性化交互和语义相似性搜索的局限性引起。

Method: 提出了一种名为TweakLLM的新型路由架构，该架构采用轻量级LLM动态适应缓存的响应以匹配传入的提示。

Result: TweakLLM在保持与前沿模型相当的响应质量的同时，显著提高了缓存效率。

Conclusion: TweakLLM是一种可扩展、资源高效的缓存解决方案，适用于大规模LLM部署，且不损害用户体验。

Abstract: Large Language Models (LLMs) process millions of queries daily, making
efficient response caching a compelling optimization for reducing cost and
latency. However, preserving relevance to user queries using this approach
proves difficult due to the personalized nature of chatbot interactions and the
limited accuracy of semantic similarity search. To address this, we present
TweakLLM, a novel routing architecture that employs a lightweight LLM to
dynamically adapt cached responses to incoming prompts. Through comprehensive
evaluation, including user studies with side-by-side comparisons, satisfaction
voting, as well as multi-agent LLM debates, we demonstrate that TweakLLM
maintains response quality comparable to frontier models while significantly
improving cache effectiveness. Our results across real-world datasets highlight
TweakLLM as a scalable, resource-efficient caching solution for high-volume LLM
deployments without compromising user experience.

</details>


### [341] [One-Step Flow Policy Mirror Descent](https://arxiv.org/abs/2507.23675)
*Tianyi Chen,Haitong Ma,Na Li,Kai Wang,Bo Dai*

Main category: cs.LG

TL;DR: 提出了一种名为FPMD的在线强化学习算法，实现了1步采样，解决了扩散策略推理速度慢的问题，并在MuJoCo基准测试中取得了与扩散策略相当的性能，同时函数评估次数减少了数百倍。


<details>
  <summary>Details</summary>
Motivation: 为了克服扩散策略模型推理依赖于缓慢的迭代采样过程而导致的响应性受限问题。

Method: 提出了一种名为Flow Policy Mirror Descent（FPMD）的在线强化学习算法，该算法能够实现1步采样，克服了现有扩散策略模型推理速度慢的限制。该方法利用了分布方差与直线插值流匹配模型中单步采样离散化误差之间的理论联系，并且不需要额外的蒸馏或一致性训练。此外，还提出了基于流策略和MeanFlow策略参数化的两种算法变体。

Result: 所提出的FPMD算法及其变体在MuJoCo基准测试中展示了强大的性能，与现有的扩散策略基线相当，并且在推理过程中所需的函数评估次数显著减少，提高了效率。

Conclusion: FPMD算法在MuJoCo基准测试中表现出色，与扩散策略基线相当，同时在推理过程中所需的函数评估次数减少了数百倍。

Abstract: Diffusion policies have achieved great success in online reinforcement
learning (RL) due to their strong expressive capacity. However, the inference
of diffusion policy models relies on a slow iterative sampling process, which
limits their responsiveness. To overcome this limitation, we propose Flow
Policy Mirror Descent (FPMD), an online RL algorithm that enables 1-step
sampling during policy inference. Our approach exploits a theoretical
connection between the distribution variance and the discretization error of
single-step sampling in straight interpolation flow matching models, and
requires no extra distillation or consistency training. We present two
algorithm variants based on flow policy and MeanFlow policy parametrizations,
respectively. Extensive empirical evaluations on MuJoCo benchmarks demonstrate
that our algorithms show strong performance comparable to diffusion policy
baselines while requiring hundreds of times fewer function evaluations during
inference.

</details>


### [342] [DepMicroDiff: Diffusion-Based Dependency-Aware Multimodal Imputation for Microbiome Data](https://arxiv.org/abs/2507.23676)
*Rabeya Tus Sadia,Qiang Cheng*

Main category: cs.LG

TL;DR: DepMicroDiff通过结合扩散模型、Transformer和LLM，改进了微生物组数据的填充，提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 由于微生物组数据的固有稀疏性和噪声，准确的填充（imputation）面临重大挑战，这阻碍了生物标志物发现等下游任务。现有的填充方法（包括基于扩散的模型）往往无法捕捉微生物类群之间复杂的相互依赖关系，并且忽略了可以指导填充的上下文元数据。

Method: DepMicroDiff框架结合了基于扩散的生成模型和依赖感知Transformer (DAT)，以捕捉微生物类群之间的相互依赖关系和自回归关系。该框架还通过在多种癌症数据集上进行VAE预训练，并利用通过大型语言模型（LLM）编码的患者元数据进行条件化，得到了增强。

Result: 在TCGA微生物组数据集上的实验表明，DepMicroDiff在皮尔逊相关性（最高可达0.712）、余弦相似度（最高可达0.812）方面显著优于最先进的基线方法，并在多个癌症类型中实现了更低的RMSE和MAE。

Conclusion: DepMicroDiff通过结合基于扩散的生成模型和依赖感知Transformer (DAT)，以及基于VAE的预训练和LLM编码的患者元数据，显著优于现有方法，在多个癌症类型中实现了更高的皮尔逊相关性、余弦相似度和更低的RMSE和MAE，证明了其在微生物组填充方面的鲁棒性和泛化能力。

Abstract: Microbiome data analysis is essential for understanding host health and
disease, yet its inherent sparsity and noise pose major challenges for accurate
imputation, hindering downstream tasks such as biomarker discovery. Existing
imputation methods, including recent diffusion-based models, often fail to
capture the complex interdependencies between microbial taxa and overlook
contextual metadata that can inform imputation. We introduce DepMicroDiff, a
novel framework that combines diffusion-based generative modeling with a
Dependency-Aware Transformer (DAT) to explicitly capture both mutual pairwise
dependencies and autoregressive relationships. DepMicroDiff is further enhanced
by VAE-based pretraining across diverse cancer datasets and conditioning on
patient metadata encoded via a large language model (LLM). Experiments on TCGA
microbiome datasets show that DepMicroDiff substantially outperforms
state-of-the-art baselines, achieving higher Pearson correlation (up to 0.712),
cosine similarity (up to 0.812), and lower RMSE and MAE across multiple cancer
types, demonstrating its robustness and generalizability for microbiome
imputation.

</details>


### [343] [Anomalous Samples for Few-Shot Anomaly Detection](https://arxiv.org/abs/2507.23712)
*Aymane Abdali,Bartosz Boguslawski,Lucas Drumetz,Vincent Gripon*

Main category: cs.LG

TL;DR: 在少样本场景下，异常样本比正常样本更有用。本研究提出了一种利用异常样本进行异常检测的新方法。


<details>
  <summary>Details</summary>
Motivation: 在少样本设置下，异常样本可能比正常样本更有用，这挑战了传统异常检测方法依赖大量正常样本的假设。

Method: 提出了一种结合零样本和基于记忆技术的多评分异常检测方法，并使用基于增强的验证技术来优化不同异常评分的聚合。

Result: 证明了异常样本在训练异常检测模型中的效用，并提出了优化异常评分聚合的验证技术。

Conclusion: 该研究探讨了在少样本设置下利用异常样本训练二元异常分类模型的方法，并提出了一种结合零样本和基于记忆技术的多评分异常检测方法。

Abstract: Several anomaly detection and classification methods rely on large amounts of
non-anomalous or "normal" samples under the assump- tion that anomalous data is
typically harder to acquire. This hypothesis becomes questionable in Few-Shot
settings, where as little as one anno- tated sample can make a significant
difference. In this paper, we tackle the question of utilizing anomalous
samples in training a model for bi- nary anomaly classification. We propose a
methodology that incorporates anomalous samples in a multi-score anomaly
detection score leveraging recent Zero-Shot and memory-based techniques. We
compare the utility of anomalous samples to that of regular samples and study
the benefits and limitations of each. In addition, we propose an
augmentation-based validation technique to optimize the aggregation of the
different anomaly scores and demonstrate its effectiveness on popular
industrial anomaly detection datasets.

</details>


### [344] [Improving annotator selection in Active Learning using a mood and fatigue-aware Recommender System](https://arxiv.org/abs/2507.23756)
*Diana Mortagua*

Main category: cs.LG

TL;DR: 该研究提出了一种新的推荐系统方法，通过考虑标注者的情绪和疲劳水平，以及历史准确性，来优化主动学习中的标注者选择，从而提高标注效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 为了克服在主动学习（AL）中为每个查询选择最佳标注者以最小化错误分类的挑战。现有策略未能考虑影响生产力的内部因素，如情绪、注意力、积极性和疲劳水平。

Method: 提出了一种新的查询-标注者配对策略，利用基于知识的推荐系统（RS）。该系统考虑了标注者的历史准确性、情绪和疲劳水平以及查询实例的信息，对可用标注者进行排名，并选择合适的标注者进行标注。

Result: 与不考虑内部因素的策略相比，所提出的方法通过考虑历史准确性、情绪和疲劳水平，减少了标注错误和模型在训练过程中的不确定性。准确性和F1分数也有所提高。

Conclusion: 本研究初步探索了影响主动学习（AL）中认知因素的开放性挑战，通过考虑历史准确性、情绪和疲劳水平，可以减少标注错误并降低模型的不确定性。

Abstract: This study centers on overcoming the challenge of selecting the best
annotators for each query in Active Learning (AL), with the objective of
minimizing misclassifications. AL recognizes the challenges related to cost and
time when acquiring labeled data, and decreases the number of labeled data
needed. Nevertheless, there is still the necessity to reduce annotation errors,
aiming to be as efficient as possible, to achieve the expected accuracy faster.
Most strategies for query-annotator pairs do not consider internal factors that
affect productivity, such as mood, attention, motivation, and fatigue levels.
This work addresses this gap in the existing literature, by not only
considering how the internal factors influence annotators (mood and fatigue
levels) but also presenting a new query-annotator pair strategy, using a
Knowledge-Based Recommendation System (RS). The RS ranks the available
annotators, allowing to choose one or more to label the queried instance using
their past accuracy values, and their mood and fatigue levels, as well as
information about the instance queried. This work bases itself on existing
literature on mood and fatigue influence on human performance, simulating
annotators in a realistic manner, and predicting their performance with the RS.
The results show that considering past accuracy values, as well as mood and
fatigue levels reduces the number of annotation errors made by the annotators,
and the uncertainty of the model through its training, when compared to not
using internal factors. Accuracy and F1-score values were also better in the
proposed approach, despite not being as substantial as the aforementioned. The
methodologies and findings presented in this study begin to explore the open
challenge of human cognitive factors affecting AL.

</details>


### [345] [Consensus-Driven Active Model Selection](https://arxiv.org/abs/2507.23771)
*Justin Kay,Grant Van Horn,Subhransu Maji,Daniel Sheldon,Sara Beery*

Main category: cs.LG

TL;DR: CODA是一种主动模型选择方法，通过利用模型之间的共识和分歧来优先标记数据点，从而减少选择最佳模型所需的注释工作量。


<details>
  <summary>Details</summary>
Motivation: 提供一个成本效益高、耗时少的方法来解决广泛的机器学习模型中选择最佳模型的问题。

Method: CODA通过对分类器、类别和数据点之间的关系进行建模，执行共识驱动的主动模型选择。该框架利用候选模型库中模型之间的共识和分歧来指导标签采集过程，并使用贝叶斯推理来更新关于哪个模型是最好的信念，以及收集更多的信息。

Result: CODA在26个基准任务上进行了验证，与现有的主动模型选择方法相比，可将发现最佳模型所需的注释工作量减少70%以上。

Conclusion: CODA通过在概率框架内对分类器、类别和数据点之间的关系进行建模，执行共识驱动的主动模型选择，并在收集更多信息时使用贝叶斯推理来更新关于哪个模型是最好的信念。CODA显著优于现有的主动模型选择方法，与之前的技术相比，发现最佳模型所需的注释工作量减少了70%以上。

Abstract: The widespread availability of off-the-shelf machine learning models poses a
challenge: which model, of the many available candidates, should be chosen for
a given data analysis task? This question of model selection is traditionally
answered by collecting and annotating a validation dataset -- a costly and
time-intensive process. We propose a method for active model selection, using
predictions from candidate models to prioritize the labeling of test data
points that efficiently differentiate the best candidate. Our method, CODA,
performs consensus-driven active model selection by modeling relationships
between classifiers, categories, and data points within a probabilistic
framework. The framework uses the consensus and disagreement between models in
the candidate pool to guide the label acquisition process, and Bayesian
inference to update beliefs about which model is best as more information is
collected. We validate our approach by curating a collection of 26 benchmark
tasks capturing a range of model selection scenarios. CODA outperforms existing
methods for active model selection significantly, reducing the annotation
effort required to discover the best model by upwards of 70% compared to the
previous state-of-the-art. Code and data are available at
https://github.com/justinkay/coda.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [346] [DNN-based Methods of Jointly Sensing Number and Directions of Targets via a Green Massive H2AD MIMO Receiver](https://arxiv.org/abs/2507.22906)
*Bin Deng,Jiatong Bai,Feilong Zhao,Zuming Xie,Maolin Li,Yan Wang,Feng Shu*

Main category: eess.SP

TL;DR: 针对H2AD MIMO感知难题，提出两阶段框架联合估计目标数量和方向。设计了改进EDC、DNN和1D-CNN三种数量感知方法，以及OMC-DOA方向估计方法。仿真验证了方法的有效性，尤其在低信噪比和多源场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 未来无线网络中，异构混合模拟-数字H2AD MIMO结构旨在解决大规模全数字MIMO的高能耗、高电路成本和高复杂度问题。然而，如何通过该结构智能感知多发射机的数量和方向仍然是一个难题。

Method: 提出了一种两阶段感知框架，联合估计多个目标的数量和方向值。设计了三种目标数量感知方法：改进的特征值域聚类（EDC）框架、基于五个关键统计特征的深度神经网络（DNN）以及利用全部特征值的一维卷积神经网络（1D-CNN）。随后，通过在线微聚类（OMC-DOA）方法实现了低复杂度、高精度的DOA估计。此外，推导了H2AD在多源条件下的Cram'er-Rao下界（CRLB）。

Result: 仿真结果表明，所提出的三种方法在信噪比适中至高时，目标数量感知准确率可达100%，其中改进的1D-CNN在信噪比极低时表现更优。所提出的OMC-DOA方法在多源环境下，其性能优于现有的基于聚类和融合的DOA方法。

Conclusion: 所提出的方法在信噪比适中至高时，目标数量感知准确率可达100%，在信噪比极低时，改进的一维卷积神经网络表现更优。提出的OMC-DOA方法在多源环境下，其性能优于现有的基于聚类和融合的DOA方法。

Abstract: As a green MIMO structure, the heterogeneous hybrid analog-digital H2AD MIMO
architecture has been shown to own a great potential to replace the massive or
extremely large-scale fully-digital MIMO in the future wireless networks to
address the three challenging problems faced by the latter: high energy
consumption, high circuit cost, and high complexity. However, how to
intelligently sense the number and direction of multi-emitters via such a
structure is still an open hard problem. To address this, we propose a
two-stage sensing framework that jointly estimates the number and direction
values of multiple targets. Specifically, three target number sensing methods
are designed: an improved eigen-domain clustering (EDC) framework, an enhanced
deep neural network (DNN) based on five key statistical features, and an
improved one-dimensional convolutional neural network (1D-CNN) utilizing full
eigenvalues. Subsequently, a low-complexity and high-accuracy DOA estimation is
achieved via the introduced online micro-clustering (OMC-DOA) method.
Furthermore, we derive the Cram\'er-Rao lower bound (CRLB) for the H2AD under
multiple-source conditions as a theoretical performance benchmark. Simulation
results show that the developed three methods achieve 100\% number of targets
sensing at moderate-to-high SNRs, while the improved 1D-CNN exhibits superior
under extremely-low SNR conditions. The introduced OMC-DOA outperforms existing
clustering and fusion-based DOA methods in multi-source environments.

</details>


### [347] [Rydberg Atomic Receivers for Wireless Communications: Fundamentals, Potential, Applications, and Challenges](https://arxiv.org/abs/2507.22909)
*Yin Zhang,Jiayi Zhang,Bokai Xu,Yuanbin Chen,Zhilong Liu,Jiakang Zheng,Enyu Shi,Ziheng Liu,Tierui Gong,Wei E. I. Sha,Chau Yuen,Shi Jin,Bo Ai*

Main category: eess.SP

TL;DR: Rydberg atomic receivers (RARs) offer superior sensitivity and bandwidth compared to traditional radio frequency receivers (RFRs), enabling advancements in wireless communications, integrated sensing, quantum radar, and space communications. Challenges like limited bandwidth and distortion are being addressed with ongoing research.


<details>
  <summary>Details</summary>
Motivation: The motivation of this paper is to highlight the innovative technology of Rydberg atomic receivers (RARs) and their potential to overcome the intrinsic physical limitations of conventional radio frequency receivers (RFRs), particularly in sensitivity and bandwidth, representing a paradigm shift in wireless communication systems.

Method: The paper systematically explains the fundamental sensing mechanisms of RARs and contrasts their differences from RFRs in working principles and architectures. It also explores the advantages of RARs in emerging wireless communication scenarios and identifies practical challenges and mitigation strategies.

Result: The paper explores the advantages of RARs in emerging wireless communication scenarios such as integrated sensing and communications, quantum Rydberg radar, and quantum space communications. It also identifies practical challenges, including limited instantaneous bandwidth and nonlinear distortion, and outlines mitigation strategies and future research directions.

Conclusion: RARs have the potential to revolutionize wireless communications by overcoming the limitations of conventional RFRs, offering advantages in sensitivity and bandwidth, particularly in emerging applications like integrated sensing and communications, quantum Rydberg radar, and quantum space communications. Practical challenges like limited instantaneous bandwidth and nonlinear distortion need to be addressed through mitigation strategies and further research to fully realize the potential of RAR-aided wireless systems.

Abstract: Rydberg atomic receivers (RARs) leverage the quantum coherence of highly
excited atoms to overcome the intrinsic physical limitations of conventional
radio frequency receivers (RFRs), particularly in sensitivity, and bandwidth.
This innovative technology represents a paradigm shift in wireless
communication systems. This paper systematically explains the fundamental
sensing mechanisms of RARs, contrasts their differences from RFRs in working
principles and architectures. We explore their advantages in emerging wireless
communication scenarios, such as integrated sensing and communications, quantum
Rydberg radar, and quantum space communications. Practical challenges, such as
limited instantaneous bandwidth and nonlinear distortion, are identified. To
address these issues, mitigation strategies and future research directions are
also outlined, supporting the advancement of RAR-aided wireless systems.

</details>


### [348] [Neural Energy Landscapes Predict Working Memory Decline After Brain Tumor Resection](https://arxiv.org/abs/2507.23057)
*Triet M. Tran,Sina Khanmohammadi*

Main category: eess.SP

TL;DR: 术前大脑高阶能量动力学特征可预测脑肿瘤切除术后工作记忆能力下降。


<details>
  <summary>Details</summary>
Motivation: 研究肿瘤如何通过术前神经动力学改变导致术后认知功能障碍（特别是工作记忆下降）。

Method: 通过分析脑肿瘤患者术前功能性磁共振成像（fMRI），提取高阶大脑相互作用的能量景观，并使用统计和机器学习（随机森林）模型检查能量特征与术后工作记忆表现之间的关系。

Result: 术后工作记忆能力较低的患者表现出更少但更极端的局部能量最小值和最大值之间的转换；相反，能力较高的患者表现出更频繁但不太极端的转变。此外，术前高阶能量特征能够以 90% 的准确率、87.5% 的 F1 分数和 0.95 的 AUC 准确预测术后工作记忆能力下降。

Conclusion: 脑肿瘤切除术前高阶神经动力学是预测术后工作记忆能力下降的有价值指标，有望实现个性化手术规划和针对性干预。

Abstract: Surgical resection is the primary treatment option for brain tumor patients,
but it carries the risk of postoperative cognitive dysfunction. This study
investigates how tumor-induced alterations in presurgical neural dynamics
relate to postoperative working memory decline. We analyzed functional magnetic
resonance imaging (fMRI) of brain tumor patients before surgery and extracted
energy landscapes of high-order brain interactions. We then examined the
relation between these energy features and postoperative working memory
performance using statistical and machine learning (random forest) models.
Patients with lower postoperative working memory scores exhibited fewer but
more extreme transitions between local energy minima and maxima, whereas
patients with higher scores showed more frequent but less extreme shifts.
Furthermore, the presurgical high-order energy features were able to accurately
predict postoperative working memory decline with a mean accuracy of 90\%, F1
score of 87.5\%, and an AUC of 0.95. Our study suggests that the brain
tumor-induced disruptions in high-order neural dynamics before surgery are
predictive of postoperative working memory decline. Our findings pave the path
for personalized surgical planning and targeted interventions to mitigate
cognitive risks associated with brain tumor resection.

</details>


### [349] [In-Orbit Cosmo-SkyMed antenna pattern estimation by a narrowband sweeper receiver](https://arxiv.org/abs/2507.23235)
*Mohammad Roueinfar,Masoud Ardini*

Main category: eess.SP

TL;DR: 本研究介绍了一种新颖的、用于卫星天线方向图估计的窄带扫频接收器（NSR）方法。NSR 通过精确测量 SAR 宽带频谱内的单个频率的功率，显著提高了天线方向图提取的准确性。


<details>
  <summary>Details</summary>
Motivation: 为了在配备合成孔径雷达（SAR）的卫星中进行天线方向图估计。

Method: 使用窄带扫频接收器（NSR）测量 SAR 固有的宽带频谱内的单个频率的功率。

Result: 与传统接收器相比，NSR 显著提高了天线方向图提取的准确性，并展示了更高的信噪比（SNR）。

Conclusion: 这项研究代表了SAR技术的关键进展，为未来的卫星校准和验证方法学提供了强大的框架。

Abstract: This paper introduces a novel method for antenna pattern estimation in
satellites equipped with Synthetic Aperture Radar (SAR), utilizing a Narrowband
Sweeper Receiver (NSR). By accurately measuring power across individual
frequencies within SAR's inherently broadband spectrum, the NSR significantly
enhances antenna pattern extraction accuracy. Analytical models and practical
experiments conducted using the Cosmo-SkyMed satellite validate the receiver's
performance, demonstrating superior signal-to-noise ratio (SNR) compared to
conventional receivers. This research represents a key advancement in SAR
technology, offering a robust framework for future satellite calibration and
verification methodologies.

</details>


### [350] [BS-1-to-N: Diffusion-Based Environment-Aware Cross-BS Channel Knowledge Map Generation for Cell-Free Networks](https://arxiv.org/abs/2507.23236)
*Zhuoyin Dai,Di Wu,Yong Zeng,Xiaoli Xu,Xinyi Wang,Zesong Fei*

Main category: eess.SP

TL;DR: 本研究提出了一种名为BS-1-to-N的生成扩散模型，用于高效地跨基站推理信道知识图谱（CKM）。该模型通过学习基站位置和CKM之间的关系，能够处理大规模分布式网络，并已成功应用于基站部署优化。


<details>
  <summary>Details</summary>
Motivation: 为了实现高效的环境感知通信，需要跨基站进行信道知识图谱（CKM）推理。现有的在具有海量分布式节点（如无主蜂窝网络）的架构中，逐一遍历基站进行CKM构建的方法成本高昂。因此，需要一种更有效的方法来推理CKM。

Method: 提出了一种名为BS-1-to-N的跨基站CKM推理方法，利用生成扩散模型，结合了基站位置嵌入（BSLE）和交叉/自注意力机制。BSLE方法将基站位置信息嵌入CKM的特征向量中，而交叉/自注意力机制则分别学习源基站与目标基站之间以及目标基站之间的关系。该方法能够以任意数量的源基站和目标基站为条件，通过控制条件（源基站位置、目标基站位置和源CKM）进行跨基站CKM推理。

Result: 通过与基准方案进行大量CKM推理比较，证明了所提出的BS-1-to-N生成模型的高效性。此外，通过一个用例研究展示了其在优化基站部署方面的实际应用。

Conclusion: 该研究提出了一种基于生成扩散模型的环境感知跨基站信道知识图谱（CKM）推理方法BS-1-to-N，通过学习CKM与基站位置之间的隐含相关性，实现了对任意数量基站的高效CKM推理，并成功应用于基站部署优化。

Abstract: Channel knowledge map (CKM) inference across base stations (BSs) is the key
to achieving efficient environmentaware communications. This paper proposes an
environmentaware cross-BS CKM inference method called BS-1-to-N based on the
generative diffusion model. To this end, we first design the BS location
embedding (BSLE) method tailored for cross-BS CKM inference to embed BS
location information in the feature vector of CKM. Further, we utilize the
cross- and self-attention mechanism for the proposed BS-1-to-N model to
respectively learn the relationships between source and target BSs, as well as
that among target BSs. Therefore, given the locations of the source and target
BSs, together with the source CKMs as control conditions, cross-BS CKM
inference can be performed for an arbitrary number of source and target BSs.
Specifically, in architectures with massive distributed nodes like cell-free
networks, traditional methods of sequentially traversing each BS for CKM
construction are prohibitively costly. By contrast, the proposed BS-1-to-N
model is able to achieve efficient CKM inference for a target BS at any
potential location based on the CKMs of source BSs. This is achieved by
exploiting the fact that within a given area, different BSs share the same
wireless environment that leads to their respective CKMs. Therefore, similar to
multi-view synthesis, CKMs of different BSs are representations of the same
wireless environment from different BS locations. By mining the implicit
correlation between CKM and BS location based on the wireless environment, the
proposed BS-1-to-N method achieves efficient CKM inference across BSs. We
provide extensive comparisons of CKM inference between the proposed BS-1-to-N
generative model versus benchmarking schemes, and provide one use case study to
demonstrate its practical application for the optimization of BS deployment.

</details>


### [351] [A Secure Full-Duplex Wireless Circulator enabled by Non-Reciprocal Beyond-Diagonal RIS](https://arxiv.org/abs/2507.23381)
*Ziang Liu,Bruno Clerckx*

Main category: eess.SP

TL;DR: NR-BD-RIS技术在全双工通信中可实现更安全、更高和速率的通信，尤其在多方向支持时优于传统RIS。


<details>
  <summary>Details</summary>
Motivation: 为了提高无线通信系统的性能和安全性，利用了NR-BD-RIS打破电路和信道互易性的特性，将其应用于全双工（FD）无线通信的互联互通，以实现安全传输，抑制来自其他用户的信号，防止窃听。

Method: 提出了一种利用NR-BD-RIS实现全双工（FD）无线通信安全传输的新应用。通过考虑包含结构散射（镜面反射）的物理约束系统模型，将问题建模为所有用户和速率最大化问题，并采用交替块坐标下降（BCD）和惩罚对偶分解（PDD）方法来求解。

Result: 数值结果表明，NR-BD-RIS在和速率性能上始终优于R-BD-RIS和D-RIS，特别是在需要支持两个以上入射和反射方向时。通过分析其他用户的信号功率和波束赋形，证明了NR-BD-RIS能够实现安全传输。

Conclusion: NR-BD-RIS在全双工（FD）无线通信系统中，特别是在需要安全传输的场景下，相比于传统RIS技术具有显著的性能优势，尤其是在支持多个入射和反射方向时。

Abstract: Beyond-diagonal reconfigurable intelligent surface (BD-RIS) has arisen as a
promising technology for enhancing wireless communication systems by enabling
flexible and intelligent wave manipulation. This is achieved through the
interconnections among the ports of the impedance network, enabling wave
reconfiguration when they flow through the surface. Thus, the output wave at
one port depends on waves impinging on neighboring ports, allowing non-local
control of both phase and magnitude. Non-reciprocal (NR)-BD-RIS further
enhances this capability by breaking circuit reciprocity and, consequently,
channel reciprocity. This feature potentially benefits communication among
non-aligned transceivers. This paper introduces a novel application of
NR-BD-RIS in full-duplex (FD) wireless circulators, where multiple FD devices
communicate via an NR-BD-RIS. This system is particularly beneficial for secure
transmission, as it enforces one-way communication among FD devices, suppresses
signal from all other users, and thus prevents eavesdropping. In addition, a
physics-compliant system model is considered by incorporating structural
scattering, also known as specular reflection. By accounting for this effect,
the advantages of NR-BD-RIS are further validated. Specifically, we formulate
an all-user sum-rate maximization problem and propose an iterative optimization
algorithm that employs block coordinate descent (BCD) and penalty dual
decomposition (PDD) methods. Numerical evaluations illustrate that NR-BD-RIS
consistently outperforms reciprocal (R)-BD-RIS and conventional diagonal
(D)-RIS in terms of sum-rate performance, particularly when more than two
impinging and reflection directions need to be supported. By analyzing the
power of signals from all other users and the beampatterns, we show that secure
transmission can be achieved.

</details>


### [352] [EVMx: An FPGA-Based Smart Contract Processing Unit](https://arxiv.org/abs/2507.23518)
*Joel Poncha Lemayian,Hachem Bensalem,Ghyslain Gagnon,Kaiwen Zhang,Pascal Giard*

Main category: eess.SP

TL;DR: EVMx 是一个基于 FPGA 的硬件加速器，可将以太坊智能合约的执行速度提高 6 倍。


<details>
  <summary>Details</summary>
Motivation: 现有的以太坊虚拟机 (EVM) 性能受限于通用计算机的约束，需要一种更高效的执行方式。

Method: 提出了一种名为 EVMx 的基于 FPGA 的智能合约执行引擎，用于卸载和加速智能合约的执行。

Result: EVMx 在常用操作码的执行时间上比基于 CPU 的环境减少了 61% 到 99%，并且以太坊区块的执行速度比文献中类似的工作快 6 倍。

Conclusion: EVMx 通过利用 FPGA 的并行性和高速处理能力，显著提高了智能合约的执行效率，与基于 CPU 的执行环境相比，执行时间减少了 61% 到 99%，并且比文献中类似的工作快 6 倍。

Abstract: Ethereum blockchain uses smart contracts (SCs) to implement decentralized
applications (dApps). SCs are executed by the Ethereum virtual machine (EVM)
running within an Ethereum client. Moreover, the EVM has been widely adopted by
other blockchain platforms, including Solana, Cardano, Avalanche, Polkadot, and
more. However, the EVM performance is limited by the constraints of the
general-purpose computer it operates on. This work proposes offloading SC
execution onto a dedicated hardware-based EVM. Specifically, EVMx is an
FPGA-based SC execution engine that benefits from the inherent parallelism and
high-speed processing capabilities of a hardware architecture. Synthesis
results demonstrate a reduction in execution time of 61% to 99% for commonly
used operation codes compared to CPU-based SC execution environments. Moreover,
the execution time of Ethereum blocks on EVMx is up to 6x faster compared to
analogous works in the literature. These results highlight the potential of the
proposed architecture to accelerate SC execution and enhance the performance of
EVM-compatible blockchains.

</details>


### [353] [Channel Estimation for 6G Near-Field Wireless Communications: A Comprehensive Survey](https://arxiv.org/abs/2507.23526)
*Wen-Xuan Long,Shengyu Ye,Marco Moretti,Michele Morelli,Luca Sanguinetti,Rui Chen,Cheng-Xiang Wang*

Main category: eess.SP

TL;DR: 6G ELAA 近场信道估计 survey。


<details>
  <summary>Details</summary>
Motivation: 6G 无线系统预计将采用极大的孔径阵列 (ELAAs)、新颖的天线架构并在极高频段运行，以满足日益增长的数据需求。ELAAs 大大增加了天线数量，能够实现更精细的空间分辨率和改进的波束成形。在高频下，ELAAs 将通信从传统的远场转移到近场区域，其中球形波前占主导地位，信道响应同时取决于角度和距离，增加了信道维度。然而，依赖角度信息的传统远场信道估计方法在近场场景下面临信道开销和计算复杂度的挑战。

Method: 本论文首先从电磁学角度定义了近场和远场的边界，并讨论了关键的传播差异以及 ELAA 的发展。随后，介绍了主流的近场信道模型并与远场模型进行了比较。最后，在不同配置（单用户/多用户、单载波/多载波）下回顾了主要的估计技术，包括直接估计和 RIS 辅助的级联估计。

Result: 该论文对近场信道估计技术进行了全面的 survey，涵盖了从定义到模型再到主流估计技术的各个方面，并分析了不同技术在估计精度、复杂度和开销之间的权衡。

Conclusion: 该论文全面 survey 了 6G 无线系统中的近场信道估计技术，包括其定义、传播差异、ELAA 的发展、近场信道模型以及主流的估计技术，旨在为 6G 系统的近场信道估计提供见解和基础，并指出了挑战和未来研究方向。

Abstract: The sixth-generation (6G) wireless systems are expected to adopt extremely
large aperture arrays (ELAAs), novel antenna architectures, and operate in
extremely high-frequency bands to meet growing data demands. ELAAs
significantly increase the number of antennas, enabling finer spatial
resolution and improved beamforming. At high frequencies, ELAAs shift
communication from the conventional far-field to near-field regime, where
spherical wavefronts dominate and the channel response depends on both angle
and distance, increasing channel dimensionality. Conventional far-field channel
estimation methods, which rely on angular information, struggle in near-field
scenarios due to increased pilot overhead and computational complexity. This
paper presents a comprehensive survey of recent advances in near-field channel
estimation. It first defines the near- and far-field boundary from an
electromagnetic perspective and discusses key propagation differences,
alongside a brief review of ELAA developments. Then, it introduces mainstream
near-field channel models and compares them with far-field models. Major
estimation techniques are reviewed under different configurations
(single/multi-user, single/multi-carrier), including both direct estimation and
RIS-assisted cascaded estimation. These techniques reveal trade-offs among
estimation accuracy, complexity, and overhead. This survey aims to provide
insights and foundations for efficient and scalable near-field channel
estimation in 6G systems, while identifying key challenges and future research
directions.

</details>


### [354] [Multiple-Parameter Graph Fractional Fourier Transform: Theory and Applications](https://arxiv.org/abs/2507.23570)
*Manjun Cui,Zhichao Zhang,Wei Yao*

Main category: eess.SP

TL;DR: This paper introduces Multiple-Parameter Graph Fractional Fourier Transforms (MPGFRFTs) to overcome the limitations of the standard GFRFT. The proposed methods offer enhanced adaptability for graph signal processing tasks like compression, denoising, and image encryption.


<details>
  <summary>Details</summary>
Motivation: The standard graph fractional Fourier transform (GFRFT) has limited adaptability due to its use of a single global fractional order for all graph frequencies. This paper aims to address this limitation by introducing multiple parameters.

Method: This paper proposes two types of multiple-parameter GFRFTs (MPGFRFTs) and establishes their corresponding theoretical frameworks. A spectral compression strategy for ultra-low compression ratios and a learnable order vector scheme for adaptive compression and denoising are designed. The application of MPGFRFTs to image encryption and decryption is also explored.

Result: MPGFRFTs, coupled with a learnable order vector scheme, show strong performance in adaptive compression and denoising for graph signals and images. The framework is also effective for image encryption and decryption.

Conclusion: The proposed MPGFRFT framework demonstrates versatility and superior performance across various graph signal processing tasks, including adaptive compression, denoising, and image encryption/decryption.

Abstract: The graph fractional Fourier transform (GFRFT) applies a single global
fractional order to all graph frequencies, which restricts its adaptability to
diverse signal characteristics across the spectral domain. To address this
limitation, in this paper, we propose two types of multiple-parameter GFRFTs
(MPGFRFTs) and establish their corresponding theoretical frameworks. We design
a spectral compression strategy tailored for ultra-low compression ratios,
effectively preserving essential information even under extreme dimensionality
reduction. To enhance flexibility, we introduce a learnable order vector scheme
that enables adaptive compression and denoising, demonstrating strong
performance on both graph signals and images. We explore the application of
MPGFRFTs to image encryption and decryption. Experimental results validate the
versatility and superior performance of the proposed MPGFRFT framework across
various graph signal processing tasks.

</details>


### [355] [On the Achievable Rate of Satellite Quantum Communication Channel using Deep Autoencoder Gaussian Mixture Model](https://arxiv.org/abs/2507.23695)
*Mouli Chakraborty,Subhash Chandra,Avishek Nag,Anshu Mukherjee*

Main category: eess.SP

TL;DR: DAGMM在卫星量子信道容量估计方面优于GMM，并提出了DCGMM。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在比较GMM和DAGMM在卫星量子信道容量估计中的性能，并提出一种新的模型用于高维量子数据分析。

Method: 对高斯混合模型（GMM）和深度自动编码器高斯混合模型（DAGMM）进行了比较研究，以估计考虑混合量子噪声（HQN）和传输约束的卫星量子信道容量。

Result: DAGMM能更好地捕捉非线性变化和噪声分布，提供更严格的容量边界和更好的聚类效果。

Conclusion: DAGMM在卫星量子信道容量估计方面优于GMM，并提出了用于高维量子数据分析的DCGMM。

Abstract: We present a comparative study of the Gaussian mixture model (GMM) and the
Deep Autoencoder Gaussian Mixture Model (DAGMM) for estimating satellite
quantum channel capacity, considering hybrid quantum noise (HQN) and
transmission constraints. While GMM is simple and interpretable, DAGMM better
captures non-linear variations and noise distributions. Simulations show that
DAGMM provides tighter capacity bounds and improved clustering. This introduces
the Deep Cluster Gaussian Mixture Model (DCGMM) for high-dimensional quantum
data analysis in quantum satellite communication.

</details>


### [356] [Cellular, Cell-less, and Everything in Between: A Unified Framework for Utility Region Analysis in Wireless Networks](https://arxiv.org/abs/2507.23707)
*Renato Luis Garrido Cavalcante,Tomasz Piotrowski,Slawomir Stanczak*

Main category: eess.SP

TL;DR: 提出了一种分析无线网络效用区域的统一框架，并推导了保证其凸性的充分条件，有助于开发更优的求解器并简化问题表述。


<details>
  <summary>Details</summary>
Motivation: 为了深入理解现代网络架构（如无小区和超大规模MIMO网络）的干扰模式，并推广现有的弱帕累托边界特征。

Method: 提出了一种统一的框架来分析无线网络的效用区域，重点关注信干噪比（SINR）和可实现速率区域。推导了保证效用区域凸性的充分条件。

Result: 推导了保证效用区域凸性的充分条件，该条件可用于识别本质上是凸的（加权）和速率最大化问题，从而开发有效的、可证明最优的求解器，并为将和速率最大化问题直接用可实现速率而非SINR水平来表述提供了理论依据。此外，还提出了一种考虑自干扰和波束形成策略的替代方法。

Conclusion: 该框架为分析无线网络的效用区域（重点关注信干噪比（SINR）和可实现速率区域）提供了一个统一的框架，并为解决相关问题提供了理论依据。

Abstract: We introduce a unified framework for analyzing utility regions of wireless
networks, with a focus on the signal-to-interference-noise-ratio (SINR) and
achievable rate regions. The framework provides valuable insights into
interference patterns of modern network architectures, such as cell-less and
extremely large MIMO networks, and it generalizes existing characterizations of
the weak Pareto boundary. A central contribution is the derivation of
sufficient conditions that guarantee convexity of the utility regions.
Convexity is an important property because it ensures that time sharing (or
user grouping) cannot simultaneously increase the utility of all users when the
network operates on the weak Pareto boundary. These sufficient conditions also
have two key implications. First, they identify a family of (weighted) sum-rate
maximization problems that are inherently convex without any variable
transformations, thus paving the way for the development of efficient, provably
optimal solvers for this family. Second, they provide a rigorous justification
for formulating sum-rate maximization problems directly in terms of achievable
rates, rather than SINR levels. Our theoretical insights also motivate an
alternative to the concept of favorable propagation in the massive MIMO
literature -- one that explicitly accounts for self-interference and the
beamforming strategy.

</details>


### [357] [Real-Time Transmission of Uncompressed High-Definition Video Via A VCSEL-Based Optical Wireless Link With Ultra-Low Latency](https://arxiv.org/abs/2507.23746)
*Hossein Kazemi,Isaac N. O. Osahon,Tiankuo Jiao,David Butler,Nikolay Ledentsov Jr.,Ilya Titkov,Nikolay Ledentsov,Harald Haas*

Main category: eess.SP

TL;DR: 该研究提出了一种基于激光的光无线通信（OWC）系统，能够以低于35 ns的延迟传输全高清和4K视频，并兼容现有的SDI标准，为专业广播设备提供了低成本、高扩展性的无线连接解决方案。


<details>
  <summary>Details</summary>
Motivation: 为了在未压缩和未加密的格式下实时传输高分辨率视频信号，需要一种具有高带宽的超可靠低延迟通信（URLLC）介质，以保持用户的体验质量（QoE）。

Method: 通过直接调制SDI信号到940nm垂直腔面发射激光器的强度，利用摄像头SDI输出来将实时视频流通过光无线链路传输。

Result: 该系统实现了2.97 Gb/s和5.94 Gb/s的数据速率，分别传输全高清（FHD）和4K超高清（UHD）分辨率，且测得的端到端延迟低于35 ns，实现了无差错传输。

Conclusion: 该系统为使用现成SDI组件的专业广播设备之间的无线连接提供了一个可扩展且廉价的解决方案。

Abstract: Real-time transmission of high-resolution video signals in an uncompressed
and unencrypted format requires an ultra-reliable and low-latency
communications (URLLC) medium with high bandwidth to maintain the quality of
experience (QoE) for users. We put forward the design and experimental
demonstration of a high-performance laser-based optical wireless communication
(OWC) system that enables high-definition (HD) video transmission with
submillisecond latencies. The serial digital interface (SDI) output of a camera
is used to transmit the live video stream over an optical wireless link by
directly modulating the SDI signal on the intensity of a 940 nm vertical cavity
surface emitting laser (VCSEL). The proposed SDI over light fidelity (LiFi)
system corroborates error-free transmission of full HD (FHD) and 4K
ultra-high-definition (UHD) resolutions at data rates of 2.97 Gb/s and 5.94
Gb/s, respectively, with a measured end-to-end latency of under 35 ns. Since
SDI standards support various video formats and VCSELs are high-bandwidth and
low-power devices, this presents a scalable and inexpensive solution for
wireless connectivity between professional broadcast equipment using
off-the-shelf SDI components.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [358] [Stabilization of Age-Structured Competing Populations](https://arxiv.org/abs/2507.23013)
*Carina Veil,Miroslav Krstić,Patrick McNamee,Oliver Sawodny*

Main category: eess.SY

TL;DR: 该研究提出了一种利用反推方法稳定化两个竞争捕食者种群的年龄结构模型的方法，通过控制一个物种的密度间接影响另一个物种，实现了系统的全局稳定化。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决多物种年龄结构模型在流行病学和生态学中的应用，特别是两个竞争捕食者种群的动力学。现有研究很少关注耦合年龄结构IPDE模型，特别是具有一个执行输入的模型。

Method: 该研究利用反推方法来稳定化两个耦合的年龄结构偏微分方程（IPDE）系统。通过将模型转化为一个由一个被驱动的常微分方程（ODE）系统和两个自主的、指数稳定的积分时滞方程（IDE）组成，该方法能够间接控制第二个物种的密度。

Result: 通过反推法，研究成功地实现了ODE系统的全局稳定化，并证明了在满足正控制约束的条件下，可以提供完整的IPDE系统的渐近稳定平衡区域的估计。

Conclusion: 该研究为具有一个执行输入的两个耦合年龄结构偏微分方程（IPDE）系统的全局稳定化提供了新的见解，证明了使用反推方法稳定化具有两个执行输入和两个物种的年龄结构模型的可行性。

Abstract: Age-structured models represent the dynamic behaviors of populations over
time and result in integro-partial differential equations (IPDEs). Such
processes arise in biotechnology, economics, demography, and other domains.
Coupled age-structured IPDE population dynamics with two or more species occur
in epidemiology and ecology, but have received little attention thus far. This
work considers an exponentially unstable model of two competing predator
populations, formally referred to in the literature as ''competition''
dynamics. If one were to apply an input that simultaneously harvests both
predator species, one would have control over only the product of the densities
of the species, not over their ratio. Therefore, it is necessary to design a
control input that directly harvests only one of the two predator species,
while indirectly influencing the other via a backstepping approach. The model
is transformed into a system of two coupled ordinary differential equations
(ODEs), of which only one is actuated, and two autonomous, exponentially stable
integral delay equations (IDEs) which enter the ODEs as nonlinear disturbances.
The ODEs are globally stabilized with backstepping and an estimate of the
region of attraction of the asymptotically stabilized equilibrium of the full
IPDE system is provided, under a positivity restriction on control. These
generalizations open exciting possibilities for future research directions,
such as investigating population systems with more than two species.

</details>


### [359] [Terahertz for Radar applications and Wireless Communication](https://arxiv.org/abs/2507.23076)
*Sofiane Latreche,Hocine Bellahsene,Abdelmalik Taleb-Ahmed*

Main category: eess.SY

TL;DR: 太赫兹（THz）频段在下一代无线通信和雷达系统中具有巨大潜力，本研究探讨了其特性、应用以及相关的传播模型。


<details>
  <summary>Details</summary>
Motivation: 为了利用最新可用的无线电频率频谱（太赫兹频段），该频段为下一代无线系统带来了巨大希望，这些系统有望无缝集成各种数据密集型和时间敏感型应用。

Method: 通过探索和分析无线通信和雷达系统在太赫兹（THz）频段运行的具体特性，以及这些应用特有的各种效应和参数，来研究太赫兹（THz）无线和雷达系统的应用，并对其无线电频率传播的各个方面进行建模。

Result: 本研究将提供对太赫兹（THz）频段的深入了解，包括其特性和应用示例。

Conclusion: 本研究将展示研究结果的解释。

Abstract: Technological advancements in the design of electronic and optical materials
have opened up the possibility of utilizing the latest available Radio
Frequency spectrum the Terahertz (THz) band. This band holds great promise for
next-generation wireless systems, which are poised to seamlessly integrate a
wide array of data-intensive and time-sensitive applications. In this article,
we delve into the Terahertz band, providing insights into its properties and
showcasing examples of its applications. We begin by exploring the specific
characteristics of wireless communications and radar systems operating in the
THz band. Subsequently, we analyze various effects and parameters unique to
each of these applications.so we scrutinize the application of Terahertz (THz)
wireless and radar systems, delving into the modeling of various facets of
radio frequency propagation within this domain. The interpretation of our
findings will be presented at the conclusion of this study.

</details>


### [360] [Experimentally-Driven Analysis of Stability in Connected Vehicle Platooning: Insights and Control Strategies](https://arxiv.org/abs/2507.23078)
*Niladri Dutta,Elham Abolfazli,Themistoklis Charalambous*

Main category: eess.SY

TL;DR: 本研究开发了一个实际平台来演示协作自适应巡航控制（CACC）系统，并验证了其在车辆编队中的有效性，解决了现有研究中缺乏物理演示的不足。


<details>
  <summary>Details</summary>
Motivation: 解决现有文献中在模拟车辆编队系统研究较多，但在物理车辆系统或机器人平台上演示这些控制器的研究较少这一不足之处。

Method: 开发了一个实用的平台来演示协作自适应巡航控制（CACC）系统，对现有的纵向控制器进行了详细审查，并在多种自主实验车辆平台拓扑结构中进行了广泛的测试。

Result: 模拟和现场测试的结果均证实了所提出的CACC编队方法在纵向车辆编队场景中的显著优势。

Conclusion: 该研究通过在物理车辆系统上演示协作自适应巡航控制（CACC）系统，填补了现有文献在模拟与实际应用之间差距的空白，验证了CACC在纵向车辆编队中的有效性和显著优势。

Abstract: This paper presents the development of a tangible platform for demonstrating
the practical implementation of cooperative adaptive cruise control (CACC)
systems, an enhancement to the standard adaptive cruise control (ACC) concept
by means of Vehicle-to-Everything (V2X) communication. It involves a detailed
examination of existing longitudinal controllers and their performance in
homogeneous vehicle platoons. Moreover, extensive tests are conducted using
multiple autonomous experimental vehicle platform topologies to verify the
effectiveness of the controller. The outcomes from both simulations and field
tests affirm the substantial benefits of the proposed CACC platooning approach
in longitudinal vehicle platooning scenarios. This research is crucial due to a
notable gap in the existing literature; while numerous studies focus on
simulated vehicle platooning systems, there is lack of research demonstrating
these controllers on physical vehicle systems or robot platforms. This paper
seeks to fill this gap by providing a practical demonstration of CACC systems
in action, showcasing their potential for real-world application in intelligent
transportation systems.

</details>


### [361] [Robust Control Design and Analysis for Nonlinear Systems with Uncertain Initial Conditions Based on Lifting Linearization](https://arxiv.org/abs/2507.23139)
*Sourav Sinha,Mazen Farhood*

Main category: eess.SY

TL;DR: This paper proposes a deep learning-based framework for robust control of nonlinear systems with uncertain initial conditions. It uses a lifting approach to approximate systems and synthesize controllers, with robustness guarantees provided by an l2-induced norm-like measure. An IQC-based analysis method is also presented to tune controllers considering measurement noise.


<details>
  <summary>Details</summary>
Motivation: This paper presents a robust control synthesis and analysis framework for nonlinear systems with uncertain initial conditions.

Method: A deep learning-based lifting approach is proposed to approximate nonlinear dynamical systems with linear parameter-varying (LPV) state-space models in higher-dimensional spaces while simultaneously characterizing the uncertain initial states within the lifted state space. Convex synthesis conditions are provided to generate full-state feedback nonstationary LPV (NSLPV) controllers for the lifted LPV system. A performance measure similar to the l2-induced norm is used to provide robust performance guarantees. A robustness analysis approach based on integral quadratic constraint (IQC) theory is developed to analyze and tune the synthesized controllers while accounting for noise associated with state measurements.

Result: The framework enables the approximation of nonlinear systems, characterization of uncertain initial states, and synthesis of robust controllers (full-state feedback NSLPV, full-state feedback LTI, and output feedback NSLPV). The IQC-based analysis accounts for noise and reduces conservatism.

Conclusion: The effectiveness of the proposed framework is demonstrated through two illustrative examples.

Abstract: This paper presents a robust control synthesis and analysis framework for
nonlinear systems with uncertain initial conditions. First, a deep
learning-based lifting approach is proposed to approximate nonlinear dynamical
systems with linear parameter-varying (LPV) state-space models in
higher-dimensional spaces while simultaneously characterizing the uncertain
initial states within the lifted state space. Then, convex synthesis conditions
are provided to generate full-state feedback nonstationary LPV (NSLPV)
controllers for the lifted LPV system. A performance measure similar to the
l2-induced norm is used to provide robust performance guarantees in the
presence of exogenous disturbances and uncertain initial conditions. The paper
also includes results for synthesizing full-state feedback LTI controllers and
output feedback NSLPV controllers. Additionally, a robustness analysis approach
based on integral quadratic constraint (IQC) theory is developed to analyze and
tune the synthesized controllers while accounting for noise associated with
state measurements. This analysis approach characterizes model parameters and
disturbance inputs using IQCs to reduce conservatism. Finally, the
effectiveness of the proposed framework is demonstrated through two
illustrative examples.

</details>


### [362] [Foundation Models for Clean Energy Forecasting: A Comprehensive Review](https://arxiv.org/abs/2507.23147)
*Md Meftahul Ferdaus,Tanmoy Dam,Md Rasel Sarkar,Moslem Uddin,Sreenatha G. Anavatti*

Main category: eess.SY

TL;DR: 本次审查介绍了基金模型在风能和太阳能预测中的应用，重点介绍了模型架构、预训练、微调和数据，并讨论了时空相关性、领域知识和可再生能源发电的间歇性。它还评估了基于基金模型的预测准确性进展，如多时间尺度预测和不确定性量化，并讨论了长期和多元时间序列预测的挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着全球能源系统向清洁能源转型，准确的可再生能源发电和需求预测对于有效的电网管理至关重要。基金模型可以通过快速处理复杂、高维的时间序列数据来帮助改进可再生能源发电和需求预测。

Method: 本次审查的重点是基金模型在可再生能源预测领域的应用，主要关注风能和太阳能。我们概述了在可再生能源预测背景下使用的模型架构、预训练策略、微调方法和数据类型。我们强调了在大规模训练的模型、领域特定的 Transformer 架构中的作用，并关注了时空相关性、领域知识嵌入以及可再生能源发电的短暂性和间歇性。

Result: 我们评估了最近基于基金模型的预测准确性进展，例如协调多个时间尺度的预测和量化可再生能源预测中的不确定性。我们还回顾了长期和多元时间序列预测中现有的挑战和有待改进的领域。

Conclusion: 本次调查区分了清洁能源预测领域中基金模型的理论与实践，并批判性地评估了基金模型的优缺点，为这一令人兴奋的新预测领域提出了未来的研究方向。

Abstract: As global energy systems transit to clean energy, accurate renewable
generation and renewable demand forecasting is imperative for effective grid
management. Foundation Models (FMs) can help improve forecasting of renewable
generation and demand because FMs can rapidly process complex, high-dimensional
time-series data. This review paper focuses on FMs in the realm of renewable
energy forecasting, primarily focusing on wind and solar. We present an
overview of the architectures, pretraining strategies, finetuning methods, and
types of data used in the context of renewable energy forecasting. We emphasize
the role of models that are trained at a large scale, domain specific
Transformer architectures, where attention is paid to spatial temporal
correlations, the embedding of domain knowledge, and also the brief and
intermittent nature of renewable generation. We assess recent FM based
advancements in forecast accuracy such as reconciling predictions over multiple
time scales and quantifying uncertainty in renewable energy forecasting. We
also review existing challenges and areas of improvement in long-term and
multivariate time series forecasting. In this survey, a distinction between
theory and practice is established regarding the use of FMs in the clean energy
forecasting domain. Additionally, it critically assesses the strengths and
weaknesses of FMs while advancing future research direction in this new and
exciting area of forecasting.

</details>


### [363] [Data-Driven Stochastic Control via Non-i.i.d. Trajectories: Foundations and Guarantees](https://arxiv.org/abs/2507.23280)
*Abolfazl Lavaei*

Main category: eess.SY

TL;DR: 本研究提出了一种新颖的数据驱动方法，用于在具有未知动力学和噪声分布的随机系统中实现安全控制。该方法利用非独立同分布轨迹和随机控制势垒证书，通过平方和优化来提供概率安全保证，克服了传统方法的保守性，并在实验中得到了验证。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有随机系统安全分析中，基于界限的鲁棒分析方法过于保守以及在实践中界限可能被违反的挑战，本研究致力于开发一种能够处理具有未知数学动力学和未知过程噪声分布的随机系统的方法。

Method: 本研究提出了一个数据驱动的框架，利用有限时间范围内收集的非独立同分布（non-i.i.d.）轨迹。通过构建基于数据的随机控制势垒证书，并将其形式化为基于经验平均值和噪声统计特征的平方和（SOS）优化问题，来量化具有认证置信水平的概率安全保证。

Result: 所提出的方法在三个具有未知模型和噪声分布的随机基准测试中得到了验证，并证明了其有效性。特别地，在一种情况下，即使在有界扰动下的鲁棒分析不存在安全控制器，该随机框架也能提供一个具有保证的概率安全控制器。

Conclusion: 该研究提出了一种基于数据的方法，用于在具有未知动力学和未知分布过程噪声的随机系统中实现概率安全保证，克服了传统基于界限的鲁棒分析的保守性。

Abstract: This work establishes a crucial step toward advancing data-driven
trajectory-based methods for stochastic systems with unknown mathematical
dynamics. In contrast to scenario-based approaches that rely on independent and
identically distributed (i.i.d.) trajectories, this work develops a data-driven
framework where each trajectory is gathered over a finite horizon and exhibits
temporal dependence-referred to as a non-i.i.d. trajectory. To ensure safety of
dynamical systems using such trajectories, the current body of literature
primarily considers dynamics subject to unknown-but-bounded disturbances, which
facilitates robust analysis. While promising, such bounds may be violated in
practice and the resulting worst-case robust analysis tends to be overly
conservative. To overcome these fundamental challenges, this paper considers
stochastic systems with unknown mathematical dynamics, influenced by process
noise with unknown distributions. In the proposed framework, data is collected
from stochastic systems under multiple realizations within a finite-horizon
experiment, where each realization generates a non-i.i.d. trajectory.
Leveraging the concept of stochastic control barrier certificates constructed
from data, this work quantifies probabilistic safety guarantees with a
certified confidence level. To achieve this, the proposed conditions are
formulated as sum-of-squares (SOS) optimization problems, relying solely on
empirical average of the collected trajectories and statistical features of the
process noise. The efficacy of the approach has been validated on three
stochastic benchmarks with both unknown models and noise distributions. In one
case study, it is shown that while no safety controller exists for the robust
analysis of the system under bounded disturbances, the proposed stochastic
framework offers a safety controller with guaranteed probabilistic
satisfaction.

</details>


### [364] [A Framework for Ethical Decision-Making in Automated Vehicles through Human Reasons-based Supervision](https://arxiv.org/abs/2507.23308)
*Lucas Elbert Suryana,Saeed Rahmani,Simeon Craig Calvert,Arkady Zgonnikov,Bart van Arem*

Main category: eess.SY

TL;DR: 日常驾驶中的道德困境对人类驾驶员来说是一个普遍的挑战，他们需要平衡安全、效率和遵守规则等竞争性优先事项。然而，自动驾驶汽车（AV）的现有研究大多集中在高风险的“电车难题”上，这涉及极端且罕见的情况。虽然这些情境具有丰富的道德内涵，但很少适用于现实世界的自动驾驶汽车决策。在实践中，当自动驾驶汽车面临日常道德困境时，它们通常会优先严格遵守交通规则。相比之下，人类驾驶员可能会在特定情况下打破规则，并利用受安全和效率等实际问题影响的判断。根据有意义的人类控制的概念，自动驾驶汽车应该对包括驾驶员、弱势道路使用者和政策制定者在内的理由做出回应。本研究提出了一个新颖的基于人类理由的监督框架，该框架可以检测自动驾驶汽车行为与预期人类理由不符的情况，从而触发轨迹重新考虑。该框架与运动规划和控制系统集成，以支持实时适应，从而实现更能反映安全、效率和监管考量的决策。仿真结果表明，该方法可以通过在当前轨迹未能与人类理由保持一致时提示重新规划，帮助自动驾驶汽车更有效地应对动态驾驶环境中的道德挑战。这些发现表明，我们的方法为自动驾驶汽车提供了更具适应性和以人为本的决策路径。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶汽车研究主要关注罕见且极端的“电车难题”情境，而忽略了日常驾驶中常见的、需要平衡安全、效率和规则遵从性等竞争性优先事项的道德困境。人类驾驶员可能会根据安全和效率等实际问题在特定情境下打破规则，而自动驾驶汽车通常会严格遵守交通规则。为了实现有意义的人类控制，自动驾驶汽车需要响应人类的理由。

Method: 提出了一种新颖的基于人类理由的监督框架，该框架可检测自动驾驶汽车行为与预期人类理由不符的情况，以触发轨迹重新考虑，并与运动规划和控制系统集成以支持实时适应。

Result: 仿真结果表明，该方法通过在当前轨迹未能与人类理由保持一致时提示重新规划，有助于自动驾驶汽车更有效地应对动态驾驶环境中的道德挑战。

Conclusion: 该方法为自动驾驶汽车提供了更具适应性和以人为本的决策路径。

Abstract: Ethical dilemmas are a common challenge in everyday driving, requiring human
drivers to balance competing priorities such as safety, efficiency, and rule
compliance. However, much of the existing research in automated vehicles (AVs)
has focused on high-stakes "trolley problems," which involve extreme and rare
situations. Such scenarios, though rich in ethical implications, are rarely
applicable in real-world AV decision-making. In practice, when AVs confront
everyday ethical dilemmas, they often appear to prioritise strict adherence to
traffic rules. By contrast, human drivers may bend the rules in
context-specific situations, using judgement informed by practical concerns
such as safety and efficiency. According to the concept of meaningful human
control, AVs should respond to human reasons, including those of drivers,
vulnerable road users, and policymakers. This work introduces a novel human
reasons-based supervision framework that detects when AV behaviour misaligns
with expected human reasons to trigger trajectory reconsideration. The
framework integrates with motion planning and control systems to support
real-time adaptation, enabling decisions that better reflect safety,
efficiency, and regulatory considerations. Simulation results demonstrate that
this approach could help AVs respond more effectively to ethical challenges in
dynamic driving environments by prompting replanning when the current
trajectory fails to align with human reasons. These findings suggest that our
approach offers a path toward more adaptable, human-centered decision-making in
AVs.

</details>


### [365] [Energy management and flexibility quantification in a discrete event distribution grid simulation](https://arxiv.org/abs/2507.23396)
*Sebastian Peter,Daniel Feismann,Johannes Bao,Thomas Oberließen,Christian Rehtanz*

Main category: eess.SY

TL;DR: 该研究改进了配电网仿真软件，以应对可再生能源和产消者带来的复杂性，并通过离散事件方法优化了计算效率。


<details>
  <summary>Details</summary>
Motivation: 为了应对可再生能源和产消者日益普及所带来的配电网运行挑战，以及当前时间序列规划方法在高计算成本和复杂仿真场景下面临的困难。

Method: 通过离散事件系统规范（DES）来规定物理模型，并提供了一种利用离散事件范例的通信协议，该协议仅在必要时计算灵活性潜力。

Result: 提供了一个可以快速实现和测试能源管理算法的仿真软件增强，并提供了一个通信协议，可以优化灵活性潜力的计算。

Conclusion: 该研究提出了一种改进的离散事件配电网仿真软件，并开发了一种通信协议，以应对日益复杂的电网运行和规划挑战，特别是在可再生能源和产消者日益普及的情况下。

Abstract: Distribution grid operation faces new challenges caused by a rising share of
renewable energy sources and the introduction of additional types of loads to
the grid. With the increasing adoption of distributed generation and emerging
prosumer households, Energy Management Systems, which manage and apply
flexibility of connected devices, are gaining popularity. While potentially
beneficial to grid capacity, strategic energy management also adds to the
complexity of distribution grid operation and planning processes. Novel
approaches of time-series-based planning likewise face increasingly complex
simulation scenarios and rising computational cost. Discrete event modelling
helps facilitating simulations of such scenarios by restraining computation to
the most relevant points in simulation time. We provide an enhancement of a
discrete event distribution grid simulation software that offers fast
implementation and testing of energy management algorithms, embedded into a
feature-rich simulation environment. Physical models are specified using the
Discrete Event System Specification. Furthermore, we contribute a communication
protocol that makes use of the discrete event paradigm by only computing
flexibility potential when necessary.

</details>


### [366] [Advancing Standard Load Profiles with Data-Driven Techniques and Recent Datasets](https://arxiv.org/abs/2507.23401)
*Jawana Gabrielski,Ulf Häger*

Main category: eess.SY

TL;DR: This paper updates Germany's outdated Standard Load Profiles (SLP) for electricity consumption using recent smart meter data, proposes improvements, and introduces a new Fourier Series-based model for more accurate load modeling.


<details>
  <summary>Details</summary>
Motivation: Accurate electricity consumption estimation is crucial for energy system planning, operation, and billing. Existing SLP in Germany are outdated (over 20 years old) and do not reflect current consumption behaviors, leading to deviations. The increasing availability of smart meter data necessitates an update to SLP.

Method: The paper utilizes recent smart meter data to create updated SLP. It also validates the assumptions of the current SLP method and proposes improvements. A Fourier Series-based model is developed as an alternative to the current SLP.

Result: Updated SLP using recent data were created. Assumptions of the SLP method were validated, and improvements were proposed. A Fourier Series-based model was developed and compared with other models.

Conclusion: The paper proposes updated Standard Load Profiles (SLP) using recent data, validates existing SLP assumptions, suggests improvements for applicability, and introduces a Fourier Series-based model as an alternative SLP model. The different models are compared and evaluated.

Abstract: Estimating electricity consumption accurately is essential for the planning
and operation of energy systems, as well as for billing processes. Standard
Load Profiles (SLP) are widely used to estimate consumption patterns of
different user groups. However, in Germany these SLP were formulated using
historical data from over 20 years ago and have not been adjusted since.
Changing electricity consumption behaviour, which leads to increasing
deviations between load patterns and SLP, results in a need for a revision
taking into account new data. The growing number of smart meters provides a
large measurement database, which enables more accurate load modelling. This
paper creates updated SLP using recent data. In addition, the assumptions of
the SLP method are validated and improvements are proposed, taking into account
the ease of applicability. Furthermore, a Fourier Series-based model is
proposed as an alternative SLP model. The different models are compared and
evaluated.

</details>


### [367] [Distributionally Robust Cascading Risk Quantification in Multi-Agent Rendezvous: Effects of Time Delay and Network Connectivity](https://arxiv.org/abs/2507.23489)
*Vivek Pandey,Nader Motee*

Main category: eess.SY

TL;DR: 提出分布鲁棒风险框架，分析多智能体集合中的级联故障，并提出降低风险的设计方法。


<details>
  <summary>Details</summary>
Motivation: 为了应对自主多智能体系统在时间关键任务（如集合）中实现安全性的挑战，特别是级联故障问题。

Method: 提出了一种分布鲁棒风险框架，利用条件分布鲁棒泛函和双变量正态分布来量化代理之间的级联效应，并推导出闭式风险表达式。

Result: 得出了闭式风险表达式，揭示了时间延迟、噪声统计、通信拓扑和故障模式对集合风险的影响。

Conclusion: 该研究提出了一个分布鲁棒风险框架，用于分析多智能体集合中的级联故障，为设计更具弹性的网络以降低级联故障风险提供了理论指导，并通过仿真验证了其有效性。

Abstract: Achieving safety in autonomous multi-agent systems, particularly in
time-critical tasks like rendezvous, is a critical challenge. In this paper, we
propose a distributionally robust risk framework for analyzing cascading
failures in multi-agent rendezvous. To capture the complex interactions between
network connectivity, system dynamics, and communication delays, we use a
time-delayed network model as a benchmark. We introduce a conditional
distributionally robust functional to quantify cascading effects between
agents, utilizing a bi-variate normal distribution. Our approach yields
closed-form risk expressions that reveal the impact of time delay, noise
statistics, communication topology, and failure modes on rendezvous risk. The
insights derived inform the design of resilient networks that mitigate the risk
of cascading failures. We validate our theoretical results through extensive
simulations, demonstrating the effectiveness of our framework.

</details>


### [368] [Asynchronous Grid Connections Providing Fast-Frequency Response: System Integration Study](https://arxiv.org/abs/2507.23571)
*Felix Wald,Amir Sajadi,Barry Mather,Giovanni De Carne*

Main category: eess.SY

TL;DR: This paper shows that by using power electronics to connect distributed energy resources, they can work together to stabilize the grid frequency and make money by providing services to the grid operator. The study used experiments and simulations to prove this works and estimated the potential earnings over 15 years, also suggesting ways to improve the technology and regulations.


<details>
  <summary>Details</summary>
Motivation: The paper aims to demonstrate the technical feasibility and techno-economic viability of using power electronic-based fast-frequency response technology, specifically an asynchronous grid connection, to aggregate behind-the-meter resources and distributed generators for grid-supporting functionalities and participation in the ancillary services market.

Method: The paper presents an integration study for a power electronic-based fast-frequency response technology (asynchronous grid connection) for behind-the-meter resources and distributed generators. It includes technical feasibility and techno-economic viability studies. Dynamic performance was validated using Power Hardware-in-the-Loop experiments and transferred to an IEEE 9-bus system for dynamic stability analysis. A long-term simulation was performed embedding the system within the PJM ancillary service market framework to calculate potential revenue over a 15-year investment horizon.

Result: The study validates the dynamic performance of fast-frequency response enabled by the asynchronous grid connection through Power Hardware-in-the-Loop experiments. It demonstrates that aggregated distributed generators with droop-based control enhancements can provide grid-supporting functionalities and participate in the ancillary services market. The techno-economic analysis projects potential revenue based on fast-frequency response regulation within the PJM market over a 15-year investment horizon.

Conclusion: The study concludes that droop-based control enhancements for local distributed generators allow their aggregation to provide grid-supporting functionalities and participate in the ancillary services market. Techno-economic analysis provides recommendations for technical and regulatory enhancements to access the full potential of distributed generators.

Abstract: This paper presents an integration study for a power electronic-based
fast-frequency response technology, an asynchronous grid connection operating
as an aggregator for behindthe-meter resources and distributed generators. Both
technical feasibility and techno-economic viability studies are presented. The
dynamic performance of the fast-frequency response enabled by the asynchronous
grid connection is validated with Power Hardware-in-the-Loop experiments and
transferred to an IEEE 9-bus system in DigSilent PowerFactory for dynamic
stability analysis. We demonstrate that droop-based control enhancements to the
local distributed generators could allow their aggregation to provide
grid-supporting functionalities and participate in the market for ancillary
services. To this end, we performed a long-term simulation embedding the system
within the ancillary service market framework of PJM. The fast-frequency
response regulation is subsequently used to calculate the potential revenue and
project the results on a 15-year investment horizon. Finally, the
techno-economic analysis concludes with recommendations for enhancements to
access the full potential of distributed generators on a technical and
regulatory level.

</details>


### [369] [Tensor-based reduction of linear parameter-varying state-space models](https://arxiv.org/abs/2507.23591)
*Bogoljub Terzin,E. Javier Olucha,Amritam Das,Siep Weiland,Roland Tóth*

Main category: eess.SY

TL;DR: 本研究提出了一种新的方法，可以同时减小LPV模型的状态和调度信号的维度，解决了现有方法无法同时处理的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的LPV模型降维方法通常分别处理状态和调度信号维度，导致模型维度高且保守，限制了控制策略的应用。本研究旨在解决此问题。

Method: 通过将LPV模型表述为张量形式，并利用张量分解来找到状态和调度子空间的主导分量，并扩展了Petrov-Galerkin投影方法，增加了调度投影，实现了联合降维。

Result: 通过在两个串联质量-弹簧-阻尼系统上进行验证，证明了所提出方法的有效性，尤其是在处理高阶模型和评估可扩展性方面。

Conclusion: 该论文提出了一种用于线性参数变化（LPV）状态空间模型的联合降维方法，包括状态和调度信号维度。

Abstract: The Linear Parameter-Varying (LPV) framework is a powerful tool for
controlling nonlinear and complex systems, but the conversion of nonlinear
models into LPV forms often results in high-dimensional and overly conservative
LPV models. To be able to apply control strategies, there is often a need for
model reduction in order to reduce computational needs. This paper presents the
first systematic approach for the joint reduction of state order and scheduling
signal dimension of LPV state space models. The existing methods typically
address these reductions separately. By formulating a tensorial form of LPV
models with an affine dependency on the scheduling variables, we leverage
tensor decomposition to find the dominant components of state and scheduling
subspaces. We extend the common Petrov-Galerkin projection approach to LPV
framework by adding a scheduling projection. This extension enables the joint
reduction. To find suitable subspaces for the extended Petrov-Galerkin
projection, we have developed two different methods: tensor-based LPV moment
matching, and an approach through Proper Orthogonal Decomposition. Advantages
of the proposed methods are demonstrated on two different series-interconnected
mass-spring-damper systems with nonlinear springs: one primarily used for
comparison with other methods and a more elaborate higher-order model designed
to assess scalability.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [370] [Unifying Post-hoc Explanations of Knowledge Graph Completions](https://arxiv.org/abs/2507.22951)
*Alessandro Lonardi,Samy Badreddine,Tarek R. Besold,Pablo Sanchez Martin*

Main category: cs.AI

TL;DR: 本研究提出了一种统一的方法来处理知识图谱补全（KGC）的事后可解释性问题，旨在通过多目标优化来平衡解释的有效性和简洁性，并改进评估协议，以提高研究的可复现性和影响力。


<details>
  <summary>Details</summary>
Motivation: 事后可解释性缺乏正式化和一致的评估，阻碍了可复现性和跨研究比较。

Method: 提出一个通用框架，通过多目标优化来表征事后解释，平衡其有效性和简洁性。这统一了现有的 KGC 事后可解释性算法及其产生的解释。此外，还提出并通过实验支持使用流行的指标（如平均倒数排名和 Hits@k）改进评估协议。

Result: 提出了一个通用的事后解释框架，并改进了评估协议，强调了可解释性作为解决用户查询的能力。

Conclusion: 通过统一方法和完善评估标准，本研究旨在使知识图谱补全（KGC）可解释性研究更具可复现性和影响力。

Abstract: Post-hoc explainability for Knowledge Graph Completion (KGC) lacks
formalization and consistent evaluations, hindering reproducibility and
cross-study comparisons. This paper argues for a unified approach to post-hoc
explainability in KGC. First, we propose a general framework to characterize
post-hoc explanations via multi-objective optimization, balancing their
effectiveness and conciseness. This unifies existing post-hoc explainability
algorithms in KGC and the explanations they produce. Next, we suggest and
empirically support improved evaluation protocols using popular metrics like
Mean Reciprocal Rank and Hits@$k$. Finally, we stress the importance of
interpretability as the ability of explanations to address queries meaningful
to end-users. By unifying methods and refining evaluation standards, this work
aims to make research in KGC explainability more reproducible and impactful.

</details>


### [371] [Data Readiness for Scientific AI at Scale](https://arxiv.org/abs/2507.23018)
*Wesley Brewer,Patrick Widener,Valentine Anantharaj,Feiyi Wang,Tom Beck,Arjun Shankar,Sarp Oral*

Main category: cs.AI

TL;DR: 本研究检查了DRAI原则在领导规模的科学数据集中的应用，这些数据集用于训练基础模型。研究人员分析了四个领域的典型工作流程，以确定共同的预处理模式和特定于域的约束。他们提出了一个二维就绪框架，该框架结合了数据就绪级别和数据处理阶段，并针对高性能计算环境进行了定制。该框架旨在为科学数据准备提供概念成熟度矩阵，并指导基础设施开发，以支持可扩展和可复现的科学AI。


<details>
  <summary>Details</summary>
Motivation: 检查数据就绪能力（DRAI）原则如何应用于用于训练基础模型的领导规模的科学数据集。

Method: 提出了一种由数据就绪级别（从原始到AI就绪）和数据处理阶段（从摄取到分片）组成的二维就绪框架，并针对高性能计算环境进行了定制。

Result: 确定了常见的预处理模式和特定于域的约束，并为科学数据准备提供了概念成熟度矩阵。

Conclusion: 该框架为科学数据集的准备情况提供了概念模型，并指导基础设施开发，以实现可扩展和可复现的科学AI。

Abstract: This paper examines how Data Readiness for AI (DRAI) principles apply to
leadership-scale scientific datasets used to train foundation models. We
analyze archetypal workflows across four representative domains - climate,
nuclear fusion, bio/health, and materials - to identify common preprocessing
patterns and domain-specific constraints. We introduce a two-dimensional
readiness framework composed of Data Readiness Levels (raw to AI-ready) and
Data Processing Stages (ingest to shard), both tailored to high performance
computing (HPC) environments. This framework outlines key challenges in
transforming scientific data for scalable AI training, emphasizing
transformer-based generative models. Together, these dimensions form a
conceptual maturity matrix that characterizes scientific data readiness and
guides infrastructure development toward standardized, cross-domain support for
scalable and reproducible AI for science.

</details>


### [372] [FairReason: Balancing Reasoning and Social Bias in MLLMs](https://arxiv.org/abs/2507.23067)
*Zhenyu Pan,Yutong Zhang,Jianshu Zhang,Haoran Lu,Haozheng Luo,Yuwei Han,Philip S. Yu,Manling Li,Han Liu*

Main category: cs.AI

TL;DR: 该研究探讨了提升多模态大语言模型（MLLMs）的推理能力与减少其社会偏见之间的平衡。通过对监督微调（SFT）、知识蒸馏（KD）和强化学习（RL）三种方法的测试，发现当使用1:4的去偏见与推理样本混合训练时，强化学习能有效降低模型偏见，同时保留大部分推理能力。


<details>
  <summary>Details</summary>
Motivation: 为了进一步提升多模态大语言模型（MLLMs）的推理能力，现有研究探索了高级提示技巧和训练后微调。然而，这些技术在提升逻辑准确性的同时，往往会使模型的输出带有明显的社会偏见。因此，阐明推理能力的提升如何与偏见缓解相互作用，以及两者之间是否存在固有的权衡关系，仍然是一个悬而未决且亟待解决的研究问题。

Method: 研究首先在相同条件下对三种偏见缓解策略——监督微调（SFT）、知识蒸馏（KD）和基于规则的强化学习（RL）——进行了基准测试，以确定它们各自的优势和劣势。在此基础上，通过改变每种范式中侧重于去偏见和侧重于推理的样本比例，描绘了推理与偏见之间的权衡关系。

Result: 实验结果揭示了一个持续存在的“最佳平衡点”：在强化学习范式下，使用大约1:4的去偏见与推理导向样本混合训练，可以将刻板印象分数降低10%，同时保留88%的模型原始推理准确性。这为平衡MLLMs的公平性和能力提供了具体的指导。

Conclusion: 该研究通过实验揭示了在多模态大语言模型（MLLMs）的推理能力提升与偏见缓解之间存在一个“最佳平衡点”，即在强化学习范式下，使用大约1:4的去偏见与推理导向样本混合训练，可以将刻板印象分数降低10%，同时保留88%的原始推理准确性。

Abstract: Multimodal Large Language Models (MLLMs) already achieve state-of-the-art
results across a wide range of tasks and modalities. To push their reasoning
ability further, recent studies explore advanced prompting schemes and
post-training fine-tuning. Although these techniques improve logical accuracy,
they frequently leave the models' outputs burdened with pronounced social
biases. Clarifying how reasoning gains interact with bias mitigation-and
whether the two objectives inherently trade off-therefore remains an open and
pressing research problem. Our study begins by benchmarking three
bias-mitigation strategies-supervised fine-uning (SFT), knowledge distillation
(KD), and rule-based reinforcement learning (RL)-under identical conditions,
establishing their baseline strengths and weaknesses. Building on these
results, we vary the proportion of debias-focused and reasoning-centric samples
within each paradigm to chart the reasoning-versus-bias trade-off. Our sweeps
reveal a consistent sweet spot: a roughly 1:4 mix trained with reinforcement
learning cuts stereotype scores by 10% while retaining 88% of the model's
original reasoning accuracy, offering concrete guidance for balancing fairness
and capability in MLLMs.

</details>


### [373] [Chatting with your ERP: A Recipe](https://arxiv.org/abs/2507.23429)
*Jorge Ruiz Gómez,Lidia Andrés Susinos,Jorge Alamo Olivé,Sonia Rey Osorno,Manuel Luis Gonzalez Hernández*

Main category: cs.AI

TL;DR: An LLM agent was created to chat with an ERP system, turning natural language into SQL. A new dual-agent design makes it more reliable.


<details>
  <summary>Details</summary>
Motivation: The motivation behind this paper is to enable interaction with industrial production-grade ERP systems using natural language, thereby simplifying data access and operational tasks for users.

Method: The study proposes a novel dual-agent architecture that combines reasoning and critique stages to improve the reliability of query generation. This architecture leverages open-weight LLMs to interpret natural language queries and translate them into executable SQL statements.

Result: The LLM agent can interpret natural language queries and generate executable SQL statements for an industrial ERP system. The dual-agent architecture shows improved query generation reliability.

Conclusion: The paper successfully designed, implemented, and evaluated an LLM agent capable of interacting with an industrial ERP system by translating natural language queries into SQL statements. A dual-agent architecture was proposed to enhance reliability.

Abstract: This paper presents the design, implementation, and evaluation behind a Large
Language Model (LLM) agent that chats with an industrial production-grade ERP
system. The agent is capable of interpreting natural language queries and
translating them into executable SQL statements, leveraging open-weight LLMs. A
novel dual-agent architecture combining reasoning and critique stages was
proposed to improve query generation reliability.

</details>


### [374] [Moravec's Paradox: Towards an Auditory Turing Test](https://arxiv.org/abs/2507.23091)
*David Noever,Forrest McKee*

Main category: cs.AI

TL;DR: 当前AI在声音任务上表现糟糕，在包含各种挑战的听觉测试中失败率超93%，远低于人类表现。AI在选择性注意、噪声处理和适应性方面存在不足，需要新的方法来提升其听觉能力。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是探索当前人工智能系统在处理对人类而言轻松完成的听觉任务时所表现出的灾难性失败。受到莫拉维克悖论的启发，该研究旨在量化人工智能与人类在听觉能力上的差距，并找出导致这些失败的原因。

Method: 本研究引入了一个包含917个挑战的听觉图灵测试，涵盖了重叠语音、噪声语音、时间失真、空间音频、咖啡店噪声、电话失真和感知错觉七个类别，以评估当前人工智能系统在声音任务上的表现。研究评估了包括GPT-4和OpenAI的Whisper在内的最先进的音频模型。

Result: 评估结果显示，当前最先进的音频模型，包括GPT-4和OpenAI的Whisper，在听觉图灵测试中取得了超过93%的惊人失败率。即使是表现最好的模型，在人类成功率7.5倍（52%）的任务上的准确率也仅为6.9%。这暴露了人工智能系统在处理复杂听觉场景时的缺陷，尤其是在选择性注意、噪声鲁棒性和上下文适应性方面。

Conclusion: 目前的人工智能系统在处理声音任务方面存在严重缺陷，即使是像GPT-4和OpenAI的Whisper这样的先进模型，在包含各种挑战的听觉图灵测试中的失败率也超过93%。这表明当前的人工智能在选择性注意力、噪声鲁棒性和上下文适应性方面存在不足，缺乏类似人类的听觉场景分析机制。该研究提出了一个诊断框架来衡量机器听觉能力的进步，并强调需要新的方法来整合选择性注意、基于物理的声音理解和上下文感知到多模态人工智能系统中。

Abstract: This research work demonstrates that current AI systems fail catastrophically
on auditory tasks that humans perform effortlessly. Drawing inspiration from
Moravec's paradox (i.e., tasks simple for humans often prove difficult for
machines, and vice versa), we introduce an auditory Turing test comprising 917
challenges across seven categories: overlapping speech, speech in noise,
temporal distortion, spatial audio, coffee-shop noise, phone distortion, and
perceptual illusions. Our evaluation of state-of-the-art audio models including
GPT-4's audio capabilities and OpenAI's Whisper reveals a striking failure rate
exceeding 93%, with even the best-performing model achieving only 6.9% accuracy
on tasks that humans solved at 7.5 times higher success (52%). These results
expose focusing failures in how AI systems process complex auditory scenes,
particularly in selective attention, noise robustness, and contextual
adaptation. Our benchmark not only quantifies the human-machine auditory gap
but also provides insights into why these failures occur, suggesting that
current architectures lack fundamental mechanisms for human-like auditory scene
analysis. The traditional design of audio CAPTCHAs highlights common filters
that humans evolved but machines fail to select in multimodal language models.
This work establishes a diagnostic framework for measuring progress toward
human-level machine listening and highlights the need for novel approaches
integrating selective attention, physics-based audio understanding, and
context-aware perception into multimodal AI systems.

</details>


### [375] [Argumentatively Coherent Judgmental Forecasting](https://arxiv.org/abs/2507.23163)
*Deniz Gorur,Antonio Rago,Francesca Toni*

Main category: cs.AI

TL;DR: 研究了预测的论证连贯性，发现强制执行连贯性可以提高准确性，但用户通常不符合此属性。


<details>
  <summary>Details</summary>
Motivation: 为了研究围绕预测形成的论证结构的预测属性，并提出一种衡量预测与其论证之间一致性的论证连贯性属性。

Method: 提出并正式定义了论证连贯性属性，研究了强制执行连贯性对人类和大型语言模型（LLM）预测者的影响，并通过众包用户实验评估了用户与连贯性属性的一致性。

Result: 强制执行连贯性可以提高人类和LLM预测的准确性。用户通常不符合连贯性属性，需要过滤掉不连贯的意见。

Conclusion: 过滤掉不连贯的预测可以持续提高预测准确性，证明了连贯性在人类和大型语言模型（LLM）预测中的实用价值。用户通常不符合连贯性属性，这表明在基于论证的判断性预测中需要机制来过滤掉不连贯的意见，然后再获得小组预测。

Abstract: Judgmental forecasting employs human opinions to make predictions about
future events, rather than exclusively historical data as in quantitative
forecasting. When these opinions form an argumentative structure around
forecasts, it is useful to study the properties of the forecasts from an
argumentative perspective. In this paper, we advocate and formally define a
property of argumentative coherence, which, in essence, requires that a
forecaster's reasoning is coherent with their forecast. We then conduct three
evaluations with our notion of coherence. First, we assess the impact of
enforcing coherence on human forecasters as well as on Large Language Model
(LLM)-based forecasters, given that they have recently shown to be competitive
with human forecasters. In both cases, we show that filtering out incoherent
predictions improves forecasting accuracy consistently, supporting the
practical value of coherence in both human and LLM-based forecasting. Then, via
crowd-sourced user experiments, we show that, despite its apparent
intuitiveness and usefulness, users do not generally align with this coherence
property. This points to the need to integrate, within argumentation-based
judgmental forecasting, mechanisms to filter out incoherent opinions before
obtaining group forecasting predictions.

</details>


### [376] [Tractable Responsibility Measures for Ontology-Mediated Query Answering](https://arxiv.org/abs/2507.23191)
*Meghyn Bienvenu,Diego Figueira,Pierre Lafourcade*

Main category: cs.AI

TL;DR: 本研究分析了本体中介查询应答中基于 Shapley 值的责任度量（WSMS）的计算复杂性。研究发现，虽然在某些情况下（如一阶可重写查询）计算是可处理的，但在其他情况下（如支持可达性查询或合取的本体语言）则会变得困难。不过，对于 DL-Lite 方言中的特定查询类型，WSMS 计算仍然是可行的。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于量化本体中介查询应答中事实的贡献度。它侧重于一种新提出的基于 Shapley 值的责任度量方法，该方法基于加权最小支持集（WSMS），旨在理解在本体中介查询应答的背景下计算这些责任得分的复杂性。

Method: 该研究利用数据库领域的现有成果，表明对于一阶可重写的本体中介查询，WSMS（基于 Shapley 值的责任度量）具有多项式数据复杂性。当本体语言能够通过像 $\exists R. A \sqsubseteq A$ 这样的公理来编码可达性查询时，问题会变得“shP”-hard。为了更全面地了解处理能力的前沿，研究人员还探讨了 WSMS 计算的组合复杂性。

Result: 对于一阶可重写的本体中介查询，WSMS 具有多项式数据复杂性。然而，当本体语言支持可达性查询时，计算 WSMS 的问题会变成“shP”-hard。此外，即使没有本体，对于支持合取的本体语言，原子查询的 WSMS 计算的组合复杂性也是难以处理的，同样对于‘良好行为’的合取查询的并集也是如此。然而，对于 DL-Lite 方言中的某些结构受限的合取查询，WSMS 计算是可处理的。

Conclusion: WSMS 计算的复杂性在本体语言支持合取时，即使在没有本体的情况下，对于原子查询也变得难以处理，并且对于‘良好行为’的合取查询的并集也是如此。然而，通过仔细分析，我们确定了结构受限的合取查询类别（直观上不允许查询原子之间产生不良交互），可以实现可处理的 WSMS 计算，特别是在常见的 DL-Lite 方言中。

Abstract: Recent work on quantitative approaches to explaining query answers employs
responsibility measures to assign scores to facts in order to quantify their
respective contributions to obtaining a given answer. In this paper, we study
the complexity of computing such responsibility scores in the setting of
ontology-mediated query answering, focusing on a very recently introduced
family of Shapley-value-based responsibility measures defined in terms of
weighted sums of minimal supports (WSMS). By exploiting results from the
database setting, we can show that such measures enjoy polynomial data
complexity for classes of ontology-mediated queries that are
first-order-rewritable, whereas the problem becomes "shP"-hard when the
ontology language can encode reachability queries (via axioms like $\exists R.
A \sqsubseteq A$). To better understand the tractability frontier, we next
explore the combined complexity of WSMS computation. We prove that
intractability applies already to atomic queries if the ontology language
supports conjunction, as well as to unions of `well-behaved' conjunctive
queries, even in the absence of an ontology. By contrast, our study yields
positive results for common DL-Lite dialects: by means of careful analysis, we
identify classes of structurally restricted conjunctive queries (which
intuitively disallow undesirable interactions between query atoms) that admit
tractable WSMS computation.

</details>


### [377] [Solution-aware vs global ReLU selection: partial MILP strikes back for DNN verification](https://arxiv.org/abs/2507.23197)
*Yuke Liao,Blaise Genest,Kuldeep Meel,Shaan Aryaman*

Main category: cs.AI

TL;DR: This paper proposes a new method (SAS) to efficiently select important ReLU variables for verifying neural networks. It uses a divide-and-conquer approach with partial MILP calls, significantly reducing the number of binary variables needed while maintaining accuracy. The Hybrid MILP implementation is effective even for large CNNs.


<details>
  <summary>Details</summary>
Motivation: To handle complex instances by breaking down complexity using a divide-and-conquer approach, relying on many small partial MILP calls. The goal is to efficiently select a few important ReLUs to treat using costly binary variables, addressing the suboptimality of previous attempts.

Method: The paper proposes a divide-and-conquer approach using many small partial MILP calls instead of few complex BaB calls. It introduces a novel solution-aware ReLU scoring (SAS) and adapts BaB-SR and BaB-FSB branching functions as global ReLU scoring (GS) functions to select important ReLU variables. The method is implemented in Hybrid MILP, which first calls $\alpha,\beta$-CROWN with a short time-out and then partial MILP.

Result: SAS reduces the number of binary variables by around 6 times while maintaining the same level of accuracy. Hybrid MILP reduces the number of undecided instances to low levels (8-15%) with a reasonable runtime per instance, even for large CNNs.

Conclusion: SAS is more efficient at selecting a set of variables to open using binary variables, reducing the number of binary variables by around 6 times while maintaining the same level of accuracy. Hybrid MILP, calling first $\alpha,\beta$-CROWN with a short time-out to solve easier instances, and then partial MILP, produces a very accurate yet efficient verifier, reducing the number of undecided instances to low levels (8-15%) while keeping a reasonable runtime per instance, even for fairly large CNNs.

Abstract: To handle complex instances, we revisit a divide-and-conquer approach to
break down the complexity: instead of few complex BaB calls, we rely on many
small {\em partial} MILP calls. The crucial step is to select very few but very
important ReLUs to treat using (costly) binary variables. The previous attempts
were suboptimal in that respect. To select these important ReLU variables, we
propose a novel {\em solution-aware} ReLU scoring ({\sf SAS}), as well as adapt
the BaB-SR and BaB-FSB branching functions as {\em global} ReLU scoring ({\sf
GS}) functions. We compare them theoretically as well as experimentally, and
{\sf SAS} is more efficient at selecting a set of variables to open using
binary variables. Compared with previous attempts, SAS reduces the number of
binary variables by around 6 times, while maintaining the same level of
accuracy. Implemented in {\em Hybrid MILP}, calling first $\alpha,\beta$-CROWN
with a short time-out to solve easier instances, and then partial MILP,
produces a very accurate yet efficient verifier, reducing by up to $40\%$ the
number of undecided instances to low levels ($8-15\%$), while keeping a
reasonable runtime ($46s-417s$ on average per instance), even for fairly large
CNNs with 2 million parameters.

</details>


### [378] [DSBC : Data Science task Benchmarking with Context engineering](https://arxiv.org/abs/2507.23336)
*Ram Mohan Rao Kadiyala,Siddhant Gupta,Jebish Purbey,Giulio Martini,Suman Debnath,Hamza Farooq*

Main category: cs.AI

TL;DR: 该研究提出了一个数据科学代理基准，评估了三个 LLM 在不同方法下的性能，并研究了提示问题和温度参数的影响，以指导未来研究。


<details>
  <summary>Details</summary>
Motivation: 为了应对数据科学代理（源于 LLM 的自动化分析工具）的快速普及，但缺乏对其有效性和局限性的系统性评估，因此有必要创建一个专门的基准。

Method: 通过观察商业应用程序的使用情况，引入了一个全面的基准来评估 Claude-4.0-Sonnet、Gemini-2.5-Flash 和 OpenAI-o4-Mini 这三个 LLM 在零样本、多步和 SmolAgent 方法下的性能。评估涵盖了八个数据科学任务类别，并探讨了模型对数据泄露和指令模糊等提示问题的敏感性以及温度参数的影响。

Result: 评估结果显示，在所评估的模型和方法之间存在明显的性能差异，具体揭示了影响实际部署的关键因素。

Conclusion: 该基准测试为评估和改进数据科学代理提供了基础，揭示了模型和方法之间的性能差异，并强调了实际部署的关键因素。

Abstract: Recent advances in large language models (LLMs) have significantly impacted
data science workflows, giving rise to specialized data science agents designed
to automate analytical tasks. Despite rapid adoption, systematic benchmarks
evaluating the efficacy and limitations of these agents remain scarce. In this
paper, we introduce a comprehensive benchmark specifically crafted to reflect
real-world user interactions with data science agents by observing usage of our
commercial applications. We evaluate three LLMs: Claude-4.0-Sonnet,
Gemini-2.5-Flash, and OpenAI-o4-Mini across three approaches: zero-shot with
context engineering, multi-step with context engineering, and with SmolAgent.
Our benchmark assesses performance across a diverse set of eight data science
task categories, additionally exploring the sensitivity of models to common
prompting issues, such as data leakage and slightly ambiguous instructions. We
further investigate the influence of temperature parameters on overall and
task-specific outcomes for each model and approach. Our findings reveal
distinct performance disparities among the evaluated models and methodologies,
highlighting critical factors that affect practical deployment. The benchmark
dataset and evaluation framework introduced herein aim to provide a foundation
for future research of more robust and effective data science agents.

</details>


### [379] [How Far Are AI Scientists from Changing the World?](https://arxiv.org/abs/2507.23276)
*Qiujie Xie,Yixuan Weng,Minjun Zhu,Fuchen Shen,Shulin Huang,Zhen Lin,Jiahui Zhou,Zilan Mao,Zijie Yang,Linyi Yang,Jian Wu,Yue Zhang*

Main category: cs.AI

TL;DR: AI科学家发展迅速，但距离颠覆性创新尚有距离，需要明确目标和克服瓶颈。


<details>
  <summary>Details</summary>
Motivation: 探讨AI科学家距离改变世界和重塑科学研究范式还有多远，以期为该领域的发展提供清晰的认识。

Method: 对AI科学家系统的当前成就进行了全面的、以前景为导向的回顾，识别了关键瓶颈和未来发展所需的核心要素。

Result: AI科学家系统在科学研究中扮演着越来越重要的角色，已经有AI生成的论文被顶级会议的 workshop 接受，预示着未来可能出现能够发现未知现象的、达到人类水平的AI科学家。

Conclusion: AI科学家正快速发展，但距离实现能够解决重大挑战的突破性发现还有差距，明确发展目标至关重要。

Abstract: The emergence of large language models (LLMs) is propelling automated
scientific discovery to the next level, with LLM-based Artificial Intelligence
(AI) Scientist systems now taking the lead in scientific research. Several
influential works have already appeared in the field of AI Scientist systems,
with AI-generated research papers having been accepted at the ICLR 2025
workshop, suggesting that a human-level AI Scientist capable of uncovering
phenomena previously unknown to humans, may soon become a reality. In this
survey, we focus on the central question: How far are AI scientists from
changing the world and reshaping the scientific research paradigm? To answer
this question, we provide a prospect-driven review that comprehensively
analyzes the current achievements of AI Scientist systems, identifying key
bottlenecks and the critical components required for the emergence of a
scientific agent capable of producing ground-breaking discoveries that solve
grand challenges. We hope this survey will contribute to a clearer
understanding of limitations of current AI Scientist systems, showing where we
are, what is missing, and what the ultimate goals for scientific AI should be.

</details>


### [380] [AI Must not be Fully Autonomous](https://arxiv.org/abs/2507.23330)
*Tosin Adewumi,Lama Alkhaled,Florent Imbert,Hui Han,Nudrat Habib,Karl Löwenmark*

Main category: cs.AI

TL;DR: Fully autonomous AI is risky; human oversight is crucial. This paper outlines AI autonomy levels, presents arguments against full autonomy, and cites evidence of AI risks.


<details>
  <summary>Details</summary>
Motivation: To address the risks associated with autonomous AI, particularly the potential development of ASI.

Method: Discuss theories of autonomy, AI, and agents, and present 12 arguments with 6 counterarguments and rebuttals.

Result: Identified 3 levels of autonomous AI and argued against full autonomy without human oversight, citing 15 pieces of evidence of AI misalignment and risks.

Conclusion: AI must not be fully autonomous due to significant risks, especially with the potential emergence of ASI.

Abstract: Autonomous Artificial Intelligence (AI) has many benefits. It also has many
risks. In this work, we identify the 3 levels of autonomous AI. We are of the
position that AI must not be fully autonomous because of the many risks,
especially as artificial superintelligence (ASI) is speculated to be just
decades away. Fully autonomous AI, which can develop its own objectives, is at
level 3 and without responsible human oversight. However, responsible human
oversight is crucial for mitigating the risks. To ague for our position, we
discuss theories of autonomy, AI and agents. Then, we offer 12 distinct
arguments and 6 counterarguments with rebuttals to the counterarguments. We
also present 15 pieces of recent evidence of AI misaligned values and other
risks in the appendix.

</details>


### [381] [LLM4Rail: An LLM-Augmented Railway Service Consulting Platform](https://arxiv.org/abs/2507.23377)
*Zhuo Li,Xianghuai Deng,Chiwei Feng,Hanmeng Li,Shenjie Wang,Haichao Zhang,Teng Jia,Conlin Chen,Louis Linchun Wu,Jia Wang*

Main category: cs.AI

TL;DR: LLM4Rail是一个利用LLM和QTAO框架的铁路服务咨询平台，能提供个性化服务，并已构建CRFD-25数据集和LLM餐饮推荐系统。


<details>
  <summary>Details</summary>
Motivation: 为了满足日益增长的个性化铁路服务的需求，并利用大型语言模型（LLM）的潜力来改进铁路业务。

Method: 提出了一种名为LLM4Rail的新型LLM增强型铁路服务咨询平台。该平台采用迭代式的“问题-思考-行动-观察（QTAO）”提示框架，将口头推理与面向任务的行动相结合，以检索与铁路运营和服务相关的外部观察，从而生成准确的响应。此外，还构建了一个名为CRFD-25的中文铁路餐饮公开数据集，并引入了一个基于LLM的零样本会话推荐系统，以及一个基于特征相似性的后处理步骤，以确保推荐的餐饮项目与CRFD-25数据集保持一致。

Result: LLM4Rail能够提供定制化的模块，用于票务、铁路餐饮推荐、天气信息和闲聊。通过QTAO框架，实现了有效的外部信息检索和准确的响应生成。基于LLM的零样本推荐系统在CRFD-25数据集上实现了对铁路餐饮的个性化推荐，并通过后处理步骤确保了推荐结果的一致性。

Conclusion: LLM4Rail通过结合LLM的强大能力和QTAO框架，为铁路服务咨询提供了一个创新的解决方案，并在个性化餐饮推荐方面取得了显著进展。

Abstract: Large language models (LLMs) have significantly reshaped different walks of
business. To meet the increasing demands for individualized railway service, we
develop LLM4Rail - a novel LLM-augmented railway service consulting platform.
Empowered by LLM, LLM4Rail can provide custom modules for ticketing, railway
food & drink recommendations, weather information, and chitchat. In LLM4Rail,
we propose the iterative "Question-Thought-Action-Observation (QTAO)" prompting
framework. It meticulously integrates verbal reasoning with task-oriented
actions, that is, reasoning to guide action selection, to effectively retrieve
external observations relevant to railway operation and service to generate
accurate responses. To provide personalized onboard dining services, we first
construct the Chinese Railway Food and Drink (CRFD-25) - a publicly accessible
takeout dataset tailored for railway services. CRFD-25 covers a wide range of
signature dishes categorized by cities, cuisines, age groups, and spiciness
levels. We further introduce an LLM-based zero-shot conversational recommender
for railway catering. To address the unconstrained nature of open
recommendations, the feature similarity-based post-processing step is
introduced to ensure all the recommended items are aligned with CRFD-25
dataset.

</details>


### [382] [Self-Foveate: Enhancing Diversity and Difficulty of Synthesized Instructions from Unsupervised Text via Multi-Level Foveation](https://arxiv.org/abs/2507.23440)
*Mingzhe Li,Xin Lu,Yanyan Zhao*

Main category: cs.AI

TL;DR: Self-Foveate is a new LLM-based method that improves instruction synthesis by using a "Micro-Scatter-Macro" foveation technique to extract diverse and challenging instructions from text, outperforming previous approaches.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of conventional methods in ensuring adequate diversity and difficulty of synthesized instructions for training LLMs, which often rely on human annotation or have limited automated synthesis capabilities.

Method: Self-Foveate, an LLM-driven method using a "Micro-Scatter-Macro" multi-level foveation methodology to excavate fine-grained information from unsupervised text for instruction synthesis.

Result: Comprehensive experiments across multiple unsupervised corpora and diverse model architectures validate the effectiveness and superiority of the proposed Self-Foveate method.

Conclusion: Self-Foveate method enhances both diversity and difficulty of synthesized instructions, outperforming existing methods in experiments.

Abstract: Large language models (LLMs) with instruction following capabilities have
demonstrated impressive problem-solving abilities. While synthesizing
instructional data from unsupervised text has become a common approach for
training such models, conventional methods rely heavily on human effort for
data annotation. Although existing automated synthesis paradigms have
alleviated this constraint, they still exhibit significant limitations in
ensuring adequate diversity and difficulty of synthesized instructions. To
address these challenges, we propose Self-Foveate, an innovative LLM-driven
method for instruction synthesis. This approach introduces a
"Micro-Scatter-Macro" multi-level foveation methodology that effectively guides
the LLM to deeply excavate fine-grained information embedded in unsupervised
text, thereby enhancing both the diversity and difficulty of synthesized
instructions. Comprehensive experiments across multiple unsupervised corpora
and diverse model architectures validate the effectiveness and superiority of
our proposed method. We publicly release our data and codes:
https://github.com/Mubuky/Self-Foveate

</details>


### [383] [Causal Reasoning in Pieces: Modular In-Context Learning for Causal Discovery](https://arxiv.org/abs/2507.23488)
*Kacper Kadziolka,Saber Salehkaleybar*

Main category: cs.AI

TL;DR: 大型语言模型在因果发现方面表现出色，尤其是在结合思维之树和思维链的上下文框架后，性能有显著提升。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在因果发现任务上的能力，以应对传统模型在过拟合和数据扰动下表现不佳的问题。

Method: 提出了一种受思维之树和思维链方法启发的模块化上下文管道，并分析了推理链的长度、复杂性，以及对传统和推理模型进行定性和定量比较。

Result: 在Corr2Cause基准测试中，OpenAI的o系列和DeepSeek-R模型家族等推理优先的架构取得了比以往方法显著更大的本地收益。所提出的管道使性能比传统基线提高了近三倍。

Conclusion: 该研究表明，先进的推理模型虽然是向前迈出的一大步，但精心设计的上下文框架对于最大化其能力至关重要，并为跨不同领域的因果发现提供了可推广的蓝图。

Abstract: Causal inference remains a fundamental challenge for large language models.
Recent advances in internal reasoning with large language models have sparked
interest in whether state-of-the-art reasoning models can robustly perform
causal discovery-a task where conventional models often suffer from severe
overfitting and near-random performance under data perturbations. We study
causal discovery on the Corr2Cause benchmark using the emergent OpenAI's
o-series and DeepSeek-R model families and find that these reasoning-first
architectures achieve significantly greater native gains than prior approaches.
To capitalize on these strengths, we introduce a modular in-context pipeline
inspired by the Tree-of-Thoughts and Chain-of-Thoughts methodologies, yielding
nearly three-fold improvements over conventional baselines. We further probe
the pipeline's impact by analyzing reasoning chain length, complexity, and
conducting qualitative and quantitative comparisons between conventional and
reasoning models. Our findings suggest that while advanced reasoning models
represent a substantial leap forward, carefully structured in-context
frameworks are essential to maximize their capabilities and offer a
generalizable blueprint for causal discovery across diverse domains.

</details>


### [384] [Causal Identification of Sufficient, Contrastive and Complete Feature Sets in Image Classification](https://arxiv.org/abs/2507.23497)
*David A Kelly,Hana Chockler*

Main category: cs.AI

TL;DR: 该研究提出了一种名为“因果解释”的新方法，用于解释图像分类器的输出。与现有方法相比，因果解释具有更严格的形式定义，并且适用于黑盒模型。研究还引入了“对比因果解释”和“完整因果解释”，并通过实验证明了该方法的有效性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的图像分类器解释算法缺乏严格的形式定义，而逻辑基础的解释虽然有严格的形式定义，但计算上依赖于对模型不成立的严格假设。本研究旨在提出一种既有严格形式定义又适用于图像分类器的解释方法。

Method: 该研究提出了一种新的图像分类器解释方法，即因果解释，并证明了其形式属性。研究人员实现了该方法，并引入了对比因果解释和完整的因果解释（考虑了置信度感知）。

Result: 实验结果表明，不同的模型在充分性、对比性和完整性方面表现出不同的模式。所提出的算法计算效率高，平均每张 ResNet50 模型图像的计算时间为 6 秒，并且是完全的黑盒方法，无需了解模型、访问模型内部或梯度，也无需模型具有单调性等属性。

Conclusion: 该研究表明，因果解释具有与逻辑基础的解释相同的形式属性，同时又适用于黑盒算法，并且能够很好地处理图像分类器。研究人员还通过置信度感知来增强解释的定义，并引入了完整的因果解释，这种解释的分类置信度与原始图像完全相同。

Abstract: Existing algorithms for explaining the outputs of image classifiers are based
on a variety of approaches and produce explanations that lack formal rigor. On
the other hand, logic-based explanations are formally and rigorously defined
but their computability relies on strict assumptions about the model that do
not hold on image classifiers.
  In this paper, we show that causal explanations, in addition to being
formally and rigorously defined, enjoy the same formal properties as
logic-based ones, while still lending themselves to black-box algorithms and
being a natural fit for image classifiers. We prove formal properties of causal
explanations and introduce contrastive causal explanations for image
classifiers. Moreover, we augment the definition of explanation with confidence
awareness and introduce complete causal explanations: explanations that are
classified with exactly the same confidence as the original image.
  We implement our definitions, and our experimental results demonstrate that
different models have different patterns of sufficiency, contrastiveness, and
completeness. Our algorithms are efficiently computable, taking on average 6s
per image on a ResNet50 model to compute all types of explanations, and are
totally black-box, needing no knowledge of the model, no access to model
internals, no access to gradient, nor requiring any properties, such as
monotonicity, of the model.

</details>


### [385] [DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer](https://arxiv.org/abs/2507.23554)
*Ruoyu Wang,Junda Wu,Yu Xia,Tong Yu,Ryan A. Rossi,Julian McAuley,Lina Yao*

Main category: cs.AI

TL;DR: DICE通过因果分析和逐步选择标准，动态地选择LLM代理任务中最相关的上下文学习演示，提高了代理的性能和鲁棒性，且无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 现有ICL方法对演示选择敏感，通常依赖于启发式或特定任务的设计，缺乏普遍的、理论上依据的标准来选择能够稳定提升代理性能的演示。

Method: DICE（动态上下文示例选择）通过因果视角将演示知识分解为可迁移和不可迁移的组件，并提出了一种逐步选择标准，以选择每个推理步骤中最相关的演示。

Result: DICE在各种领域进行了广泛的实验，证明了其有效性和通用性，强调了原则性、上下文感知的演示选择对于稳健高效的LLM代理的重要性。

Conclusion: DICE是一个理论上合理、与框架无关的ICL框架，用于代理任务，通过因果视角将演示知识分解为可迁移和不可迁移的组件，并提出了一种具有改进代理性能形式化保证的逐步选择标准。

Abstract: Large language model-based agents, empowered by in-context learning (ICL),
have demonstrated strong capabilities in complex reasoning and tool-use tasks.
However, existing works have shown that the effectiveness of ICL is highly
sensitive to the choice of demonstrations, with suboptimal examples often
leading to unstable or degraded performance. While prior work has explored
example selection, including in some agentic or multi-step settings, existing
approaches typically rely on heuristics or task-specific designs and lack a
general, theoretically grounded criterion for what constitutes an effective
demonstration across reasoning steps. Therefore, it is non-trivial to develop a
principled, general-purpose method for selecting demonstrations that
consistently benefit agent performance. In this paper, we address this
challenge with DICE, Dynamic In-Context Example Selection for LLM Agents, a
theoretically grounded ICL framework for agentic tasks that selects the most
relevant demonstrations at each step of reasoning. Our approach decomposes
demonstration knowledge into transferable and non-transferable components
through a causal lens, showing how the latter can introduce spurious
dependencies that impair generalization. We further propose a stepwise
selection criterion with a formal guarantee of improved agent performance.
Importantly, DICE is a general, framework-agnostic solution that can be
integrated as a plug-in module into existing agentic frameworks without any
additional training cost. Extensive experiments across diverse domains
demonstrate our method's effectiveness and generality, highlighting the
importance of principled, context-aware demo selection for robust and efficient
LLM agents.

</details>


### [386] [Semantic Chain-of-Trust: Autonomous Trust Orchestration for Collaborator Selection via Hypergraph-Aided Agentic AI](https://arxiv.org/abs/2507.23565)
*Botao Zhu,Xianbin Wang,Dusit Niyato*

Main category: cs.AI

TL;DR: 提出了一种基于新的语义信任链概念的自主信任编排方法，利用代理AI和超图来评估和管理设备信任，优化资源利用率，并支持大规模多跳协作。


<details>
  <summary>Details</summary>
Motivation: 在协作系统中，任务的有效完成依赖于对分布式协作的潜在设备的特定任务的信任评估。然而，任务的复杂性、分布式设备资源的时空动态性以及不可避免的评估开销，都极大地增加了信任评估过程的复杂性和资源消耗。因此，不合时宜或过于频繁的信任评估会降低受限资源的利用率，对协作任务的执行产生负面影响。

Method: 本技术采用代理AI和超图来建立和维护设备之间的信任关系。通过利用其在自主感知、任务分解和语义推理方面的优势，我们提出代理AI来感知设备状态，并仅在设备空闲期间根据历史性能数据自主执行协作者的信任评估，从而实现分布式资源的高效利用。此外，代理AI通过分析资源能力与任务需求之间的匹配度，对协作者资源进行特定任务的信任评估。此外，通过维护一个嵌入了设备信任语义的信任超图，代理AI能够对协作者进行分层管理，并根据信任语义识别需要信任评估的协作者，从而在开销和信任准确性之间取得平衡。此外，可以链接来自多个设备的本地信任超图以支持多跳协作，从而在大型系统中实现高效协调。

Result: 实验结果表明，所提出的方法实现了资源高效的信任评估。

Conclusion: 实验结果表明，所提出的方法实现了资源高效的信任评估。

Abstract: In collaborative systems, the effective completion of tasks hinges on
task-specific trust evaluations of potential devices for distributed
collaboration. However, the complexity of tasks, the spatiotemporal dynamism of
distributed device resources, and the inevitable assessment overhead
dramatically increase the complexity and resource consumption of the trust
evaluation process. As a result, ill-timed or overly frequent trust evaluations
can reduce utilization rate of constrained resources, negatively affecting
collaborative task execution. To address this challenge, this paper proposes an
autonomous trust orchestration method based on a new concept of semantic
chain-of-trust. Our technique employs agentic AI and hypergraph to establish
and maintain trust relationships among devices. By leveraging its strengths in
autonomous perception, task decomposition, and semantic reasoning, we propose
agentic AI to perceive device states and autonomously perform trust evaluations
of collaborators based on historical performance data only during device idle
periods, thereby enabling efficient utilization of distributed resources. In
addition, agentic AI performs task-specific trust evaluations on collaborator
resources by analyzing the alignment between resource capabilities and task
requirements. Moreover, by maintaining a trust hypergraph embedded with trust
semantics for each device, agentic AI enables hierarchical management of
collaborators and identifies collaborators requiring trust evaluation based on
trust semantics, thereby achieving a balance between overhead and trust
accuracy. Furthermore, local trust hypergraphs from multiple devices can be
chained together to support multi-hop collaboration, enabling efficient
coordination in large-scale systems. Experimental results demonstrate that the
proposed method achieves resource-efficient trust evaluation.

</details>


### [387] [MemoCue: Empowering LLM-Based Agents for Human Memory Recall via Strategy-Guided Querying](https://arxiv.org/abs/2507.23633)
*Qian Zhao,Zhuo Sun,Bin Guo,Zhiwen Yu*

Main category: cs.AI

TL;DR: MemoCue通过策略引导的富含线索的查询，改进了代理辅助记忆回忆。它通过召回路由器框架、5W召回图、分层召回树和蒙特卡洛树搜索来解决策略选择和响应生成问题。MemoCue在实验中表现优于现有方法，并在人类评估中显示出潜力。


<details>
  <summary>Details</summary>
Motivation: 传统的代理辅助记忆回忆方法受限于记忆模块的大小，影响了实践中的记忆回忆性能。记忆理论表明，可以通过有效的线索主动激活个体相关的记忆。受此启发，研究人员提出了一种新的策略引导代理辅助记忆回忆方法。

Method: 提出了一种新颖的策略引导代理辅助记忆回忆方法，该方法通过精心设计的策略将原始查询转换为富含线索的查询。为了解决选择适当的召回策略和利用稀疏注释的策略模式获得高质量响应的挑战，提出了召回路由器框架。具体来说，设计了5W召回图来将记忆查询分类到五个典型场景中，并定义了相应场景下的十五个召回策略模式。然后，提出了一个结合蒙特卡洛树搜索算法的分层召回树来优化策略选择和策略响应生成。构建了一个指令调优数据集，并对多个开源LLM进行了微调，开发了MemoCue。

Result: MemoCue在三个代表性数据集上进行了实验，结果表明MemoCue在回忆启发方面超越了基于LLM的方法17.74%。此外，人类评估也凸显了其在记忆回忆应用中的优势。

Conclusion: MemoCue在回忆启发方面超越了基于LLM的方法17.74%，并且在回忆应用方面具有优势。

Abstract: Agent-assisted memory recall is one critical research problem in the field of
human-computer interaction. In conventional methods, the agent can retrieve
information from its equipped memory module to help the person recall
incomplete or vague memories. The limited size of memory module hinders the
acquisition of complete memories and impacts the memory recall performance in
practice. Memory theories suggest that the person's relevant memory can be
proactively activated through some effective cues. Inspired by this, we propose
a novel strategy-guided agent-assisted memory recall method, allowing the agent
to transform an original query into a cue-rich one via the judiciously designed
strategy to help the person recall memories. To this end, there are two key
challenges. (1) How to choose the appropriate recall strategy for diverse
forgetting scenarios with distinct memory-recall characteristics? (2) How to
obtain the high-quality responses leveraging recall strategies, given only
abstract and sparsely annotated strategy patterns? To address the challenges,
we propose a Recall Router framework. Specifically, we design a 5W Recall Map
to classify memory queries into five typical scenarios and define fifteen
recall strategy patterns across the corresponding scenarios. We then propose a
hierarchical recall tree combined with the Monte Carlo Tree Search algorithm to
optimize the selection of strategy and the generation of strategy responses. We
construct an instruction tuning dataset and fine-tune multiple open-source
large language models (LLMs) to develop MemoCue, an agent that excels in
providing memory-inspired responses. Experiments on three representative
datasets show that MemoCue surpasses LLM-based methods by 17.74% in recall
inspiration. Further human evaluation highlights its advantages in
memory-recall applications.

</details>


### [388] [Personalized Education with Ranking Alignment Recommendation](https://arxiv.org/abs/2507.23664)
*Haipeng Liu,Yuxuan Liu,Ting Long*

Main category: cs.AI

TL;DR: RAR addresses inefficient exploration in personalized question recommendation by incorporating collaborative ideas, improving performance for RL-based recommenders.


<details>
  <summary>Details</summary>
Motivation: Most previous methods model this task as a Markov Decision Process and use reinforcement learning to solve, but they struggle with efficient exploration, failing to identify the best questions for each student during training.

Method: Ranking Alignment Recommendation (RAR), which incorporates collaborative ideas into the exploration mechanism, enabling more efficient exploration within limited training episodes.

Result: Experiments show that RAR effectively improves recommendation performance.

Conclusion: RAR effectively improves recommendation performance and can be applied to any RL-based question recommender.

Abstract: Personalized question recommendation aims to guide individual students
through questions to enhance their mastery of learning targets. Most previous
methods model this task as a Markov Decision Process and use reinforcement
learning to solve, but they struggle with efficient exploration, failing to
identify the best questions for each student during training. To address this,
we propose Ranking Alignment Recommendation (RAR), which incorporates
collaborative ideas into the exploration mechanism, enabling more efficient
exploration within limited training episodes. Experiments show that RAR
effectively improves recommendation performance, and our framework can be
applied to any RL-based question recommender. Our code is available in
https://github.com/wuming29/RAR.git.

</details>


### [389] [TextQuests: How Good are LLMs at Text-Based Video Games?](https://arxiv.org/abs/2507.23701)
*Long Phan,Mantas Mazeika,Andy Zou,Dan Hendrycks*

Main category: cs.AI

TL;DR: TextQuests is a new benchmark using text-based games to test AI agents' long-term reasoning without external tools.


<details>
  <summary>Details</summary>
Motivation: Existing agent benchmarks do not fully capture an agent's ability to operate autonomously in exploratory environments that demand sustained, self-directed reasoning over a long and growing context. There is a need to spur the development of agents capable of more robust intrinsic reasoning over long horizons.

Method: Introduced TextQuests, a benchmark based on the Infocom suite of interactive fiction games, designed to assess LLM agents' self-contained problem-solving and intrinsic long-context reasoning capabilities by precluding external tools.

Result: TextQuests benchmark, based on text-based adventures requiring hundreds of actions and significant time to solve, serves as an effective proxy for evaluating AI agents on focused, stateful tasks within a single interactive session, emphasizing trial-and-error learning.

Conclusion: TextQuests is a new benchmark for evaluating LLM agents on intrinsic long-context reasoning in exploratory environments, using text-based adventure games.

Abstract: Evaluating AI agents within complex, interactive environments that mirror
real-world challenges is critical for understanding their practical
capabilities. While existing agent benchmarks effectively assess skills like
tool use or performance on structured tasks, they often do not fully capture an
agent's ability to operate autonomously in exploratory environments that demand
sustained, self-directed reasoning over a long and growing context. To spur the
development of agents capable of more robust intrinsic reasoning over long
horizons, we introduce TextQuests, a benchmark based on the Infocom suite of
interactive fiction games. These text-based adventures, which can take human
players over 30 hours and require hundreds of precise actions to solve, serve
as an effective proxy for evaluating AI agents on focused, stateful tasks. The
benchmark is specifically designed to assess an LLM agent's capacity for
self-contained problem-solving by precluding the use of external tools, thereby
focusing on intrinsic long-context reasoning capabilities in an exploratory
environment characterized by the need for trial-and-error learning and
sustained problem-solving within a single interactive session. We release
TextQuests at https://textquests.ai.

</details>


### [390] [Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving](https://arxiv.org/abs/2507.23726)
*Luoxin Chen,Jinming Gu,Liankai Huang,Wenhao Huang,Zhicheng Jiang,Allan Jie,Xiaoran Jin,Xing Jin,Chenggang Li,Kaijing Ma,Cheng Ren,Jiawei Shen,Wenlei Shi,Tong Sun,He Sun,Jiahui Wang,Siran Wang,Zhihong Wang,Chenrui Wei,Shufa Wei,Yonghui Wu,Yuchen Wu,Yihang Xia,Huajian Xin,Fan Yang,Huaiyuan Ying,Hongyi Yuan,Zheng Yuan,Tianyang Zhan,Chi Zhang,Yue Zhang,Ge Zhang,Tianyun Zhao,Jianqiu Zhao,Yichi Zhou,Thomas Hanwen Zhu*

Main category: cs.AI

TL;DR: LLM在数学推理方面表现出色，但定理证明仍是挑战。本研究提出Seed-Prover和Seed-Geometry，利用Lean的形式化验证和长链式思考，在IMO、MiniF2F和PutnamBench等基准测试中取得了显著成果，并在IMO 2025竞赛中证明了5道题。


<details>
  <summary>Details</summary>
Motivation: 自然语言监督信号不足以有效训练大型语言模型进行定理证明，而像Lean这样的领域特定语言提供了明确的形式化验证监督信号，从而能够进行有效的强化学习训练。

Method: 提出了一种名为Seed-Prover的引理式全证明推理模型，该模型能够基于Lean的形式化反馈、已证明的引理和自我总结来迭代改进其证明。为了处理几何推理的不足，还引入了Seed-Geometry几何推理引擎。

Result: Seed-Prover成功证明了78.1%的已形式化IMO问题，在MiniF2F上达到饱和，并在PutnamBench上取得了超过50%的准确率，显著优于先前最先进的模型。Seed-Geometry在形式化几何推理方面也表现出色，并且与Seed-Prover一同参与IMO 2025，成功证明了6道题中的5道。

Conclusion: 该研究表明，结合形式化验证和长链式思考的推理模型在自动数学推理领域取得了重大进展，特别是在定理证明方面。

Abstract: LLMs have demonstrated strong mathematical reasoning abilities by leveraging
reinforcement learning with long chain-of-thought, yet they continue to
struggle with theorem proving due to the lack of clear supervision signals when
solely using natural language. Dedicated domain-specific languages like Lean
provide clear supervision via formal verification of proofs, enabling effective
training through reinforcement learning. In this work, we propose
\textbf{Seed-Prover}, a lemma-style whole-proof reasoning model. Seed-Prover
can iteratively refine its proof based on Lean feedback, proved lemmas, and
self-summarization. To solve IMO-level contest problems, we design three
test-time inference strategies that enable both deep and broad reasoning.
Seed-Prover proves $78.1\%$ of formalized past IMO problems, saturates MiniF2F,
and achieves over 50\% on PutnamBench, outperforming the previous
state-of-the-art by a large margin. To address the lack of geometry support in
Lean, we introduce a geometry reasoning engine \textbf{Seed-Geometry}, which
outperforms previous formal geometry engines. We use these two systems to
participate in IMO 2025 and fully prove 5 out of 6 problems. This work
represents a significant advancement in automated mathematical reasoning,
demonstrating the effectiveness of formal verification with long
chain-of-thought reasoning.

</details>


### [391] [CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks](https://arxiv.org/abs/2507.23751)
*Ping Yu,Jack Lanchantin,Tianlu Wang,Weizhe Yuan,Olga Golovneva,Ilia Kulikov,Sainbayar Sukhbaatar,Jason Weston,Jing Xu*

Main category: cs.AI

TL;DR: CoT-Self-Instruct generates high-quality synthetic data for LLMs using Chain-of-Thought reasoning and planning, outperforming existing methods on various benchmarks.


<details>
  <summary>Details</summary>
Motivation: To generate high-quality synthetic data for LLM training that improves performance on both verifiable reasoning and non-verifiable instruction-following tasks.

Method: CoT-Self-Instruct method, which involves instructing LLMs to reason and plan via Chain-of-Thought (CoT) based on seed tasks, generating new synthetic prompts, and filtering for high-quality data with automatic metrics.

Result: Outperforms existing datasets (s1k, OpenMathReasoning) on MATH500, AMC23, AIME24, and GPQA-Diamond for verifiable reasoning. Surpasses human or standard self-instruct prompts on AlpacaEval 2.0 and Arena-Hard for non-verifiable tasks.

Conclusion: CoT-Self-Instruct method significantly outperforms existing training datasets and human/standard self-instruct prompts on both verifiable reasoning and non-verifiable instruction-following tasks.

Abstract: We propose CoT-Self-Instruct, a synthetic data generation method that
instructs LLMs to first reason and plan via Chain-of-Thought (CoT) based on the
given seed tasks, and then to generate a new synthetic prompt of similar
quality and complexity for use in LLM training, followed by filtering for
high-quality data with automatic metrics. In verifiable reasoning, our
synthetic data significantly outperforms existing training datasets, such as
s1k and OpenMathReasoning, across MATH500, AMC23, AIME24 and GPQA-Diamond. For
non-verifiable instruction-following tasks, our method surpasses the
performance of human or standard self-instruct prompts on both AlpacaEval 2.0
and Arena-Hard.

</details>


### [392] [SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model](https://arxiv.org/abs/2507.23773)
*Mingkai Deng,Jinyu Hou,Yilin Shen,Hongxia Jin,Graham Neubig,Zhiting Hu,Eric Xing*

Main category: cs.AI

TL;DR: SimuRA是一种新的AI代理架构，利用LLM世界模型进行规划和模拟，解决了当前AI代理的可扩展性和泛化性问题。它在网页浏览任务中表现出色，显著提高了成功率，证明了其作为通用推理范式的潜力。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理大多采用“一个任务一个代理”的方法，这不仅难以扩展和泛化，而且受到自回归LLM根本性局限性的制约。与此相反，人类作为通用代理，通过心理模拟行为和计划的后果来进行推理。因此，需要一种更通用、更强大的AI代理架构。

Method: SimuRA是一个以目标为导向的通用代理推理架构。它基于最优代理在任何环境中的原则性公式，通过引入一个用于通过模拟进行规划的世界模型来克服自回归推理的局限性。该通用世界模型使用LLM实现，能够利用自然语言的概念丰富潜在空间，在广泛的环境中进行灵活规划。

Result: 在复杂的网页浏览任务实验中，SimuRA将航班搜索的成功率从0%提高到32.2%。基于世界模型的规划相比自回归规划，优势高达124%，证明了世界模型模拟作为一种推理范式的优势。

Conclusion: SimuRA代表了一种新颖的AI代理架构，通过引入基于LLM的世界模型进行规划和模拟，克服了传统单一任务代理和自回归LLM的局限性。在网页浏览等复杂任务上，SimuRA展示了显著的性能提升，尤其是在航班搜索任务中成功率从0%提高到32.2%，证明了基于世界模型的模拟规划作为一种推理范式的优越性。

Abstract: AI agents built on large language models (LLMs) hold enormous promise, but
current practice focuses on a one-task-one-agent approach, which not only falls
short of scalability and generality, but also suffers from the fundamental
limitations of autoregressive LLMs. On the other hand, humans are general
agents who reason by mentally simulating the outcomes of their actions and
plans. Moving towards a more general and powerful AI agent, we introduce
SimuRA, a goal-oriented architecture for generalized agentic reasoning. Based
on a principled formulation of optimal agent in any environment, \modelname
overcomes the limitations of autoregressive reasoning by introducing a world
model for planning via simulation. The generalized world model is implemented
using LLM, which can flexibly plan in a wide range of environments using the
concept-rich latent space of natural language. Experiments on difficult web
browsing tasks show that \modelname improves the success of flight search from
0\% to 32.2\%. World-model-based planning, in particular, shows consistent
advantage of up to 124\% over autoregressive planning, demonstrating the
advantage of world model simulation as a reasoning paradigm. We are excited
about the possibility for training a single, general agent model based on LLMs
that can act superintelligently in all environments. To start, we make SimuRA,
a web-browsing agent built on \modelname with pretrained LLMs, available as a
research demo for public testing.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [393] [LLMs Between the Nodes: Community Discovery Beyond Vectors](https://arxiv.org/abs/2507.22955)
*Ekta Gujral,Apurva Sinha*

Main category: cs.SI

TL;DR: This paper introduces CommLLM, a framework using GPT-4o to detect communities in social graphs by combining LLM insights with graph structure, showing improved accuracy over traditional methods, especially for smaller graphs.


<details>
  <summary>Details</summary>
Motivation: To explore how Large Language Models (LLMs) can be used to integrate semantic and contextual information into community detection in social network graphs, moving beyond traditional reliance on graph structural properties.

Method: A two-step framework called CommLLM is proposed, utilizing the GPT-4o model and prompt-based reasoning to integrate language model outputs with graph structure.

Result: Evaluations on six real-world datasets using metrics like NMI, ARI, and VOI demonstrate that LLM-based approaches, particularly CommLLM with instruction-tuned models and engineered prompts, significantly improve the accuracy and coherence of detected communities in small to medium-sized graphs.

Conclusion: LLMs, especially when combined with graph-aware strategies, show potential for community detection in small to medium-sized social graphs. Tailoring LLM interactions to graph structures is crucial for improving accuracy and coherence.

Abstract: Community detection in social network graphs plays a vital role in uncovering
group dynamics, influence pathways, and the spread of information. Traditional
methods focus primarily on graph structural properties, but recent advancements
in Large Language Models (LLMs) open up new avenues for integrating semantic
and contextual information into this task. In this paper, we present a detailed
investigation into how various LLM-based approaches perform in identifying
communities within social graphs. We introduce a two-step framework called
CommLLM, which leverages the GPT-4o model along with prompt-based reasoning to
fuse language model outputs with graph structure. Evaluations are conducted on
six real-world social network datasets, measuring performance using key metrics
such as Normalized Mutual Information (NMI), Adjusted Rand Index (ARI),
Variation of Information (VOI), and cluster purity. Our findings reveal that
LLMs, particularly when guided by graph-aware strategies, can be successfully
applied to community detection tasks in small to medium-sized graphs. We
observe that the integration of instruction-tuned models and carefully
engineered prompts significantly improves the accuracy and coherence of
detected communities. These insights not only highlight the potential of LLMs
in graph-based research but also underscore the importance of tailoring model
interactions to the specific structure of graph data.

</details>


### [394] [Constructing and Sampling Directed Graphs with Linearly Rescaled Degree Matrices](https://arxiv.org/abs/2507.23025)
*Yunxiang Yan,Meng Jiang*

Main category: cs.SI

TL;DR: 提出了一种新的有向图采样算法，该算法通过重 scaling 联合度矩阵和度相关矩阵来构建采样图，并能有效保留图的度分布和度相关分布。


<details>
  <summary>Details</summary>
Motivation: 大型有向网络的分析通常耗时且成本高昂，因此需要采样算法来加速分析过程，同时保留原始图的属性。

Method: 提出了一种采样框架，通过对联合度矩阵（JDM）和度相关矩阵（DCM）进行线性重 scaling 来构建采样图。

Result: 实验表明，JDM和DCM的非零项数量相对于图的边和节点数量来说很小。

Conclusion: 所提出的算法可以被证明能够保持度分布和度相关分布，并且这些分布的偏差与JDM和DCM的稀疏度负相关。

Abstract: In recent years, many large directed networks such as online social networks
are collected with the help of powerful data engineering and data storage
techniques. Analyses of such networks attract significant attention from both
the academics and industries. However, analyses of large directed networks are
often time-consuming and expensive because the complexities of a lot of graph
algorithms are often polynomial with the size of the graph. Hence, sampling
algorithms that can generate graphs preserving properties of original graph are
of great importance because they can speed up the analysis process. We propose
a promising framework to sample directed graphs: Construct a sample graph with
linearly rescaled Joint Degree Matrix (JDM) and Degree Correlation Matrix
(DCM). Previous work shows that graphs with the same JDM and DCM will have a
range of very similar graph properties. We also conduct experiments on
real-world datasets to show that the numbers of non-zero entries in JDM and DCM
are quite small compared to the number of edges and nodes. Adopting this
framework, we propose a novel graph sampling algorithm that can provably
preserves in-degree and out-degree distributions, which are two most
fundamental properties of a graph. We also prove the upper bound for deviations
in the joint degree distribution and degree correlation distribution, which
correspond to JDM and DCM. Besides, we prove that the deviations in these
distributions are negatively correlated with the sparsity of the JDM and DCM.
Considering that these two matrices are always quite sparse, we believe that
proposed algorithm will have a better-than-theory performance on real-world
large directed networks.

</details>


### [395] [Countering the Forgetting of Novel Health Information with 'Social Boosting'](https://arxiv.org/abs/2507.23148)
*Vaibhav Krishna,Nicholas A. Christakis*

Main category: cs.SI

TL;DR: 社会联系能通过“社会促进”增强健康知识干预的效果，特别是在信息分享和学习的互动中，从而长期巩固健康知识。


<details>
  <summary>Details</summary>
Motivation: 为了缓解低质量或虚假信息的不利影响，研究了干预技术（如揭穿和预警），并发现干预效果会衰减。本研究旨在探讨村民的社会结构在巩固干预知识中的作用。

Method: 通过对洪都拉斯110个村庄的22个月入户干预进行评估，考察了当地村民的社会结构，特别是友谊关系对知识干预效果的影响。

Result: 研究发现，在社会网络中联系紧密的人能有效增强知识干预的效果，这种现象被称为“社会促进”。这些人更可能内化和保留信息，并通过与他人互动来强化这些信息。

Conclusion: 该研究发现，在社会网络中联系紧密的人能有效增强知识干预的效果，这可能是因为他们有更多的机会进行社交互动，从而深化对信息的理解和记忆。

Abstract: To mitigate the adverse effects of low-quality or false information, studies
have shown the effectiveness of various intervention techniques through
debunking or so-called pre-bunking. However, the effectiveness of such
interventions can decay. Here, we investigate the role of the detailed social
structure of the local villages within which the intervened individuals live,
which provides opportunities for the targeted individuals to discuss and
internalize new knowledge. We evaluated this with respect to a critically
important topic, information about maternal and child health care, delivered
via a 22-month in-home intervention. Specifically, we examined the effect of
having friendship ties on the retention of knowledge interventions among
targeted individuals in 110 isolated Honduran villages. We hypothesize that
individuals who receive specific knowledge can internalize and consolidate this
information by engaging in social interactions where, for instance, they have
an opportunity to discuss it with others in the process. The opportunity to
explain information to others (knowledge sharing) promotes deeper cognitive
processing and elaborative encoding, which ultimately enhances memory
retention. We found that well-connected individuals within a social network
experience an enhanced effectiveness of knowledge interventions. These
individuals may be more likely to internalize and retain the information and
reinforce it in others, due to increased opportunities for social interaction
where they teach others or learn from them, a mechanism we refer to as "social
boosting". These findings underscore the role of social interactions in
reinforcing health knowledge interventions over the long term. We believe these
findings would be of interest to the health policy, the global health
workforce, and healthcare professionals focusing on disadvantaged populations
and UN missions on infodemics.

</details>


### [396] [Empirical cross-system meta-analysis of long-term transmission grid evolution](https://arxiv.org/abs/2507.23546)
*Bálint Hartmann,Michelle T. Cirunay*

Main category: cs.SI

TL;DR: Lack of studies on grid evolution hinders use of grid flexibility.


<details>
  <summary>Details</summary>
Motivation: The motivation is that the potential of grid-side flexibility, the latent ability to reconfigure transmission network topology, remains under-used due to the lack of empirical studies on real-world grid evolution.

Method: The paper will conduct empirical studies on how real-world grids evolve.

Result: The expected result is to provide empirical data that can inform strategies for better utilizing grid-side flexibility.

Conclusion: The paper aims to address the under-utilization of grid-side flexibility by providing empirical studies on real-world grid evolution.

Abstract: The potential of grid-side flexibility, the latent ability to reconfigure
transmission network topology remains under-used partly because of the lack of
empirical studies on how real-world grids evolve.

</details>


### [397] [Exploring Left-Wing Extremism on the Decentralized Web: An Analysis of Lemmygrad.ml](https://arxiv.org/abs/2507.23699)
*Utkucan Balci,Michael Sirivianos,Jeremy Blackburn*

Main category: cs.SI

TL;DR: 本研究分析了Lemmygrad.ml上的左翼极端主义，发现用户活动和内容毒性增加，并包含支持威权政权、认可俄罗斯入侵乌克兰及反犹太主义的内容。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在调查去中心化社交媒体平台Lemmy的Lemmygrad.ml实例中是否存在左翼极端主义，并分析其用户活动和内容。

Method: 本研究通过时间分析Lemmygrad.ml的用户活动，衡量内容中的滥用或仇恨程度，并使用基于Transformer的主题建模方法探索帖子内容。

Result: 研究发现，在r/GenZedong和r/GenZhou被禁止后，Lemmygrad.ml的用户活动和内容毒性显著增加，其中包含支持威权政权、认可俄罗斯入侵乌克兰以及反犹太主义的内容。

Conclusion: 该研究揭示了在Lemmygrad.ml上存在左翼极端主义，包括支持威权政权、认可俄罗斯入侵乌克兰以及反犹太主义内容，并强调了分析政治光谱两端极端主义的必要性。

Abstract: This study investigates the presence of left-wing extremism on the
Lemmygrad.ml instance of the decentralized social media platform Lemmy, from
its launch in 2019 up to a month after the bans of the subreddits r/GenZedong
and r/GenZhou. We conduct a temporal analysis on Lemmygrad.ml's user activity,
with also measuring the degree of highly abusive or hateful content.
Furthermore, we explore the content of their posts using a transformer-based
topic modeling approach. Our findings reveal a substantial increase in user
activity and toxicity levels following the migration of these subreddits to
Lemmygrad.ml. We also identify posts that support authoritarian regimes,
endorse the Russian invasion of Ukraine, and feature anti-Zionist and
antisemitic content. Overall, our findings contribute to a more nuanced
understanding of political extremism within decentralized social networks and
emphasize the necessity of analyzing both ends of the political spectrum in
research.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [398] [Quantitative Nonlinear Optical Polarimetry with High Spatial Resolution](https://arxiv.org/abs/2507.23050)
*Albert Suceava,Sankalpa Hazra,Jadupati Nag,John Hayden,Safdar Imam,Zhiwen Liu,Abishek Iyer,Mercouri Kanatzidis,Susan Trolier-McKinstry,Jon-Paul Maria,Venkatraman Gopalan*

Main category: cond-mat.mtrl-sci

TL;DR: 研究提出了一种在高NA聚焦下分析SHG极化测量的方法，能够定量提取材料的对称性和微观结构信息，尤其在二维材料和薄膜研究中具有潜力。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有非线性极化测量方法在处理各向异性晶体和薄膜的定量分析时，主要依赖低数值孔径（NA）聚焦的局限性，并利用高NA聚焦来揭示平面外极化响应。

Method: 提出了一种用于定量分析显微镜几何形状下高数值孔径聚焦获得的SHG极化测量的方法，并通过实验和模拟验证了该方法在单晶和薄膜等多种标准样品上的有效性，包括铁电畴的SHG空间图。

Result: 实验和模拟结果表明，该方法能够准确地分析SHG极化测量，并成功解决了逆问题，确定了二次谐波张量的空间分布，同时能够提取面外非线性极化分量。

Conclusion: 该研究提出了一种用于分析高数值孔径聚焦下二次谐波产生（SHG）极化测量的方法，该方法能够定量提取二次谐波张量的空间分布，特别是对二维材料、薄膜、异质结构和具有强面外响应的单轴晶体具有重要意义。

Abstract: Nonlinear optical microscopy such as in the optical second-harmonic
generation (SHG) modality has become a popular tool today for probing materials
in the physical and biological sciences. While imaging and spectroscopy are
widely used in the microscopy mode, nonlinear polarimetry, which can shed light
on materials' symmetry and microstructure, is relatively underdeveloped. This
is partly because quantitative analytical modeling of the optical SHG response
for anisotropic crystals and films largely assumes low-numerical aperture (NA)
focusing of light, where the plane-wave approximation is sufficient. Tight
focusing provides unique benefits in revealing out-of-plane polarization
responses, which cannot be detected by near-plane-wave illumination at normal
incidence. Here, we outline a method for quantitatively analyzing SHG
polarimetry measurements obtained under high-NA focusing within a microscope
geometry. Experiments and simulations of a variety of standard samples, from
single crystals to thin films, are in good agreement, including measured and
simulated spatial SHG maps of ferroelectric domains. A solution to the inverse
problem is demonstrated, where the spatial distribution of an SHG tensor with
unknown tensor coefficient magnitudes is determined by experimentally measured
polarimetry. The ability to extract the out-of-plane component of the nonlinear
polarization in normal incidence is demonstrated, which can be valuable for
high-resolution polarimetry of 2D materials, thin films, heterostructures, and
uniaxial crystals with a strong out-of-plane response.
  Copyright 2025 Optica Publishing Group. Users may use, reuse, and build upon
the article, or use the article for text or data mining, so long as such uses
are for non-commercial purposes and appropriate attribution is maintained. All
other rights are reserved. https://doi.org/10.1364/OPTICA.559060

</details>


### [399] [Realizing Nonreciprocal Linear Dichroism and Emission from Simple Media](https://arxiv.org/abs/2507.23051)
*Thomas J. Ugras,Daniel J. Gracias,Oriol Arteaga,Richard D. Robinson*

Main category: cond-mat.mtrl-sci

TL;DR: 研究发现，通过利用手性-线性光学干涉，可以在易于加工的材料中实现非互易光学行为，为光子控制开辟了新途径。


<details>
  <summary>Details</summary>
Motivation: 挑战了传统观点，即认为常规系统缺乏产生非互易行为的能力，并通过研究手性和线性各向异性介质的光-物质相互作用，探索了在易于获得的材料中实现光学非互易性的可能性。

Method: 利用斯托克斯-穆勒形式主义推导出预测非互易吸收和发射的简单解析表达式，并通过溶液处理的CdS、CdSe和CdTe魔术尺寸团簇薄膜进行实验验证。

Result: 成功设计并验证了能够表现出非互易吸收和发射的薄膜，为非互易线性二色性和发射在宏观对称材料中的实现提供了依据，并提出了几条设计规则。

Conclusion: 该研究发现，通过利用手性-线性光学干涉，可以在易于加工、宏观对称的材料中实现非互易线性二色性和发射，为可扩展的、基于偏振的光子控制开辟了新的机会，可用于方向依赖的光路由、光逻辑和偏振复用信息编码。

Abstract: Reciprocity, the principle that a system response is identical in the forward
path compared to the backward path, is a fundamental concept across physics,
from electrical circuits and optics to acoustics and heat conduction.
Nonreciprocity arises when this symmetry is broken, enabling
directional-dependent behavior. In photonics, nonreciprocity allows control
over the propagation of electromagnetic waves, essential for isolators and
circulators. But achieving optical nonreciprocity typically requires complex
metamaterials, exotic media, or strong external fields. Because of this,
researchers have historically overlooked the possibility that readily available
materials could support nonreciprocal optical behavior, assuming that
conventional systems lack the ability to produce nonreciprocal behavior. In
this work, we challenge that assumption by revisiting the light-matter
interactions of chiroptic and linearly anisotropic media. Through
Stokes-Mueller formalism we derive a simple analytical expression that predicts
a pathway to nonreciprocal absorption and emission of orthogonal linear
polarizations. We test this idea experimentally using solution-processed films
of CdS, CdSe, and CdTe magic-size clusters that possess commensurate circular
dichroism (CD) and linear dichroism (LD)values and find that they can support
this effect, engineering films that exhibit nonreciprocal absorption and
emission of linearly polarized light. Based on the derived expressions and
experiments, several design rules are presented. Our findings reveal that
nonreciprocal linear dichroism and emission can be achieved in readily
processable, macroscopically symmetric materials by harnessing chiral-linear
optical interference. This work opens new opportunities for scalable,
polarization-based photonic control for direction-dependent optical routing,
optical logic, and polarization-multiplexed information encoding.

</details>


### [400] [Local Inversion Symmetry Breaking and Thermodynamic Evidence for Ferrimagnetism in Fe3GaTe2](https://arxiv.org/abs/2507.23068)
*Sang-Eon Lee,Yue Li,Yeonkyu Lee,W. Kice Brown,PeiYu Cai,Jinyoung Yun,Chanyoung Lee,Alex Moon,Lingrui Mei,Jaeyong Kim,Yan Xin,Julie A. Borchers,Thomas W. Heitmann,Matthias Frontzek,William D. Ratcliff,Gregory T. McCandless,Julia Y. Chan,Elton J. G. Santos,Jeehoon Kim,Charudatta M. Phatak,Vadym Kulichenko,Luis Balicas*

Main category: cond-mat.mtrl-sci

TL;DR: Fe3GaTe2在室温以上表现出拓扑自旋纹理，具有高居里温度和低维性，是自旋电子学的候选材料。本研究利用多种显微镜和衍射技术，证明Fe3GaTe2单晶破坏局部反演对称性，解释了中心对称材料中Néel skyrmions的存在。研究还发现Fe3GaTe2的基态为亚铁磁性，拓扑自旋纹理与其磁相转变密切相关。


<details>
  <summary>Details</summary>
Motivation: 研究Fe3GaTe2的结构和磁性，特别是其局部反演对称性的破坏、Néel skyrmions的存在以及其磁基态，以解释中心对称材料中skyrmions的形成并揭示拓扑自旋纹理与其磁相之间的关系。

Method: 通过透射电子显微镜（TEM）技术，X射线衍射，洛伦兹-TEM，磁化测量，中子衍射研究和磁力显微镜观察来分析Fe3GaTe2的结构和磁性。

Result: Fe3GaTe2单晶破坏局部反演对称性但保持全局反演对称性；观察到Néel skyrmions；Fe3GaTe2的基态是全局亚铁磁性的；揭示了铁磁性到亚铁磁性的转变与Fe1和Fe2磁矩之间的耦合变化有关；发现skyrmion密度和磁滞回线之间存在明确的相关性；磁畴壁处的磁泡表明skyrmions受磁相竞争和不同交换相互作用的稳定。

Conclusion: Fe3GaTe2单晶在保持全局反演对称性的同时破坏局部反演对称性，并且观察到了Néel skyrmions，这为理解中心对称材料中skyrmions的存在提供了令人信服的解释。研究还表明Fe3GaTe2的基态是全局亚铁磁性的，并且其拓扑自旋纹理与亚铁磁性的发展密切相关。

Abstract: The layered compound Fe3GaTe2 is attracting attention due to its high Curie
temperature, low dimensionality, and the presence of topological spin textures
above room temperature, making Fe$_3$GaTe$_2$ a good candidate for applications
in spintronics. Here, we show, through transmission electron microscopy (TEM)
techniques, that Fe$_3$GaTe$_2$ single crystals break local inversion symmetry
while maintaining global inversion symmetry according to X-ray diffraction.
Coupled to the observation of N\'{e}el skyrmions via Lorentz-TEM, our
structural analysis provides a convincing explanation for their presence in
centrosymmetric materials. Magnetization measurements as a function of the
temperature displays a sharp first-order thermodynamic phase-transition leading
to a reduction in the magnetic moment. This implies that the ground state of
Fe$_3$GaTe$_2$ is globally ferrimagnetic and not a glassy magnetic state
composed of ferrimagnetic, and ferromagnetic domains as previously claimed.
Neutron diffraction studies indicate that the ferromagnetic to ferrimagnetic
transition upon reducing the external magnetic field is associated with a
change in the magnetic configuration/coupling between Fe1 and Fe2 moments. We
observe a clear correlation between the hysteresis observed in both the
skyrmion density and the magnetization of Fe$_3$GaTe$_2$. This indicates that
its topological spin textures are affected by the development of ferrimagnetism
upon cooling. Observation, via magnetic force microscopy, of magnetic bubbles
at the magnetic phase boundary suggests skyrmions stabilized by the competition
among magnetic phases and distinct exchange interactions. Our study provides an
explanation for the observation of N\'eel skyrmions in centrosymmetric systems,
while exposing a correlation between the distinct magnetic phases of
Fe$_3$GaTe$_2$ and topological spin textures.

</details>


### [401] [Temperature Dependence of Angular Momentum Transport Across Interfaces](https://arxiv.org/abs/1604.01714)
*Kai Chen,Weiwei Lin,C. L. Chien,Shufeng Zhang*

Main category: cond-mat.mtrl-sci

TL;DR: 提出了一种描述自旋输运的微观理论，该理论能定量解释实验结果。


<details>
  <summary>Details</summary>
Motivation: 磁性多层结构中的角动量输运在自旋电子学物理和器件中起着核心作用。

Method: 基于通用的界面交换相互作用，推导了适用于非磁性金属、铁磁和反铁磁绝缘体之间界面的微观理论，以描述界面自旋电导。

Result: 计算得到了不同自旋源（如自旋泵、温度梯度和自旋霍尔效应）的自旋电导及其温度依赖性，并发现计算结果与现有实验在三层结构（铁磁绝缘体/反铁磁绝缘体/非磁性重金属）的自旋电导温度依赖性方面定量一致。

Conclusion: 本文提出了一种描述不同磁性材料界面之间自旋输运的微观理论，并成功应用于计算三层结构中的自旋电流。

Abstract: Angular momentum transport in magnetic multilayered structures plays a
central role in spintronic physics and devices. The angular momentum currents
or spin currents are carried by either quasi-particles such as electrons and
magnons, or by macroscopic order parameters such as local magnetization of
ferromagnets. Based on the generic interface exchange interaction, we develop a
microscopic theory that describes interfacial spin conductance for various
interfaces among non-magnetic metals, ferromagnetic and antiferromagnetic
insulators. Spin conductance and its temperature dependence are obtained for
different spin batteries including spin pumping, temperature gradient and spin
Hall effect. As an application of our theory, we calculate the spin current in
a trilayer made of a ferromagnetic insulator, an antiferromagnetic insulator
and a non-magnetic heavy metal. The calculated results on the temperature
dependence of spin conductance quantitatively agree with the existing
experiments.

</details>


### [402] [Effect of RKKY and dipolar interaction on the nucleation of skyrmion in Pt/Co multilayer with Ir spacer](https://arxiv.org/abs/2507.23153)
*Shaktiranjan Mohanty,Brindaban Ojha,Bhuvneshwari Sharma,Ashutosh Rath,Chandrasekhar Murapaka,Subhankar Bedanta*

Main category: cond-mat.mtrl-sci

TL;DR: 通过结合偶极相互作用和 RKKY 相互作用，研究人员在 Pt/Co 多层系统中稳定了磁性斯格明子，为自旋电子器件的应用铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 研究磁性斯格明子在用于下一代自旋电子器件的合成反铁磁结构中的稳定性。

Method: 通过磁力显微镜成像和磁输运测量来研究 Pt/Co 多层系统中的斯格明子。

Result: 研究发现，增加 Co 层厚度可降低磁各向异性，从而形成更大、更密集的斯格明子。磁力显微镜证实了孤立斯格明子的成核，而磁输运测量则揭示了有限的拓扑霍尔效应。

Conclusion: 该研究通过结合偶极相互作用和 RKKY 相互作用，为稳定磁性斯格明子提供了可靠的方法，并为在自旋电子器件中可控操控斯格明子开辟了新的途径。

Abstract: Magnetic skyrmions, topologically protected spin textures, have emerged as
promising candidates for next-generation spintronic applications. In this
study, we investigate the stabilization of skyrmionic states in a uniquely
engineered Pt/Co multilayer system with an Ir spacer, where both Ruderman
Kittel Kasuya Yosida (RKKY) and dipolar interactions play a crucial role. The
studied multilayer structure consists of a synthetic antiferromagnetic (SAF)
configuration, where a single Ir layer facilitates strong antiferromagnetic
coupling between two ferromagnetic regions: FM1 (top) and FM2 (bottom), each
formed by repeated Co layers separated by Pt, enabling significant dipolar
interactions. This FM1/Ir/FM2 configuration results in a distinctive skyrmionic
hysteresis loop, driven by the interplay of dipolar and RKKY interactions.
Magnetic force microscopy (MFM) imaging confirms the nucleation of isolated
skyrmions, while magnetotransport measurements reveal a finite topological Hall
effect (THE), indicating the chiral nature of these spin textures. Furthermore,
we demonstrate that increasing the Co layer thickness leads to a reduction in
magnetic anisotropy, which in turn results in the formation of relatively
larger and denser skyrmions. Our findings establish a robust approach for
stabilizing skyrmions through the combined effects of dipolar and RKKY
interactions, offering new pathways for controlled skyrmion manipulation in
spintronic devices.

</details>


### [403] [Extended Factorization Machine Annealing for Rapid Discovery of Transparent Conducting Materials](https://arxiv.org/abs/2507.23160)
*Daisuke Makino,Tatsuya Goto,Yoshinori Suga*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究提出了一种名为FMA的新方法，结合了因子分解机和退火，并通过多种技术优化了透明导电材料（Al$_x$Ga$_y$In$_z$）_2$O$_3$的成分和结构，在速度和准确性上超越了现有方法，并成功实现了多目标材料设计。


<details>
  <summary>Details</summary>
Motivation: 为了提高太阳能电池和显示器等下一代器件的性能并降低成本，需要开发新型透明导电材料（TCMs）。

Method: 本研究提出了一种结合因子分解机（FM）和退火的框架（FMA），并引入了连续变量二值化、Hopfield网络利用、自适应随机翻转激活全局搜索以及位串局部搜索微调等技术，用于优化（Al$_x$Ga$_y$In$_z$）_2$O$_3$体系的成分和晶体结构。

Result: 通过在Kaggle“Nomad2018预测透明导体”竞赛的（Al$_x$Ga$_y$In$_z$）_2$O$_3$数据上进行验证，证明了该方法比贝叶斯优化和遗传算法更快、更准确。此外，该方法在多目标优化中也表现出色，能够同时考虑带隙和形成能来设计材料。

Conclusion: 该研究提出的方法在搜索速度和准确性方面优于贝叶斯优化和遗传算法，并成功应用于多目标优化，可同时考虑带隙和形成能，有望推动材料信息学的发展。

Abstract: The development of novel transparent conducting materials (TCMs) is essential
for enhancing the performance and reducing the cost of next-generation devices
such as solar cells and displays. In this research, we focus on the
(Al$_x$Ga$_y$In$_z$)$_2$O$_3$ system and extend the FMA framework, which
combines a Factorization Machine (FM) and annealing, to search for optimal
compositions and crystal structures with high accuracy and low cost. The
proposed method introduces (i) the binarization of continuous variables, (ii)
the utilization of good solutions using a Hopfield network, (iii) the
activation of global search through adaptive random flips, and (iv) fine-tuning
via a bit-string local search. Validation using the
(Al$_x$Ga$_y$In$_z$)$_2$O$_3$ data from the Kaggle "Nomad2018 Predicting
Transparent Conductors" competition demonstrated that our method achieves
faster and more accurate searches than Bayesian optimization and genetic
algorithms. Furthermore, its application to multi-objective optimization showed
its capability in designing materials by simultaneously considering both the
band gap and formation energy. These results suggest that applying our method
to larger, more complex search problems and diverse material designs that
reflect realistic experimental conditions is expected to contribute to the
further advancement of materials informatics.

</details>


### [404] [Low Temperature Formation of Crystalline VO2 Domains in Porous 1 Nanocolumnar Thin Films for Thermochromic Applications](https://arxiv.org/abs/2507.23393)
*H. Acosta-Rivera,V. Rico,F. J. Ferrer,T. C. Rojas,R. Alvarez,N. Martin,A. R. Gonzalez-Elipe,A. Palmero*

Main category: cond-mat.mtrl-sci

TL;DR: VOx薄膜在280°C氧化后，VO2晶域的形成，提高了薄膜的透明度和热致变色调制能力。


<details>
  <summary>Details</summary>
Motivation: 研究亚化学计量的纳米柱状VOx薄膜在低温氧化过程中VO2晶域的形成机制及其对薄膜光学和电学性质的影响。

Method: 研究了在低于300°C氧化过程中，非晶态亚化学计量的纳米柱状VOx薄膜中VO2晶域的形成。

Result: [O]/[V]值高于1.9导致仅形成V2O5，低于1.9则形成VO2、V3O7和V2O5晶域。氧化过程伴随体积膨胀和孔隙收缩。当[O]/[V]=1.5且氧化温度为280°C时，薄膜表现出最佳性能，近红外光谱调制率近50%，电阻率下降超过两个数量级。

Conclusion: VOx薄膜在低于300°C的氧化过程中，[O]/[V]值高于1.9仅形成V2O5，低于1.9则形成VO2、V3O7和V2O5晶域。氧吸附和掺入会引发体积膨胀，收缩孔隙。在特定条件下，低温氧化能形成VO2并提高薄膜的透明度和热致变色调制能力。当[O]/[V]=1.5且氧化温度为280°C时，薄膜性能最佳，近红外光谱调制率接近50%，电阻率下降两个数量级。提出了一种基于氧化过程中体积变化的模型，用于连接薄膜的结构/化学特性与低温下VO2域的形成。

Abstract: The formation of VO2 crystalline domains in amorphous substoichiometric
nanocolumnar VOx thin films subjected to an oxidation process at temperatures
below 300{\deg}C has been studied. It is obtained that values of [O]/[V] above
1.9 lead to the sole formation of V2O5 after oxidation, while values below 1.9
favor the formation of VO2, V3O7 and V2O5 crystalline domains for temperatures
as low as 260{\deg}C. Moreover, it is found that the adsorption of oxygen and
its incorporation into the film network produce a relevant volume expansion in
a so-called swelling mechanism that makes pores shrink. Under some specific
conditions, the low temperature oxidation does not only trigger the formation
of VO2 domains but also a drastic reduction of oxygen-deficient amorphous VOx
in the films, which clearly improves the overall transparency and thermochromic
modulation capabilities. The changes in the optical and electrical properties
of these films during the metal-insulator transition have been studied, finding
the best performance when the stoichiometry of the film before oxidation is
[O]/[V]=1.5 and the oxidation temperature 280{\deg}C. These conditions yield a
relatively transparent coating that presents an optical modulation in the
near-infrared range of nearly 50% and a drop of electrical resistivity of more
than two orders of magnitude. A tentative model based on the volume increase
experienced by film upon oxidation is proposed to link the structural/chemical
features of the films and the formation of VO2 domains at such relatively low
temperatures.

</details>


### [405] [Giant odd-parity magnetoresistance from proximity-induced topological states](https://arxiv.org/abs/2507.23166)
*Tomoki Hotta,Le Duc Anh,Takahiro Chiba,Yohei Kota,Masaaki Tanaka*

Main category: cond-mat.mtrl-sci

TL;DR: 在 α-Sn/(In,Fe)Sb 异质结中发现了高达 1,150% 的巨大 OMR，这归因于由磁性邻近效应引起的倾斜狄拉克表面态，为开发超灵敏磁传感器提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 填补 OMR 效应的现有研究空白，该效应通常表现出适度的值，并探索在 α-Sn/(In,Fe)Sb 异质结中实现巨大 OMR 的可能性。

Method: 通过 Shubnikov de Haas 振荡结合从头计算，并利用假设存在相反倾斜的魏尔锥的玻尔兹曼输运模型来分析和解释 OMR 行为。

Result: 在 3 nm 厚的 α-Sn 和 (In,Fe)Sb 异质结中观察到高达 1,150% 的巨大 OMR，磁场仅为 1 T。

Conclusion: 本研究在由 3 nm 厚的 α-Sn 和铁磁半导体 (In,Fe)Sb 组成的异质结中发现了高达 1,150% 的巨大奇偶校验磁阻 (OMR)，尽管磁场相对较低（仅 1 T）。通过对 Shubnikov de Haas 振荡的分析和从头计算，我们揭示了由 (In,Fe)Sb 层通过磁性邻近诱导产生的倾斜狄拉克表面态。我们提出的玻尔兹曼输运模型能够很好地解释观察到的 OMR 行为，该模型假设 α-Sn 能带结构中存在相反倾斜的魏尔锥。这些发现不仅为 OMR 的物理学提供了新的见解，还为在超灵敏磁传感器等电子和自旋电子器件中的应用指明了方向。

Abstract: Magnetoresistance typically exhibits even symmetry with respect to the
magnetic field, owing to time reversal symmetry (TRS) as dictated by Onsager
reciprocity relations. However, in certain systems where TRS is broken,
magnetoresistance may acquire an odd component with respect to the magnetic
field, referred to as odd parity magnetoresistance (OMR). To date, reported OMR
values have been modest, usually restricted to a few tens of percent even under
high magnetic fields. Here, we report the discovery of a giant OMR reaching up
to 1,150% under a relatively low field of 1 T in a heterostructure composed of
3 nm thick alpha Sn and a ferromagnetic semiconductor, (In,Fe)Sb. Although
alpha Sn in this thickness range is a trivial narrow gap semiconductor,
analysis of Shubnikov de Haas oscillations combined with ab initio calculations
reveals the emergence of tilted topological surface states, induced via
magnetic proximity from the (In,Fe)Sb layer. The observed OMR behavior is well
explained by a Boltzmann transport model assuming the presence of oppositely
tilted Weyl cones in the alpha Sn band structure. Our findings not only shed
new light on the physics of OMR but also suggest promising avenues for its
application in electronic and spintronic devices, such as ultrasensitive
magnetic sensors.

</details>


### [406] [Tuning the Topological Properties of the Antiferromagnetic V(Bi$_{1-x}$Sb$_{x}$)$_{2}$Te$_{4}$ via Sb concentration](https://arxiv.org/abs/2507.23176)
*D. A-León,D. A. Landínez Téllez,J. Roa-Rojas,Rafael Gonzalez-Hernandez*

Main category: cond-mat.mtrl-sci

TL;DR: 通过 Sb 浓度可调控 V(Bi$_{1-x}$Sb$_{x}$)$_{2}$Te$_{4}$ 的自旋霍尔电导率（SHC）及其拓扑贡献，该材料表现出强拓扑绝缘行为，可用于下一代自旋电子器件和先进的量子应用。


<details>
  <summary>Details</summary>
Motivation: 研究具有对量子技术的重要意义的拓扑材料的创新物态。

Method: 通过将钒碲化物（VTe）层引入层状拓扑绝缘体（Bi$_{1-x}$Sb$_{x}$）$_{2}$Te$_{3}$ 来探索反铁磁拓扑绝缘体家族 V(Bi$_{1-x}$Sb$_{x}$)$_{2}$Te$_{4}$ （x=0, 0.5, 1）。

Result: 研究揭示了通过 Sb 浓度可调控的自旋霍尔电导率（SHC）及其拓扑贡献，该贡献由最近引入的平均自旋陈数（ASCN）量化。该材料的强拓扑绝缘行为是通过自旋-轨道耦合引起的能带反转、非平凡 $\mathbb{Z}_2$ 不变量和拓扑表面态的存在来确立的。

Conclusion: V(Bi$_{1-x}$Sb$_{x}$)$_{2}$Te$_{4}$ ($x$=$0$, $0.5$, $1$) 是一种有前途的材料，可用于下一代自旋电子器件和先进的量子应用。

Abstract: The investigation of topological materials has uncovered groundbreaking
phases of matter with significant implications for quantum technologies. Here,
we explore the antiferromagnetic topological insulator family
V(Bi$_{1-x}$Sb$_{x}$)$_{2}$Te$_{4}$ ($x$=$0$, $0.5$, $1$), formed by
introducing vanadium telluride (VTe) layers into the layered topological
insulator (Bi$_{1-x}$Sb$_{x}$)$_{2}$Te$_{3}$. Our results reveal the tunability
of the spin Hall conductivity (SHC) and its topological contribution,
quantified by the recently introduced average Spin Chern Number (ASCN), via Sb
concentration. The materials' strong topological insulating behavior is
established through spin-orbit coupling-induced band inversions, nontrivial
$\mathbb{Z}_2$ invariants, and the presence of topological surface states.
These findings position V(Bi$_{1-x}$Sb$_{x}$)$_{2}$Te$_{4}$ as promising
candidates for next-generation spintronic devices and advanced quantum
applications.

</details>


### [407] [Altermagnetism in 6H perovskites](https://arxiv.org/abs/2507.23232)
*S. V. Streltsov,S. -W. Cheong*

Main category: cond-mat.mtrl-sci

TL;DR: 新发现的6H钙钛矿交替磁体为研究PT对称性破缺和自旋劈裂提供了新平台。


<details>
  <summary>Details</summary>
Motivation: 研究了具有中心对称晶体结构、局部结构交替和共线反铁磁性材料中的PT对称性破缺问题，以及由此产生的具有非相对论性自旋劈裂能带的交替磁体。

Method: 合成和表征了具有层状结构交替和反铁磁性的6H钙钛矿材料，并通过实验手段（如自旋极化扫描隧道显微镜和自旋极化角分辨光电子能谱）研究其性质。

Result: 发现了几种6H钙钛矿材料是交替磁体，并具有非相对论性自旋劈裂能带。此外，还探讨了这些材料中由于自旋-轨道耦合可能存在的净磁化以及巨大的压磁性。

Conclusion: 6H钙钛矿可作为新型交替磁体材料，用于研究反演对称性破缺和自旋劈裂特性。

Abstract: The combination of a centrosymmetric crystallographic structure with local
structural alternations and collinear antiferromagnetism can lead to broken PT
(Parity $\times$ Time-reversal) symmetry, resulting in altermagnets with
non-relativistic spin-split bands. The 6H perovskites with composition
A$_3$BB'$_2$O$_9$ exhibit unique layered structural alternations and typically
adopt an antiferromagnetic ground state. Here, we report the discovery that
several 6H perovskites are indeed altermagnets exhibiting non-relativistic
spin-split bands. We also explore the possible presence of net magnetization
due to spin-orbit coupling in these materials, as well as the manifestation of
giant piezomagnetism. Since the single crystals of 6H perovskites can be
readily grown and cleavable, our findings provide a new avenue to study the
cleaved atomically-flat surfaces of altermagnets with advanced experimental
techniques such as spin-resolved scanning tunneling microscopy (STM) or
spin-resolved angle-resolved photoemission spectroscopy (ARPES) to explore
their spin splitting nature.

</details>


### [408] [Disorder driven crossover between anomalous Hall regimes in Fe$_3$GaTe$_2$](https://arxiv.org/abs/2507.23243)
*Sang-Eon Lee,Minkyu Park,W. Kice Brown,Vadym Kulichenko,Yan Xin,S. H. Rhim,Chanyong Hwang,Jaeyong Kim,Gregory T. McCandless,Julia Y. Chan,Luis Balicas*

Main category: cond-mat.mtrl-sci

TL;DR: Fe3GaTe2晶体具有不依赖于无序的显著反常霍尔电导率（AHC），并揭示了无序诱导的AHC区域的交叉现象。


<details>
  <summary>Details</summary>
Motivation: 探究Fe3(Ge,Ga)Te2化合物中大的反常霍尔电导率（AHC）的内在机制，并揭示无序对AHC的影响。

Method: 通过实验测量和密度泛函理论（DFT）计算相结合的方式，研究了Fe3GaTe2晶体的反常霍尔电导率（AHC）性质。

Result: 研究发现Fe3GaTe2晶体中存在不依赖于无序的AHC，其显著值约为420 Ω-1cm-1。在低电导率下，AHC与电导率之间存在σxy ∝ σxx^1.6的标度关系，并随着电导率的增加而趋于饱和。DFT计算表明，Berry曲率主要集中在费米能级以下的Γ点附近。

Conclusion: Fe3(Ge,Ga)Te2化合物中存在大反常霍尔电导率（AHC），Fe3GaTe2晶体中存在不依赖于无序的AHC，其显著值为σxyc≈420 Ω-1cm-1。低电导率下，观察到σxy ∝ σxx^1.6的标度关系，并随着σxx的增加趋于σxy ≃ σxyc。研究通过密度泛函理论（DFT）计算揭示了Berry曲率的主要来源位于费米能级以下数百meV的Γ点附近。因此，Fe3GaTe2清晰地揭示了在不同反常霍尔电导率（AHC）区域之间诱导的无序诱导的交叉。

Abstract: The large anomalous Hall conductivity (AHC) of the Fe$_3$(Ge,Ga)Te$_2$
compounds has attracted considerable attention. Here, we expose the intrinsic
nature of AHC in Fe$_3$GaTe$_2$ crystals characterized by high conductivities,
which show disorder-independent AHC with a pronounced value
$\sigma_{xy}^{\text{c}}\approx$ 420 $\Omega^{-1}$cm$^{-1}$. In the low
conductivity regime, we observe the scaling relation
$\sigma_{xy}\propto\sigma_{xx}^{1.6}$, which crosses over to $\sigma_{xy}
\simeq \sigma_{xy}^{\text{c}}$ as $\sigma_{xx}$ increases. Disorder in
low-conductivity crystals is confirmed by the broadening of a first-order
transition between ferromagnetism and the ferrimagnetic ground state. Through
density functional theory (DFT) calculations, we reveal that the dominant
sources of Berry curvature are located a few hundred meV below the Fermi energy
around the $\Gamma$-point. Therefore, Fe$_3$GaTe$_2$ clearly exposes the
disorder-induced crossover among distinct AHC regimes, previously inferred from
measurements on different ferromagnets located in either side of the crossover
region.

</details>


### [409] [Boosting Photodetection via Plasmonic Coupling in Quasi-2D Mixed-n Ruddlesden-Popper Perovskite Nanostripes](https://arxiv.org/abs/2507.23727)
*Brindhu Malani S,Eugen Klein,Ronja Maria Piehler,Rostyslav Lesyuk,Christian Klinke*

Main category: cond-mat.mtrl-sci

TL;DR: 通过在准二维钙钛纳米条带中引入辛硫醇功能化的银纳米结构阵列，显著增强了光电探测器的性能，光电流增强了838%，光响应度、探测率和外部量子效率均有大幅提升，为高性能光电探测器的开发提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 为了克服低维准二维金属卤化物钙钛纳米粒子因量子和介电限制效应导致的难以制备高性能光电探测器的挑战，并利用等离​​​子体纳米结构来提高器件效率。

Method: 利用胶体光刻技术制备了辛硫醇（ODT）功能化的银纳米结构阵列（ANA）。通过反射光谱和有限元方法（FEM）模拟，证明了ANA的局域表面等离激元共振（LSPR）模式与钙钛的光吸收和发射光谱相匹配，实现了激子与等离激元的耦合。

Result: 制备的ODT功能化ANA光电探测器表现出弱到中等的耦合效应，光电流增强了838%，光响应度高达70.41 mA W^-1，探测率达到1.48*10^11 Jones，外部量子效率为21.55%，性能是参考器件的10倍。

Conclusion: 本研究展示了一种通过引入辛硫醇（ODT）功能化的银纳米结构阵列（ANA）来增强准二维钙钛纳米条带光电探测性能的方法，实现了838%的光电流增强，并达到了高达70.41 mA W^-1 的光响应度、1.48*10^11 Jones 的探测率和 21.55 % 的外部量子效率，相较于参考器件提高了约10倍。该方法为开发高性能的等离激元-钙钛混合光电探测器提供了一种优化等离激元-激子耦合和非辐射能量转移的途径。

Abstract: Quasi-2D metal halide perovskites have emerged as a promising material for
photodetection due to excellent optoelectronic properties, simple synthesis,
and robust stability. Albeit, developing high-performance photodetectors based
on low-dimensional quasi-2D metal halide perovskite nanoparticles remains
challenging due to quantum and dielectric confinement effects. Several
approaches have been employed to improve efficiency, with plasmonic
nanostructures being among the most effective ones. The resonant energy
transfer and coupling between plasmons and excitons play a vital role in
enhancing device performance. Here, we demonstrate enhanced photodetection of
quasi-2D perovskite nanostripes resulting from the incorporation of
octadecanethiol (ODT) functionalized Ag nanostructure arrays (ANA). Using
colloidal lithography, ANA were fabricated. Reflectance spectroscopy and finite
element method (FEM) simulations show that ANA supports localised surface
plasmon resonance (LSPR) modes that spectrally coincide with the absorption and
emission band of the perovskite. This spectral overlap enables interesting
coupling interactions between the excitons and plasmons. The ODT-functionalized
ANA photodetectors exhibit weak to intermediate coupling, resulting in a
photocurrent enhancement factor of 838 %. They achieve photoresponsivities of
up to 70.41 mA W^-1, detectivities of 1.48*10^11 Jones and external quantum
efficiencies of 21.55 %, which are approximately 10 times higher than those of
the reference photodetector. We present an approach to optimize the
plasmon-exciton coupling and non-radiative energy transfer for developing
high-performance plasmonic-perovskite hybrid photodetectors.

</details>


### [410] [Inhomogeneity identification by measuring magnetic quantum oscillations](https://arxiv.org/abs/2507.23246)
*Sang-Eon Lee,Myung-Hwa Jung*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究通过分析磁量子振荡，提出了一种识别半金属NbSb2样品不均匀性的新方法，并解释了由非均匀费米能级引起的异常现象。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索通过磁量子振荡分析识别半金属NbSb2中样品不均匀性的方法。

Method: 通过掺杂Bi和Cr获得了均匀的Bi掺杂样品和不均匀的Cr掺杂样品，并通过比较样品研磨前后磁量子振荡的结果来确认其均匀性。

Result: 分析结果表明，均匀的Bi掺杂样品可以用对称和洛伦兹有效费米能级分布来解释，而不均匀的Cr掺杂样品则表现出不对称分布，这说明了Lifshitz-Kosevich公式的非传统违反。

Conclusion: 这项研究提供了一种识别材料不均匀性的新方法，并解释了在拓扑材料研究中通常被视为非平凡贝里相位指标的磁量子振荡异常相。

Abstract: This study explores the identification of sample inhomogeneity via magnetic
quantum oscillations analysis in semimetal NbSb$_2$. By doping Bi and Cr, we
obtained a homogeneous Bi-doped sample and an inhomogeneous Cr-doped sample,
whose homogeneity was confirmed by comparing the magnetic quantum oscillation
before and after grinding the samples. The magnetic quantum oscillations in the
inhomogeneous sample exhibited a distinct phase shift and unusual
field-dependent amplitude, believed to result from a non-uniform Fermi energy.
The analysis of the magnetic quantum oscillations demonstrated that the
homogeneous Bi-doped sample can be interpreted by the symmetric and Lorentzian
effective Fermi energy distribution, while the inhomogeneous Cr-doped sample
exhibited an asymmetric distribution, illustrating an unconventional violation
of the Lifshitz-Kosevich formula. This research provides a novel method for
identifying material inhomogeneity and mitigating potential misinterpretations
of magnetic quantum oscillations' unusual phase, commonly seen as a nontrivial
Berry phase indicator in topological materials studies.

</details>


### [411] [First-principles study of Rh- and Pd-based kagome-layered shandites](https://arxiv.org/abs/2507.23329)
*Luca Buiarelli,Turan Birol,Brian M. Andersen,Morten H. Christensen*

Main category: cond-mat.mtrl-sci

TL;DR: shandite材料的电子结构鞍点可以驱动菱面体堆积的kagome层状材料的结构不稳定性。


<details>
  <summary>Details</summary>
Motivation: 研究的重点是探索电子鞍点在特定动量和结构不稳定性之间的联系。

Method: 结合对称性考虑和从头算方法，研究了这些材料的电子和结构性质，特别关注了电子鞍点与结构不稳定性之间的联系。

Result: 研究发现，虽然所研究的母体化合物在环境条件下均在$Rar{3}m$空间群中具有结构稳定性，但通过静水压或掺杂将鞍点移近费米能级会诱导某些化合物的结构不稳定性。

Conclusion: 研究结果为shandite材料的结构性质提供了广泛的调查，并阐明了电子结构中的鞍点在驱动属于$Rar{3}m$空间群的菱面体堆积的kagome层状材料的结构不稳定性方面所起的作用。

Abstract: The shandite structure hosts transition metals arranged in kagome layers
stacked rhombohedrally, and interspersed with post-transition metal ions and
chalcogens. The electronic states near the Fermi level are dominated by the
transition metal $d$-orbitals and feature saddle points near several of the
high-symmetry positions of the Brillouin zone, most notably the F and L points.
Combining symmetry considerations with ab initio methods, we study the
electronic and structural properties of these materials with an emphasis on the
connection between electronic saddle points at specific momenta and structural
instabilities at these momenta. While the parent compounds studied are all
found to be structurally stable in the $R\bar{3}m$ space group under ambient
conditions we show that, in specific compounds, moving the saddle point closer
to the Fermi level using either hydrostatic pressure or doping, can induce a
structural instability. The importance of the electronic degrees of freedom in
driving this instability is supported by the dependence of the frequency of the
soft phonon mode on the electronic smearing temperature, as is the case in
charge density wave materials. Our first-principles calculations show that as
the smearing temperature is increased, the compound becomes structurally stable
again. Our findings survey the structural properties of a large family of
shandite materials and shed light on the role played by saddle points in the
electronic structure in driving structural instabilities in rhombohedrally
stacked kagome-layered materials belonging to the $R\bar{3}m$ space group.

</details>


### [412] [Combinatorial Development of Amorphous/nanocrystalline Biphase Soft Magnetic Alloys with Silicon-steel like Saturated Magnetic Induction](https://arxiv.org/abs/2507.23333)
*Xuesong Li,Jing Zhou,Xiao Liu,Xibei Hou,Tengyu Guo,Bo Wu,Baoan Sun,Weihua Wang,Haiyang Bai*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究提出了一种新的高通量筛选方法，用于发现具有高饱和磁感应强度（Bs）和高电阻率的新型软磁合金，并发现了一种性能优异的FeCoBSi合金。


<details>
  <summary>Details</summary>
Motivation: 为了提高软磁合金的饱和磁感应强度（Bs），这是高功率密度电磁器件的关键。然而，传统的识别高Bs合金成分的方法依赖于实验密集型熔铸方法，并且高通量磁性能表征仍然具有挑战性。

Method: 采用高通量MOKE筛选方法开发新的组合方法，以快速筛选具有最佳软磁特性的合金。

Result: 研究发现，具有高Bs和低矫顽力（Hc）的合金倾向于具有非晶-纳米晶双相微观结构。一种Fe68.09Co17.02B10.9Si4成分的非晶/纳米晶合金薄膜，其Bs高达2.02 T，超过了迄今为止报道的所有非晶/纳米晶合金，并与硅钢相当，同时具有882μΩ·cm的高电阻率，约为硅钢的17倍。

Conclusion: 该研究开发了一种基于高通量MOKE筛选方法的新组合方法，用于快速筛选具有最佳软磁特性的合金。研究发现，具有高Bs和低Hc特性的合金倾向于具有非晶-纳米晶双相微观结构。研究还确定了一种Fe68.09Co17.02B10.9Si4成分的非晶/纳米晶合金薄膜，其Bs高达2.02 T，超过了迄今为止报道的所有非晶/纳米晶合金，并与硅钢相当，同时具有882μΩ·cm的高电阻率，约为硅钢的17倍。

Abstract: Maximization saturation magnetic induction (Bs) of soft magnetic alloys is
essential for the high power-density electromagnetic devices. However,
identifying the alloy compositions with high Bs often replies on the
lab-intensive melt casting method and a high-throughput characterization on
magnetic properties remains challenging. Here, we develop a new combinatorial
method for fast screening alloys with optimal soft magnetic properties based on
the high-throughput MOKE screening method. Based on the combinatorial method,
we found that the alloys with a combination of high Bs and low coercivity (Hc)
tend to have a feature of amorphous-nanocrystalline biphase microstructure. We
also identified an amorphous/nanocrystalline alloy film with the composition
the Fe68.09Co17.02B10.9Si4, exhibiting an ultra-high Bs up to 2.02 T that
surpasses all amorphous/nanocrystalline alloys reported so far and is
comparable to that of silicon steels, together with a high resistivity of 882
{\mu}{\Omega} {\dot} cm, about 17 times of silicon steels. Our high-throughput
magnetic screening method provides a paradigm for understanding the
relationship between microstructure and magnetic properties and the development
of the next-generation soft magnetic materials.

</details>


### [413] [Terahertz spin-orbit torque as a drive of spin dynamics in insulating antiferromagnet Cr$_{2}$O$_{3}$](https://arxiv.org/abs/2507.23367)
*R. M. Dubrovin,Z. V. Gareeva,A. V. Kimel,A. K. Zvezdin*

Main category: cond-mat.mtrl-sci

TL;DR: 在磁绝缘体 Cr2O3 中，位移电流可以驱动 Nél 自旋-轨道扭矩，实现对反铁磁序的超快控制，为设计新型自旋电子器件提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 挑战了电流引起的自旋动力学仅限于金属磁体的传统观点，探索了在磁绝缘体中实现此类现象的可能性。

Method: 结合对称性分析和拉格朗日方法，引入了由 Cr3+ 位点偶极矩产生的电偶极子序参量，揭示了位移电流与反铁磁自旋的耦合机制。

Result: 理论预测了在磁绝缘体 Cr2O3 中，由 THz 电场引起的位移电流能够产生 Nél 自旋-轨道扭矩，并与线性磁电响应竞争，实现了对反铁磁序的超快控制。

Conclusion: 本研究证明了磁绝缘体 Cr2O3 中的位移电流可以驱动 Nél 自旋-轨道扭矩，从而实现对反铁磁序的超快控制。这为在绝缘体中操纵反铁磁性开辟了新途径，并为非金属自旋-轨道扭矩材料提供了设计原则。

Abstract: Contrary to conventional wisdom that spin dynamics induced by current are
exclusive to metallic magnets, we theoretically predict that such phenomena can
also be realized in magnetic insulators, specifically in the magnetoelectric
antiferromagnet $\mathrm{Cr}_{2}\mathrm{O}_{3}$. We reveal that the
displacement current driven by the THz electric field is able to generate a
N{\'e}el spin-orbit torque in this insulating system. By introducing an
alternative electric dipole order parameter arising from the dipole moment at
$\mathrm{Cr}^{3+}$ sites, we combine symmetry analysis with a Lagrangian
approach and uncover that the displacement current couples to the
antiferromagnetic spins and enables ultrafast control of antiferromagnetic
order. The derived equations of motion show that this effect competes with the
linear magnetoelectric response, offering a novel pathway for manipulating
antiferromagnetic order in insulators. Our findings establish insulator
antiferromagnets as a viable platform for electric field driven
antiferromagnetic spintronics and provide general design principles for
non-metallic spin-orbit torque materials.

</details>


### [414] [Machine learning Landau free energy potentials](https://arxiv.org/abs/2507.23369)
*Mauro Pulzone,Natalya S. Fedorova,Hugo Aramberri,Jorge Íñiguez-González*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We show how to construct Landau-like free energy potentials using a
machine-learning approach. For concreteness, we focus on perovskite oxide
PbTiO$_{3}$. We work with a training set obtained from Monte Carlo simulations
based on an atomistic ''second-principles'' potential for PbTiO$_{3}$. We rely
exclusively on data that would be experimentally accessible -- i.e.,
temperature-dependent polarization and strain, both with and without external
electric fields and stresses applied --, to explore scenarios where the
training set could be obtained from laboratory measurements. We introduce a
scheme that allows us to identify optimal polynomial models of the
temperature-dependent free energy surface, mapped as a function of the
homogeneous electric polarization and homogeneous strain. Our results for
PbTiO$_{3}$ show that a very simple polynomial -- where only two parameters
depend linearly on temperature -- is sufficient to yield a correct description
of the material's behavior. Remarkably, the obtained models also capture the
subtle couplings by which elastic strain controls key features of
ferroelectricity in PbTiO$_{3}$ -- i.e., the symmetry of the polar phase and
the discontinuous character of the transition --, despite the fact that no
effort was made to include such information in the training set. We emphasize
the distinctive aspects of our methodology (which relies on an original form of
validation step) by comparing it with the usual machine-learning approach for
model construction. Our results illustrate how physically motivated models can
have remarkable predictive power, even if they are derived from a limited
amount of data. We argue that such ''third-principles'' models can be the basis
for predictive macroscopic or mesoscopic simulations of ferroelectrics and
other materials undergoing non-reconstructive structural transitions.

</details>


### [415] [Enhanced negative capacitance in La-doped Pb(Zr$_{0.4}$Ti$_{0.6}$)O$_3$ ferroelectric capacitor by tuning bias voltage pulse to induce intrinsic domain switching kinetics](https://arxiv.org/abs/2507.23448)
*Ganga S. Kumar,Sudipta Goswami,Shubhasree Chatterjee,Dilruba Hasina,Miral Verma,Devajyoti Mukherjee,Chandan Kumar Ghosh,Dipten Bhattacharya*

Main category: cond-mat.mtrl-sci

TL;DR: 通过优化偏置电压脉冲，可以增强多畴铁电电容器的负电容效应，这与畴壁密度和迟滞回线形状有关，对器件开发有重要意义。


<details>
  <summary>Details</summary>
Motivation: 为了理解多畴铁电电容器中负电容的物理机制，并探索利用其优势的器件开发。

Method: 利用时间依赖性Ginzburg-Landau方程进行相场模拟，研究了偏置电压脉冲（幅度与时间尺度）对多畴铁电电容器中畴壁密度和负电容的影响。

Result: 研究发现，特定的偏置电压脉冲（幅度与时间尺度）能够诱导铁电畴遵循内在开关动力学，从而在多畴PLZT铁电电容器中产生显著的负电容增强。这种增强与开关过程中的最大畴壁密度以及铁电迟滞回线形状密切相关。

Conclusion: 本研究表明，通过控制偏置电压脉冲（幅度与时间尺度）以驱动铁电畴在最小能量势垒下进行开关，可以在多畴掺镧的锆钛酸铅（PLZT）铁电电容器中观察到显著的负电容增强。这是由于在畴“开关”过程中出现了最大的畴壁密度。当施加更高或更低的偏置电压，或者以更快速或更慢的速率进行开关时，畴结构将偏离这种“最优”状态。基于时间依赖性Ginzburg-Landau方程的相场模拟结果显示，畴壁密度在开关过程中随偏置电压幅度变化，并在特定幅度下达到最大值。此外，铁电迟滞回线在强制电压（VC）下的极化（P）与电压（V）关系曲线的曲率半径，也取决于是否遵循了内在的开关动力学。所有这些结果都揭示了偏置电压脉冲（幅度与时间尺度）、开关过程中的畴壁密度、由此产生的铁电迟滞回线形状以及瞬态负电容之间存在密切关联。这对于理解多畴铁电电容器中负电容的物理机制以及利用其优势的器件开发都具有重要的潜在意义。

Abstract: We report a remarkable enhancement of specific negative capacitance in
multidomain La-doped Pb(Zr$_{0.4}$Ti$_{0.6}$)O$_3$ (PLZT) ferroelectric
capacitors when bias voltage pulse profile (amplitude and timescale) induces
switching of the ferroelectric domains following intrinsic switching kinetics
associated with minimum energy barrier. This is because of emergence of maximum
domain wall density during ``switching" of the domains. Domain configuration
changes from such an ``optimum" state if higher or lower bias voltage is
applied at a much faster or slower rate. Phase-field simulation using
time-dependent Ginzburg-Landau equation shows dependence of the domain wall
density during switching on the bias voltage amplitude and its maximization at
a specific bias voltage amplitude. The radius of curvature of the resulting
polarization ($P$) versus voltage ($V$) hysteresis loop at the coercive voltage
($V_C$) also turns out to be depending on whether or not intrinsic switching
kinetics is followed. All these results indicate a close correlation among the
bias voltage pulse profile (amplitude and time scale), domain wall density
during switching, shape of the resulting ferroelectric hysteresis loop, and the
transient negative capacitance. It may have important ramifications both in the
context of physics behind negative capacitance in a multidomain ferroelectric
capacitor and devices being developed by exploiting its advantages.

</details>


### [416] [Magnetic and magnetocaloric properties of the amorphous Tb$_{31}$Co$_{69}$ and Dy$_{31}$Co$_{69}$ thin films deposited on Si substrates](https://arxiv.org/abs/2507.23555)
*P. Skokowski,M. Matczak,Ł. Frąckowiak,T. Bednarchuk,M. Kowacz,B. Anastaziak,K. Synoradzki*

Main category: cond-mat.mtrl-sci

TL;DR: 研究了Tb$_{31}$Co$_{69}$和Dy$_{31}$Co$_{69}$薄膜的磁性质和磁热效应，发现Dy基薄膜在特定温度下具有更高的磁熵变值。


<details>
  <summary>Details</summary>
Motivation: 为了研究非晶薄膜Tb-Co和Dy-Co的结构、磁性和磁热性质，特别是它们在补偿温度和Laves相居里温度附近的磁熵变行为。

Method: 采用脉冲激光沉积技术制备了Tb$_{31}$Co$_{69}$和Dy$_{31}$Co$_{69}$非晶薄膜，厚度为50 nm，并覆盖有5 nm Au保护层。通过X射线衍射分析确认了材料中存在结晶的Laves相。通过磁化强度随温度的变化测量来研究其磁性质。

Result: X射线衍射分析表明材料中存在结晶的Laves相。磁化强度随温度的变化测量显示两种样品均表现出亚铁磁行为。Tb$_{31}$Co$_{69}$的非晶相补偿温度（$T_{m comp}$）估计为81.5 K，结晶Laves相的居里温度（$T_{m C,m Laves}$）为204.5 K。Dy$_{31}$Co$_{69}$的非晶相补偿温度（$T_{m comp}$）估计为88.5 K，结晶Laves相的居里温度（$T_{m C,m Laves}$）为117 K。在5T磁场变化下，Tb$_{31}$Co$_{69}$在$T_{m comp}$处磁熵变（$-\Delta S_{\rm M}$）为4.9 mJ cm$^{-3}$ K$^{-1}$，在$T_{m C,\rm Laves}$处为6.6 mJ cm$^{-3}$ K$^{-1}$；Dy$_{31}$Co$_{69}$在$T_{m comp}$处磁熵变为35 mJ cm$^{-3}$ K$^{-1}$，在$T_{m C,\rm Laves}$处为28 mJ cm$^{-3}$ K$^{-1}$。

Conclusion: 该研究展示了Tb$_{31}$Co$_{69}$和Dy$_{31}$Co$_{69}$非晶薄膜的结构、磁性和磁热性质。研究结果表明，这些薄膜表现出亚铁磁行为，并具有特定的补偿温度（$T_{m comp}$）和居里温度（$T_{m C,m Laves}$）。在5T磁场变化下，Tb$_{31}$Co$_{69}$在$T_{m comp}$处磁熵变（$-\Delta S_{\rm M}$）为4.9 mJ cm$^{-3}$ K$^{-1}$，在$T_{m C,\rm Laves}$处为6.6 mJ cm$^{-3}$ K$^{-1}$；Dy$_{31}$Co$_{69}$在$T_{m comp}$处磁熵变为35 mJ cm$^{-3}$ K$^{-1}$，在$T_{m C,\rm Laves}$处为28 mJ cm$^{-3}$ K$^{-1}$。

Abstract: We present the structural, magnetic, and magnetocaloric properties of
amorphous thin films Tb-Co and Dy-Co with stoichiometry Tb$_{31}$Co$_{69}$ and
Dy$_{31}$Co$_{69}$, deposited on naturally oxidized silicon Si (100)
substrates. Samples with a thickness $d=50$ nm covered with a protective Au
overlayer with a thickness $d_{\rm Au} =5 $ nm were produced using the pulsed
laser deposition technique. The X-ray diffraction analysis indicated the
presence of a crystallized Laves phase in the prepared materials. Magnetization
measurements as a function of temperature revealed ferrimagnetic behavior in
both samples. We estimated the compensation temperature $T_{\rm comp}$ of the
amorphous phase for Tb$_{31}$Co$_{69}$ at 81.5 K and for Dy$_{31}$Co$_{69}$ at
88.5 K, while we found the Curie temperature $T_{\rm C,\ Laves}$ of the
crystallized Laves phases at 204.5 K and at 117 K, respectively. We
investigated the magnetocaloric effect in a wide temperature range, covering
$T_{\rm comp}$ of amorphous phases and $T_{\rm C,\ Laves}$ of crystallized
Laves phases. The analysis for the magnetic field change of $\Delta \mu_0H=5$ T
showed values of the magnetic entropy change of $-\Delta S_{\rm M}=4.9$ mJ
cm$^{-3}$ K$^{-1}$ at $T_{\rm comp}$ and $-\Delta S_{\rm M}=6.6$ mJ cm$^{-3}$
K$^{-1}$ at $T_{\rm C,\ Laves}$ for Tb$_{31}$Co$_{69}$, while for
Dy$_{31}$Co$_{69}$, we determined the values of $-\Delta S_{\rm M}=35$ mJ
cm$^{-3}$ K$^{-1}$ at $T_{\rm comp}$ and $-\Delta S_{\rm M}=28$ mJ cm$^{-3}$
K$^{-1}$ at $T_{\rm C,\ Laves}$.

</details>


### [417] [Temperature-dependent Photoluminescence and Raman Spectroscopy of Selenium Thin Film Solar Cells](https://arxiv.org/abs/2507.23647)
*Rasmus S. Nielsen,Axel G. Medaille,Arnau Torrens,Oriol Segura-Blanch,Seán R. Kavanagh,David O. Scanlon,Aron Walsh,Edgardo Saucedo,Marcel Placidi,Mirjana Dimitrievska*

Main category: cond-mat.mtrl-sci

TL;DR: 硒薄膜的光电质量受加工精度影响，优化其结晶动力学和减少结构无序是提升其性能的关键。


<details>
  <summary>Details</summary>
Motivation: 硒作为一种具有吸引力的元素半导体，在光电和能源领域具有广泛的应用前景。然而，其高挥发性和低辐射效率给其结构和光电质量的评估带来了挑战，因此需要开发先进的无损表征方法。

Method: 采用气相密封衬管策略，并结合温度依赖性拉曼光谱和光致发光光谱。

Result: 研究发现，短程结构无序并非硒的固有属性，而是对细微加工变化的敏感指标，这些变化会显著影响电子-声子耦合和非辐射复合。结构无序和生长应力会促进扩展缺陷的形成，这些缺陷是非辐射复合的主要中心，限制了载流子寿命和光伏器件的开路电压。

Conclusion: 通过精确控制合成和沉积后处理，可以显著提高硒薄膜的光电质量，为通过靶向控制结晶动力学和微观结构无序来优化硒基薄膜技术提供了明确的途径。

Abstract: Selenium is experiencing renewed interest as a elemental semiconductor for a
range of optoelectronic and energy applications due to its irresistibly simple
composition and favorable wide bandgap. However, its high volatility and low
radiative efficiency make it challenging to assess structural and
optoelectronic quality, calling for advanced, non-destructive characterization
methods. In this work, we employ a closed-space encapsulation strategy to
prevent degradation during measurement and enable sensitive probing of
vibrational and optoelectronic properties. Using temperature-dependent Raman
and photoluminescence spectroscopy, we investigate grown-in stress, vibrational
dynamics, and electron-phonon interactions in selenium thin films synthesized
under nominally identical conditions across different laboratories. Our results
reveal that short-range structural disorder is not intrinsic to the material,
but highly sensitive to subtle processing variations, which strongly influence
electron-phonon coupling and non-radiative recombination. We find that such
structural disorder and grown-in stress likely promote the formation of
extended defects, which act as dominant non-radiative recombination centers
limiting carrier lifetime and open-circuit voltage in photovoltaic devices.
These findings demonstrate that the optoelectronic quality of selenium thin
films can be significantly improved through precise control of synthesis and
post-deposition treatments, outlining a clear pathway toward optimizing
selenium-based thin film technologies through targeted control of
crystallization dynamics and microstructural disorder.

</details>


### [418] [Electron Doping Stabilization of Highly-Polar Supertetragonal BaSnO3](https://arxiv.org/abs/2507.23649)
*Qing Zhang,Karin M. Rabe,Xiaohui Liu*

Main category: cond-mat.mtrl-sci

TL;DR: 电子掺杂可以稳定铁电极化，并有望设计高迁移率铁电导体。


<details>
  <summary>Details</summary>
Motivation: 探索电子掺杂是否能稳定非极化体系中的铁电极化，以及电子掺杂与极化的关系。

Method: 通过施加中等压电应变，研究了电子掺杂对 BaSnO3 铁电极化的影响，并提出了电子掺杂稳定铁电极化的新机制。

Result: 在适度的压电应变下，电子掺杂可以稳定具有巨大极化和高迁移率的超四方 BaSnO3 结构，并将稳定超四方相的关键应变降低。

Conclusion: 电子掺杂可以稳定铁电极化，并实现高迁移率铁电导体。

Abstract: Could electrons stabilize ferroelectric polarization in unpolarized system?
Basically, electron doping was thought to be contrary to polarization due to
the well-known picture that the screening effect on Coulomb interaction
diminishes ferroelectric polarization. However, in this paper, we propose a
novel mechanism of stabilizing highly-polar supertetragonal BaSnO3 by electron
doping. With moderate compressive strain applied, less than -5.5%, BaSnO3
exhibits stable nonpolarized normal tetragonal structure and an unstable
supertetragonal state which is characterized with extremely large c/a ratio and
giant polarization. We found that the band gap of the supertetragonal state is
much smaller than the normal tetragonal state, with a difference around 1.2eV.
Therefore, the energy of the doped electrons selectively favors the smaller gap
supertetragonal state than the larger band gap normal tetragonal state, and the
critical strain to stabilize the supertetragonal phase could be reduced by
electron doping. This mechanism guarantees the controllable supertetragonal
structures by electron doping and ensures the coexistence of giant polarization
and conducting in high-mobility BaSnO3, and is promising to design
high-mobility ferroelectrics conductor.

</details>


### [419] [Structural Distortions Control Scaling of Exciton Binding Energies in Two-Dimensional Ag/Bi Double Perovskites](https://arxiv.org/abs/2507.23710)
*Pierre Lechifflart,Raisa-Ioana Biega,Linn Leppert*

Main category: cond-mat.mtrl-sci

TL;DR: 铅基钙钛矿的二维衍生物通常表现出激子束缚能随层厚减小而增大的趋势，但Ag/Bi基钙钛矿却呈现反常现象。本研究发现，结构畸变（由Ag d轨道键合引起）是导致这种反常趋势的关键因素。层间距和堆叠方式也对激子特性有影响，但其物理机制与铅基钙钛矿相似。研究为调控无铅二维钙钛矿的激子特性提供了设计原则。


<details>
  <summary>Details</summary>
Motivation: 为了解决Ag/Bi基二维钙钛矿中出现的与铅基钙钛矿相反的异常现象，即激子束缚能随层厚减小而增大的趋势被反转。

Method: 利用ab initio多体微扰理论，包括GW和Bethe-Salpeter方程。

Result: 结构畸变是导致反常趋势的主要原因；层间距和堆叠方式的影响与铅基钙钛矿相似；提出了调控激子特性的设计原理。

Conclusion: 该研究通过ab initio多体微扰理论，利用GW和Bethe-Salpeter方程框架，系统地比较了实验结构与理想化模型的区别，揭示了结构畸变（由Ag d轨道键合引起）是导致Ag/Bi基二维钙钛矿中激子束缚能非单调趋势的主要原因。研究还表明，层间距和堆叠方式对带隙和激子束缚能有影响，并且在化学性质不同时，其内在的限制物理机制与铅基二维钙钛矿相似。

Abstract: Three-dimensional metal halide double perovskites such as Cs$_2$AgBiBr$_6$
exhibit pronounced excitonic effects due to their anisotropic electronic
structure and chemical localization effects. Their two-dimensional derivatives,
formed by inserting organic spacer molecules between perovskite layers, were
expected to follow well-established trends seen in Pb-based 2D perovskites,
namely, increasing exciton binding energies with decreasing layer thickness due
to enhanced quantum and dielectric confinement. However, recent experimental
and computational studies have revealed anomalous behavior in Ag/Bi-based 2D
perovskites, where this trend is reversed. Using ab initio many-body
perturbation theory within the $GW$ and Bethe-Salpeter Equation frameworks, we
resolve this puzzle by systematically comparing experimental structures with
idealized models designed to isolate the effects of octahedral distortions,
interlayer separation, and stacking. We find that structural distortions,
driven by directional Ag d orbital bonding, govern the momentum-space origin
and character of the exciton, and are the primary cause of the observed
non-monotonic trends. Furthermore, we explore how interlayer distance and
stacking influence band gaps and exciton binding energies, showing that,
despite different chemistry, the underlying confinement physics mirrors that of
Pb-based 2D perovskites. Our results establish design principles for tuning
excitonic properties in this broader class of layered, lead-free materials.

</details>


### [420] [Structural and thermodynamic stability of hexagonal-diamond $\text{Si}_{1 - x - y}\,\text{Ge}_{x}\,\text{B}_{y}$ alloys](https://arxiv.org/abs/2507.23741)
*Marc Túnica,Francesca Chiodi,Michele Amato*

Main category: cond-mat.mtrl-sci

TL;DR: 研究表明，在六方晶系 SiGe 合金中进行超掺杂是可行的，并且比在立方晶系中更有利，这使得它们成为探索 IV 族半导体超导性的有希望的材料。


<details>
  <summary>Details</summary>
Motivation: 研究了超掺杂在诱导立方晶系 Si 和 SiGe 材料超导性方面的有效性，以及在压力下几种 Si 多型体可能出现的 I 型超导态。

Method: 利用基态密度泛函理论模拟研究了低浓度和高浓度 B 掺杂对六方晶系 SiGe 合金结构和热力学性质的影响，并与立方晶系进行了系统比较。

Result: 1. 结构分析证实 SiGeB 合金的晶格参数符合三元 Vegard 定律，与立方晶系 SiGe 合金的观测一致，但在高掺杂浓度下，B 的掺入会破坏六方对称性。
2. 掺杂剂形成能计算表明，在所有 Ge 浓度下，B 在六方晶系中的热力学稳定性优于立方晶系。
3. 混合焓计算表明，超掺杂六方晶系 SiGe 合金在整个 Ge 组成范围内是热力学稳定的，并且其超掺杂倾向比立方晶系 SiGe 合金更有利。

Conclusion: 研究结果表明，超掺杂在六方晶系 SiGe 合金中是可行的，并为在 IV 族半导体中探索超导性提供了一个有前景的平台。

Abstract: Pushing dopant concentrations beyond the solubility limit in semiconductors
-- a process known as hyperdoping -- has been demonstrated as an effective
strategy for inducing superconductivity in cubic-diamond Si and SiGe materials.
Additionally, previous studies have reported that several polytypes of Si may
exhibit a type-I superconducting state under high pressure. In this work, we
employ ground-state Density Functional Theory simulations to investigate the
effects of both low and high B doping concentrations on the structural and
thermodynamic properties of hexagonal-diamond SiGe alloys, with a systematic
comparison to their cubic-diamond counterparts. Our results highlight three key
findings: (i) structural analysis confirms that the lattice parameters of SiGeB
alloys adhere to a ternary Vegard's law, consistent with observations in
cubic-diamond SiGe alloys. However, at high doping concentrations, B
incorporation can locally disrupt the hexagonal symmetry, particularly in the
presence of B clustering; (ii) dopant formation energy calculations reveal that
B is thermodynamically more stable in the hexagonal phase than in the cubic
phase across all Ge concentrations, regardless of the doping level; (iii)
mixing enthalpy calculations demonstrate that hyperdoped hexagonal-diamond SiGe
alloys are thermodynamically stable across the full range of Ge compositions
and that their tendency for hyperdoping is more favorable than that of
cubic-diamond SiGe alloys. Taken together, these findings indicate that
hyperdoping is experimentally viable in hexagonal-diamond SiGe alloys and, in
light of previous evidence, position these materials as a promising platform
for the exploration of superconductivity in group IV semiconductors.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [421] [Causal-Inspired Multi-Agent Decision-Making via Graph Reinforcement Learning](https://arxiv.org/abs/2507.23080)
*Jing Wang,Yan Jin,Fei Ding,Chongfeng Wei*

Main category: cs.MA

TL;DR: 本研究提出了一种结合因果学习和强化学习（利用CDRL和GNN）的方法，通过提取因果特征来优化自动驾驶汽车在交叉路口的决策，实验结果表明该方法能有效提升决策的安全性与效率。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶研究在处理多车辆交互等复杂环境方面仍面临挑战，本研究旨在通过整合因果学习与强化学习来解决这一问题。

Method: 本研究将因果学习与强化学习相结合，利用因果解纠缠表示学习（CDRL）来识别和提取影响自动驾驶汽车最优决策的因果特征，并将其整合到基于图神经网络的强化学习算法中，以增强在复杂交通场景下的决策能力。

Result: 实验结果表明，本研究提出的方法在训练过程中达到了最高的平均奖励，并在测试中的碰撞率和平均累积奖励等关键指标上显著优于其他基于学习的方法。

Conclusion: 本研究为多智能体自动驾驶系统提供了有前景的研究方向，能够提高自动驾驶汽车在复杂交通环境中的导航安全性与效率。

Abstract: Since the advent of autonomous driving technology, it has experienced
remarkable progress over the last decade. However, most existing research still
struggles to address the challenges posed by environments where multiple
vehicles have to interact seamlessly. This study aims to integrate causal
learning with reinforcement learning-based methods by leveraging causal
disentanglement representation learning (CDRL) to identify and extract causal
features that influence optimal decision-making in autonomous vehicles. These
features are then incorporated into graph neural network-based reinforcement
learning algorithms to enhance decision-making in complex traffic scenarios. By
using causal features as inputs, the proposed approach enables the optimization
of vehicle behavior at an unsignalized intersection. Experimental results
demonstrate that our proposed method achieves the highest average reward during
training and our approach significantly outperforms other learning-based
methods in several key metrics such as collision rate and average cumulative
reward during testing. This study provides a promising direction for advancing
multi-agent autonomous driving systems and make autonomous vehicles' navigation
safer and more efficient in complex traffic environments.

</details>


### [422] [Barriers to Healthcare: Agent-Based Modeling to Mitigate Inequity](https://arxiv.org/abs/2507.23644)
*Alba Aguilera,Georgina Curto,Nardine Osman*

Main category: cs.MA

TL;DR: 该研究整合了能力方法（CA）的理论框架，并通过强化学习环境模拟了评估社会政策（如减少无家可归者的健康不平等）的有效性，为人类发展政策的评估提供了新的途径。


<details>
  <summary>Details</summary>
Motivation: 为了在社会政策在现实人口中实施之前，以非侵入性的方式评估这些政策的社会效益，并解决紧迫的人类发展挑战。

Method: 通过整合能力方法（CA）的理论框架，定义了一个强化学习环境，代理人（人）在其中为恢复其能力而行动，并根据特定政策的限制进行评估。

Result: 该模型在巴塞罗那的一个案例研究中得到应用，以减轻无家可归者的健康不平等现象，证明了其在评估政策方面的有效性。

Conclusion: 该模型是第一个与能力方法（CA）保持一致的、用于评估人类发展影响的模拟概念证明，可用于评估正在讨论的政策。

Abstract: Agent-based simulations have an enormous potential as tools to evaluate
social policies in a non-invasive way, before these are implemented to
real-world populations. However, the recommendations that these computational
approaches may offer to tackle urgent human development challenges can vary
substantially depending on how we model agents' (people) behaviour and the
criteria that we use to measure inequity. In this paper, we integrate the
conceptual framework of the capability approach (CA), which is explicitly
designed to promote and assess human well-being, to guide the simulation and
evaluate the effectiveness of policies. We define a reinforcement learning
environment where agents behave to restore their capabilities under the
constraints of a specific policy. Working in collaboration with local
stakeholders, non-profits and domain experts, we apply our model in a case
study to mitigate health inequity among the population experiencing
homelessness (PEH) in Barcelona. By doing so, we present the first proof of
concept simulation, aligned with the CA for human development, to assess the
impact of policies under parliamentary discussion.

</details>


### [423] [A survey of multi-agent geosimulation methodologies: from ABM to LLM](https://arxiv.org/abs/2507.23694)
*Virginia Padilla,Jacinto Dávila*

Main category: cs.MA

TL;DR: This paper validates a framework for geosimulation platforms, showing that LLMs can be used as agent components if designed with a structured architecture for perception, memory, planning, and action, paving the way for advanced geosimulation systems.


<details>
  <summary>Details</summary>
Motivation: The motivation is to examine agent-based approaches in multi-agent systems, simulations, and information systems, and to formalize a specification for geosimulation platforms, exploring the potential of integrating LLMs into these systems.

Method: The paper provides a comprehensive examination of agent-based approaches in multi-agent systems, simulations, and information systems, building upon two decades of research. It confirms a framework for formal specification of geosimulation platforms and demonstrates the integration of LLMs within this framework.

Result: LLMs can be effectively incorporated as agent components in geosimulation platforms if they follow a structured architecture specific to fundamental agent activities such as perception, memory, planning, and action. This integration is consistent with the formalized architecture.

Conclusion: The study confirms that LLMs can be effectively incorporated as agent components in geosimulation platforms if they adhere to a structured architecture for fundamental agent activities like perception, memory, planning, and action. This integration aligns with the formalized architecture, offering a robust foundation for future geosimulation systems.

Abstract: We provide a comprehensive examination of agent-based approaches that codify
the principles and linkages underlying multi-agent systems, simulations, and
information systems. Based on two decades of study, this paper confirms a
framework intended as a formal specification for geosimulation platforms. Our
findings show that large language models (LLMs) can be effectively incorporated
as agent components if they follow a structured architecture specific to
fundamental agent activities such as perception, memory, planning, and action.
This integration is precisely consistent with the architecture that we
formalize, providing a solid platform for next-generation geosimulation
systems.

</details>
