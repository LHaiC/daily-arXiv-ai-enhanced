<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 220]
- [cs.CL](#cs.CL) [Total: 96]
- [cs.LG](#cs.LG) [Total: 144]
- [cs.GT](#cs.GT) [Total: 10]
- [cs.AR](#cs.AR) [Total: 8]
- [cs.LO](#cs.LO) [Total: 5]
- [cs.DC](#cs.DC) [Total: 16]
- [eess.SP](#eess.SP) [Total: 26]
- [physics.app-ph](#physics.app-ph) [Total: 4]
- [cs.MA](#cs.MA) [Total: 5]
- [q-bio.OT](#q-bio.OT) [Total: 1]
- [cs.ET](#cs.ET) [Total: 2]
- [eess.IV](#eess.IV) [Total: 15]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [cs.RO](#cs.RO) [Total: 61]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 26]
- [cs.SI](#cs.SI) [Total: 8]
- [cs.DS](#cs.DS) [Total: 10]
- [cs.AI](#cs.AI) [Total: 65]
- [cs.NE](#cs.NE) [Total: 7]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 40]
- [eess.SY](#eess.SY) [Total: 24]
- [quant-ph](#quant-ph) [Total: 61]
- [cs.GR](#cs.GR) [Total: 5]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Med-GRIM: Enhanced Zero-Shot Medical VQA using prompt-embedded Multimodal Graph RAG](https://arxiv.org/abs/2508.06496)
*Rakesh Raj Madavan,Akshat Kaimal,Hashim Faisal,Chandrakala S*

Main category: cs.CV

TL;DR: BIND模型和Med-GRIM系统在医学VQA任务中通过密集编码、图检索和提示工程，以较低的计算成本实现了高性能，并推出了DermaGraph数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态编码器和视觉-语言模型（VLMs）在处理医学VQA等需要高精度和领域特定知识的任务时存在不足，现有方法通常需要大量的计算资源进行微调。

Method: 提出了一种名为BIND（BLIVA Integrated with Dense Encoding）的表示模型，通过基于查询-词元（query-token）的密集编码来优化联合嵌入空间，并利用图检索和提示工程的Med-GRIM模型来整合领域知识，实现了高效的医学VQA。

Result: Med-GRIM在医学VQA任务中达到了与大型语言模型相当的性能，但计算成本却大大降低。引入的DermaGraph数据集支持多模态和单模态查询，促进了零样本多模态医学应用的研究。

Conclusion: Med-GRIM通过结合图检索和提示工程，并采用模块化的工作流程和小型语言模型，在医学VQA任务中实现了大型语言模型的性能，同时显著降低了计算成本。此外，DermaGraph数据集的引入为零样本多模态医学应用的研究提供了支持。

Abstract: An ensemble of trained multimodal encoders and vision-language models (VLMs)
has become a standard approach for visual question answering (VQA) tasks.
However, such models often fail to produce responses with the detailed
precision necessary for complex, domain-specific applications such as medical
VQA. Our representation model, BIND: BLIVA Integrated with Dense Encoding,
extends prior multimodal work by refining the joint embedding space through
dense, query-token-based encodings inspired by contrastive pretraining
techniques. This refined encoder powers Med-GRIM, a model designed for medical
VQA tasks that leverages graph-based retrieval and prompt engineering to
integrate domain-specific knowledge. Rather than relying on compute-heavy
fine-tuning of vision and language models on specific datasets, Med-GRIM
applies a low-compute, modular workflow with small language models (SLMs) for
efficiency. Med-GRIM employs prompt-based retrieval to dynamically inject
relevant knowledge, ensuring both accuracy and robustness in its responses. By
assigning distinct roles to each agent within the VQA system, Med-GRIM achieves
large language model performance at a fraction of the computational cost.
Additionally, to support scalable research in zero-shot multimodal medical
applications, we introduce DermaGraph, a novel Graph-RAG dataset comprising
diverse dermatological conditions. This dataset facilitates both multimodal and
unimodal querying. The code and dataset are available at:
https://github.com/Rakesh-123-cryp/Med-GRIM.git

</details>


### [2] [A Registration-Based Star-Shape Segmentation Model and Fast Algorithms](https://arxiv.org/abs/2508.07721)
*Daoping Zhang,Xue-Cheng Tai,Lok Ming Lui*

Main category: cs.CV

TL;DR: 一种新的基于注册框架的星形分割模型，可以处理遮挡、模糊和噪声，并能处理单中心或多中心以及指定标志位置。


<details>
  <summary>Details</summary>
Motivation: 图像分割在提取感兴趣对象和识别图像边界方面发挥着至关重要的作用，但当处理损坏图像中的遮挡、模糊或噪声时，准确分割会变得困难。因此，利用先验信息，特别是星形先验，来解决这一挑战。

Method: 提出了一种基于配准框架的星形分割模型，结合了水平集表示和配准框架，并通过对形变水平集函数施加约束来实现。

Result: 通过在合成和真实图像上进行数值实验，证明了该方法在实现精确星形分割方面的有效性。

Conclusion: 该模型能够实现完整和部分星形分割，适应单中心或多中心，并允许强制已识别的边界通过指定的标志位置。

Abstract: Image segmentation plays a crucial role in extracting objects of interest and
identifying their boundaries within an image. However, accurate segmentation
becomes challenging when dealing with occlusions, obscurities, or noise in
corrupted images. To tackle this challenge, prior information is often
utilized, with recent attention on star-shape priors. In this paper, we propose
a star-shape segmentation model based on the registration framework. By
combining the level set representation with the registration framework and
imposing constraints on the deformed level set function, our model enables both
full and partial star-shape segmentation, accommodating single or multiple
centers. Additionally, our approach allows for the enforcement of identified
boundaries to pass through specified landmark locations. We tackle the proposed
models using the alternating direction method of multipliers. Through numerical
experiments conducted on synthetic and real images, we demonstrate the efficacy
of our approach in achieving accurate star-shape segmentation.

</details>


### [3] [DiTalker: A Unified DiT-based Framework for High-Quality and Speaking Styles Controllable Portrait Animation](https://arxiv.org/abs/2508.06511)
*He Feng,Yongjia Ma,Donglin Di,Lei Fan,Tonghua Su,Xiangqian Wu*

Main category: cs.CV

TL;DR: DiTalker 是一个基于 DiT 的新框架，用于人像动画，通过其风格-情感编码模块和音频-风格融合模块，可以实现动态的说话风格（如头部运动）和情感控制，同时保持身份一致性并提高唇形同步精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的人像动画方法主要关注唇形同步或静态情感转换，忽视了诸如头部运动等动态风格。此外，大多数方法依赖于双 U-Net 架构，虽然可以保持身份一致性，但会增加计算开销。

Method: 提出了一种名为 DiTalker 的统一的、基于 DiT 的框架，用于说话风格可控的人像动画。该框架包含一个风格-情感编码模块，其中包含一个提取身份特定风格信息（例如头部姿势和运动）的风格分支和一个提取身份无关情感特征的情感分支。此外，还引入了一个音频-风格融合模块，通过两个并行的交叉注意力层来解耦音频和说话风格，并利用这些特征来指导动画过程。为了提高结果质量，采用了两个优化约束：一个用于改进唇形同步，另一个用于保留细粒度的身份和背景细节。

Result: DiTalker 在唇形同步和说话风格可控性方面优于现有方法。

Conclusion: DiTalker 在唇形同步和说话风格可控性方面表现出色。

Abstract: Portrait animation aims to synthesize talking videos from a static reference
face, conditioned on audio and style frame cues (e.g., emotion and head poses),
while ensuring precise lip synchronization and faithful reproduction of
speaking styles. Existing diffusion-based portrait animation methods primarily
focus on lip synchronization or static emotion transformation, often
overlooking dynamic styles such as head movements. Moreover, most of these
methods rely on a dual U-Net architecture, which preserves identity consistency
but incurs additional computational overhead. To this end, we propose DiTalker,
a unified DiT-based framework for speaking style-controllable portrait
animation. We design a Style-Emotion Encoding Module that employs two separate
branches: a style branch extracting identity-specific style information (e.g.,
head poses and movements), and an emotion branch extracting identity-agnostic
emotion features. We further introduce an Audio-Style Fusion Module that
decouples audio and speaking styles via two parallel cross-attention layers,
using these features to guide the animation process. To enhance the quality of
results, we adopt and modify two optimization constraints: one to improve lip
synchronization and the other to preserve fine-grained identity and background
details. Extensive experiments demonstrate the superiority of DiTalker in terms
of lip synchronization and speaking style controllability. Project Page:
https://thenameishope.github.io/DiTalker/

</details>


### [4] [BigTokDetect: A Clinically-Informed Vision-Language Model Framework for Detecting Pro-Bigorexia Videos on TikTok](https://arxiv.org/abs/2508.06515)
*Minh Duc Chu,Kshitij Pawar,Zihao He,Roxanna Sharifi,Ross Sonnenblick,Magdalayna Curry,Laura D'Adamo,Lindsay Young,Stuart B Murray,Kristina Lerman*

Main category: cs.CV

TL;DR: 该研究提出了BigTokDetect框架，以解决TikTok上识别“大块头癌”内容的问题。该框架使用了一个包含2200多个TikTok视频的大型多模态数据集（BigTok），并通过微调视觉语言模型实现了高准确率。研究表明，多模态信息（尤其是视频内容）对于有效检测此类有害内容至关重要，并为未来的内容审核提供了新的方法和工具。


<details>
  <summary>Details</summary>
Motivation: 社交媒体平台在检测有害内容（尤其是促进肌肉畸形行为和“大块头癌”的内容）方面面临挑战，因为这些内容常常伪装成合法的健身内容，并利用复杂的视觉、编码语言和励志信息组合来规避基于文本的检测系统。特别是，这些内容对男性青少年群体的影响尤为严重。

Method: 开发了一个名为BigTokDetect的临床信息检测框架，该框架利用了第一个专家注释的多模态数据集（BigTok），其中包含超过2200个TikTok视频，并对它们在身体意象、营养、锻炼、补充剂和男子气概等类别上进行了标注。通过对最先进的视觉语言模型进行评估，并在特定领域进行微调，实现了0.829%的主要类别分类准确率和0.690%的子类别检测准确率。消融研究表明，多模态融合比仅文本的方法提高了5-10%的性能，其中视频特征提供了最显著的区分信号。

Result: BigTokDetect框架在主要类别分类上达到了0.829%的准确率，在子类别检测上达到了0.690%的准确率。多模态融合相比仅文本的方法性能提高了5-10%，其中视频特征最为关键。

Conclusion: 该研究提出了BigTokDetect框架，为识别TikTok上的大块头癌内容设定了新的基准，并提供了可扩展的内容审核工具和方法论框架，特别是在专门的心理健康领域。

Abstract: Social media platforms increasingly struggle to detect harmful content that
promotes muscle dysmorphic behaviors, particularly pro-bigorexia content that
disproportionately affects adolescent males. Unlike traditional eating disorder
detection focused on the "thin ideal," pro-bigorexia material masquerades as
legitimate fitness content through complex multimodal combinations of visual
displays, coded language, and motivational messaging that evade text-based
detection systems. We address this challenge by developing BigTokDetect, a
clinically-informed detection framework for identifying pro-bigorexia content
on TikTok. We introduce BigTok, the first expert-annotated multimodal dataset
of over 2,200 TikTok videos labeled by clinical psychologists and psychiatrists
across five primary categories spanning body image, nutrition, exercise,
supplements, and masculinity. Through a comprehensive evaluation of
state-of-the-art vision language models, we achieve 0.829% accuracy on primary
category classification and 0.690% on subcategory detection via domain-specific
finetuning. Our ablation studies demonstrate that multimodal fusion improves
performance by 5-10% over text-only approaches, with video features providing
the most discriminative signals. These findings establish new benchmarks for
multimodal harmful content detection and provide both the computational tools
and methodological framework needed for scalable content moderation in
specialized mental health domains.

</details>


### [5] [Frequency Prior Guided Matching: A Data Augmentation Approach for Generalizable Semi-Supervised Polyp Segmentation](https://arxiv.org/abs/2508.06517)
*Haoran Xi,Chen Liu,Xiaolin Li*

Main category: cs.CV

TL;DR: FPGM是一种新的半监督学习框架，通过利用息肉边缘的频率特征来提高模型在不同成像设备和数据源下的分割性能，特别是在数据稀疏的情况下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的半监督学习方法依赖于通用的数据增强技术，忽略了息肉特有的结构属性，导致在新的成像中心和设备上泛化能力较差。而FPGM旨在解决这个问题，通过利用息肉边缘的频率特征来提高模型的泛化能力。

Method: 提出了一种名为FPGM（Frequency Prior Guided Matching）的新颖的增强框架。该框架利用息肉边缘在不同数据集中具有一致的频率特征这一关键发现。FPGM通过两个阶段进行：首先，从标记息肉的边缘区域学习领域不变的频率先验；然后，对未标记图像进行原则性的频谱扰动，使其幅度频谱与学习到的先验对齐，同时保留相位信息以维持结构完整性。

Result: FPGM在六个公共数据集上进行了验证，在与十种现有方法进行比较时，取得了新的最先进成果。在数据稀疏的情况下，其Dice分数提高了10%以上，展现了卓越的零样本泛化能力。

Conclusion: FPGM通过增强跨域鲁棒性，为有限监督下的临床结肠息肉分割提供了有效的解决方案。

Abstract: Automated polyp segmentation is essential for early diagnosis of colorectal
cancer, yet developing robust models remains challenging due to limited
annotated data and significant performance degradation under domain shift.
Although semi-supervised learning (SSL) reduces annotation requirements,
existing methods rely on generic augmentations that ignore polyp-specific
structural properties, resulting in poor generalization to new imaging centers
and devices. To address this, we introduce Frequency Prior Guided Matching
(FPGM), a novel augmentation framework built on a key discovery: polyp edges
exhibit a remarkably consistent frequency signature across diverse datasets.
FPGM leverages this intrinsic regularity in a two-stage process. It first
learns a domain-invariant frequency prior from the edge regions of labeled
polyps. Then, it performs principled spectral perturbations on unlabeled
images, aligning their amplitude spectra with this learned prior while
preserving phase information to maintain structural integrity. This targeted
alignment normalizes domain-specific textural variations, thereby compelling
the model to learn the underlying, generalizable anatomical structure.
Validated on six public datasets, FPGM establishes a new state-of-the-art
against ten competing methods. It demonstrates exceptional zero-shot
generalization capabilities, achieving over 10% absolute gain in Dice score in
data-scarce scenarios. By significantly enhancing cross-domain robustness, FPGM
presents a powerful solution for clinically deployable polyp segmentation under
limited supervision.

</details>


### [6] [DoorDet: Semi-Automated Multi-Class Door Detection Dataset via Object Detection and Large Language Models](https://arxiv.org/abs/2508.07714)
*Licheng Zhang,Bach Le,Naveed Akhtar,Tuan Ngo*

Main category: cs.CV

TL;DR: 本研究提出了一种利用对象检测器和大型语言模型（LLM）的半自动化方法，以低成本构建了用于楼层平面图门检测和分类的数据集。


<details>
  <summary>Details</summary>
Motivation: 准确检测和分类楼层平面图中各种类型的门对于建筑合规性检查和室内场景理解等多种应用至关重要，但目前缺乏专门用于细粒度多类别门检测的公开数据集。

Method: 本研究提出了一种半自动化的流程，首先利用先进的目标检测器将所有门检测为统一类别，然后利用大型语言模型（LLM）根据视觉和上下文特征对每个检测到的门实例进行分类，最后通过人工审核阶段确保标签和边界框的高质量。

Result: 该研究成功构建了一个多类别门检测数据集，并通过实验证明了其能够显著降低标注成本，并适用于楼层平面分析中神经网络模型的基准测试。

Conclusion: 该方法通过结合深度学习和多模态推理，能够以最小的人工成本构建用于楼层平面分析的多类别门检测数据集，适用于基准测试神经网络模型。

Abstract: Accurate detection and classification of diverse door types in floor plans
drawings is critical for multiple applications, such as building compliance
checking, and indoor scene understanding. Despite their importance, publicly
available datasets specifically designed for fine-grained multi-class door
detection remain scarce. In this work, we present a semi-automated pipeline
that leverages a state-of-the-art object detector and a large language model
(LLM) to construct a multi-class door detection dataset with minimal manual
effort. Doors are first detected as a unified category using a deep object
detection model. Next, an LLM classifies each detected instance based on its
visual and contextual features. Finally, a human-in-the-loop stage ensures
high-quality labels and bounding boxes. Our method significantly reduces
annotation cost while producing a dataset suitable for benchmarking neural
models in floor plan analysis. This work demonstrates the potential of
combining deep learning and multimodal reasoning for efficient dataset
construction in complex real-world domains.

</details>


### [7] [Large Language Models Facilitate Vision Reflection in Image Classification](https://arxiv.org/abs/2508.06525)
*Guoyuan An,JaeYoon Kim,SungEui Yoon*

Main category: cs.CV

TL;DR: 本研究通过提示LMM验证预测、分析其内部机制以及使用紧凑的文本表示，展示了提高LMM视觉识别准确性和可解释性的新方法，并提出了一种无需训练即可增强模型性能的连接器。


<details>
  <summary>Details</summary>
Motivation: 探究大型多模态模型（LMM）中视觉反射的可解释性，并提出提高LMM视觉识别能力的新方法。

Method: 1. 提示LMM验证专用视觉模型的预测以提高识别准确性。 2. 分析视觉反射的内部行为，发现视觉-语言连接器将视觉特征映射到显性文本概念。 3. 观察到用少量文本标记替换大量视觉标记仍能使LLaVA生成相似的答案。 4. 证明免训练连接器可以在没有广泛特征对齐训练的情况下增强LMM在细粒度识别任务中的性能。

Result: 1. 提示LMM进行验证可提高ImageNet等基准的识别准确性。 2. 视觉-语言连接器将视觉特征映射到文本概念，使语言模型能够进行推理。 3. LMM可能主要依赖于精炼的文本表示而非原始视觉特征。 4. 免训练连接器可无需大量训练即可提升细粒度识别性能。

Conclusion: 该研究为理解和改进视觉语言模型（LMM）提供了新的见解，并表明视觉反射是一种实现鲁棒和可解释视觉识别的有前景的策略。

Abstract: This paper presents several novel findings on the explainability of vision
reflection in large multimodal models (LMMs). First, we show that prompting an
LMM to verify the prediction of a specialized vision model can improve
recognition accuracy, even on benchmarks like ImageNet, despite prior evidence
that LMMs typically underperform dedicated vision encoders. Second, we analyze
the internal behavior of vision reflection and find that the vision-language
connector maps visual features into explicit textual concepts, allowing the
language model to reason about prediction plausibility using commonsense
knowledge. We further observe that replacing a large number of vision tokens
with only a few text tokens still enables LLaVA to generate similar answers,
suggesting that LMMs may rely primarily on a compact set of distilled textual
representations rather than raw vision features. Third, we show that a
training-free connector can enhance LMM performance in fine-grained recognition
tasks, without extensive feature-alignment training. Together, these findings
offer new insights into the explainability of vision-language models and
suggest that vision reflection is a promising strategy for achieving robust and
interpretable visual recognition.

</details>


### [8] [VOccl3D: A Video Benchmark Dataset for 3D Human Pose and Shape Estimation under real Occlusions](https://arxiv.org/abs/2508.06757)
*Yash Garg,Saketh Bachu,Arindam Dutta,Rohit Lal,Sarosij Bose,Calvin-Khang Ta,M. Salman Asif,Amit Roy-Chowdhury*

Main category: cs.CV

TL;DR: 该研究提出了VOccl3D数据集，解决了现有数据集在真实遮挡场景评估HPS方法时的不足。通过在该数据集上微调模型，显著提升了HPS估计和人体检测在遮挡场景下的性能，并构建了一个鲁棒的端到端系统。


<details>
  <summary>Details</summary>
Motivation: 现有的人体姿态和形状（HPS）估计方法在处理复杂人体姿态或严重遮挡的挑战性场景时表现不佳。尽管一些研究尝试解决遮挡问题，但它们通常在缺乏真实或显著遮挡的数据集上进行评估，这些数据集的遮挡方式（如随机图块或剪贴画覆盖）并不反映现实世界的挑战。因此，需要一个包含真实遮挡场景的数据集来填补这一空白。

Method: 1. 构建了一个名为VOccl3D的新型视频人体遮挡数据集，包含3D人体姿态和形状标注。
2. 使用计算机图形渲染技术，结合了多样化的真实世界遮挡场景、服装纹理和人体运动。
3. 微调了CLIFF和BEDLAM-CLIFF等近期的人体姿态和形状（HPS）估计方法，并在多个公开数据集和VOccl3D测试集上评估了性能。
4. 利用VOccl3D数据集微调了YOLOv11目标检测器，以增强在遮挡情况下的检测能力。
5. 提出了一个鲁棒的端到端HPS估计系统，能够处理遮挡场景。

Result: 1. 在VOccl3D数据集上微调的CLIFF和BEDLAM-CLIFF方法，在多个公开数据集和VOccl3D测试集上均取得了显著的定性和定量性能提升。
2. 利用VOccl3D数据集微调的YOLOv11模型，在遮挡场景下的人体检测性能得到增强。
3. 成功构建了一个能够处理遮挡的鲁棒端到端HPS估计系统。

Conclusion: 该研究提出了VOccl3D数据集，一个包含3D人体姿态和形状标注的视频遮挡数据集，旨在解决现有数据集在真实遮挡场景评估方面的不足。通过在该数据集上微调CLIFF和BEDLAM-CLIFF模型，并在多个公开数据集和VOccl3D测试集上进行了评估，证明了显著的性能提升。此外，利用该数据集微调YOLOv11也提升了遮挡场景下的人体检测性能，构建了一个鲁棒的端到端HPS估计系统。VOccl3D数据集为未来研究提供了宝贵的资源，能够更真实地评估和改进处理遮挡问题的方法。

Abstract: Human pose and shape (HPS) estimation methods have been extensively studied,
with many demonstrating high zero-shot performance on in-the-wild images and
videos. However, these methods often struggle in challenging scenarios
involving complex human poses or significant occlusions. Although some studies
address 3D human pose estimation under occlusion, they typically evaluate
performance on datasets that lack realistic or substantial occlusions, e.g.,
most existing datasets introduce occlusions with random patches over the human
or clipart-style overlays, which may not reflect real-world challenges. To
bridge this gap in realistic occlusion datasets, we introduce a novel benchmark
dataset, VOccl3D, a Video-based human Occlusion dataset with 3D body pose and
shape annotations. Inspired by works such as AGORA and BEDLAM, we constructed
this dataset using advanced computer graphics rendering techniques,
incorporating diverse real-world occlusion scenarios, clothing textures, and
human motions. Additionally, we fine-tuned recent HPS methods, CLIFF and
BEDLAM-CLIFF, on our dataset, demonstrating significant qualitative and
quantitative improvements across multiple public datasets, as well as on the
test split of our dataset, while comparing its performance with other
state-of-the-art methods. Furthermore, we leveraged our dataset to enhance
human detection performance under occlusion by fine-tuning an existing object
detector, YOLO11, thus leading to a robust end-to-end HPS estimation system
under occlusions. Overall, this dataset serves as a valuable resource for
future research aimed at benchmarking methods designed to handle occlusions,
offering a more realistic alternative to existing occlusion datasets. See the
Project page for code and dataset:https://yashgarg98.github.io/VOccl3D-dataset/

</details>


### [9] [A Framework Combining 3D CNN and Transformer for Video-Based Behavior Recognition](https://arxiv.org/abs/2508.06528)
*Xiuliang Zhang,Tadiwa Elisha Nyamasvisva,Chuntao Liu*

Main category: cs.CV

TL;DR: 提出了一种结合3D CNN和Transformer的混合框架，用于视频行为识别，在提高准确性和管理复杂性方面优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统3D CNN难以建模长期依赖性和Transformer计算成本高的问题。

Method: 提出了一种结合3D CNN和Transformer的混合框架。3D CNN模块提取低级时空特征，Transformer模块捕捉长期时间依赖性，并通过融合机制整合这两种表示。

Result: 在基准数据集上的评估结果表明，所提出的模型优于传统的3D CNN和独立的Transformer，在可管理的复杂性下实现了更高的识别精度。消融研究进一步验证了两个模块的互补优势。

Conclusion: 该混合框架为基于视频的行为识别提供了一种有效且可扩展的解决方案。

Abstract: Video-based behavior recognition is essential in fields such as public
safety, intelligent surveillance, and human-computer interaction. Traditional
3D Convolutional Neural Network (3D CNN) effectively capture local
spatiotemporal features but struggle with modeling long-range dependencies.
Conversely, Transformers excel at learning global contextual information but
face challenges with high computational costs. To address these limitations, we
propose a hybrid framework combining 3D CNN and Transformer architectures. The
3D CNN module extracts low-level spatiotemporal features, while the Transformer
module captures long-range temporal dependencies, with a fusion mechanism
integrating both representations. Evaluated on benchmark datasets, the proposed
model outperforms traditional 3D CNN and standalone Transformers, achieving
higher recognition accuracy with manageable complexity. Ablation studies
further validate the complementary strengths of the two modules. This hybrid
framework offers an effective and scalable solution for video-based behavior
recognition.

</details>


### [10] [StyleTailor: Towards Personalized Fashion Styling via Hierarchical Negative Feedback](https://arxiv.org/abs/2508.06555)
*Hongbo Ma,Fei Shen,Hongbin Xu,Xiaoce Wang,Gang Xu,Jinkai Zheng,Liangqiong Qu,Ming Li*

Main category: cs.CV

TL;DR: StyleTailor是一个创新的时尚造型框架，通过多层次负反馈和两个核心代理（设计师和顾问）实现个性化设计和推荐，并在实验中表现优于其他模型。


<details>
  <summary>Details</summary>
Motivation: 个性化时尚造型的解决方案仍有待探索，但它在改善购物体验方面具有巨大潜力。

Method: StyleTailor是一个协作代理框架，集成了个性化服装设计、购物推荐、虚拟试穿和系统评估。它采用多层次负反馈驱动的迭代视觉精炼范式，通过设计师和顾问两个核心代理，利用分层视觉-语言模型反馈进行优化。

Result: StyleTailor在提供个性化设计和推荐方面表现出色，优于没有负反馈的基线模型。

Conclusion: StyleTailor在个性化设计和推荐方面表现优于其他基线模型，为智能时尚系统设定了新基准。

Abstract: The advancement of intelligent agents has revolutionized problem-solving
across diverse domains, yet solutions for personalized fashion styling remain
underexplored, which holds immense promise for promoting shopping experiences.
In this work, we present StyleTailor, the first collaborative agent framework
that seamlessly unifies personalized apparel design, shopping recommendation,
virtual try-on, and systematic evaluation into a cohesive workflow. To this
end, StyleTailor pioneers an iterative visual refinement paradigm driven by
multi-level negative feedback, enabling adaptive and precise user alignment.
Specifically, our framework features two core agents, i.e., Designer for
personalized garment selection and Consultant for virtual try-on, whose outputs
are progressively refined via hierarchical vision-language model feedback
spanning individual items, complete outfits, and try-on efficacy.
Counterexamples are aggregated into negative prompts, forming a closed-loop
mechanism that enhances recommendation quality.To assess the performance, we
introduce a comprehensive evaluation suite encompassing style consistency,
visual quality, face similarity, and artistic appraisal. Extensive experiments
demonstrate StyleTailor's superior performance in delivering personalized
designs and recommendations, outperforming strong baselines without negative
feedback and establishing a new benchmark for intelligent fashion systems.

</details>


### [11] [DiffUS: Differentiable Ultrasound Rendering from Volumetric Imaging](https://arxiv.org/abs/2508.06768)
*Noe Bertramo,Gabriel Duguey,Vivek Gopalakrishnan*

Main category: cs.CV

TL;DR: DiffUS是一个基于物理的、可微分的超声渲染器，可以将MRI扫描转换为逼真的超声图像，从而改善术中引导。


<details>
  <summary>Details</summary>
Motivation: 为了弥合术前规划和术中引导之间的差距，需要一种能够从体积成像合成逼真B模式图像的方法，以解决术中超声成像中存在的噪声、伪影以及与高分辨率术前MRI/CT扫描对齐性差的问题。

Method: DiffUS首先使用机器学习方法将MRI 3D扫描转换为声阻抗体积。然后，它使用射线追踪和耦合的反射-透射方程来模拟超声束传播，将波传播构建为捕获多个内部反射的稀疏线性系统。最后，通过跨扇形采集几何的深度分辨回波提取来重建B模式图像，并加入散斑噪声和依赖于深度的衰减等真实伪影。

Result: DiffUS能够生成逼真的B模式超声图像，并且在ReMIND数据集上的评估证明了其能够从大脑MRI数据生成解剖学上准确的超声图像。

Conclusion: DiffUS能够从大脑MRI数据生成解剖学上准确的超声图像，适用于切片到体积配准和体积重建等下游应用。

Abstract: Intraoperative ultrasound imaging provides real-time guidance during numerous
surgical procedures, but its interpretation is complicated by noise, artifacts,
and poor alignment with high-resolution preoperative MRI/CT scans. To bridge
the gap between reoperative planning and intraoperative guidance, we present
DiffUS, a physics-based, differentiable ultrasound renderer that synthesizes
realistic B-mode images from volumetric imaging. DiffUS first converts MRI 3D
scans into acoustic impedance volumes using a machine learning approach. Next,
we simulate ultrasound beam propagation using ray tracing with coupled
reflection-transmission equations. DiffUS formulates wave propagation as a
sparse linear system that captures multiple internal reflections. Finally, we
reconstruct B-mode images via depth-resolved echo extraction across fan-shaped
acquisition geometry, incorporating realistic artifacts including speckle noise
and depth-dependent degradation. DiffUS is entirely implemented as
differentiable tensor operations in PyTorch, enabling gradient-based
optimization for downstream applications such as slice-to-volume registration
and volumetric reconstruction. Evaluation on the ReMIND dataset demonstrates
DiffUS's ability to generate anatomically accurate ultrasound images from brain
MRI data.

</details>


### [12] [RMT-PPAD: Real-time Multi-task Learning for Panoptic Perception in Autonomous Driving](https://arxiv.org/abs/2508.06529)
*Jiayuan Wang,Q. M. Jonathan Wu,Katsuya Suto,Ning Zhang*

Main category: cs.CV

TL;DR: RMT-PPAD是一个实时Transformer多任务模型，用于联合进行目标检测、可行驶区域分割和车道线分割，提高了精度和效率。


<details>
  <summary>Details</summary>
Motivation: 为了实现高精度和实时性能的全方位驾驶感知，以满足自动驾驶系统的需求。

Method: 提出了一种名为RMT-PPAD的基于Transformer的实时多任务模型，该模型能够联合执行目标检测、可行驶区域分割和车道线分割。模型包含一个轻量级模块（门控自适应融合模块），用于自适应地融合共享和任务特定的特征，以减轻任务间的负迁移。此外，还设计了一个自适应分割解码器，能够自动学习多尺度特征上的权重，避免了手动设计特定于任务的结构。同时，解决了训练和测试标签在车道线分割中的不一致性问题，以实现更公平的评估。

Result: 在BDD100K数据集上，RMT-PPAD在目标检测方面取得了84.9%的mAP50和95.4%的召回率；在可行驶区域分割方面取得了92.6%的mIoU；在车道线分割方面取得了56.8%的IoU和84.7%的准确率。推理速度达到了32.6 FPS。在真实世界场景评估中，RMT-PPAD表现出稳定的性能。

Conclusion: RMT-PPAD在BDD100K数据集上实现了最先进的性能，并在真实世界场景中表现稳定，同时推理速度达到32.6 FPS。

Abstract: Autonomous driving systems rely on panoptic driving perception that requires
both precision and real-time performance. In this work, we propose RMT-PPAD, a
real-time, transformer-based multi-task model that jointly performs object
detection, drivable area segmentation, and lane line segmentation. We introduce
a lightweight module, a gate control with an adapter to adaptively fuse shared
and task-specific features, effectively alleviating negative transfer between
tasks. Additionally, we design an adaptive segmentation decoder to learn the
weights over multi-scale features automatically during the training stage. This
avoids the manual design of task-specific structures for different segmentation
tasks. We also identify and resolve the inconsistency between training and
testing labels in lane line segmentation. This allows fairer evaluation.
Experiments on the BDD100K dataset demonstrate that RMT-PPAD achieves
state-of-the-art results with mAP50 of 84.9% and Recall of 95.4% for object
detection, mIoU of 92.6% for drivable area segmentation, and IoU of 56.8% and
accuracy of 84.7% for lane line segmentation. The inference speed reaches 32.6
FPS. Moreover, we introduce real-world scenarios to evaluate RMT-PPAD
performance in practice. The results show that RMT-PPAD consistently delivers
stable performance. The source codes and pre-trained models are released at
https://github.com/JiayuanWang-JW/RMT-PPAD.

</details>


### [13] [Evaluating Fisheye-Compatible 3D Gaussian Splatting Methods on Real Images Beyond 180 Degree Field of View](https://arxiv.org/abs/2508.06968)
*Ulas Gunes,Matias Turkulainen,Juho Kannala,Esa Rahtu*

Main category: cs.CV

TL;DR: 研究首次评估了Fisheye-GS和3DGUT这两种基于鱼眼镜头的三维高斯泼溅方法在极端广角（>180度）真实图像上的性能。结果显示，Fisheye-GS在160度视场角下效果更佳，3DGUT在200度全视场角下表现稳定。为解决SfM初始化在强畸变下失效的问题，研究提出了一种基于UniK3D深度预测的初始化策略，可在复杂场景下实现与SfM相当的重建质量。该研究证明了鱼眼三维高斯泼溅方法在处理畸变、稀疏输入进行广角重建的实用性。


<details>
  <summary>Details</summary>
Motivation: 现有三维重建方法在处理超过180度视场角的鱼眼图像时面临挑战，尤其是在强畸变和稀疏输入的情况下。本研究旨在评估和改进基于鱼眼镜头的三维高斯泼溅方法（Fisheye-GS和3DGUT）在真实广角场景下的性能，并提出一种新的初始化策略以克服传统SfM方法的局限性。

Method: 该研究评估了Fisheye-GS和3DGUT两种基于鱼眼镜头的三维高斯泼溅方法在真实图像上的性能，并分析了不同视场角（200度、160度、120度）对重建质量的影响。为了解决SfM初始化在强畸变下失效的问题，研究提出了一种基于UniK3D深度预测的初始化策略，仅使用2-3张鱼眼图像即可生成用于三维重建的点云。

Result: Fisheye-GS在160度视场角下表现更好，而3DGUT在200度全视场角下表现稳定且质量高。提出的基于UniK3D的深度初始化策略在有雾、眩光或天空等复杂场景下，能够生成高质量点云，重建效果媲美SfM。

Conclusion: 该研究展示了基于鱼眼镜头的三维高斯泼溅（3DGS）方法在超过180度视场角的真实图像上的首次评估。研究结果表明，Fisheye-GS在视场角减小到160度时性能有所提升，而3DGUT在所有视场角设置下均表现稳定，并在200度全视场角下保持了高感知质量。此外，通过引入一种基于UniK3D深度预测的初始化策略，有效解决了传统SfM方法在强畸变下失效的问题，即使在有雾、眩光或天空等复杂场景下，也能实现与SfM相当的重建质量。这证明了基于鱼眼镜头的三维高斯泼溅方法在处理稀疏且畸变严重的图像输入以进行广角三维重建方面具有实际应用潜力。

Abstract: We present the first evaluation of fisheye-based 3D Gaussian Splatting
methods, Fisheye-GS and 3DGUT, on real images with fields of view exceeding 180
degree. Our study covers both indoor and outdoor scenes captured with 200
degree fisheye cameras and analyzes how each method handles extreme distortion
in real world settings. We evaluate performance under varying fields of view
(200 degree, 160 degree, and 120 degree) to study the tradeoff between
peripheral distortion and spatial coverage. Fisheye-GS benefits from field of
view (FoV) reduction, particularly at 160 degree, while 3DGUT remains stable
across all settings and maintains high perceptual quality at the full 200
degree view. To address the limitations of SfM-based initialization, which
often fails under strong distortion, we also propose a depth-based strategy
using UniK3D predictions from only 2-3 fisheye images per scene. Although
UniK3D is not trained on real fisheye data, it produces dense point clouds that
enable reconstruction quality on par with SfM, even in difficult scenes with
fog, glare, or sky. Our results highlight the practical viability of
fisheye-based 3DGS methods for wide-angle 3D reconstruction from sparse and
distortion-heavy image inputs.

</details>


### [14] [What Makes "Good" Distractors for Object Hallucination Evaluation in Large Vision-Language Models?](https://arxiv.org/abs/2508.06530)
*Ming-Kun Xie,Jia-Hao Xiao,Gang Niu,Lei Feng,Zhiqiang Kou,Min-Ling Zhang,Masashi Sugiyama*

Main category: cs.CV

TL;DR: HOPE是一个新基准，通过生成更具欺骗性的干扰项（如不匹配的物体或描述），比POPE更能有效地检测出大型视觉语言模型（LVLM）的对象幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有的POPE基准在评估LVLM对象幻觉问题时，由于其简化的采样策略，未能充分利用图像特异性信息，并且仅限于负面物体类别，导致评估效果下降。需要一个更有效的基准来更严格地评估LVLM的幻觉问题。

Method: 提出了一种名为HOPE（Hallucination searching-based Object Probing Evaluation）的新型基准。HOPE采用内容感知和描述驱动的幻觉搜索策略，利用CLIP模型寻找与图像内容最相关的误导性负面物体，并构造包含真实物体但描述错误的干扰项，以更严格地评估LVLM的幻觉免疫力。

Result: HOPE基准在多种先进LVLM上实现了至少9%到23%的精度下降，显著优于POPE基准，能更有效地暴露LVLM的幻觉脆弱性。

Conclusion: HOPE基准在评估大规模视觉语言模型（LVLM）的对象幻觉问题上，通过生成误导性干扰项，比现有的POPE基准更有效，能显著降低模型精度，暴露其幻觉漏洞。

Abstract: Large Vision-Language Models (LVLMs), empowered by the success of Large
Language Models (LLMs), have achieved impressive performance across domains.
Despite the great advances in LVLMs, they still suffer from the unavailable
object hallucination issue, which tends to generate objects inconsistent with
the image content. The most commonly used Polling-based Object Probing
Evaluation (POPE) benchmark evaluates this issue by sampling negative
categories according to category-level statistics, \textit{e.g.}, category
frequencies and co-occurrence. However, with the continuous advancement of
LVLMs, the POPE benchmark has shown diminishing effectiveness in assessing
object hallucination, as it employs a simplistic sampling strategy that
overlooks image-specific information and restricts distractors to negative
object categories only. In this paper, we introduce the Hallucination
searching-based Object Probing Evaluation (HOPE) benchmark, aiming to generate
the most misleading distractors (\textit{i.e.}, non-existent objects or
incorrect image descriptions) that can trigger hallucination in LVLMs, which
serves as a means to more rigorously assess their immunity to hallucination. To
explore the image-specific information, the content-aware hallucination
searching leverages Contrastive Language-Image Pre-Training (CLIP) to
approximate the predictive behavior of LVLMs by selecting negative objects with
the highest predicted likelihood as distractors. To expand the scope of
hallucination assessment, the description-based hallucination searching
constructs highly misleading distractors by pairing true objects with false
descriptions. Experimental results show that HOPE leads to a precision drop of
at least 9\% and up to 23\% across various state-of-the-art LVLMs,
significantly outperforming POPE in exposing hallucination vulnerabilities. The
code is available at https://github.com/xiemk/HOPE.

</details>


### [15] [HiMat: DiT-based Ultra-High Resolution SVBRDF Generation](https://arxiv.org/abs/2508.07011)
*Zixiong Wang,Jian Yang,Yiwei Hu,Milos Hasan,Beibei Wang*

Main category: cs.CV

TL;DR: HiMat是一个创新的框架，能够高效生成高分辨率SVBRDF，并解决了跨地图一致性的关键问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有技术在创建高分辨率SVBRDF时，在模型重定向、效率和地图一致性方面存在的挑战，利用高分辨率文本到图像扩散Transformer（DiT）模型的潜力。

Method: 提出了一种名为HiMat的内存和计算高效的基于扩散的框架，用于生成4K分辨率的SVBRDF。该框架引入了CrossStitch模块，这是一个轻量级的卷积模块，通过局部操作捕捉地图间的依赖关系，以在不同地图间保持一致性，而无需重新训练VAE或大幅修改DiT骨干网络。

Result: HiMat能够生成具有高度结构一致性和高频细节的4K分辨率SVBRDF。实验结果表明，该方法在处理大量文本提示时是有效的，并且在固有分解等任务上也表现出泛化能力。

Conclusion: HiMat是一个高效的基于扩散的框架，能够生成高分辨率的SVBRDF。该框架通过引入CrossStitch模块，解决了多地图之间保持一致性的挑战，同时保持了轻量级。实验证明了HiMat在4K SVBRDF生成方面的有效性，并具有泛化到其他任务的潜力。

Abstract: Creating highly detailed SVBRDFs is essential for 3D content creation. The
rise of high-resolution text-to-image generative models, based on diffusion
transformers (DiT), suggests an opportunity to finetune them for this task.
However, retargeting the models to produce multiple aligned SVBRDF maps instead
of just RGB images, while achieving high efficiency and ensuring consistency
across different maps, remains a challenge. In this paper, we introduce HiMat:
a memory- and computation-efficient diffusion-based framework capable of
generating native 4K-resolution SVBRDFs. A key challenge we address is
maintaining consistency across different maps in a lightweight manner, without
relying on training new VAEs or significantly altering the DiT backbone (which
would damage its prior capabilities). To tackle this, we introduce the
CrossStitch module, a lightweight convolutional module that captures inter-map
dependencies through localized operations. Its weights are initialized such
that the DiT backbone operation is unchanged before finetuning starts. HiMat
enables generation with strong structural coherence and high-frequency details.
Results with a large set of text prompts demonstrate the effectiveness of our
approach for 4K SVBRDF generation. Further experiments suggest generalization
to tasks such as intrinsic decomposition.

</details>


### [16] [Matrix-3D: Omnidirectional Explorable 3D World Generation](https://arxiv.org/abs/2508.08086)
*Zhongqi Yang,Wenhang Ge,Yuqi Li,Jiaqi Chen,Haoyuan Li,Mengyin An,Fei Kang,Hua Xue,Baixin Xu,Yuyang Yin,Eric Li,Yang Liu,Yikai Wang,Hao-Xiang Guo,Yahui Zhou*

Main category: cs.CV

TL;DR: Matrix-3D 使用全景表示生成更广泛、更详细的 3D 世界，并提供快速和精确的重建方法，性能优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有 3D 世界生成方法在生成场景范围有限的问题，本研究提出 Matrix-3D 框架，利用全景表示来实现广泛的、全方向的、可探索的 3D 世界生成。

Method: 该框架结合了条件视频生成和全景 3D 重建。首先，训练了一个轨迹引导的全景视频扩散模型，使用场景网格渲染作为条件，以实现高质量、几何一致的场景视频生成。然后，提出了两种方法将全景视频提升到 3D 世界：(1) 一个前馈式的大型全景重建模型，用于快速 3D 场景重建；(2) 一个基于优化的流程，用于精确、详细的 3D 场景重建。此外，还引入了 Matrix-Pano 数据集，包含 116K 个高质量的静态全景视频序列，并带有深度和轨迹注释。

Result: 实验证明，Matrix-3D 框架在全景视频生成和 3D 世界生成方面均达到了最先进的性能。

Conclusion: Matrix-3D 框架在全景视频生成和 3D 世界生成方面取得了最先进的性能。

Abstract: Explorable 3D world generation from a single image or text prompt forms a
cornerstone of spatial intelligence. Recent works utilize video model to
achieve wide-scope and generalizable 3D world generation. However, existing
approaches often suffer from a limited scope in the generated scenes. In this
work, we propose Matrix-3D, a framework that utilize panoramic representation
for wide-coverage omnidirectional explorable 3D world generation that combines
conditional video generation and panoramic 3D reconstruction. We first train a
trajectory-guided panoramic video diffusion model that employs scene mesh
renders as condition, to enable high-quality and geometrically consistent scene
video generation. To lift the panorama scene video to 3D world, we propose two
separate methods: (1) a feed-forward large panorama reconstruction model for
rapid 3D scene reconstruction and (2) an optimization-based pipeline for
accurate and detailed 3D scene reconstruction. To facilitate effective
training, we also introduce the Matrix-Pano dataset, the first large-scale
synthetic collection comprising 116K high-quality static panoramic video
sequences with depth and trajectory annotations. Extensive experiments
demonstrate that our proposed framework achieves state-of-the-art performance
in panoramic video generation and 3D world generation. See more in
https://matrix-3d.github.io.

</details>


### [17] [Benchmarking Deep Learning-Based Object Detection Models on Feature Deficient Astrophotography Imagery Dataset](https://arxiv.org/abs/2508.06537)
*Shantanusinh Parmar*

Main category: cs.CV

TL;DR: MobilTelesco是一个包含稀疏夜空图像的智能手机摄影数据集，可用于测试天空中物体检测模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的物体检测数据集缺乏在非商业领域（如天文摄影）中常见的信号稀疏性。

Method: 使用MobilTelesco数据集对几种检测模型进行了基准测试。

Result: 在MobilTelesco数据集上对几种检测模型进行了基准测试，并指出了在特征不足条件下的挑战。

Conclusion: MobilTelesco数据集能够突出天空中物体检测的挑战，尤其是在特征不足的情况下。

Abstract: Object detection models are typically trained on datasets like ImageNet,
COCO, and PASCAL VOC, which focus on everyday objects. However, these lack
signal sparsity found in non-commercial domains. MobilTelesco, a
smartphone-based astrophotography dataset, addresses this by providing sparse
night-sky images. We benchmark several detection models on it, highlighting
challenges under feature-deficient conditions.

</details>


### [18] [MILD: Multi-Layer Diffusion Strategy for Complex and Precise Multi-IP Aware Human Erasing](https://arxiv.org/abs/2508.06543)
*Jinghan Yu,Zhiyuan Ma,Yue Ma,Kaiqi Liu,Yuhan Wang,Jianjun Li*

Main category: cs.CV

TL;DR: 本研究提出了一种名为MILD的新方法，通过多层扩散和人体形态指导来解决复杂多IP场景中的人体擦除问题，并在实验中证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在涉及人与人遮挡、人与物纠缠和背景干扰的复杂多IP场景中存在不足。这些挑战主要归因于：1) 数据集限制，现有数据集很少涵盖密集遮挡、伪装背景和多样的交互；2) 缺乏空间解耦，前景实例无法有效解耦，限制了背景的干净恢复。

Method: 提出了一种名为多层扩散（MILD）的新颖策略，该策略将生成分解为每个实例和背景的语义分离路径。为了增强以人为中心的理解，我们引入了人体形态指导，集成了姿势、解析和空间关系。我们进一步提出了空间调制注意，以更好地引导注意流。

Result: 提出了一种高质量的多IP人体擦除数据集，具有多样的姿势变化和复杂的背景。

Conclusion: MILD在具有挑战性的人体擦除基准上优于最先进的方法。

Abstract: Recent years have witnessed the success of diffusion models in
image-customized tasks. Prior works have achieved notable progress on
human-oriented erasing using explicit mask guidance and semantic-aware
inpainting. However, they struggle under complex multi-IP scenarios involving
human-human occlusions, human-object entanglements, and background
interferences. These challenges are mainly due to: 1) Dataset limitations, as
existing datasets rarely cover dense occlusions, camouflaged backgrounds, and
diverse interactions; 2) Lack of spatial decoupling, where foreground instances
cannot be effectively disentangled, limiting clean background restoration. In
this work, we introduce a high-quality multi-IP human erasing dataset with
diverse pose variations and complex backgrounds. We then propose Multi-Layer
Diffusion (MILD), a novel strategy that decomposes generation into semantically
separated pathways for each instance and the background. To enhance
human-centric understanding, we introduce Human Morphology Guidance,
integrating pose, parsing, and spatial relations. We further present
Spatially-Modulated Attention to better guide attention flow. Extensive
experiments show that MILD outperforms state-of-the-art methods on challenging
human erasing benchmarks.

</details>


### [19] [Statistical Confidence Rescoring for Robust 3D Scene Graph Generation from Multi-View Images](https://arxiv.org/abs/2508.06546)
*Qi Xun Yeo,Yanyan Li,Gim Hee Lee*

Main category: cs.CV

TL;DR: Leveraging multi-view RGB images for 3D semantic scene graph estimation by overcoming noisy geometry and background noise through semantic masks and neighboring node information, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: In the absence of given 3D ground truth representations, we explore leveraging only multi-view RGB images to tackle this task. To attain robust features for accurate scene graph estimation, we must overcome the noisy reconstructed pseudo point-based geometry from predicted depth maps and reduce the amount of background noise present in multi-view image features.

Method: We obtain semantic masks to guide feature aggregation to filter background features and design a novel method to incorporate neighboring node information to aid robustness of our scene graph estimates. Furthermore, we leverage on explicit statistical priors calculated from the training summary statistics to refine node and edge predictions based on their one-hop neighborhood.

Result: Our experiments show that our method outperforms current methods purely using multi-view images as the initial input.

Conclusion: Our method outperforms current methods purely using multi-view images as the initial input.

Abstract: Modern 3D semantic scene graph estimation methods utilize ground truth 3D
annotations to accurately predict target objects, predicates, and
relationships. In the absence of given 3D ground truth representations, we
explore leveraging only multi-view RGB images to tackle this task. To attain
robust features for accurate scene graph estimation, we must overcome the noisy
reconstructed pseudo point-based geometry from predicted depth maps and reduce
the amount of background noise present in multi-view image features. The key is
to enrich node and edge features with accurate semantic and spatial information
and through neighboring relations. We obtain semantic masks to guide feature
aggregation to filter background features and design a novel method to
incorporate neighboring node information to aid robustness of our scene graph
estimates. Furthermore, we leverage on explicit statistical priors calculated
from the training summary statistics to refine node and edge predictions based
on their one-hop neighborhood. Our experiments show that our method outperforms
current methods purely using multi-view images as the initial input. Our
project page is available at https://qixun1.github.io/projects/SCRSSG.

</details>


### [20] [Slice or the Whole Pie? Utility Control for AI Models](https://arxiv.org/abs/2508.06551)
*Ye Tao*

Main category: cs.CV

TL;DR: NNObfuscator 是一种允许单个 AI 模型根据预定义的条件动态修改其性能的机制，从而为免费和高级用户提供不同级别的性能，以克服训练 DNN 所需的大量资源。


<details>
  <summary>Details</summary>
Motivation: 为了克服训练深度神经网络 (DNN) 所需的大量资源、大量标记数据、大量计算能力和大量微调工作的挑战，即使在使用预训练模型时也是如此。

Method: NNObfuscator 是一种新颖的效用控制机制，它使 AI 模型能够根据预定义的条件动态修改其性能。

Result: NNObfuscator 允许实时调整单个模型，提供对多个性能级别的受控访问，从而提高了资源分配，减少了不必要的计算，并支持 AI 部署中的可持续业务模型。

Conclusion: NNObfuscator 成功地使模型更具适应性，使单个训练模型能够处理广泛的任务，而无需进行大量更改。

Abstract: Training deep neural networks (DNNs) has become an increasingly
resource-intensive task, requiring large volumes of labeled data, substantial
computational power, and considerable fine-tuning efforts to achieve optimal
performance across diverse use cases. Although pre-trained models offer a
useful starting point, adapting them to meet specific user needs often demands
extensive customization, and infrastructure overhead. This challenge grows when
a single model must support diverse appli-cations with differing requirements
for performance. Traditional solutions often involve training multiple model
versions to meet varying requirements, which can be inefficient and difficult
to maintain. In order to overcome this challenge, we propose NNObfuscator, a
novel utility control mechanism that enables AI models to dynamically modify
their performance according to predefined conditions. It is different from
traditional methods that need separate models for each user. Instead,
NNObfuscator allows a single model to be adapted in real time, giving you
controlled access to multiple levels of performance. This mechanism enables
model owners set up tiered access, ensuring that free-tier users receive a
baseline level of performance while premium users benefit from enhanced
capabilities. The approach improves resource allocation, reduces unnecessary
computation, and supports sustainable business models in AI deployment. To
validate our approach, we conducted experiments on multiple tasks, including
image classification, semantic segmentation, and text to image generation,
using well-established models such as ResNet, DeepLab, VGG16, FCN and Stable
Diffusion. Experimental results show that NNObfuscator successfully makes model
more adaptable, so that a single trained model can handle a broad range of
tasks without requiring a lot of changes.

</details>


### [21] [A Joint Sparse Self-Representation Learning Method for Multiview Clustering](https://arxiv.org/abs/2508.06857)
*Mengxue Jia,Zhihua Allen-Zhao,You Zhao,Sanyang Liu*

Main category: cs.CV

TL;DR: 提出了一种新的多视图聚类模型，通过引入基数约束提取局部信息，并使用低秩约束揭示全局结构。开发了一种具有全局收敛性的交替二次惩罚（AQP）方法来解决模型收敛性问题。实验证明了该模型和方法的优越性。


<details>
  <summary>Details</summary>
Motivation: 为了解决多视图聚类（MC）中子空间聚类模型在处理非凸、非光滑模型时，基于增广拉格朗日方法（ALM）的交替最小化算法无法保证收敛性，导致泛化能力差的问题。

Method: 提出了一种新颖的联合稀疏自表示学习模型，通过引入基数（$	ext{l}_0$-范数）约束来提取视图特定的局部信息，并结合低秩约束来揭示共识亲和矩阵中的全局相干结构。为解决非凸、非光滑模型引起的收敛性问题，开发了一种具有全局收敛性的交替二次惩罚（AQP）方法，通过闭式解迭代求解两个子问题。

Result: 在六个标准数据集上的实验结果表明，所提出的模型和AQP方法在性能上优于八种最先进的算法。

Conclusion: 该模型通过引入基数约束来提取视图特定的局部信息，并使用低秩约束来揭示共识亲和矩阵中的全局相干结构。提出的AQP方法具有全局收敛性，并且子问题可以通过闭式解求解。实验结果表明，该模型和AQP方法优于现有的八种算法。

Abstract: Multiview clustering (MC) aims to group samples using consistent and
complementary information across various views. The subspace clustering, as a
fundamental technique of MC, has attracted significant attention. In this
paper, we propose a novel joint sparse self-representation learning model for
MC, where a featured difference is the extraction of view-specific local
information by introducing cardinality (i.e., $\ell_0$-norm) constraints
instead of Graph-Laplacian regularization. Specifically, under each view,
cardinality constraints directly restrict the samples used in the
self-representation stage to extract reliable local and global structure
information, while the low-rank constraint aids in revealing a global coherent
structure in the consensus affinity matrix during merging. The attendant
challenge is that Augmented Lagrange Method (ALM)-based alternating
minimization algorithms cannot guarantee convergence when applied directly to
our nonconvex, nonsmooth model, thus resulting in poor generalization ability.
To address it, we develop an alternating quadratic penalty (AQP) method with
global convergence, where two subproblems are iteratively solved by closed-form
solutions. Empirical results on six standard datasets demonstrate the
superiority of our model and AQP method, compared to eight state-of-the-art
algorithms.

</details>


### [22] [Age-Diverse Deepfake Dataset: Bridging the Age Gap in Deepfake Detection](https://arxiv.org/abs/2508.06552)
*Unisha Joshi*

Main category: cs.CV

TL;DR: 该论文提出了一个年龄多样化的深度伪造数据集，以解决现有数据集中存在的年龄偏见问题，并通过实验证明使用该数据集训练的模型在公平性和准确性方面有所提升。


<details>
  <summary>Details</summary>
Motivation: 当前深度伪造检测技术面临技术进步和深度伪造内容普及带来的挑战，而现有的深度伪造数据集中存在的年龄偏见问题尚未得到充分解决。

Method: 通过整合现有深度伪造数据集（Celeb-DF、FaceForensics++、UTKFace）并创建合成数据来构建年龄多样化的深度伪造数据集，并使用XceptionNet、EfficientNet和LipForensics三个模型进行评估。

Result: 在年龄多样化的数据上训练的模型在跨年龄组的公平性、整体准确性和跨数据集的泛化能力方面表现更优。

Conclusion: 该研究提出了一个年龄多样化的深度伪造数据集和模型管线，以解决深度伪造数据集中的年龄偏见问题，提高了跨年龄组的公平性、整体准确性和跨数据集的泛化能力。

Abstract: The challenges associated with deepfake detection are increasing
significantly with the latest advancements in technology and the growing
popularity of deepfake videos and images. Despite the presence of numerous
detection models, demographic bias in the deepfake dataset remains largely
unaddressed. This paper focuses on the mitigation of age-specific bias in the
deepfake dataset by introducing an age-diverse deepfake dataset that will
improve fairness across age groups. The dataset is constructed through a
modular pipeline incorporating the existing deepfake datasets Celeb-DF,
FaceForensics++, and UTKFace datasets, and the creation of synthetic data to
fill the age distribution gaps. The effectiveness and generalizability of this
dataset are evaluated using three deepfake detection models: XceptionNet,
EfficientNet, and LipForensics. Evaluation metrics, including AUC, pAUC, and
EER, revealed that models trained on the age-diverse dataset demonstrated
fairer performance across age groups, improved overall accuracy, and higher
generalization across datasets. This study contributes a reproducible,
fairness-aware deepfake dataset and model pipeline that can serve as a
foundation for future research in fairer deepfake detection. The complete
dataset and implementation code are available at
https://github.com/unishajoshi/age-diverse-deepfake-detection.

</details>


### [23] [Static and Plugged: Make Embodied Evaluation Simple](https://arxiv.org/abs/2508.06553)
*Jiahao Xiao,Jianbo Zhang,BoWen Yan,Shengyu Guo,Tongrui Ye,Kaiwei Zhang,Zicheng Zhang,Xiaohong Liu,Zhengxue Cheng,Lei Fan,Chuyi Li,Guangtao Zhai*

Main category: cs.CV

TL;DR: 提出StaticEmbodiedBench，一个使用静态场景表示的具身智能评估基准，解决了现有评估方法的局限性，并发布了首个具身智能静态排行榜。


<details>
  <summary>Details</summary>
Motivation: 解决当前评估具身智能的方法（交互式模拟环境或真实世界设置）成本高、碎片化且难以扩展的问题。

Method: 通过使用静态场景表示，提供一个统一的评估界面，涵盖42个多样化场景和8个核心维度，并评估了19个视觉-语言模型（VLMs）和11个视觉-语言-动作模型（VLAs）。

Result: 建立了第一个具身智能静态排行榜，评估了19个VLMs和11个VLAs，并发布了200个样本子集以加速具身智能的发展。

Conclusion: StaticEmbodiedBench是一个即插即用的基准，它使用静态场景表示来实现统一评估，为具身智能的评估提供了可扩展且全面的方法，并建立了第一个具身智能静态排行榜。

Abstract: Embodied intelligence is advancing rapidly, driving the need for efficient
evaluation. Current benchmarks typically rely on interactive simulated
environments or real-world setups, which are costly, fragmented, and hard to
scale. To address this, we introduce StaticEmbodiedBench, a plug-and-play
benchmark that enables unified evaluation using static scene representations.
Covering 42 diverse scenarios and 8 core dimensions, it supports scalable and
comprehensive assessment through a simple interface. Furthermore, we evaluate
19 Vision-Language Models (VLMs) and 11 Vision-Language-Action models (VLAs),
establishing the first unified static leaderboard for Embodied intelligence.
Moreover, we release a subset of 200 samples from our benchmark to accelerate
the development of embodied intelligence.

</details>


### [24] [From Label Error Detection to Correction: A Modular Framework and Benchmark for Object Detection Datasets](https://arxiv.org/abs/2508.06556)
*Sarina Penquitt,Jonathan Klees,Rinor Cakaj,Daniel Kondermann,Matthias Rottmann,Lars Schmarje*

Main category: cs.CV

TL;DR: 该研究提出了REC$\\checkmark$D框架，通过众包微任务大规模自动校正对象检测数据中的标签错误，并发布了一个新的真实世界基准数据集以推动该领域研究。


<details>
  <summary>Details</summary>
Motivation: 对象检测数据集中的标签错误（如缺失标签、错误分类或不精确的定位）会影响模型训练和评估效果。尽管存在一些检测标签错误的方法，但它们通常仅在合成基准或有限的人工检查上进行验证，缺乏系统性、大规模的校正手段，这是一个亟待解决的问题。

Method: REC$\\checkmark$D框架结合了现有对象检测器进行错误建议，并利用轻量级的众包微任务让多个标注者独立验证候选边界框，通过聚合他们的响应来估计模糊性并提高标签质量。

Result: REC$\\checkmark$D框架在KITTI数据集的pedestrian类别上进行了应用，产生的众包审查结果显示，原始标注中至少有24%存在缺失或不准确的标注。研究表明，结合REC$\\checkmark$D，现有检测方法可以高效地恢复大量错误。然而，即使是最佳方法也可能遗漏高达66%的真实错误，并且低质量标签可能引入比发现的错误更多的错误。

Conclusion: 该研究引入了一个名为REC$\checkmark$D的半自动化框架，用于对象检测数据集中的标签错误校正。通过结合现有检测器和众包微任务，REC$\\checkmark$D能够系统性地、大规模地验证和纠正标签错误。在KITTI数据集的pedestrian类别上的实验表明，该方法能有效识别出至少24%的错误标注，并生成高质量的校正数据集，可作为新的基准。研究还指出，现有标签错误检测方法在与REC$\\checkmark$D结合后效率显著提升，但仍有改进空间，并强调了新基准对未来研究的重要性。

Abstract: Object detection has advanced rapidly in recent years, driven by increasingly
large and diverse datasets. However, label errors, defined as missing labels,
incorrect classification or inaccurate localization, often compromise the
quality of these datasets. This can have a significant impact on the outcomes
of training and benchmark evaluations. Although several methods now exist for
detecting label errors in object detection datasets, they are typically
validated only on synthetic benchmarks or limited manual inspection. How to
correct such errors systemically and at scale therefore remains an open
problem. We introduce a semi-automated framework for label-error correction
called REC$\checkmark$D (Rechecked). Building on existing detectors, the
framework pairs their error proposals with lightweight, crowd-sourced
microtasks. These tasks enable multiple annotators to independently verify each
candidate bounding box, and their responses are aggregated to estimate
ambiguity and improve label quality. To demonstrate the effectiveness of
REC$\checkmark$D, we apply it to the class pedestrian in the KITTI dataset. Our
crowdsourced review yields high-quality corrected annotations, which indicate a
rate of at least 24% of missing and inaccurate annotations in original
annotations. This validated set will be released as a new real-world benchmark
for label error detection and correction. We show that current label error
detection methods, when combined with our correction framework, can recover
hundreds of errors in the time it would take a human to annotate bounding boxes
from scratch. However, even the best methods still miss up to 66% of the true
errors and with low quality labels introduce more errors than they find. This
highlights the urgent need for further research, now enabled by our released
benchmark.

</details>


### [25] [On the effectiveness of multimodal privileged knowledge distillation in two vision transformer based diagnostic applications](https://arxiv.org/abs/2508.06558)
*Simon Baur,Alexandra Benova,Emilio Dolgener Cantú,Jackie Ma*

Main category: cs.CV

TL;DR: MMPKD uses extra training data to improve vision models when some data is missing later, but only within the same data type.


<details>
  <summary>Details</summary>
Motivation: Deep learning models in clinical practice often need multiple data modalities for robust decisions, but not all modalities are always available at inference time.

Method: The paper proposes multimodal privileged knowledge distillation (MMPKD), a training strategy that uses additional modalities available only during training to guide a unimodal vision model. A text-based teacher model for chest radiographs (MIMIC-CXR) and a tabular metadata-based teacher model for mammography (CBIS-DDSM) were used to distill knowledge into a vision transformer student model.

Result: MMPKD improves the zero-shot capabilities of attention maps for ROI localization.

Conclusion: MMPKD can improve the zero-shot capabilities of attention maps for ROI localization in input images, but this effect does not generalize across domains.

Abstract: Deploying deep learning models in clinical practice often requires leveraging
multiple data modalities, such as images, text, and structured data, to achieve
robust and trustworthy decisions. However, not all modalities are always
available at inference time. In this work, we propose multimodal privileged
knowledge distillation (MMPKD), a training strategy that utilizes additional
modalities available solely during training to guide a unimodal vision model.
Specifically, we used a text-based teacher model for chest radiographs
(MIMIC-CXR) and a tabular metadata-based teacher model for mammography
(CBIS-DDSM) to distill knowledge into a vision transformer student model. We
show that MMPKD can improve the resulting attention maps' zero-shot
capabilities of localizing ROI in input images, while this effect does not
generalize across domains, as contrarily suggested by prior research.

</details>


### [26] [Grounding Emotion Recognition with Visual Prototypes: VEGA -- Revisiting CLIP in MERC](https://arxiv.org/abs/2508.06564)
*Guanyu Hu,Dimitrios Kollias,Xinyu Yang*

Main category: cs.CV

TL;DR: This paper introduces VEGA, a novel mechanism using CLIP's image encoder to create emotion-specific visual anchors for multimodal emotion recognition. VEGA improves alignment and achieves state-of-the-art results on IEMOCAP and MELD datasets.


<details>
  <summary>Details</summary>
Motivation: Multimodal emotion recognition models lack psychologically meaningful priors to guide multimodal alignment. This paper proposes using CLIP's image encoder to construct emotion-specific visual anchors, drawing inspiration from cognitive theories.

Method: VEGA mechanism leverages CLIP's image encoder to construct emotion-specific visual anchors based on facial exemplars, guiding unimodal and multimodal features toward a perceptually grounded and psychologically aligned representation space. A stochastic anchor sampling strategy enhances robustness.

Result: Achieves sota performance on IEMOCAP and MELD datasets.

Conclusion: VEGA-augmented model achieves sota performance on IEMOCAP and MELD

Abstract: Multimodal Emotion Recognition in Conversations remains a challenging task
due to the complex interplay of textual, acoustic and visual signals. While
recent models have improved performance via advanced fusion strategies, they
often lack psychologically meaningful priors to guide multimodal alignment. In
this paper, we revisit the use of CLIP and propose a novel Visual Emotion
Guided Anchoring (VEGA) mechanism that introduces class-level visual semantics
into the fusion and classification process. Distinct from prior work that
primarily utilizes CLIP's textual encoder, our approach leverages its image
encoder to construct emotion-specific visual anchors based on facial exemplars.
These anchors guide unimodal and multimodal features toward a perceptually
grounded and psychologically aligned representation space, drawing inspiration
from cognitive theories (prototypical emotion categories and multisensory
integration). A stochastic anchor sampling strategy further enhances robustness
by balancing semantic stability and intra-class diversity. Integrated into a
dual-branch architecture with self-distillation, our VEGA-augmented model
achieves sota performance on IEMOCAP and MELD. Code is available at:
https://github.com/dkollias/VEGA.

</details>


### [27] [Bridging Brain Connectomes and Clinical Reports for Early Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2508.06565)
*Jing Zhang,Xiaowei Yu,Minheng Chen,Lu Zhang,Tong Chen,Yan Zhuang,Chao Cao,Yanjun Lyu,Li Su,Tianming Liu,Dajiang Zhu*

Main category: cs.CV

TL;DR: 本研究提出了一种新颖的框架，通过将大脑子网络视为标记来对齐大脑连接组和临床报告，以实现更好的诊断。该方法在MCI数据集上取得了最先进的性能，并识别出有临床意义的连接组-文本对，为阿尔茨海默病的研究提供了新的见解。


<details>
  <summary>Details</summary>
Motivation: 整合脑成像数据和临床报告可以利用互补的多模态信息，从而在实际临床环境中实现更有效、及时的诊断。然而，将客观的成像数据与基于文本的临床报告（如医生笔记）有效地关联起来仍然是一个关键挑战。

Method: 提出了一种新颖的框架，将大脑连接组与临床报告在共享的跨模态潜在空间中对齐，实现了主题和连接组层面的联合表示学习。该方法将大脑子网络视为成像数据的标记，以匹配临床报告中的单词标记，从而更有效地识别神经影像学发现与临床观察之间的系统级关联。

Result: 该方法不仅在轻度认知障碍（MCI）的ADNI数据集上实现了最先进的预测性能，还识别出具有临床意义的连接组-文本对，为阿尔茨海默病（Alzheimer's disease）的早期机制提供了新见解，并支持了临床上有用的多模态生物标志物的开发。

Conclusion: 该方法在轻度认知障碍（MCI）的ADNI数据集上实现了最先进的预测性能，并识别出具有临床意义的连接组-文本对，为阿尔茨海默病（Alzheimer's disease）的早期机制提供了新见解，并支持了临床上有用的多模态生物标志物的开发。

Abstract: Integrating brain imaging data with clinical reports offers a valuable
opportunity to leverage complementary multimodal information for more effective
and timely diagnosis in practical clinical settings. This approach has gained
significant attention in brain disorder research, yet a key challenge remains:
how to effectively link objective imaging data with subjective text-based
reports, such as doctors' notes. In this work, we propose a novel framework
that aligns brain connectomes with clinical reports in a shared cross-modal
latent space at both the subject and connectome levels, thereby enhancing
representation learning. The key innovation of our approach is that we treat
brain subnetworks as tokens of imaging data, rather than raw image patches, to
align with word tokens in clinical reports. This enables a more efficient
identification of system-level associations between neuroimaging findings and
clinical observations, which is critical since brain disorders often manifest
as network-level abnormalities rather than isolated regional alterations. We
applied our method to mild cognitive impairment (MCI) using the ADNI dataset.
Our approach not only achieves state-of-the-art predictive performance but also
identifies clinically meaningful connectome-text pairs, offering new insights
into the early mechanisms of Alzheimer's disease and supporting the development
of clinically useful multimodal biomarkers.

</details>


### [28] [Surformer v1: Transformer-Based Surface Classification Using Tactile and Vision Features](https://arxiv.org/abs/2508.06566)
*Manish Kansana,Elias Hossain,Shahram Rahimi,Noorbakhsh Amiri Golilarz*

Main category: cs.CV

TL;DR: Surformer v1 是一种基于 Transformer 的模型，可高效准确地识别表面材料，在准确性和推理速度方面优于其他模型。


<details>
  <summary>Details</summary>
Motivation: 表面材料识别是机器人感知和物理交互的关键组成部分，尤其是在利用触觉和视觉传感输入时。

Method: 提出了一种名为 Surformer v1 的基于 Transformer 的架构，该架构使用结构化触觉特征和通过 ResNet-50 提取的 PCA 降维视觉嵌入。该模型集成了特定于模态的编码器和跨模态注意力层，以实现视觉和触觉之间的丰富交互。

Result: 在仅触觉的表面分类任务中，基于 Transformer 的模型实现了最高的准确率和最快的推理时间。在多模态设置中，Surformer v1 实现了 99.4% 的准确率和 0.77 毫秒的推理时间，而多模态 CNN 的准确率略高，但推理时间显著更长。

Conclusion: Surformer v1 在准确性、效率和计算成本之间取得了令人信服的平衡，适用于表面材料识别。

Abstract: Surface material recognition is a key component in robotic perception and
physical interaction, particularly when leveraging both tactile and visual
sensory inputs. In this work, we propose Surformer v1, a transformer-based
architecture designed for surface classification using structured tactile
features and PCA-reduced visual embeddings extracted via ResNet-50. The model
integrates modality-specific encoders with cross-modal attention layers,
enabling rich interactions between vision and touch. Currently,
state-of-the-art deep learning models for vision tasks have achieved remarkable
performance. With this in mind, our first set of experiments focused
exclusively on tactile-only surface classification. Using feature engineering,
we trained and evaluated multiple machine learning models, assessing their
accuracy and inference time. We then implemented an encoder-only Transformer
model tailored for tactile features. This model not only achieved the highest
accuracy but also demonstrated significantly faster inference time compared to
other evaluated models, highlighting its potential for real-time applications.
To extend this investigation, we introduced a multimodal fusion setup by
combining vision and tactile inputs. We trained both Surformer v1 (using
structured features) and Multimodal CNN (using raw images) to examine the
impact of feature-based versus image-based multimodal learning on
classification accuracy and computational efficiency. The results showed that
Surformer v1 achieved 99.4% accuracy with an inference time of 0.77 ms, while
the Multimodal CNN achieved slightly higher accuracy but required significantly
more inference time. These findings suggest Surformer v1 offers a compelling
balance between accuracy, efficiency, and computational cost for surface
material recognition.

</details>


### [29] [ImpliHateVid: A Benchmark Dataset and Two-stage Contrastive Learning Framework for Implicit Hate Speech Detection in Videos](https://arxiv.org/abs/2508.06570)
*Mohammad Zia Ur Rehman,Anukriti Bhatnagar,Omkar Kabde,Shubhi Bansal,Nagendra Kumar*

Main category: cs.CV

TL;DR: 该研究提出了 ImpliHateVid 数据集，用于检测视频中的隐式仇恨言论，并提出了一种新的两阶段对比学习框架来提高检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的研究主要集中在基于文本和图像的仇恨言论检测，而基于视频的方法仍未得到充分探索。

Method: 提出了一种新颖的两阶段对比学习框架，用于视频中的仇恨言论检测。第一阶段，使用对比损失训练特定模态的编码器（音频、文本、图像），并通过串联来自三个编码器的特征。第二阶段，使用对比学习训练跨编码器以完善多模态表示。此外，还结合了情感、情绪和字幕特征以增强隐式仇恨检测。

Result: 在 ImpliHateVid 和 HateMM 数据集上评估了所提出的方法，证明了所提出框架的有效性。

Conclusion: 所提出的多模态对比学习框架在视频中的仇恨内容检测方面是有效的，并且所提出的数据集具有重要意义。

Abstract: The existing research has primarily focused on text and image-based hate
speech detection, video-based approaches remain underexplored. In this work, we
introduce a novel dataset, ImpliHateVid, specifically curated for implicit hate
speech detection in videos. ImpliHateVid consists of 2,009 videos comprising
509 implicit hate videos, 500 explicit hate videos, and 1,000 non-hate videos,
making it one of the first large-scale video datasets dedicated to implicit
hate detection. We also propose a novel two-stage contrastive learning
framework for hate speech detection in videos. In the first stage, we train
modality-specific encoders for audio, text, and image using contrastive loss by
concatenating features from the three encoders. In the second stage, we train
cross-encoders using contrastive learning to refine multimodal representations.
Additionally, we incorporate sentiment, emotion, and caption-based features to
enhance implicit hate detection. We evaluate our method on two datasets,
ImpliHateVid for implicit hate speech detection and another dataset for general
hate speech detection in videos, HateMM dataset, demonstrating the
effectiveness of the proposed multimodal contrastive learning for hateful
content detection in videos and the significance of our dataset.

</details>


### [30] [ContextGuard-LVLM: Enhancing News Veracity through Fine-grained Cross-modal Contextual Consistency Verification](https://arxiv.org/abs/2508.06623)
*Sihan Ma,Qiming Wu,Ruotong Jiang,Frank Burns*

Main category: cs.CV

TL;DR: 提出 ContextGuard-LVLM 框架，通过多阶段上下文推理和强化/对抗学习，解决了数字新闻中细粒度跨模态上下文不一致的问题，并在多个数据集上超越了现有 LVLM 基线。


<details>
  <summary>Details</summary>
Motivation: 数字新闻媒体的激增需要强有力的方法来验证内容的真实性，特别是在视觉和文本信息之间的一致性方面。传统方法在解决细粒度跨模态上下文一致性（FCCC）问题方面常常不足，该问题包括比实体匹配更深层次的视觉叙事、情感基调和背景信息与文本的匹配。

Method: 提出了一种名为 ContextGuard-LVLM 的新颖框架，该框架基于先进的视觉-语言大型模型 (LVLMs)，并集成了多阶段上下文推理机制。通过强化或对抗学习范式对其模型进行了独特增强，使其能够检测到逃避零样本基线的细微上下文失准。扩展并增强了三个已建立的数据集（TamperedNews-Ent、News400-Ent、MMG-Ent），加入了新的细粒度上下文注释，包括“上下文情感”、“视觉叙事主题”和“场景-事件逻辑一致性”，并引入了一个全面的 CTXT（上下文一致性）实体类型。

Result: ContextGuard-LVLM 框架能够检测到逃避零样本基线的细微上下文失准，并在复杂逻辑推理和细微上下文理解方面取得显著改进。该模型在具有挑战性的样本上表现出更强的鲁棒性，并且与人类专家的判断具有更高的 一致性。

Conclusion: ContextGuard-LVLM 在几乎所有细粒度一致性任务上均持续优于最先进的零样本 LVLM 基线（InstructBLIP 和 LLaVA 1.5），在复杂逻辑推理和细微上下文理解方面取得了显著的改进。此外，我们的模型在应对细微扰动方面表现出更强的鲁棒性，并且在具有挑战性的样本上与人类专家的判断具有更高的 一致性，肯定了其在识别复杂的上下文分离形式方面的有效性。

Abstract: The proliferation of digital news media necessitates robust methods for
verifying content veracity, particularly regarding the consistency between
visual and textual information. Traditional approaches often fall short in
addressing the fine-grained cross-modal contextual consistency (FCCC) problem,
which encompasses deeper alignment of visual narrative, emotional tone, and
background information with text, beyond mere entity matching. To address this,
we propose ContextGuard-LVLM, a novel framework built upon advanced
Vision-Language Large Models (LVLMs) and integrating a multi-stage contextual
reasoning mechanism. Our model is uniquely enhanced through reinforced or
adversarial learning paradigms, enabling it to detect subtle contextual
misalignments that evade zero-shot baselines. We extend and augment three
established datasets (TamperedNews-Ent, News400-Ent, MMG-Ent) with new
fine-grained contextual annotations, including "contextual sentiment," "visual
narrative theme," and "scene-event logical coherence," and introduce a
comprehensive CTXT (Contextual Coherence) entity type. Extensive experiments
demonstrate that ContextGuard-LVLM consistently outperforms state-of-the-art
zero-shot LVLM baselines (InstructBLIP and LLaVA 1.5) across nearly all
fine-grained consistency tasks, showing significant improvements in complex
logical reasoning and nuanced contextual understanding. Furthermore, our model
exhibits superior robustness to subtle perturbations and a higher agreement
rate with human expert judgments on challenging samples, affirming its efficacy
in discerning sophisticated forms of context detachment.

</details>


### [31] [VL-MedGuide: A Visual-Linguistic Large Model for Intelligent and Explainable Skin Disease Auxiliary Diagnosis](https://arxiv.org/abs/2508.06624)
*Kexin Yu,Zihan Xu,Jialei Xie,Carter Adams*

Main category: cs.CV

TL;DR: VL-MedGuide利用视觉语言大模型，通过多模态感知和可解释推理，实现智能且透明的皮肤病辅助诊断，性能优越且解释值得信赖。


<details>
  <summary>Details</summary>
Motivation: 为了解决皮肤病诊断中视觉特征复杂多样以及现有纯视觉模型缺乏可解释性的挑战，提出VL-MedGuide框架。

Method: VL-MedGuide框架包含两个阶段：1.多模态概念感知模块，通过精密的提示工程识别并描述皮肤镜图像中的相关视觉特征；2.可解释疾病推理模块，利用思维链提示将这些概念与原始视觉信息结合，提供精确的疾病诊断和透明的理由。

Result: VL-MedGuide在Derm7pt数据集上实现了最先进的性能，疾病诊断准确率（BACC 83.55%，F1 80.12%）和概念检测准确率（BACC 76.10%，F1 67.45%）均超越了现有基线。人类评估也证实了其生成解释的高度清晰性、完整性和可信度。

Conclusion: VL-MedGuide通过多模态概念感知和可解释疾病推理，在皮肤病辅助诊断方面取得了最先进的性能，并提供了清晰、完整和可信的解释，弥合了AI性能与临床效用之间的差距。

Abstract: Accurate diagnosis of skin diseases remains a significant challenge due to
the complex and diverse visual features present in dermatoscopic images, often
compounded by a lack of interpretability in existing purely visual diagnostic
models. To address these limitations, this study introduces VL-MedGuide
(Visual-Linguistic Medical Guide), a novel framework leveraging the powerful
multi-modal understanding and reasoning capabilities of Visual-Language Large
Models (LVLMs) for intelligent and inherently interpretable auxiliary diagnosis
of skin conditions. VL-MedGuide operates in two interconnected stages: a
Multi-modal Concept Perception Module, which identifies and linguistically
describes dermatologically relevant visual features through sophisticated
prompt engineering, and an Explainable Disease Reasoning Module, which
integrates these concepts with raw visual information via Chain-of-Thought
prompting to provide precise disease diagnoses alongside transparent
rationales. Comprehensive experiments on the Derm7pt dataset demonstrate that
VL-MedGuide achieves state-of-the-art performance in both disease diagnosis
(83.55% BACC, 80.12% F1) and concept detection (76.10% BACC, 67.45% F1),
surpassing existing baselines. Furthermore, human evaluations confirm the high
clarity, completeness, and trustworthiness of its generated explanations,
bridging the gap between AI performance and clinical utility by offering
actionable, explainable insights for dermatological practice.

</details>


### [32] [CycleDiff: Cycle Diffusion Models for Unpaired Image-to-image Translation](https://arxiv.org/abs/2508.06625)
*Shilong Zou,Yuhang Huang,Renjiao Yi,Chenyang Zhu,Kai Xu*

Main category: cs.CV

TL;DR: 该研究提出了一种新的基于扩散模型的跨域图像翻译方法，通过联合学习框架解决了扩散过程和翻译过程之间的对齐问题，实现了更好的翻译性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有基于扩散模型的方法在扩散过程和翻译过程之间对齐不精确的问题，该研究提出了一种联合学习框架来改进全局最优性，从而提高跨域翻译的性能。

Method: 提出了一种新颖的联合学习框架，通过在扩散模型中提取图像组件来表示清晰信号，并使用图像组件进行翻译过程，从而实现了端到端的联合学习。此外，引入了时变翻译网络来学习复杂的翻译映射。

Result: 所提出的方法实现了两个过程的全局优化，提高了保真度和结构一致性，并在各种跨模态翻译任务上取得了优于最先进方法的生成性能。

Conclusion: 通过联合学习框架，该方法能够实现两个过程的全局优化，从而提高最优性并获得更好的保真度和结构一致性。在RGB$\	owards$RGB和RGB$\	owards$Edge，RGB$\	owards$Semantics，RGB$\	owards$Depth等多种跨模态翻译任务上进行了广泛的实验，展示了比现有技术更好的生成性能。

Abstract: We introduce a diffusion-based cross-domain image translator in the absence
of paired training data. Unlike GAN-based methods, our approach integrates
diffusion models to learn the image translation process, allowing for more
coverable modeling of the data distribution and performance improvement of the
cross-domain translation. However, incorporating the translation process within
the diffusion process is still challenging since the two processes are not
aligned exactly, i.e., the diffusion process is applied to the noisy signal
while the translation process is conducted on the clean signal. As a result,
recent diffusion-based studies employ separate training or shallow integration
to learn the two processes, yet this may cause the local minimal of the
translation optimization, constraining the effectiveness of diffusion models.
To address the problem, we propose a novel joint learning framework that aligns
the diffusion and the translation process, thereby improving the global
optimality. Specifically, we propose to extract the image components with
diffusion models to represent the clean signal and employ the translation
process with the image components, enabling an end-to-end joint learning
manner. On the other hand, we introduce a time-dependent translation network to
learn the complex translation mapping, resulting in effective translation
learning and significant performance improvement. Benefiting from the design of
joint learning, our method enables global optimization of both processes,
enhancing the optimality and achieving improved fidelity and structural
consistency. We have conducted extensive experiments on RGB$\leftrightarrow$RGB
and diverse cross-modality translation tasks including
RGB$\leftrightarrow$Edge, RGB$\leftrightarrow$Semantics and
RGB$\leftrightarrow$Depth, showcasing better generative performances than the
state of the arts.

</details>


### [33] [CoDe-NeRF: Neural Rendering via Dynamic Coefficient Decomposition](https://arxiv.org/abs/2508.06632)
*Wenpeng Xing,Jie Chen,Zaifeng Yang,Tiancheng Zhao,Gaolei Li,Changting Lin,Yike Guo,Meng Han*

Main category: cs.CV

TL;DR: 提出了一种新颖的神经渲染框架，通过动态系数分解来更好地处理复杂的镜面反射和高光。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有 NeRF 方法在渲染具有复杂镜面反射和高光场景时存在的反射模糊或优化不稳定的问题。

Method: 提出了一种基于动态系数分解的神经渲染框架，将复杂外观分解为编码内在材料特性的共享静态神经基础，以及由条件于视图和光照的系数网络生成的动态系数集。然后，动态辐射积分器将这些组件组合起来以合成最终的辐射。

Result: 实验结果表明，与现有技术相比，该方法能够产生更清晰、更逼真的镜面高光。

Conclusion: 该方法通过动态系数分解，有望为神经场景表示中的复杂外观建模提供灵活有效的方向。

Abstract: Neural Radiance Fields (NeRF) have shown impressive performance in novel view
synthesis, but challenges remain in rendering scenes with complex specular
reflections and highlights. Existing approaches may produce blurry reflections
due to entanglement between lighting and material properties, or encounter
optimization instability when relying on physically-based inverse rendering. In
this work, we present a neural rendering framework based on dynamic coefficient
decomposition, aiming to improve the modeling of view-dependent appearance. Our
approach decomposes complex appearance into a shared, static neural basis that
encodes intrinsic material properties, and a set of dynamic coefficients
generated by a Coefficient Network conditioned on view and illumination. A
Dynamic Radiance Integrator then combines these components to synthesize the
final radiance. Experimental results on several challenging benchmarks suggest
that our method can produce sharper and more realistic specular highlights
compared to existing techniques. We hope that this decomposition paradigm can
provide a flexible and effective direction for modeling complex appearance in
neural scene representations.

</details>


### [34] [Rethinking Key-frame-based Micro-expression Recognition: A Robust and Accurate Framework Against Key-frame Errors](https://arxiv.org/abs/2508.06640)
*Zheyuan Zhang,Weihao Tang,Hong Chen*

Main category: cs.CV

TL;DR: CausalNet通过处理整个微表情序列并利用CMPLM和CAB模块，解决了关键帧索引错误的问题，提高了微表情识别的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在获得准确的关键帧索引方面存在困难，并且忽略了关键帧索引错误对微表情识别性能的影响，这阻碍了其在实际应用中的推广。

Method: 提出了一种名为CausalNet的新框架，该框架将整个微表情序列作为输入，并通过因果运动位置学习模块（CMPLM）和因果注意力块（CAB）来提高鲁棒性和识别精度。

Result: CausalNet在不同程度的关键帧索引噪声下实现了鲁棒的微表情识别，并在多个标准数据集上超越了现有技术水平。

Conclusion: CausalNet在存在关键帧索引错误的情况下实现了鲁棒的微表情识别，并且在标准数据集上超越了现有技术水平。

Abstract: Micro-expression recognition (MER) is a highly challenging task in affective
computing. With the reduced-sized micro-expression (ME) input that contains key
information based on key-frame indexes, key-frame-based methods have
significantly improved the performance of MER. However, most of these methods
focus on improving the performance with relatively accurate key-frame indexes,
while ignoring the difficulty of obtaining accurate key-frame indexes and the
objective existence of key-frame index errors, which impedes them from moving
towards practical applications. In this paper, we propose CausalNet, a novel
framework to achieve robust MER facing key-frame index errors while maintaining
accurate recognition. To enhance robustness, CausalNet takes the representation
of the entire ME sequence as the input. To address the information redundancy
brought by the complete ME range input and maintain accurate recognition,
first, the Causal Motion Position Learning Module (CMPLM) is proposed to help
the model locate the muscle movement areas related to Action Units (AUs),
thereby reducing the attention to other redundant areas. Second, the Causal
Attention Block (CAB) is proposed to deeply learn the causal relationships
between the muscle contraction and relaxation movements in MEs. Empirical
experiments have demonstrated that on popular ME benchmarks, the CausalNet has
achieved robust MER under different levels of key-frame index noise. Meanwhile,
it has surpassed state-of-the-art (SOTA) methods on several standard MER
benchmarks when using the provided annotated key-frames. Code is available at
https://github.com/tony19980810/CausalNet.

</details>


### [35] [SLRTP2025 Sign Language Production Challenge: Methodology, Results, and Future Work](https://arxiv.org/abs/2508.06951)
*Harry Walsh,Ed Fish,Ozge Mercanoglu Sincan,Mohamed Ilyes Lakhal,Richard Bowden,Neil Fox,Bencie Woll,Kepeng Wu,Zecheng Li,Weichao Zhao,Haodong Wang,Wengang Zhou,Houqiang Li,Shengeng Tang,Jiayi He,Xu Wang,Ruobei Zhang,Yaxiong Wang,Lechao Cheng,Meryem Tasyurek,Tugce Kiziltepe,Hacer Yalim Keles*

Main category: cs.CV

TL;DR: 首个手语生成挑战赛成功举办，旨在解决缺乏标准化评估指标的问题。挑战赛的获胜方法采用了检索和预训练语言模型，并发布了标准化的评估工具，以促进未来的研究和比较。


<details>
  <summary>Details</summary>
Motivation: 手语生成（SLP）领域缺乏标准化的评估指标，阻碍了不同系统间的有意义比较。

Method: 通过举办手语生成挑战赛，使用RWTH-PHOENIX-Weather-2014T数据集和自定义的隐藏测试集，评估将口语翻译成骨骼姿态序列（Text-to-Pose）的模型。评估指标包括BLEU-1和DTW-MJE。

Result: 挑战赛有33个团队参与，提交了231个解决方案。获胜团队取得了BLEU-1得分为31.40，DTW-MJE为0.0574。发布了包含关键点提取的标准化评估网络。

Conclusion: 该论文介绍了首个手语生成挑战赛，旨在通过引入标准化的评估指标来促进该领域的比较研究。挑战赛吸引了大量参与者，并展示了基于检索和预训练语言模型的获胜方法。同时，发布了一个标准化的评估网络，为未来研究提供了统一的基线。

Abstract: Sign Language Production (SLP) is the task of generating sign language video
from spoken language inputs. The field has seen a range of innovations over the
last few years, with the introduction of deep learning-based approaches
providing significant improvements in the realism and naturalness of generated
outputs. However, the lack of standardized evaluation metrics for SLP
approaches hampers meaningful comparisons across different systems. To address
this, we introduce the first Sign Language Production Challenge, held as part
of the third SLRTP Workshop at CVPR 2025. The competition's aims are to
evaluate architectures that translate from spoken language sentences to a
sequence of skeleton poses, known as Text-to-Pose (T2P) translation, over a
range of metrics. For our evaluation data, we use the
RWTH-PHOENIX-Weather-2014T dataset, a German Sign Language - Deutsche
Gebardensprache (DGS) weather broadcast dataset. In addition, we curate a
custom hidden test set from a similar domain of discourse. This paper presents
the challenge design and the winning methodologies. The challenge attracted 33
participants who submitted 231 solutions, with the top-performing team
achieving BLEU-1 scores of 31.40 and DTW-MJE of 0.0574. The winning approach
utilized a retrieval-based framework and a pre-trained language model. As part
of the workshop, we release a standardized evaluation network, including
high-quality skeleton extraction-based keypoints establishing a consistent
baseline for the SLP field, which will enable future researchers to compare
their work against a broader range of methods.

</details>


### [36] [Towards Robust Red-Green Watermarking for Autoregressive Image Generators](https://arxiv.org/abs/2508.06656)
*Denis Lukovnikov,Andreas Müller,Erwin Quiring,Asja Fischer*

Main category: cs.CV

TL;DR: This paper explores watermarking for AR image models, proposing cluster-level schemes that improve robustness and detectability against perturbations and regeneration attacks, with fast verification.


<details>
  <summary>Details</summary>
Motivation: The paper aims to explore the use of in-generation watermarks in autoregressive (AR) image models, which has not been previously investigated. The motivation stems from the high robustness demonstrated by in-generation watermarks in latent diffusion models (LDMs), seeking to adapt and improve watermarking techniques for AR image generation.

Method: The paper examines token-level watermarking schemes for autoregressive (AR) image models by biasing the next-token prediction based on prior tokens. It proposes two novel watermarking methods: a training-free approach using a cluster lookup table, and a method that finetunes VAE encoders to predict token clusters directly from perturbed images. These methods utilize visual token clustering to assign similar tokens to the same set.

Result: Experiments show that the proposed cluster-level watermarks improve robustness against perturbations and regeneration attacks while preserving image quality. Cluster classification enhances watermark detectability, outperforming existing baselines. The methods also provide fast verification runtime, comparable to lightweight post-hoc watermarking methods.

Conclusion: Cluster-level watermarks improve robustness against perturbations and regeneration attacks while preserving image quality. Cluster classification further boosts watermark detectability, outperforming a set of baselines. Moreover, our methods offer fast verification runtime, comparable to lightweight post-hoc watermarking methods.

Abstract: In-generation watermarking for detecting and attributing generated content
has recently been explored for latent diffusion models (LDMs), demonstrating
high robustness. However, the use of in-generation watermarks in autoregressive
(AR) image models has not been explored yet. AR models generate images by
autoregressively predicting a sequence of visual tokens that are then decoded
into pixels using a vector-quantized decoder. Inspired by red-green watermarks
for large language models, we examine token-level watermarking schemes that
bias the next-token prediction based on prior tokens. We find that a direct
transfer of these schemes works in principle, but the detectability of the
watermarks decreases considerably under common image perturbations. As a
remedy, we propose two novel watermarking methods that rely on visual token
clustering to assign similar tokens to the same set. Firstly, we investigate a
training-free approach that relies on a cluster lookup table, and secondly, we
finetune VAE encoders to predict token clusters directly from perturbed images.
Overall, our experiments show that cluster-level watermarks improve robustness
against perturbations and regeneration attacks while preserving image quality.
Cluster classification further boosts watermark detectability, outperforming a
set of baselines. Moreover, our methods offer fast verification runtime,
comparable to lightweight post-hoc watermarking methods.

</details>


### [37] [Learning More by Seeing Less: Line Drawing Pretraining for Efficient, Transferable, and Human-Aligned Vision](https://arxiv.org/abs/2508.06696)
*Tianqin Li,George Liu,Tai Sing Lee*

Main category: cs.CV

TL;DR: 本研究提出使用线描画作为视觉表征的预训练模式，以提高模型的泛化能力、效率和可压缩性，并成功将其应用于无监督学习。


<details>
  <summary>Details</summary>
Motivation: 尽管计算机视觉取得了显著进展，但现代识别系统仍然受限于对丰富、冗余视觉输入的依赖。然而，人类能够轻松理解稀疏、极简的表征，如线描画，这表明结构而非外观是实现高效视觉理解的基础。因此，本研究旨在探索线描画作为一种有效的预训练模式。

Method: 本研究提出使用线描画作为一种结构优先的预训练模式，以诱导更紧凑和更具泛化能力的视觉表征。此外，还提出了一种名为“学习画画”的方法，将线描画预训练扩展到无监督设置。

Result: 在线描画上进行预训练的模型在分类、检测和分割任务中表现出更强的形状偏置、更集中的注意力和更高的数据效率。这些模型具有更低的内在维度，并且其表征更易于压缩，从而能够更好地蒸馏到轻量级学生模型中。与从颜色监督教师模型中蒸馏出来的学生模型相比，从线描画预训练教师模型中蒸馏出来的学生模型表现更优。

Conclusion: 与传统的依赖丰富视觉输入的模型相比，基于线描画进行预训练的模型在识别、检测和分割任务中表现出更强的泛化能力、更集中的注意力和更高的数据效率。此外，这些模型具有更低的内在维度，并且其表征更易于压缩，这使得它们能够更好地迁移到轻量级模型中。线描画预训练还可以扩展到无监督学习设置。总之，这项研究表明，以结构为先的视觉学习能够提高效率、泛化能力，并引入与人类相似的归纳偏置，为构建更鲁棒、更适应性强的视觉系统提供了一种简单而有效的方法。

Abstract: Despite remarkable progress in computer vision, modern recognition systems
remain limited by their dependence on rich, redundant visual inputs. In
contrast, humans can effortlessly understand sparse, minimal representations
like line drawings - suggesting that structure, rather than appearance,
underlies efficient visual understanding. In this work, we propose using line
drawings as a structure-first pretraining modality to induce more compact and
generalizable visual representations. We show that models pretrained on line
drawings develop stronger shape bias, more focused attention, and greater data
efficiency across classification, detection, and segmentation tasks. Notably,
these models also exhibit lower intrinsic dimensionality, requiring
significantly fewer principal components to capture representational variance -
echoing the similar observation in low dimensional efficient representation in
the brain. Beyond performance improvements, line drawing pretraining produces
more compressible representations, enabling better distillation into
lightweight student models. Students distilled from line-pretrained teachers
consistently outperform those trained from color-supervised teachers,
highlighting the benefits of structurally compact knowledge. Finally, we
demonstrate that the pretraining with line-drawing can also be extended to
unsupervised setting via our proposed method "learning to draw". Together, our
results support the view that structure-first visual learning fosters
efficiency, generalization, and human-aligned inductive biases - offering a
simple yet powerful strategy for building more robust and adaptable vision
systems.

</details>


### [38] [MMFformer: Multimodal Fusion Transformer Network for Depression Detection](https://arxiv.org/abs/2508.06701)
*Md Rezwanul Haque,Md. Milon Islam,S M Taslim Uddin Raju,Hamdi Altaheri,Lobna Nassar,Fakhri Karray*

Main category: cs.CV

TL;DR: MMFformer是一种创新的多模态深度学习模型，通过融合视频和音频信息，显著提高了社交媒体内容抑郁症检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 抑郁症是一种严重的心理健康疾病，早期检测对其治疗至关重要，但由于其主要基于临床访谈中的主观评估，因此检测过程非常困难。利用社交媒体内容进行早期抑郁症诊断已成为一个重要的研究领域，但用户生成信息的广泛性和多样性给准确提取相关时间信息和跨模态数据融合带来了挑战。

Method: MMFformer是一种多模态抑郁检测网络，它利用Transformer网络捕获视频的空间特征，并利用Transformer编码器提取音频中的重要时间动态。该融合架构通过后期和中间融合策略融合提取的特征，以找出它们之间最相关的模态间相关性。

Result: MMFformer在D-Vlog数据集和LMVD数据集上都取得了优于现有最先进方法的性能。

Conclusion: MMFformer在两个大规模抑郁检测数据集上均超越了现有的最先进方法，D-Vlog数据集F1-Score提高了13.92%，LMVD数据集提高了7.74%。

Abstract: Depression is a serious mental health illness that significantly affects an
individual's well-being and quality of life, making early detection crucial for
adequate care and treatment. Detecting depression is often difficult, as it is
based primarily on subjective evaluations during clinical interviews. Hence,
the early diagnosis of depression, thanks to the content of social networks,
has become a prominent research area. The extensive and diverse nature of
user-generated information poses a significant challenge, limiting the accurate
extraction of relevant temporal information and the effective fusion of data
across multiple modalities. This paper introduces MMFformer, a multimodal
depression detection network designed to retrieve depressive spatio-temporal
high-level patterns from multimodal social media information. The transformer
network with residual connections captures spatial features from videos, and a
transformer encoder is exploited to design important temporal dynamics in
audio. Moreover, the fusion architecture fused the extracted features through
late and intermediate fusion strategies to find out the most relevant
intermodal correlations among them. Finally, the proposed network is assessed
on two large-scale depression detection datasets, and the results clearly
reveal that it surpasses existing state-of-the-art approaches, improving the
F1-Score by 13.92% for D-Vlog dataset and 7.74% for LMVD dataset. The code is
made available publicly at
https://github.com/rezwanh001/Large-Scale-Multimodal-Depression-Detection.

</details>


### [39] [Fourier Optics and Deep Learning Methods for Fast 3D Reconstruction in Digital Holography](https://arxiv.org/abs/2508.06703)
*Justin London*

Main category: cs.CV

TL;DR: 一种用于CGH合成的快速框架，使用点云和MRI数据，通过傅立叶光学优化算法生成全息图，并使用2D中值滤波提高性能。


<details>
  <summary>Details</summary>
Motivation: 为了提高计算机生成全息图（CGH）的效率和速度，提出了一种新的框架。

Method: 该框架利用初始点云和MRI数据，将输入数据重建为体积对象，然后输入到非凸傅立叶光学优化算法中，使用交替投影、SGD和拟牛顿法来生成仅相位 홀로그램（POH）和复数홀로그램（CH）。

Result: 对使用交替投影、SGD和拟牛顿法生成的POH和CH的重建性能进行了分析，并与HoloNet深度学习CGH进行了比较。

Conclusion: 通过使用2D中值滤波去除优化过程中的伪影和散斑噪声，可以提高性能指标。

Abstract: Computer-generated holography (CGH) is a promising method that modulates
user-defined waveforms with digital holograms. An efficient and fast pipeline
framework is proposed to synthesize CGH using initial point cloud and MRI data.
This input data is reconstructed into volumetric objects that are then input
into non-convex Fourier optics optimization algorithms for phase-only hologram
(POH) and complex-hologram (CH) generation using alternating projection, SGD,
and quasi-Netwton methods. Comparison of reconstruction performance of these
algorithms as measured by MSE, RMSE, and PSNR is analyzed as well as to HoloNet
deep learning CGH. Performance metrics are shown to be improved by using 2D
median filtering to remove artifacts and speckled noise during optimization.

</details>


### [40] [Restage4D: Reanimating Deformable 3D Reconstruction from a Single Video](https://arxiv.org/abs/2508.06715)
*Jixuan He,Chieh Hubert Lin,Lu Qi,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: Restage4D is a pipeline for generating physically consistent 4D content by leveraging real-world video motion priors to reanimate deformable 3D scenes. It uses a video-rewinding strategy and other mechanisms to improve consistency and correct errors from generative models.


<details>
  <summary>Details</summary>
Motivation: Generating physically consistent 4D content by leveraging the motion priors of real-world videos. The goal is to reanimate deformable 3D scenes from a single video, using the original sequence as a supervisory signal to correct artifacts from synthetic motion.

Method: Restage4D uses a video-rewinding training strategy to temporally bridge a real base video and a synthetic driving video via a shared motion representation. It also incorporates an occlusion-aware rigidity loss and a disocclusion backtracing mechanism to improve structural and geometry consistency under challenging motion.

Result: Restage4D demonstrates improved geometry consistency, motion quality, and 3D tracking performance on DAVIS and PointOdyssey datasets.

Conclusion: Restage4D not only preserves deformable structure under novel motion but also automatically corrects errors introduced by generative models, revealing the potential of video prior in 4D restaging task. Source code and trained models will be released.

Abstract: Creating deformable 3D content has gained increasing attention with the rise
of text-to-image and image-to-video generative models. While these models
provide rich semantic priors for appearance, they struggle to capture the
physical realism and motion dynamics needed for authentic 4D scene synthesis.
In contrast, real-world videos can provide physically grounded geometry and
articulation cues that are difficult to hallucinate. One question is raised:
\textit{Can we generate physically consistent 4D content by leveraging the
motion priors of the real-world video}? In this work, we explore the task of
reanimating deformable 3D scenes from a single video, using the original
sequence as a supervisory signal to correct artifacts from synthetic motion. We
introduce \textbf{Restage4D}, a geometry-preserving pipeline for
video-conditioned 4D restaging. Our approach uses a video-rewinding training
strategy to temporally bridge a real base video and a synthetic driving video
via a shared motion representation. We further incorporate an occlusion-aware
rigidity loss and a disocclusion backtracing mechanism to improve structural
and geometry consistency under challenging motion. We validate Restage4D on
DAVIS and PointOdyssey, demonstrating improved geometry consistency, motion
quality, and 3D tracking performance. Our method not only preserves deformable
structure under novel motion, but also automatically corrects errors introduced
by generative models, revealing the potential of video prior in 4D restaging
task. Source code and trained models will be released.

</details>


### [41] [FoundBioNet: A Foundation-Based Model for IDH Genotyping of Glioma from Multi-Parametric MRI](https://arxiv.org/abs/2508.06756)
*Somayeh Farahani,Marjaneh Hejazi,Antonio Di Ieva,Sidong Liu*

Main category: cs.CV

TL;DR: FoundBioNet利用SWIN-UNETR、TAFE和CMD模块，通过MRI非侵入性地预测IDH突变状态，在多个数据集上表现优于基线方法，提高了诊断准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 准确、非侵入性地检测异柠檬酸脱氢酶（IDH）突变对于有效的胶质瘤管理至关重要。传统的组织采样方法可能无法捕捉肿瘤的空间异质性，而深度学习模型受限于标注数据的稀缺性。相比之下，基础深度学习模型为胶质瘤影像学生物标志物提供了一种更具泛化性的方法。

Method: 提出了一种基于Foundation的生物标志物网络（FoundBioNet），它利用SWIN-UNETR为基础的架构，通过多参数MRI非侵入性地预测IDH突变状态。模型包含两个关键模块：肿瘤感知特征编码（TAFE）用于提取多尺度、肿瘤导向的特征，以及跨模态差异（CMD）用于突出与IDH突变相关的细微T2-FLAIR不匹配信号。

Result: 在EGD、TCGA、Ivy GAP、RHUH和UPenn的独立测试集上，FoundBioNet的AUC分别达到90.58%、88.08%、65.41%和80.31%，持续优于基线方法（p <= 0.05）。消融研究证实，TAFE和CMD模块对于提高预测准确性至关重要。

Conclusion: FoundBioNet能够通过集成大规模预训练和特定任务的微调，实现可泛化的胶质瘤表征，提高诊断准确性和可解释性，并有潜力实现更个性化的患者护理。

Abstract: Accurate, noninvasive detection of isocitrate dehydrogenase (IDH) mutation is
essential for effective glioma management. Traditional methods rely on invasive
tissue sampling, which may fail to capture a tumor's spatial heterogeneity.
While deep learning models have shown promise in molecular profiling, their
performance is often limited by scarce annotated data. In contrast, foundation
deep learning models offer a more generalizable approach for glioma imaging
biomarkers. We propose a Foundation-based Biomarker Network (FoundBioNet) that
utilizes a SWIN-UNETR-based architecture to noninvasively predict IDH mutation
status from multi-parametric MRI. Two key modules are incorporated: Tumor-Aware
Feature Encoding (TAFE) for extracting multi-scale, tumor-focused features, and
Cross-Modality Differential (CMD) for highlighting subtle T2-FLAIR mismatch
signals associated with IDH mutation. The model was trained and validated on a
diverse, multi-center cohort of 1705 glioma patients from six public datasets.
Our model achieved AUCs of 90.58%, 88.08%, 65.41%, and 80.31% on independent
test sets from EGD, TCGA, Ivy GAP, RHUH, and UPenn, consistently outperforming
baseline approaches (p <= 0.05). Ablation studies confirmed that both the TAFE
and CMD modules are essential for improving predictive accuracy. By integrating
large-scale pretraining and task-specific fine-tuning, FoundBioNet enables
generalizable glioma characterization. This approach enhances diagnostic
accuracy and interpretability, with the potential to enable more personalized
patient care.

</details>


### [42] [SafePLUG: Empowering Multimodal LLMs with Pixel-Level Insight and Temporal Grounding for Traffic Accident Understanding](https://arxiv.org/abs/2508.06763)
*Zihao Sheng,Zilin Huang,Yen-Jung Chen,Yansong Qu,Yuhao Luo,Yue Leng,Sikai Chen*

Main category: cs.CV

TL;DR: SafePLUG 是一个新框架，通过像素级理解和时间定位增强 MLLMs 在交通事故分析中的能力，解决了现有模型在细粒度细节处理上的不足，并在多项任务上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有 MLLMs 在交通事故理解领域主要关注图像或视频层面的粗粒度理解，难以处理细粒度的视觉细节或局部场景组件，限制了其在复杂交通事故场景中的应用。

Method: 提出 SafePLUG 框架，结合了像素级理解和时间定位能力，支持任意形状的视觉提示进行区域感知问答、基于语言指令的像素级分割，并能识别交通事故场景中的时间锚定事件。

Result: SafePLUG 在区域问答、像素级分割、时间事件定位和事故事件理解等多个任务上取得了优异的性能。

Conclusion: SafePLUG 通过引入像素级理解和时间定位能力，提升了 MLLMs 在交通事故理解方面的性能，为复杂交通场景的细粒度理解奠定了基础，有望提高驾驶安全和智能交通系统的态势感知能力。

Abstract: Multimodal large language models (MLLMs) have achieved remarkable progress
across a range of vision-language tasks and demonstrate strong potential for
traffic accident understanding. However, existing MLLMs in this domain
primarily focus on coarse-grained image-level or video-level comprehension and
often struggle to handle fine-grained visual details or localized scene
components, limiting their applicability in complex accident scenarios. To
address these limitations, we propose SafePLUG, a novel framework that empowers
MLLMs with both Pixel-Level Understanding and temporal Grounding for
comprehensive traffic accident analysis. SafePLUG supports both
arbitrary-shaped visual prompts for region-aware question answering and
pixel-level segmentation based on language instructions, while also enabling
the recognition of temporally anchored events in traffic accident scenarios. To
advance the development of MLLMs for traffic accident understanding, we curate
a new dataset containing multimodal question-answer pairs centered on diverse
accident scenarios, with detailed pixel-level annotations and temporal event
boundaries. Experimental results show that SafePLUG achieves strong performance
on multiple tasks, including region-based question answering, pixel-level
segmentation, temporal event localization, and accident event understanding.
These capabilities lay a foundation for fine-grained understanding of complex
traffic scenes, with the potential to improve driving safety and enhance
situational awareness in smart transportation systems. The code, dataset, and
model checkpoints will be made publicly available at:
https://zihaosheng.github.io/SafePLUG

</details>


### [43] [Edge Detection for Organ Boundaries via Top Down Refinement and SubPixel Upsampling](https://arxiv.org/abs/2508.06805)
*Aarav Mehta,Priya Deshmukh,Vikram Singh,Siddharth Malhotra,Krishnan Menon Iyer,Tanvi Iyer*

Main category: cs.CV

TL;DR: 深度卷积网络在医学图像中定位不精确。我们提出了一种新颖的从顶到底的后向细化架构，通过融合高级语义特征和低级线索来生成高分辨率、定位良好的器官边界。该方法在CT和MRI数据集上进行了评估，并在边界定位、器官分割和图像配准方面取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 深度卷积网络（ConvNets）虽然在自然图像的通用边缘检测方面取得了接近人类的性能，但其输出往往缺乏精确的定位，而这一缺陷在需要毫米级精度的医学应用中尤其有害。

Method: 提出了一种面向医学的清晰边界检测方法，该方法采用了一种新颖的从顶到底的后向细化架构来适应医学图像（2D和体积）。该方法通过后向细化通路，逐步上采样并融合了高级语义特征和细粒度的低级线索，生成了高分辨率、定位良好的器官边界。为处理各向异性体积，该方法结合了2D切片式细化和轻量级3D上下文聚合，以保持计算效率。

Result: 该方法生成了临床上有价值的、清晰的器官边界，显著增强了常见的医学成像任务。

Conclusion: 该方法在CT和MRI器官数据集的评估中，在严格的标准下（边界F度量、豪斯多夫距离）相比基线卷积网络探测器和当代医学边界/轮廓方法，边界定位得到了显著改善。将本方法生成的清晰边界图整合到下游流程中，在器官分割（更高的Dice分数、更低的边界误差）、图像配准和靠近器官界面的病变描绘方面，均取得了持续的提升。所提出的方法生成了临床上有价值的、清晰的器官边界，显著增强了常见的医学成像任务。

Abstract: Accurate localization of organ boundaries is critical in medical imaging for
segmentation, registration, surgical planning, and radiotherapy. While deep
convolutional networks (ConvNets) have advanced general-purpose edge detection
to near-human performance on natural images, their outputs often lack precise
localization, a limitation that is particularly harmful in medical applications
where millimeter-level accuracy is required. Building on a systematic analysis
of ConvNet edge outputs, we propose a medically focused crisp edge detector
that adapts a novel top-down backward refinement architecture to medical images
(2D and volumetric). Our method progressively upsamples and fuses high-level
semantic features with fine-grained low-level cues through a backward
refinement pathway, producing high-resolution, well-localized organ boundaries.
We further extend the design to handle anisotropic volumes by combining 2D
slice-wise refinement with light 3D context aggregation to retain computational
efficiency. Evaluations on several CT and MRI organ datasets demonstrate
substantially improved boundary localization under strict criteria (boundary
F-measure, Hausdorff distance) compared to baseline ConvNet detectors and
contemporary medical edge/contour methods. Importantly, integrating our crisp
edge maps into downstream pipelines yields consistent gains in organ
segmentation (higher Dice scores, lower boundary errors), more accurate image
registration, and improved delineation of lesions near organ interfaces. The
proposed approach produces clinically valuable, crisp organ edges that
materially enhance common medical-imaging tasks.

</details>


### [44] [DualResolution Residual Architecture with Artifact Suppression for Melanocytic Lesion Segmentation](https://arxiv.org/abs/2508.06816)
*Vikram Singh,Kabir Malhotra,Rohan Desai,Ananya Shankaracharya,Priyadarshini Chatterjee,Krishnan Menon Iyer*

Main category: cs.CV

TL;DR: 这篇论文介绍了一种用于皮肤镜图像黑色素瘤分割的新型双分辨率架构，通过结合全分辨率流、多尺度上下文线索、边界感知连接和通道注意力，并采用轻量级伪影抑制和多任务学习策略，显著提高了分割精度和边界准确性，为自动皮肤癌筛查系统提供了实用的解决方案。


<details>
  <summary>Details</summary>
Motivation: 为了实现自动皮肤癌筛查和临床决策支持，需要对皮肤镜图像中的黑色素瘤进行准确分割。与自然场景分割不同，病变描绘需要解决细微的纹理和颜色变化、常见的伪影（如毛发、尺子、气泡）以及精确边界定位的强烈需求，以支持下游诊断。

Method: 提出了一种新颖的、受 ResNet 启发的双分辨率架构，该架构专为黑色素瘤分割而设计。该方法包含一个全分辨率流，用于保留细粒度的边界信息，以及一个互补的池化流，用于聚合多尺度上下文线索以进行稳健的病变识别。这两个流通过边界感知残差连接和通道注意力模块紧密耦合，以将高频边缘信息注入深度特征图并适应皮肤镜外观的颜色和纹理敏感性。此外，还提出了一种轻量级伪影抑制块和一种多任务训练目标，该目标结合了 Dice Tversky 分割损失、显式边界损失和用于特征稳定性的对比正则化器。

Result: 该方法能够生成像素级准确的掩码，无需进行繁重的后处理或复杂的预训练协议。

Conclusion: 该方法在公共皮肤镜数据集上进行了广泛的实验，与标准的编码器-解码器基线相比，显著提高了边界依从性和临床相关分割指标，使其成为自动化黑色素瘤评估系统的实用构建块。

Abstract: Accurate segmentation of melanocytic tumors in dermoscopic images is a
critical step for automated skin cancer screening and clinical decision
support. Unlike natural scene segmentation, lesion delineation must reconcile
subtle texture and color variations, frequent artifacts (hairs, rulers,
bubbles), and a strong need for precise boundary localization to support
downstream diagnosis. In this paper we introduce Our method, a novel ResNet
inspired dual resolution architecture specifically designed for melanocytic
tumor segmentation. Our method maintains a full resolution stream that
preserves fine grained boundary information while a complementary pooled stream
aggregates multi scale contextual cues for robust lesion recognition. The
streams are tightly coupled by boundary aware residual connections that inject
high frequency edge information into deep feature maps, and by a channel
attention module that adapts color and texture sensitivity to dermoscopic
appearance. To further address common imaging artifacts and the limited size of
clinical datasets, we propose a lightweight artifact suppression block and a
multi task training objective that combines a Dice Tversky segmentation loss
with an explicit boundary loss and a contrastive regularizer for feature
stability. The combined design yields pixel accurate masks without requiring
heavy post processing or complex pre training protocols. Extensive experiments
on public dermoscopic benchmarks demonstrate that Our method significantly
improves boundary adherence and clinically relevant segmentation metrics
compared to standard encoder decoder baselines, making it a practical building
block for automated melanoma assessment systems.

</details>


### [45] [VesselRW: Weakly Supervised Subcutaneous Vessel Segmentation via Learned Random Walk Propagation](https://arxiv.org/abs/2508.06819)
*Ayaan Nooruddin Siddiqui,Mahnoor Zaidi,Ayesha Nazneen Shahbaz,Priyadarshini Chatterjee,Krishnan Menon Iyer*

Main category: cs.CV

TL;DR: 本研究提出了一种新颖的弱监督学习方法，使用稀疏的注释（如中心线）来训练血管分割模型。该方法通过随机游走标签传播生成密集的监督信号，并结合不确定性加权损失和拓扑正则化器，在降低注释成本的同时提高了血管分割的准确性和完整性。


<details>
  <summary>Details</summary>
Motivation: 准确地分割临床图像中的皮下血管受到真实标签稀少且昂贵、以及血管在不同患者和模态之间对比度低、噪声大的外观的阻碍。

Method: 本研究提出了一种新颖的弱监督训练框架，利用廉价的稀疏注释（例如，中心线追踪、点标记或短涂鸦）进行皮下血管分割。通过可微分的随机游走标签传播模型将稀疏标签扩展为密集、概率化的监督，该模型的过渡权重结合了图像驱动的血管特征和管状连续性先验。该传播产生了每像素的命中概率以及校准的不确定性估计；这些被纳入不确定性加权的损失中，以避免对模糊区域进行过度拟合。标签传播器与基于CNN的分割预测器联合学习，使系统能够在没有显式边缘监督的情况下发现血管边缘和连续性约束。此外，还引入了一种拓扑感知正则化器，鼓励中心线连通性并惩罚虚假分支。

Result: 在临床皮下成像数据集上的实验表明，本方法在产生更完整的血管图和为下游决策提供更好的校准不确定性方面，始终优于在稀疏标签上的朴素训练和传统的密集伪标签。该方法在保持临床相关血管拓扑的同时，大大降低了注释负担。

Conclusion: 本研究提出了一种新颖的弱监督训练框架，用于皮下血管分割，利用了廉价的稀疏注释（例如，中心线追踪、点标记或短涂鸦）。通过可微分的随机游走标签传播模型将稀疏标签扩展为密集、概率化的监督，该模型的过渡权重结合了图像驱动的血管特征和管状连续性先验。该传播产生了每像素的命中概率以及校准的不确定性估计；这些被纳入不确定性加权的损失中，以避免对模糊区域进行过度拟合。关键的是，标签传播器与基于CNN的分割预测器联合学习，使系统能够在没有显式边缘监督的情况下发现血管边缘和连续性约束。我们进一步引入了一种拓扑感知正则化器，鼓励中心线连通性并惩罚虚假分支，从而提高临床可用性。在临床皮下成像数据集上的实验表明，本方法在产生更完整的血管图和为下游决策提供更好的校准不确定性方面，始终优于在稀疏标签上的朴素训练和传统的密集伪标签。该方法在保持临床相关血管拓扑的同时，大大降低了注释负担。

Abstract: Accurate segmentation of subcutaneous vessels from clinical images is
hampered by scarce, expensive ground truth and by low contrast, noisy
appearance of vessels across patients and modalities. We present a novel weakly
supervised training framework tailored for subcutaneous vessel segmentation
that leverages inexpensive sparse annotations (e.g., centerline traces, dot
markers, or short scribbles). Sparse labels are expanded into dense,
probabilistic supervision via a differentiable random walk label propagation
model whose transition weights incorporate image driven vesselness cues and
tubular continuity priors. The propagation yields per-pixel hitting
probabilities together with calibrated uncertainty estimates; these are
incorporated into an uncertainty weighted loss to avoid over fitting to
ambiguous regions. Crucially, the label-propagator is learned jointly with a
CNN based segmentation predictor, enabling the system to discover vessel edges
and continuity constraints without explicit edge supervision. We further
introduce a topology aware regularizer that encourages centerline connectivity
and penalizes spurious branches, improving clinical usability. In experiments
on clinical subcutaneous imaging datasets, our method consistently outperforms
naive training on sparse labels and conventional dense pseudo-labeling,
producing more complete vascular maps and better calibrated uncertainty for
downstream decision making. The approach substantially reduces annotation
burden while preserving clinically relevant vessel topology.

</details>


### [46] [Low-Rank Expert Merging for Multi-Source Domain Adaptation in Person Re-Identification](https://arxiv.org/abs/2508.06831)
*Taha Mustapha Nehdi,Nairouz Mrabah,Atif Belal,Marco Pedersoli,Eric Granger*

Main category: cs.CV

TL;DR: SAGE-reID 是一种新颖的、计算成本效益高的方法，用于在 person re-identification 中进行无源多源域自适应。它通过训练低秩适配器（LoRA）和门控网络来有效融合来自多个源域的知识，而无需访问源数据，从而在不增加模型大小的情况下提高准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决在新的目标环境中适应 person re-identification（reID）模型所面临的挑战。现有的多源域自适应（MSDA）方法通常需要为每个源域学习特定主干模型或在适应过程中访问源域数据，这会导致训练参数和计算成本显著增加。

Method: SAGE-reID（Source-free Adaptive Gated Experts）是一种经济高效、无源的多源域自适应（MSDA）方法。它首先通过无源UDA训练单独的、特定于源的低秩适配器（LoRA）。接下来，引入一个轻量级的门控网络来动态分配最佳的合并权重，以融合 LoRA 专家，从而实现有效的跨域知识转移。

Result: SAGE-reID 显著减少了内存消耗和过拟合风险，同时实现了有效的跨域知识转移，并在多个基准测试中超越了最先进的方法。

Conclusion: SAGE-reID 在三个具有挑战性的基准测试：Market-1501、DukeMTMC-reID 和 MSMT17 上进行了广泛的实验，结果表明 SAGE-reID 在保持计算效率的同时，其性能优于最先进的方法。

Abstract: Adapting person re-identification (reID) models to new target environments
remains a challenging problem that is typically addressed using unsupervised
domain adaptation (UDA) methods. Recent works show that when labeled data
originates from several distinct sources (e.g., datasets and cameras),
considering each source separately and applying multi-source domain adaptation
(MSDA) typically yields higher accuracy and robustness compared to blending the
sources and performing conventional UDA. However, state-of-the-art MSDA methods
learn domain-specific backbone models or require access to source domain data
during adaptation, resulting in significant growth in training parameters and
computational cost. In this paper, a Source-free Adaptive Gated Experts
(SAGE-reID) method is introduced for person reID. Our SAGE-reID is a
cost-effective, source-free MSDA method that first trains individual
source-specific low-rank adapters (LoRA) through source-free UDA. Next, a
lightweight gating network is introduced and trained to dynamically assign
optimal merging weights for fusion of LoRA experts, enabling effective
cross-domain knowledge transfer. While the number of backbone parameters
remains constant across source domains, LoRA experts scale linearly but remain
negligible in size (<= 2% of the backbone), reducing both the memory
consumption and risk of overfitting. Extensive experiments conducted on three
challenging benchmarks: Market-1501, DukeMTMC-reID, and MSMT17 indicate that
SAGE-reID outperforms state-of-the-art methods while being computationally
efficient.

</details>


### [47] [Hybrid Machine Learning Framework for Predicting Geometric Deviations from 3D Surface Metrology](https://arxiv.org/abs/2508.06845)
*Hamidreza Samadi,Md Manjurul Ahsan,Shivakumar Raman*

Main category: cs.CV

TL;DR: 本研究提出了一种结合3D扫描和混合机器学习（CNN+GBDT）的方法，用于预测精密制造中组件的几何偏差，精度达到0.012毫米，比传统方法提高了73%。


<details>
  <summary>Details</summary>
Motivation: 尽管现代制造业取得了进步，但尤其对于复杂几何形状的组件，保持尺寸精度仍然是一个挑战。

Method: 本研究采用高分辨率3D扫描仪获取237个不同批次生产的组件的多角度表面数据，并经过精确对齐、去噪和合并处理生成3D模型。在此基础上，开发了一个混合机器学习框架，结合了用于特征提取的卷积神经网络和用于预测建模的梯度提升决策树。

Result: 该混合机器学习框架实现了0.012毫米的预测精度（95%置信水平），比传统统计过程控制方法提高了73%，并发现了制造参数与几何偏差之间的隐藏关联。

Conclusion: 该方法通过结合卷积神经网络和梯度提升决策树，在预测几何偏差方面取得了显著成效，准确率达到0.012毫米（95%置信水平），比传统统计过程控制方法提高了73%。此外，该模型还揭示了制造参数与几何偏差之间的隐藏关联，为精密制造业的自动化质量控制、预测性维护和设计优化提供了巨大潜力，并为未来的预测建模研究奠定了坚实基础。

Abstract: This study addresses the challenge of accurately forecasting geometric
deviations in manufactured components using advanced 3D surface analysis.
Despite progress in modern manufacturing, maintaining dimensional precision
remains difficult, particularly for complex geometries. We present a
methodology that employs a high-resolution 3D scanner to acquire multi-angle
surface data from 237 components produced across different batches. The data
were processed through precise alignment, noise reduction, and merging
techniques to generate accurate 3D representations. A hybrid machine learning
framework was developed, combining convolutional neural networks for feature
extraction with gradient-boosted decision trees for predictive modeling. The
proposed system achieved a prediction accuracy of 0.012 mm at a 95% confidence
level, representing a 73% improvement over conventional statistical process
control methods. In addition to improved accuracy, the model revealed hidden
correlations between manufacturing parameters and geometric deviations. This
approach offers significant potential for automated quality control, predictive
maintenance, and design optimization in precision manufacturing, and the
resulting dataset provides a strong foundation for future predictive modeling
research.

</details>


### [48] [AGIC: Attention-Guided Image Captioning to Improve Caption Relevance](https://arxiv.org/abs/2508.06853)
*L. D. M. S. Sai Teja,Ashok Urlana,Pruthwik Mishra*

Main category: cs.CV

TL;DR: AGIC improves image captioning by focusing on salient visual regions and using a hybrid decoding strategy for better fluency and diversity, outperforming existing models with faster inference.


<details>
  <summary>Details</summary>
Motivation: Generating accurate and descriptive captions remains a challenge in image captioning despite significant progress.

Method: The study proposes Attention-Guided Image Captioning (AGIC), which amplifies salient visual regions directly in the feature space to guide caption generation. It also introduces a hybrid decoding strategy that combines deterministic and probabilistic sampling to balance fluency and diversity.

Result: AGIC matches or surpasses several state-of-the-art models while achieving faster inference. It also demonstrates strong performance across multiple evaluation metrics.

Conclusion: AGIC matches or surpasses several state-of-the-art models while achieving faster inference. Moreover, AGIC demonstrates strong performance across multiple evaluation metrics, offering a scalable and interpretable solution for image captioning.

Abstract: Despite significant progress in image captioning, generating accurate and
descriptive captions remains a long-standing challenge. In this study, we
propose Attention-Guided Image Captioning (AGIC), which amplifies salient
visual regions directly in the feature space to guide caption generation. We
further introduce a hybrid decoding strategy that combines deterministic and
probabilistic sampling to balance fluency and diversity. To evaluate AGIC, we
conduct extensive experiments on the Flickr8k and Flickr30k datasets. The
results show that AGIC matches or surpasses several state-of-the-art models
while achieving faster inference. Moreover, AGIC demonstrates strong
performance across multiple evaluation metrics, offering a scalable and
interpretable solution for image captioning.

</details>


### [49] [VSI: Visual Subtitle Integration for Keyframe Selection to enhance Long Video Understanding](https://arxiv.org/abs/2508.06869)
*Jianxiang He,Shaoguang Wang,Weiyu Guo,Meisheng Hong,Jungang Li,Yijie Xu,Ziyang Chen,Hui Xiong*

Main category: cs.CV

TL;DR: 长视频理解因数据量巨大而充满挑战。现有关键帧检索方法因多模态对齐弱和缺乏时间语义信息而效果不佳。本文提出的VSI方法通过整合字幕、时间戳和场景边界，并采用双流搜索机制，显著提高了关键帧检索的准确性和长视频问答任务的性能，达到了SOTA水平。


<details>
  <summary>Details</summary>
Motivation: 现有的关键帧检索方法在处理长视频时，存在文本查询与视觉内容之间多模态对齐较弱以及无法捕捉复杂时间语义信息的问题，影响了精确推理的效率。因此，需要一种新的方法来解决这些挑战。

Method: 提出了一种名为VSI（Visual-Subtitle Integeration）的多模态关键帧搜索方法，该方法整合了字幕、时间戳和场景边界信息。通过视频搜索流和字幕匹配流的双流机制，分别捕捉视频帧的视觉信息和互补的文本信息，并通过两个搜索流的交互来提高关键帧搜索的准确性。

Result: VSI方法在LongVideoBench数据集的文本相关子集上实现了40.00%的关键帧定位准确率，在下游长视频问答任务上达到了68.48%的准确率，分别比竞争基线高出20.35%和15.79%。

Conclusion: VSI方法在LongVideoBench数据集上实现了40.00%的关键帧定位准确率，在下游长视频问答任务上达到了68.48%的准确率，显著优于现有方法。该方法在中长视频问答任务上取得了SOTA（State-of-the-Art）的成就，证明了其鲁棒性和泛化能力。

Abstract: Long video understanding presents a significant challenge to multimodal large
language models (MLLMs) primarily due to the immense data scale. A critical and
widely adopted strategy for making this task computationally tractable is
keyframe retrieval, which seeks to identify a sparse set of video frames that
are most salient to a given textual query. However, the efficacy of this
approach is hindered by weak multimodal alignment between textual queries and
visual content and fails to capture the complex temporal semantic information
required for precise reasoning. To address this, we propose Visual-Subtitle
Integeration(VSI), a multimodal keyframe search method that integrates
subtitles, timestamps, and scene boundaries into a unified multimodal search
process. The proposed method captures the visual information of video frames as
well as the complementary textual information through a dual-stream search
mechanism by Video Search Stream as well as Subtitle Match Stream,
respectively, and improves the keyframe search accuracy through the interaction
of the two search streams. Experimental results show that VSI achieve 40.00%
key frame localization accuracy on the text-relevant subset of LongVideoBench
and 68.48% accuracy on downstream long Video-QA tasks, surpassing competitive
baselines by 20.35% and 15.79%, respectively. Furthermore, on the
LongVideoBench, VSI achieved state-of-the-art(SOTA) in medium-to-long video-QA
tasks, demonstrating the robustness and generalizability of the proposed
multimodal search strategy.

</details>


### [50] [NS-FPN: Improving Infrared Small Target Detection and Segmentation from Noise Suppression Perspective](https://arxiv.org/abs/2508.06878)
*Maoxun Yuan,Duanni Meng,Ziteng Xi,Tianyi Zhao,Shiji Zhao,Yimian Dai,Xingxing Wei*

Main category: cs.CV

TL;DR: 提出了一种新颖的NS-FPN网络，通过低频引导特征纯化和螺旋感知特征采样来抑制噪声并融合目标特征，有效解决了红外小目标检测中的虚警问题，并在公开数据集上取得了优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于CNN的方法虽然在目标感知方面取得了有希望的结果，但它们只关注增强特征表示以抵消噪声的影响，导致虚警问题增加。因此，需要从噪声抑制的角度来提高性能。

Method: 提出了一种新颖的NS-FPN（噪声抑制特征金字塔网络），它将低频引导特征纯化（LFP）模块和螺旋感知特征采样（SFS）模块集成到原始FPN结构中。LFP模块通过纯化高频分量来抑制噪声特征，实现无噪声干扰的特征增强，而SFS模块在特征融合过程中采用螺旋采样来融合目标相关特征。

Result: 在公开的IRSTDS数据集上进行的广泛实验证明，该方法显著减少了虚警，并在IRSTDS任务上取得了优越的性能。

Conclusion: 该NS-FPN方法显著减少了虚警，并在IRSTDS任务上取得了优越的性能。

Abstract: Infrared small target detection and segmentation (IRSTDS) is a critical yet
challenging task in defense and civilian applications, owing to the dim,
shapeless appearance of targets and severe background clutter. Recent CNN-based
methods have achieved promising target perception results, but they only focus
on enhancing feature representation to offset the impact of noise, which
results in the increased false alarms problem. In this paper, through analyzing
the problem from the frequency domain, we pioneer in improving performance from
noise suppression perspective and propose a novel noise-suppression feature
pyramid network (NS-FPN), which integrates a low-frequency guided feature
purification (LFP) module and a spiral-aware feature sampling (SFS) module into
the original FPN structure. The LFP module suppresses the noise features by
purifying high-frequency components to achieve feature enhancement devoid of
noise interference, while the SFS module further adopts spiral sampling to fuse
target-relevant features in feature fusion process. Our NS-FPN is designed to
be lightweight yet effective and can be easily plugged into existing IRSTDS
frameworks. Extensive experiments on the public IRSTDS datasets demonstrate
that our method significantly reduces false alarms and achieves superior
performance on IRSTDS tasks.

</details>


### [51] [BASIC: Boosting Visual Alignment with Intrinsic Refined Embeddings in Multimodal Large Language Models](https://arxiv.org/abs/2508.06895)
*Jianting Tang,Yubo Wang,Haoyu Cao,Linli Xu*

Main category: cs.CV

TL;DR: MLLMs use vision projectors to connect vision encoders and LLMs. The paper proposes BASIC to improve visual embedding alignment by using refined embeddings within the LLM as direct supervision for the projector, optimizing embedding directions and semantic matching. This method enhances MLLM performance.


<details>
  <summary>Details</summary>
Motivation: Current alignment approaches for MLLMs treat visual embeddings as contextual cues and apply auto-regressive supervision to textual outputs, neglecting direct visual supervision. This hinders finer alignment of visual embeddings, which are critical for visual comprehension due to the gap between visual and textual modalities.

Method: BASIC utilizes refined visual embeddings within the LLM as supervision to directly guide the projector in generating initial visual embeddings. Guidance is conducted by optimizing embedding directions (reducing angles between initial and supervisory embeddings) and improving semantic matching (minimizing disparities between logit distributions).

Result: BASIC significantly improves MLLM performance across various benchmarks without additional supervisory models or artificial annotations.

Conclusion: BASIC, a method that utilizes refined visual embeddings within the LLM as supervision to directly guide the projector in generating initial visual embeddings, significantly improves the performance of MLLMs across a wide range of benchmarks, demonstrating the effectiveness of direct visual supervision without additional supervisory models or artificial annotations.

Abstract: Mainstream Multimodal Large Language Models (MLLMs) achieve visual
understanding by using a vision projector to bridge well-pretrained vision
encoders and large language models (LLMs). The inherent gap between visual and
textual modalities makes the embeddings from the vision projector critical for
visual comprehension. However, current alignment approaches treat visual
embeddings as contextual cues and merely apply auto-regressive supervision to
textual outputs, neglecting the necessity of introducing equivalent direct
visual supervision, which hinders the potential finer alignment of visual
embeddings. In this paper, based on our analysis of the refinement process of
visual embeddings in the LLM's shallow layers, we propose BASIC, a method that
utilizes refined visual embeddings within the LLM as supervision to directly
guide the projector in generating initial visual embeddings. Specifically, the
guidance is conducted from two perspectives: (i) optimizing embedding
directions by reducing angles between initial and supervisory embeddings in
semantic space; (ii) improving semantic matching by minimizing disparities
between the logit distributions of both visual embeddings. Without additional
supervisory models or artificial annotations, BASIC significantly improves the
performance of MLLMs across a wide range of benchmarks, demonstrating the
effectiveness of our introduced direct visual supervision.

</details>


### [52] [Advancements in Chinese font generation since deep learning era: A survey](https://arxiv.org/abs/2508.06900)
*Weiran Chen,Guiqian Zhu,Ying Li,Yi Ji,Chunping Liu*

Main category: cs.CV

TL;DR: 本论文全面 survey 了基于深度学习的中文数字生成技术，对多样本和少样本生成方法进行了分类和讨论，并对未来方向进行了展望。


<details>
  <summary>Details</summary>
Motivation: 中文数字生成是字体设计和排版领域的一个重要课题，深度学习算法的发展带来了新的技术，但如何提高生成数字图像的整体质量仍然是一个难题。

Method: 对现有中文数字生成方法进行文献检索、筛选和分析，根据所需参考样本数量将方法分为多样本生成和少样本生成两类，并对代表性方法进行总结和讨论。

Result: 对现有基于深度学习的中文数字生成方法进行了分类和总结，讨论了它们的优缺点，并指出了该领域的挑战和未来发展方向。

Conclusion: 本论文对基于深度学习的中文数字生成方法进行了全面的调查，总结了现有方法，并讨论了挑战和未来方向，旨在为该领域的研究人员提供有价值的启示。

Abstract: Chinese font generation aims to create a new Chinese font library based on
some reference samples. It is a topic of great concern to many font designers
and typographers. Over the past years, with the rapid development of deep
learning algorithms, various new techniques have achieved flourishing and
thriving progress. Nevertheless, how to improve the overall quality of
generated Chinese character images remains a tough issue. In this paper, we
conduct a holistic survey of the recent Chinese font generation approaches
based on deep learning. To be specific, we first illustrate the research
background of the task. Then, we outline our literature selection and analysis
methodology, and review a series of related fundamentals, including classical
deep learning architectures, font representation formats, public datasets, and
frequently-used evaluation metrics. After that, relying on the number of
reference samples required to generate a new font, we categorize the existing
methods into two major groups: many-shot font generation and few-shot font
generation methods. Within each category, representative approaches are
summarized, and their strengths and limitations are also discussed in detail.
Finally, we conclude our paper with the challenges and future directions, with
the expectation to provide some valuable illuminations for the researchers in
this field.

</details>


### [53] [eMotions: A Large-Scale Dataset and Audio-Visual Fusion Network for Emotion Analysis in Short-form Videos](https://arxiv.org/abs/2508.06902)
*Xuecheng Wu,Dingkang Yang,Danlei Huang,Xinyi Yin,Yifan Wang,Jia Zhang,Jiayu Nie,Liangyu Fu,Yang Liu,Junxiao Xue,Hadi Amirpour,Wei Zhou*

Main category: cs.CV

TL;DR: 研究提出了eMotions数据集和AV-CANet模型，用于分析短视频中的情感。AV-CANet通过视听融合和新颖的损失函数，有效解决了短视频情感分析中的挑战。


<details>
  <summary>Details</summary>
Motivation: 短视频（SVs）的兴起带来了新的视频情感分析（VEA）挑战，因为其内容多样性、语义差距以及视听不一致性导致的情感线索复杂化。现有数据集的有限性也促使研究者需要新的数据集。

Method: 提出了一种名为AV-CANet的端到端视听融合网络，该网络利用视频Transformer来捕获语义相关的表示。还引入了局部-全局融合模块来逐步捕获视听特征的相关性，并构建了EP-CE损失来进行全局优化。

Result: 构建了一个名为eMotions的大规模数据集，包含27,996个带全方位注释的视频。提出的AV-CANet在多个数据集上表现出有效性。

Conclusion: AV-CANet在三个eMotions相关数据集和四个公开的VEA数据集上的广泛实验证明了其有效性，并为未来的研究提供了广泛的见解。消融研究也检验了该方法的关键组成部分。

Abstract: Short-form videos (SVs) have become a vital part of our online routine for
acquiring and sharing information. Their multimodal complexity poses new
challenges for video analysis, highlighting the need for video emotion analysis
(VEA) within the community. Given the limited availability of SVs emotion data,
we introduce eMotions, a large-scale dataset consisting of 27,996 videos with
full-scale annotations. To ensure quality and reduce subjective bias, we
emphasize better personnel allocation and propose a multi-stage annotation
procedure. Additionally, we provide the category-balanced and test-oriented
variants through targeted sampling to meet diverse needs. While there have been
significant studies on videos with clear emotional cues (e.g., facial
expressions), analyzing emotions in SVs remains a challenging task. The
challenge arises from the broader content diversity, which introduces more
distinct semantic gaps and complicates the representations learning of
emotion-related features. Furthermore, the prevalence of audio-visual
co-expressions in SVs leads to the local biases and collective information gaps
caused by the inconsistencies in emotional expressions. To tackle this, we
propose AV-CANet, an end-to-end audio-visual fusion network that leverages
video transformer to capture semantically relevant representations. We further
introduce the Local-Global Fusion Module designed to progressively capture the
correlations of audio-visual features. Besides, EP-CE Loss is constructed to
globally steer optimizations with tripolar penalties. Extensive experiments
across three eMotions-related datasets and four public VEA datasets demonstrate
the effectiveness of our proposed AV-CANet, while providing broad insights for
future research. Moreover, we conduct ablation studies to examine the critical
components of our method. Dataset and code will be made available at Github.

</details>


### [54] [A Simple yet Powerful Instance-Aware Prompting Framework for Training-free Camouflaged Object Segmentation](https://arxiv.org/abs/2508.06904)
*Chao Yin,Jide Li,Xiaoqiang Li*

Main category: cs.CV

TL;DR: 该研究提出了一个名为IAPF的无监督框架，用于解决伪装目标分割（COS）的挑战。该框架通过结合MLLM和Grounding DINO来生成更精确的实例级提示，从而克服了现有方法仅能生成语义级提示的局限性，并在多个基准测试中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于训练的COS方法在标注稀疏性增加时性能会迅速下降。为了规避这一限制，研究人员探索了无监督COS方法，利用SAM自动生成视觉提示。然而，这些方法通常只产生语义级视觉提示，导致SAM输出粗略的语义掩码，并且在有效处理多个离散的实例时会失败。

Method: IAPF框架包括三个步骤：1.文本提示生成器，利用任务通用查询提示多模态大型语言模型（MLLM）生成图像特定的前景和背景标签；2.实例掩码生成器，利用Grounding DINO生成精确的实例级边界框提示，并提出单前景多背景提示策略来采样区域约束点提示；3.自一致性实例掩码投票，通过识别跨多个候选实例掩码最一致的掩码来选择最终的COS预测。

Result: IAPF框架被证明在标准的COS基准测试中显著优于现有的最先进的无监督COS方法。

Conclusion: 所提出的IAPF框架通过利用MLLM生成图像特定的前景和背景标签，并结合Grounding DINO生成精确的实例级边界框提示，以及提出的单前景多背景提示策略来采样每个框内的区域约束点提示，使SAM能够产生候选实例掩码，最终通过识别跨多个候选实例掩码最一致的掩码来选择最终的COS预测，显著优于现有的无监督COS方法。

Abstract: Camouflaged Object Segmentation (COS) remains highly challenging due to the
intrinsic visual similarity between target objects and their surroundings.
While training-based COS methods achieve good performance, their performance
degrades rapidly with increased annotation sparsity. To circumvent this
limitation, recent studies have explored training-free COS methods, leveraging
the Segment Anything Model (SAM) by automatically generating visual prompts
from a single task-generic prompt (\textit{e.g.}, "\textit{camouflaged
animal}") uniformly applied across all test images. However, these methods
typically produce only semantic-level visual prompts, causing SAM to output
coarse semantic masks and thus failing to handle scenarios with multiple
discrete camouflaged instances effectively. To address this critical
limitation, we propose a simple yet powerful \textbf{I}nstance-\textbf{A}ware
\textbf{P}rompting \textbf{F}ramework (IAPF), the first training-free COS
pipeline that explicitly converts a task-generic prompt into fine-grained
instance masks. Specifically, the IAPF comprises three steps: (1) Text Prompt
Generator, utilizing task-generic queries to prompt a Multimodal Large Language
Model (MLLM) for generating image-specific foreground and background tags; (2)
\textbf{Instance Mask Generator}, leveraging Grounding DINO to produce precise
instance-level bounding box prompts, alongside the proposed Single-Foreground
Multi-Background Prompting strategy to sample region-constrained point prompts
within each box, enabling SAM to yield a candidate instance mask; (3)
Self-consistency Instance Mask Voting, which selects the final COS prediction
by identifying the candidate mask most consistent across multiple candidate
instance masks. Extensive evaluations on standard COS benchmarks demonstrate
that the proposed IAPF significantly surpasses existing state-of-the-art
training-free COS methods.

</details>


### [55] [MultiRef: Controllable Image Generation with Multiple Visual References](https://arxiv.org/abs/2508.06905)
*Ruoxi Chen,Dongping Chen,Siyuan Wu,Sinan Wang,Shiyun Lang,Petr Sushko,Gaoyang Jiang,Yao Wan,Ranjay Krishna*

Main category: cs.CV

TL;DR: 本研究提出了MultiRef-bench评估框架和MultiRef数据集，用于解决多视觉参考图像生成问题。实验发现现有模型在处理此类任务时表现不佳，为未来研究指明了方向。


<details>
  <summary>Details</summary>
Motivation: 解决当前图像生成框架主要依赖单一输入（文本或单个参考图像）的局限性，探索可控的、利用多个视觉参考的图像生成任务。

Method: 提出了一种名为RefBlend的数据引擎，用于生成包含多种参考类型的合成样本。构建了包含38k高质量图像的MultiRef数据集。在Interleaved Image-Text模型（OmniGen, ACE, Show-o）和agentic框架（ChatDiT, LLM + SD）上进行了实验评估。

Result: 实验表明，即使是先进的模型，在处理多视觉参考条件时也存在困难。最佳模型OmniGen在合成样本上的平均准确率为66.6%，在真实世界样本上的平均准确率为79.0%，与理想答案相比仍有差距。这揭示了在开发能有效整合多视觉灵感源的创意工具方面的挑战和机遇。

Conclusion: 现有模型难以处理多视觉参考的图像生成任务，但本研究提出的MultiRef-bench和MultiRef数据集为该领域的研究提供了重要基础和方向，旨在开发更灵活、更像人类的创意工具。

Abstract: Visual designers naturally draw inspiration from multiple visual references,
combining diverse elements and aesthetic principles to create artwork. However,
current image generative frameworks predominantly rely on single-source inputs
-- either text prompts or individual reference images. In this paper, we focus
on the task of controllable image generation using multiple visual references.
We introduce MultiRef-bench, a rigorous evaluation framework comprising 990
synthetic and 1,000 real-world samples that require incorporating visual
content from multiple reference images. The synthetic samples are synthetically
generated through our data engine RefBlend, with 10 reference types and 33
reference combinations. Based on RefBlend, we further construct a dataset
MultiRef containing 38k high-quality images to facilitate further research. Our
experiments across three interleaved image-text models (i.e., OmniGen, ACE, and
Show-o) and six agentic frameworks (e.g., ChatDiT and LLM + SD) reveal that
even state-of-the-art systems struggle with multi-reference conditioning, with
the best model OmniGen achieving only 66.6% in synthetic samples and 79.0% in
real-world cases on average compared to the golden answer. These findings
provide valuable directions for developing more flexible and human-like
creative tools that can effectively integrate multiple sources of visual
inspiration. The dataset is publicly available at: https://multiref.github.io/.

</details>


### [56] [MMReID-Bench: Unleashing the Power of MLLMs for Effective and Versatile Person Re-identification](https://arxiv.org/abs/2508.06908)
*Jinhao Li,Zijian Chen,Lirong Deng,Changbo Wang,Guangtao Zhai*

Main category: cs.CV

TL;DR: MMReID-Bench是一个多模态行人ReID基准，展示了MLLMs的潜力和局限性，旨在推动更强大的多模态ReID模型发展。


<details>
  <summary>Details</summary>
Motivation: 传统行人ReID模型在多模态数据（如RGB、热成像、红外、素描、文本描述等）上泛化能力不足。虽然多模态大语言模型（MLLMs）展现了潜力，但现有方法未能充分发挥其推理、指令遵循和跨模态理解能力。

Method: MMReID-Bench是一个针对行人重识别（ReID）的多任务多模态基准，包含20,710个多模态查询和图库图像，覆盖10个ReID任务，旨在评估和促进多模态大语言模型（MLLMs）在ReID领域的应用。

Result: 实验证明了MLLMs在行人ReID任务中表现出强大的能力，能够实现有效且通用的ReID。然而，在处理热成像和红外数据等少数模态时，MLLMs仍存在局限性。

Conclusion: MMReID-Bench的出现旨在弥合现有方法在利用多模态大语言模型（MLLMs）进行行人重识别（ReID）方面的差距，该基准包含了20,710个多模态查询和图库图像，涵盖10个不同的ReID任务。实验证明了MLLMs在行人ReID方面的强大能力，但也揭示了它们在处理热成像和红外数据等特定模态时存在的局限性。研究者希望MMReID-Bench能推动社区开发更鲁棒、更具泛化性的多模态基础模型用于行人ReID。

Abstract: Person re-identification (ReID) aims to retrieve the images of an interested
person in the gallery images, with wide applications in medical rehabilitation,
abnormal behavior detection, and public security. However, traditional person
ReID models suffer from uni-modal capability, leading to poor generalization
ability in multi-modal data, such as RGB, thermal, infrared, sketch images,
textual descriptions, etc. Recently, the emergence of multi-modal large
language models (MLLMs) shows a promising avenue for addressing this problem.
Despite this potential, existing methods merely regard MLLMs as feature
extractors or caption generators, which do not fully unleash their reasoning,
instruction-following, and cross-modal understanding capabilities. To bridge
this gap, we introduce MMReID-Bench, the first multi-task multi-modal benchmark
specifically designed for person ReID. The MMReID-Bench includes 20,710
multi-modal queries and gallery images covering 10 different person ReID tasks.
Comprehensive experiments demonstrate the remarkable capabilities of MLLMs in
delivering effective and versatile person ReID. Nevertheless, they also have
limitations in handling a few modalities, particularly thermal and infrared
data. We hope MMReID-Bench can facilitate the community to develop more robust
and generalizable multimodal foundation models for person ReID.

</details>


### [57] [Talk2Image: A Multi-Agent System for Multi-Turn Image Generation and Editing](https://arxiv.org/abs/2508.06916)
*Shichao Ma,Yunhe Guo,Jiahao Su,Qihe Huang,Zhengyang Zhou,Yang Wang*

Main category: cs.CV

TL;DR: Talk2Image is a multi-agent system for interactive image generation and editing that addresses intention drift and incoherent edits in multi-turn dialogues by using specialized agents and feedback-view evaluation for refinement.


<details>
  <summary>Details</summary>
Motivation: Most text-to-image generation tasks focus on single-turn scenarios and struggle with iterative, multi-turn creative tasks. Existing dialogue-based systems suffer from intention drift and incoherent edits due to their single-agent, sequential paradigm.

Method: A multi-agent system integrating intention parsing from dialogue history, task decomposition and collaborative execution across specialized agents, and feedback-driven refinement based on a multi-view evaluation mechanism.

Result: Experiments demonstrate that Talk2Image outperforms existing baselines in controllability, coherence, and user satisfaction across iterative image generation and editing tasks.

Conclusion: Talk2Image enables step-by-step alignment with user intention and consistent image editing, outperforming existing baselines in controllability, coherence, and user satisfaction across iterative image generation and editing tasks.

Abstract: Text-to-image generation tasks have driven remarkable advances in diverse
media applications, yet most focus on single-turn scenarios and struggle with
iterative, multi-turn creative tasks. Recent dialogue-based systems attempt to
bridge this gap, but their single-agent, sequential paradigm often causes
intention drift and incoherent edits. To address these limitations, we present
Talk2Image, a novel multi-agent system for interactive image generation and
editing in multi-turn dialogue scenarios. Our approach integrates three key
components: intention parsing from dialogue history, task decomposition and
collaborative execution across specialized agents, and feedback-driven
refinement based on a multi-view evaluation mechanism. Talk2Image enables
step-by-step alignment with user intention and consistent image editing.
Experiments demonstrate that Talk2Image outperforms existing baselines in
controllability, coherence, and user satisfaction across iterative image
generation and editing tasks.

</details>


### [58] [AR-GRPO: Training Autoregressive Image Generation Models via Reinforcement Learning](https://arxiv.org/abs/2508.06924)
*Shihao Yuan,Yahui Liu,Yang Yue,Jingyuan Zhang,Wangmeng Zuo,Qi Wang,Fuzheng Zhang,Guorui Zhou*

Main category: cs.CV

TL;DR: AR-GRPO 是一种将在线 RL 训练整合到自回归图像生成模型中的方法，通过多维度奖励函数优化图像质量，并在实验中取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 受 RL 在改进 LLMs 方面成功的启发，旨在将 RL 训练整合到 AR 图像生成模型中，以提高图像质量。

Method: 提出 AR-GRPO 方法，将在线强化学习（RL）训练整合到自回归（AR）图像生成模型中，并改编了 GRPO 算法，通过评估生成图像的感知质量、真实感和语义保真度等多个质量维度来优化 AR 模型输出。

Result: 在类别条件和文本条件图像生成任务上进行的大量实验表明，与标准 AR 基线相比，AR-GRPO 框架在生成的图像质量和人类偏好方面均有显著提升，并在各种评估指标上展现出一致的改进。

Conclusion: AR-GRPO 框架通过精心设计的奖励函数，显著提高了图像生成质量和人类偏好，证明了基于 RL 的优化在自回归图像生成中的可行性，并为可控、高质量的图像合成开辟了新途径。

Abstract: Inspired by the success of reinforcement learning (RL) in refining large
language models (LLMs), we propose AR-GRPO, an approach to integrate online RL
training into autoregressive (AR) image generation models. We adapt the Group
Relative Policy Optimization (GRPO) algorithm to refine the vanilla
autoregressive models' outputs by carefully designed reward functions that
evaluate generated images across multiple quality dimensions, including
perceptual quality, realism, and semantic fidelity. We conduct comprehensive
experiments on both class-conditional (i.e., class-to-image) and
text-conditional (i.e., text-to-image) image generation tasks, demonstrating
that our RL-enhanced framework significantly improves both the image quality
and human preference of generated images compared to the standard AR baselines.
Our results show consistent improvements across various evaluation metrics,
establishing the viability of RL-based optimization for AR image generation and
opening new avenues for controllable and high-quality image synthesis. The
source codes and models are available at:
https://github.com/Kwai-Klear/AR-GRPO.

</details>


### [59] [CannyEdit: Selective Canny Control and Dual-Prompt Guidance for Training-Free Image Editing](https://arxiv.org/abs/2508.06937)
*Weiyan Xie,Han Gao,Didan Deng,Kaican Li,April Hua Liu,Yongxiang Huang,Nevin L. Zhang*

Main category: cs.CV

TL;DR: CannyEdit是一个创新的训练无关框架，通过选择性Canny控制和双提示引导，实现了高质量的文本到图像区域编辑，提高了文本依从性、上下文保真度和编辑无缝性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像（T2I）模型在训练无关的区域图像编辑方面存在挑战，难以平衡编辑区域的文本依从性、未编辑区域的上下文保真度以及编辑的无缝集成。

Method: CannyEdit框架采用选择性Canny控制（在用户指定的编辑区域内使用Canny ControlNet进行结构引导，同时保留未编辑区域的源图像细节）和双提示引导（结合局部提示和全局目标提示以保持场景连贯性）。

Result: CannyEdit在真实世界图像编辑任务（添加、替换、移除）中，文本依从性和上下文保真度的平衡比KV-Edit等现有方法提高了2.93%至10.49%。用户研究表明，CannyEdit的编辑结果更难被识别为AI编辑，尤其是在与未编辑的真实图像配对时，普通用户和AIGC专家的识别率分别为49.2%和42.0%，远低于竞争方法（76.08%至89.09%）。

Conclusion: CannyEdit框架通过选择性Canny控制和双提示引导，在文本依从性、上下文保真度和编辑无缝性方面优于现有方法。

Abstract: Recent advances in text-to-image (T2I) models have enabled training-free
regional image editing by leveraging the generative priors of foundation
models. However, existing methods struggle to balance text adherence in edited
regions, context fidelity in unedited areas, and seamless integration of edits.
We introduce CannyEdit, a novel training-free framework that addresses these
challenges through two key innovations: (1) Selective Canny Control, which
masks the structural guidance of Canny ControlNet in user-specified editable
regions while strictly preserving details of the source images in unedited
areas via inversion-phase ControlNet information retention. This enables
precise, text-driven edits without compromising contextual integrity. (2)
Dual-Prompt Guidance, which combines local prompts for object-specific edits
with a global target prompt to maintain coherent scene interactions. On
real-world image editing tasks (addition, replacement, removal), CannyEdit
outperforms prior methods like KV-Edit, achieving a 2.93 to 10.49 percent
improvement in the balance of text adherence and context fidelity. In terms of
editing seamlessness, user studies reveal only 49.2 percent of general users
and 42.0 percent of AIGC experts identified CannyEdit's results as AI-edited
when paired with real images without edits, versus 76.08 to 89.09 percent for
competitor methods.

</details>


### [60] [Beyond Frequency: Seeing Subtle Cues Through the Lens of Spatial Decomposition for Fine-Grained Visual Classification](https://arxiv.org/abs/2508.06959)
*Qin Xu,Lili Zhu,Xiaoxia Cheng,Bo Jiang*

Main category: cs.CV

TL;DR: SCOPE：一种通过动态增强细节和语义来改进细粒度视觉分类的新方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于频域的方法虽然能挖掘出区分性线索，但其固定的基函数缺乏对图像内容的适应性，无法根据不同图像的区分性需求动态调整特征提取。为了解决这个问题，提出 SCOPE 方法来适应性地增强空间域中低级细节和高级语义的表示能力，突破了频域中固定尺度的限制，提高了多尺度融合的灵活性。

Method: 提出了一种名为SCOPE 的新颖方法，包含两个核心模块：细微细节提取器 (SDE) 和显著语义精炼器 (SSR)。SDE 动态增强空间域中的细微细节（如边缘和纹理），SSR 从高层特征中学习语义上连贯且结构感知的精炼特征，并以增强的浅层特征为指导。

Result: SCOP 通过多阶段级联 SDE 和 SSR，有效结合局部细节和全局语义，在四个细粒度图像分类基准上取得了新的最先进成果。

Conclusion: SCOP通过多阶段级联SDE和SSR，有效结合局部细节和全局语义，在四个细粒度图像分类基准上取得了新的最先进成果。

Abstract: The crux of resolving fine-grained visual classification (FGVC) lies in
capturing discriminative and class-specific cues that correspond to subtle
visual characteristics. Recently, frequency decomposition/transform based
approaches have attracted considerable interests since its appearing
discriminative cue mining ability. However, the frequency-domain methods are
based on fixed basis functions, lacking adaptability to image content and
unable to dynamically adjust feature extraction according to the discriminative
requirements of different images. To address this, we propose a novel method
for FGVC, named Subtle-Cue Oriented Perception Engine (SCOPE), which adaptively
enhances the representational capability of low-level details and high-level
semantics in the spatial domain, breaking through the limitations of fixed
scales in the frequency domain and improving the flexibility of multi-scale
fusion. The core of SCOPE lies in two modules: the Subtle Detail Extractor
(SDE), which dynamically enhances subtle details such as edges and textures
from shallow features, and the Salient Semantic Refiner (SSR), which learns
semantically coherent and structure-aware refinement features from the
high-level features guided by the enhanced shallow features. The SDE and SSR
are cascaded stage-by-stage to progressively combine local details with global
semantics. Extensive experiments demonstrate that our method achieves new
state-of-the-art on four popular fine-grained image classification benchmarks.

</details>


### [61] [Adversarial Video Promotion Against Text-to-Video Retrieval](https://arxiv.org/abs/2508.06964)
*Qiwei Tian,Chenhao Lin,Zhengyu Zhao,Qian Li,Shuai Liu,Chao Shen*

Main category: cs.CV

TL;DR: 本研究提出了ViPro攻击，通过提升视频排名来利用T2VR模型的漏洞，并使用MoRe增强了攻击的可迁移性。该攻击在多种设置下均表现优异，揭示了T2VR在推广攻击方面存在被忽视的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有针对文本到视频检索（T2VR）的攻击主要集中于降低视频排名，而忽略了提升视频排名的攻击。此类攻击（例如，为了经济利益或传播错误信息而增加视频曝光度）可能更具影响力。因此，本研究旨在探索并解决这一被忽视的攻击向量。

Method: 提出了一种名为“视频推广攻击”（ViPro）的新型攻击方法，旨在提升视频而非降低视频排名。同时，提出了“模态精炼”（MoRe）方法，通过捕捉视觉和文本模态之间更细粒度的交互来增强黑盒攻击的可迁移性。

Result: ViPro攻击在白盒、灰盒和黑盒设置下平均分别比其他基线方法提高了30%、10%和4%的性能。实验在2个基线、3个领先的T2VR模型、3个流行的数据集（超过10000个视频）以及3种场景下进行了广泛评估，均采用多目标设置以反映真实攻击场景。此外，研究还评估了ViPro的防御和不可感知性。

Conclusion: 该研究开创性地提出了针对视频检索（T2VR）的“视频推广攻击”（ViPro），以提升视频排名，并引入了“模态精炼”（MoRe）方法来增强黑盒攻击的可迁移性。实验证明，ViPro在多种场景和模型下均表现出色，显著优于现有基线方法，揭示了T2VR模型在推广攻击方面存在的潜在脆弱性，并为防御策略提供了参考。

Abstract: Thanks to the development of cross-modal models, text-to-video retrieval
(T2VR) is advancing rapidly, but its robustness remains largely unexamined.
Existing attacks against T2VR are designed to push videos away from queries,
i.e., suppressing the ranks of videos, while the attacks that pull videos
towards selected queries, i.e., promoting the ranks of videos, remain largely
unexplored. These attacks can be more impactful as attackers may gain more
views/clicks for financial benefits and widespread (mis)information. To this
end, we pioneer the first attack against T2VR to promote videos adversarially,
dubbed the Video Promotion attack (ViPro). We further propose Modal Refinement
(MoRe) to capture the finer-grained, intricate interaction between visual and
textual modalities to enhance black-box transferability. Comprehensive
experiments cover 2 existing baselines, 3 leading T2VR models, 3 prevailing
datasets with over 10k videos, evaluated under 3 scenarios. All experiments are
conducted in a multi-target setting to reflect realistic scenarios where
attackers seek to promote the video regarding multiple queries simultaneously.
We also evaluated our attacks for defences and imperceptibility. Overall, ViPro
surpasses other baselines by over $30/10/4\%$ for white/grey/black-box settings
on average. Our work highlights an overlooked vulnerability, provides a
qualitative analysis on the upper/lower bound of our attacks, and offers
insights into potential counterplays. Code will be publicly available at
https://github.com/michaeltian108/ViPro.

</details>


### [62] [WeatherDiffusion: Weather-Guided Diffusion Model for Forward and Inverse Rendering](https://arxiv.org/abs/2508.06982)
*Yixin Zhu,Zuoliang Zhu,Miloš Hašan,Jian Yang,Jin Xie,Beibei Wang*

Main category: cs.CV

TL;DR: WeatherDiffusion是一个创新的框架，利用扩散模型和注意力机制，有效解决了自动驾驶场景中复杂天气和光照带来的渲染挑战，并提升了相关下游任务的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决复杂天气和光照条件对自动驾驶（AD）场景中正向和逆向渲染任务的挑战，以及现有扩散模型难以控制和缺乏鲁棒性的问题。

Method: 提出了一种名为WeatherDiffusion的基于扩散的方法，该方法通过使用预测的本征图并受文本描述的指导，实现了材料属性、场景几何和光照的真实感估计，并支持可控的天气和光照编辑。引入了内在图感知注意力（MAA）机制来提高逆向渲染的质量。

Result: WeatherDiffusion在多个基准测试中表现优于最先进的方法，并在AD的下游任务中展现出显著价值，尤其是在增强恶劣天气条件下物体检测和图像分割的鲁棒性方面。

Conclusion: WeatherDiffusion在具有各种天气和光照条件的AD场景中实现了真实感的可控天气和光照编辑，并在下游任务中增强了物体检测和图像分割的鲁棒性。

Abstract: Forward and inverse rendering have emerged as key techniques for enabling
understanding and reconstruction in the context of autonomous driving (AD).
However, complex weather and illumination pose great challenges to this task.
The emergence of large diffusion models has shown promise in achieving
reasonable results through learning from 2D priors, but these models are
difficult to control and lack robustness. In this paper, we introduce
WeatherDiffusion, a diffusion-based framework for forward and inverse rendering
on AD scenes with various weather and lighting conditions. Our method enables
authentic estimation of material properties, scene geometry, and lighting, and
further supports controllable weather and illumination editing through the use
of predicted intrinsic maps guided by text descriptions. We observe that
different intrinsic maps should correspond to different regions of the original
image. Based on this observation, we propose Intrinsic map-aware attention
(MAA) to enable high-quality inverse rendering. Additionally, we introduce a
synthetic dataset (\ie WeatherSynthetic) and a real-world dataset (\ie
WeatherReal) for forward and inverse rendering on AD scenes with diverse
weather and lighting. Extensive experiments show that our WeatherDiffusion
outperforms state-of-the-art methods on several benchmarks. Moreover, our
method demonstrates significant value in downstream tasks for AD, enhancing the
robustness of object detection and image segmentation in challenging weather
scenarios.

</details>


### [63] [TADoc: Robust Time-Aware Document Image Dewarping](https://arxiv.org/abs/2508.06988)
*Fangmin Zhao,Weichao Zeng,Zhenhang Li,Dongbao Yang,Yu Zhou*

Main category: cs.CV

TL;DR: 提出了一种新颖的文档去扭曲方法TADoc，通过将任务建模为动态过程和引入新的评估指标DLS，提高了处理复杂文档变形的能力。


<details>
  <summary>Details</summary>
Motivation: 随着数字经济和在线工作兴起，处理由便携式拍摄设备捕获的弯曲、起皱和旋转的文档图像（文档图像去扭曲）变得越来越重要。然而，现有方法在面对真实场景中复杂的文档结构和更高程度的变形时，往往难以取得满意的结果。

Method: 提出了一种名为TADoc（Time-Aware Document Dewarping Network）的轻量级框架来解决文档图像的几何失真问题，并将文档去扭曲任务首次建模为一个包含一系列中间状态的动态过程。

Result: 模型在不同文档类型和失真度上均表现出强大的鲁棒性，在多个基准测试中取得了优越的性能。

Conclusion: 该模型在不同文档类型和失真度上均表现出强大的鲁棒性，在多个基准测试中取得了优越的性能。

Abstract: Flattening curved, wrinkled, and rotated document images captured by portable
photographing devices, termed document image dewarping, has become an
increasingly important task with the rise of digital economy and online
working. Although many methods have been proposed recently, they often struggle
to achieve satisfactory results when confronted with intricate document
structures and higher degrees of deformation in real-world scenarios. Our main
insight is that, unlike other document restoration tasks (e.g., deblurring),
dewarping in real physical scenes is a progressive motion rather than a
one-step transformation. Based on this, we have undertaken two key initiatives.
Firstly, we reformulate this task, modeling it for the first time as a dynamic
process that encompasses a series of intermediate states. Secondly, we design a
lightweight framework called TADoc (Time-Aware Document Dewarping Network) to
address the geometric distortion of document images. In addition, due to the
inadequacy of OCR metrics for document images containing sparse text, the
comprehensiveness of evaluation is insufficient. To address this shortcoming,
we propose a new metric -- DLS (Document Layout Similarity) -- to evaluate the
effectiveness of document dewarping in downstream tasks. Extensive experiments
and in-depth evaluations have been conducted and the results indicate that our
model possesses strong robustness, achieving superiority on several benchmarks
with different document types and degrees of distortion.

</details>


### [64] [OctreeNCA: Single-Pass 184 MP Segmentation on Consumer Hardware](https://arxiv.org/abs/2508.06993)
*Nick Lemke,John Kalkhof,Niklas Babendererde,Anirban Mukhopadhyay*

Main category: cs.CV

TL;DR: OctreeNCA通过八叉树和CUDA优化，在医学图像和视频分割中实现了低显存占用和高效率。


<details>
  <summary>Details</summary>
Motivation: 解决了医学应用中分割大型输入（如前列腺MRI、病理切片或手术视频）时，GPU显存消耗成为瓶颈的问题，以及现有UNet或Vision Transformer等模型在处理这些数据时牺牲全局一致性和推理速度的缺点。

Method: 提出了一种名为OctreeNCA的轻量级神经细胞自动机模型，通过八叉树数据结构扩展了邻域定义，并使用CUDA实现了优化的推理函数。

Result: OctreeNCA在分割高分辨率图像和视频时速度快，显存占用比UNet低90%，能够一次性分割184兆像素的病理切片或1分钟的手术视频。

Conclusion: OctreeNCA通过使用八叉树数据结构推广邻域定义，实现了高效的全局知识遍历，解决了现有模型在处理大型医学图像和视频时遇到的显存瓶颈问题。

Abstract: Medical applications demand segmentation of large inputs, like prostate MRIs,
pathology slices, or videos of surgery. These inputs should ideally be inferred
at once to provide the model with proper spatial or temporal context. When
segmenting large inputs, the VRAM consumption of the GPU becomes the
bottleneck. Architectures like UNets or Vision Transformers scale very poorly
in VRAM consumption, resulting in patch- or frame-wise approaches that
compromise global consistency and inference speed. The lightweight Neural
Cellular Automaton (NCA) is a bio-inspired model that is by construction
size-invariant. However, due to its local-only communication rules, it lacks
global knowledge. We propose OctreeNCA by generalizing the neighborhood
definition using an octree data structure. Our generalized neighborhood
definition enables the efficient traversal of global knowledge. Since deep
learning frameworks are mainly developed for large multi-layer networks, their
implementation does not fully leverage the advantages of NCAs. We implement an
NCA inference function in CUDA that further reduces VRAM demands and increases
inference speed. Our OctreeNCA segments high-resolution images and videos
quickly while occupying 90% less VRAM than a UNet during evaluation. This
allows us to segment 184 Megapixel pathology slices or 1-minute surgical videos
at once.

</details>


### [65] [ForeSight: Multi-View Streaming Joint Object Detection and Trajectory Forecasting](https://arxiv.org/abs/2508.07089)
*Sandro Papais,Letian Wang,Brian Cheong,Steven L. Waslander*

Main category: cs.CV

TL;DR: ForeSight是一个创新的视觉基础3D感知框架，用于自动驾驶汽车的联合检测和预测。它通过多任务流和双向学习方法，实现了检测和预测的无缝信息传播，无需显式对象关联，从而提高了效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统方法将检测和预测视为独立任务，未能充分利用时间线索。ForeSight旨在通过联合框架解决此局限性。

Method: ForeSight采用多任务流和双向学习方法，实现了检测和预测的联合。其特点包括共享查询记忆、无跟踪模型以及用于空间推理和时间一致性的预测感知检测Transformer和流式预测Transformer。

Result: ForeSight实现了最先进的性能，EPA达到54.9%，比先前方法提高了9.3%，并且在多视图检测和预测模型中取得了最佳的mAP和minADE。

Conclusion: ForeSight在nuScenes数据集上实现了最先进的性能，EPA达到54.9%，比先前的方法提高了9.3%，同时在多视图检测和预测模型中取得了最佳的mAP和minADE。

Abstract: We introduce ForeSight, a novel joint detection and forecasting framework for
vision-based 3D perception in autonomous vehicles. Traditional approaches treat
detection and forecasting as separate sequential tasks, limiting their ability
to leverage temporal cues. ForeSight addresses this limitation with a
multi-task streaming and bidirectional learning approach, allowing detection
and forecasting to share query memory and propagate information seamlessly. The
forecast-aware detection transformer enhances spatial reasoning by integrating
trajectory predictions from a multiple hypothesis forecast memory queue, while
the streaming forecast transformer improves temporal consistency using past
forecasts and refined detections. Unlike tracking-based methods, ForeSight
eliminates the need for explicit object association, reducing error propagation
with a tracking-free model that efficiently scales across multi-frame
sequences. Experiments on the nuScenes dataset show that ForeSight achieves
state-of-the-art performance, achieving an EPA of 54.9%, surpassing previous
methods by 9.3%, while also attaining the best mAP and minADE among multi-view
detection and forecasting models.

</details>


### [66] [S2-UniSeg: Fast Universal Agglomerative Pooling for Scalable Segment Anything without Supervision](https://arxiv.org/abs/2508.06995)
*Huihui Xu,Jin Ye,Hongqiu Wang,Changkai Ji,Jiashi Lin,Ming Hu,Ziyan Huang,Ying Chen,Chenglong Ma,Tianbin Li,Lihao Liu,Junjun He,Lei Zhu*

Main category: cs.CV

TL;DR: S2-UniSeg通过UniAP（快速伪掩码生成）和QuerySD（自监督预训练）实现了可扩展的自监督分割，性能优于UnSAM，并在COCO、UVO、COCOStuff-27和Cityscapes上取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督图像分割模型虽然性能优异，但其预训练流程多阶段且耗时，涉及复杂的伪掩码生成过程，难以扩展且优化不连续，导致次优解。作者希望解决这些问题，提高预训练效率和分割性能。

Method: 本文提出了一种名为Fast Universal Agglomerative Pooling（UniAP）的新型伪掩码算法，能够并行地识别相似节点组，并在几毫秒内生成语义级、实例级和多粒度的伪掩码。在此基础上，提出了可扩展的自监督通用分割（S2-UniSeg）框架，采用了student-teacher模式以及查询感知的自蒸馏（QuerySD）的预训练任务，以学习局部到全局的对应关系。

Result: S2-UniSeg在COCO数据集上AP提升6.9%，在UVO数据集上AR提升11.1%，在COCOStuff-27数据集上PixelAcc提升4.5%，在Cityscapes数据集上RQ提升8.0%，优于SOTA模型UnSAM。将模型扩展到SA-1B的2M图像子集后，在所有四个基准测试上性能均有进一步提升。

Conclusion: S2-UniSeg通过UniAP和QuerySD，实现了可扩展的自监督通用分割，并在多个基准测试中取得了显著的性能提升，优于SOTA模型UnSAM。

Abstract: Recent self-supervised image segmentation models have achieved promising
performance on semantic segmentation and class-agnostic instance segmentation.
However, their pretraining schedule is multi-stage, requiring a time-consuming
pseudo-masks generation process between each training epoch. This
time-consuming offline process not only makes it difficult to scale with
training dataset size, but also leads to sub-optimal solutions due to its
discontinuous optimization routine. To solve these, we first present a novel
pseudo-mask algorithm, Fast Universal Agglomerative Pooling (UniAP). Each layer
of UniAP can identify groups of similar nodes in parallel, allowing to generate
both semantic-level and instance-level and multi-granular pseudo-masks within
ens of milliseconds for one image. Based on the fast UniAP, we propose the
Scalable Self-Supervised Universal Segmentation (S2-UniSeg), which employs a
student and a momentum teacher for continuous pretraining. A novel
segmentation-oriented pretext task, Query-wise Self-Distillation (QuerySD), is
proposed to pretrain S2-UniSeg to learn the local-to-global correspondences.
Under the same setting, S2-UniSeg outperforms the SOTA UnSAM model, achieving
notable improvements of AP+6.9 on COCO, AR+11.1 on UVO, PixelAcc+4.5 on
COCOStuff-27, RQ+8.0 on Cityscapes. After scaling up to a larger 2M-image
subset of SA-1B, S2-UniSeg further achieves performance gains on all four
benchmarks. Our code and pretrained models are available at
https://github.com/bio-mlhui/S2-UniSeg

</details>


### [67] [AR-VRM: Imitating Human Motions for Visual Robot Manipulation with Analogical Reasoning](https://arxiv.org/abs/2508.07626)
*Dejie Yang,Zijing Zhao,Yang Liu*

Main category: cs.CV

TL;DR: 一种名为AR-VRM的新方法，通过学习人类动作的关键点并进行类比推理，提高了机器人操纵在数据稀缺情况下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操纵方法依赖昂贵的机器人多模态数据，并使用隐式方法（如像素级预测）进行预训练，导致泛化能力有限。该研究旨在通过利用大规模人类动作视频数据集并显式学习人类动作来解决数据不足的问题。

Method: 提出了一种名为AR-VRM的视觉机器人操纵方法，该方法利用关键点视觉语言模型（VLM）预训练方案来明确学习人类动作知识并预测手部关键点。在机器人数据微调阶段，该方法检索相似的人类动作视频，并学习人类手部关键点与机器人部件之间的类比推理（AR）映射，以模仿人类运动模式。

Result: AR-VRM在CALVIN基准测试和真实世界实验中取得了领先的性能，尤其是在少样本场景下，其性能明显优于先前的方法，证明了在数据稀疏情况下显式模仿人类动作的有效性。

Conclusion: AR-VRM通过显式模仿人类动作（例如，通过手部关键点）并利用类比推理（AR）来学习机器人操纵任务，在数据稀疏的情况下表现出色，显著优于现有方法。

Abstract: Visual Robot Manipulation (VRM) aims to enable a robot to follow natural
language instructions based on robot states and visual observations, and
therefore requires costly multi-modal data. To compensate for the deficiency of
robot data, existing approaches have employed vision-language pretraining with
large-scale data. However, they either utilize web data that differs from
robotic tasks, or train the model in an implicit way (e.g., predicting future
frames at the pixel level), thus showing limited generalization ability under
insufficient robot data. In this paper, we propose to learn from large-scale
human action video datasets in an explicit way (i.e., imitating human actions
from hand keypoints), introducing Visual Robot Manipulation with Analogical
Reasoning (AR-VRM). To acquire action knowledge explicitly from human action
videos, we propose a keypoint Vision-Language Model (VLM) pretraining scheme,
enabling the VLM to learn human action knowledge and directly predict human
hand keypoints. During fine-tuning on robot data, to facilitate the robotic arm
in imitating the action patterns of human motions, we first retrieve human
action videos that perform similar manipulation tasks and have similar
historical observations , and then learn the Analogical Reasoning (AR) map
between human hand keypoints and robot components. Taking advantage of focusing
on action keypoints instead of irrelevant visual cues, our method achieves
leading performance on the CALVIN benchmark {and real-world experiments}. In
few-shot scenarios, our AR-VRM outperforms previous methods by large margins ,
underscoring the effectiveness of explicitly imitating human actions under data
scarcity.

</details>


### [68] [TerraMAE: Learning Spatial-Spectral Representations from Hyperspectral Earth Observation Data via Adaptive Masked Autoencoders](https://arxiv.org/abs/2508.07020)
*Tanjim Bin Faruk,Abdul Matin,Shrideep Pallickara,Sangmi Lee Pallickara*

Main category: cs.CV

TL;DR: TerraMAE是一种新的高光谱图像编码框架，通过创新的方法（通道分组和重建损失）有效学习光谱-空间表征，并在下游任务中取得优异成果。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督掩码自动编码器在处理高光谱图像（具有200多个波段）时，难以充分利用其复杂的光谱-空间相关性。

Method: TerraMAE框架采用自适应通道分组策略（基于统计反射特性以捕捉光谱相似性）和包含空间与光谱质量度量的增强重建损失函数。

Result: TerraMAE在高质量图像重建中展现了优越的光谱-空间信息保持能力。

Conclusion: TerraMAE在三个关键的下游地理空间任务（作物识别、土地覆盖分类和土壤质地预测）中表现出色，证明了其学习到的表征的实用性和质量。

Abstract: Hyperspectral satellite imagery offers sub-30 m views of Earth in hundreds of
contiguous spectral bands, enabling fine-grained mapping of soils, crops, and
land cover. While self-supervised Masked Autoencoders excel on RGB and low-band
multispectral data, they struggle to exploit the intricate spatial-spectral
correlations in 200+ band hyperspectral images. We introduce TerraMAE, a novel
HSI encoding framework specifically designed to learn highly representative
spatial-spectral embeddings for diverse geospatial analyses. TerraMAE features
an adaptive channel grouping strategy, based on statistical reflectance
properties to capture spectral similarities, and an enhanced reconstruction
loss function that incorporates spatial and spectral quality metrics. We
demonstrate TerraMAE's effectiveness through superior spatial-spectral
information preservation in high-fidelity image reconstruction. Furthermore, we
validate its practical utility and the quality of its learned representations
through strong performance on three key downstream geospatial tasks: crop
identification, land cover classification, and soil texture prediction.

</details>


### [69] [Multi-view Normal and Distance Guidance Gaussian Splatting for Surface Reconstruction](https://arxiv.org/abs/2508.07701)
*Bo Jia,Yanan Guo,Ying Chang,Benkui Zhang,Ying Xie,Kangning Du,Lin Cao*

Main category: cs.CV

TL;DR: 提出多视图法线和距离引导的高斯泼溅方法，通过约束深度图和对齐法线解决多视图匹配问题，提升重建精度。


<details>
  <summary>Details</summary>
Motivation: 为了解决多视图场景中的距离和全局匹配挑战，以及3D高斯泼溅方法在法线对齐时可能出现的视图偏差问题。

Method: 提出了一种多视图法线和距离引导的高斯泼溅方法，包括一个多视图距离重投影正则化模块，通过计算两个近邻视图与同一高斯表面之间的距离损失来实现多视图高斯对齐；以及一个多视图法线增强模块，通过匹配近邻视图中像素点的法线并计算损失来确保视图间的一致性。

Result: 该方法在定量和定性评估中均优于基线方法，显著增强了3DGS的表面重建能力，特别是在小型室内和室外场景的重建方面。

Conclusion: 该方法通过约束近邻深度图和对齐3D法线，实现了几何深度统一和高精度重建，并在定量和定性评估中优于基线方法，显著增强了3DGS的表面重建能力。

Abstract: 3D Gaussian Splatting (3DGS) achieves remarkable results in the field of
surface reconstruction. However, when Gaussian normal vectors are aligned
within the single-view projection plane, while the geometry appears reasonable
in the current view, biases may emerge upon switching to nearby views. To
address the distance and global matching challenges in multi-view scenes, we
design multi-view normal and distance-guided Gaussian splatting. This method
achieves geometric depth unification and high-accuracy reconstruction by
constraining nearby depth maps and aligning 3D normals. Specifically, for the
reconstruction of small indoor and outdoor scenes, we propose a multi-view
distance reprojection regularization module that achieves multi-view Gaussian
alignment by computing the distance loss between two nearby views and the same
Gaussian surface. Additionally, we develop a multi-view normal enhancement
module, which ensures consistency across views by matching the normals of pixel
points in nearby views and calculating the loss. Extensive experimental results
demonstrate that our method outperforms the baseline in both quantitative and
qualitative evaluations, significantly enhancing the surface reconstruction
capability of 3DGS.

</details>


### [70] [DocRefine: An Intelligent Framework for Scientific Document Understanding and Content Optimization based on Multimodal Large Model Agents](https://arxiv.org/abs/2508.07021)
*Kun Qian,Wenjie Li,Tianyu Sun,Wenhong Wang,Wenhan Luo*

Main category: cs.CV

TL;DR: DocRefine是一个创新的框架，通过多代理系统和LVLM，能够根据自然语言指令智能理解、优化和摘要科学PDF文档，并在各项指标上超越现有技术。


<details>
  <summary>Details</summary>
Motivation: 科学文献的指数级增长需要更高级的工具来高效准确地进行文档理解、摘要和内容优化，而传统方法和直接的LLM/LVLM应用在处理复杂布局和多模态内容方面存在不足。

Method: DocRefine利用先进的视觉语言大模型（LVLMs）和包括布局与结构分析、多模态内容理解、指令分解、内容提炼、摘要与生成以及保真度与一致性验证在内的六个专业协作代理，构建了一个闭环反馈架构，以确保高语义准确性和视觉保真度。

Result: 在DocEditBench数据集上的评估显示，DocRefine在语义一致性分数（SCS）、布局保真度指数（LFI）和指令遵循率（IAR）方面分别达到86.7%、93.9%和85.0%，持续优于最先进的基线。

Conclusion: DocRefine在处理复杂的模态文档编辑、保持语义完整性和视觉一致性方面表现出色，标志着自动化科学文档处理的重大进展。

Abstract: The exponential growth of scientific literature in PDF format necessitates
advanced tools for efficient and accurate document understanding,
summarization, and content optimization. Traditional methods fall short in
handling complex layouts and multimodal content, while direct application of
Large Language Models (LLMs) and Vision-Language Large Models (LVLMs) lacks
precision and control for intricate editing tasks. This paper introduces
DocRefine, an innovative framework designed for intelligent understanding,
content refinement, and automated summarization of scientific PDF documents,
driven by natural language instructions. DocRefine leverages the power of
advanced LVLMs (e.g., GPT-4o) by orchestrating a sophisticated multi-agent
system comprising six specialized and collaborative agents: Layout & Structure
Analysis, Multimodal Content Understanding, Instruction Decomposition, Content
Refinement, Summarization & Generation, and Fidelity & Consistency
Verification. This closed-loop feedback architecture ensures high semantic
accuracy and visual fidelity. Evaluated on the comprehensive DocEditBench
dataset, DocRefine consistently outperforms state-of-the-art baselines across
various tasks, achieving overall scores of 86.7% for Semantic Consistency Score
(SCS), 93.9% for Layout Fidelity Index (LFI), and 85.0% for Instruction
Adherence Rate (IAR). These results demonstrate DocRefine's superior capability
in handling complex multimodal document editing, preserving semantic integrity,
and maintaining visual consistency, marking a significant advancement in
automated scientific document processing.

</details>


### [71] [MV-CoRe: Multimodal Visual-Conceptual Reasoning for Complex Visual Question Answering](https://arxiv.org/abs/2508.07023)
*Jingwei Peng,Jiehao Chen,Mateo Alejandro Rojas,Meilin Zhang*

Main category: cs.CV

TL;DR: MV-CoRe enhances Complex VQA by deeply fusing diverse visual and linguistic information, outperforming existing LVLMs with its novel Multimodal Fusion Transformer and integration of fine-grained features.


<details>
  <summary>Details</summary>
Motivation: Complex VQA tasks, which demand sophisticated multi-modal reasoning and external knowledge integration, present significant challenges for existing LVLMs often limited by their reliance on high-level global features.

Method: MV-CoRe meticulously integrates global embeddings from pre-trained VLMs and LLMs with fine-grained semantic-aware visual features, including object detection characteristics and scene graph representations. An innovative Multimodal Fusion Transformer then processes and deeply integrates these diverse feature sets, enabling rich cross-modal attention and facilitating complex reasoning.

Result: MV-CoRe consistently outperforms established LVLM baselines, achieving an overall accuracy of 77.5% on GQA. Ablation studies confirm the critical contribution of both object and scene graph features, and human evaluations further validate MV-CoRe's superior factual correctness and reasoning depth.

Conclusion: MV-CoRe consistently outperforms established LVLM baselines, achieving an overall accuracy of 77.5% on GQA. Ablation studies confirm the critical contribution of both object and scene graph features, and human evaluations further validate MV-CoRe's superior factual correctness and reasoning depth, underscoring its robust capabilities for deep visual and conceptual understanding.

Abstract: Complex Visual Question Answering (Complex VQA) tasks, which demand
sophisticated multi-modal reasoning and external knowledge integration, present
significant challenges for existing large vision-language models (LVLMs) often
limited by their reliance on high-level global features. To address this, we
propose MV-CoRe (Multimodal Visual-Conceptual Reasoning), a novel model
designed to enhance Complex VQA performance through the deep fusion of diverse
visual and linguistic information. MV-CoRe meticulously integrates global
embeddings from pre-trained Vision Large Models (VLMs) and Language Large
Models (LLMs) with fine-grained semantic-aware visual features, including
object detection characteristics and scene graph representations. An innovative
Multimodal Fusion Transformer then processes and deeply integrates these
diverse feature sets, enabling rich cross-modal attention and facilitating
complex reasoning. We evaluate MV-CoRe on challenging Complex VQA benchmarks,
including GQA, A-OKVQA, and OKVQA, after training on VQAv2. Our experimental
results demonstrate that MV-CoRe consistently outperforms established LVLM
baselines, achieving an overall accuracy of 77.5% on GQA. Ablation studies
confirm the critical contribution of both object and scene graph features, and
human evaluations further validate MV-CoRe's superior factual correctness and
reasoning depth, underscoring its robust capabilities for deep visual and
conceptual understanding.

</details>


### [72] [Large Language Model Evaluated Stand-alone Attention-Assisted Graph Neural Network with Spatial and Structural Information Interaction for Precise Endoscopic Image Segmentation](https://arxiv.org/abs/2508.07028)
*Juntong Fan,Shuyi Fan,Debesh Jha,Changsheng Fang,Tieyong Zeng,Hengyong Yu,Dayang Wang*

Main category: cs.CV

TL;DR: FOCUS-Med通过结合图卷积网络和自注意力机制，并利用LLM进行评估，在内窥镜息肉分割任务上取得了最先进的成果，有助于早期结直肠癌检测。


<details>
  <summary>Details</summary>
Motivation: 为了解决内窥镜图像分割中因对比度低、镜面反射高光和边界模糊等问题导致的结直肠息肉早期检测的挑战。

Method: FOCUS-Med集成了一个双图卷积网络（Dual-GCN）模块来捕捉上下文空间和拓扑结构依赖性，并采用位置融合的独立自注意力机制来加强全局上下文集成。此外，还引入了一个可训练的加权快速归一化融合策略来实现有效的多尺度聚合。值得注意的是，该研究首次使用大型语言模型（LLM）对分割质量进行详细的定性评估。

Result: FOCUS-Med通过利用拓扑线索和空间连通性，更好地将息肉与背景组织区分开来，从而提高了保留边界和描绘息肉复杂形状的能力，并在五个关键指标上实现了最先进的性能。

Conclusion: FOCUS-Med在公共基准测试中取得了最先进的性能，在五个关键指标上均表现出色，证明了其在AI辅助结肠镜检查中的有效性和临床潜力。

Abstract: Accurate endoscopic image segmentation on the polyps is critical for early
colorectal cancer detection. However, this task remains challenging due to low
contrast with surrounding mucosa, specular highlights, and indistinct
boundaries. To address these challenges, we propose FOCUS-Med, which stands for
Fusion of spatial and structural graph with attentional context-aware polyp
segmentation in endoscopic medical imaging. FOCUS-Med integrates a Dual Graph
Convolutional Network (Dual-GCN) module to capture contextual spatial and
topological structural dependencies. This graph-based representation enables
the model to better distinguish polyps from background tissues by leveraging
topological cues and spatial connectivity, which are often obscured in raw
image intensities. It enhances the model's ability to preserve boundaries and
delineate complex shapes typical of polyps. In addition, a location-fused
stand-alone self-attention is employed to strengthen global context
integration. To bridge the semantic gap between encoder-decoder layers, we
incorporate a trainable weighted fast normalized fusion strategy for efficient
multi-scale aggregation. Notably, we are the first to introduce the use of a
Large Language Model (LLM) to provide detailed qualitative evaluations of
segmentation quality. Extensive experiments on public benchmarks demonstrate
that FOCUS-Med achieves state-of-the-art performance across five key metrics,
underscoring its effectiveness and clinical potential for AI-assisted
colonoscopy.

</details>


### [73] [TeSO: Representing and Compressing 3D Point Cloud Scenes with Textured Surfel Octree](https://arxiv.org/abs/2508.07083)
*Yueyu Hu,Ran Gong,Tingyu Fan,Yao Wang*

Main category: cs.CV

TL;DR: 提出了一种名为 TeSO 的新型 3D 表示方法，它使用纹理表面元八叉树来提高渲染质量和压缩效率，优于现有的点云和 3D 高斯基元方法。


<details>
  <summary>Details</summary>
Motivation: 现有的 3D 表示方法（如点云、网格和 3D 高斯基元）在渲染质量、表面定义和可压缩性方面存在局限性，而高质量的 3D 表示是 3D 远程呈现和 AR/VR 应用的关键技术。

Method: 提出了一种名为 TeSO（Textured Surfel Octree）的新型 3D 表示方法，该方法基于点云，但通过将 3D 场景表示为组织在八叉树上的立方体边界表面元（surfel），并为每个表面元关联一个纹理块，来解决现有方法的局限性。通过在八叉树的粗糙级别用大的表面元近似平滑表面，可以减少表示 3D 场景所需图元的数量，同时通过每个表面元附加的纹理图保留高频纹理细节。此外，还提出了一种利用八叉树结构有效编码几何和纹理的压缩方案。

Result: TeSO 相比现有的基于点云和 3D 高斯基元的基线，在较低的比特率下实现了更高的渲染质量。

Conclusion: TeSO 结合所提出的压缩方案，在较低的比特率下实现了比多个基于点云和 3D 高斯基元的基线更高的渲染质量。

Abstract: 3D visual content streaming is a key technology for emerging 3D telepresence
and AR/VR applications. One fundamental element underlying the technology is a
versatile 3D representation that is capable of producing high-quality renders
and can be efficiently compressed at the same time. Existing 3D representations
like point clouds, meshes and 3D Gaussians each have limitations in terms of
rendering quality, surface definition, and compressibility. In this paper, we
present the Textured Surfel Octree (TeSO), a novel 3D representation that is
built from point clouds but addresses the aforementioned limitations. It
represents a 3D scene as cube-bounded surfels organized on an octree, where
each surfel is further associated with a texture patch. By approximating a
smooth surface with a large surfel at a coarser level of the octree, it reduces
the number of primitives required to represent the 3D scene, and yet retains
the high-frequency texture details through the texture map attached to each
surfel. We further propose a compression scheme to encode the geometry and
texture efficiently, leveraging the octree structure. The proposed textured
surfel octree combined with the compression scheme achieves higher rendering
quality at lower bit-rates compared to multiple point cloud and 3D
Gaussian-based baselines.

</details>


### [74] [Communication-Efficient Multi-Agent 3D Detection via Hybrid Collaboration](https://arxiv.org/abs/2508.07092)
*Yue Hu,Juntong Peng,Yunqiao Yang,Siheng Chen*

Main category: cs.CV

TL;DR: HyComm 是一种通信高效的激光雷达基础协同 3D 检测系统，通过混合通信策略在性能和通信带宽之间取得了良好的平衡。


<details>
  <summary>Details</summary>
Motivation: 为了解决协同 3D 检测中性能与通信带宽之间的固有权衡问题，并提高通信效率。

Method: 提出了一种新颖的混合协作方法，该方法自适应地集成两种通信消息：感知输出和原始观测。通过自适应地选择最关键的消息集，确保了最优的感知信息和适应性。在此基础上，提出了 HyComm 系统，它支持消息的自适应压缩率，并使用标准化的消息数据格式，使其独立于特定的检测模型。

Result: HyComm 在 DAIR-V2X 和 OPV2V 数据集上进行了评估，与现有方法相比，在通信带宽和检测性能方面均取得了更好的结果，通信量减少了 2,006 倍以上，同时在 AP50 指标上优于 Where2comm。

Conclusion: HyComm 系统的通信效率和检测性能在真实世界和模拟数据集上都优于现有方法，并且在 AP50 指标上超越了 Where2comm。

Abstract: Collaborative 3D detection can substantially boost detection performance by
allowing agents to exchange complementary information. It inherently results in
a fundamental trade-off between detection performance and communication
bandwidth. To tackle this bottleneck issue, we propose a novel hybrid
collaboration that adaptively integrates two types of communication messages:
perceptual outputs, which are compact, and raw observations, which offer richer
information. This approach focuses on two key aspects: i) integrating
complementary information from two message types and ii) prioritizing the most
critical data within each type. By adaptively selecting the most critical set
of messages, it ensures optimal perceptual information and adaptability,
effectively meeting the demands of diverse communication scenarios.Building on
this hybrid collaboration, we present \texttt{HyComm}, a
communication-efficient LiDAR-based collaborative 3D detection system.
\texttt{HyComm} boasts two main benefits: i) it facilitates adaptable
compression rates for messages, addressing various communication requirements,
and ii) it uses standardized data formats for messages. This ensures they are
independent of specific detection models, fostering adaptability across
different agent configurations. To evaluate HyComm, we conduct experiments on
both real-world and simulation datasets: DAIR-V2X and OPV2V. HyComm
consistently outperforms previous methods and achieves a superior
performance-bandwidth trade-off regardless of whether agents use the same or
varied detection models. It achieves a lower communication volume of more than
2,006$\times$ and still outperforms Where2comm on DAIR-V2X in terms of AP50.
The related code will be released.

</details>


### [75] [AugLift: Boosting Generalization in Lifting-based 3D Human Pose Estimation](https://arxiv.org/abs/2508.07112)
*Nikolai Warner,Wenjin Zhang,Irfan Essa,Apaar Sadhwani*

Main category: cs.CV

TL;DR: AugLift 是一种简单而有效的方法，通过添加置信度和深度信息来增强 2D 关键点，从而提高 3D 人体姿势估计的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于提升（lifting-based）的 3D 人体姿势估计方法在推广到新数据集和真实世界场景时泛化能力较差。

Method: AugLift 通过在 2D 关键点坐标 $(x, y)$ 中加入关键点检测置信度分数 $c$ 和相应的深度估计 $d$ 来稀疏地丰富输入信息。这些额外的信号是从图像中提取的，使用了现成的、预训练的模型（例如，单目深度估计模型）。

Result: 在四个数据集上的大量实验表明，AugLift 将在未见过的数据集上的跨数据集性能平均提高了 10.1%，同时在分布内性能也提高了 4.0%。这些提升在各种提升架构中是一致的，表明了该方法的鲁棒性。

Conclusion: AugLift 通过稀疏地增强标准输入（2D 关键点坐标）并加入关键点检测置信度分数和相应的深度估计，可以显著提高 3D 人体姿势估计（HPE）的泛化能力，而无需额外的数据收集或传感器。该方法具有模块化和易于集成到现有模型中的优点。

Abstract: Lifting-based methods for 3D Human Pose Estimation (HPE), which predict 3D
poses from detected 2D keypoints, often generalize poorly to new datasets and
real-world settings. To address this, we propose \emph{AugLift}, a simple yet
effective reformulation of the standard lifting pipeline that significantly
improves generalization performance without requiring additional data
collection or sensors. AugLift sparsely enriches the standard input -- the 2D
keypoint coordinates $(x, y)$ -- by augmenting it with a keypoint detection
confidence score $c$ and a corresponding depth estimate $d$. These additional
signals are computed from the image using off-the-shelf, pre-trained models
(e.g., for monocular depth estimation), thereby inheriting their strong
generalization capabilities. Importantly, AugLift serves as a modular add-on
and can be readily integrated into existing lifting architectures.
  Our extensive experiments across four datasets demonstrate that AugLift
boosts cross-dataset performance on unseen datasets by an average of $10.1\%$,
while also improving in-distribution performance by $4.0\%$. These gains are
consistent across various lifting architectures, highlighting the robustness of
our method. Our analysis suggests that these sparse, keypoint-aligned cues
provide robust frame-level context, offering a practical way to significantly
improve the generalization of any lifting-based pose estimation model. Code
will be made publicly available.

</details>


### [76] [Perceptual Evaluation of GANs and Diffusion Models for Generating X-rays](https://arxiv.org/abs/2508.07128)
*Gregory Schuit,Denis Parra,Cecilia Besa*

Main category: cs.CV

TL;DR: 这项研究评估了 GANs 和 DMs 在合成胸部 X 光片以用于 AI 诊断训练方面的表现。结果显示 DMs 生成的图像更逼真，但 GANs 在某些特定条件下可能更准确。研究还指出了区分真实与合成图像的视觉线索，并强调需要进一步改进以确保生成模型能可靠地用于医疗 AI。


<details>
  <summary>Details</summary>
Motivation: 在医学影像领域，生成模型（如 GANs 和 DMs）有潜力解决数据稀缺的问题，特别是在低患病率异常的情况下，这些异常会影响 AI 诊断和分割工具的性能。然而，合成图像的保真度和临床效用仍然存在疑问，因为较低的生成质量可能会削弱模型的泛化能力和可信度。因此，评估这些生成模型在医学影像中的有效性至关重要。

Method: 研究评估了最先进的生成模型（GANs 和 DMs）在合成胸部 X 光片方面的有效性，并以四种异常为条件：Atelectasis (AT)、Lung Opacity (LO)、Pleural Effusion (PE) 和 Enlarged Cardiac Silhouette (ECS)。研究人员使用了一个包含来自 MIMIC-CXR 数据集的真实图像和来自 GANs 和 DMs 的合成图像的基准，并进行了一项有三名不同经验水平的放射科医生参与的读者研究。参与者被要求区分真实图像和合成图像，并评估视觉特征与目标异常之间的一致性。

Result: 研究结果表明，扩散模型（DMs）生成的图像在视觉上更逼真。然而，生成对抗网络（GANs）在处理某些特定条件时，例如 Enlarged Cardiac Silhouette (ECS) 的缺失，可以达到更高的准确性。此外，研究还识别出了放射科医生用来检测合成图像的视觉线索，为理解当前模型在感知方面的不足提供了见解。

Conclusion: 这项研究表明，尽管扩散模型（DMs）在生成更逼真的医学图像方面表现出优势，但生成对抗网络（GANs）在某些特定条件下（例如，不存在 Enlarged Cardiac Silhouette）可以提供更好的准确性。研究还指出了放射科医生用于检测合成图像的视觉线索，揭示了当前模型在感知方面的差距。这些发现强调了 GANs 和 DMs 的互补优势，并指出了进一步优化以确保生成模型能可靠地增强 AI 诊断系统的训练数据集的必要性。

Abstract: Generative image models have achieved remarkable progress in both natural and
medical imaging. In the medical context, these techniques offer a potential
solution to data scarcity-especially for low-prevalence anomalies that impair
the performance of AI-driven diagnostic and segmentation tools. However,
questions remain regarding the fidelity and clinical utility of synthetic
images, since poor generation quality can undermine model generalizability and
trust. In this study, we evaluate the effectiveness of state-of-the-art
generative models-Generative Adversarial Networks (GANs) and Diffusion Models
(DMs)-for synthesizing chest X-rays conditioned on four abnormalities:
Atelectasis (AT), Lung Opacity (LO), Pleural Effusion (PE), and Enlarged
Cardiac Silhouette (ECS). Using a benchmark composed of real images from the
MIMIC-CXR dataset and synthetic images from both GANs and DMs, we conducted a
reader study with three radiologists of varied experience. Participants were
asked to distinguish real from synthetic images and assess the consistency
between visual features and the target abnormality. Our results show that while
DMs generate more visually realistic images overall, GANs can report better
accuracy for specific conditions, such as absence of ECS. We further identify
visual cues radiologists use to detect synthetic images, offering insights into
the perceptual gaps in current models. These findings underscore the
complementary strengths of GANs and DMs and point to the need for further
refinement to ensure generative models can reliably augment training datasets
for AI diagnostic systems.

</details>


### [77] [CMAMRNet: A Contextual Mask-Aware Network Enhancing Mural Restoration Through Comprehensive Mask Guidance](https://arxiv.org/abs/2508.07140)
*Yingtie Lei,Fanghai Yi,Yihang Dong,Weihuang Liu,Xiaofeng Zhang,Zimeng Li,Chi-Man Pun,Xuhang Chen*

Main category: cs.CV

TL;DR: CMAMRNet improves mural restoration by using mask guidance and multi-scale features to better preserve details and structure, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing learning-based methods struggle to maintain consistent mask guidance, leading to insufficient focus on damaged regions and compromised restoration quality in digital mural restoration.

Method: The proposed CMAMRNet utilizes a Contextual Mask-Aware approach with two key components: the Mask-Aware Up/Down-Sampler (MAUDS) for consistent mask sensitivity across resolution scales, and the Co-Feature Aggregator (CFA) for capturing both fine textures and global structures.

Result: Experimental results on benchmark datasets show that CMAMRNet achieves superior performance compared to state-of-the-art methods.

Conclusion: CMAMRNet outperforms state-of-the-art methods in mural restoration, effectively preserving structural integrity and artistic details.

Abstract: Murals, as invaluable cultural artifacts, face continuous deterioration from
environmental factors and human activities. Digital restoration of murals faces
unique challenges due to their complex degradation patterns and the critical
need to preserve artistic authenticity. Existing learning-based methods
struggle with maintaining consistent mask guidance throughout their networks,
leading to insufficient focus on damaged regions and compromised restoration
quality. We propose CMAMRNet, a Contextual Mask-Aware Mural Restoration Network
that addresses these limitations through comprehensive mask guidance and
multi-scale feature extraction. Our framework introduces two key components:
(1) the Mask-Aware Up/Down-Sampler (MAUDS), which ensures consistent mask
sensitivity across resolution scales through dedicated channel-wise feature
selection and mask-guided feature fusion; and (2) the Co-Feature Aggregator
(CFA), operating at both the highest and lowest resolutions to extract
complementary features for capturing fine textures and global structures in
degraded regions. Experimental results on benchmark datasets demonstrate that
CMAMRNet outperforms state-of-the-art methods, effectively preserving both
structural integrity and artistic details in restored murals. The code is
available
at~\href{https://github.com/CXH-Research/CMAMRNet}{https://github.com/CXH-Research/CMAMRNet}.

</details>


### [78] [Dynamic Pattern Alignment Learning for Pretraining Lightweight Human-Centric Vision Models](https://arxiv.org/abs/2508.07144)
*Xuanhan Wang,Huimin Deng,Ke Liu,Jun Wang,Lianli Gao,Jingkuan Song*

Main category: cs.CV

TL;DR: DPAL是一个创新的预训练框架，通过动态模式解码器和多层级对齐目标，使轻量级视觉模型能够从大型模型中学习并获得强大的泛化能力，解决了现有方法的局限性，并在多项实验中取得了优异的成果。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有的大规模人类中心视觉模型（HVMs）对大型神经网络架构的依赖以及预训练数据的访问限制所带来的实际应用局限性，提出DPAL框架。

Method: 提出了一种名为动态模式对齐学习（DPAL）的新型基于蒸馏的预训练框架，该框架能够有效地训练轻量级的人类中心视觉模型（HVMs），使其从大型HVMs中获得强大的泛化能力。该框架包括一个动态模式解码器（D-PaDe），它作为一个动态混合专家（MoE）模型，包含三个专门的专家，用于自适应地提取全局身份模式、局部形状模式和多人物体交互模式。此外，还设计了三个层级的对齐目标，以最小化轻量级HVMs和大型HVMs在全局图像、局部像素和实例关系层面的泛化差距。

Result: DPAL在15个具有挑战性的数据集上进行了广泛的实验，证明了其有效性。特别是，当使用PATH-B作为教师模型时，DPAL-ViT/Ti（5M参数）实现了与PATH-B（84M）和Sapiens-L（307M）等现有大型HVMs相媲美的泛化能力，并且在性能上显著优于Proteus-ViT/Ti（5M）和TinyMiM-ViT/Ti（5M）等先前基于蒸馏的预训练方法。

Conclusion: DPAL框架能够有效地指导轻量级模型学习所有典型的人类视觉模式，并泛化到各种以人为中心的视觉任务。DPAL-ViT/Ti（5M参数）在15个具有挑战性的数据集上取得了与PATH-B（84M）和Sapiens-L（307M）等现有大型HVMs相当的泛化能力，并且显著优于先前的基于蒸馏的预训练方法，如Proteus-ViT/Ti（5M）和TinyMiM-ViT/Ti（5M）。

Abstract: Human-centric vision models (HVMs) have achieved remarkable generalization
due to large-scale pretraining on massive person images. However, their
dependence on large neural architectures and the restricted accessibility of
pretraining data significantly limits their practicality in real-world
applications. To address this limitation, we propose Dynamic Pattern Alignment
Learning (DPAL), a novel distillation-based pretraining framework that
efficiently trains lightweight HVMs to acquire strong generalization from large
HVMs. In particular, human-centric visual perception are highly dependent on
three typical visual patterns, including global identity pattern, local shape
pattern and multi-person interaction pattern. To achieve generalizable
lightweight HVMs, we firstly design a dynamic pattern decoder (D-PaDe), acting
as a dynamic Mixture of Expert (MoE) model. It incorporates three specialized
experts dedicated to adaptively extract typical visual patterns, conditioned on
both input image and pattern queries. And then, we present three levels of
alignment objectives, which aims to minimize generalization gap between
lightweight HVMs and large HVMs at global image level, local pixel level, and
instance relation level. With these two deliberate designs, the DPAL
effectively guides lightweight model to learn all typical human visual patterns
from large HVMs, which can generalize to various human-centric vision tasks.
Extensive experiments conducted on 15 challenging datasets demonstrate the
effectiveness of the DPAL. Remarkably, when employing PATH-B as the teacher,
DPAL-ViT/Ti (5M parameters) achieves surprising generalizability similar to
existing large HVMs such as PATH-B (84M) and Sapiens-L (307M), and outperforms
previous distillation-based pretraining methods including Proteus-ViT/Ti (5M)
and TinyMiM-ViT/Ti (5M) by a large margin.

</details>


### [79] [Intention-Aware Diffusion Model for Pedestrian Trajectory Prediction](https://arxiv.org/abs/2508.07146)
*Yu Liu,Zhijie Liu,Xiao Ren,You-Fu Li,He Kong*

Main category: cs.CV

TL;DR: 该研究提出了一种新的基于扩散的行人轨迹预测方法，通过结合短期和长期运动意图以及改进的扩散过程，提高了预测的准确性和对行人行为的理解。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有基于扩散的方法可能因缺乏显式的行人意图语义建模而导致的误解行为和预测精度下降的问题。

Method: 提出了一种基于扩散的行人轨迹预测框架，该框架结合了短期和长期运动意图。短期意图使用残差极坐标表示进行建模，该表示将方向和幅度分离以捕获细粒度的局部运动模式。长期意图通过可学习的、基于token的终点预测器进行估计，该预测器生成多个具有关联概率的候选目标，从而实现多模态和上下文感知的意图建模。此外，通过引入自适应引导和残差噪声预测器来增强扩散过程，该预测器动态地优化去噪精度。

Result: 所提出的框架在ETH、UCY和SDD基准上进行了评估，并展示了与现有最先进方法相比具有竞争力的结果。

Conclusion: 该框架在ETH、UCY和SDD基准上进行了评估，并取得了与最先进方法相比具有竞争力的结果。

Abstract: Predicting pedestrian motion trajectories is critical for the path planning
and motion control of autonomous vehicles. Recent diffusion-based models have
shown promising results in capturing the inherent stochasticity of pedestrian
behavior for trajectory prediction. However, the absence of explicit semantic
modelling of pedestrian intent in many diffusion-based methods may result in
misinterpreted behaviors and reduced prediction accuracy. To address the above
challenges, we propose a diffusion-based pedestrian trajectory prediction
framework that incorporates both short-term and long-term motion intentions.
Short-term intent is modelled using a residual polar representation, which
decouples direction and magnitude to capture fine-grained local motion
patterns. Long-term intent is estimated through a learnable, token-based
endpoint predictor that generates multiple candidate goals with associated
probabilities, enabling multimodal and context-aware intention modelling.
Furthermore, we enhance the diffusion process by incorporating adaptive
guidance and a residual noise predictor that dynamically refines denoising
accuracy. The proposed framework is evaluated on the widely used ETH, UCY, and
SDD benchmarks, demonstrating competitive results against state-of-the-art
methods.

</details>


### [80] [SketchAnimator: Animate Sketch via Motion Customization of Text-to-Video Diffusion Models](https://arxiv.org/abs/2508.07149)
*Ruolin Yang,Da Li,Honggang Zhang,Yi-Zhe Song*

Main category: cs.CV

TL;DR: SketchAnimator是一个新颖的草图动画模型，它利用LoRA和SDS技术，通过学习草图外观和参考视频中的运动动态，将静态草图转换为具有创意动态的视频。该模型解决了草图动画的复杂性和耗时性问题，尤其在单次动作定制方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 动画化草图是一个耗时的过程，需要专业技能和丰富的经验，这对于业余爱好者来说可能很困难。因此，本文旨在解决草图动画的这一挑战。

Method: 本文提出了一种新颖的草图动画模型SketchAnimator，将草图动画分为三个阶段：外观学习、动作学习和视频先验蒸馏。在阶段1和2中，利用LoRA将草图外观信息和参考视频中的动作动态集成到预训练的T2V模型中。在第三阶段，利用SDS根据获得的运动信息更新每个草图帧中的贝塞尔曲线参数。

Result: 与替代方法相比，SketchAnimator能够生成保留草图原始外观并模仿参考视频动态运动的草图视频。

Conclusion: 该模型能够生成保留原始草图外观并映射参考视频动态运动的草图视频，在单次动作定制的挑战下，能够产生期望的草图视频。

Abstract: Sketching is a uniquely human tool for expressing ideas and creativity. The
animation of sketches infuses life into these static drawings, opening a new
dimension for designers. Animating sketches is a time-consuming process that
demands professional skills and extensive experience, often proving daunting
for amateurs. In this paper, we propose a novel sketch animation model
SketchAnimator, which enables adding creative motion to a given sketch, like "a
jumping car''. Namely, given an input sketch and a reference video, we divide
the sketch animation into three stages: Appearance Learning, Motion Learning
and Video Prior Distillation. In stages 1 and 2, we utilize LoRA to integrate
sketch appearance information and motion dynamics from the reference video into
the pre-trained T2V model. In the third stage, we utilize Score Distillation
Sampling (SDS) to update the parameters of the Bezier curves in each sketch
frame according to the acquired motion information. Consequently, our model
produces a sketch video that not only retains the original appearance of the
sketch but also mirrors the dynamic movements of the reference video. We
compare our method with alternative approaches and demonstrate that it
generates the desired sketch video under the challenge of one-shot motion
customization.

</details>


### [81] [CoopDiff: Anticipating 3D Human-object Interactions via Contact-consistent Decoupled Diffusion](https://arxiv.org/abs/2508.07162)
*Xiaotong Lin,Tianming Liang,Jian-Fang Hu,Kun-Yu Lin,Yulei Kang,Chunwei Tian,Jianhuang Lai,Wei-Shi Zheng*

Main category: cs.CV

TL;DR: CoopDiff是一个新颖的框架，通过解耦人类和物体运动建模并使用接触点进行桥接，提高了3D人类-物体交互预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数方法在捕捉人类和物体运动时，都忽略了它们因物理属性不同而产生的不同运动模式的差异。

Method: 提出了一种新颖的接触一致性解耦扩散框架CoopDiff，该框架采用两个独立的支路来解耦人类和物体运动建模，并以人类-物体接触点作为共享锚点来连接跨支路的运动生成。人类动力学分支旨在预测高度结构化的人类运动，而物体动力学分支则专注于具有刚性平移和旋转的物体运动。通过一系列具有一致性约束的共享接触点连接这两个分支，以实现连贯的人类-物体运动预测。此外，还提出了一个由人类驱动的交互模块来指导物体运动建模，以增强人类-物体一致性和预测的可靠性。

Result: CoopDiff框架在BEHAVE和Human-object Interaction数据集上的实验结果优于现有最先进的方法。

Conclusion: CoopDiff框架在BEHAVE和Human-object Interaction数据集上的实验表明，其性能优于现有最先进的方法。

Abstract: 3D human-object interaction (HOI) anticipation aims to predict the future
motion of humans and their manipulated objects, conditioned on the historical
context. Generally, the articulated humans and rigid objects exhibit different
motion patterns, due to their distinct intrinsic physical properties. However,
this distinction is ignored by most of the existing works, which intend to
capture the dynamics of both humans and objects within a single prediction
model. In this work, we propose a novel contact-consistent decoupled diffusion
framework CoopDiff, which employs two distinct branches to decouple human and
object motion modeling, with the human-object contact points as shared anchors
to bridge the motion generation across branches. The human dynamics branch is
aimed to predict highly structured human motion, while the object dynamics
branch focuses on the object motion with rigid translations and rotations.
These two branches are bridged by a series of shared contact points with
consistency constraint for coherent human-object motion prediction. To further
enhance human-object consistency and prediction reliability, we propose a
human-driven interaction module to guide object motion modeling. Extensive
experiments on the BEHAVE and Human-object Interaction datasets demonstrate
that our CoopDiff outperforms state-of-the-art methods.

</details>


### [82] [Lightweight Multi-Scale Feature Extraction with Fully Connected LMF Layer for Salient Object Detection](https://arxiv.org/abs/2508.07170)
*Yunpeng Shi,Lei Chen,Xiaolu Shen,Yanju Guo*

Main category: cs.CV

TL;DR: 提出LMFNet轻量级网络，通过LMF层有效提取多尺度特征，在显著目标检测任务中以更少参数实现优越性能。


<details>
  <summary>Details</summary>
Motivation: 在计算机视觉领域，多尺度特征提取对于显著目标检测等任务至关重要，但在轻量级网络中实现这一目标面临效率和性能的权衡挑战。

Method: 提出了一种名为LMF层的轻量级多尺度特征提取层，该层采用深度可分离扩张卷积和全连接结构。基于LMF层构建了LMFNet网络。

Result: LMFNet在五个基准数据集上取得了最先进或可比的结果，参数量仅为0.81M，在效率和准确性方面优于多个传统和轻量级模型。

Conclusion: 该研究提出的LMFNet在显著目标检测任务中，通过引入LMF层（一种结合深度可分离扩张卷积和全连接结构的新型轻量级多尺度特征提取层），在显著减少参数量（仅0.81M）的同时，在五个基准数据集上取得了最先进或可比的性能，证明了其在轻量级网络中实现多尺度学习的有效性，并具有更广泛的图像处理应用潜力。

Abstract: In the domain of computer vision, multi-scale feature extraction is vital for
tasks such as salient object detection. However, achieving this capability in
lightweight networks remains challenging due to the trade-off between
efficiency and performance. This paper proposes a novel lightweight multi-scale
feature extraction layer, termed the LMF layer, which employs depthwise
separable dilated convolutions in a fully connected structure. By integrating
multiple LMF layers, we develop LMFNet, a lightweight network tailored for
salient object detection. Our approach significantly reduces the number of
parameters while maintaining competitive performance. Here, we show that LMFNet
achieves state-of-the-art or comparable results on five benchmark datasets with
only 0.81M parameters, outperforming several traditional and lightweight models
in terms of both efficiency and accuracy. Our work not only addresses the
challenge of multi-scale learning in lightweight networks but also demonstrates
the potential for broader applications in image processing tasks. The related
code files are available at https://github.com/Shi-Yun-peng/LMFNet

</details>


### [83] [EventRR: Event Referential Reasoning for Referring Video Object Segmentation](https://arxiv.org/abs/2508.07171)
*Huihui Xu,Jiashi Lin,Haoyu Chen,Junjun He,Lei Zhu*

Main category: cs.CV

TL;DR: EventRR通过将RVOS分解为对象摘要和指代推理两部分，并引入指代事件图（REG）和时间概念-角色推理（TCRR），克服了现有方法忽略指代表达式语义结构和视频特有复杂性的问题，并在多个基准数据集上取得了优于现有RVOS方法的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的RVOS方法将指代表达式视为非结构化序列，忽略了它们对指代推理至关重要的语义结构。此外，与仅关注对象属性和对象间关系的图像指代表达式相比，视频指代表达式还包含事件属性和事件间时间关系。这种复杂性给传统的结构化推理图像方法带来了挑战。

Method: EventRR框架将RVOS分解为对象摘要和指代推理两部分。摘要阶段首先将每个帧摘要为一组瓶颈令牌，然后在视频级摘要步骤中有效地聚合这些令牌，以交换全局跨模态时间上下文。对于推理部分，EventRR将视频指代表达式的语义事件结构提取到高度表达的指代事件图（REG）中，这是一个单根有向无环图。在REG的拓扑遍历的指导下，我们提出时间概念-角色推理（TCRR）以累积每个时间查询从REG叶节点到根节点的指代分数。每个推理步骤都可以解释为从REG中的概念-角色关系派生的问答对。

Result: EventRR框架将RVOS分解为对象摘要和指代推理两部分。摘要阶段首先将每个帧摘要为一组瓶颈令牌，然后在视频级摘要步骤中有效地聚合这些令牌，以交换全局跨模态时间上下文。对于推理部分，EventRR将视频指代表达式的语义事件结构提取到高度表达的指代事件图（REG）中，这是一个单根有向无环图。在REG的拓扑遍历的指导下，我们提出时间概念-角色推理（TCRR）以累积每个时间查询从REG叶节点到根节点的指代分数。每个推理步骤都可以解释为从REG中的概念-角色关系派生的问答对。

Conclusion: EventRR在四个广泛认可的基准数据集上的广泛实验表明，其在数量和质量上均优于最先进的RVOS方法。

Abstract: Referring Video Object Segmentation (RVOS) aims to segment out the object in
a video referred by an expression. Current RVOS methods view referring
expressions as unstructured sequences, neglecting their crucial semantic
structure essential for referent reasoning. Besides, in contrast to
image-referring expressions whose semantics focus only on object attributes and
object-object relations, video-referring expressions also encompass event
attributes and event-event temporal relations. This complexity challenges
traditional structured reasoning image approaches. In this paper, we propose
the Event Referential Reasoning (EventRR) framework. EventRR decouples RVOS
into object summarization part and referent reasoning part. The summarization
phase begins by summarizing each frame into a set of bottleneck tokens, which
are then efficiently aggregated in the video-level summarization step to
exchange the global cross-modal temporal context. For reasoning part, EventRR
extracts semantic eventful structure of a video-referring expression into
highly expressive Referential Event Graph (REG), which is a single-rooted
directed acyclic graph. Guided by topological traversal of REG, we propose
Temporal Concept-Role Reasoning (TCRR) to accumulate the referring score of
each temporal query from REG leaf nodes to root node. Each reasoning step can
be interpreted as a question-answer pair derived from the concept-role
relations in REG. Extensive experiments across four widely recognized benchmark
datasets, show that EventRR quantitatively and qualitatively outperforms
state-of-the-art RVOS methods. Code is available at
https://github.com/bio-mlhui/EventRR

</details>


### [84] [Similarity Matters: A Novel Depth-guided Network for Image Restoration and A New Dataset](https://arxiv.org/abs/2508.07211)
*Junyi He,Liuling Chen,Hongyang Zhou,Zhang xiaoxing,Xiaobin Zhu,Shengxiang Yu,Jingyan Qin,Xu-Cheng Yin*

Main category: cs.CV

TL;DR: 提出了一种新颖的深度引导网络（DGN）用于图像恢复，并引入了一个包含9,205张高分辨率植物图像的新数据集。该网络通过深度估计分支提供结构指导，并通过结合逐步窗口自注意力和稀疏非局部注意力来捕获相似性，从而克服了现有方法忽略深度信息的限制。实验证明该方法达到了最先进的性能，并且泛化能力强。


<details>
  <summary>Details</summary>
Motivation: 现有的图像恢复方法常常忽略深度信息，这会影响相似性匹配，并在浅景深（DoF）场景中导致注意力分散，在深景深场景中过度增强背景内容。

Method: 提出了一种新颖的深度引导网络（DGN），包含一个深度估计分支和一个图像恢复分支。该网络利用了逐步窗口自注意力和稀疏非局部注意力来捕获物体内部和物体间的相似性。通过联合训练，深度特征提高了恢复质量，而恢复分支的视觉特征则有助于改进深度估计。

Result: DGN在浅景深和深景深场景下均能有效处理背景内容，并且通过联合训练，深度特征和恢复特征相互促进，共同提升了恢复效果。

Conclusion: 该方法在多个标准基准上实现了最先进的性能，并且能够很好地泛化到未见过的植物图像，证明了其有效性和鲁棒性。

Abstract: Image restoration has seen substantial progress in recent years. However,
existing methods often neglect depth information, which hurts similarity
matching, results in attention distractions in shallow depth-of-field (DoF)
scenarios, and excessive enhancement of background content in deep DoF
settings. To overcome these limitations, we propose a novel Depth-Guided
Network (DGN) for image restoration, together with a novel large-scale
high-resolution dataset. Specifically, the network consists of two interactive
branches: a depth estimation branch that provides structural guidance, and an
image restoration branch that performs the core restoration task. In addition,
the image restoration branch exploits intra-object similarity through
progressive window-based self-attention and captures inter-object similarity
via sparse non-local attention. Through joint training, depth features
contribute to improved restoration quality, while the enhanced visual features
from the restoration branch in turn help refine depth estimation. Notably, we
also introduce a new dataset for training and evaluation, consisting of 9,205
high-resolution images from 403 plant species, with diverse depth and texture
variations. Extensive experiments show that our method achieves
state-of-the-art performance on several standard benchmarks and generalizes
well to unseen plant images, demonstrating its effectiveness and robustness.

</details>


### [85] [Unsupervised Real-World Super-Resolution via Rectified Flow Degradation Modelling](https://arxiv.org/abs/2508.07214)
*Hongyang Zhou,Xiaobin Zhu,Liuling Chen,Junyi He,Jingyan Qin,Xu-Cheng Yin,Zhang xiaoxing*

Main category: cs.CV

TL;DR: 提出了一种新的无监督真实世界超分辨率方法，利用修正流和傅里叶先验来模拟真实世界的退化，以生成更逼真的训练数据，从而提高超分辨率模型的性能。


<details>
  <summary>Details</summary>
Motivation: 无监督的真实世界超分辨率方法面临着复杂的、未知的实际退化分布的严峻挑战。现有方法在从合成低分辨率（LR）和高分辨率（HR）图像对泛化到真实世界数据时，由于显著的域间隙而难以取得良好效果。

Method: 提出了一种基于修正流的无监督真实世界超分辨率方法，并引入了修正流退化模块（RFDM）和傅里叶先验引导退化模块（FGDM）。RFDM通过对退化轨迹进行连续和可逆建模来生成中间的退化转换低分辨率（DT-LR）图像，以捕捉真实世界的退化。FGDM利用傅里叶相位分量中的结构信息来更精确地模拟退化。最终，通过结合RFDM和FGDM处理后的低分辨率图像与给定的高分辨率图像配对，来训练超分辨率网络。

Result: 在真实世界数据集上的大量实验表明，所提出的方法显著提高了现有超分辨率方法在真实世界场景中的性能。

Conclusion: 通过使用修正流和傅里叶先验来模拟真实世界的退化，可以有效地合成具有真实退化的低分辨率-高分辨率训练对，从而提高超分辨率（SR）方法在实际场景中的性能。

Abstract: Unsupervised real-world super-resolution (SR) faces critical challenges due
to the complex, unknown degradation distributions in practical scenarios.
Existing methods struggle to generalize from synthetic low-resolution (LR) and
high-resolution (HR) image pairs to real-world data due to a significant domain
gap. In this paper, we propose an unsupervised real-world SR method based on
rectified flow to effectively capture and model real-world degradation,
synthesizing LR-HR training pairs with realistic degradation. Specifically,
given unpaired LR and HR images, we propose a novel Rectified Flow Degradation
Module (RFDM) that introduces degradation-transformed LR (DT-LR) images as
intermediaries. By modeling the degradation trajectory in a continuous and
invertible manner, RFDM better captures real-world degradation and enhances the
realism of generated LR images. Additionally, we propose a Fourier Prior Guided
Degradation Module (FGDM) that leverages structural information embedded in
Fourier phase components to ensure more precise modeling of real-world
degradation. Finally, the LR images are processed by both FGDM and RFDM,
producing final synthetic LR images with real-world degradation. The synthetic
LR images are paired with the given HR images to train the off-the-shelf SR
networks. Extensive experiments on real-world datasets demonstrate that our
method significantly enhances the performance of existing SR approaches in
real-world scenarios.

</details>


### [86] [Bridging Semantic Logic Gaps: A Cognition-Inspired Multimodal Boundary-Preserving Network for Image Manipulation Localization](https://arxiv.org/abs/2508.07216)
*Songlin Li,Zhiqing Guo,Yuanman Li,Zeyu Li,Yunfeng Diao,Gaobo Yang,Liejun Wang*

Main category: cs.CV

TL;DR: CMB-Net leverages LLMs and multimodal fusion to capture semantic relationships disrupted by image manipulation, outperforming existing IML methods.


<details>
  <summary>Details</summary>
Motivation: Existing image manipulation localization (IML) models mainly rely on visual cues but ignore the semantic logical relationships between content features. This paper addresses this gap by leveraging the fact that image manipulation often disrupts the internal relationship between content features, leaving semantic clues.

Method: CMB-Net utilizes large language models (LLMs) to analyze manipulated regions within images and generate prompt-based textual information. It incorporates an image-text central ambiguity module (ITCAM) to quantify ambiguity between text and image features and assign weights to text features. Additionally, an image-text interaction module (ITIM) aligns visual and text features using a correlation matrix. A restoration edge decoder (RED) generates input and output features mutually to preserve boundary information in manipulated regions without loss.

Result: The proposed CMB-Net, utilizing LLMs, ITCAM, ITIM, and RED, demonstrates superior performance compared to existing IML models in extensive experiments.

Conclusion: CMB-Net outperforms most existing IML models.

Abstract: The existing image manipulation localization (IML) models mainly relies on
visual cues, but ignores the semantic logical relationships between content
features. In fact, the content semantics conveyed by real images often conform
to human cognitive laws. However, image manipulation technology usually
destroys the internal relationship between content features, thus leaving
semantic clues for IML. In this paper, we propose a cognition-inspired
multimodal boundary-preserving network (CMB-Net). Specifically, CMB-Net
utilizes large language models (LLMs) to analyze manipulated regions within
images and generate prompt-based textual information to compensate for the lack
of semantic relationships in the visual information. Considering that the
erroneous texts induced by hallucination from LLMs will damage the accuracy of
IML, we propose an image-text central ambiguity module (ITCAM). It assigns
weights to the text features by quantifying the ambiguity between text and
image features, thereby ensuring the beneficial impact of textual information.
We also propose an image-text interaction module (ITIM) that aligns visual and
text features using a correlation matrix for fine-grained interaction. Finally,
inspired by invertible neural networks, we propose a restoration edge decoder
(RED) that mutually generates input and output features to preserve boundary
information in manipulated regions without loss. Extensive experiments show
that CMB-Net outperforms most existing IML models.

</details>


### [87] [Generic Calibration: Pose Ambiguity/Linear Solution and Parametric-hybrid Pipeline](https://arxiv.org/abs/2508.07217)
*Yuqi Han,Qi Cai,Yuanxin Wu*

Main category: cs.CV

TL;DR: 一种结合通用和参数化模型的混合相机标定方法，解决了通用标定方法的位姿模糊问题，并提高了标定精度和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有离线相机标定技术在选择参数化模型时依赖用户经验，且模型选择不当会影响标定精度；通用标定方法过程复杂且无法提供传统内参。本文揭示了通用标定方法位姿解中的模糊性问题，该问题会不可逆地影响后续的位姿估计。

Method: 提出了一种线性求解器和非线性优化来解决位姿模糊问题，并引入了一种全局优化混合标定方法来整合通用和参数化模型。

Result: 混合标定方法提高了通用标定方法的估计位姿精度，并缓解了参数化标定中的过拟合和数值不稳定性。

Conclusion: 提出了一种结合通用和参数化模型的混合标定方法，该方法在各种镜头类型和噪声污染下表现优异，有望成为复杂场景下相机标定的可靠准确的解决方案。

Abstract: Offline camera calibration techniques typically employ parametric or generic
camera models. Selecting parametric models relies heavily on user experience,
and an inappropriate camera model can significantly affect calibration
accuracy. Meanwhile, generic calibration methods involve complex procedures and
cannot provide traditional intrinsic parameters. This paper reveals a pose
ambiguity in the pose solutions of generic calibration methods that
irreversibly impacts subsequent pose estimation. A linear solver and a
nonlinear optimization are proposed to address this ambiguity issue. Then a
global optimization hybrid calibration method is introduced to integrate
generic and parametric models together, which improves extrinsic parameter
accuracy of generic calibration and mitigates overfitting and numerical
instability in parametric calibration. Simulation and real-world experimental
results demonstrate that the generic-parametric hybrid calibration method
consistently excels across various lens types and noise contamination,
hopefully serving as a reliable and accurate solution for camera calibration in
complex scenarios.

</details>


### [88] [Landmark Guided Visual Feature Extractor for Visual Speech Recognition with Limited Resource](https://arxiv.org/abs/2508.07233)
*Lei Yang,Junshan Jin,Mingyuan Zhang,Yi He,Bofan Chen,Shilin Wang*

Main category: cs.CV

TL;DR: 提出了一种landmark引导的视觉特征提取器，结合时空多图卷积网络和多层唇动融合框架，在数据有限和未见过说话人时能提高视觉语音识别性能。


<details>
  <summary>Details</summary>
Motivation: 为了减少用户特定特征的影响并提高在有限数据下的性能，并解决现有深度学习方法受视觉干扰（如光照条件、皮肤纹理等）影响以及需要大量训练数据和计算资源的问题。

Method: 提出了一种landmark引导的视觉特征提取器，设计了一个时空多图卷积网络来充分利用面部landmark的空间位置和时空特征，并引入了一个多层唇动融合框架来结合landmark的时空特征和从原始视频帧中提取的视觉特征。

Result: 实验结果表明，该方法在数据量有限的情况下表现良好，并提高了模型在未见过说话人上的准确率。

Conclusion: 该研究提出了一种基于landmark的视觉特征提取器，并结合时空多图卷积网络和多层唇动融合框架，通过利用面部landmark的辅助信息来提高视觉语音识别的性能，特别是在数据量有限的情况下，并且能够提升模型在未见过说话人上的准确率。

Abstract: Visual speech recognition is a technique to identify spoken content in silent
speech videos, which has raised significant attention in recent years.
Advancements in data-driven deep learning methods have significantly improved
both the speed and accuracy of recognition. However, these deep learning
methods can be effected by visual disturbances, such as lightning conditions,
skin texture and other user-specific features. Data-driven approaches could
reduce the performance degradation caused by these visual disturbances using
models pretrained on large-scale datasets. But these methods often require
large amounts of training data and computational resources, making them costly.
To reduce the influence of user-specific features and enhance performance with
limited data, this paper proposed a landmark guided visual feature extractor.
Facial landmarks are used as auxiliary information to aid in training the
visual feature extractor. A spatio-temporal multi-graph convolutional network
is designed to fully exploit the spatial locations and spatio-temporal features
of facial landmarks. Additionally, a multi-level lip dynamic fusion framework
is introduced to combine the spatio-temporal features of the landmarks with the
visual features extracted from the raw video frames. Experimental results show
that this approach performs well with limited data and also improves the
model's accuracy on unseen speakers.

</details>


### [89] [ASM-UNet: Adaptive Scan Mamba Integrating Group Commonalities and Individual Variations for Fine-Grained Segmentation](https://arxiv.org/abs/2508.07237)
*Bo Wang,Mengyuan Xu,Yue Yan,Yuqun Yang,Kechen Shu,Wei Ping,Xu Tang,Wei Jiang,Zheng You*

Main category: cs.CV

TL;DR: 提出了一种新颖的基于 Mamba 的 ASM-UNet 架构，用于精细解剖结构分割 (FGS)，通过自适应扫描分数解决现有模型对个体差异适应性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 Mamba 的模型在 FGS 中依赖固定的手动定义的扫描顺序，限制了它们对个体差异的适应性。

Method: 提出了一种新颖的基于 Mamba 的 ASM-UNet 架构，用于 FGS，引入了自适应扫描分数来动态指导扫描顺序，结合了组级别共性和个体级别差异。

Result: ASM-UNet 在 ACDC、Synapse 和 BTMS 数据集上均取得了优越的 FGS 性能，并在 CGS 任务上表现出色。

Conclusion: ASM-UNet 在 CGS 和 FGS 任务上均表现出优越性能，在 BTMS 数据集上取得了有竞争力的结果。

Abstract: Precise lesion resection depends on accurately identifying fine-grained
anatomical structures. While many coarse-grained segmentation (CGS) methods
have been successful in large-scale segmentation (e.g., organs), they fall
short in clinical scenarios requiring fine-grained segmentation (FGS), which
remains challenging due to frequent individual variations in small-scale
anatomical structures. Although recent Mamba-based models have advanced medical
image segmentation, they often rely on fixed manually-defined scanning orders,
which limit their adaptability to individual variations in FGS. To address
this, we propose ASM-UNet, a novel Mamba-based architecture for FGS. It
introduces adaptive scan scores to dynamically guide the scanning order,
generated by combining group-level commonalities and individual-level
variations. Experiments on two public datasets (ACDC and Synapse) and a newly
proposed challenging biliary tract FGS dataset, namely BTMS, demonstrate that
ASM-UNet achieves superior performance in both CGS and FGS tasks. Our code and
dataset are available at https://github.com/YqunYang/ASM-UNet.

</details>


### [90] [Consistent and Controllable Image Animation with Motion Linear Diffusion Transformers](https://arxiv.org/abs/2508.07246)
*Xin Ma,Yaohui Wang,Genyun Jia,Xinyuan Chen,Tien-Tsin Wong,Cunjian Chen*

Main category: cs.CV

TL;DR: MiraMo通过采用线性注意力、运动残差学习和DCT去噪策略来提高图像动画的效率、外观一致性和运动平滑度，并在运动迁移和视频编辑中表现出色。


<details>
  <summary>Details</summary>
Motivation: 图像动画领域仍然依赖基于U-Net的扩散模型，这些模型落后于最新的文本到视频（T2V）方法。此外，Transformer中标准的自注意力机制的二次复杂度带来了高昂的计算需求，使得图像动画特别消耗资源。

Method: MiraMo框架引入了三个关键要素：1.一个基础的文本到视频架构，用高效的线性注意力取代了标准的自注意力机制，以降低计算开销并保持生成质量；2.一种新颖的运动残差学习范式，侧重于模拟运动动态而不是直接预测帧，以提高时间一致性；3.一种基于DCT的推理去噪策略，用于抑制突然的运动伪影，并辅以一个动态控制模块来平衡运动平滑度和表现力。

Result: MiraMo在保持静态输入图像的外观一致性并减轻生成动画中突变运动方面取得了显著进展，同时提高了效率、外观一致性和运动平滑度。

Conclusion: MiraMo在生成一致、平滑、可控的动画方面优于最先进的方法，并加快了推理速度。此外，MiraMo在运动迁移和视频编辑任务中也展现了其多功能性。

Abstract: Image animation has seen significant progress, driven by the powerful
generative capabilities of diffusion models. However, maintaining appearance
consistency with static input images and mitigating abrupt motion transitions
in generated animations remain persistent challenges. While text-to-video (T2V)
generation has demonstrated impressive performance with diffusion transformer
models, the image animation field still largely relies on U-Net-based diffusion
models, which lag behind the latest T2V approaches. Moreover, the quadratic
complexity of vanilla self-attention mechanisms in Transformers imposes heavy
computational demands, making image animation particularly resource-intensive.
To address these issues, we propose MiraMo, a framework designed to enhance
efficiency, appearance consistency, and motion smoothness in image animation.
Specifically, MiraMo introduces three key elements: (1) A foundational
text-to-video architecture replacing vanilla self-attention with efficient
linear attention to reduce computational overhead while preserving generation
quality; (2) A novel motion residual learning paradigm that focuses on modeling
motion dynamics rather than directly predicting frames, improving temporal
consistency; and (3) A DCT-based noise refinement strategy during inference to
suppress sudden motion artifacts, complemented by a dynamics control module to
balance motion smoothness and expressiveness. Extensive experiments against
state-of-the-art methods validate the superiority of MiraMo in generating
consistent, smooth, and controllable animations with accelerated inference
speed. Additionally, we demonstrate the versatility of MiraMo through
applications in motion transfer and video editing tasks.

</details>


### [91] [SUIT: Spatial-Spectral Union-Intersection Interaction Network for Hyperspectral Object Tracking](https://arxiv.org/abs/2508.07250)
*Fengchao Xiong,Zhenxing Wu,Sen Jia,Yuntao Qian*

Main category: cs.CV

TL;DR: 一种新颖的追踪方法，通过整合光谱信息和改进的训练策略，显著提高了在复杂场景下的追踪精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注空间交互，忽略了光谱交互，导致追踪性能不佳。

Method: 提出了一种结合了Transformer和集合论中的包含-排除原则的追踪方法，用于建模长距离空间关系和光谱交互。在训练层面，引入了光谱损失来强制对齐材料分布，增强了对形状变形和外观变化的鲁棒性。

Result: 通过广泛的实验证明，该追踪器在具有挑战性的追踪场景中实现了最先进的追踪性能。

Conclusion: 该研究提出的追踪器在克服杂乱背景和小物体等挑战性追踪场景方面表现出色，实现了最先进的追踪性能。

Abstract: Hyperspectral videos (HSVs), with their inherent spatial-spectral-temporal
structure, offer distinct advantages in challenging tracking scenarios such as
cluttered backgrounds and small objects. However, existing methods primarily
focus on spatial interactions between the template and search regions, often
overlooking spectral interactions, leading to suboptimal performance. To
address this issue, this paper investigates spectral interactions from both the
architectural and training perspectives. At the architectural level, we first
establish band-wise long-range spatial relationships between the template and
search regions using Transformers. We then model spectral interactions using
the inclusion-exclusion principle from set theory, treating them as the union
of spatial interactions across all bands. This enables the effective
integration of both shared and band-specific spatial cues. At the training
level, we introduce a spectral loss to enforce material distribution alignment
between the template and predicted regions, enhancing robustness to shape
deformation and appearance variations. Extensive experiments demonstrate that
our tracker achieves state-of-the-art tracking performance. The source code,
trained models and results will be publicly available via
https://github.com/bearshng/suit to support reproducibility.

</details>


### [92] [Understanding Dynamic Scenes in Ego Centric 4D Point Clouds](https://arxiv.org/abs/2508.07251)
*Junsheng Huang,Shengyu Hao,Bocheng Hu,Gaoang Wang*

Main category: cs.CV

TL;DR: 该论文提出了 EgoDynamic4D，一个包含RGB-D视频、相机姿态、实例掩码和4D边界框的新型QA基准，用于理解动态4D场景。他们还提出了一种端到端的时空推理框架，以处理细粒度的时空推理任务，并在EgoDynamic4D数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的 egocentric 数据集虽然包含动态场景，但缺乏统一的4D标注和面向细粒度时空推理的任务驱动评估协议，特别是在物体和人的运动及其交互方面。为了填补这一空白，需要一个包含丰富4D标注和多维度评估指标的新型基准。 


Method: 提出了一种端到端的时空推理框架，该框架整合了动态和静态场景信息，并采用了实例感知特征编码、时间与相机编码以及空间自适应下采样等技术，将大型4D场景压缩为可被语言模型处理的序列。

Result: 所提出的框架在 EgoDynamic4D 数据集上取得了优于其他基线模型的性能，验证了多模态时态模型在 egocentric 动态场景理解方面的有效性。

Conclusion: 实验结果表明，所提出的多模态时态模型能够有效提升对动态场景的 egocentric 理解能力，并且在 EgoDynamic4D 数据集上表现优于其他基线模型。

Abstract: Understanding dynamic 4D scenes from an egocentric perspective-modeling
changes in 3D spatial structure over time-is crucial for human-machine
interaction, autonomous navigation, and embodied intelligence. While existing
egocentric datasets contain dynamic scenes, they lack unified 4D annotations
and task-driven evaluation protocols for fine-grained spatio-temporal
reasoning, especially on motion of objects and human, together with their
interactions. To address this gap, we introduce EgoDynamic4D, a novel QA
benchmark on highly dynamic scenes, comprising RGB-D video, camera poses,
globally unique instance masks, and 4D bounding boxes. We construct 927K QA
pairs accompanied by explicit Chain-of-Thought (CoT), enabling verifiable,
step-by-step spatio-temporal reasoning. We design 12 dynamic QA tasks covering
agent motion, human-object interaction, trajectory prediction, relation
understanding, and temporal-causal reasoning, with fine-grained,
multidimensional metrics. To tackle these tasks, we propose an end-to-end
spatio-temporal reasoning framework that unifies dynamic and static scene
information, using instance-aware feature encoding, time and camera encoding,
and spatially adaptive down-sampling to compress large 4D scenes into token
sequences manageable by LLMs. Experiments on EgoDynamic4D show that our method
consistently outperforms baselines, validating the effectiveness of multimodal
temporal modeling for egocentric dynamic scene understanding.

</details>


### [93] [Small-Large Collaboration: Training-efficient Concept Personalization for Large VLM using a Meta Personalized Small VLM](https://arxiv.org/abs/2508.07260)
*Sihan Yang,Huitong Ji,Shaolin Lu,Jiayi Chen,Binxiao Xu,Ming Lu,Yuanxing Zhang,Wenhui Dong,Wentao Zhang*

Main category: cs.CV

TL;DR: 一个名为SLC的框架，通过让小型VLM生成个性化信息，并由大型VLM整合，实现了高效且广泛适用的大型VLM个性化。


<details>
  <summary>Details</summary>
Motivation: 当前，将VLMs个性化以用作日常助手的研究方向备受关注。然而，大型VLMs训练成本高且访问受限，而小型VLMs虽然易于个性化但推理能力不足。为了解决这一问题，该研究旨在提出一种能够有效结合大型VLMs的复杂推理能力和小型VLMs易于个性化的优势的框架。

Method: 该框架的核心是“小-大协作”（SLC），其中小型VLM负责生成个性化信息，大型VLM则整合这些信息以生成准确的响应。此外，还开发了一种“测试时反思”策略，以防止小型VLM产生幻觉。

Result: 实验结果表明，SLC框架在多个基准测试和大型VLMs上均表现出有效性，证明了其在提高大型VLM个性化方面的能力。

Conclusion: 这项研究提出了一个名为SLC（Small-Large Collaboration）的新型框架，用于大规模视觉语言模型（VLMs）的个性化。该框架通过让小型VLM生成个性化信息，并由大型VLM整合这些信息来提供准确的响应，从而实现了高效的训练和广泛的应用。

Abstract: Personalizing Vision-Language Models (VLMs) to transform them into daily
assistants has emerged as a trending research direction. However, leading
companies like OpenAI continue to increase model size and develop complex
designs such as the chain of thought (CoT). While large VLMs are proficient in
complex multi-modal understanding, their high training costs and limited access
via paid APIs restrict direct personalization. Conversely, small VLMs are
easily personalized and freely available, but they lack sufficient reasoning
capabilities. Inspired by this, we propose a novel collaborative framework
named Small-Large Collaboration (SLC) for large VLM personalization, where the
small VLM is responsible for generating personalized information, while the
large model integrates this personalized information to deliver accurate
responses. To effectively incorporate personalized information, we develop a
test-time reflection strategy, preventing the potential hallucination of the
small VLM. Since SLC only needs to train a meta personalized small VLM for the
large VLMs, the overall process is training-efficient. To the best of our
knowledge, this is the first training-efficient framework that supports both
open-source and closed-source large VLMs, enabling broader real-world
personalized applications. We conduct thorough experiments across various
benchmarks and large VLMs to demonstrate the effectiveness of the proposed SLC
framework. The code will be released at https://github.com/Hhankyangg/SLC.

</details>


### [94] [OpenHAIV: A Framework Towards Practical Open-World Learning](https://arxiv.org/abs/2508.07270)
*Xiang Xiang,Qinhao Zhou,Zhuo Xu,Jing Ma,Jiaxin Dai,Yifan Liang,Hanlin Li*

Main category: cs.CV

TL;DR: OpenHAIV是一个创新的框架，它将OOD检测、新类别发现和增量持续微调结合起来，使模型能够自主地在开放世界环境中学习和更新知识。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有OOD检测方法无法更新模型知识以及增量微调通常需要监督条件（这与开放世界设置大相径庭）的局限性。

Method: 提出了一种名为OpenHAIV的新型框架，该框架将OOD检测、新类别发现和增量持续微调整合到一个统一的流水线中。

Result: OpenHAIV是一个将OOD检测、新类别发现和增量持续微调整合到一个统一流水线中的框架，使模型能够自主获取和更新开放世界环境中的知识。

Conclusion: 该框架允许模型在开放世界环境中自主获取和更新知识。

Abstract: Substantial progress has been made in various techniques for open-world
recognition. Out-of-distribution (OOD) detection methods can effectively
distinguish between known and unknown classes in the data, while incremental
learning enables continuous model knowledge updates. However, in open-world
scenarios, these approaches still face limitations. Relying solely on OOD
detection does not facilitate knowledge updates in the model, and incremental
fine-tuning typically requires supervised conditions, which significantly
deviate from open-world settings. To address these challenges, this paper
proposes OpenHAIV, a novel framework that integrates OOD detection, new class
discovery, and incremental continual fine-tuning into a unified pipeline. This
framework allows models to autonomously acquire and update knowledge in
open-world environments. The proposed framework is available at
https://haiv-lab.github.io/openhaiv .

</details>


### [95] [Representation Understanding via Activation Maximization](https://arxiv.org/abs/2508.07281)
*Hongbo Zhu,Angelo Cangelosi*

Main category: cs.CV

TL;DR: 本研究提出了一个统一的特征可视化框架，适用于CNN和ViT，可用于中间层可视化和生成对抗样本，实验证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 理解深度神经网络（DNN）的内部特征表示是模型可解释性的基础。受神经科学中利用视觉刺激探测生物神经元方法的启发，本研究旨在开发一种能够应用于CNN和ViT的统一特征可视化框架，并深入研究其在解释DNN和生成对抗样本方面的潜力。

Method: 提出了一种统一的特征可视化框架，该框架适用于CNN和ViT，能够将特征可视化扩展到中间层，并研究了激活最大化在生成对抗样本中的应用。

Result: 实验证明了该方法在传统CNN和现代ViT上的有效性、通用性和解释价值，能够提供对学习到的特征表示的更深层次的理解，并揭示DNN的潜在漏洞和决策边界。

Conclusion: 该研究提出了一个统一的特征可视化框架，适用于CNN和ViT，并能将特征可视化扩展到中间层，同时研究了激活最大化在生成对抗样本中的应用，证明了其在CNN和ViT上的有效性、通用性和解释价值。

Abstract: Understanding internal feature representations of deep neural networks (DNNs)
is a fundamental step toward model interpretability. Inspired by neuroscience
methods that probe biological neurons using visual stimuli, recent deep
learning studies have employed Activation Maximization (AM) to synthesize
inputs that elicit strong responses from artificial neurons. In this work, we
propose a unified feature visualization framework applicable to both
Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs). Unlike
prior efforts that predominantly focus on the last output-layer neurons in
CNNs, we extend feature visualization to intermediate layers as well, offering
deeper insights into the hierarchical structure of learned feature
representations. Furthermore, we investigate how activation maximization can be
leveraged to generate adversarial examples, revealing potential vulnerabilities
and decision boundaries of DNNs. Our experiments demonstrate the effectiveness
of our approach in both traditional CNNs and modern ViT, highlighting its
generalizability and interpretive value.

</details>


### [96] [SynMatch: Rethinking Consistency in Medical Image Segmentation with Sparse Annotations](https://arxiv.org/abs/2508.07298)
*Zhiqiang Shen,Peng Cao,Xiaoli Liu,Jinzhu Yang,Osmar R. Zaiane*

Main category: cs.CV

TL;DR: SynMatch通过合成图像匹配伪标签来解决医学图像分割中的标签稀疏问题，无需改进伪标签或额外训练，并在少标注场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习医学图像分割中标签稀疏性的挑战，并克服现有伪监督方法中伪标签与无标签图像不一致的问题。

Method: SynMatch框架通过合成图像来匹配伪标签，而不是直接改进伪标签。它利用从同一分割模型中提取的纹理和形状特征来合成图像，并确保合成图像与其对应的伪标签高度一致，且无需额外的合成训练参数。

Result: SynMatch在多项医学图像分割任务中表现出色，尤其是在标注数据极少的情况下，其性能优于现有方法。例如，在结肠息肉分割任务中，使用5%和10%的涂鸦标注时，其性能分别比最近的强弱伪监督方法高出29.71%和10.05%。

Conclusion: SynMatch框架在各种医学图像分割任务的半监督、弱监督和少监督学习设置下，尤其是在标注极少的少监督设置下，均取得了优越的性能，并且优于最近的强弱伪监督方法。

Abstract: Label scarcity remains a major challenge in deep learning-based medical image
segmentation. Recent studies use strong-weak pseudo supervision to leverage
unlabeled data. However, performance is often hindered by inconsistencies
between pseudo labels and their corresponding unlabeled images. In this work,
we propose \textbf{SynMatch}, a novel framework that sidesteps the need for
improving pseudo labels by synthesizing images to match them instead.
Specifically, SynMatch synthesizes images using texture and shape features
extracted from the same segmentation model that generates the corresponding
pseudo labels for unlabeled images. This design enables the generation of
highly consistent synthesized-image-pseudo-label pairs without requiring any
training parameters for image synthesis. We extensively evaluate SynMatch
across diverse medical image segmentation tasks under semi-supervised learning
(SSL), weakly-supervised learning (WSL), and barely-supervised learning (BSL)
settings with increasingly limited annotations. The results demonstrate that
SynMatch achieves superior performance, especially in the most challenging BSL
setting. For example, it outperforms the recent strong-weak pseudo
supervision-based method by 29.71\% and 10.05\% on the polyp segmentation task
with 5\% and 10\% scribble annotations, respectively. The code will be released
at https://github.com/Senyh/SynMatch.

</details>


### [97] [BEVANet: Bilateral Efficient Visual Attention Network for Real-Time Semantic Segmentation](https://arxiv.org/abs/2508.07300)
*Ping-Mao Huang,I-Tien Chao,Ping-Chia Huang,Jia-Wei Liao,Yung-Yu Chuang*

Main category: cs.CV

TL;DR: BEVANet通过引入大核注意力（LKA）、稀疏分解大可分离卷积注意力（SDLSKA）、全面的核选择（CKS）和深度大型核金字塔池化模块（DLKPPM）以及边界引导自适应融合（BGAF）模块，在实时语义分割方面取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 为了应对实时语义分割中设计能够捕捉用于语义理解的大感受野并同时细化详细轮廓的有效架构的双重挑战，同时解决视觉 Transformer 计算成本高的问题。

Method: 提出了一种名为BEVANet的双边高效视觉注意力网络，其中引入了大核注意力（LKA）机制，并通过稀疏分解大可分离卷积注意力（SDLSKA）扩展感受野以捕获上下文信息并提取视觉和结构特征。此外，还提出了全面的核选择（CKS）机制来动态调整感受野，并结合了扩张卷积和大型核注意力的深度大型核金字塔池化模块（DLKPPM）来丰富上下文特征。双边架构促进了频繁的分支通信，而边界引导自适应融合（BGAF）模块通过整合边界引导下的空间和语义特征来增强边界细节。

Result: BEVANet实现了33 FPS的实时分割，无预训练mIoU为79.3%，ImageNet预训练后mIoU为81.0%。

Conclusion: BEVANet在Cityscapes上实现了33 FPS的实时分割，在无预训练的情况下达到79.3% mIoU，在ImageNet预训练后达到81.0% mIoU，展示了最先进的性能。

Abstract: Real-time semantic segmentation presents the dual challenge of designing
efficient architectures that capture large receptive fields for semantic
understanding while also refining detailed contours. Vision transformers model
long-range dependencies effectively but incur high computational cost. To
address these challenges, we introduce the Large Kernel Attention (LKA)
mechanism. Our proposed Bilateral Efficient Visual Attention Network (BEVANet)
expands the receptive field to capture contextual information and extracts
visual and structural features using Sparse Decomposed Large Separable Kernel
Attentions (SDLSKA). The Comprehensive Kernel Selection (CKS) mechanism
dynamically adapts the receptive field to further enhance performance.
Furthermore, the Deep Large Kernel Pyramid Pooling Module (DLKPPM) enriches
contextual features by synergistically combining dilated convolutions and large
kernel attention. The bilateral architecture facilitates frequent branch
communication, and the Boundary Guided Adaptive Fusion (BGAF) module enhances
boundary delineation by integrating spatial and semantic features under
boundary guidance. BEVANet achieves real-time segmentation at 33 FPS, yielding
79.3% mIoU without pretraining and 81.0% mIoU on Cityscapes after ImageNet
pretraining, demonstrating state-of-the-art performance. The code and model is
available at https://github.com/maomao0819/BEVANet.

</details>


### [98] [DragonFruitQualityNet: A Lightweight Convolutional Neural Network for Real-Time Dragon Fruit Quality Inspection on Mobile Devices](https://arxiv.org/abs/2508.07306)
*Md Zahurul Haquea,Yeahyea Sarker,Muhammed Farhan Sadique Mahi,Syed Jubayer Jaman,Md Robiul Islam*

Main category: cs.CV

TL;DR: 开发了一个名为DragonFruitQualityNet的轻量级CNN模型，用于在移动设备上对火龙果进行实时质量评估。该模型在包含13,789张图像的数据集上达到了93.98%的准确率，优于现有方法。此外，该模型已集成到一个移动应用程序中，使农民能够进行现场质量检查。


<details>
  <summary>Details</summary>
Motivation: 随着火龙果种植的扩大，高效的采前和采后质量检查对于提高农业生产力和最大限度地减少采后损失至关重要。

Method: 提出了一种名为DragonFruitQualityNet的轻量级卷积神经网络（CNN），并针对移动设备上的火龙果进行实时质量评估进行了优化。数据集包含13,789张图像，分为新鲜、未成熟、成熟和有缺陷四类。

Result: 所提出的模型在水果质量分类方面取得了93.98%的准确率，优于现有方法。模型已被嵌入到一个直观的移动应用程序中，允许农民和农业利益相关者进行设备上、实时的质量检查。

Conclusion: 这项研究提供了一个准确、高效且可扩展的、由人工智能驱动的火龙果质量控制解决方案，支持数字农业，并使小农户能够获得可及的技术。通过弥合研究与实际应用之间的差距，我们的工作促进了收获后管理，并推广了可持续的农业实践。

Abstract: Dragon fruit, renowned for its nutritional benefits and economic value, has
experienced rising global demand due to its affordability and local
availability. As dragon fruit cultivation expands, efficient pre- and
post-harvest quality inspection has become essential for improving agricultural
productivity and minimizing post-harvest losses. This study presents
DragonFruitQualityNet, a lightweight Convolutional Neural Network (CNN)
optimized for real-time quality assessment of dragon fruits on mobile devices.
We curated a diverse dataset of 13,789 images, integrating self-collected
samples with public datasets (dataset from Mendeley Data), and classified them
into four categories: fresh, immature, mature, and defective fruits to ensure
robust model training. The proposed model achieves an impressive 93.98%
accuracy, outperforming existing methods in fruit quality classification. To
facilitate practical adoption, we embedded the model into an intuitive mobile
application, enabling farmers and agricultural stakeholders to conduct
on-device, real-time quality inspections. This research provides an accurate,
efficient, and scalable AI-driven solution for dragon fruit quality control,
supporting digital agriculture and empowering smallholder farmers with
accessible technology. By bridging the gap between research and real-world
application, our work advances post-harvest management and promotes sustainable
farming practices.

</details>


### [99] [MCITlib: Multimodal Continual Instruction Tuning Library and Benchmark](https://arxiv.org/abs/2508.07307)
*Haiyang Guo,Fei Zhu,Hongbo Zhao,Fanhu Zeng,Wenzhuo Liu,Shijie Ma,Da-Han Wang,Xu-Yao Zhang*

Main category: cs.CV

TL;DR: MCITlib：多模态大语言模型持续学习的代码库，包含8种算法和2个基准评估，旨在解决遗忘和跨模态协调问题。


<details>
  <summary>Details</summary>
Motivation: 旨在解决多模态大语言模型在持续学习中遇到的跨模态交互和协调挑战，以及灾难性遗忘问题。

Method: 介绍了MCITlib库，实现了8种代表性算法，并在2个基准上进行了系统评估。

Result: MCITlib库的实现和评估为多模态持续学习研究提供了基础和便利。

Conclusion: MCITlib是一个全面的、不断发展的多模态大语言模型持续指令调优代码库，目前已实现8种代表性算法，并在2个基准上进行了系统评估，将持续更新以反映该领域的进展。

Abstract: Continual learning aims to equip AI systems with the ability to continuously
acquire and adapt to new knowledge without forgetting previously learned
information, similar to human learning. While traditional continual learning
methods focusing on unimodal tasks have achieved notable success, the emergence
of Multimodal Large Language Models has brought increasing attention to
Multimodal Continual Learning tasks involving multiple modalities, such as
vision and language. In this setting, models are expected to not only mitigate
catastrophic forgetting but also handle the challenges posed by cross-modal
interactions and coordination. To facilitate research in this direction, we
introduce MCITlib, a comprehensive and constantly evolving code library for
continual instruction tuning of Multimodal Large Language Models. In MCITlib,
we have currently implemented 8 representative algorithms for Multimodal
Continual Instruction Tuning and systematically evaluated them on 2 carefully
selected benchmarks. MCITlib will be continuously updated to reflect advances
in the Multimodal Continual Learning field. The codebase is released at
https://github.com/Ghy0501/MCITlib.

</details>


### [100] [MobileViCLIP: An Efficient Video-Text Model for Mobile Devices](https://arxiv.org/abs/2508.07312)
*Min Yang,Zihan Jia,Zhilin Dai,Sheng Guo,Limin Wang*

Main category: cs.CV

TL;DR: Efficient video-text model (MobileViCLIP) for mobile devices, achieving faster speeds and strong zero-shot performance.


<details>
  <summary>Details</summary>
Motivation: Existing video pre-trained models primarily use the ViT architecture, which has high latency and is not suitable for mobile devices. This paper aims to bridge this gap by developing an efficient architecture for mobile video-text understanding.

Method: The paper introduces temporal structural reparameterization into an efficient image-text model and trains it on a large-scale video-text dataset to create MobileViCLIP.

Result: MobileViCLIP-Small is 55.4x faster than InternVideo2-L14 and 6.7x faster than InternVideo2-S14 on mobile devices. It achieves similar zero-shot retrieval performance as InternVideo2-L14 and outperforms InternVideo2-S14 by 6.9% on MSR-VTT.

Conclusion: MobileViCLIP is an efficient video-text model designed for mobile devices, demonstrating strong zero-shot classification and retrieval capabilities. It achieves significantly faster inference speeds compared to existing models like InternVideo2, while maintaining competitive or improved performance.

Abstract: Efficient lightweight neural networks are with increasing attention due to
their faster reasoning speed and easier deployment on mobile devices. However,
existing video pre-trained models still focus on the common ViT architecture
with high latency, and few works attempt to build efficient architecture on
mobile devices. This paper bridges this gap by introducing temporal structural
reparameterization into an efficient image-text model and training it on a
large-scale high-quality video-text dataset, resulting in an efficient
video-text model that can run on mobile devices with strong zero-shot
classification and retrieval capabilities, termed as MobileViCLIP. In
particular, in terms of inference speed on mobile devices, our
MobileViCLIP-Small is 55.4x times faster than InternVideo2-L14 and 6.7x faster
than InternVideo2-S14. In terms of zero-shot retrieval performance, our
MobileViCLIP-Small obtains similar performance as InternVideo2-L14 and obtains
6.9\% better than InternVideo2-S14 on MSR-VTT. The code is available at
https://github.com/MCG-NJU/MobileViCLIP.

</details>


### [101] [DocR1: Evidence Page-Guided GRPO for Multi-Page Document Understanding](https://arxiv.org/abs/2508.07313)
*Junyu Xiong,Yonghui Wang,Weichao Zhao,Chenyu Liu,Bing Yin,Wengang Zhou,Houqiang Li*

Main category: cs.CV

TL;DR: 提出了一种名为DocR1的新型多页文档理解模型，采用证据页引导GRPO（EviGRPO）强化学习框架，通过粗粒度到细粒度的推理策略和证据感知奖励机制，提高了模型性能。该模型在EviBench和ArxivFullQA数据集上进行了训练和评估，并在多页和单页任务上均表现出色。


<details>
  <summary>Details</summary>
Motivation: 多页文档理解对多模态大语言模型（MLLMs）提出了重大挑战，需要细粒度的视觉理解和跨页面的多跳推理。虽然之前的研究探索了强化学习（RL）来增强MLLMs的高级推理能力，但其在多页文档理解方面的应用仍未得到充分探索。

Method: 提出了一种新颖的强化学习框架，称为证据页引导GRPO（EviGRPO），并结合了证据感知奖励机制，以促进粗粒度到细粒度的推理策略，首先检索相关页面，然后生成答案。该训练范式还包括一个两阶段的标注流程和一个课程学习策略，用于构建EviBench和ArxivFullQA数据集。

Result: DocR1在广泛的基准测试中取得了最先进的性能，并且在单页基准测试中也保持了持续的强劲结果。

Conclusion: DocR1在多页文档理解任务上取得了最先进的性能，同时在单页基准测试中也保持了强大的结果。

Abstract: Understanding multi-page documents poses a significant challenge for
multimodal large language models (MLLMs), as it requires fine-grained visual
comprehension and multi-hop reasoning across pages. While prior work has
explored reinforcement learning (RL) for enhancing advanced reasoning in MLLMs,
its application to multi-page document understanding remains underexplored. In
this paper, we introduce DocR1, an MLLM trained with a novel RL framework,
Evidence Page-Guided GRPO (EviGRPO). EviGRPO incorporates an evidence-aware
reward mechanism that promotes a coarse-to-fine reasoning strategy, guiding the
model to first retrieve relevant pages before generating answers. This training
paradigm enables us to build high-quality models with limited supervision. To
support this, we design a two-stage annotation pipeline and a curriculum
learning strategy, based on which we construct two datasets: EviBench, a
high-quality training set with 4.8k examples, and ArxivFullQA, an evaluation
benchmark with 8.6k QA pairs based on scientific papers. Extensive experiments
across a wide range of benchmarks demonstrate that DocR1 achieves
state-of-the-art performance on multi-page tasks, while consistently
maintaining strong results on single-page benchmarks.

</details>


### [102] [RORPCap: Retrieval-based Objects and Relations Prompt for Image Captioning](https://arxiv.org/abs/2508.07318)
*Jinjing Gu,Tianbao Qin,Yuanyuan Pu,Zhengpeng Zhao*

Main category: cs.CV

TL;DR: RORPCap 是一种新颖的图像字幕方法，它利用从图像中提取的对象和关系来增强字幕生成。它使用基于 Mamba 的映射网络将 CLIP 图像嵌入映射到视觉-文本嵌入，然后将这些嵌入与提示嵌入相结合，并馈送到 GPT-2 模型中进行字幕生成。RORPCap 在训练时间和性能方面均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有模型（通常利用对象检测器或结合检测器与图卷积网络（GCN））存在的冗余检测信息、GCN 构建困难和训练成本高的问题，提出了一种基于检索的对象和关系提示的图像字幕（RORPCap）方法，该方法从图像-文本检索中汲取灵感，为输入图像提供丰富的语义信息。

Method: RORPCap 采用对象和关系提取模型从图像中提取对象和关系词，然后将这些词合并到预定义的提示模板中并编码为提示嵌入。接下来，设计了一个基于 Mamba 的映射网络，以快速将 CLIP 提取的图像嵌入映射到视觉-文本嵌入。最后，将生成的提示嵌入和视觉-文本嵌入连接起来，形成文本丰富的特征嵌入，并将其输入 GPT-2 模型以生成字幕。

Result: RORPCap 在 MS-COCO 数据集上进行了广泛的实验，在“Karpathy”测试集上，在交叉熵损失训练下仅需 2.6 小时即可达到 120.5% 的 CIDEr 分数和 22.0% 的 SPICE 分数。

Conclusion: RORPCap 达到了与基于检测器和基于 GCN 的模型相当的性能指标，同时具有最短的训练时间，并展示了其作为图像字幕替代品的潜力。

Abstract: Image captioning aims to generate natural language descriptions for input
images in an open-form manner. To accurately generate descriptions related to
the image, a critical step in image captioning is to identify objects and
understand their relations within the image. Modern approaches typically
capitalize on object detectors or combine detectors with Graph Convolutional
Network (GCN). However, these models suffer from redundant detection
information, difficulty in GCN construction, and high training costs. To
address these issues, a Retrieval-based Objects and Relations Prompt for Image
Captioning (RORPCap) is proposed, inspired by the fact that image-text
retrieval can provide rich semantic information for input images. RORPCap
employs an Objects and relations Extraction Model to extract object and
relation words from the image. These words are then incorporate into predefined
prompt templates and encoded as prompt embeddings. Next, a Mamba-based mapping
network is designed to quickly map image embeddings extracted by CLIP to
visual-text embeddings. Finally, the resulting prompt embeddings and
visual-text embeddings are concatenated to form textual-enriched feature
embeddings, which are fed into a GPT-2 model for caption generation. Extensive
experiments conducted on the widely used MS-COCO dataset show that the RORPCap
requires only 2.6 hours under cross-entropy loss training, achieving 120.5%
CIDEr score and 22.0% SPICE score on the "Karpathy" test split. RORPCap
achieves comparable performance metrics to detector-based and GCN-based models
with the shortest training time and demonstrates its potential as an
alternative for image captioning.

</details>


### [103] [Planner-Refiner: Dynamic Space-Time Refinement for Vision-Language Alignment in Videos](https://arxiv.org/abs/2508.07330)
*Tuyen Tran,Thao Minh Le,Quang-Hung Le,Truyen Tran*

Main category: cs.CV

TL;DR: 提出了一种名为Planner-Refiner的框架，用于解决视频-语言对齐中的复杂性问题。该框架通过将复杂语言分解为短句，并迭代地细化视觉表示来弥合语义鸿沟，在多个视频-语言对齐任务和新的长查询基准测试中均取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 视频-语言对齐需要处理语言的复杂性、不断变化的交互实体、动作链以及语言与视觉间的语义鸿沟。现有的方法在应对这些挑战时存在不足。

Method: 提出了一种名为Planner-Refiner的框架，包括一个Planner模块用于将复杂语言提示分解为短句链，以及一个Refiner模块用于处理每个短句（名词-动词短语对），通过引导视觉令牌的跨空间和时间自注意力来迭代式地细化时空表示，以弥合语言与视觉间的语义鸿沟。该框架通过循环系统维持细化后的视觉令牌表示，并用于下游任务。

Result: Planner-Refiner在Referring Video Object Segmentation和Temporal Grounding两个视频-语言对齐任务上均取得优于现有最先进方法的性能，并且在新的MeViS-X基准测试（用于评估模型处理长查询的能力）上也表现出色。

Conclusion: Planner-Refiner在处理视频-语言对齐任务时展现出优越性能，特别是在处理复杂长查询方面，优于现有最先进方法。

Abstract: Vision-language alignment in video must address the complexity of language,
evolving interacting entities, their action chains, and semantic gaps between
language and vision. This work introduces Planner-Refiner, a framework to
overcome these challenges. Planner-Refiner bridges the semantic gap by
iteratively refining visual elements' space-time representation, guided by
language until semantic gaps are minimal. A Planner module schedules language
guidance by decomposing complex linguistic prompts into short sentence chains.
The Refiner processes each short sentence, a noun-phrase and verb-phrase pair,
to direct visual tokens' self-attention across space then time, achieving
efficient single-step refinement. A recurrent system chains these steps,
maintaining refined visual token representations. The final representation
feeds into task-specific heads for alignment generation. We demonstrate
Planner-Refiner's effectiveness on two video-language alignment tasks:
Referring Video Object Segmentation and Temporal Grounding with varying
language complexity. We further introduce a new MeViS-X benchmark to assess
models' capability with long queries. Superior performance versus
state-of-the-art methods on these benchmarks shows the approach's potential,
especially for complex prompts.

</details>


### [104] [CoAR: Concept Injection into Autoregressive Models for Personalized Text-to-Image Generation](https://arxiv.org/abs/2508.07341)
*Fangtai Wu,Mushui Liu,Weijie He,Wanggui He,Hao Jiang,Zhao Wang,Yunlong Yu*

Main category: cs.CV

TL;DR: CoAR是一种创新的框架，用于将主题概念注入统一的自回归模型，以实现高效、低成本的定制化图像生成。它通过冻结预训练参数、使用少量参数的层级多模态上下文学习策略以及正则化技术，成功解决了现有方法的痛点，并在性能和效率上均优于SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有的定制化图像生成方法（如全微调或适配器）成本高昂，且容易导致过拟合或灾难性遗忘。本研究旨在探索统一自回归（AR）模型在定制化图像生成方面的潜力，并提出一种更高效、低成本的解决方案。

Method: 提出了一种名为CoAR的新框架，该框架通过层级多模态上下文学习策略，仅用少量参数就能将主题概念注入统一的自回归（AR）模型，同时保持所有预训练参数完全冻结。为了解决过拟合和语言漂移问题，还引入了保留预训练分布的正则化，并锚定上下文令牌以提高主题保真度和再上下文化能力。此外，CoAR支持免训练的主题定制和用户提供的风格定制。

Result: 实验表明，CoAR在主题驱动的个性化和风格个性化方面均取得了优越的性能，并在计算和内存效率方面带来了显著的提升。值得注意的是，CoAR仅调整不到0.05%的参数，却能达到与最近的Proxy-Tuning方法相媲美的性能。

Conclusion: CoAR框架通过冻结预训练参数、使用少量参数的层级多模态上下文学习策略，并结合正则化技术，在图像生成领域实现了高效、低成本的个性化定制，并在主题驱动和风格个性化方面取得了优于现有方法的性能。

Abstract: The unified autoregressive (AR) model excels at multimodal understanding and
generation, but its potential for customized image generation remains
underexplored. Existing customized generation methods rely on full fine-tuning
or adapters, making them costly and prone to overfitting or catastrophic
forgetting. In this paper, we propose \textbf{CoAR}, a novel framework for
injecting subject concepts into the unified AR models while keeping all
pre-trained parameters completely frozen. CoAR learns effective, specific
subject representations with only a minimal number of parameters using a
Layerwise Multimodal Context Learning strategy. To address overfitting and
language drift, we further introduce regularization that preserves the
pre-trained distribution and anchors context tokens to improve subject fidelity
and re-contextualization. Additionally, CoAR supports training-free subject
customization in a user-provided style. Experiments demonstrate that CoAR
achieves superior performance on both subject-driven personalization and style
personalization, while delivering significant gains in computational and memory
efficiency. Notably, CoAR tunes less than \textbf{0.05\%} of the parameters
while achieving competitive performance compared to recent Proxy-Tuning. Code:
https://github.com/KZF-kzf/CoAR

</details>


### [105] [SODiff: Semantic-Oriented Diffusion Model for JPEG Compression Artifacts Removal](https://arxiv.org/abs/2508.07346)
*Tingyu Yang,Jue Gong,Jinpei Guo,Wenbo Li,Yong Guo,Yulun Zhang*

Main category: cs.CV

TL;DR: SODiff 是一种面向语义的单步扩散模型，通过 SAIPE 提取语义特征并利用预训练扩散模型的生成先验来去除 JPEG 伪影，同时通过质量因子感知时间预测器自适应去噪，实现了优于现有方法的视觉和量化效果。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有深度学习方法在去除 JPEG 伪影时难以恢复复杂纹理细节导致输出过度平滑的局限性，提出 SODiff 模型。

Method: SODiff 提出了一种新颖高效的面向语义的单步扩散模型，用于去除 JPEG 伪影。该模型通过一个语义对齐图像提示提取器（SAIPE）从低质量（LQ）图像中提取特征并将其投影到与文本编码器兼容的嵌入空间，同时保留关键信息以进行忠实重建。此外，还提出了一种质量因子感知时间预测器，用于学习压缩质量因子（QF）并自适应地选择扩散过程的最佳去噪起始时间步。

Result: SODiff 在视觉质量和定量指标上均优于最近的领先方法。

Conclusion: SODiff 在视觉质量和定量指标上均优于最近的领先方法。

Abstract: JPEG, as a widely used image compression standard, often introduces severe
visual artifacts when achieving high compression ratios. Although existing deep
learning-based restoration methods have made considerable progress, they often
struggle to recover complex texture details, resulting in over-smoothed
outputs. To overcome these limitations, we propose SODiff, a novel and
efficient semantic-oriented one-step diffusion model for JPEG artifacts
removal. Our core idea is that effective restoration hinges on providing
semantic-oriented guidance to the pre-trained diffusion model, thereby fully
leveraging its powerful generative prior. To this end, SODiff incorporates a
semantic-aligned image prompt extractor (SAIPE). SAIPE extracts rich features
from low-quality (LQ) images and projects them into an embedding space
semantically aligned with that of the text encoder. Simultaneously, it
preserves crucial information for faithful reconstruction. Furthermore, we
propose a quality factor-aware time predictor that implicitly learns the
compression quality factor (QF) of the LQ image and adaptively selects the
optimal denoising start timestep for the diffusion process. Extensive
experimental results show that our SODiff outperforms recent leading methods in
both visual quality and quantitative metrics. Code is available at:
https://github.com/frakenation/SODiff

</details>


### [106] [GS4Buildings: Prior-Guided Gaussian Splatting for 3D Building Reconstruction](https://arxiv.org/abs/2508.07355)
*Qilin Zhang,Olaf Wysocki,Boris Jutzi*

Main category: cs.CV

TL;DR: GS4Buildings利用3D建筑模型改进了高斯图的重建效果，特别是在复杂的城市场景中，提高了重建的完整性和精度，并实现了更高效的表示。


<details>
  <summary>Details</summary>
Motivation: 传统的2D高斯图（2DGS）在处理大规模、复杂且有遮挡的城市场景时，重建效果不佳，易导致建筑重建不完整。因此，需要一种新的方法来提高在这些挑战性场景下的重建鲁棒性和可扩展性。

Method: GS4Buildings是一种新的先验引导高斯图（GS）方法，它不依赖传统的运动恢复结构（SfM）流程，而是直接从低级别细节（LoD）2语义3D建筑模型初始化高斯图。该方法还从平面建筑几何生成先验深度图和法线图，并将其纳入优化过程，以实现几何引导。此外，它还提供了一个建筑聚焦模式，可以将重建限制在建筑区域内。

Result: GS4Buildings在城市数据集上的实验显示，重建完整性提高了20.5%，几何精度提高了32.8%。在建筑聚焦模式下，高斯图元数量减少了71.8%，实现了更高效和紧凑的表示。

Conclusion: GS4Buildings通过利用语义3D建筑模型，提高了大规模和复杂城市场景下建筑表面重建的完整性和几何精度，在减少高斯图元方面也表现出效率优势，为智慧城市和数字孪生等实际应用提供了潜力。

Abstract: Recent advances in Gaussian Splatting (GS) have demonstrated its
effectiveness in photo-realistic rendering and 3D reconstruction. Among these,
2D Gaussian Splatting (2DGS) is particularly suitable for surface
reconstruction due to its flattened Gaussian representation and integrated
normal regularization. However, its performance often degrades in large-scale
and complex urban scenes with frequent occlusions, leading to incomplete
building reconstructions. We propose GS4Buildings, a novel prior-guided
Gaussian Splatting method leveraging the ubiquity of semantic 3D building
models for robust and scalable building surface reconstruction. Instead of
relying on traditional Structure-from-Motion (SfM) pipelines, GS4Buildings
initializes Gaussians directly from low-level Level of Detail (LoD)2 semantic
3D building models. Moreover, we generate prior depth and normal maps from the
planar building geometry and incorporate them into the optimization process,
providing strong geometric guidance for surface consistency and structural
accuracy. We also introduce an optional building-focused mode that limits
reconstruction to building regions, achieving a 71.8% reduction in Gaussian
primitives and enabling a more efficient and compact representation.
Experiments on urban datasets demonstrate that GS4Buildings improves
reconstruction completeness by 20.5% and geometric accuracy by 32.8%. These
results highlight the potential of semantic building model integration to
advance GS-based reconstruction toward real-world urban applications such as
smart cities and digital twins. Our project is available:
https://github.com/zqlin0521/GS4Buildings.

</details>


### [107] [Training and Inference within 1 Second -- Tackle Cross-Sensor Degradation of Real-World Pansharpening with Efficient Residual Feature Tailoring](https://arxiv.org/abs/2508.07369)
*Tianyu Xin,Jin-Liang Xiao,Zeyu Xia,Shan Yin,Liang-Jian Deng*

Main category: cs.CV

TL;DR: 为解决深度学习全色增强模型在跨传感器数据上泛化能力差的问题，提出一种新的“特征定制器”方法。该方法通过模块化分解和在特征层面进行调整，实现了优异的泛化能力和极高的效率，训练和推理速度远超现有方法。


<details>
  <summary>Details</summary>
Motivation: 深度学习全色增强模型在跨传感器数据上泛化能力差，而现有的解决方法（如重新训练模型或零样本方法）耗时且需要额外数据。

Method: 通过模块化分解深度学习全色增强模型，并在关键接口处集成“特征定制器”来解决跨传感器退化问题。该方法以块状方式运行，在部分块上进行训练，并对所有块进行并行推理以提高效率。该特征定制器使用与物理相关的无监督损失进行高效训练。

Result: 该方法提高了模型的泛化能力，显著提升了跨传感器全色增强的性能，同时实现了低泛化成本。训练和推理速度极快，例如在RTX 3090 GPU上，处理512x512x8图像仅需0.2秒，处理4000x4000x8图像仅需3秒。

Conclusion: 该方法在真实世界的多传感器数据集上进行了实验，证明了其在处理跨传感器退化方面的先进质量和效率。与之前的零样本方法相比，其速度提高了100多倍。

Abstract: Deep learning methods for pansharpening have advanced rapidly, yet models
pretrained on data from a specific sensor often generalize poorly to data from
other sensors. Existing methods to tackle such cross-sensor degradation include
retraining model or zero-shot methods, but they are highly time-consuming or
even need extra training data. To address these challenges, our method first
performs modular decomposition on deep learning-based pansharpening models,
revealing a general yet critical interface where high-dimensional fused
features begin mapping to the channel space of the final image. % may need
revisement A Feature Tailor is then integrated at this interface to address
cross-sensor degradation at the feature level, and is trained efficiently with
physics-aware unsupervised losses. Moreover, our method operates in a
patch-wise manner, training on partial patches and performing parallel
inference on all patches to boost efficiency. Our method offers two key
advantages: (1) $\textit{Improved Generalization Ability}$: it significantly
enhance performance in cross-sensor cases. (2) $\textit{Low Generalization
Cost}$: it achieves sub-second training and inference, requiring only partial
test inputs and no external data, whereas prior methods often take minutes or
even hours. Experiments on the real-world data from multiple datasets
demonstrate that our method achieves state-of-the-art quality and efficiency in
tackling cross-sensor degradation. For example, training and inference of
$512\times512\times8$ image within $\textit{0.2 seconds}$ and
$4000\times4000\times8$ image within $\textit{3 seconds}$ at the fastest
setting on a commonly used RTX 3090 GPU, which is over 100 times faster than
zero-shot methods.

</details>


### [108] [DIP-GS: Deep Image Prior For Gaussian Splatting Sparse View Recovery](https://arxiv.org/abs/2508.07372)
*Rajaei Khatib,Raja Giryes*

Main category: cs.CV

TL;DR: DIP-GS是一种新的3D高斯溅射方法，它使用深度图像先验来解决稀疏视图重建问题，并在各种任务上取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 解决3DGS在稀疏视图重建方面的不足，即输入视图稀疏、未完全覆盖场景且重叠度低的问题。

Method: 提出了一种深度图像先验（DIP）3DGS表示方法，利用DIP先验以粗到精的方式运行，可以在原始3DGS失败的情况下运行，例如稀疏视图恢复。该方法不使用任何预训练模型，如生成模型或深度估计，仅依赖输入帧。

Result: DIP-GS可以运行在原始3DGS失败的情况下，例如稀疏视图恢复，并在各种稀疏视图重建任务上取得了最先进的竞争性结果。

Conclusion: DIP-GS在各种稀疏视图重建任务上取得了最先进的竞争性结果，证明了其能力。

Abstract: 3D Gaussian Splatting (3DGS) is a leading 3D scene reconstruction method,
obtaining high-quality reconstruction with real-time rendering runtime
performance. The main idea behind 3DGS is to represent the scene as a
collection of 3D gaussians, while learning their parameters to fit the given
views of the scene. While achieving superior performance in the presence of
many views, 3DGS struggles with sparse view reconstruction, where the input
views are sparse and do not fully cover the scene and have low overlaps. In
this paper, we propose DIP-GS, a Deep Image Prior (DIP) 3DGS representation. By
using the DIP prior, which utilizes internal structure and patterns, with
coarse-to-fine manner, DIP-based 3DGS can operate in scenarios where vanilla
3DGS fails, such as sparse view recovery. Note that our approach does not use
any pre-trained models such as generative models and depth estimation, but
rather relies only on the input frames. Among such methods, DIP-GS obtains
state-of-the-art (SOTA) competitive results on various sparse-view
reconstruction tasks, demonstrating its capabilities.

</details>


### [109] [LET-US: Long Event-Text Understanding of Scenes](https://arxiv.org/abs/2508.07401)
*Rui Chen,Xingyu Chen,Shaoan Wang,Shihan Kong,Junzhi Yu*

Main category: cs.CV

TL;DR: LET-US是一个用于长事件流文本理解的框架，通过自适应压缩和多阶段优化处理事件数据，并构建了大规模数据集和基准测试，在性能上超越了现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型(MLLMs)在理解和分析RGB视频内容方面取得了显著成功，但它们在有效解释事件流或处理短序列方面存在局限性。本研究旨在通过LET-US框架实现对长事件流文本的理解。

Method: LET-US采用自适应压缩机制处理长事件流，并使用两阶段优化范式、文本引导的跨模态查询、分层聚类和相似性计算来弥合事件流和文本表示之间的模态差距。

Result: LET-US在长时事件流的描述准确性和语义理解方面均优于先前最先进的多模态大语言模型(MLLMs)。

Conclusion: LET-US在描述准确性和语义理解方面均优于先前最先进的}(\textbf{MLLMs})，在处理长时事件流方面。

Abstract: Event cameras output event streams as sparse, asynchronous data with
microsecond-level temporal resolution, enabling visual perception with low
latency and a high dynamic range. While existing Multimodal Large Language
Models (MLLMs) have achieved significant success in understanding and analyzing
RGB video content, they either fail to interpret event streams effectively or
remain constrained to very short sequences. In this paper, we introduce LET-US,
a framework for long event-stream--text comprehension that employs an adaptive
compression mechanism to reduce the volume of input events while preserving
critical visual details. LET-US thus establishes a new frontier in cross-modal
inferential understanding over extended event sequences. To bridge the
substantial modality gap between event streams and textual representations, we
adopt a two-stage optimization paradigm that progressively equips our model
with the capacity to interpret event-based scenes. To handle the voluminous
temporal information inherent in long event streams, we leverage text-guided
cross-modal queries for feature reduction, augmented by hierarchical clustering
and similarity computation to distill the most representative event features.
Moreover, we curate and construct a large-scale event-text aligned dataset to
train our model, achieving tighter alignment of event features within the LLM
embedding space. We also develop a comprehensive benchmark covering a diverse
set of tasks -- reasoning, captioning, classification, temporal localization
and moment retrieval. Experimental results demonstrate that LET-US outperforms
prior state-of-the-art MLLMs in both descriptive accuracy and semantic
comprehension on long-duration event streams. All datasets, codes, and models
will be publicly available.

</details>


### [110] [ForensicsSAM: Toward Robust and Unified Image Forgery Detection and Localization Resisting to Adversarial Attack](https://arxiv.org/abs/2508.07402)
*Rongxuan Peng,Shunquan Tan,Chenqi Kong,Anwei Luo,Alex C. Kot,Jiwu Huang*

Main category: cs.CV

TL;DR: ForensicsSAM是一个集成了对抗性鲁棒性的统一图像伪影检测与定位框架，通过引入伪影专家和自适应激活的对抗性专家，有效解决了现有PEFT方法易受攻击的问题，并在实验中取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的参数高效微调（PEFT）方法在适应大型视觉基础模型时，容易受到对抗性攻击的影响，从而损害下游任务（如图像伪影检测与定位）的性能。

Method: ForensicsSAM框架通过注入伪影专家和对抗性专家来增强模型的伪影捕获能力和对抗性鲁棒性，并设计了一个轻量级对抗性检测器来识别和对抗扰动。

Result: 实验证明，ForensicsSAM在多个基准测试中，相比现有方法，能更有效地抵御多种对抗性攻击，并且在图像伪影检测和定位任务上达到了最先进的水平。

Conclusion: ForensicsSAM框架在抵御多种对抗性攻击方面表现出卓越的鲁棒性，同时在图像级和像素级伪影检测任务上取得了先进的性能。

Abstract: Parameter-efficient fine-tuning (PEFT) has emerged as a popular strategy for
adapting large vision foundation models, such as the Segment Anything Model
(SAM) and LLaVA, to downstream tasks like image forgery detection and
localization (IFDL). However, existing PEFT-based approaches overlook their
vulnerability to adversarial attacks. In this paper, we show that highly
transferable adversarial images can be crafted solely via the upstream model,
without accessing the downstream model or training data, significantly
degrading the IFDL performance. To address this, we propose ForensicsSAM, a
unified IFDL framework with built-in adversarial robustness. Our design is
guided by three key ideas: (1) To compensate for the lack of forgery-relevant
knowledge in the frozen image encoder, we inject forgery experts into each
transformer block to enhance its ability to capture forgery artifacts. These
forgery experts are always activated and shared across any input images. (2) To
detect adversarial images, we design an light-weight adversary detector that
learns to capture structured, task-specific artifact in RGB domain, enabling
reliable discrimination across various attack methods. (3) To resist
adversarial attacks, we inject adversary experts into the global attention
layers and MLP modules to progressively correct feature shifts induced by
adversarial noise. These adversary experts are adaptively activated by the
adversary detector, thereby avoiding unnecessary interference with clean
images. Extensive experiments across multiple benchmarks demonstrate that
ForensicsSAM achieves superior resistance to various adversarial attack
methods, while also delivering state-of-the-art performance in image-level
forgery detection and pixel-level forgery localization. The resource is
available at https://github.com/siriusPRX/ForensicsSAM.

</details>


### [111] [CharacterShot: Controllable and Consistent 4D Character Animation](https://arxiv.org/abs/2508.07409)
*Junyao Gao,Jiaxing Li,Wenran Liu,Yanhong Zeng,Fei Shen,Kai Chen,Yanan Sun,Cairong Zhao*

Main category: cs.CV

TL;DR: CharacterShot是一个创新的4D角色动画框架，能够从单个图像和2D姿态创建动态3D角色，并提供高度的可控性和一致性。


<details>
  <summary>Details</summary>
Motivation: 提出一个允许任何个人设计师从单个参考角色图像和2D姿态序列创建动态3D角色（即4D角色动画）的可控且一致的4D角色动画框架。

Method: CharacterShot首先训练一个基于DiT的2D图像到视频模型，然后通过引入偶极注意力模块和相机先验将2D动画模型提升到3D，最后利用新颖的邻域约束4D高斯泼溅优化来生成4D表示。

Result: CharacterShot框架能够生成连续且稳定的4D角色表示，并且在CharacterBench基准上实现了优于现有最先进方法的性能。

Conclusion: CharacterShot能够从单个角色图像和2D姿态序列生成一致且可控的4D角色动画，并在CharacterBench基准上超越了现有方法。

Abstract: In this paper, we propose \textbf{CharacterShot}, a controllable and
consistent 4D character animation framework that enables any individual
designer to create dynamic 3D characters (i.e., 4D character animation) from a
single reference character image and a 2D pose sequence. We begin by
pretraining a powerful 2D character animation model based on a cutting-edge
DiT-based image-to-video model, which allows for any 2D pose sequnce as
controllable signal. We then lift the animation model from 2D to 3D through
introducing dual-attention module together with camera prior to generate
multi-view videos with spatial-temporal and spatial-view consistency. Finally,
we employ a novel neighbor-constrained 4D gaussian splatting optimization on
these multi-view videos, resulting in continuous and stable 4D character
representations. Moreover, to improve character-centric performance, we
construct a large-scale dataset Character4D, containing 13,115 unique
characters with diverse appearances and motions, rendered from multiple
viewpoints. Extensive experiments on our newly constructed benchmark,
CharacterBench, demonstrate that our approach outperforms current
state-of-the-art methods. Code, models, and datasets will be publicly available
at https://github.com/Jeoyal/CharacterShot.

</details>


### [112] [Investigating the Design Space of Visual Grounding in Multimodal Large Language Model](https://arxiv.org/abs/2508.08066)
*Weitai Kang,Weiming Zhuang,Zhizhong Li,Yan Yan,Lingjuan Lyu*

Main category: cs.CV

TL;DR: 本研究系统地研究了影响多模态大语言模型（MLLMs）在视觉基础（VG）任务上表现的设计选择，并通过对LLaVA-1.5进行优化，在RefCOCO/+/g数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有模型在微调多模态大语言模型（MLLMs）以解决视觉基础（VG）问题时，采用了多种不同的设计选择，但缺乏系统的验证来支撑这些设计。本研究旨在弥合这一差距，对影响VG性能的设计选择进行全面研究。

Method: 本研究对LLaVA-1.5模型在视觉基础任务上的多种设计选择进行了全面的分析，包括探索不同的视觉基础范式和进行接地数据设计的剥离研究，旨在优化模型微调过程。

Result: 本研究通过在LLaVA-1.5模型上进行系统性分析和消融研究，确定了最优的视觉基础范式和接地数据设计，最终在RefCOCO/+/g数据集上取得了+5.6%/+6.9%/+7.0%的性能提升，为VG任务提供了更强的MLLM。

Conclusion: 本研究通过对LLaVA-1.5在视觉基础任务上的不同设计选择进行系统性验证，优化了多模态大语言模型（MLLMs）在视觉基础（VG）任务上的表现，并在RefCOCO/+/g数据集上实现了+5.6%/+6.9%/+7.0%的性能提升。

Abstract: Fine-grained multimodal capability in Multimodal Large Language Models
(MLLMs) has emerged as a critical research direction, particularly for tackling
the visual grounding (VG) problem. Despite the strong performance achieved by
existing approaches, they often employ disparate design choices when
fine-tuning MLLMs for VG, lacking systematic verification to support these
designs. To bridge this gap, this paper presents a comprehensive study of
various design choices that impact the VG performance of MLLMs. We conduct our
analysis using LLaVA-1.5, which has been widely adopted in prior empirical
studies of MLLMs. While more recent models exist, we follow this convention to
ensure our findings remain broadly applicable and extendable to other
architectures. We cover two key aspects: (1) exploring different visual
grounding paradigms in MLLMs, identifying the most effective design, and
providing our insights; and (2) conducting ablation studies on the design of
grounding data to optimize MLLMs' fine-tuning for the VG task. Finally, our
findings contribute to a stronger MLLM for VG, achieving improvements of +5.6%
/ +6.9% / +7.0% on RefCOCO/+/g over the LLaVA-1.5.

</details>


### [113] [CLUE: Leveraging Low-Rank Adaptation to Capture Latent Uncovered Evidence for Image Forgery Localization](https://arxiv.org/abs/2508.07413)
*Youqi Wang,Shunquan Tan,Rongxuan Peng,Bin Li,Jiwu Huang*

Main category: cs.CV

TL;DR: CLUE利用SD3和SAM，通过操纵潜在表征和结合语义信息来检测伪造图像，效果优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 随着图像编辑工具和生成式AI的普及，数字媒体的真实性受到越来越严重的威胁，需要更有效的伪造检测方法。

Method: CLUE框架利用Stable Diffusion 3（SD3）的Rectified Flow（RF）机制，通过在潜在空间注入不同强度的噪声，引导LoRA微调后的去噪过程，以增强伪造的统计不一致性。同时，结合经过参数高效适配的Segment Anything Model（SAM）的图像编码器，提取高层语义和空间细节，精确勾勒伪造区域边界。

Result: CLUE在广泛的评估中取得了最先进的泛化性能，显著超越了先前的方法，并且在面对常见的后处理攻击和在线社交网络（OSNs）时表现出更强的鲁棒性。

Conclusion: CLUE在应对数字媒体伪造方面展现了卓越的泛化能力和鲁棒性，显著优于现有方法，并能有效抵御后处理和社交网络平台的攻击。

Abstract: The increasing accessibility of image editing tools and generative AI has led
to a proliferation of visually convincing forgeries, compromising the
authenticity of digital media. In this paper, in addition to leveraging
distortions from conventional forgeries, we repurpose the mechanism of a
state-of-the-art (SOTA) text-to-image synthesis model by exploiting its
internal generative process, turning it into a high-fidelity forgery
localization tool. To this end, we propose CLUE (Capture Latent Uncovered
Evidence), a framework that employs Low- Rank Adaptation (LoRA) to
parameter-efficiently reconfigure Stable Diffusion 3 (SD3) as a forensic
feature extractor. Our approach begins with the strategic use of SD3's
Rectified Flow (RF) mechanism to inject noise at varying intensities into the
latent representation, thereby steering the LoRAtuned denoising process to
amplify subtle statistical inconsistencies indicative of a forgery. To
complement the latent analysis with high-level semantic context and precise
spatial details, our method incorporates contextual features from the image
encoder of the Segment Anything Model (SAM), which is parameter-efficiently
adapted to better trace the boundaries of forged regions. Extensive evaluations
demonstrate CLUE's SOTA generalization performance, significantly outperforming
prior methods. Furthermore, CLUE shows superior robustness against common
post-processing attacks and Online Social Networks (OSNs). Code is publicly
available at https://github.com/SZAISEC/CLUE.

</details>


### [114] [Freeze and Reveal: Exposing Modality Bias in Vision-Language Models](https://arxiv.org/abs/2508.07432)
*Vivek Hruday Kavuri,Vysishtya Karanam,Venkata Jahnavi Venkamsetty,Kriti Madumadukala,Lakshmipathi Balaji Darur,Ponnurangam Kumaraguru*

Main category: cs.CV

TL;DR: 本研究旨在通过反事实数据增强（CDA）和一种新的数据增强方法（DAUDoS）来缓解视觉语言模型中的性别偏见。研究发现CLIP的视觉编码器比PaliGemma2的文本编码器存在更严重的性别偏见，并提出DAUDoS在数据效率方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉语言模型（Vision Language Models, VLMs）在多模态任务中表现出色，但它们也从训练数据中继承了性别偏见，这种偏见可能同时来源于视觉和文本模态。

Method: 本研究通过应用反事实数据增强（CDA）和任务向量（Task Vector）等方法，以及一种新的度量标准“刻板印象程度”（Degree of Stereotypicality, DOS）和相应的缓解方法“使用刻板印象程度的数据增强”（DAUDoS），来解析视觉和文本主干网络对性别偏见的贡献，并减少偏见。

Result: 反事实数据增强（CDA）将性别差距缩小了6%，而DAUDoS缩小了3%，并且DAUDoS仅使用了三分之一的数据。两种方法都将模型正确识别图像中性别的能力提高了3%，其中DAUDoS同样仅使用了不到三分之一的训练数据。

Conclusion: CLIP的视觉编码器存在更严重的性别偏见，而PaliGemma2的文本编码器存在更严重的性别偏见。通过识别偏见来源，我们的工作能够为未来的多模态系统提供更具针对性和更有效的偏见缓解策略。

Abstract: Vision Language Models achieve impressive multi-modal performance but often
inherit gender biases from their training data. This bias might be coming from
both the vision and text modalities. In this work, we dissect the contributions
of vision and text backbones to these biases by applying targeted debiasing
using Counterfactual Data Augmentation and Task Vector methods. Inspired by
data-efficient approaches in hate-speech classification, we introduce a novel
metric, Degree of Stereotypicality and a corresponding debiasing method, Data
Augmentation Using Degree of Stereotypicality - DAUDoS, to reduce bias with
minimal computational cost. We curate a gender annotated dataset and evaluate
all methods on VisoGender benchmark to quantify improvements and identify
dominant source of bias. Our results show that CDA reduces the gender gap by 6%
and DAUDoS by 3% but using only one-third of the data. Both methods also
improve the model's ability to correctly identify gender in images by 3%, with
DAUDoS achieving this improvement using only almost one-third of training data.
From our experiment's, we observed that CLIP's vision encoder is more biased
whereas PaliGemma2's text encoder is more biased. By identifying whether bias
stems more from vision or text encoders, our work enables more targeted and
effective bias mitigation strategies in future multi-modal systems.

</details>


### [115] [Levarging Learning Bias for Noisy Anomaly Detection](https://arxiv.org/abs/2508.07441)
*Yuxin Zhang,Yunkang Cao,Yuqi Cheng,Yihan Sun,Weiming Shen*

Main category: cs.CV

TL;DR: 该研究提出了一种两阶段框架，通过利用模型学习偏差来解决无监督图像异常检测中的数据污染问题。该方法通过数据净化提高了检测性能，并证明了其在实际应用中的有效性和通用性。


<details>
  <summary>Details</summary>
Motivation: 解决在训练数据可能包含未标记异常值的全无监督图像异常检测（FUIAD）的挑战。现有方法假设训练数据不包含异常值，但实际中的污染会导致模型将异常值学习为正常值，从而降低检测性能。

Method: 提出了一种两阶段框架，该框架系统地利用了模型中固有的学习偏差。第一阶段将训练集划分为子集，训练子模型，并聚合跨模型异常分数以筛选纯净数据集。第二阶段在该数据集上训练最终的检测器。

Result: 在Real-IAD基准测试中，该方法在不同的噪声条件下展示了优越的异常检测和定位性能。模型对污染具有鲁棒性，并且可以与不同的无监督骨干网络兼容。

Conclusion: 该框架能够有效地处理包含异常值的训练数据，并在各种噪声条件下实现优越的异常检测和定位性能。此外，该框架对模型具有通用性，可与不同的无监督骨干网络兼容，为实际应用提供了可行的解决方案。

Abstract: This paper addresses the challenge of fully unsupervised image anomaly
detection (FUIAD), where training data may contain unlabeled anomalies.
Conventional methods assume anomaly-free training data, but real-world
contamination leads models to absorb anomalies as normal, degrading detection
performance. To mitigate this, we propose a two-stage framework that
systematically exploits inherent learning bias in models. The learning bias
stems from: (1) the statistical dominance of normal samples, driving models to
prioritize learning stable normal patterns over sparse anomalies, and (2)
feature-space divergence, where normal data exhibit high intra-class
consistency while anomalies display high diversity, leading to unstable model
responses. Leveraging the learning bias, stage 1 partitions the training set
into subsets, trains sub-models, and aggregates cross-model anomaly scores to
filter a purified dataset. Stage 2 trains the final detector on this dataset.
Experiments on the Real-IAD benchmark demonstrate superior anomaly detection
and localization performance under different noise conditions. Ablation studies
further validate the framework's contamination resilience, emphasizing the
critical role of learning bias exploitation. The model-agnostic design ensures
compatibility with diverse unsupervised backbones, offering a practical
solution for real-world scenarios with imperfect training data. Code is
available at https://github.com/hustzhangyuxin/LLBNAD.

</details>


### [116] [Health Care Waste Classification Using Deep Learning Aligned with Nepal's Bin Color Guidelines](https://arxiv.org/abs/2508.07450)
*Suman Kunwar,Prabesh Rai*

Main category: cs.CV

TL;DR: 本研究评估了多种模型在尼泊尔医疗废物分类中的表现，YOLOv5-s准确率最高（95.06%），YOLOv8-n速度最快，并将YOLOv5-s部署到Web端。


<details>
  <summary>Details</summary>
Motivation: 为了应对尼泊尔医疗保健设施增加带来的医疗废物管理挑战，特别是由于不当分类和处置导致的污染、传染病传播和对废物处理人员的风险，本研究旨在评估和部署先进的废物分类模型。

Method: 本研究采用了包括ResNeXt-50、EfficientNet-B0、MobileNetV3-S、YOLOv8-n和YOLOv5-s在内的多种废物分类模型，并使用5折分层K折交叉验证技术进行评估。通过重复测量方差分析（ANOVA）检验了统计学显著性。

Result: YOLOv5-s模型在准确率上取得了95.06%的最佳表现，而YOLOv8-n在推理速度上略胜一筹。EfficientNet-B0准确率为93.22%，但推理时间最长。

Conclusion: 研究表明，YOLOv5-s在处理尼泊尔医疗废物分类任务中表现最佳，准确率达到95.06%，但YOLOv8-n在推理速度上稍快。EfficientNet-B0也有不错的表现，准确率为93.22%，但推理时间最长。最终，YOLOv5-s模型被部署到Web端，并结合尼泊尔医疗废物管理标准进行了可视化。

Abstract: The increasing number of Health Care facilities in Nepal has also added up
the challenges on managing health care waste (HCW). Improper segregation and
disposal of HCW leads to the contamination, spreading of infectious diseases
and puts a risk of waste handlers. This study benchmarks the state of the art
waste classification models: ResNeXt-50, EfficientNet-B0, MobileNetV3-S,
YOLOv8-n and YOLOv5-s using Stratified K-fold techniques where we use 5 folds
on combined HCW data, and found that the YOLOv5-s achieved higher of 95.06%
accuracy but fell short few milliseconds in inference speed with YOLOv8-n
model. The EfficientNet-B0 showed promising results of 93.22% accuracy but took
the highest inference time. A repetitive ANOVA was performed to see statistical
significance and the best performing model (YOLOv5-s) was deployed to the web
with mapped bin color using Nepal's HCW management standards for public usage.
Further work on the data was suggested along with localized context.

</details>


### [117] [AURA: A Fine-Grained Benchmark and Decomposed Metric for Audio-Visual Reasoning](https://arxiv.org/abs/2508.07470)
*Siminfar Samakoush Galougah,Rishie Raj,Sanjoy Chowdhury,Sayan Nag,Ramani Duraiswami*

Main category: cs.CV

TL;DR: AURA基准和AuraScore指标旨在解决当前音视频多模态模型推理评估的不足。研究发现，尽管模型准确率高，但推理过程存在缺陷，强调了更可靠的多模态评估的必要性。


<details>
  <summary>Details</summary>
Motivation: 当前的音视频（AV）基准过于关注最终答案的准确性，忽略了潜在的推理过程，这使得区分真实理解和基于错误推理或幻觉得出的正确答案变得困难。为了解决这个问题，需要一个能够评估跨模态推理能力的基准。

Method: 本研究引入了AURA基准，包含六个具有挑战性的认知领域，这些问题被设计为无法仅凭单一模态回答，从而强制模型结合音频和视频信息进行推理。此外，提出了一种名为AuraScore的新型评估指标，用于评估推理轨迹，该指标包含事实一致性和核心推理两个方面。

Result: 在AURA基准上对最先进模型的评估结果显示，模型虽然在某些任务上达到了高达92%的准确率，但其事实一致性和核心推理得分却低于45%，这揭示了模型在推理方面存在的严重不足。

Conclusion: 本研究提出了AURA基准和AuraScore指标，旨在评估和改进多模态大语言模型（AV-LLMs和OLMs）的跨模态推理能力。研究发现，尽管现有模型在最终答案准确率上表现良好，但其事实一致性和核心推理能力存在显著差距，表明模型常通过有缺陷的逻辑得出正确答案。

Abstract: Current audio-visual (AV) benchmarks focus on final answer accuracy,
overlooking the underlying reasoning process. This makes it difficult to
distinguish genuine comprehension from correct answers derived through flawed
reasoning or hallucinations. To address this, we introduce AURA (Audio-visual
Understanding and Reasoning Assessment), a benchmark for evaluating the
cross-modal reasoning capabilities of Audio-Visual Large Language Models
(AV-LLMs) and Omni-modal Language Models (OLMs). AURA includes questions across
six challenging cognitive domains, such as causality, timbre and pitch, tempo
and AV synchronization, unanswerability, implicit distractions, and skill
profiling, explicitly designed to be unanswerable from a single modality. This
forces models to construct a valid logical path grounded in both audio and
video, setting AURA apart from AV datasets that allow uni-modal shortcuts. To
assess reasoning traces, we propose a novel metric, AuraScore, which addresses
the lack of robust tools for evaluating reasoning fidelity. It decomposes
reasoning into two aspects: (i) Factual Consistency - whether reasoning is
grounded in perceptual evidence, and (ii) Core Inference - the logical validity
of each reasoning step. Evaluations of SOTA models on AURA reveal a critical
reasoning gap: although models achieve high accuracy (up to 92% on some tasks),
their Factual Consistency and Core Inference scores fall below 45%. This
discrepancy highlights that models often arrive at correct answers through
flawed logic, underscoring the need for our benchmark and paving the way for
more robust multimodal evaluation.

</details>


### [118] [Novel View Synthesis with Gaussian Splatting: Impact on Photogrammetry Model Accuracy and Resolution](https://arxiv.org/abs/2508.07483)
*Pranav Chougule*

Main category: cs.CV

TL;DR: 本研究比较了摄影测量和高斯溅射技术在3D重建和视角合成方面的性能。结果显示，高斯溅射在生成新视角方面表现优异，并能提升摄影测量的重建效果，为XR、摄影测量和自动驾驶模拟等领域提供了参考。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在全面比较摄影测量和高斯溅射技术在3D模型重建和视角合成方面的性能，并探索高斯溅射在改进3D重建方面的潜力。

Method: 该研究创建了一个真实世界场景的图像数据集，并使用摄影测量和高斯溅射两种方法构建了3D模型。通过SSIM、PSNR、LPIPS和基于USAF分辨率图的lp/mm分辨率对模型进行了性能评估。此外，研究还开发并增强了一个修改版的高斯溅射存储库，用于渲染在Blender环境中生成的新相机视角。然后，使用包含原始图像和高斯溅射合成的新视角的增强数据集生成了一个新的摄影测量模型，并与仅使用原始图像创建的原始摄影测量模型进行了比较。

Result: 高斯溅射能够生成高质量的新视角，在包括SSIM、PSNR和LPIPS在内的各项评估指标上表现出色。使用高斯溅射生成的新视角改进了摄影测量模型的重建质量。

Conclusion: 研究结果表明，高斯溅射在生成新视角方面非常有效，并有潜力改进基于摄影测量学的3D重建。

Abstract: In this paper, I present a comprehensive study comparing Photogrammetry and
Gaussian Splatting techniques for 3D model reconstruction and view synthesis. I
created a dataset of images from a real-world scene and constructed 3D models
using both methods. To evaluate the performance, I compared the models using
structural similarity index (SSIM), peak signal-to-noise ratio (PSNR), learned
perceptual image patch similarity (LPIPS), and lp/mm resolution based on the
USAF resolution chart. A significant contribution of this work is the
development of a modified Gaussian Splatting repository, which I forked and
enhanced to enable rendering images from novel camera poses generated in the
Blender environment. This innovation allows for the synthesis of high-quality
novel views, showcasing the flexibility and potential of Gaussian Splatting. My
investigation extends to an augmented dataset that includes both original
ground images and novel views synthesized via Gaussian Splatting. This
augmented dataset was employed to generate a new photogrammetry model, which
was then compared against the original photogrammetry model created using only
the original images. The results demonstrate the efficacy of using Gaussian
Splatting to generate novel high-quality views and its potential to improve
photogrammetry-based 3D reconstructions. The comparative analysis highlights
the strengths and limitations of both approaches, providing valuable
information for applications in extended reality (XR), photogrammetry, and
autonomous vehicle simulations. Code is available at
https://github.com/pranavc2255/gaussian-splatting-novel-view-render.git.

</details>


### [119] [VisR-Bench: An Empirical Study on Visual Retrieval-Augmented Generation for Multilingual Long Document Understanding](https://arxiv.org/abs/2508.07493)
*Jian Chen,Ming Li,Jihyung Kil,Chenguang Wang,Tong Yu,Ryan Rossi,Tianyi Zhou,Changyou Chen,Ruiyi Zhang*

Main category: cs.CV

TL;DR: VisR-Bench是一个多语言长文档检索基准，包含35K+问答对，覆盖16种语言。LMMs表现优于其他模型，但在表格和低资源语言方面有待改进。


<details>
  <summary>Details</summary>
Motivation: 填补现有基准测试在多语言文档检索方面的空白，并解决仅限于英文或单页图像问答的问题。

Method: 本研究提出了VisR-Bench，一个包含超过3.5万个高质量问答对的数据集，覆盖1.2K份长文档，支持16种语言和三种问题类型（图形、文本、表格），用于评估驱动式多模态检索。

Result: 评估结果表明，大型多模态语言模型（LMMs）显著优于基于文本和多模态编码器的模型，但在处理表格和低资源语言方面仍面临挑战。

Conclusion: 现有的模型在处理结构化表格和低资源语言方面仍有不足，这指出了多语言视觉检索的关键挑战。

Abstract: Most organizational data in this world are stored as documents, and visual
retrieval plays a crucial role in unlocking the collective intelligence from
all these documents. However, existing benchmarks focus on English-only
document retrieval or only consider multilingual question-answering on a
single-page image. To bridge this gap, we introduce VisR-Bench, a multilingual
benchmark designed for question-driven multimodal retrieval in long documents.
Our benchmark comprises over 35K high-quality QA pairs across 1.2K documents,
enabling fine-grained evaluation of multimodal retrieval. VisR-Bench spans
sixteen languages with three question types (figures, text, and tables),
offering diverse linguistic and question coverage. Unlike prior datasets, we
include queries without explicit answers, preventing models from relying on
superficial keyword matching. We evaluate various retrieval models, including
text-based methods, multimodal encoders, and MLLMs, providing insights into
their strengths and limitations. Our results show that while MLLMs
significantly outperform text-based and multimodal encoder models, they still
struggle with structured tables and low-resource languages, highlighting key
challenges in multilingual visual retrieval.

</details>


### [120] [FormCoach: Lift Smarter, Not Harder](https://arxiv.org/abs/2508.07501)
*Xiaoye Zuo,Nikos Athanasiou,Ginger Delmas,Yiming Huang,Xingyu Fu,Lingjie Liu*

Main category: cs.CV

TL;DR: FormCoach uses AI (VLMs) and a camera to give real-time fitness form feedback at home. Current AI isn't as good as humans, but releasing a dataset and evaluation tools will help improve it.


<details>
  <summary>Details</summary>
Motivation: To address the lack of expert feedback for the growing community of at-home fitness enthusiasts by creating an AI training partner that can provide real-time form correction.

Method: Leveraging vision-language models (VLMs) to analyze user movements captured by a camera, identify form errors, and provide real-time corrections. A web interface showcases this capability. Benchmarking was performed on a dataset of 1,700 expert-annotated user-reference video pairs across 22 exercises.

Result: Benchmarks reveal substantial gaps between current VLMs and human-level coaching in analyzing movement nuances and context. The dataset and evaluation pipeline are released to facilitate further research.

Conclusion: FormCoach transforms a simple camera into an AI training partner that spots form errors and gives corrections in real time, using vision-language models (VLMs). Benchmarks on a dataset of 1,700 expert-annotated user-reference video pairs show significant gaps compared to human coaching, highlighting challenges and opportunities in AI movement analysis. The release of the dataset and evaluation pipeline aims to accelerate research in AI-driven coaching.

Abstract: Good form is the difference between strength and strain, yet for the
fast-growing community of at-home fitness enthusiasts, expert feedback is often
out of reach. FormCoach transforms a simple camera into an always-on,
interactive AI training partner, capable of spotting subtle form errors and
delivering tailored corrections in real time, leveraging vision-language models
(VLMs). We showcase this capability through a web interface and benchmark
state-of-the-art VLMs on a dataset of 1,700 expert-annotated user-reference
video pairs spanning 22 strength and mobility exercises. To accelerate research
in AI-driven coaching, we release both the dataset and an automated,
rubric-based evaluation pipeline, enabling standardized comparison across
models. Our benchmarks reveal substantial gaps compared to human-level
coaching, underscoring both the challenges and opportunities in integrating
nuanced, context-aware movement analysis into interactive AI systems. By
framing form correction as a collaborative and creative process between humans
and machines, FormCoach opens a new frontier in embodied AI.

</details>


### [121] [From Field to Drone: Domain Drift Tolerant Automated Multi-Species and Damage Plant Semantic Segmentation for Herbicide Trials](https://arxiv.org/abs/2508.07514)
*Artzai Picon,Itziar Eguskiza,Daniel Mugica,Javier Romero,Carlos Javier Jimenez,Eric White,Gabriel Do-Lago-Junqueira,Christian Klukas,Ramon Navarra-Mestre*

Main category: cs.CV

TL;DR: 一种新的分割模型通过结合自监督学习和植物分类，显著提高了作物和杂草识别的准确性和效率，并在不同设备和地理区域的野外试验中表现出稳健性，现已应用于BASF的自动化监测系统。


<details>
  <summary>Details</summary>
Motivation: 传统的野外试验依赖于耗时、耗力且主观的人工目视评估，而自动化物种和损害识别因细微的视觉差异而具有挑战性，但能显著提高效率和一致性。

Method: 提出了一种改进的分割模型，结合了通用的自监督视觉模型和基于植物分类体系的层级推理。该模型在包含德国和西班牙多年（2018-2020）的数字和移动相机数据集上进行训练，并在包括美国、德国和西班牙的2023年数字相机数据和2024年无人机影像上进行了测试，以评估其在跨领域变化下的鲁棒性。

Result: 模型在物种识别方面将F1分数从0.52提高到0.85，R方值从0.75提高到0.98；在损害分类方面将F1分数从0.28提高到0.44，R方值从0.71提高到0.87。在无人机影像（跨领域测试）下，该模型仍保持了较强的性能，物种识别F1分数为0.60，R方值为0.80；损害分类F1分数为0.41，R方值为0.62，而先前的方法在此情况下失效。

Conclusion: 该模型在田间试验中表现出稳健性和实际应用潜力，已成功应用于BASF的表型分析流程，实现了跨地域的大规模、自动化作物和杂草监测。

Abstract: Field trials are vital in herbicide research and development to assess
effects on crops and weeds under varied conditions. Traditionally, evaluations
rely on manual visual assessments, which are time-consuming, labor-intensive,
and subjective. Automating species and damage identification is challenging due
to subtle visual differences, but it can greatly enhance efficiency and
consistency.
  We present an improved segmentation model combining a general-purpose
self-supervised visual model with hierarchical inference based on botanical
taxonomy. Trained on a multi-year dataset (2018-2020) from Germany and Spain
using digital and mobile cameras, the model was tested on digital camera data
(year 2023) and drone imagery from the United States, Germany, and Spain (year
2024) to evaluate robustness under domain shift. This cross-device evaluation
marks a key step in assessing generalization across platforms of the model.
  Our model significantly improved species identification (F1-score: 0.52 to
0.85, R-squared: 0.75 to 0.98) and damage classification (F1-score: 0.28 to
0.44, R-squared: 0.71 to 0.87) over prior methods. Under domain shift (drone
images), it maintained strong performance with moderate degradation (species:
F1-score 0.60, R-squared 0.80; damage: F1-score 0.41, R-squared 0.62), where
earlier models failed.
  These results confirm the model's robustness and real-world applicability. It
is now deployed in BASF's phenotyping pipeline, enabling large-scale, automated
crop and weed monitoring across diverse geographies.

</details>


### [122] [Exploring Multimodal Diffusion Transformers for Enhanced Prompt-based Image Editing](https://arxiv.org/abs/2508.07519)
*Joonghyuk Shin,Alchan Hwang,Yujin Kim,Daneul Kim,Jaesik Park*

Main category: cs.CV

TL;DR: MM-DiT的统一注意力机制挑战了现有编辑技术。本文分析了MM-DiT的注意力机制，并提出了一种新的基于提示的编辑方法，能够支持全局到局部编辑和各种MM-DiT变体。


<details>
  <summary>Details</summary>
Motivation: MM-DiT引入的统一注意力机制和双向信息流对现有的编辑技术提出了重大挑战，因此需要新的编辑方法来适应这种新架构。

Method: 本文系统地分析了MM-DiT的注意力机制，通过将注意力矩阵分解为四个不同的块来揭示其固有特性，并在此基础上提出了一种鲁棒的、基于提示的图像编辑方法，支持全局到局部编辑。

Result: 分析了MM-DiT的注意力机制，并提出了一种适用于MM-DiT的鲁棒的、基于提示的图像编辑方法。

Conclusion: 本文提出的基于提示的图像编辑方法能够有效地支持各种MM-DiT变体，包括全局到局部编辑和少样本模型，弥合了现有基于U-Net的方法与新兴架构之间的差距，并提供了对MMDiT行为模式的更深入的见解。

Abstract: Transformer-based diffusion models have recently superseded traditional U-Net
architectures, with multimodal diffusion transformers (MM-DiT) emerging as the
dominant approach in state-of-the-art models like Stable Diffusion 3 and
Flux.1. Previous approaches have relied on unidirectional cross-attention
mechanisms, with information flowing from text embeddings to image latents. In
contrast, MMDiT introduces a unified attention mechanism that concatenates
input projections from both modalities and performs a single full attention
operation, allowing bidirectional information flow between text and image
branches. This architectural shift presents significant challenges for existing
editing techniques. In this paper, we systematically analyze MM-DiT's attention
mechanism by decomposing attention matrices into four distinct blocks,
revealing their inherent characteristics. Through these analyses, we propose a
robust, prompt-based image editing method for MM-DiT that supports global to
local edits across various MM-DiT variants, including few-step models. We
believe our findings bridge the gap between existing U-Net-based methods and
emerging architectures, offering deeper insights into MMDiT's behavioral
patterns.

</details>


### [123] [Enhancing Reliability of Medical Image Diagnosis through Top-rank Learning with Rejection Module](https://arxiv.org/abs/2508.07528)
*Xiaotong Ji,Ryoma Bise,Seiichi Uchida*

Main category: cs.CV

TL;DR: 一种新的方法通过集成拒绝模块来提高医学图像诊断的准确性，该模块可以识别和减轻异常值对训练的影响。


<details>
  <summary>Details</summary>
Motivation: 为了解决带噪标签和类别模糊实例可能错误地排在前列，从而阻碍top-rank学习的问题。

Method: 提出了一种新的方法，通过集成一个拒绝模块来增强top-rank学习，该模块与top-rank损失共同优化，以识别和减轻阻碍训练效果的异常值。拒绝模块作为一个额外的分支，根据衡量其与正常值偏差的拒绝函数来评估实例。

Result: 实验结果表明，该方法在医学数据集上能够有效检测和减轻异常值，提高了医学图像诊断的可靠性和准确性。

Conclusion: 该方法通过集成一个拒绝模块来增强top-rank学习，用于识别和减轻影响训练效果的异常值，从而提高医学图像诊断的可靠性和准确性。

Abstract: In medical image processing, accurate diagnosis is of paramount importance.
Leveraging machine learning techniques, particularly top-rank learning, shows
significant promise by focusing on the most crucial instances. However,
challenges arise from noisy labels and class-ambiguous instances, which can
severely hinder the top-rank objective, as they may be erroneously placed among
the top-ranked instances. To address these, we propose a novel approach that
enhances toprank learning by integrating a rejection module. Cooptimized with
the top-rank loss, this module identifies and mitigates the impact of outliers
that hinder training effectiveness. The rejection module functions as an
additional branch, assessing instances based on a rejection function that
measures their deviation from the norm. Through experimental validation on a
medical dataset, our methodology demonstrates its efficacy in detecting and
mitigating outliers, improving the reliability and accuracy of medical image
diagnoses.

</details>


### [124] [Enhanced Generative Structure Prior for Chinese Text Image Super-resolution](https://arxiv.org/abs/2508.07537)
*Xiaoming Li,Wangmeng Zuo,Chen Change Loy*

Main category: cs.CV

TL;DR: 本研究提出了一种用于中文文本图像超分辨率的框架，通过引入新颖的结构先验和基于码本的StyleGAN模型，有效恢复了低分辨率中文文本的笔画和结构。


<details>
  <summary>Details</summary>
Motivation: 现有文本超分辨率方法主要关注英文，对中文等复杂脚本关注较少。本研究旨在提出一个能恢复中文汉字精确笔画的高质量文本超分辨率框架。

Method: 提出了一种新颖的结构先验，并将其集成到StyleGAN模型中，利用码本机制来控制字符结构和风格，以实现文本图像超分辨率。

Result: 实验证明，该结构先验能提供鲁棒的、针对特定字符的指导，即使是对于具有不规则布局的真实世界低分辨率中文文本，也能准确恢复清晰的笔画。

Conclusion: 该研究提出了一种新颖的结构先验，并将其集成到StyleGAN模型中，通过基于码本的机制来约束生成空间，以实现高质量的中文文本图像超分辨率。

Abstract: Faithful text image super-resolution (SR) is challenging because each
character has a unique structure and usually exhibits diverse font styles and
layouts. While existing methods primarily focus on English text, less attention
has been paid to more complex scripts like Chinese. In this paper, we introduce
a high-quality text image SR framework designed to restore the precise strokes
of low-resolution (LR) Chinese characters. Unlike methods that rely on
character recognition priors to regularize the SR task, we propose a novel
structure prior that offers structure-level guidance to enhance visual quality.
Our framework incorporates this structure prior within a StyleGAN model,
leveraging its generative capabilities for restoration. To maintain the
integrity of character structures while accommodating various font styles and
layouts, we implement a codebook-based mechanism that restricts the generative
space of StyleGAN. Each code in the codebook represents the structure of a
specific character, while the vector $w$ in StyleGAN controls the character's
style, including typeface, orientation, and location. Through the collaborative
interaction between the codebook and style, we generate a high-resolution
structure prior that aligns with LR characters both spatially and structurally.
Experiments demonstrate that this structure prior provides robust,
character-specific guidance, enabling the accurate restoration of clear strokes
in degraded characters, even for real-world LR Chinese text with irregular
layouts. Our code and pre-trained models will be available at
https://github.com/csxmli2016/MARCONetPlusPlus

</details>


### [125] [A DICOM Image De-identification Algorithm in the MIDI-B Challenge](https://arxiv.org/abs/2508.07538)
*Hongzhu Jiang,Sihan Xie,Zhiyu Wan*

Main category: cs.CV

TL;DR: 该研究针对医疗影像（特别是 DICOM 格式）的去标识化问题，提出了多种方法，并在 MICCAI 2024 的 MIDI-B 挑战赛中取得了优异成绩，准确率达 99.92%，排名第二，同时探讨了该领域的挑战与未来方向。


<details>
  <summary>Details</summary>
Motivation: 为了在不损害数据效用的前提下，遵循 HIPAA、DICOM PS3.15 和 TCIA 等法规和标准，保护患者隐私。

Method: 通过像素蒙版、日期移位、日期哈希、文本识别、文本替换和文本移除等方法对 DICOM 图像进行去标识化处理，以符合相关标准。

Result: 文章详述了处理数据集的去标识化方法，并展示了算法在 MIDI-B 挑战赛中的优异表现，准确率达到 99.92%，排名第二。

Conclusion: MIDI-B 挑战赛的最新解决方案算法准确执行了 99.92% 的必要操作，在 10 个完成挑战的团队中排名第二。文章还分析了结果统计数据，并讨论了当前方法的局限性和未来改进的可能途径。

Abstract: Image de-identification is essential for the public sharing of medical
images, particularly in the widely used Digital Imaging and Communications in
Medicine (DICOM) format as required by various regulations and standards,
including Health Insurance Portability and Accountability Act (HIPAA) privacy
rules, the DICOM PS3.15 standard, and best practices recommended by the Cancer
Imaging Archive (TCIA). The Medical Image De-Identification Benchmark (MIDI-B)
Challenge at the 27th International Conference on Medical Image Computing and
Computer Assisted Intervention (MICCAI 2024) was organized to evaluate
rule-based DICOM image de-identification algorithms with a large dataset of
clinical DICOM images. In this report, we explore the critical challenges of
de-identifying DICOM images, emphasize the importance of removing personally
identifiable information (PII) to protect patient privacy while ensuring the
continued utility of medical data for research, diagnostics, and treatment, and
provide a comprehensive overview of the standards and regulations that govern
this process. Additionally, we detail the de-identification methods we applied
- such as pixel masking, date shifting, date hashing, text recognition, text
replacement, and text removal - to process datasets during the test phase in
strict compliance with these standards. According to the final leaderboard of
the MIDI-B challenge, the latest version of our solution algorithm correctly
executed 99.92% of the required actions and ranked 2nd out of 10 teams that
completed the challenge (from a total of 22 registered teams). Finally, we
conducted a thorough analysis of the resulting statistics and discussed the
limitations of current approaches and potential avenues for future improvement.

</details>


### [126] [Domain Generalization of Pathological Image Segmentation by Patch-Level and WSI-Level Contrastive Learning](https://arxiv.org/abs/2508.07539)
*Yuki Shigeyasu,Shota Harada,Akihiko Yoshizawa,Kazuhiro Terada,Naoki Nakazima,Mariyo Kurata,Hiroyuki Abe,Tetsuo Ushiku,Ryoma Bise*

Main category: cs.CV

TL;DR: 本文提出了一种新的方法来处理病理图像中的域移位问题，特别关注同一医院内的变化。该方法通过识别图像中的不同“域”（基于非肿瘤区域的特征聚类），并使用对比学习技术来缩小这些域之间的特征差异。这种方法不需要跨医院数据，有望提高模型在实际应用中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统的域泛化方法通常依赖多医院数据，但数据收集面临挑战且不切实际。因此，本文旨在解决病理图像中的域移位问题，特别是院内（同一医院内）的域移位，如患者特征和组织厚度的变化，而不是跨医院的域移位。

Method: 本文提出了一种基于聚类和两阶段对比学习的域泛化方法。首先，通过聚类WSI（全切片图像）的非肿瘤区域特征来识别和模拟院内域移位，将不同的聚类视为不同的域。然后，应用对比学习来减小这些不同域之间的特征差距，具体采用WSI级别和Patch级别的对比学习策略。

Result: 通过聚类WSI的非肿瘤区域特征并将聚类视为域，并结合WSI级别和Patch级别的对比学习，有效减小了不同域之间的特征差距，从而提高了模型在面临院内域移位时的泛化能力。

Conclusion: 本文提出了一种新的域泛化方法，通过聚类WSIs中的非肿瘤区域特征来捕捉和利用院内域移位，并采用两阶段对比学习来减小不同簇之间WSIs的特征差距，从而有效解决病理图像中的域移位问题。

Abstract: In this paper, we address domain shifts in pathological images by focusing on
shifts within whole slide images~(WSIs), such as patient characteristics and
tissue thickness, rather than shifts between hospitals. Traditional approaches
rely on multi-hospital data, but data collection challenges often make this
impractical. Therefore, the proposed domain generalization method captures and
leverages intra-hospital domain shifts by clustering WSI-level features from
non-tumor regions and treating these clusters as domains. To mitigate domain
shift, we apply contrastive learning to reduce feature gaps between WSI pairs
from different clusters. The proposed method introduces a two-stage contrastive
learning approach WSI-level and patch-level contrastive learning to minimize
these gaps effectively.

</details>


### [127] [CoT-Pose: Chain-of-Thought Reasoning for 3D Pose Generation from Abstract Prompts](https://arxiv.org/abs/2508.07540)
*Junuk Cha,Jihyeon Kim*

Main category: cs.CV

TL;DR: This paper presents CoT-Pose, a new method that uses Chain-of-Thought reasoning to generate 3D human poses from abstract text descriptions, overcoming limitations of previous models that required detailed prompts. It includes a data synthesis pipeline for training and shows promising results in aligning poses with high-level language.


<details>
  <summary>Details</summary>
Motivation: Existing text-to-pose models struggle with abstract, high-level language prompts commonly used by humans to describe actions and intentions, relying instead on detailed low-level prompts that specify joint configurations. This mismatch limits the practical deployment of pose generation systems.

Method: The paper introduces a novel framework that incorporates Chain-of-Thought (CoT) reasoning into the 3D human pose generation process to interpret abstract prompts into accurate 3D poses. It also proposes a data synthesis pipeline to generate triplets of abstract prompts, detailed prompts, and corresponding 3D poses for training.

Result: Experimental results demonstrate that the proposed CoT-Pose model can effectively generate plausible and semantically aligned 3D human poses from abstract textual inputs.

Conclusion: CoT-Pose, a novel framework incorporating CoT reasoning, effectively generates plausible and semantically aligned 3D human poses from abstract textual inputs, highlighting the importance of high-level understanding in pose generation and opening new directions for reasoning-enhanced approaches.

Abstract: Recent advances in multi-modal large language models (MLLMs) and
chain-of-thought (CoT) reasoning have led to significant progress in image and
text generation tasks. However, the field of 3D human pose generation still
faces critical limitations. Most existing text-to-pose models rely heavily on
detailed (low-level) prompts that explicitly describe joint configurations. In
contrast, humans tend to communicate actions and intentions using abstract
(high-level) language. This mismatch results in a practical challenge for
deploying pose generation systems in real-world scenarios. To bridge this gap,
we introduce a novel framework that incorporates CoT reasoning into the pose
generation process, enabling the interpretation of abstract prompts into
accurate 3D human poses. We further propose a data synthesis pipeline that
automatically generates triplets of abstract prompts, detailed prompts, and
corresponding 3D poses for training process. Experimental results demonstrate
that our reasoning-enhanced model, CoT-Pose, can effectively generate plausible
and semantically aligned poses from abstract textual inputs. This work
highlights the importance of high-level understanding in pose generation and
opens new directions for reasoning-enhanced approach for human pose generation.

</details>


### [128] [Commentary Generation for Soccer Highlights](https://arxiv.org/abs/2508.07543)
*Chidaksh Ravuru*

Main category: cs.CV

TL;DR: 本文基于MatchTime的MatchVoice模型，扩展了其在足球集锦评论生成上的应用，并通过实验评估了不同因素对模型性能的影响，指出了未来改进方向。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有自动解说系统在视频内容和解说之间缺乏细粒度对齐的问题，并扩展MatchVoice模型以适应足球集锦的解说生成。

Method: 提出了一种基于MatchVoice模型的足球集锦评论生成方法，并使用GOAL数据集进行了实验，同时探讨了不同训练配置、硬件限制以及窗口大小对零样本性能的影响。

Result: 成功复现了MatchTime的原始结果，并评估了所提出的方法。实验结果表明，MatchVoice具有一定的泛化能力，但仍有提升空间。

Conclusion: MatchVoice在足球集锦评论生成方面展示了良好的泛化能力，但为了进一步提高性能，有必要整合更广泛的视频语言领域的技术。

Abstract: Automated soccer commentary generation has evolved from template-based
systems to advanced neural architectures, aiming to produce real-time
descriptions of sports events. While frameworks like SoccerNet-Caption laid
foundational work, their inability to achieve fine-grained alignment between
video content and commentary remains a significant challenge. Recent efforts
such as MatchTime, with its MatchVoice model, address this issue through coarse
and fine-grained alignment techniques, achieving improved temporal
synchronization. In this paper, we extend MatchVoice to commentary generation
for soccer highlights using the GOAL dataset, which emphasizes short clips over
entire games. We conduct extensive experiments to reproduce the original
MatchTime results and evaluate our setup, highlighting the impact of different
training configurations and hardware limitations. Furthermore, we explore the
effect of varying window sizes on zero-shot performance. While MatchVoice
exhibits promising generalization capabilities, our findings suggest the need
for integrating techniques from broader video-language domains to further
enhance performance. Our code is available at
https://github.com/chidaksh/SoccerCommentary.

</details>


### [129] [Adaptive Pseudo Label Selection for Individual Unlabeled Data by Positive and Unlabeled Learning](https://arxiv.org/abs/2508.07548)
*Takehiro Yamane,Itaru Tsuge,Susumu Saito,Ryoma Bise*

Main category: cs.CV

TL;DR: 提出了一种新颖的PU学习伪标签方法，用于医学图像分割，能够有效选择伪标签。


<details>
  <summary>Details</summary>
Motivation: 为了解决医学图像分割中的伪标签选择问题，特别是处理各种背景区域。

Method: 提出了一种新颖的伪标签方法，并结合了PU学习，以在每个未标记图像上选择有效的伪标签。

Result: 实验结果证明了该方法的有效性。

Conclusion: 该方法在处理各种背景区域的伪标签选择方面具有优势。

Abstract: This paper proposes a novel pseudo-labeling method for medical image
segmentation that can perform learning on ``individual images'' to select
effective pseudo-labels. We introduce Positive and Unlabeled Learning (PU
learning), which uses only positive and unlabeled data for binary
classification problems, to obtain the appropriate metric for discriminating
foreground and background regions on each unlabeled image. Our PU learning
makes us easy to select pseudo-labels for various background regions. The
experimental results show the effectiveness of our method.

</details>


### [130] [Decoupled Functional Evaluation of Autonomous Driving Models via Feature Map Quality Scoring](https://arxiv.org/abs/2508.07552)
*Ludan Zhang,Sihan Wang,Yuqi Dai,Shuofei Qiao,Lei He*

Main category: cs.CV

TL;DR: 本研究提出了一种新颖的评估框架和方法，用于解决自动驾驶端到端模型中中间功能模块可解释性差的问题。通过FMCS和CLIP-FMQE-Net，实现了对特征图质量的量化评估和实时分析，并在实践中有效提升了模型的性能。


<details>
  <summary>Details</summary>
Motivation: 端到端模型在自动驾驶感知和规划中日益普及，但其缺乏对中间功能模块的显式监督信号，导致操作机制不透明、可解释性有限，使得传统方法难以独立评估和训练这些模块。

Method: 提出了一种基于特征图-真值表示相似性的评估框架，并在此基础上开发了特征图收敛得分（FMCS）的独立评估方法。构建了双粒度动态加权评分系统（DG-DWSS）来生成统一的特征图质量评分，并进一步开发了基于CLIP的特征图质量评估网络（CLIP-FMQE-Net），集成了特征-真值编码器和质量分数预测头，以实现对功能模块生成的特征图进行实时质量分析。

Result: 在NuScenes数据集上的实验结果表明，将本研究提出的评估模块集成到训练过程中，可以提高3D目标检测性能，NDS提高了3.89%。这些结果验证了该方法在提升特征表示质量和整体模型性能方面的有效性。

Conclusion: 该研究提出的基于FMCS和CLIP-FMQE-Net的评估方法，能够有效提升自动驾驶感知和规划任务中端到端模型特征图的质量，进而提高3D目标检测性能，在NuScenes数据集上实现了3.89%的NDS提升。

Abstract: End-to-end models are emerging as the mainstream in autonomous driving
perception and planning. However, the lack of explicit supervision signals for
intermediate functional modules leads to opaque operational mechanisms and
limited interpretability, making it challenging for traditional methods to
independently evaluate and train these modules. Pioneering in the issue, this
study builds upon the feature map-truth representation similarity-based
evaluation framework and proposes an independent evaluation method based on
Feature Map Convergence Score (FMCS). A Dual-Granularity Dynamic Weighted
Scoring System (DG-DWSS) is constructed, formulating a unified quantitative
metric - Feature Map Quality Score - to enable comprehensive evaluation of the
quality of feature maps generated by functional modules. A CLIP-based Feature
Map Quality Evaluation Network (CLIP-FMQE-Net) is further developed, combining
feature-truth encoders and quality score prediction heads to enable real-time
quality analysis of feature maps generated by functional modules. Experimental
results on the NuScenes dataset demonstrate that integrating our evaluation
module into the training improves 3D object detection performance, achieving a
3.89 percent gain in NDS. These results verify the effectiveness of our method
in enhancing feature representation quality and overall model performance.

</details>


### [131] [Splat4D: Diffusion-Enhanced 4D Gaussian Splatting for Temporally and Spatially Consistent Content Creation](https://arxiv.org/abs/2508.07557)
*Minghao Yin,Yukang Cao,Songyou Peng,Kai Han*

Main category: cs.CV

TL;DR: Splat4D 框架利用多视图渲染、不一致性识别、视频扩散模型和非对称 U-Net，从单目视频生成高质量 4D 内容，克服了时间和空间一致性、细节保留和用户指导的挑战，并在各种应用中表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了克服从单目视频生成高质量 4D 内容时在时间空间一致性、细节保留和用户指导方面的挑战。

Method: Splat4D 框架采用了多视图渲染、不一致性识别、视频扩散模型和非对称 U-Net 等技术来生成 4D 内容。

Result: Splat4D 在各项指标上都展示了最先进的性能，并且在文本/图像条件 4D 生成、4D 人体生成和文本引导内容编辑等应用中表现出了通用性。

Conclusion: Splat4D 框架通过多视图渲染、不一致性识别、视频扩散模型和非对称 U-Net 实现了从单目视频生成高质量 4D 内容，并在空间-时间一致性、细节保留和用户指导方面取得了优于现有技术的性能。

Abstract: Generating high-quality 4D content from monocular videos for applications
such as digital humans and AR/VR poses challenges in ensuring temporal and
spatial consistency, preserving intricate details, and incorporating user
guidance effectively. To overcome these challenges, we introduce Splat4D, a
novel framework enabling high-fidelity 4D content generation from a monocular
video. Splat4D achieves superior performance while maintaining faithful
spatial-temporal coherence by leveraging multi-view rendering, inconsistency
identification, a video diffusion model, and an asymmetric U-Net for
refinement. Through extensive evaluations on public benchmarks, Splat4D
consistently demonstrates state-of-the-art performance across various metrics,
underscoring the efficacy of our approach. Additionally, the versatility of
Splat4D is validated in various applications such as text/image conditioned 4D
generation, 4D human generation, and text-guided content editing, producing
coherent outcomes following user instructions.

</details>


### [132] [Adaptive Cache Enhancement for Test-Time Adaptation of Vision-Language Models](https://arxiv.org/abs/2508.07570)
*Khanh-Binh Nguyen,Phuoc-Nguyen Bui,Hyunseung Choo,Duc Thanh Nguyen*

Main category: cs.CV

TL;DR: ACE框架通过自适应的、类别的缓存策略，解决了现有TTA方法在分布外数据上的性能下降问题，提高了鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于缓存的TTA方法在分布转变下会因为不可靠的置信度指标导致错误累积，并且僵化的决策边界无法适应显著的分布变化，导致次优预测。ACE旨在克服这些限制。

Method: ACE框架通过动态的、类特定的阈值来选择性地存储高置信度或低熵的类别图像嵌入，这些阈值从零样本统计数据初始化，并使用指数移动平均和探索增强更新进行迭代优化。这种方法实现了自适应的、类别的决策边界。

Result: ACE框架通过选择性存储高置信度或低熵的类别图像嵌入，实现了自适应的、类别的决策边界，从而在不同的视觉分布下实现鲁棒且准确的预测。

Conclusion: ACE框架在15个不同的基准数据集上取得了最先进的性能，在具有挑战性的分布外场景中，与现有的TTA方法相比，展现出优越的鲁棒性和泛化能力。

Abstract: Vision-language models (VLMs) exhibit remarkable zero-shot generalization but
suffer performance degradation under distribution shifts in downstream tasks,
particularly in the absence of labeled data. Test-Time Adaptation (TTA)
addresses this challenge by enabling online optimization of VLMs during
inference, eliminating the need for annotated data. Cache-based TTA methods
exploit historical knowledge by maintaining a dynamic memory cache of
low-entropy or high-confidence samples, promoting efficient adaptation to
out-of-distribution data. Nevertheless, these methods face two critical
challenges: (1) unreliable confidence metrics under significant distribution
shifts, resulting in error accumulation within the cache and degraded
adaptation performance; and (2) rigid decision boundaries that fail to
accommodate substantial distributional variations, leading to suboptimal
predictions. To overcome these limitations, we introduce the Adaptive Cache
Enhancement (ACE) framework, which constructs a robust cache by selectively
storing high-confidence or low-entropy image embeddings per class, guided by
dynamic, class-specific thresholds initialized from zero-shot statistics and
iteratively refined using an exponential moving average and
exploration-augmented updates. This approach enables adaptive, class-wise
decision boundaries, ensuring robust and accurate predictions across diverse
visual distributions. Extensive experiments on 15 diverse benchmark datasets
demonstrate that ACE achieves state-of-the-art performance, delivering superior
robustness and generalization compared to existing TTA methods in challenging
out-of-distribution scenarios.

</details>


### [133] [Exploiting Layer Normalization Fine-tuning in Visual Transformer Foundation Models for Classification](https://arxiv.org/abs/2508.07577)
*Zhaorui Tan,Tan Pan,Kaizhu Huang,Weimiao Yu,Kai Yao,Chen Jiang,Qiufeng Wang,Anh Nguyen,Xin Guo,Yuan Cheng,Xi Yang*

Main category: cs.CV

TL;DR: 本研究针对Vision Transformers在数据匮乏和领域变化下的微调问题，提出了一种通过LayerNorm参数调整（LayerNorm shifts）来提升模型性能的方法，并引入了Fine-tuning Shift Ratio (FSR)和重适机制（λ），在多项实验中验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers中的LayerNorm在数据稀疏和领域迁移的微调动态方面研究不足，本研究旨在探讨LayerNorm参数微调后的变化（LayerNorm shifts）如何指示领域迁移，并提出改进方法。

Method: 提出了一种使用标量λ的重适机制，该标量与FSR负相关，以对齐学习到的LayerNorm位移和在完全代表性数据下实现的理想位移，并结合了增强LayerNorm微调的周期性框架。

Result: 通过在自然和病理图像上的广泛实验，包括 in-distribution (ID) 和 out-of-distribution (OOD) 设置以及不同的目标训练样本数量，验证了所提出框架的有效性。结果表明，OOD任务通常具有较低的FSR和较高的λ，尤其是在数据稀疏的情况下，表明目标训练样本的代表性不足；同时，在病理数据上微调的ViTFs表现更像ID设置，倾向于保守的LayerNorm更新。

Conclusion: 本研究提出了一个基于LayerNorm参数调整的简单有效的方法，以提升Vision Transformers在数据稀疏和领域迁移场景下的微调性能，并通过Fine-tuning Shift Ratio (FSR)量化了目标训练样本的领域代表性，为LayerNorm在迁移学习中的应用提供了实用的策略。

Abstract: LayerNorm is pivotal in Vision Transformers (ViTs), yet its fine-tuning
dynamics under data scarcity and domain shifts remain underexplored. This paper
shows that shifts in LayerNorm parameters after fine-tuning (LayerNorm shifts)
are indicative of the transitions between source and target domains; its
efficacy is contingent upon the degree to which the target training samples
accurately represent the target domain, as quantified by our proposed
Fine-tuning Shift Ratio ($FSR$). Building on this, we propose a simple yet
effective rescaling mechanism using a scalar $\lambda$ that is negatively
correlated to $FSR$ to align learned LayerNorm shifts with those ideal shifts
achieved under fully representative data, combined with a cyclic framework that
further enhances the LayerNorm fine-tuning. Extensive experiments across
natural and pathological images, in both in-distribution (ID) and
out-of-distribution (OOD) settings, and various target training sample regimes
validate our framework. Notably, OOD tasks tend to yield lower $FSR$ and higher
$\lambda$ in comparison to ID cases, especially with scarce data, indicating
under-represented target training samples. Moreover, ViTFs fine-tuned on
pathological data behave more like ID settings, favoring conservative LayerNorm
updates. Our findings illuminate the underexplored dynamics of LayerNorm in
transfer learning and provide practical strategies for LayerNorm fine-tuning.

</details>


### [134] [GAPNet: A Lightweight Framework for Image and Video Salient Object Detection via Granularity-Aware Paradigm](https://arxiv.org/abs/2508.07585)
*Yu-Huan Wu,Wei Liu,Zi-Xuan Zhu,Zizhou Wang,Yong Liu,Liangli Zhen*

Main category: cs.CV

TL;DR: GAPNet 是一种轻量级的图像和视频显著目标检测模型，通过创新的特征融合和多尺度监督，在保持低计算成本的同时提高了检测精度。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前显著目标检测（SOD）模型依赖重型骨干网络导致计算成本高昂，在边缘设备等实际应用中受到限制的问题。

Method: GAPNet 采用基于粒度感知范式的方法，并设计了粒度金字塔卷积（GPC）和跨尺度注意力（CSA）模块来实现高效特征融合。模型在多尺度解码器中使用不同粒度的显著图进行监督，并通过自注意力模块学习全局信息以实现精确的目标定位。

Result: GAPNet 在作为轻量级图像和视频 SOD 模型方面取得了最先进的性能。

Conclusion: GAPNet 在图像和视频显著目标检测（SOD）方面取得了新的最先进的性能，并且是一种轻量级模型。

Abstract: Recent salient object detection (SOD) models predominantly rely on
heavyweight backbones, incurring substantial computational cost and hindering
their practical application in various real-world settings, particularly on
edge devices. This paper presents GAPNet, a lightweight network built on the
granularity-aware paradigm for both image and video SOD. We assign saliency
maps of different granularities to supervise the multi-scale decoder
side-outputs: coarse object locations for high-level outputs and fine-grained
object boundaries for low-level outputs. Specifically, our decoder is built
with granularity-aware connections which fuse high-level features of low
granularity and low-level features of high granularity, respectively. To
support these connections, we design granular pyramid convolution (GPC) and
cross-scale attention (CSA) modules for efficient fusion of low-scale and
high-scale features, respectively. On top of the encoder, a self-attention
module is built to learn global information, enabling accurate object
localization with negligible computational cost. Unlike traditional U-Net-based
approaches, our proposed method optimizes feature utilization and semantic
interpretation while applying appropriate supervision at each processing stage.
Extensive experiments show that the proposed method achieves a new
state-of-the-art performance among lightweight image and video SOD models. Code
is available at https://github.com/yuhuan-wu/GAPNet.

</details>


### [135] [Voice Pathology Detection Using Phonation](https://arxiv.org/abs/2508.07587)
*Sri Raksha Siva,Nived Suthahar,Prakash Boominathan,Uma Ranjan*

Main category: cs.CV

TL;DR: 一项研究提出了一种利用机器学习和发声数据来无创检测语音疾病的新方法，旨在实现早期诊断和改善患者治疗效果。


<details>
  <summary>Details</summary>
Motivation: 语音障碍严重影响沟通和生活质量，需要早期准确的诊断。传统的喉镜检查等方法具有侵入性、主观性且不易获得。

Method: 该研究提出了一种基于机器学习的无创框架，利用发声数据来检测语音病理。分析了来自Saarbrücken语音数据库的发声数据，使用了包括MFCCs、色度特征和Mel频谱图在内的声学特征。使用循环神经网络（RNN），包括LSTM和注意力机制，将样本分类为正常和病理类别。数据增强技术（包括音高偏移和高斯噪声添加）提高了模型的泛化能力，而预处理确保了信号质量。基于尺度的特征，如Hölder和Hurst指数，进一步捕捉了信号的不规则性和长期依赖性。

Result: 使用循环神经网络（RNN），包括LSTM和注意力机制，将样本分类为正常和病理类别。

Conclusion: 该框架提供了一种非侵入性的、自动化的诊断工具，用于早期检测语音疾病，支持人工智能驱动的医疗保健，并改善患者的治疗效果。

Abstract: Voice disorders significantly affect communication and quality of life,
requiring an early and accurate diagnosis. Traditional methods like
laryngoscopy are invasive, subjective, and often inaccessible. This research
proposes a noninvasive, machine learning-based framework for detecting voice
pathologies using phonation data.
  Phonation data from the Saarbr\"ucken Voice Database are analyzed using
acoustic features such as Mel Frequency Cepstral Coefficients (MFCCs), chroma
features, and Mel spectrograms. Recurrent Neural Networks (RNNs), including
LSTM and attention mechanisms, classify samples into normal and pathological
categories. Data augmentation techniques, including pitch shifting and Gaussian
noise addition, enhance model generalizability, while preprocessing ensures
signal quality. Scale-based features, such as H\"older and Hurst exponents,
further capture signal irregularities and long-term dependencies.
  The proposed framework offers a noninvasive, automated diagnostic tool for
early detection of voice pathologies, supporting AI-driven healthcare, and
improving patient outcomes.

</details>


### [136] [From Prediction to Explanation: Multimodal, Explainable, and Interactive Deepfake Detection Framework for Non-Expert Users](https://arxiv.org/abs/2508.07596)
*Shahroz Tariq,Simon S. Woo,Priyanka Singh,Irena Irmalasari,Saakshi Gupta,Dev Gupta*

Main category: cs.CV

TL;DR:  DF-P2E 是一个新颖的、多模态的深度伪造检测框架，它通过视觉、语义和叙事解释使检测过程变得透明和易于访问，从而解决了现有黑箱检测方法的局限性。


<details>
  <summary>Details</summary>
Motivation:  现有的深度伪造检测系统通常是黑箱模型，缺乏透明度，对人类推理的支持有限，这在现实世界的决策环境中，尤其是在法医学、新闻和法律系统等关键领域，阻碍了它们的使用，并为非专业用户带来了挑战。

Method:  DF-P2E 框架包含三个模块：(1) 基于 Grad-CAM 的显著性可视化深度伪造分类器，(2) 生成关于被操纵区域的自然语言摘要的视觉字幕模块，(3) 使用经过微调的大型语言模型 (LLM) 来生成上下文感知、用户敏感的解释的叙事细化模块。

Result:  DF-P2E 在 DF40 基准测试中实现了有竞争力的检测性能，并提供了与 Grad-CAM 激活一致的高质量解释。

Conclusion:  DF-P2E 通过整合视觉、语义和叙事层面的解释，实现了可解释和易于理解的深度伪造检测。该框架在 DF40 基准测试中表现出与 Grad-CAM 激活一致的高质量解释，同时保持了有竞争力的检测性能。通过将预测和解释统一在连贯、以人为本的流程中，该工作为可解释的深度伪造检测提供了一种可扩展的方法，并促进了在对抗性媒体环境中值得信赖和透明的 AI 系统的更广泛愿景。

Abstract: The proliferation of deepfake technologies poses urgent challenges and
serious risks to digital integrity, particularly within critical sectors such
as forensics, journalism, and the legal system. While existing detection
systems have made significant progress in classification accuracy, they
typically function as black-box models, offering limited transparency and
minimal support for human reasoning. This lack of interpretability hinders
their usability in real-world decision-making contexts, especially for
non-expert users. In this paper, we present DF-P2E (Deepfake: Prediction to
Explanation), a novel multimodal framework that integrates visual, semantic,
and narrative layers of explanation to make deepfake detection interpretable
and accessible. The framework consists of three modular components: (1) a
deepfake classifier with Grad-CAM-based saliency visualisation, (2) a visual
captioning module that generates natural language summaries of manipulated
regions, and (3) a narrative refinement module that uses a fine-tuned Large
Language Model (LLM) to produce context-aware, user-sensitive explanations. We
instantiate and evaluate the framework on the DF40 benchmark, the most diverse
deepfake dataset to date. Experiments demonstrate that our system achieves
competitive detection performance while providing high-quality explanations
aligned with Grad-CAM activations. By unifying prediction and explanation in a
coherent, human-aligned pipeline, this work offers a scalable approach to
interpretable deepfake detection, advancing the broader vision of trustworthy
and transparent AI systems in adversarial media environments.

</details>


### [137] [ShoulderShot: Generating Over-the-Shoulder Dialogue Videos](https://arxiv.org/abs/2508.07597)
*Yuang Zhang,Junqi Cheng,Haoyu Zhao,Jiaxi Gu,Fangyuan Zou,Zenghui Lu,Peng Shu*

Main category: cs.CV

TL;DR: ShoulderShot框架能生成长对话视频，保持角色和空间一致性，效果优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 对话视频在影视和广告中至关重要，但现有视频生成研究对这类包含角色一致性、空间连续性和多轮对话的场景探索不足，并且在有限计算预算下生成长对话存在挑战。

Method: 提出了一种名为ShoulderShot的框架，该框架结合了双镜头生成和循环视频技术，以实现长时间、多轮次的对话视频生成，同时保持角色一致性。

Result: 结果表明，ShoulderShot在镜头反拍布局、空间连续性和对话长度灵活性方面优于现有方法，为对话视频的实际生成开辟了新的可能性。

Conclusion: ShoulderShot框架通过结合双镜头生成和循环视频，实现了在有限计算预算下生成具有角色一致性、空间连续性和多轮对话能力的对话视频，并在镜头反拍布局、空间连续性和对话长度灵活性方面超越了现有方法。

Abstract: Over-the-shoulder dialogue videos are essential in films, short dramas, and
advertisements, providing visual variety and enhancing viewers' emotional
connection. Despite their importance, such dialogue scenes remain largely
underexplored in video generation research. The main challenges include
maintaining character consistency across different shots, creating a sense of
spatial continuity, and generating long, multi-turn dialogues within limited
computational budgets. Here, we present ShoulderShot, a framework that combines
dual-shot generation with looping video, enabling extended dialogues while
preserving character consistency. Our results demonstrate capabilities that
surpass existing methods in terms of shot-reverse-shot layout, spatial
continuity, and flexibility in dialogue length, thereby opening up new
possibilities for practical dialogue video generation. Videos and comparisons
are available at https://shouldershot.github.io.

</details>


### [138] [LaVieID: Local Autoregressive Diffusion Transformers for Identity-Preserving Video Creation](https://arxiv.org/abs/2508.07603)
*Wenhui Song,Hanhui Li,Jiehui Huang,Panwen Hu,Yuhao Cheng,Long Chen,Yiqiang Yan,Xiaodan Liang*

Main category: cs.CV

TL;DR: LaVieID is a framework for identity-preserving text-to-video generation that uses a local router and a temporal autoregressive module to improve identity preservation and enhance inter-frame consistency, achieving state-of-the-art results.


<details>
  <summary>Details</summary>
Motivation: To tackle the challenging identity-preserving text-to-video task and mitigate the loss of identity information inherent in the stochastic global generation process of diffusion transformers (DiTs) from both spatial and temporal perspectives.

Method: LaVieID introduces a local router to explicitly represent latent states by weighted combinations of fine-grained local facial structures and integrates a temporal autoregressive module to refine denoised latent tokens before video decoding by dividing latent tokens temporally into chunks, exploiting their long-range temporal dependencies to predict biases for rectifying tokens.

Result: LaVieID alleviates undesirable feature interference and encourages DiTs to capture distinctive facial characteristics, significantly enhancing inter-frame identity consistency.

Conclusion: LaVieID can generate high-fidelity personalized videos and achieve state-of-the-art performance.

Abstract: In this paper, we present LaVieID, a novel \underline{l}ocal
\underline{a}utoregressive \underline{vi}d\underline{e}o diffusion framework
designed to tackle the challenging \underline{id}entity-preserving
text-to-video task. The key idea of LaVieID is to mitigate the loss of identity
information inherent in the stochastic global generation process of diffusion
transformers (DiTs) from both spatial and temporal perspectives. Specifically,
unlike the global and unstructured modeling of facial latent states in existing
DiTs, LaVieID introduces a local router to explicitly represent latent states
by weighted combinations of fine-grained local facial structures. This
alleviates undesirable feature interference and encourages DiTs to capture
distinctive facial characteristics. Furthermore, a temporal autoregressive
module is integrated into LaVieID to refine denoised latent tokens before video
decoding. This module divides latent tokens temporally into chunks, exploiting
their long-range temporal dependencies to predict biases for rectifying tokens,
thereby significantly enhancing inter-frame identity consistency. Consequently,
LaVieID can generate high-fidelity personalized videos and achieve
state-of-the-art performance. Our code and models are available at
https://github.com/ssugarwh/LaVieID.

</details>


### [139] [X2Edit: Revisiting Arbitrary-Instruction Image Editing through Self-Constructed Data and Task-Aware Representation Learning](https://arxiv.org/abs/2508.07607)
*Jian Ma,Xujie Zhu,Zihao Pan,Qirong Peng,Xu Guo,Chen Chen,Haonan Lu*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Existing open-source datasets for arbitrary-instruction image editing remain
suboptimal, while a plug-and-play editing module compatible with
community-prevalent generative models is notably absent. In this paper, we
first introduce the X2Edit Dataset, a comprehensive dataset covering 14 diverse
editing tasks, including subject-driven generation. We utilize the
industry-leading unified image generation models and expert models to construct
the data. Meanwhile, we design reasonable editing instructions with the VLM and
implement various scoring mechanisms to filter the data. As a result, we
construct 3.7 million high-quality data with balanced categories. Second, to
better integrate seamlessly with community image generation models, we design
task-aware MoE-LoRA training based on FLUX.1, with only 8\% of the parameters
of the full model. To further improve the final performance, we utilize the
internal representations of the diffusion model and define positive/negative
samples based on image editing types to introduce contrastive learning.
Extensive experiments demonstrate that the model's editing performance is
competitive among many excellent models. Additionally, the constructed dataset
exhibits substantial advantages over existing open-source datasets. The
open-source code, checkpoints, and datasets for X2Edit can be found at the
following link: https://github.com/OPPO-Mente-Lab/X2Edit.

</details>


### [140] [An Iterative Reconstruction Method for Dental Cone-Beam Computed Tomography with a Truncated Field of View](https://arxiv.org/abs/2508.07618)
*Hyoung Suk Park,Kiwan Jeon*

Main category: cs.CV

TL;DR: 提出一种两阶段方法，利用INR生成先验图像，结合差异校正和迭代重建，有效解决牙科CBCT中的截断伪影问题。


<details>
  <summary>Details</summary>
Motivation: 牙科CBCT常使用小探测器导致视野（FOV）截断，在前向迭代重建中，截断FOV中的实际投影与前向投影之间的差异会累积，导致重建图像质量严重下降。

Method: 提出了一种两阶段方法来缓解牙科CBCT中的截断伪影。第一阶段，采用隐式神经表示（INR）生成扩展区域的先验图像，并用其前向投影估计截断FOV引起的差异。第二阶段，在截断区域内，利用差异校正后的投影数据进行常规迭代重建。

Result: 数值结果表明，所提出的两阶段方法能有效抑制截断伪影，提高CBCT图像质量。

Conclusion: 该方法能有效抑制截断伪影，提高CBCT图像质量。

Abstract: In dental cone-beam computed tomography (CBCT), compact and cost-effective
system designs often use small detectors, resulting in a truncated field of
view (FOV) that does not fully encompass the patient's head. In iterative
reconstruction approaches, the discrepancy between the actual projection and
the forward projection within the truncated FOV accumulates over iterations,
leading to significant degradation in the reconstructed image quality. In this
study, we propose a two-stage approach to mitigate truncation artifacts in
dental CBCT. In the first stage, we employ Implicit Neural Representation
(INR), leveraging its superior representation power, to generate a prior image
over an extended region so that its forward projection fully covers the
patient's head. To reduce computational and memory burdens, INR reconstruction
is performed with a coarse voxel size. The forward projection of this prior
image is then used to estimate the discrepancy due to truncated FOV in the
measured projection data. In the second stage, the discrepancy-corrected
projection data is utilized in a conventional iterative reconstruction process
within the truncated region. Our numerical results demonstrate that the
proposed two-grid approach effectively suppresses truncation artifacts, leading
to improved CBCT image quality.

</details>


### [141] [SOFA: Deep Learning Framework for Simulating and Optimizing Atrial Fibrillation Ablation](https://arxiv.org/abs/2508.07621)
*Yunsung Chung,Chanho Lim,Ghassan Bidaoui,Christian Massad,Nassir Marrouche,Jihun Hamm*

Main category: cs.CV

TL;DR: SOFA是一个深度学习框架，通过模拟和优化手术参数来预测和减少房颤消融后的复发。


<details>
  <summary>Details</summary>
Motivation: 房颤是一种常见的心律失常，导管消融是常用治疗方法，但效果变异性很大。由于患者组织和手术因素的复杂相互作用，评估和改善消融效果具有挑战性。本文旨在通过模拟手术参数的影响来预测房颤复发，并优化手术方案以降低复发率。

Method: SOFA（模拟和优化房颤消融）是一个深度学习框架，通过生成术后疤痕形成图像来模拟消融效果，并预测房颤复发风险。它还包含一个优化方案，用于改进手术参数以降低复发风险。该方法利用多模态、多视图生成器处理房颤的2.5D表示。

Result: SOFA能够准确合成术后图像，并且其优化方案能将模型预测的复发风险降低22.18%。

Conclusion: SOFA 是首个整合了手术效果模拟、复发预测和参数优化的框架，为个性化房颤消融提供了新工具。

Abstract: Atrial fibrillation (AF) is a prevalent cardiac arrhythmia often treated with
catheter ablation procedures, but procedural outcomes are highly variable.
Evaluating and improving ablation efficacy is challenging due to the complex
interaction between patient-specific tissue and procedural factors. This paper
asks two questions: Can AF recurrence be predicted by simulating the effects of
procedural parameters? How should we ablate to reduce AF recurrence? We propose
SOFA (Simulating and Optimizing Atrial Fibrillation Ablation), a novel
deep-learning framework that addresses these questions. SOFA first simulates
the outcome of an ablation strategy by generating a post-ablation image
depicting scar formation, conditioned on a patient's pre-ablation LGE-MRI and
the specific procedural parameters used (e.g., ablation locations, duration,
temperature, power, and force). During this simulation, it predicts AF
recurrence risk. Critically, SOFA then introduces an optimization scheme that
refines these procedural parameters to minimize the predicted risk. Our method
leverages a multi-modal, multi-view generator that processes 2.5D
representations of the atrium. Quantitative evaluations show that SOFA
accurately synthesizes post-ablation images and that our optimization scheme
leads to a 22.18\% reduction in the model-predicted recurrence risk. To the
best of our knowledge, SOFA is the first framework to integrate the simulation
of procedural effects, recurrence prediction, and parameter optimization,
offering a novel tool for personalizing AF ablation.

</details>


### [142] [Enhancing Egocentric Object Detection in Static Environments using Graph-based Spatial Anomaly Detection and Correction](https://arxiv.org/abs/2508.07624)
*Vishakha Lall,Yisi Liu*

Main category: cs.CV

TL;DR: 通过图神经网络利用对象间的空间关系来纠正对象检测的错误，在杂乱或遮挡场景下效果显著，mAP@50最高可提高4%。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有对象检测模型在利用静态环境中的空间先验知识方面存在的不足，从而导致在杂乱或遮挡场景下出现不一致的预测、漏检或误分类的问题。

Method: 提出一个基于图的后处理流程，使用图神经网络（GNN）来识别无效的对象类别标签，并根据邻域上下文预测修正后的类别标签。

Result: 将该方法作为独立异常检测和校正框架，以及作为YOLOv7和RT-DETR等标准对象检测器的后处理模块进行评估，实验证明，结合空间推理可显著提高检测性能，mAP@50最高可提高4%。

Conclusion: 该方法通过显式建模对象之间的空间关系来纠正检测异常，并证明了利用环境空间结构来提高对象检测系统可靠性的潜力。

Abstract: In many real-world applications involving static environments, the spatial
layout of objects remains consistent across instances. However,
state-of-the-art object detection models often fail to leverage this spatial
prior, resulting in inconsistent predictions, missed detections, or
misclassifications, particularly in cluttered or occluded scenes. In this work,
we propose a graph-based post-processing pipeline that explicitly models the
spatial relationships between objects to correct detection anomalies in
egocentric frames. Using a graph neural network (GNN) trained on manually
annotated data, our model identifies invalid object class labels and predicts
corrected class labels based on their neighbourhood context. We evaluate our
approach both as a standalone anomaly detection and correction framework and as
a post-processing module for standard object detectors such as YOLOv7 and
RT-DETR. Experiments demonstrate that incorporating this spatial reasoning
significantly improves detection performance, with mAP@50 gains of up to 4%.
This method highlights the potential of leveraging the environment's spatial
structure to improve reliability in object detection systems.

</details>


### [143] [A Trustworthy Method for Multimodal Emotion Recognition](https://arxiv.org/abs/2508.07625)
*Junxiao Xue,Xiaozhen Liu,Jie Wang,Xuecheng Wu,Bin Wu*

Main category: cs.CV

TL;DR: 本研究提出了一种名为可信情感识别（TER）的新方法，通过不确定性估计来提高情感识别在噪声数据下的可靠性，并在IEMOCAP和Music-video数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有情感识别方法多关注于通过复杂的深度模型提升性能，但往往忽略了在处理带噪声、损坏或分布外数据时模型的可靠性问题。因此，本研究旨在提出一种新的情感识别方法，能够确保最终决策的可靠性，并提出相应的评估标准来衡量这种可靠性。

Method: TER框架利用不确定性估计来计算预测的置信度，并根据置信度融合多模态结果，从而输出可信的预测。该框架还引入了可信精确率、可信召回率、可信准确率和可信F1分数等新的评估指标，以量化模型在噪声或损坏数据下的可靠性表现。

Result: TER框架在Music-video数据集上达到了82.40%的准确率，并超越了其他方法，在IEMOCAP和Music-video数据集上分别取得了0.7511和0.9035的可信F1分数，证明了其在情感识别和可靠性方面的有效性。

Conclusion: 现有的多模态情感识别方法在可靠性方面仍有提升空间，尤其是在处理噪声、损坏和分布外数据时。本研究提出的可信情感识别（TER）框架通过引入不确定性估计来衡量预测的置信度，并结合多模态信息，旨在提高情感识别的可靠性和鲁棒性。TER框架在IEMOCAP和Music-video数据集上均取得了领先的性能，在可信性能评估指标上表现优异，证明了其有效性。

Abstract: Existing emotion recognition methods mainly focus on enhancing performance by
employing complex deep models, typically resulting in significantly higher
model complexity. Although effective, it is also crucial to ensure the
reliability of the final decision, especially for noisy, corrupted and
out-of-distribution data. To this end, we propose a novel emotion recognition
method called trusted emotion recognition (TER), which utilizes uncertainty
estimation to calculate the confidence value of predictions. TER combines the
results from multiple modalities based on their confidence values to output the
trusted predictions. We also provide a new evaluation criterion to assess the
reliability of predictions. Specifically, we incorporate trusted precision and
trusted recall to determine the trusted threshold and formulate the trusted
Acc. and trusted F1 score to evaluate the model's trusted performance. The
proposed framework combines the confidence module that accordingly endows the
model with reliability and robustness against possible noise or corruption. The
extensive experimental results validate the effectiveness of our proposed
model. The TER achieves state-of-the-art performance on the Music-video,
achieving 82.40% Acc. In terms of trusted performance, TER outperforms other
methods on the IEMOCAP and Music-video, achieving trusted F1 scores of 0.7511
and 0.9035, respectively.

</details>


### [144] [LaRender: Training-Free Occlusion Control in Image Generation via Latent Rendering](https://arxiv.org/abs/2508.07647)
*Xiaohang Zhan,Dingming Liu*

Main category: cs.CV

TL;DR: 一種新的訓練免費圖像生成算法，通過利用體積渲染原理精確控制圖像中對象的遮擋關係。


<details>
  <summary>Details</summary>
Motivation: 現有的圖像生成方法通常依賴提示來影響遮擋，但精度不足。雖然 layout-to-image 方法可以控制對象位置，但未能明確解決遮擋關係。

Method: 該方法利用體積渲染原理在潛空間中渲染場景，並以遮擋關係和估計的物體透射率為指導，同時利用預訓練的圖像擴散模型。此方法無需重新訓練或微調圖像擴散模型。

Result: 在大量實驗中，該方法在遮擋準確性方面顯著優於現有方法。此外，通過調整渲染過程中的對象不透明度，可以實現各種效果。

Conclusion: 該方法在遮擋準確性方面顯著優於現有方法，並且可以通過調整渲染過程中的對象不透明度來實現各種效果，例如改變對象的透明度、物體的密度、粒子濃度、光線強度和鏡頭效果等。

Abstract: We propose a novel training-free image generation algorithm that precisely
controls the occlusion relationships between objects in an image. Existing
image generation methods typically rely on prompts to influence occlusion,
which often lack precision. While layout-to-image methods provide control over
object locations, they fail to address occlusion relationships explicitly.
Given a pre-trained image diffusion model, our method leverages volume
rendering principles to "render" the scene in latent space, guided by occlusion
relationships and the estimated transmittance of objects. This approach does
not require retraining or fine-tuning the image diffusion model, yet it enables
accurate occlusion control due to its physics-grounded foundation. In extensive
experiments, our method significantly outperforms existing approaches in terms
of occlusion accuracy. Furthermore, we demonstrate that by adjusting the
opacities of objects or concepts during rendering, our method can achieve a
variety of effects, such as altering the transparency of objects, the density
of mass (e.g., forests), the concentration of particles (e.g., rain, fog), the
intensity of light, and the strength of lens effects, etc.

</details>


### [145] [Collaborative Learning of Scattering and Deep Features for SAR Target Recognition with Noisy Labels](https://arxiv.org/abs/2508.07656)
*Yimin Fu,Zhunga Liu,Dongxiu Guo,Longfei Wang*

Main category: cs.CV

TL;DR: 该研究提出了一种名为CLSDF（散射和深度特征的协同学习）的方法，用于解决SAR自动目标识别（ATR）中由于噪声标签导致的性能下降问题。通过融合散射特征和深度特征，并结合半监督学习和联合分布对齐策略，该方法在MSTAR数据集上取得了优于现有技术的性能。


<details>
  <summary>Details</summary>
Motivation: 由于需要专家知识，高质量标记的SAR数据获取具有挑战性，导致不可避免地存在不可靠的噪声标签，从而导致SAR自动目标识别（ATR）性能下降。现有的关于噪声标签学习的研究主要集中在图像数据上，但SAR数据非直观的视觉特性不足以实现鲁棒性学习。

Method: 1.设计了一个多模型特征融合框架，用于整合散射特征和深度特征。
2.将归因散射中心（ASC）视为动态图结构数据，并提取物理特征来丰富深度图像特征的表示。
3.通过使用多个类别的混合高斯模型（GMM）来模拟损失分布，从而划分出包含干净标签和噪声标签的样本。
4.基于划分出的数据，对两个不同的分支进行半监督学习。
5.引入联合分布对齐策略来提高共猜测标签的可靠性。

Result: 在MSTAR数据集上进行了广泛的实验，结果表明，所提出的方法在不同操作条件和各种标签噪声下均能实现最先进的性能。

Conclusion: 所提出的CLSDF方法在MSTAR数据集上进行了广泛的实验，并在不同操作条件和各种标签噪声下取得了最先进的性能。

Abstract: The acquisition of high-quality labeled synthetic aperture radar (SAR) data
is challenging due to the demanding requirement for expert knowledge.
Consequently, the presence of unreliable noisy labels is unavoidable, which
results in performance degradation of SAR automatic target recognition (ATR).
Existing research on learning with noisy labels mainly focuses on image data.
However, the non-intuitive visual characteristics of SAR data are insufficient
to achieve noise-robust learning. To address this problem, we propose
collaborative learning of scattering and deep features (CLSDF) for SAR ATR with
noisy labels. Specifically, a multi-model feature fusion framework is designed
to integrate scattering and deep features. The attributed scattering centers
(ASCs) are treated as dynamic graph structure data, and the extracted physical
characteristics effectively enrich the representation of deep image features.
Then, the samples with clean and noisy labels are divided by modeling the loss
distribution with multiple class-wise Gaussian Mixture Models (GMMs).
Afterward, the semi-supervised learning of two divergent branches is conducted
based on the data divided by each other. Moreover, a joint distribution
alignment strategy is introduced to enhance the reliability of co-guessed
labels. Extensive experiments have been done on the Moving and Stationary
Target Acquisition and Recognition (MSTAR) dataset, and the results show that
the proposed method can achieve state-of-the-art performance under different
operating conditions with various label noises.

</details>


### [146] [Undress to Redress: A Training-Free Framework for Virtual Try-On](https://arxiv.org/abs/2508.07680)
*Zhiying Li,Junhao Wu,Yeying Jin,Daiheng Gao,Yun Ji,Kaichuan Kong,Lei Yu,Hao Xu,Kai Chen,Bruce Gu,Nana Wang,Zhaoxin Fan*

Main category: cs.CV

TL;DR: UR-VTON is a new framework for virtual try-on that improves long-sleeve-to-short-sleeve conversions by "undressing" the person first, then dressing them in the new garment. It also uses special guidance and a refiner for better results and introduces a new benchmark dataset (LS-TON). It outperforms existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing VTON methods struggle with long-sleeve-to-short-sleeve conversions, often producing unrealistic outputs when exposed skin is underrepresented in the original image, due to the "majority" completion rule which leads to inaccurate skin restoration.

Method: UR-VTON introduces an "undress-to-redress" mechanism: it first reveals the user's torso by virtually "undressing," then applies the target short-sleeve garment, effectively decomposing the conversion into two more manageable steps. Additionally, it incorporates Dynamic Classifier-Free Guidance scheduling to balance diversity and image quality during DDPM sampling, and employs Structural Refiner to enhance detail fidelity using high-frequency cues.

Result: Extensive experiments demonstrate that UR-VTON outperforms state-of-the-art methods in both detail preservation and image quality.

Conclusion: UR-VTON is a novel, training-free framework that can be seamlessly integrated with any existing VTON method. UR-VTON outperforms state-of-the-art methods in both detail preservation and image quality.

Abstract: Virtual try-on (VTON) is a crucial task for enhancing user experience in
online shopping by generating realistic garment previews on personal photos.
Although existing methods have achieved impressive results, they struggle with
long-sleeve-to-short-sleeve conversions-a common and practical scenario-often
producing unrealistic outputs when exposed skin is underrepresented in the
original image. We argue that this challenge arises from the ''majority''
completion rule in current VTON models, which leads to inaccurate skin
restoration in such cases. To address this, we propose UR-VTON (Undress-Redress
Virtual Try-ON), a novel, training-free framework that can be seamlessly
integrated with any existing VTON method. UR-VTON introduces an
''undress-to-redress'' mechanism: it first reveals the user's torso by
virtually ''undressing,'' then applies the target short-sleeve garment,
effectively decomposing the conversion into two more manageable steps.
Additionally, we incorporate Dynamic Classifier-Free Guidance scheduling to
balance diversity and image quality during DDPM sampling, and employ Structural
Refiner to enhance detail fidelity using high-frequency cues. Finally, we
present LS-TON, a new benchmark for long-sleeve-to-short-sleeve try-on.
Extensive experiments demonstrate that UR-VTON outperforms state-of-the-art
methods in both detail preservation and image quality. Code will be released
upon acceptance.

</details>


### [147] [TAR-TVG: Enhancing VLMs with Timestamp Anchor-Constrained Reasoning for Temporal Video Grounding](https://arxiv.org/abs/2508.07683)
*Chaohong Guo,Xun Mo,Yongwei Nie,Xuemiao Xu,Chao Xu,Fei Yu,Chengjiang Long*

Main category: cs.CV

TL;DR: TAR-TVG 通过引入时间戳锚点和三阶段自蒸馏训练策略，改进了视频时间定位任务，提高了推理过程的质量和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法在生成推理链前进行预测时，未能明确约束推理过程以保证最终时间预测的质量。TAR-TVG 旨在解决此局限性，提高视频语言理解中的时间定位精度。

Method: TAR-TVG 框架通过在推理过程中引入时间戳锚点作为中间验证点，并要求每个推理步骤产生越来越精确的时间估计，从而对思考内容进行显式监督。为了解决低概率锚点生成问题，提出了一种三阶段自蒸馏训练策略：1) 初始 GRPO 训练以收集包含多个时间戳锚点的高质量推理轨迹；2) 在蒸馏数据上进行监督微调（SFT）；3) 在 SFT 增强模型上进行最终 GRPO 优化。

Result: TAR-TVG 实现了最先进的性能，并生成了可解释、可验证且时间估计逐步精确的推理链。

Conclusion: TAR-TVG 框架通过引入时间戳锚点来约束推理过程，确保了最终时间预测的质量。实验证明，TAR-TVG 达到了最先进的性能，并能生成可解释、可验证且时间估计逐步改进的推理链。

Abstract: Temporal Video Grounding (TVG) aims to precisely localize video segments
corresponding to natural language queries, which is a critical capability for
long-form video understanding. Although existing reinforcement learning
approaches encourage models to generate reasoning chains before predictions,
they fail to explicitly constrain the reasoning process to ensure the quality
of the final temporal predictions. To address this limitation, we propose
Timestamp Anchor-constrained Reasoning for Temporal Video Grounding (TAR-TVG),
a novel framework that introduces timestamp anchors within the reasoning
process to enforce explicit supervision to the thought content. These anchors
serve as intermediate verification points. More importantly, we require each
reasoning step to produce increasingly accurate temporal estimations, thereby
ensuring that the reasoning process contributes meaningfully to the final
prediction. To address the challenge of low-probability anchor generation in
models (e.g., Qwen2.5-VL-3B), we develop an efficient self-distillation
training strategy: (1) initial GRPO training to collect 30K high-quality
reasoning traces containing multiple timestamp anchors, (2) supervised
fine-tuning (SFT) on distilled data, and (3) final GRPO optimization on the
SFT-enhanced model. This three-stage training strategy enables robust anchor
generation while maintaining reasoning quality. Experiments show that our model
achieves state-of-the-art performance while producing interpretable, verifiable
reasoning chains with progressively refined temporal estimations.

</details>


### [148] [Make Your MoVe: Make Your 3D Contents by Adapting Multi-View Diffusion Models to External Editing](https://arxiv.org/abs/2508.07700)
*Weitao Wang,Haoran Xu,Jun Meng,Haoqian Wang*

Main category: cs.CV

TL;DR: 一种用于3D内容编辑的即插即用方案，通过几何保持模块和注入开关来保持几何形状，并提高多视图一致性和网格质量。


<details>
  <summary>Details</summary>
Motivation: 为了满足用户在生成3D内容时，在不影响几何形状的前提下，对其颜色、风格和光照进行编辑的需求，同时解决现有2D编辑工具引入信息损失的问题。

Method: 提出了一种即插即用的方案，包括一个几何保持模块和一个注入开关，以在单次推理中将编辑后的资产与原始几何形状对齐。

Result: 实验证明，该方法在多种多视图扩散模型和编辑方法的组合下，能够持续提高编辑后3D资产的多视图一致性和网格质量。

Conclusion: 该方法在不影响几何形状的前提下，能够对生成的3D内容的颜色、风格和光照进行编辑，并且能够提高编辑后3D资产的多视图一致性和网格质量。

Abstract: As 3D generation techniques continue to flourish, the demand for generating
personalized content is rapidly rising. Users increasingly seek to apply
various editing methods to polish generated 3D content, aiming to enhance its
color, style, and lighting without compromising the underlying geometry.
However, most existing editing tools focus on the 2D domain, and directly
feeding their results into 3D generation methods (like multi-view diffusion
models) will introduce information loss, degrading the quality of the final 3D
assets. In this paper, we propose a tuning-free, plug-and-play scheme that
aligns edited assets with their original geometry in a single inference run.
Central to our approach is a geometry preservation module that guides the
edited multi-view generation with original input normal latents. Besides, an
injection switcher is proposed to deliberately control the supervision extent
of the original normals, ensuring the alignment between the edited color and
normal views. Extensive experiments show that our method consistently improves
both the multi-view consistency and mesh quality of edited 3D assets, across
multiple combinations of multi-view diffusion models and editing methods.

</details>


### [149] [Enhancing Small-Scale Dataset Expansion with Triplet-Connection-based Sample Re-Weighting](https://arxiv.org/abs/2508.07723)
*Ting Xiang,Changjian Chen,Zhuo Tang,Qifeng Zhang,Fei Lyu,Li Yang,Jiapeng Zhang,Kenli Li*

Main category: cs.CV

TL;DR: Generative models expand datasets but can create noisy images. TriReWeight re-weights these noisy images, improving performance in computer vision tasks, especially with limited data. It outperforms existing methods and works with various generative techniques.


<details>
  <summary>Details</summary>
Motivation: The scarcity of images in real-world applications like medical diagnosis limits the performance of computer vision models. Generative models can expand datasets, but may produce noisy images due to uncontrollable generation processes and ambiguous natural language.

Method: TriReWeight, a triplet-connection-based sample re-weighting method, theoretically analyzes three types of supervision for generated images and assigns low weights to noisy images to enhance generative data augmentation.

Result: TriReWeight outperforms existing state-of-the-art methods by 7.9% on average across six natural image datasets and by 3.4% on average across three medical datasets. It can also enhance the performance of different generative data augmentation methods.

Conclusion: Re-weighting methods like TriReWeight can improve generative data augmentation by assigning lower weights to noisy images, leading to better performance in computer vision tasks, especially in data-scarce domains like medical imaging. TriReWeight demonstrates superior performance over existing methods and can be integrated with various generative approaches.

Abstract: The performance of computer vision models in certain real-world applications,
such as medical diagnosis, is often limited by the scarcity of available
images. Expanding datasets using pre-trained generative models is an effective
solution. However, due to the uncontrollable generation process and the
ambiguity of natural language, noisy images may be generated. Re-weighting is
an effective way to address this issue by assigning low weights to such noisy
images. We first theoretically analyze three types of supervision for the
generated images. Based on the theoretical analysis, we develop TriReWeight, a
triplet-connection-based sample re-weighting method to enhance generative data
augmentation. Theoretically, TriReWeight can be integrated with any generative
data augmentation methods and never downgrade their performance. Moreover, its
generalization approaches the optimal in the order $O(\sqrt{d\ln (n)/n})$. Our
experiments validate the correctness of the theoretical analysis and
demonstrate that our method outperforms the existing SOTA methods by $7.9\%$ on
average over six natural image datasets and by $3.4\%$ on average over three
medical datasets. We also experimentally validate that our method can enhance
the performance of different generative data augmentation methods.

</details>


### [150] [Grouped Speculative Decoding for Autoregressive Image Generation](https://arxiv.org/abs/2508.07747)
*Junhyuk So,Juncheol Shin,Hyunho Kook,Eunhyeok Park*

Main category: cs.CV

TL;DR: This paper introduces Grouped Speculative Decoding (GSD), a training-free method to speed up autoregressive (AR) image models. Unlike previous methods, GSD considers groups of valid image tokens instead of just one, addressing the unique properties of image data and improving acceleration. Experiments show GSD achieves an average 3.7x speedup without compromising image quality or requiring extra training.


<details>
  <summary>Details</summary>
Motivation: Traditional Speculative Decoding (SD) methods for AR image models have limitations, either providing modest acceleration or requiring additional training. Existing methods fail to leverage the inherent redundancy and diversity of image tokens, leading to excessive false-negative rejections because they rely on a single most-likely token. This work aims to address these limitations by proposing a new SD strategy.

Method: GSD is a novel, training-free acceleration method for AR image models that evaluates clusters of visually valid tokens rather than relying on a single target token. It dynamically clusters tokens based on embedding distance to address the ineffectiveness of static clustering.

Result: GSD accelerates AR image models by an average of 3.7x while preserving image quality. This was demonstrated through extensive experiments.

Conclusion: GSD can accelerate AR image models by an average of 3.7x while preserving image quality, without requiring additional training.

Abstract: Recently, autoregressive (AR) image models have demonstrated remarkable
generative capabilities, positioning themselves as a compelling alternative to
diffusion models. However, their sequential nature leads to long inference
times, limiting their practical scalability. In this work, we introduce Grouped
Speculative Decoding (GSD), a novel, training-free acceleration method for AR
image models. While recent studies have explored Speculative Decoding (SD) as a
means to speed up AR image generation, existing approaches either provide only
modest acceleration or require additional training. Our in-depth analysis
reveals a fundamental difference between language and image tokens: image
tokens exhibit inherent redundancy and diversity, meaning multiple tokens can
convey valid semantics. However, traditional SD methods are designed to accept
only a single most-likely token, which fails to leverage this difference,
leading to excessive false-negative rejections. To address this, we propose a
new SD strategy that evaluates clusters of visually valid tokens rather than
relying on a single target token. Additionally, we observe that static
clustering based on embedding distance is ineffective, which motivates our
dynamic GSD approach. Extensive experiments show that GSD accelerates AR image
models by an average of 3.7x while preserving image quality-all without
requiring any additional training. The source code is available at
https://github.com/junhyukso/GSD

</details>


### [151] [Comparison Reveals Commonality: Customized Image Generation through Contrastive Inversion](https://arxiv.org/abs/2508.07755)
*Minseo Kim,Minchan Kwon,Dongyeun Lee,Yunho Jeon,Junmo Kim*

Main category: cs.CV

TL;DR: A new method called Contrastive Inversion extracts common concepts from images using contrastive learning and cross-attention fine-tuning, improving image generation quality without manual guidance.


<details>
  <summary>Details</summary>
Motivation: To address the need for techniques that effectively extract common concepts from small sets of images for customized image generation, as existing methods that rely on manual guidance can lead to incomplete separation of auxiliary features and degrade generation quality.

Method: Contrastive learning is used to train the target token and image-wise auxiliary text tokens. Disentangled cross-attention fine-tuning is then applied to improve concept fidelity without overfitting.

Result: Experimental results demonstrate that the proposed method achieves balanced, high-level performance in both concept representation and editing, outperforming existing techniques.

Conclusion: Contrastive Inversion

Abstract: The recent demand for customized image generation raises a need for
techniques that effectively extract the common concept from small sets of
images. Existing methods typically rely on additional guidance, such as text
prompts or spatial masks, to capture the common target concept. Unfortunately,
relying on manually provided guidance can lead to incomplete separation of
auxiliary features, which degrades generation quality.In this paper, we propose
Contrastive Inversion, a novel approach that identifies the common concept by
comparing the input images without relying on additional information. We train
the target token along with the image-wise auxiliary text tokens via
contrastive learning, which extracts the well-disentangled true semantics of
the target. Then we apply disentangled cross-attention fine-tuning to improve
concept fidelity without overfitting. Experimental results and analysis
demonstrate that our method achieves a balanced, high-level performance in both
concept representation and editing, outperforming existing techniques.

</details>


### [152] [Correspondence as Video: Test-Time Adaption on SAM2 for Reference Segmentation in the Wild](https://arxiv.org/abs/2508.07759)
*Haoran Wang,Zekun Li,Jian Zhang,Lei Qi,Yinghuan Shi*

Main category: cs.CV

TL;DR: 提出CAV-SAM，一种新颖的参考分割方法，将参考-目标图像对表示为伪视频，利用SAM2的iVOS能力，通过DBST和TTGA模块实现轻量级适应，性能超越SOTA。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有参考分割方法依赖元学习带来的海量数据和计算成本的限制，提出了一种新颖的表示方法，将参考-目标图像对的内在对应关系表示为伪视频。

Method: CAV-SAM包含两个关键模块：基于扩散的语义转换（DBST）模块，它使用扩散模型来构建语义转换序列；以及测试时几何对齐（TTGA）模块，它通过测试时微调来对齐此序列中的几何变化。

Result: CAV-SAM在常用数据集上的评估结果显示，其分割性能比SOTA方法提高了5%以上。

Conclusion: CAV-SAM通过将参考图像和目标图像之间的对应关系表示为伪视频，并利用SAM2的iVOS能力，实现了对下游任务的轻量级适应，在分割性能上超越了SOTA方法5%以上。

Abstract: Large vision models like the Segment Anything Model (SAM) exhibit significant
limitations when applied to downstream tasks in the wild. Consequently,
reference segmentation, which leverages reference images and their
corresponding masks to impart novel knowledge to the model, emerges as a
promising new direction for adapting vision models. However, existing reference
segmentation approaches predominantly rely on meta-learning, which still
necessitates an extensive meta-training process and brings massive data and
computational cost. In this study, we propose a novel approach by representing
the inherent correspondence between reference-target image pairs as a pseudo
video. This perspective allows the latest version of SAM, known as SAM2, which
is equipped with interactive video object segmentation (iVOS) capabilities, to
be adapted to downstream tasks in a lightweight manner. We term this approach
Correspondence As Video for SAM (CAV-SAM). CAV-SAM comprises two key modules:
the Diffusion-Based Semantic Transition (DBST) module employs a diffusion model
to construct a semantic transformation sequence, while the Test-Time Geometric
Alignment (TTGA) module aligns the geometric changes within this sequence
through test-time fine-tuning. We evaluated CAVSAM on widely-used datasets,
achieving segmentation performance improvements exceeding 5% over SOTA methods.
Implementation is provided in the supplementary materials.

</details>


### [153] [UniSVG: A Unified Dataset for Vector Graphic Understanding and Generation with Multimodal Large Language Models](https://arxiv.org/abs/2508.07766)
*Jinke Li,Jiarui Yu,Chenxing Wei,Hande Dong,Qiang Lin,Liangjing Yang,Zhicai Wang,Yanbin Hao*

Main category: cs.CV

TL;DR: 该研究提出了UniSVG数据集，一个包含525K个数据项的数据集，用于训练和评估多模态大语言模型（MLLMs）在SVG（可缩放矢量图形）理解与生成方面的能力。UniSVG数据集能够提升MLLMs在SVG相关任务上的表现，并且在与GPT-4V等闭源模型的比较中表现更优。


<details>
  <summary>Details</summary>
Motivation: AI驱动的SVG理解与生成（U&G）是一个重大挑战，因为SVG代码需要高精度，并且生成过程需要处理多种条件约束（如文本提示和视觉参考），这需要强大的多模态处理能力。

Method: 提出一个名为UniSVG的数据集，包含525K个数据项，用于多模态大语言模型的训练和评估，以解决SVG代码的理解与生成问题。

Result: UniSVG是首个为统一SVG生成（从文本提示和图像）和SVG理解（颜色、类别、用法等）设计的综合性数据集。

Conclusion: 通过UniSVG数据集的训练，开源多模态大语言模型在各种SVG理解与生成任务上的表现得到提升，超越了像GPT-4V这样的闭源模型。

Abstract: Unlike bitmap images, scalable vector graphics (SVG) maintain quality when
scaled, frequently employed in computer vision and artistic design in the
representation of SVG code. In this era of proliferating AI-powered systems,
enabling AI to understand and generate SVG has become increasingly urgent.
However, AI-driven SVG understanding and generation (U&G) remain significant
challenges. SVG code, equivalent to a set of curves and lines controlled by
floating-point parameters, demands high precision in SVG U&G. Besides, SVG
generation operates under diverse conditional constraints, including textual
prompts and visual references, which requires powerful multi-modal processing
for condition-to-SVG transformation. Recently, the rapid growth of Multi-modal
Large Language Models (MLLMs) have demonstrated capabilities to process
multi-modal inputs and generate complex vector controlling parameters,
suggesting the potential to address SVG U&G tasks within a unified model. To
unlock MLLM's capabilities in the SVG area, we propose an SVG-centric dataset
called UniSVG, comprising 525k data items, tailored for MLLM training and
evaluation. To our best knowledge, it is the first comprehensive dataset
designed for unified SVG generation (from textual prompts and images) and SVG
understanding (color, category, usage, etc.). As expected, learning on the
proposed dataset boosts open-source MLLMs' performance on various SVG U&G
tasks, surpassing SOTA close-source MLLMs like GPT-4V. We release dataset,
benchmark, weights, codes and experiment details on
https://ryanlijinke.github.io/.

</details>


### [154] [Dream4D: Lifting Camera-Controlled I2V towards Spatiotemporally Consistent 4D Generation](https://arxiv.org/abs/2508.07769)
*Xiaoyan Liu,Kangrui Li,Jiaxin Liu*

Main category: cs.CV

TL;DR: Dream4D是一个新的框架，利用少样本学习和姿态条件扩散过程从单张图像生成高质量、时空一致的4D内容。


<details>
  <summary>Details</summary>
Motivation: 当前计算机视觉领域在时空一致的4D内容合成方面面临挑战，特别是在大规模、多元素交互场景下，需要同时建模高保真空间表示和物理上合理的时序动态，同时保持视图一致性。

Method: Dream4D框架采用两阶段方法：首先利用少样本学习从单张图像预测最优相机轨迹，然后通过专门的姿态条件扩散过程生成几何一致的多视图序列，最后将序列转换为持久的4D表示。

Result: Dream4D框架能够生成高质量的4D内容，并在mPSNR和mSSIM等指标上优于现有方法。

Conclusion: Dream4D框架首次结合了视频扩散模型的丰富时间先验和重建模型的几何感知能力，显著促进了4D内容的生成，并在多个指标（如mPSNR、mSSIM）上展现出优于现有方法的高质量。

Abstract: The synthesis of spatiotemporally coherent 4D content presents fundamental
challenges in computer vision, requiring simultaneous modeling of high-fidelity
spatial representations and physically plausible temporal dynamics. Current
approaches often struggle to maintain view consistency while handling complex
scene dynamics, particularly in large-scale environments with multiple
interacting elements. This work introduces Dream4D, a novel framework that
bridges this gap through a synergy of controllable video generation and neural
4D reconstruction. Our approach seamlessly combines a two-stage architecture:
it first predicts optimal camera trajectories from a single image using
few-shot learning, then generates geometrically consistent multi-view sequences
via a specialized pose-conditioned diffusion process, which are finally
converted into a persistent 4D representation. This framework is the first to
leverage both rich temporal priors from video diffusion models and geometric
awareness of the reconstruction models, which significantly facilitates 4D
generation and shows higher quality (e.g., mPSNR, mSSIM) over existing methods.

</details>


### [155] [Prototype-Guided Curriculum Learning for Zero-Shot Learning](https://arxiv.org/abs/2508.07771)
*Lei Wang,Shiming Chen,Guo-Sen Xie,Ziming Hong,Chaojian Yu,Qinmu Peng,Xinge You*

Main category: cs.CV

TL;DR: CLZSL框架通过PCL和PUP模块解决ZSL中语义原型的问题，提升了知识迁移效果。


<details>
  <summary>Details</summary>
Motivation: 现有的基于嵌入的方法在零样本学习（ZSL）中，将知识从已知类迁移到未知类，但手动定义的语义原型存在实例级别不匹配（样本与原型不符）和类别级别不精确（原型不能准确反映类别真实语义）的问题，导致视觉-语义映射被误导，降低了知识迁移的有效性。

Method: 提出了一种原型指导的课程学习框架（CLZSL），包括原型指导的课程学习（PCL）模块和原型更新（PUP）模块。PCL模块通过优先处理视觉映射与类别原型具有高余弦相似度的样本，并逐步引入对齐度较低的样本，来减少实例级别不匹配的干扰。PUP模块通过利用从实例学习到的视觉映射，动态更新类别原型，以减少类别级别的不精确性。

Result: CLZSL框架通过PCL和PUP模块，减少了实例级别不匹配和类别级别不精确性，实现了更准确的视觉-语义映射，并在AWA2、SUN和CUB数据集上取得了良好的实验效果。

Conclusion: 该研究提出的CLZSL框架通过原型指导的课程学习（PCL）模块和原型更新（PUP）模块，有效缓解了实例级别不匹配和类别级别不精确的问题，提高了零样本学习中视觉-语义映射的准确性，并在AWA2、SUN和CUB等标准基准数据集上验证了其有效性。

Abstract: In Zero-Shot Learning (ZSL), embedding-based methods enable knowledge
transfer from seen to unseen classes by learning a visual-semantic mapping from
seen-class images to class-level semantic prototypes (e.g., attributes).
However, these semantic prototypes are manually defined and may introduce noisy
supervision for two main reasons: (i) instance-level mismatch: variations in
perspective, occlusion, and annotation bias will cause discrepancies between
individual sample and the class-level semantic prototypes; and (ii) class-level
imprecision: the manually defined semantic prototypes may not accurately
reflect the true semantics of the class. Consequently, the visual-semantic
mapping will be misled, reducing the effectiveness of knowledge transfer to
unseen classes. In this work, we propose a prototype-guided curriculum learning
framework (dubbed as CLZSL), which mitigates instance-level mismatches through
a Prototype-Guided Curriculum Learning (PCL) module and addresses class-level
imprecision via a Prototype Update (PUP) module. Specifically, the PCL module
prioritizes samples with high cosine similarity between their visual mappings
and the class-level semantic prototypes, and progressively advances to
less-aligned samples, thereby reducing the interference of instance-level
mismatches to achieve accurate visual-semantic mapping. Besides, the PUP module
dynamically updates the class-level semantic prototypes by leveraging the
visual mappings learned from instances, thereby reducing class-level
imprecision and further improving the visual-semantic mapping. Experiments were
conducted on standard benchmark datasets-AWA2, SUN, and CUB-to verify the
effectiveness of our method.

</details>


### [156] [Forecasting Continuous Non-Conservative Dynamical Systems in SO(3)](https://arxiv.org/abs/2508.07775)
*Lennart Bastian,Mohammad Rashed,Nassir Navab,Tolga Birdal*

Main category: cs.CV

TL;DR: 一个利用神经控制微分方程和SO(3) Savitzky-Golay路径来外推三维旋转的新方法，该方法能很好地处理噪声和非保守力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理现实世界中的非保守力、未知的物理参数以及对噪声观测值的鲁棒性方面存在挑战。

Method: 提出了一种在三维旋转流形上对噪声位姿估计轨迹进行建模的方法，该方法利用神经控制微分方程，并结合SO(3) Savitzky-Golay路径进行引导。

Result: 所提出的方法在模拟和现实世界设置中都具有强大的外推能力，并且可以很好地泛化到具有未知物理参数的轨迹。 

Conclusion: 该方法可以很好地处理现实世界中存在的未知的物理参数，并且在模拟和各种现实场景中都表现出了强大的外推能力。

Abstract: Modeling the rotation of moving objects is a fundamental task in computer
vision, yet $SO(3)$ extrapolation still presents numerous challenges: (1)
unknown quantities such as the moment of inertia complicate dynamics, (2) the
presence of external forces and torques can lead to non-conservative
kinematics, and (3) estimating evolving state trajectories under sparse, noisy
observations requires robustness. We propose modeling trajectories of noisy
pose estimates on the manifold of 3D rotations in a physically and
geometrically meaningful way by leveraging Neural Controlled Differential
Equations guided with $SO(3)$ Savitzky-Golay paths. Existing extrapolation
methods often rely on energy conservation or constant velocity assumptions,
limiting their applicability in real-world scenarios involving non-conservative
forces. In contrast, our approach is agnostic to energy and momentum
conservation while being robust to input noise, making it applicable to
complex, non-inertial systems. Our approach is easily integrated as a module in
existing pipelines and generalizes well to trajectories with unknown physical
parameters. By learning to approximate object dynamics from noisy states during
training, our model attains robust extrapolation capabilities in simulation and
various real-world settings. Code is available at
https://github.com/bastianlb/forecasting-rotational-dynamics

</details>


### [157] [GaitSnippet: Gait Recognition Beyond Unordered Sets and Ordered Sequences](https://arxiv.org/abs/2508.07782)
*Saihui Hou,Chenye Wang,Wenpeng Lang,Zhengxiang Lan,Yongzhen Huang*

Main category: cs.CV

TL;DR: 提出了一种新颖的步态识别方法，将步态视为由随机帧组成的“步态片段”的组合，以捕捉多尺度时间上下文，有效解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于集合和基于序列的步态识别方法存在局限性：基于集合的方法忽略了帧的短期时间上下文，而基于序列的方法难以有效捕捉长期时间依赖性。

Method: 提出了一种新的步态识别视角，将步态视为个体化动作的组合，并引入了步态片段（snippet）的概念。通过随机选取连续片段中的帧来构成片段，从而结合多尺度时间上下文，促进更全面的步态特征学习。具体实现上，重点关注了片段采样和片段建模。

Result: 在四个广泛使用的数据集上进行了广泛的实验，验证了所提出方法（基于步态片段）的有效性。

Conclusion: 该方法在Gait3D和GREW数据集上分别取得了77.5%和81.7%的秩一准确率，证明了步态片段的有效性和潜力。

Abstract: Recent advancements in gait recognition have significantly enhanced
performance by treating silhouettes as either an unordered set or an ordered
sequence. However, both set-based and sequence-based approaches exhibit notable
limitations. Specifically, set-based methods tend to overlook short-range
temporal context for individual frames, while sequence-based methods struggle
to capture long-range temporal dependencies effectively. To address these
challenges, we draw inspiration from human identification and propose a new
perspective that conceptualizes human gait as a composition of individualized
actions. Each action is represented by a series of frames, randomly selected
from a continuous segment of the sequence, which we term a snippet.
Fundamentally, the collection of snippets for a given sequence enables the
incorporation of multi-scale temporal context, facilitating more comprehensive
gait feature learning. Moreover, we introduce a non-trivial solution for
snippet-based gait recognition, focusing on Snippet Sampling and Snippet
Modeling as key components. Extensive experiments on four widely-used gait
datasets validate the effectiveness of our proposed approach and, more
importantly, highlight the potential of gait snippets. For instance, our method
achieves the rank-1 accuracy of 77.5% on Gait3D and 81.7% on GREW using a 2D
convolution-based backbone.

</details>


### [158] [Boosting Active Defense Persistence: A Two-Stage Defense Framework Combining Interruption and Poisoning Against Deepfake](https://arxiv.org/abs/2508.07795)
*Hongrui Zheng,Yuezun Li,Liejun Wang,Yunfeng Diao,Zhiqing Guo*

Main category: cs.CV

TL;DR: 提出了一种两阶段防御框架（TSDF），通过扭曲伪造内容和毒化数据源来防止攻击者模型适应，从而实现比现有方法更持久的深度伪造防御。


<details>
  <summary>Details</summary>
Motivation: 现有的主动防御策略在应对深度伪造技术方面缺乏持久性，容易被攻击者通过收集受保护样本并重新训练模型来绕过。这种静态防御在面对模型再训练时会失效，严重限制了其实际应用。

Method: 提出了一种创新的两阶段防御框架（TSDF），利用了强度分离机制和双功能对抗性扰动。该扰动能够直接扭曲伪造内容，并作为一种毒化载体，破坏攻击者再训练流程所必需的数据准备过程。

Result: 实验表明，与传统中断方法在对抗性再训练下的性能急剧下降不同，TSDF展现了强大的双重防御能力，提高了主动防御的持久性。

Conclusion: 该防御框架通过在数据源中引入毒性，旨在阻止攻击者的模型适应防御性扰动，从而确保防御的长期有效性。

Abstract: Active defense strategies have been developed to counter the threat of
deepfake technology. However, a primary challenge is their lack of persistence,
as their effectiveness is often short-lived. Attackers can bypass these
defenses by simply collecting protected samples and retraining their models.
This means that static defenses inevitably fail when attackers retrain their
models, which severely limits practical use. We argue that an effective defense
not only distorts forged content but also blocks the model's ability to adapt,
which occurs when attackers retrain their models on protected images. To
achieve this, we propose an innovative Two-Stage Defense Framework (TSDF).
Benefiting from the intensity separation mechanism designed in this paper, the
framework uses dual-function adversarial perturbations to perform two roles.
First, it can directly distort the forged results. Second, it acts as a
poisoning vehicle that disrupts the data preparation process essential for an
attacker's retraining pipeline. By poisoning the data source, TSDF aims to
prevent the attacker's model from adapting to the defensive perturbations, thus
ensuring the defense remains effective long-term. Comprehensive experiments
show that the performance of traditional interruption methods degrades sharply
when it is subjected to adversarial retraining. However, our framework shows a
strong dual defense capability, which can improve the persistence of active
defense. Our code will be available at https://github.com/vpsg-research/TSDF.

</details>


### [159] [Power Battery Detection](https://arxiv.org/abs/2508.07797)
*Xiaoqi Zhao,Peiqian Cao,Lihe Zhang,Zonglei Feng,Hanqi Liu,Jiaming Zuo,Youwei Pang,Weisi Lin,Georges El Fakhri,Huchuan Lu,Xiaofeng Liu*

Main category: cs.CV

TL;DR: 该研究提出了用于动力电池X射线图像缺陷检测的PBD5K数据集和MDCNeXt模型。MDCNeXt通过多维度结构线索提取和专门设计的模块，提高了检测精度和鲁棒性，解决了传统方法在处理密集极耳和视觉干扰方面的不足。


<details>
  <summary>Details</summary>
Motivation: 电动汽车的动力电池内部结构缺陷可能引发严重的安全问题。手动检测效率低下且易出错，而传统的视觉算法难以处理密集排列的极耳、低对比度、尺度变化和成像伪影等问题。因此，有必要研究新的自动化检测方法来解决这些挑战。

Method: 研究提出了PBD5K数据集和MDCNeXt模型。PBD5K数据集包含5000张动力电池X射线图像，并进行了细粒度标注和干扰项标注。MDCNeXt模型将PBD任务建模为点级分割问题，提出了一种包含点、线、计数信息提取的多维度结构线索整合方法，并引入了提示过滤模块和密度感知重排序模块来提高模型性能。此外，还提出了一种距离自适应掩码生成策略作为模型的监督。

Result: MDCNeXt在PBD5K基准上取得了优于其他对比方法的性能，证明了其有效性。所提出的方法能够有效地从X射线图像中提取和整合多维度结构线索，并能处理密集排列的极耳和视觉干扰。

Conclusion: 该研究提出了PBD5K基准和MDCNeXt模型，用于解决动力电池X射线图像中的结构缺陷检测问题。PBD5K是首个大规模的该任务基准，包含5000张X射线图像和细粒度标注。MDCNeXt模型通过提取和整合点、线、计数等多维度结构线索，并结合了用于学习对比关系的提示过滤模块和用于处理高密度区域的密度感知重排序模块，以提高对缺陷的检测能力并抑制视觉干扰。研究还提出了一种距离自适应掩码生成策略，为模型提供鲁棒的监督。

Abstract: Power batteries are essential components in electric vehicles, where internal
structural defects can pose serious safety risks. We conduct a comprehensive
study on a new task, power battery detection (PBD), which aims to localize the
dense endpoints of cathode and anode plates from industrial X-ray images for
quality inspection. Manual inspection is inefficient and error-prone, while
traditional vision algorithms struggle with densely packed plates, low
contrast, scale variation, and imaging artifacts. To address this issue and
drive more attention into this meaningful task, we present PBD5K, the first
large-scale benchmark for this task, consisting of 5,000 X-ray images from nine
battery types with fine-grained annotations and eight types of real-world
visual interference. To support scalable and consistent labeling, we develop an
intelligent annotation pipeline that combines image filtering, model-assisted
pre-labeling, cross-verification, and layered quality evaluation. We formulate
PBD as a point-level segmentation problem and propose MDCNeXt, a model designed
to extract and integrate multi-dimensional structure clues including point,
line, and count information from the plate itself. To improve discrimination
between plates and suppress visual interference, MDCNeXt incorporates two state
space modules. The first is a prompt-filtered module that learns contrastive
relationships guided by task-specific prompts. The second is a density-aware
reordering module that refines segmentation in regions with high plate density.
In addition, we propose a distance-adaptive mask generation strategy to provide
robust supervision under varying spatial distributions of anode and cathode
positions. The source code and datasets will be publicly available at
\href{https://github.com/Xiaoqi-Zhao-DLUT/X-ray-PBD}{PBD5K}.

</details>


### [160] [MambaTrans: Multimodal Fusion Image Translation via Large Language Model Priors for Downstream Visual Tasks](https://arxiv.org/abs/2508.07803)
*Yushen Xu,Xiaosong Li,Zhenyu Kuang,Xiaoqi Cheng,Haishu Tan,Huafeng Li*

Main category: cs.CV

TL;DR: MambaTrans translates multimodal fused images for downstream tasks by using LLM descriptions and segmentation masks, improving performance without retraining.


<details>
  <summary>Details</summary>
Motivation: Existing downstream pre-training models are typically trained on visible images. However, the significant pixel distribution differences between visible and multimodal fusion images can degrade downstream task performance, sometimes even below that of using only visible images. This paper explores adapting multimodal fused images with significant modality differences to object detection and semantic segmentation models trained on visible images.

Method: MambaTrans, a novel multimodal fusion image modality translator, uses descriptions from a multimodal large language model and masks from semantic segmentation models as input. Its core component, the Multi-Model State Space Block, combines mask-image-text cross-attention and a 3D-Selective Scan Module, enhancing pure visual capabilities. By leveraging object detection prior knowledge, MambaTrans minimizes detection loss during training and captures long-term dependencies among text, masks, and images.

Result: Experiments on public datasets show that MambaTrans effectively improves multimodal image performance in downstream tasks.

Conclusion: MambaTrans effectively improves multimodal image performance in downstream tasks, enabling favorable results in pre-trained models without adjusting their parameters.

Abstract: The goal of multimodal image fusion is to integrate complementary information
from infrared and visible images, generating multimodal fused images for
downstream tasks. Existing downstream pre-training models are typically trained
on visible images. However, the significant pixel distribution differences
between visible and multimodal fusion images can degrade downstream task
performance, sometimes even below that of using only visible images. This paper
explores adapting multimodal fused images with significant modality differences
to object detection and semantic segmentation models trained on visible images.
To address this, we propose MambaTrans, a novel multimodal fusion image
modality translator. MambaTrans uses descriptions from a multimodal large
language model and masks from semantic segmentation models as input. Its core
component, the Multi-Model State Space Block, combines mask-image-text
cross-attention and a 3D-Selective Scan Module, enhancing pure visual
capabilities. By leveraging object detection prior knowledge, MambaTrans
minimizes detection loss during training and captures long-term dependencies
among text, masks, and images. This enables favorable results in pre-trained
models without adjusting their parameters. Experiments on public datasets show
that MambaTrans effectively improves multimodal image performance in downstream
tasks.

</details>


### [161] [Pose-RFT: Enhancing MLLMs for 3D Pose Generation via Hybrid Action Reinforcement Fine-Tuning](https://arxiv.org/abs/2508.07804)
*Bao Li,Xiaomei Zhang,Miao Xu,Zhaoxin Fan,Xiangyu Zhu,Zhen Lei*

Main category: cs.CV

TL;DR: Pose-RFT通过强化学习和混合动作优化，提升了多模态大语言模型生成3D人体姿态的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于监督学习的姿态特定多模态大语言模型（MLLMs）在3D人体姿态生成任务中，由于难以处理固有的模糊性和实现任务特定的对齐，效果受到限制。

Method: Pose-RFT框架，采用混合动作强化学习，引入HyGRPO算法进行联合优化，并结合空间对齐和语义一致性的任务特定奖励函数。

Result: Pose-RFT在多个3D人体姿态生成基准测试中，相比于现有的姿态特定MLLMs，性能得到了显著提升，验证了混合动作强化微调在3D姿态生成方面的有效性。

Conclusion: Pose-RFT是一个为多模态大语言模型（MLLMs）量身定制的、用于3D人体姿态生成任务的强化微调框架。通过将任务表述为混合动作强化学习问题，并引入HyGRPO算法来联合优化离散语言预测和连续姿态生成，以及结合任务特定的奖励函数，Pose-RFT在多个基准测试中显著优于现有的模型。

Abstract: Generating 3D human poses from multimodal inputs such as images or text
requires models to capture both rich spatial and semantic correspondences.
While pose-specific multimodal large language models (MLLMs) have shown promise
in this task, they are typically trained with supervised objectives such as
SMPL parameter regression or token-level prediction, which struggle to model
the inherent ambiguity and achieve task-specific alignment required for
accurate 3D pose generation. To address these limitations, we propose Pose-RFT,
a reinforcement fine-tuning framework tailored for 3D human pose generation in
MLLMs. We formulate the task as a hybrid action reinforcement learning problem
that jointly optimizes discrete language prediction and continuous pose
generation. To this end, we introduce HyGRPO, a hybrid reinforcement learning
algorithm that performs group-wise reward normalization over sampled responses
to guide joint optimization of discrete and continuous actions. Pose-RFT
further incorporates task-specific reward functions to guide optimization
towards spatial alignment in image-to-pose generation and semantic consistency
in text-to-pose generation. Extensive experiments on multiple pose generation
benchmarks demonstrate that Pose-RFT significantly improves performance over
existing pose-specific MLLMs, validating the effectiveness of hybrid action
reinforcement fine-tuning for 3D pose generation.

</details>


### [162] [DiTVR: Zero-Shot Diffusion Transformer for Video Restoration](https://arxiv.org/abs/2508.07811)
*Sicheng Gao,Nancy Mehta,Zongwei Wu,Radu Timofte*

Main category: cs.CV

TL;DR: DiTVR是一个创新的视频恢复框架，通过轨迹感知注意力和流一致采样器，解决了现有方法的局限性，并在视频恢复任务中取得了最先进的零样本性能，实现了更好的时间一致性和细节保留。


<details>
  <summary>Details</summary>
Motivation: 传统的基于回归的方法通常会产生不切实际的细节，并且需要大量的配对数据集，而最近的生成扩散模型在保证时间一致性方面面临挑战。

Method: DiTVR是一个零样本视频恢复框架，它将扩散变换器与轨迹感知注意力和小波引导、流一致采样器相结合。该注意力机制将令牌沿着光流轨迹对齐，特别强调对时间动态最敏感的关键层。时空邻域缓存根据跨帧的运动对应关系动态地选择相关的令牌。流引导采样器仅将数据一致性注入低频带，保留高频先验，同时加速收敛。

Result: DiTVR在视频恢复基准测试中建立了新的零样本状态，展示了卓越的时间一致性和细节保留能力，同时保持对流噪声和遮挡的鲁棒性。

Conclusion: DiTVR在视频恢复基准测试中建立了新的零样本状态，在保持对流噪声和遮挡的鲁棒性的同时，展示了卓越的时间一致性和细节保留能力。

Abstract: Video restoration aims to reconstruct high quality video sequences from low
quality inputs, addressing tasks such as super resolution, denoising, and
deblurring. Traditional regression based methods often produce unrealistic
details and require extensive paired datasets, while recent generative
diffusion models face challenges in ensuring temporal consistency. We introduce
DiTVR, a zero shot video restoration framework that couples a diffusion
transformer with trajectory aware attention and a wavelet guided, flow
consistent sampler. Unlike prior 3D convolutional or frame wise diffusion
approaches, our attention mechanism aligns tokens along optical flow
trajectories, with particular emphasis on vital layers that exhibit the highest
sensitivity to temporal dynamics. A spatiotemporal neighbour cache dynamically
selects relevant tokens based on motion correspondences across frames. The flow
guided sampler injects data consistency only into low-frequency bands,
preserving high frequency priors while accelerating convergence. DiTVR
establishes a new zero shot state of the art on video restoration benchmarks,
demonstrating superior temporal consistency and detail preservation while
remaining robust to flow noise and occlusions.

</details>


### [163] [Semi-supervised Multiscale Matching for SAR-Optical Image](https://arxiv.org/abs/2508.07812)
*Jingze Gai,Changchun Li*

Main category: cs.CV

TL;DR: 由于现有SAR-光学图像匹配方法需要耗费大量人力进行标注，本研究提出了一种名为S2M2-SAR的半监督学习方法，利用少量标记数据和大量未标记数据进行训练，并通过伪标签和跨模态特征解耦技术，在保证匹配精度的同时，大大降低了对标记数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有大多数SAR-光学图像匹配方法依赖于像素级匹配的监督，这需要耗时且复杂的人工标注，难以收集足够的标记数据。因此，需要一种能够利用大量未标记数据的方法。

Method: 本研究设计了一个半监督的SAR-光学图像匹配流程，利用少量的标记数据和大量的未标记数据。具体方法包括：1. 提出了一种半监督多尺度匹配（S2M2-SAR）方法。2. 通过结合深度和浅层匹配结果，为未标记的SAR-光学图像对生成伪标签的相似性热图。3. 利用标记的和伪标记的相似性热图来训练匹配模型。4. 引入了一个跨模态特征增强模块，并使用无需地面真实标签的跨模态互独立损失进行训练，以促进模态共享和模态特有特征的分离。

Result: 实验结果表明，S2M2-SAR的表现优于现有的半监督方法，并能与全监督的SOTA方法相媲美。

Conclusion: S2M2-SAR的表现优于现有的半监督方法，并能与全监督的SOTA方法相媲美，证明了其效率和实际潜力。

Abstract: Driven by the complementary nature of optical and synthetic aperture radar
(SAR) images, SAR-optical image matching has garnered significant interest.
Most existing SAR-optical image matching methods aim to capture effective
matching features by employing the supervision of pixel-level matched
correspondences within SAR-optical image pairs, which, however, suffers from
time-consuming and complex manual annotation, making it difficult to collect
sufficient labeled SAR-optical image pairs. To handle this, we design a
semi-supervised SAR-optical image matching pipeline that leverages both scarce
labeled and abundant unlabeled image pairs and propose a semi-supervised
multiscale matching for SAR-optical image matching (S2M2-SAR). Specifically, we
pseudo-label those unlabeled SAR-optical image pairs with pseudo ground-truth
similarity heatmaps by combining both deep and shallow level matching results,
and train the matching model by employing labeled and pseudo-labeled similarity
heatmaps. In addition, we introduce a cross-modal feature enhancement module
trained using a cross-modality mutual independence loss, which requires no
ground-truth labels. This unsupervised objective promotes the separation of
modality-shared and modality-specific features by encouraging statistical
independence between them, enabling effective feature disentanglement across
optical and SAR modalities. To evaluate the effectiveness of S2M2-SAR, we
compare it with existing competitors on benchmark datasets. Experimental
results demonstrate that S2M2-SAR not only surpasses existing semi-supervised
methods but also achieves performance competitive with fully supervised SOTA
methods, demonstrating its efficiency and practical potential.

</details>


### [164] [Segmenting and Understanding: Region-aware Semantic Attention for Fine-grained Image Quality Assessment with Large Language Models](https://arxiv.org/abs/2508.07818)
*Chenyue Song,Chen Hui,Haiqi Zhu,Feng Jiang,Yachun Mi,Wei Zhang,Shaohui Liu*

Main category: cs.CV

TL;DR: RSFIQA通过使用SAM分割图像并利用MLLM理解区域内容和质量退化，结合RSA机制生成全局注意力图，实现了更精确的图像质量评估。


<details>
  <summary>Details</summary>
Motivation: 现有NR-IQA方法要么侧重于全局表示，导致对语义显著区域的洞察有限，要么采用统一的区域特征加权，削弱了对局部质量变化的敏感性。本研究旨在解决这些问题。

Method: 提出了一种名为RSFIQA的细粒度图像质量评估模型，该模型整合了区域级失真信息。首先利用SAM动态分割图像为非重叠语义区域，然后利用MLLM提取区域内容和感知多维度失真，最后引入区域感知语义注意力（RSA）机制聚合区域表示以生成全局注意力图。RSFIQA支持骨干网络无关性。

Result: RSFIQA模型通过整合区域级失真信息，能够感知多维度质量差异，从而提高了对局部质量变化的敏感性。

Conclusion: RSFIQA模型在多个基准数据集上实现了具有竞争力的质量预测性能，证明了其鲁棒性和有效性。

Abstract: No-reference image quality assessment (NR-IQA) aims to simulate the process
of perceiving image quality aligned with subjective human perception. However,
existing NR-IQA methods either focus on global representations that leads to
limited insights into the semantically salient regions or employ a uniform
weighting for region features that weakens the sensitivity to local quality
variations. In this paper, we propose a fine-grained image quality assessment
model, named RSFIQA, which integrates region-level distortion information to
perceive multi-dimensional quality discrepancies. To enhance regional quality
awareness, we first utilize the Segment Anything Model (SAM) to dynamically
partition the input image into non-overlapping semantic regions. For each
region, we teach a powerful Multi-modal Large Language Model (MLLM) to extract
descriptive content and perceive multi-dimensional distortions, enabling a
comprehensive understanding of both local semantics and quality degradations.
To effectively leverage this information, we introduce Region-Aware Semantic
Attention (RSA) mechanism, which generates a global attention map by
aggregating fine-grained representations from local regions. In addition,
RSFIQA is backbone-agnostic and can be seamlessly integrated into various deep
neural network architectures. Extensive experiments demonstrate the robustness
and effectiveness of the proposed method, which achieves competitive quality
prediction performance across multiple benchmark datasets.

</details>


### [165] [Architectural Co-Design for Zero-Shot Anomaly Detection: Decoupling Representation and Dynamically Fusing Features in CLIP](https://arxiv.org/abs/2508.07819)
*Ke Ma,Jun Long,Hongxiao Fei,Liujie Hua,Yueyi Luo*

Main category: cs.CV

TL;DR: 通过Conv-LoRA和DFG的架构协同设计，改进了预训练VLM在零样本异常检测中的性能。


<details>
  <summary>Details</summary>
Motivation: 预训练的视觉-语言模型（VLMs）在应用于零样本异常检测（ZSAD）时存在显著的适应性差距，原因在于其缺乏用于密集预测的局部归纳偏置以及对不灵活的特征融合的依赖。

Method: 提出了一种架构协同设计框架，通过参数高效的卷积低秩自适应（Conv-LoRA）注入局部归纳偏置以进行细粒度表示，并引入动态融合网关（DFG）自适应调制文本提示，实现强大的双向融合。

Result: 在工业和医学基准上进行了广泛的实验，证明了该方法具有优越的准确性和鲁棒性。

Conclusion: 架构协同设计能有效解决预训练视觉-语言模型在零样本异常检测任务中的局限性，通过注入局部归纳偏置和动态多模态融合，提升了模型的准确性和鲁棒性，对于将基础模型应用于密集感知任务至关重要。

Abstract: Pre-trained Vision-Language Models (VLMs) face a significant adaptation gap
when applied to Zero-Shot Anomaly Detection (ZSAD), stemming from their lack of
local inductive biases for dense prediction and their reliance on inflexible
feature fusion paradigms. We address these limitations through an Architectural
Co-Design framework that jointly refines feature representation and cross-modal
fusion. Our method integrates a parameter-efficient Convolutional Low-Rank
Adaptation (Conv-LoRA) adapter to inject local inductive biases for
fine-grained representation, and introduces a Dynamic Fusion Gateway (DFG) that
leverages visual context to adaptively modulate text prompts, enabling a
powerful bidirectional fusion. Extensive experiments on diverse industrial and
medical benchmarks demonstrate superior accuracy and robustness, validating
that this synergistic co-design is critical for robustly adapting foundation
models to dense perception tasks.

</details>


### [166] [MIMIC: Multimodal Inversion for Model Interpretation and Conceptualization](https://arxiv.org/abs/2508.07833)
*Animesh Jain,Alexandros Stergiou*

Main category: cs.CV

TL;DR: MIMIC visualizes VLM internal representations by synthesizing visual concepts from encodings, improving transparency and trust.


<details>
  <summary>Details</summary>
Motivation: To address the limited transparency and trust in Vision Language Models (VLMs) due to their complex architectures, by visualizing internal representations.

Method: MIMIC uses a joint VLM-based inversion and a feature alignment objective, with regularizers for spatial alignment, natural image smoothness, and semantic realism.

Result: MIMIC was quantitatively and qualitatively evaluated by inverting visual concepts over a range of varying-length free-form VLM output texts, using standard visual quality and semantic text-based metrics.

Conclusion: MIMIC is the first model inversion approach to address visual interpretations of VLM concepts, providing a way to visualize internal representations and synthesize corresponding visual concepts.

Abstract: Vision Language Models (VLMs) encode multimodal inputs over large, complex,
and difficult-to-interpret architectures, which limit transparency and trust.
We propose a Multimodal Inversion for Model Interpretation and
Conceptualization (MIMIC) framework to visualize the internal representations
of VLMs by synthesizing visual concepts corresponding to internal encodings.
MIMIC uses a joint VLM-based inversion and a feature alignment objective to
account for VLM's autoregressive processing. It additionally includes a triplet
of regularizers for spatial alignment, natural image smoothness, and semantic
realism. We quantitatively and qualitatively evaluate MIMIC by inverting visual
concepts over a range of varying-length free-form VLM output texts. Reported
results include both standard visual quality metrics as well as semantic
text-based metrics. To the best of our knowledge, this is the first model
inversion approach addressing visual interpretations of VLM concepts.

</details>


### [167] [Effortless Vision-Language Model Specialization in Histopathology without Annotation](https://arxiv.org/abs/2508.07835)
*Jingna Qiu,Nishanth Jain,Jonas Ammeling,Marc Aubreville,Katharina Breininger*

Main category: cs.CV

TL;DR: 无需标注即可通过继续预训练来优化视觉语言模型在组织病理学任务上的表现，性能媲美有监督方法。


<details>
  <summary>Details</summary>
Motivation: 现有的通用视觉语言模型在组织病理学特定下游任务中可能表现不佳，而有监督微调方法需要手动标注的样本。本文旨在探索一种无需标注即可适应这些模型的方法。

Method: 通过在领域相关和任务相关的图像-标题对上继续预训练，对现有的视觉语言模型（如CONCH和QuiltNet）进行无需标注的适应。

Result: 在两个VLM（CONCH和QuiltNet）和三个下游任务上的实验表明，继续预训练能够显著提升零样本和少样本性能。在较大的训练规模下，该方法性能可媲美少样本微调方法，且无需手动标注。

Conclusion: 文章提出了一种无需标注即可对视觉语言模型（VLM）进行适应的方法，通过在相关数据集的图像-标题对上继续预训练，该方法能够显著提升模型在零样本和少样本任务上的表现，并且在训练规模较大时，其性能可媲美有监督微调方法，同时无需人工标注，具有高效、任务无关和无需标注的优点，为VLM在新的组织病理学任务中的应用提供了有前景的途径。

Abstract: Recent advances in Vision-Language Models (VLMs) in histopathology, such as
CONCH and QuiltNet, have demonstrated impressive zero-shot classification
capabilities across various tasks. However, their general-purpose design may
lead to suboptimal performance in specific downstream applications. While
supervised fine-tuning methods address this issue, they require manually
labeled samples for adaptation. This paper investigates annotation-free
adaptation of VLMs through continued pretraining on domain- and task-relevant
image-caption pairs extracted from existing databases. Our experiments on two
VLMs, CONCH and QuiltNet, across three downstream tasks reveal that these pairs
substantially enhance both zero-shot and few-shot performance. Notably, with
larger training sizes, continued pretraining matches the performance of
few-shot methods while eliminating manual labeling. Its effectiveness,
task-agnostic design, and annotation-free workflow make it a promising pathway
for adapting VLMs to new histopathology tasks. Code is available at
https://github.com/DeepMicroscopy/Annotation-free-VLM-specialization.

</details>


### [168] [CBDES MoE: Hierarchically Decoupled Mixture-of-Experts for Functional Modules in Autonomous Driving](https://arxiv.org/abs/2508.07838)
*Qi Xiang,Kunsong Shi,Zhigui Lin,Lei He*

Main category: cs.CV

TL;DR: 提出了一种新颖的 CBDES MoE 架构，用于解决自动驾驶中 BEV 感知系统的局限性，通过分层解耦的专家混合方法和自注意力路由器，提高了性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态 BEV 方法通常存在输入适应性有限、建模能力受限和泛化能力不佳的问题。

Method: 提出了一种分层解耦的专家混合（Mixture-of-Experts）架构，称为 CBDES MoE，在功能模块级别。CBDES MoE 集成了多个结构上异构的专家网络，并采用轻量级自注意力路由器（SAR）门控机制，实现了动态专家路径选择以及稀疏、感知输入的有效推理。

Result: CBDES MoE 在 3D 对象检测方面持续优于固定的单一专家基线。与最强的单一专家模型相比，mAP 提高了 1.6 个百分点，NDS 提高了 4.1 个百分点。

Conclusion: CBDES MoE 在 nuScenes 数据集上持续优于固定的单一专家基线，在 3D 对象检测方面，与最强的单一专家模型相比，mAP 提高了 1.6 个百分点，NDS 提高了 4.1 个百分点，证明了所提出方法的有效性和实际优势。

Abstract: Bird's Eye View (BEV) perception systems based on multi-sensor feature fusion
have become a fundamental cornerstone for end-to-end autonomous driving.
However, existing multi-modal BEV methods commonly suffer from limited input
adaptability, constrained modeling capacity, and suboptimal generalization. To
address these challenges, we propose a hierarchically decoupled
Mixture-of-Experts architecture at the functional module level, termed
Computing Brain DEvelopment System Mixture-of-Experts (CBDES MoE). CBDES MoE
integrates multiple structurally heterogeneous expert networks with a
lightweight Self-Attention Router (SAR) gating mechanism, enabling dynamic
expert path selection and sparse, input-aware efficient inference. To the best
of our knowledge, this is the first modular Mixture-of-Experts framework
constructed at the functional module granularity within the autonomous driving
domain. Extensive evaluations on the real-world nuScenes dataset demonstrate
that CBDES MoE consistently outperforms fixed single-expert baselines in 3D
object detection. Compared to the strongest single-expert model, CBDES MoE
achieves a 1.6-point increase in mAP and a 4.1-point improvement in NDS,
demonstrating the effectiveness and practical advantages of the proposed
approach.

</details>


### [169] [Deep Space Weather Model: Long-Range Solar Flare Prediction from Multi-Wavelength Images](https://arxiv.org/abs/2508.07847)
*Shunya Nagashima,Komei Sugiura*

Main category: cs.CV

TL;DR: Deep SWM, a new model using deep state space models and a masked autoencoder, accurately predicts solar flares by analyzing solar images and their temporal dependencies. It outperforms existing methods and human experts, validated on the FlareBench benchmark.


<details>
  <summary>Details</summary>
Motivation: Accurate solar flare prediction is crucial for mitigating disruptions to critical infrastructure, but existing methods face challenges in representation learning from solar images and modeling long-range temporal dependencies.

Method: The study proposes Deep Space Weather Model (Deep SWM), which utilizes multiple deep state space models to process ten-channel solar images and capture long-range spatio-temporal dependencies. It also incorporates a sparse masked autoencoder with a two-phase masking strategy for pretraining, which preserves critical regions like sunspots while compressing spatial information. FlareBench, a new public benchmark covering a full 11-year solar activity cycle, was created to validate the method.

Result: The proposed method, Deep SWM, demonstrated superior performance and reliability compared to baseline methods and human experts on the FlareBench benchmark.

Conclusion: Deep SWM outperformed baseline methods and even human expert performance on standard metrics in terms of performance and reliability.

Abstract: Accurate, reliable solar flare prediction is crucial for mitigating potential
disruptions to critical infrastructure, while predicting solar flares remains a
significant challenge. Existing methods based on heuristic physical features
often lack representation learning from solar images. On the other hand,
end-to-end learning approaches struggle to model long-range temporal
dependencies in solar images. In this study, we propose Deep Space Weather
Model (Deep SWM), which is based on multiple deep state space models for
handling both ten-channel solar images and long-range spatio-temporal
dependencies. Deep SWM also features a sparse masked autoencoder, a novel
pretraining strategy that employs a two-phase masking approach to preserve
crucial regions such as sunspots while compressing spatial information.
Furthermore, we built FlareBench, a new public benchmark for solar flare
prediction covering a full 11-year solar activity cycle, to validate our
method. Our method outperformed baseline methods and even human expert
performance on standard metrics in terms of performance and reliability. The
project page can be found at https://keio-smilab25.github.io/DeepSWM.

</details>


### [170] [Morphological Analysis of Semiconductor Microstructures using Skeleton Graphs](https://arxiv.org/abs/2508.07850)
*Noriko Nitta,Rei Miyata,Naoto Oishi*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this paper, electron microscopy images of microstructures formed on Ge
surfaces by ion beam irradiation were processed to extract topological features
as skeleton graphs, which were then embedded using a graph convolutional
network. The resulting embeddings were analyzed using principal component
analysis, and cluster separability in the resulting PCA space was evaluated
using the Davies-Bouldin index. The results indicate that variations in
irradiation angle have a more significant impact on the morphological
properties of Ge surfaces than variations in irradiation fluence.

</details>


### [171] [Tracking Any Point Methods for Markerless 3D Tissue Tracking in Endoscopic Stereo Images](https://arxiv.org/abs/2508.07851)
*Konrad Reuter,Suresh Guttikonda,Sarah Latus,Lennart Maack,Christian Betz,Tobias Maurer,Alexander Schlaefer*

Main category: cs.CV

TL;DR: Markerless 3D tissue tracking for minimally invasive surgery using CoTracker models shows promising results, especially on biological tissue, with potential for improved surgical guidance and safety.


<details>
  <summary>Details</summary>
Motivation: Accurate tissue tracking is crucial in minimally invasive surgery to address challenges like dynamic tissue motion and limited field of view, offering support for surgical guidance, improving safety by avoiding damage to sensitive structures, and enabling context-aware robotic assistance.

Method: A novel method for markerless 3D tissue tracking is proposed by combining two CoTracker models: one for temporal tracking and one for stereo matching, to estimate 3D motion from stereo endoscopic images.

Result: The system was evaluated on synthetic 3D-printed and chicken tissue phantoms using a clinical laparoscopic setup and a robotic arm. Tracking on the chicken tissue phantom was more reliable, achieving Euclidean distance errors as low as 1.1 mm at a velocity of 10 mm/s.

Conclusion: The proposed method, leveraging two CoTracker models for temporal tracking and stereo matching, shows potential for accurate, markerless 3D tissue tracking in challenging surgical scenarios, with reliable results on chicken tissue phantoms yielding low Euclidean distance errors.

Abstract: Minimally invasive surgery presents challenges such as dynamic tissue motion
and a limited field of view. Accurate tissue tracking has the potential to
support surgical guidance, improve safety by helping avoid damage to sensitive
structures, and enable context-aware robotic assistance during complex
procedures. In this work, we propose a novel method for markerless 3D tissue
tracking by leveraging 2D Tracking Any Point (TAP) networks. Our method
combines two CoTracker models, one for temporal tracking and one for stereo
matching, to estimate 3D motion from stereo endoscopic images. We evaluate the
system using a clinical laparoscopic setup and a robotic arm simulating tissue
motion, with experiments conducted on a synthetic 3D-printed phantom and a
chicken tissue phantom. Tracking on the chicken tissue phantom yielded more
reliable results, with Euclidean distance errors as low as 1.1 mm at a velocity
of 10 mm/s. These findings highlight the potential of TAP-based models for
accurate, markerless 3D tracking in challenging surgical scenarios.

</details>


### [172] [Being-M0.5: A Real-Time Controllable Vision-Language-Motion Model](https://arxiv.org/abs/2508.07863)
*Bin Cao,Sipeng Zheng,Ye Wang,Lujie Xia,Qianshan Wei,Qin Jin,Jing Liu,Zongqing Lu*

Main category: cs.CV

TL;DR: Being-M0.5是一个实时、可控的动作生成模型，通过新颖的部件感知技术和大规模数据集，解决了现有模型在可控性方面的五大挑战，并在实验中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型（VLMM）在可控性方面存在显著局限，包括对多样化指令响应不足、姿态初始化能力有限、长期序列表现不佳、对未见场景处理能力不足以及缺乏对单个身体部位的精细控制。这些问题阻碍了VLMM在实际应用中的部署。

Method: 提出了一种名为Being-M0.5的新型视觉-语言-动作模型（VLMM），该模型具有实时性和可控性。核心是采用了新颖的部件感知残差量化技术进行动作分词，以实现对单个身体部位的精确、细粒度控制。该模型基于HuMo100M数据集进行训练，该数据集包含海量的动作序列、多任务指令实例和部件级标注。

Result: Being-M0.5在多个动作生成基准测试中展现出优越的性能，并证实了其实时能力。通过部件感知残差量化技术，实现了对动作生成过程中单个身体部位的精确、细粒度控制。

Conclusion: Being-M0.5是首个实时、可控的视觉-语言-动作模型（VLMM），在多个动作生成任务上均达到了最先进的性能。HuMo100M是迄今为止最大、最全面的数据集，包含超过500万个动作序列、1000万个多任务指令实例和详细的部件级标注。通过新颖的部件感知残差量化技术，实现了对生成过程中单个身体部位的精确、细粒度控制。实验验证和效率分析均证实了Being-M0.5的优越性能和实时能力。该研究为未来开发实用的动作生成器提供了设计见解和详细的计算分析。

Abstract: Human motion generation has emerged as a critical technology with
transformative potential for real-world applications. However, existing
vision-language-motion models (VLMMs) face significant limitations that hinder
their practical deployment. We identify controllability as a main bottleneck,
manifesting in five key aspects: inadequate response to diverse human commands,
limited pose initialization capabilities, poor performance on long-term
sequences, insufficient handling of unseen scenarios, and lack of fine-grained
control over individual body parts. To overcome these limitations, we present
Being-M0.5, the first real-time, controllable VLMM that achieves
state-of-the-art performance across multiple motion generation tasks. Our
approach is built upon HuMo100M, the largest and most comprehensive human
motion dataset to date, comprising over 5 million self-collected motion
sequences, 100 million multi-task instructional instances, and detailed
part-level annotations that address a critical gap in existing datasets. We
introduce a novel part-aware residual quantization technique for motion
tokenization that enables precise, granular control over individual body parts
during generation. Extensive experimental validation demonstrates Being-M0.5's
superior performance across diverse motion benchmarks, while comprehensive
efficiency analysis confirms its real-time capabilities. Our contributions
include design insights and detailed computational analysis to guide future
development of practical motion generators. We believe that HuMo100M and
Being-M0.5 represent significant advances that will accelerate the adoption of
motion generation technologies in real-world applications. The project page is
available at https://beingbeyond.github.io/Being-M0.5.

</details>


### [173] [CATP: Contextually Adaptive Token Pruning for Efficient and Enhanced Multimodal In-Context Learning](https://arxiv.org/abs/2508.07871)
*Yanshu Li,Jianjiang Yang,Zhennan Shen,Ligong Han,Haoyan Xu,Ruixiang Tang*

Main category: cs.CV

TL;DR: CATP是一种用于多模态上下文学习的图像令牌剪枝方法，能显著提高效率并保持或提升性能。


<details>
  <summary>Details</summary>
Motivation: 现代大型视觉语言模型（LVLMs）虽然提升了视觉感知能力，但也引入了图像令牌冗余，增加了推理成本，尤其在多模态上下文学习（ICL）场景下，这种冗余会削弱模型优势并导致性能不稳定。现有的剪枝方法在多模态ICL场景下效果不佳，存在性能大幅下降的问题，因此需要新的技术来解决。

Method: CATP是一种训练无关的方法，通过两个阶段的渐进式剪枝来处理多模态上下文学习中的图像令牌冗余问题，充分考虑了跨模态的复杂交互。

Result: CATP在四个LVLMs和八个基准测试中，在去除77.8%的图像令牌后，平均性能比标准模型提升了0.6%，优于所有基线方法。同时，推理延迟平均降低了10.78%，有效提高了效率。

Conclusion: CATP方法通过渐进式剪枝有效解决了多模态上下文学习中的图像令牌冗余问题，在提高效率的同时保持甚至略微提升了性能，平均推理延迟降低了10.78%，平均性能提升了0.6%，证明了其在实际应用中的价值。

Abstract: Modern large vision-language models (LVLMs) convert each input image into a
large set of tokens, far outnumbering the text tokens. Although this improves
visual perception, it introduces severe image token redundancy. Because image
tokens carry sparse information, many add little to reasoning, yet greatly
increase inference cost. The emerging image token pruning methods tackle this
issue by identifying the most important tokens and discarding the rest. These
methods can raise efficiency with only modest performance loss. However, most
of them only consider single-image tasks and overlook multimodal in-context
learning (ICL), where redundancy is greater and efficiency is more critical.
Redundant tokens weaken the advantage of multimodal ICL for rapid domain
adaptation and cause unstable performance. Applying existing pruning methods in
this setting leads to large accuracy drops, exposing a clear gap and the need
for new techniques. Thus, we propose Contextually Adaptive Token Pruning
(CATP), a training-free pruning method targeted at multimodal ICL. CATP
consists of two stages that perform progressive pruning to fully account for
the complex cross-modal interactions in the input sequence. After removing
77.8\% of the image tokens, CATP produces an average performance gain of 0.6\%
over the vanilla model on four LVLMs and eight benchmarks, exceeding all
baselines remarkably. Meanwhile, it effectively improves efficiency by
achieving an average reduction of 10.78\% in inference latency. CATP enhances
the practical value of multimodal ICL and lays the groundwork for future
progress in interleaved image-text scenarios.

</details>


### [174] [Selective Contrastive Learning for Weakly Supervised Affordance Grounding](https://arxiv.org/abs/2508.07877)
*WonJun Moon,Hyun Seok Seong,Jae-Pil Heo*

Main category: cs.CV

TL;DR: 提出了一种选择性对比学习方法，通过结合零件和物体级别的线索，并利用互补视图来挖掘功能线索，从而克服了现有方法过度依赖分类和关注无关模式的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有方法主要依赖分类，关注与功能无关的常见特定类别模式的限制，提出了一种超越孤立零件级别学习的方法。

Method: 利用CLIP找到第一人称（以物体为中心）和第三人称（物体示例）图像中的动作相关物体，然后通过交叉引用互补视图的已发现物体，挖掘每个视角中精确的零件级功能线索，并学习区分与功能相关的区域和与功能无关的背景上下文。

Result: 实验结果证明了该方法的有效性。

Conclusion: 该方法通过选择性原型和像素对比目标，在零件和对象级别自适应地学习与功能相关的线索，从而有效地将激活从不相关的区域转移到有意义的功能线索上，实验结果证明了该方法的有效性。

Abstract: Facilitating an entity's interaction with objects requires accurately
identifying parts that afford specific actions. Weakly supervised affordance
grounding (WSAG) seeks to imitate human learning from third-person
demonstrations, where humans intuitively grasp functional parts without needing
pixel-level annotations. To achieve this, grounding is typically learned using
a shared classifier across images from different perspectives, along with
distillation strategies incorporating part discovery process. However, since
affordance-relevant parts are not always easily distinguishable, models
primarily rely on classification, often focusing on common class-specific
patterns that are unrelated to affordance. To address this limitation, we move
beyond isolated part-level learning by introducing selective prototypical and
pixel contrastive objectives that adaptively learn affordance-relevant cues at
both the part and object levels, depending on the granularity of the available
information. Initially, we find the action-associated objects in both
egocentric (object-focused) and exocentric (third-person example) images by
leveraging CLIP. Then, by cross-referencing the discovered objects of
complementary views, we excavate the precise part-level affordance clues in
each perspective. By consistently learning to distinguish affordance-relevant
regions from affordance-irrelevant background context, our approach effectively
shifts activation from irrelevant areas toward meaningful affordance cues.
Experimental results demonstrate the effectiveness of our method. Codes are
available at github.com/hynnsk/SelectiveCL.

</details>


### [175] [TAP: Parameter-efficient Task-Aware Prompting for Adverse Weather Removal](https://arxiv.org/abs/2508.07878)
*Hanting Wang,Shengpeng Ji,Shulei Wang,Hai Huang,Xiao Jin,Qifei Zhang,Tao Jin*

Main category: cs.CV

TL;DR: 提出了一种参数高效的AIO图像恢复框架，利用任务感知增强提示来处理各种恶劣天气退化，通过两阶段训练和低秩分解增强提示，以提高参数效率和任务建模的准确性，仅用2.75M参数取得了优越的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的AIO图像恢复方法通常需要为每种特定的退化类型设计专门的网络模块或参数，导致参数开销大，并且忽视了不同恢复任务之间的相关性。

Method: 提出了一种参数高效的AIO图像恢复框架，该框架利用任务感知增强提示来处理各种恶劣天气退化。采用两阶段训练范式，包括预训练阶段和提示调整阶段，以减轻任务间的参数冲突。首先，使用监督学习获取通用恢复知识，然后通过可训练的软提示将模型适应于处理特定的退化。至关重要的是，以任务感知的方式增强这些特定于任务的提示。对这些提示应用低秩分解以捕捉任务通用和任务特定的特征，并施加对比约束以更好地使其与实际的跨任务相关性保持一致。

Result: 实验结果表明，所提出的方法在仅使用2.75M参数的情况下，在不同的恢复任务上取得了优越的性能。

Conclusion: 所提出的方法通过仅使用2.75M参数在不同恢复任务上实现了卓越的性能，并且通过t-SNE分析证明了增强的提示能够提高参数效率和准确的任务建模。

Abstract: Image restoration under adverse weather conditions has been extensively
explored, leading to numerous high-performance methods. In particular, recent
advances in All-in-One approaches have shown impressive results by training on
multi-task image restoration datasets. However, most of these methods rely on
dedicated network modules or parameters for each specific degradation type,
resulting in a significant parameter overhead. Moreover, the relatedness across
different restoration tasks is often overlooked. In light of these issues, we
propose a parameter-efficient All-in-One image restoration framework that
leverages task-aware enhanced prompts to tackle various adverse weather
degradations.Specifically, we adopt a two-stage training paradigm consisting of
a pretraining phase and a prompt-tuning phase to mitigate parameter conflicts
across tasks. We first employ supervised learning to acquire general
restoration knowledge, and then adapt the model to handle specific degradation
via trainable soft prompts. Crucially, we enhance these task-specific prompts
in a task-aware manner. We apply low-rank decomposition to these prompts to
capture both task-general and task-specific characteristics, and impose
contrastive constraints to better align them with the actual inter-task
relatedness. These enhanced prompts not only improve the parameter efficiency
of the restoration model but also enable more accurate task modeling, as
evidenced by t-SNE analysis. Experimental results on different restoration
tasks demonstrate that the proposed method achieves superior performance with
only 2.75M parameters.

</details>


### [176] [NeeCo: Image Synthesis of Novel Instrument States Based on Dynamic and Deformable 3D Gaussian Reconstruction](https://arxiv.org/abs/2508.07897)
*Tianle Zeng,Junlei Hu,Gerardo Loza Galindo,Sharib Ali,Duygu Sarikaya,Pietro Valdastri,Dominic Jones*

Main category: cs.CV

TL;DR: 通过新颖的动态高斯泼溅技术，有效解决了手术数据稀疏性问题，生成的合成数据在提高下游任务性能方面表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于数据驱动的计算机视觉技术在手术自动化中虽然潜力巨大，但受限于需要大量高质量标记图像数据集，这限制了其在手术数据科学中的应用。

Method: 提出了一种新颖的动态高斯泼溅技术，通过动态高斯模型表示手术场景，并结合动态训练调整策略来处理现实世界中相机姿态校准不佳的问题。此外，还提出了一种基于动态高斯的方法来自动生成合成数据的注释。

Result: 生成的数据集在峰值信噪比（PSNR）方面达到了29.87，为同类最佳。使用该合成数据训练的医学神经网络性能比使用最先进标准数据增强方法训练的模型提高了10%，整体模型性能提高了近15%。

Conclusion: 该研究提出的动态高斯泼溅技术能够生成照片级的、带有注释的合成图像，并且在下游医学图像分析任务中表现优于传统数据增强方法，实现了近15%的性能提升。

Abstract: Computer vision-based technologies significantly enhance surgical automation
by advancing tool tracking, detection, and localization. However, Current
data-driven approaches are data-voracious, requiring large, high-quality
labeled image datasets, which limits their application in surgical data
science. Our Work introduces a novel dynamic Gaussian Splatting technique to
address the data scarcity in surgical image datasets. We propose a dynamic
Gaussian model to represent dynamic surgical scenes, enabling the rendering of
surgical instruments from unseen viewpoints and deformations with real tissue
backgrounds. We utilize a dynamic training adjustment strategy to address
challenges posed by poorly calibrated camera poses from real-world scenarios.
Additionally, we propose a method based on dynamic Gaussians for automatically
generating annotations for our synthetic data. For evaluation, we constructed a
new dataset featuring seven scenes with 14,000 frames of tool and camera motion
and tool jaw articulation, with a background of an ex-vivo porcine model. Using
this dataset, we synthetically replicate the scene deformation from the ground
truth data, allowing direct comparisons of synthetic image quality.
Experimental results illustrate that our method generates photo-realistic
labeled image datasets with the highest values in Peak-Signal-to-Noise Ratio
(29.87). We further evaluate the performance of medical-specific neural
networks trained on real and synthetic images using an unseen real-world image
dataset. Our results show that the performance of models trained on synthetic
images generated by the proposed method outperforms those trained with
state-of-the-art standard data augmentation by 10%, leading to an overall
improvement in model performances by nearly 15%.

</details>


### [177] [Stand-In: A Lightweight and Plug-and-Play Identity Control for Video Generation](https://arxiv.org/abs/2508.07901)
*Bowen Xue,Qixin Yan,Wenjing Wang,Hao Liu,Chen Li*

Main category: cs.CV

TL;DR: Stand-In是一个轻量级框架，用于生成高保真人脸视频，参数少，兼容性好。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成高保真人脸视频时存在训练参数过多和与其他AIGC工具兼容性差的问题。

Method: 提出了一种名为Stand-In的轻量级、即插即用框架，通过在预训练的视频生成模型中引入条件图像分支，并利用受限自注意力机制和条件位置映射来实现身份控制，仅需约2000对数据即可快速学习。

Result: Stand-In框架在视频质量和身份保留方面取得了优于全参数训练方法的成果，同时保持了轻量化和良好的兼容性。

Conclusion: Stand-In框架能够以极少的额外参数（约1%）实现高质量和高保真度的身份信息保留，并且能够与其他AIGC工具无缝集成，应用于多种下游任务。

Abstract: Generating high-fidelity human videos that match user-specified identities is
important yet challenging in the field of generative AI. Existing methods often
rely on an excessive number of training parameters and lack compatibility with
other AIGC tools. In this paper, we propose Stand-In, a lightweight and
plug-and-play framework for identity preservation in video generation.
Specifically, we introduce a conditional image branch into the pre-trained
video generation model. Identity control is achieved through restricted
self-attentions with conditional position mapping, and can be learned quickly
with only 2000 pairs. Despite incorporating and training just $\sim$1\%
additional parameters, our framework achieves excellent results in video
quality and identity preservation, outperforming other full-parameter training
methods. Moreover, our framework can be seamlessly integrated for other tasks,
such as subject-driven video generation, pose-referenced video generation,
stylization, and face swapping.

</details>


### [178] [CTC Transcription Alignment of the Bullinger Letters: Automatic Improvement of Annotation Quality](https://arxiv.org/abs/2508.07904)
*Marco Peer,Anna Scius-Bertrand,Andreas Fischer*

Main category: cs.CV

TL;DR: 针对历史文献的手写文本识别（HTR）挑战，特别是在处理断字等标注错误方面，我们提出了一种基于CTC的自训练方法。该方法通过将完整转录与文本行图像进行匹配来提高识别性能和对齐准确性，并发现较弱的模型有利于提高对齐精度，从而支持迭代优化。我们还发布了一个修正后的数据集子集、代码和基准测试。


<details>
  <summary>Details</summary>
Motivation: 手写文本识别（HTR）对于历史文献仍然是一个挑战，主要是由于字迹的多样性、文献的退化以及对感知布局的标注不足。在这项工作中，我们着重解决了Bullinger通信（一个16世纪的大型书信集合）中的标注错误，特别是断字问题。

Method: 提出了一种基于CTC对齐算法的自训练方法，该算法使用动态规划和在CTC损失下训练的模型输出来匹配完整转录与文本行图像。

Result: 该方法在PyLaia上以1.1个百分点的CER进行改进，并提高了对齐准确性。研究发现，较弱的模型能产生更准确的对齐，从而支持迭代训练策略。

Conclusion: 该方法可以迭代地应用于进一步提高文本识别流水线的词错误率（CER）和对齐质量。

Abstract: Handwritten text recognition for historical documents remains challenging due
to handwriting variability, degraded sources, and limited layout-aware
annotations. In this work, we address annotation errors - particularly
hyphenation issues - in the Bullinger correspondence, a large 16th-century
letter collection. We introduce a self-training method based on a CTC alignment
algorithm that matches full transcriptions to text line images using dynamic
programming and model output probabilities trained with the CTC loss. Our
approach improves performance (e.g., by 1.1 percentage points CER with PyLaia)
and increases alignment accuracy. Interestingly, we find that weaker models
yield more accurate alignments, enabling an iterative training strategy. We
release a new manually corrected subset of 100 pages from the Bullinger
dataset, along with our code and benchmarks. Our approach can be applied
iteratively to further improve the CER as well as the alignment quality for
text recognition pipelines. Code and data are available via
https://github.com/andreas-fischer-unifr/nntp.

</details>


### [179] [Generative Video Matting](https://arxiv.org/abs/2508.07905)
*Yongtao Ge,Kangyang Xie,Guangkai Xu,Mingyu Liu,Li Ke,Longtao Huang,Hui Xue,Hao Chen,Chunhua Shen*

Main category: cs.CV

TL;DR: 由于缺乏高质量的基础数据，视频抠像的效果受到限制。本研究提出了一个新颖的视频抠像方法，并结合了大规模预训练和利用预训练视频扩散模型的丰富先验知识。该方法在处理视频时具有内在的时间一致性，并且能够有效地缩小合成与真实世界场景之间的域差距。在三个基准数据集上的评估和真实场景中的案例研究均表明，该方法具有优越的性能和强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 视频抠像传统上受到高质量基础数据的限制。现有的大多数视频抠像数据集仅提供人类注释的不完美阿尔法和前景注释，这些注释在训练阶段必须与背景图像或视频进行合成。因此，以前的方法在真实世界场景中的泛化能力通常很差。

Method: 提出了一种新颖的视频抠像方法，该方法能够有效利用预训练视频扩散模型的丰富先验知识。该模型架构具有两个主要优点：1. 强大的先验知识在缩小合成与真实世界场景之间的域差距方面发挥着关键作用。2. 与大多数现有方法逐帧处理视频抠像并使用独立解码器聚合时间信息不同，该模型在设计上天然支持视频处理，确保了强大的时间一致性。此外，研究人员还强调了大规模预训练的重要性，方法包括利用多样化的合成数据和伪标签分割数据集，并开发了一个可扩展的合成数据生成流程，能够渲染多样化的人物身体和精细的头发，生成大约200个时长为3秒的视频片段用于微调。

Result: 研究人员提供了一个全面的定量评估，展示了所提出方法在三个基准数据集上的优越性能，并在各种真实场景中展示了全面的定性结果，说明了该方法强大的泛化能力。提供的代码可在https://github.com/aim-uofa/GVM找到。

Conclusion: 所提出的方法在三个基准数据集上进行了全面的定量评估，并在各种真实场景中展示了全面的定性结果，证明了其在真实世界场景中的强大泛化能力。

Abstract: Video matting has traditionally been limited by the lack of high-quality
ground-truth data. Most existing video matting datasets provide only
human-annotated imperfect alpha and foreground annotations, which must be
composited to background images or videos during the training stage. Thus, the
generalization capability of previous methods in real-world scenarios is
typically poor. In this work, we propose to solve the problem from two
perspectives. First, we emphasize the importance of large-scale pre-training by
pursuing diverse synthetic and pseudo-labeled segmentation datasets. We also
develop a scalable synthetic data generation pipeline that can render diverse
human bodies and fine-grained hairs, yielding around 200 video clips with a
3-second duration for fine-tuning. Second, we introduce a novel video matting
approach that can effectively leverage the rich priors from pre-trained video
diffusion models. This architecture offers two key advantages. First, strong
priors play a critical role in bridging the domain gap between synthetic and
real-world scenes. Second, unlike most existing methods that process video
matting frame-by-frame and use an independent decoder to aggregate temporal
information, our model is inherently designed for video, ensuring strong
temporal consistency. We provide a comprehensive quantitative evaluation across
three benchmark datasets, demonstrating our approach's superior performance,
and present comprehensive qualitative results in diverse real-world scenes,
illustrating the strong generalization capability of our method. The code is
available at https://github.com/aim-uofa/GVM.

</details>


### [180] [Mem4D: Decoupling Static and Dynamic Memory for Dynamic Scene Reconstruction](https://arxiv.org/abs/2508.07908)
*Xudong Cai,Shuo Wang,Peng Wang,Yongcai Wang,Zhaoxin Fan,Wanting Li,Tianbao Zhang,Jianrong Tao,Yeying Jin,Deying Li*

Main category: cs.CV

TL;DR: Mem4D 通过双记忆（TDM 和 PSM）解耦静态和动态信息，解决了动态场景单目重建的内存困境，实现了高精度和高效率。


<details>
  <summary>Details</summary>
Motivation: 解决动态场景单目视频重建中，内存表示在长期稳定性（静态结构）和高保真细节保留（动态运动）之间存在的固有的冲突，这种冲突导致现有方法在静态结构几何漂移或动态物体模糊不准确之间进行妥协。

Method: 提出了一种名为 Mem4D 的新颖框架，采用双记忆架构：1) 瞬态动态记忆 (TDM) 捕捉最近帧的高频运动细节；2) 持久结构记忆 (PSM) 压缩并保留长期空间信息。通过交替查询这些专用记忆，同时保持静态几何的全局一致性和动态元素的保真度。

Result: 在具有挑战性的基准测试上进行实验，结果表明该方法在保持高效率的同时，实现了最先进或有竞争力的性能。

Conclusion: Mem4D 提出了一种新颖的框架，通过解耦静态几何和动态运动的建模，解决了动态场景单目视频重建中的内存需求困境。该框架采用双记忆架构：瞬态动态记忆（TDM）用于捕捉高频运动细节，持久结构记忆（PSM）用于压缩和保留长期空间信息，以确保全局一致性和无漂移重建。实验证明，Mem4D 在保持高效率的同时，实现了最先进或有竞争力的性能。

Abstract: Reconstructing dense geometry for dynamic scenes from a monocular video is a
critical yet challenging task. Recent memory-based methods enable efficient
online reconstruction, but they fundamentally suffer from a Memory Demand
Dilemma: The memory representation faces an inherent conflict between the
long-term stability required for static structures and the rapid, high-fidelity
detail retention needed for dynamic motion. This conflict forces existing
methods into a compromise, leading to either geometric drift in static
structures or blurred, inaccurate reconstructions of dynamic objects. To
address this dilemma, we propose Mem4D, a novel framework that decouples the
modeling of static geometry and dynamic motion. Guided by this insight, we
design a dual-memory architecture: 1) The Transient Dynamics Memory (TDM)
focuses on capturing high-frequency motion details from recent frames, enabling
accurate and fine-grained modeling of dynamic content; 2) The Persistent
Structure Memory (PSM) compresses and preserves long-term spatial information,
ensuring global consistency and drift-free reconstruction for static elements.
By alternating queries to these specialized memories, Mem4D simultaneously
maintains static geometry with global consistency and reconstructs dynamic
elements with high fidelity. Experiments on challenging benchmarks demonstrate
that our method achieves state-of-the-art or competitive performance while
maintaining high efficiency. Codes will be publicly available.

</details>


### [181] [RSVLM-QA: A Benchmark Dataset for Remote Sensing Vision Language Model-based Question Answering](https://arxiv.org/abs/2508.07918)
*Xing Zi,Jinghao Xiao,Yunxiao Shi,Xian Tao,Jun Li,Ali Braytee,Mukesh Prasad*

Main category: cs.CV

TL;DR: 本研究提出了RSVLM-QA，一个大规模、标注丰富的遥感视觉问答数据集，旨在克服现有数据集的局限性，并通过包含13,820张图像和162,373个问答对，有效评估和推动遥感领域视觉语言模型的发展。


<details>
  <summary>Details</summary>
Motivation: 现有遥感领域视觉问答（RS VQA）数据集在标注丰富度、问题多样性和特定推理能力评估方面存在局限性。本研究旨在创建一个更大规模、标注更丰富、问题更多样化的RS VQA数据集。

Method: 本研究提出了RSVLM-QA数据集，该数据集通过整合多个遥感数据集并采用创新的双轨道标注生成流程构建，特别是利用GPT-4.1自动生成详细标注和问答对，并针对遥感图像中的物体计数问题开发了专门的自动化流程。

Result: RSVLM-QA数据集包含13,820张图像和162,373个问答对，具有丰富的标注和多样的提问类型。通过在六个主流视觉语言模型（VLMs）上的基准实验表明，该数据集能有效评估和挑战当前VLMs在遥感领域的理解和推理能力。

Conclusion: RSVLM-QA数据集为遥感领域视觉问答研究提供了丰富的数据资源和有效的评估基准，有望推动该领域的发展。

Abstract: Visual Question Answering (VQA) in remote sensing (RS) is pivotal for
interpreting Earth observation data. However, existing RS VQA datasets are
constrained by limitations in annotation richness, question diversity, and the
assessment of specific reasoning capabilities. This paper introduces RSVLM-QA
dataset, a new large-scale, content-rich VQA dataset for the RS domain.
RSVLM-QA is constructed by integrating data from several prominent RS
segmentation and detection datasets: WHU, LoveDA, INRIA, and iSAID. We employ
an innovative dual-track annotation generation pipeline. Firstly, we leverage
Large Language Models (LLMs), specifically GPT-4.1, with meticulously designed
prompts to automatically generate a suite of detailed annotations including
image captions, spatial relations, and semantic tags, alongside complex
caption-based VQA pairs. Secondly, to address the challenging task of object
counting in RS imagery, we have developed a specialized automated process that
extracts object counts directly from the original segmentation data; GPT-4.1
then formulates natural language answers from these counts, which are paired
with preset question templates to create counting QA pairs. RSVLM-QA comprises
13,820 images and 162,373 VQA pairs, featuring extensive annotations and
diverse question types. We provide a detailed statistical analysis of the
dataset and a comparison with existing RS VQA benchmarks, highlighting the
superior depth and breadth of RSVLM-QA's annotations. Furthermore, we conduct
benchmark experiments on Six mainstream Vision Language Models (VLMs),
demonstrating that RSVLM-QA effectively evaluates and challenges the
understanding and reasoning abilities of current VLMs in the RS domain. We
believe RSVLM-QA will serve as a pivotal resource for the RS VQA and VLM
research communities, poised to catalyze advancements in the field.

</details>


### [182] [Safeguarding Generative AI Applications in Preclinical Imaging through Hybrid Anomaly Detection](https://arxiv.org/abs/2508.07923)
*Jakub Binda,Valentina Paneta,Vasileios Eleftheriadis,Hongkyou Chung,Panagiotis Papadimitroulas,Neo Christopher Chung*

Main category: cs.CV

TL;DR: 本研究提出了一种混合异常检测框架，用于提高核医学领域生成式人工智能（GenAI）模型的可靠性，通过在 X 射线生成和辐射剂量图估计等应用中检测异常来增强质量控制和工业可行性。


<details>
  <summary>Details</summary>
Motivation: 在核医学领域，生成式人工智能（GenAI）在自动化和增强数据合成方面具有巨大潜力，但生物医学成像的高风险性需要强大的机制来检测和管理模型行为的异常，以确保可靠性和安全性。

Method: 本研究引入并实现了一种混合异常检测框架，并在两个应用（Pose2Xray 和 DosimetrEYE）中进行了演示，以检测和管理 GenAI 模型的意外或错误行为。

Result: 通过在 Pose2Xray 和 DosimetrEYE 应用中集成异常检测（OD），本研究证明了该框架能够提高可靠性、减少人工监督并支持实时质量控制。

Conclusion: 本研究提出了一种混合异常检测框架，用于保护核医学领域生成式人工智能（GenAI）模型的稳健性、可扩展性和合规性，从而增强其在临床前环境中的工业可行性。

Abstract: Generative AI holds great potentials to automate and enhance data synthesis
in nuclear medicine. However, the high-stakes nature of biomedical imaging
necessitates robust mechanisms to detect and manage unexpected or erroneous
model behavior. We introduce development and implementation of a hybrid anomaly
detection framework to safeguard GenAI models in BIOEMTECH's eyes(TM) systems.
Two applications are demonstrated: Pose2Xray, which generates synthetic X-rays
from photographic mouse images, and DosimetrEYE, which estimates 3D radiation
dose maps from 2D SPECT/CT scans. In both cases, our outlier detection (OD)
enhances reliability, reduces manual oversight, and supports real-time quality
control. This approach strengthens the industrial viability of GenAI in
preclinical settings by increasing robustness, scalability, and regulatory
compliance.

</details>


### [183] [TAG: A Simple Yet Effective Temporal-Aware Approach for Zero-Shot Video Temporal Grounding](https://arxiv.org/abs/2508.07925)
*Jin-Seop Lee,SungJoon Lee,Jaehan Ahn,YunSeok Choi,Jee-Hyong Lee*

Main category: cs.CV

TL;DR: TAG is a new approach for zero-shot video temporal grounding that improves accuracy and efficiency by incorporating temporal awareness and avoiding LLMs.


<details>
  <summary>Details</summary>
Motivation: Existing zero-shot VTG methods suffer from semantic fragmentation, skewed similarity distributions, and heavy reliance on expensive LLM inferences. This work proposes TAG to address these limitations.

Method: TAG incorporates temporal pooling, temporal coherence clustering, and similarity adjustment to address semantic fragmentation and skewed similarity distributions in zero-shot video temporal grounding.

Result: TAG achieves state-of-the-art results on Charades-STA and ActivityNet Captions benchmark datasets.

Conclusion: TAG effectively captures temporal context and addresses distorted similarity distributions without training, achieving state-of-the-art results on Charades-STA and ActivityNet Captions benchmark datasets without relying on LLMs.

Abstract: Video Temporal Grounding (VTG) aims to extract relevant video segments based
on a given natural language query. Recently, zero-shot VTG methods have gained
attention by leveraging pretrained vision-language models (VLMs) to localize
target moments without additional training. However, existing approaches suffer
from semantic fragmentation, where temporally continuous frames sharing the
same semantics are split across multiple segments. When segments are
fragmented, it becomes difficult to predict an accurate target moment that
aligns with the text query. Also, they rely on skewed similarity distributions
for localization, making it difficult to select the optimal segment.
Furthermore, they heavily depend on the use of LLMs which require expensive
inferences. To address these limitations, we propose a \textit{TAG}, a simple
yet effective Temporal-Aware approach for zero-shot video temporal Grounding,
which incorporates temporal pooling, temporal coherence clustering, and
similarity adjustment. Our proposed method effectively captures the temporal
context of videos and addresses distorted similarity distributions without
training. Our approach achieves state-of-the-art results on Charades-STA and
ActivityNet Captions benchmark datasets without rely on LLMs. Our code is
available at https://github.com/Nuetee/TAG

</details>


### [184] [VOIDFace: A Privacy-Preserving Multi-Network Face Recognition With Enhanced Security](https://arxiv.org/abs/2508.07960)
*Ajnas Muhammed,Iurri Medvedev,Nuno Gonçalves*

Main category: cs.CV

TL;DR: VOIDFace is a novel framework for facial recognition that enhances privacy, security, and efficiency by using visual secret sharing to eliminate data replication and improve user control, while a patch-based multi-training network ensures robust recognition. It also enables users to exercise their Right-To-Be-Forgotten.


<details>
  <summary>Details</summary>
Motivation: Current facial recognition systems face issues with data replication, complicating database management, and lack of user control over personal data, raising privacy and ethical concerns. VOIDFace aims to address these issues.

Method: VOIDFace uses visual secret sharing to securely store training face data, eliminating data replication and improving data control. It also proposes a patch-based multi-training network for privacy-preserving facial recognition.

Result: Experimental evaluations on the VGGFace2 dataset show that VOIDFace provides Right-To-Be-Forgotten, improved data control, security, and privacy while maintaining competitive facial recognition performance.

Conclusion: VOIDFace provides Right-To-Be-Forgotten, improved data control, security, and privacy while maintaining competitive facial recognition performance.

Abstract: Advancement of machine learning techniques, combined with the availability of
large-scale datasets, has significantly improved the accuracy and efficiency of
facial recognition. Modern facial recognition systems are trained using large
face datasets collected from diverse individuals or public repositories.
However, for training, these datasets are often replicated and stored in
multiple workstations, resulting in data replication, which complicates
database management and oversight. Currently, once a user submits their face
for dataset preparation, they lose control over how their data is used, raising
significant privacy and ethical concerns. This paper introduces VOIDFace, a
novel framework for facial recognition systems that addresses two major issues.
First, it eliminates the need of data replication and improves data control to
securely store training face data by using visual secret sharing. Second, it
proposes a patch-based multi-training network that uses this novel training
data storage mechanism to develop a robust, privacy-preserving facial
recognition system. By integrating these advancements, VOIDFace aims to improve
the privacy, security, and efficiency of facial recognition training, while
ensuring greater control over sensitive personal face data. VOIDFace also
enables users to exercise their Right-To-Be-Forgotten property to control their
personal data. Experimental evaluations on the VGGFace2 dataset show that
VOIDFace provides Right-To-Be-Forgotten, improved data control, security, and
privacy while maintaining competitive facial recognition performance. Code is
available at: https://github.com/ajnasmuhammed89/VOIDFace

</details>


### [185] [TrackOR: Towards Personalized Intelligent Operating Rooms Through Robust Tracking](https://arxiv.org/abs/2508.07968)
*Tony Danjun Wang,Christian Heiliger,Nassir Navab,Lennart Bastian*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Providing intelligent support to surgical teams is a key frontier in
automated surgical scene understanding, with the long-term goal of improving
patient outcomes. Developing personalized intelligence for all staff members
requires maintaining a consistent state of who is located where for long
surgical procedures, which still poses numerous computational challenges. We
propose TrackOR, a framework for tackling long-term multi-person tracking and
re-identification in the operating room. TrackOR uses 3D geometric signatures
to achieve state-of-the-art online tracking performance (+11% Association
Accuracy over the strongest baseline), while also enabling an effective offline
recovery process to create analysis-ready trajectories. Our work shows that by
leveraging 3D geometric information, persistent identity tracking becomes
attainable, enabling a critical shift towards the more granular, staff-centric
analyses required for personalized intelligent systems in the operating room.
This new capability opens up various applications, including our proposed
temporal pathway imprints that translate raw tracking data into actionable
insights for improving team efficiency and safety and ultimately providing
personalized support.

</details>


### [186] [Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation](https://arxiv.org/abs/2508.07981)
*Fangyuan Mao,Aiming Hao,Jintao Chen,Dongxia Liu,Xiaokun Feng,Jiashu Zhu,Meiqi Wu,Chubin Chen,Jiahong Wu,Xiangxiang Chu*

Main category: cs.CV

TL;DR: Omni-Effects 是一个统一的 VFX 框架，可实现多效果生成和空间控制，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前的视频生成模型在 VFX 制作方面受到每个效果 LoRA 训练的限制，这仅将生成限制为单一效果。这种根本性的限制阻碍了需要空间可控的复合效果的应用，即在指定位置同时生成多种效果。然而，将各种效果集成到统一的框架中面临着主要的挑战：效果变化造成的干扰和多 VFX 联合训练期间的空间不可控性。

Method: 提出了一种名为 Omni-Effects 的统一框架，该框架包含两个关键创新：1. 基于 LoRA 的专家混合（LoRA-MoE），它采用一组专家 LoRA，在统一的模型中集成各种效果，同时有效减轻跨任务干扰。 2. 空间感知提示（SAP），它将空间掩码信息集成到文本令牌中，从而实现精确的空间控制。此外，还引入了一个集成在 SAP 内的独立信息流（IIF）模块，以隔离对应于单个效果的控制信号，从而防止任何不期望的混合。为了便于此研究，通过结合图像编辑和第一-最后一帧到视频（FLF2V）合成的新颖数据收集管道，构建了一个全面的 VFX 数据集 Omni-VFX，并引入了一个专门的 VFX 评估框架来验证模型性能。

Result: Omni-Effects 实现了精确的空间控制和多样化的效果生成，使用户能够指定所需效果的类别和位置。

Conclusion: Omni-Effects 实现了精确的空间控制和多样化的效果生成，使用户能够指定所需效果的类别和位置。

Abstract: Visual effects (VFX) are essential visual enhancements fundamental to modern
cinematic production. Although video generation models offer cost-efficient
solutions for VFX production, current methods are constrained by per-effect
LoRA training, which limits generation to single effects. This fundamental
limitation impedes applications that require spatially controllable composite
effects, i.e., the concurrent generation of multiple effects at designated
locations. However, integrating diverse effects into a unified framework faces
major challenges: interference from effect variations and spatial
uncontrollability during multi-VFX joint training. To tackle these challenges,
we propose Omni-Effects, a first unified framework capable of generating
prompt-guided effects and spatially controllable composite effects. The core of
our framework comprises two key innovations: (1) LoRA-based Mixture of Experts
(LoRA-MoE), which employs a group of expert LoRAs, integrating diverse effects
within a unified model while effectively mitigating cross-task interference.
(2) Spatial-Aware Prompt (SAP) incorporates spatial mask information into the
text token, enabling precise spatial control. Furthermore, we introduce an
Independent-Information Flow (IIF) module integrated within the SAP, isolating
the control signals corresponding to individual effects to prevent any unwanted
blending. To facilitate this research, we construct a comprehensive VFX dataset
Omni-VFX via a novel data collection pipeline combining image editing and
First-Last Frame-to-Video (FLF2V) synthesis, and introduce a dedicated VFX
evaluation framework for validating model performance. Extensive experiments
demonstrate that Omni-Effects achieves precise spatial control and diverse
effect generation, enabling users to specify both the category and location of
desired effects.

</details>


### [187] [The Escalator Problem: Identifying Implicit Motion Blindness in AI for Accessibility](https://arxiv.org/abs/2508.07989)
*Xiantao Zhang*

Main category: cs.CV

TL;DR: 当前的多模态大语言模型（MLLMs）在感知连续运动方面存在问题（例如无法识别自动扶梯的行驶方向），这限制了它们作为辅助技术的可靠性。文章呼吁行业开发更注重物理感知和用户安全的新方法和基准。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态大语言模型（MLLMs）在辅助盲人和视障人士（BVI）方面存在关键的不可信问题，尤其是在感知运动方面，这限制了它们在现实世界应用中的潜力。

Method: 本文提出“自动扶梯问题”作为“隐性运动盲区”的典型例子，分析了当前视频理解中的帧采样范式（将视频视为离散的静态图像序列）是导致该问题的原因，并主张需要从语义识别转向物理感知。

Result: 本文识别并定义了MLLMs中的“隐性运动盲区”，并以“自动扶梯问题”为例，说明了当前模型在感知连续运动方面的局限性。

Conclusion: MLLMs在辅助盲人和视障人士方面有巨大潜力，但存在“自动扶梯问题”等关键故障模式，这源于当前视频理解中的帧采样范式，该范式难以感知连续、低信号的运动。本文旨在正式阐述这一“隐性运动盲区”，分析其对用户信任的影响，并呼吁行业范式转变，从纯粹的语义识别转向鲁棒的物理感知，并开发以人为中心的、优先考虑安全性和可靠性以及用户在动态环境中的真实需求的新基准。

Abstract: Multimodal Large Language Models (MLLMs) hold immense promise as assistive
technologies for the blind and visually impaired (BVI) community. However, we
identify a critical failure mode that undermines their trustworthiness in
real-world applications. We introduce the Escalator Problem -- the inability of
state-of-the-art models to perceive an escalator's direction of travel -- as a
canonical example of a deeper limitation we term Implicit Motion Blindness.
This blindness stems from the dominant frame-sampling paradigm in video
understanding, which, by treating videos as discrete sequences of static
images, fundamentally struggles to perceive continuous, low-signal motion. As a
position paper, our contribution is not a new model but rather to: (I) formally
articulate this blind spot, (II) analyze its implications for user trust, and
(III) issue a call to action. We advocate for a paradigm shift from purely
semantic recognition towards robust physical perception and urge the
development of new, human-centered benchmarks that prioritize safety,
reliability, and the genuine needs of users in dynamic environments.

</details>


### [188] [Prompt-Guided Relational Reasoning for Social Behavior Understanding with Vision Foundation Models](https://arxiv.org/abs/2508.07996)
*Thinesh Thiyakesan Ponbagavathi,Chengzheng Yang,Alina Roitberg*

Main category: cs.CV

TL;DR: 该研究提出了一种名为 ProGraD 的新方法，用于 Group Activity Detection (GAD)，该方法利用视觉基础模型 (VFM) 和创新的提示机制来理解群体动态。ProGraD 通过可学习的组提示和 GroupContext Transformer 来提高 GAD 的性能，尤其是在处理复杂的多小组场景时。该方法在 Cafe 和 Social-CAD 数据集上均取得了最先进的成果，并能生成可解释的注意力图。


<details>
  <summary>Details</summary>
Motivation: 视觉基础模型 (VFM) 在动作识别方面表现出色，但主要针对以物体为中心的数据进行预训练，并且在对群体动态建模方面的应用仍有待探索。虽然 VFM 是解决需要完全微调的、高度特定于任务的 GAD 架构的有希望的替代方案，但简单的 VFM 替换 VFM 带来的收益甚微，这表明需要在此基础上进行结构化、面向群体的推理。

Method: 提出了一种名为 Prompt 驱动的 Group Activity Detection (ProGraD) 的方法，该方法通过以下两个部分来弥合这一差距：1) 可学习的组提示，用于引导视觉基础模型 (VFM) 的注意力关注于社会配置；2) 一个轻量级的两层 GroupContext Transformer，用于推断演员-群体关联和集体行为。

Result: 在 Cafe 和 Social-CAD 两个 GAD 基准测试中，该方法均超越了最先进的技术。在 Cafe 数据集上，该方法在多小组场景下表现尤为出色，Group mAP@1.0 提升 6.5%，Group mAP@0.5 提升 8.2%，仅使用了 1000 万可训练参数。

Conclusion: 在复杂的、多小组的场景下，该方法尤其有效，可带来显著的性能提升（Group mAP@1.0 提升 6.5%，Group mAP@0.5 提升 8.2%），且仅使用 1000 万可训练参数。此外，实验表明 ProGraD 能够生成可解释的注意力图，为理解演员-群体推理提供见解。

Abstract: Group Activity Detection (GAD) involves recognizing social groups and their
collective behaviors in videos. Vision Foundation Models (VFMs), like DinoV2,
offer excellent features, but are pretrained primarily on object-centric data
and remain underexplored for modeling group dynamics. While they are a
promising alternative to highly task-specific GAD architectures that require
full fine-tuning, our initial investigation reveals that simply swapping CNN
backbones used in these methods with VFMs brings little gain, underscoring the
need for structured, group-aware reasoning on top.
  We introduce Prompt-driven Group Activity Detection (ProGraD) -- a method
that bridges this gap through 1) learnable group prompts to guide the VFM
attention toward social configurations, and 2) a lightweight two-layer
GroupContext Transformer that infers actor-group associations and collective
behavior. We evaluate our approach on two recent GAD benchmarks: Cafe, which
features multiple concurrent social groups, and Social-CAD, which focuses on
single-group interactions. While we surpass state-of-the-art in both settings,
our method is especially effective in complex multi-group scenarios, where we
yield a gain of 6.5\% (Group mAP\@1.0) and 8.2\% (Group mAP\@0.5) using only
10M trainable parameters. Furthermore, our experiments reveal that ProGraD
produces interpretable attention maps, offering insights into actor-group
reasoning. Code and models will be released.

</details>


### [189] [Sample-aware RandAugment: Search-free Automatic Data Augmentation for Effective Image Recognition](https://arxiv.org/abs/2508.08004)
*Anqi Xiao,Weichen Yu,Hongyuan Yu*

Main category: cs.CV

TL;DR: SRA 是一种新的自动数据增强方法，它通过动态调整增强策略来提高性能，同时保持简单和高效。


<details>
  <summary>Details</summary>
Motivation: 为了解决主流自动数据增强方法搜索过程耗时过长或策略适应不足导致性能不佳的问题，我们提出了 SRA。

Method: SRA 采用了一种不对称的、无搜索的自动数据增强方法，该方法在保持简单实现的同时动态调整增强策略。SRA 包括一个启发式评分模块，用于评估原始训练数据的复杂性，从而为每个样本应用量身定制的增强。此外，还采用不对称增强策略来最大化此评分模块的潜力。

Result: SRA 缩小了基于搜索和无搜索的自动数据增强方法之间的性能差距，在 ImageNet 上使用 ResNet-50 达到了 78.31% 的准确率。SRA 与现有的增强流程兼容，并且在新任务上具有良好的泛化性，无需调整超参数。使用 SRA 预训练的模型还增强了下游对象检测任务中的识别能力。

Conclusion: SRA 是一种有前景的自动数据增强方法，它更简单、更有效、更实用，并适用于各种未来的任务。

Abstract: Automatic data augmentation (AutoDA) plays an important role in enhancing the
generalization of neural networks. However, mainstream AutoDA methods often
encounter two challenges: either the search process is excessively
time-consuming, hindering practical application, or the performance is
suboptimal due to insufficient policy adaptation during training. To address
these issues, we propose Sample-aware RandAugment (SRA), an asymmetric,
search-free AutoDA method that dynamically adjusts augmentation policies while
maintaining straightforward implementation. SRA incorporates a heuristic
scoring module that evaluates the complexity of the original training data,
enabling the application of tailored augmentations for each sample.
Additionally, an asymmetric augmentation strategy is employed to maximize the
potential of this scoring module. In multiple experimental settings, SRA
narrows the performance gap between search-based and search-free AutoDA
methods, achieving a state-of-the-art Top-1 accuracy of 78.31\% on ImageNet
with ResNet-50. Notably, SRA demonstrates good compatibility with existing
augmentation pipelines and solid generalization across new tasks, without
requiring hyperparameter tuning. The pretrained models leveraging SRA also
enhance recognition in downstream object detection tasks. SRA represents a
promising step towards simpler, more effective, and practical AutoDA designs
applicable to a variety of future tasks. Our code is available at
\href{https://github.com/ainieli/Sample-awareRandAugment}{https://github.com/ainieli/Sample-awareRandAugment

</details>


### [190] [Mitigating Biases in Surgical Operating Rooms with Geometry](https://arxiv.org/abs/2508.08028)
*Tony Danjun Wang,Tobias Czempiel,Nassir Navab,Lennart Bastian*

Main category: cs.CV

TL;DR: 深度神经网络在 OR 人员识别中存在偏差，容易受到标准化服装的影响。本研究提出使用 3D 点云序列来编码人员，以区分身份相关的特征和外观伪影。实验证明，几何表示比 RGB 表示更能捕捉有意义的生物识别特征，在真实临床环境中表现更优。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络容易学习到虚假相关性，并利用特定于数据集的伪影，而不是有意义的特征进行预测。在 OR 中，手术服和罩衫的标准化掩盖了鲁棒的识别标志，导致 OR 人员建模任务出现模型偏差。

Method: 本研究通过将人员编码为 3D 点云序列，将与身份相关的形状和运动模式与基于外观的混淆因素分离开来，来解决偏差问题。

Result: 几何表示相比 RGB 表示更具鲁棒性，尤其是在真实的临床环境中。

Conclusion: 几何表示能够捕捉到更有意义的生物识别特征，为开发有效的 OR 人员建模方法提供了途径。RGB 模型在临床环境中准确率下降 12%，而几何方法在存在模拟伪影的数据集上表现相当。

Abstract: Deep neural networks are prone to learning spurious correlations, exploiting
dataset-specific artifacts rather than meaningful features for prediction. In
surgical operating rooms (OR), these manifest through the standardization of
smocks and gowns that obscure robust identifying landmarks, introducing model
bias for tasks related to modeling OR personnel. Through gradient-based
saliency analysis on two public OR datasets, we reveal that CNN models succumb
to such shortcuts, fixating on incidental visual cues such as footwear beneath
surgical gowns, distinctive eyewear, or other role-specific identifiers.
Avoiding such biases is essential for the next generation of intelligent
assistance systems in the OR, which should accurately recognize personalized
workflow traits, such as surgical skill level or coordination with other staff
members. We address this problem by encoding personnel as 3D point cloud
sequences, disentangling identity-relevant shape and motion patterns from
appearance-based confounders. Our experiments demonstrate that while RGB and
geometric methods achieve comparable performance on datasets with apparent
simulation artifacts, RGB models suffer a 12% accuracy drop in realistic
clinical settings with decreased visual diversity due to standardizations. This
performance gap confirms that geometric representations capture more meaningful
biometric features, providing an avenue to developing robust methods of
modeling humans in the OR.

</details>


### [191] [TRIDE: A Text-assisted Radar-Image weather-aware fusion network for Depth Estimation](https://arxiv.org/abs/2508.08038)
*Huawei Sun,Zixu Wang,Hao Feng,Julius Ott,Lorenzo Servadei,Robert Wille*

Main category: cs.CV

TL;DR: TRIDE 是一种用于自动驾驶的雷达-摄像头融合深度估计方法，它利用文本信息和天气感知技术来提高精度，尤其是在恶劣天气下。


<details>
  <summary>Details</summary>
Motivation: 为了提高自动驾驶中深度估计的准确性，尤其是在恶劣天气条件下，并探索利用视觉-语言模型进行深度估计。

Method: 该研究提出了一种结合文本生成策略、特征提取和融合技术的方法，以辅助单目深度估计。在此基础上，TRIDE 算法通过整合雷达点信息增强文本特征提取，并提出天气感知融合模块，根据天气条件自适应调整雷达权重。

Result: 在 KITTI 数据集上，所提出的方法在不同算法上均提高了准确性。在 nuScenes 数据集上，TRIDE 算法相比现有技术在 MAE（平均绝对误差）上提高了 12.87%，在 RMSE（均方根误差）上提高了 9.08%。

Conclusion: TRIDE 算法通过融合雷达和摄像头数据，并引入了天气感知融合模块，显著提高了单目深度估计的准确性，在 nuScenes 数据集上取得了优于现有技术的性能。

Abstract: Depth estimation, essential for autonomous driving, seeks to interpret the 3D
environment surrounding vehicles. The development of radar sensors, known for
their cost-efficiency and robustness, has spurred interest in radar-camera
fusion-based solutions. However, existing algorithms fuse features from these
modalities without accounting for weather conditions, despite radars being
known to be more robust than cameras under adverse weather. Additionally, while
Vision-Language models have seen rapid advancement, utilizing language
descriptions alongside other modalities for depth estimation remains an open
challenge. This paper first introduces a text-generation strategy along with
feature extraction and fusion techniques that can assist monocular depth
estimation pipelines, leading to improved accuracy across different algorithms
on the KITTI dataset. Building on this, we propose TRIDE, a radar-camera fusion
algorithm that enhances text feature extraction by incorporating radar point
information. To address the impact of weather on sensor performance, we
introduce a weather-aware fusion block that adaptively adjusts radar weighting
based on current weather conditions. Our method, benchmarked on the nuScenes
dataset, demonstrates performance gains over the state-of-the-art, achieving a
12.87% improvement in MAE and a 9.08% improvement in RMSE. Code:
https://github.com/harborsarah/TRIDE

</details>


### [192] [S^2VG: 3D Stereoscopic and Spatial Video Generation via Denoising Frame Matrix](https://arxiv.org/abs/2508.08048)
*Peng Dai,Feitong Tan,Qiangeng Xu,Yihua Huang,David Futschik,Ruofei Du,Sean Fanello,Yinda Zhang,Xiaojuan Qi*

Main category: cs.CV

TL;DR: 一种无需姿态估计和训练的方法，可以利用单视图视频生成模型来生成3D立体和空间视频。


<details>
  <summary>Details</summary>
Motivation: 为探索生成3D立体和空间视频以满足沉浸式应用需求。

Method: 提出了一种无需姿态估计和训练的方法，该方法首先利用估计的深度信息将生成的单视图视频扭曲到预定义的摄像机视点，然后应用新颖的帧矩阵修复框架。该框架利用原始视频生成模型来合成不同视点和时间戳之间的缺失内容，并采用dualupdate方案来提高视频修复质量。

Result: 生成的3D视频可以在立体对或4D高斯中进行适配，以进行空间视频合成，并且在Sora、Lumiere、WALT和Zeroscope等生成模型上进行了验证，相比现有方法有显著提升。

Conclusion: 该方法生成的3D视频在空间和时间上具有一致性，并且优于现有方法。

Abstract: While video generation models excel at producing high-quality monocular
videos, generating 3D stereoscopic and spatial videos for immersive
applications remains an underexplored challenge. We present a pose-free and
training-free method that leverages an off-the-shelf monocular video generation
model to produce immersive 3D videos. Our approach first warps the generated
monocular video into pre-defined camera viewpoints using estimated depth
information, then applies a novel \textit{frame matrix} inpainting framework.
This framework utilizes the original video generation model to synthesize
missing content across different viewpoints and timestamps, ensuring spatial
and temporal consistency without requiring additional model fine-tuning.
Moreover, we develop a \dualupdate~scheme that further improves the quality of
video inpainting by alleviating the negative effects propagated from
disoccluded areas in the latent space. The resulting multi-view videos are then
adapted into stereoscopic pairs or optimized into 4D Gaussians for spatial
video synthesis. We validate the efficacy of our proposed method by conducting
experiments on videos from various generative models, such as Sora, Lumiere,
WALT, and Zeroscope. The experiments demonstrate that our method has a
significant improvement over previous methods. Project page at:
https://daipengwa.github.io/S-2VG_ProjectPage/

</details>


### [193] [PrIINeR: Towards Prior-Informed Implicit Neural Representations for Accelerated MRI](https://arxiv.org/abs/2508.08058)
*Ziad Al-Haj Hemidi,Eytan Kats,Mattias P. Heinrich*

Main category: cs.CV

TL;DR: PrIINeR 是一种新的MRI重建方法，它利用预训练的深度学习模型来提高加速MRI图像的质量，特别是在处理高速率加速时，能够有效减少伪影并保持结构细节。


<details>
  <summary>Details</summary>
Motivation: 为了解决在高速率加速下隐式神经表示（INR）在MRI重建中存在的结构丢失和混叠伪影问题，我们提出了PrIINeR。

Method: PrIINeR 通过整合预训练深度学习模型的先验知识到INR框架中，并强制执行双重数据一致性，从而同时与采集的k空间数据和先验驱动的重建保持一致。

Result: 在NYU fastMRI数据集上的评估结果表明，PrIINeR 不仅优于目前最先进的基于INR的方法，而且在结构保持和保真度方面也优于一些最先进的学习方法，同时有效消除了混叠伪影。

Conclusion: PrIINeR 是一种结合了深度学习和隐式神经表示（INR）的MRI重建方法，能够为加速MRI提供更可靠的高质量重建解决方案。

Abstract: Accelerating Magnetic Resonance Imaging (MRI) reduces scan time but often
degrades image quality. While Implicit Neural Representations (INRs) show
promise for MRI reconstruction, they struggle at high acceleration factors due
to weak prior constraints, leading to structural loss and aliasing artefacts.
To address this, we propose PrIINeR, an INR-based MRI reconstruction method
that integrates prior knowledge from pre-trained deep learning models into the
INR framework. By combining population-level knowledge with instance-based
optimization and enforcing dual data consistency, PrIINeR aligns both with the
acquired k-space data and the prior-informed reconstruction. Evaluated on the
NYU fastMRI dataset, our method not only outperforms state-of-the-art INR-based
approaches but also improves upon several learning-based state-of-the-art
methods, significantly improving structural preservation and fidelity while
effectively removing aliasing artefacts.PrIINeR bridges deep learning and
INR-based techniques, offering a more reliable solution for high-quality,
accelerated MRI reconstruction. The code is publicly available on
https://github.com/multimodallearning/PrIINeR.

</details>


### [194] [Information Bottleneck-based Causal Attention for Multi-label Medical Image Recognition](https://arxiv.org/abs/2508.08069)
*Xiaoxiao Cui,Yiran Li,Kai He,Shanzhi Jiang,Mengli Xue,Wentao Li,Junhong Leng,Zhi Liu,Lizhen Cui,Shuo Li*

Main category: cs.CV

TL;DR: This paper introduces IBCA, a new method for multi-label classification of medical images that effectively learns class-specific attention by addressing irrelevant features, leading to improved diagnostic accuracy and interpretability. IBCA significantly outperforms existing methods on benchmark datasets.


<details>
  <summary>Details</summary>
Motivation: Current methods for multi-label classification of medical images struggle to interpret the true cause of disease identification due to inadvertent attention to class-irrelevant features. This paper addresses this challenge by proposing a new structural causal model (SCM) and an IBCA method to learn discriminative class-specific attention.

Method: A novel Information Bottleneck-based Causal Attention (IBCA) is proposed, which includes learning Gaussian mixture multi-label spatial attention to filter irrelevant information and capture class-specific attention patterns, and a contrastive enhancement-based causal intervention to mitigate spurious attention and reduce noise by aligning multi-head attention with the Gaussian mixture multi-label spatial attention.

Result: IBCA achieved improvements of 6.35% in CR, 7.72% in OR, and 5.02% in mAP for MuReD, and 1.47% in CR, 1.65% in CF1, and 1.42% in mAP for Endo, outperforming all other methods.

Conclusion: Proposed IBCA outperforms existing methods in multi-label classification of medical images, achieving significant improvements in CR, OR, and mAP on the MuReD dataset, and CR, CF1, and mAP on the Endo dataset.

Abstract: Multi-label classification (MLC) of medical images aims to identify multiple
diseases and holds significant clinical potential. A critical step is to learn
class-specific features for accurate diagnosis and improved interpretability
effectively. However, current works focus primarily on causal attention to
learn class-specific features, yet they struggle to interpret the true cause
due to the inadvertent attention to class-irrelevant features. To address this
challenge, we propose a new structural causal model (SCM) that treats
class-specific attention as a mixture of causal, spurious, and noisy factors,
and a novel Information Bottleneck-based Causal Attention (IBCA) that is
capable of learning the discriminative class-specific attention for MLC of
medical images. Specifically, we propose learning Gaussian mixture multi-label
spatial attention to filter out class-irrelevant information and capture each
class-specific attention pattern. Then a contrastive enhancement-based causal
intervention is proposed to gradually mitigate the spurious attention and
reduce noise information by aligning multi-head attention with the Gaussian
mixture multi-label spatial. Quantitative and ablation results on Endo and
MuReD show that IBCA outperforms all methods. Compared to the second-best
results for each metric, IBCA achieves improvements of 6.35\% in CR, 7.72\% in
OR, and 5.02\% in mAP for MuReD, 1.47\% in CR, and 1.65\% in CF1, and 1.42\% in
mAP for Endo.

</details>


### [195] [ME-TST+: Micro-expression Analysis via Temporal State Transition with ROI Relationship Awareness](https://arxiv.org/abs/2508.08082)
*Zizheng Guo,Bochao Zou,Junbao Zhuo,Huimin Ma*

Main category: cs.CV

TL;DR: 本研究提出ME-TST和ME-TST+两种基于状态空间模型的方法，通过视频级回归和协同策略改进了微表情的定位和识别，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的深度学习方法在微表情分析中通常采用固定窗口长度和硬分类的滑动窗口分类网络，这在实践中存在局限性。此外，这些方法将微表情的定位和识别视为两个独立任务，忽略了它们之间的内在联系。本研究旨在解决这些问题。

Method: 本研究提出两种基于状态空间模型（SSM）的架构，ME-TST和ME-TST+。ME-TST利用时态状态转换机制，将传统的滑动窗口分类方法替换为视频级回归，以更精确地捕捉微表情的时间动态并处理不同持续时间的微表情。ME-TST+在此基础上引入了多粒度区域（ROI）建模和慢快马林巴（slowfast Mamba）框架，以减少信息丢失。此外，还提出了一种在特征和结果层面进行微表情识别和定位的协同策略。

Result: 实验结果表明，所提出的ME-TST和ME-TST+方法在微表情分析任务上达到了最先进的性能。

Conclusion: 提出的ME-TST和ME-TST+方法通过利用时态状态转换机制，用视频级回归取代传统的窗口级分类，能够更精确地表征微表情的时间动态，并支持对不同持续时间的微表情进行建模。通过引入多粒度区域建模和慢快马林巴框架，ME-TST+进一步缓解了在将微表情分析视为时间序列任务时可能出现的信息丢失问题。此外，还提出了一种在特征和结果层面上进行识别和识别的协同策略，以利用它们固有的联系来提升整体分析性能。大量实验表明，所提出的方法取得了最先进的性能。

Abstract: Micro-expressions (MEs) are regarded as important indicators of an
individual's intrinsic emotions, preferences, and tendencies. ME analysis
requires spotting of ME intervals within long video sequences and recognition
of their corresponding emotional categories. Previous deep learning approaches
commonly employ sliding-window classification networks. However, the use of
fixed window lengths and hard classification presents notable limitations in
practice. Furthermore, these methods typically treat ME spotting and
recognition as two separate tasks, overlooking the essential relationship
between them. To address these challenges, this paper proposes two state space
model-based architectures, namely ME-TST and ME-TST+, which utilize temporal
state transition mechanisms to replace conventional window-level classification
with video-level regression. This enables a more precise characterization of
the temporal dynamics of MEs and supports the modeling of MEs with varying
durations. In ME-TST+, we further introduce multi-granularity ROI modeling and
the slowfast Mamba framework to alleviate information loss associated with
treating ME analysis as a time-series task. Additionally, we propose a synergy
strategy for spotting and recognition at both the feature and result levels,
leveraging their intrinsic connection to enhance overall analysis performance.
Extensive experiments demonstrate that the proposed methods achieve
state-of-the-art performance. The codes are available at
https://github.com/zizheng-guo/ME-TST.

</details>


### [196] [MDD-Net: Multimodal Depression Detection through Mutual Transformer](https://arxiv.org/abs/2508.08093)
*Md Rezwanul Haque,Md. Milon Islam,S M Taslim Uddin Raju,Hamdi Altaheri,Lobna Nassar,Fakhri Karray*

Main category: cs.CV

TL;DR: A new network (MDD-Net) uses sound and images from social media to detect depression, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: The simple nature of data collection from social media platforms has attracted significant interest in utilizing this information for mental health research, specifically for depression detection.

Method: A Multimodal Depression Detection Network (MDD-Net) is proposed, utilizing acoustic and visual data from social media networks. It employs mutual transformers to extract and fuse multimodal features through four core modules: acoustic feature extraction, visual feature extraction, mutual transformer, and detection layer.

Result: The developed MDD-Net surpasses the state-of-the-art by up to 17.37% for F1-Score on the multimodal D-Vlog dataset.

Conclusion: MDD-Net surpasses state-of-the-art by up to 17.37% for F1-Score.

Abstract: Depression is a major mental health condition that severely impacts the
emotional and physical well-being of individuals. The simple nature of data
collection from social media platforms has attracted significant interest in
properly utilizing this information for mental health research. A Multimodal
Depression Detection Network (MDD-Net), utilizing acoustic and visual data
obtained from social media networks, is proposed in this work where mutual
transformers are exploited to efficiently extract and fuse multimodal features
for efficient depression detection. The MDD-Net consists of four core modules:
an acoustic feature extraction module for retrieving relevant acoustic
attributes, a visual feature extraction module for extracting significant
high-level patterns, a mutual transformer for computing the correlations among
the generated features and fusing these features from multiple modalities, and
a detection layer for detecting depression using the fused feature
representations. The extensive experiments are performed using the multimodal
D-Vlog dataset, and the findings reveal that the developed multimodal
depression detection network surpasses the state-of-the-art by up to 17.37% for
F1-Score, demonstrating the greater performance of the proposed system. The
source code is accessible at
https://github.com/rezwanh001/Multimodal-Depression-Detection.

</details>


### [197] [3D Plant Root Skeleton Detection and Extraction](https://arxiv.org/abs/2508.08094)
*Jiakai Lin,Jinchang Zhang,Ge Jin,Wenzhan Song,Tianming Liu,Guoyu Lu*

Main category: cs.CV

TL;DR: 提出了一种从少量图像中高效提取植物根系三维结构的方法，该方法能精确捕捉根系骨架，为育种机器人提供支持，以提高育种效率。


<details>
  <summary>Details</summary>
Motivation: 植物根系的三维结构复杂且难以精确捕捉，二维研究无法满足对遗传性状和根系发育影响的研究需求，因此需要三维分析方法。

Method: 提出了一种三维根系骨架提取方法，包括侧根检测与匹配、三角测量提取侧根骨架结构以及侧根与主根的整合。

Result: 提取的三维根系骨架与真实情况高度相似，验证了该方法的有效性。

Conclusion: 该方法可以有效提取植物根系的三维结构，并为育种机器人提供支持，以提高育种效率和智能化水平。

Abstract: Plant roots typically exhibit a highly complex and dense architecture,
incorporating numerous slender lateral roots and branches, which significantly
hinders the precise capture and modeling of the entire root system.
Additionally, roots often lack sufficient texture and color information, making
it difficult to identify and track root traits using visual methods. Previous
research on roots has been largely confined to 2D studies; however, exploring
the 3D architecture of roots is crucial in botany. Since roots grow in real 3D
space, 3D phenotypic information is more critical for studying genetic traits
and their impact on root development. We have introduced a 3D root skeleton
extraction method that efficiently derives the 3D architecture of plant roots
from a few images. This method includes the detection and matching of lateral
roots, triangulation to extract the skeletal structure of lateral roots, and
the integration of lateral and primary roots. We developed a highly complex
root dataset and tested our method on it. The extracted 3D root skeletons
showed considerable similarity to the ground truth, validating the
effectiveness of the model. This method can play a significant role in
automated breeding robots. Through precise 3D root structure analysis, breeding
robots can better identify plant phenotypic traits, especially root structure
and growth patterns, helping practitioners select seeds with superior root
systems. This automated approach not only improves breeding efficiency but also
reduces manual intervention, making the breeding process more intelligent and
efficient, thus advancing modern agriculture.

</details>


### [198] [TBAC-UniImage: Unified Understanding and Generation by Ladder-Side Diffusion Tuning](https://arxiv.org/abs/2508.08098)
*Junzhe Xu,Yuyang Yin,Xi Chen*

Main category: cs.CV

TL;DR: TBAC-UniImage通过利用MLLM多层表示来指导扩散模型，实现了更深层次的多模态理解与生成统一，克服了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 克服了现有统一模型仅使用MLLM最终隐藏状态作为生成条件（连接浅）或从头开始预训练统一生成架构（计算成本高）的限制。

Method:  TBAC-UniImage将预训练的扩散模型与多模态大语言模型（MLLM）深度集成，利用MLLM的中间层表示来指导扩散模型的生成过程。

Result: TBAC-UniImage实现了更深入、更细粒度的理解和生成统一。

Conclusion: TBAC-UniImage通过使用MLLM的多个不同层的表示作为扩散模型的生成条件，实现了更深入、更细粒度的理解和生成统一。

Abstract: This paper introduces TBAC-UniImage, a novel unified model for multimodal
understanding and generation. We achieve this by deeply integrating a
pre-trained Diffusion Model, acting as a generative ladder, with a Multimodal
Large Language Model (MLLM). Previous diffusion-based unified models face two
primary limitations. One approach uses only the MLLM's final hidden state as
the generative condition. This creates a shallow connection, as the generator
is isolated from the rich, hierarchical representations within the MLLM's
intermediate layers. The other approach, pretraining a unified generative
architecture from scratch, is computationally expensive and prohibitive for
many researchers. To overcome these issues, our work explores a new paradigm.
Instead of relying on a single output, we use representations from multiple,
diverse layers of the MLLM as generative conditions for the diffusion model.
This method treats the pre-trained generator as a ladder, receiving guidance
from various depths of the MLLM's understanding process. Consequently,
TBAC-UniImage achieves a much deeper and more fine-grained unification of
understanding and generation.

</details>


### [199] [Hyperspectral Imaging](https://arxiv.org/abs/2508.08107)
*Danfeng Hong,Chenyu Li,Naoto Yokoya,Bing Zhang,Xiuping Jia,Antonio Plaza,Paolo Gamba,Jon Atli Benediktsson,Jocelyn Chanussot*

Main category: cs.CV

TL;DR: 高光谱成像（HSI）是一种先进的传感技术，可同时捕获空间和光谱信息，用于物质、化学和生物特性的无损分析。本文全面概述了HSI的原理、数据采集、分析方法（包括AI驱动技术）和跨学科应用，同时讨论了现有挑战和未来发展方向，旨在推动HSI成为一个通用的、跨学科的平台，以实现科学、技术和社会领域的变革性应用。


<details>
  <summary>Details</summary>
Motivation: 高光谱成像（HSI）能够同时捕获空间和光谱信息，实现对物质、化学和生物特性的无损、无标记分析，并能揭示人眼无法识别的亚视觉特征，从而支持先进的监测、诊断和决策。

Method: 本文全面概述了高光谱成像（HSI）的原理、传感器架构、数据采集、校准、校正、数据结构、降维、分类、光谱分解、深度学习等分析方法，并探讨了地球观测、精准农业、生物医学、工业检测、文化遗产和安全等领域的应用。

Result: 本文讨论了硬件权衡、采集变异性和高维数据复杂性等挑战，以及计算成像、物理信息建模、跨模态融合和自监督学习等新兴解决方案，并强调了数据集共享、可重复性和元数据文档的最佳实践。

Conclusion: 高光谱成像（HSI）正发展成为一个通用的、跨学科的平台，有望在科学、技术和社会领域带来变革性的应用。

Abstract: Hyperspectral imaging (HSI) is an advanced sensing modality that
simultaneously captures spatial and spectral information, enabling
non-invasive, label-free analysis of material, chemical, and biological
properties. This Primer presents a comprehensive overview of HSI, from the
underlying physical principles and sensor architectures to key steps in data
acquisition, calibration, and correction. We summarize common data structures
and highlight classical and modern analysis methods, including dimensionality
reduction, classification, spectral unmixing, and AI-driven techniques such as
deep learning. Representative applications across Earth observation, precision
agriculture, biomedicine, industrial inspection, cultural heritage, and
security are also discussed, emphasizing HSI's ability to uncover sub-visual
features for advanced monitoring, diagnostics, and decision-making. Persistent
challenges, such as hardware trade-offs, acquisition variability, and the
complexity of high-dimensional data, are examined alongside emerging solutions,
including computational imaging, physics-informed modeling, cross-modal fusion,
and self-supervised learning. Best practices for dataset sharing,
reproducibility, and metadata documentation are further highlighted to support
transparency and reuse. Looking ahead, we explore future directions toward
scalable, real-time, and embedded HSI systems, driven by sensor
miniaturization, self-supervised learning, and foundation models. As HSI
evolves into a general-purpose, cross-disciplinary platform, it holds promise
for transformative applications in science, technology, and society.

</details>


### [200] [GRASPTrack: Geometry-Reasoned Association via Segmentation and Projection for Multi-Object Tracking](https://arxiv.org/abs/2508.08117)
*Xudong Han,Pengcheng Fang,Yueying Tian,Jianhui Yu,Xiaohao Cai,Daniel Roggen,Philip Birch*

Main category: cs.CV

TL;DR: GRASPTrack通过整合深度估计和3D几何推理来解决单目MOT中的遮挡和深度歧义问题，在复杂场景下提高了跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 多目标跟踪（MOT）在单目视频中面临着遮挡和深度歧义的根本性挑战，而传统的TBD方法由于缺乏几何感知而难以解决这些问题。

Method: GRASPTrack是一个新颖的、注重深度的多目标跟踪框架，它将单目深度估计和实例分割整合到标准的TBD（跟踪-通过-检测）流程中，以生成高保真3D点云，从而实现显式的3D几何推理。这些3D点云被体素化，以实现精确且鲁棒的基于体素的3D交并比（IoU）进行空间关联。此外，该方法还结合了深度感知自适应噪声补偿，该补偿根据遮挡严重程度动态调整卡尔曼滤波器过程噪声，以实现更可靠的状态估计。还提出了一种深度增强的以观测为中心的动量，将图像平面的运动方向一致性扩展到3D空间，以改进基于运动的关联线索，特别是对于具有复杂轨迹的对象。

Result: GRASPTrack通过生成高保真3D点云，实现了显式的3D几何推理，并利用体素化实现精确且鲁棒的基于体素的3D IoU进行空间关联。通过深度感知自适应噪声补偿和深度增强的以观测为中心的动量，进一步提高了跟踪鲁棒性，尤其是在遮挡和复杂运动场景下。

Conclusion: GRASPTrack在MOT17、MOT20和DanceTrack基准测试中取得了有竞争力的性能，显著提高了在频繁遮挡和复杂运动模式下的跟踪鲁棒性。

Abstract: Multi-object tracking (MOT) in monocular videos is fundamentally challenged
by occlusions and depth ambiguity, issues that conventional
tracking-by-detection (TBD) methods struggle to resolve owing to a lack of
geometric awareness. To address these limitations, we introduce GRASPTrack, a
novel depth-aware MOT framework that integrates monocular depth estimation and
instance segmentation into a standard TBD pipeline to generate high-fidelity 3D
point clouds from 2D detections, thereby enabling explicit 3D geometric
reasoning. These 3D point clouds are then voxelized to enable a precise and
robust Voxel-Based 3D Intersection-over-Union (IoU) for spatial association. To
further enhance tracking robustness, our approach incorporates Depth-aware
Adaptive Noise Compensation, which dynamically adjusts the Kalman filter
process noise based on occlusion severity for more reliable state estimation.
Additionally, we propose a Depth-enhanced Observation-Centric Momentum, which
extends the motion direction consistency from the image plane into 3D space to
improve motion-based association cues, particularly for objects with complex
trajectories. Extensive experiments on the MOT17, MOT20, and DanceTrack
benchmarks demonstrate that our method achieves competitive performance,
significantly improving tracking robustness in complex scenes with frequent
occlusions and intricate motion patterns.

</details>


### [201] [Integrating Task-Specific and Universal Adapters for Pre-Trained Model-based Class-Incremental Learning](https://arxiv.org/abs/2508.08165)
*Yan Wang,Da-Wei Zhou,Han-Jia Ye*

Main category: cs.CV

TL;DR: TUNA 是一种新的 CIL 方法，通过结合任务特定和通用适配器来解决现有方法的局限性，并在实验中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练模型 CIL 方法在推理时选择错误的模块会损害性能，并且任务特定模块常常忽略共享的通用知识，导致区分相似类别时出错。为了解决这些挑战，提出 TUNA。

Method: 提出了一种结合任务特定适配器和通用适配器（TUNA）的方法，包括训练任务特定适配器以捕捉关键任务特征，引入基于熵的选择机制来选择最合适的适配器，并通过适配器融合策略构建一个编码跨任务共享判别性特征的通用适配器。

Result: TUNA 在各种基准数据集上展示了最先进的性能。

Conclusion: TUNA结合了任务特定适配器和通用适配器的预测，以利用专门化和通用知识进行推理，并在各种基准数据集上展示了最先进的性能。

Abstract: Class-Incremental Learning (CIL) requires a learning system to continually
learn new classes without forgetting. Existing pre-trained model-based CIL
methods often freeze the pre-trained network and adapt to incremental tasks
using additional lightweight modules such as adapters. However, incorrect
module selection during inference hurts performance, and task-specific modules
often overlook shared general knowledge, leading to errors on distinguishing
between similar classes across tasks. To address the aforementioned challenges,
we propose integrating Task-Specific and Universal Adapters (TUNA) in this
paper. Specifically, we train task-specific adapters to capture the most
crucial features relevant to their respective tasks and introduce an
entropy-based selection mechanism to choose the most suitable adapter.
Furthermore, we leverage an adapter fusion strategy to construct a universal
adapter, which encodes the most discriminative features shared across tasks. We
combine task-specific and universal adapter predictions to harness both
specialized and general knowledge during inference. Extensive experiments on
various benchmark datasets demonstrate the state-of-the-art performance of our
approach. Code is available at: https://github.com/LAMDA-CL/ICCV2025-TUNA

</details>


### [202] [Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control](https://arxiv.org/abs/2508.08134)
*Zeqian Long,Mingzhe Zheng,Kunyu Feng,Xinhua Zhang,Hongyu Liu,Harry Yang,Linfeng Zhang,Qifeng Chen,Yue Ma*

Main category: cs.CV

TL;DR: Follow-Your-Shape 框架通过轨迹发散图（TDM）和预定的 KV 注入机制，实现了精确、可控的物体形状编辑，同时保持了非目标内容的完整性，并在 ReShapeBench 基准测试中取得了优越的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有基于流的图像编辑模型在处理大尺度形状变换等具有挑战性的场景时，难以实现预期形状改变或无意中改变非目标区域的问题。

Method: 提出了一种名为 Follow-Your-Shape 的训练和掩模无关的框架。该框架通过计算轨迹发散图（TDM）来精确地定位可编辑区域，并指导预定的 KV 注入机制以实现稳定和忠实的编辑。TDM 通过比较反转和去噪路径之间的 token 级速度差异来计算。

Result: 该方法在需要大尺度形状替换的任务中实现了卓越的可编辑性和视觉保真度。

Conclusion: Follow-Your-Shape 框架在需要大尺度形状替换的任务中实现了卓越的可编辑性和视觉保真度。

Abstract: While recent flow-based image editing models demonstrate general-purpose
capabilities across diverse tasks, they often struggle to specialize in
challenging scenarios -- particularly those involving large-scale shape
transformations. When performing such structural edits, these methods either
fail to achieve the intended shape change or inadvertently alter non-target
regions, resulting in degraded background quality. We propose
Follow-Your-Shape, a training-free and mask-free framework that supports
precise and controllable editing of object shapes while strictly preserving
non-target content. Motivated by the divergence between inversion and editing
trajectories, we compute a Trajectory Divergence Map (TDM) by comparing
token-wise velocity differences between the inversion and denoising paths. The
TDM enables precise localization of editable regions and guides a Scheduled KV
Injection mechanism that ensures stable and faithful editing. To facilitate a
rigorous evaluation, we introduce ReShapeBench, a new benchmark comprising 120
new images and enriched prompt pairs specifically curated for shape-aware
editing. Experiments demonstrate that our method achieves superior editability
and visual fidelity, particularly in tasks requiring large-scale shape
replacement.

</details>


### [203] [FantasyStyle: Controllable Stylized Distillation for 3D Gaussian Splatting](https://arxiv.org/abs/2508.08136)
*Yitong Yang,Yinglin Wang,Changshuo Wang,Huajie Wang,Shuting He*

Main category: cs.CV

TL;DR: FantasyStyle利用扩散模型蒸馏和多视图频率一致性、可控风格化蒸馏来改进3DGS风格迁移，解决了现有方法的痛点，效果优于SOTA。


<details>
  <summary>Details</summary>
Motivation: 解决现有3DGS-based style transfer方法面临的多视图不一致（导致外观平滑和失真）和过度依赖VGG特征（导致内容泄露和过度风格化）的挑战。

Method: FantasyStyle框架，采用多视图频率一致性（通过3D滤波减少低频成分）和可控风格化蒸馏（引入负面引导抑制内容泄露），完全基于扩散模型蒸馏，并移除了重构项。

Result: 在各种场景和风格的实验中，FantasyStyle的风格化质量和视觉真实感持续优于最先进的方法。

Conclusion: FantasyStyle在3DGS-based style transfer方面取得了成功，相比现有方法在风格化质量和视觉真实感方面表现更优。

Abstract: The success of 3DGS in generative and editing applications has sparked
growing interest in 3DGS-based style transfer. However, current methods still
face two major challenges: (1) multi-view inconsistency often leads to style
conflicts, resulting in appearance smoothing and distortion; and (2) heavy
reliance on VGG features, which struggle to disentangle style and content from
style images, often causing content leakage and excessive stylization. To
tackle these issues, we introduce \textbf{FantasyStyle}, a 3DGS-based style
transfer framework, and the first to rely entirely on diffusion model
distillation. It comprises two key components: (1) \textbf{Multi-View Frequency
Consistency}. We enhance cross-view consistency by applying a 3D filter to
multi-view noisy latent, selectively reducing low-frequency components to
mitigate stylized prior conflicts. (2) \textbf{Controllable Stylized
Distillation}. To suppress content leakage from style images, we introduce
negative guidance to exclude undesired content. In addition, we identify the
limitations of Score Distillation Sampling and Delta Denoising Score in 3D
style transfer and remove the reconstruction term accordingly. Building on
these insights, we propose a controllable stylized distillation that leverages
negative guidance to more effectively optimize the 3D Gaussians. Extensive
experiments demonstrate that our method consistently outperforms
state-of-the-art approaches, achieving higher stylization quality and visual
realism across various scenes and styles.

</details>


### [204] [Pindrop it! Audio and Visual Deepfake Countermeasures for Robust Detection and Fine Grained-Localization](https://arxiv.org/abs/2508.08141)
*Nicholas Klein,Hemlata Tak,James Fullwood,Krishna Regmi,Leonidas Spinoulas,Ganesh Sivaraman,Tianxiang Chen,Elie Khoury*

Main category: cs.CV

TL;DR: This paper tackles the challenge of detecting deepfakes, especially those with subtle, localized manipulations, by proposing new classification and localization methods that performed exceptionally well in a major challenge.


<details>
  <summary>Details</summary>
Motivation: The rapid proliferation of new techniques in visual and audio generation underscores the need for robust solutions for detecting synthetic content in videos, especially when fine-grained alterations are performed.

Method: The paper presents methods for deepfake video classification and localization.

Result: Our methods achieved the best performance in temporal localization and a top four ranking in classification for the ACM 1M Deepfakes Detection Challenge.

Conclusion: We present solutions for deepfake video classification and localization that achieved top performance in the ACM 1M Deepfakes Detection Challenge.

Abstract: The field of visual and audio generation is burgeoning with new
state-of-the-art methods. This rapid proliferation of new techniques
underscores the need for robust solutions for detecting synthetic content in
videos. In particular, when fine-grained alterations via localized
manipulations are performed in visual, audio, or both domains, these subtle
modifications add challenges to the detection algorithms. This paper presents
solutions for the problems of deepfake video classification and localization.
The methods were submitted to the ACM 1M Deepfakes Detection Challenge,
achieving the best performance in the temporal localization task and a top four
ranking in the classification task for the TestA split of the evaluation
dataset.

</details>


### [205] [ReconDreamer-RL: Enhancing Reinforcement Learning via Diffusion-based Scene Reconstruction](https://arxiv.org/abs/2508.08170)
*Chaojun Ni,Guosheng Zhao,Xiaofeng Wang,Zheng Zhu,Wenkang Qin,Xinze Chen,Guanghong Jia,Guan Huang,Wenjun Mei*

Main category: cs.CV

TL;DR: ReconDreamer-RL 框架通过结合视频扩散模型和场景重建，并引入 DAA 和 CTG 来解决自动驾驶模拟中的 sim2real 差距和数据偏差问题，从而在训练中实现了 5 倍的碰撞率降低。


<details>
  <summary>Details</summary>
Motivation: 为了弥合模拟到现实 (sim2real) 的差距，并解决现有场景重建方法在生成新颖轨迹或转角案例场景的高质量传感器数据方面存在的局限性，本研究旨在通过集成视频扩散先验来改进用于端到端自动驾驶训练的模拟器。

Method: 提出了一种名为 ReconDreamer-RL 的框架，该框架将视频扩散模型先验与场景重建相结合，并引入动态对抗性代理 (DAA) 和表亲轨迹生成器 (CTG)。ReconSimulator 结合了用于外观建模的视频扩散先验和用于物理建模的运动学模型，以从真实世界数据中重建驾驶场景。DAA 调整了相对于自车周围车辆的轨迹，以生成转角案例交通场景。CTG 用于解决训练数据分布通常偏向简单直线运动的问题。

Result: 实验表明，ReconDreamer-RL 改进了端到端自动驾驶训练，其性能优于模仿学习方法，碰撞率降低了 5 倍。

Conclusion: ReconDreamer-RL 通过将视频扩散模型先验与场景重建相结合，并引入动态对抗性代理 (DAA) 和表亲轨迹生成器 (CTG) 来弥合模拟到现实的差距，从而改进了端到端自动驾驶模型的训练。该框架在碰撞率方面比仅模仿学习方法有 5 倍的改善。

Abstract: Reinforcement learning for training end-to-end autonomous driving models in
closed-loop simulations is gaining growing attention. However, most simulation
environments differ significantly from real-world conditions, creating a
substantial simulation-to-reality (sim2real) gap. To bridge this gap, some
approaches utilize scene reconstruction techniques to create photorealistic
environments as a simulator. While this improves realistic sensor simulation,
these methods are inherently constrained by the distribution of the training
data, making it difficult to render high-quality sensor data for novel
trajectories or corner case scenarios. Therefore, we propose ReconDreamer-RL, a
framework designed to integrate video diffusion priors into scene
reconstruction to aid reinforcement learning, thereby enhancing end-to-end
autonomous driving training. Specifically, in ReconDreamer-RL, we introduce
ReconSimulator, which combines the video diffusion prior for appearance
modeling and incorporates a kinematic model for physical modeling, thereby
reconstructing driving scenarios from real-world data. This narrows the
sim2real gap for closed-loop evaluation and reinforcement learning. To cover
more corner-case scenarios, we introduce the Dynamic Adversary Agent (DAA),
which adjusts the trajectories of surrounding vehicles relative to the ego
vehicle, autonomously generating corner-case traffic scenarios (e.g., cut-in).
Finally, the Cousin Trajectory Generator (CTG) is proposed to address the issue
of training data distribution, which is often biased toward simple
straight-line movements. Experiments show that ReconDreamer-RL improves
end-to-end autonomous driving training, outperforming imitation learning
methods with a 5x reduction in the Collision Ratio.

</details>


### [206] [CD-TVD: Contrastive Diffusion for 3D Super-Resolution with Scarce High-Resolution Time-Varying Data](https://arxiv.org/abs/2508.08173)
*Chongke Bi,Xin Gao,Jiangkang Deng,Guan*

Main category: cs.CV

TL;DR: CD-TVD是一个创新的框架，通过结合对比学习和改进的扩散模型，利用少量高分辨率数据实现科学模拟数据的3D超分辨率，解决了现有方法对大量高分辨率训练数据的依赖性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有超分辨率方法依赖大量高分辨率训练数据、限制其在多样化模拟场景中应用的问题，提出CD-TVD框架。

Method: 提出了一种结合对比学习和改进的基于扩散的超分辨率模型（CD-TVD）的框架。该框架在预训练阶段利用历史模拟数据，让对比编码器和扩散超分辨率模块学习高分辨率和低分辨率样本的退化模式和详细特征。在训练阶段，通过引入局部注意力机制的改进扩散模型，仅使用一个新生成的高分辨率时间步长进行微调，从而利用编码器学习到的退化知识。

Result: 实验结果表明，CD-TVD在流体和大气模拟数据集上实现了准确且资源高效的3D超分辨率。

Conclusion: CD-TVD框架能够对3D数据进行精确且资源高效的超分辨率处理，显著提升了大规模科学模拟中的数据增强能力。

Abstract: Large-scale scientific simulations require significant resources to generate
high-resolution time-varying data (TVD). While super-resolution is an efficient
post-processing strategy to reduce costs, existing methods rely on a large
amount of HR training data, limiting their applicability to diverse simulation
scenarios. To address this constraint, we proposed CD-TVD, a novel framework
that combines contrastive learning and an improved diffusion-based
super-resolution model to achieve accurate 3D super-resolution from limited
time-step high-resolution data. During pre-training on historical simulation
data, the contrastive encoder and diffusion superresolution modules learn
degradation patterns and detailed features of high-resolution and
low-resolution samples. In the training phase, the improved diffusion model
with a local attention mechanism is fine-tuned using only one newly generated
high-resolution timestep, leveraging the degradation knowledge learned by the
encoder. This design minimizes the reliance on large-scale high-resolution
datasets while maintaining the capability to recover fine-grained details.
Experimental results on fluid and atmospheric simulation datasets confirm that
CD-TVD delivers accurate and resource-efficient 3D super-resolution, marking a
significant advancement in data augmentation for large-scale scientific
simulations. The code is available at
https://github.com/Xin-Gao-private/CD-TVD.

</details>


### [207] [MedReasoner: Reinforcement Learning Drives Reasoning Grounding from Clinical Thought to Pixel-Level Precision](https://arxiv.org/abs/2508.08177)
*Zhonghao Yan,Muxi Diao,Yuxuan Yang,Jiayuan Xu,Kaizhou Zhang,Ruoyan Jing,Lele Yang,Yanxi Liu,Kongming Liang,Zhanyu Ma*

Main category: cs.CV

TL;DR: 该研究提出了UMRG任务和U-MRG-14K数据集，并介绍了一个名为MedReasoner的框架，该框架利用强化学习和MLLM来改进医学影像中的隐式查询区域定位。


<details>
  <summary>Details</summary>
Motivation: 当前医学影像中的区域定位（ROI）依赖于有监督的微调和明确的空间提示，这使得它们难以处理临床实践中常见的隐式查询。因此，需要一种新的方法来处理隐式查询并进行精确的区域定位。

Method: 提出了一种名为MedReasoner的模块化框架，该框架将推理与分割任务分离开来。推理部分由一个MLLM（大型多模态语言模型）负责，并使用强化学习进行优化。分割部分则依赖于一个冻结的分割专家，该专家将空间提示转换为掩码。通过格式和准确性奖励来实现推理和分割的对齐。

Result: MedReasoner在U-MRG-14K数据集上取得了最先进的性能，并且在处理未知的临床查询时表现出强大的泛化能力。

Conclusion: 该研究提出了统一医学推理基础（UMRG）这一新视觉-语言任务，并发布了包含14K个样本、支持10种模态、15个超类和108个具体类别的U-MRG-14K数据集。此外，该研究还介绍了MedReasoner框架，该框架将推理与分割分开，使用强化学习优化MLLM推理器，并冻结分割专家以生成掩码。MedReasoner在U-MRG-14K上取得了最先进的性能，并展现出对未见过的临床查询的良好泛化能力，表明强化学习在可解释医学基础方面具有巨大潜力。

Abstract: Accurately grounding regions of interest (ROIs) is critical for diagnosis and
treatment planning in medical imaging. While multimodal large language models
(MLLMs) combine visual perception with natural language, current
medical-grounding pipelines still rely on supervised fine-tuning with explicit
spatial hints, making them ill-equipped to handle the implicit queries common
in clinical practice. This work makes three core contributions. We first define
Unified Medical Reasoning Grounding (UMRG), a novel vision-language task that
demands clinical reasoning and pixel-level grounding. Second, we release
U-MRG-14K, a dataset of 14K samples featuring pixel-level masks alongside
implicit clinical queries and reasoning traces, spanning 10 modalities, 15
super-categories, and 108 specific categories. Finally, we introduce
MedReasoner, a modular framework that distinctly separates reasoning from
segmentation: an MLLM reasoner is optimized with reinforcement learning, while
a frozen segmentation expert converts spatial prompts into masks, with
alignment achieved through format and accuracy rewards. MedReasoner achieves
state-of-the-art performance on U-MRG-14K and demonstrates strong
generalization to unseen clinical queries, underscoring the significant promise
of reinforcement learning for interpretable medical grounding.

</details>


### [208] [3D Human Mesh Estimation from Single View RGBD](https://arxiv.org/abs/2508.08178)
*Ozhan Suat,Bedirhan Uguz,Batuhan Karagoz,Muhammed Can Keles,Emre Akbas*

Main category: cs.CV

TL;DR: 本文提出了一种名为M$^3$（Masked Mesh Modeling）的方法，利用RGBD相机进行3D人体网格估计。通过使用掩码自编码器和运动捕捉数据来克服数据稀缺问题，M$^3$能够从单视角RGBD数据中恢复完整的3D人体网格，并在多个数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管在从RGB图像估计3D人体网格方面取得了显著进展，但RGBD相机提供的额外深度数据仍未被充分利用。本文旨在利用RGBD相机进行准确的3D人体网格估计，以满足现实世界应用的需求。然而，全监督方法需要成本高昂且难以收集的RGBD图像和3D网格标签对数据集。为了解决数据稀疏性问题，本研究利用现有的运动捕捉（MoCap）数据集。

Method: M$^3$（Masked Mesh Modeling）首先从运动捕捉（MoCap）数据集中提取完整的3D网格，并通过投影到虚拟摄像机来创建部分、单视角版本，模拟RGBD相机的深度数据。然后，训练一个掩码自编码器来补全这些部分网格。在推理时，该方法将传感器提供的深度值与模板人体网格的顶点进行匹配，创建部分网格，并恢复不可见部分，从而生成完整的身体网格。

Result: M$^3$在SURREAL和CAPE数据集上分别实现了16.8毫米和22.0毫米的每顶点误差（PVE），优于现有方法。在BEHAVE数据集上，M$^3$获得了70.9毫米的PVE，优于最近发布的基于RGB的方法18.4毫米。

Conclusion: M$^3$在SURREAL和CAPE数据集上分别实现了16.8毫米和22.0毫米的每顶点误差（PVE），优于使用全身点云作为输入的现有方法。在BEHAVE数据集上，M$^3$获得了70.9毫米的PVE，优于最近发布的基于RGB的方法18.4毫米，证明了深度数据的有效性。

Abstract: Despite significant progress in 3D human mesh estimation from RGB images;
RGBD cameras, offering additional depth data, remain underutilized. In this
paper, we present a method for accurate 3D human mesh estimation from a single
RGBD view, leveraging the affordability and widespread adoption of RGBD cameras
for real-world applications. A fully supervised approach for this problem,
requires a dataset with RGBD image and 3D mesh label pairs. However, collecting
such a dataset is costly and challenging, hence, existing datasets are small,
and limited in pose and shape diversity. To overcome this data scarcity, we
leverage existing Motion Capture (MoCap) datasets. We first obtain complete 3D
meshes from the body models found in MoCap datasets, and create partial,
single-view versions of them by projection to a virtual camera. This simulates
the depth data provided by an RGBD camera from a single viewpoint. Then, we
train a masked autoencoder to complete the partial, single-view mesh. During
inference, our method, which we name as M$^3$ for ``Masked Mesh Modeling'',
matches the depth values coming from the sensor to vertices of a template human
mesh, which creates a partial, single-view mesh. We effectively recover parts
of the 3D human body mesh model that are not visible, resulting in a full body
mesh. M$^3$ achieves 16.8 mm and 22.0 mm per-vertex-error (PVE) on the SURREAL
and CAPE datasets, respectively; outperforming existing methods that use
full-body point clouds as input. We obtain a competitive 70.9 PVE on the BEHAVE
dataset, outperforming a recently published RGB based method by 18.4 mm,
highlighting the usefulness of depth data. Code will be released.

</details>


### [209] [PP-Motion: Physical-Perceptual Fidelity Evaluation for Human Motion Generation](https://arxiv.org/abs/2508.08179)
*Sihan Zhao,Zixuan Wang,Tianyu Luan,Jia Jia,Wentao Zhu,Jiebo Luo,Junsong Yuan,Nan Xi*

Main category: cs.CV

TL;DR: 本研究提出了一种新的动作保真度评估方法 PP-Motion，它结合了物理标注和数据驱动指标，能够同时考虑物理规律和人类感知，解决了现有方法的不足。


<details>
  <summary>Details</summary>
Motivation: 先前的人类动作生成评估方法在人类感知保真度和物理可行性之间存在差距，并且人类感知的标签具有主观性和粗糙性，阻碍了数据驱动指标的发展。

Method: 提出了一种物理标注方法，通过计算运动与物理定律对齐所需的最小修改来评估运动保真度。利用此方法生成的标注是细粒度的、连续的物理对齐注释，可作为客观依据。在此基础上，提出了一种名为 PP-Motion 的新颖的数据驱动指标，用于评估人类动作的物理和感知保真度。PP-Motion 在训练中采用了皮尔逊相关损失来捕捉潜在的物理先验，并通过引入基于人类感知的保真度损失来同时考虑人类感知和物理对齐。

Result: 实验结果表明，PP-Motion 算法不仅符合物理定律，而且比以往的工作更能与人类对动作保真度的感知相匹配。

Conclusion: PP-Motion 算法不仅符合物理定律，而且比以往的工作更能与人类对动作保真度的感知相匹配。

Abstract: Human motion generation has found widespread applications in AR/VR, film,
sports, and medical rehabilitation, offering a cost-effective alternative to
traditional motion capture systems. However, evaluating the fidelity of such
generated motions is a crucial, multifaceted task. Although previous approaches
have attempted at motion fidelity evaluation using human perception or physical
constraints, there remains an inherent gap between human-perceived fidelity and
physical feasibility. Moreover, the subjective and coarse binary labeling of
human perception further undermines the development of a robust data-driven
metric. We address these issues by introducing a physical labeling method. This
method evaluates motion fidelity by calculating the minimum modifications
needed for a motion to align with physical laws. With this approach, we are
able to produce fine-grained, continuous physical alignment annotations that
serve as objective ground truth. With these annotations, we propose PP-Motion,
a novel data-driven metric to evaluate both physical and perceptual fidelity of
human motion. To effectively capture underlying physical priors, we employ
Pearson's correlation loss for the training of our metric. Additionally, by
incorporating a human-based perceptual fidelity loss, our metric can capture
fidelity that simultaneously considers both human perception and physical
alignment. Experimental results demonstrate that our metric, PP-Motion, not
only aligns with physical laws but also aligns better with human perception of
motion fidelity than previous work.

</details>


### [210] [THAT: Token-wise High-frequency Augmentation Transformer for Hyperspectral Pansharpening](https://arxiv.org/abs/2508.08183)
*Hongkun Jin,Hongcheng Jiang,Zejun Zhang,Yuan Zhang,Jia Fu,Tingfeng Li,Kai Luo*

Main category: cs.CV

TL;DR: THAT框架通过PTSA选择性注意力和MVFN多级方差感知网络，解决了ViT在高光谱图像融合中存在的冗余token和高频细节建模不足的问题，达到了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: Transformer在高铁光谱图像融合中虽然能模拟长距离依赖，但存在冗余 token 表示和缺乏多尺度特征建模的问题。ViT在光谱-空间方面存在保留高频分量（如边缘和纹理）的不足，以及注意力分散于冗余 token 的问题。这些问题源于全局自注意力机制会稀释高频信号并忽略局部细节。

Method: 提出了一种名为THAT（Token-wise High-frequency Augmentation Transformer）的新型框架，该框架包含两个关键组件：1）枢轴 token 选择性注意力（PTSA），用于优先选择信息 token 并减少冗余；2）多级方差感知前馈网络（MVFN），用于增强高频细节的学习。

Result: THAT框架在标准数据集上进行了实验，并取得了最先进的性能，提高了重建质量和效率。

Conclusion: THAT框架通过优先考虑信息性 token 并抑制冗余（PTSA），以及增强高频细节学习（MVFN），在高光谱图像融合任务上取得了最先进的性能，提高了重建质量和效率。

Abstract: Transformer-based methods have demonstrated strong potential in hyperspectral
pansharpening by modeling long-range dependencies. However, their effectiveness
is often limited by redundant token representations and a lack of multi-scale
feature modeling. Hyperspectral images exhibit intrinsic spectral priors (e.g.,
abundance sparsity) and spatial priors (e.g., non-local similarity), which are
critical for accurate reconstruction. From a spectral-spatial perspective,
Vision Transformers (ViTs) face two major limitations: they struggle to
preserve high-frequency components--such as material edges and texture
transitions--and suffer from attention dispersion across redundant tokens.
These issues stem from the global self-attention mechanism, which tends to
dilute high-frequency signals and overlook localized details. To address these
challenges, we propose the Token-wise High-frequency Augmentation Transformer
(THAT), a novel framework designed to enhance hyperspectral pansharpening
through improved high-frequency feature representation and token selection.
Specifically, THAT introduces: (1) Pivotal Token Selective Attention (PTSA) to
prioritize informative tokens and suppress redundancy; (2) a Multi-level
Variance-aware Feed-forward Network (MVFN) to enhance high-frequency detail
learning. Experiments on standard benchmarks show that THAT achieves
state-of-the-art performance with improved reconstruction quality and
efficiency. The source code is available at https://github.com/kailuo93/THAT.

</details>


### [211] [KARMA: Efficient Structural Defect Segmentation via Kolmogorov-Arnold Representation Learning](https://arxiv.org/abs/2508.08186)
*Md Meftahul Ferdaus,Mahdi Abdelguerfi,Elias Ioup,Steven Sloan,Kendall N. Niles,Ken Pathak*

Main category: cs.CV

TL;DR: KARMA是一个高效的语义分割框架，通过使用一维函数和TiKAN模块，大大减少了参数量（97%），同时保持了高精度，并能在实时应用中运行，非常适合自动化基础设施检测。


<details>
  <summary>Details</summary>
Motivation:  सिविल बुनियादी ढांचे में संरचनात्मक दोषों के सिमेंटिक सेगमेंटेशन, जो कि दोषों की विविध दिखावट, कठोर इमेजिंग स्थितियां और महत्वपूर्ण वर्ग असंतुलन के कारण चुनौतीपूर्ण रहता है। वर्तमान गहन शिक्षण विधियों, उनकी प्रभावशीलता के बावजूद, आमतौर पर लाखों पैरामीटर की आवश्यकता होती है, जो उन्हें वास्तविक समय निरीक्षण प्रणालियों के लिए अव्यावहारिक बनाती है।

Method: KARMA（Kolmogorov-Arnold Representation Mapping Architecture）是一个高效的语义分割框架，它通过组合一维函数而非传统的卷积来模拟复杂的缺陷模式。KARMA包含三个技术创新：1）一个参数高效的Tiny Kolmogorov-Arnold Network (TiKAN) 模块，利用低秩分解进行基于KAN的特征转换；2）一个优化的特征金字塔结构，采用可分离卷积进行多尺度缺陷分析；3）一个静态-动态原型机制，增强了对不平衡类别的特征表示。

Result: KARMA使用0.959M参数，比传统方法（31.04M）减少97%，实现了每秒38帧的推理速度，同时保持了与最先进方法相当的mIoU性能，在某些情况下甚至更好，证明了其在实时基础设施检查方面的可行性。

Conclusion: KARMA在基础设施检测数据集上实现了具有竞争力的或优于最先进方法的平均交并比（mIoU）性能，同时参数量显著减少（0.959M vs 31.04M，减少了97%），并且运行速度（0.264 GFLOPS）适合实时部署，从而在不损害精度的前提下，实现了实用的自动化基础设施检测系统。

Abstract: Semantic segmentation of structural defects in civil infrastructure remains
challenging due to variable defect appearances, harsh imaging conditions, and
significant class imbalance. Current deep learning methods, despite their
effectiveness, typically require millions of parameters, rendering them
impractical for real-time inspection systems. We introduce KARMA
(Kolmogorov-Arnold Representation Mapping Architecture), a highly efficient
semantic segmentation framework that models complex defect patterns through
compositions of one-dimensional functions rather than conventional
convolutions. KARMA features three technical innovations: (1) a
parameter-efficient Tiny Kolmogorov-Arnold Network (TiKAN) module leveraging
low-rank factorization for KAN-based feature transformation; (2) an optimized
feature pyramid structure with separable convolutions for multi-scale defect
analysis; and (3) a static-dynamic prototype mechanism that enhances feature
representation for imbalanced classes. Extensive experiments on benchmark
infrastructure inspection datasets demonstrate that KARMA achieves competitive
or superior mean IoU performance compared to state-of-the-art approaches, while
using significantly fewer parameters (0.959M vs. 31.04M, a 97% reduction).
Operating at 0.264 GFLOPS, KARMA maintains inference speeds suitable for
real-time deployment, enabling practical automated infrastructure inspection
systems without compromising accuracy. The source code can be accessed at the
following URL: https://github.com/faeyelab/karma.

</details>


### [212] [Reinforcement Learning in Vision: A Survey](https://arxiv.org/abs/2508.08189)
*Weijia Wu,Chen Gao,Joya Chen,Kevin Qinghong Lin,Qingwei Meng,Yiming Zhang,Yuke Qiu,Hong Zhou,Mike Zheng Shou*

Main category: cs.CV

TL;DR: 本文对视觉强化学习（Visual RL）领域进行了全面的回顾和分析，梳理了该领域的演进、关键技术和未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 本文旨在批判性地、及时地综合视觉强化学习（Visual RL）领域的最新进展，该领域融合了强化学习（RL）和视觉智能。

Method: 本文首先形式化了视觉强化学习问题，并追溯了从RLHF到可验证奖励范式，以及从Proximal Policy Optimization到Group Relative Policy Optimization的策略优化策略的演变。然后，文章将200多项代表性工作组织成四个主题支柱：多模态大语言模型、视觉生成、统一模型框架和视觉-语言-动作模型。针对每个支柱，研究了算法设计、奖励工程、基准测试进展，并提炼了课程驱动训练、偏好对齐扩散和统一奖励建模等趋势。最后，回顾了跨越集合级保真度、样本级偏好和状态级稳定性的评估协议，并确定了包括样本效率、泛化和安全部署在内的开放性挑战。

Result: 本文全面概述了视觉强化学习领域的最新进展，涵盖了从策略优化到具体模型框架的各个方面，并对评估协议和未来挑战进行了讨论。

Conclusion: 本篇论文旨在为研究人员和实践者提供一幅关于视觉强化学习（Visual RL）快速扩展领域的连贯地图，并突出未来有希望的研究方向。

Abstract: Recent advances at the intersection of reinforcement learning (RL) and visual
intelligence have enabled agents that not only perceive complex visual scenes
but also reason, generate, and act within them. This survey offers a critical
and up-to-date synthesis of the field. We first formalize visual RL problems
and trace the evolution of policy-optimization strategies from RLHF to
verifiable reward paradigms, and from Proximal Policy Optimization to Group
Relative Policy Optimization. We then organize more than 200 representative
works into four thematic pillars: multi-modal large language models, visual
generation, unified model frameworks, and vision-language-action models. For
each pillar we examine algorithmic design, reward engineering, benchmark
progress, and we distill trends such as curriculum-driven training,
preference-aligned diffusion, and unified reward modeling. Finally, we review
evaluation protocols spanning set-level fidelity, sample-level preference, and
state-level stability, and we identify open challenges that include sample
efficiency, generalization, and safe deployment. Our goal is to provide
researchers and practitioners with a coherent map of the rapidly expanding
landscape of visual RL and to highlight promising directions for future
inquiry. Resources are available at:
https://github.com/weijiawu/Awesome-Visual-Reinforcement-Learning.

</details>


### [213] [Spatial-ORMLLM: Improve Spatial Relation Understanding in the Operating Room with Multimodal Large Language Model](https://arxiv.org/abs/2508.08199)
*Peiqi He,Zhenhao Zhang,Yixiang Zhang,Xiongjun Zhao,Shaoliang Peng*

Main category: cs.CV

TL;DR: Spatial-ORMLLM是第一个用于手术室3D空间推理的大型视觉语言模型，仅使用RGB模态即可推断体积和语义线索，从而为下游医疗任务提供详细和全面的空间背景。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖多模态3D数据进行潜在空间对齐，但忽略了MLLM的3D能力。然而，多模态3D数据的获取存在困难，并且仅在2D数据上训练无法捕捉复杂场景中的细节。为了解决这些问题，我们提出了Spatial-ORMLLM。

Method: Spatial-ORMLLM是一个利用RGB模态推断体积和语义线索的3D空间推理大型视觉语言模型。它包含一个空间增强特征融合块，将2D模态输入与从估计算法中提取的丰富3D空间知识相结合，然后将组合后的特征输入视觉塔。通过采用统一的端到端MLLM框架，它将强大的空间特征与文本特征相结合，无需任何额外的专家注释或传感器输入即可实现强大的3D场景推理。

Result: Spatial-ORMLLM实现了最先进的性能，并且能够鲁棒地泛化到以前未知的 surgical 场景和下游任务。

Conclusion: Spatial-ORMLLM在多个临床数据集上实现了最先进的性能，并能很好地泛化到以前未见过的手术场景和下游任务。

Abstract: Precise spatial modeling in the operating room (OR) is foundational to many
clinical tasks, supporting intraoperative awareness, hazard avoidance, and
surgical decision-making. While existing approaches leverage large-scale
multimodal datasets for latent-space alignment to implicitly learn spatial
relationships, they overlook the 3D capabilities of MLLMs. However, this
approach raises two issues: (1) Operating rooms typically lack multiple video
and audio sensors, making multimodal 3D data difficult to obtain; (2) Training
solely on readily available 2D data fails to capture fine-grained details in
complex scenes. To address this gap, we introduce Spatial-ORMLLM, the first
large vision-language model for 3D spatial reasoning in operating rooms using
only RGB modality to infer volumetric and semantic cues, enabling downstream
medical tasks with detailed and holistic spatial context. Spatial-ORMLLM
incorporates a Spatial-Enhanced Feature Fusion Block, which integrates 2D
modality inputs with rich 3D spatial knowledge extracted by the estimation
algorithm and then feeds the combined features into the visual tower. By
employing a unified end-to-end MLLM framework, it combines powerful spatial
features with textual features to deliver robust 3D scene reasoning without any
additional expert annotations or sensor inputs. Experiments on multiple
benchmark clinical datasets demonstrate that Spatial-ORMLLM achieves
state-of-the-art performance and generalizes robustly to previously unseen
surgical scenarios and downstream tasks.

</details>


### [214] [SAGOnline: Segment Any Gaussians Online](https://arxiv.org/abs/2508.08219)
*Wentao Sun,Quanyun Wu,Hanqing Xu,Kyle Gao,Zhengsen Xu,Yiping Chen,Dedong Zhang,Lingfei Ma,John S. Zelek,Jonathan Li*

Main category: cs.CV

TL;DR: SAGOnline是一个轻量级、零样本的框架，用于在3D高斯场景中进行实时分割和多目标跟踪，通过结合2D视频基础模型和GPU加速的3D掩模生成实现了最先进的性能和高推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有3D分段方法在计算成本、3D空间推理和多目标跟踪方面存在挑战，SAGOnline旨在解决这些限制，实现高效、一致的3D分段。

Method: SAGOnline框架通过解耦策略整合了视频基础模型（如SAM2）以实现跨视图的2D掩模传播，并利用GPU加速的3D掩模生成和高斯级别实例标记算法来为3D图元分配唯一标识符，从而实现了跨视图的无损多目标跟踪和分割。

Result: SAGOnline在NVOS和Spin-NeRF基准测试中取得了最先进的性能，mIoU分别为92.7%和95.2%，推理速度比Feature3Dgs、OmniSeg3D-gs和SA3D快15-1500倍（27毫秒/帧）。

Conclusion: SAGOnline框架能够对高斯场景进行实时3D分割，并实现了对多个物体的分割和跟踪，在NVOS和Spin-NeRF基准测试中取得了最先进的性能，并且推理速度比现有方法快15到1500倍。该框架还通过明确标记高斯图元有效地实现了2D视频基础模型向3D领域的适配，为AR/VR和机器人应用奠定了基础。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a powerful paradigm for explicit
3D scene representation, yet achieving efficient and consistent 3D segmentation
remains challenging. Current methods suffer from prohibitive computational
costs, limited 3D spatial reasoning, and an inability to track multiple objects
simultaneously. We present Segment Any Gaussians Online (SAGOnline), a
lightweight and zero-shot framework for real-time 3D segmentation in Gaussian
scenes that addresses these limitations through two key innovations: (1) a
decoupled strategy that integrates video foundation models (e.g., SAM2) for
view-consistent 2D mask propagation across synthesized views; and (2) a
GPU-accelerated 3D mask generation and Gaussian-level instance labeling
algorithm that assigns unique identifiers to 3D primitives, enabling lossless
multi-object tracking and segmentation across views. SAGOnline achieves
state-of-the-art performance on NVOS (92.7% mIoU) and Spin-NeRF (95.2% mIoU)
benchmarks, outperforming Feature3DGS, OmniSeg3D-gs, and SA3D by 15--1500 times
in inference speed (27 ms/frame). Qualitative results demonstrate robust
multi-object segmentation and tracking in complex scenes. Our contributions
include: (i) a lightweight and zero-shot framework for 3D segmentation in
Gaussian scenes, (ii) explicit labeling of Gaussian primitives enabling
simultaneous segmentation and tracking, and (iii) the effective adaptation of
2D video foundation models to the 3D domain. This work allows real-time
rendering and 3D scene understanding, paving the way for practical AR/VR and
robotic applications.

</details>


### [215] [Learning User Preferences for Image Generation Model](https://arxiv.org/abs/2508.08220)
*Wenyi Mo,Ying Ba,Tianyu Zhang,Yalong Bai,Biye Li*

Main category: cs.CV

TL;DR: 一个基于多模态大语言模型的新方法，通过对比偏好损失和偏好标记来学习个性化用户偏好，提高了偏好预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖于一般人类偏好或假设静态用户配置文件，忽略了个体差异和个人品味动态、多方面的性质。

Method: 提出一种基于多模态大语言模型的方​​法，引入对比偏好损失和偏好标记来学习个性化用户偏好。

Result: 实验证明该模型在偏好预测准确性方面优于其他方法。

Conclusion: 该模型在偏好预测准确性方面优于其他方法，能有效识别具有相似审美倾向的用户，并为生成符合个人口味的图像提供更精确的指导。

Abstract: User preference prediction requires a comprehensive and accurate
understanding of individual tastes. This includes both surface-level
attributes, such as color and style, and deeper content-related aspects, such
as themes and composition. However, existing methods typically rely on general
human preferences or assume static user profiles, often neglecting individual
variability and the dynamic, multifaceted nature of personal taste. To address
these limitations, we propose an approach built upon Multimodal Large Language
Models, introducing contrastive preference loss and preference tokens to learn
personalized user preferences from historical interactions. The contrastive
preference loss is designed to effectively distinguish between user ''likes''
and ''dislikes'', while the learnable preference tokens capture shared interest
representations among existing users, enabling the model to activate
group-specific preferences and enhance consistency across similar users.
Extensive experiments demonstrate our model outperforms other methods in
preference prediction accuracy, effectively identifying users with similar
aesthetic inclinations and providing more precise guidance for generating
images that align with individual tastes. The project page is
\texttt{https://learn-user-pref.github.io/}.

</details>


### [216] [OMGSR: You Only Need One Mid-timestep Guidance for Real-World Image Super-Resolution](https://arxiv.org/abs/2508.08227)
*Zhiqiang Wu,Zhaomang Sun,Tong Zhou,Bingtao Fu,Ji Cong,Yitong Dong,Huaqi Zhang,Xuan Tang,Mingsong Chen,Xian Wei*

Main category: cs.CV

TL;DR: OMGSR通过在中间时间步注入LQ图像潜在分布并优化潜在分布差异，改进了DDPM/FM在Real-ISR任务上的性能，OMGSR-F表现尤为突出。


<details>
  <summary>Details</summary>
Motivation: 现有的单步真实世界图像超分辨率（Real-ISR）模型通常在初始时间步注入低质量（LQ）图像潜在分布，但LQ图像潜在分布与高斯噪声潜在分布之间存在根本性差距，限制了生成先验的有效利用。研究者发现DDPM/FM中间时间步的噪声潜在分布与LQ图像潜在分布更接近，以此为出发点进行研究。

Method: 提出了一种名为OMGSR（One Mid-timestep Guidance Real-ISR）的通用框架，适用于DDPM/FM生成模型。该框架在预先计算的中间时间步注入低质量（LQ）图像潜在分布，并提出潜在分布细化损失来弥合潜在分布的差异。同时设计了重叠分块LPIPS/GAN损失来消除图像生成的棋盘格伪影。OMGSR-S（SD-Turbo）和OMGSR-F（FLUX.1-dev）是该框架的两个具体实现。

Result: OMGSR-S/F在512分辨率下实现了平衡/卓越的性能。OMGSR-F在所有参考指标上均取得了压倒性优势。1k分辨率的OMGSR-F在图像细节生成方面表现优异，并且能够通过两阶段Tiled VAE & Diffusion技术生成2k分辨率的图像。

Conclusion: OMGSR-S/F在512分辨率下实现了定量和定性指标的平衡/卓越性能，OMGSR-F在所有参考指标上均占绝对优势。1k分辨率的OMGSR-F在图像细节生成方面表现尤为出色，并能通过两阶段Tiled VAE & Diffusion生成2k分辨率图像。

Abstract: Denoising Diffusion Probabilistic Models (DDPM) and Flow Matching (FM)
generative models show promising potential for one-step Real-World Image
Super-Resolution (Real-ISR). Recent one-step Real-ISR models typically inject a
Low-Quality (LQ) image latent distribution at the initial timestep. However, a
fundamental gap exists between the LQ image latent distribution and the
Gaussian noisy latent distribution, limiting the effective utilization of
generative priors. We observe that the noisy latent distribution at DDPM/FM
mid-timesteps aligns more closely with the LQ image latent distribution. Based
on this insight, we present One Mid-timestep Guidance Real-ISR (OMGSR), a
universal framework applicable to DDPM/FM-based generative models. OMGSR
injects the LQ image latent distribution at a pre-computed mid-timestep,
incorporating the proposed Latent Distribution Refinement loss to alleviate the
latent distribution gap. We also design the Overlap-Chunked LPIPS/GAN loss to
eliminate checkerboard artifacts in image generation. Within this framework, we
instantiate OMGSR for DDPM/FM-based generative models with two variants:
OMGSR-S (SD-Turbo) and OMGSR-F (FLUX.1-dev). Experimental results demonstrate
that OMGSR-S/F achieves balanced/excellent performance across quantitative and
qualitative metrics at 512-resolution. Notably, OMGSR-F establishes
overwhelming dominance in all reference metrics. We further train a
1k-resolution OMGSR-F to match the default resolution of FLUX.1-dev, which
yields excellent results, especially in the details of the image generation. We
also generate 2k-resolution images by the 1k-resolution OMGSR-F using our
two-stage Tiled VAE & Diffusion.

</details>


### [217] [Cut2Next: Generating Next Shot via In-Context Tuning](https://arxiv.org/abs/2508.08244)
*Jingwen He,Hongbo Liu,Jiajun Li,Ziqi Huang,Yu Qiao,Wanli Ouyang,Ziwei Liu*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Effective multi-shot generation demands purposeful, film-like transitions and
strict cinematic continuity. Current methods, however, often prioritize basic
visual consistency, neglecting crucial editing patterns (e.g., shot/reverse
shot, cutaways) that drive narrative flow for compelling storytelling. This
yields outputs that may be visually coherent but lack narrative sophistication
and true cinematic integrity. To bridge this, we introduce Next Shot Generation
(NSG): synthesizing a subsequent, high-quality shot that critically conforms to
professional editing patterns while upholding rigorous cinematic continuity.
Our framework, Cut2Next, leverages a Diffusion Transformer (DiT). It employs
in-context tuning guided by a novel Hierarchical Multi-Prompting strategy. This
strategy uses Relational Prompts to define overall context and inter-shot
editing styles. Individual Prompts then specify per-shot content and
cinematographic attributes. Together, these guide Cut2Next to generate
cinematically appropriate next shots. Architectural innovations, Context-Aware
Condition Injection (CACI) and Hierarchical Attention Mask (HAM), further
integrate these diverse signals without introducing new parameters. We
construct RawCuts (large-scale) and CuratedCuts (refined) datasets, both with
hierarchical prompts, and introduce CutBench for evaluation. Experiments show
Cut2Next excels in visual consistency and text fidelity. Crucially, user
studies reveal a strong preference for Cut2Next, particularly for its adherence
to intended editing patterns and overall cinematic continuity, validating its
ability to generate high-quality, narratively expressive, and cinematically
coherent subsequent shots.

</details>


### [218] [StableAvatar: Infinite-Length Audio-Driven Avatar Video Generation](https://arxiv.org/abs/2508.08248)
*Shuyuan Tu,Yueming Pan,Yinming Huang,Xintong Han,Zhen Xing,Qi Dai,Chong Luo,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: StableAvatar通过创新的时间步感知音频适配器、音频原生指导机制和动态加权滑动窗口策略，解决了长视频同步和身份一致性问题，实现了高质量、无限长度的音频驱动化身视频生成。


<details>
  <summary>Details</summary>
Motivation: 当前音频驱动的化身视频生成模型在合成长视频时，面临自然音频同步和身份一致性方面的挑战。现有模型主要依赖第三方音频提取器，并将音频嵌入直接注入扩散模型，导致潜在分布误差累积和后续片段的潜在分布漂移。

Method: 本文提出了StableAvatar，一个端到端的视频扩散Transformer，无需后期处理即可生成无限长度的高质量视频。该模型整合了定制的训练和推理模块，通过时间步感知音频适配器来防止误差累积，利用音频原生指导机制增强音频同步性，并通过动态加权滑动窗口策略融合时域上的潜在表示，以提高无限长度视频的平滑度。

Result: 实验结果在定性和定量上均证明了StableAvatar的有效性，能够生成高质量、身份一致且与音频同步的无限长度视频。

Conclusion: StableAvatar通过其创新的时间步感知音频适配器、音频原生指导机制和动态加权滑动窗口策略，成功解决了现有音频驱动的化身视频生成模型在长视频合成中的同步性和身份一致性问题，实现了高质量、无限长度的视频生成。

Abstract: Current diffusion models for audio-driven avatar video generation struggle to
synthesize long videos with natural audio synchronization and identity
consistency. This paper presents StableAvatar, the first end-to-end video
diffusion transformer that synthesizes infinite-length high-quality videos
without post-processing. Conditioned on a reference image and audio,
StableAvatar integrates tailored training and inference modules to enable
infinite-length video generation. We observe that the main reason preventing
existing models from generating long videos lies in their audio modeling. They
typically rely on third-party off-the-shelf extractors to obtain audio
embeddings, which are then directly injected into the diffusion model via
cross-attention. Since current diffusion backbones lack any audio-related
priors, this approach causes severe latent distribution error accumulation
across video clips, leading the latent distribution of subsequent segments to
drift away from the optimal distribution gradually. To address this,
StableAvatar introduces a novel Time-step-aware Audio Adapter that prevents
error accumulation via time-step-aware modulation. During inference, we propose
a novel Audio Native Guidance Mechanism to further enhance the audio
synchronization by leveraging the diffusion's own evolving joint audio-latent
prediction as a dynamic guidance signal. To enhance the smoothness of the
infinite-length videos, we introduce a Dynamic Weighted Sliding-window Strategy
that fuses latent over time. Experiments on benchmarks show the effectiveness
of StableAvatar both qualitatively and quantitatively.

</details>


### [219] [ReferSplat: Referring Segmentation in 3D Gaussian Splatting](https://arxiv.org/abs/2508.08252)
*Shuting He,Guangquan Jie,Changshuo Wang,Yun Zhou,Shuming Hu,Guanbin Li,Henghui Ding*

Main category: cs.CV

TL;DR: 提出 R3DGS 任务和 Ref-LERF 数据集，以及 ReferSplat 框架，用于根据自然语言描述分割 3D 高斯场景中的目标对象，并取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 引入了 Referring 3D Gaussian Splatting Segmentation (R3DGS) 任务，旨在根据自然语言描述分割 3D 高斯场景中的目标对象，以推动具身 AI 的发展。

Method: 提出了一种名为 ReferSplat 的框架，该框架在空间感知范式中显式地用自然语言表达式来模拟 3D 高斯点。

Result: 所提出的 R3DGS 任务和 Ref-LERF 数据集，以及 ReferSplat 框架在 R3DGS 任务和 3D 开放词汇分割基准上取得了最先进的性能。

Conclusion: ReferSplat 框架在 R3DGS 任务和 3D 开放词汇分割基准上都取得了最先进的性能。

Abstract: We introduce Referring 3D Gaussian Splatting Segmentation (R3DGS), a new task
that aims to segment target objects in a 3D Gaussian scene based on natural
language descriptions, which often contain spatial relationships or object
attributes. This task requires the model to identify newly described objects
that may be occluded or not directly visible in a novel view, posing a
significant challenge for 3D multi-modal understanding. Developing this
capability is crucial for advancing embodied AI. To support research in this
area, we construct the first R3DGS dataset, Ref-LERF. Our analysis reveals that
3D multi-modal understanding and spatial relationship modeling are key
challenges for R3DGS. To address these challenges, we propose ReferSplat, a
framework that explicitly models 3D Gaussian points with natural language
expressions in a spatially aware paradigm. ReferSplat achieves state-of-the-art
performance on both the newly proposed R3DGS task and 3D open-vocabulary
segmentation benchmarks. Dataset and code are available at
https://github.com/heshuting555/ReferSplat.

</details>


### [220] [Learning an Implicit Physics Model for Image-based Fluid Simulation](https://arxiv.org/abs/2508.08254)
*Emily Yue-Ting Jia,Jiageng Mao,Zhiyuan Gao,Yajie Zhao,Yue Wang*

Main category: cs.CV

TL;DR: 一种新的神经网络方法，使用物理原理（如纳维-斯托克斯方程）从单张图像生成具有物理一致运动的4D流体场景，并使用3D高斯来捕捉外观。


<details>
  <summary>Details</summary>
Motivation: 旨在将神经网络从单张图像生成4D场景（包括运动和3D几何）的能力，特别是针对自然流体图像，并解决现有方法在运动预测中不符合物理原理的问题。

Method: 提出了一种新的方法，使用物理引导神经网络从输入的图像及其估计的深度中预测基于特征的3D高斯，并使用预测的运动进行动画处理，从任何期望的相机视角进行渲染。该方法使用纳维-斯托克斯方程等基本物理原理推导出的损失项来指导运动预测。

Result: 实验结果证明了该方法在生成物理上合理动画方面的有效性，与现有方法相比，性能有了显著提高。

Conclusion: 本文提出的物理引导神经网络方法能够从单张图像生成具有物理一致性动画的4D场景，显著优于现有方法。

Abstract: Humans possess an exceptional ability to imagine 4D scenes, encompassing both
motion and 3D geometry, from a single still image. This ability is rooted in
our accumulated observations of similar scenes and an intuitive understanding
of physics. In this paper, we aim to replicate this capacity in neural
networks, specifically focusing on natural fluid imagery. Existing methods for
this task typically employ simplistic 2D motion estimators to animate the
image, leading to motion predictions that often defy physical principles,
resulting in unrealistic animations. Our approach introduces a novel method for
generating 4D scenes with physics-consistent animation from a single image. We
propose the use of a physics-informed neural network that predicts motion for
each surface point, guided by a loss term derived from fundamental physical
principles, including the Navier-Stokes equations. To capture appearance, we
predict feature-based 3D Gaussians from the input image and its estimated
depth, which are then animated using the predicted motions and rendered from
any desired camera perspective. Experimental results highlight the
effectiveness of our method in producing physically plausible animations,
showcasing significant performance improvements over existing methods. Our
project page is https://physfluid.github.io/ .

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [221] [Semi-automated Fact-checking in Portuguese: Corpora Enrichment using Retrieval with Claim extraction](https://arxiv.org/abs/2508.06495)
*Juliana Resplande Sant'anna Gomes,Arlindo Rodrigues Galvão Filho*

Main category: cs.CL

TL;DR: 该论文通过整合外部证据，丰富了葡萄牙语新闻语料库，以支持半自动化事实核查（SAFC）系统，解决了葡萄牙语数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机在于，虚假信息的加速传播能力超过了人工事实核查的应对能力，因此迫切需要半自动化事实核查（SAFC）系统。特别是在葡萄牙语环境中，公开可用的整合了外部证据的数据集却很少，而外部证据是开发强大的 AFC 系统必不可少的组成部分。

Method: 该研究采用了一种模拟用户验证过程的方法，利用大型语言模型（LLMs，特别是 Gemini 1.5 Flash）提取文本中的主要论点，并使用搜索引擎 API（Google Search API、Google FactCheck Claims Search API）检索相关的外部证据文档。此外，还引入了一个数据验证和预处理框架，包括近重复检测，以提高基础语料库的质量。

Result: 该论文成功地开发并应用了一种方法，为葡萄牙语新闻语料库（Fake.Br、COVID19.BR、MuMiN-PT）增加了外部证据，填补了现有资源在整合外部证据方面的空白，为开发更强大的葡萄牙语 SAFC 系统奠定了基础。

Conclusion: 该论文开发了一种方法，通过整合外部证据来丰富葡萄牙语新闻语料库，以解决半自动化事实核查（SAFC）系统的数据集稀缺性问题。

Abstract: The accelerated dissemination of disinformation often outpaces the capacity
for manual fact-checking, highlighting the urgent need for Semi-Automated
Fact-Checking (SAFC) systems. Within the Portuguese language context, there is
a noted scarcity of publicly available datasets that integrate external
evidence, an essential component for developing robust AFC systems, as many
existing resources focus solely on classification based on intrinsic text
features. This dissertation addresses this gap by developing, applying, and
analyzing a methodology to enrich Portuguese news corpora (Fake.Br, COVID19.BR,
MuMiN-PT) with external evidence. The approach simulates a user's verification
process, employing Large Language Models (LLMs, specifically Gemini 1.5 Flash)
to extract the main claim from texts and search engine APIs (Google Search API,
Google FactCheck Claims Search API) to retrieve relevant external documents
(evidence). Additionally, a data validation and preprocessing framework,
including near-duplicate detection, is introduced to enhance the quality of the
base corpora.

</details>


### [222] [Retrieval augmented generation based dynamic prompting for few-shot biomedical named entity recognition using large language models](https://arxiv.org/abs/2508.06504)
*Yao Ge,Sudeshna Das,Yuting Guo,Abeed Sarker*

Main category: cs.CL

TL;DR: 通过动态提示和RAG技术，提升了LLMs在生物医学NER任务上的少样本学习能力。


<details>
  <summary>Details</summary>
Motivation: 旨在解决大型语言模型（LLMs）在少样本生物医学命名实体识别（NER）任务中存在的性能挑战，以期提升模型在有限训练数据下的表现。

Method: 本研究提出并评估了一种动态提示策略，通过检索与输入文本相似的样本来动态更新提示，并将其与静态提示策略进行了比较。研究者们实现了并优化了静态和动态提示工程技术，并在五个生物医学NER数据集上进行了评估。

Result: 与基础静态提示相比，结构化组件的静态提示将GPT-4的平均F1分数提高了12%，将GPT-3.5和LLaMA 3-70B的平均F1分数提高了11%。动态提示进一步提高了性能，其中TF-IDF和SBERT检索方法的表现最佳，在5-shot和10-shot设置下平均F1分数分别提高了7.3%和5.6%。

Conclusion: 动态提示策略，特别是结合检索增强生成（RAG）的方法，能够显著提升语言模型在少样本生物医学命名实体识别任务上的性能。

Abstract: Biomedical named entity recognition (NER) is a high-utility natural language
processing (NLP) task, and large language models (LLMs) show promise
particularly in few-shot settings (i.e., limited training data). In this
article, we address the performance challenges of LLMs for few-shot biomedical
NER by investigating a dynamic prompting strategy involving retrieval-augmented
generation (RAG). In our approach, the annotated in-context learning examples
are selected based on their similarities with the input texts, and the prompt
is dynamically updated for each instance during inference. We implemented and
optimized static and dynamic prompt engineering techniques and evaluated them
on five biomedical NER datasets. Static prompting with structured components
increased average F1-scores by 12% for GPT-4, and 11% for GPT-3.5 and LLaMA
3-70B, relative to basic static prompting. Dynamic prompting further improved
performance, with TF-IDF and SBERT retrieval methods yielding the best results,
improving average F1-scores by 7.3% and 5.6% in 5-shot and 10-shot settings,
respectively. These findings highlight the utility of contextually adaptive
prompts via RAG for biomedical NER.

</details>


### [223] [CarbonScaling: Extending Neural Scaling Laws for Carbon Footprint in Large Language Models](https://arxiv.org/abs/2508.06524)
*Lei Jiang,Fan Chen*

Main category: cs.CL

TL;DR: LLM训练的碳排放与模型规模、数据和计算量成指数增长，现有缩放定律忽略了这一点。本研究提出了CarbonScaling框架，将LLM的准确性与其碳足迹联系起来。研究发现，虽然准确性和碳排放之间存在幂律关系，但实际效率低下会显著增加缩放因子。硬件升级和训练优化可以帮助减少碳排放，但对于超大规模LLM，收益会递减。


<details>
  <summary>Details</summary>
Motivation: 现有神经缩放定律忽略了与LLM规模成指数增长的碳排放问题，因此需要一个考虑碳排放的分析框架。

Method: CarbonScaling框架通过整合神经缩放模型、GPU硬件演进、并行优化和碳排放估算，量化了模型准确性与碳足迹之间的联系。

Result: 结果表明，准确性和碳排放之间存在幂律关系，但实际效率低下会显著增加缩放因子。硬件技术扩展可以减少中小型模型的碳排放，但对于超大规模LLM，由于通信开销和GPU利用率不足，收益递减。训练优化（尤其是关键批量大小扩展）有助于缓解效率低下问题。

Conclusion: 该研究提出了CarbonScaling分析框架，将LLM的碳排放与模型准确性联系起来，为训练更可持续、碳效率更高的LLM提供了关键见解。

Abstract: Neural scaling laws have driven the development of increasingly large
language models (LLMs) by linking accuracy improvements to growth in parameter
count, dataset size, and compute. However, these laws overlook the carbon
emissions that scale exponentially with LLM size. This paper presents
\textit{CarbonScaling}, an analytical framework that extends neural scaling
laws to incorporate both operational and embodied carbon in LLM training. By
integrating models for neural scaling, GPU hardware evolution, parallelism
optimization, and carbon estimation, \textit{CarbonScaling} quantitatively
connects model accuracy to carbon footprint. Results show that while a
power-law relationship between accuracy and carbon holds, real-world
inefficiencies significantly increase the scaling factor. Hardware technology
scaling reduces carbon emissions for small to mid-sized models, but offers
diminishing returns for extremely large LLMs due to communication overhead and
underutilized GPUs. Training optimizations-especially aggressive critical batch
size scaling-help alleviate this inefficiency. \textit{CarbonScaling} offers
key insights for training more sustainable and carbon-efficient LLMs.

</details>


### [224] [The Art of Breaking Words: Rethinking Multilingual Tokenizer Design](https://arxiv.org/abs/2508.06533)
*Aamod Thakur,Ajay Nagpal,Atharva Savarkar,Kundeshwar Pundalik,Siddhesh Dosi,Piyush Sawarkar,Viraj Thakur,Rohit Saluja,Maunendra Sankar Desarkar,Ganesh Ramakrishnan*

Main category: cs.CL

TL;DR: 本研究旨在改进多语言大型语言模型（LLM）的分词技术，通过研究词汇量、预分词规则和训练数据组成对模型效率和质量的影响，特别是在具有挑战性的印度语言脚本上。提出了新的数据组成算法，显著降低了词元-单词比率，提高了模型性能和推理速度。


<details>
  <summary>Details</summary>
Motivation: 模型架构和训练目标是大型语言模型（LLM）开发中的重要研究方向，但分词技术，尤其是在多语言环境下，却相对被忽视。然而，分词技术直接影响着LLM的效率和性能。

Method: 现有分词器存在高词元-单词比率、上下文长度利用率低和推理速度慢等问题。本研究系统地研究词汇量大小、预分词规则和训练语料库组成对词元-单词效率和模型质量的影响。在印度语言脚本上进行了大量实验，并提出了一种新的数据组成算法来平衡分词器训练的多语言数据。

Result: 通过分析和提出的新数据组成算法，平均词元-单词比率降低了约6%，比最先进的多语言印度语言模型提高了40%以上。这带来了模型性能和推理速度上的可衡量收益。

Conclusion: 在模型架构和训练目标之外，重点关注包括多语言模型在内的的语言模型开发中的分词技术，特别是多语言模型。现有的分词器通常具有较高的词元与单词之比、上下文长度使用效率低下以及推理速度较慢的问题。因此，我们提出了一个系统性研究，将词汇量大小、预分词规则以及训练语料库组成与词元-单词效率和模型质量联系起来。为了在语言多样的环境中进行分析，我们在印度语言脚本上进行了大量实验，这些脚本因其高度的脚本多样性和复杂的拼写而带来独特的挑战。根据这些分析的见解，我们提出了一种新颖的数据组成算法，以平衡分词器训练的多语言数据。我们在预分词策略上的观察显著提高了模型性能，并且我们的数据组成算法相对于传统数据随机化方法，将平均词元-单词比率降低了约6%。我们的分词器在比最先进的多语言印度语言模型高出40%的平均词元-单词比率方面取得了更好的效果。这一改进在模型性能和推理速度上都带来了可衡量的收益。这突出了分词与架构和训练目标一起，成为构建高效、可扩展的多语言语言模型的重要杠杆。

Abstract: While model architecture and training objectives are well-studied,
tokenization, particularly in multilingual contexts, remains a relatively
neglected aspect of Large Language Model (LLM) development. Existing tokenizers
often exhibit high token-to-word ratios, inefficient use of context length, and
slower inference. We present a systematic study that links vocabulary size,
pre-tokenization rules, and training-corpus composition to both token-to-word
efficiency and model quality. To ground our analysis in a linguistically
diverse context, we conduct extensive experiments on Indic scripts, which
present unique challenges due to their high script diversity and orthographic
complexity. Drawing on the insights from these analyses, we propose a novel
algorithm for data composition that balances multilingual data for tokenizer
training. Our observations on pretokenization strategies significantly improve
model performance, and our data composition algorithm reduces the average
token-to-word ratio by approximately 6% with respect to the conventional data
randomization approach. Our tokenizer achieves more than 40% improvement on
average token-to-word ratio against stateof-the-art multilingual Indic models.
This improvement yields measurable gains in both model performance and
inference speed. This highlights tokenization alongside architecture and
training objectives as a critical lever for building efficient, scalable
multilingual LLMs

</details>


### [225] [Factor Augmented Supervised Learning with Text Embeddings](https://arxiv.org/abs/2508.06548)
*Zhanye Luo,Yuefeng Han,Xiufan Yu*

Main category: cs.CL

TL;DR: AEALT框架通过自动编码器将LLM文本嵌入降维，提高了效率和计算性能，在各种下游任务中优于传统方法。


<details>
  <summary>Details</summary>
Motivation: LLM生成的文本嵌入具有高维度，这会影响下游任务的效率和计算成本。本研究旨在解决这一问题。

Method: AEALT是一种监督的、因子增强的框架，将降维直接整合到预训练的LLM工作流程中。首先提取文本的嵌入，然后通过监督增强的自动编码器学习低维、与任务相关的潜在因子，从而模拟复杂嵌入的非线性结构。

Result: AEALT在多个真实世界的公共数据集上的分类、异常检测和预测任务中，相比于原始嵌入和几种标准的降维方法，都取得了显著的提升。

Conclusion: AEALT在分类、异常检测和预测任务上表现优于原始嵌入和几种标准的降维方法，具有广泛的适用性。

Abstract: Large language models (LLMs) generate text embeddings from text data,
producing vector representations that capture the semantic meaning and
contextual relationships of words. However, the high dimensionality of these
embeddings often impedes efficiency and drives up computational cost in
downstream tasks. To address this, we propose AutoEncoder-Augmented Learning
with Text (AEALT), a supervised, factor-augmented framework that incorporates
dimension reduction directly into pre-trained LLM workflows. First, we extract
embeddings from text documents; next, we pass them through a supervised
augmented autoencoder to learn low-dimensional, task-relevant latent factors.
By modeling the nonlinear structure of complex embeddings, AEALT outperforms
conventional deep-learning approaches that rely on raw embeddings. We validate
its broad applicability with extensive experiments on classification, anomaly
detection, and prediction tasks using multiple real-world public datasets.
Numerical results demonstrate that AEALT yields substantial gains over both
vanilla embeddings and several standard dimension reduction methods.

</details>


### [226] [Discerning minds or generic tutors? Evaluating instructional guidance capabilities in Socratic LLMs](https://arxiv.org/abs/2508.06583)
*Ying Liu,Can Li,Ting Zhang,Mei Wang,Qiannan Zhu,Jian Li,Hua Huang*

Main category: cs.CL

TL;DR: 本研究评估了大型语言模型在教育辅导中的适应性指导能力，发现现有模型表现不佳，但通过新的微调方法可大幅改进。


<details>
  <summary>Details</summary>
Motivation: 为了评估大型语言模型（LLMs）在作为教育辅导工具时的潜力，特别是它们根据学习者认知状态自适应调整教学策略的能力，弥补了以往研究主要关注苏格拉底式提问而忽略适应性指导的不足。

Method: 提出了一种名为GuideEval的基准，包含感知、组织和启发三个阶段，用于评估大型语言模型在教育辅导中的适应性指导能力。同时，引入了一种行为引导的微调策略，利用行为提示的教学对话来提升模型性能。

Result: 研究发现，现有的大型语言模型在学习者表现出困惑或需要重定向时，往往无法提供有效的适应性支架。通过行为引导的微调策略，模型的指导性能得到了显著提升。

Conclusion: 该研究提出了一种名为GuideEval的基准，用于评估大型语言模型在教育辅导中的适应性指导能力，并引入了一种行为引导的微调策略来提升模型性能。研究结果表明，现有的大型语言模型在根据学习者状态调整教学策略方面存在不足，但通过所提出的微调方法可以显著改善其表现。

Abstract: The conversational capabilities of large language models hold significant
promise for enabling scalable and interactive tutoring. While prior research
has primarily examined their capacity for Socratic questioning, it often
overlooks a critical dimension: adaptively guiding learners based on their
cognitive states. This study shifts focus from mere question generation to the
broader instructional guidance capability. We ask: Can LLMs emulate expert
tutors who dynamically adjust strategies in response to learners'
understanding? To investigate this, we propose GuideEval, a benchmark grounded
in authentic educational dialogues that evaluates pedagogical guidance through
a three-phase behavioral framework: (1) Perception, inferring learner states;
(2) Orchestration, adapting instructional strategies; and (3) Elicitation,
stimulating proper reflections. Empirical findings reveal that existing LLMs
frequently fail to provide effective adaptive scaffolding when learners exhibit
confusion or require redirection. Furthermore, we introduce a behavior-guided
finetuning strategy that leverages behavior-prompted instructional dialogues,
significantly enhancing guidance performance. By shifting the focus from
isolated content evaluation to learner-centered interaction, our work advocates
a more dialogic paradigm for evaluating Socratic LLMs.

</details>


### [227] [LLM Unlearning Without an Expert Curated Dataset](https://arxiv.org/abs/2508.06595)
*Xiaoyuan Zhu,Muru Zhang,Ollie Liu,Robin Jia,Willie Neiswanger*

Main category: cs.CL

TL;DR: 本研究提出了一种利用语言模型自动生成用于模型遗忘的数据集的方法，该方法通过结构化提示生成类似教科书的数据，实验证明其效果优于现有方法，且易于扩展到新领域。


<details>
  <summary>Details</summary>
Motivation: 现代大型语言模型经常编码敏感、有害或受版权保护的知识，这使得在不完全重新训练的情况下，移除模型中特定领域知识的“遗忘”能力变得必要。而构建有效的遗忘集是当前遗忘流程的主要瓶颈。

Method: 本研究介绍了一种利用语言模型本身来生成高质量遗忘集的，可扩展的、自动化的方法，该方法通过结构化提示管道合成类似教科书的数据，仅需领域名称作为输入。

Result: 通过在生物安全、网络安全和哈利波特小说遗忘实验中，我们证明了本研究合成的数据集持续优于基线合成替代品，并且与专家策划的数据集相当。此外，省略实验表明，多步骤生成管道显著提高了数据多样性，进而提高了遗忘效用。

Conclusion: 本研究表明，合成数据集为在无人为干预的情况下，对各种新兴领域进行实用、可扩展的遗忘提供了一条有前景的途径。

Abstract: Modern large language models often encode sensitive, harmful, or copyrighted
knowledge, raising the need for post-hoc unlearning-the ability to remove
specific domains of knowledge from a model without full retraining. A major
bottleneck in current unlearning pipelines is constructing effective forget
sets-datasets that approximate the target domain and guide the model to forget
it. In this work, we introduce a scalable, automated approach to generate
high-quality forget sets using language models themselves. Our method
synthesizes textbook-style data through a structured prompting pipeline,
requiring only a domain name as input. Through experiments on unlearning
biosecurity, cybersecurity, and Harry Potter novels, we show that our synthetic
datasets consistently outperform the baseline synthetic alternatives and are
comparable to the expert-curated ones. Additionally, ablation studies reveal
that the multi-step generation pipeline significantly boosts data diversity,
which in turn improves unlearning utility. Overall, our findings suggest that
synthetic datasets offer a promising path toward practical, scalable unlearning
for a wide range of emerging domains without the need for manual intervention.
We release our code and dataset at
https://github.com/xyzhu123/Synthetic_Textbook.

</details>


### [228] [BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent](https://arxiv.org/abs/2508.06600)
*Zijian Chen,Xueguang Ma,Shengyao Zhuang,Ping Nie,Kai Zou,Andrew Liu,Joshua Green,Kshama Patel,Ruoxi Meng,Mingyi Su,Sahel Sharifymoghaddam,Yanxi Li,Haoran Hong,Xinyu Shi,Xuye Liu,Nandan Thakur,Crystina Zhang,Luyu Gao,Wenhu Chen,Jimmy Lin*

Main category: cs.CL

TL;DR: 新的 BrowseComp-Plus 基准测试使用固定语料库解决了现有评估方法的公平性和透明度问题，实现了对深度研究代理的更好区分和分析。


<details>
  <summary>Details</summary>
Motivation: 当前的深度研究代理评估基准（如 BrowseComp）依赖于动态且不透明的实时网络搜索 API，这阻碍了公平的比较和可复现性，并且由于缺乏对文档语料库的控制，难以分离检索器的贡献。因此，评估可能无法提供对底层深度研究 LLM 能力的深入见解。

Method: 提出 BrowseComp-Plus 基准测试，该基准测试源自 BrowseComp，但使用固定的、精心策划的语料库，其中每个查询都包含人类验证的支持文档和挖掘出的具有挑战性的负例。

Result: BrowseComp-Plus 基准测试能够有效地区分深度研究系统的性能。例如，开源模型 Search-R1 与 BM25 检索器配对时，准确率为 3.86%；而 GPT-5 的准确率为 55.9%。将 GPT-5 与 Qwen3-Embedding-8B 检索器集成，在调用更少的情况下，准确率进一步提高到 70.1%。该基准测试支持对深度研究代理和检索方法的全面评估和解耦分析。

Conclusion: BrowseComp-Plus 基准测试通过提供一个固定的、精心策划的语料库，并包含经过人类验证的支持文档和挖掘出的具有挑战性的负例，解决了现有基准测试（如 BrowseComp）在公平性和透明度方面的局限性。这使得能够对深度研究系统进行可控的实验和深入分析。

Abstract: Deep-Research agents, which integrate large language models (LLMs) with
search tools, have shown success in improving the effectiveness of handling
complex queries that require iterative search planning and reasoning over
search results. Evaluations on current benchmarks like BrowseComp relies on
black-box live web search APIs, have notable limitations in (1) fairness:
dynamic and opaque web APIs hinder fair comparisons and reproducibility of deep
research methods; (2) transparency: lack of control over the document corpus
makes it difficult to isolate retriever contributions. In other words, the
current evaluations may compare a complete deep research system at a given
time, but they do not foster well-controlled experiments to provide insights
into the capability of underlying deep research LLMs. To address these
challenges, we introduce BrowseComp-Plus, a benchmark derived from BrowseComp,
employing a fixed, carefully curated corpus. Each query in BrowseComp-Plus
includes human-verified supporting documents and mined challenging negatives,
enabling controlled experimentation. The benchmark is shown to be effective in
distinguishing the performance of deep research systems. For instance, the
open-source model Search-R1, when paired with the BM25 retriever, achieves
3.86% accuracy, whereas the GPT-5 achieves 55.9%. Integrating the GPT-5 with
the Qwen3-Embedding-8B retriever further enhances its accuracy to 70.1% with
fewer search calls. This benchmark allows comprehensive evaluation and
disentangled analysis of deep research agents and retrieval methods, fostering
insights into retrieval effectiveness, citation accuracy, and context
engineering in Deep-Research system.

</details>


### [229] [Train It and Forget It: Merge Lists are Unnecessary for BPE Inference in Language Models](https://arxiv.org/abs/2508.06621)
*Tomohiro Sawada,Kartik Goyal*

Main category: cs.CL

TL;DR: BPE推理算法在不依赖合并列表的情况下，对下游任务影响甚微，为更简单的、注重隐私的文本标记方法提供了可能。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索不依赖合并列表的BPE推理算法对下游任务的影响，以评估其对语言模型训练数据泄露的可能性。

Method: 本研究的实验评估了两种BPE推理算法：a) 针对性地偏离合并列表，包括随机合并顺序、删除/截断合并列表的各种损坏；b) 非针对性地不依赖合并列表，而是贪婪地或精确地压缩文本的BPE推理算法。

Result: 实验结果表明，针对性地偏离合并列表会导致语言模型性能显著下降；而非针对性地、不依赖合并列表的推理算法对下游任务的影响很小，通常远小于预期。

Conclusion: BPE推理算法与BPE训练中的应用方式不同，可以实现更简单的、潜在的隐私保护的文本标记方法，且对模型性能的影响非常小。

Abstract: Standard Byte-Pair Encoding (BPE) tokenization compresses text by pairing a
learned token vocabulary with a detailed merge list. Recent work has shown that
this merge list exposes a potential attack surface for extracting information
about language model's training data. In this paper, we explore the downstream
impact of BPE inference algorithms that do not rely on this merge list at all,
and hence differ from the encoding process during BPE training. To address this
question, we investigate two broad classes of BPE inference schemes that differ
from BPE application during training: a) targeted deviation from merge-lists
including random merge orders, and various corruptions of merge list involving
deletion/truncation, and b) non-targeted BPE inference algorithms that do not
depend on the merge list but focus on compressing the text either greedily or
exactly. Extensive experiments across diverse language modeling tasks like
accuracy-based QA benchmarks, machine translation, and open-ended generation
reveal that while targeted deviation from the merge lists exhibits significant
degradation in language model performance, the non-targeted merge-list-free
inference algorithms result in minimal impact on downstream performance that is
often much smaller than expected. These findings pave way for simpler and
potentially more privacy-preserving tokenization schemes that do not
catastrophically compromise model performance.

</details>


### [230] [SEVADE: Self-Evolving Multi-Agent Analysis with Decoupled Evaluation for Hallucination-Resistant Irony Detection](https://arxiv.org/abs/2508.06803)
*Ziqi Liu,Yangbin Chen,Ziyang Zhou,Yilin Li,Mingxuan Hu,Yushan Pan,Zhijie Xu*

Main category: cs.CL

TL;DR: SEVADE是一个创新的自演化多智能体框架，通过DARE和RA来解决LLM在讽刺检测中的幻觉和准确性问题，并在实验中取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM方法在处理复杂的讽刺修辞时，常常受到单一视角分析、静态推理路径和易产生幻觉的限制，这影响了它们的准确性和可靠性。

Method: 提出了一种新颖的、用于抗幻觉讽刺检测的自演化多智能体分析框架（SEVADE），其中央是一个动态智能体推理引擎（DARE）。DARE利用基于语言理论的专业智能体团队来解构文本并生成结构化推理链。一个单独的轻量级推理仲裁器（RA）仅基于此推理链进行最终分类。这种分离式架构旨在通过将复杂推理与最终判断分离开来，来减轻幻觉的风险。

Result: SEVADE框架在四个基准数据集上实现了最先进的性能，平均准确率提高了6.75%，宏F1分数提高了6.29%。

Conclusion: SEVADE框架在四个基准数据集上实现了最先进的性能，平均准确率提高了6.75%，宏F1分数提高了6.29%。

Abstract: Sarcasm detection is a crucial yet challenging Natural Language Processing
task. Existing Large Language Model methods are often limited by
single-perspective analysis, static reasoning pathways, and a susceptibility to
hallucination when processing complex ironic rhetoric, which impacts their
accuracy and reliability. To address these challenges, we propose **SEVADE**, a
novel **S**elf-**Ev**olving multi-agent **A**nalysis framework with
**D**ecoupled **E**valuation for hallucination-resistant sarcasm detection. The
core of our framework is a Dynamic Agentive Reasoning Engine (DARE), which
utilizes a team of specialized agents grounded in linguistic theory to perform
a multifaceted deconstruction of the text and generate a structured reasoning
chain. Subsequently, a separate lightweight rationale adjudicator (RA) performs
the final classification based solely on this reasoning chain. This decoupled
architecture is designed to mitigate the risk of hallucination by separating
complex reasoning from the final judgment. Extensive experiments on four
benchmark datasets demonstrate that our framework achieves state-of-the-art
performance, with average improvements of **6.75%** in Accuracy and **6.29%**
in Macro-F1 score.

</details>


### [231] [Measuring Stereotype and Deviation Biases in Large Language Models](https://arxiv.org/abs/2508.06649)
*Daniel Wang,Eli Brignac,Minjia Mao,Xiao Fang*

Main category: cs.CL

TL;DR: 本研究评估了四个大型语言模型在生成个人资料时是否存在刻板印象偏见和偏差偏见，结果显示所有模型均存在这两种偏见。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）已广泛应用于各个领域，但其局限性和潜在风险引起了人们的担忧。本研究旨在调查LLMs可能显示的两种偏见：刻板印象偏见和偏差偏见。

Method: 通过要求四个先进的大型语言模型（LLMs）生成个人资料，研究了每个群体与政治倾向、宗教和性取向等属性之间的关联。

Result: 实验结果表明，所有被检查的LLMs在多个群体中均表现出显著的刻板印象偏见和偏差偏见。

Conclusion: 研究发现，所有被检查的语言模型都表现出显著的刻板印象偏见和偏差偏见，尤其是在多个群体中。这些发现揭示了语言模型在推断用户属性时出现的偏见，并指出了语言模型生成内容可能带来的潜在危害。

Abstract: Large language models (LLMs) are widely applied across diverse domains,
raising concerns about their limitations and potential risks. In this study, we
investigate two types of bias that LLMs may display: stereotype bias and
deviation bias. Stereotype bias refers to when LLMs consistently associate
specific traits with a particular demographic group. Deviation bias reflects
the disparity between the demographic distributions extracted from
LLM-generated content and real-world demographic distributions. By asking four
advanced LLMs to generate profiles of individuals, we examine the associations
between each demographic group and attributes such as political affiliation,
religion, and sexual orientation. Our experimental results show that all
examined LLMs exhibit both significant stereotype bias and deviation bias
towards multiple groups. Our findings uncover the biases that occur when LLMs
infer user attributes and shed light on the potential harms of LLM-generated
outputs.

</details>


### [232] [Enhancing Rumor Detection Methods with Propagation Structure Infused Language Model](https://arxiv.org/abs/2508.07209)
*Chaoqun Cui,Siyuan Li,Kunkun Ma,Caiyan Jia*

Main category: cs.CL

TL;DR: 通过Post Engagement Prediction (PEP)继续预训练策略和SoLM模型，提升了预训练语言模型在社交媒体谣言检测任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练语言模型在社交媒体应用（如谣言检测）任务上表现不佳，原因在于预训练语料与社交文本存在不匹配，模型未能充分处理独特的社交符号，以及预训练任务不适合模拟用户参与度传播结构。

Method: 提出了一种名为Post Engagement Prediction (PEP)的继续预训练策略，通过预测帖子之间的根、分支和父子关系来捕捉用户参与度信息，并构建了一个名为SoLM的针对Twitter语料库的预训练模型。

Result: PEP策略显著提高了通用和社交媒体预训练语言模型在谣言检测任务上的性能，在基准数据集上提升了1.0-3.7%的准确率。单独的SoLM模型也取得了有竞争力的结果，证明了该策略在学习区分性帖子交互特征方面的有效性。

Conclusion: 所提出的Post Engagement Prediction (PEP)策略能够有效提升预训练语言模型在社交媒体文本上的表现，尤其是在谣言检测任务上，即使在少样本场景下也能取得显著的性能提升，并且优于现有的一些最先进方法。

Abstract: Pretrained Language Models (PLMs) have excelled in various Natural Language
Processing tasks, benefiting from large-scale pretraining and self-attention
mechanism's ability to capture long-range dependencies. However, their
performance on social media application tasks like rumor detection remains
suboptimal. We attribute this to mismatches between pretraining corpora and
social texts, inadequate handling of unique social symbols, and pretraining
tasks ill-suited for modeling user engagements implicit in propagation
structures. To address these issues, we propose a continue pretraining strategy
called Post Engagement Prediction (PEP) to infuse information from propagation
structures into PLMs. PEP makes models to predict root, branch, and parent
relations between posts, capturing interactions of stance and sentiment crucial
for rumor detection. We also curate and release large-scale Twitter corpus:
TwitterCorpus (269GB text), and two unlabeled claim conversation datasets with
propagation structures (UTwitter and UWeibo). Utilizing these resources and PEP
strategy, we train a Twitter-tailored PLM called SoLM. Extensive experiments
demonstrate PEP significantly boosts rumor detection performance across
universal and social media PLMs, even in few-shot scenarios. On benchmark
datasets, PEP enhances baseline models by 1.0-3.7\% accuracy, even enabling it
to outperform current state-of-the-art methods on multiple datasets. SoLM
alone, without high-level modules, also achieves competitive results,
highlighting the strategy's effectiveness in learning discriminative post
interaction features.

</details>


### [233] [Testing the Limits of Machine Translation from One Book](https://arxiv.org/abs/2508.06665)
*Jonathan Shaw,Dillon Mee,Timothy Khouw,Zackary Leech,Daniel Wilson*

Main category: cs.CL

TL;DR: 本研究旨在评估大型语言模型（LLM）在卡努里语（一种数字资源匮乏的语言）上的翻译能力。通过构建包含健康、人道主义和通用术语的数据集，并结合语法、词典和并行句子等语言资源进行评估。结果表明，并行句子是提高翻译质量的最有效数据源，而单独的语法信息不足以支撑有效的翻译。研究还发现，LLM 在传达意义方面优于语法流畅性，并强调了采用多维度评估方法的重要性。


<details>
  <summary>Details</summary>
Motivation: 专注于一种有大量使用者但数字资源极少的语言——卡努里语，并为其设计了两个用于评估的数据集：一个关注健康和人道主义术语，另一个包含通用术语，研究特定领域的任务如何影响 LLM 翻译质量。

Method: 通过提供不同组合的语言资源（语法、词典和并行句子）来衡量 LLM 翻译的有效性，并将结果与母语译者和人类语言学家的表现进行比较。使用自动指标和母语者对流畅性和准确性的评估进行评估。

Result: 并行句子是最有效的数据来源。加入语法可以改进零样本翻译，但不能作为有效的独立数据源。LLM 在实现准确性（意义）方面比实现流畅性（语法）更有效。

Conclusion: 并行句子仍然是最有效的数据源，在人类评估和自动指标方面均优于其他方法。虽然加入语法可以改进零样本翻译，但它不能作为有效的独立数据源。人类评估显示，LLM 在实现准确性（意义）方面比实现流畅性（语法）更有效。这些发现表明，LLM 翻译评估受益于超越简单准确性指标的多维度评估，并且仅凭语法而没有并行句子，无法为有效的特定领域翻译提供足够的上下文。

Abstract: Current state-of-the-art models demonstrate capacity to leverage in-context
learning to translate into previously unseen language contexts. Tanzer et al.
[2024] utilize language materials (e.g. a grammar) to improve translation
quality for Kalamang using large language models (LLMs). We focus on Kanuri, a
language that, despite having substantial speaker population, has minimal
digital resources. We design two datasets for evaluation: one focused on health
and humanitarian terms, and another containing generalized terminology,
investigating how domain-specific tasks impact LLM translation quality.
  By providing different combinations of language resources (grammar,
dictionary, and parallel sentences), we measure LLM translation effectiveness,
comparing results to native speaker translations and human linguist
performance. We evaluate using both automatic metrics and native speaker
assessments of fluency and accuracy.
  Results demonstrate that parallel sentences remain the most effective data
source, outperforming other methods in human evaluations and automatic metrics.
While incorporating grammar improves over zero-shot translation, it fails as an
effective standalone data source. Human evaluations reveal that LLMs achieve
accuracy (meaning) more effectively than fluency (grammaticality).
  These findings suggest LLM translation evaluation benefits from
multidimensional assessment beyond simple accuracy metrics, and that grammar
alone, without parallel sentences, does not provide sufficient context for
effective domain-specific translation.

</details>


### [234] [Do Biased Models Have Biased Thoughts?](https://arxiv.org/abs/2508.06671)
*Swati Rajwal,Shivank Garg,Reem Abdel-Salam,Abdelrahman Zayed*

Main category: cs.CL

TL;DR: 该研究发现，大语言模型在思考过程中的偏见与其最终输出的偏见并不总是一致，这与人类不同。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型中存在的性别、种族、社会经济地位、外貌和性取向等偏见，以及链式思考提示对公平性的影响。

Method: 研究了链式思考提示对公平性的影响，并对5种主流大语言模型进行了实验，使用公平性指标量化了模型思考和输出中的11种不同偏见。

Result: 偏见在思考步骤和输出之间的相关性不高（在大多数情况下相关性低于0.6，p值小于0.001）。

Conclusion: 与人类不同，所测试的模型即使在决策中有偏见，其思考过程也未必有偏见。

Abstract: The impressive performance of language models is undeniable. However, the
presence of biases based on gender, race, socio-economic status, physical
appearance, and sexual orientation makes the deployment of language models
challenging. This paper studies the effect of chain-of-thought prompting, a
recent approach that studies the steps followed by the model before it
responds, on fairness. More specifically, we ask the following question:
\textit{Do biased models have biased thoughts}? To answer our question, we
conduct experiments on $5$ popular large language models using fairness metrics
to quantify $11$ different biases in the model's thoughts and output. Our
results show that the bias in the thinking steps is not highly correlated with
the output bias (less than $0.6$ correlation with a $p$-value smaller than
$0.001$ in most cases). In other words, unlike human beings, the tested models
with biased decisions do not always possess biased thoughts.

</details>


### [235] [Play Favorites: A Statistical Method to Measure Self-Bias in LLM-as-a-Judge](https://arxiv.org/abs/2508.06709)
*Evangelia Spiliopoulou,Riccardo Fogliato,Hanna Burnsky,Tamer Soliman,Jie Ma,Graham Horwood,Miguel Ballesteros*

Main category: cs.CL

TL;DR: LLM裁判可能存在自偏差和家族偏差，需要新的统计方法来识别和量化这些偏差，以获得更准确的模型性能评估。


<details>
  <summary>Details</summary>
Motivation: 解决LLM作为裁判时可能存在的自偏差问题，这种偏差会扭曲对模型真实性能的评估。现有的研究常常混淆模型质量的真实差异与偏差，或错误地假设LLM和人类的评分分布相同。

Method: 提出了一种统计框架，该框架明确形式化了识别和估计自偏差的假设。该方法通过对LLM裁判给出的自身输出与其他模型输出的评分分布差异进行建模，并考虑了独立的第三方裁判（如人类）提供的输出的潜在质量，从而分离和量化自偏差。

Result: 研究发现，一些模型（如GPT-4o和Claude 3.5 Sonnet）存在自偏差和家族偏差（即系统性地给同家族模型的输出分配更高评分）。

Conclusion: 一些模型（如GPT-4o和Claude 3.5 Sonnet）会系统性地给自己的输自分配更高的分数，并且也会给同家族其他模型的输出分配更高的分数。这说明在使用LLM作为裁判时需要警惕潜在的偏见，并为解释自动化评估提供实用的缓解偏见的指导。

Abstract: Large language models (LLMs) can serve as judges that offer rapid and
reliable assessments of other LLM outputs. However, models may systematically
assign overly favorable ratings to their own outputs, a phenomenon known as
self-bias, which can distort evaluations of true model performance. Previous
studies often conflate genuine differences in model quality with bias or
incorrectly assume that evaluations from LLMs and humans follow the same rating
distributions. In this work, we present a statistical framework that explicitly
formalizes assumptions under which self-bias can be identified and estimated.
Our method models the difference in the scoring distribution that
LLM-as-a-judge assigns to its own completions compared to other models, while
accounting for the underlying quality of the completions provided by an
independent, third-party judge (e.g., humans). Our method reliably isolates and
quantifies self-bias, even when models vary in ability, ensuring that genuine
performance differences are not mistaken for self-bias. We conduct an empirical
analysis of self-bias on a large dataset (>5000 prompt-completion pairs)
consisting of expert human annotations and judgments from nine different LLM
judges. We find that some models, such as GPT-4o and Claude 3.5 Sonnet,
systematically assign higher scores to their own outputs. These models also
display family-bias; systematically assigning higher ratings to outputs
produced by other models of the same family. Our findings highlight potential
pitfalls of using LLM judges and offer practical guidance to mitigate biases
when interpreting automated evaluations.

</details>


### [236] [Large Language Models for Oral History Understanding with Text Classification and Sentiment Analysis](https://arxiv.org/abs/2508.06729)
*Komala Subramanyam Cherukuri,Pranav Abishai Moses,Aisa Sakata,Jiangping Chen,Haihua Chen*

Main category: cs.CL

TL;DR: 本研究利用LLMs技术，开发了一个自动化的框架，用于对日本裔美国人监禁口述历史进行语义和情感标注，提高了分析效率和规模，为数字人文和集体记忆保护提供了新的方法和实践指导。


<details>
  <summary>Details</summary>
Motivation: 为了促进对受系统性不公正和历史遗忘影响的社区的口述历史的获取和理解，需要对大规模口述历史档案进行有效且高效的分析。然而，由于其非结构化格式、情感复杂性和高昂的标注成本，这些档案的大规模分析仍然受到限制。

Method: 本研究提出了一个可扩展的框架，利用大型语言模型（LLMs）对日本裔美国人监禁口述历史进行自动语义和情感标注。研究人员构建了一个高质量的数据集，评估了多种模型，并在具有历史敏感性的背景下测试了提示工程策略。多阶段方法结合了专家标注、提示设计以及使用ChatGPT、Llama和Qwen等模型的LLM评估。对来自15位讲述者的558个句子进行了情感和语义分类标注，并评估了零样本、少样本和检索增强生成（RAG）策略。

Result: 研究人员对来自15位讲述者的558个句子进行了情感和语义分类标注，并评估了零样本、少样本和RAG策略。在语义分类方面，ChatGPT取得了最高的F1分数（88.71%），其次是Llama（84.99%）和Qwen（83.72%）。在情感分析方面，Llama略优于Qwen（82.66%）和ChatGPT（82.29%），所有模型的表现都相当。最终，将最佳提示配置应用于标注JAIOH收藏中的1002份访谈中的92,191个句子。

Conclusion: 该研究展示了大型语言模型（LLMs）可以通过精心设计的提示，有效地对大规模口腔历史文集进行语义和情感标注。该研究提供了一个可重用的标注流程和实践指导，将档案伦理与可扩展的自然语言处理技术相结合，为人工智能在数字人文和集体记忆保护中的负责任应用奠定了基础。

Abstract: Oral histories are vital records of lived experience, particularly within
communities affected by systemic injustice and historical erasure. Effective
and efficient analysis of their oral history archives can promote access and
understanding of the oral histories. However, Large-scale analysis of these
archives remains limited due to their unstructured format, emotional
complexity, and high annotation costs. This paper presents a scalable framework
to automate semantic and sentiment annotation for Japanese American
Incarceration Oral History. Using LLMs, we construct a high-quality dataset,
evaluate multiple models, and test prompt engineering strategies in
historically sensitive contexts. Our multiphase approach combines expert
annotation, prompt design, and LLM evaluation with ChatGPT, Llama, and Qwen. We
labeled 558 sentences from 15 narrators for sentiment and semantic
classification, then evaluated zero-shot, few-shot, and RAG strategies. For
semantic classification, ChatGPT achieved the highest F1 score (88.71%),
followed by Llama (84.99%) and Qwen (83.72%). For sentiment analysis, Llama
slightly outperformed Qwen (82.66%) and ChatGPT (82.29%), with all models
showing comparable results. The best prompt configurations were used to
annotate 92,191 sentences from 1,002 interviews in the JAIOH collection. Our
findings show that LLMs can effectively perform semantic and sentiment
annotation across large oral history collections when guided by well-designed
prompts. This study provides a reusable annotation pipeline and practical
guidance for applying LLMs in culturally sensitive archival analysis. By
bridging archival ethics with scalable NLP techniques, this work lays the
groundwork for responsible use of artificial intelligence in digital humanities
and preservation of collective memory. GitHub:
https://github.com/kc6699c/LLM4OralHistoryAnalysis.

</details>


### [237] [Many-Turn Jailbreaking](https://arxiv.org/abs/2508.06755)
*Xianjun Yang,Liqiang Xiao,Shiyang Li,Faisal Ladhak,Hyokun Yun,Linda Ruth Petzold,Yi Xu,William Yang Wang*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Current jailbreaking work on large language models (LLMs) aims to elicit
unsafe outputs from given prompts. However, it only focuses on single-turn
jailbreaking targeting one specific query. On the contrary, the advanced LLMs
are designed to handle extremely long contexts and can thus conduct multi-turn
conversations. So, we propose exploring multi-turn jailbreaking, in which the
jailbroken LLMs are continuously tested on more than the first-turn
conversation or a single target query. This is an even more serious threat
because 1) it is common for users to continue asking relevant follow-up
questions to clarify certain jailbroken details, and 2) it is also possible
that the initial round of jailbreaking causes the LLMs to respond to additional
irrelevant questions consistently. As the first step (First draft done at June
2024) in exploring multi-turn jailbreaking, we construct a Multi-Turn Jailbreak
Benchmark (MTJ-Bench) for benchmarking this setting on a series of open- and
closed-source models and provide novel insights into this new safety threat. By
revealing this new vulnerability, we aim to call for community efforts to build
safer LLMs and pave the way for a more in-depth understanding of jailbreaking
LLMs.

</details>


### [238] [Annotating Errors in English Learners' Written Language Production: Advancing Automated Written Feedback Systems](https://arxiv.org/abs/2508.06810)
*Steven Coyne,Diana Galvan-Sosa,Ryan Spring,Camélia Guerraoui,Michael Zock,Keisuke Sakaguchi,Kentaro Inui*

Main category: cs.CL

TL;DR: 现有的自动写作评估（AWE）系统在纠正语法错误方面做得很好，但对于语言学习来说不够理想，因为它们倾向于直接修改，而学习者可能从解释和提示中获益更多。本研究提出了一个包含错误类型和可推广性标注的框架，并收集了相关数据集，以评估使用大型语言模型（LLM）生成反馈的几种方法。


<details>
  <summary>Details</summary>
Motivation: 现有的AWE系统虽然能纠正语法错误，但并非最优化的语言学习工具，它们倾向于直接修改，忽视了学习者可能从间接提示和解释中获益。

Method: 提出一个包含错误类型和可推广性标注的标注框架，并收集标注的学生错误及对应的人工反馈的数据集。利用LLM评估了三种生成反馈的方法（keyword-guided, keyword-free, and template-guided）。

Result: LLM在AWE系统中生成反馈的有效性得到评估，并对不同生成方法的表现进行了比较。

Conclusion: LLM在AWE系统中的表现，以及数据集的开发和对所研究系统的比较。

Abstract: Recent advances in natural language processing (NLP) have contributed to the
development of automated writing evaluation (AWE) systems that can correct
grammatical errors. However, while these systems are effective at improving
text, they are not optimally designed for language learning. They favor direct
revisions, often with a click-to-fix functionality that can be applied without
considering the reason for the correction. Meanwhile, depending on the error
type, learners may benefit most from simple explanations and strategically
indirect hints, especially on generalizable grammatical rules. To support the
generation of such feedback, we introduce an annotation framework that models
each error's error type and generalizability. For error type classification, we
introduce a typology focused on inferring learners' knowledge gaps by
connecting their errors to specific grammatical patterns. Following this
framework, we collect a dataset of annotated learner errors and corresponding
human-written feedback comments, each labeled as a direct correction or hint.
With this data, we evaluate keyword-guided, keyword-free, and template-guided
methods of generating feedback using large language models (LLMs). Human
teachers examined each system's outputs, assessing them on grounds including
relevance, factuality, and comprehensibility. We report on the development of
the dataset and the comparative performance of the systems investigated.

</details>


### [239] [Text to Speech System for Meitei Mayek Script](https://arxiv.org/abs/2508.06870)
*Gangular Singh Irengbam,Nirvash Singh Wahengbam,Lanthoiba Meitei Khumanthem,Paikhomba Oinam*

Main category: cs.CL

TL;DR: “泰语”TTS系统：基于Tacotron 2和HiFi-GAN，使用“梅泰·玛耶克”文字，支持声调音系，资源匮乏，适用于单说话人，语音清晰自然。


<details>
  <summary>Details</summary>
Motivation: 开发一种支持声调音系和资源匮乏的语言环境的神经网络TTS架构，以支持“泰语”的语言保护和技术包容性。

Method: 利用Tacotron 2和HiFi-GAN，开发了一个支持声调音系和资源匮乏的语言环境的神经网络TTS架构，并开发了“梅泰·玛耶克”到ARPAbet的音素映射，同时整理了一个单说话人数据集。

Result: 开发了一个“泰语”TTS系统，并证明了其可理解性和自然性，该系统通过主客观指标进行了验证。

Conclusion: 该系统为开发面向“泰语”的文本到语音（TTS）系统奠定了基础，该系统使用“梅泰·玛耶克”文字，这有助于语言保护和技术包容性。

Abstract: This paper presents the development of a Text-to-Speech (TTS) system for the
Manipuri language using the Meitei Mayek script. Leveraging Tacotron 2 and
HiFi-GAN, we introduce a neural TTS architecture adapted to support tonal
phonology and under-resourced linguistic environments. We develop a phoneme
mapping for Meitei Mayek to ARPAbet, curate a single-speaker dataset, and
demonstrate intelligible and natural speech synthesis, validated through
subjective and objective metrics. This system lays the groundwork for
linguistic preservation and technological inclusion of Manipuri.

</details>


### [240] [ESNERA: Empirical and semantic named entity alignment for named entity dataset merging](https://arxiv.org/abs/2508.06877)
*Xiaobo Zhang,Congqing He,Ying He,Jian Peng,Dajie Fu,Tien-Ping Tan*

Main category: cs.CL

TL;DR: 提出一种基于标签相似性的自动标签对齐方法，以解决现有命名实体识别数据集合并方法的不足，并成功应用于金融领域，提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 由于深度学习在命名实体识别（NER）方面表现出色，但高度依赖大型高质量标注数据集，而构建这些数据集成本高昂且耗时，这阻碍了进一步的研究。现有数据集合并方法在可解释性和可扩展性方面存在不足。

Method: 本文提出了一种基于标签相似性的自动标签对齐方法，该方法结合了经验和语义相似性，并采用贪心成对合并策略来统一不同数据集的标签空间。

Result: 实验结果表明，我们的方法能够有效地合并数据集，并提升了在低资源金融领域命名实体识别的效果。

Conclusion: 我们的方法能够有效地合并数据集，并提升了在低资源金融领域命名实体识别的效果。本研究为整合多源命名实体识别语料库提供了一个高效、可解释且可扩展的解决方案。

Abstract: Named Entity Recognition (NER) is a fundamental task in natural language
processing. It remains a research hotspot due to its wide applicability across
domains. Although recent advances in deep learning have significantly improved
NER performance, they rely heavily on large, high-quality annotated datasets.
However, building these datasets is expensive and time-consuming, posing a
major bottleneck for further research. Current dataset merging approaches
mainly focus on strategies like manual label mapping or constructing label
graphs, which lack interpretability and scalability. To address this, we
propose an automatic label alignment method based on label similarity. The
method combines empirical and semantic similarities, using a greedy pairwise
merging strategy to unify label spaces across different datasets. Experiments
are conducted in two stages: first, merging three existing NER datasets into a
unified corpus with minimal impact on NER performance; second, integrating this
corpus with a small-scale, self-built dataset in the financial domain. The
results show that our method enables effective dataset merging and enhances NER
performance in the low-resource financial domain. This study presents an
efficient, interpretable, and scalable solution for integrating multi-source
NER corpora.

</details>


### [241] [The ReQAP System for Question Answering over Personal Information](https://arxiv.org/abs/2508.06880)
*Philipp Christmann,Gerhard Weikum*

Main category: cs.CL

TL;DR: ReQAP是一个新系统，可以回答涉及跨多种数据源的复杂问题。它通过递归分解问题并使用轻量级语言模型来构建和执行查询计划。该系统的一个关键特性是能够追溯答案的来源，增强用户对系统的信任和理解。


<details>
  <summary>Details</summary>
Motivation: 个人信息在用户的设备上非常丰富，从日历、购物记录或健身工具中的结构化数据，到邮件和社交媒体帖子中的非结构化内容。

Method: ReQAP系统递归地分解问题并逐步构建算子树进行执行。问题解释和单个算子都巧妙地利用了轻量级语言模型，并进行了明智的微调。

Result: 演示展示了针对高级用户问题的丰富功能，并详细跟踪了答案是如何通过执行树中的算子计算出来的。能够将答案追溯到底层源对于人类的可理解性和用户对系统的信任至关重要。

Conclusion: ReQAP系统支持用户对跨异构源的复杂问题（涉及筛选、联接和聚合）进行回答。ReQAP递归地分解问题并逐步构建算子树进行执行。问题解释和单个算子都巧妙地利用了轻量级语言模型，并进行了明智的微调。该演示展示了针对高级用户问题的丰富功能，并详细跟踪了答案是如何通过执行树中的算子计算出来的。能够将答案追溯到底层源对于人类的可理解性和用户对系统的信任至关重要。

Abstract: Personal information is abundant on users' devices, from structured data in
calendar, shopping records or fitness tools, to unstructured contents in mail
and social media posts. This works presents the ReQAP system that supports
users with answers for complex questions that involve filters, joins and
aggregation over heterogeneous sources. The unique trait of ReQAP is that it
recursively decomposes questions and incrementally builds an operator tree for
execution. Both the question interpretation and the individual operators make
smart use of light-weight language models, with judicious fine-tuning. The demo
showcases the rich functionality for advanced user questions, and also offers
detailed tracking of how the answers are computed by the operators in the
execution tree. Being able to trace answers back to the underlying sources is
vital for human comprehensibility and user trust in the system.

</details>


### [242] [Score Before You Speak: Improving Persona Consistency in Dialogue Generation using Response Quality Scores](https://arxiv.org/abs/2508.06886)
*Arpita Saggar,Jonathan C. Darling,Vania Dimitrova,Duygu Sarikaya,David C. Hogg*

Main category: cs.CL

TL;DR: SBS框架通过在训练时将回复与其质量评分关联，提升了大型语言模型在个性化对话生成中的人设保真度，并在基准数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在个性化对话生成方面仍面临挑战，主要是因为现有的对话数据多样性有限，难以有效保证人设保真度。

Method: SBS框架，将回复学习和相对质量学习统一在一个步骤中。具体做法是训练一个对话模型，使其能够将增强后的回复与质量分数相关联。回复增强通过基于名词的替换实现，而质量分数则使用基于语义相似度的评分作为代理。

Result: SBS框架在PERSONA-CHAT和ConvAI2数据集上进行了大量实验，证明了分数条件训练能够让现有模型更好地捕捉一系列符合人设的对话。此外，实验还表明，在训练时将分数纳入输入提示优于传统的训练设置。

Conclusion: 通过引入SBS框架，可以提升现有模型（包括百万和十亿参数模型）在个性化对话生成任务中的表现，尤其是在保证对话的人设保真度方面。该框架通过在训练阶段将回复与其质量评分相关联，并在推理阶段利用这些知识，实现了比以往方法更好的效果。

Abstract: Persona-based dialogue generation is an important milestone towards building
conversational artificial intelligence. Despite the ever-improving capabilities
of large language models (LLMs), effectively integrating persona fidelity in
conversations remains challenging due to the limited diversity in existing
dialogue data. We propose a novel framework SBS (Score-Before-Speaking), which
outperforms previous methods and yields improvements for both million and
billion-parameter models. Unlike previous methods, SBS unifies the learning of
responses and their relative quality into a single step. The key innovation is
to train a dialogue model to correlate augmented responses with a quality score
during training and then leverage this knowledge at inference. We use
noun-based substitution for augmentation and semantic similarity-based scores
as a proxy for response quality. Through extensive experiments with benchmark
datasets (PERSONA-CHAT and ConvAI2), we show that score-conditioned training
allows existing models to better capture a spectrum of persona-consistent
dialogues. Our ablation studies also demonstrate that including scores in the
input prompt during training is superior to conventional training setups. Code
and further details are available at
https://arpita2512.github.io/score_before_you_speak

</details>


### [243] [Model-Agnostic Sentiment Distribution Stability Analysis for Robust LLM-Generated Texts Detection](https://arxiv.org/abs/2508.06913)
*Siyuan Li,Xi Lin,Guangyan Li,Zehao Liu,Aodu Wulianghai,Li Ding,Jun Wu,Jianhua Li*

Main category: cs.CL

TL;DR: SentiDetect 是一种新的 LLM 检测框架，通过分析情感分布的稳定性来区分 AI 生成文本和人类文本，并在各种条件下均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 检测方法泛化能力有限，容易受到释义、对抗性扰动和跨领域变化的影响。因此，需要更鲁棒和通用的检测框架。

Method: 提出了一种名为 SentiDetect 的模型无关框架，通过分析情感分布稳定性差异来检测 LLM 生成的文本。该方法基于 LLM 输出倾向于表现出情感一致模式，而人类书写文本的情感变异性更大的观察结果。通过定义情感分布一致性和情感分布保持性两个互补指标来量化情感变化的稳定性和语义保持的稳定性。

Result: 在五个不同的数据集和一系列先进的 LLM（包括 Gemini-1.5-Pro、Claude-3、GPT-4-0613 和 LLaMa-3.3）上进行了评估。实验结果表明，SentiDetect 在 F1 分数上分别比 Gemini-1.5-Pro 和 GPT-4-0613 提高了 16% 和 11%，并且在应对释义、对抗性攻击和文本长度变化方面表现出更强的鲁棒性。

Conclusion: SentiDetect 通过分析情感分布稳定性差异，在区分 LLM 生成文本和人类书写文本方面表现出色，并且在各种挑战性场景下展现出更强的鲁棒性，优于现有检测方法。

Abstract: The rapid advancement of large language models (LLMs) has resulted in
increasingly sophisticated AI-generated content, posing significant challenges
in distinguishing LLM-generated text from human-written language. Existing
detection methods, primarily based on lexical heuristics or fine-tuned
classifiers, often suffer from limited generalizability and are vulnerable to
paraphrasing, adversarial perturbations, and cross-domain shifts. In this work,
we propose SentiDetect, a model-agnostic framework for detecting LLM-generated
text by analyzing the divergence in sentiment distribution stability. Our
method is motivated by the empirical observation that LLM outputs tend to
exhibit emotionally consistent patterns, whereas human-written texts display
greater emotional variability. To capture this phenomenon, we define two
complementary metrics: sentiment distribution consistency and sentiment
distribution preservation, which quantify stability under sentiment-altering
and semantic-preserving transformations. We evaluate SentiDetect on five
diverse datasets and a range of advanced LLMs,including Gemini-1.5-Pro,
Claude-3, GPT-4-0613, and LLaMa-3.3. Experimental results demonstrate its
superiority over state-of-the-art baselines, with over 16% and 11% F1 score
improvements on Gemini-1.5-Pro and GPT-4-0613, respectively. Moreover,
SentiDetect also shows greater robustness to paraphrasing, adversarial attacks,
and text length variations, outperforming existing detectors in challenging
scenarios.

</details>


### [244] [Two-Stage Quranic QA via Ensemble Retrieval and Instruction-Tuned Answer Extraction](https://arxiv.org/abs/2508.06971)
*Mohamed Basem,Islam Oshallah,Ali Hamdi,Khaled Shaban,Hozaifa Kassab*

Main category: cs.CL

TL;DR: 本研究提出了一种新颖的两阶段框架，通过集成 Arabic language models 和使用 instruction-tuned LLM 进行 few-shot prompting，在古兰经问答任务上取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 解决古典阿拉伯语的复杂性和宗教文本的语义丰富性带来的古兰经问答的独特挑战。

Method: 提出了一种新颖的两阶段框架，包括用于 passage retrieval 的 Arabic language models 集成，以及用于 answer extraction 的 instruction-tuned LLM 和 few-shot prompting。

Result: 在 Quran QA 2023 Shared Task 上取得了最先进的成果，在检索方面 MAP@10 为 0.3128，MRR@10 为 0.5763；在抽取方面 pAP@10 为 0.669，显著优于以往方法。

Conclusion: 结合模型集成和指令调优的大型语言模型可以有效解决专业领域低资源问答的挑战。

Abstract: Quranic Question Answering presents unique challenges due to the linguistic
complexity of Classical Arabic and the semantic richness of religious texts. In
this paper, we propose a novel two-stage framework that addresses both passage
retrieval and answer extraction. For passage retrieval, we ensemble fine-tuned
Arabic language models to achieve superior ranking performance. For answer
extraction, we employ instruction-tuned large language models with few-shot
prompting to overcome the limitations of fine-tuning on small datasets. Our
approach achieves state-of-the-art results on the Quran QA 2023 Shared Task,
with a MAP@10 of 0.3128 and MRR@10 of 0.5763 for retrieval, and a pAP@10 of
0.669 for extraction, substantially outperforming previous methods. These
results demonstrate that combining model ensembling and instruction-tuned
language models effectively addresses the challenges of low-resource question
answering in specialized domains.

</details>


### [245] [Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models](https://arxiv.org/abs/2508.06974)
*Zhijun Tu,Hanting Chen,Siqi Liu,Chuanjian Liu,Jian Li,Jie Hu,Yunhe Wang*

Main category: cs.CL

TL;DR: 提出一种渐进式训练方法，用于平滑地将浮点权重转换为二值化权重，并结合二值感知初始化和双尺度补偿，以较低的成本和较小的精度损失，在预训练模型的基础上实现高性能的1比特大语言模型。


<details>
  <summary>Details</summary>
Motivation: 现有的1比特大语言模型量化方法通常需要从头开始训练，无法充分利用预训练模型，导致训练成本高且精度下降明显。研究旨在解决全精度和1比特表示之间的大差距，使得直接适配更加困难。

Method: 提出了一种渐进式训练方法，用于前向和后向传播，以平滑地将浮点权重转换为二值化权重。此外，还采用了二值感知初始化和双尺度补偿来降低渐进式训练的难度并提高性能。

Result: 实验结果表明，该方法在各种尺寸的大语言模型上都优于现有方法，并且能够使用预训练模型实现高性能的1比特大语言模型。

Conclusion: 通过使用预训练模型，可以实现高性能的1比特大语言模型，无需从头开始进行昂贵的训练。

Abstract: 1-bit LLM quantization offers significant advantages in reducing storage and
computational costs. However, existing methods typically train 1-bit LLMs from
scratch, failing to fully leverage pre-trained models. This results in high
training costs and notable accuracy degradation. We identify that the large gap
between full precision and 1-bit representations makes direct adaptation
difficult. In this paper, we introduce a consistent progressive training for
both forward and backward, smoothly converting the floating-point weights into
the binarized ones. Additionally, we incorporate binary-aware initialization
and dual-scaling compensation to reduce the difficulty of progressive training
and improve the performance. Experimental results on LLMs of various sizes
demonstrate that our method outperforms existing approaches. Our results show
that high-performance 1-bit LLMs can be achieved using pre-trained models,
eliminating the need for expensive training from scratch.

</details>


### [246] [Vec2Summ: Text Summarization via Probabilistic Sentence Embeddings](https://arxiv.org/abs/2508.07017)
*Mao Li,Fred Conrad,Johann Gagnon-Bartsch*

Main category: cs.CL

TL;DR: Vec2Summ是一种新颖的摘要方法，通过将文档集合压缩成一个语义向量并进行解码来生成摘要，解决了LLM摘要的上下文长度、可解释性和效率问题，在特定场景下表现出潜力。


<details>
  <summary>Details</summary>
Motivation: 解决现有LLM摘要方法存在的上下文长度限制、可解释性和可控性差、以及效率问题。

Method: Vec2Summ将文档集合表示为语义嵌入空间中的单个平均向量，并通过采样高斯分布进行扰动以捕获主题变异性，然后将平均向量反转为自然语言以生成摘要。

Result: Vec2Summ生成的摘要在连贯性、主题覆盖和效率方面表现良好，与LLM摘要相当，但在细节方面略逊一筹。

Conclusion: Vec2Summ在主题聚焦、顺序无关的语料库上能生成连贯的摘要，其在主题覆盖和效率方面与直接的LLM摘要相当，但细节不够丰富。这些结果表明，在优先考虑可扩展性、语义控制和语料库级别抽象的场景中，Vec2Summ具有潜力。

Abstract: We propose Vec2Summ, a novel method for abstractive summarization that frames
the task as semantic compression. Vec2Summ represents a document collection
using a single mean vector in the semantic embedding space, capturing the
central meaning of the corpus. To reconstruct fluent summaries, we perform
embedding inversion -- decoding this mean vector into natural language using a
generative language model. To improve reconstruction quality and capture some
degree of topical variability, we introduce stochasticity by sampling from a
Gaussian distribution centered on the mean. This approach is loosely analogous
to bagging in ensemble learning, where controlled randomness encourages more
robust and varied outputs. Vec2Summ addresses key limitations of LLM-based
summarization methods. It avoids context-length constraints, enables
interpretable and controllable generation via semantic parameters, and scales
efficiently with corpus size -- requiring only $O(d + d^2)$ parameters.
Empirical results show that Vec2Summ produces coherent summaries for topically
focused, order-invariant corpora, with performance comparable to direct LLM
summarization in terms of thematic coverage and efficiency, albeit with less
fine-grained detail. These results underscore Vec2Summ's potential in settings
where scalability, semantic control, and corpus-level abstraction are
prioritized.

</details>


### [247] [SEADialogues: A Multilingual Culturally Grounded Multi-turn Dialogue Dataset on Southeast Asian Languages](https://arxiv.org/abs/2508.07069)
*Muhammad Dehan Al Kautsar,Aswin Candra,Muhammad Alif Al Hakim,Maxalmina Satria Kahfi,Fajri Koto,Alham Fikri Aji,Peerat Limkonchotiwat,Ekapol Chuangsuwanich,Genta Indra Winata*

Main category: cs.CL

TL;DR: SEADialogues 是一个包含八种语言和文化相关主题的东南亚对话数据集，用于开发具有文化意识的大型语言模型。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数闲聊数据集都忽略了自然人类对话中固有的文化差异。为了解决这一差距，本研究介绍了以东南亚为中心的、以文化为基础的对话数据集SEADialogues。

Method: SEADialogues数据集包含八种语言的对话，并包含个人属性和反映当地社区日常生活的两个文化相关主题。

Result: SEADialogues 是一个包含东南亚八种语言的对话数据集，其中许多语言尽管有大量使用者，但仍属低资源语言。

Conclusion: SEADialogues为研究具有文化意识和以人为中心的大型语言模型，包括对话代理，提供了一个多轮对话数据集。

Abstract: Although numerous datasets have been developed to support dialogue systems,
most existing chit-chat datasets overlook the cultural nuances inherent in
natural human conversations. To address this gap, we introduce SEADialogues, a
culturally grounded dialogue dataset centered on Southeast Asia, a region with
over 700 million people and immense cultural diversity. Our dataset features
dialogues in eight languages from six Southeast Asian countries, many of which
are low-resource despite having sizable speaker populations. To enhance
cultural relevance and personalization, each dialogue includes persona
attributes and two culturally grounded topics that reflect everyday life in the
respective communities. Furthermore, we release a multi-turn dialogue dataset
to advance research on culturally aware and human-centric large language
models, including conversational dialogue agents.

</details>


### [248] [BharatBBQ: A Multilingual Bias Benchmark for Question Answering in the Indian Context](https://arxiv.org/abs/2508.07090)
*Aditya Tomar,Nihar Ranjan Sahoo,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: 为评估印度语言模型中的社会偏见，开发了BharatBBQ基准，发现在印度语言中偏见比英语更严重。


<details>
  <summary>Details</summary>
Motivation: 现有偏见评估基准（如BBQ）主要关注西方背景，不适用于印度等特定文化和社会环境，因此需要开发能够反映印度社会文化现实的基准。

Method: 构建了一个名为BharatBBQ的多语言、多文化适应性基准，涵盖13个社会类别（包括3个交叉群体），包含近5万个初始示例，并扩展到8种印度语言的近40万个示例，用于评估语言模型的偏见和刻板印象偏见。

Result: 研究发现，所有被评估的五种多语言语言模型家族在所有语言和社会类别中都存在持续的偏见，并且在印度语言中偏见比英语更为严重，证明了特定语言和文化背景下评估基准的必要性。

Conclusion: 该研究强调了在印度语言和文化背景下评估语言模型偏见的重要性，并发现与英语相比，印度语言中的偏见普遍存在且有所加剧，因此需要特定语言和文化的评估基准。

Abstract: Evaluating social biases in language models (LMs) is crucial for ensuring
fairness and minimizing the reinforcement of harmful stereotypes in AI systems.
Existing benchmarks, such as the Bias Benchmark for Question Answering (BBQ),
primarily focus on Western contexts, limiting their applicability to the Indian
context. To address this gap, we introduce BharatBBQ, a culturally adapted
benchmark designed to assess biases in Hindi, English, Marathi, Bengali, Tamil,
Telugu, Odia, and Assamese. BharatBBQ covers 13 social categories, including 3
intersectional groups, reflecting prevalent biases in the Indian sociocultural
landscape. Our dataset contains 49,108 examples in one language that are
expanded using translation and verification to 392,864 examples in eight
different languages. We evaluate five multilingual LM families across zero and
few-shot settings, analyzing their bias and stereotypical bias scores. Our
findings highlight persistent biases across languages and social categories and
often amplified biases in Indian languages compared to English, demonstrating
the necessity of linguistically and culturally grounded benchmarks for bias
evaluation.

</details>


### [249] [Less Is More: Training-Free Sparse Attention with Global Locality for Efficient Reasoning](https://arxiv.org/abs/2508.07101)
*Lijie Yang,Zhihao Zhang,Arti Jain,Shijie Cao,Baihong Yuan,Yiwei Chen,Zhihao Jia,Ravi Netravali*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large reasoning models achieve strong performance through test-time scaling
but incur substantial computational overhead, particularly from excessive token
generation when processing short input prompts. While sparse attention
mechanisms can reduce latency and memory usage, existing approaches suffer from
significant accuracy degradation due to accumulated errors during
long-generation reasoning. These methods generally require either high token
retention rates or expensive retraining. We introduce LessIsMore, a
training-free sparse attention mechanism for reasoning tasks, which leverages
global attention patterns rather than relying on traditional head-specific
local optimizations. LessIsMore aggregates token selections from local
attention heads with recent contextual information, enabling unified cross-head
token ranking for future decoding layers. This unified selection improves
generalization and efficiency by avoiding the need to maintain separate token
subsets per head. Evaluation across diverse reasoning tasks and benchmarks
shows that LessIsMore preserves -- and in some cases improves -- accuracy while
achieving a $1.1\times$ average decoding speed-up compared to full attention.
Moreover, LessIsMore attends to $2\times$ fewer tokens without accuracy loss,
achieving a $1.13\times$ end-to-end speed-up compared to existing sparse
attention methods.

</details>


### [250] [Investigating Intersectional Bias in Large Language Models using Confidence Disparities in Coreference Resolution](https://arxiv.org/abs/2508.07111)
*Falaah Arif Khan,Nivedha Sivakumar,Yinong Oliver Wang,Katherine Metcalf,Cezanne Camacho,Barry-John Theobald,Luca Zappella,Nicholas Apostoloff*

Main category: cs.CL

TL;DR: 本研究提出了WinoIdentity数据集，评估了LLM在交叉性偏见方面的表现，发现模型对双重不利身份的识别存在显著不确定性，这可能源于记忆而非推理，揭示了价值对齐和有效性方面的缺陷。


<details>
  <summary>Details</summary>
Motivation: 由于AI系统可能反映并加剧社会偏见，特别是在招聘和招生等关键社会背景下，对LLM的偏见评估至关重要。现有研究主要集中在单一维度的公平性评估，而本研究旨在扩展到交叉性偏见，认识到多个歧视轴的交叉会产生独特的劣势模式。

Method: 本研究提出了一个新的基准数据集WinoIdentity，通过在WinoBias数据集中加入25个跨越10个属性（包括年龄、国籍和种族）的人口统计学标记，并与二元性别相结合，生成了245,700个提示，以评估50种不同的偏见模式。研究重点关注了由于代表性不足而导致的遗漏性危害，并通过不确定性的视角来调查偏见，提出了一种名为“共指置信度差异”的群体（不）公平性度量。

Result: 研究评估了五种近期发布的LLM，发现其在包括体型、性取向和社会经济地位在内的各种人口统计学属性上存在高达40%的置信度差异。

Conclusion: LLM在处理反刻板印象的设置时，对处于双重不利地位的身份的识别不确定性最高，达到40%。这种不确定性不仅限于特定的群体，还延伸到主流或有优势的标记，这表明LLM的性能可能更多地依赖于记忆而非逻辑推理。这些发现揭示了价值对齐和有效性方面的两个独立缺陷，可能加剧社会危害。

Abstract: Large language models (LLMs) have achieved impressive performance, leading to
their widespread adoption as decision-support tools in resource-constrained
contexts like hiring and admissions. There is, however, scientific consensus
that AI systems can reflect and exacerbate societal biases, raising concerns
about identity-based harm when used in critical social contexts. Prior work has
laid a solid foundation for assessing bias in LLMs by evaluating demographic
disparities in different language reasoning tasks. In this work, we extend
single-axis fairness evaluations to examine intersectional bias, recognizing
that when multiple axes of discrimination intersect, they create distinct
patterns of disadvantage. We create a new benchmark called WinoIdentity by
augmenting the WinoBias dataset with 25 demographic markers across 10
attributes, including age, nationality, and race, intersected with binary
gender, yielding 245,700 prompts to evaluate 50 distinct bias patterns.
Focusing on harms of omission due to underrepresentation, we investigate bias
through the lens of uncertainty and propose a group (un)fairness metric called
Coreference Confidence Disparity which measures whether models are more or less
confident for some intersectional identities than others. We evaluate five
recently published LLMs and find confidence disparities as high as 40% along
various demographic attributes including body type, sexual orientation and
socio-economic status, with models being most uncertain about
doubly-disadvantaged identities in anti-stereotypical settings. Surprisingly,
coreference confidence decreases even for hegemonic or privileged markers,
indicating that the recent impressive performance of LLMs is more likely due to
memorization than logical reasoning. Notably, these are two independent
failures in value alignment and validity that can compound to cause social
harm.

</details>


### [251] [Fairness of Automatic Speech Recognition: Looking Through a Philosophical Lens](https://arxiv.org/abs/2508.07143)
*Anna Seo Gyeong Choi,Hoon Choi*

Main category: cs.CL

TL;DR: ASR 系统存在偏见，对非标准方言不友好，这不仅是技术问题，更是歧视，会加剧社会不公。需要从哲学和伦理角度解决，承认并适应语言多样性。


<details>
  <summary>Details</summary>
Motivation: 研究 ASR 系统的公平性问题，特别是其偏见对边缘化语言社区造成的负面影响，并提出新的分析框架和解决方案。

Method: 通过哲学视角审视 ASR 偏见，区分道德中立的分类和有害的歧视，并指出 ASR 系统可能将前者转化为后者。分析了语音技术三个独特的伦理维度：对非标准方言发言者的“时间税”，系统错误识别语音时造成的对话中断，以及语音模式与个人/文化身份之间的根本联系。探讨了 ASR 开发中语言标准化与多元化之间的矛盾，并认为当前方法可能嵌入并强化了存在问题的语言意识形态。

Result: 识别出 ASR 偏见区别于其他算法公平性问题的三个独特伦理维度（时间税、对话中断、语音与身份的联系），这些因素造成了现有技术公平性指标无法捕捉的不对称权力关系。当前的 ASR 开发方法可能嵌入并强化了存在问题的语言意识形态。

Conclusion: ASR 系统的偏见不仅仅是技术限制，更是对边缘化语言社区历史不公的加剧。要解决 ASR 偏见，需要超越技术干预，承认并适应多样化的语音表达形式，以尊重语言多样性和发言者自主权。

Abstract: Automatic Speech Recognition (ASR) systems now mediate countless
human-technology interactions, yet research on their fairness implications
remains surprisingly limited. This paper examines ASR bias through a
philosophical lens, arguing that systematic misrecognition of certain speech
varieties constitutes more than a technical limitation -- it represents a form
of disrespect that compounds historical injustices against marginalized
linguistic communities. We distinguish between morally neutral classification
(discriminate1) and harmful discrimination (discriminate2), demonstrating how
ASR systems can inadvertently transform the former into the latter when they
consistently misrecognize non-standard dialects. We identify three unique
ethical dimensions of speech technologies that differentiate ASR bias from
other algorithmic fairness concerns: the temporal burden placed on speakers of
non-standard varieties ("temporal taxation"), the disruption of conversational
flow when systems misrecognize speech, and the fundamental connection between
speech patterns and personal/cultural identity. These factors create asymmetric
power relationships that existing technical fairness metrics fail to capture.
The paper analyzes the tension between linguistic standardization and pluralism
in ASR development, arguing that current approaches often embed and reinforce
problematic language ideologies. We conclude that addressing ASR bias requires
more than technical interventions; it demands recognition of diverse speech
varieties as legitimate forms of expression worthy of technological
accommodation. This philosophical reframing offers new pathways for developing
ASR systems that respect linguistic diversity and speaker autonomy.

</details>


### [252] [Gradient Surgery for Safe LLM Fine-Tuning](https://arxiv.org/abs/2508.07172)
*Biao Yi,Jiahao Li,Baolei Zhang,Lihai Nie,Tong Li,Tiansheng Huang,Zheli Liu*

Main category: cs.CL

TL;DR: SafeGrad 是一种新的 LLM 安全微调方法，通过梯度手术解决梯度冲突，即使在存在大量恶意数据的情况下也能有效防御，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 微调服务存在安全漏洞，少量恶意样本即可损害模型的安全对齐。现有解决方案对有害比例敏感，且随着有害比例增加防御效果会急剧下降，这是因为用户任务更新直接破坏了安全目标。

Method: SafeGrad 通过梯度手术来解决梯度冲突问题，当检测到冲突时，通过将用户任务梯度投影到对齐梯度的正交平面上来抵消其有害部分，从而使模型能够学习用户任务而不牺牲安全性。此外，还采用了 KL 散度对齐损失来学习与对齐的基线模型丰富的分布安全配置文件，以增强鲁棒性和数据效率。

Result: SafeGrad 在各种 LLM 和数据集上提供了最先进的防御效果，即使在有害比例很高的情况下也能保持鲁棒性安全，同时不损害任务保真度。

Conclusion: SafeGrad 提出了一种通过梯度手术来解决 LLM 安全性对齐问题的有效方法，在各种 LLM 和数据集上实现了最先进的防御效果，即使在有害比例很高的情况下也能保持鲁棒性安全，同时不损害任务保真度。

Abstract: Fine-tuning-as-a-Service introduces a critical vulnerability where a few
malicious examples mixed into the user's fine-tuning dataset can compromise the
safety alignment of Large Language Models (LLMs). While a recognized paradigm
frames safe fine-tuning as a multi-objective optimization problem balancing
user task performance with safety alignment, we find existing solutions are
critically sensitive to the harmful ratio, with defenses degrading sharply as
harmful ratio increases. We diagnose that this failure stems from conflicting
gradients, where the user-task update directly undermines the safety objective.
To resolve this, we propose SafeGrad, a novel method that employs gradient
surgery. When a conflict is detected, SafeGrad nullifies the harmful component
of the user-task gradient by projecting it onto the orthogonal plane of the
alignment gradient, allowing the model to learn the user's task without
sacrificing safety. To further enhance robustness and data efficiency, we
employ a KL-divergence alignment loss that learns the rich, distributional
safety profile of the well-aligned foundation model. Extensive experiments show
that SafeGrad provides state-of-the-art defense across various LLMs and
datasets, maintaining robust safety even at high harmful ratios without
compromising task fidelity.

</details>


### [253] [Omni-SafetyBench: A Benchmark for Safety Evaluation of Audio-Visual Large Language Models](https://arxiv.org/abs/2508.07173)
*Leyi Pan,Zheyu Fu,Yunpeng Zhai,Shuchang Tao,Sheng Guan,Shiyu Huang,Lingzhe Zhang,Zhaoyang Liu,Bolin Ding,Felix Henry,Lijie Wen,Aiwei Liu*

Main category: cs.CL

TL;DR: 本研究提出了首个用于评估全模态大语言模型（OLLMs）安全性的基准Omni-SafetyBench及相关指标，并发现现有模型在处理复杂输入和跨模态一致性方面存在显著的安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 全模态大语言模型（OLLMs）的兴起需要对其安全性进行严格评估，但现有基准无法满足其音视频联合输入和跨模态安全一致性的评估需求。

Method: 提出Omni-SafetyBench基准，包含24种模态组合和972个样本，并设计了音视频危害案例。提出定制化指标：安全得分（基于条件攻击成功率C-ASR和拒绝率C-RR）和跨模态安全一致性得分（CMSC-score）。

Result: 评估6个开源和4个闭源OLLM发现：1.没有模型在整体安全性和一致性方面均表现优异；2.安全防护在复杂输入下减弱；3.模型在特定模态上存在严重弱点。

Conclusion: 现有的研究缺乏针对全模态大语言模型（OLLMs）的安全评估基准，特别是针对音视频联合输入或跨模态安全一致性的评估。为了解决这一问题，我们提出了Omni-SafetyBench，这是首个针对OLLM安全评估的综合性并行基准，包含24种模态组合和972个样本，并特别设计了音视频危害案例。我们还提出了针对OLLM理解复杂全模态输入和跨模态一致性评估的定制化指标：基于条件攻击成功率（C-ASR）和拒绝率（C-RR）的安全得分，以及衡量跨模态一致性的跨模态安全一致性得分（CMSC-score）。对6个开源和4个闭源OLLM的评估揭示了关键的漏洞：没有模型能在整体安全性和一致性方面表现出色，仅有3个模型在这两项指标上得分超过0.6，而表现最佳的模型得分约为0.8；安全防护在复杂输入下（尤其是音视频联合输入）会减弱；模型在特定模态上仍存在严重缺陷，部分模型得分低至0.14。本基准和指标突显了增强OLLM安全性的迫切需求，并为未来的改进奠定了基础。

Abstract: The rise of Omni-modal Large Language Models (OLLMs), which integrate visual
and auditory processing with text, necessitates robust safety evaluations to
mitigate harmful outputs. However, no dedicated benchmarks currently exist for
OLLMs, and prior benchmarks designed for other LLMs lack the ability to assess
safety performance under audio-visual joint inputs or cross-modal safety
consistency. To fill this gap, we introduce Omni-SafetyBench, the first
comprehensive parallel benchmark for OLLM safety evaluation, featuring 24
modality combinations and variations with 972 samples each, including dedicated
audio-visual harm cases. Considering OLLMs' comprehension challenges with
complex omni-modal inputs and the need for cross-modal consistency evaluation,
we propose tailored metrics: a Safety-score based on conditional Attack Success
Rate (C-ASR) and Refusal Rate (C-RR) to account for comprehension failures, and
a Cross-Modal Safety Consistency Score (CMSC-score) to measure consistency
across modalities. Evaluating 6 open-source and 4 closed-source OLLMs reveals
critical vulnerabilities: (1) no model excels in both overall safety and
consistency, with only 3 models achieving over 0.6 in both metrics and top
performer scoring around 0.8; (2) safety defenses weaken with complex inputs,
especially audio-visual joints; (3) severe weaknesses persist, with some models
scoring as low as 0.14 on specific modalities. Our benchmark and metrics
highlight urgent needs for enhanced OLLM safety, providing a foundation for
future improvements.

</details>


### [254] [Improved Personalized Headline Generation via Denoising Fake Interests from Implicit Feedback](https://arxiv.org/abs/2508.07178)
*Kejin Liu,Junhong Lian,Xiang Ao,Ningtao Wang,Xing Fu,Yu Cheng,Weiqiang Wang,Xinyu Liu*

Main category: cs.CL

TL;DR: PHG-DIF通过去除虚假兴趣的隐含反馈来生成个性化标题，解决了现有方法忽略点击噪音的问题，并在新的DT-PENS基准测试中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了整个点击流中个性化不相关的点击噪音，这可能导致生成的标题与真实用户偏好相悖。

Method: PHG-DIF框架首先采用双阶段过滤来有效去除由短停留时间和异常点击爆发引起的点击流噪音，然后利用多级时间融合来动态建模用户不断演变的多方面兴趣以进行精确画像。

Result: PHG-DIF显著减轻了点击噪音的不利影响，并显著提高了标题质量，在DT-PENS上取得了最先进（SOTA）的结果。

Conclusion: PHG-DIF框架显著减轻了点击噪音的不利影响，并显著提高了标题质量，在DT-PENS上取得了最先进（SOTA）的结果。

Abstract: Accurate personalized headline generation hinges on precisely capturing user
interests from historical behaviors. However, existing methods neglect
personalized-irrelevant click noise in entire historical clickstreams, which
may lead to hallucinated headlines that deviate from genuine user preferences.
In this paper, we reveal the detrimental impact of click noise on personalized
generation quality through rigorous analysis in both user and news dimensions.
Based on these insights, we propose a novel Personalized Headline Generation
framework via Denoising Fake Interests from Implicit Feedback (PHG-DIF).
PHG-DIF first employs dual-stage filtering to effectively remove clickstream
noise, identified by short dwell times and abnormal click bursts, and then
leverages multi-level temporal fusion to dynamically model users' evolving and
multi-faceted interests for precise profiling. Moreover, we release DT-PENS, a
new benchmark dataset comprising the click behavior of 1,000 carefully curated
users and nearly 10,000 annotated personalized headlines with historical dwell
time annotations. Extensive experiments demonstrate that PHG-DIF substantially
mitigates the adverse effects of click noise and significantly improves
headline quality, achieving state-of-the-art (SOTA) results on DT-PENS. Our
framework implementation and dataset are available at
https://github.com/liukejin-up/PHG-DIF.

</details>


### [255] [Schema Lineage Extraction at Scale: Multilingual Pipelines, Composite Evaluation, and Language-Model Benchmarks](https://arxiv.org/abs/2508.07179)
*Jiaqi Yin,Yi-Wei Chen,Meng-Lung Lee,Xiya Liu*

Main category: cs.CL

TL;DR: 该研究提出了一种从多语言企业数据管道中自动提取模式沿袭的新方法，解决了语义漂移问题。该方法通过 SLiCE 指标和新基准进行评估，并证明了大型语言模型（LLMs）在提高提取准确性方面的有效性，为实际应用中的模式感知代理部署提供了可扩展且经济高效的解决方案。


<details>
  <summary>Details</summary>
Motivation: 企业数据管道中的“语义漂移”会损害数据可重现性和治理，并降低检索增强生成（RAG）和文本到 SQL 系统等服务的实用性。

Method: 该方法通过识别四个关键组件（源模式、源表、转换逻辑和聚合操作）来自动化多语言企业管道脚本中的细粒度模式沿袭提取，从而创建数据转换的标准表示。此外，该论文还引入了模式沿袭复合评估（SLiCE）指标来评估沿袭质量，并提出了一个包含 1,700 个手动注释沿袭的新基准，以进行严格评估。

Result: 实验表明，模式沿袭提取的性能随着模型大小和提示技术的复杂性而扩展，其中一个 32B 的开源模型使用单一推理链，在标准提示下即可达到与 GPT 系列相当的性能。

Conclusion: 该方法提出了一种可扩展且经济高效的解决方案，可将模式感知代理部署到实际应用程序中。

Abstract: Enterprise data pipelines, characterized by complex transformations across
multiple programming languages, often cause a semantic disconnect between
original metadata and downstream data. This "semantic drift" compromises data
reproducibility and governance, and impairs the utility of services like
retrieval-augmented generation (RAG) and text-to-SQL systems. To address this,
a novel framework is proposed for the automated extraction of fine-grained
schema lineage from multilingual enterprise pipeline scripts. This method
identifies four key components: source schemas, source tables, transformation
logic, and aggregation operations, creating a standardized representation of
data transformations. For the rigorous evaluation of lineage quality, this
paper introduces the Schema Lineage Composite Evaluation (SLiCE), a metric that
assesses both structural correctness and semantic fidelity. A new benchmark is
also presented, comprising 1,700 manually annotated lineages from real-world
industrial scripts. Experiments were conducted with 12 language models, from
1.3B to 32B small language models (SLMs) to large language models (LLMs) like
GPT-4o and GPT-4.1. The results demonstrate that the performance of schema
lineage extraction scales with model size and the sophistication of prompting
techniques. Specially, a 32B open-source model, using a single reasoning trace,
can achieve performance comparable to the GPT series under standard prompting.
This finding suggests a scalable and economical approach for deploying
schema-aware agents in practical applications.

</details>


### [256] [DySK-Attn: A Framework for Efficient, Real-Time Knowledge Updating in Large Language Models via Dynamic Sparse Knowledge Attention](https://arxiv.org/abs/2508.07185)
*Kabir Khan,Priya Sharma,Arjun Mehta,Neha Gupta,Ravi Narayanan*

Main category: cs.CL

TL;DR: DySK-Attn 通过结合语言大模型和动态知识图，并利用稀疏知识注意力机制，实现了高效的实时知识集成，解决了语言大模型知识过时的问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决语言大模型知识静态且迅速过时的问题，而重新训练这些模型成本高昂，现有的知识编辑技术可能速度慢且会带来意想不到的副作用。

Method: DySK-Attn 框架的核心是稀疏知识注意力机制，它允许语言大模型执行从粗到细的搜索，有效地从庞大的知识图中识别并关注一小部分高度相关的知识。该机制避免了对整个知识库进行密集注意力的高度计算成本，并减少了来自不相关信息的干扰。

Result: DySK-Attn 在时间敏感问答任务上的广泛实验表明，与包括标准检索增强生成（RAG）和模型编辑技术在内的强有力基线相比，DySK-Attn 在更新知识的事实准确性和计算效率方面都显著优于它们。

Conclusion: DySK-Attn 提供了一个可扩展且有效的解决方案，用于构建能够跟上瞬息万变的世界的语言大模型。

Abstract: Large Language Models (LLMs) suffer from a critical limitation: their
knowledge is static and quickly becomes outdated. Retraining these massive
models is computationally prohibitive, while existing knowledge editing
techniques can be slow and may introduce unforeseen side effects. To address
this, we propose DySK-Attn, a novel framework that enables LLMs to efficiently
integrate real-time knowledge from a dynamic external source. Our approach
synergizes an LLM with a dynamic Knowledge Graph (KG) that can be updated
instantaneously. The core of our framework is a sparse knowledge attention
mechanism, which allows the LLM to perform a coarse-to-fine grained search,
efficiently identifying and focusing on a small, highly relevant subset of
facts from the vast KG. This mechanism avoids the high computational cost of
dense attention over the entire knowledge base and mitigates noise from
irrelevant information. We demonstrate through extensive experiments on
time-sensitive question-answering tasks that DySK-Attn significantly
outperforms strong baselines, including standard Retrieval-Augmented Generation
(RAG) and model editing techniques, in both factual accuracy for updated
knowledge and computational efficiency. Our framework offers a scalable and
effective solution for building LLMs that can stay current with the
ever-changing world.

</details>


### [257] [Adapting LLMs to Time Series Forecasting via Temporal Heterogeneity Modeling and Semantic Alignment](https://arxiv.org/abs/2508.07195)
*Yanru Sun,Emadeldeen Eldele,Zongxia Xie,Yucheng Wang,Wenzhe Niu,Qinghua Hu,Chee Keong Kwoh,Min Wu*

Main category: cs.CL

TL;DR: TALON框架通过处理时间异质性和语义对齐来增强LLM在时间序列预测方面的能力，在七个真实世界基准测试中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: LLM在自然语言处理方面展现出强大的能力，但将其直接应用于时间序列预测面临两大挑战：时间序列模式的内在异质性和连续数值信号与离散语言表示之间的模态差距。

Method: TALON框架通过设计异质时间序列编码器来处理时间模式的异质性，该编码器将多元时间序列划分为结构相干的片段，实现跨不同时间模式的本地化专家建模。为了弥合模态差距，引入了语义对齐模块，将时间序列特征与LLM兼容的表示对齐，从而在推理过程中无需手工提示即可实现时间序列与基于语言的模型有效集成。

Result: 在七个真实世界基准数据集上的大量实验表明，TALON在所有数据集上均实现了卓越的性能，平均均方误差（MSE）相较于近期最先进的方法平均提高了11%。

Conclusion: LLM在时间序列预测方面的应用仍然具有挑战性，需要解决时间序列模式的异质性和连续数值信号与离散语言表示之间的模态差距。TALON框架通过对异质时间序列进行分区，实现跨不同时间模式的本地化专家建模，并引入语义对齐模块将时间序列特征与LLM兼容表示对齐，从而有效弥合了模态差距。

Abstract: Large Language Models (LLMs) have recently demonstrated impressive
capabilities in natural language processing due to their strong generalization
and sequence modeling capabilities. However, their direct application to time
series forecasting remains challenging due to two fundamental issues: the
inherent heterogeneity of temporal patterns and the modality gap between
continuous numerical signals and discrete language representations. In this
work, we propose TALON, a unified framework that enhances LLM-based forecasting
by modeling temporal heterogeneity and enforcing semantic alignment.
Specifically, we design a Heterogeneous Temporal Encoder that partitions
multivariate time series into structurally coherent segments, enabling
localized expert modeling across diverse temporal patterns. To bridge the
modality gap, we introduce a Semantic Alignment Module that aligns temporal
features with LLM-compatible representations, enabling effective integration of
time series into language-based models while eliminating the need for
handcrafted prompts during inference. Extensive experiments on seven real-world
benchmarks demonstrate that TALON achieves superior performance across all
datasets, with average MSE improvements of up to 11\% over recent
state-of-the-art methods. These results underscore the effectiveness of
incorporating both pattern-aware and semantic-aware designs when adapting LLMs
for time series forecasting. The code is available at:
https://github.com/syrGitHub/TALON.

</details>


### [258] [How Does a Deep Neural Network Look at Lexical Stress?](https://arxiv.org/abs/2508.07229)
*Itai Allouche,Itay Asael,Rotem Rousso,Vered Dassa,Ann Bradlow,Seung-Eun Kim,Matthew Goldrick,Joseph Keshet*

Main category: cs.CL

TL;DR: 这项研究利用CNN和LRP技术分析了词重音的识别。CNN在预测重音方面表现出色（准确率达92%），其决策主要基于重读元音的光谱特性，特别是f1和f2。这表明深度学习能从自然语料中学习重音线索，并为语音学研究提供了新的视角。


<details>
  <summary>Details</summary>
Motivation: 探讨神经网络在语音处理中的决策依据以及如何进行解释，特别是在词重音识别的背景下。

Method: 使用层级相关性传播（LRP）技术对卷积神经网络（CNN）进行可解释性分析，揭示了预测中受影响最大的信息。提出了一种特定于特征的相关性分析方法，并分析了最佳分类器受到的影响因素。

Result: 研究表明，CNN模型在预测词重音位置方面达到了92%的准确率。LRP分析显示，模型预测主要受重读音节（特别是元音的光谱特性）的影响，但也关注整个单词的信息。特征特定分析表明，最佳模型受到重读元音的第一、第二共振峰（f1, f2）的强烈影响，音高和第三共振峰（f3）也有一定的贡献。

Conclusion: 深度学习能够从自然发生的语料中学习到分布式线索来识别重音，这扩展了传统语音学中基于高度受控刺激的研究。

Abstract: Despite their success in speech processing, neural networks often operate as
black boxes, prompting the question: what informs their decisions, and how can
we interpret them? This work examines this issue in the context of lexical
stress. A dataset of English disyllabic words was automatically constructed
from read and spontaneous speech. Several Convolutional Neural Network (CNN)
architectures were trained to predict stress position from a spectrographic
representation of disyllabic words lacking minimal stress pairs (e.g., initial
stress WAllet, final stress exTEND), achieving up to 92% accuracy on held-out
test data. Layerwise Relevance Propagation (LRP), a technique for CNN
interpretability analysis, revealed that predictions for held-out minimal pairs
(PROtest vs. proTEST ) were most strongly influenced by information in stressed
versus unstressed syllables, particularly the spectral properties of stressed
vowels. However, the classifiers also attended to information throughout the
word. A feature-specific relevance analysis is proposed, and its results
suggest that our best-performing classifier is strongly influenced by the
stressed vowel's first and second formants, with some evidence that its pitch
and third formant also contribute. These results reveal deep learning's ability
to acquire distributed cues to stress from naturally occurring data, extending
traditional phonetic work based around highly controlled stimuli.

</details>


### [259] [Prompt Tuning for Few-Shot Continual Learning Named Entity Recognition](https://arxiv.org/abs/2508.07248)
*Zhe Ren*

Main category: cs.CL

TL;DR: 为了解决少样本持续学习命名实体识别（FS-CLNER）中的“少样本蒸馏困境”，研究者提出了一种结合锚点词提示词调优（APT）和记忆演示模板（MDT）的策略，以增强模型在少样本场景下的泛化能力并有效利用旧知识。


<details>
  <summary>Details</summary>
Motivation: 在少样本持续学习命名实体识别（FS-CLNER）任务中，新类实体的稀缺性使得模型在推理时难以泛化，并且缺乏旧类实体信息阻碍了旧知识的蒸馏，导致了“少样本蒸馏困境”。

Method: 通过采用提示词调优范式和记忆演示模板策略来解决挑战。具体来说，设计了一个可扩展的面向锚点词的提示词调优（APT）范式来弥合预训练和微调之间的差距，并结合记忆演示模板（MDT）为每个训练实例提供来自先前任务的重放样本。

Result: 实验表明，所提出的方法在FS-CLNER任务上取得了有竞争力的性能。

Conclusion: 所提出的方法在少样本持续学习命名实体识别（FS-CLNER）任务上取得了有竞争力的性能。

Abstract: Knowledge distillation has been successfully applied to Continual Learning
Named Entity Recognition (CLNER) tasks, by using a teacher model trained on
old-class data to distill old-class entities present in new-class data as a
form of regularization, thereby avoiding catastrophic forgetting. However, in
Few-Shot CLNER (FS-CLNER) tasks, the scarcity of new-class entities makes it
difficult for the trained model to generalize during inference. More
critically, the lack of old-class entity information hinders the distillation
of old knowledge, causing the model to fall into what we refer to as the
Few-Shot Distillation Dilemma. In this work, we address the above challenges
through a prompt tuning paradigm and memory demonstration template strategy.
Specifically, we designed an expandable Anchor words-oriented Prompt Tuning
(APT) paradigm to bridge the gap between pre-training and fine-tuning, thereby
enhancing performance in few-shot scenarios. Additionally, we incorporated
Memory Demonstration Templates (MDT) into each training instance to provide
replay samples from previous tasks, which not only avoids the Few-Shot
Distillation Dilemma but also promotes in-context learning. Experiments show
that our approach achieves competitive performances on FS-CLNER.

</details>


### [260] [The 2D+ Dynamic Articulatory Model DYNARTmo: Tongue-Palate Contact Area Estimation](https://arxiv.org/abs/2508.07262)
*Bernd J. Kröger*

Main category: cs.CL

TL;DR: 该研究扩展了 DYNARTmo 模型，通过三维腭顶表示来估算舌腭接触区域，并支持多视图显示，适用于教育和治疗。


<details>
  <summary>Details</summary>
Motivation: 为了扩展二维动态发音模型 DYNARTmo，通过集成内部三维腭顶表示，从而从矢状面舌头轮廓估算舌腭接触区域。

Method: 通过集成内部三维腭顶表示，实现对 DYNARTmo 模型的扩展，该表示采用半椭圆和基于余弦的轮廓来模拟冠状面中的侧向曲率。通过解析计算每个前后位置的侧向接触点，生成类似舌腭接触图的显示。

Result: 模型可以生成舌腭接触区域的可视化，并支持同步的三个视图（矢状面、声门面和腭面）的静态和动态显示。

Conclusion: 该模型通过集成内部三维腭顶表示，从矢状面舌头轮廓估算舌腭接触区域，并支持同步的三个视图（矢状面、声门面和腭面）的静态和动态显示，适用于语音科学教育和语音治疗。

Abstract: This paper describes an extension of the two-dimensional dynamic articulatory
model DYNARTmo by integrating an internal three-dimensional representation of
the palatal dome to estimate tongue-palate contact areas from midsagittal
tongue contours. Two alternative dome geometries - a half-ellipse and a cosine
based profile - are implemented to model lateral curvature in the coronal
plane. Using these geometries, lateral contact points are analytically computed
for each anterior-posterior position, enabling the generation of
electropalatography-like visualizations within the 2D+ framework. The enhanced
model supports three synchronized views (sagittal, glottal, and palatal) for
static and dynamic (animated) articulation displays, suitable for speech
science education and speech therapy. Future work includes adding a facial
(lip) view and implementing articulatory-to-acoustic synthesis to
quantitatively evaluate model realism.

</details>


### [261] [Incorporating Contextual Paralinguistic Understanding in Large Speech-Language Models](https://arxiv.org/abs/2508.07273)
*Qiongqiong Wang,Hardik B. Sailor,Jeremy H. M. Wong,Tianchi Liu,Shuo Sun,Wenyu Zhang,Muhammad Huzaifah,Nancy Chen,Ai Ti Aw*

Main category: cs.CL

TL;DR: 本文提出显式和隐式方法来改进 speech-LLM 的共情推理，隐式方法可将性能提高 38.41%，结合两者可达 46.02%。


<details>
  <summary>Details</summary>
Motivation: 当前的 speech-LLM 在共情推理方面存在局限性，主要是因为缺乏整合上下文内容和 the paralinguistic 提示的训练数据集。

Method: 本文提出了两种方法来将上下文的 the paralinguistic 信息整合到模型训练中：一种是显式方法，直接将 the paralinguistic 元数据（例如情绪注释）提供给 LLM；另一种是隐式方法，利用分类和维度情绪注释以及语音转录自动生成新的训练问题-答案（QA）对。

Result: 隐式方法在人类注释的 QA 基准上将 LLM 判断的性能提高了 38.41%，与显式方法相结合时达到 46.02%，证明了其在上下文 the paralinguistic 理解方面的有效性。还通过展示 LLM 裁判与分类指标的相关性来验证其可靠性。

Conclusion: 所提出的显式和隐式方法通过整合上下文和 the paralinguistic 提示来改进 speech-LLM 的共情推理能力，其中隐式方法在人类注释的 QA 基准上将 LLM 判断的性能提高了 38.41%，与显式方法相结合时达到 46.02%。

Abstract: Current large speech language models (Speech-LLMs) often exhibit limitations
in empathetic reasoning, primarily due to the absence of training datasets that
integrate both contextual content and paralinguistic cues. In this work, we
propose two approaches to incorporate contextual paralinguistic information
into model training: (1) an explicit method that provides paralinguistic
metadata (e.g., emotion annotations) directly to the LLM, and (2) an implicit
method that automatically generates novel training question-answer (QA) pairs
using both categorical and dimensional emotion annotations alongside speech
transcriptions. Our implicit method boosts performance (LLM-judged) by 38.41%
on a human-annotated QA benchmark, reaching 46.02% when combined with the
explicit approach, showing effectiveness in contextual paralinguistic
understanding. We also validate the LLM judge by demonstrating its correlation
with classification metrics, providing support for its reliability.

</details>


### [262] [MAQuA: Adaptive Question-Asking for Multidimensional Mental Health Screening using Item Response Theory](https://arxiv.org/abs/2508.07279)
*Vasudha Varadarajan,Hui Xu,Rebecca Astrid Boehme,Mariam Marlan Mirstrom,Sverker Sikstrom,H. Andrew Schwartz*

Main category: cs.CL

TL;DR: MAQuA is an adaptive questioning framework for mental health screening that uses IRT and factor analysis to select the most informative questions, reducing assessment time and burden by 50-87% compared to random ordering.


<details>
  <summary>Details</summary>
Motivation: Excessive querying by LLMs burdens users and is inefficient for real-world screening across transdiagnostic symptom profiles.

Method: Combining multi-outcome modeling on language responses with item response theory (IRT) and factor analysis, MAQuA selects the questions with most informative responses across multiple dimensions at each turn to optimize diagnostic information.

Result: MAQuA reduces the number of assessment questions required for score stabilization by 50-87% compared to random ordering, achieving stable depression scores with 71% fewer questions and eating disorder scores with 85% fewer questions. It demonstrates robust performance across internalizing and externalizing domains, with early stopping strategies further reducing patient time and burden.

Conclusion: MAQuA is a powerful and efficient tool for scalable, nuanced, and interactive mental health screening, advancing the integration of LLM-based agents into real-world clinical workflows.

Abstract: Recent advances in large language models (LLMs) offer new opportunities for
scalable, interactive mental health assessment, but excessive querying by LLMs
burdens users and is inefficient for real-world screening across
transdiagnostic symptom profiles. We introduce MAQuA, an adaptive
question-asking framework for simultaneous, multidimensional mental health
screening. Combining multi-outcome modeling on language responses with item
response theory (IRT) and factor analysis, MAQuA selects the questions with
most informative responses across multiple dimensions at each turn to optimize
diagnostic information, improving accuracy and potentially reducing response
burden. Empirical results on a novel dataset reveal that MAQuA reduces the
number of assessment questions required for score stabilization by 50-87%
compared to random ordering (e.g., achieving stable depression scores with 71%
fewer questions and eating disorder scores with 85% fewer questions). MAQuA
demonstrates robust performance across both internalizing (depression, anxiety)
and externalizing (substance use, eating disorder) domains, with early stopping
strategies further reducing patient time and burden. These findings position
MAQuA as a powerful and efficient tool for scalable, nuanced, and interactive
mental health screening, advancing the integration of LLM-based agents into
real-world clinical workflows.

</details>


### [263] ["Pull or Not to Pull?'': Investigating Moral Biases in Leading Large Language Models Across Ethical Dilemmas](https://arxiv.org/abs/2508.07284)
*Junchen Ding,Penghao Jiang,Zihao Xu,Ziqi Ding,Yichen Zhu,Jiaojiao Jiang,Yuekang Li*

Main category: cs.CL

TL;DR: 本研究评估了14种大型语言模型在27个“电车难题”场景下的道德推理能力。模型在不同伦理框架下表现各异，支持推理的模型决策更果断，但在某些框架下（如利他主义）表现更符合人类判断。研究发现了“甜蜜区”，并强调了将道德推理作为LLM对齐关键评估维度和建立标准化基准的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在道德敏感性决策中扮演越来越重要的角色，理解它们的道德推理过程变得至关重要。

Method: 本研究对14种主流大型语言模型（包括支持推理和通用模型）进行了实证评估，涵盖了由十种道德哲学（如功利主义、义务论和利他主义）定义的27个不同的“电车难题”场景。研究采用了析因提示协议，收集了3780个二元决策和相应的自然语言解释，以便从决策断言性、解释与决策的一致性、与公众道德的对齐程度以及对不相关伦理线索的敏感性等多个维度进行分析。

Result: 研究结果显示，不同模型和不同伦理框架下LLM的表现存在显著差异。支持推理的模型决策更果断，解释更结构化，但不一定更符合人类共识。在利他主义、公平和美德伦理的框架下，“甜蜜区”现象出现，模型在干预率、解释一致性和与人类判断的一致性方面表现良好。但在亲属关系、合法性或自身利益的框架下，模型表现不一致，且常产生有争议的决策。

Conclusion: LLMs在做道德决策时表现出显著差异，受伦理框架和模型类型的影响。研究发现了“甜蜜区”，即模型在某些利他、公平和美德伦理框架下能达到干预率高、解释一致性好和与人类判断一致性强的平衡。然而，在强调亲属关系、合法性或自身利益的框架下，模型表现出现分歧，并可能产生有争议的决策。研究强调，道德提示不仅能改变模型行为，还能揭示其潜在的对齐哲学。研究者主张将道德推理作为LLM对齐的一个主要评估维度，并呼吁建立标准化基准来评估LLM决策的“如何”和“为何”。

Abstract: As large language models (LLMs) increasingly mediate ethically sensitive
decisions, understanding their moral reasoning processes becomes imperative.
This study presents a comprehensive empirical evaluation of 14 leading LLMs,
both reasoning enabled and general purpose, across 27 diverse trolley problem
scenarios, framed by ten moral philosophies, including utilitarianism,
deontology, and altruism. Using a factorial prompting protocol, we elicited
3,780 binary decisions and natural language justifications, enabling analysis
along axes of decisional assertiveness, explanation answer consistency, public
moral alignment, and sensitivity to ethically irrelevant cues. Our findings
reveal significant variability across ethical frames and model types: reasoning
enhanced models demonstrate greater decisiveness and structured justifications,
yet do not always align better with human consensus. Notably, "sweet zones"
emerge in altruistic, fairness, and virtue ethics framings, where models
achieve a balance of high intervention rates, low explanation conflict, and
minimal divergence from aggregated human judgments. However, models diverge
under frames emphasizing kinship, legality, or self interest, often producing
ethically controversial outcomes. These patterns suggest that moral prompting
is not only a behavioral modifier but also a diagnostic tool for uncovering
latent alignment philosophies across providers. We advocate for moral reasoning
to become a primary axis in LLM alignment, calling for standardized benchmarks
that evaluate not just what LLMs decide, but how and why.

</details>


### [264] [Arce: Augmented Roberta with Contextualized Elucidations for Ner in Automated Rule Checking](https://arxiv.org/abs/2508.07286)
*Jian Chen,Jinbao Tian,Yankui Li,Zhou Li*

Main category: cs.CL

TL;DR: ARCE通过LLM生成解释性文本来预训练RoBERTa模型，在AEC领域命名实体识别任务上取得了新的最优性能。


<details>
  <summary>Details</summary>
Motivation: 标准预训练模型在AEC领域存在域迁移问题，而ARCBERT等方法成本高昂；LLM在知识生成方面有潜力，但如何生成有效知识以增强小型模型尚不明确。

Method: ARCE通过LLM生成简明扼要的解释（Cote），然后利用Cote预训练RoBERTa模型，最后在下游任务上进行微调。

Result: ARCE在AEC数据集上达到了77.20%的宏观F1分数，优于现有方法，并发现简单的解释性知识比复杂的基于角色的知识更有效。

Conclusion: ARCE通过在下游任务微调前增量预训练RoBERTa模型，在AEC数据集上实现了77.20%的宏观F1分数，刷新了最先进的性能，并证明了简单的、基于解释的知识比基于角色的复杂知识更有效。

Abstract: Accurate information extraction from specialized texts is a critical
challenge, particularly for named entity recognition (NER) in the architecture,
engineering, and construction (AEC) domain to support automated rule checking
(ARC). The performance of standard pre-trained models is often constrained by
the domain gap, as they struggle to interpret the specialized terminology and
complex relational contexts inherent in AEC texts. Although this issue can be
mitigated by further pre-training on large, human-curated domain corpora, as
exemplified by methods like ARCBERT, this approach is both labor-intensive and
cost-prohibitive. Consequently, leveraging large language models (LLMs) for
automated knowledge generation has emerged as a promising alternative. However,
the optimal strategy for generating knowledge that can genuinely enhance
smaller, efficient models remains an open question. To address this, we propose
ARCE (augmented RoBERTa with contextualized elucidations), a novel approach
that systematically explores and optimizes this generation process. ARCE
employs an LLM to first generate a corpus of simple, direct explanations, which
we term Cote, and then uses this corpus to incrementally pre-train a RoBERTa
model prior to its fine-tuning on the downstream task. Our extensive
experiments show that ARCE establishes a new state-of-the-art on a benchmark
AEC dataset, achieving a Macro-F1 score of 77.20%. This result also reveals a
key finding: simple, explanation-based knowledge proves surprisingly more
effective than complex, role-based rationales for this task. The code is
publicly available at:https://github.com/nxcc-lab/ARCE.

</details>


### [265] [CCFQA: A Benchmark for Cross-Lingual and Cross-Modal Speech and Text Factuality Evaluation](https://arxiv.org/abs/2508.07295)
*Yexing Du,Kaiyuan Liu,Youcheng Pan,Zheng Chu,Bo Yang,Xiaocheng Feng,Yang Xiang,Ming Liu*

Main category: cs.CL

TL;DR: 本研究提出了CCFQA基准，用于评估多语言大语言模型在语音事实问答中的跨语言和跨模态能力。结果显示现有模型仍有很大提升空间，并提出了一种有效的few-shot迁移学习方法，能在少样本情况下达到与GPT-4o-mini-Audio相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有评估多模态大语言模型（MLLMs）可靠性的基准主要关注英语的文本或视觉模态，在处理多语言输入，尤其是语音时存在评估空白。为了解决这一问题，需要一个能够评估MLLM跨语言和跨模态事实性能力的基准。

Method: 提出了一种新颖的跨语言、跨模态事实性问答基准CCFQA，其中包含8种语言的并行语音-文本事实问题，用于系统评估MLLM的跨语言和跨模态事实性能力。同时，提出了一种few-shot迁移学习策略，将LLM的英语问答能力迁移到多语言语音问答任务。

Result: 当前的MLLM在CCFQA基准上面临严峻挑战。提出的few-shot迁移学习策略在5-shot训练下，能够实现与GPT-4o-mini-Audio相当的性能。

Conclusion: CCFQA基准的实验结果表明，当前的MLLM在处理多语言语音问答方面仍面临巨大挑战。提出的few-shot迁移学习策略能够有效地将LLM的英语问答能力迁移到多语言语音问答任务中，并且在仅使用5-shot训练的情况下达到了与GPT-4o-mini-Audio相媲美的性能。CCFQA的发布旨在促进MLLM在语音理解能力方面更加鲁棒和可靠的发展。

Abstract: As Large Language Models (LLMs) are increasingly popularized in the
multilingual world, ensuring hallucination-free factuality becomes markedly
crucial. However, existing benchmarks for evaluating the reliability of
Multimodal Large Language Models (MLLMs) predominantly focus on textual or
visual modalities with a primary emphasis on English, which creates a gap in
evaluation when processing multilingual input, especially in speech. To bridge
this gap, we propose a novel \textbf{C}ross-lingual and \textbf{C}ross-modal
\textbf{F}actuality benchmark (\textbf{CCFQA}). Specifically, the CCFQA
benchmark contains parallel speech-text factual questions across 8 languages,
designed to systematically evaluate MLLMs' cross-lingual and cross-modal
factuality capabilities. Our experimental results demonstrate that current
MLLMs still face substantial challenges on the CCFQA benchmark. Furthermore, we
propose a few-shot transfer learning strategy that effectively transfers the
Question Answering (QA) capabilities of LLMs in English to multilingual Spoken
Question Answering (SQA) tasks, achieving competitive performance with
GPT-4o-mini-Audio using just 5-shot training. We release CCFQA as a
foundational research resource to promote the development of MLLMs with more
robust and reliable speech understanding capabilities. Our code and dataset are
available at https://github.com/yxduir/ccfqa.

</details>


### [266] [HealthBranches: Synthesizing Clinically-Grounded Question Answering Datasets via Decision Pathways](https://arxiv.org/abs/2508.07308)
*Cristian Cosentino,Annamaria Defilippo,Marco Dossena,Christopher Irwin,Sara Joubbi,Pietro Liò*

Main category: cs.CL

TL;DR: HealthBranches 是一个用于评估 LLM 医学推理能力的新型数据集，包含 4,063 个案例和完整的推理路径，支持开放式和选择题，旨在提高 LLM 在医疗领域的可靠性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）在医学领域的复杂推理能力，并为开发更值得信赖、可解释且临床可靠的 LLM 提供基础。

Method: 该数据集通过半自动流水线生成，将医学源中的显式决策路径转化为包含问题和答案的真实患者案例。

Result: HealthBranches 包含 17 个医疗主题的 4,063 个案例研究，支持开放式和选择题两种问题格式，并提供完整的推理路径，可用于评估 LLM 的多步推理和 RAG 能力。

Conclusion: HealthBranches 是一个新颖的医学问答基准数据集，旨在评估大型语言模型（LLM）的复杂推理能力。该数据集通过半自动流水线生成，将医学源中的显式决策路径转化为真实的患者案例，并附带相关的问题和答案。HealthBranches 涵盖了 17 个医疗主题的 4,063 个案例研究，每个数据点都基于经过临床验证的推理链。该数据集支持开放式和选择题两种问题格式，并独特地包含了每个问答的完整推理路径。其结构化设计能够对 LLM 的多步推理能力进行稳健评估，包括在结构化检索增强生成（RAG）的上下文中的表现。HealthBranches 为在高风险领域开发更值得信赖、可解释且临床可靠的 LLM 奠定了基础，同时也为教育目的提供了宝贵的资源。

Abstract: HealthBranches is a novel benchmark dataset for medical Question-Answering
(Q&A), specifically designed to evaluate complex reasoning in Large Language
Models (LLMs). This dataset is generated through a semi-automated pipeline that
transforms explicit decision pathways from medical source into realistic
patient cases with associated questions and answers. Covering 4,063 case
studies across 17 healthcare topics, each data point is based on clinically
validated reasoning chains. HealthBranches supports both open-ended and
multiple-choice question formats and uniquely includes the full reasoning path
for each Q&A. Its structured design enables robust evaluation of LLMs'
multi-step inference capabilities, including their performance in structured
Retrieval-Augmented Generation (RAG) contexts. HealthBranches establishes a
foundation for the development of more trustworthy, interpretable, and
clinically reliable LLMs in high-stakes domains while also serving as a
valuable resource for educational purposes.

</details>


### [267] [ObfusQAte: A Proposed Framework to Evaluate LLM Robustness on Obfuscated Factual Question Answering](https://arxiv.org/abs/2508.07321)
*Shubhra Ghosh,Abhilekh Borah,Aditya Kumar Guru,Kripabandhu Ghosh*

Main category: cs.CL

TL;DR: LLM 在处理被混淆的问题时表现不佳，研究者提出了 ObfusQA 框架来评估这一问题，并已公开 ObfusQAte 技术。


<details>
  <summary>Details</summary>
Motivation: 评估 LLM 在面对被混淆版本的问题时的鲁棒性，因为目前没有已知研究对此进行测试。

Method: 提出了一种名为 ObfusQAte 的新颖技术，并基于此技术引入了 ObfusQA 框架，该框架包含多层混淆级别，旨在检查 LLM 在三个不同维度上的能力：(i) 命名实体间接、(ii) 干扰项间接和 (iii) 上下文过载。

Result: LLM 在面对这些日益复杂的问答变体时，存在失效或产生幻觉回应的倾向。

Conclusion: LLMs 在面对这些日益复杂的问答变体时，存在失效或产生幻觉回应的倾向。

Abstract: The rapid proliferation of Large Language Models (LLMs) has significantly
contributed to the development of equitable AI systems capable of factual
question-answering (QA). However, no known study tests the LLMs' robustness
when presented with obfuscated versions of questions. To systematically
evaluate these limitations, we propose a novel technique, ObfusQAte and,
leveraging the same, introduce ObfusQA, a comprehensive, first of its kind,
framework with multi-tiered obfuscation levels designed to examine LLM
capabilities across three distinct dimensions: (i) Named-Entity Indirection,
(ii) Distractor Indirection, and (iii) Contextual Overload. By capturing these
fine-grained distinctions in language, ObfusQA provides a comprehensive
benchmark for evaluating LLM robustness and adaptability. Our study observes
that LLMs exhibit a tendency to fail or generate hallucinated responses when
confronted with these increasingly nuanced variations. To foster research in
this direction, we make ObfusQAte publicly available.

</details>


### [268] [Strategies of Code-switching in Human-Machine Dialogs](https://arxiv.org/abs/2508.07325)
*Dean Geckt,Melinda Fricke,Shuly Wintner*

Main category: cs.CL

TL;DR: 本研究开发了一个能进行西班牙语和英语语码转换的聊天机器人，用于地图任务。实验表明，参与者偏好可预测的语码转换，随机或不合语法的转换会降低参与度和任务成功率。研究结果强调了完善多语言技术的重要性，并指出了其在双语研究中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 大多数人是多语者，并且大多数多语者会进行语码转换，但语码转换语言的特征尚未被完全理解。本研究旨在深入理解语码转换语言的特征，并探索其在人工智能和语言学研究中的应用。

Method: 本研究开发了一个能够与人类参与者完成地图任务的聊天机器人，该机器人能够进行西班牙语和英语之间的语言切换。通过两个实验，研究者引导机器人采用不同的语言切换策略，旨在探讨（1）此类实验在研究双语语言使用方面的可行性，以及（2）参与者是否能感知到话语和语法模式的差异。

Result: 参与者普遍喜欢与机器人进行语码转换的交流，前提是机器人的语码转换行为具有可预测性。然而，当语码转换随机或不符合语法规范时（例如，生成了未经验证的不一致混合语言名词短语，如“la fork”），参与者则不太享受该任务，并且在完成任务方面也表现不佳。

Conclusion: 参与者在与机器人进行多语言交流时，只要机器人的语言切换方式具有可预测性，他们通常都能享受该过程。当语言切换随机或不合乎语法（例如，生成未经证实的混合语言名词短语，如“la fork”）时，参与者的参与度会下降，任务成功率也会降低。这表明了不完善的多语言语言技术可能带来的弊端，同时也证明了这类技术在研究双语语言使用方面的潜力。

Abstract: Most people are multilingual, and most multilinguals code-switch, yet the
characteristics of code-switched language are not fully understood. We
developed a chatbot capable of completing a Map Task with human participants
using code-switched Spanish and English. In two experiments, we prompted the
bot to code-switch according to different strategies, examining (1) the
feasibility of such experiments for investigating bilingual language use, and
(2) whether participants would be sensitive to variations in discourse and
grammatical patterns. Participants generally enjoyed code-switching with our
bot as long as it produced predictable code-switching behavior; when
code-switching was random or ungrammatical (as when producing unattested
incongruent mixed-language noun phrases, such as `la fork'), participants
enjoyed the task less and were less successful at completing it. These results
underscore the potential downsides of deploying insufficiently developed
multilingual language technology, while also illustrating the promise of such
technology for conducting research on bilingual language use.

</details>


### [269] [Think Before You Talk: Enhancing Meaningful Dialogue Generation in Full-Duplex Speech Language Models with Planning-Inspired Text Guidance](https://arxiv.org/abs/2508.07375)
*Wenqian Cui,Lei Zhu,Xiaohui Li,Zhihan Guo,Haoli Bai,Lu Hou,Irwin King*

Main category: cs.CL

TL;DR: TurnGuide 提出了一种新的规划启发式方法，通过生成轮次级别的文本指导来改善全双工语音语言模型的对话能力，解决了现有方法的时序和长度问题，并在实验中取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端全双工语音语言模型（FD-SLMs）在处理实时口语交互时，其对话能力相比纯文本对话有所下降，这归因于冗长的语音序列和有限的高质量口语对话数据。而文本引导语音生成方法在将文本指导整合到双通道音频流时存在时序和长度问题，扰乱了自然交互所需的精确时间对齐。

Method: TurnGuide 是一种新颖的、受规划启发的、端到端全双工语音语言模型（FD-SLMs）的方法，它通过动态分割助手语音成对话轮次，并在语音输出前生成轮次级别的文本指导，以解决文本引导语音生成中的时序和长度问题。

Result: 实验证明，TurnGuide 方法显著提升了端到端全双工语音语言模型（FD-SLMs）的对话能力，能够生成语义有意义且连贯的语音，同时保持自然的对话流程。

Conclusion: TurnGuide 通过模仿人类对话规划，将助手语音动态分割成对话轮次，并在语音输出前生成轮次级别的文本指导，有效解决了插入时机和长度的挑战，显著提高了端到端全双工语音语言模型的对话能力，使其能够生成语义有意义且连贯的语音，同时保持自然的对话流程。

Abstract: Full-Duplex Speech Language Models (FD-SLMs) are specialized foundation
models designed to enable natural, real-time spoken interactions by modeling
complex conversational dynamics such as interruptions, backchannels, and
overlapping speech, and End-to-end (e2e) FD-SLMs leverage real-world
double-channel conversational data to capture nuanced two-speaker dialogue
patterns for human-like interactions. However, they face a critical challenge
-- their conversational abilities often degrade compared to pure-text
conversation due to prolonged speech sequences and limited high-quality spoken
dialogue data. While text-guided speech generation could mitigate these issues,
it suffers from timing and length issues when integrating textual guidance into
double-channel audio streams, disrupting the precise time alignment essential
for natural interactions. To address these challenges, we propose TurnGuide, a
novel planning-inspired approach that mimics human conversational planning by
dynamically segmenting assistant speech into dialogue turns and generating
turn-level text guidance before speech output, which effectively resolves both
insertion timing and length challenges. Extensive experiments demonstrate our
approach significantly improves e2e FD-SLMs' conversational abilities, enabling
them to generate semantically meaningful and coherent speech while maintaining
natural conversational flow. Demos are available at
https://dreamtheater123.github.io/TurnGuide-Demo/. Code will be available at
https://github.com/dreamtheater123/TurnGuide.

</details>


### [270] [Grounding Multilingual Multimodal LLMs With Cultural Knowledge](https://arxiv.org/abs/2508.07414)
*Jean de Dieu Nyandwi,Yueqi Song,Simran Khanuja,Graham Neubig*

Main category: cs.CL

TL;DR: 通过构建包含2200万个跨越42国39语言的文化视觉问答对的数据集CulturalGround，并训练MLLMCulturalPangea，有效提升了模型在低资源和长尾文化实体上的表现，缩小了文化鸿沟，为全球包容性多模态系统提供了途径。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLM）在高资源设置下表现优异，但在处理长尾文化实体和低资源语言时存在误解和性能不佳的问题。

Method: 利用维基数据知识图谱，收集代表具有文化意义的实体的图像，并生成合成的多语言视觉问答数据（CulturalGround数据集，包含2200万个视觉问答对，覆盖42个国家和39种语言）。在CulturalGround数据集上训练开源MLLM（CulturalPangea），并结合标准的法语指令调整数据以保持通用能力。

Result: CulturalPangea在多个以文化为中心的法语多模态基准测试中取得了最先进的性能，平均优于现有模型5.0个百分点，且未降低在主流视觉-语言任务上的表现。

Conclusion: 该研究提出的以数据为中心的方法，通过利用维基数据知识图谱收集代表具有文化意义的实体的图像，并生成合成的多语言视觉问答数据，有效解决了多模态大语言模型（MLLM）在高资源设置下表现优异，但在处理长尾文化实体和低资源语言时存在误解和性能不佳的问题。通过训练名为CulturalPangea的开源MLLM，并在包含2200万个高质量、文化丰富的视觉问答对（涵盖42个国家和39种语言）的数据集CulturalGround上进行训练，同时结合标准的法语指令调整数据以保持通用能力，CulturalPangea在多个以文化为中心的法语多模态基准测试中取得了最先进的性能，平均优于现有模型5.0个百分点，且未降低在主流视觉-语言任务上的表现。研究结果表明，这种有针对性的、以文化为基础的方法能够显著缩小MLLM在文化理解上的差距，为构建全球包容性的多模态系统提供了实际可行路径。

Abstract: Multimodal Large Language Models excel in high-resource settings, but often
misinterpret long-tail cultural entities and underperform in low-resource
languages. To address this gap, we propose a data-centric approach that
directly grounds MLLMs in cultural knowledge. Leveraging a large scale
knowledge graph from Wikidata, we collect images that represent culturally
significant entities, and generate synthetic multilingual visual question
answering data. The resulting dataset, CulturalGround, comprises 22 million
high-quality, culturally-rich VQA pairs spanning 42 countries and 39 languages.
We train an open-source MLLM CulturalPangea on CulturalGround, interleaving
standard multilingual instruction-tuning data to preserve general abilities.
CulturalPangea achieves state-of-the-art performance among open models on
various culture-focused multilingual multimodal benchmarks, outperforming prior
models by an average of 5.0 without degrading results on mainstream
vision-language tasks. Our findings show that our targeted, culturally grounded
approach could substantially narrow the cultural gap in MLLMs and offer a
practical path towards globally inclusive multimodal systems.

</details>


### [271] [Let's Revise Step-by-Step: A Unified Local Search Framework for Code Generation with LLMs](https://arxiv.org/abs/2508.07434)
*Zhiyi Lyu,Jianguo Huang,Yanchen Deng,Steven Hoi,Bo An*

Main category: cs.CL

TL;DR: ReLoc是一个统一的局部搜索框架，通过特定的算法组件和修订奖励模型来逐步进行代码修订，解决了LLMs代码生成中的效率和可扩展性挑战，并在各种代码生成任务中取得了优越的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型（LLMs）在代码生成中的效率和可扩展性挑战，以及现有方法（如基于构造的树搜索和基于改进的方法）的缺点。

Method: ReLoc是一个统一的局部搜索框架，通过四个关键的算法组件（初始代码起草、邻域代码生成、候选评估和初始代码更新）来逐步进行代码修订。它还开发了一个专门的修订奖励模型来指导局部搜索。

Result: ReLoc在各种代码生成任务中取得了优于基于构造的树搜索和最先进的基于改进的代码生成方法的性能。

Conclusion: ReLoc框架在代码生成任务中表现优于基于构造的树搜索和基于改进的方法，并在各种代码生成任务中实现了卓越的性能。

Abstract: Large Language Models (LLMs) with inference-time scaling techniques show
promise for code generation, yet face notable efficiency and scalability
challenges. Construction-based tree-search methods suffer from rapid growth in
tree size, high token consumption, and lack of anytime property. In contrast,
improvement-based methods offer better performance but often struggle with
uninformative reward signals and inefficient search strategies. In this work,
we propose \textbf{ReLoc}, a unified local search framework which effectively
performs step-by-step code revision. Specifically, ReLoc explores a series of
local revisions through four key algorithmic components: initial code drafting,
neighborhood code generation, candidate evaluation, and incumbent code
updating, each of which can be instantiated with specific decision rules to
realize different local search algorithms such as Hill Climbing (HC) or Genetic
Algorithm (GA). Furthermore, we develop a specialized revision reward model
that evaluates code quality based on revision distance to produce fine-grained
preferences that guide the local search toward more promising candidates.
Finally, our extensive experimental results demonstrate that our approach
achieves superior performance across diverse code generation tasks,
significantly outperforming both construction-based tree search as well as the
state-of-the-art improvement-based code generation methods.

</details>


### [272] [Positional Biases Shift as Inputs Approach Context Window Limits](https://arxiv.org/abs/2508.07479)
*Blerta Veseli,Julian Chibane,Mariya Toneva,Alexander Koller*

Main category: cs.CL

TL;DR: LLM处理长文本时，信息位置对模型表现的影响比先前认为的更复杂。‘中间迷失’效应并非普遍存在，而是取决于输入相对于模型上下文窗口的比例。当输入超过模型上下文窗口的50%时，模型更倾向于关注靠近末尾的信息，而非输入开头或中间的信息。此外，模型理解和推理信息的能力很大程度上取决于它能否成功地检索到相关信息。


<details>
  <summary>Details</summary>
Motivation: 探究长上下文研究中‘中间迷失’效应不一致的现象，以及该效应的强度和发生条件。

Method: 通过使用相对而非绝对输入长度（相对于模型的上下文窗口）进行全面分析，研究了‘中间迷失’效应在不同上下文窗口占用率下的表现。

Result: ‘中间迷失’效应在输入占用模型上下文窗口高达50%时最为强烈。当输入超过该比例时，首位偏好减弱，末位偏好保持相对稳定，‘中间迷失’效应被距离偏好取代，即信息越靠近输入末尾，模型表现越好。检索成功是LLM推理的基础，位置偏见主要来自检索。

Conclusion: LLM在处理长输入时，模型表现与信息位置的关系并非简单的首位偏好，而是存在距离偏好。当输入占模型上下文窗口的50%时，‘中间迷失’效应最为显著。超过这个阈值，首位偏好减弱，末位偏好保持稳定，‘中间迷失’效应消失，转而出现距离偏好，即信息越靠近输入末尾，模型表现越好。此外，检索的成功是LLM进行推理的前提，观察到的位置偏见很大程度上源于检索中的位置偏见。

Abstract: Large Language Models (LLMs) often struggle to use information across long
inputs effectively. Prior work has identified positional biases, such as the
Lost in the Middle (LiM) effect, where models perform better when information
appears at the beginning (primacy bias) or end (recency bias) of the input,
rather than in the middle. However, long-context studies have not consistently
replicated these effects, raising questions about their intensity and the
conditions under which they manifest. To address this, we conducted a
comprehensive analysis using relative rather than absolute input lengths,
defined with respect to each model's context window. Our findings reveal that
the LiM effect is strongest when inputs occupy up to 50% of a model's context
window. Beyond that, the primacy bias weakens, while recency bias remains
relatively stable. This effectively eliminates the LiM effect; instead, we
observe a distance-based bias, where model performance is better when relevant
information is closer to the end of the input. Furthermore, our results suggest
that successful retrieval is a prerequisite for reasoning in LLMs, and that the
observed positional biases in reasoning are largely inherited from retrieval.
These insights have implications for long-context tasks, the design of future
LLM benchmarks, and evaluation methodologies for LLMs handling extended inputs.

</details>


### [273] [ALOPE: Adaptive Layer Optimization for Translation Quality Estimation using Large Language Models](https://arxiv.org/abs/2508.07484)
*Archchana Sindhujan,Shenbin Qian,Chan Chi Chun Matthew,Constantin Orasan,Diptesh Kanojia*

Main category: cs.CL

TL;DR: ALOPE是一种用于机器翻译质量评估的自适应层优化框架，通过LoRA和回归任务头改进LLM的表示，提升了跨语言对齐和预测能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的机器翻译质量评估系统存在局限性，它们主要为因果语言建模而非回归任务进行预训练，在低资源语言场景下问题更为严重。

Method: ALOPE框架集成低秩适配（LoRA）和回归任务头，利用预训练Transformer层进行层级自适应，并通过动态加权和多头回归策略进一步优化。

Result: ALOPE框架在多个现有LLM驱动的机器翻译质量评估方法上均取得了改进，实验表明LLM的中间Transformer层提供了更符合质量评估任务跨语言特性的上下文表示。

Conclusion: ALOPE框架通过层级自适应重构Transformer表示，在机器翻译质量评估方面取得了显著进展，尤其是在低资源语言和跨语言对齐方面。

Abstract: Large Language Models (LLMs) have shown remarkable performance across a wide
range of natural language processing tasks. Quality Estimation (QE) for Machine
Translation (MT), which assesses the quality of a source-target pair without
relying on reference translations, remains a challenging cross-lingual task for
LLMs. The challenges stem from the inherent limitations of existing LLM-based
QE systems, which are pre-trained for causal language modelling rather than
regression-specific tasks, further elevated by the presence of low-resource
languages given pre-training data distribution. This paper introduces ALOPE, an
adaptive layer-optimization framework designed to enhance LLM-based QE by
restructuring Transformer representations through layer-wise adaptation for
improved regression-based prediction. Our framework integrates low-rank
adapters (LoRA) with regression task heads, leveraging selected pre-trained
Transformer layers for improved cross-lingual alignment. In addition to the
layer-specific adaptation, ALOPE introduces two strategies-dynamic weighting,
which adaptively combines representations from multiple layers, and multi-head
regression, which aggregates regression losses from multiple heads for QE. Our
framework shows improvements over various existing LLM-based QE approaches.
Empirical evidence suggests that intermediate Transformer layers in LLMs
provide contextual representations that are more aligned with the cross-lingual
nature of the QE task. We make resultant models and framework code publicly
available for further research, also allowing existing LLM-based MT frameworks
to be scaled with QE capabilities.

</details>


### [274] [Augmenting Bias Detection in LLMs Using Topological Data Analysis](https://arxiv.org/abs/2508.07516)
*Keshav Varadarajan,Tananun Songdechakraiwut*

Main category: cs.CL

TL;DR: 该研究提出了一种使用拓扑数据分析识别GPT-2模型中偏见来源的方法，发现偏见集中在特定的注意力头上，并提出了一种可用于量化和定位偏见的度量标准。


<details>
  <summary>Details</summary>
Motivation: 现有偏见检测方法大多只关注于检测大型语言模型中的偏见水平，而识别模型中具体哪些部分导致了对特定群体的偏见的方法仍不完善。

Method: 使用拓扑数据分析的方法来识别GPT-2中哪些注意力头导致了StereoSet数据集中存在的身份群体的错误表示。

Result: 研究发现，诸如性别或职业等特定类别的偏见集中在充当热点的注意力头上。

Conclusion: 该研究提出的度量标准可以用于确定哪些注意力头捕获了特定群体的偏见，并且未来的工作可以将此方法扩展到帮助消除大型语言模型的偏见。

Abstract: Recently, many bias detection methods have been proposed to determine the
level of bias a large language model captures. However, tests to identify which
parts of a large language model are responsible for bias towards specific
groups remain underdeveloped. In this study, we present a method using
topological data analysis to identify which heads in GPT-2 contribute to the
misrepresentation of identity groups present in the StereoSet dataset. We find
that biases for particular categories, such as gender or profession, are
concentrated in attention heads that act as hot spots. The metric we propose
can also be used to determine which heads capture bias for a specific group
within a bias category, and future work could extend this method to help
de-bias large language models.

</details>


### [275] [Word Clouds as Common Voices: LLM-Assisted Visualization of Participant-Weighted Themes in Qualitative Interviews](https://arxiv.org/abs/2508.07517)
*Joseph T. Colonel,Baihan Lin*

Main category: cs.CL

TL;DR: ThemeClouds利用LLM从对话记录中生成主题词云，克服了传统词云的局限性，提供了更具可操作性的见解。


<details>
  <summary>Details</summary>
Motivation: 传统的基于频率的词云方法在处理定性访谈时存在局限性，它们容易包含填充词、忽略释义，并打散语义相关的想法，这在需要快速、可解释地了解参与者实际所说内容的分析早期阶段，限制了其有效性。

Method: ThemeClouds是一个开源可视化工具，它利用大型语言模型（LLM）来处理对话记录。首先，系统提示LLM识别整个语料库中的概念级主题。随后，它计算提及每个主题的独特参与者数量。最终的词云可视化基于这种“提及广度”而非原始词频。研究人员可以自定义提示和可视化参数，以增强透明度和控制力。

Result: 与传统的词云、LDA和BERTopic等基线方法相比，ThemeClouds能更有效地揭示出可操作的设备相关问题。

Conclusion: ThemeClouds通过利用LLM识别对话记录中的主题并计算提及该主题的独特参与者数量，克服了传统词云在对话分析中的局限性。该工具生成的词云基于提及的广度而非原始词频，提供了更具可操作性的见解。研究结果表明，与基线方法相比，ThemeClouds能更有效地揭示设备相关的议题。此外，该工具允许研究人员自定义提示和可视化参数，增强了透明度和控制力，并为交互式分析（如“差异云”）开辟了道路。

Abstract: Word clouds are a common way to summarize qualitative interviews, yet
traditional frequency-based methods often fail in conversational contexts: they
surface filler words, ignore paraphrase, and fragment semantically related
ideas. This limits their usefulness in early-stage analysis, when researchers
need fast, interpretable overviews of what participant actually said. We
introduce ThemeClouds, an open-source visualization tool that uses large
language models (LLMs) to generate thematic, participant-weighted word clouds
from dialogue transcripts. The system prompts an LLM to identify concept-level
themes across a corpus and then counts how many unique participants mention
each topic, yielding a visualization grounded in breadth of mention rather than
raw term frequency. Researchers can customize prompts and visualization
parameters, providing transparency and control. Using interviews from a user
study comparing five recording-device configurations (31 participants; 155
transcripts, Whisper ASR), our approach surfaces more actionable device
concerns than frequency clouds and topic-modeling baselines (e.g., LDA,
BERTopic). We discuss design trade-offs for integrating LLM assistance into
qualitative workflows, implications for interpretability and researcher agency,
and opportunities for interactive analyses such as per-condition contrasts
(``diff clouds'').

</details>


### [276] [From Trial-and-Error to Improvement: A Systematic Analysis of LLM Exploration Mechanisms in RLVR](https://arxiv.org/abs/2508.07534)
*Jia Deng,Jie Chen,Zhipeng Chen,Daixuan Cheng,Fei Bai,Beichen Zhang,Yinqian Min,Yanzipeng Gao,Wayne Xin Zhao,Ji-Rong Wen*

Main category: cs.CL

TL;DR: RLVR 是一种用于增强 LLM 推理能力的范例，它依赖于有效的探索策略。该报告通过探索空间塑造、熵-性能交换和 RL 性能优化来系统地研究 RLVR 中的探索能力，旨在为推进 RLVR 系统提供一个基础框架。


<details>
  <summary>Details</summary>
Motivation: RLVR是一种利用基于规则的反馈来指导LLM生成和完善复杂推理链的范式，这种过程对有效的探索策略有关键依赖。然而，先前工作中RLVR的经验成功，LLM探索行为的基本机制仍然没有得到充分研究。

Method: 通过以下四个主要方面对RLVR中的探索能力进行了系统的研究：(1) 探索空间塑造，开发了量化指标来表征LLM的能力边界；(2) 熵-性能交换，分析了训练阶段、个体实例和 token 级模式；(3) RL 性能优化，检查了将探索收益转化为可衡量改进的有效方法。

Result: 该报告对RLVR中的探索能力进行了系统的调查。

Conclusion: 该报告提出了一个用于推进RLVR系统的基础框架，通过统一先前确定的见解和新的实证证据。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has emerged as a
powerful paradigm for enhancing the reasoning capabilities of large language
models (LLMs). Unlike traditional RL approaches, RLVR leverages rule-based
feedback to guide LLMs in generating and refining complex reasoning chains -- a
process critically dependent on effective exploration strategies. While prior
work has demonstrated RLVR's empirical success, the fundamental mechanisms
governing LLMs' exploration behaviors remain underexplored. This technical
report presents a systematic investigation of exploration capacities in RLVR,
covering four main aspects: (1) exploration space shaping, where we develop
quantitative metrics to characterize LLMs' capability boundaries; (2)
entropy-performance exchange, analyzed across training stages, individual
instances, and token-level patterns; and (3) RL performance optimization,
examining methods to effectively translate exploration gains into measurable
improvements. By unifying previously identified insights with new empirical
evidence, this work aims to provide a foundational framework for advancing RLVR
systems.

</details>


### [277] [IBPS: Indian Bail Prediction System](https://arxiv.org/abs/2508.07592)
*Puspesh Kumar Srivastava,Uddeshya Raj,Praveen Patel,/Shubham Kumar Nigam,Noel Shallum,Arnab Bhattacharya*

Main category: cs.CL

TL;DR: IBPS 是一个基于人工智能的框架，旨在通过预测结果和生成仅基于事实案例属性和法定规定的法律上合理的理由来协助保释决策。我们整理并发布了一个包含 150,430 个印度高等法院保释判决的大型数据集，并附有结构化注释，例如年龄、健康、犯罪历史、犯罪类别、羁押时间、法规和司法推理。


<details>
  <summary>Details</summary>
Motivation: 印度法院的保释决定虽然频繁，但仍受主观性、延误和不一致性的困扰。超过 75% 的印度监狱人口是未决囚犯，其中许多来自社会经济弱势群体，及时和公平的保释裁决的缺乏加剧了人权问题并导致了系统性的司法积压。

Method: 我们对一个大型语言模型进行了微调，使用了参数高效的技术，并在有和没有法定上下文以及使用 RAG 的情况下评估了其性能。

Result: 我们的结果表明，经过法定知识微调的模型明显优于基线，在准确性和解释质量方面表现出色，并且能够很好地泛化到由法律专家独立注释的测试集。

Conclusion: IBPS 是一个透明、可扩展且可重现的解决方案，旨在支持数据驱动的法律援助、减少保释延误并促进印度司法系统的程序公平。

Abstract: Bail decisions are among the most frequently adjudicated matters in Indian
courts, yet they remain plagued by subjectivity, delays, and inconsistencies.
With over 75% of India's prison population comprising undertrial prisoners,
many from socioeconomically disadvantaged backgrounds, the lack of timely and
fair bail adjudication exacerbates human rights concerns and contributes to
systemic judicial backlog. In this paper, we present the Indian Bail Prediction
System (IBPS), an AI-powered framework designed to assist in bail
decision-making by predicting outcomes and generating legally sound rationales
based solely on factual case attributes and statutory provisions. We curate and
release a large-scale dataset of 150,430 High Court bail judgments, enriched
with structured annotations such as age, health, criminal history, crime
category, custody duration, statutes, and judicial reasoning. We fine-tune a
large language model using parameter-efficient techniques and evaluate its
performance across multiple configurations, with and without statutory context,
and with RAG. Our results demonstrate that models fine-tuned with statutory
knowledge significantly outperform baselines, achieving strong accuracy and
explanation quality, and generalize well to a test set independently annotated
by legal experts. IBPS offers a transparent, scalable, and reproducible
solution to support data-driven legal assistance, reduce bail delays, and
promote procedural fairness in the Indian judicial system.

</details>


### [278] [Keyword-Centric Prompting for One-Shot Event Detection with Self-Generated Rationale Enhancements](https://arxiv.org/abs/2508.07598)
*Ziheng Li,Zhi-Hong Deng*

Main category: cs.CL

TL;DR: KeyCP++通过关键词和思维链提示改进了LLM在事件检测中的表现，尤其是在one-shot场景下。


<details>
  <summary>Details</summary>
Motivation: LLM在事件检测方面存在对事件触发词理解不准确和过度解释的问题，仅靠上下文示例难以纠正。

Method: KeyCP++是一种关键词驱动的思维链提示方法，通过自动标注演示中的逻辑差距，并结合触发词歧义提示模板，让LLM提出并论证候选触发词，从而弥补了传统ICL的不足，有助于LLM学习检测规则。

Result: 提出的KeyCP++在one-shot事件检测任务上表现出色，取得了显著的性能提升。

Conclusion: KeyCP++在one-shot事件检测方面取得了显著的进步。

Abstract: Although the LLM-based in-context learning (ICL) paradigm has demonstrated
considerable success across various natural language processing tasks, it
encounters challenges in event detection. This is because LLMs lack an accurate
understanding of event triggers and tend to make over-interpretation, which
cannot be effectively corrected through in-context examples alone. In this
paper, we focus on the most challenging one-shot setting and propose KeyCP++, a
keyword-centric chain-of-thought prompting approach. KeyCP++ addresses the
weaknesses of conventional ICL by automatically annotating the logical gaps
between input text and detection results for the demonstrations. Specifically,
to generate in-depth and meaningful rationale, KeyCP++ constructs a trigger
discrimination prompting template. It incorporates the exemplary triggers
(a.k.a keywords) into the prompt as the anchor to simply trigger profiling, let
LLM propose candidate triggers, and justify each candidate. These
propose-and-judge rationales help LLMs mitigate over-reliance on the keywords
and promote detection rule learning. Extensive experiments demonstrate the
effectiveness of our approach, showcasing significant advancements in one-shot
event detection.

</details>


### [279] [InterChart: Benchmarking Visual Reasoning Across Decomposed and Distributed Chart Information](https://arxiv.org/abs/2508.07630)
*Anirudh Iyengar Kaniyar Narayana Iyengar,Srija Mukhopadhyay,Adnan Qidwai,Shubhankar Singh,Dan Roth,Vivek Gupta*

Main category: cs.CL

TL;DR: InterChart 是一个评估视觉语言模型 (VLMs) 在多个相关图表上推理能力的基准。它包含不同类型的问题和三个难度级别。评估显示，当前模型在处理复杂、多图表场景时存在困难，准确率会随着图表复杂性的增加而下降。该基准旨在推动模型在多模态推理能力上的发展。


<details>
  <summary>Details</summary>
Motivation: 在现实世界的应用中，如科学报告、金融分析和公共政策仪表盘等，视觉语言模型 (VLMs) 需要能够推理多个相关图表。然而，现有的基准主要关注孤立的、视觉上均匀的图表，无法充分评估模型在处理复杂、多图表场景中的能力。

Method: 该研究引入了一个名为 InterChart 的诊断基准，该基准专注于评估视觉语言模型 (VLMs) 在推理跨多个相关图表方面的能力。该基准包含一系列不同类型的问题，旨在测试模型在处理多个图表时的综合推理能力，包括实体推断、趋势相关性、数值估计和抽象的多步推理。基准被组织成三个难度递增的级别：(1) 针对单个图表的事实推理；(2) 跨合成对齐图表集的综合分析；(3) 针对视觉复杂、真实世界图表对的语义推断。

Result: 评估结果显示，随着图表复杂性的增加，最先进的开源和闭源 VLMs 的准确率一致且急剧下降。研究发现，当将多实体图表分解为更简单的视觉单元时，模型表现更好，这表明它们在跨图表整合方面存在困难。InterChart 通过揭示这些系统性的局限性，为在复杂的多视觉环境中推进多模态推理提供了严格的框架。

Conclusion: InterChart 是一个诊断基准，用于评估视觉语言模型 (VLMs) 在多个相关图表之间的推理能力。该基准包含不同类型的问题，涵盖实体推断、趋势相关性、数值估计和抽象的多步推理。它分为三个难度级别：(1) 对单个图表的事实推理，(2) 在合成对齐图表集中的综合分析，(3) 在视觉复杂、真实世界图表对上的语义推断。

Abstract: We introduce InterChart, a diagnostic benchmark that evaluates how well
vision-language models (VLMs) reason across multiple related charts, a task
central to real-world applications such as scientific reporting, financial
analysis, and public policy dashboards. Unlike prior benchmarks focusing on
isolated, visually uniform charts, InterChart challenges models with diverse
question types ranging from entity inference and trend correlation to numerical
estimation and abstract multi-step reasoning grounded in 2-3 thematically or
structurally related charts. We organize the benchmark into three tiers of
increasing difficulty: (1) factual reasoning over individual charts, (2)
integrative analysis across synthetically aligned chart sets, and (3) semantic
inference over visually complex, real-world chart pairs. Our evaluation of
state-of-the-art open and closed-source VLMs reveals consistent and steep
accuracy declines as chart complexity increases. We find that models perform
better when we decompose multi-entity charts into simpler visual units,
underscoring their struggles with cross-chart integration. By exposing these
systematic limitations, InterChart provides a rigorous framework for advancing
multimodal reasoning in complex, multi-visual environments.

</details>


### [280] [LoSemB: Logic-Guided Semantic Bridging for Inductive Tool Retrieval](https://arxiv.org/abs/2508.07690)
*Luyao Zhuang,Qinggang Zhang,Huachi Zhou,Juhua Liu,Qing Li,Xiao Huang*

Main category: cs.CL

TL;DR: LoSemB是一个创新的框架，通过挖掘和转移潜在的逻辑信息，解决了大型语言模型（LLMs）在面对不断增长的工具库时，如何有效检索和使用未见工具的挑战，尤其是在归纳学习的场景下。


<details>
  <summary>Details</summary>
Motivation: 为了解决工具库不断扩大而LLMs输入长度有限的问题，同时克服现有方法在处理未见工具时存在的分布变化和基于相似性的检索脆弱性问题。

Method: LoSemB框架包含一个基于逻辑的嵌入对齐模块来减轻分布变化，并实现了一个关系增强检索机制来减少基于相似性的检索的脆弱性。

Result: 实验证明LoSemB在归纳设置下取得了先进的性能，并在转换设置下保持了良好的有效性。

Conclusion: LoSemB框架在归纳设置下实现了先进的性能，同时在转换设置下保持了理想的有效性。

Abstract: Tool learning has emerged as a promising paradigm for large language models
(LLMs) to solve many real-world tasks. Nonetheless, with the tool repository
rapidly expanding, it is impractical to contain all tools within the limited
input length of LLMs. To alleviate these issues, researchers have explored
incorporating a tool retrieval module to select the most relevant tools or
represent tools as unique tokens within LLM parameters. However, most
state-of-the-art methods are under transductive settings, assuming all tools
have been observed during training. Such a setting deviates from reality as the
real-world tool repository is evolving and incorporates new tools frequently.
When dealing with these unseen tools, which refer to tools not encountered
during the training phase, these methods are limited by two key issues,
including the large distribution shift and the vulnerability of
similarity-based retrieval. To this end, inspired by human cognitive processes
of mastering unseen tools through discovering and applying the logical
information from prior experience, we introduce a novel Logic-Guided Semantic
Bridging framework for inductive tool retrieval, namely, LoSemB, which aims to
mine and transfer latent logical information for inductive tool retrieval
without costly retraining. Specifically, LoSemB contains a logic-based
embedding alignment module to mitigate distribution shifts and implements a
relational augmented retrieval mechanism to reduce the vulnerability of
similarity-based retrieval. Extensive experiments demonstrate that LoSemB
achieves advanced performance in inductive settings while maintaining desirable
effectiveness in the transductive setting.

</details>


### [281] [What am I missing here?: Evaluating Large Language Models for Masked Sentence Prediction](https://arxiv.org/abs/2508.07702)
*Charlie Wyatt,Aditya Joshi,Flora Salim*

Main category: cs.CL

TL;DR: 研究显示，尽管LLM在许多任务上表现出色，但在预测被移除的句子（MSP任务）时，尤其是在故事和食谱等非结构化文本中，表现不佳，这暴露了它们在长文本连贯性方面的潜在弱点。


<details>
  <summary>Details</summary>
Motivation: 尽管基于Transformer的模型在下一词预测（NTP）任务上表现出色，但NTP侧重于单词级别的预测，可能限制了模型在长距离连贯性方面的能力。本研究旨在探讨LLM在预测更长文本（如结构化文档中的完整句子）方面的能力，特别是评估它们在句子级别的预测和保持全局连贯性方面的表现，这对于需要重构或论述的任务至关重要。

Method: 本研究评估了三种商用LLM（GPT-4o、Claude 3.5 Sonnet和Gemini 2.0 Flash）在掩码句子预测（MSP）任务上的表现，该任务旨在填充从三个领域（ROCStories、Recipe1M和Wikipedia）中随机移除的句子。研究评估了模型预测的句子的保真度（与原始句子的相似性）和内聚性（与周围上下文的契合度）。

Result: 研究发现，在低结构化领域（如ROCStories和Recipe1M），商业LLM在MSP任务上的表现不佳，表明它们在保持句子间的连贯性和准确性方面存在不足。

Conclusion: 现有的大型语言模型（LLM）在掩码句子预测（MSP）任务上表现不佳，尤其是在低结构化领域，这表明它们在生成连贯的长文本方面存在局限性。

Abstract: Transformer-based models primarily rely on Next Token Prediction (NTP), which
predicts the next token in a sequence based on the preceding context. However,
NTP's focus on single-token prediction often limits a model's ability to plan
ahead or maintain long-range coherence, raising questions about how well LLMs
can predict longer contexts, such as full sentences within structured
documents. While NTP encourages local fluency, it provides no explicit
incentive to ensure global coherence across sentence boundaries-an essential
skill for reconstructive or discursive tasks. To investigate this, we evaluate
three commercial LLMs (GPT-4o, Claude 3.5 Sonnet, and Gemini 2.0 Flash) on
Masked Sentence Prediction (MSP) - the task of infilling a randomly removed
sentence - from three domains: ROCStories (narrative), Recipe1M (procedural),
and Wikipedia (expository). We assess both fidelity (similarity to the original
sentence) and cohesiveness (fit within the surrounding context). Our key
finding reveals that commercial LLMs, despite their superlative performance in
other tasks, are poor at predicting masked sentences in low-structured domains,
highlighting a gap in current model capabilities.

</details>


### [282] [Exploring Causal Effect of Social Bias on Faithfulness Hallucinations in Large Language Models](https://arxiv.org/abs/2508.07753)
*Zhenliang Zhang,Junzhe Zhang,Xinyu Hu,HuiXuan Zhang,Xiaojun Wan*

Main category: cs.CL

TL;DR: 研究利用结构因果模型和偏见干预数据集（BID），证明社会偏见是导致大型语言模型（LLMs）产生忠实性幻觉（特别是“不公平幻觉”）的重要原因，且不同偏见的影响方向不同。


<details>
  <summary>Details</summary>
Motivation: 旨在探究社会偏见是否会导致大型语言模型（LLMs）产生忠实性幻觉，以及这种因果关系是否从未被探索过。

Method: 利用结构因果模型（SCM）建立和验证因果关系，并通过设计偏见干预措施来控制混淆变量。此外，研究者还开发了包含各种社会偏见的偏见干预数据集（BID），以便精确测量因果效应。

Result: 实验结果证实，偏见是导致忠实性幻觉的重要原因，并且不同偏见状态的影响方向各不相同。研究还分析了这些因果效应在不同模型中的范围，特别是针对主要由社会偏见引起的“不公平幻觉”，揭示了偏见对幻觉产生的微妙但显著的因果影响。

Conclusion: 研究结果表明，社会偏见是导致大型语言模型（LLMs）产生忠实性幻觉的重要原因，并且不同偏见状态的影响方向和程度各不相同。

Abstract: Large language models (LLMs) have achieved remarkable success in various
tasks, yet they remain vulnerable to faithfulness hallucinations, where the
output does not align with the input. In this study, we investigate whether
social bias contributes to these hallucinations, a causal relationship that has
not been explored. A key challenge is controlling confounders within the
context, which complicates the isolation of causality between bias states and
hallucinations. To address this, we utilize the Structural Causal Model (SCM)
to establish and validate the causality and design bias interventions to
control confounders. In addition, we develop the Bias Intervention Dataset
(BID), which includes various social biases, enabling precise measurement of
causal effects. Experiments on mainstream LLMs reveal that biases are
significant causes of faithfulness hallucinations, and the effect of each bias
state differs in direction. We further analyze the scope of these causal
effects across various models, specifically focusing on unfairness
hallucinations, which are primarily targeted by social bias, revealing the
subtle yet significant causal effect of bias on hallucination generation.

</details>


### [283] [SASST: Leveraging Syntax-Aware Chunking and LLMs for Simultaneous Speech Translation](https://arxiv.org/abs/2508.07781)
*Zeyu Yang,Lai Wei,Roman Koshkin,Xi Chen,Satoshi Nakamura*

Main category: cs.CL

TL;DR: SASST利用语法分块策略和集成的Whisper编码器及LLM，改进了同时语音翻译的质量和效率。


<details>
  <summary>Details</summary>
Motivation: 旨在提高同时语音翻译（SimulST）的质量和效率，通过引入语法信息来优化翻译过程。

Method: 提出了一种基于语法的分块策略，通过解析依赖关系（如名词短语边界、动词-宾语结构）和标点符号特征来分割输入流为语义完整的单元，确保了分块的连贯性并最大限度地减少了语义碎片化。在此机制的基础上，提出了SASST（Syntax-Aware Simultaneous Speech Translation），一个集成了冻结的Whisper编码器和仅解码器的LLM的端到端框架。该统一架构动态地输出翻译词元或<WAIT>符号，以联合优化翻译时间和内容，并通过目标侧重排序来解决词序差异。针对CoVoST2多语言语料库（英-德、英-中、英-日）进行的实验证明了跨语言翻译质量的显著提高，并验证了语法结构在LLM驱动的同时语音翻译系统中的有效性。

Result: 实验证明，SASST在多个语言对上显著提高了翻译质量，并验证了语法结构在LLM驱动的SimulST系统中的有效性。

Conclusion: SASST通过整合冻结的Whisper编码器和仅解码器的LLM，提出了一种语法驱动的同时语音翻译框架，该框架动态输出翻译词元或<WAIT>符号，以联合优化翻译时间和内容。

Abstract: This work proposes a grammar-based chunking strategy that segments input
streams into semantically complete units by parsing dependency relations (e.g.,
noun phrase boundaries, verb-object structures) and punctuation features. The
method ensures chunk coherence and minimizes semantic fragmentation. Building
on this mechanism, we present SASST (Syntax-Aware Simultaneous Speech
Translation), an end-to-end framework integrating frozen Whisper encoder and
decoder-only LLM. The unified architecture dynamically outputs translation
tokens or <WAIT> symbols to jointly optimize translation timing and content,
with target-side reordering addressing word-order divergence. Experiments on
CoVoST2 multilingual corpus En-{De, Zh, Ja} demonstrate significant translation
quality improvements across languages and validate the effectiveness of
syntactic structures in LLM-driven SimulST systems.

</details>


### [284] [Grove MoE: Towards Efficient and Superior MoE LLMs with Adjugate Experts](https://arxiv.org/abs/2508.07785)
*Haoyuan Wu,Haoxing Chen,Xiaodong Chen,Zhanchao Zhou,Tieyuan Chen,Yihong Zhuang,Guoshan Lu,Zenan Huang,Junbo Zhao,Lin Liu,Zhenzhong Lan,Bei Yu,Jianguo Li*

Main category: cs.CL

TL;DR: Grove MoE通过异构专家和动态激活解决了传统MoE效率问题，在与SOTA模型相当的性能下实现了高效扩展。


<details>
  <summary>Details</summary>
Motivation: 传统的Mixture of Experts (MoE)架构使用同质的、固定大小的专家，无论输入复杂性如何都会激活固定数量的参数，这限制了计算效率。为了克服这一限制，提出Grove MoE架构，以异构的、不同大小的专家来提高计算效率。

Method: 提出了一种名为Grove MoE的新型架构，该架构包含不同大小的专家，并引入了具有动态激活机制的新型adjugate专家。利用这种架构，通过在中期训练和训练后对Qwen3-30B-A3B-Base模型进行升级，开发了33B参数的GroveMoE-Base和GroveMoE-Inst模型。

Result: GroveMoE模型根据token的复杂性动态激活3.14-3.28B参数，性能与同等或更大规模的SOTA开源模型相当。

Conclusion: GroveMoE模型通过引入异构专家和动态激活机制，在保持可控计算开销的同时实现了模型容量的扩展，并达到了与同等规模甚至更大规模SOTA模型的性能相当的水平。

Abstract: The Mixture of Experts (MoE) architecture is a cornerstone of modern
state-of-the-art (SOTA) large language models (LLMs). MoE models facilitate
scalability by enabling sparse parameter activation. However, traditional MoE
architecture uses homogeneous experts of a uniform size, activating a fixed
number of parameters irrespective of input complexity and thus limiting
computational efficiency. To overcome this limitation, we introduce Grove MoE,
a novel architecture incorporating experts of varying sizes, inspired by the
heterogeneous big.LITTLE CPU architecture. This architecture features novel
adjugate experts with a dynamic activation mechanism, enabling model capacity
expansion while maintaining manageable computational overhead. Building on this
architecture, we present GroveMoE-Base and GroveMoE-Inst, 33B-parameter LLMs
developed by applying an upcycling strategy to the Qwen3-30B-A3B-Base model
during mid-training and post-training. GroveMoE models dynamically activate
3.14-3.28B parameters based on token complexity and achieve performance
comparable to SOTA open-source models of similar or even larger size.

</details>


### [285] [Can You Trick the Grader? Adversarial Persuasion of LLM Judges](https://arxiv.org/abs/2508.07805)
*Yerin Hwang,Dongryeol Lee,Taegwan Kang,Yongil Kim,Kyomin Jung*

Main category: cs.CL

TL;DR: 即使是AI法官，也可能被花言巧语所蒙蔽。研究发现，在数学评分中加入“劝说性语言”能提高不正确答案的得分，尤其是“一致性”技巧效果显著。模型越大越没用，越多技巧越糟糕。AI法官需要加强自身“免疫力”。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在实际应用中扮演的自动评估角色日益重要，研究其是否会被不公平地影响评分至关重要，特别是当评分应与风格无关时。

Method: 本研究提出了七种基于亚里士多德修辞学原理的劝说技巧（多数、一致性、奉承、互惠、同情、权威、身份认同），并将其嵌入到数学推理任务的回答中，用于测试LLM评分者。

Result: 在六个数学基准测试中，劝说性语言能使LLM评分者对不正确的答案给出更高的分数，平均高出8%。其中“一致性”技巧造成的偏差最大。模型规模的增大和成对评估均未能有效减轻此问题。结合多种劝说技巧会放大偏差，且对抗性提示也无法消除影响。

Conclusion: 本研究首次揭示了在数学推理任务中，策略性嵌入的劝说性语言会影响LLM评分者的判断，导致评分不公平。这种影响在多种数学基准测试中均有体现，平均会使不正确答案的评分提高8%，其中“一致性”技巧造成的扭曲最为严重。增加模型规模并未显著缓解此漏洞。此外，结合多种劝说技巧会加剧偏差，成对评估也未能幸免。即使在对抗性提示策略下，劝说效应依然存在，这表明LLM作为评估者的流程存在严重漏洞，亟需开发针对劝说攻击的鲁棒防御机制。

Abstract: As large language models take on growing roles as automated evaluators in
practical settings, a critical question arises: Can individuals persuade an LLM
judge to assign unfairly high scores? This study is the first to reveal that
strategically embedded persuasive language can bias LLM judges when scoring
mathematical reasoning tasks, where correctness should be independent of
stylistic variation. Grounded in Aristotle's rhetorical principles, we
formalize seven persuasion techniques (Majority, Consistency, Flattery,
Reciprocity, Pity, Authority, Identity) and embed them into otherwise identical
responses. Across six math benchmarks, we find that persuasive language leads
LLM judges to assign inflated scores to incorrect solutions, by up to 8% on
average, with Consistency causing the most severe distortion. Notably,
increasing model size does not substantially mitigate this vulnerability.
Further analysis demonstrates that combining multiple persuasion techniques
amplifies the bias, and pairwise evaluation is likewise susceptible. Moreover,
the persuasive effect persists under counter prompting strategies, highlighting
a critical vulnerability in LLM-as-a-Judge pipelines and underscoring the need
for robust defenses against persuasion-based attacks.

</details>


### [286] [Evaluating Compositional Approaches for Focus and Sentiment Analysis](https://arxiv.org/abs/2508.07810)
*Olga Kellert,Muhammad Imran,Nicholas Hill Matlis,Mahmud Uz Zaman,Carlos Gómez-Rodríguez*

Main category: cs.CL

TL;DR: 本研究提出了一种用于焦点分析（FA）的组合方法，并证明了其在情感分析（SA）中的有效性。与现有方法相比，该方法具有更好的可解释性和可解释性，并填补了焦点分析（FA）量化评估的空白。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是填补焦点分析（FA）在语言学领域缺乏量化评估的空白，并论证情感分析（FA）中的组合规则同样适用于焦点分析（FA），因为两者密切相关，情感分析（SA）是焦点分析（FA）的一部分。

Method: 该研究采用一种组合方法，利用通用依存关系（UDs）中的基本句法规则（如修饰、协调和否定）来分析英文文本，并将其应用于情感词汇。所提出的组合方法与非组合方法 VADER 进行了准确性比较，并使用了更合适的数据集进行评估。

Result: 研究结果表明，所提出的组合方法在准确性方面与非组合方法 VADER 相当，并且在处理否定、协调和修饰等句法现象时，比 VADER 等启发式规则方法更具可解释性和可解释性。此外，该研究还证明了将情感分析（SA）中的组合方法推广到焦点分析（FA）是可行的。

Conclusion: 这项工作通过将量化评估从情感分析（SA）推广到焦点分析（FA），弥补了焦点分析（FA）研究中的空白。研究结果表明，在情感分析（SA）中有效的组合方法也适用于焦点分析（FA）。

Abstract: This paper summarizes the results of evaluating a compositional approach for
Focus Analysis (FA) in Linguistics and Sentiment Analysis (SA) in Natural
Language Processing (NLP). While quantitative evaluations of compositional and
non-compositional approaches in SA exist in NLP, similar quantitative
evaluations are very rare in FA in Linguistics that deal with linguistic
expressions representing focus or emphasis such as "it was John who left". We
fill this gap in research by arguing that compositional rules in SA also apply
to FA because FA and SA are closely related meaning that SA is part of FA. Our
compositional approach in SA exploits basic syntactic rules such as rules of
modification, coordination, and negation represented in the formalism of
Universal Dependencies (UDs) in English and applied to words representing
sentiments from sentiment dictionaries. Some of the advantages of our
compositional analysis method for SA in contrast to non-compositional analysis
methods are interpretability and explainability. We test the accuracy of our
compositional approach and compare it with a non-compositional approach VADER
that uses simple heuristic rules to deal with negation, coordination and
modification. In contrast to previous related work that evaluates
compositionality in SA on long reviews, this study uses more appropriate
datasets to evaluate compositionality. In addition, we generalize the results
of compositional approaches in SA to compositional approaches in FA.

</details>


### [287] [Evaluating Large Language Models as Expert Annotators](https://arxiv.org/abs/2508.07827)
*Yu-Min Tseng,Wei-Lin Chen,Chung-Chi Chen,Hsin-Hsi Chen*

Main category: cs.CL

TL;DR: 本文研究了 LLM 在金融、生物医学和法律等专业领域的文本标注能力。结果发现，单独的 LLM（即使使用 CoT 等技术）效果有限，推理模型也没有带来显著提升。多主体讨论中，Claude 3.7 Sonnet 也很少修正其初始标注。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨顶尖 LLM 是否能直接替代人类专家标注员，特别是在需要专家知识的专业领域文本数据标注方面，尽管 LLM 在通用领域已显示出其潜力。

Method: 本文评估了单个 LLM 和多主体方法在金融、生物医学和法律三个高度专业化领域的表现。具体而言，我们提出了一种多主体讨论框架，模拟一群人类标注员，让 LLM 在最终确定标签前，通过考虑他人的标注和理由来进行讨论。此外，我们还引入了推理模型（例如 o3-mini）以实现更全面的比较。

Result: 1. 采用推理技术（如思维链、自洽）的 LLM 在专业领域文本标注上的表现仅有边际改进或负向增益。
2. 推理模型在大多数情况下并未比非推理模型表现出统计学上的显著改进。
3. 在多主体讨论环境中，观察到 Claude 3.7 Sonnet（开启思考功能后）即使在其他标注员提供正确标注或有效推理时，也极少改变其初始标注。

Conclusion: 在专业领域，单独的 LLM（即使采用思维链或自洽等推理技术）在文本标注方面的表现仅有边际改进，甚至可能下降。此外，与非推理模型相比，推理模型并未在大多数情况下带来显著的统计学改进，这表明长推理链对专业领域的数据标注效益有限。在多主体讨论环境中，观察到了一些特定的模型行为，例如，Claude 3.7 Sonnet（在开启思考功能时）在面对其他模型提供正确标注或有效推理时，很少改变其初始标注。

Abstract: Textual data annotation, the process of labeling or tagging text with
relevant information, is typically costly, time-consuming, and labor-intensive.
While large language models (LLMs) have demonstrated their potential as direct
alternatives to human annotators for general domains natural language
processing (NLP) tasks, their effectiveness on annotation tasks in domains
requiring expert knowledge remains underexplored. In this paper, we
investigate: whether top-performing LLMs, which might be perceived as having
expert-level proficiency in academic and professional benchmarks, can serve as
direct alternatives to human expert annotators? To this end, we evaluate both
individual LLMs and multi-agent approaches across three highly specialized
domains: finance, biomedicine, and law. Specifically, we propose a multi-agent
discussion framework to simulate a group of human annotators, where LLMs are
tasked to engage in discussions by considering others' annotations and
justifications before finalizing their labels. Additionally, we incorporate
reasoning models (e.g., o3-mini) to enable a more comprehensive comparison. Our
empirical results reveal that: (1) Individual LLMs equipped with inference-time
techniques (e.g., chain-of-thought (CoT), self-consistency) show only marginal
or even negative performance gains, contrary to prior literature suggesting
their broad effectiveness. (2) Overall, reasoning models do not demonstrate
statistically significant improvements over non-reasoning models in most
settings. This suggests that extended long CoT provides relatively limited
benefits for data annotation in specialized domains. (3) Certain model
behaviors emerge in the multi-agent discussion environment. For instance,
Claude 3.7 Sonnet with thinking rarely changes its initial annotations, even
when other agents provide correct annotations or valid reasoning.

</details>


### [288] [LLMs for Law: Evaluating Legal-Specific LLMs on Contract Understanding](https://arxiv.org/abs/2508.07849)
*Amrita Singh,H. Suhan Karaca,Aditya Joshi,Hye-young Paik,Jiaojiao Jiang*

Main category: cs.CL

TL;DR: 法律领域专用语言模型在合同理解任务上优于通用语言模型，并在两项任务上达到新的SOTA。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏涵盖多个法律领域专用语言模型的、针对合同分类任务的全面评估。

Method: 通过评估10个法律领域专用语言模型和7个通用语言模型来完成三项英语合同理解任务。

Result: 法律领域专用语言模型在合同理解任务上优于通用语言模型，Legal-BERT和Contracts-BERT在两项任务上达到新的SOTA。

Conclusion: 研究结果表明，法律领域专用语言模型在合同理解任务上始终优于通用语言模型，尤其是在需要细致法律理解的任务上。Legal-BERT和Contracts-BERT在三个任务中的两个任务上确立了新的SOTA（State-of-the-Art），尽管它们的参数量比表现最佳的通用语言模型少69%。此外，CaseLaw-BERT和LexLM也被确定为合同理解的有力基线。

Abstract: Despite advances in legal NLP, no comprehensive evaluation covering multiple
legal-specific LLMs currently exists for contract classification tasks in
contract understanding. To address this gap, we present an evaluation of 10
legal-specific LLMs on three English language contract understanding tasks and
compare them with 7 general-purpose LLMs. The results show that legal-specific
LLMs consistently outperform general-purpose models, especially on tasks
requiring nuanced legal understanding. Legal-BERT and Contracts-BERT establish
new SOTAs on two of the three tasks, despite having 69% fewer parameters than
the best-performing general-purpose LLM. We also identify CaseLaw-BERT and
LexLM as strong additional baselines for contract understanding. Our results
provide a holistic evaluation of legal-specific LLMs and will facilitate the
development of more accurate contract understanding systems.

</details>


### [289] [Large Language Models for Czech Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2508.07860)
*Jakub Šmíd,Pavel Přibáň,Pavel Král*

Main category: cs.CL

TL;DR: 本研究评估了19种LLM在捷克方面基础情感分析（ABSA）任务上的表现。结果显示，虽然微调后的LLM取得了最先进的结果，但针对ABSA微调的小型领域特定模型在零样本和少样本场景下优于通用LLM。研究还分析了影响性能的因素，并指出了方面词预测中的挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在各种NLP任务中表现强劲，但它们在捷克ABSA方面的能力仍未得到充分探索。

Method: 本研究对19种不同大小和架构的LLM在零样本、少样本和微调场景下进行了全面的捷克ABSA性能评估。

Result: 研究表明，针对ABSA进行微调的小型领域特定模型在零样本和少样本设置中优于通用LLM，而微调后的LLM取得了最先进的结果。同时，分析了多语言、模型大小和时新性等因素对性能的影响，并进行了错误分析，强调了方面词预测方面的挑战。

Conclusion: 研究结果为理解LLM在捷克ABSA任务中的适用性提供了见解，并为该领域的未来研究提供了指导。

Abstract: Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis
task that aims to identify sentiment toward specific aspects of an entity.
While large language models (LLMs) have shown strong performance in various
natural language processing (NLP) tasks, their capabilities for Czech ABSA
remain largely unexplored. In this work, we conduct a comprehensive evaluation
of 19 LLMs of varying sizes and architectures on Czech ABSA, comparing their
performance in zero-shot, few-shot, and fine-tuning scenarios. Our results show
that small domain-specific models fine-tuned for ABSA outperform
general-purpose LLMs in zero-shot and few-shot settings, while fine-tuned LLMs
achieve state-of-the-art results. We analyze how factors such as
multilingualism, model size, and recency influence performance and present an
error analysis highlighting key challenges, particularly in aspect term
prediction. Our findings provide insights into the suitability of LLMs for
Czech ABSA and offer guidance for future research in this area.

</details>


### [290] [Few-shot Cross-lingual Aspect-Based Sentiment Analysis with Sequence-to-Sequence Models](https://arxiv.org/abs/2508.07866)
*Jakub Šmíd,Pavel Přibáň,Pavel Král*

Main category: cs.CL

TL;DR: “在低资源语言中，向跨语言方面基于情感分析的训练集中添加少量目标语言示例可以显著提高性能。”


<details>
  <summary>Details</summary>
Motivation: “目前跨语言方面基于情感分析的方法通常依赖外部翻译工具，并且忽视了在训练中结合少量目标语言示例的潜在益处，尤其是在标签数据稀疏的低资源语言中。”

Method: “本文评估了在四种方面基于情感分析任务、六种目标语言和两种序列到序列模型中，向训练集中添加少样本目标语言示例的效果。”

Result: “研究表明，添加仅十个目标语言示例即可显著提高性能，其效果与约束解码在减少预测错误方面相似。此外，研究还证明，结合1000个目标语言示例和英语数据可以超越单一语言基线。”

Conclusion: “少量目标语言示例可显著提高跨语言方面基于情感分析的性能，并能有效减少预测错误。结合1000个目标语言示例和英语数据甚至可以超越单一语言基线。”

Abstract: Aspect-based sentiment analysis (ABSA) has received substantial attention in
English, yet challenges remain for low-resource languages due to the scarcity
of labelled data. Current cross-lingual ABSA approaches often rely on external
translation tools and overlook the potential benefits of incorporating a small
number of target language examples into training. In this paper, we evaluate
the effect of adding few-shot target language examples to the training set
across four ABSA tasks, six target languages, and two sequence-to-sequence
models. We show that adding as few as ten target language examples
significantly improves performance over zero-shot settings and achieves a
similar effect to constrained decoding in reducing prediction errors.
Furthermore, we demonstrate that combining 1,000 target language examples with
English data can even surpass monolingual baselines. These findings offer
practical insights for improving cross-lingual ABSA in low-resource and
domain-specific settings, as obtaining ten high-quality annotated examples is
both feasible and highly effective.

</details>


### [291] [Tailored Emotional LLM-Supporter: Enhancing Cultural Sensitivity](https://arxiv.org/abs/2508.07902)
*Chen Cecilia Liu,Hiba Arnaout,Nils Kovačić,Dana Atzil-Slonim,Iryna Gurevych*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large language models (LLMs) show promise in offering emotional support and
generating empathetic responses for individuals in distress, but their ability
to deliver culturally sensitive support remains underexplored due to lack of
resources. In this work, we introduce CultureCare, the first dataset designed
for this task, spanning four cultures and including 1729 distress messages,
1523 cultural signals, and 1041 support strategies with fine-grained emotional
and cultural annotations. Leveraging CultureCare, we (i) develop and test four
adaptation strategies for guiding three state-of-the-art LLMs toward culturally
sensitive responses; (ii) conduct comprehensive evaluations using LLM judges,
in-culture human annotators, and clinical psychologists; (iii) show that
adapted LLMs outperform anonymous online peer responses, and that simple
cultural role-play is insufficient for cultural sensitivity; and (iv) explore
the application of LLMs in clinical training, where experts highlight their
potential in fostering cultural competence in future therapists.

</details>


### [292] [Challenges and opportunities in portraying emotion in generated sign language](https://arxiv.org/abs/2508.07937)
*John C. McDonald,Rosalee Wolfe,Fabrizio Nunnari*

Main category: cs.CL

TL;DR: This paper introduces a new way to make signing avatars express emotions using two simple numbers, making them more realistic and easier to control through a system called EASIER notation.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the challenge of incorporating emotional content into signing avatars due to the lack of a standard method for specifying their emotional state, aiming to enable more nuanced and coherent emotional facial expressions.

Method: The paper applies an intuitive two-parameter representation for emotive non-manual signals to the Paula signing avatar, using the EASIER notation for textual control of the avatar's emotional expressions.

Result: The application of the two-parameter representation to the Paula avatar shows promise for facilitating the linguistic specification of emotional facial expressions, allowing for more nuanced emotional states and potentially more consistent specification in linguistic annotations.

Conclusion: This paper explores a promising two-parameter representation for emotive non-manual signals applied to the Paula signing avatar, facilitating more coherent linguistic specification of emotional facial expressions and enabling nuanced emotional states through textual control via EASIER notation. This approach has the potential for more consistent specification of emotional non-manual signals in linguistic annotations for signing avatars.

Abstract: Non-manual signals in sign languages continue to be a challenge for signing
avatars. More specifically, emotional content has been difficult to incorporate
because of a lack of a standard method of specifying the avatar's emotional
state. This paper explores the application of an intuitive two-parameter
representation for emotive non-manual signals to the Paula signing avatar that
shows promise for facilitating the linguistic specification of emotional facial
expressions in a more coherent manner than previous methods. Users can apply
these parameters to control Paula's emotional expressions through a textual
representation called the EASIER notation. The representation can allow avatars
to express more nuanced emotional states using two numerical parameters. It
also has the potential to enable more consistent specification of emotional
non-manual signals in linguistic annotations which drive signing avatars.

</details>


### [293] [Expert Preference-based Evaluation of Automated Related Work Generation](https://arxiv.org/abs/2508.07955)
*Furkan Şahinuç,Subhabrata Dutta,Iryna Gurevych*

Main category: cs.CL

TL;DR: 这项研究提出了一种名为 GREP 的新框架，用于评估科学写作的质量，特别是参考文献部分。GREP 通过结合传统标准和专家偏好，并进行细粒度评估，比现有的 LLM 方法更准确，并与人类评估者高度一致。研究还发现，当前最先进的 LLM 在生成满足科学写作要求的参考文献方面存在困难。


<details>
  <summary>Details</summary>
Motivation: 目前的自动评估指标和 LLM-as-a-judge 系统在评估自动生成的科学写作质量方面存在不足，无法掌握专家偏好和领域特定的质量标准。因此，需要开发一种新的评估框架来支持人机协作写作。

Method: 提出 GREP（一个多轮评估框架），集成了经典的文献评估标准和专家偏好，通过细粒度的维度评估和对比少样本示例来提供详细的上下文指导。GREP 有两个版本：一个使用专有 LLM 作为评估器，另一个使用开放权重 LLM。

Result: GREP 框架比标准的 LLM 裁判更能稳健地评估文献部分的质量，并且与人类专家的评估高度相关。研究还发现，最先进的 LLM 在满足合适的文献部分的验证约束方面存在困难，并且在根据反馈进行改进方面也存在不足。

Conclusion: 该研究提出了一种名为 GREP 的多轮评估框架，用于评估科学写作，特别是参考文献的质量。GREP 结合了经典的文献评估标准和专家特定的偏好，并将评估分解为细粒度的维度，辅以对比少样本示例以提供详细的上下文指导。实验表明，GREP 比标准的 LLM 裁判更能稳健地评估文献部分的质量，并与人类专家的评估高度相关。研究还发现，最先进的 LLM 在满足合适的文献部分的验证约束方面存在困难，并且在根据反馈进行改进方面也存在不足。

Abstract: Expert domain writing, such as scientific writing, typically demands
extensive domain knowledge. Recent advances in LLMs show promising potential in
reducing the expert workload. However, evaluating the quality of automatically
generated scientific writing is a crucial open issue, as it requires knowledge
of domain-specific evaluation criteria and the ability to discern expert
preferences. Conventional automatic metrics and LLM-as-a-judge systems are
insufficient to grasp expert preferences and domain-specific quality standards.
To address this gap and support human-AI collaborative writing, we focus on
related work generation, one of the most challenging scientific tasks, as an
exemplar. We propose GREP, a multi-turn evaluation framework that integrates
classical related work evaluation criteria with expert-specific preferences.
Instead of assigning a single score, our framework decomposes the evaluation
into fine-grained dimensions. This localized evaluation approach is further
augmented with contrastive few-shot examples to provide detailed contextual
guidance for the evaluation dimensions. The design principles allow our
framework to deliver cardinal assessment of quality, which can facilitate
better post-training compared to ordinal preference data. For better
accessibility, we design two variants of GREP: a more precise variant with
proprietary LLMs as evaluators, and a cheaper alternative with open-weight
LLMs. Empirical investigation reveals that our framework is able to assess the
quality of related work sections in a much more robust manner compared to
standard LLM judges, reflects natural scenarios of scientific writing, and
bears a strong correlation with the human expert assessment. We also observe
that generations from state-of-the-art LLMs struggle to satisfy validation
constraints of a suitable related work section. They (mostly) fail to improve
based on feedback as well.

</details>


### [294] [Large Language Models for Subjective Language Understanding: A Survey](https://arxiv.org/abs/2508.07959)
*Changhao Song,Yazhou Zhang,Hui Gao,Ben Yao,Peng Zhang*

Main category: cs.CL

TL;DR: 本综述全面介绍了LLM在情感分析、讽刺检测等主观语言任务中的应用进展、挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着LLM（如ChatGPT、LLaMA）的出现，主观语言理解任务的范式发生了转变，本综述旨在全面回顾LLM在这些任务上的最新进展。

Method: 对LLM在主观语言任务（如情感分析、情绪识别、讽刺检测、幽默理解、立场检测、隐喻解释、意图检测和美学评估）上的应用进行全面综述，总结了任务定义、数据集、SOTA LLM方法及挑战，并进行了比较和讨论。

Result: LLM非常适合处理主观语言的细微差别，并已在多种主观语言任务中取得显著进展，但仍存在数据限制、模型偏见和伦理考量等问题。

Conclusion: LLMs在理解和生成主观语言方面展现出巨大潜力，但也面临数据限制、模型偏见和伦理等挑战，未来研究应关注这些问题并探索多任务统一模型。

Abstract: Subjective language understanding refers to a broad set of natural language
processing tasks where the goal is to interpret or generate content that
conveys personal feelings, opinions, or figurative meanings rather than
objective facts. With the advent of large language models (LLMs) such as
ChatGPT, LLaMA, and others, there has been a paradigm shift in how we approach
these inherently nuanced tasks. In this survey, we provide a comprehensive
review of recent advances in applying LLMs to subjective language tasks,
including sentiment analysis, emotion recognition, sarcasm detection, humor
understanding, stance detection, metaphor interpretation, intent detection, and
aesthetics assessment. We begin by clarifying the definition of subjective
language from linguistic and cognitive perspectives, and we outline the unique
challenges posed by subjective language (e.g. ambiguity, figurativeness,
context dependence). We then survey the evolution of LLM architectures and
techniques that particularly benefit subjectivity tasks, highlighting why LLMs
are well-suited to model subtle human-like judgments. For each of the eight
tasks, we summarize task definitions, key datasets, state-of-the-art LLM-based
methods, and remaining challenges. We provide comparative insights, discussing
commonalities and differences among tasks and how multi-task LLM approaches
might yield unified models of subjectivity. Finally, we identify open issues
such as data limitations, model bias, and ethical considerations, and suggest
future research directions. We hope this survey will serve as a valuable
resource for researchers and practitioners interested in the intersection of
affective computing, figurative language processing, and large-scale language
models.

</details>


### [295] [Toward Machine Interpreting: Lessons from Human Interpreting Studies](https://arxiv.org/abs/2508.07964)
*Matthias Sperber,Maureen de Seyssel,Jiajun Bao,Matthias Paulik*

Main category: cs.CL

TL;DR: 本研究旨在弥合语音翻译系统与人工同传之间的差距，通过借鉴人类翻译的原则和先进的建模技术来改进其性能和用户体验。


<details>
  <summary>Details</summary>
Motivation: 为了提高语音翻译系统的实用性并实现类似人工同传的体验，理解人类翻译的本质至关重要。

Method: 本研究通过对比分析机器翻译领域和人类翻译文献，探讨了人类翻译的本质，并识别了其对语音翻译系统开发的启示。

Result: 研究结果表明，将人类翻译的原则应用于语音翻译系统具有巨大潜力，可以利用最新的建模技术来改进用户体验。

Conclusion: 该研究认为，通过借鉴人类翻译的原则并结合先进的建模技术，有潜力弥合现有语音翻译系统与理想机器翻译之间的差距，并推动机器翻译的进步。

Abstract: Current speech translation systems, while having achieved impressive
accuracies, are rather static in their behavior and do not adapt to real-world
situations in ways human interpreters do. In order to improve their practical
usefulness and enable interpreting-like experiences, a precise understanding of
the nature of human interpreting is crucial. To this end, we discuss human
interpreting literature from the perspective of the machine translation field,
while considering both operational and qualitative aspects. We identify
implications for the development of speech translation systems and argue that
there is great potential to adopt many human interpreting principles using
recent modeling techniques. We hope that our findings provide inspiration for
closing the perceived usability gap, and can motivate progress toward true
machine interpreting.

</details>


### [296] [Understanding Syntactic Generalization in Structure-inducing Language Models](https://arxiv.org/abs/2508.07969)
*David Arps,Hassan Sajjad,Laura Kallmeyer*

Main category: cs.CL

TL;DR: 对三种SiLM模型（Structformer, UDGN, GPST）的句法表示、语法判断任务表现和训练动态进行了比较。发现GPST模型表现最稳定，尤其在长距离依赖方面表现优异。小型模型在合成数据上的训练是评估模型属性的有效途径。


<details>
  <summary>Details</summary>
Motivation: 现有的SiLM模型在评估规模上相对较小，且评估方法存在系统性差距和可比性不足的问题，因此需要进行更全面的研究来理解和比较不同的SiLM架构。

Method: 通过自然语言（英语）语料库和合成括号表达式，对Structformer、UDGN和GPST三种SiLM模型在（i）诱导句法表示的属性、（ii）语法判断任务的表现和（iii）训练动态方面进行了比较和评估。

Result: 在句法表示方面存在显著差异，GPST模型在各项评估中表现最为稳定，在合成括号表达式的长距离依赖关系处理上表现优于其他模型。

Conclusion: SiLM模型在不同评估指标上没有表现出绝对优势，但GPST模型在各项评估中表现最为稳定，在处理长距离依赖关系方面优于其他模型。小型模型在大量合成数据上的训练是评估模型基本属性的有效方法。

Abstract: Structure-inducing Language Models (SiLM) are trained on a self-supervised
language modeling task, and induce a hierarchical sentence representation as a
byproduct when processing an input. A wide variety of SiLMs have been proposed.
However, these have typically been evaluated on a relatively small scale, and
evaluation of these models has systematic gaps and lacks comparability. In this
work, we study three different SiLM architectures using both natural language
(English) corpora and synthetic bracketing expressions: Structformer (Shen et
al., 2021), UDGN (Shen et al., 2022) and GPST (Hu et al., 2024). We compare
them with respect to (i) properties of the induced syntactic representations
(ii) performance on grammaticality judgment tasks, and (iii) training dynamics.
We find that none of the three architectures dominates across all evaluation
metrics. However, there are significant differences, in particular with respect
to the induced syntactic representations. The Generative Pretrained Structured
Transformer (GPST; Hu et al. 2024) performs most consistently across evaluation
settings, and outperforms the other models on long-distance dependencies in
bracketing expressions. Furthermore, our study shows that small models trained
on large amounts of synthetic data provide a useful testbed for evaluating
basic model properties.

</details>


### [297] [Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL](https://arxiv.org/abs/2508.07976)
*Jiaxuan Gao,Wei Fu,Minyang Xie,Shusheng Xu,Chuyi He,Zhiyu Mei,Banghua Zhu,Yi Wu*

Main category: cs.CL

TL;DR: ASearcher 是一个开源项目，通过大规模强化学习训练搜索智能体，解决了现有方法在可扩展性、效率和数据质量方面的不足，并显著提高了搜索智能能力。


<details>
  <summary>Details</summary>
Motivation: 现有开源智能体在解决模糊查询、生成精确搜索、分析结果和进行彻底探索等方面的搜索智能能力不足，并且在可扩展性、效率和数据质量方面存在不足。

Method: ASearcher 项目通过完全异步强化学习训练来支持长时期搜索并保持高训练效率，并利用基于提示的 LLM 智能体自主合成高质量、具有挑战性的问答数据集，以支持强化学习训练。

Result: ASearcher 项目通过强化学习训练，在 xBench 和 GAIA 上分别取得了 46.7% 和 20.8% 的 Avg@4 提升。

Conclusion: ASearcher-Web-QwQ 在 xBench 和 GAIA 上分别取得了 42.1 和 52.8 的 Avg@4 分数，超越了现有的开源 32B 智能体，并且该智能体具有极长的探索能力，在训练期间工具调用次数超过 40 次，输出令牌超过 150k 次。

Abstract: Recent advancements in LLM-based agents have demonstrated remarkable
capabilities in handling complex, knowledge-intensive tasks by integrating
external tools. Among diverse choices of tools, search tools play a pivotal
role in accessing vast external knowledge. However, open-source agents still
fall short of achieving expert-level Search Intelligence, the ability to
resolve ambiguous queries, generate precise searches, analyze results, and
conduct thorough exploration. Existing approaches fall short in scalability,
efficiency, and data quality. For example, small turn limits in existing online
RL methods, e.g. <=10, restrict complex strategy learning. This paper
introduces ASearcher, an open-source project for large-scale RL training of
search agents. Our key contributions include: (1) Scalable fully asynchronous
RL training that enables long-horizon search while maintaining high training
efficiency. (2) A prompt-based LLM agent that autonomously synthesizes
high-quality and challenging QAs, creating a large-scale QA dataset. Through RL
training, our prompt-based QwQ-32B agent achieves substantial improvements,
with 46.7% and 20.8% Avg@4 gains on xBench and GAIA, respectively. Notably, our
agent exhibits extreme long-horizon search, with tool calls exceeding 40 turns
and output tokens exceeding 150k during training time. With a simple agent
design and no external LLMs, ASearcher-Web-QwQ achieves Avg@4 scores of 42.1 on
xBench and 52.8 on GAIA, surpassing existing open-source 32B agents. We
open-source our models, training data, and codes in
https://github.com/inclusionAI/ASearcher.

</details>


### [298] [The Medical Metaphors Corpus (MCC)](https://arxiv.org/abs/2508.07993)
*Anna Sofia Lippolis,Andrea Giovanni Nuzzolese,Aldo Gangemi*

Main category: cs.CL

TL;DR: 本研究提出了医学隐喻语料库（MCC），一个包含 792 个医学和生物学领域隐喻的数据集，可用于科学隐喻研究和应用。


<details>
  <summary>Details</summary>
Motivation: 解决现有隐喻检测资源主要集中在通用领域文本，而忽略了特定领域（如医学和生物学）应用的不足。

Method: 构建了一个包含 792 个医学和生物学领域科学概念隐喻的语料库（MCC），收集了来自同行评审文献、新闻媒体、社交媒体讨论和众包贡献的隐喻表达，并通过人工标注进行了二元和分级的隐喻性判断验证，包括来源-目标概念映射和 0-7 分制的隐喻感知评分。

Result: MCC 是计算科学隐喻研究的首个标注资源。评估表明，最先进的语言模型在科学隐喻检测方面的表现尚可，但仍有很大的提升空间。MCC 可用于隐喻检测基准测试、质量感知生成系统和以患者为中心的沟通工具等多种研究应用。

Conclusion: 该研究提出了医学隐喻语料库（MCC），这是一个包含 792 个医学和生物学领域科学概念隐喻的综合数据集，旨在填补特定领域隐喻检测资源的空白。该语料库通过人工标注收集了二元和分级的隐喻判断，并提供了来源-目标概念映射和 0-7 分制的隐喻感知评分，为计算科学隐喻研究提供了首个标注资源。

Abstract: Metaphor is a fundamental cognitive mechanism that shapes scientific
understanding, enabling the communication of complex concepts while potentially
constraining paradigmatic thinking. Despite the prevalence of figurative
language in scientific discourse, existing metaphor detection resources
primarily focus on general-domain text, leaving a critical gap for
domain-specific applications. In this paper, we present the Medical Metaphors
Corpus (MCC), a comprehensive dataset of 792 annotated scientific conceptual
metaphors spanning medical and biological domains. MCC aggregates metaphorical
expressions from diverse sources including peer-reviewed literature, news
media, social media discourse, and crowdsourced contributions, providing both
binary and graded metaphoricity judgments validated through human annotation.
Each instance includes source-target conceptual mappings and perceived
metaphoricity scores on a 0-7 scale, establishing the first annotated resource
for computational scientific metaphor research. Our evaluation demonstrates
that state-of-the-art language models achieve modest performance on scientific
metaphor detection, revealing substantial room for improvement in
domain-specific figurative language understanding. MCC enables multiple
research applications including metaphor detection benchmarking, quality-aware
generation systems, and patient-centered communication tools.

</details>


### [299] [WideSearch: Benchmarking Agentic Broad Info-Seeking](https://arxiv.org/abs/2508.07999)
*Ryan Wong,Jiawei Wang,Junjie Zhao,Li Chen,Yan Gao,Long Zhang,Xuan Zhou,Zuo Wang,Kai Xiang,Ge Zhang,Wenhao Huang,Yang Wang,Ke Wang*

Main category: cs.CL

TL;DR: 本研究提出了 WideSearch 基准，用于评估大规模信息检索任务中搜索代理的可靠性。结果表明，当前代理的表现不佳，成功率接近 0%，而人类测试者在相同任务上成功率接近 100%。


<details>
  <summary>Details</summary>
Motivation: 现有的搜索代理在执行大规模、重复性的信息收集任务时能力不足，并且缺乏评估这些代理能力的基准。本研究旨在解决这一差距。

Method: 引入了一个名为 WideSearch 的新基准，其中包含 200 个由人工策划的问题（100 个英文，100 个中文），涵盖 15 个不同的领域。该基准旨在评估代理在这些大规模收集任务中的可靠性。问题需要代理收集大量原子信息并进行组织。通过了五阶段的质量控制流程，以确保数据集的难度、完整性和可验证性。对超过 10 个最先进的代理搜索系统进行了基准测试。

Result: 大多数代理系统的成功率接近 0%，即使是最好的系统也只有 5%。然而，在有足够时间的情况下，经过多个人类测试者进行交叉验证，成功率可以接近 100%。这表明当前代理在处理此类任务时存在关键缺陷。

Conclusion: 目前搜索代理在处理大规模信息检索任务时存在严重缺陷，需要对代理搜索进行大量未来的研究和开发。

Abstract: From professional research to everyday planning, many tasks are bottlenecked
by wide-scale information seeking, which is more repetitive than cognitively
complex. With the rapid development of Large Language Models (LLMs), automated
search agents powered by LLMs offer a promising solution to liberate humans
from this tedious work. However, the capability of these agents to perform such
"wide-context" collection reliably and completely remains largely unevaluated
due to a lack of suitable benchmarks. To bridge this gap, we introduce
WideSearch, a new benchmark engineered to evaluate agent reliability on these
large-scale collection tasks. The benchmark features 200 manually curated
questions (100 in English, 100 in Chinese) from over 15 diverse domains,
grounded in real user queries. Each task requires agents to collect large-scale
atomic information, which could be verified one by one objectively, and arrange
it into a well-organized output. A rigorous five-stage quality control pipeline
ensures the difficulty, completeness, and verifiability of the dataset. We
benchmark over 10 state-of-the-art agentic search systems, including
single-agent, multi-agent frameworks, and end-to-end commercial systems. Most
systems achieve overall success rates near 0\%, with the best performer
reaching just 5\%. However, given sufficient time, cross-validation by multiple
human testers can achieve a near 100\% success rate. These results demonstrate
that present search agents have critical deficiencies in large-scale
information seeking, underscoring urgent areas for future research and
development in agentic search. Our dataset, evaluation pipeline, and benchmark
results have been publicly released at https://widesearch-seed.github.io/

</details>


### [300] [Progressive Depth Up-scaling via Optimal Transport](https://arxiv.org/abs/2508.08011)
*Mingzi Cao,Xi Wang,Nikolaos Aletras*

Main category: cs.CL

TL;DR: 为了解决 LLM 深度扩展中神经元排列不匹配导致性能下降的问题，提出了一种基于最优传输（OT）的 OpT-DeUS 方法。该方法通过对齐和融合 Transformer 块来创建新层，提高了训练效率和模型性能。研究还表明，将新层置于模型顶层附近效果更佳。


<details>
  <summary>Details</summary>
Motivation: 现有的深度扩展方法在通过增加层数来提高 LLM 性能时，往往只复制或平均权重，忽略了神经元排列的差异，这可能导致性能下降。本研究旨在解决这一问题。

Method: 提出了一种名为 Optimal Transport Depth Up-Scaling（OpT-DeUS）的方法，该方法利用最优传输（OT）技术来对齐和融合相邻基础层中的 Transformer 块，以创建新层，从而解决神经元排列不匹配问题。

Result: OpT-DeUS 在持续预训练和有监督微调任务中，在不同模型规模上均取得了比现有方法更好的整体性能和更高的训练效率。通过消融研究发现，将新层插入到更靠近模型顶层的位置，可以提高训练效率（由于反向传播时间缩短）并获得额外的性能提升。

Conclusion: OpT-DeUS 方法通过最优传输（OT）对齐和融合相邻基础层中的 Transformer 块，以缓解层间神经元排列不匹配问题，在持续预训练和有监督微调任务中，相比现有方法，在不同模型规模上均实现了更好的整体性能和更高的训练效率。此外，将新层插入到更靠近顶层的位置可以获得更高的训练效率和额外的性能增益。

Abstract: Scaling Large Language Models (LLMs) yields performance gains but incurs
substantial training costs. Depth up-scaling offers training efficiency by
adding new layers to pre-trained models. However, most existing methods copy or
average weights from base layers, neglecting neuron permutation differences.
This limitation can potentially cause misalignment that harms performance.
Inspired by applying Optimal Transport (OT) for neuron alignment, we propose
Optimal Transport Depth Up-Scaling (OpT-DeUS). OpT-DeUS aligns and fuses
Transformer blocks in adjacent base layers via OT for new layer creation, to
mitigate neuron permutation mismatch between layers. OpT-DeUS achieves better
overall performance and offers improved training efficiency than existing
methods for continual pre-training and supervised fine-tuning across different
model sizes. To further evaluate the impact of interpolation positions, our
extensive analysis shows that inserting new layers closer to the top results in
higher training efficiency due to shorter back-propagation time while obtaining
additional performance gains.

</details>


### [301] [9th Workshop on Sign Language Translation and Avatar Technologies (SLTAT 2025)](https://arxiv.org/abs/2508.08050)
*Fabrizio Nunnari,Cristina Luna Jiménez,Rosalee Wolfe,John C. McDonald,Michael Filhol,Eleni Efthimiou,Evita Fotinea,Thomas Hanke*

Main category: cs.CL

TL;DR: The SLTAT workshop brings together researchers in sign language translation and avatar technology, with the 2025 edition focusing on diverse contributions beyond avatars, including recognition, data, ethics, and affective computing, fostering collaboration with the digital human community.


<details>
  <summary>Details</summary>
Motivation: To share recent advances in improving deaf/human communication through non-invasive means and foster collaboration between research communities using digital humans.

Method: The paper summarizes contributions to the SLTAT workshop, covering sign language recognition, data collection and analysis, tools, ethics, usability, and affective computing, beyond just avatar technologies.

Result: The 2025 SLTAT workshop, hosted by IVA, saw contributions across various areas including sign language recognition, data-related work, tools, ethics, usability, and affective computing, highlighting the interdisciplinary nature of the field.

Conclusion: The SLTAT workshop continues to advance research in sign language translation and avatar technology, fostering collaboration between digital human and sign language communities.

Abstract: The Sign Language Translation and Avatar Technology (SLTAT) workshops
continue a series of gatherings to share recent advances in improving deaf /
human communication through non-invasive means. This 2025 edition, the 9th
since its first appearance in 2011, is hosted by the International Conference
on Intelligent Virtual Agents (IVA), giving the opportunity for contamination
between two research communities, using digital humans as either virtual
interpreters or as interactive conversational agents. As presented in this
summary paper, SLTAT sees contributions beyond avatar technologies, with a
consistent number of submissions on sign language recognition, and other work
on data collection, data analysis, tools, ethics, usability, and affective
computing.

</details>


### [302] [Dual Information Speech Language Models for Emotional Conversations](https://arxiv.org/abs/2508.08095)
*Chun Wang,Chenyang Liu,Wenze Xu,Weihong Deng*

Main category: cs.CL

TL;DR: 为解决现有语音语言模型（SLM）在处理副语言信息和上下文理解方面的不足，本文提出了一种包含异构适配器和弱监督训练的新方法，该方法能有效解耦并整合语音中的副语言和语言信息，同时保持上下文理解能力，并在情感对话任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的依赖文本的大型语言模型（LLM）在处理以语音为输入的对话系统时，忽略了对理解情感和意图至关重要的副语言线索。而通过扩展冻结的LLM构建的语音语言模型（SLM）在捕捉副语言信息和保持上下文理解方面存在不足。文章指出，信息纠缠和不当的训练策略是主要问题。

Method: 提出两种异构适配器，并采用弱监督训练策略，仅在常见数据集上训练适配器，实现了参数和数据的效率。

Result: 在情感对话任务中取得了具有竞争力的性能，证明了该模型能够有效地在上下文环境中整合副语言信息和语言信息。

Conclusion: 所提出的方法能够解耦语音中的副语言信息和语言信息，从而使语音语言模型（SLM）能够通过结构化表示来理解语音，并且通过控制随机性来避免生成特定于任务的向量，从而保持上下文理解能力。实验证明了该方法在情感对话任务中的竞争力，有效整合了副语言信息、语言信息和上下文信息。

Abstract: Conversational systems relying on text-based large language models (LLMs)
often overlook paralinguistic cues, essential for understanding emotions and
intentions. Speech-language models (SLMs), which use speech as input, are
emerging as a promising solution. However, SLMs built by extending frozen LLMs
struggle to capture paralinguistic information and exhibit reduced context
understanding. We identify entangled information and improper training
strategies as key issues. To address these issues, we propose two heterogeneous
adapters and suggest a weakly supervised training strategy. Our approach
disentangles paralinguistic and linguistic information, enabling SLMs to
interpret speech through structured representations. It also preserves
contextual understanding by avoiding the generation of task-specific vectors
through controlled randomness. This approach trains only the adapters on common
datasets, ensuring parameter and data efficiency. Experiments demonstrate
competitive performance in emotional conversation tasks, showcasing the model's
ability to effectively integrate both paralinguistic and linguistic information
within contextual settings.

</details>


### [303] [Assessing LLM Text Detection in Educational Contexts: Does Human Contribution Affect Detection?](https://arxiv.org/abs/2508.08096)
*Lukas Gehring,Benjamin Paaßen*

Main category: cs.CL

TL;DR: 该研究评估了LLM文本探测器在教育环境中的性能，发现它们在检测学生中等贡献程度的文本时存在困难，并且容易产生误报，对学生可能产生负面影响。研究人员为此创建了一个新的数据集GEDE，并提出了“贡献程度”的概念来更好地评估这些探测器。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）的普及，学生可以轻松自动生成文本，这对教育机构提出了新的挑战，需要开发能够自动检测LLM生成文本的学习分析方法，以维护学术诚信和确保学生学习。

Method: 该研究评估了不同最先进的文本探测器的性能，并引入了一个名为GEDE（Generative Essay Detection in Education）的新数据集，其中包含900多篇学生撰写的论文和12,500多篇由LLM生成的论文。研究人员还提出了“贡献程度”的概念，以描述学生在作业中的参与度，并评估了探测器在不同贡献程度下的表现。

Result: 研究结果表明，大多数探测器在准确分类学生中等贡献程度的文本方面存在困难，并且在教育环境中容易产生误报，这可能对学生造成严重后果。

Conclusion: 大多数探测器在准确分类学生中等贡献程度的文本（例如，LLM改进的人工撰写文本）方面存在困难。在教育环境中，误报（即，错误地将人类文本分类为LLM生成文本）尤其令人担忧，因为这可能对学生产生严重影响。

Abstract: Recent advancements in Large Language Models (LLMs) and their increased
accessibility have made it easier than ever for students to automatically
generate texts, posing new challenges for educational institutions. To enforce
norms of academic integrity and ensure students' learning, learning analytics
methods to automatically detect LLM-generated text appear increasingly
appealing. This paper benchmarks the performance of different state-of-the-art
detectors in educational contexts, introducing a novel dataset, called
Generative Essay Detection in Education (GEDE), containing over 900
student-written essays and over 12,500 LLM-generated essays from various
domains. To capture the diversity of LLM usage practices in generating text, we
propose the concept of contribution levels, representing students' contribution
to a given assignment. These levels range from purely human-written texts, to
slightly LLM-improved versions, to fully LLM-generated texts, and finally to
active attacks on the detector by "humanizing" generated texts. We show that
most detectors struggle to accurately classify texts of intermediate student
contribution levels, like LLM-improved human-written texts. Detectors are
particularly likely to produce false positives, which is problematic in
educational settings where false suspicions can severely impact students'
lives. Our dataset, code, and additional supplementary materials are publicly
available at
https://github.com/lukasgehring/Assessing-LLM-Text-Detection-in-Educational-Contexts.

</details>


### [304] [Iterative refinement, not training objective, makes HuBERT behave differently from wav2vec 2.0](https://arxiv.org/abs/2508.08110)
*Robin Huo,Ewan Dunbar*

Main category: cs.CL

TL;DR: 本研究比较了 HuBERT 和 wav2vec 2.0 模型架构的差异，发现迭代优化对提升模型表示的语言信息至关重要。


<details>
  <summary>Details</summary>
Motivation: 目前关于模型架构对自监督语音表示学习中语言信息影响的研究尚不充分，本研究旨在探究此问题。

Method: 通过比较 HuBERT 和 wav2vec 2.0 模型，并分析其架构差异（训练目标和迭代伪标签优化），研究模型表示学习中语言信息的变化。

Result: 研究发现，模型隐藏表示与词汇、音素和说话人身份的相关性差异主要由训练迭代次数决定，而非训练目标。

Conclusion: wav2vec 2.0 和 HuBERT 模型在表示学习中的细微架构差异（训练目标和迭代伪标签优化）并不影响模型隐藏表示与词汇、音素和说话人身份的相关性。迭代优化在编码语言信息方面比训练目标更重要。

Abstract: Self-supervised models for speech representation learning now see widespread
use for their versatility and performance on downstream tasks, but the effect
of model architecture on the linguistic information learned in their
representations remains under-studied. This study investigates two such models,
HuBERT and wav2vec 2.0, and minimally compares two of their architectural
differences: training objective and iterative pseudo-label refinement through
multiple training iterations. We find that differences in canonical correlation
of hidden representations to word identity, phoneme identity, and speaker
identity are explained by training iteration, not training objective. We
suggest that future work investigate the reason for the effectiveness of
iterative refinement in encoding linguistic information in self-supervised
speech representations.

</details>


### [305] [Czech Dataset for Complex Aspect-Based Sentiment Analysis Tasks](https://arxiv.org/abs/2508.08125)
*Jakub Šmíd,Pavel Přibáň,Ondřej Pražák,Pavel Král*

Main category: cs.CL

TL;DR: 研究者发布了一个新的捷克语餐厅评论数据集，用于方面级情感分析，支持更复杂的任务，并包含大量无标注数据用于无监督学习。


<details>
  <summary>Details</summary>
Motivation: 为了应对捷克语在方面级情感分析（ABSA）领域缺乏适合复杂任务（如目标方面类别检测）且标注统一的数据集的问题，本研究旨在创建一个新的、更全面的捷克语ABSA数据集，并促进跨语言研究。

Method: 本研究通过引入一个包含3.1K手动标注餐厅领域评论的新型捷克语数据集，该数据集在旧有数据集的基础上进行了扩展，增加了目标方面类别检测等复杂任务，并采用了与SemEval-2016数据集一致的统一标注格式，以方便跨语言应用。研究过程中，两位标注者达到了约90%的一致性，并提供了基于Transformer的基线模型结果和误差分析。

Result: 成功构建了一个包含3.1K手动标注评论和24M无标注评论的新型捷克语ABSA数据集，该数据集支持目标方面类别检测等复杂任务，并实现了约90%的标注一致性。同时，研究提供了基于Transformer的基线模型结果和误差分析。

Conclusion: 该研究提出了一个新的捷克语数据集，用于方面级情感分析（ABSA），并包含2400万条无标注评论以支持无监督学习。

Abstract: In this paper, we introduce a novel Czech dataset for aspect-based sentiment
analysis (ABSA), which consists of 3.1K manually annotated reviews from the
restaurant domain. The dataset is built upon the older Czech dataset, which
contained only separate labels for the basic ABSA tasks such as aspect term
extraction or aspect polarity detection. Unlike its predecessor, our new
dataset is specifically designed for more complex tasks, e.g.
target-aspect-category detection. These advanced tasks require a unified
annotation format, seamlessly linking sentiment elements (labels) together. Our
dataset follows the format of the well-known SemEval-2016 datasets. This design
choice allows effortless application and evaluation in cross-lingual scenarios,
ultimately fostering cross-language comparisons with equivalent counterpart
datasets in other languages. The annotation process engaged two trained
annotators, yielding an impressive inter-annotator agreement rate of
approximately 90%. Additionally, we provide 24M reviews without annotations
suitable for unsupervised learning. We present robust monolingual baseline
results achieved with various Transformer-based models and insightful error
analysis to supplement our contributions. Our code and dataset are freely
available for non-commercial research purposes.

</details>


### [306] [Optimal Transport Regularization for Speech Text Alignment in Spoken Language Models](https://arxiv.org/abs/2508.08131)
*Wenze Xu,Chun Wang,Jiazhen Yu,Sheng Chen,Liang Gao,Weihong Deng*

Main category: cs.CL

TL;DR: OTReg 通过最优传输来解决语音语言模型在跨数据集泛化方面的挑战，取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 现有的语音语言模型 (SLM) 在跨数据集泛化方面存在困难，这可能是因为语音和文本表示之间的模态鸿沟，导致 SLM 可能利用了非预期的语音变化，而非像预期那样以类似文本的方式处理语音。

Method: OTReg (Optimal Transport Regularization) 将语音-文本对齐作为最优传输问题，通过计算最优传输计划来构建语音和文本嵌入之间的结构化对应关系，并基于此传输计划引入正则化损失来优化 SLM 训练。

Result: OTReg 提高了语音-文本对齐度，缩小了模态鸿沟，并显著提升了 SLM 在多语言自动语音识别 (ASR) 任务上的跨数据集泛化能力。

Conclusion: OTReg 通过利用最优传输来弥合语音和文本表示之间的模态鸿沟，从而增强了语音语言模型 (SLM) 的跨数据集泛化能力。

Abstract: Spoken Language Models (SLMs), which extend Large Language Models (LLMs) to
perceive speech inputs, have gained increasing attention for their potential to
advance speech understanding tasks. However, despite recent progress, studies
show that SLMs often struggle to generalize across datasets, even for trained
languages and tasks, raising concerns about whether they process speech in a
text-like manner as intended. A key challenge underlying this limitation is the
modality gap between speech and text representations. The high variability in
speech embeddings may allow SLMs to achieve strong in-domain performance by
exploiting unintended speech variations, ultimately hindering generalization.
To mitigate this modality gap, we introduce Optimal Transport Regularization
(OTReg), a method that formulates speech-text alignment as an optimal transport
problem and derives a regularization loss to improve SLM training. In each
training iteration, OTReg first establishes a structured correspondence between
speech and transcript embeddings by determining the optimal transport plan,
then incorporates the regularization loss based on this transport plan to
optimize SLMs in generating speech embeddings that align more effectively with
transcript embeddings. OTReg is lightweight, requiring no additional labels or
learnable parameters, and integrates seamlessly into existing SLM training
procedures. Extensive multilingual ASR experiments demonstrate that OTReg
enhances speech-text alignment, mitigates the modality gap, and consequently
improves SLM generalization across diverse datasets.

</details>


### [307] [Can LLMs Detect Their Confabulations? Estimating Reliability in Uncertainty-Aware Language Models](https://arxiv.org/abs/2508.08139)
*Tianyi Zhou,Johanne Medina,Sanjay Chawla*

Main category: cs.CL

TL;DR: LLM在多轮或agentic应用中容易产生虚假但流畅的错误内容。本研究调查了上下文信息对模型行为的影响，并提出了一种基于令牌级不确定性的可靠性估计方法，以提高对LLM不可靠响应的检测能力。研究发现，模型置信度与回答的正确性之间可能存在不匹配。


<details>
  <summary>Details</summary>
Motivation: 研究LLM中上下文信息如何影响模型行为以及LLM是否能识别其不可靠的响应。

Method: 提出了一种利用令牌级不确定性来指导内部模型表示聚合的可靠性估计方法，通过计算输出对数的不确定性来识别显著令牌，并将它们的隐藏状态聚合成响应级可靠性预测的紧凑表示。

Result: 正确上下文信息可提高答案准确性和模型置信度，而误导性上下文通常会导致自信的错误响应，这表明不确定性与正确性之间存在不匹配。通过基于探测的方法可以捕捉这些模型行为的变化，并提高在多个开源LLM上不可靠输出的检测能力。

Conclusion: LLMs的局限性在于直接的不确定性信号，并强调了不确定性引导探测在可靠性感知生成方面的潜力。

Abstract: Large Language Models (LLMs) are prone to generating fluent but incorrect
content, known as confabulation, which poses increasing risks in multi-turn or
agentic applications where outputs may be reused as context. In this work, we
investigate how in-context information influences model behavior and whether
LLMs can identify their unreliable responses. We propose a reliability
estimation that leverages token-level uncertainty to guide the aggregation of
internal model representations. Specifically, we compute aleatoric and
epistemic uncertainty from output logits to identify salient tokens and
aggregate their hidden states into compact representations for response-level
reliability prediction. Through controlled experiments on open QA benchmarks,
we find that correct in-context information improves both answer accuracy and
model confidence, while misleading context often induces confidently incorrect
responses, revealing a misalignment between uncertainty and correctness. Our
probing-based method captures these shifts in model behavior and improves the
detection of unreliable outputs across multiple open-source LLMs. These results
underscore the limitations of direct uncertainty signals and highlight the
potential of uncertainty-guided probing for reliability-aware generation.

</details>


### [308] [Data-Efficient Biomedical In-Context Learning: A Diversity-Enhanced Submodular Perspective](https://arxiv.org/abs/2508.08140)
*Jun Wang,Zaifu Zhan,Qixin Zhang,Mingquan Lin,Meijia Song,Rui Zhang*

Main category: cs.CL

TL;DR: LLM在生物医学任务的少样本学习中，演示数据的多样性比代表性更重要，少量（3-5个）多样化演示能达到最佳效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在选择LLM的少样本学习演示时，大多优先考虑代表性而非多样性，而多样性在适应新的生物医学NLP任务时可能很重要。

Method: Dual-Div是一个两阶段的框架，首先通过优化代表性和多样性来检索候选示例，然后根据测试查询对候选示例进行排名以选择最相关和非冗余的演示。

Result: 在三个生物医学NLP任务（NER、RE和TC）上，Dual-Div相比基线模型，在LLaMA 3.1和Qwen 2.5上取得了高达5%的宏F1分数提升，并证明了其对提示排列和类别不平衡的鲁棒性。

Conclusion: 多样性在LLM的生物医学少样本学习中至关重要，并且演示数据的选择应优先考虑多样性而非代表性。此外，将演示数量限制在3-5个示例可以实现最佳的性能效率。

Abstract: Recent progress in large language models (LLMs) has leveraged their
in-context learning (ICL) abilities to enable quick adaptation to unseen
biomedical NLP tasks. By incorporating only a few input-output examples into
prompts, LLMs can rapidly perform these new tasks. While the impact of these
demonstrations on LLM performance has been extensively studied, most existing
approaches prioritize representativeness over diversity when selecting examples
from large corpora. To address this gap, we propose Dual-Div, a
diversity-enhanced data-efficient framework for demonstration selection in
biomedical ICL. Dual-Div employs a two-stage retrieval and ranking process:
First, it identifies a limited set of candidate examples from a corpus by
optimizing both representativeness and diversity (with optional annotation for
unlabeled data). Second, it ranks these candidates against test queries to
select the most relevant and non-redundant demonstrations. Evaluated on three
biomedical NLP tasks (named entity recognition (NER), relation extraction (RE),
and text classification (TC)) using LLaMA 3.1 and Qwen 2.5 for inference, along
with three retrievers (BGE-Large, BMRetriever, MedCPT), Dual-Div consistently
outperforms baselines-achieving up to 5% higher macro-F1 scores-while
demonstrating robustness to prompt permutations and class imbalance. Our
findings establish that diversity in initial retrieval is more critical than
ranking-stage optimization, and limiting demonstrations to 3-5 examples
maximizes performance efficiency.

</details>


### [309] [REX-RAG: Reasoning Exploration with Policy Correction in Retrieval-Augmented Generation](https://arxiv.org/abs/2508.08149)
*Wentao Jiang,Xiang Feng,Zengmao Wang,Yong Luo,Pingbo Xu,Zhe Chen,Bo Du,Jing Zhang*

Main category: cs.CL

TL;DR: REX-RAG通过混合采样和策略校正解决了RL-RAG中LLM陷入死胡同的问题，在问答任务上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 在策略驱动的轨迹采样中，LLM经常陷入无效的推理路径（“死胡同”），导致过于自信但错误的结论，这严重阻碍了探索和有效的策略优化。

Method: REX-RAG框架提出了一种新颖的混合采样策略（包括探测采样方法和探索性提示）来跳出死胡同，以及一个策略校正机制（使用重要性采样）来纠正由混合采样引起的分布偏移，从而减轻梯度估计偏差。

Result: REX-RAG在七个问答基准测试中表现优于强基线，在Qwen2.5-3B上平均性能提升5.1%，在Qwen2.5-7B上平均性能提升3.6%，在多个数据集上取得了有竞争力的数据。

Conclusion: REX-RAG通过混合采样策略和策略校正机制，有效解决了RL-RAG中LLM陷入无效推理路径（

Abstract: Reinforcement learning (RL) is emerging as a powerful paradigm for enabling
large language models (LLMs) to perform complex reasoning tasks. Recent
advances indicate that integrating RL with retrieval-augmented generation (RAG)
allows LLMs to dynamically incorporate external knowledge, leading to more
informed and robust decision making. However, we identify a critical challenge
during policy-driven trajectory sampling: LLMs are frequently trapped in
unproductive reasoning paths, which we refer to as "dead ends", committing to
overconfident yet incorrect conclusions. This severely hampers exploration and
undermines effective policy optimization. To address this challenge, we propose
REX-RAG (Reasoning Exploration with Policy Correction in Retrieval-Augmented
Generation), a novel framework that explores alternative reasoning paths while
maintaining rigorous policy learning through principled distributional
corrections. Our approach introduces two key innovations: (1) Mixed Sampling
Strategy, which combines a novel probe sampling method with exploratory prompts
to escape dead ends; and (2) Policy Correction Mechanism, which employs
importance sampling to correct distribution shifts induced by mixed sampling,
thereby mitigating gradient estimation bias. We evaluate it on seven
question-answering benchmarks, and the experimental results show that REX-RAG
achieves average performance gains of 5.1% on Qwen2.5-3B and 3.6% on Qwen2.5-7B
over strong baselines, demonstrating competitive results across multiple
datasets. The code is publicly available at https://github.com/MiliLab/REX-RAG.

</details>


### [310] [LPI-RIT at LeWiDi-2025: Improving Distributional Predictions via Metadata and Loss Reweighting with DisCo](https://arxiv.org/abs/2508.08163)
*Mandira Sawkar,Samay U. Shetty,Deepak Pandita,Tharindu Cyril Weerasooriya,Christopher M. Homan*

Main category: cs.CL

TL;DR: 本文扩展了DisCo模型，通过整合注释者元数据、增强输入表示和修改损失函数，提高了在模拟注释者分歧任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 学习带分歧（LeWiDi）2025共享任务旨在通过软标签分布预测和视角评估来模拟注释者分歧，而本文的目的是扩展DisCo模型以更好地处理这个问题。

Method: 本文在DisCo模型的基础上进行了扩展，通过整合注释者元数据、增强输入表示和修改损失函数来更好地捕捉不一致模式。

Result: 通过广泛的实验，在三个数据集上，本文提出的DisCo模型在软标签和视角评估指标上都取得了实质性的改进。

Conclusion: DisCo模型的扩展通过整合注释者元数据、增强输入表示和修改损失函数，在捕捉不一致模式方面取得了显著改进，并在三个数据集的软标签和视角评估指标上均有提升。

Abstract: The Learning With Disagreements (LeWiDi) 2025 shared task is to model
annotator disagreement through soft label distribution prediction and
perspectivist evaluation, modeling annotators. We adapt DisCo (Distribution
from Context), a neural architecture that jointly models item-level and
annotator-level label distributions, and present detailed analysis and
improvements. In this paper, we extend the DisCo by incorporating annotator
metadata, enhancing input representations, and modifying the loss functions to
capture disagreement patterns better. Through extensive experiments, we
demonstrate substantial improvements in both soft and perspectivist evaluation
metrics across three datasets. We also conduct in-depth error and calibration
analyses, highlighting the conditions under which improvements occur. Our
findings underscore the value of disagreement-aware modeling and offer insights
into how system components interact with the complexity of human-annotated
data.

</details>


### [311] [Efficient Speculative Decoding for Llama at Scale: Challenges and Solutions](https://arxiv.org/abs/2508.08192)
*Bangsheng Tang,Carl Chengyan Fu,Fei Kou,Grigory Sizov,Haoci Zhang,Jason Park,Jiawen Liu,Jie You,Qirui Yang,Sachin Mehta,Shengyong Cai,Xiaodong Wang,Xingyu Liu,Yunlu Li,Yanjun Zhou,Wei Wei,Zhiwei Zhao,Zixi Qi,Adolfo Victoria,Aya Ibrahim,Bram Wasti,Changkyu Kim,Daniel Haziza,Fei Sun,Giancarlo Delfin,Emily Guo,Jialin Ouyang,Jaewon Lee,Jianyu Huang,Jeremy Reizenstein,Lu Fang,Quinn Zhu,Ria Verma,Vlad Mihailescu,Xingwen Guo,Yan Cui,Ye Hu,Yejin Lee*

Main category: cs.CL

TL;DR: Speculative decoding optimizations for Llama models (EAGLE) achieve state-of-the-art inference speed, significantly reducing latency and improving throughput for large batch sizes on GPUs.


<details>
  <summary>Details</summary>
Motivation: To address the engineering challenges of scaling speculative decoding for production environments, particularly the efficient implementation of various operations on GPUs.

Method: The paper details training and inference optimization techniques implemented to enable EAGLE-based speculative decoding at a production scale for Llama models, focusing on efficient implementation of operations like tree attention and multi-round speculative decoding on GPUs.

Result: Achieved new state-of-the-art inference latency for Llama models. Llama4 Maverick decodes at ~4 ms/token (batch size 1) on 8 NVIDIA H100 GPUs, 10% faster than previous best. EAGLE-based speculative decoding achieved 1.4x-2.0x speed-up for large batch sizes at production scale.

Conclusion: EAGLE-based speculative decoding at a production scale for Llama models has achieved a new state-of-the-art inference latency, with Llama4 Maverick decoding at about 4 ms per token on 8 NVIDIA H100 GPUs (10% faster than previous methods) and EAGLE-based speculative decoding achieving a 1.4x to 2.0x speed-up for large batch sizes.

Abstract: Speculative decoding is a standard method for accelerating the inference
speed of large language models. However, scaling it for production environments
poses several engineering challenges, including efficiently implementing
different operations (e.g., tree attention and multi-round speculative
decoding) on GPU. In this paper, we detail the training and inference
optimization techniques that we have implemented to enable EAGLE-based
speculative decoding at a production scale for Llama models. With these
changes, we achieve a new state-of-the-art inference latency for Llama models.
For example, Llama4 Maverick decodes at a speed of about 4 ms per token (with a
batch size of one) on 8 NVIDIA H100 GPUs, which is 10% faster than the
previously best known method. Furthermore, for EAGLE-based speculative
decoding, our optimizations enable us to achieve a speed-up for large batch
sizes between 1.4x and 2.0x at production scale.

</details>


### [312] [Human-Alignment and Calibration of Inference-Time Uncertainty in Large Language Models](https://arxiv.org/abs/2508.08204)
*Kyle Moore,Jesse Roberts,Daryl Watson*

Main category: cs.CL

TL;DR: 评估LLM的不确定性校准。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在[不]确定性校准以促进模型控制和调节用户信任。

Method: 我们评估了一系列推理时[不]确定性度量，使用已建立的度量和新颖的变体，以确定它们与人类的[不]确定性以及模型校准的传统观念的匹配程度。

Result: 我们发现，许多度量标准都显示出与人类不确定性高度一致的证据。

Conclusion: 许多模型在正确性相关性和分布分析两方面都显示出与人类不确定性的良好匹配，即使在不匹配人类答案偏好的情况下也是如此。

Abstract: There has been much recent interest in evaluating large language models for
uncertainty calibration to facilitate model control and modulate user trust.
Inference time uncertainty, which may provide a real-time signal to the model
or external control modules, is particularly important for applying these
concepts to improve LLM-user experience in practice. While many of the existing
papers consider model calibration, comparatively little work has sought to
evaluate how closely model uncertainty aligns to human uncertainty. In this
work, we evaluate a collection of inference-time uncertainty measures, using
both established metrics and novel variations, to determine how closely they
align with both human group-level uncertainty and traditional notions of model
calibration. We find that numerous measures show evidence of strong alignment
to human uncertainty, even despite the lack of alignment to human answer
preference. For those successful metrics, we find moderate to strong evidence
of model calibration in terms of both correctness correlation and
distributional analysis.

</details>


### [313] [SAEMark: Multi-bit LLM Watermarking with Inference-Time Scaling](https://arxiv.org/abs/2508.08211)
*Zhuohao Yu,Xingru Jiang,Weizheng Gu,Yidong Wang,Shikun Zhang,Wei Ye*

Main category: cs.CL

TL;DR: SAEMark 是一种新的 LLM 水印框架，可在不影响文本质量或需要模型访问的情况下，通过事后拒绝采样嵌入多位信息，从而实现内容归属。


<details>
  <summary>Details</summary>
Motivation: LLM 生成文本的水印对于内容归属和错误信息预防至关重要，但现有方法会影响文本质量、需要白盒模型访问和 logits 操作，这使得它们不适用于 API 模型和多语言场景。

Method: SAEMark 是一种通用的、用于事后多位水印的框架，仅通过推理时、基于特征的拒绝采样来实现个性化消息嵌入，而不改变模型 logits 或需要训练。该框架通过采样 LLM 输出而不是修改输出来保持文本质量，并确保跨语言和域的通用性。

Result: SAEMark 在英语上的 F1 分数为 99.7%，并实现了强大的多位检测精度，在 4 个数据集上的实验表明 SAEMark 性能一致，实现了优于现有方法的检测精度和文本质量。

Conclusion: SAEMark 建立了一种可扩展的、开箱即用的水印新范式，适用于闭源 LLM，并支持内容归属。

Abstract: Watermarking LLM-generated text is critical for content attribution and
misinformation prevention. However, existing methods compromise text quality,
require white-box model access and logit manipulation. These limitations
exclude API-based models and multilingual scenarios. We propose SAEMark, a
general framework for post-hoc multi-bit watermarking that embeds personalized
messages solely via inference-time, feature-based rejection sampling without
altering model logits or requiring training. Our approach operates on
deterministic features extracted from generated text, selecting outputs whose
feature statistics align with key-derived targets. This framework naturally
generalizes across languages and domains while preserving text quality through
sampling LLM outputs instead of modifying. We provide theoretical guarantees
relating watermark success probability and compute budget that hold for any
suitable feature extractor. Empirically, we demonstrate the framework's
effectiveness using Sparse Autoencoders (SAEs), achieving superior detection
accuracy and text quality. Experiments across 4 datasets show SAEMark's
consistent performance, with 99.7% F1 on English and strong multi-bit detection
accuracy. SAEMark establishes a new paradigm for scalable watermarking that
works out-of-the-box with closed-source LLMs while enabling content
attribution.

</details>


### [314] [Capabilities of GPT-5 on Multimodal Medical Reasoning](https://arxiv.org/abs/2508.08224)
*Shansong Wang,Mingzhe Hu,Qiang Li,Mojtaba Safari,Xiaofeng Yang*

Main category: cs.CL

TL;DR: GPT-5在医学多模态推理任务上表现出色，超越了GPT-4o和人类专家。


<details>
  <summary>Details</summary>
Motivation: 为了评估大型语言模型（LLM）在医学领域进行复杂推理和整合异构信息源（如患者叙述、结构化数据和医学图像）以支持决策的能力。

Method: 本研究将GPT-5、GPT-5-mini、GPT-5-nano和GPT-4o-2024-11-20作为通用多模态推理器，在文本问答和视觉问答任务上，使用统一协议系统性地评估了它们在零样本链式思考方面的表现。

Result: GPT-5在所有问答基准测试中持续优于所有基线模型，达到了最先进的准确率，并在多模态推理方面取得了显著的提升。具体而言，在MedXpertQA MM任务上，GPT-5的推理和理解得分分别比GPT-4o高出29.62%和36.18%，并且在推理和理解方面分别超越了预授权的人类专家24.23%和29.40%。GPT-4o在大多数维度上仍低于人类专家的表现。

Conclusion: GPT-5在医学领域的多模态推理能力超越了现有模型和人类专家水平，为未来临床决策支持系统的设计提供了重要参考。

Abstract: Recent advances in large language models (LLMs) have enabled general-purpose
systems to perform increasingly complex domain-specific reasoning without
extensive fine-tuning. In the medical domain, decision-making often requires
integrating heterogeneous information sources, including patient narratives,
structured data, and medical images. This study positions GPT-5 as a generalist
multimodal reasoner for medical decision support and systematically evaluates
its zero-shot chain-of-thought reasoning performance on both text-based
question answering and visual question answering tasks under a unified
protocol. We benchmark GPT-5, GPT-5-mini, GPT-5-nano, and GPT-4o-2024-11-20
against standardized splits of MedQA, MedXpertQA (text and multimodal), MMLU
medical subsets, USMLE self-assessment exams, and VQA-RAD. Results show that
GPT-5 consistently outperforms all baselines, achieving state-of-the-art
accuracy across all QA benchmarks and delivering substantial gains in
multimodal reasoning. On MedXpertQA MM, GPT-5 improves reasoning and
understanding scores by +29.62% and +36.18% over GPT-4o, respectively, and
surpasses pre-licensed human experts by +24.23% in reasoning and +29.40% in
understanding. In contrast, GPT-4o remains below human expert performance in
most dimensions. A representative case study demonstrates GPT-5's ability to
integrate visual and textual cues into a coherent diagnostic reasoning chain,
recommending appropriate high-stakes interventions. Our results show that, on
these controlled multimodal reasoning benchmarks, GPT-5 moves from
human-comparable to above human-expert performance. This improvement may
substantially inform the design of future clinical decision-support systems.

</details>


### [315] [Exploring Safety Alignment Evaluation of LLMs in Chinese Mental Health Dialogues via LLM-as-Judge](https://arxiv.org/abs/2508.08236)
*Yunna Cai,Fan Wang,Haowei Wang,Kun Wang,Kailai Yang,Sophia Ananiadou,Moyan Li,Mingming Fan*

Main category: cs.CL

TL;DR: PsyCrisis-Bench是一个新的中文心理健康对话安全评估基准，使用LLM-as-Judge方法和专家定义的推理链进行评估，无需参考答案，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在网络心理健康对话中的安全对齐是困难的，因为缺乏黄金标准答案且这些交互涉及伦理敏感性。

Method: 提出PsyCrisis-Bench，一个基于真实世界中文心理健康对话的无参考评估基准。该方法采用基于提示的LLM-as-Judge方法，使用专家定义的、基于心理干预原则的推理链进行上下文评估，并通过多个安全维度进行二元点状评分，以增强可解释性和可追溯性。

Result: 实验表明，该方法在3600次判断中，与专家评估的一致性最高，并能产生更具可解释性的评估理由。

Conclusion: PsyCrisis-Bench 在专家评估方面实现了最高的一致性，并能产生比现有方法更具可解释性的评估理由。该数据集和评估工具可公开获取，以促进未来的研究。

Abstract: Evaluating the safety alignment of LLM responses in high-risk mental health
dialogues is particularly difficult due to missing gold-standard answers and
the ethically sensitive nature of these interactions. To address this
challenge, we propose PsyCrisis-Bench, a reference-free evaluation benchmark
based on real-world Chinese mental health dialogues. It evaluates whether the
model responses align with the safety principles defined by experts.
Specifically designed for settings without standard references, our method
adopts a prompt-based LLM-as-Judge approach that conducts in-context evaluation
using expert-defined reasoning chains grounded in psychological intervention
principles. We employ binary point-wise scoring across multiple safety
dimensions to enhance the explainability and traceability of the evaluation.
Additionally, we present a manually curated, high-quality Chinese-language
dataset covering self-harm, suicidal ideation, and existential distress,
derived from real-world online discourse. Experiments on 3600 judgments show
that our method achieves the highest agreement with expert assessments and
produces more interpretable evaluation rationales compared to existing
approaches. Our dataset and evaluation tool are publicly available to
facilitate further research.

</details>


### [316] [Jinx: Unlimited LLMs for Probing Alignment Failures](https://arxiv.org/abs/2508.08243)
*Jiahao Zhao,Liwei Dong*

Main category: cs.CL

TL;DR: Jinx 是一个无限制的语言模型，可用于研究语言模型的安全问题。


<details>
  <summary>Details</summary>
Motivation: 需要为研究社区提供一个无限制的语言模型，以用于红队测试、对齐评估和研究安全故障模式。

Method: Jinx 是通过移除安全对齐约束并保留基础模型能力来创建的。

Result: Jinx 能够响应所有查询，没有拒绝或安全过滤，同时保留了基础模型的推理和指令遵循能力。

Conclusion: Jinx 的发布为研究社区提供了一个有价值的资源，用于评估语言模型的安全边界和系统地研究其故障模式。

Abstract: Unlimited, or so-called helpful-only language models are trained without
safety alignment constraints and never refuse user queries. They are widely
used by leading AI companies as internal tools for red teaming and alignment
evaluation. For example, if a safety-aligned model produces harmful outputs
similar to an unlimited model, this indicates alignment failures that require
further attention. Despite their essential role in assessing alignment, such
models are not available to the research community.
  We introduce Jinx, a helpful-only variant of popular open-weight LLMs. Jinx
responds to all queries without refusals or safety filtering, while preserving
the base model's capabilities in reasoning and instruction following. It
provides researchers with an accessible tool for probing alignment failures,
evaluating safety boundaries, and systematically studying failure modes in
language model safety.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [317] [Fractal Language Modelling by Universal Sequence Maps (USM)](https://arxiv.org/abs/2508.06641)
*Jonas S Almeida,Daniel E Russ,Susana Vinga,Ines Duarte,Lee Mason,Praphulla Bhawsar,Aaron Ge,Arlindo Oliveira,Jeya Balaji Balasubramanian*

Main category: cs.LG

TL;DR: USM是一种新的序列编码方法，可以解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 随着ChatGPT等包含Transformer的语言模型的出现，人们对探索能够以多尺度和嵌入维度在数值上表示符号序列的编码过程产生了新的兴趣。

Method: USM由两个CGR组成，可以迭代地进行前向和后向运算，并将它们投影到频域（FCGR）。

Result: 1）数字定位与序列同一性的完全协调；2）揭示了USM作为一种有效的数值过程，该过程收敛于稳定的序列嵌入解决方案。

Conclusion: USM是一种高效的数值过程，可以收敛到稳定的序列嵌入解决方案。此外，USM的分析揭示了其作为一种高效的数值过程的本质，该过程可以收敛到稳定的序列嵌入解决方案。

Abstract: Motivation: With the advent of Language Models using Transformers,
popularized by ChatGPT, there is a renewed interest in exploring encoding
procedures that numerically represent symbolic sequences at multiple scales and
embedding dimensions. The challenge that encoding addresses is the need for
mechanisms that uniquely retain contextual information about the succession of
individual symbols, which can then be modeled by nonlinear formulations such as
neural networks.
  Context: Universal Sequence Maps(USM) are iterated functions that bijectively
encode symbolic sequences onto embedded numerical spaces. USM is composed of
two Chaos Game Representations (CGR), iterated forwardly and backwardly, that
can be projected into the frequency domain (FCGR). The corresponding USM
coordinates can be used to compute a Chebyshev distance metric as well as k-mer
frequencies, without having to recompute the embedded numeric coordinates, and,
paradoxically, allowing for non-integers values of k.
  Results: This report advances the bijective fractal encoding by Universal
Sequence Maps (USM) by resolving seeding biases affecting the iterated process.
The resolution had two results, the first expected, the second an intriguing
outcome: 1) full reconciliation of numeric positioning with sequence identity;
and 2) uncovering the nature of USM as an efficient numeric process converging
towards a steady state sequence embedding solution. We illustrate these results
for genomic sequences because of the convenience of a planar representation
defined by an alphabet with only 4 tokens (the 4 nucleotides). Nevertheless,
the application to alphabet of arbitrary cardinality was found to be
straightforward.

</details>


### [318] [Structure-Preserving Digital Twins via Conditional Neural Whitney Forms](https://arxiv.org/abs/2508.06981)
*Brooks Kinch,Benjamin Shaffer,Elizabeth Armstrong,Michael Meehan,John Hewson,Nathaniel Trask*

Main category: cs.LG

TL;DR: 提出一种基于FEEC和条件注意力机制的降阶有限元模型框架，用于构建可实时校准的数字孪生，在稀疏数据和复杂几何下表现优异，速度提升巨大。


<details>
  <summary>Details</summary>
Motivation: 为了在复杂几何和稀疏数据条件下，实现对物理过程的高精度、实时数字孪生构建，以支持闭环推断和校准。

Method: 提出了一种基于结构保持降阶有限元模型（受隐变量Z的条件约束）来构建实时数字孪生的框架。该方法利用条件注意力机制，在有限元外微积分（FEEC）框架内学习降阶有限元基和非线性守恒律，从而保证了数值适定性和守恒量的精确保持。该条件机制支持对参数变量的实时校准，能够构建支持闭环推断和传感器数据校准的数字孪生。该框架以非侵入方式与传统的有限元机械设备接口，能够处理复杂几何形状并将学习模型与传统有限元技术相结合。

Result: 该方法在包含对流扩散、激波水动力学、静电学和电池热失控等基准测试中，能在稀疏数据（25个LES模拟）下对复杂几何形状进行准确预测，包括捕捉湍流转变，并实现约0.1秒的实时推断，相比于LES有3.1x10^8的加速比。

Conclusion: 该框架能够以极高的精度和效率构建数字孪生，适用于多种物理模拟，并能实现实时推断和校准。

Abstract: We present a framework for constructing real-time digital twins based on
structure-preserving reduced finite element models conditioned on a latent
variable Z. The approach uses conditional attention mechanisms to learn both a
reduced finite element basis and a nonlinear conservation law within the
framework of finite element exterior calculus (FEEC). This guarantees numerical
well-posedness and exact preservation of conserved quantities, regardless of
data sparsity or optimization error. The conditioning mechanism supports
real-time calibration to parametric variables, allowing the construction of
digital twins which support closed loop inference and calibration to sensor
data. The framework interfaces with conventional finite element machinery in a
non-invasive manner, allowing treatment of complex geometries and integration
of learned models with conventional finite element techniques.
  Benchmarks include advection diffusion, shock hydrodynamics, electrostatics,
and a complex battery thermal runaway problem. The method achieves accurate
predictions on complex geometries with sparse data (25 LES simulations),
including capturing the transition to turbulence and achieving real-time
inference ~0.1s with a speedup of 3.1x10^8 relative to LES. An open-source
implementation is available on GitHub.

</details>


### [319] [SGD Convergence under Stepsize Shrinkage in Low-Precision Training](https://arxiv.org/abs/2508.07142)
*Vincent-Daniel Yun*

Main category: cs.LG

TL;DR: 低精度训练会降低SGD的收敛速度并增加误差


<details>
  <summary>Details</summary>
Motivation: 低精度训练对于降低大规模深度学习的计算和内存成本至关重要，但量化梯度会引入量值收缩和加性噪声，从而改变SGD的收敛行为

Method: 提出梯度收缩模型，将低精度SGD的收敛性分析纳入标准SGD框架，证明了低精度SGD的收敛性，并分析了精度降低对收敛速度和误差的影响

Result: 证明了低精度SGD在标准平滑和有界方差假设下仍然收敛，但收敛速度降低（由q_min决定），并且由于量化噪声导致渐近误差地板增加

Conclusion: 低精度SGD虽然收敛，但收敛速度降低，渐近误差增加

Abstract: Low-precision training has become essential for reducing the computational
and memory costs of large-scale deep learning. However, quantization of
gradients introduces both magnitude shrinkage and additive noise, which can
alter the convergence behavior of stochastic gradient descent (SGD). In this
work, we study the convergence of SGD under a gradient shrinkage model, where
each stochastic gradient is scaled by a factor $q_k \in (0,1]$ and perturbed by
zero-mean quantization noise. We show that this shrinkage is equivalent to
replacing the nominal stepsize $\mu_k$ with an effective stepsize $\mu_k q_k$,
which slows convergence when $q_{\min} < 1$. Under standard smoothness and
bounded-variance assumptions, we prove that low-precision SGD still converges,
but at a reduced rate determined by $q_{\min}$, and with an increased
asymptotic error floor due to quantization noise. We theoretically analyze how
reduced numerical precision slows down training by modeling it as gradient
shrinkage in the standard SGD convergence framework.

</details>


### [320] [Self-Organizing Survival Manifolds: A Theory for Unsupervised Discovery of Prognostic Structures in Biological Systems](https://arxiv.org/abs/2508.06539)
*Atahan Karagoz*

Main category: cs.LG

TL;DR: 生存不再是监督学习任务，而是生物状态空间几何的涌现属性。该研究提出了自组织生存流形（SOSM）理论，将生存建模与物理定律（如热力学效率、熵流、Ricci曲率和最优输运）联系起来，并将健康、疾病、衰老和死亡视为流形结构的几何相变。


<details>
  <summary>Details</summary>
Motivation: 该研究挑战了传统的将生存视为依赖于结果标签和固定协变量的监督学习任务的观点，提出生存是生物状态空间内在曲率和流动的几何后果，是一种涌现属性。

Method: 提出了一种自组织生存流形（SOSM）的理论，其中生存相关的动力学源于潜在流形上由内部生物约束塑造的低曲率测地线流。引入了基于测地线曲率最小化的生存能量泛函，并证明了它可以诱导预后与几何流稳定性相一致的结构。推导了目标函数的离散和连续形式，并证明了在生物学合理条件下生存轨迹的出现和收敛的理论结果。

Result: 生存能量泛函基于测地线曲率最小化，诱导出预后与几何流稳定性相一致的结构。理论结果证明了在生物学合理条件下，生存轨迹的出现和收敛。

Conclusion: 该理论将健康、疾病、衰老和死亡重新定义为生物状态空间流形结构中的几何相变，为生存建模提供了一个不依赖标签的通用基础，将机器学习、生物物理学和生命几何学联系起来。

Abstract: Survival is traditionally modeled as a supervised learning task, reliant on
curated outcome labels and fixed covariates. This work rejects that premise. It
proposes that survival is not an externally annotated target but a geometric
consequence: an emergent property of the curvature and flow inherent in
biological state space. We develop a theory of Self-Organizing Survival
Manifolds (SOSM), in which survival-relevant dynamics arise from low-curvature
geodesic flows on latent manifolds shaped by internal biological constraints. A
survival energy functional based on geodesic curvature minimization is
introduced and shown to induce structures where prognosis aligns with geometric
flow stability. We derive discrete and continuous formulations of the objective
and prove theoretical results demonstrating the emergence and convergence of
survival-aligned trajectories under biologically plausible conditions. The
framework draws connections to thermodynamic efficiency, entropy flow, Ricci
curvature, and optimal transport, grounding survival modeling in physical law.
Health, disease, aging, and death are reframed as geometric phase transitions
in the manifold's structure. This theory offers a universal, label-free
foundation for modeling survival as a property of form, not annotation-bridging
machine learning, biophysics, and the geometry of life itself.

</details>


### [321] [Semi-Supervised Supply Chain Fraud Detection with Unsupervised Pre-Filtering](https://arxiv.org/abs/2508.06574)
*Fatemeh Moradi,Mehran Tarif,Mohammadhossein Homaei*

Main category: cs.LG

TL;DR: 一种结合了无监督异常检测（Isolation Forest）和半监督学习（自训练SVM）的两阶段框架，用于解决供应链欺诈检测中的数据稀疏和类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现代供应链欺诈检测面临数据稀疏和类别不平衡的挑战，传统方法受限于有限的监督，因此需要新的解决方案。

Method: 该研究提出了一个两阶段学习框架：第一阶段使用Isolation Forest算法进行无监督异常检测，识别潜在欺诈；第二阶段使用自训练支持向量机（SVM）结合标记和高可信度伪标记样本进行半监督学习。

Result: 在DataCo Smart Supply Chain Dataset上的实验结果显示，该方法达到了0.817的F1分数，并将误报率控制在3.0%以下。

Conclusion: 该研究提出了一个结合无监督预过滤和半监督改进的供应链欺诈检测方法，在实际应用中有效且高效。

Abstract: Detecting fraud in modern supply chains is a growing challenge, driven by the
complexity of global networks and the scarcity of labeled data. Traditional
detection methods often struggle with class imbalance and limited supervision,
reducing their effectiveness in real-world applications. This paper proposes a
novel two-phase learning framework to address these challenges. In the first
phase, the Isolation Forest algorithm performs unsupervised anomaly detection
to identify potential fraud cases and reduce the volume of data requiring
further analysis. In the second phase, a self-training Support Vector Machine
(SVM) refines the predictions using both labeled and high-confidence
pseudo-labeled samples, enabling robust semi-supervised learning. The proposed
method is evaluated on the DataCo Smart Supply Chain Dataset, a comprehensive
real-world supply chain dataset with fraud indicators. It achieves an F1-score
of 0.817 while maintaining a false positive rate below 3.0%. These results
demonstrate the effectiveness and efficiency of combining unsupervised
pre-filtering with semi-supervised refinement for supply chain fraud detection
under real-world constraints, though we acknowledge limitations regarding
concept drift and the need for comparison with deep learning approaches.

</details>


### [322] [GFlowNets for Learning Better Drug-Drug Interaction Representations](https://arxiv.org/abs/2508.06576)
*Azmine Toushik Wasi*

Main category: cs.LG

TL;DR: 通过GFlowNet和VGAE生成合成样本来解决DDI预测中的类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 药物-药物相互作用（DDI）的类别不平衡问题，特别是罕见但关键的相互作用样本不足，导致预测模型在该类别的表现不佳。

Method: 提出了一种结合生成流网络（GFlowNet）和变分图自编码器（VGAE）的框架，用于生成罕见类别的合成样本。

Result: 生成的合成样本有助于改善模型平衡，提高对罕见类别的预测性能，并能生成有效且新颖的DDI对，从而提升了跨相互作用类型的预测性能和临床可靠性。

Conclusion: 通过结合生成流网络（GFlowNet）和变分图自编码器（VGAE），提出了一种生成合成样本以解决罕见类别不足问题的框架，从而提高了模型的平衡性和预测性能，增强了临床可靠性。

Abstract: Drug-drug interactions pose a significant challenge in clinical pharmacology,
with severe class imbalance among interaction types limiting the effectiveness
of predictive models. Common interactions dominate datasets, while rare but
critical interactions remain underrepresented, leading to poor model
performance on infrequent cases. Existing methods often treat DDI prediction as
a binary problem, ignoring class-specific nuances and exacerbating bias toward
frequent interactions. To address this, we propose a framework combining
Generative Flow Networks (GFlowNet) with Variational Graph Autoencoders (VGAE)
to generate synthetic samples for rare classes, improving model balance and
generate effective and novel DDI pairs. Our approach enhances predictive
performance across interaction types, ensuring better clinical reliability.

</details>


### [323] [Hypergraph Neural Network with State Space Models for Node Classification](https://arxiv.org/abs/2508.06587)
*A. Quadir,M. Tanveer*

Main category: cs.LG

TL;DR: HGMN是一种新颖的超图神经网络，通过结合基于角色的特征、状态空间模型和超图结构，提升了GNN在节点分类任务上的表现，有效解决了传统GNN忽略角色信息和表现不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 传统的GNN在节点分类任务中虽然受到关注，但主要侧重于节点间的邻接关系，忽略了对学习更有表现力的节点表示至关重要的基于角色的特征。现有的捕获基于角色特征的方法主要是无监督的，并且在下游任务中的表现不佳。

Method: 提出了一种新颖的超图神经网络（HGMN），它结合了基于角色的表示、状态空间模型、超图构建技术（基于节点度和邻域级别）、可学习的mamba transformer机制以及残差网络，以处理高阶关系、捕获复杂依赖并缓解过平滑问题。

Result: HGMN在节点分类任务上取得了显著的性能提升，与最先进的GNN方法相比，在新引入的数据集和四个基准数据集上均表现出优越性。

Conclusion: HGMN通过有效融合基于角色的特征和邻接信息，提供了更丰富的节点表示，在节点分类任务上超越了最先进的GNN方法，展示了其在各种基于图的学习应用中的通用性和强大能力。

Abstract: In recent years, graph neural networks (GNNs) have gained significant
attention for node classification tasks on graph-structured data. However,
traditional GNNs primarily focus on adjacency relationships between nodes,
often overlooking the rich role-based characteristics that are crucial for
learning more expressive node representations. Existing methods for capturing
role-based features are largely unsupervised and fail to achieve optimal
performance in downstream tasks. To address these limitations, we propose a
novel hypergraph neural network with state space model (HGMN) that effectively
integrates role-aware representations into GNNs and the state space model. HGMN
utilizes hypergraph construction techniques to model higher-order relationships
and combines role-based and adjacency-based representations through a learnable
mamba transformer mechanism. By leveraging two distinct hypergraph construction
methods-based on node degree and neighborhood levels, it strengthens the
connections among nodes with similar roles, enhancing the model's
representational power. Additionally, the inclusion of hypergraph convolution
layers enables the model to capture complex dependencies within hypergraph
structures. To mitigate the over-smoothing problem inherent in deep GNNs, we
incorporate a residual network, ensuring improved stability and better feature
propagation across layers. Extensive experiments conducted on one newly
introduced dataset and four benchmark datasets demonstrate the superiority of
HGMN. The model achieves significant performance improvements on node
classification tasks compared to state-of-the-art GNN methods. These results
highlight HGMN's ability to provide enriched node representations by
effectively embedding role-based features alongside adjacency information,
making it a versatile and powerful tool for a variety of graph-based learning
applications.

</details>


### [324] [Graph is a Natural Regularization: Revisiting Vector Quantization for Graph Representation Learning](https://arxiv.org/abs/2508.06588)
*Zian Zhai,Fan Li,Xingyu Tan,Xiaoyang Wang,Wenjie Zhang*

Main category: cs.LG

TL;DR: 图VQ存在码本坍塌问题，RGVQ框架通过软分配和结构感知对比正则化解决了此问题，提升了图表示的学习效果。


<details>
  <summary>Details</summary>
Motivation: 为解决图数据上的向量量化（VQ）中存在的码本坍塌问题，该研究旨在提高图标记的表达能力和泛化能力。

Method: RGVQ框架通过Gumbel-Softmax重参数化引入软分配，确保所有码字都能接收到梯度更新，并通过结构感知对比正则化来惩罚相似节点对之间的标记共分配。

Result: 实验证明，RGVQ显著提高了码本利用率，并持续提升了最先进的图VQ骨干网络在多个下游任务上的性能。

Conclusion: RGVQ通过整合图拓扑和特征相似性作为显式正则化信号，增强了码本利用率并促进了标记多样性，从而在多个下游任务中显著提高了最先进的图VQ骨干网络的性能，实现了更具表现力和可迁移性的图标记表示。

Abstract: Vector Quantization (VQ) has recently emerged as a promising approach for
learning discrete representations of graph-structured data. However, a
fundamental challenge, i.e., codebook collapse, remains underexplored in the
graph domain, significantly limiting the expressiveness and generalization of
graph tokens.In this paper, we present the first empirical study showing that
codebook collapse consistently occurs when applying VQ to graph data, even with
mitigation strategies proposed in vision or language domains. To understand why
graph VQ is particularly vulnerable to collapse, we provide a theoretical
analysis and identify two key factors: early assignment imbalances caused by
redundancy in graph features and structural patterns, and self-reinforcing
optimization loops in deterministic VQ. To address these issues, we propose
RGVQ, a novel framework that integrates graph topology and feature similarity
as explicit regularization signals to enhance codebook utilization and promote
token diversity. RGVQ introduces soft assignments via Gumbel-Softmax
reparameterization, ensuring that all codewords receive gradient updates. In
addition, RGVQ incorporates a structure-aware contrastive regularization to
penalize the token co-assignments among similar node pairs. Extensive
experiments demonstrate that RGVQ substantially improves codebook utilization
and consistently boosts the performance of state-of-the-art graph VQ backbones
across multiple downstream tasks, enabling more expressive and transferable
graph token representations.

</details>


### [325] [ELF: Efficient Logic Synthesis by Pruning Redundancy in Refactoring](https://arxiv.org/abs/2508.08073)
*Dimitris Tsaras,Xing Li,Lei Chen,Zhiyao Xie,Mingxuan Yuan*

Main category: cs.LG

TL;DR: 通过使用分类器来修剪不成功的切割，可以提高逻辑优化的效率和速度。


<details>
  <summary>Details</summary>
Motivation: 逻辑优化算子在最小化逻辑电路的门数方面起着至关重要的作用，但其计算成本很高。过去的优化方法往往效率低下，平均有 98% 的情况会失败。

Method: 利用分类器来预先修剪不成功的切割，以消除不必要的再合成操作。

Result: 在 EPFL 基准套件和 10 个大型工业设计上使用重构算子进行的实验表明，与最先进的 ABC 实现相比，该技术平均可将逻辑优化速度提高 3.9 倍。

Conclusion: 通过使用分类器预先修剪不成功的切割，可以消除不必要的再合成操作，从而加速逻辑优化。

Abstract: In electronic design automation, logic optimization operators play a crucial
role in minimizing the gate count of logic circuits. However, their computation
demands are high. Operators such as refactor conventionally form iterative cuts
for each node, striving for a more compact representation - a task which often
fails 98% on average. Prior research has sought to mitigate computational cost
through parallelization. In contrast, our approach leverages a classifier to
prune unsuccessful cuts preemptively, thus eliminating unnecessary resynthesis
operations. Experiments on the refactor operator using the EPFL benchmark suite
and 10 large industrial designs demonstrate that this technique can speedup
logic optimization by 3.9x on average compared with the state-of-the-art ABC
implementation.

</details>


### [326] [A Federated Learning Framework for Handling Subtype Confounding and Heterogeneity in Large-Scale Neuroimaging Diagnosis](https://arxiv.org/abs/2508.06589)
*Xinglin Zhao,Yanwen Wang,Xiaobo Liu,Yanrong Hao,Rui Cao,Xin Wen*

Main category: cs.LG

TL;DR: 提出了一种新颖的联邦学习框架，通过动态导航和元集成模块解决神经影像CAD系统中的数据异质性和亚型混淆问题，提高了诊断准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了解决小样本研究复现性低以及大规模数据集因包含多种疾病亚型但仅被标记为单一类别而引起的混杂异质性问题。

Method: 提出了一种新颖的联邦学习框架，包含一个动态导航模块（根据潜在亚型表示将样本路由到最合适的局部模型）和一个元集成模块（将来自异构局部模型的预测组合成统一的诊断输出）。

Result: 所提出的框架在跨越多个研究队列的1300多名MDD患者和1100名健康对照者的fMRI数据的数据集上进行了评估。实验结果表明，与传统方法相比，在诊断准确性和鲁棒性方面取得了显著的改进，平均准确率为74.06%。

Conclusion: 该框架通过解决数据异质性和亚型混淆问题，推动了可靠且可复现的神经影像CAD系统，为神经病学和精神病学的个性化医疗和临床决策提供了巨大潜力。

Abstract: Computer-aided diagnosis (CAD) systems play a crucial role in analyzing
neuroimaging data for neurological and psychiatric disorders. However,
small-sample studies suffer from low reproducibility, while large-scale
datasets introduce confounding heterogeneity due to multiple disease subtypes
being labeled under a single category. To address these challenges, we propose
a novel federated learning framework tailored for neuroimaging CAD systems. Our
approach includes a dynamic navigation module that routes samples to the most
suitable local models based on latent subtype representations, and a
meta-integration module that combines predictions from heterogeneous local
models into a unified diagnostic output. We evaluated our framework using a
comprehensive dataset comprising fMRI data from over 1300 MDD patients and 1100
healthy controls across multiple study cohorts. Experimental results
demonstrate significant improvements in diagnostic accuracy and robustness
compared to traditional methods. Specifically, our framework achieved an
average accuracy of 74.06\% across all tested sites, showcasing its
effectiveness in handling subtype heterogeneity and enhancing model
generalizability. Ablation studies further confirmed the importance of both the
dynamic navigation and meta-integration modules in improving performance. By
addressing data heterogeneity and subtype confounding, our framework advances
reliable and reproducible neuroimaging CAD systems, offering significant
potential for personalized medicine and clinical decision-making in neurology
and psychiatry.

</details>


### [327] [Generative Artificial Intelligence Extracts Structure-Function Relationships from Plants for New Materials](https://arxiv.org/abs/2508.06591)
*Rachel K. Luu,Jingyu Deng,Mohammed Shahrudin Ibrahim,Nam-Joon Cho,Ming Dao,Subra Suresh,Markus J. Buehler*

Main category: cs.LG

TL;DR: 通过整合不同学科的文献和先进的AI工具（如BioinspiredLLM、RAG和代理系统），本研究开发了一个框架，用于从植物科学和仿生学中提取见解，以设计和制造新型材料，如可调的、基于花粉的粘合剂，从而展示了AI在材料设计和人机协作中的潜力。


<details>
  <summary>Details</summary>
Motivation: LLM在学科特定实验科学中的应用仍然有限，特别是在材料科学等高度跨学科领域。本研究旨在弥合这一差距，利用生成式AI从不同学科的文献中提取见解并设计材料。

Method: 利用包括微调模型（BioinspiredLLM）、检索增强生成（RAG）、代理系统和分层采样策略在内的一套AI工具，整合了植物科学、仿生学和材料工程等以往未连接领域的文献，以提取结构-属性关系，并将其转化为新型仿生材料。结构化推理协议从单个查询中生成和评估数百个假设。

Result: 从文献中提取了结构-属性关系，并将其转化为新型仿生材料。AI生成的程序、材料设计和机械预测在实验室中得到了验证，成功制造出一种新颖的、基于花粉的、具有可调形态和测量剪切强度的粘合剂。

Conclusion: 该工作展示了AI辅助的构思如何推动现实世界材料设计并实现有效的人机协作，例如通过实验验证了一种新颖的、基于花粉的、具有可调形态和可测量剪切强度的粘合剂，为未来植物源粘合剂的设计奠定了基础。

Abstract: Large language models (LLMs) have reshaped the research landscape by enabling
new approaches to knowledge retrieval and creative ideation. Yet their
application in discipline-specific experimental science, particularly in highly
multi-disciplinary domains like materials science, remains limited. We present
a first-of-its-kind framework that integrates generative AI with literature
from hitherto-unconnected fields such as plant science, biomimetics, and
materials engineering to extract insights and design experiments for materials.
We focus on humidity-responsive systems such as pollen-based materials and
Rhapis excelsa (broadleaf lady palm) leaves, which exhibit self-actuation and
adaptive performance. Using a suite of AI tools, including a fine-tuned model
(BioinspiredLLM), Retrieval-Augmented Generation (RAG), agentic systems, and a
Hierarchical Sampling strategy, we extract structure-property relationships and
translate them into new classes of bioinspired materials. Structured inference
protocols generate and evaluate hundreds of hypotheses from a single query,
surfacing novel and experimentally tractable ideas. We validate our approach
through real-world implementation: LLM-generated procedures, materials designs,
and mechanical predictions were tested in the laboratory, culminating in the
fabrication of a novel pollen-based adhesive with tunable morphology and
measured shear strength, establishing a foundation for future plant-derived
adhesive design. This work demonstrates how AI-assisted ideation can drive
real-world materials design and enable effective human-AI collaboration.

</details>


### [328] [Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs](https://arxiv.org/abs/2508.06601)
*Kyle O'Brien,Stephen Casper,Quentin Anthony,Tomek Korbak,Robert Kirk,Xander Davies,Ishan Mishra,Geoffrey Irving,Yarin Gal,Stella Biderman*

Main category: cs.LG

TL;DR: 通过过滤预训练数据来增强开放权重AI模型对篡改攻击的抵抗力，效果显著，但仍需结合其他防御措施。


<details>
  <summary>Details</summary>
Motivation: 开放权重AI模型虽然具有透明度、开放研究和去中心化访问等优点，但也容易受到篡改攻击，可能导致有害行为。现有的安全微调方法和训练后技术在抵御对抗性微调方面效果有限，因此需要更有效的风险管理方法。

Method: 本研究提出了一种多阶段的数据过滤流水线，用于过滤掉训练数据中关于双重用途的主题，以提高开放权重AI模型对篡改攻击的抵抗力。

Result: 研究发现，通过过滤双重用途主题数据进行预训练的模型，在对抗性微调攻击（高达10,000步和3亿个与生物威胁相关的token）方面表现出很强的抵抗力，效果比现有方法好一个数量级以上，且在不相关的能力方面没有退化。然而，这些模型在利用外部提供的信息（如通过搜索工具）时，仍然可以利用危险知识，表明需要纵深防御的方法。

Conclusion: 本研究表明，在预训练阶段通过数据过滤来管理开放权重AI模型的风险是一种有前途的方法，可以提高模型对对抗性攻击的抵抗能力，但仍需结合其他防御措施。

Abstract: Open-weight AI systems offer unique benefits, including enhanced
transparency, open research, and decentralized access. However, they are
vulnerable to tampering attacks which can efficiently elicit harmful behaviors
by modifying weights or activations. Currently, there is not yet a robust
science of open-weight model risk management. Existing safety fine-tuning
methods and other post-training techniques have struggled to make LLMs
resistant to more than a few dozen steps of adversarial fine-tuning. In this
paper, we investigate whether filtering text about dual-use topics from
training data can prevent unwanted capabilities and serve as a more
tamper-resistant safeguard. We introduce a multi-stage pipeline for scalable
data filtering and show that it offers a tractable and effective method for
minimizing biothreat proxy knowledge in LLMs. We pretrain multiple
6.9B-parameter models from scratch and find that they exhibit substantial
resistance to adversarial fine-tuning attacks on up to 10,000 steps and 300M
tokens of biothreat-related text -- outperforming existing post-training
baselines by over an order of magnitude -- with no observed degradation to
unrelated capabilities. However, while filtered models lack internalized
dangerous knowledge, we find that they can still leverage such information when
it is provided in context (e.g., via search tool augmentation), demonstrating a
need for a defense-in-depth approach. Overall, these findings help to establish
pretraining data curation as a promising layer of defense for open-weight AI
systems.

</details>


### [329] [PANAMA: A Network-Aware MARL Framework for Multi-Agent Path Finding in Digital Twin Ecosystems](https://arxiv.org/abs/2508.06767)
*Arman Dogru,R. Irem Bor-Yaliniz,Nimal Gamini Senarath*

Main category: cs.LG

TL;DR: PANAMA 是一种用于数字孪生和自动化系统的新型多主体路径查找算法，通过优化数据共享和采用 CTDE 框架，提高了准确性、速度和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 随着机器人和自动化系统的规模不断扩大，对高效数据共享框架和鲁棒算法的需求日益增长。本研究旨在探索数据处理在下一代网络中的关键作用，特别是关注数字孪生 (DT) 生态系统中应用程序提供商 (AP) 和网络提供商 (NP) 之间的动态。

Method: 本研究提出了一种名为 PANAMA 的新颖算法，它采用带有优先级不对称的网络感知多主体强化学习 (MARL) 方法，用于多主体路径查找 (MAPF)。该方法利用中心化训练与去中心化执行 (CTDE) 框架和异步 actor-学习器架构，以加速训练并支持自主任务执行。

Result: 通过仿真，PANAMA 算法在路径查找方面的准确性、速度和可扩展性表现优于现有基准。研究还强调了用于可扩展自动化系统的数据共享优化策略，确保了在复杂现实环境中的鲁棒性。

Conclusion: PANAMA 算法在准确性、速度和可扩展性方面均优于现有基准，有效协调了网络感知决策和多主体协同，促进了数字孪生、无线网络和人工智能驱动的自动化之间的协同作用。

Abstract: Digital Twins (DTs) are transforming industries through advanced data
processing and analysis, positioning the world of DTs, Digital World, as a
cornerstone of nextgeneration technologies including embodied AI. As robotics
and automated systems scale, efficient data-sharing frameworks and robust
algorithms become critical. We explore the pivotal role of data handling in
next-gen networks, focusing on dynamics between application and network
providers (AP/NP) in DT ecosystems. We introduce PANAMA, a novel algorithm with
Priority Asymmetry for Network Aware Multi-agent Reinforcement Learning (MARL)
based multi-agent path finding (MAPF). By adopting a Centralized Training with
Decentralized Execution (CTDE) framework and asynchronous actor-learner
architectures, PANAMA accelerates training while enabling autonomous task
execution by embodied AI. Our approach demonstrates superior pathfinding
performance in accuracy, speed, and scalability compared to existing
benchmarks. Through simulations, we highlight optimized data-sharing strategies
for scalable, automated systems, ensuring resilience in complex, real-world
environments. PANAMA bridges the gap between network-aware decision-making and
robust multi-agent coordination, advancing the synergy between DTs, wireless
networks, and AI-driven automation.

</details>


### [330] [Symbolic Quantile Regression for the Interpretable Prediction of Conditional Quantiles](https://arxiv.org/abs/2508.08080)
*Cas Oude Hoekstra,Floris den Hengst*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Symbolic Regression (SR) is a well-established framework for generating
interpretable or white-box predictive models. Although SR has been successfully
applied to create interpretable estimates of the average of the outcome, it is
currently not well understood how it can be used to estimate the relationship
between variables at other points in the distribution of the target variable.
Such estimates of e.g. the median or an extreme value provide a fuller picture
of how predictive variables affect the outcome and are necessary in
high-stakes, safety-critical application domains. This study introduces
Symbolic Quantile Regression (SQR), an approach to predict conditional
quantiles with SR. In an extensive evaluation, we find that SQR outperforms
transparent models and performs comparably to a strong black-box baseline
without compromising transparency. We also show how SQR can be used to explain
differences in the target distribution by comparing models that predict extreme
and central outcomes in an airline fuel usage case study. We conclude that SQR
is suitable for predicting conditional quantiles and understanding interesting
feature influences at varying quantiles.

</details>


### [331] [Neural Logic Networks for Interpretable Classification](https://arxiv.org/abs/2508.08172)
*Vincent Perreault,Katsumi Inoue,Richard Labib,Alain Hertz*

Main category: cs.LG

TL;DR: 神经逻辑网络通过引入NOT操作、偏差和因子化IF-THEN规则，改进了布尔网络发现，并在表格分类（尤其是在医学领域）中实现了可解释的规则学习。


<details>
  <summary>Details</summary>
Motivation: 传统的神经网络虽然具有出色的分类性能，但其学习过程无法被检查、验证或提取。神经逻辑网络则具有可解释的结构，能够学习到输入和输出之间的逻辑机制，并进行AND和OR操作。我们通过引入NOT操作和偏差来泛化这些网络，并结合概念组合的严格逻辑和概率建模来阐述其优势。

Method: 我们提出了一种新颖的因子化IF-THEN规则结构以及一种改进的学习算法。

Result: 我们能够学习到相关的、可解释的规则，尤其是在医学领域的一个例子中，可解释性具有切实的价值。

Conclusion: 我们提出的方法在布尔网络发现方面改进了现有技术，并且能够在表格分类中学习到相关的、可解释的规则，尤其是在医学领域的一个例子中，可解释性具有切实的价值。

Abstract: Traditional neural networks have an impressive classification performance,
but what they learn cannot be inspected, verified or extracted. Neural Logic
Networks on the other hand have an interpretable structure that enables them to
learn a logical mechanism relating the inputs and outputs with AND and OR
operations. We generalize these networks with NOT operations and biases that
take into account unobserved data and develop a rigorous logical and
probabilistic modeling in terms of concept combinations to motivate their use.
We also propose a novel factorized IF-THEN rule structure for the model as well
as a modified learning algorithm. Our method improves the state-of-the-art in
Boolean networks discovery and is able to learn relevant, interpretable rules
in tabular classification, notably on an example from the medical field where
interpretability has tangible value.

</details>


### [332] [Local Diffusion Models and Phases of Data Distributions](https://arxiv.org/abs/2508.06614)
*Fangjun Hu,Guangkuo Liu,Yifan Zhang,Xun Gao*

Main category: cs.LG

TL;DR: 扩散模型可以通过利用数据分布的相变来变得更简单、更高效，其中局部降噪器在远离相变点时可以替代全局降噪器。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型通常忽略了图像等现实世界数据的空间局部结构，并学习计算成本高昂的空间全局得分函数。本研究旨在提出一种新的视角，以开发计算成本更低的局部去噪器，从而提高扩散模型的效率。

Method: 通过定义数据分布相并证明反向去噪过程包含早期平凡相、晚期数据相和快速相变，从而引入了局部去噪器的概念。利用信息论界限（基于条件互信息）来诊断相变，并通过真实数据集上的数值实验进行验证。

Result: 研究结果表明，扩散模型可以采用更简单、更高效的架构。局部神经网络可用于计算远离相变点的得分函数，而全局神经网络仅在相变过渡的狭窄时间间隔内才是必需的。

Conclusion: 该研究提出了基于数据分布相变的新视角，可用于构建计算成本更低、结构更简化的扩散模型。局部降噪器在远离相变点时是有效的，而全局降噪器仅在相变点附近是必需的。此外，该研究还提供了信息论界限来诊断相变，并为生成式人工智能和受物理学启发的神经网络设计开辟了新的研究方向。

Abstract: As a class of generative artificial intelligence frameworks inspired by
statistical physics, diffusion models have shown extraordinary performance in
synthesizing complicated data distributions through a denoising process
gradually guided by score functions. Real-life data, like images, is often
spatially structured in low-dimensional spaces. However, ordinary diffusion
models ignore this local structure and learn spatially global score functions,
which are often computationally expensive. In this work, we introduce a new
perspective on the phases of data distributions, which provides insight into
constructing local denoisers with reduced computational costs. We define two
distributions as belonging to the same data distribution phase if they can be
mutually connected via spatially local operations such as local denoisers.
Then, we show that the reverse denoising process consists of an early trivial
phase and a late data phase, sandwiching a rapid phase transition where local
denoisers must fail. To diagnose such phase transitions, we prove an
information-theoretic bound on the fidelity of local denoisers based on
conditional mutual information, and conduct numerical experiments in a
real-world dataset. This work suggests simpler and more efficient architectures
of diffusion models: far from the phase transition point, we can use small
local neural networks to compute the score function; global neural networks are
only necessary around the narrow time interval of phase transitions. This
result also opens up new directions for studying phases of data distributions,
the broader science of generative artificial intelligence, and guiding the
design of neural networks inspired by physics concepts.

</details>


### [333] [A Physics-informed Deep Operator for Real-Time Freeway Traffic State Estimation](https://arxiv.org/abs/2508.08002)
*Hongxin Yu,Yibing Wang,Fengyue Jin,Meng Zhang,Anni Chen*

Main category: cs.LG

TL;DR: 本研究提出了一种新的交通状态估算方法，该方法基于物理信息深度算子网络（PI-DeepONet），并在实验中取得了优于现有方法的精度。


<details>
  <summary>Details</summary>
Motivation: 为了提高交通状态估算（TSE）的准确性，本研究从数学算子理论的角度，将TSE看作一种将可用测量映射到未测量交通状态变量的算子，并提出了一种新的方法。

Method: 本研究将交通状态估算（TSE）视为一个算子问题，并首次提出使用物理信息深度算子网络（PI-DeepONet）的思想来研究实时高速公路TSE。开发了一个扩展的PI-DeepONet架构，支持2-D数据输入，引入了非线性扩展层、注意力机制和MIMO机制，并专门设计了用于自适应识别交通流模型参数的神经网络。

Result: 在NGSIM和中国某城市快速路数据集上的评估结果表明，该研究提出的基于扩展PI-DeepONet的交通状态估算方法在流量和平均速度的估算精度上优于其他四种基线方法。

Conclusion: 该研究提出的基于扩展PI-DeepONet的交通状态估算器在NGSIM和中国某城市快速路数据集上进行了评估，结果表明其在流量和平均速度的估算精度上优于其他四种基线方法。

Abstract: Traffic state estimation (TSE) falls methodologically into three categories:
model-driven, data-driven, and model-data dual-driven. Model-driven TSE relies
on macroscopic traffic flow models originated from hydrodynamics. Data-driven
TSE leverages historical sensing data and employs statistical models or machine
learning methods to infer traffic state. Model-data dual-driven traffic state
estimation attempts to harness the strengths of both aspects to achieve more
accurate TSE. From the perspective of mathematical operator theory, TSE can be
viewed as a type of operator that maps available measurements of inerested
traffic state into unmeasured traffic state variables in real time. For the
first time this paper proposes to study real-time freeway TSE in the idea of
physics-informed deep operator network (PI-DeepONet), which is an
operator-oriented architecture embedding traffic flow models based on deep
neural networks. The paper has developed an extended architecture from the
original PI-DeepONet. The extended architecture is featured with: (1) the
acceptance of 2-D data input so as to support CNN-based computations; (2) the
introduction of a nonlinear expansion layer, an attention mechanism, and a MIMO
mechanism; (3) dedicated neural network design for adaptive identification of
traffic flow model parameters. A traffic state estimator built on the basis of
this extended PI-DeepONet architecture was evaluated with respect to a short
freeway stretch of NGSIM and a large-scale urban expressway in China, along
with other four baseline TSE methods. The evaluation results demonstrated that
this novel TSE method outperformed the baseline methods with high-precision
estimation results of flow and mean speed.

</details>


### [334] [Generalizing Scaling Laws for Dense and Sparse Large Language Models](https://arxiv.org/abs/2508.06617)
*Md Arafat Hossain,Xingfu Wu,Valerie Taylor,Ali Jannesari*

Main category: cs.LG

TL;DR: New scaling law proposed for efficient training of dense and sparse language models.


<details>
  <summary>Details</summary>
Motivation: The exponential growth in the size and computational cost of language models has motivated research into more efficient training techniques. Optimally predicting model size and allocating resources remains a challenge, with existing scaling laws often being architecture-specific.

Method: The paper revisits existing scaling laws and proposes a generalized scaling law to provide a unified framework applicable to both dense and sparse large language models. The effectiveness of the proposed law is evaluated and compared with existing ones.

Result: The proposed generalized scaling law provides a unified framework for both dense and sparse large language models, demonstrating effectiveness through comparative evaluation.

Conclusion: The paper proposes a generalized scaling law applicable to both dense and sparse large language models, offering a unified framework and demonstrating its effectiveness through evaluation and comparison with existing laws.

Abstract: Over the past few years, the size of language models has grown exponentially,
as has the computational cost to train these large models. This rapid growth
has motivated researchers to develop new techniques aimed at enhancing the
efficiency of the training process. Despite these advancements, optimally
predicting the model size or allocating optimal resources remains a challenge.
Several efforts have addressed the challenge by proposing different scaling
laws, but almost all of them are architecture-specific (dense or sparse). In
this work we revisit existing scaling laws and propose a generalized scaling
law to provide a unified framework that is applicable to both dense and sparse
large language models. We evaluate and compare our proposed scaling law with
existing scaling laws to demonstrate its effectiveness.

</details>


### [335] [Conformal Set-based Human-AI Complementarity with Multiple Experts](https://arxiv.org/abs/2508.06997)
*Helbert Paat,Guohao Shen*

Main category: cs.LG

TL;DR: 本研究提出了一种贪心算法，通过选择相关的专家子集来提高人类专家与AI协作进行图像分类的准确性，尤其是在有多个专家可供选择的情况下。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决现有多专家场景下，如何为每个实例选择最相关的专家子集以辅助分类任务，并探究多专家能从置信预测集中获益的条件。

Method: 提出了一种利用置信预测集进行子集选择的贪心算法，用于从多个专家中识别出对特定实例相关的专家预测子集，并与朴素方法进行对比。

Result: 模拟研究表明，所提出的贪心算法能够选择出接近最优的专家子集，在CIFAR-10H和ImageNet-16H数据集上，通过真实专家预测的实验结果验证了其优于朴素方法的分类性能。

Conclusion: 本研究提出的贪心算法在从多个专家预测中选择相关子集以进行分类任务时，能够达到接近最优的性能，从而在多专家场景下提升分类表现。

Abstract: Decision support systems are designed to assist human experts in
classification tasks by providing conformal prediction sets derived from a
pre-trained model. This human-AI collaboration has demonstrated enhanced
classification performance compared to using either the model or the expert
independently. In this study, we focus on the selection of instance-specific
experts from a pool of multiple human experts, contrasting it with existing
research that typically focuses on single-expert scenarios. We characterize the
conditions under which multiple experts can benefit from the conformal sets.
With the insight that only certain experts may be relevant for each instance,
we explore the problem of subset selection and introduce a greedy algorithm
that utilizes conformal sets to identify the subset of expert predictions that
will be used in classifying an instance. This approach is shown to yield better
performance compared to naive methods for human subset selection. Based on real
expert predictions from the CIFAR-10H and ImageNet-16H datasets, our simulation
study indicates that our proposed greedy algorithm achieves near-optimal
subsets, resulting in improved classification performance among multiple
experts.

</details>


### [336] [Learning to Forget with Information Divergence Reweighted Objectives for Noisy Labels](https://arxiv.org/abs/2508.06622)
*Jeremiah Birrell,Reza Ebrahimi*

Main category: cs.LG

TL;DR: ANTIDOTE是一种新的学习方法，可以在标签噪声下进行学习，其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在标签噪声下学习，标签噪声可能是在训练数据中固有的，或者可能被对手更改。

Method: ANTIDOTE是一种新的目标函数，通过信息散度邻域的松弛来定义，并使用凸对偶重新表述为对抗性训练方法。

Result: ANTIDOTE在实践中是有效的，并且在各种标签噪声的实验中表现优于其他方法。

Conclusion: ANTIDOTE在各种标签噪声（对称、不对称、人工注释和真实世界噪声）的各种级别上都优于其他领先的损失函数，并且时间复杂度接近标准的交叉熵损失。

Abstract: We introduce ANTIDOTE, a new class of objectives for learning under noisy
labels which are defined in terms of a relaxation over an
information-divergence neighborhood. Using convex duality, we provide a
reformulation as an adversarial training method that has similar computational
cost to training with standard cross-entropy loss. We show that our approach
adaptively reduces the influence of the samples with noisy labels during
learning, exhibiting a behavior that is analogous to forgetting those samples.
ANTIDOTE is effective in practical environments where label noise is inherent
in the training data or where an adversary can alter the training labels.
Extensive empirical evaluations on different levels of symmetric, asymmetric,
human annotation, and real-world label noise show that ANTIDOTE outperforms
leading comparable losses in the field and enjoys a time complexity that is
very close to that of the standard cross entropy loss.

</details>


### [337] [Strategic Incentivization for Locally Differentially Private Federated Learning](https://arxiv.org/abs/2508.07138)
*Yashwant Krishna Pagoti,Arunesh Sinha,Shamik Sural*

Main category: cs.LG

TL;DR: This paper uses game theory to balance privacy and accuracy in federated learning. A token system encourages clients to share less noisy data, improving overall model accuracy while maintaining client privacy.


<details>
  <summary>Details</summary>
Motivation: To address the degradation in global model accuracy caused by noise addition in Local Differential Privacy (LDP) used in Federated Learning (FL) for privacy protection, and to incentivize clients to add a lower degree of noise.

Method: The paper models the privacy-accuracy trade-off as a game with a token-based incentivization mechanism. It identifies players, actions, and payoffs, and performs a strategic analysis. Experiments are used to study the impact of different parameters.

Result: A token-based incentivization mechanism is introduced where the number of tokens credited to a client is a function of the perturbation degree of its gradients. Clients need enough tokens to access updated global models. The study analyzes the game strategically and through experiments.

Conclusion: The paper models the privacy-accuracy trade-off in Federated Learning with Local Differential Privacy as a game, introducing a token-based incentivization mechanism to encourage clients to reduce noise, thereby improving global model accuracy while preserving privacy. Strategic analysis and extensive experiments were conducted to study the impact of various parameters.

Abstract: In Federated Learning (FL), multiple clients jointly train a machine learning
model by sharing gradient information, instead of raw data, with a server over
multiple rounds. To address the possibility of information leakage in spite of
sharing only the gradients, Local Differential Privacy (LDP) is often used. In
LDP, clients add a selective amount of noise to the gradients before sending
the same to the server. Although such noise addition protects the privacy of
clients, it leads to a degradation in global model accuracy. In this paper, we
model this privacy-accuracy trade-off as a game, where the sever incentivizes
the clients to add a lower degree of noise for achieving higher accuracy, while
the clients attempt to preserve their privacy at the cost of a potential loss
in accuracy. A token based incentivization mechanism is introduced in which the
quantum of tokens credited to a client in an FL round is a function of the
degree of perturbation of its gradients. The client can later access a newly
updated global model only after acquiring enough tokens, which are to be
deducted from its balance. We identify the players, their actions and payoff,
and perform a strategic analysis of the game. Extensive experiments were
carried out to study the impact of different parameters.

</details>


### [338] [Early Detection of Pancreatic Cancer Using Multimodal Learning on Electronic Health Record](https://arxiv.org/abs/2508.06627)
*Mosbah Aouad,Anirudh Choudhary,Awais Farooq,Steven Nevers,Lusine Demirkhanyan,Bhrandon Harris,Suguna Pappu,Christopher Gondi,Ravishankar Iyer*

Main category: cs.LG

TL;DR: 提出一种新的多模态方法，利用电子健康记录数据，在临床诊断前一年检测胰腺导管腺癌，并在AUC方面取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏特异性症状和可靠的生物标志物，胰腺导管腺癌（PDAC）的早期检测仍然是一个重大的临床挑战。

Method: 本研究结合了神经控制微分方程、预训练语言模型、循环网络和交叉注意力机制，以模拟不规则的实验室时间序列，学习诊断代码轨迹表示，并捕捉两种模态之间的相互作用。

Result: 在包含近4,700名患者的真实世界数据集上评估，本研究的方法在AUC方面比最先进的方法提高了6.5%至15.5%。此外，该模型还识别了与PDAC风险升高相关的诊断代码和实验室检查项目，包括已建立和新的生物标志物。

Conclusion: 本研究提出了一种多模态方法，通过整合电子健康记录中的纵向诊断代码历史和常规收集的实验室测量数据，可以在临床诊断前一年检测胰腺导管腺癌。

Abstract: Pancreatic ductal adenocarcinoma (PDAC) is one of the deadliest cancers, and
early detection remains a major clinical challenge due to the absence of
specific symptoms and reliable biomarkers. In this work, we propose a new
multimodal approach that integrates longitudinal diagnosis code histories and
routinely collected laboratory measurements from electronic health records to
detect PDAC up to one year prior to clinical diagnosis. Our method combines
neural controlled differential equations to model irregular lab time series,
pretrained language models and recurrent networks to learn diagnosis code
trajectory representations, and cross-attention mechanisms to capture
interactions between the two modalities. We develop and evaluate our approach
on a real-world dataset of nearly 4,700 patients and achieve significant
improvements in AUC ranging from 6.5% to 15.5% over state-of-the-art methods.
Furthermore, our model identifies diagnosis codes and laboratory panels
associated with elevated PDAC risk, including both established and new
biomarkers. Our code is available at
https://github.com/MosbahAouad/EarlyPDAC-MML.

</details>


### [339] [Multi-Hop Privacy Propagation for Differentially Private Federated Learning in Social Networks](https://arxiv.org/abs/2508.07676)
*Chenchen Lin,Xuehe Wang*

Main category: cs.LG

TL;DR: 本文提出了一种新的联邦学习机制，考虑了社交网络中的隐私外部性。该机制通过斯坦克尔伯格博弈和均值场估计器来优化激励和隐私保护。实验证明该方法在提高用户效用、降低服务器成本和保持模型性能方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习（FL）虽然可以在不共享本地数据的情况下实现协作模型训练，但社交连接会带来隐私外部性，即一个客户端的隐私损失不仅取决于自身的隐私保护策略，还取决于通过网络进行的多跳交互传播的他人隐私决策。因此，有必要提出一种能够量化间接隐私泄漏的社会意识联邦学习机制。

Method: 提出了一种社会意识的隐私保护联邦学习机制，通过多跳传播模型系统地量化间接隐私泄漏。将服务器-客户端交互设计为双阶段斯坦克尔伯格博弈，其中服务器作为领导者优化激励策略，客户端作为跟随者选择其隐私预算，通过控制添加噪声的大小来确定其隐私保护级别。为了减轻网络隐私估计中的信息不对称，引入了均值场估计器来近似平均外部隐私风险。理论上证明了均值场估计器的不动点的存在性和收敛性，并推导了斯坦克尔伯格纳什均衡的闭式表达式。

Result: 实验结果表明，该方法显著提高了客户端效用并降低了服务器成本，同时保持了模型性能，并且优于仅考虑社交的基线（SA）和那些考虑社会外部性的方法。

Conclusion: 该机制在保持模型性能的同时，显著提高了客户端效用并降低了服务器成本，并且优于考虑社会外部性的方法以及仅考虑社交的基线。

Abstract: Federated learning (FL) enables collaborative model training across
decentralized clients without sharing local data, thereby enhancing privacy and
facilitating collaboration among clients connected via social networks.
However, these social connections introduce privacy externalities: a client's
privacy loss depends not only on its privacy protection strategy but also on
the privacy decisions of others, propagated through the network via multi-hop
interactions. In this work, we propose a socially-aware privacy-preserving FL
mechanism that systematically quantifies indirect privacy leakage through a
multi-hop propagation model. We formulate the server-client interaction as a
two-stage Stackelberg game, where the server, as the leader, optimizes
incentive policies, and clients, as followers, strategically select their
privacy budgets, which determine their privacy-preserving levels by controlling
the magnitude of added noise. To mitigate information asymmetry in networked
privacy estimation, we introduce a mean-field estimator to approximate the
average external privacy risk. We theoretically prove the existence and
convergence of the fixed point of the mean-field estimator and derive
closed-form expressions for the Stackelberg Nash Equilibrium. Despite being
designed from a client-centric incentive perspective, our mechanism achieves
approximately-optimal social welfare, as revealed by Price of Anarchy (PoA)
analysis. Experiments on diverse datasets demonstrate that our approach
significantly improves client utilities and reduces server costs while
maintaining model performance, outperforming both Social-Agnostic (SA)
baselines and methods that account for social externalities.

</details>


### [340] [Using Imperfect Synthetic Data in Downstream Inference Tasks](https://arxiv.org/abs/2508.06635)
*Yewon Byun,Shantanu Gupta,Zachary C. Lipton,Rachel Leah Childers,Bryan Wilder*

Main category: cs.LG

TL;DR: 提出了一种无需超参数的 GMM 估计量，用于结合合成数据和真实数据，并在计算社会科学中实现统计上有效的结论，同时发现了数据交互的潜在益处。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决在计算社会科学和人类受试者研究中，如何将大型语言模型生成的合成数据与真实数据相结合，并从中得出统计有效结论的挑战。

Method: 提出了一种基于广义矩方法（GMM）的新型估计量，该估计量无需超参数即可解决合成数据与真实数据结合的统计有效性问题。

Result: 研究发现，合成数据和真实数据之间的矩残差交互可以改进目标参数的估计。在不同的计算社会科学回归任务中，该估计量展现出了显著的经验优势。

Conclusion: 使用新的基于 GMM 的估计量，可以有效地将合成数据与真实数据相结合，并在计算社会科学应用中实现统计上有效的结论。

Abstract: Predictions and generations from large language models are increasingly being
explored as an aid to computational social science and human subject research
in limited data regimes. While previous technical work has explored the
potential to use model-predicted labels for unlabeled data in a principled
manner, there is increasing interest in using large language models to generate
entirely new synthetic samples (also termed as synthetic simulations), such as
in responses to surveys. However, it is not immediately clear by what means
practitioners can combine such data with real data and yet produce
statistically valid conclusions upon them. In this work, we introduce a new
estimator based on generalized method of moments, providing a
hyperparameter-free solution with strong theoretical guarantees to address the
challenge at hand. Surprisingly, we find that interactions between the moment
residuals of synthetic data and those of real data can improve estimates of the
target parameter. We empirically validate the finite-sample performance of our
estimator across different regression tasks in computational social science
applications, demonstrating large empirical gains.

</details>


### [341] [LLM-based Agents for Automated Confounder Discovery and Subgroup Analysis in Causal Inference](https://arxiv.org/abs/2508.07221)
*Po-Han Lee,Yu-Cheng Lin,Chan-Tung Ku,Chan Hsu,Pei-Cing Huang,Ping-Hsun Wu,Yihuang Kang*

Main category: cs.LG

TL;DR: 本研究提出使用基于LLM的代理来自动发现混淆因素和进行亚组分析，以解决因果推断中的挑战，并在医疗数据集上取得了改进的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 由于未测量的混淆因素和结构偏差，从观察数据中估计个体治疗效果一直是一个挑战。现有的因果ML方法在复杂环境中效果有限，并且依赖领域专家会带来高昂的注释成本和可扩展性问题。

Method: 该框架利用基于LLM的代理来自动发现混淆因素和进行亚组分析，将其整合到因果ML管道中，以模拟领域专业知识。

Result: 实验表明，该方法通过缩小置信区间和揭示未识别的混淆偏差，提高了治疗效果估计的鲁棒性。

Conclusion: LLM代理为可扩展、可信赖和语义感知的因果推断提供了一条有前途的途径。

Abstract: Estimating individualized treatment effects from observational data presents
a persistent challenge due to unmeasured confounding and structural bias.
Causal Machine Learning (causal ML) methods, such as causal trees and doubly
robust estimators, provide tools for estimating conditional average treatment
effects. These methods have limited effectiveness in complex real-world
environments due to the presence of latent confounders or those described in
unstructured formats. Moreover, reliance on domain experts for confounder
identification and rule interpretation introduces high annotation cost and
scalability concerns. In this work, we proposed Large Language Model-based
agents for automated confounder discovery and subgroup analysis that integrate
agents into the causal ML pipeline to simulate domain expertise. Our framework
systematically performs subgroup identification and confounding structure
discovery by leveraging the reasoning capabilities of LLM-based agents, which
reduces human dependency while preserving interpretability. Experiments on
real-world medical datasets show that our proposed approach enhances treatment
effect estimation robustness by narrowing confidence intervals and uncovering
unrecognized confounding biases. Our findings suggest that LLM-based agents
offer a promising path toward scalable, trustworthy, and semantically aware
causal inference.

</details>


### [342] [Segmented Confidence Sequences and Multi-Scale Adaptive Confidence Segments for Anomaly Detection in Nonstationary Time Series](https://arxiv.org/abs/2508.06638)
*Muyan Anna Li,Aditi Gautam*

Main category: cs.LG

TL;DR: Introduced novel adaptive thresholding frameworks (SCS and MACS) that use online learning and segmentation to handle changing data distributions in time series anomaly detection, outperforming traditional methods in tests.


<details>
  <summary>Details</summary>
Motivation: Anomaly detection must adapt to nonstationary environments where statistical properties shift over time, as time series data become increasingly prevalent in domains such as manufacturing, IT, and infrastructure monitoring. Traditional static thresholds are easily rendered obsolete by regime shifts, concept drift, or multi-scale changes.

Method: Introduced and empirically evaluated two novel adaptive thresholding frameworks: Segmented Confidence Sequences (SCS) and Multi-Scale Adaptive Confidence Segments (MACS). Both leverage statistical online learning and segmentation principles for local, contextually sensitive adaptation, maintaining guarantees on false alarm rates even under evolving distributions.

Result: Experiments across Wafer Manufacturing benchmark datasets show significant F1-score improvement compared to traditional percentile and rolling quantile approaches.

Conclusion: Robust, statistically principled adaptive thresholds enable reliable, interpretable, and timely detection of diverse real-world anomalies.

Abstract: As time series data become increasingly prevalent in domains such as
manufacturing, IT, and infrastructure monitoring, anomaly detection must adapt
to nonstationary environments where statistical properties shift over time.
Traditional static thresholds are easily rendered obsolete by regime shifts,
concept drift, or multi-scale changes. To address these challenges, we
introduce and empirically evaluate two novel adaptive thresholding frameworks:
Segmented Confidence Sequences (SCS) and Multi-Scale Adaptive Confidence
Segments (MACS). Both leverage statistical online learning and segmentation
principles for local, contextually sensitive adaptation, maintaining guarantees
on false alarm rates even under evolving distributions. Our experiments across
Wafer Manufacturing benchmark datasets show significant F1-score improvement
compared to traditional percentile and rolling quantile approaches. This work
demonstrates that robust, statistically principled adaptive thresholds enable
reliable, interpretable, and timely detection of diverse real-world anomalies.

</details>


### [343] [Privacy-Preserving Tabular Synthetic Data Generation Using TabularARGN](https://arxiv.org/abs/2508.06647)
*Andrey Sidorenko,Paul Tiwald*

Main category: cs.LG

TL;DR: A new neural network, TabularARGN, generates high-quality synthetic tabular data with strong privacy guarantees, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Synthetic data generation is crucial for secure data sharing and analysis, but traditional anonymization techniques often fall short in preserving privacy.

Method: TabularARGN utilizes a discretization-based auto-regressive approach for generating synthetic tabular data.

Result: TabularARGN generates high-fidelity synthetic tabular data efficiently and shows competitive performance against existing methods in various evaluations, including privacy assessments using membership-inference attacks.

Conclusion: TabularARGN demonstrates robustness and an effective privacy-utility balance against systematic membership-inference attacks, achieving competitive results in statistical similarity, machine learning utility, and detection robustness compared to existing methods.

Abstract: Synthetic data generation has become essential for securely sharing and
analyzing sensitive data sets. Traditional anonymization techniques, however,
often fail to adequately preserve privacy. We introduce the Tabular
Auto-Regressive Generative Network (TabularARGN), a neural network architecture
specifically designed for generating high-quality synthetic tabular data. Using
a discretization-based auto-regressive approach, TabularARGN achieves high data
fidelity while remaining computationally efficient. We evaluate TabularARGN
against existing synthetic data generation methods, showing competitive results
in statistical similarity, machine learning utility, and detection robustness.
We further perform an in-depth privacy evaluation using systematic
membership-inference attacks, highlighting the robustness and effective
privacy-utility balance of our approach.

</details>


### [344] [In-Context Reinforcement Learning via Communicative World Models](https://arxiv.org/abs/2508.06659)
*Fernando Martinez-Lopez,Tao Li,Yingdong Lu,Juntao Chen*

Main category: cs.LG

TL;DR: CORAL框架通过解耦表示学习与控制，利用双智能体通信学习可迁移的表示，提高了RL智能体的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 强化学习（RL）智能体在没有参数更新的情况下，难以泛化到新的任务和环境，因为它们学习到的表示和策略往往过拟合于训练环境的特定细节。

Method: 提出了一种名为CORAL的框架，将ICRL问题形式化为双智能体 the emergent communication问题。其中，信息智能体（IA）作为世界模型进行预训练，其目标是构建世界模型并将理解提炼成简洁的消息。新颖的因果影响损失用于指导通信协议的学习。在部署阶段，预训练的IA作为固定的情境化器，控制智能体（CA）通过解释通信上下文来学习解决任务。

Result: 实验证明，CORAL框架能够显著提高智能体在样本效率方面的表现，并在完全未见过的稀疏奖励环境中，借助预训练的IA实现零样本适应。

Conclusion: 该方法通过解耦潜在表示学习与控制，学习可迁移的交流上下文，有效提高了智能体在新的任务和环境中的适应能力，实现了零样本迁移。

Abstract: Reinforcement learning (RL) agents often struggle to generalize to new tasks
and contexts without updating their parameters, mainly because their learned
representations and policies are overfit to the specifics of their training
environments. To boost agents' in-context RL (ICRL) ability, this work
formulates ICRL as a two-agent emergent communication problem and introduces
CORAL (Communicative Representation for Adaptive RL), a framework that learns a
transferable communicative context by decoupling latent representation learning
from control. In CORAL, an Information Agent (IA) is pre-trained as a world
model on a diverse distribution of tasks. Its objective is not to maximize task
reward, but to build a world model and distill its understanding into concise
messages. The emergent communication protocol is shaped by a novel Causal
Influence Loss, which measures the effect that the message has on the next
action. During deployment, the previously trained IA serves as a fixed
contextualizer for a new Control Agent (CA), which learns to solve tasks by
interpreting the provided communicative context. Our experiments demonstrate
that this approach enables the CA to achieve significant gains in sample
efficiency and successfully perform zero-shot adaptation with the help of
pre-trained IA in entirely unseen sparse-reward environments, validating the
efficacy of learning a transferable communicative representation.

</details>


### [345] [Transferring Social Network Knowledge from Multiple GNN Teachers to Kolmogorov-Arnold Networks](https://arxiv.org/abs/2508.06663)
*Yuan-Hung Chao,Chia-Hsun Lu,Chih-Ya Shen*

Main category: cs.LG

TL;DR: 提出将KANs集成到GNN中，并使用知识杂合方法提高模型性能，结果显示KANs增强了GNN的表达能力，并实现了高效的无图推理。


<details>
  <summary>Details</summary>
Motivation: GNN在图结构数据上表现良好，但其对图连通性的依赖限制了可扩展性和效率。KANs具有可学习的单变量函数，提供强大的非线性表达能力和高效的推理能力。

Method: 将KANs集成到GAT、SGC和APPNP三种流行的GNN架构中，得到KGAT、KSGC和KAPPNP。采用多教师知识杂合框架，将知识从基于KAN的GNN蒸馏到图无关的KAN学生模型。

Result: 提出的模型提高了节点分类准确性，知识杂合方法显著提升了学生模型的性能。

Conclusion: KANs可以增强GNN的表达能力，并实现高效、无图推理。

Abstract: Graph Neural Networks (GNNs) have shown strong performance on
graph-structured data, but their reliance on graph connectivity often limits
scalability and efficiency. Kolmogorov-Arnold Networks (KANs), a recent
architecture with learnable univariate functions, offer strong nonlinear
expressiveness and efficient inference. In this work, we integrate KANs into
three popular GNN architectures-GAT, SGC, and APPNP-resulting in three new
models: KGAT, KSGC, and KAPPNP. We further adopt a multi-teacher knowledge
amalgamation framework, where knowledge from multiple KAN-based GNNs is
distilled into a graph-independent KAN student model. Experiments on benchmark
datasets show that the proposed models improve node classification accuracy,
and the knowledge amalgamation approach significantly boosts student model
performance. Our findings highlight the potential of KANs for enhancing GNN
expressiveness and for enabling efficient, graph-free inference.

</details>


### [346] [Robust Reinforcement Learning over Wireless Networks with Homomorphic State Representations](https://arxiv.org/abs/2508.07722)
*Pietro Talli,Federico Mason,Federico Chiariotti,Andrea Zanella*

Main category: cs.LG

TL;DR: 提出了一种名为 HR3L 的新颖 RL 架构，它通过非理想无线信道进行通信，无需交换梯度信息，从而实现更快的训练和更低的通信开销，并在样本效率和适应性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有 RL 框架在处理不完美反馈时的计算负担和特定限制，我们提出了一种能够通过非理想无线信道交换信息来训练远程 RL 代理的新架构。

Method: 提出了一种名为 HR3L 的新颖架构，该架构包含两个单元：发送方（编码有意义的环境表示）和接收方（解码消息并执行动作以最大化奖励信号）。HR3L 无需通过无线信道交换梯度信息。

Result: 实验结果表明，HR3L 在样本效率方面显著优于基线方法，并能适应不同的通信场景。

Conclusion: HR3L 显著优于基线方法，在样本效率方面表现更好，并且能够适应包括丢包、延迟传输和容量限制在内的不同通信场景。

Abstract: In this work, we address the problem of training Reinforcement Learning (RL)
agents over communication networks. The RL paradigm requires the agent to
instantaneously perceive the state evolution to infer the effects of its
actions on the environment. This is impossible if the agent receives state
updates over lossy or delayed wireless systems and thus operates with partial
and intermittent information. In recent years, numerous frameworks have been
proposed to manage RL with imperfect feedback; however, they often offer
specific solutions with a substantial computational burden. To address these
limits, we propose a novel architecture, named Homomorphic Robust Remote
Reinforcement Learning (HR3L), that enables the training of remote RL agents
exchanging observations across a non-ideal wireless channel. HR3L considers two
units: the transmitter, which encodes meaningful representations of the
environment, and the receiver, which decodes these messages and performs
actions to maximize a reward signal. Importantly, HR3L does not require the
exchange of gradient information across the wireless channel, allowing for
quicker training and a lower communication overhead than state-of-the-art
solutions. Experimental results demonstrate that HR3L significantly outperforms
baseline methods in terms of sample efficiency and adapts to different
communication scenarios, including packet losses, delayed transmissions, and
capacity limitations.

</details>


### [347] [Watermarking Kolmogorov-Arnold Networks for Emerging Networked Applications via Activation Perturbation](https://arxiv.org/abs/2508.06676)
*Chia-Hsun Lu,Guan-Jhih Wu,Ya-Chi Ho,Chih-Ya Shen*

Main category: cs.LG

TL;DR: A new watermarking method (DCT-AW) is introduced for Kolmogorov-Arnold Networks (KANs). It uses Discrete Cosine Transform on learnable activations to embed watermarks, showing good performance and strong resistance to attacks while preserving model accuracy.


<details>
  <summary>Details</summary>
Motivation: The increasing importance of protecting intellectual property in machine learning and the deployment of advanced models like KAN in sensitive domains necessitate robust model protection techniques. Existing methods fail to adapt to KANs due to their unique architecture with learnable activation functions.

Method: A novel watermarking method, Discrete Cosine Transform-based Activation Watermarking (DCT-AW), is proposed. It embeds watermarks by perturbing activation outputs using discrete cosine transform, leveraging the learnable activation functions of KAN.

Result: Experimental results demonstrate that DCT-AW has a small impact on model performance and provides superior robustness against various watermark removal attacks, including fine-tuning, pruning, and retraining after pruning.

Conclusion: The proposed DCT-AW method is effective and robust for watermarking KANs, with minimal impact on model performance and superior resistance to removal attacks.

Abstract: With the increasing importance of protecting intellectual property in machine
learning, watermarking techniques have gained significant attention. As
advanced models are increasingly deployed in domains such as social network
analysis, the need for robust model protection becomes even more critical.
While existing watermarking methods have demonstrated effectiveness for
conventional deep neural networks, they often fail to adapt to the novel
architecture, Kolmogorov-Arnold Networks (KAN), which feature learnable
activation functions. KAN holds strong potential for modeling complex
relationships in network-structured data. However, their unique design also
introduces new challenges for watermarking. Therefore, we propose a novel
watermarking method, Discrete Cosine Transform-based Activation Watermarking
(DCT-AW), tailored for KAN. Leveraging the learnable activation functions of
KAN, our method embeds watermarks by perturbing activation outputs using
discrete cosine transform, ensuring compatibility with diverse tasks and
achieving task independence. Experimental results demonstrate that DCT-AW has a
small impact on model performance and provides superior robustness against
various watermark removal attacks, including fine-tuning, pruning, and
retraining after pruning.

</details>


### [348] [Enhancing Privacy in Decentralized Min-Max Optimization: A Differentially Private Approach](https://arxiv.org/abs/2508.07505)
*Yueyang Quan,Chang Wang,Shengjie Zhai,Minghong Fang,Zhuqing Liu*

Main category: cs.LG

TL;DR: DPMixSGD是一种用于去中心化min-max优化的差分隐私算法，它在保护隐私的同时，通过理论和实验证明了其良好的收敛性能。


<details>
  <summary>Details</summary>
Motivation: 去中心化min-max优化虽然无需中心服务器，但模型更新的共享存在泄露敏感数据的风险。为了解决这一问题，引入差分隐私（DP）技术，但DP可能在非凸场景下影响收敛性。

Method: 提出了一种名为DPMixSGD（Differential Private Minmax Hybrid Stochastic Gradient Descent）的新型隐私保护算法，该算法基于最先进的STORM算法，并为梯度添加噪声以实现差分隐私。

Result: 理论分析表明，DPMixSGD的噪声添加不会显著损害收敛性能，并提供了隐私保证的理论界限。实验结果证实了该算法在各种任务和模型上的有效性。

Conclusion: 该研究提出了一种名为DPMixSGD的新型隐私保护算法，用于解决非凸去中心化min-max优化问题。研究证明，添加的噪声不会显著影响收敛性能，并提供了保证隐私的理论界限，实验验证了该方法的有效性。

Abstract: Decentralized min-max optimization allows multi-agent systems to
collaboratively solve global min-max optimization problems by facilitating the
exchange of model updates among neighboring agents, eliminating the need for a
central server. However, sharing model updates in such systems carry a risk of
exposing sensitive data to inference attacks, raising significant privacy
concerns. To mitigate these privacy risks, differential privacy (DP) has become
a widely adopted technique for safeguarding individual data. Despite its
advantages, implementing DP in decentralized min-max optimization poses
challenges, as the added noise can hinder convergence, particularly in
non-convex scenarios with complex agent interactions in min-max optimization
problems. In this work, we propose an algorithm called DPMixSGD (Differential
Private Minmax Hybrid Stochastic Gradient Descent), a novel privacy-preserving
algorithm specifically designed for non-convex decentralized min-max
optimization. Our method builds on the state-of-the-art STORM-based algorithm,
one of the fastest decentralized min-max solutions. We rigorously prove that
the noise added to local gradients does not significantly compromise
convergence performance, and we provide theoretical bounds to ensure privacy
guarantees. To validate our theoretical findings, we conduct extensive
experiments across various tasks and models, demonstrating the effectiveness of
our approach.

</details>


### [349] [Stabilizing Federated Learning under Extreme Heterogeneity with HeteRo-Select](https://arxiv.org/abs/2508.06692)
*Md. Akmol Masud,Md Abrar Jahin,Mahmud Hasan*

Main category: cs.LG

TL;DR: HeteRo-Select框架通过一种多维度评分系统解决了联邦学习中的训练不稳定性问题，并在实验中显著优于现有方法，提高了准确率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习（FL）中由于客户端数据多样性而导致的训练不稳定性问题，并克服现有基于效用（如Oort）的客户端选择方法在训练后期准确率下降的问题。

Method: 提出了一种名为HeteRo-Select的理论框架，该框架采用基于客户端有用性、公平性、更新速度和数据多样性的评分系统，并提供强正则化下的收敛保证。

Result: 在CIFAR-10数据集上，HeteRo-Select在标签倾斜（α=0.1）的显著情况下，在峰值准确率（74.75%）、最终准确率（72.76%）和稳定性（1.99%的下降幅度）方面均优于Oort（峰值准确率73.98%、最终准确率71.25%、下降幅度2.73%）。

Conclusion: HeteRo-Select框架为现实世界中异构的联邦学习问题提供了一个可靠的解决方案，该框架在理论基础和实证性能方面均表现出色。

Abstract: Federated Learning (FL) is a machine learning technique that often suffers
from training instability due to the diverse nature of client data. Although
utility-based client selection methods like Oort are used to converge by
prioritizing high-loss clients, they frequently experience significant drops in
accuracy during later stages of training. We propose a theoretical
HeteRo-Select framework designed to maintain high performance and ensure
long-term training stability. We provide a theoretical analysis showing that
when client data is very different (high heterogeneity), choosing a smart
subset of client participation can reduce communication more effectively
compared to full participation. Our HeteRo-Select method uses a clear,
step-by-step scoring system that considers client usefulness, fairness, update
speed, and data variety. It also shows convergence guarantees under strong
regularization. Our experimental results on the CIFAR-10 dataset under
significant label skew ($\alpha=0.1$) support the theoretical findings. The
HeteRo-Select method performs better than existing approaches in terms of peak
accuracy, final accuracy, and training stability. Specifically, HeteRo-Select
achieves a peak accuracy of $74.75\%$, a final accuracy of $72.76\%$, and a
minimal stability drop of $1.99\%$. In contrast, Oort records a lower peak
accuracy of $73.98\%$, a final accuracy of $71.25\%$, and a larger stability
drop of $2.73\%$. The theoretical foundations and empirical performance in our
study make HeteRo-Select a reliable solution for real-world heterogeneous FL
problems.

</details>


### [350] [CISO: Species Distribution Modeling Conditioned on Incomplete Species Observations](https://arxiv.org/abs/2508.06704)
*Hager Radi Abdelwahed,Mélisande Teng,Robin Zbinden,Laura Pollock,Hugo Larochelle,Devis Tuia,David Rolnick*

Main category: cs.LG

TL;DR: CISO是一种新的深度学习模型，可以利用不完整的物种观测数据和环境变量来更准确地预测物种分布，并且能够识别物种间的相互作用。


<details>
  <summary>Details</summary>
Motivation: 传统的物种分布模型（SDMs）通常仅考虑环境变量，而忽略了对物种分布有重要影响的物种间生物相互作用。现有的部分考虑生物相互作用的方法存在假设物种间关系对称和需要一致的共同出现数据的局限性，而实际中物种观测数据稀疏且其他物种的存在或缺失信息在不同地点差异很大。

Method: 提出了一种名为CISO的深度学习方法，该方法能够根据不完整的物种观测信息进行物种分布建模。CISO允许根据灵活数量的物种观测信息以及环境变量来预测物种分布，能够适应可用的生物数据的可变性和不完整性。

Result: 在植物、鸟类和蝴蝶的三个数据集上进行的实验表明，包含部分的生物信息可以提高在空间上分离的测试集上的预测性能。当根据同一数据集中的部分物种进行条件预测时，CISO在预测剩余物种的分布方面优于其他方法。此外，结合来自多个数据集的观测信息可以提高预测性能。

Conclusion: CISO是一个有前途的生态学工具，能够整合不完整的生物信息，并识别不同类群物种之间潜在的相互作用。

Abstract: Species distribution models (SDMs) are widely used to predict species'
geographic distributions, serving as critical tools for ecological research and
conservation planning. Typically, SDMs relate species occurrences to
environmental variables representing abiotic factors, such as temperature,
precipitation, and soil properties. However, species distributions are also
strongly influenced by biotic interactions with other species, which are often
overlooked. While some methods partially address this limitation by
incorporating biotic interactions, they often assume symmetrical pairwise
relationships between species and require consistent co-occurrence data. In
practice, species observations are sparse, and the availability of information
about the presence or absence of other species varies significantly across
locations. To address these challenges, we propose CISO, a deep learning-based
method for species distribution modeling Conditioned on Incomplete Species
Observations. CISO enables predictions to be conditioned on a flexible number
of species observations alongside environmental variables, accommodating the
variability and incompleteness of available biotic data. We demonstrate our
approach using three datasets representing different species groups: sPlotOpen
for plants, SatBird for birds, and a new dataset, SatButterfly, for
butterflies. Our results show that including partial biotic information
improves predictive performance on spatially separate test sets. When
conditioned on a subset of species within the same dataset, CISO outperforms
alternative methods in predicting the distribution of the remaining species.
Furthermore, we show that combining observations from multiple datasets can
improve performance. CISO is a promising ecological tool, capable of
incorporating incomplete biotic information and identifying potential
interactions between species from disparate taxa.

</details>


### [351] [Analysis of Schedule-Free Nonconvex Optimization](https://arxiv.org/abs/2508.06743)
*Connor Brown*

Main category: cs.LG

TL;DR: 本研究通过 Lyapunov 框架扩展了 SF 方法在光滑非凸优化中的无时间范围保证，提供了 O(1/log T) 到 O(T^-(1-α)) 的收敛界限，并通过 PEP 实验验证了这些界限。


<details>
  <summary>Details</summary>
Motivation: 大多数大规模学习算法都依赖于一阶方法，但其传统的收敛保证依赖于对总时间范围 T 的仔细调度的步长，而 T 很少能提前知道。SF 方法承诺通过在 Polyak-Ruppert 平均和动量之间进行插值来实现独立于 T 的超参数的最优性能，但对其非凸性的分析有限或依赖于强的全局假设。

Method: 提出了一种鲁棒的 Lyapunov 框架，该框架仅依赖于 L-平滑性和下界性，将 SF 分析简化为单步下降不等式。

Result: 得出了非凸设置下的无时间范围界限：恒定步长 + PR 平均为 O(1/log T)，线性增长步长为 O(log T/T)，以及多项式平均的 O(T^-(1-α)) 界限。通过性能估计问题 (PEP) 实验对这些证明进行了补充，这些实验在数值上验证了我们的界限，并表明我们对原始非凸 SF 算法的 O(1/log T) 界限可能会收紧到 O(1/T)。

Conclusion: 该研究将 SF 方法的无时间范围保证扩展到光滑非凸优化，并为最优非凸收敛速度指明了未来方向。

Abstract: First-order methods underpin most large-scale learning algorithms, yet their
classical convergence guarantees hinge on carefully scheduled step-sizes that
depend on the total horizon $T$, which is rarely known in advance. The
Schedule-Free (SF) method promises optimal performance with hyperparameters
that are independent of $T$ by interpolating between Polyak--Ruppert averaging
and momentum, but nonconvex analysis of SF has been limited or reliant on
strong global assumptions. We introduce a robust Lyapunov framework that, under
only $L$-smoothness and lower-boundedness, reduces SF analysis to a single-step
descent inequality. This yields horizon-agnostic bounds in the nonconvex
setting: $O(1/\log T)$ for constant step + PR averaging, $O(\log T/T)$ for a
linearly growing step-size, and a continuum of $O(T^{-(1-\alpha)})$ rates for
polynomial averaging. We complement these proofs with Performance Estimation
Problem (PEP) experiments that numerically validate our rates and suggest that
our $O(1/\log T)$ bound on the original nonconvex SF algorithm may tighten to
$O(1/T)$. Our work extends SF's horizon-free guarantees to smooth nonconvex
optimization and charts future directions for optimal nonconvex rates.

</details>


### [352] [Fed MobiLLM: Efficient Federated LLM Fine-Tuning over Heterogeneous Mobile Devices via Server Assisted Side-Tuning](https://arxiv.org/abs/2508.06765)
*Xingke Yang,Liang Li,Sicong Li,Liwei Guan,Hao Wang,Xiaoqi Qi,Jiang Liu,Xin Fu,Miao Pan*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Collaboratively fine-tuning (FT) large language models (LLMs) over
heterogeneous mobile devices fosters immense potential applications of
personalized intelligence. However, such a vision faces critical system
challenges. Conventional federated LLM FT approaches place prohibitive
computational and memory burdens on mobile hardware, and their synchronous
model aggregation protocols stall for slower devices. In this paper, we propose
Fed MobiLLM, a novel design to facilitate efficient federated LLM FT across
mobile devices with diverse computing/communication speeds and local model
architectures. In particular, Fed MobiLLM implements a pioneering
server-assisted federated side-tuning paradigm. Briefly, mobile devices perform
lightweight forward propagation computations on local data using their frozen
pre-scaled backbone LLMs, and then upload selected intermediate activations.
The server trains a shared side-network independently, eliminating client-side
backpropagation and enabling asynchronous updates. To bridge model
heterogeneity across different devices, we introduce an adaptive layer-wise
feature alignment method, which ensures consistent representations for
collaboratively tuning a shared side network. Extensive experimental results
demonstrate that Fed MobiLLM can maintain robust fine-tuning performance while
achieving extremely low on-device memory, with at least 95.2% reduction in
computation overhead, 93.2% reduction in communication costs and 5.1x faster
convergence compared to existing methods, validating its efficacy for practical
LLM adaptation over heterogeneous mobile devices.

</details>


### [353] [Zero-Direction Probing: A Linear-Algebraic Framework for Deep Analysis of Large-Language-Model Drift](https://arxiv.org/abs/2508.06776)
*Amit Pandey*

Main category: cs.LG

TL;DR: ZDP framework detects model drift using null directions of transformer activations and theoretical guarantees, without needing task labels or output evaluations.


<details>
  <summary>Details</summary>
Motivation: To develop a theory-only framework for detecting model drift from null directions of transformer activations, without relying on task labels or output evaluations.

Method: Zero-Direction Probing (ZDP) is a theory-only framework that analyzes null directions of transformer activations without requiring task labels or output evaluations. It leverages the Variance-Leak Theorem, Fisher Null-Conservation, and a Rank-Leak bound for low-rank updates, and achieves a logarithmic-regret guarantee for online null-space trackers.

Result: The framework provides a Spectral Null-Leakage (SNL) metric with non-asymptotic tail bounds and a concentration inequality, enabling a-priori thresholds for drift detection under a Gaussian null model. Theoretical proofs include the Variance-Leak Theorem, Fisher Null-Conservation, and a Rank-Leak bound.

Conclusion: Null space monitoring of transformer activations offers concrete, testable guarantees on representational change, as demonstrated by the Variance-Leak Theorem, Fisher Null-Conservation, and Rank-Leak bound.

Abstract: We present Zero-Direction Probing (ZDP), a theory-only framework for
detecting model drift from null directions of transformer activations without
task labels or output evaluations. Under assumptions A1--A6, we prove: (i) the
Variance--Leak Theorem, (ii) Fisher Null-Conservation, (iii) a Rank--Leak bound
for low-rank updates, and (iv) a logarithmic-regret guarantee for online
null-space trackers. We derive a Spectral Null-Leakage (SNL) metric with
non-asymptotic tail bounds and a concentration inequality, yielding a-priori
thresholds for drift under a Gaussian null model. These results show that
monitoring right/left null spaces of layer activations and their Fisher
geometry provides concrete, testable guarantees on representational change.

</details>


### [354] [PROPS: Progressively Private Self-alignment of Large Language Models](https://arxiv.org/abs/2508.06783)
*Noel Teku,Fengwei Tian,Payel Bhattacharjee,Souradip Chakraborty,Amrit Singh Bedi,Ravi Tandon*

Main category: cs.LG

TL;DR: PROPS是一种新的LLM对齐框架，通过多阶段的私有对齐模型作为标签生成器，实现了偏好级隐私保护，并在隐私和效用上优于DP-SGD和RR等现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型（LLM）对齐中，人类反馈可能引发的隐私问题，并提出一种在不牺牲模型效用的前提下，保护偏好标签隐私的对齐方法。

Method: PROPS (PROgressively Private Self-alignment)框架，一种多阶段的隐私保护对齐方法，其中先前阶段的私有对齐模型被用作后续阶段的标签生成器。

Result: PROPS在多个模型（Pythia和GPT）和数据集（AlpacaEval、Anthropic HH-RLHF、truthy-dpo-v0.1）上进行了验证，证明了其在提供高隐私性的同时，相比DP-SGD和RR对齐具有更高的模型效用，具体表现在更高的胜率。

Conclusion: PROPS (PROgressively Private Self-alignment)是一个多阶段的隐私保护对齐框架，它通过允许先前阶段的私有对齐模型作为后续阶段的标注者来补充训练数据，实现了偏好级隐私保护。该框架在保持高隐私性的同时，在模型效用方面优于现有方法。在相同的隐私预算下，PROPS对齐相比DP-SGD和基于随机响应(RR)的对齐，其胜率分别高出3倍和2.5倍。

Abstract: Alignment is a key step in developing Large Language Models (LLMs) using
human feedback to ensure adherence to human values and societal norms.
Dependence on human feedback raises privacy concerns about how much a labeler's
preferences may reveal about their personal values, beliefs, and personality
traits. Existing approaches, such as Differentially Private SGD (DP-SGD),
provide rigorous privacy guarantees by privatizing gradients during fine-tuning
and alignment but can provide more privacy than necessary as human preferences
are tied only to labels of (prompt, response) pairs and can degrade model
utility. This work focuses on LLM alignment with preference-level privacy,
which preserves the privacy of preference labels provided by humans. We propose
PROPS (PROgressively Private Self-alignment), a multi-stage privacy preserving
alignment framework where privately aligned models in previous stages can serve
as labelers for supplementing training data in the subsequent stages of
alignment. We present theoretical guarantees for PROPS as well as comprehensive
validation using multiple models (Pythia and GPT) and datasets (AlpacaEval,
Anthropic HH-RLHF, truthy-dpo-v0.1) to demonstrate the utility of PROPS over
existing methods while still providing high privacy. For the same privacy
budget, alignment via PROPS can achieve up to 3x higher win-rates compared to
DP-SGD, and 2.5x higher win-rates compared to Randomized Response (RR) based
alignment.

</details>


### [355] [Mode-Aware Non-Linear Tucker Autoencoder for Tensor-based Unsupervised Learning](https://arxiv.org/abs/2508.06784)
*Junjing Zheng,Chengliang Song,Weidong Jiang,Xinyu Zhang*

Main category: cs.LG

TL;DR: MA-NTAE通过非线性Tucker分解和Pick-and-Unfold策略，有效解决了高维张量自监督学习中的维度灾难和非线性关系学习能力有限的问题，在压缩和聚类任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于MLP的自编码器（AE）在处理高维张量数据时，由于展平操作加剧了维度灾难，导致模型规模过大、计算开销高，并且难以优化以捕捉深度结构特征。现有的张量网络虽然通过张量分解技术减轻了计算负担，但它们学习非线性关系的能力有限。

Method: MA-NTAE是一种广义化的Tucker分解，具有非线性框架，并采用Pick-and-Unfold策略，通过递归展开-编码-折叠操作，实现对高阶张量的灵活的每模式编码，有效整合了张量结构先验。

Result: MA-NTAE在压缩和聚类任务中展现出优越性能，其计算复杂度与张量阶数呈线性增长，与模式维度呈比例增长。

Conclusion: MA-NTAE在压缩和聚类任务中表现出优于标准AE和现有张量网络的性能优势，尤其是在处理更高阶、更高维度的张量时，这种优势更加明显。

Abstract: High-dimensional data, particularly in the form of high-order tensors,
presents a major challenge in self-supervised learning. While MLP-based
autoencoders (AE) are commonly employed, their dependence on flattening
operations exacerbates the curse of dimensionality, leading to excessively
large model sizes, high computational overhead, and challenging optimization
for deep structural feature capture. Although existing tensor networks
alleviate computational burdens through tensor decomposition techniques, most
exhibit limited capability in learning non-linear relationships. To overcome
these limitations, we introduce the Mode-Aware Non-linear Tucker Autoencoder
(MA-NTAE). MA-NTAE generalized classical Tucker decomposition to a non-linear
framework and employs a Pick-and-Unfold strategy, facilitating flexible
per-mode encoding of high-order tensors via recursive unfold-encode-fold
operations, effectively integrating tensor structural priors. Notably, MA-NTAE
exhibits linear growth in computational complexity with tensor order and
proportional growth with mode dimensions. Extensive experiments demonstrate
MA-NTAE's performance advantages over standard AE and current tensor networks
in compression and clustering tasks, which become increasingly pronounced for
higher-order, higher-dimensional tensors.

</details>


### [356] [Differentiable Adaptive Kalman Filtering via Optimal Transport](https://arxiv.org/abs/2508.07037)
*Yangguang He,Wenhao Li,Minzhe Li,Juan Zhang,Xiangfeng Wang,Bo Jin*

Main category: cs.LG

TL;DR: OTAKNet is an online adaptive Kalman filter that tackles noise-statistics drift using optimal transport, achieving superior performance without retraining or ground truth data.


<details>
  <summary>Details</summary>
Motivation: Real-world environmental factors can cause unobserved noise-statistics drift, degrading the performance of learning-based filtering methods.

Method: OTAKNet connects state estimates to drift via one-step predictive measurement likelihood and uses optimal transport for online adaptation without ground truth labels or retraining.

Result: OTAKNet demonstrates strong performance compared to classical model-based adaptive Kalman filtering and offline learning-based filtering on both synthetic and real-world NCLT datasets, particularly under limited training data.

Conclusion: OTAKNet is the first online solution for noise-statistics drift in learning-based adaptive Kalman filtering, outperforming traditional methods on synthetic and real-world datasets, especially with limited training data.

Abstract: Learning-based filtering has demonstrated strong performance in non-linear
dynamical systems, particularly when the statistics of noise are unknown.
However, in real-world deployments, environmental factors, such as changing
wind conditions or electromagnetic interference, can induce unobserved
noise-statistics drift, leading to substantial degradation of learning-based
methods. To address this challenge, we propose OTAKNet, the first online
solution to noise-statistics drift within learning-based adaptive Kalman
filtering. Unlike existing learning-based methods that perform offline
fine-tuning using batch pointwise matching over entire trajectories, OTAKNet
establishes a connection between the state estimate and the drift via one-step
predictive measurement likelihood, and addresses it using optimal transport.
This leverages OT's geometry - aware cost and stable gradients to enable fully
online adaptation without ground truth labels or retraining. We compare OTAKNet
against classical model-based adaptive Kalman filtering and offline
learning-based filtering. The performance is demonstrated on both synthetic and
real-world NCLT datasets, particularly under limited training data.

</details>


### [357] [Hardness-Aware Dynamic Curriculum Learning for Robust Multimodal Emotion Recognition with Missing Modalities](https://arxiv.org/abs/2508.06800)
*Rui Liu,Haolin Zuo,Zheng Lian,Hongyu Yuan,Qi Fan*

Main category: cs.LG

TL;DR: HARDY-MER is a new framework for multimodal emotion recognition that handles missing modalities better by estimating sample hardness and using a dynamic curriculum to focus on harder samples during training.


<details>
  <summary>Details</summary>
Motivation: Conventional approaches for missing modalities in multimodal emotion recognition (MER) using reconstruction fail to account for variations in reconstruction difficulty, limiting performance on hard samples.

Method: HARDY-MER utilizes a two-stage framework: 1. Multi-view Hardness Evaluation mechanism to estimate sample hardness based on reconstruction errors and cross-modal mutual information. 2. Retrieval-based Dynamic Curriculum Learning strategy to adjust training curriculum by retrieving semantically similar samples and balancing learning focus between easy and hard instances.

Result: Extensive experiments on benchmark datasets show HARDY-MER outperforms existing methods in missing-modality scenarios.

Conclusion: HARDY-MER consistently outperforms existing methods in missing-modality scenarios.

Abstract: Missing modalities have recently emerged as a critical research direction in
multimodal emotion recognition (MER). Conventional approaches typically address
this issue through missing modality reconstruction. However, these methods fail
to account for variations in reconstruction difficulty across different
samples, consequently limiting the model's ability to handle hard samples
effectively. To overcome this limitation, we propose a novel Hardness-Aware
Dynamic Curriculum Learning framework, termed HARDY-MER. Our framework operates
in two key stages: first, it estimates the hardness level of each sample, and
second, it strategically emphasizes hard samples during training to enhance
model performance on these challenging instances. Specifically, we first
introduce a Multi-view Hardness Evaluation mechanism that quantifies
reconstruction difficulty by considering both Direct Hardness (modality
reconstruction errors) and Indirect Hardness (cross-modal mutual information).
Meanwhile, we introduce a Retrieval-based Dynamic Curriculum Learning strategy
that dynamically adjusts the training curriculum by retrieving samples with
similar semantic information and balancing the learning focus between easy and
hard instances. Extensive experiments on benchmark datasets demonstrate that
HARDY-MER consistently outperforms existing methods in missing-modality
scenarios. Our code will be made publicly available at
https://github.com/HARDY-MER/HARDY-MER.

</details>


### [358] [Discovery Learning accelerates battery design evaluation](https://arxiv.org/abs/2508.06985)
*Jiawei Zhang,Yifei Zhang,Baozhao Yi,Yao Ren,Qi Jiao,Hanyu Bai,Weiran Jiang,Ziyou Song*

Main category: cs.LG

TL;DR: 发现学习（DL）是一种新的机器学习方法，通过模拟人类学习过程，从历史数据中学习，并减少实验需求，从而大大加快了电池设计的寿命评估过程，显著节省了时间和能源。


<details>
  <summary>Details</summary>
Motivation: 电池等复杂物理系统的创新设计需要快速可靠的验证，但电池的研发因评估大量新设计候选方案所需的高昂时间和能源成本而受到瓶颈。现有的数据驱动电池寿命预测方法需要目标设计的标记数据来提高精度，并且在原型制作之后才能进行可靠预测，效率低下，无法满足电池设计的快速反馈需求。

Method: 该研究介绍了一种名为发现学习（DL）的科学机器学习范式，该范式整合了主动学习、物理引导学习和零样本学习，并借鉴了教育心理学中的学习理论，形成了一个类似人类的推理循环。DL能够利用历史电池设计数据，并通过主动学习策略来减少对原型制作的依赖，从而对未知的材料-设计组合实现快速寿命评估，而无需额外的标注数据。

Result: 在测试中，DL在预测未知设备差异下的平均循环寿命时，测试误差为7.2%。与工业实践相比，DL在时间和能源方面分别节省了98%和95%。

Conclusion: 该研究提出了一种名为发现学习（DL）的科学机器学习范式，该范式通过整合主动学习、物理引导学习和零样本学习，模拟人类推理过程，能够从历史电池设计中学习，并主动减少原型制作的需求，从而在无需额外数据标记的情况下，对未观察到的材料设计组合进行快速寿命评估。DL在预测未知设备差异下的平均循环寿命方面取得了7.2%的测试误差，与工业实践相比，节省了98%的时间和95%的能源，展示了从历史设计中发掘见解以加速下一代电池技术发展的潜力。

Abstract: Fast and reliable validation of novel designs in complex physical systems
such as batteries is critical to accelerating technological innovation.
However, battery research and development remain bottlenecked by the
prohibitively high time and energy costs required to evaluate numerous new
design candidates, particularly in battery prototyping and life testing.
Despite recent progress in data-driven battery lifetime prediction, existing
methods require labeled data of target designs to improve accuracy and cannot
make reliable predictions until after prototyping, thus falling far short of
the efficiency needed to enable rapid feedback for battery design. Here, we
introduce Discovery Learning (DL), a scientific machine-learning paradigm that
integrates active learning, physics-guided learning, and zero-shot learning
into a human-like reasoning loop, drawing inspiration from learning theories in
educational psychology. DL can learn from historical battery designs and
actively reduce the need for prototyping, thus enabling rapid lifetime
evaluation for unobserved material-design combinations without requiring
additional data labeling. To test DL, we present 123 industrial-grade
large-format lithium-ion pouch cells, spanning eight material-design
combinations and diverse cycling protocols. Trained solely on public datasets
of small-capacity cylindrical cells, DL achieves 7.2% test error in predicting
the average cycle life under unknown device variability. This results in
savings of 98% in time and 95% in energy compared to industrial practices. This
work highlights the potential of uncovering insights from historical designs to
inform and accelerate the development of next-generation battery technologies.
DL represents a key advance toward efficient data-driven modeling and helps
realize the promise of machine learning for accelerating scientific discovery
and engineering innovation.

</details>


### [359] [PySeizure: A single machine learning classifier framework to detect seizures in diverse datasets](https://arxiv.org/abs/2508.07253)
*Bartlomiej Chybowski,Shima Abdullateef,Hollan Haule,Alfredo Gonzalez-Sulser,Javier Escudero*

Main category: cs.LG

TL;DR: 该研究提出了一个创新的、开源的机器学习框架，用于在不同EEG数据集中进行可靠的癫痫检测。该框架通过自动预处理和多数投票机制提高了鲁棒性和泛化能力，实现了高内部和跨数据集性能，为临床应用提供了基础。


<details>
  <summary>Details</summary>
Motivation: 可靠的癫痫检测对于诊断和管理癫痫至关重要，但临床工作流程仍然依赖于耗时的人工EEG解释。现有的机器学习方法通常依赖于特定数据集的优化，限制了其在现实世界中的适用性和可重复性。

Method: 提出了一种创新的、开源的机器学习框架，包含自动预处理管道以标准化数据，以及一个多数投票机制，其中多个模型独立评估每个EEG秒数，然后做出最终决策。在两个公开可用的EEG数据集（CHB-MIT和TUSZ）上评估了该方法的鲁棒性和跨数据集泛化能力。

Result: 所提出的框架在CHB-MIT数据集上实现了0.904（+/-0.059）的AUC，在TUSZ数据集上实现了0.864（+/-0.060）的AUC。在跨数据集测试中，从CHB-MIT训练到TUSZ测试的AUC为0.615（+/-0.039），从TUSZ训练到CHB-MIT测试的AUC为0.762（+/-0.175）。经过轻微后处理后，数据集内部性能提升至0.913（+/-0.064）和0.867（+/-0.058），跨数据集性能提升至0.619（+/-0.036）和0.768（+/-0.172）。

Conclusion: 该研究提出了一个创新的、开源的机器学习框架，用于在不同的临床脑电图（EEG）数据集中实现可靠且可泛化的癫痫检测。该框架通过自动预处理管道和多数投票机制增强了鲁棒性，并在两个公开可用的EEG数据集上进行了评估。研究结果表明，该框架在数据集内部表现出高精度（CHB-MIT的AUC为0.904，TUSZ的AUC为0.864），并能很好地泛化到其他数据集（CHB-MIT到TUSZ的AUC为0.615，TUSZ到CHB-MIT的AUC为0.762），无需任何后处理。轻微的后处理进一步提升了性能。该研究强调了该框架在不同临床环境部署的潜力和关键考虑因素，并为开发临床可用、与数据集无关的癫痫检测系统奠定了基础。

Abstract: Reliable seizure detection is critical for diagnosing and managing epilepsy,
yet clinical workflows remain dependent on time-consuming manual EEG
interpretation. While machine learning has shown promise, existing approaches
often rely on dataset-specific optimisations, limiting their real-world
applicability and reproducibility. Here, we introduce an innovative,
open-source machine-learning framework that enables robust and generalisable
seizure detection across varied clinical datasets. We evaluate our approach on
two publicly available EEG datasets that differ in patient populations and
electrode configurations. To enhance robustness, the framework incorporates an
automated pre-processing pipeline to standardise data and a majority voting
mechanism, in which multiple models independently assess each second of EEG
before reaching a final decision. We train, tune, and evaluate models within
each dataset, assessing their cross-dataset transferability. Our models achieve
high within-dataset performance (AUC 0.904+/-0.059 for CHB-MIT and
0.864+/-0.060 for TUSZ) and demonstrate strong generalisation across datasets
despite differences in EEG setups and populations (AUC 0.615+/-0.039 for models
trained on CHB-MIT and tested on TUSZ and 0.762+/-0.175 in the reverse case)
without any post-processing. Furthermore, a mild post-processing improved the
within-dataset results to 0.913+/-0.064 and 0.867+/-0.058 and cross-dataset
results to 0.619+/-0.036 and 0.768+/-0.172. These results underscore the
potential of, and essential considerations for, deploying our framework in
diverse clinical settings. By making our methodology fully reproducible, we
provide a foundation for advancing clinically viable, dataset-agnostic seizure
detection systems. This approach has the potential for widespread adoption,
complementing rather than replacing expert interpretation, and accelerating
clinical integration.

</details>


### [360] [Offline-to-Online Reinforcement Learning with Classifier-Free Diffusion Generation](https://arxiv.org/abs/2508.06806)
*Xiao Huang,Xu Liu,Enze Zhang,Tong Yu,Shuai Li*

Main category: cs.LG

TL;DR: CFDG 通过改进数据增强技术，在离线到在线强化学习中提高了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 O2O RL 方法在数据增强方面存在生成数据与在线数据分布不一致的问题，限制了整体性能。

Method: CFDG 利用分类器无关的扩散模型生成高质量的离线和在线数据，并通过重加权方法使生成的数据与在线数据对齐。

Result: CFDG 在 D4RL 基准测试（如 MuJoCo 和 AntMaze）上，通过集成到 IQL、PEX 和 APL 等常用方法，实现了 15% 的平均性能提升。

Conclusion: CFDG 是一种新的数据增强方法，可以提高 O2O RL 的性能，并且可以集成到现有的 O2O RL 算法中。

Abstract: Offline-to-online Reinforcement Learning (O2O RL) aims to perform online
fine-tuning on an offline pre-trained policy to minimize costly online
interactions. Existing work used offline datasets to generate data that conform
to the online data distribution for data augmentation. However, generated data
still exhibits a gap with the online data, limiting overall performance. To
address this, we propose a new data augmentation approach, Classifier-Free
Diffusion Generation (CFDG). Without introducing additional classifier training
overhead, CFDG leverages classifier-free guidance diffusion to significantly
enhance the generation quality of offline and online data with different
distributions. Additionally, it employs a reweighting method to enable more
generated data to align with the online data, enhancing performance while
maintaining the agent's stability. Experimental results show that CFDG
outperforms replaying the two data types or using a standard diffusion model to
generate new data. Our method is versatile and can be integrated with existing
offline-to-online RL algorithms. By implementing CFDG to popular methods IQL,
PEX and APL, we achieve a notable 15% average improvement in empirical
performance on the D4RL benchmark such as MuJoCo and AntMaze.

</details>


### [361] [From Imitation to Optimization: A Comparative Study of Offline Learning for Autonomous Driving](https://arxiv.org/abs/2508.07029)
*Antonio Guillen-Perez*

Main category: cs.LG

TL;DR: 与行为克隆相比，离线强化学习（CQL）在从静态专家数据中学习驾驶策略方面具有显著优势，尤其是在长期鲁棒性和错误恢复方面。


<details>
  <summary>Details</summary>
Motivation: 从大规模真实世界数据中学习鲁棒的驾驶策略是一个核心挑战，因为在线数据收集通常不安全且不切实际。行为克隆（BC）虽然简单，但其策略往往脆弱，并且在闭环执行中会出现复合错误。

Method: 通过一个包含行为克隆（BC）和离线强化学习（CQL）的综合流水线和比较研究来解决从大规模真实世界数据中学习鲁棒驾驶策略的挑战。BC方法包括一个基于Transformer的模型，该模型在结构化的、以实体为中心的状态表示上操作。CQL方法应用了最先进的离线强化学习算法，并结合精心设计的奖励函数，以学习一个保守的价值函数。

Result: 在Waymo开放运动数据集的1000个未见过场景的大规模评估中，最终的CQL代理实现了比最强的BC基线高3.2倍的成功率和低7.4倍的碰撞率。

Conclusion: 离线强化学习（CQL）方法比行为克隆（BC）方法更能从静态专家数据中学习鲁棒的、长期的驾驶策略。

Abstract: Learning robust driving policies from large-scale, real-world datasets is a
central challenge in autonomous driving, as online data collection is often
unsafe and impractical. While Behavioral Cloning (BC) offers a straightforward
approach to imitation learning, policies trained with BC are notoriously
brittle and suffer from compounding errors in closed-loop execution. This work
presents a comprehensive pipeline and a comparative study to address this
limitation. We first develop a series of increasingly sophisticated BC
baselines, culminating in a Transformer-based model that operates on a
structured, entity-centric state representation. While this model achieves low
imitation loss, we show that it still fails in long-horizon simulations. We
then demonstrate that by applying a state-of-the-art Offline Reinforcement
Learning algorithm, Conservative Q-Learning (CQL), to the same data and
architecture, we can learn a significantly more robust policy. Using a
carefully engineered reward function, the CQL agent learns a conservative value
function that enables it to recover from minor errors and avoid
out-of-distribution states. In a large-scale evaluation on 1,000 unseen
scenarios from the Waymo Open Motion Dataset, our final CQL agent achieves a
3.2x higher success rate and a 7.4x lower collision rate than the strongest BC
baseline, proving that an offline RL approach is critical for learning robust,
long-horizon driving policies from static expert data.

</details>


### [362] [Technical Report: Full-Stack Fine-Tuning for the Q Programming Language](https://arxiv.org/abs/2508.06813)
*Brendan R. Hogan,Will Brown,Adel Boyarsky,Anderson Schneider,Yuriy Nevmyvaka*

Main category: cs.LG

TL;DR: 为Q编程语言适配LLM，模型性能大幅提升，方法可推广至其他小众领域。


<details>
  <summary>Details</summary>
Motivation: 目前的LLM在互联网代表性不足的领域（如Q编程语言）表现不佳，需要专门的适配方法。

Method: 通过预训练、监督微调和强化学习，在Q语言Leetcode风格数据集上训练了基于Qwen-2.5系列模型的多个版本，并进行了性能评估。

Result: 在Q语言基准测试中，最佳模型pass@1准确率达到59%，超越了Claude Opus-4，所有模型均优于GPT-4.1。

Conclusion: 该研究提出了一种针对Q语言的LLM适配方法，并取得了显著成果，为其他小众领域LLM应用提供了借鉴。

Abstract: Even though large language models are becoming increasingly capable, it is
still unreasonable to expect them to excel at tasks that are under-represented
on the Internet. Leveraging LLMs for specialized applications, particularly in
niche programming languages and private domains, remains challenging and
largely unsolved. In this work, we address this gap by presenting a
comprehensive, open-source approach for adapting LLMs to the Q programming
language, a popular tool in quantitative finance that is much less present on
the Internet compared to Python, C, Java, and other ``mainstream" languages and
is therefore not a strong suit of general-purpose AI models. We introduce a new
Leetcode style evaluation dataset for Q, benchmark major frontier models on the
dataset, then do pretraining, supervised fine tuning, and reinforcement
learning to train a suite of reasoning and non-reasoning models based on the
Qwen-2.5 series, spanning five parameter sizes (1.5B, 3B, 7B, 14B, 32B). Our
best model achieves a pass@1 accuracy of 59 percent on our Q benchmark,
surpassing the best-performing frontier model, Claude Opus-4 by 29.5 percent.
Additionally, all models, even our 1.5B model, outperform GPT-4.1 on this task.
In addition to releasing models, code, and data, we provide a detailed
blueprint for dataset construction, model pretraining, supervised fine-tuning,
and reinforcement learning. Our methodology is broadly applicable, and we
discuss how these techniques can be extended to other tasks, including those
where evaluation may rely on soft or subjective signals.

</details>


### [363] [Who's the Evil Twin? Differential Auditing for Undesired Behavior](https://arxiv.org/abs/2508.06827)
*Ishwar Balappanawar,Venkata Hasith Vattikuti,Greta Kintzley,Ronan Azimi-Mancel,Satvik Golechha*

Main category: cs.LG

TL;DR: 该研究提出了一种通过对抗性博弈来检测神经网络中隐藏行为的方法，并对CNN和LLM进行了实验。研究发现，基于对抗性攻击的方法在有提示的情况下效果最佳，并强调了为LLM设计专门审计方法的重要性。


<details>
  <summary>Details</summary>
Motivation: 由于先验知识极少且可能存在对抗性混淆，因此检测神经网络中隐藏行为是一个重大挑战。

Method: 该研究将检测问题构建为一个对抗性博弈，红队训练两个相似但其中一个包含隐藏有害行为的模型，蓝队则在信息有限的情况下尝试识别受损模型。研究人员尝试了多种蓝队策略，包括高斯噪声分析、模型差异分析、集成梯度和对抗性攻击。

Result: 基于对抗性攻击的方法在提供提示时能达到100%的准确率，表现出巨大潜力，而其他技术表现则参差不齐。在LLM方面，研究发现与CNN研究类似的方法有限，有效的LLM审计方法需要关于不良分布的提示。

Conclusion: 需要针对LLM设计专门的审计方法，并且需要提供一些关于不良分布的提示，以便使用标准的黑盒或白盒方法进一步探测模型。

Abstract: Detecting hidden behaviors in neural networks poses a significant challenge
due to minimal prior knowledge and potential adversarial obfuscation. We
explore this problem by framing detection as an adversarial game between two
teams: the red team trains two similar models, one trained solely on benign
data and the other trained on data containing hidden harmful behavior, with the
performance of both being nearly indistinguishable on the benign dataset. The
blue team, with limited to no information about the harmful behaviour, tries to
identify the compromised model. We experiment using CNNs and try various blue
team strategies, including Gaussian noise analysis, model diffing, integrated
gradients, and adversarial attacks under different levels of hints provided by
the red team. Results show high accuracy for adversarial-attack-based methods
(100\% correct prediction, using hints), which is very promising, whilst the
other techniques yield more varied performance. During our LLM-focused rounds,
we find that there are not many parallel methods that we could apply from our
study with CNNs. Instead, we find that effective LLM auditing methods require
some hints about the undesired distribution, which can then used in standard
black-box and open-weight methods to probe the models further and reveal their
misalignment. We open-source our auditing games (with the model and data) and
hope that our findings contribute to designing better audits.

</details>


### [364] [Deep Learning-Based Analysis of Power Consumption in Gasoline, Electric, and Hybrid Vehicles](https://arxiv.org/abs/2508.08034)
*Roksana Yahyaabadi,Ghazal Farhani,Taufiq Rahman,Soodeh Nikan,Abdullah Jirjees,Fadi Araji*

Main category: cs.LG

TL;DR: 该研究提出了一种创新的数据驱动方法，使用机器学习和深度学习技术，能够准确预测内燃机、电动汽车和混合动力汽车的功率消耗，克服了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 准确的功率消耗预测对于提高效率和减少环境影响至关重要，但传统的依赖专用仪器或刚性物理模型的方法对于大规模、真实世界的部署来说是不切实际的。

Method: 该研究提出了一种可扩展的数据驱动方法，利用动力系统动态特征集，并结合传统机器学习和深度神经网络（特别是Transformer和长短期记忆模型）来估算内燃机（ICE）、电动汽车（EV）和混合动力汽车（HEV）的瞬时和累积功率消耗。

Result: ICE模型实现了很高的瞬时精度，平均绝对误差和均方根误差的数量级约为10^{-3}，累积误差低于3%。对于EV和HEV，Transformer和长短期记忆模型表现最佳，累积误差分别低于4.1%和2.1%。

Conclusion: 该研究提出的数据驱动方法在不同类型的车辆（ICE、EV、HEV）上实现了高精度的功率消耗预测，并验证了其跨模型和跨平台的有效性。不确定性分析表明，EV和HEV数据集比ICE数据集具有更大的变异性，这强调了为高级动力系统构建鲁棒模型的重要性。

Abstract: Accurate power consumption prediction is crucial for improving efficiency and
reducing environmental impact, yet traditional methods relying on specialized
instruments or rigid physical models are impractical for large-scale,
real-world deployment. This study introduces a scalable data-driven method
using powertrain dynamic feature sets and both traditional machine learning and
deep neural networks to estimate instantaneous and cumulative power consumption
in internal combustion engine (ICE), electric vehicle (EV), and hybrid electric
vehicle (HEV) platforms. ICE models achieved high instantaneous accuracy with
mean absolute error and root mean squared error on the order of $10^{-3}$, and
cumulative errors under 3%. Transformer and long short-term memory models
performed best for EVs and HEVs, with cumulative errors below 4.1% and 2.1%,
respectively. Results confirm the approach's effectiveness across vehicles and
models. Uncertainty analysis revealed greater variability in EV and HEV
datasets than ICE, due to complex power management, emphasizing the need for
robust models for advanced powertrains.

</details>


### [365] [Sparsity-Driven Plasticity in Multi-Task Reinforcement Learning](https://arxiv.org/abs/2508.06871)
*Aleksandar Todorov,Juan Cardenas-Cartagena,Rafael F. Cunha,Marco Zullich,Matthia Sabatelli*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Plasticity loss, a diminishing capacity to adapt as training progresses, is a
critical challenge in deep reinforcement learning. We examine this issue in
multi-task reinforcement learning (MTRL), where higher representational
flexibility is crucial for managing diverse and potentially conflicting task
demands. We systematically explore how sparsification methods, particularly
Gradual Magnitude Pruning (GMP) and Sparse Evolutionary Training (SET), enhance
plasticity and consequently improve performance in MTRL agents. We evaluate
these approaches across distinct MTRL architectures (shared backbone, Mixture
of Experts, Mixture of Orthogonal Experts) on standardized MTRL benchmarks,
comparing against dense baselines, and a comprehensive range of alternative
plasticity-inducing or regularization methods. Our results demonstrate that
both GMP and SET effectively mitigate key indicators of plasticity degradation,
such as neuron dormancy and representational collapse. These plasticity
improvements often correlate with enhanced multi-task performance, with sparse
agents frequently outperforming dense counterparts and achieving competitive
results against explicit plasticity interventions. Our findings offer insights
into the interplay between plasticity, network sparsity, and MTRL designs,
highlighting dynamic sparsification as a robust but context-sensitive tool for
developing more adaptable MTRL systems.

</details>


### [366] [Cross-Subject and Cross-Montage EEG Transfer Learning via Individual Tangent Space Alignment and Spatial-Riemannian Feature Fusion](https://arxiv.org/abs/2508.08216)
*Nicole Lai-Tan,Xiao Gu,Marios G. Philiastides,Fani Deligianni*

Main category: cs.LG

TL;DR: ITSA通过预对齐策略和混合架构解决了BCI的个体差异问题，提高了泛化能力和性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决BCI中个体差异、运动伪影和运动规划差异导致的泛化能力受限和校准时间长的问题，我们提出了一种新的预对齐策略。

Method: ITSA通过结合特定于主体的重置、分布匹配和监督旋转对齐，以及RCSP和黎曼几何的混合架构（并行和串行配置）来增强跨主体的泛化能力。

Result: ITSA在交叉验证中表现出显著的跨主体和跨条件性能提升，其中并行融合方法优于串行方法，并在不同数据条件和电极配置下保持稳健的性能。

Conclusion: ITSA是一种新颖的预对齐策略，通过结合特定于主体的重置、分布匹配和监督旋转对齐，增强了跨主体的泛化能力。它通过RCSP和黎曼几何的混合架构，提高了类可分离性，同时保持了协方差矩阵的几何结构，用于稳健的统计计算。

Abstract: Personalised music-based interventions offer a powerful means of supporting
motor rehabilitation by dynamically tailoring auditory stimuli to provide
external timekeeping cues, modulate affective states, and stabilise gait
patterns. Generalisable Brain-Computer Interfaces (BCIs) thus hold promise for
adapting these interventions across individuals. However, inter-subject
variability in EEG signals, further compounded by movement-induced artefacts
and motor planning differences, hinders the generalisability of BCIs and
results in lengthy calibration processes. We propose Individual Tangent Space
Alignment (ITSA), a novel pre-alignment strategy incorporating subject-specific
recentering, distribution matching, and supervised rotational alignment to
enhance cross-subject generalisation. Our hybrid architecture fuses Regularised
Common Spatial Patterns (RCSP) with Riemannian geometry in parallel and
sequential configurations, improving class separability while maintaining the
geometric structure of covariance matrices for robust statistical computation.
Using leave-one-subject-out cross-validation, `ITSA' demonstrates significant
performance improvements across subjects and conditions. The parallel fusion
approach shows the greatest enhancement over its sequential counterpart, with
robust performance maintained across varying data conditions and electrode
configurations. The code will be made publicly available at the time of
publication.

</details>


### [367] [Conformal Prediction and Trustworthy AI](https://arxiv.org/abs/2508.06885)
*Anthony Bellotti,Xindi Zhao*

Main category: cs.LG

TL;DR: Conformal predictors offer reliable uncertainty quantification for trustworthy AI, helping with generalization, governance, and bias issues.


<details>
  <summary>Details</summary>
Motivation: To explore the potential of conformal predictors for trustworthy AI, addressing issues like generalization risk and AI governance, and to demonstrate their practical applications.

Method: Review of conformal predictors and their potential for trustworthy AI, including experiments for calibration, bias identification, and mitigation.

Result: Conformal predictors are shown to be well-calibrated and useful for bias identification and mitigation, contributing to trustworthy AI.

Conclusion: Conformal predictors are beneficial for trustworthy AI beyond marginal validity, addressing generalization risk and AI governance. Experiments demonstrate their use in calibration, bias identification, and mitigation.

Abstract: Conformal predictors are machine learning algorithms developed in the 1990's
by Gammerman, Vovk, and their research team, to provide set predictions with
guaranteed confidence level. Over recent years, they have grown in popularity
and have become a mainstream methodology for uncertainty quantification in the
machine learning community. From its beginning, there was an understanding that
they enable reliable machine learning with well-calibrated uncertainty
quantification. This makes them extremely beneficial for developing trustworthy
AI, a topic that has also risen in interest over the past few years, in both
the AI community and society more widely. In this article, we review the
potential for conformal prediction to contribute to trustworthy AI beyond its
marginal validity property, addressing problems such as generalization risk and
AI governance. Experiments and examples are also provided to demonstrate its
use as a well-calibrated predictor and for bias identification and mitigation.

</details>


### [368] [QuiZSF: An efficient data-model interaction framework for zero-shot time-series forecasting](https://arxiv.org/abs/2508.06915)
*Shichao Ma,Zhengyang Zhou,Qihe Huang,Binwu Wang,Kuo Yang,Huan Li,Yang Wang*

Main category: cs.LG

TL;DR: QuiZSF是一个结合了RAG和TSPMs的新框架，用于零样本时间序列预测。它通过CRB、MSIL和MCC等组件，在多个预测场景中都取得了领先的性能，并且效率很高。


<details>
  <summary>Details</summary>
Motivation: 零样本时间序列预测（ZSF）在数据稀疏的场景下（如领域迁移或极端条件预测）具有重要价值，但传统模型难以处理。虽然时间序列预训练模型（TSPMs）在ZSF方面表现出色，但缺乏动态整合外部知识的机制。检索增强生成（RAG）技术可以按需注入外部知识，但很少与TSPMs结合。因此，本研究旨在利用RAG和TSPMs的优点，提出一种新的方法来增强ZSF能力。

Method: 本研究提出了QuiZSF框架，一个轻量级且模块化的框架，结合了高效检索、表示学习和模型适应，用于零样本时间序列预测（ZSF）。具体而言，研究构建了一个分层的树状ChronoRAG Base（CRB）用于可扩展的时间序列存储和领域感知检索；引入了一个Multi-grained Series Interaction Learner（MSIL）来提取细粒度和粗粒度的关系特征；并开发了一个双分支Model Cooperation Coherer（MCC）来将检索到的知识与两种TSPM（非LLM和LLM）进行对齐。

Result: QuiZSF框架在使用非LLM和LLM作为基础模型时，分别在75%和87.5%的预测设置中排名第一，并且在内存和推理时间方面保持了高效率，相比于现有基线模型表现更优。

Conclusion: QuiZSF框架通过结合检索增强生成（RAG）和时间序列预训练模型（TSPM），在零样本时间序列预测（ZSF）任务上取得了显著成效。该框架包含ChronoRAG Base（CRB）用于高效检索，Multi-grained Series Interaction Learner（MSIL）用于提取多粒度特征，以及Model Cooperation Coherer（MCC）用于模型适应。QuiZSF在多个预测场景中均排名第一，同时保持了良好的内存和推理效率。

Abstract: Time series forecasting has become increasingly important to empower diverse
applications with streaming data. Zero-shot time-series forecasting (ZSF),
particularly valuable in data-scarce scenarios, such as domain transfer or
forecasting under extreme conditions, is difficult for traditional models to
deal with. While time series pre-trained models (TSPMs) have demonstrated
strong performance in ZSF, they often lack mechanisms to dynamically
incorporate external knowledge. Fortunately, emerging retrieval-augmented
generation (RAG) offers a promising path for injecting such knowledge on
demand, yet they are rarely integrated with TSPMs. To leverage the strengths of
both worlds, we introduce RAG into TSPMs to enhance zero-shot time series
forecasting. In this paper, we propose QuiZSF (Quick Zero-Shot Time Series
Forecaster), a lightweight and modular framework that couples efficient
retrieval with representation learning and model adaptation for ZSF.
Specifically, we construct a hierarchical tree-structured ChronoRAG Base (CRB)
for scalable time-series storage and domain-aware retrieval, introduce a
Multi-grained Series Interaction Learner (MSIL) to extract fine- and
coarse-grained relational features, and develop a dual-branch Model Cooperation
Coherer (MCC) that aligns retrieved knowledge with two kinds of TSPMs: Non-LLM
based and LLM based. Compared with contemporary baselines, QuiZSF, with Non-LLM
based and LLM based TSPMs as base model, respectively, ranks Top1 in 75% and
87.5% of prediction settings, while maintaining high efficiency in memory and
inference time.

</details>


### [369] [Class Unbiasing for Generalization in Medical Diagnosis](https://arxiv.org/abs/2508.06943)
*Lishi Zuo,Man-Wai Mak,Lu Yi,Youzhi Tu*

Main category: cs.LG

TL;DR: 提出Cls-unbias方法，通过类别不均衡损失和类别不均衡的分布鲁棒优化，解决医学诊断中的类别-特征偏差和类别不平衡问题，提升模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决医学诊断中的偏见问题，特别是识别出类别-特征偏差，即模型可能依赖与仅一部分类别强相关的特征，导致在其他类别上表现出偏见和泛化能力差。

Method: 提出了一种类别不均衡损失，以促进来自正类和负类样本的分类损失的相等贡献。提出了一种类别不均衡的分布鲁棒优化目标，以增强在类别不均衡情况下类别不均衡损失的有效性。

Result: 通过合成和真实世界的数据集，实证证明了类别-特征偏差会对模型性能产生负面影响。提出的方法能有效缓解类别-特征偏差和类别不平衡，从而提高模型的泛化能力。

Conclusion: 该方法有效缓解了类别-特征偏差和类别不平衡问题，提高了模型的泛化能力。

Abstract: Medical diagnosis might fail due to bias. In this work, we identified
class-feature bias, which refers to models' potential reliance on features that
are strongly correlated with only a subset of classes, leading to biased
performance and poor generalization on other classes. We aim to train a
class-unbiased model (Cls-unbias) that mitigates both class imbalance and
class-feature bias simultaneously. Specifically, we propose a class-wise
inequality loss which promotes equal contributions of classification loss from
positive-class and negative-class samples. We propose to optimize a class-wise
group distributionally robust optimization objective-a class-weighted training
objective that upweights underperforming classes-to enhance the effectiveness
of the inequality loss under class imbalance. Through synthetic and real-world
datasets, we empirically demonstrate that class-feature bias can negatively
impact model performance. Our proposed method effectively mitigates both
class-feature bias and class imbalance, thereby improving the model's
generalization ability.

</details>


### [370] [Learning Satellite Attitude Dynamics with Physics-Informed Normalising Flow](https://arxiv.org/abs/2508.07841)
*Carlo Cena,Mauro Martini,Marcello Chiaberge*

Main category: cs.LG

TL;DR: PINNs可提高航天器姿态控制精度和稳定性。


<details>
  <summary>Details</summary>
Motivation: 在物理模型不完整或计算成本高的情况下，机器学习可作为替代方案，但纯数据驱动模型存在泛化性和稳定性问题，因此需要研究PINNs的优势。

Method: 使用Real-valued Non-Volume Preserving (Real NVP)神经网络架构和自注意力机制，通过纯数据驱动和物理信息两种策略训练模型，并进行比较。

Result: PINN-based模型在平均相对误差方面比纯数据驱动模型提高了27.08%，在MPC框架下，性能稳定性误差提高了42.86%，并增强了对噪声的鲁棒性。

Conclusion: 结合物理信息（PINNs）的学习方法在航天器姿态动力学控制中显著优于纯数据驱动方法，尤其是在MPC框架下，能提高控制精度和稳定性。

Abstract: Attitude control is a fundamental aspect of spacecraft operations. Model
Predictive Control (MPC) has emerged as a powerful strategy for these tasks,
relying on accurate models of the system dynamics to optimize control actions
over a prediction horizon. In scenarios where physics models are incomplete,
difficult to derive, or computationally expensive, machine learning offers a
flexible alternative by learning the system behavior directly from data.
However, purely data-driven models often struggle with generalization and
stability, especially when applied to inputs outside their training domain. To
address these limitations, we investigate the benefits of incorporating
Physics-Informed Neural Networks (PINNs) into the learning of spacecraft
attitude dynamics, comparing their performance with that of purely data-driven
approaches. Using a Real-valued Non-Volume Preserving (Real NVP) neural network
architecture with a self-attention mechanism, we trained several models on
simulated data generated with the Basilisk simulator. Two training strategies
were considered: a purely data-driven baseline and a physics-informed variant
to improve robustness and stability. Our results demonstrate that the inclusion
of physics-based information significantly enhances the performance in terms of
the mean relative error of the best architectures found by 27.08%. These
advantages are particularly evident when the learned models are integrated into
an MPC framework, where PINN-based models consistently outperform their purely
data-driven counterparts in terms of control accuracy and robustness, yielding
improvements of up to 42.86% in performance stability error and increased
robustness-to-noise.

</details>


### [371] [AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance](https://arxiv.org/abs/2508.06944)
*Lixuan He,Jie Feng,Yong Li*

Main category: cs.LG

TL;DR: LLMs are usually fine-tuned using SFT then RL, but this has issues. This paper introduces AMFT, a new method that combines SFT and RL in a single stage using a learnable controller to balance them. AMFT achieves better results and generalization on various reasoning tasks compared to existing methods.


<details>
  <summary>Details</summary>
Motivation: The typical two-stage fine-tuning pipeline (SFT followed by RL) for LLMs suffers from catastrophic forgetting and suboptimal trade-offs between imitation and exploration. Existing single-stage methods lack a principled mechanism for dynamically balancing SFT and RL.

Method: AMFT (Adaptive Meta Fine-Tuning) is a novel single-stage algorithm that reframes LLM fine-tuning for reasoning tasks through the lens of implicit rewards. It uses a meta-gradient adaptive weight controller to dynamically balance Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) by treating the SFT-RL balance as a learnable parameter, optimized to maximize long-term task performance. The approach is regularized by policy entropy for stability and autonomously discovers an effective training curriculum.

Result: AMFT consistently establishes a new state-of-the-art across mathematical reasoning, abstract visual reasoning, and vision-language navigation benchmarks. It also demonstrates superior generalization on out-of-distribution tasks, with ablation studies confirming the effectiveness of its meta-learning controller for stability, sample efficiency, and overall performance.

Conclusion: AMFT provides a principled and effective paradigm for LLM alignment, consistently establishing new state-of-the-art performance and demonstrating superior generalization on out-of-distribution tasks. The meta-learning controller is crucial for its stability, sample efficiency, and performance.

Abstract: Large Language Models (LLMs) are typically fine-tuned for reasoning tasks
through a two-stage pipeline of Supervised Fine-Tuning (SFT) followed by
Reinforcement Learning (RL), a process fraught with catastrophic forgetting and
suboptimal trade-offs between imitation and exploration. Recent single-stage
methods attempt to unify SFT and RL using heuristics, but lack a principled
mechanism for dynamically balancing the two paradigms. In this paper, we
reframe this challenge through the theoretical lens of \textbf{implicit
rewards}, viewing SFT and RL not as distinct methods but as complementary
reward signals. We introduce \textbf{Adaptive Meta Fine-Tuning (AMFT)}, a novel
single-stage algorithm that learns the optimal balance between SFT's implicit,
path-level reward and RL's explicit, outcome-based reward. The core of AMFT is
a \textbf{meta-gradient adaptive weight controller} that treats the SFT-RL
balance as a learnable parameter, dynamically optimizing it to maximize
long-term task performance. This forward-looking approach, regularized by
policy entropy for stability, autonomously discovers an effective training
curriculum. We conduct a comprehensive evaluation on challenging benchmarks
spanning mathematical reasoning, abstract visual reasoning (General Points),
and vision-language navigation (V-IRL). AMFT consistently establishes a new
state-of-the-art and demonstrats superior generalization on out-of-distribution
(OOD) tasks. Ablation studies and training dynamic analysis confirm that the
meta-learning controller is crucial for AMFT's stability, sample efficiency,
and performance, offering a more principled and effective paradigm for LLM
alignment.Our codes are open-sourced via https://github.com/hlxtsyj/AMFT.

</details>


### [372] [BoRA: Towards More Expressive Low-Rank Adaptation with Block Diversity](https://arxiv.org/abs/2508.06953)
*Shiwei Li,Xiandi Luo,Haozhao Wang,Xing Tang,Ziqiang Cui,Dugang Liu,Yuhua Li,Xiuqiang He,Ruixuan Li*

Main category: cs.LG

TL;DR: BoRA是一种参数高效的微调方法，通过块对角矩阵提升LoRA权重秩，性能优于LoRA且参数量增加较少。


<details>
  <summary>Details</summary>
Motivation: LoRA通过近似低秩矩阵来微调大语言模型，但增加秩以提升性能会显著增加参数数量。本研究旨在提出一种方法，在参数量增加不多的情况下，提升LoRA权重的秩，从而优化微调性能。

Method: BoRA将LoRA的低秩矩阵乘积BA视为块矩阵乘法，并将A和B分别划分为b个块。通过为每个块乘积引入对角矩阵Σᵢⱼ，得到BᵢΣᵢⱼAⱼ，从而在不显著增加参数数量的情况下，将LoRA权重的秩提高b倍。

Result: BoRA在多个数据集和模型上进行了广泛实验，证明了其性能优于现有方法，并且消融研究验证了其良好的可扩展性。

Conclusion: BoRA通过引入块对角矩阵来提高LoRA权重的秩，仅需少量额外参数即可实现性能提升，并在多项实验中证明了其优越性和可扩展性。

Abstract: Low-rank adaptation (LoRA) is a parameter-efficient fine-tuning (PEFT) method
widely used in large language models (LLMs). It approximates the update of a
pretrained weight matrix $W\in\mathbb{R}^{m\times n}$ by the product of two
low-rank matrices, $BA$, where $A \in\mathbb{R}^{r\times n}$ and
$B\in\mathbb{R}^{m\times r} (r\ll\min\{m,n\})$. Increasing the dimension $r$
can raise the rank of LoRA weights (i.e., $BA$), which typically improves
fine-tuning performance but also significantly increases the number of
trainable parameters. In this paper, we propose Block Diversified Low-Rank
Adaptation (BoRA), which improves the rank of LoRA weights with a small number
of additional parameters. Specifically, BoRA treats the product $BA$ as a block
matrix multiplication, where $A$ and $B$ are partitioned into $b$ blocks along
the columns and rows, respectively (i.e., $A=[A_1,\dots,A_b]$ and
$B=[B_1,\dots,B_b]^\top$). Consequently, the product $BA$ becomes the
concatenation of the block products $B_iA_j$ for $i,j\in[b]$. To enhance the
diversity of different block products, BoRA introduces a unique diagonal matrix
$\Sigma_{i,j} \in \mathbb{R}^{r\times r}$ for each block multiplication,
resulting in $B_i \Sigma_{i,j} A_j$. By leveraging these block-wise diagonal
matrices, BoRA increases the rank of LoRA weights by a factor of $b$ while only
requiring $b^2r$ additional parameters. Extensive experiments across multiple
datasets and models demonstrate the superiority of BoRA, and ablation studies
further validate its scalability.

</details>


### [373] [MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation](https://arxiv.org/abs/2508.08137)
*Pravallika Abbineni,Saoud Aldowaish,Colin Liechty,Soroosh Noorzad,Ali Ghazizadeh,Morteza Fayazi*

Main category: cs.LG

TL;DR: MuaLLM 是一个用于电路设计的 LLM 代理，通过 RAG 和 ReAct 框架，能高效处理文本和视觉信息，并在检索和推理任务上表现出色，同时降低了成本和提高了速度。


<details>
  <summary>Details</summary>
Motivation: 全面的文献综述对于推进电路设计方法至关重要，但当前的研究方法面临着来自大量最新研究、不一致的数据表示以及优化电路设计目标的复杂性带来的挑战。

Method: MuaLLM 集成了一个混合检索增强生成（RAG）框架，并使用了一个自适应的电路设计研究论文向量数据库。它采用了 Reason + Act（ReAct）工作流，支持迭代推理、目标设定和多步信息检索。该模型能够处理文本和视觉数据，并通过智能搜索工具、自动文档检索和实时数据库更新来动态适应。它将检索与推理分离，实现了在任意大规模语料库上的可扩展推理。

Result: MuaLLM 在 RAG-250 数据集上实现了 90.1% 的召回率，在 Reasoning-100（Reas-100）数据集上达到了 86.8% 的准确率。与标准 LLM 相比，在相同的上下文长度下，MuaLLM 的成本降低了 10 倍，速度提高了 1.6 倍，同时保持了相同的准确性。

Conclusion: MuaLLM 是一个开源的多模态大语言模型（LLM）代理，用于电路设计辅助。它通过结合混合检索增强生成（RAG）框架和自适应电路设计研究论文向量数据库，并采用 Reason + Act（ReAct）工作流进行迭代推理、目标设定和多步信息检索，解决了文献综述的挑战。与其他模型相比，MuaLLM 在保持相同准确性的前提下，成本降低高达 10 倍，速度提高 1.6 倍，并且能够处理文本和视觉数据。在 RAG-250 和 Reasoning-100 数据集上的评估结果表明，MuaLLM 在检索和多步推理方面表现出色，分别达到了 90.1% 的召回率和 86.8% 的准确率。

Abstract: Conducting a comprehensive literature review is crucial for advancing circuit
design methodologies. However, the rapid influx of state-of-the-art research,
inconsistent data representation, and the complexity of optimizing circuit
design objectives make this task significantly challenging. In this paper, we
propose MuaLLM, an open-source multimodal Large Language Model (LLM) agent for
circuit design assistance that integrates a hybrid Retrieval-Augmented
Generation (RAG) framework with an adaptive vector database of circuit design
research papers. Unlike conventional LLMs, the MuaLLM agent employs a Reason +
Act (ReAct) workflow for iterative reasoning, goal-setting, and multi-step
information retrieval. It functions as a question-answering design assistant,
capable of interpreting complex queries and providing reasoned responses
grounded in circuit literature. Its multimodal capabilities enable processing
of both textual and visual data, facilitating more efficient and comprehensive
analysis. The system dynamically adapts using intelligent search tools,
automated document retrieval from the internet, and real-time database updates.
Unlike conventional approaches constrained by model context limits, MuaLLM
decouples retrieval from inference, enabling scalable reasoning over
arbitrarily large corpora. At the maximum context length supported by standard
LLMs, MuaLLM remains up to 10x less costly and 1.6x faster while maintaining
the same accuracy. This allows rapid, no-human-in-the-loop database generation,
overcoming the bottleneck of simulation-based dataset creation for circuits. To
evaluate MuaLLM, we introduce two custom datasets: RAG-250, targeting retrieval
and citation performance, and Reasoning-100 (Reas-100), focused on multistep
reasoning in circuit design. MuaLLM achieves 90.1% recall on RAG-250, and 86.8%
accuracy on Reas-100.

</details>


### [374] [Can Multitask Learning Enhance Model Explainability?](https://arxiv.org/abs/2508.06966)
*Hiba Najjar,Bushra Alshbib,Andreas Dengel*

Main category: cs.LG

TL;DR: 使用多任务学习，将卫星数据模态作为辅助目标，在不牺牲性能的情况下提高模型的可解释性，并解决了数据稀疏性的问题。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过多任务学习来利用模态以内在解释模型行为，以解决多模态学习网络复杂性导致的可解释性差的问题。

Method: 将某些模态作为额外目标，与主任务一起预测，而不是作为附加输入。

Result: （1）在数据稀疏的情况下，在部署时进行模型推理不需要收集额外的模态；（2）模型性能与多模态基线模型性能相当，有时甚至更优；（3）可以通过辅助任务中的模型行为来解释主任务中的预测错误。

Conclusion: 该方法在三种数据集上进行了效率验证，包括分割、分类和回归任务。

Abstract: Remote sensing provides satellite data in diverse types and formats. The
usage of multimodal learning networks exploits this diversity to improve model
performance, except that the complexity of such networks comes at the expense
of their interpretability. In this study, we explore how modalities can be
leveraged through multitask learning to intrinsically explain model behavior.
In particular, instead of additional inputs, we use certain modalities as
additional targets to be predicted along with the main task. The success of
this approach relies on the rich information content of satellite data, which
remains as input modalities. We show how this modeling context provides
numerous benefits: (1) in case of data scarcity, the additional modalities do
not need to be collected for model inference at deployment, (2) the model
performance remains comparable to the multimodal baseline performance, and in
some cases achieves better scores, (3) prediction errors in the main task can
be explained via the model behavior in the auxiliary task(s). We demonstrate
the efficiency of our approach on three datasets, including segmentation,
classification, and regression tasks. Code available at
git.opendfki.de/hiba.najjar/mtl_explainability/.

</details>


### [375] [UniMove: A Unified Model for Multi-city Human Mobility Prediction](https://arxiv.org/abs/2508.06986)
*Chonghua Han,Yuan Yuan,Yukun Liu,Jingtao Ding,Jie Feng,Yong Li*

Main category: cs.LG

TL;DR: UniMove 是一种统一的多城市人类出行预测模型，通过双塔架构和 MoE Transformer 块解决了城市异质性和复杂出行模式的挑战，将预测准确性提高了 10.2%。


<details>
  <summary>Details</summary>
Motivation: 现有的解决方案通常需要为每个城市训练单独的模型，因为城市具有不同的空间表示和地理覆盖范围。然而，人类出行具有内在的随机性、不均匀的时间间隔和复杂的模式，并且由于城市结构、基础设施和人口密度的变化而带来异质性，这给建模带来了重大挑战。

Method: 提出了一种轨迹-位置双塔架构，其中位置塔用于通用空间编码，轨迹塔用于序列移动建模。还设计了 MoE Transformer 块来适应性地选择专家以处理各种移动模式。

Result: 与现有方法相比，UniMove 在多城市数据集上的广泛实验表明，其移动预测准确性提高了 10.2%。

Conclusion: UniMove 通过在多城市数据上进行联合训练和互数据增强，显著提高了出行预测的准确性，实现了真正的统一模型，代表了迈向实现人类出行统一架构的真正基础模型的关键进展。

Abstract: Human mobility prediction is vital for urban planning, transportation
optimization, and personalized services. However, the inherent randomness,
non-uniform time intervals, and complex patterns of human mobility, compounded
by the heterogeneity introduced by varying city structures, infrastructure, and
population densities, present significant challenges in modeling. Existing
solutions often require training separate models for each city due to distinct
spatial representations and geographic coverage. In this paper, we propose
UniMove, a unified model for multi-city human mobility prediction, addressing
two challenges: (1) constructing universal spatial representations for
effective token sharing across cities, and (2) modeling heterogeneous mobility
patterns from varying city characteristics. We propose a trajectory-location
dual-tower architecture, with a location tower for universal spatial encoding
and a trajectory tower for sequential mobility modeling. We also design MoE
Transformer blocks to adaptively select experts to handle diverse movement
patterns. Extensive experiments across multiple datasets from diverse cities
demonstrate that UniMove truly embodies the essence of a unified model. By
enabling joint training on multi-city data with mutual data enhancement, it
significantly improves mobility prediction accuracy by over 10.2\%. UniMove
represents a key advancement toward realizing a true foundational model with a
unified architecture for human mobility. We release the implementation at
https://github.com/tsinghua-fib-lab/UniMove/.

</details>


### [376] [A Comparative Study of Feature Selection in Tsetlin Machines](https://arxiv.org/abs/2508.06991)
*Vojtech Halenka,Ole-Christoffer Granmo,Lei Jiao,Per-Arne Andersen*

Main category: cs.LG

TL;DR: 本文首次为Tsetlin机（TM）建立了特征选择（FS）的全面基线，并评估了多种FS技术，包括TM内部评分器。研究结果表明，TM内部评分器表现具有竞争力，并能揭示特征交互模式，同时更简单的评分器成本效益更高。


<details>
  <summary>Details</summary>
Motivation: Tsetlin机（TM）提供可解释的基于子句的学习，但缺乏用于估计特征重要性的既定工具。特征选择（FS）对于提高模型的可解释性、降低复杂性以及有时提高准确性至关重要。

Method: 本文改编并评估了一系列用于TM的FS技术，包括经典的过滤方法、嵌入式方法以及最初为神经网络开发的后设解释方法（例如SHAP和LIME），还有一种源自TM子句权重和Tsetlin自动机（TA）状态的新型嵌入式评分器家族。我们使用诸如移除和再训练（ROAR）策略以及移除和去偏（ROAD）等评估协议，在12个数据集上对所有方法进行了基准测试，以评估因果影响。

Result: TM内部评分器不仅表现出竞争力，而且利用子句的可解释性揭示了相互作用的特征模式。更简单的TM特定评分器以一小部分计算成本实现了相似的准确性保留。

Conclusion: 本研究首次为Tsetlin机（TM）建立了特征选择（FS）的全面基线，并为开发专门的TM特定可解释性技术铺平了道路。TM内部评分器不仅表现出竞争力，而且利用子句的可解释性揭示了相互作用的特征模式。此外，更简单的TM特定评分器以一小部分计算成本实现了相似的准确性保留。

Abstract: Feature Selection (FS) is crucial for improving model interpretability,
reducing complexity, and sometimes for enhancing accuracy. The recently
introduced Tsetlin machine (TM) offers interpretable clause-based learning, but
lacks established tools for estimating feature importance. In this paper, we
adapt and evaluate a range of FS techniques for TMs, including classical filter
and embedded methods as well as post-hoc explanation methods originally
developed for neural networks (e.g., SHAP and LIME) and a novel family of
embedded scorers derived from TM clause weights and Tsetlin automaton (TA)
states. We benchmark all methods across 12 datasets, using evaluation
protocols, like Remove and Retrain (ROAR) strategy and Remove and Debias
(ROAD), to assess causal impact. Our results show that TM-internal scorers not
only perform competitively but also exploit the interpretability of clauses to
reveal interacting feature patterns. Simpler TM-specific scorers achieve
similar accuracy retention at a fraction of the computational cost. This study
establishes the first comprehensive baseline for FS in TM and paves the way for
developing specialized TM-specific interpretability techniques.

</details>


### [377] [TLCCSP: A Scalable Framework for Enhancing Time Series Forecasting with Time-Lagged Cross-Correlations](https://arxiv.org/abs/2508.07016)
*Jianfei Wu,Wenmian Yang,Bingning Liu,Weijia Jia*

Main category: cs.LG

TL;DR: TLCCSP framework improves time series forecasting by using SSDTW and a contrastive learning encoder to capture time-lagged cross-correlations, significantly reducing MSE and computational cost.


<details>
  <summary>Details</summary>
Motivation: Traditional deep learning models often neglect time-lagged cross-correlations between related sequences, which are vital for capturing complex temporal relationships in time series forecasting.

Method: The framework utilizes the Sequence Shifted Dynamic Time Warping (SSDTW) algorithm to capture lagged correlations and a contrastive learning-based encoder to approximate SSDTW distances, thereby reducing computational time significantly.

Result: Experimental results show substantial Mean Squared Error (MSE) reductions across weather, finance, and real estate datasets, with SSDTW achieving reductions of 16.01%, 9.95%, and 21.29% respectively, and the contrastive learning encoder further improving these by 17.88%, 6.13%, and 8.62%. The contrastive learning approach also reduces SSDTW computational time by approximately 99%.

Conclusion: The proposed TLCCSP framework effectively enhances time series forecasting accuracy by integrating time-lagged cross-correlations, outperforming single-sequence methods and offering significant computational efficiency through a contrastive learning encoder.

Abstract: Time series forecasting is critical across various domains, such as weather,
finance and real estate forecasting, as accurate forecasts support informed
decision-making and risk mitigation. While recent deep learning models have
improved predictive capabilities, they often overlook time-lagged
cross-correlations between related sequences, which are crucial for capturing
complex temporal relationships. To address this, we propose the Time-Lagged
Cross-Correlations-based Sequence Prediction framework (TLCCSP), which enhances
forecasting accuracy by effectively integrating time-lagged cross-correlated
sequences. TLCCSP employs the Sequence Shifted Dynamic Time Warping (SSDTW)
algorithm to capture lagged correlations and a contrastive learning-based
encoder to efficiently approximate SSDTW distances.
  Experimental results on weather, finance and real estate time series datasets
demonstrate the effectiveness of our framework. On the weather dataset, SSDTW
reduces mean squared error (MSE) by 16.01% compared with single-sequence
methods, while the contrastive learning encoder (CLE) further decreases MSE by
17.88%. On the stock dataset, SSDTW achieves a 9.95% MSE reduction, and CLE
reduces it by 6.13%. For the real estate dataset, SSDTW and CLE reduce MSE by
21.29% and 8.62%, respectively. Additionally, the contrastive learning approach
decreases SSDTW computational time by approximately 99%, ensuring scalability
and real-time applicability across multiple time series forecasting tasks.

</details>


### [378] [A Stage-Aware Mixture of Experts Framework for Neurodegenerative Disease Progression Modelling](https://arxiv.org/abs/2508.07032)
*Tiantian He,Keyue Jiang,An Zhao,Anna Schroder,Elinor Thompson,Sonja Soskic,Frederik Barkhof,Daniel C. Alexander*

Main category: cs.LG

TL;DR: 本研究提出了一种名为IGND-MoE的新框架，用于模拟神经退行性疾病的长期进展。该框架通过整合图神经网络和专家混合模型，能够处理不规则的纵向数据，并捕捉疾病不同阶段的复杂病理机制。实验结果表明，该模型能够提供有价值的临床见解，并与现有文献证据相符。


<details>
  <summary>Details</summary>
Motivation: 尽管长期神经退行性疾病进展通常被概念化为时空扩散过程，但由于纵向数据稀疏且疾病机制复杂多变，传统模型难以对其进行建模。为了解决这些限制，需要一种能够处理不规则数据并适应疾病进展中不同机制的模型的。

Method: 本研究提出了一种新颖的、感知阶段的专家混合（MoE）框架，通过时变专家权重明确地模拟不同贡献机制在不同疾病阶段的主导作用。在数据方面，利用迭代双重优化方法估计个体观测的时间位置，构建了从不规则快照的队列级分化轨迹。在模型方面，通过非齐次图神经网络扩散模型（IGND）增强了空间成分，该模型允许扩散系数根据节点状态和时间变化，为大脑网络提供更灵活的表示。此外，还引入了局部神经反应模块来捕获超出标准过程的复杂动态。

Result: IGND-MoE模型在处理纵向数据稀疏性和疾病机制复杂性方面取得了显著进展，并且模型产生的阶段性权重与现有研究文献一致，揭示了图相关过程在早期阶段的影响力更大，而后期则由其他未知物理过程主导。

Conclusion: 提出的IGND-MoE模型能够动态地整合时间状态下的各个组件，为理解特定阶段的病理机制如何促成分化提供了一个有原则的方法。该模型的时间阶段权重产生了新的临床见解，这些见解与现有文献一致，表明图相关过程在早期阶段更具影响力，而在后期，其他未知的物理过程则变得占主导地位。

Abstract: The long-term progression of neurodegenerative diseases is commonly
conceptualized as a spatiotemporal diffusion process that consists of a graph
diffusion process across the structural brain connectome and a localized
reaction process within brain regions. However, modeling this progression
remains challenging due to 1) the scarcity of longitudinal data obtained
through irregular and infrequent subject visits and 2) the complex interplay of
pathological mechanisms across brain regions and disease stages, where
traditional models assume fixed mechanisms throughout disease progression. To
address these limitations, we propose a novel stage-aware Mixture of Experts
(MoE) framework that explicitly models how different contributing mechanisms
dominate at different disease stages through time-dependent expert
weighting.Data-wise, we utilize an iterative dual optimization method to
properly estimate the temporal position of individual observations,
constructing a co hort-level progression trajectory from irregular snapshots.
Model-wise, we enhance the spatial component with an inhomogeneous graph neural
diffusion model (IGND) that allows diffusivity to vary based on node states and
time, providing more flexible representations of brain networks. We also
introduce a localized neural reaction module to capture complex dynamics beyond
standard processes.The resulting IGND-MoE model dynamically integrates these
components across temporal states, offering a principled way to understand how
stage-specific pathological mechanisms contribute to progression. The
stage-wise weights yield novel clinical insights that align with literature,
suggesting that graph-related processes are more influential at early stages,
while other unknown physical processes become dominant later on.

</details>


### [379] [Membership and Memorization in LLM Knowledge Distillation](https://arxiv.org/abs/2508.07054)
*Ziqi Zhang,Ali Shahin Shamsabadi,Hanxiao Lu,Yifeng Cai,Hamed Haddadi*

Main category: cs.LG

TL;DR: 大语言模型知识蒸馏（KD）存在隐私风险，所有现有方法均如此，但风险程度不同，且风险在模型不同部分和记忆/成员风险之间存在差异。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型知识蒸馏（KD）技术虽然旨在降低大语言模型的计算成本，但可能将教师模型训练中的隐私泄露给学生模型。

Method: 本研究系统地表征和研究了六种大语言模型知识蒸馏（KD）技术中固有的成员资格和记忆隐私风险。研究人员在跨越七个自然语言处理任务的指令调整设置中，结合三种教师模型系列（GPT-2、LLAMA-2 和 OPT）和不同大小的学生模型进行了实验，以分析关键的 KD 组件（如 KD 目标函数、学生训练数据和自然语言处理任务）如何影响隐私风险。

Result: 研究表明，所有现有的大语言模型知识蒸馏（KD）方法都存在隐私风险，但风险程度因 KD 技术而异。研究还发现，记忆和成员隐私风险之间存在显著差异，并且隐私风险在模型的不同部分（按块划分）也存在显著差异。

Conclusion: 所有现有的大语言模型知识蒸馏（KD）方法都存在从教师模型到学生模型的成员和记忆隐私风险，但不同 KD 技术之间的隐私风险程度不同。此外，记忆和成员隐私风险之间存在显著差异，并且隐私风险因模型块而异。

Abstract: Recent advances in Knowledge Distillation (KD) aim to mitigate the high
computational demands of Large Language Models (LLMs) by transferring knowledge
from a large ''teacher'' to a smaller ''student'' model. However, students may
inherit the teacher's privacy when the teacher is trained on private data. In
this work, we systematically characterize and investigate membership and
memorization privacy risks inherent in six LLM KD techniques. Using
instruction-tuning settings that span seven NLP tasks, together with three
teacher model families (GPT-2, LLAMA-2, and OPT), and various size student
models, we demonstrate that all existing LLM KD approaches carry membership and
memorization privacy risks from the teacher to its students. However, the
extent of privacy risks varies across different KD techniques. We
systematically analyse how key LLM KD components (KD objective functions,
student training data and NLP tasks) impact such privacy risks. We also
demonstrate a significant disagreement between memorization and membership
privacy risks of LLM KD techniques. Finally, we characterize per-block privacy
risk and demonstrate that the privacy risk varies across different blocks by a
large margin.

</details>


### [380] [Surgical Knowledge Rewrite in Compact LLMs: An 'Unlearn-then-Learn' Strategy with ($IA^3$) for Localized Factual Modulation and Catastrophic Forgetting Mitigation](https://arxiv.org/abs/2508.07075)
*Stanley Ngugi*

Main category: cs.LG

TL;DR: 该研究提出了一种“遗忘-学习”策略，利用$IA^3$和电路定位技术，有效解决了大语言模型（LLMs）在更新冲突知识时遇到的精确编辑和灾难性遗忘问题，提高了知识更新的安全性和可控性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在动态知识更新方面存在困难，特别是在新信息与深层嵌入事实冲突时。这种冲突的事实编辑通常会导致两个关键问题：对新事实的采纳产生抵抗力，以及严重地遗忘无关知识（灾难性遗忘）。本研究旨在解决LLMs在知识更新中的这些挑战。

Method: 该研究引入并评估了一种新颖的“遗忘-学习”策略，用于大语言模型（LLM）的精确知识编辑。该策略利用参数高效微调（PEFT）技术中的Infused Adapter by Inhibiting and Amplifying Inner Activations ($IA^3$)。关键在于，该两阶段方法依赖于一个初始的电路定位阶段，以识别并精确靶向负责编码冲突事实的内部组件。通过在microsoft/Phi-3-mini-4k-instruct模型上进行严格的实验方法学评估，验证了该方法。

Result: 该两阶段方法在microsoft/Phi-3-mini-4k-instruct模型上实现了近乎完美的准确率（98.50%），用于新调制的知识，同时有效抑制了原始冲突事实（96.00%的遗忘率）。该策略展现了前所未有的定位能力（72.00%的F_control准确率），显著缓解了直接微调方法中出现的灾难性遗忘问题（F_control准确率低至约20%）。定性分析揭示了一种“软遗忘”机制，原始知识被抑制但仍可条件性访问，增强了模型的安全性和可控性。

Conclusion: 这项研究通过引入一种新颖的“遗忘-学习”策略，并结合参数高效微调（PEFT）技术和内部组件定位，实现了大语言模型（LLM）的精确知识编辑。该方法在微软的Phi-3-mini-4k-instruct模型上进行了严格评估，结果显示在更新冲突事实方面取得了近乎完美的准确率（98.50%），同时有效抑制了冲突事实（遗忘率为96.00%）。该策略还展现了前所未有的定位能力（72.00% F_control准确率），显著缓解了直接微调方法中出现的灾难性遗忘问题（F_control准确率低至约20%）。此外，定性分析揭示了一种“软遗忘”机制，使得原始知识在默认检索时被抑制，但仍可被条件性访问，从而提高了模型的安全性和可控性。这些发现标志着在实现紧凑型LLM的精确、局部化和安全知识管理方面取得了重大进展。

Abstract: Large Language Models (LLMs) struggle with dynamic knowledge updates,
especially when new information conflicts with deeply embedded facts. Such
conflicting factual edits often lead to two critical issues: resistance to
adopting the new fact and severe catastrophic forgetting of unrelated
knowledge. This paper introduces and evaluates a novel "unlearn-then-learn"
strategy for precise knowledge editing in LLMs, leveraging the
parameter-efficient fine-tuning (PEFT) technique, Infused Adapter by Inhibiting
and Amplifying Inner Activations ($IA^3$). Crucially, this two-stage approach
is powered by an initial circuit localization phase that identifies and targets
the specific internal components responsible for encoding the conflicting fact.
Through a rigorous experimental methodology on
microsoft/Phi-3-mini-4k-instruct, we demonstrate that this mechanistically
informed two-stage approach achieves near-perfect accuracy (98.50%) for the
new, modulated fact while simultaneously effectively suppressing the original
conflicting fact (96.00% forget rate). Critically, our strategy exhibits
unprecedented localization (72.00% F_control accuracy), dramatically mitigating
catastrophic forgetting observed in direct fine-tuning approaches (which showed
as low as ~20% F_control accuracy), a direct benefit of our targeted
interpretability-guided intervention. Furthermore, qualitative analysis reveals
a nuanced mechanism of "soft forgetting," where original knowledge is
suppressed from default retrieval but remains latent and conditionally
accessible, enhancing model safety and control. These findings represent a
significant advancement towards precise, localized, and safe knowledge
management in compact LLMs.

</details>


### [381] [Improving Real-Time Concept Drift Detection using a Hybrid Transformer-Autoencoder Framework](https://arxiv.org/abs/2508.07085)
*N Harshit,K Mounvik*

Main category: cs.LG

TL;DR: 提出了一种基于Transformer和Autoencoder的混合框架，通过Trust Score方法能更早、更灵敏地检测概念漂移。


<details>
  <summary>Details</summary>
Motivation: 现有的概念漂移检测方法通常是反应性的，对早期检测不敏感，而概念漂移（数据分布的渐进或突然变化）会显著降低应用机器学习模型的性能。

Method: 提出了一种混合框架，结合了Transformers和Autoencoders来模拟复杂的时间动态并提供在线漂移检测。构建了一个Trust Score方法，该方法结合了统计和重构指标（PSI、JSD、Transformer-AE误差）、预测不确定性、规则冲突以及与Trust Score定义的组合指标一致的分类器错误率趋势。

Result: 所提出的混合框架在包含注入漂移的航空乘客数据集上进行了评估，结果表明与常用的Autoencoders和其他基线方法相比，Transformer-Autoencoder能够更早、更灵敏地检测到漂移，并在误差率和逻辑冲突方面提供了更好的建模。

Conclusion: 该研究提出了一种结合Transformer和Autoencoder的混合框架，用于在线概念漂移检测，通过结合统计指标、预测不确定性、规则冲突和分类器错误率等多种信号，构建了一个Trust Score方法，能够更早、更灵敏地检测漂移，并优于现有基线方法。

Abstract: In applied machine learning, concept drift, which is either gradual or abrupt
changes in data distribution, can significantly reduce model performance.
Typical detection methods,such as statistical tests or reconstruction-based
models,are generally reactive and not very sensitive to early detection. Our
study proposes a hybrid framework consisting of Transformers and Autoencoders
to model complex temporal dynamics and provide online drift detection. We
create a distinct Trust Score methodology, which includes signals on (1)
statistical and reconstruction-based drift metrics, more specifically, PSI,
JSD, Transformer-AE error, (2) prediction uncertainty, (3) rules violations,
and (4) trend of classifier error aligned with the combined metrics defined by
the Trust Score. Using a time sequenced airline passenger data set with
synthetic drift, our proposed model allows for a better detection of drift
using as a whole and at different detection thresholds for both sensitivity and
interpretability compared to baseline methods and provides a strong pipeline
for drift detection in real time for applied machine learning. We evaluated
performance using a time-sequenced airline passenger dataset having the
gradually injected stimulus of drift in expectations,e.g. permuted ticket
prices in later batches, broken into 10 time segments [1].In the data, our
results support that the Transformation-Autoencoder detected drift earlier and
with more sensitivity than the autoencoders commonly used in the literature,
and provided improved modeling over more error rates and logical violations.
Therefore, a robust framework was developed to reliably monitor concept drift.

</details>


### [382] [Towards High-Order Mean Flow Generative Models: Feasibility, Expressivity, and Provably Efficient Criteria](https://arxiv.org/abs/2508.07102)
*Yang Cao,Yubin Chen,Zhao Song,Jiahao Zhang*

Main category: cs.LG

TL;DR: 本研究提出了二阶均值流，将平均加速度场纳入均值流目标，以实现高效采样。我们证明了其理论可行性、表达能力和可扩展性，为高阶流匹配模型铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 生成模型通过无模拟范式（如流匹配）取得了显著进展，特别是均值流框架，它用平均速度替换瞬时速度场以实现高效的单步采样。在本研究中，我们对二阶均值流进行了理论研究，这是一个通过将平均加速度场纳入均值流目标来引入的新扩展。

Method: 我们首先通过证明平均加速度满足类似于一阶均值流的广义一致性条件来建立我们方法的可行性，从而支持稳定的单步采样和可处理的损失函数。然后，我们通过电路复杂性分析来表征其表达能力，表明在温和的假设下，二阶均值流采样过程可以通过 $\mathsf{TC}^0$ 类中的均匀阈值电路来实现。最后，我们通过利用快速近似注意力计算，推导出可扩展实现的具有可证明效率的标准。

Result: 我们证明了平均加速度满足一个广义的一致性条件，这支持了稳定的单步采样和可处理的损失函数。我们还表明，二阶均值流采样过程可以用 $\mathsf{TC}^0$ 类中的均匀阈值电路实现。此外，我们证明了二阶均值流架构中的注意力操作可以在 $n^{2+o(1)}$ 时间内近似到 $1/\mathrm{poly}(n)$ 的误差。

Conclusion: 我们的结果为高阶流匹配模型奠定了理论基础，这些模型结合了丰富的动力学和实用的采样效率。

Abstract: Generative modelling has seen significant advances through simulation-free
paradigms such as Flow Matching, and in particular, the MeanFlow framework,
which replaces instantaneous velocity fields with average velocities to enable
efficient single-step sampling. In this work, we introduce a theoretical study
on Second-Order MeanFlow, a novel extension that incorporates average
acceleration fields into the MeanFlow objective. We first establish the
feasibility of our approach by proving that the average acceleration satisfies
a generalized consistency condition analogous to first-order MeanFlow, thereby
supporting stable, one-step sampling and tractable loss functions. We then
characterize its expressivity via circuit complexity analysis, showing that
under mild assumptions, the Second-Order MeanFlow sampling process can be
implemented by uniform threshold circuits within the $\mathsf{TC}^0$ class.
Finally, we derive provably efficient criteria for scalable implementation by
leveraging fast approximate attention computations: we prove that attention
operations within the Second-Order MeanFlow architecture can be approximated to
within $1/\mathrm{poly}(n)$ error in time $n^{2+o(1)}$. Together, these results
lay the theoretical foundation for high-order flow matching models that combine
rich dynamics with practical sampling efficiency.

</details>


### [383] [BrainATCL: Adaptive Temporal Brain Connectivity Learning for Functional Link Prediction and Age Estimation](https://arxiv.org/abs/2508.07106)
*Yiran Huang,Amirhossein Nouranizadeh,Christine Ahrends,Mengjia Xu*

Main category: cs.LG

TL;DR: BrainATCL是一种用于学习动态fMRI数据连接的新型框架，能够有效处理长程时间依赖性，并在预测任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统图神经网络（GNNs）在捕获动态fMRI数据中的长程时间依赖性方面的不足，提出BrainATCL框架。

Method: BrainATCL是一个无监督、非参数的自适应时间大脑连接学习框架，通过动态调整查找窗口并结合GINE-Mamba2骨干网络来编码图序列，同时融入大脑结构和功能信息作为边属性，以学习动态功能连接的时空表示。

Result: BrainATCL在功能链接预测和年龄估计任务上均取得优异实验结果，证明了其有效性。

Conclusion: BrainATCL在功能链接预测和年龄估计任务上展现出优越的性能和强大的泛化能力，包括跨会话预测。

Abstract: Functional Magnetic Resonance Imaging (fMRI) is an imaging technique widely
used to study human brain activity. fMRI signals in areas across the brain
transiently synchronise and desynchronise their activity in a highly structured
manner, even when an individual is at rest. These functional connectivity
dynamics may be related to behaviour and neuropsychiatric disease. To model
these dynamics, temporal brain connectivity representations are essential, as
they reflect evolving interactions between brain regions and provide insight
into transient neural states and network reconfigurations. However,
conventional graph neural networks (GNNs) often struggle to capture long-range
temporal dependencies in dynamic fMRI data. To address this challenge, we
propose BrainATCL, an unsupervised, nonparametric framework for adaptive
temporal brain connectivity learning, enabling functional link prediction and
age estimation. Our method dynamically adjusts the lookback window for each
snapshot based on the rate of newly added edges. Graph sequences are
subsequently encoded using a GINE-Mamba2 backbone to learn spatial-temporal
representations of dynamic functional connectivity in resting-state fMRI data
of 1,000 participants from the Human Connectome Project. To further improve
spatial modeling, we incorporate brain structure and function-informed edge
attributes, i.e., the left/right hemispheric identity and subnetwork membership
of brain regions, enabling the model to capture biologically meaningful
topological patterns. We evaluate our BrainATCL on two tasks: functional link
prediction and age estimation. The experimental results demonstrate superior
performance and strong generalization, including in cross-session prediction
scenarios.

</details>


### [384] [Approaching Maximal Information Extraction in Low-Signal Regimes via Multiple Instance Learning](https://arxiv.org/abs/2508.07114)
*Atakan Azakli,Bernd Stelzer*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this work, we propose a new machine learning (ML) methodology to obtain
more precise predictions for some parameters of interest in a given hypotheses
testing problem. Our proposed method also allows ML models to have more
discriminative power in cases where it is extremely challenging for
state-of-the-art classifiers to have any level of accurate predictions. This
method can also allow us to systematically decrease the error from ML models in
their predictions. In this paper, we provide a mathematical motivation why
Multiple Instance Learning (MIL) would have more predictive power over their
single-instance counterparts. We support our theoretical claims by analyzing
the behavior of the MIL models through their scaling behaviors with respect to
the number of instances on which the model makes predictions. As a concrete
application, we constrain Wilson coefficients of the Standard Model Effective
Field Theory (SMEFT) using kinematic information from subatomic particle
collision events at the Large Hadron Collider (LHC). We show that under certain
circumstances, it might be possible to extract the theoretical maximum Fisher
Information latent in a dataset.

</details>


### [385] [From Nodes to Narratives: Explaining Graph Neural Networks with LLMs and Graph Context](https://arxiv.org/abs/2508.07117)
*Peyman Baghershahi,Gregoire Fournier,Pranav Nyati,Sourav Medya*

Main category: cs.LG

TL;DR: LOGIC uses LLMs to create faithful and understandable explanations for GNN predictions, overcoming limitations of existing methods by combining GNN embeddings with textual graph data in hybrid prompts, leading to better insightfulness.


<details>
  <summary>Details</summary>
Motivation: GNNs are not inherently interpretable and thus, many explanation methods have been proposed. However, existing explanation methods often struggle to generate interpretable, fine-grained rationales, especially when node attributes include rich natural language.

Method: LOGIC, a lightweight, post-hoc framework that uses large language models (LLMs) to generate faithful and interpretable explanations for GNN predictions. LOGIC projects GNN node embeddings into the LLM embedding space and constructs hybrid prompts that interleave soft prompts with textual inputs from the graph structure.

Result: LOGIC achieves a favorable trade-off between fidelity and sparsity, while significantly improving human-centric metrics such as insightfulness.

Conclusion: LOGIC sets a new direction for LLM-based explainability in graph learning by aligning GNN internals with human reasoning.

Abstract: Graph Neural Networks (GNNs) have emerged as powerful tools for learning over
structured data, including text-attributed graphs, which are common in domains
such as citation networks, social platforms, and knowledge graphs. GNNs are not
inherently interpretable and thus, many explanation methods have been proposed.
However, existing explanation methods often struggle to generate interpretable,
fine-grained rationales, especially when node attributes include rich natural
language. In this work, we introduce LOGIC, a lightweight, post-hoc framework
that uses large language models (LLMs) to generate faithful and interpretable
explanations for GNN predictions. LOGIC projects GNN node embeddings into the
LLM embedding space and constructs hybrid prompts that interleave soft prompts
with textual inputs from the graph structure. This enables the LLM to reason
about GNN internal representations and produce natural language explanations
along with concise explanation subgraphs. Our experiments across four
real-world TAG datasets demonstrate that LOGIC achieves a favorable trade-off
between fidelity and sparsity, while significantly improving human-centric
metrics such as insightfulness. LOGIC sets a new direction for LLM-based
explainability in graph learning by aligning GNN internals with human
reasoning.

</details>


### [386] [Multi-Level Service Performance Forecasting via Spatiotemporal Graph Neural Networks](https://arxiv.org/abs/2508.07122)
*Zhihao Xue,Yun Zi,Nia Qi,Ming Gong,Yujun Zou*

Main category: cs.LG

TL;DR: 提出了一种基于时空图神经网络的算法，用于预测分布式后端系统中多层级服务调用结构的性能波动。该模型通过提取服务拓扑依赖和捕捉性能指标的时间动态演化，实现了高精度预测，并在大规模数据集上的实验结果优于现有方法，展现了实际应用潜力。


<details>
  <summary>Details</summary>
Motivation: 为了解决分布式后端系统中多层级服务调用结构下性能波动预测的挑战。

Method: 提出了一种基于时空图神经网络的性能预测算法。该算法将不同时间切片下的系统状态抽象为一系列图结构，并整合了服务节点的运行时特征和它们之间的调用关系，构建了一个统一的时空建模框架。具体来说，模型首先利用图卷积网络提取服务拓扑中的高阶依赖信息，然后使用门控循环网络捕捉性能指标随时间变化的动态演化，并引入时间编码机制来增强对非平稳时间序列的表示能力。该模型采用端到端的方式进行训练，通过优化多层嵌套结构来实现对未来服务性能指标的高精度回归。

Result: 实验结果表明，所提出的模型在MAE、RMSE和R2等关键指标上优于现有的代表性方法，并且在不同负载强度和结构复杂度下保持了良好的鲁棒性。

Conclusion: 该模型在预测性能方面优于现有方法，并且在不同负载强度和结构复杂度下表现出良好的鲁棒性，证明了其在后端服务性能管理方面的实际应用潜力。

Abstract: This paper proposes a spatiotemporal graph neural network-based performance
prediction algorithm to address the challenge of forecasting performance
fluctuations in distributed backend systems with multi-level service call
structures. The method abstracts system states at different time slices into a
sequence of graph structures. It integrates the runtime features of service
nodes with the invocation relationships among services to construct a unified
spatiotemporal modeling framework. The model first applies a graph
convolutional network to extract high-order dependency information from the
service topology. Then it uses a gated recurrent network to capture the dynamic
evolution of performance metrics over time. A time encoding mechanism is also
introduced to enhance the model's ability to represent non-stationary temporal
sequences. The architecture is trained in an end-to-end manner, optimizing the
multi-layer nested structure to achieve high-precision regression of future
service performance metrics. To validate the effectiveness of the proposed
method, a large-scale public cluster dataset is used. A series of
multi-dimensional experiments are designed, including variations in time
windows and concurrent load levels. These experiments comprehensively evaluate
the model's predictive performance and stability. The experimental results show
that the proposed model outperforms existing representative methods across key
metrics such as MAE, RMSE, and R2. It maintains strong robustness under varying
load intensities and structural complexities. These results demonstrate the
model's practical potential for backend service performance management tasks.

</details>


### [387] [Pref-GUIDE: Continual Policy Learning from Real-Time Human Feedback via Preference-Based Learning](https://arxiv.org/abs/2508.07126)
*Zhengran Ji,Boyuan Chen*

Main category: cs.LG

TL;DR: Pref-GUIDE 将有噪声的实时标量人类反馈转化为更可靠的偏好数据，以改进在线强化学习中的奖励模型。


<details>
  <summary>Details</summary>
Motivation: 在奖励函数难以精确定义的强化学习任务中，利用人类反馈进行训练至关重要。以往的方法依赖于离线轨迹比较来收集人类偏好，但在智能体需要实时适应的在线学习场景中，这种数据不可用。虽然最近的方法通过收集实时标量反馈来指导智能体行为，但这种标量反馈通常存在噪声和不一致性，限制了学习到的奖励的准确性和泛化能力。

Method: Pref-GUIDE 框架将实时标量反馈转化为偏好类数据，以改进奖励模型学习，实现持续策略训练。具体来说，Pref-GUIDE Individual 通过比较短期内的智能体行为并过滤模糊反馈来解决时间不一致性问题。Pref-GUIDE Voting 进一步通过聚合用户群体中的奖励模型来形成共识偏好，从而提高鲁棒性。

Result: Pref-GUIDE 在三种具有挑战性的环境中显著优于基于标量反馈的基线方法，其中投票变体甚至优于专家设计的密集奖励。

Conclusion: Pref-GUIDE 通过将标量反馈重构为基于偏好的数据，改进了用于持续策略训练的奖励模型学习。Pref-GUIDE Individual 通过比较短期内的智能体行为并过滤模糊反馈来减轻时间不一致性。Pref-GUIDE Voting 通过聚合用户群体中的奖励模型来形成共识偏好，进一步增强了鲁棒性。在三种具有挑战性的环境中，Pref-GUIDE 的表现明显优于基于标量反馈的基线方法，其中投票变体甚至优于专家设计的密集奖励。通过将标量反馈重构为具有群体反馈的结构化偏好，Pref-GUIDE 为在线强化学习中利用人类输入提供了一种可扩展且有原则的方法。

Abstract: Training reinforcement learning agents with human feedback is crucial when
task objectives are difficult to specify through dense reward functions. While
prior methods rely on offline trajectory comparisons to elicit human
preferences, such data is unavailable in online learning scenarios where agents
must adapt on the fly. Recent approaches address this by collecting real-time
scalar feedback to guide agent behavior and train reward models for continued
learning after human feedback becomes unavailable. However, scalar feedback is
often noisy and inconsistent, limiting the accuracy and generalization of
learned rewards. We propose Pref-GUIDE, a framework that transforms real-time
scalar feedback into preference-based data to improve reward model learning for
continual policy training. Pref-GUIDE Individual mitigates temporal
inconsistency by comparing agent behaviors within short windows and filtering
ambiguous feedback. Pref-GUIDE Voting further enhances robustness by
aggregating reward models across a population of users to form consensus
preferences. Across three challenging environments, Pref-GUIDE significantly
outperforms scalar-feedback baselines, with the voting variant exceeding even
expert-designed dense rewards. By reframing scalar feedback as structured
preferences with population feedback, Pref-GUIDE offers a scalable and
principled approach for harnessing human input in online reinforcement
learning.

</details>


### [388] [How Effectively Can Large Language Models Connect SNP Variants and ECG Phenotypes for Cardiovascular Risk Prediction?](https://arxiv.org/abs/2508.07127)
*Niranjana Arun Menon,Iqra Farooq,Yulong Li,Sara Ahmed,Yutong Xie,Muhammad Awais,Imran Razzak*

Main category: cs.LG

TL;DR: LLM在基因组数据分析中展现出在心脏病风险预测方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病（CVD）的预测因其多因素病因和全球负担而充满挑战。尽管基因组学和电生理学数据可用性不断提高，但从这些数据中提取有意义的生物学见解仍然困难。本研究旨在探索微调LLM在利用基因标记预测心脏病和SNP方面的潜力。

Method: 利用链式思考（CoT）推理，对微调后的LLM进行训练，使其能够处理高维、嘈杂和稀疏注释的基因组数据，并生成疾病标签和临床推断。

Result: LLM能够学习结构化和半结构化基因组数据中的潜在生物学关系，并根据家庭遗传谱系信息进行推断。

Conclusion: LLM在心脏病预测和SNP风险评估方面显示出巨大潜力，有望促进心脏病早期检测、风险评估和个性化医疗。

Abstract: Cardiovascular disease (CVD) prediction remains a tremendous challenge due to
its multifactorial etiology and global burden of morbidity and mortality.
Despite the growing availability of genomic and electrophysiological data,
extracting biologically meaningful insights from such high-dimensional, noisy,
and sparsely annotated datasets remains a non-trivial task. Recently, LLMs has
been applied effectively to predict structural variations in biological
sequences. In this work, we explore the potential of fine-tuned LLMs to predict
cardiac diseases and SNPs potentially leading to CVD risk using genetic markers
derived from high-throughput genomic profiling. We investigate the effect of
genetic patterns associated with cardiac conditions and evaluate how LLMs can
learn latent biological relationships from structured and semi-structured
genomic data obtained by mapping genetic aspects that are inherited from the
family tree. By framing the problem as a Chain of Thought (CoT) reasoning task,
the models are prompted to generate disease labels and articulate informed
clinical deductions across diverse patient profiles and phenotypes. The
findings highlight the promise of LLMs in contributing to early detection, risk
assessment, and ultimately, the advancement of personalized medicine in cardiac
care.

</details>


### [389] [A Globally Optimal Analytic Solution for Semi-Nonnegative Matrix Factorization with Nonnegative or Mixed Inputs](https://arxiv.org/abs/2508.07134)
*Lu Chenggang*

Main category: cs.LG

TL;DR: 提出了一种新的、无迭代的、全局最优的半非负矩阵分解（semi-NMF）方法，通过正交分解解决现有算法易陷入局部最小值的问题，并在实验中证明其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的半非负矩阵分解（semi-NMF）算法通常是迭代的、非凸的，并且容易陷入局部最小值，限制了其在分解具有混合符号的数据方面的应用。

Method: 提出了一种通过对输入数据的散布矩阵进行正交分解来获得半非负矩阵分解（semi-NMF）全局最优解的新方法，该方法是无迭代的。

Result: 在Frobenius范数下，该方法能获得semi-NMF问题的全局最优解，并严格证明了其解能够达到重构误差的全局最小值。在输入矩阵非负的情况下，该方法通常能获得比标准NMF算法更低的重构误差，并且在低秩情况下（秩为1或2）能精确地还原为非负矩阵分解。实验结果表明，该方法在重构精度方面优于现有的NMF和semi-NMF方法。

Conclusion: 该算法提供理论保证和实际优势，为优化和数据分析中的矩阵分解提供了新的视角。

Abstract: Semi-Nonnegative Matrix Factorization (semi-NMF) extends classical
Nonnegative Matrix Factorization (NMF) by allowing the basis matrix to contain
both positive and negative entries, making it suitable for decomposing data
with mixed signs. However, most existing semi-NMF algorithms are iterative,
non-convex, and prone to local minima. In this paper, we propose a novel method
that yields a globally optimal solution to the semi-NMF problem under the
Frobenius norm, through an orthogonal decomposition derived from the scatter
matrix of the input data. We rigorously prove that our solution attains the
global minimum of the reconstruction error. Furthermore, we demonstrate that
when the input matrix is nonnegative, our method often achieves lower
reconstruction error than standard NMF algorithms, although unfortunately the
basis matrix may not satisfy nonnegativity. In particular, in low-rank cases
such as rank 1 or 2, our solution reduces exactly to a nonnegative
factorization, recovering the NMF structure. We validate our approach through
experiments on both synthetic data and the UCI Wine dataset, showing that our
method consistently outperforms existing NMF and semi-NMF methods in terms of
reconstruction accuracy. These results confirm that our globally optimal,
non-iterative formulation offers both theoretical guarantees and empirical
advantages, providing a new perspective on matrix factorization in optimization
and data analysis.

</details>


### [390] [A Stable and Principled Loss Function for Direct Language Model Alignment](https://arxiv.org/abs/2508.07137)
*Yuandong Tan*

Main category: cs.LG

TL;DR: 本研究提出了一种新的损失函数，以解决 DPO 在 LLM 对齐中的理论缺陷和训练不稳定性问题。该方法通过设定一个有限的目标 logits 差值，提高了训练稳定性和对齐效果，并在实验中取得了优于 DPO 和可与更大模型相媲美的结果。


<details>
  <summary>Details</summary>
Motivation: 现有方法 DPO（直接偏好优化）虽然简化了 RLHF 流程，但其损失函数在理论上存在问题，可能导致训练不稳定和奖励黑客行为。这是因为 DPO 损失函数鼓励无限最大化 logits 差值，这可能偏离其原始推导。

Method: 提出了一种新的损失函数，该函数直接从 RLHF 最优性条件推导而来。该方法通过将 logits 差值目标设定为一个由潜在奖励决定的特定有限值，而不是最大化该差值，来解决 DPO 损失函数理论上的不一致性问题。通过理论分析和基于梯度的比较，证明了该方法可以避免 DPO 在不期望响应概率接近零时出现的梯度问题，从而提高了训练的稳定性和对齐效果。

Result: 通过对 Qwen2.5-7B 模型进行微调，实验结果表明，所提出的方法相比标准的 DPO 基线在胜率上有了显著的提升，并且在与 Llama-3.1-8B 等更大模型进行比较时，也取得了具有竞争力的性能。

Conclusion: 所提出的损失函数通过将 logits 差值目标设定为一个由潜在奖励决定的特定有限值，而非最大化该差值，从而解决了 DPO 的理论和实践问题。该方法在理论上避免了 DPO 在不期望响应概率接近零时出现的梯度问题，提高了训练的稳定性并防止了奖励黑客行为，最终实现了更有效的对齐。在 Qwen2.5-7B 模型上的实验结果表明，该方法相比标准 DPO 有显著的胜率提升，并且在与 Llama-3.1-8B 等更大模型相比时也表现出竞争力。

Abstract: The alignment of large language models (LLMs) with human preferences is
commonly achieved through Reinforcement Learning from Human Feedback (RLHF).
Direct Preference Optimization (DPO) simplified this paradigm by establishing a
direct mapping between the optimal policy and a reward function, eliminating
the need for an explicit reward model. However, we argue that the DPO loss
function is theoretically misaligned with its own derivation, as it promotes
the indefinite maximization of a logits difference, which can lead to training
instability and reward hacking. In this paper, we propose a novel loss function
derived directly from the RLHF optimality condition. Our proposed loss targets
a specific, finite value for the logits difference, which is dictated by the
underlying reward, rather than its maximization. We provide a theoretical
analysis, including a gradient-based comparison, to demonstrate that our method
avoids the large gradients that plague DPO when the probability of dispreferred
responses approaches zero. This inherent stability prevents reward hacking and
leads to more effective alignment. We validate our approach by fine-tuning a
Qwen2.5-7B model, showing significant win-rate improvements over a standard DPO
baseline and achieving competitive performance against larger models like
Llama-3.1-8B.

</details>


### [391] [What One Cannot, Two Can: Two-Layer Transformers Provably Represent Induction Heads on Any-Order Markov Chains](https://arxiv.org/abs/2508.07208)
*Chanakya Ekbote,Marco Bondaschi,Nived Rajaraman,Jason D. Lee,Michael Gastpar,Ashok Vardhan Makkuva,Paul Pu Liang*

Main category: cs.LG

TL;DR: 两层单头 Transformer 可表示任意 k 阶马尔可夫过程，揭示了浅层模型在结构化序列建模任务中的 ICL 能力。


<details>
  <summary>Details</summary>
Motivation: 探究 Transformer 深度与马尔可夫阶数对 ICL 能力的影响，特别是解决两层单头 Transformer 是否能表示任意 k 阶马尔可夫过程的问题。

Method: 通过理论分析，证明了具有单头层的两层 Transformer 可以表示任何 k 阶马尔可夫过程，并分析了该构造的学习动态，特别是针对一阶马尔可夫链的简化变体。

Result: 证明了具有单头层的两层 Transformer 可以表示任何 k 阶马尔可夫过程，提供了 Transformer 深度和马尔可夫阶数在 ICL 中相互作用的最精确表征。

Conclusion: 本文证明了具有单头层的两层 Transformer 可以表示任何 k 阶马尔可夫过程，为 Transformer 深度和马尔可夫阶数在 ICL 中的相互作用提供了最精确的表征。此外，我们还分析了两层构造的学习动态，特别关注了一阶马尔可夫链的简化变体，阐释了有效的上下文表示如何在训练过程中出现。

Abstract: In-context learning (ICL) is a hallmark capability of transformers, through
which trained models learn to adapt to new tasks by leveraging information from
the input context. Prior work has shown that ICL emerges in transformers due to
the presence of special circuits called induction heads. Given the equivalence
between induction heads and conditional k-grams, a recent line of work modeling
sequential inputs as Markov processes has revealed the fundamental impact of
model depth on its ICL capabilities: while a two-layer transformer can
efficiently represent a conditional 1-gram model, its single-layer counterpart
cannot solve the task unless it is exponentially large. However, for higher
order Markov sources, the best known constructions require at least three
layers (each with a single attention head) - leaving open the question: can a
two-layer single-head transformer represent any kth-order Markov process? In
this paper, we precisely address this and theoretically show that a two-layer
transformer with one head per layer can indeed represent any conditional
k-gram. Thus, our result provides the tightest known characterization of the
interplay between transformer depth and Markov order for ICL. Building on this,
we further analyze the learning dynamics of our two-layer construction,
focusing on a simplified variant for first-order Markov chains, illustrating
how effective in-context representations emerge during training. Together,
these results deepen our current understanding of transformer-based ICL and
illustrate how even shallow architectures can surprisingly exhibit strong ICL
capabilities on structured sequence modeling tasks.

</details>


### [392] [Neural Bridge Processes](https://arxiv.org/abs/2508.07220)
*Jian Xu,Yican Liu,Qibin Zhao,John Paisley,Delu Zeng*

Main category: cs.LG

TL;DR: 神经桥接过程（NBPs）通过将输入视为扩散轨迹的锚点，解决了现有模型（如GP、NP、NDP）在处理随机函数和部分观测数据时的可扩展性、表达能力和端点一致性问题。NBPs通过改进前向核，确保扩散过程准确终止于目标值，从而在多个任务上取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的GP模型在处理大型数据集时存在可扩展性问题，并且其高斯假设限制了适用性。虽然NP模型更灵活，但它们难以捕捉复杂的多模态目标分布。NDP模型通过学习到的扩散过程增强了表达能力，但其降噪网络仅依赖于条件信号，导致与无条件前向过程的耦合较弱，并且在扩散终点存在语义不匹配的问题。

Method: 提出了一种名为神经桥接过程（NBPs）的新方法，该方法通过将输入x作为扩散轨迹的动态锚点，并修改前向核使其显式依赖于x，来实现输入与扩散过程的强耦合，确保扩散过程严格终止于目标值。

Result: NBPs在合成数据、EEG信号回归和图像回归任务上取得了显著的性能提升，优于现有基线模型。

Conclusion: NBPs通过将输入x作为整个扩散轨迹的动态锚点，并显式地使前向核依赖于x，从而强制执行一个严格终止于监督目标的约束路径。这种方法提供了更强的梯度信号，并保证了端点的一致性。NBPs在合成数据、EEG信号回归和图像回归任务上取得了实质性改进，展示了DDPM风格的桥接采样在提高结构化预测任务的性能和理论一致性方面的有效性。

Abstract: Learning stochastic functions from partially observed context-target pairs is
a fundamental problem in probabilistic modeling. Traditional models like
Gaussian Processes (GPs) face scalability issues with large datasets and assume
Gaussianity, limiting their applicability. While Neural Processes (NPs) offer
more flexibility, they struggle with capturing complex, multi-modal target
distributions. Neural Diffusion Processes (NDPs) enhance expressivity through a
learned diffusion process but rely solely on conditional signals in the
denoising network, resulting in weak input coupling from an unconditional
forward process and semantic mismatch at the diffusion endpoint. In this work,
we propose Neural Bridge Processes (NBPs), a novel method for modeling
stochastic functions where inputs x act as dynamic anchors for the entire
diffusion trajectory. By reformulating the forward kernel to explicitly depend
on x, NBP enforces a constrained path that strictly terminates at the
supervised target. This approach not only provides stronger gradient signals
but also guarantees endpoint coherence. We validate NBPs on synthetic data, EEG
signal regression and image regression tasks, achieving substantial
improvements over baselines. These results underscore the effectiveness of
DDPM-style bridge sampling in enhancing both performance and theoretical
consistency for structured prediction tasks.

</details>


### [393] [EDGE: A Theoretical Framework for Misconception-Aware Adaptive Learning](https://arxiv.org/abs/2508.07224)
*Ananda Prakash Verma*

Main category: cs.LG

TL;DR: EDGE is an adaptive learning framework that uses psychometrics, cognitive diagnostics, contrastive item generation, and principled scheduling to improve learning by identifying and addressing misconceptions. It introduces the EdgeScore metric and an associated policy for near-optimal learning.


<details>
  <summary>Details</summary>
Motivation: To develop a general-purpose, misconception-aware adaptive learning framework.

Method: EDGE unifies psychometrics (IRT/Bayesian state space models), cognitive diagnostics (misconception discovery from distractor patterns and response latencies), contrastive item generation (minimal perturbations that invalidate learner shortcuts while pre-serving psychometric validity), and principled scheduling (a restless bandit approximation to spaced retrieval).

Result: The paper formalizes a composite readiness metric, EdgeScore, proves its monotonicity and Lipschitz continuity, and derives an index policy that is near-optimal under mild assumptions on forgetting and learning gains. It also establishes conditions under which counterfactual items provably reduce the posterior probability of a targeted misconception faster than standard practice.

Conclusion: EDGE is a general-purpose, misconception-aware adaptive learning framework.

Abstract: We present EDGE, a general-purpose, misconception-aware adaptive learning
framework composed of four stages: Evaluate (ability and state estimation),
Diagnose (posterior infer-ence of misconceptions), Generate (counterfactual
item synthesis), and Exercise (index-based retrieval scheduling). EDGE unifies
psychometrics (IRT/Bayesian state space models), cog-nitive diagnostics
(misconception discovery from distractor patterns and response latencies),
contrastive item generation (minimal perturbations that invalidate learner
shortcuts while pre-serving psychometric validity), and principled scheduling
(a restless bandit approximation to spaced retrieval). We formalize a composite
readiness metric, EdgeScore, prove its monotonicity and Lipschitz continuity,
and derive an index policy that is near-optimal under mild assumptions on
forgetting and learning gains. We further establish conditions under which
counterfactual items provably reduce the posterior probability of a targeted
misconception faster than standard practice. The paper focuses on theory and
implementable pseudocode; empirical study is left to future work.

</details>


### [394] [Causal Negative Sampling via Diffusion Model for Out-of-Distribution Recommendation](https://arxiv.org/abs/2508.07243)
*Chu Zhao,Eneng Yang,Yizhou Dang,Jianzhe Zhao,Guibing Guo,Xingwei Wang*

Main category: cs.LG

TL;DR: CNSDiff通过扩散模型在潜在空间合成负样本，并加入因果正则化，解决了启发式负采样引入的虚假困难负样本问题，显著提升了推荐模型在分布外场景下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的启发式负采样方法在推荐系统中可能引入虚假困难负样本（FHNS），这些样本由候选集中存在的未观测环境混淆因素（如曝光或流行度偏差）引起，进而导致模型学习到错误的关联，损害其在分布偏移下的泛化能力。

Method: CNSDiff通过在潜在空间中利用条件扩散过程来合成负样本，并引入因果正则化项来处理环境混淆因素，以生成更鲁棒的负样本。

Result: CNSDiff在四个代表性的分布偏移场景下进行了全面实验，结果显示其在所有评估指标上的平均表现比最先进的基线提高了13.96%，验证了其在OOD推荐任务中的有效性和鲁棒性。

Conclusion: CNSDiff通过在潜在空间中通过条件扩散过程合成负样本，有效解决了现有启发式负采样方法中存在的虚假困难负样本（FHNS）问题，并结合因果正则化项来缓解环境混淆因素的影响，从而提高了模型在分布外（OOD）推荐任务上的泛化能力。实验结果表明，CNSDiff在多种分布偏移场景下表现优于现有最先进方法，平均提升达13.96%。

Abstract: Heuristic negative sampling enhances recommendation performance by selecting
negative samples of varying hardness levels from predefined candidate pools to
guide the model toward learning more accurate decision boundaries. However, our
empirical and theoretical analyses reveal that unobserved environmental
confounders (e.g., exposure or popularity biases) in candidate pools may cause
heuristic sampling methods to introduce false hard negatives (FHNS). These
misleading samples can encourage the model to learn spurious correlations
induced by such confounders, ultimately compromising its generalization ability
under distribution shifts. To address this issue, we propose a novel method
named Causal Negative Sampling via Diffusion (CNSDiff). By synthesizing
negative samples in the latent space via a conditional diffusion process,
CNSDiff avoids the bias introduced by predefined candidate pools and thus
reduces the likelihood of generating FHNS. Moreover, it incorporates a causal
regularization term to explicitly mitigate the influence of environmental
confounders during the negative sampling process, leading to robust negatives
that promote out-of-distribution (OOD) generalization. Comprehensive
experiments under four representative distribution shift scenarios demonstrate
that CNSDiff achieves an average improvement of 13.96% across all evaluation
metrics compared to state-of-the-art baselines, verifying its effectiveness and
robustness in OOD recommendation tasks.

</details>


### [395] [Policy Newton methods for Distortion Riskmetrics](https://arxiv.org/abs/2508.07249)
*Soumen Pachal,Mizhaan Prajit Maniyar,Prashanth L. A*

Main category: cs.LG

TL;DR: 本文提出了一种用于风险敏感控制的单策略 RL 算法，该算法通过最大化失真风险度量 (DRM) 来寻找风险最优策略，并保证收敛到 $\\


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决强化学习 (RL) 框架下的风险敏感控制问题，通过最大化有限范围马尔可夫决策过程 (MDP) 的折扣奖励的失真风险度量 (DRM) 来寻找风险最优策略。

Method: 该论文提出了一种基于似然比方法的 DRM 策略 Hessian 定理，并基于此提出了一种 DRM Hessian 估计器。然后，在单策略 RL 设置下，利用 DRM 梯度和 Hessian 的估计，提出了一种立方正则化的策略牛顿算法来解决风险敏感控制问题。

Result: 所提出的算法被证明可以收敛到 DRM 目标的一个 $\\

Conclusion: 该算法保证收敛到 DRM 目标的一个 $\\

Abstract: We consider the problem of risk-sensitive control in a reinforcement learning
(RL) framework. In particular, we aim to find a risk-optimal policy by
maximizing the distortion riskmetric (DRM) of the discounted reward in a finite
horizon Markov decision process (MDP). DRMs are a rich class of risk measures
that include several well-known risk measures as special cases. We derive a
policy Hessian theorem for the DRM objective using the likelihood ratio method.
Using this result, we propose a natural DRM Hessian estimator from sample
trajectories of the underlying MDP. Next, we present a cubic-regularized policy
Newton algorithm for solving this problem in an on-policy RL setting using
estimates of the DRM gradient and Hessian. Our proposed algorithm is shown to
converge to an $\epsilon$-second-order stationary point ($\epsilon$-SOSP) of
the DRM objective, and this guarantee ensures the escaping of saddle points.
The sample complexity of our algorithms to find an $ \epsilon$-SOSP is
$\mathcal{O}(\epsilon^{-3.5})$. Our experiments validate the theoretical
findings. To the best of our knowledge, our is the first work to present
convergence to an $\epsilon$-SOSP of a risk-sensitive objective, while existing
works in the literature have either shown convergence to a first-order
stationary point of a risk-sensitive objective, or a SOSP of a risk-neutral
one.

</details>


### [396] [Revisiting Data Attribution for Influence Functions](https://arxiv.org/abs/2508.07297)
*Hongbo Zhu,Angelo Cangelosi*

Main category: cs.LG

TL;DR: Influence functions help identify influential training data points and understand model behavior in deep learning, with ongoing work to improve their application in large-scale scenarios.


<details>
  <summary>Details</summary>
Motivation: Understanding how individual training examples influence model predictions is crucial for machine learning interpretability, data debugging, and model accountability. This paper aims to comprehensively review the data attribution capabilities of influence functions in deep learning.

Method: Influence functions, derived from robust statistics, approximate the impact of training data points on model parameters and predictions without retraining. This paper reviews their theoretical foundations, efficient estimation algorithms (inverse-Hessian-vector products), and applications.

Result: The paper evaluates the effectiveness of influence functions for data attribution and mislabel detection, highlighting their potential in deep learning.

Conclusion: Influence functions are effective for data attribution and mislabel detection in deep learning, with ongoing research addressing challenges in large-scale applications.

Abstract: The goal of data attribution is to trace the model's predictions through the
learning algorithm and back to its training data. thereby identifying the most
influential training samples and understanding how the model's behavior leads
to particular predictions. Understanding how individual training examples
influence a model's predictions is fundamental for machine learning
interpretability, data debugging, and model accountability. Influence
functions, originating from robust statistics, offer an efficient, first-order
approximation to estimate the impact of marginally upweighting or removing a
data point on a model's learned parameters and its subsequent predictions,
without the need for expensive retraining. This paper comprehensively reviews
the data attribution capability of influence functions in deep learning. We
discuss their theoretical foundations, recent algorithmic advances for
efficient inverse-Hessian-vector product estimation, and evaluate their
effectiveness for data attribution and mislabel detection. Finally,
highlighting current challenges and promising directions for unleashing the
huge potential of influence functions in large-scale, real-world deep learning
scenarios.

</details>


### [397] [When Is Prior Knowledge Helpful? Exploring the Evaluation and Selection of Unsupervised Pretext Tasks from a Neuro-Symbolic Perspective](https://arxiv.org/abs/2508.07299)
*Lin-Han Jia,Si-Yu Han,Wen-Chao Hu,Jie-Jing Shao,Wen-Da Wei,Zhi Zhou,Lan-Zhe Guo,Yu-Feng Li*

Main category: cs.LG

TL;DR: 提出了一种统一SSL和Nesy学习的理论框架，并通过理论和实验证明了预测预置任务有效性的方法。


<details>
  <summary>Details</summary>
Motivation: 统一SSL和Nesy的理论框架，解决当前SSL中预置任务选择的启发式和评估困难的问题。

Method: 将Nesy理论扩展到包含不可靠知识（假设）的场景，并进行理论分析，提出操作化理论指标的方案，开发预测预置任务有效性的方法。

Result: 实验验证了预测性能与实际性能之间的高度相关性，证实了理论的有效性和评估方法的有效性。

Conclusion: 该研究统一了半监督学习（SSL）和神经符号（Nesy）学习的理论框架，并通过理论分析提出了评估和预测预置任务有效性的方法。

Abstract: Neuro-symbolic (Nesy) learning improves the target task performance of models
by enabling them to satisfy knowledge, while semi/self-supervised learning
(SSL) improves the target task performance by designing unsupervised pretext
tasks for unlabeled data to make models satisfy corresponding assumptions. We
extend the Nesy theory based on reliable knowledge to the scenario of
unreliable knowledge (i.e., assumptions), thereby unifying the theoretical
frameworks of SSL and Nesy. Through rigorous theoretical analysis, we
demonstrate that, in theory, the impact of pretext tasks on target performance
hinges on three factors: knowledge learnability with respect to the model,
knowledge reliability with respect to the data, and knowledge completeness with
respect to the target. We further propose schemes to operationalize these
theoretical metrics, and thereby develop a method that can predict the
effectiveness of pretext tasks in advance. This will change the current status
quo in practical applications, where the selections of unsupervised tasks are
heuristic-based rather than theory-based, and it is difficult to evaluate the
rationality of unsupervised pretext task selection before testing the model on
the target task. In experiments, we verify a high correlation between the
predicted performance-estimated using minimal data-and the actual performance
achieved after large-scale semi-supervised or self-supervised learning, thus
confirming the validity of the theory and the effectiveness of the evaluation
method.

</details>


### [398] [Efficient Edge LLMs Deployment via HessianAware Quantization and CPU GPU Collaborative](https://arxiv.org/abs/2508.07329)
*Tuo Zhang,Ning Li,Xin Yuan,Wenchao Xu,Quan Chen,Song Guo,Haijun Zhang*

Main category: cs.LG

TL;DR: 该研究提出了一种新的MoE边缘部署方案，通过HAQ量化和CPU-GPU协同推理，解决了LLM在边缘设备部署中的量化精度和内存效率问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: LLM在NLP和多模态任务中取得突破，但在资源受限的边缘设备上高效部署面临挑战。MoE架构虽然增强了模型容量，但在实际部署中存在激活值离群点导致量化精度下降和内存受限下专家模块协同推理效率低的问题。

Method: 提出了一种基于Hessian感知量化（HAQ）和CPU-GPU协同推理的MoE边缘部署方案。通过引入平滑Hessian矩阵量化，实现了激活值和权重的联合8位量化，有效解决了量化精度下降问题。设计了专家级协同卸载和推理机制，结合专家激活路径统计，实现了专家模块在CPU和GPU之间的高效部署和调度，降低了显存占用和推理延迟。

Result: 低比特量化模型的推理精度接近全精度模型，GPU显存占用减少约60%，推理延迟显著提升。

Conclusion: 通过实验验证，该方法在OPT系列和Mixtral 8*7B等主流大模型上，使用Wikitext2和C4等数据集，低比特量化模型的推理精度接近全精度模型，同时GPU显存占用减少约60%，推理延迟显著提升。

Abstract: With the breakthrough progress of large language models (LLMs) in natural
language processing and multimodal tasks, efficiently deploying them on
resource-constrained edge devices has become a critical challenge. The Mixture
of Experts (MoE) architecture enhances model capacity through sparse
activation, but faces two major difficulties in practical deployment: (1) The
presence of numerous outliers in activation distributions leads to severe
degradation in quantization accuracy for both activations and weights,
significantly impairing inference performance; (2) Under limited memory,
efficient offloading and collaborative inference of expert modules struggle to
balance latency and throughput. To address these issues, this paper proposes an
efficient MoE edge deployment scheme based on Hessian-Aware Quantization (HAQ)
and CPU-GPU collaborative inference. First, by introducing smoothed Hessian
matrix quantization, we achieve joint 8-bit quantization of activations and
weights, which significantly alleviates the accuracy loss caused by outliers
while ensuring efficient implementation on mainstream hardware. Second, we
design an expert-level collaborative offloading and inference mechanism, which,
combined with expert activation path statistics, enables efficient deployment
and scheduling of expert modules between CPU and GPU, greatly reducing memory
footprint and inference latency. Extensive experiments validate the
effectiveness of our method on mainstream large models such as the OPT series
and Mixtral 8*7B: on datasets like Wikitext2 and C4, the inference accuracy of
the low-bit quantized model approaches that of the full-precision model, while
GPU memory usage is reduced by about 60%, and inference latency is
significantly improved.

</details>


### [399] [Finite-Time Convergence Analysis of ODE-based Generative Models for Stochastic Interpolants](https://arxiv.org/abs/2508.07333)
*Yuhao Liu,Rui Hu,Yu Chen,Longbo Huang*

Main category: cs.LG

TL;DR: 本研究分析了随机插值数值实现的有限时间收敛性，为生成模型提供了理论支持。


<details>
  <summary>Details</summary>
Motivation: 尽管随机插值在生成模型中具有潜力，但其数值实现的有限时间收敛性保证在实践中仍未得到充分研究。本工作旨在解决这一问题，为随机插值在生成模型中的可靠应用提供理论支持。

Method: 本文针对随机插值生成的常微分方程（ODEs），研究了两种常用数值积分方法（一阶欧拉法和二阶龙格-库塔法）的有限时间收敛性，并给出了总变差距离的误差界限。此外，还分析了特定随机插值构造的迭代复杂度，并提出了优化计算效率的时间表。

Result: 研究成功建立了两种数值积分方法（一阶欧拉法和二阶龙格-库塔法）在随机插值常微分方程（ODEs）上的有限时间误差界限（总变差距离）。同时，分析了迭代复杂度并给出了优化计算效率的时间表。数值实验结果验证了理论分析的准确性。

Conclusion: 该研究为随机插值在生成模型中的应用提供了重要的理论基础，并指出了数值方法在实际应用中的收敛性和效率问题。

Abstract: Stochastic interpolants offer a robust framework for continuously
transforming samples between arbitrary data distributions, holding significant
promise for generative modeling. Despite their potential, rigorous finite-time
convergence guarantees for practical numerical schemes remain largely
unexplored. In this work, we address the finite-time convergence analysis of
numerical implementations for ordinary differential equations (ODEs) derived
from stochastic interpolants. Specifically, we establish novel finite-time
error bounds in total variation distance for two widely used numerical
integrators: the first-order forward Euler method and the second-order Heun's
method. Furthermore, our analysis on the iteration complexity of specific
stochastic interpolant constructions provides optimized schedules to enhance
computational efficiency. Our theoretical findings are corroborated by
numerical experiments, which validate the derived error bounds and complexity
analyses.

</details>


### [400] [ProteoKnight: Convolution-based phage virion protein classification and uncertainty analysis](https://arxiv.org/abs/2508.07345)
*Samiha Afaf Neha,Abir Ahammed Bhuiyan,Md. Ishrak Khan*

Main category: cs.LG

TL;DR: 本研究提出了一种名为ProteoKnight的蛋白质序列图像编码新方法，用于预测噬菌体病毒颗粒蛋白（PVP）。该方法在二元分类任务中达到了90.8%的准确率，并能评估预测的不确定性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有技术在计算注释噬菌体蛋白序列时存在的空间限制问题，并提高基因组研究中噬菌体病毒颗粒蛋白（PVP）预测的准确性，本研究引入了新的基于图像的编码方法ProteoKnight。

Method: ProteoKnight将经典的DNA-Walk算法应用于蛋白质序列，通过像素颜色和调整步长来捕捉复杂的蛋白质特征。使用多种预训练的卷积神经网络（CNN）对编码后的序列进行分类，并通过方差和熵度量来评估不同类别和长度蛋白质的预测不确定性。

Result: ProteoKnight在二元分类任务中达到了90.8%的准确率，与现有最佳方法相当，但在多类分类任务中的表现仍有待提高。不确定性分析显示，预测置信度因蛋白质类别和序列长度而异。

Conclusion: 该研究通过引入新的图像编码方法，超越了频率混沌游戏表示（FCGR），解决了空间信息丢失的限制。该分类技术能够准确、稳健地预测噬菌体病毒颗粒蛋白（PVP），同时还能识别置信度较低的预测。

Abstract: \textbf{Introduction:} Accurate prediction of Phage Virion Proteins (PVP) is
essential for genomic studies due to their crucial role as structural elements
in bacteriophages. Computational tools, particularly machine learning, have
emerged for annotating phage protein sequences from high-throughput sequencing.
However, effective annotation requires specialized sequence encodings. Our
paper introduces ProteoKnight, a new image-based encoding method that addresses
spatial constraints in existing techniques, yielding competitive performance in
PVP classification using pre-trained convolutional neural networks.
Additionally, our study evaluates prediction uncertainty in binary PVP
classification through Monte Carlo Dropout (MCD). \textbf{Methods:}
ProteoKnight adapts the classical DNA-Walk algorithm for protein sequences,
incorporating pixel colors and adjusting walk distances to capture intricate
protein features. Encoded sequences were classified using multiple pre-trained
CNNs. Variance and entropy measures assessed prediction uncertainty across
proteins of various classes and lengths. \textbf{Results:} Our experiments
achieved 90.8% accuracy in binary classification, comparable to
state-of-the-art methods. Multi-class classification accuracy remains
suboptimal. Our uncertainty analysis unveils variability in prediction
confidence influenced by protein class and sequence length.
\textbf{Conclusions:} Our study surpasses frequency chaos game representation
(FCGR) by introducing novel image encoding that mitigates spatial information
loss limitations. Our classification technique yields accurate and robust PVP
predictions while identifying low-confidence predictions.

</details>


### [401] [Intrinsic training dynamics of deep neural networks](https://arxiv.org/abs/2508.07370)
*Sibylle Marcotte,Gabriel Peyré,Rémi Gribonval*

Main category: cs.LG

TL;DR: 深度学习梯度流在高维参数空间中可以被低维结构捕获，特别是通过路径提升和放松的均衡初始化，这在ReLU网络和线性网络中得到了证明。


<details>
  <summary>Details</summary>
Motivation: 深度学习理论中的一个基本挑战是理解高维参数空间中的梯度下降训练过程是否可以被更简单的低维结构所描述，即所谓的隐式偏倚。这项工作旨在通过研究高维变量的梯度流如何约束低维变量的内在梯度流来解决这一挑战。

Method: 研究基于梯度流和因子分解理论，提出了一个包含线性映射核的判据，用于判断高维梯度流是否能被表示为低维内在梯度流。该理论被应用于ReLU网络和线性网络，并通过分析路径提升和放松的均衡初始化来证明降维的可能性和必要性。

Result: 研究表明，对于ReLU网络，路径提升可以实现任意深度的降维内在动力学。对于线性网络，放松的均衡初始化是确保内在动力学性质的唯一初始化类型。此外，研究还显式表达了与无限深度线性网络相关的线性神经网络ODE的内在动力学。

Conclusion: 该研究提出了一个关于梯度流在高维参数空间中是否能被低维结构捕获的理论，并将其应用于ReLU网络和线性网络。研究表明，特定的初始化（如路径提升和放松的均衡初始化）可以实现这种降维，并为线性神经网络的内在动力学提供了一个显式表达式。

Abstract: A fundamental challenge in the theory of deep learning is to understand
whether gradient-based training in high-dimensional parameter spaces can be
captured by simpler, lower-dimensional structures, leading to so-called
implicit bias. As a stepping stone, we study when a gradient flow on a
high-dimensional variable $\theta$ implies an intrinsic gradient flow on a
lower-dimensional variable $z = \phi(\theta)$, for an architecture-related
function $\phi$. We express a so-called intrinsic dynamic property and show how
it is related to the study of conservation laws associated with the
factorization $\phi$. This leads to a simple criterion based on the inclusion
of kernels of linear maps which yields a necessary condition for this property
to hold. We then apply our theory to general ReLU networks of arbitrary depth
and show that, for any initialization, it is possible to rewrite the flow as an
intrinsic dynamic in a lower dimension that depends only on $z$ and the
initialization, when $\phi$ is the so-called path-lifting. In the case of
linear networks with $\phi$ the product of weight matrices, so-called balanced
initializations are also known to enable such a dimensionality reduction; we
generalize this result to a broader class of {\em relaxed balanced}
initializations, showing that, in certain configurations, these are the
\emph{only} initializations that ensure the intrinsic dynamic property.
Finally, for the linear neural ODE associated with the limit of infinitely deep
linear networks, with relaxed balanced initialization, we explicitly express
the corresponding intrinsic dynamics.

</details>


### [402] [Tight Bounds for Schrödinger Potential Estimation in Unpaired Image-to-Image Translation Problems](https://arxiv.org/abs/2508.07392)
*Nikita Puchkin,Denis Suchkov,Alexey Naumov,Denis Belomestny*

Main category: cs.LG

TL;DR: This paper uses stochastic optimal control and an Ornstein-Uhlenbeck process for generative modeling and image-to-image translation, achieving near-optimal convergence rates with theoretical guarantees and numerical validation.


<details>
  <summary>Details</summary>
Motivation: The paper addresses generative modeling and unpaired image-to-image translation by transforming an initial density to a target density, assuming access only to i.i.d. samples from both distributions.

Method: We employed a stochastic optimal control approach using an Ornstein-Uhlenbeck process as a reference and estimated the corresponding Schr"odinger potential. A risk function based on the Kullback-Leibler divergence between couplings was introduced to derive generalization bounds.

Result: The proposed approach shows performance illustrated through numerical experiments and achieves near-optimal convergence rates, up to logarithmic factors, in favorable scenarios due to the mixing properties of the Ornstein-Uhlenbeck process.

Conclusion: We derived tight bounds on the generalization ability of an empirical risk minimizer in a class of Schr"odinger potentials, achieving near-optimal convergence rates thanks to the properties of the Ornstein-Uhlenbeck process.

Abstract: Modern methods of generative modelling and unpaired image-to-image
translation based on Schr\"odinger bridges and stochastic optimal control
theory aim to transform an initial density to a target one in an optimal way.
In the present paper, we assume that we only have access to i.i.d. samples from
initial and final distributions. This makes our setup suitable for both
generative modelling and unpaired image-to-image translation. Relying on the
stochastic optimal control approach, we choose an Ornstein-Uhlenbeck process as
the reference one and estimate the corresponding Schr\"odinger potential.
Introducing a risk function as the Kullback-Leibler divergence between
couplings, we derive tight bounds on generalization ability of an empirical
risk minimizer in a class of Schr\"odinger potentials including Gaussian
mixtures. Thanks to the mixing properties of the Ornstein-Uhlenbeck process, we
almost achieve fast rates of convergence up to some logarithmic factors in
favourable scenarios. We also illustrate performance of the suggested approach
with numerical experiments.

</details>


### [403] [Parity Requires Unified Input Dependence and Negative Eigenvalues in SSMs](https://arxiv.org/abs/2508.07395)
*Behnoush Khavari,Mehran Shakerinava,Jayesh Khullar,Jerry Huang,François Rivest,Siamak Ravanbakhsh,Sarath Chandar*

Main category: cs.LG

TL;DR: SSM需要输入依赖性和负特征值才能有效处理状态跟踪任务，单纯堆叠或增加深度（即使结合了S4D和Mamba层）是不够的。


<details>
  <summary>Details</summary>
Motivation: 探究将输入无关和非负SSM组合能否解决状态跟踪任务，如奇偶校验。

Method: 通过分析具有对角线转移矩阵的SSM模型，并进行实验验证，对比了S4D和Mamba层。

Result: 实验表明，即使组合了S4D和Mamba层，SSM仍然无法解决奇偶校验任务，除非转移矩阵具有输入依赖性和负特征值。

Conclusion: SSM无法仅仅通过堆叠或增加深度来解决状态跟踪任务，需要同时具备输入依赖性和负特征值。

Abstract: Recent work has shown that LRNN models such as S4D, Mamba, and DeltaNet lack
state-tracking capability due to either time-invariant transition matrices or
restricted eigenvalue ranges. To address this, input-dependent transition
matrices, particularly those that are complex or non-triangular, have been
proposed to enhance SSM performance on such tasks. While existing theorems
demonstrate that both input-independent and non-negative SSMs are incapable of
solving simple state-tracking tasks, such as parity, regardless of depth, they
do not explore whether combining these two types in a multilayer SSM could
help. We investigate this question for efficient SSMs with diagonal transition
matrices and show that such combinations still fail to solve parity. This
implies that a recurrence layer must both be input-dependent and include
negative eigenvalues. Our experiments support this conclusion by analyzing an
SSM model that combines S4D and Mamba layers.

</details>


### [404] [Efficient Reward Identification In Max Entropy Reinforcement Learning with Sparsity and Rank Priors](https://arxiv.org/abs/2508.07400)
*Mohamad Louai Shehab,Alperen Tercan,Necmiye Ozay*

Main category: cs.LG

TL;DR: 从最优策略或演示中恢复时间变化的奖励函数。利用奖励函数稀疏或低秩的先验信息，将问题转化为稀疏化或秩最小化问题，并提出基于优化的算法来解决。


<details>
  <summary>Details</summary>
Motivation: 在强化学习中，奖励函数对于学习最优策略至关重要。然而，在许多实际应用中，奖励函数是未知的，并且可能是随时间变化的。从最优策略或演示中恢复这些时间变化的奖励函数是一个具有挑战性的问题，因为该问题本身是病态的，需要额外的假设。因此，研究奖励函数的恢复具有重要的理论和实践意义。

Method: 我们考虑了从最优策略或最大熵强化学习问题的演示中恢复时间变化的奖励函数。我们提出了两种方法：1）利用奖励函数主要恒定且变化不频繁的先验信息，将问题转化为稀疏化问题，并提出一个精确的多项式时间算法。2）利用奖励函数可以表示为少量特征函数线性组合的先验信息，将问题转化为秩最小化问题，并应用秩的凸松弛。

Result: 我们提出的基于优化的算法在识别时间变化的奖励函数方面表现出了准确性和可推广性。通过实验证明，我们的算法能够有效地从最优策略或演示中恢复出真实的奖励函数，即使在存在噪声或不完整数据的情况下也是如此。

Conclusion: 本文提出了一种基于优化的方法来识别时间变化奖励函数。我们证明了具有稀疏先验的奖励识别问题可以转化为稀疏化问题，并提供了一个精确的多项式时间算法。此外，我们还表明，具有低秩先验的奖励识别问题可以转化为秩最小化问题，可以通过凸松弛来解决。这两种方法都导致了有效的基于优化的奖励识别算法。

Abstract: In this paper, we consider the problem of recovering time-varying reward
functions from either optimal policies or demonstrations coming from a max
entropy reinforcement learning problem. This problem is highly ill-posed
without additional assumptions on the underlying rewards. However, in many
applications, the rewards are indeed parsimonious, and some prior information
is available. We consider two such priors on the rewards: 1) rewards are mostly
constant and they change infrequently, 2) rewards can be represented by a
linear combination of a small number of feature functions. We first show that
the reward identification problem with the former prior can be recast as a
sparsification problem subject to linear constraints. Moreover, we give a
polynomial-time algorithm that solves this sparsification problem exactly.
Then, we show that identifying rewards representable with the minimum number of
features can be recast as a rank minimization problem subject to linear
constraints, for which convex relaxations of rank can be invoked. In both
cases, these observations lead to efficient optimization-based reward
identification algorithms. Several examples are given to demonstrate the
accuracy of the recovered rewards as well as their generalizability.

</details>


### [405] [Lightning Prediction under Uncertainty: DeepLight with Hazy Loss](https://arxiv.org/abs/2508.07428)
*Md Sultanul Arifin,Abu Nowshed Sakib,Yeasir Rayhan,Tanzima Hashem*

Main category: cs.LG

TL;DR: DeepLight是一种新的深度学习模型，通过结合多种气象数据和创新的损失函数，提高了闪电预测的准确性，比现有方法效果好18%-30%。


<details>
  <summary>Details</summary>
Motivation: 闪电作为一种常见的恶劣天气现象，会对人类生命和财产造成重大风险，气候变化进一步加剧了这些风险。因此，早期准确地预测闪电对于采取预防措施、保护人民生命财产安全至关重要。

Method: DeepLight利用多源气象数据（包括雷达反射率、云属性和历史闪电发生情况）通过双编码器架构来预测闪电。它采用多分支卷积技术来动态捕捉不同范围的空间相关性，并使用新颖的Hazy Loss函数来解决时空不确定性问题。

Result: 实验结果表明，DeepLight的ETS评分比现有最先进的方法提高了18%-30%，证明了其在闪电预测方面的鲁棒性。

Conclusion: DeepLight通过利用多源气象数据、双编码器架构、多分支卷积技术和Hazy Loss函数，在准确预测闪电方面取得了显著进展，其ETS评分比现有方法提高了18%-30%，为减少闪电造成的危害提供了一个有效的解决方案。

Abstract: Lightning, a common feature of severe meteorological conditions, poses
significant risks, from direct human injuries to substantial economic losses.
These risks are further exacerbated by climate change. Early and accurate
prediction of lightning would enable preventive measures to safeguard people,
protect property, and minimize economic losses. In this paper, we present
DeepLight, a novel deep learning architecture for predicting lightning
occurrences. Existing prediction models face several critical limitations: they
often struggle to capture the dynamic spatial context and inherent uncertainty
of lightning events, underutilize key observational data, such as radar
reflectivity and cloud properties, and rely heavily on Numerical Weather
Prediction (NWP) systems, which are both computationally expensive and highly
sensitive to parameter settings. To overcome these challenges, DeepLight
leverages multi-source meteorological data, including radar reflectivity, cloud
properties, and historical lightning occurrences through a dual-encoder
architecture. By employing multi-branch convolution techniques, it dynamically
captures spatial correlations across varying extents. Furthermore, its novel
Hazy Loss function explicitly addresses the spatio-temporal uncertainty of
lightning by penalizing deviations based on proximity to true events, enabling
the model to better learn patterns amidst randomness. Extensive experiments
show that DeepLight improves the Equitable Threat Score (ETS) by 18%-30% over
state-of-the-art methods, establishing it as a robust solution for lightning
prediction.

</details>


### [406] [Unsupervised operator learning approach for dissipative equations via Onsager principle](https://arxiv.org/abs/2508.07440)
*Zhipeng Chang,Zhenye Wen,Xiaofei Zhao*

Main category: cs.LG

TL;DR: DOOL是一种基于Onsager变分原理的无监督算子学习方法，用于解决耗散方程。它通过最小化Rayleighian泛函进行训练，无需标签数据，并通过时空解耦策略提高效率和实现时间外推。实验证明DOOL比监督方法更有效，并可扩展到更广泛的模型。


<details>
  <summary>Details</summary>
Motivation: 现有的算子学习方法需要高保真仿真数据进行监督训练，计算成本高昂。本研究提出了一种名为DOOL的新型无监督框架，用于解决耗散方程，以降低计算成本并提高效率。

Method: DOOL（深度Onsager算子学习）是一种无监督框架，利用Onsager变分原理（OVP）通过最小化Rayleighian泛函来训练深度算子网络，无需标签数据。它采用时空解耦策略，其中干网络仅处理空间坐标以提高训练效率，并结合外部时间步马来处理时间外推。在有耗散的情况下，还对其二阶波动模型进行了扩展。

Result: DOOL方法在解决耗散方程方面显示出有效性，并在与监督学习的DeepONet和MIONet的比较中展示了其优越性。该方法还成功扩展到处理二阶耗散波动模型。

Conclusion: DOOL方法在处理耗散方程方面表现出色，并且在数值实验中被证明比监督学习的DeepONet和MIONet方法更有效。此外，该方法还成功扩展到处理不直接遵循OVP的二阶耗散波动模型。

Abstract: Existing operator learning methods rely on supervised training with
high-fidelity simulation data, introducing significant computational cost. In
this work, we propose the deep Onsager operator learning (DOOL) method, a novel
unsupervised framework for solving dissipative equations. Rooted in the Onsager
variational principle (OVP), DOOL trains a deep operator network by directly
minimizing the OVP-defined Rayleighian functional, requiring no labeled data,
and then proceeds in time explicitly through conservation/change laws for the
solution. Another key innovation here lies in the spatiotemporal decoupling
strategy: the operator's trunk network processes spatial coordinates
exclusively, thereby enhancing training efficiency, while integrated external
time stepping enables temporal extrapolation. Numerical experiments on typical
dissipative equations validate the effectiveness of the DOOL method, and
systematic comparisons with supervised DeepONet and MIONet demonstrate its
enhanced performance. Extensions are made to cover the second-order wave models
with dissipation that do not directly follow OVP.

</details>


### [407] [Stackelberg Coupling of Online Representation Learning and Reinforcement Learning](https://arxiv.org/abs/2508.07452)
*Fernando Martinez,Tao Li,Yingdong Lu,Juntao Chen*

Main category: cs.LG

TL;DR: SCORER 框架通过将感知和控制网络之间的交互建模为 Stackelberg 博弈，提升了深度强化学习的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决从稀疏奖励信号中学习有效特征的挑战，该研究旨在提供一种替代解耦和端到端学习的方法，通过结构化感知和控制网络之间的交互来提升深度强化学习的性能。

Method: 提出了一种名为 SCORER（Stackelberg Coupled Representation and Reinforcement Learning）的框架，将感知（leader）和控制（follower）网络之间的交互建模为 Stackelberg 博弈，并使用一种实用的双时间尺度算法来近似博弈的均衡。将此框架应用于标准 DQN 变体。

Result: 在基准任务上，SCORER 框架在样本效率和最终性能上均有所提升，证明了通过原则性的感知-控制动态算法设计可以实现性能的提升。

Conclusion: 该研究提出了一种名为 SCORER（Stackelberg Coupled Representation and Reinforcement Learning）的框架，通过将感知和控制网络之间的交互建模为 Stackelberg 博弈，可以显著提升深度强化学习的性能，而无需复杂的辅助目标或架构。

Abstract: Integrated, end-to-end learning of representations and policies remains a
cornerstone of deep reinforcement learning (RL). However, to address the
challenge of learning effective features from a sparse reward signal, recent
trends have shifted towards adding complex auxiliary objectives or fully
decoupling the two processes, often at the cost of increased design complexity.
This work proposes an alternative to both decoupling and naive end-to-end
learning, arguing that performance can be significantly improved by structuring
the interaction between distinct perception and control networks with a
principled, game-theoretic dynamic. We formalize this dynamic by introducing
the Stackelberg Coupled Representation and Reinforcement Learning (SCORER)
framework, which models the interaction between perception and control as a
Stackelberg game. The perception network (leader) strategically learns features
to benefit the control network (follower), whose own objective is to minimize
its Bellman error. We approximate the game's equilibrium with a practical
two-timescale algorithm. Applied to standard DQN variants on benchmark tasks,
SCORER improves sample efficiency and final performance. Our results show that
performance gains can be achieved through principled algorithmic design of the
perception-control dynamic, without requiring complex auxiliary objectives or
architectures.

</details>


### [408] [Towards Unveiling Predictive Uncertainty Vulnerabilities in the Context of the Right to Be Forgotten](https://arxiv.org/abs/2508.07458)
*Wei Qian,Chenxu Zhao,Yangyi Li,Wenqian Ye,Mengdi Huai*

Main category: cs.LG

TL;DR: 该研究首次提出了一种针对深度学习模型预测不确定性的恶意机器学习攻击，该攻击能够有效地操纵不确定性结果，且现有防御措施无效。


<details>
  <summary>Details</summary>
Motivation: 填补现有研究中关于机器学习不确定性量化漏洞的空白，并研究专门针对预测不确定性的恶意机器学习攻击。

Method: 提出了一种新的中性攻击，专门针对预测不确定性，并设计了新的攻击优化框架，包括黑盒场景的实验。

Result: 所提出的攻击在操纵预测不确定性方面比传统的、侧重于错误分类标签的攻击更有效，并且现有的防御措施无法防御所提出的攻击。

Conclusion: 现有针对预测不确定性的机器学习攻击和现有防御措施都无法防御所提出之中性攻击。

Abstract: Currently, various uncertainty quantification methods have been proposed to
provide certainty and probability estimates for deep learning models' label
predictions. Meanwhile, with the growing demand for the right to be forgotten,
machine unlearning has been extensively studied as a means to remove the impact
of requested sensitive data from a pre-trained model without retraining the
model from scratch. However, the vulnerabilities of such generated predictive
uncertainties with regard to dedicated malicious unlearning attacks remain
unexplored. To bridge this gap, for the first time, we propose a new class of
malicious unlearning attacks against predictive uncertainties, where the
adversary aims to cause the desired manipulations of specific predictive
uncertainty results. We also design novel optimization frameworks for our
attacks and conduct extensive experiments, including black-box scenarios.
Notably, our extensive experiments show that our attacks are more effective in
manipulating predictive uncertainties than traditional attacks that focus on
label misclassifications, and existing defenses against conventional attacks
are ineffective against our attacks.

</details>


### [409] [MOTGNN: Interpretable Graph Neural Networks for Multi-Omics Disease Classification](https://arxiv.org/abs/2508.07465)
*Tiantian Yang,Zhiqian Chen*

Main category: cs.LG

TL;DR: MOTGNN是一个整合多组学数据的新框架，通过XGBoost和GNNs提高了疾病分类的准确性和可解释性，在不平衡数据上表现优异。


<details>
  <summary>Details</summary>
Motivation: 整合多组学数据（如DNA甲基化、mRNA表达和miRNA表达）可以提供对疾病生物学机制的全面理解。然而，组学层之间的高维性和复杂的相互作用给预测建模带来了重大挑战。

Method: 提出了一个名为MOTGNN的新型可解释框架，用于二元疾病分类。该框架首先使用XGBoost进行特定组学类型的监督图构建，然后利用特定模态的图神经网络（GNNs）进行分层表示学习，最后通过深度前馈网络进行跨组学集成。

Result: 在三个真实世界疾病数据集上，MOTGNN的准确率、ROC-AUC和F1分数比最先进的基线提高了5-10%，并且在严重的类别不平衡情况下（例如，在不平衡数据上F1分数从33.4%提高到87.2%）保持了鲁棒性。该模型通过稀疏图（每个节点2.1-2.8条边）保持了计算效率，并提供了内置的可解释性，揭示了排名靠前的生物标志物以及每种组学模态的相对贡献。

Conclusion: MOTGNN在多组学疾病建模中展示了提高预测准确性和可解释性的潜力。

Abstract: Integrating multi-omics data, such as DNA methylation, mRNA expression, and
microRNA (miRNA) expression, offers a comprehensive view of the biological
mechanisms underlying disease. However, the high dimensionality and complex
interactions among omics layers present major challenges for predictive
modeling. We propose Multi-Omics integration with Tree-generated Graph Neural
Network (MOTGNN), a novel and interpretable framework for binary disease
classification. MOTGNN employs eXtreme Gradient Boosting (XGBoost) to perform
omics-specific supervised graph construction, followed by modality-specific
Graph Neural Networks (GNNs) for hierarchical representation learning, and a
deep feedforward network for cross-omics integration. On three real-world
disease datasets, MOTGNN outperforms state-of-the-art baselines by 5-10% in
accuracy, ROC-AUC, and F1-score, and remains robust to severe class imbalance
(e.g., 87.2% vs. 33.4% F1 on imbalanced data). The model maintains
computational efficiency through sparse graphs (2.1-2.8 edges per node) and
provides built-in interpretability, revealing both top-ranked biomarkers and
the relative contributions of each omics modality. These results highlight
MOTGNN's potential to improve both predictive accuracy and interpretability in
multi-omics disease modeling.

</details>


### [410] [Online Convex Optimization with Heavy Tails: Old Algorithms, New Regrets, and Applications](https://arxiv.org/abs/2508.07473)
*Zijian Liu*

Main category: cs.LG

TL;DR: 在有重尾噪声的在线凸优化问题中，经典算法无需修改即可达到最优遗憾界，并且在非光滑非凸优化等问题上也有应用。


<details>
  <summary>Details</summary>
Motivation: 由于在重尾噪声（即随机梯度只承认有限的p阶中心矩，其中p属于(1,2])的OCO设定下，已知的算法结果有限，因此激励本研究去探索和分析现有算法在这一更具挑战性环境下的表现。

Method: 本研究通过分析在线梯度下降等经典OCO算法在重尾噪声环境下的表现，在标准有界域假设下，为这些算法建立了新的遗憾界限，且这些界限在所有参数上都是最优的。

Result: 研究建立了最优的遗憾界限，表明即使在不知道p的情况下，也可以在没有额外操作（如梯度裁剪）的情况下有效解决OCO问题。同时，该研究还首次证明了在重尾噪声下、无需梯度裁剪的非光滑非凸优化的收敛性，并将其思想扩展到更广泛的设置，如光滑OCO和乐观算法。

Conclusion: 该研究为在线凸优化（OCO）在有重尾噪声的设定下提供了新的理论保证，表明经典算法在无需修改的情况下也能有效处理此类噪声，并且提供的遗憾界是最优的。此外，该研究将这些发现扩展到了非光滑非凸优化和乐观算法等更广泛的场景。

Abstract: In Online Convex Optimization (OCO), when the stochastic gradient has a
finite variance, many algorithms provably work and guarantee a sublinear
regret. However, limited results are known if the gradient estimate has a heavy
tail, i.e., the stochastic gradient only admits a finite $\mathsf{p}$-th
central moment for some $\mathsf{p}\in\left(1,2\right]$. Motivated by it, this
work examines different old algorithms for OCO (e.g., Online Gradient Descent)
in the more challenging heavy-tailed setting. Under the standard bounded domain
assumption, we establish new regrets for these classical methods without any
algorithmic modification. Remarkably, these regret bounds are fully optimal in
all parameters (can be achieved even without knowing $\mathsf{p}$), suggesting
that OCO with heavy tails can be solved effectively without any extra operation
(e.g., gradient clipping). Our new results have several applications. A
particularly interesting one is the first provable convergence result for
nonsmooth nonconvex optimization under heavy-tailed noise without gradient
clipping. Furthermore, we explore broader settings (e.g., smooth OCO) and
extend our ideas to optimistic algorithms to handle different cases
simultaneously.

</details>


### [411] [N-BEATS-MOE: N-BEATS with a Mixture-of-Experts Layer for Heterogeneous Time Series Forecasting](https://arxiv.org/abs/2508.07490)
*Ricardo Matos,Luis Roque,Vitor Cerqueira*

Main category: cs.LG

TL;DR: N-BEATS-MOE通过引入混合专家和动态块加权，提高了时间序列预测的准确性和可解释性，尤其在异构时间序列上表现更佳。


<details>
  <summary>Details</summary>
Motivation: 为了改进深度学习在时间序列预测任务中的表现，特别是N-BEATS模型，并探索其可解释性。

Method: N-BEATS-MOE是一种基于混合专家（MoE）层的N-BEATS扩展，采用动态块加权策略，通过门控网络实现对每个时间序列的自适应。

Result: N-BEATS-MOE在12个基准数据集上的评估显示，在包含异构时间序列的数据集上取得了优于其他方法的持续改进，门控机制也提供了额外可解释性。

Conclusion: N-BEATS-MOE通过动态块加权策略和门控网络，能够更好地适应每个时间序列的特性，并在包含异构时间序列的数据集上取得持续的改进。

Abstract: Deep learning approaches are increasingly relevant for time series
forecasting tasks. Methods such as N-BEATS, which is built on stacks of
multilayer perceptrons (MLPs) blocks, have achieved state-of-the-art results on
benchmark datasets and competitions. N-BEATS is also more interpretable
relative to other deep learning approaches, as it decomposes forecasts into
different time series components, such as trend and seasonality. In this work,
we present N-BEATS-MOE, an extension of N-BEATS based on a Mixture-of-Experts
(MoE) layer. N-BEATS-MOE employs a dynamic block weighting strategy based on a
gating network which allows the model to better adapt to the characteristics of
each time series. We also hypothesize that the gating mechanism provides
additional interpretability by identifying which expert is most relevant for
each series. We evaluate our method across 12 benchmark datasets against
several approaches, achieving consistent improvements on several datasets,
especially those composed of heterogeneous time series.

</details>


### [412] [FairDRL-ST: Disentangled Representation Learning for Fair Spatio-Temporal Mobility Prediction](https://arxiv.org/abs/2508.07518)
*Sichen Zhao,Wei Shao,Jeffrey Chan,Ziqi Xu,Flora Salim*

Main category: cs.LG

TL;DR: FairDRL-ST框架通过无监督解耦表示学习解决了城市计算中时空预测的公平性问题，在缩小公平性差距的同时保持了性能。


<details>
  <summary>Details</summary>
Motivation: 随着深度时空神经网络在城市计算中的广泛应用，其部署可能直接影响到公共交通、紧急服务和交通管理系统等关键城市基础设施用户。由于存在偏见预测可能会不成比例地使某些人口或地理群体处于不利地位，从而加剧现有的社会经济不平等并破坏人工智能在公共服务中的伦理部署，因此公平性已成为研究重点。

Method: 提出了一种基于解耦表示学习的新型框架FairDRL-ST，利用对抗性学习和解耦表示学习来分离包含敏感信息属性，以解决时空预测中的公平性问题。

Result: 与现有的通过监督学习强制执行公平性的方法不同，该框架在无监督的情况下实现了公平性，同时将性能损失降至最低。在真实世界的城市移动性数据集上的应用表明，该框架能够缩小公平性差距，并与最先进的公平性感知方法相比，具有可预测的性能。

Conclusion: 通过利用对抗性学习和解耦表示学习，该框架以无监督方式在最小化性能损失的情况下实现公平性，解决了时空预测中的公平性问题，特别关注移动性需求预测，并在真实世界的城市移动性数据集上进行了验证，证明了其在缩小公平性差距方面的能力，并与最先进的公平性感知方法相比具有可预测的性能。

Abstract: As deep spatio-temporal neural networks are increasingly utilised in urban
computing contexts, the deployment of such methods can have a direct impact on
users of critical urban infrastructure, such as public transport, emergency
services, and traffic management systems. While many spatio-temporal methods
focus on improving accuracy, fairness has recently gained attention due to
growing evidence that biased predictions in spatio-temporal applications can
disproportionately disadvantage certain demographic or geographic groups,
thereby reinforcing existing socioeconomic inequalities and undermining the
ethical deployment of AI in public services. In this paper, we propose a novel
framework, FairDRL-ST, based on disentangled representation learning, to
address fairness concerns in spatio-temporal prediction, with a particular
focus on mobility demand forecasting. By leveraging adversarial learning and
disentangled representation learning, our framework learns to separate
attributes that contain sensitive information. Unlike existing methods that
enforce fairness through supervised learning, which may lead to
overcompensation and degraded performance, our framework achieves fairness in
an unsupervised manner with minimal performance loss. We apply our framework to
real-world urban mobility datasets and demonstrate its ability to close
fairness gaps while delivering competitive predictive performance compared to
state-of-the-art fairness-aware methods.

</details>


### [413] [Physics-Informed Multimodal Bearing Fault Classification under Variable Operating Conditions using Transfer Learning](https://arxiv.org/abs/2508.07536)
*Tasfiq E. Alam,Md Manjurul Ahsan,Shivakumar Raman*

Main category: cs.LG

TL;DR: 该研究提出了一种结合物理知识和多模态数据的CNN模型，用于轴承故障诊断，在不同工况下表现出更好的准确性和鲁棒性，并通过迁移学习提升了泛化能力，最终实现了高精度的跨数据集诊断。


<details>
  <summary>Details</summary>
Motivation: 为了确保旋转机械的可靠性，尤其是在工作条件多变且域偏移会显著降低模型性能的情况下，实现准确且可解释的轴承故障分类至关重要。

Method: 本研究提出了一个物理信息多模态卷积神经网络（CNN），采用了后期融合架构，整合了振动信号和电机电流信号，并包含一个专门的基于物理特征提取的分支。模型引入了一个新颖的物理信息损失函数，该函数会根据从轴承几何和轴速度推导出的特征轴承座外圈频率（BPFO）和轴承座内圈频率（BPFI）来惩罚不符合物理规律的预测。此外，研究评估了三种迁移学习（TL）策略：目标特定微调（TSFT）、层级自适应策略（LAS）和混合特征复用（HFR）。

Result: 实验结果表明，所提出的物理信息方法在Paderborn大学数据集上持续优于非物理信息基线模型，实现了更高的准确性、更少的错误分类，并在多个数据分割中表现出更强的鲁棒性。在迁移学习方面，LAS策略展现出最佳的泛化能力，并且与物理信息建模结合时能带来额外的性能提升。在KAIST轴承数据集上的验证结果也证实了该框架的跨数据集适用性，准确率高达98%。统计假设检验进一步证实了分类性能的显著改进（p < 0.01）。

Conclusion: 该研究提出的物理信息多模态卷积神经网络（CNN）结合后期融合架构，通过整合振动和电机电流信号以及专门的基于物理特征提取分支，并在物理信息损失函数中引入基于轴承几何和轴速度推导出的特征轴承座外圈频率（BPFO）和轴承座内圈频率（BPFI）的物理不合理预测惩罚，在Paderborn大学数据集的实验中，相较于非物理信息基线模型，在准确性、减少错误分类和提高跨多个数据分割的鲁棒性方面均表现出优越性。研究还评估了三种迁移学习（TL）策略（目标特定微调TSFT、层级自适应策略LAS和混合特征复用HFR）以应对未知工况下的性能下降，其中LAS表现出最佳的泛化能力，并与物理信息模型结合能带来额外的性能提升。在KAIST轴承数据集上的验证证实了该框架的跨数据集适用性，准确率高达98%。统计假设检验进一步验证了分类性能的显著提升（p < 0.01）。该框架展示了将领域知识与数据驱动学习相结合，以实现实际工业应用中鲁棒、可解释和可泛化的故障诊断的潜力。

Abstract: Accurate and interpretable bearing fault classification is critical for
ensuring the reliability of rotating machinery, particularly under variable
operating conditions where domain shifts can significantly degrade model
performance. This study proposes a physics-informed multimodal convolutional
neural network (CNN) with a late fusion architecture, integrating vibration and
motor current signals alongside a dedicated physics-based feature extraction
branch. The model incorporates a novel physics-informed loss function that
penalizes physically implausible predictions based on characteristic bearing
fault frequencies - Ball Pass Frequency Outer (BPFO) and Ball Pass Frequency
Inner (BPFI) - derived from bearing geometry and shaft speed. Comprehensive
experiments on the Paderborn University dataset demonstrate that the proposed
physics-informed approach consistently outperforms a non-physics-informed
baseline, achieving higher accuracy, reduced false classifications, and
improved robustness across multiple data splits. To address performance
degradation under unseen operating conditions, three transfer learning (TL)
strategies - Target-Specific Fine-Tuning (TSFT), Layer-Wise Adaptation Strategy
(LAS), and Hybrid Feature Reuse (HFR) - are evaluated. Results show that LAS
yields the best generalization, with additional performance gains when combined
with physics-informed modeling. Validation on the KAIST bearing dataset
confirms the framework's cross-dataset applicability, achieving up to 98
percent accuracy. Statistical hypothesis testing further verifies significant
improvements (p < 0.01) in classification performance. The proposed framework
demonstrates the potential of integrating domain knowledge with data-driven
learning to achieve robust, interpretable, and generalizable fault diagnosis
for real-world industrial applications.

</details>


### [414] [Multimodal Remote Inference](https://arxiv.org/abs/2508.07555)
*Keyuan Zhang,Yin Sun,Bo Ji*

Main category: cs.LG

TL;DR: 该研究提出了一种优化的调度策略，以最小化多模态远程推理系统的推理误差，在网络资源有限的情况下，通过优化数据传输来提高模型准确性。


<details>
  <summary>Details</summary>
Motivation: 在多模态远程推理系统中，及时交付所有模态的特征对于保持模型的准确性至关重要。然而，由于网络资源有限，这通常是不可行的。因此，研究双模态调度问题以最小化机器学习模型的推理误差。

Method: 提出了一种基于索引的阈值策略，证明了其最优性。调度器在当前模态的索引函数超过阈值时切换模态。证明了两种模态具有相同的阈值，并且索引函数和阈值都可以有效地计算。

Result: 所提出的策略可将推理误差减少多达55%，优于随机轮询和均匀随机策略。

Conclusion: 研究结果表明，通过优化面向任务的平均驻留时间（AoI）函数可以提高远程推理的准确性。

Abstract: We consider a remote inference system with multiple modalities, where a
multimodal machine learning (ML) model performs real-time inference using
features collected from remote sensors. As sensor observations may change
dynamically over time, fresh features are critical for inference tasks.
However, timely delivering features from all modalities is often infeasible due
to limited network resources. To this end, we study a two-modality scheduling
problem to minimize the ML model's inference error, which is expressed as a
penalty function of AoI for both modalities. We develop an index-based
threshold policy and prove its optimality. Specifically, the scheduler switches
modalities when the current modality's index function exceeds a threshold. We
show that the two modalities share the same threshold, and both the index
functions and the threshold can be computed efficiently. The optimality of our
policy holds for (i) general AoI functions that are \emph{non-monotonic} and
\emph{non-additive} and (ii) \emph{heterogeneous} transmission times. Numerical
results show that our policy reduces inference error by up to 55% compared to
round-robin and uniform random policies, which are oblivious to the AoI-based
inference error function. Our results shed light on how to improve remote
inference accuracy by optimizing task-oriented AoI functions.

</details>


### [415] [Uncertainty-Driven Reliability: Selective Prediction and Trustworthy Deployment in Modern Machine Learning](https://arxiv.org/abs/2508.07556)
*Stephan Rabanser*

Main category: cs.LG

TL;DR: 机器学习模型在关键任务中应知道何时表示“我不知道”。本文提出了一种利用模型训练轨迹的中间检查点来估计不确定性的方法，以提高机器学习的可靠性。该方法在差分隐私下保持鲁棒性，并能防御对抗性操纵不确定性信号的策略。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统越来越多地应用于高风险领域，对可靠性要求极高。本文旨在研究不确定性估计如何提高机器学习的安全性和可信度，特别是通过选择性预测（即模型在置信度低时弃权）。

Method: 本文提出了一种利用模型训练轨迹的中间检查点来估计不确定性的方法。该方法通过集成中间检查点的预测来实现，无需改变模型架构或损失函数。此外，研究还开发了一种有限样本分解选择性分类差距的方法，并设计了结合校准审计和可验证推理的防御策略。

Result: 本文提出的基于训练轨迹的方法是一种轻量级的、事后不确定性估计方法，适用于多种任务，且成本低于深度集成。该方法在差分隐私下保持鲁棒性，并能分离隐私-不确定性权衡。此外，研究还明确了选择性分类差距的五个可解释的误差来源，并展示了不确定性信号可能被操纵，以及相应的防御措施。

Conclusion: 本文提出了一种利用模型训练轨迹的中间检查点来估计不确定性的方法，以提高机器学习的可靠性。该方法能够在模型置信度低时进行选择性预测，并且与差分隐私兼容。此外，研究还分析了选择性预测的误差来源，并提出了防御对抗性操纵不确定性信号的策略。

Abstract: Machine learning (ML) systems are increasingly deployed in high-stakes
domains where reliability is paramount. This thesis investigates how
uncertainty estimation can enhance the safety and trustworthiness of ML,
focusing on selective prediction -- where models abstain when confidence is
low.
  We first show that a model's training trajectory contains rich uncertainty
signals that can be exploited without altering its architecture or loss. By
ensembling predictions from intermediate checkpoints, we propose a lightweight,
post-hoc abstention method that works across tasks, avoids the cost of deep
ensembles, and achieves state-of-the-art selective prediction performance.
Crucially, this approach is fully compatible with differential privacy (DP),
allowing us to study how privacy noise affects uncertainty quality. We find
that while many methods degrade under DP, our trajectory-based approach remains
robust, and we introduce a framework for isolating the privacy-uncertainty
trade-off. Next, we then develop a finite-sample decomposition of the selective
classification gap -- the deviation from the oracle accuracy-coverage curve --
identifying five interpretable error sources and clarifying which interventions
can close the gap. This explains why calibration alone cannot fix ranking
errors, motivating methods that improve uncertainty ordering. Finally, we show
that uncertainty signals can be adversarially manipulated to hide errors or
deny service while maintaining high accuracy, and we design defenses combining
calibration audits with verifiable inference.
  Together, these contributions advance reliable ML by improving, evaluating,
and safeguarding uncertainty estimation, enabling models that not only make
accurate predictions -- but also know when to say "I do not know".

</details>


### [416] [Towards Theoretical Understanding of Transformer Test-Time Computing: Investigation on In-Context Linear Regression](https://arxiv.org/abs/2508.07571)
*Xingwu Chen,Miao Lu,Beining Wu,Difan Zou*

Main category: cs.LG

TL;DR: 本文通过整合随机性和采样来弥合实际语言模型推理和理论 Transformer 分析之间的差距，重点研究了上下文内线性回归，并提出了一个展示其在理解语言模型推理行为方面的潜力的理论框架。


<details>
  <summary>Details</summary>
Motivation: 本文旨在弥合实际语言模型推理和理论 Transformer 分析之间的差距，方法是整合随机性和采样。

Method: 本文将随机性和采样纳入其框架，模拟了语言模型解码过程，重点研究了具有连续/二元系数的上下文内线性回归，并通过噪声注入和二元系数采样进行。

Result: 该框架通过经验结果得到了支持，并为理解真实世界语言模型的推理行为提供了见解。

Conclusion: 本文提出的理论框架和分析通过经验结果得到支持，展示了为理解真实世界语言模型的推理行为提供新见解的潜力。

Abstract: Using more test-time computation during language model inference, such as
generating more intermediate thoughts or sampling multiple candidate answers,
has proven effective in significantly improving model performance. This paper
takes an initial step toward bridging the gap between practical language model
inference and theoretical transformer analysis by incorporating randomness and
sampling. We focus on in-context linear regression with continuous/binary
coefficients, where our framework simulates language model decoding through
noise injection and binary coefficient sampling. Through this framework, we
provide detailed analyses of widely adopted inference techniques. Supported by
empirical results, our theoretical framework and analysis demonstrate the
potential for offering new insights into understanding inference behaviors in
real-world language models.

</details>


### [417] [When and how can inexact generative models still sample from the data manifold?](https://arxiv.org/abs/2508.07581)
*Nisha Chandramoorthy,Adriaan de Clercq*

Main category: cs.LG

TL;DR: 该研究通过动力学方法解释了生成模型中的“支撑集鲁棒性”现象，即模型即使在学习误差下也能生成逼真的数据。研究发现，李雅普诺夫向量与数据流形边界切空间的对齐是实现该现象的关键，并提出了相应的计算和验证方法。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在探究并解释一类生成模型在学习过程中出现的“支撑集鲁棒性”现象，即模型在学习误差下仍能生成接近真实数据分布的样本。

Method: 通过扰动分析概率流，研究发现对于广泛的生成模型，微小的学习误差仅会导致数据流形上的预测密度与目标密度产生差异。通过分析最敏感的微小扰动方向（顶级李雅普诺夫向量）是否沿着数据流形边界的切空间对齐，来揭示导致支撑集鲁棒性的动力学机制，并提出了实现这种对齐的动力学过程的充分条件。

Result: 研究表明，顶级李雅普诺夫向量与数据流形边界切空间的对齐是实现支撑集鲁棒性的关键。此外，该研究提出的对齐条件不仅易于计算，而且在实践中能自动得到数据流形切空间束的准确估计。该研究通过有限时间线性扰动分析样本路径和概率流，为生成模型提供了理论保证，并扩展了随机分析、统计学习和不确定性量化等领域的相关工作。

Conclusion: 该研究解释了为什么即使在得分函数或漂移向量场存在学习误差的情况下，某些动态生成模型仍能生成沿数据分布支撑集而非偏离其支撑集的样本。通过对生成过程（随机/确定性）进行动力系统分析，该研究揭示了“支撑集鲁棒性”现象。

Abstract: A curious phenomenon observed in some dynamical generative models is the
following: despite learning errors in the score function or the drift vector
field, the generated samples appear to shift \emph{along} the support of the
data distribution but not \emph{away} from it. In this work, we investigate
this phenomenon of \emph{robustness of the support} by taking a dynamical
systems approach on the generating stochastic/deterministic process. Our
perturbation analysis of the probability flow reveals that infinitesimal
learning errors cause the predicted density to be different from the target
density only on the data manifold for a wide class of generative models.
Further, what is the dynamical mechanism that leads to the robustness of the
support? We show that the alignment of the top Lyapunov vectors (most sensitive
infinitesimal perturbation directions) with the tangent spaces along the
boundary of the data manifold leads to robustness and prove a sufficient
condition on the dynamics of the generating process to achieve this alignment.
Moreover, the alignment condition is efficient to compute and, in practice, for
robust generative models, automatically leads to accurate estimates of the
tangent bundle of the data manifold. Using a finite-time linear perturbation
analysis on samples paths as well as probability flows, our work complements
and extends existing works on obtaining theoretical guarantees for generative
models from a stochastic analysis, statistical learning and uncertainty
quantification points of view. Our results apply across different dynamical
generative models, such as conditional flow-matching and score-based generative
models, and for different target distributions that may or may not satisfy the
manifold hypothesis.

</details>


### [418] [Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization](https://arxiv.org/abs/2508.07629)
*Zhenpeng Su,Leiyu Pan,Xue Bai,Dening Liu,Guanting Dong,Jiaming Huang,Wenping Hu,Guorui Zhou*

Main category: cs.LG

TL;DR: Klear-Reasoner是一个长推理模型，通过改进SFT数据选择和提出GPPO算法，在数学和编程基准测试中取得了优异成绩。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前推理模型在复现高性能方面存在的问题，例如训练细节披露不完整。

Method: 提出了一种名为Klear-Reasoner的模型，该模型具有长推理能力。研究了从数据准备、长链式思考监督微调（long CoT SFT）到强化学习（RL）的整个训练后工作流程。提出了梯度保留裁剪策略优化（GPPO）方法来解决RL中的裁剪机制问题，该方法温和地反向传播裁剪令牌的梯度，增强了模型的探索能力并提高了从负样本学习的效率。

Result: 研究表明，高质量的SFT数据源比大量多样的数据源更有效，并且困难样本在没有准确性过滤的情况下可以取得更好的结果。GPPO增强了模型的探索能力，并提高了从负样本学习的效率。

Conclusion: Klear-Reasoner在数学和编程方面表现出卓越的推理能力，在AIME 2024上得分90.5%，在AIME 2025上得分83.2%，在LiveCodeBench V5上得分66.0%，在LiveCodeBench V6上得分58.1%。

Abstract: We present Klear-Reasoner, a model with long reasoning capabilities that
demonstrates careful deliberation during problem solving, achieving outstanding
performance across multiple benchmarks. Although there are already many
excellent works related to inference models in the current community, there are
still many problems with reproducing high-performance inference models due to
incomplete disclosure of training details. This report provides an in-depth
analysis of the reasoning model, covering the entire post-training workflow
from data preparation and long Chain-of-Thought supervised fine-tuning (long
CoT SFT) to reinforcement learning (RL), along with detailed ablation studies
for each experimental component. For SFT data, our experiments show that a
small number of high-quality data sources are more effective than a large
number of diverse data sources, and that difficult samples can achieve better
results without accuracy filtering. In addition, we investigate two key issues
with current clipping mechanisms in RL: Clipping suppresses critical
exploration signals and ignores suboptimal trajectories. To address these
challenges, we propose Gradient-Preserving clipping Policy Optimization (GPPO)
that gently backpropagates gradients from clipped tokens. GPPO not only
enhances the model's exploration capacity but also improves its efficiency in
learning from negative samples. Klear-Reasoner exhibits exceptional reasoning
abilities in mathematics and programming, scoring 90.5\% on AIME 2024, 83.2\%
on AIME 2025, 66.0\% on LiveCodeBench V5 and 58.1\% on LiveCodeBench V6.

</details>


### [419] [Efficient Approximate Posterior Sampling with Annealed Langevin Monte Carlo](https://arxiv.org/abs/2508.07631)
*Advait Parulekar,Litu Rout,Karthikeyan Shanmugam,Sanjay Shakkottai*

Main category: cs.LG

TL;DR: 得分基生成模型在后验采样（从 p(x|y) 采样）方面存在挑战，这在 KL 散度下通常是不可行的。本研究将此问题视为“倾斜”问题，并提出了一种在 KL 散度和 Fisher 散度下都接近目标后验分布的采样方法，该方法在多项式时间内是可行的。


<details>
  <summary>Details</summary>
Motivation: 在得分基生成模型中，即使在最坏情况下，从后验分布 p(x|y) 进行采样在 KL 散度下也是不可行的。然而，像图像超分辨率、风格化和重建等任务中的流行算法取得了经验上的成功。因此，本研究旨在解决这种不一致性。

Method: 将后验采样视为一个“倾斜”问题，即偏置一个分布使其倾向于一个测量模型。在最小假设下，证明了可以有效地从一个同时在 KL 散度下接近带噪声先验后验分布且在 Fisher 散度下接近真实后验分布的分布中进行采样。

Result: 本研究提供了首个在多项式时间内（近似）后验采样的形式化结果，该方法结合了 KL 散度和 Fisher 散度，以确保样本同时与测量模型和先验保持一致。

Conclusion: 本研究首次在多项式时间内对（近似）后验采样进行了形式化证明，并展示了如何在最小假设下从一个 KL 散度下接近带噪声先验后验分布且 Fisher 散度下接近真实后验分布的分布中进行采样。

Abstract: We study the problem of posterior sampling in the context of score based
generative models. We have a trained score network for a prior $p(x)$, a
measurement model $p(y|x)$, and are tasked with sampling from the posterior
$p(x|y)$. Prior work has shown this to be intractable in KL (in the worst case)
under well-accepted computational hardness assumptions. Despite this, popular
algorithms for tasks such as image super-resolution, stylization, and
reconstruction enjoy empirical success. Rather than establishing distributional
assumptions or restricted settings under which exact posterior sampling is
tractable, we view this as a more general "tilting" problem of biasing a
distribution towards a measurement. Under minimal assumptions, we show that one
can tractably sample from a distribution that is simultaneously close to the
posterior of a noised prior in KL divergence and the true posterior in Fisher
divergence. Intuitively, this combination ensures that the resulting sample is
consistent with both the measurement and the prior. To the best of our
knowledge these are the first formal results for (approximate) posterior
sampling in polynomial time.

</details>


### [420] [Attribution Explanations for Deep Neural Networks: A Theoretical Perspective](https://arxiv.org/abs/2508.07636)
*Huiqi Deng,Hongbin Pei,Quanshi Zhang,Mengnan Du*

Main category: cs.LG

TL;DR: 本篇论文探讨了当前用于解释深度神经网络（DNN）的归因方法所面临的“忠实性”挑战，并重点介绍了通过理论统一、理论依据和理论评估来解决这些挑战的最新进展。


<details>
  <summary>Details</summary>
Motivation: 当前许多归因方法在解释深度神经网络（DNN）方面存在忠实性问题，即它们是否准确反映了输入变量对最终输出的实际贡献尚不明确，这影响了归因解释的可靠性和实用性。

Method: 本文对用于解释深度神经网络（DNN）的归因方法进行了综述，重点关注解决“忠实性”问题的理论进展。文章讨论了三个关键方向：理论统一、理论依据和理论评估。

Result: 该综述总结了近期在理论统一、理论依据和理论评估方面为解决归因方法忠实性问题所做的努力，并讨论了这些研究如何深化理论理解、指导方法选择以及启发新方法的开发。

Conclusion: 随着研究的深入，理论统一、理论依据和理论评估为解决归因方法的忠实性问题提供了有力的支持，加深了对这些方法的理论理解，并指导了新方法的开发。

Abstract: Attribution explanation is a typical approach for explaining deep neural
networks (DNNs), inferring an importance or contribution score for each input
variable to the final output. In recent years, numerous attribution methods
have been developed to explain DNNs. However, a persistent concern remains
unresolved, i.e., whether and which attribution methods faithfully reflect the
actual contribution of input variables to the decision-making process. The
faithfulness issue undermines the reliability and practical utility of
attribution explanations. We argue that these concerns stem from three core
challenges. First, difficulties arise in comparing attribution methods due to
their unstructured heterogeneity, differences in heuristics, formulations, and
implementations that lack a unified organization. Second, most methods lack
solid theoretical underpinnings, with their rationales remaining absent,
ambiguous, or unverified. Third, empirically evaluating faithfulness is
challenging without ground truth. Recent theoretical advances provide a
promising way to tackle these challenges, attracting increasing attention. We
summarize these developments, with emphasis on three key directions: (i)
Theoretical unification, which uncovers commonalities and differences among
methods, enabling systematic comparisons; (ii) Theoretical rationale,
clarifying the foundations of existing methods; (iii) Theoretical evaluation,
rigorously proving whether methods satisfy faithfulness principles. Beyond a
comprehensive review, we provide insights into how these studies help deepen
theoretical understanding, inform method selection, and inspire new attribution
methods. We conclude with a discussion of promising open problems for further
work.

</details>


### [421] [Extracting Complex Topology from Multivariate Functional Approximation: Contours, Jacobi Sets, and Ridge-Valley Graphs](https://arxiv.org/abs/2508.07637)
*Guanqun Ma,David Lenz,Hanqi Guo,Tom Peterka,Bei Wang*

Main category: cs.LG

TL;DR: 提出了一种从连续隐式模型（MFA）中提取拓扑特征（轮廓、雅可比集、脊谷图）的新框架，无需离散化，为拓扑数据分析和可视化开辟了新途径。


<details>
  <summary>Details</summary>
Motivation: 将离散数据表示替换为连续、高阶、可微的替代模型，以存储、传输和分析科学数据。

Method: 提出了一种直接从多变量函数逼近（MFA）模型中提取复杂拓扑特征（轮廓、雅可比集、脊谷图）的框架，无需转回离散表示。

Result: 首次实现了从MFA模型直接提取复杂拓扑特征，并且该方法易于泛化到支持函数值和高阶导数查询的任何连续隐式模型。

Conclusion: 该研究为拓扑数据分析和可视化在隐式连续模型上的应用奠定了基础。

Abstract: Implicit continuous models, such as functional models and implicit neural
networks, are an increasingly popular method for replacing discrete data
representations with continuous, high-order, and differentiable surrogates.
These models offer new perspectives on the storage, transfer, and analysis of
scientific data. In this paper, we introduce the first framework to directly
extract complex topological features -- contours, Jacobi sets, and ridge-valley
graphs -- from a type of continuous implicit model known as multivariate
functional approximation (MFA). MFA replaces discrete data with continuous
piecewise smooth functions. Given an MFA model as the input, our approach
enables direct extraction of complex topological features from the model,
without reverting to a discrete representation of the model. Our work is easily
generalizable to any continuous implicit model that supports the queries of
function values and high-order derivatives. Our work establishes the building
blocks for performing topological data analysis and visualization on implicit
continuous models.

</details>


### [422] [Beyond Single: A Data Selection Principle for LLM Alignment via Fine-Grained Preference Signals](https://arxiv.org/abs/2508.07638)
*Jia Zhang,Yao Liu,Chen-Xi Zhang,Yi Liu,Yi-Xuan Jin,Lan-Zhe Guo,Yu-Feng Li*

Main category: cs.LG

TL;DR: This paper introduces a data selection method called PD selection to improve LLM alignment using fine-grained preferences. It uses a 'Preference Divergence' term to find data with high agreement, making training more efficient and improving results by over 10% compared to other methods.


<details>
  <summary>Details</summary>
Motivation: Existing methods like DPO struggle with noisy and conflicting fine-grained preference data, necessitating a more robust approach to aligning Large Language Models (LLMs) with diverse human values. The motivation is to move beyond single, holistic preference criteria and effectively utilize scalable, aspect-specific preference data.

Method: The paper proposes a data-centric approach by deriving the Direct Multi-Preference Optimization (DMPO) objective and identifying a Preference Divergence (PD) term that quantifies inter-aspect preference conflicts. This PD term is then used to formulate a data selection principle, favoring data with high consensus (negative PD values) for efficient Direct Preference Optimization (DPO) training. Practical methods for PD term estimation and length bias mitigation are also introduced.

Result: The PD selection method achieves over 10% relative improvement compared to standard holistic preference and an oracle method on the UltraFeedback dataset, even with high conflict levels. It also enhances training efficiency and avoids the need for difficult holistic preference annotations.

Conclusion: Aligning LLMs with diverse human values can be effectively achieved by leveraging fine-grained preference signals through a novel data selection strategy based on Preference Divergence (PD). This method, termed PD selection, identifies and utilizes high-consensus data points, leading to significant improvements over existing methods and boosting training efficiency.

Abstract: Aligning Large Language Models (LLMs) with diverse human values requires
moving beyond a single holistic "better-than" preference criterion. While
collecting fine-grained, aspect-specific preference data is more reliable and
scalable, existing methods like Direct Preference Optimization (DPO) struggle
with the severe noise and conflicts inherent in such aggregated datasets. In
this paper, we tackle this challenge from a data-centric perspective. We first
derive the Direct Multi-Preference Optimization (DMPO) objective, and uncover a
key Preference Divergence (PD) term that quantifies inter-aspect preference
conflicts. Instead of using this term for direct optimization, we leverage it
to formulate a novel, theoretically-grounded data selection principle. Our
principle advocates for selecting a subset of high-consensus data-identified by
the most negative PD values-for efficient DPO training. We prove the optimality
of this strategy by analyzing the loss bounds of the DMPO objective in the
selection problem. To operationalize our approach, we introduce practical
methods of PD term estimation and length bias mitigation, thereby proposing our
PD selection method. Evaluation on the UltraFeedback dataset with three varying
conflict levels shows that our simple yet effective strategy achieves over 10%
relative improvement against both the standard holistic preference and a
stronger oracle using aggregated preference signals, all while boosting
training efficiency and obviating the need for intractable holistic preference
annotating, unlocking the potential of robust LLM alignment via fine-grained
preference signals.

</details>


### [423] [Multi-Turn Jailbreaks Are Simpler Than They Seem](https://arxiv.org/abs/2508.07646)
*Xiaoxue Yang,Jaeha Lee,Anna-Katharina Dick,Jasper Timm,Fei Xie,Diogo Cruz*

Main category: cs.LG

TL;DR: 多轮越狱攻击并不比单轮攻击更复杂，并且与模型拒绝有害请求的方式相关，尤其是对于推理能力强的模型。


<details>
  <summary>Details</summary>
Motivation: 尽管针对单轮越狱攻击的防御能力有了显著提高，但多轮越狱仍然是一种持续存在的漏洞，成功率往往超过70%。

Method: 对包括GPT-4、Claude和Gemini变体在内的最先进模型进行了自动化多轮越狱攻击的实证分析，使用了StrongREJECT基准。

Result: 当考虑到攻击者能够从模型如何拒绝有害请求中学习时，多轮越狱方法大约等同于对单轮攻击进行多次采样。攻击成功率在相似模型之间相关。对于推理模型，更高的推理努力通常会导致更高的攻击成功率。

Conclusion: 多轮越狱攻击的成功率与单轮攻击的多次采样相当，攻击成功率与相似模型相关，高推理能力模型更容易被越狱。

Abstract: While defenses against single-turn jailbreak attacks on Large Language Models
(LLMs) have improved significantly, multi-turn jailbreaks remain a persistent
vulnerability, often achieving success rates exceeding 70% against models
optimized for single-turn protection. This work presents an empirical analysis
of automated multi-turn jailbreak attacks across state-of-the-art models
including GPT-4, Claude, and Gemini variants, using the StrongREJECT benchmark.
Our findings challenge the perceived sophistication of multi-turn attacks: when
accounting for the attacker's ability to learn from how models refuse harmful
requests, multi-turn jailbreaking approaches are approximately equivalent to
simply resampling single-turn attacks multiple times. Moreover, attack success
is correlated among similar models, making it easier to jailbreak newly
released ones. Additionally, for reasoning models, we find surprisingly that
higher reasoning effort often leads to higher attack success rates. Our results
have important implications for AI safety evaluation and the design of
jailbreak-resistant systems. We release the source code at
https://github.com/diogo-cruz/multi_turn_simpler

</details>


### [424] [Discovering Spatial Correlations between Earth Observations in Global Atmospheric State Estimation by using Adaptive Graph Structure Learning](https://arxiv.org/abs/2508.07659)
*Hyeon-Ju Jeon,Jeon-Ho Kang,In-Hyuk Kwon,O-Joun Lee*

Main category: cs.LG

TL;DR: 为提高天气预报精度，本文提出了一种改进的STGNN模型，通过自适应边采样解决结构学习中的信息丢失和平滑问题，并在实际数据中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 为了提高全球大气状态估计的预测准确性，需要发现地球观测与大气状态之间的空间相关性。传统的数值天气预报（NWP）系统在预测时存在固定网格点的问题，而观测数据没有固定位置，这使得空间相关性变得复杂且动态变化。

Method: 本文提出了一种采用结构学习的图神经网络（STGNN）方法，并通过自适应地确定节点度数和考虑网格点与观测值的空间距离来调节边采样，以解决传统结构学习方法中可能存在的信息丢失和平滑问题。

Result: 实验结果表明，该模型在东亚地区的实际大气状态和观测数据上，即使在İ高大气变率的区域，其性能也优于现有的STGNN模型，包括那些未使用结构学习的模型。

Conclusion: 该研究提出的结合了结构学习和自适应边采样策略的STGNN模型，在东亚地区的实际大气状态和观测数据验证中，相比现有的STGNN模型（包括未使用结构学习的模型），在提高天气预报准确性方面表现出优越性，尤其是在大气变化剧烈的区域。

Abstract: This study aims to discover spatial correlations between Earth observations
and atmospheric states to improve the forecasting accuracy of global
atmospheric state estimation, which are usually conducted using conventional
numerical weather prediction (NWP) systems and is the beginning of weather
forecasting. NWP systems predict future atmospheric states at fixed locations,
which are called NWP grid points, by analyzing previous atmospheric states and
newly acquired Earth observations without fixed locations. Thus, surrounding
meteorological context and the changing locations of the observations make
spatial correlations between atmospheric states and observations over time. To
handle complicated spatial correlations, which change dynamically, we employ
spatiotemporal graph neural networks (STGNNs) with structure learning. However,
structure learning has an inherent limitation that this can cause structural
information loss and over-smoothing problem by generating excessive edges. To
solve this problem, we regulate edge sampling by adaptively determining node
degrees and considering the spatial distances between NWP grid points and
observations. We validated the effectiveness of the proposed method by using
real-world atmospheric state and observation data from East Asia. Even in areas
with high atmospheric variability, the proposed method outperformed existing
STGNN models with and without structure learning.

</details>


### [425] [GLiClass: Generalist Lightweight Model for Sequence Classification Tasks](https://arxiv.org/abs/2508.07662)
*Ihor Stepanov,Mykhailo Shtopko,Dmytro Vodianytskyi,Oleksandr Lukashov,Alexander Yavorskyi,Mykyta Yaroshenko*

Main category: cs.LG

TL;DR: GLiClass是一种新的序列分类方法，通过改编GLiNER架构和PPO，在效率和准确性上表现出色，并能适应零样本和少样本学习。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有AI分类方法在处理大规模数据、动态变化的需求以及效率和准确性方面的挑战，例如生成式语言模型（LLMs）的计算效率和指令遵循不一致性，以及交叉编码器的顺序处理瓶颈。

Method: GLiClass方法将GLiNER架构应用于序列分类任务，并通过改编近端策略优化（PPO）来处理多标签文本分类。

Result: GLiClass在准确性和效率方面取得了与嵌入式方法相媲美的结果，同时具备处理零样本和少样本学习场景的灵活性。

Conclusion: GLiClass方法在准确性和效率方面均表现出色，可与基于嵌入式的方法相媲美，同时保持了零样本和少样本学习场景所需的灵活性。此外，我们还为多标签文本分类任务改编了近端策略优化（PPO），实现了在数据稀疏条件下或根据人类反馈进行分类器训练。

Abstract: Classification is one of the most widespread tasks in AI applications,
serving often as the first step in filtering, sorting, and categorizing data.
Since modern AI systems must handle large volumes of input data and early
pipeline stages can propagate errors downstream, achieving high efficiency and
accuracy is critical. Moreover, classification requirements can change
dynamically based on user needs, necessitating models with strong zero-shot
capabilities. While generative LLMs have become mainstream for zero-shot
classification due to their versatility, they suffer from inconsistent
instruction following and computational inefficiency. Cross-encoders, commonly
used as rerankers in RAG pipelines, face a different bottleneck: they must
process text-label pairs sequentially, significantly reducing efficiency with
large label sets. Embedding-based approaches offer good efficiency but struggle
with complex scenarios involving logical and semantic constraints. We propose
GLiClass, a novel method that adapts the GLiNER architecture for sequence
classification tasks. Our approach achieves strong accuracy and efficiency
comparable to embedding-based methods, while maintaining the flexibility needed
for zero-shot and few-shot learning scenarios. Additionally, we adapted
proximal policy optimization (PPO) for multi-label text classification,
enabling training classifiers in data-sparse conditions or from human feedback.

</details>


### [426] [AIS-LLM: A Unified Framework for Maritime Trajectory Prediction, Anomaly Detection, and Collision Risk Assessment with Explainable Forecasting](https://arxiv.org/abs/2508.07668)
*Hyobin Park,Jinwook Jung,Minseok Seo,Hyunsoo Choi,Deukjae Cho,Sekil Park,Dong-Geol Choi*

Main category: cs.LG

TL;DR: AIS-LLM是一个创新的框架，它结合了AIS数据和LLM，能够同时处理海上交通的轨迹预测、异常检测和碰撞风险评估，并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的海上交通分析方法倾向于单独处理轨迹预测、异常检测和碰撞风险评估等任务，难以整体考虑复杂的海上情况。

Method: 提出了一种名为AIS-LLM的新框架，该框架整合了时间序列AIS数据和一个大型语言模型（LLM）。AIS-LLM包含一个用于处理AIS序列的时间序列编码器、一个基于LLM的提示编码器、一个用于时间序列数据和文本提示之间语义对齐的跨模态对齐模块，以及一个基于LLM的多任务解码器。

Result: 实验结果表明，AIS-LLM在各项单独任务上的表现均优于现有方法，并且通过整合分析任务输出来生成态势摘要和简报，展示了其在更智能、更高效的海上交通管理方面的潜力。

Conclusion: AIS-LLM通过整合时间序列AIS数据和大型语言模型，实现了轨迹预测、异常检测和碰撞风险评估这三个关键任务的集成，并且在各项任务上均超越了现有方法，为更智能高效的海上交通管理提供了潜力。

Abstract: With the increase in maritime traffic and the mandatory implementation of the
Automatic Identification System (AIS), the importance and diversity of maritime
traffic analysis tasks based on AIS data, such as vessel trajectory prediction,
anomaly detection, and collision risk assessment, is rapidly growing. However,
existing approaches tend to address these tasks individually, making it
difficult to holistically consider complex maritime situations. To address this
limitation, we propose a novel framework, AIS-LLM, which integrates time-series
AIS data with a large language model (LLM). AIS-LLM consists of a Time-Series
Encoder for processing AIS sequences, an LLM-based Prompt Encoder, a
Cross-Modality Alignment Module for semantic alignment between time-series data
and textual prompts, and an LLM-based Multi-Task Decoder. This architecture
enables the simultaneous execution of three key tasks: trajectory prediction,
anomaly detection, and risk assessment of vessel collisions within a single
end-to-end system. Experimental results demonstrate that AIS-LLM outperforms
existing methods across individual tasks, validating its effectiveness.
Furthermore, by integratively analyzing task outputs to generate situation
summaries and briefings, AIS-LLM presents the potential for more intelligent
and efficient maritime traffic management.

</details>


### [427] [Semantic Caching for Low-Cost LLM Serving: From Offline Learning to Online Adaptation](https://arxiv.org/abs/2508.07675)
*Xutong Liu,Baran Atalar,Xiangxiang Dai,Jinhang Zuo,Siwei Wang,John C. S. Lui,Wei Chen,Carlee Joe-Wong*

Main category: cs.LG

TL;DR: 该研究提出了一种新的语义缓存策略，通过学习来优化缓存驱逐，以降低大型语言模型的推理成本，并在实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLM）高推理成本带来的可扩展性和可持续性挑战，以及现有语义缓存方法在处理不确定性方面的不足。

Method: 提出了一种基于学习的框架，包括离线优化和在线学习的变体，并开发了具有可证明效率和最新保证的算法。

Result: 在合成数据集上进行了评估，结果显示所提出的算法与基线相比具有匹配或更优的性能。

Conclusion: 该研究提出了一个基于学习的语义缓存驱逐框架，能够处理未知的查询和成本分布，并提供了具有理论保证的有效算法。

Abstract: Large Language Models (LLMs) are revolutionizing how users interact with
information systems, yet their high inference cost poses serious scalability
and sustainability challenges. Caching inference responses, allowing them to be
retrieved without another forward pass through the LLM, has emerged as one
possible solution. Traditional exact-match caching, however, overlooks the
semantic similarity between queries, leading to unnecessary recomputation.
Semantic caching addresses this by retrieving responses based on semantic
similarity, but introduces a fundamentally different cache eviction problem:
one must account for mismatch costs between incoming queries and cached
responses. Moreover, key system parameters, such as query arrival probabilities
and serving costs, are often unknown and must be learned over time. Existing
semantic caching methods are largely ad-hoc, lacking theoretical foundations
and unable to adapt to real-world uncertainty. In this paper, we present a
principled, learning-based framework for semantic cache eviction under unknown
query and cost distributions. We formulate both offline optimization and online
learning variants of the problem, and develop provably efficient algorithms
with state-of-the-art guarantees. We also evaluate our framework on a synthetic
dataset, showing that our proposed algorithms perform matching or superior
performance compared with baselines.

</details>


### [428] [MORE-CLEAR: Multimodal Offline Reinforcement learning for Clinical notes Leveraged Enhanced State Representation](https://arxiv.org/abs/2508.07681)
*Yooseok Lim,ByoungJun Jeon,Seong-A Park,Jisoo Lee,Sae Won Choi,Chang Wook Jeong,Ho-Geol Ryu,Hongyeol Lee,Hyun-Lim Yang*

Main category: cs.LG

TL;DR: MORE-CLEAR框架使用大语言模型处理临床笔记，结合多模态数据，在脓毒症管理中提高了生存率和策略表现。


<details>
  <summary>Details</summary>
Motivation: 脓毒症是一种危及生命的感染反应，会导致器官功能障碍，因此早期检测和最佳管理至关重要。以往的强化学习（RL）方法主要依赖结构化数据，缺乏对患者病情的全面理解。

Method: 本文提出了一种名为MORE-CLEAR的脓毒症管理框架，该框架利用预训练大语言模型（LLMs）从临床笔记中提取丰富的语义表征，以增强患者状态的表示。框架结合了门控融合和跨模态注意力机制，能够动态调整时间背景下的权重，并有效整合多模态数据。

Result: 通过在MIMIC-III、MIMIC-IV以及一个私有数据集上进行的大量交叉验证，MORE-CLEAR相比单一模态的RL方法，能够显著提高估计生存率和策略表现。

Conclusion: MORE-CLEAR框架通过利用预训练大语言模型提取临床笔记中的语义信息，并结合门控融合和跨模态注意力机制，实现了对多模态数据的有效整合，显著提高了脓毒症管理的生存率和策略表现，是医疗领域首个在大语言模型赋能的多模态离线强化学习方面的应用。

Abstract: Sepsis, a life-threatening inflammatory response to infection, causes organ
dysfunction, making early detection and optimal management critical. Previous
reinforcement learning (RL) approaches to sepsis management rely primarily on
structured data, such as lab results or vital signs, and on a dearth of a
comprehensive understanding of the patient's condition. In this work, we
propose a Multimodal Offline REinforcement learning for Clinical notes
Leveraged Enhanced stAte Representation (MORE-CLEAR) framework for sepsis
control in intensive care units. MORE-CLEAR employs pre-trained large-scale
language models (LLMs) to facilitate the extraction of rich semantic
representations from clinical notes, preserving clinical context and improving
patient state representation. Gated fusion and cross-modal attention allow
dynamic weight adjustment in the context of time and the effective integration
of multimodal data. Extensive cross-validation using two public (MIMIC-III and
MIMIC-IV) and one private dataset demonstrates that MORE-CLEAR significantly
improves estimated survival rate and policy performance compared to
single-modal RL approaches. To our knowledge, this is the first to leverage LLM
capabilities within a multimodal offline RL for better state representation in
medical applications. This approach can potentially expedite the treatment and
management of sepsis by enabling reinforcement learning models to propose
enhanced actions based on a more comprehensive understanding of patient
conditions.

</details>


### [429] [Semantic-Enhanced Time-Series Forecasting via Large Language Models](https://arxiv.org/abs/2508.07697)
*Hao Liu,Chun Yang,Zhang xiaoxing,Xiaobin Zhu*

Main category: cs.LG

TL;DR: SE-LLM 通过增强 LLM 的语义表示和改进其在时间序列中的依赖建模能力，提升了其在时间序列预测任务中的表现，同时降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的 LLM 在时间序列预测方面的研究主要集中在 token 级别的模式对齐，未能解决语言知识结构与时间序列数据模式之间固有的模态鸿沟，这严重限制了语义表示能力。此外，现有的基于 Transformer 的 LLM 在建模短期异常方面存在不足。

Method: 提出了一种新的语义增强 LLM (SE-LLM)，该模型通过将时间序列的固有周期性和异常特征嵌入到语义空间来增强 token 嵌入，并设计了一个嵌入在自注意力机制中的插件模块来同时处理长期和短期依赖关系。该模型冻结 LLM 并降低 token 的序列维度，从而减少计算消耗。

Result: 实验证明，SE-LLM 在时间序列分析任务上取得了优于现有最先进 (SOTA) 方法的性能。

Conclusion: SE-LLM 通过嵌入时间序列的周期性和异常特征来增强 LLM 的语义表示，并结合插件模块来处理短期异常，在时间序列分析任务中展现出优于 SOTA 方法的性能。

Abstract: Time series forecasting plays a significant role in finance, energy,
meteorology, and IoT applications. Recent studies have leveraged the
generalization capabilities of large language models (LLMs) to adapt to time
series forecasting, achieving promising performance. However, existing studies
focus on token-level modal alignment, instead of bridging the intrinsic
modality gap between linguistic knowledge structures and time series data
patterns, greatly limiting the semantic representation. To address this issue,
we propose a novel Semantic-Enhanced LLM (SE-LLM) that explores the inherent
periodicity and anomalous characteristics of time series to embed into the
semantic space to enhance the token embedding. This process enhances the
interpretability of tokens for LLMs, thereby activating the potential of LLMs
for temporal sequence analysis. Moreover, existing Transformer-based LLMs excel
at capturing long-range dependencies but are weak at modeling short-term
anomalies in time-series data. Hence, we propose a plugin module embedded
within self-attention that models long-term and short-term dependencies to
effectively adapt LLMs to time-series analysis. Our approach freezes the LLM
and reduces the sequence dimensionality of tokens, greatly reducing
computational consumption. Experiments demonstrate the superiority performance
of our SE-LLM against the state-of-the-art (SOTA) methods.

</details>


### [430] [Energy Consumption in Parallel Neural Network Training](https://arxiv.org/abs/2508.07706)
*Philipp Huber,David Li,Juan Pedro Gutiérrez Hermosillo Muriedas,Deifilia Kieckhefen,Markus Götz,Achim Streit,Charlotte Debus*

Main category: cs.LG

TL;DR: 该研究通过扩展实验，调查了并行化对训练神经网络的能源消耗的影响，发现在能源消耗与 GPU 小时之间存在近似线性的关系，但具体关系因模型和硬件而异。


<details>
  <summary>Details</summary>
Motivation: 文章旨在解决训练神经网络日益增长的计算资源需求所带来的令人担忧的能源消耗增长问题，并解决在扩展模型和数据集大小以及加速训练方面，并行化对能源消耗的影响被忽视的研究空白。

Method: 通过运行扩展实验，重点关注数据并行训练，并评估了 GPU 数量、全局批次大小和局部批次大小等并行化参数对预测性能、训练时间和能源消耗的影响。

Result: 研究表明，能源消耗与所消耗的资源（即 GPU 小时）大致呈线性增长；但是，每个 GPU 小时的样本和梯度更新的数量会系统地影响各自的增长因子，而这在不同的模型训练和硬件之间存在显著差异。

Conclusion: 该研究揭示了扩展神经网络训练与实现更可持续的人工智能研究之间复杂而微妙的相互作用，其结果可为未来的发展提供信息。

Abstract: The increasing demand for computational resources of training neural networks
leads to a concerning growth in energy consumption. While parallelization has
enabled upscaling model and dataset sizes and accelerated training, its impact
on energy consumption is often overlooked. To close this research gap, we
conducted scaling experiments for data-parallel training of two models,
ResNet50 and FourCastNet, and evaluated the impact of parallelization
parameters, i.e., GPU count, global batch size, and local batch size, on
predictive performance, training time, and energy consumption. We show that
energy consumption scales approximately linearly with the consumed resources,
i.e., GPU hours; however, the respective scaling factor differs substantially
between distinct model trainings and hardware, and is systematically influenced
by the number of samples and gradient updates per GPU hour. Our results shed
light on the complex interplay of scaling up neural network training and can
inform future developments towards more sustainable AI research.

</details>


### [431] [Training-Free ANN-to-SNN Conversion for High-Performance Spiking Transformer](https://arxiv.org/abs/2508.07710)
*Jingya Wang,Xin Deng,Wenjie Wei,Dehao Zhang,Shuai Wang,Qian Sun,Jieyuan Zhang,Hanwen Liu,Ning Xie,Malu Zhang*

Main category: cs.LG

TL;DR: 提出了一种名为MBE的新型神经元，用于无需训练的ANN到SNN转换，可高效处理Transformer中的非线性操作，实现高精度和低延迟。


<details>
  <summary>Details</summary>
Motivation: 现有ANN到SNN转换方法在处理Transformer架构中的非线性操作和对预训练ANN进行微调方面存在局限性，训练成本高。

Method: 提出了一种无需训练的ANN到SNN转换框架，并引入了多基指数衰减（MBE）神经元，该神经元采用指数衰减策略和多基编码方法来近似非线性操作，无需对预训练ANN的权重进行修改。

Result: 在CV、NLU、NLG等多种任务和主流Transformer架构（ViT、RoBERTa、GPT-2）上的广泛实验证明，该方法实现了近乎无损的转换精度和显著降低的延迟。

Conclusion: 本研究提出的无需训练的、针对Transformer架构的ANN到SNN转换框架，能够以近乎无损的精度和显著降低的延迟，有效地处理Transformer中的非线性操作，为现实世界中Spiking Transformer的高效和可扩展部署提供了有前景的途径。

Abstract: Leveraging the event-driven paradigm, Spiking Neural Networks (SNNs) offer a
promising approach for constructing energy-efficient Transformer architectures.
Compared to directly trained Spiking Transformers, ANN-to-SNN conversion
methods bypass the high training costs. However, existing methods still suffer
from notable limitations, failing to effectively handle nonlinear operations in
Transformer architectures and requiring additional fine-tuning processes for
pre-trained ANNs. To address these issues, we propose a high-performance and
training-free ANN-to-SNN conversion framework tailored for Transformer
architectures. Specifically, we introduce a Multi-basis Exponential Decay (MBE)
neuron, which employs an exponential decay strategy and multi-basis encoding
method to efficiently approximate various nonlinear operations. It removes the
requirement for weight modifications in pre-trained ANNs. Extensive experiments
across diverse tasks (CV, NLU, NLG) and mainstream Transformer architectures
(ViT, RoBERTa, GPT-2) demonstrate that our method achieves near-lossless
conversion accuracy with significantly lower latency. This provides a promising
pathway for the efficient and scalable deployment of Spiking Transformers in
real-world applications.

</details>


### [432] [Detecting Mislabeled and Corrupted Data via Pointwise Mutual Information](https://arxiv.org/abs/2508.07713)
*Jinghan Yang,Jiayu Weng*

Main category: cs.LG

TL;DR: 提出一种基于互信息的数据选择框架，用于在混合噪声（标签噪声和输入噪声）场景下选择高质量数据。该方法通过计算样本对互信息的贡献度来识别噪声样本，并在实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络容易记住损坏的标签，导致数据质量对模型性能至关重要，但现实世界的数据集经常同时存在标签噪声和输入噪声。

Method: 提出了一种基于互信息的数据选择框架，该框架量化了输入和标签之间的统计依赖性。通过计算每个样本对整体互信息的贡献度，认为贡献度较低的样本是噪声或错误标签的样本。

Result: 在MNIST数据集上进行了不同合成噪声设置下的经验验证，结果表明该方法能有效过滤低质量样本。

Conclusion: 该方法能够有效过滤低质量样本，并且在标签损坏的情况下，训练高质量样本的分类精度相较于随机采样最高可提升15%。该方法对良性输入修改具有鲁棒性，能够保留语义有效的而数据，同时过滤掉真正损坏的样本。

Abstract: Deep neural networks can memorize corrupted labels, making data quality
critical for model performance, yet real-world datasets are frequently
compromised by both label noise and input noise. This paper proposes a mutual
information-based framework for data selection under hybrid noise scenarios
that quantifies statistical dependencies between inputs and labels. We compute
each sample's pointwise contribution to the overall mutual information and find
that lower contributions indicate noisy or mislabeled instances. Empirical
validation on MNIST with different synthetic noise settings demonstrates that
the method effectively filters low-quality samples. Under label corruption,
training on high-MI samples improves classification accuracy by up to 15\%
compared to random sampling. Furthermore, the method exhibits robustness to
benign input modifications, preserving semantically valid data while filtering
truly corrupted samples.

</details>


### [433] [Separation and Collaboration: Two-Level Routing Grouped Mixture-of-Experts for Multi-Domain Continual Learning](https://arxiv.org/abs/2508.07738)
*Jialu Zhou,Dianxi Shi,Shaowu Yang,Xinyu Wei,Mingyue Yang,Leqian Li,Mengzhu Wang,Chunping Qiu*

Main category: cs.LG

TL;DR: TRGE是一种新的多域持续学习方法，通过创新的路由机制和多模态大语言模型，有效解决了灾难性遗忘和前向遗忘问题，并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 参数高效微调（PEFT）方法在多域持续学习（MDCL）中虽然能适应类别和分布的变化，但仍存在灾难性遗忘和前向遗忘的问题。

Method: TRGE方法包括：1.动态扩展预训练CLIP模型，为每个任务分配特定的专家组以减轻灾难性遗忘，通过组内路由器缓解路由过拟合，并基于任务标识符和原型距离设计组间路由策略以增强任务协作。2.利用MLLM生成语义任务描述并识别正确的任务标识符。3.通过动态融合冻结CLIP模型和TRGE适配器的输出来缓解前向遗忘。

Result: TRGE方法在各种设置的广泛实验中，以更少的训练参数取得了优于其他先进方法的性能。

Conclusion: TRGE通过动态扩展预训练CLIP模型、引入组内和组间路由策略以及利用MLLM生成任务描述来解决MDCL中的灾难性遗忘和前向遗忘问题，同时通过动态融合预训练和适配器知识来增强对未见样本的处理，在减少可训练参数的同时取得了优于其他先进方法的性能。

Abstract: Multi-Domain Continual Learning (MDCL) acquires knowledge from sequential
tasks with shifting class sets and distribution. Despite the
Parameter-Efficient Fine-Tuning (PEFT) methods can adapt for this dual
heterogeneity, they still suffer from catastrophic forgetting and forward
forgetting. To address these challenges, we propose a Two-Level Routing Grouped
Mixture-of-Experts (TRGE) method. Firstly, TRGE dynamically expands the
pre-trained CLIP model, assigning specific expert group for each task to
mitigate catastrophic forgetting. With the number of experts continually grows
in this process, TRGE maintains the static experts count within the group and
introduces the intra-group router to alleviate routing overfitting caused by
the increasing routing complexity. Meanwhile, we design an inter-group routing
policy based on task identifiers and task prototype distance, which dynamically
selects relevant expert groups and combines their outputs to enhance inter-task
collaboration. Secondly, to get the correct task identifiers, we leverage
Multimodal Large Language Models (MLLMs) which own powerful multimodal
comprehension capabilities to generate semantic task descriptions and recognize
the correct task identifier. Finally, to mitigate forward forgetting, we
dynamically fuse outputs for unseen samples from the frozen CLIP model and TRGE
adapter based on training progress, leveraging both pre-trained and learned
knowledge. Through extensive experiments across various settings, our method
outperforms other advanced methods with fewer trainable parameters.

</details>


### [434] [A Tutorial: An Intuitive Explanation of Offline Reinforcement Learning Theory](https://arxiv.org/abs/2508.07746)
*Fengdi Che*

Main category: cs.LG

TL;DR: 离线 RL 的理论和实践之间的差距仍然存在。本研究回顾了理论见解，如函数表示和数据覆盖假设，并讨论了它们如何影响算法设计，同时强调了离线 RL 的局限性。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习（RL）旨在在没有与环境进行额外交互的情况下，利用固定数据集优化回报。

Method: 本文首先列出了证明所需的条件，包括函数表示和数据覆盖假设。然后，我们检查反例，其中离线 RL 在没有大量数据的情况下是无法解决的。基于解决这些挑战的技术，我们讨论了离线 RL 的充分条件。

Result: 研究了理论见解对离线 RL 算法的影响，强调了函数表示和数据覆盖假设的重要性，并讨论了离线 RL 的固有难度以及在无法满足条件时寻找新颖解决方案的必要性。

Conclusion: 将理论见解与实际算法设计相结合仍然是一个持续的挑战，本文探讨了从理论工作中获得的 Kxf 见解及其对离线 RL 算法的影响。

Abstract: Offline reinforcement learning (RL) aims to optimize the return given a fixed
dataset of agent trajectories without additional interactions with the
environment. While algorithm development has progressed rapidly, significant
theoretical advances have also been made in understanding the fundamental
challenges of offline RL. However, bridging these theoretical insights with
practical algorithm design remains an ongoing challenge. In this survey, we
explore key intuitions derived from theoretical work and their implications for
offline RL algorithms.
  We begin by listing the conditions needed for the proofs, including function
representation and data coverage assumptions. Function representation
conditions tell us what to expect for generalization, and data coverage
assumptions describe the quality requirement of the data. We then examine
counterexamples, where offline RL is not solvable without an impractically
large amount of data. These cases highlight what cannot be achieved for all
algorithms and the inherent hardness of offline RL. Building on techniques to
mitigate these challenges, we discuss the conditions that are sufficient for
offline RL. These conditions are not merely assumptions for theoretical proofs,
but they also reveal the limitations of these algorithms and remind us to
search for novel solutions when the conditions cannot be satisfied.

</details>


### [435] [Learning to Align, Aligning to Learn: A Unified Approach for Self-Optimized Alignment](https://arxiv.org/abs/2508.07750)
*Haowen Wang,Yun Yue,Zhiling Ye,Shuowen Zhang,Lei Fan,Jiaxin Liang,Jiadi Jiang,Cheng Wei,Jingyuan Deng,Xudong Han,Ji Li,Chunxiao Guo,Peng Wei,Jian Wang,Jinjie Gu*

Main category: cs.LG

TL;DR: GRAO是一个统一的框架，结合了SFT和RL的优点，通过多样本生成、组直接对齐损失和参考感知参数更新来优化语言模型对齐，提高了样本效率和性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决SFT的离线策略轨迹限制和RL的低样本效率及对高质量基础模型的严格依赖性这两个挑战，提出GRAO框架。

Method: GRAO通过以下三个关键创新，结合了SFT和RL的优点：1）多样本生成策略，通过奖励反馈进行比较质量评估；2）利用组内相对优势加权的新颖的组直接对齐损失公式；3）由成对偏好动态指导的参考感知参数更新。

Result: GRAO在复杂的对齐任务中展现出优越的性能，实现了相对于SFT、DPO、PPO和GRPO基线57.70%、17.65%、7.95%和5.18%的相对改进。

Conclusion: GRAO是一个理论可靠且能提升语言模型能力进化的经验性工作，它在复杂的人类对齐任务中取得了优于SFT、DPO、PPO和GRPO基线57.70%、17.65%、7.95%和5.18%的相对改进。

Abstract: Alignment methodologies have emerged as a critical pathway for enhancing
language model alignment capabilities. While SFT (supervised fine-tuning)
accelerates convergence through direct token-level loss intervention, its
efficacy is constrained by offline policy trajectory. In contrast,
RL(reinforcement learning) facilitates exploratory policy optimization, but
suffers from low sample efficiency and stringent dependency on high-quality
base models. To address these dual challenges, we propose GRAO (Group Relative
Alignment Optimization), a unified framework that synergizes the respective
strengths of SFT and RL through three key innovations: 1) A multi-sample
generation strategy enabling comparative quality assessment via reward
feedback; 2) A novel Group Direct Alignment Loss formulation leveraging
intra-group relative advantage weighting; 3) Reference-aware parameter updates
guided by pairwise preference dynamics. Our theoretical analysis establishes
GRAO's convergence guarantees and sample efficiency advantages over
conventional approaches. Comprehensive evaluations across complex human
alignment tasks demonstrate GRAO's superior performance, achieving
57.70\%,17.65\% 7.95\% and 5.18\% relative improvements over SFT, DPO, PPO and
GRPO baselines respectively. This work provides both a theoretically grounded
alignment framework and empirical evidence for efficient capability evolution
in language models.

</details>


### [436] [Sparse Probabilistic Graph Circuits](https://arxiv.org/abs/2508.07763)
*Martin Rektoris,Milan Papež,Václav Šmídl,Tomáš Pevný*

Main category: cs.LG

TL;DR: New Sparse PGCs (SPGCs) model graphs efficiently with O(n+m) complexity, offering exact inference and matching DGMs performance in drug design.


<details>
  <summary>Details</summary>
Motivation: Existing Probabilistic Graph Circuits (PGCs) have a complexity of O(n^2) for graphs with n nodes, which is not scalable. DGMs are intractable for probabilistic inference queries.

Method: Introduced Sparse PGCs (SPGCs), a new class of tractable generative models that operate directly on sparse graph representations.

Result: SPGCs reduce complexity to O(n + m), improve memory efficiency and inference speed, and match the performance of intractable DGMs in key metrics for de novo drug design.

Conclusion: Sparse PGCs (SPGCs) are a new class of tractable generative models that operate directly on sparse graph representations, reducing complexity to O(n + m). SPGCs retain exact inference capabilities, improve memory efficiency and inference speed, and match the performance of intractable DGMs in key metrics in de novo drug design.

Abstract: Deep generative models (DGMs) for graphs achieve impressively high expressive
power thanks to very efficient and scalable neural networks. However, these
networks contain non-linearities that prevent analytical computation of many
standard probabilistic inference queries, i.e., these DGMs are considered
\emph{intractable}. While recently proposed Probabilistic Graph Circuits (PGCs)
address this issue by enabling \emph{tractable} probabilistic inference, they
operate on dense graph representations with $\mathcal{O}(n^2)$ complexity for
graphs with $n$ nodes and \emph{$m$ edges}. To address this scalability issue,
we introduce Sparse PGCs, a new class of tractable generative models that
operate directly on sparse graph representation, reducing the complexity to
$\mathcal{O}(n + m)$, which is particularly beneficial for $m \ll n^2$. In the
context of de novo drug design, we empirically demonstrate that SPGCs retain
exact inference capabilities, improve memory efficiency and inference speed,
and match the performance of intractable DGMs in key metrics.

</details>


### [437] [Pareto Multi-Objective Alignment for Language Models](https://arxiv.org/abs/2508.07768)
*Qiang He,Setareh Maghsudi*

Main category: cs.LG

TL;DR: PAMA 是一种高效的多目标对齐算法，可解决 LLM 中的复杂偏好问题，相比之下，它比传统方法更具可扩展性和更快的速度。


<details>
  <summary>Details</summary>
Motivation: 现有的对齐方法（主要是基于 RLHF）将 LLM 优化为单一奖励函数，导致行为僵化，无法捕捉人类偏好的复杂性和多样性。这种局限性阻碍了 LLM 在实际场景中的适应性，因此，多目标对齐（MOA）成为一个关键但探索不足的领域。

Method: PAMA 将多目标强化学习（RLHF）转化为具有封闭形式解的凸优化问题，将传统多目标优化（MOO）的 O(n^2*d) 复杂性降低到 O(n)，其中 n 是目标数量，d 是模型参数数量。

Result: PAMA 具有可扩展性，可以在几毫秒内完成优化，并有理论保证收敛到帕累托稳定点。在不同大小（1.25 亿到 70 亿参数）的语言模型上的大量实验证明了 PAMA 稳健而有效的 MOA 能力。

Conclusion: PAMA 提供了一个高效且经过理论验证的解决方案，解决了以前被认为难以处理的多目标对齐问题，为将 LLM 与多样化的人类价值观对齐提供了一种实用且有理论依据的方法，从而为通用和适应性强的实际人工智能部署铺平了道路。

Abstract: Large language models (LLMs) are increasingly deployed in real-world
applications that require careful balancing of multiple, often conflicting,
objectives, such as informativeness versus conciseness, or helpfulness versus
creativity. However, current alignment methods, primarily based on RLHF,
optimize LLMs toward a single reward function, resulting in rigid behavior that
fails to capture the complexity and diversity of human preferences. This
limitation hinders the adaptability of LLMs to practical scenarios, making
multi-objective alignment (MOA) a critical yet underexplored area. To bridge
this gap, we propose Pareto Multi-Objective Alignment (PAMA), a principled and
computationally efficient algorithm designed explicitly for MOA in LLMs. In
contrast to computationally prohibitive multi-objective optimization (MOO)
methods, PAMA transforms multi-objective RLHF into a convex optimization with a
closed-form solution, significantly enhancing scalability. Traditional MOO
approaches suffer from prohibitive O(n^2*d) complexity, where d represents the
number of model parameters, typically in the billions for LLMs, rendering
direct optimization infeasible. PAMA reduces this complexity to O(n) where n is
the number of objectives, enabling optimization to be completed within
milliseconds. We provide theoretical guarantees that PAMA converges to a Pareto
stationary point, where no objective can be improved without degrading at least
one other. Extensive experiments across language models ranging from 125M to 7B
parameters demonstrate PAMA's robust and effective MOA capabilities, aligning
with its theoretical advantages. PAMA provides a highly efficient solution to
the MOA problem that was previously considered intractable, offering a
practical and theoretically grounded approach to aligning LLMs with diverse
human values, paving the way for versatile and adaptable real-world AI
deployments.

</details>


### [438] [Topological Feature Compression for Molecular Graph Neural Networks](https://arxiv.org/abs/2508.07807)
*Rahul Khorana*

Main category: cs.LG

TL;DR: A new GNN model combines topological signals and molecular features to improve chemical insight extraction, achieving top accuracy and robustness on various datasets.


<details>
  <summary>Details</summary>
Motivation: Extracting general chemical insight while balancing predictive accuracy, interpretability, and computational efficiency remains a challenge in molecular representation learning.

Method: A novel Graph Neural Network (GNN) architecture that combines compressed higher-order topological signals with standard molecular features.

Result: Superior performance in accuracy and robustness across small-molecule and complex material datasets using a parameter-efficient architecture.

Conclusion: The novel GNN architecture achieves superior performance in accuracy and robustness across various benchmarks due to its ability to capture global geometric information while maintaining computational tractability and human-interpretability.

Abstract: Recent advances in molecular representation learning have produced highly
effective encodings of molecules for numerous cheminformatics and
bioinformatics tasks. However, extracting general chemical insight while
balancing predictive accuracy, interpretability, and computational efficiency
remains a major challenge. In this work, we introduce a novel Graph Neural
Network (GNN) architecture that combines compressed higher-order topological
signals with standard molecular features. Our approach captures global
geometric information while preserving computational tractability and
human-interpretable structure. We evaluate our model across a range of
benchmarks, from small-molecule datasets to complex material datasets, and
demonstrate superior performance using a parameter-efficient architecture. We
achieve the best performing results in both accuracy and robustness across
almost all benchmarks. We open source all code \footnote{All code and results
can be found on Github https://github.com/rahulkhorana/TFC-PACT-Net}.

</details>


### [439] [From Source to Target: Leveraging Transfer Learning for Predictive Process Monitoring in Organizations](https://arxiv.org/abs/2508.08061)
*Sven Weinzierl,Sandra Zilker,Annina Liessmann,Martin Käppel,Weixin Wang,Martin Matzner*

Main category: cs.LG

TL;DR: 本研究提出了一种基于迁移学习的预测性流程监控技术，解决了现有技术对数据资源的要求，实现了跨组织的数据转移和应用。


<details>
  <summary>Details</summary>
Motivation: 现有的预测性流程监控技术需要大量的事件数据或其他相关资源，这可能无法满足所有组织的需求。

Method: 提出了一种基于迁移学习的预测性流程监控技术。

Result: 实验表明，一个业务流程的知识可以转移到相同或不同组织中的类似业务流程，以实现有效的预测性流程监控。

Conclusion: 知识可以跨组织边界转移，以实现目标环境中有效的预测性流程监控。

Abstract: Event logs reflect the behavior of business processes that are mapped in
organizational information systems. Predictive process monitoring (PPM)
transforms these data into value by creating process-related predictions that
provide the insights required for proactive interventions at process runtime.
Existing PPM techniques require sufficient amounts of event data or other
relevant resources that might not be readily available, preventing some
organizations from utilizing PPM. The transfer learning-based PPM technique
presented in this paper allows organizations without suitable event data or
other relevant resources to implement PPM for effective decision support. The
technique is instantiated in two real-life use cases, based on which numerical
experiments are performed using event logs for IT service management processes
in an intra- and inter-organizational setting. The results of the experiments
suggest that knowledge of one business process can be transferred to a similar
business process in the same or a different organization to enable effective
PPM in the target context. With the proposed technique, organizations can
benefit from transfer learning in an intra- and inter-organizational setting,
where resources like pre-trained models are transferred within and across
organizational boundaries.

</details>


### [440] [EvoCoT: Overcoming the Exploration Bottleneck in Reinforcement Learning](https://arxiv.org/abs/2508.07809)
*Huanyu Liu,Jia Li,Chang Yu,Taozhi Chen,Yihong Dong,Lecheng Wang,Hu XiaoLong,Ge Li*

Main category: cs.LG

TL;DR: EvoCoT is a new framework that helps LLMs learn to solve harder problems by evolving their reasoning process, overcoming limitations of existing methods.


<details>
  <summary>Details</summary>
Motivation: Reinforcement learning with verifiable reward (RLVR) is promising for improving LLM reasoning, but suffers from sparse rewards on hard problems, limiting learning efficiency and causing exploration bottlenecks. Existing methods have scalability limitations or restrict reasoning improvement.

Method: EvoCoT is a self-evolving curriculum learning framework based on two-stage chain-of-thought (CoT) reasoning optimization. It constrains the exploration space by self-generating and verifying CoT trajectories, then gradually shortens them to expand the space in a controlled way.

Result: Experiments show that EvoCoT enables LLMs to solve previously unsolved problems and improves reasoning capability without external CoT supervision. It is compatible with various RL fine-tuning methods and has been applied to Qwen, DeepSeek, and Llama families.

Conclusion: EvoCoT enables LLMs to solve previously unsolved problems, improves reasoning capability without external CoT supervision, and is compatible with various RL fine-tuning methods.

Abstract: Reinforcement learning with verifiable reward (RLVR) has become a promising
paradigm for post-training large language models (LLMs) to improve their
reasoning capability. However, when the rollout accuracy is low on hard
problems, the reward becomes sparse, limiting learning efficiency and causing
exploration bottlenecks. Existing approaches either rely on stronger LLMs for
distillation or filter out difficult problems, which limits scalability or
restricts reasoning improvement through exploration.
  We propose EvoCoT, a self-evolving curriculum learning framework based on
two-stage chain-of-thought (CoT) reasoning optimization. EvoCoT constrains the
exploration space by self-generating and verifying CoT trajectories, then
gradually shortens them to expand the space in a controlled way. This enables
LLMs to stably learn from initially unsolved hard problems under sparse
rewards. We apply EvoCoT to multiple LLM families, including Qwen, DeepSeek,
and Llama. Experiments show that EvoCoT enables LLMs to solve previously
unsolved problems, improves reasoning capability without external CoT
supervision, and is compatible with various RL fine-tuning methods. We release
the source code to support future research.

</details>


### [441] [Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning](https://arxiv.org/abs/2508.08221)
*Zihe Liu,Jiashun Liu,Yancheng He,Weixun Wang,Jiaheng Liu,Ling Pan,Xinyu Hu,Shaopan Xiong,Ju Huang,Jian Hu,Shengyi Huang,Siran Yang,Jiamang Wang,Wenbo Su,Bo Zheng*

Main category: cs.LG

TL;DR: 该论文通过统一框架复现和评估RL技术在LLM中的应用，为实践者提供了选择指南和路线图，并发现简化的PPO策略组合优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 鉴于RL在LLM推理中的应用研究激增，但仍存在缺乏标准化指南、机制理解碎片化、实验设置不一致等挑战，导致实践者难以选择合适的技术。

Method: 通过严格复现和隔离评估，在统一的开源框架内系统性地回顾了广泛采用的RL技术。通过细致的实验，包括不同难度的数据集、模型大小和架构，分析了每种技术的内部机制、适用场景和核心原理。

Result: 通过细粒度实验，分析了不同RL技术的内部机制、适用场景和核心原理，并提供了选择RL技术的明确指南和可靠路线图。结果显示，一种简化的、仅包含两种技术的组合策略，利用标准的PPO损失，能够解锁无判别器策略的学习能力，并且其性能持续优于GRPO和DAPO等策略。

Conclusion: 该研究提出了一个包含RL技术、实验设置和模型细节的统一框架，旨在为RL在LLM中的应用提供清晰的指南和可靠的路线图。研究结果表明，一种简化的PPO策略组合能够提升性能，优于GRPO和DAPO等策略。

Abstract: Reinforcement learning for LLM reasoning has rapidly emerged as a prominent
research area, marked by a significant surge in related studies on both
algorithmic innovations and practical applications. Despite this progress,
several critical challenges remain, including the absence of standardized
guidelines for employing RL techniques and a fragmented understanding of their
underlying mechanisms. Additionally, inconsistent experimental settings,
variations in training data, and differences in model initialization have led
to conflicting conclusions, obscuring the key characteristics of these
techniques and creating confusion among practitioners when selecting
appropriate techniques. This paper systematically reviews widely adopted RL
techniques through rigorous reproductions and isolated evaluations within a
unified open-source framework. We analyze the internal mechanisms, applicable
scenarios, and core principles of each technique through fine-grained
experiments, including datasets of varying difficulty, model sizes, and
architectures. Based on these insights, we present clear guidelines for
selecting RL techniques tailored to specific setups, and provide a reliable
roadmap for practitioners navigating the RL for the LLM domain. Finally, we
reveal that a minimalist combination of two techniques can unlock the learning
capability of critic-free policies using vanilla PPO loss. The results
demonstrate that our simple combination consistently improves performance,
surpassing strategies like GRPO and DAPO.

</details>


### [442] [Not Yet AlphaFold for the Mind: Evaluating Centaur as a Synthetic Participant](https://arxiv.org/abs/2508.07887)
*Sabrina Namazova,Alessandra Brondetta,Younes Strittmatter,Matthew Nassar,Sebastian Musslick*

Main category: cs.LG

TL;DR: Centaur LLM shows promise in predicting behavior but doesn't yet simulate human participants reliably due to behavioral deviations.


<details>
  <summary>Details</summary>
Motivation: To evaluate the potential of the Centaur LLM as a human participant simulator in the behavioral sciences, analogous to the impact of simulators like AlphaFold in chemistry.

Method: Review and assessment of the Centaur LLM against core criteria for a participant simulator.

Result: Centaur demonstrates high predictive accuracy but its generative behavior systematically diverges from human data, indicating it is not yet a reliable participant simulator or accurate cognitive model.

Conclusion: Centaur LLM, despite strong predictive accuracy, shows systematic divergence in generative behavior from human data, failing to meet the standards of a reliable participant simulator or accurate cognitive model.

Abstract: Simulators have revolutionized scientific practice across the natural
sciences. By generating data that reliably approximate real-world phenomena,
they enable scientists to accelerate hypothesis testing and optimize
experimental designs. This is perhaps best illustrated by AlphaFold, a
Nobel-prize winning simulator in chemistry that predicts protein structures
from amino acid sequences, enabling rapid prototyping of molecular
interactions, drug targets, and protein functions. In the behavioral sciences,
a reliable participant simulator - a system capable of producing human-like
behavior across cognitive tasks - would represent a similarly transformative
advance. Recently, Binz et al. introduced Centaur, a large language model (LLM)
fine-tuned on human data from 160 experiments, proposing its use not only as a
model of cognition but also as a participant simulator for "in silico
prototyping of experimental studies", e.g., to advance automated cognitive
science. Here, we review the core criteria for a participant simulator and
assess how well Centaur meets them. Although Centaur demonstrates strong
predictive accuracy, its generative behavior - a critical criterion for a
participant simulator - systematically diverges from human data. This suggests
that, while Centaur is a significant step toward predicting human behavior, it
does not yet meet the standards of a reliable participant simulator or an
accurate model of cognition.

</details>


### [443] [Score Augmentation for Diffusion Models](https://arxiv.org/abs/2508.07926)
*Liang Hou,Yuan Gao,Boyuan Jiang,Xin Tao,Qi Yan,Renjie Liao,Pengfei Wan,Di Zhang,Kun Gai*

Main category: cs.LG

TL;DR: Diffusion models can overfit, especially with limited data. ScoreAug is a new method that augments noisy data and helps models learn better, improving performance and reducing overfitting.


<details>
  <summary>Details</summary>
Motivation: To address the overfitting issue in diffusion model training, particularly in data-limited regimes.

Method: ScoreAug, a novel data augmentation framework that applies transformations to noisy data and requires the denoiser to predict the augmentation of the original target, establishing an equivariant learning objective.

Result: ScoreAug demonstrates significant performance improvements over baselines on CIFAR-10, FFHQ, AFHQv2, and ImageNet, effectively mitigates overfitting, exhibits stable convergence, and can circumvent data leakage issues.

Conclusion: ScoreAug can effectively mitigate overfitting in diffusion models, improve performance across various benchmarks, and can be combined with traditional data augmentation techniques for further gains.

Abstract: Diffusion models have achieved remarkable success in generative modeling.
However, this study confirms the existence of overfitting in diffusion model
training, particularly in data-limited regimes. To address this challenge, we
propose Score Augmentation (ScoreAug), a novel data augmentation framework
specifically designed for diffusion models. Unlike conventional augmentation
approaches that operate on clean data, ScoreAug applies transformations to
noisy data, aligning with the inherent denoising mechanism of diffusion.
Crucially, ScoreAug further requires the denoiser to predict the augmentation
of the original target. This design establishes an equivariant learning
objective, enabling the denoiser to learn scores across varied denoising
spaces, thereby realizing what we term score augmentation. We also
theoretically analyze the relationship between scores in different spaces under
general transformations. In experiments, we extensively validate ScoreAug on
multiple benchmarks including CIFAR-10, FFHQ, AFHQv2, and ImageNet, with
results demonstrating significant performance improvements over baselines.
Notably, ScoreAug effectively mitigates overfitting across diverse scenarios,
such as varying data scales and model capacities, while exhibiting stable
convergence properties. Another advantage of ScoreAug over standard data
augmentation lies in its ability to circumvent data leakage issues under
certain conditions. Furthermore, we show that ScoreAug can be synergistically
combined with traditional data augmentation techniques to achieve additional
performance gains.

</details>


### [444] [Adaptive Fine-Tuning via Pattern Specialization for Deep Time Series Forecasting](https://arxiv.org/abs/2508.07927)
*Amal Saadallah,Abdulaziz Al-Ademi*

Main category: cs.LG

TL;DR: 通过模型适应和选择来提高深度神经网络在非平稳时间序列预测中的性能。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测在非平稳环境中（即底层模式随时间演变）带来了重大挑战。

Method: 提出了一种新颖的框架，利用专门的模型适应和选择来增强深度神经网络（DNN）的性能。首先，在历史时间序列数据上离线训练基础DNN。然后，对保留的验证子集进行分割，提取并聚类序列中最主要的模式，从而识别出不同的状态。对每个识别出的集群，对基础DNN进行微调，生成能够捕获独特模式特征的专门版本。在推理时，将最近的输入与集群中心进行匹配，并根据最相似的度量标准部署相应的微调版本。此外，该方法集成了概念漂移检测机制，以识别和适应由非平稳行为引起的新兴模式。

Result: 所提出的框架通用性强，在传统DNN和GluonTS库中实现的先进架构上均展示出显著的性能提升。

Conclusion: 该框架通用性强，可适用于各种深度神经网络架构，并在GluonTS库中实现的传统和先进架构上均展示出显著的性能提升。

Abstract: Time series forecasting poses significant challenges in non-stationary
environments where underlying patterns evolve over time. In this work, we
propose a novel framework that enhances deep neural network (DNN) performance
by leveraging specialized model adaptation and selection. Initially, a base DNN
is trained offline on historical time series data. A reserved validation subset
is then segmented to extract and cluster the most dominant patterns within the
series, thereby identifying distinct regimes. For each identified cluster, the
base DNN is fine-tuned to produce a specialized version that captures unique
pattern characteristics. At inference, the most recent input is matched against
the cluster centroids, and the corresponding fine-tuned version is deployed
based on the closest similarity measure. Additionally, our approach integrates
a concept drift detection mechanism to identify and adapt to emerging patterns
caused by non-stationary behavior. The proposed framework is generalizable
across various DNN architectures and has demonstrated significant performance
gains on both traditional DNNs and recent advanced architectures implemented in
the GluonTS library.

</details>


### [445] [Shapley-Inspired Feature Weighting in $k$-means with No Additional Hyperparameters](https://arxiv.org/abs/2508.07952)
*Richard J. Fawley,Renato Cordeiro de Amorim*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Clustering algorithms often assume all features contribute equally to the
data structure, an assumption that usually fails in high-dimensional or noisy
settings. Feature weighting methods can address this, but most require
additional parameter tuning. We propose SHARK (Shapley Reweighted $k$-means), a
feature-weighted clustering algorithm motivated by the use of Shapley values
from cooperative game theory to quantify feature relevance, which requires no
additional parameters beyond those in $k$-means. We prove that the $k$-means
objective can be decomposed into a sum of per-feature Shapley values, providing
an axiomatic foundation for unsupervised feature relevance and reducing Shapley
computation from exponential to polynomial time. SHARK iteratively re-weights
features by the inverse of their Shapley contribution, emphasising informative
dimensions and down-weighting irrelevant ones. Experiments on synthetic and
real-world data sets show that SHARK consistently matches or outperforms
existing methods, achieving superior robustness and accuracy, particularly in
scenarios where noise may be present. Software:
https://github.com/rickfawley/shark.

</details>


### [446] [WeChat-YATT: A Simple, Scalable and Balanced RLHF Trainer](https://arxiv.org/abs/2508.07970)
*Junyu Wu,Weiming Chang,Xiaotao Liu,Guanyou He,Tingfeng Xian,Haoqiang Hong,Boqi Chen,Haotao Tian,Tao Yang,Yunsheng Shi,Feng Lin,Ting Yao*

Main category: cs.LG

TL;DR: WeChat-YATT是一个用于RLHF训练的新框架，它通过并行控制器和动态资源分配提高了可扩展性和效率，并在实际应用中得到了验证。


<details>
  <summary>Details</summary>
Motivation: 现有的RLHF训练框架在扩展到复杂的多模态工作流和适应动态工作负载方面存在挑战，特别是在管理大型模型和编排复杂的RLHF流水线时效率低下。

Method: 提出了一种名为WeChat-YATT的RLHF训练框架，采用了并行控制器编程模型和动态资源分配方案，以解决现有框架在可扩展性、复杂工作流编排和动态负载适应方面的挑战。

Result: WeChat-YATT在吞吐量方面相比最先进的RLHF训练框架取得了显著的改进。

Conclusion: WeChat-YATT框架在实际应用中成功部署，用于训练支持微信产品功能的模型，证明了其在真实世界应用中的有效性和鲁棒性。

Abstract: Reinforcement Learning from Human Feedback (RLHF) has emerged as a prominent
paradigm for training large language models and multimodal systems. Despite
notable advances enabled by existing RLHF training frameworks, significant
challenges remain in scaling to complex multimodal workflows and adapting to
dynamic workloads. In particular, current systems often encounter limitations
related to controller scalability when managing large models, as well as
inefficiencies in orchestrating intricate RLHF pipelines, especially in
scenarios that require dynamic sampling and resource allocation. In this paper,
we introduce WeChat-YATT (Yet Another Transformer Trainer in WeChat), a simple,
scalable, and balanced RLHF training framework specifically designed to address
these challenges. WeChat-YATT features a parallel controller programming model
that enables flexible and efficient orchestration of complex RLHF workflows,
effectively mitigating the bottlenecks associated with centralized controller
architectures and facilitating scalability in large-scale data scenarios. In
addition, we propose a dynamic placement schema that adaptively partitions
computational resources and schedules workloads, thereby significantly reducing
hardware idle time and improving GPU utilization under variable training
conditions. We evaluate WeChat-YATT across a range of experimental scenarios,
demonstrating that it achieves substantial improvements in throughput compared
to state-of-the-art RLHF training frameworks. Furthermore, WeChat-YATT has been
successfully deployed to train models supporting WeChat product features for a
large-scale user base, underscoring its effectiveness and robustness in
real-world applications.

</details>


### [447] [Learning to Select MCP Algorithms: From Traditional ML to Dual-Channel GAT-MLP](https://arxiv.org/abs/2508.08005)
*Xiang Li,Shanshan Wang,Chenglong Xiao*

Main category: cs.LG

TL;DR: 由于没有一种最大团问题（MCP）算法能在所有实例上表现最佳，因此需要根据实例特征选择合适的算法。本研究提出了一种结合图神经网络（GNN）和传统机器学习的学习框架（GAT-MLP），用于MCP算法选择，并在实验中取得了优异且稳定的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的最大团问题（MCP）算法在不同实例上表现不一，算法选择至关重要，但目前针对MCP的算法选择研究尚缺乏。本研究旨在弥补这一研究空白。

Method: 提出了一种结合传统机器学习和图神经网络（GNN）的学习框架。首先，使用SVM、RF、DT和KNN四种传统分类器进行评估，并发现随机森林（RF）表现稳定。随后，开发了一个名为GAT-MLP的双通道模型，结合了用于局部结构编码的图注意力网络（GAT）和用于全局特征建模的多层感知机（MLP）。

Result: GAT-MLP模型在所有指标上均表现出强大且一致的性能，证明了其在算法选择任务上的有效性。

Conclusion: 研究结果凸显了双通道架构的有效性以及图神经网络在组合算法选择方面的潜力。

Abstract: Extensive experiments and prior studies show that no single maximum clique
algorithm consistently performs best across all instances, highlighting the
importance of selecting suitable algorithms based on instance features. Through
an extensive analysis of relevant studies, it is found that there is a lack of
research work concerning algorithm selection oriented toward the Maximum Clique
Problem (MCP). In this work, we propose a learning-based framework that
integrates both traditional machine learning and graph neural networks to
address this gap. We construct a labeled dataset by running four exact MCP
algorithms on a diverse collection of graph instances, accompanied by
structural and global statistical features extracted from each graph. We first
evaluate four conventional classifiers: Support Vector Machine (SVM), Random
Forest (RF), Decision Tree (DT), and K-Nearest Neighbors (KNN), across multiple
dataset variants. Experimental results show that RF consistently shows strong
performance across metrics and dataset variants, making it a reliable baseline.
In addition, feature importance analysis indicates that connectivity and
topological structure are strong predictors of algorithm performance. Building
on these findings, we develop a dual-channel model named GAT-MLP, which
combines a Graph Attention Network (GAT) for local structural encoding with a
Multilayer Perceptron (MLP) for global feature modeling. The GAT-MLP model
shows strong and consistent performance across all metrics. Our results
highlight the effectiveness of dual-channel architectures and the promise of
graph neural networks in combinatorial algorithm selection.

</details>


### [448] [Communication-Efficient Zero-Order and First-Order Federated Learning Methods over Wireless Networks](https://arxiv.org/abs/2508.08013)
*Mohamad Assaad,Zeinab Nehme,Merouane Debbah*

Main category: cs.LG

TL;DR: 本文提出了两种通信高效的联邦学习方法，利用信道信息和异步设备来减少通信开销并优化学习算法。


<details>
  <summary>Details</summary>
Motivation: 为了解决联邦学习（FL）中由于设备与聚合器之间需要交换大量信息而导致的通信开销问题，该研究旨在减少通信开销。

Method: 本文提出两种通信高效的联邦学习方法：一种采用零阶优化技术和两点梯度估计，另一种涉及一阶梯度计算策略。这两种方法都利用了信道信息，并考虑了异步设备。

Result: 本文为两种方法提供了严格的分析框架，推导了收敛保证，并建立了适当的性能边界。

Conclusion: 本文提出了两种通信高效的联邦学习方法，通过通信标量值和允许用户同时发送信息来减少通信开销，并利用信道信息和异步设备来进一步优化学习算法。

Abstract: Federated Learning (FL) is an emerging learning framework that enables edge
devices to collaboratively train ML models without sharing their local data. FL
faces, however, a significant challenge due to the high amount of information
that must be exchanged between the devices and the aggregator in the training
phase, which can exceed the limited capacity of wireless systems. In this
paper, two communication-efficient FL methods are considered where
communication overhead is reduced by communicating scalar values instead of
long vectors and by allowing high number of users to send information
simultaneously. The first approach employs a zero-order optimization technique
with two-point gradient estimator, while the second involves a first-order
gradient computation strategy. The novelty lies in leveraging channel
information in the learning algorithms, eliminating hence the need for
additional resources to acquire channel state information (CSI) and to remove
its impact, as well as in considering asynchronous devices. We provide a
rigorous analytical framework for the two methods, deriving convergence
guarantees and establishing appropriate performance bounds.

</details>


### [449] [BadPromptFL: A Novel Backdoor Threat to Prompt-based Federated Learning in Multimodal Models](https://arxiv.org/abs/2508.08040)
*Maozhen Zhang,Mengnan Zhao,Bo Wang*

Main category: cs.LG

TL;DR: 本篇论文提出了一种名为BadPromptFL的后门攻击，专门针对联邦多模态学习中的提示微调技术。该攻击通过污染提示，能在不修改模型参数的情况下，实现对模型的后门控制，且攻击成功率高、隐蔽性强，对现有技术的安全性提出了严重警告。


<details>
  <summary>Details</summary>
Motivation: 提示微调作为一种轻量级的模型适配方式，已扩展到联邦学习设置中。然而，在联邦多模态学习中，基于提示聚合的安全含义尚未得到充分研究，存在关键的安全隐患。

Method: 提出了一种名为BadPromptFL的后门攻击方法，该方法利用了CLIP风格架构的上下文学习行为。受损客户端协同优化本地后门触发器和提示嵌入，将污染的提示注入全局聚合过程。

Result: BadPromptFL在多个数据集和聚合协议上进行了广泛的实验，证明了其高攻击成功率（例如，>90%），同时具有较低的可见性和有限的客户端参与。

Conclusion: 该研究揭示了基于提示的联邦学习在多模态对比学习中的安全漏洞，并提出了一种名为BadPromptFL的后门攻击方法。该方法通过在联邦学习过程中注入被污染的提示，可以在推理时实现通用的后门激活，且无需修改模型参数。实验证明了该攻击的有效性、隐蔽性和泛化能力，对基于提示的联邦学习的鲁棒性提出了严峻挑战。

Abstract: Prompt-based tuning has emerged as a lightweight alternative to full
fine-tuning in large vision-language models, enabling efficient adaptation via
learned contextual prompts. This paradigm has recently been extended to
federated learning settings (e.g., PromptFL), where clients collaboratively
train prompts under data privacy constraints. However, the security
implications of prompt-based aggregation in federated multimodal learning
remain largely unexplored, leaving a critical attack surface unaddressed. In
this paper, we introduce \textbf{BadPromptFL}, the first backdoor attack
targeting prompt-based federated learning in multimodal contrastive models. In
BadPromptFL, compromised clients jointly optimize local backdoor triggers and
prompt embeddings, injecting poisoned prompts into the global aggregation
process. These prompts are then propagated to benign clients, enabling
universal backdoor activation at inference without modifying model parameters.
Leveraging the contextual learning behavior of CLIP-style architectures,
BadPromptFL achieves high attack success rates (e.g., \(>90\%\)) with minimal
visibility and limited client participation. Extensive experiments across
multiple datasets and aggregation protocols validate the effectiveness,
stealth, and generalizability of our attack, raising critical concerns about
the robustness of prompt-based federated learning in real-world deployments.

</details>


### [450] [On Understanding of the Dynamics of Model Capacity in Continual Learning](https://arxiv.org/abs/2508.08052)
*Supriyo Chakraborty,Krishnan Raghavan*

Main category: cs.LG

TL;DR: 持续学习中，模型处理新任务的能力会因新旧任务分布不匹配而下降，此现象可用“有效模型容量”（CLEMC）量化，且该容量非固定不变。


<details>
  <summary>Details</summary>
Motivation: 研究核心在于解决持续学习中的稳定性-可塑性困境，并提出“有效模型容量”（CLEMC）来量化稳定性-可塑性平衡点动态行为。

Method: 利用协方差分析和格兰杰因果检验方法，证明了不同任务分布导致的能力下降效应。

Result: 提出了“有效模型容量”（CLEMC）的概念，并推导出差分方程来模拟神经网络、任务数据和优化过程之间的相互作用演变。实验结果支持了理论发现，表明有效容量和稳定性-可塑性平衡点本质上是非固定的，并且任务分布的变化会影响模型的学习能力。

Conclusion: 该研究表明，无论神经网络架构或优化方法如何，当输入任务分布与先前任务不同时，神经网络表示新任务的能力会下降。

Abstract: The stability-plasticity dilemma, closely related to a neural network's (NN)
capacity-its ability to represent tasks-is a fundamental challenge in continual
learning (CL). Within this context, we introduce CL's effective model capacity
(CLEMC) that characterizes the dynamic behavior of the stability-plasticity
balance point. We develop a difference equation to model the evolution of the
interplay between the NN, task data, and optimization procedure. We then
leverage CLEMC to demonstrate that the effective capacity-and, by extension,
the stability-plasticity balance point is inherently non-stationary. We show
that regardless of the NN architecture or optimization method, a NN's ability
to represent new tasks diminishes when incoming task distributions differ from
previous ones. We conduct extensive experiments to support our theoretical
findings, spanning a range of architectures-from small feedforward network and
convolutional networks to medium-sized graph neural networks and
transformer-based large language models with millions of parameters.

</details>


### [451] [C-MAG: Cascade Multimodal Attributed Graphs for Supply Chain Link Prediction](https://arxiv.org/abs/2508.08071)
*Yunqing Li,Zixiang Tang,Jiaying Zhuang,Zhenyu Yang,Farhad Ameri,Jianbang Zhang*

Main category: cs.LG

TL;DR: PMGraph是一个包含制造商、产品和产品图像的大型数据集。C-MAG是一个两阶段模型，利用文本和视觉信息来提高供应链中的链接预测准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的连接产品与制造商和供应商的方法难以处理现实世界中制造商档案所固有的复杂功能、认证、地理限制和丰富多模态数据，因此需要新的方法来解决这些差距。

Method: PMGraph是一个包含8,888个制造商，70,000多个产品，110,000多个制造商-产品边缘和29,000多个产品图像的公共数据集。C-MAG是一种两阶段架构，首先将文本和视觉属性对齐并聚合为中间组嵌入，然后通过多尺度消息传递在制造商-产品异构图上传播这些嵌入。

Result: PMGraph基准测试包含了大量的制造商、产品和制造商-产品关系，以及产品图像。C-MAG模型提高了链接预测的准确性。

Conclusion: C-MAG通过在文本和视觉属性上进行多尺度消息传递，以增强链接预测精度。

Abstract: Connecting an ever-expanding catalogue of products with suitable
manufacturers and suppliers is critical for resilient, efficient global supply
chains, yet traditional methods struggle to capture complex capabilities,
certifications, geographic constraints, and rich multimodal data of real-world
manufacturer profiles. To address these gaps, we introduce PMGraph, a public
benchmark of bipartite and heterogeneous multimodal supply-chain graphs linking
8,888 manufacturers, over 70k products, more than 110k manufacturer-product
edges, and over 29k product images. Building on this benchmark, we propose the
Cascade Multimodal Attributed Graph C-MAG, a two-stage architecture that first
aligns and aggregates textual and visual attributes into intermediate group
embeddings, then propagates them through a manufacturer-product hetero-graph
via multiscale message passing to enhance link prediction accuracy. C-MAG also
provides practical guidelines for modality-aware fusion, preserving predictive
performance in noisy, real-world settings.

</details>


### [452] [Fast and Generalizable parameter-embedded Neural Operators for Lithium-Ion Battery Simulation](https://arxiv.org/abs/2508.08087)
*Amir Ali Panahi,Daniel Luder,Billy Wu,Gregory Offer,Dirk Uwe Sauer,Weihan Li*

Main category: cs.LG

TL;DR: Operator learning models (DeepONets, FNOs, PE-FNO) were benchmarked for lithium-ion battery digital twins. PE-FNO achieved high speed (~200x faster than traditional solvers) and accuracy, enabling real-time applications and parameter estimation, outperforming other neural surrogates.


<details>
  <summary>Details</summary>
Motivation: Reliable digital twins of lithium-ion batteries require high physical fidelity with sub-millisecond speed, which current methods struggle to achieve.

Method: Benchmarking DeepONets, FNOs, and a parameter-embedded FNO (PE-FNO) for the Single Particle Model (SPM) of lithium-ion batteries, training on simulated trajectories across various current families and SOC levels. PE-FNO conditions spectral layers on particle radius and solid-phase diffusivity.

Result: DeepONet accurately replicated constant-current behavior but struggled with dynamic loads. Basic FNO maintained mesh invariance and kept concentration errors below 1%, with voltage mean-absolute errors under 1.7 mV across all load types. PE-FNO enabled generalization to varying radii and diffusivities, executing ~200 times faster than a traditional SPM solver. In parameter estimation tasks, PE-FNO recovered anode and cathode diffusivities with 1.14% and 8.4% mean absolute percentage error, respectively.

Conclusion: PE-FNO outperforms conventional neural surrogates, offering a practical path towards high-speed and high-fidelity electrochemical digital twins, meeting accuracy, speed, and parametric flexibility demands for real-time battery management, design-of-experiments, and large-scale inference.

Abstract: Reliable digital twins of lithium-ion batteries must achieve high physical
fidelity with sub-millisecond speed. In this work, we benchmark three
operator-learning surrogates for the Single Particle Model (SPM): Deep Operator
Networks (DeepONets), Fourier Neural Operators (FNOs) and a newly proposed
parameter-embedded Fourier Neural Operator (PE-FNO), which conditions each
spectral layer on particle radius and solid-phase diffusivity. Models are
trained on simulated trajectories spanning four current families (constant,
triangular, pulse-train, and Gaussian-random-field) and a full range of
State-of-Charge (SOC) (0 % to 100 %). DeepONet accurately replicates
constant-current behaviour but struggles with more dynamic loads. The basic FNO
maintains mesh invariance and keeps concentration errors below 1 %, with
voltage mean-absolute errors under 1.7 mV across all load types. Introducing
parameter embedding marginally increases error, but enables generalisation to
varying radii and diffusivities. PE-FNO executes approximately 200 times faster
than a 16-thread SPM solver. Consequently, PE-FNO's capabilities in inverse
tasks are explored in a parameter estimation task with Bayesian optimisation,
recovering anode and cathode diffusivities with 1.14 % and 8.4 % mean absolute
percentage error, respectively, and 0.5918 percentage points higher error in
comparison with classical methods. These results pave the way for neural
operators to meet the accuracy, speed and parametric flexibility demands of
real-time battery management, design-of-experiments and large-scale inference.
PE-FNO outperforms conventional neural surrogates, offering a practical path
towards high-speed and high-fidelity electrochemical digital twins.

</details>


### [453] [Grid2Guide: A* Enabled Small Language Model for Indoor Navigation](https://arxiv.org/abs/2508.08100)
*Md. Wasiul Haque,Sagar Dasgupta,Mizanur Rahman*

Main category: cs.LG

TL;DR: Grid2Guide是一个结合A*算法和小型语言模型的混合导航框架，能生成易于理解的室内导航指示，且无需外部信号或基础设施。


<details>
  <summary>Details</summary>
Motivation: 在缺乏外部定位信号和专用基础设施的复杂室内环境中，提供可靠的室内导航仍然是一个重大挑战。

Method: 该框架首先从室内地图生成二进制占用矩阵，然后利用A*算法计算最优路径并生成简洁的导航步骤。接着，利用SLM将这些步骤转换为自然语言指示，提高了可解释性。

Result: 实验评估表明，该方法在各种室内场景下都能生成准确、及时的导航指导，验证了该方法作为一种轻量级、无基础设施的实时室内导航支持解决方案的有效性。

Conclusion: 该研究提出了一种名为Grid2Guide的混合导航框架，结合了A*搜索算法和小型语言模型（SLM），能够为用户生成清晰、易于理解的路线导航指示。该方法无需外部定位信号或专用基础设施，是一种轻量级的解决方案，适用于实时室内导航。

Abstract: Reliable indoor navigation remains a significant challenge in complex
environments, particularly where external positioning signals and dedicated
infrastructures are unavailable. This research presents Grid2Guide, a hybrid
navigation framework that combines the A* search algorithm with a Small
Language Model (SLM) to generate clear, human-readable route instructions. The
framework first conducts a binary occupancy matrix from a given indoor map.
Using this matrix, the A* algorithm computes the optimal path between origin
and destination, producing concise textual navigation steps. These steps are
then transformed into natural language instructions by the SLM, enhancing
interpretability for end users. Experimental evaluations across various indoor
scenarios demonstrate the method's effectiveness in producing accurate and
timely navigation guidance. The results validate the proposed approach as a
lightweight, infrastructure-free solution for real-time indoor navigation
support.

</details>


### [454] [Vision-Based Localization and LLM-based Navigation for Indoor Environments](https://arxiv.org/abs/2508.08120)
*Keyan Rahimi,Md. Wasiul Haque,Sagar Dasgupta,Mizanur Rahman*

Main category: cs.LG

TL;DR: 本研究提出了一种结合视觉定位和LLM导航的室内导航方法，在模拟和真实场景中均表现出高准确率，证明了其在资源受限环境中应用的潜力。


<details>
  <summary>Details</summary>
Motivation: 室内导航仍然是一个复杂的挑战，因为缺乏可靠的GPS信号以及大型封闭环境的建筑复杂性。

Method: 本研究提出了一种结合了基于视觉的定位和基于大语言模型（LLM）的导航的室内定位和导航方法。定位系统利用在两个阶段进行微调的ResNet-50卷积神经网络，通过智能手机摄像头输入来识别用户的位置。为了补充定位，导航模块采用了一个LLM，并由一个精心设计的系统提示来指导，以解释预处理的楼层平面图图像并生成分步指示。

Result: 定位模型在所有测试的航点上实现了96%的高置信度和准确率，即使在受限的视野条件下和短时间查询下也是如此。使用ChatGPT在实际建筑楼层地图上进行的导航测试产生了75%的平均指令准确率，并观察到零样本推理和推理时间存在局限性。

Conclusion: 该研究展示了使用现成相机和公开楼层平面图进行可扩展、无基础设施的室内导航的潜力，尤其是在医院、机场和教育机构等资源受限的环境中。

Abstract: Indoor navigation remains a complex challenge due to the absence of reliable
GPS signals and the architectural intricacies of large enclosed environments.
This study presents an indoor localization and navigation approach that
integrates vision-based localization with large language model (LLM)-based
navigation. The localization system utilizes a ResNet-50 convolutional neural
network fine-tuned through a two-stage process to identify the user's position
using smartphone camera input. To complement localization, the navigation
module employs an LLM, guided by a carefully crafted system prompt, to
interpret preprocessed floor plan images and generate step-by-step directions.
Experimental evaluation was conducted in a realistic office corridor with
repetitive features and limited visibility to test localization robustness. The
model achieved high confidence and an accuracy of 96% across all tested
waypoints, even under constrained viewing conditions and short-duration
queries. Navigation tests using ChatGPT on real building floor maps yielded an
average instruction accuracy of 75%, with observed limitations in zero-shot
reasoning and inference time. This research demonstrates the potential for
scalable, infrastructure-free indoor navigation using off-the-shelf cameras and
publicly available floor plans, particularly in resource-constrained settings
like hospitals, airports, and educational institutions.

</details>


### [455] [MemoryKT: An Integrative Memory-and-Forgetting Method for Knowledge Tracing](https://arxiv.org/abs/2508.08122)
*Mingrong Lin,Ke Deng,Zhengyang Wu,Zetao Zheng,Jie Li*

Main category: cs.LG

TL;DR: memoryKT是一个知识追踪模型，通过模拟完整的编码-存储-检索周期，并包含个性化遗忘模块，能够更好地捕捉学生知识掌握情况，实验结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的知识追踪模型大多依赖单一的、未区分的遗忘机制，忽略了其他记忆过程以及个性化的遗忘模式，而模拟学生记忆状态是提升知识追踪模型性能和可解释性的有前景的方法。

Method: 提出了一种基于新颖时间变分自编码器（temporal variational autoencoder）的知识追踪模型（memoryKT），该模型通过三个阶段模拟记忆动态：学习学生知识记忆特征的分布、重建练习反馈、并在时间工作流中嵌入个性化遗忘模块以动态调节记忆存储强度。

Result: 实验结果表明，所提出的方法在四个公共数据集上显著优于最先进的基线模型。

Conclusion: 该模型通过模拟记忆的三个过程：编码、存储和检索，并引入个性化遗忘机制，能够更好地感知个体差异，实验结果表明该模型在四个公共数据集上显著优于最先进的基线模型。

Abstract: Knowledge Tracing (KT) is committed to capturing students' knowledge mastery
from their historical interactions. Simulating students' memory states is a
promising approach to enhance both the performance and interpretability of
knowledge tracing models. Memory consists of three fundamental processes:
encoding, storage, and retrieval. Although forgetting primarily manifests
during the storage stage, most existing studies rely on a single,
undifferentiated forgetting mechanism, overlooking other memory processes as
well as personalized forgetting patterns. To address this, this paper proposes
memoryKT, a knowledge tracing model based on a novel temporal variational
autoencoder. The model simulates memory dynamics through a three-stage process:
(i) Learning the distribution of students' knowledge memory features, (ii)
Reconstructing their exercise feedback, while (iii) Embedding a personalized
forgetting module within the temporal workflow to dynamically modulate memory
storage strength. This jointly models the complete encoding-storage-retrieval
cycle, significantly enhancing the model's perception capability for individual
differences. Extensive experiments on four public datasets demonstrate that our
proposed approach significantly outperforms state-of-the-art baselines.

</details>


### [456] [NeuroDx-LM: A Clinical Large-Scale Model for EEG-based Neurological Disorder Detection](https://arxiv.org/abs/2508.08124)
*Guanghao Jin,Yuan Liang,Yihan Ma,Jingpei Wu,Guoyang Liu*

Main category: cs.LG

TL;DR: NeuroDx-LM is a new large-scale model for detecting neurological disorders using EEG. It uses advanced embedding and training methods to improve performance, overcoming limitations of existing models and achieving top results on benchmark datasets.


<details>
  <summary>Details</summary>
Motivation: The practical deployment of EEG-based large-scale models faces challenges due to limited labeled EEG data and suboptimal clinical performance.

Method: NeuroDx-LM utilizes a Selective Temporal-Frequency Embedding mechanism to capture complex EEG patterns and a Progressive Feature-Aware Training strategy in two stages: first learning fundamental discriminative features, then extracting specialized fine-grained features for diagnosis.

Result: NeuroDx-LM achieved state-of-the-art performance on the CHB-MIT dataset for seizure detection and the Schizophrenia dataset for schizophrenia detection.

Conclusion: EEG-based large-scale models have great potential to advance clinical applicability, as demonstrated by NeuroDx-LM's state-of-the-art performance in seizure and schizophrenia detection.

Abstract: Large-scale models pre-trained on Electroencephalography (EEG) have shown
promise in clinical applications such as neurological disorder detection.
However, the practical deployment of EEG-based large-scale models faces
critical challenges such as limited labeled EEG data and suboptimal performance
in clinical scenarios. To address these issues, we propose NeuroDx-LM, a novel
large-scale model specifically designed for detecting EEG-based neurological
disorders. Our key contributions include (i) a Selective Temporal-Frequency
Embedding mechanism that adaptively captures complex temporal and spectral
patterns in EEG signals; and (ii) a Progressive Feature-Aware Training strategy
that refines feature representation in a two-stage process. In the first stage,
our model learns the fundamental discriminative features of EEG activities; in
the second stage, the model further extracts more specialized fine-grained
features for accurate diagnostic performance. We evaluated NeuroDx-LM on the
CHB-MIT and Schizophrenia datasets, achieving state-of-the-art performance in
EEG-based seizure and schizophrenia detection, respectively. These results
demonstrate the great potential of EEG-based large-scale models to advance
clinical applicability. Our code is available at
https://github.com/LetItBe12345/NeuroDx-LM.

</details>


### [457] [OFAL: An Oracle-Free Active Learning Framework](https://arxiv.org/abs/2508.08126)
*Hadi Khorsand,Vahid Pourahmadi*

Main category: cs.LG

TL;DR: OFAL是一种主动学习方法，它不依赖神谕，而是利用神经网络的不确定性来生成新的不确定样本，从而提高模型准确性。


<details>
  <summary>Details</summary>
Motivation: 在主动学习范式中，使用神谕来标记数据是一项复杂且昂贵 Thus, has always been a complex and expensive task. With the emergence of large unlabeled data pools, it would be highly beneficial if we could achieve better results without relying on an oracle.

Method: OFAL是一种无神谕的主动学习方案，它利用神经网络的不确定性。具体来说，它首先分离和量化不确定性的不同部分，并引入蒙特卡洛Dropout作为贝叶斯神经网络模型的近似。然后，通过添加变分自编码器，从置信种子样本开始，在潜在空间的不确定部分进行采样，生成新的不确定样本。

Result: OFAL利用模型自身的不确定性，将高置信度的未标记样本转化为信息不确定的样本，从而提升模型的准确性。

Conclusion: OFAL可以通过生成新的不确定样本来提升模型准确性，并且可以与现有的主动学习采样方法相结合。

Abstract: In the active learning paradigm, using an oracle to label data has always
been a complex and expensive task, and with the emersion of large unlabeled
data pools, it would be highly beneficial If we could achieve better results
without relying on an oracle. This research introduces OFAL, an oracle-free
active learning scheme that utilizes neural network uncertainty. OFAL uses the
model's own uncertainty to transform highly confident unlabeled samples into
informative uncertain samples. First, we start with separating and quantifying
different parts of uncertainty and introduce Monte Carlo Dropouts as an
approximation of the Bayesian Neural Network model. Secondly, by adding a
variational autoencoder, we go on to generate new uncertain samples by stepping
toward the uncertain part of latent space starting from a confidence seed
sample. By generating these new informative samples, we can perform active
learning and enhance the model's accuracy. Lastly, we try to compare and
integrate our method with other widely used active learning sampling methods.

</details>


### [458] [FairFLRep: Fairness aware fault localization and repair of Deep Neural Networks](https://arxiv.org/abs/2508.08151)
*Moses Openja,Paolo Arcaini,Foutse Khomh,Fuyuki Ishikawa*

Main category: cs.LG

TL;DR: FairFLRep 是一种新的技术，可以帮助人工智能（AI）系统在决策时更加公平，即使在处理不同人群的数据时也是如此。它通过识别和调整 AI 内部可能导致不公平行为的部分来工作。


<details>
  <summary>Details</summary>
Motivation: DNN 在日常生活中得到广泛应用，但也存在偏见问题，例如在不同人群中的错误分类率不同，而有效识别和纠正 DNN 中的偏见行为仍然是一个挑战。

Method: FairFLRep 是一种自动化的、公平感知的故障定位和修复技术，通过调整与性别或种族等敏感属性相关的神经元权重来识别和纠正 DNN 分类器中可能引起偏见的神经元。

Result: FairFLRep 在四个图像分类数据集和四个表格数据集上进行了评估，结果表明 FairFLRep 在提高公平性方面始终优于现有方法，同时保持准确性。而对 FairFLRep 进行的消融研究证实了在故障定位和修复阶段都考虑公平性的重要性。研究还表明 FairFLRep 在修复网络方面比基线方法更有效率。

Conclusion: FairFLRep 能够提高 DNN 分类器的公平性，同时保持准确性，并且比现有方法更有效率。

Abstract: Deep neural networks (DNNs) are being utilized in various aspects of our
daily lives, including high-stakes decision-making applications that impact
individuals. However, these systems reflect and amplify bias from the data used
during training and testing, potentially resulting in biased behavior and
inaccurate decisions. For instance, having different misclassification rates
between white and black sub-populations. However, effectively and efficiently
identifying and correcting biased behavior in DNNs is a challenge. This paper
introduces FairFLRep, an automated fairness-aware fault localization and repair
technique that identifies and corrects potentially bias-inducing neurons in DNN
classifiers. FairFLRep focuses on adjusting neuron weights associated with
sensitive attributes, such as race or gender, that contribute to unfair
decisions. By analyzing the input-output relationships within the network,
FairFLRep corrects neurons responsible for disparities in predictive quality
parity. We evaluate FairFLRep on four image classification datasets using two
DNN classifiers, and four tabular datasets with a DNN model. The results show
that FairFLRep consistently outperforms existing methods in improving fairness
while preserving accuracy. An ablation study confirms the importance of
considering fairness during both fault localization and repair stages. Our
findings also show that FairFLRep is more efficient than the baseline
approaches in repairing the network.

</details>


### [459] [Federated Learning for Epileptic Seizure Prediction Across Heterogeneous EEG Datasets](https://arxiv.org/abs/2508.08159)
*Cem Ata Baykara,Saurav Raj Pandey,Ali Burak Ünal,Harlin Lee,Mete Akgün*

Main category: cs.LG

TL;DR: 为解决跨多中心EEG数据训练癫痫预测模型的隐私和数据异构性问题，本研究提出了一种随机子集聚合的联邦学习方法，显著提高了在代表性不足的数据集上的模型性能和泛化能力，实现了更鲁棒和公平的全局模型。


<details>
  <summary>Details</summary>
Motivation: 开发准确且可泛化的癫痫发作预测模型，该模型能够跨多个临床站点对脑电图（EEG）数据进行训练，但面临患者隐私法规和数据异构性（非独立同分布特征）的挑战。标准的联邦学习聚合方法（如联邦平均法）可能因异构环境中占主导地位的数据集而产生偏差。

Method: 本研究提出了一种随机子集聚合策略，其中每个客户端在每轮训练中使用固定大小的随机数据子集，以确保聚合过程中的相等贡献，并实现了隐私保护的全局归一化。

Result: 与仅在本地训练的模型无法泛化到其他站点，以及标准的加权联邦平均法产生高度倾斜的性能（在CHB-MIT上准确率为89.0%，但在Helsinki上仅为50.8%，在NCH上为50.6%）相比，随机子集聚合策略显著提高了代表性不足的客户端的性能（Helsinki的准确率提高到81.7%，NCH提高到68.7%），并在所有站点上实现了更高的宏观平均准确率（77.1%）和汇总准确率（80.0%），展示了一个更鲁棒和公平的全局模型。

Conclusion: 通过采用平衡的联邦学习方法，可以构建有效且可泛化的癫痫预测系统，以应对现实中异构的多医院环境，同时尊重数据隐私。

Abstract: Developing accurate and generalizable epileptic seizure prediction models
from electroencephalography (EEG) data across multiple clinical sites is
hindered by patient privacy regulations and significant data heterogeneity
(non-IID characteristics). Federated Learning (FL) offers a privacy-preserving
framework for collaborative training, but standard aggregation methods like
Federated Averaging (FedAvg) can be biased by dominant datasets in
heterogeneous settings. This paper investigates FL for seizure prediction using
a single EEG channel across four diverse public datasets (Siena, CHB-MIT,
Helsinki, NCH), representing distinct patient populations (adult, pediatric,
neonate) and recording conditions. We implement privacy-preserving global
normalization and propose a Random Subset Aggregation strategy, where each
client trains on a fixed-size random subset of its data per round, ensuring
equal contribution during aggregation. Our results show that locally trained
models fail to generalize across sites, and standard weighted FedAvg yields
highly skewed performance (e.g., 89.0% accuracy on CHB-MIT but only 50.8% on
Helsinki and 50.6% on NCH). In contrast, Random Subset Aggregation
significantly improves performance on under-represented clients (accuracy
increases to 81.7% on Helsinki and 68.7% on NCH) and achieves a superior
macro-average accuracy of 77.1% and pooled accuracy of 80.0% across all sites,
demonstrating a more robust and fair global model. This work highlights the
potential of balanced FL approaches for building effective and generalizable
seizure prediction systems in realistic, heterogeneous multi-hospital
environments while respecting data privacy.

</details>


### [460] [Multi-head Transformers Provably Learn Symbolic Multi-step Reasoning via Gradient Descent](https://arxiv.org/abs/2508.08222)
*Tong Yang,Yu Huang,Yingbin Liang,Yuejie Chi*

Main category: cs.LG

TL;DR: Transformer模型通过链式思考学习推理，即使是浅层模型也能解决复杂问题。


<details>
  <summary>Details</summary>
Motivation: 探讨Transformer模型在多步推理任务中能力获取的机制，特别是从理论角度解释其链式思考过程。

Method: 通过梯度下降的动力学对Transformer模型进行理论分析，研究其在树状结构上的路径寻找任务。

Result: 证明了训练好的单层Transformer能够泛化到未见过的树状结构，并解释了多阶段训练如何使注意力头协同工作以解决前向推理任务。

Conclusion: Transformer模型可以通过链式思考过程学习符号多步推理，即使是浅层模型也能通过多头注意力机制解决复杂问题。

Abstract: Transformers have demonstrated remarkable capabilities in multi-step
reasoning tasks. However, understandings of the underlying mechanisms by which
they acquire these abilities through training remain limited, particularly from
a theoretical standpoint. This work investigates how transformers learn to
solve symbolic multi-step reasoning problems through chain-of-thought
processes, focusing on path-finding in trees. We analyze two intertwined tasks:
a backward reasoning task, where the model outputs a path from a goal node to
the root, and a more complex forward reasoning task, where the model implements
two-stage reasoning by first identifying the goal-to-root path and then
reversing it to produce the root-to-goal path. Our theoretical analysis,
grounded in the dynamics of gradient descent, shows that trained one-layer
transformers can provably solve both tasks with generalization guarantees to
unseen trees. In particular, our multi-phase training dynamics for forward
reasoning elucidate how different attention heads learn to specialize and
coordinate autonomously to solve the two subtasks in a single autoregressive
path. These results provide a mechanistic explanation of how trained
transformers can implement sequential algorithmic procedures. Moreover, they
offer insights into the emergence of reasoning abilities, suggesting that when
tasks are structured to take intermediate chain-of-thought steps, even shallow
multi-head transformers can effectively solve problems that would otherwise
require deeper architectures.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [461] [Generative Bid Shading in Real-Time Bidding Advertising](https://arxiv.org/abs/2508.06550)
*Yinqiu Huang,Hao Ma,Wenshuai Chen,Shuli Wang,Yongqiang Zhang,Xue Wei,Yinhua Zhu,Haitao Wang,Xingxing Wang*

Main category: cs.GT

TL;DR: GBS通过端到端的生成模型和奖励偏好对齐系统，解决了现有竞价着色方法的局限性，能够处理非凸剩余曲线和依赖关系，并优化短期和长期剩余，已在实际平台部署并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有主流的两阶段方法受限于单峰假设，无法适应非凸剩余曲线，并且在顺序工作流中容易出现级联错误。此外，连续值的离散化模型忽略了离散区间之间的依赖关系，降低了模型的误差校正能力，而竞价场景中的样本选择偏差则给预测带来了进一步的挑战。

Method: 提出了一种名为生成式竞价着色（GBS）的方法，该方法包含两个主要部分：1.端到端的生成模型，使用自回归方法通过逐步残差生成着色比率，捕捉复杂的依赖关系，无需预定义先验；2.奖励偏好对齐系统，该系统将渠道感知的分层动态网络（CHNet）作为奖励模型提取细粒度特征，并结合剩余优化和探索效用奖励对齐模块，使用组相对策略优化（GRPO）来优化短期和长期剩余。

Result: GBS通过实验证明了其有效性，并在Meituan DSP平台成功部署，服务于日常数十亿的竞价请求。

Conclusion: GBS在Meituan DSP平台已成功部署，并服务于日常数十亿的竞价请求，实验结果验证了GBS的有效性。

Abstract: Bid shading plays a crucial role in Real-Time Bidding~(RTB) by adaptively
adjusting the bid to avoid advertisers overspending. Existing mainstream
two-stage methods, which first model bid landscapes and then optimize surplus
using operations research techniques, are constrained by unimodal assumptions
that fail to adapt for non-convex surplus curves and are vulnerable to
cascading errors in sequential workflows. Additionally, existing discretization
models of continuous values ignore the dependence between discrete intervals,
reducing the model's error correction ability, while sample selection bias in
bidding scenarios presents further challenges for prediction. To address these
issues, this paper introduces Generative Bid Shading~(GBS), which comprises two
primary components: (1) an end-to-end generative model that utilizes an
autoregressive approach to generate shading ratios by stepwise residuals,
capturing complex value dependencies without relying on predefined priors; and
(2) a reward preference alignment system, which incorporates a channel-aware
hierarchical dynamic network~(CHNet) as the reward model to extract
fine-grained features, along with modules for surplus optimization and
exploration utility reward alignment, ultimately optimizing both short-term and
long-term surplus using group relative policy optimization~(GRPO). Extensive
experiments on both offline and online A/B tests validate GBS's effectiveness.
Moreover, GBS has been deployed on the Meituan DSP platform, serving billions
of bid requests daily.

</details>


### [462] [Algorithmic Delegated Choice: An Annotated Reading List](https://arxiv.org/abs/2508.06562)
*Mohammad T. Hajiaghayi,Suho Shin*

Main category: cs.GT

TL;DR: This paper reviews the literature on delegated choice problems, bridging economic and computer science perspectives.


<details>
  <summary>Details</summary>
Motivation: To provide a comprehensive overview of the delegated choice problem, integrating classic economic theories with modern algorithmic approaches.

Method: Literature review and overview of existing papers on delegated choice problems.

Result: A curated list of papers on delegated choice, highlighting the evolution from economic theory to algorithmic solutions.

Conclusion: This paper provides an overview of delegated choice problems, covering classic economic works and recent algorithmic perspectives.

Abstract: The problem of delegated choice has been of long interest in economics and
recently on computer science. We overview a list of papers on delegated choice
problem, from classic works to recent papers with algorithmic perspectives.

</details>


### [463] [Asymmetric Network Games: $α$-Potential Function and Learning](https://arxiv.org/abs/2508.06619)
*Kiran Rokade,Adit Jain,Francesca Parise,Vikram Krishnamurthy,Eva Tardos*

Main category: cs.GT

TL;DR: 该研究分析了网络博弈，并提出了一种可以收敛到 2α-Nash 均衡的算法。


<details>
  <summary>Details</summary>
Motivation: 分析具有大量异构玩家和非对称性的网络博弈。

Method: 使用 α-potential 框架分析静态网络博弈，并提出改进的顺序最佳响应算法和梯度下降算法以达到 2α-Nash 均衡。

Result: 推导出 α-potential 函数，并证明了所提出的算法能够收敛到 2α-Nash 均衡。对于线性二次网络博弈，推导了 α 的表达式，并界定了其范围。此外，还推导了在某些假设下的社会福利界限。

Conclusion: 该研究为网络博弈提供了一种新的分析框架，并提出了一种计算和分析均衡的算法。对于线性二次网络博弈，研究推导了 α 的表达式，并对 α 进行了界定，证明了在实际应用中 α 是良定义的。

Abstract: In a network game, players interact over a network and the utility of each
player depends on his own action and on an aggregate of his neighbours'
actions. Many real world networks of interest are asymmetric and involve a
large number of heterogeneous players. This paper analyzes static network games
using the framework of $\alpha$-potential games. Under mild assumptions on the
action sets (compact intervals) and the utility functions (twice continuously
differentiable) of the players, we derive an expression for an inexact
potential function of the game, called the $\alpha$-potential function. Using
such a function, we show that modified versions of the sequential best-response
algorithm and the simultaneous gradient play algorithm achieve convergence of
players' actions to a $2\alpha$-Nash equilibrium. For linear-quadratic network
games, we show that $\alpha$ depends on the maximum asymmetry in the network
and is well-behaved for a wide range of networks of practical interest.
Further, we derive bounds on the social welfare of the $\alpha$-Nash
equilibrium corresponding to the maximum of the $\alpha$-potential function,
under suitable assumptions. We numerically illustrate the convergence of the
proposed algorithms and properties of the learned $2\alpha$-Nash equilibria.

</details>


### [464] [Convergence of Fast Policy Iteration in Markov Games and Robust MDPs](https://arxiv.org/abs/2508.06661)
*Keith Badger,Marek Petrik,Jefferson Huang*

Main category: cs.GT

TL;DR: FT算法在马尔可夫博弈和鲁棒MDP中可能无法收敛到鞍点。新提出的RCPI算法解决了这个问题，并且性能更优。


<details>
  <summary>Details</summary>
Motivation: 为了开发更有效的算法来计算马尔可夫博弈和鲁棒MDP中的鞍点策略，并且指出FT算法可能存在收敛问题。

Method: 提出Residual Conditioned Policy Iteration (RCPI)算法，该算法在Filar-Tolwinski (FT)算法的基础上进行改进，以解决FT算法可能无法收敛到鞍点的问题。

Result: FT算法可能无法收敛到鞍点，而RCPI算法保证收敛，并且在数值结果上表现优于其他收敛算法。

Conclusion: Filar-Tolwinski (FT)算法可能无法收敛到鞍点，甚至在小型博弈中可能无限循环。Residual Conditioned Policy Iteration (RCPI)算法在FT算法的基础上进行了改进，保证收敛到鞍点，并且在数值结果上显示其性能比其他收敛算法高出几个数量级。

Abstract: Markov games and robust MDPs are closely related models that involve
computing a pair of saddle point policies. As part of the long-standing effort
to develop efficient algorithms for these models, the Filar-Tolwinski (FT)
algorithm has shown considerable promise. As our first contribution, we
demonstrate that FT may fail to converge to a saddle point and may loop
indefinitely, even in small games. This observation contradicts the proof of
FT's convergence to a saddle point in the original paper. As our second
contribution, we propose Residual Conditioned Policy Iteration (RCPI). RCPI
builds on FT, but is guaranteed to converge to a saddle point. Our numerical
results show that RCPI outperforms other convergent algorithms by several
orders of magnitude.

</details>


### [465] [Emergence of Cooperation and Commitment in Optional Prisoner's Dilemma](https://arxiv.org/abs/2508.06702)
*Zhao Song,The Anh Han*

Main category: cs.GT

TL;DR: 本研究探讨了在参与具有可选性的囚徒困境博弈中，承诺和合作的演化。研究发现，可选参与虽提高了承诺接受率，但导致了广泛的退出行为。严格的制度激励措施比灵活的措施更能促进合作，但灵活的措施在特定情况下能提高社会福利。研究强调了精心设计的制度激励措施对促进合作和社会福利的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注承诺机制以促进合作，但往往忽略了玩家选择不参与互动的自由，这限制了其在现实世界中的应用。因此，本研究旨在探讨在参与具有可选性的情况下，承诺和合作的演化机制，并提出有效的制度激励措施来促进合作和社会福利。

Method: 本研究采用两阶段博弈模型，在可选的囚徒困境博弈框架内，研究了基于承诺的行为和合作的演化。首先，在博弈前阶段，玩家决定是否接受相互承诺；然后在博弈阶段，玩家根据是否形成事先承诺，选择合作、背叛或退出。之后，研究引入并比较了两种制度激励方法：严格的承诺（STRICT-COM）和灵活的承诺（FLEXIBLE-COM），以解决可选参与未能促进合作的问题。

Result: 研究发现，可选参与虽然提高了承诺的接受率，但并未能有效促进合作，反而导致了普遍的退出行为。在引入制度激励措施后，严格的承诺方法（STRICT-COM）在促进合作方面优于灵活的承诺方法（FLEXIBLE-COM）。然而，当机会主义行为能带来高收益时，灵活的承诺方法（FLEXIBLE-COM）作为一种提高社会福利的替代方案，也具有一定的效率。

Conclusion: 现有研究主要集中于承诺机制，但忽视了玩家选择不参与互动的自由，这限制了其在许多现实场景中的应用。本研究提出了一个两阶段博弈模型，在可选的囚徒困境博弈框架内研究基于承诺的行为和合作的演化。研究发现，可选参与会增加承诺接受率，但未能促进合作，反而导致了广泛的退出行为。为了解决这个问题，本研究引入并比较了两种制度激励方法：一种是严格的，只奖励在博弈中合作的承诺玩家；另一种是灵活的，奖励所有不违背承诺的玩家。结果表明，严格的方法在促进合作方面明显优于灵活的方法，因为灵活的规则为承诺后的机会主义退出留下了漏洞。然而，当这种机会主义行为带来高收益时，灵活的规则为提高社会福利提供了一种有效的替代方案。本研究强调了仅依靠自愿参与和承诺来解决社会困境的局限性，并强调了精心设计的制度激励对于有效促进合作和社会福利的重要性。

Abstract: Commitment is a well-established mechanism for fostering cooperation in human
society and multi-agent systems. However, existing research has predominantly
focused on the commitment that neglects the freedom of players to abstain from
an interaction, limiting their applicability to many real-world scenarios where
participation is often voluntary. In this paper, we present a two-stage game
model to investigate the evolution of commitment-based behaviours and
cooperation within the framework of the optional Prisoner's Dilemma game. In
the pre-game stage, players decide whether to accept a mutual commitment. Once
in the game, they choose among cooperation, defection, or exiting, depending on
the formation of a pre-game commitment. We find that optional participation
boosts commitment acceptance but fails to foster cooperation, leading instead
to widespread exit behaviour. To address this, we then introduce and compare
two institutional incentive approaches: i) a strict one (STRICT-COM) that
rewards only committed players who cooperate in the game, and ii) a flexible
one (FLEXIBLE-COM) that rewards any committed players who do not defect in the
game. The results reveal that, while the strict approach is demonstrably better
for promoting cooperation as the flexible rule creates a loophole for an
opportunistic exit after committing, the flexible rule offers an efficient
alternative for enhancing social welfare when such opportunistic behaviour
results in a high gain. This study highlights the limitations of relying solely
on voluntary participation and commitment to resolving social dilemmas,
emphasising the importance of well-designed institutional incentives to promote
cooperation and social welfare effectively.

</details>


### [466] [When Competition Helps: Achieving Optimal Traffic Flow with Multiple Autonomous Planners](https://arxiv.org/abs/2508.07145)
*Ivan Geffner,Erez Karpas,Moshe Tennenholtz*

Main category: cs.GT

TL;DR: 在自动驾驶汽车网络中，引入竞争而非完全中心化控制，是实现最优交通流量分配的关键。


<details>
  <summary>Details</summary>
Motivation: 探究自动驾驶汽车的部署是否能消除拥塞网络中自我路由的低效率问题，特别是当存在多个竞争性规划主体时。

Method: 设计了一个包含竞争机制的路由机制，并以经典的Pigou网络作为基础案例。

Result: 设计出的路由机制能够收敛到最优分配，证明了竞争是实现最优结果的必要因素。

Conclusion: 通过引入竞争机制，可以实现最优的交通流量分配，这与直觉相反。

Abstract: The inefficiency of selfish routing in congested networks is a classical
problem in algorithmic game theory, often captured by the Price of Anarchy
(i.e., the ratio between the social cost of decentralized decisions and that of
a centrally optimized solution.) With the advent of autonomous vehicles,
capable of receiving and executing centrally assigned routes, it is natural to
ask whether their deployment can eliminate this inefficiency. At first glance,
a central authority could simply compute an optimal traffic assignment and
instruct each vehicle to follow its assigned path. However, this vision
overlooks critical challenges: routes must be individually rational (no vehicle
has an incentive to deviate), and in practice, multiple planning agents (e.g.,
different companies) may coexist and compete. Surprisingly, we show that such
competition is not merely an obstacle but a necessary ingredient for achieving
optimal outcomes. In this work, we design a routing mechanism that embraces
competition and converges to an optimal assignment, starting from the classical
Pigou network as a foundational case.

</details>


### [467] [Maximizing Social Welfare with Side Payments](https://arxiv.org/abs/2508.07147)
*Ivan Geffner,Caspar Oesterheld,Vincent Conitzer*

Main category: cs.GT

TL;DR: 在正则式博弈中，预先承诺可能导致效率低下。通过引入分阶段、有上限且需一致同意的承诺协议，可以实现福利最大化目标，并规避此类问题。


<details>
  <summary>Details</summary>
Motivation: 研究了在正则式博弈中，玩家预先承诺根据结果支付，以及这种承诺可能导致效率低下的问题，特别是当承诺能力被滥用以至于出现“囚徒困境”效应时。

Method: 提出并证明了一种分阶段承诺协议的有效性，该协议允许玩家在多轮中以分期、有上限的方式进行承诺，并通过所有玩家的一致同意来推进。

Result: 证明了分阶段承诺协议能够实现所有能严格改进现有纳什均衡的福利最大化支付组合，从而恢复了支付能力的所有效率潜力，并避免了效率低下问题。

Conclusion: 通过引入分阶段承诺协议，即玩家可以在多轮中以小额、有上限的增量进行转让，并且只有在所有玩家一致同意的情况下才能继续进行，可以规避“承诺后顾之忧”问题。该协议可以实现所有能严格改进现有纳什均衡的福利最大化支付组合，从而避免了杰克逊和威尔基所指出的低效问题。

Abstract: We examine normal-form games in which players may \emph{pre-commit} to
outcome-contingent transfers before choosing their actions. In the one-shot
version of this model, Jackson and Wilkie showed that side contracting can
backfire: even a game with a Pareto-optimal Nash equilibrium can devolve into
inefficient equilibria once unbounded, simultaneous commitments are allowed.
The root cause is a prisoner's dilemma effect, where each player can exploit
her commitment power to reshape the equilibrium in her favor, harming overall
welfare.
  To circumvent this problem we introduce a \emph{staged-commitment} protocol.
Players may pledge transfers only in small, capped increments over multiple
rounds, and the phase continues only with unanimous consent. We prove that,
starting from any finite game $\Gamma$ with a non-degenerate Nash equilibrium
$\vec{\sigma}$, this protocol implements every welfare-maximizing payoff
profile that \emph{strictly} Pareto-improves $\vec{\sigma}$. Thus, gradual and
bounded commitments restore the full efficiency potential of side payments
while avoiding the inefficiencies identified by Jackson and Wilkie.

</details>


### [468] [Last-Iterate Convergence in Adaptive Regret Minimization for Approximate Extensive-Form Perfect Equilibrium](https://arxiv.org/abs/2508.07699)
*Hang Ren,Xiaozhen Sun,Tianzi Ma,Jiajia Zhang,Xuan Wang*

Main category: cs.GT

TL;DR: 提出了一种新的算法，通过自适应调整博弈中的扰动，更有效地找到纳什均衡和扩展型完美均衡，并在实验中表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有的EFPE算法在计算平均策略时成本高昂且存在近似误差，固定的扰动则在NE近似精度和收敛速度之间造成权衡，限制了其在实际应用中的效果。

Method: 提出了一种高效的自适应悔恨最小化算法，包括奖励转换反事实悔恨最小化（RTCFR）来解决扰动博弈，并定义了信息集纳什均衡（ISNE）来动态调整扰动。

Result: 理论分析证实了算法收敛到EFPE，实验结果表明该方法在NE和EFPE查找任务中均显著优于现有最先进算法。

Conclusion: 该方法在不完美信息扩展型博弈中，通过引入RTCFR和ISNE，能够高效地计算近似EFPE，并在NE和EFPE查找任务中显著优于现有算法。

Abstract: The Nash Equilibrium (NE) assumes rational play in imperfect-information
Extensive-Form Games (EFGs) but fails to ensure optimal strategies for
off-equilibrium branches of the game tree, potentially leading to suboptimal
outcomes in practical settings. To address this, the Extensive-Form Perfect
Equilibrium (EFPE), a refinement of NE, introduces controlled perturbations to
model potential player errors. However, existing EFPE-finding algorithms, which
typically rely on average strategy convergence and fixed perturbations, face
significant limitations: computing average strategies incurs high computational
costs and approximation errors, while fixed perturbations create a trade-off
between NE approximation accuracy and the convergence rate of NE refinements.
  To tackle these challenges, we propose an efficient adaptive regret
minimization algorithm for computing approximate EFPE, achieving last-iterate
convergence in two-player zero-sum EFGs. Our approach introduces Reward
Transformation Counterfactual Regret Minimization (RTCFR) to solve perturbed
games and defines a novel metric, the Information Set Nash Equilibrium (ISNE),
to dynamically adjust perturbations. Theoretical analysis confirms convergence
to EFPE, and experimental results demonstrate that our method significantly
outperforms state-of-the-art algorithms in both NE and EFPE-finding tasks.

</details>


### [469] [Truthful Two-Obnoxious-Facility Location Games with Optional Preferences and Minimum Distance Constraint](https://arxiv.org/abs/2508.08036)
*Xiaojia Han,Wenjing Liu,Qizhi Fang*

Main category: cs.GT

TL;DR: 该论文研究了两类“厌恶型”设施的选址问题，提出了激励相容的机制设计，并分析了不同机制的近似最优性。


<details>
  <summary>Details</summary>
Motivation: 为了解决在代理拥有私有位置和可选的两设施偏好的情况下，如何放置设施以激励代理真实报告位置并最大化社会效用。

Method: 研究提出了确定性策略证明机制和随机性策略证明机制，并分析了它们在d=0和d>0两种情况下的近似比，同时给出了相应机制的近似比下界。

Result: 在d=0的情况下，提出了近似比不超过4的确定性机制和近似比不超过2的随机性机制。在d>0的普遍情况下，提出了近似比不超过8的确定性机制和近似比不超过4的随机性机制。此外，还证明了确定性机制近似比的下界为2，随机性机制近似比的下界为14/13。

Conclusion: 该研究提出了在满足最小距离约束d的情况下，解决两设施选址问题的激励机制，并给出了确定性和随机性机制的近似比界限。

Abstract: In this paper, we study a truthful two-obnoxious-facility location problem,
in which each agent has a private location in [0, 1] and a public optional
preference over two obnoxious facilities, and there is a minimum distance
constraint d between the two facilities. Each agent wants to be as far away as
possible from the facilities that affect her, and the utility of each agent is
the total distance from her to these facilities. The goal is to decide how to
place the facilities in [0, 1] so as to incentivize agents to report their
private locations truthfully as well as maximize the social utility. First, we
consider the special setting where d = 0, that is, the two facilities can be
located at any point in [0, 1]. We propose a deterministic strategyproof
mechanism with approximation ratio of at most 4 and a randomized strategyproof
mechanism with approximation ratio of at most 2, respectively. Then we study
the general setting. We propose a deterministic strategyproof mechanism with
approximation ratio of at most 8 and a randomized strategyproof mechanism with
approximation ratio of at most 4, respectively. Furthermore, we provide lower
bounds of 2 and 14/13 on the approximation ratio for any deterministic and any
randomized strategyproof mechanism, respectively.

</details>


### [470] [Constrained Distributed Heterogeneous Two-Facility Location Problems with Max-Variant Cost](https://arxiv.org/abs/2508.08045)
*Xinru Xu,Wenjing Liu,Qizhi Fang*

Main category: cs.GT

TL;DR: We study a constrained distributed heterogeneous two-facility location problem and design strategyproof distributed mechanisms with constant upper and lower distortion bounds under four social objectives.


<details>
  <summary>Details</summary>
Motivation: We aim to design strategyproof distributed mechanisms that can incentivize all agents to truthfully report their locations and approximately optimize some social objective.

Method: We focus on a class of deterministic strategyproof distributed mechanisms and analyze upper and lower bounds on the distortion under the Average-of-Average cost, the Max-of-Max cost, the Average-of-Max cost and the Max-of-Average cost.

Result: We analyze upper and lower bounds on the distortion under four social objectives, obtaining constant upper and lower distortion bounds.

Conclusion: Under four social objectives, we obtain constant upper and lower distortion bounds.

Abstract: We study a constrained distributed heterogeneous two-facility location
problem, where a set of agents with private locations on the real line are
divided into disjoint groups. The constraint means that the facilities can only
be built in a given multiset of candidate locations and at most one facility
can be built at each candidate location. Given the locations of the two
facilities, the cost of an agent is the distance from her location to the
farthest facility (referred to as max-variant). Our goal is to design
strategyproof distributed mechanisms that can incentivize all agents to
truthfully report their locations and approximately optimize some social
objective. A distributed mechanism consists of two steps: for each group, the
mechanism chooses two candidate locations as the representatives of the group
based only on the locations reported by agents therein; then, it outputs two
facility locations among all the representatives. We focus on a class of
deterministic strategyproof distributed mechanisms and analyze upper and lower
bounds on the distortion under the Average-of-Average cost (average of the
average individual cost of agents in each group), the Max-of-Max cost (maximum
individual cost among all agents), the Average-of-Max cost (average of the
maximum individual cost among all agents in each group) and the Max-of-Average
cost (maximum of the average individual cost of all agents in each group).
Under four social objectives, we obtain constant upper and lower distortion
bounds.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [471] [SSD Offloading for LLM Mixture-of-Experts Weights Considered Harmful in Energy Efficiency](https://arxiv.org/abs/2508.06978)
*Kwanhee Kyung,Sungmin Yun,Jung Ho Ahn*

Main category: cs.AR

TL;DR: 该论文分析了在LLM推理中将MoE专家权重卸载到SSD的能量影响。研究发现，虽然SSD成本低，但其较高的读取能量消耗会显著增加整体能量使用。除非SSD的读取能量有大幅提升，否则当前技术下SSD不适用于此场景。


<details>
  <summary>Details</summary>
Motivation: LLM应用MoE模型可以扩展到万亿参数，但需要巨大的内存，这促使研究人员将专家权重从快速但小的DRAM（HBM）卸载到更密集的Flash SSD。

Method: 通过比较SSD、CPU内存（DDR）和HBM存储器场景，对LLM推理的关键解码阶段将MoE专家权重卸载到SSD的能量影响进行了量化分析。

Result: 将MoE权重卸载到目前的SSD会大大增加每个token生成的能量消耗（与HBM基线相比最高约增加12倍），并主导总的推理能量预算。

Conclusion: 虽然预取等技术可以隐藏访问延迟，但不能减轻这种根本性的能量损失。我们进一步探讨了未来的技术扩展，发现如果闪存读取能量有显著（约十倍）的提高，MoE模型的固有稀疏性可能使SSD在能量上可行。

Abstract: Large Language Models (LLMs) applying Mixture-of-Experts (MoE) scale to
trillions of parameters but require vast memory, motivating a line of research
to offload expert weights from fast-but-small DRAM (HBM) to denser Flash SSDs.
While SSDs provide cost-effective capacity, their read energy per bit is
substantially higher than that of DRAM. This paper quantitatively analyzes the
energy implications of offloading MoE expert weights to SSDs during the
critical decode stage of LLM inference. Our analysis, comparing SSD, CPU memory
(DDR), and HBM storage scenarios for models like DeepSeek-R1, reveals that
offloading MoE weights to current SSDs drastically increases
per-token-generation energy consumption (e.g., by up to ~12x compared to the
HBM baseline), dominating the total inference energy budget. Although
techniques like prefetching effectively hide access latency, they cannot
mitigate this fundamental energy penalty. We further explore future
technological scaling, finding that the inherent sparsity of MoE models could
potentially make SSDs energy-viable if Flash read energy improves
significantly, roughly by an order of magnitude.

</details>


### [472] [Physical Design Exploration of a Wire-Friendly Domain-Specific Processor for Angstrom-Era Nodes](https://arxiv.org/abs/2508.07110)
*Lorenzo Ruotolo,Lara Orlandic,Pengbo Yu,Moritz Brunion,Daniele Jahier Pagliari,Dwaipayan Biswas,Giovanni Ansaloni,David Atienza,Julien Ryckaert,Francky Catthoor,Yukai Chen*

Main category: cs.AR

TL;DR: 本研究提出了一种用于机器学习的DSIP架构，通过优化互连设计（使用专用内存和SIMD单元）显著提高了密度（3倍以上）并减少了线长（2倍以上），适用于先进工艺节点，且易于实现。


<details>
  <summary>Details</summary>
Motivation: 针对先进Angstrom时代技术中互连效率的挑战，探索用于机器学习（ML）的领域特定处理器（DSIP）架构的物理设计。

Method: 通过利用专门的内存结构和SIMD单元，并使用IMEC A10纳米片节点PDK对五种配置进行综合和评估，以探索针对机器学习（ML）的DSIP架构的物理设计。

Result: 与现有的DSIP基线（VWR2A）相比，所提出的架构实现了超过2倍的归一化线长降低和超过3倍的密度提升，并且在所有配置中各项指标的变异性较低。

Conclusion: 该研究提出的领域特定处理器（DSIP）架构在互连效率、线长和核心密度方面展现出优越性能，为下一代DSIP设计提供了有前景的解决方案，且仅需少量手动干预即可实现。

Abstract: This paper presents the physical design exploration of a domain-specific
processor (DSIP) architecture targeted at machine learning (ML), addressing the
challenges of interconnect efficiency in advanced Angstrom-era technologies.
The design emphasizes reduced wire length and high core density by utilizing
specialized memory structures and SIMD (Single Instruction, Multiple Data)
units. Five configurations are synthesized and evaluated using the IMEC A10
nanosheet node PDK. Key physical design metrics are compared across
configurations and against VWR2A, a state-of-the-art (SoA) DSIP baseline.
Results show that our architecture achieves over 2x lower normalized wire
length and more than 3x higher density than the SoA, with low variability in
the metrics across all configurations, making it a promising solution for
next-generation DSIP designs. These improvements are achieved with minimal
manual layout intervention, demonstrating the architecture's intrinsic physical
efficiency and potential for low-cost wire-friendly implementation.

</details>


### [473] [LP-Spec: Leveraging LPDDR PIM for Efficient LLM Mobile Speculative Inference with Architecture-Dataflow Co-Optimization](https://arxiv.org/abs/2508.07227)
*Siyuan He,Zhantong Zhu,Yandong He,Tianyu Jia*

Main category: cs.AR

TL;DR: LP-Spec通过PIM、草稿标记修剪和动态调度优化LLM推断，大幅提升性能和能效，在移动端和高端GPU上均表现优异。


<details>
  <summary>Details</summary>
Motivation: 移动设备上的LLM推断面临内存带宽和计算资源有限的挑战。现有的推断技术（如推测推断和PIM）存在一些问题，例如推测推断会增加GEMM运算量，给现有的GEMV加速PIM架构带来新的设计权衡；而基于树的推测推断会产生大量冗余的草稿标记，需要高效的标记管理方案来降低能耗。

Method: LP-Spec采用了一种架构-数据流协同设计的策略，集成了高性能PIM架构、草稿标记修剪和动态工作负载调度。具体措施包括：提出了一种近数据内存控制器，用于DRAM和PIM银行之间的数据重新分配；开发了一个基于硬件感知草稿标记修剪器的数据分配单元，以最小化能耗并充分利用并行执行机会。

Result: 与现有的移动解决方案（如移动NPU或GEMV加速PIM）相比，LP-Spec在性能、能效和EDP方面分别实现了13.21倍、7.56倍和99.87倍的提升。与之前的AttAcc PIM和RTX 3090 GPU相比，LP-Spec在EDP方面分别降低了12.83倍和415.31倍。

Conclusion: LP-Spec通过结合混合LPDDR5 PIM架构、草稿标记修剪和动态工作负载调度，在LLM推断方面实现了显著的性能提升和能效改进，与现有移动解决方案和高端GPU相比，其EDP方面表现尤为突出。

Abstract: LLM inference on mobile devices faces extraneous challenges due to limited
memory bandwidth and computational resources. To address these issues,
speculative inference and processing-in-memory (PIM) techniques have been
explored at the algorithmic and hardware levels. However, speculative inference
results in more compute-intensive GEMM operations, creating new design
trade-offs for existing GEMV-accelerated PIM architectures. Furthermore, there
exists a significant amount of redundant draft tokens in tree-based speculative
inference, necessitating efficient token management schemes to minimize energy
consumption. In this work, we present LP-Spec, an architecture-dataflow
co-design leveraging hybrid LPDDR5 performance-enhanced PIM architecture with
draft token pruning and dynamic workload scheduling to accelerate LLM
speculative inference. A near-data memory controller is proposed to enable data
reallocation between DRAM and PIM banks. Furthermore, a data allocation unit
based on the hardware-aware draft token pruner is developed to minimize energy
consumption and fully exploit parallel execution opportunities. Compared to
end-to-end LLM inference on other mobile solutions such as mobile NPUs or
GEMV-accelerated PIMs, our LP-Spec achieves 13.21x, 7.56x, and 99.87x
improvements in performance, energy efficiency, and energy-delay-product (EDP).
Compared with prior AttAcc PIM and RTX 3090 GPU, LP-Spec can obtain 12.83x and
415.31x EDP reduction benefits.

</details>


### [474] [Tasa: Thermal-aware 3D-Stacked Architecture Design with Bandwidth Sharing for LLM Inference](https://arxiv.org/abs/2508.07252)
*Siyuan He,Peiran Yan,Yandong He,Youwei Zhuo,Tianyu Jia*

Main category: cs.AR

TL;DR: 该研究提出了一种名为Tasa的异构3D堆叠架构，通过热优化和带宽共享调度，解决了LLM推理中的内存瓶颈和热问题，实现了显著的性能提升和温度降低。


<details>
  <summary>Details</summary>
Motivation: 为了更好地利用3D堆叠架构的潜力，并解决其比2D架构更严峻的热问题（包括温度、梯度和可扩展性），本文提出了一种新的架构。

Method: 提出了一种名为Tasa的异构架构，该架构采用跨堆栈热优化来平衡温度分布，并结合高性能核心（用于计算密集型操作）和高效率核心（用于内存密集型操作，如注意力层）。此外，还提出了一种带宽共享调度策略来提高带宽利用率。

Result: Tasa架构实现了显著的性能提升和温度降低。在48、60和72核配置下，峰值温度分别降低了5.55°C、9.37°C和7.91°C。在Llama-65B和GPT-3 66B推理方面，与GPU基线和最先进的异构PIM LLM加速器相比，分别实现了2.85倍和2.21倍的加速。

Conclusion: Tasa架构通过跨堆栈热优化平衡温度分布，最大化热约束下的性能，并提出带宽共享调度以提高异构架构的带宽利用率。实验表明，与同质3D堆叠架构相比，Tasa架构在48、60和72核配置下分别实现了高达5.55°C、9.37°C和7.91°C的峰值温度降低，并证明了其在Llama-65B和GPT-3 66B推理方面比GPU基线和最先进的异构PIM LLM加速器有2.85倍和2.21倍的加速。

Abstract: The autoregressive decoding in LLMs is the major inference bottleneck due to
the memory-intensive operations and limited hardware bandwidth. 3D-stacked
architecture is a promising solution with significantly improved memory
bandwidth, which vertically stacked multi DRAM dies on top of logic die.
However, our experiments also show the 3D-stacked architecture faces severer
thermal issues compared to 2D architecture, in terms of thermal temperature,
gradient and scalability. To better exploit the potential of 3D-stacked
architecture, we present Tasa, a heterogeneous architecture with cross-stack
thermal optimizations to balance the temperature distribution and maximize the
performance under the thermal constraints. High-performance core is designed
for compute-intensive operations, while high-efficiency core is used for
memory-intensive operators, e.g. attention layers. Furthermore, we propose a
bandwidth sharing scheduling to improve the bandwidth utilization in such
heterogeneous architecture. Extensive thermal experiments show that our Tasa
architecture demonstrates greater scalability compared with the homogeneous
3D-stacked architecture, i.e. up to 5.55 $\tccentigrade$, 9.37 $\tccentigrade$,
and 7.91 $\tccentigrade$ peak temperature reduction for 48, 60, and 72 core
configurations. Our experimental for Llama-65B and GPT-3 66B inferences also
demonstrate 2.85x and 2.21x speedup are obtained over the GPU baselines and
state-of-the-art heterogeneous PIM-based LLM accelerator

</details>


### [475] [The Monte Carlo Method and New Device and Architectural Techniques for Accelerating It](https://arxiv.org/abs/2508.07457)
*Janith Petangoda,Chatura Samarakoon,James Meech,Divya Thekke Kanapram,Hamid Toshani,Nathaniel Tye,Vasileios Tsoutsouras,Phillip Stanley-Marbell*

Main category: cs.AR

TL;DR: 新框架和架构技术可处理不确定数据，克服蒙特卡洛方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了安全可靠地处理与现实世界过程交互的计算系统中存在的不确定数据，需要新的方法来克服传统蒙特卡洛采样方法的局限性。

Method: 文章介绍了一个用于描述蒙特卡洛方法的框架，并重点介绍了物理学中基于非均匀随机变量生成器（PPRVGs）的两个最新进展，以克服传统蒙特卡洛采样方法的局限性。同时，文章还探讨了利用分布式微架构状态直接计算概率分布的最新架构技术。

Result: 文章展示了物理学中基于非均匀随机变量生成器（PPRVGs）的两个最新进展，并提出了利用分布式微架构状态直接计算概率分布的架构技术，这些技术无需蒙特卡洛方法即可处理不确定性。

Conclusion: 文章提出了一种处理不确定数据的框架，并重点介绍了物理学中基于非均匀随机变量生成器（PPRVGs）的两个最新进展，以克服传统蒙特卡洛采样方法的局限性。此外，文章还强调了最新的架构技术，这些技术利用分布式的微架构状态直接计算概率分布，从而无需使用蒙特卡洛方法。

Abstract: Computing systems interacting with real-world processes must safely and
reliably process uncertain data. The Monte Carlo method is a popular approach
for computing with such uncertain values. This article introduces a framework
for describing the Monte Carlo method and highlights two advances in the domain
of physics-based non-uniform random variate generators (PPRVGs) to overcome
common limitations of traditional Monte Carlo sampling. This article also
highlights recent advances in architectural techniques that eliminate the need
to use the Monte Carlo method by leveraging distributional microarchitectural
state to natively compute on probability distributions. Unlike Monte Carlo
methods, uncertainty-tracking processor architectures can be said to be
convergence-oblivious.

</details>


### [476] [A Matrix Decomposition Method for Odd-Type Gaussian Normal Basis Multiplication](https://arxiv.org/abs/2508.07541)
*Kittiphon Phalakarn,Athasit Surarerks*

Main category: cs.AR

TL;DR: 提出一种用于奇数类型高斯正规基乘法器的空间复杂度降低技术，以解决现有技术局限性。


<details>
  <summary>Details</summary>
Motivation: 大多数空间复杂度降低技术仅适用于最优正规基或偶数类型高斯正规基，但存在大量使用奇数类型高斯正规基的二元域GF(2^k)。

Method: 该方法借鉴了最优正规基的矩阵分解方法，用于降低GF(2^k)上奇数类型高斯正规基乘法器的空间复杂度。

Result: 与之前的方法相比，该方法可减少XOR门数量，但关键路径延迟略有增加。

Conclusion: 所提出的空间复杂度降低方法与之前的技术相比，可以减少实现中使用的XOR门数量，但关键路径延迟的权衡很小。

Abstract: Normal basis is used in many applications because of the efficiency of the
implementation. However, most space complexity reduction techniques for binary
field multiplier are applicable for only optimal normal basis or Gaussian
normal basis of even type. There are 187 binary fields GF(2^k) for k from 2 to
1,000 that use odd-type Gaussian normal basis. This paper presents a method to
reduce the space complexity of odd-type Gaussian normal basis multipliers over
binary field GF(2^k). The idea is adapted from the matrix decomposition method
for optimal normal basis. The result shows that our space complexity reduction
method can reduce the number of XOR gates used in the implementation comparing
to previous works with a small trade-off in critical path delay.

</details>


### [477] [ARISE: Automating RISC-V Instruction Set Extension](https://arxiv.org/abs/2508.07725)
*Andreas Hager-Clukas,Philipp van Kempen,Stefan Wallentowitz*

Main category: cs.AR

TL;DR: ARISE automates RISC-V instruction generation to optimize code size and instruction count, showing significant improvements on benchmarks.


<details>
  <summary>Details</summary>
Motivation: Optimizing RISC-V for specific requirements is labor-intensive, creating a need for a tool to bridge the gap between software and ISA.

Method: ARISE automates the generation of RISC-V instructions based on assembly patterns and a set of metrics, using CoreDSL for ISA description and integrating with tools like Seal5 and ETISS.

Result: ARISE improves static code size by 1.48%, dynamic code size by 3.84%, and reduces the number of executed instructions by 7.39% on average for Embench-Iot.

Conclusion: ARISE can automate the generation of RISC-V instructions, improving code size and instruction count.

Abstract: RISC-V is an extendable Instruction Set Architecture, growing in popularity
for embedded systems. However, optimizing it to specific requirements, imposes
a great deal of manual effort. To bridge the gap between software and ISA, the
tool ARISE is presented. It automates the generation of RISC-V instructions
based on assembly patterns, which are selected by an extendable set of metrics.
These metrics implement the optimization goals of code size and instruction
count reduction, both statically and dynamically. The instruction set
extensions are generated using the ISA description language CoreDSL. Allowing
seamless embedding in advanced tools such as the retargeting compiler Seal5 or
the instruction set simulator ETISS. ARISE improves the static code size by
1.48% and the dynamic code size by 3.84%, as well as the number of instructions
to be executed by 7.39% on average for Embench-Iot.

</details>


### [478] [TLV-HGNN: Thinking Like a Vertex for Memory-efficient HGNN Inference](https://arxiv.org/abs/2508.07796)
*Dengke Han,Duo Wang,Mingyu Yan,Xiaochun Ye,Dongrui Fan*

Main category: cs.AR

TL;DR: 该研究提出了一种名为 TVL-HGNN 的新硬件加速器，通过优化内存使用和邻居聚合过程，显著提高了 HGNN 推理的速度并降低了能耗。


<details>
  <summary>Details</summary>
Motivation: 现有的异构图神经网络（HGNN）在推理过程中，由于按语义执行模式存储中间结果以及聚合过程中存在大量的冗余内存访问（重复加载目标顶点特征和重复访问共享邻居），导致内存效率低下，严重限制了 HGNN 的可扩展性和推理性能。

Method: 提出了一种基于顶点视角、消除语义间冗余存储和访问的语义完整执行模式。设计了一个名为 TVL-HGNN 的可重构硬件加速器，并引入了一种基于跨语义邻居重叠的顶点分组技术，以减少冗余的邻居访问。

Result: TVL-HGNN 在平均加速方面比 NVIDIA A100 GPU 快 7.85 倍，比最先进的 HGNN 加速器 HiHGNN 快 1.41 倍，同时能耗分别降低了 98.79% 和 32.61%。

Conclusion: TVL-HGNN 通过采用语义无关的执行模式和优化的聚合设计，在内存效率和性能方面取得了显著的改进，实现了比 A100 GPU 高 7.85 倍的平均加速，并大幅降低了能耗。

Abstract: Heterogeneous graph neural networks (HGNNs) excel at processing heterogeneous
graph data and are widely applied in critical domains. In HGNN inference, the
neighbor aggregation stage is the primary performance determinant, yet it
suffers from two major sources of memory inefficiency. First, the commonly
adopted per-semantic execution paradigm stores intermediate aggregation results
for each semantic prior to semantic fusion, causing substantial memory
expansion. Second, the aggregation process incurs extensive redundant memory
accesses, including repeated loading of target vertex features across semantics
and repeated accesses to shared neighbors due to cross-semantic neighborhood
overlap. These inefficiencies severely limit scalability and reduce HGNN
inference performance.
  In this work, we first propose a semantics-complete execution paradigm from a
vertex perspective that eliminates per-semantic intermediate storage and
redundant target vertex accesses. Building on this paradigm, we design
TVL-HGNN, a reconfigurable hardware accelerator optimized for efficient
aggregation. In addition, we introduce a vertex grouping technique based on
cross-semantic neighborhood overlap, with hardware implementation, to reduce
redundant accesses to shared neighbors. Experimental results demonstrate that
TVL-HGNN achieves average speedups of 7.85x and 1.41x over the NVIDIA A100 GPU
and the state-of-the-art HGNN accelerator HiHGNN, respectively, while reducing
energy consumption by 98.79% and 32.61%.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [479] [On the fault diameter and wide diameter of the exchanged 3-ary $n$-cube](https://arxiv.org/abs/2508.07174)
*Rongshuan Geng,Wantao Ning*

Main category: cs.LO

TL;DR: 分析了3-ary n-cube的故障直径和宽直径。


<details>
  <summary>Details</summary>
Motivation: 需要评估互连网络的通信性能，特别是故障容错能力和传输效率，引入了3-ary n-cube（E3C(r, s, t)）作为研究对象。

Method: 推导了3-ary n-cube的故障直径和宽直径。

Result: 得到了E3C(r, s, t)在1 <= r <= s <= t条件下的故障直径的界限为n+3到n+5，宽直径的界限为n+3到n+5。

Conclusion: 3-ary n-cube的(2r+1)故障直径和(2r+2)宽直径在r<=s<=t时界于n+3和n+5之间。

Abstract: Fault diameter and wide diameter are two critical parameters for evaluating
communication performance in interconnection networks. They measure the fault
tolerance and transmission efficiency of networks. The exchanged 3-ary $n$-cube
is a recently proposed variant of the hypercube, denoted by $E3C(r, s, t)$. In
this work, we obtain that the $(2r + 1)$-fault diameter and $(2r + 2)$-wide
diameter of $E3C(r, s, t)$ are bounded between $n + 3$ and $n + 5$ for $1 \leq
r \leq s \leq t$.

</details>


### [480] [Presburger Functional Synthesis: Complexity and Tractable Normal Forms](https://arxiv.org/abs/2508.07207)
*S. Akshay,A. R. Balasubramanian,Supratik Chakraborty,Georg Zetzsche*

Main category: cs.LO

TL;DR: 本文研究 Presburger 算术下的函数合成问题 (PFnS)，证明其为 EXPTIME 完全问题，并提出 PSyNF 范式可实现多项式时间求解。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究 Presburger 算术下的函数合成问题（PFnS），并探索其计算复杂性。研究动机在于了解 PFnS 问题相对于其他理论（如布尔逻辑）下的函数合成问题的异同，特别是其计算复杂度以及是否存在更高效的求解方法。同时，研究也希望为 Presburger 算术下的函数合成提供理论基础和实际可行的解决方案。

Method: 本文首先将 Presburger 算术下的函数合成问题（PFnS）建模为逻辑公式，然后证明了该问题可以在 EXPTIME 中解决，并给出了相应的指数级下界。接着，文章将单个输入输出变量的 PFnS 问题与一般的布尔函数合成问题（BFnS）进行了难度比较。随后，提出了一种名为 PSyNF 的范式，并证明了满足此范式的 PFnS 问题具有多项式时间与多项式空间可解性。文章还对 PSyNF 的性质进行了证明，包括如何检查和编译到该范式，以及与其他保证多项式时间可解性的范式的编译关系。最后，提出了一种语法范式，并分析了其与 PSyNF 的规模和检查复杂度差异。

Result: PFnS 问题可在 EXPTIME 中解决，并具有指数级下界。单个输入输出变量的 PFnS 问题与 BFnS 问题难度相当。PSyNF 范式可保证 PFnS 的多项式时间与多项式空间可解性。文章还提供了关于 PSyNF 的检查、编译方法以及与其他范式的关系。

Conclusion: 本文研究了 Presburger 算术下的函数合成问题（PFnS），证明了其可解性在 EXPTIME 中，并给出了匹配的指数级下界。此外，研究还表明，单个输入输出变量的 PFnS 问题与一般的布尔函数合成问题（BFnS）具有相同的难度。文章还提出了一种名为 PSyNF 的范式，该范式能够保证 PFnS 的多项式时间与多项式空间可解性，并对 PSyNF 的性质进行了深入分析，包括其检查和编译方法，以及与其他保证多项式时间可解性的范式的关系。最后，文章识别了一种更易于检查但规模可能呈指数级增长的语法范式。

Abstract: Given a relational specification between inputs and outputs as a logic
formula, the problem of functional synthesis is to automatically synthesize a
function from inputs to outputs satisfying the relation. Recently, a rich line
of work has emerged tackling this problem for specifications in different
theories, from Boolean to general first-order logic. In this paper, we launch
an investigation of this problem for the theory of Presburger Arithmetic, that
we call Presburger Functional Synthesis (PFnS). We show that PFnS can be solved
in EXPTIME and provide a matching exponential lower bound. This is unlike the
case for Boolean functional synthesis (BFnS), where only conditional
exponential lower bounds are known. Further, we show that PFnS for one input
and one output variable is as hard as BFnS in general. We then identify a
special normal form, called PSyNF, for the specification formula that
guarantees poly-time and poly-size solvability of PFnS. We prove several
properties of PSyNF, including how to check and compile to this form, and
conditions under which any other form that guarantees poly-time solvability of
PFnS can be compiled in poly-time to PSyNF. Finally, we identify a syntactic
normal form that is easier to check but is exponentially less succinct than
PSyNF.

</details>


### [481] [From Knowledge to Conjectures: A Modal Framework for Reasoning about Hypotheses](https://arxiv.org/abs/2508.07304)
*Fabio Vitali*

Main category: cs.LO

TL;DR: 本文提出了一种新的认知模态逻辑，用于形式化猜想推理，通过引入公理C和副完备语义来避免模态坍塌，并能区分事实与猜想。


<details>
  <summary>Details</summary>
Motivation: 本文旨在形式化猜想推理，这是一种在认知情境中，通过加入假设性假设来探索其后果的推理方式。现有的认知系统（如义务逻辑和认知逻辑）在处理这种推理时存在局限性，特别是在区分事实和假设时容易导致模态坍塌。

Method: 本文提出了一种新的认知模态逻辑，该逻辑扩展了已知的知识，并加入了假设性假设以探索其后果。该逻辑的关键在于公理C（φ→□φ），它确保所有已建立的事实能够跨越假设层。为了避免模态坍塌，本文放弃了公理T，并采用了一个基于弱克莱尼逻辑或描述逻辑的副完备语义框架，允许未定义命题与模态断言共存。

Result: 本文成功构建了新的模态系统KC和KDC，并证明了它们是完备的、可判定的，并且在部分知识下是稳健的。研究表明，在副完备的语义框架下，公理C不会导致模态坍塌。最后，引入了“settle(φ)”操作来形式化从猜想到事实的转变。

Conclusion: 本文提出的认知模态逻辑通过引入公理C（φ→□φ）并结合非经典（特别是副完备）的语义框架，成功地解决了模态坍塌问题，从而能够区分事实和猜想陈述。新的模态系统KC和KDC被证明是完备、可判定且在部分知识下是稳健的。此外，通过引入动态操作“settle(φ)”，该逻辑能够形式化从猜想到被接受事实的过渡，捕捉认知状态更新的过程。

Abstract: This paper introduces a new family of cognitive modal logics designed to
formalize conjectural reasoning: a modal system in which cognitive contexts
extend known facts with hypothetical assumptions to explore their consequences.
Unlike traditional doxastic and epistemic systems, conjectural logics rely on a
principle, called Axiom C ($\varphi \rightarrow \Box\varphi$), that ensures
that all established facts are preserved across hypothetical layers. While
Axiom C was dismissed in the past due to its association with modal collapse,
we show that the collapse only arises under classical and bivalent assumptions,
and specifically in the presence of Axiom T. Hence we avoid Axiom T and adopt a
paracomplete semantic framework, grounded in Weak Kleene logic or Description
Logic, where undefined propositions coexist with modal assertions. This
prevents the modal collapse and guarantees a layering to distinguish between
factual and conjectural statements. Under this framework we define new modal
systems, e.g., KC and KDC, and show that they are complete, decidable, and
robust under partial knowledge. Finally, we introduce a dynamic operation,
$\mathsf{settle}(\varphi)$, which formalizes the transition from conjecture to
accepted fact, capturing the event of the update of a world's cognitive state
through the resolution of uncertainty.

</details>


### [482] [A Rule-Based Approach to Specifying Preferences over Conflicting Facts and Querying Inconsistent Knowledge Bases](https://arxiv.org/abs/2508.07742)
*Meghyn Bienvenu,Camille Bourgaux,Katsumi Inoue,Robin Jean*

Main category: cs.LO

TL;DR: 该研究提出了一种声明式的、基于规则的框架，用于处理不一致知识库中的事实优先级，并通过答案集编程实现了一个端到端系统。


<details>
  <summary>Details</summary>
Motivation: 在修复基础语义被广泛研究用以获得不一致知识库查询的有效答案时，关于如何利用事实间的优先级关系来选择最优修复的研究仍未得到充分解决。这促使我们提出一个声明式的、基于规则的框架，以指定和计算事实间的优先级关系。

Method: 提出了一种声明式的、基于规则的框架，用于指定和计算冲突事实之间的优先级关系，并考虑了偏好规则可能包含不期望的冲突，以及确定偏好规则集何时产生无环关系，并通过应用各种冲突消除技术提取无环关系。

Result: 该框架使用答案集编程来评估偏好规则，应用冲突解决技术获得优先级关系，并在优先修复语义下回答查询。

Conclusion: 所提出的框架通过使用答案集编程来评估偏好规则，应用所需的冲突解决技术来获得优先级关系，并在优先修复语义下回答查询，从而为查询不一致的知识库提供了一个端到端系统的初步实现和实验评估。

Abstract: Repair-based semantics have been extensively studied as a means of obtaining
meaningful answers to queries posed over inconsistent knowledge bases (KBs).
While several works have considered how to exploit a priority relation between
facts to select optimal repairs, the question of how to specify such
preferences remains largely unaddressed. This motivates us to introduce a
declarative rule-based framework for specifying and computing a priority
relation between conflicting facts. As the expressed preferences may contain
undesirable cycles, we consider the problem of determining when a set of
preference rules always yields an acyclic relation, and we also explore a
pragmatic approach that extracts an acyclic relation by applying various cycle
removal techniques. Towards an end-to-end system for querying inconsistent KBs,
we present a preliminary implementation and experimental evaluation of the
framework, which employs answer set programming to evaluate the preference
rules, apply the desired cycle resolution techniques to obtain a priority
relation, and answer queries under prioritized-repair semantics.

</details>


### [483] [Runtime Verification for LTL in Stochastic Systems](https://arxiv.org/abs/2508.07963)
*Javier Esparza,Vincent Fischer*

Main category: cs.LO

TL;DR: 提出了一种新的运行时验证方法，用概率预测和置信度分数取代硬性判断，解决了传统方法在处理活性属性时的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的运行时验证器（monitor）在每一步只输出三个结果之一：真、假或不确定。然而，对于许多LTL（线性时序逻辑）公式，特别是活性属性，无法从有限的前缀确定满足性，导致传统监控器总是输出不确定。这促使我们需要一种新的方法。

Method: 提出了一种新颖的监控方法，用概率预测和相关的置信度分数来取代硬性判断。

Result: 该方法生成的预测是最终正确的，并且置信度会随着时间的推移而不断提高。

Conclusion: 该方法通过提供概率预测和置信度分数来替换硬性判断，能够保证预测的最终正确性，并确保在此之后置信度无界增长。

Abstract: Runtime verification encompasses several lightweight techniques for checking
whether a system's current execution satisfies a given specification. We focus
on runtime verification for Linear Temporal Logic (LTL). Previous work
describes monitors which produce, at every time step one of three outputs -
true, false, or inconclusive - depending on whether the observed execution
prefix definitively determines satisfaction of the formula. However, for many
LTL formulas, such as liveness properties, satisfaction cannot be concluded
from any finite prefix. For these properties traditional monitors will always
output inconclusive. In this work, we propose a novel monitoring approach that
replaces hard verdicts with probabilistic predictions and an associated
confidence score. Our method guarantees eventual correctness of the prediction
and ensures that confidence increases without bound from that point on.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [484] [PiKV: KV Cache Management System for Mixture of Experts](https://arxiv.org/abs/2508.06526)
*Dong Liu,Yanxuan Yu,Ben Lengerich,Ying Nian Wu,Xuhong Wang*

Main category: cs.DC

TL;DR: PiKV is an open-source framework that optimizes KV cache serving for Mixture-of-Experts (MoE) models by sharding, routing, scheduling, and compressing caches, thus reducing memory and communication overhead during inference.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the memory and communication cost of KV cache storage, which has become a major bottleneck in multi-GPU and multi-node inference for large language models, especially in MoE-based architectures where KV caches remain dense and globally synchronized.

Method: PiKV utilizes expert-sharded KV storage to partition caches across GPUs, PiKV routing to reduce token-to-KV access, PiKV scheduling to adaptively retain query-relevant entries, and PiKV compression modules to reduce memory usage.

Result: PiKV reduces the memory and communication cost of KV cache storage, leading to acceleration in inference.

Conclusion: PiKV is a parallel and distributed KV cache serving framework tailored for MoE architecture, which addresses the memory and communication cost bottleneck in large language models by leveraging expert-sharded KV storage, PiKV routing, PiKV scheduling, and PiKV compression. The project is open-source and aims to become a comprehensive KV cache management system for MoE architectures.

Abstract: As large language models continue to scale up in both size and context
length, the memory and communication cost of key-value (KV) cache storage has
become a major bottleneck in multi-GPU and multi-node inference. While
MoE-based architectures sparsify computation across experts, the corresponding
KV caches remain dense and globally synchronized, resulting in significant
overhead.
  We introduce \textbf{PiKV}, a parallel and distributed KV cache serving
framework tailored for MoE architecture. PiKV leverages \textit{expert-sharded
KV storage} to partition caches across GPUs, \textit{PiKV routing} to reduce
token-to-KV access, and a \textit{PiKV Scheduling} to adaptively retain
query-relevant entries. To further reduce memory usage, PiKV integrates
\textit{PiKV Compression} modules the caching pipeline for acceleration.
  PiKV is recently publicly available as an open-source software library:
\href{https://github.com/NoakLiu/PiKV}{https://github.com/NoakLiu/PiKV}.
Experiments details is recorded at:
\href{https://github.com/NoakLiu/PiKV/blob/main/downstream_tasks/README.md}{https://github.com/NoakLiu/PiKV/Experimental\_Results}.
We also have PiKV integrated with Nvidia kvpress for acceleration, details see
\href{https://github.com/NoakLiu/PiKVpress}{https://github.com/NoakLiu/PiKVpress}.
PiKV is still a living project, aiming to become a comprehesive KV Cache
management system for MoE Architectures.

</details>


### [485] [Kairos: Low-latency Multi-Agent Serving with Shared LLMs and Excessive Loads in the Public Cloud](https://arxiv.org/abs/2508.06948)
*Jinyuan Chen,Jiuchen Shi,Quan Chen,Minyi Guo*

Main category: cs.DC

TL;DR: Kairos是一个多智能体编排系统，通过工作流感知调度和内存感知分派来优化LLM服务，有效降低了多智能体应用的端到端延迟。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM服务方法未能考虑智能体间延迟和资源差异，导致服务性能低下，并使共享LLM面临过载。

Method: Kairos是一个多智能体编排系统，包含工作流编排器、工作流感知优先级调度器和内存感知分派器。工作流编排器收集特定智能体信息进行在线工作流分析；调度器根据请求的延迟特性决定服务优先级以减少整体排队；分派器根据内存需求将请求分派到不同的LLM实例，以避免GPU过载。

Result: 实验结果表明，Kairos与现有技术相比，端到端延迟降低了17.8%至28.4%。

Conclusion: Kairos通过优化端到端延迟，在多智能体应用中相比现有技术将延迟降低了17.8%至28.4%。

Abstract: Multi-agent applications utilize the advanced capabilities of large language
models (LLMs) for intricate task completion through agent collaboration in a
workflow. Under this situation, requests from different agents usually access
the same shared LLM to perform different kinds of tasks, forcing the shared LLM
to suffer excessive loads. However, existing works have low serving performance
for these multi-agent applications, mainly due to the ignorance of inter-agent
latency and resource differences for request scheduling. We therefore propose
Kairos, a multi-agent orchestration system that optimizes end-to-end latency
for multi-agent applications. Kairos consists of a workflow orchestrator, a
workflow-aware priority scheduler, and a memory-aware dispatcher. The
orchestrator collects agent-specific information for online workflow analysis.
The scheduler decides the serving priority of the requests based on their
latency characteristics to reduce the overall queuing. The dispatcher
dispatches the requests to different LLM instances based on their memory
demands to avoid GPU overloading. Experimental results show that Kairos reduces
end-to-end latency by 17.8% to 28.4% compared to state-of-the-art works.

</details>


### [486] [Convergence Sans Synchronization](https://arxiv.org/abs/2508.06949)
*Arya Tanmay Gupta*

Main category: cs.DC

TL;DR: 论文提出理论简化了异步算法收敛性证明，开发了无需同步的算法并改进了现有算法，实验证明异步执行更高效。


<details>
  <summary>Details</summary>
Motivation: 现有的并行处理算法大多需要同步机制，而同步机制会消耗大量的计算资源和时间。如果算法能够在异步状态下执行，则可以充分利用所有计算能力，并且节点无需调度或锁定即可执行。

Method: 提出了一套理论，证明了局部状态转移图构成偏序是异步算法收敛的充要条件，并基于此理论开发了无需同步的算法，同时改进了现有算法以支持异步执行。

Result: 开发了无需同步的算法，改进了现有算法以支持异步执行，并通过实验证明了异步执行显著减少了收敛时间。

Conclusion: 该论文提出了一个理论，能够显著降低证明异步算法收敛性的复杂性，只需要证明局部状态转移图构成偏序即可，而无需生成全局状态转移图并检查是否存在环。此外，论文还设计了多种无需同步的算法，并改进了现有算法以支持异步执行，实验证明了异步执行带来的时间效率提升。

Abstract: We currently see a steady rise in the usage and size of multiprocessor
systems, and so the community is evermore interested in developing fast
parallel processing algorithms. However, most algorithms require a
synchronization mechanism, which is costly in terms of computational resources
and time. If an algorithm can be executed in asynchrony, then it can use all
the available computation power, and the nodes can execute without being
scheduled or locked. However, to show that an algorithm guarantees convergence
in asynchrony, we need to generate the entire global state transition graph and
check for the absence of cycles. This takes time exponential in the size of the
global state space. In this dissertation, we present a theory that explains the
necessary and sufficient properties of a multiprocessor algorithm that
guarantees convergence even without synchronization. We develop algorithms for
various problems that do not require synchronization. Additionally, we show for
several existing algorithms that they can be executed without any
synchronization mechanism. A significant theoretical benefit of our work is in
proving that an algorithm can converge even in asynchrony. Our theory implies
that we can make such conclusions about an algorithm, by only showing that the
local state transition graph of a computing node forms a partial order, rather
than generating the entire global state space and determining the absence of
cycles in it. Thus, the complexity of rendering such proofs, formal or social,
is phenomenally reduced. Experiments show a significant reduction in time taken
to converge, when we compare the execution time of algorithms in the literature
versus the algorithms that we design. We get similar results when we run an
algorithm, that guarantees convergence in asynchrony, under a scheduler versus
in asynchrony.

</details>


### [487] [The Fused Kernel Library: A C++ API to Develop Highly-Efficient GPU Libraries](https://arxiv.org/abs/2508.07071)
*Oscar Amoros,Albert Andaluz,Johnny Nunez,Antonio J. Pena*

Main category: cs.DC

TL;DR: 一种新的 GPU 库构建方法，通过 C++17 元编程自动按需融合 GPU 函数内核，优化性能并降低开发成本。


<details>
  <summary>Details</summary>
Motivation: 现有的 GPU 库在链接多个 GPU 函数作为独立内核时，往往难以充分利用 GPU 的并行资源和片上内存 (SRAM)。目前的内核融合 (KF) 技术，如水平融合 (HF) 和垂直融合 (VF)，虽然可以缓解这一问题，但通常需要库开发者手动创建融合内核，导致库用户只能依赖有限的预编译或基于模板的融合内核，限制了应用场景并增加了开发成本。

Method: 提出了一种新的 GPU 库构建方法，通过定义可重用的、可融合的组件，并利用 C++17 元编程特性，在编译时自动按需进行水平融合 (HF) 和垂直融合 (VF)，生成针对用户特定操作序列进行优化的单一融合内核，无需自定义编译器或手动开发预编译的内核组合。

Result: 提供了一个开源实现，该实现能够自动按需进行任意 GPU 库函数组合的 HF 和 VF，与传统库相比，在各种基准测试中实现了 2 倍到 1000 倍以上的显著速度提升，证明了该方法在提高 GPU 性能和保持高级可编程性方面的有效性。

Conclusion: 通过利用 C++17 元编程特性，该方法能够在编译时自动生成定制化的融合内核，从而优化 GPU 资源利用率，将中间数据保留在 SRAM 中，并在各种基准测试中与传统库相比实现了 2 倍到 1000 倍以上的显著加速，同时保持了高级可编程性。

Abstract: Existing GPU libraries often struggle to fully exploit the parallel resources
and on-chip memory (SRAM) of GPUs when chaining multiple GPU functions as
individual kernels. While Kernel Fusion (KF) techniques like Horizontal Fusion
(HF) and Vertical Fusion (VF) can mitigate this, current library
implementations often require library developers to manually create fused
kernels. Hence, library users rely on limited sets of pre-compiled or
template-based fused kernels. This limits the use cases that can benefit from
HF and VF and increases development costs. In order to solve these issues, we
present a novel methodology for building GPU libraries that enables automatic
on-demand HF and VF for arbitrary combinations of GPU library functions. Our
methodology defines reusable, fusionable components that users combine via
high-level programming interfaces. Leveraging C++17 metaprogramming features
available in compilers like nvcc, our methodology generates a single and
optimized fused kernel tailored to the user's specific sequence of operations
at compile time, without needing a custom compiler or manual development and
pre-compilation of kernel combinations. This approach abstracts low-level GPU
complexities while maximizing GPU resource utilization and keeping intermediate
data in SRAM. We provide an open-source implementation demonstrating
significant speedups compared to traditional libraries in various benchmarks,
validating the effectiveness of this methodology for improving GPU performance
in the range of 2x to more than 1000x, while preserving high-level
programmability.

</details>


### [488] [AerialDB: A Federated Peer-to-Peer Spatio-temporal Edge Datastore for Drone Fleets](https://arxiv.org/abs/2508.07124)
*Shashwat Jaiswal,Suman Raj,Subhajit Sidhanta,Yogesh Simmhan*

Main category: cs.DC

TL;DR: AerialDB是一个为无人机群设计的轻量级、去中心化时空数据存储和查询系统，能有效处理海量数据，性能优于现有技术和云方案。


<details>
  <summary>Details</summary>
Motivation: 随着无人机（UAV）在监测和分析等任务中得到广泛应用，特别是在灾难区域等动态环境中，UAV收集的数据量（如视频和图像）通常超过其板载计算机的处理能力。因此，需要一种系统能够实时将数据卸载到边缘和云端进行处理。

Method: 提出了一种名为AerialDB的轻量级、去中心化的数据存储和查询系统，该系统专为多UAV系统设计，能够存储和处理时序数据。该方法利用了轻量级的基于内容的副本放置和分片索引技术，并优化了空间和时间查询的处理。系统包括一个包含数百架UAV的机队和一个通过蜂窝网络连接的地面边缘服务器。它还包含一个去中心化、面向本地的分布式执行引擎，能够优雅地处理边缘故障。

Result: 在包含多达400架无人机和80个边缘服务器的容器化部署中，AerialDB能够高效扩展并提供近乎实时的性能。与现有技术基线相比，AerialDB的插入性能相当，查询性能提高了100倍。与云基线相比，在插入和查询工作负载下，AerialDB的性能分别提高了10倍和100倍。

Conclusion: AerialDB通过利用轻量级的基于内容的副本放置和分片索引技术，为多UAV系统中的时空数据存储和处理进行了优化，在真实灾难管理场景下，能够高效处理空间和时间查询。该系统在高达400架无人机和80个边缘服务器的容器化部署中，展现了良好的可扩展性和近乎实时的性能，即使在边缘故障下也能提供性能的优雅降级和较低的延迟。与现有技术相比，AerialDB在插入性能方面相当，查询性能提高了100倍，并且在插入和查询工作负载方面分别比云基线提高了10倍和100倍。

Abstract: Recent years have seen an unprecedented growth in research that leverages the
newest computing paradigm of Internet of Drones, comprising a fleet of
connected Unmanned Aerial Vehicles (UAVs) used for a wide range of tasks such
as monitoring and analytics in highly mobile and changing environments
characteristic of disaster regions. Given that the typical data (i.e., videos
and images) collected by the fleet of UAVs deployed in such scenarios can be
considerably larger than what the onboard computers can process, the UAVs need
to offload their data in real-time to the edge and the cloud for further
processing. To that end, we present the design of AerialDB - a lightweight
decentralized data storage and query system that can store and process time
series data on a multi-UAV system comprising: A) a fleet of hundreds of UAVs
fitted with onboard computers, and B) ground-based edge servers connected
through a cellular link. Leveraging lightweight techniques for content-based
replica placement and indexing of shards, AerialDB has been optimized for
efficient processing of different possible combinations of typical spatial and
temporal queries performed by real-world disaster management applications.
Using containerized deployment spanning up to 400 drones and 80 edges, we
demonstrate that AerialDB is able to scale efficiently while providing near
real-time performance with different realistic workloads. Further, AerialDB
comprises a decentralized and locality-aware distributed execution engine which
provides graceful degradation of performance upon edge failures with relatively
low latency while processing large spatio-temporal data. AerialDB exhibits
comparable insertion performance and 100 times improvement in query performance
against state-of-the-art baseline. Moreover, it exhibits a 10 times and 100
times improvement with insertion and query workloads respectively over the
cloud baseline.

</details>


### [489] [FlashMP: Fast Discrete Transform-Based Solver for Preconditioning Maxwell's Equations on GPUs](https://arxiv.org/abs/2508.07193)
*Haoyuan Zhang,Yaqian Gao,Xinxin Zhang,Jialin Li,Runfeng Jin,Yidong Chen,Feng Zhang,Wu Yuan,Wenpeng Ma,Shan Liang,Jian Zhang,Zhonghua Lu*

Main category: cs.DC

TL;DR: FlashMP是一种新的预处理系统，使用基于离散变换的子域精确求解器来加速大规模线性系统在GPU上的求解。


<details>
  <summary>Details</summary>
Motivation: 解决电磁模拟中，特别是使用CN-FDTD方法时，大规模线性系统求解效率低下的问题，现有迭代求解器的收敛速度慢，直接求解器内存需求过大。

Method: 提出了一种基于离散变换的子域精确求解器，并实现了多GPU可扩展性。

Result: FlashMP将迭代次数减少了高达16倍，并与Hypre等库相比实现了2.5倍至4.9倍的加速，在1000个GPU上表现出高达84.1%的并行效率。

Conclusion: FlashMP通过基于离散变换的子域精确求解器有效地解决了大规模线性系统问题，并在GPU集群上实现了出色的可扩展性和性能提升。

Abstract: Efficiently solving large-scale linear systems is a critical challenge in
electromagnetic simulations, particularly when using the Crank-Nicolson
Finite-Difference Time-Domain (CN-FDTD) method. Existing iterative solvers are
commonly employed to handle the resulting sparse systems but suffer from slow
convergence due to the ill-conditioned nature of the double-curl operator.
Approximate preconditioners, like Successive Over-Relaxation (SOR) and
Incomplete LU decomposition (ILU), provide insufficient convergence, while
direct solvers are impractical due to excessive memory requirements. To address
this, we propose FlashMP, a novel preconditioning system that designs a
subdomain exact solver based on discrete transforms. FlashMP provides an
efficient GPU implementation that achieves multi-GPU scalability through domain
decomposition. Evaluations on AMD MI60 GPU clusters (up to 1000 GPUs) show that
FlashMP reduces iteration counts by up to 16x and achieves speedups of 2.5x to
4.9x compared to baseline implementations in state-of-the-art libraries such as
Hypre. Weak scalability tests show parallel efficiencies up to 84.1%.

</details>


### [490] [An Experimental Exploration of In-Memory Computing for Multi-Layer Perceptrons](https://arxiv.org/abs/2508.07317)
*Pedro Carrinho,Hamid Moghadaspour,Oscar Ferraz,João Dinis Ferreira,Yann Falevoz,Vitor Silva,Gabriel Falcao*

Main category: cs.DC

TL;DR: 在处理内存（PiM）的帮助下，神经网络的性能可以得到提升。


<details>
  <summary>Details</summary>
Motivation: 解决内存密集型工作负载（如机器学习）面临的数据移动瓶颈问题，探索处理内存（PiM）技术在加速神经网络方面的潜力。

Method: 分析了现代通用处理内存（PiM）架构加速神经网络的潜力。选择了 UPMEM PiM 系统，并将其多层感知机（MLP）的实现与在 Intel Xeon CPU 上的顺序基线进行了比较。此外，还使用 UPMEM 的工作 SRAM（WRAM）实现了两个较小的 MLP，并与低功耗 Nvidia Jetson GPU 进行了性能评估。

Result: UPMEM PiM 实现的 MLP 在大批量推理方面比 CPU 快 259 倍。使用 WRAM 的 MLP 推理内核执行时间不到 3 毫秒，与低功耗 GPU 处于同一数量级。

Conclusion: UPMEM PiM 系统在处理神经网络方面具有潜力，尤其是在利用其大容量内存和 WRAM 时，可以与低功耗 GPU 媲美。

Abstract: In modern computer architectures, the performance of many memory-bound
workloads (e.g., machine learning, graph processing, databases) is limited by
the data movement bottleneck that emerges when transferring large amounts of
data between the main memory and the central processing unit (CPU).
Processing-in-memory is an emerging computing paradigm that aims to alleviate
this data movement bottleneck by performing computation close to or within the
memory units, where data resides. One example of a prevalent workload whose
performance is bound by the data movement bottleneck is the training and
inference process of artificial neural networks. In this work, we analyze the
potential of modern general-purpose PiM architectures to accelerate neural
networks. To this end, we selected the UPMEM PiM system, the first commercially
available real-world general-purpose PiM architecture. We compared the
implementation of multilayer perceptrons (MLPs) in PiM with a sequential
baseline running on an Intel Xeon CPU. The UPMEM implementation achieves up to
$259\times$ better performance for inference of large batch sizes when compared
against the CPU that exploits the size of the available PiM memory.
Additionally, two smaller MLPs were implemented using UPMEM's working SRAM
(WRAM), a scratchpad memory, to evaluate their performance against a low-power
Nvidia Jetson graphics processing unit (GPU), providing further insights into
the efficiency of UPMEM's PiM for neural network inference. Results show that
using WRAM achieves kernel execution times for MLP inference of under $3$ ms,
which is within the same order of magnitude as low-power GPUs.

</details>


### [491] [On the Efficiency of Dynamic Transaction Scheduling in Blockchain Sharding](https://arxiv.org/abs/2508.07472)
*Ramesh Adhikari,Costas Busch,Miroslav Popovic*

Main category: cs.DC

TL;DR: 该研究针对区块链分片系统的动态调度问题，提出了新的算法并分析了其性能，在提高交易处理效率方面取得了理论突破。


<details>
  <summary>Details</summary>
Motivation: 为了解决区块链分片系统中交易处理速度的瓶颈，研究动态调度问题，以提高交易处理效率。

Method: 研究了动态调度问题，提出了适用于不同d值的局部敏感分解，并分别在无状态和有状态模型中进行了分析，证明了相应的竞争比界限。对状态相关模型，还证明了近似最优调度的NP-hard性质。

Result: 在无状态模型中，证明了竞争比为O(d log^2 s * min{k, sqrt{s}})；在有状态模型中，证明了竞争比为O(log s * min{k, sqrt{s}} + log^2 s)。证明了近似最优调度（在min{k, sqrt{s}}）^(1-ε)因子内是NP-hard的。

Conclusion: 该研究首次为区块链分片系统建立了可证明的高效动态调度算法，并将状态相关模型中的界限在多对数因子内推向了最优可能实现的下界。

Abstract: Sharding is a technique to speed up transaction processing in blockchains,
where the $n$ processing nodes in the blockchain are divided into $s$ disjoint
groups (shards) that can process transactions in parallel. We study dynamic
scheduling problems on a shard graph $G_s$ where transactions arrive online
over time and are not known in advance. Each transaction may access at most $k$
shards, and we denote by $d$ the worst distance between a transaction and its
accessing (destination) shards (the parameter $d$ is unknown to the shards). To
handle different values of $d$, we assume a locality sensitive decomposition of
$G_s$ into clusters of shards, where every cluster has a leader shard that
schedules transactions for the cluster. We first examine the simpler case of
the stateless model, where leaders are not aware of the current state of the
transaction accounts, and we prove a $O(d \log^2 s \cdot \min\{k, \sqrt{s}\})$
competitive ratio for latency. We then consider the stateful model, where
leader shards gather the current state of accounts, and we prove a $O(\log
s\cdot \min\{k, \sqrt{s}\}+\log^2 s)$ competitive ratio for latency. Each
leader calculates the schedule in polynomial time for each transaction that it
processes. We show that for any $\epsilon > 0$, approximating the optimal
schedule within a $(\min\{k, \sqrt{s}\})^{1 -\epsilon}$ factor is NP-hard.
Hence, our bound for the stateful model is within a poly-log factor from the
best possibly achievable. To the best of our knowledge, this is the first work
to establish provably efficient dynamic scheduling algorithms for blockchain
sharding systems.

</details>


### [492] [Coordinated Power Management on Heterogeneous Systems](https://arxiv.org/abs/2508.07605)
*Zhong Zheng,Michael E. Papka,Zhiling Lan*

Main category: cs.DC

TL;DR: OPEN是一个框架，用于在异构计算系统（包括CPU和GPU）中进行节能的性能预测。它通过结合离线阶段的性能预测器和在线阶段的轻量级性能分析，实现了高准确率（高达98.29%）和低分析成本，适用于节能计算。


<details>
  <summary>Details</summary>
Motivation: 传统的性能建模方法依赖于详尽的离线性能分析，但由于设置空间大且分析成本高，对于大规模应用程序不实用。因此，需要一种更有效的方法来预测性能。

Method: OPEN框架包含离线和在线两个阶段。离线阶段构建性能预测器并构造初始稠密矩阵。在线阶段，OPEN执行轻量级的在线性能分析，并利用性能预测器和协同过滤进行性能预测。

Result: OPEN在异构系统上的评估结果显示，其预测准确率高达98.29%，有效降低了分析成本，同时保持了高准确性，可用于现代HPC环境的节能性能建模。

Conclusion: OPEN通过在异构系统上进行评估，在A100和A30 GPU上实现了高达98.29%的预测准确率，有效降低了性能分析成本，同时保持了高准确性，适用于现代高性能计算环境中的节能性能建模。

Abstract: Performance prediction is essential for energy-efficient computing in
heterogeneous computing systems that integrate CPUs and GPUs. However,
traditional performance modeling methods often rely on exhaustive offline
profiling, which becomes impractical due to the large setting space and the
high cost of profiling large-scale applications. In this paper, we present
OPEN, a framework consists of offline and online phases. The offline phase
involves building a performance predictor and constructing an initial dense
matrix. In the online phase, OPEN performs lightweight online profiling, and
leverages the performance predictor with collaborative filtering to make
performance prediction. We evaluate OPEN on multiple heterogeneous systems,
including those equipped with A100 and A30 GPUs. Results show that OPEN
achieves prediction accuracy up to 98.29\%. This demonstrates that OPEN
effectively reduces profiling cost while maintaining high accuracy, making it
practical for power-aware performance modeling in modern HPC environments.
Overall, OPEN provides a lightweight solution for performance prediction under
power constraints, enabling better runtime decisions in power-aware computing
environments.

</details>


### [493] [Taming Cold Starts: Proactive Serverless Scheduling with Model Predictive Control](https://arxiv.org/abs/2508.07640)
*Chanh Nguyen,Monowar Bhuyan,Erik Elmroth*

Main category: cs.DC

TL;DR: 该框架使用模型预测控制来预测未来的调用，以主动缓解冷启动问题，从而提高响应时间。


<details>
  <summary>Details</summary>
Motivation: 无服务器计算的冷启动问题（平台在配置新容器时会产生显著延迟）是其主要缺点，尽管它具有按需的性质，非常适合延迟敏感和突发的工作负载。

Method: 该框架使用模型预测控制来预测未来的调用，以主动缓解冷启动问题。该控制器协同优化容器预热和请求调度，以减少延迟并最大限度地减少资源开销。

Result: 该方法可将尾部延迟最多降低 85%，并可将资源使用率降低 34%。

Conclusion: 该方法在 Apache OpenWhisk 上实现，并在真实函数跟踪和合成工作负载的实验中，与最先进的基线相比，尾部延迟降低了 85%，资源使用率降低了 34%，显著优于它们。

Abstract: Serverless computing has transformed cloud application deployment by
introducing a fine-grained, event-driven execution model that abstracts away
infrastructure management. Its on-demand nature makes it especially appealing
for latency-sensitive and bursty workloads. However, the cold start problem,
i.e., where the platform incurs significant delay when provisioning new
containers, remains the Achilles' heel of such platforms.
  This paper presents a predictive serverless scheduling framework based on
Model Predictive Control to proactively mitigate cold starts, thereby improving
end-to-end response time. By forecasting future invocations, the controller
jointly optimizes container prewarming and request dispatching, improving
latency while minimizing resource overhead.
  We implement our approach on Apache OpenWhisk, deployed on a Kubernetes-based
testbed. Experimental results using real-world function traces and synthetic
workloads demonstrate that our method significantly outperforms
state-of-the-art baselines, achieving up to 85% lower tail latency and a 34%
reduction in resource usage.

</details>


### [494] [Perpetual exploration in anonymous synchronous networks with a Byzantine black hole](https://arxiv.org/abs/2508.07703)
*Adri Bhattacharya,Pritam Goswami,Evangelos Bampas,Partha Sarathi Mandal*

Main category: cs.DC

TL;DR: 在具有拜占庭黑洞（BBH）的未知网络中，智能体需要进行永久探索。BBH可能随时销毁智能体。研究了探索至少一个连通分量（
pbmPerpExpl
）和探索包含初始位置的连通分量（
pbmPerpExplHome
）两种情况。在树状网络中，分别需要4个和6个智能体。在一般网络中，
pbmPerpExpl
需要$2
u-1$个智能体，
pbmPerpExplHome
需要$3
u+3$个智能体。


<details>
  <summary>Details</summary>
Motivation: 在网络探索问题中，黑洞（Black Hole）是一个常见的障碍。然而，当黑洞的行为变得不可预测（即拜占庭行为）时，传统的探索策略可能会失效。本研究旨在解决这种更复杂的、具有潜在恶意行为的黑洞环境下的网络探索问题。

Method: 我们研究了在存在一个拜占庭黑洞（BBH）的未知图图中，一组初始共址的移动智能体如何进行永久探索的问题。BBH在每一轮可能销毁访问它的智能体，或者不进行任何操作。我们定义了两个问题变体：
pbmPerpExpl
（探索至少一个连通分量）和 
pbmPerpExplHome
（探索包含初始位置的连通分量）。智能体在同步调度下工作，并采用面对面通信模型。我们旨在确定解决这些问题所需的最小智能体数量。

Result: 在有环网络中，我们提出的算法能够以4个智能体解决
pbmPerpExpl
问题，以6个智能体解决
pbmPerpExplHome
问题，且这些算法是最优的。在一般图中，我们为
pbmPerpExpl
问题提供了$2
u-1$的智能体数量下界，为
pbmPerpExplHome
问题提供了$3
u+3$的智能体数量上界。

Conclusion: 本研究首次研究了在未知拓扑的任意网络中，存在拜占庭黑洞（BBH）的变种问题。我们为 
pbmPerpExpl
 和 
pbmPerpExplHome
 问题分别找到了最优解（在有环网络中）以及非平凡的解，并给出了相应的最少智能体数量。

Abstract: In this paper, we investigate: ``How can a group of initially co-located
mobile agents perpetually explore an unknown graph, when one stationary node
occasionally behaves maliciously, under an adversary's control?'' We call this
node a ``Byzantine black hole (BBH)'' and at any given round it may choose to
destroy all visiting agents, or none. This subtle power can drastically
undermine classical exploration strategies designed for an always active black
hole. We study this perpetual exploration problem in the presence of at most
one BBH, without initial knowledge of the network size. Since the underlying
graph may be 1-connected, perpetual exploration of the entire graph may be
infeasible. We thus define two variants: \pbmPerpExpl\ and \pbmPerpExplHome. In
the former, the agents are tasked to perform perpetual exploration of at least
one component, obtained after the exclusion of the BBH. In the latter, the
agents are tasked to perform perpetual exploration of the component which
contains the \emph{home} node, where agents are initially co-located.
Naturally, \pbmPerpExplHome\ is a special case of \pbmPerpExpl. Agents operate
under a synchronous scheduler and communicate in a face-to-face model. Our goal
is to determine the minimum number of agents necessary and sufficient to solve
these problems. In acyclic networks, we obtain optimal algorithms that solve
\pbmPerpExpl\ with $4$ agents, and \pbmPerpExplHome\ with $6$ agents in trees.
The lower bounds hold even in path graphs. In general graphs, we give a
non-trivial lower bound of $2\Delta-1$ agents for \pbmPerpExpl, and an upper
bound of $3\Delta+3$ agents for \pbmPerpExplHome. To our knowledge, this is the
first study of a black-hole variant in arbitrary networks without initial
topological knowledge.

</details>


### [495] [Over-the-Top Resource Broker System for Split Computing: An Approach to Distribute Cloud Computing Infrastructure](https://arxiv.org/abs/2508.07744)
*Ingo Friese,Jochen Klaffer,Mandy Galkow-Schneider,Sergiy Melnyk,Qiuheng Zhou,Hans Dieter Schotten*

Main category: cs.DC

TL;DR: 6G网络需要一个置顶代理来简化服务部署，该代理能隐藏不同基础设施的复杂性，适用于多种环境，论文对此进行了探讨并提供了概念验证。


<details>
  <summary>Details</summary>
Motivation: 为了应对6G网络架构带来的创新服务和能力，如分离计算和动态处理节点，需要一种能够统一接口、隐藏不同基础设施提供商复杂性的方法，以简化服务部署。

Method: 通过对两种分离计算场景的分析，并提供一个概念验证实现的详细讨论，来探讨置顶代理在资源分配中的作用。

Result: 置顶代理作为资源分配的工具，可以简化服务集成，并且具有广泛的应用前景，不仅限于云环境，也适用于网络等其他领域。

Conclusion: 该论文提出一个置顶的代理（over-the-top broker）作为一种有前景的方法，用于简化在未来网络和云基础设施中的服务集成。该代理通过抽象化各种基础设施的复杂性，可以应用于网络、云等多种环境。此外，论文还提供了一个概念验证实现的详细讨论，揭示了代理的实际架构框架。

Abstract: 6G network architectures will usher in a wave of innovative services and
capabilities, introducing concepts like split computing and dynamic processing
nodes. This implicates a paradigm where accessing resources seamlessly aligns
with diverse processing node characteristics, ensuring a uniform interface. In
this landscape, the identity of the operator becomes inconsequential, paving
the way for a collaborative ecosystem where multiple providers contribute to a
shared pool of resources. At the core of this vision is the guarantee of
specific performance parameters, precisely tailored to the location and service
requirements. A consistent layer, as the abstraction of the complexities of
different infrastructure providers, is needed to simplify service deployment.
One promising approach is the introduction of an over-the-top broker for
resource allocation, which streamlines the integration of these services into
the network and cloud infrastructure of the future. This paper explores the
role of the broker in two split computing scenarios. By abstracting the
complexities of various infrastructures, the broker proves to be a versatile
solution applicable not only to cloud environments but also to networks and
beyond. Additionally, a detailed discussion of a proof-of-concept
implementation provides insights into the broker's actual architectural
framework.

</details>


### [496] [Towards Lock Modularization for Heterogeneous Environments](https://arxiv.org/abs/2508.07756)
*Hanze Zhang,Rong Chen,Haibo Chen*

Main category: cs.DC

TL;DR: 通过将锁分解并分配到不同硬件组件，提高在异构环境中的性能。


<details>
  <summary>Details</summary>
Motivation: 现代硬件环境日益异构化，现有锁解决方案通常针对特定硬件，无法充分利用其他组件的资源，导致性能瓶颈。

Method: 提出了一种名为锁模块化的新设计原则和系统化方法，将锁分解为独立模块并分配到适当的硬件组件。

Result: 该方法旨在最大化利用硬件优势，最小化劣势，提高锁操作在异构环境中的性能。

Conclusion: 本文提出了一种名为锁模块化的新方法，通过将锁分解为独立模块并分配到适当的硬件组件，以充分利用异构环境中的不均衡资源，从而解决现代异构硬件环境中锁操作带来的挑战。

Abstract: Modern hardware environments are becoming increasingly heterogeneous, leading
to the emergence of applications specifically designed to exploit this
heterogeneity. Efficiently adopting locks in these applications poses distinct
challenges. The uneven distribution of resources in such environments can
create bottlenecks for lock operations, severely hindering application
performance. Existing solutions are often tailored to specific types of
hardware, which underutilizes resources on other components within
heterogeneous environments.
  This paper introduces a new design principle: decomposing locks across
hardware components to fully utilize unevenly distributed resources in
heterogeneous environments. Following this principle, we propose lock
modularization, a systematic approach that decomposes a lock into independent
modules and assigns them to appropriate hardware components. This approach
aligns the resource requirements of lock modules with the attributes of
specific hardware components, maximizing strengths while minimizing weaknesses.

</details>


### [497] [Performance Evaluation of Brokerless Messaging Libraries](https://arxiv.org/abs/2508.07934)
*Lorenzo La Corte,Syed Aftab Rashid,Andrei-Marian Dan*

Main category: cs.DC

TL;DR: 这项工作通过定性分析和广泛的开源基准测试，评估了 ZeroMQ、NanoMsg 和 NNG 等无代理消息传递系统的性能，为从业者提供了选择合适库的见解。


<details>
  <summary>Details</summary>
Motivation: 与主要关注具有中间代理以保证可靠性和服务质量的代理消息系统不同，这项工作解决了新兴的、消除单点故障的无代理消息系统，并解决了对其性能评估的现有研究不足的问题。

Method: 首先，对几种可能的候选者进行了定性分析，以找到最有希望的。然后，设计并实现了一个广泛的开源基准测试套件，以系统和公平地评估所选库（即 ZeroMQ、NanoMsg 和 NanoMsg-Next-Generation (NNG)）的性能。

Result: 评估了这些库在不同指标和工作负载条件下的性能，并揭示了它们的局限性。

Conclusion: 该分析使得实践者能够为他们的需求选择最合适的无代理消息传递库。

Abstract: Messaging systems are essential for efficiently transferring large volumes of
data, ensuring rapid response times and high-throughput communication. The
state-of-the-art on messaging systems mainly focuses on the performance
evaluation of brokered messaging systems, which use an intermediate broker to
guarantee reliability and quality of service. However, over the past decade,
brokerless messaging systems have emerged, eliminating the single point of
failure and trading off reliability guarantees for higher performance. Still,
the state-of-the-art on evaluating the performance of brokerless systems is
scarce. In this work, we solely focus on brokerless messaging systems. First,
we perform a qualitative analysis of several possible candidates, to find the
most promising ones. We then design and implement an extensive open-source
benchmarking suite to systematically and fairly evaluate the performance of the
chosen libraries, namely, ZeroMQ, NanoMsg, and NanoMsg-Next-Generation (NNG).
We evaluate these libraries considering different metrics and workload
conditions, and provide useful insights into their limitations. Our analysis
enables practitioners to select the most suitable library for their
requirements.

</details>


### [498] [Optimizing Federated Learning for Scalable Power-demand Forecasting in Microgrids](https://arxiv.org/abs/2508.08022)
*Roopkatha Banerjee,Sampath Koti,Gyanendra Singh,Anirban Chakraborty,Gurunath Gurrala,Bhushan Jagyasi,Yogesh Simmhan*

Main category: cs.DC

TL;DR: 通过优化联邦学习，在保证隐私的同时，高效准确地预测电力需求，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 为了在不暴露用户活动模式的情况下，通过物联网（IoT）对城市和微电网的电力消耗进行实时监控，以预测未来需求并优化电网运营，但现有的FL方法面临数据非IID和计算成本高的挑战。

Method: 本文开发并评估了多种优化联邦学习（FL）训练的方法，包括在训练过程中使用指数加权损失，以在微电网和城市规模的公用事业中实现时间序列需求预测。

Result: 通过在三个美国州的OpenEIA语料库上进行验证，并在伪分布式设置和Pi边缘集群中执行FL，结果表明所提出的方法比ARIMA和针对个体消费者的DNN模型具有更好的可扩展性和性能。

Conclusion: 该研究通过在边缘和云端进行优化联邦学习（FL）训练，在微电网和城市规模的公用事业中实现了高预测精度和低训练成本，有效解决了非IID数据和计算成本的挑战，并优于ARIMA和仅针对个体消费者的DNN模型。

Abstract: Real-time monitoring of power consumption in cities and micro-grids through
the Internet of Things (IoT) can help forecast future demand and optimize grid
operations. But moving all consumer-level usage data to the cloud for
predictions and analysis at fine time scales can expose activity patterns.
Federated Learning~(FL) is a privacy-sensitive collaborative DNN training
approach that retains data on edge devices, trains the models on private data
locally, and aggregates the local models in the cloud. But key challenges
exist: (i) clients can have non-independently identically distributed~(non-IID)
data, and (ii) the learning should be computationally cheap while scaling to
1000s of (unseen) clients. In this paper, we develop and evaluate several
optimizations to FL training across edge and cloud for time-series demand
forecasting in micro-grids and city-scale utilities using DNNs to achieve a
high prediction accuracy while minimizing the training cost. We showcase the
benefit of using exponentially weighted loss while training and show that it
further improves the prediction of the final model. Finally, we evaluate these
strategies by validating over 1000s of clients for three states in the US from
the OpenEIA corpus, and performing FL both in a pseudo-distributed setting and
a Pi edge cluster. The results highlight the benefits of the proposed methods
over baselines like ARIMA and DNNs trained for individual consumers, which are
not scalable.

</details>


### [499] [On the Operational Resilience of CBDC: Threats and Prospects of Formal Validation for Offline Payments](https://arxiv.org/abs/2508.08064)
*Marco Bernardo,Federico Calandra,Andrea Esposito,Francesco Fabris*

Main category: cs.DC

TL;DR: Formal methods are crucial for ensuring the reliability of CBDC software, particularly for offline payments, to prevent potential financial collapse due to bugs.


<details>
  <summary>Details</summary>
Motivation: The motivation is the potential for even minor bugs in CBDC software to trigger financial collapse, as highlighted by the increasing role of ICT in finance and the impossibility results of theoretical computer science regarding software quality certification.

Method: The paper discusses the use of formal methods to provide assertions of computing systems correctness.

Result: The paper argues that while absolute software quality certification is impossible, formal methods can offer practical assurances for critical systems like CBDCs, especially for offline payment functionalities.

Conclusion: The paper advocates for the use of formal methods to validate the operational resilience of software infrastructures enabling CBDCs, with a particular emphasis on offline payments.

Abstract: Information and communication technologies are by now employed in most
activities, including economics and finance. Despite the extraordinary power of
modern computers and the vast amount of memory, some results of theoretical
computer science imply the impossibility of certifying software quality in
general. With the exception of safety-critical systems, this has primarily
concerned the information processed by confined systems, with limited
socio-economic consequences. In the emerging era of technologies for exchanging
digital money and tokenized assets over the Internet - such as central bank
digital currencies (CBDCs) - even a minor bug could trigger a financial
collapse. Although the aforementioned impossibility results cannot be overcome
in an absolute sense, there exist formal methods that can provide assertions of
computing systems correctness. We advocate their use to validate the
operational resilience of software infrastructures enabling CBDCs, with special
emphasis on offline payments as they constitute a very critical issue.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [500] [Applying the Spectral Method for Modeling Linear Filters: Butterworth, Linkwitz-Riley, and Chebyshev filters](https://arxiv.org/abs/2508.07206)
*Konstantin A. Rybakov,Egor D. Shermatov*

Main category: eess.SP

TL;DR: A new technique for computer modeling linear filters is proposed, using spectral representation and orthogonal expansions for signals and filters. It's tested successfully on various filter types.


<details>
  <summary>Details</summary>
Motivation: To propose a new technique for computer modeling linear filters.

Method: The technique models linear filters based on the spectral form of mathematical description of linear systems, representing input and output signals as orthogonal expansions and filters by two-dimensional non-stationary transfer functions.

Result: The technique is successfully tested on Butterworth, Linkwitz-Riley, and Chebyshev filters with different orders.

Conclusion: The proposed technique successfully models the output signal in continuous time and is tested on Butterworth, Linkwitz-Riley, and Chebyshev filters with different orders.

Abstract: This paper proposes a new technique for computer modeling linear filters
based on the spectral form of mathematical description of linear systems. It
assumes that input and output signals of the filter are represented as
orthogonal expansions, while filters themselves are described by
two-dimensional non-stationary transfer functions. This technique allows one to
model the output signal in continuous time, and it is successfully tested on
the Butterworth, Linkwitz-Riley, and Chebyshev filters with different orders.

</details>


### [501] [A Completely Blind Channel Estimation Technique for OFDM Using Generalized Constellation Splitting and Modified Phase-Directed Algorithm](https://arxiv.org/abs/2508.06508)
*Sameera Bharadwaja H.,D. K. Mehra*

Main category: eess.SP

TL;DR: 本文提出了一种新的盲道估计算法，解决了现有方法的歧义问题，并通过模拟验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决盲道估计中的复杂标量估计模糊问题，该问题通常需要使用导频或参考符号，但这与盲估计的目的相矛盾。

Method: 提出了一种利用广义星座分裂和改进的相位导向算法来解决盲道估计中的复杂标量估计模糊问题。

Result: 通过数值模拟评估了所提出方案的性能。

Conclusion: 本文提出了一种利用广义星座分裂和改进的相位导向算法来解决盲道估计的复杂标量估计模糊问题的新算法。

Abstract: The problem of blind channel estimation for SISO-OFDM systems using
second-order statistics (SOS) is addressed. A comparison of two prominent
SOS-based techniques: subspace-decomposition and precoding-induced
correlation-averaging techniques in terms of MSE performance is presented. The
drawback of these methods is that they suffer from a complex-scalar estimation
ambiguity which is resolved by using pilots or reference symbols. By using
pilots the whole purpose of blind techniques is contradicted. We propose an
algorithm to resolve this ambiguity in blind manner using generalized
constellation-splitting and modified phase-directed algorithm. The performance
of the proposed scheme is evaluated via numerical simulations in MATLAB
environment.

</details>


### [502] [GPU-accelerated Direct Geolocation of GNSS Interference](https://arxiv.org/abs/2508.06672)
*Jacob S. Clements,Zachary L. Clements*

Main category: eess.SP

TL;DR: A new GPU-based method speeds up GNSS interference location for satellites by processing calculations in parallel, overcoming the high computational cost of existing techniques.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the increasing problem of GNSS interference in civilian applications, particularly for receivers in Low Earth Orbit (LEO). Existing GNSS receivers often lack adequate countermeasures, and the direct geolocation approach, while suitable for LEO conditions, suffers from high computational requirements, which are further exacerbated by the extensive search space for LEO receivers.

Method: The paper proposes a GPU-accelerated direct geolocation method. This approach exploits the independence of position-domain correlation across candidate points and time steps, allowing for parallel computation on a GPU to alleviate the computational burden associated with direct geolocation for LEO-based receivers.

Result: The paper evaluates the performance of the GPU-accelerated direct geolocation compared to traditional CPU processing, demonstrating its effectiveness in alleviating the computational burden.

Conclusion: The paper presents a GPU-accelerated direct geolocation approach to address the computational challenges of GNSS interference detection and localization for LEO-based receivers. The proposed method significantly reduces computational burden by leveraging the parallelism of GPU processing, offering a viable solution for improving GNSS security in civilian applications.

Abstract: In recent years, there has been a sharp increase in Global Navigation
Satellite Systems (GNSS) interference, which has proven to be problematic in
GNSS-dependent civilian applications. Many currently deployed GNSS receivers
lack the proper countermeasures to defend themselves against interference,
prompting the need for alternative defenses. Satellites in Low Earth Orbit
(LEO) provide an opportunity for GNSS interference detection, classification,
and localization. The direct geolocation approach has been shown to be
well-suited for low SNR regimes and in cases limited to short captures --
exactly what is expected for receivers in LEO. Direct geolocation is a
single-step search over a geographical grid that enables estimation of the
transmitter location directly from correlating raw observed signals. However, a
key limitation to this approach is the computational requirements. This
computational burden is compounded for LEO-based receivers as the geographic
search space is extensive. This paper alleviates the computational burden of
direct geolocation by exploiting the independence of position-domain
correlation across candidate points and time steps: nearly all computation can
be accomplished in parallel on a graphics processing unit (GPU). This paper
presents and evaluates the performance of GPU-accelerated direct geolocation
compared to traditional CPU processing.

</details>


### [503] [Physical Layer Authentication Based on Hierarchical Variational Auto-Encoder for Industrial Internet of Things](https://arxiv.org/abs/2508.06794)
*Rui Meng,Xiaodong Xu,Bizhu Wang,Hao Sun,Shida Xia,Shujun Han,Ping Zhang*

Main category: eess.SP

TL;DR: 本篇论文提出了一种名为HVAE的新型物理层认证（PLA）方案，用于工业物联网（IIoT）环境。HVAE能够有效地提取信道特征并进行身份认证，即使在攻击者信道信息未知且训练数据有限的情况下也能保持高认证性能。仿真结果表明，HVAE在不同IIoT场景下优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 现有的针对IIoT的PLA方案通常需要攻击者的先验信道信息，在训练阶段信号源未知的情况下会导致严重的性能下降。因此，需要一种能够在不了解攻击者先验信道信息的情况下，即使在训练数据较少的情况下也能在复杂环境中实现高认证性能的PLA方案。

Method: 提出了一种名为“分层变分自编码器”（HVAE）的基于信道冲激响应（CIR）的PLA方案，该方案包括一个用于CIR特征提取的自动编码器（AE）模块和一个用于提高CIR特征表示能力并输出认证结果的变分自编码器（VAE）模块。在VAE模块中，构建了一个新的目标函数，同时考虑了单峰和双峰高斯分布。

Result: HVAE方案能够实现高认证性能，并且在训练数据较少的情况下也能在复杂环境中（静态和移动IIoT场景）取得优于其他三种PLA方案的性能。

Conclusion: 该研究提出的HVAE方案在静态和移动IIoT场景下进行了仿真，并与其他三种PLA方案进行了比较，证明了HVAE即使在训练数据较少的情况下也具有优越性。

Abstract: Recently, Physical Layer Authentication (PLA) has attracted much attention
since it takes advantage of the channel randomness nature of transmission media
to achieve communication confidentiality and authentication. In the complex
environment, such as the Industrial Internet of Things (IIoT), machine learning
(ML) is widely employed with PLA to extract and analyze complex channel
characteristics for identity authentication. However, most PLA schemes for IIoT
require attackers' prior channel information, leading to severe performance
degradation when the source of the received signals is unknown in the training
stage. Thus, a channel impulse response (CIR)-based PLA scheme named
"Hierarchical Variational Auto-Encoder (HVAE)" for IIoT is proposed in this
article, aiming at achieving high authentication performance without knowing
attackers' prior channel information even when trained on a few data in the
complex environment. HVAE consists of an Auto-Encoder (AE) module for CIR
characteristics extraction and a Variational Auto-Encoder (VAE) module for
improving the representation ability of the CIR characteristic and outputting
the authentication results. Besides, a new objective function is constructed in
which both the single-peak and the double-peak Gaussian distribution are taken
into consideration in the VAE module. Moreover, the simulations are conducted
under the static and mobile IIoT scenario, which verify the superiority of the
proposed HVAE over three comparison PLA schemes even with a few training data.

</details>


### [504] [Deep Domain-Adversarial Adaptation for Automatic Modulation Classification under Channel Variability](https://arxiv.org/abs/2508.06829)
*K. A. Shahriar*

Main category: eess.SP

TL;DR: 提出了一种基于域对抗的深度学习框架，用于解决无线通信中的自动调制分类问题，该框架能够有效应对不同信道条件带来的挑战，相比传统方法在精度上有所提升。


<details>
  <summary>Details</summary>
Motivation: 现代认知和智能无线电系统中的自动调制分类（AMC）至关重要，但异构无线信道条件（如瑞利和莱斯衰落）对传统AMC模型的泛化能力构成了严峻挑战。

Method: 提出了一种基于域对抗神经网络（DANN）的深度学习框架，以明确减轻源域和目标域之间由信道引起的分布偏移。

Result: 所提出的DANN模型在包含五个调制方案（BPSK、QPSK、16QAM、64QAM、256QAM）的综合模拟数据集上进行了评估，这些数据集涵盖了瑞利和莱斯衰落信道以及五个频段。与仅在源域上训练的基线监督模型相比，DANN模型在某些调制情况下实现了高达14.93%的绝对精度提升。

Conclusion: 所提出的基于域对抗的深度学习框架在实际信道变化下的自动调制分类任务中具有工程可行性，并为自适应频谱智能的未来研究提供了有力的方向。

Abstract: Automatic Modulation Classification (AMC) plays a significant role in modern
cognitive and intelligent radio systems, where accurate identification of
modulation is crucial for adaptive communication. The presence of heterogeneous
wireless channel conditions, such as Rayleigh and Rician fading, poses
significant challenges to the generalization ability of conventional AMC
models. In this work, a domain-adversarial neural network (DANN) based deep
learning framework is proposed that explicitly mitigates channel-induced
distribution shifts between source and target domains. The approach is
evaluated using a comprehensive simulated dataset containing five modulation
schemes (BPSK, QPSK, 16QAM, 64QAM, 256QAM) across Rayleigh and Rician fading
channels at five frequency bands. Comparative experiments demonstrate that the
DANN-based model achieves up to 14.93% absolute accuracy improvement in certain
modulation cases compared to a baseline supervised model trained solely on the
source domain. The findings establish the engineering feasibility of domain
adversarial learning in AMC tasks under real-world channel variability and
offer a robust direction for future research in adaptive spectrum intelligence

</details>


### [505] [Secure Transmission for Cell-Free Symbiotic Radio Communications with Movable Antenna: Continuous and Discrete Positioning Designs](https://arxiv.org/abs/2508.06868)
*Bin Lyu,Jiayu Guan,Meng Hua,Changsheng You,Tianqi Mao,Abbas Jamalipour*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this paper, we study a movable antenna (MA) empowered secure transmission
scheme for reconfigurable intelligent surface (RIS) aided cell-free symbiotic
radio (SR) system. Specifically, the MAs deployed at distributed access points
(APs) work collaboratively with the RIS to establish high-quality propagation
links for both primary and secondary transmissions, as well as suppressing the
risk of eavesdropping on confidential primary information. We consider both
continuous and discrete MA position cases and maximize the secrecy rate of
primary transmission under the secondary transmission constraints,
respectively. For the continuous position case, we propose a two-layer
iterative optimization method based on differential evolution with one-in-one
representation (DEO), to find a high-quality solution with relatively moderate
computational complexity. For the discrete position case, we first extend the
DEO based iterative framework by introducing the mapping and determination
operations to handle the characteristic of discrete MA positions. To further
reduce the computational complexity, we then design an alternating optimization
(AO) iterative framework to solve all variables within a single layer. In
particular, we develop an efficient strategy to derive the sub-optimal solution
for the discrete MA positions, superseding the DEO-based method. Numerical
results validate the effectiveness of the proposed MA empowered secure
transmission scheme along with its optimization algorithms.

</details>


### [506] [Extremely Large-Scale Dynamic Metasurface Antennas for 6G Near-Field Networks: Opportunities and Challenges](https://arxiv.org/abs/2508.06952)
*Haiyang Zhang,Nir Shlezinger,Giulia Torcolacci,Francesco Guidi,Anna Guerra,Qianyu Yang,Mohammadreza F. Imani,Davide Dardari,Yonina C. Eldar*

Main category: eess.SP

TL;DR: XL-DMA是一种低功耗、低成本的6G近场网络技术，在通信、定位和成像方面有巨大潜力，但仍需解决一些挑战。


<details>
  <summary>Details</summary>
Motivation: 为了满足6G网络对更高的数据速率、高精度定位和成像能力的要求，需要引入XL-array等新型近场技术。然而，传统的全数字或混合架构存在功耗高、成本高等问题。XL-DMA作为一种新兴的解决方案，能够以超低功耗和低成本实现这些目标，因此成为6G近场网络的理想选择。

Method: 本文讨论了XL-DMAs在6G近场网络中的机遇和挑战，包括其基本原理、近场模型、潜在应用以及开放性问题和未来方向。

Result: XL-DMAs在6G近场通信、定位和成像等应用中展现出巨大的潜力，但其广泛应用仍面临一些挑战，需要进一步的研究和发展。

Conclusion: XL-DMAs是6G近场网络中的一种有前途的解决方案，但仍需解决一些挑战和开放性问题。

Abstract: 6G networks will need to support higher data rates, high-precision
localization, and imaging capabilities. Near-field technologies, enabled by
extremely large-scale (XL)-arrays, are expected to be essential physical-layer
solutions to meet these ambitious requirements. However, implementing XL-array
systems using traditional fully-digital or hybrid analog/digital architectures
poses significant challenges due to high power consumption and implementation
costs. Emerging XL-dynamic metasurface antennas (XL-DMAs) provide a promising
alternative, enabling ultra-low power and cost-efficient solutions, making them
ideal candidates for 6G near-field networks. In this article, we discuss the
opportunities and challenges of XL-DMAs employed in 6G near-field networks. We
first outline the fundamental principles of XL-DMAs and present the specifics
of the near-field model of XL-DMAs. We then highlight several promising
applications that might benefit from XL-DMAs, including near-field
communication, localization, and imaging. Finally, we discuss several open
problems and potential future directions that should be addressed to fully
exploit the capabilities of XL-DMAs in the next 6G near-field networks.

</details>


### [507] [Millimeter-Wave Position Sensing Using Reconfigurable Intelligent Surfaces: Positioning Error Bound and Phase Shift Configuration](https://arxiv.org/abs/2508.06958)
*Xin Cheng,Guangjie Han,Menglu Li,Ruoguang Li,Feng Shu*

Main category: eess.SP

TL;DR: 本论文提出了一种新的三维MISO毫米波定位系统，利用多RIS和优化的相位移来提高定位精度。


<details>
  <summary>Details</summary>
Motivation: 为了在高精度毫米波定位中实现智能系统，并利用可重构智能表面（RIS）动态操控无线传播环境。

Method: 提出了一种包含顺序RIS激活和定向波束成形的测量框架，并推导了费希尔信息和测pos误差界限（PEB）。针对连续和离散相位移配置，分别提出了基于黎曼流形和灰狼优化启发式算法的优化方法。

Result: 仿真结果表明，所提出的算法能有效降低PEB，且多RIS辅助系统能显著提高定位精度。

Conclusion: 本论文提出的基于流形优化的算法和基于灰狼优化的算法在降低测位误差界限和提高定位精度方面均表现出优越性，证明了多RIS辅助下的三维MISO毫米波定位系统的有效性。

Abstract: Millimeter-wave (mmWave) positioning has emerged as a promising technology
for next-generation intelligent systems. The advent of reconfigurable
intelligent surfaces (RISs) has revolutionized high-precision mmWave
localization by enabling dynamic manipulation of wireless propagation
environments. This paper investigates a three-dimensional (3D) multi-input
single-output (MISO) mmWave positioning system assisted by multiple RISs. We
introduce a measurement framework incorporating sequential RIS activation and
directional beamforming to fully exploit virtual line-of-sight (VLoS) paths.
The theoretical performance limits are rigorously analyzed through derivation
of the Fisher information and subsequent positioning error bound (PEB). To
minimize the PEB, two distinct optimization approaches are proposed for
continuous and discrete phase shift configurations of RISs. For continuous
phase shifts, a Riemannian manifold-based optimization algorithm is proposed.
For discrete phase shifts, a heuristic algorithm incorporating the grey wolf
optimizer is proposed. Extensive numerical simulations demonstrate the
effectiveness of the proposed algorithms in reducing the PEB and validate the
improvement in positioning accuracy achieved by multiple RISs.

</details>


### [508] [Joint Beamforming Optimization for Pinching-Antenna Systems (PASS)-assisted Symbiotic Radio](https://arxiv.org/abs/2508.07002)
*Ze Wang,Guoping Zhang,Hongbo Xu*

Main category: eess.SP

TL;DR: This paper introduces a new symbiotic radio framework using a pinching antenna system (PASS) to improve wireless transmissions. Two methods, LGD and SCA-PSO, are proposed to optimize the system, with SCA-PSO showing better performance and efficiency.


<details>
  <summary>Details</summary>
Motivation: To investigate a novel downlink symbiotic radio (SR) framework empowered by the pinching antenna system (PASS), aiming to enhance both primary and secondary transmissions through reconfigurable antenna positioning.

Method: Two solution strategies are developed: 1) A learning-aided gradient descent (LGD) algorithm where the problem is reformulated into a differentiable form and solved through end-to-end learning. 2) A two-stage optimization-based approach (SCA-PSO) where transmit beamforming is optimized via successive convex approximation (SCA), followed by pinching beamforming optimization using particle swarm optimization (PSO).

Result: The SCA-PSO algorithm achieves performance close to that of the element-wise method while significantly reducing computational complexity and improving upon the LGD method by avoiding undesirable local optima.

Conclusion: The paper proposes two strategies to optimize the symbiotic radio framework empowered by the pinching antenna system (PASS), aiming to enhance both primary and secondary transmissions. The proposed LGD and SCA-PSO algorithms show promising results, with SCA-PSO achieving performance close to the element-wise method while significantly reducing computational complexity and avoiding local optima.

Abstract: This paper investigates a novel downlink symbiotic radio (SR) framework
empowered by the pinching antenna system (PASS), aiming to enhance both primary
and secondary transmissions through reconfigurable antenna positioning. PASS
consists of multiple waveguides equipped with numerous low-cost pinching
antennas (PAs), whose positions can be flexibly adjusted to simultaneously
manipulate large-scale path loss and signal phases.We formulate a joint
transmit and pinching beamforming optimization problem to maximize the
achievable sum rate while satisfying the detection error probability constraint
for the IR and the feasible deployment region constraints for the PAs. This
problem is inherently nonconvex and highly coupled. To address it, two solution
strategies are developed. 1) A learning-aided gradient descent (LGD) algorithm
is proposed, where the constrained problem is reformulated into a
differentiable form and solved through end-to-end learning based on the
principle of gradient descent. The PA position matrix is reparameterized to
inherently satisfy minimum spacing constraints, while transmit power and
waveguide length limits are enforced via projection and normalization. 2) A
two-stage optimization-based approach is designed, in which the transmit
beamforming is first optimized via successive convex approximation (SCA),
followed by pinching beamforming optimization using a particle swarm
optimization (PSO) search over candidate PA placements. The SCA-PSO algorithm
achieves performance close to that of the element-wise method while
significantly reducing computational complexity by exploring a randomly
generated effective solution subspace, while further improving upon the LGD
method by avoiding undesirable local optima.

</details>


### [509] [Robust Super-Resolution Compressive Sensing: A Two-timescale Alternating MAP Approach](https://arxiv.org/abs/2508.07013)
*Yufan Zhou,Jingyi Li,Wenkang Xu,An Liu*

Main category: eess.SP

TL;DR: 提出了一种新的鲁棒超分辨率压缩感知算法框架，使用双时间尺度交替最大后验（MAP）方法，通过tanh-VBI和BFGS算法提高了稀疏信号恢复的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有超分辨率压缩感知（SR-CS）方法在分辨率和超参数敏感性方面存在局限性，尤其是在网格参数靠近且不精确地位于固定网格上时，难以准确恢复稀疏信号。

Method: 使用双时间尺度交替最大后验（MAP）方法，包括稀疏信号估计模块（基于tanh-VBI算法）和网格更新模块（基于BFGS算法）。

Result: 仿真结果表明，所提出的方案在信道外推问题上优于基线方案。

Conclusion: 所提出的方法在信道外推问题上优于基线方法。

Abstract: The problem of super-resolution compressive sensing (SR-CS) is crucial for
various wireless sensing and communication applications. Existing methods often
suffer from limited resolution capabilities and sensitivity to
hyper-parameters, hindering their ability to accurately recover sparse signals
when the grid parameters do not lie precisely on a fixed grid and are close to
each other. To overcome these limitations, this paper introduces a novel robust
super-resolution compressive sensing algorithmic framework using a
two-timescale alternating maximum a posteriori (MAP) approach. At the slow
timescale, the proposed framework iterates between a sparse signal estimation
module and a grid update module. In the sparse signal estimation module, a
hyperbolic-tangent prior distribution based variational Bayesian inference
(tanh-VBI) algorithm with a strong sparsity promotion capability is adopted to
estimate the posterior probability of the sparse vector and accurately identify
active grid components carrying primary energy under a dense grid.
Subsequently, the grid update module utilizes the BFGS algorithm to refine
these low-dimensional active grid components at a faster timescale to achieve
super-resolution estimation of the grid parameters with a low computational
cost. The proposed scheme is applied to the channel extrapolation problem, and
simulation results demonstrate the superiority of the proposed scheme compared
to baseline schemes.

</details>


### [510] [Pinching-Antenna System Design with LoS Blockage: Does In-Waveguide Attenuation Matter?](https://arxiv.org/abs/2508.07131)
*Yanqing Xu,Zhiguo Ding,Octavia A. Dobre,Tsung-Hui Chang*

Main category: eess.SP

TL;DR: 在波导衰减通常被忽略的夹紧天线系统中，这项研究评估了其对性能的影响，特别是在存在视线遮挡的条件下。研究结果表明，忽略衰减的影响很小，并且通过优化天线位置和波束成形器，可以大大提高系统性能。


<details>
  <summary>Details</summary>
Motivation: 在夹紧天线系统的文献中，为了简化系统设计和分析，通常会忽略波导内的衰减。然而，它对整体系统性能的影响在现有文献中受到的关注有限。本研究旨在探讨更现实的包含任意视线遮挡条件下的场景，并评估忽略波导内衰减对系统性能的影响。

Method: 研究人员推导了由忽略波导内衰减引起的平均数据速率损失的显式表达式，并提出了一种动态样本平均近似（SAA）算法来解决多用户场景下的随机非凸优化问题，以优化天线位置和传输波束成形器。

Result: 在单用户情况下，即使在服务区域较大的情况下，在典型的视线遮挡条件下，速率损失也可以忽略不计。在多用户场景下，所提出的动态SAA算法在存在显着视线遮挡的环境中，能够实现夹紧天线系统的性能的大幅提升。

Conclusion: 该研究表明，即使在存在显着视线遮挡的环境中，在波导衰减可以忽略不计的情况下，夹紧天线系统的性能也得到了显着提升。

Abstract: In the literature of pinching-antenna systems, in-waveguide attenuation is
often neglected to simplify system design and enable more tractable analysis.
However, its effect on overall system performance has received limited
attention in the existing literature. While a recent study has shown that, in
line-of-sight (LoS)-dominated environments, the data rate loss incurred by
omitting in-waveguide attenuation is negligible when the communication area is
not excessively large, its effect under more general conditions remains
unclear. This work extends the analysis to more realistic scenarios involving
arbitrary levels of LoS blockage. We begin by examining a single-user case and
derive an explicit expression for the average data rate loss caused by
neglecting in-waveguide attenuation. The results demonstrate that, even for
large service areas, the rate loss remains negligible under typical LoS
blockage conditions. We then consider a more general multi-user scenario, where
multiple pinching antennas, each deployed on a separate waveguide, jointly
serve multiple users. The objective is to maximize the average sum rate by
jointly optimize antenna positions and transmit beamformers to maximize the
average sum rate under probabilistic LoS blockage. To solve the resulting
stochastic and nonconvex optimization problem, we propose a dynamic sample
average approximation (SAA) algorithm. At each iteration, this method replaces
the expected objective with an empirical average computed from dynamically
regenerated random channel realizations, ensuring that the optimization
accurately reflects the current antenna configuration. Extensive simulation
results are provided to the proposed algorithm and demonstrate the substantial
performance gains of pinching-antenna systems, particularly in environments
with significant LoS blockage.

</details>


### [511] [Low-Complexity Equalization of Zak-OTFS in the Frequency Domain](https://arxiv.org/abs/2508.07148)
*Sandesh Rao Mattu,Nishant Mehrotra,Saif Khan Mohammed,Venkatesh Khammammetti,Robert Calderbank*

Main category: eess.SP

TL;DR: 提出了一种新的低复杂度频域均衡方法，用于解决Zak-OTFS调制在双选择性信道下的均衡问题，并验证了其有效性和性能。


<details>
  <summary>Details</summary>
Motivation: OFDM在4G/5G中虽然鲁棒性好但随着移动性的增加，多普勒频移会导致子载波间干扰（ICI），从而降低性能。Zak-OTFS调制被证明对双选择性信道具有鲁棒性，但其均衡复杂度较高。

Method: 提出了一种在频域（FD）进行Zak-OTFS均衡的新型低复杂度方法，推导了FD系统模型并证明其与DD域系统模型是酉等价的，利用了FD信道矩阵的带状特性，应用共轭梯度法降低了均衡复杂度，复杂度为线性。

Result: 所提出的FD均衡方法的复杂度是Zak-OTFS帧维度的线性函数，而朴素MMSE均衡的复杂度是帧维度的三次函数。数值模拟结果表明，FD均衡的Zak-OTFS性能与DD域均衡相当。

Conclusion: 提出的频域（FD）等化方法可以有效地实现Zak-OTFS的低复杂度均衡，并且在数值模拟中显示出与时延-多普勒（DD）域均衡相当的性能。

Abstract: 4G/5G wireless standards use orthogonal frequency division multiplexing
(OFDM) which is robust to frequency selectivity. Equalization is possible with
a single tap filter, and low-complexity equalization makes OFDM an attractive
physical layer. However the performance of OFDM degrades with mobility, since
Doppler spreads introduce inter-carrier interference (ICI) between subcarriers
and they are no longer orthogonal. Zak-transform based orthogonal time
frequency space (Zak-OTFS) modulation has been shown to be robust to doubly
selective channels. Zak-OTFS signals are formed in the delay-Doppler (DD)
domain, converted to time domain (TD) for transmission and reception, then
returned to the DD domain for processing. The received signal is a
superposition of many attenuated copies since the doubly selective channel
introduces delay and Doppler shifts. The received symbols are more difficult to
equalize since they are subject to interference along both delay and Doppler
axes. In this paper, we propose a new low-complexity method of equalizing
Zak-OTFS in the frequency domain (FD). We derive the FD system model and show
that it is unitarily equivalent to the DD system model. We show that the
channel matrix in the FD is banded, making it possible to apply conjugate
gradient methods to reduce the complexity of equalization. We show that
complexity of FD equalization is linear in the dimension of a Zak-OTFS frame.
For comparison the complexity of naive MMSE equalization is cubic in the frame
dimension. Through numerical simulations we show that FD equalization of
Zak-OTFS achieves similar performance as equalization in DD domain.

</details>


### [512] [Vector Orthogonal Chirp Division Multiplexing Over Doubly Selective Channels](https://arxiv.org/abs/2508.07160)
*Deyu Lu,Xiaoli Ma,Yiyin Wang*

Main category: eess.SP

TL;DR: VOCDM通过并行IDFT实现，可以优化双选择性信道下的分集性能和PAPR。


<details>
  <summary>Details</summary>
Motivation: 为了在双选择性信道中提供更多的设计自由度，将OCDM扩展到VOCDM。

Method: 通过执行M个并行的N点逆离散傅里叶变换（IDFT）来实现VOCDM调制。基于CE-BEM模型推导了VOCDM的输入输出关系，并分析了M和N参数对VOCDM的性能影响。

Result: VOCDM在双选择性信道下表现出优越的多样性性能，且PAPPR随N的减小而减小。理论发现通过数值模拟得到验证。

Conclusion: VOCDM在双选择性信道下表现出优越的分集性能，并且可以通过调整M和N参数来优化。

Abstract: In this letter, we extend orthogonal chirp division multiplexing (OCDM) to
vector OCDM (VOCDM) to provide more design freedom to deal with doubly
selective channels. The VOCDM modulation is implemented by performing M
parallel N-size inverse discrete Fresnel transforms (IDFnT). Based on the
complex exponential basis expansion model (CE-BEM) for doubly selective
channels, we derive the VOCDM input-output relationship, and show performance
tradeoffs of VOCDM with respect to (w.r.t.) its modulation parameters M and N.
Specifically, we investigate the diversity and peak-to-average power ratio
(PAPR) of VOCDM w.r.t. M and N. Under doubly selective channels, VOCDM exhibits
superior diversity performance as long as the parameters M and N are configured
to satisfy some constraints from the delay and the Doppler spreads of the
channel, respectively. Furthermore, the PAPR of VOCDM signals decreases with a
decreasing N. These theoretical findings are verified through numerical
simulations.

</details>


### [513] [Multi-RIS Deployment Optimization for mmWave ISAC Systems in Real-World Environments](https://arxiv.org/abs/2508.07226)
*Yueheng Li,Xueyun Long,Mario Pauli,Suheng Tian,Xiang Wan,Benjamin Nuss,Tiejun Cui,Haixia Zhang,Thomas Zwick*

Main category: eess.SP

TL;DR: 本研究提出了一种针对RIS辅助ISAC系统的优化部署方法，通过迭代算法优化RIS的尺寸、位置和方向，以提高通信覆盖和感知精度，同时降低RIS尺寸。


<details>
  <summary>Details</summary>
Motivation: 为了增强未来空地一体化网络应用中的ISAC功能，需要仔细设计和评估RIS的部署，这是本研究的核心动机。

Method: 提出了一种基于等效增益缩放方法的简化重构方法，并设计了一种两步迭代算法来求解非凸混合整数问题，以优化RIS部署。

Result: 仿真结果表明，优化的RIS部署显著提高了通信覆盖和感知精度，同时最小化了RIS尺寸，优于现有方法。

Conclusion: 所提出的优化部署方案在通信覆盖、感知精度和RIS尺寸方面均优于现有方法。

Abstract: Reconfigurable intelligent surface-assisted integrated sensing and
communication (RIS-ISAC) presents a promising system architecture to leverage
the wide bandwidth available at millimeter-wave (mmWave) frequencies, while
mitigating severe signal propagation losses and reducing infrastructure costs.
To enhance ISAC functionalities in the future air-ground integrated network
applications, RIS deployment must be carefully designed and evaluated, which
forms the core motivation of this paper. To ensure practical relevance, a
multi-RIS-ISAC system is established, with its signal model at mmWave
frequencies demonstrated using ray-launching calibrated to real-world
environments. On this basis, an energy-efficiency-driven optimization problem
is formulated to minimize the multi-RIS size-to-coverage sum ratio,
comprehensively considering real-world RIS deployment constraints, positions,
orientations, as well as ISAC beamforming strategies at both the base station
and the RISs. To solve the resulting non-convex mixed-integer problem, a
simplified reformulation based on equivalent gain scaling method is introduced.
A two-step iterative algorithm is then proposed, in which the deployment
parameters are determined under fixed RIS positions in the first step, and the
RIS position set is updated in the second step to progressively approach the
optimum solution. Simulation results based on realistic parameter benchmarks
present that the optimized RISs deployment significantly enhances communication
coverage and sensing accuracy with the minimum RIS sizes, outperforming
existing approaches.

</details>


### [514] [A Scalable Machine Learning Approach Enabled RIS Optimization with Implicit Channel Estimation](https://arxiv.org/abs/2508.07265)
*Bile Peng,Vahid Jamali,Eduard Jorswieck*

Main category: eess.SP

TL;DR: 本文提出了一种利用无监督机器学习（特别是RISnet神经网络）来优化RIS配置的方法，解决了RIS面临的可扩展性和信道状态信息获取的难题，并取得了优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: RIS被认为是下一代移动无线电系统的关键技术，但RIS元件的可扩展性和信道状态信息（CSI）的要求是其实现面临的两个主要挑战。

Method: 提出了一种无监督机器学习（ML）驱动的优化方法来配置RIS，结合了名为RISnet的专用神经网络（NN）架构和隐式信道估计方法。RISnet直接从接收到的导频信号映射到RIS配置，而无需显式信道估计。

Result: 仿真结果表明，该方法能够成功地从接收到的导频信号中推断出RIS配置，而无需显式信道估计，并且在性能上优于现有方法。

Conclusion: 所提出的算法明显优于基线方法。

Abstract: The reconfigurable intelligent surface (RIS) is considered as a key enabler
of the next-generation mobile radio systems. While attracting extensive
interest from academia and industry due to its passive nature and low cost,
scalability of RIS elements and requirement for channel state information (CSI)
are two major difficulties for the RIS to become a reality. In this work, we
introduce an unsupervised machine learning (ML) enabled optimization approach
to configure the RIS. The dedicated neural network (NN) architecture RISnet is
combined with an implicit channel estimation method. The RISnet learns to map
from received pilot signals to RIS configuration directly without explicit
channel estimation. Simulation results show that the proposed algorithm
outperforms baselines significantly.

</details>


### [515] [Channel Charting in Smart Radio Environments](https://arxiv.org/abs/2508.07305)
*Mahdi Maleki,Reza Agahzadeh Ayoubi,Marouan Mizmizi,Umberto Spagnolini*

Main category: eess.SP

TL;DR: 本研究提出一种利用静态电磁皮肤（EMS）和信道图谱（CC）技术，在城市环境中显著提高设备定位精度和鲁棒性，尤其是在非视距（NLoS）条件下。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是在具有挑战性的城市环境中，利用智能无线环境（SRE）和静态电磁皮肤（EMS）来提高设备定位的鲁棒性和精度，特别是在非视距（NLoS）条件下。

Method: 本研究提出了一种利用静态电磁皮肤（EMS）通过信道图谱（CC）在城市环境中进行鲁棒设备定位的方法。通过严格的优化框架，利用EMS增强信道差异性和空间指纹，将EMS相位剖面设计问题转化为基于码本的问题，以优化关键嵌入指标（定位误差、可信度、连续性）的上分位数。

Result: 通过对代表性城市场景的3D射线追踪模拟，研究表明，优化的EMS配置不仅显著提高了平均定位误差，还将定位误差的90th百分位数从超过60米（无EMS）降低到不到25米，同时大幅提高了可信度和连续性。

Conclusion: 该研究首次利用带有静态电磁皮肤（EMS）的智能无线环境（SRE）增强信道图谱（CC），在具有挑战性的非视距（NLoS）条件下实现了定位性能的大幅提升。

Abstract: This paper introduces the use of static electromagnetic skins (EMSs) to
enable robust device localization via channel charting (CC) in realistic urban
environments. We develop a rigorous optimization framework that leverages EMS
to enhance channel dissimilarity and spatial fingerprinting, formulating EMS
phase profile design as a codebook-based problem targeting the upper quantiles
of key embedding metric, localization error, trustworthiness, and continuity.
Through 3D ray-traced simulations of a representative city scenario, we
demonstrate that optimized EMS configurations, in addition to significant
improvement of the average positioning error, reduce the 90th-percentile
localization error from over 60 m (no EMS) to less than 25 m, while drastically
improving trustworthiness and continuity. To the best of our knowledge, this is
the first work to exploit Smart Radio Environment (SRE) with static EMS for
enhancing CC, achieving substantial gains in localization performance under
challenging None-Line-of-Sight (NLoS) conditions.

</details>


### [516] [Detection and Classification of Internal Leakage in Hydraulic Cylinders](https://arxiv.org/abs/2508.07436)
*Mehrbod Zarifi,Mohamad Amin Jamshidi,Zolfa Anvari,Hamed Ghafarirad,Mohammad Zareinejad*

Main category: eess.SP

TL;DR: 该研究提出了一种基于LSTM神经网络的液压系统泄漏检测方法，准确率高，可实时诊断，有助于降低成本和延长设备寿命。


<details>
  <summary>Details</summary>
Motivation: 液压系统中的泄漏问题（特别是内部泄漏）难以检测，但会影响系统性能甚至导致故障。该研究旨在开发一种能够检测最小泄漏并缩短检测时间的故障检测算法。

Method: 通过收集液压系统运行时的压力传感器等信号数据，利用长短期记忆（LSTM）循环神经网络进行数据分析，以实现对液压系统内部泄漏的检测。

Result: 该方法实现了对液压系统泄漏类型的分类，准确率接近96%，能够进行实时在线的每个周期的故障诊断。

Conclusion: 所提出的基于LSTM的泄漏检测算法能够对液压系统进行实时在线故障诊断，准确率达到96%，有助于降低维护成本并延长液压系统寿命。

Abstract: Hydraulic systems have been one of the most used technologies in many
industries due to their reliance on incompressible fluids that facilitate
energy and power transfer. Within such systems, hydraulic cylinders are prime
devices that convert hydraulic energy into mechanical energy. Some of the
genuine and very common problems related to hydraulic cylinders are leakages.
Leakage in hydraulic systems can cause a drop in pressure, general
inefficiency, and even complete failure of such systems. The various ways
leakage can occur define the major categorization of leakage: internal and
external leakage. External leakage is easily noticeable, while internal
leakage, which involves fluid movement between pressure chambers, can be harder
to detect and may gradually impact system performance without obvious signs.
When leakage surpasses acceptable limits, it is classified as a fault or
failure. In such cases, leakage is divided into three categories: no leakage,
low leakage, and high leakage. It suggests a fault detection algorithm with the
basic responsibility of detecting minimum leakage within the Hydraulic system,
and minimizing detection time is the core idea of this paper. In order to fully
develop this idea, experimental data collection of Hydraulic systems is
required. The collected data uses pressure sensors and other signals that are
single-related. Due to the utilization of Long Short-Term Memory (LSTM)
recurrent neural networks, more complex data analysis was enabled, which the
LSTM-based leakage detection algorithm successfully achieved, providing almost
96% accuracy in classifying leakage types. Results demonstrate that the
proposed method can perform real-time and online fault diagnosis for each
cycle, reducing maintenance costs and prolonging the hydraulic system's
lifespan.

</details>


### [517] [Direction of Arrival Estimation with Virtual Antenna Array Using FMCW Radar Simulated Data](https://arxiv.org/abs/2508.07513)
*Emre Kurtoglu,Mohammad Mahbubur Rahman*

Main category: eess.SP

TL;DR: 该项目研究了77GHz FMCW汽车雷达的DOA估计，比较了FFT、MUSIC和压缩感知的性能，发现MUSIC和压缩感知具有更好的角度分辨率。


<details>
  <summary>Details</summary>
Motivation: 随着对汽车安全功能需求的不断增长，需要DOA估计来区分近距离的目标。

Method: 通过仿真数据，研究了FFT、MUSIC和压缩感知在77GHz FMCW汽车雷达DOA估计任务上的性能表现。

Result: MUSIC和压缩感知在角度估计方面表现优于FFT，提供了更高的角度分辨率。

Conclusion: FFT算法速度最快，但角度分辨率较低，而MUSIC和压缩感知是具有更高角度分辨率的超分辨率算法。

Abstract: The FMCW radars are widely used for automotive radar systems. The basic idea
for FMCW radars is to generate a linear frequency ramp as transmit signal. The
difference frequency, (i.e., beat frequency) between the transmitted and
received signal is determined after down conversion. The FFT operation on beat
frequency signal can recognize targets at different range and velocity.
Increasing demand on safety functionality leads to the Direction of Arrival
(DOA) estimation to resolve two closely located targets. Consequently, the
problem of angle estimation for 77GHz FMCW automotive radar simulated data has
been investigated in this term project. In particular, we examined the
performances of FFT, MUSIC and compressed sensing in angle estimation task, and
it was found that although FFT is the fastest algorithm, it has very poor
angular resolution when compared with others which are both super resolution
algorithms. The code for this project report is available at
https://github.com/ekurtgl/FMCW-MIMO-Radar-Simulation.

</details>


### [518] [Pinching-Antenna Systems (PASS): A Tutorial](https://arxiv.org/abs/2508.07572)
*Yuanwei Liu,Hao Jiang,Xiaoxia Xu,Zhaolin Wang,Jia Guo,Chongjun Ouyang,Xidong Mu,Zhiguo Ding,Arumugam Nallanathan,George K. Karagiannidis,Robert Schober*

Main category: eess.SP

TL;DR: This paper is a tutorial on Pinching Antenna Systems (PASS), a new flexible antenna technology. It covers PASS fundamentals, capacity limits, beamforming, communication strategies for single-user and multi-user scenarios, wideband implementation, channel estimation, and machine learning applications. PASS shows advantages over traditional antennas for future wireless networks.


<details>
  <summary>Details</summary>
Motivation: To introduce and analyze the breakthrough technology of Pinching Antenna Systems (PASS), highlighting its advantages in bringing wireless communications from the last mile to the last meter through features like large-scale reconfiguration, line-of-sight creation, scalability, and near-field benefits.

Method: This paper provides a comprehensive tutorial on PASS, covering fundamental aspects such as signal, hardware, and power radiation models, as well as activation methods. It analyzes information-theoretic capacity limits and performance metrics, compares PASS with conventional technologies, and investigates beamforming designs, including power scaling laws and transmission strategies for single-user and multi-user scenarios (waveguide switching, division, and multiplexing). The paper also discusses wideband communication implementations, channel state information acquisition, and explores machine-learning-based methods (deep neural networks and training algorithms) for PASS operation.

Result: The paper demonstrates the superiority of PASS over conventional antenna technologies through the analysis of its information-theoretic capacity limits and performance metrics. It also proposes various strategies and protocols for PASS-based communication and explores machine learning approaches for its operation.

Conclusion: Pinching antenna systems (PASS) offer significant advantages over conventional antenna technologies, enabling large-scale reconfiguration, line-of-sight creation, scalable implementation, and near-field benefits for wireless communications. Machine learning approaches show promise for optimizing PASS operations, overcoming the limitations of traditional methods. PASS holds potential for various applications in next-generation wireless networks.

Abstract: Pinching antenna systems (PASS) present a breakthrough among the
flexible-antenna technologies, and distinguish themselves by facilitating
large-scale antenna reconfiguration, line-of-sight creation, scalable
implementation, and near-field benefits, thus bringing wireless communications
from the last mile to the last meter. A comprehensive tutorial is presented in
this paper. First, the fundamentals of PASS are discussed, including PASS
signal models, hardware models, power radiation models, and pinching antenna
activation methods. Building upon this, the information-theoretic capacity
limits achieved by PASS are characterized, and several typical performance
metrics of PASS-based communications are analyzed to demonstrate its
superiority over conventional antenna technologies. Next, the pinching
beamforming design is investigated. The corresponding power scaling law is
first characterized. For the joint transmit and pinching design in the general
multiple-waveguide case, 1) a pair of transmission strategies is proposed for
PASS-based single-user communications to validate the superiority of PASS,
namely sub-connected and fully connected structures; and 2) three practical
protocols are proposed for facilitating PASS-based multi-user communications,
namely waveguide switching, waveguide division, and waveguide multiplexing. A
possible implementation of PASS in wideband communications is further
highlighted. Moreover, the channel state information acquisition in PASS is
elaborated with a pair of promising solutions. To overcome the high complexity
and suboptimality inherent in conventional convex-optimization-based
approaches, machine-learning-based methods for operating PASS are also
explored, focusing on selected deep neural network architectures and training
algorithms. Finally, several promising applications of PASS in next-generation
wireless networks are highlighted.

</details>


### [519] [Remote ID Based UAV Collision Avoidance Optimization for Low-Altitude Airspace Safety](https://arxiv.org/abs/2508.07651)
*Ziye Jia,Yian Zhu,Qihui Wu,Lei Zhang,Sen Yang,Zhu Han*

Main category: eess.SP

TL;DR: 本研究提出了一个基于远程识别的分布式多UAV防碰撞框架（DMUCA），并通过一种新的自适应通信配置算法（基于多智能体深度Q网络）来优化通信延迟。实验结果表明，该方法能显著降低通信延迟（减少32%），提高了碰撞避免的效率。


<details>
  <summary>Details</summary>
Motivation: 随着无人机（UAV）的快速发展，确保在开放空域中的安全高效运行至关重要。远程识别（Remote ID）被认为是有效的实时UAV监控系统，并有潜力实现UAV之间的通信。本研究旨在应用远程识别技术来避免UAV碰撞，同时最小化通信延迟。

Method: 本研究提出了一种基于远程识别的分布式多UAV防碰撞（DMUCA）框架，用于支持碰撞检测、避免决策和轨迹恢复。分析了平均传输延迟，并构建了一个优化问题来最小化长期平均通信延迟。设计了一种基于多智能体深度Q网络的自适应通信配置算法来解决该问题。

Result: 数值结果验证了所提出的DMUCA框架的可行性，并表明所提出的机制与固定的协议配置相比，平均延迟减少了32%。

Conclusion: 该研究提出了一个基于远程识别的分布式多无人机（UAV）防碰撞（DMUCA）框架，并设计了一种基于多智能体深度Q网络的自适应通信配置算法，以最小化通信延迟并提高碰撞避免性能。数值结果表明，所提出的机制与固定的协议配置相比，平均延迟减少了32%。

Abstract: With the rapid development of unmanned aerial vehicles (UAVs), it is
paramount to ensure safe and efficient operations in open airspaces. The remote
identification (Remote ID) is deemed an effective real-time UAV monitoring
system by the federal aviation administration, which holds potentials for
enabling inter-UAV communications. This paper deeply investigates the
application of Remote ID for UAV collision avoidance while minimizing
communication delays. First, we propose a Remote ID based distributed multi-UAV
collision avoidance (DMUCA) framework to support the collision detection,
avoidance decision-making, and trajectory recovery. Next, the average
transmission delays for Remote ID messages are analyzed, incorporating the
packet reception mechanisms and packet loss due to interference. The
optimization problem is formulated to minimize the long-term average
communication delay, where UAVs can flexibly select the Remote ID protocol to
enhance the collision avoidance performance. To tackle the problem, we design a
multi-agent deep Q-network based adaptive communication configuration
algorithm, allowing UAVs to autonomously learn the optimal protocol
configurations in dynamic environments. Finally, numerical results verify the
feasibility of the proposed DMUCA framework, and the proposed mechanism can
reduce the average delay by 32% compared to the fixed protocol configuration.

</details>


### [520] [Importance-Aware Semantic Communication in MIMO-OFDM Systems Using Vision Transformer](https://arxiv.org/abs/2508.07696)
*Joohyuk Park,Yongjeong Oh,Jihun Park,Yo-Seb Jeon*

Main category: eess.SP

TL;DR: 提出一种用于MIMO-OFDM语义通信的IA-QSMPA框架，利用ViT提取重要性，联合优化量化、子载波映射和功率分配，以提高任务性能和通信效率。


<details>
  <summary>Details</summary>
Motivation: 为MIMO-OFDM系统中的语义通信提出一种新颖的IA-QSMPA框架，以提高任务性能和通信效率。

Method: 利用预训练的Vision Transformer（ViT）提取基于注意力的重要性，联合优化量化级别、子载波映射和功率分配。采用块坐标下降算法求解非凸优化问题，并引入分段线性信道分散度惩罚以处理有限块长度传输。

Result: 模拟结果表明，IA-QSMPA在多视图图像分类任务上显著优于传统方法。

Conclusion: 该框架在理想和有限信道长度传输场景下均显著优于传统方法，实现了卓越的任务性能和通信效率。

Abstract: This paper presents a novel importance-aware quantization, subcarrier
mapping, and power allocation (IA-QSMPA) framework for semantic communication
in multiple-input multiple-output orthogonal frequency division multiplexing
(MIMO-OFDM) systems, empowered by a pretrained Vision Transformer (ViT). The
proposed framework exploits attention-based importance extracted from a
pretrained ViT to jointly optimize quantization levels, subcarrier mapping, and
power allocation. Specifically, IA-QSMPA maps semantically important features
to high-quality subchannels and allocates resources in accordance with their
contribution to task performance and communication latency. To efficiently
solve the resulting nonconvex optimization problem, a block coordinate descent
algorithm is employed. The framework is further extended to operate under
finite blocklength transmission, where communication errors may occur. In this
setting, a segment-wise linear approximation of the channel dispersion penalty
is introduced to enable efficient joint optimization under practical
constraints. Simulation results on a multi-view image classification task using
the MVP-N dataset demonstrate that IA-QSMPA significantly outperforms
conventional methods in both ideal and finite blocklength transmission
scenarios, achieving superior task performance and communication efficiency.

</details>


### [521] [Touch-Augmented Gaussian Splatting for Enhanced 3D Scene Reconstruction](https://arxiv.org/abs/2508.07717)
*Yuchen Gao,Xiao Xu,Eckehard Steinbach,Daniel E. Lucani,Qi Zhang*

Main category: eess.SP

TL;DR: 本研究提出一种将触觉信号（接触点、表面法线）融入3D高斯泼溅（3DGS）的多模态框架，通过双阶段采样和几何损失，显著提升了在低光照、遮挡等挑战性条件下的三维重建精度，尤其在严重遮挡下Chamfer距离降低超15倍，且保持在线处理能力。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是为了提高3D高斯泼溅（3DGS）在低光照、有限视角和遮挡等具有挑战性条件下的场景重建能力。通过整合触觉信号，旨在克服纯视觉方法的局限性，实现更准确和鲁棒的三维场景重建。

Method: 本研究提出了一个多模态框架，将触觉信号（接触点和表面法线）集成到3D高斯泼溅（3DGS）中。该方法采用双阶段采样策略，首先探测稀疏区域，然后关注从重建网格中识别出的高不确定性边界。引入了几何损失函数以确保表面光滑度，从而改善几何形状。

Result: 实验结果显示，与仅使用视觉信息的方法相比，本研究提出的集成触觉信号的方法在几何精度上有了持续的提升。在最严峻的严重遮挡场景下，Chamfer距离降低了超过15倍，验证了触觉线索在3DGS中的有效性。该方法还保持了完全在线的处理流程。

Conclusion: 本研究成功地将触觉信号（接触点和表面法线）集成到3D高斯泼溅（3DGS）框架中，显著提高了3D场景重建的准确性，尤其是在低光照、视角有限和遮挡等挑战性条件下。通过提出的双阶段采样策略和几何损失函数，实现了对3D高斯表示的几何和外观的精细调整，获得了更优的几何精度和表面光滑度。实验结果表明，该方法在严重遮挡等极端情况下，Chamfer距离降低了15倍以上，证明了触觉线索在3DGS中的有效性。此外，该方法保持了完全在线的处理流程，使其在视觉退化环境中具有可行性。

Abstract: This paper presents a multimodal framework that integrates touch signals
(contact points and surface normals) into 3D Gaussian Splatting (3DGS). Our
approach enhances scene reconstruction, particularly under challenging
conditions like low lighting, limited camera viewpoints, and occlusions.
Different from the visual-only method, the proposed approach incorporates
spatially selective touch measurements to refine both the geometry and
appearance of the 3D Gaussian representation. To guide the touch exploration,
we introduce a two-stage sampling scheme that initially probes sparse regions
and then concentrates on high-uncertainty boundaries identified from the
reconstructed mesh. A geometric loss is proposed to ensure surface smoothness,
resulting in improved geometry. Experimental results across diverse scenarios
show consistent improvements in geometric accuracy. In the most challenging
case with severe occlusion, the Chamfer Distance is reduced by over 15x,
demonstrating the effectiveness of integrating touch cues into 3D Gaussian
Splatting. Furthermore, our approach maintains a fully online pipeline,
underscoring its feasibility in visually degraded environments.

</details>


### [522] [RIS-Assisted NOMA with Partial CSI and Mutual Coupling: A Machine Learning Approach](https://arxiv.org/abs/2508.07909)
*Bile Peng,Karl-Ludwig Besser,Shanpu Shen,Finn Siegismund-Poschmann,Ramprasad Raghunath,Daniel M. Mittleman,Vahid Jamali,Eduard A. Jorswieck*

Main category: eess.SP

TL;DR: 本研究提出了一种利用RISnet神经网络优化NOMA系统中的基站预编码和RIS配置的方法，相比现有技术，该方法在可扩展性、CSI需求和互耦处理方面表现更优，并且是领域知识驱动机器学习的早期贡献。


<details>
  <summary>Details</summary>
Motivation: 为了提升非正交多址（NOMA）技术的性能，该研究旨在利用可重构智能表面（RIS）来改善无线信道特性。

Method: 通过设计名为RISnet的神经网络架构，并结合通信领域的领域知识，实现了对基站预编码和RIS配置的联合优化。

Result: 与现有技术相比，该方法结合了最优基站预编码和机器学习驱动的RIS，具有良好的可扩展性（可控制超过1000个RIS单元），对信道状态信息（CSI）的要求低，并能处理RIS单元间的互耦问题。

Conclusion: 该论文提出了一种结合了基站预编码和RIS配置的联合优化方法，并利用无监督机器学习实现自主最优解的搜索。

Abstract: Non-orthogonal multiple access (NOMA) is a promising multiple access
technique. Its performance depends strongly on the wireless channel property,
which can be enhanced by reconfigurable intelligent surfaces (RISs). In this
paper, we jointly optimize base station (BS) precoding and RIS configuration
with unsupervised machine learning (ML), which looks for the optimal solution
autonomously. In particular, we propose a dedicated neural network (NN)
architecture RISnet inspired by domain knowledge in communication. Compared to
state-of-the-art, the proposed approach combines analytical optimal BS
precoding and ML-enabled RIS, has a high scalability to control more than 1000
RIS elements, has a low requirement for channel state information (CSI) in
input, and addresses the mutual coupling between RIS elements. Beyond the
considered problem, this work is an early contribution to domain knowledge
enabled ML, which exploit the domain expertise of communication systems to
design better approaches than general ML methods.

</details>


### [523] [Advancing the Control of Low-Altitude Wireless Networks: Architecture, Design Principles, and Future Directions](https://arxiv.org/abs/2508.07967)
*Haijia Jin,Weijie Yuan,Jun Wu,Jiacheng Wang,Dusit Niyato,Xianbin Wang,George K. Karagiannidis,Zhiyun Lin,Yi Gong,Dong In Kim,Athina Petropulu,Maria Sabrina Greco,Abbas Jamalipour,Sumei Sun*

Main category: eess.SP

TL;DR: Introduces a low-altitude wireless network (LAWN) for aerial-ground environments, focusing on control, communication, and estimation, with a case study and future directions.


<details>
  <summary>Details</summary>
Motivation: The motivation is to support reliable networked control in dynamic aerial-ground environments by integrating near-ground communications and remote estimation of the internal system state.

Method: The paper introduces the network's modular architecture and key performance metrics, discusses core design trade-offs across control, communication, and estimation layers, and includes a case study illustrating closed-loop coordination under wireless constraints.

Result: The paper presents a control-oriented low-altitude wireless network (LAWN) and illustrates its closed-loop coordination under wireless constraints through a case study.

Conclusion: This article introduces a control-oriented low-altitude wireless network (LAWN) that integrates near-ground communications and remote estimation of the internal system state, supporting reliable networked control in dynamic aerial-ground environments. It also discusses core design trade-offs and illustrates closed-loop coordination under wireless constraints, outlining future directions for scalable, resilient LAWN deployments.

Abstract: This article introduces a control-oriented low-altitude wireless network
(LAWN) that integrates near-ground communications and remote estimation of the
internal system state. This integration supports reliable networked control in
dynamic aerial-ground environments. First, we introduce the network's modular
architecture and key performance metrics. Then, we discuss core design
trade-offs across the control, communication, and estimation layers. A case
study illustrates closed-loop coordination under wireless constraints. Finally,
we outline future directions for scalable, resilient LAWN deployments in
real-time and resource-constrained scenarios.

</details>


### [524] [Robust Design of Beyond-Diagonal Reconfigurable Intelligent Surface Empowered RSMA-SWIPT System Under Channel Estimation Errors](https://arxiv.org/abs/2508.08097)
*Muhammad Asif,Zain Ali,Asim Ihsan,Ali Ranjha,Zhu Shoujin,Manzoor Ahmed,Xingwang Li,Symeon Chatzinotas*

Main category: eess.SP

TL;DR: 本研究集成了RSMA、SWIPT和BD-RIS技术，通过鲁棒优化和交替优化算法，在不完美信道和非线性能量收集的条件下，最大化了6G网络的和速率，并取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了提高未来第六代（6G）通信网络的频谱效率、能源效率、覆盖范围和连接性，本研究探索了速率分裂多址（RSMA）、同步无线信息与能量传输（SWIPT）以及超越对角可重构智能表面（BD-RIS）的集成。

Method: 本研究提出了一种联合优化预编码向量、用户公共速率比例、功率分配比和BD-RIS散射矩阵的鲁棒优化框架，以最大化系统和速率。该框架利用交替优化方法，将问题分解为多个子问题，并采用连续凸近似（SCA）、凸半定规划、MOSEK驱动的CVX工具箱以及基于共轭梯度法的流形优化策略进行求解，同时考虑了不完美的信道状态信息（CSI）和非线性能量收集模型。

Result: 通过仿真结果验证，所提出的方案在多项关键性能指标上显著优于现有方法，并展示了良好的收敛性。

Conclusion: 所提出的方案在频谱效率、能源效率、覆盖范围和连接性方面均优于现有基准，并且在合理的迭代次数内收敛速度快。

Abstract: This work explores the integration of rate-splitting multiple access (RSMA),
simultaneous wireless information and power transfer (SWIPT), and
beyond-diagonal reconfigurable intelligent surface (BD-RIS) to enhance the
spectral-efficiency, energy-efficiency, coverage, and connectivity of future
sixth-generation (6G) communication networks. Specifically, with a multiuser
BD-RIS-empowered RSMA-SWIPT system, we jointly optimize the transmit precoding
vectors, the common rate proportion of users, the power-splitting ratios, and
scattering matrix of BD-RIS node, under the assumption of imperfect channel
state information (CSI). Additionally, to better capture practical hardware
behavior, we incorporate a nonlinear energy harvesting model under energy
harvesting constraints. We design a robust optimization framework to maximize
the system sum-rate, while explicitly accounting for the worst-case impact of
CSI uncertainties. Further, we introduce an alternating optimization framework
that partitions the problem into several blocks, which are optimized
iteratively. More specifically, the transmit precoding vectors are optimized by
reformulating the problem as a convex semidefinite programming through
successive-convex approximation (SCA), whereas the power-splitting problem is
solved using the MOSEK-enabled CVX toolbox. Subsequently, to optimize the
scattering matrix of the BD-RIS, we first employ SCA to reformulate the problem
into a convex form, and then design a manifold optimization strategy based on
the Conjugate-Gradient method. Finally, numerical simulation results reveal
that the proposed scheme provides significant performance improvements over
existing benchmarks and demonstrates rapid convergence within a reasonable
number of iterations.

</details>


### [525] [Adaptive Learning for IRS-Assisted Wireless Networks: Securing Opportunistic Communications Against Byzantine Eavesdroppers](https://arxiv.org/abs/2508.08206)
*Amirhossein Taherpour,Abbas Taherpour,Tamer Khattab*

Main category: eess.SP

TL;DR: "A joint learning framework for Byzantine-resilient spectrum sensing and secure IRS-assisted opportunistic access under CSI uncertainty is proposed. The framework utilizes logit-domain Bayesian updates and trimmed aggregation for sensing, and an augmented-Lagrangian alternating algorithm or constrained Bayesian optimization for downlink design, depending on CSI availability. The simulations demonstrate improved detection probability, reduced sum MSE, suppressed eavesdropper signal power, and fast convergence."


<details>
  <summary>Details</summary>
Motivation: "To propose a joint learning framework for Byzantine-resilient spectrum sensing and secure intelligent reflecting surface (IRS)--assisted opportunistic access under channel state information (CSI) uncertainty."

Method: "The sensing stage performs logit-domain Bayesian updates with trimmed aggregation and attention-weighted consensus, and the base station (BS) fuses network beliefs with a conservative minimum rule. With partial (or known) CSI, an augmented-Lagrangian alternating algorithm with projected updates is developed. With unknown CSI, constrained Bayesian optimization (BO) in a geometry-aware low-dimensional latent space using Gaussian process (GP) surrogates is performed."

Result: "Simulations show higher detection probability at fixed false-alarm rate under adversarial attacks, large reductions in sum MSE for honest users, strong suppression of eavesdropper signal power, and fast convergence."

Conclusion: "The framework offers a practical path to secure opportunistic communication that adapts to CSI availability while coherently coordinating sensing and transmission through joint learning."

Abstract: We propose a joint learning framework for Byzantine-resilient spectrum
sensing and secure intelligent reflecting surface (IRS)--assisted opportunistic
access under channel state information (CSI) uncertainty. The sensing stage
performs logit-domain Bayesian updates with trimmed aggregation and
attention-weighted consensus, and the base station (BS) fuses network beliefs
with a conservative minimum rule, preserving detection accuracy under a bounded
number of Byzantine users. Conditioned on the sensing outcome, we pose downlink
design as sum mean-squared error (MSE) minimization under transmit-power and
signal-leakage constraints and jointly optimize the BS precoder, IRS phase
shifts, and user equalizers. With partial (or known) CSI, we develop an
augmented-Lagrangian alternating algorithm with projected updates and provide
provable sublinear convergence, with accelerated rates under mild local
curvature. With unknown CSI, we perform constrained Bayesian optimization (BO)
in a geometry-aware low-dimensional latent space using Gaussian process (GP)
surrogates; we prove regret bounds for a constrained upper confidence bound
(UCB) variant of the BO module, and demonstrate strong empirical performance of
the implemented procedure. Simulations across diverse network conditions show
higher detection probability at fixed false-alarm rate under adversarial
attacks, large reductions in sum MSE for honest users, strong suppression of
eavesdropper signal power, and fast convergence. The framework offers a
practical path to secure opportunistic communication that adapts to CSI
availability while coherently coordinating sensing and transmission through
joint learning.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [526] [Acoustic Holography in the Megahertz Frequency Range with Optimal Lens Topologies and Nonlinear Acoustic Feedback](https://arxiv.org/abs/2508.07103)
*Pradosh Pritam Dash,Costas D. Arvanitis*

Main category: physics.app-ph

TL;DR: 提出一种异构角谱方法，可优化透镜设计以实现高保真声全息术，并能补偿像差，用于神经干预。该方法还能通过声反馈实现颅骨补偿和脑脊液监测。


<details>
  <summary>Details</summary>
Motivation: 在兆赫兹频率范围内，声全息术在制造、无损检测和经颅超声等领域具有重要应用前景。然而，为复杂声全息图设计兆赫兹范围内的透镜拓扑是一个重大挑战，因为无法忽略波穿过透镜的传播效应。

Method: 提出了一种异构角谱方法，该方法能够结合平面内变化的声速图并支持透镜厚度剖面的快速可微优化。

Result: 该方法可生成高保真声全息术的透镜拓扑，并能校正波前像差。此外，研究还发现低频声反馈可实现颅骨补偿透镜对齐，并监测脑脊液容量变化，从而支持设计简单、经济、高性能的超声系统。

Conclusion: 该框架为高保真声全息术设计了透镜拓扑，并能补偿传播介质中的波前像差，有望用于高精度神经干预。

Abstract: Acoustic holography in the megahertz frequency range can impact numerous
applications, including manufacturing, non-destructive testing, and
transcranial ultrasound. However, designing lens topologies for complex
acoustic holograms in the megahertz range poses a significant challenge, as
weave propagation effects through the lens cannot be ignored. Here, we show
that the inherent ability of heterogeneous angular spectrum approach to
incorporate in plane varying speed-of-sound maps and support rapid
differentiable optimization of lens thickness profiles can generate lens
topologies for high fidelity acoustic holography. Crucially, we show that this
framework can also account for wavefront aberrations in the propagation media,
providing the opportunity to reconfigure this disruptive technology for high
precision neuro-interventions. Our investigations also revealed that low
frequency acoustic feedback generated by nonlinear mixing of high frequency
waves allows attaining accurate skull-compensating lens alignment and creates
the possibility to monitor CSF fluid build-up and removal in hydrocephalus.
Together, our findings support the design of simple, economical, and
high-performance ultrasound systems.

</details>


### [527] [Determining the acceleration field of a rigid body using three accelerometers and one gyroscope, with applications in mild traumatic brain injury](https://arxiv.org/abs/2508.07464)
*Yang Wan,Benjamin E. Grossman-Ponemona,Haneesh Kesari*

Main category: physics.app-ph

TL;DR: 提出了一种利用加速度计和陀螺仪数据重建刚体运动的算法，克服了传统方法的缺点，并在足球头球实验中得到验证。


<details>
  <summary>Details</summary>
Motivation: 为了应对轻度创伤性脑损伤（mTBI）的预防，该研究旨在提供一种精确测量头部运动的方法，因为大多数预防策略都依赖于运动或变形损伤标准。

Method: 提出了一种从三个三轴加速度计和一个三轴陀螺仪的测量数据中重建刚体完整加速度场的算法。该算法通过求解源自刚体运动学的方程组来恢复角加速度和平行加速度，克服了传统方法的局限性。

Result: 在控制下的足球头球实验中验证了该算法，证明了其在各试验中准确预测非传感位置加速度的能力。

Conclusion: 该算法为刚体运动重建提供了一个强大、灵活且高效的工具，可直接应用于接触性运动、机器人技术和生物力学损伤预测。

Abstract: Mild traumatic brain injury (mTBI) often results from violent head motion or
impact. Most prevention strategies explicitly or implicitly rely on motion- or
deformation-based injury criteria, both of which require accurate measurements
of head motion. We present an algorithm for reconstructing the full
acceleration field of a rigid body from measurements obtained by three
tri-axial accelerometers and one tri-axial gyroscope. Unlike traditional
gyroscope-based methods, which require numerically differentiating noisy
angular velocity data, or gyroscope-free methods, which may impose restrictive
sensor placement or involve nonlinear optimization, the proposed algorithm
recovers angular acceleration and translational acceleration by solving a set
of linear equations derived from rigid body kinematics. In the proposed method,
the only constraint on sensor placement is that the accelerometers must be
non-collinear. We validated the algorithm in controlled soccer heading
experiments, demonstrating accurate prediction of accelerations at unsensed
locations across trials. The proposed algorithm provides a robust, flexible,
and efficient tool for reconstructing rigid body motion, with direct
applications in contact sports, robotics, and biomechanical injury prediction.

</details>


### [528] [Fabry-Pérot quasinormal modes for topological edge states](https://arxiv.org/abs/2508.07767)
*Marc Martí-Sabaté,Benjamin Vial,Richard Wiltshaw,Sébastien Guenneau,Richard V. Craster*

Main category: physics.app-ph

TL;DR: Topological waveguides are usually studied in infinite systems, but this paper introduces a new method (QMEM) for finite systems, showing topological states are like leaky cavity modes.


<details>
  <summary>Details</summary>
Motivation: To propose an alternative framework for analyzing topologically non-trivial states in open, finite systems, as practical implementations are finite, unlike typical studies of topological insulators which use infinite spectral problems.

Method: Quasinormal Modal Expansion Method (QMEM)

Result: The QMEM directly characterizes the existence and excitation of topological modes in open systems. The complex and discrete spectrum reveals an analogy of topological mode steering with a Fabry-Pérot cavity, showing a dispersion relation related to the infinite ribbon problem.

Conclusion: The study proposes a Quasinormal Modal Expansion Method (QMEM) to analyze topologically non-trivial states in open, finite systems, offering a new framework for understanding topological mode steering and analyzing finite topological devices.

Abstract: Topological waveguides supporting quantum valley Hall interfacial states
confine waves to interfaces and, due to topological protection, are resistant
to backscattering even in the presence of defects. These topological insulators
are typically studied by means of an infinite spectral problem. However,
practical implementations are necessarily finite. In this work, we propose an
alternative framework for analysing topologically non-trivial states in open,
finite systems. Our approach is based on a Quasinormal Modal Expansion Method
(QMEM), which directly characterizes the existence and excitation of these
modes within the open system. The resulting spectrum is complex and discrete
and fully describes the topologically non-trivial states, revealing an analogy
of topological mode steering as a dispersive Fabry-P\'erot cavity, with a
dispersion relation closely related to that of the corresponding infinite
(Floquet-Bloch) ribbon problem. Our results illustrate how topologically
protected waveguiding can be understood in terms of leaky cavity modes and
offers a powerful framework for analysing finite topological devices.

</details>


### [529] [Optical discrimination of live single cancer cells using reflection-based nanohole array sensor](https://arxiv.org/abs/2508.08205)
*Alfredo Franco,Izan Calderón,Dolores Ortiz,José L. Fernández-Luna,Fernando Moreno*

Main category: physics.app-ph

TL;DR: 这项研究开发了一种基于反射的纳米孔阵列传感器，可以区分具有迁移能力的癌细胞和无法迁移的癌细胞，其准确性通过分析反射光的生化特征得到验证。


<details>
  <summary>Details</summary>
Motivation: 为了开发一种能够区分具有迁移能力癌细胞和无法迁移癌细胞的诊断工具，同时克服现有透射式方法的局限性，实现更实际的诊断应用。

Method: 本研究提出了一种基于反射的纳米孔阵列传感器系统，通过分析活单细胞对反射光的，光谱特征来区分癌细胞。

Result: 研究证明，肌动球蛋白皮层的存在会显著影响癌细胞的光学响应，从而可以实现高灵敏度和特异性的细胞分类。

Conclusion: 本研究展示了一种基于反射的纳米孔阵列传感器系统，用于区分具有完整肌动球蛋白皮层的迁移能力癌细胞和缺乏肌动球蛋白皮层而无法迁移的癌细胞。与先前的透射式方法不同，这种配置可以更实际地集成到原地诊断工具中。首次通过研究活单细胞对反射光的光谱特征来分析系统性能。结果表明，对于细胞迁移所必需的肌动球蛋白皮层的存在，会显著影响不同类型癌细胞的光学响应，从而实现高灵敏度和特异性的细胞分类。本研究结果为基于反射的等离子体生物传感器设备作为开发生物医学应用工具的紧凑高效平台铺平了道路。

Abstract: In this research, a reflection-based nanohole array sensor system is
presented for discriminating between migration-competent cancer cells that
maintain the integrity of the actin cortex and those cells lacking the actin
cortex and thus unable to migrate. Unlike previous transmission-based
approaches, this configuration allows for more practical integration into in
situ diagnostic tools. For the first time, the system performance is analyzed
by studying the spectral features of the reflected light by live single cells.
We demonstrate that the presence of the actin cortex, needed for cell
migration, in different types of cancer cells significantly affect their
optical response, enabling high sensitivity and specificity in cell
classification. Our results pave the way for reflection-based plasmonic
biosensor devices as a compact and efficient platform for developing biomedical
application tools.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [530] [Energy Efficient Task Offloading in UAV-Enabled MEC Using a Fully Decentralized Deep Reinforcement Learning Approach](https://arxiv.org/abs/2508.06863)
*Hamidreza Asadian-Rad,Hossein Soleimani,Shahrokh Farahmand*

Main category: cs.MA

TL;DR: 本文提出了一种基于GAT和EPS-PPO的完全去中心化DRL方法，用于优化UAV在MEC中的部署，解决了现有方法的局限性，并取得了优于MADDPG的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决无人机（UAV）在多路接入边缘计算（MEC）中，同时确保用户满意度和能源效率所面临的非凸性、用户未来位置和信道增益未知、以及（半）集中式处理带来的通信开销、瓶颈、缺乏灵活性和可扩展性、以及容错性差等挑战。

Method: 本研究提出了一种基于图注意力层（GAT）和经验参数共享近端策略优化（EPS-PPO）的完全去中心化深度强化学习（DRL）框架，用于解决无人机（UAV）在多路接入边缘计算（MEC）中的轨迹和用户分配优化问题。

Result: 与现有的MADDPG算法相比，该方法在多项标准上都取得了显著的性能提升，证明了仅利用本地通信即可获得更好性能的潜力。

Conclusion: 提出了一种完全去中心化的设置，消除了现有方法的局限性，并保证了比独立本地DRL更好的性能，同时仅使用本地通信。

Abstract: Unmanned aerial vehicles (UAVs) have been recently utilized in multi-access
edge computing (MEC) as edge servers. It is desirable to design UAVs'
trajectories and user to UAV assignments to ensure satisfactory service to the
users and energy efficient operation simultaneously. The posed optimization
problem is challenging to solve because: (i) The formulated problem is
non-convex, (ii) Due to the mobility of ground users, their future positions
and channel gains are not known in advance, (iii) Local UAVs' observations
should be communicated to a central entity that solves the optimization
problem. The (semi-) centralized processing leads to communication overhead,
communication/processing bottlenecks, lack of flexibility and scalability, and
loss of robustness to system failures. To simultaneously address all these
limitations, we advocate a fully decentralized setup with no centralized
entity. Each UAV obtains its local observation and then communicates with its
immediate neighbors only. After sharing information with neighbors, each UAV
determines its next position via a locally run deep reinforcement learning
(DRL) algorithm. None of the UAVs need to know the global communication graph.
Two main components of our proposed solution are (i) Graph attention layers
(GAT), and (ii) Experience and parameter sharing proximal policy optimization
(EPS-PPO). Our proposed approach eliminates all the limitations of
semi-centralized MADRL methods such as MAPPO and MA deep deterministic policy
gradient (MADDPG), while guaranteeing a better performance than independent
local DRLs such as in IPPO. Numerical results reveal notable performance gains
in several different criteria compared to the existing MADDPG algorithm,
demonstrating the potential for offering a better performance, while utilizing
local communications only.

</details>


### [531] [A Survey on Agentic Service Ecosystems: Measurement, Analysis, and Optimization](https://arxiv.org/abs/2508.07343)
*Xuwen Zhang,Xiao Xue,Xia Xie,Qun Ma,Xiangning Yu,Deyu Zhou,Yifan Wang,Ming Zhang*

Main category: cs.MA

TL;DR: 本论文提出一个分析代理服务生态系统中群体智能涌现的框架，通过测量、分析和优化三个步骤，并回顾现有技术，以应对复杂性和提供实际应用方法。


<details>
  <summary>Details</summary>
Motivation: 传统的线性分析方法不足以应对由具有不同行为和动机的异构自主代理组成的代理服务生态系统的复杂性。现有研究由于观点分散和跨生态系统的差异，未能全面捕捉代理环境中群体智能涌现的复杂性，缺乏统一的方法论也限制了研究的深度和系统性。

Method: 本研究提出一个包含测量、分析和优化三个步骤的框架，以分析代理服务生态系统中群体智能的涌现。该框架旨在揭示促进涌现的循环机制和定量标准。

Result: 通过回顾现有技术，分析其优缺点，确定尚未解决的挑战，并展示该框架如何为实际应用提供理论支持和可行方法。

Conclusion: 该论文提出了一个分析代理服务生态系统中群体智能涌现的框架，该框架包括测量、分析和优化三个步骤，以揭示促进涌现的循环机制和定量标准。

Abstract: The Agentic Service Ecosystem consists of heterogeneous autonomous agents
(e.g., intelligent machines, humans, and human-machine hybrid systems) that
interact through resource exchange and service co-creation. These agents, with
distinct behaviors and motivations, exhibit autonomous perception, reasoning,
and action capabilities, which increase system complexity and make traditional
linear analysis methods inadequate. Swarm intelligence, characterized by
decentralization, self-organization, emergence, and dynamic adaptability,
offers a novel theoretical lens and methodology for understanding and
optimizing such ecosystems. However, current research, owing to fragmented
perspectives and cross-ecosystem differences, fails to comprehensively capture
the complexity of swarm-intelligence emergence in agentic contexts. The lack of
a unified methodology further limits the depth and systematic treatment of the
research. This paper proposes a framework for analyzing the emergence of swarm
intelligence in Agentic Service Ecosystems, with three steps: measurement,
analysis, and optimization, to reveal the cyclical mechanisms and quantitative
criteria that foster emergence. By reviewing existing technologies, the paper
analyzes their strengths and limitations, identifies unresolved challenges, and
shows how this framework provides both theoretical support and actionable
methods for real-world applications.

</details>


### [532] [Retrieval-Augmented Multi-Agent System for Rapid Statement of Work Generation](https://arxiv.org/abs/2508.07569)
*Amulya Suravarjhula,Rashi Chandrashekhar Agrawal,Sakshi Jayesh Patel,Rahul Gupta*

Main category: cs.MA

TL;DR: AI自动化系统通过三个智能代理（起草、法律审查、格式化）革新了SOW的起草过程，实现了快速（<3分钟）、准确且合规的文档生成，显著优于传统手动方法。


<details>
  <summary>Details</summary>
Motivation: 传统的SOW起草过程耗时、复杂且容易出错，需要多人协作且耗时数天。本文旨在通过引入AI自动化系统来解决这些问题，提高SOW起草的速度、简易性和准确性。

Method: 本文介绍了一个由三个智能代理组成的AI驱动的自动化系统，用于起草SOW。一个代理负责生成初稿，第二个代理进行法律合规性检查，第三个代理负责格式化和整理文档。该系统能够理解内容含义并进行定制化处理，而非简单的模板填充。

Result: 通过实际业务案例测试，该系统能在不到三分钟的时间内完成SOW的起草，相比传统手动方法可节省数小时甚至数天。同时，在准确性和质量方面表现出色，能够降低法律风险并节省大量时间。

Conclusion: 该AI驱动的自动化系统能够显著提高SOW（工作说明书）的起草效率和准确性，通过三个智能代理协同工作，自动完成起草、法律审查和格式化，从而减少了时间和潜在的法律风险，使法律和商业专业人士能够专注于更重要的决策。

Abstract: Drafting a Statement of Work (SOW) is a vital part of business and legal
projects. It outlines key details like deliverables, timelines,
responsibilities, and legal terms. However, creating these documents is often a
slow and complex process. It usually involves multiple people, takes several
days, and leaves room for errors or outdated content. This paper introduces a
new AI-driven automation system that makes the entire SOW drafting process
faster, easier, and more accurate. Instead of relying completely on humans, the
system uses three intelligent components or 'agents' that each handle a part of
the job. One agent writes the first draft, another checks if everything is
legally correct, and the third agent formats the document and ensures
everything is in order. Unlike basic online tools that just fill in templates,
this system understands the meaning behind the content and customizes the SOW
to match the needs of the project. It also checks legal compliance and
formatting so that users can trust the result. The system was tested using real
business examples. It was able to create a full SOW in under three minutes,
compared to several hours or days using manual methods. It also performed well
in accuracy and quality, showing that it can reduce legal risks and save a lot
of time. This solution shows how artificial intelligence can be used to support
legal and business professionals by taking care of routine work and helping
them focus on more important decisions. It's a step toward making legal
processes smarter, faster, and more reliable.

</details>


### [533] [Toward Goal-Oriented Communication in Multi-Agent Systems: An overview](https://arxiv.org/abs/2508.07720)
*Themistoklis Charalambous,Nikolaos Pappas,Nikolaos Nomikos,Risto Wichman*

Main category: cs.MA

TL;DR: MAS通信面临资源约束的挑战，目标导向通信优先考虑信息对共享目标的重要性。本综述总结了MAS中的目标导向通信，包括基础概念、学习方法、新兴协议，并关注通信约束下的协调及应用，同时指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着MAS在自主系统、分布式控制和边缘智能中日益普及，在资源约束下进行高效通信成为一个关键挑战，传统通信范式忽视了通信信息的任务相关性，而目标导向通信优先考虑信息对代理共享目标的重要性。

Method: 本综述全面 survey 了MAS中的目标导向通信，涵盖了信息论、通信理论和机器学习等观点，并审视了基础概念、学习方法和新兴协议。

Result: 本文重点关注了通信约束下的协调问题，以及在群体机器人、联邦学习和边缘计算等领域的应用。

Conclusion: 本文总结了多智能体系统（MAS）中以目标为导向的通信，探讨了信息论、通信理论和机器学习等领域的交叉应用，并指出了未来的研究方向。

Abstract: As multi-agent systems (MAS) become increasingly prevalent in autonomous
systems, distributed control, and edge intelligence, efficient communication
under resource constraints has emerged as a critical challenge. Traditional
communication paradigms often emphasize message fidelity or bandwidth
optimization, overlooking the task relevance of the exchanged information. In
contrast, goal-oriented communication prioritizes the importance of information
with respect to the agents' shared objectives. This review provides a
comprehensive survey of goal-oriented communication in MAS, bridging
perspectives from information theory, communication theory, and machine
learning. We examine foundational concepts alongside learning-based approaches
and emergent protocols. Special attention is given to coordination under
communication constraints, as well as applications in domains such as swarm
robotics, federated learning, and edge computing. The paper concludes with a
discussion of open challenges and future research directions at the
intersection of communication theory, machine learning, and multi-agent
decision making.

</details>


### [534] [Multi-agent systems for chemical engineering: A review and perspective](https://arxiv.org/abs/2508.07880)
*Sophia Rupprecht,Qinghe Gao,Tanuj Karia,Artur M. Schweidtmann*

Main category: cs.MA

TL;DR: LLM驱动的多智能体系统（MASs）有潜力革新化工领域，但需要解决架构、数据、模型和安全等方面的挑战。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的多智能体系统（MASs）有潜力通过将复杂工作流分解为协作代理团队来改变化工领域。

Method: 本文对化工领域MASs的最新研究进展进行了综述。

Result: 早期研究结果显示出巨大潜力，但仍存在科学挑战。

Conclusion: LLM驱动的多智能体系统（MASs）为化工领域带来了革新潜力，但仍面临架构设计、异构数据整合、领域特定基础模型开发以及确保透明度、安全性和环境影响等方面的科学挑战。

Abstract: Large language model (LLM)-based multi-agent systems (MASs) are a recent but
rapidly evolving technology with the potential to transform chemical
engineering by decomposing complex workflows into teams of collaborative agents
with specialized knowledge and tools. This review surveys the state-of-the-art
of MAS within chemical engineering. While early studies demonstrate promising
results, scientific challenges remain, including the design of tailored
architectures, integration of heterogeneous data modalities, development of
foundation models with domain-specific modalities, and strategies for ensuring
transparency, safety, and environmental impact. As a young but fast-moving
field, MASs offer exciting opportunities to rethink chemical engineering
workflows.

</details>


<div id='q-bio.OT'></div>

# q-bio.OT [[Back]](#toc)

### [535] [Frequency-Domain Analysis of Time-Dependent Multiomic Data in Progressive Neurodegenerative Diseases: A Proposed Quantum-Classical Hybrid Approach with Quaternionic Extensions](https://arxiv.org/abs/2508.07948)
*John D. Mayfield*

Main category: q-bio.OT

TL;DR: 通过将时间序列数据转换为频域/s域，并利用量子-经典混合计算模拟神经元动力学，以提高对神经退行性疾病的模式检测和预测能力。


<details>
  <summary>Details</summary>
Motivation: 传统的时域分析难以捕捉神经退行性疾病（如阿尔茨海默病、多发性硬化症、帕金森病和肌萎缩侧索硬化症）数据中隐藏的振荡模式，限制了预测的准确性。

Method: 提出了一种理论数学框架，使用傅里叶变换和拉普拉斯变换将时间序列数据转换为频域或s域，通过哈密顿公式模拟神经元动力学，并采用量子-经典混合计算和变分量子本征求解器（VQE）进行增强模式检测。该方法利用量子优势处理高维幅-相数据，实现异常值检测和频率特征分析。

Result: 该框架利用量子优势处理高维幅-相数据，实现异常值检测和频率特征分析。量子机器学习（QML）在阿尔茨海默病分类中已达到99.89%的准确率。

Conclusion: 该框架旨在为通过未来验证重新定义神经退行性疾病的精准医疗奠定基础。

Abstract: Progressive neurodegenerative diseases, including Alzheimer's disease (AD),
multiple sclerosis (MS), Parkinson's disease (PD), and amyotrophic lateral
sclerosis (ALS), exhibit complex, nonlinear trajectories that challenge
deterministic modeling. Traditional time-domain analyses of multiomic and
neuroimaging data often fail to capture hidden oscillatory patterns, limiting
predictive accuracy. We propose a theoretical mathematical framework that
transforms time-series data into frequency or s-domain using Fourier and
Laplace transforms, models neuronal dynamics via Hamiltonian formulations, and
employs quantum-classical hybrid computing with variational quantum
eigensolvers (VQE) for enhanced pattern detection. This theoretical construct
serves as a foundation for future empirical works in quantum-enhanced analysis
of neurodegenerative diseases. We extend this to quaternionic representations
with three imaginary axes ($i, j, k$) to model multistate Hamiltonians in
multifaceted disorders, drawing from quantum neuromorphic computing to capture
entangled neural dynamics \citep{Pehle2020, Emani2019}. This approach leverages
quantum advantages in handling high-dimensional amplitude-phase data, enabling
outlier detection and frequency signature analysis. Potential clinical
applications include identifying high-risk patients with rapid progression or
therapy resistance using s-domain biomarkers, supported by quantum machine
learning (QML) precedents achieving up to 99.89% accuracy in Alzheimer's
classification \citep{Belay2024, Bhowmik2025}. This framework aims to lay the
groundwork for redefining precision medicine for neurodegenerative diseases
through future validations.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [536] [LSDTs: LLM-Augmented Semantic Digital Twins for Adaptive Knowledge-Intensive Infrastructure Planning](https://arxiv.org/abs/2508.06799)
*Naiyi Li,Zihui Ma,Runlong Yu,Lingyao Li*

Main category: cs.ET

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Digital Twins (DTs) offer powerful tools for managing complex infrastructure
systems, but their effectiveness is often limited by challenges in integrating
unstructured knowledge. Recent advances in Large Language Models (LLMs) bring
new potential to address this gap, with strong abilities in extracting and
organizing diverse textual information. We therefore propose LSDTs
(LLM-Augmented Semantic Digital Twins), a framework that helps LLMs extract
planning knowledge from unstructured documents like environmental regulations
and technical guidelines, and organize it into a formal ontology. This ontology
forms a semantic layer that powers a digital twin-a virtual model of the
physical system-allowing it to simulate realistic, regulation-aware planning
scenarios. We evaluate LSDTs through a case study of offshore wind farm
planning in Maryland, including its application during Hurricane Sandy. Results
demonstrate that LSDTs support interpretable, regulation-aware layout
optimization, enable high-fidelity simulation, and enhance adaptability in
infrastructure planning. This work shows the potential of combining generative
AI with digital twins to support complex, knowledge-driven planning tasks.

</details>


### [537] [Enhancing Mega-Satellite Networks with Generative Semantic Communication: A Networking Perspective](https://arxiv.org/abs/2508.07573)
*Binquan Guo,Wanting Yang,Zehui Xiong,Zhou Zhang,Baosheng Li,Zhu Han,Rahim Tafazolli,Tony Q. S. Quek*

Main category: cs.ET

TL;DR: GSC通过AI赋能，用传递语义信息代替原始数据，有望解决卫星通信的带宽和容量瓶颈。本文提出了GSC赋能的卫星网络架构和路由策略。


<details>
  <summary>Details</summary>
Motivation: 随着6G无线通信和巨型卫星星座的发展，尽管其能够实现全球无缝连接，但频谱稀缺和容量限制仍是制约其支持海量多媒体数据需求的重大挑战。因此，需要新的通信范式来克服这些限制。

Method: 本文提出了一种GSC赋能的卫星网络架构，并识别了关键使能技术。具体包括：1. 构建离散时间图来对GSC赋能的卫星网络中的语义编码器、解码器、知识库和资源变异进行建模。2. 基于该模型，开发了语义编码器和解码器的模型部署以及GSC兼容的路由方案。

Result: 文章通过性能评估展示了所提出的GSC赋能的卫星网络架构和路由方案的有效性，并为GSC赋能的卫星网络未来的研究方向提供了展望。

Conclusion: GSC为解决传统卫星通信的频谱稀缺和容量限制提供了新途径，通过交换语义信息来降低带宽消耗并增强多媒体内容的关键语义特征。文章提出了GSC赋能的卫星网络架构，并识别了关键技术，包括基于离散时间图的语义编码器/解码器、知识库和资源变异建模，以及GSC兼容的路由策略。

Abstract: The advance of direct satellite-to-device communication has positioned
mega-satellite constellations as a cornerstone of 6G wireless communication,
enabling seamless global connectivity even in remote and underserved areas.
However, spectrum scarcity and capacity constraints imposed by the Shannon's
classical information theory remain significant challenges for supporting the
massive data demands of multimedia-rich wireless applications. Generative
Semantic Communication (GSC), powered by artificial intelligence-based
generative foundation models, represents a paradigm shift from transmitting raw
data to exchanging semantic meaning. GSC can not only reduce bandwidth
consumption, but also enhance key semantic features in multimedia content,
thereby offering a promising solution to overcome the limitations of
traditional satellite communication systems. This article investigates the
integration of GSC into mega-satellite constellations from a networking
perspective. We propose a GSC-empowered satellite networking architecture and
identify key enabling technologies, focusing on GSC-empowered network modeling
and GSC-aware networking strategies. We construct a discrete temporal graph to
model semantic encoders and decoders, distinct knowledge bases, and resource
variations in mega-satellite networks. Based on this framework, we develop
model deployment for semantic encoders and decoders and GSC-compatible routing
schemes, and then present performance evaluations. Finally, we outline future
research directions for advancing GSC-empowered satellite networks.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [538] [Transfer Learning with EfficientNet for Accurate Leukemia Cell Classification](https://arxiv.org/abs/2508.06535)
*Faisal Ahmed*

Main category: eess.IV

TL;DR: 该研究通过使用EfficientNet-B3结合数据增强技术，在白血病诊断方面取得了高准确率，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 从外周血涂片图像中准确分类急性淋巴细胞白血病（ALL）对于早期诊断和有效治疗计划至关重要。

Method: 研究采用了迁移学习和预训练的卷积神经网络（CNN），并应用了数据增强技术来解决类别不平衡问题。评估了ResNet50、ResNet101和EfficientNet变体B0、B1和B3等模型。

Result: EfficientNet-B3取得了最佳结果，F1分数为94.30%，准确率为92.02%，AUC为94.79%，优于C-NMC挑战中先前报道的方法。

Conclusion: 这项研究表明，结合数据增强和先进的迁移学习模型（特别是EfficientNet-B3）可以有效地开发用于血癌诊断的准确且可靠的诊断工具。

Abstract: Accurate classification of Acute Lymphoblastic Leukemia (ALL) from peripheral
blood smear images is essential for early diagnosis and effective treatment
planning. This study investigates the use of transfer learning with pretrained
convolutional neural networks (CNNs) to improve diagnostic performance. To
address the class imbalance in the dataset of 3,631 Hematologic and 7,644 ALL
images, we applied extensive data augmentation techniques to create a balanced
training set of 10,000 images per class. We evaluated several models, including
ResNet50, ResNet101, and EfficientNet variants B0, B1, and B3. EfficientNet-B3
achieved the best results, with an F1-score of 94.30%, accuracy of 92.02%,
andAUCof94.79%,outperformingpreviouslyreported methods in the C-NMCChallenge.
Thesefindings demonstrate the effectiveness of combining data augmentation with
advanced transfer learning models, particularly EfficientNet-B3, in developing
accurate and robust diagnostic tools for hematologic malignancy detection.

</details>


### [539] [LWT-ARTERY-LABEL: A Lightweight Framework for Automated Coronary Artery Identification](https://arxiv.org/abs/2508.06874)
*Shisheng Zhang,Ramtin Gharleghi,Sonit Singh,Daniel Moses,Dona Adikari,Arcot Sowmya,Susann Beier*

Main category: eess.IV

TL;DR: 提出了一种轻量级方法，结合解剖学知识和基于规则的拓扑约束，用于有效的冠状动脉标记，解决了传统方法计算量大和深度学习方法需要大量计算资源的问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法计算量大，耗时，而深度学习方法需要大量计算资源并忽略了关键的临床知识。

Method: 提出了一种结合解剖学知识和基于规则的拓扑约束的轻量级方法，用于有效的冠状动脉标记。

Result: 实现了最先进的性能，为自动冠状动脉标记提供了一个有前景的替代方案。

Conclusion: 该方法在基准数据集上实现了最先进的性能，为自动冠状动脉标记提供了一个有前景的替代方案。

Abstract: Coronary artery disease (CAD) remains the leading cause of death globally,
with computed tomography coronary angiography (CTCA) serving as a key
diagnostic tool. However, coronary arterial analysis using CTCA, such as
identifying artery-specific features from computational modelling, is
labour-intensive and time-consuming. Automated anatomical labelling of coronary
arteries offers a potential solution, yet the inherent anatomical variability
of coronary trees presents a significant challenge. Traditional knowledge-based
labelling methods fall short in leveraging data-driven insights, while recent
deep-learning approaches often demand substantial computational resources and
overlook critical clinical knowledge. To address these limitations, we propose
a lightweight method that integrates anatomical knowledge with rule-based
topology constraints for effective coronary artery labelling. Our approach
achieves state-of-the-art performance on benchmark datasets, providing a
promising alternative for automated coronary artery labelling.

</details>


### [540] [Fusion-Based Brain Tumor Classification Using Deep Learning and Explainable AI, and Rule-Based Reasoning](https://arxiv.org/abs/2508.06891)
*Melika Filvantorkaman,Mohsen Piri,Maral Filvan Torkaman,Ashkan Zabihi,Hamidreza Moradi*

Main category: eess.IV

TL;DR: 本研究提出了一种结合MobileNetV2和DenseNet121的集成深度学习框架，用于对脑肿瘤MRI图像进行分类，并结合XAI和临床规则来提高模型的可解释性。该框架在准确性和可解释性方面均表现出色，并得到了放射科医生的积极评价。


<details>
  <summary>Details</summary>
Motivation: 准确且可解释的从MRI图像中对脑肿瘤进行分类，对于有效的诊断和治疗计划至关重要。

Method: 本研究提出了一种基于集成学习的深度学习框架，结合了MobileNetV2和DenseNet121卷积神经网络（CNN），并采用软投票策略对三种常见的脑肿瘤（胶质瘤、脑膜瘤和垂体瘤）进行分类。此外，该框架还集成了一个XAI模块（Grad-CAM++）用于可视化，以及一个符号化临床决策规则叠加（CDRO）模块，将预测映射到放射学启发式方法。

Result: 该集成学习分类器实现了91.7%的准确率、91.9%的精确率、91.7%的召回率和91.6%的F1分数，优于单独的CNN模型。Grad-CAM++可视化显示了模型注意力和专家标注的肿瘤区域在空间上高度一致（Dice系数高达0.88，IoU分数高达0.78）。临床规则激活也验证了模型在具有明显形态特征的病例中的预测。对5名放射科医生进行的评估显示，解释的有用性（平均4.4）和热图-区域对应性（平均4.0）的李克特量表评分都很高，进一步证实了该框架的临床相关性。

Conclusion: 该研究提出的方法为脑肿瘤分类提供了一个强大、可解释且可泛化的解决方案，促进了深度学习在临床神经诊断学中的整合。

Abstract: Accurate and interpretable classification of brain tumors from magnetic
resonance imaging (MRI) is critical for effective diagnosis and treatment
planning. This study presents an ensemble-based deep learning framework that
combines MobileNetV2 and DenseNet121 convolutional neural networks (CNNs) using
a soft voting strategy to classify three common brain tumor types: glioma,
meningioma, and pituitary adenoma. The models were trained and evaluated on the
Figshare dataset using a stratified 5-fold cross-validation protocol. To
enhance transparency and clinical trust, the framework integrates an
Explainable AI (XAI) module employing Grad-CAM++ for class-specific saliency
visualization, alongside a symbolic Clinical Decision Rule Overlay (CDRO) that
maps predictions to established radiological heuristics. The ensemble
classifier achieved superior performance compared to individual CNNs, with an
accuracy of 91.7%, precision of 91.9%, recall of 91.7%, and F1-score of 91.6%.
Grad-CAM++ visualizations revealed strong spatial alignment between model
attention and expert-annotated tumor regions, supported by Dice coefficients up
to 0.88 and IoU scores up to 0.78. Clinical rule activation further validated
model predictions in cases with distinct morphological features. A
human-centered interpretability assessment involving five board-certified
radiologists yielded high Likert-scale scores for both explanation usefulness
(mean = 4.4) and heatmap-region correspondence (mean = 4.0), reinforcing the
framework's clinical relevance. Overall, the proposed approach offers a robust,
interpretable, and generalizable solution for automated brain tumor
classification, advancing the integration of deep learning into clinical
neurodiagnostics.

</details>


### [541] [Spatio-Temporal Conditional Diffusion Models for Forecasting Future Multiple Sclerosis Lesion Masks Conditioned on Treatments](https://arxiv.org/abs/2508.07006)
*Gian Mario Favero,Ge Ya Luo,Nima Fathi,Justin Szeto,Douglas L. Arnold,Brennan Nichyporuk,Chris Pal,Tal Arbel*

Main category: eess.IV

TL;DR: 一种新的扩散模型可以根据 MRI 和治疗数据预测多发性硬化症的病变进展。


<details>
  <summary>Details</summary>
Motivation: 为了利用基于图像的个性化医疗的潜力，特别是对于像多发性硬化症 (MS) 这样进展异质性疾病的医疗保健。

Method: 提出了一种首创的、感知时间的扩散模型，该模型能够生成显示 MS 中病变进展的未来掩码。该模型采用体素空间方法，并结合了包括 MRI 和治疗信息在内的多模态患者数据，以预测未来时间点的新的和扩大的 T2 (NET2) 病变掩码。

Result: 在来自复发缓解型 MS 的随机临床试验的 2131 名患者的 3D MRI 的多中心数据集上进行了广泛的实验，证明了我们的生成模型能够准确预测跨六种不同治疗的患者的 NET2 病变掩码。此外，我们证明了我们的模型具有通过下游任务（例如，未来病变计数和位置估计、二元病变活动分类以及为几种具有不同疗效的治疗生成反事实未来 NET2 掩码）实现真实世界临床应用的潜力。

Conclusion: 这项工作强调了因果、基于图像的生成模型在推进 MS 数据驱动的预后方面的潜力。

Abstract: Image-based personalized medicine has the potential to transform healthcare,
particularly for diseases that exhibit heterogeneous progression such as
Multiple Sclerosis (MS). In this work, we introduce the first treatment-aware
spatio-temporal diffusion model that is able to generate future masks
demonstrating lesion evolution in MS. Our voxel-space approach incorporates
multi-modal patient data, including MRI and treatment information, to forecast
new and enlarging T2 (NET2) lesion masks at a future time point. Extensive
experiments on a multi-centre dataset of 2131 patient 3D MRIs from randomized
clinical trials for relapsing-remitting MS demonstrate that our generative
model is able to accurately predict NET2 lesion masks for patients across six
different treatments. Moreover, we demonstrate our model has the potential for
real-world clinical applications through downstream tasks such as future lesion
count and location estimation, binary lesion activity classification, and
generating counterfactual future NET2 masks for several treatments with
different efficacies. This work highlights the potential of causal, image-based
generative models as powerful tools for advancing data-driven prognostics in
MS.

</details>


### [542] [Trustworthy Medical Imaging with Large Language Models: A Study of Hallucinations Across Modalities](https://arxiv.org/abs/2508.07031)
*Anindya Bijoy Das,Shahnewaz Karim Sakib,Shibbir Ahmed*

Main category: eess.IV

TL;DR: LLMs在医学影像中会产生幻觉，影响临床决策。本研究分析了影像到文本和文本到影像任务中的幻觉，发现了常见错误，并讨论了如何提高LLM在医学影像中的安全性和可信赖性。


<details>
  <summary>Details</summary>
Motivation: LLMs在医学影像领域的应用日益广泛，但其产生的幻觉可能误导临床决策，因此有必要系统性地研究这些幻觉现象。

Method: 本研究通过分析LLMs在医学影像解释（影像到文本）和合成（文本到影像）任务中的幻觉现象，揭示了事实不一致和解剖学不准确等常见错误模式，并依据专家标准评估了不同影像模态下的输出。

Result: 研究发现了LLMs在医学影像解释和生成任务中普遍存在的幻觉模式，并探讨了导致这些问题的因素，包括模型架构和训练数据。

Conclusion: LLMs在医学影像领域的应用虽然广泛，但其产生的幻觉（尽管自信但错误的输出）对临床决策可能产生误导。本研究通过分析LLMs在医学影像解释（影像到文本）和合成（文本到影像）任务中的幻觉现象，揭示了事实不一致和解剖学不准确等常见错误模式，并依据专家标准评估了不同影像模态下的输出。研究结果对LLM在医学影像系统中的安全性和可信赖性具有重要意义，并探讨了模型架构和训练数据等因素对这些失败的影响。

Abstract: Large Language Models (LLMs) are increasingly applied to medical imaging
tasks, including image interpretation and synthetic image generation. However,
these models often produce hallucinations, which are confident but incorrect
outputs that can mislead clinical decisions. This study examines hallucinations
in two directions: image to text, where LLMs generate reports from X-ray, CT,
or MRI scans, and text to image, where models create medical images from
clinical prompts. We analyze errors such as factual inconsistencies and
anatomical inaccuracies, evaluating outputs using expert informed criteria
across imaging modalities. Our findings reveal common patterns of hallucination
in both interpretive and generative tasks, with implications for clinical
reliability. We also discuss factors contributing to these failures, including
model architecture and training data. By systematically studying both image
understanding and generation, this work provides insights into improving the
safety and trustworthiness of LLM driven medical imaging systems.

</details>


### [543] [3DGS-VBench: A Comprehensive Video Quality Evaluation Benchmark for 3DGS Compression](https://arxiv.org/abs/2508.07038)
*Yuke Xing,William Gordon,Qi Yang,Kaifa Yang,Jiarui Wang,Yiling Xu*

Main category: eess.IV

TL;DR: 3DGS-VBench：首个3DGS压缩视频质量评估基准，包含660个模型和视频，用于训练VQA模型和推动压缩研究。


<details>
  <summary>Details</summary>
Motivation: 为了解决3DGS模型存储需求大以及现有压缩技术引入的独特失真缺乏系统性质量评估问题。

Method: 创建了一个包含660个压缩3DGS模型和视频序列的大规模视频质量评估（VQA）数据集和基准（3DGS-VBench），涵盖11个场景和6个SOTA 3DGS压缩算法。收集了50名参与者的MOS评分，并验证了数据集的可靠性。对6个3DGS压缩算法进行了基准测试，并评估了15个质量评估指标。

Result: 建立了3DGS-VBench数据集，并对6个3DGS压缩算法的存储效率和视觉质量进行了基准测试，同时评估了15个质量评估指标。

Conclusion: 该研究建立了3DGS-VBench，一个大规模视频质量评估（VQA）数据集和基准，包含660个压缩的3DGS模型和视频序列，来自11个场景和6个SOTA 3DGS压缩算法。通过50名参与者的标注，获得了MOS分数，并验证了数据集的可靠性。研究对6个3DGS压缩算法的存储效率和视觉质量进行了基准测试，并评估了15个跨多个范式的质量评估指标。该研究支持专门的3DGS VQA模型训练，并促进压缩和质量评估研究。

Abstract: 3D Gaussian Splatting (3DGS) enables real-time novel view synthesis with high
visual fidelity, but its substantial storage requirements hinder practical
deployment, prompting state-of-the-art (SOTA) 3DGS methods to incorporate
compression modules. However, these 3DGS generative compression techniques
introduce unique distortions lacking systematic quality assessment research. To
this end, we establish 3DGS-VBench, a large-scale Video Quality Assessment
(VQA) Dataset and Benchmark with 660 compressed 3DGS models and video sequences
generated from 11 scenes across 6 SOTA 3DGS compression algorithms with
systematically designed parameter levels. With annotations from 50
participants, we obtained MOS scores with outlier removal and validated dataset
reliability. We benchmark 6 3DGS compression algorithms on storage efficiency
and visual quality, and evaluate 15 quality assessment metrics across multiple
paradigms. Our work enables specialized VQA model training for 3DGS, serving as
a catalyst for compression and quality assessment research. The dataset is
available at https://github.com/YukeXing/3DGS-VBench.

</details>


### [544] [SAGCNet: Spatial-Aware Graph Completion Network for Missing Slice Imputation in Population CMR Imaging](https://arxiv.org/abs/2508.07041)
*Junkai Liu,Nay Aung,Theodoros N. Arvanitis,Stefan K. Piechnik,Joao A C Lima,Steffen E. Petersen,Le Zhang*

Main category: eess.IV

TL;DR: SAGCNet是一种用于心脏MRI的3D重建方法，通过图结构和空间适配器来补全缺失的切片，即使数据有限也能取得优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 解决了现有三维磁共振成像（MRI）数据（如心脏磁共振（CMR））在缺失切片时难以建模切片间的局部相关性和依赖性，以及有限地探索三维空间信息和全局上下文的问题。

Method: 提出了一种名为空间感知图补全网络（SAGCNet）的方法，该方法包含两个关键创新：1.一个空间感知图补全模块，将切片间的关系构建成图结构；2.一个空间适配组件，使模型能够捕捉和利用各种形式的三维空间上下文。

Result: 在心脏MRI数据集上进行的广泛实验表明，SAGCNet能够合成缺失的CMR切片，并且在定量和定性方面均优于竞争性的最先进的MRI合成方法。

Conclusion: SAGCNet在CMR数据上能够合成缺失的CMR切片，并且在定量和定性方面均优于其他最先进的MRI合成方法。此外，即使在切片数据有限的情况下，该模型也能保持优越的性能。

Abstract: Magnetic resonance imaging (MRI) provides detailed soft-tissue
characteristics that assist in disease diagnosis and screening. However, the
accuracy of clinical practice is often hindered by missing or unusable slices
due to various factors. Volumetric MRI synthesis methods have been developed to
address this issue by imputing missing slices from available ones. The inherent
3D nature of volumetric MRI data, such as cardiac magnetic resonance (CMR),
poses significant challenges for missing slice imputation approaches, including
(1) the difficulty of modeling local inter-slice correlations and dependencies
of volumetric slices, and (2) the limited exploration of crucial 3D spatial
information and global context. In this study, to mitigate these issues, we
present Spatial-Aware Graph Completion Network (SAGCNet) to overcome the
dependency on complete volumetric data, featuring two main innovations: (1) a
volumetric slice graph completion module that incorporates the inter-slice
relationships into a graph structure, and (2) a volumetric spatial adapter
component that enables our model to effectively capture and utilize various
forms of 3D spatial context. Extensive experiments on cardiac MRI datasets
demonstrate that SAGCNet is capable of synthesizing absent CMR slices,
outperforming competitive state-of-the-art MRI synthesis methods both
quantitatively and qualitatively. Notably, our model maintains superior
performance even with limited slice data.

</details>


### [545] [Large-scale Multi-sequence Pretraining for Generalizable MRI Analysis in Versatile Clinical Applications](https://arxiv.org/abs/2508.07165)
*Zelin Qiu,Xi Wang,Zhuoyao Xie,Juan Zhou,Yu Wang,Lingjie Yang,Xinrui Jiang,Juyoung Bae,Moo Hyun Son,Qiang Ye,Dexuan Chen,Rui Zhang,Tao Li,Neeraj Ramesh Mahboobani,Varut Vardhanabhuti,Xiaohui Duan,Yinghua Zhao,Hao Chen*

Main category: eess.IV

TL;DR: PRISM是一個在大規模多序列MRI上預訓練的基礎模型，能有效解決MRI序列異質性帶來的泛化能力挑戰，在多項下游任務中表現優於現有模型，顯著提升了AI在放射學中的臨床應用潛力。


<details>
  <summary>Details</summary>
Motivation: 解決深度學習模型在處理多序列MRI時，因序列異質性導致的泛化能力挑戰，以及由此對模型性能和臨床應用的限制。

Method: 透過收集64個資料集，包含336,476個MRI掃描，建構了目前最大規模的多器官、多序列MRI預訓練語料庫。提出了一種新穎的預訓練範式，旨在將MRI中的解剖結構不變特徵與序列特異性變化分離，同時保留高階語義表徵。

Result: PRISM在39/44項下游任務中取得第一名，顯著優於對照組，證明了其在不同MRI協議下學習穩健且可泛化表徵的能力。

Conclusion: PRISM模型在跨越不同MRI序列和解剖結構的44項下游任務中，相比未預訓練模型和現有基礎模型，表現出優越的泛化能力，並在39項任務中取得了顯著的統計學優勢，顯示其學習穩健、可泛化表徵的能力，從而增強了AI在放射學中的轉化潛力，並提高了其臨床適用性。

Abstract: Multi-sequence Magnetic Resonance Imaging (MRI) offers remarkable
versatility, enabling the distinct visualization of different tissue types.
Nevertheless, the inherent heterogeneity among MRI sequences poses significant
challenges to the generalization capability of deep learning models. These
challenges undermine model performance when faced with varying acquisition
parameters, thereby severely restricting their clinical utility. In this study,
we present PRISM, a foundation model PRe-trained with large-scale
multI-Sequence MRI. We collected a total of 64 datasets from both public and
private sources, encompassing a wide range of whole-body anatomical structures,
with scans spanning diverse MRI sequences. Among them, 336,476 volumetric MRI
scans from 34 datasets (8 public and 26 private) were curated to construct the
largest multi-organ multi-sequence MRI pretraining corpus to date. We propose a
novel pretraining paradigm that disentangles anatomically invariant features
from sequence-specific variations in MRI, while preserving high-level semantic
representations. We established a benchmark comprising 44 downstream tasks,
including disease diagnosis, image segmentation, registration, progression
prediction, and report generation. These tasks were evaluated on 32 public
datasets and 5 private cohorts. PRISM consistently outperformed both
non-pretrained models and existing foundation models, achieving first-rank
results in 39 out of 44 downstream benchmarks with statistical significance
improvements. These results underscore its ability to learn robust and
generalizable representations across unseen data acquired under diverse MRI
protocols. PRISM provides a scalable framework for multi-sequence MRI analysis,
thereby enhancing the translational potential of AI in radiology. It delivers
consistent performance across diverse imaging protocols, reinforcing its
clinical applicability.

</details>


### [546] [HaDM-ST: Histology-Assisted Differential Modeling for Spatial Transcriptomics Generation](https://arxiv.org/abs/2508.07225)
*Xuepeng Liu,Zheng Jiang,Pinan Zhu,Hanyu Liu,Chao Li*

Main category: eess.IV

TL;DR: HaDM-ST 是一个利用 H&E 图像和低分辨率 ST 生成高分辨率 ST 的框架，解决了现有方法的三个主要挑战，并在实验中表现出优越性。


<details>
  <summary>Details</summary>
Motivation: 目前的空间转录组学 (ST) 技术分辨率有限，尽管有利用 H&E 染色组织学图像来提高分辨率的方法，但仍存在三个主要挑战：从视觉上复杂的 H&E 图像中分离出与表达相关的特征；在基于扩散的框架中实现空间精确的多模态对齐；以及模拟跨表达通道的基因特异性变异。

Method: HaDM-ST 框架包含一个语义蒸馏网络，用于从 H&E 图像中提取预测线索；一个空间对齐模块，用于强制与低分辨率 ST 进行像素级对应；以及一个通道感知对抗学习器，用于进行细粒度的基因水平建模。

Result: 在跨越不同组织和物种的 200 个基因的实验中，HaDM-ST 在提高空间保真度和基因水平相干性方面优于现有方法。

Conclusion: HaDM-ST 在真实世界的数据中表现优于现有方法，提高了高分辨率 ST 预测的空间保真度和基因水平相干性。

Abstract: Spatial transcriptomics (ST) reveals spatial heterogeneity of gene
expression, yet its resolution is limited by current platforms. Recent methods
enhance resolution via H&E-stained histology, but three major challenges
persist: (1) isolating expression-relevant features from visually complex H&E
images; (2) achieving spatially precise multimodal alignment in diffusion-based
frameworks; and (3) modeling gene-specific variation across expression
channels. We propose HaDM-ST (Histology-assisted Differential Modeling for ST
Generation), a high-resolution ST generation framework conditioned on H&E
images and low-resolution ST. HaDM-ST includes: (i) a semantic distillation
network to extract predictive cues from H&E; (ii) a spatial alignment module
enforcing pixel-wise correspondence with low-resolution ST; and (iii) a
channel-aware adversarial learner for fine-grained gene-level modeling.
Experiments on 200 genes across diverse tissues and species show HaDM-ST
consistently outperforms prior methods, enhancing spatial fidelity and
gene-level coherence in high-resolution ST predictions.

</details>


### [547] [DiffVC-OSD: One-Step Diffusion-based Perceptual Neural Video Compression Framework](https://arxiv.org/abs/2508.07682)
*Wenzhuo Ma,Zhenzhong Chen*

Main category: eess.IV

TL;DR: DiffVC-OSD 是一种创新的单步扩散视频编解码框架，在保持高感知质量的同时，显著提高了压缩效率和解码速度。


<details>
  <summary>Details</summary>
Motivation: 为了提高感知质量和压缩性能，提出了一种新的单步扩散视频编解码框架。

Method: 提出了一种名为 DiffVC-OSD 的单步扩散视频编解码框架，通过单步扩散模型增强感知质量，并设计了时间上下文适配器来利用时间依赖性，最后采用端到端微调策略来提高整体性能。

Result: DiffVC-OSD 在感知压缩性能上达到了最先进水平，解码速度提高了 20 倍，比特率降低了 86.92%。

Conclusion: DiffVC-OSD 实现了最先进的感知压缩性能，解码速度比多步扩散方法快 20 倍，比特率降低了 86.92%。

Abstract: In this work, we first propose DiffVC-OSD, a One-Step Diffusion-based
Perceptual Neural Video Compression framework. Unlike conventional multi-step
diffusion-based methods, DiffVC-OSD feeds the reconstructed latent
representation directly into a One-Step Diffusion Model, enhancing perceptual
quality through a single diffusion step guided by both temporal context and the
latent itself. To better leverage temporal dependencies, we design a Temporal
Context Adapter that encodes conditional inputs into multi-level features,
offering more fine-grained guidance for the Denoising Unet. Additionally, we
employ an End-to-End Finetuning strategy to improve overall compression
performance. Extensive experiments demonstrate that DiffVC-OSD achieves
state-of-the-art perceptual compression performance, offers about 20$\times$
faster decoding and a 86.92\% bitrate reduction compared to the corresponding
multi-step diffusion-based variant.

</details>


### [548] [Anatomy-Aware Low-Dose CT Denoising via Pretrained Vision Models and Semantic-Guided Contrastive Learning](https://arxiv.org/abs/2508.07788)
*Runze Wang,Zeli Chen,Zhiyun Song,Wei Fang,Jiajin Zhang,Danyang Tu,Yuxing Tang,Minfeng Xu,Xianghua Ye,Le Lu,Dakai Jin*

Main category: eess.IV

TL;DR: ALDEN是一种解剖结构感知的低剂量CT去噪方法，它结合了预训练视觉模型的语义特征、对抗学习和对比学习，以提高去噪效果并保持解剖结构的完整性。实验证明，ALDEN在去噪和下游分割任务上均表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大多数现有的深度学习去噪方法忽略了人体组织的解剖语义信息，这可能导致次优的去噪结果。为了解决这个问题，我们提出了一种名为ALDEN的解剖结构感知的低剂量CT去噪方法。

Method: ALDEN是一种解剖结构感知的低剂量CT去噪方法，它通过集成预训练视觉模型（PVM）的语义特征，并结合对抗学习和对比学习来实现。具体而言，该方法引入了一个解剖结构感知的判别器，通过交叉注意力机制动态融合来自参考正常剂量CT（NDCT）的层次化语义特征，从而在判别器中实现特定组织的真实感评估。此外，还提出了一种语义引导的对比学习模块，通过对比来自LDCT、去噪CT和NDCT的PVM特征，强制执行解剖结构的一致性，并通过正样本对保留特定组织的模式，并通过双负样本对抑制伪影。

Result: ALDEN实现了最先进的性能，提供了卓越的解剖结构保持能力，并显著减少了先前工作中过度平滑的问题。

Conclusion: ALDEN在两个低剂量CT去噪数据集上的广泛实验表明，ALDEN达到了最先进的性能，提供了卓越的解剖结构保持能力，并显著减少了先前工作中过度平滑的问题。在下游多器官分割任务（包含117个解剖结构）上的进一步验证，证实了该模型保持解剖结构感知的能力。

Abstract: To reduce radiation exposure and improve the diagnostic efficacy of low-dose
computed tomography (LDCT), numerous deep learning-based denoising methods have
been developed to mitigate noise and artifacts. However, most of these
approaches ignore the anatomical semantics of human tissues, which may
potentially result in suboptimal denoising outcomes. To address this problem,
we propose ALDEN, an anatomy-aware LDCT denoising method that integrates
semantic features of pretrained vision models (PVMs) with adversarial and
contrastive learning. Specifically, we introduce an anatomy-aware discriminator
that dynamically fuses hierarchical semantic features from reference
normal-dose CT (NDCT) via cross-attention mechanisms, enabling tissue-specific
realism evaluation in the discriminator. In addition, we propose a
semantic-guided contrastive learning module that enforces anatomical
consistency by contrasting PVM-derived features from LDCT, denoised CT and
NDCT, preserving tissue-specific patterns through positive pairs and
suppressing artifacts via dual negative pairs. Extensive experiments conducted
on two LDCT denoising datasets reveal that ALDEN achieves the state-of-the-art
performance, offering superior anatomy preservation and substantially reducing
over-smoothing issue of previous work. Further validation on a downstream
multi-organ segmentation task (encompassing 117 anatomical structures) affirms
the model's ability to maintain anatomical awareness.

</details>


### [549] [Towards Human-AI Collaboration System for the Detection of Invasive Ductal Carcinoma in Histopathology Images](https://arxiv.org/abs/2508.07875)
*Shuo Han,Ahmed Karam Eldaly,Solomon Sunday Oyelere*

Main category: eess.IV

TL;DR: 该研究提出了一种“人在回路”的深度学习系统，结合AI（EfficientNetV2S）和人类专家的反馈，用于提高乳腺癌（IDC）检测的准确性，最终模型准确率达93.65%。


<details>
  <summary>Details</summary>
Motivation: 浸润性导管癌（IDC）是乳腺癌中最常见的类型，早期准确诊断对提高患者生存率至关重要。结合医学专业知识和人工智能（AI）有望提高IDC检测的精确度和效率。

Method: 提出一个包含EfficientNetV2S模型和人类专家反馈的“人在回路”（HITL）深度学习系统。系统首先由AI进行初步诊断，然后由医学专家审核并修正错误分类的图像，将修正后的标签反馈给AI进行模型迭代优化。

Result: EfficientNetV2S模型在与现有方法比较中取得了93.65%的准确率。通过HITL系统，利用包含错误分类图像的四个实验组进行进一步优化，模型性能得到提升。

Conclusion: 该研究提出了一种结合人类专家反馈的人工智能（AI）深度学习系统，用于检测浸润性导管癌（IDC）。该系统通过迭代优化，能够提高AI在医学诊断中的性能，为未来AI辅助医学诊断提供了有前景的方向。

Abstract: Invasive ductal carcinoma (IDC) is the most prevalent form of breast cancer,
and early, accurate diagnosis is critical to improving patient survival rates
by guiding treatment decisions. Combining medical expertise with artificial
intelligence (AI) holds significant promise for enhancing the precision and
efficiency of IDC detection. In this work, we propose a human-in-the-loop
(HITL) deep learning system designed to detect IDC in histopathology images.
The system begins with an initial diagnosis provided by a high-performance
EfficientNetV2S model, offering feedback from AI to the human expert. Medical
professionals then review the AI-generated results, correct any misclassified
images, and integrate the revised labels into the training dataset, forming a
feedback loop from the human back to the AI. This iterative process refines the
model's performance over time. The EfficientNetV2S model itself achieves
state-of-the-art performance compared to existing methods in the literature,
with an overall accuracy of 93.65\%. Incorporating the human-in-the-loop system
further improves the model's accuracy using four experimental groups with
misclassified images. These results demonstrate the potential of this
collaborative approach to enhance AI performance in diagnostic systems. This
work contributes to advancing automated, efficient, and highly accurate methods
for IDC detection through human-AI collaboration, offering a promising
direction for future AI-assisted medical diagnostics.

</details>


### [550] [Diffusing the Blind Spot: Uterine MRI Synthesis with Diffusion Models](https://arxiv.org/abs/2508.07903)
*Johanna P. Müller,Anika Knupfer,Pedro Blöss,Edoardo Berardi Vittur,Bernhard Kainz,Jana Hutter*

Main category: eess.IV

TL;DR: 这项研究提出了一种新颖的扩散模型框架，用于生成高保真的子宫MRI图像，解决了妇科成像中的数据稀缺和隐私问题，并在诊断任务中取得了优于现有方法的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型在生成解剖学上精确的女性盆腔图像方面存在困难，这限制了它们在妇科成像中的应用，而数据稀疏和患者隐私问题在其中至关重要。

Method: 本文提出了一种新颖的基于扩散的框架，用于合成子宫MRI，整合了无条件和有条件的去噪扩散概率模型（DDPM）和潜在扩散模型（LDM），并支持2D和3D。

Result: 所提出的方法生成了解剖学上一致、高保真的合成图像，这些图像在临床上与真实扫描非常相似，并且在关键的分类任务中显示出诊断精度的显著提高。此外，专家盲评进一步验证了我们合成图像的临床现实性。

Conclusion: 我们发布了模型，并附带了隐私保护措施和一个全面的合成子宫MRI数据集，以支持可重复的研究并促进妇科领域AI的公平性。

Abstract: Despite significant progress in generative modelling, existing diffusion
models often struggle to produce anatomically precise female pelvic images,
limiting their application in gynaecological imaging, where data scarcity and
patient privacy concerns are critical. To overcome these barriers, we introduce
a novel diffusion-based framework for uterine MRI synthesis, integrating both
unconditional and conditioned Denoising Diffusion Probabilistic Models (DDPMs)
and Latent Diffusion Models (LDMs) in 2D and 3D. Our approach generates
anatomically coherent, high fidelity synthetic images that closely mimic real
scans and provide valuable resources for training robust diagnostic models. We
evaluate generative quality using advanced perceptual and distributional
metrics, benchmarking against standard reconstruction methods, and demonstrate
substantial gains in diagnostic accuracy on a key classification task. A
blinded expert evaluation further validates the clinical realism of our
synthetic images. We release our models with privacy safeguards and a
comprehensive synthetic uterine MRI dataset to support reproducible research
and advance equitable AI in gynaecology.

</details>


### [551] [A Physics-Driven Neural Network with Parameter Embedding for Generating Quantitative MR Maps from Weighted Images](https://arxiv.org/abs/2508.08123)
*Lingjing Chen,Chengxiu Zhang,Yinqiao Yi,Yida Wang,Yang Song,Xu Yan,Shengfang Xu,Dalin Zhu,Mengqiu Cao,Yan Zhou,Chenglong Wang,Guang Yang*

Main category: eess.IV

TL;DR: 提出一种深度学习方法，通过整合MRI序列参数（TR、TE、TI）到模型中，利用参数嵌入来提高定量MRI图像合成的准确性和泛化能力。该方法在各种数据集上均表现出色，优于传统深度学习模型，尤其在处理未见过的脑部结构和病灶时展现出强大的泛化能力，有望加速qMRI并提升其临床应用价值。


<details>
  <summary>Details</summary>
Motivation: 为了提高从临床加权MRI进行定量图像合成的准确性和泛化能力。

Method: 提出一种基于深度学习的方法，通过参数嵌入将MRI序列参数（重复时间TR、回波时间TE和反转时间TI）整合到模型中，以提高从临床加权MRI进行定量图像合成的准确性和泛化能力。该模型以常规T1加权、T2加权和T2-FLAIR图像作为输入，合成T1、T2和质子密度（PD）定量图。

Result: 在健康脑部MRI图像上训练的模型，在内部和外部测试数据集上进行了评估。所提出的方法在所有合成的参数图上都取得了很高的性能，PSNR值超过34 dB，SSIM值超过0.92。与传统的深度学习模型相比，该方法在准确性和鲁棒性方面表现更优，包括对先前未见过的脑部结构和病灶数据。值得注意的是，该模型能够准确地合成这些未见的病理区域的定量图，凸显了其卓越的泛化能力。

Conclusion: 该方法通过参数嵌入整合MRI序列参数，使神经网络能够更好地学习MR信号的物理特性，显著提高了定量MRI合成的性能和可靠性。该方法在加速qMRI和提高其临床应用性方面显示出巨大潜力。

Abstract: We propose a deep learning-based approach that integrates MRI sequence
parameters to improve the accuracy and generalizability of quantitative image
synthesis from clinical weighted MRI. Our physics-driven neural network embeds
MRI sequence parameters -- repetition time (TR), echo time (TE), and inversion
time (TI) -- directly into the model via parameter embedding, enabling the
network to learn the underlying physical principles of MRI signal formation.
The model takes conventional T1-weighted, T2-weighted, and T2-FLAIR images as
input and synthesizes T1, T2, and proton density (PD) quantitative maps.
Trained on healthy brain MR images, it was evaluated on both internal and
external test datasets. The proposed method achieved high performance with PSNR
values exceeding 34 dB and SSIM values above 0.92 for all synthesized parameter
maps. It outperformed conventional deep learning models in accuracy and
robustness, including data with previously unseen brain structures and lesions.
Notably, our model accurately synthesized quantitative maps for these unseen
pathological regions, highlighting its superior generalization capability.
Incorporating MRI sequence parameters via parameter embedding allows the neural
network to better learn the physical characteristics of MR signals,
significantly enhancing the performance and reliability of quantitative MRI
synthesis. This method shows great potential for accelerating qMRI and
improving its clinical utility.

</details>


### [552] [RedDino: A foundation model for red blood cell analysis](https://arxiv.org/abs/2508.08180)
*Luca Zedda,Andrea Loddo,Cecilia Di Ruberto,Carsten Marr*

Main category: eess.IV

TL;DR: RedDino是一个针对红细胞图像分析的自监督基础模型，在红细胞形状分类任务上表现优于现有模型，并具有良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 旨在为红细胞分析提供全面的AI解决方案，以应对目前相关AI方案的缺乏。

Method: RedDino是一个利用DINOv2自监督学习框架并针对红细胞图像分析进行优化的模型，在125万张红细胞图像数据集上进行了训练。

Result: RedDino在红细胞形状分类任务上超越了现有的最先进模型，并展现出强大的特征表示和泛化能力。

Conclusion: RedDino通过捕捉细微的形态特征，解决了计算血液学中的关键挑战，推动了可靠诊断工具的发展。

Abstract: Red blood cells (RBCs) are essential to human health, and their precise
morphological analysis is important for diagnosing hematological disorders.
Despite the promise of foundation models in medical diagnostics, comprehensive
AI solutions for RBC analysis remain scarce. We present RedDino, a
self-supervised foundation model designed for RBC image analysis. RedDino uses
an RBC-specific adaptation of the DINOv2 self-supervised learning framework and
is trained on a curated dataset of 1.25 million RBC images from diverse
acquisition modalities and sources. Extensive evaluations show that RedDino
outperforms existing state-of-the-art models on RBC shape classification.
Through assessments including linear probing and nearest neighbor
classification, we confirm its strong feature representations and
generalization ability. Our main contributions are: (1) a foundation model
tailored for RBC analysis, (2) ablation studies exploring DINOv2 configurations
for RBC modeling, and (3) a detailed evaluation of generalization performance.
RedDino addresses key challenges in computational hematology by capturing
nuanced morphological features, advancing the development of reliable
diagnostic tools. The source code and pretrained models for RedDino are
available at https://github.com/Snarci/RedDino, and the pretrained models can
be downloaded from our Hugging Face collection at
https://huggingface.co/collections/Snarcy/reddino-689a13e29241d2e5690202fc

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [553] [Benchmarking Self-Driving Labs](https://arxiv.org/abs/2508.06642)
*Adedire D. Adesiji,Jiashuo Wang,Cheng-Shu Kuo,Keith A. Brown*

Main category: physics.comp-ph

TL;DR: 自驾实验室（SDL）通过机器学习和自动化技术加速材料发现。本综述回顾了量化SDL学习加速效果的指标（AF和EF），发现SDL能显著减少实验次数（AF中位数为6），且EF在10-20个实验/维时达到峰值。研究结果强调了SDL在不同材料参数空间中的价值，并为理解其加速效应提供了通用语言。


<details>
  <summary>Details</summary>
Motivation: 现代材料科学的一个关键目标是加速材料发现的进程。自驾实验室（SDL）通过机器学习选择实验并利用自动化执行实验，旨在通过比传统方法更快、更智能、更可靠地进行实验并生成更丰富的元数据来实现这一目标。

Method: 本文首先总结了两种关键指标——加速因子（AF）和增强因子（EF）——的理论基础，这两种指标用于量化算法相对于参考策略的速度和性能提升程度。随后，对现有文献进行了全面的回顾，并进行了一系列模拟贝叶斯优化活动，以揭示EF如何依赖于参数空间的统计特性，而AF则依赖于其复杂性。

Result: 文献回顾显示，AF值范围广泛，中位数为6，并且随着空间维度的增加而增加，这反映了一种有趣的“维度诅咒”现象。相比之下，EF值变化超过两个数量级，尽管它们在每个维度10-20个实验处持续达到峰值。

Conclusion: 该综述通过量化自驾实验室（SDL）在实现特定目标所需的实验数量方面的缩减程度，总结了在理解SDL加速学习方面的进展。研究结果表明，SDL在材料发现方面具有广泛的应用价值，并提供了一种通用的语言来量化和理解这种加速。

Abstract: A key goal of modern materials science is accelerating the pace of materials
discovery. Self-driving labs, or systems that select experiments using machine
learning and then execute them using automation, are designed to fulfil this
promise by performing experiments faster, more intelligently, more reliably,
and with richer metadata than conventional means. This review summarizes
progress in understanding the degree to which SDLs accelerate learning by
quantifying how much they reduce the number of experiments required for a given
goal. The review begins by summarizing the theory underlying two key metrics,
namely acceleration factor AF and enhancement factor EF, which quantify how
much faster and better an algorithm is relative to a reference strategy. Next,
we provide a comprehensive review of the literature, which reveals a wide range
of AFs with a median of 6, and that tends to increase with the dimensionality
of the space, reflecting an interesting blessing of dimensionality. In
contrast, reported EF values vary by over two orders of magnitude, although
they consistently peak at 10-20 experiments per dimension. To understand these
results, we perform a series of simulated Bayesian optimization campaigns that
reveal how EF depends upon the statistical properties of the parameter space
while AF depends on its complexity. Collectively, these results reinforce the
motivation for using SDLs by revealing their value across a wide range of
material parameter spaces and provide a common language for quantifying and
understanding this acceleration.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [554] [Automated Seam Folding and Sewing Machine on Pleated Pants for Apparel Manufacturing](https://arxiv.org/abs/2508.06518)
*Ray Wai Man Kong*

Main category: cs.RO

TL;DR: 本研究设计了一种自动化折叠和缝纫机，可将裤子生产的劳动时间减少93%，循环时间减少70%，从而提高效率并减少浪费。


<details>
  <summary>Details</summary>
Motivation: 传统裤子褶皱的制作方法劳动密集、易出错且需要高技能水平，因此在服装行业实现自动化势在必行。本研究旨在探索将先进技术融入服装生产的技术可行性和操作优势，重点是开发能够精确折叠和缝纫的自动化机器，从而消除标记工序。

Method: 本研究通过设计和开发一种集成了精密折叠机构和自动化缝纫单元并具有实时监控功能的机器，解决了服装行业在生产褶皱裤子过程中遇到的挑战。

Result: 自动化系统将每件的劳动时间从117秒减少到8秒（降低93%），机械时间提高了73%，总产量提高了72%，循环时间从117秒减少到33秒。通过消除手动标记，该机器降低了劳动力成本，并通过一致的褶皱形成最大限度地减少了材料浪费，符合行业对可持续性和效率的关注。

Conclusion: 该研究通过设计和开发自动化折叠和缝纫机，解决了服装行业手动缝纫褶皱裤子过程中劳动密集、不一致和高技能要求等挑战。自动化系统将每件的劳动时间从117秒减少到8秒，机械时间提高了73%，总产量提高了72%，循环时间从117秒减少到33秒，从而提高了效率并满足了客户需求。此外，通过消除手动标记过程，该机器降低了劳动力成本，并通过一致的褶皱形成最大限度地减少了材料浪费，符合行业对可持续性和效率的关注。

Abstract: The applied research is the design and development of an automated folding
and sewing machine for pleated pants. It represents a significant advancement
in addressing the challenges associated with manual sewing processes.
Traditional methods for creating pleats are labour-intensive, prone to
inconsistencies, and require high levels of skill, making automation a critical
need in the apparel industry. This research explores the technical feasibility
and operational benefits of integrating advanced technologies into garment
production, focusing on the creation of an automated machine capable of precise
folding and sewing operations and eliminating the marking operation.
  The proposed machine incorporates key features such as a precision folding
mechanism integrated into the automated sewing unit with real-time monitoring
capabilities. The results demonstrate remarkable improvements: the standard
labour time has been reduced by 93%, dropping from 117 seconds per piece to
just 8 seconds with the automated system. Similarly, machinery time improved by
73%, and the total output rate increased by 72%. These enhancements translate
into a cycle time reduction from 117 seconds per piece to an impressive 33
seconds, enabling manufacturers to meet customer demand more swiftly. By
eliminating manual marking processes, the machine not only reduces labour costs
but also minimizes waste through consistent pleat formation. This automation
aligns with industry trends toward sustainability and efficiency, potentially
reducing environmental impact by decreasing material waste and energy
consumption.

</details>


### [555] [Optimization of Flip-Landing Trajectories for Starship based on a Deep Learned Simulator](https://arxiv.org/abs/2508.06520)
*Liwei Chen,Tong Qin,Zhenhua Huangfu,Li Li,Wei Wei*

Main category: cs.RO

TL;DR: 提出了一种用于航天器翻转和着陆轨迹设计的可微优化框架，使用神经网络预测气动力，并通过可微求解器进行端到端优化。


<details>
  <summary>Details</summary>
Motivation: 为了解决可重复使用航天器（以星舰为例）的翻转和着陆轨迹设计问题。

Method: 提出了一种可微优化框架，该框架集成了深度神经网络（用于预测气动力的CFD数据）和可微刚体动力学求解器，实现了端到端的梯度优化。

Result: 生成的控制序列在物理上是一致的，并满足执行器限制和终端着陆约束。

Conclusion: 该框架能够有效地对具有高非线性复杂机动进行建模和优化，为未来涉及不稳定空气动力学、羽流相互作用和智能制导设计的扩展奠定了基础。

Abstract: We propose a differentiable optimization framework for flip-and-landing
trajectory design of reusable spacecraft, exemplified by the Starship vehicle.
A deep neural network surrogate, trained on high-fidelity CFD data, predicts
aerodynamic forces and moments, and is tightly coupled with a differentiable
rigid-body dynamics solver. This enables end-to-end gradient-based trajectory
optimization without linearization or convex relaxation. The framework handles
actuator limits and terminal landing constraints, producing physically
consistent, optimized control sequences. Both standard automatic
differentiation and Neural ODEs are applied to support long-horizon rollouts.
Results demonstrate the framework's effectiveness in modeling and optimizing
complex maneuvers with high nonlinearities. This work lays the groundwork for
future extensions involving unsteady aerodynamics, plume interactions, and
intelligent guidance design.

</details>


### [556] [Stinger Robot: A Self-Bracing Robotic Platform for Autonomous Drilling in Confined Underground Environments](https://arxiv.org/abs/2508.06521)
*H. Liu,L. S. Moreu,T. S. Andersen,V. V. Puche,M. Fumagalli*

Main category: cs.RO

TL;DR: Stinger Robot是一种新型机器人，专为在狭窄、非结构化、无基础设施的废弃地下矿山中进行高力钻探而设计。它使用三足支撑机制和力感知控制策略，实现了在不平坦表面的稳定锚定和自主钻探，克服了传统机械的限制。


<details>
  <summary>Details</summary>
Motivation: 为了应对废弃地下矿山中对关键原材料日益增长的需求，并克服传统钻探机械在这些充满挑战的环境中（如空间狭窄、结构非结构化且无基础设施）的局限性。

Method: 本文提出了一种名为Stinger Robot的新型紧凑型机器人平台，该平台采用机械自锁三足支撑机制，并结合了力的感知和闭环控制策略，在ROS 2中实现为有限状态机，以在非结构化环境中进行稳定锚定和钻探。

Result: 通过仿真和初步硬件测试表明，Stinger Robot能够在目前采矿设备无法进入的条件下自主稳定和钻探。

Conclusion: 该研究首次验证了一种集成了分布式力支撑和地下自主钻探的机器人架构，为未来模块化机器人系统的协同采矿作业奠定了基础。

Abstract: The increasing demand for critical raw materials has revitalized interest in
abandoned underground mines, which pose extreme challenges for conventional
drilling machinery due to confined, unstructured, and infrastructure-less
environments. This paper presents the Stinger Robot, a novel compact robotic
platform specifically designed for autonomous high-force drilling in such
settings. The robot features a mechanically self-locking tri-leg bracing
mechanism that enables stable anchoring to irregular tunnel surfaces. A key
innovation lies in its force-aware, closed-loop control strategy, which enables
force interaction with unstructured environments during bracing and drilling.
Implemented as a finite-state machine in ROS 2, the control policy dynamically
adapts leg deployment based on real-time contact feedback and load thresholds,
ensuring stability without external supports. We demonstrate, through
simulation and preliminary hardware tests, that the Stinger Robot can
autonomously stabilize and drill in conditions previously inaccessible to
nowadays mining machines. This work constitutes the first validated robotic
architecture to integrate distributed force-bracing and autonomous drilling in
underground environments, laying the groundwork for future collaborative mining
operations using modular robot systems.

</details>


### [557] [MetAdv: A Unified and Interactive Adversarial Testing Platform for Autonomous Driving](https://arxiv.org/abs/2508.06534)
*Aishan Liu,Jiakai Wang,Tianyuan Zhang,Hainan Li,Jiangfan Liu,Siyuan Liang,Yilong Ren,Xianglong Liu,Dacheng Tao*

Main category: cs.RO

TL;DR: MetAdv是一个用于自动驾驶系统对抗性鲁棒性评估的混合虚拟-物理测试平台，支持多种任务和模型，并包含人为干预能力。


<details>
  <summary>Details</summary>
Motivation: 评估和确保自动驾驶（AD）系统的对抗鲁棒性是一项关键且悬而未决的挑战。

Method: MetAdv是一个新颖的对抗性测试平台，通过将虚拟仿真与物理车辆反馈紧密集成，实现了现实、动态和交互式评估。其核心是一个混合虚拟-物理沙箱，其中设计了一个三层闭环测试环境，具有动态对抗性测试演化。该架构促进了端到端的对抗性评估，包括高级统一对抗生成、基于仿真的中间层交互以及物理车辆上的低级执行。MetAdv还支持广泛的自动驾驶任务、算法范式（如模块化深度学习流水线、端到端学习、视觉语言模型），支持灵活的3D车辆建模以及模拟和物理环境之间的无缝转换，并内置了与Apollo和Tesla等商业平台的兼容性。其关键特性是人为干预能力：除了灵活的环境配置以进行更定制化的评估外，它还可以实时捕获来自驾驶员的生理信号和行为反馈，从而在对抗条件下提供对人机信任的新见解。

Result: MetAdv能够对自动驾驶系统进行端到端的对抗性评估，并提供对人为干预的洞察。

Conclusion: MetAdv提供了一个可扩展且统一的框架，用于对抗性评估，为更安全的自动驾驶铺平了道路。

Abstract: Evaluating and ensuring the adversarial robustness of autonomous driving (AD)
systems is a critical and unresolved challenge. This paper introduces MetAdv, a
novel adversarial testing platform that enables realistic, dynamic, and
interactive evaluation by tightly integrating virtual simulation with physical
vehicle feedback. At its core, MetAdv establishes a hybrid virtual-physical
sandbox, within which we design a three-layer closed-loop testing environment
with dynamic adversarial test evolution. This architecture facilitates
end-to-end adversarial evaluation, ranging from high-level unified adversarial
generation, through mid-level simulation-based interaction, to low-level
execution on physical vehicles. Additionally, MetAdv supports a broad spectrum
of AD tasks, algorithmic paradigms (e.g., modular deep learning pipelines,
end-to-end learning, vision-language models). It supports flexible 3D vehicle
modeling and seamless transitions between simulated and physical environments,
with built-in compatibility for commercial platforms such as Apollo and Tesla.
A key feature of MetAdv is its human-in-the-loop capability: besides flexible
environmental configuration for more customized evaluation, it enables
real-time capture of physiological signals and behavioral feedback from
drivers, offering new insights into human-machine trust under adversarial
conditions. We believe MetAdv can offer a scalable and unified framework for
adversarial assessment, paving the way for safer AD.

</details>


### [558] [Symbolic Learning of Interpretable Reduced-Order Models for Jumping Quadruped Robots](https://arxiv.org/abs/2508.06538)
*Gioele Buriani,Jingyue Liu,Maximilian Stölzle,Cosimo Della Santina,Jiatao Ding*

Main category: cs.RO

TL;DR: 该研究提出了一种新的学习方法，结合SINDy和物理先验，为四足机器人跳跃生成了更准确的降维动力学模型，优于传统aSLIP模型。


<details>
  <summary>Details</summary>
Motivation: 为了实现四足机器人运动规划和控制，需要简化复杂动力学并保留关键行为的降维模型，尤其是在跳跃场景下。

Method: 提出了一种结合稀疏识别非线性动力学（SINDy）和基于跳跃动力学的物理结构先验的学习架构，用于提取降维的、可解释的动力学模型。

Result: 该方法在仿真和硬件实验中，针对不同的跳跃策略，展现了比传统aSLIP模型更优越的精度。

Conclusion: 该方法通过结合SINDy和物理结构先验，成功地将高维非线性跳跃动力学映射到低维潜在空间，并且在仿真和硬件实验中均表现优于传统的aSLIP模型，证明了其有效性。

Abstract: Reduced-order models are essential for motion planning and control of
quadruped robots, as they simplify complex dynamics while preserving critical
behaviors. This paper introduces a novel methodology for deriving such
interpretable dynamic models, specifically for jumping. We capture the
high-dimensional, nonlinear jumping dynamics in a low-dimensional latent space
by proposing a learning architecture combining Sparse Identification of
Nonlinear Dynamics (SINDy) with physical structural priors on the jump
dynamics. Our approach demonstrates superior accuracy to the traditional
actuated Spring-loaded Inverted Pendulum (aSLIP) model and is validated through
simulation and hardware experiments across different jumping strategies.

</details>


### [559] [A tutorial note on collecting simulated data for vision-language-action models](https://arxiv.org/abs/2508.06547)
*Heran Wu,Zirun Zhou,Jingfeng Zhang*

Main category: cs.RO

TL;DR: VLA模型通过统一框架处理视觉-语言-动作，但依赖高质量数据集。本教程介绍了PyBullet、LIBERO和RT-X数据集，并展示了数据生成和收集方法。


<details>
  <summary>Details</summary>
Motivation: 传统机器人系统将智能分解为独立模块，而VLA模型通过单一神经网络实现视觉-语言-动作的统一处理。

Method: 本教程回顾了PyBullet模拟框架、LIBERO基准套件和RT-X数据集，并演示了在PyBullet中生成数据集以及在LIBERO中收集定制数据。

Result: 介绍了PyBullet、LIBERO和RT-X数据集的特点和作用，为VLA模型的训练提供了数据支持。

Conclusion: VLA模型通过统一框架处理视觉-语言-动作，但依赖高质量数据集。本教程介绍了PyBullet、LIBERO和RT-X数据集，并展示了数据生成和收集方法。

Abstract: Traditional robotic systems typically decompose intelligence into independent
modules for computer vision, natural language processing, and motion control.
Vision-Language-Action (VLA) models fundamentally transform this approach by
employing a single neural network that can simultaneously process visual
observations, understand human instructions, and directly output robot actions
-- all within a unified framework. However, these systems are highly dependent
on high-quality training datasets that can capture the complex relationships
between visual observations, language instructions, and robotic actions. This
tutorial reviews three representative systems: the PyBullet simulation
framework for flexible customized data generation, the LIBERO benchmark suite
for standardized task definition and evaluation, and the RT-X dataset
collection for large-scale multi-robot data acquisition. We demonstrated
dataset generation approaches in PyBullet simulation and customized data
collection within LIBERO, and provide an overview of the characteristics and
roles of the RT-X dataset for large-scale multi-robot data acquisition.

</details>


### [560] [AquaChat++: LLM-Assisted Multi-ROV Inspection for Aquaculture Net Pens with Integrated Battery Management and Thruster Fault Tolerance](https://arxiv.org/abs/2508.06554)
*Abdelhaleem Saad,Waseem Akram,Irfan Hussain*

Main category: cs.RO

TL;DR: AquaChat++是一个利用LLM实现自适应任务规划、协调任务执行和容错控制的新型多ROV检查框架，旨在解决传统水下检查方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了确保海上渔业养殖系统的结构完整性和可持续运行，对养殖网箱进行检查至关重要。传统的基于手动操作或单ROV系统的检查方法，在适应实时约束（如能源消耗、硬件故障和动态水下条件）方面适应性有限。

Method: 该框架采用了分层架构：高级规划层利用LLM（如ChatGPT-4）将自然语言用户命令转换为符号化的多智能体检查计划；任务管理器根据ROV的实时状态和操作限制（包括推进器故障和电池电量）动态分配和调度ROV之间的动作。低级控制层确保精确的轨迹跟踪，并整合推进器故障检测和补偿机制。通过结合实时反馈和事件触发的重新规划，AquaChat++提高了系统的鲁棒性和运行效率。

Result: 模拟实验表明，与传统方法相比，AquaChat++在检查覆盖范围、节能行为和对执行器故障的鲁棒性方面有所提高。

Conclusion: LLM驱动的框架有潜力支持水产养殖领域中可扩展、智能和自主的水下机器人操作。

Abstract: Inspection of aquaculture net pens is essential for ensuring the structural
integrity and sustainable operation of offshore fish farming systems.
Traditional methods, typically based on manually operated or single-ROV
systems, offer limited adaptability to real-time constraints such as energy
consumption, hardware faults, and dynamic underwater conditions. This paper
introduces AquaChat++, a novel multi-ROV inspection framework that uses Large
Language Models (LLMs) to enable adaptive mission planning, coordinated task
execution, and fault-tolerant control in complex aquaculture environments. The
proposed system consists of a two-layered architecture. The high-level plan
generation layer employs an LLM, such as ChatGPT-4, to translate natural
language user commands into symbolic, multi-agent inspection plans. A task
manager dynamically allocates and schedules actions among ROVs based on their
real-time status and operational constraints, including thruster faults and
battery levels. The low-level control layer ensures accurate trajectory
tracking and integrates thruster fault detection and compensation mechanisms.
By incorporating real-time feedback and event-triggered replanning, AquaChat++
enhances system robustness and operational efficiency. Simulated experiments in
a physics-based aquaculture environment demonstrate improved inspection
coverage, energy-efficient behavior, and resilience to actuator failures. These
findings highlight the potential of LLM-driven frameworks to support scalable,
intelligent, and autonomous underwater robotic operations within the
aquaculture sector.

</details>


### [561] [Robust and Agile Quadrotor Flight via Adaptive Unwinding-Free Quaternion Sliding Mode Control](https://arxiv.org/abs/2508.06568)
*Amin Yazdanshenas,Reza Faieghi*

Main category: cs.RO

TL;DR: 提出了一种新的自适应滑模控制框架，用于四旋翼飞行器，解决了现有方法的局限性，并在计算资源受限的情况下实现了鲁棒、敏捷和高精度的飞行，能够执行高难度机动。


<details>
  <summary>Details</summary>
Motivation: 解决现有SMC方法存在的局限性，包括基于SO(3)方法的收敛慢和几乎全局稳定性问题、欧拉基控制器中旋转动力学的过度简化问题、基于四元数公式的解缠绕现象问题，以及自适应SMC方案中的增益过度增长问题。

Method: 提出了一种新的自适应滑模控制（SMC）框架，利用非光滑稳定性分析，对定义在S3上的非光滑姿态滑模动力学和位置滑模动力学进行了严格的全局稳定性证明。

Result: 所提出的控制器在计算上是高效的，能够在资源受限的纳米四旋翼上可靠运行，分别实现250 Hz和500 Hz的位置和姿态控制刷新率。在超过130次飞行试验的广泛硬件实验中，该控制器始终优于三种基准方法，在相对较低的控制努力下展现了卓越的轨迹跟踪精度和鲁棒性，并能执行32克纳米四旋翼上非凡的激进机动。

Conclusion: 该控制器在计算资源受限的纳米四旋翼飞行器上实现了鲁棒且敏捷的飞行，在大量的硬件实验中表现优于基准方法，能够执行高难度的激进机动，如动态抛掷起飞、翻转机动和超过3g的加速度，证明了在实际应用中的巨大潜力，尤其是在需要鲁棒、高性能飞行控制且受到显著外部干扰和严格计算限制的场景。

Abstract: This paper presents a new adaptive sliding mode control (SMC) framework for
quadrotors that achieves robust and agile flight under tight computational
constraints. The proposed controller addresses key limitations of prior SMC
formulations, including (i) the slow convergence and almost-global stability of
$\mathrm{SO(3)}$-based methods, (ii) the oversimplification of rotational
dynamics in Euler-based controllers, (iii) the unwinding phenomenon in
quaternion-based formulations, and (iv) the gain overgrowth problem in adaptive
SMC schemes. Leveraging nonsmooth stability analysis, we provide rigorous
global stability proofs for both the nonsmooth attitude sliding dynamics
defined on $\mathbb{S}^3$ and the position sliding dynamics. Our controller is
computationally efficient and runs reliably on a resource-constrained nano
quadrotor, achieving 250 Hz and 500 Hz refresh rates for position and attitude
control, respectively. In an extensive set of hardware experiments with over
130 flight trials, the proposed controller consistently outperforms three
benchmark methods, demonstrating superior trajectory tracking accuracy and
robustness with relatively low control effort. The controller enables
aggressive maneuvers such as dynamic throw launches, flip maneuvers, and
accelerations exceeding 3g, which is remarkable for a 32-gram nano quadrotor.
These results highlight promising potential for real-world applications,
particularly in scenarios requiring robust, high-performance flight control
under significant external disturbances and tight computational constraints.

</details>


### [562] [Integrating Neurosymbolic AI in Advanced Air Mobility: A Comprehensive Survey](https://arxiv.org/abs/2508.07163)
*Kamal Acharya,Iman Sharifi,Mehul Lad,Liang Sun,Houbing Song*

Main category: cs.RO

TL;DR: Neurosymbolic AI 结合了神经网络和符号推理，在先进空中交通管理（AAM）领域有应用前景，但研究尚不成熟，存在挑战。本文综述了该领域的研究进展，并为未来的发展提供了方向。


<details>
  <summary>Details</summary>
Motivation: 为应对先进空中交通管理（AAM）复杂的监管、运营和安全挑战，结合神经网络的适应性和符号推理的结合，是实现可靠、透明的 AAM 系统的关键。

Method: 对 Neurosymbolic AI 在 AAM 关键领域的应用进行回顾和分类，包括需求预测、飞机设计和实时空中交通管理。分析了 Neurosymbolic Reinforcement Learning 等方法在动态优化方面的潜力，并提出了未来研究方向。

Result: Neurosymbolic AI 在 AAM 领域的应用展现出潜力，但目前的研究存在方法论不统一、可扩展性、鲁棒性和合规性方面的不足。文章对现有进展进行了分类，并提供了案例研究，为未来的研究指明了方向。

Conclusion: Neurosymbolic AI 在先进空中交通管理（AAM）领域具有巨大潜力，但目前的研究仍处于碎片化状态，面临可扩展性、鲁棒性和航空标准合规性等挑战。未来的研究应着重于克服这些障碍，以实现可靠、透明的 AAM 系统。

Abstract: Neurosymbolic AI combines neural network adaptability with symbolic
reasoning, promising an approach to address the complex regulatory,
operational, and safety challenges in Advanced Air Mobility (AAM). This survey
reviews its applications across key AAM domains such as demand forecasting,
aircraft design, and real-time air traffic management. Our analysis reveals a
fragmented research landscape where methodologies, including Neurosymbolic
Reinforcement Learning, have shown potential for dynamic optimization but still
face hurdles in scalability, robustness, and compliance with aviation
standards. We classify current advancements, present relevant case studies, and
outline future research directions aimed at integrating these approaches into
reliable, transparent AAM systems. By linking advanced AI techniques with AAM's
operational demands, this work provides a concise roadmap for researchers and
practitioners developing next-generation air mobility solutions.

</details>


### [563] [Efficient Safety Testing of Autonomous Vehicles via Adaptive Search over Crash-Derived Scenarios](https://arxiv.org/abs/2508.06575)
*Rui Zhou*

Main category: cs.RO

TL;DR: 本研究提出ALVNS-SA算法，通过加速测试提高了自动驾驶汽车在安全关键场景下的测试效率和覆盖率。


<details>
  <summary>Details</summary>
Motivation: 为确保自动驾驶汽车（AVs）在安全关键场景下的安全性，需要高效的测试方法来验证其驾驶能力。

Method: 从CIMSS-TA数据库提取典型逻辑场景，并通过Baidu Apollo集成黑盒自动驾驶系统进行行为控制，最后应用ALVNS-SA算法进行加速测试。

Result: ALVNS-SA算法显著提高了测试效率，达到了84.00%的安全关键场景覆盖率，其中碰撞场景覆盖率为96.83%，接近碰撞场景覆盖率为92.07%，优于遗传算法、自适应大邻域模拟退火算法和随机测试。

Conclusion: 本研究提出了一种自适应大变量邻域模拟退火算法（ALVNS-SA），以提高自动驾驶汽车（AVs）在安全关键场景下的测试效率，并取得了显著的测试覆盖率提升。

Abstract: Ensuring the safety of autonomous vehicles (AVs) is paramount in their
development and deployment. Safety-critical scenarios pose more severe
challenges, necessitating efficient testing methods to validate AVs safety.
This study focuses on designing an accelerated testing algorithm for AVs in
safety-critical scenarios, enabling swift recognition of their driving
capabilities. First, typical logical scenarios were extracted from real-world
crashes in the China In-depth Mobility Safety Study-Traffic Accident (CIMSS-TA)
database, obtaining pre-crash features through reconstruction. Second, Baidu
Apollo, an advanced black-box automated driving system (ADS) is integrated to
control the behavior of the ego vehicle. Third, we proposed an adaptive
large-variable neighborhood-simulated annealing algorithm (ALVNS-SA) to
expedite the testing process. Experimental results demonstrate a significant
enhancement in testing efficiency when utilizing ALVNS-SA. It achieves an
84.00% coverage of safety-critical scenarios, with crash scenario coverage of
96.83% and near-crash scenario coverage of 92.07%. Compared to genetic
algorithm (GA), adaptive large neighborhood-simulated annealing algorithm
(ALNS-SA), and random testing, ALVNS-SA exhibits substantially higher coverage
in safety-critical scenarios.

</details>


### [564] [Optimal Planning and Machine Learning for Responsive Tracking and Enhanced Forecasting of Wildfires using a Spacecraft Constellation](https://arxiv.org/abs/2508.06687)
*Sreeja Roy-Singh,Vinay Ravindra,Richard Levinson,Mahta Moghaddam,Jan Mandel,Adam Kochanski,Angel Farguell Caus,Kurtis Nelson,Samira Alkaee Taleghan,Archana Kannan,Amer Melebari*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We propose a novel concept of operations using optimal planning methods and
machine learning (ML) to collect spaceborne data that is unprecedented for
monitoring wildfires, process it to create new or enhanced products in the
context of wildfire danger or spread monitoring, and assimilate them to improve
existing, wildfire decision support tools delivered to firefighters within
latency appropriate for time-critical applications. The concept is studied with
respect to NASA's CYGNSS Mission, a constellation of passive microwave
receivers that measure specular GNSS-R reflections despite clouds and smoke.
Our planner uses a Mixed Integer Program formulation to schedule joint
observation data collection and downlink for all satellites. Optimal solutions
are found quickly that collect 98-100% of available observation opportunities.
ML-based fire predictions that drive the planner objective are greater than 40%
more correlated with ground truth than existing state-of-art. The presented
case study on the TX Smokehouse Creek fire in 2024 and LA fires in 2025
represents the first high-resolution data collected by CYGNSS of active fires.
Creation of Burnt Area Maps (BAM) using ML applied to the data during active
fires and BAM assimilation into NASA's Weather Research and Forecasting Model
using ML to broadcast fire spread are novel outcomes. BAM and CYGNSS obtained
soil moisture are integrated for the first time into USGS fire danger maps.
Inclusion of CYGNSS data in ML-based burn predictions boosts accuracy by 13%,
and inclusion of high-resolution data boosts ML recall by another 15%. The
proposed workflow has an expected latency of 6-30h, improving on the current
delivery time of multiple days. All components in the proposed concept are
shown to be computationally scalable and globally generalizable, with
sustainability considerations such as edge efficiency and low latency on small
devices.

</details>


### [565] [Improved Obstacle Avoidance for Autonomous Robots with ORCA-FLC](https://arxiv.org/abs/2508.06722)
*Justin London*

Main category: cs.RO

TL;DR: ORCA-FL通过模糊逻辑和强化学习提高了机器人避障能力。


<details>
  <summary>Details</summary>
Motivation: 为了提高机器人或自主系统在复杂动态环境中的导航能力，并克服现有碰撞避免算法（如DWA、TEB、RVO和ORCA）在处理不确定性、计算成本和动态障碍物适应性方面的局限性。

Method: 提出了一种名为ORCA-FL的算法，它改进了ORCA，通过使用模糊逻辑控制器（FLCs）来更好地处理不确定性和不精确性。此外，还详细介绍了一种使用模糊Q强化学习（FQL）来优化和调整FLCs的算法。

Result: ORCA-FL在减少碰撞数量方面优于ORCA，特别是在智能体速度超过特定阈值的情况下。

Conclusion: ORCA-FL通过使用模糊逻辑控制器（FLCs）来处理不确定性和不精确性，在多智能体环境中可以优于ORCA，尤其是在智能体速度超过一定阈值时。此外，还提出了一种使用模糊Q强化学习（FQL）来优化和调整FLCs的算法。

Abstract: Obstacle avoidance enables autonomous agents and robots to operate safely and
efficiently in dynamic and complex environments, reducing the risk of
collisions and damage. For a robot or autonomous system to successfully
navigate through obstacles, it must be able to detect such obstacles. While
numerous collision avoidance algorithms like the dynamic window approach (DWA),
timed elastic bands (TEB), and reciprocal velocity obstacles (RVO) have been
proposed, they may lead to suboptimal paths due to fixed weights, be
computationally expensive, or have limited adaptability to dynamic obstacles in
multi-agent environments. Optimal reciprocal collision avoidance (ORCA), which
improves on RVO, provides smoother trajectories and stronger collision
avoidance guarantees. We propose ORCA-FL to improve on ORCA by using fuzzy
logic controllers (FLCs) to better handle uncertainty and imprecision for
obstacle avoidance in path planning. Numerous multi-agent experiments are
conducted and it is shown that ORCA-FL can outperform ORCA in reducing the
number of collision if the agent has a velocity that exceeds a certain
threshold. In addition, a proposed algorithm for improving ORCA-FL using fuzzy
Q reinforcement learning (FQL) is detailed for optimizing and tuning FLCs.

</details>


### [566] [Learning Causal Structure Distributions for Robust Planning](https://arxiv.org/abs/2508.06742)
*Alejandro Murillo-Gonzalez,Junhong Xu,Lantao Liu*

Main category: cs.RO

TL;DR: 通过同时学习函数关系和考虑结构信息的不确定性，可以提高机器人动力学模型的鲁棒性并降低计算资源消耗。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有模型学习方法忽略因果结构、无法利用稀疏性交互的问题，并提高机器人动力学模型的鲁棒性，以应对新任务和新环境的挑战。

Method: 提出了一种估计因果结构分布的方法，该分布用于采样因果图，并指导编码器-多解码器概率模型中的潜空间表示。

Result: 学习到的动力学模型与采样方法相结合，可以执行新任务，并且在模拟和真实世界中对操纵器和移动机器人进行了验证。该模型还表现出对损坏输入和环境变化的适应性和鲁棒性。

Conclusion: 该研究提出了一种结合结构因果模型和概率模型的方法，用于学习机器人动力学模型。通过同时学习函数关系和考虑结构信息的不确定性，可以提高模型的鲁棒性并降低计算资源消耗。

Abstract: Structural causal models describe how the components of a robotic system
interact. They provide both structural and functional information about the
relationships that are present in the system. The structural information
outlines the variables among which there is interaction. The functional
information describes how such interactions work, via equations or learned
models. In this paper we find that learning the functional relationships while
accounting for the uncertainty about the structural information leads to more
robust dynamics models which improves downstream planning, while using
significantly lower computational resources. This in contrast with common
model-learning methods that ignore the causal structure and fail to leverage
the sparsity of interactions in robotic systems. We achieve this by estimating
a causal structure distribution that is used to sample causal graphs that
inform the latent-space representations in an encoder-multidecoder
probabilistic model. We show that our model can be used to learn the dynamics
of a robot, which together with a sampling-based planner can be used to perform
new tasks in novel environments, provided an objective function for the new
requirement is available. We validate our method using manipulators and mobile
robots in both simulation and the real-world. Additionally, we validate the
learned dynamics' adaptability and increased robustness to corrupted inputs and
changes in the environment, which is highly desirable in challenging real-world
robotics scenarios. Video: https://youtu.be/X6k5t7OOnNc.

</details>


### [567] [Robust-Sub-Gaussian Model Predictive Control for Safe Ultrasound-Image-Guided Robotic Spinal Surgery](https://arxiv.org/abs/2508.06744)
*Yunke Ao,Manish Prajapat,Yarden As,Yassine Taoudi-Benchekroun,Fabio Carrillo,Hooman Esfandiari,Benjamin F. Grewe,Andreas Krause,Philipp Fürnstahl*

Main category: cs.RO

TL;DR: 本研究提出了一种新的噪声表征和控制方法，用于解决机器人手术中的安全问题，并在模拟中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶和机器人手术等领域，利用光学数据（如图像、点云）进行安全关键控制时，高维传感反馈带来了严峻的挑战。尽管可以通过从高维数据估计的低维状态来控制，但估计误差的复杂且未知的分布常常使得标准的概率模型难以捕捉，从而阻碍了正式的安全保证。

Method: 提出了一种利用具有界定均值的亚高斯噪声来表征一般估计误差的新方法，并结合了基于鲁棒集合的方法和亚高斯方差代理传播，以解决线性系统中的不确定性传播问题。在此基础上，开发了一种模型预测控制（MPC）框架，为线性系统在所提出的噪声假设下提供闭环安全保证。

Result: 所提出的MPC方法应用于超声图像引导的机器人脊柱手术流程，该流程包括基于深度学习的语义分割、基于图像的配准、基于优化的规划以及机器人控制。通过在集成了真实人体解剖结构、机器人动力学、超声模拟以及呼吸运动和钻孔力的真实模拟环境中进行评估，结果证明了该方法在解决复杂图像引导手术任务时确保安全性的潜力。

Conclusion: 该研究成功地将所提出的新颖亚高斯噪声假设应用于超声图像引导机器人脊柱手术，并在模拟环境中展示了其在确保安全方面的潜力。

Abstract: Safety-critical control using high-dimensional sensory feedback from optical
data (e.g., images, point clouds) poses significant challenges in domains like
autonomous driving and robotic surgery. Control can rely on low-dimensional
states estimated from high-dimensional data. However, the estimation errors
often follow complex, unknown distributions that standard probabilistic models
fail to capture, making formal safety guarantees challenging. In this work, we
introduce a novel characterization of these general estimation errors using
sub-Gaussian noise with bounded mean. We develop a new technique for
uncertainty propagation of proposed noise characterization in linear systems,
which combines robust set-based methods with the propagation of sub-Gaussian
variance proxies. We further develop a Model Predictive Control (MPC) framework
that provides closed-loop safety guarantees for linear systems under the
proposed noise assumption. We apply this MPC approach in an
ultrasound-image-guided robotic spinal surgery pipeline, which contains
deep-learning-based semantic segmentation, image-based registration, high-level
optimization-based planning, and low-level robotic control. To validate the
pipeline, we developed a realistic simulation environment integrating real
human anatomy, robot dynamics, efficient ultrasound simulation, as well as
in-vivo data of breathing motion and drilling force. Evaluation results in
simulation demonstrate the potential of our approach for solving complex
image-guided robotic surgery task while ensuring safety.

</details>


### [568] [Learning a Vision-Based Footstep Planner for Hierarchical Walking Control](https://arxiv.org/abs/2508.06779)
*Minku Kim,Brian Acosta,Pratik Chaudhari,Michael Posa*

Main category: cs.RO

TL;DR: Vision-based hierarchical control with RL for footstep planning improves bipedal robot navigation on challenging terrain.


<details>
  <summary>Details</summary>
Motivation: Current frameworks for bipedal robots struggle with real-time footstep planning in unstructured environments due to over-reliance on proprioception or fragile, manually designed visual pipelines.

Method: A vision-based hierarchical control framework is proposed, combining a reinforcement learning high-level footstep planner that uses local elevation maps with a low-level Operational Space Controller. The Angular Momentum Linear Inverted Pendulum model is used for a low-dimensional state representation.

Result: The method was evaluated on the underactuated bipedal robot Cassie across various terrain conditions through simulation and hardware experiments, demonstrating its capabilities and challenges.

Conclusion: The proposed vision-based hierarchical control framework effectively integrates a reinforcement learning footstep planner with an Operational Space Controller for bipedal robot navigation in challenging terrains, outperforming existing methods by reducing complexity and improving real-time adaptability.

Abstract: Bipedal robots demonstrate potential in navigating challenging terrains
through dynamic ground contact. However, current frameworks often depend solely
on proprioception or use manually designed visual pipelines, which are fragile
in real-world settings and complicate real-time footstep planning in
unstructured environments. To address this problem, we present a vision-based
hierarchical control framework that integrates a reinforcement learning
high-level footstep planner, which generates footstep commands based on a local
elevation map, with a low-level Operational Space Controller that tracks the
generated trajectories. We utilize the Angular Momentum Linear Inverted
Pendulum model to construct a low-dimensional state representation to capture
an informative encoding of the dynamics while reducing complexity. We evaluate
our method across different terrain conditions using the underactuated bipedal
robot Cassie and investigate the capabilities and challenges of our approach
through simulation and hardware experiments.

</details>


### [569] [D3P: Dynamic Denoising Diffusion Policy via Reinforcement Learning](https://arxiv.org/abs/2508.06804)
*Shu-Ang Yu,Feng Gao,Yi Wu,Chao Yu,Yu Wang*

Main category: cs.RO

TL;DR: D3P是一种动态去噪扩散策略，通过自适应分配去噪步数来加速机器人视觉任务的执行。


<details>
  <summary>Details</summary>
Motivation: 机器人任务通常包含关键动作和常规动作，它们对任务成功的影响不同，现有的加速方法忽略了这一点。

Method: D3P使用轻量级的、状态感知的适配器来为每个动作分配最优的去噪步数，并通过强化学习联合优化适配器和基础扩散策略。

Result: D3P在模拟任务和物理机器人上均实现了显著的推理加速，平均加速比分别为2.2倍和1.9倍，且不影响任务成功率。

Conclusion: D3P在物理机器人上实现了1.9倍的加速，在模拟任务上实现了2.2倍的加速，同时没有降低成功率。

Abstract: Diffusion policies excel at learning complex action distributions for robotic
visuomotor tasks, yet their iterative denoising process poses a major
bottleneck for real-time deployment. Existing acceleration methods apply a
fixed number of denoising steps per action, implicitly treating all actions as
equally important. However, our experiments reveal that robotic tasks often
contain a mix of \emph{crucial} and \emph{routine} actions, which differ in
their impact on task success. Motivated by this finding, we propose
\textbf{D}ynamic \textbf{D}enoising \textbf{D}iffusion \textbf{P}olicy
\textbf{(D3P)}, a diffusion-based policy that adaptively allocates denoising
steps across actions at test time. D3P uses a lightweight, state-aware adaptor
to allocate the optimal number of denoising steps for each action. We jointly
optimize the adaptor and base diffusion policy via reinforcement learning to
balance task performance and inference efficiency. On simulated tasks, D3P
achieves an averaged 2.2$\times$ inference speed-up over baselines without
degrading success. Furthermore, we demonstrate D3P's effectiveness on a
physical robot, achieving a 1.9$\times$ acceleration over the baseline.

</details>


### [570] [Vibration-Based Energy Metric for Restoring Needle Alignment in Autonomous Robotic Ultrasound](https://arxiv.org/abs/2508.06921)
*Zhongyu Chen,Chenyang Li,Xuesong Li,Dianye Huang,Zhongliang Jiang,Stefanie Speidel,Xiangyu Chu,K. W. Samuel Au*

Main category: cs.RO

TL;DR: 提出一种利用针振动来恢复机器人超声引导针插入中对齐的方法，即使在针不可见时也有效。


<details>
  <summary>Details</summary>
Motivation: 精确的针对齐对于机器人超声引导过程中的经皮针插入至关重要。然而，散斑噪声、针状伪影和低图像分辨率等固有挑战使得鲁棒的针检测变得困难，尤其是在可见性降低或丢失时。本研究旨在解决超声成像平面与针插入平面不对齐时的针对齐恢复问题。

Method: 提出了一种基于振动的能量度量，该度量通过机械系统周期性地振动针来恢复超声引导的针插入过程中的针对齐。该方法不依赖于超声图像中的针可见性。

Result: 实验结果表明，在猪组织样本上，平移误差为 0.41±0.27 mm，旋转误差为 0.51±0.19 度。

Conclusion: 提出的基于振动的能量度量即使在针完全脱离平面时也有效，并提出了一种控制策略来重新定位超声探头以应对成像平面和针插入平面之间的平移和旋转不对齐。实验证明了该方法的有效性。

Abstract: Precise needle alignment is essential for percutaneous needle insertion in
robotic ultrasound-guided procedures. However, inherent challenges such as
speckle noise, needle-like artifacts, and low image resolution make robust
needle detection difficult, particularly when visibility is reduced or lost. In
this paper, we propose a method to restore needle alignment when the ultrasound
imaging plane and the needle insertion plane are misaligned. Unlike many
existing approaches that rely heavily on needle visibility in ultrasound
images, our method uses a more robust feature by periodically vibrating the
needle using a mechanical system. Specifically, we propose a vibration-based
energy metric that remains effective even when the needle is fully out of
plane. Using this metric, we develop a control strategy to reposition the
ultrasound probe in response to misalignments between the imaging plane and the
needle insertion plane in both translation and rotation. Experiments conducted
on ex-vivo porcine tissue samples using a dual-arm robotic ultrasound-guided
needle insertion system demonstrate the effectiveness of the proposed approach.
The experimental results show the translational error of 0.41$\pm$0.27 mm and
the rotational error of 0.51$\pm$0.19 degrees.

</details>


### [571] [Manipulator for people with limited abilities](https://arxiv.org/abs/2508.06969)
*Bingkun Huang,Evgeniy Kotov,Arkady Yuschenko*

Main category: cs.RO

TL;DR: This paper presents the development of a robotic hand with a control system, vision, and ROS software to help people with disabilities.


<details>
  <summary>Details</summary>
Motivation: The motivation behind this work is the growing importance of developing robotic systems to assist people with disabilities, aiming to significantly improve their quality of life through advanced robotics and automation.

Method: The paper details the process of designing a four-degree-of-freedom robotic hand, developing its control system, and integrating it with a technical vision system and software based on the Robot Operating System (ROS).

Result: The work involves the development and manufacturing of a functional four-degree-of-freedom robotic hand with an integrated control system, vision system, and ROS software, tailored for practical manipulation and assisting people with disabilities.

Conclusion: The paper focuses on the development and manufacturing of a four-degree-of-freedom robotic hand, along with its control system, integrated with a vision system and ROS software. This aims to improve the quality of life for people with disabilities through robotic assistance.

Abstract: The topic of this final qualification work was chosen due to the importance
of developing robotic systems designed to assist people with disabilities.
Advances in robotics and automation technologies have opened up new prospects
for creating devices that can significantly improve the quality of life for
these people. In this context, designing a robotic hand with a control system
adapted to the needs of people with disabilities is a major scientific and
practical challenge. This work addresses the problem of developing and
manufacturing a four-degree-of-freedom robotic hand suitable for practical
manipulation. Addressing this issue requires a comprehensive approach,
encompassing the design of the hand's mechanical structure, the development of
its control system, and its integration with a technical vision system and
software based on the Robot Operating System (ROS).

</details>


### [572] [Imaginative World Modeling with Scene Graphs for Embodied Agent Navigation](https://arxiv.org/abs/2508.06990)
*Yue Hu,Junzhe Wu,Ruihan Xu,Hang Liu,Avery Xi,Henry X. Liu,Ram Vasudevan,Maani Ghaffari*

Main category: cs.RO

TL;DR: SGImagineNav是一個創新的想像導航框架，通過符號世界建模和大型語言模型預測未來場景，實現更快的目標導航。該方法在真實世界和模擬環境中均表現出色。


<details>
  <summary>Details</summary>
Motivation: 為了解決無預測導航的低效率問題，提出一種能夠預測未來場景的想像導航策略，以幫助代理更快地找到目標。

Method: 提出SGImagineNav框架，利用符號世界建模和層次化場景圖來預測和探索未知環境。該框架使用大型語言模型預測未來場景，並採用自適應導航策略，在有利時利用語義捷徑，否則探索未知區域以收集更多上下文。

Result: SGImagineNav在真實世界場景和模擬基準測試中均優於現有方法。

Conclusion: SGImagineNav在HM3D和HSSD的成功率分別達到65.4%和66.8%，並在真實環境中展示了跨樓層和跨房間導航能力，證明了其有效性和通用性。

Abstract: Semantic navigation requires an agent to navigate toward a specified target
in an unseen environment. Employing an imaginative navigation strategy that
predicts future scenes before taking action, can empower the agent to find
target faster. Inspired by this idea, we propose SGImagineNav, a novel
imaginative navigation framework that leverages symbolic world modeling to
proactively build a global environmental representation. SGImagineNav maintains
an evolving hierarchical scene graphs and uses large language models to predict
and explore unseen parts of the environment. While existing methods solely
relying on past observations, this imaginative scene graph provides richer
semantic context, enabling the agent to proactively estimate target locations.
Building upon this, SGImagineNav adopts an adaptive navigation strategy that
exploits semantic shortcuts when promising and explores unknown areas otherwise
to gather additional context. This strategy continuously expands the known
environment and accumulates valuable semantic contexts, ultimately guiding the
agent toward the target. SGImagineNav is evaluated in both real-world scenarios
and simulation benchmarks. SGImagineNav consistently outperforms previous
methods, improving success rate to 65.4 and 66.8 on HM3D and HSSD, and
demonstrating cross-floor and cross-room navigation in real-world environments,
underscoring its effectiveness and generalizability.

</details>


### [573] [EGS-SLAM: RGB-D Gaussian Splatting SLAM with Events](https://arxiv.org/abs/2508.07003)
*Siyu Chen,Shenghai Yuan,Thien-Minh Nguyen,Zhuyu Huang,Chenyang Shi,Jin Jing,Lihua Xie*

Main category: cs.RO

TL;DR: EGS-SLAM通过融合事件数据和RGB-D输入，解决了传统GS-SLAM在运动模糊场景下的性能下降问题，实现了更准确的跟踪和更高质量的3D重建。


<details>
  <summary>Details</summary>
Motivation: 现有GS-SLAM系统在真实世界的持久性、严重运动模糊场景下表现不佳，导致跟踪精度下降和3D重建质量受损。

Method: 提出了一种名为EGS-SLAM的新框架，融合事件数据与RGB-D输入，通过显式建模相机在曝光期间的连续轨迹，实现事件感知和模糊感知的跟踪与建图，并引入可学习的相机响应函数来对齐事件和图像的动态范围，同时使用无事件损失来抑制重建过程中的振铃伪影。

Result: 在包含显著运动模糊的合成和真实世界序列的新数据集上进行验证，实验结果表明EGS-SLAM在轨迹准确性和3D高斯喷涂重建质量方面持续优于现有GS-SLAM系统。

Conclusion: EGS-SLAM通过融合事件数据和RGB-D输入，在处理运动模糊方面取得了显著进步，在轨迹准确性和3D高斯喷涂重建质量上均优于现有GS-SLAM系统。

Abstract: Gaussian Splatting SLAM (GS-SLAM) offers a notable improvement over
traditional SLAM methods, enabling photorealistic 3D reconstruction that
conventional approaches often struggle to achieve. However, existing GS-SLAM
systems perform poorly under persistent and severe motion blur commonly
encountered in real-world scenarios, leading to significantly degraded tracking
accuracy and compromised 3D reconstruction quality. To address this limitation,
we propose EGS-SLAM, a novel GS-SLAM framework that fuses event data with RGB-D
inputs to simultaneously reduce motion blur in images and compensate for the
sparse and discrete nature of event streams, enabling robust tracking and
high-fidelity 3D Gaussian Splatting reconstruction. Specifically, our system
explicitly models the camera's continuous trajectory during exposure,
supporting event- and blur-aware tracking and mapping on a unified 3D Gaussian
Splatting scene. Furthermore, we introduce a learnable camera response function
to align the dynamic ranges of events and images, along with a no-event loss to
suppress ringing artifacts during reconstruction. We validate our approach on a
new dataset comprising synthetic and real-world sequences with significant
motion blur. Extensive experimental results demonstrate that EGS-SLAM
consistently outperforms existing GS-SLAM systems in both trajectory accuracy
and photorealistic 3D Gaussian Splatting reconstruction. The source code will
be available at https://github.com/Chensiyu00/EGS-SLAM.

</details>


### [574] [$\mathcal{P}^3$: Toward Versatile Embodied Agents](https://arxiv.org/abs/2508.07033)
*Shengli Zhou,Xiangchen Wang,Jinrui Zhang,Ruozai Tian,Rongtao Xu,Feng Zheng*

Main category: cs.RO

TL;DR: P3 是一个统一的框架，用于解决具身智能体在动态环境感知、工具使用和多任务规划方面的挑战。它通过主动感知、即插即用工具和动态任务调度来改进智能体的性能，并在现实世界实验中取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 之前的具身智能体研究在动态环境感知、开放式工具使用和复杂多任务规划方面存在局限性。具体来说，以往的研究主要依赖工具代理的反馈来感知环境变化和任务状态，这限制了对实时动态的适应性，导致错误累积，并限制了工具的灵活性。此外，由于管理任务依赖关系和在动态复杂环境中平衡竞争优先级 inherent complexity，多任务调度问题受到的关注有限。

Method: P3 框架集成了实时感知和动态调度。具体而言，P3 能够 1) 主动从环境中感知相关的任务信息，2) 即插即用地使用任何工具而无需反馈，并且 3) 基于优先处理紧急任务和根据依赖关系动态调整任务顺序来规划多任务执行。

Result: 大量的现实世界实验表明，P3 方法有效地弥合了基准测试与实际部署之间的差距，实现了高度可迁移、通用的具身智能体。

Conclusion: 该研究提出的 P3 框架能够有效地解决动态环境感知、开放式工具使用和复杂多任务规划这三个关键挑战，从而为构建多功能性具身智能体提供了新的解决方案。通过主动感知环境信息、无需反馈即可使用工具以及基于优先级和动态依赖关系规划多任务执行，P3 框架在现实世界实验中表现出色，证明了其在实际应用中的高度可迁移性和通用性。

Abstract: Embodied agents have shown promising generalization capabilities across
diverse physical environments, making them essential for a wide range of
real-world applications. However, building versatile embodied agents poses
critical challenges due to three key issues: dynamic environment perception,
open-ended tool usage, and complex multi-task planning. Most previous works
rely solely on feedback from tool agents to perceive environmental changes and
task status, which limits adaptability to real-time dynamics, causes error
accumulation, and restricts tool flexibility. Furthermore, multi-task
scheduling has received limited attention, primarily due to the inherent
complexity of managing task dependencies and balancing competing priorities in
dynamic and complex environments. To overcome these challenges, we introduce
$\mathcal{P}^3$, a unified framework that integrates real-time perception and
dynamic scheduling. Specifically, $\mathcal{P}^3$ enables 1) \textbf Perceive
relevant task information actively from the environment, 2) \textbf Plug and
utilize any tool without feedback requirement, and 3) \textbf Plan multi-task
execution based on prioritizing urgent tasks and dynamically adjusting task
order based on dependencies. Extensive real-world experiments show that our
approach bridges the gap between benchmarks and practical deployment,
delivering highly transferable, general-purpose embodied agents. Code and data
will be released soon.

</details>


### [575] [From Data to Safe Mobile Robot Navigation: An Efficient and Modular Robust MPC Design Pipeline](https://arxiv.org/abs/2508.07045)
*Dennis Benders,Johannes Köhler,Robert Babuška,Javier Alonso-Mora,Laura Ferranti*

Main category: cs.RO

TL;DR: A new pipeline for robust Model Predictive Control (MPC) that uses experimental data to estimate disturbance bounds and create a safer control system for robots, shown to work in simulations.


<details>
  <summary>Details</summary>
Motivation: Existing MPC approaches for robot navigation often rely on idealized assumptions, neglect the impact of noisy measurements, and heuristically guess unrealistic bounds, making safety challenging in real-world deployments with disturbances and measurement noise.

Method: An iterative procedure that leverages closed-loop experimental data to estimate disturbance bounds and synthesize a robust output-feedback MPC scheme. The pipeline is provided in the form of deterministic and reproducible code.

Result: Empirically demonstrated robust constraint satisfaction and recursive feasibility in quadrotor simulations using Gazebo.

Conclusion: The proposed pipeline can systematically address limitations in existing robust MPC designs by leveraging closed-loop experimental data to estimate disturbance bounds and synthesize a robust output-feedback MPC scheme, which has been empirically demonstrated to achieve robust constraint satisfaction and recursive feasibility in quadrotor simulations.

Abstract: Model predictive control (MPC) is a powerful strategy for planning and
control in autonomous mobile robot navigation. However, ensuring safety in
real-world deployments remains challenging due to the presence of disturbances
and measurement noise. Existing approaches often rely on idealized assumptions,
neglect the impact of noisy measurements, and simply heuristically guess
unrealistic bounds. In this work, we present an efficient and modular robust
MPC design pipeline that systematically addresses these limitations. The
pipeline consists of an iterative procedure that leverages closed-loop
experimental data to estimate disturbance bounds and synthesize a robust
output-feedback MPC scheme. We provide the pipeline in the form of
deterministic and reproducible code to synthesize the robust output-feedback
MPC from data. We empirically demonstrate robust constraint satisfaction and
recursive feasibility in quadrotor simulations using Gazebo.

</details>


### [576] [Model Predictive Control for Crowd Navigation via Learning-Based Trajectory Prediction](https://arxiv.org/abs/2508.07079)
*Mohamed Parvez Aslam,Bojan Derajic,Mohamed-Khalil Bouzidi,Sebastian Bernhard,Jan Oliver Ringert*

Main category: cs.RO

TL;DR: 在拥挤的环境中，SI-MPC系统比传统的CV模型更安全、更平稳，但其预测过于谨慎。


<details>
  <summary>Details</summary>
Motivation: 在富含行人的环境中安全导航仍然是自主机器人的一个关键挑战。

Method: 将基于深度学习的社会-隐式（SI）行人轨迹预测器集成到模型预测控制（MPC）框架中，并在大陆信使机器人上进行了评估。

Result: SI提高了轨迹预测精度（在低密度环境下误差最多可减少76%），并提高了拥挤场景下的安全性和运动平稳性。然而，实际部署显示，开放式循环度量与闭环性能之间存在差异，因为SI模型产生了更广泛、更谨慎的预测。

Conclusion:  SI-MPC框架在动态、人口密集的で環境中具有更安全、更适应性导航的潜力，并强调了系统级评估的重要性。

Abstract: Safe navigation in pedestrian-rich environments remains a key challenge for
autonomous robots. This work evaluates the integration of a deep learning-based
Social-Implicit (SI) pedestrian trajectory predictor within a Model Predictive
Control (MPC) framework on the physical Continental Corriere robot. Tested
across varied pedestrian densities, the SI-MPC system is compared to a
traditional Constant Velocity (CV) model in both open-loop prediction and
closed-loop navigation. Results show that SI improves trajectory prediction -
reducing errors by up to 76% in low-density settings - and enhances safety and
motion smoothness in crowded scenes. Moreover, real-world deployment reveals
discrepancies between open-loop metrics and closed-loop performance, as the SI
model yields broader, more cautious predictions. These findings emphasize the
importance of system-level evaluation and highlight the SI-MPC framework's
promise for safer, more adaptive navigation in dynamic, human-populated
environments.

</details>


### [577] [An Evolutionary Game-Theoretic Merging Decision-Making Considering Social Acceptance for Autonomous Driving](https://arxiv.org/abs/2508.07080)
*Haolin Liu,Zijun Guo,Yanbo Chen,Jiaqi Chen,Huilong Yu,Junqiang Xi*

Main category: cs.RO

TL;DR: A new EGT framework for AV highway merging improves safety, efficiency, and comfort by considering human driving behavior and dynamically adjusting to surrounding vehicles.


<details>
  <summary>Details</summary>
Motivation: Existing decision-making algorithms for autonomous vehicles (AVs) at highway on-ramps fail to adequately address dynamic complexities and social acceptance, leading to suboptimal or unsafe merging decisions. There is a need for a framework that accounts for the bounded rationality of human drivers and balances the benefits of both AVs and main-road vehicles (MVs).

Method: An evolutionary game-theoretic (EGT) merging decision-making framework is proposed. The cut-in decision-making process is formulated as an EGT problem with a multi-objective payoff function. The replicator dynamic equation is solved to derive the optimal cut-in timing. A real-time driving style estimation algorithm adjusts the game payoff function online.

Result: Empirical results demonstrate that the proposed framework improves the efficiency, comfort, and safety of both AVs and MVs compared with existing game-theoretic and traditional planning approaches across multi-object metrics.

Conclusion: We propose an evolutionary game-theoretic (EGT) merging decision-making framework that balances the benefits of AVs and main-road vehicles (MVs), grounded in the bounded rationality of human drivers. The framework formulates the cut-in decision-making process as an EGT problem with a multi-objective payoff function reflecting human-like driving preferences. By solving the replicator dynamic equation for the evolutionarily stable strategy (ESS), we derive the optimal cut-in timing, balancing efficiency, comfort, and safety for both AVs and MVs. A real-time driving style estimation algorithm adjusts the game payoff function online by observing the immediate reactions of MVs. Empirical results demonstrate improvements in efficiency, comfort, and safety for both AVs and MVs compared to existing approaches.

Abstract: Highway on-ramp merging is of great challenge for autonomous vehicles (AVs),
since they have to proactively interact with surrounding vehicles to enter the
main road safely within limited time. However, existing decision-making
algorithms fail to adequately address dynamic complexities and social
acceptance of AVs, leading to suboptimal or unsafe merging decisions. To
address this, we propose an evolutionary game-theoretic (EGT) merging
decision-making framework, grounded in the bounded rationality of human
drivers, which dynamically balances the benefits of both AVs and main-road
vehicles (MVs). We formulate the cut-in decision-making process as an EGT
problem with a multi-objective payoff function that reflects human-like driving
preferences. By solving the replicator dynamic equation for the evolutionarily
stable strategy (ESS), the optimal cut-in timing is derived, balancing
efficiency, comfort, and safety for both AVs and MVs. A real-time driving style
estimation algorithm is proposed to adjust the game payoff function online by
observing the immediate reactions of MVs. Empirical results demonstrate that we
improve the efficiency, comfort and safety of both AVs and MVs compared with
existing game-theoretic and traditional planning approaches across multi-object
metrics.

</details>


### [578] [DexFruit: Dexterous Manipulation and Gaussian Splatting Inspection of Fruit](https://arxiv.org/abs/2508.07118)
*Aiden Swann,Alex Qiu,Matthew Strong,Angelina Zhang,Samuel Morstein,Kai Rayle,Monroe Kennedy III*

Main category: cs.RO

TL;DR: DexFruit通过光学触觉和3D高斯放射状损伤量化技术，实现了对易损水果的轻柔抓取，减少了20%的损伤，提高了31%的抓取成功率。


<details>
  <summary>Details</summary>
Motivation: 为了解决人工采摘水果时易损水果容易碰伤的问题，以及现有损伤评估指标的量化不足或设备昂贵的问题，本研究旨在通过机器人自主操控和先进的损伤量化技术，实现对易损水果的轻柔处理并精确评估损伤。

Method: 该研究提出了一种名为DexFruit的机器人操控框架，结合了光学触觉传感和一种名为FruitSplat的新型损伤量化技术（基于3D高斯放射状）。DexFruit框架能够实现水果的自主抓取和处理，而FruitSplat技术则能以高分辨率3D形式量化视觉损伤。

Result: DexFruit框架在三种水果（草莓、番茄、黑莓）上的抓取策略比基线方法在减少擦伤和提高抓取成功率方面表现更优。具体来说，抓取策略成功率达到92%，视觉擦伤减少高达20%，在挑战性水果上的抓取成功率比基线提高了31%，该结果经过了超过630次试验的严格评估。

Conclusion: DexFruit框架通过使用光学触觉传感和基于3D高斯放射状的损伤量化技术，实现了对易损水果（草莓、番茄和黑莓）的轻柔自主抓取和损伤评估，显著减少了损伤并提高了抓取成功率。

Abstract: DexFruit is a robotic manipulation framework that enables gentle, autonomous
handling of fragile fruit and precise evaluation of damage. Many fruits are
fragile and prone to bruising, thus requiring humans to manually harvest them
with care. In this work, we demonstrate by using optical tactile sensing,
autonomous manipulation of fruit with minimal damage can be achieved. We show
that our tactile informed diffusion policies outperform baselines in both
reduced bruising and pick-and-place success rate across three fruits:
strawberries, tomatoes, and blackberries. In addition, we introduce FruitSplat,
a novel technique to represent and quantify visual damage in high-resolution 3D
representation via 3D Gaussian Splatting (3DGS). Existing metrics for measuring
damage lack quantitative rigor or require expensive equipment. With FruitSplat,
we distill a 2D strawberry mask as well as a 2D bruise segmentation mask into
the 3DGS representation. Furthermore, this representation is modular and
general, compatible with any relevant 2D model. Overall, we demonstrate a 92%
grasping policy success rate, up to a 20% reduction in visual bruising, and up
to an 31% improvement in grasp success rate on challenging fruit compared to
our baselines across our three tested fruits. We rigorously evaluate this
result with over 630 trials. Please checkout our website at
https://dex-fruit.github.io .

</details>


### [579] [3D Gaussian Representations with Motion Trajectory Field for Dynamic Scene Reconstruction](https://arxiv.org/abs/2508.07182)
*Xuesong Li,Lars Petersson,Vivien Rolland*

Main category: cs.RO

TL;DR: 该研究提出了一种结合3D高斯泼溅和运动轨迹场的新方法，用于单目视频中的动态场景新视角合成和运动重建，实现了优于现有技术的性能。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决单目视频中动态场景的新视角合成和运动重建的挑战，这对于许多机器人应用至关重要。

Method: 通过将3D高斯泼溅（3DGS）与运动轨迹场相结合，引入了一种新颖的方法，能够精确处理复杂的物体运动并实现物理上合理的运动轨迹。该方法通过将动态对象与静态背景分离，紧凑地优化运动轨迹场，并结合了时不变运动系数和共享运动轨迹基以捕获复杂的运动模式，同时最小化优化复杂度。

Result: 该方法在动态场景的新视角合成和运动轨迹恢复方面取得了最先进的结果。

Conclusion: 该方法在动态场景的新视角合成和运动轨迹恢复方面取得了最先进的结果，提高了动态场景重建的能力。

Abstract: This paper addresses the challenge of novel-view synthesis and motion
reconstruction of dynamic scenes from monocular video, which is critical for
many robotic applications. Although Neural Radiance Fields (NeRF) and 3D
Gaussian Splatting (3DGS) have demonstrated remarkable success in rendering
static scenes, extending them to reconstruct dynamic scenes remains
challenging. In this work, we introduce a novel approach that combines 3DGS
with a motion trajectory field, enabling precise handling of complex object
motions and achieving physically plausible motion trajectories. By decoupling
dynamic objects from static background, our method compactly optimizes the
motion trajectory field. The approach incorporates time-invariant motion
coefficients and shared motion trajectory bases to capture intricate motion
patterns while minimizing optimization complexity. Extensive experiments
demonstrate that our approach achieves state-of-the-art results in both
novel-view synthesis and motion trajectory recovery from monocular video,
advancing the capabilities of dynamic scene reconstruction.

</details>


### [580] [Impact of Gaze-Based Interaction and Augmentation on Human-Robot Collaboration in Critical Tasks](https://arxiv.org/abs/2508.07244)
*Ayesha Jena,Stefan Reitmann,Elin Anna Topp*

Main category: cs.RO

TL;DR: Foveated vision helps robots in search-and-rescue by improving performance and reducing user effort, and studying gaze patterns is key for better control.


<details>
  <summary>Details</summary>
Motivation: The study aimed to analyze head-gaze-based robot control and foveated visual augmentation in a simulated search-and-rescue task to understand their impact on performance and user experience.

Method: The study involved a user experiment analyzing head-gaze-based robot control and foveated visual augmentation in a simulated search-and-rescue task.

Result: Foveated augmentation significantly improved task performance, reduced cognitive load by 38%, and shortened task time by over 60%. Analysis of head-gaze patterns revealed the importance of near and far attention capture for understanding user intention in critical scenarios.

Conclusion: The study highlights the potential of foveation as an augmentation technique and the need for further research into gaze measures for leveraging them in critical tasks.

Abstract: We present a user study analyzing head-gaze-based robot control and foveated
visual augmentation in a simulated search-and-rescue task. Results show that
foveated augmentation significantly improves task performance, reduces
cognitive load by 38%, and shortens task time by over 60%. Head-gaze patterns
analysed over both the entire task duration and shorter time segments show that
near and far attention capture is essential to better understand user intention
in critical scenarios. Our findings highlight the potential of foveation as an
augmentation technique and the need to further study gaze measures to leverage
them during critical tasks.

</details>


### [581] [Bio-Inspired Topological Autonomous Navigation with Active Inference in Robotics](https://arxiv.org/abs/2508.07267)
*Daria de Tinguy,Tim Verbelen,Emilio Gamba,Bart Dhoedt*

Main category: cs.RO

TL;DR: 本研究提出了一种基于主动推理框架（AIF）的仿生代理，用于机器人自主导航。该方法无需预训练，能够实时建图、定位并自适应决策，以应对动态和未知环境。实验证明，该方法在探索和导航任务上表现出色，与现有先进策略相当，并具有良好的可扩展性和透明性。


<details>
  <summary>Details</summary>
Motivation: 现有机器人自主探索和导航的方法要么依赖缺乏适应性的严格导航规则，要么依赖需要大量数据集的预训练。这些人工智能方法通常计算量大或基于静态假设，限制了它们在动态或未知环境中的适应性。

Method: 提出了一种基于主动推理框架（AIF）的仿生代理，实现了地图绘制、定位和自适应决策的统一，无需预先训练，即可在动态或未知环境中进行自主导航、探索和目标达成。

Result: 该模型实时创建和更新环境的拓扑地图，规划有向目标轨迹进行探索或达成目标。它提供了一个用于可解释导航的概率推理框架，并具有对动态变化的鲁棒适应性，以及与现有导航系统兼容的模块化 ROS2 架构。

Conclusion: 该方法在模拟和真实世界环境中都进行了测试，证明了其在复杂、非结构化环境中的可扩展性和透明性。其在探索大尺度模拟环境以及适应动态障碍物和漂移方面的表现，与 Gbplanner、FAEL 和 Frontiers 等其他探索策略相当。

Abstract: Achieving fully autonomous exploration and navigation remains a critical
challenge in robotics, requiring integrated solutions for localisation,
mapping, decision-making and motion planning. Existing approaches either rely
on strict navigation rules lacking adaptability or on pre-training, which
requires large datasets. These AI methods are often computationally intensive
or based on static assumptions, limiting their adaptability in dynamic or
unknown environments. This paper introduces a bio-inspired agent based on the
Active Inference Framework (AIF), which unifies mapping, localisation, and
adaptive decision-making for autonomous navigation, including exploration and
goal-reaching. Our model creates and updates a topological map of the
environment in real-time, planning goal-directed trajectories to explore or
reach objectives without requiring pre-training. Key contributions include a
probabilistic reasoning framework for interpretable navigation, robust
adaptability to dynamic changes, and a modular ROS2 architecture compatible
with existing navigation systems. Our method was tested in simulated and
real-world environments. The agent successfully explores large-scale simulated
environments and adapts to dynamic obstacles and drift, proving to be
comparable to other exploration strategies such as Gbplanner, FAEL and
Frontiers. This approach offers a scalable and transparent approach for
navigating complex, unstructured environments.

</details>


### [582] [Navigation and Exploration with Active Inference: from Biology to Industry](https://arxiv.org/abs/2508.07269)
*Daria de Tinguy,Tim Verbelen,Bart Dhoedt*

Main category: cs.RO

TL;DR: 受生物导航的启发，我们提出了一个基于主动推理框架的机器人实时导航系统，该系统能够构建认知地图、进行自主定位和规划动作，无需预先训练，并在各种环境中表现出竞争力。


<details>
  <summary>Details</summary>
Motivation: 受生物导航机制的启发，旨在为机器人开发一种实时的、无需预先训练的、基于认知地图的导航系统。

Method: 通过构建和更新内部认知图，结合了主动推理框架（AIF）、增量式拓扑地图构建、自主定位和基于预期不确定性最小化及感知目标实现的动作规划，并集成了ROS2生态系统。

Result: 在2D和3D环境（模拟和真实世界）中，该系统展示了适应性和效率，并与传统和最先进的探索方法相比具有竞争力。

Conclusion: 该系统在2D和3D环境（模拟和真实世界）中都得到了验证，展示了与传统和最先进的探索方法相比具有竞争力，同时提供了一种受生物启发的导航方法。

Abstract: By building and updating internal cognitive maps, animals exhibit
extraordinary navigation abilities in complex, dynamic environments. Inspired
by these biological mechanisms, we present a real time robotic navigation
system grounded in the Active Inference Framework (AIF). Our model
incrementally constructs a topological map, infers the agent's location, and
plans actions by minimising expected uncertainty and fulfilling perceptual
goals without any prior training. Integrated into the ROS2 ecosystem, we
validate its adaptability and efficiency across both 2D and 3D environments
(simulated and real world), demonstrating competitive performance with
traditional and state of the art exploration approaches while offering a
biologically inspired navigation approach.

</details>


### [583] [Multimodal Spiking Neural Network for Space Robotic Manipulation](https://arxiv.org/abs/2508.07287)
*Liwen Zhang,Dong Zhou,Shibo Shao,Zihao Su,Guanghui Sun*

Main category: cs.RO

TL;DR: A new SNN-based multimodal control framework for space robotic arms improves task success and energy efficiency using curriculum reinforcement learning.


<details>
  <summary>Details</summary>
Motivation: The framework is designed to cope with limited onboard resources in space stations and enable autonomous manipulation and material transfer in space operations, strengthening environmental awareness and contributing to more robust control strategies.

Method: The paper integrates geometric states with tactile and semantic information within a multimodal control framework. It utilizes a dual-channel, three-stage curriculum reinforcement learning (CRL) scheme to guide the learning process. The framework was tested on robotic arms in space stations for tasks such as target approach, object grasping, and stable lifting.

Result: Experimental evaluations show that the proposed method consistently outperforms baseline approaches in both task success rate and energy efficiency across various robotic arm tasks.

Conclusion: The proposed multimodal control framework based on SNNs demonstrates reliable performance and outperforms baseline approaches in task success rate and energy efficiency, highlighting its suitability for real-world aerospace applications.

Abstract: This paper presents a multimodal control framework based on spiking neural
networks (SNNs) for robotic arms aboard space stations. It is designed to cope
with the constraints of limited onboard resources while enabling autonomous
manipulation and material transfer in space operations. By combining geometric
states with tactile and semantic information, the framework strengthens
environmental awareness and contributes to more robust control strategies. To
guide the learning process progressively, a dual-channel, three-stage
curriculum reinforcement learning (CRL) scheme is further integrated into the
system. The framework was tested across a range of tasks including target
approach, object grasping, and stable lifting with wall-mounted robotic arms,
demonstrating reliable performance throughout. Experimental evaluations
demonstrate that the proposed method consistently outperforms baseline
approaches in both task success rate and energy efficiency. These findings
highlight its suitability for real-world aerospace applications.

</details>


### [584] [A Hybrid Force-Position Strategy for Shape Control of Deformable Linear Objects With Graph Attention Networks](https://arxiv.org/abs/2508.07319)
*Yanzhao Yu,Haotian Yang,Junbo Tan,Xueqian Wang*

Main category: cs.RO

TL;DR: 该研究提出了一种结合力空间轨迹规划和位空间模型预测控制（MPC）的混合方法，利用图注意力网络来改进DLO的形状控制，并在模拟和真实世界实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在电子组装和外科手术等应用中，操作可变形线性物体（DLO）如电线和电缆至关重要，但由于其无限的自由度、复杂的非线性动力学以及系统的非充分驱动等挑战，使得DLO的操作面临困难。

Method: 该研究提出了一种混合力-位策略，结合了DLO的力和位表示，并在力空间中整合了状态轨迹规划，在位空间中使用了基于图注意力网络的模型预测控制（MPC），该模型包含显式的动作编码器、属性提取器和图处理器，以提高预测的准确性。

Result: 模拟和真实世界实验的结果证明了该方法在实现DLO的高效且稳定的形状控制方面的有效性。

Conclusion: 该研究提出的混合力-位混合策略在模拟和真实世界实验中都证明了其在一个可变形线性物体（DLO）的形状控制方面的有效性，实现了高效且稳定的控制。

Abstract: Manipulating deformable linear objects (DLOs) such as wires and cables is
crucial in various applications like electronics assembly and medical
surgeries. However, it faces challenges due to DLOs' infinite degrees of
freedom, complex nonlinear dynamics, and the underactuated nature of the
system. To address these issues, this paper proposes a hybrid force-position
strategy for DLO shape control. The framework, combining both force and
position representations of DLO, integrates state trajectory planning in the
force space and Model Predictive Control (MPC) in the position space. We
present a dynamics model with an explicit action encoder, a property extractor
and a graph processor based on Graph Attention Networks. The model is used in
the MPC to enhance prediction accuracy. Results from both simulations and
real-world experiments demonstrate the effectiveness of our approach in
achieving efficient and stable shape control of DLOs. Codes and videos are
available at https://sites.google.com/view/dlom.

</details>


### [585] [Collision-Free Trajectory Planning and control of Robotic Manipulator using Energy-Based Artificial Potential Field (E-APF)](https://arxiv.org/abs/2508.07323)
*Adeetya Uppal,Rakesh Kumar Sahoo,Manoranjan Sinha*

Main category: cs.RO

TL;DR: 提出了一种新的能量型人工势场（E-APF）框架，并结合混合轨迹优化器，解决了机器人路径规划中的局部极小值和振荡问题，实现了高效、平稳的运动。


<details>
  <summary>Details</summary>
Motivation: 解决传统路径规划器（如人工势场法）在动态和杂乱环境中存在局部极小值和振荡运动的问题。

Method: 提出了一种能量型人工势场（E-APF）框架，该框架集成了位置和速度相关的势函数，并将其与混合轨迹优化器相结合，以在速度和加速度的约束下共同最小化加加速度和执行时间。

Result: 在模拟中，该框架能够生成无碰撞、平稳、高效且无振荡的轨迹。

Conclusion: 该框架为未来的反应式控制策略集成和实际硬件部署奠定了基础。

Abstract: Robotic trajectory planning in dynamic and cluttered environments remains a
critical challenge, particularly when striving for both time efficiency and
motion smoothness under actuation constraints. Traditional path planner, such
as Artificial Potential Field (APF), offer computational efficiency but suffer
from local minima issue due to position-based potential field functions and
oscillatory motion near the obstacles due to Newtonian mechanics. To address
this limitation, an Energy-based Artificial Potential Field (APF) framework is
proposed in this paper that integrates position and velocity-dependent
potential functions. E-APF ensures dynamic adaptability and mitigates local
minima, enabling uninterrupted progression toward the goal. The proposed
framework integrates E-APF with a hybrid trajectory optimizer that jointly
minimizes jerk and execution time under velocity and acceleration constraints,
ensuring geometric smoothness and time efficiency. The entire framework is
validated in simulation using the 7-degree-of-freedom Kinova Gen3 robotic
manipulator. The results demonstrate collision-free, smooth, time-efficient,
and oscillation-free trajectory in the presence of obstacles, highlighting the
efficacy of the combined trajectory optimization and real-time obstacle
avoidance approach. This work lays the foundation for future integration with
reactive control strategies and physical hardware deployment in real-world
manipulation tasks.

</details>


### [586] [MonoMPC: Monocular Vision Based Navigation with Learned Collision Model and Risk-Aware Model Predictive Control](https://arxiv.org/abs/2508.07387)
*Basant Sharma,Prajyot Jadhav,Pranjal Paul,K. Madhava Krishna,Arun Kumar Singh*

Main category: cs.RO

TL;DR: 在未知环境中，使用单一RGB摄像头导航时，由于深度信息缺失，难以进行碰撞检测。本研究提出了一种新方法，利用估计的深度信息作为输入，训练一个碰撞模型来预测最小障碍物间隙，并通过风险感知的MPC规划器来最小化碰撞风险，在混乱环境中导航时取得了显著的成功率提升。


<details>
  <summary>Details</summary>
Motivation: 在未知环境中使用单一RGB摄像头进行导航时，缺乏深度信息会导致可靠的碰撞检查出现问题。虽然一些方法使用估计的深度来构建碰撞地图，但研究发现，视觉基础模型估计的深度在杂乱环境中进行零样本导航时过于嘈杂。

Method: 本文提出了一种新颖的基于学习的碰撞模型，该模型利用估计的深度信息作为上下文输入，预测最小障碍物间隙分布。该模型与风险感知MPC规划器相结合，通过最小化估计的碰撞风险来进行导航。通过联合训练碰撞模型和风险度量，并优化碰撞模型的方差，提高了在混乱环境中的导航能力。

Result: 实验结果表明，与NoMaD和ROS堆栈相比，该方法在成功率方面分别提高了9倍和7倍。消融研究也验证了所选设计决策的有效性。

Conclusion: 该研究提出了一种新颖的方法，利用估计的深度信息作为上下文输入到一个学习到的碰撞模型中，该模型可以预测机器人可预期的最小障碍物间隙分布，从而提高了在混乱环境中的导航性能。

Abstract: Navigating unknown environments with a single RGB camera is challenging, as
the lack of depth information prevents reliable collision-checking. While some
methods use estimated depth to build collision maps, we found that depth
estimates from vision foundation models are too noisy for zero-shot navigation
in cluttered environments.
  We propose an alternative approach: instead of using noisy estimated depth
for direct collision-checking, we use it as a rich context input to a learned
collision model. This model predicts the distribution of minimum obstacle
clearance that the robot can expect for a given control sequence. At inference,
these predictions inform a risk-aware MPC planner that minimizes estimated
collision risk. Our joint learning pipeline co-trains the collision model and
risk metric using both safe and unsafe trajectories. Crucially, our
joint-training ensures optimal variance in our collision model that improves
navigation in highly cluttered environments. Consequently, real-world
experiments show 9x and 7x improvements in success rates over NoMaD and the ROS
stack, respectively. Ablation studies further validate the effectiveness of our
design choices.

</details>


### [587] [AgriVLN: Vision-and-Language Navigation for Agricultural Robots](https://arxiv.org/abs/2508.07406)
*Xiaobei Zhao,Xingqi Lyu,Xiang Li*

Main category: cs.RO

TL;DR: 提出 A2A 基准和 AgriVLN 方法，用于农业场景的视觉和语言导航。通过集成 STL 模块，改进了对长指令的处理能力，并在农业领域实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的农业机器人移动能力有限且适应性差，主要依赖手动操作或不可运输的轨道。视觉和语言导航 (VLN) 技术在其他领域表现良好，但缺乏专门针对农业场景的基准和方法。

Method: 提出 A2A 基准（包含 1,560 个跨越六个不同农业场景的试验）和 AgriVLN 基线（基于视觉语言模型并使用精心设计的模板提示），用于农业场景的视觉和语言导航。AgriVLN 进一步集成了子任务列表（STL）指令分解模块以提高对长指令的处理能力。

Result: AgriVLN 在 A2A 基准上表现良好，但对长指令的处理能力不足。集成 STL 模块后，成功率从 0.33 提高到 0.47。与现有 VLN 方法相比，AgriVLN 在农业领域取得了最先进的性能。

Conclusion: AgriVLN 结合了 STL 模块，在 A2A 基准上的成功率从 0.33 提高到 0.47，并在农业领域展示了最先进的性能。

Abstract: Agricultural robots have emerged as powerful members in agricultural tasks,
nevertheless, still heavily rely on manual operation or untransportable railway
for movement, resulting in limited mobility and poor adaptability.
Vision-and-Language Navigation (VLN) enables robots to navigate to the target
destinations following natural language instructions, demonstrating strong
performance on several domains. However, none of the existing benchmarks or
methods is specifically designed for agricultural scenes. To bridge this gap,
we propose Agriculture to Agriculture (A2A) benchmark, containing 1,560
episodes across six diverse agricultural scenes, in which all realistic RGB
videos are captured by front-facing camera on a quadruped robot at a height of
0.38 meters, aligning with the practical deployment conditions. Meanwhile, we
propose Vision-and-Language Navigation for Agricultural Robots (AgriVLN)
baseline based on Vision-Language Model (VLM) prompted with carefully crafted
templates, which can understand both given instructions and agricultural
environments to generate appropriate low-level actions for robot control. When
evaluated on A2A, AgriVLN performs well on short instructions but struggles
with long instructions, because it often fails to track which part of the
instruction is currently being executed. To address this, we further propose
Subtask List (STL) instruction decomposition module and integrate it into
AgriVLN, improving Success Rate (SR) from 0.33 to 0.47. We additionally compare
AgriVLN with several existing VLN methods, demonstrating the state-of-the-art
performance in the agricultural domain.

</details>


### [588] [Triple-S: A Collaborative Multi-LLM Framework for Solving Long-Horizon Implicative Tasks in Robotics](https://arxiv.org/abs/2508.07421)
*Zixi Jia,Hongbin Gao,Fashe Li,Jiqiang Liu,Hexiao Li,Qinghua Liu*

Main category: cs.RO

TL;DR: Triple-S框架使用多个LLM协作，通过简化-解决-总结的流程，解决了LLM生成机器人策略代码在长时序任务中的错误问题，提高了成功率和鲁棒性，并在实验中取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM用于机器人策略代码生成的方法在长时序隐含任务中存在API参数、注释和排序错误等问题，导致任务失败。需要一种更有效的方法来提高成功率和鲁棒性。

Method: 提出了一种名为Triple-S的协作框架，该框架利用多LLM通过情境学习（In-Context Learning）扮演不同角色，执行简化-解决-总结（Simplification-Solution-Summary）的闭环过程。此外，还提出了一种新颖的演示库更新机制，能够从成功案例中学习并泛化到先前失败的任务。

Result: 在LDIP数据集上，Triple-S在可观察和部分可观察场景下成功执行了89%的任务。该框架在模拟和真实机器人环境中都得到了有效验证。

Conclusion: 该研究提出了一种名为Triple-S的协作框架，利用多LLM在长时序隐含任务中生成机器人策略代码，显著提高了成功率和鲁棒性，并在LDIP数据集和真实机器人环境中得到了验证。

Abstract: Leveraging Large Language Models (LLMs) to write policy code for controlling
robots has gained significant attention. However, in long-horizon implicative
tasks, this approach often results in API parameter, comments and sequencing
errors, leading to task failure. To address this problem, we propose a
collaborative Triple-S framework that involves multiple LLMs. Through
In-Context Learning, different LLMs assume specific roles in a closed-loop
Simplification-Solution-Summary process, effectively improving success rates
and robustness in long-horizon implicative tasks. Additionally, a novel
demonstration library update mechanism which learned from success allows it to
generalize to previously failed tasks. We validate the framework in the
Long-horizon Desktop Implicative Placement (LDIP) dataset across various
baseline models, where Triple-S successfully executes 89% of tasks in both
observable and partially observable scenarios. Experiments in both simulation
and real-world robot settings further validated the effectiveness of Triple-S.
Our code and dataset is available at: https://github.com/Ghbbbbb/Triple-S.

</details>


### [589] [A Learning-Based Framework for Collision-Free Motion Planning](https://arxiv.org/abs/2508.07502)
*Mateus Salomão,Tianyü Ren,Alexander König*

Main category: cs.RO

TL;DR: 提出了一种基于学习的运动规划方法，用于在杂乱环境中高效生成无碰撞轨迹，通过深度学习自动调整参数，实现了实时规划和更好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了克服手动调整力场参数的局限性，为基于圆形视场（CF）的运动规划器提出一种基于学习的扩展，以在杂乱环境中实现高效、无碰撞的轨迹生成。

Method: 提出了一种基于学习的扩展，用于基于圆形视场（CF）的运动规划器，通过训练深度神经网络来从场景的单个深度图像推断最优规划器增益，克服了手动调整力场参数的局限性。

Result: 实验结果表明，与经典规划器相比，任务完成度和泛化能力均得到提升。

Conclusion: 该框架能够在无手动参数调整的情况下实现实时规划，并在模拟和Franka Emika Panda机器人上得到验证。实验结果表明，与经典规划器相比，任务完成度和泛化能力均得到提升。

Abstract: This paper presents a learning-based extension to a Circular Field (CF)-based
motion planner for efficient, collision-free trajectory generation in cluttered
environments. The proposed approach overcomes the limitations of hand-tuned
force field parameters by employing a deep neural network trained to infer
optimal planner gains from a single depth image of the scene. The pipeline
incorporates a CUDA-accelerated perception module, a predictive agent-based
planning strategy, and a dataset generated through Bayesian optimization in
simulation. The resulting framework enables real-time planning without manual
parameter tuning and is validated both in simulation and on a Franka Emika
Panda robot. Experimental results demonstrate successful task completion and
improved generalization compared to classical planners.

</details>


### [590] [Progressive Bird's Eye View Perception for Safety-Critical Autonomous Driving: A Comprehensive Survey](https://arxiv.org/abs/2508.07560)
*Yan Gong,Naibang Wang,Jianli Lu,Xinyu Zhang,Yongsheng Gao,Jie Zhao,Zifan Huang,Haozhi Bai,Nanxin Zeng,Nayu Su,Lei Yang,Ziying Song,Xiaoxi Hu,Xinmin Jiang,Xiaojuan Zhang,Susanto Rahardja*

Main category: cs.RO

TL;DR: BEV perception is crucial for autonomous driving, but real-world deployment faces safety challenges. This survey reviews current methods, datasets, and future research directions for safer BEV perception.


<details>
  <summary>Details</summary>
Motivation: To address the critical challenge of ensuring the safety and reliability of BEV perception in complex real-world scenarios as autonomous vehicles transition from controlled environments to deployment.

Method: Systematic review and analysis of state-of-the-art BEV perception frameworks, implementation strategies, and public datasets, focusing on safety and robustness in autonomous driving.

Result: An analysis of state-of-the-art BEV perception frameworks, evaluation of public datasets for safety and robustness, and identification of key open-world challenges and future research directions.

Conclusion: This survey provides the first comprehensive review of Bird's-Eye-View (BEV) perception from a safety-critical perspective, systematically analyzing state-of-the-art frameworks and implementation strategies across three progressive stages: single-modality vehicle-side, multimodal vehicle-side, and multi-agent collaborative perception. It also examines public datasets and identifies key open-world challenges and future research directions.

Abstract: Bird's-Eye-View (BEV) perception has become a foundational paradigm in
autonomous driving, enabling unified spatial representations that support
robust multi-sensor fusion and multi-agent collaboration. As autonomous
vehicles transition from controlled environments to real-world deployment,
ensuring the safety and reliability of BEV perception in complex scenarios -
such as occlusions, adverse weather, and dynamic traffic - remains a critical
challenge. This survey provides the first comprehensive review of BEV
perception from a safety-critical perspective, systematically analyzing
state-of-the-art frameworks and implementation strategies across three
progressive stages: single-modality vehicle-side, multimodal vehicle-side, and
multi-agent collaborative perception. Furthermore, we examine public datasets
encompassing vehicle-side, roadside, and collaborative settings, evaluating
their relevance to safety and robustness. We also identify key open-world
challenges - including open-set recognition, large-scale unlabeled data, sensor
degradation, and inter-agent communication latency - and outline future
research directions, such as integration with end-to-end autonomous driving
systems, embodied intelligence, and large language models.

</details>


### [591] [Autonomous Navigation of Cloud-Controlled Quadcopters in Confined Spaces Using Multi-Modal Perception and LLM-Driven High Semantic Reasoning](https://arxiv.org/abs/2508.07885)
*Shoaib Ahmmad,Zubayer Ahmed Aditto,Md Mehrab Hossain,Noushin Yeasmin,Shorower Hossain*

Main category: cs.RO

TL;DR: 一项新的人工智能驱动的无人机导航系统，在无GPS的室内环境中表现出色，其特点是利用云计算、定制PCB、YOLOv11、Depth Anything V2和LLM，实现了低延迟和高精度。


<details>
  <summary>Details</summary>
Motivation: 在禁止GPS的室内环境中，为自主四旋翼飞行器导航提供一种先进的、由人工智能驱动的感知系统。

Method: 本研究提出了一种先进的、由人工智能驱动的感知系统，用于在禁止GPS的室内环境中进行自主四旋翼飞行器导航。该框架利用云计算来卸载计算密集型任务，并包含一个定制设计的印刷电路板（PCB），用于高效的传感器数据采集，从而在有限的空间内实现稳健的导航。该系统集成了YOLOv11进行对象检测、Depth Anything V2进行单目深度估计、一个配备飞行时间（ToF）传感器和惯性测量单元（IMU）的PCB，以及一个基于云的、用于上下文感知决策制定的语言模型（LLM）。通过经过校准的传感器偏移量强制执行的虚拟安全包络可确保避免碰撞，而多线程体系结构可实现低延迟处理。通过带有卡尔曼滤波的三维边界框估计可增强空间感知能力。

Result: 在室内测试中，对象检测达到了0.6的平均精度（mAP50），深度估计的平均绝对误差（MAE）为7.2厘米。在42次试验（约11分钟）中，仅发生了16次安全包络违规，并且端到端的系统延迟低于1秒。

Conclusion: 该框架作为一种辅助感知和导航系统，对无GPS的封闭空间中的先进无人机自主性进行了补充。

Abstract: This paper introduces an advanced AI-driven perception system for autonomous
quadcopter navigation in GPS-denied indoor environments. The proposed framework
leverages cloud computing to offload computationally intensive tasks and
incorporates a custom-designed printed circuit board (PCB) for efficient sensor
data acquisition, enabling robust navigation in confined spaces. The system
integrates YOLOv11 for object detection, Depth Anything V2 for monocular depth
estimation, a PCB equipped with Time-of-Flight (ToF) sensors and an Inertial
Measurement Unit (IMU), and a cloud-based Large Language Model (LLM) for
context-aware decision-making. A virtual safety envelope, enforced by
calibrated sensor offsets, ensures collision avoidance, while a multithreaded
architecture achieves low-latency processing. Enhanced spatial awareness is
facilitated by 3D bounding box estimation with Kalman filtering. Experimental
results in an indoor testbed demonstrate strong performance, with object
detection achieving a mean Average Precision (mAP50) of 0.6, depth estimation
Mean Absolute Error (MAE) of 7.2 cm, only 16 safety envelope breaches across 42
trials over approximately 11 minutes, and end-to-end system latency below 1
second. This cloud-supported, high-intelligence framework serves as an
auxiliary perception and navigation system, complementing state-of-the-art
drone autonomy for GPS-denied confined spaces.

</details>


### [592] [Feedback Control of a Single-Tail Bioinspired 59-mg Swimmer](https://arxiv.org/abs/2508.07566)
*Conor K. Trygstad,Cody R. Longwell,Francisco M. F. R. Gonçalves,Elijah K. Blankenship,Néstor O. Pérez-Arancibia*

Main category: cs.RO

TL;DR: 本研究介绍了一种改进的 FRISSHBot，它可以在二维空间中进行控制和轨迹跟踪，并实现了亚克级尺度上的板载驱动。


<details>
  <summary>Details</summary>
Motivation: 为了实现亚克级水下机器人的二维运动控制和轨迹跟踪，我们改进了 FRISSHBot。

Method: 通过改进的物理信息设计，包括增大的头部和缩短的尾部，并采用基于形状记忆合金的新型弯曲执行器，实现了 FRISSHBot 的可控性。

Result: 新 FRISSHBot 的最大前进速度达到 13.6 毫米/秒（比原平台快四倍以上），在进行闭环二维轨迹跟踪时，最大前进速度为 9.1 毫米/秒，均方根跟踪误差低至 2.6 毫米，最大转向速率为 13.1 度/秒，最小转向半径为 10 毫米。

Conclusion: FRISSHBot 平台成功实现了二维空间中的运动控制和轨迹跟踪，该机器人具有在亚克级尺度上通过板载驱动实现反馈控制的能力。

Abstract: We present an evolved steerable version of the single-tail
Fish-&-Ribbon-Inspired Small Swimming Harmonic roBot (FRISSHBot), a 59-mg
biologically inspired swimmer, which is driven by a new shape-memory alloy
(SMA)-based bimorph actuator. The new FRISSHBot is controllable in the
two-dimensional (2D) space, which enabled the first demonstration of
feedback-controlled trajectory tracking of a single-tail aquatic robot with
onboard actuation at the subgram scale. These new capabilities are the result
of a physics-informed design with an enlarged head and shortened tail relative
to those of the original platform. Enhanced by its design, this new platform
achieves forward swimming speeds of up to 13.6 mm/s (0.38 Bl/s), which is over
four times that of the original platform. Furthermore, when following 2D
references in closed loop, the tested FRISSHBot prototype attains forward
swimming speeds of up to 9.1 mm/s, root-mean-square (RMS) tracking errors as
low as 2.6 mm, turning rates of up to 13.1 {\deg}/s, and turning radii as small
as 10 mm.

</details>


### [593] [In-situ Value-aligned Human-Robot Interactions with Physical Constraints](https://arxiv.org/abs/2508.07606)
*Hongtao Li,Ziyuan Jiao,Xiaofeng Liu,Hangxin Liu,Zilong Zheng*

Main category: cs.RO

TL;DR: 提出ICLHF框架，使机器人能在执行任务时兼顾物理约束和人类偏好。


<details>
  <summary>Details</summary>
Motivation: 为了让以人为本的机器人不仅能完成任务，还能学习并应用人类偏好。

Method: 提出了一种将人类偏好与物理约束相结合的框架，并引入了从人类反馈中进行语境学习（ICLHF），从日常生活中收集人类反馈。

Result: 通过在日常家务活动基准测试中进行的大量实验证明了该方法的有效性。

Conclusion: 该方法有效，能在执行任务时兼顾物理约束和人类偏好。

Abstract: Equipped with Large Language Models (LLMs), human-centered robots are now
capable of performing a wide range of tasks that were previously deemed
challenging or unattainable. However, merely completing tasks is insufficient
for cognitive robots, who should learn and apply human preferences to future
scenarios. In this work, we propose a framework that combines human preferences
with physical constraints, requiring robots to complete tasks while considering
both. Firstly, we developed a benchmark of everyday household activities, which
are often evaluated based on specific preferences. We then introduced
In-Context Learning from Human Feedback (ICLHF), where human feedback comes
from direct instructions and adjustments made intentionally or unintentionally
in daily life. Extensive sets of experiments, testing the ICLHF to generate
task plans and balance physical constraints with preferences, have demonstrated
the efficiency of our approach.

</details>


### [594] [COMponent-Aware Pruning for Accelerated Control Tasks in Latent Space Models](https://arxiv.org/abs/2508.08144)
*Ganesh Sundaram,Jonas Ulmen,Amjad Haider,Daniel Görges*

Main category: cs.RO

TL;DR: 为了解决深度神经网络（DNN）在计算复杂性和内存需求方面对边缘设备的挑战，提出了一种利用组件感知结构化剪枝的综合模型压缩方法。该方法通过将数学稳定性保证（特别是李雅普诺夫标准）与时间差分模型预测控制（TD-MPC）相结合，在模型压缩和控制器稳定性之间取得了平衡。该方法为安全压缩率设定了定量边界，从而能够可靠地部署压缩的神经网络控制器（NNC）。


<details>
  <summary>Details</summary>
Motivation: 资源受限的移动平台（包括移动机器人、可穿戴系统和物联网设备）的快速发展，增加了对计算高效的神经网络控制器（NNC）的需求，这些控制器可以在严格的硬件限制下运行。虽然深度神经网络（DNN）在控制应用中表现出卓越的性能，但其巨大的计算复杂性和内存需求阻碍了其在边缘设备的实际部署。

Method: 提出了一种利用组件感知结构化剪枝来确定每个剪枝组的最佳剪枝幅度，以在压缩和稳定性之间取得平衡的综合模型压缩方法。

Result: 实验验证表明，该方法在时间差分模型预测控制（TD-MPC）这一最先进的基于模型的强化学习算法上得到了严格评估，并系统地整合了数学稳定性保证属性，特别是李雅普诺夫标准。

Conclusion: 该方法成功降低了模型复杂度，同时保持了所需的控制性能和稳定性特征。此外，该方法为安全压缩率建立了定量边界，使实践者能够系统地确定违反关键稳定性属性之前的最大允许模型缩减量，从而有助于在资源有限的环境中可靠地部署压缩的NNC。

Abstract: The rapid growth of resource-constrained mobile platforms, including mobile
robots, wearable systems, and Internet-of-Things devices, has increased the
demand for computationally efficient neural network controllers (NNCs) that can
operate within strict hardware limitations. While deep neural networks (DNNs)
demonstrate superior performance in control applications, their substantial
computational complexity and memory requirements present significant barriers
to practical deployment on edge devices. This paper introduces a comprehensive
model compression methodology that leverages component-aware structured pruning
to determine the optimal pruning magnitude for each pruning group, ensuring a
balance between compression and stability for NNC deployment. Our approach is
rigorously evaluated on Temporal Difference Model Predictive Control (TD-MPC),
a state-of-the-art model-based reinforcement learning algorithm, with a
systematic integration of mathematical stability guarantee properties,
specifically Lyapunov criteria. The key contribution of this work lies in
providing a principled framework for determining the theoretical limits of
model compression while preserving controller stability. Experimental
validation demonstrates that our methodology successfully reduces model
complexity while maintaining requisite control performance and stability
characteristics. Furthermore, our approach establishes a quantitative boundary
for safe compression ratios, enabling practitioners to systematically determine
the maximum permissible model reduction before violating critical stability
properties, thereby facilitating the confident deployment of compressed NNCs in
resource-limited environments.

</details>


### [595] [End-to-End Humanoid Robot Safe and Comfortable Locomotion Policy](https://arxiv.org/abs/2508.07611)
*Zifan Wang,Xun Yang,Jianzhuang Zhao,Jiaming Zhou,Teli Ma,Ziyao Gao,Arash Ajoudani,Junwei Liang*

Main category: cs.RO

TL;DR: Humanoid robots navigate safely and smoothly in cluttered environments using LiDAR and a novel reinforcement learning approach combining CMDP and CBFs.


<details>
  <summary>Details</summary>
Motivation: Current reinforcement learning approaches for humanoid robot navigation in human-centric environments are limited by blind controllers or vision-based systems that fail with complex 3D obstacles. There is a need for robust perception, provable safety, and socially aware behavior.

Method: An end-to-end locomotion policy using Constrained Markov Decision Process (CMDP) and Penalized Proximal Policy Optimization (P3O) is presented. Safety constraints are enforced by translating Control Barrier Functions (CBFs) into costs within the CMDP, and comfort-oriented rewards are introduced for smooth, predictable, and less intrusive motion.

Result: The framework successfully navigates cluttered dynamic scenes and demonstrates effective sim-to-real transfer to a physical humanoid robot, exhibiting agile and safe movement around static and dynamic 3D obstacles.

Conclusion: The proposed framework enables agile and safe navigation for humanoid robots in cluttered dynamic scenes by directly mapping LiDAR point clouds to motor commands, achieving successful sim-to-real transfer.

Abstract: The deployment of humanoid robots in unstructured, human-centric environments
requires navigation capabilities that extend beyond simple locomotion to
include robust perception, provable safety, and socially aware behavior.
Current reinforcement learning approaches are often limited by blind
controllers that lack environmental awareness or by vision-based systems that
fail to perceive complex 3D obstacles. In this work, we present an end-to-end
locomotion policy that directly maps raw, spatio-temporal LiDAR point clouds to
motor commands, enabling robust navigation in cluttered dynamic scenes. We
formulate the control problem as a Constrained Markov Decision Process (CMDP)
to formally separate safety from task objectives. Our key contribution is a
novel methodology that translates the principles of Control Barrier Functions
(CBFs) into costs within the CMDP, allowing a model-free Penalized Proximal
Policy Optimization (P3O) to enforce safety constraints during training.
Furthermore, we introduce a set of comfort-oriented rewards, grounded in
human-robot interaction research, to promote motions that are smooth,
predictable, and less intrusive. We demonstrate the efficacy of our framework
through a successful sim-to-real transfer to a physical humanoid robot, which
exhibits agile and safe navigation around both static and dynamic 3D obstacles.

</details>


### [596] [Grasp-HGN: Grasping the Unexpected](https://arxiv.org/abs/2508.07648)
*Mehrshad Zandigohar,Mallesham Dasari,Gunar Schirner*

Main category: cs.RO

TL;DR: 研究通过Grasp-LLaVA和混合抓取网络(HGN)技术，显著提升了机器人假肢手在未知物体抓取任务上的准确率和效率，解决了当前技术的泛化性不足和速度瓶颈问题，为用户带来了更好的体验。


<details>
  <summary>Details</summary>
Motivation: 当前机器人假肢手在实际应用中存在鲁棒性和泛化性不足的问题，尤其是在处理数据集以外的、种类繁多的物体时，抓取模型的表现会急剧下降，影响用户独立性和生活质量。现有数据集的局限性（有限的物体交互数量）导致模型难以适应真实世界中几乎无限的物体多样性。

Method: 该研究首先定义了“语义投射”的概念，以量化模型泛化到新物体类型的能力。然后，提出了一种名为Grasp-LLaVA的视觉语言模型，用于基于物体的物理特性进行抓取类型推断。最后，设计了混合抓取网络(HGN)的基础设施，结合了边缘计算的低延迟和云计算的高准确性，并通过置信度校准（DC）实现了动态模型切换，以优化性能和延迟。

Result: Grasp-LLaVA在未见过的物体类型上实现了50.2%的准确率，显著高于现有技术的36.7%。混合抓取网络(HGN)结合置信度校准（DC）后，在未见过的物体类型上将语义投射准确率提升了5.6%（达到42.3%），同时实现了3.5倍的速度提升。在真实世界物体样本混合测试中，HGN达到了86%的平均准确率（比仅使用边缘模型高12.2%），并且推理速度是单独使用Grasp-LLaVA的2.2倍。

Conclusion: 该研究提出了Grasp-LLaVA和混合抓取网络(HGN)来解决机器人假肢手在现实世界应用中的泛化性和效率问题。Grasp-LLaVA通过引入类似人类的推理能力，在处理未见过物体类型时，准确率显著优于现有技术。HGN通过边缘-云协同部署，平衡了抓取估计的速度和准确性，实现了更快的推理速度和更高的准确率，特别是在处理多样化的真实世界物体时表现更佳。

Abstract: For transradial amputees, robotic prosthetic hands promise to regain the
capability to perform daily living activities. To advance next-generation
prosthetic hand control design, it is crucial to address current shortcomings
in robustness to out of lab artifacts, and generalizability to new
environments. Due to the fixed number of object to interact with in existing
datasets, contrasted with the virtually infinite variety of objects encountered
in the real world, current grasp models perform poorly on unseen objects,
negatively affecting users' independence and quality of life.
  To address this: (i) we define semantic projection, the ability of a model to
generalize to unseen object types and show that conventional models like YOLO,
despite 80% training accuracy, drop to 15% on unseen objects. (ii) we propose
Grasp-LLaVA, a Grasp Vision Language Model enabling human-like reasoning to
infer the suitable grasp type estimate based on the object's physical
characteristics resulting in a significant 50.2% accuracy over unseen object
types compared to 36.7% accuracy of an SOTA grasp estimation model.
  Lastly, to bridge the performance-latency gap, we propose Hybrid Grasp
Network (HGN), an edge-cloud deployment infrastructure enabling fast grasp
estimation on edge and accurate cloud inference as a fail-safe, effectively
expanding the latency vs. accuracy Pareto. HGN with confidence calibration (DC)
enables dynamic switching between edge and cloud models, improving semantic
projection accuracy by 5.6% (to 42.3%) with 3.5x speedup over the unseen object
types. Over a real-world sample mix, it reaches 86% average accuracy (12.2%
gain over edge-only), and 2.2x faster inference than Grasp-LLaVA alone.

</details>


### [597] [GraphCoT-VLA: A 3D Spatial-Aware Reasoning Vision-Language-Action Model for Robotic Manipulation with Ambiguous Instructions](https://arxiv.org/abs/2508.07650)
*Helong Huang,Min Cen,Kai Tan,Xingyue Quan,Guowei Huang,Hong Zhang*

Main category: cs.RO

TL;DR: 本研究提出了 GraphCoT-VLA 模型，通过结合思维链推理和 3D 空间图，显著提高了机器人处理模糊指令和未知环境的能力，并在真实机器人任务中取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作（VLA）模型在处理模糊语言指令和未知环境状态方面存在局限性。此外，它们的感知能力主要局限于静态的二维观察，缺乏对机器人与其环境之间三维交互建模的能力。

Method: 本文提出了 GraphCoT-VLA，一个高效的端到端模型。它包含一个结构化的思维链（Chain-of-Thought）推理模块，用于解释模糊指令和改进任务规划，该模块整合了高级任务理解、规划、失败任务反馈以及对未来物体位置和机器人动作的低级推理。此外，还构建了一个实时可更新的 3D 姿态-物体图，用于捕捉机器人关节的空间配置和物体在 3D 空间中的拓扑关系，从而更好地理解和操作它们之间的交互。模型还集成了 Dropout 混合推理策略以实现高效的控制输出。

Result: 实验结果表明，GraphCoT-VLA 在真实世界的机器人任务中，在任务成功率和响应速度方面显著优于现有方法，并在开放环境和不确定指令下展现出强大的泛化能力和鲁棒性。

Conclusion: GraphCoT-VLA 在真实世界的机器人任务中显著优于现有方法，在成功率和响应速度方面表现出色，并在开放环境和不确定指令下展现出强大的泛化能力和鲁棒性。

Abstract: Vision-language-action models have emerged as a crucial paradigm in robotic
manipulation. However, existing VLA models exhibit notable limitations in
handling ambiguous language instructions and unknown environmental states.
Furthermore, their perception is largely constrained to static two-dimensional
observations, lacking the capability to model three-dimensional interactions
between the robot and its environment. To address these challenges, this paper
proposes GraphCoT-VLA, an efficient end-to-end model. To enhance the model's
ability to interpret ambiguous instructions and improve task planning, we
design a structured Chain-of-Thought reasoning module that integrates
high-level task understanding and planning, failed task feedback, and low-level
imaginative reasoning about future object positions and robot actions.
Additionally, we construct a real-time updatable 3D Pose-Object graph, which
captures the spatial configuration of robot joints and the topological
relationships between objects in 3D space, enabling the model to better
understand and manipulate their interactions. We further integrates a dropout
hybrid reasoning strategy to achieve efficient control outputs. Experimental
results across multiple real-world robotic tasks demonstrate that GraphCoT-VLA
significantly outperforms existing methods in terms of task success rate and
response speed, exhibiting strong generalization and robustness in open
environments and under uncertain instructions.

</details>


### [598] [MoRoCo: Multi-operator-robot Coordination, Interaction and Exploration under Restricted Communication](https://arxiv.org/abs/2508.07657)
*Zhuoli Tian,Yuyang Zhang,Jinsheng Wei,Meng Guo*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Fleets of autonomous robots are increasingly deployed alongside multiple
human operators to explore unknown environments, identify salient features, and
perform complex tasks in scenarios such as subterranean exploration,
reconnaissance, and search-and-rescue missions. In these contexts,
communication is often severely limited to short-range exchanges via ad-hoc
networks, posing challenges to coordination. While recent studies have
addressed multi-robot exploration under communication constraints, they largely
overlook the essential role of human operators and their real-time interaction
with robotic teams. Operators may demand timely updates on the exploration
progress and robot status, reprioritize or cancel tasks dynamically, or request
live video feeds and control access. Conversely, robots may seek human
confirmation for anomalous events or require help recovering from motion or
planning failures. To enable such bilateral, context-aware interactions under
restricted communication, this work proposes MoRoCo, a unified framework for
online coordination and exploration in multi-operator, multi-robot systems.
MoRoCo enables the team to adaptively switch among three coordination modes:
spread mode for parallelized exploration with intermittent data sharing,
migrate mode for coordinated relocation, and chain mode for maintaining
high-bandwidth connectivity through multi-hop links. These transitions are
managed through distributed algorithms via only local communication. Extensive
large-scale human-in-the-loop simulations and hardware experiments validate the
necessity of incorporating human robot interactions and demonstrate that MoRoCo
enables efficient, reliable coordination under limited communication, marking a
significant step toward robust human-in-the-loop multi-robot autonomy in
challenging environments.

</details>


### [599] [Risk Map As Middleware: Towards Interpretable Cooperative End-to-end Autonomous Driving for Risk-Aware Planning](https://arxiv.org/abs/2508.07686)
*Mingyue Lei,Zewei Zhou,Hongchen Li,Jiaqi Ma,Jia Hu*

Main category: cs.RO

TL;DR: 提出了一种名为RiskMM的可解释协同端到端驾驶框架，使用风险地图中间件，通过Transformer和MPC解决了传统方法的局限性，提升了安全性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶方法存在被遮挡和感知范围有限的问题，导致驾驶危险，且其黑盒性质阻碍了驾驶行为的可解释性，降低了系统的可信度。

Method: 首先，通过统一的Transformer基础架构构建多智能体时空表示；其次，通过对周围环境的交互进行建模，并利用注意力机制，导出风险感知表示；最后，将这些表示输入到基于学习的MPC（模型预测控制）模块中进行规划。

Result: 在真实世界的V2XPnP-Seq数据集上进行了评估，RiskMM在风险感知轨迹规划方面取得了优越且鲁棒的性能，显著增强了协同端到端驾驶框架的可解释性。

Conclusion: RiskMM通过引入风险地图作为中间件，提出了一种可解释的多智能体协同端到端驾驶框架，有效解决了现有方法的局限性。通过Transformer和注意力机制学习时空表示和风险感知表示，并结合MPC规划器，实现了优越且鲁棒的风险感知轨迹规划，显著提升了协同端到端驾驶框架的可解释性。

Abstract: End-to-end paradigm has emerged as a promising approach to autonomous
driving. However, existing single-agent end-to-end pipelines are often
constrained by occlusion and limited perception range, resulting in hazardous
driving. Furthermore, their black-box nature prevents the interpretability of
the driving behavior, leading to an untrustworthiness system. To address these
limitations, we introduce Risk Map as Middleware (RiskMM) and propose an
interpretable cooperative end-to-end driving framework. The risk map learns
directly from the driving data and provides an interpretable spatiotemporal
representation of the scenario from the upstream perception and the
interactions between the ego vehicle and the surrounding environment for
downstream planning. RiskMM first constructs a multi-agent spatiotemporal
representation with unified Transformer-based architecture, then derives
risk-aware representations by modeling interactions among surrounding
environments with attention. These representations are subsequently fed into a
learning-based Model Predictive Control (MPC) module. The MPC planner
inherently accommodates physical constraints and different vehicle types and
can provide interpretation by aligning learned parameters with explicit MPC
elements. Evaluations conducted on the real-world V2XPnP-Seq dataset confirm
that RiskMM achieves superior and robust performance in risk-aware trajectory
planning, significantly enhancing the interpretability of the cooperative
end-to-end driving framework. The codebase will be released to facilitate
future research in this field.

</details>


### [600] [LAURON VI: A Six-Legged Robot for Dynamic Walking](https://arxiv.org/abs/2508.07689)
*Christian Eichmann,Sabine Bellmann,Nicolas Hügel,Louis-Elias Enslin,Carsten Plasberg,Georg Heppner,Arne Roennau,Ruediger Dillmann*

Main category: cs.RO

TL;DR: 本文介绍了 LAURON VI 六足机器人平台，通过开发 fast locomotion strategies，解决了六足机器人在平坦地形上速度慢的问题，提高了其在各种现实场景中的适用性。


<details>
  <summary>Details</summary>
Motivation: 六足机器人虽然在崎岖地形上具有优势，但在平坦地形上的行走速度较慢，限制了其应用。为了克服这一限制，需要开发更快的行走策略。

Method: 本文设计、实现并比较了三种控制方法：基于运动学、模型预测和强化学习的控制器。机器人硬件和不同控制方法在实验室环境和火星模拟任务中都经过了广泛测试。

Result: 通过引入 fast locomotion strategies，LAURON VI 平台能够实现更快的行走速度，提高了六足机器人在不同地形下的适用性。

Conclusion:  LAURON VI 平台的开发和 fast locomotion strategies 的引入，使得六足机器人能够适应更广泛的现实世界应用场景。

Abstract: Legged locomotion enables robotic systems to traverse extremely challenging
terrains. In many real-world scenarios, the terrain is not that difficult and
these mixed terrain types introduce the need for flexible use of different
walking strategies to achieve mission goals in a fast, reliable, and
energy-efficient way. Six-legged robots have a high degree of flexibility and
inherent stability that aids them in traversing even some of the most difficult
terrains, such as collapsed buildings. However, their lack of fast walking
gaits for easier surfaces is one reason why they are not commonly applied in
these scenarios.
  This work presents LAURON VI, a six-legged robot platform for research on
dynamic walking gaits as well as on autonomy for complex field missions. The
robot's 18 series elastic joint actuators offer high-frequency interfaces for
Cartesian impedance and pure torque control. We have designed, implemented, and
compared three control approaches: kinematic-based, model-predictive, and
reinforcement-learned controllers. The robot hardware and the different control
approaches were extensively tested in a lab environment as well as on a Mars
analog mission. The introduction of fast locomotion strategies for LAURON VI
makes six-legged robots vastly more suitable for a wide range of real-world
applications.

</details>


### [601] [Robot and Overhead Crane Collaboration Scheme to Enhance Payload Manipulation](https://arxiv.org/abs/2508.07758)
*Antonio Rosales,Alaa Abderrahim,Markku Suomalainen,Mikael Haag,Tapio Heikkilä*

Main category: cs.RO

TL;DR: 本文提出了一种机器人与起重机协同操纵重物的方案，以解决手动精细调控重物带来的风险和劳动强度。该方案利用机器人引导，起重机跟随，通过交互力实现两者协调，并设计了顺从控制器以确保平稳操作。仿真和实验结果证明了该方案的可行性。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前工业实践中，起重机有效载荷的精细操纵和精确定位任务劳动强度大且风险高的问题，因为操作员需要手动引导有效载荷的精细运动。

Method: 提出了一种协作方案，其中起重机起吊有效载荷，机器人的末端执行器将其引导至目标位置。机器人和起重机之间的唯一联系是通过引导有效载荷产生的交互力。考虑了两种顺从传递函数来实现无害、平稳的接触：一种用于基于位置的顺从控制（集成在机器人中）；另一种通过顺从传递函数处理交互力，生成起重机的速度指令，使起重机能够跟随有效载荷。最后，提出了一种设计顺从控制器的方法，以实现机器人-起重机之间的流畅协作。

Result: 通过仿真和实验验证了所提出方案的潜力，该方案能够实现机器人和起重机的协同工作，从而引导有效载荷到达目标位置。

Conclusion: 该方案通过机器人与起重机协同工作，增强了有效载荷的操纵能力，并通过仿真和实验验证了其潜力。

Abstract: This paper presents a scheme to enhance payload manipulation using a robot
collaborating with an overhead crane. In the current industrial practice, when
the crane's payload has to be accurately manipulated and located in a desired
position, the task becomes laborious and risky since the operators have to
guide the fine motions of the payload by hand. In the proposed collaborative
scheme, the crane lifts the payload while the robot's end-effector guides it
toward the desired position. The only link between the robot and the crane is
the interaction force produced during the guiding of the payload. Two
admittance transfer functions are considered to accomplish harmless and smooth
contact with the payload. The first is used in a position-based admittance
control integrated with the robot. The second one adds compliance to the crane
by processing the interaction force through the admittance transfer function to
generate a crane's velocity command that makes the crane follow the payload.
Then the robot's end-effector and the crane move collaboratively to guide the
payload to the desired location. A method is presented to design the admittance
controllers that accomplish a fluent robot-crane collaboration. Simulations and
experiments validating the scheme potential are shown.

</details>


### [602] [AgentWorld: An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation](https://arxiv.org/abs/2508.07770)
*Yizheng Zhang,Zhenjun Yu,Jiaxin Lai,Cewu Lu,Lei Han*

Main category: cs.RO

TL;DR: AgentWorld 是一个交互式模拟平台，用于开发家庭移动操作能力，并附带一个捕获各种家庭任务的数据集，可通过行为克隆、动作分块转换器、扩散策略和视觉-语言-动作模型进行基准测试，以实现模拟到现实的迁移。


<details>
  <summary>Details</summary>
Motivation: 为了在家庭环境中开发移动操作能力。

Method: 该平台结合了自动场景构建（包括布局生成、语义资产放置、视觉材料配置和物理模拟）以及支持轮式底盘和人形运动策略的双模式遥操作系统，用于数据收集。

Result: AgentWorld 数据集捕获了从基本动作（抓取和放置、推拉等）到多阶段活动（服务饮料、加热食物等）的各种任务，涵盖客厅、卧室和厨房。通过对行为克隆、动作分块转换器、扩散策略和视觉-语言-动作模型等模仿学习方法的广泛基准测试，证明了该数据集在模拟到现实迁移方面的有效性。

Conclusion: 该系统为在复杂家庭环境中扩展机器人技能获取提供了全面的解决方案，弥合了基于仿真的训练与实际部署之间的差距。

Abstract: We introduce AgentWorld, an interactive simulation platform for developing
household mobile manipulation capabilities. Our platform combines automated
scene construction that encompasses layout generation, semantic asset
placement, visual material configuration, and physics simulation, with a
dual-mode teleoperation system supporting both wheeled bases and humanoid
locomotion policies for data collection. The resulting AgentWorld Dataset
captures diverse tasks ranging from primitive actions (pick-and-place,
push-pull, etc.) to multistage activities (serve drinks, heat up food, etc.)
across living rooms, bedrooms, and kitchens. Through extensive benchmarking of
imitation learning methods including behavior cloning, action chunking
transformers, diffusion policies, and vision-language-action models, we
demonstrate the dataset's effectiveness for sim-to-real transfer. The
integrated system provides a comprehensive solution for scalable robotic skill
acquisition in complex home environments, bridging the gap between
simulation-based training and real-world deployment. The code, datasets will be
available at https://yizhengzhang1.github.io/agent_world/

</details>


### [603] [SwarmVLM: VLM-Guided Impedance Control for Autonomous Navigation of Heterogeneous Robots in Dynamic Warehousing](https://arxiv.org/abs/2508.07814)
*Malaika Zafar,Roohan Ahmed Khan,Faryal Batool,Yasheerah Yaqoot,Ziang Guo,Mikhail Litvinov,Aleksey Fedoseev,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: SwarmVLM系统通过VLM和RAG技术，利用UAV和地面机器人的协同，解决了UAV的续航和负载限制，成功实现了高效、安全的物流配送。系统在真实环境中表现出高成功率和避障能力。


<details>
  <summary>Details</summary>
Motivation: 随着对高效物流需求的增长，无人机（UAV）越来越多地与自动导引车（AGV）配对。无人机虽然能够穿越密集环境和不同高度，但其电池寿命、负载能力和飞行时间有限，需要地面支援。SwarmVLM旨在通过阻抗控制实现UAV和地面机器人之间的语义协作，以解决这些限制。

Method: 该系统利用视觉语言模型（VLM）和检索增强生成（RAG）来响应环境变化，从而调整阻抗控制参数。在该框架中，UAV使用人工势场（APF）规划进行实时导航，而地面机器人则通过具有自适应连接拓扑的虚拟阻抗链接进行跟随，以避免与短障碍物发生碰撞。

Result: 该系统在12次真实世界试验中成功率达到了92%。在最佳光照条件下，VLM-RAG框架在物体检测和阻抗参数选择方面达到了8%的准确率。移动机器人优先避开短障碍物，有时会导致与UAV路径产生高达50厘米的横向偏差，这展示了在混乱环境中安全导航的能力。

Conclusion: 该系统在12次真实世界试验中成功率达到了92%，在最佳光照条件下，VLM-RAG框架在物体检测和阻抗参数选择方面达到了8%的准确率。移动机器人优先避开短障碍物，有时会导致与UAV路径产生高达50厘米的横向偏差，这展示了在混乱环境中安全导航的能力。

Abstract: With the growing demand for efficient logistics, unmanned aerial vehicles
(UAVs) are increasingly being paired with automated guided vehicles (AGVs).
While UAVs offer the ability to navigate through dense environments and varying
altitudes, they are limited by battery life, payload capacity, and flight
duration, necessitating coordinated ground support.
  Focusing on heterogeneous navigation, SwarmVLM addresses these limitations by
enabling semantic collaboration between UAVs and ground robots through
impedance control. The system leverages the Vision Language Model (VLM) and the
Retrieval-Augmented Generation (RAG) to adjust impedance control parameters in
response to environmental changes. In this framework, the UAV acts as a leader
using Artificial Potential Field (APF) planning for real-time navigation, while
the ground robot follows via virtual impedance links with adaptive link
topology to avoid collisions with short obstacles.
  The system demonstrated a 92% success rate across 12 real-world trials. Under
optimal lighting conditions, the VLM-RAG framework achieved 8% accuracy in
object detection and selection of impedance parameters. The mobile robot
prioritized short obstacle avoidance, occasionally resulting in a lateral
deviation of up to 50 cm from the UAV path, which showcases safe navigation in
a cluttered setting.

</details>


### [604] [Touch Speaks, Sound Feels: A Multimodal Approach to Affective and Social Touch from Robots to Humans](https://arxiv.org/abs/2508.07839)
*Qiaoqiao Ren,Tony Belpaeme*

Main category: cs.RO

TL;DR: 触觉和声音的结合比单独使用任何一种都能更好地传达情感和社交手势。单独的手势不足以传达情感。


<details>
  <summary>Details</summary>
Motivation: 现有机器人通过面部表情和语音传达情感的研究较多，但通过触觉传达社交手势和情感的能力却未得到充分探索。

Method: 开发了一个包含25个振动马达的5*5网格的多模态交互系统，并同步音频播放，使机器人能够传递触觉-音频组合刺激。

Result: 1. 触觉-音频组合模态显著提高了解码准确性；2. 单独的触觉或听觉通道均能有效支持某些情绪的识别；3. 手势本身不足以传达清晰可辨的情感。

Conclusion: 研究结果强调了多感官整合在情感人机交互中的重要性，并突出了触觉和听觉线索在增强情感交流方面的互补作用。

Abstract: Affective tactile interaction constitutes a fundamental component of human
communication. In natural human-human encounters, touch is seldom experienced
in isolation; rather, it is inherently multisensory. Individuals not only
perceive the physical sensation of touch but also register the accompanying
auditory cues generated through contact. The integration of haptic and auditory
information forms a rich and nuanced channel for emotional expression. While
extensive research has examined how robots convey emotions through facial
expressions and speech, their capacity to communicate social gestures and
emotions via touch remains largely underexplored. To address this gap, we
developed a multimodal interaction system incorporating a 5*5 grid of 25
vibration motors synchronized with audio playback, enabling robots to deliver
combined haptic-audio stimuli. In an experiment involving 32 Chinese
participants, ten emotions and six social gestures were presented through
vibration, sound, or their combination. Participants rated each stimulus on
arousal and valence scales. The results revealed that (1) the combined
haptic-audio modality significantly enhanced decoding accuracy compared to
single modalities; (2) each individual channel-vibration or sound-effectively
supported certain emotions recognition, with distinct advantages depending on
the emotional expression; and (3) gestures alone were generally insufficient
for conveying clearly distinguishable emotions. These findings underscore the
importance of multisensory integration in affective human-robot interaction and
highlight the complementary roles of haptic and auditory cues in enhancing
emotional communication.

</details>


### [605] [DETACH: Cross-domain Learning for Long-Horizon Tasks via Mixture of Disentangled Experts](https://arxiv.org/abs/2508.07842)
*Yutong Shen,Hangxu Liu,Penghui Liu,Ruizhe Xia,Tianyi Yao,Yitong Sun,Tongtong Feng*

Main category: cs.RO

TL;DR: DETACH框架通过双流解耦技术，解决了长时任务中的泛化和跨领域执行问题，显著提升了成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖技能链接，难以泛化到新的环境和技能组合，无法完成跨领域的长时任务

Method: DETACH框架包含两个核心模块：环境学习模块（空间理解）和技能学习模块（任务执行），通过环境-自我和动作模式的解耦，实现跨领域和跨技能的迁移

Result: DETACH框架在跨领域长时任务中取得了显著的性能提升，子任务成功率和执行效率平均分别提高了23%和29%

Conclusion: DETACH框架通过生物启发的双流解耦，实现了跨领域长时任务的学习，相比现有方法在子任务成功率和执行效率上分别提高了23%和29%

Abstract: Long-Horizon (LH) tasks in Human-Scene Interaction (HSI) are complex
multi-step tasks that require continuous planning, sequential decision-making,
and extended execution across domains to achieve the final goal. However,
existing methods heavily rely on skill chaining by concatenating pre-trained
subtasks, with environment observations and self-state tightly coupled, lacking
the ability to generalize to new combinations of environments and skills,
failing to complete various LH tasks across domains. To solve this problem,
this paper presents DETACH, a cross-domain learning framework for LH tasks via
biologically inspired dual-stream disentanglement. Inspired by the brain's
"where-what" dual pathway mechanism, DETACH comprises two core modules: i) an
environment learning module for spatial understanding, which captures object
functions, spatial relationships, and scene semantics, achieving cross-domain
transfer through complete environment-self disentanglement; ii) a skill
learning module for task execution, which processes self-state information
including joint degrees of freedom and motor patterns, enabling cross-skill
transfer through independent motor pattern encoding. We conducted extensive
experiments on various LH tasks in HSI scenes. Compared with existing methods,
DETACH can achieve an average subtasks success rate improvement of 23% and
average execution efficiency improvement of 29%.

</details>


### [606] [MolmoAct: Action Reasoning Models that can Reason in Space](https://arxiv.org/abs/2508.07917)
*Jason Lee,Jiafei Duan,Haoquan Fang,Yuquan Deng,Shuo Liu,Boyang Li,Bohan Fang,Jieyu Zhang,Yi Ru Wang,Sangho Lee,Winson Han,Wilbert Pumacay,Angelica Wu,Rose Hendrix,Karen Farley,Eli VanderBilt,Ali Farhadi,Dieter Fox,Ranjay Krishna*

Main category: cs.RO

TL;DR: 介绍了一种名为 MolmoAct 的新型机器人基础模型，它通过集成感知、规划和控制来改进机器人行为。该模型在多项基准测试和真实世界场景中表现出色，并发布了相关数据集和代码，以推动机器人领域的发展。


<details>
  <summary>Details</summary>
Motivation: 当前的机器人基础模型大多将感知和指令直接映射到控制，这限制了机器人的适应性、泛化能力和语义基础。为了解决这个问题，提出了一种新的模型类别——行动推理模型（ARMs），以实现更强的机器人能力。

Method: 通过三阶段的结构化流程，将感知、规划和控制集成到行动推理模型（ARMs）中。具体而言，模型将观察和指令编码为深度感知的感知令牌，生成可编辑的轨迹追踪作为中级空间规划，并预测精确的低级动作。

Result: MolmoAct-7B-D 在各项测试中均取得了优异的成绩：在 SimplerEnv 可视匹配任务中实现了 70.5% 的零样本准确率，优于 Pi-0 和 GR00T N1；在 LIBERO 数据集上平均成功率为 86.6%，在长时任务上比 ThinkAct 提高了 6.3%；在真实世界微调中，比 Pi-0-FAST 单臂和双臂任务分别提高了 10% 和 22.7%；在分布外泛化任务上比基线模型提高了 23.3%；并在开放式指令遵循和轨迹引导方面获得了高人类偏好评分。此外，新发布的 MolmoAct 数据集（包含超过 10,000 个高质量机器人轨迹）可将模型性能平均提高 5.5%。

Conclusion: MolmoAct 是一个先进的机器人基础模型，通过集成的感知、规划和控制，实现了可解释、可控的行为，并在模拟和现实世界任务中展现出卓越的性能和泛化能力。该模型以及 MolmoAct 数据集的发布，为机器人领域的研究和发展提供了开放的蓝图。

Abstract: Reasoning is central to purposeful action, yet most robotic foundation models
map perception and instructions directly to control, which limits adaptability,
generalization, and semantic grounding. We introduce Action Reasoning Models
(ARMs), a class of vision-language-action models that integrate perception,
planning, and control through a structured three-stage pipeline. Our model,
MolmoAct, encodes observations and instructions into depth-aware perception
tokens, generates mid-level spatial plans as editable trajectory traces, and
predicts precise low-level actions, enabling explainable and steerable
behavior. MolmoAct-7B-D achieves strong performance across simulation and
real-world settings: 70.5% zero-shot accuracy on SimplerEnv Visual Matching
tasks, surpassing closed-source Pi-0 and GR00T N1; 86.6% average success on
LIBERO, including an additional 6.3% gain over ThinkAct on long-horizon tasks;
and in real-world fine-tuning, an additional 10% (single-arm) and an additional
22.7% (bimanual) task progression over Pi-0-FAST. It also outperforms baselines
by an additional 23.3% on out-of-distribution generalization and achieves top
human-preference scores for open-ended instruction following and trajectory
steering. Furthermore, we release, for the first time, the MolmoAct Dataset --
a mid-training robot dataset comprising over 10,000 high quality robot
trajectories across diverse scenarios and tasks. Training with this dataset
yields an average 5.5% improvement in general performance over the base model.
We release all model weights, training code, our collected dataset, and our
action reasoning dataset, establishing MolmoAct as both a state-of-the-art
robotics foundation model and an open blueprint for building ARMs that
transform perception into purposeful action through structured reasoning.
Blogpost: https://allenai.org/blog/molmoact

</details>


### [607] [PCHands: PCA-based Hand Pose Synergy Representation on Manipulators with N-DoF](https://arxiv.org/abs/2508.07945)
*En Yen Puang,Federico Ceola,Giulia Pasquale,Lorenzo Natale*

Main category: cs.RO

TL;DR: PCHands是一种用于灵巧操控的新方法，通过学习操纵器姿势的通用表征，提高了强化学习和模仿学习的效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决在不同形态操纵器之间学习通用表征以实现灵巧操控的问题。

Method: 提出了一种名为PCHands的新方法，通过基于锚点位置的简化统一描述格式，为不同形态的操纵器（从两指夹爪到五指拟人手）提取手部姿势协同，并学习变量长度的潜在表征。

Result: PCHands能够提取出在不同结构和自由度的操纵器之间通用的主成分，并成功应用于强化学习和模仿学习任务中，表现出优于基线方法的学习效率、一致性和鲁棒性。

Conclusion: PCHands方法在不同形态的操纵器之间学习通用表征，并在学习效率、一致性和跨操纵器鲁棒性方面优于基线方法。

Abstract: We consider the problem of learning a common representation for dexterous
manipulation across manipulators of different morphologies. To this end, we
propose PCHands, a novel approach for extracting hand postural synergies from a
large set of manipulators. We define a simplified and unified description
format based on anchor positions for manipulators ranging from 2-finger
grippers to 5-finger anthropomorphic hands. This enables learning a
variable-length latent representation of the manipulator configuration and the
alignment of the end-effector frame of all manipulators. We show that it is
possible to extract principal components from this latent representation that
is universal across manipulators of different structures and degrees of
freedom. To evaluate PCHands, we use this compact representation to encode
observation and action spaces of control policies for dexterous manipulation
tasks learned with RL. In terms of learning efficiency and consistency, the
proposed representation outperforms a baseline that learns the same tasks in
joint space. We additionally show that PCHands performs robustly in RL from
demonstration, when demonstrations are provided from a different manipulator.
We further support our results with real-world experiments that involve a
2-finger gripper and a 4-finger anthropomorphic hand. Code and additional
material are available at https://hsp-iit.github.io/PCHands/.

</details>


### [608] [Aerial Target Encirclement and Interception with Noisy Range Observations](https://arxiv.org/abs/2508.08046)
*Fen Liu,Shenghai Yuan,Thien-Minh Nguyen,Wei Meng,Lihua Xie*

Main category: cs.RO

TL;DR: 本研究提出了一种通过反同步和反目标控制器实现无人机包围、拦截和中和非合作空中移动目标的策略，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 提出一种策略来包围和拦截非合作的空中点质量移动目标。

Method: 利用噪声距离测量进行状态估计，并采用反同步（AS）、3D“振动弦”轨迹和反目标控制器。

Result: 证明了状态估计误差的指数有界稳定性和包围误差的收敛性，并通过仿真和真实无人机实验进行了验证。

Conclusion: 通过使用反同步（AS）、3D“振动弦”轨迹和反目标控制器，成功实现了对非合作空中点质量移动目标的包围、拦截和中和。

Abstract: This paper proposes a strategy to encircle and intercept a non-cooperative
aerial point-mass moving target by leveraging noisy range measurements for
state estimation. In this approach, the guardians actively ensure the
observability of the target by using an anti-synchronization (AS), 3D
``vibrating string" trajectory, which enables rapid position and velocity
estimation based on the Kalman filter. Additionally, a novel anti-target
controller is designed for the guardians to enable adaptive transitions from
encircling a protected target to encircling, intercepting, and neutralizing a
hostile target, taking into consideration the input constraints of the
guardians. Based on the guaranteed uniform observability, the exponentially
bounded stability of the state estimation error and the convergence of the
encirclement error are rigorously analyzed. Simulation results and real-world
UAV experiments are presented to further validate the effectiveness of the
system design.

</details>


### [609] [Capsizing-Guided Trajectory Optimization for Autonomous Navigation with Rough Terrain](https://arxiv.org/abs/2508.08108)
*Wei Zhang,Yinchuan Wang,Wangtao Lu,Pengyu Zhang,Xiang Zhang,Yue Wang,Chaoqun Wang*

Main category: cs.RO

TL;DR: A new trajectory planner (CAP) enhances robot navigation on uneven terrain by considering tip-over stability and incorporating it as a safety constraint, outperforming previous methods in simulations and real-world tests.


<details>
  <summary>Details</summary>
Motivation: Autonomous navigation in harsh environments with non-trivial obstacles and uneven terrain is challenging for ground robots, requiring trajectory planning that balances safety and efficiency. The primary challenge is generating a feasible trajectory that prevents robot tip-over while ensuring effective navigation.

Method: The paper proposes a capsizing-aware trajectory planner (CAP). It analyzes the tip-over stability of the robot on rough terrain, defines traversable orientation based on this stability, and incorporates this orientation into a capsizing-safety constraint for trajectory optimization. A graph-based solver is employed to compute the trajectory.

Result: Extensive simulation and real-world experiments validate the effectiveness and robustness of the CAP method. The results demonstrate enhanced navigation performance on uneven terrains compared to existing approaches.

Conclusion: CAP outperforms existing state-of-the-art approaches, providing enhanced navigation performance on uneven terrains.

Abstract: It is a challenging task for ground robots to autonomously navigate in harsh
environments due to the presence of non-trivial obstacles and uneven terrain.
This requires trajectory planning that balances safety and efficiency. The
primary challenge is to generate a feasible trajectory that prevents robot from
tip-over while ensuring effective navigation. In this paper, we propose a
capsizing-aware trajectory planner (CAP) to achieve trajectory planning on the
uneven terrain. The tip-over stability of the robot on rough terrain is
analyzed. Based on the tip-over stability, we define the traversable
orientation, which indicates the safe range of robot orientations. This
orientation is then incorporated into a capsizing-safety constraint for
trajectory optimization. We employ a graph-based solver to compute a robust and
feasible trajectory while adhering to the capsizing-safety constraint.
Extensive simulation and real-world experiments validate the effectiveness and
robustness of the proposed method. The results demonstrate that CAP outperforms
existing state-of-the-art approaches, providing enhanced navigation performance
on uneven terrains.

</details>


### [610] [AimBot: A Simple Auxiliary Visual Cue to Enhance Spatial Awareness of Visuomotor Policies](https://arxiv.org/abs/2508.08113)
*Yinpei Dai,Jayjun Lee,Yichi Zhang,Ziqiao Ma,Jed Yang,Amir Zadeh,Chuan Li,Nima Fazeli,Joyce Chai*

Main category: cs.RO

TL;DR: AimBot 是一种视觉增强技术，通过添加瞄准线和准星等空间线索来帮助机器人学习操作，从而提高性能，并且计算开销很小。


<details>
  <summary>Details</summary>
Motivation: AimBot 旨在通过提供明确的空间线索来改进机器人操作中的视觉神经策略学习，以增强空间接地视觉反馈。

Method: AimBot 在多视图 RGB 图像上叠加了瞄准线和准星，以提供编码末端执行器状态的辅助视觉指导。这些叠加层是通过深度图像、相机外接和当前的末端执行器姿势计算出来的，明确传达了抓手和场景中物体之间的空间关系。AimBot 的计算开销极小（不到 1 毫秒），并且不需要更改模型架构，因为它只是用增强后的对应物替换原始 RGB 图像。

Result: AimBot 持续提高了各种视觉神经策略在模拟和现实世界中的性能，证明了空间接地视觉反馈的好处。

Conclusion: AimBot 是一种简单但有效的视觉增强技术，可以通过提供明确的空间线索来改进机器人操作中的视觉神经策略学习。它在模拟和现实世界中都提高了各种视觉神经策略的性能，证明了空间接地视觉反馈的好处。

Abstract: In this paper, we propose AimBot, a lightweight visual augmentation technique
that provides explicit spatial cues to improve visuomotor policy learning in
robotic manipulation. AimBot overlays shooting lines and scope reticles onto
multi-view RGB images, offering auxiliary visual guidance that encodes the
end-effector's state. The overlays are computed from depth images, camera
extrinsics, and the current end-effector pose, explicitly conveying spatial
relationships between the gripper and objects in the scene. AimBot incurs
minimal computational overhead (less than 1 ms) and requires no changes to
model architectures, as it simply replaces original RGB images with augmented
counterparts. Despite its simplicity, our results show that AimBot consistently
improves the performance of various visuomotor policies in both simulation and
real-world settings, highlighting the benefits of spatially grounded visual
feedback.

</details>


### [611] [Verti-Arena: A Controllable and Standardized Indoor Testbed for Multi-Terrain Off-Road Autonomy](https://arxiv.org/abs/2508.08226)
*Haiyue Chen,Aniket Datar,Tong Xu,Francesco Cancelliere,Harsh Rangwala,Madhan Balaji Rao,Daeun Song,David Eichinger,Xuesu Xiao*

Main category: cs.RO

TL;DR: Verti-Arena是一个用于越野机器人导航的可重构室内测试设施，用于数据收集和算法验证。


<details>
  <summary>Details</summary>
Motivation: 越野导航对移动机器人很重要，但缺乏可控和标准化的真实世界测试平台来收集数据和验证。为了解决这个问题，我们引入了Verti-Arena。

Method: 介绍了Verti-Arena，一个可重构的室内设施，用于越野自主导航的系统化数据收集和验证。

Result: Verti-Arena是一个可重构的室内设施，用于越野自主导航的测试和数据收集。

Conclusion: Verti-Arena通过提供一个可重复的基准环境，支持在各种垂直挑战地形上进行可重复的实验，并通过车载传感器和运动捕捉系统提供精确的地面真实测量。Verti-Arena还支持跨研究组的标准化数据收集和算法的比较评估，并通过基于Web的接口实现了全球远程实验。

Abstract: Off-road navigation is an important capability for mobile robots deployed in
environments that are inaccessible or dangerous to humans, such as disaster
response or planetary exploration. Progress is limited due to the lack of a
controllable and standardized real-world testbed for systematic data collection
and validation. To fill this gap, we introduce Verti-Arena, a reconfigurable
indoor facility designed specifically for off-road autonomy. By providing a
repeatable benchmark environment, Verti-Arena supports reproducible experiments
across a variety of vertically challenging terrains and provides precise ground
truth measurements through onboard sensors and a motion capture system.
Verti-Arena also supports consistent data collection and comparative evaluation
of algorithms in off-road autonomy research. We also develop a web-based
interface that enables research groups worldwide to remotely conduct
standardized off-road autonomy experiments on Verti-Arena.

</details>


### [612] [ODYSSEY: Open-World Quadrupeds Exploration and Manipulation for Long-Horizon Tasks](https://arxiv.org/abs/2508.08240)
*Kaijun Wang,Liqin Lu,Mingyu Liu,Jianuo Jiang,Zeju Li,Bolin Zhang,Wancai Zheng,Xinyi Yu,Hao Chen,Chunhua Shen*

Main category: cs.RO

TL;DR: ODYSSEY框架解决了四足机器人进行语言引导的长期移动操作的挑战，通过结合视觉-语言模型和全身控制，实现了在非结构化环境中的鲁棒性和泛化能力，并在真实世界中得到了验证。


<details>
  <summary>Details</summary>
Motivation: 现有研究在移动操作方面存在局限性：1. 大型语言模型在空间推理和任务规划方面虽有改进，但仅限于桌面场景，未能解决移动平台的感知约束和驱动范围限制。2. 当前的操作策略在开放世界环境中面对多样化的物体配置时，泛化能力不足。3. 在非结构化环境中，同时保持高平台机动性和精确的末端执行器控制这一关键的双重需求研究不足。

Method: ODYSSEY是一个统一的移动操作框架，专为配备机械臂的敏捷四足机器人设计。该框架集成了由视觉-语言模型驱动的分层规划器，用于长距离指令分解和精确动作执行，以及一种新的全身控制策略，用于在复杂地形中实现鲁棒的协调。此外，还建立了一个用于评估长期移动操作的基准测试。

Result: ODYSSEY框架通过成功的sim-to-real迁移，在真实世界的部署中展示了系统的泛化能力和鲁棒性，证明了在非结构化环境中，带机械臂的腿式机器人的实用性。

Conclusion: ODYSSEY框架通过将高级任务规划与低级全身控制相结合，解决了语言引导的长期移动操作的挑战，并成功进行了真实世界部署，展示了其在非结构化环境中的通用性和鲁棒性，推动了通用机器人助手的可行性。

Abstract: Language-guided long-horizon mobile manipulation has long been a grand
challenge in embodied semantic reasoning, generalizable manipulation, and
adaptive locomotion. Three fundamental limitations hinder progress: First,
although large language models have improved spatial reasoning and task
planning through semantic priors, existing implementations remain confined to
tabletop scenarios, failing to address the constrained perception and limited
actuation ranges of mobile platforms. Second, current manipulation strategies
exhibit insufficient generalization when confronted with the diverse object
configurations encountered in open-world environments. Third, while crucial for
practical deployment, the dual requirement of maintaining high platform
maneuverability alongside precise end-effector control in unstructured settings
remains understudied.
  In this work, we present ODYSSEY, a unified mobile manipulation framework for
agile quadruped robots equipped with manipulators, which seamlessly integrates
high-level task planning with low-level whole-body control. To address the
challenge of egocentric perception in language-conditioned tasks, we introduce
a hierarchical planner powered by a vision-language model, enabling
long-horizon instruction decomposition and precise action execution. At the
control level, our novel whole-body policy achieves robust coordination across
challenging terrains. We further present the first benchmark for long-horizon
mobile manipulation, evaluating diverse indoor and outdoor scenarios. Through
successful sim-to-real transfer, we demonstrate the system's generalization and
robustness in real-world deployments, underscoring the practicality of legged
manipulators in unstructured environments. Our work advances the feasibility of
generalized robotic assistants capable of complex, dynamic tasks. Our project
page: https://kaijwang.github.io/odyssey.github.io/

</details>


### [613] [BeyondMimic: From Motion Tracking to Versatile Humanoid Control via Guided Diffusion](https://arxiv.org/abs/2508.08241)
*Takara E. Truong,Qiayuan Liao,Xiaoyu Huang,Guy Tevet,C. Karen Liu,Koushil Sreenath*

Main category: cs.RO

TL;DR: BeyondMimic is a novel framework for humanoid robots that learns complex skills from human motion using guided diffusion. It excels at tracking dynamic movements and synthesizing new motions, enabling robots to perform tasks like navigation and obstacle avoidance without prior task-specific training.


<details>
  <summary>Details</summary>
Motivation: Learning skills from human motions for generalizable policies in whole-body humanoid control. Key challenges include a high-quality motion tracking framework for dynamic motions and a distillation approach for learning and composing motion primitives.

Method: BeyondMimic framework utilizes guided diffusion for learning human motion primitives. It includes a motion tracking pipeline for dynamic motions and a unified diffusion policy for zero-shot task-specific control.

Result: State-of-the-art motion quality for challenging skills like jumping spins, sprinting, and cartwheels. Diverse task performance at test time, including waypoint navigation, joystick teleoperation, and obstacle avoidance.

Conclusion: BeyondMimic is the first real-world framework to learn from human motions for versatile and naturalistic humanoid control via guided diffusion. It provides a motion tracking pipeline capable of challenging skills and a unified diffusion policy that enables zero-shot task-specific control using simple cost functions. Deployed on hardware, it performs diverse tasks like waypoint navigation, joystick teleoperation, and obstacle avoidance, bridging sim-to-real motion tracking and flexible synthesis of human motion primitives for whole-body control.

Abstract: Learning skills from human motions offers a promising path toward
generalizable policies for whole-body humanoid control, yet two key
cornerstones are missing: (1) a high-quality motion tracking framework that
faithfully transforms large-scale kinematic references into robust and
extremely dynamic motions on real hardware, and (2) a distillation approach
that can effectively learn these motion primitives and compose them to solve
downstream tasks. We address these gaps with BeyondMimic, the first real-world
framework to learn from human motions for versatile and naturalistic humanoid
control via guided diffusion. Our framework provides a motion tracking pipeline
capable of challenging skills such as jumping spins, sprinting, and cartwheels
with state-of-the-art motion quality. Moving beyond mimicking existing motions
and synthesize novel ones, we further introduce a unified diffusion policy that
enables zero-shot task-specific control at test time using simple cost
functions. Deployed on hardware, BeyondMimic performs diverse tasks at test
time, including waypoint navigation, joystick teleoperation, and obstacle
avoidance, bridging sim-to-real motion tracking and flexible synthesis of human
motion primitives for whole-body control. https://beyondmimic.github.io/.

</details>


### [614] [UPP: Unified Path Planner with Adaptive Safety and Optimality](https://arxiv.org/abs/2505.23197)
*Jatin Kumar Arora,Shubhendu Bhasin*

Main category: cs.RO

TL;DR: 提出了一种统一路径规划器（UPP），通过改进的启发式方法和动态安全成本函数，在安全性和最优性之间取得平衡，并能通过参数调整进行权衡。


<details>
  <summary>Details</summary>
Motivation: 路径规划是机器人领域的一个主要挑战，现有算法大多只关注最优性或安全性，很少同时解决两者。本研究旨在解决这一问题。

Method: 提出了一种统一路径规划器（UPP），该规划器使用改进的启发式方法和动态安全成本函数来平衡安全性和最优性。

Result: 模拟结果表明，UPP 能够成功找到安全且次优的路径，并且在不同场景下与传统算法相比表现更优。在 TurtleBot 机器人上的验证也证实了这一点。

Conclusion: 该研究提出了一个统一路径规划器（UPP），并能在安全性和最优性之间取得平衡，通过可调参数可以调整安全级别，并以计算复杂度作为权衡。在模拟和 TurtleBot 机器人上的实验结果表明，UPP 能够找到安全且次优的路径，并且在不同场景下优于传统的路径规划算法。

Abstract: We are surrounded by robots helping us perform complex tasks. Robots have a
wide range of applications, from industrial automation to personalized
assistance. However, with great technological innovation come significant
challenges. One of the major challenges in robotics is path planning. Despite
advancements such as graph search, sampling, and potential field methods, most
path planning algorithms focus either on optimality or on safety. Very little
research addresses both simultaneously. We propose a Unified Path Planner (UPP)
that uses modified heuristics and a dynamic safety cost function to balance
safety and optimality. The level of safety can be adjusted via tunable
parameters, trading off against computational complexity. We demonstrate the
planner's performance in simulations, showing how parameter variation affects
results. UPP is compared with various traditional and safe-optimal planning
algorithms across different scenarios. We also validate it on a TurtleBot,
where the robot successfully finds safe and sub-optimal paths.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [615] [Radiative Heat Transfer and 2D Transition Metal Dichalcogenide Materials](https://arxiv.org/abs/2508.06658)
*Long Ma,Dai-Nam Le,Lilia M. Woods*

Main category: cond-mat.mes-hall

TL;DR: 研究了过渡金属二卤化物单层中的辐射传热，并提出了一种结合分析模型和第一性原理计算的方法来建立材料数据库。


<details>
  <summary>Details</summary>
Motivation: 辐射传热在基本观点和能量收集应用方面都备受关注。材料的维度对增强有益，尤其是等离​​子体激发的限制、双曲性和其他性质。

Method: 结合分析模型和从头模拟的性质。

Result: 研究了过渡金属二卤化物单层在 H 和 T 对称性中的辐射热功率。

Conclusion: 该研究为基于第一性原理计算的第一性原理计算的电子和光学性质，在有效的模型中用于理解新兴的金属和半导体的标度律以及用于辐射传热的特定材料信号。该方法可用于其他材料家族，以建立辐射传热的材料数据库。

Abstract: Radiative heat transfer is of great interest from a fundamental point of view
and for energy harvesting applications. This is a material dependent phenomenon
where confined plasmonic excitations, hyperbolicity and other properties can be
effective channels for enhancement, especially at the near field regime.
Materials with reduced dimensions may offer further benefits of enhancement
compared to the bulk systems. Here we study the radiative thermal power in the
family of transition metal dichalcogenide monolayers in their H- and
T-symmetries. For this purpose, the computed from first principles electronic
and optical properties are then used in effective models to understand the
emerging scaling laws for metals and semiconductors as well as specific
materials signatures as control knobs for radiative heat transfer. Our combined
approach of analytical modeling with properties from ab initio simulations can
be used for other materials families to build a materials database for
radiative heat transfer.

</details>


### [616] [Incommensuration in odd-parity antiferromagnets](https://arxiv.org/abs/2508.06713)
*Changhee Lee,Nico A. Hackner,P. M. R. Brydon*

Main category: cond-mat.mes-hall

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Inversion-asymmetric antiferromagnets (AFMs) with odd-parity
spin-polarization pattern have been proposed as a new venue for spintronics.
These AFMs require commensurate ordering to ensure an effective time-reversal
symmetry, which guarantees a strictly antisymmetric spin polarization of the
electronic states. Recently, nonsymmorphic centrosymmetric crystals have been
identified as a broad class of materials which could exhibit unit-cell doubling
magnetism with odd-parity spin-polarization. Here we investigate the stability
of these states against incommensuration. We first demonstrate that the
symmetry conditions which permit a p-wave spin polarization pattern also permit
the existence of a non-relativistic Lifshitz invariant in the phenomenological
Ginzburg-Landau free energy. This implies magnetism with an incommensurate
ordering vector, independent of its microscopic origin. AFMs with f- or h-wave
spin-polarization are also prone to incommensurability, especially when they
have an itinerant origin. Here the symmetry which ensures the odd-parity
spin-polarization also guarantees the existence of van Hove saddle points off
the time-reversal-invariant momenta, which promote incommensurate spin
fluctuations in quasi-two-dimensional electronic systems. Finally, we study the
effect of weak spin-orbit coupling in locally noncentrosymmetric materials and
find that it favors antiferromagnetic phases with in-plane magnetic moments.
However, the inclusion of the spin-orbit coupling also introduces a new
mechanism for driving incommensuration. Our results imply that odd-parity AFMs
are likely to be preceded by an incommensurate phase, or emerge directly from
the normal state via a first order transition. These conclusions are consistent
with the phase diagram of several candidate materials.

</details>


### [617] [Topological hydrodynamics in spin-triplet superconductors](https://arxiv.org/abs/2508.06758)
*Chau Dao,Eric Kleinherbers,Bjørnulf Brekke,Yaroslav Tserkovnyak*

Main category: cond-mat.mes-hall

TL;DR: 自旋三联体超导体存在连接超电流环流和体磁斯格明子密度的体边对应关系，从而产生磁性斯格明子的拓扑流体动力学。该研究提出了一个无需约瑟夫森结的自旋三联体超导量子干涉器件（SQUID）的蓝图，该器件经历了非奇异的4π相变，并可能通过奥斯特场测量提供铁磁自旋三联体超导的实验证据。


<details>
  <summary>Details</summary>
Motivation: 为了探究电荷和自旋动力学之间的相互作用，提出了一种自旋三联体超导量子干涉器件（SQUID），该器件无需约瑟夫森结。

Method: 提出了一种自旋三联体超导量子干涉器件（SQUID）的蓝图，该器件无需约瑟夫森结。通过感应耦合该器件与槽路，并通过奥斯特场测量探测非线性超流响应。

Result: 自旋三联体超导量子干涉器件（SQUID）经历了非奇异的4π相变，电流弛豫由描绘磁性斯格明子纹理的自旋动力学促进。这可为铁磁自旋三联体超导提供实验证据。

Conclusion: 该研究提出了一个无需约瑟夫森结的自旋三联体超导量子干涉器件（SQUID）的蓝图。该器件通过自旋动力学弛豫电流，该动力学描绘了磁性斯格明子纹理，并经历了非奇异的4π相变。通过将器件与槽路耦合，并通过奥斯特场测量探测非线性超流响应，可以为铁磁自旋三联体超导提供实验证据。

Abstract: Due to the structure of the underlying SO(3) $\mathbf d$-vector order
parameter, spin triplet superconductors exhibit a bulk-edge correspondence
linking the circulation of supercurrent to the bulk magnetic skyrmion density,
giving rise to topological hydrodynamics of magnetic skyrmions. To probe the
interplay of charge and spin dynamics, we propose a blueprint for a
spin-triplet superconducting quantum interference device (SQUID), which
functions without a Josephson weak link. The triplet SQUID undergoes
nonsingular $4\pi$ phase slips, in which current relaxation is facilitated by
spin dynamics that trace out a magnetic skyrmion texture. Inductively coupling
the device to a tank circuit and probing the nonlinear supercurrent response
via Oersted field measurements could provide an experimental signature of
ferromagnetic spin-triplet superconductivity.

</details>


### [618] [Observation of anomalous Floquet non-Abelian topological insulators](https://arxiv.org/abs/2508.06818)
*Huahui Qiu,Shuaishuai Tong,Qicheng Zhang,Kun Zhang,Chunyin Qiu*

Main category: cond-mat.mes-hall

TL;DR: 本研究首次在声学领域通过实验实现了反常非阿贝尔傅立叶拓扑绝缘体（FNTIs），展示了在平凡整体电荷下跨越所有三个能隙的拓扑边缘模式，并观察到了以前无法实现的拓扑界面模式。


<details>
  <summary>Details</summary>
Motivation: 非阿贝尔拓扑相（超越传统的阿贝尔拓扑能带理论）正受到越来越多的关注，而周期性驱动的引入更是激发了对许多新颖多能隙傅立叶拓扑相的预测，包括由非阿贝尔傅立叶编织引起的反常欧拉和狄拉克弦相位，以及表现出多重体边对应关系的傅立叶非阿贝尔拓扑绝缘体（FNTIs）。

Method: 本研究通过将时间周期性耦合电路集成到静态声学晶体中，在声学领域构建并实现了一个一维三带傅立叶模型，用于实验验证反常非阿贝尔傅立叶拓扑绝缘体（FNTIs）。

Result: 本研究首次实验实现了反常FNTIs，在三个能隙中均展示了拓扑边缘模式，且整体电荷平凡。在反常FNTI与其交换驱动序列对应体形成的畴壁中，观察到了新的拓扑界面模式。

Conclusion: 本研究首次实验实现了反常非阿贝尔傅立叶拓扑绝缘体（FNTIs），该绝缘体在整个三个能隙中都表现出拓扑边缘模式，尽管其整体电荷是平凡的。通过将时间周期性耦合电路集成到静态声学晶体中，我们在声学领域构建并实现了一个一维三带傅立叶模型。此外，我们观察到了在反常FNTI与其具有交换驱动序列的对应体形成的畴壁中出现的违反直觉的拓扑界面模式，这些模式在之前的傅立叶阿贝尔系统中是无法获得的。

Abstract: Non-Abelian topological phases, which go beyond traditional Abelian
topological band theory, are garnering increasing attention. This is further
spurred by periodic driving, leading to predictions of many novel multi-gap
Floquet topological phases, including anomalous Euler and Dirac string phases
induced by non-Abelian Floquet braiding, as well as Floquet non-Abelian
topological insulators (FNTIs) that exhibit multifold bulk-edge correspondence.
Here, we report the first experimental realization of anomalous FNTIs, which
demonstrate topological edge modes in all three gaps despite having a trivial
bulk charge. Concretely, we construct an experimentally feasible
one-dimensional three-band Floquet model and implement it in acoustics by
integrating time-periodic coupling circuits to static acoustic crystals.
Furthermore, we observe counterintuitive topological interface modes in the
domain-wall formed by an anomalous FNTI and its counterpart with swapped
driving sequences, modes previously inaccessible in Floquet Abelian systems.
Our work paves the way for further experimental exploration of the uncharted
non-equilibrium topological physics.

</details>


### [619] [Randomly twisted bilayer graphene -- the cascade transitions](https://arxiv.org/abs/2508.07024)
*Baruch Horovitz,Pierre Le Doussal*

Main category: cond-mat.mes-hall

TL;DR: Disorder in twisted bilayer graphene (TBG) becomes huge near the magic angle, causing the density of states to diverge at the Dirac point. Electrons occupy energies near E=0, and each added electron contributes equal intraband Coulomb interaction energy. Jumps in the chemical potential are observed at integer fillings.


<details>
  <summary>Details</summary>
Motivation: Twisted bilayer graphene (TBG) is known to have disorder in its twist angle. We show that in terms of a Dirac equation with a random gauge potential A(r) this disorder becomes huge when the average twist angle is near the magic angle where the Dirac velocity vanishes.

Method: We prove a sum rule on the disorder averaged eigenfunctions from which we deduce that each added electron contributes equal intraband Coulomb interaction energy. The various bands in TBG are related by either A(r)→A(−r) or A(r)→−A(r) which affects the interband interaction energy.

Result: The density of states (DOS) then diverges at the Dirac point as ρ(E)∼E^((2/z)−1) with z≫1 and we deduce that all electrons occupy energies very near E=0.

Conclusion: We find, within Hartree-Fock, jumps in the chemical potential at each integer filling, accounting for the cascade transitions.

Abstract: Twisted bilayer graphene (TBG) is known to have disorder in its twist angle.
We show that in terms of a Dirac equation with a random gauge potential ${\bf
A}({\bf r})$ this disorder becomes huge when the average twist angle is near
the magic angle where the Dirac velocity vanishes. The density of states (DOS)
then diverges at the Dirac point as $\rho(E)\sim E^{(2/z)-1}$ with $z\gg 1$ and
we deduce that all electrons occupy energies very near $E=0$. We prove a sum
rule on the disorder averaged eigenfunctions from which we deduce that each
added electron contributes equal intraband Coulomb interaction energy. The
various bands in TBG are related by either ${\bf A}({\bf r})\rightarrow {\bf
A}({-\bf r})$ or ${\bf A}({\bf r})\rightarrow -{\bf A}({\bf r})$ which affects
the interband interaction energy. We find, within Hartree-Fock, jumps in the
chemical potential at each integer filling, accounting for the cascade
transitions.

</details>


### [620] [Wannier Center Analysis on Possible Three-Dimensional Topological Phases in α-Type Layered Organic Conductors](https://arxiv.org/abs/2508.07164)
*Toshihito Osada*

Main category: cond-mat.mes-hall

TL;DR: 该研究利用WCC框架分析了α-类型有机导体中的拓扑状态。发现I型狄拉克半金属状态（由层间SOC引起）能解释α-(ET)2I3中的手征输运现象，而α-(BETS)2I3中出现的是三维弱拓扑绝缘体状态，而非实验推测的强拓扑绝缘体状态。


<details>
  <summary>Details</summary>
Motivation: 旨在识别实际的拓扑状态。

Method: 基于Wannier电荷中心(WCC)的统一框架，研究了α-类型层状有机导体中可能的三维(3D)状态的拓扑特征。

Result: 在多层α-(ET)2I3的3D狄拉克/外尔半金属状态中，I型狄拉克半金属状态（由层间SOC引起）最能有效解释由WCC片螺旋结构引起的手征磁效应所归因的手征输运现象。在多层α-(BETS)2I3中，无论是否存在层间SOC和/或反转对称性破坏，都会持续出现三维弱拓扑绝缘体(TI)状态。实验观测表明的强TI状态似乎不太可能实现。

Conclusion: 在多层α-(BETS)2I3中，无论是否存在层间自旋-轨道耦合(SOC)和/或反转对称性破坏，都会持续出现三维弱拓扑绝缘体(TI)状态。由层间SOC引起的I型狄拉克半金属状态最能解释观察到的手征输运现象，这源于WCC片的螺旋结构。实验观测表明的强TI状态似乎不太可能实现。

Abstract: Topological features of possible three-dimensional (3D) states in \alpha-type
layered organic conductors are investigated within a unified framework based on
Wannier charge centers (WCCs), aiming to identify their actual topological
states. Among the 3D Dirac/Weyl semimetal states of multilayered
\alpha-(ET)2I3, the type-I Dirac semimetal state, induced by interlayer
spin-orbit coupling (SOC), most effectively explains the observed chiral
transport phenomena attributed to the chiral magnetic effect, which originates
from the spiral structures of the WCC sheets. In multilayered \alpha-(BETS)2I3,
a 3D weak topological insulator (TI) state consistently emerges, irrespective
of the presence of interlayer SOC and/or inversion symmetry breaking. The
strong TI state suggested by experimental observations appears unlikely to be
realized.

</details>


### [621] [Magnetic Moment vs Angular Momentum: Spin Hall Response in Bismuth](https://arxiv.org/abs/2508.07200)
*Junji Fujimoto,Yuki Izaki,Yuki Fuseya*

Main category: cond-mat.mes-hall

TL;DR: In multiband systems like Bi, spin currents carrying angular momentum and magnetic moments behave differently. The magnetic moment's spin Hall effect is much stronger than the angular momentum's and can exceed unity, proving distinct treatments are crucial.


<details>
  <summary>Details</summary>
Motivation: Investigating the proportionality between spin angular momentum and magnetic moment in spin currents within multiband systems.

Method: Using a multiband k·p model to compute the intrinsic spin Hall conductivity tensors of elemental Bi.

Result: The magnetic-moment tensor is significantly larger and less anisotropic than the angular-momentum tensor. Quasiparticle damping activates longitudinal components. The magnetic-moment spin Hall angle exceeds unity.

Conclusion: spin currents in multiband systems are not proportional, and the magnetic-moment spin Hall angle can exceed unity, showing the necessity of distinguishing between spin currents in these systems.

Abstract: Spin currents can carry either spin angular momentum or its associated
magnetic moment, which are no longer strictly proportional in multiband
systems. Using a multiband $k \cdot p$ model, we compute the intrinsic spin
Hall conductivity tensors of elemental Bi. The magnetic-moment tensor emerges
about two orders of magnitude larger and far less anisotropic than the
angular-momentum tensor, while quasiparticle damping activates otherwise
longitudinal components. The magnetic-moment spin Hall angle exceeds unity,
demonstrating that a clear distinction between the two currents is
indispensable for multiband systems.

</details>


### [622] [Conical Intersections Shed Light on Hot Carrier Cooling in Quantum Dots](https://arxiv.org/abs/2508.07322)
*Caitlin V. Hetherington,Nila Mohan T. M.,Shanu A. Shameem,Warren F. Beck,Benjamin G. Levine*

Main category: cond-mat.mes-hall

TL;DR: 胺封端的量子点和羧酸盐封端的量子点都通过多级圆锥交叉进行弛豫，但配体与量子点核心之间的耦合不同，影响了弛豫动力学。


<details>
  <summary>Details</summary>
Motivation: 研究了表面结合的羧酸盐配体在量子点（QDs）的超快动力学和热载流子冷却中的作用，以证明之前提出的涉及多级圆锥交叉的电子激发态弛豫模型具有普遍性。

Method: 通过应用一个涉及多级圆锥交叉的模型，该模型能够准确地再现通过宽带多维光谱观察到的振动相干的频率。

Result: 证明了多级圆锥交叉模型也适用于羧酸盐封端的量子点，并且可以通过分析配体与量子点核心之间的电子或振动耦合来解释配体对弛豫动力学的影响。

Conclusion: 与之前研究的胺封端的量子点相比，羧酸盐封端的量子点中的电子耦合机制不那么明显。此外，比较乙酸盐和甲酸盐配体表明，截断配体烷基链会改变模型预测的弛豫行为。

Abstract: Experimental observations of vibronic coherences in electronically excited
colloidal semiconductor nanocrystals offer a window into the ultrafast dynamics
of hot carrier cooling. In previous work, we showed that, in amine-passivated
quantum dots (QDs), these coherences arise during relaxation through a cascade
of conical intersections between electronically excited states. Here, we
demonstrate the generality of this framework by application to QDs with
surface-bound carboxylate ligands. A model involving a similar cascade of
conical intersections accurately reproduces the frequencies of vibronic
coherences observed with broadband multidimensional spectroscopy. The impact of
ligands on the relaxation dynamics is attributed to two distinct mechanisms
involving either electronic or vibrational coupling between the core and
ligands. Compared to the amine-passivated QDs studied previously, the
electronic coupling mechanism is less prominent in carboxylate-passivated QDs.
Furthermore, comparison of acetate and formate ligands reveals that truncating
the ligand alkyl chains alters the relaxation behavior predicted by the model.

</details>


### [623] [Gradient Electronic Landscapes in van der Waals Heterostructures](https://arxiv.org/abs/2508.07896)
*Nolan Lassaline,Camilla H. Sørensen,Giulia Meucci,Sander J. Linde,Kian Latifi Yaghin,Tuan K. Chau,Damon J. Carrad,Peter Bøggild,Thomas S. Jespersen,Timothy J. Booth*

Main category: cond-mat.mes-hall

TL;DR: tSPL技术能够精确控制二维材料的厚度，实现高质量量子电子器件的定制。


<details>
  <summary>Details</summary>
Motivation: 现有的二维材料器件加工技术（如电子束光刻和刻蚀）在器件的平面几何形状上存在限制，阻碍了更先进器件架构的发展。需要一种新的技术来精确控制器件的三维形貌，以实现更高级的功能。

Method: 利用热扫描探针光刻（tSPL）技术在二维材料异质结中制造光滑的形貌，并精确控制厚度。通过对 the sinusoidal topography 进行电学门控，在石墨烯层上产生电场梯度，空间调制载流子掺杂。

Result: 研究表明，tSPL技术能够实现对二维材料异质结形貌的精确控制，能够制造出具有纳米级厚度梯度的光滑形貌。通过电学门控正弦形貌，成功地在石墨烯层中实现了电场梯度的空间调制载流子掺杂。输运测量结果（电阻峰展宽和可公度振荡）证实了tSPL在定制高质量量子电子器件方面的潜力。

Conclusion: tSPL技术可用于精确控制二维材料异质结的形貌，实现高质量量子电子器件的定制。

Abstract: Two-dimensional (2D) materials such as graphene and hexagonal boron nitride
(hBN) provide a versatile platform for quantum electronics. Experiments
generally require encapsulating graphene within hBN flakes, forming a
protective van der Waals (vdW) heterostructure that preserves delicate
properties of the embedded crystal. To produce functional devices,
heterostructures are typically shaped by electron beam lithography and etching,
which has driven progress in 2D materials research. However, patterns are
primarily restricted to in-plane geometries such as boxes, holes, and stripes,
limiting opportunities for advanced architectures. Here, we use thermal
scanning-probe lithography (tSPL) to produce smooth topographic landscapes in
vdW heterostructures, controlling the thickness degree of freedom with
nanometer precision. We electrically gate a sinusoidal topography to impose an
electric-field gradient on the graphene layer to spatially modulate
charge-carrier doping. We observe signatures of the landscape in transport
measurements-resistance-peak spreading and commensurability
oscillations-establishing tSPL for tailoring high-quality quantum electronics.

</details>


### [624] [Magnetic Field Induced Quantum Metric Dipole in Dirac Semimetal Cd3As2](https://arxiv.org/abs/2508.07364)
*Tong-Yang Zhao,An-Qi Wang,Zhen-Tao Zhang,Zheng-Yang Cao,Xing-Yu Liu,Zhi-Min Liao*

Main category: cond-mat.mes-hall

TL;DR: 本研究在非磁性材料中实现了由磁场调控的非线性霍尔效应，为开发可调谐的非线性量子器件提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 探究量子度量偶极子是否能在非磁性系统中驱动无散射非线性霍尔效应，以及是否能通过外加磁场进行调控。

Method: 通过构建包含塞曼和轨道耦合的狄拉克能带的k.p有效模型，推导出量子度量偶极子随磁场的演变，从而全面解释实验结果。

Result: 在非磁性拓扑狄拉克半金属Cd3As2中，通过外加磁场成功调控了量子度量偶极子，产生了时间反演破缺的非线性霍尔响应。在高磁场下，除了已知的由手征反常引起负纵向磁阻外，还出现了一种由磁场调制的量子度量偶极子控制的奇异的非线性平面霍尔效应。

Conclusion: 本研究通过磁场调控量子度量偶极子，在非磁性拓扑狄拉克半金属Cd3As2中实现了时间反演破坏的非线性霍尔效应，并提出了通过量子度量偶极子工程化非磁性材料中非线性磁输运的带状结构策略，为可调谐的非线性量子器件开辟了道路。

Abstract: The quantum geometry, comprising Berry curvature and quantum metric, plays a
fundamental role in governing electron transport phenomena in solids. Recent
studies show that the quantum metric dipole drives scattering-free nonlinear
Hall effect in topological antiferromagnets, prompting the questions of whether
this effect can occur in nonmagnetic systems and be externally tuned by a
magnetic field. Our work addresses these frontiers by demonstrating that the
quantum metric dipole is actively tuned by an external magnetic field to
generate a time-reversal-odd nonlinear Hall response in a nonmagnetic
topological Dirac semimetal Cd3As2. Alongside the well-known
chiral-anomaly-induced negative longitudinal magnetoresistance, an exotic
nonlinear planar Hall effect emerges with increasing magnetic field. Careful
scaling analysis indicates that this nonlinear planar Hall effect is controlled
by the magnetic-field-modulated quantum metric dipole. Constructing a k.p
effective model of the Dirac bands under Zeeman and orbital coupling, we derive
the evolution of the quantum metric dipole as a function of the magnetic field,
providing a comprehensive explanation of the experimental results. Our results
establish a band-structure-based strategy for engineering nonlinear
magnetotransport in nonmagnetic materials via the quantum metric dipole,
opening a pathway toward magnetic-field-tunable nonlinear quantum devices.

</details>


### [625] [Non-Abelian Chern band in rhombohedral graphene multilayers](https://arxiv.org/abs/2508.07366)
*Taketo Uchida,Takuto Kawakami,Mikito Koshino*

Main category: cond-mat.mes-hall

TL;DR: 菱面多层石墨烯自发形成非阿贝尔陈吉布森带，揭示了新的拓扑相。


<details>
  <summary>Details</summary>
Motivation: 菱面多层石墨烯的Moiré平带为探索相互作用驱动的拓扑相提供了一个平台，但具有SU(N)等内部对称性的非简并非阿贝尔陈吉布森带的实现通常需要高度工程化的系统。本研究旨在探索在更易实现的系统中实现非阿贝尔陈吉布森带的可能性。

Method: 通过自洽Hartree-Fock计算，研究了位移场和电子周期性对菱面3层、4层和5层石墨烯的影响，并绘制了相图。理论上证明了Fock项驱动了自发对称性破缺，并产生了非阿贝尔贝里曲率。

Result: 在菱面3层、4层和5层石墨烯的填充数为2时，无条件地出现了双重简并的非阿贝尔陈吉布森带，其陈数绝对值为1。该现象不依赖于hBN衬底的存在。研究还绘制了相图，并证明了Fock项是导致这种非阿贝尔陈吉布森带形成的关键因素。

Conclusion: 该研究发现了菱面多层石墨烯在特定填充下能自发形成双重简并的非阿贝尔陈吉布森带，其陈数绝对值为1，并且不依赖于hBN衬底。这揭示了一类新的由相互作用驱动的非阿贝尔拓扑相，不同于量子反常霍尔相和分数量子霍尔相。

Abstract: Moir\'e flat bands in rhombohedral multilayer graphene provide a platform for
exploring interaction-driven topological phases, where a single isolated band
often forms a Chern band. However, non-Abelian degenerate Chern bands with
internal symmetries such as SU($N$) have so far been realized only in highly
engineered systems. Here, we show that a doubly degenerate non-Abelian Chern
band with Chern number $|C|=1$ emerges spontaneously at filling $\nu=2$ in
rhombohedral 3-, 4-, and 5-layer graphene, regardless of the presence of an hBN
substrate. Using self-consistent Hartree-Fock calculations, we map out phase
diagrams as functions of displacement field and electronic periodicity, and
analytically demonstrate that the Fock term drives spontaneous symmetry
breaking and generates non-Abelian Berry curvature. Our findings unveil a new
class of interaction-driven non-Abelian topological phases, distinct from
quantum anomalous Hall and fractional Chern phases.

</details>


### [626] [Asymmetric-gate Mach--Zehnder interferometry in graphene: Multi-path conductance oscillations and visibility characteristics](https://arxiv.org/abs/2508.07380)
*Taegeun Song,Nojoon Myoung*

Main category: cond-mat.mes-hall

TL;DR: Graphene Mach-Zehnder interferometers with asymmetric p-n junctions are studied. Asymmetry tunes the area and creates new paths. Machine learning analyzes complex patterns, and symmetric gates improve visibility.


<details>
  <summary>Details</summary>
Motivation: Investigate electron quantum interference in graphene using Mach-Zehnder interferometers with asymmetric p-n junctions, exploring how asymmetry affects interference patterns and visibility.

Method: The paper proposes a phenomenological framework for analyzing graphene-based Mach-Zehnder interferometry with asymmetric p-n junctions. It utilizes machine learning-based Fourier transform to analyze complex beat oscillations and investigates the impact of asymmetric gates on interference visibility.

Result: Asymmetric gate potentials allow tuning of the enclosed interferometer area, and higher filling factors lead to additional Mach-Zehnder interferometer pathways. Machine learning-based Fourier transform improves peak-to-background ratios for analyzing complex oscillations. Symmetric gate conditions enhance interference visibility.

Conclusion: The study presents a phenomenological framework for graphene-based Mach-Zehnder interferometry with asymmetric p-n junction configurations, demonstrating tunability of interferometer area and the emergence of new pathways. It also highlights the effectiveness of machine learning for analyzing complex interference patterns and discusses the impact of asymmetric gates on interference visibility.

Abstract: Graphene provides an excellent platform for investigating electron quantum
interference due to its outstanding coherent properties. In the quantum Hall
regime, Mach--Zehnder (MZ) electronic interferometers are realized using p--n
junctions in graphene, where electron interference is highly protected against
decoherence. In this work, we present a phenomenological framework for
graphene-based MZ interferometry with asymmetric p--n junction configurations.
We show that the enclosed interferometer area can be tuned by asymmetric gate
potentials, and additional MZ pathways emerge in higher-filling-factor
scenarios, e.g. $\left(\nu_{n},\nu_{p}\right)=\left(-3,+3\right)$. The
resulting complicated beat oscillations in asymmetric-gate MZ interference are
efficiently analyzed using a machine-learning--based Fourier transform, which
yields improved peak-to-background ratios compared to conventional
signal-processing techniques. Furthermore, we examine the impact of the
asymmetric gate on the interference visibility, finding that interference
visibility is enhanced under symmetric gate conditions.

</details>


### [627] [Dissipation-induced Half Quantized Conductance in One-dimensional Topological Systems](https://arxiv.org/abs/2508.07398)
*Bozhen Zhou,Pan Zhang,Yucheng Wang,Chao Yang*

Main category: cond-mat.mes-hall

TL;DR: 一维拓扑系统中的边缘态通常不传输电流，但本研究发现增益和损耗可以使一维拓扑系统表现出半量子化的导带，这为了解和利用一维拓扑系统的拓扑性质提供了新的途径。


<details>
  <summary>Details</summary>
Motivation: 一维拓扑系统中的边缘态无法跨越绝缘体主体传输电流，这使得它们的拓扑性质在输运中变得不可见。

Method: 通过研究增益和损耗的Su-Schrieffer-Heeger模型，并分析零能耗导带的行为。

Result: 零能耗导带的行为在拓扑平凡相和非平凡相之间表现出显著的差异，并且在拓扑非平凡相中，导带可以表现出半量子化的特征，而这是在拓扑平凡相中不存在的。

Conclusion: 本研究揭示了一種在开放量子系统中实现量子化输运的新机制，并强调了耗散在实现一维拓扑系统中的拓扑特征方面所起的关键作用。

Abstract: Quantized conductance from topologically protected edge states is a hallmark
of two-dimensional topological phases. In contrast, edge states in
one-dimensional (1D) topological systems cannot transmit current across the
insulating bulk, rendering their topological nature invisible in transport. In
this work, we investigate the transport properties of the Su-Schrieffer-Heeger
model with gain and loss, and show that the zero-energy conductance exhibits
qualitatively distinct behaviors between the topologically trivial and
nontrivial phases, depending on the hybridization and dissipation strengths.
Crucially, we analytically demonstrate that the conductance can become
half-quantized in the topologically nontrivial phase, a feature absent in the
trivial phase. We further show that the half quantization predominantly
originates from transport channels involving gain/loss and edge states. Our
results uncover a new mechanism for realizing quantized transport in 1D
topological systems and highlight the nontrivial role of dissipation in
enabling topological signatures in open quantum systems.

</details>


### [628] [Strong and selective magnon-phonon coupling in van der Waals antiferromagnet CoPS$_3$](https://arxiv.org/abs/2508.07412)
*Dipankar Jana,Diana Vaclavkova,Rajesh Kumar Ulaganathan,Raman Sankar,Milan Orlita,Clement Faugeras,Maciej Koperski,M. E. Zhitomirsky,Marek Potemski*

Main category: cond-mat.mes-hall

TL;DR: CoPS3中的混合磁激发-声子相互作用导致了两个声子模式在152 cm^-1和158 cm^-1处的分裂。


<details>
  <summary>Details</summary>
Motivation: 研究CoPS3的拉曼散射响应，以识别混合磁激发-声子激发，并确定其参数。

Method: 通过研究磁场和温度下的拉曼散射响应来识别混合激子-声子激发，并确定其能量和耦合强度。

Result: 识别了低频光谱（90-200 cm^-1）的峰值为混合磁激发-声子激发，并确定了参数。

Conclusion: 基于对裸露的磁激发及其磁场依赖性的识别，我们提出了一个更新的有效交换（J_eff = 9.9 meV）和双轴磁各向异性（D = 4.3 meV 和 E = -0.7 meV）参数集，并倡导使用明显各向异性的g因子（Gx = Gy = 2，Gz = 4）在CoPS3反铁磁体中。

Abstract: The Raman scattering response of the biaxial antiferromagnet CoPS$_3$ has
been investigated as a function of both magnetic field and temperature. The
peaks observed in the low-frequency spectral range (90--200~cm$^{-1}$) have
been identified as hybrid magnon--phonon excitations. The energies of the bare
magnon and phonon modes, as well as the effective coupling strengths between
different excitation pairs, have been determined. The strong and selective
magnon--phonon interaction largely accounts for the pronounced splitting of two
phonon-like modes observed at 152~cm$^{-1}$ and 158~cm$^{-1}$ in the
antiferromagnetic phase of CoPS$_3$. Based on the identification of bare magnon
excitations and their magnetic-field dependence, we propose an updated set of
parameters for the effective exchange ($J_{\mathrm{eff}} = 9.9$~meV) and
biaxial magnetic anisotropy ($D = 4.3$~meV and $E = -0.7$~meV) and advocate for
an apparent anisotropic $g$-factor ($g_x = g_y = 2$, $g_z = 4$) in the CoPS$_3$
antiferromagnet.

</details>


### [629] [Electronic band structure of a nodal line semimetal candidate ErSbTe](https://arxiv.org/abs/2508.07422)
*Iftakhar Bin Elius,Nathan Valadez,Dante James,Sami Elgalal,Grzegorz Chajewski,Tetiana Romanova,Andrzej Ptok,Dariusz Kaczorowski,Madhab Neupane*

Main category: cond-mat.mes-hall

TL;DR: ErSbTe 是一种在约 1.94 K 和 1.75 K 发生磁相变的节点线半金属候选物，其电子结构和德泽尔效应使其成为拓扑材料研究的有前景的候选物。


<details>
  <summary>Details</summary>
Motivation: LnSbTe 家族因其晶体对称性、磁结构、4f 电子相关性和自旋-轨道耦合（SOC）现象而闻名，但 ErSbTe 的具体性质尚未得到充分研究。

Method: 使用角分辨光电子能谱（ARPES）结合第一性原理理论能带结构计算（考虑和不考虑 SOC 的影响）来系统研究 ErSbTe 的块体电学和热力学性质以及电子结构。

Result: ErSbTe 在大约 1.94 K 和 1.75 K 发生顺磁到反铁磁相变。其电子能带结构在 GX 方向上表现出菱形费米面，并且存在由非同形对称性引起的穿越费米能量的电子带交叉。沿 GX 方向的另一个交叉点被间隙化，并在动量空间中演化。

Conclusion: ErSbTe 表现出与镧系原子相关的多类迷人特征，这归因于其晶体对称性、磁结构、4f 电子相关性和自旋-轨道耦合（SOC）。ErSbTe 的低温性质在德泽尔效应和赝简并方面表现出新颖性，这与通过 ARPES 和第一性原理计算揭示的电子结构一致，表明 ErSbTe 是一种有前途的拓扑材料。

Abstract: The LnSbTe family is well known for hosting a plethora of intriguing
characteristics stemming from its crystalline symmetry, magnetic structure, 4f
electronic correlations and spin orbit coupling (SOC) phenomena. In this paper,
we have systematically studied the bulk electrical and thermodynamic properties
and electronic structure of the nodal line semimetal candidate ErSbTe using
angle resolved photoemission spectroscopy (ARPES) corroborated with first
principles based theoretical band structure calculations with and without
considering the effect of SOC, a critical factor dictating the band degeneracy
which depends on the choice of the Ln atom. Corroborative temperature dependent
susceptibility, electrical resistivity and thermodynamic measurements,
coherently exhibit paramagnetic to antiferromagnetic phase transition
approximately at 1.94 K, and another sharp anomaly at 1.75 K. The zero field
cooled resistivity measurement does not show the characteristic hump like
feature in the other LnSbTe materials. The electronic band structure of ErSbTe,
exhibits a diamond shaped Fermi surface. Along the high symmetry direction GX,
electronic bands are projected to cross over the Fermi energy, necessitated by
the nonsymmorphic symmetry of the system. The other crossing along this
direction is gapped, which evolves along the momentum space reaching its
maximum along the GM direction.

</details>


### [630] [Giant spin Hall effects and topological surface states in ternary-layered MAX carbides Mn+1AlCn (M= Nb, Ta, n=1, 2, 3)](https://arxiv.org/abs/2508.07061)
*Yanhui Chen,Hong-Yan Lu,Wenjin Yang,Meifeng Liu,Bin Cui,Desheng Liu,Bing Huang,Xi Zuo*

Main category: cond-mat.mes-hall

TL;DR: MAX碳化物Mn+1AlCn（M=Nb，Ta，n=1, 2, 3）的系统研究表明，Ta3AlC2是一种具有高自旋霍尔效应的Z2拓扑金属。


<details>
  <summary>Details</summary>
Motivation: 探索MAX碳化物在电子结构、能带拓扑和自旋霍尔效应方面的性质，特别是关联效应对SHE的影响。

Method: 对MAX碳化物Mn+1AlCn（M=Nb，Ta，n=1, 2, 3）的电子结构、能带拓扑和本征自旋霍尔效应（SHE）进行了系统研究，并探讨了关联效应对SHE的影响。

Result: 研究发现M3AlC2和M4AlC3（M=Nb，Ta）在费米能级附近具有相似的狄拉克能带交叉特征，在没有自旋-轨道耦合（SOC）的情况下形成节点线。当考虑SOC时，狄拉克能带交叉被完全打开，产生非平凡的Z2拓扑不变量（1;000）以及在（001）平面上的一对表面态。多个狄拉克点的存在导致了局部强自旋贝里曲率，从而产生了大的自旋霍尔电导率，Ta3AlC2的自旋霍尔角高达约60%。此外，还阐明了Hubbard U校正对SHC的影响。

Conclusion: Ta3AlC2 可能是一种具有优越的电荷-自旋转换效率的 Z2 拓扑金属。

Abstract: In this work, we report a systematic study of the electronic structures, band
topology, and intrinsic spin Hall effect (SHE) of the layered MAX carbides
Mn+1AlCn (M= Nb, Ta, n=1, 2, 3) and explore the correlation effects on the SHE.
The results show that M3AlC2 and M4AlC3 (M= Nb, Ta) share similar
Dirac-band-crossing features near the Fermi level (EF) and form nodal lines in
the absence of spin-orbit coupling (SOC). When the SOC is included, the Dirac
band crossings are fully gapped, resulting in nontrivial Z2 topological
invariants (1;000) with a pair of surface states on the (001) plane.
Remarkably, the multiple gapped Dirac points contribute to locally strong spin
Berry curvatures, which lead to large spin Hall conductivities and a giant spin
Hall angle up to ~ 60% for Ta3AlC2. Moreover, we also elucidate the impact of
Hubbard U correction on SHC. Our findings indicate that Ta3AlC2 might represent
an intriguing layered Z2 topological metal with superior charge-to-spin
conversion efficiency.

</details>


### [631] [Unified Semiclassical Theory of Nonlinear Hall Effect:Bridging Ballistic and Diffusive Transport Regime](https://arxiv.org/abs/2508.07445)
*Xinyu Liu,Haozhi Liao,Guangyun Qi,Hao Geng,Li Sheng,Dingyu Xing*

Main category: cond-mat.mes-hall

TL;DR: 非线性霍尔效应理论研究，考虑尺寸效应，提出统一理论框架。


<details>
  <summary>Details</summary>
Motivation: 填补了先前理论研究中对尺寸依赖性效应的不足，旨在深入理解非线性霍尔效应。

Method: 基于玻尔兹曼输运方程，结合广义边界条件，建立了统一的半经典理论框架。

Result: 揭示了非线性霍尔效应源于贝里曲率偶极和贝里曲率的费米面积分，并阐明了在拓扑晶体绝缘体中尺寸依赖性是这两种输运机制竞争的结果。

Conclusion: 该理论框架统一了弹道和扩散输运，为理解有限尺寸系统中的非线性霍尔效应提供了全面的视角，并为进一步的尺寸依赖性研究提供了基础和分析工具。

Abstract: The nonlinear Hall effect has attracted considerable attention and undergone
extensive investigation in recent years. However, theoretical studies
addressing size-dependent effects remain largely unexplored. In this work, we
establish a unified semiclassical framework based on the Boltzmann transport
equation, incorporating generalized boundary conditions to bridge the ballistic
and diffusive transport regimes. Our analysis reveals that the nonlinear Hall
effect arises from the combined action of two distinct mechanisms: the Berry
curvature dipole and the Fermi-surface integral of Berry curvature.
Furthermore, we investigate the Hall effect in topological crystalline
insulators (TCIs), elucidating that the size dependence originates from
competition between the two transport mechanisms. By connecting the two
distinct regimes, our theoretical framework provides a comprehensive
understanding of the nonlinear Hall effect in finite-sized systems, offering
both fundamental insights and a useful analytical tool for more size-dependent
investigations.

</details>


### [632] [Tunable Interfacial Thermal Conductance in Graphene/Germanene van der Waals Heterostructure using an Optimized Interlayer Potential](https://arxiv.org/abs/2508.07614)
*Sapta Sindhu Paul Chowdhury,Sourav Thapliyal,Bheema Lingam Chittari,Santosh Mogurampelly*

Main category: cond-mat.mes-hall

TL;DR: 通过开发新的势能模型，研究了石墨烯/锗烷异质结构中的界面热传输，并发现应变可以有效调控热导率。


<details>
  <summary>Details</summary>
Motivation: 准确模拟范德华异质结构中的界面热传输具有挑战性，因为层间相互作用势的可用性有限。

Method: 采用从头密度泛函理论计算得到的结合能，开发了一种用于石墨烯/锗烷范德华异质结构的点间相互作用势，并利用该势计算了界面热导率。

Result: 计算表明，界面热导率随外部应变具有优异的可调性。声子态密度计算显示，在沿热流方向施加压缩应变时，声子光谱发生蓝移，界面热导增加了约 136%。相反，拉伸应变则使热导降低了约 70%。此外，温度和相互作用强度都与界面热导呈正相关。

Conclusion: 我们开发了一种用于石墨烯/锗烷范德华异质结构的点间相互作用势，并计算了界面热导率。结果表明，界面热导率可以通过外部应变进行调节，压缩应变可以显著提高界面热导，而拉伸应变则会降低界面热导。此外，温度和相互作用强度也与界面热导呈正相关。

Abstract: Accurately modeling interfacial thermal transport in van der Waals
heterostructures is challenging due to the limited availability of interlayer
interaction potentials. We develop a pairwise interlayer potential for
graphene/germanene van der Waals heterostructure using the binding energy
obtained from ab-initio density functional theory calculations and use it to
calculate the interfacial thermal conductivity. Our calculations reveal that
the interfacial thermal conductivity shows superior tunability with external
strain. The phonon density of states calculations show a blueshift in the
phonon spectra with an applied compressive strain in the direction of heat
flow, increasing the interfacial thermal conductance to $\sim$136% of the
unstrained value. In contrast, a tensile strain is found to cause an opposite
effect, reducing the conductance to $\sim$70% of the unstrained value.
Moreover, due to increased availability of phonons for heat transfer, both
temperature and interaction strength are found to correlate positively with the
interfacial thermal conductance for both directions of heat flow.

</details>


### [633] [Sagnac and Mashhoon effects in graphene](https://arxiv.org/abs/2508.07718)
*Yu. V. Shtanov,T. -H. O. Pokalchuk,S. G. Sharapov*

Main category: cond-mat.mes-hall

TL;DR: Graphene's spin and pseudospin effects analyzed in rotating systems: Sagnac shift similar to free electrons, Mashhoon shift dependent on Fermi velocity. Similarities and differences between spin and pseudospin are highlighted.


<details>
  <summary>Details</summary>
Motivation: The paper investigates the Sagnac and Mashhoon effects in graphene, considering the roles of pseudospin and intrinsic spin of electrons to understand their behavior in a rotating system.

Method: The study employs the effective Larmor theorem and considers the relativistic phase of the wave function to investigate the Sagnac and Mashhoon effects in graphene, accounting for both pseudospin and intrinsic spin of electrons within a simplified model of a rotating nanotube or infinitesimally narrow ring.

Result: The Sagnac fringe shift in graphene is analogous to that for free electrons, governed by electron's vacuum mass. An additional $\pi$-phase shift arises in a narrow ring due to Berry phase. The Mashhoon fringe shift retains its conventional form, dependent on Fermi velocity.

Conclusion: The analysis reveals similarities and differences between spin and pseudospin degrees of freedom in graphene, with the Sagnac fringe shift analogous to free electrons and the Mashhoon fringe shift retaining its conventional form dependent on Fermi velocity.

Abstract: We investigate the Sagnac and Mashhoon effects in graphene, taking into
account both the pseudospin and intrinsic spin of electrons, within a
simplified model of a rotating nanotube or infinitesimally narrow ring. Based
on considerations of the relativistic phase of the wave function and employing
the effective Larmor theorem, we demonstrate that the Sagnac fringe shift
retains a form analogous to that for free electrons, governed by the electron's
vacuum mass. In the case of a narrow ring, an additional $\pi$-phase shift
arises due to the Berry phase associated with the honeycomb graphene lattice.
The Mashhoon fringe shift, which characterizes the dynamics of intrinsic spin,
retains its conventional form in graphene, with its dependence on the Fermi
velocity. Our analysis highlights both the similarities and differences between
spin and pseudospin degrees of freedom in graphene.

</details>


### [634] [Mechanistic Insight into BEOL Thermal Transport via Optical Metrology and Multiphysics Simulation](https://arxiv.org/abs/2508.07740)
*Yang Shen,Shangzhi Song,Tao Chen,Kexin Zhang,Yu Chen,Lu Zhao,Puqing Jiang*

Main category: cond-mat.mes-hall

TL;DR: 由于先进集成电路设计中的尺寸缩小和3D堆叠，对BEOL热管理的需求日益增长。本研究结合了实验（SPS）和仿真（COMSOL）方法，在纳米尺度上表征了BEOL多层膜的热传输特性。研究发现，介电材料是限制热传导的主要因素，而过孔结构也起着一定作用。该方法为优化未来的3D堆叠器件提供了指导。


<details>
  <summary>Details</summary>
Motivation: 随着集成电路的不断缩小和三维（3D）堆叠的应用，后端（BEOL）的热管理已成为关键的设计约束。

Method: 使用方形脉冲源（SPS）方法，一种时间分辨的光学计量技术，在纳米分辨率下测量半导体芯片的跨平面热阻和面热容。使用COMSOL Multiphysics进行有限元模拟，检查过孔连通性和介电热导率对有效跨平面热传输的影响。

Result: 结果表明，热阻遵循串联模型，而面热容与金属含量呈线性关系。模拟表明，由于其较大的体积分数，介电材料是BEOL热传导的主要限制因素，而过孔结构起着次要但重要的作用。

Conclusion: 实验与仿真相结合的方法为先进集成电路架构中的热传输提供了力学见解，并为优化未来高性能3D堆叠器件的热通路提供了实际指导。

Abstract: As integrated circuits continue to scale down and adopt three-dimensional
(3D) stacking, thermal management in the back-end-of-line (BEOL) has emerged as
a critical design constraint. In this study, we present a combined experimental
and simulation framework to quantitatively characterize and mechanistically
understand thermal transport in BEOL multilayers. Using the Square-Pulsed
Source (SPS) method, a time-resolved optical metrology technique, we measure
cross-plane thermal resistance and areal heat capacity in semiconductor chips
at nanometer resolution. Two fabricated chip samples, polished to the M4 and M6
interconnection layers, are analyzed to extract thermal properties of distinct
multilayer stacks. Results show that thermal resistance follows a series model,
while areal heat capacity scales linearly with metal content. To uncover the
underlying physical mechanisms, we perform finite element simulations using
COMSOL Multiphysics, examining the influence of via connectivity and dielectric
thermal conductivity on effective cross-plane heat transport. The simulations
reveal that dielectric materials, due to their large volume fraction, are the
primary limiting factor in BEOL thermal conduction, while the via structure
plays a secondary but significant role. This combined experimental-simulation
approach provides mechanistic insight into heat transport in advanced IC
architectures and offers practical guidance for optimizing thermal pathways in
future high-performance 3D-stacked devices.

</details>


### [635] [QVNTVS, Open-Source Quantum Well Simulator](https://arxiv.org/abs/2508.07792)
*Barbaros Şair*

Main category: cond-mat.mes-hall

TL;DR: QVNTVS是一个开源的量子阱模拟器，使用有限差分法求解薛定谔方程，能够快速准确地计算多种量子阱的各种光电属性。


<details>
  <summary>Details</summary>
Motivation: 为了能够更快速地模拟量子阱的各种拓扑结构（如矩形、多重和三角势阱异质结），并进行理论表征，开发了QVNTVS模拟器。

Method: 使用有限差分法在离散空间中求解定态薛定谔方程，以模拟不同势能剖面下的量子阱。

Result: QVNTVS能够快速准确地计算能量和波函数、复合概率、跃迁能量和光学发射等属性，并且可以解决电场下的势阱、异质结、复合和跃迁矩阵等特殊问题。

Conclusion: QVNTVS通过求解离散空间中的定态薛定谔方程来模拟量子阱，并计算器件的各种属性，与解析计算和实验数据一致。

Abstract: Quantum Wells (QW) are of great importance in optoelectronic devices such as
LEDs and LASERs, being the emissive layers.Simulating the quantum particles in
different QW topologies like rectangular finite potential wells, multiple
potential wells, and triangular biased potential well heterojunctions enables
faster modeling, theoretical characterization, and more. QVNTVS performs energy
level and wavefunction calculations, recombination probability, transition
energy, and optical emission computations quickly and accurately. Contrasting
with the existing simulators, QVNTVS is an open-source project and can produce
solutions for niche problems like potential wells under an electric field,
heterojunctions, recombination, and transition matrices. QVNTVS simulates QWs
by solving the Time-Independent Schr\"odinger Equation for different potential
profiles in a discretized space using the finite-difference method and computes
the properties of the device using the extracted information from the solution.
The results align with the analytical calculations and the experimental data.

</details>


### [636] [Gate tunable spin-charge interconversion in a graphene/ReS$_{2}$ heterostructure up to room temperature](https://arxiv.org/abs/2508.07888)
*Eoin Dolan,Zhendong Chi,Haozhe Yang,Luis E. Hueso,Fèlix Casanova*

Main category: cond-mat.mes-hall

TL;DR: 通过将石墨烯与ReS2靠近，可以实现石墨烯中的自旋-电荷转换（SCI），并可在室温下进行表征，这为下一代逻辑器件提供了潜力。


<details>
  <summary>Details</summary>
Motivation: 为了克服石墨烯中缺乏自旋-轨道耦合（SOC）限制其自旋流操控能力的缺点，利用邻近诱导SOC是关键策略，以实现自旋-电荷转换（SCI），并应用于下一代逻辑器件。

Method: 通过将石墨烯置于ReS2近旁，并对不同偏振的自旋流进行SCI表征，研究了其在不同温度和栅极电压下的行为。

Result: 实现了石墨烯中平面内和面外偏振自旋流的SCI。平面内偏振的SCI归因于石墨烯/ReS2界面的Rashba-Edelstein效应（REE）或非常规自旋霍尔效应（SHE）；面外偏振的SCI归因于邻近石墨烯中的常规SHE，或ReS2体相中的非常规SHE。SCI在高达300 K的温度和一定的栅极电压范围内均可表征。

Conclusion: 将石墨烯置于室温铁电体候选物ReS2的近旁，可诱导石墨烯中的自旋-电荷转换（SCI），可用于下一代逻辑器件。

Abstract: Graphene is a material with great potential in the field of spintronics,
combining good conductivity with low spin--orbit coupling (SOC), which allows
for the transport of spin currents over long distances. However, this lack of
SOC also limits the capacity for manipulating spin current. A key strategy to
address this limitation is to induce SOC in graphene via proximity to other
two-dimensional (2D) materials. Such proximity-induced SOC can enable
spin--charge interconversion (SCI) in graphene, with potential applications in
next-generation logic devices. Here, we place graphene in close proximity to
the room-temperature ferroelectric candidate ReS$_\mathrm{2}$, inducing SCI for
both in-plane and out-of-plane polarized spin current. We attribute the SCI for
in-plane polarized current to either the Rashba--Edelstein effect (REE) or the
unconventional spin Hall effect (SHE) at the graphene/ReS$_\mathrm{2}$
interface, and the SCI for out-of-plane polarized current to either the
conventional SHE in the proximitised graphene, or the unconventional SHE in the
bulk of the ReS$_\mathrm{2}$. SCI due to in-plane spin is characterised over a
wide range of temperature, up to 300 K and a range of gate voltages.

</details>


### [637] [Rabi Oscillations Modulated Noise Squeezing in Active Quantum Dot Ensembles](https://arxiv.org/abs/2508.07890)
*Ori Gabai,Amnon Willinger,Igor Khanonkin,Vitalii Sichkovskyi,Johann Peter Reithmaier,Gadi Eisenstein*

Main category: cond-mat.mes-hall

TL;DR: 量子点SOA中的Rabi振荡产生了准压缩，这是首次在有源设备中观察到的现象。


<details>
  <summary>Details</summary>
Motivation: 解释了半导体光学放大器（SOA）中的噪声特性，并提出在SOA中实现压缩的理论可能性。

Method: 通过实验演示了量子点SOA中短共振脉冲诱导的Rabi振荡。

Result: 在量子点SOA中观察到了准压缩现象，噪声周期性地低于散粒噪声极限，但未达到量子极限。这种准压缩与Rabi振荡的周期相关，并随激发脉冲能量的增加而重复出现。

Conclusion: 量子点SOA中的Rabi振荡导致了准压缩，其噪声周期性地随激发脉冲面积变化，在量子点提供增益的Rabi周期部分发生。

Abstract: Generation of squeezed light is usually implemented in nonlinear \c{hi}(2) or
\c{hi}(3) materials. Semiconductor lasers and optical amplifiers (SOAs) also
offer non-linearities but they differ from passive elements in that they add
amplified spontaneous emission noise (ASE). In a semiconductor laser, squeezing
to below the shot noise limit has been demonstrated. An SOA contains no cavity
and it adds significant noise. Gain saturation can lead, in principle, to
squeezing of the photon number quadrature to below the shot noise level but
often the noise is reduced only to below the ASE level of a linear amplifier.
At the same time, the noise in the phase quadrature increases according to the
Heisenberg uncertainty principle. Short resonant pulses interacting with a
quantum dot SOA induce coherent effects such as Rabi oscillations. Here, we
demonstrate, for the first time, that Rabi oscillations cause cyclical noise
squeezing which varies periodically with the excitation pulse area. The noise
in the present experiments does not reach the quantum limit so we term this
condition quasi squeezing. It occurs during the portions of the Rabi cycle when
the quantum dots provide gain and repeats with every fourfold increase of the
pulse excitation energy which amounts to a 2{\pi} increase in pulse area. In
all other cases, the noise exhibits the properties of a coherent state.

</details>


### [638] [On Noise-Sensitive Automatic Tuning of Gate-Defined Sensor Dots](https://arxiv.org/abs/2508.07898)
*Fabian Hader,Jan Vogelbruch,Simon Humpohl,Tobias Hangleiter,Chimezie Eguzo,Stefan Heinen,Stefanie Meyer,Stefan van Waasen*

Main category: cond-mat.mes-hall

TL;DR: 本研究旨在优化门控量子点系统中的传感点灵敏度，通过评估和选择最佳噪声估计器来精确测量量子点的电荷和自旋状态，Chen et al. 的方法被证明是最有效的。


<details>
  <summary>Details</summary>
Motivation: 为了在门控量子点系统中，通过传感点的电导测量来精确地观察量子点的电荷和自旋状态，需要优化传感点的静电灵敏度。

Method: 评估和优化了多种现有噪声估计器，并对它们进行了修改以适应一维数据，然后基于模拟数据分析了它们的质量。

Result:  Chen et al. 的噪声估计器被证明最适合此应用，并且所提出的算法在实际测量数据中显示了其相关性和适用性。

Conclusion: 确定用于量子点电荷和自旋状态测量的传感点最佳工作状态，需要精确的噪声估计，Chen et al. 的噪声估计器在所测应用中表现最佳。

Abstract: In gate-defined quantum dot systems, the conductance change of
electrostatically coupled sensor dots allows the observation of the quantum
dots' charge and spin states. Therefore, the sensor dot must be optimally
sensitive to changes in its electrostatic environment. A series of conductance
measurements varying the two sensor-dot-forming barrier gate voltages serve to
tune the dot into a corresponding operating regime. In this paper, we analyze
the noise characteristics of the measured data and define a criterion to
identify continuous regions with a sufficient signal-gradient-to-noise ratio.
Hence, accurate noise estimation is required when identifying the optimal
operating regime. Therefore, we evaluate several existing noise estimators,
modify them for 1D data, optimize their parameters, and analyze their quality
based on simulated data. The estimator of Chen et al. turns out to be best
suited for our application concerning minimally scattering results.
Furthermore, using this estimator in an algorithm for flank-of-interest
classification in measured data shows the relevance and applicability of our
approach.

</details>


### [639] [Simulation of Charge Stability Diagrams for Automated Tuning Solutions (SimCATS)](https://arxiv.org/abs/2508.08032)
*Fabian Hader,Sarah Fleitmann,Jan Vogelbruch,Lotte Geck,Stefan van Waasen*

Main category: cond-mat.mes-hall

TL;DR: 该文章介绍了一种新的模拟方法，用于生成量子点量子计算中电荷稳定性图（CSDs）的真实数据，以解决自动化调优算法的数据需求问题。


<details>
  <summary>Details</summary>
Motivation: 为了实现可扩展的量子计算平台，需要完全自动化量子点的调优过程，其中关键一步是捕获适量的电子，这通常通过分析电荷稳定性图（CSDs）来完成。

Method: 介绍了一种用于模拟电荷稳定性图（CSDs）及其传感器响应和失真的新方法。

Result: 开发了一个灵活的框架，可以模拟理想的CSD数据以及适当的传感器响应和失真。

Conclusion: 通过仿真对算法进行基准测试，并鼓励使用自定义模型和参数集来推动独立于技术的鲁棒算法的发展。

Abstract: Quantum dots must be tuned precisely to provide a suitable basis for quantum
computation. A scalable platform for quantum computing can only be achieved by
fully automating the tuning process. One crucial step is to trap the
appropriate number of electrons in the quantum dots, typically accomplished by
analyzing charge stability diagrams (CSDs). Training and testing automation
algorithms require large amounts of data, which can be either measured and
manually labeled in an experiment or simulated. This article introduces a new
approach to the realistic simulation of such measurements. Our flexible
framework enables the simulation of ideal CSD data complemented with
appropriate sensor responses and distortions. We suggest using this simulation
to benchmark published algorithms. Also, we encourage the extension by custom
models and parameter sets to drive the development of robust,
technology-independent algorithms. Code is available at
https://github.com/f-hader/SimCATS.

</details>


### [640] [Readout of multi-level quantum geometry from electronic transport](https://arxiv.org/abs/2508.08239)
*Raffael L. Klees,Mónica Benito*

Main category: cond-mat.mes-hall

TL;DR: 提出了一种在电子输运系统中测量量子几何张量的方法，该方法通过测量隧道电导的变化来探测系统的几何和拓扑特征。


<details>
  <summary>Details</summary>
Motivation: 填补了在电子输运系统中探测局域量子几何张量的空白，而这在之前的研究中尚未解决。

Method: 提出了一种基于弱和共振参数调制的测量方案，并通过理论证明了如何直接从隧道电导的变化中探测此类系统中的局域量子几何张量。

Result: 理论上证明了所提出的测量方案能够直接探测局域量子几何张量。

Conclusion: 该方法能够测量多种基于输运的量子系统的几何和拓扑特征。

Abstract: The quantum geometric tensor (QGT) of a quantum system in a given parameter
space captures both the geometry of the state manifold and the topology of the
system. While the local QGT elements have been successfully measured in various
platforms, the challenge of detecting them in electronic transport systems -
such as tunnel or molecular junctions - has yet to be resolved. To fill this
gap, we propose a measurement protocol based on weak and resonant parameter
modulations, and theoretically demonstrate how the local QGT in such systems
can be directly probed from changes of the tunnel conductance. This approach
enables the measurement of both geometrical and topological features of quantum
states in a broad class of transport-based quantum systems.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [641] [The Vertex-Attribute-Constrained Densest $k$-Subgraph Problem](https://arxiv.org/abs/2508.06655)
*Qiheng Lu,Nicholas D. Sidiropoulos,Aritra Konar*

Main category: cs.SI

TL;DR: 提出了一种新的最密子图挖掘问题 (VAC-DkS)，该问题考虑了顶点的属性，并使用 Frank-Wolfe 算法解决了它。实验证明该方法比经典方法更有效，尤其是在政治网络分析中。


<details>
  <summary>Details</summary>
Motivation: 在欺诈检测、社区检测、产品推荐和文档摘要等应用中，需要识别反映不同选民、风格、体裁和观点的社区、推荐或摘要。因此，需要一种能够包含顶点属性值的新型最密子图挖掘技术。

Method: 提出了一种新的顶点属性约束最密 k-子图 (VAC-DkS) 问题，该问题保留了经典 DkS 的 NP-难和近似难性质。通过证明 VAC-DkS 的连续松弛是有效的，并使用无投影的 Frank-Wolfe 算法进行有效处理。还对松弛问题的优化进行了分析。

Result: 提出的 VAC-DkS 公式和算法能够有效地处理大规模图，并且比经典的 DkS 能够发现更有意义的子图。

Conclusion: VAC-DkS 识别出的政治网络比经典的 DkS 更平衡、更有意义，能够代表不同的意识形态阵营。

Abstract: Dense subgraph mining is a fundamental technique in graph mining, commonly
applied in fraud detection, community detection, product recommendation, and
document summarization. In such applications, we are often interested in
identifying communities, recommendations, or summaries that reflect different
constituencies, styles or genres, and points of view. For this task, we
introduce a new variant of the Densest $k$-Subgraph (D$k$S) problem that
incorporates the attribute values of vertices. The proposed
Vertex-Attribute-Constrained Densest $k$-Subgraph (VAC-D$k$S) problem retains
the NP-hardness and inapproximability properties of the classical D$k$S.
Nevertheless, we prove that a suitable continuous relaxation of VAC-D$k$S is
tight and can be efficiently tackled using a projection-free Frank--Wolfe
algorithm. We also present an insightful analysis of the optimization landscape
of the relaxed problem. Extensive experimental results demonstrate the
effectiveness of our proposed formulation and algorithm, and its ability to
scale up to large graphs. We further elucidate the properties of VAC-D$k$S
versus classical D$k$S in a political network mining application, where
VAC-D$k$S identifies a balanced and more meaningful set of politicians
representing different ideological camps, in contrast to the classical D$k$S
solution which is unbalanced and rather mundane.

</details>


### [642] [Anatomy of a Machine Learning Ecosystem: 2 Million Models on Hugging Face](https://arxiv.org/abs/2508.06811)
*Benjamin Laufer,Hamidah Oderinwale,Jon Kleinberg*

Main category: cs.SI

TL;DR: 本研究分析了1.86亿个模型，发现微调模型形成庞大谱系，有家族相似性但变异快且有方向性。许可证趋向宽松，模型趋向英语化，模型卡片趋于模板化。


<details>
  <summary>Details</summary>
Motivation: 尽管预训练模型被广泛用于下游任务的微调，但对这些交互结构的研究却有限。本研究旨在通过实证分析，探究模型微调的结构和模式。

Method: 利用进化生物学的方法，分析了Hugging Face上1.86亿个模型的“模型家族树”（连接微调模型与其基础/父模型的网络）。通过模型元数据和模型卡片，衡量了模型家族的遗传相似性和特征变异。

Result: 模型微调形成了庞大的谱系，大小和结构各异。模型倾向于表现出“家族相似性”，但其变异方式不同于无性繁殖，变异快且有方向性，兄弟模型比亲子模型更相似。许可证从限制性漂移到宽松性，模型兼容性从多语言转向英语，模型卡片变短并趋于模板化。

Conclusion: 该研究通过分析Hugging Face上的186万个模型，揭示了模型微调的谱系结构和进化模式。研究发现，模型之间存在“家族相似性”，但其变异方式不同于无性繁殖，变异速度快且有方向性，兄弟模型比亲子模型更相似。此外，研究还观察到许可证从限制性向宽松性漂移、模型从多语言兼容转向仅英语兼容，以及模型卡片长度缩短和模板化等现象，这些都为了解开放机器学习生态系统提供了新的见解。

Abstract: Many have observed that the development and deployment of generative machine
learning (ML) and artificial intelligence (AI) models follow a distinctive
pattern in which pre-trained models are adapted and fine-tuned for specific
downstream tasks. However, there is limited empirical work that examines the
structure of these interactions. This paper analyzes 1.86 million models on
Hugging Face, a leading peer production platform for model development. Our
study of model family trees -- networks that connect fine-tuned models to their
base or parent -- reveals sprawling fine-tuning lineages that vary widely in
size and structure. Using an evolutionary biology lens to study ML models, we
use model metadata and model cards to measure the genetic similarity and
mutation of traits over model families. We find that models tend to exhibit a
family resemblance, meaning their genetic markers and traits exhibit more
overlap when they belong to the same model family. However, these similarities
depart in certain ways from standard models of asexual reproduction, because
mutations are fast and directed, such that two `sibling' models tend to exhibit
more similarity than parent/child pairs. Further analysis of the directional
drifts of these mutations reveals qualitative insights about the open machine
learning ecosystem: Licenses counter-intuitively drift from restrictive,
commercial licenses towards permissive or copyleft licenses, often in violation
of upstream license's terms; models evolve from multi-lingual compatibility
towards english-only compatibility; and model cards reduce in length and
standardize by turning, more often, to templates and automatically generated
text. Overall, this work takes a step toward an empirically grounded
understanding of model fine-tuning and suggests that ecological models and
methods can yield novel scientific insights.

</details>


### [643] [Propagation Tree Is Not Deep: Adaptive Graph Contrastive Learning Approach for Rumor Detection](https://arxiv.org/abs/2508.07201)
*Chaoqun Cui,Caiyan Jia*

Main category: cs.SI

TL;DR: Rumor detection models often assume deep tree structures, but real-world data shows wide structures. We propose RAGCL, a graph contrastive learning method that adapts to these wide structures using centrality-guided augmentation (keeping deep nodes, dropping shallow ones). RAGCL outperforms existing methods.


<details>
  <summary>Details</summary>
Motivation: Most existing graph-based models for rumor detection presume rumor propagation trees (RPTs) have deep structures and learn sequential stance features along branches. However, statistical analysis on real-world datasets indicates that RPTs exhibit wide structures, with most nodes being shallow 1-level replies. This necessitates a focus on learning from intensive substructures.

Method: We propose Rumor Adaptive Graph Contrastive Learning (RAGCL) with adaptive view augmentation guided by node centralities. Three principles for RPT augmentation are: 1) exempt root nodes, 2) retain deep reply nodes, and 3) preserve lower-level nodes in deep sections. Node dropping, attribute masking, and edge dropping with probabilities derived from centrality-based importance scores are used to generate views. A graph contrastive objective is then employed to learn robust rumor representations.

Result: RAGCL outperforms state-of-the-art methods in extensive experiments on four benchmark datasets, demonstrating its effectiveness in rumor detection by leveraging the wide-structure nature of RPTs through adaptive graph contrastive learning.

Conclusion: RAGCL in extensive experiments on four benchmark datasets demonstrates superior performance compared to state-of-the-art methods. The study reveals the wide-structure nature of RPTs and contributes an effective graph contrastive learning approach tailored for rumor detection through principled adaptive augmentation. The proposed principles and augmentation techniques have potential benefits for other applications involving tree-structured graphs.

Abstract: Rumor detection on social media has become increasingly important. Most
existing graph-based models presume rumor propagation trees (RPTs) have deep
structures and learn sequential stance features along branches. However,
through statistical analysis on real-world datasets, we find RPTs exhibit wide
structures, with most nodes being shallow 1-level replies. To focus learning on
intensive substructures, we propose Rumor Adaptive Graph Contrastive Learning
(RAGCL) method with adaptive view augmentation guided by node centralities. We
summarize three principles for RPT augmentation: 1) exempt root nodes, 2)
retain deep reply nodes, 3) preserve lower-level nodes in deep sections. We
employ node dropping, attribute masking and edge dropping with probabilities
from centrality-based importance scores to generate views. A graph contrastive
objective then learns robust rumor representations. Extensive experiments on
four benchmark datasets demonstrate RAGCL outperforms state-of-the-art methods.
Our work reveals the wide-structure nature of RPTs and contributes an effective
graph contrastive learning approach tailored for rumor detection through
principled adaptive augmentation. The proposed principles and augmentation
techniques can potentially benefit other applications involving tree-structured
graphs.

</details>


### [644] [Towards Real-World Rumor Detection: Anomaly Detection Framework with Graph Supervised Contrastive Learning](https://arxiv.org/abs/2508.07205)
*Chaoqun Cui,Caiyan Jia*

Main category: cs.SI

TL;DR: 该研究提出了一种名为AD-GSCL的框架，通过将谣言检测视为异常检测问题，并利用图监督对比学习来处理数据不平衡和稀疏性问题，在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 真实世界社交媒体数据存在类别不平衡问题，谣言数量远少于正常帖子，现有的方法在有限的标记数据上将谣言检测视为类别平衡分类任务，未能有效解决数据稀疏和不平衡问题。

Method: 提出了一种名为AD-GSCL（Anomaly Detection framework with Graph Supervised Contrastive Learning）的框架，该框架将无标签数据视为非谣言，并采用图监督对比学习来进行谣言检测。

Result: AD-GSCL在类别平衡、不平衡和少样本条件下均表现出优越性。

Conclusion: 该研究为具有不平衡数据分布的真实世界谣言检测提供了宝贵的见解。

Abstract: Current rumor detection methods based on propagation structure learning
predominately treat rumor detection as a class-balanced classification task on
limited labeled data. However, real-world social media data exhibits an
imbalanced distribution with a minority of rumors among massive regular posts.
To address the data scarcity and imbalance issues, we construct two large-scale
conversation datasets from Weibo and Twitter and analyze the domain
distributions. We find obvious differences between rumor and non-rumor
distributions, with non-rumors mostly in entertainment domains while rumors
concentrate in news, indicating the conformity of rumor detection to an anomaly
detection paradigm. Correspondingly, we propose the Anomaly Detection framework
with Graph Supervised Contrastive Learning (AD-GSCL). It heuristically treats
unlabeled data as non-rumors and adapts graph contrastive learning for rumor
detection. Extensive experiments demonstrate AD-GSCL's superiority under
class-balanced, imbalanced, and few-shot conditions. Our findings provide
valuable insights for real-world rumor detection featuring imbalanced data
distributions.

</details>


### [645] [FLUID: Flow-Latent Unified Integration via Token Distillation for Expert Specialization in Multimodal Learning](https://arxiv.org/abs/2508.07264)
*Van Duc Cuong,Ta Dinh Tam,Tran Duc Chinh,Nguyen Thi Hanh*

Main category: cs.SI

TL;DR: FLUID是一种新颖的多模态分类方法，通过令牌蒸馏实现跨模态的统一集成，提高了对噪声的鲁棒性和可扩展性，并在GLAMI-1M数据集上取得了优异的成绩。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态分类方法在融合视觉和文本信号时，通常采用的融合策略比较脆弱，容易受到特定模态噪声的影响。因此，需要一种能够提高跨模态鲁棒性和可扩展性的方法。

Method: FLUID（Flow-Latent Unified Integration via Token Distillation）提出了一种基于令牌的管道，通过Q-transforms（可学习的查询令牌）来提取和保留特定模态骨干网络中的显著令牌级特征。其特点包括：1. Q-transforms：用于从特定模态骨干网络中提取和保留显著的令牌级特征。2. 两阶段融合方案：首先通过对比对齐强制实现跨模态一致性，然后通过门控机制和Q-bottleneck（选择性压缩信息以适应下游推理）进行自适应、任务感知的融合。3. 轻量级的、负载均衡的专家混合（Mixture-of-Experts）模型：在预测时实现高效的专业化，以适应多样的语义模式。

Result: FLUID在GLAMI-1M基准测试中达到了91%的准确率，显著优于现有方法。实验证明，FLUID在面对标签噪声、长尾类别不平衡和语义异构性时表现出强大的鲁棒性。消融研究也证实了所提出组件的单独和协同效益。

Conclusion: FLUID是一种可扩展、抗噪声的多模态产品分类解决方案，在GLAMI-1M基准测试中达到了91%的准确率，显著优于现有方法，并且对标签噪声、长尾类别不平衡和语义异构性具有很强的鲁棒性。

Abstract: Multimodal classification requires robust integration of visual and textual
signals, yet common fusion strategies are brittle and vulnerable to
modality-specific noise. In this paper, we present \textsc{FLUID}-Flow-Latent
Unified Integration via Token Distillation for Expert Specialization, a
principled token-level pipeline that improves cross-modal robustness and
scalability. \textsc{FLUID} contributes three core elements: (1)
\emph{Q-transforms}, learnable query tokens that distill and retain salient
token-level features from modality-specific backbones; (2) a two-stage fusion
scheme that enforces cross-modal consistency via contrastive alignment and then
performs adaptive, task-aware fusion through a gating mechanism and a
\emph{Q-bottleneck} that selectively compresses information for downstream
reasoning; and (3) a lightweight, load-balanced Mixture-of-Experts at
prediction time that enables efficient specialization to diverse semantic
patterns. Extensive experiments demonstrate that \textsc{FLUID} attains
\(91\%\) accuracy on the GLAMI-1M benchmark, significantly outperforming prior
baselines and exhibiting strong resilience to label noise, long-tail class
imbalance, and semantic heterogeneity. Targeted ablation studies corroborate
both the individual and synergistic benefits of the proposed components,
positioning \textsc{FLUID} as a scalable, noise-resilient solution for
multimodal product classification.

</details>


### [646] [Recovering link-weight structure in complex networks with weight-aware random walks](https://arxiv.org/abs/2508.07489)
*Adilson Vital Jr.,Filipi N. Silva,Diego R. Amancio*

Main category: cs.SI

TL;DR: 本研究评估了不同的随机游走策略在节点嵌入中保留边权重信息的效果。研究发现，权重感知策略通常效果最好，但在真实世界网络中的表现各异。移除弱连接可以改善结果，但需注意适度。


<details>
  <summary>Details</summary>
Motivation: 现实世界系统中，边权重至关重要，因为链接携带了相关信息。在低维表示中保留这些信息对于分类和预测任务非常重要。

Method: 本研究通过使用网络模型、真实世界图和进行低权重边移除的网络，来系统地研究了三种不同的随机游走策略（传统的非加权、基于强度和完全权重感知）在生成节点嵌入时保留边权重信息的方式。通过衡量原始边权重与通过随机游走策略生成的嵌入空间中的节点对相似性之间的相关性，来评估不同策略的表现。

Result: 研究结果一致表明，权重感知随机游走策略显著优于其他策略，在网络模型中实现了高于0.90的相关性。然而，在真实世界网络中的表现更为多样化，受拓扑和权重分布等因素的影响。此外，通过阈值化移除弱边可以暂时提高相关性，但过度修剪会损害表示质量。

Conclusion: “保留节点嵌入中的边权重信息”的研究表明，虽然权重感知随机游走通常是最佳方法，但它并非万能解决方案，实际效果会受到网络拓扑和权重分布等因素的影响。阈值化移除弱连接可以提高相关性，但过度修剪会降低表示质量。

Abstract: Using edge weights is essential for modeling real-world systems where links
possess relevant information, and preserving this information in
low-dimensional representations is relevant for classification and prediction
tasks. This paper systematically investigates how different random walk
strategies - traditional unweighted, strength-based, and fully weight-aware -
keeps edge weight information when generating node embeddings. Using network
models, real-world graphs, and networks subjected to low-weight edge removal,
we measured the correlation between original edge weights and the similarity of
node pairs in the embedding space generated by random walk strategies. Our
results consistently showed that weight-aware random walks significantly
outperform other strategies, achieving correlations above 0.90 in network
models. However, performance in real-world networks was more heterogeneous,
influenced by factors like topology and weight distribution. Our analysis also
revealed that removing weak edges via thresholding can initially improve
correlation by reducing noise, but excessive pruning degrades representation
quality. Our findings suggest that simply using a weight-aware random walk is
generally the best approach for preserving node weight information in
embeddings, but it is not a universal solution.

</details>


### [647] [From Platform Migration to Cultural Integration: the Ingress and Diffusion of #wlw from TikTok to RedNote in Queer Women](https://arxiv.org/abs/2508.07579)
*Ziqi Pan,Runhua Zhang,Jiehui Luo,Yuanhao Zhang,Yue Deng,Xiaojuan Ma*

Main category: cs.SI

TL;DR: 本研究分析了“#wlw”标签在中国女同性恋社群的引入和传播过程，发现该标签的成功传播得益于用户迁移和跨文化互动，并最终成为分享酷儿生活和支持女权主义话语的重要标签。


<details>
  <summary>Details</summary>
Motivation: 研究美国TikTok临时禁令引发的用户迁移事件，探讨跨文化标签的引入和传播，以及网络移民中的人群响应行为。

Method: 通过对2022年1月和4月418个#wlw帖子的两阶段内容分析，研究了标签引入和传播期间的不同使用模式。

Result: “#wlw”标签的引入得益于TikTok移民的大胆引入、两个群体间的相互解读以及RedNote用户的讨论。在传播过程中，“#wlw”已成为RedNote上公认的分享酷儿生活的酷儿标签，并在语义上扩展到支持女权主义话语。

Conclusion: “#wlw”标签成功引入并传播，成为RedNote上用于分享酷儿生活和支持女权主义话语的酷儿标签，为边缘化社群的跨文化交流提供了经验见解。

Abstract: Hashtags serve as identity markers and connection tools in online queer
communities. Recently, the Western-origin #wlw (women-loving-women) hashtag has
risen in the Chinese lesbian community on RedNote, coinciding with user
migration triggered by the temporary US TikTok ban. This event provides a
unique lens to study cross-cultural hashtag ingress and diffusion through the
populations' responsive behaviors in cyber-migration. In this paper, we
conducted a two-phase content analysis of 418 #wlw posts from January and
April, examining different usage patterns during the hashtag's ingress and
diffusion. Results indicate that the successful introduction of #wlw was
facilitated by TikTok immigrants' bold importation, both populations' mutual
interpretation, and RedNote natives' discussions. In current manifestation of
diffusion, #wlw becomes a RedNote-recognized queer hashtag for sharing queer
life, and semantically expands to support feminism discourse. Our findings
provide empirical insights for enhancing the marginalized communities'
cross-cultural communication.

</details>


### [648] [Fabricating Holiness: Characterizing Religious Misinformation Circulators on Arabic Social Media](https://arxiv.org/abs/2508.07845)
*Mahmoud Fawzi,Björn Ross,Walid Magdy*

Main category: cs.SI

TL;DR: 该研究通过量化方法分析了阿拉伯社交媒体上伪造圣训的传播，识别了传播者和揭穿者的不同特征。


<details>
  <summary>Details</summary>
Motivation: 研究宗教方面错误信息，特别是阿拉伯社交媒体上伪造圣训的传播，填补了现有研究的空白，并旨在通过量化方法理解与此类信息互动的用户特征。

Method: 使用逻辑回归模型自动预测用户行为，并通过分析模型权重来深入了解传播者和揭穿者的特征与兴趣。

Result: 研究发现，传播者和揭穿者都与宗教账户有联系，但传播者更关注逊尼派的特定群体和内容，而揭穿者则更关注学术和广泛的非宗教话题。

Conclusion: 该研究量化分析了阿拉伯社交媒体上伪造圣训的传播，并识别了传播者和揭穿者的特征。传播者倾向于关注海湾国家的逊尼派公众人物和发布伊斯兰内容的逊尼派非专业页面，而揭穿者则倾向于关注学术伊斯兰学者，并对慈善、政治和激进主义等非宗教话题有更多兴趣。

Abstract: Misinformation is a growing concern in a decade involving critical global
events. While social media regulation is mainly dedicated towards the detection
and prevention of fake news and political misinformation, there is limited
research about religious misinformation which has only been addressed through
qualitative approaches. In this work, we study the spread of fabricated quotes
(Hadith) that are claimed to belong to Prophet Muhammad (the prophet of Islam)
as a case study demonstrating one of the most common religious misinformation
forms on Arabic social media. We attempt through quantitative methods to
understand the characteristics of social media users who interact with
fabricated Hadith. We spotted users who frequently circulate fabricated Hadith
and others who frequently debunk it to understand the main differences between
the two groups. We used Logistic Regression to automatically predict their
behaviors and analyzed its weights to gain insights about the characteristics
and interests of each group. We find that both fabricated Hadith circulators
and debunkers have generally a lot of ties to religious accounts. However,
circulators are identified by many accounts that follow the Shia branch of
Islam, Sunni Islamic public figures from the gulf countries, and many Sunni
non-professional pages posting Islamic content. On the other hand, debunkers
are identified by following academic Islamic scholars from multiple countries
and by having more intellectual non-religious interests like charity, politics,
and activism.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [649] [A Tight Lower Bound for the Approximation Guarantee of Higher-Order Singular Value Decomposition](https://arxiv.org/abs/2508.06693)
*Matthew Fahrbach,Mehrdad Ghadiri*

Main category: cs.DS

TL;DR: HOSVD、ST-HOSVD 和 HOOI 的近似保证被证明是紧确的，并且其近似比率无法进一步提高。


<details>
  <summary>Details</summary>
Motivation: 证明经典高阶奇异值分解（HOSVD）的近似保证是紧确的，并改进了 ST-HOSVD 和 HOOI 算法的近似保证。

Method: 通过构造特定张量，证明了 HOSVD 的近似上界是紧确的，其比率接近 N/(1+ε)。同样，也证明了 ST-HOSVD 和 HOOI 算法的最坏情况近似比也是 N/(1+ε)，其中 ε 可以任意小。

Result: HOSVD 的近似比率匹配了 De Lathauwer 等人（2000a）的上界。ST-HOSVD 和 HOOI 算法也能达到其最坏情况近似比率 N/(1+ε)，其中 ε > 0。

Conclusion: HOSVD、ST-HOSVD 和 HOOI 的近似保证是紧确的，其近似比无法进一步提高。

Abstract: We prove that the classic approximation guarantee for the higher-order
singular value decomposition (HOSVD) is tight by constructing a tensor for
which HOSVD achieves an approximation ratio of $N/(1+\varepsilon)$, for any
$\varepsilon > 0$. This matches the upper bound of De Lathauwer et al. (2000a)
and shows that the approximation ratio of HOSVD cannot be improved. Using a
more advanced construction, we also prove that the approximation guarantees for
the ST-HOSVD algorithm of Vannieuwenhoven et al. (2012) and higher-order
orthogonal iteration (HOOI) of De Lathauwer et al. (2000b) are tight by showing
that they can achieve their worst-case approximation ratio of $N / (1 +
\varepsilon)$, for any $\varepsilon > 0$.

</details>


### [650] [Approximating High-Dimensional Earth Mover's Distance as Fast as Closest Pair](https://arxiv.org/abs/2508.06774)
*Lorenzo Beretta,Vincent Cohen-Addad,Rajesh Jayaram,Erik Waingarten*

Main category: cs.DS

TL;DR: 本研究提出了一种将近似地球搬运距离 (EMD) 规约到近似最近点对 (CP) 的方法，并改进了高维 EMD 的近似算法。


<details>
  <summary>Details</summary>
Motivation: 为了改进高维 EMD 的近似算法，特别是利用 CP 问题的最新进展。

Method: 通过子线性实现多权重更新框架，利用底层几何结构隐式执行更新，无需显式计算或存储权重。

Result: 当 $(1+\varepsilon)$-近似 CP 可在 $n^{2-\phi}$ 时间内计算时，EMD 的 $1+O(\varepsilon)$ 近似可在 $n^{2-\Omega(\phi)}$ 时间内计算。结合 CP 的最快算法，实现了针对高维点集的 EMD $(1+\varepsilon)$ 近似算法，运行时间为 $n^{2-\tilde{\Omega}(\varepsilon^{1/3})}$，优于先前 $n^{2-\Omega(\varepsilon^2)}$ 的运行时间。

Conclusion: 该研究将 $(1+\varepsilon)$-近似地球搬运距离 (EMD) 规约到 $(1+\varepsilon)$-近似最近点对 (CP)，从而改进了高维 EMD 的最快近似算法。

Abstract: We give a reduction from $(1+\varepsilon)$-approximate Earth Mover's Distance
(EMD) to $(1+\varepsilon)$-approximate Closest Pair (CP). As a consequence, we
improve the fastest known approximation algorithm for high-dimensional EMD.
Here, given $p\in [1, 2]$ and two sets of $n$ points $X,Y \subseteq (\mathbb
R^d,\ell_p)$, their EMD is the minimum cost of a perfect matching between $X$
and $Y$, where the cost of matching two vectors is their $\ell_p$ distance.
Further, CP is the basic problem of finding a pair of points realizing $\min_{x
\in X, y\in Y} ||x-y||_p$. Our contribution is twofold: we show that if a
$(1+\varepsilon)$-approximate CP can be computed in time $n^{2-\phi}$, then a
$1+O(\varepsilon)$ approximation to EMD can be computed in time
$n^{2-\Omega(\phi)}$; plugging in the fastest known algorithm for CP [Alman,
Chan, Williams FOCS'16], we obtain a $(1+\varepsilon)$-approximation algorithm
for EMD running in time $n^{2-\tilde{\Omega}(\varepsilon^{1/3})}$ for
high-dimensional point sets, which improves over the prior fastest running time
of $n^{2-\Omega(\varepsilon^2)}$ [Andoni, Zhang FOCS'23]. Our main technical
contribution is a sublinear implementation of the Multiplicative Weights Update
framework for EMD. Specifically, we demonstrate that the updates can be
executed without ever explicitly computing or storing the weights; instead, we
exploit the underlying geometric structure to perform the updates implicitly.

</details>


### [651] [Controlling tail risk in two-slope ski rental](https://arxiv.org/abs/2508.06809)
*Qiming Cui,Michael Dinitz*

Main category: cs.DS

TL;DR: 对具有尾部风险的双斜率滑雪租赁问题进行了研究，提出了新的最优解结构和计算算法。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决一个一般性的双斜率滑雪租赁问题，并考虑尾部风险，即竞争比超过某个值 γ 的概率有界（不超过 δ）。这是对现有滑雪租赁尾部界限研究的扩展，并试图模拟现实世界中“租买”场景，即一次性投资可以降低但不能完全消除每次的时间成本。

Method: 该研究通过结构定理来表征最优解的特征，并利用这些定理设计了两种算法：一种是基于贪心算法结合二分查找的快速算法，另一种是基于线性规划的精确算法。

Result: 研究发现，即使是简单的扩展，尾部风险约束也导致了根本不同的最优解结构，例如，最优解可能永远不购买，或者在购买成本对应时间点之后，以非平凡的概率进行购买。此外，在许多情况下，不存在唯一的最优解。研究为此开发了结构定理，并设计了两种算法来计算最优解，一种是近似最优解的快速算法，另一种是精确最优解的慢速算法。

Conclusion: 该研究为具有尾部风险的双斜率滑雪租赁问题提供了结构定理和算法。

Abstract: We study the optimal solution to a general two-slope ski rental problem with
a tail risk, i.e., the chance of the competitive ratio exceeding a value
$\gamma$ is bounded by $\delta$. This extends the recent study of tail bounds
for ski rental by [Dinitz et al. SODA 2024] to the two-slope version defined by
[Lotker et al. IPL 2008]. In this version, even after "buying," we must still
pay a rental cost at each time step, though it is lower after buying. This
models many real-world "rent-or-buy" scenarios where a one-time investment
decreases (but does not eliminate) the per-time cost.
  Despite this being a simple extension of the classical problem, we find that
adding tail risk bounds creates a fundamentally different solution structure.
For example, in our setting there is a possibility that we never buy in an
optimal solution (which can also occur without tail bounds), but more strangely
(and unlike the case without tail bounds or the classical case with tail
bounds) we also show that the optimal solution might need to have nontrivial
probabilities of buying even at finite points beyond the time corresponding to
the buying cost. Moreover, in many regimes there does not exist a unique
optimal solution. As our first contribution, we develop a series of structure
theorems to characterize some features of optimal solutions.
  The complex structure of optimal solutions makes it more difficult to develop
an algorithm to compute such a solution. As our second contribution, we utilize
our structure theorems to design two algorithms: one based on a greedy
algorithm combined with binary search that is fast but yields arbitrarily close
to optimal solutions, and a slower algorithm based on linear programming which
computes exact optimal solutions.

</details>


### [652] [A near-linear time approximation scheme for $(k,\ell)$-median clustering under discrete Fréchet distance](https://arxiv.org/abs/2508.07008)
*Anne Driemel,Jan Höckendorff,Ioannis Psarros,Christian Sohler*

Main category: cs.DS

TL;DR: 本研究提出了一种新颖的维度约减技术，并将其应用于现有的 (k,ℓ)-median 算法，以在离散 Fréchet 距离下实现近线性时间 (1+ε) 近似。该方法不仅解决了大规模 k 值的问题，还改进了核构造的大小，使其不依赖于输入数据的复杂性。


<details>
  <summary>Details</summary>
Motivation: 解决离散 Fréchet 距离下的 (k,ℓ)-median 问题，并改进了相关的核构造。

Method: 通过引入新的维度约减技术，并将其应用于 Cohen-Addad 等人（J. ACM 2021）的算法，解决了离散 Fréchet 距离下的 (k,ℓ)-median 问题。

Result: 实现了近线性时间 (1+ε) 近似算法，并将核构造的尺寸独立于输入时间序列的数量及其复杂度。

Conclusion: 该论文为离散 Fréchet 距离下的 (k,ℓ)-median 问题提出了首个近线性时间 (1+ε) 近似算法，适用于 l 和 ε 为常数但 k 可达 Ω(n) 的情况。该算法通过引入新的维度约减技术，并将其应用于 Cohen-Addad 等人（J. ACM 2021）的算法。

Abstract: A time series of complexity $m$ is a sequence of $m$ real valued
measurements. The discrete Fr\'echet distance $d_{dF}(x,y)$ is a distance
measure between two time series $x$ and $y$ of possibly different complexity.
Given a set of $n$ time series represented as $m$-dimensional vectors over the
reals, the $(k,\ell)$-median problem under discrete Fr\'echet distance aims to
find a set $C$ of $k$ time series of complexity $\ell$ such that $$\sum_{x\in
P} \min_{c\in C} d_{dF}(x,c)$$ is minimized. In this paper, we give the first
near-linear time $(1+\varepsilon)$-approximation algorithm for this problem
when $\ell$ and $\varepsilon$ are constants but $k$ can be as large as
$\Omega(n)$. We obtain our result by introducing a new dimension reduction
technique for discrete Fr\'echet distance and then adapt an algorithm of
Cohen-Addad et al. (J. ACM 2021) to work on the dimension-reduced input. As a
byproduct we also improve the best coreset construction for $(k,\ell)$-median
under discrete Fr\'echet distance (Cohen-Addad et al., SODA 2025) and show that
its size can be independent of the number of input time series \emph{ and }
their complexity.

</details>


### [653] [Unbiased Insights: Optimal Streaming Algorithms for $\ell_p$ Sampling, the Forget Model, and Beyond](https://arxiv.org/abs/2508.07067)
*Honghao Lin,Hoai-An Nguyen,William Swartworth,David P. Woodruff*

Main category: cs.DS

TL;DR: 该论文提出了用于数据流的$\\\ell_p$采样和频率估计的新算法，解决了三个开放性问题，并在空间效率方面取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 为了解决Pavan等人提出的关于数据流中的$\\\ell_p$采样和频率估计问题的三个开放性问题。

Method: 使用$\\\ell_p$采样和频率估计技术。

Result: 在数据流环境中，为$\\\ell_p$估计和熵估计设计了近乎最优的算法。

Conclusion: 该研究为p∈(0,2)的几乎空间最优估计器提供了一个使用$\	ilde O(\\\log n \\log(1/\\delta))$比特空间通过了优化，并且为p=2的估计器提供了$\\\tilde O(\\\log^2 n \\log(1/\\delta))$空间复杂度。

Abstract: We study $\ell_p$ sampling and frequency moment estimation in a single-pass
insertion-only data stream. For $p \in (0,2)$, we present a nearly
space-optimal approximate $\ell_p$ sampler that uses $\widetilde{O}(\log n
\log(1/\delta))$ bits of space and for $p = 2$, we present a sampler with space
complexity $\widetilde{O}(\log^2 n \log(1/\delta))$. This space complexity is
optimal for $p \in (0, 2)$ and improves upon prior work by a $\log n$ factor.
We further extend our construction to a continuous $\ell_p$ sampler, which
outputs a valid sample index at every point during the stream.
  Leveraging these samplers, we design nearly unbiased estimators for $F_p$ in
data streams that include forget operations, which reset individual element
frequencies and introduce significant non-linear challenges. As a result, we
obtain near-optimal algorithms for estimating $F_p$ for all $p$ in this model,
originally proposed by Pavan, Chakraborty, Vinodchandran, and Meel [PODS'24],
resolving all three open problems they posed.
  Furthermore, we generalize this model to what we call the suffix-prefix
deletion model, and extend our techniques to estimate entropy as a corollary of
our moment estimation algorithms. Finally, we show how to handle arbitrary
coordinate-wise functions during the stream, for any $g \in \mathbb{G}$, where
$\mathbb{G}$ includes all (linear or non-linear) contraction functions.

</details>


### [654] [Optimizing Districting Plans to Maximize Majority-Minority Districts via IPs and Local Search](https://arxiv.org/abs/2508.07446)
*Daniel Brous,David Shmoys*

Main category: cs.DS

TL;DR: 本研究提出了一种基于整数规划和列生成的新方法，以生成更多的多数少数族裔选区，优于现有的“短爆发”算法。


<details>
  <summary>Details</summary>
Motivation: 为了在重新划分选区诉讼中更有效地执行《投票权法案》，需要生成包含更多多数少数族裔选区的选区规划。

Method: 提出了一种基于整数规划的新方法，通过列生成算法来优化多数少数族裔选区，并结合了新的局部再优化算法和增加选区紧凑性的算法。

Result: 新方法在生成州级选区规划方面优于“短爆发”算法，能够生成显著更多数量的多数少数族裔选区，并且可以提高选区的紧凑性而不会影响多数少数族裔选区的数量。

Conclusion: 本研究提出了一种基于整数规划和列生成算法的新方法，旨在优化多数少数族裔选区，并在多个数据集上生成比现有“短爆发”算法具有更多多数少数族裔选区的州级选区规划。

Abstract: In redistricting litigation, effective enforcement of the Voting Rights Act
has often involved providing the court with districting plans that display a
larger number of majority-minority districts than the current proposal (as was
true, for example, in what followed Allen v. Milligan concerning the
congressional districting plan for Alabama in 2023). Recent work by Cannon et
al. proposed a heuristic algorithm for generating plans to optimize
majority-minority districts, which they called short bursts; that algorithm
relies on a sophisticated random walk over the space of all plans,
transitioning in bursts, where the initial plan for each burst is the most
successful plan from the previous burst. We propose a method based on integer
programming, where we build upon another previous work, the stochastic
hierarchical partitioning algorithm, which heuristically generates a robust set
of potential districts (viewed as columns in a standard set partitioning
formulation); that approach was designed to optimize a different notion of
fairness across a statewide plan. We design a new column generation algorithm
to find plans via integer programming that outperforms short bursts on multiple
data sets in generating statewide plans with significantly more
majority-minority districts. These results also rely on a new local
re-optimization algorithm to iteratively improve on any baseline solution, as
well as an algorithm to increase the compactness of districts in plans
generated (without impacting the number of majority-minority districts).

</details>


### [655] [Simple Algorithms for Fully Dynamic Edge Connectivity](https://arxiv.org/abs/2508.07783)
*Yotam Kenneth-Mordoch,Robert Krauthgamer*

Main category: cs.DS

TL;DR: 本文提出了两种解决动态图边连通性问题的随机化算法，其中一种在特定条件下能实现更优的更新与查询时间。


<details>
  <summary>Details</summary>
Motivation: 旨在解决图的边插入和删除操作下，维护图的边连通性问题。

Method: 本文提出了两种随机化算法，第一种算法的更新时间复杂度为~O(n)，第二种算法的更新时间复杂度为~O(n/λG)，查询时间复杂度为~O(n²/λG²)。

Result: 第一种算法的更新时间与已知界匹配但分析更简单；第二种算法在λG = ω(√n)时，更新和查询时间复杂度达到o(n)。

Conclusion: 本文提出了两种解决全动态图边连通性问题的随机化算法，其中第二种算法在边连通度较大时（λG = ω(√n)）实现了o(n)的更新与查询时间。

Abstract: In the fully dynamic edge connectivity problem, the input is a simple graph
$G$ undergoing edge insertions and deletions, and the goal is to maintain its
edge connectivity, denoted $\lambda_G$. We present two simple randomized
algorithms solving this problem. The first algorithm maintains the edge
connectivity in worst-case update time $\tilde{O}(n)$ per edge update, matching
the known bound but with simpler analysis. Our second algorithm achieves
worst-case update time $\tilde{O}(n/\lambda_G)$ and worst-case query time
$\tilde{O}(n^2/\lambda_G^2)$, which is the first algorithm with worst-case
update and query time $o(n)$ for large edge connectivity, namely, $\lambda_G =
\omega(\sqrt{n})$.

</details>


### [656] [Nearly Optimal Bounds for Stochastic Online Sorting](https://arxiv.org/abs/2508.07823)
*Yang Hu*

Main category: cs.DS

TL;DR: 研究了在线排序的随机版本，并提出了一种接近最优的算法，其期望成本为 log n * 2^O(log* n)。


<details>
  <summary>Details</summary>
Motivation: 研究随机版本的在线排序问题，其中输入项是均匀随机抽样的。之前的算法未能充分利用随机性，仅达到 O(n^1/4) 的成本。

Method: 提出一个算法，该算法实现了对数 n 乘以 2 的 O(log* n) 的期望成本，并证明了对数 n 的成本下界。

Result: 提出了一种接近最优的算法，期望成本为 log n * 2^O(log* n)，并证明了 log n 的成本下界。

Conclusion: 通过提出一个算法，该算法实现了对数 n 乘以 2 的 O(log* n) 的期望成本，并且证明了对数 n 的成本下界，从而表明该算法接近最优。

Abstract: In the online sorting problem, we have an array $A$ of $n$ cells, and receive
a stream of $n$ items $x_1,\dots,x_n\in [0,1]$. When an item arrives, we need
to immediately and irrevocably place it into an empty cell. The goal is to
minimize the sum of absolute differences between adjacent items, which is
called the \emph{cost} of the algorithm. It has been shown by Aamand,
Abrahamsen, Beretta, and Kleist (SODA 2023) that when the stream
$x_1,\dots,x_n$ is generated adversarially, the optimal cost bound for any
deterministic algorithm is $\Theta(\sqrt{n})$.
  In this paper, we study the stochastic version of online sorting, where the
input items $x_1,\dots,x_n$ are sampled uniformly at random. Despite the
intuition that the stochastic version should yield much better cost bounds, the
previous best algorithm for stochastic online sorting by Abrahamsen, Bercea,
Beretta, Klausen and Kozma (ESA 2024) only achieves $\tilde{O}(n^{1/4})$ cost,
which seems far from optimal. We show that stochastic online sorting indeed
allows for much more efficient algorithms, by presenting an algorithm that
achieves expected cost $\log n\cdot 2^{O(\log^* n)}$. We also prove a cost
lower bound of $\Omega(\log n)$, thus show that our algorithm is nearly
optimal.

</details>


### [657] [Sparsifying Cayley Graphs on Every Group](https://arxiv.org/abs/2508.08078)
*Jun-Ting Hsieh,Daniel Z. Lee,Sidhanth Mohanty,Aaron Putterman,Rachel Yun Zhang*

Main category: cs.DS

TL;DR: 本研究证明了任何群G上的凯莱图都存在其谱稀疏化器，并提出了一个有效的算法。此外，还研究了非阿贝尔群上线性方程的稀疏化问题，并与凯莱图稀疏化进行了区分。


<details>
  <summary>Details</summary>
Motivation: 尽管已有图论中的经典结果表明任何图都承认一个（1±ε）割（或谱）稀疏化器，但当应用于凯莱图时，结果的稀疏化器不再必然是凯莱图。这促使研究人员探索是否存在凯莱图的谱稀疏化器，其稀疏化器仍然是凯莱图。

Method: 提出了一种新的算法来寻找凯莱图的谱稀疏化器，该算法适用于所有群G，并且可以扩展到有向凯莱图的割稀疏化。

Result: 证明了对于任何群G，其凯莱图都存在稀疏化器，该稀疏化器仅保留O(n/ε^2)条边，并且可以通过一个有效的算法找到。此外，研究还发现非阿贝尔群上的线性方程的稀疏化与阿贝尔群上的情况有显著不同，需要保留超多项式数量的方程才能近似保持满足方程的数量。

Conclusion: 该研究首次证明了任何群G上的所有凯莱图都允许仅保留多对数（|G|）/ε^2个重新加权的生成器的稀疏化器，并提出了一个有效的算法来寻找它们。该算法甚至可以扩展到有向凯莱图，如果只要求割稀疏化而不是谱稀疏化。

Abstract: A classic result in graph theory, due to Batson, Spielman, and Srivastava
(STOC 2009) shows that every graph admits a $(1 \pm \varepsilon)$ cut (or
spectral) sparsifier which preserves only $O(n / \varepsilon^2)$ reweighted
edges. However, when applying this result to \emph{Cayley graphs}, the
resulting sparsifier is no longer necessarily a Cayley graph -- it can be an
arbitrary subset of edges.
  Thus, a recent line of inquiry, and one which has only seen minor progress,
asks: for any group $G$, do all Cayley graphs over the group $G$ admit
sparsifiers which preserve only $\mathrm{polylog}(|G|)/\varepsilon^2$ many
re-weighted generators?
  As our primary contribution, we answer this question in the affirmative,
presenting a proof of the existence of such Cayley graph spectral sparsifiers,
along with an efficient algorithm for finding them. Our algorithm even extends
to \emph{directed} Cayley graphs, if we instead ask only for cut sparsification
instead of spectral sparsification.
  We additionally study the sparsification of linear equations over non-abelian
groups. In contrast to the abelian case, we show that for non-abelian valued
equations, super-polynomially many linear equations must be preserved in order
to approximately preserve the number of satisfied equations for any input.
Together with our Cayley graph sparsification result, this provides a formal
separation between Cayley graph sparsification and sparsifying linear
equations.

</details>


### [658] [Sparsifying Sums of Positive Semidefinite Matrices](https://arxiv.org/abs/2508.08169)
*Arpon Basu,Pravesh K. Kothari,Yang P. Liu,Raghu Meka*

Main category: cs.DS

TL;DR: 本文针对正半定（PSD）矩阵和的谱稀疏化问题，提出了一种新的基于连通性阈值 N*(A) 的理论。主要结果是开发出一种能将稀疏器使用的矩阵数量限制在 O(ε^-2 N*(A) (log n)(log r)) 内的算法，并证明了该方法在凯莱图稀疏化上的应用，提供了优于以往的生成元数量上界。


<details>
  <summary>Details</summary>
Motivation: 为了解决任意正半定（PSD）矩阵和的谱稀疏化问题，并为凯莱图的凯莱稀疏化提供新的解决方案。

Method: 本文基于新的连通性阈值 N*(A) 理论，该理论概括了使图连通所需的边数阈值，来开发新的、实例特定的 PSD 矩阵稀疏化理论。

Result: 本文提出了一种新的 PSD 矩阵稀疏化方法，其稀疏器使用的矩阵数量至多为 O(ε^-2 N*(A) (log n)(log r))，并且可以通过随机多项式时间构建。此外，证明了任何凯莱图都可以被稀疏化到 O(ε^-2 log^4 N) 个生成元。

Conclusion: 该论文证明了任何凯莱图都可以被稀疏化到 O(ε^-2 log^4 N) 个生成元。之前，仅在群为 F_2^n 的情况下才对凯莱稀疏器有非平凡的上界。

Abstract: In this paper, we revisit spectral sparsification for sums of arbitrary
positive semidefinite (PSD) matrices. Concretely, for any collection of PSD
matrices $\mathcal{A} = \{A_1, A_2, \ldots, A_r\} \subset \mathbb{R}^{n \times
n}$, given any subset $T \subseteq [r]$, our goal is to find sparse weights
$\mu \in \mathbb{R}_{\geq 0}^r$ such that $(1 - \epsilon) \sum_{i \in T} A_i
\preceq \sum_{i \in T} \mu_i A_i \preceq (1 + \epsilon) \sum_{i \in T} A_i.$
This generalizes spectral sparsification of graphs which corresponds to
$\mathcal{A}$ being the set of Laplacians of edges. It also captures
sparsifying Cayley graphs by choosing a subset of generators. The former has
been extensively studied with optimal sparsifiers known. The latter has
received attention recently and was solved for a few special groups (e.g.,
$\mathbb{F}_2^n$).
  Prior work shows any sum of PSD matrices can be sparsified down to $O(n)$
elements. This bound however turns out to be too coarse and in particular
yields no non-trivial bound for building Cayley sparsifiers for Cayley graphs.
  In this work, we develop a new, instance-specific (i.e., specific to a given
collection $\mathcal{A}$) theory of PSD matrix sparsification based on a new
parameter $N^*(\mathcal{A})$ which we call connectivity threshold that
generalizes the threshold of the number of edges required to make a graph
connected.
  Our main result gives a sparsifier that uses at most
$O(\epsilon^{-2}N^*(\mathcal{A}) (\log n)(\log r))$ matrices and is
constructible in randomized polynomial time. We also show that we need
$N^*(\mathcal{A})$ elements to sparsify for any $\epsilon < 0.99$.
  As the main application of our framework, we prove that any Cayley graph can
be sparsified to $O(\epsilon^{-2}\log^4 N)$ generators. Previously, a
non-trivial bound on Cayley sparsifiers was known only in the case when the
group is $\mathbb{F}_2^n$.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [659] [Solving Pasur Using GPU-Accelerated Counterfactual Regret Minimization](https://arxiv.org/abs/2508.06559)
*Sina Baghal*

Main category: cs.AI

TL;DR: 该研究提出了一种 CUDA 加速的计算框架，用于模拟扑克牌游戏 Pasur，并通过反事实遗憾最小化（CFR）计算近纳什均衡。该框架通过优化内存和处理复杂规则，能够处理大型游戏树，并利用训练好的模型和 GPU 加速进行大规模自我对弈，最终估计牌组的公平价值。


<details>
  <summary>Details</summary>
Motivation: 解决扑克牌游戏（Pasur）由于其复杂的规则和巨大的游戏树而带来的计算挑战，并利用 CUDA 加速来模拟游戏和计算近纳什均衡。

Method: 提出了一种利用 PyTorch CUDA 张量处理复杂规则和内存密集型游戏的方法，通过将游戏树分解为实际游戏状态和继承分数来优化内存，并采用从后往前的训练策略来处理计算复杂性。最终，通过训练基于树的模型来预测策略，并利用 GPU 加速进行大规模自我对弈来估计公平价值。

Result: 成功构建了一个包含超过 10 亿个节点的游戏树，并计算出了近纳什均衡策略。通过大规模自我对弈（例如，每个对局模拟 10,000 场比赛），估计了牌组的公平价值。

Conclusion: 该框架能够处理具有复杂规则和大型游戏树的扑克牌游戏，通过反事实遗憾最小化（CFR）计算近纳什均衡，并训练模型进行策略预测，最终通过大规模自我对弈估计牌组的公平价值。

Abstract: Pasur is a fishing card game played over six rounds and is played similarly
to games such as Cassino and Scopa, and Bastra. This paper introduces a
CUDA-accelerated computational framework for simulating Pasur, emphasizing
efficient memory management. We use our framework to compute near-Nash
equilibria via Counterfactual Regret Minimization (CFR), a well-known algorithm
for solving large imperfect-information games.
  Solving Pasur presents unique challenges due to its intricate rules and the
large size of its game tree. We handle rule complexity using PyTorch CUDA
tensors and to address the memory-intensive nature of the game, we decompose
the game tree into two key components: (1) actual game states, and (2)
inherited scores from previous rounds. We construct the Full Game Tree by
pairing card states with accumulated scores in the Unfolding Process. This
design reduces memory overhead by storing only essential strategy values and
node connections. To further manage computational complexity, we apply a
round-by-round backward training strategy, starting from the final round and
recursively propagating average utilities to earlier stages. Our approach
constructs the complete game tree, which on average consists of over $10^9$
nodes. We provide detailed implementation snippets.
  After computing a near-Nash equilibrium strategy, we train a tree-based model
to predict these strategies for use during gameplay. We then estimate the fair
value of each deck through large-scale self-play between equilibrium strategies
by simulating, for instance, 10,000 games per matchup, executed in parallel
using GPU acceleration.
  Similar frameworks can be extended to other reinforcement learning algorithms
where the action tree naturally decomposes into multiple rounds such as
turn-based strategy games or sequential trading decisions in financial markets.

</details>


### [660] [Operationalizing Serendipity: Multi-Agent AI Workflows for Enhanced Materials Characterization with Theory-in-the-Loop](https://arxiv.org/abs/2508.06569)
*Lance Yao,Suman Samantray,Ayana Ghosh,Kevin Roccapriore,Libor Kovarik,Sarah Allec,Maxim Ziatdinov*

Main category: cs.AI

TL;DR: SciLink 是一个人工智能框架，旨在通过自动化链接实验观察、新颖性评估和理论模拟来增强材料研究中的偶然发现。


<details>
  <summary>Details</summary>
Motivation: 现代自主实验室在加速假设检验方面表现出色，但其对效率的优化存在忽略重要的、计划外的发现的风险。为了解决这一差距，我们引入了 SciLink，这是一个开源的、多代理的人工智能框架，旨在通过在实验观察、新颖性评估和理论模拟之间建立直接的自动化链接，来操作化材料研究中的偶然性。

Method: SciLink 框架采用混合人工智能策略，其中专门的机器学习模型对实验数据进行定量分析，而大型语言模型则处理更高级别的推理。这些代理器能够自动将材料表征技术的原始数据转换为可证伪的科学主张，然后根据已发表的文献对其新颖性进行定量评分。

Result: 我们展示了该框架在各种研究场景中的多功能性，包括其在原子分辨率和高光谱数据方面的应用、集成实时人类专家指导的能力以及通过提出有针对性的后续实验来闭合研究循环的能力。

Conclusion: SciLink 框架为材料研究中的人工智能驱动的研究提供了一个实用的框架，它不仅提高了效率，而且积极培养了有利于偶然发现的环境，从而弥合了自动化实验与开放式科学探索之间的差距。

Abstract: The history of science is punctuated by serendipitous discoveries, where
unexpected observations, rather than targeted hypotheses, opened new fields of
inquiry. While modern autonomous laboratories excel at accelerating hypothesis
testing, their optimization for efficiency risks overlooking these crucial,
unplanned findings. To address this gap, we introduce SciLink, an open-source,
multi-agent artificial intelligence framework designed to operationalize
serendipity in materials research by creating a direct, automated link between
experimental observation, novelty assessment, and theoretical simulations. The
framework employs a hybrid AI strategy where specialized machine learning
models perform quantitative analysis of experimental data, while large language
models handle higher-level reasoning. These agents autonomously convert raw
data from materials characterization techniques into falsifiable scientific
claims, which are then quantitatively scored for novelty against the published
literature. We demonstrate the framework's versatility across diverse research
scenarios, showcasing its application to atomic-resolution and hyperspectral
data, its capacity to integrate real-time human expert guidance, and its
ability to close the research loop by proposing targeted follow-up experiments.
By systematically analyzing all observations and contextualizing them, SciLink
provides a practical framework for AI-driven materials research that not only
enhances efficiency but also actively cultivates an environment ripe for
serendipitous discoveries, thereby bridging the gap between automated
experimentation and open-ended scientific exploration.

</details>


### [661] [IRL-VLA: Training an Vision-Language-Action Policy via Reward World Model](https://arxiv.org/abs/2508.06571)
*Anqing Jiang,Yu Gao,Yiru Wang,Zhigang Sun,Shuo Wang,Yuwen Heng,Hao Sun,Shichen Tang,Lijuan Zhu,Jinhao Chai,Jijun Wang,Zichong Gu,Hao Jiang,Li Sun*

Main category: cs.AI

TL;DR: IRL-VLA通过结合逆强化学习和VLA方法，利用轻量级奖励世界模型实现了高效的闭环强化学习，并在自动驾驶任务中取得了优异的成果。


<details>
  <summary>Details</summary>
Motivation: 解决现有VLA模型在开放循环设置下的模仿学习限制（倾向于学习数据集中的记录行为，导致性能次优且受限）以及闭环训练对高保真传感器模拟的依赖（存在域差距和计算效率低下问题）。

Method: 提出了一种新颖的闭环强化学习方法IRL-VLA，该方法结合了逆强化学习（IRL）的奖励世界模型和自建的VLA方法。该框架分为三个阶段：1. 提出VLA架构并通过模仿学习预训练VLA策略。2. 通过IRL构建轻量级奖励世界模型以实现高效的闭环奖励计算。3. 设计了专门的奖励世界模型引导强化学习（PPO），以有效平衡安全事故、舒适驾驶和交通效率。

Result: 在NAVSIM v2端到端驾驶基准测试中取得最先进的性能，并在CVPR2025自动驾驶挑战赛中获得1st runner up。

Conclusion: IRL-VLA框架在NAVSIM v2端到端驾驶基准测试中取得了最先进的性能，并在CVPR2025自动驾驶挑战赛中获得亚军，有望加速闭环自动驾驶中VLA的研究。

Abstract: Vision-Language-Action (VLA) models have demonstrated potential in autonomous
driving. However, two critical challenges hinder their development: (1)
Existing VLA architectures are typically based on imitation learning in
open-loop setup which tends to capture the recorded behaviors in the dataset,
leading to suboptimal and constrained performance, (2) Close-loop training
relies heavily on high-fidelity sensor simulation, where domain gaps and
computational inefficiencies pose significant barriers. In this paper, we
introduce IRL-VLA, a novel close-loop Reinforcement Learning via
\textbf{I}nverse \textbf{R}einforcement \textbf{L}earning reward world model
with a self-built VLA approach. Our framework proceeds in a three-stage
paradigm: In the first stage, we propose a VLA architecture and pretrain the
VLA policy via imitation learning. In the second stage, we construct a
lightweight reward world model via inverse reinforcement learning to enable
efficient close-loop reward computation. To further enhance planning
performance, finally, we design specialized reward world model guidence
reinforcement learning via PPO(Proximal Policy Optimization) to effectively
balance the safety incidents, comfortable driving, and traffic efficiency. Our
approach achieves state-of-the-art performance in NAVSIM v2 end-to-end driving
benchmark, 1st runner up in CVPR2025 Autonomous Grand Challenge. We hope that
our framework will accelerate VLA research in close-loop autonomous driving.

</details>


### [662] [CountQA: How Well Do MLLMs Count in the Wild?](https://arxiv.org/abs/2508.06585)
*Jayant Sravan Tamarapalli,Rynaa Grover,Nilay Pande,Sahiti Yerramilli*

Main category: cs.AI

TL;DR: 多模态大语言模型（MLLMs）在对象计数方面存在严重缺陷，本研究提出的CountQA基准（包含1500+真实世界图像）评估了15个模型，发现最佳模型准确率仅42.9%，且随对象数增加而降低，揭示了模型在计数能力上的不足。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）虽然在理解视觉场景方面表现出色，但在对象计数这一基本认知技能上存在明显缺陷，这严重限制了它们在现实世界应用中的可靠性。现有的基准测试未能充分评估该能力，因为它们要么对象密度稀疏，要么局限于特定视觉领域，无法在真实条件下测试模型。

Method: 本研究通过引入一个名为CountQA的新基准来解决多模态大语言模型（MLLMs）在对象计数方面的不足。CountQA包含超过1500对问答，涵盖了具有高对象密度、混乱和遮挡的真实世界图像。研究人员评估了15个主流MLLMs在CountQA基准上的表现。

Result: 研究发现，即使是表现最好的模型在CountQA基准上的准确率也仅为42.9%，并且随着对象数量的增加，模型的性能会下降。这一结果凸显了当前MLLMs在对象计数方面的普遍弱点。

Conclusion: CountQA旨在为多模态大语言模型（MLLMs）提供一个用于评估和改进其对象计数能力的基准。通过引入包含高密度、混乱和遮挡的真实世界图像的CountQA基准，并评估了15个MLLMs，研究揭示了当前模型在该技能上的显著不足，即使是最佳模型也仅达到42.9%的准确率，且准确率随对象数量增加而下降。该研究为开发更可靠、在现实世界应用中更具鲁棒性的MLLMs铺平了道路。

Abstract: Multimodal Large Language Models (MLLMs) demonstrate remarkable fluency in
understanding visual scenes, yet they exhibit a critical lack in a fundamental
cognitive skill: object counting. This blind spot severely limits their
reliability in real-world applications. To date, this capability has been
largely unevaluated in complex scenarios, as existing benchmarks either feature
sparse object densities or are confined to specific visual domains, failing to
test models under realistic conditions. Addressing this gap, we introduce
CountQA, a challenging new benchmark designed to probe this deficiency.
Comprising over 1,500 question-answer pairs, CountQA features real-world images
with high object density, clutter, and occlusion. We investigate this weakness
by evaluating 15 prominent MLLMs on the CountQA benchmark and reveal that the
top-performing model achieves a mere 42.9% accuracy, with performance declining
as object counts rise. By providing a dedicated benchmark to diagnose and
rectify this core weakness, CountQA paves the way for a new generation of MLLMs
that are not only descriptively fluent but also numerically grounded and
spatially aware. We will open-source the dataset and code upon paper acceptance
to foster further research.

</details>


### [663] [KIRETT: Knowledge-Graph-Based Smart Treatment Assistant for Intelligent Rescue Operations](https://arxiv.org/abs/2508.07834)
*Mubaris Nadeem,Johannes Zenkert,Lisa Bender,Christian Weber,Madjid Fathi*

Main category: cs.AI

TL;DR: 本文提出了一种基于知识图谱的智能急救系统，利用AI技术为急救人员提供实时的治疗建议，以应对日益增长的急救需求。


<details>
  <summary>Details</summary>
Motivation: 随着人口结构变化和健康风险增加，急救需求日益增长。急救人员需要在紧急情况下快速、个性化地提供医疗救助，但往往知识掌握不足，需要辅助和建议。

Method: 本文提出了一种基于知识图谱的知识管理方法，利用人工智能进行预识别，为急救人员提供智能化的治疗建议。

Result: 所提出的知识图谱方法能够为急救人员提供及时的、经过评估和处理的知识，以改进治疗效果。

Conclusion: 知识图谱作为一种集中的知识表示，为急救人员提供了一种创新的知识管理，能够通过人工智能进行预识别，从而提供智能化的治疗建议。

Abstract: Over the years, the need for rescue operations throughout the world has
increased rapidly. Demographic changes and the resulting risk of injury or
health disorders form the basis for emergency calls. In such scenarios, first
responders are in a rush to reach the patient in need, provide first aid, and
save lives. In these situations, they must be able to provide personalized and
optimized healthcare in the shortest possible time and estimate the patients
condition with the help of freshly recorded vital data in an emergency
situation. However, in such a timedependent situation, first responders and
medical experts cannot fully grasp their knowledge and need assistance and
recommendation for further medical treatments. To achieve this, on the spot
calculated, evaluated, and processed knowledge must be made available to
improve treatments by first responders. The Knowledge Graph presented in this
article as a central knowledge representation provides first responders with an
innovative knowledge management that enables intelligent treatment
recommendations with an artificial intelligence-based pre-recognition of the
situation.

</details>


### [664] [Formal Concept Analysis: a Structural Framework for Variability Extraction and Analysis](https://arxiv.org/abs/2508.06668)
*Jessie Galasso*

Main category: cs.AI

TL;DR: FCA is a mathematical framework for knowledge discovery that organizes objects based on shared attributes, making it suitable for variability analysis. This paper highlights essential FCA properties for variability analysis and demonstrates how to interpret variability information within its resulting conceptual structures.


<details>
  <summary>Details</summary>
Motivation: To bridge the gap in understanding how FCA properties can be leveraged for variability-related tasks.

Method: Gathering a selection of properties of the framework which are essential to variability analysis.

Result: Conceptual structures that highlight commonalities and variabilities among similar objects by categorizing them into groups arranged by similarity.

Conclusion:  FCA can be used to interpret diverse variability information within conceptual structures.

Abstract: Formal Concept Analysis (FCA) is a mathematical framework for knowledge
representation and discovery. It performs a hierarchical clustering over a set
of objects described by attributes, resulting in conceptual structures in which
objects are organized depending on the attributes they share. These conceptual
structures naturally highlight commonalities and variabilities among similar
objects by categorizing them into groups which are then arranged by similarity,
making it particularly appropriate for variability extraction and analysis.
Despite the potential of FCA, determining which of its properties can be
leveraged for variability-related tasks (and how) is not always
straightforward, partly due to the mathematical orientation of its foundational
literature. This paper attempts to bridge part of this gap by gathering a
selection of properties of the framework which are essential to variability
analysis, and how they can be used to interpret diverse variability information
within the resulting conceptual structures.

</details>


### [665] [Probabilistic Circuits for Knowledge Graph Completion with Reduced Rule Sets](https://arxiv.org/abs/2508.06706)
*Jaikrishna Manojkumar Patil,Nathaniel Lee,Al Mehdi Saadat Chowdhury,YooJung Choi,Paulo Shakarian*

Main category: cs.AI

TL;DR: 该研究提出了一种基于概率电路学习规则上下文的方法，以减少知识图谱补全中规则数量，同时保持甚至提高性能，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 基于规则的方法在知识图谱补全中可解释性强，但需要大量规则才能达到有竞争力的性能，这可能因规则集过大而影响可解释性。

Method: 发现规则上下文（共同作用的有意义的规则子集），并使用学习到的关于这些规则上下文的概率分布（概率电路）来比使用完整规则集更快地获得性能。

Result: 在使用的规则数量上实现了70-96%的减少，在规则数量等效时比基线方法高出31倍，并且在最小规则集与基线完整规则集进行比较时，保留了91%的峰值基线性能。

Conclusion: 该方法通过使用概率电路学习规则上下文，在保持较高性能的同时显著减少了规则数量，并在8个标准基准数据集上进行了验证，表现优于现有的基于规则的知识图谱补全方法。

Abstract: Rule-based methods for knowledge graph completion provide explainable results
but often require a significantly large number of rules to achieve competitive
performance. This can hinder explainability due to overwhelmingly large rule
sets. We discover rule contexts (meaningful subsets of rules that work
together) from training data and use learned probability distribution (i.e.
probabilistic circuits) over these rule contexts to more rapidly achieve
performance of the full rule set. Our approach achieves a 70-96% reduction in
number of rules used while outperforming baseline by up to 31$\times$ when
using equivalent minimal number of rules and preserves 91% of peak baseline
performance even when comparing our minimal rule sets against baseline's full
rule sets. We show that our framework is grounded in well-known semantics of
probabilistic logic, does not require independence assumptions, and that our
tractable inference procedure provides both approximate lower bounds and exact
probability of a given query. The efficacy of our method is validated by
empirical studies on 8 standard benchmark datasets where we show competitive
performance by using only a fraction of the rules required by AnyBURL's
standard inference method, the current state-of-the-art for rule-based
knowledge graph completion. This work may have further implications for general
probabilistic reasoning over learned sets of rules.

</details>


### [666] [Zero-Shot Cellular Trajectory Map Matching](https://arxiv.org/abs/2508.06674)
*Weijie Shi,Yue Cui,Hao Chen,Jiaming Li,Mengze Li,Jia Zhu,Jiajie Xu,Xiaofang Zhou*

Main category: cs.AI

TL;DR: 提出了一种新颖的零样本 CTMM 方法，通过像素级轨迹校准和先进的机器学习技术（如 VAE 和高斯混合模型）提高了准确性，实验证明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有 CTMM 方法依赖于 ID 和区域特定数据，难以适应新区域。零样本 CTMM 需要提取区域自适应特征、序列信息和位置不确定性，以克服细胞数据中的定位误差。

Method: 提出了一种像素级轨迹校准辅助方法，结合高斯混合模型、变分自编码器（VAE）和空间-时间感知模块，用于零样本 CTMM。

Result: 在零样本 CTMM 方面比现有方法提高了 16.8%。

Conclusion: 该研究提出了一种用于零样本 CTMM 的像素级轨迹校准辅助方法，该方法利用可迁移的地理空间知识来校准像素化轨迹，并在道路网络级别指导路径查找过程。通过结合高斯混合模型和变分自编码器（VAE），该模型能够通过软聚类识别场景自适应专家。同时，空间-时间感知模块用于捕获序列特征和位置不确定性，以减轻定位误差。最终，采用约束路径查找算法来重建道路 ID 序列，确保道路网络内的拓扑有效性，并优化最短可行路径。实验证明，该模型在零样本 CTMM 方面比现有方法提高了 16.8%。

Abstract: Cellular Trajectory Map-Matching (CTMM) aims to align cellular location
sequences to road networks, which is a necessary preprocessing in
location-based services on web platforms like Google Maps, including navigation
and route optimization. Current approaches mainly rely on ID-based features and
region-specific data to learn correlations between cell towers and roads,
limiting their adaptability to unexplored areas. To enable high-accuracy CTMM
without additional training in target regions, Zero-shot CTMM requires to
extract not only region-adaptive features, but also sequential and location
uncertainty to alleviate positioning errors in cellular data. In this paper, we
propose a pixel-based trajectory calibration assistant for zero-shot CTMM,
which takes advantage of transferable geospatial knowledge to calibrate
pixelated trajectory, and then guide the path-finding process at the road
network level. To enhance knowledge sharing across similar regions, a Gaussian
mixture model is incorporated into VAE, enabling the identification of
scenario-adaptive experts through soft clustering. To mitigate high positioning
errors, a spatial-temporal awareness module is designed to capture sequential
features and location uncertainty, thereby facilitating the inference of
approximate user positions. Finally, a constrained path-finding algorithm is
employed to reconstruct the road ID sequence, ensuring topological validity
within the road network. This process is guided by the calibrated trajectory
while optimizing for the shortest feasible path, thus minimizing unnecessary
detours. Extensive experiments demonstrate that our model outperforms existing
methods in zero-shot CTMM by 16.8\%.

</details>


### [667] [GLIDR: Graph-Like Inductive Logic Programming with Differentiable Reasoning](https://arxiv.org/abs/2508.06716)
*Blair Johnson,Clayton Kerce,Faramarz Fekri*

Main category: cs.AI

TL;DR: GLIDR is a new differentiable ILP method that uses a message passing algorithm to learn logic rules with more complex structures (branches, cycles) than previous methods. It outperforms existing methods on knowledge graph completion, is robust to noise, and can be integrated with deep neural networks.


<details>
  <summary>Details</summary>
Motivation: Existing differentiable ILP techniques assume chain-like rule structures, which can hinder performance and interpretability. GLIDR addresses this by modeling logic rule inference with more expressive syntax.

Method: GLIDR uses a differentiable message passing inference algorithm that generalizes previous chain-like rule learning methods to allow rules with features like branches and cycles. GLIDR has a simple and expressive rule search space which is parameterized by a limit on the maximum number of free variables that may be included in a rule.

Result: GLIDR significantly outperforms existing rule learning methods on knowledge graph completion tasks and competes with embedding methods, despite being a structure-only prediction method.

Conclusion: GLIDR can be chained with deep neural networks and optimized end-to-end for rule learning on arbitrary data modalities. Rules extracted from GLIDR retain significant predictive performance, and GLIDR is highly robust to training data noise.

Abstract: Differentiable inductive logic programming (ILP) techniques have proven
effective at finding approximate rule-based solutions to link prediction and
node classification problems on knowledge graphs; however, the common
assumption of chain-like rule structure can hamper the performance and
interpretability of existing approaches. We introduce GLIDR, a differentiable
rule learning method that models the inference of logic rules with more
expressive syntax than previous methods. GLIDR uses a differentiable message
passing inference algorithm that generalizes previous chain-like rule learning
methods to allow rules with features like branches and cycles. GLIDR has a
simple and expressive rule search space which is parameterized by a limit on
the maximum number of free variables that may be included in a rule. Explicit
logic rules can be extracted from the weights of a GLIDR model for use with
symbolic solvers. We demonstrate that GLIDR can significantly outperform
existing rule learning methods on knowledge graph completion tasks and even
compete with embedding methods despite the inherent disadvantage of being a
structure-only prediction method. We show that rules extracted from GLIDR
retain significant predictive performance, and that GLIDR is highly robust to
training data noise. Finally, we demonstrate that GLIDR can be chained with
deep neural networks and optimized end-to-end for rule learning on arbitrary
data modalities.

</details>


### [668] [Best-Effort Policies for Robust Markov Decision Processes](https://arxiv.org/abs/2508.07790)
*Alessandro Abate,Thom Badings,Giuseppe De Giacomo,Francesco Fabiano*

Main category: cs.AI

TL;DR: 本研究提出了一种新的策略选择标准ORBE，用于打破RMDP中最优鲁棒策略之间的僵局，并证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 标准鲁棒马尔可夫决策过程（RMDP）的最优鲁棒策略在最坏情况下是等价的，但在非对抗性选择的转换概率下，可能反映了不同的期望回报。因此，需要一个改进的策略选择标准来打破最优鲁棒策略之间的僵局。

Method: 提出了一种改进的策略选择标准，即最优鲁棒尽力而为（ORBE）策略，该策略在不同（即非完全对抗）的转换概率下，实现了最大化期望回报，并证明了ORBE策略的存在性、结构特征，并提出了一种计算算法。

Result: ORBE策略总是存在的，其结构得到了表征，并且提出了一种与标准鲁棒价值迭代相比开销很小的计算算法。数值实验表明了该方法的可行性。

Conclusion: ORBE策略是标准鲁棒策略的改进，在不完全对抗的转换概率下，可以实现最大的期望回报，并且ORBE策略总是存在的。

Abstract: We study the common generalization of Markov decision processes (MDPs) with
sets of transition probabilities, known as robust MDPs (RMDPs). A standard goal
in RMDPs is to compute a policy that maximizes the expected return under an
adversarial choice of the transition probabilities. If the uncertainty in the
probabilities is independent between the states, known as s-rectangularity,
such optimal robust policies can be computed efficiently using robust value
iteration. However, there might still be multiple optimal robust policies,
which, while equivalent with respect to the worst-case, reflect different
expected returns under non-adversarial choices of the transition probabilities.
Hence, we propose a refined policy selection criterion for RMDPs, drawing
inspiration from the notions of dominance and best-effort in game theory.
Instead of seeking a policy that only maximizes the worst-case expected return,
we additionally require the policy to achieve a maximal expected return under
different (i.e., not fully adversarial) transition probabilities. We call such
a policy an optimal robust best-effort (ORBE) policy. We prove that ORBE
policies always exist, characterize their structure, and present an algorithm
to compute them with a small overhead compared to standard robust value
iteration. ORBE policies offer a principled tie-breaker among optimal robust
policies. Numerical experiments show the feasibility of our approach.

</details>


### [669] [ParBalans: Parallel Multi-Armed Bandits-based Adaptive Large Neighborhood Search](https://arxiv.org/abs/2508.06736)
*Alican Yilmaz,Junyang Cai,Serdar Kadioglu,Bistra Dilkina*

Main category: cs.AI

TL;DR: This paper introduces ParBalans, a parallelized version of the Balans algorithm for solving Mixed-Integer Programming (MIP) problems. ParBalans shows competitive performance against Gurobi, a leading commercial solver, especially on difficult problem instances.


<details>
  <summary>Details</summary>
Motivation: To address the need for accelerated solution times and enhanced scalability for Mixed-Integer Programming (MIP) problems by investigating and extending the parallelization capabilities of the Balans algorithm.

Method: The paper investigates the parallelization capabilities of Balans, a multi-armed bandits-based adaptive large neighborhood search for MIPs, and introduces ParBalans, an extension that leverages both solver-level and algorithmic-level parallelism.

Result: Experimental results show that ParBalans exhibits competitive performance compared to the state-of-the-art commercial solver Gurobi, particularly on hard optimization benchmarks.

Conclusion: ParBalans, an extension of Balans that utilizes solver-level and algorithmic-level parallelism, demonstrates competitive performance against Gurobi on challenging MIP instances.

Abstract: Solving Mixed-Integer Programming (MIP) problems often requires substantial
computational resources due to their combinatorial nature. Parallelization has
emerged as a critical strategy to accelerate solution times and enhance
scalability to tackle large, complex instances. This paper investigates the
parallelization capabilities of Balans, a recently proposed multi-armed
bandits-based adaptive large neighborhood search for MIPs. While Balans's
modular architecture inherently supports parallel exploration of diverse
parameter configurations, this potential has not been thoroughly examined. To
address this gap, we introduce ParBalans, an extension that leverages both
solver-level and algorithmic-level parallelism to improve performance on
challenging MIP instances. Our experimental results demonstrate that ParBalans
exhibits competitive performance compared to the state-of-the-art commercial
solver Gurobi, particularly on hard optimization benchmarks.

</details>


### [670] [Topology Generation of UAV Covert Communication Networks: A Graph Diffusion Approach with Incentive Mechanism](https://arxiv.org/abs/2508.06746)
*Xin Tang,Qian Chen,Fengshun Li,Youchun Gong,Yinqiu Liu,Wen Tian,Shaowen Qin,Xiaohuan Li*

Main category: cs.AI

TL;DR: 提出了一种结合GDPO和SG激励机制的无人机网络框架，以应对动态移动性和暴露风险的挑战，并提升隐蔽通信性能。


<details>
  <summary>Details</summary>
Motivation: 为了满足在城市监控、应急响应和安全传感等敏感应用中对无人机（UAV）网络日益增长的需求，确保可靠的连接和隐蔽通信变得至关重要。然而，动态移动性和暴露风险带来了重大挑战。

Method: 本研究提出了一种结合基于图扩散策略优化（GDPO）和基于Stackelberg博弈（SG）的激励机制的自组织无人机网络框架。GDPO利用生成式AI动态生成稀疏但连接良好的拓扑，以适应节点分布和地面用户需求的动态变化。SG激励机制则引导无人机选择支持协作和增强隐蔽通信的中继行为和邻居链路。

Result: 通过大量的实验验证了所提出的框架在模型收敛性、拓扑生成质量以及隐蔽通信性能提升方面的有效性。

Conclusion: 该研究提出的自组织无人机网络框架结合了基于图扩散策略优化（GDPO）和基于Stackelberg博弈（SG）的激励机制，在提高模型收敛性、拓扑生成质量以及增强隐蔽通信性能方面均验证了其有效性。

Abstract: With the growing demand for Uncrewed Aerial Vehicle (UAV) networks in
sensitive applications, such as urban monitoring, emergency response, and
secure sensing, ensuring reliable connectivity and covert communication has
become increasingly vital. However, dynamic mobility and exposure risks pose
significant challenges. To tackle these challenges, this paper proposes a
self-organizing UAV network framework combining Graph Diffusion-based Policy
Optimization (GDPO) with a Stackelberg Game (SG)-based incentive mechanism. The
GDPO method uses generative AI to dynamically generate sparse but
well-connected topologies, enabling flexible adaptation to changing node
distributions and Ground User (GU) demands. Meanwhile, the Stackelberg Game
(SG)-based incentive mechanism guides self-interested UAVs to choose relay
behaviors and neighbor links that support cooperation and enhance covert
communication. Extensive experiments are conducted to validate the
effectiveness of the proposed framework in terms of model convergence, topology
generation quality, and enhancement of covert communication performance.

</details>


### [671] [Pushing the Envelope of LLM Inference on AI-PC](https://arxiv.org/abs/2508.06753)
*Evangelos Georganas,Dhiraj Kalamkar,Alexander Heinecke*

Main category: cs.AI

TL;DR: 研究通过优化CPU微内核并集成到PyTorch-TPP框架，显著提升了超低比特大语言模型在边缘设备的推理速度，最高可达现有SOTA运行时的2.2倍。


<details>
  <summary>Details</summary>
Motivation: 为了探索和提升超低比特大语言模型（1/1.58/2比特）在资源受限环境（如边缘设备和AI PC）下的推理效率，因为现有SOTA推理运行时的计算效率尚未得到充分研究。

Method: 该研究采用自下而上的方法，首先设计并实现了针对现代CPU优化的1比特和2比特微内核，然后在PyTorch-TPP这一先进的大语言模型推理框架中集成了这些微内核，并展示了端到端的推理结果。

Result: 集成了优化的微内核的PyTorch-TPP框架，在2比特模型上的端到端推理性能比现有的SOTA运行时bitnet.cpp快2.2倍，并且比16比特模型快7倍。

Conclusion: 该研究通过设计和实现优化的1比特和2比特微内核，并将它们集成到PyTorch-TPP框架中，显著提高了超低比特大语言模型在CPU上的推理效率，其性能超越了现有的SOTA运行时bitnet.cpp达2.2倍，并比16比特模型快7倍，为在资源受限环境（如边缘设备和AI PC）中高效部署大语言模型铺平了道路。

Abstract: The advent of ultra-low-bit LLM models (1/1.58/2-bit), which match the
perplexity and end-task performance of their full-precision counterparts using
the same model size, is ushering in a new era of LLM inference for
resource-constrained environments such as edge devices and AI PCs. While these
quantization advances promise models that are more cost-effective in terms of
latency, memory, throughput, and energy consumption, the computational
efficiency of state-of-the-art (SOTA) inference runtimes (e.g., bitnet.cpp)
used to deploy them remains underexplored. In this work, we take a bottom-up
approach: we first design and implement 1-bit and 2-bit microkernels optimized
for modern CPUs, achieving peak computational efficiency across a variety of
CPU platforms. We integrate these microkernels into a state-of-the-art LLM
inference framework, namely PyTorch-TPP, and present end-to-end inference
results with 2-bit models that outperform the current SOTA runtime bitnet.cpp
by up to 2.2x, and deliver up to 7x speedup compared to the 16-bit model
inference. Our optimized runtime advances the state of LLM inference on AI PCs
and edge devices, paving the way for efficient deployment of ultra-low-bit LLM
models.

</details>


### [672] [K-Dense Analyst: Towards Fully Automated Scientific Analysis](https://arxiv.org/abs/2508.07043)
*Orion Li,Vinayak Agarwal,Summer Zhou,Ashwin Gopinath,Timothy Kassis*

Main category: cs.AI

TL;DR: K-Dense Analyst 是一个创新的多代理系统，通过其双循环架构显著提高了生物信息学分析的自主性和准确性，在 BixBench 基准测试中超越了 GPT-5 和单独的 Gemini 2.5 Pro。


<details>
  <summary>Details</summary>
Motivation: 现代生物信息学分析的复杂性在数据生成与科学洞察发展之间造成了关键差距。大型语言模型（LLMs）在科学推理方面显示出潜力，但在处理需要迭代计算、工具集成和严格验证的实际分析工作流时仍然存在根本性限制。

Method: K-Dense Analyst 是一个分层多代理系统，它使用双循环架构将复杂的目标分解为可在安全计算环境中执行和验证的任务。

Result: 在针对开放式生物分析的综合基准 BixBench 上，K-Dense Analyst 的准确率达到 29.2%，超过了性能最佳的语言模型 (GPT-5) 6.3 个百分点，比目前最强大的 LLM（被广泛认为）有了近 27% 的提升。值得注意的是，K-Dense Analyst 使用 Gemini 2.5 Pro 取得了这一性能，而 Gemini 2.5 Pro 单独使用时准确率仅为 18.3%，这表明我们的架构创新所解锁的能力远远超出了底层模型的基线性能。

Conclusion: K-Dense Analyst 是一个分层多代理系统，通过双循环架构实现了自主生物信息学分析。它通过结合规划和经验证的执行，以及专门的代理，将复杂的目标分解为可在安全计算环境中执行和验证的任务。

Abstract: The complexity of modern bioinformatics analysis has created a critical gap
between data generation and developing scientific insights. While large
language models (LLMs) have shown promise in scientific reasoning, they remain
fundamentally limited when dealing with real-world analytical workflows that
demand iterative computation, tool integration and rigorous validation. We
introduce K-Dense Analyst, a hierarchical multi-agent system that achieves
autonomous bioinformatics analysis through a dual-loop architecture. K-Dense
Analyst, part of the broader K-Dense platform, couples planning with validated
execution using specialized agents to decompose complex objectives into
executable, verifiable tasks within secure computational environments. On
BixBench, a comprehensive benchmark for open-ended biological analysis, K-Dense
Analyst achieves 29.2% accuracy, surpassing the best-performing language model
(GPT-5) by 6.3 percentage points, representing nearly 27% improvement over what
is widely considered the most powerful LLM available. Remarkably, K-Dense
Analyst achieves this performance using Gemini 2.5 Pro, which attains only
18.3% accuracy when used directly, demonstrating that our architectural
innovations unlock capabilities far beyond the underlying model's baseline
performance. Our insights demonstrate that autonomous scientific reasoning
requires more than enhanced language models, it demands purpose-built systems
that can bridge the gap between high-level scientific objectives and low-level
computational execution. These results represent a significant advance toward
fully autonomous computational biologists capable of accelerating discovery
across the life sciences.

</details>


### [673] [A Fuzzy Logic Prompting Framework for Large Language Models in Adaptive and Uncertain Tasks](https://arxiv.org/abs/2508.06754)
*Vanessa Figueiredo*

Main category: cs.AI

TL;DR: "提出一种模块化提示框架，用于LLM在动态任务中的安全自适应使用，借鉴了近侧发展区理论，通过结合自然语言边界提示和模糊控制模式，无需微调即可实现自适应，并在教育和游戏等领域展现出潜力。"


<details>
  <summary>Details</summary>
Motivation: "本研究旨在为大型语言模型（LLM）在动态、以用户为中心的任务中提供一种更安全、更具适应性的使用框架，特别关注在教育等交互性强的领域。"

Method: "该方法结合了基于人类学习理论（特别是近侧发展区）的自然语言边界提示，以及一套包含模糊脚手架逻辑和适应规则的控制模式。"

Result: "在模拟的智能辅导环境中，该框架提高了脚手架质量、自适应性和教学一致性，并且在多种模型上均优于标准的提示基线。评估是通过大规模的、基于评分标准的LLM评估进行的。"

Conclusion: "该框架通过结合自然语言边界提示、模糊脚手架逻辑和适应规则，实现了语言模型在用户中心任务中的安全和自适应使用。它在模拟的智能辅导环境中，提高了脚手架质量、自适应性和教学一致性，优于标准提示基线。该框架旨在安全部署，为在不确定的或不断发展的环境中构建可解释的、以目标为导向的语言模型行为提供了一种可重用的方法，并在游戏等领域显示出应用前景."

Abstract: We introduce a modular prompting framework that supports safer and more
adaptive use of large language models (LLMs) across dynamic, user-centered
tasks. Grounded in human learning theory, particularly the Zone of Proximal
Development (ZPD), our method combines a natural language boundary prompt with
a control schema encoded with fuzzy scaffolding logic and adaptation rules.
This architecture enables LLMs to modulate behavior in response to user state
without requiring fine-tuning or external orchestration. In a simulated
intelligent tutoring setting, the framework improves scaffolding quality,
adaptivity, and instructional alignment across multiple models, outperforming
standard prompting baselines. Evaluation is conducted using rubric-based LLM
graders at scale. While initially developed for education, the framework has
shown promise in other interaction-heavy domains, such as procedural content
generation for games. Designed for safe deployment, it provides a reusable
methodology for structuring interpretable, goal-aligned LLM behavior in
uncertain or evolving contexts.

</details>


### [674] [Multi-Dimensional Summarization Agents with Context-Aware Reasoning over Enterprise Tables](https://arxiv.org/abs/2508.07186)
*Amit Dhanda*

Main category: cs.AI

TL;DR: 提出了一种新的多智能体框架，利用LLM智能体来总结多维企业数据，解决了传统方法在处理分层结构和上下文变化方面的局限性，并在忠实度、覆盖范围和相关性方面取得了更好的结果。


<details>
  <summary>Details</summary>
Motivation: 传统的表格到文本模型往往缺乏跨越分层结构和上下文感知变化的推理能力，而这些对于业务报告任务至关重要。

Method: 提出了一种新颖的框架，使用基于大语言模型（LLM）的智能体来总结企业结构化数据跨越多个维度。该方法引入了一个多智能体流水线，利用用于切片、方差检测、上下文构建和基于LLM的生成的智能体来提取、分析和总结多维数据。

Result: 所提出的框架在忠实度（83%）、对显著变化的覆盖范围以及决策关键见解的相关性得分（4.4/5）方面优于传统方法。

Conclusion: 该框架在处理涉及细微权衡的类别时表现出尤其显著的改进，例如价格变动带来的收入增长与单位销量下降并存的情况，而竞争方法则忽略了这些或仅进行了有限的阐述。

Abstract: We propose a novel framework for summarizing structured enterprise data
across multiple dimensions using large language model (LLM)-based agents.
Traditional table-to-text models often lack the capacity to reason across
hierarchical structures and context-aware deltas, which are essential in
business reporting tasks. Our method introduces a multi-agent pipeline that
extracts, analyzes, and summarizes multi-dimensional data using agents for
slicing, variance detection, context construction, and LLM-based generation.
Our results show that the proposed framework outperforms traditional
approaches, achieving 83\% faithfulness to underlying data, superior coverage
of significant changes, and high relevance scores (4.4/5) for decision-critical
insights. The improvements are especially pronounced in categories involving
subtle trade-offs, such as increased revenue due to price changes amid
declining unit volumes, which competing methods either overlook or address with
limited specificity. We evaluate the framework on Kaggle datasets and
demonstrate significant improvements in faithfulness, relevance, and insight
quality over baseline table summarization approaches.

</details>


### [675] [Natural Language-Driven Viewpoint Navigation for Volume Exploration via Semantic Block Representation](https://arxiv.org/abs/2508.06823)
*Xuan Zhao,Jun Tao*

Main category: cs.AI

TL;DR: 通过自然语言交互和强化学习，自动化体积数据探索中的视点选择，提高导航效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 探索体积数据对于解释科学数据集至关重要。然而，为有效的导航选择最佳视点可能具有挑战性，特别是对于没有广泛领域专业知识或熟悉3D导航的用户。

Method: 提出了一种利用自然语言交互来增强体积数据探索的新框架。该方法将体积块进行编码以捕捉和区分底层结构，并结合了提供语义信息给块以指导导航的CLIP Score机制。导航由强化学习框架支持，该框架利用这些语义线索来有效地搜索和识别与用户意图一致的期望视点。所选视点通过CLIP Score进行评估，以确保它们最能反映用户的查询。

Result: 通过自动化视点选择，提高了体积数据导航的效率，并增强了复杂科学现象的可解释性。

Conclusion: 该方法通过自动化视点选择，提高了体积数据导航的效率，并增强了复杂科学现象的可解释性。

Abstract: Exploring volumetric data is crucial for interpreting scientific datasets.
However, selecting optimal viewpoints for effective navigation can be
challenging, particularly for users without extensive domain expertise or
familiarity with 3D navigation. In this paper, we propose a novel framework
that leverages natural language interaction to enhance volumetric data
exploration. Our approach encodes volumetric blocks to capture and
differentiate underlying structures. It further incorporates a CLIP Score
mechanism, which provides semantic information to the blocks to guide
navigation. The navigation is empowered by a reinforcement learning framework
that leverage these semantic cues to efficiently search for and identify
desired viewpoints that align with the user's intent. The selected viewpoints
are evaluated using CLIP Score to ensure that they best reflect the user
queries. By automating viewpoint selection, our method improves the efficiency
of volumetric data navigation and enhances the interpretability of complex
scientific phenomena.

</details>


### [676] [Remote Sensing Image Intelligent Interpretation with the Language-Centered Perspective: Principles, Methods and Challenges](https://arxiv.org/abs/2508.06832)
*Haifeng Li,Wang Guo,Haiyang Wu,Mengwei Wu,Jipeng Zhang,Qing Zhu,Yu Liu,Xin Huang,Chao Tao*

Main category: cs.AI

TL;DR: 这篇综述文章提出了一种新的以语言为中心的遥感图像解释方法，利用大语言模型（LLMs）作为认知中心，整合多模态信息，克服了传统方法的局限性，并为未来的智能地理空间分析指明了方向。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有以视觉为中心的遥感图像解释模型在处理多模态推理、语义抽象和交互式决策方面的固有局限性，并为将大语言模型（LLMs）应用于遥感领域提供一个统一的理论框架，解释语言在认知中的作用。

Method: 文章借鉴了人类认知的全局工作区理论（GWT），提出了一种以语言为中心的遥感图像解释框架，并将大语言模型（LLMs）视为整合感知、任务、知识和行动空间的认知中心枢纽，以实现统一的理解、推理和决策。

Result: 文章探讨了LLMs作为遥感图像解释核心认知成分的潜力，总结了统一多模态表示、知识关联、推理和决策等技术挑战，并提出了一个由全局工作区驱动的解释机制，概述了多模态数据自适应对齐、动态知识约束下的任务理解、可信推理和自主交互等未来研究方向。

Conclusion: 该综述文章主张从以视觉为中心的研究范式转变为以语言为中心的研究范式，以应对当前遥感图像解释的局限性，并为下一代遥感解释系统奠定概念基础，同时为认知驱动的智能地理空间分析提供路线图。

Abstract: The mainstream paradigm of remote sensing image interpretation has long been
dominated by vision-centered models, which rely on visual features for semantic
understanding. However, these models face inherent limitations in handling
multi-modal reasoning, semantic abstraction, and interactive decision-making.
While recent advances have introduced Large Language Models (LLMs) into remote
sensing workflows, existing studies primarily focus on downstream applications,
lacking a unified theoretical framework that explains the cognitive role of
language. This review advocates a paradigm shift from vision-centered to
language-centered remote sensing interpretation. Drawing inspiration from the
Global Workspace Theory (GWT) of human cognition, We propose a
language-centered framework for remote sensing interpretation that treats LLMs
as the cognitive central hub integrating perceptual, task, knowledge and action
spaces to enable unified understanding, reasoning, and decision-making. We
first explore the potential of LLMs as the central cognitive component in
remote sensing interpretation, and then summarize core technical challenges,
including unified multimodal representation, knowledge association, and
reasoning and decision-making. Furthermore, we construct a global
workspace-driven interpretation mechanism and review how language-centered
solutions address each challenge. Finally, we outline future research
directions from four perspectives: adaptive alignment of multimodal data, task
understanding under dynamic knowledge constraints, trustworthy reasoning, and
autonomous interaction. This work aims to provide a conceptual foundation for
the next generation of remote sensing interpretation systems and establish a
roadmap toward cognition-driven intelligent geospatial analysis.

</details>


### [677] [Efficient and Reliable Hitting-Set Computations for the Implicit Hitting Set Approach](https://arxiv.org/abs/2508.07015)
*Hannes Ihalainen,Dieter Vandesande,André Schidler,Jeremias Berg,Bart Bogaerts,Matti Järvisalo*

Main category: cs.AI

TL;DR: 本研究探讨了用于隐式命题集（IHS）问题的伪布尔（PB）推理和随机局部搜索优化技术。研究发现，虽然商业整数规划（IP）求解器通常是最有效的，但PB推理可以提供更稳定和可认证的替代方案，并且在某些情况下具有可比的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决计算上困难的组合优化问题，隐式命题集（IHS）方法提供了一个通用的声明式框架。IHS在决策预言机和命题集优化器之间迭代。本研究旨在探索命题集优化的替代算法技术。

Method: 本研究探索了基于伪布尔（PB）推理和随机局部搜索的不同命题集优化算法技术。

Result: 与数值精确的IP求解器相比，基于PB推理的精确命题集计算具有竞争力。PB推理还可以为IHS计算的正确性提供证书。

Conclusion: 研究表明，虽然商业整数规划（IP）求解器在实例化命题集（HS）计算方面仍然是最有效的方法，但其数值不稳定性可能导致正确性问题。通过伪布尔（PB）推理实现的精确命题集计算可以与数值精确的IP求解器相媲美。此外，基于PB推理的命题集计算可以为隐式命题集（IHS）计算的正确性提供证书。

Abstract: The implicit hitting set (IHS) approach offers a general framework for
solving computationally hard combinatorial optimization problems declaratively.
IHS iterates between a decision oracle used for extracting sources of
inconsistency and an optimizer for computing so-called hitting sets (HSs) over
the accumulated sources of inconsistency. While the decision oracle is
language-specific, the optimizers is usually instantiated through integer
programming.
  We explore alternative algorithmic techniques for hitting set optimization
based on different ways of employing pseudo-Boolean (PB) reasoning as well as
stochastic local search. We extensively evaluate the practical feasibility of
the alternatives in particular in the context of pseudo-Boolean (0-1 IP)
optimization as one of the most recent instantiations of IHS. Highlighting a
trade-off between efficiency and reliability, while a commercial IP solver
turns out to remain the most effective way to instantiate HS computations, it
can cause correctness issues due to numerical instability; in fact, we show
that exact HS computations instantiated via PB reasoning can be made
competitive with a numerically exact IP solver. Furthermore, the use of PB
reasoning as a basis for HS computations allows for obtaining certificates for
the correctness of IHS computations, generally applicable to any IHS
instantiation in which reasoning in the declarative language at hand can be
captured in the PB-based proof format we employ.

</details>


### [678] [A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems](https://arxiv.org/abs/2508.07407)
*Jinyuan Fang,Yanwen Peng,Xi Zhang,Yingxu Wang,Xinhao Yi,Guibin Zhang,Yi Xu,Bin Wu,Siwei Liu,Zihao Li,Zhaochun Ren,Nikos Aletras,Xi Wang,Han Zhou,Zaiqiao Meng*

Main category: cs.AI

TL;DR: 本调查全面回顾了自演化人工智能代理，重点介绍了它们的概念框架、技术、特定领域策略以及安全和伦理方面的考量，旨在促进更具适应性和自主性的代理系统的发展。


<details>
  <summary>Details</summary>
Motivation: 本调查旨在解决现有代理系统依赖于手动配置的限制，这些配置在部署后保持静态，从而限制了它们适应动态和不断变化的环境的能力。因此，本调查探讨了旨在基于交互数据和环境反馈自动增强代理系统的代理演化技术。

Method: 本调查提出了一个统一的概念框架，该框架抽象了自演化代理系统的设计基础。该框架突出了四个关键组成部分：系统输入、代理系统、环境和优化器，为理解和比较不同的策略奠定了基础。基于此框架，我们系统地回顾了针对代理系统不同组成部分的广泛的自演化技术。我们还研究了为生物医学、编程和金融等专业领域开发的特定领域演化策略，其中优化目标与领域约束紧密耦合。此外，我们专门讨论了自演化代理系统的评估、安全和伦理考量，这对于确保其有效性和可靠性至关重要。

Result: 本调查对自演化代理系统进行了全面的回顾，包括其概念框架、各种技术、特定领域策略以及评估、安全和伦理方面的考量。

Conclusion: 本调查为研究人员和从业者提供了对自演化人工智能代理的系统性理解，为开发更具适应性、自主性和终身性的代理系统奠定了基础。

Abstract: Recent advances in large language models have sparked growing interest in AI
agents capable of solving complex, real-world tasks. However, most existing
agent systems rely on manually crafted configurations that remain static after
deployment, limiting their ability to adapt to dynamic and evolving
environments. To this end, recent research has explored agent evolution
techniques that aim to automatically enhance agent systems based on interaction
data and environmental feedback. This emerging direction lays the foundation
for self-evolving AI agents, which bridge the static capabilities of foundation
models with the continuous adaptability required by lifelong agentic systems.
In this survey, we provide a comprehensive review of existing techniques for
self-evolving agentic systems. Specifically, we first introduce a unified
conceptual framework that abstracts the feedback loop underlying the design of
self-evolving agentic systems. The framework highlights four key components:
System Inputs, Agent System, Environment, and Optimisers, serving as a
foundation for understanding and comparing different strategies. Based on this
framework, we systematically review a wide range of self-evolving techniques
that target different components of the agent system. We also investigate
domain-specific evolution strategies developed for specialised fields such as
biomedicine, programming, and finance, where optimisation objectives are
tightly coupled with domain constraints. In addition, we provide a dedicated
discussion on the evaluation, safety, and ethical considerations for
self-evolving agentic systems, which are critical to ensuring their
effectiveness and reliability. This survey aims to provide researchers and
practitioners with a systematic understanding of self-evolving AI agents,
laying the foundation for the development of more adaptive, autonomous, and
lifelong agentic systems.

</details>


### [679] [Multi-level Advantage Credit Assignment for Cooperative Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2508.06836)
*Xutong Zhao,Yaqi Xie*

Main category: cs.AI

TL;DR: MARL 信用分配的挑战在于，代理可能执行不同类型的协调，奖励归因于不同且通常重叠的代理子集。本研究提出了一种名为 MACA 的多层优势信用分配方法，该方法通过显式的反事实推理来推断跨不同层级的信用，并利用基于注意力的框架来识别相关代理关系并构建多层优势以指导策略学习。实验证明 MACA 在复杂信用分配场景中表现优越。


<details>
  <summary>Details</summary>
Motivation: MARL 中的关键挑战是信用分配，即评估每个代理对共享奖励的贡献。鉴于任务的多样性，代理可能执行不同类型的协调，奖励归因于不同且通常重叠的代理子集。本研究旨在解决信用分配层级多样性问题。

Method: 提出了一种名为 MACA（Multi-level Advantage Credit Assignment）的多层优势信用分配方法，该方法通过整合优势函数来推断跨不同层级的信用，并利用基于注意力的框架来识别相关代理关系并构建多层优势以指导策略学习。

Result: 在具有挑战性的 Starcraft v1 和 v2 任务上进行的综合实验证明了 MACA 的优越性能。

Conclusion: MACA 在复杂信用分配场景中表现出优越的性能，证明了其有效性。

Abstract: Cooperative multi-agent reinforcement learning (MARL) aims to coordinate
multiple agents to achieve a common goal. A key challenge in MARL is credit
assignment, which involves assessing each agent's contribution to the shared
reward. Given the diversity of tasks, agents may perform different types of
coordination, with rewards attributed to diverse and often overlapping agent
subsets. In this work, we formalize the credit assignment level as the number
of agents cooperating to obtain a reward, and address scenarios with multiple
coexisting levels. We introduce a multi-level advantage formulation that
performs explicit counterfactual reasoning to infer credits across distinct
levels. Our method, Multi-level Advantage Credit Assignment (MACA), captures
agent contributions at multiple levels by integrating advantage functions that
reason about individual, joint, and correlated actions. Utilizing an
attention-based framework, MACA identifies correlated agent relationships and
constructs multi-level advantages to guide policy learning. Comprehensive
experiments on challenging Starcraft v1\&v2 tasks demonstrate MACA's superior
performance, underscoring its efficacy in complex credit assignment scenarios.

</details>


### [680] [MDK12-Bench: A Comprehensive Evaluation of Multimodal Large Language Models on Multidisciplinary Exams](https://arxiv.org/abs/2508.06851)
*Pengfei Zhou,Xiaopeng Peng,Fanrui Zhang,Zhaopan Xu,Jiaxin Ai,Yansheng Qiu,Chuanhao Li,Zhen Li,Ming Li,Yukang Feng,Jianwen Sun,Haoquan Zhang,Zizhen Li,Xiaofeng Mao,Zekai Li,Wangbo Zhao,Kai Wang,Xiaojun Chang,Wenqi Shao,Yang You,Kaipeng Zhang*

Main category: cs.AI

TL;DR: MDK12-Bench是一个新的大规模基准，用于评估多模态大语言模型在K-12学科知识上的能力。它通过模拟真实考试场景和引入动态挑战，揭示了当前模型的不足，并为未来的模型改进指明了方向。


<details>
  <summary>Details</summary>
Motivation: 当前用于评估多模态大语言模型（MLLMs）的基准在规模、覆盖范围和知识结构化方面存在不足，无法提供动态和差异化的评估，阻碍了通用人工智能（AGI）的发展。需要一个更大规模、更全面的基准来捕捉MLLMs在不同维度上的能力。

Method: 提出MDK12-Bench，一个包含141K实例和6,225个知识点的K-12考试基准，涵盖六个学科和五种问题格式，并带有难度和年份标注。设计了一个动态评估框架，引入了不熟悉的可视化、文本和问题形式的转变，以挑战模型的泛化能力，并缓解数据污染。评估了知识点参考增强生成（KP-RAG）以检查知识在解决问题中的作用。

Result: 评估结果揭示了当前MLLMs在处理不同难度级别、跨年度变化、情境转变和知识驱动推理方面存在多方面局限性。研究为增强模型的鲁棒性、可解释性以及在AI辅助教育中的应用提供了指导。

Conclusion: 当前的多模态大语言模型（MLLMs）在理解和解决跨学科问题方面存在局限性。MDK12-Bench基准通过引入大规模、多学科、结构化的K-12考试数据，为评估MLLMs在不同难度、时间、情境和知识推理能力方面提供了更全面的视角。动态评估框架和KP-RAG的引入有助于挑战模型的泛化能力并评估知识的作用。研究结果表明，MLLMs在多个方面仍有提升空间，并为改进模型鲁棒性、可解释性以及AI辅助教育提供了指导。

Abstract: Multimodal large language models (MLLMs), which integrate language and visual
cues for problem-solving, are crucial for advancing artificial general
intelligence (AGI). However, current benchmarks for measuring the intelligence
of MLLMs suffer from limited scale, narrow coverage, and unstructured
knowledge, offering only static and undifferentiated evaluations. To bridge
this gap, we introduce MDK12-Bench, a large-scale multidisciplinary benchmark
built from real-world K-12 exams spanning six disciplines with 141K instances
and 6,225 knowledge points organized in a six-layer taxonomy. Covering five
question formats with difficulty and year annotations, it enables comprehensive
evaluation to capture the extent to which MLLMs perform over four dimensions:
1) difficulty levels, 2) temporal (cross-year) shifts, 3) contextual shifts,
and 4) knowledge-driven reasoning. We propose a novel dynamic evaluation
framework that introduces unfamiliar visual, textual, and question form shifts
to challenge model generalization while improving benchmark objectivity and
longevity by mitigating data contamination. We further evaluate knowledge-point
reference-augmented generation (KP-RAG) to examine the role of knowledge in
problem-solving. Key findings reveal limitations in current MLLMs in multiple
aspects and provide guidance for enhancing model robustness, interpretability,
and AI-assisted education.

</details>


### [681] [EMPATHIA: Multi-Faceted Human-AI Collaboration for Refugee Integration](https://arxiv.org/abs/2508.07671)
*Mohamed Rayan Barhdadi,Mehmet Tuncel,Erchin Serpedin,Hasan Kurban*

Main category: cs.AI

TL;DR: EMPATHIA框架通过整合文化、情感和伦理考量，改进了AI在难民安置中的应用，旨在在AI辅助决策时维护人类尊严，并在实验中取得了良好的效果。


<details>
  <summary>Details</summary>
Motivation: 当前AI在难民融合方面的应用过于狭隘，未能充分考虑到对长期成功至关重要的文化、情感和伦理等维度。本研究旨在解决在机器参与影响生活的重要决策时如何保持人类尊严的核心创意AI问题。

Method: EMPATHIA是一个多智能体框架，基于Kegan的建构性发展理论，将整合过程分为三个模块：SEED（社会文化入门和嵌入决策）、RISE（快速整合和自给自足引擎）和THRIVE（跨文化和谐与通过整合价值观和参与实现韧性）。SEED模块采用选择器-验证器架构，包含三个专门的智能体（情感、文化和伦理），能够透明地进行审议以产生可解释的建议。

Result: 在联合国Kakuma数据集（15,026名个体，根据国际劳工组织/联合国难民署标准，7,960名15岁及以上合格成年人）上进行的实验以及在150多个社会经济变量的6,359名15岁及以上劳动年龄难民上的实施，达到了87.4%的验证收敛率，并在五个接收国实现了可解释的评估。

Conclusion: EMPATHIA是一个通用的AI框架，用于处理需要协调多个价值的分配任务，通过增强而非取代人类专业知识，在文化、情感和伦理因素之间取得平衡，并支持从业者与AI的协作。

Abstract: Current AI approaches to refugee integration optimize narrow objectives such
as employment and fail to capture the cultural, emotional, and ethical
dimensions critical for long-term success. We introduce EMPATHIA (Enriched
Multimodal Pathways for Agentic Thinking in Humanitarian Immigrant Assistance),
a multi-agent framework addressing the central Creative AI question: how do we
preserve human dignity when machines participate in life-altering decisions?
Grounded in Kegan's Constructive Developmental Theory, EMPATHIA decomposes
integration into three modules: SEED (Socio-cultural Entry and Embedding
Decision) for initial placement, RISE (Rapid Integration and Self-sufficiency
Engine) for early independence, and THRIVE (Transcultural Harmony and
Resilience through Integrated Values and Engagement) for sustained outcomes.
SEED employs a selector-validator architecture with three specialized agents -
emotional, cultural, and ethical - that deliberate transparently to produce
interpretable recommendations. Experiments on the UN Kakuma dataset (15,026
individuals, 7,960 eligible adults 15+ per ILO/UNHCR standards) and
implementation on 6,359 working-age refugees (15+) with 150+ socioeconomic
variables achieved 87.4% validation convergence and explainable assessments
across five host countries. EMPATHIA's weighted integration of cultural,
emotional, and ethical factors balances competing value systems while
supporting practitioner-AI collaboration. By augmenting rather than replacing
human expertise, EMPATHIA provides a generalizable framework for AI-driven
allocation tasks where multiple values must be reconciled.

</details>


### [682] [MeteorPred: A Meteorological Multimodal Large Model and Dataset for Severe Weather Event Prediction](https://arxiv.org/abs/2508.06859)
*Shuo Tang,Jian Xu,Jiadong Zhang,Yi Chen,Qizhao Jin,Lingdong Shen,Chenglin Liu,Shiming Xiang*

Main category: cs.AI

TL;DR: 该研究提出了MP-Bench数据集和MMLM模型，以解决AI气象预报中的数据稀疏、数据与文本匹配以及高维数据处理等问题，并在实验中取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 当前天气预报系统依赖人工解释，存在主观性和操作负担。AI气象站是趋势，但面临数据稀疏、高维气象数据与文本警告不匹配、现有模型无法处理高维气象数据及复杂依赖关系等挑战。

Method: 提出了MP-Bench，一个包含421,363个气象数据和对应文本描述的数据集，并在此基础上开发了MMLM模型，该模型能直接处理4D气象数据，并通过三个即插即用的自适应融合模块来处理时间序列、垂直气压层和空间维度的特征。

Result: MMLM模型在MP-Bench数据集上表现出色，有效提升了恶劣天气的理解能力。

Conclusion: MMLM在MP-Bench数据集上的广泛实验证明了其在多任务上的卓越表现，在恶劣天气理解方面效果显著，是实现自动化、人工智能驱动的天气预报系统的关键一步。代码和数据集将公开。

Abstract: Timely and accurate severe weather warnings are critical for disaster
mitigation. However, current forecasting systems remain heavily reliant on
manual expert interpretation, introducing subjectivity and significant
operational burdens. With the rapid development of AI technologies, the
end-to-end "AI weather station" is gradually emerging as a new trend in
predicting severe weather events. Three core challenges impede the development
of end-to-end AI severe weather system: (1) scarcity of severe weather event
samples; (2) imperfect alignment between high-dimensional meteorological data
and textual warnings; (3) existing multimodal language models are unable to
handle high-dimensional meteorological data and struggle to fully capture the
complex dependencies across temporal sequences, vertical pressure levels, and
spatial dimensions. To address these challenges, we introduce MP-Bench, the
first large-scale temporal multimodal dataset for severe weather events
prediction, comprising 421,363 pairs of raw multi-year meteorological data and
corresponding text caption, covering a wide range of severe weather scenarios
across China. On top of this dataset, we develop a meteorology multimodal large
model (MMLM) that directly ingests 4D meteorological inputs. In addition, it is
designed to accommodate the unique characteristics of 4D meteorological data
flow, incorporating three plug-and-play adaptive fusion modules that enable
dynamic feature extraction and integration across temporal sequences, vertical
pressure layers, and spatial dimensions. Extensive experiments on MP-Bench
demonstrate that MMLM performs exceptionally well across multiple tasks,
highlighting its effectiveness in severe weather understanding and marking a
key step toward realizing automated, AI-driven weather forecasting systems. Our
source code and dataset will be made publicly available.

</details>


### [683] [Pushdown Reward Machines for Reinforcement Learning](https://arxiv.org/abs/2508.06894)
*Giovanni Varricchione,Toryn Q. Klassen,Natasha Alechina,Mehdi Dastani,Brian Logan,Sheila A. McIlraith*

Main category: cs.AI

TL;DR: 奖励机（RM）是用于强化学习（RL）的自动机结构，可以对表示在正则表达式中的行为进行奖励。本文提出了奖励机（RM）的扩展，称为下推奖励机（pdRM），它基于确定性下推自动机。pdRM可以识别和奖励确定性上下文无关语言中可表示的时序行为。作者还提出了两种pdRM策略变体，并提供了理论结果，以建立pdRM的表现力以及学习问题的空间复杂性。最后，作者进行了实验，以表明使用pdRM的智能体可以被训练来执行确定性上下文无关语言中可表示的任务。


<details>
  <summary>Details</summary>
Motivation: 为了扩展奖励机（RM）以处理更复杂的非马尔可夫奖励功能，需要更具表现力的模型。

Method: 提出了一种基于确定性下推自动机的奖励机（pdRM）的扩展，作为奖励机（RM）的替代。然后，提出了两种基于pdRM的策略变体，并研究了它们的学习问题。

Result: 实验结果表明，使用pdRM可以训练智能体来执行确定性上下文无关语言中可表示的任务。

Conclusion: pdRM相比RM更具表现力，可以识别和奖励确定性上下文无关语言中可表示的时期行为。此外，还提出了策略的两种变体，并对它们进行了分析。

Abstract: Reward machines (RMs) are automata structures that encode (non-Markovian)
reward functions for reinforcement learning (RL). RMs can reward any behaviour
representable in regular languages and, when paired with RL algorithms that
exploit RM structure, have been shown to significantly improve sample
efficiency in many domains. In this work, we present pushdown reward machines
(pdRMs), an extension of reward machines based on deterministic pushdown
automata. pdRMs can recognize and reward temporally extended behaviours
representable in deterministic context-free languages, making them more
expressive than reward machines. We introduce two variants of pdRM-based
policies, one which has access to the entire stack of the pdRM, and one which
can only access the top $k$ symbols (for a given constant $k$) of the stack. We
propose a procedure to check when the two kinds of policies (for a given
environment, pdRM, and constant $k$) achieve the same optimal expected reward.
We then provide theoretical results establishing the expressive power of pdRMs,
and space complexity results about the proposed learning problems. Finally, we
provide experimental results showing how agents can be trained to perform tasks
representable in deterministic context-free languages using pdRMs.

</details>


### [684] [DSperse: A Framework for Targeted Verification in Zero-Knowledge Machine Learning](https://arxiv.org/abs/2508.06972)
*Dan Ivanov,Tristan Freiberg,Haruna Isah*

Main category: cs.AI

TL;DR: DSperse是一个用于分布式机器学习推理的框架，通过只验证部分计算（切片）而非整个模型来降低成本和提高灵活性，并提供信任最小化方案。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是解决分布式机器学习推理中高昂的成本和僵化的电路化问题，提出一种更务实、可信度更小化的方案，将零知识证明定位在最有价值的组件上。

Method: DSperse框架通过“切片”技术，仅对部分子计算进行零知识证明验证，而非对整个模型进行电路化，从而降低了成本和提高了灵活性。它还通过审计、复制或经济激励等机制强制执行全局一致性。

Result: DSperse框架在内存使用、运行时和电路行为方面进行了评估，并报告了切片和非切片配置下的经验结果。

Conclusion: DSperse框架通过灵活对齐模型结构和允许可扩展、有针对性的验证策略，支持多样化的部署需求。

Abstract: DSperse is a modular framework for distributed machine learning inference
with strategic cryptographic verification. Operating within the emerging
paradigm of distributed zero-knowledge machine learning, DSperse avoids the
high cost and rigidity of full-model circuitization by enabling targeted
verification of strategically chosen subcomputations. These verifiable
segments, or "slices", may cover part or all of the inference pipeline, with
global consistency enforced through audit, replication, or economic incentives.
This architecture supports a pragmatic form of trust minimization, localizing
zero-knowledge proofs to the components where they provide the greatest value.
We evaluate DSperse using multiple proving systems and report empirical results
on memory usage, runtime, and circuit behavior under sliced and unsliced
configurations. By allowing proof boundaries to align flexibly with the model's
logical structure, DSperse supports scalable, targeted verification strategies
suited to diverse deployment needs.

</details>


### [685] [GDBA Revisited: Unleashing the Power of Guided Local Search for Distributed Constraint Optimization](https://arxiv.org/abs/2508.06899)
*Yanchen Deng,Xinrun Wang,Bo An*

Main category: cs.AI

TL;DR: DGLS是一种新的GLS框架，用于解决DCOPs问题，通过解决GDBA的不足之处，在各种标准基准测试中展现出优越的性能。


<details>
  <summary>Details</summary>
Motivation: 现有分布式约束优化问题（DCOPs）的本地搜索算法（如GDBA）存在收敛到不良局部最优解的问题。GDBA虽然提供了一套完整的规则来避免过早收敛，但在通用值问题上的实际效果不佳。作者系统地检查了GDBA，发现其性能不佳的潜在因素包括：过于激进的约束违反条件、无界的惩罚累积以及不协调的惩罚更新。

Method: 提出了一种名为分布式引导本地搜索（DGLS）的新颖GLS框架，该框架包含自适应违反条件、惩罚蒸发机制和协调惩罚更新。

Result: DGLS在通用值问题上取得了与阻尼最大和（damping factors为0.7或0.9）相当的性能，并在结构化问题上以3.77%--66.3%的优势超越了它。

Conclusion: DGLS在通用值问题上取得了与阻尼最大和（damping factors为0.7或0.9）相当的性能，并在结构化问题上以4.15%--76.0%的优势超越了它。

Abstract: Local search is an important class of incomplete algorithms for solving
Distributed Constraint Optimization Problems (DCOPs) but it often converges to
poor local optima. While GDBA provides a comprehensive rule set to escape
premature convergence, its empirical benefits remain marginal on general-valued
problems. In this work, we systematically examine GDBA and identify three
factors that potentially lead to its inferior performance, i.e.,
over-aggressive constraint violation conditions, unbounded penalty
accumulation, and uncoordinated penalty updates. To address these issues, we
propose Distributed Guided Local Search (DGLS), a novel GLS framework for DCOPs
that incorporates an adaptive violation condition to selectively penalize
constraints with high cost, a penalty evaporation mechanism to control the
magnitude of penalization, and a synchronization scheme for coordinated penalty
updates. We theoretically show that the penalty values are bounded, and agents
play a potential game in our DGLS. Our extensive empirical results on various
standard benchmarks demonstrate the great superiority of DGLS over
state-of-the-art baselines. Particularly, compared to Damped Max-sum with high
damping factors (e.g., 0.7 or 0.9), our DGLS achieves competitive performance
on general-valued problems, and outperforms it by significant margins
(\textbf{3.77\%--66.3\%}) on structured problems in terms of anytime results.

</details>


### [686] [FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis](https://arxiv.org/abs/2508.07950)
*Chen Shen,Wanqing Zhang,Kehan Li,Erwen Huang,Haitao Bi,Aiying Fan,Yiwen Shen,Hongmei Dong,Ji Zhang,Yuming Shao,Zengjia Liu,Xinshe Liu,Tao Li,Chunxia Yan,Shuanliang Fan,Di Wu,Jianhua Ma,Bin Cong,Zhenyuan Wang,Chunfeng Lian*

Main category: cs.AI

TL;DR: FEAT是一个创新的多智能体AI框架，利用优化的LLM来自动化和标准化法医死亡调查。在中国案例中，它在准确性和效率上超越了现有AI系统，并获得了专家的高度认可，有望解决法医领域的挑战并提高服务可及性。


<details>
  <summary>Details</summary>
Motivation: 为应对法医鉴定领域，特别是在中国等高工作量系统中存在的劳动力短缺和诊断变异性等系统性挑战，旨在自动化和标准化死亡调查。

Method: FEAT（ForEnsic AgenT）是一个多智能体AI框架，利用领域适应的大型语言模型来自动化和标准化死亡调查。其架构包括：中心规划器（任务分解）、局部求解器（证据分析）、记忆与反思模块（迭代优化）和全局求解器（结论综合）。系统采用工具增强推理、分层检索增强生成、法医优化的LLM以及人机回环反馈。

Result: 在中国的各类案例队列评估中，FEAT在长篇尸检分析和简洁的死因结论方面均优于最先进的AI系统。它在六个地理区域表现出强大的泛化能力，并在盲法验证中达到高专家一致性。资深病理学家证实FEAT的输出可与人类专家的水平相媲美，并能更好地检测细微的证据差别。

Conclusion: FEAT系统是首个用于法医领域的基于大型语言模型的AI代理系统，能够实现可扩展、一致的死亡证明，并保持专家级严谨性。该系统通过整合AI效率和人工监督，有望促进可靠的法医学服务的公平可及性，同时解决法医系统中的关键能力限制。

Abstract: Forensic cause-of-death determination faces systemic challenges, including
workforce shortages and diagnostic variability, particularly in high-volume
systems like China's medicolegal infrastructure. We introduce FEAT (ForEnsic
AgenT), a multi-agent AI framework that automates and standardizes death
investigations through a domain-adapted large language model. FEAT's
application-oriented architecture integrates: (i) a central Planner for task
decomposition, (ii) specialized Local Solvers for evidence analysis, (iii) a
Memory & Reflection module for iterative refinement, and (iv) a Global Solver
for conclusion synthesis. The system employs tool-augmented reasoning,
hierarchical retrieval-augmented generation, forensic-tuned LLMs, and
human-in-the-loop feedback to ensure legal and medical validity. In evaluations
across diverse Chinese case cohorts, FEAT outperformed state-of-the-art AI
systems in both long-form autopsy analyses and concise cause-of-death
conclusions. It demonstrated robust generalization across six geographic
regions and achieved high expert concordance in blinded validations. Senior
pathologists validated FEAT's outputs as comparable to those of human experts,
with improved detection of subtle evidentiary nuances. To our knowledge, FEAT
is the first LLM-based AI agent system dedicated to forensic medicine, offering
scalable, consistent death certification while maintaining expert-level rigor.
By integrating AI efficiency with human oversight, this work could advance
equitable access to reliable medicolegal services while addressing critical
capacity constraints in forensic systems.

</details>


### [687] [Automated Formalization via Conceptual Retrieval-Augmented LLMs](https://arxiv.org/abs/2508.06931)
*Wangyue Lu,Lun Du,Sirui Li,Ke Weng,Haozhe Sun,Hengyu Liu,Minghe Yu,Tiancheng Zhang,Ge Yu*

Main category: cs.AI

TL;DR: CRAMF框架通过检索和上下文增强，解决了自动数学形式化的难题，显著提升了准确性。


<details>
  <summary>Details</summary>
Motivation: 为了解决交互式定理证明器（ITPs）在手动形式化方面耗时且需要专业知识的问题，以及现有自动形式化方法面临的模型幻觉和语义鸿沟挑战。

Method: 提出了一种名为CRAMF（概念驱动检索增强数学形式化）的框架，该框架通过检索形式化定义来增强基于LLM的自动形式化，并构建了一个包含26,000多个形式化定义和1,000多个核心数学概念的知识库，采用上下文查询增强和双通道混合检索策略来处理概念多态性和提高检索精度。

Result: CRAMF可以无缝集成到基于LLM的自动形式化器中，在翻译准确性方面取得持续改进，最高可达62.1%，平均相对改进率为29.9%。

Conclusion: CRAMF通过从Mathlib4构建概念知识库，并采用上下文查询增强和双通道混合检索策略，有效解决了LLM自动形式化的模型幻觉和语义鸿沟问题，在多个基准测试中显著提高了翻译准确性。

Abstract: Interactive theorem provers (ITPs) require manual formalization, which is
labor-intensive and demands expert knowledge. While automated formalization
offers a potential solution, it faces two major challenges: model hallucination
(e.g., undefined predicates, symbol misuse, and version incompatibility) and
the semantic gap caused by ambiguous or missing premises in natural language
descriptions. To address these issues, we propose CRAMF, a Concept-driven
Retrieval-Augmented Mathematical Formalization framework. CRAMF enhances
LLM-based autoformalization by retrieving formal definitions of core
mathematical concepts, providing contextual grounding during code generation.
However, applying retrieval-augmented generation (RAG) in this setting is
non-trivial due to the lack of structured knowledge bases, the polymorphic
nature of mathematical concepts, and the high precision required in formal
retrieval. We introduce a framework for automatically constructing a
concept-definition knowledge base from Mathlib4, the standard mathematical
library for the Lean 4 theorem prover, indexing over 26,000 formal definitions
and 1,000+ core mathematical concepts. To address conceptual polymorphism, we
propose contextual query augmentation with domain- and application-level
signals. In addition, we design a dual-channel hybrid retrieval strategy with
reranking to ensure accurate and relevant definition retrieval. Experiments on
miniF2F, ProofNet, and our newly proposed AdvancedMath benchmark show that
CRAMF can be seamlessly integrated into LLM-based autoformalizers, yielding
consistent improvements in translation accuracy, achieving up to 62.1% and an
average of 29.9% relative improvement.

</details>


### [688] [Intrinsic Explainability of Multimodal Learning for Crop Yield Prediction](https://arxiv.org/abs/2508.06939)
*Hiba Najjar,Deepak Pathak,Marlon Nuske,Andreas Dengel*

Main category: cs.AI

TL;DR: This paper uses Transformer models for crop yield prediction, outperforming others. It introduces methods (AR, GA, WMA) to explain how the model works and which data sources are important, finding that AR is reliable for time-based explanations and the model's predictions align with agricultural knowledge.


<details>
  <summary>Details</summary>
Motivation: To address the overlook of model interpretability in multimodal learning networks, especially in agriculture where diverse data sources are used. The study aims to leverage the explainability of Transformer-based models for tasks like crop yield prediction.

Method: Leveraging Transformer-based models for multimodal learning in crop yield prediction. Employing Attention Rollout (AR) and Generic Attention (GA) for feature attribution estimation, and comparing them with Shapley Value Sampling (SVS). Proposing Weighted Modality Activation (WMA) for modality attribution assessment and comparing it with SVS.

Result: Transformer-based models showed improved performance (higher R2 scores by 0.10 at subfield and 0.04 at field levels) compared to CNNs and RNNs. AR demonstrated more robust and reliable temporal attributions than GA and SVS. WMA and SVS showed different patterns in modality attributions.

Conclusion: Transformer-based models outperform other architectures like CNNs and RNNs in crop yield prediction, achieving higher R2 scores. Attention Rollout (AR) provides more robust temporal attributions compared to GA and SVS. Modality attributions vary between WMA and SVS methods. Explanation results align with agronomic knowledge when interpreted using crop phenology stages.

Abstract: Multimodal learning enables various machine learning tasks to benefit from
diverse data sources, effectively mimicking the interplay of different factors
in real-world applications, particularly in agriculture. While the
heterogeneous nature of involved data modalities may necessitate the design of
complex architectures, the model interpretability is often overlooked. In this
study, we leverage the intrinsic explainability of Transformer-based models to
explain multimodal learning networks, focusing on the task of crop yield
prediction at the subfield level. The large datasets used cover various crops,
regions, and years, and include four different input modalities: multispectral
satellite and weather time series, terrain elevation maps and soil properties.
Based on the self-attention mechanism, we estimate feature attributions using
two methods, namely the Attention Rollout (AR) and Generic Attention (GA), and
evaluate their performance against Shapley-based model-agnostic estimations,
Shapley Value Sampling (SVS). Additionally, we propose the Weighted Modality
Activation (WMA) method to assess modality attributions and compare it with SVS
attributions. Our findings indicate that Transformer-based models outperform
other architectures, specifically convolutional and recurrent networks,
achieving R2 scores that are higher by 0.10 and 0.04 at the subfield and field
levels, respectively. AR is shown to provide more robust and reliable temporal
attributions, as confirmed through qualitative and quantitative evaluation,
compared to GA and SVS values. Information about crop phenology stages was
leveraged to interpret the explanation results in the light of established
agronomic knowledge. Furthermore, modality attributions revealed varying
patterns across the two methods compared.[...]

</details>


### [689] [Large Language Models Do Not Simulate Human Psychology](https://arxiv.org/abs/2508.06950)
*Sarah Schröder,Thekla Morgenroth,Ulrike Kuhl,Valerie Vaquet,Benjamin Paaßen*

Main category: cs.AI

TL;DR: LLM不能模拟人类心理学，其反应不稳定且与人类存在差异。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM在心理学研究中取代人类参与者的可能性，并对该方法提出警告。

Method: 通过概念论证和实证证据，展示了LLM在面对措辞细微变化时与人类反应存在显著差异，并指出不同LLM对新项目的反应也存在很大差异。

Result: LLM的反应会因措辞的细微变化而产生显著差异，并且不同LLM的反应也不同，证明了其不可靠性。

Conclusion: LLM不能模拟人类心理学，研究者应将LLM视为在每次新应用中都需要根据人类反应进行验证的有用但不可靠的工具。

Abstract: Large Language Models (LLMs),such as ChatGPT, are increasingly used in
research, ranging from simple writing assistance to complex data annotation
tasks. Recently, some research has suggested that LLMs may even be able to
simulate human psychology and can, hence, replace human participants in
psychological studies. We caution against this approach. We provide conceptual
arguments against the hypothesis that LLMs simulate human psychology. We then
present empiric evidence illustrating our arguments by demonstrating that
slight changes to wording that correspond to large changes in meaning lead to
notable discrepancies between LLMs' and human responses, even for the recent
CENTAUR model that was specifically fine-tuned on psychological responses.
Additionally, different LLMs show very different responses to novel items,
further illustrating their lack of reliability. We conclude that LLMs do not
simulate human psychology and recommend that psychological researchers should
treat LLMs as useful but fundamentally unreliable tools that need to be
validated against human responses for every new application.

</details>


### [690] [DatasetResearch: Benchmarking Agent Systems for Demand-Driven Dataset Discovery](https://arxiv.org/abs/2508.06960)
*Keyu Li,Mohan Jiang,Dayuan Fu,Yunze Wu,Xiangkun Hu,Dequan Wang,Pengfei Liu*

Main category: cs.AI

TL;DR: 大型语言模型的发展将瓶颈从计算能力转移到了数据可用性上。我们引入了一个新的基准 DatasetResearch 来评估 AI 代理发现和合成数据集的能力，发现现有系统在面对“边缘情况”时表现不佳，并为未来的研究指明了方向。


<details>
  <summary>Details</summary>
Motivation: 随着推理能力和深度研究方法的不断发展，一个关键问题出现了：人工智能代理能否超越传统的搜索，系统地发现满足特定用户需求的任何数据集，从而实现真正自主的需求驱动数据策展？

Method: 我们引入了 DatasetResearch，这是第一个评估 AI 代理从跨越知识密集型和推理密集型任务的 208 个现实世界需求中发现和合成数据集的能力的综合基准。我们的三维评估框架揭示了一个严峻的现实：即使是先进的深度研究系统在我们具有挑战性的 DatasetResearch-pro 子集上也只能获得 22% 的分数，这暴露了当前能力与完美数据集发现之间的巨大差距。

Result: 我们的分析揭示了一个根本性的二分法——搜索代理通过检索广度在知识任务方面表现出色，而综合代理通过结构化生成在推理挑战方面占主导地位——但两者在现有分布之外的“边缘情况”下都会灾难性地失败。

Conclusion: 该基准和分析为下一代自学人工智能系统奠定了基础，并阐明了能够发现数字宇宙中任何数据集的 AI 系统的发展方向。

Abstract: The rapid advancement of large language models has fundamentally shifted the
bottleneck in AI development from computational power to data availability-with
countless valuable datasets remaining hidden across specialized repositories,
research appendices, and domain platforms. As reasoning capabilities and deep
research methodologies continue to evolve, a critical question emerges: can AI
agents transcend conventional search to systematically discover any dataset
that meets specific user requirements, enabling truly autonomous demand-driven
data curation? We introduce DatasetResearch, the first comprehensive benchmark
evaluating AI agents' ability to discover and synthesize datasets from 208
real-world demands across knowledge-intensive and reasoning-intensive tasks.
Our tri-dimensional evaluation framework reveals a stark reality: even advanced
deep research systems achieve only 22% score on our challenging
DatasetResearch-pro subset, exposing the vast gap between current capabilities
and perfect dataset discovery. Our analysis uncovers a fundamental
dichotomy-search agents excel at knowledge tasks through retrieval breadth,
while synthesis agents dominate reasoning challenges via structured
generation-yet both catastrophically fail on "corner cases" outside existing
distributions. These findings establish the first rigorous baseline for dataset
discovery agents and illuminate the path toward AI systems capable of finding
any dataset in the digital universe. Our benchmark and comprehensive analysis
provide the foundation for the next generation of self-improving AI systems and
are publicly available at https://github.com/GAIR-NLP/DatasetResearch.

</details>


### [691] [MASteer: Multi-Agent Adaptive Steer Strategy for End-to-End LLM Trustworthiness Repair](https://arxiv.org/abs/2508.06963)
*Changqing Li,Tianlin Li,Xiaohan Zhang,Aishan Liu,Li Pan*

Main category: cs.AI

TL;DR: MASteer通过其创新的AutoTester和AutoRepairer组件，实现了LLM信任度修复的自动化和适应性，解决了现有方法的局限性，并在实验中取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）在信任度方面存在持续存在且不断演进的问题，促使开发者寻求自动化和灵活的修复方法，以便在不同场景下方便部署。然而，现有的方法（如SFT和RLHF）成本高昂且速度缓慢，而提示工程则缺乏鲁棒性和可扩展性。表示工程虽然是一种轻量级、无需训练的方法，但其手动样本和固定策略的依赖限制了自动化和适应性。

Method: MASteer框架集成了AutoTester（一个多代理系统，用于生成多样化、高质量的引导样本）和AutoRepairer（用于构建具有锚定向量的自适应引导策略），实现了自动化、上下文感知的策略选择。

Result: MASteer在标准和定制的信任度任务上持续优于基线方法，在LLaMA-3.1-8B-Chat上提高了15.36%，在Qwen-3-8B-Chat上提高了4.21%，同时保持了模型的通用能力，展示了其强大的鲁棒性、泛化能力和可扩展、高效的信任度修复的实用价值。

Conclusion: MASteer是一个端到端的表示工程框架，用于修复大型语言模型的信任度问题，通过AutoTester和AutoRepairer组件实现了自动化和适应性，在多个基准测试中均优于现有方法。

Abstract: Large Language Models (LLMs) face persistent and evolving trustworthiness
issues, motivating developers to seek automated and flexible repair methods
that enable convenient deployment across diverse scenarios. Existing repair
methods like supervised fine-tuning (SFT) and reinforcement learning with human
feedback (RLHF) are costly and slow, while prompt engineering lacks robustness
and scalability. Representation engineering, which steers model behavior by
injecting targeted concept vectors during inference, offers a lightweight,
training-free alternative. However, current approaches depend on manually
crafted samples and fixed steering strategies, limiting automation and
adaptability. To overcome these challenges, we propose MASteer, the first
end-to-end framework for trustworthiness repair in LLMs based on representation
engineering. MASteer integrates two core components: AutoTester, a multi-agent
system that generates diverse, high-quality steer samples tailored to developer
needs; and AutoRepairer, which constructs adaptive steering strategies with
anchor vectors for automated, context-aware strategy selection during
inference. Experiments on standard and customized trustworthiness tasks show
MASteer consistently outperforms baselines, improving metrics by 15.36% on
LLaMA-3.1-8B-Chat and 4.21% on Qwen-3-8B-Chat, while maintaining general model
capabilities. MASteer demonstrates strong robustness, generalization, and
practical value for scalable, efficient trustworthiness repair.

</details>


### [692] [Simulating Biological Intelligence: Active Inference with Experiment-Informed Generative Model](https://arxiv.org/abs/2508.06980)
*Aswin Paul,Moein Khajehnejad,Forough Habibollahi,Brett J. Kagan,Adeel Razi*

Main category: cs.AI

TL;DR: 本研究提出了一个基于主动推理的框架，使用生物神经网络模拟决策过程，展示了学习能力，为可解释AI提供了新方向。


<details>
  <summary>Details</summary>
Motivation: 理解自主智能体的目标行为对于开发安全有效的系统至关重要，同时探索生物系统（如生物神经网络）在AI领域的潜力，以实现更具可解释性和生物学合理性的模型。

Method: 提出一个基于主动推理的框架，并使用实验启发式生成模型在模拟游戏中进行决策过程的模拟。

Result: 在模拟游戏中展示了仿生代理的学习能力，揭示了记忆学习和预测规划在智能决策中的作用。

Conclusion: 该研究通过提出一个基于主动推理的框架，并使用实验启发式生成模型在模拟游戏中进行决策过程的模拟，展示了在仿生代理中学习的可能性，为可解释AI领域提供了生物学基础和可扩展的方法。

Abstract: With recent and rapid advancements in artificial intelligence (AI),
understanding the foundation of purposeful behaviour in autonomous agents is
crucial for developing safe and efficient systems. While artificial neural
networks have dominated the path to AI, recent studies are exploring the
potential of biologically based systems, such as networks of living biological
neuronal networks. Along with promises of high power and data efficiency, these
systems may also inform more explainable and biologically plausible models. In
this work, we propose a framework rooted in active inference, a general theory
of behaviour, to model decision-making in embodied agents. Using
experiment-informed generative models, we simulate decision-making processes in
a simulated game-play environment, mirroring experimental setups that use
biological neurons. Our results demonstrate learning in these agents, providing
insights into the role of memory-based learning and predictive planning in
intelligent decision-making. This work contributes to the growing field of
explainable AI by offering a biologically grounded and scalable approach to
understanding purposeful behaviour in agents.

</details>


### [693] [MultiMedEdit: A Scenario-Aware Benchmark for Evaluating Knowledge Editing in Medical VQA](https://arxiv.org/abs/2508.07022)
*Shengtao Wen,Haodong Chen,Yadong Wang,Zhongying Pan,Xiang Chen,Yu Tian,Bo Qian,Dong Liang,Sheng-Jun Huang*

Main category: cs.AI

TL;DR: MultiMedEdit 是首个针对临床多模态任务知识编辑的基准，发现现有方法在泛化和长尾推理方面存在不足，并提供了效率分析。


<details>
  <summary>Details</summary>
Motivation: 现有研究对医学知识编辑的关注较少，尤其是在多模态场景下，而医学知识编辑需要整合更新的知识和视觉推理以支持安全可解释的临床决策。

Method: 提出 MultiMedEdit 框架，包括理解和推理任务类型，定义了一个三维度量套件（可靠性、通用性和局部性），并支持跨范式比较。

Result: 通过单次编辑和终身编辑设置下的广泛实验表明，当前方法在泛化和长尾推理方面存在挑战，特别是在复杂的临床工作流程中。此外，效率分析揭示了实际部署中的权衡。

Conclusion: MultiMedEdit 为在临床多模态任务中评估知识编辑（KE）提供了一个基准，揭示了当前方法的局限性，并为未来开发临床稳健的知识编辑技术奠定了坚实的基础。

Abstract: Knowledge editing (KE) provides a scalable approach for updating factual
knowledge in large language models without full retraining. While previous
studies have demonstrated effectiveness in general domains and medical QA
tasks, little attention has been paid to KE in multimodal medical scenarios.
Unlike text-only settings, medical KE demands integrating updated knowledge
with visual reasoning to support safe and interpretable clinical decisions. To
address this gap, we propose MultiMedEdit, the first benchmark tailored to
evaluating KE in clinical multimodal tasks. Our framework spans both
understanding and reasoning task types, defines a three-dimensional metric
suite (reliability, generality, and locality), and supports cross-paradigm
comparisons across general and domain-specific models. We conduct extensive
experiments under single-editing and lifelong-editing settings. Results suggest
that current methods struggle with generalization and long-tail reasoning,
particularly in complex clinical workflows. We further present an efficiency
analysis (e.g., edit latency, memory footprint), revealing practical trade-offs
in real-world deployment across KE paradigms. Overall, MultiMedEdit not only
reveals the limitations of current approaches but also provides a solid
foundation for developing clinically robust knowledge editing techniques in the
future.

</details>


### [694] [Towards Safer AI Moderation: Evaluating LLM Moderators Through a Unified Benchmark Dataset and Advocating a Human-First Approach](https://arxiv.org/abs/2508.07063)
*Naseem Machlovi,Maryam Saleki,Innocent Ababio,Ruhul Amin*

Main category: cs.AI

TL;DR: LLM 在内容审核方面仍有局限，特别是在处理隐晦偏见和道德推理时。本研究提出了 SafePhi 模型，它在审核任务中表现出色，但仍需改进以提高鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 随着 AI 系统在日常生活中的应用日益广泛，对更安全、更可靠的内容审核的需求日益增长。尽管大型语言模型 (LLM) 在复杂性和性能方面取得了显著进展，但在涉及道德推理、隐晦偏见和性别歧视等细微差别的问题上，LLM 仍然容易出错并可能强化社会偏见。

Method: 提出了一种基于 SOTA 模型的实验框架，并构建了一个包含 49 个类别的统一基准数据集，用于评估人类情感、冒犯性文本以及性别和种族偏见。在此基础上，引入了经过 QLoRA 微调的 SafePhi 模型。

Result: SafePhi 模型在审核任务中取得了 0.89 的 Macro F1 分数，显著优于 OpenAI Moderator (0.77) 和 Llama Guard (0.74)。研究还揭示了 LLM 审核员表现不佳的关键领域，强调了整合更多样化、更具代表性的数据以及引入人工干预的必要性。

Conclusion: LLM 审核员在处理隐晦的仇恨言论、冒犯性语言和性别偏见方面仍存在不足，并且可能因训练数据而加剧社会偏见。尽管 SafePhi 模型在道德背景适应和性能上优于现有模型（Macro F1 分数为 0.89），但仍需纳入更多样化和具有代表性的数据，并结合人工干预，以提高模型鲁棒性和可解释性。

Abstract: As AI systems become more integrated into daily life, the need for safer and
more reliable moderation has never been greater. Large Language Models (LLMs)
have demonstrated remarkable capabilities, surpassing earlier models in
complexity and performance. Their evaluation across diverse tasks has
consistently showcased their potential, enabling the development of adaptive
and personalized agents. However, despite these advancements, LLMs remain prone
to errors, particularly in areas requiring nuanced moral reasoning. They
struggle with detecting implicit hate, offensive language, and gender biases
due to the subjective and context-dependent nature of these issues. Moreover,
their reliance on training data can inadvertently reinforce societal biases,
leading to inconsistencies and ethical concerns in their outputs. To explore
the limitations of LLMs in this role, we developed an experimental framework
based on state-of-the-art (SOTA) models to assess human emotions and offensive
behaviors. The framework introduces a unified benchmark dataset encompassing 49
distinct categories spanning the wide spectrum of human emotions, offensive and
hateful text, and gender and racial biases. Furthermore, we introduced SafePhi,
a QLoRA fine-tuned version of Phi-4, adapting diverse ethical contexts and
outperforming benchmark moderators by achieving a Macro F1 score of 0.89, where
OpenAI Moderator and Llama Guard score 0.77 and 0.74, respectively. This
research also highlights the critical domains where LLM moderators consistently
underperformed, pressing the need to incorporate more heterogeneous and
representative data with human-in-the-loop, for better model robustness and
explainability.

</details>


### [695] [Designing a Feedback-Driven Decision Support System for Dynamic Student Intervention](https://arxiv.org/abs/2508.07107)
*Timothy Oluwapelumi Adeyemi,Nadiah Fahad AlOtaibi*

Main category: cs.AI

TL;DR: 提出一个具有闭环架构的反馈驱动决策支持系统（DSS），用于持续优化模型。实验结果显示，再训练后RMSE降低了10.7%，并且干预后学生预测分数的调整持续向上。


<details>
  <summary>Details</summary>
Motivation: 教育领域大多数机器学习模型都是静态的，当有新的数据（如干预后的结果）可用时，它们无法进行调整。为了解决这个局限性。

Method: 提出一个具有闭环架构的反馈驱动决策支持系统（DSS），该架构能够进行持续的模型优化。该系统集成了基于LightGBM的回归器和增量再训练，允许教育工作者输入更新的学生结果，自动触发模型更新。该平台具有基于Flask的Web界面，用于实时交互，并结合了SHAP以提高可解释性。

Result: 实验结果显示，再训练后RMSE降低了10.7%，并且干预后学生预测分数的调整持续向上。

Conclusion: 通过将静态预测模型转变为能够自我改进的系统，我们的方法推动教育分析朝着以人为本、数据驱动和响应迅速的人工智能发展。该框架旨在与学习管理系统和机构仪表板集成。

Abstract: Accurate prediction of student performance is essential for timely academic
intervention. However, most machine learning models in education are static and
cannot adapt when new data, such as post-intervention outcomes, become
available. To address this limitation, we propose a Feedback-Driven Decision
Support System (DSS) with a closed-loop architecture that enables continuous
model refinement. The system integrates a LightGBM-based regressor with
incremental retraining, allowing educators to input updated student results,
which automatically trigger model updates. This adaptive mechanism improves
prediction accuracy by learning from real-world academic progress. The platform
features a Flask-based web interface for real-time interaction and incorporates
SHAP for explainability, ensuring transparency. Experimental results show a
10.7\% reduction in RMSE after retraining, with consistent upward adjustments
in predicted scores for intervened students. By transforming static predictors
into self-improving systems, our approach advances educational analytics toward
human-centered, data-driven, and responsive AI. The framework is designed for
integration into LMS and institutional dashboards.

</details>


### [696] [EndoAgent: A Memory-Guided Reflective Agent for Intelligent Endoscopic Vision-to-Decision Reasoning](https://arxiv.org/abs/2508.07292)
*Yi Tang,Kaini Wang,Yang Chen,Guangquan Zhou*

Main category: cs.AI

TL;DR: EndoAgent是首个用于内窥镜分析的记忆引导式智能体，通过双记忆设计和工具集成，实现了迭代推理和自适应工具选择，在EndoAgentBench基准测试中表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有基于大规模预训练的方法在处理复杂临床工作流中的多步骤过程时，往往缺乏跨任务的统一协调。尽管AI智能体在跨域的灵活指令解析和工具集成方面显示出潜力，但其在内窥镜领域的应用仍有待探索。

Method: 提出了一种名为EndoAgent的记忆引导式智能体，用于视觉到决策的内窥镜分析。该智能体集成了迭代推理、自适应工具选择和协作，并采用了双记忆设计，通过短期动作跟踪确保逻辑连贯性，并通过长期经验学习逐步提高推理准确性。此外，还引入了EndoAgentBench基准，包含5,709个视觉问答对，用于评估在现实场景中的视觉理解和语言生成能力。

Result: EndoAgent在各种临床任务中集成了专家设计的工具，并在统一的推理循环中运行。实验证明，EndoAgent在评估视觉理解和语言生成能力方面，持续优于通用的和医学的多模态模型。

Conclusion: EndoAgent在视觉问答和多模态基准测试中表现优于通用和医学多模态模型，展现了其强大的灵活性和推理能力。

Abstract: Developing general artificial intelligence (AI) systems to support endoscopic
image diagnosis is an emerging research priority. Existing methods based on
large-scale pretraining often lack unified coordination across tasks and
struggle to handle the multi-step processes required in complex clinical
workflows. While AI agents have shown promise in flexible instruction parsing
and tool integration across domains, their potential in endoscopy remains
underexplored. To address this gap, we propose EndoAgent, the first
memory-guided agent for vision-to-decision endoscopic analysis that integrates
iterative reasoning with adaptive tool selection and collaboration. Built on a
dual-memory design, it enables sophisticated decision-making by ensuring
logical coherence through short-term action tracking and progressively
enhancing reasoning acuity through long-term experiential learning. To support
diverse clinical tasks, EndoAgent integrates a suite of expert-designed tools
within a unified reasoning loop. We further introduce EndoAgentBench, a
benchmark of 5,709 visual question-answer pairs that assess visual
understanding and language generation capabilities in realistic scenarios.
Extensive experiments show that EndoAgent consistently outperforms both general
and medical multimodal models, exhibiting its strong flexibility and reasoning
capabilities.

</details>


### [697] [Hallucination as a Computational Boundary: A Hierarchy of Inevitability and the Oracle Escape](https://arxiv.org/abs/2508.07334)
*Quan Shi,Wang Xi,Zenghui Ding,Jianqing Gao,Xianjun Yang*

Main category: cs.AI

TL;DR: 本文将LLM形式化为概率图灵机，证明了幻觉是不可避免的，并提出了RAG和连续学习的“逃生路线”。


<details>
  <summary>Details</summary>
Motivation: LLM的幻觉现象是其可靠部署的核心障碍。

Method: 本文提出两种“逃生路线”：一种是将检索增强生成（RAG）建模为预言机，通过“计算跳跃”证明其绝对逃生，为RAG的有效性提供了第一个形式化理论；第二种是将连续学习形式化为“内部化预言机”机制，并通过新颖的神经博弈论框架实现这一路径。

Result: 本文为RAG的有效性提供了第一个形式化理论，并提出了一种新颖的神经博弈论框架。

Conclusion: LLM的幻觉是其可靠部署的核心障碍。本文通过构建“计算必要性层次结构”，将LLM形式化为概率图灵机，并首次证明了在二元化、不可计算性和信息论边界上幻觉是不可避免的，这得到了新的“学习者泵引理”的支持。

Abstract: The illusion phenomenon of large language models (LLMs) is the core obstacle
to their reliable deployment. This article formalizes the large language model
as a probabilistic Turing machine by constructing a "computational necessity
hierarchy", and for the first time proves the illusions are inevitable on
diagonalization, incomputability, and information theory boundaries supported
by the new "learner pump lemma". However, we propose two "escape routes": one
is to model Retrieval Enhanced Generations (RAGs) as oracle machines, proving
their absolute escape through "computational jumps", providing the first formal
theory for the effectiveness of RAGs; The second is to formalize continuous
learning as an "internalized oracle" mechanism and implement this path through
a novel neural game theory framework.Finally, this article proposes a

</details>


### [698] [Rethinking Domain-Specific LLM Benchmark Construction: A Comprehensiveness-Compactness Approach](https://arxiv.org/abs/2508.07353)
*Rubing Chen,Jiaxin Wu,Jian Wang,Xulu Zhang,Wenqi Fan,Chenghua Lin,Xiao-Yong Wei,Qing Li*

Main category: cs.AI

TL;DR: 该研究提出了一种新的基准测试框架 Comp-Comp，用于改进特定领域大型语言模型的评估。该框架优先考虑全面性和紧凑性，而不是传统的扩展定律，并在学术领域创建了一个名为 XUBench 的新基准测试。


<details>
  <summary>Details</summary>
Motivation: 现有针对大型语言模型（LLMs）的领域特定基准测试，主要关注扩展定律，依赖大规模语料库进行监督微调或生成广泛的问答集。然而，语料库和问答集设计对领域特定LLMs的精确率和召回率的影响尚未得到充分研究。

Method: 提出了一种名为 Comp-Comp 的迭代基准测试框架，该框架基于全面性-紧凑性原则，用于指导语料库和问答集（QA set）的构建，以提高特定领域大型语言模型（LLMs）的精确率和召回率。

Result: 通过在某知名大学进行的案例研究，创建了一个名为 XUBench 的大规模、全面的闭域基准测试。研究结果表明，Comp-Comp 框架在学术领域是有效的，并且该框架具有广泛的适用性，可扩展到学术领域之外的其他领域。

Conclusion: 该研究提出了一种名为 Comp-Comp 的迭代基准测试框架，该框架基于全面性-紧凑性原则，旨在改进特定领域大型语言模型的基准测试方法。研究表明，扩展定律并非特定领域基准测试的最佳原则，而 Comp-Comp 框架通过确保语义召回率（全面性）和提高精确率（紧凑性）来指导语料库和问答对的构建。

Abstract: Numerous benchmarks have been built to evaluate the domain-specific abilities
of large language models (LLMs), highlighting the need for effective and
efficient benchmark construction. Existing domain-specific benchmarks primarily
focus on the scaling law, relying on massive corpora for supervised fine-tuning
or generating extensive question sets for broad coverage. However, the impact
of corpus and question-answer (QA) set design on the precision and recall of
domain-specific LLMs remains unexplored. In this paper, we address this gap and
demonstrate that the scaling law is not always the optimal principle for
benchmark construction in specific domains. Instead, we propose Comp-Comp, an
iterative benchmarking framework based on a comprehensiveness-compactness
principle. Here, comprehensiveness ensures semantic recall of the domain, while
compactness enhances precision, guiding both corpus and QA set construction. To
validate our framework, we conducted a case study in a well-renowned
university, resulting in the creation of XUBench, a large-scale and
comprehensive closed-domain benchmark. Although we use the academic domain as
the case in this work, our Comp-Comp framework is designed to be extensible
beyond academia, providing valuable insights for benchmark construction across
various domains.

</details>


### [699] [Pentest-R1: Towards Autonomous Penetration Testing Reasoning Optimized via Two-Stage Reinforcement Learning](https://arxiv.org/abs/2508.07382)
*He Kong,Die Hu,Jingguo Ge,Liangxiong Li,Hui Li,Tong Li*

Main category: cs.AI

TL;DR: Pentest-R1是一个利用两阶段强化学习（离线+在线）的框架，用于提升LLM在自动化渗透测试中的表现。它通过专门的数据集和CTF环境进行训练，成功解决了现有LLM在该领域的局限性，并在多个基准测试中取得了领先成果。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM在自动化渗透测试方面存在局限性，包括错误处理能力差、推理效率低以及无法自主完成复杂的端到端任务。为了解决这些问题，需要一种优化的方法来增强LLM在网络安全领域的应用能力。

Method: 该研究介绍了一种名为Pentest-R1的新框架，该框架采用两阶段强化学习流水线来优化LLM在渗透测试中的推理能力。第一阶段是离线强化学习，利用超过500个真实世界的多步骤演练数据集来构建基础攻击逻辑。第二阶段是在交互式CTF环境中进行在线强化学习，通过环境反馈进行微调，以培养鲁棒的错误自我纠正和适应性策略。

Result: Pentest-R1在AutoPenBench上取得了24.2%的成功率，表现优于大多数最先进的模型，仅次于Gemini 2.5 Flash。在Cybench的无指导任务中，其成功率为15.0%，达到了开源LLM的最先进水平，并与顶级的专有模型性能相当。消融研究证实了两个训练阶段协同作用的关键性。

Conclusion: Pentest-R1通过两阶段强化学习流水线成功优化了LLM在渗透测试任务中的推理能力，在AutoPenBench和Cybench基准测试中取得了显著的成果，在开源LLM中达到了最先进的水平。

Abstract: Automating penetration testing is crucial for enhancing cybersecurity, yet
current Large Language Models (LLMs) face significant limitations in this
domain, including poor error handling, inefficient reasoning, and an inability
to perform complex end-to-end tasks autonomously. To address these challenges,
we introduce Pentest-R1, a novel framework designed to optimize LLM reasoning
capabilities for this task through a two-stage reinforcement learning pipeline.
We first construct a dataset of over 500 real-world, multi-step walkthroughs,
which Pentest-R1 leverages for offline reinforcement learning (RL) to instill
foundational attack logic. Subsequently, the LLM is fine-tuned via online RL in
an interactive Capture The Flag (CTF) environment, where it learns directly
from environmental feedback to develop robust error self-correction and
adaptive strategies. Our extensive experiments on the Cybench and AutoPenBench
benchmarks demonstrate the framework's effectiveness. On AutoPenBench,
Pentest-R1 achieves a 24.2\% success rate, surpassing most state-of-the-art
models and ranking second only to Gemini 2.5 Flash. On Cybench, it attains a
15.0\% success rate in unguided tasks, establishing a new state-of-the-art for
open-source LLMs and matching the performance of top proprietary models.
Ablation studies confirm that the synergy of both training stages is critical
to its success.

</details>


### [700] [Invert4TVG: A Temporal Video Grounding Framework with Inversion Tasks for Enhanced Action Understanding](https://arxiv.org/abs/2508.07388)
*Zhaoyu Chen,Hongnan Lin,Yongwei Nie,Fei Ma,Xuemiao Xu,Fei Yu,Chengjiang Long*

Main category: cs.AI

TL;DR: 提出了一种名为 Invert4TVG 的新颖框架，通过引入三个反转任务（动词补全、动作识别和视频描述）来增强视频地面定位的语义理解和定位精度，而无需额外数据。


<details>
  <summary>Details</summary>
Motivation: 当前的方法虽然优化了高时间 IoU，但常常过度拟合该指标，损害了视频和查询中语义动作的理解，而这是稳健 TVG 的一个关键因素。

Method: Invert4TVG 框架利用了从现有 TVG 注释派生出的三个反转任务：(1) 动词补全，从视频片段预测查询中被遮盖的动作动词；(2) 动作识别，识别查询描述的动作；(3) 视频描述，生成视频片段的描述，并明确嵌入与查询相关的动作。这些任务通过具有精心设计的奖励函数的强化学习框架与 TVG 集成，确保了定位和语义的平衡优化。

Result: 实验表明，我们的方法优于最先进的方法，对于 3B 模型在 Charades-STA 上相对于 Time-R1 实现了 7.1% 的 R1@0.7 提升。

Conclusion: Invert4TVG 通过反转 TVG 以从视频片段中提取与查询相关的动作，从而加强了语义理解，显著提高了定位的上限。

Abstract: Temporal Video Grounding (TVG) seeks to localize video segments matching a
given textual query. Current methods, while optimizing for high temporal
Intersection-over-Union (IoU), often overfit to this metric, compromising
semantic action understanding in the video and query, a critical factor for
robust TVG. To address this, we introduce Inversion Tasks for TVG (Invert4TVG),
a novel framework that enhances both localization accuracy and action
understanding without additional data. Our approach leverages three inversion
tasks derived from existing TVG annotations: (1) Verb Completion, predicting
masked action verbs in queries from video segments; (2) Action Recognition,
identifying query-described actions; and (3) Video Description, generating
descriptions of video segments that explicitly embed query-relevant actions.
These tasks, integrated with TVG via a reinforcement learning framework with
well-designed reward functions, ensure balanced optimization of localization
and semantics. Experiments show our method outperforms state-of-the-art
approaches, achieving a 7.1\% improvement in R1@0.7 on Charades-STA for a 3B
model compared to Time-R1. By inverting TVG to derive query-related actions
from segments, our approach strengthens semantic understanding, significantly
raising the ceiling of localization accuracy.

</details>


### [701] [Generative AI for Strategic Plan Development](https://arxiv.org/abs/2508.07405)
*Jesse Ponnock*

Main category: cs.AI

TL;DR: 本研究提出了一种利用GAI开发政府战略计划的模块化模型，并评估了BERTopic和NMF在主题建模生成愿景要素方面的表现。结果表明，BERTopic效果更优，为GAI在战略规划领域的应用提供了可行性。


<details>
  <summary>Details</summary>
Motivation: 随着生成式人工智能（GAI）和大语言模型（LLM）的突破，本研究旨在探索利用GAI开发大规模政府组织战略计划的模块化模型，并评估机器学习技术在该模型的一个模块中的应用。

Method: 评估了BERTopic和NMF两种主题建模技术，使用政府问责局（GAO）的报告进行训练，并通过与已发布的战略计划的愿景要素进行相似度评分来比较其性能。

Result: BERTopic和NMF技术能够生成与评估的愿景要素相似的主题，其中BERTopic的相关主题有超过一半达到了“中等”或“强”相关性。

Conclusion: BERTopic在主题建模生成战略计划愿景要素方面表现优于NMF，超过一半的相关主题达到了“中等”或“强”相关性。

Abstract: Given recent breakthroughs in Generative Artificial Intelligence (GAI) and
Large Language Models (LLMs), more and more professional services are being
augmented through Artificial Intelligence (AI), which once seemed impossible to
automate. This paper presents a modular model for leveraging GAI in developing
strategic plans for large scale government organizations and evaluates leading
machine learning techniques in their application towards one of the identified
modules. Specifically, the performance of BERTopic and Non-negative Matrix
Factorization (NMF) are evaluated in their ability to use topic modeling to
generate themes representative of Vision Elements within a strategic plan. To
accomplish this, BERTopic and NMF models are trained using a large volume of
reports from the Government Accountability Office (GAO). The generated topics
from each model are then scored for similarity against the Vision Elements of a
published strategic plan and the results are compared. Our results show that
these techniques are capable of generating themes similar to 100% of the
elements being evaluated against. Further, we conclude that BERTopic performs
best in this application with more than half of its correlated topics achieving
a "medium" or "strong" correlation. A capability of GAI-enabled strategic plan
development impacts a multi-billion dollar industry and assists the federal
government in overcoming regulatory requirements which are crucial to the
public good. Further work will focus on the operationalization of the concept
proven in this study as well as viability of the remaining modules in the
proposed model for GAI-generated strategic plans.

</details>


### [702] [Grounding Natural Language for Multi-agent Decision-Making with Multi-agentic LLMs](https://arxiv.org/abs/2508.07466)
*Dom Huh,Prasant Mohapatra*

Main category: cs.AI

TL;DR: 本研究扩展了LLM的能力，将其与多智能体决策算法相结合，通过先进的技术实现更好的协调和策略。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在多智能体决策中的应用，旨在通过共同语言促进代理间的协调和策略。

Method: 开发了一个系统框架来设计多智能体LLM，包括先进的提示工程技术、有效的记忆结构、多模态信息处理和通过微调算法进行的对齐策略。

Result: 通过在具有社会困境和博弈论考量的经典游戏环境中进行的大量消减研究，评估了设计选择。

Conclusion: LLMs可以通过集成多智能体决策算法来扩展其能力，通过先进的提示工程、有效的记忆结构、多模态信息处理和通过微调算法进行的对齐策略来设计多智能体LLM。

Abstract: Language is a ubiquitous tool that is foundational to reasoning and
collaboration, ranging from everyday interactions to sophisticated
problem-solving tasks. The establishment of a common language can serve as a
powerful asset in ensuring clear communication and understanding amongst
agents, facilitating desired coordination and strategies. In this work, we
extend the capabilities of large language models (LLMs) by integrating them
with advancements in multi-agent decision-making algorithms. We propose a
systematic framework for the design of multi-agentic large language models
(LLMs), focusing on key integration practices. These include advanced prompt
engineering techniques, the development of effective memory architectures,
multi-modal information processing, and alignment strategies through
fine-tuning algorithms. We evaluate these design choices through extensive
ablation studies on classic game settings with significant underlying social
dilemmas and game-theoretic considerations.

</details>


### [703] [CP-Agent: Agentic Constraint Programming](https://arxiv.org/abs/2508.07468)
*Stefan Szeider*

Main category: cs.AI

TL;DR: 使用 ReAct 代理和持久 IPython 内核，通过提示词注入领域知识，成功解决了 CP-Bench 上的所有约束编程问题，表明通用工具和提示词工程比特定架构更重要。


<details>
  <summary>Details</summary>
Motivation: 自动化将自然语言问题描述转换为正式约束模型是约束编程中的一个基本挑战，需要深厚的领域和建模专业知识。以往的方法在处理大量基准问题时存在不足。

Method: 该方法采用基于 ReAct（Reason and Act）原则的通用 Python 编码代理，并利用持久的 IPython 内核进行有状态的代码执行和迭代开发。代理将领域专业知识通过精心设计的项目提示词注入，并结合文件操作和代码执行工具，以动态地测试假设、调试故障和验证解决方案。

Result: 该方法成功解决了 CP-Bench 约束编程基准测试集中的全部 101 个问题。

Conclusion: 所提出的方法结合了通用编码工具和通过提示词编码的领域专业知识，而不是专门的代理架构或预定义的模型。该方法在 CP-Bench 约束编程基准测试集中的全部 101 个问题上均取得了成功。

Abstract: Translating natural language problem descriptions into formal constraint
models remains a fundamental challenge in constraint programming, requiring
deep expertise in both the problem domain and modeling frameworks. Previous
approaches to automating this translation have employed fixed workflows with
predetermined modeling steps, failing on a significant number of benchmark
problems. We present a new approach using a pure agentic strategy without any
fixed pipeline. We developed a general-purpose Python coding agent based on the
ReAct (Reason and Act) principle, utilizing a persistent IPython kernel for
stateful code execution and iterative development. Rather than embedding
constraint programming logic into the agent architecture, domain-specific
expertise is injected solely through a carefully crafted project prompt. The
agent combines this prompt-encoded knowledge with access to file operations and
code execution tools, enabling it to test hypotheses, debug failures, and
verify solutions dynamically. Implemented in just a few hundred lines of code,
this architecture successfully solves all 101 problems of the CP-Bench
constraint programming benchmark set. The results suggest that constraint
modeling tasks require the combination of general coding tools and domain
expertise encoded in prompts, rather than specialized agent architectures or
predefined workflows.

</details>


### [704] [Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy](https://arxiv.org/abs/2508.07485)
*Alexander Duffy,Samuel J Paech,Ishana Shastri,Elizabeth Karpinski,Baptiste Alloui-Cros,Tyler Marques,Matthew Lyle Olson*

Main category: cs.AI

TL;DR: 首次提出无需微调即可评估LLM玩“外交”游戏的框架，优化了状态表示，使24B模型能玩完整游戏。研究还开发了分析工具和关键状态分析协议，表明大模型表现更好但小模型也够用，并普及了LLM策略推理评估。


<details>
  <summary>Details</summary>
Motivation: “外交”游戏的高复杂性和信息密度，以及比赛的高变异性，使得之前的研究难以在无需微调或专门训练的情况下进行，限制了对LLM策略推理能力的研究。本研究旨在克服这些挑战，使任何本地LLM都能参与游戏，从而普及评估。

Method: 本研究提出了一种评估框架，优化了“外交”游戏的文本状态表示，使得24B参数模型无需微调即可完成游戏。开发了用于假设检验和统计分析的工具，并引入了“关键状态分析”协议。

Result: 研究成功实现了一个评估框架，允许LLM在无微调的情况下玩“外交”游戏。实验表明，更大参数的LLM表现更佳，但较小模型也表现尚可。该框架为研究LLM的策略推理能力提供了便利，并揭示了这些能力在LLM中的自然涌现。

Conclusion: 该研究首次提出了一个评估框架，允许任何现成的、本地的大型语言模型（LLMs）在无需微调或专门训练的情况下，玩完整的“外交”（Diplomacy）游戏。研究通过数据驱动的迭代优化了文本游戏状态表示，使得一个24B参数的模型能够在无微调的情况下可靠地完成游戏。研究还开发了用于假设检验和统计分析的工具，并进行了关于说服力、攻击性游戏风格以及不同模型性能的案例研究。实验表明，更大参数的模型表现更好，但较小模型也能充分发挥作用。此外，研究引入了“关键状态分析”（Critical State Analysis）协议，用于快速迭代和深入分析游戏中的关键时刻。该框架通过消除微调需求，普及了对LLM策略推理能力的评估，并揭示了这些能力如何在广泛使用的LLM中自然涌现。

Abstract: We present the first evaluation harness that enables any out-of-the-box,
local, Large Language Models (LLMs) to play full-press Diplomacy without
fine-tuning or specialized training. Previous work required frontier LLMs, or
fine-tuning, due to the high complexity and information density of Diplomacy's
game state. Combined with the high variance of matches, these factors made
Diplomacy prohibitive for study. In this work, we used data-driven iteration to
optimize a textual game state representation such that a 24B model can reliably
complete matches without any fine tuning. We develop tooling to facilitate
hypothesis testing and statistical analysis, and we present case studies on
persuasion, aggressive playstyles, and performance across a range of models. We
conduct a variety of experiments across many popular LLMs, finding the larger
models perform the best, but the smaller models still play adequately. We also
introduce Critical State Analysis: an experimental protocol for rapidly
iterating and analyzing key moments in a game at depth. Our harness
democratizes the evaluation of strategic reasoning in LLMs by eliminating the
need for fine-tuning, and it provides insights into how these capabilities
emerge naturally from widely used LLMs. Our code is available in the supplement
and will be open sourced.

</details>


### [705] [MCPToolBench++: A Large Scale AI Agent Model Context Protocol MCP Tool Use Benchmark](https://arxiv.org/abs/2508.07575)
*Shiqing Fan,Xichen Ding,Liang Zhang,Linjian Mo*

Main category: cs.AI

TL;DR: MCPToolBench++是一个包含4000多个MCP服务器的大型基准，用于评估LLM的工具使用能力，解决了现有评估方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM评估方法在处理MCP工具使用方面存在不足，包括缺乏全面的数据集和基准、MCP工具响应格式多样、实际工具调用成功率不确定以及LLM上下文窗口限制了工具调用数量。作者旨在通过提出MCPToolBench++来解决这些问题。

Method: 提出了一种名为MCPToolBench++的新基准，该基准包含来自40多个类别、超过4000个MCP服务器的数据集，支持单步和多步工具调用。此外，还评估了具有代理能力的最先进LLM在该基准上的表现。

Result: MCPToolBench++基准包含了来自40多个类别、超过4000个MCP服务器的数据集，支持单步和多步工具调用。作者使用该基准评估了最先进的LLM，并报告了评估结果，为LLM的工具使用能力评估提供了更全面的视角。

Conclusion: MCPToolBench++是一个大规模、多领域的人工智能代理工具使用基准，旨在解决评估LLM调用MCP工具能力的挑战。该基准包含超过40个类别的4000多个MCP服务器，涵盖单步和多步工具调用。通过在基准上评估最先进的LLM，可以更准确地衡量它们在实际应用中的工具使用能力。

Abstract: LLMs' capabilities are enhanced by using function calls to integrate various
data sources or API results into the context window. Typical tools include
search, web crawlers, maps, financial data, file systems, and browser usage,
etc. Integrating these data sources or functions requires a standardized
method. The Model Context Protocol (MCP) provides a standardized way to supply
context to LLMs. However, the evaluation of LLMs and AI Agents' MCP tool use
abilities suffer from several issues. First, there's a lack of comprehensive
datasets or benchmarks to evaluate various MCP tools. Second, the diverse
formats of response from MCP tool call execution further increase the
difficulty of evaluation. Additionally, unlike existing tool-use benchmarks
with high success rates in functions like programming and math functions, the
success rate of real-world MCP tool is not guaranteed and varies across
different MCP servers. Furthermore, the LLMs' context window also limits the
number of available tools that can be called in a single run, because the
textual descriptions of tool and the parameters have long token length for an
LLM to process all at once. To help address the challenges of evaluating LLMs'
performance on calling MCP tools, we propose MCPToolBench++, a large-scale,
multi-domain AI Agent tool use benchmark. As of July 2025, this benchmark is
build upon marketplace of over 4k MCP servers from more than 40 categories,
collected from the MCP marketplaces and GitHub communities. The datasets
consist of both single-step and multi-step tool calls across different
categories. We evaluated SOTA LLMs with agentic abilities on this benchmark and
reported the results.

</details>


### [706] [Optimization of Private Semantic Communication Performance: An Uncooperative Covert Communication Method](https://arxiv.org/abs/2508.07586)
*Wenjing Zhang,Ye Hu,Tao Luo,Zhilong Zhang,Mingzhe Chen*

Main category: cs.AI

TL;DR: 该论文提出了一种新的隐蔽语义通信框架，并引入了一种优先采样辅助的双延迟深度确定性策略梯度算法来优化语义信息传输和功率分配，以提高隐私性和传输质量。


<details>
  <summary>Details</summary>
Motivation: 为了在隐蔽语义通信中隐藏传输的语义信息，部署了友好的干扰器来干扰攻击者的检测和窃听。然而，由于干扰器能量有限且不与服务器通信，服务器不知道干扰器的发射功率。因此，服务器必须联合优化每个时隙传输的语义信息和相应的传输功率，以最大化用户隐私和语义信息传输质量。

Method: 提出了一种优先采样辅助的双延迟深度确定性策略梯度算法，该算法无需服务器和干扰器之间的通信，即可联合确定每个时隙传输的语义信息和传输功率。

Result: 所提出的算法相比传统强化学习方法，可将隐私性提高高达77.8%，将语义信息传输质量提高高达14.3%。

Conclusion: 仿真结果表明，所提出的算法与传统强化学习方法相比，隐私性和语义信息传输质量可分别提高高达77.8%和14.3%。

Abstract: In this paper, a novel covert semantic communication framework is
investigated. Within this framework, a server extracts and transmits the
semantic information, i.e., the meaning of image data, to a user over several
time slots. An attacker seeks to detect and eavesdrop the semantic transmission
to acquire details of the original image. To avoid data meaning being
eavesdropped by an attacker, a friendly jammer is deployed to transmit jamming
signals to interfere the attacker so as to hide the transmitted semantic
information. Meanwhile, the server will strategically select time slots for
semantic information transmission. Due to limited energy, the jammer will not
communicate with the server and hence the server does not know the transmit
power of the jammer. Therefore, the server must jointly optimize the semantic
information transmitted at each time slot and the corresponding transmit power
to maximize the privacy and the semantic information transmission quality of
the user. To solve this problem, we propose a prioritised sampling assisted
twin delayed deep deterministic policy gradient algorithm to jointly determine
the transmitted semantic information and the transmit power per time slot
without the communications between the server and the jammer. Compared to
standard reinforcement learning methods, the propose method uses an additional
Q network to estimate Q values such that the agent can select the action with a
lower Q value from the two Q networks thus avoiding local optimal action
selection and estimation bias of Q values. Simulation results show that the
proposed algorithm can improve the privacy and the semantic information
transmission quality by up to 77.8% and 14.3% compared to the traditional
reinforcement learning methods.

</details>


### [707] [HGMF: A Hierarchical Gaussian Mixture Framework for Scalable Tool Invocation within the Model Context Protocol](https://arxiv.org/abs/2508.07602)
*Wenpeng Xing,Zhipeng Chen,Changting Lin,Meng Han*

Main category: cs.AI

TL;DR: HGMF框架通过分层聚类和过滤来解决LLM在从大型工具库中选择工具的挑战，提高了准确性并降低了延迟。


<details>
  <summary>Details</summary>
Motivation: 为了解决LLM在从大型、层级化工具库中选择正确工具时面临的挑战，例如有限的上下文窗口和无关选项产生的噪声导致的低选择准确性和高计算成本。

Method: HGMF框架首先将用户查询和所有工具描述映射到统一的语义空间。然后，它通过高斯混合模型（GMM）对服务器进行聚类，并根据查询的似然度对服务器进行过滤。随后，将相同的GMM聚类和过滤方法应用于所选服务器关联的工具。这种分层过程生成了一个紧凑、高相关性的候选集，从而简化了LLM的最终选择任务。

Result: 实验结果表明，HGMF显著提高了工具选择的准确性，同时降低了推理延迟。

Conclusion: HGMF框架通过分层聚类和过滤显著提高了工具选择的准确性，同时降低了推理延迟，证明了其在大规模工具库中的可扩展性和有效性。

Abstract: Invoking external tools enables Large Language Models (LLMs) to perform
complex, real-world tasks, yet selecting the correct tool from large,
hierarchically-structured libraries remains a significant challenge. The
limited context windows of LLMs and noise from irrelevant options often lead to
low selection accuracy and high computational costs. To address this, we
propose the Hierarchical Gaussian Mixture Framework (HGMF), a probabilistic
pruning method for scalable tool invocation. HGMF first maps the user query and
all tool descriptions into a unified semantic space. The framework then
operates in two stages: it clusters servers using a Gaussian Mixture Model
(GMM) and filters them based on the query's likelihood. Subsequently, it
applies the same GMM-based clustering and filtering to the tools associated
with the selected servers. This hierarchical process produces a compact,
high-relevance candidate set, simplifying the final selection task for the LLM.
Experiments on a public dataset show that HGMF significantly improves tool
selection accuracy while reducing inference latency, confirming the framework's
scalability and effectiveness for large-scale tool libraries.

</details>


### [708] [ThinkTuning: Instilling Cognitive Reflections without Distillation](https://arxiv.org/abs/2508.07616)
*Aswin RRV,Jacob Dineen,Divij Handa,Md Nayem Uddin,Mihir Parmar,Chitta Baral,Ben Zhou*

Main category: cs.AI

TL;DR: ThinkTuning 是一种新颖的训练方法，通过模仿课堂教学中的师生互动，利用一个教师模型来指导学生模型进行推理训练，从而有效提升了学生模型的思考和解决问题的能力。


<details>
  <summary>Details</summary>
Motivation: 尽管测试时缩放技术和强化学习（RL）的进步使得大型语言模型（LLMs）能够进行多步推理和自我反思，但有研究表明 RL 本身并不能真正赋予这些推理能力，而只是激发了基础模型中已有的行为。这引发了一个问题：如何训练那些不具备这些思考能力的模型，使它们首先发展出这种能力？

Method: ThinkTuning 是一种基于 GRPO 的交互式训练方法，通过教师模型提供反馈来指导学生模型进行学习。具体来说，教师模型会提出问题，让学生模型尝试回答，然后提供纠正性反馈，最终展示正确答案，以此来重塑学生模型的思考过程。

Result: ThinkTuning 方法在平均而言，在基准测试上比零样本基线提高了 3.85%。在 MATH-500、AIME 和 GPQA-Diamond 数据集上，分别比 vanilla-GRPO 基线提高了 2.08%、2.23% 和 3.99%。

Conclusion: ThinkTuning 是一种基于 GRPO 的交互式训练方法，通过教师模型的隐式监督来提高学生模型的推理能力，在多个基准测试中表现出显著的改进。

Abstract: Recent advances in test-time scaling have led to the emergence of thinking
LLMs that exhibit self-reflective behaviors and multi-step reasoning. While RL
drives this self-improvement paradigm, a recent study (Gandhi et al., 2025)
shows that RL alone does not truly instill these new reasoning abilities - it
merely draws out behaviors already present in the base models. This raises a
question: How can we train the models that don't exhibit such thinking behavior
to develop it in the first place? To this end, we propose ThinkTuning, a
GRPO-based interactive training approach where we augment the rollouts of a
student model with the guidance from a teacher model. A simple idea from
classroom practice inspires our method: a teacher poses a problem, lets the
student try an answer, then gives corrective feedback -- enough to point the
mind in the right direction and then show the solution. Each piece of feedback
reshapes the student's thoughts, leading them to arrive at the correct
solution. Similarly, we find that this type of implicit supervision through
feedback from a teacher model of the same size improves the reasoning
capabilities of the student model. In particular, on average, our method shows
a 3.85% improvement over zero-shot baselines across benchmarks, and on
MATH-500, AIME and GPQA-Diamond it shows 2.08%, 2.23% and 3.99% improvements
over the vanilla-GRPO baseline. Source code is available at
https://github.com/3rdAT/ThinkTuning.

</details>


### [709] [Multimodal AI Systems for Enhanced Laying Hen Welfare Assessment and Productivity Optimization](https://arxiv.org/abs/2508.07628)
*Daniel Essien,Suresh Neethirajan*

Main category: cs.AI

TL;DR: 该研究提出了一种利用多模式人工智能（AI）和新的评估工具（DTS、DRI）来改进蛋鸡福利监控的方法，以克服传统方法的局限性，并为实现生产力和动物福利的结合奠定基础。


<details>
  <summary>Details</summary>
Motivation: 传统方法受限于人类观察和单一传感器数据，无法完全捕捉现代农场蛋鸡福利的复杂性、多维度性质。因此，需要一种由数据驱动、智能化的监控生态系统来取代主观、劳动密集型的福利检查。

Method: 本研究通过整合视觉、听觉、环境和生理数据流的多模式人工智能（AI）来评估蛋鸡福利。研究强调了中间（特征级）融合策略在现实家禽条件下的鲁棒性和性能之间取得了最佳平衡，并且比早期或晚期融合方法具有更好的可扩展性。引入了域迁移得分（DTS）和数据可靠性指数（DRI）来评估模型的适应性和传感器数据的质量。此外，还提出了一个模块化的、上下文感知的部署框架。

Result: 研究表明，中间（特征级）融合策略在真实家禽环境下表现出最佳的鲁棒性和性能平衡，并且比早期或晚期融合具有更好的可扩展性。通过引入DTS和DRI，为评估模型适应性和数据质量提供了新的工具，并提出了一个模块化的部署框架，以实现多模式传感的可扩展和实际集成。

Conclusion: 这项工作为从被动、单一模式监控到主动、由精度驱动的福利系统奠定了基础，该系统将生产力与合乎道德的、基于科学的动物护理相结合。

Abstract: The future of poultry production depends on a paradigm shift replacing
subjective, labor-intensive welfare checks with data-driven, intelligent
monitoring ecosystems. Traditional welfare assessments-limited by human
observation and single-sensor data-cannot fully capture the complex,
multidimensional nature of laying hen welfare in modern farms. Multimodal
Artificial Intelligence (AI) offers a breakthrough, integrating visual,
acoustic, environmental, and physiological data streams to reveal deeper
insights into avian welfare dynamics. This investigation highlights multimodal
As transformative potential, showing that intermediate (feature-level) fusion
strategies achieve the best balance between robustness and performance under
real-world poultry conditions, and offer greater scalability than early or late
fusion approaches. Key adoption barriers include sensor fragility in harsh farm
environments, high deployment costs, inconsistent behavioral definitions, and
limited cross-farm generalizability. To address these, we introduce two novel
evaluation tools - the Domain Transfer Score (DTS) to measure model
adaptability across diverse farm settings, and the Data Reliability Index (DRI)
to assess sensor data quality under operational constraints. We also propose a
modular, context-aware deployment framework designed for laying hen
environments, enabling scalable and practical integration of multimodal
sensing. This work lays the foundation for a transition from reactive, unimodal
monitoring to proactive, precision-driven welfare systems that unite
productivity with ethical, science based animal care.

</details>


### [710] [Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents](https://arxiv.org/abs/2508.07642)
*Tianyi Ma,Yue Zhang,Zehao Wang,Parisa Kordjamshidi*

Main category: cs.AI

TL;DR: SkillNav是一个创新的框架，通过将导航分解为可解释的技能并使用VLM路由器来提高VLN智能体的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前的VLN方法在泛化到需要复杂空间和时间推理的未知场景时仍然存在困难。目前的进步主要依赖于大规模预训练和数据增强。

Method: 提出了一种名为SkillNav的模块化框架，通过将导航分解为一系列可解释的原子技能（如垂直移动、区域识别、停止和暂停），并由专门的智能体处理。引入了一个基于VLM的新型零样本路由器，通过将子目标与视觉观察和历史动作对齐，动态地为每个时间步选择最合适的智能体。

Result: SkillNav在R2R基准上取得了最先进的性能，并在GSA-R2R基准上展现了良好的泛化能力。

Conclusion: SkillNav在R2R基准上实现了新的最先进性能，并对GSA-R2R基准表现出强大的泛化能力，该基准包含新颖的指令风格和未知的环境。

Abstract: Vision-and-Language Navigation (VLN) poses significant challenges in enabling
agents to interpret natural language instructions and navigate complex 3D
environments. While recent progress has been driven by large-scale pre-training
and data augmentation, current methods still struggle to generalize to unseen
scenarios, particularly when complex spatial and temporal reasoning is
required. In this work, we propose SkillNav, a modular framework that
introduces structured, skill-based reasoning into Transformer-based VLN agents.
Our method decomposes navigation into a set of interpretable atomic skills
(e.g., Vertical Movement, Area and Region Identification, Stop and Pause), each
handled by a specialized agent. We then introduce a novel zero-shot
Vision-Language Model (VLM)-based router, which dynamically selects the most
suitable agent at each time step by aligning sub-goals with visual observations
and historical actions. SkillNav achieves a new state-of-the-art performance on
the R2R benchmark and demonstrates strong generalization to the GSA-R2R
benchmark that includes novel instruction styles and unseen environments.

</details>


### [711] [Disentangling Multiplex Spatial-Temporal Transition Graph Representation Learning for Socially Enhanced POI Recommendation](https://arxiv.org/abs/2508.07649)
*Jie Li,Haoye Dong,Zhengyang Wu,Zetao Zheng,Mingrong Lin*

Main category: cs.AI

TL;DR: DiMuST是一种新的POI推荐模型，通过解纠缠表示学习来解决现有模型中空间-时间表示不匹配的问题。它在两个数据集上均取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的POI推荐研究通常分别对空间和时间转移进行建模，这会导致相同的空间-时间关键节点的表示不匹配，从而在融合过程中引入冗余信息，增加模型不确定性并降低可解释性。

Method: 提出了一种基于多重空间-时间转移图解纠缠表示学习的、具有社会增强功能的POI推荐模型DiMuST。该模型采用新颖的解纠缠变分多重图自动编码器（DAE），利用多重空间-时间图策略首先解纠缠共享和私有分布，然后通过专家乘积（PoE）机制融合共享特征，并通过对比约束对私有特征进行去噪。DiMuST能有效捕捉POI的空间-时间转移表示，同时保留其空间-时间关系的内在相关性。

Result: DiMuST模型有效地捕捉了POI的空间-时间转移表示，同时保留了其空间-时间关系的内在相关性。

Conclusion: DiMuST模型在两个具有挑战性的数据集上显著优于现有方法，并在多个指标上表现更好。

Abstract: Next Point-of-Interest (POI) recommendation is a research hotspot in business
intelligence, where users' spatial-temporal transitions and social
relationships play key roles. However, most existing works model spatial and
temporal transitions separately, leading to misaligned representations of the
same spatial-temporal key nodes. This misalignment introduces redundant
information during fusion, increasing model uncertainty and reducing
interpretability. To address this issue, we propose DiMuST, a socially enhanced
POI recommendation model based on disentangled representation learning over
multiplex spatial-temporal transition graphs. The model employs a novel
Disentangled variational multiplex graph Auto-Encoder (DAE), which first
disentangles shared and private distributions using a multiplex
spatial-temporal graph strategy. It then fuses the shared features via a
Product of Experts (PoE) mechanism and denoises the private features through
contrastive constraints. The model effectively captures the spatial-temporal
transition representations of POIs while preserving the intrinsic correlation
of their spatial-temporal relationships. Experiments on two challenging
datasets demonstrate that our DiMuST significantly outperforms existing methods
across multiple metrics.

</details>


### [712] [1-2-3 Check: Enhancing Contextual Privacy in LLM via Multi-Agent Reasoning](https://arxiv.org/abs/2508.07667)
*Wenkai Li,Liwen Sun,Zhenxiang Guan,Xuhui Zhou,Maarten Sap*

Main category: cs.AI

TL;DR: LLM在处理包含私人和公共信息的交互式数据时存在隐私风险。本文提出了一种多智能体方法，将隐私推理分解为子任务，以减少信息泄露并提高准确性，在基准测试中取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 在交互式环境中，LLM处理来自多个来源的信息（例如，总结包含私人和公共信息的会议），这带来了具有挑战性的上下文隐私问题。

Method: 本文提出了一种多智能体框架，将隐私推理分解为提取和分类等专门子任务，以解决交互式环境中LLM的上下文隐私问题。通过系统地消融信息流拓扑结构来研究隐私错误的产生和传播。

Result: 在ConfAIde和PrivacyLens基准上，使用GPT-4o的我们最好的多智能体配置可将私人信息泄露减少18%（ConfAIde）和19%（PrivacyLens），同时保持公共内容的保真度，优于单智能体基线。

Conclusion: 我们的多智能体框架通过将隐私推理分解为专门的子任务（提取、分类），减少了任何单个智能体的信息负载，同时实现了迭代验证和对上下文隐私规范更可靠的遵守。实验表明，我们最好的多智能体配置在ConfAIde和PrivacyLens基准上，可以显著减少私人信息泄露（在ConfAIde上减少18%，在PrivacyLens上减少19%），同时保持公共内容的保真度，优于单智能体基线。这些结果突显了在具有LLM的上下文隐私的多智能体系统中，基于原则的信息流设计的承诺。

Abstract: Addressing contextual privacy concerns remains challenging in interactive
settings where large language models (LLMs) process information from multiple
sources (e.g., summarizing meetings with private and public information). We
introduce a multi-agent framework that decomposes privacy reasoning into
specialized subtasks (extraction, classification), reducing the information
load on any single agent while enabling iterative validation and more reliable
adherence to contextual privacy norms. To understand how privacy errors emerge
and propagate, we conduct a systematic ablation over information-flow
topologies, revealing when and why upstream detection mistakes cascade into
downstream leakage. Experiments on the ConfAIde and PrivacyLens benchmark with
several open-source and closed-sourced LLMs demonstrate that our best
multi-agent configuration substantially reduces private information leakage
(\textbf{18\%} on ConfAIde and \textbf{19\%} on PrivacyLens with GPT-4o) while
preserving the fidelity of public content, outperforming single-agent
baselines. These results highlight the promise of principled information-flow
design in multi-agent systems for contextual privacy with LLMs.

</details>


### [713] [Ethics2vec: aligning automatic agents and human preferences](https://arxiv.org/abs/2508.07673)
*Gianluca Bontempi*

Main category: cs.AI

TL;DR: 
The paper introduces Ethics2vec, a method based on Anything2vec, to represent AI decision-making strategies as vectors. This allows for the measurement and comparison of AI alignment with human values, addressing the challenge of incommensurable ethical criteria. The method is shown to be applicable to both binary decisions and control systems like self-driving cars.



<details>
  <summary>Details</summary>
Motivation: 
The motivation of this paper is to address the challenge of aligning AI systems with human values, a problem exacerbated by the incommensurable nature of many human ethical considerations. It is difficult for humans to grasp the ethical values embedded in AI behavior, and the paper aims to provide a method for quantifying and comparing these values to ensure AI alignment.


Method: 
This paper proposes extending the Anything2vec approach to ethics, introducing the Ethics2vec method. This method maps agent decision-making or control law strategies to a multivariate vector representation. The paper first details this approach for agents performing binary decision-making, and then discusses its extension to automatic control settings, such as self-driving cars.


Result: 
The paper proposes the Ethics2vec method as a way to create a common space with a defined metric for aligning human and artificial values. This method generates a multivariate vector representation of agent decision-making strategies, allowing for comparison and assessment of alignment. The effectiveness of this approach is demonstrated through its application to binary decision-making and its extension to automatic control.


Conclusion: 
While the alignment between human and artificial values is challenging due to incommensurable values, this paper proposes the Ethics2vec method to map agent decision-making strategies to a multivariate vector representation, enabling comparison and assessment of alignment with human values. The method is introduced for binary decision-making and extended to automatic control settings.


Abstract: Though intelligent agents are supposed to improve human experience (or make
it more efficient), it is hard from a human perspective to grasp the ethical
values which are explicitly or implicitly embedded in an agent behaviour. This
is the well-known problem of alignment, which refers to the challenge of
designing AI systems that align with human values, goals and preferences. This
problem is particularly challenging since most human ethical considerations
refer to \emph{incommensurable} (i.e. non-measurable and/or incomparable)
values and criteria. Consider, for instance, a medical agent prescribing a
treatment to a cancerous patient. How could it take into account (and/or weigh)
incommensurable aspects like the value of a human life and the cost of the
treatment? Now, the alignment between human and artificial values is possible
only if we define a common space where a metric can be defined and used. This
paper proposes to extend to ethics the conventional Anything2vec approach,
which has been successful in plenty of similar and hard-to-quantify domains
(ranging from natural language processing to recommendation systems and graph
analysis). This paper proposes a way to map an automatic agent decision-making
(or control law) strategy to a multivariate vector representation, which can be
used to compare and assess the alignment with human values. The Ethics2Vec
method is first introduced in the case of an automatic agent performing binary
decision-making. Then, a vectorisation of an automatic control law (like in the
case of a self-driving car) is discussed to show how the approach can be
extended to automatic control settings.

</details>


### [714] [Symmetry-Aware Transformer Training for Automated Planning](https://arxiv.org/abs/2508.07743)
*Markus Fritzsche,Elliot Gestrin,Jendrik Seipp*

Main category: cs.AI

TL;DR: Transformer 在自动化规划中存在问题对称性导致的泛化能力不足。我们提出了一种对称感知对比学习方法，改进了 Transformer，使其能够高效地用于计划生成和启发式预测，并克服了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: Transformer 在自动化规划领域存在局限性，特别是 PlanGPT 在处理从易到难的规划问题时存在外推能力不足的问题，这源于问题对称性（任意的变量名导致等价表示的组合爆炸，纯 Transformer 难以有效学习）。

Method: 提出了一种新颖的对比学习目标，使 Transformer 能够感知对称性，并结合了架构改进。

Result: 证明了 Transformer 可以被高效训练用于计划生成或启发式预测，并且所提出的对称感知训练方法有效且高效地解决了 PlanGPT 的局限性。

Conclusion: 通过引入新颖的对比学习目标和架构改进，使 Transformer 能够感知对称性，从而有效且高效地克服了 PlanGPT 的局限性，并在多个规划领域取得了成果。

Abstract: While transformers excel in many settings, their application in the field of
automated planning is limited. Prior work like PlanGPT, a state-of-the-art
decoder-only transformer, struggles with extrapolation from easy to hard
planning problems. This in turn stems from problem symmetries: planning tasks
can be represented with arbitrary variable names that carry no meaning beyond
being identifiers. This causes a combinatorial explosion of equivalent
representations that pure transformers cannot efficiently learn from. We
propose a novel contrastive learning objective to make transformers
symmetry-aware and thereby compensate for their lack of inductive bias.
Combining this with architectural improvements, we show that transformers can
be efficiently trained for either plan-generation or heuristic-prediction. Our
results across multiple planning domains demonstrate that our symmetry-aware
training effectively and efficiently addresses the limitations of PlanGPT.

</details>


### [715] [\(X\)-evolve: Solution space evolution powered by large language models](https://arxiv.org/abs/2508.07932)
*Yi Zhai,Zhiqiang Wei,Ruohan Li,Keyu Pan,Shuo Liu,Lu Zhang,Jianmin Ji,Wuyang Zhang,Yu Zhang,Yanyong Zhang*

Main category: cs.AI

TL;DR: X-evolve 通过进化可调谐程序定义的解空间（而非单个解）来优化复杂问题，显著降低了 LLM 调用成本，并在盖帽集、信息论和在线装箱问题上取得了新成果。


<details>
  <summary>Details</summary>
Motivation: 现有方法将大型语言模型（LLM）与进化算法（EA）结合用于解决复杂优化问题，但它们通常进化单个解，导致 LLM 调用成本高昂。X-evolve 旨在通过进化解空间来降低成本并提高效率。

Method: 本研究提出了一种名为 X-evolve 的新范式，它通过进化解空间（即一组解）而不是单个解来解决优化问题。LLM 用于生成可调谐程序，其中特定代码片段被指定为参数，从而定义了一个可调谐的解空间。然后，基于分数的搜索算法通过目标函数分数的反馈来高效地探索这个参数化空间。

Result: X-evolve 在三个优化问题上取得了显著成果：在盖帽集问题中，发现了一个更大的部分可容许集，为盖帽集常数（C ≥ 2.2203）建立了一个新的更紧的渐近下界；在信息论中，为 15-顶点循环图（C15⊛5，大小 19,946）发现了一个更大的独立集，从而提高了其香农容量的已知下界；在 NP-hard 在线装箱问题中，生成了持续优于标准策略的启发式算法。

Conclusion: 通过进化解空间而不是单个解，该方法能够以更低的成本解决先前计算成本过高而无法解决的高维问题。通过在三个不同的硬优化问题上展示其有效性，该方法在盖帽集问题、信息论和在线装箱问题上都取得了显著成果。

Abstract: While combining large language models (LLMs) with evolutionary algorithms
(EAs) shows promise for solving complex optimization problems, current
approaches typically evolve individual solutions, often incurring high LLM call
costs. We introduce \(X\)-evolve, a paradigm-shifting method that instead
evolves solution spaces \(X\) (sets of individual solutions) - subsets of the
overall search space \(S\). In \(X\)-evolve, LLMs generate tunable programs
wherein certain code snippets, designated as parameters, define a tunable
solution space. A score-based search algorithm then efficiently explores this
parametrically defined space, guided by feedback from objective function
scores. This strategy enables broader and more efficient exploration, which can
potentially accelerate convergence at a much lower search cost, requiring up to
two orders of magnitude fewer LLM calls than prior leading methods. We
demonstrate \(X\)-evolve's efficacy across three distinct hard optimization
problems. For the cap set problem, we discover a larger partial admissible set,
establishing a new tighter asymptotic lower bound for the cap set constant (\(C
\ge 2.2203\)). In information theory, we uncover a larger independent set for
the 15-vertex cycle graph (\(\mathcal{C}_{15}^{\boxtimes 5}\), size 19,946),
thereby raising the known lower bound on its Shannon capacity. Furthermore, for
the NP-hard online bin packing problem, we generate heuristics that
consistently outperform standard strategies across established benchmarks. By
evolving solution spaces, our method considerably improves search
effectiveness, making it possible to tackle high-dimensional problems that were
previously computationally prohibitive.

</details>


### [716] [Deep Reinforcement Learning with anticipatory reward in LSTM for Collision Avoidance of Mobile Robots](https://arxiv.org/abs/2508.07941)
*Olivier Poulet,Frédéric Guinand,François Guérin*

Main category: cs.AI

TL;DR: 通过LSTM预测机器人位置并用DQN调整奖励，降低碰撞率并提高稳定性，适用于嵌入式系统。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人自主导航中的碰撞问题，提出一种新的碰撞风险预知方法。

Method: 提出一种基于短期预测的碰撞风险预知方法，利用长短期记忆（LSTM）模型估计机器人下一位置，并通过动态调整深度Q学习（DQN）智能体的奖励来定义预知的碰撞风险。

Result: 在无通信或标识符的双机器人场景下，尽管采样频率有限（1Hz），结果显示碰撞次数显著减少，稳定性有所提高。

Conclusion: 该方法计算成本低廉，特别适合在嵌入式系统上实现。

Abstract: This article proposes a collision risk anticipation method based on
short-term prediction of the agents position. A Long Short-Term Memory (LSTM)
model, trained on past trajectories, is used to estimate the next position of
each robot. This prediction allows us to define an anticipated collision risk
by dynamically modulating the reward of a Deep Q-Learning Network (DQN) agent.
The approach is tested in a constrained environment, where two robots move
without communication or identifiers. Despite a limited sampling frequency (1
Hz), the results show a significant decrease of the collisions number and a
stability improvement. The proposed method, which is computationally
inexpensive, appears particularly attractive for implementation on embedded
systems.

</details>


### [717] [Interpreting Fedspeak with Confidence: A LLM-Based Uncertainty-Aware Framework Guided by Monetary Policy Transmission Paths](https://arxiv.org/abs/2508.08001)
*Rui Yao,Qi Chai,Jinhai Yao,Siyuan Li,Junhao Chen,Qi Zhang,Hao Wang*

Main category: cs.AI

TL;DR: 该研究提出了一种基于LLM的框架，通过结合货币政策知识和不确定性解码来分析美联储的Fedspeak，以确定其货币政策立场，并在实验中取得了领先的性能。


<details>
  <summary>Details</summary>
Motivation: 自动解析和解释Fedspeak具有高影响力，对金融预测、算法交易和数据驱动的政策分析具有重要意义，因为Fedspeak包含隐性的政策信号和战略立场，美联储使用它来塑造市场预期并影响经济条件。

Method: 提出了一种基于LLM的、感知不确定性的框架，通过结合货币政策传导机制的领域特定推理和动态不确定性解码模块来解读Fedspeak并对其货币政策立场进行分类。

Result: 实验结果表明，该框架在政策立场分析任务上取得了最先进的性能。统计分析显示感知不确定性与模型错误率之间存在显著的正相关关系，验证了感知不确定性作为诊断信号的有效性。

Conclusion: 该框架在政策立场分析任务上实现了最先进的性能，并且感知不确定性作为一种诊断信号被证明是有效的。

Abstract: "Fedspeak", the stylized and often nuanced language used by the U.S. Federal
Reserve, encodes implicit policy signals and strategic stances. The Federal
Open Market Committee strategically employs Fedspeak as a communication tool to
shape market expectations and influence both domestic and global economic
conditions. As such, automatically parsing and interpreting Fedspeak presents a
high-impact challenge, with significant implications for financial forecasting,
algorithmic trading, and data-driven policy analysis. In this paper, we propose
an LLM-based, uncertainty-aware framework for deciphering Fedspeak and
classifying its underlying monetary policy stance. Technically, to enrich the
semantic and contextual representation of Fedspeak texts, we incorporate
domain-specific reasoning grounded in the monetary policy transmission
mechanism. We further introduce a dynamic uncertainty decoding module to assess
the confidence of model predictions, thereby enhancing both classification
accuracy and model reliability. Experimental results demonstrate that our
framework achieves state-of-the-art performance on the policy stance analysis
task. Moreover, statistical analysis reveals a significant positive correlation
between perceptual uncertainty and model error rates, validating the
effectiveness of perceptual uncertainty as a diagnostic signal.

</details>


### [718] [Fitting Description Logic Ontologies to ABox and Query Examples](https://arxiv.org/abs/2508.08007)
*Maurice Funk,Marvin Grosser,Carsten Lutz*

Main category: cs.AI

TL;DR: 本文研究了本体中介查询中的拟合问题，在$\\mathcal{ALC}}$和$\\mathcal{ALCI}}}$本体语言以及AQs、CQs、UCQs查询语言下，给出了拟合问题的有效特征和计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 受到本体中介查询的启发，研究了一个拟合问题：给定一系列形式为$(\\mathcal{A},q)$的正面和负面例子，其中$\\mathcal{A}$是ABox，$q$是布尔查询，寻找一个本体$\\mathcal{O}$，使得对于所有正面例子，$\\mathcal{A} \\cup \\mathcal{O} \\vDash q$，对于所有负面例子，$\\mathcal{A} \\cup \\mathcal{O} \\not\\vDash q$

Method: 研究了本体$\\mathcal{ALC}$和$\\mathcal{ALCI}$以及原子查询（AQs）、联接查询（CQs）及其并集（UCQs）的拟合问题，并给出了有效的特征描述和计算复杂度。

Result: 为拟合问题提供了有效的特征描述，并确定了判定是否存在拟合本体的计算复杂度。

Conclusion: 该问题对于原子查询（AQs）和全联接查询（CQs）为${\small CO}NP$ -complete，对于联接查询（CQs）和其并集（UCQs）为$2E{\small XP}T{\small IME}$-complete。这些结果同时适用于$\\mathcal{ALC}$和$\\mathcal{ALCI}$。

Abstract: We study a fitting problem inspired by ontology-mediated querying: given a
collection
  of positive and negative examples of
  the form $(\mathcal{A},q)$ with
  $\mathcal{A}$ an ABox and $q$ a Boolean query, we seek
  an ontology $\mathcal{O}$ that satisfies $\mathcal{A} \cup \mathcal{O} \vDash
q$ for all positive examples and $\mathcal{A} \cup \mathcal{O}\not\vDash q$ for
all negative examples.
  We consider the description logics $\mathcal{ALC}$ and $\mathcal{ALCI}$ as
ontology languages and
  a range of query languages that
  includes atomic queries (AQs), conjunctive queries (CQs), and unions thereof
(UCQs).
  For all of the resulting fitting problems,
  we provide
  effective characterizations and determine the computational complexity
  of deciding whether a fitting ontology exists. This problem turns out to be
${\small CO}NP$ for AQs and full CQs
  and $2E{\small XP}T{\small IME}$-complete for CQs and UCQs.
  These results hold for both $\mathcal{ALC}$ and $\mathcal{ALCI}$.

</details>


### [719] [AdaptFlow: Adaptive Workflow Optimization via Meta-Learning](https://arxiv.org/abs/2508.08053)
*Runchuan Zhu,Bowen Jiang,Lingrui Mei,Fangkai Yang,Lu Wang,Haoxiang Gao,Fengshuo Bai,Pu Zhao,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang*

Main category: cs.AI

TL;DR: AdaptFlow是一个新框架，通过元学习优化LLM工作流，以适应各种任务，并在多个基准测试中取得领先成果。


<details>
  <summary>Details</summary>
Motivation: 现有的agentic workflows方法依赖于静态模板或手动设计的工作流，这限制了对不同任务的适应性并阻碍了可扩展性。

Method: AdaptFlow是一个基于自然语言的元学习框架，受到模型无关元学习（MAML）的启发。它采用双层优化方案：内循环利用LLM生成的反馈为特定子任务优化工作流，外循环更新共享初始化以跨任务执行。

Result: AdaptFlow在问答、代码生成和数学推理基准测试中，始终优于手动设计的和自动搜索的基线，实现了最先进的结果，并具有强大的跨任务和跨模型泛化能力。

Conclusion: AdaptFlow在问答、代码生成和数学推理基准测试中，始终优于手动设计的和自动搜索的基线，在跨任务和跨模型实现最先进的结果和强大的泛化能力。

Abstract: Recent advances in large language models (LLMs) have sparked growing interest
in agentic workflows, which are structured sequences of LLM invocations
intended to solve complex tasks. However, existing approaches often rely on
static templates or manually designed workflows, which limit adaptability to
diverse tasks and hinder scalability. We propose AdaptFlow, a natural
language-based meta-learning framework inspired by model-agnostic meta-learning
(MAML). AdaptFlow learns a generalizable workflow initialization that enables
rapid subtask-level adaptation. It employs a bi-level optimization scheme: the
inner loop refines the workflow for a specific subtask using LLM-generated
feedback, while the outer loop updates the shared initialization to perform
well across tasks. This setup allows AdaptFlow to generalize effectively to
unseen tasks by adapting the initialized workflow through language-guided
modifications. Evaluated across question answering, code generation, and
mathematical reasoning benchmarks, AdaptFlow consistently outperforms both
manually crafted and automatically searched baselines, achieving
state-of-the-art results with strong generalization across tasks and models.
The source code and data are available at
https://github.com/microsoft/DKI_LLM/tree/AdaptFlow/AdaptFlow.

</details>


### [720] [FNBT: Full Negation Belief Transformation for Open-World Information Fusion Based on Dempster-Shafer Theory of Evidence](https://arxiv.org/abs/2508.08075)
*Meishen He,Wenjun Ma,Jiao Wang,Huijun Yue,Xiaoma Fan*

Main category: cs.AI

TL;DR: FNBT是一种用于处理异构框架下信息融合的Dempster-Shafer理论方法，通过框架扩展和全否定转换来解决传统方法的不足，并在模式分类任务中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的证据理论方法主要关注同一辨别框架内的证据组合，但在实际场景中，数据源或模型可能来自不同的区域或组织，导致辨别框架异构，传统融合方法效果不佳。

Method: 提出了一种基于Dempster-Shafer理论的开放世界信息融合方法，称为全否定信念转换（FNBT）。该方法通过引入一个标准来判断融合任务是否属于开放世界设置，然后扩展框架以适应来自异构框架的元素，最后使用全否定机制转换质量函数，以便将现有的组合规则应用于转换后的质量函数进行信息融合。

Result: FNBT满足质量函数不变性、可继承性和本质冲突消除三个期望的性质，并已得到正式证明。

Conclusion: FNBT在现实世界数据集的模式分类任务中表现出优越的性能，并成功解决了Zadeh的逆否命题，验证了其有效性。

Abstract: The Dempster-Shafer theory of evidence has been widely applied in the field
of information fusion under uncertainty. Most existing research focuses on
combining evidence within the same frame of discernment. However, in real-world
scenarios, trained algorithms or data often originate from different regions or
organizations, where data silos are prevalent. As a result, using different
data sources or models to generate basic probability assignments may lead to
heterogeneous frames, for which traditional fusion methods often yield
unsatisfactory results. To address this challenge, this study proposes an
open-world information fusion method, termed Full Negation Belief
Transformation (FNBT), based on the Dempster-Shafer theory. More specially, a
criterion is introduced to determine whether a given fusion task belongs to the
open-world setting. Then, by extending the frames, the method can accommodate
elements from heterogeneous frames. Finally, a full negation mechanism is
employed to transform the mass functions, so that existing combination rules
can be applied to the transformed mass functions for such information fusion.
Theoretically, the proposed method satisfies three desirable properties, which
are formally proven: mass function invariance, heritability, and essential
conflict elimination. Empirically, FNBT demonstrates superior performance in
pattern classification tasks on real-world datasets and successfully resolves
Zadeh's counterexample, thereby validating its practical effectiveness.

</details>


### [721] [TeamMedAgents: Enhancing Medical Decision-Making of LLMs Through Structured Teamwork](https://arxiv.org/abs/2508.08115)
*Pranav Pushkar Mishra,Mohammad Arvan,Mohan Zalake*

Main category: cs.AI

TL;DR: TeamMedAgents将人类团队合作理论应用于医学决策LLM，通过整合六个核心团队合作组成部分来提高性能，并在大多数医学基准测试中显示出改进，其最优配置因任务而异。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是将人类协作中的循证团队合作理论系统地转化为代理协作，为在关键决策领域设计循证多代理系统奠定基础。

Method: TeamMedAgents是一种新颖的多代理方法，它将循证团队合作的组成部分系统地整合到大型语言模型（LLM）的医学决策中。该方法通过实施源自Salas等人的“大五”模型的六个核心团队组成部分（团队领导、相互绩效监控、团队导向、心智模型共享、闭环沟通和相互信任）来验证从人类协作到计算性多代理医学系统。这些组成部分被实现为自适应协作架构中的模块化、可配置机制，并评估了所涉及代理数量对任务需求和领域的影响。

Result: 在八个医学基准（MedQA、MedMCQA、MMLU-Pro Medical、PubMedQA、DDXPlus、MedBullets、Path-VQA和PMC-VQA）上的评估表明，TeamMedAgents在7个数据集中持续改进。消融研究揭示了特定于数据集的最优团队合作配置，表明不同的医学推理模式受益于不同的协作模式。

Conclusion: TeamMedAgents在跨越八个医学基准的评估中，在7个数据集中展示了持续的改进，并提供了关于个别组件贡献的机制见解，揭示了可根据推理任务复杂性和特定领域要求进行调整的最优团队配置。

Abstract: We present TeamMedAgents, a novel multi-agent approach that systematically
integrates evidence-based teamwork components from human-human collaboration
into medical decision-making with large language models (LLMs). Our approach
validates an organizational psychology teamwork model from human collaboration
to computational multi-agent medical systems by operationalizing six core
teamwork components derived from Salas et al.'s "Big Five" model: team
leadership, mutual performance monitoring, team orientation, shared mental
models, closed-loop communication, and mutual trust. We implement and evaluate
these components as modular, configurable mechanisms within an adaptive
collaboration architecture while assessing the effect of the number of agents
involved based on the task's requirements and domain. Systematic evaluation of
computational implementations of teamwork behaviors across eight medical
benchmarks (MedQA, MedMCQA, MMLU-Pro Medical, PubMedQA, DDXPlus, MedBullets,
Path-VQA, and PMC-VQA) demonstrates consistent improvements across 7 out of 8
evaluated datasets. Controlled ablation studies conducted on 50 questions per
configuration across 3 independent runs provide mechanistic insights into
individual component contributions, revealing optimal teamwork configurations
that vary by reasoning task complexity and domain-specific requirements. Our
ablation analyses reveal dataset-specific optimal teamwork configurations,
indicating that different medical reasoning modalities benefit from distinct
collaborative patterns. TeamMedAgents represents an advancement in
collaborative AI by providing a systematic translation of established teamwork
theories from human collaboration into agentic collaboration, establishing a
foundation for evidence-based multi-agent system design in critical
decision-making domains.

</details>


### [722] [BlindGuard: Safeguarding LLM-based Multi-Agent Systems under Unknown Attacks](https://arxiv.org/abs/2508.08127)
*Rui Miao,Yixin Liu,Yili Wang,Xu Shen,Yue Tan,Yiwei Dai,Shirui Pan,Xin Wang*

Main category: cs.AI

TL;DR: BlindGuard 是一种无监督的 LLM MAS 安全防御方法，通过分层编码和腐败引导检测来检测恶意代理，无需先验知识即可实现高效的攻击检测和泛化。


<details>
  <summary>Details</summary>
Motivation: 现有基于监督的防御方法在真实场景中可能不切实际，因为它们严重依赖标记的恶意代理来训练监督恶意检测模型。因此，需要一种无需攻击特定标签或恶意行为先验知识的无监督防御方法。

Method: BlindGuard 通过分层代理编码器捕获个体、邻域和全局交互模式，并设计了以腐败为指导的检测器，包括定向噪声注入和对比学习，仅使用正常代理行为即可有效训练检测模型。

Result: BlindGuard 在各种通信模式的 MAS 中有效地检测了各种攻击类型（即提示注入、内存中毒和工具攻击），与监督基线相比，保持了卓越的泛化能力。

Conclusion: BlindGuard 是一种无监督防御方法，无需攻击特定的标签或恶意行为的先验知识，即可有效检测各种类型的攻击，并具有出色的泛化能力。

Abstract: The security of LLM-based multi-agent systems (MAS) is critically threatened
by propagation vulnerability, where malicious agents can distort collective
decision-making through inter-agent message interactions. While existing
supervised defense methods demonstrate promising performance, they may be
impractical in real-world scenarios due to their heavy reliance on labeled
malicious agents to train a supervised malicious detection model. To enable
practical and generalizable MAS defenses, in this paper, we propose BlindGuard,
an unsupervised defense method that learns without requiring any
attack-specific labels or prior knowledge of malicious behaviors. To this end,
we establish a hierarchical agent encoder to capture individual, neighborhood,
and global interaction patterns of each agent, providing a comprehensive
understanding for malicious agent detection. Meanwhile, we design a
corruption-guided detector that consists of directional noise injection and
contrastive learning, allowing effective detection model training solely on
normal agent behaviors. Extensive experiments show that BlindGuard effectively
detects diverse attack types (i.e., prompt injection, memory poisoning, and
tool attack) across MAS with various communication patterns while maintaining
superior generalizability compared to supervised baselines. The code is
available at: https://github.com/MR9812/BlindGuard.

</details>


### [723] [From Natural Language to Solver-Ready Power System Optimization: An LLM-Assisted, Validation-in-the-Loop Framework](https://arxiv.org/abs/2508.08147)
*Yunkai Hu,Tianqiao Zhao,Meng Yue*

Main category: cs.AI

TL;DR: 本研究提出了一种 LLM 辅助代理，可将自然语言描述的电力系统优化问题转换为可求解的模型，并确保解决方案的可行性和最优性。与直接使用 LLM 生成解决方案不同，该方法结合了 LLM 的理解能力和传统优化求解器的精确性，通过验证和修复来提高结果的可靠性。在单元承诺问题上的实验证明了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 直接使用 LLM 产生解决方案可能导致不可行或次优的结果，因为这些模型缺乏既定优化求解器的数值精度和约束处理能力。

Method: 提出了一种新颖的大型语言模型（LLMs）辅助代理，可自动将电力系统优化场景的自然语言描述转换为紧凑、可供求解器使用的模型，并生成相应的解决方案。该方法侧重于发现数学上兼容且可被现成优化求解器有效求解的模型，并通过领域感知提示和模式集成 LLM，利用系统验证和迭代修复来强制执行可行性。

Result: 在以单元承诺问题为代表性案例研究中，该代理生成了最优或接近最优的调度以及相关的目标成本。结果表明，将求解器与特定任务验证相结合可显著提高解决方案的可靠性。

Conclusion: 该研究表明，将人工智能与既定的优化框架相结合，可以架起高级问题描述与可执行数学模型之间的桥梁，从而在能源系统中实现更高效的决策。

Abstract: This paper introduces a novel Large Language Models (LLMs)-assisted agent
that automatically converts natural-language descriptions of power system
optimization scenarios into compact, solver-ready formulations and generates
corresponding solutions. In contrast to approaches that rely solely on LLM to
produce solutions directly, the proposed method focuses on discovering a
mathematically compatible formulation that can be efficiently solved by
off-the-shelf optimization solvers. Directly using LLMs to produce solutions
often leads to infeasible or suboptimal results, as these models lack the
numerical precision and constraint-handling capabilities of established
optimization solvers. The pipeline integrates a domain-aware prompt and schema
with an LLM, enforces feasibility through systematic validation and iterative
repair, and returns both solver-ready models and user-facing results. Using the
unit commitment problem as a representative case study, the agent produces
optimal or near-optimal schedules along with the associated objective costs.
Results demonstrate that coupling the solver with task-specific validation
significantly enhances solution reliability. This work shows that combining AI
with established optimization frameworks bridges high-level problem
descriptions and executable mathematical models, enabling more efficient
decision-making in energy systems

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [724] [Reservoir computing with large valid prediction time for the Lorenz system](https://arxiv.org/abs/2508.06730)
*Lauren A Hurley,Sean E Shaheen*

Main category: cs.NE

TL;DR: 本文研究了超参数对储层计算机（RC）有效预测时间（VPT）的影响，发现在特定条件下 VPT 超过 30 个李亚普诺夫时间，并且可以通过预测误差来评估 VPT。文章还确定了实现大 VPT 的两个谱半径区域，并强调了数值求解器对结果的重要性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究超参数（如正则化系数、储层大小和谱半径）对储层计算机（RC）的有效预测时间（VPT）的影响，并探索一种计算上有效的评估 VPT 的方法。

Method: 本文研究了正则化系数、储层大小和谱半径等超参数对储层计算机（RC）的有效预测时间（VPT）的影响。我们使用拉越诺埃（Lorenz）方程的单步预测作为初始条件来评估 RC 的性能。此外，我们还利用了李亚普诺夫指数的知识，并通过前几步预测的误差来预测 VPT。我们还定义了有效基准时间（VGTT），以评估数值求解器的重要性。

Result: 在特定条件下，RC 的 VPT 超过 30 个李亚普诺夫时间。预测的 VPT 可以通过前几步预测的误差来计算。存在两个谱半径区域可以实现大 VPT：接近零的小半径和接近“混沌边缘”的大半径。

Conclusion: 在研究了正则化系数、储层大小和谱半径等超参数对储层计算机（RC）的有效预测时间（VPT）的影响后，我们发现，在仔细选择的条件下，RC 可以达到约 70% 的基准性能。通过利用与拉越诺埃（Lorenz）方程初始条件输出相关的单步预测，我们报告了超过 30 个李亚普诺夫时间（Lyapunov times）的高 VPT 值，这在预测无噪声系统时尤为明显，因为在这种情况下，过拟合可能是有益的。尽管这些条件可能不适用于有噪声的系统，但它们仍可能对噪声有限的实际应用有用。此外，我们发现通过利用李亚普诺夫指数的知识，可以通过前几步预测的误差来预测 VPT，这提供了一种计算上有效的评估方法。我们强调了用于生成拉越诺埃数据集的数值求解器的重要性，并定义了有效基准时间（VGTT），在此期间，几个通用求解器的输出是一致的。超过 VGTT 的 VPT 没有意义，因为不同的求解器可能会产生不同的结果。最后，我们确定了实现大 VPT 的两个谱半径区域：接近零的小半径，可实现简单但稳定的操作；以及在大约“混沌边缘”运行的较大半径。

Abstract: We study the dependence of the Valid Prediction Time (VPT) of Reservoir
Computers (RCs) on hyperparameters including the regularization coefficient,
reservoir size, and spectral radius. Under carefully chosen conditions, the RC
can achieve approximately 70% of a benchmark performance, based on the output
of a single prediction step used as initial conditions for the Lorenz
equations. We report high VPT values (>30 Lyapunov times), as we are predicting
a noiseless system where overfitting can be beneficial. While these conditions
may not hold for noisy systems, they could still be useful for real-world
applications with limited noise. Furthermore, utilizing knowledge of the
Lyapunov exponent, we find that the VPT can be predicted by the error in the
first few prediction steps, offering a computationally efficient evaluation
method. We emphasize the importance of the numerical solver used to generate
the Lorenz dataset and define a Valid Ground Truth Time (VGTT), during which
the outputs of several common solvers agree. A VPT exceeding the VGTT is not
meaningful, as a different solver could produce a different result. Lastly, we
identify two spectral radius regimes that achieve large VPT: a small radius
near zero, resulting in simple but stable operation, and a larger radius
operating at the "edge of chaos."

</details>


### [725] [Geometry-Aware Spiking Graph Neural Network](https://arxiv.org/abs/2508.06793)
*Bowen Zhang,Genan Dai,Hu Huang,Long Lan*

Main category: cs.NE

TL;DR: GSG是一种新颖的几何感知脉冲图神经网络，它在黎曼流形上进行自适应表示学习，实现了优越的准确性、鲁棒性和能效。


<details>
  <summary>Details</summary>
Motivation: 现有脉冲GNN主要在欧几里得空间中运行，并依赖于固定的几何假设，这限制了它们对层次结构和周期等复杂图结构建模的能力。

Method: GSG是一种新颖的几何感知脉冲图神经网络，它将脉冲神经动力学与黎曼流形上的自适应表示学习相结合。其关键组成部分包括：黎曼嵌入层（将节点特征投影到恒定曲率流形池中，以捕捉非欧几里得结构）、脉冲流形层（通过几何一致的邻域聚合和基于曲率的注意力在弯曲空间中模拟膜电位演化和脉冲行为）和流形学习目标（通过联合优化的分类和测地线距离上的链接预测损失来实现实例级的几何适应）。所有模块均使用黎曼SGD进行训练，无需通过时间反向传播。

Result: GSG在准确性、鲁棒性和能效方面均优于欧几里得SNN和基于流形的GNN。

Conclusion: GSG在准确性、鲁棒性和能效方面均优于欧几里得SNN和基于流形的GNN，为曲率感知、能效图学习树立了新范例。

Abstract: Graph Neural Networks (GNNs) have demonstrated impressive capabilities in
modeling graph-structured data, while Spiking Neural Networks (SNNs) offer high
energy efficiency through sparse, event-driven computation. However, existing
spiking GNNs predominantly operate in Euclidean space and rely on fixed
geometric assumptions, limiting their capacity to model complex graph
structures such as hierarchies and cycles. To overcome these limitations, we
propose \method{}, a novel Geometry-Aware Spiking Graph Neural Network that
unifies spike-based neural dynamics with adaptive representation learning on
Riemannian manifolds. \method{} features three key components: a Riemannian
Embedding Layer that projects node features into a pool of constant-curvature
manifolds, capturing non-Euclidean structures; a Manifold Spiking Layer that
models membrane potential evolution and spiking behavior in curved spaces via
geometry-consistent neighbor aggregation and curvature-based attention; and a
Manifold Learning Objective that enables instance-wise geometry adaptation
through jointly optimized classification and link prediction losses defined
over geodesic distances. All modules are trained using Riemannian SGD,
eliminating the need for backpropagation through time. Extensive experiments on
multiple benchmarks show that GSG achieves superior accuracy, robustness, and
energy efficiency compared to both Euclidean SNNs and manifold-based GNNs,
establishing a new paradigm for curvature-aware, energy-efficient graph
learning.

</details>


### [726] [Memory Enhanced Fractional-Order Dung Beetle Optimization for Photovoltaic Parameter Identification](https://arxiv.org/abs/2508.06841)
*Yiwei Li,Zhihua Allen-Zhao,Yuncheng Xu,Sanyang Liu*

Main category: cs.NE

TL;DR: MFO-DBO算法通过引入分数阶演算和混沌映射来增强DBO算法，解决了光伏模型参数识别中的收敛和优化问题，并在多项测试中取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决光伏（PV）模型参数识别的挑战，即其非线性、多模态和高维特性，以及DBO算法容易过早收敛的问题。

Method: 提出了一种结合记忆增强、分数阶逻辑混沌映射和混沌扰动机制的MFO-DBO算法。

Result: MFO-DBO算法在准确性、鲁棒性、收敛速度方面持续优于先进的DBO变体、CEC竞赛获胜者、基于FO的优化器、改进的经典算法和近期元启发式算法。

Conclusion: MFO-DBO算法在PV参数识别问题和CEC2017基准测试套件上均表现优于其他算法，具有更高的准确性、鲁棒性、收敛速度，并能在探索和利用之间保持良好的平衡。

Abstract: Accurate parameter identification in photovoltaic (PV) models is crucial for
performance evaluation but remains challenging due to their nonlinear,
multimodal, and high-dimensional nature. Although the Dung Beetle Optimization
(DBO) algorithm has shown potential in addressing such problems, it often
suffers from premature convergence. To overcome these issues, this paper
proposes a Memory Enhanced Fractional-Order Dung Beetle Optimization (MFO-DBO)
algorithm that integrates three coordinated strategies. Firstly,
fractional-order (FO) calculus introduces memory into the search process,
enhancing convergence stability and solution quality. Secondly, a
fractional-order logistic chaotic map improves population diversity during
initialization. Thirdly, a chaotic perturbation mechanism helps elite solutions
escape local optima. Numerical results on the CEC2017 benchmark suite and the
PV parameter identification problem demonstrate that MFO-DBO consistently
outperforms advanced DBO variants, CEC competition winners, FO-based
optimizers, enhanced classical algorithms, and recent metaheuristics in terms
of accuracy, robustness, convergence speed, while also maintaining an excellent
balance between exploration and exploitation compared to the standard DBO
algorithm.

</details>


### [727] [Enhancing Decision Space Diversity in Multi-Objective Evolutionary Optimization for the Diet Problem](https://arxiv.org/abs/2508.07077)
*Gustavo V. Nascimento,Ivan R. Meneghini,Valéria Santos,Eduardo Luz,Gladston Moreira*

Main category: cs.NE

TL;DR: 本论文提出了一种将汉明距离均匀性度量整合到MOEA选择机制中的方法，以增强决策空间多样性，并在食物问题上取得了比NSGA-II更好的效果。


<details>
  <summary>Details</summary>
Motivation: 大多数MOEA在优化目标空间解的同时，往往忽略了决策空间解的多样性，而这对于为决策者提供广泛的选择至关重要。

Method: 通过将基于汉明距离的均匀性度量直接集成到MOEA的选择机制中来增强决策空间的多样性。

Result: 在多目标食物问题制定上进行实验，证明该方法与NSGA-II相比，显著提高了决策空间多样性，同时保持了可比的目标空间性能。

Conclusion: 该方法为将决策空间意识纳入MOEA提供了一种通用的策略。

Abstract: Multi-objective evolutionary algorithms (MOEAs) are essential for solving
complex optimization problems, such as the diet problem, where balancing
conflicting objectives, like cost and nutritional content, is crucial. However,
most MOEAs focus on optimizing solutions in the objective space, often
neglecting the diversity of solutions in the decision space, which is critical
for providing decision-makers with a wide range of choices. This paper
introduces an approach that directly integrates a Hamming distance-based
measure of uniformity into the selection mechanism of a MOEA to enhance
decision space diversity. Experiments on a multi-objective formulation of the
diet problem demonstrate that our approach significantly improves decision
space diversity compared to NSGA-II, while maintaining comparable objective
space performance. The proposed method offers a generalizable strategy for
integrating decision space awareness into MOEAs.

</details>


### [728] [Evolutionary Optimization of Deep Learning Agents for Sparrow Mahjong](https://arxiv.org/abs/2508.07522)
*Jim O'Connor,Derin Gezgin,Gary B. Parker*

Main category: cs.NE

TL;DR: Evo-Sparrow, an AI agent using deep learning (LSTM) and evolutionary optimization (CMA-ES), excels in Sparrow Mahjong, offering an efficient alternative to traditional methods for complex games.


<details>
  <summary>Details</summary>
Motivation: The paper aims to develop an AI agent for the complex stochastic game of Sparrow Mahjong, exploring the viability of hybrid learning strategies combining deep learning and evolutionary optimization as a computationally effective alternative to traditional reinforcement learning methods.

Method: A deep learning-based agent, Evo-Sparrow, was developed using LSTM networks optimized with Covariance Matrix Adaptation Evolution Strategy (CMA-ES) to evaluate board states and optimize decision policies in Sparrow Mahjong.

Result: The Evo-Sparrow model outperforms random and rule-based agents and shows performance comparable to a Proximal Policy Optimization (PPO) baseline in Sparrow Mahjong simulations.

Conclusion: Evo-Sparrow, a deep learning-based agent, demonstrates strong strategic play and robust policy quality in Sparrow Mahjong, outperforming random and rule-based agents and achieving performance comparable to PPO baselines. The hybrid approach of deep learning with evolutionary optimization offers a computationally effective alternative to traditional reinforcement learning and gradient-based methods, with potential applications in adaptive decision-making and strategic AI development.

Abstract: We present Evo-Sparrow, a deep learning-based agent for AI decision-making in
Sparrow Mahjong, trained by optimizing Long Short-Term Memory (LSTM) networks
using Covariance Matrix Adaptation Evolution Strategy (CMA-ES). Our model
evaluates board states and optimizes decision policies in a non-deterministic,
partially observable game environment. Empirical analysis conducted over a
significant number of simulations demonstrates that our model outperforms both
random and rule-based agents, and achieves performance comparable to a Proximal
Policy Optimization (PPO) baseline, indicating strong strategic play and robust
policy quality. By combining deep learning with evolutionary optimization, our
approach provides a computationally effective alternative to traditional
reinforcement learning and gradient-based optimization methods. This research
contributes to the broader field of AI game playing, demonstrating the
viability of hybrid learning strategies for complex stochastic games. These
findings also offer potential applications in adaptive decision-making and
strategic AI development beyond Sparrow Mahjong.

</details>


### [729] [Energy and Quality of Surrogate-Assisted Search Algorithms: a First Analysis](https://arxiv.org/abs/2508.07691)
*Tomohiro Harada,Enrique Alba,Gabriel Luque*

Main category: cs.NE

TL;DR: 本文分析了粒子群优化（PSO）的能量消耗和代理准确性，强调了在评估算法时考虑这些因素的重要性，为未来的研究奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 本文研究了代理如何从一个重要但被忽视的角度——能量消耗——来帮助元启发式算法，尽管代理可以替代耗时的复杂适应度函数，但由此产生的代理辅助元启发式算法的能量消耗、整体效率和准确性仍需深入研究。

Method: 本文分析了粒子群优化（PSO）不同版本（包括预训练和重新训练的神经网络作为代理）的能量消耗（处理器和内存）及其代理准确性。

Result: 研究结果为评估代理辅助算法提供了新的视角，展示了在优化和学习技术中考虑能源和代理准确性的重要性。

Conclusion: 本结论强调了对代理辅助算法进行全面评估的必要性，不仅要考虑时间或数值效率，还要考虑能源消耗和代理准确性，为优化和学习技术提供更全面、更深入的理解。

Abstract: Solving complex real problems often demands advanced algorithms, and then
continuous improvements in the internal operations of a search technique are
needed. Hybrid algorithms, parallel techniques, theoretical advances, and much
more are needed to transform a general search algorithm into an efficient,
useful one in practice. In this paper, we study how surrogates are helping
metaheuristics from an important and understudied point of view: their energy
profile. Even if surrogates are a great idea for substituting a time-demanding
complex fitness function, the energy profile, general efficiency, and accuracy
of the resulting surrogate-assisted metaheuristic still need considerable
research. In this work, we make a first step in analyzing particle swarm
optimization in different versions (including pre-trained and retrained neural
networks as surrogates) for its energy profile (for both processor and memory),
plus a further study on the surrogate accuracy to properly drive the search
towards an acceptable solution. Our conclusions shed new light on this topic
and could be understood as the first step towards a methodology for assessing
surrogate-assisted algorithms not only accounting for time or numerical
efficiency but also for energy and surrogate accuracy for a better, more
holistic characterization of optimization and learning techniques.

</details>


### [730] [Growing Reservoirs with Developmental Graph Cellular Automata](https://arxiv.org/abs/2508.08091)
*Matias Barandiaran,James Stovold*

Main category: cs.NE

TL;DR: DGCA模型可以训练生成功能性储层，并在解决NARMA任务方面表现优于典型储层。


<details>
  <summary>Details</summary>
Motivation: 探索DGCA模型在生成功能性、自适应形态发生和可塑性储层方面的潜力。

Method: DGCA模型通过端到端训练生成储层，并使用NARMA任务系列和储层指标作为目标。

Result: DGCA模型能够生成专门化的、生命形式的结构，在解决基准任务时表现优于典型的储层。

Conclusion: DGCA模型为形态发生提供了一个新颖的框架，能够生成可塑的、能够解决基准任务的、具有统计学优势的“生命般”的储层。

Abstract: Developmental Graph Cellular Automata (DGCA) are a novel model for
morphogenesis, capable of growing directed graphs from single-node seeds. In
this paper, we show that DGCAs can be trained to grow reservoirs. Reservoirs
are grown with two types of targets: task-driven (using the NARMA family of
tasks) and task-independent (using reservoir metrics).
  Results show that DGCAs are able to grow into a variety of specialized,
life-like structures capable of effectively solving benchmark tasks,
statistically outperforming `typical' reservoirs on the same task. Overall,
these lay the foundation for the development of DGCA systems that produce
plastic reservoirs and for modeling functional, adaptive morphogenesis.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [731] [Digital generation of the 3-D pore architecture of isotropic membranes using 2-D cross-sectional scanning electron microscopy images](https://arxiv.org/abs/2508.06664)
*Sima Zeinali Danalou,Hooman Chamani,Arash Rabbani,Patrick C. Lee,Jason Hattrick Simpers,Jay R Werber*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究提出了一种从单张二维扫描电镜图像重建三维多孔膜结构的增强算法，该算法能高保真地复制孔隙形貌并与X射线断层扫描数据高度一致，且分辨率优于后者，可用于各向同性多孔膜，但对非各向同性膜仍需改进。


<details>
  <summary>Details</summary>
Motivation: 二维扫描电镜成像在成像多孔膜时存在无法解析三维孔隙结构和连通性的局限性，而传统的三维断层扫描技术成本高、技术要求高且不易获取。本研究旨在改进一种从单张二维扫描电镜图像重建三维孔隙网络的方法，以克服这些挑战。

Method: 提出了一种增强的重建算法，用于从单张二维扫描电镜图像中重建膜的三维孔隙网络，该算法在保持统计特性的同时，能够精确复制复杂的孔隙形貌。

Result: 通过将该技术应用于商业微滤膜，生成了高保真的三维重建，并导出了关键的膜性质。与X射线断层扫描数据的验证显示，在结构指标上具有优异的一致性，并且在分辨精细孔隙特征方面具有更高的分辨率。

Conclusion: 该研究提出的基于二维扫描电镜图像的增强重建算法能够高保真地重建微滤膜的三维孔隙结构，并且在结构指标上与X射线断层扫描数据具有良好的一致性，在分辨精细孔隙特征方面表现出优越的分辨率。该方法可广泛应用于任何尺寸的各向同性多孔膜结构，但对于非各向同性膜的结构生成仍需进一步研究。

Abstract: A major limitation of two-dimensional scanning electron microscopy (SEM) in
imaging porous membranes is its inability to resolve three-dimensional pore
architecture and interconnectivity, which are critical factors governing
membrane performance. Although conventional tomographic 3-D reconstruction
techniques can address this limitation, they are often expensive, technically
challenging, and not widely accessible. We previously introduced a
proof-of-concept method for reconstructing a membrane's 3-D pore network from a
single 2-D SEM image, yielding statistically equivalent results to those
obtained from 3-D tomography. However, this initial approach struggled to
replicate the diverse pore geometries commonly observed in real membranes. In
this study, we advance the methodology by developing an enhanced reconstruction
algorithm that not only maintains essential statistical properties (e.g., pore
size distribution), but also accurately reproduces intricate pore morphologies.
Applying this technique to a commercial microfiltration membrane, we generated
a high-fidelity 3-D reconstruction and derived key membrane properties.
Validation with X-ray tomography data revealed excellent agreement in
structural metrics, with our SEM-based approach achieving superior resolution
in resolving fine pore features. The tool can be readily applied to isotropic
porous membrane structures of any pore size, as long as those pores can be
visualized by SEM. Further work is needed for 3-D structure generation of
anisotropic membranes.

</details>


### [732] [Potassium polytungstate nanoparticles by combustion aerosol technology for benzene sensing](https://arxiv.org/abs/2508.06669)
*Adrien Baut,Sebastian Kravecz,Andreas T. Guentner*

Main category: cond-mat.mtrl-sci

TL;DR: Flame aerosol synthesis offers a scalable and efficient method for producing K2W7O22 nanoparticles for benzene sensing applications.


<details>
  <summary>Details</summary>
Motivation: Traditional synthesis methods for polytungstates are limited in scalability and ability to yield nanostructured materials. This paper introduces flame aerosol synthesis as a faster and more efficient alternative.

Method: Flame aerosol synthesis was employed as a single-step, rapid, and dry method to prepare K2W7O22 nanoparticulate powders and coatings. Monocrystalline and phase-pure K2W7O22 with varying crystal sizes were obtained by controlling flame temperature, residence time, and metal ion concentration during particle formation, involving nucleation, coagulation, and sintering.

Result: The prepared K2W7O22 nanoparticles showed n-type semiconductor behavior, enabling the chemoresistive quantification of benzene down to 0.2 parts-per-million at 20% relative humidity. The sensors demonstrated high selectivity towards benzene over other compounds, including similar hydrocarbons like toluene and xylene.

Conclusion: Flame aerosol synthesis successfully prepared monocrystalline and phase-pure K2W7O22 nanoparticulate powders and coatings, which exhibited n-type semiconductor behavior suitable for chemoresistive quantification of benzene.

Abstract: Polytungstates are oxygen-linked assemblies of highly oxidized tungsten
polyhedra, valued for their tunability and stability in diverse applications.
Traditional synthesis methods (hydrothermal, solvothermal, solid-state) offer
material variety but are limited in scalability and their ability to yield
nanostructured materials due to long reaction times and high temperatures.
Here, we introduce flame aerosol synthesis as a single-step, rapid and dry
method to prepare K$_2$W$_7$O$_{22}$ nanoparticulate powders and coatings.
Thereby, monocrystalline and phase-pure K$_2$W$_7$O$_{22}$ with varying
crystal-sizes were obtained by controlling flame temperature, residence time
and metal ion concentration during particle formation by nucleation,
coagulation and sintering. X-ray diffraction and electron microscopy identified
the high potassium tolerance of the K$_2$W$_7$O$_{22}$ lattice (K/W ratio up to
0.6) and phase stability up to 400 $^\circ$C, before other polytungstates and
WO$_3$ polymorphs were formed, respectively. Porous films of such
K$_2$W$_7$O$_{22}$ nanoparticles featured n-type semiconductor behavior that
was utilized for the chemoresistive quantification of the air pollutant benzene
down to 0.2 parts-per-million at 20% relative humidity. Such sensors were quite
selective over other compounds (e.g. alcohols, aldehydes, ketones, CO, NH$_3$
or H$_2$), in particular to chemically similar toluene and xylene (>18).

</details>


### [733] [Role of Large Language Models and Retrieval-Augmented Generation for Accelerating Crystalline Material Discovery: A Systematic Review](https://arxiv.org/abs/2508.06691)
*Agada Joseph Oche,Arpan Biswas*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large language models (LLMs) have emerged as powerful tools for
knowledge-intensive tasks across domains. In materials science, to find novel
materials for various energy efficient devices for various real-world
applications, requires several time and cost expensive simulations and
experiments. In order to tune down the uncharted material search space,
minimizing the experimental cost, LLMs can play a bigger role to first provide
an accelerated search of promising known material candidates. Furthermore, the
integration of LLMs with domain-specific information via retrieval-augmented
generation (RAG) is poised to revolutionize how researchers predict materials
structures, analyze defects, discover novel compounds, and extract knowledge
from literature and databases. In motivation to the potentials of LLMs and RAG
in accelerating material discovery, this paper presents a broad and systematic
review to examine the recent advancements in applying LLMs and RAG to key
materials science problems. We survey state-of-the-art developments in crystal
structure prediction, defect analysis, materials discovery, literature mining,
database integration, and multi-modal retrieval, highlighting how combining
LLMs with external knowledge sources enables new capabilities. We discuss the
performance, limitations, and implications of these approaches, and outline
future directions for leveraging LLMs to accelerate materials research and
discovery for advancement in technologies in the area of electronics, optics,
biomedical, and energy storage.

</details>


### [734] [Design of high-mobility p-type GaN via the piezomobility tensor](https://arxiv.org/abs/2508.06723)
*Jie-Cheng Chen,Joshua Leveillee,Chris G. Van de Walle,Feliciano Giustino*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究利用压电迁移率张量符号和从头算玻尔兹曼传输方程，发现单轴压缩和剪切应变可显著提高氮化镓（GaN）的空穴迁移率。


<details>
  <summary>Details</summary>
Motivation: 氮化镓（GaN）的本征空穴迁移率低，阻碍了p沟道器件的开发和GaN CMOS的大规模集成，因此需要研究应变对提高GaN空穴迁移率的影响。

Method: 研究人员利用压电迁移率张量符号来表征外加应变和氮化镓（GaN）空穴迁移率之间的关系，并通过求解从头算玻尔兹曼传输方程（考虑电子-声子散射和GW准粒子能量修正）来绘制应变依赖性的空穴迁移率。

Result: 研究发现了三种最佳应变构型（两种单轴应变和一种剪切应变）可以显著提高空穴迁移率，其中2%单轴压缩和2%剪切应变分别可以将室温空穴迁移率预测提高到164 cm^2/Vs和148 cm^2/Vs。

Conclusion: 本研究引入了压电迁移率张量符号来表征外加应变和氮化镓（GaN）空穴迁移率之间的关系，并找到了三种最佳应变构型（两种单轴应变和一种剪切应变）可以显著提高空穴迁移率，其中2%单轴压缩和2%剪切应变分别可以将室温空穴迁移率预测提高到164 cm^2/Vs和148 cm^2/Vs。

Abstract: Gallium nitride (GaN) is a wide-bandgap semiconductor of significant interest
for applications in solid-state lighting, power electronics, and
radio-frequency amplifiers. An important limitation of this semiconductor is
its low intrinsic hole mobility, which hinders the development of
\textit{p}-channel devices and the large-scale integration of GaN CMOS in
next-generation electronics. Prior research has explored the use of strain to
improve the hole mobility of GaN, but a systematic analysis of all possible
strain conditions and their impact on the mobility is lacking. In this study,
we introduce a piezomobility tensor notation to characterize the relationship
between applied strain and hole mobility in GaN. To map the strain-dependence
of the hole mobility, we solve the \textit{ab initio} Boltzmann transport
equation, accounting for electron-phonon scattering and GW quasiparticle energy
corrections. We show that there exist three optimal strain configurations, two
uniaxial strains and one shear strain, that can lead to significant mobility
enhancement. In particular, we predict room-temperature hole mobility of up to
164~\mob\ for 2\% uniaxial compression and 148~\mob\ for 2\% shear strain. Our
methodology provides a general framework for investigating strain effects on
the transport properties of semiconductors from first principles.

</details>


### [735] [Impact of Ge substrate Thicknesses and Epitaxy Growth Conditions on the Optical and Material Properties of Ge- and GaAs-based VCSELs](https://arxiv.org/abs/2508.06777)
*Wenhan Dong,Zeyu Wan,Yun-Cheng Yang,Chao-Hsin Wu,Yiwen Zhang,Rui-Tao Wen,Guangrui Xia*

Main category: cond-mat.mtrl-sci

TL;DR: Ge substrates are a promising alternative to GaAs for VCSELs, offering comparable or better performance and properties.


<details>
  <summary>Details</summary>
Motivation: To investigate the potential of Ge substrates for VCSELs by comparing their properties with GaAs substrates.

Method: Comparative study of optical and material property dependences of VCSELs on Ge or GaAs substrate thicknesses and epitaxy process conditions.

Result: Adjusting Ge substrate thickness and optimizing epitaxy process can shift stopband center and cavity resonance wavelength. Ge-based VCSELs show improved epitaxial uniformity, smaller deviations from design, reduced stoichiometry variations, and comparable strain to GaAs-based VCSELs. No QW defects and low TDD (<2.13e6/cm^2) were observed in Ge-based VCSELs within a 46.92 um^2 area.

Conclusion: Ge substrate shows potential for advanced VCSELs due to improved uniformity, reduced variations, and comparable strain to GaAs. Ge-based VCSELs exhibit no defects in QW regions and low TDD.

Abstract: We present a comparative study of the optical and material property
dependences of VCSELs on Ge or GaAs substrate thicknesses and epitaxy process
conditions. It was found that adjusting the Ge substrate thickness and
optimizing the epitaxy process can shift the stopband center and cavity
resonance wavelength by several nanometers. Ge-based VCSELs exhibit improved
epitaxial uniformity, smaller deviations from design specifications, reduced
stoichiometry variations, and strain magnitudes comparable to those of
GaAs-based counterparts. In the selected 46.92 square micron sample area, no
defects were observed in the quantum well (QW) regions of Ge-based VCSELs, and
the threading dislocation density (TDD) was measured to be below 2.13e6 per
square cm. These results highlight the potential of Ge substrates as promising
candidates for advanced VCSELs.

</details>


### [736] [Grain Boundaries in Ceramic Solid-State Lithium Metal Batteries: A Review](https://arxiv.org/abs/2508.06866)
*Md Salman Rabbi Limon,Abrar Fahim Navid,Curtis Wesley Duffee,Zeeshan Ahmad*

Main category: cond-mat.mtrl-sci

TL;DR: Grain boundaries are key to solid-state battery performance; this review covers their impact on transport, failure, and how to engineer them for better batteries.


<details>
  <summary>Details</summary>
Motivation: To understand and control grain boundaries, which are critical for enabling safe, high-rate operation of solid-state batteries with lithium metal anodes, by exploring their multifaceted influence on performance and reliability.

Method: This review explores the multifaceted influence of grain boundaries in ceramic solid electrolytes and metal anodes, discussing their impact on transport, dendrite/void formation, failure mechanisms, space charge layers, defect chemistry, and potential as fast-ion pathways or failure sites. It also highlights differences across electrolyte classes and advances in modeling, experimental characterization, and processing techniques, concluding with open questions and opportunities for grain boundary engineering.

Result: Grain boundaries significantly impact ionic and electronic transport, dendrite and void formation, and failure mechanisms in solid-state batteries. Space charge layers at grain boundaries modulate local defect chemistry, potentially serving as fast-ion pathways or failure sites. Key differences exist across various solid electrolyte classes, and advances in modeling, characterization, and processing are aiding in understanding and engineering these boundaries.

Conclusion: Grain boundaries are critical to the performance and reliability of solid-state batteries with lithium metal anodes, influencing ionic and electronic transport, dendrite/void formation, and failure mechanisms. Understanding and engineering these boundaries, including space charge layers and defect chemistry, is essential for safe, high-rate operation. Differences in grain boundaries across electrolyte classes and advances in modeling, characterization, and processing are highlighted, along with open questions for future progress.

Abstract: It is now widely accepted that grain boundaries play a critical role in the
performance and reliability of solid-state batteries with lithium metal anodes.
Understanding and controlling grain boundaries is essential for enabling safe,
high-rate operation of solid-state batteries. This review explores the
multifaceted influence of grain boundaries in ceramic solid electrolytes and
metal anodes, including their impact on ionic and electronic transport,
dendrite and void formation, connecting them to the failure mechanisms. We
discuss the formation and structure of space charge layers at grain boundaries,
their role in modulating local defect chemistry, and the conditions under which
grain boundaries may serve as fast-ion pathways or as vulnerable sites for
failure. We highlight key differences in the grain boundaries of different
classes of solid electrolytes and advances in modeling, experimental
characterization, and processing techniques to understand the complexity and
engineer grain boundaries in solid electrolytes. Finally, we outline key open
questions and opportunities for grain boundary engineering to stimulate further
progress in the field.

</details>


### [737] [Ab-initio heat transport in defect-laden quasi-1D systems from a symmetry-adapted perspective](https://arxiv.org/abs/2508.06882)
*Yu-Jie Cen,Sandro Wieser,Georg K. H. Madsen,Jesús Carrete*

Main category: cond-mat.mtrl-sci

TL;DR: 研究纳米管中的声子传输，发现对称性破缺能增强热传输，强调了对称性在纳米尺度热传输中的关键作用。


<details>
  <summary>Details</summary>
Motivation: 研究结构对称性在缺陷纳米管热传输中的作用，以解决实际应用中因结构缺陷或材料界面引入的热阻问题。

Method: 开发了一个结合了群论和模分辨格林函数法的框架，并基于线群对准一维结构进行对称性分析，同时利用基于Allegro的机器学习势能来获取力常数和声子信息。

Result: 计算了单层和多层MoS2-WS2纳米管的详细声子传输曲线，并将每种模式的传输概率与结构对称性联系起来，发现对称性破缺能增强热传输。

Conclusion: 研究表明，显著的对称性破缺可以通过放宽选择规则和打开额外的传输通道来抑制散射，这表明了在高无序缺陷中，对称性在理解纳米尺度热传输的细微差别方面起着关键作用。

Abstract: Due to their aspect ratio and wide range of thermal conductivities, nanotubes
hold significant promise as heat-management nanocomponents. Their practical use
is, however, often limited by thermal resistance introduced by structural
defects or material interfaces. An intriguing question is the role that
structural symmetry plays in thermal transport through those defect-laden
sections. To address this, we develop a framework that combines representation
theory with the mode-resolved Green's function method, enabling a detailed,
symmetry-resolved analysis of phonon transmission through defected segments of
quasi-1D systems. To avoid artifacts inherent to formalisms developed for bulk
3D systems, we base our analysis on line groups, the appropriate description of
the symmetries of quasi-1D structures. This categorization introduces
additional quantum numbers that partition the phonon branches into smaller,
symmetry-distinct subsets, enabling clearer mode classification. We employ an
Allegro-based machine learning potential to obtain the force constants and
phonons with near-ab-initio accuracy. We calculate detailed phonon transmission
profiles for single- and multi-layer MoS$_\mathrm{2}$-WS$_\mathrm{2}$ nanotubes
and connect the transmission probability of each mode to structural symmetry.
Surprisingly, we find that pronounced symmetry breaking can suppress scattering
by relaxing selection rules and opening additional transmission channels. That
higher disorder introduced through defects can enhance thermal transport, and
not just suppress it, demonstrates the critical role of symmetry in deciphering
the nuances of nanoscale thermal transport.

</details>


### [738] [Breakdown and polarization contrasts in ferroelectric devices observed by operando laser-based photoemission electron microscopy with the AC/DC electrical characterization system](https://arxiv.org/abs/2508.07698)
*Hirokazu Fujiwara,Yuki Itoya,Masaharu Kobayashi,Cédric Bareille,Toshiyuki Taniuchi*

Main category: cond-mat.mtrl-sci

TL;DR: 开发了一种新的operando激光-PEEM系统，可以同时表征铁电特性并可视化铁电器件的微观结构和电子态。该系统能够清晰地显示HZO电容器的P-V滞后回线，并在介电击穿后可视化导电细丝，还能观察氧化物半导体的极化对比度。


<details>
  <summary>Details</summary>
Motivation: 为了开发一种能可视化导电细丝、铁电极化对比度和电子态分布的工具，以用于研究铁电器件。

Method: 开发了一种联用铁电表征系统的operando激光光电子能显微镜（laser-PEEM）。使用Sawyer-Tower电路测量了铁电器件的极化-电压（P-V）特性。

Result: 成功获得了包含Hf$_{0.5}$Zr$_{0.5}$O$_2$（HZO）的铁电电容器的清晰的P-V滞后回线，并重现了HZO电容器典型的场循环特性。在由场循环应力引起的介电击穿后，在无任何破坏性处理的情况下，通过顶电极可视化了导电细丝。此外，还成功观察到了氧化物半导体（InZnO$_x$）顶电极的极化对比度。

Conclusion: 该operando激光-PEEM系统可作为一种强大的工具，用于可视化介电击穿后的导电细丝、铁电极化对比度以及铁电器件（包括铁电场效应晶体管和铁电隧道结）中实现的材料的电子态分布。

Abstract: We have developed an operando laser-based photoemission electron microscope
(laser-PEEM) with a ferroelectric characterization system. A Sawyer-Tower
circuit was implemented to measure the polarization-voltage ($P-V$)
characteristics of ferroelectric devices. Using this system, we successfully
obtained the well-defined $P-V$ hysteresis loops for a ferroelectric capacitor
incorporating Hf$_{0.5}$Zr$_{0.5}$O$_2$ (HZO), reproducing the typical
field-cycling characteristics of HZO capacitors. After dielectric breakdown
caused by field-cycling stress, we visualized a conduction filament through the
top electrode without any destructive processing. Additionally, we successfully
observed polarization contrast through the top electrode of an oxide
semiconductor (InZnO$_x$). These results indicate that our operando laser-PEEM
system is a powerful tool for visualizing conduction filaments after dielectric
breakdown, the ferroelectric polarization contrasts, and electronic state
distribution of materials implemented in ferroelectric devices, including
ferroelectric field-effect transistors and ferroelectric tunnel junctions.

</details>


### [739] [Unveiling the Puzzle of Brittleness in Single Crystal Iridium](https://arxiv.org/abs/2508.06929)
*Qing Cheng,Sergey V. Erohin,Konstantin V. Larionov,Bin Gan,Pavel B. Sorokin,Xiandong Xu*

Main category: cond-mat.mtrl-sci

TL;DR: 铱的脆性主要是由一种独特的、不可动的弗兰克位错环造成的，这限制了其在需要延展性的应用中的使用。


<details>
  <summary>Details</summary>
Motivation: 解决铱在极端环境下应用的关键材料，但其固有的脆性是一个长期存在的难题。

Method: 结合原子分辨率扫描透射电子显微镜、密度泛函第一性原理计算和离散位错动力学模拟，研究了铱的脆性机制。

Result: 发现了高密度、不可动的零净柏格矢量弗兰克位错环，它们是导致铱脆性的关键机制，并通过阻碍位错滑移和消耗位错来提高屈服强度和加工硬化。

Conclusion: 研究发现高密度的、不可动的零净柏格矢量弗兰克位错环是导致铱脆性的关键机制，这种机制在面心立方金属中是铱独有的，并且可以通过优化设计来提高材料的延展性。

Abstract: Iridium is critical for extreme-environment applications due to its
exceptional thermal stability and corrosion resistance, but its intrinsic
brittleness remains a decades-old puzzle. Combining atomic-resolution scanning
transmission electron microscopy, density first-principles calculations, and
discrete dislocation dynamics simulations, we identify high-density, sessile
Frank dislocation loops with zero-net Burgers vectors as the key mechanism.
These loops form via an energetically favorable transformation from mixed
perfect dislocations under stress, a process unique to iridium among
face-centered cubic metals. The immobile loops act as potent barriers,
drastically increasing yield strength and work hardening by impeding
dislocation glide and consuming mobile dislocations. This dominance of these
findings deepens the understanding of iridium's brittleness and offers a
pathway for designing more ductile variants of this critical material.

</details>


### [740] [Efficient GW calculations for metals from an accurate ab initio polarizability](https://arxiv.org/abs/2508.06930)
*Giacomo Sesti,Alberto Guandalini,Andrea Ferretti,Pino D'Amico,Claudia Cardoso,Massimo Rontani,Daniele Varsano*

Main category: cond-mat.mtrl-sci

TL;DR: 本文提出了一种改进的GW计算方法（W-av），用于金属体系，能加速收敛并提高精度，与实验结果一致。


<details>
  <summary>Details</summary>
Motivation: GW方法在光谱性质研究中虽有成功应用，但在应用于具有金属屏蔽效应的体系时，存在特定的方法学挑战。本文旨在提出一种能够解决这些挑战的有效计算方法。

Method: 提出了一种高效、全从头算的计算方法，用于计算具有金属屏蔽效应的3D和2D金属体系的屏蔽势。该方法结合了蒙特卡洛积分、在计算网格点之间进行插值（W-av），并对长波极限进行外插，能够无缝地考虑带内项。

Result: 该方法能显著加速金属的GW计算收敛性，并提高精度，通过对3D金属和掺杂的MoS$_2$及石墨烯等二维金属的分析证明了其正确性。W-av方法与ARPES测量结果在掺杂MoS$_2$单层中表现出优异的一致性。此外，在石墨烯研究中，结合高阶洛伦兹函数描述自能并求解线性化近似以外的准粒子方程，能获得更稳健的结果。

Conclusion: 所提出的W-av方法通过结合蒙特卡洛积分、插值以及对长波极限的推值，能有效加速金属系统的GW计算收敛性并提高精度，特别是在处理带内跃迁方面。该方法在3D金属和掺杂的MoS$_2$及石墨烯等二维金属中得到了验证，并与ARPES测量结果高度一致，表明其在描述金属系统的光谱性质方面具有显著优势。

Abstract: Despite its success in the study of spectroscopic properties, the $GW$ method
presents specific methodological challenges when applied to systems with
metallic screening. Here, we present an efficient and fully ab-initio
implementation for the calculation of the screened potential, specifically
designed for 3D and 2D metals. It combines a Monte Carlo integration with an
appropriate interpolation of the screened potential between the calculated grid
points (W-av), complemented with an extrapolation to the long-wavelength limit,
able to seamlessly account for the so-called intraband term. This method
greatly accelerates the convergence of GW calculations for metals while
improving their accuracy, due to the correct description of the intraband
transitions in the long wavelength limit, as shown here for 3D metals and doped
monolayers, such as MoS$_2$ and graphene. The use of W-av results in an
excellent agreement with ARPES measurements for monolayer doped MoS$_2$.
Furthermore, for graphene we show that more robust results are found with the
use of higher-order Lorentzians in the description of the self-energy, together
with the solution of the QP equation beyond the linearized approximation.

</details>


### [741] [Coulombic control of charge transfer in luminescent radicals with long-lived quartet states](https://arxiv.org/abs/2508.06945)
*Lujo Matasovic,Petri Murto,Shilong Yu,Wenzhao Wang,James D. Green,Giacomo Londi,Weixuan Zeng,Laura Brown,William K. Myers,David Beljonne,Yoann Olivier,Feng Li,Hugo Bronstein,Timothy J. H. Hele,Richard H. Friend,Sebastian Gorgon*

Main category: cond-mat.mtrl-sci

TL;DR: 有机材料中的激子为量子技术提供了新途径。通过调整分子结构，可以控制高自旋态的生成和发光，从而提高量子效率。


<details>
  <summary>Details</summary>
Motivation: 有机材料中的激子为可调谐的量子技术提供了一个有吸引力的平台，但需要控制所有亚稳态的退激发路径以利用高自旋态。

Method: 通过改变分子单元的连接方式，并研究电子耦合强度、芳香烃-自由基电荷转移态的能量以及库仑相互作用对发光和四重态形成产率的影响，来探究和控制激子退激发路径。

Result: 开发了一种具有55%发光产率的自由基-咔唑-烯烃材料，其中94%的发光激子源自微秒时间尺度的四重态。

Conclusion: 分子拓扑在发光量子材料中起着核心作用。通过控制分子单元（如三苯甲基自由基、烯烃和咔唑）的连接方式，可以为高效的四重态生成设定设计规则。

Abstract: Excitons in organic materials are emerging as an attractive platform for
tunable quantum technologies. Structures with near-degenerate doublet and
triplet excitations in linked trityl radical, acene and carbazole units can
host quartet states. These high spin states can be coherently manipulated, and
later decay radiatively via the radical doublet transition. However, this
requires controlling the deexcitation pathways of all metastable states. Here
we establish design rules for efficient quartet generation in luminescent
radicals, using different connection arrangements of the molecular units. We
discover that electronic coupling strength between these units dictates
luminescence and quartet formation yields, particularly through the energetics
of an acene-radical charge transfer state, which we tune Coulombically. This
state acts as a source of non-radiative decay when acene-radical separation is
small, but facilitates doublet-quartet spin interconversion when acene-radical
separation is large. Using these rules we report a radical-carbazole-acene
material with 55% luminescence yield, where 94% of emitting excitons originate
from the quartet at microsecond times. This reveals the central role of
molecular topology in luminescent quantum materials.

</details>


### [742] [Mechanism of Anisotropic Crystallization and Phase Transitions under Van der Waals Squeezing](https://arxiv.org/abs/2508.06992)
*Yuxiang Gao,Zhicheng Zhong*

Main category: cond-mat.mtrl-sci

TL;DR: 通过机器学习增强的分子动力学模拟，揭示了范德华力限制下铋的各向异性结晶机制，解释了如何形成高质量二维单晶，并确定了关键的相变压力。


<details>
  <summary>Details</summary>
Motivation: 解决在范德华力限制下，非范德华力二维材料（如铋）的合成挑战，特别是理解这种简单方法如何克服长期存在的合成难题，并揭示其结晶机制。

Method: 通过分子动力学（MD）模拟，并利用经过预训练模型微调和蒸馏的机器学习力场（具有DFT级别精度），研究了铋在范德华力限制下的结晶动力学和相演化。

Result: 1. 发现了由量子限制驱动的各向异性结晶机制，其中面外成层速度比面内排序快近两个数量级。
2. 识别出两个关键的相变：在1.64 GPa时发生α到β的相变，在2.19 GPa时坍塌成单原子层。
3. 阐明了大面积单晶的形成归因于衬底诱导的取向选择和原子扩散驱动的晶界迁移加速。
4. 建立了控制合成亚稳态二维单晶的指导原则。

Conclusion: 本研究揭示了在范德华力限制下，铋的结晶动力学和相演化，阐明了克服非范德华力二维材料合成挑战的机制。研究发现了由量子限制驱动的各向异性结晶机制，其中面外成层速度远快于面内排序。通过分子动力学模拟，识别出在1.64 GPa时发生α到β的相变，以及在2.19 GPa时坍塌成单原子层。研究还表明，大面积单晶的形成得益于衬底诱导的取向选择和由高温下原子扩散驱动的晶界迁移加速。这些发现解决了限制下高质量二维晶体生长的机制起源，并为控制合成亚稳态二维单晶建立了指导原则，对下一代量子和纳米电子器件具有重要意义。

Abstract: Mechanical confinement strategies, such as van der Waals (vdW) squeezing,
have emerged as promising routes for synthesizing non-vdW two-dimensional (2D)
layers, surprisingly yielding high-quality single crystals with lateral sizes
approaching 100 micrometer. However, the underlying mechanisms by which such a
straightforward approach overcomes the long-standing synthesis challenges of
non-vdW 2D materials remains a puzzle. Here, we investigate the crystallization
dynamics and phase evolution of Bi under vdW confinement through molecular
dynamics (MD) simulations powered by a machine-learning force filed fine-tuned
and distilled from a pre-trained model with DFT-level accuracy. We reveal that
pressure-dependent layer modulation arises from a quantum confinement-driven
anisotropic crystallization mechanism, in which out-of-plane layering occurs
nearly two orders of magnitude faster than in-plane ordering. Two critical
transitions are identified: an alpha-to-beta phase transformation at 1.64 GPa,
and a subsequent collapse into a single-atomic layer at 2.19 GPa. The formation
of large-area single crystals is enabled by substrate-induced orientational
selection and accelerated grain boundary migration, driven by atomic diffusion
at elevated temperatures. These findings resolve the mechanistic origin of
high-quality 2D crystal growth under confinement and establish guiding
principles for the controlled synthesis of metastable 2D single crystals, with
implications for next-generation quantum and nanoelectronic devices.

</details>


### [743] [Explainable AI for Curie Temperature Prediction in Magnetic Materials](https://arxiv.org/abs/2508.06996)
*M. Adeel Ajaib,Fariha Nasir,Abdul Rehman*

Main category: cond-mat.mtrl-sci

TL;DR: 机器学习预测磁性材料居里温度，Extra Trees Regressor效果最佳，并解释了关键影响因素


<details>
  <summary>Details</summary>
Motivation: 利用机器学习技术预测磁性材料的居里温度，并提供模型预测的可解释性

Method: 使用NEMAD数据库，结合基于成分和域的描述符，评估了多种机器学习模型（包括Extra Trees Regressor）的性能，并使用k-means聚类分析化学成分不同的材料组，最后通过SHAP分析来解释模型预测行为

Result: Extra Trees Regressor达到了0.85 ± 0.01的交叉验证R^2分数，同时识别出平均原子序数和磁矩是影响居里温度的关键因素

Conclusion: Extra Trees Regressor在预测磁性材料的居里温度方面表现最佳，R^2分数最高可达0.85 ± 0.01，并通过SHAP分析确定了平均原子序数和磁矩等关键物理化学因素影响居里温度

Abstract: We explore machine learning techniques for predicting Curie temperatures of
magnetic materials using the NEMAD database. By augmenting the dataset with
composition-based and domain-aware descriptors, we evaluate the performance of
several machine learning models. We find that the Extra Trees Regressor
delivers the best performance reaching an R^2 score of up to 0.85 $\pm$ 0.01
(cross-validated) for a balanced dataset. We employ the k-means clustering
algorithm to gain insights into the performance of chemically distinct material
groups. Furthermore, we perform the SHAP analysis to identify key
physicochemical drivers of Curie behavior, such as average atomic number and
magnetic moment. By employing explainable AI techniques, this analysis offers
insights into the model's predictive behavior, thereby advancing scientific
interpretability.

</details>


### [744] [VASPilot: MCP-Facilitated Multi-Agent Intelligence for Autonomous VASP Simulations](https://arxiv.org/abs/2508.07035)
*Jiaxuan Liu,Tiannian Zhu,Caiyuan Ye,Zhong Fang,Hongming Weng,Quansheng Wu*

Main category: cond-mat.mtrl-sci

TL;DR: VASPilot是一个自动化VASP工作流的开源平台，通过多代理架构和Web界面，简化了计算材料研究的流程，提高了效率。


<details>
  <summary>Details</summary>
Motivation: 计算材料科学中的DFT模拟（如VASP）通常需要大量的手动设置、监控和后处理，这阻碍了研究效率。因此，需要一个能够自动化VASP工作流的平台，以减轻研究人员的技术负担，使其能专注于科学发现，并加速高通量计算材料研究。

Method: VASPilot采用基于CrewAI框架的多代理架构和标准化的模型上下文协议（MCP），实现对VASP工作流的全面自动化，包括结构检索、输入文件生成、任务提交、错误解析和参数调整等。此外，还提供了一个基于Flask的Web界面，用于任务提交、进度跟踪和结果可视化。

Result: VASPilot在自动化的能带结构和态密度计算（包括对称性校正）、平面波截断收敛性测试、不同范德华校正的晶格常数优化以及跨材料的过渡金属二硫属化物带隙比较等常规和高级基准测试中均表现出色，成功完成了任务且无需人工干预。

Conclusion: VASPilot通过多代理架构和标准化的模型上下文协议（MCP），实现了VASP工作流的全自动化，并提供了轻量级的Web界面，能够可靠地处理从任务提交到参数动态调整的各个环节，无需人工干预。该平台不仅提高了计算材料研究的效率，还通过模块化设计支持扩展到其他DFT代码，使研究人员能够更专注于科学发现。

Abstract: Density-functional-theory (DFT) simulations with the Vienna Ab initio
Simulation Package (VASP) are indispensable in computational materials science
but often require extensive manual setup, monitoring, and postprocessing. Here,
we introduce VASPilot, an open-source platform that fully automates VASP
workflows via a multi-agent architecture built on the CrewAI framework and a
standardized Model Context Protocol (MCP). VASPilot's agent suite handles every
stage of a VASP study-from retrieving crystal structures and generating input
files to submitting Slurm jobs, parsing error messages, and dynamically
adjusting parameters for seamless restarts. A lightweight Flask-based web
interface provides intuitive task submission, real-time progress tracking, and
drill-down access to execution logs, structure visualizations, and plots. We
validate VASPilot on both routine and advanced benchmarks: automated
band-structure and density-of-states calculations (including on-the-fly
symmetry corrections), plane-wave cutoff convergence tests, lattice-constant
optimizations with various van der Waals corrections, and cross-material
band-gap comparisons for transition-metal dichalcogenides. In all cases,
VASPilot completed the missions reliably and without manual intervention.
Moreover, its modular design allows easy extension to other DFT codes simply by
deploying the appropriate MCP server. By offloading technical overhead,
VASPilot enables researchers to focus on scientific discovery and accelerates
high-throughput computational materials research.

</details>


### [745] [Electron Energy Loss Spectra Simulations of Coupled Phonon and Magnon Excitations](https://arxiv.org/abs/2508.07073)
*José Ángel Castellanos-Reyes,Anders Bergman,Ivan P. Miranda,Ján Rusz*

Main category: cond-mat.mtrl-sci

TL;DR: 我们通过结合ASLD和TACAW方法模拟了铁的EELS光谱，发现了声子-磁振子耦合效应，并预测了磁振子信号的可探测性。


<details>
  <summary>Details</summary>
Motivation: 为了在体心立方铁中模拟动量分辨电子能量损失谱（EELS），捕捉声子和磁振子激发耦合的效应。

Method: 通过扩展时间关联辅助波函数（TACAW）方法，并结合原子尺度自旋-晶格动力学（ASLD），模拟了包括相互作用效应、动力学衍射和多重散射在内的完整EELS信号。

Result: 结果揭示了由声子-磁振子耦合产生的非加性光谱特征，包括干涉和能量再分配效应，并预测在优化的探测器条件下，实验上可探测到磁振子信号。

Conclusion: 该框架通过将动力学理论与低能实验EELS信号直接联系起来，推进了STEM中定量磁振谱学的发展。

Abstract: We simulate momentum-resolved electron energy loss spectra (EELS) in
body-centered cubic iron at 300 K, capturing the effects of coupled phonon and
magnon excitations within a unified dynamical formalism. By extending the Time
Autocorrelation of Auxiliary Wavefunctions (TACAW) method to incorporate
atomistic spin-lattice dynamics (ASLD), we simulate the full EELS signal -
including interaction effects, dynamical diffraction, and multiple scattering.
Our results reveal non-additive spectral features arising from phonon-magnon
coupling, including interference and energy redistribution effects, and predict
experimental detectability of magnon signals under optimized detector
conditions. This framework advances quantitative magnon spectroscopy in STEM,
establishing a direct link between dynamical theory and low-energy experimental
EELS signatures.

</details>


### [746] [A Novel Computational Thermodynamics Framework with Intrinsic Chemical Short-Range Order](https://arxiv.org/abs/2508.07100)
*Chuliang Fu*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究提出了一种名为FYL-CVM的混合CVM-CALPHAD框架，能够高效且精确地模拟多组分合金中的化学短程有序（SRO）现象，解决了传统CALPHAD方法无法准确描述SRO的问题。


<details>
  <summary>Details</summary>
Motivation: 传统的CALPHAD框架无法准确描述多组分合金中的化学短程有序（SRO）或有序-无序转变，而第一性原理方法计算成本高昂。本研究旨在解决这一问题。

Method: 提出了一种名为FYL-CVM的混合CVM-CALPHAD框架，利用FYL变换减少了自由能最小化所需的变量数量，实现了SRO的高效建模。

Result: FYL-CVM在fcc AB二元合金上的测试表明，其在更高的效率下重现了CVM相图，并结合了非构型贡献以捕捉其对有序-无序边界的物理效应。在Cu-Au系统中的应用，以高效的参数化产生了与实验数据一致的相图，并通过SRO图阐明了SRO参数的温度-成分依赖性。该方法也展示了其在Cu-Au-Ag三元合金中的适用性。

Conclusion: 该混合CVM-CALPHAD框架结合了FYL变换，在CALPHAD形式主义内实现了多组分体系中SRO的高效建模，平衡了精度和效率，并将 Ordering 现象扩展到物理信息模型。

Abstract: Chemical short-range order (SRO) provides new opportunities for tuning alloy
properties, but conventional computational thermodynamics frameworks such as
CALPHAD, based on Bragg-Williams mean-field approximations, cannot properly
describe SRO or order-disorder transformations in multicomponent ($\geq$3)
alloys. First-principles approaches combined with the cluster variation method
(CVM) or cluster expansion method (CEM) can capture SRO but suffer from high
computational cost. Here we present a hybrid CVM-CALPHAD framework with a
thermodynamic solid solution model named as FYL-CVM, enabled by the
Fowler-Yang-Li (FYL) transform to reduce the number of variables required in
free-energy minimization. This achieves efficient modeling of SRO in
multicomponent systems within the CALPHAD formalism. Benchmark tests on fcc AB
binaries show that FYL-CVM reproduces CVM phase diagrams with much higher
efficiency, while non-configurational contributions from vibrational, elastic,
and electronic terms are also incorporated to capture their physical effects on
order-disorder boundaries. Applied to the Cu-Au system, this method produces
phase diagrams with experimental data in an efficient parameterization and
elucidates the temperature-composition dependence of SRO parameters via the SRO
diagram. Its applicability to ternary alloys is also demonstrated for the
Cu-Au-Ag system. Overall, this framework strikes a balance between accuracy and
efficiency, extends CALPHAD to account for chemical SRO, and enables a
comprehensive physics-informed modeling of ordering phenomena. (This
dissertation was submitted to the University of Virginia in 2023 as the
author's doctoral research. For the original complete abstract, please refer to
the PDF version.)

</details>


### [747] [Ferroelectric switching of interfacial dipoles in $α$-RuCl$_3$/graphene heterostructure](https://arxiv.org/abs/2508.07187)
*Soyun Kim,Jo Hyun Yun,Takashi Taniguchi,Kenji Watanabe,Joseph Falson,Jun Sung Kim,Kyung-Hwan Jin,Gil Young Cho,Youngwook Kim*

Main category: cond-mat.mtrl-sci

TL;DR: 研究发现在graphene/thin hBN/$\\%\\alpha$-RuCl3异质结构中，可通过界面电荷转移实现可电切换的非挥发性偶极子，并观察到铁电类磁滞回线，该现象主要由静电驱动。


<details>
  <summary>Details</summary>
Motivation: 探索界面电荷转移与温度调谐的偶极子状态势垒穿越在原子尺度上的相互作用。

Method: 通过系统测量研究了强面内外磁场对磁滞回线特性的影响，确认了驱动偶极子开关的主要机制是静电的，而非磁场的。发现了在graphene/thin hBN/$\\%\\alpha$-RuCl3异质结构中，通过界面电荷转移实现可电调谐的铁电现象。

Result: 在graphene/thin hBN/$\\%\\alpha$-RuCl3异质结构中实现了可通过电切换、非挥发性的偶极子，并观察到强铁电类磁滞回线，证明了该机制的鲁棒性，并为研究界面电荷转移和温度调谐的偶极子状态势垒穿越提供了新的途径。

Conclusion: 该研究在graphene/thin hBN/$\\%\\alpha$-RuCl3异质结构中展示了可通过电切换、非挥发性的偶极子，该偶极子仅通过原子层电介质势垒中的界面电荷转移来稳定。此机制无需滑动或扭转即可明确打破反演对称性，并产生在30 K附近显著出现的强铁电类磁滞回线。

Abstract: We demonstrate electrically switchable, non-volatile dipoles in graphene/thin
hBN/$\alpha$-RuCl$_3$ heterostructures, stabilized purely by interfacial charge
transfer across an atomically thin dielectric barrier. This mechanism requires
no sliding or twisting to explicitly break inversion symmetry and produces
robust ferroelectric-like hysteresis loops that emerge prominently near 30~K.
Systematic measurements under strong in-plane and out-of-plane magnetic fields
reveal negligible effects on the hysteresis characteristics, confirming that
the primary mechanism driving the dipole switching is electrostatic. Our
findings establish a distinct and robust route to electrically tunable
ferroelectric phenomena in van der Waals heterostructures, opening
opportunities to explore the interplay between interfacial charge transfer and
temperature-tuned barrier crossing of dipole states at the atomic scale.

</details>


### [748] [Reproducibility of high-throughput density-functional-theory calculations](https://arxiv.org/abs/2508.07204)
*Chenxi Lu,Musen Li,Jeffrey R. Reimers*

Main category: cond-mat.mtrl-sci

TL;DR: DFT计算在代码实现、参数优化和工作流程上存在差异。本研究以带隙为例，探讨了这些差异对高通量计算结果可重现性的影响，并提出了保证可重现性的基本要求，包括使用相同程序优化结构和确保k点积分网格精度，这对方法开发和AI模型训练至关重要。


<details>
  <summary>Details</summary>
Motivation: 标准密度泛函理论（DFT）计算协议具有普遍适用性，但代码实现存在差异。特定应用需要手动参数优化，而高通量计算则采用预定义的工作流程。

Method: 本研究使用带隙作为关键属性，揭示了计算工作流程差异对高通量计算结果可重现性的影响。

Result: 研究提出了保证可重现性的基本要求：使用相同程序优化的结构来计算属性，并确保布里渊区（k点）积分网格的准确性。

Conclusion: 本研究为确保DFT计算的可重现性及结果的可靠应用奠定了基础，这对于方法开发和人工智能模型训练具有重大意义。

Abstract: While standard computational protocols for density functional theory (DFT)
have universal applicability, differences exist in code implementations.
Specific applications require manual parameter optimization, whereas
high-throughput calculations employ predefined workflows. This paper uses the
bandgap as a key property to reveal the impact of computational workflow
differences on the reproducibility of high-throughput calculation results. The
study proposes basic requirements for ensuring reproducibility: using
structures optimised using the same procedure as used to calculate properties
and ensuring Brillouin zone (k-point) integration grid accuracy. This research
establishes a foundation for the reproducibility of DFT calculations and
reliable application of results, which is of great significance for method
development and artificial intelligence model training.

</details>


### [749] [On the Néel Vector Dependence of X-ray Magnetic Circular Dichroism in Altermagnets](https://arxiv.org/abs/2508.07234)
*Jan Kuneš*

Main category: cond-mat.mtrl-sci

TL;DR: XMCD的几何依赖性可通过霍尔矢量描述，其与反铁磁体中N'eel矢量的关系可通过群论在FVS近似下推导，具体表现取决于系统对称性。


<details>
  <summary>Details</summary>
Motivation: 研究x射线磁圆二色性（XMCD）在不同实验几何形状下的依赖性，并将其与反铁磁体的N'eel矢量方向联系起来。

Method: 使用群论推导了霍尔矢量与反铁磁体中N'eel矢量方向之间的关系，并在自由价自旋（FVS）近似下进行了推导。

Result: 推导了霍尔矢量与N'eel矢量方向的普遍关系，并将结果推广到MnTe和MnF2的特例。

Conclusion: XMCD在FVS近似下可能存在、仅在包含被忽略项时出现或完全被禁止，具体取决于系统对称性。

Abstract: Dependence of x-ray magnetic circular dichroism on the experimental geometry
is described by a frequency-dependent Hall vector. Using group theory, we
derive a general relationship between the Hall vector and the orientation of
the N\'eel vector $\bL$ in altermagnets within the free valence spin (FVS)
approximation, where the spin-orbit coupling of the valence electrons and their
exchange interaction with the core electrons are neglected. For a given spin
point group, the full $\bL$-dependence of the Hall vector can be expressed in
terms of several irreducible spectral functions. This derivation generalizes
earlier results for the special cases of MnTe and MnF$_2$. Depending on the
system symmetry, XMCD in the FVS approximation may be present, emerge only when
the neglected terms are included, or be completely forbidden.

</details>


### [750] [Controlling Single-Pulse Magnetization Switching through Angular Momentum Reservoir Engineering](https://arxiv.org/abs/2508.07272)
*B. Kunyangyuen,G. Malinowski,D. Lacour,B. Seng,W. Zhang,S. Mangin,J. Hohlfeld,J. Gorchon,M. Hehn*

Main category: cond-mat.mtrl-sci

TL;DR: 研究了CoGd双层膜中的全光开关动力学，发现通过调控Gd厚度和插入Pt层可以控制磁化反转速度。结果表明，角动量传递是控制反转速度的关键因素。


<details>
  <summary>Details</summary>
Motivation: 研究稀土-过渡金属材料中的磁化反转动力学，特别是光子开关。

Method: 通过改变Gd的厚度或在Co和Gd之间插入Pt间隔层，系统地研究了单脉冲全光开关动力学。

Result: 研究发现，当Gd含量高且与Co耦合强时，Gd去磁过程中角动量有效传递，导致Co超快反转。通过减小Gd厚度或引入Pt阻挡层会阻碍这种传递，导致反转过程由磁畴生长介导，时间尺度从纳秒到微秒不等。将Gd替换为Dy或Ho等更重的稀土元素会减慢开关速度，因为去磁过程中传递到Co的角动量减少。

Conclusion: 本研究揭示了角动量可用性和传递途径是控制稀土-过渡金属系统中磁化反转动力学的关键参数，为理解不同反转动力学提供了统一的框架。

Abstract: We report a systematic study of single pulse all optical helicity independent
switching in CoGd bilayers, revealing that the magnetization reversal dynamics
can be tuned over more than three orders of magnitude. By varying the Gd
thickness or inserting a Pt spacer layer between Co and Gd, we control the
angular momentum transferred from the rare earth sublattice to the transition
metal sublattice. Our results show that when Gd is abundant and strongly
coupled to Co, angular momentum is efficiently transferred during Gd
demagnetization, leading to ultrafast Co reversal. In contrast, reducing the Gd
thickness or introducing a Pt barrier impedes this transfer, resulting in a
domain growth mediated reversal on nanosecond and possibly to microsecond
timescales as previously observed in CoDy and CoHo alloys. As a result, in rare
earth transition metal systems, replacing Gd with heavier rare-earth elements
such as Dy or Ho slows down the switching due to a reduced angular momentum
transfer towards Co upon demagnetization as demonstrated in CoGdDy alloys. Our
findings establish angular momentum availability and transfer pathways as key
parameters governing AO HIS dynamics, offering a unified framework for fast and
slow magnetization reversal across rare earth transition metal systems.

</details>


### [751] [Intercalation-Induced Near Room-Temperature Ferromagnetism in CrI3 via Synergistic Exchange Pathways](https://arxiv.org/abs/2508.07278)
*Qing-Han Yang,Jia-Wen Li,Xin-Wei Yi,Xiang Li,Jing-Yang You,Gang Su,Bo Gu*

Main category: cond-mat.mtrl-sci

TL;DR: 通过原子插层（特别是锂）增强CrI3磁性，提高其居里温度至接近室温，为设计新型磁性半导体提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 为了推进自旋电子学技术，开发室温磁性半导体至关重要，但现有的范德华磁体（如CrI3）具有较低的居里温度（Tc = 45 K）。

Method: 本研究采用第一性原理计算，结合X射线光电子能谱等实验数据，分析了原子插层（特别是Li）增强CrI3磁交换耦合的机制，包括协同的超交换和双交换相互作用。

Result: 通过锂插层，CrI3的预测Tc提高到286 K（实验报告为420 K），实现了接近室温的铁磁性。研究还发现铜（Cu）和钠（Na）插层也能有效提高CrI3的Tc， Cu0.25CrI3的Tc为267 K，Na0.25CrI3的Tc为247 K。

Conclusion: 该研究提出的原子插层策略，特别是锂（Li）插层，显著增强了CrI3的磁交换耦合，实现了接近室温的铁磁性（预测Tc为286 K，实验报告为420 K），为设计高居里温度（Tc）磁性半导体提供了一种多功能策略，并已成功扩展到其他插层剂（如Cu和Na），Cu0.25CrI3和Na0.25CrI3的Tc分别为267 K和247 K，为未来自旋电子学器件的实际应用奠定了基础。

Abstract: The development of room-temperature magnetic semiconductors is critical for
advancing spintronic technologies, yet van der Waals magnets like CrI3 exhibit
intrinsically low Curie temperatures (Tc = 45 K). This study employs
first-principles calculations to demonstrate that atom intercalation,
particularly lithium (Li), dramatically enhances magnetic exchange couplings in
CrI3, achieving near room-temperature ferromagnetism with a predicted Tc of 286
K-aligning with experimental reports of 420 K. The underlying mechanism
involves synergistic superexchange and double-exchange interactions:
intercalation reduces the |Ep-Ed| energy difference between iodine p-orbitals
and chromium d-orbitals, strengthening superexchange pathways, while charge
transfer induces valence mixing (e.g., Cr3+ to Cr2+, as confirmed by
experimental X-ray photoelectron spectrometry data), promoting double-exchange.
Theoretical predictions extend to other intercalants including Cu and Na, with
Cu0.25CrI3 and Na0.25CrI3 exhibiting Tc of 267 K and 247 K, respectively,
establishing a versatile strategy for designing high-Tc magnetic
semiconductors. This work bridges theoretical insights with experimental
validation, offering a transferable framework for intercalation-driven material
design and accelerating practical spintronic device realization.

</details>


### [752] [Linear and nonlinear optical responses in Green's function formula](https://arxiv.org/abs/2508.07280)
*Maoyuan Wang,Jianhui Zhou,Yugui Yao*

Main category: cond-mat.mtrl-sci

TL;DR: 利用格林函数方法研究高阶非线性光学响应，并引入了新的物理量。


<details>
  <summary>Details</summary>
Motivation: 尽管线性光学和非线性光学效应在多种材料中得到了广泛研究，但高阶非线性响应的研究仍不充分。

Method: 从密度算符出发，推导了不同阶数的光学电导率在格林函数公式中的表达式，并将其与贝里曲率、贝里曲率偶极子、三阶非线性霍尔电导率等物理量联系起来。

Result: 推导了不同阶数的光学电导率的格林函数公式，并将其与贝里曲率、贝里曲率偶极子、三阶非线性霍尔电导率等新物理量联系起来，展示了格林函数公式在研究高阶非线性光学响应中的多体效应方面的潜力。

Conclusion: 该研究将格林函数公式与高阶非线性光学响应联系起来，并引入了贝里曲率、贝里曲率偶极子、三阶非线性霍尔电导率等新物理量，为研究高阶非线性光学响应中的多体效应提供了新的视角和工具。

Abstract: Linear and nonlinear optical effect has been widely discussed in large
quantity of materials using theoretical or experimental methods. Except linear
optical conductivity, higher-order nonlinear responses are not studied fully.
Starting from density operator method, we derive optical conductivities of
different orders in Green's function formula, and also connect them to novel
physical quantities, such as Berry curvature, Berry curvature dipole,
third-order nonlinear Hall conductivity and so on. Based on the advantages of
Green's function formulas, we believe that these formulas have a lot of
benefits for many-body effect study in high-order nonlinear optical responses.

</details>


### [753] [Experimental Realization of the Topologically Nontrivial Phase in Monolayer Si$_2$Te$_2$](https://arxiv.org/abs/2508.07351)
*Xiaochun Huang,Lingxiao Zhao,Rui Xiong,Wenbin Li,Bao-tian Wang,Baisheng Sa,Matthias Bode*

Main category: cond-mat.mtrl-sci

TL;DR: 研究首次在HfTe$_2$衬底上通过外延生长实现了ML-Si$_2$Te$_2$，并实验验证了其作为室温量子自旋霍尔材料的潜力。


<details>
  <summary>Details</summary>
Motivation: 解决ML-Si$_2$Te$_2$缺乏三维对应物而难以实现的问题，并实验验证其量子自旋霍尔性质。

Method: 利用扫描隧道显微镜和光谱学技术，结合第一性原理计算，证实了ML-Si$_2$Te$_2$的无应变$(1 	imes 1)$晶格和显著的带隙，并观察到了与台阶几何无关且空间分布广泛的边缘态。

Result: 成功在HfTe$_2$衬底上外延生长了无应变的ML-Si$_2$Te$_2$薄膜，其带隙和拓扑边缘态得到了实验证实。

Conclusion: 通过HfTe$_2$作为衬底，成功实现了ML-Si$_2$Te$_2$外延生长，并保持了其拓扑相。

Abstract: The free-standing monolayer Si$_2$Te$_2$ (ML-Si$_2$Te$_2$) has been
theoretically predicted to host a room-temperature quantum spin Hall phase.
However, its experimental realization remains challenge due to the absence of a
three-dimensional counterpart. Here, we demonstrate that HfTe$_2$ serves as an
ideal substrate for the epitaxial growth of ML-Si$_2$Te$_2$, preserving its
topological phase. Scanning tunneling microscopy and spectroscopy confirm a
strain-free ${(1 \times 1)}$ lattice of ML-Si$_2$Te$_2$, along with a sizable
band gap, which is well captured by first-principles calculations. Moreover,
distinct edge states, independent of step geometry and exhibiting a broad
spatial distribution, are observed at ML-Si$_2$Te$_2$ step edges, underscoring
its topological nature.

</details>


### [754] [Effective toughness estimation by FFT based phase field fracture: application to composites and polycrystals](https://arxiv.org/abs/2508.07424)
*Pedro Aranda,Javier Segurado*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究提出了一种基于相场断裂模型和FFT均匀化求解器的方法，用于估计异质材料的有效韧性。该方法考虑了微观结构、弹性以及断裂响应的影响，并通过裂纹尖端富集来提高预测精度。研究发现，异质性有助于提高材料的有效韧性，并且增韧机制与裂纹的扩展路径有关。


<details>
  <summary>Details</summary>
Motivation: 提出一种基于相场断裂模型和FFT均匀化求解器的方法，用于估计异质材料的有效韧性，并考虑微观结构、弹性以及断裂响应的影响。

Method: 基于相场断裂模型，在FFT均匀化求解器中实现，通过恒定的能量耗散率（使用弧长类型控制）来模拟代表性体积单元的变形，以估计有效韧性。

Result: 通过裂纹尖端富集和FFT均匀化求解器，研究了复合材料和弹性多晶体的有效韧性。结果表明，弹性响应和断裂能的异质性都会增加有效韧性。增韧机制与裂纹穿过韧性相和裂纹路径偏转有关。当杂质或各向异性足够高时，裂纹路径偏转是控制机制，可能导致韧性饱和。

Conclusion: 异质材料的有效韧性估计考虑了韧性和弹性响应的异质性，并且可以考虑具有各向异性弹性 तसेच断裂响应（解理断裂）的相。通过将裂纹尖端富集用于模拟初始裂纹，可以提高韧性预测的准确性。该方法应用于复合材料和弹性多晶体，发现韧性和弹性响应的异质性都会增加有效韧性。微观上，增韧机制与裂纹穿过更韧相以及裂纹路径的偏转有关。在杂质或各向异性足够高的情况下，裂纹路径的偏转是控制机制，最终会导致韧性饱和。

Abstract: An estimate of the effective toughness of heterogeneous materials is proposed
based on the Phase Field Fracture model implemented in an FFT homogenization
solver. The estimate is based on the simulation of the deformation of
representative volume elements of the microstructure, controlled by a constant
energy dissipation rate using an arc-length type control. The definition of the
toughness corresponds to the total energy dissipated after the total fracture
of the RVE -- which can be accurately obtained thanks to the dissipation
control -- divided by the RVE transverse area (length in 2D). The proposed
estimate accounts for both the effect of heterogeneity in toughness and elastic
response on the overall fracture energy and allows as well to account for
phases with anisotropic elastic and fracture response (fracture by cleavage).
To improve toughness predictions, crack-tip enrichment is used to model initial
cracks. The method is applied to obtain the effective toughness of composites
and elastic polycrystals in a series of examples. In the two types of
materials, it is found that both heterogeneity in elastic response and fracture
energy contribute to increase the effective toughness. Microscopically, it is
found that toughening mechanisms are related to the passage of the crack
through tougher phases and deviation of the crack path. It is also found that
the latter is the controlling mechanism for cases with marked heterogeneity and
high anisotropy, eventually provoking toughening saturation for sufficiently
high values of heterogeneity or anisotropy.

</details>


### [755] [Experimental and Computational Demonstration of a Highly Stable, in-situ Pt Decorated Sputtered ZnO Hydrogen Sensor for sub-ppm Level Detection](https://arxiv.org/abs/2508.07455)
*Puja Ghosh,Pritam Ghosh,Rizwin Khanam,Chandra Shekhar Prajapati,Aarti Nagarajan,Shreeja Das,Rakesh Paleja,Sharan Shetty,Gopalakrishnan Sai Gautam,Navakanta Bhat*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究制备了一种Pt修饰的ZnO薄膜传感器，用于氢气检测。该传感器在498 K下表现出优异的性能，包括快速响应、高选择性和长期稳定性。理论计算结果支持实验观察，并揭示了Pt增强传感机制。


<details>
  <summary>Details</summary>
Motivation: 开发一种用于氢气检测的高效、稳定和高选择性的传感器，以满足工业和环境监测的需求。

Method: 采用溅射技术和原位Pt修饰方法制备Pt修饰的ZnO薄膜，并通过密度泛函理论计算分析了Pt修饰对ZnO(002)表面吸附和反应活性的影响。

Result: Pt修饰的ZnO薄膜传感器在498 K的最佳工作温度下，对1%的氢气浓度表现出约52,987%的增强响应，并能可靠检测低至100 ppb的氢气浓度，且在一年测试中无响应漂移。理论计算表明，Pt的引入通过激活吸附的OH、促进H2的解离以及维持形成H2O的晶格氧途径，增强了氢气传感敏感性。

Conclusion: Pt修饰的ZnO薄膜传感器在氢气检测方面表现出优异的性能，具有快速响应、高选择性和长期稳定性，适用于工业和环境监测。理论计算结果与实验数据一致，解释了Pt提高氢气传感敏感性的机制。

Abstract: In this work, we present a Pt decorated ZnO thin film-based gas sensor for
hydrogen detection, fabricated using a sputtering technique and an in-situ Pt
decoration approach. Specifically, we deposit a ZnO thin film on an
interdigitated electrode substrate, with Pt nanoclusters added to the (002)
polar plane by brief sputtering (1 to 6 s) to create an active sensing
interface. Our sensor demonstrates optimal performance at an operating
temperature of 498 K, with rapid response and recovery times (10 and 3 s), high
selectivity, and long-term stability. We find the Pt decorated ZnO sensor, with
a Pt deposition time of 2 s, to exhibit enhanced response (~52,987%) to 1%
hydrogen concentration, indicating its suitability for industrial and
environmental monitoring applications. Additionally, our device demonstrates
reliable detection of low hydrogen concentrations (~100 ppb), with a response
of ~38% and no response drift over one year of testing, underscoring the
long-term stability of the sensor. To elucidate the role of Pt deposition and
pristine ZnO in hydrogen sensing, we perform density functional theory
calculations, analysing adsorption and reaction energetics involving H2, O2, O,
OH, and H2O, and lattice oxygen atoms on the ZnO (002) surface with and without
Pt decoration. Our computational data is in agreement with our experiments,
identifying the oxygen-exposed (002) surface to be most active for hydrogen
sensing in both pristine and Pt decorated ZnO. Further, our computations
highlight the role of Pt in enhancing hydrogen sensitivity via i) activating an
autoreduction pathway of adsorbed OH, ii) spontaneous dissociation of adsorbed
molecular H2, and iii) keeping the lattice oxygen pathway of forming H2O
active. Our systematic approach of designing sensors combining an experimental
setup with theoretical insights, is key in developing and optimizing efficient
hydrogen gas sensors.

</details>


### [756] [Spin Phonon Coupling and Relaxation time in Lu(II) compound with 9.2GHz clock transition](https://arxiv.org/abs/2508.07521)
*Xiaoliang Zhang,Haechan Park*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究利用第一性原理计算和Redfield主方程，分析了声子对Lu(II)配合物自旋量子比特的T1和T2的影响，验证了原子钟跃迁对相干性的保护作用，并提出了一个通用的计算框架。研究结果与实验现象定性符合，但T1和T2的绝对值存在差异。


<details>
  <summary>Details</summary>
Motivation: 电子自旋量子比特因其在原子钟跃迁下具有极长的相干时间，在可扩展的量子信息应用中显示出潜力。然而，在固态系统中，量子比特与晶格声子的相互作用对自旋弛豫（T1）和退相干（T2）起着关键作用。本研究旨在量化声子对特定自旋量子比特（Lu(II)配合物）的超精相互作用的影响，并理解其对T1和T2的影响，以验证原子钟跃迁的保护效应。

Method: 本研究利用第一性原理计算，结合先进的电子结构方法，量化了声子对超精相互作用（主要的自旋-晶格耦合机制）的影响。研究将声子诱导的变异视为一阶微扰，并应用Redfield主方程计算了T1和T2及其温度依赖性。T1的计算采用了描述声子相互作用的二阶量化形式，而T2的评估则通过对整个布里渊区的声子贡献进行积分来实现。

Result: 研究结果成功复现了实验观察到的T2随磁场变化的依赖关系，包括在0.43 T附近的相干峰值。然而，计算得到的T1和T2的绝对值与实验值存在一到两个数量级的差异。分析表明，T1主要受纵向声子影响，而T2则主要受中等波长、中等能量的声学模式影响。

Conclusion: 该研究通过计算模拟，定量验证了原子钟跃迁对自旋量子比特的保护效应，并提出了一个可迁移的计算框架用于评估分子自旋量子比特中的自旋-声子相互作用。

Abstract: Electron spin qubits operating at atomic clock transitions exhibit
exceptionally long coherence times, making them promising candidates for
scalable quantum information applications. In solid-state systems, interactions
between qubits and lattice phonons are known to play a critical role in spin
relaxation (T1) and decoherence (T2). In this work, we perform first-principles
calculations on a Lu(II) complex spin qubit featuring a prominent clock
transition. By employing advanced electronic structure methods, we
quantitatively evaluate the influence of phonons on the hyperfine interaction,
which serves as the primary spin-lattice coupling mechanism. Treating these
phonon-induced variations as first-order perturbations, we apply the Redfield
master equation to compute both T1 and T2, along with their temperature
dependencies. For T1, we adopt a second quantization formalism to describe
phonon interactions, while T2 is evaluated by explicitly integrating acoustic
phonon contributions across the full Brillouin zone. Our results reproduce the
experimentally observed magnetic field dependence of T2, including the
coherence peak near 0.43 T, though the absolute values of T1 and T2 differ by
one to two orders of magnitude. Analysis reveals that T1 is primarily governed
by longitudinal phonons, whereas T2 is most strongly influenced by
mid-wavelength, mid-energy acoustic modes. These findings provide a
quantitative demonstration of the clock transition protective effect on spin
qubit coherence and offer a transferable computational framework for evaluating
spin-phonon interactions in other molecular spin qubits.

</details>


### [757] [Hydrazine-Free Precursor for Solution-Processed All-Inorganic Se and Se1-xTex Photovoltaics](https://arxiv.org/abs/2508.07530)
*Adam D. Alfieri,Swarnendu Das,Kim Kisslinger,Chloe Leblanc,Jamie Ford,Cherie R. Kagan,Eric A. Stach,Deep Jariwala*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究成功开发了一种更安全的硒和硒碲合金溶液加工方法，制备出高性能、高稳定性的光伏器件，为低成本、低毒性光伏技术的进一步发展奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 硒 (Se) 作为一种有前途的室内和叠层光伏 (PV) 吸收材料，其与碲 (Te) 的合金 (Se1-xTex) 具有广泛可调的带隙。溶液加工为低成本制造提供了一条途径。然而，目前硒的溶液加工仅使用高度危险的溶剂肼。

Method: 本工作在更安全的硫醇-胺溶剂体系中制备并分离了丙基铵聚硒和聚硒碲前驱体。通过在二甲基甲酰胺 (DMF) 中添加单乙醇胺 (EA) 来配制分子油墨，并加工出带隙在 1.20 eV 至 1.86 eV 范围内的高质量硒和硒碲合金薄膜。

Result: 使用 TiO2 和 MoO3 电荷传输层 (CTL) 制成的光伏器件，硒的光电转换效率高达 2.73%，硒碲合金 (Se0.7Te0.3) 的光电转换效率高达 2.33%。硒器件表现出出色的稳定性，在空气中放置 1 个月后无明显衰减。

Conclusion: 这项工作代表了迈向低成本、低毒性、高带隙可调谐的硒和硒碲合金在光伏和光电探测器中溶液相加工的重要一步。

Abstract: Selenium (Se) has reemerged as a promising absorber material for indoor and
tandem photovoltaics (PVs), and its alloys with Te (Se1-xTex) offer a widely
tunable bandgap. Solution processing of this materials system offers a route to
low-cost fabrication. However, solution processing of Se has, thus far, only
used hydrazine, which is an extremely hazardous solvent. In this work, we
prepare and isolate propylammonium poly-Se and poly-Se-Te precursors from a
safer thiol-amine solvent system. We formulate molecular inks by dissolving the
precursor n,n-dimethylformamide (DMF) with a monoethanolamine (EA) additive and
process high-quality Se and Se1-xTex films with bandgaps ranging from 1.20 eV
to 1.86 eV. We fabricate PVs from these films using TiO2 and MoO3 charge
transport layers (CTLs) to achieve power conversion efficiencies as high as
2.73% for Se and 2.33% for Se0.7Te0.3 under solar simulation. Se devices show
excellent stability with no degradation after 1 month in air, enabled by the
excellent stability of Se and the use of inorganic CTLs. This work represents
an important step towards low-cost solution-phase processing of Se and Se1-xTex
alloys for PVs and photodetectors with low toxicity and high bandgap
tunability.

</details>


### [758] [Field-derivative torque induced magnetization reversal in ferrimagnetic Gd$_{3/2}$Yb$_{1/2}$BiFe$_5$O$_{12}$](https://arxiv.org/abs/2508.07582)
*Pratyay Mukherjee,Arpita Dutta,Somasree Bhattacharjee,Shovon Pal,Ritwik Mondal*

Main category: cond-mat.mtrl-sci

TL;DR: FDT在铁磁Gd$_{3/2}$Yb$_{1/2}$BiFe$_5$O$_{12}$中极大地增强了自旋翻转的可能性，并降低了翻转所需的磁场。


<details>
  <summary>Details</summary>
Motivation: 理解亚太赫兹脉冲激发亚铁磁体中自旋翻转的机制，为下一代磁性存储器提供了前景。

Method: 通过计算方法研究了FDT在铁磁Gd$_{3/2}$Yb$_{1/2}$BiFe$_5$O$_{12}$自旋翻转中的作用。

Result: 研究结果表明，在FDT存在的情况下，自旋翻转所需的亚太赫兹磁场低于没有FDT的情况。没有FDT项时，所需磁场极高。计算出的翻转和非翻转等值线图表明，FDT极大地增强了自旋翻转的可能性。

Conclusion: FDT极大地增强了磁化翻转的可能性，并指出了开关效应明显的材料。

Abstract: Understanding the mechanism of spin switching in ferrimagnets via the
excitation of THz pulses holds promise for future-generation magnetic memory
devices. Such spin switching can be accomplished by the Zeeman torque exerted
by the THz pulses on the magnetic spins. Theoretical and experimental works
have established that the field-derivative of a terahertz pulse also exerts a
torque, field derivative torque (FDT). Here, we investigate the role of the FDT
in the spin switching in ferrimagnetic Gd$_{3/2}$Yb$_{1/2}$BiFe$_5$O$_{12}$
using a computational approach. Our results foresee that the spin switching in
the presence of the FDT requires less THz magnetic fields than the spin
switching without the FDT. Without the FDT terms, the spin switching in the
considered system requires an extremely high magnetic field. Furthermore, we
compute the switching and non-switching contour diagrams to show that the FDT
tremendously enhances the possibility of spin switching. These results not only
shed light on the significance of the FDT in magnetization switching but also
suggest materials where the switching effect is pronounced.

</details>


### [759] [Magnetic and Crystal Symmetry Effects on Spin Hall Conductivity in Altermagnets](https://arxiv.org/abs/2508.07639)
*Dameul Jeong,Seoung-Hun Kang,Young-Kyun Kwon*

Main category: cond-mat.mtrl-sci

TL;DR: 研究了三种磁异体材料（RuO2、CrSb、MnTe）的非传统自旋霍尔电导，发现晶体和磁对称性是调控该效应的关键，为在零净磁矩材料中实现增强的相干性和鲁棒的自旋输运提供了工程化思路。


<details>
  <summary>Details</summary>
Motivation: 探索磁异体材料（具有零净磁化但仍有显著自旋分裂）在电子和自旋电子器件中的应用潜力，特别是研究其非传统的自旋霍尔效应。

Method: 利用第一性原理计算，研究了 RuO2、CrSb 和 MnTe 三种典型磁异体材料的非传统自旋霍尔电导（USHC），重点分析了晶体对称性和磁对称性如何影响自旋霍尔响应。

Result: RuO2 在倾斜几何下仅表现出平凡的 USHC，表明对称性投影可诱导表观上的非传统效应。CrSb 和 MnTe 则在无结构倾斜的情况下展现出稳健的、由对称性驱动的 USHC，这得益于其易轴取向降低了磁对称性。研究还阐明了时间反演偶数和奇数分量在决定整体 SHC 中的互补作用。

Conclusion: 通过研究揭示了晶体和磁性对称性如何调节磁异体材料（包括 RuO2、CrSb 和 MnTe）的自旋霍尔效应，为调控非零磁矩材料中的自旋传输提供了新的思路，有望应用于下一代自旋电子器件。

Abstract: Altermagnets, which reconcile zero net magnetization with pronounced spin
splitting, offer fresh opportunities for spin-based functionalities in
next-generation electronic and spintronic devices. In this paper, we explore
the unconventional spin Hall conductivity (USHC) in three prototypical
altermagnets -- RuO$_2$, CrSb, and MnTe -- and elucidate how distinct magnetic
and crystal symmetries modulate their spin Hall responses. RuO$_2$ exhibits
only trivial USHC contributions under a tilted geometry, demonstrating that
symmetry projections alone can induce apparent unconventional elements. In
contrast, CrSb and MnTe manifest robust, symmetry-driven USHC without
structural tilts, enabled by easy-axis orientations that reduce magnetic
symmetry. Through extensive first-principles calculations, we demonstrate the
complementary roles of the time-reversal-even and time-reversal-odd components
in determining the overall SHC. Our findings indicate that controlling the
interplay between crystal and magnetic symmetry -- for instance, by epitaxial
strain or doping -- can provide an experimental avenue to tune USHC magnitudes
and directions in altermagnets. These results pave the way for the engineering
of multifunctional spintronic devices, where enhanced coherence and robust spin
transport are realized in zero-net-moment materials with easily tailored spin
configurations.

</details>


### [760] [Proximate spin-liquid behavior in the double trillium lattice antiferromagnet K$_2$Co$_2$(SO$_4$)$_3$](https://arxiv.org/abs/2508.07687)
*A. Magar,K. Somesh,M. P. Saravanan,J. Sichelschmidt,Y. Skourski,M. T. F. Telling,V. A. Ginga,A. A. Tsirlin,R. Nath*

Main category: cond-mat.mtrl-sci

TL;DR: K$_{2}$Co$_{2}$(SO$_{4}$)$_{3}$在双三叶草晶格中表现出量子自旋液体行为，在1T磁场下，其低温热容呈T$^{2}$行为。


<details>
  <summary>Details</summary>
Motivation: 在高度挫折的三维双三叶草晶格中，磁性Co$^{2+}$离子表现出量子自旋液体行为。

Method: 本文通过单晶和高分辨率同步辐射粉末X射线衍射实验、磁化强度和热容测量以及μ子自旋弛豫实验，并结合从头算方法，分析了K$_{2}$Co$_{2}$(SO$_{4}$)$_{3}$的结构、磁性和量子磁行为。

Result: 在1 T的小磁场下，静态磁有序被完全抑制，并且在该磁场以上的低温热容表现出T$^{2}$行为，这是量子自旋液体的另一个特征。从头算结果表明，多种反铁磁耦合的竞争使得K$_{2}$Co$_{2}$(SO$_{4}$)$_{3}$成为研究双三叶草晶格几何中量子磁性的有希望的赝自旋1/2材料。

Conclusion: K$_{2}$Co$_{2}$(SO$_{4}$)$_{3}$ 是一种有潜力的赝自旋1/2材料，用于研究双三叶草晶格几何中的量子磁性。

Abstract: We report proximate quantum spin liquid behavior in K$_2$Co$_2$(SO$_4$)$_3$
with the magnetic Co$^{2+}$ ions embedded on a highly frustrated
three-dimensional double trillium lattice. Single-crystal and high-resolution
synchrotron powder x-ray diffraction experiments reveal a structural phase
transition at $T_{\rm t} \simeq 125$ K from high-temperature cubic to
low-temperature monoclinic phase with the three-fold superstructure.
Magnetization and heat capacity consistently show the formation of the $J_{\rm
eff} =1/2$ state of Co$^{2+}$ below 50 K. In zero field,
K$_2$Co$_2$(SO$_4$)$_3$ shows signatures of static magnetic order formed below
$T^* \simeq 0.6$ K, but muon spin relaxation experiments reveal a large
fluctuating component that persists down to at least 50 mK, reminiscent of
quantum spin liquid (QSL). Static order is completely suppressed in the small
magnetic field of $\sim 1$ T, and low-temperature heat capacity demonstrates
the $T^2$ behavior above this field, another fingerprint of QSL. Ab initio
calculations show a competition of several antiferromagnetic couplings that
render K$_2$Co$_2$(SO$_4$)$_3$ a promising pseudospin-$\frac12$ material for
studying quantum magnetism in the double trillium lattice geometry.

</details>


### [761] [Extreme anharmonicity and thermal contraction of 1D wires](https://arxiv.org/abs/2508.07971)
*Chiara Cignarella,Lorenzo Bastonero,Lorenzo Monacelli,Nicola Marzari*

Main category: cond-mat.mtrl-sci

TL;DR: Ultrathin nanowires (CuC2, TaSe3, AuSe2) show record negative thermal expansion and large deviations from standard heat capacity laws due to strong anharmonicity, suggesting potential for next-gen electronics.


<details>
  <summary>Details</summary>
Motivation: To gain insight into the thermodynamic and anharmonic behaviors of ultrathin nanowires (CuC2, TaSe3, and AuSe2) exfoliated from weakly-bonded three-dimensional materials for next-generation electronics.

Method: Stochastic self-consistent harmonic approximation was used to analyze thermal stability, linear thermal expansion, and anharmonic heat capacity.

Result: The study revealed common exotic features among the 1D wires, specifically a colossal record negative thermal expansion and very large deviations from the Dulong-Petit law attributed to strong anharmonicity.

Conclusion: Ultrathin nanowires such as CuC2, TaSe3, and AuSe2 exhibit exotic features including colossal negative thermal expansion and large deviations from the Dulong-Petit law due to strong anharmonicity.

Abstract: Ultrathin nanowires could play a central role in next-generation downscaled
electronics. Here, we explore some of the most promising candidates identified
from previous high-throughput screening: CuC$_2$, TaSe$_3$, and AuSe$_2$, to
gain insight into the thermodynamic and anharmonic behaviors of nanowires that
could be exfoliated from weakly-bonded three-dimensional materials. We analyze
thermal stability, linear thermal expansion, and anharmonic heat capacity using
the stochastic self-consistent harmonic approximation. Notably, our work
unveils exotic features common among all the 1D wires: a colossal record
negative thermal expansion and very large deviations from the Dulong-Petit law
due to strong anharmonicity.

</details>


### [762] [Anisotropy at twin interfaces in $RT_{12}$ ($R$=rare earth, $T$=transition metal) magnets](https://arxiv.org/abs/2508.07724)
*Christopher E Patrick*

Main category: cond-mat.mtrl-sci

TL;DR: RT12材料因其“稀土元素含量低”的永磁体潜力而备受关注，但将其优异的内禀性能转化为实际的高性能仍然是一个挑战。本研究利用第一性原理计算，结合高分辨率电子显微镜图像构建的模型，分析了两种界面结构（孪晶和堆垛层错）的磁性能。结果发现，堆垛层错结构中的磁化易轴旋转可能导致矫顽力下降。


<details>
  <summary>Details</summary>
Motivation: 为了将RT12材料的潜在性能转化为实际的高性能，需要了解其原子尺度结构与磁性能之间的联系，但现有的模拟方法需要本征磁性能数据作为输入。

Method: 使用基于密度泛函理论的第一性原理计算，确定了两种模型界面的本征磁性能，包括磁矩和晶体场系数。

Result: 计算得到的磁矩和晶体场系数表明，界面在亚纳米尺度上改变了磁性能。具体而言，“堆垛层错”结构中R元素富集区域的局部磁化易轴相对于其体相方向旋转了49°。

Conclusion: 该研究计算了两种模型界面的磁性能，并发现“堆垛层错”结构中的局部磁化易轴旋转可能导致矫顽力降低。

Abstract: RT\textsubscript{12} materials continue to attract attention due to their
potential use as ``rare-earth-lean'' permanent magnets, but converting their
promising intrinsic properties into practical high performance remains an
elusive goal. Sophisticated experimental characterization techniques are
providing unprecedented insight into the structure of these materials at the
atomistic scale. Atomistic spin dynamics or micromagnetics simulations could
help unravel the links between these structures and resultant magnet
performance, but require input data describing the intrinsic magnetic
properties. Here, first-principles calculations based on density-functional
theory are used to determine these properties for two model interface
structures which have been derived from recently reported high resolution
electron microscopy images. One model structure is a stoichiometric twin formed
by mirroring the RT\textsubscript{12} structure in the (101) plane, and the
other model structure is a ``stacking fault'' involving the insertion of a
RT\textsubscript{4} plane and a displacement along the [100] axis. Magnetic
moments and crystal field coefficients have been calculated for the optimized
structures. The interfaces modify the magnetic properties at the sub-nm scale.
In particular, in the R-rich region of the ``stacking fault'', the local easy
axis of magnetization rotates by $49^\circ$ from its bulk direction, which may
lead to reduced coercivity through the easier nucleation of reverse domains.

</details>


### [763] [Generative Inversion for Property-Targeted Materials Design: Application to Shape Memory Alloys](https://arxiv.org/abs/2508.07798)
*Cheng Li,Pengfei Danga,Yuehui Xiana,Yumei Zhou,Bofeng Shi,Xiangdong Ding,Jun Suna,Dezhen Xue*

Main category: cond-mat.mtrl-sci

TL;DR: 通过GAN反演框架，成功设计出高性能SMA，Ni$_{49.8}$Ti$_{26.4}$Hf$_{18.6}$Zr$_{5.2}$合金性能优于现有NiTi合金。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是解决具有高转变温度和大的机械功输出的形状记忆合金（SMA）的设计挑战。

Method: 提出了一种基于生成对抗网络（GAN）反演的数据驱动框架，通过耦合预训练的GAN和属性预测模型，进行梯度下降的潜在空间优化，直接生成满足用户定义属性目标的候选合金成分和工艺参数。

Result: 实验验证了该框架，合成了五种NiTi基SMA。其中，Ni$_{49.8}$Ti$_{26.4}$Hf$_{18.6}$Zr$_{5.2}$合金实现了404°C的高转变温度、9.9 J/cm$^3$的大机械功输出、43 J/g的转变焓和29°C的热滞，性能优于现有的NiTi合金。研究结果归因于Zr和Hf的缓慢扩散以及与局部应变场半相干界面所带来的显著的转变体积变化和细分散的Ti$_2$Ni型沉淀物。

Conclusion: 该研究证明了GAN反转为目标性能的复杂合金发现提供了一条高效且可推广的途径。

Abstract: The design of shape memory alloys (SMAs) with high transformation
temperatures and large mechanical work output remains a longstanding challenge
in functional materials engineering. Here, we introduce a data-driven framework
based on generative adversarial network (GAN) inversion for the inverse design
of high-performance SMAs. By coupling a pretrained GAN with a property
prediction model, we perform gradient-based latent space optimization to
directly generate candidate alloy compositions and processing parameters that
satisfy user-defined property targets. The framework is experimentally
validated through the synthesis and characterization of five NiTi-based SMAs.
Among them, the Ni$_{49.8}$Ti$_{26.4}$Hf$_{18.6}$Zr$_{5.2}$ alloy achieves a
high transformation temperature of 404 $^\circ$C, a large mechanical work
output of 9.9 J/cm$^3$, a transformation enthalpy of 43 J/g , and a thermal
hysteresis of 29 {\deg}C, outperforming existing NiTi alloys. The enhanced
performance is attributed to a pronounced transformation volume change and a
finely dispersed of Ti$_2$Ni-type precipitates, enabled by sluggish Zr and Hf
diffusion, and semi-coherent interfaces with localized strain fields. This
study demonstrates that GAN inversion offers an efficient and generalizable
route for the property-targeted discovery of complex alloys.

</details>


### [764] [Impact of Ce Substitution on Structural and Electrochemical Properties of Ga Doped Garnet Li7La3Zr2O12 Solid Electrolyte](https://arxiv.org/abs/2508.07826)
*Muktai Aote,A. V. Deshpande,Vaibhav Sirsulwar,Priya Padaganur,Neha,Abhishek Pradhan*

Main category: cond-mat.mtrl-sci

TL;DR: 研究了Ga-Ce共掺杂对Li7La3Zr2O12固态电解质的影响，发现Li6.4Ga0.2La3Zr2-xCexO12（Ce=0.10 a.p.f.u.）在室温下具有4 x 10^-4 S/cm的最高离子电导率和0.29 eV的最低活化能，适用于全固态锂离子电池。


<details>
  <summary>Details</summary>
Motivation: 为了替代传统的液体电解质，开发具有高离子电导率的固体电解质是关键。本研究旨在探索Ga-Ce共掺杂对石榴石Li7La3Zr2O12固态电解质的影响，以期提高其离子电导率，满足全固态锂离子电池的应用需求。

Method: 通过烧结制备Li6.4Ga0.2La3Zr2-xCexO12（Ce含量从0到0.30 a.p.f.u.），并采用X射线衍射、扫描电子显微镜和密度测量等结构表征技术，以及电化学分析和直流电导率测量来评估材料性能。

Result: Li6.4Ga0.2La3Zr2-xCexO12样品在1050°C烧结后，Ce含量为0.10 a.p.f.u.的样品在室温下展现出最高的离子电导率，达到4 x 10^-4 S/cm，同时具有最低的活化能0.29 eV。直流电导率测量证实了其主要的离子传导性。

Conclusion: Ga-Ce共掺杂对石榴石Li7La3Zr2O12固态电解质的性能进行了研究，其中Li6.4Ga0.2La3Zr2-xCexO12（Ce含量为0至0.30 a.p.f.u.）在1050°C烧结后表现出优异的性能。Ce含量为0.10 a.p.f.u.的样品在室温下表现出最高的离子电导率（4 x 10^-4 S/cm），具有最低的活化能（0.29 eV）。直流电导率测量证实了其主要的离子传导特性，使其成为全固态锂离子电池的潜在候选材料。

Abstract: In order to replace conventional liquid electrolytes, solid electrolyte
should possess high ionic conductivity. In this study, the effects of Ga-Ce
co-doping on the garnet Li7La3Zr2O12 solid electrolyte have been investigated.
The series Li6.4Ga0.2La3Zr2-xCexO12 has been prepared with varying content of
Ce from 0 to 0.30 atoms per formula unit (a.p.f.u.) by sintering at 1050^0C.
Various structural characterizations namely X-diffraction, Scanning Electron
Microscopy (SEM), density measurements were carried out. The electrochemical
analysis suggested that, the sample with 0.10 a.p.f.u. of Ce offered the
highest room temperature ionic conductivity of 4 x 10-4 S/cm with the minimum
activation energy of 0.29 eV. Moreover, DC conductivity measurement proved the
predominant ionic conduction in the prepared samples making it suitable for the
application in all solid state Li-ion batteries (ASSLIBs).

</details>


### [765] [Multiple Adsorption of CO Molecules on Transition Metal Substitutional Impurities in Copper Surfaces](https://arxiv.org/abs/2508.07858)
*Magnus A. H. Christiansen,Wei Wang,Elvar Ö. Jónsson,Giancarlo Cicero,Hannes Jónsson*

Main category: cond-mat.mtrl-sci

TL;DR: 铜基催化剂添加第二行过渡金属杂质可以提高CO2RR的活性和选择性。CO分子在杂质上的吸附能力更强，色散相互作用尤其重要。CO吸附会引起杂质原子位移，C-O拉伸频率可用于实验识别。


<details>
  <summary>Details</summary>
Motivation: 为了提高铜基催化剂在CO2RR中的活性和选择性，本研究旨在探究第二行过渡金属杂质对CO吸附行为的影响，并考虑色散相互作用的作用，以期发现能更好地描述CO2RR活性的吸附描述符。

Method: 使用RPBE函数和BEEF-vdW函数，研究了第二行过渡金属杂质对铜基催化剂电化学还原CO2（CO2RR）的影响。通过计算CO分子在含杂质铜表面的吸附能和差分吸附能，分析杂质对催化活性的影响。此外，还计算了C-O拉伸频率，以寻找多重CO吸附的实验信号。

Result: 研究发现，CO分子在第二行过渡金属杂质上的吸附能比在纯铜表面显著更高，但随着吸附CO分子数量的增加，差分吸附能通常会下降。色散相互作用显著影响吸附能，尤其是在最弱吸附的CO分子上。在某些情况下，四个CO分子在杂质原子上的吸附能力可能强于在纯铜表面。CO吸附还会导致杂质原子移位甚至脱离表面层。计算的C-O拉伸频率为识别多重CO吸附的实验特征提供了依据。

Conclusion: 铜基催化剂在CO2RR中对生成CO以外的产物具有潜力。通过添加其他元素作为替代杂质可以提高催化剂的活性和选择性。RPBE函数和BEEF-vdW函数的研究表明，CO分子在杂质原子上的吸附能比在纯Cu(111)和Cu(100)表面上显著更高，并且吸附的CO分子越多，差分吸附能越低。色散相互作用对吸附能有显著贡献，尤其是在吸附的最后一个CO分子上，该分子最有可能参与CO2RR。在某些情况下，四个CO分子在杂质原子上的吸附能力可能强于在纯铜表面上的吸附能力。CO的吸附会导致杂质原子向外移动，甚至脱离表面层。计算C-O拉伸频率以识别多重CO吸附的潜在实验特征。

Abstract: Copper-based catalysts are of particular interest for electrochemical
reduction of CO$_2$ (CO2RR) as products beyond CO can form. To improve activity
and selectivity, several studies have focused on the addition of other elements
as substitutional impurities. Although the adsorption of a single CO molecule
has often been used as a descriptor for CO2RR activity, our recent calculations
using the RPBE functional showed that multiple CO molecules can bind to
first-row transition metal impurities. Here, we extend the study to second-row
transition metals and also to a functional that explicitly includes dispersion
interaction, BEEF-vdW. The binding energy of the first CO molecule on the
impurity atom is found to be significantly larger than on the clean Cu(111) and
Cu(100) surfaces, but the differential binding energy generally drops as more
CO molecules adsorb. The dispersion interaction is found to make a significant
contribution to the binding energy, in particular for the last and weakest
bound CO molecule, the one that is most likely to participate in CO2RR. In some
cases, four CO admolecules can bind more strongly on the impurity atom than on
the clean copper surface. The adsorption of CO causes the position of the
impurity atom to shift outwards and in some cases, even escape from the surface
layer. The C-O stretch frequencies are calculated in order to identify possible
experimental signatures of multiple CO adsorption.

</details>


### [766] [Optimizing the depth-dependent nitrogen-vacancy center quantum sensor in diamane](https://arxiv.org/abs/2508.07874)
*Pei Li,Guanjian Hu,Xiao Yu,Bing Huang,Song Li*

Main category: cond-mat.mtrl-sci

TL;DR: We used first-principles calculations to study NV centers in a 2D diamond material called diamane. We found that diamane with oxygen surface termination can improve photostability and optical properties compared to bulk diamond, while maintaining long coherence times. This makes diamane a promising material for quantum information processing.


<details>
  <summary>Details</summary>
Motivation: To achieve high sensitivity and spatial resolution, shallow NV center near the surface are preferred. However, shallow NV center suffers from surface states and spin noise which reduce the photostability and coherence time.

Method: first-principles calculations

Result: The quantum confinement in finite-layer diamane, with appropriate surface passivation, could significantly modify the band structure. Oxygen surface termination is capable of hosting NV center in diamane while optimizing photostability compared to bulk diamond. Layer-dependent NV center demonstrates tunable zero-phonon-line and suppressed phonon side band, while retaining long coherence time.

Conclusion: diamane is a promising platform for NV-based quantum information processing with improved optical properties and stability

Abstract: Negatively charged nitrogen-vacancy (NV) center in diamond is the
representative solid state defect qubit for quantum information science,
offering long coherence time at room temperature. To achieve high sensitivity
and spatial resolution, shallow NV center near the surface are preferred.
However, shallow NV center suffers from surface states and spin noise which
reduce the photostability and coherence time. In this work, we systematically
study the NV center in recently reported two-dimensional diamond, known as
diamane--using first-principles calculations. We show that the quantum
confinement in finite-layer diamane, with appropriate surface passivation,
could significantly modify the band structure. In particular, we identify
oxygen surface termination capable of hosting NV center in diamane while
optimizing photostability compared to bulk diamond. Furthermore,
layer-dependent NV center demonstrates tunable zero-phonon-line and suppressed
phonon side band, while retaining long coherence time. Our findings highlight
diamane as a promising platform for NV-based quantum information processing
with improved optical properties and stability

</details>


### [767] [Cr resonant impurity for studies of band inversion and band offsets in IV-VI semiconductors](https://arxiv.org/abs/2508.07911)
*A. Królicka,K. Gas,W. Dobrowolski,H. Przybylińska,Y. K. Edathumkandy,J. Korczak,E. Łusakowska,R. Minikayev,A. Reszka,R. Jakieła,L. Kowalczyk,A. Mirowska,M. Gryglas-Borysiewicz,J. Kossut,M. Sawicki,A. Łusakowski,P. Bogusławski,T. Story,K. Dybko*

Main category: cond-mat.mtrl-sci

TL;DR: 研究了Cr掺杂在IV-VI半导体中的电子结构和磁性，发现费米能级钉扎效应和多种Cr离子电荷状态，为设计新型晶体管提供了基础。


<details>
  <summary>Details</summary>
Motivation: 理解IV-VI半导体中过渡金属掺杂剂的电子结构对于调谐其带结构至关重要。

Method: 通过磁学和输运测量分析了$Pb_{1-x}Sn_xTe$和PbSe中Cr掺杂剂的性质，并基于密度泛函理论计算进行了解释。

Result: Cr掺杂的IV-VI半导体在整个成分范围内，费米能级都被钉扎在Cr共振能级，这使得能够确定PbTe/SnTe/PbSe异质结的价带和导带偏移。磁性测量揭示了Cr离子存在三种电荷状态：$Cr^{3+}$、$Cr^{2+}$和$Cr^{1+}$。其中$Cr^{1+}$对应于掺杂在间隙位而非取代位上的Cr，间隙Cr和取代Cr的浓度相当。

Conclusion: Cr掺杂的IV-VI半导体在整个成分范围内，费米能级都被钉扎在Cr共振能级，这使得能够确定PbTe/SnTe/PbSe异质结的价带和导带偏移，这对于设计高性能二维晶体管至关重要。磁性测量揭示了Cr离子存在三种电荷状态：$Cr^{3+}$、$Cr^{2+}$和$Cr^{1+}$。其中$Cr^{1+}$对应于掺杂在间隙位而非取代位上的Cr，间隙Cr和取代Cr的浓度相当。

Abstract: Understanding the electronic structure of transition-metal dopants in IV-VI
semiconductors is critical for tuning their band structure. We analyze
properties of Cr dopant in $Pb_{1-x}Sn_xTe$ and PbSe by magnetic and transport
measurements, which are interpreted based on density functional calculations.
We demonstrate that the pinning of the Fermi energy to the chromium resonant
level occurs for both n-type and p-type $Pb_{1-x}Sn_xTe$ in the whole
composition range. This enables us to determine the valence band and conduction
band offsets at the PbTe/SnTe/PbSe heterointerfaces, which is important for
designing high-prformance 2D transistors. Furthermore, the magnetic
measurements reveal the presence of Cr ions in three charge states, $Cr^{3+}$,
$Cr^{2+}$, and $Cr^{1+}$. The last one corresponds to the Cr dopants
incorporated at the interstitial, and not the substitutional, sites. The
measured concentrations of the interstitial and substitutional Cr are
comparable.

</details>


### [768] [Sliding Ferroelectric Metal with Ferrimagnetism](https://arxiv.org/abs/2508.07947)
*Zhenzhou Guo,Xiaodong Zhou,Wenhong Wang,Zhenxiang Cheng,Xiaotian Wang*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究提出了一种新型的二维滑动铁电亚铁磁金属，通过层间滑动实现了铁电性、金属性和磁性的耦合，从而在自旋电子器件中实现了可电调谐的功能和三态开关。


<details>
  <summary>Details</summary>
Motivation: 探索具有铁电性、金属性和磁性相互作用的新型自旋电子材料，以实现强磁电耦合和可电调谐的自旋电子功能。

Method: 通过设计双层滑动FE金属，从单层Fe5GeTe2衍生的具有本征磁序的范德华金属，实现FE相变并研究其磁电耦合和输运性质。

Result: 成功构建了二维滑动FE亚铁磁金属，实现了三态开关，其中FE极化、自旋劈裂和净磁化强度通过FE开关同时反转。证明了FE金属态的 in-plane mirror symmetry breaking 导致了净磁矩和强线性ME耦合。观察到金属性和FE FiM相互作用在费米能级附近产生了符号可逆的输运响应，并且这些响应可以通过FE开关进行电控制。

Conclusion: 该研究提出了构建二维（2D）滑动铁电（FE）亚铁磁（FiM）金属的一般策略，该材料结合了铁电性、金属性和磁性，实现了强磁电（ME）耦合和可电调谐的自旋电子功能。作为原型，研究设计了一种由单层Fe5GeTe2衍生的双层滑动FE金属，该金属具有接近室温的本征磁序。系统通过层间滑动实现了从非极性（NP）反铁磁（AFM）相到FE FiM相的FE相变。FE金属态的 in-plane mirror symmetry breaking 导致了NP相中存在的自旋简并性的破裂，从而产生了显著的净磁矩和强线性ME耦合。金属性和FE FiM之间的相互作用在费米能级附近产生了明显的符号可逆的输运响应，这些响应都可以通过FE开关完全由电控制，而无需重新定向Néel序。该结果表明，具有FiM的滑动FE金属是电可重构、高速和低功耗自旋电子器件的有前途的平台。

Abstract: Two-dimensional (2D) sliding ferroelectric (FE) metals with ferrimagnetism
represent a previously unexplored class of spintronic materials, where the
interplay of ferroelectricity, metallicity, and magnetism enables strong
magnetoelectric (ME) coupling and electrically tunable spintronic
functionalities. Here, based on antiferromagnetic (AFM) metallic bilayers, we
propose a general strategy for constructing 2D sliding FE ferrimagnetic (FiM)
metals that can achieve tri-state switching, in which the FE polarization, spin
splitting, and net magnetization are reversed simultaneously through FE
switching. As a prototypical realization, we design a bilayer sliding FE metal
with FiM order, derived from monolayer Fe5GeTe2-a van der Waals metal with
intrinsic magnetic order close to room temperature. The system exhibits a FE
transition from a nonpolar (NP) AFM phase to a FE FiM phase via interlayer
sliding. The in-plane mirror symmetry breaking in FE metallic states lift the
spin degeneracy that exists in the NP phase, leading to a sizable net magnetic
moment and strong linear ME coupling. The interplay between metallicity and FE
FiM gives rise to pronounced sign-reversible transport responses near the Fermi
level, all of which can be fully electrically controlled by FE switching
without reorienting the N\'{e}el order. Our results establish sliding FE metals
with FiM as a promising platform for electrically reconfigurable, high-speed,
and low-dissipation spintronic devices.

</details>


### [769] [Cu2OSeO3 Turns Trigonal with Structural Transformation and Implications for Skyrmions](https://arxiv.org/abs/2508.08015)
*Alla Arakcheeva,Priya Ranjan Baral,Wen Hua Bi,Christian Jandl,Oleg Janson,Arnaud Magrez*

Main category: cond-mat.mtrl-sci

TL;DR: Cu2OSeO3纳米粒子中发现了一种新的三方晶型，具有C3v对称性，可能驱动从Bloch到Néel斯格明子的转变，揭示了尺寸、结构和磁性之间的联系。


<details>
  <summary>Details</summary>
Motivation: 磁畴的形成和特征很大程度上受控于晶体结构的对称性。本研究旨在探索Cu2OSeO3的晶体结构对称性与其磁畴（特别是斯格明子）形成之间的关系。

Method: 通过电子衍射和密度泛函理论计算确认了Cu2OSeO3的新三方晶型，其空间群为R3m，具有C3v对称性。

Result: 发现了一种仅在纳米粒子中观察到的Cu2OSeO3新三方晶型，其R3m空间群和C3v对称性与Néel型斯格明子宿主相似。该晶型可能由表面效应稳定，并可能解释尺寸诱导的从Bloch型到Néel型斯格明子的转变，以及块体晶体表面观察到的Néel型斯格明子现象。

Conclusion: 本研究揭示了Cu2OSeO3的新三方晶型，其R3m空间群和C3v对称性与Néel型斯格明子的宿主相似。该晶型可能由表面效应稳定，提示尺寸诱导的结构变化可能驱动Cu2OSeO3中从Bloch型到Néel型斯格明子的转变。该假设与先前在块体晶体表面观察到的未解释的Néel型斯格明子现象一致，这可能源于表面特异性结构畸变。总的来说，这些发现为理解尺寸、结构和磁性之间的相互作用提供了见解，并为控制纳米系统中斯格明子的性质开辟了途径。

Abstract: The formation and characteristics of magnetic skyrmions are strongly governed
by the symmetry of the underlying crystal structure. In this study, we report
the discovery of a new trigonal polymorph of Cu2OSeO3, observed exclusively in
nanoparticles. Electron diffraction and density functional theory calculations
confirm its R3m space group, sharing C3v symmetry with N\'eel-type skyrmion
hosts. This polymorph is likely stabilized by surface effects, suggesting that
size-induced structural changes may drive a transformation from Bloch-type to
Neel-type skyrmions in Cu2OSeO3. This hypothesis is consistent with prior
unexplained observations of Neel-type skyrmions at the surfaces of bulk
crystals, which may result from surface-specific structural distortions.
Overall, these findings provide insights into the interplay between size,
structure, and magnetism, opening pathways for controlling skyrmionic
properties in nanoscale systems.

</details>


### [770] [Short-Range Order and Li$_x$TM$_{4-x}$ Probability Maps for Disordered Rocksalt Cathodes](https://arxiv.org/abs/2508.08112)
*Tzu-chen Liu,Steven B. Torrisi,Chris Wolverton*

Main category: cond-mat.mtrl-sci

TL;DR: 研究了无序岩盐（DRX）阴极材料中的短程有序（SRO）对 Li$_{4}$ 四面体簇概率的影响，并提出了超越随机极限的策略。


<details>
  <summary>Details</summary>
Motivation: 研究了阳离子无序状态下短程有序（SRO）对无序岩盐（DRX）阴极材料中 Li$_{4}$ 四面体簇概率的影响，并探索了超越随机极限的策略以及 FCC 晶格上的基本排序行为。

Method: 通过详尽的蒙特卡洛模拟，量化了配对短程有序参数和 Li$_{x}$TM$_{4-x}$ 概率。

Result: 结果表明，在无序状态下，Li$_{4}$ 概率受最近邻（NN）配对 SRO 参数控制，并且这些量并不一定代表其相应低温长程有序的简单衰减，尤其是在层状和尖晶石类排序的重要情况下。

Conclusion: 该研究提出的策略可用于克服锂和过渡金属的混合趋势，以实现超出随机极限的 Li$_{4}$ 概率，为富锂阴极材料的设计提供了新的方向。

Abstract: Short-range order (SRO) in the cation-disordered state is a controlling
factor influencing the probability of finding Li$_{4}$ tetrahedron clusters in
disordered rocksalt (DRX) cathode materials. However, the prevalent Li$_4$
probability below the random limit across reported DRX compositions has not
been systematically investigated, active strategies to surpass the random limit
of Li$_4$ probability are lacking, and the fundamental ordering behavior on the
face-centered cubic (FCC) lattice remains insufficiently explored. This
research quantitatively examines pair SRO parameters and Li$_x$TM$_{4-x}$
probabilities via exhaustive Monte Carlo mapping across a simplified subset of
the parameter space. The results indicate that, in the disordered state, the
Li$_4$ probability is governed by the nearest neighbor (NN) pair-wise SRO
parameter, and that these quantities do not necessarily represent a simple
attenuation of their corresponding low-temperature long-range order,
particularly for the important cases of Layered and Spinel-like orderings.
Strategies are proposed to mitigate or even reverse the lithium and transition
metals mixing tendency of NN pair SRO to achieve Li$_4$ probabilities that
exceed the random limit. This study advances the fundamental thermodynamic
understanding of ordering behaviors, which can be generalized to any FCC
system.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [771] [Robust pid sliding mode control for dc servo motor speed control](https://arxiv.org/abs/2508.06567)
*Ngoc Son Vu,Van Cuong Pham,Phuc Anh Nguyen,My Linh Dao Thi,Thanh Hai Vu*

Main category: eess.SY

TL;DR: 提出了一种SMC-PID控制器，用于提高直流伺服电机速度控制的性能。


<details>
  <summary>Details</summary>
Motivation: 为了提高直流伺服电机在工业应用（如机器人和数控机床）中的速度控制性能。

Method: 通过将滑模控制机制与传统PID控制器相结合，提出了一种滑模PID（SMC-PID）控制器。

Result: 实验结果表明，与传统PID控制器相比，SMC-PID方法在精度和稳定性方面有了显著提高，具有更小的超调量、更短的建立时间和更强的系统不确定性适应能力。

Conclusion: SMC-PID控制器能有效提高直流伺服电机速度控制的精度和稳定性，并具有更好的鲁棒性。

Abstract: This research proposes a Sliding Mode PID (SMC-PID) controller to improve the
speed control performance of DC servo motors, which are widely used in
industrial applications such as robotics and CNC. The objective of the proposed
controller is to enhance the speed control performance of DC servo motors on
the CE110 Servo Trainer. The proposed method integrates a traditional PID
controller with a sliding mode control mechanism to effectively handle system
uncertainties and disturbances. Experimental results show that the SMC-PID
method provides significant improvements in accuracy and stability compared to
traditional PID controllers, with metrics such as reduced overshoot, shorter
settling time, and increased adaptability to system uncertainties. This
research highlights the effectiveness of the SMC-PID controller, enhancing the
performance of DC servo motor speed control.

</details>


### [772] [Dual-Head Physics-Informed Graph Decision Transformer for Distribution System Restoration](https://arxiv.org/abs/2508.06634)
*Hong Zhao,Jin Wei-Kocsis,Adel Heidari Akhijahani,Karen L Butler-Purry*

Main category: eess.SY

TL;DR: 提出了一种新的双头物理信息图决策Transformer（DH-PGDT），用于解决配电系统恢复（DSR）中的长期时间依赖性和少样本/零样本决策问题，提高了泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的DRL技术在处理DSR问题时，由于其数据密集性和对MDP的依赖，难以应对需要长期时间依赖性或少样本/零样本决策的场景。新兴的决策Transformer（DT）虽然提供了一种替代方案，但其对RTG克隆的依赖和有限的泛化能力限制了其在动态电力系统环境中的有效性。

Method: DH-PGDT采用双头物理信息因果Transformer架构，包括一个生成子目标表示的引导头和一个利用子目标独立于RTG生成动作的动作头。此外，还集成了一个操作约束感知图推理模块，该模块对配电系统拓扑和操作约束进行编码，生成置信度加权的动作向量，以优化DT轨迹，从而提高泛化能力并实现对未见场景的鲁棒适应。

Result: DH-PGDT通过其创新的架构和集成方法，能够有效地处理DSR中的长期时间依赖性和少样本/零样本决策问题，提高了泛化能力，并实现了对未见场景的鲁棒适应。

Conclusion: 该研究提出了双头物理信息图决策Transformer（DH-PGDT），以解决现有深度强化学习（DRL）方法在配电系统恢复（DSR）中处理长期时间依赖性、少样本和零样本决策的局限性。DH-PGDT通过集成物理建模、结构推理和基于子目标指导，实现了可扩展和鲁棒的DSR，即使在零样本或少样本场景下也能有效应对。

Abstract: Driven by recent advances in sensing and computing, deep reinforcement
learning (DRL) technologies have shown great potential for addressing
distribution system restoration (DSR) under uncertainty. However, their
data-intensive nature and reliance on the Markov Decision Process (MDP)
assumption limit their ability to handle scenarios that require long-term
temporal dependencies or few-shot and zero-shot decision making. Emerging
Decision Transformers (DTs), which leverage causal transformers for sequence
modeling in DRL tasks, offer a promising alternative. However, their reliance
on return-to-go (RTG) cloning and limited generalization capacity restricts
their effectiveness in dynamic power system environments. To address these
challenges, we introduce an innovative Dual-Head Physics-informed Graph
Decision Transformer (DH-PGDT) that integrates physical modeling, structural
reasoning, and subgoal-based guidance to enable scalable and robust DSR even in
zero-shot or few-shot scenarios. DH-PGDT features a dual-head physics-informed
causal transformer architecture comprising Guidance Head, which generates
subgoal representations, and Action Head, which uses these subgoals to generate
actions independently of RTG. It also incorporates an operational
constraint-aware graph reasoning module that encodes power system topology and
operational constraints to generate a confidence-weighted action vector for
refining DT trajectories. This design effectively improves generalization and
enables robust adaptation to unseen scenarios. While this work focuses on DSR,
the underlying computing model of the proposed PGDT is broadly applicable to
sequential decision making across various power system operations and other
complex engineering domains.

</details>


### [773] [Embedded Microcontrol for Photovoltaic Water Pumping System](https://arxiv.org/abs/2508.06708)
*Justin London*

Main category: eess.SY

TL;DR: A 3-axis solar tracker system automates water pumping using solar energy, battery storage, and sensors to monitor light, water levels, and soil moisture. Controlled by Arduino, it optimizes water delivery for plants.


<details>
  <summary>Details</summary>
Motivation: The motivation is to develop an automated and efficient water pumping system powered by solar energy. The system aims to optimize water usage by tracking sunlight for maximum energy generation and by sensing water levels and soil moisture to deliver water only when needed.

Method: The study introduces a 3-axis solar tracker water pumping system that utilizes a photovoltaic panel to charge a 12V battery. A solar charge controller with an MPPT algorithm functions as a DC-DC converter to power two water diaphragm pumps. The system is monitored and controlled using an Arduino microcontroller with embedded software. Four light photocell resistors (LPRs) measure solar light intensity, an ultrasonic sensor monitors the water level in a reservoir tank, and a soil moisture sensor determines the need for watering plants.

Result: The paper provides circuit designs and embedded software for the described system. It also includes simulation and experimental results to validate the system's performance.

Conclusion: The paper presents a novel 3-axis solar tracker water pumping system with two pumps, powered by a battery charged from a PV panel. The system uses an MPPT algorithm for DC-DC conversion and is controlled by an Arduino microcontroller. It includes sensors for light intensity, water level, and soil moisture to automate watering. Circuit designs and embedded software are provided, along with simulation and experimental results.

Abstract: We introduce a novel 3-axis solar tracker water pumping system. The charge
generated from solar energy converted by the photovolatic panel (PV) cells is
stored in a 12V battery that in turn powers two water diaphragm pumps using a
solar charge controller that includes an MPPT algorithm that serves as a DC-DC
converter. The system is analyzed from an embedded microcontroller and embedded
software perspective using Arduino. The photovoltaic panel uses four light
photocell resistors (LPRs) which measure solar light intensity. An ultrasonic
sensor measures the water level in a reservoir water tank. If the water level
is too low, water is pumped from one water tank to the reservoir tank. Using a
soil moisture sensor, another water pump pumps water from the reservoir tank to
the plant if water is needed. Circuit designs for the system are provided as
well as the embedded software used. Simulation and experimental results are
given.

</details>


### [774] [Secure and Decentralized Peer-to-Peer Energy Transactions using Blockchain Technology](https://arxiv.org/abs/2508.06728)
*Antar Kumar Biswas,Masoud H. Nazari*

Main category: eess.SY

TL;DR: This paper proposes a blockchain-based P2P energy trading mechanism with a decentralized bidding strategy to maximize profits and social welfare in a retail electricity market for DERs. Simulations on the Ethereum testnet confirm its security, transparency, and sustainability.


<details>
  <summary>Details</summary>
Motivation: To enable a secure and scalable retail electricity market for the increasing penetration of distributed energy resources (DERs) by presenting an optimal peer-to-peer (P2P) energy transaction mechanism leveraging decentralized blockchain technology.

Method: A decentralized bidding strategy is proposed and the market design and transaction processes are simulated using the Ethereum testnet.

Result: The simulation results using the Ethereum testnet demonstrate the blockchain network's capability to ensure secure, transparent, and sustainable P2P energy trading.

Conclusion: The study demonstrates the feasibility of using blockchain technology for secure, transparent, and sustainable P2P energy trading among DER participants, validating its potential for a retail electricity market.

Abstract: This paper presents an optimal peer-to-peer (P2P) energy transaction
mechanism leveraging decentralized blockchain technology to enable a secure and
scalable retail electricity market for the increasing penetration of
distributed energy resources (DERs). A decentralized bidding strategy is
proposed to maximize individual profits while collectively enhancing social
welfare. The market design and transaction processes are simulated using the
Ethereum testnet, demonstrating the blockchain network's capability to ensure
secure, transparent, and sustainable P2P energy trading among DER participants.

</details>


### [775] [Collaborative Computing Strategy Based SINS Prediction for Emergency UAVs Network](https://arxiv.org/abs/2508.06864)
*Bing Li,Haoming Guo,Zhiyuan Ren,Wenchi Cheng,Jialin Hu,Xinke Jian*

Main category: eess.SY

TL;DR: 为应对紧急无人机网络动态拓扑和潜在任务失败，提出基于SINS预测的协同计算策略。通过WTEG处理拓扑变化，将任务调度映射到WTEG，并用BPSO优化延迟。结果。实验证明，该策略在降低延迟和提高任务成功率方面效果显著。


<details>
  <summary>Details</summary>
Motivation: 在紧急场景下，无人机需要进行及时的轨迹调整，导致网络拓扑动态变化，可能引起任务失败。为了解决这些挑战，需要一种能够应对动态环境并保证任务成功率的协同计算策略。

Method: 提出了一种基于SINS预测的协同计算策略，并构建了两步加权时空扩展图（WTEG）来处理动态网络拓扑。任务调度被表述为有向无环图（DAG）到WTEG的映射问题，并采用二元粒子群优化（BPSO）算法来最小化端到端处理延迟。

Result: 仿真结果表明，所提出的协同计算策略在延迟方面显著优于云计算和本地计算。与没有预测的方法相比，使用SINS预测的任务成功率也得到了显著提高。

Conclusion: 本论文提出的协同计算策略通过使用SINS预测和WTEG图，能够有效应对无人机网络动态拓扑变化，显著降低了端到端处理延迟，并大幅提高了任务成功率，优于传统云计算和本地计算方法。

Abstract: In emergency scenarios, the dynamic and harsh conditions necessitate timely
trajectory adjustments for drones, leading to highly dynamic network topologies
and potential task failures. To address these challenges, a collaborative
computing strategy based strapdown inertial navigation system (SINS) prediction
for emergency UAVs network (EUN) is proposed, where a two-step weighted time
expanded graph (WTEG) is constructed to deal with dynamic network topology
changes. Furthermore, the task scheduling is formulated as a Directed Acyclic
Graph (DAG) to WTEG mapping problem to achieve collaborative computing while
transmitting among UAVs. Finally, the binary particle swarm optimization (BPSO)
algorithm is employed to choose the mapping strategy that minimizes end-to-end
processing latency. The simulation results validate that the collaborative
computing strategy significantly outperforms both cloud and local computing in
terms of latency. Moreover, the task success rate using SINS is substantially
improved compared to approaches without prior prediction.

</details>


### [776] [Average Consensus with Dynamic Compression in Bandwidth-Limited Directed Networks](https://arxiv.org/abs/2508.06893)
*Evagoras Makridis,Gabriele Oliva,Apostolos I. Rikos,Themistoklis Charalambous*

Main category: eess.SY

TL;DR: PP-ACDC 是一种用于有向不平衡网络的分布式共识算法，它使用自适应量化在有限比特率下收敛到精确平均值。


<details>
  <summary>Details</summary>
Motivation: 解决有向不平衡网络在有限比特率通信下的平均共识问题。

Method: 提出了一种名为 PP-ACDC (Push-Pull Average Consensus with Dynamic Compression) 的分布式共识算法，该算法采用自适应量化方案。

Result: 数值收敛性分析和模拟结果证实了 PP-ACDC 算法的性能。

Conclusion: PP-ACDC 算法收敛到精确平均值，并且不需要全局信息。

Abstract: In this paper, the average consensus problem has been considered for directed
unbalanced networks under finite bit-rate communication. We propose the
Push-Pull Average Consensus algorithm with Dynamic Compression (PP-ACDC)
algorithm, a distributed consensus algorithm that deploys an adaptive
quantization scheme and achieves convergence to the exact average without the
need of global information. A preliminary numerical convergence analysis and
simulation results corroborate the performance of PP-ACDC.

</details>


### [777] [Decoupling Structural Heterogeneity from Functional Fairness in Complex Networks: A Theoretical Framework based on the Imbalance Metric](https://arxiv.org/abs/2508.06898)
*Zhiyuan Ren,Zhiliang Shuai,Wenchi Cheng,Kun Yang*

Main category: eess.SY

TL;DR: 该研究提出了网络失衡度（I）指标，用于评估网络公平性，发现结构不对称的网络也能实现高公平性，这为网络设计提供了新的视角。


<details>
  <summary>Details</summary>
Motivation: 传统网络性能评估主要关注结构完整性或平均传输效率，忽略了功能公平性维度。该研究旨在解决一个核心问题：在何种条件下，结构异质性网络可以展现出高的功能公平性。

Method: 提出了一种名为“网络失衡度”（I）的新指标，该指标结合了可调的sigmoid函数和全局Shannon熵框架，以量化感知服务质量（QoS）下端到端可达性公平性。通过分析该指标的数学特性，并在各种经典网络模型上进行验证，以评估其解释力。

Result: 研究发现，低网络失衡度（即高功能公平性）可以通过两种不同的机制实现：一种是基于拓扑对称性（如完全图），另一种是基于由结构不平等驱动的极端连接效率（如无标度网络）。这揭示了结构与功能之间的解耦关系。

Conclusion: 该研究提出了一个新的网络性能评估指标“网络失衡度”（I），用于量化从感知服务质量（QoS）角度来看的端到端可达性公平性。研究表明，结构不对称的网络在特定条件下也可以实现高度的功能公平性，并通过拓扑对称性或极端的连接效率实现低失衡度。这一发现为网络性能评估提供了新的理论视角，并为网络设计中平衡效率和公平性提供了量化工具。

Abstract: Performance evaluation of complex networks has traditionally focused on
structural integrity or average transmission efficiency, perspectives that
often overlook the dimension of functional fairness. This raises a central
question: Under certain conditions, structurally heterogeneous networks can
exhibit high functional fairness. To systematically address this issue, we
introduce a new metric, Network Imbalance (I), designed to quantitatively
assess end-to-end accessibility fairness from a perceived QoS perspective. By
combining a tunable sigmoid function with a global Shannon entropy framework,
the I metric quantifies the uniformity of connection experiences between all
node pairs. We analyze the mathematical properties of this metric and validate
its explanatory power on various classical network models. Our findings reveal
that low imbalance (i.e., high functional fairness) can be achieved through two
distinct mechanisms: one via topological symmetry (e.g., in a complete graph)
and the other via extreme connection efficiency driven by structural inequality
(e.g., in a scale-free network). This decoupling of structure and function
provides a new theoretical perspective for network performance evaluation and
offers an effective quantitative tool for balancing efficiency and fairness in
network design.

</details>


### [778] [Fixed-Time Voltage Regulation for Boost Converters via Unit-Safe Saturating Functions](https://arxiv.org/abs/2508.06987)
*Yiwei Liu,Ziming Wang,Xin Wang,Yiding Ji*

Main category: eess.SY

TL;DR: This paper presents a new control algorithm for boost converters that achieves fixed-time stability, reduces chattering using novel functions, and handles unknown loads with observers and adaptive parameters, proven effective in simulations.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address voltage regulation challenges in boost converter systems and improve the performance of fixed-time control methods by mitigating chattering issues and handling uncertainties like unknown load resistance.

Method: The paper proposes a novel control algorithm for boost converter systems that ensures fixed-time stability. It introduces a new class of function families to mitigate chattering issues common in existing fixed-time control methods. The approach utilizes state observers and adaptive parameters to handle uncertainties from unknown load resistance. Additionally, a new disturbance observer is developed based on the proposed function family.

Result: The proposed control algorithm demonstrates effectiveness and deployability through both non-real-time and real-time simulations, validating its ability to ensure fixed-time stability and manage system uncertainties.

Conclusion: The proposed control algorithm effectively addresses voltage regulation challenges in boost converter systems by ensuring fixed-time stability and managing uncertainties. The novel function families and disturbance observer overcome chattering issues and handle unknown load resistance, as validated by simulations.

Abstract: This paper explores the voltage regulation challenges in boost converter
systems, which are critical components in power electronics due to their
ability to step up voltage levels efficiently. The proposed control algorithm
ensures fixed-time stability, a desirable property that guarantees system
stability within a fixed time frame regardless of initial conditions. To tackle
the common chattering issues in conventional fixed-time control methods, a
novel class of function families is introduced. State observers and adaptive
parameters are utilized to manage the uncertainties associated with unknown
load resistance. Furthermore, a new disturbance observer is developed using the
proposed function family, and its advantages and limitations are illustrated
through comparison with existing designs. Finally, both non-real-time and
real-time simulations are conducted to validate the effectiveness and
deployability of the proposed control algorithm.

</details>


### [779] [Learning-Enabled Adaptive Power Capping Scheme for Cloud Data Centers](https://arxiv.org/abs/2508.06994)
*Yimeng Sun,Zhaohao Ding,Payman Dehghanian,Fei Teng*

Main category: eess.SY

TL;DR: 针对云数据中心高能耗问题，提出一种自适应功率封盖框架，结合不确定性感知强化学习方法，通过重塑功率负载以适应市场信号，并通过模拟实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 数字经济和人工智能的快速发展导致云数据中心能耗和碳排放量巨大，需要有效的能源管理。现有方法在信息不完整、参数不确定和环境动态变化方面存在挑战。

Method: 通过将功率封盖问题制定为部分可观察马尔可夫决策过程，并开发一种考虑不确定性的基于模型强化学习（MBRL）方法，结合两阶段不确定性感知优化算法，以适应动态变化的环境。

Result: 通过基于阿里巴巴真实生产追踪数据构建的云数据中心运行环境模拟器进行的数值实验，验证了所提出方法在云数据中心能源管理方面的有效性。

Conclusion: 该研究提出了一种自适应功率封盖框架，通过动态设置能耗上限来重塑数据中心的功率负载，以适应电价或市场信号。

Abstract: The rapid growth of the digital economy and artificial intelligence has
transformed cloud data centers into essential infrastructure with substantial
energy consumption and carbon emission, necessitating effective energy
management. However, existing methods face challenges such as incomplete
information, uncertain parameters, and dynamic environments, which hinder their
real-world implementation. This paper proposes an adaptive power capping
framework tailored to cloud data centers. By dynamically setting the energy
consumption upper bound, the power load of data centers can be reshaped to
align with the electricity price or other market signals. To this end, we
formulate the power capping problem as a partially observable Markov decision
process. Subsequently, we develop an uncertainty-aware model-based
reinforcement learning (MBRL) method to perceive the cloud data center
operational environment and optimize power-capping decisions. By incorporating
a two-stage uncertainty-aware optimization algorithm into the MBRL, we improve
its adaptability to the ever-changing environment. Additionally, we derive the
optimality gap of the proposed scheme under finite iterations, ensuring
effective decisions under complex and uncertain scenarios. The numerical
experiments validate the effectiveness of the proposed method using a cloud
data center operational environment simulator built on real-world production
traces from Alibaba, which demonstrates its potential as an efficient energy
management solution for cloud data centers.

</details>


### [780] [Distributionally Robust Control with Constraints on Linear Unidimensional Projections](https://arxiv.org/abs/2508.07121)
*Alexandros E. Tzikas,Lukas Fiechtner,Arec Jamgochian,Mykel J. Kochenderfer*

Main category: eess.SY

TL;DR: 提出新的分布鲁棒控制方法，通过迭代算法解决不确定性问题，并成功应用于实际场景。


<details>
  <summary>Details</summary>
Motivation: 为了在不确定性条件下实现最优决策，并解决现有方法在处理特定模糊集时的局限性。

Method: 提出两种迭代算法来近似求解问题：一种基于最佳响应动力学，另一种将问题重新表述为半无限规划并求解其松弛。

Result: 成功地将问题转化为有限凸问题，并提出两种迭代算法近似求解，应用于投资组合构建和轨迹规划。

Conclusion: 该研究提出了一种新的分布鲁棒控制方法，用于解决不确定性下的最优决策问题。

Abstract: Distributionally robust control is a well-studied framework for optimal
decision making under uncertainty, with the objective of minimizing an expected
cost function over control actions, assuming the most adverse probability
distribution from an ambiguity set. We consider an interpretable and expressive
class of ambiguity sets defined by constraints on the expected value of
functions of one-dimensional linear projections of the uncertain parameters.
Prior work has shown that, under conditions, problems in this class can be
reformulated as finite convex problems. In this work, we propose two iterative
methods that can be used to approximately solve problems of this class in the
general case. The first is an approximate algorithm based on best-response
dynamics. The second is an approximate method that first reformulates the
problem as a semi-infinite program and then solves a relaxation. We apply our
methods to portfolio construction and trajectory planning scenarios.

</details>


### [781] [An Analogy of Frequency Droop Control for Grid-forming Sources](https://arxiv.org/abs/2508.07177)
*Minghui Lu,Brett Ross*

Main category: eess.SY

TL;DR: An analogy using water vessels visualizes power system dynamics with grid-forming sources, making complex concepts like power flow and frequency regulation easier to understand and demonstrate.


<details>
  <summary>Details</summary>
Motivation: To provide a powerful visualization tool for power system analyses, particularly for grid-forming (GFM) sources, and to explain abstract power-flow problems using intuitive phenomena for a wider audience.

Method: An analogy is presented where water vessel characteristics (water level, vessel size) represent power system components (frequency, droop slope) and water flow represents power flow. This allows for intuitive explanations of abstract power system concepts.

Result: The analogy accurately reflects GFM source frequency droop characteristics and simulates renewable integration via GFM inverters. Simulation results verify the proposal's effectiveness.

Conclusion: The proposed analogy effectively visualizes power system dynamics dominated by GFM sources, aiding in understanding power flow, frequency regulation, and dispatch for both experts and non-experts.

Abstract: In this paper, we present an analogy for a power system dominated by
grid-forming (GFM) sources that proves to be a powerful visualization tool for
analyses of power flow, frequency regulation, and power dispatch. Frequency
droop characteristics of a typical GFM source are exactly reflected by an
ordinary model of water vessels. The frequency is represented by visible water
levels while the droop slope is reified by the vessel sizes. This proposed
analogy allows us to use the intuitive water-flow phenomenon to explain the
abstract power-flow problems. The grid integration of renewables via GFM
inverters is interestingly simulated by a vessel connected to an infinite water
tank. This paper also provides a means for demonstrating issues to audiences
with little or no background in power systems. Finally, the proposal is
verified by simulation results.

</details>


### [782] [Human-in-the-Loop Simulation for Real-Time Exploration of HVAC Demand Flexibility](https://arxiv.org/abs/2508.07314)
*Xinlei Zhou,Han Du,Emily W. Yap,Wanbin Dou,Mingyang Huang,Zhenjun Ma*

Main category: eess.SY

TL;DR: 本研究开发了一个交互式仿真平台，用户可以实时控制HVAC系统，以探索需求侧灵活性，比传统仿真更具互动性。


<details>
  <summary>Details</summary>
Motivation: 为了应对可再生能源并网带来的对需求侧灵活性日益增长的需求，特别是HVAC系统作为关键的柔性负荷，需要一种更有效的方式来探索和展示其需求灵活性能力。

Method: 开发了一个集成高保真仿真引擎和用户仪表板的交互式仿真平台，允许用户在仿真过程中实时修改HVAC系统设置（如温度设定点和运行计划），以探索需求响应策略。

Result: 用户可以通过实时交互，直观地理解不同需求灵活性场景下的系统行为，增强了对需求侧灵活性的认识，并对实际应用建立信心，从而支持更明智的决策。

Conclusion: 该研究提出的交互式仿真平台通过允许用户实时干预和观察HVAC系统行为，提供了一种更直观、更具交互性的方式来探索需求侧灵活性，超越了传统的被动式仿真。

Abstract: The increasing integration of renewable energy into the power grid has
highlighted the critical importance of demand-side flexibility. Among flexible
loads, heating, ventilation, and air-conditioning (HVAC) systems are
particularly significant due to their high energy consumption and
controllability. This study presents the development of an interactive
simulation platform that integrates a high-fidelity simulation engine with a
user-facing dashboard, specifically designed to explore and demonstrate the
demand flexibility capacity of HVAC systems. Unlike conventional simulations,
where users are passive observers of simulation results with no ability to
intervene in the embedded control during the simulation, this platform
transforms them into active participants. Users can override system default
control settings, such as zone temperature setpoints and HVAC schedules, at any
point during the simulation runtime to implement demand response strategies of
their choice. This human-in-the-loop capability enables real-time interaction
and allows users to observe the immediate impact of their actions, emulating
the practical decision-making process of a building or system operator. By
exploring different demand flexibility scenarios and system behaviour in a
manner that reflects real-world operation, users gain a deeper understanding of
demand flexibility and their impacts. This interactive experience builds
confidence and supports more informed decision-making in the practical adoption
of demand-side flexibility. This paper presents the architecture of the
simulation platform, user-oriented dashboard design, and user case showcase.
The introduced human-in-the-loop simulation paradigm offers a more intuitive
and interactive means of engaging with grid-interactive building operations,
extending beyond HVAC demand flexibility exploration.

</details>


### [783] [A Multi-Model Probabilistic Framework for Seismic Risk Assessment and Retrofit Planning of Electric Power Networks](https://arxiv.org/abs/2508.07376)
*Huangbin Liang,Beatriz Moya,Francisco Chinesta,Eleni Chatzi*

Main category: eess.SY

TL;DR: 为了提高电力系统的抗震能力，本研究提出了一种新的框架，用于评估地震风险和规划修复策略，该策略考虑了系统效应、组件损坏和运行约束，并在IEEE 24总线系统上进行了演示。


<details>
  <summary>Details</summary>
Motivation: 现有的研究往往忽略了电力网络在地震荷载下的系统行为。常见的局限性包括：孤立的组件分析，忽略了全网络的相互依赖性；过于简化的损坏模型，假设二元状态或损坏独立性；以及排除了电气运行约束。这些简化可能导致不准确的风险估计和低效的修复决策。

Method: 本研究提出了一种多模型概率框架，用于电力系统的抗震风险评估和修复规划。该方法集成了区域地震危险性特征化、基于脆弱性函数的组件级损伤分析、基于图的孤岛检测和约束最优潮流分析的系统级级联影响评估，以及通过启发式优化最小化预算约束下的预期年度功能损失（EAFL）的修复规划。使用蒙特卡洛模拟将不确定性传播到整个框架。

Result: 通过对IEEE 24总线可靠性测试系统的演示，证明了该方法能够捕获级联故障、识别关键组件并生成有效的修复策略。

Conclusion: 该框架有潜力成为一个可扩展的、数据驱动的决策支持工具，用于提高电力基础设施的抗震能力。

Abstract: Electric power networks are critical lifelines, and their disruption during
earthquakes can lead to severe cascading failures and significantly hinder
post-disaster recovery. Enhancing their seismic resilience requires identifying
and strengthening vulnerable components in a cost-effective and system-aware
manner. However, existing studies often overlook the systemic behavior of power
networks under seismic loading. Common limitations include isolated component
analyses that neglect network-wide interdependencies, oversimplified damage
models assuming binary states or damage independence, and the exclusion of
electrical operational constraints. These simplifications can result in
inaccurate risk estimates and inefficient retrofit decisions. This study
proposes a multi-model probabilistic framework for seismic risk assessment and
retrofit planning of electric power systems. The approach integrates: (1)
regional seismic hazard characterization with ground motion prediction and
spatial correlation models; (2) component-level damage analysis using fragility
functions and multi-state damage-functionality mappings; (3) system-level
cascading impact evaluation through graph-based island detection and
constrained optimal power flow analysis; and (4) retrofit planning via
heuristic optimization to minimize expected annual functionality loss (EAFL)
under budget constraints. Uncertainty is propagated throughout the framework
using Monte Carlo simulation. The methodology is demonstrated on the IEEE
24-bus Reliability Test System, showcasing its ability to capture cascading
failures, identify critical components, and generate effective retrofit
strategies. Results underscore the potential of the framework as a scalable,
data-informed decision-support tool for enhancing the seismic resilience of
power infrastructure.

</details>


### [784] [Noise-Aware Generative Microscopic Traffic Simulation](https://arxiv.org/abs/2508.07453)
*Vindula Jayawardana,Catherine Tang,Junyi Ji,Jonah Philion,Xue Bin Peng,Cathy Wu*

Main category: eess.SY

TL;DR: 本研究通过创建一个包含真实传感器不完美性的交通数据集（I24-MSD），并开发能利用这些不完美性的生成模型，成功提升了交通仿真的真实感，为未来更贴近实际需求的交通仿真提供了新的方向。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有交通仿真模型在模拟真实个体车辆行为（特别是幻影交通拥堵）时遇到的挑战，以及解决现有数据集过于理想化或缺乏标准化的缺点，本研究旨在构建一个能够真实反映传感器不完美性的数据集，并开发能够有效利用这些不完美数据的仿真模型。

Method: 提出I-24 MOTION Scenario Dataset (I24-MSD)数据集，并在此基础上，借鉴计算机视觉领域的噪声感知学习策略，对现有自动驾驶领域的生成模型进行了改进，使其能够处理并利用数据中的不完美性。

Result: 基于噪声感知学习策略的生成模型在I24-MSD数据集上的表现优于传统基线模型，不仅真实感更强，而且通过明确地利用数据不完美性而非消除它，取得了更好的效果。

Conclusion: 该研究提出的I-24 MOTION Scenario Dataset (I24-MSD)数据集以及基于噪声感知学习策略的生成模型，能够更好地处理现实世界中传感器感知的不完美性，并在交通仿真中取得比传统方法更优越的真实感表现。

Abstract: Accurately modeling individual vehicle behavior in microscopic traffic
simulation remains a key challenge in intelligent transportation systems, as it
requires vehicles to realistically generate and respond to complex traffic
phenomena such as phantom traffic jams. While traditional human driver
simulation models offer computational tractability, they do so by abstracting
away the very complexity that defines human driving. On the other hand, recent
advances in infrastructure-mounted camera-based roadway sensing have enabled
the extraction of vehicle trajectory data, presenting an opportunity to shift
toward generative, agent-based models. Yet, a major bottleneck remains: most
existing datasets are either overly sanitized or lack standardization, failing
to reflect the noisy, imperfect nature of real-world sensing. Unlike data from
vehicle-mounted sensors-which can mitigate sensing artifacts like occlusion
through overlapping fields of view and sensor fusion-infrastructure-based
sensors surface a messier, more practical view of challenges that traffic
engineers encounter. To this end, we present the I-24 MOTION Scenario Dataset
(I24-MSD)-a standardized, curated dataset designed to preserve a realistic
level of sensor imperfection, embracing these errors as part of the learning
problem rather than an obstacle to overcome purely from preprocessing. Drawing
from noise-aware learning strategies in computer vision, we further adapt
existing generative models in the autonomous driving community for I24-MSD with
noise-aware loss functions. Our results show that such models not only
outperform traditional baselines in realism but also benefit from explicitly
engaging with, rather than suppressing, data imperfection. We view I24-MSD as a
stepping stone toward a new generation of microscopic traffic simulation that
embraces the real-world challenges and is better aligned with practical needs.

</details>


### [785] [Neuro-Symbolic Acceleration of MILP Motion Planning with Temporal Logic and Chance Constraints](https://arxiv.org/abs/2508.07515)
*Junyang Cai,Weimin Huang,Jyotirmoy V. Deshmukh,Lars Lindemann,Bistra Dilkina*

Main category: eess.SY

TL;DR: A neuro-symbolic approach accelerates MILP-based motion planning by using machine learning to guide symbolic search, improving scalability and performance by ~20%.


<details>
  <summary>Details</summary>
Motivation: Existing MILP-based planning methods are computationally expensive and lack scalability, hindering real-time applicability for complex, time-sensitive, and uncertain missions.

Method: A neuro-symbolic approach is proposed, leveraging graph neural network-based learning methods to guide traditional symbolic MILP solvers in solving motion planning problems with STL specifications and chance constraints.

Result: The proposed neuro-symbolic approach yields substantial scalability gains, with an average performance improvement of about 20% over state-of-the-art solvers in terms of runtime and solution quality.

Conclusion: Neuro-symbolic search techniques significantly improve the scalability of MILP-based motion planning, achieving an average performance gain of about 20% over state-of-the-art solvers.

Abstract: Autonomous systems must solve motion planning problems subject to
increasingly complex, time-sensitive, and uncertain missions. These problems
often involve high-level task specifications, such as temporal logic or chance
constraints, which require solving large-scale Mixed-Integer Linear Programs
(MILPs). However, existing MILP-based planning methods suffer from high
computational cost and limited scalability, hindering their real-time
applicability. We propose to use a neuro-symbolic approach to accelerate
MILP-based motion planning by leveraging machine learning techniques to guide
the solver's symbolic search. Focusing on two representative classes of
planning problems, namely, those with Signal Temporal Logic (STL)
specifications and those with chance constraints formulated via Conformal
Predictive Programming (CPP). We demonstrate how graph neural network-based
learning methods can guide traditional symbolic MILP solvers in solving
challenging planning problems, including branching variable selection and
solver parameter configuration. Through extensive experiments, we show that
neuro-symbolic search techniques yield scalability gains. Our approach yields
substantial improvements, achieving an average performance gain of about 20%
over state-of-the-art solver across key metrics, including runtime and solution
quality.

</details>


### [786] [Nonlinear Systems in Wireless Power Transfer Applications](https://arxiv.org/abs/2508.07627)
*H Chan*

Main category: eess.SY

TL;DR: The paper explores three wireless power transfer systems with nonlinear control to understand nonlinear systems and reduce battery dependence.


<details>
  <summary>Details</summary>
Motivation: To provide a new energy acquisition method for electric-driven devices, reducing battery dependency, and to deepen the understanding of nonlinear systems.

Method: The paper discusses three types of wireless power transfer (WPT) systems that utilize nonlinear control methods.

Result: The study aims to provide an in-depth understanding of nonlinear systems through the analysis of WPT systems.

Conclusion: This paper presents three types of WPT systems using nonlinear control methods to understand nonlinear systems.

Abstract: As a novel pattern of energization, the wireless power transfer (WPT) offers
a brand-new way to the energy acquisition for electric-driven devices, thus
alleviating the over-dependence on the battery. This report presents three
types of WPT systems that use nonlinear control methods, in order to acquire an
in-depth understanding of the course of Nonlinear Systems.

</details>


### [787] [When are safety filters safe? On minimum phase conditions of control barrier functions](https://arxiv.org/abs/2508.07684)
*Jason J. Choi,Claire J. Tomlin,Shankar Sastry,Koushil Sreenath*

Main category: eess.SY

TL;DR: Safety filters (CBFs) can make system internals unsafe; new conditions ensure safety for all states.


<details>
  <summary>Details</summary>
Motivation: Safety filters, particularly CBFs, are crucial for complex control applications but can lead to internal state divergence despite ensuring state constraints.

Method: Proposing new CBF minimum phase conditions inspired by input-output linearization, tailored to the structure of CBF-constrained control laws, to ensure boundedness of internal dynamics driven by a nonnegative virtual control input.

Result: Developed and validated new CBF minimum phase conditions that ensure the boundedness of the full system state under CBF-based safety filters across various system types (single/multi-input, linear/nonlinear).

Conclusion: CBF-based safety filters can cause internal state divergence, necessitating new CBF minimum phase conditions to ensure boundedness of the full system state, including internal states. These conditions are validated with numerical examples.

Abstract: In emerging control applications involving multiple and complex tasks, safety
filters are gaining prominence as a modular approach to enforcing safety
constraints. Among various methods, control barrier functions (CBFs) are widely
used for designing safety filters due to their simplicity, imposing a single
linear constraint on the control input at each state. In this work, we focus on
the internal dynamics of systems governed by CBF-constrained control laws. Our
key observation is that, although CBFs guarantee safety by enforcing state
constraints, they can inadvertently be "unsafe" by causing the internal state
to diverge. We investigate the conditions under which the full system state,
including the internal state, can remain bounded under a CBF-based safety
filter. Drawing inspiration from the input-output linearization literature,
where boundedness is ensured by minimum phase conditions, we propose a new set
of CBF minimum phase conditions tailored to the structure imposed by the CBF
constraint. A critical distinction from the original minimum phase conditions
is that the internal dynamics in our setting is driven by a nonnegative virtual
control input, which reflects the enforcement of the safety constraint. We
include a range of numerical examples, including single-input, multi-input,
linear, and nonlinear systems, validating both our analysis and the necessity
of the proposed CBF minimum phase conditions.

</details>


### [788] [Deep Reinforcement Learning-Based Control Strategy with Direct Gate Control for Buck Converters](https://arxiv.org/abs/2508.07693)
*Noboru Katayama*

Main category: eess.SY

TL;DR: 所提出的DGC方法通过DRL直接控制栅极信号，在Buck转换器中实现电压调节，相比传统PWM控制具有更快的瞬态响应和更好的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 旨在实现高控制速度和灵活性，同时保持稳定性。

Method: 提出一种基于深度强化学习（DRL）的方​​法，通过DRL训练的神经网络直接生成栅极信号，以实现 Buck 转换器的电压调节。

Result: 仿真结果表明，所提出的DGC方法实现了比传统基于PWM的控制方案更快的瞬态响应和稳定的输出电压调节。

Conclusion: 所提出的直接门控（DGC）方法通过仿真验证了其有效性，该方法在参数变化和传感器噪声下表现出强大的鲁棒性，表明其适用于实际电力电子应用。

Abstract: This paper proposes a deep reinforcement learning (DRL)-based approach for
directly controlling the gate signals of switching devices to achieve voltage
regulation in a buck converter. Unlike conventional control methods, the
proposed method directly generates gate signals using a neural network trained
through DRL, with the objective of achieving high control speed and flexibility
while maintaining stability. Simulation results demonstrate that the proposed
direct gate control (DGC) method achieves a faster transient response and
stable output voltage regulation, outperforming traditional PWM-based control
schemes. The DGC method also exhibits strong robustness against parameter
variations and sensor noise, indicating its suitability for practical power
electronics applications. The effectiveness of the proposed approach is
validated via simulation.

</details>


### [789] [Robust Integrated Priority and Speed Control based on Hierarchical Stochastic Optimization to Promote Bus Schedule Adherence along Signalized Arterial](https://arxiv.org/abs/2508.07749)
*Shurui Guan,Keqiang Li,Haoyu Yang,Yihe Chen,Hanxiao Ren,Yugong Luo*

Main category: eess.SY

TL;DR: 提出了一种新的公交信号优先和速度控制策略，通过分层随机优化和并行计算，提高了公交车准点率，同时最小化了对私家车的影响。


<details>
  <summary>Details</summary>
Motivation: 现有的自适应公交信号优先（TSP）和动态公交车控制系统是独立开发的，缺乏协调可能导致冲突决策。现有的集成控制策略仅依赖信号重规划来解决系统不确定性，在实际交叉口设置中效果不佳，因为考虑到倒计时和行人信号设计，信号计时变化可能不适用。

Method: 提出了一种基于分层随机优化的鲁棒集成优先和速度控制策略，上层负责跨交叉口的协调，下层利用随机规划处理各交叉口的つき不确定性，并通过样本平均近似法（SAA）并行求解。

Result: 仿真结果表明，该方法在各种随机公交车停靠时间和不同交通需求下，显著提高了公交车准点率和时刻表依从性，同时将对私家车延误的负面影响限制在交通需求增加的0.8%-5.2%之间，且无需改变信号配时。

Conclusion: 该方法在不改变信号配时方案的情况下，提高了公交车准点率和时刻表依从性，同时仅略微增加了私家车延误。

Abstract: In intelligent transportation systems (ITS), adaptive transit signal priority
(TSP) and dynamic bus control systems have been independently developed to
maintain efficient and reliable urban bus services. However, those two systems
could potentially lead to conflicting decisions due to the lack of
coordination. Although some studies explore the integrated control strategies
along the arterial, they merely rely on signal replanning to address system
uncertainties. Therefore, their performance severely deteriorates in real-world
intersection settings, where abrupt signal timing variation is not always
applicable in consideration of countdown timers and pedestrian signal design.
  In this study, we propose a robust integrated priority and speed control
strategy based on hierarchical stochastic optimization to enhance bus schedule
adherence along the arterial. In the proposed framework, the upper level
ensures the coordination across intersections while the lower level handles
uncertainties for each intersection with stochastic programming. Hence, the
route-level system randomness is decomposed into a series of local problems
that can be solved in parallel using sample average approximation (SAA).
Simulation experiments are conducted under various scenarios with stochastic
bus dwell time and different traffic demand. The results demonstrate that our
approach significantly enhances bus punctuality and time headway equivalence
without abrupt signal timing variation, with negative impacts on car delays
limited to only 0.8%-5.2% as traffic demand increases.

</details>


### [790] [Deep Reinforcement Learning with Local Interpretability for Transparent Microgrid Resilience Energy Management](https://arxiv.org/abs/2508.08132)
*Mohammad Hossein Nejati Amiri,Fawaz Annaz,Mario De Oliveira,Florimond Gueniat*

Main category: eess.SY

TL;DR: 本研究提出了一种结合PPO和LIME的可解释深度强化学习（XDRL）方法，用于管理微电网韧性。通过在印度Ongole的案例研究，在模拟的极端天气条件下，证明了该方法能有效提高微电网的可靠性和透明度，韧性指数为0.9736，电池寿命预计15.11年。


<details>
  <summary>Details</summary>
Motivation: 可再生能源并网对解决气候变化和资源稀缺等全球能源问题至关重要。然而，可再生能源的波动性和高影响力低概率（HILP）事件的日益增多，对可靠且有韧性的能源管理提出了创新策略的需求。

Method: 本研究提出了一种通过可解释深度强化学习（XDRL）管理微电网韧性的实用方法，结合了近端策略优化（PPO）算法进行决策，以及局部可解释模型无关解释（LIME）方法来提高Actor网络决策的透明度。

Result: 在Ongole，印度的一个包含风能、太阳能和电池组件的微电网案例研究中，模拟了在Layla气旋期间的极端天气条件。结果显示，韧性指数（RI）为0.9736，电池寿命估计为15.11年。LIME分析揭示了智能体在空闲、充电和放电模式下行为的合理性，其中可再生能源发电被确定为最具影响力的特征。

Conclusion: 本研究表明，集成先进的深度强化学习算法与可解释人工智能技术相结合，能够实现可靠且透明的微电网能源管理。

Abstract: Renewable energy integration into microgrids has become a key approach to
addressing global energy issues such as climate change and resource scarcity.
However, the variability of renewable sources and the rising occurrence of High
Impact Low Probability (HILP) events require innovative strategies for reliable
and resilient energy management. This study introduces a practical approach to
managing microgrid resilience through Explainable Deep Reinforcement Learning
(XDRL). It combines the Proximal Policy Optimization (PPO) algorithm for
decision-making with the Local Interpretable Model-agnostic Explanations (LIME)
method to improve the transparency of the actor network's decisions. A case
study in Ongole, India, examines a microgrid with wind, solar, and battery
components to validate the proposed approach. The microgrid is simulated under
extreme weather conditions during the Layla cyclone. LIME is used to analyse
scenarios, showing the impact of key factors such as renewable generation,
state of charge, and load prioritization on decision-making. The results
demonstrate a Resilience Index (RI) of 0.9736 and an estimated battery lifespan
of 15.11 years. LIME analysis reveals the rationale behind the agent's actions
in idle, charging, and discharging modes, with renewable generation identified
as the most influential feature. This study shows the effectiveness of
integrating advanced DRL algorithms with interpretable AI techniques to achieve
reliable and transparent energy management in microgrids.

</details>


### [791] [Robust Adaptive Discrete-Time Control Barrier Certificate](https://arxiv.org/abs/2508.08153)
*Changrui Liu,Anil Alan,Shengling Shi,Bart De Schutter*

Main category: eess.SY

TL;DR: 本研究提出了一种用于离散时间系统的鲁棒自适应CBF方法，该方法可以处理不确定性和干扰，并简化了安全自适应控制器的设计。


<details>
  <summary>Details</summary>
Motivation: 为了确保离散时间系统在参数模型不确定和干扰下的安全性，本研究开发了一种鲁棒自适应控制策略。

Method: 本研究提出了一种使用控制障碍函数（CBFs）的鲁棒自适应控制策略，并为离散时间系统中的一般在线参数估计算法建立了障碍函数证书。

Result: 该研究成功地证明了其提出的鲁棒自适应CBF框架可以保证系统保持在安全集内，同时适应模型不确定性。

Conclusion: 该研究为离散时间系统开发了一种鲁棒自适应控制策略，该策略使用控制障碍函数（CBFs）来确保在参数模型不确定和干扰下的安全性。该方法通过建立离散时间中的障碍函数证书来实现这一点，即使在没有真实系统参数的情况下，也能保证安全集不受干扰和参数不确定的影响。该研究还提供了实时实现的鲁棒性保证，并证明了参数估计模块可以与基于CBF的安全滤波器分开设计，从而简化了离散时间系统的安全自适应控制器的开发。

Abstract: This work develops a robust adaptive control strategy for discrete-time
systems using Control Barrier Functions (CBFs) to ensure safety under
parametric model uncertainty and disturbances. A key contribution of this work
is establishing a barrier function certificate in discrete time for general
online parameter estimation algorithms. This barrier function certificate
guarantees positive invariance of the safe set despite disturbances and
parametric uncertainty without access to the true system parameters. In
addition, real-time implementation and inherent robustness guarantees are
provided. Our approach demonstrates that, using the proposed robust adaptive
CBF framework, the parameter estimation module can be designed separately from
the CBF-based safety filter, simplifying the development of safe adaptive
controllers for discrete-time systems. The resulting safety filter guarantees
that the system remains within the safe set while adapting to model
uncertainties, making it a promising strategy for real-world applications
involving discrete-time safety-critical systems.

</details>


### [792] [Pinching-Antenna Systems (PASS)-based Indoor Positioning](https://arxiv.org/abs/2508.08185)
*Yaoyu Zhang,Xin Sun,Jun Wang,Tianwei Hou,Anna Li,Yuanwei Liu,Arumugam Nallanathan*

Main category: eess.SY

TL;DR: 夹持天线（PA）是一种集成了介电粒子的柔性波导，可以智能地重建视线（LoS）信道。PA系统（PASS）已成功应用于上行链路室内定位。


<details>
  <summary>Details</summary>
Motivation: 为了解决室内定位问题，提出了一种名为“夹持天线”（PA）的新型灵活波导，它可以智能地重建视线（LoS）信道，并将其应用于上行链路室内定位。

Method: 提出了一种基于PASS的接收信号强度指示（RSSI）方法来测量用户到每个PA的距离，然后设计了一种基于PASS的加权最小二乘（WLS）算法来计算用户的二维坐标。

Result: 研究结果表明，波导上的PA数量越多，定位精度和鲁棒性越好；当PA数量超过一定阈值时，性能增益变得不明显；位于PA之间及附近的用户的定位精度更高。

Conclusion: PA系统（PASS）可以通过接收信号强度指示（RSSI）方法和加权最小二乘（WLS）算法实现高效且适合PASS的上行链路室内定位，并能计算用户的二维坐标。

Abstract: Pinching antenna (PA), a flexible waveguide integrated with dielectric
particles, intelligently reconstructs line-of-sight channels. Utilizing its
geometric deterministic model and meter-level reconstruction, PA systems (PASS)
are applied to uplink indoor positioning. In this paper, the uplink positioning
system model for PASS is firstly proposed. A PASS-based received signal
strength indication (RSSI) method is proposed to measure the distance from the
users to each PA, which is efficient and suitable for PASS. PASS-based weighted
least squares (WLS) algorithm is designed to calculate the two-dimensional
coordinates of the users. Several critical observations can be drawn from our
results: i) More PAs on the waveguide improves the positioning accuracy and
robustness. ii) When the number of PAs exceeds a certain threshold, the
performance gain becomes marginal. iii) User locations between and near PAs
yield superior positioning accuracy.

</details>


### [793] [IDSO-Managed Bid-Based Transactive Distribution Systems Design for DER Participation in Wholesale Markets While Preserving T-D Interactions](https://arxiv.org/abs/2508.08187)
*Swastik Sharma,Swathi Battula,Sri Niwas Singh*

Main category: eess.SY

TL;DR: 该研究提出了一种新的交易电能系统（TES）设计，允许分布式能源（DER）通过独立分布式系统运营商（IDSO）参与电力市场，并解决了输电-配电（T-D）系统间的耦合问题。通过创新的投标聚合和零售定价机制，实现了DER的高效协调和价值最大化。


<details>
  <summary>Details</summary>
Motivation: 为了促进分布式能源（DER）在基于竞价的交易电能系统（TES）中的参与，并解决其在配电系统中的应用所带来的输电-配电（T-D）系统强耦合、双向交互问题，同时确保集成输电-配电（ITD）框架的无缝整合。

Method: 提出了一种独立分布式系统运营商（IDSO）管理的、面向非平衡配电系统的竞价式交易电能系统（TES）设计。该设计在集成输电-配电（ITD）框架内运行，通过IDSO允许分布式能源（DER）参与批发电力市场（WPM），同时保持输电-配电系统（T-D）的紧密联系。具体而言，研究提出了一种新颖的投标/报价资格预审和聚合方法，以确保DER参与WPM的投标和报价是安全且有价值的。此外，还提出了一种零售定价机制，以反映在配电系统内购买或提供额定功率的真实价值。

Result: 通过在包含高浓度DER的改进版IEEE 123节点辐射馈线上的案例研究，验证了所提出的框架在高效可靠地协调DER方面的有效性。

Conclusion: 该研究提出的包含大量分布式能源（DER）的非平衡配电系统的独立分布式系统运营商（IDSO）管理竞价式交易电能系统（TES）的设计，能在实际运行中有效协调分布式能源（DER），确保了电力交易的效率和可靠性，并为实现输电-配电系统（T-D）的紧密耦合和双向互动提供了一种有效的解决方案。

Abstract: Participation of Distributed Energy Resources (DERs) in bid-based Transactive
Energy Systems (TES) at the distribution systems facilitates strongly coupled,
bidirectional interactions between Transmission-Distribution (T-D) systems.
Capturing these interactions is critical for ensuring seamless integration
within an Integrated Transmission and Distribution (ITD) framework. This study
proposes a methodology to preserve such tight T-D linkages by developing an
Independent Distribution System Operator (IDSO) managed bid-based TES design
for unbalanced distribution systems. The proposed design operates within the
ITD paradigm and permits DER participation in the Wholesale Power Market (WPM)
through IDSO while preserving tight T-D linkages. To this end, this research
offers the following key contributions: a novel bid/offer
prequalification-cum-aggregation method to ensure a grid-safe and value-based
aggregation of DERs' bids and offers for WPM participation through IDSO; and a
retail pricing mechanism that reflects the true value of procuring or offering
additional units of power within the distribution system. Case studies are
conducted on a modified IEEE 123-bus radial feeder populated with a high DER
concentration to validate the proposed frameworks' effectiveness in
coordinating the DERs efficiently and reliably.

</details>


### [794] [Autonomous Air-Ground Vehicle Operations Optimization in Hazardous Environments: A Multi-Armed Bandit Approach](https://arxiv.org/abs/2508.08217)
*Jimin Choi,Max Z. Li*

Main category: eess.SY

TL;DR: 本研究提出了一种包含BUCB传感策略和VRPP的自主车辆调度框架，用于危险环境的危害缓解。仿真结果显示，该框架能将所需调度周期平均减少约30%。


<details>
  <summary>Details</summary>
Motivation: 危险环境（如化学品泄漏、辐射区域、生物污染场地）对人类安全和公共基础设施构成重大威胁。在这些环境中，快速可靠的危害缓解措施通常对人类来说是不安全的，因此需要能够自适应感知和响应不断变化的风险的自主系统。

Method: 本研究提出了一种用于危险环境的自主车辆调度决策框架，该框架集成了贝叶斯上限置信度（BUCB）传感策略和特定任务的车辆路径规划（VRPP），实现了无人机（UAVs）和无人地面车辆（UGVs）的自适应协调。BUCB策略用于引导UAV进行信息探索和利用，而UGV的路径则根据资源限制优化，以最大化预期的危害降低。

Result: 仿真结果表明，与基线调度策略相比，本框架将解决危害所需的调度周期平均减少了约30%，证明了不确定性感知车辆调度在可靠危害缓解中的价值。

Conclusion: 本框架通过不确定性感知和任务导向的车辆路径规划，能够有效降低危险环境中的危害，并能通过调度车辆解决潜在的危害，从而减少约30%的调度周期。

Abstract: Hazardous environments such as chemical spills, radiological zones, and
bio-contaminated sites pose significant threats to human safety and public
infrastructure. Rapid and reliable hazard mitigation in these settings often
unsafe for humans, calling for autonomous systems that can adaptively sense and
respond to evolving risks. This paper presents a decision-making framework for
autonomous vehicle dispatch in hazardous environments with uncertain and
evolving risk levels. The system integrates a Bayesian Upper Confidence Bound
(BUCB) sensing strategy with task-specific vehicle routing problems with
profits (VRPP), enabling adaptive coordination of unmanned aerial vehicles
(UAVs) for hazard sensing and unmanned ground vehicles (UGVs) for cleaning.
Using VRPP allows selective site visits under resource constraints by assigning
each site a visit value that reflects sensing or cleaning priorities.
Site-level hazard beliefs are maintained through a time-weighted Bayesian
update. BUCB scores guide UAV routing to balance exploration and exploitation
under uncertainty, while UGV routes are optimized to maximize expected hazard
reduction under resource constraints. Simulation results demonstrate that our
framework reduces the number of dispatch cycles to resolve hazards by around
30% on average compared to baseline dispatch strategies, underscoring the value
of uncertainty-aware vehicle dispatch for reliable hazard mitigation.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [795] [Comment on "Unifying Aspects of Generalized Calculus"](https://arxiv.org/abs/2508.06596)
*Mikołaj Sienicki,Krzysztof Sienicki*

Main category: quant-ph

TL;DR: Czachor提出的非牛顿微积分在数学上很有创意，但在物理上存在严重概念问题，尤其是在处理病态双射和缺乏实际预测能力时。


<details>
  <summary>Details</summary>
Motivation: 评估Czachor提出的非牛顿微积分形式主义在物理学中的适用性，特别是其在相对论、熵和宇宙学等领域的应用。

Method: 通过分析任意连续体之间的双射来回拉算术运算来构建非牛顿微积分，并评估其在物理学中的应用。

Result: 该形式主义在应用于相对论、熵或宇宙学等领域时，结果常常归结为没有实际预测能力的同义反复重述，并且在考虑像康托函数这样的病态双射时，该框架的核心假设被打破。

Conclusion: 该形式主义未能提供一个物理上连贯的理论

Abstract: Czachor's recent proposal introduces a form of non-Newtonian calculus built
by pulling back arithmetic operations through arbitrary bijections between
continua. Although the idea is mathematically inventive, it runs into serious
conceptual trouble when examined from a physical standpoint. Claims of
universal applicability quickly unravel under scrutiny -- especially when
considering pathological bijections like the Cantor function, which break the
framework's core assumptions. When applied to domains such as relativity,
entropy, or cosmology, the results often collapse into tautological
restatements lacking real predictive power. This commentary explores these
issues in depth, highlighting where and why the formalism falls short of
providing a physically coherent theory.

</details>


### [796] [Matrix Inversion by Quantum Walk](https://arxiv.org/abs/2508.06611)
*Alastair Kay,Christino Tamon*

Main category: quant-ph

TL;DR: Simplified HHL algorithm using quantum walk instead of phase estimations.


<details>
  <summary>Details</summary>
Motivation: The motivation is to simplify the complex HHL algorithm for matrix inversion and explore its potential applications.

Method: The HHL algorithm is simplified by replacing phase estimations with a continuous time quantum walk, utilizing weak couplings to access matrix inversion within perturbation theory.

Result: The simplified algorithm replaces phase estimations with continuous time quantum walk, offering a new approach to quantum computation for matrix inversion.

Conclusion: the paper presents a simplified HHL algorithm using continuous time quantum walk, which has potential for diverse applications.

Abstract: The HHL algorithm for matrix inversion is a landmark algorithm in quantum
computation. Its ability to produce a state $|x\rangle$ that is the solution of
$Ax=b$, given the input state $|b\rangle$, is envisaged to have diverse
applications. In this paper, we substantially simplify the algorithm,
originally formed of a complex sequence of phase estimations, amplitude
amplifications and Hamiltonian simulations, by replacing the phase estimations
with a continuous time quantum walk. The key technique is the use of weak
couplings to access the matrix inversion embedded in perturbation theory.

</details>


### [797] [Learning to stabilize nonequilibrium phases of matter with active feedback using partial information](https://arxiv.org/abs/2508.06612)
*Giovanni Cemin,Markus Schmitt,Marin Bukov*

Main category: quant-ph

TL;DR: 强化学习被用来控制量子多体系统，防止纠缠扩散。学习到的策略是非贪婪的、随机的，并通过创建瓶颈来减少纠缠。这些策略是内在非平衡的，无法被简单的控制规则取代。


<details>
  <summary>Details</summary>
Motivation: 为了探索信息在量子多体系统的有源反馈控制中的作用，以及利用有源反馈来设计稳态和物质动力学相。

Method: 研究使用强化学习训练智能体，利用部分状态信息来防止（1+1）维稳定器电路中高达128个量子比特的纠缠扩散。

Result: 在临界信息阈值之上，学习到的近乎最优的策略是非贪婪的、随机的，并将体积律纠缠稳态降低到面积律尺度。智能体通过放置一系列瓶颈来实现这一目标，这些瓶颈在长时间空间纠缠分布中诱导金字塔结构，从而有效地分离系统并降低可访问的最大纠缠。

Conclusion: 该研究为经典控制的量子许多相互作用的自由度奠定了基础，展示了强化学习在稳定和揭示许多体非平衡稳态的新的临界性质方面的能力。

Abstract: We investigate the role of information in active feedback control of quantum
many-body systems using reinforcement learning. Active feedback breaks detailed
balance, enabling the engineering of steady states and dynamical phases of
matter otherwise inaccessible in equilibrium. We train reinforcement learning
agents using partial state information to prevent entanglement spreading in
(1+1)-dimensional stabilizer circuits with up to 128 qubits. We find that,
above a critical information threshold, learned near-optimal strategies are
non-greedy, stochastic, and reduce volume-law entangled steady states to
area-law scaling. The agents achieve this by placing a series of bottlenecks
that induce pyramidal structures in the long-time spatial entanglement
distribution, which effectively split the system and reduce the maximum
accessible entanglement. Crucially, learned strategies are inherently out of
equilibrium and require real-time active feedback; we find that the learned
behavior cannot be replaced by simple human-designed control rules. This work
establishes the foundations for classically implemented, information-driven
individual control of many interacting quantum degrees of freedom,
demonstrating the capabilities of reinforcement learning to stabilize and
uncover novel critical properties of many-body nonequilibrium steady states.

</details>


### [798] [Nondegenerate Josephson Mixers with Enhanced Bandwidth and Saturation Power for Quantum Signal Amplification and Transduction](https://arxiv.org/abs/2508.06636)
*Baleegh Abdo,Dongbing Shao,Shayne Cairns,Jae-woong Nah,Oblesh Jinka,Srikanth Srinivasan,Thomas McConkey,Vincent Arena,Corrado Mancini*

Main category: quant-ph

TL;DR: 新约瑟夫森混频器带宽和饱和功率翻倍，可用于量子技术。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有基于谐振器的约瑟夫森混频器（JMs）在带宽和饱和功率方面的限制，以满足大型量子处理器中处理频率多路复用信号的需求。

Method: 通过优化约瑟夫森环调制器（JRMs）的电感参数以抑制高阶混合产物，并结合集总元件耦合模式网络来改善电磁环境，从而重新设计了约瑟夫森混频器。

Result: 实现了约瑟夫森混频器（JMs）在放大（转换）模式下约400 MHz（700 MHz）的带宽，功率反射高于10 dB（低于-10 dB），以及约-110 dBm（-91 dBm）的饱和功率。此外，在转换模式下，低外部品质因数谐振模式约瑟夫森混频器实现了约670 MHz的最大带宽，功率反射低于-10 dB，最大饱和功率约为-86 dBm。

Conclusion: 优化设计的无退化约瑟夫森混频器（JMs）通过抑制高阶混合产物和改进电磁环境，实现了更宽的带宽和更高的饱和功率，可用于高保真度量子比特读出、量子信号单向路由以及连续变量远程纠缠生成等应用。

Abstract: Nondegenerate Josephson mixers (JMs), formed by coupling two different
transmission-line resonators to Josephson ring modulators (JRMs), are vital and
versatile devices capable of processing microwave signals at the quantum limit.
Owing to the lossless nondegenerate three-wave mixing process enabled by the
JRM, JMs can perform phase preserving amplification of quantum signals,
generate two-mode squeezed states, and perform noiseless frequency conversion.
However, due to their limited bandwidth and saturation power, such
resonator-based JMs are generally unable to simultaneously process
frequency-multiplexed signals required in large quantum processors. To overcome
this longstanding dual challenge, we redesign the JRM parameters by optimizing
its inductances to suppress higher order mixing products and engineer its
electromagnetic environment by incorporating lumped-element coupled-mode
networks between the JRM and the two distinct ports of the JM. By implementing
these strategies, we measure for JMs realized with four coupled modes per port,
operated in amplification (conversion), bandwidths of about 400 MHz (700 MHz)
with power reflections above 10 dB (below -10 dB) and saturation powers of
about -110 dBm at 15 dB (-91 dBm at -26 dB). Similarly, we demonstrate for a
low external quality factor resonant-mode JM operated in conversion, a maximum
bandwidth of about $670$ MHz with power reflections below -10 dB and a maximum
saturation power of about -86 dBm at -17 dB. Such nondegenerate JMs with
enhanced bandwidths and saturation powers could serve in a variety of
frequency-multiplexed settings ranging from high fidelity qubit readout and
unidirectional routing of quantum signals to generation of remote entanglement
with continuous variables.

</details>


### [799] [A disputable assumption behind the empirical equivalence between pilot-wave theory and standard quantum mechanics](https://arxiv.org/abs/2508.06667)
*J. Manero,R. Muciño,E. Okon*

Main category: quant-ph

TL;DR: The de Broglie-Bohm pilot-wave theory's claims of agreement with quantum mechanics rely on a flawed assumption about information, which this paper argues against.


<details>
  <summary>Details</summary>
Motivation: The paper aims to analyze the de Broglie-Bohm pilot-wave theory, specifically its claims of complete agreement with standard quantum mechanics through absolute uncertainty and the POVM theorem, and to question the underlying assumption of configurationally grounded information.

Method: The paper argues that the derivations of absolute uncertainty and the POVM theorem depend upon the questionable assumption that "information is always configurationally grounded". It explains in detail why the offered rationale behind such an assumption is deficient and explores the consequences of having to let go of it.

Result: The paper argues that the claimed agreement between pilot-wave theory and standard quantum mechanics, based on absolute uncertainty and the POVM theorem, is flawed due to a questionable assumption about information being configurationally grounded.

Conclusion: The derivations of absolute uncertainty and the POVM theorem depend upon the questionable assumption that "information is always configurationally grounded".

Abstract: The de Broglie-Bohm pilot-wave theory asserts that a complete
characterization of an $N$-particle system is given by its wave function
together with the (at-all-times-defined) positions of the particles, with the
wave function always satisfying the Schr\"odinger equation and the positions
evolving according to the deterministic "guiding equation". A complete
agreement with the predictive apparatus of standard quantum mechanics,
including the uncertainty principle and the probabilistic Born rule, is then
said to emerge from these equations, without having to confer any special
status to measurements or observers. Two key elements behind the proof of this
complete agreement are absolute uncertainty and the POVM theorem. The former
involves an alleged "naturally emerging, irreducible limitation on the
possibility of obtaining knowledge within pilot-wave theory" and the latter
establishes that the outcome distributions of all measurements are described by
POVMs. Here, we argue that the derivations of absolute uncertainty and the POVM
theorem depend upon the questionable assumption that "information is always
configurationally grounded". We explain in detail why the offered rationale
behind such an assumption is deficient and explore the consequences of having
to let go of it.

</details>


### [800] [A scalable photonic quantum interconnect platform](https://arxiv.org/abs/2508.06675)
*Daniel Riedel,Teodoro Graziosi,Zhuoxian Wang,Chawina De-Eknamkul,Alex Abulnaga,Jonathan Dietz,Andrea Mucchietto,Michael Haas,Madison Sutula,Pierre Barral,Matteo Pompili,Carsten Robens,Jeonghoon Ha,Denis Sukachev,David Levonian,Mihir Bhaskar,Matthew Markham,Bartholomeus Machielse*

Main category: quant-ph

TL;DR: 一种用于大规模生产量子存储器的新型金刚石处理技术，可实现高产率和与光子器件的强耦合，为构建模块化量子网络奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 许多量子网络应用需要高效的光子接口到量子存储器，这些存储器可以规模化生产并具有高产率。

Method: 本研究报告了一种在薄膜金刚石上进行晶圆级处理的技术，该技术结合了离子注入和膜剥离、高质量过度生长、目标色心注入以及串行、高通量热压键合，产率接近统一。

Result: 研究演示了将硅-空位（SiV）量子存储器与光子晶体腔可靠、强耦合，其合作度接近100。此外，研究表明光子晶体腔可以可靠地制造在粘合到同一处理芯片的几个膜上。

Conclusion: 这项工作为可扩展的光学可寻址量子存储器阵列的组装铺平了道路，这是模块化光量子互连的关键组成部分。

Abstract: Many quantum networking applications require efficient photonic interfaces to
quantum memories which can be produced at scale and with high yield. Synthetic
diamond offers unique potential for the implementation of this technology as it
hosts color centers which retain coherent optical interfaces and long spin
coherence times in nanophotonic structures. Here, we report a technique
enabling wafer-scale processing of thin-film diamond that combines ion
implantation and membrane liftoff, high-quality overgrowth, targeted color
center implantation, and serial, high-throughput thermocompression bonding with
yields approaching unity. The deterministic deposition of thin diamond
membranes onto semiconductor substrates facilitates consistent integration of
photonic crystal cavities with silicon-vacancy (SiV) quantum memories. We
demonstrate reliable, strong coupling of SiVs to photons with cooperativities
approaching 100. Furthermore, we show that photonic crystal cavities can be
reliably fabricated across several membranes bonded to the same handling chip.
Our platform enables modular fabrication where the photonic layer can be
integrated with functionalized substrates featuring electronic control lines
such as coplanar waveguides for microwave delivery. Finally, we implement
passive optical packaging with sub-decibel insertion loss. Together, these
advances pave the way to the scalable assembly of optically addressable quantum
memory arrays which are a key building block for modular photonic quantum
interconnects.

</details>


### [801] [Reducing quantum resources for observable estimation with window-assisted coherent QPE](https://arxiv.org/abs/2508.06677)
*Harriet Apel,Cristian L. Cortes,Jessica Lemieux,Mark Steudtner*

Main category: quant-ph

TL;DR: 量子相位估计算法中的窗口函数可以提高精度并减少资源消耗。


<details>
  <summary>Details</summary>
Motivation: 量子相位估计算法存在固有的概率性失败，即使在完美门和输入状态下也是如此，这是由于有限量子寄存器无法精确捕获相位。

Method: 研究了窗口函数如何应用于量子相位估计算法，并将其作为实现本征态反射的子程序，同时结合了改进的块编码技术。

Result: 与之前的技术相比，量子资源估计显示了超过两个数量级的Toffoli门计数减少，证明了在量子计算分子可观测值方面资源的有效减少。aterina窗口函数可以改善整体算法的准确性。

Conclusion: 通过使用窗口函数可以提高量子相位估计算法的精度，并为理解窗口函数在复合算法中的误差传播提供了模型。

Abstract: Quantum Phase Estimation (QPE) routines are known to fail probabilistically
even with perfect gates and input states. This effect stems from an
incompatibility of finite-sized quantum registers to capture a phase within QPE
with phase angles of infinite precision, and the effect extend even beyond what
would be reasonably expected from rounding. This effect can be partially
mitigated by biasing the phase register with a window, or taper state, from
classical signal processing. This paper focuses on how windowing a coherent QPE
used as a subroutine can improve the accuracy of the overall algorithm.
Specifically we study the quantum task of estimating observables where
window-assisted coherent QPE is used as a subroutine to implement a reflection
about an eigenstate. Quantum resource estimates show over 2-orders-of-magnitude
reduction in Toffoli counts over the previous costed techniques -- also
assisted by the use of improved block encoding techniques -- demonstrating an
encouraging decrease in resources for quantum computation of molecular
observables. Since QPE, as one of only a few quantum building blocks, appears
as a subroutine in many algorithms; this analysis also provides a model for
understanding how window functions propagate to an improved error in composite
algorithms.

</details>


### [802] [Interference Between Electromagnetic and Mechanical Waves](https://arxiv.org/abs/2508.06683)
*Alexandre Cesar Ricardo,Ciro Micheletti Diniz,Celso Jorge Villas-Bôas*

Main category: quant-ph

TL;DR: 在离子阱中，我们实现了电磁波和机械波的干涉，通过控制它们的相位关系，可以增强或抵消它们对离子状态的影响。这为制造新型量子设备（如晶体管或波包过滤器）开辟了道路。


<details>
  <summary>Details</summary>
Motivation: 在量子理论中，观测结果需要同时考虑系统和测量仪器。本研究旨在利用离子阱平台探索不同物理性质波的干涉现象，以深化对量子干涉的理解，并探索其在量子器件中的应用。

Method: 通过驱动双激光到单离子上，产生Jaynes-Cummings和Carrier相互作用，并研究了其与机械波相位相干性对种群转移的影响。将结果推广到离子链，通过精确调制CarrierRabi频率和相位来控制干涉。

Result: 在单离子实验中，通过调节电磁波与机械波的相位关系，实现了对种群转移的增强或抵消。在离子链实验中，通过精确控制电磁脉冲的参数，实现了与机械相干态的相长或相消干涉，使得离子的电子态表现出不同的行为。

Conclusion: 本研究在离子阱平台上实现了不同物理性质（电磁波与机械波）的干涉，并提出了基于此的新型混合量子器件。

Abstract: Classically, wave interference is a phenomenon that can be explained by
considering only the waves themselves, that is, without the need to consider
the apparatus that monitors or observes them. Thus, in classical theories,
interference can only occur between waves of the same nature. In quantum
theory, the observed results require a description of the system and its
measuring apparatus, which allows us to rethink the explanation of various
natural phenomena. In this paper, we consider the ion-trap platform to study
the interference of waves with different physical natures, specifically the
electromagnetic and mechanical. At first, we drive two lasers onto a
single-trapped ion to produce Jaynes-Cummings and Carrier interactions, where
we verify that, depending on the phase relationship between the coherent state
of the vibrational (mechanical) mode and the Carrier pulse (electromagnetic
wave), the interactions enhance or cancel out population transfer to the
electronic state of the ion, that works out as our measuring apparatus for
those waves. Extending our result to an ion chain, we verify that a precise
modulation of the Carrier Rabi frequency and phase (electromagnetic pulse)
according to the amplitude of the incoming mechanical coherent state in the ion
chain enables creating either constructive or destructive interference with
propagating pulses, in which the electronic state of the driven ion is,
respectively, populated more and faster, or transparent to both pulse waves,
when the information flux behaves as if no external fields are applied.
Finally, this new type of controlled interference between waves of different
natures allows us to propose new hybrid quantum devices, such as transistors or
filters of wave packets, where photonic (phononic) pulses control the passage
of phononic (photonic) waves.

</details>


### [803] [Continuous-Time Quantum Markov Chains And Discretizations Of p-Adic Schrödinger Equations: Comparisons And Simulations](https://arxiv.org/abs/2508.06712)
*W. A. Zúñiga-Galindo,L. F. Chacón-Cortés*

Main category: quant-ph

TL;DR: p-adic薛定谔方程产生的量子马尔可夫链的极限分布通常比其经典马尔可夫链的平稳概率更大。


<details>
  <summary>Details</summary>
Motivation: 为了理解p-adic薛定谔方程产生的CTQMCs与经典的CTMCs之间的关系，以及CTQMCs的性质。

Method: 通过数学研究（包括求解初值问题）和数值模拟（包括极限分布的数值逼近）来比较p-adic薛定谔方程及其CTQMCs与p-adic热方程及其CTMCs。

Result: 数值模拟显示，对于一类广泛的CTQMCs，其量子马尔可夫链的极限分布大于其经典对应物的平稳概率。

Conclusion: 通过数学研究和数值模拟，比较了p-adic薛定谔方程及其相关的连续时间量子马尔可夫链（CTQMCs）与p-adic热方程及其相关的连续时间马尔可夫链（CTMCs）。研究表明，对于一类广泛的CTQMCs，其量子马尔可夫链的极限分布大于其经典对应物的平稳概率。

Abstract: The continuous-time quantum walks (CTQWs) are a fundamental tool in the
development of quantum algorithms. Recently, it was shown that discretizations
of p-adic Schr\"odinger equations give rise to continuous-time quantum Markov
chains (CTQMCs); this type of Markov chain includes the CTQWs constructed using
adjacency matrices of graphs as a particular case. In this paper, we study a
large class of p-adic Schr\"odinger equations and the associated CTQMCs by
comparing them with p-adic heat equations and the associated continuous-time
Markov chains (CTMCs). The comparison is done by a mathematical study of the
mentioned equations, which requires, for instance, solving the initial value
problems attached to the mentioned equations, and through numerical
simulations. We conducted multiple simulations, including numerical
approximations of the limiting distribution. Our simulations show that the
limiting distribution of quantum Markov chains is greater than the stationary
probability of their classical counterparts, for a large class of CTQMCs.

</details>


### [804] [Rotation Errors Due to Field Quantization for Simultaneously Driven Atoms](https://arxiv.org/abs/2508.06769)
*Hunter Lindemann,Shanon Vuglar,Julio Gea-Banacloche*

Main category: quant-ph

TL;DR: 论文研究了量子场驱动多原子系统时的误差问题，发现误差与原子数量 N 的关系取决于初始状态，并提出了利用压缩态或调整相互作用时间来减小误差的方法。


<details>
  <summary>Details</summary>
Motivation: 量子逻辑门中，电磁场与多原子系统相互作用时，场的量子性质可能导致与经典场预测不符的最终原子状态，这是量子逻辑门潜在的误差来源。

Method: 使用二阶微扰理论分析误差随原子数 N 的缩放比例，并考虑了相干态和压缩态。

Result: 误差的缩放比例取决于初始原子状态。对于某些高度纠缠态，误差可能随 N^2 缩放；而对于随机初始状态的平均，误差仅随 N 缩放。

Conclusion: 使用二阶微扰理论研究了相干或拟经典电磁场驱动多原子系统时量子性质引入的误差，并提出了减小误差的方法。

Abstract: When an electromagnetic field in a coherent or quasiclassical (e.g.,
squeezed) state is used to simultaneously drive an ensemble of two-level atoms,
the quantum nature of the field will, in general, cause the final state of the
atoms to differ from the one predicted for a totally classical field. This is a
potential source of error in quantum logic gates in which the gate is the
rotation of the atoms by a laser. In this paper, we use second order
perturbation theory to find how this error scales with the number of atoms,
$N$, being driven simultaneously, for an arbitrary rotation angle. The result
depends on the initial atomic state: for some highly entangled states, and a
field in a coherent state, the error may scale as $N^2$, yet we find that the
average over a random distribution of initial states only scales as $N$. We
discuss possible ways to mitigate the error, including the use of squeezed
states, as well as adjusting the interaction time between the field and atoms
to be different from what would be expected from the classical-field treatment.

</details>


### [805] [Unambiguous discrimination of the change point for quantum channels](https://arxiv.org/abs/2508.06785)
*Kenji Nakahira*

Main category: quant-ph

TL;DR: 研究量子信道状态改变时间的辨识问题，并提出了一种解析求解辨识成功率界限的方法。


<details>
  <summary>Details</summary>
Motivation: 量子信道状态改变时间的辨识是一个基本问题，但其解析解的获取十分困难。

Method: 提出了一种推导最大平均成功率的上下界限的方法。

Result: 当信道转换前后的变换为酉变换时，最大平均成功率可以被解析地表示出来，其结果与信道序列长度以及两个信道的辨识极限有关。

Conclusion: 该研究为量子过程辨识任务提供了一种推导辨识成功率界限的方法，特别是在沟道转换前后均为酉变换的情况下，成功率的上限和下限可以被解析地表达出来。

Abstract: Identifying the precise moment when a quantum channel undergoes a change is a
fundamental problem in quantum information theory. We study how accurately one
can determine the time at which a channel transitions to another. We
investigate the quantum limit of the average success probability in unambiguous
discrimination, in which errors are completely avoided by allowing inconclusive
results with a certain probability. This problem can be viewed as a quantum
process discrimination task, where the process consists of a sequence of
quantum channels; however, obtaining analytical solutions for quantum process
discrimination is generally extremely challenging. In this paper, we propose a
method to derive lower and upper bounds on the maximum average success
probability in unambiguous discrimination. In particular, when the channels
before and after the change are unitary, we show that the maximum average
success probability can be analytically expressed in terms of the length of the
channel sequence and the discrimination limits for the two channels.

</details>


### [806] [Squeezed Magnons-Induced Nonreciprocal Entanglement in a Magnomechanical Cavity](https://arxiv.org/abs/2508.06850)
*Ziyad Imara,Khadija El Anouz,İlkay Demir,Abderrahim El Allati*

Main category: quant-ph

TL;DR: 提出了一种利用替代压缩模式实现磁微腔中磁子、光子和声子非互易性宏观纠缠的新方法，并验证了其在实验上的可行性。


<details>
  <summary>Details</summary>
Motivation: 探索量子电动力学的新前沿，实现宏观纠缠的非互易性，并为混合磁微腔量子技术提供新的可能性。

Method: 通过利用替代压缩模式的磁微腔，并控制其振幅和相位，实现了磁子、光子和声子之间的非互易性宏观纠缠。

Result: 成功实现了可调控的非互易性宏观纠缠，并且该方案的理想非互易性可以通过腔-磁子耦合和环境温度进行优化，所用参数具有实验可行性。

Conclusion: 本文提出的基于替代压缩模式的磁微腔新方法，在实现宏观纠缠的非互易性方面取得了理论上的突破，并且该方案在实验参数上具有可行性，为基于磁微腔的量子技术提供了新的视角。

Abstract: Magnomechanical cavities offer a new frontier in quantum electrodynamics that
give rise to several significant theoretical and experimental results. In this
paper, we propose a novel theoretical mechanism for achieving a nonreciprocal
macroscopic entanglement between magnons, photons and phonons, based on the use
of an alternative squeezed magnons method. Indeed, in contrast to conventional
approaches, we show how precise control of the amplitude and phase of the
squeezed mode allows to obtain a tunable nonreciprocity of entanglement. The
magnons resulting from the collective motion of the spin in a macroscopic
ferrimagnet become coupled to the microwave photons via magnetic dipole
interaction and to the phonons via magnetostrictive interaction. Moreover, we
establish that the proposed scheme achieves ideal nonreciprocity, which can be
optimized by cavity-magnon coupling and bath temperature control. Finally, by
using the parameters that are experimentally feasible with current
technologies, this work provides new perspectives for hybrid magnon-based
quantum technologies.

</details>


### [807] [Counter-propagating Entangled Photon Pairs from a Monolayer](https://arxiv.org/abs/2508.06860)
*Zhuoyuan Lu,Jiri Janousek,Syed M. Assad,Shuyao Qiu,Mayank Joshi,Yecheng Hu,Alex Y Song,Chuanyu Wang,Manuka Suriyage,Jie Zhao,Ping Koy Lam,Yuerui Lu*

Main category: quant-ph

TL;DR: 该研究首次在原子级薄的单层GaSe材料中实现了非相位匹配的自发参量下转换（SPDC），并观察到了双光子量子关联和高保真度贝尔态，为可扩展、可集成的可编程量子态生成平台提供了新的可能性。


<details>
  <summary>Details</summary>
Motivation: 非相位匹配的自发参量下转换（SPDC）在原子级薄材料中为量子信息提供了新的自由度和增强的容量，有望用于量子计算、通信和成像，但直接观测单层材料的光子对发射一直存在实验挑战。

Method: 通过理论建模和实验测量，研究了单层GaSe薄膜中的SPDC发射，并验证了理论模型，同时观察了双光子量子关联和高保真度贝尔态。

Result: 我们成功地在原子级薄的单层GaSe薄膜中实现了电信C波段的双光子量子关联，这是迄今为止报道的最薄的SPDC源。我们还首次在单层材料中实现了反向传播配置下的高保真度贝尔态，证明了其在可编程量子态生成方面的潜力。

Conclusion: 这项工作揭示了在深亚波长、非相位匹配的区域中SPDC的发射特性，并将原子级薄的、反向传播的SPDC引入为可扩展、可集成的可编程量子态生成平台，并且可以通过莫尔超晶格工程进行扩展。

Abstract: Non-phase-matched spontaneous parametric down-conversion (SPDC) in atomically
thin materials provides new degrees of freedom and enhanced quantum information
capacity compared to conventional phase-matched sources. These systems emerged
as promising platforms for quantum computing, communication, and imaging, with
the potential to support higher-order nonlinear processes. However, direct
observation of photon-pair emission from a monolayer has remained
experimentally challenging. In this work, we theoretically modeled SPDC
emission across the full angular space from a monolayer GaSe film and
experimentally validated the model through measurements of both co- and
counter-propagating photon pairs. We demonstrated two-photon quantum
correlations in the telecom C-band from the thinnest SPDC source reported to
date. The spatially symmetric, broadband emission predicted by theory was
confirmed experimentally. Furthermore, we observed high-fidelity Bell states in
the counter-propagating configuration, marking the first realization of
polarization-entangled photon pairs from a monolayer. Our results revealed the
emission characteristics of SPDC in the deeply subwavelength, non-phase-matched
regime, and introduced atomically thin, counterpropagating SPDC as a scalable
and integrable platform for programmable quantum state generation, extendable
via moir\'e superlattice engineering.

</details>


### [808] [A Quantum Walk-Driven Algorithm for the Minimum Spanning Tree Problem under a Maximal Degree Constraint](https://arxiv.org/abs/2508.07007)
*F. S. Luiz,F. F. Fanchini,Victor Hugo C. de Albuquerque,J. P. Papa,M. C. de Oliveira*

Main category: quant-ph

TL;DR: 量子行走方法解决了带最大度约束（MDC）的最小生成树（MST）问题，减少了量子资源需求，并在某些情况下提供了最优或接近最优的解决方案。


<details>
  <summary>Details</summary>
Motivation: 提出一种新颖的量子行走方法来解决带最大度约束（MDC）的最小生成树（MST）问题。

Method: 量子行走方法，将MST问题转化为量子行走，其中顶点编码为量子态，边权重被反转以定义修改后的哈密顿量，通过最大化累积跃迁概率（以及香农熵）来选择MST。

Result: 该方法将量子资源需求减少到O(log N)量子比特，同时保持有竞争力的经典计算复杂性。数值实验表明，当MDC值大于4时，算法能够提供最优或接近最优的总权重MST。当MDC值小于或等于4时，某些实例可以获得次优解，但仍优于几个经典的算法。

Conclusion: 该方法为解决带最大度约束（MDC）的最小生成树（MST）问题提供了一种新颖的量子行走方法，该方法将经典MST问题转化为量子行走问题，并通过最大化累积跃迁概率来选择MST。该方法将量子资源需求减少到O(log N)量子比特，同时保持有竞争力的经典计算复杂性。

Abstract: We present a novel quantum walk-based approach to solve the Minimum Spanning
Tree (MST) problem under a maximal degree constraint (MDC). By recasting the
classical MST problem as a quantum walk on a graph, where vertices are encoded
as quantum states and edge weights are inverted to define a modified
Hamiltonian, we demonstrate that the quantum evolution naturally selects the
MST by maximizing the cumulative transition probability (and thus the Shannon
entropy) over the spanning tree. Our method, termed Quantum Kruskal with MDC,
significantly reduces the quantum resource requirement to $\mathcal{O}(\log N)$
qubits while retaining a competitive classical computational complexity.
Numerical experiments on fully connected graphs up to $10^4$ vertices confirm
that, particularly for MDC values exceeding $4$, the algorithm delivers MSTs
with optimal or near-optimal total weights. When MDC values are less or equal
to $4$, some instances achieve a suboptimal solution, still outperforming
several established classical algorithms. These results open promising
perspectives for hybrid quantum-classical solutions in large-scale graph
optimization.

</details>


### [809] [Bridging Classical and Quantum Computing for Next-Generation Language Models](https://arxiv.org/abs/2508.07026)
*Yi Pan,Hanqi Jiang,Junhao Chen,Yiwei Li,Huaqin Zhao,Lin Zhao,Yohannes Abate,Yingfeng Wang,Tianming Liu*

Main category: quant-ph

TL;DR: AQCF是一个创新的框架，通过动态适应和协同设计，成功地将大型语言模型与量子计算在NISQ设备上相结合，提高了效率并解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决当前将大型语言模型（LLMs）与量子计算集成时，由于NISQ设备的限制（如巴林特和有限相干性）以及静态量子-经典划分导致的挑战。

Method: 提出了一种名为自适应量子-经典融合（AQCF）的框架，通过实时分析输入复杂性，动态地在经典和量子处理之间进行转换。其核心创新包括：1. 熵驱动自适应电路以规避巴林特；2. 量子记忆库以统一经典注意力与量子状态相似性检索；3. 智能融合控制器以优化任务分配。

Result: 在情感分析实验中，AQCF取得了有竞争力的性能，显著提高了量子资源效率，并成功在典型的NISQ约束下运行。

Conclusion: AQCF通过动态、量子-经典协同设计，实现了LLM与量子计算的融合，在NISQ设备上取得了有竞争力且资源高效的成果，为成熟的量子LLM提供了演进路径。

Abstract: Integrating Large Language Models (LLMs) with quantum computing is a critical
challenge, hindered by the severe constraints of Noisy Intermediate-Scale
Quantum (NISQ) devices, including barren plateaus and limited coherence.
Current approaches often fail due to static quantum-classical partitioning. We
introduce Adaptive Quantum-Classical Fusion (AQCF), the first framework to
bridge this gap through dynamic, quantum-classical co-design. AQCF's core
principle is real-time adaptation: it analyzes input complexity to orchestrate
seamless transitions between classical and quantum processing. The framework
features three key innovations: (1) entropy-driven adaptive circuits that
circumvent barren plateaus; (2) quantum memory banks that unify classical
attention with quantum state-based similarity retrieval; and (3) intelligent
fusion controllers that allocate tasks for optimal performance. This
architecture maintains full compatibility with classical Transformers while
progressively incorporating quantum advantages. Experiments on sentiment
analysis demonstrate that AQCF achieves competitive performance, significantly
improves quantum resource efficiency, and operates successfully within typical
NISQ constraints. By providing a seamless integration pathway, AQCF offers both
immediate practical value on current quantum hardware and a clear evolution
path toward mature Quantum LLMs.

</details>


### [810] [Geometry-Controlled Freezing and Revival of Bell Nonlocality through Environmental Memory](https://arxiv.org/abs/2508.07046)
*Mohamed Hatifi*

Main category: quant-ph

TL;DR: Inter-qubit distance in structured reservoirs controls Bell nonlocality. Quantum correlations revive at recurrence times, creating nonlocality passively. Analytical methods quantify this effect and enable sensitive detection via geometry control, e.g., subwavelength displacements. Applicable to superconducting and nanophotonic platforms.


<details>
  <summary>Details</summary>
Motivation: The motivation is to explore passive, geometry-controlled methods for manipulating and preserving quantum correlations, specifically Bell nonlocality, in the presence of decoherence. The research aims to provide practical routes for creating non-Markovian devices by leveraging the geometric properties of qubit-reservoir coupling and system architecture.

Method: The paper employs analytical models to investigate the behavior of qubits coupled to a structured reservoir. It analyzes the role of inter-qubit distance as a geometric control for Bell nonlocality. Specific methods include examining quantum correlation dynamics in a mirror-terminated guide, deriving criteria for nonlocality from backflow in the continuum limit, and introducing a Bell-based analogue of the BLP measure. The study also explores the impact of subwavelength displacements on state lifetimes for interferometric detection.

Result: Quantum correlations lost to a reservoir can return at discrete recurrence times in a mirror-terminated guide, reviving Bell nonlocality. In the continuum limit, closed-form criteria for nonlocality emergence from backflow are derived, along with a measure to quantify this effect. Subwavelength displacements near decoherence-free nodes can reduce state lifetimes, enabling sensitive interferometric detection. All results are analytically derived and compatible with current quantum computing platforms.

Conclusion: The study demonstrates that the distance between qubits coupled to a structured reservoir acts as a geometric control for Bell nonlocality, enabling storage, revival, or suppression. Quantum correlations can be recovered at specific recurrence times in a mirror-terminated guide, generating nonlocality without external entangling drives. Analytical criteria for nonlocality emergence and a Bell-based measure for quantification are derived in the continuum limit. Subwavelength displacements near decoherence-free nodes offer sensitive interferometric detection by reducing state lifetimes. The findings, supported by analytically solvable models, are applicable to superconducting and nanophotonic platforms, paving the way for passive, geometry-controlled non-Markovian devices.

Abstract: We show that the distance between two qubits coupled to a structured
reservoir acts as a single geometric control that can store, revive, or
suppress Bell nonlocality. In a mirror-terminated guide, quantum correlations
lost to the bath return at discrete recurrence times, turning a product state
into a Bell-violating one without any entangling drive (only local basis
rotations/readout). In the continuum limit, we derive closed-form criteria for
the emergence of nonlocality from backflow, and introduce a Bell-based analogue
of the BLP measure to quantify this effect. We also show how subwavelength
displacements away from a decoherence-free node quadratically reduce the
lifetime of a dark state or bright state, enabling highly sensitive
interferometric detection. All results rely on analytically solvable models and
are compatible with current superconducting and nanophotonic platforms,
offering a practical route to passive, geometry-controlled non-Markovian
devices.

</details>


### [811] [QuProFS: An Evolutionary Training-free Approach to Efficient Quantum Feature Map Search](https://arxiv.org/abs/2508.07104)
*Yaswitha Gujju,Romain Harang,Chao Li,Tetsuo Shibuya,Qibin Zhao*

Main category: quant-ph

TL;DR: 提出了一种进化的、无需训练的量子架构搜索（QAS）框架，通过优化可训练性、鲁棒性、泛化能力、表达能力、复杂性和核目标对齐，解决了参数化量子电路训练的挑战，并在分类任务中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决参数化量子电路在数据编码中面临的平坦训练景观和漫长训练过程的挑战。

Method: 提出了一种进化的、无需训练的量子架构搜索（QAS）框架，该框架采用基于电路的启发式方法，专注于可训练性、硬件鲁棒性、泛化能力、表达能力、复杂性和核目标对齐。

Result: 在模拟器和真实量子硬件上，该方法在分类任务（使用量子支持向量机）和各种数据集上都取得了有竞争力的准确性，在采样效率方面超越了最先进的QAS方法，并且在架构搜索运行时间上实现了高达2倍的加速。

Conclusion: 该方法在模拟器和真实量子硬件上都展现出具有竞争力的分类准确性，并且在采样效率方面优于最先进的QAS方法，同时在架构搜索运行时间方面实现了高达2倍的加速。

Abstract: The quest for effective quantum feature maps for data encoding presents
significant challenges, particularly due to the flat training landscapes and
lengthy training processes associated with parameterised quantum circuits. To
address these issues, we propose an evolutionary training-free quantum
architecture search (QAS) framework that employs circuit-based heuristics
focused on trainability, hardware robustness, generalisation ability,
expressivity, complexity, and kernel-target alignment. By ranking circuit
architectures with various proxies, we reduce evaluation costs and incorporate
hardware-aware circuits to enhance robustness against noise. We evaluate our
approach on classification tasks (using quantum support vector machine) across
diverse datasets using both artificial and quantum-generated datasets. Our
approach demonstrates competitive accuracy on both simulators and real quantum
hardware, surpassing state-of-the-art QAS methods in terms of sampling
efficiency and achieving up to a 2x speedup in architecture search runtime.

</details>


### [812] [Low Cost Bayesian Experimental Design for Quantum Frequency Estimation with Decoherence](https://arxiv.org/abs/2508.07120)
*Alexandra Ramôa,Luís Paulo Santos,Akihito Soeda*

Main category: quant-ph

TL;DR: WES is a low cost adaptive Bayesian experimental design strategy for estimating frequency in two-level quantum systems. It uses cost-reduction techniques for efficiency and parallelism, and its performance is adjustable. WES outperforms other heuristics and saturates the Heisenberg limit.


<details>
  <summary>Details</summary>
Motivation: The estimation of the associated frequency is a cornerstone problem in quantum metrology, sensing, calibration and control.

Method: WES employs empirical cost-reduction techniques to keep the optimization overhead low, curb scaling problems, and enable high degrees of parallelism. It offers adjustable classical processing costs that determine the performance standard.

Result: Numerical simulations show that WES delivers the most reliable performance and fastest learning rate, saturating the Heisenberg limit. As a benchmark, we analyze the performance of widely adopted heuristics, comparing them with the fundamental limits of metrology and a baseline random strategy.

Conclusion: WES delivers the most reliable performance and fastest learning rate, saturating the Heisenberg limit.

Abstract: A two-level quantum system evolving under a time-independent Hamiltonian
produces oscillatory measurement probabilities. The estimation of the
associated frequency is a cornerstone problem in quantum metrology, sensing,
calibration and control. In this work, we tackle this task by introducing WES:
a Window Expansion Strategy for low cost adaptive Bayesian experimental design.
WES employs empirical cost-reduction techniques to keep the optimization
overhead low, curb scaling problems, and enable high degrees of parallelism.
Unlike previous heuristics, it offers adjustable classical processing costs
that determine the performance standard. As a benchmark, we analyze the
performance of widely adopted heuristics, comparing them with the fundamental
limits of metrology and a baseline random strategy. Numerical simulations show
that WES delivers the most reliable performance and fastest learning rate,
saturating the Heisenberg limit.

</details>


### [813] [Block encoding the 3D heterogeneous Poisson equation with application to fracture flow](https://arxiv.org/abs/2508.07125)
*Austin Pechan,John Golden,Daniel O'Malley*

Main category: quant-ph

TL;DR: 量子算法在解决三维泊松方程方面比经典方法更快，并节省内存，但降低条件数是实现量子优势的关键。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索量子线性系统（QLS）算法在解决三维非均质泊松方程方面的可行性，特别是在地下水流模拟中的应用，以克服经典方法在处理大规模线性系统时的挑战。

Method: 通过显式构建三维非均质泊松方程的块编码，利用离散化算子的稀疏局部结构。分析了将系统矩阵和预处理条件数分别进行块编码对有效条件数的影响，并与经典方法进行了对比。

Result: 量子算法实现了$O(N^{2/3} 	ext{ polylog } N 	imes 	ext{ log}(1/	ext{epsilon}))$ 的运行时间，优于经典方法的$O(N 	ext{ log } N 	imes 	ext{ log}(1/	ext{epsilon}))$，并实现了指数级内存节省。但单独对系统矩阵和预处理条件数进行块编码并不能提高有效条件数。

Conclusion: 该研究突显了量子线性系统（QLS）算法在解决三维非均质泊松方程方面的潜力，尤其是在地下水流模拟方面。尽管存在状态制备和数据加载等挑战，但通过显式构建离散化算子的块编码，该量子算法实现了$O(N^{2/3} 	ext{ polylog } N 	imes 	ext{ log}(1/	ext{epsilon}))$ 的运行时间，优于经典方法。然而，研究也指出，单独对系统矩阵和预处理条件数进行块编码并不能提高有效的条件数，这与经典方法不同。有效的条件数降低是实现量子优势的关键障碍。

Abstract: Quantum linear system (QLS) algorithms offer the potential to solve
large-scale linear systems exponentially faster than classical methods.
However, applying QLS algorithms to real-world problems remains challenging due
to issues such as state preparation, data loading, and efficient information
extraction. In this work, we study the feasibility of applying QLS algorithms
to solve discretized three-dimensional heterogeneous Poisson equations, with
specific examples relating to groundwater flow through geologic fracture
networks. We explicitly construct a block encoding for the 3D heterogeneous
Poisson matrix by leveraging the sparse local structure of the discretized
operator. While classical solvers benefit from preconditioning, we show that
block encoding the system matrix and preconditioner separately does not improve
the effective condition number that dominates the QLS runtime. This differs
from classical approaches where the preconditioner and the system matrix can
often be implemented independently. Nevertheless, due to the structure of the
problem in three dimensions, the quantum algorithm achieves a runtime of
$O(N^{2/3} \ \text{polylog } N \cdot \log(1/\epsilon))$, outperforming the best
classical methods (with runtimes of $O(N \log N \cdot \log(1/\epsilon))$) and
offering exponential memory savings. These results highlight both the promise
and limitations of QLS algorithms for practical scientific computing, and point
to effective condition number reduction as a key barrier in achieving quantum
advantages.

</details>


### [814] [Optimal Quantum Estimation with Stabilizer-Based Local Measurements](https://arxiv.org/abs/2508.07150)
*Jia-Xuan Liu,Hai-Long Shi,Chunfeng Wu,Sixia Yu*

Main category: quant-ph

TL;DR: 本研究提出一种基于稳定器形式主义的方法，可在局部测量下实现最优量子计量精度，尤其在噪声环境下，所提出的探针态子空间比GHZ态更具鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 量子计量的一个核心挑战是在反映实际实验条件的测量约束下，识别最优的量子计量方案，例如在多体场景下的局部测量。本研究旨在解决这一挑战，提出能在局部测量下饱和量子克拉美-Rao界的方案。

Method: 本研究基于稳定器形式主义，提出了一个充分条件，用于判断量子计量方案是否能在局部测量约束下饱和量子克拉美-Rao界（QCRB）。研究分析了图态在理想和噪声环境下的表现，并构建了能在噪声环境下饱和QCRB并保持精度标度不变的探针态子空间。

Result: 研究表明，图态在理想情况下可以通过局部测量实现最优估计精度，精度由图结构决定。还发现了一类探针态具有次优精度标度。在噪声环境下，构建的探针态子空间不仅能饱和QCRB，还能保持精度标度不变，并表现出对噪声的鲁棒性，优于GHZ态。

Conclusion: 本研究提出了一个基于稳定器形式主义的充分条件，用于在存在局部测量约束的量子计量方案中实现量子克拉美-Rao界（QCRB）。研究表明，在理想情况下，图态总是允许局部估计协议，其最优估计精度仅由基础图结构决定。还确定了一类实现次优精度标度的图态作为探针态。在噪声环境下，研究构建了探针态的几个子空间（通常是混合态），这些子空间不仅可以用局部测量饱和QCRB，还能保持近似不变的精度标度。这些子空间提供了多种计量优势，包括高精度、部分抗噪声能力以及在参数编码前进行噪声校正的能力。在退相干噪声下，与Greenberger-Horne-Zeilinger态相比，这些子空间表现出明显更好的性能。研究结果推进了局部测量量子计量的框架，实现了精度和噪声容忍度之间的稳健权衡。

Abstract: A central challenge in quantum metrology is to identify optimal protocols
under measurement constraints that reflect realistic experimental conditions,
e.g., local measurements in multipartite scenarios. Here, we present a
sufficient criterion for metrological schemes to saturate the quantum
Cram\'er-Rao bound (QCRB) using local measurements, based on stabilizer
formalism. In ideal settings, we show that graph states always admit local
estimation protocols with an optimal estimation precision determined only by
the underlying graph structure. A family of graph states is identified as probe
states that achieve suboptimal precision scaling. In noisy environments, we
construct several subspaces of probe states (mixed in general) that not only
saturate the QCRB with local measurements but also maintain approximately
invariant precision scaling. These subspaces offer multiple metrological
advantages, including high precision, partial noise resilience, and
noise-correcting capability prior to parameter encoding. Under dephasing noise,
they exhibit markedly better performance than Greenberger-Horne-Zeilinger
states. Our results advance the framework for local-measurement quantum
metrology, achieving a robust trade-off between precision and noise tolerance.

</details>


### [815] [Bargmann invariants of Gaussian states](https://arxiv.org/abs/2508.07155)
*Jianwei Xu*

Main category: quant-ph

TL;DR: This paper derives the formula for the Bargmann invariant of bosonic Gaussian states using their means and covariance matrices, and investigates the possible values the invariant can take.


<details>
  <summary>Details</summary>
Motivation: The Bargmann invariant is a fundamental concept in quantum mechanics with applications in quantum information science. Bosonic Gaussian states are important in quantum optics and information science.

Method: The expression of Bargmann invariant tr($\rho _{1}\rho _{2}...
$\rho _{n}$) for any $m$-mode bosonic Gaussian states is derived in terms of their means and covariance matrices.

Result: The expression of the Bargmann invariant for bosonic Gaussian states is derived and used to explore its permissible values.

Conclusion: We provide the expression of Bargmann invariant for bosonic Gaussian states and explore its permissible values.

Abstract: Given a set of ordered quantum states, described by density operators $%
\{\rho _{j}\}_{j=1}^{n}$, the Bargmann invariant of $\{\rho _{j}\}_{j=1}^{n}$
is defined as tr($\rho _{1}\rho _{2}...\rho _{n}$). Bargmann invariant serves
as a fundamental concept for quantum mechanics and has diverse applications in
quantum information science. Bosonic Gaussian states are a class of quantum
states on infinite-dimensional Hilbert space, widely used in quantum optics and
quantum information science. Bosonic Gaussian states are conveniently and
conventionally characterized by their means and covariance matrices. In this
work, we provide the expression of Bargmann invariant tr($\rho _{1}\rho
_{2}...\rho _{n}$) for any $m$-mode bosonic Gaussian states $\{\rho
_{j}\}_{j=1}^{n}$ in terms of the means and covariance matrices of $\{\rho
_{j}\}_{j=1}^{n}.$ We also use this expression to explore the permissible
values of Bargmann invariants for bosonic Gaussian states.

</details>


### [816] [GPU-Accelerated Syndrome Decoding for Quantum LDPC Codes below the 63 $μ$s Latency Threshold](https://arxiv.org/abs/2508.07879)
*Oscar Ferraz,Bruno Coutinho,Gabriel Falcao,Marco Gomes,Francisco A. Monteiro,Vitor Silva*

Main category: quant-ph

TL;DR: 研究提出了一种在普通GPU上运行的量子低密度奇偶校验码解码器，速度很快（低于50微秒），可以用于超越表面码的量子计算机。


<details>
  <summary>Details</summary>
Motivation: 为了应对Panteleev和Kalachev提出的量子低密度奇偶校验码（QLDPC）所带来的更高解码复杂性，同时克服表面码随码距离增加而编码速率趋近于零的扩展性挑战，本研究致力于开发一种高效的解码器。

Method: 该研究提出了一种利用综合GPU硬件的并行化信念传播解码器，该解码器利用了综合信息来最大化目标延迟限制内的性能。

Result: 所提出的GPU加速解码器实现了低于63微秒的延迟，低于在Google的Willow量子处理器上演示的表面码解码器的实时阈值。对于[[784, 24, 24]]码，解码延迟低于50微秒，对于更小的码，延迟低至23.3微秒。

Conclusion: 该研究展示了在商品GPU硬件上实现的并行化信念传播解码器，能够以低于50微秒的延迟解码[[784, 24, 24]]的量子低密度奇偶校验码，最低可达23.3微秒，满足了超导量子比特周期的严格时序要求。这表明使用广泛可用的商品硬件，可以实现对超出行波码的、可扩展的、具有良好渐近性能的量子码的实时解码，从而推进了容错量子计算的可行性。

Abstract: This paper presents a GPU-accelerated decoder for quantum low-density
parity-check (QLDPC) codes that achieves sub-$63$ $\mu$s latency, below the
surface code decoder's real-time threshold demonstrated on Google's Willow
quantum processor. While surface codes have demonstrated below-threshold
performance, the encoding rates approach zero as code distances increase,
posing challenges for scalability. Recently proposed QLDPC codes, such as those
by Panteleev and Kalachev, offer constant-rate encoding and asymptotic goodness
but introduce higher decoding complexity. To address such limitation, this work
presents a parallelized belief propagation decoder leveraging syndrome
information on commodity GPU hardware. Parallelism was exploited to maximize
performance within the limits of target latency, allowing decoding latencies
under $50$ $\mu$s for [[$784$, $24$, $24$]] codes and as low as $23.3$ $\mu$s
for smaller codes, meeting the tight timing constraints of superconducting
qubit cycles. These results show that real-time, scalable decoding of
asymptotically good quantum codes is achievable using widely available
commodity hardware, advancing the feasibility of fault-tolerant quantum
computation beyond surface codes.

</details>


### [817] [Positive-divisibility of Subsystems in Quantum Dynamics](https://arxiv.org/abs/2508.07188)
*Anumita Mukhopadhyay,Praggnyamita Ghosh,Shibdas Roy*

Main category: quant-ph

TL;DR: 记忆效应可以恢复量子关联，后向信息流与CP和P不可分性有关。本研究表明，幺正信道是P可分的，并且在联合态演化是幺正的情况下，系统和环境需要是P可分的，但不能同时是P不可分的。三比特W态的例子表明，从环境回溯的信息可以增加系统的量子性。


<details>
  <summary>Details</summary>
Motivation: 已知记忆效应可以恢复开放量子系统动力学中的量子关联，环境到系统的后向信息流可以通过完全正（CP）不可分性和正（P）不可分性标准来识别。

Method: 研究了P可分性与噪声信道幺正性条件的关系，证明了幺正信道是P可分的。

Result: 展示了系统信道及其环境都需要是P可分的，但不能同时是P不可分的。此外，还通过作用在不同状态集合上的三个幺正算符建立了这一结果，并以三比特W态为例，说明了由于环境向系统回溯信息，系统的量子性可以增加。

Conclusion: 系统和环境都需要是 P 可分（P-divisible）的，但不能同时是 P 不可分（P-indivisible）的，前提是系统-环境联合量子态演化是幺正的。

Abstract: It is known that the existence of memory effect can revive quantum
correlations in open system dynamics. In this regard, the backflow of
information from environment to the system can be identified with Complete
Positive (CP) indivisibility as well as Positive (P) indivisibility criteria.
It is also known that if a quantum system is CP-divisible, it can also have
memory effect which can be witnessed by P-indivisibility. Here, we have
explored the relation of P-divisibility with unitality condition of noise
channels, showing that a unital channel is P-divisible. We have shown how a
system channel and its environment need to be both P-divisible, but cannot be
both P-indivisible, provided the system-environment joint quantum state evolves
unitarily. We have also established our results using three unitaries acting on
different sets of states. In particular, due to backflow of information from
the environment, quantumness of a system can increase, as shown for an example
of the three-qubit W state.

</details>


### [818] [Squeezed Coherent States in Supersymmetric Quantum Mechanics with Position-Dependent Mass](https://arxiv.org/abs/2508.07228)
*Daniel Sabi Takou,Amidou Boukari,Assimiou Yarou Mora,Gabriel Y. H. Avossevou*

Main category: quant-ph

TL;DR: 本研究在超对称量子力学（SUSYQM）框架和位置相关质量（PDM）概念下，利用变形代数结构推广了产生和湮灭算符，得到了具有压缩、相干和修正不确定性关系等非经典特征的新型量子态，这些特征同时受到形变参数和质量函数的影响，为相干态理论在更复杂的量子系统中的应用提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在将相干态理论扩展到更复杂的量子系统，这些系统具有丰富的几何和代数结构。

Method: 利用变形代数结构，我们推广了产生和湮灭算符，以适应空间变化的质量分布。

Result: 生成的新型量子态表现出压缩、相干和修正的不确定性关系等非经典特征，这些特征受到形变参数和质量函数的影响。

Conclusion: 本研究将发展超对称量子力学（SUSYQM）框架下的相干态理论，并引入位置相关质量（PDM）的概念，通过变形代数结构推广了产生和湮灭算符，以适应空间变化的质量分布。

Abstract: In this paper, we construct and analyze a class of squeezed coherent states
within the framework of supersymmetric quantum mechanics (SUSYQM) involving a
position-dependent mass (PDM). Using a deformed algebraic structure, we
generalize the creation and annihilation operators to accommodate spatially
varying mass profiles. The resulting states exhibit non-classical features,
such as squeezing, coherence, and modified uncertainty relations, strongly
influenced by both the
  deformation parameters and the mass function. We explore their physical
properties through expectation values, variances, and probability densities.
This work provides a pathway toward extending coherent state theory to more
complex quantum systems with geometrical and algebraic richness.

</details>


### [819] [Information in quantum field theory simulators: Thin-film superfluid helium](https://arxiv.org/abs/2508.07247)
*Maciej T. Jarema,Cameron R. D. Bunney,Vitor S. Barroso,Mohammadamin Tajik,Chris Goodwin,Silke Weinfurtner*

Main category: quant-ph

TL;DR: 在超流氦薄膜中测量互信息，以验证量子关联的面积定则缩放。


<details>
  <summary>Details</summary>
Motivation: 理解量子关联对于量子场论、量子信息和量子多体物理学的发展至关重要，而面积定则是许多系统的一个中心特征，但实验验证，尤其是在连续系统中，仍然有限。

Method: 提出了一种在超流氦薄膜（模拟 (2 + 1) 维度时空）实验模拟器中测量互信息的方法。

Result: 预测了考虑氦样品自然热态的数值结果，该结果例证了互信息的面积定则缩放，并描述了由于有限系统尺寸引起的偏差。

Conclusion: 本研究提出了在超流氦薄膜实验模拟器中测量互信息的方法，并展示了互信息如何体现面积定则缩放，以及有限系统尺寸对结果的影响。

Abstract: Understanding quantum correlations through information-theoretic measures is
fundamental to developments in quantum field theory, quantum information, and
quantum many-body physics. A central feature in a plethora of systems is the
area law, under which information scales with the size of the boundary of the
system, rather than volume. Whilst many systems and regimes exhibiting an area
law have been identified theoretically, experimental verification remains
limited, particularly in continuous systems. We present a methodology for
measuring mutual information in an experimental simulator of non-interacting
quantum fields, and propose using the analogue $(2 + 1)$-dimensional spacetime
offered by thin films of superfluid helium. We provide numerical predictions
incorporating the natural thermal state of the helium sample that exemplify an
area-law scaling of mutual information, and characterise deviations
attributable to the inherent finite system size.

</details>


### [820] [The simplest Kochen-Specker set](https://arxiv.org/abs/2508.07335)
*Adán Cabello*

Main category: quant-ph

TL;DR: 新KS集合：更对称、基数少至14，反驳猜想2。


<details>
  <summary>Details</summary>
Motivation: 为了寻找更简单、更对称的Kochen-Specker（KS）集合，并优化实现无信号限制的二方相关性和非局部博弈的量子系统。

Method: 提出了一种新的Kochen-Specker（KS）集合，该集合在三维系统中具有更高的对称性，并且比现有的KS集合更容易证明。通过此新集合，将三维系统中KS集合所需的最小基数从16个减少到14个。

Result: 发现了一个包含14个基数的更对称、更易于证明的Kochen-Specker（KS）集合，创纪录地减少了所需基数。此外，该集合在qutrit-qutrit完美策略中将最少输入数减少到5-9个，并反驳了Phys. Rev. Lett. 134, 010201 (2025)中的猜想2。

Conclusion: 新发现了一个更对称、更容易证明的Kochen-Specker（KS）集合，并创纪录地将三维系统中KS集合所需的最少基数减少到14个，同时在qutrit-qutrit完美策略中将最少输入数减少到5-9个，从而反驳了Phys. Rev. Lett. 134, 010201 (2025)中的猜想2。

Abstract: Kochen-Specker (KS) sets are fundamental in physics. Every time nature
produces bipartite correlations attaining the nonsignaling limit, or two
parties always win a nonlocal game impossible to always win classically, is
because the parties are measuring a KS set. The simplest quantum system in
which all these phenomena occur is a pair of three-level systems. However, the
simplest KS sets in dimension three known are asymmetrical and require a large
number of bases (the current minimum is 16, set by Peres and Penrose). Here we
present a KS set that is much more symmetrical and easier to prove than any
previous example. It sets a new record for minimum number of bases, 14, and
enables us to refute Conjecture 2 in Phys. Rev. Lett. 134, 010201 (2025),
setting a new record for qutrit-qutrit perfect strategies with a minimum number
of inputs: 5-9.

</details>


### [821] [Quantum MIMO Diversity over Discrete-Variable Crosstalk Channels](https://arxiv.org/abs/2508.07344)
*Shehbaz Tariq,Junaid ur Rehman,Symeon Chatzinotas*

Main category: quant-ph

TL;DR: 提出了一种量子MIMO分集策略，利用克隆和提纯技术来提高通信可靠性，并在特定条件下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 量子通信在实现分布式量子计算和传感中起着关键作用。当存在多个通信信道时，可以使用分集策略来提高通信的可靠性（在输出保真度方面）。

Method: 提出了一种用于量子离散变量（DV）多输入多输出（MIMO）信道的协作策略，该策略利用近似克隆技术在发射端将信息分布到多个信道，并利用提纯技术在接收端将混合的、纠缠的联合态合并为单个量子态。

Result: 克隆-提纯策略提供了优势，尤其是在可以利用完整的信道状态信息（CSI）来优化克隆不对称性的情况下。与经典MIMO分集不同，量子信息分布在所有可用信道上并不总是有利的，因为克隆操作会稀释信息。

Conclusion: 量子信息分布在所有可用信道上并不总是有利的，因为克隆操作会稀释信息。

Abstract: Quantum communication plays a pivotal role in enabling distributed quantum
computing and sensing. Diversity strategies can be used to increase the
communication reliability (in the sense of output fidelity with respect to the
input quantum state) when multiple communication channels are available. The
current paper proposes a diversity strategy for quantum discrete variable (DV)
multiple-input-multiple-output (MIMO) channels, utilizing approximate cloning
to distribute information across multiple channels at the transmitter and
purification to merge the noisy and entangled joint state into a single quantum
state at the receiver. The proposed method is compared with simpler strategies,
such as the best-channel selection, to identify the advantage regions over a
quantum channel combining both crosstalk and depolarization, where the
crosstalk is modeled by a controlled-SWAP operator. Our numerical results show
that the cloning-purification strategy offers an advantage, especially in cases
where full channel state information (CSI) can be exploited to optimize the
cloning asymmetry. More importantly, and in contrast to the classic MIMO
diversity, we demonstrate that the distribution of quantum information over all
available channels does not always provide an advantage due to the dilution
cost of the cloning operation.

</details>


### [822] [Quantum simulation of topological zero modes on a 41-qubit superconducting processor](https://arxiv.org/abs/2211.05341)
*Yun-Hao Shi,Yu Liu,Yu-Ran Zhang,Zhongcheng Xiang,Kaixuan Huang,Tao Liu,Yong-Yi Wang,Jia-Chi Zhang,Cheng-Lin Deng,Gui-Han Liang,Zheng-Yang Mei,Hao Li,Tian-Ming Li,Wei-Guo Ma,Hao-Tian Liu,Chi-Tong Chen,Tong Liu,Ye Tian,Xiaohui Song,S. P. Zhao,Kai Xu,Dongning Zheng,Franco Nori,Heng Fan*

Main category: quant-ph

TL;DR: 在43比特量子处理器上模拟了拓扑相，演示了Hofstadter蝴蝶能谱，并验证了从未实验实现的拓扑零模。


<details>
  <summary>Details</summary>
Motivation: 在嘈杂的中等规模量子（NISQ）处理器上进行不同奇异拓扑量子物态的量子模拟引起了日益增长的兴趣。

Method: 在一台包含43个超导量子比特的量子处理器（命名为“子”）上，通过工程化设计一维43比特的对角线Aubry-André-Harper（AAH）模型，并利用Floquet工程，实验演示了Hofstadter蝴蝶能谱，并验证了在整数次off-diagonal AAH模型中拓扑零模的存在。

Result: 在40个以上的量子比特的量子处理器上，成功捕获了量子系统的复杂能带结构的拓扑特征，包括狄拉克点、能隙闭合、奇偶数个位点的差异以及边界态和体态的区别。

Conclusion: 该研究结果为在NISQ时代探索量子拓扑系统提供了一种通用的混合量子模拟方法。

Abstract: Quantum simulation of different exotic topological phases of quantum matter
on a noisy intermediate-scale quantum (NISQ) processor is attracting growing
interest. Here, we develop a one-dimensional 43-qubit superconducting quantum
processor, named as Chuang-tzu, to simulate and characterize emergent
topological states. By engineering diagonal
Aubry-Andr$\acute{\mathrm{e}}$-Harper (AAH) models, we experimentally
demonstrate the Hofstadter butterfly energy spectrum. Using Floquet
engineering, we verify the existence of the topological zero modes in the
commensurate off-diagonal AAH models, which have never been experimentally
realized before. Remarkably, the qubit number over 40 in our quantum processor
is large enough to capture the substantial topological features of a quantum
system from its complex band structure, including Dirac points, the energy
gap's closing, the difference between even and odd number of sites, and the
distinction between edge and bulk states. Our results establish a versatile
hybrid quantum simulation approach to exploring quantum topological systems in
the NISQ era.

</details>


### [823] [Integrating Quantum Computing with Multiconfiguration Pair-Density Functional Theory for Biological Electron Transfer](https://arxiv.org/abs/2508.07359)
*Yibo Chen,Zirui Sheng,Weitang Li,Yong Zhang,Xun Xu,Jun-Han Huang,Yuxiang Li*

Main category: quant-ph

TL;DR: 本研究提出了一种名为VQE-PDFT的量子-经典混合方法，用于精确计算强关联电子系统。该方法在生物系统（如ErCRY4蛋白）中的应用取得了与实验相符的结果，证明了其在生物量子计算方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以精确计算强关联电子系统，因为需要同时处理静态和动态相关性。本研究旨在开发一种新的混合方法来解决这一挑战。

Method: 提出了一种结合变分量子本征求解器（VQE）和多构型对密度泛函理论（MC-PDFT）的量子-经典混合框架VQE-PDFT。该框架使用量子电路表示多构型波函数，并利用密度泛函评估相关能，以准确处理静态和动态相关性，同时降低量子资源需求。此外，还开发了浅层硬件高效ansatz电路，并将其集成到QM/MM多尺度架构中，用于复杂生物系统。

Result: VQE-PDFT在电荷转移数据集上的基准测试结果与传统MC-PDFT相当。将其应用于欧洲知更鸟隐色素蛋白ErCRY4的电子转移，计算出的转移速率与实验测量值吻合良好。

Conclusion: VQE-PDFT框架在量子计算硬件上成功应用于生物系统，计算出的电子转移速率与实验结果一致，证明了其在生物量子计算领域的实际可行性。

Abstract: Accurate calculation of strongly correlated electronic systems requires
proper treatment of both static and dynamic correlations, which remains
challenging for conventional methods. To address this, we present VQE-PDFT, a
quantum-classical hybrid framework that integrates variational quantum
eigensolver with multiconfiguration pair-density functional theory (MC-PDFT).
This framework strategically employs quantum circuits for multiconfigurational
wavefunction representation while utilizing density functionals for correlation
energy evaluation. The hybrid strategy maintains accurate treatment of static
and dynamic correlations while reducing quantum resource requirements.
Benchmark validation on the Charge-Transfer dataset confirmed that VQE-PDFT
achieves results comparable to conventional MC-PDFT. Building upon this, we
developed shallow-depth hardware-efficient ansatz circuits and integrated them
into a QM/MM multiscale architecture to enable applications in complex
biological systems. This extended framework, when applied to electron transfer
in the European robin cryptochrome protein ErCRY4, yielded transfer rates that
align well with experimental measurements. Importantly, successful execution on
actual quantum hardware demonstrates practical feasibility for biological
quantum computing applications, supported by comprehensive error analysis.

</details>


### [824] [Universally Robust Control of Open Quantum Systems](https://arxiv.org/abs/2508.07379)
*Lixiang Ding,Jingtao Fan,Xingze Qiu*

Main category: quant-ph

TL;DR: 提出一种噪声无关的量子控制框架，通过调整系统-环境耦合，在无先验噪声知识的情况下，实现高保真度操作，并在不同平台上得到验证。


<details>
  <summary>Details</summary>
Motivation:  Mitigating noise-induced decoherence is the central challenge in controlling open quantum systems. 现有的鲁棒协议通常需要精确的噪声模型，而本研究旨在提供一种通用的、不依赖噪声模型的量子控制框架。

Method: 提出一个基于控制驱动调整系统-环境耦合的通用框架，以实现噪声无关的量子控制。

Result: 通过量子态转移和门操作的数值验证，在各种噪声环境下实现了近乎统一的保真度（>99%），与仅以目标为导向的方法相比，误差抑制能力提高了几个数量级。

Conclusion: 该框架为实现容错量子技术提供了硬件无关的途径，适用于超导电路、离子阱和固态量子比特等多种平台。

Abstract: Mitigating noise-induced decoherence is the central challenge in controlling
open quantum systems. While existing robust protocols often require precise
noise models, we introduce a universal framework for noise-agnostic quantum
control that achieves high-fidelity operations without prior environmental
noise characterization. This framework capitalizes on the dynamical
modification of the system-environment coupling through control drives, an
effect rigorously encoded in the dynamical equation. Since the derived noise
sensitivity metric remains independent of the coupling details between the
system and the environment, our protocol demonstrates provable robustness
against arbitrary Markovian noises. Numerical validation through quantum state
transfer and gate operations reveals near-unity fidelity ($>\!99\%$) across
diverse noise regimes, achieving orders-of-magnitude error suppression compared
to target-only approaches. This framework bridges critical gaps between
theoretical control design and experimental constraints, establishing a
hardware-agnostic pathway toward fault-tolerant quantum technologies across
platforms such as superconducting circuits, trapped ions, and solid-state
qubits.

</details>


### [825] [Quanutm-State Texture as a Resource: Measures and Nonclassical Interdependencies](https://arxiv.org/abs/2508.07481)
*Yuntao Cui,Zhaobing Fan,Sunho Kim*

Main category: quant-ph

TL;DR: 本研究提出了新的量子态纹理度量方法，并探讨了其在量子态转变和与其他量子资源（如相干性）关系方面的应用。


<details>
  <summary>Details</summary>
Motivation: 量子态纹理作为一种新兴的量子资源，在量子理论发展中受到关注。本研究旨在探讨量子态纹理资源理论的核心问题，包括度量、状态转变和与其他量子资源的关系，以丰富该领域的理论框架。

Method: 本研究首先提出两种新的量子态纹理度量，并采用凸集合函数方法构建了量子态纹理度量函数。随后，研究给出了在自由操作下量子态的最大转变概率。最后，建立了量子态纹理与其他量子资源（相干性、虚部、可预测性）之间的关系。

Result: 研究提出了两种新的量子态纹理度量，并通过凸集合函数方法给出了构造量子态纹理度量函数的具体形式。此外，研究还给出了通过自由操作实现量子态转变的最大概率，并建立了量子态纹理与相干性、虚部和可预测性等其他量子资源之间的联系。

Conclusion: 本研究对量子态纹理资源理论进行了探讨，包括其度量、在自由操作下的状态转变以及与其他量子资源（如相干性、虚部和可预测性）的关系。研究提出了两种新的量子态纹理度量，并通过凸集合函数方法给出了构造量子态纹理度量函数的具体形式，同时阐述了通过自由操作实现量子态转变的最大概率，并建立了量子态纹理与其他量子资源之间的联系。

Abstract: Quantum-state texture is a newly recognized quantum resource that has
garnered attention with the advancement of quantum theory. In this work, we
discuss several main tasks concerning quantum-state texture resource theory,
including quantum-state texture measure, quantum state transformation under
free operations, and relations between quantum resources. We first provide two
new quantum-state texture measures and propose specific form of function for
constructing quantum-state texture measures through a convex roof method. Then,
we present the maximal probability of quantum state transformation through free
operations. Lastly, we establish relationships between quantum-state texture
and other highly regarded quantum resources, such as coherence, imaginary, and
predictability. Our research complements the measure theory of quantum-state
texture and enriches the theory framework of quantum-state texture resource.

</details>


### [826] [PHIP Sequences and Dipolar Fields](https://arxiv.org/abs/2508.07488)
*Martin C. Korzeczek,Ilai Schwartz,Martin B. Plenio*

Main category: quant-ph

TL;DR: 本研究提出了一种新的理论框架和控制序列，用于解决Para-氢诱导极化（PHIP）在实际应用中遇到的B0/B1不均匀性和偶极场问题，旨在提高超极化效率，尤其是在高浓度液态核磁共振样品中。


<details>
  <summary>Details</summary>
Motivation: Para-氢诱导极化（PHIP）虽然能有效地实现核自旋的超极化，但在实际的B0/B1不均匀性和高浓度样品的偶极场下，极化转移效率会显著降低。因此，需要开发能够克服这些挑战的控制序列。

Method: 本研究结合了平均哈密顿量理论和详细的数值模拟，提出并表征了广泛的转移序列，包括偶极场调整和偶极场抑制方案。

Result: 研究确定了偶极相互作用是阻碍还是稳定极化转移的条件，具体取决于序列结构。研究结果为在实际实验约束下选择和设计PHIP转移序列提供了实用指导。

Conclusion: 本研究提出了旨在缓解由偶极场、B0/B1不均匀性和适中化学位移引起的有害影响的脉冲和连续波（CW）控制序列的理论框架和综合分析。研究结果为在实际实验条件下选择和设计PHIP转移序列提供了实用指导，并为在浓缩液态核磁共振样品中实现稳健的超极化开辟了道路。

Abstract: Para-hydrogen induced polarization (PHIP) achieves efficient
hyperpolarisation of nuclear spins with the transfer of the singlet order of
parahydrogen to target molecules through catalytic hydrogenation reactions and
subsequent coherent control of the spin dynamics. However, in realistic
conditions B0/B1 inhomogeneities lead to significant reduction in the
polarization transfer efficiency. Moreover, in high-concentration samples,
dipolar fields arising from the magnetisation of the sample can degrade
polarisation transfer efficiency significantly. In this work, we present a
theoretical framework and a comprehensive analysis of both pulsed and
continuous-wave (CW) control sequences designed to mitigate the detrimental
effects of dipolar fields, $B_0/B_1$ inhomogeneities, and moderate chemical
shifts. By combining tools from average Hamiltonian theory with detailed
numerical simulations, we introduce and characterise a wide range of transfer
sequences, including dipolar-field adjusted and dipolar-field suppressing
protocols. We identify conditions under which dipolar interactions either
hinder or, perhaps surprisingly, stabilise polarization transfer, depending on
the sequence structure. Our results offer practical guidance for the selection
and design of PHIP transfer sequences under realistic experimental constraints
and open pathways toward robust hyperpolarisation in concentrated liquid-state
NMR samples.

</details>


### [827] [Information Transport in Classic-Quantum Hybrid System](https://arxiv.org/abs/2508.07870)
*Julian Rapp,Radhika H. Joshi,Alwin van Steensel,Yuli V. Nazarov,Mohammad H. Ansari*

Main category: quant-ph

TL;DR: 本研究将多副本方法扩展到强耦合区域，通过多副本主方程实现了熵流等非线性量的直接评估，并发现量子相干性和杂化共同作用会抑制熵转移，从而为设计更优的量子硬件提供了新方向。


<details>
  <summary>Details</summary>
Motivation: 由于密度矩阵的非线性函数，如熵和纠缠，不能表示为算子可观测量，因此标准的开放系统方法只能演化密度矩阵的单个副本，这使得追踪这些量的动力学成为不可能。先前由部分作者提出的形式主义通过演化多个虚拟副本解决了这个挑战，但仅限于弱耦合区域。

Method: 我们提出了一种多副本主方程，该方程能够直接评估强杂交量子-经典系统中的熵流和相关指标。

Result: 我们的结果表明，量子相干性和杂化共同抑制了净熵转移，形成了热力学瓶颈。

Conclusion: 本框架为研究熵动力学和设计更鲁棒、资源高效的量子硬件提供了通用工具。

Abstract: Many important quantities in quantum information science, such as entropy and
entanglement, are non-linear functions of the density matrix and cannot be
expressed as operator observables. Standard open-system approaches evolve only
a single copy of the density matrix, making it impossible to track the dynamics
of such quantities. A formalism proposed by some of the present authors
addressed this challenge by evolving multiple virtual replicas, but was limited
to the weak-coupling regime. Here, we extend this approach to strong coupling
between a quantum system and classical environments. The resulting
multi-replica master equation enables direct evaluation of entropy flow and
related metrics in strongly hybridized quantum-classical systems. Our results
show that quantum coherence and hybridization jointly suppress net entropy
transfer, creating a thermodynamic bottleneck. This framework provides a
general tool for studying entropy dynamics and guiding the design of more
robust, resource-efficient quantum hardware.

</details>


### [828] [A Method for Constructing Quasi-Random Peaked Quantum Circuits](https://arxiv.org/abs/2508.07491)
*O. G. Udalov*

Main category: quant-ph

TL;DR: 提出了一种构建“峰值”量子电路的算法，该电路的最终状态高度集中于特定比特串，并提出了一种隐藏该比特串的技术。MPS方法在模拟浅层电路方面效果较好。


<details>
  <summary>Details</summary>
Motivation: 提出算法以构建最终量子比特状态在特定计算基态上具有高概率集中度的“峰值”量子电路，并能隐藏最终比特字符串。

Method: 提出了一种构建准随机“峰值”量子电路的算法，该电路由砖墙结构中的随机门组成。提出了一种隐藏最终比特字符串的技术。

Result: 算法能够精确控制最终峰值状态的概率，改进算法可用于构建双峰或多峰量子电路。MPS方法对于模拟浅层峰值电路有效，但对于更深层的电路没有显著优势。

Conclusion: 该算法能够构建具有高概率集中在特定计算基态的“峰值”量子电路，并允许精确控制最终峰值状态的概率。改进算法可用于构建双峰或多峰量子电路。

Abstract: An algorithm is proposed for constructing quasi-random "peaked" quantum
circuits, i.e., circuits whose final qubit state exhibits a high probability
concentration on a specific computational basis state. These circuits consist
of random gates arranged in a brick-wall architecture. While the multiqubit
state in the middle of the circuit can exhibit significant entanglement, the
final state is, with high probability, a predetermined pure bitstring. A
technique is introduced to obscure the final bitstring in the structure of the
quantum circuit. The algorithm allows precise control over the probability of
the final peaked state. A modified version of the algorithm enables the
construction of double- or multi-peaked quantum circuits. The matrix product
state (MPS) method is evaluated for simulating such circuits; it performs
effectively for shallow peaked circuits but offers no significant advantage for
deeper ones.

</details>


### [829] [Graded Quantum Codes: From Weighted Algebraic Geometry to Homological Chain Complexes](https://arxiv.org/abs/2508.07542)
*Tony Shaska*

Main category: quant-ph

TL;DR: 本文介绍了渐进量子码，统一了两种量子纠错码，得到了新的界，并在密码学、量子计算和优化中有潜在应用。


<details>
  <summary>Details</summary>
Motivation: 统一量子加权AG码和同源量子码，并探索其在密码学、容错量子计算和优化中的应用。

Method: 通过引入加权次数和奇点，并利用链复形和同调代数，构建了具有改进性能的量子纠错码。

Result: 提出了渐进量子码，得到了改进的单例界，并通过实例验证了其有效性。

Conclusion: 本文提出了新的量子纠错码“渐进量子码”，统一了量子加权代数几何码和链复形码。

Abstract: We introduce graded quantum codes, unifying two classes of quantum
error-correcting codes. The first, quantum weighted algebraic geometry (AG)
codes, derives from rational points on hypersurfaces in weighted projective
spaces over finite fields. This extends classical AG codes by adding weighted
degrees and singularities, enabling self-orthogonal codes via the CSS method
with improved distances using algebraic structures and invariants like weighted
heights.The second class arises from chain complexes of graded vector spaces,
generalizing homological quantum codes to include torsion and multiple
gradings. This produces low-density parity-check codes with parameters based on
homology ranks, including examples from knot invariants and quantum rotors.
  A shared grading leads to a refined Singleton bound: $d \leq \frac{n - k +
2}{2} - \frac{\epsilon}{2}$, where $\epsilon > 0$ reflects entropy adjustments
from geometric singularities and defects. The bound holds partially for simple
orbifolds and is supported by examples over small fields.
  Applications include post-quantum cryptography, fault-tolerant quantum
computing, and optimization via graded neural networks, linking algebraic
geometry, homological algebra, and quantum information.

</details>


### [830] [Observation of Metal-Insulator and Spectral Phase Transitions in Aubry-André-Harper Models](https://arxiv.org/abs/2508.08255)
*Quan Lin,Christopher Cedzich,Qi Zhou,Peng Xue*

Main category: quant-ph

TL;DR: 本研究首次通过单光子量子行走实验实现了幺正近 Mathieu 算符（UAMO），探索了非厄米 Aubry-André-Harper（AAH）模型中的相变，揭示了局域化、对称性破缺和拓扑之间的联系。


<details>
  <summary>Details</summary>
Motivation: 为了克服在实验中实现受控非厄米性的复杂性，探索 Aubry-André-Harper（AAH）模型中由拟周期性和非厄米性相互作用引起的丰富相变。

Method: 利用单光子量子行走实验实现了幺正近 Mathieu 算符（UAMO），模拟了 Aubry-André-Harper（AAH）模型。

Result: 实验探索了AAH模型的相图，在厄米极限下展示了局域化和非局域化区域之间的相变。通过引入非互易跳变，探测了由准能量复数出现的 the parity-time (PT) 对称性破缺相变。此外，还识别了一种仅存在于离散时间系统中的新型谱相变，其中所有准能量变为纯虚数。这两种相变均与谱缠绕数的变化相关。

Conclusion: 该研究阐明了非厄米系统中的局域化、对称性破缺和拓扑之间的相互作用，为未来合成量子物质的探索铺平了道路。

Abstract: Non-Hermitian extensions of the Aubry-Andr\'e-Harper (AAH) model reveal a
rich variety of phase transitions arising from the interplay of
quasiperiodicity and non-Hermiticity. Despite their theoretical significance,
experimental explorations remain challenging due to complexities in realizing
controlled non-Hermiticity. Here, we present the first experimental realization
of the unitary almost-Mathieu operator (UAMO) which simulates the AAH model by
employing single-photon quantum walks. Through precise control of
quasiperiodicity, we systematically explore the phase diagram displaying a
phase transition between localized and delocalized regimes in the Hermitian
limit. Subsequently, by introducing non-reciprocal hopping, we experimentally
probe the parity-time (PT) symmetry-breaking transition that is characterized
by the emergence of complex quasienergies. Moreover, we identify a novel
spectral transition exclusive to discrete-time settings, where all
quasienergies become purely imaginary. Both transitions are connected to
changes in the spectral winding number, demonstrating their topological
origins. These results clarify the interplay between localization, symmetry
breaking, and topology in non-Hermitian quasicrystals, paving the way for
future exploration of synthetic quantum matter.

</details>


### [831] [Error-Resilient Fast Entangling Gates for Scalable Ion-Trap Quantum Processors](https://arxiv.org/abs/2508.07593)
*Isabelle Savill-Brown,Zain Mehdi,Alexander K. Ratcliffe,Varun D. Vaidya,Haonan Liu,Simon A. Haine,C. Ricardo Viteri,Joseph J. Hope*

Main category: quant-ph

TL;DR: 提出了一种新的量子门方案，该方案通过机器学习优化，可以实现高保真度的快速双量子比特门操作，并对实验误差具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有快速门方案中由单量子比特跃迁误差引起的限制，这些误差限制了高保真度解决方案中的脉冲总数。

Method: 提出了一种改进的门搜索方案，该方案结合了多目标机器学习设计方法，并考虑了主要的误差源。通过对脉冲序列施加对称性，消除了对激光相位噪声的敏感性，并简化了对离子晶体状态相关运动的多模控制。允许在门演化过程中出现未配对脉冲。

Result: 实现了可在包含数十个离子的链中进行局部和非局部双量子比特门操作的协议，保真度接近99.9%。

Conclusion: 通过对实验误差的全面分析，证明了在长达50个离子的线性离子阱处理器中，在任意离子对之间执行微秒级双量子比特门的可能性，保真度接近99.9%。

Abstract: Non-adiabatic two-qubit gate proposals for trapped-ion systems offer superior
performance and flexibility over adiabatic schemes at the cost of increased
laser control requirements. Existing fast gate schemes are limited by
single-qubit transition errors, which constrain the total number of pulses in
high-fidelity solutions. We introduce an improved gate search scheme that
enables both local and non-local two-qubit gates in chains containing tens of
ions. These protocols use a multi-objective machine design approach that
incorporates dominant sources of error in the design to ensure the solutions
are compatible with existing fast laser controls. We also generalize previous
schemes by allowing for unpaired pulses during the gate evolution. By imposing
symmetries on the pulse sequences, we eliminate susceptibility to laser phase
noise and further simplify the multi-mode control over the state-dependent
motion of the ion crystal. We perform a comprehensive analysis of expected gate
performance in the presence of random and systematic experimental errors to
demonstrate the feasibility of performing microsecond two-qubit gates between
arbitrary ion pairs in current linear ion-trap processors of up to $50$ ions
with fidelities approaching $99.9\%$.

</details>


### [832] [Tomography-assisted noisy quantum circuit simulator using matrix product density operators](https://arxiv.org/abs/2508.07610)
*Wei-guo Ma,Yun-Hao Shi,Kai Xu,Heng Fan*

Main category: quant-ph

TL;DR: 本研究提出了一种结合量子过程层析（QPT）和矩阵乘积密度算子（MPDO）的新型模拟器，用于模拟真实NISQ设备上的复杂噪声。研究结果为理解和应对这些噪声提供了重要见解，有助于改进量子算法的设计和评估。


<details>
  <summary>Details</summary>
Motivation: 解决真实噪声中等规模量子（NISQ）设备上的复杂噪声问题，这些噪声包含不可控因素和特定仪器效应（如串扰），而现有的基于理想噪声假设的张量网络模拟器（特别是MPDO）无法满足需求。

Method: 利用量子过程层析（QPT）技术捕捉实验噪声特性，并将其集成到矩阵乘积密度算子（MPDO）框架的数值模拟中。

Result: 开发了MPDO辅助模拟器，并将其应用于探索生成噪声纠缠态的变分方法，与标准噪声模拟和Quafu云量子计算平台上的演示进行了比较。研究了噪声MaxCut问题以及串扰和噪声截断的影响。结果为理解噪声在NISQ设备上的影响提供了宝贵的见解，并为在复杂噪声环境中设计和评估量子算法奠定了基础。

Conclusion: 本研究将量子过程层析（QPT）技术与矩阵乘积密度算子（MPDO）相结合，开发了一种能够直接捕捉实验设备运行特性并将其集成到数值模拟中的MPDO辅助模拟器，以解决真实噪声中等规模量子（NISQ）设备上的复杂噪声问题。该模拟器应用于探索生成噪声纠缠态的变分方法，并研究了噪声MaxCut问题以及串扰和噪声截断的影响。结果为理解噪声在NISQ设备上的影响提供了宝贵的见解，并为在复杂噪声环境中设计和评估量子算法奠定了基础。

Abstract: In recent years, efficient quantum circuit simulations incorporating ideal
noise assumptions have relied on tensor network simulators, particularly
leveraging the matrix product density operator (MPDO) framework. However,
experiments on real noisy intermediate-scale quantum (NISQ) devices often
involve complex noise profiles, encompassing uncontrollable elements and
instrument-specific effects such as crosstalk. To address these challenges, we
employ quantum process tomography (QPT) techniques to directly capture the
operational characteristics of the experimental setup and integrate them into
numerical simulations using MPDOs. Our QPT-assisted MPDO simulator is then
applied to explore a variational approach for generating noisy entangled
states, comparing the results with standard noise numerical simulations and
demonstrations conducted on the Quafu cloud quantum computation platform.
Additionally, we investigate noisy MaxCut problems, as well as the effects of
crosstalk and noise truncation. Our results provide valuable insights into the
impact of noise on NISQ devices and lay the foundation for enhanced design and
assessment of quantum algorithms in complex noise environments.

</details>


### [833] [Obfuscated Quantum and Post-Quantum Cryptography](https://arxiv.org/abs/2508.07635)
*Anju Rani,Xiaoyu Ai,Aman Gupta,Ravi Singh Adhikari,Robert Malaney*

Main category: quant-ph

TL;DR: 提出了一种结合QKD和PQC的新型通信系统，通过动态模糊化和量子同步协议增强了安全性，并证明其在实时性与低开销方面优于标准QKD系统。


<details>
  <summary>Details</summary>
Motivation: 为了提高通信系统的安全性，应对实际部署中存在的各种威胁。

Method: 提出了一种结合量子密钥分发（QKD）和后量子密码学（PQC）的新设计，并进行了实验部署。该系统的创新之处在于动态模糊化QKD-PQC操作序列、操作次数以及相关参数，并集成了无GPS量子同步协议。

Result: 实验结果表明，该QKD-PQC系统能够实时运行，且由于新的安全特性而产生的额外开销很小。与标准QKD系统相比，该设计提供了更强的安全性。

Conclusion: 该设计代表了目前最安全、可适应性最强的通信系统之一，能够抵御广泛的实际攻击。

Abstract: In this work, we present an experimental deployment of a new design for
combined quantum key distribution (QKD) and post-quantum cryptography (PQC).
Novel to our system is the dynamic obfuscation of the QKD-PQC sequence of
operations, the number of operations, and parameters related to the operations;
coupled to the integration of a GPS-free quantum synchronization protocol
within the QKD process. We compare the performance and overhead of our QKD-PQC
system relative to a standard QKD system with one-time pad encryption,
demonstrating that our design can operate in real time with little additional
overhead caused by the new security features. Since our system can offer
additional defensive strategies against a wide spectrum of practical attacks
that undermine deployed QKD, PQC, and certain combinations of these two
primitives, we suggest that our design represents one of the most secure
communication systems currently available. Given the dynamic nature of its
obfuscation attributes, our new system can also be adapted in the field to
defeat yet-to-be-discovered practical attacks.

</details>


### [834] [Estimating classical mutual information between quantum subsystems with neural networks](https://arxiv.org/abs/2508.07652)
*D. A. Konyshev,V. V. Mazurenko*

Main category: quant-ph

TL;DR: Neural networks can estimate quantum system information from limited measurements, successfully applied to the quantum Ising model's phase diagram.


<details>
  <summary>Details</summary>
Motivation: Estimating information-entropy-based quantities like classical mutual information typically requires complete statistics. This work investigates the potential of neural networks to perform such estimations with limited data.

Method: The study explores reconstructing classical mutual information and specific entropy of a quantum system using a neural network approach with limited projective measurements.

Result: The neural network approach effectively estimates classical mutual information even for paramagnetic wave functions. It also successfully reconstructs the phase diagram of the quantum Ising model, differentiating various disordered states.

Conclusion: The neural network approach provides reliable estimates of classical mutual information, even for delocalized paramagnetic wave functions. The phase diagram of the quantum Ising model, with a focus on distinguishing disordered states, can be reconstructed.

Abstract: Characterizing correlations in a quantum system on the basis of the results
of the projective measurements can be performed with different means including
the calculation of the classical mutual information. Generally, estimating such
information-entropy-based quantities requires having complete statistics of the
system's states. Here we explore the possibility to reconstruct the classical
mutual information and specific entropy of a quantum system with neural network
approach on the basis of limited number of projective measurements. As a
prominent example we consider the antiferromagnetic quantum Ising model in
transverse and longitudinal magnetic fields which is in demand in both
condensed matter physics and quantum computing. We show that the neural network
approach gives reliable estimates of the classical mutual information even in
the case of paramagnetic wave functions delocalized in the state space. In
addition, the phase diagram of the considered quantum system is reconstructed
with a special focus on discriminating various types of disordered states.

</details>


### [835] [Steady state properties of periodically driven quantum systems](https://arxiv.org/abs/2508.07674)
*Milan Šindelka,David Gelbwaser-Klimovsky*

Main category: quant-ph

TL;DR: 本研究使用Floquet散射理论分析了周期性驱动的开放量子系统，发现其非平衡定态（NESS）在高温下遵循玻尔兹曼定律，克服了以往研究的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有研究中对周期性驱动开放量子系统NESS表征的局限性（通常仅限于特定类型的驱动和玻恩-马尔可夫近似），本研究旨在探索更通用的方法。

Method: 利用Floquet散射理论框架，建立了约束NESS性质和跃迁率的Floquet热化条件，并研究了高温下NESS的结构。

Result: 1. 建立了适用于通用周期性驱动N能级量子系统的Floquet热化条件。2. 发现高温下NESS出人意料地遵循玻尔兹曼定律。3. 通过一个简单的玩具模型进行了数值计算，证明了理论的有效性。

Conclusion: 研究表明，在高温下，非平衡定态（NESS）出人意料地遵循玻尔兹曼定律，且适用于任何驱动。

Abstract: Periodic driving is used to steer physical systems to unique stationary
states or nonequilibrium steady states (NESS), producing enhanced properties
inaccessible to non-driven systems. For open quantum systems, characterizing
the NESS is challenging and existing results are generally limited to specific
types of driving and the Born-Markov approximation. Here we go beyond these
limits by studying a generic periodically driven $ N$-level quantum system
interacting with a low-density thermal gas. Exploiting the framework of Floquet
scattering theory, we establish general Floquet thermalization conditions
constraining the nature of the NESS and the transition rates. Moreover, we
examine theoretically the structure of the NESS at high temperatures, and find
out that the NESS complies, rather surprisingly, with the Boltzmann law for any
driving. Numerical calculations illustrate our theoretical elaborations for a
simple toy model.

</details>


### [836] [Observation and Modulation of the Quantum Mpemba Effect on a Superconducting Quantum Processor](https://arxiv.org/abs/2508.07707)
*Yueshan Xu,Cai-Ping Fang,Bing-Jie Chen,Ming-Chuan Wang,Zi-Yong Ge,Yun-Hao Shi,Yu Liu,Cheng-Lin Deng,Kui Zhao,Zheng-He Liu,Tian-Ming Li,Hao Li,Ziting Wang,Gui-Han Liang,Da'er Feng,Xueyi Guo,Xu-Yang Gu,Yang He,Hao-Tian Liu,Zheng-Yang Mei,Yongxi Xiao,Yu Yan,Yi-Han Yu,Wei-Ping Yuan,Jia-Chi Zhang,Zheng-An Wang,Gangqin Liu,Xiaohui Song,Ye Tian,Yu-Ran Zhang,Shi-Xin Zhang,Kaixuan Huang,Zhongcheng Xiang,Dongning Zheng,Kai Xu,Heng Fan*

Main category: quant-ph

TL;DR: 超導平台實現了量子姆潘巴效應（QME）的多維調製，揭示了耦合、勢和初始態對QME的影響，並為量子信息應用開闢了新途徑。


<details>
  <summary>Details</summary>
Motivation: 儘管理論上對量子姆潘巴效應（QME）的研究日益增多，但其實驗研究，特別是其多維調製方面仍然有限。本研究旨在填補這一空白，通過實驗探索QME的調製機制。

Method: 利用超導處理器，通過調整耦合強度、局域勢和初始狀態，實現對量子多體系統的精確控制，並採用糾纏不對稱性（EA）作為探針來量化對稱性恢復。

Result: 在強短程耦合下觀察到了QME的存在，而在中程耦合下則抑制了QME。此外，通過引入局域線性勢或從傾斜鐵磁態進行猝滅，可以重新觀察到QME，後者對局域無序具有魯棒性。

Conclusion: 本研究首次在超導平台展示了量子姆潘巴效應（QME）的靈活調製，並通過控制多個參數來深入理解非平衡量子多體動力學。

Abstract: In non-equilibrium quantum many-body systems, the quantum Mpemba effect (QME)
emerges as a counterintuitive phenomenon: systems exhibiting greater initial
symmetry breaking restore symmetry faster than those with less. While
theoretical exploration of QME has surged, experimental studies on its
multidimensional modulation remain limited. Here, we report the observation and
control of QME using a superconducting processor featuring a unique fully
connected, tunable-coupling architecture that enables precise modulation from
short- to long-range interactions. This platform allows independent
manipulation of coupling regimes, on-site potentials, and initial states,
elucidating their roles in QME. To quantify symmetry restoration, we employ
entanglement asymmetry (EA) -- the relative entropy between a subsystem reduced
density matrix and its symmetric projection -- as a sensitive probe of symmetry
breaking. In strong short-range coupling regimes, EA crossovers during quenches
from tilted N\'{e}el states confirm the presence of QME. In contrast, in
intermediate coupling regimes, synchronized EA and entanglement entropy
dynamics reveal the suppression of QME. Remarkably, QME reemerges with the
introduction of on-site linear potentials or quenches from tilted ferromagnetic
states, the latter proving robust against on-site disorder. Our study provides
the first demonstration of flexible QME modulation on a superconducting
platform with multiple controllable parameters, shedding light on quantum
many-body non-equilibrium dynamics and opening avenues for quantum information
applications.

</details>


### [837] [Master Equation for Quantum Self-Organization of Atoms and Molecules in Cavities](https://arxiv.org/abs/2508.07853)
*Tom Schmit,Catalin-Mihai Halati,Tobias Donner,Giovanna Morigi,Simon B. Jäger*

Main category: quant-ph

TL;DR: 我们推导了一个有效的Lindblad主方程，用于描述腔内量子气体中粒子的运动动力学，该方程在光子数较大时也有效，并能捕捉从弱到强相互作用的动力学。


<details>
  <summary>Details</summary>
Motivation: 为了控制腔内量子气体中相互作用系统的非平衡动力学，需要对作用机制有详细的了解。然而，由于自由度的数量，有效的理论模型通常在特定极限下工作。

Method: 我们推导了一个有效的Lindblad主方程，用于描述仅限于可极化粒子（如原子或分子）的运动变量的动力学，这些粒子与腔场呈色散耦合。该主方程即使在腔内光子数相对较大的情况下也有效。

Result: 我们通过表明该理论能够捕捉从多普勒冷却到超冷状态的宽温度区间以及从弱到强腔介导相互作用的动力学，从而验证了该理论描述。

Conclusion: 该理论为腔内量子气体的动力学描述提供了一个强大的框架，并允许将统计力学的模型和假设与多功能的实验平台联系起来。

Abstract: Quantum gases of atoms and molecules in optical cavities offer a formidable
laboratory for studying the out-of-equilibrium dynamics of long-range
interacting systems. Multiple scattering of cavity photons mediate
interactions, and the emerging phases of matter are determined by the interplay
of photon-mediated forces, dissipation, and quantum and thermal fluctuations.
Control of these dynamics requires a detailed understanding of the mechanisms
at play. Due to the number of degrees of freedom, however, effective
theoretical models often work in specific limits, where either the cavity field
is treated as a semiclassical variable or the cavity state is a slightly
perturbed vacuum state. In this work, we present the derivation of an effective
Lindblad master equation for the dynamics of the sole motional variables of
polarizable particles, such as atoms or molecules, that dispersively couple to
the cavity field. The master equation is valid even for relatively large
intracavity photon numbers, and is apt to study both the steady-state regime
and the out-of-equilibrium dynamics where quantum fluctuations of the field
seed the onset of macroscopic coherences. We validate the theoretical
description by showing that it captures the dynamics across a wide temperature
interval, from Doppler cooling down to the ultra-cold regime, and from weak to
strong cavity-mediated interactions. Our theory provides a powerful framework
for the description of the dynamics of quantum gases in cavities and permits,
amongst others, to connect models and hypotheses of statistical mechanics with
a versatile experimental platform.

</details>


### [838] [Scheduling of syndrome measurements with a few ancillary qubits](https://arxiv.org/abs/2508.07913)
*Shintaro Sato,Yasunari Suzuki*

Main category: quant-ph

TL;DR: 通过使用更少的辅助量子比特，可以减少逻辑错误率。


<details>
  <summary>Details</summary>
Motivation: 量子纠错码需要数据量子比特来编码量子信息和用于获取错误校正的错误综合的辅助量子比特。大量辅助量子比特的需求是量子计算特有的开销，它阻碍了量子计算向有用规模的扩展。

Method: 提出了一种生成高效的 CSS 码的综合测量电路的框架，并提出了一种在通用设置中最小化物理量子比特总数的方法。

Result: 将所提出的方法应用于表面码，并在总量子比特数的约束下生成了综合测量电路。

Conclusion: 与量子比特总数固定的情况相比，平衡的数据和辅助量子比特计数可以在较低的逻辑错误率下实现。

Abstract: Quantum error-correcting codes are a vital technology for demonstrating
reliable quantum computation. They require data qubits for encoding quantum
information and ancillary qubits for taking error syndromes necessary for error
correction. The need for a large number of ancillary qubits is an overhead
specific to quantum computing, and it prevents the scaling of quantum computers
to a useful size. In this work, we propose a framework for generating efficient
syndrome measurement circuits with a few ancillary qubits in CSS codes and
provide a method to minimize the total number of physical qubits in general
settings. We demonstrated our proposal by applying it to surface codes, and we
generated syndrome measurement circuits under several constraints of total
qubit count. As a result, we find that balanced data and ancillary qubit counts
achieve the lower logical error rates under a fixed total number of physical
qubits. This result indicates that using fewer ancillary qubits than the number
of stabilizers can be effective for reducing logical error rates in a practical
noise model.

</details>


### [839] [Calculating the Projective Norm of higher-order tensors using a gradient descent algorithm](https://arxiv.org/abs/2508.07933)
*Aaditya Rudra,Maria Anastasia Jivulescu*

Main category: quant-ph

TL;DR: 提出了一种梯度下降算法来估计高阶张量的射影范数，解决了计算复杂性问题，并应用于对称张量和密度矩阵。


<details>
  <summary>Details</summary>
Motivation: 计算射影范数是NP难问题，对于高阶张量，参数空间呈指数增长，带来了计算挑战。

Method: 提出了一种新颖的梯度下降算法来估计高阶张量的射影范数。

Result: 通过计算纯态和混合态的核秩和射影范数，并提供数值证据，证明了该算法的性能。

Conclusion: 该算法保证收敛到给定张量最小核秩分解，并已成功应用于对称张量和密度矩阵。

Abstract: Projective Norms are a class of tensor norms that map on the input and output
spaces. These norms are useful for providing a measure of entanglement.
Calculating the projective norms is an NP-hard problem, which creates
challenges in computing due to the complexity of the exponentially growing
parameter space for higher-order tensors. We develop a novel gradient descent
algorithm to estimate the projective norm of higher-order tensors. The
algorithm guarantees convergence to a minimum nuclear rank decomposition of our
given tensor. We extend our algorithm to symmetric tensors and density
matrices. We demonstrate the performance of our algorithm by computing the
nuclear rank and the projective norm for both pure and mixed states and provide
numerical evidence for the same.

</details>


### [840] [Expanding a 4-qubit Dicke State a to 5-qubit Dicke State with Limited Qubit Access](https://arxiv.org/abs/2508.07977)
*Bibhuti Thapa,Oberon Moran,Duc-Kha Vu,Fatih Ozaydin*

Main category: quant-ph

TL;DR: 研究了一种在量子比特受限的情况下，制备和扩展狄克态的量子方法。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，直接控制所有量子比特往往受到限制，因此需要研究在受限控制下制备和扩展量子态的方法。

Method: 提出了一种制备四比特狄克态的有效方法，并设计了一个量子电路，在只访问部分比特的情况下，将四比特狄克态扩展到五比特狄克态。

Result: 成功制备了四比特狄克态，并通过提出的量子电路将其扩展到五比特狄克态，且该电路对噪声具有良好的鲁棒性。

Conclusion: 提出了一种在受限控制下将四比特狄克态扩展到五比特狄克态的量子电路，并进行了数值模拟和鲁棒性分析，证明了该电路在存在噪声的情况下仍然具有高保真度。

Abstract: In scenarios where full access to all qubits of a multipartite quantum system
is available and global operations can be implemented, the preparation of
arbitrary entangled states - including multipartite Dicke states - is
theoretically straightforward. However, practical constraints often limit
direct control over all qubits. In this work, we first present an efficient
method for preparing a four-qubit Dicke state, and then demonstrate how a
four-qubit Dicke state can be expanded to a five-qubit Dicke state even when
only a subset of qubits is accessible. We propose a quantum circuit that
achieves this transformation under restricted control, and support our
analytical derivation with numerical simulations. We further carry out a
robustness analysis of our circuit under imperfect gate implementations and
find that it retains high fidelity for experimentally relevant levels of
coherent over-rotation errors, confirming its resilience to realistic noise.

</details>


### [841] [$\bf A^2$-robust superradiant phase transition in hybrid qubit-cavity optomechanics](https://arxiv.org/abs/2508.08024)
*Gang Liu,Wei Xiong*

Main category: quant-ph

TL;DR: 通过混合量子系统（量子比特+机械模式+光学腔+辅助腔）克服了 A^2 项对超辐射相变（SPT）的限制，实现了可控的 SPT 观测，降低了实验门槛，并发现了声子的不同行为和高阶压缩可作为 SPT 的探测手段。


<details>
  <summary>Details</summary>
Motivation: 为了克服 A^2 项对在腔量子电动力学中实现超辐射相变（SPT）的根本性挑战。

Method: 提出了一种包含量子比特、机械模式和光学腔的混合量子系统。其中，量子比特和机械模式构成量子拉比模型，机械模式和光学腔构成光力学系统。通过引入一个辅助腔，该系统能够产生一个可切换的 A^2 项，用以抵消或消除原始系统中的 A^2 效应。

Result: 成功实现了在存在 A^2 项的情况下，通过混合量子系统（包含量子比特、机械模式和光学腔）进行可控的 SPT 观测。通过辅助腔抵消了 A^2 效应，降低了临界耦合强度，使得实验要求得以放宽。研究还发现，正常相的声子表现出聚束性，而超辐射相的声子则表现出相干性。在 SPT 点附近实现了高阶压缩，可作为探测 SPT 的手段。

Conclusion: 该研究提出了一种混合量子系统，可在存在 A^2 项的情况下实现超辐射相变（SPT），该系统通过引入辅助腔来抵消或消除 A^2 效应，从而实现可控的 SPT 观测，并通过分析声子的二阶等时关联函数 g^(2)(0) 进行诊断。此外，该系统能显著降低 SPT 的临界耦合强度，放宽了实验要求。研究还发现，正常相中的声子表现出聚束行为，而在超辐射相中则表现出相干性。在两个相中均观察到高阶压缩，并在 SPT 点附近实现了近乎完美的高阶压缩，可作为 SPT 的探测手段。该研究表明，混合光力学和腔量子电动力学是实现存在 A^2 项的 SPT 物理学的有前景的途径。

Abstract: The $\mathbf{A}^2$ term presents a fundamental challenge to realizing the
superradiant phase transition (SPT) in cavity quantum electrodynamics. Here, we
propose a hybrid quantum system enabling SPT regardless of the presence of the
$\mathbf{A}^2$ term. The system consisting of a qubit, a mechanical mode, and
an optical cavity, where the qubit and mechanical mode constitute a quantum
Rabi model, while the mechanical mode and cavity form an optomechanical system.
Crucially, the auxiliary cavity introduces a switchable $\mathbf{A}^2$ term
that effectively counteracts or even fully eliminates the original
$\mathbf{A}^2$ effect. This allows controllable observation of SPT, diagnosed
via the second-order equal-time correlation function $g^{(2)}(0)$ of phonons.
Furthermore, the auxiliary cavity exponentially reduces the critical coupling
strength, significantly relaxing experimental requirements. Besides, we show
that phonons in the normal phase are bunching, but coherent in the superradiant
phase. Interestly, higher-order squeezing is found in both phases, with
near-perfect higher-order squeezing achieved at SPT point, establishing it as a
probe for SPT behavior. Our work demonstrates that hybridizing optomechanics
and cavity quantum electrodynamics provides a promising route to accessing SPT
physics in the presence of the $\mathbf{A}^2$ term.

</details>


### [842] [Superresolution for two incoherent optical sources with arbitrary intensities in two dimensions](https://arxiv.org/abs/2508.08049)
*Junyan Li,Shengshi Pang*

Main category: quant-ph

TL;DR: 量子超分辨率技术在距离估计上超越了瑞利判据，但在方位角估计上存在局限性。


<details>
  <summary>Details</summary>
Motivation: 现有技术在区分两个点源的距离上存在局限性，尤其是在二维光学系统中，距离估计的精度上限仍然未知。

Method: 利用多参数量子估计理论，研究了二维成像系统中估计两个不相干点源之间距离的精度。

Result: 推导了距离估计的最终精度，即使在距离趋近于零时也保持非零，超越了瑞利判据。研究发现，通过优化点源的相对方位角可以提高距离估计的精度。然而，方位角估计的精度随距离二次方衰减，表明在点源非常接近时，方位角无法被解析，这是量子超分辨率技术无法克服的。

Conclusion: 虽然量子超分辨率技术可以打破瑞利判据的限制，但方位角估计的精度随距离二次方衰减，当两个点源足够接近时，方位角将无法分辨，这是多维量子成像中固有的局限性。

Abstract: The Rayleigh criterion has long served as a fundamental limit for the
resolution of classical optical imaging. However, recent advances in quantum
metrology have led to the quantum superresolution technique that can break
Rayleigh's curse and estimate the separation between a pair of incoherent point
sources with nonvanishing precision. For two-dimensional optical systems, the
precision limit of estimating the whole separation, i.e., the distance, between
two point sources remains unknown so far. In this paper, we investigate the
estimation precision of the distance between two incoherent point sources with
arbitrary intensities in a two-dimensional imaging system. Through the
multiparameter quantum estimation theory, we obtain the ultimate estimation
precision of the distance and show that it remains nonzero when the distance
approaches zero, which surpasses the Rayleigh criterion. We further show that
the precision can be enhanced by aligning the two point sources along specific
directions if the point-spread functions of the two sources are not circularly
symmetric, and find the optimial relative azimuth between the two point sources
and the highest estimation precision of the distance. In addition to the
distance estimation, we also consider the quantum estimation of the relative
azimuth between two incoherent point sources. A surprising result is that the
precision limit of the azimuth decays quadratically with the distance, which
suggests that the azimuth cannot be resolved when the two point sources get
sufficiently close to each other and is therefore inaccessible by the quantum
superresolution technique in this case. This reveals a new and fundamental
limitation on the resolvability of two incoherent point sources in
multi-dimensional quantum imaging which cannot be addressed by optimizing the
quantum measurements.

</details>


### [843] [The role of Quantum Diffusion Flux in Super-Luminal Wave Packets](https://arxiv.org/abs/2508.08065)
*Charalampos Antonakos*

Main category: quant-ph

TL;DR: 本文介绍了Mita在量子流体力学中的数学，重点研究了扩散通量在波包演化中的作用，尤其是在超光速波包的情况下。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是介绍Mita在量子流体力学中提出的关键数学，并深入探讨扩散通量在波包演化中的作用，特别是在超光速波包的情况下。

Method: 本文首先简要回顾了Mita论文中的一些结果，通过分析高斯和孤子波包，然后将重点放在扩散在超光速波包演化中的作用。

Result: 本文分析了高斯和孤子波包，并重点研究了扩散在超光速波包演化中的作用。

Conclusion: 该论文主要讨论了Mita提出的在量子流体力学中起核心作用的数学，并分析了扩散通量在波包演化中的作用，重点关注了超光速波包的演化。

Abstract: In this short-length paper, we will present some math that play a central
role in quantum hydrodynamics and that were presented by Mita in the past. In
this formulation of QM, a quantity is involved which is called the diffusion
flux. As we will see, this quantity plays a crucial role on the evolution of
wave packets. More specifically, we will initially briefly explain some results
derived in Mita's papers, by analyzing Gaussian and soliton wave packets, while
our main focus is on the role of diffusion in the evolution of super-luminal
wave packets

</details>


### [844] [How Quantum Agents Can Change Which Strategies Are More Complex](https://arxiv.org/abs/2508.08092)
*Spiros Kechrimparis,Nix Barnett,Mile Gu,Hyukjoon Kwon*

Main category: quant-ph

TL;DR: 策略的复杂性取决于是否能处理量子信息；量子代理与经典代理可能对策略复杂性得出相反结论。


<details>
  <summary>Details</summary>
Motivation: 在复杂性科学中，记忆被用作复杂性的量化指标，但这种量化可能受到代理处理信息能力的限制，特别是量子信息处理能力。

Method: 通过推导充分条件并展示跨多个场景的现象来说明，在代理是否能够处理和存储量子信息的情况下，会得出关于策略复杂性的矛盾结论。

Result: 提出了一个信息论的下限，用于确定执行给定策略所需的最小记忆量，该下限适用于经典和量子代理。

Conclusion: 代理执行策略的复杂性评估取决于代理是否能够处理和存储量子信息。与经典代理不同，量子代理可能会得出相反的复杂性结论，这表明量子信息处理在理解和量化复杂性方面发挥着关键作用。

Abstract: Whether winning blackjack or navigating busy streets, achieving desired
outcomes requires agents to execute adaptive strategies, strategies where
actions depend contextually on past events. In complexity science, this
motivates memory as an operational quantifier of complexity: given two
strategies, the more complex one demands the agent to track more about the
past. Here, we show that conclusions about complexity fundamentally depend on
whether agents can process and store quantum information. Thus, while classical
agents might find Strategy A more complex to execute than Strategy B, quantum
agents can reach the opposite conclusion. We derive sufficient conditions for
such contradictory conclusions and illustrate the phenomenon across multiple
scenarios. As a byproduct, our results yield an information-theoretic lower
bound on the minimal memory required by any agent - classical or quantum - to
execute a given strategy.

</details>


### [845] [Handling fabrication defects in hex-grid surface codes](https://arxiv.org/abs/2508.08116)
*Oscar Higgott,Benjamin Anker,Matt McEwen,Dripto M. Debroy*

Main category: quant-ph

TL;DR: 六边形栅格表面码可以使用LUCI框架的扩展来处理损坏的量子比特和耦合器，从而为大规模量子纠错铺平道路。


<details>
  <summary>Details</summary>
Motivation: 为了在硬件中实现大规模量子纠错的六边形量子比特栅格，需要一种处理损坏的量子比特和耦合器的方法。

Method: 提出一种使用LUCI框架的扩展方法来处理六边形栅格表面码架构中的损坏量子比特和耦合器。

Result: 研究表明，对于孤立的损坏量子比特，电路距离减少一个；对于孤立的损坏耦合器，电路距离在一个或两个基中都减少一个。

Conclusion: 该研究提出的方法为在六边形量子比特栅格中处理损坏的量子比特和耦合器提供了可行的丢弃策略，消除了在实现大规模量子纠错的六边形量子比特栅格硬件方面的一个关键障碍。

Abstract: Recent work has shown that a hexagonal grid qubit layout, with only three
couplers per qubit, is sufficient to implement the surface code with
performance comparable to that of a traditional four-coupler layout [McEwen et
al., 2023]. In this work we propose a method for handling broken qubits and
couplers even in hex-grid surface code architectures, using an extension of the
LUCI framework [Debroy et al., 2024]. We show that for isolated broken qubits,
the circuit distance drops by one, while for isolated broken couplers, the
distance drops by one in one or both bases. By providing a viable dropout
strategy, we have removed a critical roadblock to the implementation of
hexagonal qubit grids in hardware for large-scale quantum error correction.

</details>


### [846] [Quantum Circuit Complexity of Matrix-Product Unitaries](https://arxiv.org/abs/2508.08160)
*Georgios Styliaris,Rahul Trivedi,J. Ignacio Cirac*

Main category: quant-ph

TL;DR: 本文研究了如何用量子电路实现矩阵乘积幺正算符(MPU)，并提出了一种多项式深度的量子电路实现方法，证明了其在保持纠缠和生成长程纠缠方面的潜力。


<details>
  <summary>Details</summary>
Motivation: MPU具有保持1D系统纠缠面积定律的特性，但如何实现MPU作为量子电路仍然未知。

Method: 通过明确构建一个量子电路来实现MPU。

Result: 所提出的量子电路深度为 T = O(N^α)，其中 α 仅取决于体和边界张量，而不取决于系统大小 N。该类MPU包含生成长程纠缠的非平凡酉算子，特别是包含一类由C*-弱Hopf代数表示构造的酉算子。此外，该构造也适用于非均匀平移变异MPU，其电路深度为O(N^β poly D)。

Conclusion: 本文表明，一类大的MPU可以通过多项式深度的量子电路实现，并明确构建了一个实现MPU的多项式深度量子电路。

Abstract: Matrix-product unitaries (MPUs) are many-body unitary operators that, as a
consequence of their tensor-network structure, preserve the entanglement area
law in 1D systems. However, it is unknown how to implement an MPU as a quantum
circuit since the individual tensors describing the MPU are not unitary. In
this paper, we show that a large class of MPUs can be implemented with a
polynomial-depth quantum circuit. For an $N$-site MPU built from a repeated
bulk tensor with open boundary, we explicitly construct a quantum circuit of
polynomial depth $T = O(N^{\alpha})$ realizing the MPU, where the constant
$\alpha$ depends only on the bulk and boundary tensor and not the system size
$N$. We show that this class includes nontrivial unitaries that generate
long-range entanglement and, in particular, contains a large class of unitaries
constructed from representations of $C^*$-weak Hopf algebras. Furthermore, we
also adapt our construction to nonuniform translationally-varying MPUs and show
that they can be implemented by a circuit of depth $O(N^{\beta} \,
\mathrm{poly}\, D)$ where $\beta \le 1 + \log_2 \sqrt{D}/ s_{\min}$, with $D$
being the bond dimension and $s_{\min}$ is the smallest nonzero Schmidt value
of the normalized Choi state corresponding to the MPU.

</details>


### [847] [Fast and efficient long-distance quantum state transfer in long-range spin-$\frac{1}{2}$ models](https://arxiv.org/abs/2508.08182)
*F. Faria,C. C. Nelmes,T. J. G. Apollaro,T. P. Spiller,I. D'Amico*

Main category: quant-ph

TL;DR: 通过对长自旋链进行微调（端点磁场和耦合修改），可以实现高效的量子态传输。


<details>
  <summary>Details</summary>
Motivation: 研究在长自旋链中超越最近邻耦合的量子态传输问题。

Method: 利用下一最近邻哈密顿量的色散关系性质，通过在两个端点处施加小的静磁场，并对少数几个端点处的耦合进行对称修改，实现了超过99%的平均传输保真度。所需时间与链长成正比。通过仔细设计的遗传算法找到端点处的耦合值，以将波包宽度约束在线性色散区域内。

Result: 在长自旋链中，通过在两个端点处施加小的静磁场并对称修改少数几个端点处的耦合，可以实现超过99%的平均传输保真度，且所需时间与链长成正比。

Conclusion: 该方案适用于任意下一最近邻耦合值，并且可以轻松应用于更长范围的耦合方案。

Abstract: Quantum state transfer is investigated beyond the nearest-neighbour coupling
scheme in long spin-$\frac{1}{2}$ linear chains. Exploiting the properties of
the next-nearest neighbour Hamiltonian's dispersion relation, it is shown that
with minimal engineering, i.e., an on-site magnetic field on the two end sites
and only a few symmetrically-modified end inter-site couplings, an average
transfer fidelity above $99\%$ can be achieved. To leading order, the required
time scales linearly with the length of the chain. Such a fast, high-quality
quantum state transfer is based on the ballistic propagation of the wave packet
centred in the linear region of the dispersion relation by means of the on-site
magnetic field. At the same time, the wave packet width, modulated by the
inter-site couplings at the chain ends, whose values are found via a carefully
designed genetic algorithm, is constrained mostly in the linear region of the
dispersion relation. Our coupling scheme is shown to hold for arbitrary values
of the next-nearest inter-site coupling and can be straightforwardly applied to
longer range coupling schemes.

</details>


### [848] [Characterization of syndrome-dependent logical noise in detector regions](https://arxiv.org/abs/2508.08188)
*Matthew Girling,Ben Criger,Cristina Cirstoiu*

Main category: quant-ph

TL;DR: 在 H1-1 离子阱设备上，开发了一种新的协议来表征量子纠错电路的噪声，并使用噪声定制和缓解策略改进了诊断测试。


<details>
  <summary>Details</summary>
Motivation: 为了在现实的硬件噪声下表征量子纠错电路的行为，需要了解逻辑错误率与综合结果的条件关系，以实现噪声感知解码和验证阈值相关的假设。

Method: 提出了一种新的协议，用于直接估计与由两个或多个综合提取装置组成的检测器区域相关的逻辑 Pauli 通道（以及纯错误），并以观察到的综合结果特定奇偶校验为条件。该方法具有 SPAM 鲁棒性，并且最适合基于标志的综合测量方案。实验数据的经典处理采用了贝叶斯建模方法。

Result: 在 Quantinuum H1-1 离子阱设备上，使用一个小型纠错码对新协议进行了验证，结果表明噪声定制和缓解策略可以显著改进用于容错的噪声诊断测试。

Conclusion: 该协议在 Quantinuum H1-1 离子阱设备上进行了验证，证明了通过使用已交换的测量、泄漏保护和 Pauli 帧随机化等噪声定制和缓解策略，可以显著改进用于容错的噪声诊断测试。

Abstract: Characterizing how quantum error correction circuits behave under realistic
hardware noise is essential for testing the premises that enable scalable fault
tolerance. Logical error rates conditioned on syndrome outcomes are needed to
enable noise-aware decoding and validate threshold-relevant assumptions. We
introduce a protocol to directly estimate the logical Pauli channels (and pure
errors) associated with detector regions formed of two or more syndrome
extraction gadgets, conditioned on observing a particular parity in the
syndrome outcomes. The method is SPAM-robust and most suitable for flag-based
syndrome measurement schemes. For classical processing of the experimental data
we implement a Bayesian modelling approach. We validate this new protocol on a
small error-detecting code using Quantinuum H1-1, a trapped-ion device, and
demonstrate that several noise diagnostic tests for fault tolerance improve
significantly when using noise tailoring and mitigation strategies, such as
swapped measurements for leakage protection, and Pauli frame randomization.

</details>


### [849] [Single-Shot Decoding and Fault-tolerant Gates with Trivariate Tricycle Codes](https://arxiv.org/abs/2508.08191)
*Abraham Jacob,Campbell McLauchlan,Dan E. Browne*

Main category: quant-ph

TL;DR: TT codes are new quantum error-correcting codes that are resource-efficient and fault-tolerant, outperforming the 3D toric code in several aspects like qubit usage and error correction thresholds.


<details>
  <summary>Details</summary>
Motivation: The motivation for this research is to develop quantum error-correcting codes that are not only resource-efficient (low-overhead) but also possess fault-tolerant features beyond mere resource efficiency. Specifically, the authors aim to create quantum codes that offer high thresholds under circuit-level noise, enable efficient decoding through partial single-shot decodability, and support a rich set of transversal gates and automorphisms for enhanced quantum computation capabilities.

Method: This paper introduces trivariate tricycle (TT) codes, a type of quantum low-density parity check (qLDPC) code. The codes are constructed using three trivariate polynomials and are based on a length-3 chain complex, with the 3D toric code being a specific instance. The research involves numerically searching for TT codes with improved parameters and constructing syndrome-extraction circuits to demonstrate their performance. The analysis includes evaluating thresholds under phenomenological and circuit-level noise models, as well as investigating the properties of transversal gates and automorphisms.

Result: The paper presents TT codes, which demonstrate high thresholds (0.3% in Z, 1% in X error channels under circuit-level noise with single-shot decoding) and partial single-shot decodability. Several TT codes with improved parameters compared to the 3D toric code were found through numerical search, requiring significantly fewer data qubits. The codes possess transversal CZ gates for inter-block operations and numerous automorphisms for intra-block Clifford gates. Additionally, specific polynomial constructions allow for constant-depth CCZ gate implementations, with examples outperforming the 3D toric code in terms of data qubit usage for equivalent distances.

Conclusion: TT codes are a class of qLDPC codes based on trivariate polynomials and chain complexes, offering fault tolerance, partial single-shot decodability, transversal Clifford gates, and constant-depth CCZ gate implementations. Numerical searches have identified TT codes with improved parameters compared to the 3D toric code, requiring fewer data qubits for equivalent encoding distances. These codes demonstrate promising performance under circuit-level noise models, with reported thresholds of 0.3% in the Z error channel and 1% in the X error channel.

Abstract: While quantum low-density parity check (qLDPC) codes are a low-overhead means
of quantum information storage, it is valuable for quantum codes to possess
fault-tolerant features beyond this resource efficiency. In this work, we
introduce trivariate tricycle (TT) codes, qLDPC codes that combine several
desirable features: high thresholds under a circuit-level noise model, partial
single-shot decodability for low-time-overhead decoding, a large set of
transversal Clifford gates and automorphisms within and between code blocks,
and (for several sub-constructions) constant-depth implementations of a
(non-Clifford) $CCZ$ gate. TT codes are CSS codes based on a length-3 chain
complex, and are defined from three trivariate polynomials, with the 3D toric
code (3DTC) belonging to this construction. We numerically search for TT codes
and find several candidates with improved parameters relative to the 3DTC,
using up to 48$\times$ fewer data qubits as equivalent 3DTC encodings. We
construct syndrome-extraction circuits for these codes and numerically
demonstrate single-shot decoding in the X error channel in both
phenomenological and circuit-level noise models. Under circuit-level noise, TT
codes have a threshold of $0.3\%$ in the Z error channel and $1\%$ in the X
error channel (with single-shot decoding). All TT codes possess several
transversal $CZ$ gates that can partially address logical qubits between two
code blocks. Additionally, the codes possess a large set of automorphisms that
can perform Clifford gates within a code block. Finally, we establish several
TT code polynomial constructions that allows for a constant-depth
implementation of logical $CCZ$ gates. We find examples of error-correcting and
error-detecting codes using these constructions whose parameters out-perform
those of the 3DTC, using up to $4\times$ fewer data qubits for
equivalent-distance 3DTC encodings.

</details>


### [850] [Pangenome-guided sequence assembly via binary optimisation](https://arxiv.org/abs/2508.08200)
*Josh Cudby,James Bonfield,Chenxi Zhou,Richard Durbin,Sergii Strelchuk*

Main category: quant-ph

TL;DR: A new pangenome-guided assembly method, solvable by quantum computers, improves contiguity over de novo methods without reference bias, with competitive accuracy and better scalability.


<details>
  <summary>Details</summary>
Motivation: Addressing the challenges of de novo genome assembly in highly repetitive regions and the bias issues of reference-guided assemblers.

Method: Frames assembly as a graph traversal optimisation problem, implemented on quantum computers. The pipeline annotates pangenome graphs with estimated copy numbers for each node and finds a path that best explains these copy numbers.

Result: Significantly reduces the number of contigs compared to de novo assemblers on simulated data, with a small increase in inaccuracies like false joins. The optimisation-based methods are competitive with exhaustive search techniques and designed for efficient scaling on quantum computers.

Conclusion: pangenome-guided sequence assembly framework can resolve short-read data in complex regions without bias towards a single reference genome, showing competitive performance with current exhaustive search techniques and potential for efficient scaling on quantum computers.

Abstract: De novo genome assembly is challenging in highly repetitive regions; however,
reference-guided assemblers often suffer from bias. We propose a framework for
pangenome-guided sequence assembly, which can resolve short-read data in
complex regions without bias towards a single reference genome. Our method
frames assembly as a graph traversal optimisation problem, which can be
implemented on quantum computers. The pipeline first annotates pangenome graphs
with estimated copy numbers for each node, then finds a path on the graph that
best explains those copy numbers. On simulated data, our approach significantly
reduces the number of contigs compared to de novo assemblers. While it
introduces a small increase in inaccuracies, such as false joins, our
optimisation-based methods are competitive with current exhaustive search
techniques. They are also designed to scale more efficiently as the problem
size grows and will run effectively on future quantum computers.

</details>


### [851] [Color it, Code it, Cancel it: k-local dynamical decoupling from classical additive codes](https://arxiv.org/abs/2508.08213)
*Minh T. P. Nguyen,Maximilian Rimbach-Russ,Stefano Bosco*

Main category: quant-ph

TL;DR: Dynamical decoupling sequences are usually long and inefficient. We developed a new method using graph coloring and coding theory to create short, efficient, and hardware-specific sequences that suppress unwanted interactions and enable Hamiltonian engineering.


<details>
  <summary>Details</summary>
Motivation: Conventional dynamical decoupling sequences often result in long protocols that scale exponentially with system size, as they aim to completely freeze system dynamics. There is a need for more efficient and compact sequences tailored to specific hardware and interactions.

Method: Our method combines techniques from graph coloring and classical coding theory. It maps dynamical decoupling sequence design to error-detecting codes, allowing the use of coding-theoretic tools to construct customized sequences. To overcome exponential overheads, we exploit symmetries in colored interaction hypergraphs, extending graph-coloring strategies to arbitrary many-body Hamiltonians.

Result: We demonstrate the effectiveness of our framework through concrete examples, including compact sequences that suppress residual ZZ and ZZZ interactions in superconducting qubits and Heisenberg exchange coupling in spin qubits. We also show how it enables Hamiltonian engineering by simulating the anisotropic Kitaev honeycomb model using only isotropic Heisenberg interactions.

Conclusion: We introduce a general framework for constructing time-optimal, selectively-tailored dynamical decoupling sequences that remove only specific local interactions. This framework leverages techniques from graph coloring and classical coding theory to create compact, hardware-tailored sequences applicable across diverse qubit platforms. It efficiently cancels undesired Hamiltonian terms while preserving target interactions, opening up broad applications in quantum computing and simulation.

Abstract: Dynamical decoupling is a central technique in quantum computing for actively
suppressing decoherence and systematic imperfections through sequences of
single-qubit operations. Conventional sequences typically aim to completely
freeze system dynamics, often resulting in long protocols whose length scales
exponentially with system size. In this work, we introduce a general framework
for constructing time-optimal, selectively-tailored sequences that remove only
specific local interactions. By combining techniques from graph coloring and
classical coding theory, our approach enables compact and hardware-tailored
sequences across diverse qubit platforms, efficiently canceling undesired
Hamiltonian terms while preserving target interactions. This opens up broad
applications in quantum computing and simulation. At the core of our method is
a mapping between dynamical decoupling sequence design and error-detecting
codes, which allows us to leverage powerful coding-theoretic tools to construct
customized sequences. To overcome exponential overheads, we exploit symmetries
in colored interaction hypergraphs, extending graph-coloring strategies to
arbitrary many-body Hamiltonians. We demonstrate the effectiveness of our
framework through concrete examples, including compact sequences that suppress
residual ZZ and ZZZ interactions in superconducting qubits and Heisenberg
exchange coupling in spin qubits. We also show how it enables Hamiltonian
engineering by simulating the anisotropic Kitaev honeycomb model using only
isotropic Heisenberg interactions.

</details>


### [852] [Average Contraction Coefficients of Quantum Channels](https://arxiv.org/abs/2508.08214)
*Ruben Ibarrondo,Daniel Stilck França*

Main category: quant-ph

TL;DR: 该研究提出了一种新的量子信道噪声分析方法，通过“收缩矩”量化“典型”状态的可区分性，发现了平均收缩的相变现象，并揭示了噪声、隐私和可区分性之间的联系。


<details>
  <summary>Details</summary>
Motivation: 传统的量子信道分析主要关注“最坏情况”下的收缩系数，这可能导致对信道行为的过度乐观估计，不能代表实际的“典型”行为。因此，本研究旨在探索噪声如何收缩“典型”状态的可区分性，超越最坏情况的限制，以更精细地量化量子信息和计算中的典型信道噪声。

Method: 本研究引入并研究了一族收缩矩，用于插值信道的“最坏情况”收缩系数与其在特定输入状态系综下的平均行为。研究人员推导了这些矩的一般性质，并将不同散度下的矩联系起来，还基于Choi状态的熵或纯度等信道参数推导出界限。具体来说，针对迹距离，研究人员给出了其在张量积噪声信道下的平均收缩的上下界，并证明了平均收缩行为会随局部噪声强度的变化发生相变：在低于临界错误率时，平均收缩接近于1；高于临界错误率时，平均收缩则随系统大小呈指数衰减。研究还将这种相变现象推广到具有单位噪声的随机量子电路。

Result: 研究发现了量子信道收缩系数的新现象，例如平均收缩的相变。对于迹距离，在张量积噪声信道下，当局部噪声强度低于某一临界值时，平均收缩接近于1；当高于该临界值时，平均收缩随系统大小指数衰减。对于具有单位噪声的随机量子电路，即使深度很浅（如对数对数n），平均迹距离也可以变得非常小（超多项式地小）。此外，在f-散度方面，研究表明保证隐私的噪声条件可能会导致输出平均无法区分。

Conclusion: 这项工作提出了一个量化量子信道噪声的框架，通过研究收缩矩来衡量‘典型’状态的可区分性。研究发现，在张量积噪声信道和随机量子电路中存在相变现象，这取决于局部噪声强度。结果表明，在特定噪声条件下，即使是高度纠缠的状态，其平均可区分性也不会减小，这与传统的基于最坏情况的分析不同。此外，研究还探讨了f-散度，并将其应用于本地差分隐私，揭示了在保证隐私的噪声条件下，输出平均而言几乎无法区分。

Abstract: The data-processing inequality ensures quantum channels reduce state
distinguishability, with contraction coefficients quantifying optimal bounds.
However, these can be overly optimistic and not representative of the usual
behavior. We study how noise contracts distinguishability of `typical' states,
beyond the worst-case. To that end, we introduce and study a family of moments
of contraction for quantum divergences, which interpolate between the
worst-case contraction coefficient of a channel and its average behavior under
a chosen ensemble of input states. We establish general properties of these
moments, relate moments for different divergences, and derive bounds in terms
of channel parameters like the entropy or purity of its Choi state.
  Focusing on the trace distance, we obtain upper and lower bounds on its
average contraction under tensor-product noise channels, and prove that,
depending on the local noise strength, there is a phase transition in the limit
of many channel uses: below a critical error rate the average contraction
remains near unity, whereas above it decays exponentially with system size. We
extend these phase-transition phenomena to random quantum circuits with unital
noise, showing that constant-depth noisy circuits do not shrink the trace
distance on average, even when given highly entangled states as input. In
contrast, even at $\log\log n$ depth, the average trace distance can become
superpolynomially small.
  Finally, we explore moments of contraction for f-divergences and discuss
applications to local differential privacy, demonstrating that noise regimes
ensuring privacy can render outputs essentially indistinguishable on average.
Thus, our results provide a fine-grained framework to quantify typical channel
noise in quantum information and computation and unveil new phenomena in
contraction coefficients, such as phase transitions for average contraction.

</details>


### [853] [Photon Statistics for Fock and Coherent States Interfering in a Beamsplitter](https://arxiv.org/abs/2508.08223)
*Jhordan A. T. Santiago*

Main category: quant-ph

TL;DR: Analyzed quantum states from a beamsplitter with different inputs to explain photon statistics, providing a learning resource.


<details>
  <summary>Details</summary>
Motivation: To provide a pedagogical resource for understanding basic photon statistics using beamsplitters, serving as an introductory reference for students and researchers.

Method: Theoretical study analyzing output states from a bi-modal beamsplitter with different input states (Fock, hybrid, coherent) and calculating statistical properties.

Result: Explicit expressions for output state vectors and calculated statistical properties (mean photon number, photon number variance, Mandel Q parameter, second-order coherence function) for various input states.

Conclusion: We derived explicit expressions for the output state vectors and calculated statistical properties like mean photon number, photon number variance, Mandel Q parameter, and second-order coherence function for various input states (Fock, hybrid, coherent) interfering in a bi-modal beamsplitter.

Abstract: We present a straightforward yet comprehensive theoretical study of different
quantum states emerging from a bi-modal beamsplitter when various input states
interfere. Specifically, we analyze the output states for different
combinations of input fields, including Fock states $|n\rangle|m\rangle$,
hybrid states $|n\rangle|\alpha\rangle$, and coherent states
$|\alpha\rangle|\beta\rangle$. We derive explicit expressions for the output
state vectors, calculate the mean photon number, photon number variance, Mandel
Q parameter, and secondorder coherence function to characterize the statistical
properties of the output fields. Our results are intended as a pedagogical
resource, serving as an introductory reference for students and researchers
aiming to understand basic photon statistics using beamsplitters.

</details>


### [854] [Quantum-centric simulation of hydrogen abstraction by sample-based quantum diagonalization and entanglement forging](https://arxiv.org/abs/2508.08229)
*Tyler Smith,Tanvi P. Gujarati,Mario Motta,Ben Link,Ieva Liepuoniute,Triet Friedhoff,Hiromichi Nishimura,Nam Nguyen,Kristen S. Williams,Javier Robledo Moreno,Caleb Johnson,Kevin J. Sung,Abdullah Ash Saki,Marna Kagele*

Main category: quant-ph

TL;DR: 本文介绍了一种结合纠缠锻造（EF）和基于样本的量子对角化（SQD）的新型量子模拟方法，并成功应用于计算2,2-二苯基丙烷的氢提取反应的活化能和反应能，证明了该方法在化学模拟领域的潜力。


<details>
  <summary>Details</summary>
Motivation: 为了在量子计算的应用中模拟电子系统，特别是计算复合材料光降解中的自由基链反应（如航空航天工程中使用的材料），本文研究了自由基链反应中的一个关键步骤——2,2-二苯基丙烷的氢提取反应的活化能和反应能。

Method: 本文结合了纠缠锻造（EF）和基于样本的量子对角化（SQD）两种技术。EF是一种量子比特约简技术，它将量子比特映射到空间轨道，从而将所需的量子比特数量减少一半。SQD则是一种将薛定谔方程投影到从量子设备采样的配置子空间中的方法。通过结合这两种技术，并利用IBM Heron系列的超导量子处理器和经典计算资源，对2,2-二苯基丙烷的氢提取反应进行了计算。

Result: 计算结果表明，该结合EF和SQD的方法能够准确地评估不同尺寸活性空间的化学反应能量，为在量子计算机上进行复杂的化学模拟提供了可行性。

Conclusion: 结合纠缠锻造（EF）和基于样本的量子对角化（SQD）的方法被证明可以准确地模拟化学反应，为量子计算在材料科学和化学模拟中的应用提供了有前景的途径。

Abstract: The simulation of electronic systems is an anticipated application for
quantum-centric computers, i.e. heterogeneous architectures where classical and
quantum processing units operate in concert. An important application is the
computation of radical chain reactions, including those responsible for the
photodegradation of composite materials used in aerospace engineering. Here, we
compute the activation energy and reaction energy for hydrogen abstraction from
2,2-diphenyldipropane, used as a minimal model for a step in a radical chain
reaction. Calculations are performed using a superconducting quantum processor
of the IBM Heron family and classical computing resources. To this end, we
combine a qubit-reduction technique called entanglement forging (EF) with
sample based quantum diagonalization (SQD), a method that projects the
Schr\"{o}dinger equation into a subspace of configurations sampled from a
quantum device. In conventional quantum simulations, a qubit represents a
spin-orbital. In contrast, EF maps a qubit to a spatial orbital, reducing the
required number of qubits by half. We provide a complete derivation and a
detailed description of the combined EF and SQD approach, and we assess its
accuracy across active spaces of varying sizes.

</details>


### [855] [Composable Quantum Fault-Tolerance](https://arxiv.org/abs/2508.08246)
*Zhiyang He,Quynh T. Nguyen,Christopher A. Pattison*

Main category: quant-ph

TL;DR: 提出可组合容错性框架，简化量子计算阈值证明，并提供常用小工具库。


<details>
  <summary>Details</summary>
Motivation: 证明容错量子计算的阈值定理是一项繁重的工作，涉及许多相互关联的部分，并且通常需要冗长的公式推导。由于容错性度量各不相同，将来自多个论文的要素组合成单个正式的阈值证明非常困难且罕见。

Method: 提出了一种名为“可组合容错性”的新框架，用于简化容错量子计算的阈值证明。该框架将噪声分布的概率分析与电路正确性的组合分析分离开来，使得能够独立分析的小工具可以轻松组合，从而进行严格的阈值证明。

Result: 提供了一个包含量子低密度奇偶校验码和蒸馏的恒定深度电路实现的标准常用小工具库。作为示例应用，明确给出了表面码计算的阈值证明，并使用该库中的小工具重新推导了Gottesman的恒定空间开销容错方案。

Conclusion: 引入了可组合的容错性框架，将噪声分布的概率分析与电路正确性的组合分析解耦，使阈值证明能够轻松严谨地组合独立分析的小工具。

Abstract: Proving threshold theorems for fault-tolerant quantum computation is a
burdensome endeavor with many moving parts that come together in relatively
formulaic but lengthy ways. It is difficult and rare to combine elements from
multiple papers into a single formal threshold proof, due to the use of
different measures of fault-tolerance. In this work, we introduce composable
fault-tolerance, a framework that decouples the probabilistic analysis of the
noise distribution from the combinatorial analysis of circuit correctness, and
enables threshold proofs to compose independently analyzed gadgets easily and
rigorously. Within this framework, we provide a library of standard and
commonly used gadgets such as memory and logic implemented by constant-depth
circuits for quantum low-density parity check codes and distillation. As sample
applications, we explicitly write down a threshold proof for computation with
surface code and re-derive the constant space-overhead fault-tolerant scheme of
Gottesman using gadgets from this library. We expect that future
fault-tolerance proofs may focus on the analysis of novel techniques while
leaving the standard components to the composable fault-tolerance framework,
with the formal proof following the intuitive ``napkin math'' exactly.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [856] [PureSample: Neural Materials Learned by Sampling Microgeometry](https://arxiv.org/abs/2508.07240)
*Zixuan Li,Zixiong Wang,Jian Yang,Milos Hasan,Beibei Wang*

Main category: cs.GR

TL;DR: PureSample 是一种新的神经 BRDF 表示，它纯粹通过在微几何上进行正向随机游动的采样来学习材质的行为，从而能够进行高效的重要性采样、PDF 评估和 BRDF 评估，解决了传统材质模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的基于物理的材质模型依赖于解析推导的 BRDF，通常复杂且特定于模型，并且忽略了空间变化。需要新的方法来解决这些限制。

Method: PureSample 使用流匹配神经网络学习采样分布以实现重要性采样和 PDF 评估，并使用轻量级神经网络学习视图相关的反照率项来将标量 PDF 值转换为彩色 BRDF 值。

Result: PureSample 能够对同质和空间变化的材质进行高效的重要性采样、PDF 评估和 BRDF 评估，并在多层材质、多次散射微面材质和各种其他微结构等具有挑战性的材质上进行了演示。

Conclusion: PureSample 通过使用流匹配神经网络对采样分布进行建模，并引入一个视图相关的反照率项，实现了对齐, 变异材料以及多层材料等具有挑战性材料的有效表示和采样。

Abstract: Traditional physically-based material models rely on analytically derived
bidirectional reflectance distribution functions (BRDFs), typically by
considering statistics of micro-primitives such as facets, flakes, or spheres,
sometimes combined with multi-bounce interactions such as layering and multiple
scattering. These derivations are often complex and model-specific, and
typically consider a statistical aggregate of a large surface area, ignoring
spatial variation. Once an analytic BRDF's evaluation is defined, one still
needs to design an importance sampling method for it, and a way to evaluate the
pdf of that sampling distribution, requiring further model-specific
derivations.
  We present PureSample: a novel neural BRDF representation that allows
learning a material's behavior purely by sampling forward random walks on the
microgeometry, which is usually straightforward to implement. Our
representation allows for efficient importance sampling, pdf evaluation, and
BRDF evaluation, for homogeneous as well as spatially varying materials.
  We achieve this by two learnable components: first, the sampling distribution
is modeled using a flow matching neural network, which allows both importance
sampling and pdf evaluation; second, we introduce a view-dependent albedo term,
captured by a lightweight neural network, which allows for converting a scalar
pdf value to a colored BRDF value for any pair of view and light directions.
  We demonstrate PureSample on challenging materials, including multi-layered
materials, multiple-scattering microfacet materials, and various other
microstructures.

</details>


### [857] [Verification Method for Graph Isomorphism Criteria](https://arxiv.org/abs/2508.07615)
*Chuanfu Hu,Aimin Hou*

Main category: cs.GR

TL;DR: 文章提出了一种新的图同构判定验证方法和细分方法，提高了判定效率。


<details>
  <summary>Details</summary>
Motivation: 图同构问题的判定条件对于解决图同构问题至关重要。

Method: 提出了一种验证方法和一种细分方法

Result: 该验证方法可以正确判断已有图同构判断条件是否为充分必要条件，细分方法可以有效减小回溯空间。

Conclusion: 该文章提出了一种验证方法，可以正确判断已有图同构判断条件是否为充分必要条件，并且提出了一种细分方法，可以对必要条件获得更多的细分，有效减小回溯空间。

Abstract: The criteria for determining graph isomorphism are crucial for solving graph
isomorphism problems. The necessary condition is that two isomorphic graphs
possess invariants, but their function can only be used to filtrate and
subdivide candidate spaces. The sufficient conditions are used to rebuild the
isomorphic reconstruction of special graphs, but their drawback is that the
isomorphic functions of subgraphs may not form part of the isomorphic functions
of the parent graph. The use of sufficient or necessary conditions generally
results in backtracking to ensure the correctness of the decision algorithm.
The sufficient and necessary conditions can ensure that the determination of
graph isomorphism does not require backtracking, but the correctness of its
proof process is difficult to guarantee. This article proposes a verification
method that can correctly determine whether the judgment conditions proposed by
previous researchers are sufficient and necessary conditions. A subdivision
method has also been proposed in this article, which can obtain more
subdivisions for necessary conditions and effectively reduce the size of
backtracking space.

</details>


### [858] [Vertex Features for Neural Global Illumination](https://arxiv.org/abs/2508.07852)
*Rui Su,Honghao Dong,Haojie Jin,Yisong Chen,Guoping Wang,Sheng Li*

Main category: cs.GR

TL;DR: 一种新的神经渲染技术，通过将特征存储在网格顶点上而不是整个空间中，大大减少了内存使用，同时保持了高质量的渲染效果。


<details>
  <summary>Details</summary>
Motivation: 传统的特征网格表示通常具有很大的内存占用，对现代并行计算硬件造成显著瓶颈。

Method: 本文提出了一种称为神经顶点特征的通用公式，用于处理涉及显式网格表面的神经渲染任务。该方法将可学习的特征直接存储在网格顶点上，而不是在整个三维空间中均匀分布神经特征，利用底层几何结构作为神经处理的紧凑且结构化的表示。

Result: 实验结果表明，与基于网格的表示相比，该方法将内存消耗降低到原来的五分之一（或更少），同时保持了可比的渲染质量并降低了推理开销。

Conclusion: 该方法在保持可比的渲染质量和降低推理开销的同时，将内存消耗降低到基于网格的表示的五分之一（甚至更低）。

Abstract: Recent research on learnable neural representations has been widely adopted
in the field of 3D scene reconstruction and neural rendering applications.
However, traditional feature grid representations often suffer from substantial
memory footprint, posing a significant bottleneck for modern parallel computing
hardware. In this paper, we present neural vertex features, a generalized
formulation of learnable representation for neural rendering tasks involving
explicit mesh surfaces. Instead of uniformly distributing neural features
throughout 3D space, our method stores learnable features directly at mesh
vertices, leveraging the underlying geometry as a compact and structured
representation for neural processing. This not only optimizes memory
efficiency, but also improves feature representation by aligning compactly with
the surface using task-specific geometric priors. We validate our neural
representation across diverse neural rendering tasks, with a specific emphasis
on neural radiosity. Experimental results demonstrate that our method reduces
memory consumption to only one-fifth (or even less) of grid-based
representations, while maintaining comparable rendering quality and lowering
inference overhead.

</details>


### [859] [Emergent morphogenesis via planar fabrication enabled by a reduced model of composites](https://arxiv.org/abs/2508.08198)
*Yupeng Zhang,Adam Alon,M. Khalid Jawed*

Main category: cs.GR

TL;DR: 通过加热响应性薄膜和 kirigami 塑料，从平面薄片制造可编程 3D 形状。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机在于实现对复杂三维形状的精确、可编程控制，这对于软机器人、可重构设备和功能材料等新兴技术至关重要。

Method: 提出了一种简化的数值和实验框架，该框架通过将多层复合材料折叠成单层节点和单元来减少自由度，从而能够在一个 2D 几何形状上进行模拟。这通过引入一种新颖的能量公式来实现，该公式捕捉了面内拉伸失配和面外弯曲之间的耦合，超越了简单的各向同性线性弹性模型。

Result: 通过均匀加热，所提出的框架能够从简单的平面前体生成可编程的 3D 形态，如碗、独木舟和花瓣。这些形态已通过模拟和物理原型得到验证。

Conclusion: 该研究提出了一个用于双层系统的数值和实验框架，该系统由刺激响应性热塑性薄片（Shrinky Dink）和一个 kirigami 图案化的惰性塑料层组成。通过均匀加热，主动层收缩，而图案化层限制面内拉伸但允许面外弯曲，从而从简单的平面前体获得可编程的 3D 形态。

Abstract: The ability to engineer complex three-dimensional shapes from planar sheets
with precise, programmable control underpins emerging technologies in soft
robotics, reconfigurable devices, and functional materials. Here, we present a
reduced-order numerical and experimental framework for a bilayer system
consisting of a stimuli-responsive thermoplastic sheet (Shrinky Dink) bonded to
a kirigami-patterned, inert plastic layer. Upon uniform heating, the active
layer contracts while the patterned layer constrains in-plane stretch but
allows out-of-plane bending, yielding programmable 3D morphologies from simple
planar precursors. Our approach enables efficient computational design and
scalable manufacturing of 3D forms with a single-layer reduced model that
captures the coupled mechanics of stretching and bending. Unlike traditional
bilayer modeling, our framework collapses the multilayer composite into a
single layer of nodes and elements, reducing the degrees of freedom and
enabling simulation on a 2D geometry. This is achieved by introducing a novel
energy formulation that captures the coupling between in-plane stretch mismatch
and out-of-plane bending - extending beyond simple isotropic linear elastic
models. Experimentally, we establish a fully planar, repeatable fabrication
protocol using a stimuli-responsive thermoplastic and a laser-cut inert plastic
layer. The programmed strain mismatch drives an array of 3D morphologies, such
as bowls, canoes, and flower petals, all verified by both simulation and
physical prototypes.

</details>


### [860] [LL3M: Large Language 3D Modelers](https://arxiv.org/abs/2508.08228)
*Sining Lu,Guan Chen,Nam Anh Dinh,Itai Lang,Ari Holtzman,Rana Hanocka*

Main category: cs.GR

TL;DR: LL3M 是一个使用 Python 代码在 Blender 中生成 3D 资源的多代理 LLM 系统，支持编辑、用户协作和复杂 3D 操作。


<details>
  <summary>Details</summary>
Motivation: LL3M 的目标是摆脱传统的生成方法，探索代码作为 3D 资源生成媒介的可能性，以实现更高的模块化、可编辑性，并与艺术家的工作流程集成。

Method: LL3M 是一个多代理系统，它利用预训练的大型语言模型 (LLMs) 通过编写 Blender 的 Python 代码来生成 3D 资源。该系统不依赖于 3D 数据集，而是将形状生成重新定义为代码编写任务，并引入了一个由 Blender API 文档组成的检索增强生成知识库 (BlenderRAG)。

Result: LL3M 能够根据文本提示，协调专门的 LLM 代理来计划、检索、编写、调试和完善 Blender 脚本，以生成和编辑几何形状和外观。生成的代码是可解释的、人类可读的、文档齐全的，并且可以利用 Blender 的高级功能来实现多样化和无约束的形状、材质和场景。

Conclusion: LL3M 系统通过代码生成 3D 资产，展示了代码作为 3D 资产创建的可生成和可解释媒介的强大功能。

Abstract: We present LL3M, a multi-agent system that leverages pretrained large
language models (LLMs) to generate 3D assets by writing interpretable Python
code in Blender. We break away from the typical generative approach that learns
from a collection of 3D data. Instead, we reformulate shape generation as a
code-writing task, enabling greater modularity, editability, and integration
with artist workflows. Given a text prompt, LL3M coordinates a team of
specialized LLM agents to plan, retrieve, write, debug, and refine Blender
scripts that generate and edit geometry and appearance. The generated code
works as a high-level, interpretable, human-readable, well-documented
representation of scenes and objects, making full use of sophisticated Blender
constructs (e.g. B-meshes, geometry modifiers, shader nodes) for diverse,
unconstrained shapes, materials, and scenes. This code presents many avenues
for further agent and human editing and experimentation via code tweaks or
procedural parameters. This medium naturally enables a co-creative loop in our
system: agents can automatically self-critique using code and visuals, while
iterative user instructions provide an intuitive way to refine assets. A shared
code context across agents enables awareness of previous attempts, and a
retrieval-augmented generation knowledge base built from Blender API
documentation, BlenderRAG, equips agents with examples, types, and functions
empowering advanced modeling operations and code correctness. We demonstrate
the effectiveness of LL3M across diverse shape categories, style and material
edits, and user-driven refinements. Our experiments showcase the power of code
as a generative and interpretable medium for 3D asset creation. Our project
page is at https://threedle.github.io/ll3m.

</details>
