{"id": "2507.10567", "categories": ["cs.GT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10567", "abs": "https://arxiv.org/abs/2507.10567", "authors": ["Miranda Christ", "Daniel Reichman", "Jonathan Shafer"], "title": "Protocols for Verifying Smooth Strategies in Bandits and Games", "comment": null, "summary": "We study protocols for verifying approximate optimality of strategies in\nmulti-armed bandits and normal-form games. As the number of actions available\nto each player is often large, we seek protocols where the number of queries to\nthe utility oracle is sublinear in the number of actions. We prove that such\nverification is possible for sufficiently smooth strategies that do not put too\nmuch probability mass on any specific action. We provide protocols for\nverifying that a smooth policy for a multi-armed bandit is\n$\\varepsilon$-optimal. Our verification protocols require provably fewer arm\nqueries than learning. Furthermore, we establish a nearly-tight lower bound on\nthe query complexity of verification in our settings. As an application, we\nshow how to use verification for bandits to achieve verification in normal-form\ngames. This gives a protocol for verifying whether a given strategy profile is\nan approximate strong smooth Nash equilibrium, with a query complexity that is\nsublinear in the number of actions.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u7528\u4e8e\u9a8c\u8bc1\u591a\u81c2\u8001\u864e\u673a\u548c\u6807\u51c6\u578b\u535a\u5f08\u4e2d\u7b56\u7565\u8fd1\u4f3c\u6700\u4f18\u6027\u7684\u9ad8\u6548\u534f\u8bae\uff0c\u5176\u67e5\u8be2\u590d\u6742\u5ea6\u76f8\u5bf9\u4e8e\u52a8\u4f5c\u6570\u91cf\u5448\u4e9a\u7ebf\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u5b66\u4e60\u65b9\u6cd5\u3002", "motivation": "\u591a\u81c2\u8001\u864e\u673a\u548c\u6807\u51c6\u578b\u535a\u5f08\u4e2d\uff0c\u7b56\u7565\u7684\u52a8\u4f5c\u6570\u91cf\u53ef\u80fd\u975e\u5e38\u5e9e\u5927\uff0c\u5bfc\u81f4\u4f20\u7edf\u7684\u9a8c\u8bc1\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u7684\u67e5\u8be2\u3002\u672c\u7814\u7a76\u65e8\u5728\u8bbe\u8ba1\u66f4\u9ad8\u6548\u7684\u9a8c\u8bc1\u534f\u8bae\uff0c\u5176\u67e5\u8be2\u590d\u6742\u5ea6\u76f8\u5bf9\u4e8e\u52a8\u4f5c\u6570\u91cf\u662f\u4e9a\u7ebf\u6027\u7684\uff0c\u4ece\u800c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u66f4\u5177\u53ef\u884c\u6027\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u5e76\u5206\u6790\u4e86\u5728\u591a\u81c2\u8001\u864e\u673a\uff08multi-armed bandits\uff09\u548c\u6807\u51c6\u578b\u535a\u5f08\uff08normal-form games\uff09\u4e2d\u9a8c\u8bc1\u7b56\u7565\u8fd1\u4f3c\u6700\u4f18\u6027\u7684\u534f\u8bae\u3002\u7814\u7a76\u7684\u91cd\u70b9\u662f\u5f00\u53d1\u67e5\u8be2\u6570\u91cf\u76f8\u5bf9\u4e8e\u52a8\u4f5c\u6570\u91cf\u5448\u4e9a\u7ebf\u6027\u589e\u957f\u7684\u9a8c\u8bc1\u534f\u8bae\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u52a8\u4f5c\u6570\u91cf\u5e9e\u5927\u7684\u60c5\u51b5\u3002\u5bf9\u4e8e\u5177\u6709\u7279\u5b9a\u5149\u6ed1\u6027\u8d28\uff08\u5373\u7b56\u7565\u4e0d\u4f1a\u5728\u4efb\u4f55\u5355\u4e00\u52a8\u4f5c\u4e0a\u5206\u914d\u8fc7\u591a\u7684\u6982\u7387\u8d28\u91cf\uff09\u7684\u7b56\u7565\uff0c\u7814\u7a76\u8bc1\u660e\u4e86\u8fd9\u79cd\u4e9a\u7ebf\u6027\u9a8c\u8bc1\u662f\u53ef\u884c\u7684\u3002\u7814\u7a76\u4e2d\u63d0\u4f9b\u4e86\u5177\u4f53\u7684\u534f\u8bae\uff0c\u7528\u4e8e\u9a8c\u8bc1\u591a\u81c2\u8001\u864e\u673a\u4e2d\u7684\u5149\u6ed1\u7b56\u7565\u662f\u5426\u8fbe\u5230\u4e86\u03b5-\u6700\u4f18\u6027\u3002\u8fd9\u4e9b\u9a8c\u8bc1\u534f\u8bae\u5728\u81c2\u67e5\u8be2\u6b21\u6570\u4e0a\u4f18\u4e8e\u5b66\u4e60\u7b97\u6cd5\u3002\u540c\u65f6\uff0c\u7814\u7a76\u8fd8\u5efa\u7acb\u4e86\u8be5\u8bbe\u5b9a\u4e0b\u67e5\u8be2\u590d\u6742\u6027\u7684\u8fd1\u4e4e\u7d27\u5bc6\u7684\u4e0b\u754c\u3002\u6700\u540e\uff0c\u7814\u7a76\u5c55\u793a\u4e86\u5982\u4f55\u5c06\u8001\u864e\u673a\u9a8c\u8bc1\u6280\u672f\u5e94\u7528\u4e8e\u6807\u51c6\u578b\u535a\u5f08\uff0c\u4ee5\u9a8c\u8bc1\u7b56\u7565\u7ec4\u5408\u662f\u5426\u6784\u6210\u8fd1\u4f3c\u5f3a\u5149\u6ed1\u7eb3\u4ec0\u5747\u8861\uff0c\u5176\u67e5\u8be2\u590d\u6742\u5ea6\u540c\u6837\u4f4e\u4e8e\u52a8\u4f5c\u6570\u91cf\u7684\u7ebf\u6027\u3002", "result": "\u7814\u7a76\u6210\u529f\u5f00\u53d1\u4e86\u7528\u4e8e\u9a8c\u8bc1\u591a\u81c2\u8001\u864e\u673a\u4e2d\u5149\u6ed1\u7b56\u7565\u8fd1\u4f3c\u6700\u4f18\u6027\u7684\u534f\u8bae\uff0c\u5176\u67e5\u8be2\u590d\u6742\u5ea6\u4f18\u4e8e\u5b66\u4e60\u7b97\u6cd5\uff0c\u5e76\u5efa\u7acb\u4e86\u8fd1\u4e4e\u7d27\u5bc6\u7684\u4e0b\u754c\u3002\u6b64\u5916\uff0c\u7814\u7a76\u5c06\u6b64\u6280\u672f\u6269\u5c55\u5230\u6807\u51c6\u578b\u535a\u5f08\uff0c\u5b9e\u73b0\u4e86\u5bf9\u8fd1\u4f3c\u5f3a\u5149\u6ed1\u7eb3\u4ec0\u5747\u8861\u7684\u4e9a\u7ebf\u6027\u67e5\u8be2\u590d\u6742\u5ea6\u9a8c\u8bc1\u3002", "conclusion": "\u5728\u591a\u81c2\u8001\u864e\u673a\u548c\u6807\u51c6\u578b\u535a\u5f08\u4e2d\uff0c\u7814\u7a76\u4e86\u9a8c\u8bc1\u7b56\u7565\u8fd1\u4f3c\u6700\u4f18\u6027\u7684\u534f\u8bae\u3002\u6211\u4eec\u8bc1\u660e\u4e86\u5bf9\u4e8e\u8db3\u591f\u5149\u6ed1\u4e14\u4e0d\u4f1a\u5728\u4efb\u4f55\u7279\u5b9a\u52a8\u4f5c\u4e0a\u6295\u5165\u8fc7\u591a\u6982\u7387\u8d28\u91cf\u7684\u7b56\u7565\uff0c\u53ef\u4ee5\u5b9e\u73b0\u67e5\u8be2\u6570\u91cf\u76f8\u5bf9\u4e8e\u52a8\u4f5c\u6570\u91cf\u7684\u4e9a\u7ebf\u6027\u9a8c\u8bc1\u3002\u6211\u4eec\u63d0\u4f9b\u4e86\u9a8c\u8bc1\u5149\u6ed1\u7b56\u7565\u5728\u591a\u81c2\u8001\u864e\u673a\u4e2d\u662f\u5426\u4e3a\u03b5-\u6700\u4f18\u7684\u534f\u8bae\uff0c\u8fd9\u4e9b\u534f\u8bae\u6240\u9700\u7684\u81c2\u67e5\u8be2\u6b21\u6570\u6bd4\u5b66\u4e60\u6240\u9700\u7684\u5c11\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u4e3a\u6211\u4eec\u8bbe\u5b9a\u7684\u67e5\u8be2\u590d\u6742\u6027\u5efa\u7acb\u4e86\u4e00\u4e2a\u8fd1\u4e4e\u7d27\u5bc6\u7684\u4e0b\u754c\u3002\u4f5c\u4e3a\u5e94\u7528\uff0c\u6211\u4eec\u5c06\u8001\u864e\u673a\u9a8c\u8bc1\u7528\u4e8e\u535a\u5f08\u4e2d\u7684\u9a8c\u8bc1\uff0c\u5b9e\u73b0\u4e86\u5bf9\u7ed9\u5b9a\u7b56\u7565\u7ec4\u5408\u662f\u5426\u4e3a\u8fd1\u4f3c\u5f3a\u5149\u6ed1\u7eb3\u4ec0\u5747\u8861\u7684\u9a8c\u8bc1\uff0c\u5176\u67e5\u8be2\u590d\u6742\u5ea6\u4e5f\u4f4e\u4e8e\u52a8\u4f5c\u6570\u91cf\u7684\u7ebf\u6027\u3002"}}
{"id": "2507.10872", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2507.10872", "abs": "https://arxiv.org/abs/2507.10872", "authors": ["Yannai A. Gonczarowski", "Gary Qiurui Ma", "David C. Parkes"], "title": "Pricing with Tips in Three-Sided Delivery Platforms", "comment": null, "summary": "We model a delivery platform facilitating transactions among three sides:\nbuyers, stores, and couriers. In addition to buyers paying store-specific\npurchase prices and couriers receiving store--buyer-specific delivery\ncompensation from the platform, each buyer has the option to directly tip for\ndelivery from a specific store. An equilibrium consists of prices,\ncompensations, tips, and transactions that clear the market, such that buyers\nreceive deliveries from preferred stores considering the prices and tips they\npay, and couriers deliver preferred orders considering the compensations and\ntips they receive.\n  We illustrate the role of tips in pricing: Without tips, an equilibrium is\nonly guaranteed to exist when there are at least as many couriers as buyers or\nstores. In contrast, with tips an equilibrium always exists. From an efficiency\nperspective, the optimal with-tip equilibrium welfare is always weakly larger\nthan the optimal without-tip equilibrium welfare. However, we show that even\nwith tips, efficient equilibria may not exist, and calculating the optimal\nequilibrium welfare is NP-hard. To address these challenges, we identify\nnatural conditions on market structure that ensure the existence of efficient\nwith-tip equilibria and allow these efficient equilibria to be computed in\npolynomial time.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5e26\u5c0f\u8d39\u548c\u4e0d\u5e26\u5c0f\u8d39\u7684\u914d\u9001\u5e73\u53f0\u7684\u5747\u8861\u3002\u6709\u5c0f\u8d39\u65f6\uff0c\u5747\u8861\u603b\u662f\u5b58\u5728\u7684\uff0c\u4e14\u798f\u5229\u66f4\u9ad8\uff0c\u4f46\u5e76\u975e\u603b\u80fd\u4fdd\u8bc1\u6700\u4f18\u5747\u8861\u3002\u7814\u7a76\u63d0\u51fa\u4e86\u5728\u7279\u5b9a\u5e02\u573a\u6761\u4ef6\u4e0b\u4fdd\u8bc1\u5b58\u5728\u5e76\u80fd\u9ad8\u6548\u8ba1\u7b97\u6700\u4f18\u5747\u8861\u7684\u65b9\u6cd5\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u8bf4\u660e\u5c0f\u8d39\u5728\u5b9a\u4ef7\u4e2d\u7684\u4f5c\u7528\uff0c\u5e76\u7814\u7a76\u6709\u5c0f\u8d39\u548c\u65e0\u5c0f\u8d39\u60c5\u51b5\u4e0b\u7684\u5747\u8861\u5b58\u5728\u6027\u3001\u6548\u7387\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "method": "\u672c\u6587\u8003\u8651\u4e86\u4e00\u4e2a\u4fc3\u8fdb\u4e70\u5bb6\u3001\u5546\u5e97\u548c\u5feb\u9012\u5458\u4e4b\u95f4\u4ea4\u6613\u7684\u914d\u9001\u5e73\u53f0\u3002\u9664\u4e86\u4e70\u5bb6\u652f\u4ed8\u7279\u5b9a\u4e8e\u5546\u5e97\u7684\u8d2d\u4e70\u4ef7\u683c\u4ee5\u53ca\u5feb\u9012\u5458\u4ece\u5e73\u53f0\u63a5\u6536\u7279\u5b9a\u4e8e\u5546\u5e97-\u4e70\u5bb6\u7684\u914d\u9001\u8865\u507f\u5916\uff0c\u6bcf\u4f4d\u4e70\u5bb6\u8fd8\u53ef\u4ee5\u9009\u62e9\u76f4\u63a5\u4e3a\u7279\u5b9a\u5546\u5e97\u7684\u914d\u9001\u63d0\u4f9b\u5c0f\u8d39\u3002\u5747\u8861\u7531\u6e05\u7b97\u5e02\u573a\u7684\u4ef7\u683c\u3001\u8865\u507f\u3001\u5c0f\u8d39\u548c\u4ea4\u6613\u7ec4\u6210\uff0c\u4ee5\u4fbf\u4e70\u5bb6\u5728\u8003\u8651\u4ed6\u4eec\u652f\u4ed8\u7684\u4ef7\u683c\u548c\u5c0f\u8d39\u7684\u60c5\u51b5\u4e0b\uff0c\u4ece\u504f\u597d\u7684\u5546\u5e97\u83b7\u5f97\u914d\u9001\uff0c\u5e76\u4e14\u5feb\u9012\u5458\u5728\u8003\u8651\u4ed6\u4eec\u6536\u5230\u7684\u8865\u507f\u548c\u5c0f\u8d39\u7684\u60c5\u51b5\u4e0b\uff0c\u914d\u9001\u504f\u597d\u7684\u8ba2\u5355\u3002", "result": "\u6709\u5c0f\u8d39\u7684\u60c5\u51b5\u4e0b\uff0c\u603b\u80fd\u4fdd\u8bc1\u5b58\u5728\u4e00\u4e2a\u5747\u8861\uff0c\u800c\u6ca1\u6709\u5c0f\u8d39\u7684\u60c5\u51b5\u4e0b\uff0c\u4ec5\u5f53\u5feb\u9012\u5458\u6570\u91cf\u4e0d\u4e0d\u5c11\u4e8e\u4e70\u5bb6\u6216\u5546\u5e97\u6570\u91cf\u65f6\uff0c\u624d\u80fd\u4fdd\u8bc1\u5b58\u5728\u5747\u8861\u3002\u6709\u5c0f\u8d39\u60c5\u51b5\u4e0b\u7684\u6700\u4f18\u5747\u8861\u798f\u5229\u603b\u662f\u5f31\u5927\u4e8e\u6ca1\u6709\u5c0f\u8d39\u60c5\u51b5\u4e0b\u7684\u6700\u4f18\u5747\u8861\u798f\u5229\u3002\u7136\u800c\uff0c\u5373\u4f7f\u6709\u5c0f\u8d39\uff0c\u4e5f\u53ef\u80fd\u4e0d\u5b58\u5728\u6709\u6548\u7684\u5747\u8861\uff0c\u5e76\u4e14\u8ba1\u7b97\u6700\u4f18\u5747\u8861\u798f\u5229\u662fNP\u96be\u7684\u3002", "conclusion": "\u5728\u6709\u5c0f\u8d39\u7684\u60c5\u51b5\u4e0b\uff0c\u603b\u80fd\u4fdd\u8bc1\u5b58\u5728\u4e00\u4e2a\u5747\u8861\uff0c\u800c\u6ca1\u6709\u5c0f\u8d39\u7684\u60c5\u51b5\u4e0b\uff0c\u4ec5\u5f53\u5feb\u9012\u5458\u6570\u91cf\u4e0d\u5c11\u4e8e\u4e70\u5bb6\u6216\u5546\u5e97\u6570\u91cf\u65f6\uff0c\u624d\u80fd\u4fdd\u8bc1\u5b58\u5728\u5747\u8861\u3002\u7136\u800c\uff0c\u5373\u4f7f\u6709\u5c0f\u8d39\uff0c\u4e5f\u53ef\u80fd\u4e0d\u5b58\u5728\u6709\u6548\u7684\u5747\u8861\uff0c\u5e76\u4e14\u8ba1\u7b97\u6700\u4f18\u5747\u8861\u798f\u5229\u662fNP\u96be\u7684\u3002\u901a\u8fc7\u8bc6\u522b\u5e02\u573a\u7ed3\u6784\u4e0a\u7684\u81ea\u7136\u6761\u4ef6\uff0c\u53ef\u4ee5\u786e\u4fdd\u5b58\u5728\u6709\u6548\u7684\u6709\u5c0f\u8d39\u5747\u8861\uff0c\u5e76\u80fd\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u8ba1\u7b97\u51fa\u8fd9\u4e9b\u6709\u6548\u7684\u5747\u8861\u3002"}}
{"id": "2507.11214", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2507.11214", "abs": "https://arxiv.org/abs/2507.11214", "authors": ["Matteo Castiglioni", "Junjie Chen", "Yingkai Li"], "title": "Fair Contracts", "comment": null, "summary": "We introduce and study the problem of designing optimal contracts under\nfairness constraints on the task assignments and compensations. We adopt the\nnotion of envy-free (EF) and its relaxations, $\\epsilon$-EF and envy-free up to\none item (EF1), in contract design settings. Unlike fair allocations, EF\ncontracts are guaranteed to exist. However, computing any constant-factor\napproximation to the optimal EF contract is NP-hard in general, even using\n$\\epsilon$-EF contracts. For this reason, we consider settings in which the\nnumber of agents or tasks is constant. Notably, while even with three agents,\nfinding an EF contract better than $2/5$ approximation of the optimal is\nNP-hard, we are able to design an FPTAS when the number of agents is constant,\nunder relaxed notions of $\\epsilon$-EF and EF1. Moreover, we present a\npolynomial-time algorithm for computing the optimal EF contract when the number\nof tasks is constant. Finally, we analyze the price of fairness in contract\ndesign. We show that the price of fairness for exact EF contracts can be\nunbounded, even with a single task and two agents. In contrast, for EF1\ncontracts, the price of fairness is bounded between $\\Omega(\\sqrt{n})$ and\n$O(n^2)$, where $n$ is the number of agents.", "AI": {"tldr": "\u672c\u7814\u7a76\u89e3\u51b3\u4e86\u5728\u516c\u5e73\u6027\u7ea6\u675f\u4e0b\u8bbe\u8ba1\u6700\u4f18\u5408\u540c\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u51e0\u79cd\u7b97\u6cd5\u6765\u5904\u7406\u4e0d\u540c\u7684\u516c\u5e73\u6027\u5b9a\u4e49\u548c\u7ea6\u675f\u6761\u4ef6\u3002", "motivation": "\u672c\u7814\u7a76\u7684\u52a8\u673a\u662f\u8bbe\u8ba1\u5728\u516c\u5e73\u6027\u7ea6\u675f\u4e0b\u6700\u4f18\u7684\u5408\u540c\uff0c\u5e76\u7814\u7a76\u4e86\u516c\u5e73\u6027\u5bf9\u5408\u540c\u8bbe\u8ba1\u7684\u5f71\u54cd\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u516c\u5e73\uff08EF\uff09\u53ca\u5176\u653e\u677e\u5f62\u5f0f $\\epsilon$-EF \u548c\u516c\u5e73\uff08\u9664\u4e86\u4e00\u4e2a\u9879\u76ee\uff09\uff08EF1\uff09\u7684\u6982\u5ff5\uff0c\u7814\u7a76\u4e86\u5728\u516c\u5e73\u6027\u7ea6\u675f\u4e0b\u8bbe\u8ba1\u6700\u4f18\u5408\u540c\u7684\u95ee\u9898\u3002", "result": "\u5bf9\u4e8e EF \u5408\u540c\uff0c\u5f53\u4ee3\u7406\u4eba\u6570\u91cf\u6052\u5b9a\u65f6\uff0c\u53ef\u4ee5\u8bbe\u8ba1\u4e00\u4e2a FPTAS\u3002\u5f53\u4efb\u52a1\u6570\u91cf\u6052\u5b9a\u65f6\uff0c\u53ef\u4ee5\u8bbe\u8ba1\u4e00\u4e2a\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u6765\u8ba1\u7b97\u6700\u4f18 EF \u5408\u540c\u3002EF1 \u5408\u540c\u7684\u516c\u5e73\u4ef7\u683c\u6709\u754c\uff0c\u5728 $\\Omega(\\sqrt{n})$ \u548c $O(n^2)$ \u4e4b\u95f4\uff0c\u5176\u4e2d n \u662f\u4ee3\u7406\u4eba\u7684\u6570\u91cf\u3002\u7136\u800c\uff0c\u5bf9\u4e8e\u7cbe\u786e\u7684 EF \u5408\u540c\uff0c\u516c\u5e73\u4ef7\u683c\u53ef\u80fd\u662f\u65e0\u9650\u7684\u3002", "conclusion": "EF \u5408\u540c\u7684\u786e\u5b58\u5728\uff0c\u4f46\u8ba1\u7b97\u4efb\u4f55\u5e38\u6570\u56e0\u5b50\u8fd1\u4f3c\u7684\u6700\u4f18 EF \u5408\u540c\u5728\u4e00\u822c\u60c5\u51b5\u4e0b\u662f NP-hard \u7684\uff0c\u5373\u4f7f\u4f7f\u7528 $\\epsilon$-EF \u5408\u540c\u4e5f\u662f\u5982\u6b64\u3002\u7136\u800c\uff0c\u5f53\u4ee3\u7406\u4eba\u6570\u91cf\u6052\u5b9a\u65f6\uff0c\u6211\u4eec\u80fd\u591f\u8bbe\u8ba1\u4e00\u4e2a\u5173\u4e8e $\\epsilon$-EF \u548c EF1 \u7684 FPTAS\u3002\u6b64\u5916\uff0c\u5f53\u4efb\u52a1\u6570\u91cf\u6052\u5b9a\u65f6\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u8ba1\u7b97\u6700\u4f18 EF \u5408\u540c\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u3002\u6700\u540e\uff0c\u6211\u4eec\u5206\u6790\u4e86\u5408\u540c\u8bbe\u8ba1\u4e2d\u7684\u516c\u5e73\u4ef7\u683c\u3002"}}
{"id": "2507.11366", "categories": ["cs.GT", "cs.LG", "90C47, 91A05, 91A26, 68Q32"], "pdf": "https://arxiv.org/pdf/2507.11366", "abs": "https://arxiv.org/abs/2507.11366", "authors": ["Taemin Kim", "James P. Bailey"], "title": "A Parallelizable Approach for Characterizing NE in Zero-Sum Games After a Linear Number of Iterations of Gradient Descent", "comment": null, "summary": "We study online optimization methods for zero-sum games, a fundamental\nproblem in adversarial learning in machine learning, economics, and many other\ndomains. Traditional methods approximate Nash equilibria (NE) using either\nregret-based methods (time-average convergence) or contraction-map-based\nmethods (last-iterate convergence). We propose a new method based on\nHamiltonian dynamics in physics and prove that it can characterize the set of\nNE in a finite (linear) number of iterations of alternating gradient descent in\nthe unbounded setting, modulo degeneracy, a first in online optimization.\nUnlike standard methods for computing NE, our proposed approach can be\nparallelized and works with arbitrary learning rates, both firsts in\nalgorithmic game theory. Experimentally, we support our results by showing our\napproach drastically outperforms standard methods.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u54c8\u5bc6\u987f\u52a8\u529b\u5b66\u7684\u65b0\u5728\u7ebf\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u96f6\u548c\u535a\u5f08\uff0c\u5177\u6709\u6709\u9650\u8fed\u4ee3\u3001\u53ef\u5e76\u884c\u5316\u3001\u4efb\u610f\u5b66\u4e60\u7387\u7684\u4f18\u70b9\uff0c\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u96f6\u548c\u535a\u5f08\u7684\u5728\u7ebf\u4f18\u5316\u662f\u673a\u5668\u5b66\u4e60\u3001\u7ecf\u6d4e\u5b66\u7b49\u9886\u57df\u4e2d\u7684\u4e00\u4e2a\u57fa\u7840\u6027\u95ee\u9898\u3002\u4f20\u7edf\u65b9\u6cd5\u5728\u8fd1\u4f3c\u7eb3\u4ec0\u5747\u8861\uff08NE\uff09\u65f6\u5b58\u5728\u6536\u655b\u901f\u5ea6\u548c\u5e76\u884c\u5316\u7b49\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002\u672c\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u66f4\u901a\u7528\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u5b66\u4e2d\u54c8\u5bc6\u987f\u52a8\u529b\u5b66\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u7ebf\u4f18\u5316\u96f6\u548c\u535a\u5f08\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6709\u9650\u6b21\u7684\u4ea4\u66ff\u68af\u5ea6\u4e0b\u964d\u8fed\u4ee3\uff0c\u80fd\u591f\u7cbe\u786e\u523b\u753b\u7eb3\u4ec0\u5747\u8861\u96c6\uff08\u5728\u7b80\u5e76\u60c5\u51b5\u4e0b\uff09\uff0c\u5e76\u4e14\u53ef\u4ee5\u5e76\u884c\u5316\uff0c\u9002\u7528\u4e8e\u4efb\u610f\u5b66\u4e60\u7387\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u4ee5\u6709\u9650\u6b21\u6570\u7684\u8fed\u4ee3\u523b\u753b\u7eb3\u4ec0\u5747\u8861\u96c6\uff0c\u4e14\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5e76\u884c\u5316\uff0c\u5e76\u9002\u7528\u4e8e\u4efb\u610f\u5b66\u4e60\u7387\u3002\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u8fdc\u8d85\u6807\u51c6\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u57fa\u4e8e\u54c8\u5bc6\u987f\u52a8\u529b\u5b66\u7684\u65b0\u65b9\u6cd5\uff0c\u5728\u89e3\u51b3\u96f6\u548c\u535a\u5f08\u7684\u5728\u7ebf\u4f18\u5316\u95ee\u9898\u4e0a\u53d6\u5f97\u4e86\u7a81\u7834\u6027\u8fdb\u5c55\uff0c\u80fd\u591f\u4ee5\u6709\u9650\u7684\u8fed\u4ee3\u6b21\u6570\u7cbe\u786e\u523b\u753b\u7eb3\u4ec0\u5747\u8861\u96c6\uff0c\u5e76\u4e14\u5177\u6709\u53ef\u5e76\u884c\u5316\u548c\u4efb\u610f\u5b66\u4e60\u7387\u7684\u4f18\u70b9\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5176\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2507.10715", "categories": ["physics.app-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10715", "abs": "https://arxiv.org/abs/2507.10715", "authors": ["Chandler Jones", "Mark Bandstra", "Stefan Faaland", "Yue Shi Lai", "Nico Abgrall", "Scott Suchyta", "Reynold Cooper"], "title": "Real-time, Adaptive Radiological Anomaly Detection and Isotope Identification Using Non-negative Matrix Factorization", "comment": "11 pages, 8 figures", "summary": "Spectroscopic anomaly detection and isotope identification algorithms are\nintegral components in nuclear nonproliferation applications such as search\noperations. The task is especially challenging in the case of mobile detector\nsystems due to the fact that the observed gamma-ray background changes more\nthan for a static detector system, and a pretrained background model can easily\nfind itself out of domain. The result is that algorithms may exceed their\nintended false alarm rate, or sacrifice detection sensitivity in order to\nmaintain the desired false alarm rate. Non-negative matrix factorization (NMF)\nhas been shown to be a powerful tool for spectral anomaly detection and\nidentification, but, like many similar algorithms that rely on data-driven\nbackground models, in its conventional implementation it is unable to update in\nreal time to account for environmental changes that affect the background\nspectroscopic signature. We have developed a novel NMF-based algorithm that\nperiodically updates its background model to accommodate changing environmental\nconditions. The Adaptive NMF algorithm involves fewer assumptions about its\nenvironment, making it more generalizable than existing NMF-based methods while\nmaintaining or exceeding detection performance on simulated and real-world\ndatasets.", "AI": {"tldr": "\u4e3a\u89e3\u51b3\u79fb\u52a8\u63a2\u6d4b\u5668\u7cfb\u7edf\u5728\u6838\u4e0d\u6269\u6563\u5e94\u7528\u4e2d\u80cc\u666f\u53d8\u5316\u5e26\u6765\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u81ea\u9002\u5e94NMF\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u80fd\u5b9e\u65f6\u66f4\u65b0\u80cc\u666f\u6a21\u578b\uff0c\u63d0\u9ad8\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u5728\u6838\u4e0d\u6269\u6563\u5e94\u7528\u4e2d\uff0c\u5982\u641c\u7d22\u64cd\u4f5c\uff0c\u5149\u8c31\u5f02\u5e38\u68c0\u6d4b\u548c\u540c\u4f4d\u7d20\u8bc6\u522b\u7b97\u6cd5\u662f\u4e0d\u53ef\u6216\u7f3a\u7684\u7ec4\u6210\u90e8\u5206\u3002\u7136\u800c\uff0c\u5bf9\u4e8e\u79fb\u52a8\u63a2\u6d4b\u5668\u7cfb\u7edf\u6765\u8bf4\uff0c\u7531\u4e8e\u89c2\u6d4b\u5230\u7684\u4f3d\u9a6c\u5c04\u7ebf\u80cc\u666f\u53d8\u5316\u6bd4\u9759\u6001\u63a2\u6d4b\u5668\u7cfb\u7edf\u66f4\u5927\uff0c\u56e0\u6b64\u8be5\u4efb\u52a1\u5c24\u5176\u5177\u6709\u6311\u6218\u6027\u3002\u8fd9\u53ef\u80fd\u5bfc\u81f4\u7b97\u6cd5\u8d85\u51fa\u9884\u671f\u7684\u8bef\u62a5\u7387\uff0c\u6216\u8005\u727a\u7272\u68c0\u6d4b\u7075\u654f\u5ea6\u4ee5\u7ef4\u6301\u6240\u9700\u7684\u8bef\u62a5\u7387\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8eNMF\u7684\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u80fd\u591f\u5468\u671f\u6027\u5730\u66f4\u65b0\u5176\u80cc\u666f\u6a21\u578b\u4ee5\u9002\u5e94\u4e0d\u65ad\u53d8\u5316\u7684Ifs\u3002", "result": "\u8be5\u81ea\u9002\u5e94NMF\u7b97\u6cd5\u6bd4\u73b0\u6709\u7684\u57fa\u4e8eNMF\u7684\u65b9\u6cd5\u5177\u6709\u66f4\u5c11\u7684\u73af\u5883\u5047\u8bbe\uff0c\u4f7f\u5176\u66f4\u5177\u901a\u7528\u6027\uff0c\u540c\u65f6\u5728\u6a21\u62df\u548c\u771f\u5b9e\u4e16\u754c\u7684\u6570\u636e\u96c6\u4e0a\u4fdd\u6301\u6216\u8d85\u8fc7\u68c0\u6d4b\u6027\u80fd\u3002", "conclusion": "\u5f00\u53d1\u7684\u81ea\u9002\u5e94NMF\u7b97\u6cd5\u80fd\u66f4\u597d\u5730\u9002\u5e94\u4e0d\u65ad\u53d8\u5316\u7684Ifs\uff0c\u5e76\u5728\u6a21\u62df\u548c\u771f\u5b9e\u4e16\u754c\u7684\u6570\u636e\u96c6\u4e0a\u4fdd\u6301\u6216\u8d85\u8fc7\u68c0\u6d4b\u6027\u80fd\u3002"}}
{"id": "2507.10635", "categories": ["quant-ph", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2507.10635", "abs": "https://arxiv.org/abs/2507.10635", "authors": ["Nicola Assolini", "Luca Marzari", "Isabella Mastroeni", "Alessandra di Pierro"], "title": "Formal Verification of Variational Quantum Circuits", "comment": "Assolini and Marzari contributed equally to the paper", "summary": "Variational quantum circuits (VQCs) are a central component of many quantum\nmachine learning algorithms, offering a hybrid quantum-classical framework\nthat, under certain aspects, can be considered similar to classical deep neural\nnetworks. A shared aspect is, for instance, their vulnerability to adversarial\ninputs, small perturbations that can lead to incorrect predictions. While\nformal verification techniques have been extensively developed for classical\nmodels, no comparable framework exists for certifying the robustness of VQCs.\nHere, we present the first in-depth theoretical and practical study of the\nformal verification problem for VQCs. Inspired by abstract interpretation\nmethods used in deep learning, we analyze the applicability and limitations of\ninterval-based reachability techniques in the quantum setting. We show that\nquantum-specific aspects, such as state normalization, introduce inter-variable\ndependencies that challenge existing approaches. We investigate these issues by\nintroducing a novel semantic framework based on abstract interpretation, where\nthe verification problem for VQCs can be formally defined, and its complexity\nanalyzed. Finally, we demonstrate our approach on standard verification\nbenchmarks.", "AI": {"tldr": "\u672c\u7814\u7a76\u586b\u8865\u4e86\u53d8\u5206\u91cf\u5b50\u7535\u8def\uff08VQC\uff09\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u7a7a\u767d\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u62bd\u8c61\u89e3\u91ca\u7684\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u91cf\u5b50\u9886\u57df\u7684\u6311\u6218\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u5b9e\u7528\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u53d8\u5206\u91cf\u5b50\u7535\u8def\uff08VQC\uff09\u5728\u9762\u5bf9\u5bf9\u6297\u6027\u8f93\u5165\u65f6\u7f3a\u4e4f\u5f62\u5f0f\u5316\u9a8c\u8bc1\u6846\u67b6\u7684\u95ee\u9898\uff0c\u4e3a\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u6a21\u578b\u63d0\u4f9b\u9c81\u68d2\u6027\u8ba4\u8bc1\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u62bd\u8c61\u89e3\u91ca\u7684\u8bed\u4e49\u6846\u67b6\uff0c\u7528\u4e8e\u5f62\u5f0f\u5316\u5b9a\u4e49VQC\u7684\u9a8c\u8bc1\u95ee\u9898\u5e76\u5206\u6790\u5176\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u7814\u7a76\u4e86\u533a\u95f4\u53ef\u8fbe\u6027\u6280\u672f\u5728\u91cf\u5b50\u9886\u57df\u7684\u9002\u7528\u6027\u548c\u5c40\u9650\u6027\u3002", "result": "\u5c55\u793a\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u5206\u6790\u4e86\u91cf\u5b50\u7279\u5b9a\u56e0\u7d20\uff08\u5982\u72b6\u6001\u5f52\u4e00\u5316\uff09\u5bf9\u73b0\u6709\u9a8c\u8bc1\u65b9\u6cd5\u5e26\u6765\u7684\u6311\u6218\u3002", "conclusion": "\u672c\u7814\u7a76\u9996\u6b21\u6df1\u5165\u7814\u7a76\u4e86\u53d8\u5206\u91cf\u5b50\u7535\u8def\uff08VQC\uff09\u7684\u5f62\u5f0f\u9a8c\u8bc1\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u62bd\u8c61\u89e3\u91ca\u7684\u8bed\u4e49\u6846\u67b6\u6765\u5e94\u5bf9\u91cf\u5b50\u7279\u6709\u7684\u6311\u6218\u3002"}}
{"id": "2507.10689", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10689", "abs": "https://arxiv.org/abs/2507.10689", "authors": ["Tongshun Zhang", "Pingping Liu", "Yubing Lu", "Mengen Cai", "Zijian Zhang", "Zhe Zhang", "Qiuzhan Zhou"], "title": "CWNet: Causal Wavelet Network for Low-Light Image Enhancement", "comment": "Accepted by ICCV 2025", "summary": "Traditional Low-Light Image Enhancement (LLIE) methods primarily focus on\nuniform brightness adjustment, often neglecting instance-level semantic\ninformation and the inherent characteristics of different features. To address\nthese limitations, we propose CWNet (Causal Wavelet Network), a novel\narchitecture that leverages wavelet transforms for causal reasoning.\nSpecifically, our approach comprises two key components: 1) Inspired by the\nconcept of intervention in causality, we adopt a causal reasoning perspective\nto reveal the underlying causal relationships in low-light enhancement. From a\nglobal perspective, we employ a metric learning strategy to ensure causal\nembeddings adhere to causal principles, separating them from non-causal\nconfounding factors while focusing on the invariance of causal factors. At the\nlocal level, we introduce an instance-level CLIP semantic loss to precisely\nmaintain causal factor consistency. 2) Based on our causal analysis, we present\na wavelet transform-based backbone network that effectively optimizes the\nrecovery of frequency information, ensuring precise enhancement tailored to the\nspecific attributes of wavelet transforms. Extensive experiments demonstrate\nthat CWNet significantly outperforms current state-of-the-art methods across\nmultiple datasets, showcasing its robust performance across diverse scenes.\nCode is available at https://github.com/bywlzts/CWNet-Causal-Wavelet-Network.", "AI": {"tldr": "CWNet\u5229\u7528\u5c0f\u6ce2\u53d8\u6362\u548c\u56e0\u679c\u63a8\u7406\u6765\u6539\u8fdb\u4f4e\u5149\u56fe\u50cf\u589e\u5f3a\uff0c\u901a\u8fc7\u5ea6\u91cf\u5b66\u4e60\u548c\u5b9e\u4f8b\u7ea7\u8bed\u4e49\u635f\u5931\u6765\u5904\u7406\u5b9e\u4f8b\u7ea7\u8bed\u4e49\u4fe1\u606f\u548c\u7279\u5f81\u7279\u6027\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u4f4e\u5149\u56fe\u50cf\u589e\u5f3a\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u7edf\u4e00\u4eae\u5ea6\u8c03\u6574\uff0c\u5ffd\u7565\u5b9e\u4f8b\u7ea7\u8bed\u4e49\u4fe1\u606f\u548c\u4e0d\u540c\u7279\u5f81\u56fa\u6709\u7279\u6027\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684CWNet\uff08\u56e0\u679c\u5c0f\u6ce2\u7f51\u7edc\uff09\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u5229\u7528\u5c0f\u6ce2\u53d8\u6362\u8fdb\u884c\u56e0\u679c\u63a8\u7406\u3002\u8be5\u65b9\u6cd5\u5305\u62ec\uff1a1\uff09\u91c7\u7528\u56e0\u679c\u63a8\u7406\u89c6\u89d2\uff0c\u5229\u7528\u5ea6\u91cf\u5b66\u4e60\u7b56\u7565\u786e\u4fdd\u56e0\u679c\u5d4c\u5165\u9075\u5faa\u56e0\u679c\u539f\u7406\uff0c\u5e76\u5f15\u5165\u5b9e\u4f8b\u7ea7CLIP\u8bed\u4e49\u635f\u5931\u6765\u7cbe\u786e\u7ef4\u62a4\u56e0\u679c\u56e0\u7d20\u4e00\u81f4\u6027\u30022\uff09\u57fa\u4e8e\u56e0\u679c\u5206\u6790\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c0f\u6ce2\u53d8\u6362\u7684\u9aa8\u5e72\u7f51\u7edc\uff0c\u4ee5\u4f18\u5316\u9891\u7387\u4fe1\u606f\u7684\u6062\u590d\u3002", "result": "CWNet\u663e\u8457\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u5728\u5404\u79cd\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u7a33\u5065\u7684\u6027\u80fd\u3002", "conclusion": "CWNet\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u5728\u5404\u79cd\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u7a33\u5065\u7684\u6027\u80fd\u3002"}}
{"id": "2507.10562", "categories": ["cs.AI", "cs.CR", "cs.DB", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10562", "abs": "https://arxiv.org/abs/2507.10562", "authors": ["Hari Masoor"], "title": "SAMEP: A Secure Protocol for Persistent Context Sharing Across AI Agents", "comment": "7 pages, 4 figures, 3 implementation examples. Original work\n  submitted as a preprint", "summary": "Current AI agent architectures suffer from ephemeral memory limitations,\npreventing effective collaboration and knowledge sharing across sessions and\nagent boundaries. We introduce SAMEP (Secure Agent Memory Exchange Protocol), a\nnovel framework that enables persistent, secure, and semantically searchable\nmemory sharing among AI agents. Our protocol addresses three critical\nchallenges: (1) persistent context preservation across agent sessions, (2)\nsecure multi-agent collaboration with fine-grained access control, and (3)\nefficient semantic discovery of relevant historical context. SAMEP implements a\ndistributed memory repository with vector-based semantic search, cryptographic\naccess controls (AES-256-GCM), and standardized APIs compatible with existing\nagent communication protocols (MCP, A2A). We demonstrate SAMEP's effectiveness\nacross diverse domains including multi-agent software development, healthcare\nAI with HIPAA compliance, and multi-modal processing pipelines. Experimental\nresults show 73% reduction in redundant computations, 89% improvement in\ncontext relevance scores, and complete compliance with regulatory requirements\nincluding audit trail generation. SAMEP enables a new paradigm of persistent,\ncollaborative AI agent ecosystems while maintaining security and privacy\nguarantees.", "AI": {"tldr": "SAMEP is a framework for persistent, secure, and semantically searchable memory sharing among AI agents, reducing redundant computations and improving context relevance.", "motivation": "Current AI agent architectures suffer from ephemeral memory limitations, preventing effective collaboration and knowledge sharing across sessions and agent boundaries. SAMEP addresses persistent context preservation, secure multi-agent collaboration, and efficient semantic discovery.", "method": "SAMEP implements a distributed memory repository with vector-based semantic search, cryptographic access controls (AES-256-GCM), and standardized APIs compatible with existing agent communication protocols (MCP, A2A).", "result": "Experimental results show 73% reduction in redundant computations, 89% improvement in context relevance scores, and complete compliance with regulatory requirements including audit trail generation.", "conclusion": "SAMEP enabled a new paradigm of persistent, collaborative AI agent ecosystems while maintaining security and privacy guarantees."}}
{"id": "2507.10577", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.10577", "abs": "https://arxiv.org/abs/2507.10577", "authors": ["Log\u00e9 C\u00e9cile", "Ghori Rehan"], "title": "Truth Sleuth and Trend Bender: AI Agents to fact-check YouTube videos and influence opinions", "comment": null, "summary": "Misinformation poses a significant threat in today's digital world, often\nspreading rapidly through platforms like YouTube. This paper introduces a novel\napproach to combating misinformation by developing an AI-powered system that\nnot only fact-checks claims made in YouTube videos but also actively engages\nusers in the comment section and challenge misleading narratives. Our system\ncomprises two main agents: Truth Sleuth and Trend Bender.\n  Truth Sleuth extracts claims from a YouTube video, uses a Retrieval-Augmented\nGeneration (RAG) approach - drawing on sources like Wikipedia, Google Search,\nGoogle FactCheck - to accurately assess their veracity and generates a nuanced\nand comprehensive report. Through rigorous prompt engineering, Trend Bender\nleverages this report along with a curated corpus of relevant articles to\ngenerate insightful and persuasive comments designed to stimulate a productive\ndebate. With a carefully set up self-evaluation loop, this agent is able to\niteratively improve its style and refine its output.\n  We demonstrate the system's capabilities through experiments on established\nbenchmark datasets and a real-world deployment on YouTube, showcasing its\npotential to engage users and potentially influence perspectives. Our findings\nhighlight the high accuracy of our fact-checking agent, and confirm the\npotential of AI-driven interventions in combating misinformation and fostering\na more informed online space.", "AI": {"tldr": "\u63a8\u51fa\u4e00\u4e2aAI\u7cfb\u7edf\uff0c\u7531Truth Sleuth\u548cTrend Bender\u7ec4\u6210\uff0c\u7528\u4e8e\u4e8b\u5b9e\u6838\u67e5YouTube\u89c6\u9891\u4e2d\u7684\u4e3b\u5f20\uff0c\u5e76\u901a\u8fc7\u5728\u8bc4\u8bba\u533a\u4e0e\u7528\u6237\u4e92\u52a8\u6765\u6311\u6218\u9519\u8bef\u4fe1\u606f\uff0c\u4ee5\u671f\u4fc3\u8fdb\u66f4\u77e5\u60c5\u7684\u5728\u7ebf\u73af\u5883\u3002", "motivation": "\u4e3a\u4e86\u5e94\u5bf9\u6570\u5b57\u65f6\u4ee3\u865a\u5047\u4fe1\u606f\u901a\u8fc7YouTube\u7b49\u5e73\u53f0\u8fc5\u901f\u4f20\u64ad\u7684\u5a01\u80c1\uff0c\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u4e8b\u5b9e\u6838\u67e5\u5e76\u4e0e\u7528\u6237\u4e92\u52a8\u4ee5\u6311\u6218\u9519\u8bef\u4fe1\u606f\u7684AI\u7cfb\u7edf\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7531\u4e24\u4e2aAI\u4ee3\u7406\u7ec4\u6210\u7684\u7cfb\u7edf\uff1aTruth Sleuth\uff08\u5229\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6280\u672f\u4ece\u7ef4\u57fa\u767e\u79d1\u3001\u8c37\u6b4c\u641c\u7d22\u548c\u8c37\u6b4cFactCheck\u7b49\u6765\u6e90\u6838\u67e5YouTube\u89c6\u9891\u4e2d\u7684\u4e3b\u5f20\uff09\u548cTrend Bender\uff08\u5229\u7528Truth Sleuth\u7684\u62a5\u544a\u548c\u76f8\u5173\u6587\u7ae0\u8bed\u6599\u5e93\u751f\u6210\u8bc4\u8bba\uff0c\u4ee5\u5f15\u53d1\u8fa9\u8bba\uff0c\u5e76\u901a\u8fc7\u81ea\u6211\u8bc4\u4f30\u5faa\u73af\u8fdb\u884c\u6539\u8fdb\uff09\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u7684\u4e8b\u5b9e\u6838\u67e5\u4ee3\u7406\u5177\u6709\u9ad8\u51c6\u786e\u6027\uff0c\u5e76\u4e14AI\u9a71\u52a8\u7684\u5e72\u9884\u63aa\u65bd\u6709\u6f5c\u529b\u5728\u5bf9\u6297\u865a\u5047\u4fe1\u606f\u548c\u8425\u9020\u66f4\u77e5\u60c5\u7684\u5728\u7ebf\u7a7a\u95f4\u65b9\u9762\u53d1\u6325\u4f5c\u7528\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u5c55\u793a\u4e86AI\u5728\u6253\u51fb\u865a\u5047\u4fe1\u606f\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u901a\u8fc7\u51c6\u786e\u7684\u4e8b\u5b9e\u6838\u67e5\u548c\u5bcc\u6709\u6d1e\u5bdf\u529b\u7684\u8bc4\u8bba\u4e0e\u7528\u6237\u4e92\u52a8\uff0c\u4fc3\u8fdb\u66f4\u77e5\u60c5\u7684\u5728\u7ebf\u73af\u5883\u3002"}}
{"id": "2507.10560", "categories": ["cs.NE", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10560", "abs": "https://arxiv.org/abs/2507.10560", "authors": ["Shreel Golwala"], "title": "Tangma: A Tanh-Guided Activation Function with Learnable Parameters", "comment": null, "summary": "Activation functions are key to effective backpropagation and expressiveness\nin deep neural networks. This work introduces Tangma, a new activation function\nthat combines the smooth shape of the hyperbolic tangent with two learnable\nparameters: $\\alpha$, which shifts the curve's inflection point to adjust\nneuron activation, and $\\gamma$, which adds linearity to preserve weak\ngradients and improve training stability. Tangma was evaluated on MNIST and\nCIFAR-10 using custom networks composed of convolutional and linear layers, and\ncompared against ReLU, Swish, and GELU. On MNIST, Tangma achieved the highest\nvalidation accuracy of 99.09% and the lowest validation loss, demonstrating\nfaster and more stable convergence than the baselines. On CIFAR-10, Tangma\nreached a top validation accuracy of 78.15%, outperforming all other activation\nfunctions while maintaining a competitive training loss. Tangma also showed\nimproved training efficiency, with lower average epoch runtimes compared to\nSwish and GELU. These results suggest that Tangma performs well on standard\nvision tasks and enables reliable, efficient training. Its learnable design\ngives more control over activation behavior, which may benefit larger models in\ntasks such as image recognition or language modeling.", "AI": {"tldr": "Tangma\u662f\u4e00\u79cd\u65b0\u7684\u3001\u53ef\u5b66\u4e60\u7684\u6fc0\u6d3b\u51fd\u6570\uff0c\u901a\u8fc7\u5f15\u5165\u53ef\u5b66\u4e60\u53c2\u6570$\\alpha$\u548c$\\\\gamma$\u6765\u8c03\u6574\u795e\u7ecf\u5143\u6fc0\u6d3b\u548c\u63d0\u9ad8\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002\u5728MNIST\u548cCIFAR-10\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cTangma\u5728\u51c6\u786e\u7387\u3001\u6536\u655b\u901f\u5ea6\u548c\u8bad\u7ec3\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8eReLU\u3001Swish\u548cGELU\u7b49\u73b0\u6709\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e3a\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u6027\u80fd\u548c\u66f4\u5f3a\u7684\u53ef\u63a7\u6027\u3002", "motivation": "\u6fc0\u6d3b\u51fd\u6570\u662f\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4e2d\u6709\u6548\u53cd\u5411\u4f20\u64ad\u548c\u8868\u8fbe\u80fd\u529b\u7684\u5173\u952e\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u65b0\u7684\u3001\u53ef\u5b66\u4e60\u7684\u6fc0\u6d3b\u51fd\u6570Tangma\u6765\u6539\u8fdb\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3\u6548\u679c\u548c\u6027\u80fd\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTangma\u7684\u65b0\u6fc0\u6d3b\u51fd\u6570\uff0c\u5b83\u7ed3\u5408\u4e86\u53cc\u66f2\u6b63\u5207\u51fd\u6570\u7684\u5e73\u6ed1\u5f62\u72b6\u4ee5\u53ca\u4e24\u4e2a\u53ef\u5b66\u4e60\u53c2\u6570\uff1a$\\alpha$\u7528\u4e8e\u8c03\u6574\u795e\u7ecf\u5143\u6fc0\u6d3b\uff0c$\\\\gamma$\u7528\u4e8e\u4fdd\u7559\u5f31\u68af\u5ea6\u548c\u63d0\u9ad8\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002\u5728MNIST\u548cCIFAR-10\u6570\u636e\u96c6\u4e0a\uff0c\u4f7f\u7528\u5305\u542b\u5377\u79ef\u5c42\u548c\u7ebf\u6027\u5c42\u7684\u81ea\u5b9a\u4e49\u7f51\u7edc\u5bf9Tangma\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5e76\u4e0eReLU\u3001Swish\u548cGELU\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "result": "Tangma\u5728MNIST\u4e0a\u5b9e\u73b0\u4e8699.09%\u7684\u9a8c\u8bc1\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u5176\u4ed6\u6fc0\u6d3b\u51fd\u6570\uff0c\u5e76\u5c55\u793a\u4e86\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u548c\u66f4\u9ad8\u7684\u7a33\u5b9a\u6027\u3002\u5728CIFAR-10\u4e0a\uff0cTangma\u8fbe\u5230\u4e8678.15%\u7684\u9a8c\u8bc1\u51c6\u786e\u7387\uff0c\u540c\u6837\u4f18\u4e8e\u5176\u4ed6\u6fc0\u6d3b\u51fd\u6570\uff0c\u5e76\u4fdd\u6301\u4e86\u6709\u7ade\u4e89\u529b\u7684\u8bad\u7ec3\u635f\u5931\u3002\u6b64\u5916\uff0cTangma\u7684\u5e73\u5747\u8bad\u7ec3\u65f6\u95f4\u4e5f\u4f4e\u4e8eSwish\u548cGELU\u3002", "conclusion": "Tangma\u5728MNIST\u548cCIFAR-10\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8eReLU\u3001Swish\u548cGELU\u7b49\u57fa\u7ebf\u6fc0\u6d3b\u51fd\u6570\uff0c\u5728MNIST\u4e0a\u8fbe\u5230\u4e86\u6700\u9ad8\u7684\u9a8c\u8bc1\u51c6\u786e\u7387(99.09%)\u548c\u6700\u4f4e\u7684\u9a8c\u8bc1\u635f\u5931\uff0c\u5b9e\u73b0\u4e86\u6bd4\u57fa\u7ebf\u66f4\u5feb\u3001\u66f4\u7a33\u5b9a\u7684\u6536\u655b\u3002\u5728CIFAR-10\u4e0a\uff0cTangma\u8fbe\u5230\u4e8678.15%\u7684\u9a8c\u8bc1\u51c6\u786e\u7387\uff0c\u5e76\u4e14\u8bad\u7ec3\u6548\u7387\u4e5f\u4f18\u4e8eSwish\u548cGELU\u3002\u8fd9\u8868\u660eTangma\u5728\u6807\u51c6\u7684\u89c6\u89c9\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u5e76\u80fd\u5b9e\u73b0\u53ef\u9760\u3001\u9ad8\u6548\u7684\u8bad\u7ec3\u3002\u5176\u53ef\u5b66\u4e60\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5bf9\u6fc0\u6d3b\u884c\u4e3a\u7684\u66f4\u591a\u63a7\u5236\uff0c\u8fd9\u53ef\u80fd\u6709\u5229\u4e8e\u56fe\u50cf\u8bc6\u522b\u6216\u8bed\u8a00\u5efa\u6a21\u7b49\u4efb\u52a1\u4e2d\u7684\u5927\u578b\u6a21\u578b\u3002"}}
{"id": "2507.10757", "categories": ["cs.DC", "cs.NI"], "pdf": "https://arxiv.org/pdf/2507.10757", "abs": "https://arxiv.org/abs/2507.10757", "authors": ["Ryan Zarick", "Isaac Zhang", "Daniel Wong", "Thomas Kim", "Bryan Pellegrino", "Mignon Li", "Kelvin Wong"], "title": "FAFO: Over 1 million TPS on a single node running EVM while still Merkleizing every block", "comment": null, "summary": "Current blockchain execution throughput is limited by data contention,\nreducing execution layer parallelism. Fast Ahead-of-Formation Optimization\n(FAFO) is the first blockchain transaction scheduler to address this problem by\nreordering transactions before block formation for maximum concurrency. FAFO\nuses CPU-optimized cache-friendly Bloom filters to efficiently detect conflicts\nand schedule parallel transaction execution at high throughput and low\noverhead.\n  We integrate the Rust EVM client (REVM) into FAFO and achieve over 1.1\nmillion native ETH transfers per second and over half a million ERC20 transfers\nper second on a single node (Table 1), with 91% lower cost compared to\nstate-of-the-art sharded execution. Unlike many other existing high throughput\nblockchain execution clients, FAFO uses QMDB to Merkleize world state after\nevery block, enabling light clients and stateless validation for ZK-based\nvApps. FAFO scales with minimal synchronization overhead, scaling linearly with\nadditional CPU resources until it fully exploits the maximum parallelism of the\nunderlying transaction flow. FAFO proves that the high throughput necessary to\nsupport future decentralized applications can be achieved with a streamlined\nexecution layer and innovations in blockchain transaction scheduler design.\nFAFO is open-sourced at https://github.com/LayerZero-Labs/fafo.", "AI": {"tldr": "FAFO \u662f\u4e00\u79cd\u65b0\u7684\u533a\u5757\u94fe\u4ea4\u6613\u8c03\u5ea6\u5668\uff0c\u901a\u8fc7\u5728\u533a\u5757\u5f62\u6210\u524d\u91cd\u6392\u4ea4\u6613\u6765\u89e3\u51b3\u6570\u636e\u4e89\u7528\u95ee\u9898\uff0c\u4ece\u800c\u5b9e\u73b0\u9ad8\u541e\u5410\u91cf\u548c\u5e76\u884c\u6027\u3002", "motivation": "\u89e3\u51b3\u5f53\u524d\u533a\u5757\u94fe\u6267\u884c\u541e\u5410\u91cf\u53d7\u6570\u636e\u4e89\u7528\u9650\u5236\u3001\u964d\u4f4e\u6267\u884c\u5c42\u5e76\u884c\u6027\u7684\u95ee\u9898\u3002", "method": "FAFO \u91c7\u7528 CPU \u4f18\u5316\u7684\u7f13\u5b58\u53cb\u597d\u578b Bloom \u8fc7\u6ee4\u5668\u6765\u68c0\u6d4b\u51b2\u7a81\u5e76\u8c03\u5ea6\u5e76\u884c\u4ea4\u6613\u6267\u884c\uff0c\u5b9e\u73b0\u4e86\u9ad8\u541e\u5410\u91cf\u548c\u4f4e\u5f00\u9500\u3002", "result": "FAFO \u5728\u5355\u8282\u70b9\u4e0a\u5b9e\u73b0\u4e86\u8d85\u8fc7\u6bcf\u79d2\u4e00\u767e\u4e00\u5341\u4e07\u7b14\u539f\u751f ETH \u4ea4\u6613\u548c\u8d85\u8fc7\u6bcf\u79d2\u4e94\u5341\u4e07\u7b14 ERC20 \u4ea4\u6613\uff0c\u6210\u672c\u6bd4\u5f53\u524d\u5206\u7247\u6267\u884c\u4f4e 91%\uff0c\u5e76\u4e14\u80fd\u591f\u652f\u6301\u8f7b\u5ba2\u6237\u7aef\u548c\u57fa\u4e8e ZK \u7684 vApps \u7684\u65e0\u72b6\u6001\u9a8c\u8bc1\u3002", "conclusion": "FAFO \u901a\u8fc7\u7b80\u5316\u7684\u6267\u884c\u5c42\u548c\u533a\u5757\u94fe\u4ea4\u6613\u8c03\u5ea6\u5668\u8bbe\u8ba1\u521b\u65b0\uff0c\u8bc1\u660e\u4e86\u652f\u6301\u672a\u6765\u53bb\u4e2d\u5fc3\u5316\u5e94\u7528\u6240\u9700\u7684\u9ad8\u541e\u5410\u91cf\u662f\u53ef\u884c\u7684\u3002"}}
{"id": "2507.11134", "categories": ["cs.ET", "cs.AR"], "pdf": "https://arxiv.org/pdf/2507.11134", "abs": "https://arxiv.org/abs/2507.11134", "authors": ["Zhicheng Xu", "Jiawei Liu", "Sitao Huang", "Zefan Li", "Shengbo Wang", "Bo Wen", "Ruibin Mao", "Mingrui Jiang", "Giacomo Pedretti", "Jim Ignowski", "Kaibin Huang", "Can Li"], "title": "Fault-Free Analog Computing with Imperfect Hardware", "comment": null, "summary": "The growing demand for edge computing and AI drives research into analog\nin-memory computing using memristors, which overcome data movement bottlenecks\nby computing directly within memory. However, device failures and variations\ncritically limit analog systems' precision and reliability. Existing\nfault-tolerance techniques, such as redundancy and retraining, are often\ninadequate for high-precision applications or scenarios requiring fixed\nmatrices and privacy preservation. Here, we introduce and experimentally\ndemonstrate a fault-free matrix representation where target matrices are\ndecomposed into products of two adjustable sub-matrices programmed onto analog\nhardware. This indirect, adaptive representation enables mathematical\noptimization to bypass faulty devices and eliminate differential pairs,\nsignificantly enhancing computational density. Our memristor-based system\nachieved >99.999% cosine similarity for a Discrete Fourier Transform matrix\ndespite 39% device fault rate, a fidelity unattainable with conventional direct\nrepresentation, which fails with single device faults (0.01% rate). We\ndemonstrated 56-fold bit-error-rate reduction in wireless communication and\n>196% density with 179% energy efficiency improvements compared to\nstate-of-the-art techniques. This method, validated on memristors, applies\nbroadly to emerging memories and non-electrical computing substrates, showing\nthat device yield is no longer the primary bottleneck in analog computing\nhardware.", "AI": {"tldr": "\u901a\u8fc7\u5c06\u77e9\u9635\u5206\u89e3\u4e3a\u4e24\u4e2a\u5b50\u77e9\u9635\u7684\u4e58\u79ef\uff0c\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u5fc6\u963b\u5668\u7b49\u6a21\u62df\u8ba1\u7b97\u786c\u4ef6\u4e2d\u7684\u5668\u4ef6\u6545\u969c\u95ee\u9898\uff0c\u5927\u5e45\u63d0\u9ad8\u8ba1\u7b97\u7cbe\u5ea6\u548c\u6548\u7387\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u6a21\u62df\u8ba1\u7b97\uff08\u7279\u522b\u662f\u57fa\u4e8e\u5fc6\u963b\u5668\u7684\u8ba1\u7b97\uff09\u4e2d\u5668\u4ef6\u6545\u969c\u548c\u53d8\u5f02\u6027\u5bfc\u81f4\u7684\u7cbe\u5ea6\u548c\u53ef\u9760\u6027\u95ee\u9898\uff0c\u4ee5\u53ca\u73b0\u6709\u5bb9\u9519\u6280\u672f\uff08\u5982\u5197\u4f59\u548c\u518d\u8bad\u7ec3\uff09\u5728\u5904\u7406\u9ad8\u7cbe\u5ea6\u5e94\u7528\u6216\u9700\u8981\u56fa\u5b9a\u77e9\u9635\u548c\u9690\u79c1\u4fdd\u62a4\u7684\u573a\u666f\u4e0b\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u77e9\u9635\u5206\u89e3\u6280\u672f\uff0c\u5c06\u76ee\u6807\u77e9\u9635\u5206\u89e3\u4e3a\u4e24\u4e2a\u5b50\u77e9\u9635\u7684\u4e58\u79ef\u3002\u901a\u8fc7\u5728\u6a21\u62df\u786c\u4ef6\u4e0a\u5bf9\u8fd9\u4e24\u4e2a\u5b50\u77e9\u9635\u8fdb\u884c\u7f16\u7a0b\uff0c\u5b9e\u73b0\u4e86\u8ba1\u7b97\u7684\u5bb9\u9519\u6027\u3002\u5229\u7528\u6570\u5b66\u4f18\u5316\u6765\u89c4\u907f\u6545\u969c\u5668\u4ef6\u548c\u6d88\u9664\u5dee\u5206\u5bf9\uff0c\u4ece\u800c\u63d0\u9ad8\u8ba1\u7b97\u5bc6\u5ea6\u548c\u7cbe\u5ea6\u3002", "result": "\u57fa\u4e8e\u5fc6\u963b\u5668\u7684\u7cfb\u7edf\u5728 39% \u7684\u5668\u4ef6\u6545\u969c\u7387\u4e0b\u5b9e\u73b0\u4e86 >99.999% \u7684\u4f59\u5f26\u76f8\u4f3c\u5ea6\uff08\u9488\u5bf9\u79bb\u6563\u5085\u7acb\u53f6\u53d8\u6362\u77e9\u9635\uff09\uff0c\u800c\u4f20\u7edf\u76f4\u63a5\u8868\u793a\u65b9\u6cd5\u5728 0.01% \u7684\u6545\u969c\u7387\u4e0b\u5c31\u4f1a\u5931\u8d25\u3002\u5728\u65e0\u7ebf\u901a\u4fe1\u4e2d\u5b9e\u73b0\u4e86 56 \u500d\u7684\u6bd4\u7279\u9519\u8bef\u7387\u964d\u4f4e\uff0c\u5bc6\u5ea6\u548c\u80fd\u6548\u76f8\u6bd4\u73b0\u6709\u6280\u672f\u5206\u522b\u63d0\u9ad8\u4e86 179% \u548c 196%\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u6545\u969c\u77e9\u9635\u8868\u793a\u65b9\u6cd5\uff0c\u5c06\u76ee\u6807\u77e9\u9635\u5206\u89e3\u4e3a\u4e24\u4e2a\u53ef\u8c03\u5b50\u77e9\u9635\u7684\u4e58\u79ef\uff0c\u5e76\u53ef\u5728\u6a21\u62df\u786c\u4ef6\u4e0a\u8fdb\u884c\u7f16\u7a0b\u3002\u8fd9\u79cd\u95f4\u63a5\u3001\u81ea\u9002\u5e94\u7684\u8868\u793a\u80fd\u591f\u901a\u8fc7\u6570\u5b66\u4f18\u5316\u7ed5\u8fc7\u6545\u969c\u8bbe\u5907\u5e76\u6d88\u9664\u5dee\u5206\u5bf9\uff0c\u4ece\u800c\u663e\u8457\u63d0\u9ad8\u8ba1\u7b97\u5bc6\u5ea6\u3002\u8be5\u65b9\u6cd5\u5728\u57fa\u4e8e\u5fc6\u963b\u5668\u7684\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u4e86\u8d85\u8fc7 99.999% \u7684\u4f59\u5f26\u76f8\u4f3c\u5ea6\uff0c\u5373\u4f7f\u5728 39% \u7684\u5668\u4ef6\u6545\u969c\u7387\u4e0b\u4e5f\u80fd\u5904\u7406\u79bb\u6563\u5085\u7acb\u53f6\u53d8\u6362\u77e9\u9635\uff0c\u8fd9\u5728\u4f20\u7edf\u76f4\u63a5\u8868\u793a\u65b9\u6cd5\u4e2d\u662f\u65e0\u6cd5\u5b9e\u73b0\u7684\u3002\u6b64\u5916\uff0c\u8be5\u7814\u7a76\u5728\u65e0\u7ebf\u901a\u4fe1\u4e2d\u5b9e\u73b0\u4e86 56 \u500d\u7684\u6bd4\u7279\u9519\u8bef\u7387\u964d\u4f4e\uff0c\u5728\u5bc6\u5ea6\u548c\u80fd\u6548\u65b9\u9762\u6bd4\u73b0\u6709\u6280\u672f\u63d0\u9ad8\u4e86 196% \u548c 179%\u3002\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u5728\u5fc6\u963b\u5668\u4e0a\u5f97\u5230\u4e86\u9a8c\u8bc1\uff0c\u800c\u4e14\u5e7f\u6cdb\u9002\u7528\u4e8e\u65b0\u5174\u5b58\u50a8\u5668\u548c\u975e\u7535\u8ba1\u7b97\u57fa\u5143\uff0c\u8868\u660e\u5668\u4ef6\u826f\u7387\u4e0d\u518d\u662f\u6a21\u62df\u8ba1\u7b97\u786c\u4ef6\u7684\u4e3b\u8981\u74f6\u9888\u3002"}}
{"id": "2507.10913", "categories": ["cs.MA", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.10913", "abs": "https://arxiv.org/abs/2507.10913", "authors": ["Shuangyao Huang", "Haibo Zhang", "Zhiyi Huang"], "title": "A Learning Framework For Cooperative Collision Avoidance of UAV Swarms Leveraging Domain Knowledge", "comment": "Under review at AAAI 2026", "summary": "This paper presents a multi-agent reinforcement learning (MARL) framework for\ncooperative collision avoidance of UAV swarms leveraging domain\nknowledge-driven reward. The reward is derived from knowledge in the domain of\nimage processing, approximating contours on a two-dimensional field. By\nmodeling obstacles as maxima on the field, collisions are inherently avoided as\ncontours never go through peaks or intersect. Additionally, counters are smooth\nand energy-efficient. Our framework enables training with large swarm sizes as\nthe agent interaction is minimized and the need for complex credit assignment\nschemes or observation sharing mechanisms in state-of-the-art MARL approaches\nare eliminated. Moreover, UAVs obtain the ability to adapt to complex\nenvironments where contours may be non-viable or non-existent through intensive\ntraining. Extensive experiments are conducted to evaluate the performances of\nour framework against state-of-the-art MARL algorithms.", "AI": {"tldr": "\u4e00\u79cd\u65b0\u7684 MARL \u6846\u67b6\uff0c\u4f7f\u7528\u57fa\u4e8e\u56fe\u50cf\u5904\u7406\u7684\u8f6e\u5ed3\u903c\u8fd1\u65b9\u6cd5\u6765\u9a71\u52a8\u5956\u52b1\uff0c\u4ee5\u5b9e\u73b0\u65e0\u4eba\u673a\u7fa4\u7684\u534f\u4f5c\u907f\u969c\u3002\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5b83\u51cf\u5c11\u4e86\u667a\u80fd\u4f53\u4ea4\u4e92\uff0c\u5e76\u63d0\u9ad8\u4e86\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u65e0\u4eba\u673a\u7fa4\u5728\u534f\u4f5c\u907f\u5f00\u78b0\u649e\u65f6\u9047\u5230\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u5e94\u7528\u548c\u590d\u6742\u73af\u5883\u9002\u5e94\u6027\u65b9\u9762\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08MARL\uff09\u6846\u67b6\uff0c\u5229\u7528\u56fe\u50cf\u5904\u7406\u9886\u57df\u7684\u77e5\u8bc6\u6765\u83b7\u53d6\u5956\u52b1\uff0c\u5c06\u969c\u788d\u7269\u5efa\u6a21\u4e3a\u4e8c\u7ef4\u573a\u4e0a\u7684\u6781\u503c\u70b9\uff0c\u901a\u8fc7\u903c\u8fd1\u8f6e\u5ed3\u6765\u907f\u514d\u78b0\u649e\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6700\u5c0f\u5316\u667a\u80fd\u4f53\u4ea4\u4e92\u548c\u6d88\u9664\u590d\u6742\u7684\u4fe1\u7528\u5206\u914d\u65b9\u6848\u6216\u89c2\u6d4b\u5171\u4eab\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u5927\u89c4\u6a21\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u6846\u67b6\u5728\u65e0\u4eba\u673a\u7fa4\u534f\u4f5c\u907f\u969c\u65b9\u9762\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u7684 MARL \u7b97\u6cd5\uff0c\u5e76\u4e14\u80fd\u591f\u9002\u5e94\u5305\u542b\u975e\u53ef\u884c\u6216\u4e0d\u5b58\u5728\u8f6e\u5ed3\u7684\u590d\u6742\u73af\u5883\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u5229\u7528\u9886\u57df\u77e5\u8bc6\u9a71\u52a8\u7684\u5956\u52b1\uff0c\u5b9e\u73b0\u4e86\u65e0\u4eba\u673a\u7fa4\u534f\u4f5c\u907f\u969c\uff0c\u80fd\u591f\u9002\u5e94\u590d\u6742\u73af\u5883\u5e76\u51cf\u5c11\u8bad\u7ec3\u4e2d\u7684\u4ea4\u4e92\u9700\u6c42\u3002"}}
{"id": "2507.10691", "categories": ["cs.DS", "cs.CC", "math.CO"], "pdf": "https://arxiv.org/pdf/2507.10691", "abs": "https://arxiv.org/abs/2507.10691", "authors": ["Cassandra Marcussen", "Edward Pyne", "Ronitt Rubinfeld", "Asaf Shapira", "Shlomo Tauber"], "title": "A Fast Coloring Oracle for Average Case Hypergraphs", "comment": "18 pages, 2 figures", "summary": "Hypergraph $2$-colorability is one of the classical NP-hard problems. Person\nand Schacht [SODA'09] designed a deterministic algorithm whose expected running\ntime is polynomial over a uniformly chosen $2$-colorable $3$-uniform\nhypergraph. Lee, Molla, and Nagle recently extended this to $k$-uniform\nhypergraphs for all $k\\geq 3$. Both papers relied heavily on the regularity\nlemma, hence their analysis was involved and their running time hid tower-type\nconstants.\n  Our first result in this paper is a new simple and elementary deterministic\n$2$-coloring algorithm that reproves the theorems of Person-Schacht and\nLee-Molla-Nagle while avoiding the use of the regularity lemma. We also show\nhow to turn our new algorithm into a randomized one with average expected\nrunning time of only $O(n)$.\n  Our second and main result gives what we consider to be the ultimate evidence\nof just how easy it is to find a $2$-coloring of an average $2$-colorable\nhypergraph. We define a coloring oracle to be an algorithm which, given vertex\n$v$, assigns color red/blue to $v$ while inspecting as few edges as possible,\nso that the answers to any sequence of queries to the oracle are consistent\nwith a single legal $2$-coloring of the input. Surprisingly, we show that there\nis a coloring oracle that, on average, can answer every vertex query in time\n$O(1)$.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u3001\u66f4\u7b80\u5355\u7684\u8d85\u56fe2\u7740\u8272\u7b97\u6cd5\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u4f18\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u63a5\u8fd1\u7406\u60f3\u7684\u7740\u8272\u9884\u8a00\u673a\u3002", "motivation": "\u8be5\u7814\u7a76\u65e8\u5728\u89e3\u51b3NP\u96be\u95ee\u9898\u2014\u2014\u8d85\u56fe2\u7740\u8272\u95ee\u9898\u3002\u73b0\u6709\u7684\u7b97\u6cd5\u4f9d\u8d56\u4e8e\u6b63\u5219\u6027\u5f15\u7406\uff0c\u5206\u6790\u590d\u6742\u4e14\u8fd0\u884c\u65f6\u95f4\u5e38\u6570\u5de8\u5927\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u627e\u5230\u4e00\u79cd\u66f4\u7b80\u5355\u3001\u66f4\u6709\u6548\u7684\u7b97\u6cd5\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b80\u5355\u4e14\u57fa\u7840\u7684\u786e\u5b9a\u60272-\u67d3\u8272\u7b97\u6cd5\uff0c\u5e76\u5c06\u5176\u8f6c\u5316\u4e3a\u4e00\u4e2a\u968f\u673a\u5316\u7b97\u6cd5\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u5b9a\u4e49\u4e86\u4e00\u4e2a\u7740\u8272\u9884\u8a00\u673a\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5e73\u5747\u67e5\u8be2\u65f6\u95f4\u4e3aO(1)\u3002", "result": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u786e\u5b9a\u60272-\u67d3\u8272\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u80fd\u591f\u91cd\u65b0\u8bc1\u660ePerson-Schacht\u548cLee-Molla-Nagle\u5b9a\u7406\uff0c\u5e76\u4e14\u907f\u514d\u4f7f\u7528\u6b63\u5219\u6027\u5f15\u7406\u3002\u540c\u65f6\uff0c\u8be5\u7b97\u6cd5\u8fd8\u53ef\u4ee5\u8f6c\u5316\u4e3a\u4e00\u4e2a\u968f\u673a\u5316\u7b97\u6cd5\uff0c\u5176\u5e73\u5747\u671f\u671b\u8fd0\u884c\u65f6\u95f4\u4e3aO(n)\u3002\u7814\u7a76\u8fd8\u8bc1\u660e\u4e86\u4e00\u4e2a\u7740\u8272\u9884\u8a00\u673a\uff0c\u8be5\u9884\u8a00\u673a\u5e73\u5747\u53ef\u4ee5\u5728O(1)\u65f6\u95f4\u5185\u56de\u7b54\u6bcf\u4e2a\u9876\u70b9\u7740\u8272\u67e5\u8be2\uff0c\u5e76\u4e14\u4fdd\u6301\u4e00\u81f4\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7b80\u5355\u4e14\u57fa\u7840\u7684\u786e\u5b9a\u60272-\u67d3\u8272\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u53ef\u4ee5\u91cd\u65b0\u8bc1\u660ePerson-Schacht\u548cLee-Molla-Nagle\u5b9a\u7406\uff0c\u5e76\u4e14\u907f\u514d\u4e86\u4f7f\u7528\u6b63\u5219\u6027\u5f15\u7406\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u5c06\u8be5\u7b97\u6cd5\u8f6c\u5316\u4e3a\u4e00\u4e2a\u968f\u673a\u5316\u7b97\u6cd5\uff0c\u5176\u5e73\u5747\u671f\u671b\u8fd0\u884c\u65f6\u95f4\u4ec5\u4e3aO(n)\u3002\u7814\u7a76\u7684\u7b2c\u4e8c\u4e2a\u4e3b\u8981\u6210\u679c\u662f\u63d0\u51fa\u4e86\u4e00\u4e2a\u7740\u8272\u9884\u8a00\u673a\uff0c\u8be5\u9884\u8a00\u673a\u53ef\u4ee5\u5728O(1)\u7684\u5e73\u5747\u65f6\u95f4\u5185\u4e3a\u6bcf\u4e2a\u9876\u70b9\u7740\u8272\uff0c\u5e76\u4e14\u786e\u4fdd\u6240\u6709\u7740\u8272\u67e5\u8be2\u90fd\u4e0e\u4e00\u4e2a\u5408\u6cd5\u76842-\u67d3\u8272\u4e00\u81f4\u3002"}}
{"id": "2507.10634", "categories": ["eess.SY", "cs.LG", "cs.SY", "eess.SP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.10634", "abs": "https://arxiv.org/abs/2507.10634", "authors": ["Thomas Feys", "Liesbet Van der Perre", "Fran\u00e7ois Rottenberg"], "title": "Learning to Quantize and Precode in Massive MIMO Systems for Energy Reduction: a Graph Neural Network Approach", "comment": null, "summary": "Massive MIMO systems are moving toward increased numbers of radio frequency\nchains, higher carrier frequencies and larger bandwidths. As such,\ndigital-to-analog converters (DACs) are becoming a bottleneck in terms of\nhardware complexity and power consumption. In this work, non-linear precoding\nfor coarsely quantized downlink massive MIMO is studied. Given the NP-hard\nnature of this problem, a graph neural network (GNN) is proposed that directly\noutputs the precoded quantized vector based on the channel matrix and the\nintended transmit symbols. The model is trained in a self-supervised manner, by\ndirectly maximizing the achievable rate. To overcome the non-differentiability\nof the objective function, introduced due to the non-differentiable DAC\nfunctions, a straight-through Gumbel-softmax estimation of the gradient is\nproposed. The proposed method achieves a significant increase in achievable sum\nrate under coarse quantization. For instance, in the single-user case, the\nproposed method can achieve the same sum rate as maximum ratio transmission\n(MRT) by using one-bit DAC's as compared to 3 bits for MRT. This reduces the\nDAC's power consumption by a factor 4-7 and 3 for baseband and RF DACs\nrespectively. This, however, comes at the cost of increased digital signal\nprocessing power consumption. When accounting for this, the reduction in\noverall power consumption holds for a system bandwidth up to 3.5 MHz for\nbaseband DACs, while the RF DACs can maintain a power reduction of 2.9 for\nhigher bandwidths. Notably, indirect effects, which further reduce the power\nconsumption, such as a reduced fronthaul consumption and reduction in other\ncomponents, are not considered in this analysis.", "AI": {"tldr": "\u4e3a\u4e86\u89e3\u51b3\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u4e2dDAC\u529f\u8017\u74f6\u9888\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u7684\u975e\u7ebf\u6027\u9884\u7f16\u7801\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u81ea\u76d1\u7763\u5b66\u4e60\u548cGumbel-softmax\u68af\u5ea6\u4f30\u8ba1\uff0c\u5728\u7c97\u91cf\u5316\u4e0b\u663e\u8457\u63d0\u5347\u4e86\u53ef\u5b9e\u73b0\u901f\u7387\uff0c\u5e76\u5927\u5e45\u964d\u4f4e\u4e86DAC\u529f\u8017\uff081\u4f4dDAC\u6548\u679c\u5ab2\u7f8e3\u4f4dDAC\u7684MRT\uff09\uff0c\u5c3d\u7ba1\u589e\u52a0\u4e86\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u7684\u529f\u8017\uff0c\u4f46\u5728\u4e00\u5b9a\u5e26\u5bbd\u5185\u4ecd\u53ef\u5b9e\u73b0\u6574\u4f53\u529f\u8017\u964d\u4f4e\u3002", "motivation": "\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u6b63\u671d\u7740\u589e\u52a0\u5c04\u9891\u94fe\u6570\u91cf\u3001\u66f4\u9ad8\u8f7d\u6ce2\u9891\u7387\u548c\u66f4\u5927\u5e26\u5bbd\u7684\u65b9\u5411\u53d1\u5c55\uff0c\u5bfc\u81f4\u6570\u6a21\u8f6c\u6362\u5668\uff08DAC\uff09\u5728\u786c\u4ef6\u590d\u6742\u5ea6\u548c\u529f\u8017\u65b9\u9762\u6210\u4e3a\u74f6\u9888\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u975e\u7ebf\u6027\u9884\u7f16\u7801\u4ee5\u5e94\u5bf9\u7c97\u91cf\u5316\u4e0b\u884c\u6d77\u91cfMIMO\u7684DAC\u529f\u8017\u95ee\u9898\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u6a21\u578b\uff0c\u7528\u4e8e\u5904\u7406\u7c97\u91cf\u5316\u4e0b\u884c\u6d77\u91cfMIMO\u7684\u975e\u7ebf\u6027\u9884\u7f16\u7801\u95ee\u9898\u3002\u8be5\u6a21\u578b\u76f4\u63a5\u6839\u636e\u4fe1\u9053\u77e9\u9635\u548c\u9884\u671f\u7684\u53d1\u5c04\u7b26\u53f7\u8f93\u51fa\u9884\u7f16\u7801\u91cf\u5316\u5411\u91cf\uff0c\u5e76\u901a\u8fc7\u6700\u5927\u5316\u53ef\u5b9e\u73b0\u901f\u7387\u8fdb\u884c\u81ea\u76d1\u7763\u5b66\u4e60\u3002\u4e3a\u89e3\u51b3\u76ee\u6807\u51fd\u6570\u4e2d\u7684\u975e\u53ef\u5fae\u6027\u95ee\u9898\uff08\u6e90\u4e8e\u975e\u53ef\u5fae\u7684DAC\u51fd\u6570\uff09\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u76f4\u63a5\u901a\u8fc7Gumbel-softmax\u4f30\u8ba1\u68af\u5ea6\u7684\u65b9\u6cd5\u3002", "result": "\u6240\u63d0\u51fa\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u65b9\u6cd5\u5728\u7c97\u91cf\u5316\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u53ef\u89c2\u7684\u603b\u548c\u901f\u7387\u63d0\u5347\u3002\u5177\u4f53\u800c\u8a00\uff0c\u5728\u5355\u7528\u6237\u573a\u666f\u4e0b\uff0c\u8be5\u65b9\u6cd5\u4ec5\u4f7f\u75281\u4f4dDAC\u4fbf\u80fd\u8fbe\u5230\u4e0e\u6700\u5927 ratio transmission (MRT) \u76f8\u5f53\u7684\u603b\u548c\u901f\u7387\uff0c\u800cMRT\u9700\u89813\u4f4dDAC\u3002\u8fd9\u4f7f\u5f97\u57fa\u5e26DAC\u548c\u5c04\u9891DAC\u7684\u529f\u8017\u5206\u522b\u964d\u4f4e\u4e864-7\u500d\u548c3\u500d\u3002\u5c3d\u7ba1\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u7684\u529f\u8017\u6709\u6240\u589e\u52a0\uff0c\u4f46\u8003\u8651\u5230\u8fd9\u4e00\u70b9\uff0c\u5728\u7cfb\u7edf\u5e26\u5bbd\u9ad8\u8fbe3.5 MHz\u65f6\uff0c\u57fa\u5e26DAC\u7684\u6574\u4f53\u529f\u8017\u4ecd\u80fd\u964d\u4f4e\uff0c\u800c\u5c04\u9891DAC\u5728\u66f4\u9ad8\u5e26\u5bbd\u4e0b\u4ecd\u80fd\u4fdd\u63012.9\u500d\u7684\u529f\u8017\u964d\u4f4e\u3002\u5206\u6790\u672a\u8003\u8651\u95f4\u63a5\u964d\u4f4e\u529f\u8017\u7684\u56e0\u7d20\uff08\u5982\u7f29\u77ed\u7684\u524d\u4f20\u94fe\u8def\u548c\u51cf\u5c11\u5176\u4ed6\u7ec4\u4ef6\u7684\u529f\u8017\uff09\u3002", "conclusion": "\u63d0\u51fa\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u65b9\u6cd5\u901a\u8fc7\u76f4\u63a5\u8f93\u51fa\u9884\u7f16\u7801\u91cf\u5316\u5411\u91cf\uff0c\u5728\u7c97\u91cf\u5316\u4e0b\u663e\u8457\u63d0\u9ad8\u4e86\u53ef\u5b9e\u73b0\u7684\u603b\u548c\u901f\u7387\uff0c\u5e76\u5728\u5355\u7528\u6237\u60c5\u51b5\u4e0b\uff0c\u4f7f\u75281\u4f4dDAC\u5b9e\u73b0\u4e86\u4e0e\u6700\u5927 ratio transmission (MRT) \u76f8\u540c\u7684\u603b\u548c\u901f\u7387\uff0c\u76f8\u8f83\u4e8eMRT\u76843\u4f4dDAC\uff0c\u53ef\u5c06\u57fa\u5e26\u548c\u5c04\u9891DAC\u7684\u529f\u8017\u964d\u4f4e4-7\u500d\u548c3\u500d\u3002\u7136\u800c\uff0c\u8fd9\u4f1a\u589e\u52a0\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u7684\u529f\u8017\uff0c\u4f46\u5728\u8003\u8651\u6b64\u56e0\u7d20\u540e\uff0c\u5bf9\u4e8e\u57fa\u5e26DAC\uff0c\u5728\u9ad8\u8fbe3.5 MHz\u7684\u7cfb\u7edf\u5e26\u5bbd\u4e0b\u4ecd\u53ef\u5b9e\u73b0\u6574\u4f53\u529f\u8017\u964d\u4f4e\uff0c\u800c\u5c04\u9891DAC\u5728\u66f4\u9ad8\u5e26\u5bbd\u4e0b\u4ecd\u53ef\u7ef4\u63012.9\u500d\u7684\u529f\u8017\u964d\u4f4e\u3002"}}
{"id": "2507.10564", "categories": ["cs.LG", "cs.AI", "eess.SP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.10564", "abs": "https://arxiv.org/abs/2507.10564", "authors": ["Sameera Bharadwaja H.", "Siddhrath Jandial", "Shashank S. Agashe", "Rajesh Kumar Reddy Moore", "Youngkwan Kim"], "title": "Tool-to-Tool Matching Analysis Based Difference Score Computation Methods for Semiconductor Manufacturing", "comment": null, "summary": "We consider the problem of tool-to-tool matching (TTTM), also called, chamber\nmatching in the context of a semiconductor manufacturing equipment. Traditional\nTTTM approaches utilize static configuration data or depend on a golden\nreference which are difficult to obtain in a commercial manufacturing line.\nFurther, existing methods do not extend very well to a heterogeneous setting,\nwhere equipment are of different make-and-model, sourced from different\nequipment vendors. We propose novel TTTM analysis pipelines to overcome these\nissues. We hypothesize that a mismatched equipment would have higher variance\nand/or higher number of modes in the data. Our best univariate method achieves\na correlation coefficient >0.95 and >0.5 with the variance and number of modes,\nrespectively showing that the proposed methods are effective. Also, the best\nmultivariate method achieves a correlation coefficient >0.75 with the\ntop-performing univariate methods, showing its effectiveness. Finally, we\nanalyze the sensitivity of the multivariate algorithms to the algorithm\nhyper-parameters.", "AI": {"tldr": "Novel TTTM methods using univariate and multivariate analysis are proposed to overcome limitations of traditional approaches in semiconductor manufacturing, showing effective results with high correlations and analyzing hyper-parameter sensitivity.", "motivation": "Traditional TTTM approaches struggle with static configurations, the lack of a golden reference in commercial manufacturing, and heterogeneity in equipment make-and-model and vendors. The proposed methods aim to overcome these limitations.", "method": "Novel TTTM analysis pipelines are proposed, utilizing univariate and multivariate approaches to analyze semiconductor manufacturing equipment data. The univariate methods correlate with variance and number of modes, while the multivariate methods build upon the univariate approaches.", "result": "The best univariate method achieves a correlation coefficient >0.95 with variance and >0.5 with the number of modes. The best multivariate method achieves a correlation coefficient >0.75 with the top-performing univariate methods. Algorithm sensitivity to hyper-parameters is also analyzed.", "conclusion": "The proposed TTTM analysis pipelines effectively overcome the limitations of traditional methods by addressing issues related to static configurations, golden references, and heterogeneous equipment settings. The methods show strong correlations with variance and number of modes, demonstrating their effectiveness."}}
{"id": "2507.10602", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10602", "abs": "https://arxiv.org/abs/2507.10602", "authors": ["Maximilian St\u00f6lzle", "T. Konstantin Rusch", "Zach J. Patterson", "Rodrigo P\u00e9rez-Dattari", "Francesco Stella", "Josie Hughes", "Cosimo Della Santina", "Daniela Rus"], "title": "Learning to Move in Rhythm: Task-Conditioned Motion Policies with Orbital Stability Guarantees", "comment": "73 pages", "summary": "Learning from demonstration provides a sample-efficient approach to acquiring\ncomplex behaviors, enabling robots to move robustly, compliantly, and with\nfluidity. In this context, Dynamic Motion Primitives offer built - in stability\nand robustness to disturbances but often struggle to capture complex periodic\nbehaviors. Moreover, they are limited in their ability to interpolate between\ndifferent tasks. These shortcomings substantially narrow their applicability,\nexcluding a wide class of practically meaningful tasks such as locomotion and\nrhythmic tool use. In this work, we introduce Orbitally Stable Motion\nPrimitives (OSMPs) - a framework that combines a learned diffeomorphic encoder\nwith a supercritical Hopf bifurcation in latent space, enabling the accurate\nacquisition of periodic motions from demonstrations while ensuring formal\nguarantees of orbital stability and transverse contraction. Furthermore, by\nconditioning the bijective encoder on the task, we enable a single learned\npolicy to represent multiple motion objectives, yielding consistent zero-shot\ngeneralization to unseen motion objectives within the training distribution. We\nvalidate the proposed approach through extensive simulation and real-world\nexperiments across a diverse range of robotic platforms - from collaborative\narms and soft manipulators to a bio-inspired rigid-soft turtle robot -\ndemonstrating its versatility and effectiveness in consistently outperforming\nstate-of-the-art baselines such as diffusion policies, among others.", "AI": {"tldr": "OSMPs\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u5b66\u4e60\u5230\u7684\u5fae\u5206\u540c\u80da\u7f16\u7801\u5668\u548c\u8d85\u4e34\u754cHopf\u5206\u5c94\uff0c\u6210\u529f\u514b\u670d\u4e86DMPs\u5728\u6355\u6349\u5468\u671f\u6027\u8fd0\u52a8\u548c\u4efb\u52a1\u63d2\u503c\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u673a\u5668\u4eba\u5e94\u7528\u4e2d\u5c55\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u52a8\u6001\u8fd0\u52a8\u539f\u8bed\uff08DMPs\uff09\u867d\u7136\u5177\u6709\u5185\u7f6e\u7684\u7a33\u5b9a\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4f46\u5728\u6355\u6349\u590d\u6742\u7684\u5468\u671f\u6027\u8fd0\u52a8\u548c\u4efb\u52a1\u95f4\u7684\u63d2\u503c\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5728\u884c\u8d70\u548c\u8282\u594f\u6027\u5de5\u5177\u4f7f\u7528\u7b49\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002OSMPs\u65e8\u5728\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u8f68\u9053\u7a33\u5b9a\u8fd0\u52a8\u539f\u8bed\uff08OSMPs\uff09\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u5b66\u4e60\u5230\u7684\u5fae\u5206\u540c\u80da\u7f16\u7801\u5668\u548c\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u8d85\u4e34\u754cHopf\u5206\u5c94\u3002", "result": "OSMPs\u6846\u67b6\u5728\u5404\u79cd\u673a\u5668\u4eba\u5e73\u53f0\uff08\u5305\u62ec\u534f\u4f5c\u81c2\u3001\u8f6f\u64cd\u7eb5\u5668\u548c\u53d7\u751f\u7269\u542f\u53d1\u7684\u786c\u8f6f\u6d77\u9f9f\u673a\u5668\u4eba\uff09\u7684\u4eff\u771f\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u4e2d\u5f97\u5230\u4e86\u9a8c\u8bc1\uff0c\u5e76\u4e14\u5728\u96f6\u6b21\u5c04\u51fb\u6cdb\u5316\u5230\u672a\u89c1\u8fd0\u52a8\u76ee\u6807\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u5305\u62ec\u6269\u6563\u7b56\u7565\u5728\u5185\u7684\u6700\u5148\u8fdb\u57fa\u7ebf\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u5b66\u4e60\u5230\u7684\u5fae\u5206\u540c\u80da\u7f16\u7801\u5668\u548c\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u8d85\u4e34\u754cHopf\u5206\u5c94\uff0c\u80fd\u591f\u4ece\u6f14\u793a\u4e2d\u51c6\u786e\u5b66\u4e60\u5468\u671f\u6027\u8fd0\u52a8\uff0c\u5e76\u786e\u4fdd\u8f68\u9053\u7a33\u5b9a\u6027\u548c\u6a2a\u5411\u6536\u7f29\u7684\u6b63\u5f0f\u4fdd\u8bc1\u3002\u901a\u8fc7\u5c06\u53cc\u5c04\u7f16\u7801\u5668\u6761\u4ef6\u5316\u4e8e\u4efb\u52a1\uff0c\u53ef\u4ee5\u4f7f\u5355\u4e2a\u5b66\u4e60\u7b56\u7565\u4ee3\u8868\u591a\u4e2a\u8fd0\u52a8\u76ee\u6807\uff0c\u4ece\u800c\u5728\u8bad\u7ec3\u5206\u5e03\u5185\u5b9e\u73b0\u5bf9\u672a\u89c1\u8fd0\u52a8\u76ee\u6807\u7684\u96f6\u6b21\u5c04\u51fb\u6cdb\u5316\u3002"}}
{"id": "2507.10573", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2507.10573", "abs": "https://arxiv.org/abs/2507.10573", "authors": ["Tianyu Ren", "Yajuan Du", "Jinhua Cui", "Yina Lv", "Qiao Li", "Chun Jason Xue"], "title": "Device-Level Optimization Techniques for Solid-State Drives: A Survey", "comment": null, "summary": "Solid-state drives (SSDs) have revolutionized data storage with their high\nperformance, energy efficiency, and reliability. However, as storage demands\ngrow, SSDs face critical challenges in scalability, endurance, latency, and\nsecurity. This survey provides a comprehensive analysis of SSD architecture,\nkey challenges, and device-level optimization techniques. We first examine the\nfundamental components of SSDs, including NAND flash memory structures, SSD\ncontroller functionalities (e.g., address mapping, garbage collection, wear\nleveling), and host interface protocols (SATA, SAS, NVMe). Next, we discuss\nmajor challenges such as reliability degradation, endurance limitations,\nlatency variations, and security threats (e.g., secure deletion, ransomware\ndefense). We then explore advanced optimization techniques, including error\ncorrection mechanisms, flash translation layer (FTL) enhancements, and emerging\narchitectures like zoned namespace (ZNS) SSDs and flexible data placement\n(FDP). Finally, we highlight open research challenges, such as QLC/PLC NAND\nscalability, performance-reliability trade-offs, and SSD optimizations for\nAI/LLM workloads. This survey aims to guide future research in developing\nnext-generation SSDs that balance performance, longevity, and security in\nevolving storage ecosystems.", "AI": {"tldr": "This survey analyzes SSD architecture, challenges (scalability, endurance, latency, security), and optimizations (error correction, FTL, ZNS, FDP), highlighting future research directions for AI/LLM workloads.", "motivation": "As storage demands grow, SSDs face critical challenges in scalability, endurance, latency, and security.", "method": "The survey examines the fundamental components of SSDs (NAND flash memory, controller functionalities, host interface protocols), discusses major challenges (reliability degradation, endurance limitations, latency variations, security threats), explores advanced optimization techniques (error correction, FTL enhancements, ZNS, FDP), and highlights open research challenges (QLC/PLC NAND scalability, performance-reliability trade-offs, SSD optimizations for AI/LLM workloads).", "result": "The survey offers a comprehensive overview of SSDs, their challenges, and optimization techniques, guiding future research.", "conclusion": "This survey provides a comprehensive analysis of SSD architecture, key challenges, and device-level optimization techniques. It aims to guide future research in developing next-generation SSDs that balance performance, longevity, and security in evolving storage ecosystems."}}
{"id": "2507.10883", "categories": ["cs.GR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.10883", "abs": "https://arxiv.org/abs/2507.10883", "authors": ["Juhee Bae", "Benjamin Watson"], "title": "Developing and evaluating quilts for the depiction of large layered graphs", "comment": null, "summary": "Traditional layered graph depictions such as flow charts are in wide use. Yet\nas graphs grow more complex, these depictions can become difficult to\nunderstand. Quilts are matrix-based depictions for layered graphs designed to\naddress this problem. In this research, we first improve Quilts by developing\nthree design alternatives, and then compare the best of these alternatives to\nbetter-known node-link and matrix depictions. A primary weakness in Quilts is\ntheir depiction of skip links, links that do not simply connect to a succeeding\nlayer. Therefore in our first study, we compare Quilts using color-only,\ntext-only, and mixed (color and text) skip link depictions, finding that path\nfinding with the color-only depiction is significantly slower and less\naccurate, and that in certain cases, the mixed depiction offers an advantage\nover the text-only depiction. In our second study, we compare Quilts using the\nmixed depiction to node-link diagrams and centered matrices. Overall results\nshow that users can find paths through graphs significantly faster with Quilts\n(46.6 secs) than with node-link (58.3 secs) or matrix (71.2 secs) diagrams.\nThis speed advantage is still greater in large graphs (e.g. in 200 node graphs,\n55.4 secs vs. 71.1 secs for node-link and 84.2 secs for matrix depictions).", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.10706", "categories": ["eess.SP", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.10706", "abs": "https://arxiv.org/abs/2507.10706", "authors": ["Pradyumna Kunchala", "Ashish Patwari"], "title": "A Leap-on-Success Exhaustive Search Method to Find Optimal Robust Minimum Redundancy Arrays (RMRAs): New Array Configurations for Sensor Counts 11 to 20", "comment": "21 pages, 8 Tables, 4 Figures", "summary": "Two-fold redundant sparse arrays (TFRAs) are designed to maintain accurate\ndirection estimation even in the event of a single sensor failure, leveraging\nthe deliberate coarray redundancy infused into their design. Robust Minimum\nRedundancy Arrays (RMRAs), a specialized class of TFRAs, optimize this\nredundancy to achieve the maximum possible aperture for a given number of\nsensors. However, finding optimal RMRA configurations is an NP-hard problem,\nwith prior research reporting optimal solutions only for arrays of up to ten\nsensors. This paper presents newly discovered optimal RMRA configurations for\narray sizes 11 to 15, identified using a novel Leap-on-Success exhaustive\nsearch algorithm that efficiently reduces computational effort by terminating\nthe search upon locating optimal solutions. The robustness of these arrays was\nvalidated under all single-element failure scenarios using MATLAB simulations,\nconfirming their superior resilience compared to some existing TFRAs vulnerable\nto failures at specific sensor positions. Furthermore, near-optimal\nconfigurations for array sizes 16 to 20 are also reported, highlighting the\npotential applicability of the proposed method for larger array designs given\nsufficient computational resources. This work not only advances the\nstate-of-the-art in RMRA design but also introduces an effective search\nmethodology that can be leveraged for future explorations in array\nconfiguration optimization.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u4e00\u79cd\u65b0\u7684\u641c\u7d22\u7b97\u6cd5\u53d1\u73b0\u4e86\u66f4\u591a\u4f20\u611f\u5668\u6570\u91cf\u4e0b\u7684\u6700\u4f18 RMRA \u914d\u7f6e\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4ec5\u62a5\u544a\u4e86\u591a\u8fbe 10 \u4e2a\u4f20\u611f\u5668\u7684\u6700\u4f18 RMRA \u914d\u7f6e\uff0c\u56e0\u4e3a\u5bfb\u627e\u6700\u4f18 RMRA \u914d\u7f6e\u662f\u4e00\u4e2a NP \u96be\u95ee\u9898\u3002\u672c\u7814\u7a76\u65e8\u5728\u53d1\u73b0\u66f4\u591a\u4f20\u611f\u5668\u6570\u91cf\u4e0b\u7684\u6700\u4f18 RMRA \u914d\u7f6e\uff0c\u5e76\u9a8c\u8bc1\u5176\u5728\u5355\u4f20\u611f\u5668\u6545\u969c\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "method": "\u4f7f\u7528\u65b0\u9896\u7684 Leap-on-Success \u7a77\u4e3e\u641c\u7d22\u7b97\u6cd5\u6765\u5bfb\u627e\u6700\u4f18 RMRA \u914d\u7f6e\uff0c\u8be5\u7b97\u6cd5\u901a\u8fc7\u5728\u627e\u5230\u6700\u4f18\u89e3\u540e\u7ec8\u6b62\u641c\u7d22\u6765\u6709\u6548\u51cf\u5c11\u8ba1\u7b97\u5de5\u4f5c\u91cf\u3002", "result": "\u53d1\u73b0\u4e86 11 \u81f3 15 \u4e2a\u4f20\u611f\u5668\u7684\u65b0\u578b\u6700\u4f18 RMRA \u914d\u7f6e\uff0c\u5e76\u62a5\u544a\u4e86 16 \u81f3 20 \u4e2a\u4f20\u611f\u5668\u7684\u8fd1\u4f3c\u6700\u4f18\u914d\u7f6e\u3002\u901a\u8fc7 MATLAB \u6a21\u62df\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u9635\u5217\u5728\u6240\u6709\u5355\u4f20\u611f\u5668\u6545\u969c\u573a\u666f\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u8bc1\u5b9e\u4e86\u5b83\u4eec\u6bd4\u67d0\u4e9b\u73b0\u6709 TFRAs \u66f4\u5177\u5f39\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u53d1\u73b0\u4e86 11 \u81f3 15 \u4e2a\u4f20\u611f\u5668\u7684\u65b0\u578b\u6700\u4f18\u9c81\u68d2\u6700\u5c0f\u5197\u4f59\u9635\u5217\uff08RMRA\uff09\u914d\u7f6e\uff0c\u5e76\u4e3a 16 \u81f3 20 \u4e2a\u4f20\u611f\u5668\u63d0\u4f9b\u4e86\u8fd1\u4f3c\u6700\u4f18\u914d\u7f6e\u3002\u8fd9\u4e0d\u4ec5\u63a8\u8fdb\u4e86 RMRA \u8bbe\u8ba1\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u641c\u7d22\u65b9\u6cd5\uff0c\u53ef\u7528\u4e8e\u672a\u6765\u9635\u5217\u914d\u7f6e\u4f18\u5316\u7684\u63a2\u7d22\u3002"}}
{"id": "2507.10570", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2507.10570", "abs": "https://arxiv.org/abs/2507.10570", "authors": ["Giuseppe F. Italiano", "Athanasios L. Konstantinidis", "Anna Mpanti", "Fariba Ranjbar"], "title": "Local Clustering in Hypergraphs through Higher-Order Motifs", "comment": null, "summary": "Hypergraphs provide a powerful framework for modeling complex systems and\nnetworks with higher-order interactions beyond simple pairwise relationships.\nHowever, graph-based clustering approaches, which focus primarily on pairwise\nrelations, fail to represent higher-order interactions, often resulting in\nlow-quality clustering outcomes. In this work, we introduce a novel approach\nfor local clustering in hypergraphs based on higher-order motifs, small\nconnected subgraphs in which nodes may be linked by interactions of any order,\nextending motif-based techniques previously applied to standard graphs. Our\nmethod exploits hypergraph-specific higher-order motifs to better characterize\nlocal structures and optimize motif conductance. We propose two alternative\nstrategies for identifying local clusters around a seed hyperedge: a core-based\nmethod utilizing hypergraph core decomposition and a BFS-based method based on\nbreadth-first exploration. We construct an auxiliary hypergraph to facilitate\nefficient partitioning and introduce a framework for local motif-based\nclustering. Extensive experiments on real-world datasets demonstrate the\neffectiveness of our framework and provide a comparative analysis of the two\nproposed clustering strategies in terms of clustering quality and computational\nefficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8d85\u56fe\u5c40\u90e8\u805a\u7c7b\u65b9\u6cd5\uff0c\u5229\u7528\u9ad8\u9636\u8d85\u56fe\u7684\u7ed3\u6784\u6765\u63d0\u9ad8\u805a\u7c7b\u8d28\u91cf\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u56fe\u805a\u7c7b\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6210\u5bf9\u5173\u7cfb\uff0c\u5ffd\u7565\u4e86\u8d85\u56fe\u4e2d\u5b58\u5728\u7684\u9ad8\u9636\u4ea4\u4e92\uff0c\u5bfc\u81f4\u805a\u7c7b\u7ed3\u679c\u4e0d\u4f73\u3002", "method": "\u8be5\u65b9\u6cd5\u57fa\u4e8e\u9ad8\u9636\u8d85\u56fe\u7684\u5c40\u90e8\u805a\u7c7b\uff0c\u901a\u8fc7\u9ad8\u9636\u8d85\u56fe\u7684\u7279\u5b9a\u7ed3\u6784\u6765\u4f18\u5316\u8d85\u56fe\u7684\u57fa\u51c6\uff0c\u5e76\u63d0\u51fa\u4e24\u79cd\u7b56\u7565\uff1a\u57fa\u4e8e\u6838\u5fc3\u7684\u7684\u65b9\u6cd5\u548c\u57fa\u4e8eBFS\u7684\u65b9\u6cd5\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u5e76\u5bf9\u4e24\u79cd\u63d0\u51fa\u7684\u805a\u7c7b\u7b56\u7565\u5728\u805a\u7c7b\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u8fdb\u884c\u4e86\u6bd4\u8f83\u5206\u6790\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9ad8\u9636\u8d85\u56fe\u7684\u5c40\u90e8\u805a\u7c7b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u9ad8\u9636\u8d85\u56fe\u7684\u7279\u5b9a\u7ed3\u6784\u6765\u4f18\u5316\u805a\u7c7b\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2507.10871", "categories": ["cs.LG", "cs.NA", "math.NA", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2507.10871", "abs": "https://arxiv.org/abs/2507.10871", "authors": ["Tsung Yeh Hsieh", "Yongjie Jessica Zhang"], "title": "GALDS: A Graph-Autoencoder-based Latent Dynamics Surrogate model to predict neurite material transport", "comment": null, "summary": "Neurons exhibit intricate geometries within their neurite networks, which\nplay a crucial role in processes such as signaling and nutrient transport.\nAccurate simulation of material transport in the networks is essential for\nunderstanding these biological phenomena but poses significant computational\nchallenges because of the complex tree-like structures involved. Traditional\napproaches are time-intensive and resource-demanding, yet the inherent\nproperties of neuron trees, which consists primarily of pipes with steady-state\nparabolic velocity profiles and bifurcations, provide opportunities for\ncomputational optimization. To address these challenges, we propose a\nGraph-Autoencoder-based Latent Dynamics Surrogate (GALDS) model, which is\nspecifically designed to streamline the simulation of material transport in\nneural trees. GALDS employs a graph autoencoder to encode latent\nrepresentations of the network's geometry, velocity fields, and concentration\nprofiles. These latent space representations are then assembled into a global\ngraph, which is subsequently used to predict system dynamics in the latent\nspace via a trained graph latent space system dynamic model, inspired by the\nNeural Ordinary Differential Equations (Neural ODEs) concept. The integration\nof an autoencoder allows for the use of smaller graph neural network models\nwith reduced training data requirements. Furthermore, the Neural ODE component\neffectively mitigates the issue of error accumulation commonly encountered in\nrecurrent neural networks. The effectiveness of the GALDS model is demonstrated\nthrough results on eight unseen geometries and four abnormal transport\nexamples, where our approach achieves mean relative error of 3% with maximum\nrelative error <8% and demonstrates a 10-fold speed improvement compared to\nprevious surrogate model approaches.", "AI": {"tldr": "GALDS\u6a21\u578b\u901a\u8fc7\u56fe\u81ea\u7f16\u7801\u5668\u548c\u795e\u7ecfODE\uff0c\u5728\u52a0\u901f\u548c\u63d0\u9ad8\u795e\u7ecf\u5143\u7269\u8d28\u8fd0\u8f93\u6a21\u62df\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u964d\u4f4e\u4e86\u6570\u636e\u548c\u8ba1\u7b97\u9700\u6c42\u3002", "motivation": "\u4e3a\u4e86\u5e94\u5bf9\u795e\u7ecf\u5143\u7f51\u7edc\u4e2d\u7269\u8d28\u8fd0\u8f93\u6a21\u62df\u7684\u8ba1\u7b97\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u8017\u65f6\u4e14\u8d44\u6e90\u6d88\u8017\u5927\u3002\u795e\u7ecf\u5143\u6811\u7684\u56fa\u6709\u7279\u6027\uff08\u4e3b\u8981\u662f\u5177\u6709\u7a33\u6001\u629b\u7269\u7ebf\u901f\u5ea6\u5256\u9762\u548c\u5206\u53c9\u7684\u7ba1\u9053\uff09\u4e3a\u8ba1\u7b97\u4f18\u5316\u63d0\u4f9b\u4e86\u673a\u4f1a\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u81ea\u7f16\u7801\u5668\u7684\u6f5c\u5728\u52a8\u529b\u5b66\u4ee3\u7406\u6a21\u578b\uff08GALDS\uff09\uff0c\u5229\u7528\u56fe\u81ea\u7f16\u7801\u5668\u5bf9\u7f51\u7edc\u51e0\u4f55\u3001\u901f\u5ea6\u573a\u548c\u6d53\u5ea6\u5206\u5e03\u8fdb\u884c\u7f16\u7801\uff0c\u5e76\u901a\u8fc7\u56fe\u6f5c\u5728\u7a7a\u95f4\u7cfb\u7edf\u52a8\u529b\u5b66\u6a21\u578b\uff08\u53d7\u795e\u7ecfODE\u542f\u53d1\uff09\u9884\u6d4b\u7cfb\u7edf\u52a8\u529b\u5b66\uff0c\u4ee5\u7b80\u5316\u795e\u7ecf\u5143\u6811\u4e2d\u7269\u8d28\u8fd0\u8f93\u7684\u6a21\u62df\u3002", "result": "GALDS\u6a21\u578b\u5b9e\u73b0\u4e863%\u7684\u5e73\u5747\u76f8\u5bf9\u8bef\u5dee\u548c\u4f4e\u4e8e8%\u7684\u6700\u5927\u76f8\u5bf9\u8bef\u5dee\uff0c\u5e76\u4e14\u4e0e\u4e4b\u524d\u7684\u4ee3\u7406\u6a21\u578b\u65b9\u6cd5\u76f8\u6bd4\uff0c\u901f\u5ea6\u63d0\u9ad8\u4e8610\u500d\u3002", "conclusion": "GALDS\u6a21\u578b\u5728\u6a21\u62df\u795e\u7ecf\u5143\u7f51\u7edc\u4e2d\u7684\u7269\u8d28\u8fd0\u8f93\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u57288\u4e2a\u672a\u89c1\u8fc7\u7684\u51e0\u4f55\u7ed3\u6784\u548c4\u4e2a\u5f02\u5e38\u8fd0\u8f93\u793a\u4f8b\u4e0a\uff0c\u5b9e\u73b03%\u7684\u5e73\u5747\u76f8\u5bf9\u8bef\u5dee\u548c\u4f4e\u4e8e8%\u7684\u6700\u5927\u76f8\u5bf9\u8bef\u5dee\uff0c\u540c\u65f6\u5c06\u901f\u5ea6\u63d0\u9ad8\u4e8610\u500d\u3002"}}
{"id": "2507.10557", "categories": ["cond-mat.mtrl-sci", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2507.10557", "abs": "https://arxiv.org/abs/2507.10557", "authors": ["Xianhu Wu", "Gaojie Xia", "Guanglei Cui", "Jieyu Bi", "Nian Liu", "Jiaxin Jiang", "Jilong Sun", "Luyang Liu", "Ping Li", "Ning Lu", "Zewen Zuo", "Min Gu"], "title": "An eco-friendly universal strategy via ribavirin to achieve highly efficient and stable perovskite solar cells", "comment": null, "summary": "The grain boundaries of perovskite films prepared by the solution method are\nhighly disordered, with a large number of defects existing at the grain\nboundaries. These defect sites promote the decomposition of perovskite. Here,\nwe use ribavirin obtained through bacillus subtilis fermentation to regulate\nthe crystal growth of perovskite, inducing changes in the work function and\nenergy level structure of perovskite, which significantly reduces the defect\ndensity. Based on density functional theory calculations, the defect formation\nenergies of VI, VMA, VPb, and PbI in perovskite are improved. This increases\nthe open-circuit voltage of perovskite solar cells (PSCs)\n(ITO/PEDOT:PSS/perovskite/PCBM/BCP/Ag) from 1.077 to 1.151 V, and the PCE\nincreases significantly from 17.05% to 19.86%. Unencapsulated PSCs were stored\nin the environment (humidity approximately 35+-5%) for long-term stability\ntesting. After approximately 900 hours of storage, the PCE of the\nribavirin-based device retains 84.33% of its initial PCE, while the\ncontrol-based device retains only 13.44% of its initial PCE. The PCE of PSCs\n(ITO/SnO2/perovskite/Spiro-OMETAD/Ag) is increased from 20.16% to 22.14%,\ndemonstrating the universality of this doping method. This universal doping\nstrategy provides a new approach for improving the efficiency and stability of\nPSCs using green molecular doping strategies.", "AI": {"tldr": "\u4f7f\u7528\u53d1\u9175\u4ea7\u751f\u7684\u6838\u7cd6\u6838\u9178\u4f5c\u4e3a\u63ba\u6742\u5242\uff0c\u63d0\u9ad8\u9499\u949b\u77ff\u592a\u9633\u80fd\u7535\u6c60\u7684\u6548\u7387\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u9499\u949b\u77ff\u8584\u819c\u4e2d\u7684\u6676\u754c\u6742\u4e71\u4e14\u5b58\u5728\u5927\u91cf\u7f3a\u9677\uff0c\u8fd9\u4e9b\u7f3a\u9677\u4f1a\u4fc3\u8fdb\u9499\u949b\u77ff\u7684\u5206\u89e3\uff0c\u4ece\u800c\u5f71\u54cd\u5668\u4ef6\u7684\u6027\u80fd\u548c\u7a33\u5b9a\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u8c03\u63a7\u6676\u4f53\u751f\u957f\uff0c\u51cf\u5c11\u7f3a\u9677\u5bc6\u5ea6\u3002", "method": "\u4f7f\u7528\u53d1\u9175\u4ea7\u751f\u7684\u6838\u7cd6\u6838\u9178\uff08\u4e00\u79cd\u6765\u81ea\u67af\u8349\u82bd\u5b62\u6746\u83cc\u7684\u5316\u5408\u7269\uff09\u4f5c\u4e3a\u63ba\u6742\u5242\uff0c\u8c03\u63a7\u9499\u949b\u77ff\u8584\u819c\u7684\u6676\u4f53\u751f\u957f\u3002\u901a\u8fc7\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\u8ba1\u7b97\uff0c\u9a8c\u8bc1\u4e86\u6838\u7cd6\u6838\u9178\u80fd\u591f\u63d0\u9ad8\u9499\u949b\u77ff\u4e2dVI\u3001VMA\u3001VPb\u548cPbI\u7684\u7f3a\u9677\u5f62\u6210\u80fd\u3002", "result": "\u4f7f\u7528\u6838\u7cd6\u6838\u9178\u4f5c\u4e3a\u63ba\u6742\u5242\uff0c\u9499\u949b\u77ff\u592a\u9633\u80fd\u7535\u6c60\uff08ITO/PEDOT:PSS/perovskite/PCBM/BCP/Ag\uff09\u7684\u5f00\u8def\u7535\u538b\u4ece1.077V\u63d0\u9ad8\u52301.151V\uff0c\u529f\u7387\u8f6c\u6362\u6548\u7387\uff08PCE\uff09\u4ece17.05%\u63d0\u9ad8\u523019.86%\u3002\u5728\u957f\u671f\u7a33\u5b9a\u6027\u6d4b\u8bd5\u4e2d\uff0c\u7ecf\u8fc7\u7ea6900\u5c0f\u65f6\u7684\u50a8\u5b58\uff0c\u4f7f\u7528\u6838\u7cd6\u6838\u9178\u7684\u5668\u4ef6\u7684PCE\u4ecd\u4fdd\u7559\u4e86\u521d\u59cb\u503c\u768484.33%\uff0c\u800c\u5bf9\u7167\u7ec4\u5668\u4ef6\u4ec5\u4fdd\u755913.44%\u3002\u6b64\u5916\uff0c\u5728\u53e6\u4e00\u79cd\u5668\u4ef6\u7ed3\u6784\uff08ITO/SnO2/perovskite/Spiro-OMETAD/Ag\uff09\u4e2d\uff0cPCE\u4e5f\u4ece20.16%\u63d0\u9ad8\u523022.14%\uff0c\u8bc1\u660e\u4e86\u8be5\u63ba\u6742\u65b9\u6cd5\u7684\u901a\u7528\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u53d1\u9175\u4ea7\u751f\u7684\u6838\u7cd6\u6838\u9178\u6765\u63a7\u5236\u9499\u949b\u77ff\u6676\u4f53\u751f\u957f\u7684\u65b0\u7b56\u7565\uff0c\u8fd9\u79cd\u7b56\u7565\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u9499\u949b\u77ff\u592a\u9633\u80fd\u7535\u6c60\u7684\u6548\u7387\u548c\u7a33\u5b9a\u6027\u3002\u901a\u8fc7\u8c03\u6574\u9499\u949b\u77ff\u7684\u529f\u51fd\u6570\u548c\u80fd\u7ea7\u7ed3\u6784\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u51cf\u5c11\u7f3a\u9677\u5bc6\u5ea6\uff0c\u63d0\u9ad8\u5f00\u8def\u7535\u538b\u548c\u529f\u7387\u8f6c\u6362\u6548\u7387\u3002\u6b64\u5916\uff0c\u8fd9\u79cd\u63ba\u6742\u65b9\u6cd5\u5728\u4e0d\u540c\u5668\u4ef6\u7ed3\u6784\u4e2d\u5747\u8868\u73b0\u51fa\u826f\u597d\u7684\u901a\u7528\u6027\uff0c\u5e76\u4e14\u5728\u957f\u671f\u7a33\u5b9a\u6027\u6d4b\u8bd5\u4e2d\u4e5f\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2507.10732", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2507.10732", "abs": "https://arxiv.org/abs/2507.10732", "authors": ["Jos\u00e9e Desharnais", "Ana Sokolova"], "title": "$\u03b5$-Distance via L\u00e9vy-Prokhorov Lifting", "comment": null, "summary": "The most studied and accepted pseudometric for probabilistic processes is one\nbased on the Kantorovich distance between distributions. It comes with many\ntheoretical and motivating results, in particular it is the fixpoint of a given\nfunctional and defines a functor on (complete) pseudometric spaces.\n  Other notions of behavioural pseudometrics have also been proposed, one of\nthem ($\\epsilon$-distance) based on $\\epsilon$-bisimulation.\n$\\epsilon$-Distance has the advantages that it is intuitively easy to\nunderstand, it relates systems that are conceptually close (for example, an\nimperfect implementation is close to its specification), and it comes equipped\nwith a natural notion of $\\epsilon$-coupling. Finally, this distance is easy to\ncompute.\n  We show that $\\epsilon$-distance is also the greatest fixpoint of a\nfunctional and provides a functor. The latter is obtained by replacing the\nKantorovich distance in the lifting functor with the L\\'evy-Prokhorov distance.\nIn addition, we show that $\\epsilon$-couplings and $\\epsilon$-bisimulations\nhave an appealing coalgebraic characterization.", "AI": {"tldr": "\u03b5-distance \u662f\u4e00\u79cd\u57fa\u4e8e \u03b5-bisimulation \u7684\u884c\u4e3a\u5047\u5ea6\u91cf\uff0c\u5177\u6709\u76f4\u89c2\u3001\u6613\u4e8e\u8ba1\u7b97\u7684\u4f18\u70b9\u3002\u672c\u7814\u7a76\u8868\u660e\uff0c\u5b83\u4e5f\u662f\u4e00\u4e2a\u51fd\u5b50\uff0c\u5e76\u4e14\u4e0e \u03b5-coupling \u548c \u03b5-bisimulation \u5177\u6709\u5171\u4ee3\u6570\u8868\u5f81\u3002", "motivation": " Kantorovich \u8ddd\u79bb\u88ab\u8ba4\u4e3a\u662f\u6982\u7387\u8fc7\u7a0b\u7684\u6700\u4f18\u5047\u5ea6\u91cf\uff0c\u4f46\u03b5-distance \u5728\u53ef\u8ba1\u7b97\u6027\u548c\u76f4\u89c2\u6027\u65b9\u9762\u4e5f\u5177\u6709\u4f18\u52bf\uff0c\u4fc3\u4f7f\u7814\u7a76\u8005\u5bf9\u03b5-distance \u7684\u6027\u8d28\u8fdb\u884c\u66f4\u6df1\u5165\u7684\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u5c06 Kantorovich \u8ddd\u79bb\u66ff\u6362\u4e3a L'evy-Prokhorov \u8ddd\u79bb\uff0c\u4e3a\u03b5-distance\u63d0\u4f9b\u4e86\u51fd\u5b50\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u03b5-distance \u4e5f\u662f\u67d0\u4e2a\u6cdb\u51fd\u7684\u6700\u5927\u4e0d\u52a8\u70b9\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u51fd\u5b50\u3002\u6b64\u5916\uff0c\u03b5-coupling \u548c \u03b5-bisimulation \u5177\u6709\u4ee4\u4eba\u4fe1\u670d\u7684\u5171\u4ee3\u6570\u8868\u5f81\u3002", "conclusion": "\u5c06 L'evy-Prokhorov \u8ddd\u79bb\u66ff\u6362\u5230\u63d0\u5347\u7684\u51fd\u5b50\u4e2d\u7684 Kantorovich \u8ddd\u79bb\uff0c\u53ef\u4ee5\u5f97\u5230\u03b5-distance\uff0c\u5b83\u662f\u67d0\u4e2a\u6cdb\u51fd\u7684\u6700\u5927\u4e0d\u52a8\u70b9\u7684\u51fd\u5b50\u3002"}}
{"id": "2507.11419", "categories": ["cs.GT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11419", "abs": "https://arxiv.org/abs/2507.11419", "authors": ["Anna Lunghi", "Matteo Castiglioni", "Alberto Marchesi"], "title": "Better Regret Rates in Bilateral Trade via Sublinear Budget Violation", "comment": null, "summary": "Bilateral trade is a central problem in algorithmic economics, and recent\nwork has explored how to design trading mechanisms using no-regret learning\nalgorithms. However, no-regret learning is impossible when budget balance has\nto be enforced at each time step. Bernasconi et al. [Ber+24] show how this\nimpossibility can be circumvented by relaxing the budget balance constraint to\nhold only globally over all time steps. In particular, they design an algorithm\nachieving regret of the order of $\\tilde O(T^{3/4})$ and provide a lower bound\nof $\\Omega(T^{5/7})$.\n  In this work, we interpolate between these two extremes by studying how the\noptimal regret rate varies with the allowed violation of the global budget\nbalance constraint. Specifically, we design an algorithm that, by violating the\nconstraint by at most $T^{\\beta}$ for any given $\\beta \\in [\\frac{3}{4},\n\\frac{6}{7}]$, attains regret $\\tilde O(T^{1 - \\beta/3})$. We complement this\nresult with a matching lower bound, thus fully characterizing the trade-off\nbetween regret and budget violation. Our results show that both the $\\tilde\nO(T^{3/4})$ upper bound in the global budget balance case and the\n$\\Omega(T^{5/7})$ lower bound under unconstrained budget balance violation\nobtained by Bernasconi et al. [Ber+24] are tight.", "AI": {"tldr": "\u901a\u8fc7\u653e\u5bbd\u9884\u7b97\u5e73\u8861\u7ea6\u675f\uff0c\u53ef\u4ee5\u5b9e\u73b0\u66f4\u597d\u7684\u9057\u61be\u754c\u3002\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5728 $\\beta \\in [\\frac{3}{4}, \\frac{6}{7}]$ \u8303\u56f4\u5185\uff0c\u9884\u7b97\u8fdd\u53cd\u6700\u591a\u4e3a $T^{\\beta}$ \u65f6\uff0c\u9057\u61be\u754c\u4e3a $\\tilde O(T^{1 - \\beta/3})$ \u7684\u7b97\u6cd5\uff0c\u5e76\u7ed9\u51fa\u4e86\u5339\u914d\u7684\u4e0b\u754c\u3002", "motivation": "\u7814\u7a76\u4e86\u5728\u53cc\u8fb9\u4ea4\u6613\u673a\u5236\u4e2d\uff0c\u5f53\u9884\u7b97\u5e73\u8861\u7ea6\u675f\u88ab\u653e\u5bbd\u65f6\uff0c\u9057\u61be\u4e0e\u9884\u7b97\u8fdd\u53cd\u4e4b\u95f4\u7684\u6743\u8861\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u901a\u8fc7\u5141\u8bb8\u4ee5\u6700\u591a $T^{\\beta}$ \u7684\u65b9\u5f0f\u8fdd\u53cd\u5168\u5c40\u9884\u7b97\u5e73\u8861\u7ea6\u675f\uff08\u5176\u4e2d $\\beta \\in [\\frac{3}{4}, \\frac{6}{7}]$\uff09\uff0c\u5b9e\u73b0\u4e86 $\\tilde O(T^{1 - \\beta/3})$ \u7684\u9057\u61be\u754c\u3002", "result": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u7b97\u6cd5\uff0c\u5176\u9057\u61be\u754c\u4e3a $\\tilde O(T^{1 - \\beta/3})$\uff0c\u5e76\u7ed9\u51fa\u4e86\u5339\u914d\u7684\u4e0b\u754c\uff0c\u5b8c\u5168\u523b\u753b\u4e86\u9057\u61be\u4e0e\u9884\u7b97\u8fdd\u53cd\u4e4b\u95f4\u7684\u6743\u8861\u3002", "conclusion": "\u8be5\u7814\u7a76\u5b8c\u5168\u523b\u753b\u4e86 the trade-off between regret and budget violation\uff0c\u5e76\u8bc1\u660e\u4e86 Bernasconi et al. [Ber+24] \u5f97\u5230\u7684\u754c\u662f\u7d27\u786e\u7684\u3002"}}
{"id": "2507.11390", "categories": ["physics.app-ph"], "pdf": "https://arxiv.org/pdf/2507.11390", "abs": "https://arxiv.org/abs/2507.11390", "authors": ["Bowei Wu", "BoyueSu", "Shuanghuizhi Li", "Tingfeng Ma"], "title": "Realization of Friedrich-Wintgen QBIC with high Q-factors based on acoustic-solid coupling and sensing applications", "comment": null, "summary": "In recent years, bound states in the continuum (BICs) have attracted\nextensive attentions in the sensing field due to their theoretically ultra-high\nresonance quality factors (Q-factors). Among them, Friedrich-Wintgen (F-W)\nBICs, which arise from the interference between different coupled modes, are\nparticularly promising for acoustic sensing applications owing to the easy\nrealization. Most existing F-W BICs are realized in open systems through the\ninterference between waveguides and resonant cavities. However, with increasing\ndemands for higher resolution and sensitivity in modern chemical and biological\nsensing, the practically measured Q-factors of conventional open-system F-W\nBICs often fall short of expectations.In this work, we introduce F-P resonance\nvia acoustic-solid coupling to explore the formation mechanism and realization\nmethod of high-Q F-W BICs in quasi-closed systems, and further investigate\ntheir application in gas sensing. A coupled resonator model combining elastic\nand acoustic waves in a quasi-closed cavity is first established. Coupled mode\ntheory is employed to calculate the eigenmodes of both localized and radiative\nmodes. Based on this, the Hamiltonian matrix of the coupled system is\nconstructed, from which the acoustic transmission spectrum is derived. The\nresults show that the Q-factor of the F-W BIC induced by acoustic-solid\ncoupling is significantly higher than that of open systems, which is further\nvalidated by experiments.Based on this, a gas concentration sensing technique\nbased on acoustic-solid coupled F-W BIC behavior is developed. A sensing device\nis fabricated accordingly, and gas concentration measurements are carried out.\nExperimental results demonstrate a pronounced response to gases with different\nconcentrations, confirming the feasibility and reliability of this novel gas\nsensing approach.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u58f0\u56fa\u8026\u5408F-W BICs\u7684\u6c14\u4f53\u4f20\u611f\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u9ad8Q\u56e0\u5b50\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4e3a\u4e86\u6ee1\u8db3\u73b0\u4ee3\u5316\u5b66\u548c\u751f\u7269\u4f20\u611f\u9886\u57df\u5bf9\u66f4\u9ad8\u5206\u8fa8\u7387\u548c\u7075\u654f\u5ea6\u7684\u9700\u6c42\uff0c\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u4f20\u7edf\u5f00\u653e\u7cfb\u7edfF-W BICs\u7684Q\u56e0\u5b50\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5e76\u63a2\u7d22\u5176\u5728\u6c14\u4f53\u4f20\u611f\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u9996\u5148\u5efa\u7acb\u4e86\u7ed3\u5408\u51c6\u5c01\u95ed\u8154\u5185\u5f39\u6027\u6ce2\u548c\u58f0\u6ce2\u7684\u8026\u5408\u8c10\u632f\u5668\u6a21\u578b\u3002\u7136\u540e\u91c7\u7528\u8026\u5408\u6a21\u5f0f\u7406\u8bba\u8ba1\u7b97\u5c40\u57df\u6a21\u5f0f\u548c\u8f90\u5c04\u6a21\u5f0f\u7684\u672c\u5f81\u6a21\u5f0f\uff0c\u5e76\u6784\u5efa\u8026\u5408\u7cfb\u7edf\u7684\u54c8\u5bc6\u987f\u77e9\u9635\uff0c\u63a8\u5bfc\u51fa\u58f0\u5b66\u900f\u5c04\u8c31\u3002", "result": "\u4e0e\u5f00\u653e\u7cfb\u7edf\u76f8\u6bd4\uff0c\u58f0\u56fa\u8026\u5408\u8bf1\u5bfc\u7684F-W BIC\u7684Q\u56e0\u5b50\u663e\u8457\u63d0\u9ad8\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u3002\u57fa\u4e8e\u6b64\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u58f0\u56fa\u8026\u5408F-W BIC\u884c\u4e3a\u7684\u6c14\u4f53\u6d53\u5ea6\u4f20\u611f\u6280\u672f\uff0c\u5e76\u8fdb\u884c\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u6280\u672f\u5bf9\u4e0d\u540c\u6d53\u5ea6\u7684\u6c14\u4f53\u5177\u6709\u826f\u597d\u7684\u54cd\u5e94\u3002", "conclusion": "\u672c\u5de5\u4f5c\u901a\u8fc7\u58f0\u56fa\u8026\u5408\u5f15\u5165\u6cd5\u5e03\u91cc-\u73c0\u7f57\uff08F-P\uff09\u5171\u632f\uff0c\u63a2\u7d22\u4e86\u51c6\u5c01\u95ed\u7cfb\u7edf\u4e2d\u9ad8Q\u503c\u5f17\u91cc\u5fb7\u91cc\u5e0c-\u6e29\u7279\u6839\uff08F-W\uff09\u675f\u7f1a\u6001\u8fde\u7eed\u4f53\uff08BICs\uff09\u7684\u5f62\u6210\u673a\u5236\u548c\u5b9e\u73b0\u65b9\u6cd5\uff0c\u5e76\u8fdb\u4e00\u6b65\u7814\u7a76\u4e86\u5176\u5728\u6c14\u4f53\u4f20\u611f\u4e2d\u7684\u5e94\u7528\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u58f0\u56fa\u8026\u5408F-W BIC\u884c\u4e3a\u7684\u6c14\u4f53\u4f20\u611f\u6280\u672f\u5177\u6709\u53ef\u884c\u6027\u548c\u53ef\u9760\u6027\uff0c\u80fd\u591f\u5bf9\u4e0d\u540c\u6d53\u5ea6\u7684\u6c14\u4f53\u4ea7\u751f\u663e\u8457\u54cd\u5e94\u3002"}}
{"id": "2507.10656", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2507.10656", "abs": "https://arxiv.org/abs/2507.10656", "authors": ["Masahiro Hoshino", "Yuto Ashida"], "title": "Stabilizer R\u00e9nyi Entropy Encodes Fusion Rules of Topological Defects and Boundaries", "comment": "18 pages, 4 figures. arXiv admin note: substantial text overlap with\n  arXiv:2503.13599", "summary": "We demonstrate that the stabilizer R\\'{e}nyi entropy (SRE), a computable\nmeasure of quantum magic, can serve as an information-theoretic probe for\nuniversal properties associated with conformal defects in one-dimensional\nquantum critical systems. Using boundary conformal field theory, we show that\nopen boundaries manifest as a universal logarithmic correction to the SRE,\nwhereas topological defects yield a universal size-independent term. When\nmultiple defects are present, we find that the universal terms in the SRE\nfaithfully reflect the defect-fusion rules that define noninvertible symmetry\nalgebra. These analytical predictions are corroborated by numerical\ncalculations of the Ising model, where boundaries and topological defects are\ndescribed by Cardy states and Verlinde lines, respectively.", "AI": {"tldr": "SRE\u53ef\u7528\u4e8e\u7814\u7a76\u91cf\u5b50\u4e34\u754c\u7cfb\u7edf\u4e2d\u7684\u7f3a\u9677\u3002\u5f00\u653e\u8fb9\u754c\u548c\u62d3\u6251\u7f3a\u9677\u5728SRE\u4e2d\u4ea7\u751f\u7279\u5b9a\u7684\u4fee\u6b63\uff0cSRE\u8fd8\u80fd\u53cd\u6620\u7f3a\u9677\u878d\u5408\u89c4\u5219\u3002Ising\u6a21\u578b\u6570\u503c\u8ba1\u7b97\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u53d1\u73b0\u3002", "motivation": "\u63a2\u7d22SRE\uff08\u53ef\u8ba1\u7b97\u7684\u91cf\u5b50\u9b54\u6027\u5ea6\u91cf\uff09\u4f5c\u4e3a\u4fe1\u606f\u8bba\u63a2\u9488\uff0c\u7528\u4e8e\u7814\u7a76\u4e00\u7ef4\u91cf\u5b50\u4e34\u754c\u7cfb\u7edf\u4e2d\u6e10\u8fd1\u7f3a\u9677\u7684\u666e\u9002\u6027\u8d28\u3002", "method": "\u5229\u7528\u8fb9\u754c\u5171\u5f62\u573a\u8bba\uff0c\u63a8\u5bfcSRE\u4e0e\u5f00\u653e\u8fb9\u754c\uff08\u5bf9\u6570\u4fee\u6b63\uff09\u548c\u62d3\u6251\u7f3a\u9677\uff08\u5c3a\u5bf8\u65e0\u5173\u9879\uff09\u7684\u5173\u7cfb\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u8ba1\u7b97\uff08Ising\u6a21\u578b\uff09\u9a8c\u8bc1\u7406\u8bba\u9884\u6d4b\u3002", "result": "\u5f00\u653e\u8fb9\u754c\u5bfc\u81f4SRE\u51fa\u73b0\u666e\u9002\u5bf9\u6570\u4fee\u6b63\uff0c\u62d3\u6251\u7f3a\u9677\u4ea7\u751f\u666e\u9002\u5c3a\u5bf8\u65e0\u5173\u9879\u3002\u591a\u4e2a\u7f3a\u9677\u7684\u5b58\u5728\u4f7f\u5f97SRE\u4e2d\u7684\u666e\u9002\u9879\u80fd\u591f\u7cbe\u786e\u53cd\u6620\u5b9a\u4e49\u975e\u53ef\u9006\u5bf9\u79f0\u4ee3\u6570\u7684\u7f3a\u9677\u878d\u5408\u89c4\u5219\u3002", "conclusion": "SRE\u53ef\u4f5c\u4e3a\u63a2\u9488\uff0c\u7528\u4e8e\u7814\u7a76\u4e00\u7ef4\u91cf\u5b50\u4e34\u754c\u7cfb\u7edf\u4e2d\u6e10\u8fd1\u7f3a\u9677\u7684\u666e\u9002\u6027\u8d28\uff0c\u7279\u522b\u662f\u5f00\u653e\u8fb9\u754c\u548c\u62d3\u6251\u7f3a\u9677\u5728SRE\u4e2d\u8868\u73b0\u4e3a\u7279\u5b9a\u7684\u666e\u9002\u4fee\u6b63\u9879\uff0c\u4e14SRE\u80fd\u53cd\u6620\u7f3a\u9677\u878d\u5408\u89c4\u5219\uff08\u975e\u53ef\u9006\u5bf9\u79f0\u4ee3\u6570\uff09\u3002"}}
{"id": "2507.10737", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10737", "abs": "https://arxiv.org/abs/2507.10737", "authors": ["Jiayuan Chen", "Thai-Hoang Pham", "Yuanlong Wang", "Ping Zhang"], "title": "Integrating Biological Knowledge for Robust Microscopy Image Profiling on De Novo Cell Lines", "comment": "ICCV 2025", "summary": "High-throughput screening techniques, such as microscopy imaging of cellular\nresponses to genetic and chemical perturbations, play a crucial role in drug\ndiscovery and biomedical research. However, robust perturbation screening for\n\\textit{de novo} cell lines remains challenging due to the significant\nmorphological and biological heterogeneity across cell lines. To address this,\nwe propose a novel framework that integrates external biological knowledge into\nexisting pretraining strategies to enhance microscopy image profiling models.\nOur approach explicitly disentangles perturbation-specific and cell\nline-specific representations using external biological information.\nSpecifically, we construct a knowledge graph leveraging protein interaction\ndata from STRING and Hetionet databases to guide models toward\nperturbation-specific features during pretraining. Additionally, we incorporate\ntranscriptomic features from single-cell foundation models to capture cell\nline-specific representations. By learning these disentangled features, our\nmethod improves the generalization of imaging models to \\textit{de novo} cell\nlines. We evaluate our framework on the RxRx database through one-shot\nfine-tuning on an RxRx1 cell line and few-shot fine-tuning on cell lines from\nthe RxRx19a dataset. Experimental results demonstrate that our method enhances\nmicroscopy image profiling for \\textit{de novo} cell lines, highlighting its\neffectiveness in real-world phenotype-based drug discovery applications.", "AI": {"tldr": "\u901a\u8fc7\u6574\u5408\u77e5\u8bc6\u56fe\u8c31\u548c\u8f6c\u5f55\u7ec4\u5b66\u7279\u5f81\uff0c\u63d0\u51fa\u65b0\u6846\u67b6\u63d0\u5347\u663e\u5fae\u6210\u50cf\u6a21\u578b\u5728\u65b0\u7ec6\u80de\u7cfb\u4e0a\u7684\u6027\u80fd\uff0c\u7528\u4e8e\u836f\u7269\u53d1\u73b0\u3002", "motivation": "\u89e3\u51b3\u9ad8\u901a\u91cf\u7b5b\u9009\u6280\u672f\u5728\u5904\u7406\u5177\u6709\u663e\u8457\u5f62\u6001\u548c\u751f\u7269\u5f02\u8d28\u6027\u7684\u65b0\u578b\u7ec6\u80de\u7cfb\u65f6\u6240\u9762\u4e34\u7684\u6311\u6218\uff0c\u4ee5\u63d0\u9ad8\u6a21\u578b\u5728\u65b0\u578b\u7ec6\u80de\u7cfb\u4e0a\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6574\u5408\u5916\u90e8\u751f\u7269\u5b66\u77e5\u8bc6\u5230\u9884\u8bad\u7ec3\u7b56\u7565\u7684\u65b0\u6846\u67b6\uff0c\u5229\u7528\u86cb\u767d\u8d28\u76f8\u4e92\u4f5c\u7528\u6570\u636e\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u4ee5\u5206\u79bb\u6270\u52a8\u7279\u5f81\uff0c\u5e76\u7ed3\u5408\u5355\u7ec6\u80de\u8f6c\u5f55\u7ec4\u5b66\u7279\u5f81\u4ee5\u6355\u6349\u7ec6\u80de\u7cfb\u7279\u5f02\u6027\u8868\u793a\u3002", "result": "\u5728RxRx\u6570\u636e\u5e93\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u901a\u8fc7\u5355\u6837\u672c\u5fae\u8c03\u548c\u5c11\u6837\u672c\u5fae\u8c03\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u65b0\u578b\u7ec6\u80de\u7cfb\u7684\u663e\u5fae\u6210\u50cf\u5206\u6790\u80fd\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u6574\u5408\u5916\u90e8\u751f\u7269\u5b66\u77e5\u8bc6\u548c\u9884\u8bad\u7ec3\u7b56\u7565\uff0c\u6210\u529f\u63d0\u5347\u4e86\u6210\u50cf\u6a21\u578b\u5728\u65b0\u578b\u7ec6\u80de\u7cfb\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5728\u57fa\u4e8e\u8868\u578b\u7684\u836f\u7269\u53d1\u73b0\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.10566", "categories": ["cs.AI", "cs.GT", "cs.LG", "cs.MA", "cs.NE", "68T07, 68T40, 91A20", "I.2.6; I.2.11; I.2.4"], "pdf": "https://arxiv.org/pdf/2507.10566", "abs": "https://arxiv.org/abs/2507.10566", "authors": ["Hung Ming Liu"], "title": "AI Mother Tongue: Self-Emergent Communication in MARL via Endogenous Symbol Systems", "comment": "30 pages, 4 figures", "summary": "In Decentralized Multi-Agent Reinforcement Learning (MARL), the development\nof Emergent Communication has long been constrained by the ``Joint Exploration\nDilemma'', leading agents to fall into a ``Communication Vacuum Equilibrium'' .\nTraditional methods address this by introducing inductive biases to facilitate\ncommunication emergence . This study fundamentally questions whether such\nartificial inductive biases are, in fact, over-engineering. Through experiments\nwith the ``AI Mother Tongue'' (AIM) framework, based on a Vector Quantized\nVariational Autoencoder (VQ-VAE), we demonstrate that when agents possess an\nendogenous symbol system, their neural representations naturally exhibit\nspontaneous semantic compression and Nash equilibrium-driven semantic\nconvergence, achieving effective symbolic communication without external\ninductive biases. This aligns with recent neuroscience findings suggesting that\nthe human brain does not directly use human language for internal thought , and\nresonates with research on ``soft thinking'' capabilities in Large Language\nModels (LLMs) . Compared to traditional explicit communication methods, AIM\ndemonstrates stronger generality and efficiency. The interpretable analysis\ntoolkit developed in this study confirms that symbol usage exhibits a\nsignificant power-law distribution, leading to three major theoretical\ninsights: the ``Neural Communication Hypothesis'', the ``Tool-First\nPrinciple'', and the ``Semantic Interpretability Paradigm''. Future research\nwill explore the integration of Hierarchical Quantized Variational Autoencoders\n(HQ-VAE) to enhance AIM's complex expressive capabilities and investigate the\npotential for ``Reinforcement Learning (RL) Low-Level Pre-training''. This\ndiscovery offers new avenues for bridging symbolism and connectionism.", "AI": {"tldr": "AIM\u6846\u67b6\u901a\u8fc7\u5185\u751f\u7b26\u53f7\u7cfb\u7edf\u89e3\u51b3MARL\u901a\u4fe1\u56f0\u5883\uff0c\u65e0\u9700\u5916\u90e8\u504f\u5dee\uff0c\u5b9e\u73b0\u9ad8\u6548\u901a\u4fe1\uff0c\u5e76\u63d0\u51fa\u4e09\u5927\u7406\u8bba\u89c1\u89e3\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5206\u5e03\u5f0f\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08MARL\uff09\u4e2d\u201c\u8054\u5408\u63a2\u7d22\u56f0\u5883\u201d\u5bfc\u81f4\u667a\u80fd\u4f53\u9677\u5165\u201c\u901a\u4fe1\u771f\u7a7a\u5747\u8861\u201d\u7684\u95ee\u9898\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u662f\u5426\u53ef\u4ee5\u4e0d\u4f9d\u8d56\u4f20\u7edf\u7684\u5916\u90e8\u5f52\u7eb3\u504f\u5dee\uff0c\u800c\u662f\u901a\u8fc7\u667a\u80fd\u4f53\u81ea\u8eab\u7684\u5185\u751f\u7b26\u53f7\u7cfb\u7edf\u6765\u5b9e\u73b0\u901a\u4fe1\u7684\u6d8c\u73b0\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528AI Mother Tongue\uff08AIM\uff09\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u57fa\u4e8e\u5411\u91cf\u91cf\u5316\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VQ-VAE\uff09\uff0c\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5728\u667a\u80fd\u4f53\u62e5\u6709\u5185\u751f\u7b26\u53f7\u7cfb\u7edf\u65f6\uff0c\u5176\u795e\u7ecf\u8868\u5f81\u80fd\u591f\u81ea\u53d1\u5730\u8fdb\u884c\u8bed\u4e49\u538b\u7f29\u548c\u7ecf\u5386Nash\u5747\u8861\u9a71\u52a8\u7684\u8bed\u4e49\u6536\u655b\uff0c\u4ece\u800c\u5728\u65e0\u9700\u5916\u90e8\u5f52\u7eb3\u504f\u5dee\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u6709\u6548\u7684\u7b26\u53f7\u901a\u4fe1\u3002\u7814\u7a76\u8fd8\u5f00\u53d1\u4e86\u53ef\u89e3\u91ca\u6027\u5206\u6790\u5de5\u5177\uff0c\u4ee5\u9a8c\u8bc1\u7b26\u53f7\u4f7f\u7528\u5448\u73b0\u51fa\u663e\u8457\u7684\u5e42\u5f8b\u5206\u5e03\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5f53\u667a\u80fd\u4f53\u62e5\u6709\u5185\u751f\u7b26\u53f7\u7cfb\u7edf\u65f6\uff0c\u5176\u795e\u7ecf\u8868\u5f81\u80fd\u591f\u81ea\u53d1\u5730\u5b9e\u73b0\u8bed\u4e49\u538b\u7f29\u548cNash\u5747\u8861\u9a71\u52a8\u7684\u8bed\u4e49\u6536\u655b\uff0c\u6709\u6548\u8fbe\u6210\u7b26\u53f7\u901a\u4fe1\uff0c\u4e14\u65e0\u9700\u5916\u90e8\u5f52\u7eb3\u504f\u5dee\u3002AIM\u6846\u67b6\u76f8\u6bd4\u4f20\u7edf\u7684\u663e\u5f0f\u901a\u4fe1\u65b9\u6cd5\uff0c\u5c55\u73b0\u51fa\u66f4\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6548\u7387\u3002\u5206\u6790\u5de5\u5177\u8bc1\u5b9e\u4e86\u7b26\u53f7\u4f7f\u7528\u7684\u5e42\u5f8b\u5206\u5e03\u7279\u6027\uff0c\u5e76\u5f15\u51fa\u4e86\u4e09\u4e2a\u7406\u8bba\u89c1\u89e3\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201cAI\u6bcd\u8bed\u201d\uff08AIM\uff09\u7684\u6846\u67b6\uff0c\u57fa\u4e8e\u5411\u91cf\u91cf\u5316\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VQ-VAE\uff09\uff0c\u8bc1\u660e\u4e86\u5728\u62e5\u6709\u5185\u751f\u7b26\u53f7\u7cfb\u7edf\u7684\u6761\u4ef6\u4e0b\uff0c\u667a\u80fd\u4f53\u80fd\u591f\u81ea\u53d1\u5730\u5b9e\u73b0\u8bed\u4e49\u538b\u7f29\u548c\u6536\u655b\uff0c\u4ece\u800c\u5728\u6ca1\u6709\u5916\u90e8\u5f52\u7eb3\u504f\u5dee\u7684\u60c5\u51b5\u4e0b\u8fbe\u6210\u6709\u6548\u7684\u7b26\u53f7\u4ea4\u6d41\u3002\u7814\u7a76\u7ed3\u679c\u4e0e\u795e\u7ecf\u79d1\u5b66\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7814\u7a76\u53d1\u73b0\u76f8\u547c\u5e94\uff0c\u5e76\u63d0\u51fa\u4e86\u201c\u795e\u7ecf\u901a\u4fe1\u5047\u8bf4\u201d\u3001\u201c\u5de5\u5177\u4f18\u5148\u539f\u5219\u201d\u548c\u201c\u8bed\u4e49\u53ef\u89e3\u91ca\u8303\u5f0f\u201d\u4e09\u4e2a\u7406\u8bba\u89c1\u89e3\uff0c\u4e3a\u8fde\u63a5\u7b26\u53f7\u4e3b\u4e49\u548c\u8054\u7ed3\u4e3b\u4e49\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.10580", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.10580", "abs": "https://arxiv.org/abs/2507.10580", "authors": ["Vimaleswar A", "Prabhu Nandan Sahu", "Nilesh Kumar Sahu", "Haroon R Lone"], "title": "An Offline Mobile Conversational Agent for Mental Health Support: Learning from Emotional Dialogues and Psychological Texts with Student-Centered Evaluation", "comment": null, "summary": "Mental health plays a crucial role in the overall well-being of an\nindividual. In recent years, digital platforms have been increasingly used to\nexpand mental health and emotional support. However, there are persistent\nchallenges related to limited user accessibility, internet connectivity, and\ndata privacy, which highlight the need for an offline, smartphone-based\nsolution. To address these challenges, we propose EmoSApp (Emotional Support\nApp): an entirely offline, smartphone-based conversational app designed for\nmental health and emotional support. The system leverages Large Language Models\n(LLMs), specifically fine-tuned, quantized and deployed using Torchtune and\nExecutorch for resource-constrained devices, allowing all inferences to occur\non the smartphone. To equip EmoSApp with robust domain expertise, we fine-tuned\nthe LLaMA-3.2-1B-Instruct model on our custom curated ``Knowledge dataset'' of\n14,582 mental-health QA pairs, along with the multi-turn conversational data.\n  Through qualitative human evaluation with the student population, we\ndemonstrate that EmoSApp has the ability to respond coherently, empathetically,\nmaintain interactive dialogue, and provide relevant suggestions to user's\nmental health problems. Additionally, quantitative evaluations on nine standard\ncommonsense and reasoning benchmarks demonstrate the efficacy of our\nfine-tuned, quantized model in low-resource settings. By prioritizing on-device\ndeployment and specialized domain adaptation, EmoSApp serves as a blueprint for\nfuture innovations in portable, secure, and highly tailored AI-driven mental\nhealth solutions.", "AI": {"tldr": "EmoSApp \u662f\u4e00\u6b3e\u521b\u65b0\u7684\u79bb\u7ebf\u667a\u80fd\u624b\u673a\u5e94\u7528\uff0c\u5229\u7528\u5fae\u8c03\u7684 LLM \u63d0\u4f9b\u5b89\u5168\u3001\u4e2a\u6027\u5316\u7684\u5fc3\u7406\u5065\u5eb7\u652f\u6301\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6570\u5b57\u5e73\u53f0\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u6570\u5b57\u5fc3\u7406\u5065\u5eb7\u548c\u60c5\u611f\u652f\u6301\u5e73\u53f0\u5b58\u5728\u7528\u6237\u53ef\u53ca\u6027\u3001\u7f51\u7edc\u8fde\u63a5\u548c\u6570\u636e\u9690\u79c1\u65b9\u9762\u7684\u9650\u5236\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u7684\u79bb\u7ebf\u3001\u57fa\u4e8e\u667a\u80fd\u624b\u673a\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u540d\u4e3a EmoSApp \u7684\u79bb\u7ebf\u3001\u57fa\u4e8e\u667a\u80fd\u624b\u673a\u7684\u5bf9\u8bdd\u5e94\u7528\u7a0b\u5e8f\uff0c\u7528\u4e8e\u63d0\u4f9b\u5fc3\u7406\u5065\u5eb7\u548c\u60c5\u611f\u652f\u6301\u3002\u8be5\u7cfb\u7edf\u5229\u7528\u4e86\u7ecf\u8fc7 Torchtune \u548c Executorch \u5fae\u8c03\u3001\u91cf\u5316\u548c\u90e8\u7f72\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM)\uff0c\u4ee5\u786e\u4fdd\u6240\u6709\u63a8\u7406\u90fd\u5728\u667a\u80fd\u624b\u673a\u4e0a\u8fdb\u884c\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5bf9 LLaMA-3.2-1B-Instruct \u6a21\u578b\u8fdb\u884c\u4e86\u5fae\u8c03\uff0c\u4f7f\u7528\u4e86\u5305\u542b 14,582 \u4e2a\u5fc3\u7406\u5065\u5eb7\u95ee\u7b54\u5bf9\u7684\u81ea\u5b9a\u4e49\u201c\u77e5\u8bc6\u6570\u636e\u96c6\u201d\u4ee5\u53ca\u591a\u8f6e\u5bf9\u8bdd\u6570\u636e\u3002", "result": "EmoSApp \u5728\u5b66\u751f\u4eba\u7fa4\u4e2d\u7684\u5b9a\u6027\u4eba\u7c7b\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u5e94\u7528\u80fd\u591f\u505a\u51fa\u8fde\u8d2f\u3001\u5bcc\u6709\u540c\u60c5\u5fc3\u7684\u56de\u5e94\uff0c\u7ef4\u6301\u4e92\u52a8\u5bf9\u8bdd\uff0c\u5e76\u4e3a\u7528\u6237\u7684\u5fc3\u7406\u5065\u5eb7\u95ee\u9898\u63d0\u4f9b\u76f8\u5173\u5efa\u8bae\u3002\u6b64\u5916\uff0c\u5728\u4e5d\u4e2a\u6807\u51c6\u5e38\u8bc6\u548c\u63a8\u7406\u57fa\u51c6\u4e0a\u7684\u5b9a\u91cf\u8bc4\u4f30\u8bc1\u660e\u4e86\u7ecf\u8fc7\u5fae\u8c03\u3001\u91cf\u5316\u7684\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u7684\u6709\u6548\u6027\u3002", "conclusion": "EmoSApp \u4f5c\u4e3a\u4e00\u4e2a\u5b8c\u5168\u79bb\u7ebf\u3001\u57fa\u4e8e\u667a\u80fd\u624b\u673a\u7684\u5bf9\u8bdd\u5e94\u7528\u7a0b\u5e8f\uff0c\u4e3a\u5fc3\u7406\u5065\u5eb7\u548c\u60c5\u611f\u652f\u6301\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002\u5b83\u901a\u8fc7\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u90e8\u7f72\u7ecf\u8fc7\u5fae\u8c03\u3001\u91cf\u5316\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u7528\u6237\u53ef\u53ca\u6027\u3001\u7f51\u7edc\u8fde\u63a5\u548c\u6570\u636e\u9690\u79c1\u7b49\u6311\u6218\u3002\u8be5\u5e94\u7528\u5728\u5b9a\u6027\u548c\u5b9a\u91cf\u8bc4\u4f30\u4e2d\u5747\u8868\u73b0\u51fa\u826f\u597d\u7684\u6548\u679c\uff0c\u80fd\u591f\u8fdb\u884c\u8fde\u8d2f\u3001\u5bcc\u6709\u540c\u60c5\u5fc3\u7684\u4e92\u52a8\uff0c\u5e76\u63d0\u4f9b\u76f8\u5173\u7684\u5fc3\u7406\u5065\u5eb7\u5efa\u8bae\uff0c\u4e3a\u672a\u6765\u4fbf\u643a\u3001\u5b89\u5168\u3001\u5b9a\u5236\u5316\u7684 AI \u5fc3\u7406\u5065\u5eb7\u89e3\u51b3\u65b9\u6848\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.10561", "categories": ["cs.NE", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10561", "abs": "https://arxiv.org/abs/2507.10561", "authors": ["Alessio Caviglia", "Filippo Marostica", "Alessio Carpegna", "Alessandro Savino", "Stefano Di Carlo"], "title": "SFATTI: Spiking FPGA Accelerator for Temporal Task-driven Inference -- A Case Study on MNIST", "comment": null, "summary": "Hardware accelerators are essential for achieving low-latency,\nenergy-efficient inference in edge applications like image recognition. Spiking\nNeural Networks (SNNs) are particularly promising due to their event-driven and\ntemporally sparse nature, making them well-suited for low-power Field\nProgrammable Gate Array (FPGA)-based deployment. This paper explores using the\nopen-source Spiker+ framework to generate optimized SNNs accelerators for\nhandwritten digit recognition on the MNIST dataset. Spiker+ enables high-level\nspecification of network topologies, neuron models, and quantization,\nautomatically generating deployable HDL. We evaluate multiple configurations\nand analyze trade-offs relevant to edge computing constraints.", "AI": {"tldr": "\u672c\u6587\u5229\u7528Spiker+\u6846\u67b6\u4e3aMNIST\u624b\u5199\u6570\u5b57\u8bc6\u522b\u751f\u6210SNN\u52a0\u901f\u5668\uff0c\u63a2\u8ba8\u4e86\u4e0d\u540c\u914d\u7f6e\u7684\u4f18\u7f3a\u70b9\uff0c\u4ee5\u6ee1\u8db3\u8fb9\u7f18\u8ba1\u7b97\u7684\u4f4e\u529f\u8017\u548c\u4f4e\u5ef6\u8fdf\u9700\u6c42\u3002", "motivation": "\u4e3a\u4e86\u5728\u8fb9\u7f18\u5e94\u7528\uff08\u5982\u56fe\u50cf\u8bc6\u522b\uff09\u4e2d\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u80fd\u6548\u63a8\u7406\uff0c\u9700\u8981\u786c\u4ef6\u52a0\u901f\u5668\u3002SNN\u56e0\u5176\u4e8b\u4ef6\u9a71\u52a8\u548c\u65f6\u95f4\u7a00\u758f\u7684\u7279\u6027\uff0c\u975e\u5e38\u9002\u5408\u4f4e\u529f\u8017FPGA\u90e8\u7f72\u3002", "method": "\u672c\u6587\u4f7f\u7528Spiker+\u6846\u67b6\uff0c\u901a\u8fc7HLS\u89c4\u8303\u7f51\u7edc\u62d3\u6251\u3001\u795e\u7ecf\u5143\u6a21\u578b\u548c\u91cf\u5316\uff0c\u81ea\u52a8\u751f\u6210SNN\u52a0\u901f\u5668\uff0c\u5e76\u5728MNIST\u6570\u636e\u96c6\u4e0a\u624b\u5199\u6570\u5b57\u8bc6\u522b\u4efb\u52a1\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u901a\u8fc7\u8bc4\u4f30\u591a\u79cd\u914d\u7f6e\uff0c\u5206\u6790\u4e86\u4e0e\u8fb9\u7f18\u8ba1\u7b97\u7ea6\u675f\u76f8\u5173\u7684\u6743\u8861\u3002", "conclusion": "\u786c\u4ef6\u52a0\u901f\u5668\u5bf9\u4e8e\u5728\u56fe\u50cf\u8bc6\u522b\u7b49\u8fb9\u7f18\u5e94\u7528\u4e2d\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u80fd\u6548\u63a8\u7406\u81f3\u5173\u91cd\u8981\u3002\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\uff08SNN\uff09\u7531\u4e8e\u5176\u4e8b\u4ef6\u9a71\u52a8\u548c\u65f6\u95f4\u7a00\u758f\u7684\u7279\u6027\uff0c\u7279\u522b\u6709\u524d\u666f\uff0c\u975e\u5e38\u9002\u5408\u4f4e\u529f\u8017\u57fa\u4e8eFPGA\u7684\u90e8\u7f72\u3002\u672c\u6587\u63a2\u8ba8\u4f7f\u7528\u5f00\u6e90Spiker+\u6846\u67b6\u4e3aMNIST\u6570\u636e\u96c6\u4e0a\u7684\u624b\u5199\u6570\u5b57\u8bc6\u522b\u751f\u6210\u4f18\u5316\u7684SNN\u52a0\u901f\u5668\u3002Spiker+\u652f\u6301\u7f51\u7edc\u62d3\u6251\u3001\u795e\u7ecf\u5143\u6a21\u578b\u548c\u91cf\u5316\u7684 HLS \u89c4\u8303\uff0c\u53ef\u81ea\u52a8\u751f\u6210\u53ef\u90e8\u7f72\u7684HDL\u3002"}}
{"id": "2507.10789", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2507.10789", "abs": "https://arxiv.org/abs/2507.10789", "authors": ["Aaron Jarmusch", "Nathan Graddon", "Sunita Chandrasekaran"], "title": "Dissecting the NVIDIA Blackwell Architecture with Microbenchmarks", "comment": null, "summary": "The rapid development in scientific research provides a need for more compute\npower, which is partly being solved by GPUs. This paper presents a\nmicroarchitectural analysis of the modern NVIDIA Blackwell architecture by\nstudying GPU performance\n  features with thought through microbenchmarks. We unveil key subsystems,\nincluding the memory hierarchy, SM execution\n  pipelines, and the SM sub-core units, including the 5th generation tensor\ncores supporting FP4 and FP6 precisions.\n  To understand the different key features of the NVIDIA GPU, we study latency,\nthroughput, cache behavior, and scheduling\n  details, revealing subtle tuning metrics in the design of Blackwell. To\ndevelop a comprehensive analysis, we compare the\n  Blackwell architecture with the previous Hopper architecture by using the\nGeForce RTX 5080 and H100 PCIe, respectively. We\n  evaluate and compare results, presenting both generational improvements and\nperformance regressions. Additionally, we\n  investigate the role of power efficiency and energy consumption under varied\nworkloads. Our findings provide actionable insights\n  for application developers, compiler writers, and performance engineers to\noptimize workloads on Blackwell-based platforms,\n  and contribute new data to the growing research on GPU architectures.", "AI": {"tldr": "\u672c\u7814\u7a76\u5bf9NVIDIA Blackwell GPU\u67b6\u6784\u8fdb\u884c\u4e86\u8be6\u5c3d\u7684\u5fae\u67b6\u6784\u5206\u6790\uff0c\u901a\u8fc7\u4e0eHopper\u67b6\u6784\u7684\u5bf9\u6bd4\uff0c\u63ed\u793a\u4e86\u5176\u5173\u952e\u6027\u80fd\u7279\u5f81\u3001\u4ee3\u9645\u6539\u8fdb\u53ca\u529f\u8017\u8868\u73b0\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u4f18\u5316\u6307\u5bfc\u3002", "motivation": "\u968f\u7740\u79d1\u5b66\u7814\u7a76\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u5bf9\u8ba1\u7b97\u80fd\u529b\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0cGPU\u5728\u6ee1\u8db3\u8fd9\u4e00\u9700\u6c42\u65b9\u9762\u53d1\u6325\u7740\u5173\u952e\u4f5c\u7528\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u5bf9\u73b0\u4ee3NVIDIA Blackwell GPU\u67b6\u6784\u8fdb\u884c\u6df1\u5165\u7684\u5fae\u67b6\u6784\u5206\u6790\uff0c\u4ee5\u4e86\u89e3\u5176\u6027\u80fd\u7279\u5f81\u3001\u6539\u8fdb\u4e4b\u5904\u4ee5\u53ca\u4e3a\u4f18\u5316\u5de5\u4f5c\u8d1f\u8f7d\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u5fae\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5bf9NVIDIA Blackwell GPU\u67b6\u6784\u8fdb\u884c\u4e86\u7ec6\u81f4\u7684\u5fae\u67b6\u6784\u5206\u6790\uff0c\u7814\u7a76\u4e86\u5176\u6027\u80fd\u7279\u5f81\uff0c\u5305\u62ec\u5ef6\u8fdf\u3001\u541e\u5410\u91cf\u3001\u7f13\u5b58\u884c\u4e3a\u548c\u8c03\u5ea6\u7ec6\u8282\u3002\u5c06Blackwell\u67b6\u6784\u4e0eHopper\u67b6\u6784\u8fdb\u884c\u4e86\u5bf9\u6bd4\u5206\u6790\uff0c\u5e76\u8bc4\u4f30\u4e86\u529f\u8017\u6548\u7387\u548c\u80fd\u8017\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86Blackwell\u67b6\u6784\u7684\u5173\u952e\u5b50\u7cfb\u7edf\u7ec6\u8282\uff0c\u5305\u62ec\u5185\u5b58\u5c42\u6b21\u7ed3\u6784\u3001SM\u6267\u884c\u6d41\u6c34\u7ebf\u548cSM\u5b50\u6838\u5fc3\u5355\u5143\uff08\u5982\u7b2c\u4e94\u4ee3Tensor Core\uff09\u3002\u901a\u8fc7\u4e0eHopper\u67b6\u6784\u7684\u5bf9\u6bd4\uff0c\u8bc4\u4f30\u4e86\u4ee3\u9645\u6539\u8fdb\u548c\u6027\u80fd\u56de\u5f52\u3002\u6b64\u5916\uff0c\u8fd8\u7814\u7a76\u4e86\u529f\u8017\u6548\u7387\u548c\u80fd\u8017\u3002\u7814\u7a76\u7ed3\u679c\u4e3a\u4f18\u5316Blackwell\u5e73\u53f0\u4e0a\u7684\u5de5\u4f5c\u8d1f\u8f7d\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u5bf9NVIDIA Blackwell\u67b6\u6784\u8fdb\u884c\u5fae\u57fa\u51c6\u6d4b\u8bd5\u548c\u6027\u80fd\u5206\u6790\uff0c\u63ed\u793a\u4e86\u5176\u5173\u952e\u5b50\u7cfb\u7edf\uff08\u5305\u62ec\u5185\u5b58\u5c42\u6b21\u7ed3\u6784\u3001SM\u6267\u884c\u6d41\u6c34\u7ebf\u548cSM\u5b50\u6838\u5fc3\u5355\u5143\uff0c\u7279\u522b\u662f\u652f\u6301FP4\u548cFP6\u7cbe\u5ea6\u7684\u7b2c\u4e94\u4ee3Tensor Core\uff09\u7684\u7ec6\u8282\u3002\u901a\u8fc7\u5bf9\u6bd4Blackwell\u4e0eHopper\u67b6\u6784\uff08\u5206\u522b\u4f7f\u7528GeForce RTX 5080\u548cH100 PCIe\uff09\uff0c\u7814\u7a76\u8bc4\u4f30\u4e86\u4ee3\u9645\u6539\u8fdb\u548c\u6027\u80fd\u56de\u5f52\uff0c\u5e76\u63a2\u8ba8\u4e86\u529f\u8017\u6548\u7387\u548c\u80fd\u8017\u3002\u7814\u7a76\u7ed3\u679c\u4e3aBlackwell\u5e73\u53f0\u7684\u5e94\u7528\u7a0b\u5e8f\u5f00\u53d1\u8005\u3001\u7f16\u8bd1\u5668\u7f16\u5199\u8005\u548c\u6027\u80fd\u5de5\u7a0b\u5e08\u63d0\u4f9b\u4e86\u4f18\u5316\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5b9e\u7528\u89c1\u89e3\uff0c\u5e76\u4e3aGPU\u67b6\u6784\u7814\u7a76\u8d21\u732e\u4e86\u65b0\u7684\u6570\u636e\u3002"}}
{"id": "2507.10833", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2507.10833", "abs": "https://arxiv.org/abs/2507.10833", "authors": ["Arpon Basu", "Jun-Ting Hsieh", "Andrew D. Lin", "Peter Manohar"], "title": "Solving Random Planted CSPs below the $n^{k/2}$ Threshold", "comment": null, "summary": "We present a family of algorithms to solve random planted instances of any\n$k$-ary Boolean constraint satisfaction problem (CSP). A randomly planted\ninstance of a Boolean CSP is generated by (1) choosing an arbitrary planted\nassignment $x^*$, and then (2) sampling constraints from a particular \"planting\ndistribution\" designed so that $x^*$ will satisfy every constraint. Given an\n$n$ variable instance of a $k$-ary Boolean CSP with $m$ constraints, our\nalgorithm runs in time $n^{O(\\ell)}$ for a choice of a parameter $\\ell$, and\nsucceeds in outputting a satisfying assignment if $m \\geq O(n) \\cdot\n(n/\\ell)^{\\frac{k}{2} - 1} \\log n$. This generalizes the\n$\\mathrm{poly}(n)$-time algorithm of [FPV15], the case of $\\ell = O(1)$, to\nlarger runtimes, and matches the constraint number vs.\\ runtime trade-off\nestablished for refuting random CSPs by [RRS17].\n  Our algorithm is conceptually different from the recent algorithm of\n[GHKM23], which gave a $\\mathrm{poly}(n)$-time algorithm to solve semirandom\nCSPs with $m \\geq \\tilde{O}(n^{\\frac{k}{2}})$ constraints by exploiting\nconditions that allow a basic SDP to recover the planted assignment $x^*$\nexactly. Instead, we forego certificates of uniqueness and recover $x^*$ in two\nsteps: we first use a degree-$O(\\ell)$ Sum-of-Squares SDP to find some\n$\\hat{x}$ that is $o(1)$-close to $x^*$, and then we use a second rounding\nprocedure to recover $x^*$ from $\\hat{x}$.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u51b3k\u5143\u5e03\u5c14CSP\u968f\u673aplanted\u5b9e\u4f8b\u7684\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5728\u7279\u5b9a\u7ea6\u675f\u6570\u91cf\u4e0b\uff0c\u80fd\u5728n^O(l)\u65f6\u95f4\u5185\u627e\u5230\u6ee1\u8db3\u8d4b\u503c\uff0c\u5e76\u4e0e\u73b0\u6709\u7b97\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "motivation": "\u89e3\u51b3k\u5143\u5e03\u5c14\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\uff08CSP\uff09\u7684\u968f\u673aplanted\u5b9e\u4f8b\uff0c\u5e76\u4e0e\u73b0\u6709\u7b97\u6cd5\u8fdb\u884c\u5bf9\u6bd4\u548c\u6cdb\u5316\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u7b97\u6cd5\u6765\u89e3\u51b3k\u5143\u5e03\u5c14\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\uff08CSP\uff09\u7684\u968f\u673aplanted\u5b9e\u4f8b\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u7b97\u6cd5\u9996\u5148\u4f7f\u7528\u4e00\u4e2a\u5ea6\u4e3aO(l)\u7684Sum-of-Squares SDP\u627e\u5230\u4e00\u4e2a\u8fd1\u4f3c\u89e3\tilde{x}\uff0c\u8be5\u89e3\u4e0eplanted\u8d4b\u503cx*\u7684\u5dee\u8ddd\u4e3ao(1)\uff0c\u7136\u540e\u4f7f\u7528\u7b2c\u4e8c\u4e2a\u820d\u5165\u8fc7\u7a0b\u4ece\tilde{x}\u4e2d\u6062\u590d\u51fax*\u3002", "result": "\u5f53\u7ea6\u675f\u6570\u91cfm\u6ee1\u8db3m >= O(n) * (n/l)^((k/2)-1) log n\u65f6\uff0c\u7b97\u6cd5\u53ef\u4ee5\u5728n^O(l)\u65f6\u95f4\u5185\u6210\u529f\u627e\u5230\u6ee1\u8db3\u7684\u8d4b\u503c\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u5728\u6ee1\u8db3\u7279\u5b9a\u7ea6\u675f\u6570\u91cf\u7684\u6761\u4ef6\u4e0b\uff0c\u80fd\u591f\u6210\u529f\u627e\u51fa\u6ee1\u8db3\u7684\u8d4b\u503c\u3002"}}
{"id": "2507.10979", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.10979", "abs": "https://arxiv.org/abs/2507.10979", "authors": ["Mahdieh Zaker", "Amy Nejati", "Abolfazl Lavaei"], "title": "Data-Driven Safety Certificates of Infinite Networks with Unknown Models and Interconnection Topologies", "comment": null, "summary": "Infinite networks are complex interconnected systems comprising a countably\ninfinite number of subsystems, where counting them precisely poses a\nsignificant challenge due to the seemingly endless interconnected nature of the\nnetwork (e.g., counting vehicles on the road). In such scenarios, the presence\nof infinitely many subsystems within the network renders the existing analysis\nframeworks tailored for finite networks inapplicable to infinite ones. This\npaper is concerned with offering a data-driven approach, within a compositional\nframework, for the safety certification of infinite networks with both unknown\nmathematical models and interconnection topologies. Given the immense\ncomputational complexity stemming from the extensive dimension of infinite\nnetworks, our approach capitalizes on the joint dissipativity-type properties\nof subsystems, characterized by storage certificates. We introduce innovative\ncompositional data-driven conditions to construct a barrier certificate for the\ninfinite network leveraging storage certificates of its unknown subsystems\nderived from data, while offering correctness guarantees across the network\nsafety. We demonstrate that our compositional data-driven reasoning eliminates\nthe requirement for checking the traditional dissipativity condition, which\ntypically mandates precise knowledge of the interconnection topology. In\naddition, while existing data-driven literature demonstrates an exponential\ntrend in sample complexity with respect to network size, we showcase that our\ncompositional strategy notably reduces it to a linear scale in terms of the\nnumber of subsystems. We illustrate our data-driven results on two physical\ninfinite networks with unknown models and interconnection topologies.", "AI": {"tldr": "This paper offers a data-driven method to certify the safety of complex, infinite networks whose models and connections are unknown. It uses subsystem properties (storage certificates) to create a safety guarantee (barrier certificate) without needing to know exact network details or how subsystems connect. This method is more efficient in terms of data needed and works even when system details are not fully known, as shown in real-world examples.", "motivation": "Existing analysis frameworks for finite networks are inapplicable to infinite networks due to their complex, interconnected nature and the challenge of precisely counting subsystems. The paper aims to provide a data-driven approach for safety certification in these scenarios where mathematical models and interconnection topologies are unknown.", "method": "A compositional data-driven framework is used, focusing on the joint dissipativity-type properties of subsystems characterized by storage certificates. Innovative compositional data-driven conditions are introduced to construct a barrier certificate for the infinite network using storage certificates derived from data of unknown subsystems.", "result": "The approach successfully constructs a barrier certificate for infinite networks with unknown models and topologies, offering correctness guarantees for network safety. It eliminates the need to check traditional dissipativity conditions and reduces sample complexity to a linear scale compared to existing methods. The effectiveness is demonstrated on two physical infinite networks.", "conclusion": "The paper presents a compositional data-driven approach for the safety certification of infinite networks with unknown models and interconnection topologies. It leverages joint dissipativity-type properties and storage certificates of subsystems to construct a barrier certificate. The approach eliminates the need for precise knowledge of the interconnection topology and reduces sample complexity from exponential to linear with respect to the number of subsystems."}}
{"id": "2507.10574", "categories": ["cs.LG", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2507.10574", "abs": "https://arxiv.org/abs/2507.10574", "authors": ["Jae Wan Shim"], "title": "Enhancing Cross Entropy with a Linearly Adaptive Loss Function for Optimized Classification Performance", "comment": "13 pages, 2 figures", "summary": "We propose the Linearly Adaptive Cross Entropy Loss function. This is a novel\nmeasure derived from the information theory. In comparison to the standard\ncross entropy loss function, the proposed one has an additional term that\ndepends on the predicted probability of the true class. This feature serves to\nenhance the optimization process in classification tasks involving one-hot\nencoded class labels. The proposed one has been evaluated on a ResNet-based\nmodel using the CIFAR-100 dataset. Preliminary results show that the proposed\none consistently outperforms the standard cross entropy loss function in terms\nof classification accuracy. Moreover, the proposed one maintains simplicity,\nachieving practically the same efficiency to the traditional cross entropy\nloss. These findings suggest that our approach could broaden the scope for\nfuture research into loss function design.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u635f\u5931\u51fd\u6570\u2014\u2014\u7ebf\u6027\u81ea\u9002\u5e94\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u5b83\u901a\u8fc7\u589e\u52a0\u4e00\u4e2a\u9879\u6765\u6539\u8fdb\u4f18\u5316\u8fc7\u7a0b\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u663e\u793a\u51fa\u6bd4\u6807\u51c6\u4ea4\u53c9\u71b5\u635f\u5931\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u76f8\u5f53\u7684\u6548\u7387\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u5305\u542b\u72ec\u70ed\u7f16\u7801\u7c7b\u522b\u6807\u7b7e\u7684\u5206\u7c7b\u4efb\u52a1\u7684\u4f18\u5316\u8fc7\u7a0b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6e90\u81ea\u4fe1\u606f\u8bba\u7684\u65b0\u578b\u5ea6\u91cf\u65b9\u6cd5\u2014\u2014\u7ebf\u6027\u81ea\u9002\u5e94\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u8be5\u51fd\u6570\u5728\u6807\u51c6\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\u7684\u57fa\u7840\u4e0a\u589e\u52a0\u4e86\u4e00\u4e2a\u4f9d\u8d56\u4e8e\u771f\u5b9e\u7c7b\u522b\u9884\u6d4b\u6982\u7387\u7684\u9879\uff0c\u4ee5\u589e\u5f3a\u5305\u542b\u72ec\u70ed\u7f16\u7801\u7c7b\u522b\u6807\u7b7e\u7684\u5206\u7c7b\u4efb\u52a1\u7684\u4f18\u5316\u8fc7\u7a0b\u3002", "result": "\u5728\u57fa\u4e8eResNet\u7684\u6a21\u578b\u548cCIFAR-100\u6570\u636e\u96c6\u4e0a\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5206\u7c7b\u51c6\u786e\u6027\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u6807\u51c6\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u5e76\u4e14\u5728\u6548\u7387\u4e0a\u4e0e\u4f20\u7edf\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u57fa\u672c\u76f8\u5f53\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u4ee5\u62d3\u5bbd\u672a\u6765\u635f\u5931\u51fd\u6570\u8bbe\u8ba1\u7684\u8303\u56f4\u3002"}}
{"id": "2507.10672", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10672", "abs": "https://arxiv.org/abs/2507.10672", "authors": ["Muhayy Ud Din", "Waseem Akram", "Lyes Saad Saoud", "Jan Rosell", "Irfan Hussain"], "title": "Vision Language Action Models in Robotic Manipulation: A Systematic Review", "comment": "submitted to annual review in control", "summary": "Vision Language Action (VLA) models represent a transformative shift in\nrobotics, with the aim of unifying visual perception, natural language\nunderstanding, and embodied control within a single learning framework. This\nreview presents a comprehensive and forward-looking synthesis of the VLA\nparadigm, with a particular emphasis on robotic manipulation and\ninstruction-driven autonomy. We comprehensively analyze 102 VLA models, 26\nfoundational datasets, and 12 simulation platforms that collectively shape the\ndevelopment and evaluation of VLAs models. These models are categorized into\nkey architectural paradigms, each reflecting distinct strategies for\nintegrating vision, language, and control in robotic systems. Foundational\ndatasets are evaluated using a novel criterion based on task complexity,\nvariety of modalities, and dataset scale, allowing a comparative analysis of\ntheir suitability for generalist policy learning. We introduce a\ntwo-dimensional characterization framework that organizes these datasets based\non semantic richness and multimodal alignment, showing underexplored regions in\nthe current data landscape. Simulation environments are evaluated for their\neffectiveness in generating large-scale data, as well as their ability to\nfacilitate transfer from simulation to real-world settings and the variety of\nsupported tasks. Using both academic and industrial contributions, we recognize\nongoing challenges and outline strategic directions such as scalable\npretraining protocols, modular architectural design, and robust multimodal\nalignment strategies. This review serves as both a technical reference and a\nconceptual roadmap for advancing embodiment and robotic control, providing\ninsights that span from dataset generation to real world deployment of\ngeneralist robotic agents.", "AI": {"tldr": "\u672c\u7efc\u8ff0\u5168\u9762\u5206\u6790\u4e86\u673a\u5668\u4eba\u9886\u57df\u7684\u89c6\u89c9\u8bed\u8a00\u52a8\u4f5c\uff08VLA\uff09\u6a21\u578b\uff0c\u91cd\u70b9\u5173\u6ce8\u673a\u5668\u4eba\u64cd\u7eb5\u548c\u6307\u4ee4\u9a71\u52a8\u7684\u81ea\u4e3b\u6027\u3002\u6211\u4eec\u8bc4\u4f30\u4e86\u6a21\u578b\u3001\u6570\u636e\u96c6\u548c\u6a21\u62df\u5e73\u53f0\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u672a\u6765\u7814\u7a76\u548c\u53d1\u5c55\u7684\u6218\u7565\u65b9\u5411\u3002", "motivation": "\u65e8\u5728\u7edf\u4e00\u89c6\u89c9\u611f\u77e5\u3001\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u548c\u5177\u8eab\u63a7\u5236\u5728\u4e00\u4e2a\u5b66\u4e60\u6846\u67b6\u5185\uff0c\u91cd\u70b9\u5173\u6ce8\u673a\u5668\u4eba\u64cd\u7eb5\u548c\u6307\u4ee4\u9a71\u52a8\u7684\u81ea\u4e3b\u6027\uff0c\u4e3a\u5177\u8eab\u667a\u80fd\u548c\u673a\u5668\u4eba\u63a7\u5236\u7684\u7814\u7a76\u63d0\u4f9b\u4e00\u4e2a\u5168\u9762\u7684\u6280\u672f\u53c2\u8003\u548c\u6982\u5ff5\u8def\u7ebf\u56fe\u3002", "method": "\u901a\u8fc7\u5bf9102\u4e2aVLA\u6a21\u578b\u300126\u4e2a\u6570\u636e\u96c6\u548c12\u4e2a\u6a21\u62df\u5e73\u53f0\u7684\u5168\u9762\u5206\u6790\uff0c\u8bc4\u4f30VLA\u6a21\u578b\u5728\u673a\u5668\u4eba\u64cd\u7eb5\u548c\u6307\u4ee4\u9a71\u52a8\u81ea\u4e3b\u6027\u65b9\u9762\u7684\u73b0\u72b6\u3002\u91c7\u7528\u57fa\u4e8e\u4efb\u52a1\u590d\u6742\u5ea6\u3001\u6a21\u6001\u591a\u6837\u6027\u548c\u6570\u636e\u96c6\u89c4\u6a21\u7684\u65b0\u6807\u51c6\u6765\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u5e76\u5f15\u5165\u4e00\u4e2a\u4e8c\u7ef4\u6846\u67b6\u6765\u8868\u5f81\u6570\u636e\u96c6\u7684\u8bed\u4e49\u4e30\u5bcc\u5ea6\u548c\u591a\u6a21\u6001\u5bf9\u9f50\u5ea6\u3002\u8bc4\u4f30\u6a21\u62df\u73af\u5883\u751f\u6210\u5927\u89c4\u6a21\u6570\u636e\u4ee5\u53ca\u6a21\u62df\u5230\u73b0\u5b9e\u4e16\u754c\u8fc1\u79fb\u7684\u80fd\u529b\u3002", "result": "\u5bf9\u73b0\u6709VLA\u6a21\u578b\u3001\u6570\u636e\u96c6\u548c\u6a21\u62df\u5e73\u53f0\u8fdb\u884c\u4e86\u5206\u7c7b\u548c\u8bc4\u4f30\uff0c\u6307\u51fa\u4e86\u5f53\u524d\u6570\u636e\u683c\u5c40\u4e2d\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u9886\u57df\uff0c\u5e76\u8bc6\u522b\u4e86\u53ef\u6269\u5c55\u7684\u9884\u8bad\u7ec3\u534f\u8bae\u3001\u6a21\u5757\u5316\u67b6\u6784\u8bbe\u8ba1\u548c\u5f3a\u5927\u7684\u591a\u6a21\u6001\u5bf9\u9f50\u7b56\u7565\u7b49\u5173\u952e\u6311\u6218\u548c\u6218\u7565\u65b9\u5411\u3002", "conclusion": "\u8be5\u7efc\u8ff0\u5168\u9762\u8bc4\u4f30\u4e86102\u4e2a\u89c6\u89c9\u8bed\u8a00\u52a8\u4f5c\uff08VLA\uff09\u6a21\u578b\u300126\u4e2a\u57fa\u7840\u6570\u636e\u96c6\u548c12\u4e2a\u6a21\u62df\u5e73\u53f0\uff0c\u5bf9\u673a\u5668\u4eba\u64cd\u7eb5\u548c\u6307\u4ee4\u9a71\u52a8\u7684\u81ea\u4e3b\u6027\u8fdb\u884c\u4e86\u91cd\u70b9\u5206\u6790\uff0c\u5e76\u63d0\u51fa\u4e86\u53ef\u6269\u5c55\u7684\u9884\u8bad\u7ec3\u534f\u8bae\u3001\u6a21\u5757\u5316\u67b6\u6784\u8bbe\u8ba1\u548c\u5f3a\u5927\u7684\u591a\u6a21\u6001\u5bf9\u9f50\u7b56\u7565\u7b49\u6218\u7565\u65b9\u5411\uff0c\u65e8\u5728\u63a8\u52a8\u5177\u8eab\u667a\u80fd\u548c\u673a\u5668\u4eba\u63a7\u5236\u7684\u53d1\u5c55\u3002"}}
{"id": "2507.10639", "categories": ["cs.AR", "cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2507.10639", "abs": "https://arxiv.org/abs/2507.10639", "authors": ["Simon Nau", "Jan Krummenauer", "Andr\u00e9 Zimmermann"], "title": "SPICEAssistant: LLM using SPICE Simulation Tools for Schematic Design of Switched-Mode Power Supplies", "comment": "11 pages, 10 figures", "summary": "State-of-the-art large language models (LLMs) show high performance across a\nwide range of tasks in many domains of science. In the field of electronic\ndesign automation (EDA), it is yet to be determined to what extent they are\ncapable to understand, adapt, and dimension electronic circuits. This paper\nfocuses on the application of LLMs to switched-mode power supply (SMPS) design\non printed circuit boards (PCBs). Particular challenges for LLMs in this\ncontext include their limited ability to interpret results from key simulation\ntools like SPICE and the multi-step design process. To address these\nchallenges, we suggest SPICEAssistant, a framework that provides a broad\nselection of tools to an LLM. The tools serve as an interface to SPICE,\nallowing the LLM to interact flexibly with the simulator to estimate the impact\nof its modifications to the circuit. To evaluate the performance of\nSPICEAssistant, we defined a benchmark consisting of 256 questions testing the\nability to adapt circuit netlists to fulfil different SMPS design tasks. The\nbenchmarking results show that simulation feedback effectively improves SMPS\ndesign capabilities of LLMs. An increasing number of simulation iterations\nleads to enhanced performance. The SPICEAssistant framework significantly\noutperforms the standalone LLM GPT-4o on the benchmark by approximately 38%.", "AI": {"tldr": "SPICEAssistant\u6846\u67b6\u901a\u8fc7\u4e0eSPICE\u4eff\u771f\u5668\u96c6\u6210\uff0c\u63d0\u5347\u4e86LLM\u5728\u5f00\u5173\u6a21\u5f0f\u7535\u6e90\u8bbe\u8ba1\u4e2d\u7684\u8868\u73b0\uff0c\u76f8\u6bd4GPT-4o\u6027\u80fd\u63d0\u534738%\u3002", "motivation": "\u63a2\u7d22LLM\u5728\u7535\u5b50\u8bbe\u8ba1\u81ea\u52a8\u5316\uff08EDA\uff09\u9886\u57df\uff0c\u7279\u522b\u662f\u5f00\u5173\u6a21\u5f0f\u7535\u6e90\uff08SMPS\uff09\u8bbe\u8ba1\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u89e3\u51b3LLM\u5728\u7406\u89e3SPICE\u4eff\u771f\u7ed3\u679c\u548c\u591a\u6b65\u8bbe\u8ba1\u6d41\u7a0b\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faSPICEAssistant\u6846\u67b6\uff0c\u4e3aLLM\u63d0\u4f9b\u4e00\u4e2a\u5305\u542b\u591a\u79cd\u5de5\u5177\u7684\u63a5\u53e3\uff0c\u4f7f\u5176\u80fd\u591f\u4e0eSPICE\u4eff\u771f\u5668\u8fdb\u884c\u4ea4\u4e92\uff0c\u4ece\u800c\u8bc4\u4f30\u5bf9\u7535\u8def\u4fee\u6539\u7684\u5f71\u54cd\u3002", "result": "SPICEAssistant\u6846\u67b6\u901a\u8fc7\u589e\u52a0\u4eff\u771f\u8fed\u4ee3\u6b21\u6570\uff0c\u6709\u6548\u63d0\u5347\u4e86LLM\u8fdb\u884cSMPS\u8bbe\u8ba1\u7684\u80fd\u529b\u3002SPICEAssistant\u5728\u5305\u542b256\u4e2a\u95ee\u9898\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4\u72ec\u7acb\u7684GPT-4o\uff0c\u6027\u80fd\u63d0\u5347\u4e86\u7ea638%\u3002", "conclusion": "SPICEAssistant\u6846\u67b6\u663e\u8457\u4f18\u4e8e\u72ec\u7acb\u7684LLM GPT-4o\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u63d0\u5347\u7ea638%\u3002"}}
{"id": "2507.10924", "categories": ["cs.GR"], "pdf": "https://arxiv.org/pdf/2507.10924", "abs": "https://arxiv.org/abs/2507.10924", "authors": ["Zihan Zhao", "Pengfei Wang", "Minfeng Xu", "Shuangmin Chen", "Shiqing Xin", "Changhe Tu", "Wenping Wang"], "title": "OffsetCrust: Variable-Radius Offset Approximation with Power Diagrams", "comment": null, "summary": "Offset surfaces, defined as the Minkowski sum of a base surface and a rolling\nball, play a crucial role in geometry processing, with applications ranging\nfrom coverage motion planning to brush modeling. While considerable progress\nhas been made in computing constant-radius offset surfaces, computing\nvariable-radius offset surfaces remains a challenging problem. In this paper,\nwe present OffsetCrust, a novel framework that efficiently addresses the\nvariable-radius offsetting problem by computing a power diagram. Let $R$ denote\nthe radius function defined on the base surface $S$. The power diagram is\nconstructed from contributing sites, consisting of carefully sampled base\npoints on $S$ and their corresponding off-surface points, displaced along\n$R$-dependent directions. In the constant-radius case only, these displacement\ndirections align exactly with the surface normals of $S$. Moreover, our method\nmitigates the misalignment issues commonly seen in crust-based approaches\nthrough a lightweight fine-tuning procedure. We validate the accuracy and\nefficiency of OffsetCrust through extensive experiments, and demonstrate its\npractical utility in applications such as reconstructing original boundary\nsurfaces from medial axis transform (MAT) representations.", "AI": {"tldr": "OffsetCrust\u662f\u4e00\u4e2a\u65b0\u7684\u6846\u67b6\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u8ba1\u7b97\u53ef\u53d8\u534a\u5f84\u7684\u504f\u79fb\u66f2\u9762\uff0c\u901a\u8fc7\u5e42\u56fe\u548c\u8f7b\u91cf\u7ea7\u5fae\u8c03\u6765\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u7f3a\u70b9\u3002", "motivation": "\u53ef\u53d8\u534a\u5f84\u504f\u7f6e\u66f2\u9762\u7684\u8ba1\u7b97\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\u6027\u95ee\u9898\uff0c\u800c\u504f\u79fb\u66f2\u9762\u5728\u51e0\u4f55\u5904\u7406\u4e2d\u6709\u91cd\u8981\u5e94\u7528\u3002", "method": "\u901a\u8fc7\u8ba1\u7b97\u5e42\u56fe\u6765\u89e3\u51b3\u53ef\u53d8\u534a\u5f84\u504f\u7f6e\u66f2\u9762\u7684\u95ee\u9898\u3002\u5e42\u56fe\u7531\u8d21\u732e\u4f4d\u70b9\u6784\u6210\uff0c\u8fd9\u4e9b\u4f4d\u70b9\u7531\u5728\u57fa\u66f2\u9762S\u4e0a\u4ed4\u7ec6\u91c7\u6837\u7684\u70b9\u53ca\u5176\u5bf9\u5e94\u7684\u79bb\u66f2\u9762\u70b9\u7ec4\u6210\uff0c\u8fd9\u4e9b\u70b9\u6cbf\u7740\u4f9d\u8d56\u4e8eR\uff08\u5b9a\u4e49\u5728\u57fa\u66f2\u9762S\u4e0a\u7684\u534a\u5f84\u51fd\u6570\uff09\u7684\u65b9\u5411\u8fdb\u884c\u4f4d\u79fb\u3002\u5728\u5747\u5300\u534a\u5f84\u7684\u60c5\u51b5\u4e0b\uff0c\u8fd9\u4e9b\u4f4d\u79fb\u65b9\u5411\u4e0eS\u7684\u6cd5\u7ebf\u65b9\u5411\u7cbe\u786e\u5bf9\u9f50\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u5f97\u5230\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u4ece\u5185\u8f74\u53d8\u6362\uff08MAT\uff09\u8868\u793a\u91cd\u5efa\u539f\u59cb\u8fb9\u754c\u66f2\u9762\u7b49\u5e94\u7528\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aOffsetCrust\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u8ba1\u7b97\u5e42\u56fe\u6765\u89e3\u51b3\u53ef\u53d8\u534a\u5f84\u504f\u7f6e\u66f2\u9762\u7684\u95ee\u9898\uff0c\u5e76\u5728\u5747\u5300\u534a\u5f84\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u7684\u5fae\u8c03\u8fc7\u7a0b\u6765\u7f13\u89e3\u57fa\u4e8e \u0935\u0943\u0924\u094d\u0924 (crust) \u7684\u65b9\u6cd5\u4e2d\u5e38\u89c1\u7684\u9519\u4f4d\u95ee\u9898\u3002"}}
{"id": "2507.10838", "categories": ["eess.SP", "cs.IT", "math.IT", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.10838", "abs": "https://arxiv.org/abs/2507.10838", "authors": ["Gokberk Yaylali", "Ahmad Ali Khan", "Dionysios S. Kalogerias"], "title": "Waterfilling at the Edge: Optimal Percentile Resource Allocation via Risk-Averse Reduction", "comment": "5 pages, 5 figures", "summary": "We address deterministic resource allocation in point-to-point multi-terminal\nAWGN channels without inter-terminal interference, with particular focus on\noptimizing quantile transmission rates for cell-edge terminal service.\nClassical utility-based approaches -- such as minimum rate, sumrate, and\nproportional fairness -- are either overconservative, or inappropriate, or do\nnot provide a rigorous and/or interpretable foundation for fair rate\noptimization at the edge. To overcome these challenges, we employ Conditional\nValue-at-Risk (CVaR), a popular coherent risk measure, and establish its\nequivalence with the sum-least-$\\alpha$th-quantile (SL$\\alpha$Q) utility. This\nconnection enables an exact convex reformulation of the SL$\\alpha$Q\nmaximization problem, facilitating analytical tractability and precise and\ninterpretable control over cell-edge terminal performance. Utilizing Lagrangian\nduality, we provide (for the first time) parameterized closed-form solutions\nfor the optimal resource policy -- which is of waterfilling-type -- as well as\nthe associated (auxiliary) Value-at-Risk variable. We further develop a novel\ninexact dual subgradient descent algorithm of minimal complexity to determine\nglobally optimal resource policies, and we rigorously establish its\nconvergence. The resulting edge waterfilling algorithm iteratively and\nefficiently allocates resources while explicitly ensuring transmission rate\nfairness across (cell-edge) terminals. Several (even large-scale) numerical\nexperiments validate the effectiveness of the proposed method for enabling\nrobust quantile rate optimization at the edge.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eCVaR\u548cSL\u03b1Q\u7684\u4f18\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u7ec8\u7aefAWGN\u4fe1\u9053\u4e2d\u7684\u786e\u5b9a\u6027\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u7279\u522b\u662f\u4f18\u5316\u5c0f\u533a\u8fb9\u7f18\u7ec8\u7aef\u7684\u91cf\u5316\u4f20\u8f93\u901f\u7387\u3002\u901a\u8fc7\u63a8\u5bfc\u95ed\u5f0f\u89e3\u548c\u5f00\u53d1\u8fb9\u7f18\u6c34\u586b\u5145\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u516c\u5e73\u7684\u8d44\u6e90\u5206\u914d\u3002", "motivation": "\u4e3a\u4e86\u514b\u670d\u7ecf\u5178\u6548\u7528\u65b9\u6cd5\uff08\u5982\u6700\u5c0f\u901f\u7387\u3001\u548c\u901f\u7387\u548c\u6bd4\u4f8b\u516c\u5e73\u6027\uff09\u5728\u70b9\u5bf9\u70b9\u591a\u7ec8\u7aef\u9ad8\u65af\u566a\u58f0\uff08AWGN\uff09\u4fe1\u9053\u4e2d\u4f18\u5316\u5c0f\u533a\u8fb9\u7f18\u7ec8\u7aef\u91cf\u5316\u4f20\u8f93\u901f\u7387\u65f6\u7684\u5c40\u9650\u6027\uff08\u8fc7\u4e8e\u4fdd\u5b88\u3001\u4e0d\u9002\u7528\u6216\u7f3a\u4e4f\u4e25\u683c/\u53ef\u89e3\u91ca\u7684\u57fa\u7840\uff09\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63d0\u4f9b\u4e00\u79cd\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5229\u7528\u6761\u4ef6\u5728\u9669\u4ef7\u503c\uff08CVaR\uff09\u53ca\u5176\u4e0e\u548c\u6700\u5c0f\u5206\u4f4d\u6570\uff08SL\u03b1Q\uff09\u6548\u7528\u7684\u7b49\u4ef7\u6027\uff0c\u5c06SL\u03b1Q\u6700\u5927\u5316\u95ee\u9898\u7cbe\u786e\u5730\u51f8\u91cd\u6784\u3002\u5229\u7528\u62c9\u683c\u6717\u65e5\u5bf9\u5076\u6027\uff0c\u63a8\u5bfc\u4e86\u6700\u4f18\u8d44\u6e90\u7b56\u7565\uff08\u6c34\u586b\u5145\u7c7b\u578b\uff09\u548c\u76f8\u5173\u7684\uff08\u8f85\u52a9\uff09\u5728\u9669\u4ef7\u503c\u53d8\u91cf\u7684\u53c2\u6570\u5316\u95ed\u5f0f\u89e3\u3002\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4e0d\u7cbe\u786e\u5bf9\u5076\u6b21\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u6765\u786e\u5b9a\u5168\u5c40\u6700\u4f18\u8d44\u6e90\u7b56\u7565\uff0c\u5e76\u4e25\u683c\u8bc1\u660e\u4e86\u5176\u6536\u655b\u6027\u3002", "result": "\u7814\u7a76\u5b9e\u73b0\u4e86\u6700\u4f18\u7684\u8d44\u6e90\u5206\u914d\u7b56\u7565\uff0c\u8be5\u7b56\u7565\u4e3a\u6c34\u586b\u5145\u7c7b\u578b\uff0c\u5e76\u63d0\u4f9b\u4e86\u76f8\u5173\u7684\uff08\u8f85\u52a9\uff09\u5728\u9669\u4ef7\u503c\u53d8\u91cf\u7684\u53c2\u6570\u5316\u95ed\u5f0f\u89e3\u3002\u63d0\u51fa\u7684\u8fb9\u7f18\u6c34\u586b\u5145\u7b97\u6cd5\u80fd\u591f\u8fed\u4ee3\u4e14\u9ad8\u6548\u5730\u5206\u914d\u8d44\u6e90\uff0c\u540c\u65f6\u660e\u786e\u786e\u4fdd\u5c0f\u533a\u8fb9\u7f18\u7ec8\u7aef\u7684\u4f20\u8f93\u901f\u7387\u516c\u5e73\u6027\u3002\u5927\u89c4\u6a21\u6570\u503c\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8fb9\u7f18\u6c34\u586b\u5145\u7b97\u6cd5\uff0c\u53ef\u786e\u4fdd\u8de8\uff08\u5c0f\u533a\u8fb9\u7f18\uff09\u7ec8\u7aef\u7684\u4f20\u8f93\u901f\u7387\u516c\u5e73\u6027\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5728\u5c0f\u533a\u8fb9\u7f18\u8fdb\u884c\u9c81\u68d2\u91cf\u5316\u901f\u7387\u4f18\u5316\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.10608", "categories": ["cs.SI", "cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2507.10608", "abs": "https://arxiv.org/abs/2507.10608", "authors": ["Danny Butvinik", "Ofir Yakobi", "Michal Einhorn Cohen", "Elina Maliarsky"], "title": "The Shape of Deceit: Behavioral Consistency and Fragility in Money Laundering Patterns", "comment": null, "summary": "Conventional anti-money laundering (AML) systems predominantly focus on\nidentifying anomalous entities or transactions, flagging them for manual\ninvestigation based on statistical deviation or suspicious behavior. This\nparadigm, however, misconstrues the true nature of money laundering, which is\nrarely anomalous but often deliberate, repeated, and concealed within\nconsistent behavioral routines. In this paper, we challenge the entity-centric\napproach and propose a network-theoretic perspective that emphasizes detecting\npredefined laundering patterns across directed transaction networks. We\nintroduce the notion of behavioral consistency as the core trait of laundering\nactivity, and argue that such patterns are better captured through subgraph\nstructures expressing semantic and functional roles - not solely geometry.\nCrucially, we explore the concept of pattern fragility: the sensitivity of\nlaundering patterns to small attribute changes and, conversely, their semantic\nrobustness even under drastic topological transformations. We claim that\nlaundering detection should not hinge on statistical outliers, but on\npreservation of behavioral essence, and propose a reconceptualization of\npattern similarity grounded in this insight. This philosophical and practical\nshift has implications for how AML systems model, scan, and interpret networks\nin the fight against financial crime.", "AI": {"tldr": "\u4f20\u7edf\u7684\u53cd\u6d17\u94b1\u7cfb\u7edf\u4fa7\u91cd\u4e8e\u8bc6\u522b\u5f02\u5e38\u4ea4\u6613\uff0c\u4f46\u6d17\u94b1\u884c\u4e3a\u5f80\u5f80\u9690\u85cf\u5728\u5e38\u89c4\u6a21\u5f0f\u4e2d\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u7f51\u7edc\u7406\u8bba\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522b\u4ea4\u6613\u7f51\u7edc\u4e2d\u7684\u7279\u5b9a\u6a21\u5f0f\u548c\u884c\u4e3a\u4e00\u81f4\u6027\u6765\u68c0\u6d4b\u6d17\u94b1\uff0c\u800c\u975e\u4f9d\u8d56\u5f02\u5e38\u503c\u3002", "motivation": "\u5f53\u524d\u7684AML\u7cfb\u7edf\u4e3b\u8981\u5173\u6ce8\u5f02\u5e38\u5b9e\u4f53\u6216\u4ea4\u6613\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u672a\u80fd\u6293\u4f4f\u6d17\u94b1\u6d3b\u52a8\u771f\u5b9e\u3001\u9690\u853d\u4e14\u89c4\u5f8b\u7684\u672c\u8d28\u3002\u6d17\u94b1\u884c\u4e3a\u5f80\u5f80\u4e0d\u662f\u5f02\u5e38\u7684\uff0c\u800c\u662f\u9690\u85cf\u5728\u5e38\u89c4\u884c\u4e3a\u6a21\u5f0f\u4e2d\u7684\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7f51\u7edc\u7406\u8bba\u7684\u89c6\u89d2\uff0c\u901a\u8fc7\u5206\u6790\u4ea4\u6613\u7f51\u7edc\u7684\u5b50\u56fe\u7ed3\u6784\u6765\u8bc6\u522b\u9884\u5b9a\u4e49\u7684\u6d17\u94b1\u6a21\u5f0f\uff0c\u5e76\u5f15\u5165\u4e86\u201c\u884c\u4e3a\u4e00\u81f4\u6027\u201d\u4f5c\u4e3a\u6d17\u94b1\u6d3b\u52a8\u7684\u6838\u5fc3\u7279\u5f81\uff0c\u540c\u65f6\u7814\u7a76\u4e86\u6a21\u5f0f\u7684\u8106\u5f31\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4ee5\u53ca\u57fa\u4e8e\u884c\u4e3a\u672c\u8d28\u7684\u6a21\u5f0f\u76f8\u4f3c\u6027\u6982\u5ff5\u3002", "result": "\u8be5\u7814\u7a76\u901a\u8fc7\u7f51\u7edc\u7406\u8bba\u548c\u884c\u4e3a\u4e00\u81f4\u6027\u6982\u5ff5\uff0c\u4e3aAML\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u68c0\u6d4b\u6d17\u94b1\u6d3b\u52a8\u7684\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u66f4\u51c6\u786e\u5730\u8bc6\u522b\u9690\u85cf\u5728\u5e38\u89c4\u4ea4\u6613\u7f51\u7edc\u4e2d\u7684\u6d17\u94b1\u6a21\u5f0f\uff0c\u800c\u975e\u4ec5\u4ec5\u4f9d\u8d56\u4e8e\u7edf\u8ba1\u4e0a\u7684\u5f02\u5e38\u503c\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53cd\u6d17\u94b1\uff08AML\uff09\u7cfb\u7edf\u8303\u5f0f\uff0c\u4ece\u4f20\u7edf\u7684\u5b9e\u4f53/\u4ea4\u6613\u5c42\u9762\u8f6c\u5411\u57fa\u4e8e\u7f51\u7edc\u7406\u8bba\u7684\u6a21\u5f0f\u68c0\u6d4b\uff0c\u5f3a\u8c03\u884c\u4e3a\u4e00\u81f4\u6027\u548c\u5b50\u56fe\u7ed3\u6784\u6765\u8bc6\u522b\u6d17\u94b1\u6d3b\u52a8\uff0c\u800c\u975e\u4ec5\u4ec5\u4f9d\u8d56\u7edf\u8ba1\u5f02\u5e38\u503c\u3002\u7814\u7a76\u8fd8\u63a2\u8ba8\u4e86\u6a21\u5f0f\u7684\u8106\u5f31\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4e3b\u5f20\u68c0\u6d4b\u5e94\u4fa7\u91cd\u4e8e\u884c\u4e3a\u672c\u8d28\u7684\u4fdd\u6301\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u6a21\u5f0f\u76f8\u4f3c\u6027\u6982\u5ff5\u3002"}}
{"id": "2507.11076", "categories": ["cs.RO", "cs.NA", "math.DG", "math.DS", "math.GR", "math.NA"], "pdf": "https://arxiv.org/pdf/2507.11076", "abs": "https://arxiv.org/abs/2507.11076", "authors": ["Andreas Mueller", "Shivesh Kumar"], "title": "Closed Form Time Derivatives of the Equations of Motion of Rigid Body Systems", "comment": null, "summary": "Derivatives of equations of motion(EOM) describing the dynamics of rigid body\nsystems are becoming increasingly relevant for the robotics community and find\nmany applications in design and control of robotic systems. Controlling robots,\nand multibody systems comprising elastic components in particular, not only\nrequires smooth trajectories but also the time derivatives of the control\nforces/torques, hence of the EOM. This paper presents the time derivatives of\nthe EOM in closed form up to second-order as an alternative formulation to the\nexisting recursive algorithms for this purpose, which provides a direct insight\ninto the structure of the derivatives. The Lie group formulation for rigid body\nsystems is used giving rise to very compact and easily parameterized equations.", "AI": {"tldr": "A new closed-form method using Lie group formulation to calculate time derivatives of rigid body dynamics equations for robotics control.", "motivation": "Derivatives of equations of motion are increasingly relevant for robotics, especially for controlling systems with elastic components, which require not only smooth trajectories but also time derivatives of control forces/torques.", "method": "The Lie group formulation for rigid body systems is used to derive compact and easily parameterized equations.", "result": "The paper provides a closed-form formulation for the time derivatives of the EOM up to second-order.", "conclusion": "This paper presents a closed-form formulation for the time derivatives of the equations of motion (EOM) for rigid body systems up to second-order, offering a direct insight into their structure as an alternative to recursive algorithms."}}
{"id": "2507.10736", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.10736", "abs": "https://arxiv.org/abs/2507.10736", "authors": ["Hossein Mirhosseini", "Luis Elcoro", "Andreas Kn\u00fcpfer", "Thomas D. K\u00fchne"], "title": "Revisiting the Abundance of Topological Materials", "comment": null, "summary": "The classification of topological materials is revisited using advanced\ncomputational workflows that integrate hybrid density functional theory\ncalculations with exact Hartree-Fock exchange. Unlike previous studies, our\nworkflow optimizes atomic configurations obtained from the Materials Project\nDatabase, followed by precise electronic structure calculations. Our results\nbased on hybrid density functional theory calculations reveal that only 15\\% of\nmaterials are topologically nontrivial, which is in stark contrast to the\npreviously reported 30\\% based on semi-local exchange and correlation\nfunctionals. This discrepancy underscores the critical dependence of\ntopological classifications on accurate atomic and electronic structures,\nrendering the abundance of topological materials much lower than generally\nassumed.", "AI": {"tldr": "\u8ba1\u7b97\u65b9\u6cd5\u548c\u7cbe\u5ea6\u5bf9\u62d3\u6251\u6750\u6599\u7684\u5206\u7c7b\u6709\u663e\u8457\u5f71\u54cd\uff0c\u51c6\u786e\u7684\u8ba1\u7b97\u8868\u660e\u62d3\u6251\u6750\u6599\u6bd4\u4e4b\u524d\u8ba4\u4e3a\u7684\u8981\u5c11\u3002", "motivation": "\u91cd\u65b0\u5ba1\u89c6\u4e86\u62d3\u6251\u6750\u6599\u7684\u5206\u7c7b\uff0c\u91cd\u70b9\u5173\u6ce8\u4e86\u8ba1\u7b97\u5de5\u4f5c\u6d41\u7684\u4f18\u5316\u548c\u7cbe\u786e\u6027\u3002", "method": "\u901a\u8fc7\u6574\u5408\u6df7\u5408\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\u8ba1\u7b97\u548c Hartree-Fock \u4ea4\u6362\uff0c\u5e76\u4f18\u5316\u4ece\u6750\u6599\u9879\u76ee\u6570\u636e\u5e93\u83b7\u5f97\u7684\u539f\u5b50\u6784\u578b\uff0c\u7136\u540e\u8fdb\u884c\u7cbe\u786e\u7684\u7535\u5b50\u7ed3\u6784\u8ba1\u7b97\u3002", "result": "\u6df7\u5408\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\u8ba1\u7b97\u7ed3\u679c\u663e\u793a\uff0c\u53ea\u6709 15% \u7684\u6750\u6599\u662f\u62d3\u6251\u91cd\u8981\u7684\uff0c\u8fd9\u4e0e\u4e4b\u524d\u57fa\u4e8e\u534a\u5c40\u90e8\u6cdb\u51fd\u7684 30% \u7684\u7ed3\u679c\u5f62\u6210\u5bf9\u6bd4\u3002", "conclusion": "\u4e0e\u6b64\u524d\u57fa\u4e8e\u534a\u5c40\u90e8\u4ea4\u6362\u548c\u76f8\u5173\u6cdb\u51fd\u7684\u62a5\u9053\u5f62\u6210\u9c9c\u660e\u5bf9\u6bd4\uff0c\u57fa\u4e8e\u6df7\u5408\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\u8ba1\u7b97\u7684\u7ed3\u679c\u8868\u660e\uff0c\u53ea\u6709 15% \u7684\u6750\u6599\u662f\u62d3\u6251\u91cd\u8981\u7684\u3002\u8fd9\u51f8\u663e\u4e86\u62d3\u6251\u5206\u7c7b\u5bf9\u51c6\u786e\u7684\u539f\u5b50\u548c\u7535\u5b50\u7ed3\u6784\u7684\u4f9d\u8d56\u6027\uff0c\u4f7f\u5f97\u62d3\u6251\u6750\u6599\u7684\u4e30\u5ea6\u8fdc\u4f4e\u4e8e\u666e\u904d\u5047\u8bbe\u3002"}}
{"id": "2507.10781", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2507.10781", "abs": "https://arxiv.org/abs/2507.10781", "authors": ["Jaikrishna Manojkumar Patil", "Adam Chapman", "Richard Knuszka", "John Chapman", "Paulo Shakarian"], "title": "Reasoning about Medical Triage Optimization with Logic Programming", "comment": "Accepted in International Conference on Logic Programming (ICLP 2025)", "summary": "We present a logic programming framework that orchestrates multiple variants\nof an optimization problem and reasons about their results to support\nhigh-stakes medical decision-making. The logic programming layer coordinates\nthe construction and evaluation of multiple optimization formulations,\ntranslating solutions into logical facts that support further symbolic\nreasoning and ensure efficient resource allocation-specifically targeting the\n\"right patient, right platform, right escort, right time, right destination\"\nprinciple. This capability is integrated into GuardianTwin, a decision support\nsystem for Forward Medical Evacuation (MEDEVAC), where rapid and explainable\nresource allocation is critical. Through a series of experiments, our framework\ndemonstrates an average reduction in casualties by 35.75 % compared to standard\nbaselines. Additionally, we explore how users engage with the system via an\nintuitive interface that delivers explainable insights, ultimately enhancing\ndecision-making in critical situations. This work demonstrates how logic\nprogramming can serve as a foundation for modular, interpretable, and\noperationally effective optimization in mission-critical domains.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u903b\u8f91\u7f16\u7a0b\u6846\u67b6\uff0c\u7528\u4e8e\u533b\u7597\u540e\u9001\u51b3\u7b56\uff0c\u5c06\u4f24\u4ea1\u4eba\u6570\u5e73\u5747\u51cf\u5c11\u4e86 35.75%\u3002", "motivation": "\u652f\u6301\u9ad8\u98ce\u9669\u533b\u7597\u51b3\u7b56\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u903b\u8f91\u7f16\u7a0b\u6846\u67b6\uff0c\u7528\u4e8e\u7f16\u6392\u4f18\u5316\u95ee\u9898\u7684\u591a\u79cd\u53d8\u4f53\uff0c\u5e76\u63a8\u7406\u5176\u7ed3\u679c\uff0c\u4ee5\u652f\u6301\u9ad8\u98ce\u9669\u7684\u533b\u7597\u51b3\u7b56\u3002\u8be5\u903b\u8f91\u7f16\u7a0b\u5c42\u534f\u8c03\u591a\u4e2a\u4f18\u5316\u516c\u5f0f\u7684\u6784\u5efa\u548c\u8bc4\u4f30\uff0c\u5c06\u89e3\u51b3\u65b9\u6848\u8f6c\u6362\u4e3a\u652f\u6301\u8fdb\u4e00\u6b65\u7b26\u53f7\u63a8\u7406\u548c\u786e\u4fdd\u6709\u6548\u8d44\u6e90\u5206\u914d\u7684\u903b\u8f91\u4e8b\u5b9e\u3002", "result": "\u4e0e\u6807\u51c6\u57fa\u7ebf\u76f8\u6bd4\uff0c\u5e73\u5747\u4f24\u4ea1\u51cf\u5c11\u4e86 35.75%\u3002", "conclusion": "\u8be5\u6846\u67b6\u8bc1\u660e\u4e86\u903b\u8f91\u7f16\u7a0b\u5982\u4f55\u4e3a\u4efb\u52a1\u5173\u952e\u9886\u57df\u4e2d\u6a21\u5757\u5316\u3001\u53ef\u89e3\u91ca\u548c\u64cd\u4f5c\u6709\u6548\u7684\u4f18\u5316\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2507.11509", "categories": ["cs.GT", "cs.CC", "F.2.0"], "pdf": "https://arxiv.org/pdf/2507.11509", "abs": "https://arxiv.org/abs/2507.11509", "authors": ["Vincent Cheval", "Florian Horn", "Soumyajit Paul", "Mahsa Shirmohammadi"], "title": "On the Complexity of the Optimal Correlated Equilibria in Extensive-Form Games", "comment": null, "summary": "A major open question in algorithmic game theory is whether normal-form\ncorrelated equilibria (NFCE) can be computed efficiently in succinct games such\nas extensive-form games [DFF+25,6PR24,FP23,HvS08,VSF08,PR08]. Motivated by this\nquestion, we study the associated Threshold problem: deciding whether there\nexists a correlated equilibrium whose value exceeds a given threshold. We prove\nthat this problem is PSPACE-hard for NFCE in multiplayer extensive-form games\nwith perfect recall, even for fixed thresholds. To contextualize this result,\nwe also establish the complexity of the Threshold problem for Nash equilibria\nin this setting, showing it is ER-complete. These results uncover a surprising\ncomplexity reversal: while optimal correlated equilibria are computationally\nsimpler than optimal Nash in normal-form games, the opposite holds in\nextensive-form games, where computing optimal correlated equilibria is provably\nharder. Building on this line of inquiry, we also address a related question by\n[VSF08], who introduced the notions of extensive-form correlated equilibrium\n(EFCE) and agent-form correlated equilibrium (AFCE). They asked how difficult\nthe Threshold problem is for AFCE; we answer this question by proving that it\nis NP-hard, even in two-player games without chance nodes. Complementing our\nhardness results, we establish tight complexity classifications for the\nThreshold problem across several correlated equilibrium concepts - including\nEFCE, AFCE, normal-form coarse, extensive-form coarse, and agent-form coarse\ncorrelated equilibria. For each of these solution concepts in multiplayer\nstochastic extensive-form games with perfect recall, we prove NP-completeness\nby providing matching NP upper bounds to the previously known hardness results.\nTogether, our results provide the most complete landscape to date for the\ncomplexity of optimal equilibrium computation in extensive-form games.", "AI": {"tldr": "\u7814\u7a76\u6269\u5c55\u5f62\u5f0f\u6e38\u620f\u4e2d\u5404\u79cd\u76f8\u5173\u5747\u8861\u6982\u5ff5\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u53d1\u73b0 NFCE \u6bd4 Nash \u5747\u8861\u66f4\u96be\u8ba1\u7b97\uff0c\u5e76\u4e3a NP-complete \u6027\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u590d\u6742\u6027\u56fe\u666f\u3002", "motivation": "\u89e3\u51b3\u7b97\u6cd5\u535a\u5f08\u8bba\u4e2d\u7684\u4e00\u4e2a\u4e3b\u8981\u672a\u89e3\u95ee\u9898\uff0c\u5373\u5728\u8bf8\u5982\u6269\u5c55\u5f62\u5f0f\u6e38\u620f\u7b49\u538b\u7f29\u535a\u5f08\u4e2d\u662f\u5426\u53ef\u4ee5\u6709\u6548\u8ba1\u7b97\u8303\u5f0f\u76f8\u5173\u5747\u8861 (NFCE)\u3002", "method": "\u901a\u8fc7\u8bc1\u660e NFCE \u7684\u9608\u503c\u95ee\u9898\u5728\u5177\u6709\u5b8c\u7f8e\u56de\u5fc6\u7684\u591a\u4eba\u6269\u5c55\u5f62\u5f0f\u6e38\u620f\u4e2d\u662f PSPACE-hard\uff0c\u4ee5\u53ca AFCE \u7684\u9608\u503c\u95ee\u9898\u5728\u4e24\u4eba\u6e38\u620f\u4e2d\u662f NP-hard \u6765\u5efa\u7acb\u590d\u6742\u6027\u3002\u901a\u8fc7\u63d0\u4f9b NP \u4e0a\u754c\u6765\u8865\u5145\u786c\u5ea6\u7ed3\u679c\uff0c\u4ece\u800c\u5728\u5404\u79cd\u76f8\u5173\u5747\u8861\u6982\u5ff5\u4e2d\u83b7\u5f97\u6700\u4f73\u5747\u8861\u8ba1\u7b97\u7684\u5b8c\u6574\u590d\u6742\u6027\u56fe\u666f\u3002", "result": "NFCE \u7684\u9608\u503c\u95ee\u9898\u5728\u5177\u6709\u5b8c\u7f8e\u56de\u5fc6\u7684\u591a\u4eba\u6269\u5c55\u5f62\u5f0f\u6e38\u620f\u4e2d\u662f PSPACE-hard \u7684\uff0c\u800c Nash \u5747\u8861\u7684\u9608\u503c\u95ee\u9898\u662f ER-complete \u7684\u3002AFCE \u7684\u9608\u503c\u95ee\u9898\u5728\u4e24\u4eba\u6e38\u620f\u4e2d\u662f NP-hard \u7684\u3002\u6b64\u5916\uff0cEFCE\u3001AFCE\u3001\u8303\u5f0f\u7c97\u7565\u3001\u6269\u5c55\u5f62\u5f0f\u7c97\u7565\u548c\u4ee3\u7406\u5f62\u5f0f\u7c97\u7565\u76f8\u5173\u5747\u8861\u7684\u9608\u503c\u95ee\u9898\u5df2\u88ab\u8bc1\u660e\u662f NP-complete \u7684\u3002", "conclusion": "\u8ba1\u7b97 NFCE\u3001EFCE \u548c AFCE \u7684\u9608\u503c\u95ee\u9898\uff0c\u5e76\u5728\u591a\u4eba\u968f\u673a\u6269\u5c55\u5f62\u5f0f\u6e38\u620f\u4e2d\u63d0\u4f9b NP-\u5b8c\u5907\u6027\u7684\u6700\u4f73\u5206\u7c7b\uff0c\u4ee5\u63ed\u793a\u6269\u5c55\u5f62\u5f0f\u6e38\u620f\u4e2d\u7684\u590d\u6742\u6027\u53cd\u8f6c\u3002"}}
{"id": "2507.10661", "categories": ["quant-ph", "cond-mat.other", "cond-mat.stat-mech", "math-ph", "math.MP", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2507.10661", "abs": "https://arxiv.org/abs/2507.10661", "authors": ["David Shnaiderov", "Matan Ben Dov", "Yoav Woldiger", "Assaf Hamo", "Eugene Demler", "Emanuele G. Dalla Torre"], "title": "Optimal Calibration of Qubit Detuning and Crosstalk", "comment": null, "summary": "Characterizing and calibrating physical qubits is essential for maintaining\nthe performance of quantum processors. A key challenge in this process is the\npresence of crosstalk that complicates the estimation of individual qubit\ndetunings. In this work, we derive optimal strategies for estimating detuning\nand crosstalk parameters by optimizing Ramsey interference experiments using\nFisher information and the Cramer-Rao bound. We compare several calibration\nprotocols, including measurements of a single quadrature at multiple times and\nof two quadratures at a single time, for a fixed number of total measurements.\nOur results predict that the latter approach yields the highest precision and\nrobustness in both cases of isolated and coupled qubits. We validate\nexperimentally our approach using a single NV center as well as superconducting\ntransmons. Our approach enables accurate parameter extraction with\nsignificantly fewer measurements, resulting in up to a 50\\% reduction in\ncalibration time while maintaining estimation accuracy.", "AI": {"tldr": "\u91cf\u5b50\u8ba1\u7b97\u4e2d\u7684\u6821\u51c6\uff1a\u66f4\u5c11\u6d4b\u91cf\uff0c\u66f4\u5feb\u901f\u5ea6\u3002", "motivation": "\u91cf\u5b50\u5904\u7406\u5668\u4e2d\u7269\u7406\u91cf\u5b50\u6bd4\u7279\u7684\u8868\u5f81\u548c\u6821\u51c6\u5bf9\u4e8e\u7ef4\u6301\u5176\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u800c\u4e32\u6270\u7684\u5b58\u5728\u4f7f\u4f30\u8ba1\u5355\u4e2a\u91cf\u5b50\u6bd4\u7279\u7684\u5931\u8c10\u53d8\u5f97\u590d\u6742\u3002", "method": "\u901a\u8fc7\u4f18\u5316\u62c9\u59c6\u9f50\u5e72\u6d89\u5b9e\u9a8c\u5e76\u5229\u7528\u8d39\u96ea\u4fe1\u606f\u548c\u514b\u62c9\u7f8e-Rao\u8fb9\u754c\u6765\u63a8\u5bfc\u4f30\u8ba1\u62c9 \u59c6\u9f50\u5e72\u6d89\u548c\u4e32\u6270\u53c2\u6570\u7684\u6700\u4f18\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5355\u4e2a NV \u4e2d\u5fc3\u548c\u8d85\u5bfc Transmon \u4e0a\u90fd\u80fd\u5b9e\u73b0\u53c2\u6570\u7684\u7cbe\u786e\u63d0\u53d6\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6d4b\u91cf\u6b21\u6570\u51cf\u5c11\u4e86 50%\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4f30\u8ba1\u7cbe\u5ea6\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u4ee5\u66f4\u5c11 \u7684\u6d4b\u91cf\u6b21\u6570\u5b9e\u73b0\u7cbe\u786e\u7684\u53c2\u6570\u63d0\u53d6\uff0c\u5e76\u5c06\u6821\u51c6\u65f6\u95f4\u7f29\u77ed\u591a\u8fbe 50%\uff0c\u540c\u65f6\u4fdd\u6301\u4f30\u8ba1\u7cbe\u5ea6\u3002"}}
{"id": "2507.10755", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10755", "abs": "https://arxiv.org/abs/2507.10755", "authors": ["Rina Khan", "Catherine Stinson"], "title": "Auditing Facial Emotion Recognition Datasets for Posed Expressions and Racial Bias", "comment": null, "summary": "Facial expression recognition (FER) algorithms classify facial expressions\ninto emotions such as happy, sad, or angry. An evaluative challenge facing FER\nalgorithms is the fall in performance when detecting spontaneous expressions\ncompared to posed expressions. An ethical (and evaluative) challenge facing FER\nalgorithms is that they tend to perform poorly for people of some races and\nskin colors. These challenges are linked to the data collection practices\nemployed in the creation of FER datasets. In this study, we audit two\nstate-of-the-art FER datasets. We take random samples from each dataset and\nexamine whether images are spontaneous or posed. In doing so, we propose a\nmethodology for identifying spontaneous or posed images. We discover a\nsignificant number of images that were posed in the datasets purporting to\nconsist of in-the-wild images. Since performance of FER models vary between\nspontaneous and posed images, the performance of models trained on these\ndatasets will not represent the true performance if such models were to be\ndeployed in in-the-wild applications. We also observe the skin color of\nindividuals in the samples, and test three models trained on each of the\ndatasets to predict facial expressions of people from various races and skin\ntones. We find that the FER models audited were more likely to predict people\nlabeled as not white or determined to have dark skin as showing a negative\nemotion such as anger or sadness even when they were smiling. This bias makes\nsuch models prone to perpetuate harm in real life applications.", "AI": {"tldr": "\u8be5\u7814\u7a76\u53d1\u73b0\uff0c\u9762\u90e8\u8868\u60c5\u8bc6\u522b\uff08FER\uff09\u7b97\u6cd5\u5728\u8bc6\u522b\u81ea\u53d1\u8868\u60c5\u548c\u4e0d\u540c\u80a4\u8272\u4eba\u7fa4\u7684\u8868\u60c5\u65f6\u5b58\u5728\u6027\u80fd\u95ee\u9898\uff0c\u8fd9\u5f52\u56e0\u4e8e\u6570\u636e\u96c6\u7684\u504f\u5dee\u3002\u7814\u7a76\u5ba1\u8ba1\u4e86\u4e24\u4e2aFER\u6570\u636e\u96c6\uff0c\u53d1\u73b0\u5176\u4e2d\u6df7\u6709\u5927\u91cf\u6446\u62cd\u8868\u60c5\u56fe\u50cf\uff0c\u5e76\u4e14\u6a21\u578b\u5bf9\u975e\u767d\u4eba\u6216\u6df1\u80a4\u8272\u4eba\u7fa4\u5b58\u5728\u8bc6\u522b\u504f\u89c1\uff0c\u503e\u5411\u4e8e\u5c06\u5176\u8bef\u5224\u4e3a\u8d1f\u9762\u60c5\u7eea\uff0c\u8fd9\u53ef\u80fd\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9020\u6210\u4e0d\u826f\u540e\u679c\u3002", "motivation": "\u89e3\u51b3 FER \u7b97\u6cd5\u5728\u8bc6\u522b\u81ea\u53d1\u8868\u60c5\u65f6\u6027\u80fd\u4e0b\u964d\u4ee5\u53ca\u5728\u8de8\u79cd\u65cf\u8bc6\u522b\u65f6\u8868\u73b0\u4e0d\u4f73\u7684\u6311\u6218\uff0c\u8fd9\u4e9b\u6311\u6218\u6e90\u4e8e FER \u6570\u636e\u96c6\u7684\u6784\u5efa\u65b9\u5f0f\u3002", "method": "\u901a\u8fc7\u968f\u673a\u62bd\u6837\u7684\u65b9\u5f0f\u5bf9\u4e24\u4e2a\u6700\u5148\u8fdb\u7684 FER \u6570\u636e\u96c6\u8fdb\u884c\u5ba1\u8ba1\uff0c\u5e76\u68c0\u67e5\u56fe\u50cf\u662f\u5c5e\u4e8e\u81ea\u53d1\u8868\u60c5\u8fd8\u662f\u6446\u62cd\u8868\u60c5\uff0c\u4ee5\u6b64\u63d0\u51fa\u8bc6\u522b\u81ea\u53d1\u6216\u6446\u62cd\u56fe\u50cf\u7684\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u8fd8\u89c2\u5bdf\u4e86\u6837\u672c\u4e2d\u4e2a\u4f53\u7684\u80a4\u8272\uff0c\u5e76\u6d4b\u8bd5\u4e86\u5728\u8fd9\u4e9b\u6570\u636e\u4e0a\u8bad\u7ec3\u7684\u4e09\u4e2a\u6a21\u578b\uff0c\u4ee5\u8bc4\u4f30\u5176\u5bf9\u4e0d\u540c\u79cd\u65cf\u548c\u80a4\u8272\u4e2a\u4f53\u9762\u90e8\u8868\u60c5\u7684\u9884\u6d4b\u80fd\u529b\u3002", "result": "\u5728\u58f0\u79f0\u5305\u542b\u201cin-the-wild\u201d\u56fe\u50cf\u7684\u6570\u636e\u96c6\u4e2d\u53d1\u73b0\u4e86\u5927\u91cf\u6446\u62cd\u56fe\u50cf\uff0c\u8fd9\u610f\u5473\u7740\u5728\u8fd9\u4e9b\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u65e0\u6cd5\u51c6\u786e\u53cd\u6620\u5176\u5728\u771f\u5b9e\u5e94\u7528\u573a\u666f\u4e0b\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0c\u7814\u7a76\u53d1\u73b0 FER \u6a21\u578b\u66f4\u6709\u53ef\u80fd\u5c06\u90a3\u4e9b\u88ab\u6807\u8bb0\u4e3a\u975e\u767d\u4eba\u6216\u80a4\u8272\u8f83\u6df1\u7684\u4eba\u8bc6\u522b\u4e3a\u8d1f\u9762\u60c5\u7eea\uff08\u5982\u6124\u6012\u6216\u60b2\u4f24\uff09\uff0c\u5373\u4f7f\u4ed6\u4eec\u5b9e\u9645\u4e0a\u5728\u5fae\u7b11\u3002\u8fd9\u79cd\u504f\u5dee\u4f1a\u4f7f\u6a21\u578b\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u4ea7\u751f\u548c\u52a0\u5267\u4f24\u5bb3\u3002", "conclusion": "FER \u6a21\u578b\u5728\u5904\u7406\u81ea\u53d1\u8868\u60c5\u548c\u8de8\u79cd\u65cf\u8bc6\u522b\u65b9\u9762\u5b58\u5728\u6027\u80fd\u5dee\u8ddd\uff0c\u8fd9\u4e0e FER \u6570\u636e\u96c6\u7684\u6784\u5efa\u65b9\u5f0f\u6709\u5173\u3002\u7814\u7a76\u5ba1\u8ba1\u4e86\u4e24\u4e2a FER \u6570\u636e\u96c6\uff0c\u53d1\u73b0\u5176\u4e2d\u5305\u542b\u5927\u91cf\u6446\u62cd\u8868\u60c5\u56fe\u50cf\uff0c\u5e76\u4e14\u6a21\u578b\u5bf9\u975e\u767d\u4eba\u6216\u6df1\u80a4\u8272\u4e2a\u4f53\u7684\u8bc6\u522b\u5b58\u5728\u504f\u89c1\uff0c\u503e\u5411\u4e8e\u5c06\u5176\u5f52\u7c7b\u4e3a\u8d1f\u9762\u60c5\u7eea\uff0c\u5373\u4f7f\u4ed6\u4eec\u5b9e\u9645\u4e0a\u5728\u5fae\u7b11\u3002\u8fd9\u79cd\u504f\u89c1\u53ef\u80fd\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u9020\u6210\u5371\u5bb3\u3002"}}
{"id": "2507.10571", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.10571", "abs": "https://arxiv.org/abs/2507.10571", "authors": ["Konstantinos I. Roumeliotis", "Ranjan Sapkota", "Manoj Karkee", "Nikolaos D. Tselikas"], "title": "Orchestrator-Agent Trust: A Modular Agentic AI Visual Classification System with Trust-Aware Orchestration and RAG-Based Reasoning", "comment": null, "summary": "Modern Artificial Intelligence (AI) increasingly relies on multi-agent\narchitectures that blend visual and language understanding. Yet, a pressing\nchallenge remains: How can we trust these agents especially in zero-shot\nsettings with no fine-tuning? We introduce a novel modular Agentic AI visual\nclassification framework that integrates generalist multimodal agents with a\nnon-visual reasoning orchestrator and a Retrieval-Augmented Generation (RAG)\nmodule. Applied to apple leaf disease diagnosis, we benchmark three\nconfigurations: (I) zero-shot with confidence-based orchestration, (II)\nfine-tuned agents with improved performance, and (III) trust-calibrated\norchestration enhanced by CLIP-based image retrieval and re-evaluation loops.\nUsing confidence calibration metrics (ECE, OCR, CCC), the orchestrator\nmodulates trust across agents. Our results demonstrate a 77.94\\% accuracy\nimprovement in the zero-shot setting using trust-aware orchestration and RAG,\nachieving 85.63\\% overall. GPT-4o showed better calibration, while Qwen-2.5-VL\ndisplayed overconfidence. Furthermore, image-RAG grounded predictions with\nvisually similar cases, enabling correction of agent overconfidence via\niterative re-evaluation. The proposed system separates perception (vision\nagents) from meta-reasoning (orchestrator), enabling scalable and interpretable\nmulti-agent AI. This blueprint is extensible to diagnostics, biology, and other\ntrust-critical domains. All models, prompts, results, and system components\nincluding the complete software source code are openly released to support\nreproducibility, transparency, and community benchmarking at Github:\nhttps://github.com/Applied-AI-Research-Lab/Orchestrator-Agent-Trust", "AI": {"tldr": "\u901a\u8fc7\u7ed3\u5408\u901a\u7528\u89c6\u89c9\u667a\u80fd\u4f53\u3001\u63a8\u7406\u534f\u8c03\u5668\u548c RAG \u6a21\u5757\uff0c\u5e76\u5728\u82f9\u679c\u53f6\u75c5\u8bca\u65ad\u4e2d\u8fdb\u884c\u8bc4\u4f30\uff0c\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684 Agentic AI \u6846\u67b6\uff0c\u4ee5\u63d0\u9ad8\u96f6\u6837\u672c\u573a\u666f\u4e0b\u591a\u667a\u80fd\u4f53 AI \u7684\u4fe1\u4efb\u5ea6\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u5728\u73b0\u4ee3\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u65e5\u76ca\u4f9d\u8d56\u878d\u5408\u89c6\u89c9\u548c\u8bed\u8a00\u7406\u89e3\u7684\u591a\u667a\u80fd\u4f53\u67b6\u6784\u7684\u80cc\u666f\u4e0b\uff0c\u5982\u4f55\u5728\u96f6\u6837\u672c\uff08\u65e0\u9700\u5fae\u8c03\uff09\u8bbe\u7f6e\u4e0b\u4fe1\u4efb\u8fd9\u4e9b\u667a\u80fd\u4f53\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u5757\u5316 Agentic AI \u89c6\u89c9\u5206\u7c7b\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u96c6\u6210\u4e86\u901a\u7528\u591a\u6a21\u6001\u667a\u80fd\u4f53\u3001\u975e\u89c6\u89c9\u63a8\u7406\u534f\u8c03\u5668\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6a21\u5757\u3002\u901a\u8fc7\u4e09\u79cd\u914d\u7f6e\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff1a(I) \u96f6\u6837\u672c\u7f6e\u4fe1\u5ea6\u534f\u8c03\uff1b(II) \u5fae\u8c03\u667a\u80fd\u4f53\uff1b(III) \u57fa\u4e8e CLIP \u56fe\u50cf\u68c0\u7d22\u548c\u91cd\u65b0\u8bc4\u4f30\u5faa\u73af\u589e\u5f3a\u7684\u4fe1\u4efb\u6821\u51c6\u534f\u8c03\u3002\u4f7f\u7528\u7f6e\u4fe1\u5ea6\u6821\u51c6\u6307\u6807\uff08ECE, OCR, CCC\uff09\u6765\u8c03\u8282\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u4fe1\u4efb\u5ea6\u3002", "result": "\u5728\u82f9\u679c\u53f6\u75c5\u8bca\u65ad\u5e94\u7528\u4e2d\uff0c\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u4f7f\u7528\u4fe1\u4efb\u611f\u77e5\u534f\u8c03\u548c RAG \u7684\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u63d0\u9ad8\u4e86 77.94%\uff0c\u8fbe\u5230 85.63%\u3002GPT-4o \u8868\u73b0\u51fa\u66f4\u597d\u7684\u6821\u51c6\u6027\uff0c\u800c Qwen-2.5-VL \u5219\u5b58\u5728\u8fc7\u5ea6\u81ea\u4fe1\u95ee\u9898\u3002\u56fe\u50cf RAG \u901a\u8fc7\u89c6\u89c9\u76f8\u4f3c\u6848\u4f8b\u7684\u5173\u8054\uff0c\u5b9e\u73b0\u4e86\u5bf9\u667a\u80fd\u4f53\u8fc7\u5ea6\u81ea\u4fe1\u7684\u7ea0\u6b63\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u521b\u65b0\u7684\u6a21\u5757\u5316 Agentic AI \u89c6\u89c9\u5206\u7c7b\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u6210\u901a\u7528\u591a\u6a21\u6001\u667a\u80fd\u4f53\u3001\u975e\u89c6\u89c9\u63a8\u7406\u534f\u8c03\u5668\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6a21\u5757\uff0c\u89e3\u51b3\u4e86\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u4fe1\u4efb\u591a\u667a\u80fd\u4f53 AI \u7684\u6311\u6218\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u7ed3\u5408\u4fe1\u4efb\u611f\u77e5\u534f\u8c03\u548c RAG \u7684\u96f6\u6837\u672c\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u63d0\u9ad8\u4e86 77.94%\uff0c\u603b\u4f53\u8fbe\u5230 85.63%\u3002\u8be5\u6846\u67b6\u5c06\u611f\u77e5\uff08\u89c6\u89c9\u667a\u80fd\u4f53\uff09\u4e0e\u5143\u63a8\u7406\uff08\u534f\u8c03\u5668\uff09\u5206\u79bb\uff0c\u63d0\u9ad8\u4e86\u53ef\u6269\u5c55\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u53ef\u5e94\u7528\u4e8e\u8bca\u65ad\u3001\u751f\u7269\u5b66\u548c\u5176\u4ed6\u4fe1\u4efb\u5173\u952e\u9886\u57df\u3002"}}
{"id": "2507.10582", "categories": ["cs.CL", "stat.ME"], "pdf": "https://arxiv.org/pdf/2507.10582", "abs": "https://arxiv.org/abs/2507.10582", "authors": ["Anders Ledberg", "Anna Thal\u00e9n"], "title": "Transforming Sensitive Documents into Quantitative Data: An AI-Based Preprocessing Toolchain for Structured and Privacy-Conscious Analysis", "comment": null, "summary": "Unstructured text from legal, medical, and administrative sources offers a\nrich but underutilized resource for research in public health and the social\nsciences. However, large-scale analysis is hampered by two key challenges: the\npresence of sensitive, personally identifiable information, and significant\nheterogeneity in structure and language. We present a modular toolchain that\nprepares such text data for embedding-based analysis, relying entirely on\nopen-weight models that run on local hardware, requiring only a\nworkstation-level GPU and supporting privacy-sensitive research.\n  The toolchain employs large language model (LLM) prompting to standardize,\nsummarize, and, when needed, translate texts to English for greater\ncomparability. Anonymization is achieved via LLM-based redaction, supplemented\nwith named entity recognition and rule-based methods to minimize the risk of\ndisclosure. We demonstrate the toolchain on a corpus of 10,842 Swedish court\ndecisions under the Care of Abusers Act (LVM), comprising over 56,000 pages.\nEach document is processed into an anonymized, standardized summary and\ntransformed into a document-level embedding. Validation, including manual\nreview, automated scanning, and predictive evaluation shows the toolchain\neffectively removes identifying information while retaining semantic content.\nAs an illustrative application, we train a predictive model using embedding\nvectors derived from a small set of manually labeled summaries, demonstrating\nthe toolchain's capacity for semi-automated content analysis at scale.\n  By enabling structured, privacy-conscious analysis of sensitive documents,\nour toolchain opens new possibilities for large-scale research in domains where\ntextual data was previously inaccessible due to privacy and heterogeneity\nconstraints.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b LLM \u63d0\u793a\u3001\u533f\u540d\u5316\u548c\u5d4c\u5165\u751f\u6210\u7684\u5de5\u5177\u94fe\uff0c\u7528\u4e8e\u5206\u6790\u745e\u5178\u6cd5\u9662\u7684\u654f\u611f\u6cd5\u5f8b\u6587\u4ef6\uff0c\u6210\u529f\u5730\u5b9e\u73b0\u4e86\u6570\u636e\u533f\u540d\u5316\u548c\u7ed3\u6784\u5316\uff0c\u5e76\u652f\u6301\u5927\u89c4\u6a21\u5185\u5bb9\u5206\u6790\u3002", "motivation": "\u975e\u7ed3\u6784\u5316\u6cd5\u5f8b\u3001\u533b\u7597\u548c\u884c\u653f\u6765\u6e90\u7684\u6587\u672c\u4e3a\u516c\u5171\u536b\u751f\u548c\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u4e30\u5bcc\u4f46\u672a\u88ab\u5145\u5206\u5229\u7528\u7684\u8d44\u6e90\u3002\u7136\u800c\uff0c\u5927\u89c4\u6a21\u5206\u6790\u53d7\u5230\u4e24\u4e2a\u5173\u952e\u6311\u6218\u7684\u963b\u788d\uff1a\u5b58\u5728\u654f\u611f\u7684\u3001\u53ef\u8bc6\u522b\u7684\u4e2a\u4eba\u4fe1\u606f\uff0c\u4ee5\u53ca\u5728\u7ed3\u6784\u548c\u8bed\u8a00\u4e0a\u7684\u663e\u8457\u5dee\u5f02\u3002\u672c\u7814\u7a76\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u5de5\u5177\u94fe\uff0c\u4ee5\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\uff0c\u5b9e\u73b0\u5bf9\u654f\u611f\u6587\u672c\u6570\u636e\u7684\u53ef\u6269\u5c55\u5206\u6790\u3002", "method": "\u8be5\u5de5\u5177\u94fe\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63d0\u793a\u6765\u6807\u51c6\u5316\u3001\u6458\u8981\u548c\u7ffb\u8bd1\u6587\u672c\uff08\u5982\u6709\u5fc5\u8981\uff09\u4e3a\u82f1\u8bed\uff0c\u4ee5\u63d0\u9ad8\u53ef\u6bd4\u6027\u3002\u901a\u8fc7\u57fa\u4e8e LLM \u7684 redaction\uff0c\u5e76\u8f85\u4ee5\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u533f\u540d\u5316\uff0c\u4ee5\u6700\u5927\u9650\u5ea6\u5730\u964d\u4f4e\u6cc4\u9732\u98ce\u9669\u3002\u5728\u745e\u5178\u6cd5\u9662\u5173\u4e8e\u300a\u6ee5\u7528\u8005\u5173\u6000\u6cd5\u300b\uff08LVM\uff09\u7684 10,842 \u4efd\u88c1\u51b3\u8bed\u6599\u5e93\uff08\u8d85\u8fc7 56,000 \u9875\uff09\u4e0a\u5c55\u793a\u4e86\u8be5\u5de5\u5177\u94fe\u3002\u6bcf\u4e2a\u6587\u6863\u90fd\u88ab\u5904\u7406\u6210\u533f\u540d\u5316\u3001\u6807\u51c6\u5316\u7684\u6458\u8981\uff0c\u5e76\u8f6c\u6362\u4e3a\u6587\u6863\u7ea7\u5d4c\u5165\u3002", "result": "\u8be5\u5de5\u5177\u94fe\u5df2\u88ab\u8bc1\u660e\u53ef\u4ee5\u6709\u6548\u53bb\u9664\u8bc6\u522b\u4fe1\u606f\uff0c\u540c\u65f6\u4fdd\u7559\u8bed\u4e49\u5185\u5bb9\u3002\u901a\u8fc7\u5bf9\u7531\u624b\u52a8\u6807\u8bb0\u6458\u8981\u7ec4\u6210\u7684\u8bed\u6599\u5e93\u8fdb\u884c\u8bad\u7ec3\uff0c\u8bc1\u660e\u4e86\u8be5\u5de5\u5177\u94fe\u5728\u5927\u89c4\u6a21\u534a\u81ea\u52a8\u5316\u5185\u5bb9\u5206\u6790\u65b9\u9762\u7684\u80fd\u529b\u3002", "conclusion": "\u8be5\u5de5\u5177\u94fe\u901a\u8fc7\u5b9e\u73b0\u5bf9\u654f\u611f\u6587\u6863\u7684\u7ed3\u6784\u5316\u3001\u6ce8\u91cd\u9690\u79c1\u7684\u5206\u6790\uff0c\u4e3a\u4e4b\u524d\u56e0\u9690\u79c1\u548c\u5f02\u6784\u6027\u9650\u5236\u800c\u65e0\u6cd5\u8bbf\u95ee\u7684\u6587\u672c\u6570\u636e\u9886\u57df\u7684\u5927\u89c4\u6a21\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2507.10563", "categories": ["cs.NE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10563", "abs": "https://arxiv.org/abs/2507.10563", "authors": ["Antonis Messinis"], "title": "A Biomimetic Way for Coral-Reef-Inspired Swarm Intelligence for Carbon-Neutral Wastewater Treatment", "comment": null, "summary": "With increasing wastewater rates, achieving energy-neutral purification is\nchallenging. We introduce a coral-reef-inspired Swarm Interaction Network for\ncarbon-neutral wastewater treatment, combining morphogenetic abstraction with\nmulti-task carbon awareness. Scalability stems from linear token complexity,\nmitigating the energy-removal problem. Compared with seven baselines, our\napproach achieves 96.7\\% removal efficiency, 0.31~kWh~m$^{-3}$ energy\nconsumption, and 14.2~g~m$^{-3}$ CO$_2$ emissions. Variance analysis\ndemonstrates robustness under sensor drift. Field scenarios--insular lagoons,\nbrewery spikes, and desert greenhouses--show potential diesel savings of up to\n22\\%. However, data-science staffing remains an impediment. Future work will\nintegrate AutoML wrappers within the project scope, although governance\nrestrictions pose interpretability challenges that require further visual\nanalytics.", "AI": {"tldr": "\u8fd9\u9879\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u53d7\u73ca\u745a\u7901\u542f\u53d1\u7684\u7fa4\u96c6\u4ea4\u4e92\u7f51\u7edc\uff0c\u7528\u4e8e\u78b3\u4e2d\u548c\u5e9f\u6c34\u5904\u7406\uff0c\u5b9e\u73b0\u4e86\u9ad8\u53bb\u9664\u6548\u7387\u548c\u4f4e\u80fd\u8017\uff0c\u5e76\u6709\u6f5c\u529b\u8282\u7701\u67f4\u6cb9\uff0c\u4f46\u6570\u636e\u79d1\u5b66\u4eba\u5458\u548c\u53ef\u89e3\u91ca\u6027\u662f\u672a\u6765\u7684\u6311\u6218\u3002", "motivation": "\u968f\u7740\u5e9f\u6c34\u5904\u7406\u7387\u7684\u589e\u52a0\uff0c\u5b9e\u73b0\u80fd\u6e90\u4e2d\u548c\u7684\u51c0\u5316\u8fc7\u7a0b\u9762\u4e34\u6311\u6218\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u53d7\u73ca\u745a\u7901\u542f\u53d1\u7684\u7fa4\u96c6\u4ea4\u4e92\u7f51\u7edc\uff08Swarm Interaction Network\uff09\uff0c\u5e76\u7ed3\u5408\u4e86\u5f62\u6001\u53d1\u751f\u62bd\u8c61\u548c\u591a\u4efb\u52a1\u78b3\u611f\u77e5\u6280\u672f\uff0c\u4ee5\u5b9e\u73b0\u78b3\u4e2d\u548c\u5e9f\u6c34\u5904\u7406\u3002", "result": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86 96.7% \u7684\u53bb\u9664\u6548\u7387\uff0c0.31 kWh m$^{-3}$ \u7684\u80fd\u8017\u548c 14.2 g m$^{-3}$ \u7684 CO$_{2}$ \u6392\u653e\u91cf\uff0c\u5e76\u5728\u5c9b\u5c7f\u6cfb\u6e56\u3001\u5564\u9152\u5382\u5e9f\u6c34\u548c\u6c99\u6f20\u6e29\u5ba4\u7b49\u73b0\u573a\u60c5\u666f\u4e2d\u663e\u793a\u51fa\u9ad8\u8fbe 22% \u7684\u67f4\u6cb9\u8282\u7701\u6f5c\u529b\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u79cd\u53d7\u73ca\u745a\u7901\u542f\u53d1\u7684\u3001\u7528\u4e8e\u78b3\u4e2d\u548c\u5e9f\u6c34\u5904\u7406\u7684\u7fa4\u96c6\u4ea4\u4e92\u7f51\u7edc\uff0c\u8be5\u7f51\u7edc\u7ed3\u5408\u4e86\u5f62\u6001\u53d1\u751f\u62bd\u8c61\u548c\u591a\u4efb\u52a1\u78b3\u611f\u77e5\u3002\u4e0e\u4e03\u4e2a\u57fa\u7ebf\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86 96.7% \u7684\u53bb\u9664\u6548\u7387\uff0c0.31 kWh m$^{-3}$ \u7684\u80fd\u8017\u548c 14.2 g m$^{-3}$ \u7684 CO$_{2}$ \u6392\u653e\u91cf\u3002\u65b9\u5dee\u5206\u6790\u8bc1\u660e\u4e86\u5176\u5728\u4f20\u611f\u5668\u6f02\u79fb\u4e0b\u7684\u9c81\u68d2\u6027\u3002\u73b0\u573a\u60c5\u666f\u2014\u2014\u5c9b\u5c7f\u6cfb\u6e56\u3001\u5564\u9152\u5382\u5e9f\u6c34\u548c\u6c99\u6f20\u6e29\u5ba4\u2014\u2014\u663e\u793a\u51fa\u9ad8\u8fbe 22% \u7684\u67f4\u6cb9\u8282\u7701\u6f5c\u529b\u3002"}}
{"id": "2507.11067", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2507.11067", "abs": "https://arxiv.org/abs/2507.11067", "authors": ["Yinuo Wang", "Tianqi Mao", "Lin Gan", "Wubing Wan", "Zeyu Song", "Jiayu Fu", "Lanke He", "Wenqiang Wang", "Zekun Yin", "Wei Xue", "Guangwen Yang"], "title": "MMStencil: Optimizing High-order Stencils on Multicore CPU using Matrix Unit", "comment": "Yinuo Wang and Tianqi Mao contributed equally to this work", "summary": "Matrix-accelerated stencil computation is a hot research topic, yet its\napplication to three-dimensional (3D) high-order stencils and HPC remains\nunderexplored. With the emergence of matrix units on multicore CPUs, we analyze\nmatrix-based acceleration strategies and tailor an optimal approach for 3D\nhigh-order stencils. We introduce algorithmic optimizations based on SIMD and\nmatrix units to address strided memory accesses, alignment conflicts, and\nredundant accesses. We propose memory optimizations to boost on-package memory\nefficiency, and a novel multi-thread parallelism paradigm to overcome\ndata-sharing challenges caused by the absence of shared data caches. MMStencil\nsustains consistently high hardware utilization across diverse stencil shapes\nand dimensions. Our DMA-based inter-NUMA communication further mitigates NUMA\neffects and MPI limitations in hybrid parallelism. Combining all the\ninnovations, MMStencil outperforms state-of-the-art libraries on Nvidia A100\nGPGPU by up to 2.1x. Moreover, the performance improvements translate directly\nto real-world HPC applications and enable RTM applications to yield 1.8x\nspeedup versus a highly optimized industrial Nvidia A100 GPGPU version.", "AI": {"tldr": "MMStencil optimizes matrix-accelerated stencil computation for 3D high-order stencils and HPC using SIMD, matrix units, and advanced parallelism, achieving significant performance gains.", "motivation": "To explore the underexplored application of matrix-accelerated stencil computation to three-dimensional (3D) high-order stencils and HPC, addressing challenges like strided memory accesses, alignment conflicts, redundant accesses, and data-sharing issues in multicore CPUs with matrix units.", "method": "The study analyzes matrix-based acceleration strategies for 3D high-order stencils, introducing algorithmic optimizations (SIMD, matrix units) and memory optimizations. It also proposes a multi-thread parallelism paradigm and DMA-based inter-NUMA communication.", "result": "MMStencil achieves high hardware utilization, outperforms state-of-the-art libraries on Nvidia A100 GPGPU by up to 2.1x, and provides 1.8x speedup for RTM applications compared to a highly optimized industrial version.", "conclusion": "Matrix-accelerated stencil computation is effective for 3D high-order stencils and HPC, outperforming state-of-the-art libraries and enabling significant speedups in real-world applications like RTM."}}
{"id": "2507.10644", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.HC", "cs.MA", "I.2.11; I.2.7; C.2.4; K.6.5; I.2.4"], "pdf": "https://arxiv.org/pdf/2507.10644", "abs": "https://arxiv.org/abs/2507.10644", "authors": ["Tatiana Petrova", "Aleksandr Puzikov", "Boris Bliznukov", "Radu State"], "title": "From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents", "comment": "33 pages, 9 figures, 8 tables", "summary": "The concept of the Web of Agents (WoA), which transforms the static,\ndocument-centric Web into an environment of autonomous agents acting on users'\nbehalf, has attracted growing interest as large language models (LLMs) become\nmore capable. However, research in this area is still fragmented across\ndifferent communities. Contemporary surveys catalog the latest LLM-powered\nframeworks, while the rich histories of Multi-Agent Systems (MAS) and the\nSemantic Web are often treated as separate, legacy domains. This fragmentation\nobscures the intellectual lineage of modern systems and hinders a holistic\nunderstanding of the field's trajectory. We present the first comprehensive\nevolutionary overview of the WoA. We show that modern protocols like A2A and\nthe MCP, are direct evolutionary responses to the well-documented limitations\nof earlier standards like FIPA standards and OWL-based semantic agents. To\nsystematize this analysis, we introduce a four-axis taxonomy (semantic\nfoundation, communication paradigm, locus of intelligence, discovery\nmechanism). This framework provides a unified analytical lens for comparing\nagent architectures across all generations, revealing a clear line of descent\nwhere others have seen a disconnect. Our analysis identifies a paradigm shift\nin the 'locus of intelligence': from being encoded in external data (Semantic\nWeb) or the platform (MAS) to being embedded within the agent's core model\n(LLM). This shift is foundational to modern Agentic AI, enabling the scalable\nand adaptive systems the WoA has long envisioned. We conclude that while new\nprotocols are essential, they are insufficient for building a robust, open,\ntrustworthy ecosystem. Finally, we argue that the next research frontier lies\nin solving persistent socio-technical challenges, and we map out a new agenda\nfocused on decentralized identity, economic models, security, and governance\nfor the emerging WoA.", "AI": {"tldr": "\u672c\u7814\u7a76\u9996\u6b21\u5168\u9762\u56de\u987e\u4e86WoA\u7684\u6f14\u53d8\u5386\u7a0b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5206\u7c7b\u6cd5\uff0c\u63ed\u793a\u4e86\u4ece\u8bed\u4e49\u7f51\u548cMAS\u5230LLM\u9a71\u52a8\u7684\u4ee3\u7406\u7684\u6e05\u6670\u6f14\u53d8\u8109\u7edc\uff0c\u5e76\u6307\u51fa\u4e86WoA\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u5728\u4e8e\u89e3\u51b3\u793e\u4f1a\u6280\u672f\u6311\u6218\u3002", "motivation": "\u5f53\u524d\u5173\u4e8eWeb of Agents\uff08WoA\uff09\u7684\u7814\u7a76\u5206\u6563\u5728\u4e0d\u540c\u7684\u793e\u533a\uff0c\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9a71\u52a8\u7684\u6846\u67b6\u3001\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u548c\u8bed\u4e49\u7f51\uff08Semantic Web\uff09\u7684\u5386\u53f2\u89c6\u4e3a\u72ec\u7acb\u7684\u9886\u57df\uff0c\u963b\u788d\u4e86\u5bf9\u8be5\u9886\u57df\u53d1\u5c55\u8f68\u8ff9\u7684\u6574\u4f53\u7406\u89e3\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u56db\u8f74\u5206\u7c7b\u6cd5\uff08\u8bed\u4e49\u57fa\u7840\u3001\u901a\u4fe1\u8303\u5f0f\u3001\u667a\u80fd\u4e2d\u5fc3\u3001\u53d1\u73b0\u673a\u5236\uff09\u6765\u7cfb\u7edf\u5316\u5206\u6790\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u5206\u6790\u89c6\u89d2\u6765\u6bd4\u8f83\u6240\u6709\u4ee3\u7684\u4ee3\u7406\u67b6\u6784\u3002", "result": "\u5c55\u793a\u4e86\u73b0\u4ee3\u534f\u8bae\uff08\u5982A2A\u548cMCP\uff09\u662f\u65e9\u671f\u6807\u51c6\uff08\u5982FIPA\u548c\u57fa\u4e8eOWL\u7684\u8bed\u4e49\u4ee3\u7406\uff09\u5c40\u9650\u6027\u7684\u76f4\u63a5\u6f14\u53d8\u7ed3\u679c\u3002\u8bc6\u522b\u51fa\u201c\u667a\u80fd\u4e2d\u5fc3\u201d\u7684\u8303\u5f0f\u8f6c\u53d8\uff1a\u4ece\u7f16\u7801\u5728\u5916\u90e8\u6570\u636e\uff08\u8bed\u4e49\u7f51\uff09\u6216\u5e73\u53f0\uff08MAS\uff09\u4e2d\uff0c\u8f6c\u53d8\u4e3a\u5d4c\u5165\u4ee3\u7406\u7684\u6838\u5fc3\u6a21\u578b\uff08LLM\uff09\u4e2d\u3002", "conclusion": "\u867d\u7136\u65b0\u7684\u534f\u8bae\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5b83\u4eec\u4e0d\u8db3\u4ee5\u6784\u5efa\u4e00\u4e2a\u5065\u58ee\u3001\u5f00\u653e\u3001\u53ef\u4fe1\u7684\u751f\u6001\u7cfb\u7edf\u3002\u4e0b\u4e00\u7814\u7a76\u524d\u6cbf\u5728\u4e8e\u89e3\u51b3\u6301\u7eed\u5b58\u5728\u7684\u793e\u4f1a\u6280\u672f\u6311\u6218\uff0c\u5e76\u4e3a\u65b0\u5174\u7684\u4ee3\u7406\u7f51\u7edc\uff08WoA\uff09\u5236\u5b9a\u5173\u4e8e\u53bb\u4e2d\u5fc3\u5316\u8eab\u4efd\u3001\u7ecf\u6d4e\u6a21\u578b\u3001\u5b89\u5168\u548c\u6cbb\u7406\u7684\u65b0\u8bae\u7a0b\u3002"}}
{"id": "2507.10946", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2507.10946", "abs": "https://arxiv.org/abs/2507.10946", "authors": ["Alina Ene", "Huy Le Nguyen", "Ta Duy Nguyen", "Adrian Vladu"], "title": "Solving Linear Programs with Differential Privacy", "comment": null, "summary": "We study the problem of solving linear programs of the form $Ax\\le b$,\n$x\\ge0$ with differential privacy. For homogeneous LPs $Ax\\ge0$, we give an\nefficient $(\\epsilon,\\delta)$-differentially private algorithm which with\nprobability at least $1-\\beta$ finds in polynomial time a solution that\nsatisfies all but\n$O(\\frac{d^{2}}{\\epsilon}\\log^{2}\\frac{d}{\\delta\\beta}\\sqrt{\\log\\frac{1}{\\rho_{0}}})$\nconstraints, for problems with margin $\\rho_{0}>0$. This improves the bound of\n$O(\\frac{d^{5}}{\\epsilon}\\log^{1.5}\\frac{1}{\\rho_{0}}\\mathrm{poly}\\log(d,\\frac{1}{\\delta},\\frac{1}{\\beta}))$\nby [Kaplan-Mansour-Moran-Stemmer-Tur, STOC '25]. For general LPs $Ax\\le b$,\n$x\\ge0$ with potentially zero margin, we give an efficient\n$(\\epsilon,\\delta)$-differentially private algorithm that w.h.p drops\n$O(\\frac{d^{4}}{\\epsilon}\\log^{2.5}\\frac{d}{\\delta}\\sqrt{\\log dU})$\nconstraints, where $U$ is an upper bound for the entries of $A$ and $b$ in\nabsolute value. This improves the result by Kaplan et al. by at least a factor\nof $d^{5}$. Our techniques build upon privatizing a rescaling perceptron\nalgorithm by [Hoberg-Rothvoss, IPCO '17] and a more refined iterative procedure\nfor identifying equality constraints by Kaplan et al.", "AI": {"tldr": "This paper presents differentially private algorithms for linear programming that significantly outperform previous methods in terms of accuracy and efficiency, especially for general LP problems.", "motivation": "The paper addresses the challenge of solving linear programs (LPs) under differential privacy constraints, aiming to improve the efficiency and accuracy of private solutions compared to prior work.", "method": "We adapt and improve upon existing algorithms, specifically a rescaling perceptron algorithm and an iterative procedure for identifying equality constraints, to achieve differential privacy for linear programming.", "result": "For homogeneous LPs, we achieve an improved bound on the number of violated constraints. For general LPs, our algorithm offers a substantial improvement (at least a factor of d^5) over the previous best results in terms of the number of dropped constraints.", "conclusion": "Our algorithms provide efficient differentially private solutions for linear programs, improving upon existing bounds by significant factors for both homogeneous and general cases."}}
{"id": "2507.11021", "categories": ["eess.SY", "cs.GT", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.11021", "abs": "https://arxiv.org/abs/2507.11021", "authors": ["Pau de las Heras Molins", "Eric Roy-Almonacid", "Dong Ho Lee", "Lasse Peters", "David Fridovich-Keil", "Georgios Bakirtzis"], "title": "Approximate solutions to games of ordered preference", "comment": null, "summary": "Autonomous vehicles must balance ranked objectives, such as minimizing travel\ntime, ensuring safety, and coordinating with traffic. Games of ordered\npreference effectively model these interactions but become computationally\nintractable as the time horizon, number of players, or number of preference\nlevels increase. While receding horizon frameworks mitigate long-horizon\nintractability by solving sequential shorter games, often warm-started, they do\nnot resolve the complexity growth inherent in existing methods for solving\ngames of ordered preference. This paper introduces a solution strategy that\navoids excessive complexity growth by approximating solutions using\nlexicographic iterated best response (IBR) in receding horizon, termed\n\"lexicographic IBR over time.\" Lexicographic IBR over time uses past\ninformation to accelerate convergence. We demonstrate through simulated traffic\nscenarios that lexicographic IBR over time efficiently computes\napproximate-optimal solutions for receding horizon games of ordered preference,\nconverging towards generalized Nash equilibria.", "AI": {"tldr": "Autonomous vehicles use games of ordered preference to balance objectives like travel time and safety. ", "motivation": "Games of ordered preference effectively model interactions for autonomous vehicles ", "method": "lexicographic iterated best response (IBR) in receding horizon, termed ", "result": "demonstrates through simulated traffic scenarios that lexicographic IBR over time efficiently computes ", "conclusion": "lexicographic IBR over time efficiently computes approximate-optimal solutions for receding horizon games of ordered preference, converging towards generalized Nash equilibria."}}
{"id": "2507.10575", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10575", "abs": "https://arxiv.org/abs/2507.10575", "authors": ["Kieran Chai Kai Ren"], "title": "An Adaptive Volatility-based Learning Rate Scheduler", "comment": null, "summary": "Effective learning rate (LR) scheduling is crucial for training deep neural\nnetworks. However, popular pre-defined and adaptive schedulers can still lead\nto suboptimal generalization. This paper introduces VolSched, a novel adaptive\nLR scheduler inspired by the concept of volatility in stochastic processes like\nGeometric Brownian Motion to dynamically adjust the learning rate. By\ncalculating the ratio between long-term and short-term accuracy volatility,\nVolSched increases the LR to escape plateaus and decreases it to stabilize\ntraining, allowing the model to explore the loss landscape more effectively. We\nevaluate VolSched on the CIFAR-100 dataset against a strong baseline using a\nstandard augmentation pipeline. When paired with ResNet-18 and ResNet-34, our\nscheduler delivers consistent performance gains, improving top-1 accuracy by\n1.4 and 1.3 percentage points respectively. Analysis of the loss curves reveals\nthat VolSched promotes a longer exploration phase. A quantitative analysis of\nthe Hessian shows that VolSched finds a final solution that is 38% flatter than\nthe next-best baseline, allowing the model to obtain wider minima and hence\nbetter generalization performance.", "AI": {"tldr": "VolSched \u662f\u4e00\u79cd\u65b0\u7684\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\uff0c\u901a\u8fc7\u5206\u6790\u51c6\u786e\u6027\u6ce2\u52a8\u7387\u6765\u52a8\u6001\u8c03\u6574\u5b66\u4e60\u7387\uff0c\u4ee5\u63d0\u9ad8\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u6709\u6548\u7684\u5b66\u4e60\u7387\uff08LR\uff09\u8c03\u5ea6\u5bf9\u4e8e\u8bad\u7ec3\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u7684\u8c03\u5ea6\u5668\u53ef\u80fd\u5bfc\u81f4\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u3002", "method": "VolSched \u901a\u8fc7\u8ba1\u7b97\u51c6\u786e\u6027\u6ce2\u52a8\u7387\u6765\u52a8\u6001\u8c03\u6574\u5b66\u4e60\u7387\uff0c\u63d0\u9ad8 LR \u4ee5\u8df3\u51fa\u5e73\u53f0\u671f\uff0c\u964d\u4f4e LR \u4ee5\u7a33\u5b9a\u8bad\u7ec3\u3002", "result": "VolSched \u5728 CIFAR-100 \u6570\u636e\u96c6\u4e0a\u4e0e ResNet-18 \u548c ResNet-34 \u7ed3\u5408\u4f7f\u7528\u65f6\uff0c\u4e00\u81f4\u5730\u63d0\u9ad8\u4e86 top-1 \u51c6\u786e\u7387\uff0c\u5e76\u627e\u5230\u4e86\u6bd4\u6b21\u4f18\u57fa\u7ebf\u5e73\u5766 38% \u7684\u6700\u7ec8\u89e3\u51b3\u65b9\u6848\uff0c\u8868\u660e\u5176\u6cdb\u5316\u80fd\u529b\u5f97\u5230\u63d0\u5347\u3002", "conclusion": "VolSched \u662f\u4e00\u79cd\u65b0\u9896\u7684\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\uff0c\u901a\u8fc7\u8ba1\u7b97\u957f\u671f\u548c\u77ed\u671f\u51c6\u786e\u6027\u6ce2\u52a8\u7387\u4e4b\u95f4\u7684\u6bd4\u7387\u6765\u52a8\u6001\u8c03\u6574\u5b66\u4e60\u7387\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002\u4e0e ResNet-18 \u548c ResNet-34 \u7ed3\u5408\u4f7f\u7528\u65f6\uff0cVolSched \u5206\u522b\u63d0\u9ad8\u4e86 1.4% \u548c 1.3% \u7684 top-1 \u51c6\u786e\u7387\uff0c\u5e76\u627e\u5230\u4e86\u6bd4\u6b21\u4f18\u57fa\u7ebf\u5e73\u5766 38% \u7684\u6700\u7ec8\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.10694", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.10694", "abs": "https://arxiv.org/abs/2507.10694", "authors": ["Francesco Fuentes", "Serigne Diagne", "Zachary Kingston", "Laura H. Blumenschein"], "title": "Exteroception through Proprioception Sensing through Improved Contact Modeling for Soft Growing Robots", "comment": "22 pages, 21 figures, submitted to journal for potential publication", "summary": "Passive deformation due to compliance is a commonly used benefit of soft\nrobots, providing opportunities to achieve robust actuation with few active\ndegrees of freedom. Soft growing robots in particular have shown promise in\nnavigation of unstructured environments due to their passive deformation. If\ntheir collisions and subsequent deformations can be better understood, soft\nrobots could be used to understand the structure of the environment from direct\ntactile measurements. In this work, we propose the use of soft growing robots\nas mapping and exploration tools. We do this by first characterizing collision\nbehavior during discrete turns, then leveraging this model to develop a\ngeometry-based simulator that models robot trajectories in 2D environments.\nFinally, we demonstrate the model and simulator validity by mapping unknown\nenvironments using Monte Carlo sampling to estimate the optimal next deployment\ngiven current knowledge. Over both uniform and non-uniform environments, this\nselection method rapidly approaches ideal actions, showing the potential for\nsoft growing robots in unstructured environment exploration and mapping.", "AI": {"tldr": "\u8f6f\u4f53\u751f\u957f\u673a\u5668\u4eba\u53ef\u901a\u8fc7\u6a21\u578b\u548c\u6a21\u62df\u5668\u7528\u4e8e\u975e\u7ed3\u6784\u5316\u73af\u5883\u7684\u63a2\u7d22\u548c\u6d4b\u7ed8\u3002", "motivation": "\u8f6f\u4f53\u673a\u5668\u4eba\u56e0\u5176\u88ab\u52a8\u7684\u5f62\u53d8\u80fd\u529b\uff0c\u5728\u9c81\u68d2\u9a71\u52a8\u548c\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u5bfc\u822a\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002\u672c\u7814\u7a76\u65e8\u5728\u5229\u7528\u8f6f\u4f53\u751f\u957f\u673a\u5668\u4eba\u7684\u88ab\u52a8\u5f62\u53d8\u7279\u6027\uff0c\u901a\u8fc7\u7406\u89e3\u5176\u78b0\u649e\u548c\u5f62\u53d8\u884c\u4e3a\uff0c\u5c06\u5176\u4f5c\u4e3a\u73af\u5883\u6d4b\u7ed8\u548c\u63a2\u7d22\u7684\u5de5\u5177\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u8868\u5f81\u78b0\u649e\u884c\u4e3a\u548c\u5f00\u53d1\u57fa\u4e8e\u51e0\u4f55\u7684\u6a21\u62df\u5668\u6765\u6a21\u62df\u673a\u5668\u4eba\u8f68\u8ff9\uff0c\u5e76\u5229\u7528\u8499\u7279\u5361\u6d1b\u91c7\u6837\u6765\u4f30\u8ba1\u6700\u4f73\u7684\u673a\u5668\u4eba\u90e8\u7f72\u3002", "result": "\u7814\u7a76\u6210\u529f\u5f00\u53d1\u4e86\u4e00\u4e2a\u80fd\u591f\u6a21\u62df\u673a\u5668\u4eba\u8f68\u8ff9\u7684\u6a21\u62df\u5668\uff0c\u5e76\u901a\u8fc7\u5728\u672a\u77e5\u73af\u5883\u4e2d\u8fdb\u884c\u6d4b\u7ed8\uff0c\u8bc1\u660e\u4e86\u8be5\u6a21\u578b\u548c\u6a21\u62df\u5668\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u8f6f\u4f53\u751f\u957f\u673a\u5668\u4eba\u80fd\u591f\u6709\u6548\u5730\u7528\u4e8e\u63a2\u7d22\u548c\u6d4b\u7ed8\u672a\u77e5\u73af\u5883\uff0c\u5e76\u4e14\u5728\u5747\u5300\u548c\u975e\u5747\u5300\u73af\u5883\u4e2d\uff0c\u5176\u52a8\u4f5c\u9009\u62e9\u65b9\u6cd5\u80fd\u5feb\u901f\u63a5\u8fd1\u7406\u60f3\u72b6\u6001\u3002"}}
{"id": "2507.10748", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2507.10748", "abs": "https://arxiv.org/abs/2507.10748", "authors": ["Jason Ho", "James A. Boyle", "Linshen Liu", "Andreas Gerstlauer"], "title": "LASANA: Large-scale Surrogate Modeling for Analog Neuromorphic Architecture Exploration", "comment": null, "summary": "Neuromorphic systems using in-memory or event-driven computing are motivated\nby the need for more energy-efficient processing of artificial intelligence\nworkloads. Emerging neuromorphic architectures aim to combine traditional\ndigital designs with the computational efficiency of analog computing and novel\ndevice technologies. A crucial problem in the rapid exploration and co-design\nof such architectures is the lack of tools for fast and accurate modeling and\nsimulation. Typical mixed-signal design tools integrate a digital simulator\nwith an analog solver like SPICE, which is prohibitively slow for large\nsystems. By contrast, behavioral modeling of analog components is faster, but\nexisting approaches are fixed to specific architectures with limited energy and\nperformance modeling. In this paper, we propose LASANA, a novel approach that\nleverages machine learning to derive data-driven surrogate models of analog\nsub-blocks in a digital backend architecture. LASANA uses SPICE-level\nsimulations of a circuit to train ML models that predict circuit energy,\nperformance, and behavior at analog/digital interfaces. Such models can provide\nenergy and performance annotation on top of existing behavioral models or\nfunction as replacements to analog simulation. We apply LASANA to an analog\ncrossbar array and a spiking neuron circuit. Running MNIST and spiking MNIST,\nLASANA surrogates demonstrate up to three orders of magnitude speedup over\nSPICE, with energy, latency, and behavioral error less than 7%, 8%, and 2%,\nrespectively.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.11465", "categories": ["cs.GR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11465", "abs": "https://arxiv.org/abs/2507.11465", "authors": ["Nuri Ryu", "Jiyun Won", "Jooeun Son", "Minsu Gong", "Joo-Haeng Lee", "Sunghyun Cho"], "title": "Elevating 3D Models: High-Quality Texture and Geometry Refinement from a Low-Quality Model", "comment": "Accepted to SIGGRAPH 2025. For the project page, see\n  https://cg.postech.ac.kr/research/Elevate3D/", "summary": "High-quality 3D assets are essential for various applications in computer\ngraphics and 3D vision but remain scarce due to significant acquisition costs.\nTo address this shortage, we introduce Elevate3D, a novel framework that\ntransforms readily accessible low-quality 3D assets into higher quality. At the\ncore of Elevate3D is HFS-SDEdit, a specialized texture enhancement method that\nsignificantly improves texture quality while preserving the appearance and\ngeometry while fixing its degradations. Furthermore, Elevate3D operates in a\nview-by-view manner, alternating between texture and geometry refinement.\nUnlike previous methods that have largely overlooked geometry refinement, our\nframework leverages geometric cues from images refined with HFS-SDEdit by\nemploying state-of-the-art monocular geometry predictors. This approach ensures\ndetailed and accurate geometry that aligns seamlessly with the enhanced\ntexture. Elevate3D outperforms recent competitors by achieving state-of-the-art\nquality in 3D model refinement, effectively addressing the scarcity of\nhigh-quality open-source 3D assets.", "AI": {"tldr": "Elevate3D\u662f\u4e00\u4e2a\u65b0\u7684\u6846\u67b6\uff0c\u53ef\u4ee5\u63d0\u9ad8\u4f4e\u8d28\u91cf3D\u8d44\u4ea7\u7684\u8d28\u91cf\u3002\u5b83\u4f7f\u7528\u540d\u4e3aHFS-SDEdit\u7684\u7eb9\u7406\u589e\u5f3a\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5728\u7eb9\u7406\u548c\u51e0\u4f55\u4e4b\u95f4\u4ea4\u66ff\u6765\u6539\u8fdb\u6a21\u578b\u3002\u4e0e\u5176\u4ed6\u65b9\u6cd5\u4e0d\u540c\uff0cElevate3D\u8fd8\u5305\u62ec\u51e0\u4f55\u7cbe\u70bc\uff0c\u5229\u7528\u56fe\u50cf\u4e2d\u7684\u51e0\u4f55\u7ebf\u7d22\u6765\u521b\u5efa\u66f4\u7cbe\u786e\u7684\u6a21\u578b\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u8ba1\u7b97\u673a\u56fe\u5f62\u5b66\u548c3D\u89c6\u89c9\u5e94\u7528\u4e2d\u9ad8\u8d28\u91cf3D\u8d44\u4ea7\u7a00\u7f3a\u4e14\u83b7\u53d6\u6210\u672c\u9ad8\u6602\u7684\u95ee\u9898\uff0c\u63d0\u51faElevate3D\u6846\u67b6\u6765\u63d0\u5347\u4f4e\u8d28\u91cf3D\u8d44\u4ea7\u7684\u8d28\u91cf\u3002", "method": "Elevate3D\u6846\u67b6\u901a\u8fc7HFS-SDEdit\u8fdb\u884c\u7eb9\u7406\u589e\u5f3a\uff0c\u5e76\u5229\u7528HFS-SDEdit\u4f18\u5316\u540e\u7684\u56fe\u50cf\u4e2d\u7684\u51e0\u4f55\u7ebf\u7d22\uff0c\u901a\u8fc7\u6700\u5148\u8fdb\u7684\u5355\u76ee\u51e0\u4f55\u9884\u6d4b\u5668\u8fdb\u884c\u51e0\u4f55\u7cbe\u70bc\uff0c\u5b9e\u73b0\u89c6\u56fe\u4e0e\u89c6\u56fe\u7684\u4ea4\u66ff\u4f18\u5316\u3002", "result": "Elevate3D\u57283D\u6a21\u578b\u7cbe\u70bc\u65b9\u9762\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u8d28\u91cf\uff0c\u4f18\u4e8e\u8fd1\u671f\u7684\u65b9\u6cd5\u3002", "conclusion": "Elevate3D\u901a\u8fc7HFS-SDEdit\u548c\u51e0\u4f55\u7ebf\u7d22\u4f18\u5316\uff0c\u57283D\u6a21\u578b\u7cbe\u70bc\u65b9\u9762\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u8d28\u91cf\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u9ad8\u8d28\u91cf\u5f00\u6e903D\u8d44\u4ea7\u7a00\u7f3a\u7684\u95ee\u9898\u3002"}}
{"id": "2507.11036", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.11036", "abs": "https://arxiv.org/abs/2507.11036", "authors": ["Salman Liaquat", "Ijaz Haider Naqvi", "Nor Muzlifah Mahyuddin"], "title": "Dual RIS-Assisted Monostatic L-Band Radar Target Detection in NLoS Scenarios", "comment": "Accepted for presentation at the 9th International Conference on\n  Communications and Future Internet", "summary": "The use of a single Reconfigurable Intelligent Surface (RIS) to boost the\nsignal-to-noise ratio (SNR) at the radar offers significant improvement in\ndetecting targets, especially in non-line-of-sight (NLoS) scenarios. However,\nthere are scenarios where no path exists between the radar and the target, even\nwith a single RIS-assisted radar, due to other present obstacles. This paper\nderives an expression for SNR in target detection scenarios where dual RISs\nassist a monostatic radar in NLoS situations. We calculate the power received\nat the radar through a dual RIS configuration. We show that the SNR performance\nof RIS-assisted radars can improve with known locations of the radar and RISs.\nOur results demonstrate that the required accuracy in target localization can\nbe achieved by controlling the number of RISs, the number of unit cells in each\nRIS, and properly selecting the locations of RISs to cover the desired region.\nThe performance of dual RIS-assisted radar systems can surpass that of single\nRIS-assisted radar systems under favourable alignment and sufficiently large\nRIS sizes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u53cc RIS \u8f85\u52a9\u96f7\u8fbe\u7cfb\u7edf\u6765\u6539\u5584\u975e\u89c6\u8ddd (NLoS) \u76ee\u6807\u68c0\u6d4b\u7684\u4fe1\u566a\u6bd4 (SNR)\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u51b3\u4e86\u5355\u4e2a RIS \u65e0\u6cd5\u5728\u96f7\u8fbe\u4e0e\u76ee\u6807\u4e4b\u95f4\u5efa\u7acb\u8def\u5f84\u7684\u573a\u666f\uff0c\u5c24\u5176\u662f\u5728\u975e\u89c6\u8ddd (NLoS) \u60c5\u51b5\u4e0b\u3002", "method": "\u63a8\u5bfc\u4e86\u53cc RIS \u8f85\u52a9\u4e0b\u975e\u89c6\u8ddd (NLoS) \u60c5\u51b5\u4e0b\u7684\u4fe1\u566a\u6bd4 (SNR) \u8868\u8fbe\u5f0f\uff0c\u5e76\u8ba1\u7b97\u4e86\u901a\u8fc7\u53cc RIS \u914d\u7f6e\u63a5\u6536\u5230\u7684\u529f\u7387\u3002", "result": "\u8bc1\u660e\u4e86 RIS \u8f85\u52a9\u96f7\u8fbe\u7684 SNR \u6027\u80fd\u53ef\u4ee5\u901a\u8fc7\u63a7\u5236\u96f7\u8fbe\u548c RIS \u7684\u4f4d\u7f6e\u6765\u63d0\u9ad8\u3002\u53cc RIS \u8f85\u52a9\u96f7\u8fbe\u7cfb\u7edf\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u4f18\u4e8e\u5355 RIS \u8f85\u52a9\u96f7\u8fbe\u7cfb\u7edf\u3002", "conclusion": "\u901a\u8fc7\u63a7\u5236 RIS \u7684\u6570\u91cf\u3001\u6bcf\u4e2a RIS \u7684\u5355\u5143\u6570\u91cf\u4ee5\u53ca RIS \u4f4d\u7f6e\u7684\u9009\u62e9\uff0c\u53ef\u4ee5\u5b9e\u73b0\u76ee\u6807\u5b9a\u4f4d\u6240\u9700\u7684\u7cbe\u5ea6\u3002\u5728\u6709\u5229\u7684\u5bf9\u9f50\u548c\u8db3\u591f\u5927\u7684 RIS \u5c3a\u5bf8\u4e0b\uff0c\u53cc RIS \u8f85\u52a9\u96f7\u8fbe\u7cfb\u7edf\u7684\u6027\u80fd\u53ef\u4ee5\u8d85\u8fc7\u5355 RIS \u8f85\u52a9\u96f7\u8fbe\u7cfb\u7edf\u3002"}}
{"id": "2507.10795", "categories": ["cs.SI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10795", "abs": "https://arxiv.org/abs/2507.10795", "authors": ["\u0141ukasz Krai\u0144ski", "Micha\u0142 Czuba", "Piotr Br\u00f3dka", "Pawe\u0142 Pra\u0142at", "Bogumi\u0142 Kami\u0144ski", "Fran\u00e7ois Th\u00e9berge"], "title": "Multilayer Artificial Benchmark for Community Detection (mABCD)", "comment": "28 pages, 15 figures, 7 tables", "summary": "The Artificial Benchmark for Community Detection (ABCD) model is a random\ngraph model with community structure and power-law distribution for both\ndegrees and community sizes. The model generates graphs similar to the\nwell-known LFR model but it is faster, more interpretable, and can be\ninvestigated analytically. In this paper, we use the underlying ingredients of\nthe ABCD model and introduce its variant for multilayer networks, mABCD.", "AI": {"tldr": "A new model called mABCD is introduced for multilayer networks, which is faster, more interpretable, and analytically tractable, building upon the ABCD model.", "motivation": "The research aims to extend the capabilities of the ABCD model to multilayer networks, leveraging its advantages such as speed, interpretability, and analytical investigation.", "method": "The study adapts the ABCD model, a random graph model with community structure and power-law distributions, to create a variant for multilayer networks named mABCD.", "result": "The paper presents the mABCD model, a new model for multilayer networks that is based on the ABCD model and offers similar benefits.", "conclusion": "The paper introduces mABCD, a variant of the ABCD model for multilayer networks, which is inspired by the ABCD model's strengths in speed, interpretability, and analytical tractability."}}
{"id": "2507.11512", "categories": ["cs.DC", "cs.NA", "cs.PF", "math.NA", "65Y10", "G.4; C.4"], "pdf": "https://arxiv.org/pdf/2507.11512", "abs": "https://arxiv.org/abs/2507.11512", "authors": ["Aditya Kashi", "Nicholson Koukpaizan", "Hao Lu", "Michael Matheson", "Sarp Oral", "Feiyi Wang"], "title": "Scaling the memory wall using mixed-precision -- HPG-MxP on an exascale machine", "comment": "Accepted for presentation at SC25, St. Louis, MO, USA", "summary": "Mixed-precision algorithms have been proposed as a way for scientific\ncomputing to benefit from some of the gains seen for artificial intelligence\n(AI) on recent high performance computing (HPC) platforms. A few applications\ndominated by dense matrix operations have seen substantial speedups by\nutilizing low precision formats such as FP16. However, a majority of scientific\nsimulation applications are memory bandwidth limited. Beyond preliminary\nstudies, the practical gain from using mixed-precision algorithms on a given\nHPC system is largely unclear.\n  The High Performance GMRES Mixed Precision (HPG-MxP) benchmark has been\nproposed to measure the useful performance of a HPC system on sparse\nmatrix-based mixed-precision applications. In this work, we present a highly\noptimized implementation of the HPG-MxP benchmark for an exascale system and\ndescribe our algorithm enhancements. We show for the first time a speedup of\n1.6x using a combination of double- and single-precision on modern GPU-based\nsupercomputers.", "AI": {"tldr": "\u6df7\u5408\u7cbe\u5ea6\u7b97\u6cd5\u53ef\u4ee5\u63d0\u5347\u79d1\u5b66\u8ba1\u7b97\u5728HPC\u4e0a\u7684\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728GPU\u4e0a\u3002\u901a\u8fc7\u4f18\u5316HPG-MxP\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5b9e\u73b0\u4e861.6\u500d\u7684\u901f\u5ea6\u63d0\u5347\u3002", "motivation": "\u4e3a\u4e86\u5e2e\u52a9\u79d1\u5b66\u8ba1\u7b97\u4eceAI\u5728HPC\u5e73\u53f0\u4e0a\u7684\u6536\u76ca\u4e2d\u83b7\u76ca\uff0c\u5e76\u89e3\u51b3\u6df7\u5408\u7cbe\u5ea6\u7b97\u6cd5\u5728\u79d1\u5b66\u6a21\u62df\u5e94\u7528\u4e2d\u7684\u5b9e\u9645\u589e\u76ca\u4e0d\u660e\u786e\u7684\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u9ad8\u5ea6\u4f18\u5316\u7684HPG-MxP\u57fa\u51c6\u6d4b\u8bd5\u5b9e\u73b0\uff0c\u5e76\u5bf9\u7b97\u6cd5\u8fdb\u884c\u4e86\u589e\u5f3a\u3002", "result": "\u5728\u4e00\u4e2aexascale\u7cfb\u7edf\u4e0a\u5b9e\u73b0\u4e86HPG-MxP\u57fa\u51c6\u6d4b\u8bd5\u7684\u9ad8\u5ea6\u4f18\u5316\u5b9e\u73b0\uff0c\u5e76\u5c55\u793a\u4e86\u4f7f\u7528\u53cc\u7cbe\u5ea6\u548c\u5355\u7cbe\u5ea6\u7ec4\u5408\u53ef\u5b9e\u73b01.6\u500d\u7684\u901f\u5ea6\u63d0\u5347\u3002", "conclusion": "\u5728\u73b0\u4ee3GPU\u8d85\u7ea7\u8ba1\u7b97\u673a\u4e0a\uff0c\u901a\u8fc7\u7ed3\u5408\u4f7f\u7528\u53cc\u7cbe\u5ea6\u548c\u5355\u7cbe\u5ea6\uff0c\u9996\u6b21\u5b9e\u73b0\u4e861.6\u500d\u7684\u901f\u5ea6\u63d0\u5347\u3002"}}
{"id": "2507.10751", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.10751", "abs": "https://arxiv.org/abs/2507.10751", "authors": ["J. K. Liyanage", "M. D. Nadeesha Tharundi", "Laalitha S. I. Liyanage"], "title": "A molecular dynamics investigation of the dependence of mechanical properties of steel nanowires on C concentration", "comment": null, "summary": "The temperature dependence of mechanical properties of steel nanowires with\nvarying carbon content was studied using molecular dynamics simulations. Four\ninteratomic potentials were assessed, with the Modified Embedded Atom Method\n(MEAM) potential developed by Liyanage et al. selected for its accuracy in\npredicting the behavior of BCC Fe, FeC in the B1 rock salt structure, and BCC\niron with carbon. Uniaxial tensile tests were conducted on FeC nanowires with\ncarbon concentrations of 0-10% at temperatures ranging from 0.1 K to 900 K.\nStress-strain curves were analyzed to determine Young's modulus, yield stress,\nand ultimate tensile strength (UTS). Results showed that Young's modulus\nincreased between 0.1 K and 300 K but decreased between 600 K and 900 K with\nincreasing carbon content. Both yield stress and UTS decreased progressively\nwith higher carbon percentages. Common Neighbor Analysis revealed rapid\nformation of slip planes as carbon content increased and greater slip plane\npropagation at elevated temperatures, contributing to reduced nanowire\nstrength. These findings provide insights into the influence of carbon content\nand temperature on the mechanical behavior of steel nanowires, which may inform\nthe design of nanostructured steel materials for various applications.", "AI": {"tldr": "\u901a\u8fc7\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u7814\u7a76\u4e86\u94a2\u7eb3\u7c73\u7ebf\u7684\u529b\u5b66\u6027\u80fd\u4e0e\u6e29\u5ea6\u548c\u78b3\u542b\u91cf\u7684\u5173\u7cfb\u3002\u7ed3\u679c\u663e\u793a\uff0c\u6768\u6c0f\u6a21\u91cf\u968f\u6e29\u5ea6\u548c\u78b3\u542b\u91cf\u7684\u53d8\u5316\u800c\u53d8\u5316\uff0c\u5c48\u670d\u5f3a\u5ea6\u548c\u6297\u62c9\u5f3a\u5ea6\u968f\u78b3\u542b\u91cf\u589e\u52a0\u800c\u964d\u4f4e\uff0c\u8fd9\u4e0e\u6ed1\u79fb\u9762\u7684\u5f62\u6210\u548c\u6269\u5c55\u6709\u5173\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u94a2\u7eb3\u7c73\u7ebf\u7684\u529b\u5b66\u6027\u80fd\u4e0e\u6e29\u5ea6\u53ca\u78b3\u542b\u91cf\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u4ee5\u671f\u4e3a\u7eb3\u7c73\u7ed3\u6784\u94a2\u6750\u6599\u7684\u8bbe\u8ba1\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u91c7\u7528\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u7814\u7a76\u4e86\u4e0d\u540c\u78b3\u542b\u91cf\u7684\u94a2\u7eb3\u7c73\u7ebf\u7684\u529b\u5b66\u6027\u80fd\u4e0e\u6e29\u5ea6\u7684\u5173\u7cfb\u3002\u8bc4\u4f30\u4e86\u56db\u79cd\u539f\u5b50\u95f4\u52bf\u80fd\uff0c\u5e76\u9009\u62e9\u4e86Liyanage\u7b49\u4eba\u5f00\u53d1\u7684MEAM\u52bf\u80fd\uff0c\u56e0\u4e3a\u5b83\u80fd\u51c6\u786e\u9884\u6d4bBCC Fe\u3001B1\u7ed3\u6784FeC\u4ee5\u53ca\u542b\u78b3BCC\u94c1\u7684\u884c\u4e3a\u3002\u5bf9\u542b\u78b3\u91cf\u4e3a0-10%\u7684FeC\u7eb3\u7c73\u7ebf\u57280.1 K\u81f3900 K\u7684\u6e29\u5ea6\u8303\u56f4\u5185\u8fdb\u884c\u4e86\u5355\u8f74\u62c9\u4f38\u8bd5\u9a8c\uff0c\u5e76\u901a\u8fc7\u5206\u6790\u5e94\u529b-\u5e94\u53d8\u66f2\u7ebf\u786e\u5b9a\u4e86\u6768\u6c0f\u6a21\u91cf\u3001\u5c48\u670d\u5e94\u529b\u548c\u6297\u62c9\u5f3a\u5ea6\uff08UTS\uff09\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u6768\u6c0f\u6a21\u91cf\u968f\u78b3\u542b\u91cf\u7684\u589e\u52a0\u57280.1 K\u81f3300 K\u8303\u56f4\u5185\u5448\u73b0\u589e\u957f\u8d8b\u52bf\uff0c\u4f46\u5728600 K\u81f3900 K\u8303\u56f4\u5185\u5219\u5448\u4e0b\u964d\u8d8b\u52bf\u3002\u5c48\u670d\u5e94\u529b\u548c\u6297\u62c9\u5f3a\u5ea6\uff08UTS\uff09\u5747\u968f\u7740\u78b3\u542b\u91cf\u7684\u589e\u52a0\u800c\u9010\u6e10\u964d\u4f4e\u3002\u901a\u8fc7\u516c\u5171\u8fd1\u90bb\u5206\u6790\u53d1\u73b0\uff0c\u968f\u7740\u78b3\u542b\u91cf\u7684\u589e\u52a0\uff0c\u6ed1\u79fb\u9762\u7684\u5f62\u6210\u901f\u5ea6\u52a0\u5feb\uff0c\u5e76\u4e14\u5728\u8f83\u9ad8\u6e29\u5ea6\u4e0b\u6ed1\u79fb\u9762\u7684\u6269\u5c55\u6027\u589e\u5f3a\uff0c\u8fd9\u662f\u5bfc\u81f4\u7eb3\u7c73\u7ebf\u5f3a\u5ea6\u4e0b\u964d\u7684\u539f\u56e0\u3002", "conclusion": "\u672c\u7814\u7a76\u63ed\u793a\u4e86\u78b3\u542b\u91cf\u548c\u6e29\u5ea6\u5bf9\u94a2\u7eb3\u7c73\u7ebf\u529b\u5b66\u884c\u4e3a\u7684\u5f71\u54cd\u89c4\u5f8b\uff0c\u4e3a\u7eb3\u7c73\u7ed3\u6784\u94a2\u6750\u6599\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u53c2\u8003\u3002"}}
{"id": "2507.11126", "categories": ["cs.LO", "cs.FL"], "pdf": "https://arxiv.org/pdf/2507.11126", "abs": "https://arxiv.org/abs/2507.11126", "authors": ["Luca Di Stefano"], "title": "Execution and monitoring of HOA automata with HOAX", "comment": "To appear in RV'25", "summary": "We present a tool called Hoax for the execution of {\\omega}-automata\nexpressed in the popular HOA format. The tool leverages the notion of trap sets\nto enable runtime monitoring of any (non-parity) acceptance condition supported\nby the format. When the automaton is not monitorable, the tool may still be\nable to recognise so-called ugly prefixes, and determine that no further\nobservation will ever lead to a conclusive verdict. The tool is open-source and\nhighly configurable. We present its formal foundations, its design, and compare\nit against the trace analyser PyContract on a lock acquisition scenario.", "AI": {"tldr": "Hoax is a configurable, open-source tool for executing \u03c9-automata (HOA format) with runtime monitoring via trap sets, capable of identifying unresolvable 'ugly prefixes'. It's compared to PyContract.", "motivation": "To present a tool called Hoax for the execution of \u03c9-automata expressed in the popular HOA format, enabling runtime monitoring of acceptance conditions and identification of non-monitorable scenarios.", "method": "The tool Hoax leverages the notion of trap sets for runtime monitoring of any (non-parity) acceptance condition supported by the HOA format. When the automaton is not monitorable, the tool identifies 'ugly prefixes'. The paper details the formal foundations and design of the tool and compares it against the trace analyser PyContract.", "result": "Hoax leverages trap sets for runtime monitoring of acceptance conditions in \u03c9-automata and can identify 'ugly prefixes' in non-monitorable cases. A comparison with PyContract on a lock acquisition scenario is provided.", "conclusion": "The paper presents Hoax, an open-source and configurable tool for executing \u03c9-automata in HOA format, which leverages trap sets for runtime monitoring of various acceptance conditions. It can identify 'ugly prefixes' when an automaton is not monitorable, indicating that no future observation can lead to a conclusive verdict. The tool's formal foundations, design, and comparison with PyContract on a lock acquisition scenario are also presented."}}
{"id": "2507.11011", "categories": ["cond-mat.mtrl-sci", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2507.11011", "abs": "https://arxiv.org/abs/2507.11011", "authors": ["Hikaru Sadahira", "Prashant R. Ghediya", "Hyeonjun Kong", "Akira Miura", "Yasutaka Matsuo", "Hiromichi Ohta", "Yusaku Magari"], "title": "Indium Hydroxide Ceramic Targets: A Breakthrough in High-Mobility Thin-Film Transistor Technology", "comment": "29 pages, 7 figures, 8 supplementary figures", "summary": "Thin-film transistors composed of a hydrogen-containing indium oxide active\nlayer are promising candidates for backplane devices in next-generation flat\npanel displays, offering higher definition and faster operation. However, the\nhydrogen incorporation process during film deposition poses challenges for\nscalable and industrial development due to both safety and controllability\nissues. Here, we demonstrate that using indium hydroxide ceramic as the target\nmaterial for film deposition overcomes the difficulties associated with\nhydrogen gas usage. We sintered commercially available indium hydroxide powder\nusing a conventional ceramic process at 150-250{\\deg}C in air and utilized it\nfor the deposition of hydrogen-incorporated indium oxide films via pulsed laser\ndeposition. The resulting indium oxide films, after thermal annealing,\ncontained a sufficient concentration of hydrogen and exhibited very high\nelectron mobility due to significantly grown grains. Furthermore, we confirmed\nthat the fabricated thin-film transistors exhibited comparably high performance\nto those produced using the gas-phase hydrogen incorporation method. This\napproach offers a practical pathway for hydrogen-containing indium oxide-based\nthin-film transistors in next-generation flat panel displays.", "AI": {"tldr": "\u4f7f\u7528\u6c22\u6c27\u5316\u94df\u9676\u74f7\u9776\u6750\u901a\u8fc7\u8109\u51b2\u6fc0\u5149\u6c89\u79ef\u5236\u5907\u542b\u6c22\u6c27\u5316\u94df\u8584\u819c\u6676\u4f53\u7ba1\uff0c\u89e3\u51b3\u4e86\u6c22\u6c14\u4f7f\u7528\u7684\u6311\u6218\uff0c\u5e76\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u514b\u670d\u5728\u8584\u819c\u6c89\u79ef\u8fc7\u7a0b\u4e2d\u6c22\u6c14\u63ba\u6742\u5e26\u6765\u7684\u5b89\u5168\u548c\u53ef\u63a7\u6027\u6311\u6218\uff0c\u4ee5\u5b9e\u73b0\u4e0b\u4e00\u4ee3\u5e73\u677f\u663e\u793a\u5668\u4e2d\u8584\u819c\u6676\u4f53\u7ba1\u7684\u89c4\u6a21\u5316\u548c\u5de5\u4e1a\u5316\u751f\u4ea7\u3002", "method": "\u901a\u8fc7\u4f7f\u7528\u6c22\u6c27\u5316\u94df\u9676\u74f7\u4f5c\u4e3a\u9776\u6750\u8fdb\u884c\u8584\u819c\u6c89\u79ef\uff0c\u5e76\u91c7\u7528\u8109\u51b2\u6fc0\u5149\u6c89\u79ef\u6280\u672f\uff0c\u5728\u8584\u819c\u9000\u706b\u540e\uff0c\u6210\u529f\u5236\u5907\u4e86\u542b\u6709\u8db3\u591f\u6c22\u6d53\u5ea6\u4e14\u5177\u6709\u9ad8\u7535\u5b50\u8fc1\u79fb\u7387\u7684\u6c27\u5316\u94df\u8584\u819c\uff0c\u5b9e\u73b0\u4e86\u4e0e\u4f7f\u7528\u6c14\u76f8\u6c22\u590d\u5408\u65b9\u6cd5\u76f8\u5f53\u7684\u9ad8\u6027\u80fd\u8584\u819c\u6676\u4f53\u7ba1\u3002", "result": "\u5236\u5907\u7684\u6c27\u5316\u94df\u8584\u819c\u542b\u6709\u8db3\u591f\u7684\u6c22\uff0c\u5e76\u4e14\u7531\u4e8e\u6676\u7c92\u663e\u8457\u751f\u957f\u800c\u8868\u73b0\u51fa\u975e\u5e38\u9ad8\u7684\u7535\u5b50\u8fc1\u79fb\u7387\u3002\u6b64\u5916\uff0c\u5236\u9020\u7684\u8584\u819c\u6676\u4f53\u7ba1\u8868\u73b0\u51fa\u4e0e\u4f7f\u7528\u6c14\u76f8\u6c22\u63ba\u6742\u65b9\u6cd5\u751f\u4ea7\u7684\u5668\u4ef6\u76f8\u5f53\u7684\u9ad8\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u542b\u6c22\u6c27\u5316\u94df\u8584\u819c\u6676\u4f53\u7ba1\u5728\u4e0b\u4e00\u4ee3\u5e73\u677f\u663e\u793a\u5668\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u6761\u5b9e\u7528\u7684\u9014\u5f84\u3002"}}
{"id": "2507.10668", "categories": ["quant-ph", "cond-mat.quant-gas", "hep-th"], "pdf": "https://arxiv.org/pdf/2507.10668", "abs": "https://arxiv.org/abs/2507.10668", "authors": ["Raoul Serao", "Aniello Quaranta", "Antonio Capolupo", "Fabio Franchini", "Salvatore Marco Giampaolo"], "title": "Entanglement and Purity in Open Systems: A Breakdown of the Lindblad Approach", "comment": "6 pages, no figures", "summary": "We examine the effectiveness of Lindblad master equation in capturing the\nshort-time dynamics of entanglement and purity in open quantum systems.\nFocusing on two interacting two-level systems interacting with a larger\nenvironment, we compare the Lindbladian approach to a full microscopic\ntreatment. While the latter shows entanglement growth and a quadratic decay of\npurity, the Lindbladian method predicts a linear purity decay and can entirely\nsuppress entanglement when the dissipative coupling exceeds the interaction\nstrength. Introducing a time-dependent Lindbladian improves some predictions\nbut causes inconsistencies in other observables. Our results highlight the\nlimitations of effective models and the need for caution when applying them to\ndescribe subtle quantum behaviors.", "AI": {"tldr": "Lindblad master equation \u5728\u6a21\u62df\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u77ed\u671f\u52a8\u529b\u5b66\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u53ef\u80fd\u5bfc\u81f4\u5bf9\u7ea0\u7f20\u548c\u7eaf\u5ea6\u884c\u4e3a\u7684\u9519\u8bef\u9884\u6d4b\u3002", "motivation": "\u65e8\u5728\u8bc4\u4f30 Lindblad master equation \u5728\u6a21\u62df\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u77ed\u671f\u52a8\u529b\u5b66\u65b9\u9762\u7684\u51c6\u786e\u6027\uff0c\u5e76\u63ed\u793a\u5176\u6f5c\u5728\u5c40\u9650\u6027\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83 Lindblad master equation \u548c\u5b8c\u6574\u7684\u5fae\u89c2\u5904\u7406\u65b9\u6cd5\uff0c\u6765\u68c0\u9a8c Lindblad master equation \u5728\u6a21\u62df\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\uff08\u7279\u522b\u662f\u4e24\u4e2a\u76f8\u4e92\u4f5c\u7528\u7684\u4e8c\u80fd\u7ea7\u7cfb\u7edf\uff09\u77ed\u671f\u52a8\u529b\u5b66\uff08\u7ea0\u7f20\u548c\u7eaf\u5ea6\uff09\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "result": "\u5fae\u89c2\u5904\u7406\u65b9\u6cd5\u663e\u793a\u7ea0\u7f20\u589e\u957f\u548c\u7eaf\u5ea6\u5448\u4e8c\u6b21\u8870\u51cf\uff0c\u800c Lindbladian \u65b9\u6cd5\u9884\u6d4b\u7eaf\u5ea6\u5448\u7ebf\u6027\u8870\u51cf\uff0c\u5e76\u4e14\u5728\u8017\u6563\u8026\u5408\u8d85\u8fc7\u76f8\u4e92\u4f5c\u7528\u5f3a\u5ea6\u65f6\u4f1a\u6291\u5236\u7ea0\u7f20\u3002\u65f6\u95f4\u4f9d\u8d56\u7684 Lindbladian \u6a21\u578b\u6539\u5584\u4e86\u90e8\u5206\u9884\u6d4b\uff0c\u4f46\u5bfc\u81f4\u5176\u4ed6\u53ef\u89c2\u6d4b\u91cf\u7684\u7ed3\u679c\u4e0d\u4e00\u81f4\u3002", "conclusion": "Lindblad master equation \u5728\u6355\u6349\u5f00\u653e\u91cf\u5b50\u7cfb\u7edf\u7ea0\u7f20\u548c\u7eaf\u5ea6\u77ed\u671f\u52a8\u529b\u5b66\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5c24\u5176\u662f\u5728\u8017\u6563\u8026\u5408\u8d85\u8fc7\u76f8\u4e92\u4f5c\u7528\u5f3a\u5ea6\u65f6\uff0c\u5b83\u4f1a\u6291\u5236\u7ea0\u7f20\uff0c\u5e76\u53ef\u80fd\u5bfc\u81f4\u7eaf\u5ea6\u8870\u51cf\u7684\u9884\u6d4b\u4e0d\u51c6\u786e\u3002\u5373\u4f7f\u662f\u65f6\u95f4\u4f9d\u8d56\u7684 Lindbladian \u6a21\u578b\uff0c\u4e5f\u53ea\u80fd\u6539\u5584\u90e8\u5206\u9884\u6d4b\uff0c\u800c\u5bfc\u81f4\u5176\u4ed6\u53ef\u89c2\u6d4b\u91cf\u7684\u7ed3\u679c\u4e0d\u4e00\u81f4\u3002"}}
{"id": "2507.10770", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10770", "abs": "https://arxiv.org/abs/2507.10770", "authors": ["Ionu\u0163 Grigore", "C\u0103lin-Adrian Popa", "Claudiu Leoveanu-Condrei"], "title": "FPC-Net: Revisiting SuperPoint with Descriptor-Free Keypoint Detection via Feature Pyramids and Consistency-Based Implicit Matching", "comment": null, "summary": "The extraction and matching of interest points are fundamental to many\ngeometric computer vision tasks. Traditionally, matching is performed by\nassigning descriptors to interest points and identifying correspondences based\non descriptor similarity. This work introduces a technique where interest\npoints are inherently associated during detection, eliminating the need for\ncomputing, storing, transmitting, or matching descriptors. Although the\nmatching accuracy is marginally lower than that of conventional approaches, our\nmethod completely eliminates the need for descriptors, leading to a drastic\nreduction in memory usage for localization systems. We assess its effectiveness\nby comparing it against both classical handcrafted methods and modern learned\napproaches.", "AI": {"tldr": "\u4e00\u79cd\u65e0\u9700\u63cf\u8ff0\u7b26\u5373\u53ef\u5339\u914d\u5174\u8da3\u70b9\u7684\u65b0\u6280\u672f\uff0c\u53ef\u5927\u5e45\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\u3002", "motivation": "\u51cf\u5c11\u672c\u5730\u5316\u7cfb\u7edf\u4e2d\u7684\u5185\u5b58\u4f7f\u7528\u91cf\uff0c\u5e76\u63a2\u7d22\u4e00\u79cd\u65e0\u9700\u63cf\u8ff0\u7b26\u7684\u5174\u8da3\u70b9\u5339\u914d\u6280\u672f\u3002", "method": "\u5728\u68c0\u6d4b\u8fc7\u7a0b\u4e2d\u56fa\u6709\u5730\u5173\u8054\u5174\u8da3\u70b9\uff0c\u65e0\u9700\u8ba1\u7b97\u3001\u5b58\u50a8\u3001\u4f20\u8f93\u6216\u5339\u914d\u63cf\u8ff0\u7b26\u3002", "result": "\u4e0e\u7ecf\u5178\u624b\u5de5\u65b9\u6cd5\u548c\u73b0\u4ee3\u5b66\u4e60\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u5185\u5b58\u4f7f\u7528\u65b9\u9762\u6709\u663e\u8457\u4f18\u52bf\uff0c\u5339\u914d\u7cbe\u5ea6\u7565\u6709\u4e0b\u964d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5728\u68c0\u6d4b\u8fc7\u7a0b\u4e2d\u56fa\u6709\u5730\u5173\u8054\u5174\u8da3\u70b9\u6765\u6d88\u9664\u5bf9\u63cf\u8ff0\u7b26\u7684\u9700\u6c42\uff0c\u5c3d\u7ba1\u5339\u914d\u7cbe\u5ea6\u7565\u6709\u4e0b\u964d\uff0c\u4f46\u663e\u8457\u51cf\u5c11\u4e86\u5185\u5b58\u4f7f\u7528\u91cf\uff0c\u9002\u7528\u4e8e\u672c\u5730\u5316\u7cfb\u7edf\u3002"}}
{"id": "2507.10624", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10624", "abs": "https://arxiv.org/abs/2507.10624", "authors": ["Zheng Zhang"], "title": "Comprehension Without Competence: Architectural Limits of LLMs in Symbolic Computation and Reasoning", "comment": "Substantial change to previous version (experiments, theorem,\n  analysis and related work); currently under review at TMLR", "summary": "Large Language Models (LLMs) display striking surface fluency yet\nsystematically fail at tasks requiring symbolic reasoning, arithmetic accuracy,\nand logical consistency. This paper offers a structural diagnosis of such\nfailures, revealing a persistent gap between \\textit{comprehension} and\n\\textit{competence}. Through controlled experiments and architectural analysis,\nwe demonstrate that LLMs often articulate correct principles without reliably\napplying them--a failure rooted not in knowledge access, but in computational\nexecution. We term this phenomenon the computational \\textit{split-brain\nsyndrome}, where instruction and action pathways are geometrically and\nfunctionally dissociated. This core limitation recurs across domains, from\nmathematical operations to relational inferences, and explains why model\nbehavior remains brittle even under idealized prompting. We argue that LLMs\nfunction as powerful pattern completion engines, but lack the architectural\nscaffolding for principled, compositional reasoning. Our findings delineate the\nboundary of current LLM capabilities and motivate future models with\nmetacognitive control, principle lifting, and structurally grounded execution.\nThis diagnosis also clarifies why mechanistic interpretability findings may\nreflect training-specific pattern coordination rather than universal\ncomputational principles, and why the geometric separation between instruction\nand execution pathways suggests limitations in neural introspection and\nmechanistic analysis.", "AI": {"tldr": "LLMs\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u5b58\u5728\u201c\u8ba1\u7b97\u6027\u5206\u88c2\u8111\u201d\u95ee\u9898\uff0c\u5373\u7406\u89e3\u4e0e\u6267\u884c\u8131\u8282\uff0c\u9650\u5236\u4e86\u5176\u53ef\u9760\u5e94\u7528\u77e5\u8bc6\u7684\u80fd\u529b\u3002", "motivation": "LLMs\u867d\u7136\u5177\u6709\u51fa\u8272\u7684\u8868\u9762\u6d41\u7545\u6027\uff0c\u4f46\u5728\u7b26\u53f7\u63a8\u7406\u3001\u7b97\u672f\u51c6\u786e\u6027\u548c\u903b\u8f91\u4e00\u81f4\u6027\u65b9\u9762\u5b58\u5728\u7cfb\u7edf\u6027\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u53d7\u63a7\u5b9e\u9a8c\u548c\u67b6\u6784\u5206\u6790\u6765\u8bca\u65adLLMs\u7684\u7f3a\u9677\u3002", "result": "LLMs\u7ecf\u5e38\u80fd\u591f\u9610\u8ff0\u6b63\u786e\u7684\u539f\u7406\u4f46\u65e0\u6cd5\u53ef\u9760\u5730\u5e94\u7528\u5b83\u4eec\uff0c\u8fd9\u79cd\u201c\u8ba1\u7b97\u6027\u201c\u5206\u88c2\u8111\u201d\u7efc\u5408\u5f81\u201d\u7684\u5c40\u9650\u6027\u5728\u4e0d\u540c\u9886\u57df\u666e\u904d\u5b58\u5728\uff0c\u5373\u4f7f\u5728\u7406\u60f3\u5316\u7684\u63d0\u793a\u4e0b\u6a21\u578b\u884c\u4e3a\u4ecd\u7136\u8106\u5f31\u3002", "conclusion": "LLMs\u5728\u9700\u8981\u7b26\u53f7\u63a8\u7406\u3001\u7b97\u672f\u51c6\u786e\u6027\u548c\u903b\u8f91\u4e00\u81f4\u6027\u7684\u4efb\u52a1\u4e2d\u5b58\u5728\u7cfb\u7edf\u6027\u7f3a\u9677\uff0c\u8fd9\u6e90\u4e8e\u201c\u7406\u89e3\u201d\u4e0e\u201c\u80fd\u529b\u201d\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u8868\u73b0\u4e3a\u201c\u8ba1\u7b97\u6027\u201c\u5206\u88c2\u8111\u201d\u7efc\u5408\u5f81\u201d\uff0c\u5373\u6307\u4ee4\u548c\u52a8\u4f5c\u8def\u5f84\u5728\u51e0\u4f55\u548c\u529f\u80fd\u4e0a\u5206\u79bb\u3002LLMs\u662f\u5f3a\u5927\u7684\u6a21\u5f0f\u8865\u5168\u5f15\u64ce\uff0c\u4f46\u7f3a\u4e4f\u7ed3\u6784\u5316\u7684\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2507.10585", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10585", "abs": "https://arxiv.org/abs/2507.10585", "authors": ["Isar Nejadgholi", "Mona Omidyeganeh", "Marc-Antoine Drouin", "Jonathan Boisvert"], "title": "A Taxonomy for Design and Evaluation of Prompt-Based Natural Language Explanations", "comment": "Presented at the Workshop of Technical AI Governance, 5 pages 2\n  figures", "summary": "Effective AI governance requires structured approaches for stakeholders to\naccess and verify AI system behavior. With the rise of large language models,\nNatural Language Explanations (NLEs) are now key to articulating model\nbehavior, which necessitates a focused examination of their characteristics and\ngovernance implications. We draw on Explainable AI (XAI) literature to create\nan updated XAI taxonomy, adapted to prompt-based NLEs, across three dimensions:\n(1) Context, including task, data, audience, and goals; (2) Generation and\nPresentation, covering generation methods, inputs, interactivity, outputs, and\nforms; and (3) Evaluation, focusing on content, presentation, and user-centered\nproperties, as well as the setting of the evaluation. This taxonomy provides a\nframework for researchers, auditors, and policymakers to characterize, design,\nand enhance NLEs for transparent AI systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2aXAI\u5206\u7c7b\u6cd5\uff0c\u7528\u4e8e\u8868\u5f81\u548c\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff08NLE\uff09\uff0c\u4ee5\u589e\u5f3aAI\u6cbb\u7406\u7684\u900f\u660e\u5ea6\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5174\u8d77\uff0c\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff08NLE\uff09\u6210\u4e3a\u9610\u660e\u6a21\u578b\u884c\u4e3a\u7684\u5173\u952e\uff0c\u56e0\u6b64\u9700\u8981\u5bf9\u5176\u7279\u6027\u548c\u6cbb\u7406\u5f71\u54cd\u8fdb\u884c\u7814\u7a76\uff0c\u4ee5\u5b9e\u73b0\u6709\u6548\u7684AI\u6cbb\u7406\u3002", "method": "\u901a\u8fc7\u501f\u9274XAI\u6587\u732e\uff0c\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5174\u8d77\uff0c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u9002\u7528\u4e8e\u63d0\u793a\u5f0fNLE\u7684XAI\u5206\u7c7b\u6cd5\uff0c\u8be5\u5206\u7c7b\u6cd5\u4ece\u4e0a\u4e0b\u6587\u3001\u751f\u6210\u4e0e\u5448\u73b0\u3001\u8bc4\u4f30\u4e09\u4e2a\u7ef4\u5ea6\u5bf9NLE\u7684\u7279\u6027\u548c\u6cbb\u7406\u5f71\u54cd\u8fdb\u884c\u4e86\u68b3\u7406\u3002", "result": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b\u4e09\u4e2a\u7ef4\u5ea6\uff08\u4e0a\u4e0b\u6587\u3001\u751f\u6210\u4e0e\u5448\u73b0\u3001\u8bc4\u4f30\uff09\u7684XAI\u5206\u7c7b\u6cd5\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u3001\u5ba1\u8ba1\u4eba\u5458\u548c\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u4e86\u8868\u5f81\u3001\u8bbe\u8ba1\u548c\u589e\u5f3aNLE\u4ee5\u5b9e\u73b0\u900f\u660eAI\u7cfb\u7edf\u7684\u6846\u67b6\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u9002\u7528\u4e8e\u57fa\u4e8e\u63d0\u793a\u7684\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff08NLE\uff09\u7684XAI\uff08\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\uff09\u5206\u7c7b\u6cd5\uff0c\u6db5\u76d6\u4e86\u4e0a\u4e0b\u6587\u3001\u751f\u6210\u4e0e\u5448\u73b0\u3001\u8bc4\u4f30\u4e09\u4e2a\u7ef4\u5ea6\uff0c\u65e8\u5728\u4e3aAI\u6cbb\u7406\u63d0\u4f9b\u4e00\u4e2a\u6846\u67b6\u3002"}}
{"id": "2507.10568", "categories": ["cs.NE"], "pdf": "https://arxiv.org/pdf/2507.10568", "abs": "https://arxiv.org/abs/2507.10568", "authors": ["Arman Ferdowsi", "Atakan Aral"], "title": "An Exact Gradient Framework for Training Spiking Neural Networks", "comment": null, "summary": "Spiking neural networks inherently rely on the precise timing of discrete\nspike events for information processing. Incorporating additional bio-inspired\ndegrees of freedom, such as trainable synaptic transmission delays and adaptive\nfiring thresholds, is essential for fully leveraging the temporal dynamics of\nSNNs. Although recent methods have demonstrated the benefits of training\nsynaptic weights and delays, both in terms of accuracy and temporal\nrepresentation, these techniques typically rely on discrete-time simulations,\nsurrogate gradient approximations, or full access to internal state variables\nsuch as membrane potentials. Such requirements limit training precision and\nefficiency and pose challenges for neuromorphic hardware implementation due to\nincreased memory and I/O bandwidth demands. To overcome these challenges, we\npropose an analytical event-driven learning framework that computes exact loss\ngradients not only with respect to synaptic weights and transmission delays but\nalso to adaptive neuronal firing thresholds. Experiments on multiple benchmarks\ndemonstrate significant gains in accuracy (up to 7%), timing precision, and\nrobustness compared to existing methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e8b\u4ef6\u9a71\u52a8\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u8bad\u7ec3\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\uff08SNN\uff09\uff0c\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u3001\u65f6\u95f4\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\uff0c\u5e76\u7b80\u5316\u4e86\u795e\u7ecf\u5f62\u6001\u786c\u4ef6\u7684\u5b9e\u73b0\u3002", "motivation": "\u4e3a\u4e86\u5145\u5206\u5229\u7528SNN\u7684\u65f6\u95f4\u52a8\u6001\uff0c\u9700\u8981\u6574\u5408\u53ef\u8bad\u7ec3\u7684\u7a81\u89e6\u4f20\u8f93\u5ef6\u8fdf\u548c\u81ea\u9002\u5e94\u53d1\u653e\u9608\u503c\u7b49\u751f\u7269\u542f\u53d1\u7684\u81ea\u7531\u5ea6\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u8bad\u7ec3\u7cbe\u5ea6\u548c\u6548\u7387\u9650\u5236\uff0c\u5e76\u4e14\u5bf9\u795e\u7ecf\u5f62\u6001\u786c\u4ef6\u5b9e\u73b0\u63d0\u51fa\u4e86\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u6790\u6027\u4e8b\u4ef6\u9a71\u52a8\u5b66\u4e60\u6846\u67b6\uff0c\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u5bf9\u79bb\u6563\u65f6\u95f4\u6a21\u62df\u3001\u4ee3\u7406\u68af\u5ea6\u8fd1\u4f3c\u6216\u5b8c\u5168\u8bbf\u95ee\u5185\u90e8\u72b6\u6001\u53d8\u91cf\u7684\u4f9d\u8d56\uff0c\u80fd\u591f\u8ba1\u7b97\u7cbe\u786e\u7684\u635f\u5931\u68af\u5ea6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u5728\u51c6\u786e\u6027\uff08\u6700\u9ad8\u63d0\u53477%\uff09\u3001\u65f6\u95f4\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u65b9\u9762\u5747\u6709\u663e\u8457\u7684\u63d0\u9ad8\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u6790\u6027\u4e8b\u4ef6\u9a71\u52a8\u5b66\u4e60\u6846\u67b6\uff0c\u80fd\u591f\u7cbe\u786e\u8ba1\u7b97\u5173\u4e8e\u7a81\u89e6\u6743\u91cd\u3001\u4f20\u8f93\u5ef6\u8fdf\u548c\u81ea\u9002\u5e94\u795e\u7ecf\u5143\u53d1\u653e\u9608\u503c\u7684\u635f\u5931\u68af\u5ea6\uff0c\u5728\u51c6\u786e\u6027\u3001\u65f6\u95f4\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u65b9\u9762\u5747\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2507.11094", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2507.11094", "abs": "https://arxiv.org/abs/2507.11094", "authors": ["Nibedita Behera", "Ashwina Kumar", "Atharva Chougule", "Mohammed Shan P S", "Rushabh Nirdosh Lalwani", "Rupesh Nasre"], "title": "Generating Dynamic Graph Algorithms for Multiple Backends for a Graph DSL", "comment": null, "summary": "With the rapid growth of unstructured and semistructured data, parallelizing\ngraph algorithms has become essential for efficiency. However, due to the\ninherent irregularity in computation, memory access patterns, and\ncommunication, graph algorithms are notoriously difficult to parallelize. To\naddress this challenge, several libraries, frameworks, and domain-specific\nlanguages (DSLs) have been proposed to ease the parallel programming burden for\ndomain experts. Existing frameworks partially or fully abstract away\nparallelism intricacies, provide intuitive scheduling mnemonics, and employ\nprogram analysis to identify data races and generate synchronization code.\nDespite these advances, most frameworks are limited in their abstractions and\nruntime optimizations, especially when dealing with static graphs. In contrast,\nmany real-world graphs are inherently dynamic, with evolving structures over\ntime through insertions, deletions, and modifications of vertices, edges, and\nattributes. Generating efficient and correctly synchronized code for such\ndynamic graph algorithms remains a significant challenge.\n  In this work, we introduce an abstraction scheme and runtime optimizations\nfor the efficient processing of morph algorithms. Specifically, given an\ninitial graph G and a set of updates $\\Delta$G involving edge insertions and\ndeletions, we express the dynamic processing logic through a DSL and\nautomatically generate parallel code targeting multicore, distributed, and\nmany-core environments. We demonstrate the effectiveness of our approach by\napplying the DSL-generated code to ten large graphs with diverse\ncharacteristics and three widely used algorithms: Shortest Paths, PageRank, and\nTriangle Counting.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7DSL\u7b80\u5316\u4e86\u52a8\u6001\u56fe\u7684\u5e76\u884c\u7f16\u7a0b\uff0c\u63d0\u9ad8\u4e86\u5904\u7406\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u56fe\u5904\u7406\u6846\u67b6\u5728\u5904\u7406\u52a8\u6001\u56fe\uff08\u56fe\u7ed3\u6784\u968f\u65f6\u95f4\u53d8\u5316\uff09\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5c24\u5176\u662f\u5728\u751f\u6210\u9ad8\u6548\u4e14\u540c\u6b65\u6b63\u786e\u7684\u4ee3\u7801\u65b9\u9762\u4ecd\u7136\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u62bd\u8c61\u65b9\u6848\u548c\u8fd0\u884c\u65f6\u4f18\u5316\uff0c\u5229\u7528\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff08DSL\uff09\u6765\u8868\u8fbe\u52a8\u6001\u56fe\u5904\u7406\u903b\u8f91\uff0c\u5e76\u81ea\u52a8\u751f\u6210\u53ef\u5e76\u884c\u6267\u884c\u7684\u4ee3\u7801\u3002", "result": "\u901a\u8fc7\u5c06DSL\u751f\u6210\u7684\u4ee3\u7801\u5e94\u7528\u4e8e\u5341\u4e2a\u5177\u6709\u4e0d\u540c\u7279\u5f81\u7684\u5927\u578b\u56fe\u548c\u4e09\u79cd\u5e38\u7528\u7b97\u6cd5\uff08\u6700\u77ed\u8def\u5f84\u3001PageRank\u548c\u4e09\u89d2\u5f62\u8ba1\u6570\uff09\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u9ad8\u6548\u5904\u7406\u52a8\u6001\u56fe\u7684\u62bd\u8c61\u65b9\u6848\u548c\u8fd0\u884c\u65f6\u4f18\u5316\uff0c\u901a\u8fc7\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff08DSL\uff09\u81ea\u52a8\u751f\u6210\u5e76\u884c\u4ee3\u7801\uff0c\u5e76\u5728\u591a\u6838\u3001\u5206\u5e03\u5f0f\u548c\u4f17\u6838\u73af\u5883\u4e2d\u8fdb\u884c\u4e86\u6d4b\u8bd5\u3002"}}
{"id": "2507.11277", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.11277", "abs": "https://arxiv.org/abs/2507.11277", "authors": ["Dany Moshkovich", "Sergey Zeltyn"], "title": "Taming Uncertainty via Automation: Observing, Analyzing, and Optimizing Agentic AI Systems", "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed within agentic\nsystems-collections of interacting, LLM-powered agents that execute complex,\nadaptive workflows using memory, tools, and dynamic planning. While enabling\npowerful new capabilities, these systems also introduce unique forms of\nuncertainty stemming from probabilistic reasoning, evolving memory states, and\nfluid execution paths. Traditional software observability and operations\npractices fall short in addressing these challenges.\n  This paper introduces AgentOps: a comprehensive framework for observing,\nanalyzing, optimizing, and automating operation of agentic AI systems. We\nidentify distinct needs across four key roles-developers, testers, site\nreliability engineers (SREs), and business users-each of whom engages with the\nsystem at different points in its lifecycle. We present the AgentOps Automation\nPipeline, a six-stage process encompassing behavior observation, metric\ncollection, issue detection, root cause analysis, optimized recommendations,\nand runtime automation. Throughout, we emphasize the critical role of\nautomation in managing uncertainty and enabling self-improving AI systems-not\nby eliminating uncertainty, but by taming it to ensure safe, adaptive, and\neffective operation.", "AI": {"tldr": "AgentOps\u662f\u4e00\u4e2a\u7528\u4e8e\u8fd0\u7ef4LLM\u9a71\u52a8\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u6d41\u7a0b\u7ba1\u7406\u4e0d\u786e\u5b9a\u6027\uff0c\u5b9e\u73b0\u7cfb\u7edf\u7684\u5b89\u5168\u6709\u6548\u8fd0\u884c\u3002", "motivation": "\u73b0\u6709\u8f6f\u4ef6\u8fd0\u7ef4\u5b9e\u8df5\u96be\u4ee5\u5e94\u5bf9LLM\u9a71\u52a8\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u56fa\u6709\u7684\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51faAgentOps\u6846\u67b6\uff0c\u5305\u542b\u884c\u4e3a\u89c2\u5bdf\u3001\u6307\u6807\u6536\u96c6\u3001\u95ee\u9898\u68c0\u6d4b\u3001\u6839\u672c\u539f\u56e0\u5206\u6790\u3001\u4f18\u5316\u5efa\u8bae\u548c\u8fd0\u884c\u65f6\u81ea\u52a8\u5316\u516d\u4e2a\u9636\u6bb5\u7684\u81ea\u52a8\u5316\u8fd0\u7ef4\u6d41\u7a0b\u3002", "result": "AgentOps\u4e3a\u5f00\u53d1\u8005\u3001\u6d4b\u8bd5\u8005\u3001SRE\u548c\u4e1a\u52a1\u7528\u6237\u63d0\u4f9b\u4e86\u8de8\u8d8a\u7cfb\u7edf\u751f\u547d\u5468\u671f\u4e0d\u540c\u9636\u6bb5\u7684\u8fd0\u7ef4\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86AI\u7cfb\u7edf\u7684\u81ea\u6211\u6539\u8fdb\u3002", "conclusion": "AgentOps\u901a\u8fc7\u81ea\u52a8\u5316\u7ba1\u7406\u4e0d\u786e\u5b9a\u6027\uff0c\u5b9e\u73b0AI\u7cfb\u7edf\u7684\u5b89\u5168\u3001\u81ea\u9002\u5e94\u548c\u6709\u6548\u8fd0\u884c\u3002"}}
{"id": "2507.11080", "categories": ["cs.DS", "cs.CC"], "pdf": "https://arxiv.org/pdf/2507.11080", "abs": "https://arxiv.org/abs/2507.11080", "authors": ["Matthias Lanzinger", "Igor Razgon", "Daniel Unterberger"], "title": "FPT Parameterisations of Fractional and Generalised Hypertree Width", "comment": null, "summary": "We present the first fixed-parameter tractable (fpt) algorithms for precisely\ndetermining several central hypergraph decomposition parameters, including\ngeneralized hypertree width, fractional hypertree width, and adaptive width.\nDespite the recognized importance of these measures in complexity theory,\ndatabases, and constraint satisfaction, no exact fpt algorithms for any of them\nhad previously been known. Our results are obtained for hypergraph classes of\nbounded rank and bounded degree.\n  Our approach extends a recent algorithm for treewidth (Boja\\'ncyk &\nPilipczuk, LMCS 2022) utilizing monadic second-order (MSO) transductions.\nLeveraging this framework, we overcome the significant technical hurdles\npresented by hypergraphs, whose structural decompositions are technically much\nmore intricate than their graph counterparts.", "AI": {"tldr": "Introduced the first FPT algorithms for key hypergraph decomposition parameters (generalized hypertree width, fractional hypertree width, adaptive width) using MSO transductions, applicable to bounded rank/degree hypergraphs.", "motivation": "To provide the first exact fpt algorithms for important hypergraph decomposition parameters that have recognized importance in complexity theory, databases, and constraint satisfaction.", "method": "The approach extends a recent treewidth algorithm using monadic second-order (MSO) transductions, overcoming technical challenges specific to hypergraphs.", "result": "Successfully developed and presented the first fpt algorithms for generalized hypertree width, fractional hypertree width, and adaptive width in hypergraphs.", "conclusion": "The paper presents the first fixed-parameter tractable (fpt) algorithms for determining central hypergraph decomposition parameters like generalized hypertree width, fractional hypertree width, and adaptive width. These algorithms apply to hypergraph classes with bounded rank and degree."}}
{"id": "2507.11064", "categories": ["eess.SY", "cs.AI", "cs.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2507.11064", "abs": "https://arxiv.org/abs/2507.11064", "authors": ["Sehyun Ryu", "Hyun Jong Yang"], "title": "Standards-Compliant DM-RS Allocation via Temporal Channel Prediction for Massive MIMO Systems", "comment": null, "summary": "Reducing feedback overhead in beyond 5G networks is a critical challenge, as\nthe growing number of antennas in modern massive MIMO systems substantially\nincreases the channel state information (CSI) feedback demand in frequency\ndivision duplex (FDD) systems. To address this, extensive research has focused\non CSI compression and prediction, with neural network-based approaches gaining\nmomentum and being considered for integration into the 3GPP 5G-Advanced\nstandards. While deep learning has been effectively applied to CSI-limited\nbeamforming and handover optimization, reference signal allocation under such\nconstraints remains surprisingly underexplored. To fill this gap, we introduce\nthe concept of channel prediction-based reference signal allocation (CPRS),\nwhich jointly optimizes channel prediction and DM-RS allocation to improve data\nthroughput without requiring CSI feedback. We further propose a\nstandards-compliant ViViT/CNN-based architecture that implements CPRS by\ntreating evolving CSI matrices as sequential image-like data, enabling\nefficient and adaptive transmission in dynamic environments. Simulation results\nusing ray-tracing channel data generated in NVIDIA Sionna validate the proposed\nmethod, showing up to 36.60% throughput improvement over benchmark strategies.", "AI": {"tldr": "\u9488\u5bf95G\u53ca\u4ee5\u540e\u7f51\u7edc\u4e2d\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u7684CSI\u53cd\u9988\u5f00\u9500\u8fc7\u5927\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u9053\u9884\u6d4b\u7684\u53c2\u8003\u4fe1\u53f7\u5206\u914d\uff08CPRS\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u4fe1\u9053\u9884\u6d4b\u548cDM-RS\u5206\u914d\u6765\u63d0\u5347\u541e\u5410\u91cf\uff0c\u800c\u65e0\u9700CSI\u53cd\u9988\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528\u7b26\u5408\u6807\u51c6\u7684ViViT/CNN\u67b6\u6784\uff0c\u5c06CSI\u77e9\u9635\u89c6\u4e3a\u5e8f\u5217\u56fe\u50cf\u6570\u636e\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u81ea\u9002\u5e94\u4f20\u8f93\uff0c\u5e76\u5728\u4eff\u771f\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5728\u8d85\u8d8a5G\u7684\u7f51\u7edc\u4e2d\uff0c\u968f\u7740\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u4e2d\u5929\u7ebf\u6570\u91cf\u7684\u4e0d\u65ad\u589e\u52a0\uff0c\u5bf9\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\uff08CSI\uff09\u53cd\u9988\u7684\u9700\u6c42\u4e5f\u968f\u4e4b\u589e\u52a0\uff0c\u8fd9\u7ed9\u51cf\u5c11\u53cd\u9988\u5f00\u9500\u5e26\u6765\u4e86\u4e25\u5cfb\u7684\u6311\u6218\u3002\u867d\u7136\u5728CSI\u538b\u7f29\u548c\u9884\u6d4b\u65b9\u9762\u8fdb\u884c\u4e86\u5927\u91cf\u7814\u7a76\uff0c\u4f46\u53c2\u8003\u4fe1\u53f7\u5206\u914d\u5728CSI\u53d7\u9650\u6761\u4ef6\u4e0b\u7684\u7814\u7a76\u5374\u5f88\u5c11\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7b26\u5408\u6807\u51c6\u7684\u57fa\u4e8eViViT/CNN\u7684\u67b6\u6784\u6765\u5b9e\u73b0CPRS\uff0c\u5c06\u6f14\u8fdb\u4e2d\u7684CSI\u77e9\u9635\u89c6\u4e3a\u5e8f\u5217\u56fe\u50cf\u6570\u636e\uff0c\u4ece\u800c\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5b9e\u73b0\u9ad8\u6548\u548c\u81ea\u9002\u5e94\u7684\u4f20\u8f93\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u57fa\u51c6\u7b56\u7565\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684CPRS\u65b9\u6cd5\u80fd\u591f\u5c06\u541e\u5410\u91cf\u63d0\u9ad8\u9ad8\u8fbe36.60%\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684CPRS\u65b9\u6cd5\u901a\u8fc7\u8054\u5408\u4f18\u5316\u4fe1\u9053\u9884\u6d4b\u548cDM-RS\u5206\u914d\uff0c\u5728\u65e0\u9700CSI\u53cd\u9988\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u4e86\u6570\u636e\u541e\u5410\u91cf\uff0c\u5e76\u5f97\u5230\u4e86\u4eff\u771f\u7ed3\u679c\u7684\u9a8c\u8bc1\uff0c\u4e0e\u57fa\u51c6\u7b56\u7565\u76f8\u6bd4\uff0c\u541e\u5410\u91cf\u63d0\u9ad8\u4e8636.60%\u3002"}}
{"id": "2507.10581", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.10581", "abs": "https://arxiv.org/abs/2507.10581", "authors": ["Esmail Gumaan"], "title": "Universal Approximation Theorem for a Single-Layer Transformer", "comment": "7 pages, 2 figures, 1 theorem, 10 formulas", "summary": "Deep learning employs multi-layer neural networks trained via the\nbackpropagation algorithm. This approach has achieved success across many\ndomains and relies on adaptive gradient methods such as the Adam optimizer.\nSequence modeling evolved from recurrent neural networks to attention-based\nmodels, culminating in the Transformer architecture. Transformers have achieved\nstate-of-the-art performance in natural language processing (for example, BERT\nand GPT-3) and have been applied in computer vision and computational biology.\nHowever, theoretical understanding of these models remains limited. In this\npaper, we examine the mathematical foundations of deep learning and\nTransformers and present a novel theoretical result. We review key concepts\nfrom linear algebra, probability, and optimization that underpin deep learning,\nand we analyze the multi-head self-attention mechanism and the backpropagation\nalgorithm in detail. Our main contribution is a universal approximation theorem\nfor Transformers: we prove that a single-layer Transformer, comprising one\nself-attention layer followed by a position-wise feed-forward network with ReLU\nactivation, can approximate any continuous sequence-to-sequence mapping on a\ncompact domain to arbitrary precision. We provide a formal statement and a\ncomplete proof. Finally, we present case studies that demonstrate the practical\nimplications of this result. Our findings advance the theoretical understanding\nof Transformer models and help bridge the gap between theory and practice.", "AI": {"tldr": "\u672c\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u6df1\u5ea6\u5b66\u4e60\u548cTransformer\u7684\u7406\u8bba\u57fa\u7840\uff0c\u8bc1\u660e\u4e86\u5355\u5c42Transformer\u6a21\u578b\u53ef\u4ee5\u8fd1\u4f3c\u4efb\u610f\u8fde\u7eed\u5e8f\u5217\u5230\u5e8f\u5217\u6620\u5c04\u3002", "motivation": "\u5c3d\u7ba1Transformer\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7b49\u9886\u57df\u53d6\u5f97\u4e86\u5de8\u5927\u6210\u529f\uff0c\u4f46\u5bf9\u5176\u7406\u8bba\u7406\u89e3\u4ecd\u7136\u6709\u9650\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u68c0\u9a8c\u5176\u6570\u5b66\u57fa\u7840\u5e76\u63d0\u51fa\u65b0\u7684\u7406\u8bba\u7ed3\u679c\u6765\u589e\u8fdb\u5bf9\u8fd9\u4e9b\u6a21\u578b\u7684\u7406\u89e3\u3002", "method": "\u672c\u6587\u7814\u7a76\u4e86\u6df1\u5ea6\u5b66\u4e60\u548cTransformer\u7684\u6570\u5b66\u57fa\u7840\uff0c\u5305\u62ec\u7ebf\u6027\u4ee3\u6570\u3001\u6982\u7387\u548c\u4f18\u5316\u4e2d\u7684\u5173\u952e\u6982\u5ff5\uff0c\u5e76\u8be6\u7ec6\u5206\u6790\u4e86\u591a\u5934\u81ea\u6ce8\u610f\u529b\u673a\u5236\u548c\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\u3002\u6838\u5fc3\u8d21\u732e\u662f\u8bc1\u660e\u4e86\u5355\u5c42Transformer\uff08\u5305\u542b\u4e00\u4e2a\u81ea\u6ce8\u610f\u529b\u5c42\u548c\u4e00\u4e2a\u5e26ReLU\u6fc0\u6d3b\u7684\u9010\u4f4d\u7f6e\u524d\u9988\u7f51\u7edc\uff09\u53ef\u4ee5\u4efb\u610f\u7cbe\u5ea6\u5730\u8fd1\u4f3c\u7d27\u57df\u4e0a\u7684\u4efb\u4f55\u8fde\u7eed\u5e8f\u5217\u5230\u5e8f\u5217\u6620\u5c04\u3002", "result": "\u6211\u4eec\u8bc1\u660e\u4e86\u4e00\u4e2a\u9002\u7528\u4e8eTransformer\u7684\u901a\u7528\u8fd1\u4f3c\u5b9a\u7406\uff1a\u5355\u5c42Transformer\u53ef\u4ee5\u8fd1\u4f3c\u4efb\u610f\u7684\u8fde\u7eed\u5e8f\u5217\u5230\u5e8f\u5217\u6620\u5c04\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7406\u8bba\u7ed3\u679c\uff0c\u5373\u5355\u5c42Transformer\u53ef\u4ee5\u8fd1\u4f3c\u4efb\u610f\u7684\u8fde\u7eed\u5e8f\u5217\u5230\u5e8f\u5217\u6620\u5c04\uff0c\u8fd9\u5728\u7406\u8bba\u4e0a\u52a0\u6df1\u4e86\u5bf9Transformer\u6a21\u578b\u7684\u7406\u89e3\uff0c\u5e76\u6709\u52a9\u4e8e\u7f29\u5c0f\u7406\u8bba\u4e0e\u5b9e\u8df5\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2507.10749", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.10749", "abs": "https://arxiv.org/abs/2507.10749", "authors": ["Benjamin Stoler", "Juliet Yang", "Jonathan Francis", "Jean Oh"], "title": "RCG: Safety-Critical Scenario Generation for Robust Autonomous Driving via Real-World Crash Grounding", "comment": null, "summary": "Safety-critical scenarios are essential for training and evaluating\nautonomous driving (AD) systems, yet remain extremely rare in real-world\ndriving datasets. To address this, we propose Real-world Crash Grounding (RCG),\na scenario generation framework that integrates crash-informed semantics into\nadversarial perturbation pipelines. We construct a safety-aware behavior\nrepresentation through contrastive pre-training on large-scale driving logs,\nfollowed by fine-tuning on a small, crash-rich dataset with approximate\ntrajectory annotations extracted from video. This embedding captures semantic\nstructure aligned with real-world accident behaviors and supports selection of\nadversary trajectories that are both high-risk and behaviorally realistic. We\nincorporate the resulting selection mechanism into two prior scenario\ngeneration pipelines, replacing their handcrafted scoring objectives with an\nembedding-based criterion. Experimental results show that ego agents trained\nagainst these generated scenarios achieve consistently higher downstream\nsuccess rates, with an average improvement of 9.2% across seven evaluation\nsettings. Qualitative and quantitative analyses further demonstrate that our\napproach produces more plausible and nuanced adversary behaviors, enabling more\neffective and realistic stress testing of AD systems. Code and tools will be\nreleased publicly.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86RCG\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u6210\u78b0\u649e\u4fe1\u606f\u8bed\u4e49\u548c\u5b89\u5168\u611f\u77e5\u7684\u884c\u4e3a\u8868\u793a\uff0c\u751f\u6210\u771f\u5b9e\u7684\u5b89\u5168\u5173\u952e\u81ea\u52a8\u9a7e\u9a76\u573a\u666f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u771f\u5b9e\u4e16\u754c\u7684\u5b89\u5168\u5173\u952e\u573a\u666f\u5bf9\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5728\u5b9e\u9645\u9a7e\u9a76\u6570\u636e\u96c6\u4e2d\u5374\u6781\u4e3a\u7f55\u89c1\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aReal-world Crash Grounding (RCG)\u7684\u573a\u666f\u751f\u6210\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5c06\u78b0\u649e\u4fe1\u606f\u8bed\u4e49\u96c6\u6210\u5230\u5bf9\u6297\u6027\u6270\u52a8\u6d41\u7a0b\u4e2d\u3002\u901a\u8fc7\u5728\u5927\u91cf\u9a7e\u9a76\u65e5\u5fd7\u4e0a\u8fdb\u884c\u5bf9\u6bd4\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u5728\u5305\u542b\u78b0\u649e\u7684\u3001\u5e26\u6709\u8fd1\u4f3c\u8f68\u8ff9\u6ce8\u91ca\u7684\u5c0f\u578b\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5fae\u8c03\uff0c\u6784\u5efa\u4e86\u5b89\u5168\u611f\u77e5\u7684\u884c\u4e3a\u8868\u793a\u3002\u8be5\u5d4c\u5165\u80fd\u591f\u6355\u83b7\u4e0e\u771f\u5b9e\u4e16\u754c\u4e8b\u6545\u884c\u4e3a\u4e00\u81f4\u7684\u8bed\u4e49\u7ed3\u6784\uff0c\u5e76\u652f\u6301\u9009\u62e9\u9ad8\u98ce\u9669\u4e14\u884c\u4e3a\u4e0a\u771f\u5b9e\u53ef\u4fe1\u7684\u5bf9\u624b\u8f68\u8ff9\u3002\u5c06\u6b64\u9009\u62e9\u673a\u5236\u96c6\u6210\u5230\u73b0\u6709\u7684\u573a\u666f\u751f\u6210\u6d41\u7a0b\u4e2d\uff0c\u7528\u57fa\u4e8e\u5d4c\u5165\u7684\u6807\u51c6\u66ff\u4ee3\u4e86\u624b\u5de5\u8bbe\u8ba1\u7684\u8bc4\u5206\u76ee\u6807\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528\u8be5\u6846\u67b6\u751f\u6210\u7684\u573a\u666f\u8fdb\u884c\u8bad\u7ec3\u7684\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\uff0c\u5728\u4e03\u79cd\u8bc4\u4f30\u8bbe\u7f6e\u4e0b\u5e73\u5747\u6210\u529f\u7387\u63d0\u9ad8\u4e869.2%\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u66f4\u5408\u7406\u3001\u66f4\u7ec6\u81f4\u7684\u5bf9\u624b\u884c\u4e3a\uff0c\u4f7f\u5f97\u5bf9\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u538b\u529b\u6d4b\u8bd5\u66f4\u52a0\u6709\u6548\u548c\u771f\u5b9e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u751f\u6210\u7684\u5b89\u5168\u5173\u952e\u573a\u666f\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u4e0b\u6e38\u6210\u529f\u7387\uff0c\u5e73\u5747\u63d0\u9ad8\u4e869.2%\uff0c\u5e76\u4e14\u80fd\u591f\u751f\u6210\u66f4\u5177\u53ef\u4fe1\u5ea6\u548c\u7ec6\u5fae\u5dee\u522b\u7684\u5bf9\u624b\u884c\u4e3a\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u6709\u6548\u548c\u73b0\u5b9e\u7684\u538b\u529b\u6d4b\u8bd5\u3002"}}
{"id": "2507.10849", "categories": ["cs.AR", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.10849", "abs": "https://arxiv.org/abs/2507.10849", "authors": ["Xinxin Wang", "Lixian Yan", "Shuhan Liu", "Luke Upton", "Zhuoqi Cai", "Yiming Tan", "Shengman Li", "Koustav Jana", "Peijing Li", "Jesse Cirimelli-Low", "Thierry Tambe", "Matthew Guthaus", "H. -S. Philip Wong"], "title": "OpenGCRAM: An Open-Source Gain Cell Compiler Enabling Design-Space Exploration for AI Workloads", "comment": null, "summary": "Gain Cell memory (GCRAM) offers higher density and lower power than SRAM,\nmaking it a promising candidate for on-chip memory in domain-specific\naccelerators. To support workloads with varying traffic and lifetime metrics,\nGCRAM also offers high bandwidth, ultra low leakage power and a wide range of\nretention times, which can be adjusted through transistor design (like\nthreshold voltage and channel material) and on-the-fly by changing the\noperating voltage. However, designing and optimizing GCRAM sub-systems can be\ntime-consuming. In this paper, we present OpenGCRAM, an open-source GCRAM\ncompiler capable of generating GCRAM bank circuit designs and DRC- and\nLVS-clean layouts for commercially available foundry CMOS, while also providing\narea, delay, and power simulations based on user-specified configurations\n(e.g., word size and number of words). OpenGCRAM enables fast, accurate,\ncustomizable, and optimized GCRAM block generation, reduces design time, ensure\nprocess compliance, and delivers performance-tailored memory blocks that meet\ndiverse application requirements.", "AI": {"tldr": "OpenGCRAM\u662f\u4e00\u4e2a\u5f00\u6e90GCRAM\u7f16\u8bd1\u5668\uff0c\u53ef\u4ee5\u4e3aCMOS\u4ee3\u5de5\u5382\u751f\u6210GCRAM\u8bbe\u8ba1\u548c\u7248\u56fe\uff0c\u5e76\u8fdb\u884c\u6027\u80fd\u6a21\u62df\uff0c\u4ee5\u6ee1\u8db3\u4e0d\u540c\u5e94\u7528\u7684\u9700\u6c42\u3002", "motivation": "\u4e3a\u4e86\u652f\u6301\u5177\u6709\u4e0d\u540c\u6d41\u91cf\u548c\u5bff\u547d\u6307\u6807\u7684\u5de5\u4f5c\u8d1f\u8f7d\uff0cGCRAM\u4e5f\u63d0\u4f9b\u9ad8\u5e26\u5bbd\u3001\u8d85\u4f4e\u6f0f\u7535\u548c\u5bbd\u8303\u56f4\u7684\u4fdd\u6301\u65f6\u95f4\uff0c\u8fd9\u53ef\u4ee5\u901a\u8fc7\u6676\u4f53\u7ba1\u8bbe\u8ba1\uff08\u5982\u9608\u503c\u7535\u538b\u548c\u6c9f\u9053\u6750\u6599\uff09\u4ee5\u53ca\u901a\u8fc7\u6539\u53d8\u5de5\u4f5c\u7535\u538b\u6765\u52a8\u6001\u8c03\u6574\u3002\u7136\u800c\uff0c\u8bbe\u8ba1\u548c\u4f18\u5316GCRAM\u5b50\u7cfb\u7edf\u53ef\u80fd\u975e\u5e38\u8017\u65f6\u3002", "method": "\u901a\u8fc7\u7528\u6237\u6307\u5b9a\u7684\u914d\u7f6e\uff08\u4f8b\u5982\u5b57\u5927\u5c0f\u548c\u5b57\u6570\uff09\u751f\u6210GCRAM bank\u7535\u8def\u8bbe\u8ba1\u548cDRC-\u3001LVS-clean\u7248\u56fe\uff0c\u5e76\u63d0\u4f9b\u9762\u79ef\u3001\u5ef6\u8fdf\u548c\u529f\u8017\u6a21\u62df\u3002", "result": "OpenGCRAM\u80fd\u591f\u5feb\u901f\u3001\u51c6\u786e\u3001\u53ef\u5b9a\u5236\u4e14\u4f18\u5316\u5730\u751f\u6210GCRAM\u5757\uff0c\u51cf\u5c11\u8bbe\u8ba1\u65f6\u95f4\uff0c\u786e\u4fdd\u5de5\u827a\u5408\u89c4\u6027\uff0c\u5e76\u63d0\u4f9b\u6ee1\u8db3\u4e0d\u540c\u5e94\u7528\u9700\u6c42\u7684\u3001\u6027\u80fd\u5b9a\u5236\u7684\u5185\u5b58\u5757\u3002", "conclusion": "OpenGCRAM\u662f\u4e00\u4e2a\u5f00\u6e90GCRAM\u7f16\u8bd1\u5668\uff0c\u80fd\u591f\u4e3a\u5546\u7528CMOS\u4ee3\u5de5\u5382\u751f\u6210GCRAM bank\u7535\u8def\u8bbe\u8ba1\u548cDRC-\u3001LVS-clean\u7248\u56fe\uff0c\u5e76\u6839\u636e\u7528\u6237\u6307\u5b9a\u7684\u914d\u7f6e\uff08\u4f8b\u5982\u5b57\u5927\u5c0f\u548c\u5b57\u6570\uff09\u63d0\u4f9b\u9762\u79ef\u3001\u5ef6\u8fdf\u548c\u529f\u8017\u6a21\u62df\u3002OpenGCRAM\u80fd\u591f\u5feb\u901f\u3001\u51c6\u786e\u3001\u53ef\u5b9a\u5236\u4e14\u4f18\u5316\u5730\u751f\u6210GCRAM\u5757\uff0c\u51cf\u5c11\u8bbe\u8ba1\u65f6\u95f4\uff0c\u786e\u4fdd\u5de5\u827a\u5408\u89c4\u6027\uff0c\u5e76\u63d0\u4f9b\u6ee1\u8db3\u4e0d\u540c\u5e94\u7528\u9700\u6c42\u7684\u3001\u6027\u80fd\u5b9a\u5236\u7684\u5185\u5b58\u5757\u3002"}}
{"id": "2507.11479", "categories": ["cs.AI", "cs.GR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.11479", "abs": "https://arxiv.org/abs/2507.11479", "authors": ["Daniel Platnick", "Matti Gruener", "Marjan Alirezaie", "Kent Larson", "Dava J. Newman", "Hossein Rahnama"], "title": "Perspective-Aware AI in Extended Reality", "comment": "Accepted to the International Conference on eXtended Reality (2025),\n  12 pages, 3 figures", "summary": "AI-enhanced Extended Reality (XR) aims to deliver adaptive, immersive\nexperiences-yet current systems fall short due to shallow user modeling and\nlimited cognitive context. We introduce Perspective-Aware AI in Extended\nReality (PAiR), a foundational framework for integrating Perspective-Aware AI\n(PAi) with XR to enable interpretable, context-aware experiences grounded in\nuser identity. PAi is built on Chronicles: reasoning-ready identity models\nlearned from multimodal digital footprints that capture users' cognitive and\nexperiential evolution. PAiR employs these models in a closed-loop system\nlinking dynamic user states with immersive environments. We present PAiR's\narchitecture, detailing its modules and system flow, and demonstrate its\nutility through two proof-of-concept scenarios implemented in the Unity-based\nOpenDome engine. PAiR opens a new direction for human-AI interaction by\nembedding perspective-based identity models into immersive systems.", "AI": {"tldr": "PAiR\u662f\u4e00\u4e2a\u5c06\u89c6\u89d2\u611f\u77e5AI\uff08PAi\uff09\u4e0eXR\u96c6\u6210\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u57fa\u4e8e\u591a\u6a21\u6001\u6570\u5b57\u8db3\u8ff9\u5b66\u4e60\u7684\u7528\u6237\u8eab\u4efd\u6a21\u578b\uff0c\u5b9e\u73b0\u53ef\u89e3\u91ca\u3001\u60c5\u5883\u611f\u77e5\u7684\u6c89\u6d78\u5f0f\u4f53\u9a8c\u3002", "motivation": "\u5f53\u524d\u7684XR\u7cfb\u7edf\u7531\u4e8e\u7528\u6237\u6a21\u578b\u80a4\u6d45\u548c\u8ba4\u77e5\u80cc\u666f\u6709\u9650\uff0c\u65e0\u6cd5\u63d0\u4f9b\u81ea\u9002\u5e94\u3001\u6c89\u6d78\u5f0f\u7684\u4f53\u9a8c\u3002", "method": "PAiR\u662f\u4e00\u4e2a\u57fa\u7840\u6846\u67b6\uff0c\u5b83\u5c06\u89c6\u89d2\u611f\u77e5AI\uff08PAi\uff09\u4e0eXR\u96c6\u6210\uff0c\u4ee5\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u3001\u4ee5\u7528\u6237\u8eab\u4efd\u4e3a\u57fa\u7840\u7684\u4f53\u9a8c\u3002PAi\u57fa\u4e8eChronicles\u6784\u5efa\uff0cChronicles\u662f\u57fa\u4e8e\u591a\u6a21\u6001\u6570\u5b57\u8db3\u8ff9\u5b66\u4e60\u7684\u3001\u53ef\u63a8\u7406\u7684\u8eab\u4efd\u6a21\u578b\uff0c\u80fd\u591f\u6355\u6349\u7528\u6237\u8ba4\u77e5\u548c\u7ecf\u9a8c\u7684\u6f14\u53d8\u3002PAiR\u5728\u95ed\u73af\u7cfb\u7edf\u4e2d\u8fd0\u7528\u8fd9\u4e9b\u6a21\u578b\uff0c\u5c06\u52a8\u6001\u7528\u6237\u72b6\u6001\u4e0e\u6c89\u6d78\u5f0f\u73af\u5883\u8054\u7cfb\u8d77\u6765\u3002", "result": "\u5c55\u793a\u4e86PAiR\u7684\u67b6\u6784\uff0c\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u5176\u6a21\u5757\u548c\u7cfb\u7edf\u6d41\u7a0b\uff0c\u5e76\u901a\u8fc7\u5728\u57fa\u4e8eUnity\u7684OpenDome\u5f15\u64ce\u4e2d\u5b9e\u73b0\u7684\u4e24\u4e2a\u6982\u5ff5\u9a8c\u8bc1\u573a\u666f\u8bc1\u660e\u4e86\u5176\u6548\u7528\u3002", "conclusion": "PAiR\u901a\u8fc7\u5c06\u57fa\u4e8e\u89c6\u89d2\u7684\u8eab\u4efd\u6a21\u578b\u5d4c\u5165\u6c89\u6d78\u5f0f\u7cfb\u7edf\uff0c\u4e3a\u4eba\u673a\u4ea4\u4e92\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2507.11093", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.11093", "abs": "https://arxiv.org/abs/2507.11093", "authors": ["Wenxuan Sun", "Mingjie Shao", "Luteng Zhu", "Yao Ge", "Tong Zhang", "Zhi Liu"], "title": "Optimizing Fluid Antenna Configurations for Constructive Interference Precoding", "comment": null, "summary": "The fluid antenna system (FAS) has emerged as a new physical-layer concept to\nprovide enhanced propagation conditions for multiuser multiple-input\nmultiple-output (MIMO) communications over conventional fixed arrays. This work\nfocuses on minimizing the maximum symbol error probability (SEP) under $M$-ary\nphase shift keying (MPSK) signaling in a multiuser downlink equipped with FAS,\nwhere each antenna moves within nonoverlapping intervals. This specific problem\nof joint SEP minimization with FAS and constructive interference (CI) precoding\nhas not been previously addressed. The resulting problem turns out to be a\nnonconvex and nonsmooth optimization challenge. We transform the SEP\nminimization problem into a safety margin maximization problem in constructive\ninterference precoding. Then, we customize a smoothing technique and a block\ncoordinate descent (BCD) algorithm, with emphasis on low computational\ncomplexity. Simulation results show that our approach can reduce bit error rate\n(BER) compared to both the fixed arrays and FAS designed by existing particle\nswarm optimization (PSO). Also, our approach shows attractively low\ncomputational complexity compared to PSO benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684 FAS \u548c CI pre\u00adcoding \u65b9\u6cd5\uff0c\u53ef\u964d\u4f4e\u901a\u4fe1\u8bef\u7801\u7387\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4f20\u7edf\u56fa\u5b9a\u9635\u5217\u5728\u591a\u7528\u6237 MIMO \u901a\u4fe1\u4e2d\u4f20\u64ad\u6761\u4ef6\u53d7\u9650\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u7269\u7406\u5c42\u6982\u5ff5\u2014\u2014\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf (FAS)\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684 FAS \u548c CI pre\u00adcoding \u65b9\u6cd5\u672a\u80fd\u6709\u6548\u89e3\u51b3 SEP \u6700\u5c0f\u5316\u95ee\u9898\u3002", "method": "\u5c06 SEP \u6700\u5c0f\u5316\u95ee\u9898\u8f6c\u5316\u4e3a CI pre\u00adcoding \u4e2d\u7684\u5b89\u5168\u88d5\u5ea6\u6700\u5927\u5316\u95ee\u9898\uff0c\u5e76\u81ea\u5b9a\u4e49\u4e86\u5e73\u6ed1\u6280\u672f\u548c\u5757\u5750\u6807\u4e0b\u964d (BCD) \u7b97\u6cd5\uff0c\u4ee5\u5b9e\u73b0\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u672c\u6587\u63d0\u51fa\u7684 FAS \u548c CI pre\u00adcoding \u65b9\u6cd5\u4e0e\u73b0\u6709\u7684\u56fa\u5b9a\u9635\u5217\u548c\u57fa\u4e8e PSO \u7684 FAS \u65b9\u6cd5\u76f8\u6bd4\uff0c\u80fd\u591f\u964d\u4f4e\u8bef\u6bd4\u7279\u7387 (BER)\u3002\u6b64\u5916\uff0c\u4e0e PSO \u57fa\u51c6\u65b9\u6cd5\u76f8\u6bd4\uff0c\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u5177\u6709\u8f83\u4f4e\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684 joint SEP minimization \u7b97\u6cd5\u5728\u964d\u4f4e\u8bef\u6bd4\u7279\u7387\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2507.10936", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2507.10936", "abs": "https://arxiv.org/abs/2507.10936", "authors": ["Ashfaq Ali Shafin", "Khandaker Mamun Ahmed"], "title": "Toxicity in State Sponsored Information Operations", "comment": "Accepted at 36th ACM Conference on Hypertext and Social Media (HT\n  '25), September 15-18, 2025, Chicago, IL. 4 pages, 3 figures, 1 table", "summary": "State-sponsored information operations (IOs) increasingly influence global\ndiscourse on social media platforms, yet their emotional and rhetorical\nstrategies remain inadequately characterized in scientific literature. This\nstudy presents the first comprehensive analysis of toxic language deployment\nwithin such campaigns, examining 56 million posts from over 42 thousand\naccounts linked to 18 distinct geopolitical entities on X/Twitter. Using\nGoogle's Perspective API, we systematically detect and quantify six categories\nof toxic content and analyze their distribution across national origins,\nlinguistic structures, and engagement metrics, providing essential information\nregarding the underlying patterns of such operations. Our findings reveal that\nwhile toxic content constitutes only 1.53% of all posts, they are associated\nwith disproportionately high engagement and appear to be strategically deployed\nin specific geopolitical contexts. Notably, toxic content originating from\nRussian influence operations receives significantly higher user engagement\ncompared to influence operations from any other country in our dataset. Our\ncode is available at https://github.com/shafin191/Toxic_IO.", "AI": {"tldr": "This study analyzes toxic language in state-sponsored information operations on X/Twitter, finding it's strategically used and drives high engagement, especially from Russian operations.", "motivation": "To comprehensively analyze the emotional and rhetorical strategies, specifically toxic language, employed in state-sponsored information operations on social media platforms, which is inadequately characterized in scientific literature.", "method": "Analyzed 56 million posts from over 42 thousand accounts linked to 18 geopolitical entities on X/Twitter using Google's Perspective API to detect and quantify six categories of toxic content.", "result": "Toxic content constitutes 1.53% of all posts but is associated with disproportionately high engagement and is strategically deployed. Russian influence operations' toxic content receives significantly higher user engagement compared to other countries.", "conclusion": "State-sponsored information operations increasingly use toxic language, with Russian operations showing disproportionately high engagement."}}
{"id": "2507.10796", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.10796", "abs": "https://arxiv.org/abs/2507.10796", "authors": ["M. Markwitz", "K. Van Koughnet", "K. Kneisel", "W. F. Holmes-Hewett", "F. Natali", "E. X. M. Trewick", "L. Porteous", "B. J. Ruck", "H. J. Trodahl"], "title": "Raman signature of cation vacancies in rare-earth nitrides", "comment": "7 pages, 5 figures, 42 references. The following article has been\n  accepted by Physical Review B. After it is published, it can be found at\n  https://doi.org/10.1103/583w-9pt7", "summary": "We report a coordinated Raman/computation study of the rare-earth nitrides, a\nseries of intrinsic ferromagnetic semiconductors, to reveal the presence of\ncation vacancies. Their presence is signaled by a Raman-active vibrational mode\nat 1100-1400 cm$^{-1}$, rising steadily as the lattice contracts across the\nseries. The mode's frequency is in excellent agreement with the computed\nbreathing-mode vibration of the six nitrogen ions surrounding cation vacancies.\nThe discovery of such cation vacancies opens the door for hole doping that has\nso far been lacking in the exploitation of rare-earth nitrides.", "AI": {"tldr": "\u901a\u8fc7\u62c9\u66fc\u5149\u8c31\u548c\u8ba1\u7b97\u7814\u7a76\uff0c\u53d1\u73b0\u4e86\u7a00\u571f\u7269\u76f8\u4e2d\u7684\u9633\u79bb\u5b50\u7a7a\u4f4d\uff0c\u8fd9\u4e3a\u7a00\u571f\u7269\u76f8\u7684\u7a7a\u7a74\u63ba\u6742\u63d0\u4f9b\u4e86\u65b0\u7684\u9014\u5f84\u3002", "motivation": "\u7a00\u571f\u7269\u76f8\u662f\u5185\u5728\u94c1\u78c1\u534a\u5bfc\u4f53\uff0c\u4f46\u7f3a\u4e4f\u7a7a\u7a74\u63ba\u6742\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u5176\u6027\u8d28\u4ee5\u5b9e\u73b0\u7a7a\u7a74\u63ba\u6742\u3002", "method": "\u901a\u8fc7\u62c9\u66fc\u5149\u8c31/\u8ba1\u7b97\u7814\u7a76\u4e86\u7a00\u571f\u7269\u76f8\uff0c\u63ed\u793a\u4e86\u9633\u79bb\u5b50\u7a7a\u4f4d\u7684\u5b58\u5728\u3002", "result": "\u53d1\u73b0\u4e86\u7a00\u571f\u7269\u76f8\u4e2d\u7684\u9633\u79bb\u5b50\u7a7a\u4f4d\uff0c\u5176\u62c9\u66fc\u6d3b\u6027\u632f\u52a8\u6a21\u5f0f\u57281100-1400 cm$^{-1}$\uff0c\u5e76\u4e14\u8be5\u6a21\u5f0f\u7684\u9891\u7387\u4e0e\u8ba1\u7b97\u5f97\u5230\u7684\u9633\u79bb\u5b50\u7a7a\u4f4d\u5468\u56f4\u7684\u6c2e\u79bb\u5b50\u7684\u547c\u5438\u6a21\u5f0f\u632f\u52a8\u9891\u7387\u9ad8\u5ea6\u4e00\u81f4\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\u4e86\u7a00\u571f\u7269\u76f8\u4e2d\u7684\u9633\u79bb\u5b50\u7a7a\u4f4d\uff0c\u8fd9\u4e3a\u7a00\u571f\u7269\u76f8\u7684\u7a7a\u7a74\u63ba\u6742\u63d0\u4f9b\u4e86\u65b0\u7684\u9014\u5f84\u3002"}}
{"id": "2507.11141", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2507.11141", "abs": "https://arxiv.org/abs/2507.11141", "authors": ["Simon Guilloud", "Sankalp Gambhir", "Viktor Kun\u010dak"], "title": "Interpolation and Quantifiers in Ortholattices", "comment": null, "summary": "We study quantifiers and interpolation properties in \\emph{orthologic}, a\nnon-distributive weakening of classical logic that is sound for formula\nvalidity with respect to classical logic, yet has a quadratic-time decision\nprocedure. We present a sequent-based proof system for quantified orthologic,\nwhich we prove sound and complete for the class of all complete ortholattices.\nWe show that orthologic does not admit quantifier elimination in general.\nDespite that, we show that interpolants always exist in orthologic. We give an\nalgorithm to compute interpolants efficiently. We expect our result to be\nuseful to quickly establish unreachability as a component of verification\nalgorithms.", "AI": {"tldr": "This paper analyzes quantifiers and interpolation in orthologic, a weaker version of classical logic. It introduces a proof system, shows interpolants exist despite no general quantifier elimination, and provides an efficient algorithm for computing them, useful for verification tasks.", "motivation": "The paper studies quantifiers and interpolation properties in orthologic, a non-distributive weakening of classical logic with a quadratic-time decision procedure, aiming to provide useful tools for verification algorithms.", "method": "A sequent-based proof system for quantified orthologic is presented and proven sound and complete for complete ortholattices.", "result": "An efficient algorithm to compute interpolants in orthologic is provided, which is expected to be useful for establishing unreachability in verification algorithms.", "conclusion": "The paper proves that orthologic does not admit quantifier elimination in general, but interpolants always exist and provides an efficient algorithm for their computation."}}
{"id": "2507.10669", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2507.10669", "abs": "https://arxiv.org/abs/2507.10669", "authors": ["Sara Finocchiaro", "Giovanni Luilli", "Giuliano Benenti", "Matteo G. A. Paris", "Luca Razzoli"], "title": "Optimal quantum transport on a ring via locally monitored chiral quantum walks", "comment": "10 pages, 7 figures", "summary": "In purely coherent transport on finite networks, destructive interference can\nsignificantly suppress transfer probabilities, which can only reach high values\nthrough careful fine-tuning of the evolution time or tailored initial-state\npreparations. We address this issue by investigating excitation transfer on a\nring, modeling it as a locally monitored continuous-time chiral quantum walk.\nChirality, introduced through time-reversal symmetry breaking, imparts a\ndirectional bias to the coherent dynamics and can lift dark states. Local\nmonitoring, implemented via stroboscopic projective measurements at the target\nsite, provides a practical detection protocol without requiring fine-tuning of\nthe evolution time. By analyzing the interplay between chirality and\nmeasurement frequency, we identify optimal conditions for maximizing the\nasymptotic detection probability. The optimization of this transfer protocol\nrelies on the spectral properties of the Perron-Frobenius operator, which\ncapture the asymptotic non-unitary dynamics, and on the analysis of dark\nstates. Our approach offers a general framework for enhancing quantum transport\nin monitored systems.", "AI": {"tldr": "\u901a\u8fc7\u5c40\u90e8\u76d1\u6d4b\u7684\u8fde\u7eed\u65f6\u95f4\u624b\u5f81\u91cf\u5b50\u884c\u8d70\uff0c\u5728\u73af\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u6fc0\u53d1\u8f6c\u79fb\uff0c\u65e0\u9700\u7cbe\u7ec6\u8c03\u6574\u6f14\u5316\u65f6\u95f4\u3002", "motivation": "\u5728\u7eaf\u76f8\u5e72\u4f20\u8f93\u7684\u6709\u9650\u7f51\u7edc\u4e2d\uff0c\u7834\u574f\u6027\u5e72\u6d89\u4f1a\u663e\u8457\u6291\u5236\u4f20\u8f93\u6982\u7387\uff0c\u53ea\u6709\u901a\u8fc7\u7cbe\u5fc3\u8c03\u6574\u6f14\u5316\u65f6\u95f4\u6216\u5236\u5907\u521d\u59cb\u72b6\u6001\u624d\u80fd\u8fbe\u5230\u9ad8\u503c\u3002", "method": "\u7814\u7a76\u4e86\u4e00\u4e2a\u73af\u4e0a\u7684\u6fc0\u53d1\u8f6c\u79fb\u95ee\u9898\uff0c\u5c06\u5176\u5efa\u6a21\u4e3a\u5c40\u90e8\u76d1\u6d4b\u7684\u8fde\u7eed\u65f6\u95f4\u624b\u5f81\u91cf\u5b50\u884c\u8d70\u3002\u901a\u8fc7\u65f6\u95f4\u53cd\u6f14\u5bf9\u79f0\u6027\u7834\u574f\u5f15\u5165\u624b\u5f81\u6027\uff0c\u8d4b\u4e88\u76f8\u5e72\u52a8\u529b\u5b66\u65b9\u5411\u504f\u5dee\u5e76\u80fd\u63d0\u5347\u6697\u6001\u3002\u901a\u8fc7\u5728\u76ee\u6807\u4f4d\u70b9\u8fdb\u884c\u9891\u95ea\u6295\u5f71\u6d4b\u91cf\u6765\u5b9e\u73b0\u5c40\u90e8\u76d1\u6d4b\uff0c\u65e0\u9700\u7cbe\u7ec6\u8c03\u6574\u6f14\u5316\u65f6\u95f4\u5373\u53ef\u8fdb\u884c\u5b9e\u9645\u63a2\u6d4b\u3002", "result": "\u901a\u8fc7\u5206\u6790\u624b\u5f81\u6027\u4e0e\u6d4b\u91cf\u9891\u7387\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u786e\u5b9a\u4e86\u6700\u5927\u5316\u6e10\u8fd1\u63a2\u6d4b\u6982\u7387\u7684\u6700\u4f73\u6761\u4ef6\u3002\u8be5\u4f20\u8f93\u534f\u8bae\u7684\u4f18\u5316\u4f9d\u8d56\u4e8e\u63cf\u8ff0\u6e10\u8fd1\u975e\u5e7a\u6b63\u52a8\u529b\u5b66\u7684Perron-Frobenius\u7b97\u5b50\u7684\u8c31\u6027\u8d28\u4ee5\u53ca\u5bf9\u6697\u6001\u7684\u5206\u6790\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5728\u53d7\u76d1\u63a7\u7cfb\u7edf\u4e2d\u589e\u5f3a\u91cf\u5b50\u8f93\u8fd0\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u6846\u67b6\u3002"}}
{"id": "2507.10775", "categories": ["cs.CV", "cs.AI", "eess.IV"], "pdf": "https://arxiv.org/pdf/2507.10775", "abs": "https://arxiv.org/abs/2507.10775", "authors": ["Jeffrey Joan Sam", "Janhavi Sathe", "Nikhil Chigali", "Naman Gupta", "Radhey Ruparel", "Yicheng Jiang", "Janmajay Singh", "James W. Berck", "Arko Barman"], "title": "A New Dataset and Performance Benchmark for Real-time Spacecraft Segmentation in Onboard Flight Computers", "comment": null, "summary": "Spacecraft deployed in outer space are routinely subjected to various forms\nof damage due to exposure to hazardous environments. In addition, there are\nsignificant risks to the subsequent process of in-space repairs through human\nextravehicular activity or robotic manipulation, incurring substantial\noperational costs. Recent developments in image segmentation could enable the\ndevelopment of reliable and cost-effective autonomous inspection systems. While\nthese models often require large amounts of training data to achieve\nsatisfactory results, publicly available annotated spacecraft segmentation data\nare very scarce. Here, we present a new dataset of nearly 64k annotated\nspacecraft images that was created using real spacecraft models, superimposed\non a mixture of real and synthetic backgrounds generated using NASA's TTALOS\npipeline. To mimic camera distortions and noise in real-world image\nacquisition, we also added different types of noise and distortion to the\nimages. Finally, we finetuned YOLOv8 and YOLOv11 segmentation models to\ngenerate performance benchmarks for the dataset under well-defined hardware and\ninference time constraints to mimic real-world image segmentation challenges\nfor real-time onboard applications in space on NASA's inspector spacecraft. The\nresulting models, when tested under these constraints, achieved a Dice score of\n0.92, Hausdorff distance of 0.69, and an inference time of about 0.5 second.\nThe dataset and models for performance benchmark are available at\nhttps://github.com/RiceD2KLab/SWiM.", "AI": {"tldr": "\u4e3a\u89e3\u51b3\u592a\u7a7a\u635f\u5bb3\u68c0\u6d4b\u548c\u4fee\u590d\u6210\u672c\u95ee\u9898\uff0c\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u8fd164,000\u5f20\u56fe\u50cf\u7684\u6570\u636e\u96c6\uff0c\u5e76\u5fae\u8c03\u4e86YOLO\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u51c6\u786e\u7684\u592a\u7a7a\u56fe\u50cf\u5206\u5272\u3002", "motivation": "\u4e3a\u4e86\u5e94\u5bf9\u5916\u592a\u7a7a\u7a7a\u95f4\u7ad9\u9762\u4e34\u7684\u635f\u574f\u95ee\u9898\u4ee5\u53ca\u4eba\u5de5\u6216\u673a\u5668\u4eba\u4fee\u590d\u7684\u98ce\u9669\u548c\u9ad8\u6210\u672c\uff0c\u63d0\u51fa\u5229\u7528\u56fe\u50cf\u5206\u5272\u6280\u672f\u5f00\u53d1\u81ea\u4e3b\u68c0\u6d4b\u7cfb\u7edf\u3002\u7136\u800c\uff0c\u73b0\u6709\u6a21\u578b\u9700\u8981\u5927\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u800c\u516c\u5f00\u7684\u6807\u6ce8\u6570\u636e\u5374\u5341\u5206\u7a00\u5c11\u3002", "method": "\u5229\u7528NASA\u7684TTALOS\u7ba1\u7ebf\u751f\u6210\u5305\u542b\u8fd164,000\u5f20\u6807\u6ce8\u822a\u5929\u5668\u56fe\u50cf\u7684\u6570\u636e\u96c6\uff0c\u5e76\u52a0\u5165\u566a\u58f0\u548c\u7578\u53d8\u4ee5\u6a21\u62df\u771f\u5b9e\u4e16\u754c\u6761\u4ef6\u3002\u5bf9YOLOv8\u548cYOLOv11\u5206\u5272\u6a21\u578b\u8fdb\u884c\u4e86\u5fae\u8c03\uff0c\u4ee5\u5728\u6a21\u62df\u7684\u771f\u5b9e\u4e16\u754c\u6311\u6218\u4e2d\u5efa\u7acb\u6027\u80fd\u57fa\u51c6\u3002", "result": "\u751f\u6210\u4e86\u4e00\u4e2a\u5305\u542b\u8fd164,000\u5f20\u6807\u6ce8\u822a\u5929\u5668\u56fe\u50cf\u7684\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u4f9b\u4e86\u5fae\u8c03\u540e\u7684YOLOv8\u548cYOLOv11\u6a21\u578b\u6027\u80fd\u57fa\u51c6\u3002\u6240\u63d0\u51fa\u7684\u6a21\u578b\u5728\u7279\u5b9a\u7ea6\u675f\u4e0b\u8fbe\u5230\u4e860.92\u7684Dice\u5206\u6570\uff0c0.69\u7684Hausdorff\u8ddd\u79bb\uff0c\u63a8\u7406\u65f6\u95f4\u7ea6\u4e3a0.5\u79d2\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e3a\u5728\u592a\u7a7a\u4e2d\u7684\u5b9e\u65f6\u5e94\u7528\u63d0\u4f9b\u4e86\u6027\u80fd\u57fa\u51c6\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u901a\u8fc7\u5bf9YOLOv8\u548cYOLOv11\u8fdb\u884c\u5fae\u8c03\uff0c\u5728\u7279\u5b9a\u786c\u4ef6\u548c\u63a8\u7406\u65f6\u95f4\u9650\u5236\u4e0b\u5b9e\u73b0\u4e860.92\u7684Dice\u5206\u6570\u548c0.69\u7684Hausdorff\u8ddd\u79bb\uff0c\u63a8\u7406\u65f6\u95f4\u7ea6\u4e3a0.5\u79d2\u3002"}}
{"id": "2507.10630", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.10630", "abs": "https://arxiv.org/abs/2507.10630", "authors": ["Ye Yang", "Xue Xiao", "Ping Yin", "Taotao Xie"], "title": "Enhancing the Capabilities of Large Language Models for API calls through Knowledge Graphs", "comment": null, "summary": "API calls by large language models (LLMs) offer a cutting-edge approach for\ndata analysis. However, their ability to effectively utilize tools via API\ncalls remains underexplored in knowledge-intensive domains like meteorology.\nThis paper introduces KG2data, a system that integrates knowledge graphs, LLMs,\nReAct agents, and tool-use technologies to enable intelligent data acquisition\nand query handling in the meteorological field. Using a virtual API, we\nevaluate API call accuracy across three metrics: name recognition failure,\nhallucination failure, and call correctness. KG2data achieves superior\nperformance (1.43%, 0%, 88.57%) compared to RAG2data (16%, 10%, 72.14%) and\nchat2data (7.14%, 8.57%, 71.43%). KG2data differs from typical LLM-based\nsystems by addressing their limited access to domain-specific knowledge, which\nhampers performance on complex or terminology-rich queries. By using a\nknowledge graph as persistent memory, our system enhances content retrieval,\ncomplex query handling, domain-specific reasoning, semantic relationship\nresolution, and heterogeneous data integration. It also mitigates the high cost\nof fine-tuning LLMs, making the system more adaptable to evolving domain\nknowledge and API structures. In summary, KG2data provides a novel solution for\nintelligent, knowledge-based question answering and data analysis in domains\nwith high knowledge demands.", "AI": {"tldr": "KG2data \u901a\u8fc7\u96c6\u6210\u77e5\u8bc6\u56fe\u8c31\u3001LLM \u548c ReAct \u4ee3\u7406\uff0c\u5728\u6c14\u8c61\u9886\u57df\u5b9e\u73b0\u4e86\u667a\u80fd\u6570\u636e\u5206\u6790\u548c\u95ee\u7b54\uff0c\u5176 API \u8c03\u7528\u51c6\u786e\u6027\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u89e3\u51b3\u4e86 LLM \u5728\u5904\u7406\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u7136\u800c\uff0c\u5728\u6c14\u8c61\u5b66\u7b49\u77e5\u8bc6\u5bc6\u96c6\u578b\u9886\u57df\uff0cLLM \u901a\u8fc7 API \u8c03\u7528\u6709\u6548\u5229\u7528\u5de5\u5177\u7684\u80fd\u529b\u4ecd\u6709\u5f85\u63a2\u7d22\u3002\u73b0\u6709\u7cfb\u7edf\u5728\u5904\u7406\u590d\u6742\u6216\u672f\u8bed\u4e30\u5bcc\u7684\u67e5\u8be2\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u56e0\u4e3a\u5b83\u4eec\u5bf9\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u7684\u8bbf\u95ee\u6709\u9650\u3002", "method": "KG2data \u7cfb\u7edf\u96c6\u6210\u4e86\u77e5\u8bc6\u56fe\u8c31\u3001\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM)\u3001ReAct \u4ee3\u7406\u548c\u5de5\u5177\u4f7f\u7528\u6280\u672f\uff0c\u4ee5\u5b9e\u73b0\u6c14\u8c61\u9886\u57df\u7684\u667a\u80fd\u6570\u636e\u91c7\u96c6\u548c\u67e5\u8be2\u5904\u7406\u3002\u901a\u8fc7\u4f7f\u7528\u865a\u62df API\uff0c\u6839\u636e\u540d\u79f0\u8bc6\u522b\u5931\u8d25\u3001\u5e7b\u89c9\u5931\u8d25\u548c\u8c03\u7528\u6b63\u786e\u6027\u8fd9\u4e09\u4e2a\u6307\u6807\u8bc4\u4f30 API \u8c03\u7528\u51c6\u786e\u6027\u3002", "result": "KG2data \u5728 API \u8c03\u7528\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u4f18\u4e8e RAG2data \u548c chat2data\uff0c\u5177\u4f53\u6307\u6807\u5206\u522b\u4e3a\uff081.43%\u30010%\u300188.57%\uff09\uff0c\u800c RAG2data \u4e3a\uff0816%\u300110%\u300172.14%\uff09\uff0cchat2data \u4e3a\uff087.14%\u30018.57%\u300171.43%\uff09\u3002KG2data \u901a\u8fc7\u5c06\u77e5\u8bc6\u56fe\u8c31\u7528\u4f5c\u6301\u4e45\u5185\u5b58\uff0c\u589e\u5f3a\u4e86\u5185\u5bb9\u68c0\u7d22\u3001\u590d\u6742\u67e5\u8be2\u5904\u7406\u3001\u9886\u57df\u7279\u5b9a\u63a8\u7406\u3001\u8bed\u4e49\u5173\u7cfb\u89e3\u6790\u548c\u5f02\u6784\u6570\u636e\u96c6\u6210\uff0c\u5e76\u964d\u4f4e\u4e86\u5bf9 LLM \u8fdb\u884c\u5fae\u8c03\u7684\u9ad8\u6602\u6210\u672c\u3002", "conclusion": "KG2data \u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u9886\u57df\u4e2d\u5b9e\u73b0\u667a\u80fd\u7684\u3001\u57fa\u4e8e\u77e5\u8bc6\u7684\u95ee\u7b54\u548c\u6570\u636e\u5206\u6790\u3002"}}
{"id": "2507.10586", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10586", "abs": "https://arxiv.org/abs/2507.10586", "authors": ["Kaushik Dwivedi", "Padmanabh Patanjali Mishra"], "title": "AutoRAG-LoRA: Hallucination-Triggered Knowledge Retuning via Lightweight Adapters", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable fluency across a\nrange of natural language tasks, yet remain vulnerable to hallucinations -\nfactual inaccuracies that undermine trust in real world deployment. We present\nAutoRAG-LoRA, a modular framework for Retrieval-Augmented Generation (RAG) that\ntackles hallucination in large language models through lightweight LoRA-based\nadapters and KL-regularized training. Our pipeline integrates automated prompt\nrewriting, hybrid retrieval, and low-rank adapter tuning to ground responses in\nretrieved evidence. A hallucination detection module, using both\nclassifier-based and self-evaluation techniques, assigns confidence scores to\ngenerated outputs, triggering an optional feedback correction loop. This loop\nenforces factual alignment via contrastive KL loss and adapter fine tuning. We\ndemonstrate that AutoRAG-LoRA significantly reduces the factual drift while\npreserving the efficiency and modularity of the model.", "AI": {"tldr": "AutoRAG-LoRA\u662f\u4e00\u4e2a\u7528\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684\u6846\u67b6\uff0c\u901a\u8fc7LoRA\u9002\u914d\u5668\u548cKL\u6b63\u5219\u5316\u8bad\u7ec3\u6765\u51cf\u5c11LLM\u7684\u5e7b\u89c9\uff0c\u5e76\u5305\u542b\u5e7b\u89c9\u68c0\u6d4b\u548c\u53cd\u9988\u7ea0\u6b63\u673a\u5236\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5e7f\u6cdb\u7684\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u4f46\u4ecd\u6613\u51fa\u73b0\u5e7b\u89c9\uff08\u4e8b\u5b9e\u4e0d\u51c6\u786e\uff09\u7684\u95ee\u9898\uff0c\u4ee5\u589e\u5f3a\u5728\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u4e2d\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "\u901a\u8fc7\u96c6\u6210\u81ea\u52a8\u5316\u63d0\u793a\u91cd\u5199\u3001\u6df7\u5408\u68c0\u7d22\u3001\u4f4e\u79e9\u9002\u914d\u5668\u8c03\u4f18\u3001\u5e7b\u89c9\u68c0\u6d4b\u6a21\u5757\uff08\u7ed3\u5408\u5206\u7c7b\u5668\u548c\u81ea\u8bc4\u4f30\u6280\u672f\uff09\u4ee5\u53ca\u5305\u542b\u5bf9\u6bd4KL\u635f\u5931\u548c\u9002\u914d\u5668\u5fae\u8c03\u7684\u53cd\u9988\u7ea0\u6b63\u5faa\u73af\u6765\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u95ee\u9898\u3002", "result": "AutoRAG-LoRA\u663e\u8457\u51cf\u5c11\u4e86\u4e8b\u5b9e\u6f02\u79fb\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u6548\u7387\u548c\u6a21\u5757\u5316\u3002", "conclusion": "AutoRAG-LoRA\u901a\u8fc7\u8f7b\u91cf\u7ea7\u7684LoRA\u9002\u914d\u5668\u548cKL\u6b63\u5219\u5316\u8bad\u7ec3\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u6548\u7387\u548c\u6a21\u5757\u5316\u3002"}}
{"id": "2507.10708", "categories": ["cs.NE", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.10708", "abs": "https://arxiv.org/abs/2507.10708", "authors": ["Maziar Kanani", "Sean O Leary", "James McDermott"], "title": "Grammatical Structure and Grammatical Variations in Non-Metric Iranian Classical Music", "comment": null, "summary": "In this study we introduce a symbolic dataset composed of non-metric Iranian\nclassical music, and algorithms for structural parsing of this music, and\ngeneration of variations. The corpus comprises MIDI files and data sheets of\nDastgah Shour from Radif Mirza Abdollah, the foundational repertoire of Iranian\nclassical music. Furthermore, we apply our previously-introduced algorithm for\nparsing melodic structure (Kanani et al., 2023b)to the dataset. Unlike much\nWestern music, this type of non-metric music does not follow bar-centric\norganisation. The non-metric organisation can be captured well by our parsing\nalgorithm. We parse each tune (Gusheh) into a grammar to identify motifs and\nphrases. These grammar representations can be useful for educational and\nethnomusicological purposes. We also further develop a previously-introduced\nmethod of creating melodic variations (Kanani et al., 2023b). After parsing an\nexisting tune to produce a grammar, by applying mutations to this grammar, we\ngenerate a new grammar. Expanding this new version yields a variation of the\noriginal tune. Variations are assessed by a domain-expert listener.\nAdditionally, we conduct a statistical analysis of mutation with different\nrepresentation setups for our parsing and generation algorithms. The\noverarching conclusion is that the system successfully produces acceptable\nvariations post-mutation. While our case study focuses on Iranian classical\nmusic, the methodology can be adapted for Arabic or Turkish classical music.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4ecb\u7ecd\u4e86\u7528\u4e8e\u89e3\u6790\u548c\u751f\u6210\u975e\u516c\u5236\u4f0a\u6717\u53e4\u5178\u97f3\u4e50\u7684\u7b97\u6cd5\uff0c\u5e76\u6210\u529f\u521b\u5efa\u4e86\u53ef\u63a5\u53d7\u7684\u97f3\u4e50\u53d8\u4f53\u3002", "motivation": "\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u7528\u4e8e\u89e3\u6790\u548c\u751f\u6210\u975e\u516c\u5236\u4f0a\u6717\u53e4\u5178\u97f3\u4e50\u7684\u7b97\u6cd5\uff0c\u4ee5\u7528\u4e8e\u6559\u80b2\u548c\u97f3\u4e50\u5b66\u76ee\u7684\uff0c\u5e76\u4e3a\u8be5\u7c7b\u578b\u97f3\u4e50\u521b\u5efa\u53d8\u4f53\u3002", "method": "\u4ecb\u7ecd\u4e86\u7b26\u53f7\u6570\u636e\u96c6\u548c\u7528\u4e8e\u7ed3\u6784\u89e3\u6790\u548c\u751f\u6210\u4f0a\u6717\u53e4\u5178\u97f3\u4e50\u53d8\u4f53\u7684\u7b97\u6cd5\u3002\u8be5\u7b97\u6cd5\u5c06\u6bcf\u4e2a\u65cb\u5f8b\uff08Gusheh\uff09\u89e3\u6790\u4e3a\u4e00\u79cd\u8bed\u6cd5\uff0c\u4ee5\u8bc6\u522b\u52a8\u673a\u548c\u4e50\u53e5\uff0c\u7136\u540e\u901a\u8fc7\u5bf9\u8bed\u6cd5\u8fdb\u884c\u7a81\u53d8\u6765\u751f\u6210\u65b0\u8bed\u6cd5\uff0c\u4ece\u800c\u4ea7\u751f\u539f\u59cb\u66f2\u8c03\u7684\u53d8\u4f53\u3002\u5bf9\u7a81\u53d8\u8fdb\u884c\u4e86\u7edf\u8ba1\u5206\u6790\u3002", "result": "\u8be5\u89e3\u6790\u7b97\u6cd5\u80fd\u591f\u5f88\u597d\u5730\u6355\u6349\u975e\u516c\u5236\u7ec4\u7ec7\u3002\u751f\u6210\u7684\u53d8\u4f53\u88ab\u9886\u57df\u4e13\u5bb6\u542c\u4f17\u8ba4\u4e3a\u662f\u53ef\u63a5\u53d7\u7684\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u6210\u529f\u5730\u901a\u8fc7\u7a81\u53d8\u4ea7\u751f\u4e86\u53ef\u63a5\u53d7\u7684\u53d8\u4f53\u3002\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5e94\u7528\u4e8e\u963f\u62c9\u4f2f\u6216\u571f\u8033\u5176\u53e4\u5178\u97f3\u4e50\u3002"}}
{"id": "2507.11165", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2507.11165", "abs": "https://arxiv.org/abs/2507.11165", "authors": ["Shixun Wu", "Jinwen Pan", "Jinyang Liu", "Jiannan Tian", "Ziwei Qiu", "Jiajun Huang", "Kai Zhao", "Xin Liang", "Sheng Di", "Zizhong Chen", "Franck Cappello"], "title": "Boosting Scientific Error-Bounded Lossy Compression through Optimized Synergistic Lossy-Lossless Orchestration", "comment": "accepted by SC '25", "summary": "As high-performance computing architectures evolve, more scientific computing\nworkflows are being deployed on advanced computing platforms such as GPUs.\nThese workflows can produce raw data at extremely high throughputs, requiring\nurgent high-ratio and low-latency error-bounded data compression solutions. In\nthis paper, we propose cuSZ-Hi, an optimized high-ratio GPU-based scientific\nerror-bounded lossy compressor with a flexible, domain-irrelevant, and fully\nopen-source framework design. Our novel contributions are: 1) We maximally\noptimize the parallelized interpolation-based data prediction scheme on GPUs,\nenabling the full functionalities of interpolation-based scientific data\nprediction that are adaptive to diverse data characteristics; 2) We thoroughly\nexplore and investigate lossless data encoding techniques, then craft and\nincorporate the best-fit lossless encoding pipelines for maximizing the\ncompression ratio of cuSZ-Hi; 3) We systematically evaluate cuSZ-Hi on\nbenchmarking datasets together with representative baselines. Compared to\nexisting state-of-the-art scientific lossy compressors, with comparative or\nbetter throughput than existing high-ratio scientific error-bounded lossy\ncompressors on GPUs, cuSZ-Hi can achieve up to 249% compression ratio\nimprovement under the same error bound, and up to 215% compression ratio\nimprovement under the same decompression data PSNR.", "AI": {"tldr": "cuSZ-Hi \u662f\u4e00\u79cd\u65b0\u7684 GPU \u538b\u7f29\u5668\uff0c\u5728\u79d1\u5b66\u6570\u636e\u538b\u7f29\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u968f\u7740\u9ad8\u6027\u80fd\u8ba1\u7b97\u67b6\u6784\u7684\u4e0d\u65ad\u53d1\u5c55\uff0c\u8d8a\u6765\u8d8a\u591a\u7684\u79d1\u5b66\u8ba1\u7b97\u5de5\u4f5c\u6d41\u88ab\u90e8\u7f72\u5230 GPU \u7b49\u5148\u8fdb\u8ba1\u7b97\u5e73\u53f0\u4e0a\u3002\u8fd9\u4e9b\u5de5\u4f5c\u6d41\u80fd\u4ee5\u6781\u9ad8\u7684\u541e\u5410\u91cf\u4ea7\u751f\u539f\u59cb\u6570\u636e\uff0c\u56e0\u6b64\u8feb\u5207\u9700\u8981\u9ad8\u538b\u7f29\u6bd4\u3001\u4f4e\u5ef6\u8fdf\u7684\u8bef\u5dee\u6709\u754c\u6570\u636e\u538b\u7f29\u89e3\u51b3\u65b9\u6848\u3002", "method": "cuSZ-Hi \u662f\u4e00\u79cd\u4f18\u5316\u7684\u3001\u57fa\u4e8e GPU \u7684\u3001\u9ad8\u538b\u7f29\u6bd4\u7684\u79d1\u5b66\u8bef\u5dee\u6709\u754c\u6709\u635f\u538b\u7f29\u5668\uff0c\u5176\u6846\u67b6\u8bbe\u8ba1\u7075\u6d3b\u3001\u4e0e\u57df\u65e0\u5173\u4e14\u5b8c\u5168\u5f00\u6e90\u3002\u5176\u521b\u65b0\u4e4b\u5904\u5728\u4e8e\uff1a1\uff09\u6700\u5927\u5316\u4f18\u5316\u4e86\u57fa\u4e8e GPU \u7684\u5e76\u884c\u5316\u63d2\u503c\u6570\u636e\u9884\u6d4b\u65b9\u6848\uff0c\u4f7f\u5176\u80fd\u591f\u9002\u5e94\u591a\u6837\u5316\u7684\u6570\u636e\u7279\u5f81\uff1b2\uff09\u6df1\u5165\u63a2\u7d22\u548c\u7814\u7a76\u4e86\u65e0\u635f\u6570\u636e\u7f16\u7801\u6280\u672f\uff0c\u5e76\u6574\u5408\u4e86\u6700\u9002\u5408\u7684\u65e0\u635f\u7f16\u7801\u6d41\u7a0b\u4ee5\u6700\u5927\u5316 cuSZ-Hi \u7684\u538b\u7f29\u7387\uff1b3\uff09\u7cfb\u7edf\u5730\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u4e0e\u4ee3\u8868\u6027\u57fa\u7ebf\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u4e0e\u73b0\u6709\u7684\u79d1\u5b66\u6709\u635f\u538b\u7f29\u5668\u76f8\u6bd4\uff0ccuSZ-Hi \u5728 GPU \u4e0a\u7684\u541e\u5410\u91cf\u4e0e\u73b0\u6709\u9ad8\u538b\u7f29\u6bd4\u7684\u79d1\u5b66\u8bef\u5dee\u6709\u754c\u6709\u635f\u538b\u7f29\u5668\u76f8\u5f53\u6216\u66f4\u4f18\uff0c\u540c\u65f6\u5728\u76f8\u540c\u7684\u8bef\u5dee\u8303\u56f4\u5185\u53ef\u5b9e\u73b0\u9ad8\u8fbe 249% \u7684\u538b\u7f29\u7387\u63d0\u5347\uff0c\u5728\u76f8\u540c\u7684\u89e3\u538b\u6570\u636e PSNR \u4e0b\u53ef\u5b9e\u73b0\u9ad8\u8fbe 215% \u7684\u538b\u7f29\u7387\u63d0\u5347\u3002", "conclusion": "cuSZ-Hi \u5728\u76f8\u540c\u7684\u8bef\u5dee\u8303\u56f4\u5185\u53ef\u5b9e\u73b0\u9ad8\u8fbe 249% \u7684\u538b\u7f29\u7387\u63d0\u5347\uff0c\u5728\u76f8\u540c\u7684\u89e3\u538b\u6570\u636e PSNR \u4e0b\u53ef\u5b9e\u73b0\u9ad8\u8fbe 215% \u7684\u538b\u7f29\u7387\u63d0\u5347\u3002"}}
{"id": "2507.11371", "categories": ["cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.11371", "abs": "https://arxiv.org/abs/2507.11371", "authors": ["Gabriel Bo", "Koa Chang", "Justin Gu"], "title": "Step-wise Policy for Rare-tool Knowledge (SPaRK): Offline RL that Drives Diverse Tool Use in LLMs", "comment": "12 pages, 4 figures", "summary": "We present Step-wise Policy for Rare-tool Knowledge (SPaRK), a novel\nreinforcement learning framework that teaches large language models to explore\ndiverse tool usage patterns beyond conventional high-temperature sampling.\nBuilding on recent advances in step-wise reinforcement learning, we introduce a\ndual-objective reward system that simultaneously optimizes for answer quality\nand tool diversity, training a Llama-3.1 8B model through offline PPO on\nsynthetically generated trajectories from the MMLU-Pro dataset. Our approach\nuniquely employs a rarity-first exploitation strategy where a GPT-4o judge\nscores candidate actions across eight distinct tools plus chain-of-thought\nreasoning, with the policy favoring less-frequently used but still viable tools\nto encourage systematic exploration. Empirical results demonstrate that SPaRK\nachieves competitive performance across 14 MMLU-Pro categories while exhibiting\nsignificantly higher entropy in tool selection compared to both baseline and\nsupervised fine-tuning approaches, suggesting that algorithmic exploration\nthrough explicit tool diversity can enhance reasoning capabilities without\nsacrificing accuracy.", "AI": {"tldr": "SPaRK\uff1a\u4e00\u79cd\u901a\u8fc7\u4f18\u5316\u5de5\u5177\u591a\u6837\u6027\u6765\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u3002", "motivation": "\u4e3a\u4e86\u8ba9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5229\u7528\u591a\u6837\u5316\u7684\u5de5\u5177\u4f7f\u7528\u6a21\u5f0f\uff0c\u5e76\u8d85\u8d8a\u4f20\u7edf\u7684\u9ad8\u6e29\u91c7\u6837\u65b9\u6cd5\uff0c\u63a2\u7d22\u66f4\u5e7f\u6cdb\u7684\u5de5\u5177\u4f7f\u7528\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a SPaRK\uff08Step-wise Policy for Rare-tool Knowledge\uff09\u7684\u65b0\u578b\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u3002\u8be5\u6846\u67b6\u57fa\u4e8e\u9010\u6b65\u5f3a\u5316\u5b66\u4e60\uff0c\u5f15\u5165\u4e86\u53cc\u76ee\u6807\u5956\u52b1\u7cfb\u7edf\uff0c\u540c\u65f6\u4f18\u5316\u7b54\u6848\u8d28\u91cf\u548c\u5de5\u5177\u591a\u6837\u6027\u3002\u901a\u8fc7\u5728\u5408\u6210\u751f\u6210\u7684\u6570\u636e\u96c6 MMLU-Pro \u4e0a\u4f7f\u7528\u79bb\u7ebf PPO \u8bad\u7ec3 Llama-3.1 8B \u6a21\u578b\u3002\u5176\u72ec\u7279\u4e4b\u5904\u5728\u4e8e\u91c7\u7528\u201c\u7a00\u6709\u6027\u4f18\u5148\u201d\u7b56\u7565\uff0c\u5e76\u4f7f\u7528 GPT-4o \u4f5c\u4e3a\u88c1\u5224\u6765\u8bc4\u4f30\u8de8\u8d8a\u516b\u79cd\u4e0d\u540c\u5de5\u5177\u548c\u94fe\u5f0f\u601d\u8003\u7684\u5019\u9009\u52a8\u4f5c\uff0c\u9f13\u52b1\u6a21\u578b\u63a2\u7d22\u8f83\u5c11\u4f7f\u7528\u7684\u5de5\u5177\u3002", "result": "SPaRK \u5728 14 \u4e2a MMLU-Pro \u7c7b\u522b\u4e0a\u53d6\u5f97\u4e86\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u540c\u65f6\u5728\u5de5\u5177\u9009\u62e9\u65b9\u9762\u8868\u73b0\u51fa\u6bd4\u57fa\u7ebf\u548c\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\u660e\u663e\u66f4\u9ad8\u7684\u71b5\u3002\u8fd9\u8868\u660e\u901a\u8fc7\u660e\u786e\u7684\u5de5\u5177\u591a\u6837\u6027\u8fdb\u884c\u7684\u7b97\u6cd5\u63a2\u7d22\u53ef\u4ee5\u63d0\u9ad8\u63a8\u7406\u80fd\u529b\uff0c\u540c\u65f6\u4e0d\u727a\u7272\u51c6\u786e\u6027\u3002", "conclusion": "SPaRK \u6846\u67b6\u901a\u8fc7\u4f18\u5148\u8003\u8651\u7a00\u6709\u4f46\u53ef\u884c\u7684\u5de5\u5177\uff0c\u5e76\u5728\u5956\u52b1\u7cfb\u7edf\u4e2d\u540c\u65f6\u4f18\u5316\u7b54\u6848\u8d28\u91cf\u548c\u5de5\u5177\u591a\u6837\u6027\uff0c\u5b9e\u73b0\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\u548c\u66f4\u9ad8\u7684\u5de5\u5177\u9009\u62e9\u71b5\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e14\u4e0d\u727a\u7272\u51c6\u786e\u6027\u3002"}}
{"id": "2507.11098", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2507.11098", "abs": "https://arxiv.org/abs/2507.11098", "authors": ["Anita D\u00fcrr", "Evangelos Kipouridis", "Karol W\u0119grzycki"], "title": "Faster algorithms for k-Orthogonal Vectors in low dimension", "comment": null, "summary": "In the Orthogonal Vectors problem (OV), we are given two families $A, B$ of\nsubsets of $\\{1,\\ldots,d\\}$, each of size $n$, and the task is to decide\nwhether there exists a pair $a \\in A$ and $b \\in B$ such that $a \\cap b =\n\\emptyset$. Straightforward algorithms for this problem run in $\\mathcal{O}(n^2\n\\cdot d)$ or $\\mathcal{O}(2^d \\cdot n)$ time, and assuming SETH, there is no\n$2^{o(d)}\\cdot n^{2-\\varepsilon}$ time algorithm that solves this problem for\nany constant $\\varepsilon > 0$.\n  Williams (FOCS 2024) presented a $\\tilde{\\mathcal{O}}(1.35^d \\cdot n)$-time\nalgorithm for the problem, based on the succinct equality-rank decomposition of\nthe disjointness matrix. In this paper, we present a combinatorial algorithm\nthat runs in randomized time $\\tilde{\\mathcal{O}}(1.25^d n)$. This can be\nimproved to $\\mathcal{O}(1.16^d \\cdot n)$ using computer-aided evaluations.\n  We generalize our result to the $k$-Orthogonal Vectors problem, where given\n$k$ families $A_1,\\ldots,A_k$ of subsets of $\\{1,\\ldots,d\\}$, each of size $n$,\nthe task is to find elements $a_i \\in A_i$ for every $i \\in \\{1,\\ldots,k\\}$\nsuch that $a_1 \\cap a_2 \\cap \\ldots \\cap a_k = \\emptyset$. We show that for\nevery fixed $k \\ge 2$, there exists $\\varepsilon_k > 0$ such that the $k$-OV\nproblem can be solved in time $\\mathcal{O}(2^{(1 - \\varepsilon_k)\\cdot d}\\cdot\nn)$. We also show that, asymptotically, this is the best we can hope for: for\nany $\\varepsilon > 0$ there exists a $k \\ge 2$ such that $2^{(1 -\n\\varepsilon)\\cdot d} \\cdot n^{\\mathcal{O}(1)}$ time algorithm for\n$k$-Orthogonal Vectors would contradict the Set Cover Conjecture.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ec4\u5408\u7b97\u6cd5\uff0c\u4ee5\u968f\u673a\u5316\u65f6\u95f4 $\\tilde{\\mathcal{O}}(1.25^d n)$ \u89e3\u51b3\u4e86 $k$-\u6b63\u4ea4\u5411\u91cf\u95ee\u9898\uff0c\u8be5\u7b97\u6cd5\u901a\u8fc7\u8ba1\u7b97\u673a\u8f85\u52a9\u8bc4\u4f30\u53ef\u8fdb\u4e00\u6b65\u4f18\u5316\u81f3 $\\mathcal{O}(1.16^d \\cdot n)$\u3002\u7814\u7a76\u7ed3\u679c\u5bf9\u4e8e $k \\ge 2$ \u65f6\u7684 $k$-\u6b63\u4ea4\u5411\u91cf\u95ee\u9898\u63d0\u4f9b\u4e86\u6700\u4f73\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u5e76\u4e0e\u96c6\u5408\u8986\u76d6\u731c\u60f3\u76f8\u5173\u3002", "motivation": "\u8be5\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u6b63\u4ea4\u5411\u91cf\uff08OV\uff09\u95ee\u9898\u53ca\u5176\u63a8\u5e7f\u5f62\u5f0f $k$-\u6b63\u4ea4\u5411\u91cf\u95ee\u9898\uff0c\u5e76\u5bfb\u6c42\u6bd4\u73b0\u6709\u7b97\u6cd5\u66f4\u4f18\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ec4\u5408\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u80fd\u591f\u4ee5\u968f\u673a\u5316\u65f6\u95f4 $\\tilde{\\mathcal{O}}(1.25^d n)$ \u89e3\u51b3 $k$-\u6b63\u4ea4\u5411\u91cf\u95ee\u9898\uff0c\u901a\u8fc7\u8ba1\u7b97\u673a\u8f85\u52a9\u8bc4\u4f30\u53ef\u8fdb\u4e00\u6b65\u4f18\u5316\u81f3 $\\mathcal{O}(1.16^d \\cdot n)$\u3002", "result": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ec4\u5408\u7b97\u6cd5\uff0c\u4ee5\u968f\u673a\u5316\u65f6\u95f4 $\\tilde{\\mathcal{O}}(1.25^d n)$ \u89e3\u51b3\u4e86 $k$-\u6b63\u4ea4\u5411\u91cf\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u901a\u8fc7\u8ba1\u7b97\u673a\u8f85\u52a9\u8bc4\u4f30\u53ef\u8fdb\u4e00\u6b65\u4f18\u5316\u81f3 $\\mathcal{O}(1.16^d \\cdot n)$\u3002\u5bf9\u4e8e $k \\ge 2$\uff0c\u8bc1\u660e\u4e86 $k$-\u6b63\u4ea4\u5411\u91cf\u95ee\u9898\u53ef\u4ee5\u5728 $\\mathcal{O}(2^{(1 - \\varepsilon_k)\\cdot d}\\cdot n)$ \u65f6\u95f4\u5185\u89e3\u51b3\uff0c\u5e76\u6307\u51fa\u8be5\u7ed3\u679c\u5728\u6e10\u8fd1\u610f\u4e49\u4e0a\u662f\u6700\u4f73\u7684\uff0c\u4e0e\u96c6\u5408\u8986\u76d6\u731c\u60f3\u76f8\u6096\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ec4\u5408\u7b97\u6cd5\uff0c\u80fd\u591f\u4ee5\u968f\u673a\u5316\u65f6\u95f4 $\tilde{\\mathcal{O}}(1.25^d n)$ \u89e3\u51b3 $k$-\u6b63\u4ea4\u5411\u91cf\u95ee\u9898\uff0c\u5e76\u80fd\u901a\u8fc7\u8ba1\u7b97\u673a\u8f85\u52a9\u8bc4\u4f30\u8fdb\u4e00\u6b65\u4f18\u5316\u81f3 $\\mathcal{O}(1.16^d \\cdot n)$\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5bf9\u4e8e\u6bcf\u4e2a\u56fa\u5b9a\u7684 $k \\ge 2$\uff0c\u5b58\u5728 $\\varepsilon_k > 0$\uff0c\u4f7f\u5f97 $k$-\u6b63\u4ea4\u5411\u91cf\u95ee\u9898\u53ef\u4ee5\u5728 $\\mathcal{O}(2^{(1 - \\varepsilon_k)\\cdot d}\\cdot n)$ \u65f6\u95f4\u5185\u89e3\u51b3\uff0c\u8fd9\u5728\u6e10\u8fd1\u610f\u4e49\u4e0a\u662f\u76ee\u524d\u6700\u597d\u7684\u7ed3\u679c\uff0c\u5e76\u4e0e\u96c6\u5408\u8986\u76d6\u731c\u60f3\u76f8\u6096\u3002"}}
{"id": "2507.11113", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.11113", "abs": "https://arxiv.org/abs/2507.11113", "authors": ["Yueyue Xu", "Yuewei Chen", "Lin Wang", "Zhaoyang Cheng", "Xiaoming Hu"], "title": "Optimal Honeypot Ratio and Convergent Fictitious-Play Learning in Signaling Games for CPS Defense", "comment": "14 pages, 8 figures", "summary": "Cyber-Physical Systems (CPSs) are facing a fast-growing wave of attacks. To\nachieve effective proactive defense, this paper models honeypot deployment as a\ngamma-fixed signaling game in which node liveness serves as the only signal and\nnormal-node signal gamma is exogenously fixed. We define the gamma-perfect\nBayesian-Nash equilibrium (gamma-PBNE). Analytical expressions are obtained for\nall gamma-PBNEs, revealing three distinct equilibrium regimes that depend on\nthe priori honeypot ratio. Furthermore, the optimal honeypot ratio and\nsignaling strategy that jointly maximize the network average utility are\nobtained. To capture strategic interaction over time, we develop a\ndiscrete-time fictitious-play algorithm that couples Bayesian belief updates\nwith empirical best responses. We prove that, as long as the honeypot ratio is\nperturbed within a non-degenerate neighbourhood of the optimum, every\nfictitious-play path converges to the defender-optimal gamma-PBNE. Numerical\nresults confirm the effectiveness of the proposed method and demonstrate its\napplicability to CPS defense.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u871c\u7f50\u90e8\u7f72\u5efa\u6a21\u4e3a\u4f3d\u9a6c\u56fa\u5b9a\u4fe1\u53f7\u535a\u5f08\u7684\u65b9\u6cd5\uff0c\u4ee5\u5e94\u5bf9\u7f51\u7edc\u7269\u7406\u7cfb\u7edf\uff08CPS\uff09\u65e5\u76ca\u589e\u957f\u7684\u653b\u51fb\u3002\u7814\u7a76\u4e86\u4f3d\u9a6c-\u5b8c\u7f8e\u8d1d\u53f6\u65af\u7eb3\u4ec0\u5747\u8861\uff0c\u5e76\u63a8\u5bfc\u4e86\u5176\u89e3\u6790\u8868\u8fbe\u5f0f\uff0c\u63ed\u793a\u4e86\u4e09\u79cd\u4e0d\u540c\u7684\u5747\u8861\u673a\u5236\u3002\u6b64\u5916\uff0c\u8fd8\u786e\u5b9a\u4e86\u6700\u5927\u5316\u7f51\u7edc\u5e73\u5747\u6548\u7528\u7684\u6700\u4f18\u7b56\u7565\u3002\u901a\u8fc7\u4e00\u79cd\u79bb\u6563\u65f6\u95f4\u7684\u865a\u62df\u535a\u5f08\u7b97\u6cd5\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u80fd\u591f\u6536\u655b\u5230\u6700\u4f18\u5747\u8861\u3002\u6570\u503c\u7ed3\u679c\u8bc1\u5b9e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u5728CPS\u9632\u5fa1\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u4e3a\u4e86\u5b9e\u73b0\u6709\u6548\u7684\u9884\u9632\u6027\u9632\u5fa1\uff0c\u672c\u6587\u7814\u7a76\u4e86\u7f51\u7edc\u7269\u7406\u7cfb\u7edf\uff08CPS\uff09\u9762\u4e34\u7684\u65e5\u76ca\u589e\u957f\u7684\u653b\u51fb\u95ee\u9898\u3002", "method": "\u672c\u6587\u5c06\u871c\u7f50\u90e8\u7f72\u5efa\u6a21\u4e3a\u4e00\u4e2a\u4f3d\u9a6c\u56fa\u5b9a\u4fe1\u53f7\u535a\u5f08\uff0c\u5176\u4e2d\u8282\u70b9\u6d3b\u6027\u662f\u552f\u4e00\u7684\u4fe1\u53f7\uff0c\u5e76\u4e14\u6b63\u5e38\u8282\u70b9\u7684\u4fe1\u53f7\u4f3d\u9a6c\u662f\u5916\u751f\u7684\u56fa\u5b9a\u3002\u6211\u4eec\u5b9a\u4e49\u4e86\u4f3d\u9a6c-\u5b8c\u7f8e\u8d1d\u53f6\u65af\u7eb3\u4ec0\u5747\u8861\uff08gamma-PBNE\uff09\uff0c\u5e76\u83b7\u5f97\u4e86\u6240\u6709\u4f3d\u9a6c-PBNE\u7684\u89e3\u6790\u8868\u8fbe\u5f0f\uff0c\u63ed\u793a\u4e86\u4e09\u79cd\u53d6\u51b3\u4e8e\u5148\u9a8c\u871c\u7f50\u6bd4\u4f8b\u7684\u72ec\u7279\u5747\u8861\u673a\u5236\u3002\u6b64\u5916\uff0c\u8fd8\u83b7\u5f97\u4e86\u8054\u5408\u6700\u5927\u5316\u7f51\u7edc\u5e73\u5747\u6548\u7528\u7684\u6700\u4f18\u871c\u7f50\u6bd4\u4f8b\u548c\u4fe1\u53f7\u7b56\u7565\u3002\u4e3a\u4e86\u6355\u6349\u8de8\u65f6\u95f4\u7684\u6218\u7565\u4e92\u52a8\uff0c\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u79cd\u79bb\u6563\u65f6\u95f4\u7684\u865a\u62df\u535a\u5f08\u7b97\u6cd5\uff0c\u5b83\u5c06\u8d1d\u53f6\u65af\u4fe1\u5ff5\u66f4\u65b0\u4e0e\u7ecf\u9a8c\u6700\u4f73\u54cd\u5e94\u76f8\u7ed3\u5408\u3002", "result": "\u901a\u8fc7\u6570\u503c\u7ed3\u679c\u8bc1\u5b9e\u4e86\u6240\u63d0\u8bae\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5728CPS\u9632\u5fa1\u4e2d\u7684\u9002\u7528\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u4f3d\u9a6c\u56fa\u5b9a\u4fe1\u53f7\u535a\u5f08\u7684\u6a21\u578b\u80fd\u591f\u6709\u6548\u5730\u7528\u4e8e\u7f51\u7edc\u9632\u5fa1\uff0c\u5e76\u4e14\u8be5\u7b97\u6cd5\u53ef\u4ee5\u6536\u655b\u5230\u6700\u4f18\u7684\u4f3d\u9a6c-\u5b8c\u7f8e\u8d1d\u53f6\u65af\u7eb3\u4ec0\u5747\u8861\uff0c\u4ece\u800c\u5b9e\u73b0\u4e86\u7f51\u7edc\u7684\u5e73\u5747\u6548\u7528\u6700\u5927\u5316\u3002"}}
{"id": "2507.10591", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.PF", "68T01", "I.2"], "pdf": "https://arxiv.org/pdf/2507.10591", "abs": "https://arxiv.org/abs/2507.10591", "authors": ["Vanderson Rocha", "Diego Kreutz", "Gabriel Canto", "Hendrio Bragan\u00e7a", "Eduardo Feitosa"], "title": "MH-FSF: A Unified Framework for Overcoming Benchmarking and Reproducibility Limitations in Feature Selection Evaluation", "comment": "11 pages; 4 figures; 5 tables; submitted to JBCS", "summary": "Feature selection is vital for building effective predictive models, as it\nreduces dimensionality and emphasizes key features. However, current research\noften suffers from limited benchmarking and reliance on proprietary datasets.\nThis severely hinders reproducibility and can negatively impact overall\nperformance. To address these limitations, we introduce the MH-FSF framework, a\ncomprehensive, modular, and extensible platform designed to facilitate the\nreproduction and implementation of feature selection methods. Developed through\ncollaborative research, MH-FSF provides implementations of 17 methods (11\nclassical, 6 domain-specific) and enables systematic evaluation on 10 publicly\navailable Android malware datasets. Our results reveal performance variations\nacross both balanced and imbalanced datasets, highlighting the critical need\nfor data preprocessing and selection criteria that account for these\nasymmetries. We demonstrate the importance of a unified platform for comparing\ndiverse feature selection techniques, fostering methodological consistency and\nrigor. By providing this framework, we aim to significantly broaden the\nexisting literature and pave the way for new research directions in feature\nselection, particularly within the context of Android malware detection.", "AI": {"tldr": "MH-FSF\u6846\u67b6\u901a\u8fc7\u572810\u4e2a\u516c\u5f00\u7684Android\u6076\u610f\u8f6f\u4ef6\u6570\u636e\u96c6\u4e0a\u5b9e\u73b017\u79cd\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u7814\u7a76\u5728\u57fa\u51c6\u6d4b\u8bd5\u548c\u53ef\u91cd\u590d\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5f3a\u8c03\u4e86\u6570\u636e\u9884\u5904\u7406\u548c\u5904\u7406\u6570\u636e\u96c6\u4e0d\u5bf9\u79f0\u6027\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5f53\u524d\u7814\u7a76\u5728\u57fa\u51c6\u6d4b\u8bd5\u548c\u4e13\u6709\u6570\u636e\u96c6\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u963b\u788d\u4e86\u53ef\u91cd\u590d\u6027\u5e76\u53ef\u80fd\u5f71\u54cd\u6574\u4f53\u6027\u80fd\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u6211\u4eec\u5f15\u5165\u4e86MH-FSF\u6846\u67b6\uff0c\u4ee5\u4fc3\u8fdb\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u7684\u518d\u73b0\u548c\u5b9e\u73b0\u3002", "method": "MH-FSF\u6846\u67b6\uff0c\u4e00\u4e2a\u5168\u9762\u3001\u6a21\u5757\u5316\u548c\u53ef\u6269\u5c55\u7684\u5e73\u53f0\uff0c\u5b9e\u73b0\u4e8617\u79cd\u65b9\u6cd5\uff0811\u79cd\u7ecf\u5178\u30016\u79cd\u9886\u57df\u7279\u5b9a\uff09\uff0c\u5e76\u572810\u4e2a\u516c\u5f00\u7684Android\u6076\u610f\u8f6f\u4ef6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "\u5728\u5e73\u8861\u548c\u4e0d\u5e73\u8861\u6570\u636e\u96c6\u4e0a\u90fd\u53d1\u73b0\u4e86\u6027\u80fd\u5dee\u5f02\uff0c\u51f8\u663e\u4e86\u6570\u636e\u9884\u5904\u7406\u548c\u8003\u8651\u8fd9\u4e9b\u4e0d\u5bf9\u79f0\u6027\u7684\u9009\u62e9\u6807\u51c6\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "MH-FSF\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u5e73\u53f0\uff0c\u7528\u4e8e\u6bd4\u8f83\u5404\u79cd\u7279\u5f81\u9009\u62e9\u6280\u672f\uff0c\u4fc3\u8fdb\u4e86\u65b9\u6cd5\u7684\u4e00\u81f4\u6027\u548c\u4e25\u8c28\u6027\uff0c\u6709\u671b\u62d3\u5bbd\u73b0\u6709\u6587\u732e\u5e76\u4e3a\u7279\u5f81\u9009\u62e9\u65b0\u7814\u7a76\u65b9\u5411\u94fa\u5e73\u9053\u8def\uff0c\u7279\u522b\u662f\u5728Android\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u65b9\u9762\u3002"}}
{"id": "2507.10776", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10776", "abs": "https://arxiv.org/abs/2507.10776", "authors": ["Howard H. Qian", "Yiting Chen", "Gaotian Wang", "Podshara Chanrungmaneekul", "Kaiyu Hang"], "title": "rt-RISeg: Real-Time Model-Free Robot Interactive Segmentation for Active Instance-Level Object Understanding", "comment": "8 pages, IROS 2025, Interactive Perception, Segmentation, Robotics,\n  Computer Vision", "summary": "Successful execution of dexterous robotic manipulation tasks in new\nenvironments, such as grasping, depends on the ability to proficiently segment\nunseen objects from the background and other objects. Previous works in unseen\nobject instance segmentation (UOIS) train models on large-scale datasets, which\noften leads to overfitting on static visual features. This dependency results\nin poor generalization performance when confronted with out-of-distribution\nscenarios. To address this limitation, we rethink the task of UOIS based on the\nprinciple that vision is inherently interactive and occurs over time. We\npropose a novel real-time interactive perception framework, rt-RISeg, that\ncontinuously segments unseen objects by robot interactions and analysis of a\ndesigned body frame-invariant feature (BFIF). We demonstrate that the relative\nrotational and linear velocities of randomly sampled body frames, resulting\nfrom selected robot interactions, can be used to identify objects without any\nlearned segmentation model. This fully self-contained segmentation pipeline\ngenerates and updates object segmentation masks throughout each robot\ninteraction without the need to wait for an action to finish. We showcase the\neffectiveness of our proposed interactive perception method by achieving an\naverage object segmentation accuracy rate 27.5% greater than state-of-the-art\nUOIS methods. Furthermore, although rt-RISeg is a standalone framework, we show\nthat the autonomously generated segmentation masks can be used as prompts to\nvision foundation models for significantly improved performance.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86rt-RISeg\u6846\u67b6\uff0c\u901a\u8fc7\u673a\u5668\u4eba\u4ea4\u4e92\u548c\u8eab\u4f53\u56fa\u5b9a\u4e0d\u53d8\u7279\u5f81\uff08BFIF\uff09\u6765\u5206\u5272\u672a\u89c1\u5bf9\u8c61\uff0c\u63d0\u9ad8\u4e8627.5%\u7684\u51c6\u786e\u7387\uff0c\u5e76\u4e14\u53ef\u4ee5\u4e0e\u89c6\u89c9\u57fa\u7840\u6a21\u578b\u7ed3\u5408\u4f7f\u7528\u3002", "motivation": "\u4ee5\u5f80\u7684\u672a\u89c1\u5bf9\u8c61\u5b9e\u4f8b\u5206\u5272\uff08UOIS\uff09\u65b9\u6cd5\u5728\u5927\u578b\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u6a21\u578b\uff0c\u5bb9\u6613\u5bfc\u81f4\u5728\u9759\u6001\u89c6\u89c9\u7279\u5f81\u4e0a\u8fc7\u62df\u5408\uff0c\u5728\u9762\u5bf9\u5206\u5e03\u5916\u573a\u666f\u65f6\u6cdb\u5316\u6027\u80fd\u5dee\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u57fa\u4e8e\u89c6\u89c9\u672c\u8d28\u4e0a\u662f\u4ea4\u4e92\u7684\u5e76\u4e14\u968f\u7740\u65f6\u95f4\u53d1\u751f\u7684\u539f\u7406\u91cd\u65b0\u601d\u8003\u4e86UOIS\u4efb\u52a1\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5b9e\u65f6\u4ea4\u4e92\u611f\u77e5\u6846\u67b6rt-RISeg\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u673a\u5668\u4eba\u4ea4\u4e92\u548c\u5206\u6790\u8bbe\u8ba1\u7684\u8eab\u4f53\u56fa\u5b9a\u4e0d\u53d8\u7279\u5f81\uff08BFIF\uff09\u6765\u6301\u7eed\u5206\u5272\u672a\u89c1\u8fc7\u7684\u5bf9\u8c61\uff0c\u5229\u7528\u968f\u673a\u91c7\u6837\u8eab\u4f53\u6846\u67b6\u7684\u76f8\u5bf9\u65cb\u8f6c\u548c\u7ebf\u6027\u901f\u5ea6\u6765\u8bc6\u522b\u5bf9\u8c61\uff0c\u65e0\u9700\u4efb\u4f55\u5b66\u4e60\u5230\u7684\u5206\u5272\u6a21\u578b\u3002", "result": "\u6240\u63d0\u51fa\u7684rt-RISeg\u65b9\u6cd5\u5b9e\u73b0\u4e86\u5e73\u574727.5%\u7684\u51c6\u786e\u7387\u63d0\u5347\uff0c\u5e76\u4e14\u5176\u751f\u6210\u7684\u5206\u5272\u63a9\u7801\u53ef\u4f5c\u4e3a\u63d0\u793a\u7528\u4e8e\u89c6\u89c9\u57fa\u7840\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002\u6b64\u5916\uff0crt-RISeg\u662f\u4e00\u4e2a\u72ec\u7acb\u7684\u6846\u67b6\uff0c\u4f46\u4e5f\u80fd\u591f\u4e0e\u66f4\u5e7f\u6cdb\u7684\u6a21\u578b\u7ed3\u5408\u3002", "conclusion": "\u901a\u8fc7\u4f7f\u7528\u673a\u5668\u4eba\u4ea4\u4e92\u548c\u8bbe\u8ba1\u7684\u8eab\u4f53\u56fa\u5b9a\u4e0d\u53d8\u7279\u5f81\uff08BFIF\uff09\u7684\u5206\u6790\uff0crt-RISeg\u6846\u67b6\u5728\u6bcf\u6b21\u673a\u5668\u4eba\u4ea4\u4e92\u4e2d\u751f\u6210\u548c\u66f4\u65b0\u5bf9\u8c61\u5206\u5272\u63a9\u7801\uff0c\u800c\u65e0\u9700\u7b49\u5f85\u52a8\u4f5c\u5b8c\u6210\uff0c\u5b9e\u73b0\u4e86\u5b8c\u5168\u81ea\u5305\u542b\u7684\u5206\u5272\u6d41\u7a0b\uff0c\u5e73\u5747\u5bf9\u8c61\u5206\u5272\u51c6\u786e\u7387\u6bd4\u6700\u5148\u8fdb\u7684UOIS\u65b9\u6cd5\u63d0\u9ad8\u4e8627.5%\u3002"}}
{"id": "2507.10912", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2507.10912", "abs": "https://arxiv.org/abs/2507.10912", "authors": ["Cunxi Yu"], "title": "Mapping Fusion: Improving FPGA Technology Mapping with ASIC Mapper", "comment": "7 pages. to appear at MLCAD 2025", "summary": "LUT (Look-Up Table) mapping is a critical step in FPGA logic synthesis, where\na logic network is transformed into a form that can be directly implemented\nusing the FPGA's LUTs. An FPGA LUT is a flexible digital memory structure that\ncan implement any logic function of a limited number of inputs, typically 4 to\n6 inputs, depending on the FPGA architecture. The goal of LUT mapping is to map\nthe Boolean network into LUTs, where each LUT can implement any function with a\nfixed number of inputs. In parallel to FPGA technology mapping, ASIC technology\nmapping maps the Boolean network to user-defined standard cells, which has\ntraditionally been developed separately from LUT mapping algorithms. However,\nin this work, our motivating examples demonstrate that ASIC technology mappers\ncan potentially improve the performance of LUT mappers, such that standard cell\nmapping and LUT mapping work in an incremental manner.\n  Therefore, we propose the FuseMap framework, which explores this opportunity\nto improve LUT mapping in the FPGA design flow by utilizing reinforcement\nlearning to make design-specific choices during cell selection. The\neffectiveness of FuseMap is evaluated on a wide range of benchmarks, different\ntechnology libraries, and technology mappers. The experimental results\ndemonstrate that FuseMap achieves higher mapping accuracy while reducing delay\nand area across diverse circuit designs collected from ISCAS 85/89, ITC/ISCAS\n99, VTR 8.0, and EPFL benchmarks.", "AI": {"tldr": "FuseMap\u6846\u67b6\u901a\u8fc7\u7ed3\u5408ASIC\u6280\u672f\u6620\u5c04\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u6539\u8fdb\u4e86FPGA\u7684LUT\u6620\u5c04\uff0c\u63d0\u9ad8\u4e86\u7cbe\u5ea6\u5e76\u964d\u4f4e\u4e86\u5ef6\u8fdf\u548c\u9762\u79ef\u3002", "motivation": "ASIC\u6280\u672f\u6620\u5c04\u5668\u53ef\u4ee5\u6f5c\u5728\u5730\u63d0\u9ad8LUT\u6620\u5c04\u5668\u7684\u6027\u80fd\uff0c\u4f7f\u5f97\u6807\u51c6\u5355\u5143\u6620\u5c04\u548cLUT\u6620\u5c04\u80fd\u591f\u4ee5\u589e\u91cf\u65b9\u5f0f\u534f\u540c\u5de5\u4f5c\u3002", "method": "\u63d0\u51faFuseMap\u6846\u67b6\uff0c\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u6765\u6539\u8fdbFPGA\u7684LUT\u6620\u5c04\u8fc7\u7a0b\uff0c\u5e76\u5c06\u5176\u4e0eASIC\u6280\u672f\u6620\u5c04\u76f8\u7ed3\u5408\uff0c\u5b9e\u73b0\u589e\u91cf\u5f0f\u6620\u5c04\u3002", "result": "FuseMap\u5728ISCAS 85/89\u3001ITC/ISCAS 99\u3001VTR 8.0\u548cEPFL\u57fa\u51c6\u6d4b\u8bd5\u96c6\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eFuseMap\u5728\u591a\u79cd\u7535\u8def\u8bbe\u8ba1\u4e2d\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6620\u5c04\u7cbe\u5ea6\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u5ef6\u8fdf\u548c\u9762\u79ef\u3002", "conclusion": "FuseMap\u6846\u67b6\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u5728\u5355\u5143\u9009\u62e9\u8fc7\u7a0b\u4e2d\u505a\u51fa\u9488\u5bf9\u7279\u5b9a\u8bbe\u8ba1\u7684\u9009\u62e9\uff0c\u4ee5\u6539\u8fdbFPGA\u8bbe\u8ba1\u6d41\u7a0b\u4e2d\u7684LUT\u6620\u5c04\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6620\u5c04\u7cbe\u5ea6\uff0c\u5e76\u964d\u4f4e\u4e86\u591a\u79cd\u7535\u8def\u8bbe\u8ba1\u7684\u5ef6\u8fdf\u548c\u9762\u79ef\u3002"}}
{"id": "2507.11224", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.11224", "abs": "https://arxiv.org/abs/2507.11224", "authors": ["Ali Khandan Boroujeni", "Kuranage Roche Rayan Ranasinghe", "Giuseppe Thadeu Freitas de Abreu", "Stefan K\u00f6psell", "Ghazal Bagheri", "Rafael F. Schaefer"], "title": "Fairness-Aware Secure Integrated Sensing and Communications with Fractional Programming", "comment": "Submitted to an IEEE journal", "summary": "We propose a novel secure integrated sensing and communications (ISAC) system\ndesigned to serve multiple communication users (CUs) and targets. To that end,\nwe formulate an optimization problem that maximizes the secrecy rate under\nconstraints balancing both communication and sensing requirements. To enhance\nfairness among users, an entropy-regularized fairness metric is introduced\nwithin the problem framework. We then propose a solution employing an\naccelerated quadratic transform (QT) with a non-homogeneous bound to\niteratively solve two subproblems, thereby effectively optimizing the overall\nobjective. This approach ensures robust security and fairness in resource\nallocation for ISAC systems. Finally, simulation results verify the performance\ngains in terms of average secrecy rate, average data rate, and beam gain.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.11057", "categories": ["cs.SI", "physics.soc-ph", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.11057", "abs": "https://arxiv.org/abs/2507.11057", "authors": ["Devashish Khulbe", "Stanislav Sobolevsky"], "title": "Urban delineation through the lens of commute networks: Leveraging graph embeddings to distinguish socioeconomic groups in cities", "comment": null, "summary": "Delineating areas within metropolitan regions stands as an important focus\namong urban researchers, shedding light on the urban perimeters shaped by\nevolving population dynamics. Applications to urban science are numerous, from\nfacilitating comparisons between delineated districts and administrative\ndivisions to informing policymakers of the shifting economic and labor\nlandscapes. In this study, we propose using commute networks sourced from the\ncensus for the purpose of urban delineation, by modeling them with a Graph\nNeural Network (GNN) architecture. We derive low-dimensional representations of\ngranular urban areas (nodes) using GNNs. Subsequently, nodes' embeddings are\nclustered to identify spatially cohesive communities in urban areas. Our\nexperiments across the U.S. demonstrate the effectiveness of network embeddings\nin capturing significant socioeconomic disparities between communities in\nvarious cities, particularly in factors such as median household income. The\nrole of census mobility data in regional delineation is also noted, and we\nestablish the utility of GNNs in urban community detection, as a powerful\nalternative to existing methods in this domain. The results offer insights into\nthe wider effects of commute networks and their use in building meaningful\nrepresentations of urban regions.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u5206\u6790\u901a\u52e4\u7f51\u7edc\uff0c\u4ee5\u754c\u5b9a\u57ce\u5e02\u533a\u57df\u5e76\u8bc6\u522b\u793e\u533a\uff0c\u6709\u6548\u63ed\u793a\u4e86\u793e\u4f1a\u7ecf\u6d4e\u5dee\u5f02\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u57ce\u5e02\u7814\u7a76\u4e2d\u533a\u5206\u90fd\u5e02\u533a\u5185\u90e8\u533a\u57df\u4ee5\u7406\u89e3\u7531\u4eba\u53e3\u52a8\u6001\u53d8\u5316\u7684\u57ce\u5e02\u8fb9\u754c\u7684\u91cd\u8981\u6027\uff0c\u5e76\u5e94\u7528\u4e8e\u57ce\u5e02\u79d1\u5b66\uff0c\u5982\u4fc3\u8fdb\u5df2\u5212\u5206\u533a\u57df\u4e0e\u884c\u653f\u533a\u5212\u7684\u6bd4\u8f83\uff0c\u4ee5\u53ca\u4e3a\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u53d8\u5316\u7684\u7ecf\u6d4e\u548c\u52b3\u52a8\u529b\u72b6\u51b5\u4fe1\u606f\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4f7f\u7528\u6e90\u81ea\u4eba\u53e3\u666e\u67e5\u7684\u901a\u52e4\u7f51\u7edc\uff0c\u5e76\u5229\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u67b6\u6784\u5bf9\u5176\u8fdb\u884c\u5efa\u6a21\u3002\u9996\u5148\uff0c\u4f7f\u7528GNN\u751f\u6210\u57ce\u5e02\u533a\u57df\uff08\u8282\u70b9\uff09\u7684\u4f4e\u7ef4\u8868\u793a\uff1b\u968f\u540e\uff0c\u5bf9\u8282\u70b9\u7684\u5d4c\u5165\u8fdb\u884c\u805a\u7c7b\uff0c\u4ee5\u8bc6\u522b\u57ce\u5e02\u4e2d\u7a7a\u95f4\u4e0a\u5185\u805a\u7684\u793e\u533a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u7f51\u7edc\u5d4c\u5165\u80fd\u591f\u6709\u6548\u6355\u6349\u4e0d\u540c\u57ce\u5e02\u793e\u533a\u4e4b\u95f4\u663e\u8457\u7684\u793e\u4f1a\u7ecf\u6d4e\u5dee\u5f02\uff0c\u7279\u522b\u662f\u5728\u5bb6\u5ead\u6536\u5165\u4e2d\u4f4d\u6570\u7b49\u56e0\u7d20\u4e0a\u3002\u7814\u7a76\u8fd8\u5f3a\u8c03\u4e86\u4eba\u53e3\u666e\u67e5\u6d41\u52a8\u6027\u6570\u636e\u5728\u533a\u57df\u5212\u5206\u4e2d\u7684\u4f5c\u7528\uff0c\u5e76\u786e\u7acb\u4e86GNN\u5728\u57ce\u5e02\u793e\u533a\u68c0\u6d4b\u4e2d\u7684\u6548\u7528\uff0c\u662f\u8be5\u9886\u57df\u73b0\u6709\u65b9\u6cd5\u7684\u6709\u529b\u66ff\u4ee3\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u57fa\u4e8eGNN\u7684\u901a\u52e4\u7f51\u7edc\u5206\u6790\u5728\u57ce\u5e02\u533a\u57df\u5212\u5206\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4e3a\u7406\u89e3\u57ce\u5e02\u7ed3\u6784\u548c\u793e\u4f1a\u7ecf\u6d4e\u5dee\u5f02\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2507.10811", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2507.10811", "abs": "https://arxiv.org/abs/2507.10811", "authors": ["Paul Hoffrogge", "Nils Becker", "Daniel Schneider", "Britta Nestler", "Axel Voigt", "Marco Salvalaglio"], "title": "Solid-State Dewetting of Polycrystalline Thin Films: a Phase Field Approach", "comment": "7 pages, 4 figures. Supplemental Material Included (3 pages, 1\n  figure)", "summary": "Solid-state dewetting (SSD) is the process by which thin solid films break up\nand retract on a substrate, resulting in the formation of nanostructures and\nislands. While SSD in single-crystalline films is generally understood as a\nsurface-energy-driven process mediated by surface diffusion, polycrystalline\nfilms feature additional complexity due to the presence of grain boundaries.\nTheoretical investigations and simulation frameworks have mainly focused on\nsingle-crystalline SSD. In this work, we present and apply a multi-phase-field\nframework that captures key mechanisms in polycrystalline thin films with\nmultiple grains and grain boundaries in three dimensions. By considering\nisotropic surface and interface energy and curvature-driven grain boundary\nmotion, we demonstrate how the framework reproduces the key phenomenology of\nSSD while being consistent with predictions based on energetic arguments. We\nalso introduce refined analytical criteria for the onset of dewetting,\nconfirmed by numerical simulations. Key evidence is given concerning the onset\nof dewetting at grain-boundary triple junctions. Moreover, we showcase SSD of\npolycrystalline patches. This work paves the way for in-depth investigations of\nthe morphological evolution of polycrystalline thin films.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e09\u7ef4\u591a\u76f8\u573a\u6846\u67b6\uff0c\u7528\u4e8e\u6a21\u62df\u591a\u6676\u8584\u819c\u4e2d\u7684\u56fa\u6001\u53bb\u6e7f\uff08SSD\uff09\uff0c\u8be5\u6846\u67b6\u8003\u8651\u4e86\u6676\u754c\u7684\u5f71\u54cd\uff0c\u5e76\u80fd\u91cd\u73b0SSD\u73b0\u8c61\uff0c\u89e3\u91ca\u4e86\u53bb\u6e7f\u5728\u6676\u754c\u4e09\u91cd\u7ed3\u7684\u53d1\u751f\uff0c\u5e76\u63d0\u51fa\u4e86\u53bb\u6e7f\u5f00\u59cb\u7684\u7cbe\u786e\u5224\u636e\u3002", "motivation": "\u586b\u8865\u4e86\u7406\u8bba\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u5355\u6676SSD\u800c\u5ffd\u7565\u4e86\u591a\u6676\u8584\u819c\u4e2d\u6676\u754c\u590d\u6742\u6027\u7684\u7a7a\u767d\u3002", "method": "\u5229\u7528\u4e00\u4e2a\u591a\u76f8\u573a\u6846\u67b6\uff0c\u8003\u8651\u4e86\u5404\u5411\u540c\u6027\u7684\u8868\u9762\u548c\u754c\u9762\u80fd\u4ee5\u53ca\u7531\u66f2\u7387\u9a71\u52a8\u7684\u6676\u754c\u8fd0\u52a8\uff0c\u4ee5\u6a21\u62df\u4e09\u7ef4\u591a\u6676\u8584\u819c\u4e2d\u7684SSD\u3002", "result": "\u63d0\u51fa\u5e76\u5e94\u7528\u4e86\u4e00\u4e2a\u591a\u76f8\u573a\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u91cd\u73b0\u591a\u6676\u8584\u819cSSD\u7684\u5173\u952e\u73b0\u8c61\uff0c\u5e76\u4e0e\u80fd\u91cf\u8bba\u8bc1\u4e00\u81f4\u3002\u7814\u7a76\u63d0\u4f9b\u4e86\u5173\u4e8e\u53bb\u6e7f\u5728\u6676\u754c\u4e09\u91cd\u7ed3\u5904\u5f00\u59cb\u7684\u5173\u952e\u8bc1\u636e\uff0c\u5e76\u63d0\u51fa\u4e86\u7ecf\u6570\u503c\u6a21\u62df\u8bc1\u5b9e\u7684\u53bb\u6e7f\u5f00\u59cb\u7684\u7cbe\u786e\u5206\u6790\u5224\u636e\uff0c\u540c\u65f6\u5c55\u793a\u4e86\u591a\u6676\u8584\u819c\u5757\u7684SSD\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u76f8\u573a\u6846\u67b6\uff0c\u7528\u4e8e\u6a21\u62df\u548c\u7406\u89e3\u591a\u6676\u8584\u819c\u4e2d\u7684\u56fa\u6001\u53bb\u6e7f\uff08SSD\uff09\u73b0\u8c61\u3002\u8be5\u6846\u67b6\u80fd\u591f\u91cd\u73b0SSD\u7684\u5173\u952e\u73b0\u8c61\uff0c\u5e76\u4e0e\u57fa\u4e8e\u80fd\u91cf\u8bba\u8bc1\u7684\u9884\u6d4b\u4e00\u81f4\uff0c\u540c\u65f6\u8fd8\u80fd\u89e3\u91ca\u53bb\u6e7f\u5728\u6676\u754c\u4e09\u91cd\u7ed3\u5904\u7684\u53d1\u751f\u3002\u6b64\u5916\uff0c\u8be5\u7814\u7a76\u8fd8\u63d0\u51fa\u4e86\u53bb\u6e7f\u5f00\u59cb\u7684\u7cbe\u786e\u5206\u6790\u5224\u636e\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u6a21\u62df\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u5e76\u5c55\u793a\u4e86\u591a\u6676\u8584\u819c\u5757\u7684SSD\u73b0\u8c61\u3002"}}
{"id": "2507.11167", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2507.11167", "abs": "https://arxiv.org/abs/2507.11167", "authors": ["Simon Guilloud", "Sankalp Gambhir", "Viktor Kun\u010dak"], "title": "LISA -- A Modern Proof System", "comment": null, "summary": "We present LISA, a proof system and proof assistant for constructing proofs\nin schematic first-order logic and axiomatic set theory. The logical kernel of\nthe system is a proof checker for first-order logic with equality and schematic\npredicate and function symbols. It implements polynomial-time proof checking\nand uses the axioms of ortholattices (which implies the irrelevance of the\norder of conjuncts and disjuncts and additional propositional laws). The kernel\nsupports the notion of theorems (whose proofs are not expanded), as well as\ndefinitions of predicate symbols and objects whose unique existence is proven.\nA domain-specific language enables construction of proofs and development of\nproof tactics with user-friendly tools and presentation, while remaining within\nthe general-purpose language, Scala. We describe the LISA proof system and\nillustrate the flavour and the level of abstraction of proofs written in LISA.\nThis includes a proof-generating tactic for propositional tautologies,\nleveraging the ortholattice properties to reduce the size of proofs. We also\npresent early formalization of set theory in LISA, including Cantor's theorem.", "AI": {"tldr": "LISA \u662f\u4e00\u4e2a\u7528 Scala \u7f16\u5199\u7684\u8bc1\u660e\u7cfb\u7edf\u548c\u52a9\u624b\uff0c\u7528\u4e8e\u6a21\u5f0f\u5316\u4e00\u9636\u903b\u8f91\u548c\u96c6\u5408\u8bba\u3002\u5b83\u4f7f\u7528\u591a\u9879\u5f0f\u65f6\u95f4\u8bc1\u660e\u68c0\u67e5\u548c\u659c\u683c\u516c\u7406\uff0c\u5e76\u63d0\u4f9b\u7528\u6237\u53cb\u597d\u7684\u8bc1\u660e\u6784\u5efa\u548c\u7b56\u7565\u5f00\u53d1\u8bc1\u660e\u7b56\u7565\u7684\u5de5\u5177\u3002", "motivation": "\u63d0\u51fa\u4e00\u4e2a\u7528\u4e8e\u6a21\u5f0f\u5316\u4e00\u9636\u903b\u8f91\u548c\u516c\u7406\u96c6\u5408\u8bba\u7684\u8bc1\u660e\u7cfb\u7edf\u548c\u8bc1\u660e\u52a9\u624b\uff0c\u4ee5\u63d0\u4f9b\u7528\u6237\u53cb\u597d\u7684\u5de5\u5177\u548c\u8868\u793a\u6cd5\u6765\u6784\u5efa\u8bc1\u660e\u548c\u5f00\u53d1\u8bc1\u660e\u7b56\u7565\u3002", "method": "LISA \u7cfb\u7edf\u7684\u903b\u8f91\u5185\u6838\u662f\u4e00\u4e2a\u7528\u4e8e\u6a21\u5f0f\u5316\u4e00\u9636\u903b\u8f91\uff08\u5e26\u7b49\u8bcd\u548c\u6a21\u5f0f\u8c13\u8bcd/\u51fd\u6570\u7b26\u53f7\uff09\u7684\u8bc1\u660e\u68c0\u67e5\u5668\u3002\u5b83\u5b9e\u73b0\u4e86\u591a\u9879\u5f0f\u65f6\u95f4\u8bc1\u660e\u68c0\u67e5\uff0c\u5e76\u4f7f\u7528\u659c\u683c\u516c\u7406\u3002\u5b83\u652f\u6301\u5b9a\u7406\uff08\u5176\u8bc1\u660e\u672a\u5c55\u5f00\uff09\u3001\u8c13\u8bcd\u7b26\u53f7\u5b9a\u4e49\u4ee5\u53ca\u552f\u4e00\u6027\u5df2\u8bc1\u5b9e\u7684\u5bf9\u8c61\u7684\u6982\u5ff5\u3002\u4e00\u4e2a\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u652f\u6301\u5728 Scala \u4e2d\u6784\u5efa\u8bc1\u660e\u548c\u5f00\u53d1\u8bc1\u660e\u7b56\u7565\u3002", "result": "LISA \u8bc1\u660e\u7cfb\u7edf\u5f97\u5230\u4e86\u9610\u8ff0\uff0c\u5176\u8bc1\u660e\u7684\u98ce\u683c\u548c\u62bd\u8c61\u7ea7\u522b\u5f97\u5230\u4e86\u8bf4\u660e\u3002\u5305\u62ec\u4e00\u4e2a\u5229\u7528\u659c\u683c\u6027\u8d28\u6765\u51cf\u5c0f\u8bc1\u660e\u89c4\u6a21\u7684\u547d\u9898\u91cd\u8a00\u5f0f\u751f\u6210\u7b56\u7565\u3002\u6b64\u5916\uff0c\u8fd8\u5c55\u793a\u4e86\u5728 LISA \u4e2d\u5bf9\u96c6\u5408\u8bba\uff08\u5305\u62ec\u5eb7\u6258\u5c14\u5b9a\u7406\uff09\u7684\u65e9\u671f\u5f62\u5f0f\u5316\u3002", "conclusion": "LISA\u662f\u4e00\u4e2a\u7528\u4e8e\u6a21\u5f0f\u5316\u4e00\u9636\u903b\u8f91\u548c\u516c\u7406\u96c6\u5408\u8bba\u7684\u8bc1\u660e\u7cfb\u7edf\u548c\u8bc1\u660e\u52a9\u624b\uff0c\u5176\u903b\u8f91\u5185\u6838\u5b9e\u73b0\u4e86\u591a\u9879\u5f0f\u65f6\u95f4\u8bc1\u660e\u68c0\u67e5\uff0c\u5e76\u5229\u7528\u4e86\u659c\u683c\u516c\u7406\u3002\u8be5\u7cfb\u7edf\u652f\u6301\u5b9a\u7406\u3001\u8c13\u8bcd\u7b26\u53f7\u5b9a\u4e49\u4ee5\u53ca\u552f\u4e00\u6027\u5df2\u8bc1\u5b9e\u7684\u5bf9\u8c61\u7684\u6982\u5ff5\u3002\u5b83\u63d0\u4f9b\u4e86\u4e00\u79cd\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff0c\u5141\u8bb8\u7528\u6237\u4f7f\u7528\u7528\u6237\u53cb\u597d\u7684\u5de5\u5177\u548c\u8868\u793a\u6cd5\u6765\u6784\u5efa\u8bc1\u660e\u548c\u5f00\u53d1\u8bc1\u660e\u7b56\u7565\uff0c\u540c\u65f6\u4fdd\u7559\u5728\u901a\u7528\u8bed\u8a00 Scala \u4e2d\u3002LISA \u7684\u8bc1\u660e\u98ce\u683c\u548c\u62bd\u8c61\u7ea7\u522b\u5f97\u5230\u4e86\u8bf4\u660e\uff0c\u5305\u62ec\u4e00\u4e2a\u5229\u7528\u659c\u683c\u6027\u8d28\u6765\u51cf\u5c0f\u8bc1\u660e\u89c4\u6a21\u7684\u547d\u9898\u91cd\u8a00\u5f0f\u751f\u6210\u7b56\u7565\u3002\u6b64\u5916\uff0c\u8fd8\u5c55\u793a\u4e86\u5728 LISA \u4e2d\u5bf9\u96c6\u5408\u8bba\uff08\u5305\u62ec\u5eb7\u6258\u5c14\u5b9a\u7406\uff09\u7684\u65e9\u671f\u5f62\u5f0f\u5316\u3002"}}
{"id": "2507.10687", "categories": ["cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2507.10687", "abs": "https://arxiv.org/abs/2507.10687", "authors": ["Phanibhusan S. Mahapatra", "Haining Pan", "Kenji Watanabe", "Takashi Taniguchi", "J. H. Pixley", "Eva Y. Andrei"], "title": "Quantum criticality and tunable Griffiths phase in superconducting twisted trilayer graphene", "comment": "17 pages 4 figures", "summary": "When dimensionality is reduced, enhanced quantum fluctuations can destroy\nlong-range phase coherence, driving a superconductor insulator transition, SIT,\nwhere disorder and electronic correlations give rise to novel many-body states.\nHere, we report the first observation of a magnetic field tuned SIT in\nmirrorsymmetric twisted trilayer graphene, TTG. Remarkably, signatures of\nquantum criticality persist over an exceptionally broad range of magnetic\nfields and are well described by the formation of a quantum Griffiths phase, a\nregime in which rare spatially extended regions develop local order within a\nglobally disordered phase. This leads to a quantum phase transition governed by\nan infinite-randomness fixed point and characterized by ultraslow relaxation\ndynamics. Near the quantum critical region, transport measurements reveal\nstrongly nonlinear electrical behavior, including a current-driven reentrant\ntransition from insulating to superconducting transport, providing direct\nevidence of local superconducting order. By tilting the magnetic field, we are\nable to collapse the broad Griffiths regime into a single quantum critical\npoint, QCP, demonstrating a striking level of control over disorder induced\nquantum dynamics. Our results further show that TTG strongly violates the Pauli\nlimit and establishes twisted trilayer graphene as a tunable platform for\nexploring quantum phase fluctuations, Cooper pair localization, and\nunconventional superconductivity.", "AI": {"tldr": "\u5728\u626d\u66f2\u4e09\u5c42\u77f3\u58a8\u70ef\u4e2d\u53d1\u73b0\u78c1\u573a\u53ef\u8bf1\u5bfc\u8d85\u5bfc\u4f53-\u7edd\u7f18\u4f53\u8f6c\u53d8\uff0c\u5e76\u89c2\u5bdf\u5230\u4e00\u79cd\u5728\u5bbd\u78c1\u573a\u8303\u56f4\u5185\u5b58\u5728\u7684\u91cf\u5b50\u683c\u91cc\u83f2\u65af\u76f8\uff0c\u8be5\u76f8\u53ef\u7528\u503e\u659c\u78c1\u573a\u7cbe\u786e\u63a7\u5236\uff0c\u5e76\u63ed\u793a\u4e86\u8d85\u5bfc\u914d\u5bf9\u5c40\u57df\u5316\u7b49\u65b0\u73b0\u8c61\u3002", "motivation": "\u5728\u4f4e\u7ef4\u5ea6\u7cfb\u7edf\u4e2d\uff0c\u91cf\u5b50\u6da8\u843d\u53ef\u80fd\u7834\u574f\u957f\u7a0b\u76f8\u5e72\u6027\uff0c\u5f15\u53d1\u8d85\u5bfc\u4f53-\u7edd\u7f18\u4f53\u8f6c\u53d8\uff08SIT\uff09\uff0c\u5e76\u4ea7\u751f\u65b0\u5947\u7684\u591a\u4f53\u7269\u6001\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u626d\u66f2\u4e09\u5c42\u77f3\u58a8\u70ef\uff08TTG\uff09\u5728\u78c1\u573a\u4f5c\u7528\u4e0b\u7684SIT\u884c\u4e3a\uff0c\u5e76\u63ed\u793a\u5176\u6f5c\u5728\u7684\u91cf\u5b50\u4e34\u754c\u673a\u5236\u3002", "method": "\u901a\u8fc7\u78c1\u573a\u548c\u503e\u659c\u78c1\u573a\u8c03\u63a7\u626d\u66f2\u4e09\u5c42\u77f3\u58a8\u70ef\uff08TTG\uff09\uff0c\u5e76\u8fdb\u884c\u8f93\u8fd0\u6d4b\u91cf\uff0c\u89c2\u5bdf\u548c\u5206\u6790\u8d85\u5bfc\u4f53-\u7edd\u7f18\u4f53\u8f6c\u53d8\uff08SIT\uff09\u73b0\u8c61\u53ca\u5176\u76f8\u5173\u7684\u91cf\u5b50\u4e34\u754c\u884c\u4e3a\u3002", "result": "\u5728\u626d\u66f2\u4e09\u5c42\u77f3\u58a8\u70ef\uff08TTG\uff09\u4e2d\u89c2\u5bdf\u5230\u78c1\u573a\u8c03\u5236\u7684SIT\uff0c\u5e76\u53d1\u73b0\u91cf\u5b50\u4e34\u754c\u6027\u5728\u5bbd\u5e7f\u7684\u78c1\u573a\u8303\u56f4\u5185\u8868\u73b0\u660e\u663e\uff0c\u7b26\u5408\u91cf\u5b50\u683c\u91cc\u83f2\u65af\u76f8\uff08QGP\uff09\u7684\u63cf\u8ff0\u3002\u8be5\u76f8\u8868\u73b0\u51fa\u7531\u65e0\u9650\u968f\u673a\u56fa\u5b9a\u70b9\u652f\u914d\u7684\u91cf\u5b50\u76f8\u53d8\u548c\u8d85\u6162\u5f1b\u8c6b\u52a8\u529b\u5b66\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u89c2\u5bdf\u5230\u7535\u6d41\u9a71\u52a8\u7684\u7edd\u7f18-\u8d85\u5bfc\u518dentrant\u8f6c\u53d8\uff0c\u4ee5\u53caTTG\u663e\u8457\u8fdd\u53cd\u6ce1\u5229\u6781\u9650\u7684\u73b0\u8c61\u3002", "conclusion": "\u672c\u7814\u7a76\u9996\u6b21\u5728\u626d\u66f2\u4e09\u5c42\u77f3\u58a8\u70ef\uff08TTG\uff09\u4e2d\u89c2\u5bdf\u5230\u78c1\u573a\u8c03\u5236\u7684\u8d85\u5bfc\u4f53-\u7edd\u7f18\u4f53\u8f6c\u53d8\uff08SIT\uff09\uff0c\u5e76\u63ed\u793a\u4e86\u91cf\u5b50\u4e34\u754c\u6027\u7684\u65b0\u8bc1\u636e\uff0c\u5373\u91cf\u5b50\u683c\u91cc\u83f2\u65af\u76f8\uff08QGP\uff09\u3002\u8be5\u76f8\u5728\u5bbd\u5e7f\u7684\u78c1\u573a\u8303\u56f4\u5185\u5b58\u5728\uff0c\u5e76\u53ef\u901a\u8fc7\u503e\u659c\u78c1\u573a\u7cbe\u786e\u8c03\u63a7\uff0c\u6700\u7ec8\u6307\u5411\u4e00\u4e2a\u7531\u65e0\u9650\u968f\u673a\u56fa\u5b9a\u70b9\u652f\u914d\u7684\u91cf\u5b50\u76f8\u53d8\u3002"}}
{"id": "2507.10671", "categories": ["quant-ph", "physics.atom-ph"], "pdf": "https://arxiv.org/pdf/2507.10671", "abs": "https://arxiv.org/abs/2507.10671", "authors": ["Jeremy T. Young", "Ron Belyansky", "Kang-Kuen Ni", "Alexey V. Gorshkov"], "title": "Data-insenstive cooling of polar molecules with Rydberg atoms", "comment": "5 pages, 4 figures", "summary": "We propose a method to sympathetically cool polar molecules with Rydberg\natoms without destroying the quantum information encoded in the polar\nmolecules. While the interactions between the two are usually state-dependent,\nwe show how to engineer state-insensitive interactions between the hot\nmolecules and the cold atoms with a suitable choice of internal states and the\napplication of external fields. The resulting interactions, which may be van\nder Waals or dipolar, induce a phonon swap interaction between the two species,\nthereby coherently cooling the polar molecules without affecting the internal\nstate, a process which can be repeated if the atoms are cooled again or new\ncold atoms are brought in. Our cooling schemes open the possibility of\nextending quantum computation and simulation times in emerging hybrid tweezer\narrays of polar molecules and neutral atoms.", "AI": {"tldr": "\u4e00\u79cd\u65b0\u7684\u51b7\u5374\u6280\u672f\uff0c\u5229\u7528\u91cc\u5fb7\u5821\u539f\u5b50\u51b7\u5374\u6781\u6027\u5206\u5b50\uff0c\u4fdd\u6301\u5176\u91cf\u5b50\u4fe1\u606f\uff0c\u5ef6\u957f\u91cf\u5b50\u8ba1\u7b97\u65f6\u95f4\u3002", "motivation": "\u4e3a\u4e86\u5728\u6781\u6027\u5206\u5b50\u548c\u4e2d\u6027\u539f\u5b50\u7684\u6df7\u5408\u9648\u5217\u4e2d\u6269\u5c55\u91cf\u5b50\u8ba1\u7b97\u548c\u6a21\u62df\u7684\u65f6\u95f4\u3002", "method": "\u5229\u7528\u91cc\u5fb7\u5821\u539f\u5b50\u4e0e\u6781\u6027\u5206\u5b50\u4e4b\u95f4\u7684\u8303\u5fb7\u534e\u6216\u5076\u6781\u76f8\u4e92\u4f5c\u7528\uff0c\u901a\u8fc7\u58f0\u5b50\u4ea4\u6362\u5b9e\u73b0\u76f8\u5e72\u51b7\u5374\uff0c\u5e76\u8bbe\u8ba1\u4e86\u72b6\u6001\u4e0d\u654f\u611f\u7684\u76f8\u4e92\u4f5c\u7528\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u5bf9\u6781\u6027\u5206\u5b50\u7684\u76f8\u5e72\u51b7\u5374\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5176\u5185\u90e8\u91cf\u5b50\u6001\u7684\u5b8c\u6574\u6027\uff0c\u4e3a\u6df7\u5408\u91cf\u5b50\u7cfb\u7edf\u4e2d\u91cf\u5b50\u4fe1\u606f\u7684\u6269\u5c55\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u91cc\u5fb7\u5821\u539f\u5b50\u5bf9\u6781\u6027\u5206\u5b50\u8fdb\u884c\u51b7\u5374\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u4e0d\u7834\u574f\u5206\u5b50\u4e2d\u7f16\u7801\u7684\u91cf\u5b50\u4fe1\u606f\u3002\u901a\u8fc7\u9009\u62e9\u5408\u9002\u7684\u5185\u6001\u5e76\u65bd\u52a0\u5916\u90e8\u573a\uff0c\u5b9e\u73b0\u4e86\u70ed\u5206\u5b50\u4e0e\u51b7\u539f\u5b50\u4e4b\u95f4\u7684\u72b6\u6001\u4e0d\u654f\u611f\u76f8\u4e92\u4f5c\u7528\u3002\u8fd9\u79cd\u76f8\u4e92\u4f5c\u7528\uff08\u53ef\u80fd\u662f\u8303\u5fb7\u534e\u76f8\u4e92\u4f5c\u7528\u6216\u5076\u6781\u76f8\u4e92\u4f5c\u7528\uff09\u4f1a\u5728\u4e24\u4e2a\u7269\u79cd\u4e4b\u95f4\u8bf1\u5bfc\u58f0\u5b50\u4ea4\u6362\u76f8\u4e92\u4f5c\u7528\uff0c\u4ece\u800c\u5728\u4e0d\u5f71\u54cd\u5185\u6001\u7684\u60c5\u51b5\u4e0b\u76f8\u5e72\u5730\u51b7\u5374\u6781\u6027\u5206\u5b50\u3002\u8be5\u8fc7\u7a0b\u53ef\u4ee5\u91cd\u590d\u8fdb\u884c\uff0c\u4ee5\u5b9e\u73b0\u6301\u7eed\u51b7\u5374\u3002"}}
{"id": "2507.10778", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10778", "abs": "https://arxiv.org/abs/2507.10778", "authors": ["Hsiang-Wei Huang", "Jen-Hao Cheng", "Kuang-Ming Chen", "Cheng-Yen Yang", "Bahaa Alattar", "Yi-Ru Lin", "Pyongkun Kim", "Sangwon Kim", "Kwangju Kim", "Chung-I Huang", "Jenq-Neng Hwang"], "title": "Warehouse Spatial Question Answering with LLM Agent", "comment": "1st Place Solution of the 9th AI City Challenge Track 3", "summary": "Spatial understanding has been a challenging task for existing Multi-modal\nLarge Language Models~(MLLMs). Previous methods leverage large-scale MLLM\nfinetuning to enhance MLLM's spatial understanding ability. In this paper, we\npresent a data-efficient approach. We propose a LLM agent system with strong\nand advanced spatial reasoning ability, which can be used to solve the\nchallenging spatial question answering task in complex indoor warehouse\nscenarios. Our system integrates multiple tools that allow the LLM agent to\nconduct spatial reasoning and API tools interaction to answer the given\ncomplicated spatial question. Extensive evaluations on the 2025 AI City\nChallenge Physical AI Spatial Intelligence Warehouse dataset demonstrate that\nour system achieves high accuracy and efficiency in tasks such as object\nretrieval, counting, and distance estimation. The code is available at:\nhttps://github.com/hsiangwei0903/SpatialAgent", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2aLLM\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u96c6\u6210\u591a\u79cd\u5de5\u5177\u6765\u589e\u5f3a\u5176\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\uff0c\u4ee5\u5e94\u5bf9\u590d\u6742\u7684\u7a7a\u95f4\u95ee\u7b54\u4efb\u52a1\uff0c\u5e76\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u9ad8\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709MLLM\u5728\u7a7a\u95f4\u7406\u89e3\u65b9\u9762\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u7684\u5ba4\u5185\u4ed3\u5e93\u573a\u666f\u4e2d\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u5177\u6709\u5f3a\u5927\u9ad8\u7ea7\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u7684LLM\u4ee3\u7406\u7cfb\u7edf\uff0c\u5e76\u96c6\u6210\u591a\u79cd\u5de5\u5177\uff0c\u4f7fLLM\u4ee3\u7406\u80fd\u591f\u8fdb\u884c\u7a7a\u95f4\u63a8\u7406\u548cAPI\u5de5\u5177\u4ea4\u4e92\u6765\u56de\u7b54\u590d\u6742\u7a7a\u95f4\u95ee\u9898\u3002", "result": "\u5728\u7269\u4f53\u68c0\u7d22\u3001\u8ba1\u6570\u548c\u8ddd\u79bb\u4f30\u8ba1\u7b49\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u9ad8\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u57282025 AI City Challenge Physical AI Spatial Intelligence Warehouse \u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u8bc4\u4f30\uff0c\u5728\u7269\u4f53\u68c0\u7d22\u3001\u8ba1\u6570\u548c\u8ddd\u79bb\u4f30\u8ba1\u7b49\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u51c6\u786e\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2507.10587", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10587", "abs": "https://arxiv.org/abs/2507.10587", "authors": ["Dennis Ulmer", "Alexandra Lorson", "Ivan Titov", "Christian Hardmeier"], "title": "Anthropomimetic Uncertainty: What Verbalized Uncertainty in Language Models is Missing", "comment": null, "summary": "Human users increasingly rely on natural language interactions with large\nlanguage models (LLMs) in order to receive help on a large variety of tasks and\nproblems. However, the trustworthiness and perceived legitimacy of LLMs is\nundermined by the fact that their output is frequently stated in very confident\nterms, even when its accuracy is questionable. Therefore, there is a need to\nsignal the confidence of the language model to a user in order to reap the\nbenefits of human-machine collaboration and mitigate potential harms.\nVerbalized uncertainty is the expression of confidence with linguistic means,\nan approach that integrates perfectly into language-based interfaces.\nNevertheless, most recent research in natural language processing (NLP)\noverlooks the nuances surrounding human uncertainty communication and the data\nbiases that influence machine uncertainty communication. We argue for\nanthropomimetic uncertainty, meaning that intuitive and trustworthy uncertainty\ncommunication requires a degree of linguistic authenticity and personalization\nto the user, which could be achieved by emulating human communication. We\npresent a thorough overview over the research in human uncertainty\ncommunication, survey ongoing research, and perform additional analyses to\ndemonstrate so-far overlooked biases in verbalized uncertainty. We conclude by\npointing out unique factors in human-machine communication of uncertainty and\ndeconstruct anthropomimetic uncertainty into future research directions for\nNLP.", "AI": {"tldr": "\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u8fc7\u4e8e\u81ea\u4fe1\uff0c\u4f46\u51c6\u786e\u6027\u5b58\u7591\uff0c\u5f71\u54cd\u4e86\u7528\u6237\u5bf9\u5176\u7684\u4fe1\u4efb\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u6a21\u4eff\u4eba\u7c7b\u6c9f\u901a\u65b9\u5f0f\u6765\u6539\u5584\u8bed\u8a00\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u4f20\u8fbe\uff0c\u5e76\u6307\u51fa\u4e86\u8be5\u9886\u57df\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u4e3a\u4e86\u5728\u4eba\u673a\u534f\u4f5c\u4e2d\u53d1\u6325\u8bed\u8a00\u6a21\u578b\u7684\u4f18\u52bf\u5e76\u51cf\u5c11\u6f5c\u5728\u5371\u5bb3\uff0c\u9700\u8981\u89e3\u51b3\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u8fc7\u4e8e\u81ea\u4fe1\u4f46\u51c6\u786e\u6027\u5b58\u7591\u7684\u95ee\u9898\uff0c\u5e76\u63a2\u7d22\u66f4\u53ef\u4fe1\u8d56\u7684\u4e0d\u786e\u5b9a\u6027\u4f20\u8fbe\u65b9\u5f0f\u3002", "method": "\u5bf9\u4eba\u7c7b\u4e0d\u786e\u5b9a\u6027\u6c9f\u901a\u7684\u7814\u7a76\u8fdb\u884c\u4e86\u5168\u9762\u7684\u6982\u8ff0\uff0c\u5e76\u5bf9\u73b0\u6709\u7814\u7a76\u8fdb\u884c\u4e86\u8c03\u67e5\uff0c\u540c\u65f6\u5206\u6790\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u786e\u5b9a\u6027\u4f20\u8fbe\u4e2d\u5b58\u5728\u7684\u504f\u5dee\u3002", "result": "\u76ee\u524d\u7684\u7814\u7a76\u5ffd\u89c6\u4e86\u4eba\u7c7b\u4e0d\u786e\u5b9a\u6027\u6c9f\u901a\u7684\u7ec6\u5fae\u5dee\u522b\u4ee5\u53ca\u5f71\u54cd\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u6c9f\u901a\u7684\u6570\u636e\u504f\u5dee\u3002\u63d0\u51fa\u201c\u62df\u4eba\u5316\u4e0d\u786e\u5b9a\u6027\u201d\u7684\u6982\u5ff5\uff0c\u5f3a\u8c03\u76f4\u89c2\u548c\u53ef\u4fe1\u8d56\u7684\u4e0d\u786e\u5b9a\u6027\u6c9f\u901a\u9700\u8981\u6a21\u4eff\u4eba\u7c7b\u7684\u6c9f\u901a\u65b9\u5f0f\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u7684\u72ec\u7279\u56e0\u7d20\u548c\u65b9\u5411\u3002", "conclusion": "\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u786e\u5b9a\u6027\u4f20\u8fbe\u65b9\u9762\u9700\u8981\u6a21\u4eff\u4eba\u7c7b\u7684\u6c9f\u901a\u65b9\u5f0f\uff0c\u4ee5\u5b9e\u73b0\u76f4\u89c2\u548c\u53ef\u4fe1\u8d56\u7684\u6c9f\u901a\u3002"}}
{"id": "2507.10951", "categories": ["cs.NE", "cs.AI", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2507.10951", "abs": "https://arxiv.org/abs/2507.10951", "authors": ["Siyu Yu", "Zihan Qin", "Tingshan Liu", "Beiya Xu", "R. Jacob Vogelstein", "Jason Brown", "Joshua T. Vogelstein"], "title": "Biological Processing Units: Leveraging an Insect Connectome to Pioneer Biofidelic Neural Architectures", "comment": "Accepted to AGI 2025", "summary": "The complete connectome of the Drosophila larva brain offers a unique\nopportunity to investigate whether biologically evolved circuits can support\nartificial intelligence. We convert this wiring diagram into a Biological\nProcessing Unit (BPU), a fixed recurrent network derived directly from synaptic\nconnectivity. Despite its modest size 3,000 neurons and 65,000 weights between\nthem), the unmodified BPU achieves 98% accuracy on MNIST and 58% on CIFAR-10,\nsurpassing size-matched MLPs. Scaling the BPU via structured connectome\nexpansions further improves CIFAR-10 performance, while modality-specific\nablations reveal the uneven contributions of different sensory subsystems. On\nthe ChessBench dataset, a lightweight GNN-BPU model trained on only 10,000\ngames achieves 60% move accuracy, nearly 10x better than any size transformer.\nMoreover, CNN-BPU models with ~2M parameters outperform parameter-matched\nTransformers, and with a depth-6 minimax search at inference, reach 91.7%\naccuracy, exceeding even a 9M-parameter Transformer baseline. These results\ndemonstrate the potential of biofidelic neural architectures to support complex\ncognitive tasks and motivate scaling to larger and more intelligent connectomes\nin future work.", "AI": {"tldr": "\u679c\u8747\u5927\u8111\u7684\u8fde\u63a5\u7ec4\u53ef\u4ee5\u8f6c\u5316\u4e3a\u751f\u7269\u5904\u7406\u5355\u5143\uff08BPU\uff09\uff0c\u5728MNIST\u548cCIFAR-10\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u751a\u81f3\u4f18\u4e8e\u5c3a\u5bf8\u5339\u914d\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002", "motivation": "\u63a2\u7d22\u751f\u7269\u8fdb\u5316\u7684\u7535\u8def\u662f\u5426\u80fd\u591f\u652f\u6301\u4eba\u5de5\u667a\u80fd\u3002", "method": "\u5c06\u679c\u8747\u5e7c\u866b\u5927\u8111\u7684\u5b8c\u6574\u8fde\u63a5\u7ec4\u8f6c\u6362\u4e3a\u751f\u7269\u5904\u7406\u5355\u5143\uff08BPU\uff09\uff0c\u4e00\u4e2a\u76f4\u63a5\u6e90\u4e8e\u7a81\u89e6\u8fde\u63a5\u7684\u56fa\u5b9a\u9012\u5f52\u7f51\u7edc\u3002", "result": "\u5c3d\u7ba1\u89c4\u6a21\u4e0d\u5927\uff083000\u4e2a\u795e\u7ecf\u5143\u548c65000\u4e2a\u8fde\u63a5\uff09\uff0cBPU\u5728MNIST\u4e0a\u8fbe\u5230\u4e8698%\u7684\u51c6\u786e\u7387\uff0c\u5728CIFAR-10\u4e0a\u8fbe\u5230\u4e8658%\uff0c\u4f18\u4e8e\u5c3a\u5bf8\u5339\u914d\u7684\u591a\u5c42\u611f\u77e5\u673a\uff08MLP\uff09\u3002\u901a\u8fc7\u7ed3\u6784\u5316\u8fde\u63a5\u7ec4\u6269\u5c55BPU\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63d0\u9ad8CIFAR-10\u7684\u6027\u80fd\u3002\u6a21\u578b\u5728ChessBench\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e8660%\u7684\u8d70\u6cd5\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u5c3a\u5bf8\u76f8\u5f53\u7684Transformer\u3002CNN-BPU\u6a21\u578b\u4f18\u4e8e\u53c2\u6570\u5339\u914d\u7684Transformer\uff0c\u5e76\u5728\u63a8\u7406\u65f6\u4f7f\u7528\u6df1\u5ea6-6\u6781\u5c0f\u6781\u5927\u641c\u7d22\uff0c\u8fbe\u5230\u4e8691.7%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u751f\u7269\u4fdd\u771f\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u6709\u6f5c\u529b\u652f\u6301\u590d\u6742\u7684\u8ba4\u77e5\u4efb\u52a1\uff0c\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u5c06\u5176\u6269\u5c55\u5230\u66f4\u5927\u3001\u66f4\u667a\u80fd\u7684\u8fde\u63a5\u7ec4\u3002"}}
{"id": "2507.11289", "categories": ["cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2507.11289", "abs": "https://arxiv.org/abs/2507.11289", "authors": ["Martin Rose", "Simon Homes", "Lukas Ramsperger", "Jose Gracia", "Christoph Niethammer", "Jadran Vrabec"], "title": "Cyclic Data Streaming on GPUs for Short Range Stencils Applied to Molecular Dynamics", "comment": "Accepted for publication at HeteroPar 2025 co-located with Euro-Par\n  2025", "summary": "In the quest for highest performance in scientific computing, we present a\nnovel framework that relies on high-bandwidth communication between GPUs in a\ncompute cluster. The framework offers linear scaling of performance for\nexplicit algorithms that is only limited by the size of the dataset and the\nnumber of GPUs. Slices of the dataset propagate in a ring of processes (GPUs)\nfrom one GPU, where they are processed, to the next, which results in a\nparallel-in-time parallelization. The user of the framework has to write GPU\nkernels that implement the algorithm and provide slices of the dataset.\nKnowledge about the underlying parallelization strategy is not required because\nthe communication between processes is carried out by the framework. As a case\nstudy, molecular dynamics simulation based on the Lennard-Jones potential is\nimplemented to measure the performance for a homogeneous fluid. Single node\nperformance and strong scaling behavior of this framework is compared to\nLAMMPS, which is outperformed in the strong scaling case.", "AI": {"tldr": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u521b\u65b0\u7684 GPU \u901a\u4fe1\u6846\u67b6\uff0c\u5728\u79d1\u5b66\u8ba1\u7b97\u4e2d\u5b9e\u73b0\u7ebf\u6027\u6027\u80fd\u6269\u5c55\uff0c\u5e76\u4f18\u4e8e LAMMPS\u3002", "motivation": "\u4e3a\u4e86\u5728\u79d1\u5b66\u8ba1\u7b97\u4e2d\u83b7\u5f97\u6700\u9ad8\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f9d\u8d56\u4e8e\u8ba1\u7b97\u96c6\u7fa4\u4e2d GPU \u4e4b\u95f4\u9ad8\u5e26\u5bbd\u901a\u4fe1\u7684\u65b0\u9896\u6846\u67b6\u3002\u6570\u636e\u96c6\u7684\u5207\u7247\u5728\u8fdb\u7a0b\uff08GPU\uff09\u7684\u73af\u4e2d\u4f20\u64ad\uff0c\u4ece\u4e00\u4e2a GPU \u4f20\u64ad\u5230\u4e0b\u4e00\u4e2a GPU\uff0c\u5b9e\u73b0\u4e86\u65f6\u5e8f\u5e76\u884c\u5316\u3002", "result": "\u8be5\u6846\u67b6\u4e3a\u663e\u5f0f\u7b97\u6cd5\u63d0\u4f9b\u4e86\u7ebf\u6027\u7684\u6027\u80fd\u6269\u5c55\uff0c\u8be5\u6027\u80fd\u6269\u5c55\u4ec5\u53d7\u6570\u636e\u96c6\u5927\u5c0f\u548c GPU \u6570\u91cf\u7684\u9650\u5236\u3002\u4f5c\u4e3a\u6848\u4f8b\u7814\u7a76\uff0c\u5b9e\u73b0\u4e86\u57fa\u4e8e Lennard-Jones \u52bf\u7684\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\uff0c\u4ee5\u6d4b\u91cf\u5747\u8d28\u6d41\u4f53\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u5f3a\u6269\u5c55\u60c5\u51b5\u4e0b\u4f18\u4e8e LAMMPS\u3002"}}
{"id": "2507.11464", "categories": ["cs.RO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.11464", "abs": "https://arxiv.org/abs/2507.11464", "authors": ["Ajay Shankar", "Keisuke Okumura", "Amanda Prorok"], "title": "LF: Online Multi-Robot Path Planning Meets Optimal Trajectory Control", "comment": "9 pages; under review for IEEE Robotics & Automation - Letters (RA-L)", "summary": "We propose a multi-robot control paradigm to solve point-to-point navigation\ntasks for a team of holonomic robots with access to the full environment\ninformation. The framework invokes two processes asynchronously at high\nfrequency: (i) a centralized, discrete, and full-horizon planner for computing\ncollision- and deadlock-free paths rapidly, leveraging recent advances in\nmulti-agent pathfinding (MAPF), and (ii) dynamics-aware, robot-wise optimal\ntrajectory controllers that ensure all robots independently follow their\nassigned paths reliably. This hierarchical shift in planning representation\nfrom (i) discrete and coupled to (ii) continuous and decoupled domains enables\nthe framework to maintain long-term scalable motion synthesis. As an\ninstantiation of this idea, we present LF, which combines a fast\nstate-of-the-art MAPF solver (LaCAM), and a robust feedback control stack\n(Freyja) for executing agile robot maneuvers. LF provides a robust and\nversatile mechanism for lifelong multi-robot navigation even under asynchronous\nand partial goal updates, and adapts to dynamic workspaces simply by quick\nreplanning. We present various multirotor and ground robot demonstrations,\nincluding the deployment of 15 real multirotors with random, consecutive target\nupdates while a person walks through the operational workspace.", "AI": {"tldr": "A new multi-robot navigation system uses a two-part approach: a fast central planner for paths and independent controllers for movement, allowing many robots to navigate complex spaces reliably.", "motivation": "To develop a multi-robot control paradigm for point-to-point navigation tasks for holonomic robots, ensuring scalability and reliability even with dynamic environments and goal updates.", "method": "A hierarchical approach is used, with a centralized discrete planner for collision-free paths and decentralized trajectory controllers for reliable execution. This shifts from coupled discrete planning to decoupled continuous control.", "result": "Demonstrations with up to 15 real multirotors and ground robots showed robust and versatile lifelong navigation, handling random and consecutive target updates while a person moved through the workspace.", "conclusion": "The proposed hierarchical framework enables scalable and reliable lifelong multi-robot navigation, adapting to dynamic environments and asynchronous goal updates."}}
{"id": "2507.11107", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2507.11107", "abs": "https://arxiv.org/abs/2507.11107", "authors": ["Yimin Hao", "Yi Zhou", "Chao Xu", "Zhang-Hua Fu"], "title": "Efficient Branch-and-Bound for Submodular Function Maximization under Knapsack Constraint", "comment": "Accepted to ECAI 2025", "summary": "The submodular knapsack problem (SKP), which seeks to maximize a submodular\nset function by selecting a subset of elements within a given budget, is an\nimportant discrete optimization problem. The majority of existing approaches to\nsolving the SKP are approximation algorithms. However, in domains such as\nhealth-care facility location and risk management, the need for optimal\nsolutions is still critical, necessitating the use of exact algorithms over\napproximation methods. In this paper, we present an optimal branch-and-bound\napproach, featuring a novel upper bound with a worst-case tightness guarantee\nand an efficient dual branching method to minimize repeat computations.\nExperiments in applications such as facility location, weighted coverage,\ninfluence maximization, and so on show that the algorithms that implement the\nnew ideas are far more efficient than conventional methods.", "AI": {"tldr": "\u9488\u5bf9\u6b21\u6a21\u80cc\u5305\u95ee\u9898\uff08SKP\uff09\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6700\u4f18\u5206\u652f\u5b9a\u754c\u7b97\u6cd5\uff0c\u5728\u4fdd\u8bc1\u89e3\u6700\u4f18\u6027\u7684\u540c\u65f6\uff0c\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u6b21\u6a21\u80cc\u5305\u95ee\u9898\uff08SKP\uff09\u7684\u4f18\u5316\u89e3\u95ee\u9898\uff0c\u8be5\u95ee\u9898\u5728\u533b\u7597\u4fdd\u5065\u8bbe\u65bd\u9009\u5740\u548c\u98ce\u9669\u7ba1\u7406\u7b49\u9886\u57df\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u4f7f\u7528\u7cbe\u786e\u7b97\u6cd5\u800c\u975e\u8fd1\u4f3c\u7b97\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6700\u4f18\u5206\u652f\u5b9a\u754c\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u4e86\u5177\u6709\u6700\u5dee\u60c5\u51b5\u4e25\u683c\u6027\u4fdd\u8bc1\u7684\u65b0\u578b\u4e0a\u754c\u548c\u4e00\u79cd\u6709\u6548\u7684\u5bf9\u5076\u5206\u652f\u65b9\u6cd5\u4ee5\u51cf\u5c11\u91cd\u590d\u8ba1\u7b97\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u91c7\u7528\u8be5\u65b0\u65b9\u6cd5\u7684\u7b97\u6cd5\u6548\u7387\u8fdc\u9ad8\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u5206\u652f\u5b9a\u754c\u65b9\u6cd5\u5728\u8bbe\u65bd\u9009\u5740\u3001\u52a0\u6743\u8986\u76d6\u3001\u5f71\u54cd\u529b\u6700\u5927\u5316\u7b49\u5e94\u7528\u4e2d\uff0c\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u6709\u6548\u3002"}}
{"id": "2507.11240", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.11240", "abs": "https://arxiv.org/abs/2507.11240", "authors": ["Mohamad Al Ahdab", "John Leth", "Zheng-Hua Tan"], "title": "Optimal Sensor Scheduling and Selection for Continuous-Discrete Kalman Filtering with Auxiliary Dynamics", "comment": "Accepted to ICML 2025", "summary": "We study the Continuous-Discrete Kalman Filter (CD-KF) for State-Space Models\n(SSMs) where continuous-time dynamics are observed via multiple sensors with\ndiscrete, irregularly timed measurements. Our focus extends to scenarios in\nwhich the measurement process is coupled with the states of an auxiliary SSM.\nFor instance, higher measurement rates may increase energy consumption or heat\ngeneration, while a sensor's accuracy can depend on its own spatial trajectory\nor that of the measured target. Each sensor thus carries distinct costs and\nconstraints associated with its measurement rate and additional constraints and\ncosts on the auxiliary state. We model measurement occurrences as independent\nPoisson processes with sensor-specific rates and derive an upper bound on the\nmean posterior covariance matrix of the CD-KF along the mean auxiliary state.\nThe bound is continuously differentiable with respect to the measurement rates,\nwhich enables efficient gradient-based optimization. Exploiting this bound, we\npropose a finite-horizon optimal control framework to optimize measurement\nrates and auxiliary-state dynamics jointly. We further introduce a\ndeterministic method for scheduling measurement times from the optimized rates.\nEmpirical results in state-space filtering and dynamic temporal Gaussian\nprocess regression demonstrate that our approach achieves improved trade-offs\nbetween resource usage and estimation accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f18\u5316CD-KF\u6d4b\u91cf\u901f\u7387\u548c\u8f85\u52a9\u72b6\u6001\u52a8\u529b\u5b66\u7684\u65b9\u6cd5\uff0c\u4ee5\u5728\u8d44\u6e90\u6d88\u8017\u548c\u4f30\u8ba1\u51c6\u786e\u6027\u4e4b\u95f4\u53d6\u5f97\u66f4\u597d\u7684\u5e73\u8861\u3002", "motivation": "\u672c\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff08SSM\uff09\u4e2d\u8fde\u7eed\u79bb\u6563\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\uff08CD-KF\uff09\u5728\u5904\u7406\u7531\u591a\u4e2a\u4f20\u611f\u5668\u901a\u8fc7\u79bb\u6563\u3001\u4e0d\u89c4\u5219\u8ba1\u65f6\u7684\u6d4b\u91cf\u8fdb\u884c\u89c2\u5bdf\u7684\u8fde\u7eed\u65f6\u95f4\u52a8\u529b\u5b66\u65f6\u7684\u6548\u7387\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u6d4b\u91cf\u8fc7\u7a0b\u4e0e\u8f85\u52a9SSM\u7684\u72b6\u6001\u8026\u5408\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u6d4b\u91cf\u901f\u7387\u4e0e\u80fd\u6e90\u6d88\u8017\u6216\u6563\u70ed\u76f8\u5173\uff0c\u6216\u4f20\u611f\u5668\u7684\u7cbe\u5ea6\u53d6\u51b3\u4e8e\u5176\u81ea\u8eab\u6216\u76ee\u6807\u7684\u7a7a\u95f4\u8f68\u8ff9\u3002", "method": "\u6211\u4eec\u63a8\u5bfc\u4e86CD-KF\u7684\u5747\u503c\u540e\u9a8c\u534f\u65b9\u5dee\u77e9\u9635\u7684\u5747\u503c\u4e0a\u754c\uff0c\u8be5\u4e0a\u754c\u76f8\u5bf9\u4e8e\u6d4b\u91cf\u901f\u7387\u662f\u8fde\u7eed\u53ef\u5fae\u7684\uff0c\u5e76\u5229\u7528\u8be5\u4e0a\u754c\u63d0\u51fa\u4e86\u4e00\u4e2a\u6709\u9650\u65f6\u95f4\u6700\u4f18\u63a7\u5236\u6846\u67b6\uff0c\u4ee5\u8054\u5408\u4f18\u5316\u6d4b\u91cf\u901f\u7387\u548c\u8f85\u52a9\u72b6\u6001\u52a8\u529b\u5b66\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u5f15\u5165\u4e86\u4e00\u79cd\u786e\u5b9a\u6027\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u4f18\u5316\u901f\u7387\u8c03\u5ea6\u6d4b\u91cf\u65f6\u95f4\u3002", "result": "\u5728\u72b6\u6001\u7a7a\u95f4\u6ee4\u6ce2\u548c\u52a8\u6001\u65f6\u95f4\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u7684\u5b9e\u8bc1\u7ed3\u679c\u4e2d\uff0c\u8bc1\u660e\u4e86\u6211\u4eec\u7684\u65b9\u6cd5\u5728\u8d44\u6e90\u4f7f\u7528\u548c\u4f30\u8ba1\u51c6\u786e\u6027\u4e4b\u95f4\u5b9e\u73b0\u4e86\u6539\u8fdb\u7684\u6743\u8861\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4f18\u5316\u6846\u67b6\u5728\u72b6\u6001\u7a7a\u95f4\u6ee4\u6ce2\u548c\u52a8\u6001\u65f6\u95f4\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u7684\u5b9e\u8bc1\u7ed3\u679c\u4e2d\uff0c\u5b9e\u73b0\u4e86\u8d44\u6e90\u4f7f\u7528\u4e0e\u4f30\u8ba1\u51c6\u786e\u6027\u4e4b\u95f4\u6539\u8fdb\u7684\u6743\u8861\u3002"}}
{"id": "2507.10594", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10594", "abs": "https://arxiv.org/abs/2507.10594", "authors": ["Shengda Zhuo", "Di Wu", "Yi He", "Shuqiang Huang", "Xindong Wu"], "title": "Extension OL-MDISF: Online Learning from Mix-Typed, Drifted, and Incomplete Streaming Features", "comment": null, "summary": "Online learning, where feature spaces can change over time, offers a flexible\nlearning paradigm that has attracted considerable attention. However, it still\nfaces three significant challenges. First, the heterogeneity of real-world data\nstreams with mixed feature types presents challenges for traditional parametric\nmodeling. Second, data stream distributions can shift over time, causing an\nabrupt and substantial decline in model performance. Third, it is often\ninfeasible to label every data instance due to time and cost constraints. To\naddress these issues, we proposed OL-MDISF (Online Learning from Mix-typed,\nDrifted, and Incomplete Streaming Features), which constructs a latent\ncopula-based representation for heterogeneous features, detects drifts via\nensemble entropy and latent mismatch, and performs structure-aware\npseudo-labeling.\n  This companion paper serves as a standalone technical reference to OL-MDISF.\nIt provides a contextual discussion of related work in mixed-type modeling,\ndrift adaptation, and weak supervision, as well as a comprehensive set of\nexperiments across 14 real-world datasets under two types of drift scenarios.\nThese include CER trends, ablation studies, sensitivity analyses, and temporal\nensemble dynamics. We hope this document offers a reproducible benchmark for\nonline learning on complex, weakly supervised streaming data.", "AI": {"tldr": "This paper introduces OL-MDISF, a novel framework for online learning that tackles heterogeneous, drifting, and incompletely labeled data streams using copula-based representations, ensemble entropy for drift detection, and pseudo-labeling. It offers a reproducible benchmark for complex online learning scenarios.", "motivation": "The paper addresses three significant challenges in online learning: data heterogeneity with mixed feature types, performance decline due to data stream distribution shifts (drifts), and the infeasibility of labeling every data instance due to time and cost constraints.", "method": "The proposed OL-MDISF (Online Learning from Mix-typed, Drifted, and Incomplete Streaming Features) framework utilizes a latent copula-based representation for heterogeneous features, employs ensemble entropy and latent mismatch for drift detection, and incorporates structure-aware pseudo-labeling to handle data stream challenges.", "result": "This companion paper serves as a technical reference for OL-MDISF, including a discussion of related work and a comprehensive set of experiments on 14 real-world datasets under two drift scenarios, featuring CER trends, ablation studies, sensitivity analyses, and temporal ensemble dynamics.", "conclusion": "The paper provides a reproducible benchmark for online learning on complex, weakly supervised streaming data, detailing the OL-MDISF framework which addresses data heterogeneity, distribution shifts, and labeling constraints through latent copula-based representation, ensemble entropy and latent mismatch for drift detection, and structure-aware pseudo-labeling."}}
{"id": "2507.10814", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.10814", "abs": "https://arxiv.org/abs/2507.10814", "authors": ["Huiyi Wang", "Fahim Shahriar", "Alireza Azimi", "Gautham Vasan", "Rupam Mahmood", "Colin Bellinger"], "title": "Versatile and Generalizable Manipulation via Goal-Conditioned Reinforcement Learning with Grounded Object Detection", "comment": "8 pages, 4 figures, 3 tables", "summary": "General-purpose robotic manipulation, including reach and grasp, is essential\nfor deployment into households and workspaces involving diverse and evolving\ntasks. Recent advances propose using large pre-trained models, such as Large\nLanguage Models and object detectors, to boost robotic perception in\nreinforcement learning. These models, trained on large datasets via\nself-supervised learning, can process text prompts and identify diverse objects\nin scenes, an invaluable skill in RL where learning object interaction is\nresource-intensive. This study demonstrates how to integrate such models into\nGoal-Conditioned Reinforcement Learning to enable general and versatile robotic\nreach and grasp capabilities. We use a pre-trained object detection model to\nenable the agent to identify the object from a text prompt and generate a mask\nfor goal conditioning. Mask-based goal conditioning provides object-agnostic\ncues, improving feature sharing and generalization. The effectiveness of the\nproposed framework is demonstrated in a simulated reach-and-grasp task, where\nthe mask-based goal conditioning consistently maintains a $\\sim$90\\% success\nrate in grasping both in and out-of-distribution objects, while also ensuring\nfaster convergence to higher returns.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u9884\u8bad\u7ec3\u7684\u7269\u4f53\u68c0\u6d4b\u6a21\u578b\u96c6\u6210\u5230\u76ee\u6807\u6761\u4ef6\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u65b9\u6cd5\uff0c\u4ee5\u5b9e\u73b0\u66f4\u901a\u7528\u3001\u66f4\u9ad8\u6548\u7684\u673a\u5668\u4eba\u6293\u53d6\u3002", "motivation": "\u901a\u7528\u673a\u5668\u4eba\u64cd\u4f5c\u5bf9\u4e8e\u5728\u6d89\u53ca\u591a\u6837\u5316\u548c\u4e0d\u65ad\u53d8\u5316\u7684\u5bb6\u5ead\u548c\u5de5\u4f5c\u573a\u6240\u4e2d\u7684\u90e8\u7f72\u81f3\u5173\u91cd\u8981\uff0c\u800c\u5229\u7528\u5927\u578b\u9884\u8bad\u7ec3\u6a21\u578b\uff08\u5982\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u7269\u4f53\u68c0\u6d4b\u5668\uff09\u53ef\u4ee5\u63d0\u9ad8\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u673a\u5668\u4eba\u611f\u77e5\u80fd\u529b\u3002", "method": "\u5c06\u9884\u8bad\u7ec3\u7684\u7269\u4f53\u68c0\u6d4b\u6a21\u578b\u7528\u4e8e\u76ee\u6807\u6761\u4ef6\u5f3a\u5316\u5b66\u4e60\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8e\u63a9\u7801\u7684\u76ee\u6807\u6761\u4ef6\u5316\u63d0\u4f9b\u5bf9\u8c61\u4e0d\u53ef\u77e5\u7ebf\u7d22\uff0c\u4ee5\u6539\u8fdb\u7279\u5f81\u5171\u4eab\u548c\u6cdb\u5316\u3002", "result": "\u5728\u6a21\u62df\u7684\u6293\u53d6\u4efb\u52a1\u4e2d\uff0c\u57fa\u4e8e\u63a9\u7801\u7684\u76ee\u6807\u6761\u4ef6\u5316\u5728\u6293\u53d6\u5206\u5e03\u5185\u548c\u5206\u5e03\u5916\u7684\u7269\u4f53\u65f6\u5747\u4fdd\u6301\u7ea6 90% \u7684\u6210\u529f\u7387\uff0c\u5e76\u786e\u4fdd\u4e86\u66f4\u5feb\u7684\u6536\u655b\u5230\u66f4\u9ad8\u7684\u56de\u62a5\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5730\u5c06\u9884\u8bad\u7ec3\u7684\u7269\u4f53\u68c0\u6d4b\u6a21\u578b\u96c6\u6210\u5230\u76ee\u6807\u6761\u4ef6\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u5b9e\u73b0\u4e86\u901a\u7528\u4e14\u591a\u529f\u80fd\u7684\u673a\u5668\u4eba\u6293\u53d6\u80fd\u529b\u3002"}}
{"id": "2507.10971", "categories": ["cs.AR", "cs.CR"], "pdf": "https://arxiv.org/pdf/2507.10971", "abs": "https://arxiv.org/abs/2507.10971", "authors": ["Kshitij Raj", "Atri Chatterjee", "Patanjali SLPSK", "Swarup Bhunia", "Sandip Ray"], "title": "Security Enclave Architecture for Heterogeneous Security Primitives for Supply-Chain Attacks", "comment": null, "summary": "Designing secure architectures for system-on-chip (SoC) platforms is a highly\nintricate and time-intensive task, often requiring months of development and\nmeticulous verification. Even minor architectural oversights can lead to\ncritical vulnerabilities that undermine the security of the entire chip. In\nresponse to this challenge, we introduce CITADEL, a modular security framework\naimed at streamlining the creation of robust security architectures for SoCs.\nCITADEL offers a configurable, plug-and-play subsystem composed of custom\nintellectual property (IP) blocks, enabling the construction of diverse\nsecurity mechanisms tailored to specific threats. As a concrete demonstration,\nwe instantiate CITADEL to defend against supply-chain threats, illustrating how\nthe framework adapts to one of the most pressing concerns in hardware security.\nThis paper explores the range of obstacles encountered when building a unified\nsecurity architecture capable of addressing multiple attack vectors and\npresents CITADEL's strategies for overcoming them. Through several real-world\ncase studies, we showcase the practical implementation of CITADEL and present a\nthorough evaluation of its impact on silicon area and power consumption across\nvarious ASIC technologies. Results indicate that CITADEL introduces only\nminimal resource overhead, making it a practical solution for enhancing SoC\nsecurity.", "AI": {"tldr": "CITADEL \u662f\u4e00\u4e2a\u521b\u65b0\u7684\u6a21\u5757\u5316\u5b89\u5168\u6846\u67b6\uff0c\u7528\u4e8e\u7b80\u5316\u7247\u4e0a\u7cfb\u7edf (SoC) \u7684\u5b89\u5168\u67b6\u6784\u8bbe\u8ba1\u3002\u8be5\u6846\u67b6\u5177\u6709\u9ad8\u5ea6\u53ef\u914d\u7f6e\u6027\u548c\u5373\u63d2\u5373\u7528\u529f\u80fd\uff0c\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u5404\u79cd\u5b89\u5168\u5a01\u80c1\uff0c\u5982\u4f9b\u5e94\u94fe\u653b\u51fb\u3002\u901a\u8fc7\u5b9e\u9645\u6848\u4f8b\u7814\u7a76\uff0cCITADEL \u88ab\u8bc1\u660e\u5728\u4e0d\u663e\u8457\u589e\u52a0\u786c\u4ef6\u6210\u672c\u7684\u60c5\u51b5\u4e0b\uff0c\u80fd\u591f\u663e\u8457\u589e\u5f3a SoC \u7684\u5b89\u5168\u6027\u3002", "motivation": "\u4e3a\u5e94\u5bf9\u7247\u4e0a\u7cfb\u7edf (SoC) \u5b89\u5168\u67b6\u6784\u8bbe\u8ba1\u8017\u65f6\u4e14\u5bb9\u6613\u51fa\u73b0\u5b89\u5168\u6f0f\u6d1e\u7684\u6311\u6218\uff0c\u63d0\u51fa CITADEL \u6846\u67b6\u4ee5\u7b80\u5316\u8bbe\u8ba1\u6d41\u7a0b\u5e76\u63d0\u9ad8\u5b89\u5168\u6027\u3002", "method": "CITADEL \u662f\u4e00\u4e2a\u6a21\u5757\u5316\u7684\u5b89\u5168\u6846\u67b6\uff0c\u901a\u8fc7\u7ec4\u5408\u81ea\u5b9a\u4e49\u77e5\u8bc6\u4ea7\u6743 (IP) \u6a21\u5757\u6765\u6784\u5efa\u5b89\u5168\u5b50\u7cfb\u7edf\uff0c\u5b9e\u73b0\u53ef\u914d\u7f6e\u3001\u5373\u63d2\u5373\u7528\u7684\u529f\u80fd\u3002", "result": "CITADEL \u5728\u5e94\u5bf9\u4f9b\u5e94\u94fe\u5a01\u80c1\u65b9\u9762\u8fdb\u884c\u4e86\u5b9e\u4f8b\u5316\u6f14\u793a\uff0c\u5e76\u4e14\u5728\u591a\u79cd ASIC \u6280\u672f\u4e2d\u8fdb\u884c\u4e86\u5b9e\u9645\u6848\u4f8b\u7814\u7a76\u548c\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u5176\u5bf9\u7845\u9762\u79ef\u548c\u529f\u8017\u7684\u5f71\u54cd\u6781\u5c0f\u3002", "conclusion": "CITADEL \u662f\u4e00\u4e2a\u6a21\u5757\u5316\u7684\u5b89\u5168\u6846\u67b6\uff0c\u53ef\u4ee5\u7b80\u5316\u7247\u4e0a\u7cfb\u7edf (SoC) \u7684\u5b89\u5168\u67b6\u6784\u8bbe\u8ba1\uff0c\u5177\u6709\u53ef\u914d\u7f6e\u3001\u5373\u63d2\u5373\u7528\u7b49\u7279\u70b9\uff0c\u80fd\u591f\u9488\u5bf9\u7279\u5b9a\u5a01\u80c1\u5b9a\u5236\u5b89\u5168\u673a\u5236\u3002\u8be5\u6846\u67b6\u5728\u5e94\u5bf9\u4f9b\u5e94\u94fe\u5a01\u80c1\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u80fd\u514b\u670d\u6784\u5efa\u7edf\u4e00\u5b89\u5168\u67b6\u6784\u4ee5\u5e94\u5bf9\u591a\u79cd\u653b\u51fb\u5411\u91cf\u7684\u6311\u6218\u3002\u5b9e\u9645\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0cCITADEL \u5728\u7845\u9762\u79ef\u548c\u529f\u8017\u65b9\u9762\u53ea\u6709\u5fae\u5c0f\u7684\u5f00\u9500\uff0c\u662f\u589e\u5f3a SoC \u5b89\u5168\u6027\u7684\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.11249", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.11249", "abs": "https://arxiv.org/abs/2507.11249", "authors": ["Ruohai Guo", "Jiang Zhu", "Xing Jiang", "Fengzhong Qu"], "title": "Fast and Efficient Implementation of the Maximum Likelihood Estimation for the Linear Regression with Gaussian Model Uncertainty", "comment": null, "summary": "The linear regression model with a random variable (RV) measurement matrix,\nwhere the mean of the random measurement matrix has full column rank, has been\nextensively studied. In particular, the quasiconvexity of the maximum\nlikelihood estimation (MLE) problem was established, and the corresponding\nCramer-Rao bound (CRB) was derived, leading to the development of an efficient\nbisection-based algorithm known as RV-ML. In contrast, this work extends the\nanalysis to both overdetermined and underdetermined cases, allowing the mean of\nthe random measurement matrix to be rank-deficient. A remarkable contribution\nis the proof that the equivalent MLE problem is convex and satisfies strong\nduality, strengthening previous quasiconvexity results. Moreover, it is shown\nthat in underdetermined scenarios, the randomness in the measurement matrix can\nbe beneficial for estimation under certain conditions. In addition, a fast and\nunified implementation of the MLE solution, referred to as generalized RV-ML\n(GRV-ML), is proposed, which handles a more general case including both\nunderdetermined and overdetermined systems. Extensive numerical simulations are\nprovided to validate the theoretical findings.", "AI": {"tldr": "\u672c\u7814\u7a76\u6269\u5c55\u4e86\u968f\u673a\u6d4b\u91cf\u77e9\u9635\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u7684\u5206\u6790\uff0c\u5141\u8bb8\u5176\u5747\u503c\u79e9\u4e8f\u7f3a\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u7edf\u4e00\u7b97\u6cd5GRV-ML\uff0c\u8bc1\u660e\u4e86\u5176\u51f8\u6027\u548c\u5f3a\u5bf9\u5076\u6027\u3002", "motivation": "\u6269\u5c55\u4e86\u968f\u673a\u53d8\u91cf\uff08RV\uff09\u6d4b\u91cf\u77e9\u9635\u7684\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u5206\u6790\uff0c\u5141\u8bb8\u6d4b\u91cf\u77e9\u9635\u5747\u503c\u79e9\u4e8f\u7f3a\uff0c\u4ee5\u89e3\u51b3\u8fc7\u5b9a\u548c\u4e0d\u5b9a\u60c5\u51b5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u5e7f\u4e49RV-ML\uff08GRV-ML\uff09\u7684\u5feb\u901f\u7edf\u4e00\u5b9e\u73b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5904\u7406\u66f4\u4e00\u822c\u7684\u8fc7\u5b9a\u548c\u4e0d\u5b9a\u7cfb\u7edf\uff0c\u5305\u62ec\u6d4b\u91cf\u77e9\u9635\u5747\u503c\u79e9\u4e8f\u7f3a\u7684\u60c5\u51b5\u3002", "result": "\u8bc1\u660e\u4e86\u7b49\u6548\u7684\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\uff08MLE\uff09\u95ee\u9898\u662f\u51f8\u7684\u5e76\u6ee1\u8db3\u5f3a\u5bf9\u5076\u6027\uff0c\u8bc1\u5b9e\u4e86\u968f\u673a\u6027\u5728\u67d0\u4e9b\u6761\u4ef6\u4e0b\u5bf9\u4f30\u8ba1\u662f\u6709\u76ca\u7684\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u5e7f\u4e49RV-ML\uff08GRV-ML\uff09\u7684\u5feb\u901f\u7edf\u4e00\u5b9e\u73b0\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c06\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u5206\u6790\u6269\u5c55\u5230\u968f\u673a\u6d4b\u91cf\u77e9\u9635\u5747\u503c\u79e9\u4e8f\u7f3a\u7684\u573a\u666f\uff0c\u63d0\u51fa\u4e86\u5e7f\u4e49RV-ML\u7b97\u6cd5\uff0c\u5e76\u5728\u6570\u503c\u6a21\u62df\u4e2d\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\u3002"}}
{"id": "2507.11090", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2507.11090", "abs": "https://arxiv.org/abs/2507.11090", "authors": ["Hongbo Qiu", "Renjie Sun", "Chen chen", "Xiaoyang Wang"], "title": "Enhance Stability of Network by Edge Anchor", "comment": null, "summary": "With the rapid growth of online social networks, strengthening their\nstability has emerged as a key research focus. This study aims to identify\ninfluential relationships that significantly impact community stability. In\nthis paper, we introduce and explore the anchor trussness reinforcement problem\nto reinforce the overall user engagement of networks by anchoring some edges.\nSpecifically, for a given graph $G$ and a budget $b$, we aim to identify $b$\nedges whose anchoring maximizes the trussness gain, which is the cumulative\nincrement of trussness across all edges in $G$. We establish the NP-hardness of\nthe problem. To address this problem, we introduce a greedy framework that\niteratively selects the current best edge. To scale for larger networks, we\nfirst propose an upward-route method to constrain potential trussness increment\nedges. Augmented with a support check strategy, this approach enables the\nefficient computation of the trussness gain for anchoring one edge. Then, we\ndesign a classification tree structure to minimize redundant computations in\neach iteration by organizing edges based on their trussness. We conduct\nextensive experiments on 8 real-world networks to validate the efficiency and\neffectiveness of the proposed model and methods.", "AI": {"tldr": "\u901a\u8fc7\u951a\u5b9a\u5173\u952e\u8fb9\u6765\u63d0\u5347\u793e\u4ea4\u7f51\u7edc\u7a33\u5b9a\u6027\u548c\u7528\u6237\u53c2\u4e0e\u5ea6\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u51b3\u6b64NP\u96be\u95ee\u9898\u7684\u6709\u6548\u7b97\u6cd5\u3002", "motivation": "\u968f\u7740\u5728\u7ebf\u793e\u4ea4\u7f51\u7edc\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u589e\u5f3a\u5176\u7a33\u5b9a\u6027\u6210\u4e3a\u7814\u7a76\u7684\u7126\u70b9\u3002\u672c\u7814\u7a76\u65e8\u5728\u8bc6\u522b\u5bf9\u793e\u533a\u7a33\u5b9a\u6027\u6709\u663e\u8457\u5f71\u54cd\u7684\u5173\u952e\u5173\u7cfb\uff0c\u5e76\u63d0\u51fa\u901a\u8fc7\u951a\u5b9a\u5173\u952e\u8fb9\u6765\u63d0\u5347\u7f51\u7edc\u6574\u4f53\u7528\u6237\u53c2\u4e0e\u5ea6\u7684\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u951a\u5b9a\u7ea6\u675f\u52a0\u5f3a\u201d\u7684\u65b0\u95ee\u9898\uff0c\u65e8\u5728\u901a\u8fc7\u951a\u5b9a\u4e00\u90e8\u5206\u8fb9\u6765\u63d0\u5347\u56fe\u7684\u6574\u4f53\u97e7\u6027\u3002\u8be5\u95ee\u9898\u88ab\u8bc1\u660e\u662fNP\u96be\u7684\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u4e2a\u8fed\u4ee3\u5f0f\u7684\u8d2a\u5fc3\u6846\u67b6\uff0c\u5e76\u5728\u5176\u4e2d\u8bbe\u8ba1\u4e86\u5411\u4e0a\u8def\u7531\u65b9\u6cd5\u3001\u652f\u6301\u68c0\u67e5\u7b56\u7565\u548c\u5206\u7c7b\u6811\u7ed3\u6784\uff0c\u4ee5\u4f18\u5316\u8ba1\u7b97\u6548\u7387\u548c\u6269\u5c55\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u63d0\u5347\u7f51\u7edc\u7684\u97e7\u6027\uff0c\u5e76\u4e14\u5728\u5904\u7406\u5927\u89c4\u6a21\u7f51\u7edc\u65f6\u5177\u6709\u826f\u597d\u7684\u6548\u7387\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u57fa\u4e8e\u951a\u5b9a\u8fb9\u9009\u62e9\u7684\u52a0\u5f3a\u56fe\u97e7\u6027\u65b9\u6cd5\u5728\u771f\u5b9e\u7f51\u7edc\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u5176\u6548\u7387\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2507.10848", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.10848", "abs": "https://arxiv.org/abs/2507.10848", "authors": ["San-Dong Guo", "Shaobo Chen", "Guangzhao Wang"], "title": "Spin ordering-induced fully-compensated ferrimagnetism", "comment": "6 pages, 7 figures", "summary": "Fully-compensated ferrimagnets exhibit zero net magnetic moment yet display\nnon-relativistic global spin splitting, making them highly advantageous for\nconstructing high-performance spintronic devices. The general strategy is to\nbreak the inversion symmetry of conventional antiferromagnets or the\nrotational/mirror symmetry of altermagnets to achieve fully-compensated\nferrimagnets. Here, we propose to induce fully-compensated ferrimagnetism by\nengineering the spin ordering rather than modifying the lattice structure.\nBilayer stacking engineering offers a convenient platform to verify our\nproposal and readily enables switching between two distinct electronic states\nby tuning the $\\mathrm{N\\acute{e}el}$ vector of one layer. By the\nfirst-principles calculations, a bilayer system is constructed with monolayer\n$\\mathrm{Cr_2C_2S_6}$ as the elementary building block to corroborate our\nproposal. This strategy can also be extended to inducing altermagnetism via\nspin ordering engineering. Our work offers an alternative route to realize\nnon-relativistic spin splitting in zero-net-magnetization magnets, paving the\nway for the advancement and construction of low-power spintronic device.", "AI": {"tldr": "\u901a\u8fc7\u5de5\u7a0b\u5316\u81ea\u65cb\u5e8f\u800c\u975e\u6539\u53d8\u6676\u683c\u7ed3\u6784\uff0c\u5b9e\u73b0\u4e86\u5168\u8865\u507f\u4e9a\u94c1\u78c1\u6027\uff0c\u4e3a\u96f6\u51c0\u78c1\u77e9\u4e0b\u7684\u975e\u76f8\u5bf9\u8bba\u81ea\u65cb\u5288\u88c2\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002", "motivation": "\u5168\u8865\u507f\u4e9a\u94c1\u78c1\u4f53\u5177\u6709\u96f6\u51c0\u78c1\u77e9\u4f46\u663e\u793a\u51fa\u975e\u76f8\u5bf9\u8bba\u5168\u5c40\u81ea\u65cb\u5288\u88c2\uff0c\u8fd9\u5728\u6784\u5efa\u9ad8\u6027\u80fd\u81ea\u65cb\u7535\u5b50\u5668\u4ef6\u65b9\u9762\u5177\u6709\u9ad8\u5ea6\u4f18\u52bf\u3002", "method": "\u5229\u7528\u7b2c\u4e00\u6027\u539f\u7406\u8ba1\u7b97\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u4ee5\u5355\u5c42$\text{Cr}_2\text{C}_2\text{S}_6$\u4e3a\u57fa\u672c\u6784\u7b51\u5355\u5143\u7684\u53cc\u5c42\u7cfb\u7edf\u6765\u8bc1\u5b9e\u8be5\u63d0\u8bae\u3002", "result": "\u901a\u8fc7\u7b2c\u4e00\u6027\u539f\u7406\u8ba1\u7b97\uff0c\u8bc1\u5b9e\u4e86\u8be5\u7b56\u7565\u53ef\u4ee5\u8bf1\u5bfc\u5168\u8865\u507f\u4e9a\u94c1\u78c1\u6027\uff0c\u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u8c03\u6574\u5176\u4e2d\u4e00\u5c42\u7684$\text{N\u00e9el}$\u77e2\u91cf\u8f7b\u677e\u5730\u5728\u4e24\u79cd\u4e0d\u540c\u7684\u7535\u5b50\u72b6\u6001\u4e4b\u95f4\u5207\u6362\u3002\u8be5\u7b56\u7565\u8fd8\u53ef\u4ee5\u901a\u8fc7\u81ea\u65cb\u5e8f\u5de5\u7a0b\u6269\u5c55\u5230\u8bf1\u5bfc\u4ea4\u53d8\u78c1\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u5de5\u7a0b\u5316\u81ea\u65cb\u5e8f\u800c\u4e0d\u662f\u4fee\u6539\u6676\u683c\u7ed3\u6784\u6765\u8bf1\u5bfc\u5168\u8865\u507f\u4e9a\u94c1\u78c1\u6027\u7684\u65b9\u6cd5\uff0c\u4e3a\u5b9e\u73b0\u96f6\u51c0\u78c1\u5316\u78c1\u4f53\u4e2d\u7684\u975e\u76f8\u5bf9\u8bba\u81ea\u65cb\u5288\u88c2\u63d0\u4f9b\u4e86\u4e00\u6761\u66ff\u4ee3\u9014\u5f84\uff0c\u6709\u671b\u63a8\u52a8\u4f4e\u529f\u8017\u81ea\u65cb\u7535\u5b50\u5668\u4ef6\u7684\u53d1\u5c55\u548c\u6784\u5efa\u3002"}}
{"id": "2507.11186", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2507.11186", "abs": "https://arxiv.org/abs/2507.11186", "authors": ["Ana Sokolova", "Harald Woracek"], "title": "Cancellative Convex Semilattices", "comment": null, "summary": "Convex semilattices are algebras that are at the same time a convex algebra\nand a semilattice, together with a distributivity axiom. These algebras have\nattracted some attention in the last years as suitable algebras for probability\nand nondeterminism, in particular by being the Eilenberg-Moore algebras of the\nnonempty finitely-generated convex subsets of the distributions monad.\n  A convex semilattice is cancellative if the underlying convex algebra is\ncancellative. Cancellative convex algebras have been characterized by M. H.\nStone and by H. Kneser: A convex algebra is cancellative if and only if it is\nisomorphic to a convex subset of a vector space (with canonical convex algebra\noperations).\n  We prove an analogous theorem for convex semilattices: A convex semilattice\nis cancellative if and only if it is isomorphic to a convex subset of a Riesz\nspace, i.e., a lattice-ordered vector space (with canonical convex semilattice\noperations).", "AI": {"tldr": "\u53ef\u6362\u8d4b\u683c\u662f\u4ee3\u6570\uff0c\u5b83\u4eec\u540c\u65f6\u662f\u51f8\u4ee3\u6570\u548c\u8d4b\u683c\uff0c\u5e76\u6ee1\u8db3\u5206\u914d\u516c\u7406\u3002\u672c\u6587\u8bc1\u660e\u4e86\u53ef\u6362\u8d4b\u683c\u662f\u53ef\u6362\u7684\u5f53\u4e14\u4ec5\u5f53\u5b83\u540c\u6784\u4e8eRiesz\u7a7a\u95f4\u7684\u51f8\u5b50\u96c6\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u8bc1\u660e\u53ef\u6362\u8d4b\u683c\u662f\u53ef\u6362\u7684\u5f53\u4e14\u4ec5\u5f53\u5b83\u540c\u6784\u4e8eRiesz\u7a7a\u95f4\u7684\u51f8\u5b50\u96c6\u3002", "method": "\u6211\u4eec\u8bc1\u660e\u4e86\u4e00\u4e2a\u7c7b\u4f3c\u7684\u5b9a\u7406\uff1a\u53ef\u6362\u8d4b\u683c\u662f\u53ef\u6362\u7684\u5f53\u4e14\u4ec5\u5f53\u5b83\u540c\u6784\u4e8eRiesz\u7a7a\u95f4\uff08\u5373\u5177\u6709\u89c4\u8303\u7684\u53ef\u6362\u8d4b\u683c\u8fd0\u7b97\u7684\u683c\u5e8f\u5411\u91cf\u7a7a\u95f4\uff09\u7684\u51f8\u5b50\u96c6\u3002", "result": "\u53ef\u6362\u8d4b\u683c\u662f\u53ef\u6362\u7684\u5f53\u4e14\u4ec5\u5f53\u5b83\u540c\u6784\u4e8eRiesz\u7a7a\u95f4\u7684\u51f8\u5b50\u96c6\u3002", "conclusion": "\u53ef\u6362\u8d4b\u683c\u662f\u8d4b\u683c\u548c\u51f8\u4ee3\u6570\uff0c\u5e76\u4e14\u6ee1\u8db3\u5206\u914d\u516c\u7406\u3002\u8fd9\u4e9b\u4ee3\u6570\u5728\u8fd1\u5e74\u6765\u4f5c\u4e3a\u6982\u7387\u548c\u975e\u786e\u5b9a\u6027\u7684\u5408\u9002\u4ee3\u6570\u800c\u53d7\u5230\u5173\u6ce8\uff0c\u7279\u522b\u662f\u901a\u8fc7\u6210\u4e3a\u975e\u7a7a\u6709\u9650\u751f\u6210\u51f8\u5b50\u96c6\u5230\u5206\u5e03\u4ee3\u6570\u4e0a\u7684Eilenberg-Moore\u4ee3\u6570\u3002"}}
{"id": "2507.10716", "categories": ["cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2507.10716", "abs": "https://arxiv.org/abs/2507.10716", "authors": ["Ahmed Jellal", "Nadia Benlakhouy", "Pablo D\u00edaz", "David Laroze"], "title": "Spin and valley-dependent tunneling in MoS$_2$ through magnetic barrier", "comment": "9 pages, 8 figures. Version to appear in Comput. Mater. Sci", "summary": "We study electron transport in monolayer molybdenum disulfide MoS$_2$\nsubjected to a magnetic barrier. Our analysis employs a full-band continuum\nmodel to capture the relevant physical phenomena. We focus on how electron\nenergy, magnetic field strength, and the geometric characteristics of the\nbarrier affect the transmission and conductance. We observe sharp resonant\ntunneling features emerging from quantum interference effects induced by\nmagnetic confinement. A key outcome of our study is the discovery of distinct\nresonance patterns in the conduction and valence bands. These patterns are\nclosely related to the intrinsic spin-orbit coupling in MoS$_2$ and the\nbreaking of time-reversal symmetry by the magnetic field. This results in\nsignificant spin and valley selectivity in electron transport. We demonstrate\nthat adjusting external parameters precisely controls spin-polarized and\nvalley-polarized currents. We show that a magnetic barrier can control electron\nspin and valley in MoS$_2$, making it a promising platform for energy-efficient\nspintronic and valleytronic devices.", "AI": {"tldr": "\u7814\u7a76\u4e86\u78c1\u52bf\u5792\u5bf9 MoS$_{2}$ \u7535\u5b50\u4f20\u8f93\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u4e86\u4e0e\u81ea\u65cb\u8f68\u9053\u8026\u5408\u548c\u78c1\u573a\u76f8\u5173\u7684\u5171\u632f\u96a7\u7a7f\u73b0\u8c61\uff0c\u5e76\u5c55\u793a\u4e86\u5229\u7528\u78c1\u52bf\u5792\u5b9e\u73b0\u81ea\u65cb\u548c\u8c37\u9009\u62e9\u6027\u7535\u5b50\u4f20\u8f93\u7684\u6f5c\u529b\u3002", "motivation": "\u7814\u7a76\u4e86\u5728\u78c1\u52bf\u5792\u4f5c\u7528\u4e0b\u5355\u5c42\u4e8c\u786b\u5316\u94bc MoS$_{2}$ \u4e2d\u7684\u7535\u5b50\u4f20\u8f93\u3002", "method": "\u91c7\u7528\u5168\u5e26\u8fde\u7eed\u6a21\u578b\u6765\u6355\u6349\u76f8\u5173\u7684\u7269\u7406\u73b0\u8c61\u3002", "result": "\u89c2\u5bdf\u5230\u7531\u78c1\u7ea6\u675f\u5f15\u8d77\u7684\u91cf\u5b50\u5e72\u6d89\u6548\u5e94\u4ea7\u751f\u7684\u6e05\u6670\u7684\u5171\u632f\u96a7\u7a7f\u7279\u5f81\uff0c\u5e76\u5728\u5bfc\u5e26\u548c\u4ef7\u5e26\u4e2d\u53d1\u73b0\u4e86\u72ec\u7279\u7684\u5171\u632f\u6a21\u5f0f\uff0c\u8fd9\u4e0e MoS$_{2}$ \u7684\u5185\u5728\u81ea\u65cb-\u8f68\u9053\u8026\u5408\u548c\u78c1\u573a\u5f15\u8d77\u7684\u65f6\u53cd\u5bf9\u79f0\u6027\u7834\u574f\u5bc6\u5207\u76f8\u5173\u3002", "conclusion": "\u901a\u8fc7\u8c03\u6574\u5916\u90e8\u53c2\u6570\uff0c\u53ef\u4ee5\u7cbe\u786e\u63a7\u5236\u81ea\u65cb\u6781\u5316\u548c\u8c37\u6781\u5316\u7535\u6d41\uff0c\u8868\u660e\u78c1\u52bf\u5792\u53ef\u4ee5\u63a7\u5236 MoS$_{2}$ \u4e2d\u7684\u7535\u5b50\u81ea\u65cb\u548c\u8c37\uff0c\u4f7f\u5176\u6210\u4e3a\u8282\u80fd\u81ea\u65cb\u7535\u5b50\u548c\u8c37\u7535\u5b50\u5668\u4ef6\u7684\u6709\u524d\u9014\u7684\u5e73\u53f0\u3002"}}
{"id": "2507.10676", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.10676", "abs": "https://arxiv.org/abs/2507.10676", "authors": ["Agustin Silva", "Alvaro Orgaz-Fuertes"], "title": "Manarat: A Scalable QICK-Based Control System for Superconducting Quantum Processors Supporting Synchronized Control of 10 Flux-Tunable Qubits", "comment": null, "summary": "A scalable control architecture for superconducting quantum processors is\nessential as the number of qubits increases and coherent multi-qubit operations\nspan beyond the capacity of a single control module. The Quantum\nInstrumentation Control Kit (QICK), built on AMD RFSoC platforms, offers a\nflexible open-source framework for pulse-level qubit control but lacks native\nsupport for multi-board synchronization, limiting its applicability to mid- and\nlarge-scale quantum devices. To overcome this limitation, we introduce Manarat,\na scalable multi-board control platform based on QICK that incorporates\nhardware, firmware, and software enhancements to enable sub-100 ps timing\nalignment across multiple AMD ZCU216 RFSoC boards. Our system integrates a\nlow-jitter clock distribution network, modifications to the tProcessor, and a\nsynchronization scheme to ensure deterministic alignment of program execution\nacross boards. It also includes a custom analog front-end for flux control that\ncombines high-speed RF signals with software-programmable DC biasing voltages\ngenerated by a low-noise, high-precision DAC. These capabilities are\ncomplemented by a software stack capable of orchestrating synchronized\nmulti-board experiments and fully integrated with the open-source Qibo\nframework for quantum device calibration and algorithm execution. We validate\nManarat on a 10-qubit superconducting processor controlled by two RFSoC boards,\ndemonstrating reliable execution of synchronized control sequences for\ncross-board CZ gate calibration. These results confirm that sub-nanosecond\nsynchronization and coherent control is achievable across multiple RFSoC\nboards, enabling scalable operation of superconducting quantum computers.", "AI": {"tldr": "Manarat\u662f\u4e00\u4e2a\u57fa\u4e8eQICK\u7684\u53ef\u6269\u5c55\u591a\u677f\u63a7\u5236\u5e73\u53f0\uff0c\u901a\u8fc7\u786c\u4ef6\u3001\u56fa\u4ef6\u548c\u8f6f\u4ef6\u7684\u589e\u5f3a\uff0c\u5b9e\u73b0\u4e86\u8de8\u591a\u4e2aRFSoC\u677f\u7684\u4e9a\u7eb3\u79d2\u7ea7\u5b9a\u65f6\u5bf9\u9f50\u3002\u8be5\u5e73\u53f0\u5df2\u6210\u529f\u7528\u4e8e10\u91cf\u5b50\u6bd4\u7279\u5904\u7406\u5668\u7684\u540c\u6b65\u63a7\u5236\uff0c\u4e3a\u6784\u5efa\u66f4\u5927\u89c4\u6a21\u7684\u91cf\u5b50\u8ba1\u7b97\u673a\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u7684QICK\u6846\u67b6\u867d\u7136\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684\u5f00\u6e90\u8109\u51b2\u7ea7\u91cf\u5b50\u6bd4\u7279\u63a7\u5236\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u591a\u677f\u540c\u6b65\u7684\u539f\u751f\u652f\u6301\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5728\u4e2d\u5927\u89c4\u6a21\u91cf\u5b50\u8bbe\u5907\u4e0a\u7684\u5e94\u7528\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u9650\u5236\uff0c\u9700\u8981\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u591a\u677f\u63a7\u5236\u5e73\u53f0\u3002", "method": "Manarat\u5e73\u53f0\u57fa\u4e8eQICK\uff0c\u901a\u8fc7\u96c6\u6210\u4f4e\u6296\u52a8\u65f6\u949f\u5206\u53d1\u7f51\u7edc\u3001\u5bf9tProcessor\u7684\u4fee\u6539\u4ee5\u53ca\u4e00\u79cd\u786e\u5b9a\u6027\u5730\u5bf9\u9f50\u8de8\u677f\u7a0b\u5e8f\u6267\u884c\u7684\u540c\u6b65\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u8de8\u591a\u4e2aAMD ZCU216 RFSoC\u677f\u7684100\u76ae\u79d2\u7ea7\u5b9a\u65f6\u5bf9\u9f50\u3002\u6b64\u5916\uff0c\u8fd8\u5305\u62ec\u4e00\u4e2a\u5b9a\u5236\u7684\u6a21\u62df\u524d\u7aef\uff0c\u7528\u4e8e\u78c1\u901a\u63a7\u5236\uff0c\u96c6\u6210\u4e86\u9ad8\u901fRF\u4fe1\u53f7\u548c\u4f4e\u566a\u58f0\u3001\u9ad8\u7cbe\u5ea6DAC\u4ea7\u751f\u7684\u8f6f\u4ef6\u53ef\u7f16\u7a0b\u76f4\u6d41\u504f\u7f6e\u7535\u538b\u3002\u8f6f\u4ef6\u6808\u80fd\u591f\u534f\u8c03\u540c\u6b65\u7684\u591a\u677f\u5b9e\u9a8c\uff0c\u5e76\u4e0eQibo\u6846\u67b6\u5b8c\u5168\u96c6\u6210\u3002", "result": "Manarat\u5e73\u53f0\u6210\u529f\u5b9e\u73b0\u4e86\u8de8\u591a\u4e2aRFSoC\u677f\u7684\u4e9a\u7eb3\u79d2\u7ea7\u5b9a\u65f6\u5bf9\u9f50\u548c\u76f8\u5e72\u63a7\u5236\uff0c\u5e76\u80fd\u572810\u91cf\u5b50\u6bd4\u7279\u7684\u8d85\u5bfc\u5904\u7406\u5668\u4e0a\u53ef\u9760\u6267\u884c\u540c\u6b65\u63a7\u5236\u5e8f\u5217\uff0c\u4f8b\u5982\u8de8\u677fCZ\u95e8\u6821\u51c6\u3002", "conclusion": "Manarat\u5e73\u53f0\u572810\u4e2a\u91cf\u5b50\u6bd4\u7279\u7684\u8d85\u5bfc\u5904\u7406\u5668\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u901a\u8fc7\u4e24\u4e2aRFSoC\u677f\u5b9e\u73b0\u4e86\u8de8\u677fCZ\u95e8\u6821\u51c6\u7b49\u540c\u6b65\u63a7\u5236\u5e8f\u5217\u7684\u53ef\u9760\u6267\u884c\uff0c\u8bc1\u660e\u4e86\u5728\u591a\u4e2aRFSoC\u677f\u4e4b\u95f4\u5b9e\u73b0\u4e9a\u7eb3\u79d2\u540c\u6b65\u548c\u76f8\u5e72\u63a7\u5236\u662f\u53ef\u884c\u7684\uff0c\u4e3a\u8d85\u5bfc\u91cf\u5b50\u8ba1\u7b97\u673a\u7684\u53ef\u6269\u5c55\u64cd\u4f5c\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.10800", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10800", "abs": "https://arxiv.org/abs/2507.10800", "authors": ["Ali Hojjat", "Janek Haberer", "Soren Pirk", "Olaf Landsiedel"], "title": "ThinkingViT: Matryoshka Thinking Vision Transformer for Elastic Inference", "comment": "Under Review", "summary": "Vision Transformers deliver state-of-the-art performance, yet their fixed\ncomputational budget prevents scalable deployment across heterogeneous\nhardware. Recent nested Transformer architectures mitigate this by embedding\nnested subnetworks within a single model to enable scalable inference. However,\nthese models allocate the same amount of compute to all inputs, regardless of\ntheir complexity, which leads to inefficiencies. To address this, we introduce\nThinkingViT, a nested ViT architecture that employs progressive thinking stages\nto dynamically adjust inference computation based on input difficulty.\nThinkingViT initiates inference by activating a small subset of the most\nimportant attention heads and terminates early if predictions reach sufficient\ncertainty. Otherwise, it activates additional attention heads and re-evaluates\nthe input. At the core of ThinkingViT is our Token Recycling mechanism, which\nconditions each subsequent inference stage on the embeddings from the previous\nstage, enabling progressive improvement. Due to its backbone-preserving design,\nThinkingViT also serves as a plugin upgrade for vanilla ViT. Experiments show\nthat ThinkingViT surpasses nested baselines by up to 2.0 percentage points\n(p.p.) in accuracy at the same throughput and by up to 2.9 p.p. at equal GMACs\non ImageNet-1K. The source code is available at\nhttps://github.com/ds-kiel/ThinkingViT.", "AI": {"tldr": "ThinkingViT\u662f\u4e00\u79cd\u65b0\u7684\u5d4c\u5957ViT\u67b6\u6784\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u8ba1\u7b97\u91cf\u548c\u4f7f\u7528Token Recycling\u673a\u5236\uff0c\u5728\u63d0\u9ad8\u63a8\u7406\u6548\u7387\u548c\u51c6\u786e\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7684Vision Transformer\u867d\u7136\u6027\u80fd\u4f18\u8d8a\uff0c\u4f46\u8ba1\u7b97\u9884\u7b97\u56fa\u5b9a\uff0c\u96be\u4ee5\u5728\u5f02\u6784\u786c\u4ef6\u4e0a\u8fdb\u884c\u6269\u5c55\u3002\u5d4c\u5957Transformer\u6a21\u578b\u867d\u7136\u80fd\u5b9e\u73b0\u53ef\u6269\u5c55\u63a8\u7406\uff0c\u4f46\u4f1a\u4e3a\u6240\u6709\u8f93\u5165\u5206\u914d\u76f8\u540c\u7684\u8ba1\u7b97\u91cf\uff0c\u6548\u7387\u4f4e\u4e0b\u3002", "method": "ThinkingViT\u662f\u4e00\u79cd\u5d4c\u5957Vision Transformer\uff08ViT\uff09\u67b6\u6784\uff0c\u5176\u6838\u5fc3\u662fToken Recycling\u673a\u5236\uff0c\u80fd\u591f\u6839\u636e\u8f93\u5165\u96be\u5ea6\u52a8\u6001\u8c03\u6574\u63a8\u7406\u8ba1\u7b97\u3002\u5b83\u901a\u8fc7\u6fc0\u6d3b\u90e8\u5206\u6ce8\u610f\u529b\u5934\u5e76\u8fdb\u884c\u65e9\u671f\u9884\u6d4b\uff0c\u6216\u8005\u6fc0\u6d3b\u66f4\u591a\u6ce8\u610f\u529b\u5934\u5e76\u91cd\u65b0\u8bc4\u4f30\u8f93\u5165\u6765\u5de5\u4f5c\u3002", "result": "\u5728ImageNet-1K\u4e0a\uff0cThinkingViT\u5728\u76f8\u540c\u541e\u5410\u91cf\u4e0b\u51c6\u786e\u7387\u9ad8\u51fa\u57fa\u7ebf\u6a21\u578b2.0\u4e2a\u767e\u5206\u70b9\uff0c\u5728\u76f8\u540cGMACs\u4e0b\u9ad8\u51fa2.9\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "ThinkingViT\u901a\u8fc7\u91c7\u7528\u6e10\u8fdb\u5f0f\u601d\u7ef4\u9636\u6bb5\u6765\u52a8\u6001\u8c03\u6574\u57fa\u4e8e\u8f93\u5165\u96be\u5ea6\u7684\u63a8\u7406\u8ba1\u7b97\uff0c\u5e76\u5728ImageNet-1K\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u5d4c\u5957\u57fa\u7ebf\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2507.10740", "categories": ["cs.AI", "cs.NE", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.10740", "abs": "https://arxiv.org/abs/2507.10740", "authors": ["Maziar Kanani", "Sean O Leary", "James McDermott"], "title": "Parsing Musical Structure to Enable Meaningful Variations", "comment": null, "summary": "This paper presents a novel rule-based approach for generating music by\nvarying existing tunes. We parse each tune to find the Pathway Assembly (PA) [\n1], that is a structure representing all repetitions in the tune. The Sequitur\nalgorithm [2 ] is used for this. The result is a grammar. We then carry out\nmutation on the grammar, rather than on a tune directly. There are potentially\n19 types of mutations such as adding, removing, swapping or reversing parts of\nthe grammar that can be applied to the grammars. The system employs one of the\nmutations randomly in this step to automatically manipulate the grammar.\nFollowing the mutation, we need to expand the grammar which returns a new tune.\nThe output after 1 or more mutations will be a new tune related to the original\ntune. Our study examines how tunes change gradually over the course of multiple\nmutations. Edit distances, structural complexity and length of the tunes are\nused to show how a tune is changed after multiple mutations. In addition, the\nsize of effect of each mutation type is analyzed. As a final point, we review\nthe musical aspect of the output tunes. It should be noted that the study only\nfocused on generating new pitch sequences. The study is based on an Irish\ntraditional tune dataset and a list of integers has been used to represent each\ntune's pitch values.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u8bed\u6cd5\u7684\u97f3\u4e50\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u53d8\u5f02\u73b0\u6709\u66f2\u8c03\u7684\u8bed\u6cd5\u7ed3\u6784\u6765\u751f\u6210\u65b0\u7684\u97f3\u4e50\uff0c\u5e76\u5206\u6790\u4e86\u53d8\u5f02\u8fc7\u7a0b\u5bf9\u97f3\u4e50\u7684\u5f71\u54cd\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4e00\u79cd\u65b0\u9896\u7684\u97f3\u4e50\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u73b0\u6709\u66f2\u8c03\u8fdb\u884c\u7ed3\u6784\u5316\u53d8\u5f02\u6765\u81ea\u52a8\u751f\u6210\u65b0\u7684\u3001\u76f8\u5173\u7684\u97f3\u4e50\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u53d8\u5f02\u73b0\u6709\u66f2\u8c03\u6765\u751f\u6210\u97f3\u4e50\u3002\u9996\u5148\uff0c\u4f7f\u7528 Sequitur \u7b97\u6cd5\u89e3\u6790\u66f2\u8c03\u4ee5\u63d0\u53d6\u5176 Pathway Assembly (PA) \u7ed3\u6784\uff0c\u5f62\u6210\u4e00\u4e2a\u8bed\u6cd5\u3002\u7136\u540e\uff0c\u5bf9\u8be5\u8bed\u6cd5\u8fdb\u884c\u591a\u79cd\u7c7b\u578b\u7684\u53d8\u5f02\uff08\u5982\u6dfb\u52a0\u3001\u5220\u9664\u3001\u4ea4\u6362\u6216\u53cd\u8f6c\u90e8\u5206\uff09\uff0c\u4ee5\u751f\u6210\u65b0\u7684\u66f2\u8c03\u3002\u7814\u7a76\u4e2d\u8fd8\u5206\u6790\u4e86\u4e0d\u540c\u53d8\u5f02\u7c7b\u578b\u5bf9\u66f2\u8c03\u7684\u5f71\u54cd\uff0c\u5e76\u4ece\u7f16\u8f91\u8ddd\u79bb\u3001\u7ed3\u6784\u590d\u6742\u6027\u548c\u957f\u5ea6\u7b49\u65b9\u9762\u8bc4\u4f30\u4e86\u53d8\u5f02\u5bf9\u66f2\u8c03\u7684\u6539\u53d8\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u5c55\u793a\u4e86\u901a\u8fc7\u5bf9\u97f3\u4e50\u8bed\u6cd5\u8fdb\u884c\u53d8\u5f02\u53ef\u4ee5\u751f\u6210\u65b0\u7684\u97f3\u9ad8\u5e8f\u5217\uff0c\u5e76\u91cf\u5316\u4e86\u8fd9\u4e9b\u53d8\u5f02\u5bf9\u66f2\u8c03\u7684\u9010\u6b65\u5f71\u54cd\uff0c\u5305\u62ec\u7f16\u8f91\u8ddd\u79bb\u3001\u7ed3\u6784\u590d\u6742\u6027\u548c\u957f\u5ea6\u7684\u53d8\u5316\uff0c\u540c\u65f6\u8fd8\u5206\u6790\u4e86\u4e0d\u540c\u53d8\u5f02\u7c7b\u578b\u7684\u5f71\u54cd\u6548\u679c\u548c\u8f93\u5904\u97f3\u4e50\u7684\u97f3\u4e50\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u5bf9\u73b0\u6709\u66f2\u8c03\u8fdb\u884c\u53d8\u5f02\u6765\u751f\u6210\u65b0\u97f3\u4e50\uff0c\u5e76\u5206\u6790\u4e86\u53d8\u5f02\u5bf9\u66f2\u8c03\u7684\u9010\u6b65\u5f71\u54cd\u3002"}}
{"id": "2507.10596", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10596", "abs": "https://arxiv.org/abs/2507.10596", "authors": ["Yogachandran Rahulamathavan", "Misbah Farooq", "Varuna De Silva"], "title": "PLEX: Perturbation-free Local Explanations for LLM-Based Text Classification", "comment": null, "summary": "Large Language Models (LLMs) excel in text classification, but their\ncomplexity hinders interpretability, making it difficult to understand the\nreasoning behind their predictions. Explainable AI (XAI) methods like LIME and\nSHAP offer local explanations by identifying influential words, but they rely\non computationally expensive perturbations. These methods typically generate\nthousands of perturbed sentences and perform inferences on each, incurring a\nsubstantial computational burden, especially with LLMs. To address this, we\npropose \\underline{P}erturbation-free \\underline{L}ocal \\underline{Ex}planation\n(PLEX), a novel method that leverages the contextual embeddings extracted from\nthe LLM and a ``Siamese network\" style neural network trained to align with\nfeature importance scores. This one-off training eliminates the need for\nsubsequent perturbations, enabling efficient explanations for any new sentence.\nWe demonstrate PLEX's effectiveness on four different classification tasks\n(sentiment, fake news, fake COVID-19 news and depression), showing more than\n92\\% agreement with LIME and SHAP. Our evaluation using a ``stress test\"\nreveals that PLEX accurately identifies influential words, leading to a similar\ndecline in classification accuracy as observed with LIME and SHAP when these\nwords are removed. Notably, in some cases, PLEX demonstrates superior\nperformance in capturing the impact of key features. PLEX dramatically\naccelerates explanation, reducing time and computational overhead by two and\nfour orders of magnitude, respectively. This work offers a promising solution\nfor explainable LLM-based text classification.", "AI": {"tldr": "PLEX \u662f\u4e00\u79cd\u65b0\u7684 XAI \u65b9\u6cd5\uff0c\u5b83\u5229\u7528 LLM \u7684\u4e0a\u4e0b\u6587\u5d4c\u5165\u548c\u4e00\u4e2a Siamese \u7f51\u7edc\u6765\u4e3a\u6587\u672c\u5206\u7c7b\u63d0\u4f9b\u5feb\u901f\u3001\u51c6\u786e\u7684\u89e3\u91ca\uff0c\u4e0e LIME \u548c SHAP \u76f8\u6bd4\uff0c\u5176\u6548\u7387\u63d0\u9ad8\u4e86\u51e0\u4e2a\u6570\u91cf\u7ea7\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u6587\u672c\u5206\u7c7b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u590d\u6742\u6027\u963b\u788d\u4e86\u53ef\u89e3\u91ca\u6027\uff0c\u4f7f\u5f97\u7406\u89e3\u5176\u9884\u6d4b\u80cc\u540e\u7684\u63a8\u7406\u53d8\u5f97\u56f0\u96be\u3002LIME \u548c SHAP \u7b49\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u65b9\u6cd5\u901a\u8fc7\u8bc6\u522b\u6709\u5f71\u54cd\u529b\u7684\u8bcd\u8bed\u6765\u63d0\u4f9b\u5c40\u90e8\u89e3\u91ca\uff0c\u4f46\u5b83\u4eec\u4f9d\u8d56\u4e8e\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u7684\u6270\u52a8\u3002\u8fd9\u4e9b\u65b9\u6cd5\u901a\u5e38\u4f1a\u751f\u6210\u6570\u5343\u4e2a\u6270\u52a8\u53e5\u5b50\u5e76\u5bf9\u6bcf\u4e2a\u53e5\u5b50\u8fdb\u884c\u63a8\u7406\uff0c\u5c24\u5176\u662f\u5728\u4f7f\u7528 LLM \u65f6\uff0c\u4f1a\u5e26\u6765\u5de8\u5927\u7684\u8ba1\u7b97\u8d1f\u62c5\u3002", "method": "PLEX\uff08\u65e0\u6270\u52a8\u5c40\u90e8\u89e3\u91ca\uff09\u662f\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u5b83\u5229\u7528\u4ece LLM \u4e2d\u63d0\u53d6\u7684\u4e0a\u4e0b\u6587\u5d4c\u5165\u548c\u4e00\u4e2a\u201cSiamese \u7f51\u7edc\u201d\u98ce\u683c\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u8be5\u7f51\u7edc\u7ecf\u8fc7\u8bad\u7ec3\u4ee5\u5339\u914d\u7279\u5f81\u91cd\u8981\u6027\u5206\u6570\u3002\u8fd9\u79cd\u4e00\u6b21\u6027\u8bad\u7ec3\u6d88\u9664\u4e86\u540e\u7eed\u6270\u52a8\u7684\u9700\u8981\uff0c\u4ece\u800c\u80fd\u591f\u4e3a\u4efb\u4f55\u65b0\u53e5\u5b50\u63d0\u4f9b\u9ad8\u6548\u7684\u89e3\u91ca\u3002", "result": "PLEX \u5728\u56db\u4e2a\u4e0d\u540c\u7684\u5206\u7c7b\u4efb\u52a1\uff08\u60c5\u7eea\u3001\u5047\u65b0\u95fb\u3001\u865a\u5047 COVID-19 \u65b0\u95fb\u548c\u6291\u90c1\u75c7\uff09\u4e0a\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\uff0c\u4e0e LIME \u548c SHAP \u76f8\u6bd4\uff0c\u5177\u6709\u8d85\u8fc7 92% \u7684\u4e00\u81f4\u6027\u3002\u6211\u4eec\u4f7f\u7528\u201c\u538b\u529b\u6d4b\u8bd5\u201d\u8fdb\u884c\u7684\u8bc4\u4f30\u663e\u793a\uff0cPLEX \u80fd\u591f\u51c6\u786e\u8bc6\u522b\u6709\u5f71\u54cd\u529b\u7684\u8bcd\u8bed\uff0c\u5f53\u5220\u9664\u8fd9\u4e9b\u8bcd\u8bed\u65f6\uff0c\u5176\u5206\u7c7b\u51c6\u786e\u6027\u7684\u4e0b\u964d\u5e45\u5ea6\u4e0e LIME \u548c SHAP \u76f8\u5f53\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0cPLEX \u5728\u6355\u6349\u5173\u952e\u7279\u5f81\u7684\u5f71\u54cd\u65b9\u9762\u8868\u73b0\u51fa\u66f4\u4f18\u8d8a\u7684\u6027\u80fd\u3002", "conclusion": "PLEX \u6781\u5927\u5730\u52a0\u901f\u4e86\u6587\u672c\u5206\u7c7b\u7684\u89e3\u91ca\u8fc7\u7a0b\uff0c\u5c06\u65f6\u95f4\u548c\u8ba1\u7b97\u5f00\u9500\u5206\u522b\u964d\u4f4e\u4e86\u4e24\u4e2a\u548c\u56db\u4e2a\u6570\u91cf\u7ea7\uff0c\u4e3a\u57fa\u4e8e LLM \u7684\u6587\u672c\u5206\u7c7b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u524d\u666f\u7684\u53ef\u89e3\u91ca\u6027\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.11386", "categories": ["cs.DC", "65M50, 65N50"], "pdf": "https://arxiv.org/pdf/2507.11386", "abs": "https://arxiv.org/abs/2507.11386", "authors": ["Carsten Burstedde", "Mikhail Kirilin", "Robert Kl\u00f6fkorn"], "title": "A new Dune grid for scalable dynamic adaptivity based on the p4est software library", "comment": "27 pages, 8 figures, 2 algorithms", "summary": "In this work we extend the Dune solver library with another grid interface to\nthe open-source p4est software. While Dune already supports about a dozen\ndifferent mesh implementations through its mesh interface Dune-Grid, we\nundertake this new coupling effort in order to inherit p4est's practically\nunlimited MPI scalability as well as its relatively thin data structures, and\nits native support for multi-block (forest) mesh topologies in both 2D and 3D.\n  The presented implementation is compared to an existing implementation based\non Dune-ALUGrid for a variety of challenging test examples in a parallel\nenvironment. The numerical experiments show that the implementation presented\nhere is outperforming Dune-ALUGrid in terms of scalability. In addition, an\nalternative balancing strategy is presented to ensure 2:1 balancing across\nelement faces showing improved performance compared to the existing p4est\nbalance strategy in the numerical examples considered in this work.", "AI": {"tldr": "\u5c06 p4est \u96c6\u6210\u5230 Dune \u4e2d\uff0c\u4ee5\u63d0\u9ad8 MPI \u53ef\u6269\u5c55\u6027\uff0c\u5e76\u5728\u7f51\u683c\u5e73\u8861\u65b9\u9762\u53d6\u5f97\u4e86\u6539\u8fdb\u3002", "motivation": "\u7ee7\u627f p4est \u51e0\u4e4e\u65e0\u9650\u7684 MPI \u53ef\u6269\u5c55\u6027\u3001\u76f8\u5bf9\u8f83thin\u7684\u6570\u636e\u7ed3\u6784\u4ee5\u53ca\u5bf9 2D \u548c 3D \u4e2d\u591a\u5757\uff08\u68ee\u6797\uff09\u7f51\u683c\u62d3\u6251\u7684\u539f\u751f\u652f\u6301\u3002", "method": "\u5c06 p4est \u7684\u7f51\u683c\u63a5\u53e3\u6dfb\u52a0\u5230 Dune \u6c42\u89e3\u5668\u5e93\uff0c\u5e76\u4e0e\u73b0\u6709\u7684 Dune-ALUGrid \u5b9e\u73b0\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "result": "\u5728\u53ef\u6269\u5c55\u6027\u65b9\u9762\uff0c\u65b0\u5b9e\u73b0\u4f18\u4e8e Dune-ALUGrid\u3002\u63d0\u51fa\u7684\u66ff\u4ee3\u5e73\u8861\u7b56\u7565\u5728\u6570\u503c\u793a\u4f8b\u4e2d\u4e5f\u663e\u793a\u51fa\u6bd4\u73b0\u6709 p4est \u5e73\u8861\u7b56\u7565\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u5b9e\u73b0\u4f18\u4e8e Dune-ALUGrid\uff0c\u5728\u53ef\u6269\u5c55\u6027\u65b9\u9762\u8868\u73b0\u66f4\u597d\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u66ff\u4ee3\u7684\u5e73\u8861\u7b56\u7565\uff0c\u4ee5\u786e\u4fdd\u8de8\u5355\u5143\u9762\u7684 2:1 \u5e73\u8861\uff0c\u4e0e\u73b0\u6709\u7684 p4est \u5e73\u8861\u7b56\u7565\u76f8\u6bd4\uff0c\u5728\u6240\u8003\u8651\u7684\u6570\u503c\u793a\u4f8b\u4e2d\u5177\u6709\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2507.11115", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2507.11115", "abs": "https://arxiv.org/abs/2507.11115", "authors": ["Haruya Imamura", "Yasuaki Kobayashi", "Yota Otachi", "Toshiki Saitoh", "Keita Sato", "Asahi Takaoka", "Ryo Yoshinaka"], "title": "Finding Order-Preserving Subgraphs", "comment": null, "summary": "(Induced) Subgraph Isomorphism and Maximum Common (Induced) Subgraph are\nfundamental problems in graph pattern matching and similarity computation. In\ngraphs derived from time-series data or protein structures, a natural total\nordering of vertices often arises from their underlying structure, such as\ntemporal sequences or amino acid sequences. This motivates the study of problem\nvariants that respect this inherent ordering. This paper addresses Ordered\n(Induced) Subgraph Isomorphism (O(I)SI) and its generalization, Maximum Common\nOrdered (Induced) Subgraph (MCO(I)S), which seek to find subgraph isomorphisms\nthat preserve the vertex orderings of two given ordered graphs. Our main\ncontributions are threefold: (1) We prove that these problems remain\nNP-complete even when restricted to small graph classes, such as trees of depth\n2 and threshold graphs. (2) We establish a gap in computational complexity\nbetween OSI and OISI on certain graph classes. For instance, OSI is\npolynomial-time solvable for interval graphs with their interval orderings,\nwhereas OISI remains NP-complete under the same setting. (3) We demonstrate\nthat the tractability of these problems can depend on the vertex ordering. For\nexample, while OISI is NP-complete on threshold graphs, its generalization,\nMCOIS, can be solved in polynomial time if the specific vertex orderings that\ncharacterize the threshold graphs are provided.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u8003\u8651\u9876\u70b9\u6392\u5e8f\u7684\u60c5\u51b5\u4e0b\uff0c\u5b50\u56fe\u540c\u6784\u548c\u6700\u5927\u516c\u5171\u5b50\u56fe\u95ee\u9898\u7684\u8ba1\u7b97\u590d\u6742\u6027\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5373\u4f7f\u5728\u6df1\u5ea6\u4e3a2\u7684\u6811\u548c\u9608\u503c\u56fe\u7b49\u53d7\u9650\u56fe\u7c7b\u4e2d\uff0c\u8fd9\u4e9b\u95ee\u9898\uff08\u7279\u522b\u662fOISI\uff09\u4ecd\u7136\u662fNP\u5b8c\u5168\u7684\u3002\u6b64\u5916\uff0c\u95ee\u9898\u53ef\u89e3\u6027\u53d6\u51b3\u4e8e\u5177\u4f53\u7684\u9876\u70b9\u6392\u5e8f\u65b9\u5f0f\uff0c\u67d0\u4e9b\u6392\u5e8f\u65b9\u5f0f\u53ef\u4ee5\u4f7f\u95ee\u9898\u53d8\u5f97\u5bb9\u6613\u5904\u7406\uff08\u5982MCOIS\u5728\u7279\u5b9a\u6392\u5e8f\u4e0b\u7684\u591a\u9879\u5f0f\u89e3\u6cd5\uff09\u3002", "motivation": "\u7531\u4e8e\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u6216\u86cb\u767d\u8d28\u7ed3\u6784\u7b49\u56fe\u6570\u636e\u4e2d\u901a\u5e38\u5b58\u5728\u81ea\u7136\u7684\u9876\u70b9\u5168\u5e8f\u5173\u7cfb\uff08\u5982\u65f6\u95f4\u5e8f\u5217\u6216\u6c28\u57fa\u9178\u5e8f\u5217\uff09\uff0c\u7814\u7a76\u6709\u5e8f\uff08\u8bf1\u5bfc\uff09\u5b50\u56fe\u540c\u6784\uff08O(I)SI\uff09\u548c\u6700\u5927\u516c\u5171\u6709\u5e8f\uff08\u8bf1\u5bfc\uff09\u5b50\u56fe\uff08MCO(I)S\uff09\u95ee\u9898\uff0c\u5373\u5728\u5bfb\u627e\u5b50\u56fe\u540c\u6784\u65f6\u8981\u4fdd\u6301\u9876\u70b9\u6392\u5e8f\uff0c\u5177\u6709\u91cd\u8981\u7684\u5b9e\u9645\u610f\u4e49\u3002\u8fd9\u4fc3\u4f7f\u7814\u7a76\u8005\u4eec\u53bb\u63a2\u7d22\u548c\u7406\u89e3\u8fd9\u4e9b\u95ee\u9898\u5728\u4e0d\u540c\u56fe\u7c7b\u548c\u4e0d\u540c\u9876\u70b9\u6392\u5e8f\u4e0b\u7684\u8ba1\u7b97\u590d\u6742\u6027\u3002", "method": "\u8be5\u7814\u7a76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u8bc1\u660e\uff0c\u7814\u7a76\u4e86\u6709\u5e8f\uff08\u8bf1\u5bfc\uff09\u5b50\u56fe\u540c\u6784\uff08O(I)SI\uff09\u548c\u6700\u5927\u516c\u5171\u6709\u5e8f\uff08\u8bf1\u5bfc\uff09\u5b50\u56fe\uff08MCO(I)S\uff09\u7684\u8ba1\u7b97\u590d\u6742\u6027\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u7814\u7a76\u8005\u4eec\u8bc1\u660e\u4e86\u8fd9\u4e9b\u95ee\u9898\u5728\u7279\u5b9a\u56fe\u7c7b\uff08\u5982\u6df1\u5ea6\u4e3a2\u7684\u6811\u548c\u9608\u503c\u56fe\uff09\u4e0a\u7684NP\u5b8c\u5168\u6027\uff0c\u5e76\u5206\u6790\u4e86\u4e0d\u540c\u9876\u70b9\u6392\u5e8f\u5bf9\u95ee\u9898\u53ef\u5904\u7406\u6027\u7684\u5f71\u54cd\uff0c\u63ed\u793a\u4e86OSI\u548cOISI\u5728\u8ba1\u7b97\u590d\u6742\u6027\u4e0a\u7684\u5dee\u5f02\u3002", "result": "\u7814\u7a76\u7684\u4e3b\u8981\u6210\u679c\u5305\u62ec\uff1a1. \u8bc1\u660e\u4e86\u5728\u6df1\u5ea6\u4e3a2\u7684\u6811\u548c\u9608\u503c\u56fe\u7b49\u7279\u5b9a\u56fe\u7c7b\u4e0a\uff0cO(I)SI\u548cMCO(I)S\u95ee\u9898\u4ecd\u7136\u662fNP\u5b8c\u5168\u7684\u30022. \u63ed\u793a\u4e86OSI\u548cOISI\u5728\u67d0\u4e9b\u56fe\u7c7b\u4e0a\u7684\u8ba1\u7b97\u590d\u6742\u6027\u5dee\u5f02\uff0c\u4f8b\u5982\uff0cOSI\u5728\u533a\u95f4\u56fe\u7684\u533a\u95f4\u6392\u5e8f\u4e0b\u662f\u591a\u9879\u5f0f\u53ef\u89e3\u7684\uff0c\u800cOISI\u5728\u6b64\u8bbe\u7f6e\u4e0b\u4ecd\u7136\u662fNP\u5b8c\u5168\u7684\u30023. \u8bba\u8bc1\u4e86\u8fd9\u4e9b\u95ee\u9898\u7684\u53ef\u5904\u7406\u6027\u53ef\u80fd\u4f9d\u8d56\u4e8e\u9876\u70b9\u6392\u5e8f\uff0c\u4f8b\u5982\uff0cMCOIS\u5728\u7ed9\u5b9a\u9608\u503c\u56fe\u7684\u7279\u5b9a\u9876\u70b9\u6392\u5e8f\u65f6\u662f\u591a\u9879\u5f0f\u53ef\u89e3\u7684\uff0c\u5c3d\u7ba1OISI\u672c\u8eab\u5728\u9608\u503c\u56fe\u4e0a\u662fNP\u5b8c\u5168\u7684\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u6709\u5e8f\uff08\u8bf1\u5bfc\uff09\u5b50\u56fe\u540c\u6784\uff08O(I)SI\uff09\u53ca\u5176\u6cdb\u5316\u95ee\u9898\u6700\u5927\u516c\u5171\u6709\u5e8f\uff08\u8bf1\u5bfc\uff09\u5b50\u56fe\uff08MCO(I)S\uff09\u5728\u67d0\u4e9b\u56fe\u7c7b\uff08\u5982\u6df1\u5ea6\u4e3a2\u7684\u6811\u548c\u9608\u503c\u56fe\uff09\u4e0a\u4ecd\u7136\u662fNP\u5b8c\u5168\u95ee\u9898\uff0c\u5373\u4f7f\u5728\u8fd9\u4e9b\u9650\u5236\u6761\u4ef6\u4e0b\u4e5f\u662f\u5982\u6b64\u3002\u7814\u7a76\u8fd8\u63ed\u793a\u4e86OSI\u548cOISI\u5728\u8ba1\u7b97\u590d\u6742\u6027\u4e0a\u7684\u5dee\u5f02\uff0c\u4f8b\u5982OSI\u5728\u533a\u95f4\u56fe\u7684\u533a\u95f4\u6392\u5e8f\u4e0b\u662f\u591a\u9879\u5f0f\u53ef\u89e3\u7684\uff0c\u800cOISI\u4ecd\u7136\u662fNP\u5b8c\u5168\u7684\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8868\u660e\u8fd9\u4e9b\u95ee\u9898\u7684\u53ef\u5904\u7406\u6027\u53ef\u80fd\u53d6\u51b3\u4e8e\u9876\u70b9\u6392\u5e8f\uff0c\u4f8b\u5982\uff0c\u867d\u7136OISI\u5728\u9608\u503c\u56fe\u4e0a\u662fNP\u5b8c\u5168\u7684\uff0c\u4f46\u5176\u6cdb\u5316\u95ee\u9898MCOIS\u5728\u7ed9\u5b9a\u7279\u5b9a\u9876\u70b9\u6392\u5e8f\u65f6\u53ef\u4ee5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u89e3\u51b3\u3002"}}
{"id": "2507.11377", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.11377", "abs": "https://arxiv.org/abs/2507.11377", "authors": ["Philipp Wiesner", "Odej Kao"], "title": "Moving Beyond Marginal Carbon Intensity: A Poor Metric for Both Carbon Accounting and Grid Flexibility", "comment": "Presented at the Workshop on Measurements, Modeling, and Metrics for\n  Carbon-Aware Computing (CarbonMetrics) @ ACM SIGMETRICS '25", "summary": "Marginal Carbon Intensity (MCI) has been promoted as an effective metric for\ncarbon-aware computing. Although it is already considered as impractical for\ncarbon accounting purposes, many still view it as valuable when optimizing for\ngrid flexibility by incentivizing electricity usage during curtailment periods.\nIn this statement paper, we argue that MCI is neither reliable nor actionable\nfor either purpose. We outline its fundamental limitations, including\nnon-observability, reliance on opaque predictive models, and the lack of\nverifiability. Moreover, MCI fails to reflect curtailment caused by high-carbon\nsources and offers no insight into the quantity of available excess power. We\nadvocate moving beyond MCI and instead call for research on more actionable\nmetrics, such as direct reporting of excess power, explicit modeling of energy\nstorage and grid stability, and integration with emerging granular renewable\nenergy certificate markets.", "AI": {"tldr": "MCI\u5728\u78b3\u611f\u77e5\u8ba1\u7b97\u548c\u7535\u7f51\u7075\u6d3b\u6027\u65b9\u9762\u90fd\u5b58\u5728\u95ee\u9898\uff0c\u5e94\u7814\u7a76\u66f4\u53ef\u884c\u7684\u66ff\u4ee3\u6307\u6807\u3002", "motivation": "\u8ba8\u8bba\u4e86MCI\u5728\u78b3\u611f\u77e5\u8ba1\u7b97\u548c\u6fc0\u52b1\u7535\u7f51\u7075\u6d3b\u6027\u65b9\u9762\u7684\u4f5c\u7528\uff0c\u5e76\u6307\u51fa\u4e86\u5176\u4e0d\u8db3\u4e4b\u5904\u3002", "method": "\u5206\u6790\u4e86MCI\u5728\u78b3\u611f\u77e5\u8ba1\u7b97\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5305\u62ec\u4e0d\u53ef\u89c2\u6d4b\u6027\u3001\u4f9d\u8d56\u4e0d\u900f\u660e\u7684\u9884\u6d4b\u6a21\u578b\u4ee5\u53ca\u7f3a\u4e4f\u53ef\u9a8c\u8bc1\u6027\u3002", "result": "MCI\u65e0\u6cd5\u53cd\u6620\u9ad8\u78b3\u6e90\u9020\u6210\u7684\u524a\u51cf\uff0c\u4e5f\u65e0\u6cd5\u63d0\u4f9b\u53ef\u7528\u8fc7\u5269\u7535\u529b\u7684\u4fe1\u606f\u3002", "conclusion": "MCI\u5728\u78b3\u611f\u77e5\u8ba1\u7b97\u548c\u7535\u7f51\u7075\u6d3b\u6027\u65b9\u9762\u90fd\u4e0d\u53ef\u9760\u4e14\u4e0d\u53ef\u884c\u3002"}}
{"id": "2507.10595", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10595", "abs": "https://arxiv.org/abs/2507.10595", "authors": ["Yaowen Hu", "Wenxuan Tu", "Yue Liu", "Miaomiao Li", "Wenpeng Lu", "Zhigang Luo", "Xinwang Liu", "Ping Chen"], "title": "Divide-Then-Rule: A Cluster-Driven Hierarchical Interpolator for Attribute-Missing Graphs", "comment": null, "summary": "Deep graph clustering (DGC) for attribute-missing graphs is an unsupervised\ntask aimed at partitioning nodes with incomplete attributes into distinct\nclusters. Addressing this challenging issue is vital for practical\napplications. However, research in this area remains underexplored. Existing\nimputation methods for attribute-missing graphs often fail to account for the\nvarying amounts of information available across node neighborhoods, leading to\nunreliable results, especially for nodes with insufficient known neighborhood.\nTo address this issue, we propose a novel method named Divide-Then-Rule Graph\nCompletion (DTRGC). This method first addresses nodes with sufficient known\nneighborhood information and treats the imputed results as new knowledge to\niteratively impute more challenging nodes, while leveraging clustering\ninformation to correct imputation errors. Specifically, Dynamic Cluster-Aware\nFeature Propagation (DCFP) initializes missing node attributes by adjusting\npropagation weights based on the clustering structure. Subsequently,\nHierarchical Neighborhood-aware Imputation (HNAI) categorizes attribute-missing\nnodes into three groups based on the completeness of their neighborhood\nattributes. The imputation is performed hierarchically, prioritizing the groups\nwith nodes that have the most available neighborhood information. The cluster\nstructure is then used to refine the imputation and correct potential errors.\nFinally, Hop-wise Representation Enhancement (HRE) integrates information\nacross multiple hops, thereby enriching the expressiveness of node\nrepresentations. Experimental results on six widely used graph datasets show\nthat DTRGC significantly improves the clustering performance of various DGC\nmethods under attribute-missing graphs.", "AI": {"tldr": "DTRGC\u901a\u8fc7\u5206\u5c42\u586b\u5145\u548c\u805a\u7c7b\u4fe1\u606f\u7ea0\u9519\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5c5e\u6027\u7f3a\u5931\u56fe\u7684\u805a\u7c7b\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u5c5e\u6027\u7f3a\u5931\u56fe\u586b\u5145\u65b9\u6cd5\u672a\u80fd\u8003\u8651\u8282\u70b9\u90bb\u57df\u4e2d\u53ef\u7528\u4fe1\u606f\u7684\u91cf\u4e0d\u540c\uff0c\u5bfc\u81f4\u7ed3\u679c\u4e0d\u53ef\u9760\uff0c\u5c24\u5176\u5bf9\u4e8e\u90bb\u57df\u4fe1\u606f\u4e0d\u8db3\u7684\u8282\u70b9\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201cDivide-Then-Rule Graph Completion\u201d\uff08DTRGC\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u9996\u5148\u5904\u7406\u5177\u6709\u5145\u8db3\u5df2\u77e5\u90bb\u57df\u4fe1\u606f\u7684\u8282\u70b9\uff0c\u5e76\u5c06\u5176\u586b\u5145\u7ed3\u679c\u4f5c\u4e3a\u65b0\u77e5\u8bc6\u6765\u8fed\u4ee3\u5730\u586b\u5145\u66f4\u96be\u5904\u7406\u7684\u8282\u70b9\uff0c\u540c\u65f6\u5229\u7528\u805a\u7c7b\u4fe1\u606f\u6765\u7ea0\u6b63\u586b\u5145\u9519\u8bef\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u52a8\u6001\u805a\u7c7b\u611f\u77e5\u7279\u5f81\u4f20\u64ad\uff08DCFP\uff09\u901a\u8fc7\u57fa\u4e8e\u805a\u7c7b\u7ed3\u6784\u8c03\u6574\u4f20\u64ad\u6743\u91cd\u6765\u521d\u59cb\u5316\u7f3a\u5931\u7684\u8282\u70b9\u5c5e\u6027\u3002\u968f\u540e\uff0c\u5206\u5c42\u90bb\u57df\u611f\u77e5\u586b\u5145\uff08HNAI\uff09\u6839\u636e\u8282\u70b9\u90bb\u57df\u5c5e\u6027\u7684\u5b8c\u6574\u6027\u5c06\u5176\u5206\u4e3a\u4e09\u7c7b\uff0c\u5e76\u4f18\u5148\u5904\u7406\u90bb\u57df\u4fe1\u606f\u6700\u591a\u7684\u8282\u70b9\u7ec4\u8fdb\u884c\u586b\u5145\u3002\u6700\u540e\uff0cHop-wise Representation Enhancement\uff08HRE\uff09\u6574\u5408\u4e86\u591a\u8df3\u4fe1\u606f\uff0c\u4e30\u5bcc\u4e86\u8282\u70b9\u8868\u793a\u7684\u8868\u8fbe\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDTRGC\u5728\u516d\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u56fe\u6570\u636e\u96c6\u4e0a\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5404\u79cdDGC\u65b9\u6cd5\u5728\u5c5e\u6027\u7f3a\u5931\u56fe\u4e0a\u7684\u805a\u7c7b\u6027\u80fd\u3002", "conclusion": "DTRGC\u65b9\u6cd5\u5728\u5c5e\u6027\u7f3a\u5931\u56fe\u7684\u805a\u7c7b\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u73b0\u6709DGC\u65b9\u6cd5\u7684\u6027\u80fd\u3002"}}
{"id": "2507.10878", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.10878", "abs": "https://arxiv.org/abs/2507.10878", "authors": ["Savva Morozov", "Tobia Marcucci", "Bernhard Paus Graesdal", "Alexandre Amice", "Pablo A. Parrilo", "Russ Tedrake"], "title": "Mixed Discrete and Continuous Planning using Shortest Walks in Graphs of Convex Sets", "comment": "10 pages", "summary": "We study the Shortest-Walk Problem (SWP) in a Graph of Convex Sets (GCS). A\nGCS is a graph where each vertex is paired with a convex program, and each edge\ncouples adjacent programs via additional costs and constraints. A walk in a GCS\nis a sequence of vertices connected by edges, where vertices may be repeated.\nThe length of a walk is given by the cumulative optimal value of the\ncorresponding convex programs. To solve the SWP in GCS, we first synthesize a\npiecewise-quadratic lower bound on the problem's cost-to-go function using\nsemidefinite programming. Then we use this lower bound to guide an\nincremental-search algorithm that yields an approximate shortest walk. We show\nthat the SWP in GCS is a natural language for many mixed discrete-continuous\nplanning problems in robotics, unifying problems that typically require\nspecialized solutions while delivering high performance and computational\nefficiency. We demonstrate this through experiments in collision-free motion\nplanning, skill chaining, and optimal control of hybrid systems.", "AI": {"tldr": "SWP\u5728GCS\u4e2d\u7684\u7814\u7a76\uff0c\u4f7f\u7528SDP\u548c\u589e\u91cf\u641c\u7d22\u627e\u5230\u8fd1\u4f3c\u6700\u77ed\u8def\u5f84\uff0c\u5e76\u6210\u529f\u5e94\u7528\u4e8e\u673a\u5668\u4eba\u89c4\u5212\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u56fe\u8bba\u4e2d\u7684\u6700\u77ed\u8def\u5f84\u95ee\u9898\uff08SWP\uff09\uff0c\u7279\u522b\u662f\u5728\u51f8\u96c6\u56fe\uff08GCS\uff09\u7684\u80cc\u666f\u4e0b\u3002GCS\u56fe\u7684\u6bcf\u4e2a\u9876\u70b9\u4ee3\u8868\u4e00\u4e2a\u51f8\u7a0b\u5e8f\uff0c\u8fb9\u4ee3\u8868\u7a0b\u5e8f\u95f4\u7684\u8026\u5408\u7ea6\u675f\u548c\u6210\u672c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u534adefiniteness programming\uff08SDP\uff09\u5408\u6210\u5206\u6bb5\u4e8c\u6b21\u51fd\u6570\u4f5c\u4e3a\u6210\u672c\u5230\u671f\u51fd\u6570\u4e0b\u754c\u7684\u65b9\u6cd5\uff0c\u5e76\u4f7f\u7528\u8be5\u4e0b\u754c\u5f15\u5bfc\u589e\u91cf\u641c\u7d22\u7b97\u6cd5\u6765\u627e\u5230\u8fd1\u4f3c\u6700\u77ed\u8def\u5f84\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u78b0\u649e\u68c0\u6d4b\u8fd0\u52a8\u89c4\u5212\u3001\u6280\u80fd\u94fe\u63a5\u548c\u6df7\u5408\u7cfb\u7edf\u6700\u4f18\u63a7\u5236\u7b49\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u4e86\u9ad8\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u89e3\u51b3\u6df7\u5408\u79bb\u6563-\u8fde\u7eed\u89c4\u5212\u95ee\u9898\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "SWP\u5728GCS\u4e2d\u662f\u673a\u5668\u4eba\u9886\u57df\u8bb8\u591a\u6df7\u5408\u79bb\u6563-\u8fde\u7eed\u89c4\u5212\u95ee\u9898\u7684\u81ea\u7136\u8bed\u8a00\uff0c\u80fd\u591f\u7edf\u4e00\u901a\u5e38\u9700\u8981\u4e13\u95e8\u89e3\u51b3\u65b9\u6848\u7684\u95ee\u9898\uff0c\u540c\u65f6\u63d0\u4f9b\u9ad8\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2507.11331", "categories": ["cs.AR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11331", "abs": "https://arxiv.org/abs/2507.11331", "authors": ["Jiawei Lin", "Guokai Chen", "Yuanlong Li", "Thomas Bourgeat"], "title": "SystolicAttention: Fusing FlashAttention within a Single Systolic Array", "comment": null, "summary": "Transformer models rely heavily on scaled dot-product attention (SDPA),\ntypically implemented using the FlashAttention algorithm. However, current\nsystolic-array-based accelerators face significant challenges when executing\nFlashAttention. Systolic arrays can only achieve high utilization for\nconsecutive and large matrix multiplications. In contrast, FlashAttention\nrequires frequently interleaved matrix multiplications and softmax operations.\n  The frequent data swaps between the systolic array and external vector units\nresult in low systolic array utilization. This is further exacerbated by the\nfact that softmax involves numerous non-matrix operations, which are not\nwell-suited for systolic arrays. Moreover, the concurrent execution of matrix\nmultiplication on systolic arrays and softmax on vector units leads to register\nfile and SRAM port contention, further degrading performance.\n  To overcome these limitations, we propose FSA, an enhanced systolic array\narchitecture that enables the entire FlashAttention algorithm to run entirely\nwithin a single systolic array, eliminating the need for external vector units.\nAt the core of FSA is SystolicAttention, a novel scheduling algorithm that maps\nFlashAttention operations onto systolic arrays with fine-grained, element-wise\noverlap. This significantly improves array utilization while preserving the\noriginal floating-point operation order to maintain numerical stability.\n  We implement FSA in synthesizable RTL and evaluate its performance against\nstate-of-the-art commercial accelerators. Our results show that FSA achieves\n1.77x and 4.83x higher attention FLOPs/s utilization compared to AWS\nNeuronCore-v2 and Google TPUv5e, respectively, with only about 10% area\noverhead.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.11284", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.11284", "abs": "https://arxiv.org/abs/2507.11284", "authors": ["Mohamed-Amine Lahmeri", "Pouya Fakharizadeh", "V\u00edctor Mustieles-P\u00e9rez", "Martin Vossiek", "Gerhard Krieger", "Robert Schober"], "title": "Sensing Accuracy Optimization for Multi-UAV SAR Interferometry with Data Offloading", "comment": null, "summary": "The integration of unmanned aerial vehicles (UAVs) with radar imaging sensors\nhas revolutionized the monitoring of dynamic and local Earth surface processes\nby enabling high-resolution and cost-effective remote sensing. This paper\ninvestigates the optimization of the sensing accuracy of a UAV swarm deployed\nto perform multi-baseline interferometric synthetic aperture radar (InSAR)\nsensing. In conventional single-baseline InSAR systems, only one synthetic\naperture radar (SAR) antenna pair acquires two SAR images from two distinct\nangles to generate a digital elevation model (DEM) of the target area. However,\nmulti-baseline InSAR extends this concept by aggregating multiple acquisitions\nfrom different angles, thus, significantly enhancing the vertical accuracy of\nthe DEM. The heavy computations required for this process are performed on the\nground and, therefore, the radar data is transmitted in real time to a ground\nstation (GS) via a frequency-division multiple access (FDMA) air-to-ground\nbackhaul link. This work focuses on improving the sensing precision by\nminimizing the height error of the averaged DEM while simultaneously ensuring\nsensing and communication quality-of-service (QoS). To this end, the UAV\nformation, velocity, and communication power allocation are jointly optimized\nusing evolutionary algorithms (EAs). Our approach is benchmarked against\nestablished optimization methods, including genetic algorithms (GAs), simulated\nannealing (SA), and deep reinforcement learning (DRL) techniques. Numerical\nresults show that the proposed solution outperforms these baseline schemes and\nachieves sub-decimeter vertical accuracy in several scenarios. These findings\nunderline the potential of coordinated UAV swarms for delivering high-precision\nand real-time Earth observations through radar interferometry.", "AI": {"tldr": "\u901a\u8fc7\u8fdb\u5316\u7b97\u6cd5\u4f18\u5316\u65e0\u4eba\u673a\u7fa4\u7684\u7f16\u961f\u3001\u901f\u5ea6\u548c\u901a\u4fe1\u529f\u7387\uff0c\u63d0\u9ad8\u4e86InSAR\u4f20\u611f\u7cbe\u5ea6\uff0c\u5b9e\u73b0\u4e86\u4e9a\u5206\u7c73\u7ea7\u5782\u76f4\u7cbe\u5ea6\u3002", "motivation": "\u63d0\u9ad8\u65e0\u4eba\u673a\u7fa4\u8fdb\u884c\u591a\u57fa\u7ebfInSAR\u4f20\u611f\u65f6\u7684\u4f20\u611f\u7cbe\u5ea6\uff0c\u540c\u65f6\u4fdd\u8bc1\u901a\u4fe1\u8d28\u91cf\u3002", "method": "\u5229\u7528\u8fdb\u5316\u7b97\u6cd5\uff08EAs\uff09\u8054\u5408\u4f18\u5316\u65e0\u4eba\u673a\u7f16\u961f\u3001\u901f\u5ea6\u548c\u901a\u4fe1\u529f\u7387\u5206\u914d\uff0c\u4ee5\u6700\u5c0f\u5316\u5e73\u5747DEM\u7684\u9ad8\u5ea6\u8bef\u5dee\uff0c\u540c\u65f6\u786e\u4fdd\u4f20\u611f\u548c\u901a\u4fe1\u7684\u670d\u52a1\u8d28\u91cf\uff08QoS\uff09\u3002", "result": "\u63d0\u51fa\u7684\u89e3\u51b3\u65b9\u6848\u4f18\u4e8e\u4f20\u7edf\u7684\u9057\u4f20\u7b97\u6cd5\uff08GAs\uff09\u3001\u6a21\u62df\u9000\u706b\uff08SA\uff09\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u7b49\u4f18\u5316\u65b9\u6cd5\uff0c\u5728\u591a\u79cd\u573a\u666f\u4e0b\u5b9e\u73b0\u4e86\u4e9a\u5206\u7c73\u7ea7\u7684\u5782\u76f4\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u901a\u8fc7\u4f18\u5316\u65e0\u4eba\u673a\u7f16\u961f\u3001\u901f\u5ea6\u548c\u901a\u4fe1\u529f\u7387\u5206\u914d\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u65e0\u4eba\u673a\u7fa4\u8fdb\u884c\u591a\u57fa\u7ebfInSAR\u4f20\u611f\u65f6\u7684\u4f20\u611f\u7cbe\u5ea6\uff0c\u5e76\u8fbe\u5230\u4e9a\u5206\u7c73\u7ea7\u5782\u76f4\u7cbe\u5ea6\uff0c\u8bc1\u660e\u4e86\u65e0\u4eba\u673a\u7fa4\u5728\u96f7\u8fbe\u5e72\u6d89\u6d4b\u91cf\u4e2d\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u3001\u5b9e\u65f6\u5730\u7403\u89c2\u6d4b\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.10605", "categories": ["cs.LG", "cs.AI", "cs.SI"], "pdf": "https://arxiv.org/pdf/2507.10605", "abs": "https://arxiv.org/abs/2507.10605", "authors": ["Fei Zhao", "Chonggang Lu", "Yue Wang", "Zheyong Xie", "Ziyan Liu", "Haofu Qian", "JianZhao Huang", "Fangcheng Shi", "Zijie Meng", "Hongcheng Guo", "Mingqian He", "Xinze Lyu", "Yiming Lu", "Ziyang Xiang", "Zheyu Ye", "Chengqiang Lu", "Zhe Xu", "Yi Wu", "Yao Hu", "Yan Gao", "Jun Fan", "Xiaolong Jiang", "Weiting Liu", "Boyang Wang", "Shaosheng Cao"], "title": "RedOne: Revealing Domain-specific LLM Post-Training in Social Networking Services", "comment": null, "summary": "As a primary medium for modern information dissemination, social networking\nservices (SNS) have experienced rapid growth, which has proposed significant\nchallenges for platform content management and interaction quality improvement.\nRecently, the development of large language models (LLMs) has offered potential\nsolutions but existing studies focus on isolated tasks, which not only\nencounter diminishing benefit from the data scaling within individual scenarios\nbut also fail to flexibly adapt to diverse real-world context. To address these\nchallenges, we introduce RedOne, a domain-specific LLM designed to break the\nperformance bottleneck of single-task baselines and establish a comprehensive\nfoundation for the SNS. RedOne was developed through a three-stage training\nstrategy consisting of continue pretraining, supervised fine-tuning, and\npreference optimization, using a large-scale real-world dataset. Through\nextensive experiments, RedOne maintains strong general capabilities, and\nachieves an average improvement up to 14.02% across 8 major SNS tasks and 7.56%\nin SNS bilingual evaluation benchmark, compared with base models. Furthermore,\nthrough online testing, RedOne reduced the exposure rate in harmful content\ndetection by 11.23% and improved the click page rate in post-view search by\n14.95% compared with single-tasks finetuned baseline models. These results\nestablish RedOne as a robust domain-specific LLM for SNS, demonstrating\nexcellent generalization across various tasks and promising applicability in\nreal-world scenarios.", "AI": {"tldr": "RedOne\u662f\u4e00\u4e2a\u9488\u5bf9\u793e\u4ea4\u7f51\u7edc\u670d\u52a1\uff08SNS\uff09\u7684\u9886\u57df\u7279\u5b9a\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u4e0a\u8fdb\u884c\u4f18\u5316\u3002\u4e0e\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\u76f8\u6bd4\uff0cRedOne\u5728\u591a\u4e2aSNS\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u5728\u7ebf\u4e0a\u6d4b\u8bd5\u4e2d\u5c55\u73b0\u4e86\u5728\u6709\u5bb3\u5185\u5bb9\u68c0\u6d4b\u548c\u641c\u7d22\u63a8\u8350\u65b9\u9762\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u672a\u80fd\u7075\u6d3b\u9002\u5e94\u591a\u6837\u5316\u7684\u771f\u5b9e\u4e16\u754c\u80cc\u666f\uff0c\u5e76\u4e14\u5728\u6570\u636e\u6269\u5c55\u65b9\u9762\u5b58\u5728\u6536\u76ca\u9012\u51cf\u7684\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u6211\u4eec\u5f15\u5165\u4e86RedOne\uff0c\u4e00\u4e2a\u9886\u57df\u7279\u5b9a\u7684LLM\uff0c\u65e8\u5728\u6253\u7834\u5355\u4efb\u52a1\u57fa\u7ebf\u7684\u6027\u80fd\u74f6\u9888\uff0c\u5e76\u4e3aSNS\u5efa\u7acb\u5168\u9762\u7684\u57fa\u7840\u3002", "method": "RedOne\u6a21\u578b\u901a\u8fc7\u5305\u542b\u6301\u7eed\u9884\u8bad\u7ec3\u3001\u76d1\u7763\u5fae\u8c03\u548c\u504f\u597d\u4f18\u5316\u4e09\u4e2a\u9636\u6bb5\u7684\u7b56\u7565\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u4f7f\u7528\u4e86\u5927\u89c4\u6a21\u7684\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u3002", "result": "RedOne\u57288\u4e2a\u4e3b\u8981\u7684SNS\u4efb\u52a1\u4e0a\u5e73\u5747\u63d0\u5347\u4e8614.02%\uff0c\u5728SNS\u53cc\u8bed\u8bc4\u4f30\u57fa\u51c6\u4e0a\u63d0\u5347\u4e867.56%\u3002\u5728\u7ebf\u6d4b\u8bd5\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u5355\u4efb\u52a1\u5fae\u8c03\u57fa\u7ebf\u6a21\u578b\u76f8\u6bd4\uff0cRedOne\u5728\u6709\u5bb3\u5185\u5bb9\u68c0\u6d4b\u65b9\u9762\u66dd\u5149\u7387\u964d\u4f4e\u4e8611.23%\uff0c\u5728\u5e16\u5b50\u6d4f\u89c8\u641c\u7d22\u65b9\u9762\u7684\u70b9\u51fb\u9875\u9762\u7387\u63d0\u9ad8\u4e8614.95%\u3002", "conclusion": "RedOne\u662f\u4e00\u4e2a\u5f3a\u5927\u7684\u3001\u9762\u5411\u793e\u4ea4\u7f51\u7edc\u670d\u52a1\u7684\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u5927\u6a21\u578b\uff0c\u5b83\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u5177\u6709\u5e7f\u9614\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2507.10889", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.10889", "abs": "https://arxiv.org/abs/2507.10889", "authors": ["Jacob T. Baillie", "Kimo Pressler", "Nick J. Adams", "Faris Horani", "Thom J. Snoeren", "R\u00e9mi Beaulac", "Daniel R. Gamelin"], "title": "Optical Spin Sensing and Metamagnetic Phase Control in the 2D Van der Waals Magnet Yb3+-Doped CrPS4", "comment": "19 pages, 5 figures, plus supporting information", "summary": "The emergence of two-dimensional magnets within the van der Waals toolkit has\nintroduced unprecedented opportunities to develop ultrathin spintronic\ntechnologies. Strong coupling between spin and optical properties in such\nmaterials can further enable novel spin-photonic capabilities of both\nfundamental and technological interest. Here, we investigate the optical and\nspin properties of the air-stable, layered A-type antiferromagnet chromium\nthiophosphate (CrPS4) when doped with Yb3+. We show that the collective spin\nproperties of CrPS4 are encoded in the sharp f-f luminescence of isolated Yb3+\ndopants via strong magnetic superexchange coupling between the two, and that\nspontaneous magnetic ordering in CrPS4 induces large exchange splittings in the\nnarrow Yb3+ f-f photoluminescence features below TN. Spin reorientation in\nCrPS4 via a \"spin-flop\" metamagnetic transition modulates the Yb3+ f-f\nluminescence energies and exchange splittings. This pronounced link between\nspin and optical properties enables the demonstration of optically driven\nspin-flop transitions in CrPS4.", "AI": {"tldr": "\u901a\u8fc7\u63ba\u6742Yb3+\uff0c\u5b9e\u73b0\u4e86\u5bf9CrPS4\u78c1\u6027\u548c\u5149\u5b66\u6027\u8d28\u7684\u8c03\u63a7\uff0c\u5e76\u6210\u529f\u6f14\u793a\u4e86\u5149\u9a71\u52a8\u7684\u81ea\u65cb\u7ffb\u8f6c\u8dc3\u8fc1\u3002", "motivation": "\u63a2\u7d22\u4e8c\u7ef4\u78c1\u6027\u6750\u6599\u5728\u81ea\u65cb\u5149\u5b50\u5b66\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u4ee5\u53ca\u78c1\u6027\u4e0e\u5149\u5b66\u6027\u8d28\u8026\u5408\u7684\u673a\u5236\u3002", "method": "\u7814\u7a76\u4e86\u63ba\u6742Yb3+\u7684CrPS4\u7684\u5149\u5b66\u548c\u81ea\u65cb\u6027\u8d28\uff0c\u7279\u522b\u662fYb3+\u7684f-f\u53d1\u5149\u4e0eCrPS4\u7684\u78c1\u5e8f\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u53d1\u73b0CrPS4\u7684\u78c1\u5e8f\u901a\u8fc7\u8d85\u4ea4\u6362\u8026\u5408\u7f16\u7801\u5728Yb3+\u7684f-f\u53d1\u5149\u4e2d\uff0c\u5e76\u4e14\u81ea\u65cb\u91cd\u53d6\u5411\u53ef\u4ee5\u8c03\u5236Yb3+\u7684\u53d1\u5149\u80fd\u91cf\u548c\u4ea4\u6362\u5288\u88c2\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u63ba\u6742Yb3+\u53ef\u4ee5\u8c03\u8282CrPS4\u7684\u78c1\u6027\u548c\u5149\u5b66\u6027\u8d28\uff0c\u5e76\u5b9e\u73b0\u4e86\u5149\u9a71\u52a8\u7684\u81ea\u65cb\u7ffb\u8f6c\u8dc3\u8fc1\u3002"}}
{"id": "2507.11238", "categories": ["cs.LO", "03B45", "F.4.1"], "pdf": "https://arxiv.org/pdf/2507.11238", "abs": "https://arxiv.org/abs/2507.11238", "authors": ["Philippe Balbiani", "Olivier Gasquet"], "title": "Complexity of some modal logics of density (extended version)", "comment": null, "summary": "By using a selective filtration argument, we prove that the satisfiability\nproblem of the unimodal logic of density is in $EXPTIME$. By using a\ntableau-like approach, we prove that the satisfiability problem of the bimodal\nlogic of weak density is in $PSPACE$.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5c06\u5bc6\u5ea6\u5355\u6a21\u6001\u903b\u8f91\u7684\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u786e\u5b9a\u4e3aEXPTIME\u7c7b\uff0c\u5e76\u5c06\u5f31\u5bc6\u5ea6\u53cc\u6a21\u6001\u903b\u8f91\u7684\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u786e\u5b9a\u4e3aPSPACE\u7c7b\u3002", "motivation": "\u8be5\u7814\u7a76\u7684\u52a8\u673a\u662f\u786e\u5b9a\u5bc6\u5ea6\u5355\u6a21\u6001\u903b\u8f91\u548c\u5f31\u5bc6\u5ea6\u53cc\u6a21\u6001\u903b\u8f91\u7684\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "method": "\u901a\u8fc7\u4f7f\u7528\u9009\u62e9\u6027\u8fc7\u6ee4\u8bba\u8bc1\u8bc1\u660e\u4e86\u5bc6\u5ea6\u5355\u6a21\u6001\u903b\u8f91\u7684\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u5c5e\u4e8eEXPTIME\u7c7b\uff1b\u901a\u8fc7\u4f7f\u7528\u7c7b\u4f3c\u6a21\u578b\u63a8\u8bba\u7684\u65b9\u6cd5\u8bc1\u660e\u4e86\u5f31\u5bc6\u5ea6\u53cc\u6a21\u6001\u903b\u8f91\u7684\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u5c5e\u4e8ePSPACE\u7c7b\u3002", "result": "\u5bc6\u5ea6\u5355\u6a21\u6001\u903b\u8f91\u7684\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u5c5e\u4e8eEXPTIME\u7c7b\uff0c\u5f31\u5bc6\u5ea6\u53cc\u6a21\u6001\u903b\u8f91\u7684\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u5c5e\u4e8ePSPACE\u7c7b\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u5bc6\u5ea6\u5355\u6a21\u6001\u903b\u8f91\u7684\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u5c5e\u4e8eEXPTIME\u7c7b\uff0c\u800c\u5f31\u5bc6\u5ea6\u53cc\u6a21\u6001\u903b\u8f91\u7684\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u5c5e\u4e8ePSPACE\u7c7b\u3002"}}
{"id": "2507.10724", "categories": ["cond-mat.mes-hall", "cond-mat.mtrl-sci", "quant-ph"], "pdf": "https://arxiv.org/pdf/2507.10724", "abs": "https://arxiv.org/abs/2507.10724", "authors": ["N. Beaver", "B. Luo", "S-W. Chiu", "D. A. Bas", "P. J. Shah", "A. Franson", "M. S. Wolf", "M. R. Page", "M. J. Newburger", "L. Caretta", "N. X. Sun", "P. Stevenson"], "title": "Imaging Nonlinear Spin Waves in Magnetoacoustic Devices", "comment": null, "summary": "Magnetoacoustic systems offer promising platforms for next-generation sensors\nand computing applications, but understanding their nonlinear dynamics remains\nchallenging. Here, we use nitrogen vacancy (NV) centers in diamond to spatially\nmap nonlinear magnon scattering processes in FeGaB/LiNbO3 magnetoacoustic\ndevices with sub-micron resolution. We observe highly heterogeneous magnetic\nnoise generation under acoustic driving at 1425 MHz, with responses varying\ndramatically across micron length scales. Time-domain measurements reveal\nthreshold-like nonlinear behavior where NV center spin relaxation rates\nincrease over two orders of magnitude as drive power is increased. These\nfindings reveal microscopic noise sources that limit magnetoacoustic sensor\nperformance while simultaneously demonstrating how acoustic mode engineering\ncould enable selective control of nonlinear magnon processes.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528NV\u4e2d\u5fc3\u7814\u7a76\u4e86\u78c1\u58f0\u5668\u4ef6\u4e2d\u7684\u975e\u7ebf\u6027\u52a8\u529b\u5b66\uff0c\u53d1\u73b0\u4e86\u566a\u58f0\u6e90\u5e76\u63d0\u51fa\u4e86\u63a7\u5236\u65b9\u6cd5\u3002", "motivation": "\u7406\u89e3\u78c1\u58f0\u7cfb\u7edf\u7684\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u5bf9\u4e8e\u5176\u5728\u4e0b\u4e00\u4ee3\u4f20\u611f\u5668\u548c\u8ba1\u7b97\u5e94\u7528\u4e2d\u7684\u53d1\u5c55\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5229\u7528\u91d1\u521a\u77f3\u4e2d\u7684\u6c2e\u7a7a\u4f4d\uff08NV\uff09\u4e2d\u5fc3\uff0c\u5bf9FeGaB/LiNbO3\u78c1\u58f0\u5668\u4ef6\u4e2d\u7684\u975e\u7ebf\u6027\u78c1\u7574\u6563\u5c04\u8fc7\u7a0b\u8fdb\u884c\u4e9a\u5fae\u7c73\u7ea7\u7a7a\u95f4\u5206\u8fa8\u6210\u50cf\u3002", "result": "\u57281425 MHz\u58f0\u5b66\u9a71\u52a8\u4e0b\uff0c\u89c2\u5bdf\u5230\u9ad8\u5ea6\u5f02\u8d28\u7684\u78c1\u566a\u58f0\u4ea7\u751f\uff0c\u54cd\u5e94\u5728\u5fae\u7c73\u5c3a\u5ea6\u4e0a\u5448\u73b0\u663e\u8457\u5dee\u5f02\u3002\u65f6\u95f4\u57df\u6d4b\u91cf\u663e\u793a\uff0c\u968f\u7740\u9a71\u52a8\u529f\u7387\u7684\u589e\u52a0\uff0cNV\u4e2d\u5fc3\u81ea\u65cb\u5f1b\u8c6b\u7387\u589e\u52a0\u4e86\u4e24\u4e2a\u6570\u91cf\u7ea7\uff0c\u8868\u73b0\u51fa\u9608\u503c\u72b6\u7684\u975e\u7ebf\u6027\u884c\u4e3a\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u9650\u5236\u78c1\u58f0\u4f20\u611f\u5668\u6027\u80fd\u7684\u5fae\u89c2\u566a\u58f0\u6e90\uff0c\u5e76\u5c55\u793a\u4e86\u58f0\u5b66\u6a21\u5f0f\u5de5\u7a0b\u5982\u4f55\u5b9e\u73b0\u5bf9\u975e\u7ebf\u6027\u78c1\u7574\u8fc7\u7a0b\u7684\u9009\u62e9\u6027\u63a7\u5236\u3002"}}
{"id": "2507.10688", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2507.10688", "abs": "https://arxiv.org/abs/2507.10688", "authors": ["Cheng Wang", "Zhi-Cheng Yang", "Tianci Zhou", "Xiao Chen"], "title": "Magic transition in monitored free fermion dynamics", "comment": "12 pages, 8 figures", "summary": "We investigate magic and its connection to entanglement in 1+1 dimensional\nrandom free fermion circuits, with a focus on hybrid free fermion dynamics that\ncan exhibit an entanglement phase transition. To quantify magic, we use the\nStabilizer R\\'enyi Entropy (SRE), which we compute numerically via a perfect\nsampling algorithm. We show that although the SRE remains extensive as the\nsystem transitions from a critical phase to an area-law (disentangled) phase,\nthe structure of magic itself undergoes a delocalization phase transition. This\ntransition is characterized using the bipartite stabilizer mutual information,\nwhich exhibits the same scaling behavior as entanglement entropy: logarithmic\nscaling in the critical phase and a finite constant in the area-law phase.\nAdditionally, we explore the dynamics of SRE. While the total SRE becomes\nextensive in $O(1)$ time, we find that in the critical phase, the relaxation\ntime to the steady-state value is parameterically longer than that in generic\nrandom circuits. The relaxation follows a universal form, with a relaxation\ntime that grows linearly with the system size, providing further evidence for\nthe critical nature of the phase.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u7279\u5b9a\u7684\u91cf\u5b50\u7535\u8def\u6a21\u578b\u4e2d\uff0c\u9b54\u529b\u4e0e\u7ea0\u7f20\u4e4b\u95f4\u7684\u5173\u7cfb\u5728\u76f8\u53d8\u8fc7\u7a0b\u4e2d\u4f1a\u53d1\u751f\u53d8\u5316\uff0c\u8868\u73b0\u4e3a\u9b54\u529b\u7ed3\u6784\u7684\u975e\u5c40\u57df\u5316\u76f8\u53d8\uff0c\u5e76\u4e14\u5176\u52a8\u529b\u5b66\u884c\u4e3a\u5177\u6709\u7279\u6b8a\u7684\u5f1b\u8c6b\u7279\u6027\u3002", "motivation": "\u8be5\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u9b54\u529b\u4e0e\u7ea0\u7f20\u57281+1\u7ef4\u968f\u673a\u81ea\u7531\u8d39\u7c73\u5b50\u7535\u8def\u4e2d\u7684\u8054\u7cfb\uff0c\u7279\u522b\u5173\u6ce8\u80fd\u591f\u8868\u73b0\u51fa\u7ea0\u7f20\u76f8\u53d8\u7684\u6df7\u5408\u81ea\u7531\u8d39\u7c73\u5b50\u52a8\u529b\u5b66\u3002", "method": "\u8be5\u7814\u7a76\u4f7f\u7528\u7a33\u5b9a\u91cfR\u00e9nyi\u71b5\uff08SRE\uff09\u6765\u91cf\u5316\u9b54\u529b\uff0c\u5e76\u901a\u8fc7\u5b8c\u7f8e\u91c7\u6837\u7b97\u6cd5\u8fdb\u884c\u6570\u503c\u8ba1\u7b97\u3002\u540c\u65f6\uff0c\u5229\u7528\u4e8c\u5206\u7a33\u5b9a\u4e92\u4fe1\u606f\u6765\u8868\u5f81\u9b54\u529b\u7ed3\u6784\u7684\u975e\u5c40\u57df\u5316\u76f8\u53d8\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0cSRE\u5728\u7cfb\u7edf\u4ece\u4e34\u754c\u76f8\u8fc7\u6e21\u5230\u9762\u79ef\u5b9a\u5f8b\uff08\u975e\u7ea0\u7f20\uff09\u76f8\u65f6\u4fdd\u6301\u5e7f\u6cdb\u3002\u7136\u800c\uff0c\u9b54\u529b\u7ed3\u6784\u672c\u8eab\u7ecf\u5386\u4e86\u4e00\u4e2a\u975e\u5c40\u57df\u5316\u76f8\u53d8\uff0c\u8be5\u76f8\u53d8\u53ef\u4ee5\u901a\u8fc7\u4e8c\u5206\u7a33\u5b9a\u4e92\u4fe1\u606f\u6765\u8868\u5f81\uff0c\u5176\u7f29\u653e\u884c\u4e3a\u4e0e\u7ea0\u7f20\u71b5\u76f8\u4f3c\u3002\u6b64\u5916\uff0cSRE\u7684\u52a8\u529b\u5b66\u8868\u73b0\u51fa\u4e34\u754c\u76f8\u7684\u5f1b\u8c6b\u65f6\u95f4\u6bd4\u4e00\u822c\u968f\u673a\u7535\u8def\u66f4\u957f\uff0c\u5e76\u4e14\u968f\u7cfb\u7edf\u5c3a\u5bf8\u7ebf\u6027\u589e\u957f\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u57281+1\u7ef4\u968f\u673a\u81ea\u7531\u8d39\u7c73\u5b50\u7535\u8def\u4e2d\uff0c\u867d\u7136\u7cfb\u7edf\u7684\u7ea0\u7f20\u71b5\u5728\u76f8\u53d8\u4e2d\u4fdd\u6301\u5e7f\u6cdb\uff0c\u4f46\u9b54\u529b\uff08magic\uff09\u7684\u7ed3\u6784\u4f1a\u7ecf\u5386\u4e00\u4e2a\u975e\u5c40\u57df\u5316\u76f8\u53d8\uff0c\u8fd9\u53ef\u4ee5\u901a\u8fc7\u4e8c\u5206\u7a33\u5b9a\u4e92\u4fe1\u606f\u6765\u8868\u5f81\uff0c\u5e76\u4e14\u5176\u7f29\u653e\u884c\u4e3a\u4e0e\u7ea0\u7f20\u71b5\u76f8\u4f3c\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u63ed\u793a\u4e86SRE\u7684\u52a8\u529b\u5b66\u7279\u6027\uff0c\u5728\u4e34\u754c\u76f8\u4e2d\uff0c\u5176\u5f1b\u8c6b\u5230\u7a33\u6001\u7684\u65f6\u95f4\u6bd4\u4e00\u822c\u7684\u968f\u673a\u7535\u8def\u957f\uff0c\u5e76\u4e14\u968f\u7cfb\u7edf\u5c3a\u5bf8\u7ebf\u6027\u589e\u957f\u3002"}}
{"id": "2507.10844", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10844", "abs": "https://arxiv.org/abs/2507.10844", "authors": ["Furkan Mumcu", "Michael J. Jones", "Anoop Cherian", "Yasin Yilmaz"], "title": "LLM-Guided Agentic Object Detection for Open-World Understanding", "comment": null, "summary": "Object detection traditionally relies on fixed category sets, requiring\ncostly re-training to handle novel objects. While Open-World and\nOpen-Vocabulary Object Detection (OWOD and OVOD) improve flexibility, OWOD\nlacks semantic labels for unknowns, and OVOD depends on user prompts, limiting\nautonomy. We propose an LLM-guided agentic object detection (LAOD) framework\nthat enables fully label-free, zero-shot detection by prompting a Large\nLanguage Model (LLM) to generate scene-specific object names. These are passed\nto an open-vocabulary detector for localization, allowing the system to adapt\nits goals dynamically. We introduce two new metrics, Class-Agnostic Average\nPrecision (CAAP) and Semantic Naming Average Precision (SNAP), to separately\nevaluate localization and naming. Experiments on LVIS, COCO, and COCO-OOD\nvalidate our approach, showing strong performance in detecting and naming novel\nobjects. Our method offers enhanced autonomy and adaptability for open-world\nunderstanding.", "AI": {"tldr": "\u63d0\u51faLAOD\u6846\u67b6\uff0c\u5229\u7528LLM\u751f\u6210\u5bf9\u8c61\u540d\u79f0\uff0c\u5b9e\u73b0\u65e0\u9700\u6807\u7b7e\u7684\u96f6\u6837\u672c\u68c0\u6d4b\uff0c\u63d0\u9ad8\u4e86\u81ea\u4e3b\u6027\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u5bf9\u8c61\u68c0\u6d4b\u4f9d\u8d56\u4e8e\u56fa\u5b9a\u7684\u7c7b\u522b\u96c6\uff0c\u5904\u7406\u65b0\u5bf9\u8c61\u9700\u8981\u91cd\u65b0\u8bad\u7ec3\u3002\u867d\u7136OWOD\u548cOVOD\u63d0\u9ad8\u4e86\u7075\u6d3b\u6027\uff0c\u4f46OWOD\u7f3a\u4e4f\u672a\u77e5\u5bf9\u8c61\u7684\u8bed\u4e49\u6807\u7b7e\uff0cOVOD\u4f9d\u8d56\u7528\u6237\u63d0\u793a\uff0c\u9650\u5236\u4e86\u81ea\u4e3b\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLAOD\uff08LLM-guided agentic object detection\uff09\u7684\u6846\u67b6\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u573a\u666f\u7279\u5b9a\u7684\u5bf9\u8c61\u540d\u79f0\uff0c\u5e76\u5c06\u5176\u8f93\u5165\u5230\u5f00\u653e\u8bcd\u6c47\u68c0\u6d4b\u5668\u4e2d\u8fdb\u884c\u5b9a\u4f4d\uff0c\u5b9e\u73b0\u4e86\u5b8c\u5168\u65e0\u9700\u6807\u7b7e\u7684\u96f6\u6837\u672c\u68c0\u6d4b\u3002", "result": "\u901a\u8fc7\u5728LVIS\u3001COCO\u548cCOCO-OOD\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u8be5\u65b9\u6cd5\u5728\u68c0\u6d4b\u548c\u547d\u540d\u65b0\u5bf9\u8c61\u65b9\u9762\u8868\u73b0\u5f3a\u52b2\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684LAOD\u6846\u67b6\u901a\u8fc7\u63d0\u793aLLM\u751f\u6210\u573a\u666f\u7279\u5b9a\u7684\u5bf9\u8c61\u540d\u79f0\uff0c\u5b9e\u73b0\u4e86\u5b8c\u5168\u65e0\u9700\u6807\u7b7e\u7684\u96f6\u6837\u672c\u68c0\u6d4b\uff0c\u5e76\u80fd\u52a8\u6001\u8c03\u6574\u76ee\u6807\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u5f00\u653e\u4e16\u754c\u7406\u89e3\u7684\u81ea\u4e3b\u6027\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2507.10750", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10750", "abs": "https://arxiv.org/abs/2507.10750", "authors": ["Pandu Devarakota", "Nicolas Tsesmetzis", "Faruk O. Alpak", "Apurva Gala", "Detlef Hohl"], "title": "AI and the Net-Zero Journey: Energy Demand, Emissions, and the Potential for Transition", "comment": "Technical article to be submitted to Data Centric Engineering Journal", "summary": "Thanks to the availability of massive amounts of data, computing resources,\nand advanced algorithms, AI has entered nearly every sector. This has sparked\nsignificant investment and interest, particularly in building data centers with\nthe necessary hardware and software to develop and operate AI models and\nAI-based workflows. In this technical review article, we present energy\nconsumption scenarios of data centers and impact on GHG emissions, considering\nboth near-term projections (up to 2030) and long-term outlook (2035 and\nbeyond). We address the quintessential question of whether AI will have a net\npositive, neutral, or negative impact on CO2 emissions by 2035. Additionally,\nwe discuss AI's potential to automate, create efficient and disruptive\nworkflows across various fields related to energy production, supply and\nconsumption. In the near-term scenario, the growing demand for AI will likely\nstrain computing resources, lead to increase in electricity consumption and\ntherefore associated CO2 emissions. This is due to the power-hungry nature of\nbig data centers and the requirements for training and running of large and\ncomplex AI models, as well as the penetration of AI assistant search and\napplications for public use. However, the long-term outlook could be more\npromising. AI has the potential to be a game-changer in CO2 reduction. Its\nability to further automate and optimize processes across industries, from\nenergy production to logistics, could significantly decrease our carbon\nfootprint. This positive impact is anticipated to outweigh the initial\nemissions bump, creating value for businesses and society in areas where\ntraditional solutions have fallen short. In essence, AI might cause some\ninitial growing pains for the environment, but it has the potential to support\nclimate mitigation efforts.", "AI": {"tldr": "AI\u5728\u77ed\u671f\u5185\u4f1a\u589e\u52a0\u78b3\u6392\u653e\uff0c\u4f46\u957f\u671f\u6765\u770b\uff0c\u901a\u8fc7\u4f18\u5316\u80fd\u6e90\u5229\u7528\uff0cAI\u53ef\u4ee5\u5927\u5e45\u51cf\u5c11\u78b3\u6392\u653e\uff0c\u6700\u7ec8\u5bf9\u6c14\u5019\u4ea7\u751f\u79ef\u6781\u5f71\u54cd\u3002", "motivation": "\u8bc4\u4f30AI\u5728\u53d1\u5c55\u548c\u8fd0\u8425\u8fc7\u7a0b\u4e2d\u5bf9\u6570\u636e\u4e2d\u5fc3\u80fd\u6e90\u6d88\u8017\u548c\u6e29\u5ba4\u6c14\u4f53\u6392\u653e\u7684\u5f71\u54cd\uff0c\u5e76\u63a2\u8ba8AI\u5728\u80fd\u6e90\u751f\u4ea7\u3001\u4f9b\u5e94\u548c\u6d88\u8d39\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u4ee5\u89e3\u51b3AI\u5bf9\u6c14\u5019\u53d8\u5316\u7684\u51c0\u6548\u5e94\u8fd9\u4e00\u6838\u5fc3\u95ee\u9898\u3002", "method": "\u672c\u6587\u662f\u4e00\u7bc7\u6280\u672f\u7efc\u8ff0\u6587\u7ae0\uff0c\u901a\u8fc7\u5206\u6790\u6570\u636e\u4e2d\u5fc3\u7684\u80fd\u6e90\u6d88\u8017\u60c5\u666f\u548c\u6e29\u5ba4\u6c14\u4f53\u6392\u653e\u5f71\u54cd\uff0c\u5e76\u7ed3\u5408\u8fd1\u671f\uff08\u81f32030\u5e74\uff09\u548c\u957f\u671f\uff082035\u5e74\u53ca\u4ee5\u540e\uff09\u7684\u9884\u6d4b\uff0c\u63a2\u8ba8AI\u5bf9\u4e8c\u6c27\u5316\u78b3\u6392\u653e\u7684\u51c0\u6548\u5e94\uff0c\u5e76\u8ba8\u8bbaAI\u5728\u80fd\u6e90\u9886\u57df\u7684\u81ea\u52a8\u5316\u548c\u6548\u7387\u63d0\u5347\u6f5c\u529b\u3002", "result": "\u8fd1\u671f\u9884\u6d4b\u663e\u793a\uff0cAI\u9700\u6c42\u589e\u957f\u5c06\u5bfc\u81f4\u7535\u529b\u6d88\u8017\u548c\u76f8\u5173\u4e8c\u6c27\u5316\u78b3\u6392\u653e\u589e\u52a0\u3002\u7136\u800c\uff0c\u957f\u671f\u6765\u770b\uff0cAI\u901a\u8fc7\u81ea\u52a8\u5316\u548c\u4f18\u5316\u5404\u884c\u4e1a\u6d41\u7a0b\uff08\u4ece\u80fd\u6e90\u751f\u4ea7\u5230\u7269\u6d41\uff09\uff0c\u6709\u6f5c\u529b\u663e\u8457\u964d\u4f4e\u78b3\u8db3\u8ff9\uff0c\u5176\u79ef\u6781\u5f71\u54cd\u9884\u8ba1\u5c06\u8d85\u8fc7\u521d\u671f\u7684\u6392\u653e\u589e\u957f\u3002", "conclusion": "\u867d\u7136AI\u5728\u77ed\u671f\u5185\u53ef\u80fd\u56e0\u6570\u636e\u4e2d\u5fc3\u548c\u6a21\u578b\u8bad\u7ec3\u7684\u7535\u529b\u9700\u6c42\u800c\u589e\u52a0\u78b3\u6392\u653e\uff0c\u4f46\u4ece\u957f\u8fdc\u6765\u770b\uff0cAI\u6709\u6f5c\u529b\u901a\u8fc7\u4f18\u5316\u80fd\u6e90\u751f\u4ea7\u3001\u4f9b\u5e94\u94fe\u548c\u6d88\u8d39\u6765\u5927\u5e45\u51cf\u5c11\u78b3\u6392\u653e\uff0c\u5176\u79ef\u6781\u5f71\u54cd\u6709\u671b\u62b5\u6d88\u521d\u59cb\u7684\u589e\u957f\uff0c\u4ece\u800c\u652f\u6301\u6c14\u5019\u51cf\u7f13\u5de5\u4f5c\u3002"}}
{"id": "2507.10599", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10599", "abs": "https://arxiv.org/abs/2507.10599", "authors": ["Bo Zhao", "Maya Okawa", "Eric J. Bigelow", "Rose Yu", "Tomer Ullman", "Ekdeep Singh Lubana", "Hidenori Tanaka"], "title": "Emergence of Hierarchical Emotion Organization in Large Language Models", "comment": null, "summary": "As large language models (LLMs) increasingly power conversational agents,\nunderstanding how they model users' emotional states is critical for ethical\ndeployment. Inspired by emotion wheels -- a psychological framework that argues\nemotions organize hierarchically -- we analyze probabilistic dependencies\nbetween emotional states in model outputs. We find that LLMs naturally form\nhierarchical emotion trees that align with human psychological models, and\nlarger models develop more complex hierarchies. We also uncover systematic\nbiases in emotion recognition across socioeconomic personas, with compounding\nmisclassifications for intersectional, underrepresented groups. Human studies\nreveal striking parallels, suggesting that LLMs internalize aspects of social\nperception. Beyond highlighting emergent emotional reasoning in LLMs, our\nresults hint at the potential of using cognitively-grounded theories for\ndeveloping better model evaluations.", "AI": {"tldr": "\u7814\u7a76LLMs\u5982\u4f55\u6a21\u62df\u7528\u6237\u60c5\u7eea\u72b6\u6001\uff0c\u53d1\u73b0LLMs\u5177\u6709\u60c5\u7eea\u5c42\u6b21\u7ed3\u6784\u4e14\u4f1a\u5185\u5316\u793e\u4f1a\u8ba4\u77e5\uff0c\u4f46\u5728\u60c5\u7eea\u8bc6\u522b\u65b9\u9762\u5b58\u5728\u5bf9\u5f31\u52bf\u7fa4\u4f53\u7684\u504f\u5dee\u3002", "motivation": "\u4e3a\u4e86\u80fd\u591f\u7b26\u5408\u4f26\u7406\u5730\u90e8\u7f72LLMs\u9a71\u52a8\u7684\u5bf9\u8bdd\u4ee3\u7406\uff0c\u7406\u89e3\u5b83\u4eec\u5982\u4f55\u6a21\u62df\u7528\u6237\u7684\u60c5\u7eea\u72b6\u6001\u81f3\u5173\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6a21\u578b\u8f93\u51fa\u4e2d\u7684\u6982\u7387\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u5c06\u5176\u4e0e\u5fc3\u7406\u5b66\u4e2d\u7684\u60c5\u7eea\u8f6e\u7406\u8bba\u8fdb\u884c\u6bd4\u8f83\uff0c\u6765\u7814\u7a76LLMs\u5982\u4f55\u6a21\u62df\u7528\u6237\u7684\u60c5\u7eea\u72b6\u6001\u3002\u6b64\u5916\uff0c\u8fd8\u8fdb\u884c\u4e86\u4eba\u7c7b\u7814\u7a76\u4ee5\u9a8c\u8bc1LLMs\u7684\u53d1\u73b0\u3002", "result": "LLMs\u4f1a\u81ea\u7136\u5730\u5f62\u6210\u4e0e\u4eba\u7c7b\u5fc3\u7406\u6a21\u578b\u4e00\u81f4\u7684\u60c5\u7eea\u5c42\u6b21\u6811\u3002\u7814\u7a76\u8fd8\u53d1\u73b0\uff0cLLMs\u5728\u60c5\u7eea\u8bc6\u522b\u65b9\u9762\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\uff0c\u5bf9\u5f31\u52bf\u7fa4\u4f53\u7684\u8bef\u5206\u7c7b\u4f1a\u52a0\u5267\u3002\u4eba\u7c7b\u7814\u7a76\u8868\u660eLLMs\u4f1a\u5185\u5316\u793e\u4f1a\u8ba4\u77e5\u3002", "conclusion": "LLMs\u4f1a\u5185\u5316\u793e\u4f1a\u8ba4\u77e5\uff0c\u5e76\u8868\u73b0\u51fa\u4e0e\u4eba\u7c7b\u76f8\u4f3c\u7684\u60c5\u7eea\u5c42\u6b21\u7ed3\u6784\u3002\u6a21\u578b\u89c4\u6a21\u8d8a\u5927\uff0c\u60c5\u7eea\u5c42\u6b21\u7ed3\u6784\u8d8a\u590d\u6742\u3002\u7136\u800c\uff0c\u5728\u8de8\u793e\u4f1a\u7ecf\u6d4e\u7fa4\u4f53\u7684\u60c5\u7eea\u8bc6\u522b\u65b9\u9762\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\uff0c\u5bf9\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u7fa4\u4f53\u7684\u8bef\u5206\u7c7b\u4f1a\u52a0\u5267\u3002"}}
{"id": "2507.11417", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2507.11417", "abs": "https://arxiv.org/abs/2507.11417", "authors": ["Miray \u00d6zcan", "Philipp Wiesner", "Philipp Wei\u00df", "Odej Kao"], "title": "Quantifying the Energy Consumption and Carbon Emissions of LLM Inference via Simulations", "comment": "Presented at the Workshop on Performance and Energy Efficiency in\n  Concurrent and Distributed Systems (PECS) at Euro-PAR'25", "summary": "The environmental impact of Large Language Models (LLMs) is rising\nsignificantly, with inference now accounting for more than half of their total\nlifecycle carbon emissions. However, existing simulation frameworks, which are\nincreasingly used to determine efficient LLM deployments, lack any concept of\npower and, therefore, cannot accurately estimate inference-related emissions.\nWe present a simulation framework to assess the energy and carbon implications\nof LLM inference under varying deployment setups. First, we extend a\nhigh-fidelity LLM inference simulator with a GPU power model that estimates\npower consumption based on utilization metrics, enabling analysis across\nconfigurations like batch size, sequence length, and model parallelism. Second,\nwe integrate simulation outputs into an energy system co-simulation environment\nto quantify carbon emissions under specific grid conditions and explore the\npotential of carbon-aware scheduling. Through scenario-based analysis, our\nframework reveals how inference parameters affect energy demand and carbon\nfootprint, demonstrates a renewable offset potential of up to 69.2% in an\nillustrative deployment case, and provides a foundation for future carbon-aware\ninference infrastructure design.", "AI": {"tldr": "LLM \u63a8\u7406\u7684\u78b3\u6392\u653e\u6b63\u5728\u589e\u52a0\uff0c\u4f46\u73b0\u6709\u6a21\u62df\u6846\u67b6\u65e0\u6cd5\u51c6\u786e\u4f30\u7b97\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b GPU \u529f\u8017\u6a21\u578b\u548c\u80fd\u6e90\u7cfb\u7edf\u8054\u5408\u4eff\u771f\u73af\u5883\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30 LLM \u63a8\u7406\u7684\u80fd\u6e90\u548c\u78b3\u5f71\u54cd\uff0c\u5e76\u5c55\u793a\u4e86\u78b3\u611f\u77e5\u8c03\u5ea6\u7684\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709 LLM \u90e8\u7f72\u7684\u4eff\u771f\u6846\u67b6\u7f3a\u4e4f\u5bf9\u529f\u8017\u7684\u8003\u91cf\uff0c\u65e0\u6cd5\u51c6\u786e\u4f30\u7b97\u63a8\u7406\u76f8\u5173\u7684\u6392\u653e\uff0c\u800c\u63a8\u7406\u5360 LLM \u751f\u547d\u5468\u671f\u78b3\u6392\u653e\u7684\u4e00\u534a\u4ee5\u4e0a\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b GPU \u529f\u8017\u6a21\u578b\u548c\u80fd\u6e90\u7cfb\u7edf\u8054\u5408\u4eff\u771f\u73af\u5883\u7684\u4eff\u771f\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30 LLM \u63a8\u7406\u5728\u4e0d\u540c\u90e8\u7f72\u8bbe\u7f6e\u4e0b\u7684\u80fd\u6e90\u548c\u78b3\u5f71\u54cd\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u5206\u6790\u4e0d\u540c\u914d\u7f6e\uff08\u5982\u6279\u5904\u7406\u5927\u5c0f\u3001\u5e8f\u5217\u957f\u5ea6\u548c\u6a21\u578b\u5e76\u884c\u6027\uff09\u5bf9\u80fd\u6e90\u9700\u6c42\u548c\u78b3\u8db3\u8ff9\u7684\u5f71\u54cd\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u672a\u6765\u78b3\u611f\u77e5\u63a8\u7406\u57fa\u7840\u8bbe\u65bd\u7684\u8bbe\u8ba1\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u8bf4\u660e\u6027\u90e8\u7f72\u6848\u4f8b\u4e2d\u9ad8\u8fbe 69.2% \u7684\u53ef\u518d\u751f\u80fd\u6e90\u62b5\u6d88\u6f5c\u529b\u3002"}}
{"id": "2507.11236", "categories": ["cs.DS", "cs.LG", "math.PR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.11236", "abs": "https://arxiv.org/abs/2507.11236", "authors": ["Yuchen He", "Zhehan Lei", "Jianan Shao", "Chihao Zhang"], "title": "Improved sampling algorithms and Poincar\u00e9 inequalities for non-log-concave distributions", "comment": null, "summary": "We study the problem of sampling from a distribution $\\mu$ with density\n$\\propto e^{-V}$ for some potential function $V:\\mathbb R^d\\to \\mathbb R$ with\nquery access to $V$ and $\\nabla V$. We start with the following standard\nassumptions:\n  (1) The potential function $V$ is $L$-smooth.\n  (2) The second moment $\\mathbf{E}_{X\\sim \\mu}[\\|X\\|^2]\\leq M$.\n  Recently, He and Zhang (COLT'25) showed that the query complexity of sampling\nfrom such distributions is at least\n$\\left(\\frac{LM}{d\\epsilon}\\right)^{\\Omega(d)}$ where $\\epsilon$ is the desired\naccuracy in total variation distance, and the Poincar\\'e constant can be\narbitrarily large.\n  Meanwhile, another common assumption in the study of diffusion based samplers\n(see e.g., the work of Chen, Chewi, Li, Li, Salim and Zhang (ICLR'23))\nstrengthens the smoothness condition (1) to the following:\n  (1*) The potential function of *every* distribution along the\nOrnstein-Uhlenbeck process starting from $\\mu$ is $L$-smooth.\n  We show that under the assumptions (1*) and (2), the query complexity of\nsampling from $\\mu$ can be $\\mathrm{poly}(L,d)\\cdot\n\\left(\\frac{Ld+M}{\\epsilon^2}\\right)^{\\mathcal{O}(L+1)}$, which is polynomial\nin $d$ and $\\frac{1}{\\epsilon}$ when $L=\\mathcal{O}(1)$ and\n$M=\\mathrm{poly}(d)$. This improves the algorithm with quasi-polynomial query\ncomplexity developed by Huang et al. (COLT'24). Our results imply that the\nseemly moderate strengthening of the smoothness condition (1) to (1*) can lead\nto an exponential gap in the query complexity of sampling algorithms.\n  Moreover, we show that together with the assumption (1*) and the stronger\nmoment assumption that $\\|X\\|$ is $\\lambda$-sub-Gaussian for $X\\sim\\mu$, the\nPoincar\\'e constant of $\\mu$ is at most $\\mathcal{O}(\\lambda)^{2(L+1)}$. As an\napplication of our technique, we obtain improved estimate of the Poincar\\'e\nconstant for mixture of Gaussians with the same covariance.", "AI": {"tldr": "\u7814\u7a76\u6539\u8fdb\u4e86\u4ece\u7279\u5b9a\u5206\u5e03\u91c7\u6837\u7684\u7b97\u6cd5\uff0c\u53d1\u73b0\u66f4\u5f3a\u7684\u5e73\u6ed1\u6027\u6761\u4ef6\u80fd\u6307\u6570\u7ea7\u964d\u4f4e\u91c7\u6837\u590d\u6742\u5ea6\u3002\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\uff0c\u65b0\u7b97\u6cd5\u590d\u6742\u5ea6\u4e3a\u591a\u9879\u5f0f\uff0c\u4f18\u4e8e\u73b0\u6709\u7b97\u6cd5\uff0c\u5e76\u6539\u8fdb\u4e86\u5e9e\u52a0\u83b1\u5e38\u6570\u4f30\u8ba1\u3002", "motivation": "\u8be5\u7814\u7a76\u7684\u52a8\u673a\u662f\u63a2\u7d22\u66f4\u5f3a\u7684\u5e73\u6ed1\u6027\u6761\u4ef6\uff081*\uff09\u5982\u4f55\u5f71\u54cd\u4ece\u5206\u5e03 $\\\\\\mu$\uff08\u5bc6\u5ea6\u4e3a $e^{-V}$\uff09\u91c7\u6837\u7684\u67e5\u8be2\u590d\u6742\u5ea6\u3002\u7814\u7a76\u4eba\u5458\u53d1\u73b0\uff0c\u76f8\u6bd4\u4e8e\u4ec5\u6ee1\u8db3\u6807\u51c6\u5e73\u6ed1\u6027\u6761\u4ef6\uff081\uff09\u7684\u91c7\u6837\u7b97\u6cd5\uff0c\u6ee1\u8db3\uff081*\uff09\u7684\u7b97\u6cd5\u53ef\u4ee5\u83b7\u5f97\u663e\u8457\u7684\u67e5\u8be2\u590d\u6742\u5ea6\u63d0\u5347\uff0c\u4ece\u800c\u6539\u8fdb\u4e86\u73b0\u6709\u7684\u51c6\u591a\u9879\u5f0f\u65f6\u95f4\u91c7\u6837\u7b97\u6cd5\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u5728(1*)\uff08\u6240\u6709 Ornstein-Uhlenbeck \u8fc7\u7a0b\u4e2d\u7684\u5206\u5e03\u90fd\u5177\u6709 L-\u5e73\u6ed1\u6027\uff09\u548c(2)\uff08\u4e8c\u9636\u77e9\u6709\u754c\uff09\u5047\u8bbe\u4e0b\uff0c\u4ece\u5206\u5e03 $\\\\\\mu$\uff08\u5bc6\u5ea6\u4e3a $e^{-V}$\uff09\u91c7\u6837\u7684\u7b97\u6cd5\u3002\u8be5\u7b97\u6cd5\u7684\u67e5\u8be2\u590d\u6742\u5ea6\u4e3a $\\mathrm{poly}(L,d) \\cdot \\left(\frac{Ld+M}{\\epsilon^2}\\right)^{\\mathcal{O}(L+1)}$\uff0c\u5f53 L=O(1) \u4e14 M=poly(d) \u65f6\uff0c\u590d\u6742\u5ea6\u5173\u4e8e d \u548c $1/\\epsilon$ \u662f\u591a\u9879\u5f0f\u7684\u3002", "result": "\u5728\u5047\u8bbe (1*) \u548c (2) \u4e0b\uff0c\u6211\u4eec\u8bc1\u660e\u4e86\u91c7\u6837\u590d\u6742\u5ea6\u53ef\u4ee5\u8fbe\u5230 $\\mathrm{poly}(L,d) \\cdot \\left(\frac{Ld+M}{\\epsilon^2}\\right)^{\\mathcal{O}(L+1)}$\uff0c\u8fd9\u5728 L=O(1) \u548c M=poly(d) \u65f6\uff0c\u76f8\u5bf9\u4e8e d \u548c $1/\\epsilon$ \u662f\u591a\u9879\u5f0f\u7684\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u51c6\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u8bc1\u660e\u4e86\u5728 (1*) \u548c $\\\\\\lambda$-\u6b21\u9ad8\u65af\u5047\u8bbe\u4e0b\uff0c\u5e9e\u52a0\u83b1\u5e38\u6570\u6700\u591a\u4e3a $O(\\\\lambda)^{2(L+1)}$\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u6df7\u5408\u9ad8\u65af\u5206\u5e03\u7684\u5e9e\u52a0\u83b1\u5e38\u6570\u4f30\u8ba1\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u5c06\u5e73\u6ed1\u6027\u6761\u4ef6\u4ece(1)\u589e\u5f3a\u5230(1*)\u53ef\u4ee5\u4f7f\u91c7\u6837\u7b97\u6cd5\u7684\u67e5\u8be2\u590d\u6742\u5ea6\u4ea7\u751f\u6307\u6570\u7ea7\u5dee\u8ddd\u3002\u6b64\u5916\uff0c\u5728(1*)\u548c$\\|X\\|$\u662f $\\lambda$-\u6b21\u9ad8\u65af\u5206\u5e03\u7684\u5047\u8bbe\u4e0b\uff0c$\\\\\\mu$ \u7684\u5e9e\u52a0\u83b1\u5e38\u6570\u6700\u591a\u4e3a $O(\\\\lambda)^{2(L+1)}$\u3002\u4f5c\u4e3a\u8be5\u6280\u672f\u7684\u4e00\u4e2a\u5e94\u7528\uff0c\u6211\u4eec\u83b7\u5f97\u4e86\u6df7\u5408\u9ad8\u65af\u5206\u5e03\uff08\u5177\u6709\u76f8\u540c\u534f\u65b9\u5dee\uff09\u7684\u5e9e\u52a0\u83b1\u5e38\u6570\u7684\u6539\u8fdb\u4f30\u8ba1\u3002"}}
{"id": "2507.11392", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.11392", "abs": "https://arxiv.org/abs/2507.11392", "authors": ["Rahel Rickenbach", "Amon Lahr", "Melanie N. Zeilinger"], "title": "Inverse Optimal Control with Constraint Relaxation", "comment": null, "summary": "Inverse optimal control (IOC) is a promising paradigm for learning and\nmimicking optimal control strategies from capable demonstrators, or gaining a\ndeeper understanding of their intentions, by estimating an unknown objective\nfunction from one or more corresponding optimal control sequences. When\ncomputing estimates from demonstrations in environments with safety-preserving\ninequality constraints, acknowledging their presence in the chosen IOC method\nis crucial given their strong influence on the final control strategy. However,\nsolution strategies capable of considering inequality constraints, such as the\ninverse Karush-Kuhn-Tucker approach, rely on their correct activation and\nfulfillment; a restrictive assumption when dealing with noisy demonstrations.\nTo overcome this problem, we leverage the concept of exact penalty functions\nfor IOC and show preservation of estimation accuracy. Considering noisy\ndemonstrations, we then illustrate how the usage of penalty functions reduces\nthe number of unknown variables and how their approximations enhance the\nestimation method's capacity to account for wrong constraint activations within\na polytopic-constrained environment. The proposed method is evaluated for three\nsystems in simulation, outperforming traditional relaxation approaches for\nnoisy demonstrations.", "AI": {"tldr": "\u5728\u53cd\u5411\u6700\u4f18\u63a7\u5236\uff08IOC\uff09\u4e2d\uff0c\u63d0\u51fa\u4f7f\u7528\u7cbe\u786e\u60e9\u7f5a\u51fd\u6570\u6765\u5904\u7406\u5e26\u566a\u58f0\u6f14\u793a\u4e2d\u7684\u7ea6\u675f\u6fc0\u6d3b\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u4f30\u8ba1\u51c6\u786e\u6027\uff0c\u5e76\u51cf\u5c11\u4e86\u672a\u77e5\u53d8\u91cf\u7684\u6570\u91cf\u3002", "motivation": "\u89e3\u51b3\u5728\u53cd\u5411\u6700\u4f18\u63a7\u5236\uff08IOC\uff09\u4e2d\uff0c\u7531\u4e8e\u5e26\u566a\u58f0\u6f14\u793a\u800c\u5bfc\u81f4\u7684\u53cd\u5411Karush-Kuhn-Tucker\u65b9\u6cd5\u5bf9\u7ea6\u675f\u6fc0\u6d3b\u548c\u6ee1\u8db3\u7684\u4f9d\u8d56\u6027\u95ee\u9898\u3002", "method": "\u5229\u7528\u7cbe\u786e\u60e9\u7f5a\u51fd\u6570\u5904\u7406\u53cd\u5411\u6700\u4f18\u63a7\u5236\uff08IOC\uff09\u4e2d\u7684\u7ea6\u675f\u6fc0\u6d3b\u95ee\u9898\uff0c\u901a\u8fc7\u51cf\u5c11\u672a\u77e5\u53d8\u91cf\u548c\u8fd1\u4f3c\u65b9\u6cd5\u6765\u63d0\u9ad8\u5bf9\u9519\u8bef\u7ea6\u675f\u6fc0\u6d3b\u7684\u5bb9\u7eb3\u80fd\u529b\u3002", "result": "\u5728\u591a\u9762\u4f53\u7ea6\u675f\u73af\u5883\u4e2d\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u901a\u8fc7\u7cbe\u786e\u60e9\u7f5a\u51fd\u6570\u63d0\u9ad8\u4e86\u4f30\u8ba1\u51c6\u786e\u6027\uff0c\u5e76\u51cf\u5c11\u4e86\u672a\u77e5\u53d8\u91cf\u7684\u6570\u91cf\uff0c\u4f18\u4e8e\u4f20\u7edf\u7684\u677e\u5f1b\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u4f7f\u7528\u7cbe\u786e\u60e9\u7f5a\u51fd\u6570\u514b\u670d\u4e86\u5728\u53cd\u5411\u6700\u4f18\u63a7\u5236\uff08IOC\uff09\u4e2d\u5904\u7406\u5e26\u566a\u58f0\u6f14\u793a\u4e2d\u7684\u7ea6\u675f\u6fc0\u6d3b\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u4f30\u8ba1\u7684\u51c6\u786e\u6027\uff0c\u5e76\u51cf\u5c11\u4e86\u672a\u77e5\u53d8\u91cf\u7684\u6570\u91cf\uff0c\u4ece\u800c\u5728\u591a\u9762\u4f53\u7ea6\u675f\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u677e\u5f1b\u65b9\u6cd5\u3002"}}
{"id": "2507.10899", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.10899", "abs": "https://arxiv.org/abs/2507.10899", "authors": ["Wang Zhicheng", "Satoshi Yagi", "Satoshi Yamamori", "Jun Morimoto"], "title": "Object-Centric Mobile Manipulation through SAM2-Guided Perception and Imitation Learning", "comment": null, "summary": "Imitation learning for mobile manipulation is a key challenge in the field of\nrobotic manipulation. However, current mobile manipulation frameworks typically\ndecouple navigation and manipulation, executing manipulation only after\nreaching a certain location. This can lead to performance degradation when\nnavigation is imprecise, especially due to misalignment in approach angles. To\nenable a mobile manipulator to perform the same task from diverse orientations,\nan essential capability for building general-purpose robotic models, we propose\nan object-centric method based on SAM2, a foundation model towards solving\npromptable visual segmentation in images, which incorporates manipulation\norientation information into our model. Our approach enables consistent\nunderstanding of the same task from different orientations. We deploy the model\non a custom-built mobile manipulator and evaluate it on a pick-and-place task\nunder varied orientation angles. Compared to Action Chunking Transformer, our\nmodel maintains superior generalization when trained with demonstrations from\nvaried approach angles. This work significantly enhances the generalization and\nrobustness of imitation learning-based mobile manipulation systems.", "AI": {"tldr": "\u6a21\u4eff\u5b66\u4e60\u5728\u79fb\u52a8\u64cd\u4f5c\u4e2d\u7684\u4e00\u4e2a\u5173\u952e\u6311\u6218\u662f\u5bfc\u822a\u548c\u64cd\u4f5c\u7684\u89e3\u8026\uff0c\u8fd9\u5728\u5bfc\u822a\u4e0d\u7cbe\u786e\u65f6\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5bf9\u8c61\u4e2d\u5fc3\u65b9\u6cd5\uff0c\u5229\u7528SAM2\u6574\u5408\u64cd\u4f5c\u65b9\u5411\u4fe1\u606f\uff0c\u5b9e\u73b0\u4e86\u4ece\u4e0d\u540c\u89c6\u89d2\u5bf9\u540c\u4e00\u4efb\u52a1\u7684\u4e00\u81f4\u6027\u7406\u89e3\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u6bd4Action Chunking Transformer\u5177\u6709\u66f4\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u79fb\u52a8\u64cd\u4f5c\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u5f53\u524d\u7684\u79fb\u52a8\u64cd\u4f5c\u6846\u67b6\u5c06\u5bfc\u822a\u548c\u64cd\u4f5c\u89e3\u8026\uff0c\u4ec5\u5728\u5230\u8fbe\u7279\u5b9a\u4f4d\u7f6e\u540e\u6267\u884c\u64cd\u4f5c\uff0c\u8fd9\u5728\u5bfc\u822a\u4e0d\u7cbe\u786e\uff08\u5c24\u5176\u662f\u5728\u63a5\u8fd1\u89d2\u5ea6\u4e0d\u5bf9\u9f50\u65f6\uff09\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002\u4e3a\u4e86\u8ba9\u79fb\u52a8\u673a\u68b0\u81c2\u80fd\u591f\u4ece\u4e0d\u540c\u65b9\u5411\u6267\u884c\u76f8\u540c\u7684\u4efb\u52a1\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSAM2\u7684\u5bf9\u8c61\u4e2d\u5fc3\u65b9\u6cd5\uff0c\u5c06\u64cd\u4f5c\u65b9\u5411\u4fe1\u606f\u6574\u5408\u5230\u6a21\u578b\u4e2d\uff0c\u4ee5\u5b9e\u73b0\u4ece\u4e0d\u540c\u65b9\u5411\u5bf9\u540c\u4e00\u4efb\u52a1\u7684\u4e00\u81f4\u6027\u7406\u89e3\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u62fe\u53d6\u548c\u653e\u7f6e\u4efb\u52a1\u4e2d\uff0c\u4e0eAction Chunking Transformer\u76f8\u6bd4\uff0c\u5728\u591a\u6837\u5316\u7684\u63a5\u8fd1\u89d2\u5ea6\u8bad\u7ec3\u4e0b\u8868\u73b0\u51fa\u66f4\u4f18\u8d8a\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u4eff\u5b66\u4e60\u5728\u79fb\u52a8\u64cd\u4f5c\u7cfb\u7edf\u4e2d\u7684\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u5f15\u5165\u57fa\u4e8eSAM2\u7684\u5bf9\u8c61\u4e2d\u5fc3\u65b9\u6cd5\uff0c\u5c06\u64cd\u4f5c\u65b9\u5411\u4fe1\u606f\u6574\u5408\u5230\u6a21\u578b\u4e2d\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u4eff\u5b66\u4e60\u5728\u79fb\u52a8\u64cd\u4f5c\u4e2d\u7684\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6846\u67b6\u4e2d\u5bfc\u822a\u4e0e\u64cd\u4f5c\u89e3\u8026\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u3002"}}
{"id": "2507.11506", "categories": ["cs.AR", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11506", "abs": "https://arxiv.org/abs/2507.11506", "authors": ["Yiqi Liu", "Yuqi Xue", "Noelle Crawford", "Jilong Xue", "Jian Huang"], "title": "Elk: Exploring the Efficiency of Inter-core Connected AI Chips with Deep Learning Compiler Techniques", "comment": "This paper is accepted at the 58th IEEE/ACM International Symposium\n  on Microarchitecture (MICRO'25)", "summary": "To meet the increasing demand of deep learning (DL) models, AI chips are\nemploying both off-chip memory (e.g., HBM) and high-bandwidth low-latency\ninterconnect for direct inter-core data exchange. However, it is not easy to\nexplore the efficiency of these inter-core connected AI (ICCA) chips, due to a\nfundamental tussle among compute (per-core execution), communication\n(inter-core data exchange), and I/O (off-chip data access).\n  In this paper, we develop Elk, a DL compiler framework to maximize the\nefficiency of ICCA chips by jointly trading off all the three performance\nfactors discussed above. Elk structures these performance factors into\nconfigurable parameters and forms a global trade-off space in the DL compiler.\nTo systematically explore this space and maximize overall efficiency, Elk\nemploys a new inductive operator scheduling policy and a cost-aware on-chip\nmemory allocation algorithm. It generates globally optimized execution plans\nthat best overlap off-chip data loading and on-chip execution. To examine the\nefficiency of Elk, we build a full-fledged emulator based on a real ICCA chip\nIPU-POD4, and an ICCA chip simulator for sensitivity analysis with different\ninterconnect network topologies. Elk achieves 94% of the ideal roofline\nperformance of ICCA chips on average, showing the benefits of supporting large\nDL models on ICCA chips. We also show Elk's capability of enabling architecture\ndesign space exploration for new ICCA chip development.", "AI": {"tldr": "Elk is a DL compiler that maximizes AI chip efficiency by optimizing compute, communication, and I/O through advanced scheduling and memory allocation, achieving 94% of ideal performance.", "motivation": "The increasing demand for deep learning (DL) models necessitates efficient AI chips that balance compute, communication, and I/O. However, exploring the efficiency of inter-core connected AI (ICCA) chips is challenging due to the inherent trade-offs among these factors.", "method": "Elk, a DL compiler framework, jointly optimizes compute, communication, and I/O by structuring these factors into configurable parameters. It utilizes a novel inductive operator scheduling policy and a cost-aware on-chip memory allocation algorithm to maximize efficiency and generate globally optimized execution plans.", "result": "Elk achieves 94% of the ideal roofline performance on average for ICCA chips. It effectively overlaps off-chip data loading and on-chip execution, supporting large DL models and aiding in the architecture design space exploration for new ICCA chip development.", "conclusion": "Elk achieves 94% of the ideal roofline performance of ICCA chips on average, demonstrating its effectiveness in supporting large DL models on ICCA chips and enabling architecture design space exploration for new ICCA chip development."}}
{"id": "2507.11383", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.11383", "abs": "https://arxiv.org/abs/2507.11383", "authors": ["V S V Sandeep", "Sai Dinesh Kancharana", "Arun Pachai Kannu"], "title": "Sparse Regression Codes exploit Multi-User Diversity without CSI", "comment": null, "summary": "We study sparse regression codes (SPARC) for multiple access channels with\nmultiple receive antennas, in non-coherent flat fading channels. We propose a\nnovel practical decoder, referred to as maximum likelihood matching pursuit\n(MLMP), which greedily finds the support of the codewords of users with partial\nmaximum likelihood metrics. As opposed to the conventional\nsuccessive-cancellation based greedy algorithms, MLMP works as a\nsuccessive-combining energy detector. We also propose MLMP modifications to\nimprove the performance at high code rates. Our studies in short block lengths\nshow that, even without any channel state information, SPARC with MLMP decoder\nachieves multi-user diversity in some scenarios, giving better error\nperformance with multiple users than that of the corresponding single-user\ncase. We also show that SPARC with MLMP performs better than conventional\nsparse recovery algorithms and pilot-aided transmissions with polar codes.", "AI": {"tldr": "SPARC with MLMP decoder shows good performance in multiple access channels, outperforming existing methods.", "motivation": "We study sparse regression codes (SPARC) for multiple access channels with multiple receive antennas, in non-coherent flat fading channels.", "method": "We propose a novel practical decoder, referred to as maximum likelihood matching pursuit (MLMP), which greedily finds the support of the codewords of users with partial maximum likelihood metrics. MLMP works as a successive-combining energy detector. We also propose MLMP modifications to improve the performance at high code rates.", "result": "Our studies in short block lengths show that, even without any channel state information, SPARC with MLMP decoder achieves multi-user diversity in some scenarios.", "conclusion": "SPARC with MLMP decoder achieves multi-user diversity in some scenarios, giving better error performance with multiple users than that of the corresponding single-user case. SPARC with MLMP performs better than conventional sparse recovery algorithms and pilot-aided transmissions with polar codes."}}
{"id": "2507.10810", "categories": ["cs.CL", "cs.SI"], "pdf": "https://arxiv.org/pdf/2507.10810", "abs": "https://arxiv.org/abs/2507.10810", "authors": ["David M. Markowitz", "Samuel Hardman Taylor"], "title": "Testing Hypotheses from the Social Approval Theory of Online Hate: An Analysis of 110 Million Posts from Parler", "comment": null, "summary": "In this paper, we explored how online hate is motivated by receiving social\napproval from others. We specifically examined two central tenets of Walther's\n(2024) social approval theory of online hate: (H1a) more signals of social\napproval on hate messages predicts more subsequent hate messages, and (H1b) as\nsocial approval increases, hate speech messages become more extreme. Using over\n110 million posts from Parler (2018-2021), we observed that the number of\nupvotes a person received on a hate speech post was unassociated with the\namount of hate speech in their next post and posts during the next week, month,\nthree months, and six months. Between-person effects revealed an average\nnegative relationship between social approval and hate speech production at the\npost level, but this relationship was mixed at other time intervals. Social\napproval reinforcement mechanisms of online hate may operate differently on\nniche social media platforms.", "AI": {"tldr": "\u5728\u7ebf\u4ec7\u6068\u8a00\u8bba\u7684\u793e\u4f1a\u8d5e\u8bb8\u7406\u8bba\u5728Parler\u5e73\u53f0\u4e0a\u4e0d\u6210\u7acb\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5728\u7ebf\u4ec7\u6068\u8a00\u8bba\u7684\u52a8\u673a\uff0c\u7279\u522b\u662f\u8003\u5bdf\u793e\u4f1a\u8d5e\u8bb8\u7406\u8bba\u5728\u89e3\u91ca\u7528\u6237\u53d1\u5e03\u4ec7\u6068\u8a00\u8bba\u884c\u4e3a\u4e2d\u7684\u4f5c\u7528\uff0c\u5e76\u68c0\u9a8c\u8be5\u7406\u8bba\u5728\u5c0f\u4f17\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u4e0a\u7684\u9002\u7528\u6027\u3002", "method": "\u672c\u7814\u7a76\u4f7f\u75282018\u5e74\u81f32021\u5e74\u95f4\u4eceParler\u6536\u96c6\u7684\u8d85\u8fc71.11\u4ebf\u6761\u5e16\u5b50\uff0c\u68c0\u9a8c\u4e86Walther\uff082024\uff09\u63d0\u51fa\u7684\u5728\u7ebf\u4ec7\u6068\u7684\u793e\u4f1a\u8d5e\u8bb8\u7406\u8bba\u7684\u4e24\u4e2a\u6838\u5fc3\u89c2\u70b9\uff1a1) \u4ec7\u6068\u8a00\u8bba\u83b7\u5f97\u66f4\u591a\u7684\u793e\u4f1a\u8d5e\u8bb8\u4fe1\u53f7\u4f1a\u9884\u6d4b\u540e\u7eed\u4ea7\u751f\u66f4\u591a\u4ec7\u6068\u8a00\u8bba\uff1b2) \u968f\u7740\u793e\u4f1a\u8d5e\u8bb8\u7684\u589e\u52a0\uff0c\u4ec7\u6068\u8a00\u8bba\u4f1a\u53d8\u5f97\u66f4\u52a0\u6781\u7aef\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u7528\u6237\u5728\u4e00\u4e2a\u4ec7\u6068\u8a00\u8bba\u5e16\u5b50\u4e2d\u83b7\u5f97\u7684\u70b9\u8d5e\u6570\u4e0e\u5176\u4e4b\u540e\u53d1\u5e03\u7684\u4ec7\u6068\u8a00\u8bba\u6570\u91cf\uff08\u5305\u62ec\u4e0b\u4e00\u6761\u5e16\u5b50\u4ee5\u53ca\u4e4b\u540e\u4e00\u5468\u3001\u4e00\u6708\u3001\u4e09\u6708\u3001\u516d\u4e2a\u6708\u5185\u7684\u5e16\u5b50\uff09\u6ca1\u6709\u5173\u8054\uff08H1a\u4e0d\u6210\u7acb\uff09\u3002\u540c\u65f6\uff0c\u7814\u7a76\u4e5f\u672a\u53d1\u73b0\u793e\u4f1a\u8d5e\u8bb8\u7684\u589e\u52a0\u4f1a\u5bfc\u81f4\u4ec7\u6068\u8a00\u8bba\u7684\u6781\u7aef\u5316\uff08H1b\u4e0d\u6210\u7acb\uff09\u3002\u8de8\u4e2a\u4f53\u6548\u5e94\u5206\u6790\u663e\u793a\uff0c\u5728\u5e16\u5b50\u5c42\u9762\uff0c\u793e\u4f1a\u8d5e\u8bb8\u4e0e\u4ec7\u6068\u8a00\u8bba\u4ea7\u751f\u4e4b\u95f4\u5b58\u5728\u5e73\u5747\u8d1f\u76f8\u5173\uff0c\u4f46\u5728\u5176\u4ed6\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u7684\u5173\u7cfb\u5219\u4e0d\u4e00\u81f4\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728Parler\u5e73\u53f0\u4e0a\uff0c\u7528\u6237\u4ece\u4ec7\u6068\u8a00\u8bba\u4e2d\u83b7\u5f97\u7684\u201c\u70b9\u8d5e\u201d\uff08\u793e\u4f1a\u8d5e\u8bb8\uff09\u6570\u91cf\u4e0e\u4ed6\u4eec\u540e\u7eed\u53d1\u5e03\u4ec7\u6068\u8a00\u8bba\u7684\u6570\u91cf\u4e4b\u95f4\u6ca1\u6709\u5173\u8054\uff0c\u5e76\u4e14\u793e\u4f1a\u8d5e\u8bb8\u7684\u589e\u52a0\u5e76\u672a\u5bfc\u81f4\u4ec7\u6068\u8a00\u8bba\u7684\u6781\u7aef\u5316\u3002\u6b64\u5916\uff0c\u8de8\u4e2a\u4f53\u6548\u5e94\u663e\u793a\uff0c\u793e\u4f1a\u8d5e\u8bb8\u4e0e\u4ec7\u6068\u8a00\u8bba\u7684\u4ea7\u751f\u4e4b\u95f4\u5b58\u5728\u5e73\u5747\u8d1f\u76f8\u5173\u5173\u7cfb\uff0c\u4f46\u5728\u5176\u4ed6\u65f6\u95f4\u95f4\u9694\u4e0a\u7684\u5173\u7cfb\u5219\u4e0d\u786e\u5b9a\u3002\u7814\u7a76\u8ba4\u4e3a\uff0c\u5728\u7ebf\u4ec7\u6068\u7684\u793e\u4f1a\u8d5e\u8bb8\u5f3a\u5316\u673a\u5236\u5728\u7279\u5b9a\u7684\u5c0f\u4f17\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u4e0a\u53ef\u80fd\u6709\u6240\u4e0d\u540c\u3002"}}
{"id": "2507.10922", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.10922", "abs": "https://arxiv.org/abs/2507.10922", "authors": ["Minghao Li", "Zhejunyu Jin", "Zhaozhuo Zeng", "Peng Yan"], "title": "Frequency comb in twisted magnonic crystals", "comment": "10 pages, 9 figures", "summary": "While twisted magnonic crystals (MCs) have recently gained attention for\ntheir intriguing linear phenomena, such as magnon flat bands, their nonlinear\ndynamics -- particularly the generation of magnonic frequency combs (MFCs) --\nhave remained largely unexplored. In this work, we demonstrate the creation of\nMFCs in twisted MCs using two-tone microwave excitation. We find that finite\ntwist angles significantly enhance three-magnon interactions, driven by the\nnon-collinear ground-state magnetic configuration induced by interlayer\ndipole-dipole interactions. The number of comb teeth exhibits a plateau-like\ndependence on the twist angle, with the plateau's width and height saturating\nas the excitation frequency of the propagating magnon mode increases. This\nbehavior reveals an optimal range of twist angles and frequencies for achieving\nhigh-quality MFCs with a large number of comb teeth. Our findings deepen the\nunderstanding of nonlinear interactions in twisted MCs and highlight their\npotential for advancing moir\\'e-based materials in information processing and\nhigh-precision metrology.", "AI": {"tldr": "\u626d\u66f2\u78c1\u5b50\u6676\u4f53\u4e2d\u7684 MFCs\uff1a\u8fd9\u9879\u7814\u7a76\u901a\u8fc7\u53cc\u97f3\u5fae\u6ce2\u6fc0\u52b1\u5728\u626d\u66f2\u78c1\u5b50\u6676\u4f53\u4e2d\u4ea7\u751f\u4e86 MFCs\uff0c\u5e76\u53d1\u73b0\u626d\u8f6c\u89d2\u4f1a\u663e\u8457\u5f71\u54cd\u4e09\u78c1\u5b50\u76f8\u4e92\u4f5c\u7528\u3002\u7814\u7a76\u7ed3\u679c\u6709\u52a9\u4e8e\u4f18\u5316 MFCs \u7684\u4ea7\u751f\uff0c\u5e76\u4e3a\u4fe1\u606f\u5904\u7406\u548c\u9ad8\u7cbe\u5ea6\u8ba1\u91cf\u7b49\u9886\u57df\u5f00\u8f9f\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002", "motivation": "\u63a2\u7d22\u626d\u66f2\u78c1\u5b50\u6676\u4f53\uff08MCs\uff09\u4e2d\u672a\u88ab\u5145\u5206\u7814\u7a76\u7684\u975e\u7ebf\u6027\u52a8\u529b\u5b66\uff0c\u7279\u522b\u662f\u78c1\u5b50\u9891\u7387\u68b3\uff08MFCs\uff09\u7684\u4ea7\u751f\u3002", "method": "\u901a\u8fc7\u53cc\u97f3\u5fae\u6ce2\u6fc0\u52b1\u5728\u626d\u66f2\u78c1\u5b50\u6676\u4f53\u4e2d\u6f14\u793a\u4e86\u78c1\u5b50\u9891\u7387\u68b3\uff08MFCs\uff09\u7684\u4ea7\u751f\u3002", "result": "\u53d1\u73b0\u6709\u9650\u7684\u626d\u8f6c\u89d2\u80fd\u663e\u8457\u589e\u5f3a\u4e09\u78c1\u5b50\u76f8\u4e92\u4f5c\u7528\uff0c\u5176\u539f\u56e0\u662f\u5c42\u95f4\u5076\u6781-\u5076\u6781\u76f8\u4e92\u4f5c\u7528\u5f15\u8d77\u7684\u975e\u5171\u7ebf\u57fa\u6001\u78c1\u6784\u578b\u3002\u68b3\u9f7f\u7684\u6570\u91cf\u5bf9\u626d\u8f6c\u89d2\u7684\u4f9d\u8d56\u6027\u5448\u73b0\u51fa\u7c7b\u4f3c\u5e73\u53f0\u72b6\u7684\u884c\u4e3a\uff0c\u5e76\u4e14\u968f\u7740\u4f20\u64ad\u78c1\u5b50\u6a21\u5f0f\u7684\u6fc0\u53d1\u9891\u7387\u7684\u589e\u52a0\uff0c\u5e73\u53f0\u7684\u5bbd\u5ea6\u548c\u9ad8\u5ea6\u4f1a\u9971\u548c\u3002", "conclusion": "\u8be5\u7814\u7a76\u52a0\u6df1\u4e86\u5bf9\u626d\u66f2\u78c1\u5b50\u6676\u4f53\u4e2d\u975e\u7ebf\u6027\u76f8\u4e92\u4f5c\u7528\u7684\u7406\u89e3\uff0c\u5e76\u5f3a\u8c03\u4e86\u5176\u5728\u57fa\u4e8e\u83ab\u5c14\u6750\u6599\u7684\u4fe1\u606f\u5904\u7406\u548c\u9ad8\u7cbe\u5ea6\u8ba1\u91cf\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.11258", "categories": ["cs.LO", "03B45", "F.4.1"], "pdf": "https://arxiv.org/pdf/2507.11258", "abs": "https://arxiv.org/abs/2507.11258", "authors": ["Olivier Gasquet"], "title": "Path-filtration for modal logics applied to revisiting quasi-dense logics", "comment": null, "summary": "In https://arxiv.org/pdf/2405.10094 (also published at LICS'24 conference),\nLyon and Ostropolski-Nalewaja answer the question of the decidability of\nquasi-dense modallogics, and give an upper bound in EXPSPACE. Unfortunately,\ntheir intricate proof contains a major flaw that cannot be fixed, leaving the\nquestion wide open. In this paper we provide a correct and rather simple and\ndirect proof of it by introducing a new variant of the well-know filtration\nmethod based on paths in a canonical model and improve the hypothetical\nmembership to membership NEXPTIME.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u4e86Lyon\u548cOstropolski-Nalewaja\u5173\u4e8e\u51c6\u7a20\u5bc6\u6a21\u6001\u903b\u8f91\u53ef\u5224\u5b9a\u6027\u8bc1\u660e\u4e2d\u7684\u4e00\u4e2a\u4e3b\u8981\u7f3a\u9677\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u3001\u66f4\u7b80\u5355\u7684\u8bc1\u660e\uff0c\u5c06\u4e0a\u754c\u4eceEXPSPACE\u6539\u8fdb\u5230NEXPTIME\u3002", "motivation": "\u89e3\u51b3Lyon\u548cOstropolski-Nalewaja\u8bba\u6587\u4e2d\u51c6\u7a20\u5bc6\u6a21\u6001\u903b\u8f91\u53ef\u5224\u5b9a\u6027\u8bc1\u660e\u4e2d\u7684\u4e3b\u8981\u7f3a\u9677\uff0c\u5e76\u6539\u8fdb\u5176\u4e0a\u754c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6b63\u5219\u6a21\u578b\u4e2d\u8def\u5f84\u7684\u65b0\u578b\u8fc7\u6ee4\u65b9\u6cd5\u3002", "result": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6b63\u786e\u3001\u7b80\u5355\u3001\u76f4\u63a5\u7684\u8bc1\u660e\uff0c\u5c06\u5047\u8bbe\u7684\u6210\u5458\u8d44\u683c\u4eceEXPSPACE\u6539\u8fdb\u5230NEXPTIME\u3002\u1ec7c l\u00e0 m\u1ed9t c\u00e2u h\u1ecfi m\u1edf.", "conclusion": "\u51c6\u7a20\u5bc6\u6a21\u6001\u903b\u8f91\u7684\u53ef\u5224\u5b9a\u6027\u95ee\u9898\u4ecd\u7136\u662f\u5f00\u653e\u7684\uff0c\u4f46\u5df2\u83b7\u5f97\u6539\u8fdb\u7684\u4e0a\u754c\u3002"}}
{"id": "2507.10762", "categories": ["cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2507.10762", "abs": "https://arxiv.org/abs/2507.10762", "authors": ["Chang-An Li", "Bo Fu", "Huaiming Guo", "Bj\u00f6rn Trauzettel", "Song-Bo Zhang"], "title": "Marginal Metals and Kosterlitz-Thouless Type Phase Transition in Disordered Altermagnets", "comment": "7+3 pages, 5+3 figures", "summary": "Altermagnetism, a recently discovered magnetic phase characterized by\nspin-split bands without net magnetization, has emerged as promising platform\nfor novel physics and potential applications. However, its stability against\ndisorder-ubiquitous in real materials-remains poorly understood. Here, we study\nthe electron localization properties of two-dimensional altermagnets subject to\ndisorder. Remarkably, we discover a disorder-driven phase transition from a\nmarginal metallic phase to an insulator, which falls into the\nKosterlitz-Thouless class. We demonstrate this by convincing numerical evidence\nand propose a vortex-antivortex-like spin pair picture for its interpretation.\nMoreover, we show that the characteristic spin anisotropy of altermagnets\npersists but gradually fades away across the transition. These changes directly\naffect the spin-splitting features that are detectable in angle-resolved\nphotoemission spectroscopy and tunneling magnetoresistance. Our findings\nprovide a new perspective on recent experimental observations of altermagnetism\nin candidate materials.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.10698", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.10698", "abs": "https://arxiv.org/abs/2507.10698", "authors": ["Atanu Bhunia", "Saronath Halder", "Ritabrata Sengupta"], "title": "Classifying locally distinguishable sets: No activation across bipartitions", "comment": null, "summary": "A set of orthogonal quantum states is said to be locally indistinguishable if\nthey cannot be perfectly distinguished by local operations and classical\ncommunication (LOCC). Otherwise, the states are locally distinguishable.\nHowever, locally indistinguishable states may find applications in information\nprocessing protocols. In this sense, locally indistinguishable states are\nuseful. On the other hand, it is usual to consider that locally distinguishable\nstates are useless. Nevertheless, recent works suggest that locally\ndistinguishable states should be given due consideration as in certain\nsituations these states can be converted to locally indistinguishable states\nunder orthogonality-preserving LOCC (OP-LOCC). Such a counterintuitive\nphenomenon motivates us to ask when the aforesaid conversion is possible and\nwhen it is not. In this work, we provide different structures of locally\ndistinguishable product and entangled states which do not allow the aforesaid\nconversion. We also provide certain structures of locally distinguishable\nstates which allow the aforesaid conversion. In this way, we classify the\nlocally distinguishable sets by introducing hierarchies among them. In a\nmultipartite system, this study becomes more involved as there exist\nmultipartite locally distinguishable sets which cannot be converted to locally\nindistinguishable sets by OP-LOCC across any bipartition. We say this as ``no\nactivation across bi-partitions\".", "AI": {"tldr": "\u672c\u7814\u7a76\u5bf9\u91cf\u5b50\u6001\u7684\u5c40\u90e8\u53ef\u533a\u5206\u6027\u8fdb\u884c\u4e86\u6df1\u5165\u63a2\u8ba8\uff0c\u53d1\u73b0\u67d0\u4e9b\u770b\u4f3c\u201c\u65e0\u7528\u201d\u7684\u672c\u5730\u53ef\u533a\u5206\u6001\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\uff08OP-LOCC\uff09\u53ef\u8f6c\u5316\u4e3a\u6709\u7528\u7684\u672c\u5730\u4e0d\u53ef\u533a\u5206\u6001\u3002\u901a\u8fc7\u6784\u5efa\u4e0d\u540c\u72b6\u6001\u7ed3\u6784\uff0c\u7814\u7a76\u8005\u5bf9\u672c\u5730\u53ef\u533a\u5206\u6001\u8fdb\u884c\u4e86\u5206\u7c7b\uff0c\u5e76\u63ed\u793a\u4e86\u5728\u591a\u65b9\u7cfb\u7edf\u4e2d\u5b58\u5728\u201c\u65e0\u8de8\u4e8c\u5212\u5206\u6fc0\u6d3b\u201d\u7684\u7279\u6b8a\u73b0\u8c61\u3002", "motivation": "\u7814\u7a76\u5728\u6b63\u4ea4\u6027\u4fdd\u6301\u7684\u5c40\u90e8\u64cd\u4f5c\u548c\u7ecf\u5178\u901a\u4fe1\uff08OP-LOCC\uff09\u4e0b\uff0c\u672c\u5730\u53ef\u533a\u5206\u6001\u96c6\u5411\u672c\u5730\u4e0d\u53ef\u533a\u5206\u6001\u96c6\u8f6c\u5316\u7684\u53ef\u884c\u6027\uff0c\u4ee5\u53ca\u8fd9\u79cd\u8f6c\u5316\u7684\u9650\u5236\u6761\u4ef6\uff0c\u7279\u522b\u662f\u5728\u591a\u65b9\u7cfb\u7edf\u4e2d\u662f\u5426\u5b58\u5728\u201c\u65e0\u8de8\u4e8c\u5212\u5206\u6fc0\u6d3b\u201d\u7684\u73b0\u8c61\u3002", "method": "\u901a\u8fc7\u63d0\u4f9b\u4e0d\u540c\u7ed3\u6784\u7684\u672c\u5730\u53ef\u533a\u5206\u4e58\u79ef\u548c\u7ea0\u7f20\u6001\uff0c\u4ee5\u53ca\u5141\u8bb8\u6b64\u7c7b\u8f6c\u5316\u7684\u67d0\u4e9b\u672c\u5730\u53ef\u533a\u5206\u6001\u7ed3\u6784\uff0c\u5bf9\u672c\u5730\u53ef\u533a\u5206\u6001\u96c6\u8fdb\u884c\u5206\u7c7b\uff0c\u5e76\u5f15\u5165\u5c42\u7ea7\u7ed3\u6784\u3002\u7814\u7a76\u4e86\u5728\u591a\u65b9\u7cfb\u7edf\u4e2d\uff0c\u5f53\u65e0\u6cd5\u8de8\u8d8a\u4efb\u4f55\u4e8c\u5212\u5206\u8fdb\u884c\u6fc0\u6d3b\u65f6\uff0c\u5373\u201c\u65e0\u8de8\u4e8c\u5212\u5206\u6fc0\u6d3b\u201d\u7684\u73b0\u8c61\u3002", "result": "\u63d0\u4f9b\u4e86\u4e0d\u5141\u8bb8\u6b64\u7c7b\u8f6c\u5316\u7684\u672c\u5730\u53ef\u533a\u5206\u4e58\u79ef\u548c\u7ea0\u7f20\u6001\u7684\u7ed3\u6784\uff0c\u4ee5\u53ca\u5141\u8bb8\u6b64\u7c7b\u8f6c\u5316\u7684\u672c\u5730\u53ef\u533a\u5206\u6001\u7684\u7ed3\u6784\uff0c\u4ece\u800c\u5bf9\u672c\u5730\u53ef\u533a\u5206\u6001\u96c6\u8fdb\u884c\u4e86\u5206\u7c7b\u5e76\u5f15\u5165\u4e86\u5c42\u7ea7\u3002\u5728\u591a\u65b9\u7cfb\u7edf\u4e2d\uff0c\u53d1\u73b0\u4e86\u201c\u65e0\u8de8\u4e8c\u5212\u5206\u6fc0\u6d3b\u201d\u7684\u73b0\u8c61\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5bf9\u672c\u5730\u53ef\u533a\u5206\u6001\u96c6\u8fdb\u884c\u4e86\u5206\u7c7b\uff0c\u5f15\u5165\u4e86\u5c42\u7ea7\u7ed3\u6784\uff0c\u5e76\u7814\u7a76\u4e86\u5728\u6b63\u4ea4\u6027\u4fdd\u6301\u7684\u5c40\u90e8\u64cd\u4f5c\u548c\u7ecf\u5178\u901a\u4fe1\uff08OP-LOCC\uff09\u4e0b\uff0c\u672c\u5730\u53ef\u533a\u5206\u6001\u96c6\u8f6c\u5316\u4e3a\u672c\u5730\u4e0d\u53ef\u533a\u5206\u6001\u96c6\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2507.10846", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10846", "abs": "https://arxiv.org/abs/2507.10846", "authors": ["Casey Wall", "Longwei Wang", "Rodrigue Rizk", "KC Santosh"], "title": "Winsor-CAM: Human-Tunable Visual Explanations from Deep Networks via Layer-Wise Winsorization", "comment": "15 pages, 10 figures, 7 tables. Submitted to IEEE Transactions on\n  Pattern Analysis and Machine Intelligence", "summary": "Interpreting the decision-making process of Convolutional Neural Networks\n(CNNs) is critical for deploying models in high-stakes domains.\nGradient-weighted Class Activation Mapping (Grad-CAM) is a widely used method\nfor visual explanations, yet it typically focuses on the final convolutional\nlayer or na\\\"ively averages across layers, strategies that can obscure\nimportant semantic cues or amplify irrelevant noise. We propose Winsor-CAM, a\nnovel, human-tunable extension of Grad-CAM that generates robust and coherent\nsaliency maps by aggregating information across all convolutional layers. To\nmitigate the influence of noisy or extreme attribution values, Winsor-CAM\napplies Winsorization, a percentile-based outlier attenuation technique. A\nuser-controllable threshold allows for semantic-level tuning, enabling flexible\nexploration of model behavior across representational hierarchies. Evaluations\non standard architectures (ResNet50, DenseNet121, VGG16, InceptionV3) using the\nPASCAL VOC 2012 dataset demonstrate that Winsor-CAM produces more interpretable\nheatmaps and achieves superior performance in localization metrics, including\nintersection-over-union and center-of-mass alignment, when compared to Grad-CAM\nand uniform layer-averaging baselines. Winsor-CAM advances the goal of\ntrustworthy AI by offering interpretable, multi-layer insights with\nhuman-in-the-loop control.", "AI": {"tldr": "Winsor-CAM\u662fGrad-CAM\u7684\u4e00\u79cd\u6539\u8fdb\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u591a\u5c42\u4fe1\u606f\u548c\u5f02\u5e38\u503c\u6291\u5236\u6280\u672f\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u89e3\u91ca\u7684\u51c6\u786e\u6027\u548c\u7075\u6d3b\u6027\u3002", "motivation": "\u4e3a\u4e86\u5728\u5173\u952e\u9886\u57df\u90e8\u7f72\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u6a21\u578b\uff0c\u7406\u89e3\u5176\u51b3\u7b56\u8fc7\u7a0b\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7684Grad-CAM\u65b9\u6cd5\u5728\u5904\u7406\u591a\u4e2a\u5377\u79ef\u5c42\u7684\u4fe1\u606f\u65f6\u5b58\u5728\u4e0d\u8db3\uff0c\u53ef\u80fd\u9690\u85cf\u91cd\u8981\u7684\u8bed\u4e49\u7ebf\u7d22\u6216\u653e\u5927\u65e0\u5173\u7684\u566a\u58f0\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aWinsor-CAM\u7684\u65b0\u578b\u3001\u53ef\u7531\u7528\u6237\u8c03\u4f18\u7684Grad-CAM\u6269\u5c55\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u805a\u5408\u6240\u6709\u5377\u79ef\u5c42\u7684\u4fe1\u606f\u6765\u751f\u6210\u9c81\u68d2\u4e14\u8fde\u8d2f\u7684\u663e\u8457\u6027\u56fe\uff0c\u5e76\u91c7\u7528Winsorization\uff08\u4e00\u79cd\u57fa\u4e8e\u767e\u5206\u4f4d\u6570\u7684\u5f02\u5e38\u503c\u8870\u51cf\u6280\u672f\uff09\u6765\u51cf\u8f7b\u566a\u58f0\u6216\u6781\u7aef\u5f52\u56e0\u503c\u7684\u5f71\u54cd\u3002\u7528\u6237\u53ef\u4ee5\u901a\u8fc7\u4e00\u4e2a\u53ef\u63a7\u9608\u503c\u8fdb\u884c\u8bed\u4e49\u5c42\u9762\u7684\u8c03\u6574\uff0c\u4ece\u800c\u7075\u6d3b\u5730\u63a2\u7d22\u6a21\u578b\u5728\u4e0d\u540c\u8868\u5f81\u5c42\u7ea7\u4e2d\u7684\u884c\u4e3a\u3002", "result": "\u5728PASCAL VOC 2012\u6570\u636e\u96c6\u548c\u6807\u51c6CNN\u67b6\u6784\uff08ResNet50\u3001DenseNet121\u3001VGG16\u3001InceptionV3\uff09\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u4e0eGrad-CAM\u548c\u5747\u5300\u5c42\u5e73\u5747\u57fa\u7ebf\u76f8\u6bd4\uff0cWinsor-CAM\u751f\u6210\u7684\u70ed\u56fe\u66f4\u5177\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u4e14\u5728\u4ea4\u5e76\u6bd4\u548c\u8d28\u5fc3\u5bf9\u9f50\u7b49\u5b9a\u4f4d\u6307\u6807\u4e0a\u53d6\u5f97\u4e86\u66f4\u4f18\u8d8a\u7684\u6027\u80fd\u3002", "conclusion": "Winsor-CAM\u901a\u8fc7\u805a\u5408\u6240\u6709\u5377\u79ef\u5c42\u7684\u4fe1\u606f\uff0c\u5e76\u5e94\u7528Winsorization\u6280\u672f\u6765\u7f13\u89e3\u566a\u58f0\u6216\u6781\u7aef\u5f52\u56e0\u503c\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u751f\u6210\u9c81\u68d2\u4e14\u8fde\u8d2f\u7684\u663e\u8457\u6027\u56fe\u3002\u7528\u6237\u53ef\u63a7\u7684\u9608\u503c\u5141\u8bb8\u8fdb\u884c\u8bed\u4e49\u5c42\u9762\u7684\u8c03\u6574\uff0c\u4ece\u800c\u7075\u6d3b\u5730\u63a2\u7d22\u6a21\u578b\u5728\u4e0d\u540c\u8868\u5f81\u5c42\u7ea7\u4e2d\u7684\u884c\u4e3a\u3002Winsor-CAM\u901a\u8fc7\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u3001\u591a\u5c42\u7ea7\u7684\u89c1\u89e3\u548c\u4eba\u4e3a\u5e72\u9884\u7684\u63a7\u5236\uff0c\u63a8\u52a8\u4e86\u53ef\u4fe1AI\u7684\u76ee\u6807\u3002"}}
{"id": "2507.10758", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10758", "abs": "https://arxiv.org/abs/2507.10758", "authors": ["Nikesh Prajapati", "Bimal Karki", "Saroj Gopali", "Akbar Siami Namin"], "title": "IoT Malware Network Traffic Detection using Deep Learning and GraphSAGE Models", "comment": null, "summary": "This paper intends to detect IoT malicious attacks through deep learning\nmodels and demonstrates a comprehensive evaluation of the deep learning and\ngraph-based models regarding malicious network traffic detection. The models\nparticularly are based on GraphSAGE, Bidirectional encoder representations from\ntransformers (BERT), Temporal Convolutional Network (TCN) as well as Multi-Head\nAttention, together with Bidirectional Long Short-Term Memory (BI-LSTM)\nMulti-Head Attention and BI-LSTM and LSTM models. The chosen models\ndemonstrated great performance to model temporal patterns and detect feature\nsignificance. The observed performance are mainly due to the fact that IoT\nsystem traffic patterns are both sequential and diverse, leaving a rich set of\ntemporal patterns for the models to learn. Experimental results showed that\nBERT maintained the best performance. It achieved 99.94% accuracy rate\nalongside high precision and recall, F1-score and AUC-ROC score of 99.99% which\ndemonstrates its capabilities through temporal dependency capture. The\nMulti-Head Attention offered promising results by providing good detection\ncapabilities with interpretable results. On the other side, the Multi-Head\nAttention model required significant processing time like BI-LSTM variants. The\nGraphSAGE model achieved good accuracy while requiring the shortest training\ntime but yielded the lowest accuracy, precision, and F1 score compared to the\nother models", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u591a\u79cd\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff08\u5305\u62ecBERT\u3001TCN\u3001Multi-Head Attention\u3001GraphSAGE\u3001BI-LSTM\uff09\u5728\u7269\u8054\u7f51\u6076\u610f\u6d41\u91cf\u68c0\u6d4b\u4e2d\u7684\u6027\u80fd\u3002\u7ed3\u679c\u663e\u793a\uff0cBERT\u8868\u73b0\u6700\u4f73\uff0c\u51c6\u786e\u7387\u548c\u591a\u9879\u5173\u952e\u6307\u6807\u63a5\u8fd1100%\uff1bMulti-Head Attention\u6027\u80fd\u826f\u597d\u4f46\u5904\u7406\u65f6\u95f4\u957f\uff1bGraphSAGE\u8bad\u7ec3\u5feb\u4f46\u6027\u80fd\u8f83\u4f4e\u3002", "motivation": "\u7269\u8054\u7f51\u7cfb\u7edf\u6d41\u91cf\u6a21\u5f0f\u5177\u6709\u5e8f\u5217\u6027\u548c\u591a\u6837\u6027\uff0c\u5176\u4e2d\u8574\u542b\u4e30\u5bcc\u7684\u65f6\u5e8f\u6a21\u5f0f\u4f9b\u6a21\u578b\u5b66\u4e60\uff0c\u56e0\u6b64\u672c\u6587\u65e8\u5728\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u68c0\u6d4b\u7269\u8054\u7f51\u6076\u610f\u653b\u51fb\uff0c\u5e76\u5bf9\u6240\u9009\u6a21\u578b\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\u3002", "method": "\u672c\u6587\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7279\u522b\u662fGraphSAGE\u3001Transformer\u7684BERT\u3001TCN\u4ee5\u53caMulti-Head Attention\u3001BI-LSTM Multi-Head Attention\u548cBI-LSTM\u4e0eLSTM\u6a21\u578b\uff0c\u6765\u68c0\u6d4b\u7269\u8054\u7f51\u7684\u6076\u610f\u653b\u51fb\u3002\u5bf9\u8fd9\u4e9b\u6a21\u578b\u5728\u6076\u610f\u7f51\u7edc\u6d41\u91cf\u68c0\u6d4b\u65b9\u9762\u7684\u6027\u80fd\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cBERT\u6a21\u578b\u7684\u6027\u80fd\u6700\u4f18\uff0c\u51c6\u786e\u7387\u9ad8\u8fbe99.94%\uff0c\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u3001F1\u5206\u6570\u548cAUC-ROC\u5206\u6570\u4e5f\u8fbe\u5230\u4e8699.99%\u3002Multi-Head Attention\u6a21\u578b\u68c0\u6d4b\u80fd\u529b\u826f\u597d\u4e14\u7ed3\u679c\u53ef\u89e3\u91ca\uff0c\u4f46\u5904\u7406\u65f6\u95f4\u957f\u3002GraphSAGE\u6a21\u578b\u8bad\u7ec3\u65f6\u95f4\u6700\u77ed\uff0c\u4f46\u5404\u9879\u6027\u80fd\u6307\u6807\u6700\u4f4e\u3002", "conclusion": "BERT\u6a21\u578b\u5728\u68c0\u6d4b\u7269\u8054\u7f51\u6076\u610f\u653b\u51fb\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u51c6\u786e\u7387\u8fbe\u523099.94%\uff0c\u5e76\u5177\u6709\u9ad8\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u3001F1\u5206\u6570\u548cAUC-ROC\u5206\u6570\uff08\u5747\u4e3a99.99%\uff09\uff0c\u8fd9\u5f97\u76ca\u4e8e\u5176\u5f3a\u5927\u7684\u65f6\u5e8f\u4f9d\u8d56\u6355\u6349\u80fd\u529b\u3002Multi-Head Attention\u6a21\u578b\u4e5f\u5c55\u73b0\u4e86\u826f\u597d\u7684\u68c0\u6d4b\u80fd\u529b\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4f46\u5904\u7406\u65f6\u95f4\u8f83\u957f\u3002GraphSAGE\u6a21\u578b\u8bad\u7ec3\u65f6\u95f4\u6700\u77ed\uff0c\u4f46\u51c6\u786e\u7387\u3001\u7cbe\u786e\u7387\u548cF1\u5206\u6570\u6700\u4f4e\u3002"}}
{"id": "2507.10743", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10743", "abs": "https://arxiv.org/abs/2507.10743", "authors": ["Nickolas Freeman", "Thanh Nguyen", "Gregory Bott", "Jason Parton", "Collin Francel"], "title": "Language Models for Adult Service Website Text Analysis", "comment": "32 pages, 12 figures, 1 table", "summary": "Sex trafficking refers to the use of force, fraud, or coercion to compel an\nindividual to perform in commercial sex acts against their will. Adult service\nwebsites (ASWs) have and continue to be linked to sex trafficking, offering a\nplatform for traffickers to advertise their victims. Thus, organizations\ninvolved in the fight against sex trafficking often use ASW data when\nattempting to identify potential sex trafficking victims. A critical challenge\nin transforming ASW data into actionable insight is text analysis. Previous\nresearch using ASW data has shown that ASW ad text is important for linking\nads. However, working with this text is challenging due to its extensive use of\nemojis, poor grammar, and deliberate obfuscation to evade law enforcement\nscrutiny. We conduct a comprehensive study of language modeling approaches for\nthis application area, including simple information retrieval methods,\npre-trained transformers, and custom transformer models. We demonstrate that\ncharacteristics of ASW text data allow efficient custom transformer models to\nbe trained with relatively small GPU resources and used efficiently for\ninference on consumer hardware. Our custom models outperform fine-tuned\nvariants of well-known encoder-only transformer models, including BERT-base,\nRoBERTa, and ModernBERT, on accuracy, recall, F1 score, and ROC AUC. We\ndemonstrate the use of our best-performing custom configuration on three tasks\nrelated to ASW data analysis: (i) decomposing the giant component in a graph\nrepresentation of ASW data, (ii) clustering ASW ad text, and (iii) using the\nlearned token embeddings to understand the use of emojis in the illicit context\nwe study. The models we develop represent a significant advancement in ASW text\nanalysis, which can be leveraged in a variety of downstream applications and\nresearch.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9488\u5bf9\u6210\u4eba\u670d\u52a1\u7f51\u7ad9\uff08ASW\uff09\u7684\u6587\u672c\u5206\u6790\uff0c\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u81ea\u5b9a\u4e49 transformer \u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5728\u51c6\u786e\u6027\u3001\u53ec\u56de\u7387\u3001F1 \u5206\u6570\u548c ROC AUC \u7b49\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u6570\u636e\u5206\u89e3\u3001\u805a\u7c7b\u548c\u8868\u60c5\u7b26\u53f7\u4f7f\u7528\u5206\u6790\u7b49\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u6210\u4eba\u670d\u52a1\u7f51\u7ad9\uff08ASW\uff09\u957f\u671f\u4ee5\u6765\u4e00\u76f4\u4e0e\u4eba\u53e3\u8d29\u8fd0\u76f8\u5173\uff0c\u4e3a\u4eba\u53e3\u8d29\u8fd0\u8005\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5ba3\u4f20\u5176\u53d7\u5bb3\u8005\u7684\u5e73\u53f0\u3002\u56e0\u6b64\uff0c\u6253\u51fb\u4eba\u53e3\u8d29\u8fd0\u7684\u7ec4\u7ec7\u5728\u8bd5\u56fe\u8bc6\u522b\u6f5c\u5728\u7684\u4eba\u53e3\u8d29\u8fd0\u53d7\u5bb3\u8005\u65f6\uff0c\u7ecf\u5e38\u4f7f\u7528 ASW \u6570\u636e\u3002\u5c06 ASW \u6570\u636e\u8f6c\u5316\u4e3a\u53ef\u884c\u7684\u89c1\u89e3\u6240\u9762\u4e34\u7684\u4e00\u4e2a\u5173\u952e\u6311\u6218\u662f\u6587\u672c\u5206\u6790\u3002", "method": "\u5bf9\u8bed\u8a00\u5efa\u6a21\u65b9\u6cd5\u8fdb\u884c\u4e86\u5168\u9762\u7814\u7a76\uff0c\u5305\u62ec\u7b80\u5355\u4fe1\u606f\u68c0\u7d22\u65b9\u6cd5\u3001\u9884\u8bad\u7ec3 transformer \u548c\u81ea\u5b9a\u4e49 transformer \u6a21\u578b\uff0c\u5e76\u8bc1\u660e\u4e86 ASW \u6587\u672c\u6570\u636e\u7684\u7279\u6027\u5141\u8bb8\u4f7f\u7528\u76f8\u5bf9\u8f83\u5c11\u7684 GPU \u8d44\u6e90\u9ad8\u6548\u5730\u8bad\u7ec3\u81ea\u5b9a\u4e49 transformer \u6a21\u578b\uff0c\u5e76\u80fd\u5728\u6d88\u8d39\u8005\u786c\u4ef6\u4e0a\u9ad8\u6548\u5730\u7528\u4e8e\u63a8\u7406\u3002", "result": "\u81ea\u5b9a\u4e49\u6a21\u578b\u5728\u51c6\u786e\u6027\u3001\u53ec\u56de\u7387\u3001F1 \u5206\u6570\u548c ROC AUC \u65b9\u9762\u4f18\u4e8e\u5305\u62ec BERT-base\u3001RoBERTa \u548c ModernBERT \u5728\u5185\u7684\u77e5\u540d encoder-only transformer \u6a21\u578b\u7684\u5fae\u8c03\u53d8\u4f53\u3002", "conclusion": "\u6240\u5f00\u53d1\u6a21\u578b\u4ee3\u8868\u4e86\u6210\u4eba\u670d\u52a1\u7f51\u7ad9(ASW)\u6587\u672c\u5206\u6790\u7684\u91cd\u5927\u8fdb\u5c55\uff0c\u53ef\u7528\u4e8e\u5404\u79cd\u4e0b\u6e38\u5e94\u7528\u7a0b\u5e8f\u548c\u7814\u7a76\u3002"}}
{"id": "2507.10636", "categories": ["cs.LG", "cs.AI", "cs.NE", "cs.RO", "90B06", "I.2.8"], "pdf": "https://arxiv.org/pdf/2507.10636", "abs": "https://arxiv.org/abs/2507.10636", "authors": ["Jianing Zhi", "Xinghua Li", "Zidong Chen"], "title": "GeoHopNet: Hopfield-Augmented Sparse Spatial Attention for Dynamic UAV Site Location Problem", "comment": "12 Pages, 5 Figures", "summary": "The rapid development of urban low-altitude unmanned aerial vehicle (UAV)\neconomy poses new challenges for dynamic site selection of UAV landing points\nand supply stations. Traditional deep reinforcement learning methods face\ncomputational complexity bottlenecks, particularly with standard attention\nmechanisms, when handling large-scale urban-level location problems. This paper\nproposes GeoHopNet, a Hopfield-augmented sparse spatial attention network\nspecifically designed for dynamic UAV site location problems. Our approach\nintroduces four core innovations: (1) distance-biased multi-head attention\nmechanism that explicitly encodes spatial geometric information; (2) K-nearest\nneighbor sparse attention that reduces computational complexity from $O(N^2)$\nto $O(NK)$; (3) a modern Hopfield external memory module; and (4) a memory\nregularization strategy. Experimental results demonstrate that GeoHopNet\nextends the boundary of solvable problem sizes. For large-scale instances with\n1,000 nodes, where standard attention models become prohibitively slow (over 3\nseconds per instance) and traditional solvers fail, GeoHopNet finds\nhigh-quality solutions (0.22\\% optimality gap) in under 0.1 seconds. Compared\nto the state-of-the-art ADNet baseline on 100-node instances, our method\nimproves solution quality by 22.2\\% and is 1.8$\\times$ faster.", "AI": {"tldr": "GeoHopNet\uff1a\u4e00\u79cd\u9ad8\u6548\u7684\u65e0\u4eba\u673a\u52a8\u6001\u9009\u5740\u89e3\u51b3\u65b9\u6848\uff0c\u7a81\u7834\u8ba1\u7b97\u9650\u5236\u3002", "motivation": "\u4f20\u7edf\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u5904\u7406\u5927\u89c4\u6a21\u57ce\u5e02\u65e0\u4eba\u673a\u52a8\u6001\u9009\u5740\u95ee\u9898\u65f6\uff0c\u7531\u4e8e\u6807\u51c6\u6ce8\u610f\u529b\u673a\u5236\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u74f6\u9888\uff0c\u9762\u4e34\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a GeoHopNet \u7684\u65b0\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u7ed3\u5408\u4e86 Hopfield \u589e\u5f3a\u7684\u7a00\u758f\u7a7a\u95f4\u6ce8\u610f\u529b\u7f51\u7edc\uff0c\u5e76\u5305\u542b\u56db\u4e2a\u6838\u5fc3\u521b\u65b0\uff1a(1) \u8ddd\u79bb\u504f\u7f6e\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\uff0c(2) K-\u6700\u8fd1\u90bb\u7a00\u758f\u6ce8\u610f\u529b\uff0c(3) \u73b0\u4ee3 Hopfield \u5916\u90e8\u5185\u5b58\u6a21\u5757\uff0c(4) \u5185\u5b58\u6b63\u5219\u5316\u7b56\u7565\u3002", "result": "GeoHopNet \u7b97\u6cd5\u5728\u5904\u7406\u5305\u542b 1000 \u4e2a\u8282\u70b9\u7684\u5927\u89c4\u6a21\u5b9e\u4f8b\u65f6\uff0c\u80fd\u5728 0.1 \u79d2\u5185\u627e\u5230\u9ad8\u8d28\u91cf\u89e3\uff08\u6700\u4f18\u6027\u5dee\u8ddd\u4e3a 0.22%\uff09\uff0c\u8fdc\u8d85\u73b0\u6709\u65b9\u6cd5\u3002\u5728 100 \u8282\u70b9\u5b9e\u4f8b\u4e0a\uff0c\u76f8\u6bd4 ADNet \u57fa\u7ebf\uff0cGeoHopNet \u5c06\u89e3\u7684\u8d28\u91cf\u63d0\u9ad8\u4e86 22.2%\uff0c\u901f\u5ea6\u63d0\u5347\u4e86 1.8 \u500d\u3002", "conclusion": "GeoHopNet \u7b97\u6cd5\u5728\u89e3\u51b3\u5927\u89c4\u6a21\u57ce\u5e02\u65e0\u4eba\u673a\u52a8\u6001\u9009\u5740\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6548\u7387\u548c\u89e3\u7684\u8d28\u91cf\uff0c\u7a81\u7834\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u8ba1\u7b97\u74f6\u9888\u3002"}}
{"id": "2507.11430", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11430", "abs": "https://arxiv.org/abs/2507.11430", "authors": ["Arnab Mukherjee", "Raju Halder", "Joydeep Chandra"], "title": "FLsim: A Modular and Library-Agnostic Simulation Framework for Federated Learning", "comment": null, "summary": "Federated Learning (FL) has undergone significant development since its\ninception in 2016, advancing from basic algorithms to complex methodologies\ntailored to address diverse challenges and use cases. However, research and\nbenchmarking of novel FL techniques against a plethora of established\nstate-of-the-art solutions remain challenging. To streamline this process, we\nintroduce FLsim, a comprehensive FL simulation framework designed to meet the\ndiverse requirements of FL workflows in the literature. FLsim is characterized\nby its modularity, scalability, resource efficiency, and controlled\nreproducibility of experimental outcomes. Its easy to use interface allows\nusers to specify customized FL requirements through job configuration, which\nsupports: (a) customized data distributions, ranging from non-independent and\nidentically distributed (non-iid) data to independent and identically\ndistributed (iid) data, (b) selection of local learning algorithms according to\nuser preferences, with complete agnosticism to ML libraries, (c) choice of\nnetwork topology illustrating communication patterns among nodes, (d)\ndefinition of model aggregation and consensus algorithms, and (e) pluggable\nblockchain support for enhanced robustness. Through a series of experimental\nevaluations, we demonstrate the effectiveness and versatility of FLsim in\nsimulating a diverse range of state-of-the-art FL experiments. We envisage that\nFLsim would mark a significant advancement in FL simulation frameworks,\noffering unprecedented flexibility and functionality for researchers and\npractitioners alike.", "AI": {"tldr": "FLsim \u662f\u4e00\u4e2a\u7075\u6d3b\u3001\u53ef\u6269\u5c55\u4e14\u6613\u4e8e\u4f7f\u7528\u7684\u8054\u90a6\u5b66\u4e60\u6a21\u62df\u6846\u67b6\uff0c\u652f\u6301\u5b9a\u5236\u5316\u6570\u636e\u3001\u7b97\u6cd5\u3001\u7f51\u7edc\u62d3\u6251\u548c\u805a\u5408\u7b56\u7565\uff0c\u5e76\u53ef\u96c6\u6210\u533a\u5757\u94fe\uff0c\u6709\u52a9\u4e8e\u7b80\u5316\u8054\u90a6\u5b66\u4e60\u7684\u7814\u7a76\u548c\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u73b0\u6709\u7684\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u7814\u7a76\u548c\u65b0 FL \u6280\u672f\u4e0e\u4f17\u591a\u65e2\u6709\u6700\u5148\u8fdb\u89e3\u51b3\u65b9\u6848\u7684\u57fa\u51c6\u6d4b\u8bd5\u4ecd\u7136\u5145\u6ee1\u6311\u6218\u3002\u4e3a\u4e86\u7b80\u5316\u8fd9\u4e00\u8fc7\u7a0b\uff0c\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u6ee1\u8db3\u6587\u732e\u4e2d\u5404\u79cd FL \u5de5\u4f5c\u6d41\u9700\u6c42\u7684\u7efc\u5408\u6027 FL \u6a21\u62df\u6846\u67b6\u3002", "method": "\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3a FLsim \u7684\u7efc\u5408\u6027\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u6a21\u62df\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5177\u6709\u6a21\u5757\u5316\u3001\u53ef\u6269\u5c55\u3001\u8d44\u6e90\u6548\u7387\u9ad8\u4ee5\u53ca\u5b9e\u9a8c\u7ed3\u679c\u53ef\u63a7\u53ef\u590d\u73b0\u7b49\u7279\u70b9\u3002FLsim \u7684\u7528\u6237\u754c\u9762\u5141\u8bb8\u7528\u6237\u901a\u8fc7\u4f5c\u4e1a\u914d\u7f6e\u6307\u5b9a\u5b9a\u5236\u5316\u7684 FL \u9700\u6c42\uff0c\u652f\u6301\u5b9a\u5236\u5316\u7684\u6570\u636e\u5206\u5e03\uff08\u4ece\u975e\u72ec\u7acb\u540c\u5206\u5e03\u5230\u72ec\u7acb\u540c\u5206\u5e03\uff09\u3001\u652f\u6301\u7528\u6237\u9009\u62e9\u672c\u5730\u5b66\u4e60\u7b97\u6cd5\uff08\u4e0d\u4f9d\u8d56\u4e8e\u7279\u5b9a\u7684\u673a\u5668\u5b66\u4e60\u5e93\uff09\u3001\u652f\u6301\u9009\u62e9\u7f51\u7edc\u62d3\u6251\u4ee5\u8bf4\u660e\u8282\u70b9\u95f4\u7684\u901a\u4fe1\u6a21\u5f0f\u3001\u652f\u6301\u5b9a\u4e49\u6a21\u578b\u805a\u5408\u4e0e\u5171\u8bc6\u7b97\u6cd5\uff0c\u5e76\u652f\u6301\u53ef\u63d2\u5165\u7684\u533a\u5757\u94fe\u6280\u672f\u4ee5\u589e\u5f3a\u9c81\u68d2\u6027\u3002", "result": "\u901a\u8fc7\u4e00\u7cfb\u5217\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u8bc1\u660e\u4e86 FLsim \u5728\u6a21\u62df\u5404\u79cd\u6700\u5148\u8fdb\u7684\u8054\u90a6\u5b66\u4e60\u5b9e\u9a8c\u65b9\u9762\u7684\u6709\u6548\u6027\u548c\u591a\u529f\u80fd\u6027\u3002", "conclusion": "FLsim \u6846\u67b6\u80fd\u591f\u6709\u6548\u6a21\u62df\u5404\u79cd\u6700\u5148\u8fdb\u7684\u8054\u90a6\u5b66\u4e60\u5b9e\u9a8c\uff0c\u63d0\u4f9b\u4e86\u524d\u6240\u672a\u6709\u7684\u7075\u6d3b\u6027\u548c\u529f\u80fd\uff0c\u6709\u671b\u6210\u4e3a\u8054\u90a6\u5b66\u4e60\u6a21\u62df\u6846\u67b6\u7684\u91cd\u5927\u8fdb\u6b65\u3002"}}
{"id": "2507.11256", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2507.11256", "abs": "https://arxiv.org/abs/2507.11256", "authors": ["Sayan Bhattacharya", "Mart\u00edn Costa", "Ermiya Farokhnejad", "Shaofeng H. -C. Jiang", "Yaonan Jin", "Jianing Lou"], "title": "Fully Dynamic Euclidean k-Means", "comment": null, "summary": "We consider the fundamental Euclidean $k$-means clustering problem in a\ndynamic setting, where the input $X \\subseteq \\mathbb{R}^d$ evolves over time\nvia a sequence of point insertions/deletions. We have to explicitly maintain a\nsolution (a set of $k$ centers) $S \\subseteq \\mathbb{R}^d$ throughout these\nupdates, while minimizing the approximation ratio, the update time (time taken\nto handle a point insertion/deletion) and the recourse (number of changes made\nto the solution $S$) of the algorithm.\n  We present a dynamic algorithm for this problem with\n$\\text{poly}(1/\\epsilon)$-approximation ratio, $\\tilde{O}(k^{\\epsilon})$ update\ntime and $\\tilde{O}(1)$ recourse. In the general regime, where the dimension\n$d$ cannot be assumed to be a fixed constant, our algorithm has almost optimal\nguarantees across all these three parameters. Indeed, improving our update time\nor approximation ratio would imply beating the state-of-the-art static\nalgorithm for this problem (which is widely believed to be the best possible),\nand the recourse of any dynamic algorithm must be $\\Omega(1)$.\n  We obtain our result by building on top of the recent work of [Bhattacharya,\nCosta, Farokhnejad; STOC'25], which gave a near-optimal dynamic algorithm for\n$k$-means in general metric spaces (as opposed to in the Euclidean setting).\nAlong the way, we design several novel geometric data structures that are of\nindependent interest. Specifically, one of our main contributions is designing\nthe first consistent hashing scheme [Czumaj, Jiang, Krauthgamer, Vesel\\'y,\nYang; FOCS'22] that achieves $\\text{poly}(d)$ running time per point evaluation\nwith competitive parameters.", "AI": {"tldr": "\u9488\u5bf9\u52a8\u6001\u6b27\u6c0fk-\u5747\u503c\u805a\u7c7b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5177\u6709\u8fd1\u4e4e\u6700\u4f18\u8fd1\u4f3c\u6bd4\u3001\u66f4\u65b0\u65f6\u95f4\u548c\u8ffd\u7d22\u6027\u7684\u65b0\u7b97\u6cd5\u3002", "motivation": "\u5728\u52a8\u6001\u73af\u5883\u4e2d\u89e3\u51b3\u6b27\u6c0fk-\u5747\u503c\u805a\u7c7b\u95ee\u9898\uff0c\u8be5\u73af\u5883\u4e2d\u7684\u8f93\u5165\u70b9\u4f1a\u968f\u7740\u65f6\u95f4\u7684\u63a8\u79fb\u901a\u8fc7\u63d2\u5165/\u5220\u9664\u800c\u6f14\u53d8\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u8fd1\u4f3c\u6bd4\u3001\u66f4\u65b0\u65f6\u95f4\u548c\u8ffd\u7d22\u6027\u3002", "method": "\u901a\u8fc7\u5229\u7528\u6700\u8fd1\u5173\u4e8e\u5ea6\u91cf\u7a7a\u95f4k-\u5747\u503c\u805a\u7c7b\u95ee\u9898\u7684\u52a8\u6001\u7b97\u6cd5\u7684\u5de5\u4f5c\uff0c\u5e76\u7ed3\u5408\u65b0\u9896\u7684\u51e0\u4f55\u6570\u636e\u7ed3\u6784\uff0c\u7279\u522b\u662f\u7b2c\u4e00\u4e2a\u5b9e\u73b0\u591a\u9879\u5f0f\u65f6\u95f4\u6bcf\u70b9\u8bc4\u4f30\u7684\u76f8\u5bb9\u54c8\u5e0c\u65b9\u6848\uff0c\u6765\u89e3\u51b3\u6b27\u6c0fk-\u5747\u503c\u805a\u7c7b\u95ee\u9898\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u52a8\u6001\u7b97\u6cd5\uff0c\u5177\u6709\u591a\u9879\u5f0f\uff081/\u03b5\uff09\u7684\u8fd1\u4f3c\u6bd4\u3001\u8fd1\u4e4e\u6700\u4f18\u7684\uff08~O(k^\u03b5)\uff09\u66f4\u65b0\u65f6\u95f4\u4ee5\u53ca\u8fd1\u4e4e\u6700\u4f18\u7684\uff08~O(1)\uff09\u8ffd\u7d22\u6027\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u5728\u901a\u7528\u73af\u5883\u4e2d\u63d0\u4f9b\u4e86\u8fd1\u4e4e\u6700\u4f18\u7684\u4fdd\u8bc1\uff0c\u51e0\u4e4e\u6db5\u76d6\u4e86\u6240\u6709\u4e09\u4e2a\u53c2\u6570\uff08\u8fd1\u4f3c\u6bd4\u3001\u66f4\u65b0\u65f6\u95f4\u548c\u8ffd\u7d22\u6027\uff09\u3002"}}
{"id": "2507.11420", "categories": ["eess.SY", "cs.SY", "93C40", "I.2.8"], "pdf": "https://arxiv.org/pdf/2507.11420", "abs": "https://arxiv.org/abs/2507.11420", "authors": ["Mingcong Li"], "title": "A Risk-Aware Adaptive Robust MPC with Learned Uncertainty Quantification", "comment": "17 pages, 10 figures", "summary": "Solving chance-constrained optimal control problems for systems subject to\nnon-stationary uncertainties is a significant challenge.Conventional robust\nmodel predictive control (MPC) often yields excessive conservatism by relying\non static worst-case assumptions, while standard stochastic MPC methods\nstruggle when underlying uncertainty distributions are unknown a priori.This\narticle presents a Risk-Aware Adaptive Robust MPC (RAAR-MPC) framework,a\nhierarchical architecture that systematically orchestrates a novel synthesis of\nproactive, learning-based risk assessment and reactive risk regulation. The\nframework employs a medium-frequency risk assessment engine, which leverages\nGaussian process regression and active learning, to construct a tight,\ndata-driven characterization of the prediction error set from operational\ndata.Concurrently, a low-timescale outer loop implements a self-correcting\nupdate law for an adaptive safety margin to precisely regulate the empirical\nrisk and compensate for unmodeled dynamics.This dual-timescale adaptation\nenables the system to rigorously satisfy chance constraints with a user-defined\nprobability, while minimizing the conservatism inherent in traditional\napproaches.We formally establish that the interplay between these adaptive\ncomponents guarantees recursive feasibility and ensures the closed-loop system\nsatisfies the chance constraints up to a user-defined risk level with high\nprobability.Numerical experiments on a benchmark DC-DC converter under\nnon-stationary parametric uncertainties demonstrate that our framework\nprecisely achieves the target risk level, resulting in a significantly lower\naverage cost compared to state-of-the-art robust and stochastic MPC strategies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRAAR-MPC\u7684\u98ce\u9669\u611f\u77e5\u81ea\u9002\u5e94\u9c81\u68d2MPC\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u5177\u6709\u975e\u5e73\u7a33\u4e0d\u786e\u5b9a\u6027\u7684\u7ea6\u675f\u6700\u4f18\u63a7\u5236\u95ee\u9898\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u5b66\u4e60\u548c\u81ea\u9002\u5e94\u7b56\u7565\uff0c\u5728\u4fdd\u8bc1\u7ea6\u675f\u6ee1\u8db3\u7684\u540c\u65f6\u51cf\u5c11\u4e86\u4fdd\u5b88\u6027\u3002", "motivation": "\u89e3\u51b3\u53d7\u975e\u5e73\u7a33\u4e0d\u786e\u5b9a\u6027\u5f71\u54cd\u7684\u7ea6\u675f\u6700\u4f18\u63a7\u5236\u95ee\u9898\uff0c\u514b\u670d\u4f20\u7edf\u9c81\u68d2MPC\u7684\u8fc7\u5ea6\u4fdd\u5b88\u6027\u548c\u968f\u673aMPC\u5728\u672a\u77e5\u4e0d\u786e\u5b9a\u6027\u5206\u5e03\u4e0b\u7684\u56f0\u96be\u3002", "method": "RAAR-MPC\u6846\u67b6\u91c7\u7528\u5206\u5c42\u67b6\u6784\uff0c\u5305\u62ec\u4e00\u4e2a\u4e2d\u9891\u98ce\u9669\u8bc4\u4f30\u5f15\u64ce\uff08\u5229\u7528\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u548c\u4e3b\u52a8\u5b66\u4e60\u6784\u5efa\u6570\u636e\u9a71\u52a8\u7684\u9884\u6d4b\u8bef\u5dee\u96c6\uff09\u548c\u4e00\u4e2a\u4f4e\u65f6\u5e8f\u7684\u81ea\u7ea0\u6b63\u5916\u73af\uff08\u7528\u4e8e\u66f4\u65b0\u81ea\u9002\u5e94\u5b89\u5168\u88d5\u5ea6\uff09\uff0c\u4ee5\u5b9e\u73b0\u98ce\u9669\u8c03\u63a7\u3002", "result": "RAAR-MPC\u6846\u67b6\u5728DC-DC\u8f6c\u6362\u5668\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u8f83\u4e8e\u6700\u5148\u8fdb\u7684\u9c81\u68d2\u548c\u968f\u673aMPC\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u76ee\u6807\u98ce\u9669\u6c34\u5e73\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u4e86\u5e73\u5747\u6210\u672c\u3002", "conclusion": "RAAR-MPC\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u5b66\u4e60\u9a71\u52a8\u7684\u98ce\u9669\u8bc4\u4f30\u548c\u81ea\u9002\u5e94\u5b89\u5168\u88d5\u5ea6\uff0c\u80fd\u591f\u4e25\u683c\u6ee1\u8db3\u7528\u6237\u5b9a\u4e49\u7684\u6982\u7387\u7ea6\u675f\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u4fdd\u5b88\u6027\uff0c\u5e76\u4e14\u4fdd\u8bc1\u4e86\u9012\u5f52\u53ef\u884c\u6027\u3002"}}
{"id": "2507.10606", "categories": ["cs.LG", "cs.AI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2507.10606", "abs": "https://arxiv.org/abs/2507.10606", "authors": ["Bing-Yue Wu", "Vidya A. Chhabria"], "title": "DALI-PD: Diffusion-based Synthetic Layout Heatmap Generation for ML in Physical Design", "comment": "Under review at Asia and South Pacific Design Automation Conference\n  (ASP-DAC'26)", "summary": "Machine learning (ML) has demonstrated significant promise in various\nphysical design (PD) tasks. However, model generalizability remains limited by\nthe availability of high-quality, large-scale training datasets. Creating such\ndatasets is often computationally expensive and constrained by IP. While very\nfew public datasets are available, they are typically static, slow to generate,\nand require frequent updates. To address these limitations, we present DALI-PD,\na scalable framework for generating synthetic layout heatmaps to accelerate ML\nin PD research. DALI-PD uses a diffusion model to generate diverse layout\nheatmaps via fast inference in seconds. The heatmaps include power, IR drop,\ncongestion, macro placement, and cell density maps. Using DALI-PD, we created a\ndataset comprising over 20,000 layout configurations with varying macro counts\nand placements. These heatmaps closely resemble real layouts and improve ML\naccuracy on downstream ML tasks such as IR drop or congestion prediction.", "AI": {"tldr": "DALI-PD\uff1a\u4e00\u4e2a\u7528\u4e8e\u751f\u6210\u5408\u6210\u7269\u7406\u8bbe\u8ba1\u5e03\u5c40\u70ed\u56fe\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6269\u6563\u6a21\u578b\u52a0\u901f\u673a\u5668\u5b66\u4e60\u7814\u7a76\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u5728\u7269\u7406\u8bbe\u8ba1\u4efb\u52a1\u4e2d\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u53d7\u9650\u4e8e\u9ad8\u8d28\u91cf\u3001\u5927\u89c4\u6a21\u8bad\u7ec3\u6570\u636e\u7684\u53ef\u7528\u6027\uff0c\u800c\u73b0\u6709\u6570\u636e\u96c6\u521b\u5efa\u6210\u672c\u9ad8\u3001\u53d7IP\u9650\u5236\u4e14\u66f4\u65b0\u6162\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u6846\u67b6\u6765\u751f\u6210\u5408\u6210\u6570\u636e\u4ee5\u52a0\u901f\u7814\u7a76\u3002", "method": "DALI-PD\u6846\u67b6\u5229\u7528\u6269\u6563\u6a21\u578b\u751f\u6210\u5305\u62ec\u529f\u8017\u3001IR\u964d\u3001\u62e5\u585e\u3001\u5b8f\u653e\u7f6e\u548c\u5355\u5143\u5bc6\u5ea6\u5728\u5185\u7684\u591a\u79cd\u5e03\u5c40\u70ed\u56fe\uff0c\u5b9e\u73b0\u79d2\u7ea7\u5feb\u901f\u63a8\u7406\u3002", "result": "\u4f7f\u7528DALI-PD\u6846\u67b6\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u8d85\u8fc720,000\u4e2a\u5177\u6709\u4e0d\u540c\u5b8f\u6570\u91cf\u548c\u5e03\u5c40\u914d\u7f6e\u7684\u6570\u636e\u96c6\uff0c\u751f\u6210\u7684\u70ed\u56fe\u4e0e\u771f\u5b9e\u5e03\u5c40\u9ad8\u5ea6\u76f8\u4f3c\uff0c\u5e76\u6210\u529f\u63d0\u9ad8\u4e86\u4e0b\u6e38\u4efb\u52a1\uff08\u5982IR\u964d\u548c\u62e5\u585e\u9884\u6d4b\uff09\u7684\u673a\u5668\u5b66\u4e60\u51c6\u786e\u6027\u3002", "conclusion": "DALI-PD\u6846\u67b6\u901a\u8fc7\u5feb\u901f\u751f\u6210\u5408\u6210\u5e03\u5c40\u70ed\u56fe\uff0c\u89e3\u51b3\u4e86\u673a\u5668\u5b66\u4e60\u5728\u7269\u7406\u8bbe\u8ba1\u4efb\u52a1\u4e2d\u6570\u636e\u7a00\u758f\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u4e0b\u6e38\u4efb\u52a1\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2507.10914", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.10914", "abs": "https://arxiv.org/abs/2507.10914", "authors": ["James A. Preiss", "Fengze Xie", "Yiheng Lin", "Adam Wierman", "Yisong Yue"], "title": "Fast Non-Episodic Adaptive Tuning of Robot Controllers with Online Policy Optimization", "comment": "11 pages, 9 figures", "summary": "We study online algorithms to tune the parameters of a robot controller in a\nsetting where the dynamics, policy class, and optimality objective are all\ntime-varying. The system follows a single trajectory without episodes or state\nresets, and the time-varying information is not known in advance. Focusing on\nnonlinear geometric quadrotor controllers as a test case, we propose a\npractical implementation of a single-trajectory model-based online policy\noptimization algorithm, M-GAPS,along with reparameterizations of the quadrotor\nstate space and policy class to improve the optimization landscape. In hardware\nexperiments,we compare to model-based and model-free baselines that impose\nartificial episodes. We show that M-GAPS finds near-optimal parameters more\nquickly, especially when the episode length is not favorable. We also show that\nM-GAPS rapidly adapts to heavy unmodeled wind and payload disturbances, and\nachieves similar strong improvement on a 1:6-scale Ackermann-steered car. Our\nresults demonstrate the hardware practicality of this emerging class of online\npolicy optimization that offers significantly more flexibility than classic\nadaptive control, while being more stable and data-efficient than model-free\nreinforcement learning.", "AI": {"tldr": "M-GAPS \u662f\u4e00\u79cd\u65b0\u7684\u5728\u7ebf\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u52a8\u6001\u53d8\u5316\u7684\u673a\u5668\u4eba\u63a7\u5236\u5668\u53c2\u6570\u8c03\u6574\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u7814\u7a76\u5728\u52a8\u529b\u5b66\u3001\u7b56\u7565\u7c7b\u522b\u548c\u6700\u4f18\u76ee\u6807\u90fd\u968f\u65f6\u95f4\u53d8\u5316\u7684\u60c5\u51b5\u4e0b\uff0c\u673a\u5668\u4eba\u63a7\u5236\u5668\u53c2\u6570\u7684\u5728\u7ebf\u7b97\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u7684\u5355\u8f68\u8ff9\u5728\u7ebf\u7b56\u7565\u4f18\u5316\u7b97\u6cd5 M-GAPS\uff0c\u5e76\u5bf9\u56db\u65cb\u7ffc\u98de\u884c\u5668\u72b6\u6001\u7a7a\u95f4\u548c\u7b56\u7565\u7c7b\u522b\u8fdb\u884c\u4e86\u91cd\u65b0\u53c2\u6570\u5316\uff0c\u4ee5\u6539\u8fdb\u4f18\u5316\u666f\u89c2\u3002", "result": "M-GAPS \u6bd4\u56fa\u5b9a\u8bd5\u9a8c\u6bb5\u957f\u5ea6\u7684\u57fa\u7ebf\u7b97\u6cd5\u66f4\u5feb\u5730\u627e\u5230\u8fd1\u4f3c\u6700\u4f18\u53c2\u6570\uff0c\u5e76\u80fd\u5feb\u901f\u9002\u5e94\u672a\u5efa\u6a21\u7684\u98ce\u548c\u8d1f\u8f7d\u6270\u52a8\u3002\u5728 1:6 \u6bd4\u4f8b\u7684 Ackermann \u8f6c\u5411\u5c0f\u8f66\u4e0a\u4e5f\u53d6\u5f97\u4e86\u7c7b\u4f3c\u7684\u5927\u5e45\u6539\u8fdb\u3002", "conclusion": "M-GAPS \u7b97\u6cd5\u5728\u786c\u4ef6\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u5feb\u901f\u627e\u5230\u8fd1\u4f3c\u6700\u4f18\u53c2\u6570\uff0c\u5c24\u5176\u662f\u5728\u4e0d\u5229\u7684\u8bd5\u9a8c\u6bb5\u957f\u5ea6\u4e0b\uff0c\u5e76\u80fd\u5feb\u901f\u9002\u5e94\u98ce\u548c\u8d1f\u8f7d\u6270\u52a8\uff0c\u5728 1:6 \u6bd4\u4f8b\u7684 Ackermann \u8f6c\u5411\u5c0f\u8f66\u4e0a\u4e5f\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7b97\u6cd5\u4ee3\u8868\u4e86\u4e00\u7c7b\u65b0\u5174\u7684\u5728\u7ebf\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\uff0c\u6bd4\u4f20\u7edf\u81ea\u9002\u5e94\u63a7\u5236\u66f4\u7075\u6d3b\uff0c\u6bd4\u65e0\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u66f4\u7a33\u5b9a\u3001\u6570\u636e\u66f4\u9ad8\u6548\u3002"}}
{"id": "2507.11413", "categories": ["eess.SP", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.11413", "abs": "https://arxiv.org/abs/2507.11413", "authors": ["Christos N. Efrem", "Ioannis Krikidis"], "title": "Joint Power Allocation and Reflecting-Element Activation for Energy Efficiency Maximization in IRS-Aided Communications Under CSI Uncertainty", "comment": "5 pages, 3 figures", "summary": "We study the joint power allocation and reflecting element (RE) activation to\nmaximize the energy efficiency (EE) in communication systems assisted by an\nintelligent reflecting surface (IRS), taking into account imperfections in\nchannel state information (CSI). The robust optimization problem is mixed\ninteger, i.e., the optimization variables are continuous (transmit power) and\ndiscrete (binary states of REs). In order to solve this challenging problem we\ndevelop two algorithms. The first one is an alternating optimization (AO)\nmethod that attains a suboptimal solution with low complexity, based on the\nLambert W function and a dynamic programming (DP) algorithm. The second one is\na branch-and-bound (B&B) method that uses AO as its subroutine and is formally\nguaranteed to achieve a globally optimal solution. Both algorithms do not\nrequire any external optimization solver for their implementation. Furthermore,\nnumerical results show that the proposed algorithms outperform the baseline\nschemes, AO achieves near-optimal performance in most cases, and B&B has low\ncomputational complexity on average.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u4e0d\u5b8c\u7f8e\u7684\u667a\u80fd\u53cd\u5c04\u9762\uff08IRS\uff09\u8f85\u52a9\u901a\u4fe1\u7cfb\u7edf\u4e2d\uff0c\u8054\u5408\u529f\u7387\u5206\u914d\u548c\u53cd\u5c04\u5355\u5143\uff08RE\uff09\u6fc0\u6d3b\u4ee5\u6700\u5927\u5316\u80fd\u91cf\u6548\u7387\uff08EE\uff09\u7684\u95ee\u9898\u3002\u6587\u7ae0\u63d0\u51fa\u4e86\u4e00\u79cd\u4ea4\u66ff\u4f18\u5316\uff08AO\uff09\u7b97\u6cd5\u548c\u4e00\u79cd\u5206\u652f\u5b9a\u754c\uff08B&B\uff09\u7b97\u6cd5\u6765\u89e3\u51b3\u8be5\u95ee\u9898\uff0c\u5e76\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u7b97\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u4e3a\u4e86\u5728\u8003\u8651\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\uff08CSI\uff09\u4e0d\u5b8c\u7f8e\u7684\u60c5\u51b5\u4e0b\uff0c\u6700\u5927\u5316\u667a\u80fd\u53cd\u5c04\u9762\uff08IRS\uff09\u8f85\u52a9\u901a\u4fe1\u7cfb\u7edf\u7684\u80fd\u91cf\u6548\u7387\uff08EE\uff09\uff0c\u9700\u8981\u7814\u7a76\u8054\u5408\u529f\u7387\u5206\u914d\u548c\u53cd\u5c04\u5355\u5143\uff08RE\uff09\u6fc0\u6d3b\u95ee\u9898\u3002", "method": "\u6587\u7ae0\u63d0\u51fa\u4e86\u4e00\u79cd\u4ea4\u66ff\u4f18\u5316\uff08AO\uff09\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5229\u7528\u6717\u4f2fW\u51fd\u6570\u548c\u52a8\u6001\u89c4\u5212\uff08DP\uff09\u6765\u89e3\u51b3\u9c81\u68d2\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u652f\u5b9a\u754c\uff08B&B\uff09\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5229\u7528AO\u4f5c\u4e3a\u5b50\u7a0b\u5e8f\uff0c\u80fd\u591f\u4fdd\u8bc1\u627e\u5230\u5168\u5c40\u6700\u4f18\u89e3\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6848\uff0cAO\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u6027\u80fd\uff0c\u5e76\u4e14B&B\u7b97\u6cd5\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u5e73\u5747\u8f83\u4f4e\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4ea4\u66ff\u4f18\u5316\uff08AO\uff09\u548c\u5206\u652f\u5b9a\u754c\uff08B&B\uff09\u7b97\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5177\u6709\u8f83\u4f4e\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u63a5\u8fd1\u6700\u4f18\u7684\u6027\u80fd\u3002"}}
{"id": "2507.10964", "categories": ["cond-mat.mtrl-sci", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2507.10964", "abs": "https://arxiv.org/abs/2507.10964", "authors": ["Chenfei Shi", "Zhaodi Lin", "Qiyuan Liu", "Junai Lv", "Xiaofan Xu", "Baojuan Kang", "Jin-Hu Yang", "Yi Liu", "Jian Zhang", "Shixun Cao", "Jin-Ke Bao"], "title": "Weak low-temperature ferromagnetism and linear magnetoresistance in Lu$_{0.75}$Fe$_6$Sn$_6$ with a disordered HfFe$_6$Ge$_6$-type structure", "comment": "20 pages, 6 figures", "summary": "We report the synthesis of Lu$_{0.75}$Fe$_6$Sn$_6$ single crystals with a\nFe-kagome lattice using a self-flux method. The crystal structure, magnetic,\nthermodynamic and electrical transport properties were investigated. Structure\nrefinement reveals that Lu$_{0.75}$Fe$_6$Sn$_6$ has a HfFe$_6$Ge$_6$-type\nstructure as the major framework intergrown with a CoSn-type structure, leading\nto a vacancy of 25% on the Lu-site and disorder on the Sn-site. It exhibits a\nsignificant magnetic anisotropy with weak ferromagnetism in the ab-plane below\n40 K and antiferromagnetic behavior along the c-axis. The weak ferromagnetism\nis due to the canted antiferromagnetism with magnetic moment deviating from the\n$c$-axis to the ab-plane. Besides, an anisotropic non-saturated linear\nmagnetoresistance is also observed in Lu$_{0.75}$Fe$_6$Sn$_6$, probably\nresulting from the structural disorder in the sample.", "AI": {"tldr": "\u7814\u7a76\u4eba\u5458\u4f7f\u7528\u81ea\u7194\u5242\u6cd5\u5408\u6210\u4e86\u4e00\u79cd\u540d\u4e3a Lu$_{0.75}$Fe$_6$Sn$_6$ \u7684\u65b0\u6750\u6599\uff0c\u53d1\u73b0\u5b83\u5177\u6709\u590d\u6742\u7684\u6676\u4f53\u7ed3\u6784\uff0c\u5e76\u5728\u4f4e\u6e29\u4e0b\u8868\u73b0\u51fa\u6709\u8da3\u7684\u78c1\u6027\u548c\u7535\u5b66\u7279\u6027\uff0c\u5305\u62ec\u5e73\u9762\u5185\u7684\u5f31\u94c1\u78c1\u6027\u548c\u7ebf\u6027\u78c1\u963b\uff0c\u8fd9\u53ef\u80fd\u4e0e\u6750\u6599\u7684\u7ed3\u6784\u7f3a\u9677\u6709\u5173\u3002", "motivation": "\u63a2\u7d22\u5177\u6709 Fe-kagome \u6676\u683c\u7684 Lu$_{0.75}$Fe$_6$Sn$_6$ \u6750\u6599\u7684\u5408\u6210\u53ca\u5176\u7269\u7406\u6027\u8d28\u3002", "method": "\u4f7f\u7528\u81ea\u7194\u5242\u6cd5\u5408\u6210 Lu$_{0.75}$Fe$_6$Sn$_6$ \u5355\u6676\uff0c\u5e76\u7814\u7a76\u5176\u6676\u4f53\u7ed3\u6784\u3001\u78c1\u6027\u3001\u70ed\u529b\u5b66\u548c\u7535\u8f93\u8fd0\u6027\u8d28\u3002", "result": "\u5408\u6210\u4e86 Lu$_{0.75}$Fe$_6$Sn$_6$ \u5355\u6676\uff0c\u53d1\u73b0\u5176\u7ed3\u6784\u4e3a HfFe$_6$Ge$_6$ \u578b\u4e0e CoSn \u578b\u7ed3\u6784\u7684\u4ea4\u9519\uff0cLu \u4f4d\u5b58\u5728 25% \u7a7a\u4f4d\uff0cSn \u4f4d\u5b58\u5728\u65e0\u5e8f\u3002\u5728 40 K \u4ee5\u4e0b\u8868\u73b0\u51fa ab \u5e73\u9762\u5185\u7684\u5f31\u94c1\u78c1\u6027\uff08\u503e\u659c\u53cd\u94c1\u78c1\u6027\uff09\u548c c \u8f74\u65b9\u5411\u7684\u53cd\u94c1\u78c1\u6027\uff0c\u5e76\u89c2\u5bdf\u5230\u5404\u5411\u5f02\u6027\u7684\u975e\u9971\u548c\u7ebf\u6027\u78c1\u963b\u3002", "conclusion": "\u8be5\u7814\u7a76\u62a5\u544a\u4e86\u4f7f\u7528\u81ea\u7194\u5242\u6cd5\u5408\u6210\u5177\u6709 Fe-kagome \u6676\u683c\u7684 Lu$_{0.75}$Fe$_6$Sn$_6$ \u5355\u6676\uff0c\u5e76\u5bf9\u5176\u8fdb\u884c\u4e86\u7ed3\u6784\u3001\u78c1\u6027\u3001\u70ed\u529b\u5b66\u548c\u8f93\u8fd0\u6027\u8d28\u7684\u7814\u7a76\u3002\u7ed3\u6784\u7cbe\u70bc\u8868\u660e\uff0cLu$_{0.75}$Fe$_6$Sn$_6$ \u4e3b\u8981\u6846\u67b6\u4e3a HfFe$_6$Ge$_6$ \u578b\u7ed3\u6784\uff0c\u5e76\u4f34\u6709 CoSn \u578b\u7ed3\u6784\uff0c\u5bfc\u81f4 Lu \u4f4d\u5b58\u5728 25% \u7684\u7a7a\u4f4d\u4ee5\u53ca Sn \u4f4d\u5b58\u5728\u65e0\u5e8f\u3002\u8be5\u6750\u6599\u5728 40 K \u4ee5\u4e0b\u8868\u73b0\u51fa\u663e\u8457\u7684\u78c1\u5404\u5411\u5f02\u6027\uff0c\u5728 ab \u5e73\u9762\u5185\u5177\u6709\u5f31\u94c1\u78c1\u6027\uff0c\u800c\u5728 c \u8f74\u65b9\u5411\u8868\u73b0\u51fa\u53cd\u94c1\u78c1\u884c\u4e3a\u3002\u5f31\u94c1\u78c1\u6027\u6e90\u4e8e\u503e\u659c\u7684\u53cd\u94c1\u78c1\u6027\uff0c\u78c1\u77e9\u504f\u79bb c \u8f74\u6307\u5411 ab \u5e73\u9762\u3002\u6b64\u5916\uff0c\u5728 Lu$_{0.75}$Fe$_6$Sn$_6$ \u4e2d\u8fd8\u89c2\u5bdf\u5230\u5404\u5411\u5f02\u6027\u7684\u975e\u9971\u548c\u7ebf\u6027\u78c1\u963b\uff0c\u8fd9\u53ef\u80fd\u6e90\u4e8e\u6837\u54c1\u4e2d\u7684\u7ed3\u6784\u65e0\u5e8f\u3002"}}
{"id": "2507.11349", "categories": ["cs.LO"], "pdf": "https://arxiv.org/pdf/2507.11349", "abs": "https://arxiv.org/abs/2507.11349", "authors": ["Julie Cailler", "Simon Guilloud"], "title": "SC-TPTP: An Extension of the TPTP Derivation Format for Sequent-Based Calculus", "comment": null, "summary": "Motivated by the transfer of proofs between proof systems, and in particular\nfrom first order automated theorem provers (ATPs) to interactive theorem\nprovers (ITPs), we specify an extension of the TPTP derivation text format to\ndescribe proofs in first-order logic: SC-TPTP. To avoid multiplication of\nstandards, our proposed format over-specifies the TPTP derivation format by\nfocusing on sequent formalisms. By doing so, it provides a high level of\ndetail, is faithful to mathematical tradition, and cover multiple existing\ntools and in particular tableaux-based strategies. We make use of this format\nto allow the Lisa proof assistant to query the Go\\'eland automated theorem\nprover, and implement a library of tools able to parse, print and check SC-TPTP\nproofs, export them into Coq files, and rebuild low-level proof steps from\nadvanced ones.", "AI": {"tldr": "A new format (SC-TPTP) and tools were created to transfer first-order logic proofs between automated and interactive theorem provers, demonstrated by connecting Lisa and Go'eland.", "motivation": "Motivated by the transfer of proofs between proof systems, particularly from first-order automated theorem provers (ATPs) to interactive theorem provers (ITPs).", "method": "Specified an extension of the TPTP derivation text format (SC-TPTP) focusing on sequent formalisms to describe first-order logic proofs, and implemented a library of tools for parsing, printing, checking, and exporting these proofs, including rebuilding low-level proof steps from advanced ones.", "result": "Developed SC-TPTP format and a library of tools, enabling the Lisa proof assistant to query the Go'eland automated theorem prover and facilitating proof management and interoperability between different proof systems.", "conclusion": "We specified an extension of the TPTP derivation text format to describe proofs in first-order logic called SC-TPTP, which allows the Lisa proof assistant to query the Go'eland automated theorem prover and provides a library of tools for managing SC-TPTP proofs."}}
{"id": "2507.10763", "categories": ["cond-mat.mes-hall", "cond-mat.quant-gas", "cond-mat.str-el", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2507.10763", "abs": "https://arxiv.org/abs/2507.10763", "authors": ["Leyla Saraj", "Daksh Malhotra", "Aymar Muhikira", "Alexander J. Shook", "John P. Davis", "Igor Boettcher"], "title": "Dimensional crossover of superfluid $^{3}$He in a magnetic field", "comment": "35 pages", "summary": "Motivated by recent experiments on superfluid $^3$He in nanoscale-confined\ngeometries, we theoretically investigate the associated phase diagram in a slab\ngeometry and perpendicular magnetic field as the size of confinement is varied.\nOur analysis is based on minimizing the Ginzburg--Landau free energy for the\n$3\\times 3$ matrix superfluid order parameter for three different boundary\nconditions. We observe a smooth crossover from the phase diagram of the 3D\nsystem to the quasi-2D limit for slab heights of several hundred nanometres and\nmagnetic fields of several kilogauss. We illuminate that, despite the apparent\ncomplexity of the underlying equations, many precise numerical and even\nanalytical statements can be made about the phase structure for general values\nof the coefficients of the free energy functional, which can in turn be used to\nconstrain or measure these parameters. To guide future experimental studies, we\ncompute the phase diagram in dependence of pressure, temperature, slab height,\nand magnetic field.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5728\u7eb3\u7c73\u9650\u5236\u51e0\u4f55\u4e2d\u63a2\u7d22\u4e86\u8d85\u6d413He\u7684\u76f8\u4f4d\u56fe\uff0c\u53d1\u73b0\u4e86\u4ece3D\u5230\u51c62D\u7684\u5e73\u6ed1\u8fc7\u6e21\uff0c\u5e76\u4e3a\u5b9e\u9a8c\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "motivation": "\u8bba\u6587\u7684\u52a8\u673a\u662f\u53d7\u5230\u8fd1\u671f\u5728\u7eb3\u7c73\u5c3a\u5ea6\u9650\u5236\u51e0\u4f55\u5f62\u72b6\u4e0b\u8d85\u6d413He\u5b9e\u9a8c\u7684\u542f\u53d1\u3002", "method": "\u8bba\u6587\u57fa\u4e8e\u6700\u5c0f\u5316Ginzburg-Landau\u81ea\u7531\u80fd\uff0c\u91c7\u75283x3\u77e9\u9635\u8d85\u6d41\u5e8f\u53c2\u6570\uff0c\u5e76\u8003\u8651\u4e86\u4e09\u79cd\u4e0d\u540c\u7684\u8fb9\u754c\u6761\u4ef6\u3002", "result": "\u7814\u7a76\u89c2\u5bdf\u5230\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\uff0c\u4ece3D\u7cfb\u7edf\u5230\u51c62D\u6781\u9650\u5b58\u5728\u5e73\u6ed1\u7684\u76f8\u53d8\uff0c\u5e76\u4e14\u53ef\u4ee5\u5bf9\u81ea\u7531\u80fd\u6cdb\u51fd\u7cfb\u6570\u8fdb\u884c\u7cbe\u786e\u7684\u6570\u503c\u548c\u89e3\u6790\u8bf4\u660e\uff0c\u4e5f\u53ef\u7528\u4e8e\u7ea6\u675f\u6216\u6d4b\u91cf\u8fd9\u4e9b\u53c2\u6570\u3002", "conclusion": "\u8bba\u6587\u5bf9\u8d85\u6d413He\u5728\u7eb3\u7c73\u5c3a\u5ea6\u9650\u5236\u51e0\u4f55\u5f62\u72b6\u4e0b\u7684\u76f8\u4f4d\u56fe\u8fdb\u884c\u4e86\u7406\u8bba\u7814\u7a76\uff0c\u91cd\u70b9\u5173\u6ce8\u5e73\u677f\u51e0\u4f55\u548c\u5782\u76f4\u78c1\u573a\u5bf9\u9650\u5236\u5c3a\u5bf8\u53d8\u5316\u7684\u54cd\u5e94\u3002\u901a\u8fc7\u5bf9\u5177\u6709\u4e09\u79cd\u4e0d\u540c\u8fb9\u754c\u6761\u4ef6\u76843x3\u77e9\u9635\u8d85\u6d41\u5e8f\u53c2\u6570\u7684Ginzburg-Landau\u81ea\u7531\u80fd\u8fdb\u884c\u6700\u5c0f\u5316\u5206\u6790\uff0c\u7814\u7a76\u89c2\u5bdf\u5230\u5728\u6570\u767e\u7eb3\u7c73\u7684\u5e73\u677f\u9ad8\u5ea6\u548c\u6570\u5343\u9ad8\u65af\u78c1\u573a\u4e0b\uff0c\u4ece3D\u7cfb\u7edf\u5230\u51c62D\u6781\u9650\u7684\u5e73\u6ed1\u8fc7\u6e21\u3002\u7814\u7a76\u8fd8\u6307\u51fa\uff0c\u5c3d\u7ba1\u5e95\u5c42\u65b9\u7a0b\u590d\u6742\uff0c\u4f46\u53ef\u4ee5\u5bf9\u81ea\u7531\u80fd\u6cdb\u51fd\u7cfb\u6570\u7684\u4e00\u822c\u503c\u8fdb\u884c\u7cbe\u786e\u7684\u6570\u503c\u548c\u89e3\u6790\u8bf4\u660e\uff0c\u8fd9\u53ef\u7528\u4e8e\u7ea6\u675f\u6216\u6d4b\u91cf\u8fd9\u4e9b\u53c2\u6570\u3002\u4e3a\u4e86\u6307\u5bfc\u672a\u6765\u7684\u5b9e\u9a8c\u7814\u7a76\uff0c\u8bba\u6587\u8ba1\u7b97\u4e86\u76f8\u4f4d\u56fe\u4e0e\u538b\u529b\u3001\u6e29\u5ea6\u3001\u5e73\u677f\u9ad8\u5ea6\u548c\u78c1\u573a\u7684\u5173\u7cfb\u3002"}}
{"id": "2507.10699", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.10699", "abs": "https://arxiv.org/abs/2507.10699", "authors": ["Jan Balewski", "Wan-Hsuan Lin", "Anupam Mitra", "Milan Kornja\u010da", "Stefan Ostermann", "Pedro L. S. Lopes", "Daniel Bochen Tan", "Jason Cong"], "title": "Compilation ofQCrank Encoding Algorithm for a Dynamically Programmable Qubit Array Processor", "comment": "7 pages, 5 figures", "summary": "Algorithm and hardware-aware compilation co-design is essential for the\nefficient deployment of near-term quantum programs. We present a compilation\ncase-study implementing QCrank -- an efficient encoding protocol for storing\nsequenced real-valued classical data in a quantum state -- targeting neutral\natom-based Dynamically Programmable Qubit Arrays (DPQAs). We show how key\nfeatures of neutral-atom arrays such as high qubits count, operation\nparallelism, multi-zone architecture, and natively reconfigurable connectivity\ncan be used to inform effective algorithm deployment. We identify algorithmic\nand circuit features that signal opportunities to implement them in a\nhardware-efficient manner. To evaluate projected hardware performance, we\ndefine a realistic noise model for DPQAs using parameterized Pauli channels,\nimplement it in Qiskit circuit simulators, and assess QCrank's accuracy for\nwriting and reading back 24-320 real numbers into 6-20 qubits. We compare DPQA\nresults with simulated performances of Quantinuum's H1-1E and with experimental\nresults from IBM Fez, highlighting promising accuracy scaling for DPQAs.", "AI": {"tldr": "QCrank \u534f\u8bae\u901a\u8fc7\u7b97\u6cd5\u548c\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\uff0c\u5728 DPQA \u4e0a\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u6570\u636e\u7f16\u7801\uff0c\u663e\u793a\u51fa\u826f\u597d\u7684\u51c6\u786e\u6027\u6269\u5c55\u6f5c\u529b\u3002", "motivation": "\u4e3a\u4e86\u5728\u8fd1\u671f\u7684\u91cf\u5b50\u7a0b\u5e8f\u4e2d\u9ad8\u6548\u90e8\u7f72\uff0c\u9700\u8981\u8fdb\u884c\u7b97\u6cd5\u548c\u786c\u4ef6\u611f\u77e5\u7684\u7f16\u8bd1\u534f\u540c\u8bbe\u8ba1\uff0c\u7279\u522b\u662f\u9488\u5bf9\u5177\u6709\u9ad8\u91cf\u5b50\u6bd4\u7279\u6570\u3001\u64cd\u4f5c\u5e76\u884c\u6027\u3001\u591a\u533a\u57df\u67b6\u6784\u548c\u53ef\u91cd\u6784\u8fde\u63a5\u7b49\u7279\u6027\u7684\u4e2d\u6027\u539f\u5b50 DPQA\u3002", "method": "\u901a\u8fc7\u4f7f\u7528\u53c2\u6570\u5316\u6ce1\u5229\u901a\u9053\u7684\u566a\u58f0\u6a21\u578b\uff0c\u5728 Qiskit \u4e2d\u5bf9 DPQA \u8fdb\u884c\u4e86\u6a21\u62df\uff0c\u5e76\u8bc4\u4f30\u4e86 QCrank \u5c06 24-320 \u4e2a\u5b9e\u6570\u5199\u5165\u548c\u8bfb\u51fa 6-20 \u4e2a\u91cf\u5b50\u6bd4\u7279\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4e0e Quantinuum H1-1E \u7684\u6a21\u62df\u6027\u80fd\u548c IBM Fez \u7684\u5b9e\u9a8c\u7ed3\u679c\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "result": "DPQA \u5728\u5199/\u8bfb 24-320 \u4e2a\u5b9e\u6570\u5230 6-20 \u4e2a\u91cf\u5b50\u6bd4\u7279\u65f6\u8868\u73b0\u51fa\u6709\u5e0c\u671b\u7684\u51c6\u786e\u6027\u6269\u5c55\uff0c\u5728\u4e0e Quantinuum H1-1E \u548c IBM Fez \u7684\u6bd4\u8f83\u4e2d\u663e\u793a\u51fa\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\u3002", "conclusion": "DPQA \u5728\u5904\u7406 QCrank \u534f\u8bae\u65b9\u9762\u5177\u6709\u51c6\u786e\u6027\u6269\u5c55\u7684\u6f5c\u529b\uff0c\u4e0e Quantinuum H1-1E \u7b49\u786c\u4ef6\u76f8\u6bd4\uff0c\u8be5\u534f\u8bae\u80fd\u591f\u5c06\u5927\u91cf\u5b9e\u503c\u7ecf\u5178\u6570\u636e\u7f16\u7801\u5230\u91cf\u5b50\u6001\u4e2d\u3002"}}
{"id": "2507.10855", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10855", "abs": "https://arxiv.org/abs/2507.10855", "authors": ["Wei Chen", "Jingxi Yu", "Zichen Miao", "Qiang Qiu"], "title": "Sparse Fine-Tuning of Transformers for Generative Tasks", "comment": "Accepted by International Conference on Computer Vision 2025", "summary": "Large pre-trained transformers have revolutionized artificial intelligence\nacross various domains, and fine-tuning remains the dominant approach for\nadapting these models to downstream tasks due to the cost of training from\nscratch. However, in existing fine-tuning methods, the updated representations\nare formed as a dense combination of modified parameters, making it challenging\nto interpret their contributions and understand how the model adapts to new\ntasks. In this work, we introduce a fine-tuning framework inspired by sparse\ncoding, where fine-tuned features are represented as a sparse combination of\nbasic elements, i.e., feature dictionary atoms. The feature dictionary atoms\nfunction as fundamental building blocks of the representation, and tuning atoms\nallows for seamless adaptation to downstream tasks. Sparse coefficients then\nserve as indicators of atom importance, identifying the contribution of each\natom to the updated representation. Leveraging the atom selection capability of\nsparse coefficients, we first demonstrate that our method enhances image\nediting performance by improving text alignment through the removal of\nunimportant feature dictionary atoms. Additionally, we validate the\neffectiveness of our approach in the text-to-image concept customization task,\nwhere our method efficiently constructs the target concept using a sparse\ncombination of feature dictionary atoms, outperforming various baseline\nfine-tuning methods.", "AI": {"tldr": "\u4e00\u79cd\u53d7\u7a00\u758f\u7f16\u7801\u542f\u53d1\u7684\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7\u7a00\u758f\u7ec4\u5408\u7279\u5f81\u5b57\u5178\u539f\u5b50\u6765\u9002\u5e94\u4e0b\u6e38\u4efb\u52a1\uff0c\u63d0\u9ad8\u4e86\u56fe\u50cf\u7f16\u8f91\u548c\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u7684\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u5fae\u8c03\u65b9\u6cd5\u5c06\u66f4\u65b0\u540e\u7684\u8868\u793a\u5f62\u5f0f\u5316\u4e3a\u4fee\u6539\u53c2\u6570\u7684\u5bc6\u96c6\u7ec4\u5408\uff0c\u4f7f\u5f97\u89e3\u91ca\u5176\u8d21\u732e\u548c\u7406\u89e3\u6a21\u578b\u5982\u4f55\u9002\u5e94\u65b0\u4efb\u52a1\u53d8\u5f97\u56f0\u96be\u3002", "method": "\u672c\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u79cd\u53d7\u7a00\u758f\u7f16\u7801\u542f\u53d1\u7684\u5fae\u8c03\u6846\u67b6\uff0c\u5176\u4e2d\u5fae\u8c03\u540e\u7684\u7279\u5f81\u8868\u793a\u4e3a\u57fa\u672c\u5143\u7d20\uff08\u5373\u7279\u5f81\u5b57\u5178\u539f\u5b50\uff09\u7684\u7a00\u758f\u7ec4\u5408\u3002\u7a00\u758f\u7cfb\u6570\u4f5c\u4e3a\u539f\u5b50\u91cd\u8981\u6027\u7684\u6307\u6807\uff0c\u7528\u4e8e\u8bc6\u522b\u6bcf\u4e2a\u539f\u5b50\u5bf9\u66f4\u65b0\u8868\u793a\u7684\u8d21\u732e\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u56fe\u50cf\u7f16\u8f91\u4efb\u52a1\u4e2d\u901a\u8fc7\u79fb\u9664\u4e0d\u91cd\u8981\u7684\u7279\u5f81\u5b57\u5178\u539f\u5b50\u63d0\u9ad8\u4e86\u6587\u672c\u5bf9\u9f50\u5ea6\uff1b\u5728\u6587\u672c\u5230\u56fe\u50cf\u7684\u6982\u5ff5\u5b9a\u5236\u4efb\u52a1\u4e2d\uff0c\u8be5\u65b9\u6cd5\u6709\u6548\u5730\u6784\u5efa\u4e86\u76ee\u6807\u6982\u5ff5\uff0c\u5e76\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u79fb\u9664\u4e0d\u91cd\u8981\u7684\u7279\u5f81\u5b57\u5178\u539f\u5b50\u6765\u589e\u5f3a\u56fe\u50cf\u7f16\u8f91\u6027\u80fd\uff0c\u63d0\u9ad8\u6587\u672c\u5bf9\u9f50\u5ea6\uff0c\u5e76\u5728\u6587\u672c\u5230\u56fe\u50cf\u7684\u6982\u5ff5\u5b9a\u5236\u4efb\u52a1\u4e2d\uff0c\u901a\u8fc7\u7a00\u758f\u7ec4\u5408\u7279\u5f81\u5b57\u5178\u539f\u5b50\u6709\u6548\u5730\u6784\u5efa\u76ee\u6807\u6982\u5ff5\uff0c\u4f18\u4e8e\u5404\u79cd\u57fa\u7ebf\u5fae\u8c03\u65b9\u6cd5\u3002"}}
{"id": "2507.10761", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.10761", "abs": "https://arxiv.org/abs/2507.10761", "authors": ["Tyler King", "Nikolos Gurney", "John H. Miller", "Volkan Ustun"], "title": "Detecting AI Assistance in Abstract Complex Tasks", "comment": "Accepted to HCII 2025", "summary": "Detecting assistance from artificial intelligence is increasingly important\nas they become ubiquitous across complex tasks such as text generation, medical\ndiagnosis, and autonomous driving. Aid detection is challenging for humans,\nespecially when looking at abstract task data. Artificial neural networks excel\nat classification thanks to their ability to quickly learn from and process\nlarge amounts of data -- assuming appropriate preprocessing. We posit detecting\nhelp from AI as a classification task for such models. Much of the research in\nthis space examines the classification of complex but concrete data classes,\nsuch as images. Many AI assistance detection scenarios, however, result in data\nthat is not machine learning-friendly. We demonstrate that common models can\neffectively classify such data when it is appropriately preprocessed. To do so,\nwe construct four distinct neural network-friendly image formulations along\nwith an additional time-series formulation that explicitly encodes the\nexploration/exploitation of users, which allows for generalizability to other\nabstract tasks. We benchmark the quality of each image formulation across three\nclassical deep learning architectures, along with a parallel CNN-RNN\narchitecture that leverages the additional time series to maximize testing\nperformance, showcasing the importance of encoding temporal and spatial\nquantities for detecting AI aid in abstract tasks.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.10772", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.10772", "abs": "https://arxiv.org/abs/2507.10772", "authors": ["Michal Podstawski"], "title": "Applying Text Embedding Models for Efficient Analysis in Labeled Property Graphs", "comment": null, "summary": "Labeled property graphs often contain rich textual attributes that can\nenhance analytical tasks when properly leveraged. This work explores the use of\npretrained text embedding models to enable efficient semantic analysis in such\ngraphs. By embedding textual node and edge properties, we support downstream\ntasks including node classification and relation prediction with improved\ncontextual understanding. Our approach integrates language model embeddings\ninto the graph pipeline without altering its structure, demonstrating that\ntextual semantics can significantly enhance the accuracy and interpretability\nof property graph analysis.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5d4c\u5165\u6587\u672c\u5c5e\u6027\u6765\u589e\u5f3a\u5c5e\u6027\u56fe\u7684\u5206\u6790\uff0c\u63d0\u9ad8\u4e86\u8282\u70b9\u5206\u7c7b\u548c\u5173\u7cfb\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5229\u7528\u6807\u8bb0\u5c5e\u6027\u56fe\u4e2d\u4e30\u5bcc\u7684\u6587\u672c\u5c5e\u6027\u6765\u589e\u5f3a\u5206\u6790\u4efb\u52a1\u3002", "method": "\u63a2\u7d22\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u6587\u672c\u5d4c\u5165\u6a21\u578b\u6765\u5d4c\u5165\u6587\u672c\u8282\u70b9\u548c\u8fb9\u7f18\u5c5e\u6027\uff0c\u4ee5\u5b9e\u73b0\u9ad8\u6548\u7684\u8bed\u4e49\u5206\u6790\u3002", "result": "\u901a\u8fc7\u5d4c\u5165\u6587\u672c\u5c5e\u6027\uff0c\u652f\u6301\u8282\u70b9\u5206\u7c7b\u548c\u5173\u7cfb\u9884\u6d4b\u7b49\u4e0b\u6e38\u4efb\u52a1\uff0c\u5e76\u63d0\u9ad8\u4e86\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u5c06\u6587\u672c\u8bed\u4e49\u96c6\u6210\u5230\u5c5e\u6027\u56fe\u7684\u5206\u6790\u6d41\u7a0b\u4e2d\uff0c\u53ef\u4ee5\u63d0\u9ad8\u5206\u6790\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2507.10678", "categories": ["cs.LG", "cs.AI", "cs.NE", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2507.10678", "abs": "https://arxiv.org/abs/2507.10678", "authors": ["Cutter Dawes", "Simon Segert", "Kamesh Krishnamurthy", "Jonathan D. Cohen"], "title": "A Group Theoretic Analysis of the Symmetries Underlying Base Addition and Their Learnability by Neural Networks", "comment": "22 pages, 6 figures", "summary": "A major challenge in the use of neural networks both for modeling human\ncognitive function and for artificial intelligence is the design of systems\nwith the capacity to efficiently learn functions that support radical\ngeneralization. At the roots of this is the capacity to discover and implement\nsymmetry functions. In this paper, we investigate a paradigmatic example of\nradical generalization through the use of symmetry: base addition. We present a\ngroup theoretic analysis of base addition, a fundamental and defining\ncharacteristic of which is the carry function -- the transfer of the remainder,\nwhen a sum exceeds the base modulus, to the next significant place. Our\nanalysis exposes a range of alternative carry functions for a given base, and\nwe introduce quantitative measures to characterize these. We then exploit\ndifferences in carry functions to probe the inductive biases of neural networks\nin symmetry learning, by training neural networks to carry out base addition\nusing different carries, and comparing efficacy and rate of learning as a\nfunction of their structure. We find that even simple neural networks can\nachieve radical generalization with the right input format and carry function,\nand that learning speed is closely correlated with carry function structure. We\nthen discuss the relevance this has for cognitive science and machine learning.", "AI": {"tldr": "\u795e\u7ecf\u7f51\u7edc\u901a\u8fc7\u5bf9\u79f0\u6027\u5b66\u4e60\u5b9e\u73b0\u5f7b\u5e95\u6cdb\u5316\uff1a\u7814\u7a76\u53d1\u73b0\uff0c\u901a\u8fc7\u4f18\u5316\u8f93\u5165\u683c\u5f0f\u548c\u91c7\u7528\u5408\u9002\u7684\u8fdb\u4f4d\u51fd\u6570\uff0c\u795e\u7ecf\u7f51\u7edc\u80fd\u9ad8\u6548\u5b66\u4e60\u5e76\u5b9e\u73b0\u5f7b\u5e95\u6cdb\u5316\uff0c\u5b66\u4e60\u901f\u5ea6\u4e0e\u8fdb\u4f4d\u51fd\u6570\u7ed3\u6784\u7d27\u5bc6\u76f8\u5173\u3002", "motivation": "\u5728\u5c06\u795e\u7ecf\u7f51\u7edc\u7528\u4e8e\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u529f\u80fd\u548c\u4eba\u5de5\u667a\u80fd\u65f6\uff0c\u8bbe\u8ba1\u80fd\u591f\u6709\u6548\u5b66\u4e60\u652f\u6301\u5f7b\u5e95\u6cdb\u5316\u529f\u80fd\u7684\u7cfb\u7edf\u662f\u4e00\u4e2a\u4e3b\u8981\u6311\u6218\u3002\u5176\u6839\u672c\u5728\u4e8e\u53d1\u73b0\u548c\u5b9e\u73b0\u5bf9\u79f0\u6027\u529f\u80fd\u7684\u80fd\u529b\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u5bf9\u57fa\u6570\u52a0\u6cd5\u8fdb\u884c\u7fa4\u8bba\u5206\u6790\uff0c\u63ed\u793a\u4e86\u8fdb\u4f4d\u51fd\u6570\u7684\u591a\u79cd\u9009\u62e9\uff0c\u5e76\u5f15\u5165\u4e86\u91cf\u5316\u6307\u6807\u6765\u8868\u5f81\u8fd9\u4e9b\u51fd\u6570\u3002\u63a5\u7740\uff0c\u901a\u8fc7\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u6267\u884c\u4e0d\u540c\u8fdb\u4f4d\u51fd\u6570\u7684\u57fa\u6570\u52a0\u6cd5\uff0c\u5e76\u6bd4\u8f83\u5b66\u4e60\u6548\u7387\u548c\u5b66\u4e60\u901f\u7387\u4e0e\u7f51\u7edc\u7ed3\u6784\u7684\u5173\u7cfb\uff0c\u6765\u63a2\u7a76\u795e\u7ecf\u7f51\u7edc\u5728\u5bf9\u79f0\u6027\u5b66\u4e60\u4e2d\u7684\u5f52\u7eb3\u504f\u7f6e\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5373\u4f7f\u662f\u7b80\u5355\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u53ea\u8981\u6709\u6b63\u786e\u7684\u8f93\u5165\u683c\u5f0f\u548c\u8fdb\u4f4d\u51fd\u6570\uff0c\u4e5f\u80fd\u591f\u5b9e\u73b0\u5f7b\u5e95\u7684\u6cdb\u5316\u3002\u540c\u65f6\uff0c\u5b66\u4e60\u901f\u5ea6\u4e0e\u8fdb\u4f4d\u51fd\u6570\u7684\u7ed3\u6784\u9ad8\u5ea6\u76f8\u5173\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u6b63\u786e\u7684\u8f93\u5165\u683c\u5f0f\u548c\u8fdb\u4f4d\u51fd\u6570\uff0c\u5373\u4f7f\u662f\u7b80\u5355\u7684\u795e\u7ecf\u7f51\u7edc\u4e5f\u80fd\u5b9e\u73b0\u5f7b\u5e95\u7684\u6cdb\u5316\u3002\u5b66\u4e60\u901f\u5ea6\u4e0e\u8fdb\u4f4d\u51fd\u6570\u7684\u7ed3\u6784\u5bc6\u5207\u76f8\u5173\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u8ba8\u8bba\u4e86\u5176\u5bf9\u8ba4\u77e5\u79d1\u5b66\u548c\u673a\u5668\u5b66\u4e60\u7684\u610f\u4e49\u3002"}}
{"id": "2507.11437", "categories": ["cs.DC", "cs.ET"], "pdf": "https://arxiv.org/pdf/2507.11437", "abs": "https://arxiv.org/abs/2507.11437", "authors": ["Sagar Bharadwaj", "Srinivasan Seshan", "Anthony Rowe"], "title": "Uniting the World by Dividing it: Federated Maps to Enable Spatial Applications", "comment": null, "summary": "The emergence of the Spatial Web -- the Web where content is tied to\nreal-world locations has the potential to improve and enable many applications\nsuch as augmented reality, navigation, robotics, and more. The Spatial Web is\nmissing a key ingredient that is impeding its growth -- a spatial naming system\nto resolve real-world locations to names. Today's spatial naming systems are\ndigital maps such as Google and Apple maps. These maps and the location-based\nservices provided on top of these maps are primarily controlled by a few large\ncorporations and mostly cover outdoor public spaces. Emerging classes of\napplications, such as persistent world-scale augmented reality, require\ndetailed maps of both outdoor and indoor spaces. Existing centralized mapping\ninfrastructures are proving insufficient for such applications because of the\nscale of cartography efforts required and the privacy of indoor map data.\n  In this paper, we present a case for a federated spatial naming system, or in\nother words, a federated mapping infrastructure. This enables disparate parties\nto manage and serve their own maps of physical regions and unlocks scalability\nof map management, isolation and privacy of maps. Map-related services such as\naddress-to-location mapping, location-based search, and routing needs\nre-architecting to work on federated maps. We discuss some essential services\nand practicalities of enabling these services.", "AI": {"tldr": "\u7a7a\u95f4Web\u9700\u8981\u4e00\u4e2a\u53bb\u4e2d\u5fc3\u5316\u7684\u5730\u56fe\u7cfb\u7edf\uff0c\u4ee5\u652f\u6301AR\u7b49\u5e94\u7528\uff0c\u73b0\u6709\u5730\u56fe\u670d\u52a1\u5b58\u5728\u5c40\u9650\u3002\u672c\u6587\u63d0\u51fa\u8054\u90a6\u5236\u7a7a\u95f4\u547d\u540d\u7cfb\u7edf\uff0c\u4ee5\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u4e2d\u5fc3\u5316\u5730\u56fe\u670d\u52a1\uff08\u5982\u8c37\u6b4c\u5730\u56fe\u3001\u82f9\u679c\u5730\u56fe\uff09\u65e0\u6cd5\u6ee1\u8db3\u65b0\u5174\u5e94\u7528\uff08\u5982AR\u3001\u5ba4\u5185\u5730\u56fe\uff09\u7684\u9700\u6c42\uff0c\u5b83\u4eec\u5728\u89c4\u6a21\u3001\u9690\u79c1\u548c\u8986\u76d6\u8303\u56f4\u4e0a\u5b58\u5728\u5c40\u9650\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u8054\u90a6\u5236\u7a7a\u95f4\u547d\u540d\u7cfb\u7edf\uff0c\u5141\u8bb8\u4e0d\u540c\u65b9\u7ba1\u7406\u548c\u63d0\u4f9b\u5404\u81ea\u7684\u5730\u56fe\u6570\u636e\uff0c\u5e76\u63a2\u8ba8\u4e86\u5b9e\u73b0\u8fd9\u4e00\u7cfb\u7edf\u6240\u9700\u7684\u670d\u52a1\u548c\u5b9e\u9645\u95ee\u9898\u3002", "result": "\u8bba\u8bc1\u4e86\u8054\u90a6\u5236\u7a7a\u95f4\u547d\u540d\u7cfb\u7edf\u7684\u53ef\u884c\u6027\uff0c\u8be5\u7cfb\u7edf\u80fd\u63d0\u9ad8\u5730\u56fe\u7ba1\u7406\u7684\u6269\u5c55\u6027\u3001\u9694\u79bb\u6027\u548c\u9690\u79c1\u6027\uff0c\u5e76\u4e3a\u5730\u5740\u89e3\u6790\u3001\u4f4d\u7f6e\u641c\u7d22\u548c\u8def\u7531\u7b49\u670d\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002", "conclusion": "\u672a\u6765\u9700\u8981\u4e00\u4e2a\u8054\u90a6\u5236\u7a7a\u95f4\u547d\u540d\u7cfb\u7edf\u6765\u652f\u6301\u5730\u7406\u7a7a\u95f4Web\uff0c\u89e3\u51b3\u73b0\u6709\u4e2d\u5fc3\u5316\u5730\u56fe\u670d\u52a1\u5728\u89c4\u6a21\u3001\u9690\u79c1\u548c\u8986\u76d6\u8303\u56f4\u4e0a\u7684\u4e0d\u8db3\u3002"}}
{"id": "2507.11257", "categories": ["cs.DS", "cs.DC"], "pdf": "https://arxiv.org/pdf/2507.11257", "abs": "https://arxiv.org/abs/2507.11257", "authors": ["Peter Robinson", "Ming Ming Tan"], "title": "Deterministic Lower Bounds for $k$-Edge Connectivity in the Distributed Sketching Model", "comment": null, "summary": "We study the $k$-edge connectivity problem on undirected graphs in the\ndistributed sketching model, where we have $n$ nodes and a referee. Each node\nsends a single message to the referee based on its 1-hop neighborhood in the\ngraph, and the referee must decide whether the graph is $k$-edge connected by\ntaking into account the received messages.\n  We present the first lower bound for deciding a graph connectivity problem in\nthis model with a deterministic algorithm. Concretely, we show that the worst\ncase message length is $\\Omega( k )$ bits for $k$-edge connectivity, for any\nsuper-constant $k = O(\\sqrt{n})$. Previously, only a lower bound of $\\Omega(\n\\log^3 n )$ bits was known for ($1$-edge) connectivity, due to Yu (SODA 2021).\nIn fact, our result is the first super-polylogarithmic lower bound for a\nconnectivity decision problem in the distributed graph sketching model.\n  To obtain our result, we introduce a new lower bound graph construction, as\nwell as a new 3-party communication complexity problem that we call\nUniqueOverlap. As this problem does not appear to be amenable to reductions to\nexisting hard problems such as set disjointness or indexing due to correlations\nbetween the inputs of the three players, we leverage results from\ncross-intersecting set families to prove the hardness of UniqueOverlap for\ndeterministic algorithms. Finally, we obtain the sought lower bound for\ndeciding $k$-edge connectivity via a novel simulation argument that, in\ncontrast to previous works, does not introduce any probability of error and\nthus works for deterministic algorithms.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u5728\u5206\u5e03\u5f0f\u56fe\u63cf\u6479\u6a21\u578b\u4e2d\u4e3a k \u8fb9\u8fde\u901a\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u786e\u5b9a\u6027\u7b97\u6cd5\u7684\u4e0b\u754c\uff0c\u8bc1\u660e\u4e86\u6700\u574f\u60c5\u51b5\u6d88\u606f\u957f\u5ea6\u81f3\u5c11\u4e3a $\\Omega(k)$ \u6bd4\u7279\u3002", "motivation": "\u5728\u5206\u5e03\u5f0f\u56fe\u63cf\u6479\u6a21\u578b\u4e2d\uff0c\u4e3a\u56fe\u8fde\u901a\u6027\u95ee\u9898\uff08\u7279\u522b\u662f k \u8fb9\u8fde\u901a\u6027\uff09\u63d0\u4f9b\u786e\u5b9a\u6027\u7b97\u6cd5\u7684\u7b2c\u4e00\u4e2a\u4e0b\u754c\uff0c\u5e76\u514b\u670d\u4e86\u5148\u524d\u7814\u7a76\u4e2d\u4ec5\u9650\u4e8e 1 \u8fb9\u8fde\u901a\u6027\u7684\u5bf9\u6570\u7ea7\u4e0b\u754c\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u65b0\u7684\u56fe\u6784\u9020\u548c\u4e09\u65b9\u901a\u4fe1\u590d\u6742\u6027\u95ee\u9898 UniqueOverlap \u6765\u8bc1\u660e\u4e0b\u754c\uff0c\u5e76\u5229\u7528\u4ea4\u53c9\u76f8\u4ea4\u96c6\u65cf\u7684\u7ed3\u679c\u6765\u8bc1\u660e UniqueOverlap \u7684\u786e\u5b9a\u6027\u7b97\u6cd5\u7684\u96be\u70b9\uff0c\u6700\u540e\u901a\u8fc7\u65b0\u7684\u6a21\u62df\u8bba\u8bc1\u83b7\u5f97 k \u8fb9\u8fde\u901a\u6027\u7684\u4e0b\u754c\u3002", "result": "\u5728\u5206\u5e03\u5f0f\u56fe\u63cf\u6479\u6a21\u578b\u4e2d\uff0c\u4e3a k \u8fb9\u8fde\u901a\u6027\u95ee\u9898\uff08\u9002\u7528\u4e8e $k = O(\\sqrt{n})$\uff09\u63d0\u4f9b\u4e86\u7b2c\u4e00\u4e2a\u786e\u5b9a\u6027\u7b97\u6cd5\u4e0b\u754c\uff0c\u5373\u6700\u574f\u60c5\u51b5\u6d88\u606f\u957f\u5ea6\u4e3a $\\Omega(k)$ \u6bd4\u7279\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u786e\u5b9a\u6027\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u5206\u5e03\u5f0f\u56fe\u63cf\u6479\u6a21\u578b\u4e2d\u51b3\u5b9a k \u8fb9\u8fde\u901a\u6027\uff0c\u5176\u6700\u574f\u60c5\u51b5\u6d88\u606f\u957f\u5ea6\u4e3a $\\Omega(k)$ \u6bd4\u7279\uff0c\u9002\u7528\u4e8e $k = O(\\sqrt{n})$ \u7684\u60c5\u51b5\u3002"}}
{"id": "2507.10609", "categories": ["cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.10609", "abs": "https://arxiv.org/abs/2507.10609", "authors": ["Obumneme Nwafor", "Chioma Nwafor", "Amro Zakaria", "Nkechi Nwankwo"], "title": "A Feed-Forward Artificial Intelligence Pipeline for Sustainable Desalination under Climate Uncertainties: UAE Insights", "comment": null, "summary": "The United Arab Emirates (UAE) relies heavily on seawater desalination to\nmeet over 90% of its drinking water needs. Desalination processes are highly\nenergy intensive and account for approximately 15% of the UAE's electricity\nconsumption, contributing to over 22% of the country's energy-related CO2\nemissions. Moreover, these processes face significant sustainability challenges\nin the face of climate uncertainties such as rising seawater temperatures,\nsalinity, and aerosol optical depth (AOD). AOD greatly affects the operational\nand economic performance of solar-powered desalination systems through\nphotovoltaic soiling, membrane fouling, and water turbidity cycles.\n  This study proposes a novel pipelined two-stage predictive modelling\narchitecture: the first stage forecasts AOD using satellite-derived time series\nand meteorological data; the second stage uses the predicted AOD and other\nmeteorological factors to predict desalination performance efficiency losses.\nThe framework achieved 98% accuracy, and SHAP (SHapley Additive exPlanations)\nwas used to reveal key drivers of system degradation. Furthermore, this study\nproposes a dust-aware rule-based control logic for desalination systems based\non predicted values of AOD and solar efficiency. This control logic is used to\nadjust the desalination plant feed water pressure, adapt maintenance\nscheduling, and regulate energy source switching.\n  To enhance the practical utility of the research findings, the predictive\nmodels and rule-based controls were packaged into an interactive dashboard for\nscenario and predictive analytics. This provides a management decision-support\nsystem for climate-adaptive planning.", "AI": {"tldr": "\u963f\u8054\u914b\u7684\u6d77\u6c34\u6de1\u5316\u9762\u4e34\u6c14\u5019\u53d8\u5316\uff08\u7279\u522b\u662f\u6c14\u6eb6\u80f6\u5149\u5b66\u539a\u5ea6AOD\uff09\u5e26\u6765\u7684\u6311\u6218\u3002\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u4e24\u9636\u6bb5\u9884\u6d4b\u6a21\u578b\uff0c\u51c6\u786e\u9884\u6d4bAOD\u548c\u6d77\u6c34\u6de1\u5316\u6548\u7387\u635f\u5931\uff08\u51c6\u786e\u7387\u8fbe98%\uff09\uff0c\u5e76\u901a\u8fc7SHAP\u8bc6\u522b\u5173\u952e\u5f71\u54cd\u56e0\u7d20\u3002\u6b64\u5916\uff0c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eAOD\u9884\u6d4b\u7684\u9632\u5c18\u63a7\u5236\u903b\u8f91\uff0c\u53ef\u4f18\u5316\u6d77\u6c34\u6de1\u5316\u8fd0\u8425\uff08\u5982\u8c03\u6574\u538b\u529b\u3001\u7ef4\u62a4\u548c\u80fd\u6e90\u5207\u6362\uff09\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u4eea\u8868\u677f\u4ee5\u652f\u6301\u6c14\u5019\u9002\u5e94\u6027\u89c4\u5212\u3002", "motivation": "\u9274\u4e8e\u963f\u8054\u914b\u4e25\u91cd\u4f9d\u8d56\u6d77\u6c34\u6de1\u5316\u6ee1\u8db3\u996e\u7528\u6c34\u9700\u6c42\uff0c\u800c\u8fd9\u4e00\u8fc7\u7a0b\u80fd\u8017\u9ad8\uff0c\u5bf9\u6c14\u5019\u53d8\u5316\u654f\u611f\uff08\u5982\u6d77\u6c34\u6e29\u5ea6\u3001\u76d0\u5ea6\u548c\u6c14\u6eb6\u80f6\u5149\u5b66\u539a\u5ea6\u589e\u52a0\uff09\uff0c\u7279\u522b\u662fAOD\u4f1a\u5f71\u54cd\u592a\u9633\u80fd\u6de1\u5316\u7cfb\u7edf\u7684\u8fd0\u884c\u548c\u7ecf\u6d4e\u6548\u76ca\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u9884\u6d4b\u5e76\u9002\u5e94\u8fd9\u4e9b\u6c14\u5019\u4e0d\u786e\u5b9a\u6027\u7684\u6a21\u578b\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6d41\u6c34\u7ebf\u5f0f\u4e24\u9636\u6bb5\u9884\u6d4b\u5efa\u6a21\u67b6\u6784\uff0c\u7b2c\u4e00\u9636\u6bb5\u5229\u7528\u536b\u661f\u6570\u636e\u548c\u6c14\u8c61\u6570\u636e\u9884\u6d4b\u6c14\u6eb6\u80f6\u5149\u5b66\u539a\u5ea6\uff08AOD\uff09\uff0c\u7b2c\u4e8c\u9636\u6bb5\u5229\u7528\u9884\u6d4b\u7684AOD\u548c\u5176\u4ed6\u6c14\u8c61\u56e0\u7d20\u9884\u6d4b\u6d77\u6c34\u6de1\u5316\u6548\u7387\u635f\u5931\u3002\u7814\u7a76\u8fd8\u91c7\u7528\u4e86SHAP\u65b9\u6cd5\u6765\u8bc6\u522b\u5bfc\u81f4\u7cfb\u7edf\u9000\u5316\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eAOD\u548c\u592a\u9633\u80fd\u6548\u7387\u9884\u6d4b\u503c\u7684\u9632\u5c18\u89c4\u5219\u63a7\u5236\u903b\u8f91\uff0c\u4ee5\u8c03\u6574\u8fdb\u6c34\u538b\u529b\u3001\u7ef4\u62a4\u8ba1\u5212\u548c\u80fd\u6e90\u5207\u6362\u3002\u6700\u540e\uff0c\u5c06\u9884\u6d4b\u6a21\u578b\u548c\u63a7\u5236\u903b\u8f91\u6253\u5305\u6210\u4ea4\u4e92\u5f0f\u4eea\u8868\u677f\uff0c\u7528\u4e8e\u573a\u666f\u548c\u9884\u6d4b\u5206\u6790\u3002", "result": "\u8be5\u9884\u6d4b\u6846\u67b6\u5b9e\u73b0\u4e8698%\u7684\u51c6\u786e\u7387\uff0c\u5e76\u4f7f\u7528SHAP\u65b9\u6cd5\u63ed\u793a\u4e86\u5bfc\u81f4\u7cfb\u7edf\u9000\u5316\u7684\u5173\u952e\u56e0\u7d20\u3002\u6b64\u5916\uff0c\u7814\u7a76\u63d0\u51fa\u7684\u9632\u5c18\u89c4\u5219\u63a7\u5236\u903b\u8f91\u80fd\u591f\u8c03\u6574\u6d77\u6c34\u6de1\u5316\u5382\u7684\u8fdb\u6c34\u538b\u529b\u3001\u7ef4\u62a4\u8ba1\u5212\u548c\u80fd\u6e90\u5207\u6362\uff0c\u5e76\u901a\u8fc7\u4ea4\u4e92\u5f0f\u4eea\u8868\u677f\u63d0\u4f9b\u4e86\u7ba1\u7406\u51b3\u7b56\u652f\u6301\uff0c\u4ee5\u5b9e\u73b0\u6c14\u5019\u9002\u5e94\u6027\u89c4\u5212\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u521b\u65b0\u7684\u6d41\u6c34\u7ebf\u5f0f\u4e24\u9636\u6bb5\u9884\u6d4b\u5efa\u6a21\u67b6\u6784\uff0c\u7ed3\u5408\u4e86\u9884\u6d4b\u6a21\u578b\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u63a7\u5236\u903b\u8f91\uff0c\u4e3a\u963f\u8054\u914b\u7684\u6d77\u6c34\u6de1\u5316\u884c\u4e1a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5e94\u5bf9\u6c14\u5019\u53d8\u5316\u6311\u6218\u7684\u7ba1\u7406\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u548c\u7cfb\u7edf\u7684\u9002\u5e94\u6027\u3002"}}
{"id": "2507.10950", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.10950", "abs": "https://arxiv.org/abs/2507.10950", "authors": ["Zhiwei Wu", "Jiahao Luo", "Siyi Wei", "Jinhui Zhang"], "title": "Unified Modeling and Structural Optimization of Multi-magnet Embedded Soft Continuum Robots for Enhanced Kinematic Performances", "comment": null, "summary": "This paper presents a unified modeling and optimization framework to enhance\nthe kinematic performance of multi-magnet embedded soft continuum robots\n(MeSCRs). To this end, we establish a differentiable system formulation based\non an extended pseudo-rigid-body model. This formulation enables analysis of\nthe equilibrium well-posedness and the geometry of the induced configuration\nunder magnetic actuation. In particular, we show that the maximum controllable\ndegrees of freedom of a MeSCR equal twice the number of embedded magnets. We\nsubsequently develop a structural optimization framework based on differential\ngeometry that links classical kinematic measures (e.g., manipulability and\ndexterity) to the configuration of embedded magnets. The resulting optimization\ncondition reveals that improving local performance requires structurally\nmodulating the spectrum of the configuration space metric to counteract its\ndistortion. Closed-form solutions for optimal magnet configurations are derived\nunder representative conditions, and a gradient-based numerical method is\nproposed for general design scenarios. Simulation studies validate the\neffectiveness of the proposed framework.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u63d0\u9ad8\u8f6f\u8fde\u7eed\u673a\u5668\u4eba\u8fd0\u52a8\u5b66\u6027\u80fd\u7684\u5efa\u6a21\u4e0e\u4f18\u5316\u6846\u67b6\uff0c\u5e76\u63d0\u4f9b\u4e86\u6700\u4f18\u8bbe\u8ba1\u65b9\u6cd5\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u591a\u78c1\u5d4c\u5165\u8f6f\u8fde\u7eed\u673a\u5668\u4eba\u7684\u8fd0\u52a8\u5b66\u6027\u80fd\uff0c\u7814\u7a76\u8005\u4eec\u9700\u8981\u4e00\u4e2a\u7edf\u4e00\u7684\u5efa\u6a21\u548c\u4f18\u5316\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u5c55\u4f2a\u521a\u4f53\u6a21\u578b\u7684\u5fae\u5206\u7cfb\u7edf\u516c\u5f0f\uff0c\u5e76\u7ed3\u5408\u4e86\u57fa\u4e8e\u5fae\u5206\u51e0\u4f55\u7684\u7ed3\u6784\u4f18\u5316\u6846\u67b6\u3002", "result": "\u8bc1\u660e\u4e86MeSCRs\u7684\u6700\u5927\u53ef\u63a7\u81ea\u7531\u5ea6\u7b49\u4e8e\u5d4c\u5165\u78c1\u4f53\u6570\u91cf\u7684\u4e24\u500d\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u6846\u67b6\u63d0\u9ad8\u4e86\u5c40\u90e8\u6027\u80fd\uff0c\u4e3a\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6700\u4f18\u78c1\u4f53\u914d\u7f6e\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u5efa\u6a21\u548c\u4f18\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u9ad8\u591a\u78c1\u5d4c\u5165\u8f6f\u8fde\u7eed\u673a\u5668\u4eba\u7684\u8fd0\u52a8\u5b66\u6027\u80fd\uff0c\u5e76\u63a8\u5bfc\u51fa\u4e86\u6700\u4f18\u78c1\u4f53\u914d\u7f6e\u7684\u89e3\u6790\u548c\u6570\u503c\u89e3\u3002"}}
{"id": "2507.11150", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.11150", "abs": "https://arxiv.org/abs/2507.11150", "authors": ["Alessandro Bertagnon", "Marcello Dalpasso", "Michele Favalli", "Marco Gavanelli"], "title": "Fine-grained Timing Analysis of Digital Integrated Circuits in Answer Set Programming", "comment": "Accepted for publication in the issues of Theory and Practice of\n  Logic Programming (TPLP) dedicated to ICLP 2025, 16 pages, 9 figures", "summary": "In the design of integrated circuits, one critical metric is the maximum\ndelay introduced by combinational modules within the circuit. This delay is\ncrucial because it represents the time required to perform a computation: in an\nArithmetic-Logic Unit it represents the maximum time taken by the circuit to\nperform an arithmetic operation. When such a circuit is part of a larger,\nsynchronous system, like a CPU, the maximum delay directly impacts the maximum\nclock frequency of the entire system. Typically, hardware designers use Static\nTiming Analysis to compute an upper bound of the maximum delay because it can\nbe determined in polynomial time. However, relying on this upper bound can lead\nto suboptimal processor speeds, thereby missing performance opportunities. In\nthis work, we tackle the challenging task of computing the actual maximum\ndelay, rather than an approximate value. Since the problem is computationally\nhard, we model it in Answer Set Programming (ASP), a logic language featuring\nextremely efficient solvers. We propose non-trivial encodings of the problem\ninto ASP. Experimental results show that ASP is a viable solution to address\ncomplex problems in hardware design.", "AI": {"tldr": "This paper presents a method using Answer Set Programming (ASP) to accurately calculate the maximum delay in integrated circuits, a task traditionally approximated. Experiments show ASP is effective for hardware design challenges.", "motivation": "To compute the actual maximum delay in integrated circuits, rather than an upper bound, to avoid suboptimal processor speeds and missed performance opportunities.", "method": "Modeling the maximum delay problem in Answer Set Programming (ASP) using non-trivial encodings.", "result": "Experimental results demonstrate the viability of ASP for addressing complex problems in hardware design.", "conclusion": "ASP is a viable solution for computing the actual maximum delay in integrated circuits, which can lead to better processor speeds compared to traditional methods."}}
{"id": "2507.10875", "categories": ["cond-mat.mes-hall", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2507.10875", "abs": "https://arxiv.org/abs/2507.10875", "authors": ["Wenxuan Wang", "Yijie Wang", "Zaizhe Zhang", "Zihao Huo", "Gengdong Zhou", "Kenji Watanabe", "Takashi Taniguchi", "X. C. Xie", "Kaihui Liu", "Zhida Song", "Xiaobo Lu"], "title": "Moir\u00e9 dependent Chern insulators in twisted crystalline flatbands", "comment": null, "summary": "In moir\\'e crystals, the competition between different isospin configurations\ncan be tuned by twist angles and stacking orders, forming various\nsymmetry-broken states. Here we report twisted double\nrhombohedral-trilayer-gaphene as a new twisted crystalline flatbands system\nshowing rich moir\\'e dependent topological phenomena. For small twist angles,\nprogrammable Chern insulators with Chern number C = 3 at integer moir\\'e\nfilling v = 1 have been observed. We have further revealed multiple first-order\ntransitions and an exotic hidden order which can quench the Chern insulator.\nInterestingly, for a larger twist angle, multiple Chern insulators with C = 1\nat fractional fillings including v = 1/4, 1/3 and 1/2 have been observed,\nwhereas the Chern insulator at v = 1 is absent. Our study demonstrated the\ntwisted flatbands from rhombohedral-multilayer-graphene as a new platform to\nstudy topological correlated physics, offering a promising pathway toward\ndeveloping new devices for quantum storage and computation.", "AI": {"tldr": "\u53cc\u94d1\u4e09\u5c42\u95f4\u9699\u70ef\u5728\u4e0d\u540c\u626d\u8f6c\u89d2\u4e0b\u8868\u73b0\u51fa\u4e30\u5bcc\u7684\u62d3\u6251\u73b0\u8c61\uff0c\u53ef\u7528\u4e8e\u91cf\u5b50\u5b58\u50a8\u548c\u8ba1\u7b97\u3002", "motivation": "\u7814\u7a76\u53cc\u94d1\u4e09\u5c42\u95f4\u9699\u70ef\u5728\u4e0d\u540c\u626d\u8f6c\u89d2\u4e0b\u7684\u5bf9\u79f0\u6027\u7834\u7f3a\u6001\u548c\u62d3\u6251\u73b0\u8c61\uff0c\u63a2\u7d22\u5176\u5728\u91cf\u5b50\u5b58\u50a8\u548c\u8ba1\u7b97\u65b9\u9762\u7684\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u7814\u7a76\u4e86\u626d\u8f6c\u53cc\u94d1\u4e09\u5c42\u95f4\u9699\u70ef\u7684\u80fd\u5e26\u7ed3\u6784\u548c\u5bf9\u79f0\u6027\u7834\u7f3a\u6001\uff0c\u5e76\u89c2\u5bdf\u5230\u4e86\u4e0d\u540c\u626d\u8f6c\u89d2\u4e0b\u7684\u62d3\u6251\u73b0\u8c61\u3002", "result": "\u5728\u5c0f\u626d\u8f6c\u89d2\u4e0b\uff0c\u89c2\u5bdf\u5230\u4e86 Chern \u6570 C = 3 \u7684\u53ef\u7f16\u7a0b Chern \u7edd\u7f18\u4f53\uff1b\u5728\u8f83\u5927\u626d\u8f6c\u89d2\u4e0b\uff0c\u89c2\u5bdf\u5230\u4e86\u5206\u6570\u586b\u5145\u4e0b\u7684\u591a\u91cd Chern \u7edd\u7f18\u4f53\uff08C = 1\uff09\uff0c\u4f46\u7f3a\u5931\u4e86 C = 1 \u7684 Chern \u7edd\u7f18\u4f53\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u5c55\u793a\u4e86\u6765\u81ea\u94d1\u591a\u5c42\u77f3\u58a8\u70ef\u7684\u626d\u8f6c\u5e73\u5e26\u4f5c\u4e3a\u7814\u7a76\u62d3\u6251\u76f8\u5173\u7269\u7406\u5b66\u7684\u65b0\u5e73\u53f0\uff0c\u4e3a\u5f00\u53d1\u7528\u4e8e\u91cf\u5b50\u5b58\u50a8\u548c\u8ba1\u7b97\u7684\u65b0\u8bbe\u5907\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\u3002"}}
{"id": "2507.10739", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.10739", "abs": "https://arxiv.org/abs/2507.10739", "authors": ["Marianna Podzorova", "Yi-Kai Liu"], "title": "Quantum Wave Atom Transforms", "comment": "45 pages, 12 figures", "summary": "This paper constructs the first quantum algorithm for wavelet packet\ntransforms with a tree structure, sometimes called wave atom transforms.\nClassically, wave atoms are used to construct sparse representations of\ndifferential operators, which enable fast numerical algorithms for partial\ndifferential equations. Compared to previous work, our quantum algorithm can\nimplement a larger class of wavelet and wave atom transforms, by using an\nefficient representation for a larger class of possible tree structures. Our\nquantum implementation has $O(\\mathrm{poly}(n))$ gate complexity for the\ntransform of dimension $2^n$, while classical implementations have $O(n 2^n)$\nfloating point operations. The result can be used to improve existing quantum\nalgorithms for solving hyperbolic partial differential equations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u91cf\u5b50\u7b97\u6cd5\uff0c\u7528\u4e8e\u6267\u884c\u5c0f\u6ce2\u5305\u53d8\u6362\u548c\u6ce2\u539f\u5b50\u53d8\u6362\uff0c\u5176\u6548\u7387\u8fdc\u9ad8\u4e8e\u7ecf\u5178\u7b97\u6cd5\uff0c\u5e76\u4e14\u80fd\u591f\u5904\u7406\u66f4\u5e7f\u6cdb\u7684\u53d8\u6362\u7c7b\u578b\uff0c\u6709\u671b\u5e94\u7528\u4e8e\u6c42\u89e3\u504f\u5fae\u5206\u65b9\u7a0b\u3002", "motivation": "\u7ecf\u5178\u65b9\u6cd5\u4e2d\uff0c\u6ce2\u539f\u5b50\u7528\u4e8e\u6784\u5efa\u5fae\u5206\u7b97\u5b50\u7684\u7a00\u758f\u8868\u793a\uff0c\u4ece\u800c\u5b9e\u73b0\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u5feb\u901f\u6570\u503c\u7b97\u6cd5\u3002\u5c06\u6b64\u65b9\u6cd5\u91cf\u5b50\u5316\uff0c\u4ee5\u671f\u63d0\u9ad8\u6548\u7387\u548c\u9002\u7528\u6027\u3002", "method": "\u6784\u5efa\u4e86\u7b2c\u4e00\u4e2a\u5177\u6709\u6811\u72b6\u7ed3\u6784\u7684\u5c0f\u6ce2\u5305\u53d8\u6362\uff08\u6709\u65f6\u79f0\u4e3a\u6ce2\u539f\u5b50\u53d8\u6362\uff09\u7684\u91cf\u5b50\u7b97\u6cd5\u3002", "result": "\u8be5\u91cf\u5b50\u7b97\u6cd5\u80fd\u591f\u5b9e\u73b0\u66f4\u5927\u7c7b\u7684\u5c0f\u6ce2\u548c\u6ce2\u539f\u5b50\u53d8\u6362\uff0c\u80fd\u591f\u5904\u7406\u66f4\u5927\u7c7b\u53ef\u80fd\u7684\u6811\u72b6\u7ed3\u6784\u3002\u5bf9\u4e8e\u7ef4\u5ea6\u4e3a$2^n$\u7684\u53d8\u6362\uff0c\u91cf\u5b50\u7b97\u6cd5\u7684\u95e8\u590d\u6742\u5ea6\u4e3a$O(\\mathrm{poly}(n))$\uff0c\u800c\u7ecf\u5178\u5b9e\u73b0\u9700\u8981$O(n 2^n)$\u6b21\u6d6e\u70b9\u8fd0\u7b97\u3002\u8fd9\u4e00\u7ed3\u679c\u53ef\u4ee5\u7528\u4e8e\u6539\u8fdb\u73b0\u6709\u7684\u6c42\u89e3\u53cc\u66f2\u578b\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u91cf\u5b50\u7b97\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u91cf\u5b50\u7b97\u6cd5\u5728\u5904\u7406\u5c0f\u6ce2\u5305\u53d8\u6362\u548c\u6ce2\u539f\u53d8\u6362\u65b9\u9762\uff0c\u76f8\u8f83\u4e8e\u7ecf\u5178\u7b97\u6cd5\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u6548\u7387\u548c\u66f4\u5e7f\u6cdb\u7684\u9002\u7528\u6027\uff0c\u6709\u671b\u6539\u8fdb\u73b0\u6709\u7684\u6c42\u89e3\u53cc\u66f2\u578b\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u91cf\u5b50\u7b97\u6cd5\u3002"}}
{"id": "2507.10864", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10864", "abs": "https://arxiv.org/abs/2507.10864", "authors": ["Saadat Behzadi", "Danial Sharifrazi", "Bita Mesbahzadeh", "Javad Hassannataj Joloudarid", "Roohallah Alizadehsani"], "title": "A Lightweight and Robust Framework for Real-Time Colorectal Polyp Detection Using LOF-Based Preprocessing and YOLO-v11n", "comment": null, "summary": "Objectives: Timely and accurate detection of colorectal polyps plays a\ncrucial role in diagnosing and preventing colorectal cancer, a major cause of\nmortality worldwide. This study introduces a new, lightweight, and efficient\nframework for polyp detection that combines the Local Outlier Factor (LOF)\nalgorithm for filtering noisy data with the YOLO-v11n deep learning model.\n  Study design: An experimental study leveraging deep learning and outlier\nremoval techniques across multiple public datasets.\n  Methods: The proposed approach was tested on five diverse and publicly\navailable datasets: CVC-ColonDB, CVC-ClinicDB, Kvasir-SEG, ETIS, and EndoScene.\nSince these datasets originally lacked bounding box annotations, we converted\ntheir segmentation masks into suitable detection labels. To enhance the\nrobustness and generalizability of our model, we apply 5-fold cross-validation\nand remove anomalous samples using the LOF method configured with 30 neighbors\nand a contamination ratio of 5%. Cleaned data are then fed into YOLO-v11n, a\nfast and resource-efficient object detection architecture optimized for\nreal-time applications. We train the model using a combination of modern\naugmentation strategies to improve detection accuracy under diverse conditions.\n  Results: Our approach significantly improves polyp localization performance,\nachieving a precision of 95.83%, recall of 91.85%, F1-score of 93.48%, mAP@0.5\nof 96.48%, and mAP@0.5:0.95 of 77.75%. Compared to previous YOLO-based methods,\nour model demonstrates enhanced accuracy and efficiency.\n  Conclusions: These results suggest that the proposed method is well-suited\nfor real-time colonoscopy support in clinical settings. Overall, the study\nunderscores how crucial data preprocessing and model efficiency are when\ndesigning effective AI systems for medical imaging.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408LOF\u548cYOLO-v11n\u7684\u7ed3\u76f4\u80a0\u606f\u8089\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u6570\u636e\u9884\u5904\u7406\u548c\u6a21\u578b\u4f18\u5316\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u7ed3\u80a0\u955c\u68c0\u67e5\u3002", "motivation": "\u53ca\u65f6\u51c6\u786e\u5730\u68c0\u6d4b\u7ed3\u76f4\u80a0\u606f\u8089\u5bf9\u4e8e\u8bca\u65ad\u548c\u9884\u9632\u7ed3\u76f4\u80a0\u764c\u81f3\u5173\u91cd\u8981\uff0c\u800c\u7ed3\u76f4\u80a0\u764c\u662f\u5168\u7403\u4e3b\u8981\u7684\u6b7b\u4ea1\u539f\u56e0\u4e4b\u4e00\u3002", "method": "\u8be5\u7814\u7a76\u91c7\u7528\u4e86\u4e00\u79cd\u7ed3\u5408\u4e86\u5c40\u90e8\u5f02\u5e38\u503c\u56e0\u5b50\uff08LOF\uff09\u7b97\u6cd5\u548cYOLO-v11n\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u65b0\u578b\u8f7b\u91cf\u7ea7\u9ad8\u6548\u6846\u67b6\uff0c\u7528\u4e8e\u7ed3\u76f4\u80a0\u606f\u8089\u68c0\u6d4b\u3002\u901a\u8fc7\u5bf9\u4e94\u4e2a\u516c\u5171\u6570\u636e\u96c6\uff08CVC-ColonDB\u3001CVC-ClinicDB\u3001Kvasir-SEG\u3001ETIS\u548cEndoScene\uff09\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5c06\u5206\u5272\u63a9\u7801\u8f6c\u6362\u4e3a\u68c0\u6d4b\u6807\u7b7e\uff0c\u5e76\u5229\u7528LOF\u65b9\u6cd5\uff08\u914d\u7f6e30\u4e2a\u90bb\u5c45\u548c5%\u7684\u6c61\u67d3\u7387\uff09\u79fb\u9664\u5f02\u5e38\u6837\u672c\u3002\u7136\u540e\u5c06\u6e05\u7406\u540e\u7684\u6570\u636e\u8f93\u5165\u7ecf\u8fc7\u73b0\u4ee3\u589e\u5f3a\u7b56\u7565\u4f18\u5316\u7684YOLO-v11n\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u91c7\u75285\u6298\u4ea4\u53c9\u9a8c\u8bc1\u6765\u589e\u5f3a\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u606f\u8089\u5b9a\u4f4d\u6027\u80fd\uff0c\u53d6\u5f97\u4e8695.83%\u7684\u7cbe\u786e\u7387\u300191.85%\u7684\u53ec\u56de\u7387\u300193.48%\u7684F1\u5206\u6570\u300196.48%\u7684mAP@0.5\u548c77.75%\u7684mAP@0.5:0.95\u3002\u4e0e\u4e4b\u524d\u7684\u57fa\u4e8eYOLO\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u6a21\u578b\u5c55\u793a\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u65b9\u6cd5\u975e\u5e38\u9002\u5408\u4e34\u5e8a\u73af\u5883\u4e2d\u7684\u5b9e\u65f6\u7ed3\u80a0\u955c\u68c0\u67e5\u652f\u6301\u3002\u8fd9\u9879\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u8bbe\u8ba1\u6709\u6548\u7684\u533b\u5b66\u5f71\u50cf\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u65f6\uff0c\u6570\u636e\u9884\u5904\u7406\u548c\u6a21\u578b\u6548\u7387\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.10798", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10798", "abs": "https://arxiv.org/abs/2507.10798", "authors": ["Asim H. Gazi", "Bhanu T. Gullapalli", "Daiqi Gao", "Benjamin M. Marlin", "Vivek Shetty", "Susan A. Murphy"], "title": "Uncertainty-Informed Scheduling of Decision Points for Intelligent Mobile Health Interventions", "comment": "4 pages, 3 figures", "summary": "Timely decision making is critical to the effectiveness of mobile health\n(mHealth) interventions. At predefined timepoints called \"decision points,\"\nintelligent mHealth systems such as just-in-time adaptive interventions\n(JITAIs) estimate an individual's biobehavioral context from sensor or survey\ndata and determine whether and how to intervene. For interventions targeting\nhabitual behavior (e.g., oral hygiene), effectiveness often hinges on\ndelivering support shortly before the target behavior is likely to occur.\nCurrent practice schedules decision points at a fixed interval (e.g., one hour)\nbefore user-provided behavior times, and the fixed interval is kept the same\nfor all individuals. However, this one-size-fits-all approach performs poorly\nfor individuals with irregular routines, often scheduling decision points after\nthe target behavior has already occurred, rendering interventions ineffective.\nIn this paper, we propose SigmaScheduling, a method to dynamically schedule\ndecision points based on uncertainty in predicted behavior times. When behavior\ntiming is more predictable, SigmaScheduling schedules decision points closer to\nthe predicted behavior time; when timing is less certain, SigmaScheduling\nschedules decision points earlier, increasing the likelihood of timely\nintervention. We evaluated SigmaScheduling using real-world data from 68\nparticipants in a 10-week trial of Oralytics, a JITAI designed to improve daily\ntoothbrushing. SigmaScheduling increased the likelihood that decision points\npreceded brushing events in at least 70% of cases, preserving opportunities to\nintervene and impact behavior. Our results indicate that SigmaScheduling can\nadvance precision mHealth, particularly for JITAIs targeting time-sensitive,\nhabitual behaviors such as oral hygiene or dietary habits.", "AI": {"tldr": "\u4e3a\u4e86\u89e3\u51b3mHealth\u5e72\u9884\u4e2d\u56fa\u5b9a\u51b3\u7b56\u70b9\u8c03\u5ea6\u7684\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSigmaScheduling\u7684\u65b0\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u6839\u636e\u5bf9\u7528\u6237\u884c\u4e3a\u65f6\u95f4\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\u6765\u52a8\u6001\u8c03\u6574\u51b3\u7b56\u70b9\uff0c\u63d0\u9ad8\u4e86\u5e72\u9884\u7684\u53ca\u65f6\u6027\uff0c\u5c24\u5176\u9002\u7528\u4e8eOralytics\u7b49\u65e8\u5728\u6539\u5584\u53e3\u8154\u536b\u751f\u7b49\u4e60\u60ef\u6027\u884c\u4e3a\u7684mHealth\u5e94\u7528\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSigmaScheduling\u80fd\u663e\u8457\u63d0\u9ad8\u51b3\u7b56\u70b9\u5728\u7528\u6237\u884c\u4e3a\u53d1\u751f\u524d\u88ab\u5b89\u6392\u7684\u51e0\u7387\uff0c\u4ece\u800c\u63d0\u5347\u5e72\u9884\u6548\u679c\u3002", "motivation": "\u76ee\u524d\u7684mHealth\u5e72\u9884\u63aa\u65bd\uff08\u5982JITAIs\uff09\u5728\u5b89\u6392\u51b3\u7b56\u70b9\u65f6\u91c7\u7528\u56fa\u5b9a\u7684\u65f6\u95f4\u95f4\u9694\uff0c\u8fd9\u79cd\u201c\u4e00\u5200\u5207\u201d\u7684\u65b9\u6cd5\u5bf9\u4e8e\u65e5\u5e38\u89c4\u5f8b\u4e0d\u89c4\u5f8b\u7684\u4e2a\u4f53\u6548\u679c\u4e0d\u4f73\uff0c\u5e38\u5e38\u5bfc\u81f4\u51b3\u7b56\u70b9\u5b89\u6392\u5728\u76ee\u6807\u884c\u4e3a\u53d1\u751f\u4e4b\u540e\uff0c\u4f7f\u5f97\u5e72\u9884\u63aa\u65bd\u5931\u6548\u3002", "method": "SigmaScheduling\u662f\u4e00\u79cd\u52a8\u6001\u8c03\u5ea6\u51b3\u7b56\u70b9\u7684\u65b9\u6cd5\uff0c\u5b83\u57fa\u4e8e\u5bf9\u9884\u671f\u884c\u4e3a\u65f6\u95f4\u7684\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u3002\u5f53\u884c\u4e3a\u65f6\u95f4\u66f4\u5177\u53ef\u9884\u6d4b\u6027\u65f6\uff0cSigmaScheduling\u5c06\u51b3\u7b56\u70b9\u5b89\u6392\u5728\u66f4\u63a5\u8fd1\u9884\u671f\u884c\u4e3a\u7684\u65f6\u95f4\uff1b\u5f53\u4e0d\u786e\u5b9a\u6027\u66f4\u9ad8\u65f6\uff0cSigmaScheduling\u5219\u4f1a\u63d0\u524d\u5b89\u6392\u51b3\u7b56\u70b9\uff0c\u4ee5\u589e\u52a0\u53ca\u65f6\u5e72\u9884\u7684\u53ef\u80fd\u6027\u3002", "result": "\u5728\u5bf9Oralytics\uff08\u4e00\u9879\u65e8\u5728\u6539\u5584\u65e5\u5e38\u5237\u7259\u4e60\u60ef\u7684JITAI\uff09\u7684\u4e3a\u671f10\u5468\u3001\u6d89\u53ca68\u540d\u53c2\u4e0e\u8005\u7684\u771f\u5b9e\u4e16\u754c\u6570\u636e\u8fdb\u884c\u7684\u8bc4\u4f30\u4e2d\uff0cSigmaScheduling\u5c06\u51b3\u7b56\u70b9\u5b89\u6392\u5728\u5237\u7259\u4e8b\u4ef6\u4e4b\u524d\u7684\u51e0\u7387\u63d0\u9ad8\u4e8670%\u4ee5\u4e0a\uff0c\u4ece\u800c\u4fdd\u7559\u4e86\u5e72\u9884\u5e76\u5f71\u54cd\u884c\u4e3a\u7684\u673a\u4f1a\u3002", "conclusion": "SigmaScheduling\u53ef\u4ee5\u63a8\u8fdb\u7cbe\u51c6\u7684mHealth\uff0c\u7279\u522b\u662f\u9488\u5bf9\u90a3\u4e9b\u6709\u65f6\u95f4\u654f\u611f\u6027\u3001\u4e60\u60ef\u6027\u884c\u4e3a\uff08\u5982\u53e3\u8154\u536b\u751f\u6216\u996e\u98df\u4e60\u60ef\uff09\u7684JITAIs\u3002"}}
{"id": "2507.10787", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10787", "abs": "https://arxiv.org/abs/2507.10787", "authors": ["Yilun Zhao", "Chengye Wang", "Chuhan Li", "Arman Cohan"], "title": "Can Multimodal Foundation Models Understand Schematic Diagrams? An Empirical Study on Information-Seeking QA over Scientific Papers", "comment": "ACL 2025 Findings", "summary": "This paper introduces MISS-QA, the first benchmark specifically designed to\nevaluate the ability of models to interpret schematic diagrams within\nscientific literature. MISS-QA comprises 1,500 expert-annotated examples over\n465 scientific papers. In this benchmark, models are tasked with interpreting\nschematic diagrams that illustrate research overviews and answering\ncorresponding information-seeking questions based on the broader context of the\npaper. We assess the performance of 18 frontier multimodal foundation models,\nincluding o4-mini, Gemini-2.5-Flash, and Qwen2.5-VL. We reveal a significant\nperformance gap between these models and human experts on MISS-QA. Our analysis\nof model performance on unanswerable questions and our detailed error analysis\nfurther highlight the strengths and limitations of current models, offering key\ninsights to enhance models in comprehending multimodal scientific literature.", "AI": {"tldr": "MISS-QA\u662f\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u7406\u89e3\u79d1\u5b66\u6587\u732e\u4e2d\u7684\u793a\u610f\u56fe\u3002\u6d4b\u8bd5\u8868\u660e\uff0c\u5373\u4f7f\u662f\u9876\u5c16\u6a21\u578b\u4e5f\u65e0\u6cd5\u8fbe\u5230\u4eba\u7c7b\u4e13\u5bb6\u7684\u6c34\u5e73\u3002", "motivation": "\u4e3a\u4e86\u8bc4\u4f30\u548c\u6539\u8fdb\u6a21\u578b\u89e3\u8bfb\u79d1\u5b66\u6587\u732e\u4e2d\u793a\u610f\u56fe\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86MISS-QA\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b1500\u4e2a\u4e13\u5bb6\u6807\u6ce8\u7684\u793a\u4f8b\uff0c\u6db5\u76d6465\u7bc7\u79d1\u5b66\u8bba\u6587\uff0c\u65e8\u5728\u8bc4\u4f30\u6a21\u578b\u89e3\u8bfb\u79d1\u5b66\u6587\u732e\u4e2d\u793a\u610f\u56fe\u7684\u80fd\u529b\u3002\u5bf918\u79cd\u524d\u6cbf\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u4e86\u6d4b\u8bd5\u3002", "result": "\u5728MISS-QA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c18\u79cd\u524d\u6cbf\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\uff08\u5305\u62eco4-mini\u3001Gemini-2.5-Flash\u548cQwen2.5-VL\uff09\u7684\u8868\u73b0\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u5c55\u793a\u4e86\u6a21\u578b\u5728\u7406\u89e3\u4e0d\u53ef\u56de\u7b54\u95ee\u9898\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5e76\u63d0\u4f9b\u4e86\u8be6\u7ec6\u7684\u9519\u8bef\u5206\u6790\uff0c\u6307\u51fa\u4e86\u5f53\u524d\u6a21\u578b\u7684\u4f18\u52bf\u548c\u5c40\u9650\u6027\u3002", "conclusion": "\u76ee\u524d\u7684\u591a\u6a21\u6001\u6a21\u578b\u5728\u89e3\u8bfb\u79d1\u5b66\u6587\u732e\u4e2d\u7684\u793a\u610f\u56fe\u65b9\u9762\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u5728MISS-QA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u66b4\u9732\u4e86\u5b83\u4eec\u7684\u4f18\u52bf\u548c\u5c40\u9650\u6027\u3002"}}
{"id": "2507.11260", "categories": ["cs.DS", "cs.CG", "cs.DM"], "pdf": "https://arxiv.org/pdf/2507.11260", "abs": "https://arxiv.org/abs/2507.11260", "authors": ["Lingxiao Huang", "Zhenyu Jiang", "Yi Li", "Xuan Wu"], "title": "On Tight Robust Coresets for $k$-Medians Clustering", "comment": null, "summary": "This paper considers coresets for the robust $k$-medians problem with $m$\noutliers, and new constructions in various metric spaces are obtained.\nSpecifically, for metric spaces with a bounded VC or doubling dimension $d$,\nthe coreset size is $O(m) + \\tilde{O}(kd\\varepsilon^{-2})$, which is optimal up\nto logarithmic factors. For Euclidean spaces, the coreset size is\n$O(m\\varepsilon^{-1}) +\n\\tilde{O}(\\min\\{k^{4/3}\\varepsilon^{-2},k\\varepsilon^{-3}\\})$, improving upon a\nrecent result by Jiang and Lou (ICALP 2025). These results also extend to\nrobust $(k,z)$-clustering, yielding, for VC and doubling dimension, a coreset\nsize of $O(m) + \\tilde{O}(kd\\varepsilon^{-2z})$ with the optimal linear\ndependence on $m$. This extended result improves upon the earlier work of Huang\net al. (SODA 2025). The techniques introduce novel dataset decompositions,\nenabling chaining arguments to be applied jointly across multiple components.", "AI": {"tldr": "\u672c\u6587\u4e3a\u9c81\u68d2k-\u4e2d\u4f4d\u6570\u95ee\u9898\u5728\u5404\u79cd\u5ea6\u91cf\u7a7a\u95f4\u4e2d\u63d0\u4f9b\u4e86\u65b0\u7684Coreset\u6784\u9020\uff0c\u5e76\u5728VC\u548c\u53cc\u7ef4\u5ea6\u7a7a\u95f4\u4e2d\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u5927\u5c0f\u3002", "motivation": "\u8be5\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u9c81\u68d2k-\u4e2d\u4f4d\u6570\u95ee\u9898\uff0c\u4e3a\u5177\u6709m\u4e2a\u5f02\u5e38\u503c\u7684\u805a\u7c7b\u95ee\u9898\u63d0\u4f9b\u66f4\u6709\u6548\u7684Coreset\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8be5\u7814\u7a76\u901a\u8fc7\u65b0\u7684\u6570\u636e\u96c6\u5206\u89e3\u6280\u672f\uff0c\u7ed3\u5408\u94fe\u63a5\u8bba\u8bc1\uff0c\u5b9e\u73b0\u4e86Coreset\u7684\u6784\u9020\uff0c\u5e76\u5c06\u5176\u6269\u5c55\u5230\u9c81\u68d2(k,z)-\u805a\u7c7b\u95ee\u9898\u3002", "result": "\u5728VC\u6216\u53cc\u7ef4\u5ea6d\u7684\u5ea6\u91cf\u7a7a\u95f4\u4e2d\uff0cCoreset\u5927\u5c0f\u4e3aO(m) + \tilde{O}(kd\bes^{-2})\uff1b\u5728\u6b27\u6c0f\u7a7a\u95f4\u4e2d\uff0cCoreset\u5927\u5c0f\u4e3aO(m\bes^{-1}) + \tilde{O}(\bis{k^{4/3}\bes^{-2}, k\bes^{-3}})\u3002\u8fd9\u4e9b\u7ed3\u679c\u4f18\u4e8e\u73b0\u6709\u7814\u7a76\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u9c81\u68d2k-\u4e2d\u4f4d\u6570\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684Coreset\u6784\u9020\uff0c\u5e76\u5728\u591a\u79cd\u5ea6\u91cf\u7a7a\u95f4\u4e2d\u5b9e\u73b0\u4e86\u6700\u4f18\u6216\u63a5\u8fd1\u6700\u4f18\u7684Coreset\u5927\u5c0f\u3002"}}
{"id": "2507.10611", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10611", "abs": "https://arxiv.org/abs/2507.10611", "authors": ["Mengwen Ye", "Yingzi Huangfu", "Shujian Gao", "Wei Ren", "Weifan Liu", "Zekuan Yu"], "title": "FedGSCA: Medical Federated Learning with Global Sample Selector and Client Adaptive Adjuster under Label Noise", "comment": null, "summary": "Federated Learning (FL) emerged as a solution for collaborative medical image\nclassification while preserving data privacy. However, label noise, which\narises from inter-institutional data variability, can cause training\ninstability and degrade model performance. Existing FL methods struggle with\nnoise heterogeneity and the imbalance in medical data. Motivated by these\nchallenges, we propose FedGSCA, a novel framework for enhancing robustness in\nnoisy medical FL. FedGSCA introduces a Global Sample Selector that aggregates\nnoise knowledge from all clients, effectively addressing noise heterogeneity\nand improving global model stability. Furthermore, we develop a Client Adaptive\nAdjustment (CAA) mechanism that combines adaptive threshold pseudo-label\ngeneration and Robust Credal Labeling Loss. CAA dynamically adjusts to class\ndistributions, ensuring the inclusion of minority samples and carefully\nmanaging noisy labels by considering multiple plausible labels. This dual\napproach mitigates the impact of noisy data and prevents overfitting during\nlocal training, which improves the generalizability of the model. We evaluate\nFedGSCA on one real-world colon slides dataset and two synthetic medical\ndatasets under various noise conditions, including symmetric, asymmetric,\nextreme, and heterogeneous types. The results show that FedGSCA outperforms the\nstate-of-the-art methods, excelling in extreme and heterogeneous noise\nscenarios. Moreover, FedGSCA demonstrates significant advantages in improving\nmodel stability and handling complex noise, making it well-suited for\nreal-world medical federated learning scenarios.", "AI": {"tldr": "FedGSCA \u662f\u4e00\u4e2a\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5168\u5c40\u6837\u672c\u9009\u62e9\u5668\u548c\u5ba2\u6237\u7aef\u81ea\u9002\u5e94\u8c03\u6574 (CAA) \u673a\u5236\u6765\u589e\u5f3a\u5608\u6742\u533b\u7597\u8054\u90a6\u5b66\u4e60\u7684\u9c81\u68d2\u6027\uff0c\u4ee5\u89e3\u51b3\u566a\u58f0\u5f02\u8d28\u6027\u548c\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u5728\u5904\u7406\u566a\u58f0\u5f02\u8d28\u6027\u548c\u533b\u7597\u6570\u636e\u4e0d\u5e73\u8861\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002\u56e0\u6b64\uff0c\u63d0\u51fa FedGSCA \u6846\u67b6\u4ee5\u589e\u5f3a\u5608\u6742\u533b\u7597\u8054\u90a6\u5b66\u4e60\u7684\u9c81\u68d2\u6027\u3002", "method": "FedGSCA \u6846\u67b6\u901a\u8fc7\u5168\u5c40\u6837\u672c\u9009\u62e9\u5668\u805a\u5408\u6765\u81ea\u6240\u6709\u5ba2\u6237\u7aef\u7684\u566a\u58f0\u77e5\u8bc6\uff0c\u4ee5\u89e3\u51b3\u566a\u58f0\u5f02\u8d28\u6027\u95ee\u9898\u5e76\u63d0\u9ad8\u5168\u5c40\u6a21\u578b\u7684\u7a33\u5b9a\u6027\u3002\u6b64\u5916\uff0c\u8fd8\u5f00\u53d1\u4e86\u4e00\u79cd\u5ba2\u6237\u7aef\u81ea\u9002\u5e94\u8c03\u6574 (CAA) \u673a\u5236\uff0c\u8be5\u673a\u5236\u7ed3\u5408\u4e86\u81ea\u9002\u5e94\u9608\u503c\u4f2a\u6807\u7b7e\u751f\u6210\u548c\u9c81\u68d2\u7684 Credal \u6807\u7b7e\u635f\u5931\uff0c\u4ee5\u52a8\u6001\u8c03\u6574\u7c7b\u522b\u5206\u5e03\uff0c\u786e\u4fdd\u5305\u542b\u5c11\u6570\u6837\u672c\uff0c\u5e76\u901a\u8fc7\u8003\u8651\u591a\u4e2a\u5408\u7406\u7684\u6807\u7b7e\u6765\u4ed4\u7ec6\u7ba1\u7406\u566a\u58f0\u6807\u7b7e\u3002", "result": "FedGSCA \u5728\u5404\u79cd\u566a\u58f0\u6761\u4ef6\u4e0b\uff0c\u5305\u62ec\u5bf9\u79f0\u3001\u4e0d\u5bf9\u79f0\u3001\u6781\u7aef\u548c\u5f02\u6784\u7c7b\u578b\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u7684\u7ed3\u80a0\u56fe\u50cf\u6570\u636e\u96c6\u548c\u4e24\u4e2a\u5408\u6210\u533b\u7597\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002\u7ed3\u679c\u8868\u660e\uff0cFedGSCA \u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u5728\u6781\u7aef\u548c\u5f02\u6784\u566a\u58f0\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u8272\u3002\u6b64\u5916\uff0cFedGSCA \u5728\u63d0\u9ad8\u6a21\u578b\u7a33\u5b9a\u6027\u548c\u5904\u7406\u590d\u6742\u566a\u58f0\u65b9\u9762\u663e\u793a\u51fa\u663e\u8457\u4f18\u52bf\u3002", "conclusion": "FedGSCA \u5728\u5404\u79cd\u566a\u58f0\u6761\u4ef6\u4e0b\uff0c\u5305\u62ec\u5bf9\u79f0\u3001\u4e0d\u5bf9\u79f0\u3001\u6781\u7aef\u548c\u5f02\u6784\u7c7b\u578b\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u7684\u7ed3\u80a0\u56fe\u50cf\u6570\u636e\u96c6\u548c\u4e24\u4e2a\u5408\u6210\u533b\u7597\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002\u7ed3\u679c\u8868\u660e\uff0cFedGSCA \u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u5728\u6781\u7aef\u548c\u5f02\u6784\u566a\u58f0\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u8272\u3002\u6b64\u5916\uff0cFedGSCA \u5728\u63d0\u9ad8\u6a21\u578b\u7a33\u5b9a\u6027\u548c\u5904\u7406\u590d\u6742\u566a\u58f0\u65b9\u9762\u663e\u793a\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u975e\u5e38\u9002\u5408\u771f\u5b9e\u7684\u533b\u7597\u8054\u90a6\u5b66\u4e60\u573a\u666f\u3002"}}
{"id": "2507.10960", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10960", "abs": "https://arxiv.org/abs/2507.10960", "authors": ["He Zhu", "Ryo Miyoshi", "Yuki Okafuji"], "title": "Whom to Respond To? A Transformer-Based Model for Multi-Party Social Robot Interaction", "comment": null, "summary": "Prior human-robot interaction (HRI) research has primarily focused on\nsingle-user interactions, where robots do not need to consider the timing or\nrecipient of their responses. However, in multi-party interactions, such as at\nmalls and hospitals, social robots must understand the context and decide both\nwhen and to whom they should respond. In this paper, we propose a\nTransformer-based multi-task learning framework to improve the decision-making\nprocess of social robots, particularly in multi-user environments. Considering\nthe characteristics of HRI, we propose two novel loss functions: one that\nenforces constraints on active speakers to improve scene modeling, and another\nthat guides response selection towards utterances specifically directed at the\nrobot. Additionally, we construct a novel multi-party HRI dataset that captures\nreal-world complexities, such as gaze misalignment. Experimental results\ndemonstrate that our model achieves state-of-the-art performance in respond\ndecisions, outperforming existing heuristic-based and single-task approaches.\nOur findings contribute to the development of socially intelligent social\nrobots capable of engaging in natural and context-aware multi-party\ninteractions.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u591a\u4efb\u52a1\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u65b0\u9896\u7684\u635f\u5931\u51fd\u6570\u548c\u6570\u636e\u96c6\uff0c\u63d0\u5347\u4e86\u793e\u4ea4\u673a\u5668\u4eba\u5728\u591a\u4eba\u573a\u666f\u4e0b\u7684\u54cd\u5e94\u51b3\u7b56\u80fd\u529b\u548c\u793e\u4ea4\u667a\u80fd\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u4eba\u4ea4\u4e92\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u5355\u7528\u6237\u4ea4\u4e92\uff0c\u5ffd\u7565\u4e86\u5728\u591a\u65b9\u4ea4\u4e92\uff08\u5982\u5546\u573a\u3001\u533b\u9662\uff09\u4e2d\u673a\u5668\u4eba\u9700\u8981\u7406\u89e3\u4e0a\u4e0b\u6587\u5e76\u51b3\u5b9a\u4f55\u65f6\u4ee5\u53ca\u5bf9\u8c01\u505a\u51fa\u54cd\u5e94\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u591a\u4efb\u52a1\u5b66\u4e60\u6846\u67b6\uff0c\u5e76\u5f15\u5165\u4e86\u4e24\u4e2a\u65b0\u9896\u7684\u635f\u5931\u51fd\u6570\uff1a\u4e00\u4e2a\u7528\u4e8e\u7ea6\u675f\u6d3b\u52a8\u53d1\u8a00\u8005\u4ee5\u6539\u8fdb\u573a\u666f\u5efa\u6a21\uff0c\u53e6\u4e00\u4e2a\u7528\u4e8e\u5f15\u5bfc\u54cd\u5e94\u9009\u62e9\u81f3\u673a\u5668\u4eba\u63a5\u6536\u5230\u7684\u8bed\u97f3\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6a21\u578b\u5728\u54cd\u5e94\u51b3\u7b56\u65b9\u9762\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u4e8e\u542f\u53d1\u5f0f\u548c\u5355\u4efb\u52a1\u7684\u65b9\u6cd5\u3002\u7279\u522b\u662f\u5728\u5904\u7406\u5982\u6ce8\u89c6\u672a\u5bf9\u51c6\u7b49\u73b0\u5b9e\u590d\u6742\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u63d0\u51fa\u7684Transformer\u6a21\u578b\u548c\u65b0\u9896\u7684\u635f\u5931\u51fd\u6570\uff0c\u5728\u591a\u65b9\u4ea4\u4e92\u73af\u5883\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u793e\u4ea4\u673a\u5668\u4eba\u7684\u54cd\u5e94\u51b3\u7b56\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u4e3a\u5f00\u53d1\u66f4\u5177\u793e\u4ea4\u667a\u80fd\u7684\u673a\u5668\u4eba\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.11118", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.11118", "abs": "https://arxiv.org/abs/2507.11118", "authors": ["San-Dong Guo"], "title": "Hidden fully-compensated ferrimagnetism", "comment": "6 pages, 7 figures. arXiv admin note: text overlap with\n  arXiv:2411.13795", "summary": "Incorporating zero-net-magnetization magnets that exhibit spin-splitting into\nspintronics delivers key advantages: faster switching dynamics, greater\nimmunity to destabilizing fields, lower power consumption, and markedly\nimproved overall efficiency. The collinear magnets with net-zero magnetization\nand spin-splitting mainly include altermagnet and fully-compensated\nferrimagnet, which provide possibility to achieve hidden spin polarization\n(HSP) with net-zero spin polarization in total but non-zero local spin\npolarization. In addition to proposal of hidden altermagnetism, we hereby\nintroduce this concept of hidden fully-compensated ferrimagnetism, where the\ntotal spin polarization is zero, but either of the two inversion-partner\nsectors possesses fully-compensated ferrimagnetism with non-zero local spin\npolarization in the real space. By the first-principle calculations, we predict\nthat $PT$-bilayer $\\mathrm{CrMoC_2S_6}$ is a possible hidden fully-compensated\nferrimagnet, showing fully-compensated ferrimagnetic HSP, which can be\nseparated and observed by an out-of-plane external electric field. Our works\nprovide a class of hidden spin-polarized materials that facilitates the\nadvancement of spintronics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9690\u85cf\u7684\u5168\u8865\u507f\u4e9a\u94c1\u78c1\u6027\u6982\u5ff5\uff0c\u5e76\u9884\u6d4b\u4e86\u4e00\u79cd\u540d\u4e3a $PT$-\u53cc\u5c42 $\text{CrMoC}_2\text{S}_6$ \u7684\u65b0\u578b\u6750\u6599\uff0c\u5b83\u5177\u6709\u9690\u85cf\u81ea\u65cb\u6781\u5316\uff0c\u53ef\u4ee5\u901a\u8fc7\u7535\u573a\u8c03\u63a7\uff0c\u4e3a\u81ea\u65cb\u7535\u5b50\u5b66\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002", "motivation": "\u4e3a\u4e86\u5728\u81ea\u65cb\u7535\u5b50\u5b66\u4e2d\u5b9e\u73b0\u66f4\u5feb\u7684\u5f00\u5173\u52a8\u529b\u5b66\u3001\u66f4\u9ad8\u7684\u6297\u5e72\u6270\u6027\u3001\u66f4\u4f4e\u7684\u529f\u8017\u548c\u66f4\u9ad8\u7684\u6574\u4f53\u6548\u7387\uff0c\u9700\u8981\u5f15\u5165\u5177\u6709\u81ea\u65cb\u5288\u88c2\u7684\u96f6\u51c0\u78c1\u5316\u6750\u6599\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u9664\u8d85\u78c1\u4f53\u5916\uff0c\u5177\u6709\u96f6\u51c0\u81ea\u65cb\u6781\u5316\u4f46\u5c40\u90e8\u81ea\u65cb\u6781\u5316\u975e\u96f6\u7684\u9690\u85cf\u81ea\u65cb\u6781\u5316\uff08HSP\uff09\u7684\u65b0\u578b\u6750\u6599\u3002", "method": "\u901a\u8fc7\u7b2c\u4e00\u6027\u539f\u7406\u8ba1\u7b97\uff0c\u9884\u6d4b\u4e86 $PT$-\u53cc\u5c42 $\text{CrMoC}_2\text{S}_6$ \u662f\u4e00\u79cd\u9690\u85cf\u7684\u5168\u8865\u507f\u4e9a\u94c1\u78c1\u6027\u6750\u6599\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5168\u8865\u507f\u7684\u9690\u85cf\u81ea\u65cb\u6781\u5316\u7279\u6027\uff0c\u4ee5\u53ca\u5982\u4f55\u901a\u8fc7\u5916\u7535\u573a\u8fdb\u884c\u8c03\u63a7\u3002", "result": "\u9884\u6d4b\u4e86 $PT$-\u53cc\u5c42 $\text{CrMoC}_2\text{S}_6$ \u662f\u4e00\u79cd\u9690\u85cf\u7684\u5168\u8865\u507f\u4e9a\u94c1\u78c1\u6027\u6750\u6599\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u9690\u85cf\u81ea\u65cb\u6781\u5316\u7279\u6027\uff0c\u8be5\u7279\u6027\u53ef\u4ee5\u901a\u8fc7\u5916\u52a0\u5782\u76f4\u7535\u573a\u8fdb\u884c\u5206\u79bb\u548c\u89c2\u5bdf\u3002 ", "conclusion": "\u672c\u6587\u63d0\u51fa\u5e76\u9884\u6d4b\u4e86\u4e00\u79cd\u9690\u85cf\u7684\u3001\u5168\u8865\u507f\u7684\u4e9a\u94c1\u78c1\u6027\u6750\u6599 $PT$-\u53cc\u5c42 $\text{CrMoC}_2\text{S}_6$\uff0c\u5176\u5177\u6709\u5168\u8865\u507f\u7684\u9690\u85cf\u81ea\u65cb\u6781\u5316\uff0c\u53ef\u901a\u8fc7\u5782\u76f4\u5916\u7535\u573a\u5206\u79bb\u548c\u89c2\u5bdf\u3002\u8fd9\u4e9b\u7814\u7a76\u4e3a\u81ea\u65cb\u7535\u5b50\u5b66\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u4e00\u7c7b\u65b0\u7684\u9690\u85cf\u81ea\u65cb\u6781\u5316\u6750\u6599\u3002"}}
{"id": "2507.10887", "categories": ["cond-mat.mes-hall", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.10887", "abs": "https://arxiv.org/abs/2507.10887", "authors": ["Alexandre R. Rocha", "Rodrigo G. Amorim", "Wanderl\u00e3 L. Scopel", "Cesar E. P. Villegas"], "title": "Tunable Interlayer Excitons in Bilayer Graphene Nanoribbons", "comment": null, "summary": "Vertically stacked van der Waals structures are promising platforms that\nenable layer engineering, opening new avenues for the quantum control of\nelementary excitations, including optically generated bound electron-hole\npairs. Here we employ excited-state density functional calculations to\ndemonstrate strong interlayer excitonic coupling in one-dimensional van der\nWaals nanostructures derived from armchair graphene nanoribbons. The excitonic\nresponse exhibits prominent peaks in the near-infrared range, mainly attributed\nto intralayer excitons, while interlayer excitations with absorption peak\nstrengths of up to 13\\% of the maximum absorption are also observed. Both\ntype-I and type-II band alignments are found, which promote the formation of\nintralayer and interlayer excitons. Notably, interlayer excitons in these\nsystems exhibit long-lived radiative lifetimes at room temperature, ranging\nfrom 1 nanosecond to 9.4 microseconds. Our calculations suggest the potential\nto tune the excitonic response and lifetimes of bilayer graphene nanoribbons\nvia careful engineering of the stacking order.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528\u91cf\u5b50\u5316\u5b66\u8ba1\u7b97\u53d1\u73b0\uff0c\u77f3\u58a8\u70ef\u7eb3\u7c73\u5e26\u5f62\u6210\u7684\u8303\u5fb7\u534e\u5f02\u8d28\u7ed3\u6784\u4e2d\u5b58\u5728\u5c42\u95f4\u6fc0\u5b50\u8026\u5408\u6548\u5e94\uff0c\u5e76\u80fd\u5b9e\u73b0\u957f\u5bff\u547d\u6fc0\u5b50\uff0c\u6709\u671b\u7528\u4e8e\u91cf\u5b50\u8c03\u63a7\u548c\u5149\u7535\u5b50\u5668\u4ef6\u3002", "motivation": "\u4e3a\u4e86\u63a2\u7d22\u5782\u76f4\u5806\u53e0\u7684\u8303\u5fb7\u534e\u7ed3\u6784\u5728\u91cf\u5b50\u8c03\u63a7\u548c\u65b0\u5947\u5149\u7535\u5b50\u7279\u6027\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u7814\u7a76\u5c42\u95f4\u6fc0\u5b50\u8026\u5408\u6548\u5e94\u3002", "method": "\u5229\u7528\u6fc0\u53d1\u6001\u5bc6\u5ea6\u6cdb\u51fd\u7406\u8bba\u8ba1\u7b97\uff0c\u7814\u7a76\u4e86\u76f4\u7ebf\u578b\u77f3\u58a8\u70ef\u7eb3\u7c73\u5e26\u884d\u751f\u7684\u4e8c\u7ef4\u8303\u5fb7\u534e\u7eb3\u7c73\u7ed3\u6784\u4e2d\u7684\u5c42\u95f4\u6fc0\u5b50\u8026\u5408\u3002", "result": "\u53d1\u73b0\u6240\u7814\u7a76\u7684\u7ed3\u6784\u4e2d\u5b58\u5728\u5f3a\u70c8\u7684\u5c42\u95f4\u6fc0\u5b50\u8026\u5408\uff0c\u6fc0\u5b50\u54cd\u5e94\u5728\u8fd1\u7ea2\u5916\u533a\u57df\u51fa\u73b0\u5cf0\u503c\uff0c\u5e76\u89c2\u5bdf\u5230\u4e86\u5c42\u95f4\u6fc0\u5b50\u6fc0\u53d1\uff0c\u5176\u5438\u6536\u5cf0\u5f3a\u5ea6\u53ef\u8fbe\u6700\u5927\u5438\u6536\u768413%\u3002\u540c\u65f6\uff0c\u53d1\u73b0\u4e86\u4fc3\u8fdb\u6fc0\u5b50\u5f62\u6210\u7684I\u578b\u548cII\u578b\u5e26\u5bf9\u9f50\u3002\u7279\u522b\u5730\uff0c\u5728\u5ba4\u6e29\u4e0b\uff0c\u5c42\u95f4\u6fc0\u5b50\u7684\u8f90\u5c04\u5bff\u547d\u957f\u8fbe1\u7eb3\u79d2\u81f39.4\u5fae\u79d2\u3002", "conclusion": "\u901a\u8fc7\u4ed4\u7ec6\u8bbe\u8ba1\u5806\u53e0\u987a\u5e8f\uff0c\u53ef\u4ee5\u8c03\u8282\u53cc\u5c42\u77f3\u58a8\u70ef\u7eb3\u7c73\u5e26\u7684\u6fc0\u5b50\u54cd\u5e94\u548c\u5bff\u547d\uff0c\u8fd9\u8868\u660e\u5176\u5728\u91cf\u5b50\u63a7\u5236\u548c\u5149\u7535\u5b50\u5668\u4ef6\u9886\u57df\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2507.10771", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.10771", "abs": "https://arxiv.org/abs/2507.10771", "authors": ["Hrant Gharibyan", "Siddharth Hariprakash", "Mohammed Zuhair Mullath", "Vincent P. Su"], "title": "A Practical Guide to using Pauli Path Simulators for Utility-Scale Quantum Experiments", "comment": "27 pages, 17 figures", "summary": "In this this paper we present an inexpensive protocol to perform runtime and\nmemory estimation for large-scale experiments with Pauli Path simulators (PPS).\nAdditionally, we propose a conceptually simple solution for studying whether\nPPS can be used as a scientific discovery tool, rather than reproducing\nexisting answers. We start by analyzing the dynamics of the Pauli coefficients\ntracked in the Heisenberg picture. In addition to surprisingly generic\nconvergence features of the Pauli coefficient distributions, we find certain\nregularities that allow for extrapolation of memory and runtime requirements\nfor smaller and smaller coefficient truncation parameter $\\delta$. We then\nintroduce a framework for understanding convergence in the absence of rigorous\nerror guarantees on PPS. Combined with runtime analysis, we propose bifurcating\nquantum simulation problems broadly into two classes, based on whether there is\napparent convergence of expectation values as a function of $\\delta$. This\nserves as a way for practitioners to understand where their problem falls on\nthe frontier of classical simulability. In the case without apparent\nconvergence, PPS may still serve useful as a Monte Carlo-like estimate. Applied\nto IBM's utility-scale experiments, we show parameter regimes where both\nbehaviors are realized. Some of our key findings challenge conventional\nintuition: reducing $\\delta$ does not always improve accuracy, and deeper\nquantum circuits may actually be easier to simulate than shallower ones. The\nBlueQubit SDK implementing these methods has been released publicly, offering\nresearchers a comprehensive toolkit for evaluating this frontier classical\nsimulation approach. These results establish practical guidelines for when PPS\ncan serve as a reliable verification tool versus when it should be used as a\ncomplementary estimate alongside quantum experiments.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.10881", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10881", "abs": "https://arxiv.org/abs/2507.10881", "authors": ["Roman Naeem", "David Hagerman", "Jennifer Alv\u00e9n", "Lennart Svensson", "Fredrik Kahl"], "title": "Trexplorer Super: Topologically Correct Centerline Tree Tracking of Tubular Objects in CT Volumes", "comment": "Submitted Version. Accepted at MICCAI 2025", "summary": "Tubular tree structures, such as blood vessels and airways, are essential in\nhuman anatomy and accurately tracking them while preserving their topology is\ncrucial for various downstream tasks. Trexplorer is a recurrent model designed\nfor centerline tracking in 3D medical images but it struggles with predicting\nduplicate branches and terminating tracking prematurely. To address these\nissues, we present Trexplorer Super, an enhanced version that notably improves\nperformance through novel advancements. However, evaluating centerline tracking\nmodels is challenging due to the lack of public datasets. To enable thorough\nevaluation, we develop three centerline datasets, one synthetic and two real,\neach with increasing difficulty. Using these datasets, we conduct a\ncomprehensive evaluation of existing state-of-the-art (SOTA) models and compare\nthem with our approach. Trexplorer Super outperforms previous SOTA models on\nevery dataset. Our results also highlight that strong performance on synthetic\ndata does not necessarily translate to real datasets. The code and datasets are\navailable at https://github.com/RomStriker/Trexplorer-Super.", "AI": {"tldr": "A new model, Trexplorer Super, improves centerline tracking in 3D medical images and is validated on new synthetic and real-world datasets, outperforming existing methods. Performance on synthetic data doesn't always generalize to real data.", "motivation": "Accurately tracking tubular tree structures like blood vessels and airways in 3D medical images is crucial for various downstream tasks, but existing models like Trexplorer struggle with issues like predicting duplicate branches and premature tracking termination. There is also a lack of public datasets for evaluating centerline tracking models.", "method": "The paper introduces Trexplorer Super, an enhanced version of the Trexplorer model, designed for centerline tracking in 3D medical images. It also develops three centerline datasets (one synthetic, two real) with increasing difficulty to enable comprehensive evaluation.", "result": "Trexplorer Super significantly improves performance compared to previous SOTA models on all developed datasets. The evaluation also revealed that high performance on synthetic data does not guarantee similar performance on real-world datasets.", "conclusion": "Trexplorer Super outperforms previous SOTA models on every dataset, and strong performance on synthetic data does not necessarily translate to real datasets."}}
{"id": "2507.10803", "categories": ["cs.AI", "cs.CL", "cs.ET", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.10803", "abs": "https://arxiv.org/abs/2507.10803", "authors": ["JaMor Hairston", "Ritvik Ranjan", "Sahithi Lakamana", "Anthony Spadaro", "Selen Bozkurt", "Jeanmarie Perrone", "Abeed Sarker"], "title": "Automated Thematic Analyses Using LLMs: Xylazine Wound Management Social Media Chatter Use Case", "comment": "Pages: 19, Abstract word count: 151 words, Manuscript word count:\n  2185 words, References: 14, Figures: 3, Tables: 2", "summary": "Background Large language models (LLMs) face challenges in inductive thematic\nanalysis, a task requiring deep interpretive and domain-specific expertise. We\nevaluated the feasibility of using LLMs to replicate expert-driven thematic\nanalysis of social media data. Methods Using two temporally non-intersecting\nReddit datasets on xylazine (n=286 and n=686, for model optimization and\nvalidation, respectively) with twelve expert-derived themes, we evaluated five\nLLMs against expert coding. We modeled the task as a series of binary\nclassifications, rather than a single, multi-label classification, employing\nzero-, single-, and few-shot prompting strategies and measuring performance via\naccuracy, precision, recall, and F1-score. Results On the validation set,\nGPT-4o with two-shot prompting performed best (accuracy: 90.9%; F1-score:\n0.71). For high-prevalence themes, model-derived thematic distributions closely\nmirrored expert classifications (e.g., xylazine use: 13.6% vs. 17.8%; MOUD use:\n16.5% vs. 17.8%). Conclusions Our findings suggest that few-shot LLM-based\napproaches can automate thematic analyses, offering a scalable supplement for\nqualitative research. Keywords: thematic analysis, large language models,\nnatural language processing, qualitative analysis, social media, prompt\nengineering, public health", "AI": {"tldr": "\u672c\u7814\u7a76\u53d1\u73b0\uff0c\u901a\u8fc7\u5c11\u6b21\u63d0\u793a\uff0cLLM\u53ef\u4ee5\u6709\u6548\u8fdb\u884c\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u7684\u5f52\u7eb3\u4e3b\u9898\u5206\u6790\uff0c\u5e76\u4e14\u5728\u67d0\u4e9b\u65b9\u9762\u80fd\u5ab2\u7f8e\u751a\u81f3\u8d85\u8d8a\u4e13\u5bb6\u5206\u6790\uff0c\u4e3a\u5b9a\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u8f85\u52a9\u65b9\u6cd5\u3002", "motivation": "\u8bc4\u4f30\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u590d\u5236\u4e13\u5bb6\u9a71\u52a8\u7684\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u5f52\u7eb3\u4e3b\u9898\u5206\u6790\u7684\u53ef\u884c\u6027\uff0c\u56e0\u4e3aLLM\u5728\u5904\u7406\u9700\u8981\u6df1\u5ea6\u89e3\u91ca\u548c\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u7684\u4efb\u52a1\u65f6\u9762\u4e34\u6311\u6218\u3002", "method": "\u7814\u7a76\u4eba\u5458\u4f7f\u7528\u4e86\u4e24\u4e2a\u4e0d\u76f8\u4ea4\u7684Reddit\u6570\u636e\u96c6\uff08\u5206\u522b\u5305\u542b286\u548c686\u6761\u5173\u4e8exylazine\u7684\u5e16\u5b50\uff09\uff0c\u5e76\u7ed3\u5408\u4e8612\u4e2a\u7531\u4e13\u5bb6\u786e\u5b9a\u7684\u4e3b\u9898\u3002\u4ed6\u4eec\u91c7\u7528\u4e86\u96f6\u6b21\u3001\u4e00\u6b21\u548c\u5c11\u6b21\u63d0\u793a\u7b56\u7565\uff0c\u5c06\u8fd9\u9879\u4efb\u52a1\u5efa\u6a21\u4e3a\u4e00\u7cfb\u5217\u4e8c\u5143\u5206\u7c7b\u95ee\u9898\uff0c\u800c\u4e0d\u662f\u5355\u4e00\u7684\u591a\u6807\u7b7e\u5206\u7c7b\u95ee\u9898\u3002\u4f7f\u7528\u51c6\u786e\u7387\u3001\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u6765\u8861\u91cf\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5728\u9a8c\u8bc1\u96c6\u4e0a\uff0cGPT-4o\u91c7\u7528\u4e24\u6b21\u63d0\u793a\u7b56\u7565\u8868\u73b0\u6700\u4f73\uff0c\u51c6\u786e\u7387\u4e3a90.9%\uff0cF1\u5206\u6570\u4e3a0.71\u3002\u5bf9\u4e8e\u9ad8\u6d41\u884c\u5ea6\u7684\u4e3b\u9898\uff0c\u6a21\u578b\u5f97\u51fa\u7684\u4e3b\u9898\u5206\u5e03\u4e0e\u4e13\u5bb6\u5206\u7c7b\u975e\u5e38\u63a5\u8fd1\uff08\u4f8b\u5982\uff0cxylazine\u4f7f\u7528\uff1a13.6% vs. 17.8%\uff1bMOUD\u4f7f\u7528\uff1a16.5% vs. 17.8%\uff09\u3002", "conclusion": "LLM\u5728\u5b9a\u6027\u7814\u7a76\u4e2d\u53ef\u4ee5\u4f5c\u4e3a\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u8865\u5145\uff0c\u7528\u4e8e\u4e3b\u9898\u5206\u6790\u3002"}}
{"id": "2507.11493", "categories": ["cs.LG", "cs.NE", "68T07"], "pdf": "https://arxiv.org/pdf/2507.11493", "abs": "https://arxiv.org/abs/2507.11493", "authors": ["Majid Darehmiraki"], "title": "A parametric activation function based on Wendland RBF", "comment": "11 pages, 2 figures", "summary": "This paper introduces a novel parametric activation function based on\nWendland radial basis functions (RBFs) for deep neural networks. Wendland RBFs,\nknown for their compact support, smoothness, and positive definiteness in\napproximation theory, are adapted to address limitations of traditional\nactivation functions like ReLU, sigmoid, and tanh. The proposed enhanced\nWendland activation combines a standard Wendland component with linear and\nexponential terms, offering tunable locality, improved gradient propagation,\nand enhanced stability during training. Theoretical analysis highlights its\nmathematical properties, including smoothness and adaptability, while empirical\nexperiments on synthetic tasks (e.g., sine wave approximation) and benchmark\ndatasets (MNIST, Fashion-MNIST) demonstrate competitive performance. Results\nshow that the Wendland-based activation achieves superior accuracy in certain\nscenarios, particularly in regression tasks, while maintaining computational\nefficiency. The study bridges classical RBF theory with modern deep learning,\nsuggesting that Wendland activations can mitigate overfitting and improve\ngeneralization through localized, smooth transformations. Future directions\ninclude hybrid architectures and domain-specific adaptations.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8eWendland\u5f84\u5411\u57fa\u51fd\u6570\u7684\u6fc0\u6d3b\u51fd\u6570\uff0c\u5b83\u6bd4\u4f20\u7edf\u7684\u6fc0\u6d3b\u51fd\u6570\u66f4\u5149\u6ed1\u3001\u66f4\u7a33\u5b9a\uff0c\u5e76\u4e14\u5728\u67d0\u4e9b\u4efb\u52a1\u4e0a\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u4e3a\u4e86\u514b\u670dReLU\u3001sigmoid\u548ctanh\u7b49\u4f20\u7edf\u6fc0\u6d3b\u51fd\u6570\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5229\u7528Wendland RBF\u7684\u7d27\u652f\u6491\u3001\u5149\u6ed1\u6027\u548c\u6b63\u5b9a\u6027\u7b49\u4f18\u70b9\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eWendland\u5f84\u5411\u57fa\u51fd\u6570\u7684\u589e\u5f3a\u578b\u6fc0\u6d3b\u51fd\u6570\uff0c\u8be5\u51fd\u6570\u7ed3\u5408\u4e86\u7ebf\u6027\u3001\u6307\u6570\u548cWendland\u5206\u91cf\uff0c\u5e76\u5177\u6709\u53ef\u8c03\u7684\u5c40\u90e8\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5Wendland\u6fc0\u6d3b\u51fd\u6570\u5728\u67d0\u4e9b\u573a\u666f\u4e0b\uff08\u5c24\u5176\u662f\u5728\u56de\u5f52\u4efb\u52a1\u4e2d\uff09\u5b9e\u73b0\u4e86\u4f18\u4e8e\u4f20\u7edf\u6fc0\u6d3b\u51fd\u6570\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u5e76\u80fd\u7f13\u89e3\u8fc7\u62df\u5408\u3001\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u57fa\u4e8eWendland\u5f84\u5411\u57fa\u51fd\u6570\uff08RBF\uff09\u7684\u65b0\u578b\u53c2\u6570\u5316\u6fc0\u6d3b\u51fd\u6570\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5728\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4e2d\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u7f13\u89e3\u8fc7\u62df\u5408\u548c\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u3002"}}
{"id": "2507.11291", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2507.11291", "abs": "https://arxiv.org/abs/2507.11291", "authors": ["Benjamin Aram Berendsohn"], "title": "Permutation patterns in streams", "comment": null, "summary": "Permutation patterns and pattern avoidance are central, well-studied concepts\nin combinatorics and computer science. Given two permutations $\\tau$ and $\\pi$,\nthe pattern matching problem (PPM) asks whether $\\tau$ contains $\\pi$. This\nproblem arises in various contexts in computer science and statistics and has\nbeen studied extensively in exact-, parameterized-, approximate-,\nproperty-testing- and other formulations.\n  In this paper, we study pattern matching in a \\emph{streaming setting}, when\nthe input $\\tau$ is revealed sequentially, one element at a time. There is\nextensive work on the space complexity of various statistics in streams of\nintegers. The novelty of our setting is that the input stream is \\emph{a\npermutation}, which allows inferring some information about future inputs. Our\nalgorithms crucially take advantage of this fact, while existing lower bound\ntechniques become difficult to apply.\n  We show that the complexity of the problem changes dramatically depending on\nthe pattern~$\\pi$. The space requirement is: $\\Theta(k\\log{n})$ for the\nmonotone patterns $\\pi = 12\\dots k$, or $\\pi = k\\dots21$, $O(\\sqrt{n\\log{n}})$\nfor $\\pi \\in \\{312,132\\}$, $O(\\sqrt{n} \\log n)$ for $\\pi \\in \\{231,213\\}$, and\n$\\widetilde{\\Theta}_{\\pi}(n)$ for all other $\\pi$. If $\\tau$ is an arbitrary\nsequence of integers (not necessary a permutation), we show that the complexity\nis $\\widetilde{\\Theta}_{\\pi}(n)$ in all except the first (monotone) cases.", "AI": {"tldr": "This paper analyzes the space complexity of finding permutation patterns in a stream. The complexity depends on the pattern: monotone patterns take $\\Theta(k\\log n)$, some patterns take $O(\\sqrt{n\\log n})$ or $O(\\sqrt{n} \\log n)$, and others take $\\widetilde{\\Theta}_{\\pi}(n)$. For non-permutation streams, it", "motivation": "The motivation is to study permutation pattern matching in a streaming setting, where the input is revealed sequentially. This setting is novel because the input being a permutation allows for inferring information about future inputs, which can be exploited by algorithms. Existing lower bound techniques are difficult to apply in this context.", "method": "The paper proposes algorithms for permutation pattern matching in a streaming setting, leveraging the sequential nature of the input permutation to infer information about future elements. It analyzes the space complexity for different types of patterns (monotone, 312, 132, 231, 213, and others) and compares it to the case where the input is an arbitrary sequence of integers.", "result": "The paper demonstrates that the space complexity of permutation pattern matching in a streaming setting is highly dependent on the pattern. Specifically, it establishes complexity bounds for various patterns, including $\\Theta(k\\log n)$ for monotone patterns, $O(\\sqrt{n\\log n})$ for $\\pi \\in \\{312,132\\}$, $O(\\sqrt{n} \\log n)$ for $\\pi \\in \\{231,213\\}$, and $\\widetilde{\\Theta}_{\\pi}(n)$ for all other patterns. The results also show that for arbitrary sequences, the complexity is $\\widetilde{\\Theta}_{\\pi}(n)$ except for monotone patterns.", "conclusion": "The paper studies the complexity of permutation pattern matching in a streaming setting, showing that the space complexity varies significantly based on the specific pattern being searched for. For monotone patterns, the complexity is $\\Theta(k\\log n)$. For patterns like 312 and 132, it is $O(\\sqrt{n\\log n})$. For patterns 231 and 213, it is $O(\\sqrt{n} \\log n)$. For all other patterns, it is $\\widetilde{\\Theta}_{\\pi}(n)$. In contrast, for arbitrary sequences (not permutations), the complexity is $\\widetilde{\\Theta}_{\\pi}(n)$ for all cases except the monotone ones."}}
{"id": "2507.10613", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10613", "abs": "https://arxiv.org/abs/2507.10613", "authors": ["Zhengyu Chen", "Siqi Wang", "Teng Xiao", "Yudong Wang", "Shiqi Chen", "Xunliang Cai", "Junxian He", "Jingang Wang"], "title": "Sub-Scaling Laws: On the Role of Data Density and Training Strategies in LLMs", "comment": null, "summary": "Traditional scaling laws in natural language processing suggest that\nincreasing model size and training data enhances performance. However, recent\nstudies reveal deviations, particularly in large language models, where\nperformance improvements decelerate, which is a phenomenon known as\nsub-scaling. This paper revisits these scaling laws by examining the impact of\ndata quality and training strategies on model performance. Through extensive\nempirical analysis of over 400 models, we identify high data density and\nnon-optimal resource allocation as key factors contributing to sub-scaling.\nHigh data density leads to diminishing returns due to redundant information,\nwhile optimal resource allocation is crucial for sustained performance\nimprovements. We propose a sub-optimal scaling law that better predicts\nperformance in sub-scaling regimes, highlighting the importance of data quality\nand diversity.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u6570\u636e\u8d28\u91cf\u548c\u8bad\u7ec3\u7b56\u7565\uff08\u5982\u6570\u636e\u5bc6\u5ea6\u548c\u8d44\u6e90\u5206\u914d\uff09\u4f1a\u5f71\u54cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5e76\u63d0\u51fa\u65b0\u7684\u7f29\u653e\u5b9a\u5f8b\u4ee5\u66f4\u597d\u5730\u9884\u6d4b\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u63a2\u8ba8\u4e86\u4f20\u7edf\u7f29\u653e\u5b9a\u5f8b\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u51fa\u73b0\u7684\u504f\u5dee\uff08\u5373\u4e9a\u7ebf\u6027\u7f29\u653e\uff09\uff0c\u65e8\u5728\u7406\u89e3\u5176\u80cc\u540e\u7684\u539f\u56e0\u3002", "method": "\u901a\u8fc7\u5bf9400\u591a\u4e2a\u6a21\u578b\u8fdb\u884c\u5e7f\u6cdb\u7684\u5b9e\u8bc1\u5206\u6790\uff0c\u7814\u7a76\u4e86\u6570\u636e\u8d28\u91cf\u548c\u8bad\u7ec3\u7b56\u7565\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u786e\u5b9a\u4e86\u9ad8\u6570\u636e\u5bc6\u5ea6\u548c\u8d44\u6e90\u5206\u914d\u4e0d\u5f53\u662f\u5bfc\u81f4\u4e9a\u7ebf\u6027\u7f29\u653e\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u66f4\u597d\u5730\u9884\u6d4b\u4e9a\u7ebf\u6027\u7f29\u653e\u6a21\u578b\u6027\u80fd\u7684\u6b21\u4f18\u7f29\u653e\u5b9a\u5f8b\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u8bc6\u522b\u6570\u636e\u8d28\u91cf\u548c\u8bad\u7ec3\u7b56\u7565\u5728\u6a21\u578b\u6027\u80fd\u4e2d\u7684\u4f5c\u7528\uff0c\u4e3a\u7406\u89e3\u548c\u9884\u6d4b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4e9a\u7ebf\u6027\u7f29\u653e\u73b0\u8c61\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002"}}
{"id": "2507.10961", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.10961", "abs": "https://arxiv.org/abs/2507.10961", "authors": ["Joohwan Seo", "Arvind Kruthiventy", "Soomi Lee", "Megan Teng", "Xiang Zhang", "Seoyeon Choi", "Jongeun Choi", "Roberto Horowitz"], "title": "EquiContact: A Hierarchical SE(3) Vision-to-Force Equivariant Policy for Spatially Generalizable Contact-rich Tasks", "comment": "Submitted to RA-L", "summary": "This paper presents a framework for learning vision-based robotic policies\nfor contact-rich manipulation tasks that generalize spatially across task\nconfigurations. We focus on achieving robust spatial generalization of the\npolicy for the peg-in-hole (PiH) task trained from a small number of\ndemonstrations. We propose EquiContact, a hierarchical policy composed of a\nhigh-level vision planner (Diffusion Equivariant Descriptor Field, Diff-EDF)\nand a novel low-level compliant visuomotor policy (Geometric Compliant ACT,\nG-CompACT). G-CompACT operates using only localized observations (geometrically\nconsistent error vectors (GCEV), force-torque readings, and wrist-mounted RGB\nimages) and produces actions defined in the end-effector frame. Through these\ndesign choices, we show that the entire EquiContact pipeline is\nSE(3)-equivariant, from perception to force control. We also outline three key\ncomponents for spatially generalizable contact-rich policies: compliance,\nlocalized policies, and induced equivariance. Real-world experiments on PiH\ntasks demonstrate a near-perfect success rate and robust generalization to\nunseen spatial configurations, validating the proposed framework and\nprinciples. The experimental videos can be found on the project website:\nhttps://sites.google.com/berkeley.edu/equicontact", "AI": {"tldr": "EquiContact\u6846\u67b6\u901a\u8fc7\u7ed3\u5408SE(3)\u7b49\u53d8\u7684\u89c6\u89c9\u89c4\u5212\u548c\u4f4e\u5c42\u51e0\u4f55\u9c81\u68d2\u6027\u63a7\u5236\uff0c\u5b9e\u73b0\u4e86\u673a\u5668\u4eba\u63a5\u89e6\u64cd\u4f5c\u4efb\u52a1\uff08\u5982\u9489\u5b50\u63d2\u5165\u5b54\uff09\u7684\u7a7a\u95f4\u6cdb\u5316\u548c\u9ad8\u6210\u529f\u7387\u3002", "motivation": "\u65e8\u5728\u5b9e\u73b0\u89c6\u89c9\u5f15\u5bfc\u7684\u3001\u63a5\u89e6\u4e30\u5bcc\u7684\u64cd\u4f5c\u4efb\u52a1\u4e2d\u7b56\u7565\u7684\u7a7a\u95f4\u6cdb\u5316\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u9489\u5b50\u63d2\u5165\u5b54\uff08PiH\uff09\u4efb\u52a1\u4e2d\uff0c\u5e76\u4ece\u5c11\u91cf\u6f14\u793a\u4e2d\u8fdb\u884c\u8bad\u7ec3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEquiContact\u7684\u5c42\u6b21\u5316\u7b56\u7565\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7531\u9ad8\u5c42\u7684\u6269\u6563\u7b49\u53d8\u63cf\u8ff0\u7b26\u573a\uff08Diff-EDF\uff09\u548c\u4f4e\u5c42\u7684\u51e0\u4f55\u9c81\u68d2\u6027AC T\uff08G-CompACT\uff09\u7ec4\u6210\u3002G-CompACT\u4ec5\u4f7f\u7528\u5c40\u90e8\u89c2\u6d4b\uff08\u51e0\u4f55\u4e00\u81f4\u8bef\u5dee\u5411\u91cf\u3001\u529b\u77e9\u8bfb\u6570\u548c\u8155\u90e8RGB\u56fe\u50cf\uff09\u5e76\u8f93\u51fa\u672b\u7aef\u6267\u884c\u5668\u5750\u6807\u7cfb\u4e2d\u7684\u52a8\u4f5c\u3002EquiContact\u7684\u6574\u4e2a\u6d41\u7a0b\u90fd\u5177\u6709SE(3)\u7b49\u53d8\u6027\u3002", "result": "\u5728\u73b0\u5b9e\u4e16\u754c\u7684PiH\u4efb\u52a1\u5b9e\u9a8c\u4e2d\uff0cEquiContact\u6846\u67b6\u5b9e\u73b0\u4e86\u63a5\u8fd1\u5b8c\u7f8e\u7684\u6210\u529f\u7387\uff0c\u5e76\u80fd\u9c81\u68d2\u5730\u6cdb\u5316\u5230\u672a\u89c1\u7684\u7a7a\u95f4\u914d\u7f6e\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u7684\u6846\u67b6\u548c\u539f\u7406\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86EquiContact\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u9ad8\u5c42\u6269\u6563\u7b49\u53d8\u63cf\u8ff0\u7b26\u573a\uff08Diff-EDF\uff09\u548c\u4f4e\u5c42\u51e0\u4f55\u9c81\u68d2\u6027AC T\uff08G-CompACT\uff09\u7684\u5c42\u6b21\u5316\u7b56\u7565\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u89c6\u89c9\u5f15\u5bfc\u7684\u3001\u63a5\u89e6\u4e30\u5bcc\u7684\u64cd\u4f5c\u4efb\u52a1\u7684\u9c81\u68d2\u7a7a\u95f4\u6cdb\u5316\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u6846\u67b6\u5728\u9489\u5b50\u63d2\u5165\u5b54\uff08PiH\uff09\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u63a5\u8fd1\u5b8c\u7f8e\u7684\u6210\u529f\u7387\uff0c\u5e76\u80fd\u6cdb\u5316\u5230\u672a\u89c1\u7684\u7a7a\u95f4\u914d\u7f6e\u3002"}}
{"id": "2507.10876", "categories": ["quant-ph", "eess.SP"], "pdf": "https://arxiv.org/pdf/2507.10876", "abs": "https://arxiv.org/abs/2507.10876", "authors": ["Makoto Takagi", "Ryuji Kokubo", "Misato Kurosawa", "Tsubasa Ikami", "Yasuhiro Egami", "Hiroki Nagai", "Takahiro Kashikawa", "Koichi Kimura", "Yutaka Takita", "Yu Matsuda"], "title": "Time-series forecasting for nonlinear high-dimensional system using hybrid method combining autoencoder and multi-parallelized quantum long short-term memory and gated recurrent unit", "comment": null, "summary": "A time-series forecasting method for high-dimensional spatial data is\nproposed. The method involves optimal selection of sparse sensor positions to\nefficiently represent the spatial domain, time-series forecasting at these\npositions, and estimation of the entire spatial distribution from the\nforecasted values via a learned decoder. Sensor positions are selected using a\nmethod based on combinatorial optimization. Introducing multi-parallelized\nquantum long short-term memory (MP-QLSTM) and gated recurrent unit (MP-QGRU)\nimproves time-series forecasting performance by extending QLSTM models using\nthe same number of variational quantum circuits (VQCs) as the cell state\ndimensions. Unlike the original QLSTM, our method fully measures all qubits in\neach VQC, maximizing the representation capacity. MP-QLSTM and MP-QGRU achieve\napproximately 1.5% lower test loss than classical LSTM and GRU. The root mean\nsquared percentage error of MP-QLSTM is 0.256% against the values measured\nindependently using semiconductor pressure sensors, demonstrating the method's\naccuracy and effectiveness for high-dimensional forecasting tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u91cf\u5b50\u8ba1\u7b97\u7684\u9ad8\u7ef4\u7a7a\u95f4\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u4f20\u611f\u5668\u5e03\u5c40\u548c\u6539\u8fdb\u91cf\u5b50LSTM/GRU\u6a21\u578b\uff0c\u63d0\u9ad8\u4e86\u9884\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u9ad8\u7ef4\u7a7a\u95f4\u6570\u636e\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u95ee\u9898\uff0c\u5e76\u63d0\u9ad8\u9884\u6d4b\u6548\u7387\u548c\u7cbe\u5ea6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u7ef4\u7a7a\u95f4\u6570\u636e\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\uff0c\u5305\u62ec\uff1a1. \u5229\u7528\u7ec4\u5408\u4f18\u5316\u65b9\u6cd5\u9009\u62e9\u7a00\u758f\u4f20\u611f\u5668\u6700\u4f18\u4f4d\u7f6e\u30022. \u5728\u9009\u5b9a\u4f4d\u7f6e\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u30023. \u901a\u8fc7\u5b66\u4e60\u5230\u7684\u89e3\u7801\u5668\u4ece\u9884\u6d4b\u503c\u4f30\u8ba1\u6574\u4e2a\u7a7a\u95f4\u5206\u5e03\u3002\u5f15\u5165\u4e86\u591a\u5e76\u884c\u91cf\u5b50\u957f\u77ed\u671f\u8bb0\u5fc6\uff08MP-QLSTM\uff09\u548c\u95e8\u63a7\u5faa\u73af\u5355\u5143\uff08MP-QGRU\uff09\u6765\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002", "result": "MP-QLSTM\u548cMP-QGRU\u76f8\u6bd4\u4e8e\u7ecf\u5178LSTM\u548cGRU\uff0c\u6d4b\u8bd5\u635f\u5931\u964d\u4f4e\u4e86\u7ea61.5%\u3002MP-QLSTM\u7684\u5747\u65b9\u6839\u767e\u5206\u6bd4\u8bef\u5dee\u4e3a0.256%\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u51c6\u786e\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u9ad8\u7ef4\u7a7a\u95f4\u6570\u636e\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\uff0c\u5e76\u4e14\u5728\u9884\u6d4b\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u4f20\u7edf\u7684LSTM\u548cGRU\u6a21\u578b\u3002"}}
{"id": "2507.11239", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.11239", "abs": "https://arxiv.org/abs/2507.11239", "authors": ["Michaela Janovsk\u00e1", "Petr Sedl\u00e1k", "Martin \u0160ev\u010d\u00edk", "Jan Cizek", "Jan Kondas", "Reeti Singh", "Jan \u010cupera", "Hanu\u0161 Seiner"], "title": "Magneto-elastic softening in cold-sprayed polycrystalline nickel studied by resonant ultrasound spectroscopy", "comment": "Manuscript accepted to the Journal of the Acoustical Society of\n  America", "summary": "Cold-sprayed metallic deposits are additively manufactured materials\ncontaining high levels of compressive residual stress. Here we show that the\npresence and intensity of this stress can be analyzed using laser-ultrasonics,\nprovided that the sprayed material is ferromagnetic and magnetostrictive, as in\nthe case of pure nickel. Contactless resonant ultrasound spectroscopy is used\nto monitor the evolution of shear modulus and internal friction parameter of\ntwo polycrystalline Ni deposits with temperature over the Curie point, which\nenables a direct assessment of the strength of magneto-elastic softening that\nis known to be strongly stress-dependent. In addition, the proposed methodology\nis also shown to be suitable for in-situ observation of the recrystallization\nprocess in the vicinity of the Curie point, as well as inspecting the\nhomogeneity of the residual stress level across the thickness of the\ncold-sprayed deposit. Finally, a methodology for room-temperature probing of\nthe magnetoelastic coupling is proposed and tested on the examined materials.", "AI": {"tldr": "\u6fc0\u5149\u8d85\u58f0\u53ef\u7528\u4e8e\u5206\u6790\u7eaf\u954d\u51b7\u55b7\u6d82\u6c89\u79ef\u7269\u7684\u6b8b\u4f59\u5e94\u529b\uff0c\u5e76\u80fd\u76d1\u6d4b\u9000\u706b\u548c\u5e94\u529b\u5747\u5300\u6027\u3002", "motivation": "\u4e3a\u4e86\u5206\u6790\u51b7\u55b7\u6d82\u91d1\u5c5e\u6c89\u79ef\u7269\u4e2d\u9ad8\u542b\u91cf\u7684\u538b\u7f29\u6b8b\u4f59\u5e94\u529b\uff0c\u5e76\u63a2\u7d22\u4e00\u79cd\u53ef\u884c\u7684\u65e0\u635f\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u9488\u5bf9\u7eaf\u954d\u7b49\u94c1\u78c1\u6027\u548c\u78c1\u81f4\u4f38\u7f29\u6750\u6599\u3002", "method": "\u91c7\u7528\u6fc0\u5149\u8d85\u58f0\u6280\u672f\uff0c\u901a\u8fc7\u63a5\u89e6\u5f0f\u5171\u632f\u8d85\u58f0\u5149\u8c31\u6cd5\u76d1\u6d4b\u7eaf\u954d\u6c89\u79ef\u7269\u5728\u5c45\u91cc\u70b9\u6e29\u5ea6\u4e0b\u7684\u526a\u5207\u6a21\u91cf\u548c\u5185\u90e8\u6469\u64e6\u53c2\u6570\uff0c\u4ee5\u8bc4\u4f30\u78c1\u5f39\u6027\u8f6f\u5316\u5f3a\u5ea6\u3002\u540c\u65f6\uff0c\u8be5\u65b9\u6cd5\u4e5f\u7528\u4e8e\u539f\u4f4d\u89c2\u5bdf\u9000\u706b\u8fc7\u7a0b\u548c\u68c0\u6d4b\u6b8b\u4f59\u5e94\u529b\u5747\u5300\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u5ba4\u6e29\u4e0b\u78c1\u5f39\u6027\u8026\u5408\u63a2\u6d4b\u7684\u65b9\u6cd5\u3002", "result": "\u6fc0\u5149\u8d85\u58f0\u6280\u672f\u80fd\u591f\u6709\u6548\u5206\u6790\u7eaf\u954d\u51b7\u55b7\u6d82\u6c89\u79ef\u7269\u7684\u6b8b\u4f59\u5e94\u529b\u3002\u8be5\u65b9\u6cd5\u53ef\u4ee5\u76d1\u6d4b\u6750\u6599\u5728\u5c45\u91cc\u70b9\u6e29\u5ea6\u4e0b\u7684\u78c1\u5f39\u6027\u8f6f\u5316\uff0c\u539f\u4f4d\u89c2\u5bdf\u9000\u706b\u8fc7\u7a0b\uff0c\u5e76\u68c0\u6d4b\u6b8b\u4f59\u5e94\u529b\u5728\u539a\u5ea6\u65b9\u5411\u7684\u5747\u5300\u6027\u3002\u540c\u65f6\uff0c\u63d0\u51fa\u7684\u5ba4\u6e29\u63a2\u6d4b\u65b9\u6cd5\u4e5f\u5bf9\u6240\u6d4b\u6750\u6599\u8fdb\u884c\u4e86\u6d4b\u8bd5\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u6fc0\u5149\u8d85\u58f0\u65b9\u6cd5\u53ef\u7528\u4e8e\u5206\u6790\u51b7\u55b7\u6d82\u91d1\u5c5e\u6c89\u79ef\u7269\u7684\u6b8b\u4f59\u5e94\u529b\uff0c\u7279\u522b\u662f\u94c1\u78c1\u6027\u548c\u78c1\u81f4\u4f38\u7f29\u6750\u6599\uff08\u5982\u7eaf\u954d\uff09\u3002\u8be5\u65b9\u6cd5\u53ef\u5728\u5c45\u91cc\u70b9\u6e29\u5ea6\u4e0b\u76d1\u6d4b\u6750\u6599\u7684\u526a\u5207\u6a21\u91cf\u548c\u5185\u90e8\u6469\u64e6\u53c2\u6570\uff0c\u4ece\u800c\u8bc4\u4f30\u78c1\u5f39\u6027\u8f6f\u5316\u5f3a\u5ea6\uff0c\u5e76\u80fd\u539f\u4f4d\u89c2\u5bdf\u9000\u706b\u8fc7\u7a0b\u548c\u68c0\u6d4b\u6c89\u79ef\u7269\u539a\u5ea6\u65b9\u5411\u7684\u6b8b\u4f59\u5e94\u529b\u5747\u5300\u6027\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u5e76\u6d4b\u8bd5\u4e86\u4e00\u79cd\u7528\u4e8e\u5ba4\u6e29\u4e0b\u78c1\u5f39\u6027\u8026\u5408\u63a2\u6d4b\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.10930", "categories": ["cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2507.10930", "abs": "https://arxiv.org/abs/2507.10930", "authors": ["A. Kudlis", "V. Shahnazaryan", "I. V. Tokatly"], "title": "Polarons in two-dimensional polar materials: All-coupling variational theory", "comment": null, "summary": "We present a detailed and self-contained theoretical study of polarons in\ntwo-dimensional (2D) polar materials, which extends the classical macroscopic\ntheory of Fr\\\"ohlich polarons to the 2D case. The theory is fully determined by\nexperimentally accessible parameters, the static and optical 2D\npolarizabilities of a monolayer, the frequency of transverse optical phonons,\nand the effective mass of charge carriers. We define a single dimensionless\nparameter, which characterizes the coupling of electrons with longitudinal\noptical phonons, analyze both weak- and strong-coupling regimes, and adopt the\nFeynman variational path-integral approach for a high-quality interpolation\nbetween these limits. Our results provide insight into the ground-state energy\nand effective mass of polarons in the new generation of 2D polar monolayers.", "AI": {"tldr": "A theoretical study of polarons in 2D materials using experimentally accessible parameters and Feynman's approach, analyzing coupling regimes to understand polaron properties.", "motivation": "The motivation is to provide a detailed theoretical study of polarons in 2D polar materials, extending existing theories to this new class of materials.", "method": "The paper extends the classical Fr\"ohlich polaron theory to 2D materials. It defines a dimensionless parameter to characterize electron-phonon coupling and uses the Feynman variational path-integral approach to analyze both weak and strong coupling regimes.", "result": "The theoretical framework is determined by experimentally accessible parameters and analyzes both weak and strong coupling regimes, offering insights into polaron properties in 2D materials.", "conclusion": "The study provides insights into the ground-state energy and effective mass of polarons in 2D polar monolayers, based on a theoretical framework derived from experimentally accessible parameters."}}
{"id": "2507.10777", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.10777", "abs": "https://arxiv.org/abs/2507.10777", "authors": ["Sam Alterman", "Peter J. Love"], "title": "Entanglement and magic on the light-front", "comment": "7 pages, 1 figure", "summary": "In the light-front (LF) formulation of quantum field theory (QFT), physics is\nformulated from the perspective of a massless observer necessarily traveling at\nthe speed of light. The LF formulation provides an alternative computational\napproach to lattice gauge theory, and has recently been investigated as a\nfuture application of quantum computers. A natural question is how quantum\nresources such as entanglement and contextuality amongst physical qubits in the\nlaboratory are utilized in LF simulations of QFTs. We use the (1+1)D\ntransverse-field Ising model to explore this question. We derive the LF energy\noperator that generates the LF dynamics of the system, which is distinct from\nthe instant-form (IF) Hamiltonian. We find that while the eigenstates of the IF\nHamiltonian exhibit pairwise entanglement between positive and negative momenta\nin IF momentum-space, the eigenstates of the LF Hamiltonian are separable in LF\nmomentum-space. We then calculate the momentum-space magic of the\nIF-momentum-space ground state and show that it always requires more magic to\nprepare than the LF-momentum-space ground state. At the quantum critical point,\ncorresponding to a massless free fermion, both LF and IF ground states are\nstabilizers, but the LF ground state is separable in LF momentum-space while\nthe IF ground state is a product of maximally entangled pairs in IF\nmomentum-space. These results show that quantum resources such as entanglement\nand magic are utilized differently by quantum simulations formulated in LF and\nIF, and that the simplicity of the LF ground state results in fewer required\nquantum resources.", "AI": {"tldr": "LF\u548cIF\u5f62\u5f0f\u4e0b\u7684\u91cf\u5b50\u6a21\u62df\u5229\u7528\u4e86\u4e0d\u540c\u7684\u91cf\u5b50\u8d44\u6e90\uff0cLF\u6240\u9700\u7684\u8d44\u6e90\u66f4\u5c11\u3002", "motivation": "\u5728\u91cf\u5b50\u573a\u8bba\uff08QFT\uff09\u7684\u8f7b\u524d\u6cbf\uff08LF\uff09\u8868\u8ff0\u4e2d\uff0c\u7269\u7406\u5b66\u662f\u4ece\u5fc5\u7136\u4ee5\u5149\u901f\u884c\u8fdb\u7684\u65e0\u8d28\u91cf\u89c2\u5bdf\u8005\u7684\u89d2\u5ea6\u6765\u8868\u8ff0\u7684\u3002LF\u8868\u8ff0\u4e3a\u683c\u70b9\u89c4\u8303\u7406\u8bba\u63d0\u4f9b\u4e86\u4e00\u79cd\u8ba1\u7b97\u65b9\u6cd5\uff0c\u5e76\u88ab\u7814\u7a76\u4f5c\u4e3a\u91cf\u5b50\u8ba1\u7b97\u673a\u7684\u4e00\u4e2a\u672a\u6765\u5e94\u7528\u3002\u4e00\u4e2a\u81ea\u7136\u7684\u95ee\u9898\u662f\uff0c\u5b9e\u9a8c\u5ba4\u4e2d\u7269\u7406\u91cf\u5b50\u6bd4\u7279\u7684\u7ea0\u7f20\u548c\u8bed\u5883\u6027\u7b49\u91cf\u5b50\u8d44\u6e90\u5982\u4f55\u5728QFT\u7684LF\u6a21\u62df\u4e2d\u88ab\u5229\u7528\u3002", "method": "\u672c\u7814\u7a76\u4f7f\u7528\uff081+1\uff09\u7ef4\u6a2a\u5411\u573a\u4f0a\u8f9b\u6a21\u578b\u6765\u63a2\u7d22\u8fd9\u4e2a\u95ee\u9898\uff0c\u5e76\u63a8\u5bfc\u4e86LF\u80fd\u91cf\u7b97\u7b26\u3002", "result": "LF\u54c8\u5bc6\u987f\u91cf\u7684\u672c\u5f81\u6001\u5728LF\u52a8\u91cf\u7a7a\u95f4\u4e2d\u662f\u53ef\u5206\u79bb\u7684\uff0c\u800cIF\u54c8\u5bc6\u987f\u91cf\u7684\u672c\u5f81\u6001\u5728IF\u52a8\u91cf\u7a7a\u95f4\u4e2d\u8868\u73b0\u51fa\u6210\u5bf9\u7684\u7ea0\u7f20\u3002LF\u57fa\u7840\u6001\u6bd4IF\u57fa\u7840\u6001\u9700\u8981\u66f4\u5c11\u7684\u52a8\u91cf\u7a7a\u95f4\u9b54\u529b\u3002\u5728\u91cf\u5b50\u4e34\u754c\u70b9\uff0cLF\u57fa\u7840\u6001\u662f\u7a33\u5b9a\u5b50\uff0c\u5e76\u4e14\u5728LF\u52a8\u91cf\u7a7a\u95f4\u4e2d\u662f\u53ef\u5206\u79bb\u7684\uff0c\u800cIF\u57fa\u7840\u6001\u662fIF\u52a8\u91cf\u7a7a\u95f4\u4e2d\u6700\u5927\u7ea0\u7f20\u5bf9\u7684\u4e58\u79ef\u3002", "conclusion": "LF\u548cIF\u5f62\u5f0f\u4e0b\u7684\u91cf\u5b50\u6a21\u62df\u5229\u7528\u4e86\u4e0d\u540c\u7684\u91cf\u5b50\u8d44\u6e90\uff08\u4f8b\u5982\u7ea0\u7f20\u548c\u9b54\u529b\uff09\uff0c\u5e76\u4e14LF\u57fa\u7840\u6001\u7684\u7b80\u6d01\u6027\u6240\u9700\u7684\u91cf\u5b50\u8d44\u6e90\u66f4\u5c11\u3002"}}
{"id": "2507.10893", "categories": ["cs.CV", "cs.AI", "cs.LG", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2507.10893", "abs": "https://arxiv.org/abs/2507.10893", "authors": ["Minjong Cheon", "Eunhan Goo", "Su-Hyeon Shin", "Muhammad Ahmed", "Hyungjun Kim"], "title": "Modernizing CNN-based Weather Forecast Model towards Higher Computational Efficiency", "comment": "26pages, 9 Figures", "summary": "Recently, AI-based weather forecast models have achieved impressive advances.\nThese models have reached accuracy levels comparable to traditional NWP\nsystems, marking a significant milestone in data-driven weather prediction.\nHowever, they mostly leverage Transformer-based architectures, which often\nleads to high training complexity and resource demands due to the massive\nparameter sizes. In this study, we introduce a modernized CNN-based model for\nglobal weather forecasting that delivers competitive accuracy while\nsignificantly reducing computational requirements. To present a systematic\nmodernization roadmap, we highlight key architectural enhancements across\nmultiple design scales from an earlier CNN-based approach. KAI-a incorporates a\nscale-invariant architecture and InceptionNeXt-based blocks within a\ngeophysically-aware design, tailored to the structure of Earth system data.\nTrained on the ERA5 daily dataset with 67 atmospheric variables, the model\ncontains about 7 million parameters and completes training in just 12 hours on\na single NVIDIA L40s GPU. Our evaluation shows that KAI-a matches the\nperformance of state-of-the-art models in medium-range weather forecasting,\nwhile offering a significantly lightweight design. Furthermore, case studies on\nthe 2018 European heatwave and the East Asian summer monsoon demonstrate\nKAI-a's robust skill in capturing extreme events, reinforcing its practical\nutility.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684CNN\u5929\u6c14\u9884\u62a5\u6a21\u578bKAI-a\uff0c\u5b83\u6bd4Transformer\u6a21\u578b\u66f4\u8f7b\u4fbf\u3001\u8bad\u7ec3\u66f4\u5feb\uff0c\u540c\u65f6\u8fbe\u5230\u4e86\u76f8\u4f3c\u7684\u51c6\u786e\u6027\uff0c\u5e76\u80fd\u5f88\u597d\u5730\u9884\u6d4b\u6781\u7aef\u5929\u6c14\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u76ee\u524d\u57fa\u4e8eTransformer\u7684\u5929\u6c14\u9884\u62a5\u6a21\u578b\u6240\u9762\u4e34\u7684\u8bad\u7ec3\u590d\u6742\u5ea6\u548c\u9ad8\u8d44\u6e90\u9700\u6c42\u95ee\u9898\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u8fbe\u5230\u540c\u7b49\u9884\u6d4b\u7cbe\u5ea6\u4f46\u8ba1\u7b97\u9700\u6c42\u663e\u8457\u964d\u4f4e\u7684CNN\u6a21\u578b\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u73b0\u4ee3\u5316\u7684\u3001\u57fa\u4e8e\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u7684\u5168\u7403\u5929\u6c14\u9884\u62a5\u6a21\u578bKAI-a\u3002\u8be5\u6a21\u578b\u91c7\u7528\u4e86\u5c3a\u5ea6\u4e0d\u53d8\u67b6\u6784\u548cInceptionNeXt\u5757\uff0c\u5e76\u7ed3\u5408\u4e86\u5730\u7406\u7269\u7406\u611f\u77e5\u8bbe\u8ba1\uff0c\u4ee5\u9002\u5e94\u5730\u7403\u7cfb\u7edf\u6570\u636e\u7684\u7ed3\u6784\u3002KAI-a \u6a21\u578b\u62e5\u6709\u7ea6700\u4e07\u4e2a\u53c2\u6570\uff0c\u5728\u5355\u5757NVIDIA L40s GPU\u4e0a\u4ec5\u970012\u5c0f\u65f6\u5373\u53ef\u5b8c\u6210\u8bad\u7ec3\u3002", "result": "KAI-a \u6a21\u578b\u5728\u4f20\u7edf\u7684\u6570\u503c\u5929\u6c14\u9884\u62a5\uff08NWP\uff09\u7cfb\u7edf\u65b9\u9762\u8fbe\u5230\u4e86\u53ef\u6bd4\u7684\u51c6\u786e\u6027\u6c34\u5e73\uff0c\u4e0e\u76ee\u524d\u6700\u5148\u8fdb\u7684\u6a21\u578b\u5728\u4e2d\u671f\u5929\u6c14\u9884\u62a5\u65b9\u9762\u6027\u80fd\u76f8\u5f53\uff0c\u4f46\u5176\u8bbe\u8ba1\u66f4\u4e3a\u8f7b\u91cf\u7ea7\u3002\u6b64\u5916\uff0c\u57282018\u5e74\u6b27\u6d32\u70ed\u6d6a\u548c\u4e1c\u4e9a\u590f\u5b63\u98ce\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0cKAI-a \u8bc1\u660e\u4e86\u5176\u5728\u6355\u6349\u6781\u7aef\u5929\u6c14\u4e8b\u4ef6\u65b9\u9762\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "KAI-a \u6a21\u578b\u5728\u4fdd\u6301\u4e0e\u6700\u5148\u8fdb\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u9700\u6c42\uff0c\u5c55\u793a\u4e86\u5176\u5728\u6355\u6349\u6781\u7aef\u4e8b\u4ef6\u65b9\u9762\u7684\u5f3a\u5927\u80fd\u529b\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.10831", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10831", "abs": "https://arxiv.org/abs/2507.10831", "authors": ["Yilin Xia", "Heng Zheng", "Shawn Bowers", "Bertram Lud\u00e4scher"], "title": "AF-XRAY: Visual Explanation and Resolution of Ambiguity in Legal Argumentation Frameworks", "comment": "International Conference on Artificial Intelligence and Law (ICAIL),\n  June 16-20, 2025. Chicago, IL, USA", "summary": "Argumentation frameworks (AFs) provide formal approaches for legal reasoning,\nbut identifying sources of ambiguity and explaining argument acceptance remains\nchallenging for non-experts. We present AF-XRAY, an open-source toolkit for\nexploring, analyzing, and visualizing abstract AFs in legal reasoning. AF-XRAY\nintroduces: (i) layered visualizations based on game-theoretic argument length\nrevealing well-founded derivation structures; (ii) classification of attack\nedges by semantic roles (primary, secondary, blunders); (iii) overlay\nvisualizations of alternative 2-valued solutions on ambiguous 3-valued grounded\nsemantics; and (iv) identification of critical attack sets whose suspension\nresolves undecided arguments. Through systematic generation of critical attack\nsets, AF-XRAY transforms ambiguous scenarios into grounded solutions, enabling\nusers to pinpoint specific causes of ambiguity and explore alternative\nresolutions. We use real-world legal cases (e.g., Wild Animals as modeled by\nBench-Capon) to show that our tool supports teleological legal reasoning by\nrevealing how different assumptions lead to different justified conclusions.", "AI": {"tldr": "AF-XRAY \u662f\u4e00\u4e2a\u5f00\u6e90\u5de5\u5177\u5305\uff0c\u7528\u4e8e\u63a2\u7d22\u3001\u5206\u6790\u548c\u53ef\u89c6\u5316\u6cd5\u5f8b\u63a8\u7406\u4e2d\u7684\u62bd\u8c61\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u53ef\u89c6\u5316\u3001\u653b\u51fb\u8fb9\u5206\u7c7b\u3001\u66ff\u4ee3\u8bed\u4e49\u53e0\u52a0\u548c\u5173\u952e\u653b\u51fb\u96c6\u8bc6\u522b\u6765\u89e3\u51b3\u6b67\u4e49\u548c\u89e3\u91ca\u8bba\u70b9\u53ef\u63a5\u53d7\u6027\u95ee\u9898\u3002", "motivation": "\u4e3a\u4e86\u5e94\u5bf9\u975e\u4e13\u5bb6\u5728\u6cd5\u5f8b\u63a8\u7406\u4e2d\u8bc6\u522b\u6b67\u4e49\u6765\u6e90\u548c\u89e3\u91ca\u8bba\u70b9\u53ef\u63a5\u53d7\u6027\u7684\u6311\u6218\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 AF-XRAY \u5de5\u5177\u5305\u3002", "method": "AF-XRAY \u5de5\u5177\u5305\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u8fdb\u884c\u5206\u6790\uff1a(i) \u57fa\u4e8e\u535a\u5f08\u8bba\u8bba\u70b9\u957f\u5ea6\u7684\u5206\u5c42\u53ef\u89c6\u5316\uff0c\u63ed\u793a\u6709\u6839\u636e\u7684\u63a8\u5bfc\u7ed3\u6784\uff1b(ii) \u6309\u8bed\u4e49\u89d2\u8272\uff08\u4e3b\u8981\u3001\u6b21\u8981\u3001\u5931\u8bef\uff09\u5bf9\u653b\u51fb\u8fb9\u8fdb\u884c\u5206\u7c7b\uff1b(iii) \u5728\u6a21\u7cca\u7684\u4e09\u503c\u57fa\u672c\u8bed\u4e49\u4e0a\u53e0\u52a0\u66ff\u4ee3\u7684\u4e24\u503c\u89e3\u7684\u53ef\u89c6\u5316\uff1b(iv) \u8bc6\u522b\u53ef\u60ac\u6302\u4ee5\u89e3\u51b3\u672a\u5b9a\u8bba\u70b9\u7684\u5173\u952e\u653b\u51fb\u96c6\u3002", "result": "\u901a\u8fc7\u7cfb\u7edf\u751f\u6210\u5173\u952e\u653b\u51fb\u96c6\uff0cAF-XRAY \u5c06\u6a21\u7cca\u573a\u666f\u8f6c\u5316\u4e3a\u53ef\u89e3\u91ca\u7684\u7ed3\u8bba\uff0c\u4f7f\u7528\u6237\u80fd\u591f\u7cbe\u786e\u627e\u51fa\u6b67\u4e49\u7684\u5177\u4f53\u539f\u56e0\u5e76\u63a2\u7d22\u66ff\u4ee3\u89e3\u51b3\u65b9\u6848\u3002\u6211\u4eec\u4f7f\u7528\u5b9e\u9645\u6cd5\u5f8b\u6848\u4f8b\uff08\u4f8b\u5982\uff0cBench-Capon \u5efa\u6a21\u7684\u201c\u91ce\u751f\u52a8\u7269\u201d\u6848\u4f8b\uff09\u8bc1\u660e\uff0c\u6211\u4eec\u7684\u5de5\u5177\u901a\u8fc7\u63ed\u793a\u4e0d\u540c\u5047\u8bbe\u5982\u4f55\u5bfc\u81f4\u4e0d\u540c\u7684\u65e2\u5b9a\u7ed3\u8bba\uff0c\u652f\u6301\u76ee\u7684\u8bba\u7684\u6cd5\u5f8b\u63a8\u7406\u3002", "conclusion": "AF-XRAY \u80fd\u591f\u5e2e\u52a9\u7528\u6237\u8bc6\u522b\u6cd5\u5f8b\u63a8\u7406\u4e2d\u7684\u6b67\u4e49\u6765\u6e90\u5e76\u89e3\u91ca\u8bba\u70b9\u53ef\u63a5\u53d7\u6027\uff0c\u5176\u901a\u8fc7\u5206\u5c42\u53ef\u89c6\u5316\u3001\u653b\u51fb\u8fb9\u5206\u7c7b\u3001\u66ff\u4ee3\u8bed\u4e49\u53ef\u89c6\u5316\u4ee5\u53ca\u5173\u952e\u653b\u51fb\u96c6\u8bc6\u522b\u7b49\u529f\u80fd\uff0c\u5c06\u6a21\u7cca\u573a\u666f\u8f6c\u5316\u4e3a\u53ef\u89e3\u91ca\u7684\u7ed3\u8bba\u3002"}}
{"id": "2507.10852", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.10852", "abs": "https://arxiv.org/abs/2507.10852", "authors": ["Yiran Hu", "Zongyue Xue", "Haitao Li", "Siyuan Zheng", "Qingjing Chen", "Shaochun Wang", "Xihan Zhang", "Ning Zheng", "Yun Liu", "Qingyao Ai", "Yiqun Liu", "Charles L. A. Clarke", "Weixing Shen"], "title": "LLMs on Trial: Evaluating Judicial Fairness for Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) are increasingly used in high-stakes fields\nwhere their decisions impact rights and equity. However, LLMs' judicial\nfairness and implications for social justice remain underexplored. When LLMs\nact as judges, the ability to fairly resolve judicial issues is a prerequisite\nto ensure their trustworthiness. Based on theories of judicial fairness, we\nconstruct a comprehensive framework to measure LLM fairness, leading to a\nselection of 65 labels and 161 corresponding values. Applying this framework to\nthe judicial system, we compile an extensive dataset, JudiFair, comprising\n177,100 unique case facts. To achieve robust statistical inference, we develop\nthree evaluation metrics, inconsistency, bias, and imbalanced inaccuracy, and\nintroduce a method to assess the overall fairness of multiple LLMs across\nvarious labels. Through experiments with 16 LLMs, we uncover pervasive\ninconsistency, bias, and imbalanced inaccuracy across models, underscoring\nsevere LLM judicial unfairness. Particularly, LLMs display notably more\npronounced biases on demographic labels, with slightly less bias on substance\nlabels compared to procedure ones. Interestingly, increased inconsistency\ncorrelates with reduced biases, but more accurate predictions exacerbate\nbiases. While we find that adjusting the temperature parameter can influence\nLLM fairness, model size, release date, and country of origin do not exhibit\nsignificant effects on judicial fairness. Accordingly, we introduce a publicly\navailable toolkit containing all datasets and code, designed to support future\nresearch in evaluating and improving LLM fairness.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u53f8\u6cd5\u9886\u57df\u7684\u516c\u5e73\u6027\uff0c\u53d1\u73b0\u73b0\u6709LLM\u666e\u904d\u5b58\u5728\u4e0d\u516c\u5e73\u73b0\u8c61\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u5957\u8bc4\u4f30\u6846\u67b6\u548c\u6307\u6807\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u548c\u6539\u8fdb\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "motivation": "LLM\u8d8a\u6765\u8d8a\u591a\u5730\u5e94\u7528\u4e8e\u9ad8\u98ce\u9669\u9886\u57df\uff0c\u5176\u53f8\u6cd5\u516c\u5e73\u6027\u548c\u5bf9\u793e\u4f1a\u516c\u6b63\u7684\u6f5c\u5728\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\uff0c\u800cLLM\u4f5c\u4e3a\u6cd5\u5b98\u65f6\uff0c\u516c\u5e73\u89e3\u51b3\u53f8\u6cd5\u95ee\u9898\u7684\u80fd\u529b\u662f\u786e\u4fdd\u5176\u53ef\u4fe1\u5ea6\u7684\u5148\u51b3\u6761\u4ef6\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u5305\u542b65\u4e2a\u6807\u7b7e\u548c161\u4e2a\u503c\u7684\u7efc\u5408\u6846\u67b6\u6765\u8861\u91cfLLM\u7684\u53f8\u6cd5\u516c\u5e73\u6027\uff0c\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b177,100\u4e2a\u6848\u4f8b\u4e8b\u5b9e\u7684\u6570\u636e\u96c6JudiFair\u3002\u5f00\u53d1\u4e86\u4e00\u81f4\u6027\u3001\u504f\u89c1\u548c\u4e0d\u5e73\u8861\u51c6\u786e\u6027\u4e09\u4e2a\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u8bc4\u4f30\u591a\u4e2aLLM\u5728\u5404\u79cd\u6807\u7b7e\u4e0a\u6574\u4f53\u516c\u5e73\u6027\u7684\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u5bf916\u4e2aLLM\u7684\u5b9e\u9a8c\uff0c\u53d1\u73b0LLM\u5728\u53f8\u6cd5\u9886\u57df\u5b58\u5728\u666e\u904d\u7684\u4e0d\u4e00\u81f4\u6027\u3001\u504f\u89c1\u548c\u4e0d\u5e73\u8861\u7684\u51c6\u786e\u6027\u3002\u4eba\u53e3\u7edf\u8ba1\u5b66\u6807\u7b7e\u4e0a\u7684\u504f\u89c1\u6bd4\u7a0b\u5e8f\u6027\u6807\u7b7e\u4e0a\u7684\u504f\u89c1\u66f4\u660e\u663e\u3002\u4e0d\u4e00\u81f4\u6027\u589e\u52a0\u4e0e\u504f\u89c1\u51cf\u5c11\u76f8\u5173\uff0c\u4f46\u51c6\u786e\u6027\u63d0\u9ad8\u4f1a\u52a0\u5267\u504f\u89c1\u3002\u8c03\u6574\u6e29\u5ea6\u53c2\u6570\u4f1a\u5f71\u54cdLLM\u516c\u5e73\u6027\uff0c\u4f46\u6a21\u578b\u5927\u5c0f\u3001\u53d1\u5e03\u65e5\u671f\u548c\u6765\u6e90\u56fd\u5bf9\u53f8\u6cd5\u516c\u5e73\u6027\u65e0\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "LLM\u5728\u53f8\u6cd5\u9886\u57df\u5b58\u5728\u666e\u904d\u7684\u4e0d\u516c\u5e73\u73b0\u8c61\uff0c\u5177\u4f53\u8868\u73b0\u5728\u4e0d\u4e00\u81f4\u6027\u3001\u504f\u89c1\u548c\u4e0d\u5e73\u8861\u7684\u51c6\u786e\u6027\u65b9\u9762\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u4eba\u53e3\u7edf\u8ba1\u5b66\u6807\u7b7e\u65f6\u504f\u89c1\u66f4\u4e3a\u660e\u663e\u3002"}}
{"id": "2507.11471", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2507.11471", "abs": "https://arxiv.org/abs/2507.11471", "authors": ["Harsha Varun Marisetty", "Manik Gupta", "Yogesh Simmhan"], "title": "D3FL: Data Distribution and Detrending for Robust Federated Learning in Non-linear Time-series Data", "comment": "Preprint of paper to appear in the proceedings of IEEE INTERNATIONAL\n  CONFERENCE ON EDGE COMPUTING & COMMUNICATIONS EDGE 2025", "summary": "With advancements in computing and communication technologies, the Internet\nof Things (IoT) has seen significant growth. IoT devices typically collect data\nfrom various sensors, such as temperature, humidity, and energy meters. Much of\nthis data is temporal in nature. Traditionally, data from IoT devices is\ncentralized for analysis, but this approach introduces delays and increased\ncommunication costs. Federated learning (FL) has emerged as an effective\nalternative, allowing for model training across distributed devices without the\nneed to centralize data. In many applications, such as smart home energy and\nenvironmental monitoring, the data collected by IoT devices across different\nlocations can exhibit significant variation in trends and seasonal patterns.\nAccurately forecasting such non-stationary, non-linear time-series data is\ncrucial for applications like energy consumption estimation and weather\nforecasting. However, these data variations can severely impact prediction\naccuracy. The key contributions of this paper are: (1) Investigating how\nnon-linear, non-stationary time-series data distributions, like generalized\nextreme value (gen-extreme) and log norm distributions, affect FL performance.\n(2) Analyzing how different detrending techniques for non-linear time-series\ndata influence the forecasting model's performance in a FL setup. We generated\nseveral synthetic time-series datasets using non-linear data distributions and\ntrained an LSTM-based forecasting model using both centralized and FL\napproaches. Additionally, we evaluated the impact of detrending on real-world\ndatasets with non-linear time-series data distributions. Our experimental\nresults show that: (1) FL performs worse than centralized approaches when\ndealing with non-linear data distributions. (2) The use of appropriate\ndetrending techniques improves FL performance, reducing loss across different\ndata distributions.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u8054\u90a6\u5b66\u4e60\u5728\u5904\u7406\u975e\u7ebf\u6027\u3001\u975e\u5e73\u7a33\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u65f6\u7684\u6027\u80fd\u3002\u7814\u7a76\u53d1\u73b0\uff0cFL\u5728\u5904\u7406\u6b64\u7c7b\u6570\u636e\u65f6\u4e0d\u5982\u96c6\u4e2d\u5f0f\u65b9\u6cd5\uff0c\u4f46\u901a\u8fc7\u4f7f\u7528\u8d8b\u52bf\u5254\u9664\u6280\u672f\u53ef\u4ee5\u63d0\u9ad8\u5176\u6027\u80fd\u3002", "motivation": "\u7269\u8054\u7f51\uff08IoT\uff09\u8bbe\u5907\u4ea7\u751f\u5927\u91cf\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u8fd9\u4e9b\u6570\u636e\u901a\u5e38\u5177\u6709\u975e\u7ebf\u6027\u548c\u975e\u5e73\u7a33\u6027\uff0c\u8fd9\u5bf9\u9884\u6d4b\u7cbe\u5ea6\u63d0\u51fa\u4e86\u6311\u6218\u3002\u4f20\u7edf\u7684\u96c6\u4e2d\u5f0f\u6570\u636e\u5206\u6790\u65b9\u6cd5\u5b58\u5728\u5ef6\u8fdf\u548c\u901a\u4fe1\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u4f5c\u4e3a\u4e00\u79cd\u5206\u5e03\u5f0f\u5b66\u4e60\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u4e0d\u96c6\u4e2d\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff0c\u4f46\u5176\u5728\u5904\u7406\u5177\u6709\u663e\u8457\u5dee\u5f02\u7684\u5206\u5e03\u5f0f\u6570\u636e\u65f6\u6027\u80fd\u4f1a\u53d7\u5230\u5f71\u54cd\u3002", "method": "\u672c\u6587\u7814\u7a76\u4e86\u975e\u7ebf\u6027\u3001\u975e\u5e73\u7a33\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5206\u5e03\uff08\u5982\u5e7f\u4e49\u6781\u503c\u5206\u5e03\u548c\u5bf9\u6570\u6b63\u6001\u5206\u5e03\uff09\u5bf9\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u5206\u6790\u4e86\u4e0d\u540c\u7684\u8d8b\u52bf\u5254\u9664\u6280\u672f\u5bf9FL\u8bbe\u7f6e\u4e0b\u9884\u6d4b\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002\u901a\u8fc7\u751f\u6210\u5408\u6210\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u548c\u4f7f\u7528\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\uff0c\u5e76\u8bad\u7ec3LSTM\u9884\u6d4b\u6a21\u578b\uff0c\u5728\u96c6\u4e2d\u5f0f\u548cFL\u65b9\u6cd5\u4e0b\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\uff081\uff09\u5728\u5904\u7406\u975e\u7ebf\u6027\u6570\u636e\u5206\u5e03\u65f6\uff0cFL\u7684\u6027\u80fd\u52a3\u4e8e\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u3002\uff082\uff09\u4f7f\u7528\u9002\u5f53\u7684\u8d8b\u52bf\u5254\u9664\u6280\u672f\u80fd\u591f\u6539\u5584FL\u7684\u6027\u80fd\uff0c\u5e76\u964d\u4f4e\u4e0d\u540c\u6570\u636e\u5206\u5e03\u4e0b\u7684\u635f\u5931\u3002", "conclusion": "\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u5728\u5904\u7406\u975e\u7ebf\u6027\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5206\u5e03\u65f6\uff0c\u5176\u6027\u80fd\u4e0d\u5982\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u91c7\u7528\u9002\u5f53\u7684\u8d8b\u52bf\u5254\u9664\u6280\u672f\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8FL\u5728\u4e0d\u540c\u6570\u636e\u5206\u5e03\u4e0b\u7684\u6027\u80fd\uff0c\u51cf\u5c11\u635f\u5931\u3002"}}
{"id": "2507.11311", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2507.11311", "abs": "https://arxiv.org/abs/2507.11311", "authors": ["Yasushi Kawase", "Kazuhisa Makino", "Vinh Long Phan", "Hanna Sumita"], "title": "Scheduling on Identical Machines with Setup Time and Unknown Execution Time", "comment": "Accepted to the 19th Algorithms and Data Structures Symposium (WADS\n  2025)", "summary": "In this study, we investigate a scheduling problem on identical machines in\nwhich jobs require initial setup before execution. We assume that an algorithm\ncan dynamically form a batch (i.e., a collection of jobs to be processed\ntogether) from the remaining jobs. The setup time is modeled as a known\nmonotone function of the set of jobs within a batch, while the execution time\nof each job remains unknown until completion. This uncertainty poses\nsignificant challenges for minimizing the makespan. We address these challenges\nby considering two scenarios: each job batch must be assigned to a single\nmachine, or a batch may be distributed across multiple machines. For both\nscenarios, we analyze settings with and without preemption. Across these four\nsettings, we design online algorithms that achieve asymptotically optimal\ncompetitive ratios with respect to both the number of jobs and the number of\nmachines.", "AI": {"tldr": "\u8be5\u7814\u7a76\u89e3\u51b3\u4e86\u5177\u6709\u8bbe\u7f6e\u65f6\u95f4\u548c\u672a\u77e5\u6267\u884c\u65f6\u95f4\u7684\u4f5c\u4e1a\u8c03\u5ea6\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u5728\u7ebf\u7b97\u6cd5\uff0c\u5e76\u5728\u4e0d\u540c\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u4e86\u6e10\u8fd1\u6700\u4f18\u7684\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5728\u5177\u6709\u8bbe\u7f6e\u65f6\u95f4\u548c\u672a\u77e5\u6267\u884c\u65f6\u95f4\u7684\u4f5c\u4e1a\u8c03\u5ea6\u95ee\u9898\u4e2d\u6700\u5c0f\u5316\u6700\u5927\u5b8c\u5de5\u65f6\u95f4\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u7814\u7a76\u8bbe\u8ba1\u4e86\u5728\u7ebf\u7b97\u6cd5\u6765\u89e3\u51b3\u5728\u76f8\u540c\u7684\u673a\u5668\u4e0a\u8fdb\u884c\u4f5c\u4e1a\u8c03\u5ea6\u7684\u95ee\u9898\uff0c\u5176\u4e2d\u4f5c\u4e1a\u9700\u8981\u5728\u6267\u884c\u524d\u8fdb\u884c\u521d\u59cb\u8bbe\u7f6e\u3002\u8bbe\u7f6e\u65f6\u95f4\u662f\u6279\u6b21\u5185\u4f5c\u4e1a\u96c6\u7684\u5355\u8c03\u51fd\u6570\uff0c\u800c\u4f5c\u4e1a\u7684\u6267\u884c\u65f6\u95f4\u5728\u5b8c\u6210\u524d\u662f\u672a\u77e5\u7684\u3002\u7814\u7a76\u8003\u8651\u4e86\u4e24\u79cd\u60c5\u51b5\uff1a\u6279\u6b21\u5206\u914d\u5230\u5355\u4e2a\u673a\u5668\u6216\u591a\u4e2a\u673a\u5668\uff0c\u5e76\u5206\u6790\u4e86\u5141\u8bb8\u6216\u4e0d\u5141\u8bb8\u62a2\u5360\u7684\u60c5\u51b5\u3002", "result": "\u7814\u7a76\u4e2d\u7684\u5728\u7ebf\u7b97\u6cd5\u5728\u6240\u6709\u56db\u79cd\u8003\u8651\u7684\u573a\u666f\uff08\u6279\u6b21\u5206\u914d\u5230\u5355\u4e2a\u673a\u5668\u6216\u591a\u4e2a\u673a\u5668\uff0c\u5141\u8bb8\u6216\u4e0d\u5141\u8bb8\u62a2\u5360\uff09\u4e2d\uff0c\u9488\u5bf9\u4f5c\u4e1a\u6570\u91cf\u548c\u673a\u5668\u6570\u91cf\u90fd\u5b9e\u73b0\u4e86\u6e10\u8fd1\u6700\u4f18\u7684\u7ade\u4e89\u6bd4\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5728\u5177\u6709\u8bbe\u7f6e\u65f6\u95f4\u548c\u672a\u77e5\u6267\u884c\u65f6\u95f4\u7684\u4f5c\u4e1a\u8c03\u5ea6\u95ee\u9898\u8bbe\u8ba1\u4e86\u5728\u7ebf\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4e86\u6e10\u8fd1\u6700\u4f18\u7684\u7ade\u4e89\u6bd4\u3002"}}
{"id": "2507.10968", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.10968", "abs": "https://arxiv.org/abs/2507.10968", "authors": ["Toktam Mohammadnejad", "Jovin D'sa", "Behdad Chalaki", "Hossein Nourkhiz Mahjoub", "Ehsan Moradi-Pari"], "title": "SMART-Merge Planner: A Safe Merging and Real-Time Motion Planner for Autonomous Highway On-Ramp Merging", "comment": "Accepted at IEEE ITSC 2025", "summary": "Merging onto a highway is a complex driving task that requires identifying a\nsafe gap, adjusting speed, often interactions to create a merging gap, and\ncompleting the merge maneuver within a limited time window while maintaining\nsafety and driving comfort. In this paper, we introduce a Safe Merging and\nReal-Time Merge (SMART-Merge) planner, a lattice-based motion planner designed\nto facilitate safe and comfortable forced merging. By deliberately adapting\ncost terms to the unique challenges of forced merging and introducing a desired\nspeed heuristic, SMART-Merge planner enables the ego vehicle to merge\nsuccessfully while minimizing the merge time. We verify the efficiency and\neffectiveness of the proposed merge planner through high-fidelity CarMaker\nsimulations on hundreds of highway merge scenarios. Our proposed planner\nachieves the success rate of 100% as well as completes the merge maneuver in\nthe shortest amount of time compared with the baselines, demonstrating our\nplanner's capability to handle complex forced merge tasks and provide a\nreliable and robust solution for autonomous highway merge. The simulation\nresult videos are available at\nhttps://sites.google.com/view/smart-merge-planner/home.", "AI": {"tldr": "SMART-Merge\uff1a\u4e00\u79cd\u7528\u4e8e\u5b89\u5168\u8212\u9002\u9ad8\u901f\u516c\u8def\u5f3a\u5236\u5408\u6d41\u7684\u8fd0\u52a8\u89c4\u5212\u5668\uff0c\u6a21\u62df\u7ed3\u679c\u663e\u793a\u6210\u529f\u7387 100%\uff0c\u5408\u5e76\u65f6\u95f4\u77ed\u3002", "motivation": "\u89e3\u51b3\u9ad8\u901f\u516c\u8def\u5408\u6d41\uff08\u5c24\u5176\u662f\u5f3a\u5236\u5408\u6d41\uff09\u7684\u590d\u6742\u6027\uff0c\u8be5\u4efb\u52a1\u8981\u6c42\u5728\u6709\u9650\u7684\u65f6\u95f4\u5185\u5b89\u5168\u8212\u9002\u5730\u5b8c\u6210\u53d8\u9053\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u683c\u70b9\uff08lattice-based\uff09\u7684\u8fd0\u52a8\u89c4\u5212\u5668 SMART-Merge\uff0c\u901a\u8fc7\u8c03\u6574\u6210\u672c\u9879\u548c\u5f15\u5165\u671f\u671b\u901f\u5ea6\u542f\u53d1\u5f0f\u65b9\u6cd5\u6765\u4f18\u5316\u5f3a\u5236\u5408\u6d41\u8fc7\u7a0b\u3002", "result": "\u5728 CarMaker \u9ad8\u4fdd\u771f\u6a21\u62df\u4e2d\uff0cSMART-Merge \u89c4\u5212\u5668\u5728\u6570\u767e\u4e2a\u9ad8\u901f\u516c\u8def\u5408\u6d41\u573a\u666f\u4e0b\u5b9e\u73b0\u4e86 100% \u7684\u6210\u529f\u7387\uff0c\u5e76\u663e\u8457\u7f29\u77ed\u4e86\u5408\u5e76\u65f6\u95f4\uff0c\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "SMART-Merge \u89c4\u5212\u5668\u5728\u590d\u6742\u5f3a\u5236\u5408\u6d41\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa 100% \u7684\u6210\u529f\u7387\uff0c\u5e76\u4e14\u5408\u5e76\u65f6\u95f4\u6700\u77ed\uff0c\u8bc1\u660e\u4e86\u5176\u53ef\u9760\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2507.10614", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10614", "abs": "https://arxiv.org/abs/2507.10614", "authors": ["Fei Liu", "Rui Zhang", "Xi Lin", "Zhichao Lu", "Qingfu Zhang"], "title": "Fine-tuning Large Language Model for Automated Algorithm Design", "comment": null, "summary": "The integration of large language models (LLMs) into automated algorithm\ndesign has shown promising potential. A prevalent approach embeds LLMs within\nsearch routines to iteratively generate and refine candidate algorithms.\nHowever, most existing methods rely on off-the-shelf LLMs trained for general\ncoding tasks,leaving a key question open: Do we need LLMs specifically tailored\nfor algorithm design? If so, how can such LLMs be effectively obtained and how\nwell can they generalize across different algorithm design tasks? In this\npaper, we take a first step toward answering these questions by exploring\nfine-tuning of LLMs for algorithm design. We introduce a Diversity-Aware Rank\nbased (DAR) sampling strategy to balance training data diversity and quality,\nthen we leverage direct preference optimization to efficiently align LLM\noutputs with task objectives. Our experiments, conducted on\nLlama-3.2-1B-Instruct and Llama- 3.1-8B-Instruct, span three distinct algorithm\ndesign tasks. Results suggest that finetuned LLMs can significantly outperform\ntheir off-the-shelf counterparts with the smaller Llama-3.2-1B-Instruct and\nmatch the larger Llama-3.1-8B-Instruct on the admissible set problem. Moreover,\nwe observe promising generalization: LLMs finetuned on specific algorithm\ndesign tasks also improve performance on related tasks with varying settings.\nThese findings highlight the value of task-specific adaptation for LLMs in\nalgorithm design and open new avenues for future research.", "AI": {"tldr": "\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\u4ee5\u9002\u5e94\u7b97\u6cd5\u8bbe\u8ba1\u4efb\u52a1\uff0c\u6548\u679c\u4f18\u4e8e\u901a\u7528\u6a21\u578b\uff0c\u5e76\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u6027\u3002", "motivation": "\u8be5\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u5728\u7b97\u6cd5\u8bbe\u8ba1\u4e2d\u662f\u5426\u9700\u8981\u4e13\u95e8\u4e3a\u8be5\u4efb\u52a1\u8bad\u7ec3\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u4ee5\u53ca\u5982\u4f55\u6709\u6548\u83b7\u53d6\u548c\u8bc4\u4f30\u8fd9\u7c7b\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u7684\u95ee\u9898\u3002", "method": "\u672c\u7814\u7a76\u63a2\u7d22\u4e86\u9488\u5bf9\u7b97\u6cd5\u8bbe\u8ba1\u4efb\u52a1\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u3002\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u79cd\u201c\u591a\u6837\u6027\u611f\u77e5\u6392\u5e8f\u91c7\u6837\u201d\uff08DAR\uff09\u7b56\u7565\uff0c\u4ee5\u5e73\u8861\u8bad\u7ec3\u6570\u636e\u7684\u591a\u6837\u6027\u548c\u8d28\u91cf\uff0c\u5e76\u5229\u7528\u201c\u76f4\u63a5\u504f\u597d\u4f18\u5316\u201d\uff08DPO\uff09\u6280\u672f\u6765\u9ad8\u6548\u5730\u4f7f\u8bed\u8a00\u6a21\u578b\u7684\u8f93\u51fa\u4e0e\u4efb\u52a1\u76ee\u6807\u4fdd\u6301\u4e00\u81f4\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u7ecf\u8fc7\u5fae\u8c03\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u5373\u4f7f\u662f\u8f83\u5c0f\u7684\u6a21\u578b\uff08\u5982 Llama-3.2-1B-Instruct\uff09\uff0c\u5728\u7279\u5b9a\u7b97\u6cd5\u8bbe\u8ba1\u4efb\u52a1\uff08\u5982\u5bb9\u8bb8\u96c6\u95ee\u9898\uff09\u4e0a\u7684\u8868\u73b0\u4e5f\u663e\u8457\u4f18\u4e8e\u5176\u901a\u7528\u7248\u672c\uff1b\u540c\u65f6\uff0c\u8f83\u5927\u7684\u6a21\u578b\uff08\u5982 Llama-3.1-8B-Instruct\uff09\u5728\u7ecf\u8fc7\u5fae\u8c03\u540e\u80fd\u8fbe\u5230\u751a\u81f3\u8d85\u8fc7\u901a\u7528\u7248\u672c\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u89c2\u5bdf\u5230\uff0c\u5728\u7279\u5b9a\u7b97\u6cd5\u8bbe\u8ba1\u4efb\u52a1\u4e0a\u5fae\u8c03\u8fc7\u7684\u6a21\u578b\uff0c\u5728\u8bbe\u7f6e\u4e0d\u540c\u7684\u76f8\u5173\u4efb\u52a1\u4e0a\u4e5f\u8868\u73b0\u51fa\u4ee4\u4eba\u9f13\u821e\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u5fae\u8c03\u540e\u7684\u8bed\u8a00\u6a21\u578b\u5728\u7b97\u6cd5\u8bbe\u8ba1\u4efb\u52a1\u4e0a\u80fd\u591f\u663e\u8457\u4f18\u4e8e\u6216\u5339\u654c\u901a\u7528\u6a21\u578b\uff0c\u5e76\u4e14\u5728\u76f8\u5173\u4efb\u52a1\u4e0a\u5c55\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u8fd9\u8868\u660e\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\u8fdb\u884c\u8c03\u6574\u5bf9\u4e8e\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u5728\u7b97\u6cd5\u8bbe\u8ba1\u4e2d\u7684\u8868\u73b0\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.10895", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2507.10895", "abs": "https://arxiv.org/abs/2507.10895", "authors": ["Xiaocong Zeng", "Craig Michoski", "Yan Pang", "Dongyang Kuang"], "title": "Commuting Distance Regularization for Timescale-Dependent Label Inconsistency in EEG Emotion Recognition", "comment": null, "summary": "In this work, we address the often-overlooked issue of Timescale Dependent\nLabel Inconsistency (TsDLI) in training neural network models for EEG-based\nhuman emotion recognition. To mitigate TsDLI and enhance model generalization\nand explainability, we propose two novel regularization strategies: Local\nVariation Loss (LVL) and Local-Global Consistency Loss (LGCL). Both methods\nincorporate classical mathematical principles--specifically, functions of\nbounded variation and commute-time distances--within a graph theoretic\nframework. Complementing our regularizers, we introduce a suite of new\nevaluation metrics that better capture the alignment between temporally local\npredictions and their associated global emotion labels. We validate our\napproach through comprehensive experiments on two widely used EEG emotion\ndatasets, DREAMER and DEAP, across a range of neural architectures including\nLSTM and transformer-based models. Performance is assessed using five distinct\nmetrics encompassing both quantitative accuracy and qualitative consistency.\nResults consistently show that our proposed methods outperform state-of-the-art\nbaselines, delivering superior aggregate performance and offering a principled\ntrade-off between interpretability and predictive power under label\ninconsistency. Notably, LVL achieves the best aggregate rank across all\nbenchmarked backbones and metrics, while LGCL frequently ranks the second,\nhighlighting the effectiveness of our framework.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.11300", "categories": ["cond-mat.mtrl-sci", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2507.11300", "abs": "https://arxiv.org/abs/2507.11300", "authors": ["Prakriti Kayastha", "Erik Fransson", "Paul Erhart", "Lucy Whalley"], "title": "Diverse polymorphism in Ruddlesden-Popper chalcogenides", "comment": null, "summary": "Ruddlesden-Popper (RP) chalcogenides are stable, non-toxic candidates for\noptoelectronic or thermoelectric applications. The structural diversity of RP\noxides is already exploited to tune properties or achieve more advanced\nfunctionalities like multiferroicity, however, little is known about the\nstructural evolution of RP chalcogenides. In this work, we develop a\nhigh-accuracy machine-learned interatomic potential to run large-scale\nmolecular dynamics simulations on $Ba_{n+1}Zr_nS_{3n+1}$ for $n=1$ to $n=6$. We\npredict new polymorphs for each $n$-value, calculate their corresponding phase\ntransition temperatures, and validate our approach through comparison to\npublished experimental results. We find that the $n=1$ phase exhibits negative\nthermal expansion, that $n=1$ and $n=3$ undergo unusual ascending symmetry\nbreaking, and that phases with $n\\geq4$ form layer-dependent tilt patterns\npreviously unreported for inorganic RP materials. This unique behaviour results\nfrom competition between octahedral rotations and rumpling at the rocksalt\ninterface, and suggests new strategies for accessing advanced functionalities.", "AI": {"tldr": "RP\u786b\u5c5e\u5316\u5408\u7269\u7684\u7ed3\u6784\u6f14\u53d8", "motivation": "RP\u6c27\u5316\u7269\u7684\u7ed3\u6784\u591a\u6837\u6027\u5df2\u88ab\u7528\u4e8e\u8c03\u8282\u6027\u8d28\u6216\u5b9e\u73b0\u591a\u94c1\u6027\u7b49\u9ad8\u7ea7\u529f\u80fd\uff0c\u4f46\u5bf9RP\u786b\u5c5e\u5316\u5408\u7269\u7684\u7ed3\u6784\u6f14\u53d8\u77e5\u4e4b\u751a\u5c11\u3002", "method": "\u5f00\u53d1\u9ad8\u7cbe\u5ea6\u673a\u5668\u5b66\u4e60\u539f\u5b50\u95f4\u52bf\uff0c\u5bf9 Ba$_{n+1}$Zr$_n$S$_{3n+1}$\uff08n=1\u81f36\uff09\u8fdb\u884c\u5927\u89c4\u6a21\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u3002", "result": "\u9884\u6d4b\u4e86\u6bcf\u4e2an\u503c\u7684\u65b0\u591a\u6676\u578b\u7269\uff0c\u8ba1\u7b97\u4e86\u5b83\u4eec\u76f8\u5e94\u7684\u76f8\u53d8\u6e29\u5ea6\uff0c\u5e76\u901a\u8fc7\u4e0e\u5df2\u53d1\u8868\u7684\u5b9e\u9a8c\u7ed3\u679c\u8fdb\u884c\u6bd4\u8f83\u6765\u9a8c\u8bc1\u4e86\u6211\u4eec [\u7684\u65b9\u6cd5]\u3002\u6211\u4eec\u53d1\u73b0n=1\u76f8\u8868\u73b0\u51fa\u8d1f\u70ed\u81a8\u80c0\uff0cn=1\u548cn=3\u7ecf\u5386\u4e86\u4e0d\u5bfb\u5e38\u7684\u5347\u5e8f\u5bf9\u79f0\u6027\u7834\u7f3a\uff0cn\u22654\u7684\u76f8\u5f62\u6210\u4e86\u5c42\u4f9d\u8d56\u6027\u503e\u659c\u6a21\u5f0f\u3002", "conclusion": "RP\u786b\u5c5e\u5316\u5408\u7269\u7684\u7ed3\u6784\u6f14\u53d8\u63ed\u793a\u4e86\u4e0e\u65e0\u673aRP\u6750\u6599\u524d\u6240\u672a\u89c1\u7684\u5c42\u4f9d\u8d56\u6027\u503e\u659c\u6a21\u5f0f\uff0c\u8fd9\u6e90\u4e8e\u516b\u9762\u4f53\u65cb\u8f6c\u548c\u5ca9\u76d0\u754c\u9762\u4e4b\u95f4 the \u5d0e\u5c96\u4e0d\u5e73\u7684\u7ade\u4e89\uff0c\u5e76\u63d0\u51fa\u4e86\u5b9e\u73b0\u9ad8\u7ea7\u529f\u80fd\u7684\u65b0\u7b56\u7565\u3002"}}
{"id": "2507.11039", "categories": ["cond-mat.mes-hall", "quant-ph"], "pdf": "https://arxiv.org/pdf/2507.11039", "abs": "https://arxiv.org/abs/2507.11039", "authors": ["Maximilian Nitsch", "Viktor Svensson", "William Samuelson", "Konstantin Nestmann", "Jeroen Danon", "Karsten Flensberg", "Rub\u00e9n Seoane Souto", "Martin Leijnse"], "title": "Adiabatic nonabelian braiding of imperfect Majoranas", "comment": "5 pages, 3 Figures + 7 pages, 2 Figures in the Supplementary\n  Information", "summary": "Demonstration of a nontrivial result of quasiparticle exchange (or braiding)\nis usually considered the definitive proof of a topological phase with\nnonabelian excitations, such as Majorana bound states (MBSs). However, in\nfinite systems with disorder and smooth potential variations, the MBSs are\nimperfect in the sense that they are not fully isolated in space and can, to a\nvarying degree, resemble conventional fermions. Here, we study the braiding\nproperties of isolated MBSs, regular fermions, and anything in between. We find\na way to compensate for the undesired splitting of the ground-state degeneracy\nwhich occurs during the protocol for imperfect MBS. This leads to a braiding\noutcome that depends on the degree of MBS isolation but remains robust and\nnonabelian except in the perfect fermion limit. Our protocol could be\nimplemented in different platforms with nonabelian excitations, including\nquantum-dot-based minimal Kitaev chains.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u4e0d\u5b8c\u7f8eMBS\u7cfb\u7edf\u4e2d\u8fdb\u884c\u9c81\u68d2\u975e\u963f\u8d1d\u5c14\u7f16\u7ec7\u7684\u65b0\u65b9\u6cd5\uff0c\u5373\u4f7f\u5728MBS\u4e0d\u5b8c\u5168\u9694\u79bb\u7684\u60c5\u51b5\u4e0b\u4e5f\u9002\u7528\u3002", "motivation": "\u5728\u5177\u6709\u6563\u5c04\u548c\u5149\u6ed1\u52bf\u80fd\u53d8\u5316\u7684\u6709\u9650\u7cfb\u7edf\u4e2d\uff0cMBS\u5e76\u4e0d\u5b8c\u7f8e\uff0c\u53ef\u80fd\u7c7b\u4f3c\u4e8e\u5e38\u89c4\u8d39\u7c73\u5b50\uff0c\u800c\u901a\u5e38\u8ba4\u4e3a\u51c6\u7c92\u5b50\u4ea4\u6362\uff08\u6216\u7f16\u7ec7\uff09\u662f\u62d3\u6251\u76f8\u7684\u660e\u786e\u8bc1\u636e\u3002", "method": "\u7814\u7a76\u4e86\u9694\u79bbMBS\u3001\u5e38\u89c4\u8d39\u7c73\u5b50\u4ee5\u53ca\u4ecb\u4e8e\u4e24\u8005\u4e4b\u95f4\u72b6\u6001\u7684\u7f16\u7ec7\u6027\u8d28\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u8865\u507f\u56e0\u4e0d\u5b8c\u7f8eMBS\u7f16\u7ec7\u534f\u8bae\u5f15\u8d77\u7684\u4e0d\u671f\u671b\u7684\u5730\u9762\u6001\u7b80\u5e76\u5206\u88c2\u7684\u65b9\u6cd5\u3002", "result": "\u53d1\u73b0\u6240\u63d0\u51fa\u7684\u7f16\u7ec7\u534f\u8bae\u5728\u4e0d\u5b8c\u7f8eMBS\u7cfb\u7edf\u4e2d\u662f\u9c81\u68d2\u4e14\u975e\u963f\u8d1d\u5c14\u7684\uff0c\u5176\u7ed3\u679c\u53d6\u51b3\u4e8eMBS\u7684\u9694\u79bb\u5ea6\uff0c\u4f46\u5728\u5b8c\u5168\u8d39\u7c73\u5b50\u7684\u60c5\u51b5\u4e0b\u9664\u5916\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u8865\u507f\u4e0d\u5b8c\u7f8eMajorana\u675f\u7f1a\u6001\uff08MBS\uff09\u7cfb\u7edf\u4e2d\u7684\u5730\u9762\u6001\u7b80\u5e76\u5206\u88c2\u7684\u65b9\u6cd5\uff0c\u4f7f\u5f97\u7f16\u7ec7\u7ed3\u679c\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u4f9d\u8d56\u4e8eMBS\u7684\u9694\u79bb\u5ea6\uff0c\u4f46\u53ea\u8981\u4e0d\u662f\u5b8c\u5168\u8d39\u7c73\u5b50\u5316\u7684\u6781\u9650\uff0c\u7ed3\u679c\u4ecd\u7136\u662f\u9c81\u68d2\u4e14\u975e\u963f\u8d1d\u5c14\u7684\u3002"}}
{"id": "2507.10784", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.10784", "abs": "https://arxiv.org/abs/2507.10784", "authors": ["Satoshi Yoshida", "Jisho Miyazaki", "Mio Murao"], "title": "Quantum Advantage in Storage and Retrieval of Isometry Channels", "comment": "5+28 pages, 2 figures", "summary": "Storage and retrieval refer to the task of encoding a quantum channel\n$\\Lambda$ into a quantum state, known as the program state, such that the\nchannel can later be retrieved. This task is closely related to quantum channel\nestimation, where multiple queries to $\\Lambda$ are used to prepare a quantum\nstate $\\phi_\\Lambda$ that encodes information about the channel. The channel\ncan then be retrieved by measuring $\\phi_\\Lambda$, following a\nmeasure-and-prepare strategy. In this work, we analyze the asymptotic\nperformance of the estimation-based strategy for storage and retrieval of\nisometry channels. We show that the optimal fidelity for isometry estimation is\ngiven by $F = 1-{d(D-d)\\over n} + O(n^{-2})$, where $d$ and $D$ denote the\ninput and output dimensions of the isometry, and $n$ is the number of queries.\nThis result indicates that, unlike in the case of unitary channels, the\nestimation-based strategy is suboptimal for the storage and retrieval of\nisometry channels, which requires $n = \\Theta(\\epsilon^{-1})$ to achieve the\ndiamond-norm error $\\epsilon$. To address this limitation, we propose a more\nefficient protocol based on port-based teleportation, which stores the isometry\nchannel in a program state using only $n = \\Theta(1/\\sqrt{\\epsilon})$ queries.\nAs an application, we extend our approach to general quantum channels,\nachieving improved program cost compared to prior results by Gschwedtner,\nBluhm, and Winter [Quantum $\\textbf{5}$, 488 (2021)].", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u57fa\u4e8e\u7aef\u53e3\u8f6c\u79fb\u7684\u534f\u8bae\uff0c\u4ee5\u66f4\u6709\u6548\u5730\u5b58\u50a8\u548c\u68c0\u7d22\u540c\u4f4d\u5f02\u5f62\u901a\u9053\uff0c\u5e76\u5728\u4e00\u822c\u91cf\u5b50\u901a\u9053\u65b9\u9762\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u6027\u80fd\u3002", "motivation": "\u8be5\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u5206\u6790\u57fa\u4e8e\u4f30\u8ba1\u7684\u7b56\u7565\u5728\u540c\u4f4d\u5f02\u5f62\u901a\u9053\u5b58\u50a8\u548c\u68c0\u7d22\u65b9\u9762\u7684\u6e10\u8fd1\u6027\u80fd\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u534f\u8bae\u6765\u514b\u670d\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "method": "\u8be5\u7814\u7a76\u5206\u6790\u4e86\u57fa\u4e8e\u4f30\u8ba1\u7684\u7b56\u7565\u5728\u540c\u4f4d\u5f02\u5f62\u901a\u9053\u5b58\u50a8\u548c\u68c0\u7d22\u65b9\u9762\u7684\u6e10\u8fd1\u6027\u80fd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7aef\u53e3\u8f6c\u79fb\u7684\u66f4\u9ad8\u6548\u534f\u8bae\u3002", "result": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u540c\u4f4d\u5f02\u5f62\u901a\u9053\u4f30\u8ba1\u7684\u6700\u4f73\u4fdd\u771f\u5ea6\u4e3a$F = 1-{d(D-d)\boldsymbol{}/\boldsymbol{n}} + O(n^{-2})$\uff0c\u5176\u4e2dd\u548cD\u5206\u522b\u662f\u540c\u4f4d\u5f02\u5f62\u901a\u9053\u7684\u8f93\u5165\u548c\u8f93\u51fa\u7ef4\u5ea6\uff0c$n$\u662f\u67e5\u8be2\u6b21\u6570\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8e\u4f30\u8ba1\u7684\u7b56\u7565\u5bf9\u4e8e\u540c\u4f4d\u5f02\u5f62\uff08isometry\uff09\u901a\u9053\u7684\u5b58\u50a8\u548c\u68c0\u7d22\u6765\u8bf4\u5e76\u975e\u6700\u4f18\uff0c\u56e0\u4e3a\u9700\u8981$n=\boldsymbol{\rm \boldsymbol{\theta}}(\boldsymbol{\bf \boldsymbol{\boldsymbol{\text{1}}}}\boldsymbol{/}\boldsymbol{\bf \boldsymbol{\boldsymbol{\text{ \textbackslash epsilon}}}}}$\u624d\u80fd\u8fbe\u5230$\boldsymbol{\bf \boldsymbol{\boldsymbol{\text{ \textbackslash epsilon}}}}}$\u7684\u94bb\u77f3\u8303\u6570\u8bef\u5dee\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u5c40\u9650\u6027\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7aef\u53e3\u8f6c\u79fb\uff08port-based teleportation\uff09\u7684\u66f4\u9ad8\u6548\u534f\u8bae\uff0c\u4ec5\u7528$n=\boldsymbol{\rm \boldsymbol{\theta}}(\boldsymbol{\bf \boldsymbol{\boldsymbol{\text{1}}}}\boldsymbol{/}\boldsymbol{\bf \boldsymbol{\boldsymbol{\text{ \textbackslash sqrt{\textbackslash epsilon}}}}}})$\u6b21\u67e5\u8be2\u5373\u53ef\u5c06\u540c\u4f4d\u5f02\u5f62\u901a\u9053\u5b58\u50a8\u5728\u7a0b\u5e8f\u72b6\u6001\u4e2d\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u5df2\u88ab\u63a8\u5e7f\u5230\u4e00\u822c\u91cf\u5b50\u901a\u9053\uff0c\u5e76\u5728\u7a0b\u5e8f\u6210\u672c\u65b9\u9762\u4f18\u4e8eGschwedtner\u3001Bluhm\u548cWinter\u7b49\u4eba\u5148\u524d\u7684\u5de5\u4f5c\u3002"}}
{"id": "2507.10894", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10894", "abs": "https://arxiv.org/abs/2507.10894", "authors": ["Zongtao He", "Liuyi Wang", "Lu Chen", "Chengju Liu", "Qijun Chen"], "title": "NavComposer: Composing Language Instructions for Navigation Trajectories through Action-Scene-Object Modularization", "comment": null, "summary": "Language-guided navigation is a cornerstone of embodied AI, enabling agents\nto interpret language instructions and navigate complex environments. However,\nexpert-provided instructions are limited in quantity, while synthesized\nannotations often lack quality, making them insufficient for large-scale\nresearch. To address this, we propose NavComposer, a novel framework for\nautomatically generating high-quality navigation instructions. NavComposer\nexplicitly decomposes semantic entities such as actions, scenes, and objects,\nand recomposes them into natural language instructions. Its modular\narchitecture allows flexible integration of state-of-the-art techniques, while\nthe explicit use of semantic entities enhances both the richness and accuracy\nof instructions. Moreover, it operates in a data-agnostic manner, supporting\nadaptation to diverse navigation trajectories without domain-specific training.\nComplementing NavComposer, we introduce NavInstrCritic, a comprehensive\nannotation-free evaluation system that assesses navigation instructions on\nthree dimensions: contrastive matching, semantic consistency, and linguistic\ndiversity. NavInstrCritic provides a holistic evaluation of instruction\nquality, addressing limitations of traditional metrics that rely heavily on\nexpert annotations. By decoupling instruction generation and evaluation from\nspecific navigation agents, our method enables more scalable and generalizable\nresearch. Extensive experiments provide direct and practical evidence for the\neffectiveness of our method.", "AI": {"tldr": "NavComposer \u548c NavInstrCritic \u6846\u67b6\u81ea\u52a8\u751f\u6210\u548c\u8bc4\u4f30\u5bfc\u822a\u6307\u4ee4\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u6570\u91cf\u548c\u8d28\u91cf\u4e0a\u7684\u4e0d\u8db3\uff0c\u5e76\u652f\u6301\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u3002", "motivation": "\u4e13\u5bb6\u63d0\u4f9b\u7684\u5bfc\u822a\u6307\u4ee4\u6570\u91cf\u6709\u9650\uff0c\u5408\u6210\u7684\u6807\u6ce8\u8d28\u91cf\u4e0d\u9ad8\uff0c\u4e0d\u8db3\u4ee5\u652f\u6301\u5927\u89c4\u6a21\u7814\u7a76\u3002\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u4e13\u5bb6\u6807\u6ce8\uff0c\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faNavComposer\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u5206\u89e3\u548c\u91cd\u7ec4\u8bed\u4e49\u5b9e\u4f53\uff08\u52a8\u4f5c\u3001\u573a\u666f\u3001\u5bf9\u8c61\uff09\u6765\u81ea\u52a8\u751f\u6210\u5bfc\u822a\u6307\u4ee4\uff0c\u5e76\u4ecb\u7ecd\u4e86NavInstrCritic\u8bc4\u4f30\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u4ece\u5bf9\u6bd4\u5339\u914d\u3001\u8bed\u4e49\u4e00\u81f4\u6027\u548c\u8bed\u8a00\u591a\u6837\u6027\u4e09\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u65e0\u6807\u6ce8\u8bc4\u4f30\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4e3a\u53ef\u6269\u5c55\u548c\u53ef\u6cdb\u5316\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u652f\u6301\u3002", "conclusion": "NavComposer\u901a\u8fc7\u660e\u786e\u5206\u89e3\u548c\u91cd\u7ec4\u8bed\u4e49\u5b9e\u4f53\uff08\u5982\u52a8\u4f5c\u3001\u573a\u666f\u548c\u5bf9\u8c61\uff09\u6765\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u5bfc\u822a\u6307\u4ee4\uff0c\u5176\u6a21\u5757\u5316\u67b6\u6784\u53ef\u7075\u6d3b\u96c6\u6210\u6700\u5148\u8fdb\u7684\u6280\u672f\uff0c\u5e76\u589e\u5f3a\u6307\u4ee4\u7684\u4e30\u5bcc\u6027\u548c\u51c6\u786e\u6027\u3002NavInstrCritic\u662f\u4e00\u4e2a\u65e0\u6807\u6ce8\u7684\u8bc4\u4f30\u7cfb\u7edf\uff0c\u4ece\u5bf9\u6bd4\u5339\u914d\u3001\u8bed\u4e49\u4e00\u81f4\u6027\u548c\u8bed\u8a00\u591a\u6837\u6027\u4e09\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\u5bfc\u822a\u6307\u4ee4\u8d28\u91cf\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u4f9d\u8d56\u4e13\u5bb6\u6807\u6ce8\u7684\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5c06\u6307\u4ee4\u751f\u6210\u548c\u8bc4\u4f30\u4e0e\u7279\u5b9a\u5bfc\u822a\u4ee3\u7406\u5206\u79bb\uff0c\u5b9e\u73b0\u4e86\u66f4\u5177\u53ef\u6269\u5c55\u6027\u548c\u901a\u7528\u6027\u7684\u7814\u7a76\u3002"}}
{"id": "2507.10918", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.10918", "abs": "https://arxiv.org/abs/2507.10918", "authors": ["Ikumi Numaya", "Shoji Moriya", "Shiki Sato", "Reina Akama", "Jun Suzuki"], "title": "How Stylistic Similarity Shapes Preferences in Dialogue Dataset with User and Third Party Evaluations", "comment": "Accepted to SIGDIAL 2025 (long)", "summary": "Recent advancements in dialogue generation have broadened the scope of\nhuman-bot interactions, enabling not only contextually appropriate responses\nbut also the analysis of human affect and sensitivity. While prior work has\nsuggested that stylistic similarity between user and system may enhance user\nimpressions, the distinction between subjective and objective similarity is\noften overlooked. To investigate this issue, we introduce a novel dataset that\nincludes users' preferences, subjective stylistic similarity based on users'\nown perceptions, and objective stylistic similarity annotated by third party\nevaluators in open-domain dialogue settings. Analysis using the constructed\ndataset reveals a strong positive correlation between subjective stylistic\nsimilarity and user preference. Furthermore, our analysis suggests an important\nfinding: users' subjective stylistic similarity differs from third party\nobjective similarity. This underscores the importance of distinguishing between\nsubjective and objective evaluations and understanding the distinct aspects\neach captures when analyzing the relationship between stylistic similarity and\nuser preferences. The dataset presented in this paper is available online.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u6784\u5efa\u6570\u636e\u96c6\uff0c\u53d1\u73b0\u7528\u6237\u611f\u77e5\u5230\u7684\u98ce\u683c\u76f8\u4f3c\u6027\u6bd4\u5ba2\u89c2\u6807\u6ce8\u7684\u98ce\u683c\u76f8\u4f3c\u6027\u66f4\u80fd\u5f71\u54cd\u7528\u6237\u504f\u597d\uff0c\u5f3a\u8c03\u4e86\u533a\u5206\u8fd9\u4e24\u8005\u5728\u5bf9\u8bdd\u7cfb\u7edf\u7814\u7a76\u4e2d\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u63a2\u8ba8\u4e86\u7528\u6237\u4e0e\u804a\u5929\u673a\u5668\u4eba\u4e4b\u95f4\u98ce\u683c\u76f8\u4f3c\u6027\u7684\u4e3b\u89c2\u548c\u5ba2\u89c2\u533a\u522b\uff0c\u4ee5\u53ca\u5b83\u4eec\u5bf9\u7528\u6237\u504f\u597d\u7684\u5f71\u54cd\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u7528\u6237\u504f\u597d\u3001\u4e3b\u89c2\u98ce\u683c\u76f8\u4f3c\u6027\u548c\u5ba2\u89c2\u98ce\u683c\u76f8\u4f3c\u6027\uff08\u7531\u7b2c\u4e09\u65b9\u8bc4\u4f30\u8005\u6807\u6ce8\uff09\u7684\u5f00\u653e\u57df\u5bf9\u8bdd\u6570\u636e\u96c6\u3002", "result": "\u4e3b\u89c2\u98ce\u683c\u76f8\u4f3c\u6027\u4e0e\u7528\u6237\u504f\u597d\u4e4b\u95f4\u5b58\u5728\u5f88\u5f3a\u7684\u6b63\u76f8\u5173\u5173\u7cfb\uff0c\u5e76\u4e14\u7528\u6237\u611f\u77e5\u7684\u4e3b\u89c2\u98ce\u683c\u76f8\u4f3c\u6027\u4e0e\u7b2c\u4e09\u65b9\u8bc4\u4f30\u7684\u5ba2\u89c2\u98ce\u683c\u76f8\u4f3c\u6027\u4e0d\u540c\u3002", "conclusion": "\u533a\u5206\u4e3b\u89c2\u548c\u5ba2\u89c2\u98ce\u683c\u76f8\u4f3c\u6027\u5bf9\u4e8e\u7406\u89e3\u7528\u6237\u504f\u597d\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2507.11484", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2507.11484", "abs": "https://arxiv.org/abs/2507.11484", "authors": ["N. Efe \u00c7ekirge", "William Gay", "David P. Woodruff"], "title": "Multipass Linear Sketches for Geometric LP-Type Problems", "comment": "To Appear in APPROX 2025, 45 pages", "summary": "LP-type problems such as the Minimum Enclosing Ball (MEB), Linear Support\nVector Machine (SVM), Linear Programming (LP), and Semidefinite Programming\n(SDP) are fundamental combinatorial optimization problems, with many important\napplications in machine learning applications such as classification,\nbioinformatics, and noisy learning. We study LP-type problems in several\nstreaming and distributed big data models, giving $\\varepsilon$-approximation\nlinear sketching algorithms with a focus on the high accuracy regime with low\ndimensionality $d$, that is, when ${d < (1/\\varepsilon)^{0.999}}$. Our main\nresult is an $O(ds)$ pass algorithm with $O(s( \\sqrt{d}/\\varepsilon)^{3d/s})\n\\cdot \\mathrm{poly}(d, \\log (1/\\varepsilon))$ space complexity in words, for\nany parameter $s \\in [1, d \\log (1/\\varepsilon)]$, to solve\n$\\varepsilon$-approximate LP-type problems of $O(d)$ combinatorial and VC\ndimension. Notably, by taking $s = d \\log (1/\\varepsilon)$, we achieve space\ncomplexity polynomial in $d$ and polylogarithmic in $1/\\varepsilon$, presenting\nexponential improvements in $1/\\varepsilon$ over current algorithms. We\ncomplement our results by showing lower bounds of $(1/\\varepsilon)^{\\Omega(d)}$\nfor any $1$-pass algorithm solving the $(1 + \\varepsilon)$-approximation MEB\nand linear SVM problems, further motivating our multi-pass approach.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8eLP\u7c7b\u578b\u95ee\u9898\u7684\u591a\u901a\u9053\u7ebf\u6027\u8349\u56fe\u7b97\u6cd5\uff0c\u5728\u4f4e\u7ef4\u5ea6\u548c\u9ad8\u7cbe\u5ea6\u4e0b\u5177\u6709\u51fa\u8272\u7684\u6027\u80fd\uff0c\u7a7a\u95f4\u590d\u6742\u5ea6\u76f8\u6bd4\u73b0\u6709\u7b97\u6cd5\u57281/\u03b5\u4e0a\u6709\u6307\u6570\u7ea7\u63d0\u5347\uff0c\u5e76\u8bc1\u660e\u4e86\u5355\u901a\u9053\u7b97\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "LP\u7c7b\u578b\u95ee\u9898\uff08\u5982\u6700\u5c0f\u5305\u56f4\u7403\u3001\u7ebf\u6027\u652f\u6301\u5411\u91cf\u673a\u3001\u7ebf\u6027\u89c4\u5212\u548c\u534a\u5b9a\u89c4\u5212\uff09\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u6709\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u73b0\u6709\u7b97\u6cd5\u5728\u5904\u7406\u6d41\u5f0f\u548c\u5206\u5e03\u5f0f\u5927\u6570\u636e\u6a21\u578b\u65f6\u5b58\u5728\u6548\u7387\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ebf\u6027\u8349\u56fe\u7684$\nu$-\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5177\u6709O(ds)\u901a\u9053\u548cO(s(\u221ad/\u03b5)3d/s)\u00b7poly(d, log(1/\u03b5))\u7684\u7a7a\u95f4\u590d\u6742\u5ea6\uff0c\u9002\u7528\u4e8e\u7ec4\u5408\u7ef4\u5ea6\u548cVC\u7ef4\u5ea6\u4e3aO(d)\u7684LP\u7c7b\u578b\u95ee\u9898\u3002", "result": "\u5728\u4f4e\u7ef4\u5ea6\uff08d < (1/\u03b5)^0.999\uff09\u548c\u9ad8\u7cbe\u5ea6\uff08\u03b5\uff09\u8981\u6c42\u4e0b\uff0c\u5b9e\u73b0\u4e86O(ds)\u901a\u9053\u548cO(s(\u221ad/\u03b5)3d/s)\u00b7poly(d, log(1/\u03b5))\u7a7a\u95f4\u590d\u6742\u5ea6\u7684$\nu$-\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u5e76\u5728\u53c2\u6570s=d log(1/\u03b5)\u65f6\uff0c\u5b9e\u73b0\u4e86\u57281/\u03b5\u4e0a\u7684\u6307\u6570\u7ea7\u6539\u8fdb\u3002\u6b64\u5916\uff0c\u8fd8\u8bc1\u660e\u4e86\u4efb\u4f55\u5355\u901a\u9053\u7b97\u6cd5\u5728\u89e3\u51b3MEB\u548c\u7ebf\u6027SVM\u95ee\u9898\u65f6\uff0c\u81f3\u5c11\u9700\u8981(1/\u03b5)^\u03a9(d)\u7684\u4e0b\u754c\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aLP\u7c7b\u578b\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u6d41\u5f0f\u548c\u5206\u5e03\u5f0f\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5728\u4f4e\u7ef4\u5ea6\u548c\u9ad8\u7cbe\u5ea6\u8981\u6c42\u4e0b\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e14\u901a\u8fc7\u591a\u901a\u9053\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u7b97\u6cd5\u57281/\u03b5\u4e0a\u7684\u6307\u6570\u7ea7\u6539\u8fdb\u3002"}}
{"id": "2507.11211", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.11211", "abs": "https://arxiv.org/abs/2507.11211", "authors": ["Chen Cai", "Ernesto Dickel Saraiva", "Ya-jun Pan", "Steven Liu"], "title": "MPC-based Coarse-to-Fine Motion Planning for Robotic Object Transportation in Cluttered Environments", "comment": "10 pages, 5 figures, submitted to IEEE Robotics and Automation\n  Letters (RA-L)", "summary": "This letter presents a novel coarse-to-fine motion planning framework for\nrobotic manipulation in cluttered, unmodeled environments. The system\nintegrates a dual-camera perception setup with a B-spline-based model\npredictive control (MPC) scheme. Initially, the planner generates feasible\nglobal trajectories from partial and uncertain observations. As new visual data\nare incrementally fused, both the environment model and motion planning are\nprogressively refined. A vision-based cost function promotes target-driven\nexploration, while a refined kernel-perceptron collision detector enables\nefficient constraint updates for real-time planning. The framework accommodates\nclosed-chain kinematics and supports dynamic replanning. Experiments on a\nmulti-arm platform validate its robustness and adaptability under uncertainties\nand clutter.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u673a\u5668\u4eba\u64cd\u4f5c\u8fd0\u52a8\u89c4\u5212\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u53cc\u76ee\u89c6\u89c9\u548cMPC\uff0c\u80fd\u591f\u5b9e\u65f6\u5904\u7406\u6df7\u4e71\u548c\u4e0d\u786e\u5b9a\u7684\u73af\u5883\u3002", "motivation": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5728\u6df7\u4e71\u3001\u672a\u5efa\u6a21\u73af\u5883\u4e2d\u8fdb\u884c\u673a\u5668\u4eba\u64cd\u4f5c\u7684\u65b0\u9896\u7684\u7c97\u5230\u7ec6\u8fd0\u52a8\u89c4\u5212\u6846\u67b6\u3002", "method": "\u8be5\u7cfb\u7edf\u96c6\u6210\u4e86\u53cc\u76ee\u89c6\u89c9\u611f\u77e5\u8bbe\u7f6e\u548c\u57fa\u4e8eB\u6837\u6761\u7684}(\nmodel)\u9884\u6d4b\u63a7\u5236(MPC)\u65b9\u6848\u3002\u5b83\u5229\u7528\u57fa\u4e8e\u89c6\u89c9\u7684\u6210\u672c\u51fd\u6570\u6765\u4fc3\u8fdb\u76ee\u6807\u9a71\u52a8\u7684\u63a2\u7d22\uff0c\u5e76\u91c7\u7528\u6539\u8fdb\u7684\u6838\u611f\u77e5\u5668\u78b0\u649e\u68c0\u6d4b\u5668\u6765\u5b9e\u73b0\u9ad8\u6548\u7684\u7ea6\u675f\u66f4\u65b0\u4ee5\u8fdb\u884c\u5b9e\u65f6\u89c4\u5212\u3002\u8be5\u6846\u67b6\u80fd\u591f\u5904\u7406\u95ed\u94fe\u8fd0\u52a8\u5b66\u5e76\u652f\u6301\u52a8\u6001\u91cd\u89c4\u5212\u3002", "result": "\u8be5\u7cfb\u7edf\u80fd\u591f\u4ece\u90e8\u5206\u548c\u4e0d\u786e\u5b9a\u7684\u89c2\u6d4b\u4e2d\u751f\u6210\u53ef\u884c\u7684\u5168\u5c40\u8f68\u8ff9\uff0c\u5e76\u968f\u7740\u65b0\u7684\u89c6\u89c9\u6570\u636e\u7684\u4e0d\u65ad\u878d\u5408\uff0c\u9010\u6b65\u5b8c\u5584\u73af\u5883\u6a21\u578b\u548c\u8fd0\u52a8\u89c4\u5212\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u591a\u81c2\u5e73\u53f0\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u4e0d\u786e\u5b9a\u6027\u548c\u6df7\u4e71\u73af\u5883\u4e0b\u7684\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2507.10616", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.10616", "abs": "https://arxiv.org/abs/2507.10616", "authors": ["Neel Rajani", "Aryo Pradipta Gema", "Seraphina Goldfarb-Tarrant", "Ivan Titov"], "title": "Scalpel vs. Hammer: GRPO Amplifies Existing Capabilities, SFT Replaces Them", "comment": null, "summary": "Training large language models (LLMs) for reasoning via maths and code\ndatasets has become a major new focus in LLM post-training. Two particularly\npopular approaches are reinforcement learning (RL) and supervised fine-tuning\n(SFT), but their training dynamics are poorly understood. We present a\ncomparative analysis of RL and SFT on the same maths problems with the same\nmodel and similar hyperparameters. We find that RL yields minor in-domain gains\non maths and slight degradation on knowledge-intensive benchmarks like MMLU,\nwhile both trends are more pronounced in SFT. We also analyse model parameters\nacross checkpoints, observing that both algorithms modify query and key weights\nthe most. Meanwhile, SFT exhibits greater updates and also affects mid-layer\nMLPs more, leading us to hypothesise that this may have caused the\nout-of-domain degradation. We therefore investigate whether freezing parts of\nthe model during training can mitigate the reduced performance on\nknowledge-intensive benchmarks. However, our results are inconclusive, with\nbenefits on GPQA:Diamond and degradation on other benchmarks. Taken together,\nour observations provide a preliminary indication for why RL amplifies existing\ncapabilities, while SFT replaces old skills with new ones.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86RL\u548cSFT\u5728LLM\u63a8\u7406\u8bad\u7ec3\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0\u5728\u6570\u5b66\u4efb\u52a1\u4e0aRL\u7565\u6709\u63d0\u5347\uff0cSFT\u63d0\u5347\u66f4\u660e\u663e\u4f46\u4f1a\u635f\u5bb3\u5176\u4ed6\u80fd\u529b\u3002SFT\u7684\u8bad\u7ec3\u8fc7\u7a0b\u5bf9\u6a21\u578b\u53c2\u6570\u7684\u4fee\u6539\u66f4\u5927\uff0c\u53ef\u80fd\u5bfc\u81f4\u4e86\u8fd9\u79cd\u635f\u5bb3\u3002\u901a\u8fc7\u51bb\u7ed3\u6a21\u578b\u90e8\u5206\u8fdb\u884c\u8bad\u7ec3\u7684\u6548\u679c\u4e0d\u786e\u5b9a\u3002", "motivation": "LLM\u901a\u8fc7\u6570\u5b66\u548c\u4ee3\u7801\u6570\u636e\u96c6\u8fdb\u884c\u63a8\u7406\u7684\u8bad\u7ec3\u5df2\u6210\u4e3aLLM\u8bad\u7ec3\u540e\u7684\u4e00\u9879\u4e3b\u8981\u65b0\u7126\u70b9\uff0c\u5176\u4e2dRL\u548cSFT\u662f\u4e24\u79cd\u7279\u522b\u6d41\u884c\u7684\u65b9\u6cd5\uff0c\u4f46\u5b83\u4eec\u7684\u8bad\u7ec3\u52a8\u6001\u77e5\u4e4b\u751a\u5c11\u3002", "method": "\u901a\u8fc7\u5728\u76f8\u540c\u7684\u6570\u5b66\u95ee\u9898\u3001\u76f8\u540c\u7684\u6a21\u578b\u548c\u76f8\u4f3c\u7684\u8d85\u53c2\u6570\u4e0a\u5bf9RL\u548cSFT\u8fdb\u884c\u6bd4\u8f83\u5206\u6790\u3002", "result": "RL\u5728\u6570\u5b66\u65b9\u9762\u5e26\u6765\u4e86\u8f83\u5c0f\u7684\u9886\u57df\u5185\u6536\u76ca\uff0c\u5728MMLU\u7b49\u77e5\u8bc6\u5bc6\u96c6\u578b\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7565\u6709\u4e0b\u964d\uff0c\u800cSFT\u7684\u8fd9\u4e9b\u8d8b\u52bf\u66f4\u4e3a\u660e\u663e\u3002RL\u548cSFT\u90fd\u4e3b\u8981\u4fee\u6539\u4e86\u67e5\u8be2\u548c\u952e\u6743\u91cd\uff0c\u5176\u4e2dSFT\u7684\u66f4\u65b0\u66f4\u5927\uff0c\u5e76\u4e14\u66f4\u591a\u5730\u5f71\u54cd\u4e86\u4e2d\u95f4\u5c42\u7684MLP\u3002\u901a\u8fc7\u51bb\u7ed3\u6a21\u578b\u90e8\u5206\u8fdb\u884c\u8bad\u7ec3\u4ee5\u7f13\u89e3\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u6027\u80fd\u4e0b\u964d\u7684\u7814\u7a76\u7ed3\u679c\u4e0d\u786e\u5b9a\uff0c\u5728GPQA:Diamond\u4e0a\u6709\u6240\u6539\u5584\uff0c\u4f46\u5728\u5176\u4ed6\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u6709\u6240\u4e0b\u964d\u3002", "conclusion": "RL\u653e\u5927\u4e86\u73b0\u6709\u80fd\u529b\uff0c\u800cSFT\u7528\u65b0\u6280\u80fd\u53d6\u4ee3\u4e86\u65e7\u6280\u80fd\u3002"}}
{"id": "2507.10991", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.10991", "abs": "https://arxiv.org/abs/2507.10991", "authors": ["Abhimanyu Bhowmik", "Mohit Singh", "Madhushree Sannigrahi", "Martin Ludvigsen", "Kostas Alexis"], "title": "Uncertainty Aware Mapping for Vision-Based Underwater Robots", "comment": "Presented at the 2025 IEEE ICRA Workshop on Field Robotics", "summary": "Vision-based underwater robots can be useful in inspecting and exploring\nconfined spaces where traditional sensors and preplanned paths cannot be\nfollowed. Sensor noise and situational change can cause significant uncertainty\nin environmental representation. Thus, this paper explores how to represent\nmapping inconsistency in vision-based sensing and incorporate depth estimation\nconfidence into the mapping framework. The scene depth and the confidence are\nestimated using the RAFT-Stereo model and are integrated into a voxel-based\nmapping framework, Voxblox. Improvements in the existing Voxblox weight\ncalculation and update mechanism are also proposed. Finally, a qualitative\nanalysis of the proposed method is performed in a confined pool and in a pier\nin the Trondheim fjord. Experiments using an underwater robot demonstrated the\nchange in uncertainty in the visualization.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u878d\u5408\u6df1\u5ea6\u4f30\u8ba1\u7f6e\u4fe1\u5ea6\u7684\u6c34\u4e0b\u673a\u5668\u4eba\u5efa\u56fe\u65b9\u6cd5\uff0c\u6539\u8fdb\u4e86Voxblox\u7b97\u6cd5\uff0c\u5e76\u5728\u6c34\u4e0b\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u4e0d\u786e\u5b9a\u6027\u8868\u793a\u7684\u6709\u6548\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u6c34\u4e0b\u673a\u5668\u4eba\u5728\u68c0\u67e5\u548c\u63a2\u7d22\u53d7\u9650\u7a7a\u95f4\u65f6\uff0c\u7531\u4e8e\u4f20\u611f\u5668\u566a\u58f0\u548c\u73af\u5883\u53d8\u5316\u5bfc\u81f4\u7684\u73af\u5883\u8868\u793a\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u89c6\u89c9\u611f\u77e5\u4e2d\u7684\u6df1\u5ea6\u4f30\u8ba1\u7f6e\u4fe1\u5ea6\u878d\u5408\u5230\u57fa\u4e8e\u4f53\u7d20\u7684\u5730\u56fe\u6784\u5efa\u6846\u67b6\uff08Voxblox\uff09\u4e2d\u7684\u65b9\u6cd5\uff0c\u5e76\u5bf9Voxblox\u7684\u6743\u91cd\u8ba1\u7b97\u548c\u66f4\u65b0\u673a\u5236\u8fdb\u884c\u4e86\u6539\u8fdb\u3002", "result": "\u5728\u6c34\u6c60\u548c\u5ce1\u6e7e\u7684\u5b9e\u9a8c\u4e2d\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u8868\u793a\u5730\u56fe\u6784\u5efa\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u901a\u8fc7\u6c34\u4e0b\u673a\u5668\u4eba\u5b9e\u9a8c\u5c55\u793a\u4e86\u4e0d\u786e\u5b9a\u6027\u7684\u53d8\u5316\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u878d\u5408\u6df1\u5ea6\u4f30\u8ba1\u7f6e\u4fe1\u5ea6\u5230\u57fa\u4e8e\u4f53\u7d20\u7684\u5730\u56fe\u6784\u5efa\u6846\u67b6\u4e2d\uff0c\u5e76\u6539\u8fdb\u4e86\u73b0\u6709\u7684Voxblox\u6743\u91cd\u8ba1\u7b97\u548c\u66f4\u65b0\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u5728\u5b58\u5728\u4f20\u611f\u5668\u566a\u58f0\u548c\u73af\u5883\u53d8\u5316\u7684\u6c34\u4e0b\u673a\u5668\u4eba\u89c6\u89c9\u611f\u77e5\u548c\u5efa\u56fe\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u8868\u793a\u3002"}}
{"id": "2507.11309", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.11309", "abs": "https://arxiv.org/abs/2507.11309", "authors": ["H. Mager", "M. Litterst", "Sophia Klubertz", "S. V. Haridas", "O. Shyshov", "M. von Delius", "M. Kemerink"], "title": "A supramolecular ferroelectric with two sublattices and polarization dependent conductivity", "comment": null, "summary": "The possibility to combine and finetune properties of functional molecular\nmaterials by chemical design is particularly relevant for organic\nferroelectrics. In this work, we investigate a class of organic molecular\nmaterials that show long-range supramolecular organization into fibrillar\nbundles. In solid state, the material shows ferroelectric behavior resulting\nfrom two largely independent dipolar moieties that show up as two separate\ncoercive fields in polarization-hysteresis and capacitance-voltage curves.\nMoreover, the material shows a long-range electronic conductivity that arises\ndue to oxidation at the positive electrode, followed by electron transfer\nbetween neighboring molecules. We find that this conductivity is modulated by\nthe direction and degree of ferroelectric polarization, which we interpret in\nterms of injection barrier modulation at low electric fields and a recently\ndeveloped framework for asymmetric polaron hopping at high fields. With two\ndistinct, partially independent dipolar moieties offering the possibility to\nuse ferroelectric properties to modulate conductance, the materials presented\nherein are a promising basis for multifunctional materials.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e00\u79cd\u6709\u673a\u5206\u5b50\u6750\u6599\uff0c\u5b83\u5177\u6709\u94c1\u7535\u6027\u548c\u7535\u5b50\u7535\u5bfc\u6027\uff0c\u5e76\u4e14\u8fd9\u4e24\u79cd\u6027\u8d28\u53ef\u4ee5\u901a\u8fc7\u5316\u5b66\u8bbe\u8ba1\u8fdb\u884c\u8c03\u63a7\uff0c\u5728\u591a\u529f\u80fd\u6750\u6599\u9886\u57df\u5177\u6709\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u63a2\u7d22\u6709\u673a\u94c1\u7535\u6750\u6599\u7684\u5316\u5b66\u8bbe\u8ba1\u53ef\u80fd\u6027\uff0c\u4ee5\u671f\u7ed3\u5408\u548c\u5fae\u8c03\u529f\u80fd\u5206\u5b50\u6750\u6599\u7684\u6027\u8d28\uff0c\u5e76\u7814\u7a76\u94c1\u7535\u6781\u5316\u4e0e\u7535\u5b50\u7535\u5bfc\u6027\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u5316\u5b66\u8bbe\u8ba1\uff0c\u7ed3\u5408\u548c\u5fae\u8c03\u4e86\u529f\u80fd\u5206\u5b50\u6750\u6599\u7684\u6027\u8d28\uff0c\u7279\u522b\u662f\u7814\u7a76\u4e86\u4e00\u7c7b\u5177\u6709\u957f\u8ddd\u79bb\u8d85\u5206\u5b50\u7ec4\u7ec7\u6210\u7ea4\u7ef4\u675f\u7684\u6709\u673a\u5206\u5b50\u6750\u6599\u3002\u901a\u8fc7\u6781\u5316-\u6ede\u540e\u548c\u7535\u5bb9-\u7535\u538b\u66f2\u7ebf\uff0c\u7814\u7a76\u4e86\u6750\u6599\u7684\u94c1\u7535\u884c\u4e3a\u548c\u7535\u5b50\u7535\u5bfc\u6027\uff0c\u5e76\u5206\u6790\u4e86\u94c1\u7535\u6781\u5316\u65b9\u5411\u548c\u7a0b\u5ea6\u5bf9\u7535\u5bfc\u7387\u7684\u8c03\u8282\u4f5c\u7528\u3002", "result": "\u6240\u7814\u7a76\u7684\u6750\u6599\u5728\u56fa\u6001\u4e0b\u8868\u73b0\u51fa\u94c1\u7535\u884c\u4e3a\uff0c\u5177\u6709\u4e24\u4e2a\u72ec\u7acb\u7684\u5076\u6781\u5b50\u90e8\u5206\uff0c\u5728\u6781\u5316-\u6ede\u540e\u548c\u7535\u5bb9-\u7535\u538b\u66f2\u7ebf\u4e0a\u8868\u73b0\u4e3a\u4e24\u4e2a\u4e0d\u540c\u7684\u77eb\u987d\u7535\u573a\u3002\u6b64\u5916\uff0c\u6750\u6599\u8fd8\u8868\u73b0\u51fa\u957f\u8ddd\u79bb\u7535\u5b50\u7535\u5bfc\u6027\uff0c\u8be5\u7535\u5bfc\u6027\u53d7\u5230\u94c1\u7535\u6781\u5316\u65b9\u5411\u548c\u7a0b\u5ea6\u7684\u8c03\u8282\u3002", "conclusion": "\u8be5\u6750\u6599\u5177\u6709\u53cc\u91cd\u5076\u6781\u5b50\u90e8\u5206\uff0c\u53ef\u5229\u7528\u94c1\u7535\u7279\u6027\u8c03\u8282\u7535\u5bfc\u7387\uff0c\u662f\u591a\u529f\u80fd\u6750\u6599\u7684\u4f18\u826f\u57fa\u7840\u3002"}}
{"id": "2507.11087", "categories": ["cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2507.11087", "abs": "https://arxiv.org/abs/2507.11087", "authors": ["Josep Planelles", "Juan I. Climente", "Jose L. Movilla"], "title": "Internal dynamics and dielectric screening of confined multiexciton states", "comment": null, "summary": "Recent experimental and computational studies suggest that biexcitons (BX)\nconfined in large CsPbBr$_3$ nanocrystals experience reduced dielectric\nscreening as compared to excitons (X) and trions (X$^*$). Here we provide a\nphysical rationale to explain such a behavior. A characteristic frequency is\nintroduced, which describes the internal dynamics of an exciton within the\nexcitonic complex. By means of effective mass--variational Quantum Monte Carlo\nsimulations, we show that, in large nanocrystals, the frequency is similar for\nX and X$^*$, but smaller for BX. Because the frequencies exceed that of the\nbulk longitudinal optical phonon, this leads to a reduced dielectric constant\nfor BX, which is in contrast with the behavior of strongly confined\nnanocrystals.", "AI": {"tldr": "\u5927\u578bCsPbBr3\u7eb3\u7c73\u6676\u4f53\u4e2d\u7684\u4e8c\u6fc0\u5b50\uff08BX\uff09\u5177\u6709\u6bd4\u6fc0\u5b50\uff08X\uff09\u548c\u4e09\u4f53\uff08X*\uff09\u66f4\u4f4e\u7684\u4ecb\u7535\u5c4f\u853d\u3002\u8fd9\u662f\u56e0\u4e3aBX\u7684\u5185\u90e8\u52a8\u529b\u5b66\u9891\u7387\u8f83\u4f4e\uff0c\u5bfc\u81f4\u5176\u4ecb\u7535\u5e38\u6570\u964d\u4f4e\u3002", "motivation": "\u89e3\u91ca\u4e3a\u4ec0\u4e48\u6fc0\u5b50\uff08X\uff09\u548c\u4e09\u4f53\uff08X*\uff09\u5728\u5927\u578bCsPbBr3\u7eb3\u7c73\u6676\u4f53\u4e2d\u6bd4\u4e8c\u6fc0\u5b50\uff08BX\uff09\u7ecf\u5386\u66f4\u5c11\u7684\u4ecb\u7535\u5c4f\u853d\u3002", "method": "\u4f7f\u7528\u6709\u6548\u8d28\u91cf-\u53d8\u5206\u91cf\u5b50\u8499\u7279\u5361\u6d1b\u6a21\u62df\uff0c\u5e76\u5f15\u5165\u7279\u5f81\u9891\u7387\u6765\u63cf\u8ff0\u6fc0\u5b50\u5185\u90e8\u52a8\u529b\u5b66\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u8868\u660e\uff0c\u5927\u578b\u7eb3\u7c73\u6676\u4f53\u4e2dX\u548cX*\u7684\u7279\u5f81\u9891\u7387\u76f8\u4f3c\uff0c\u800cBX\u7684\u7279\u5f81\u9891\u7387\u8f83\u4f4e\u3002\u7531\u4e8e\u8fd9\u4e9b\u9891\u7387\u9ad8\u4e8e\u5757\u4f53LO\u58f0\u5b50\u7684\u9891\u7387\uff0c\u56e0\u6b64BX\u7684\u4ecb\u7535\u5e38\u6570\u8f83\u4f4e\uff0c\u8fd9\u4e0e\u5f3a\u7ea6\u675f\u7eb3\u7c73\u6676\u4f53\u7684\u60c5\u51b5\u76f8\u53cd\u3002", "conclusion": "BX\u5728\u5927\u578bCsPbBr3\u7eb3\u7c73\u6676\u4f53\u4e2d\u7684\u4ecb\u7535\u5c4f\u853d\u6548\u5e94\u6bd4X\u548cX*\u5f31\uff0c\u8fd9\u662f\u7531\u4e8e\u5176\u5185\u90e8\u52a8\u529b\u5b66\u9891\u7387\u4f4e\u4e8eLO\u58f0\u5b50\u9891\u7387\uff0c\u5bfc\u81f4\u5176\u4ecb\u7535\u5e38\u6570\u964d\u4f4e\u3002"}}
{"id": "2507.10830", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.10830", "abs": "https://arxiv.org/abs/2507.10830", "authors": ["Sumit Rout", "Anubhav Chaturvedi", "Some Sankar Bhattacharya", "Pawe\u0142 Horodecki"], "title": "Facets of Non-locality and Advantage in Entanglement-Assisted Classical Communication Tasks", "comment": "Comments and suggestions are welcome. 24 pages, 3 figures, 3 tables", "summary": "We reveal key connections between non-locality and advantage in\ncorrelation-assisted classical communication. First, using the wire-cutting\ntechnique, we provide a Bell inequality tailored to any correlation-assisted\nbounded classical communication task. The violation of this inequality by a\nquantum correlation is equivalent to its quantum-assisted advantage in the\ncorresponding communication task. Next, we introduce wire-reading, which\nleverages the readability of classical messages to demonstrate advantageous\nassistance of non-local correlations in setups where no such advantage can be\notherwise observed. Building on this, we introduce families of classical\ncommunication tasks in a Bob-without-input prepare-and-measure scenario, where\nnon-local correlation enhances bounded classical communication while shared\nrandomness assistance yields strictly suboptimal payoff. For the first family\nof tasks, assistance from any non-local facet leads to optimal payoff, while\neach task in the second family is tailored to a non-local facet. We reveal\nquantum advantage in these tasks, including qutrit over qubit entanglement\nadvantage.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u975e\u5c40\u57df\u6027\u4e0e\u5173\u8054\u8f85\u52a9\u7ecf\u5178\u901a\u4fe1\u4f18\u52bf\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8d1d\u5c14\u4e0d\u7b49\u5f0f\uff0c\u5e76\u5f15\u5165\u4e86\u7ebf\u8bfb\u53d6\u673a\u5236\u6765\u5c55\u793a\u975e\u5c40\u57df\u5173\u8054\u7684\u4f18\u52bf\u4f5c\u7528\uff0c\u7279\u522b\u662f\u5728Bob-\u65e0\u8f93\u5165\u51c6\u5907-\u6d4b\u91cf\u573a\u666f\u4e0b\uff0c\u975e\u5c40\u57df\u5173\u8054\u80fd\u589e\u5f3a\u901a\u4fe1\u6548\u679c\uff0c\u4f18\u4e8e\u5171\u4eab\u968f\u673a\u6027\u8f85\u52a9\u3002", "motivation": "\u63ed\u793a\u975e\u5c40\u57df\u6027\u4e0e\u5173\u8054\u8f85\u52a9\u7ecf\u5178\u901a\u4fe1\u4f18\u52bf\u4e4b\u95f4\u7684\u5173\u952e\u8054\u7cfb\u3002", "method": "\u5229\u7528\u7ebf\u5207\u5272\u6280\u672f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9002\u7528\u4e8e\u4efb\u4f55\u5173\u8054\u8f85\u52a9\u6709\u754c\u7ecf\u5178\u901a\u4fe1\u4efb\u52a1\u7684\u8d1d\u5c14\u4e0d\u7b49\u5f0f\uff0c\u5e76\u901a\u8fc7\u5f15\u5165\u7ebf\u8bfb\u53d6\u673a\u5236\u6765\u5229\u7528\u7ecf\u5178\u6d88\u606f\u7684\u53ef\u8bfb\u6027\u3002", "result": "\u8d1d\u5c14\u4e0d\u7b49\u5f0f\u7684\u8fdd\u53cd\u7b49\u540c\u4e8e\u91cf\u5b50\u5173\u8054\u5728\u901a\u4fe1\u4efb\u52a1\u4e2d\u7684\u91cf\u5b50\u8f85\u52a9\u4f18\u52bf\u3002\u7ebf\u8bfb\u53d6\u673a\u5236\u5c55\u793a\u4e86\u975e\u5c40\u57df\u5173\u8054\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff08\u5426\u5219\u65e0\u6cd5\u89c2\u5bdf\u5230\u4f18\u52bf\uff09\u7684\u6709\u5229\u8f85\u52a9\u4f5c\u7528\u3002\u5728Bob-\u65e0\u8f93\u5165\u51c6\u5907-\u6d4b\u91cf\u573a\u666f\u4e0b\uff0c\u63d0\u51fa\u4e86\u51e0\u7c7b\u7ecf\u5178\u901a\u4fe1\u4efb\u52a1\uff0c\u5176\u4e2d\u975e\u5c40\u57df\u5173\u8054\u589e\u5f3a\u4e86\u6709\u754c\u7ecf\u5178\u901a\u4fe1\uff0c\u800c\u5171\u4eab\u968f\u673a\u6027\u8f85\u52a9\u7684\u6536\u76ca\u5219\u4e25\u683c\u6b21\u4f18\u3002\u7b2c\u4e00\u7c7b\u4efb\u52a1\u7684\u4f18\u52bf\u6765\u81ea\u4efb\u4f55\u975e\u5c40\u57df\u65b9\u9762\uff0c\u7b2c\u4e8c\u7c7b\u4efb\u52a1\u5219\u9488\u5bf9\u7279\u5b9a\u7684\u975e\u5c40\u57df\u65b9\u9762\u3002\u7814\u7a76\u63ed\u793a\u4e86\u8fd9\u4e9b\u4efb\u52a1\u4e2d\u7684\u91cf\u5b50\u4f18\u52bf\uff0c\u5305\u62ecqutrit\u4f18\u4e8equbit\u7684\u7ea0\u7f20\u4f18\u52bf\u3002", "conclusion": "\u63ed\u793a\u4e86\u975e\u5c40\u57df\u6027\u4e0e\u5173\u8054\u8f85\u52a9\u7ecf\u5178\u901a\u4fe1\u4f18\u52bf\u4e4b\u95f4\u7684\u5173\u952e\u8054\u7cfb\u3002"}}
{"id": "2507.10935", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10935", "abs": "https://arxiv.org/abs/2507.10935", "authors": ["Shaowen Tong", "Zimin Xia", "Alexandre Alahi", "Xuming He", "Yujiao Shi"], "title": "GeoDistill: Geometry-Guided Self-Distillation for Weakly Supervised Cross-View Localization", "comment": "accepted by ICCV2025", "summary": "Cross-view localization, the task of estimating a camera's\n3-degrees-of-freedom (3-DoF) pose by aligning ground-level images with\nsatellite images, is crucial for large-scale outdoor applications like\nautonomous navigation and augmented reality. Existing methods often rely on\nfully supervised learning, which requires costly ground-truth pose annotations.\nIn this work, we propose GeoDistill, a Geometry guided weakly supervised self\ndistillation framework that uses teacher-student learning with Field-of-View\n(FoV)-based masking to enhance local feature learning for robust cross-view\nlocalization. In GeoDistill, the teacher model localizes a panoramic image,\nwhile the student model predicts locations from a limited FoV counterpart\ncreated by FoV-based masking. By aligning the student's predictions with those\nof the teacher, the student focuses on key features like lane lines and ignores\ntextureless regions, such as roads. This results in more accurate predictions\nand reduced uncertainty, regardless of whether the query images are panoramas\nor limited FoV images. Our experiments show that GeoDistill significantly\nimproves localization performance across different frameworks. Additionally, we\nintroduce a novel orientation estimation network that predicts relative\norientation without requiring precise planar position ground truth. GeoDistill\nprovides a scalable and efficient solution for real-world cross-view\nlocalization challenges. Code and model can be found at\nhttps://github.com/tongshw/GeoDistill.", "AI": {"tldr": "GeoDistill\u5229\u7528\u6559\u5e08-\u5b66\u751f\u5b66\u4e60\u548c\u89c6\u573a\u611f\u77e5\u7684\u906e\u853d\uff0c\u901a\u8fc7\u5173\u6ce8\u5173\u952e\u7279\u5f81\u548c\u5ffd\u7565\u65e0\u7eb9\u7406\u533a\u57df\uff0c\u63d0\u9ad8\u4e86\u8de8\u89c6\u56fe\u5b9a\u4f4d\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u51cf\u5c11\u4e86\u5bf9\u6602\u8d35\u771f\u5b9e\u4f4d\u59ff\u6807\u6ce8\u7684\u4f9d\u8d56\u3002", "motivation": "\u8de8\u89c6\u56fe\u5b9a\u4f4d\u5bf9\u4e8e\u81ea\u52a8\u5bfc\u822a\u548c\u589e\u5f3a\u73b0\u5b9e\u7b49\u5927\u89c4\u6a21\u6237\u5916\u5e94\u7528\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u9700\u8981\u6602\u8d35\u771f\u5b9e\u4f4d\u59ff\u6807\u6ce8\u7684\u5168\u76d1\u7763\u5b66\u4e60\u3002", "method": "GeoDistill\u91c7\u7528\u6559\u5e08-\u5b66\u751f\u5b66\u4e60\u6846\u67b6\uff0c\u5e76\u5229\u7528\u89c6\u573a\uff08FoV\uff09\u611f\u77e5\u7684\u906e\u853d\u6765\u589e\u5f3a\u5c40\u90e8\u7279\u5f81\u5b66\u4e60\uff0c\u4ee5\u5b9e\u73b0\u9c81\u68d2\u7684\u8de8\u89c6\u56fe\u5b9a\u4f4d\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6559\u5e08\u6a21\u578b\u5bf9\u5168\u666f\u56fe\u50cf\u8fdb\u884c\u5b9a\u4f4d\uff0c\u800c\u5b66\u751f\u6a21\u578b\u5219\u4ece\u901a\u8fc7FoV\u611f\u77e5\u7684\u906e\u853d\u521b\u5efa\u7684\u6709\u9650FoV\u5bf9\u5e94\u56fe\u50cf\u4e2d\u9884\u6d4b\u4f4d\u7f6e\u3002\u901a\u8fc7\u4f7f\u5b66\u751f\u6a21\u578b\u7684\u9884\u6d4b\u4e0e\u6559\u5e08\u6a21\u578b\u5bf9\u9f50\uff0c\u5b66\u751f\u6a21\u578b\u53ef\u4ee5\u4e13\u6ce8\u4e8e\u8f66\u9053\u7ebf\u7b49\u5173\u952e\u7279\u5f81\uff0c\u5e76\u5ffd\u7565\u9053\u8def\u7b49\u65e0\u7eb9\u7406\u533a\u57df\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cGeoDistill\u5728\u4e0d\u540c\u6846\u67b6\u4e0b\u5747\u663e\u8457\u63d0\u9ad8\u4e86\u5b9a\u4f4d\u6027\u80fd\uff0c\u5e76\u4e14\u5176\u5b9a\u4f4d\u7cbe\u5ea6\u548c\u4e0d\u786e\u5b9a\u6027\u51cf\u5c11\uff0c\u4e0e\u67e5\u8be2\u56fe\u50cf\u662f\u5168\u666f\u56fe\u8fd8\u662f\u6709\u9650FoV\u56fe\u65e0\u5173\u3002", "conclusion": "GeoDistill\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u5e94\u5bf9\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u8de8\u89c6\u56fe\u5b9a\u4f4d\u6311\u6218\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5b9a\u5411\u4f30\u8ba1\u7f51\u7edc\uff0c\u65e0\u9700\u7cbe\u786e\u7684\u5e73\u9762\u4f4d\u7f6e\u771f\u5b9e\u503c\u5373\u53ef\u9884\u6d4b\u76f8\u5bf9\u65b9\u5411\u3002"}}
{"id": "2507.10911", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10911", "abs": "https://arxiv.org/abs/2507.10911", "authors": ["Yicong Wu", "Ting Chen", "Irit Hochberg", "Zhoujian Sun", "Ruth Edry", "Zhengxing Huang", "Mor Peleg"], "title": "Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy Recommendation", "comment": null, "summary": "Therapy recommendation for chronic patients with multimorbidity is\nchallenging due to risks of treatment conflicts. Existing decision support\nsystems face scalability limitations. Inspired by the way in which general\npractitioners (GP) manage multimorbidity patients, occasionally convening\nmultidisciplinary team (MDT) collaboration, this study investigated the\nfeasibility and value of using a Large Language Model (LLM)-based multi-agent\nsystem (MAS) for safer therapy recommendations. We designed a single agent and\na MAS framework simulating MDT decision-making by enabling discussion among LLM\nagents to resolve medical conflicts. The systems were evaluated on therapy\nplanning tasks for multimorbidity patients using benchmark cases. We compared\nMAS performance with single-agent approaches and real-world benchmarks. An\nimportant contribution of our study is the definition of evaluation metrics\nthat go beyond the technical precision and recall and allow the inspection of\nclinical goals met and medication burden of the proposed advices to a gold\nstandard benchmark. Our results show that with current LLMs, a single agent GP\nperforms as well as MDTs. The best-scoring models provide correct\nrecommendations that address all clinical goals, yet the advices are\nincomplete. Some models also present unnecessary medications, resulting in\nunnecessary conflicts between medication and conditions or drug-drug\ninteractions.", "AI": {"tldr": "LLM-based systems for therapy recommendations in multimorbid patients show promise but require further refinement to ensure complete and conflict-free advice.", "motivation": "Existing decision support systems for therapy recommendations in chronic patients with multimorbidity face scalability limitations and risks of treatment conflicts. This study was inspired by the way General Practitioners (GPs) manage such patients by convening Multidisciplinary Teams (MDTs), and investigated the feasibility and value of using an LLM-based MAS for safer therapy recommendations.", "method": "The study designed and evaluated a Large Language Model (LLM)-based multi-agent system (MAS) framework simulating Multidisciplinary Team (MDT) decision-making by enabling discussion among LLM agents to resolve medical conflicts. This MAS was compared against a single-agent approach and real-world benchmarks using therapy planning tasks for multimorbidity patients. New evaluation metrics were defined to assess clinical goals met and medication burden.", "result": "The results indicate that a single LLM agent acting as a GP performs comparably to MDT simulations. The top-performing models offered correct recommendations that met all clinical goals but were incomplete. Additionally, some models suggested unnecessary medications, causing unintended medication-condition conflicts or drug-drug interactions.", "conclusion": "The study found that current LLMs, when used in a single-agent system simulating a GP, perform as well as multi-agent systems simulating MDTs for therapy recommendations in chronic patients with multimorbidity. However, even the best-performing models provided incomplete advice and some included unnecessary medications, leading to potential conflicts."}}
{"id": "2507.10920", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10920", "abs": "https://arxiv.org/abs/2507.10920", "authors": ["Seungho Choi"], "title": "HanjaBridge: Resolving Semantic Ambiguity in Korean LLMs via Hanja-Augmented Pre-Training", "comment": null, "summary": "Large language models (LLMs) often show poor performance in low-resource\nlanguages like Korean, partly due to unique linguistic challenges such as\nhomophonous Sino-Korean words that are indistinguishable in Hangul script. To\naddress this semantic ambiguity, we propose HanjaBridge, a novel\nmeaning-injection technique integrated into a continual pre-training (CPT)\nframework. Instead of deterministically mapping a word to a single Hanja\n(Chinese character), HanjaBridge presents the model with all possible Hanja\ncandidates for a given homograph, encouraging the model to learn contextual\ndisambiguation. This process is paired with token-level knowledge distillation\nto prevent catastrophic forgetting. Experimental results show that HanjaBridge\nsignificantly improves Korean language understanding, achieving a 21\\% relative\nimprovement on the KoBALT benchmark. Notably, by reinforcing semantic alignment\nbetween Korean and Chinese through shared Hanja, we observe a strong positive\ncross-lingual transfer. Furthermore, these gains persist even when Hanja\naugmentation is omitted at inference time, ensuring practical efficiency with\nno additional run-time cost.", "AI": {"tldr": "HanjaBridge\u901a\u8fc7\u5728\u6301\u7eed\u9884\u8bad\u7ec3\u4e2d\u6ce8\u5165\u6c49\u5b57\u4fe1\u606f\u6765\u89e3\u51b3\u97e9\u8bed\u540c\u97f3\u8bcd\u7684\u6b67\u4e49\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u5728\u97e9\u8bed\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u4fc3\u8fdb\u4e86\u8de8\u8bed\u8a00\u8fc1\u79fb\uff0c\u540c\u65f6\u5728\u63a8\u7406\u65f6\u4fdd\u6301\u4e86\u6548\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u97e9\u8bed\u7b49\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u7684\u8868\u73b0\u4e0d\u4f73\uff0c\u90e8\u5206\u539f\u56e0\u662f\u72ec\u7279\u7684\u8bed\u8a00\u6311\u6218\uff0c\u4f8b\u5982\u97e9\u6587\u4e66\u5199\u4e2d\u65e0\u6cd5\u533a\u5206\u7684\u540c\u97f3\u6c49\u97e9\u8bed\u8bcd\u6c47\u9020\u6210\u7684\u8bed\u4e49\u6b67\u4e49\u3002", "method": "HanjaBridge\u662f\u4e00\u79cd\u65b0\u9896\u7684\u610f\u4e49\u6ce8\u5165\u6280\u672f\uff0c\u96c6\u6210\u5728\u6301\u7eed\u9884\u8bad\u7ec3\uff08CPT\uff09\u6846\u67b6\u4e2d\u3002\u5b83\u4e0d\u5c06\u5355\u8bcd\u786e\u5b9a\u6027\u5730\u6620\u5c04\u5230\u5355\u4e2a\u6c49\u5b57\uff0c\u800c\u662f\u5411\u6a21\u578b\u5c55\u793a\u7ed9\u5b9a\u540c\u5f62\u5f02\u4e49\u8bcd\u7684\u6240\u6709\u53ef\u80fd\u7684\u6c49\u5b57\u5019\u9009\uff0c\u4fc3\u4f7f\u6a21\u578b\u5b66\u4e60\u4e0a\u4e0b\u6587\u6d88\u6b67\u3002\u8be5\u8fc7\u7a0b\u4e0e\u4ee4\u724c\u7ea7\u77e5\u8bc6\u84b8\u998f\u76f8\u7ed3\u5408\uff0c\u4ee5\u9632\u6b62\u707e\u96be\u6027\u9057\u5fd8\u3002", "result": "HanjaBridge\u5728KoBALT\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e8621%\u7684\u76f8\u5bf9\u63d0\u5347\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u97e9\u8bed\u8bed\u8a00\u7406\u89e3\u80fd\u529b\u3002\u901a\u8fc7\u5171\u4eab\u6c49\u5b57\u589e\u5f3a\u4e86\u97e9\u8bed\u548c\u4e2d\u6587\u4e4b\u95f4\u7684\u8bed\u4e49\u5bf9\u9f50\uff0c\u89c2\u5bdf\u5230\u4e86\u5f3a\u5927\u7684\u8de8\u8bed\u8a00\u8fc1\u79fb\u6548\u5e94\u3002\u5373\u4f7f\u5728\u63a8\u7406\u65f6\u7701\u7565\u6c49\u5b57\u589e\u5f3a\uff0c\u6027\u80fd\u589e\u76ca\u4e5f\u4f9d\u7136\u5b58\u5728\uff0c\u6ca1\u6709\u989d\u5916\u7684\u8fd0\u884c\u6210\u672c\u3002", "conclusion": "HanjaBridge\u901a\u8fc7\u4e3a\u6a21\u578b\u63d0\u4f9b\u6240\u6709\u53ef\u80fd\u7684\u76f8\u5173\u6c49\u5b57\u5019\u9009\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u97e9\u8bed\u540c\u97f3\u8bcd\u7684\u8bed\u4e49\u6b67\u4e49\u95ee\u9898\uff0c\u5e76\u5728\u6301\u7eed\u9884\u8bad\u7ec3\u6846\u67b6\uff08CPT\uff09\u4e2d\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u9632\u6b62\u4e86\u707e\u96be\u6027\u9057\u5fd8\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u97e9\u8bed\u7406\u89e3\u80fd\u529b\uff08\u5728KoBALT\u57fa\u51c6\u4e0a\u76f8\u5bf9\u63d0\u534721%\uff09\uff0c\u5e76\u901a\u8fc7\u5171\u4eab\u6c49\u5b57\u4fc3\u8fdb\u4e86\u97e9\u8bed\u548c\u4e2d\u6587\u4e4b\u95f4\u7684\u8de8\u8bed\u8a00\u8fc1\u79fb\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u5373\u4f7f\u5728\u63a8\u7406\u65f6\u7701\u7565\u6c49\u5b57\u589e\u5f3a\uff0c\u6027\u80fd\u589e\u76ca\u4f9d\u7136\u5b58\u5728\uff0c\u4fdd\u8bc1\u4e86\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6548\u7387\u3002"}}
{"id": "2507.10718", "categories": ["cs.LG", "cs.DS", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.10718", "abs": "https://arxiv.org/abs/2507.10718", "authors": ["Shuyao Li", "Ilias Diakonikolas", "Jelena Diakonikolas"], "title": "Distributionally Robust Optimization with Adversarial Data Contamination", "comment": null, "summary": "Distributionally Robust Optimization (DRO) provides a framework for\ndecision-making under distributional uncertainty, yet its effectiveness can be\ncompromised by outliers in the training data. This paper introduces a\nprincipled approach to simultaneously address both challenges. We focus on\noptimizing Wasserstein-1 DRO objectives for generalized linear models with\nconvex Lipschitz loss functions, where an $\\epsilon$-fraction of the training\ndata is adversarially corrupted. Our primary contribution lies in a novel\nmodeling framework that integrates robustness against training data\ncontamination with robustness against distributional shifts, alongside an\nefficient algorithm inspired by robust statistics to solve the resulting\noptimization problem. We prove that our method achieves an estimation error of\n$O(\\sqrt{\\epsilon})$ for the true DRO objective value using only the\ncontaminated data under the bounded covariance assumption. This work\nestablishes the first rigorous guarantees, supported by efficient computation,\nfor learning under the dual challenges of data contamination and distributional\nshifts.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u80fd\u591f\u540c\u65f6\u5e94\u5bf9\u6570\u636e\u6c61\u67d3\u548c\u5206\u5e03\u53d8\u5316\uff0c\u5e76\u5728\u5b58\u5728\u5f02\u5e38\u503c\u7684\u60c5\u51b5\u4e0b\uff0c\u4e3a\u5206\u5e03\u9c81\u68d2\u4f18\u5316\u63d0\u4f9b\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u548c\u7406\u8bba\u4fdd\u8bc1\u3002", "motivation": "\u89e3\u51b3\u5206\u5e03\u9c81\u68d2\u4f18\u5316\uff08DRO\uff09\u5728\u9762\u5bf9\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u5f02\u5e38\u503c\u65f6\u9c81\u68d2\u6027\u4f1a\u53d7\u5230\u5f71\u54cd\u7684\u95ee\u9898\uff0c\u5e76\u540c\u65f6\u5e94\u5bf9\u6570\u636e\u6c61\u67d3\u548c\u5206\u5e03\u53d8\u5316\u5e26\u6765\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5efa\u6a21\u6846\u67b6\uff0c\u5c06\u5bf9\u8bad\u7ec3\u6570\u636e\u6c61\u67d3\u7684\u9c81\u68d2\u6027\u4e0e\u5bf9\u5206\u5e03\u53d8\u5316\u7684\u9c81\u68d2\u6027\u76f8\u7ed3\u5408\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u53d7\u9c81\u68d2\u7edf\u8ba1\u5b66\u542f\u53d1\u7684\u6709\u6548\u7b97\u6cd5\u6765\u89e3\u51b3\u4f18\u5316\u95ee\u9898\u3002", "result": "\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u6709\u754c\u534f\u65b9\u5dee\u5047\u8bbe\u4e0b\uff0c\u4ec5\u4f7f\u7528\u53d7\u6c61\u67d3\u7684\u6570\u636e\u5373\u53ef\u5b9e\u73b0\u5bf9\u771f\u5b9e DRO \u76ee\u6807\u503c $O(\\sqrt{\\epsilon})$ \u7684\u4f30\u8ba1\u8bef\u5dee\u3002", "conclusion": "\u8be5\u7814\u7a76\u9996\u6b21\u5728\u6570\u636e\u6c61\u67d3\u548c\u5206\u5e03\u53d8\u5316\u7684\u53cc\u91cd\u6311\u6218\u4e0b\uff0c\u4e3a\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u4fdd\u8bc1\u548c\u6709\u6548\u7684\u8ba1\u7b97\u65b9\u6cd5\u3002"}}
{"id": "2507.11283", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.11283", "abs": "https://arxiv.org/abs/2507.11283", "authors": ["Weiyi Liu", "Jingzehua Xu", "Guanwen Xie", "Yi Li"], "title": "Ocean Diviner: A Diffusion-Augmented Reinforcement Learning for AUV Robust Control in the Underwater Tasks", "comment": null, "summary": "This paper presents a diffusion-augmented reinforcement learning (RL)\napproach for robust autonomous underwater vehicle (AUV) control, addressing key\nchallenges in underwater trajectory planning and dynamic environment\nadaptation. The proposed method integrates three core innovations: (1) A\ndiffusion-based trajectory generation framework that produces physically\nfeasible multi-step trajectories, enhanced by a high-dimensional state encoding\nmechanism combining current observations with historical states and actions\nthrough a novel diffusion U-Net architecture, significantly improving\nlong-horizon planning. (2) A sample-efficient hybrid learning architecture that\nsynergizes diffusion-guided exploration with RL policy optimization, where the\ndiffusion model generates diverse candidate actions and the RL critic selects\noptimal actions, achieving higher exploration efficiency and policy stability\nin dynamic underwater environments. Extensive simulation experiments validating\nthe method's superior robustness and flexibility, outperforms conventional\ncontrol methods in challenging marine conditions, offering enhanced\nadaptability and reliability for AUV operations in the underwater tasks.", "AI": {"tldr": "A new diffusion-augmented RL method improves AUV control by generating feasible trajectories and using diffusion for efficient exploration and RL for action selection, showing better performance in tough underwater environments.", "motivation": "This paper addresses key challenges in underwater trajectory planning and dynamic environment adaptation for autonomous underwater vehicle (AUV) control.", "method": "This paper proposes a diffusion-augmented reinforcement learning (RL) approach integrating a diffusion-based trajectory generation framework with a novel diffusion U-Net architecture for high-dimensional state encoding, and a sample-efficient hybrid learning architecture that combines diffusion-guided exploration with RL policy optimization for robust AUV control.", "result": "Extensive simulation experiments validate the method's superior robustness and flexibility, outperforming conventional control methods in challenging marine conditions.", "conclusion": "The proposed diffusion-augmented reinforcement learning approach demonstrates superior robustness and flexibility for autonomous underwater vehicle (AUV) control, outperforming conventional methods in challenging marine conditions and offering enhanced adaptability and reliability for underwater tasks."}}
{"id": "2507.10618", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10618", "abs": "https://arxiv.org/abs/2507.10618", "authors": ["Peter Barnett"], "title": "Compute Requirements for Algorithmic Innovation in Frontier AI Models", "comment": null, "summary": "Algorithmic innovation in the pretraining of large language models has driven\na massive reduction in the total compute required to reach a given level of\ncapability. In this paper we empirically investigate the compute requirements\nfor developing algorithmic innovations. We catalog 36 pre-training algorithmic\ninnovations used in Llama 3 and DeepSeek-V3. For each innovation we estimate\nboth the total FLOP used in development and the FLOP/s of the hardware\nutilized. Innovations using significant resources double in their requirements\neach year. We then use this dataset to investigate the effect of compute caps\non innovation. Our analysis suggests that compute caps alone are unlikely to\ndramatically slow AI algorithmic progress. Even stringent compute caps -- such\nas capping total operations to the compute used to train GPT-2 or capping\nhardware capacity to 8 H100 GPUs -- could still have allowed for half of the\ncataloged innovations.", "AI": {"tldr": "\u7b97\u6cd5\u521b\u65b0\u9700\u6c42\u6bcf\u5e74\u7ffb\u500d\uff0c\u4f46\u8ba1\u7b97\u4e0a\u9650\u4e0d\u592a\u53ef\u80fd\u663e\u8457\u51cf\u7f13AI\u7b97\u6cd5\u8fdb\u5c55\u3002", "motivation": "\u63a2\u8ba8\u7b97\u6cd5\u521b\u65b0\u5728\u5f00\u53d1\u4e2d\u5bf9\u8ba1\u7b97\u80fd\u529b\u7684\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u7f16\u76eeLlama 3\u548cDeepSeek-V3\u4e2d\u4f7f\u7528\u768436\u79cd\u9884\u8bad\u7ec3\u7b97\u6cd5\u521b\u65b0\uff0c\u5e76\u4f30\u7b97\u5176\u5f00\u53d1\u6240\u4f7f\u7528\u7684\u603bFLOP\u548c\u6240\u7528\u786c\u4ef6\u7684FLOP/s\u6765\u5b9e\u8bc1\u7814\u7a76\u3002", "result": "\u521b\u65b0\u6027\u7814\u7a76\u53d1\u73b0\uff0c\u4f7f\u7528\u5927\u91cf\u8d44\u6e90\u7684\u521b\u65b0\uff0c\u5176\u9700\u6c42\u6bcf\u5e74\u7ffb\u500d\u3002\u5206\u6790\u8868\u660e\uff0c\u5355\u72ec\u7684\u8ba1\u7b97\u4e0a\u9650\u4e0d\u592a\u53ef\u80fd\u663e\u8457\u51cf\u7f13AI\u7b97\u6cd5\u7684\u8fdb\u5c55\u3002", "conclusion": "\u5373\u4f7f\u6709\u4e25\u683c\u7684\u8ba1\u7b97\u4e0a\u9650\uff0c\u4f8b\u5982\u5c06\u603b\u64cd\u4f5c\u6570\u9650\u5236\u5728\u8bad\u7ec3GPT-2\u7684\u8ba1\u7b97\u91cf\uff0c\u6216\u5c06\u786c\u4ef6\u5bb9\u91cf\u9650\u5236\u4e3a8\u4e2aH100 GPU\uff0c\u4ecd\u6709\u53ef\u80fd\u5b9e\u73b0\u6240\u5206\u7c7b\u522b\u4e2d\u4e00\u534a\u7684\u521b\u65b0\u3002"}}
{"id": "2507.11000", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.11000", "abs": "https://arxiv.org/abs/2507.11000", "authors": ["Minwoo Cho", "Jaehwi Jang", "Daehyung Park"], "title": "ILCL: Inverse Logic-Constraint Learning from Temporally Constrained Demonstrations", "comment": "8 pages, 6 figures", "summary": "We aim to solve the problem of temporal-constraint learning from\ndemonstrations to reproduce demonstration-like logic-constrained behaviors.\nLearning logic constraints is challenging due to the combinatorially large\nspace of possible specifications and the ill-posed nature of non-Markovian\nconstraints. To figure it out, we introduce a novel temporal-constraint\nlearning method, which we call inverse logic-constraint learning (ILCL). Our\nmethod frames ICL as a two-player zero-sum game between 1) a genetic\nalgorithm-based temporal-logic mining (GA-TL-Mining) and 2) logic-constrained\nreinforcement learning (Logic-CRL). GA-TL-Mining efficiently constructs syntax\ntrees for parameterized truncated linear temporal logic (TLTL) without\npredefined templates. Subsequently, Logic-CRL finds a policy that maximizes\ntask rewards under the constructed TLTL constraints via a novel constraint\nredistribution scheme. Our evaluations show ILCL outperforms state-of-the-art\nbaselines in learning and transferring TL constraints on four temporally\nconstrained tasks. We also demonstrate successful transfer to real-world\npeg-in-shallow-hole tasks.", "AI": {"tldr": "ILCL\u662f\u4e00\u79cd\u65b0\u9896\u7684\u65f6\u95f4\u7ea6\u675f\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7GA-TL-Mining\u548cLogic-CRL\u4e4b\u95f4\u7684\u535a\u5f08\u6765\u5b66\u4e60\u903b\u8f91\u7ea6\u675f\uff0c\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u90fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u4ece\u6f14\u793a\u4e2d\u5b66\u4e60\u65f6\u95f4\u7ea6\u675f\u4ee5\u590d\u73b0\u7c7b\u4f3c\u6f14\u793a\u7684\u903b\u8f91\u7ea6\u675f\u884c\u4e3a\u7684\u95ee\u9898\uff0c\u56e0\u4e3a\u5b66\u4e60\u903b\u8f91\u7ea6\u675f\u7531\u4e8e\u53ef\u80fd\u7684\u89c4\u8303\u7684\u7ec4\u5408\u5927\u7a7a\u95f4\u548c\u975e\u9a6c\u5c14\u53ef\u592b\u7ea6\u675f\u7684\u75c5\u6001\u6027\u8d28\u800c\u5177\u6709\u6311\u6218\u6027\u3002", "method": "ILCL\u88ab\u6784\u5efa\u4e3a\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684\u65f6\u95f4\u903b\u8f91\u6316\u6398\uff08GA-TL-Mining\uff09\u548c\u57fa\u4e8e\u903b\u8f91\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\uff08Logic-CRL\uff09\u4e4b\u95f4\u7684\u53cc\u4eba\u96f6\u548c\u535a\u5f08\u3002GA-TL-Mining\u7528\u4e8e\u6784\u5efa\u53c2\u6570\u5316\u622a\u65ad\u7ebf\u6027\u65f6\u5e8f\u903b\u8f91\uff08TLTL\uff09\u7684\u8bed\u6cd5\u6811\uff0c\u800cLogic-CRL\u5219\u901a\u8fc7\u4e00\u79cd\u65b0\u9896\u7684\u7ea6\u675f\u91cd\u5206\u914d\u65b9\u6848\uff0c\u5728TLTL\u7ea6\u675f\u4e0b\u5bfb\u627e\u6700\u5927\u5316\u4efb\u52a1\u5956\u52b1\u7684\u7b56\u7565\u3002", "result": "ILCL\u5728\u5b66\u4e60\u548c\u8f6c\u79fbTL\u7ea6\u675f\u65b9\u9762\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\uff0c\u5e76\u5728\u56db\u9879\u65f6\u95f4\u7ea6\u675f\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u6210\u529f\u3002", "conclusion": "ILCL\u5728\u5b66\u4e60\u548c\u8f6c\u79fbTL\u7ea6\u675f\u65b9\u9762\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\uff0c\u5e76\u5728\u56db\u9879\u65f6\u95f4\u7ea6\u675f\u4efb\u52a1\u548c\u73b0\u5b9e\u4e16\u754c\u7684\u63d2\u5165\u6d45\u5b54\u4efb\u52a1\u4e2d\u5f97\u5230\u4e86\u6210\u529f\u8f6c\u79fb\u3002"}}
{"id": "2507.11338", "categories": ["cond-mat.mtrl-sci", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2507.11338", "abs": "https://arxiv.org/abs/2507.11338", "authors": ["Andr\u00e9s Burgos-Caminal", "Brener R. C. Vale", "Andr\u00e9 F. V. Fonseca", "Juan F. Hidalgo", "Elisa P. P. Collet", "L\u00e1zaro Garc\u00eda", "V\u00edctor Vega-Mayoral", "Sa\u00fcl Garcia-Orrit", "Iciar Arnay", "Juan Cabanillas-Gonz\u00e1lez", "Laura Simonelli", "Ana Fl\u00e1via Nogueira", "Marco Ant\u00f4nio Schiavon", "Thomas J. Penfold", "Lazaro A. Padilha", "Wojciech Gawelda"], "title": "Unveiling Zn incorporation in CuInS$_2$ quantum dots: X-ray and optical analysis of doping effects, structural modifications and surface passivation", "comment": "arXiv admin note: text overlap with arXiv:2412.15418", "summary": "Quantum dots (QDs) exhibit unique properties arising from their reduced size\nand quantum confinement effects, including exceptionally bright and tunable\nphotoluminescence. Among these, CuInS$_{2}$ QDs have gained significant\nattention owing to their remarkable broadband emission, making them highly\ndesirable for various optoelectronic applications requiring efficient\nluminescent nanomaterials. However, maximizing radiative recombination in\nCuInS$_{2}$ QDs often necessitates minimizing intragap trap states. A common\napproach involves the introduction of Zn during the synthesis, which typically\npromotes the formation of a ZnS shell that passivates the QD surface.\n  Despite its importance, the characterization and quantification of Zn\nincorporation using conventional techniques, such as optical spectroscopy or\nelectron microscopy, remains challenging. In this study, we utilized X-ray\nabsorption spectroscopy (XAS), in both X-ray absorption near-edge structure\n(XANES) and extended X-ray absorption fine structure (EXAFS) spectral ranges,\nto investigate Zn incorporation into CuInS$_{2}$ QDs with element-specific\nprecision. This approach allowed us to detect the formation of a ZnS surface\nshell and to resolve the spatial distribution of Zn atoms within the QD\nlattice, distinguishing between Zn as a substituent, or as an interstitial\ndefect.\n  Additionally, we explored the optical and dynamical properties of CuInS$_{2}$\nQDs using time-resolved optical spectroscopies, particularly in the presence of\nelectron and hole acceptors. These results provide deeper insights into the\nrole and effectiveness of the Zn-induced passivating layer, paving the way for\noptimizing QD performance in photoluminescence applications.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.11108", "categories": ["cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2507.11108", "abs": "https://arxiv.org/abs/2507.11108", "authors": ["Hendrik Mannel", "Fabio Rimek", "Marcel Zoellner", "Nico Schwarz", "Andreas D. Wieck", "Nikolai Bart", "Arne Ludwig", "Martin Geller"], "title": "Near transform-limited single photons from rapid-thermal annealed quantum dots", "comment": null, "summary": "Single-photon emitters are essential components for quantum communication\nsystems, enabling applications such as secure quantum key distribution and the\nlong-term vision of a quantum internet. Among various candidates,\nself-assembled InAs/GaAs quantum dots (QDs) remain highly promising due to\ntheir ability to emit coherent and indistinguishable photons, as well as their\ncompatibility with photonic integration. In this work, we investigate the\nimpact of post-growth rapid thermal annealing (RTA) on the quantum optical\nproperties of single self-assembled QDs embedded in a p-i-n diode structure.\nThe annealing process induces a controlled blueshift of the emission wavelength\nby promoting Ga in-diffusion and intermixing. Using resonance fluorescence\nmeasurements at cryogenic temperatures (4.2 K), we investigate the\nsingle-photon statistics, the emission linewidths, and coherence time $T_2$ of\nthe emitted photons. Our results show that, despite the high annealing\ntemperature of $760^\\circ$C, the process does not degrade the optical quality\nof the quantum dots strongly. Instead, we observe single-photon emission with\nnear transform-limited linewidths, where the dephasing time $T_2$ is only a\nfactor 1.5 above the Fourier-limit $T_2=2T_1$. These findings demonstrate that\nrapid thermal annealing (RTA) serves as an effective tuning method that\npreserves the key single-photon emission properties and may help reduce\nundesirable effects such as non-radiative Auger recombination in quantum\nphotonic applications.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528\u5feb\u901f\u70ed\u9000\u706b\uff08RTA\uff09\u8c03\u63a7\u4e86\u81ea\u7ec4\u88c5InAs/GaAs\u91cf\u5b50\u70b9\u7684\u5149\u5b66\u6027\u8d28\uff0c\u53d1\u73b0\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u5355\u5149\u5b50\u53d1\u5c04\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u53d1\u5c04\u6ce2\u957f\u84dd\u79fb\uff0c\u4e3a\u91cf\u5b50\u5149\u5b50\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u624b\u6bb5\u3002", "motivation": "\u4e3a\u4e86\u5b9e\u73b0\u91cf\u5b50\u901a\u4fe1\u548c\u91cf\u5b50\u4e92\u8054\u7f51\u7b49\u5e94\u7528\uff0c\u7814\u7a76\u4e86\u81ea\u7ec4\u88c5InAs/GaAs\u91cf\u5b50\u70b9\uff08QDs\uff09\u7684\u5355\u5149\u5b50\u53d1\u5c04\u7279\u6027\uff0c\u5e76\u63a2\u7d22\u4e86\u9000\u706b\u5bf9\u5176\u5149\u5b66\u6027\u8d28\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5728\u4f4e\u6e29\uff084.2 K\uff09\u4e0b\u8fdb\u884c\u5171\u632f\u8367\u5149\u6d4b\u91cf\uff0c\u7814\u7a76\u4e86\u9000\u706b\u5bf9\u91cf\u5b50\u70b9\u5355\u5149\u5b50\u7edf\u8ba1\u3001\u53d1\u5c04\u7ebf\u5bbd\u548c\u76f8\u5e72\u65f6\u95f4 $T_2$ \u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5c3d\u7ba1\u9000\u706b\u6e29\u5ea6\u9ad8\u8fbe $760^\text{o}\text{C}$\uff0c\u4f46\u8be5\u8fc7\u7a0b\u5e76\u672a\u4e25\u91cd\u964d\u4f4e\u91cf\u5b50\u70b9\u7684\u5149\u5b66\u8d28\u91cf\u3002\u76f8\u53cd\uff0c\u89c2\u5bdf\u5230\u8fd1\u4e4e\u5085\u91cc\u53f6\u6781\u9650\u7684\u5355\u5149\u5b50\u53d1\u5c04\u7ebf\u5bbd\uff0c\u4e14\u76f8\u5e72\u65f6\u95f4 $T_2$ \u4ec5\u4e3a\u5085\u91cc\u53f6\u6781\u9650 $T_2=2T_1$ \u76841.5\u500d\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u5feb\u901f\u70ed\u9000\u706b\uff08RTA\uff09\u662f\u8c03\u6574\u91cf\u5b50\u70b9\u5149\u5b66\u6027\u8d28\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u80fd\u591f\u4fdd\u6301\u5173\u952e\u7684\u5355\u5149\u5b50\u53d1\u5c04\u7279\u6027\uff0c\u5e76\u53ef\u80fd\u6709\u52a9\u4e8e\u51cf\u5c11\u91cf\u5b50\u5149\u5b50\u5e94\u7528\u4e2d\u975e\u8f90\u5c04\u4fc4\u6b47\u590d\u5408\u7b49\u4e0d\u826f\u6548\u5e94\u3002"}}
{"id": "2507.10851", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.10851", "abs": "https://arxiv.org/abs/2507.10851", "authors": ["N. L. Diaz", "Antonio Anna Mele", "Pablo Bermejo", "Paolo Braccia", "Andrew E. Deneris", "Martin Larocca", "M. Cerezo"], "title": "A unified approach to quantum resource theories and a new class of free operations", "comment": "5+8 pages, 3+1 figures", "summary": "In quantum resource theories (QRTs) certain quantum states and operations are\ndeemed more valuable than others. While the determination of the ``free''\nelements is usually guided by the constraints of some experimental setup, this\ncan make it difficult to study similarities and differences between QRTs. In\nthis work, we argue that QRTs follow from the choice of a preferred algebraic\nstructure $\\mathcal{E}$ to be preserved, thus setting the free operations as\nthe automorphisms of $\\mathcal{E}$. We illustrate our finding by determining\n$\\mathcal{E}$ for the QRTs of entanglement, Clifford stabilizerness, purity,\nimaginarity, fermionic Gaussianity, reference frames, thermodynamics and\ncoherence; showing instances where $\\mathcal{E}$ is a Lie algebra, group, ring,\nor even a simple set. This unified understanding allows us to generalize the\nconcept of stochastic local operations and classical communication (SLOCC) to\nidentify novel resource non-increasing operations for Lie-algebra based QRTs,\nthus finding a new solution to an open problem in the literature. We showcase\nthe sanity of our new set of operations by rigorously proving that they map\nfree states to free states, as well as determine more general situations where\nthese transformations strictly do not increase the resource of a state.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u7edf\u4e00\u7406\u89e3\u548c\u6784\u5efa\u91cf\u5b50\u8d44\u6e90\u7406\u8bba\uff08QRTs\uff09\uff0c\u5c06\u81ea\u7531\u64cd\u4f5c\u5b9a\u4e49\u4e3a\u4ee3\u6570\u7ed3\u6784\u7684\u81ea\u540c\u6784\u3002\u6b64\u65b9\u6cd5\u88ab\u5e94\u7528\u4e8e\u591a\u79cdQRTs\uff0c\u5e76\u6210\u529f\u8bc6\u522b\u4e86\u65b0\u7684\u975e\u8d44\u6e90\u589e\u52a0\u64cd\u4f5c\uff0c\u89e3\u51b3\u4e86\u6587\u732e\u4e2d\u7684\u4e00\u4e2a\u5f00\u653e\u6027\u95ee\u9898\u3002", "motivation": "\u8be5\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u91cf\u5b50\u8d44\u6e90\u7406\u8bba\uff08QRTs\uff09\u4e2d\u4e0d\u540c\u7406\u8bba\u4e4b\u95f4\u96be\u4ee5\u6bd4\u8f83\u548c\u7814\u7a76\u7684\u96be\u9898\u3002\u901a\u8fc7\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u5c06QRTs\u4e0e\u5176\u4ee3\u6570\u7ed3\u6784\u76f8\u5173\u8054\uff0c\u5e76\u5c06\u81ea\u7531\u64cd\u4f5c\u5b9a\u4e49\u4e3a\u4ee3\u6570\u7ed3\u6784\u7684\u81ea\u540c\u6784\uff0c\u8be5\u7814\u7a76\u5e0c\u671b\u80fd\u591f\u66f4\u6e05\u6670\u5730\u63ed\u793a\u4e0d\u540cQRTs\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\u548c\u5dee\u5f02\u6027\uff0c\u5e76\u4e3a\u89e3\u51b3\u5f00\u653e\u6027\u95ee\u9898\u63d0\u4f9b\u65b0\u7684\u9014\u5f84\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u91cf\u5b50\u8d44\u6e90\u7406\u8bba\uff08QRTs\uff09\u4e0e\u5176\u4ee3\u6570\u7ed3\u6784$\\\\mathcal{E}$\u76f8\u5173\u8054\u7684\u65b0\u65b9\u6cd5\uff0c\u5176\u4e2d\u81ea\u7531\u64cd\u4f5c\u88ab\u5b9a\u4e49\u4e3a$\\\\mathcal{E}$\u7684\u81ea\u540c\u6784\u3002\u901a\u8fc7\u7814\u7a76\u7ea0\u7f20\u3001Clifford\u53ef\u7a33\u5b9a\u6027\u3001\u7eaf\u5ea6\u3001\u865a\u6570\u6027\u3001\u8d39\u7c73\u9ad8\u65af\u6027\u3001\u53c2\u8003\u7cfb\u3001\u70ed\u529b\u5b66\u548c\u76f8\u5e72\u6027\u7b49QRTs\uff0c\u786e\u5b9a\u4e86\u5b83\u4eec\u5404\u81ea\u7684\u4ee3\u6570\u7ed3\u6784$\\\\mathcal{E}$\uff0c\u5e76\u5c55\u793a\u4e86$\\\\mathcal{E}$\u53ef\u4ee5\u662f\u674e\u4ee3\u6570\u3001\u7fa4\u3001\u73af\u6216\u96c6\u5408\u3002\u57fa\u4e8e\u8fd9\u79cd\u7edf\u4e00\u7684\u7406\u89e3\uff0c\u4f5c\u8005\u5c06\u968f\u673a\u5c40\u90e8\u64cd\u4f5c\u548c\u7ecf\u5178\u901a\u4fe1\uff08SLOCC\uff09\u7684\u6982\u5ff5\u63a8\u5e7f\u5230\u57fa\u4e8e\u674e\u4ee3\u6570\u7684QRTs\uff0c\u8bc6\u522b\u4e86\u65b0\u7684\u975e\u8d44\u6e90\u589e\u52a0\u64cd\u4f5c\uff0c\u5e76\u8bc1\u660e\u4e86\u8fd9\u4e9b\u64cd\u4f5c\u7684\u6709\u6548\u6027\u3002", "result": "\u672c\u7814\u7a76\u6210\u529f\u5730\u4e3a\u91cf\u5b50\u8d44\u6e90\u7406\u8bba\uff08QRTs\uff09\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6570\u5b66\u6846\u67b6\uff0c\u5e76\u5c06\u81ea\u7531\u64cd\u4f5c\u7684\u6982\u5ff5\u63a8\u5e7f\u5230\u66f4\u5e7f\u6cdb\u7684\u9886\u57df\u3002\u901a\u8fc7\u8bc6\u522b\u4e0d\u540cQRTs\u7684\u4ee3\u6570\u7ed3\u6784\uff0c\u4f5c\u8005\u53d1\u73b0\u4e86\u65b0\u7684\u975e\u8d44\u6e90\u589e\u52a0\u64cd\u4f5c\uff0c\u5e76\u4e3a\u57fa\u4e8e\u674e\u4ee3\u6570\u7684QRTs\u63d0\u51fa\u4e86SLOCC\u7684\u63a8\u5e7f\uff0c\u89e3\u51b3\u4e86\u6587\u732e\u4e2d\u7684\u4e00\u4e2a\u5f00\u653e\u6027\u95ee\u9898\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u63d0\u4f9b\u4e86\u8fd9\u4e9b\u65b0\u64cd\u4f5c\u7684\u4e25\u683c\u8bc1\u660e\uff0c\u786e\u4fdd\u4e86\u5b83\u4eec\u5c06\u81ea\u7531\u6001\u6620\u5c04\u5230\u81ea\u7531\u6001\uff0c\u5e76\u4e14\u5728\u7279\u5b9a\u60c5\u51b5\u4e0b\u4e0d\u4f1a\u589e\u52a0\u8d44\u6e90\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\u6765\u7406\u89e3\u548c\u6784\u5efa\u91cf\u5b50\u8d44\u6e90\u7406\u8bba\uff08QRTs\uff09\uff0c\u5c06\u81ea\u7531\u64cd\u4f5c\u5b9a\u4e49\u4e3a\u7279\u5b9a\u4ee3\u6570\u7ed3\u6784$\\mathcal{E}$\u7684\u81ea\u540c\u6784\u3002\u901a\u8fc7\u5c06\u6b64\u6846\u67b6\u5e94\u7528\u4e8e\u73b0\u6709\u7684\u591a\u4e2aQRTs\uff0c\u5305\u62ec\u7ea0\u7f20\u3001Clifford\u53ef\u7a33\u5b9a\u6027\u3001\u7eaf\u5ea6\u3001\u865a\u6570\u6027\u3001\u8d39\u7c73\u9ad8\u65af\u6027\u3001\u53c2\u8003\u7cfb\u3001\u70ed\u529b\u5b66\u548c\u76f8\u5e72\u6027\uff0c\u5e76\u5c55\u793a\u4e86$\\mathcal{E}$\u53ef\u4ee5\u7684\u4e0d\u540c\u4ee3\u6570\u7ed3\u6784\uff08\u5982\u674e\u4ee3\u6570\u3001\u7fa4\u3001\u73af\u6216\u96c6\u5408\uff09\uff0c\u4f5c\u8005\u4e3aQRTs\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u89c6\u89d2\u3002\u6b64\u5916\uff0c\u8be5\u7814\u7a76\u5c06\u968f\u673a\u5c40\u90e8\u64cd\u4f5c\u548c\u7ecf\u5178\u901a\u4fe1\uff08SLOCC\uff09\u7684\u6982\u5ff5\u63a8\u5e7f\u5230\u57fa\u4e8e\u674e\u4ee3\u6570\u7684QRTs\uff0c\u8bc6\u522b\u4e86\u65b0\u7684\u975e\u8d44\u6e90\u589e\u52a0\u64cd\u4f5c\uff0c\u4e3a\u6587\u732e\u4e2d\u7684\u4e00\u4e2a\u5f00\u653e\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u4e25\u683c\u8bc1\u660e\u4e86\u8fd9\u4e9b\u64cd\u4f5c\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.10938", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10938", "abs": "https://arxiv.org/abs/2507.10938", "authors": ["Zhengyi Xu", "Haoran Wu", "Wen Jiang", "Jie Geng"], "title": "Graph Aggregation Prototype Learning for Semantic Change Detection in Remote Sensing", "comment": null, "summary": "Semantic change detection (SCD) extends the binary change detection task to\nprovide not only the change locations but also the detailed \"from-to\"\ncategories in multi-temporal remote sensing data. Such detailed semantic\ninsights into changes offer considerable advantages for a wide array of\napplications. However, since SCD involves the simultaneous optimization of\nmultiple tasks, the model is prone to negative transfer due to task-specific\nlearning difficulties and conflicting gradient flows. To address this issue, we\npropose Graph Aggregation Prototype Learning for Semantic Change Detection in\nremote sensing(GAPL-SCD). In this framework, a multi-task joint optimization\nmethod is designed to optimize the primary task of semantic segmentation and\nchange detection, along with the auxiliary task of graph aggregation prototype\nlearning. Adaptive weight allocation and gradient rotation methods are used to\nalleviate the conflict between training tasks and improve multi-task learning\ncapabilities. Specifically, the graph aggregation prototype learning module\nconstructs an interaction graph using high-level features. Prototypes serve as\nclass proxies, enabling category-level domain alignment across time points and\nreducing interference from irrelevant changes. Additionally, the proposed\nself-query multi-level feature interaction and bi-temporal feature fusion\nmodules further enhance multi-scale feature representation, improving\nperformance in complex scenes. Experimental results on the SECOND and\nLandsat-SCD datasets demonstrate that our method achieves state-of-the-art\nperformance, with significant improvements in accuracy and robustness for SCD\ntask.", "AI": {"tldr": "GAPL-SCD \u901a\u8fc7\u56fe\u805a\u5408\u539f\u578b\u5b66\u4e60\u548c\u591a\u4efb\u52a1\u4f18\u5316\u6765\u89e3\u51b3\u9065\u611f\u6570\u636e\u4e2d\u7684\u8bed\u4e49\u53d8\u5316\u68c0\u6d4b\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u7531\u4e8e SCD \u6d89\u53ca\u591a\u4efb\u52a1\u7684\u8054\u5408\u4f18\u5316\uff0c\u6a21\u578b\u5bb9\u6613\u56e0\u7279\u5b9a\u4efb\u52a1\u7684\u5b66\u4e60\u56f0\u96be\u548c\u51b2\u7a81\u7684\u68af\u5ea6\u6d41\u800c\u4ea7\u751f\u8d1f\u8fc1\u79fb\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a GAPL-SCD \u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u8bbe\u8ba1\u4e86\u4e00\u79cd\u591a\u4efb\u52a1\u8054\u5408\u4f18\u5316\u65b9\u6cd5\uff0c\u4ee5\u4f18\u5316\u8bed\u4e49\u5206\u5272\u548c\u53d8\u5316\u68c0\u6d4b\u7684\u4e3b\u8981\u4efb\u52a1\uff0c\u4ee5\u53ca\u56fe\u805a\u5408\u539f\u578b\u5b66\u4e60\u7684\u8f85\u52a9\u4efb\u52a1\u3002\u901a\u8fc7\u81ea\u67e5\u8be2\u591a\u5c42\u6b21\u7279\u5f81\u4ea4\u4e92\u548c\u53cc\u65f6\u76f8\u7279\u5f81\u878d\u5408\u6a21\u5757\u8fdb\u4e00\u6b65\u589e\u5f3a\u4e86\u591a\u5c3a\u5ea6\u7279\u5f81\u8868\u793a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728 SECOND \u548c Landsat-SCD \u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5728 SCD \u4efb\u52a1\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u6709\u663e\u8457\u7684\u63d0\u9ad8\u3002", "conclusion": "GAPL-SCD \u5728 SECOND \u548c Landsat-SCD \u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5728 SCD \u4efb\u52a1\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u6709\u663e\u8457\u7684\u63d0\u9ad8\u3002"}}
{"id": "2507.10923", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10923", "abs": "https://arxiv.org/abs/2507.10923", "authors": ["Yuhao Wang", "Keyan Ding", "Kehua Feng", "Zeyuan Wang", "Ming Qin", "Xiaotong Li", "Qiang Zhang", "Huajun Chen"], "title": "Enhancing Safe and Controllable Protein Generation via Knowledge Preference Optimization", "comment": "Accepted at ACL 2025 (Main Conference)", "summary": "Protein language models have emerged as powerful tools for sequence\ngeneration, offering substantial advantages in functional optimization and\ndenovo design. However, these models also present significant risks of\ngenerating harmful protein sequences, such as those that enhance viral\ntransmissibility or evade immune responses. These concerns underscore critical\nbiosafety and ethical challenges. To address these issues, we propose a\nKnowledge-guided Preference Optimization (KPO) framework that integrates prior\nknowledge via a Protein Safety Knowledge Graph. This framework utilizes an\nefficient graph pruning strategy to identify preferred sequences and employs\nreinforcement learning to minimize the risk of generating harmful proteins.\nExperimental results demonstrate that KPO effectively reduces the likelihood of\nproducing hazardous sequences while maintaining high functionality, offering a\nrobust safety assurance framework for applying generative models in\nbiotechnology.", "AI": {"tldr": "KPO\u6846\u67b6\u901a\u8fc7\u6574\u5408\u77e5\u8bc6\u56fe\u8c31\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u5728\u5229\u7528\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bbe\u8ba1\u7684\u540c\u65f6\uff0c\u89e3\u51b3\u4e86\u5176\u6f5c\u5728\u7684\u751f\u7269\u5b89\u5168\u548c\u4f26\u7406\u98ce\u9669\u3002", "motivation": "\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u5728\u5e8f\u5217\u751f\u6210\u65b9\u9762\u5c55\u73b0\u51fa\u5f3a\u5927\u6f5c\u529b\uff0c\u53ef\u7528\u4e8e\u529f\u80fd\u4f18\u5316\u548c\u4ece\u5934\u8bbe\u8ba1\uff0c\u4f46\u4e5f\u5b58\u5728\u751f\u6210\u589e\u5f3a\u75c5\u6bd2\u4f20\u64ad\u6216\u9003\u907f\u514d\u75ab\u5e94\u7b54\u7b49\u6709\u5bb3\u86cb\u767d\u8d28\u5e8f\u5217\u7684\u91cd\u5927\u98ce\u9669\uff0c\u5f15\u53d1\u4e86\u751f\u7269\u5b89\u5168\u548c\u4f26\u7406\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u77e5\u8bc6\u5f15\u5bfc\u7684\u504f\u597d\u4f18\u5316\uff08KPO\uff09\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u86cb\u767d\u8d28\u5b89\u5168\u77e5\u8bc6\u56fe\u8c31\u6574\u5408\u5148\u9a8c\u77e5\u8bc6\uff0c\u5e76\u91c7\u7528\u56fe\u4fee\u526a\u7b56\u7565\u8bc6\u522b\u4f18\u9009\u5e8f\u5217\uff0c\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u6700\u5c0f\u5316\u751f\u6210\u6709\u5bb3\u86cb\u767d\u8d28\u7684\u98ce\u9669\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cKPO\u6846\u67b6\u80fd\u6709\u6548\u964d\u4f4e\u751f\u6210\u5371\u9669\u5e8f\u5217\u7684\u53ef\u80fd\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u529f\u80fd\u6027\u3002", "conclusion": "KPO\u6846\u67b6\u901a\u8fc7\u6574\u5408\u86cb\u767d\u8d28\u5b89\u5168\u77e5\u8bc6\u56fe\u8c31\u548c\u5229\u7528\u56fe\u4fee\u526a\u7b56\u7565\u4e0e\u5f3a\u5316\u5b66\u4e60\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u751f\u6210\u6709\u5bb3\u86cb\u767d\u8d28\u5e8f\u5217\u7684\u98ce\u9669\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u86cb\u767d\u8d28\u7684\u9ad8\u529f\u80fd\u6027\uff0c\u4e3a\u751f\u7269\u6280\u672f\u4e2d\u5e94\u7528\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u5b89\u5168\u4fdd\u969c\u6846\u67b6\u3002"}}
{"id": "2507.10957", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10957", "abs": "https://arxiv.org/abs/2507.10957", "authors": ["Kalit Inani", "Keshav Kabra", "Vijay Marupudi", "Sashank Varma"], "title": "Modeling Understanding of Story-Based Analogies Using Large Language Models", "comment": "To appear at CogSci 2025", "summary": "Recent advancements in Large Language Models (LLMs) have brought them closer\nto matching human cognition across a variety of tasks. How well do these models\nalign with human performance in detecting and mapping analogies? Prior research\nhas shown that LLMs can extract similarities from analogy problems but lack\nrobust human-like reasoning. Building on Webb, Holyoak, and Lu (2023), the\ncurrent study focused on a story-based analogical mapping task and conducted a\nfine-grained evaluation of LLM reasoning abilities compared to human\nperformance. First, it explored the semantic representation of analogies in\nLLMs, using sentence embeddings to assess whether they capture the similarity\nbetween the source and target texts of an analogy, and the dissimilarity\nbetween the source and distractor texts. Second, it investigated the\neffectiveness of explicitly prompting LLMs to explain analogies. Throughout, we\nexamine whether LLMs exhibit similar performance profiles to those observed in\nhumans by evaluating their reasoning at the level of individual analogies, and\nnot just at the level of overall accuracy (as prior studies have done). Our\nexperiments include evaluating the impact of model size (8B vs. 70B parameters)\nand performance variation across state-of-the-art model architectures such as\nGPT-4 and LLaMA3. This work advances our understanding of the analogical\nreasoning abilities of LLMs and their potential as models of human reasoning.", "AI": {"tldr": "LLMs\u5728\u7c7b\u6bd4\u63a8\u7406\u65b9\u9762\u4e0e\u4eba\u7c7b\u7684\u5339\u914d\u5ea6\u4e0d\u5982\u9884\u671f\uff0c\u5c24\u5176\u5728\u7cbe\u7ec6\u5316\u63a8\u7406\u548c\u89e3\u91ca\u65b9\u9762\u5b58\u5728\u5dee\u8ddd\u3002", "motivation": "\u63a2\u8ba8\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u68c0\u6d4b\u548c\u6620\u5c04\u7c7b\u6bd4\u65b9\u9762\u7684\u80fd\u529b\u662f\u5426\u4e0e\u4eba\u7c7b\u76f8\u5f53\uff0c\u4ee5\u53ca\u5b83\u4eec\u5728\u7c7b\u6bd4\u63a8\u7406\u65b9\u9762\u662f\u5426\u5c55\u73b0\u51fa\u7c7b\u4f3c\u4eba\u7c7b\u7684\u8868\u73b0\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u5206\u6790LLMs\u7684\u8bed\u4e49\u8868\u5f81\u548c\u663e\u5f0f\u63d0\u793a\u6765\u8bc4\u4f30\u5176\u7c7b\u6bd4\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u4e0e\u4eba\u7c7b\u8868\u73b0\u8fdb\u884c\u5bf9\u6bd4\uff0c\u540c\u65f6\u8003\u5bdf\u4e86\u6a21\u578b\u89c4\u6a21\u548c\u67b6\u6784\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cLLMs\u5728\u6355\u6349\u7c7b\u6bd4\u7684\u76f8\u4f3c\u6027\u548c\u5dee\u5f02\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u5e76\u4e14\u663e\u5f0f\u63d0\u793a\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u53ef\u4ee5\u63d0\u5347\u5176\u7c7b\u6bd4\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u4ecd\u9700\u4e0e\u4eba\u7c7b\u8868\u73b0\u8fdb\u884c\u7ec6\u81f4\u7684\u5bf9\u6bd4\u3002", "conclusion": "LLMs\u5728\u7406\u89e3\u548c\u751f\u6210\u7c7b\u6bd4\u65b9\u9762\u4e0e\u4eba\u7c7b\u7684\u76f8\u4f3c\u6027\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\uff0c\u5c24\u5176\u662f\u5728\u4e2a\u4f53\u7c7b\u6bd4\u63a8\u7406\u548c\u89e3\u91ca\u65b9\u9762\u3002"}}
{"id": "2507.11447", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.11447", "abs": "https://arxiv.org/abs/2507.11447", "authors": ["Shuo Yang", "John Z. Zhang", "Ibrahima Sory Sow", "Zachary Manchester"], "title": "Multi-IMU Sensor Fusion for Legged Robots", "comment": "16 pages", "summary": "This paper presents a state-estimation solution for legged robots that uses a\nset of low-cost, compact, and lightweight sensors to achieve low-drift pose and\nvelocity estimation under challenging locomotion conditions. The key idea is to\nleverage multiple inertial measurement units on different links of the robot to\ncorrect a major error source in standard proprioceptive odometry. We fuse the\ninertial sensor information and joint encoder measurements in an extended\nKalman filter, then combine the velocity estimate from this filter with camera\ndata in a factor-graph-based sliding-window estimator to form a\nvisual-inertial-leg odometry method. We validate our state estimator through\ncomprehensive theoretical analysis and hardware experiments performed using\nreal-world robot data collected during a variety of challenging locomotion\ntasks. Our algorithm consistently achieves minimal position deviation, even in\nscenarios involving substantial ground impact, foot slippage, and sudden body\nrotations. A C++ implementation, along with a large-scale dataset, is available\nat https://github.com/ShuoYangRobotics/Cerberus2.0.", "AI": {"tldr": "\u4e00\u79cd\u7528\u4e8e\u6709\u817f\u673a\u5668\u4eba\u7684\u72b6\u6001\u4f30\u8ba1\u89e3\u51b3\u65b9\u6848\uff0c\u5229\u7528\u4f4e\u6210\u672c\u4f20\u611f\u5668\u548c\u591aIMU\u6570\u636e\uff0c\u901a\u8fc7\u89c6\u89c9-\u60ef\u6027-\u817f\u90e8\u91cc\u7a0b\u8ba1\u5b9e\u73b0\u4f4e\u6f02\u79fb\u59ff\u6001\u548c\u901f\u5ea6\u4f30\u8ba1\u3002", "motivation": "\u4e3a\u4e86\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u8fd0\u52a8\u6761\u4ef6\u4e0b\uff0c\u5229\u7528\u4e00\u7ec4\u4f4e\u6210\u672c\u3001\u7d27\u51d1\u3001\u8f7b\u4fbf\u7684\u4f20\u611f\u5668\uff0c\u4e3a\u6709\u817f\u673a\u5668\u4eba\u5b9e\u73b0\u4f4e\u6f02\u79fb\u7684\u59ff\u6001\u548c\u901f\u5ea6\u4f30\u8ba1\u3002", "method": "\u8be5\u65b9\u6cd5\u878d\u5408\u4e86\u591a\u7ec4\u60ef\u6027\u6d4b\u91cf\u5355\u5143\uff08IMU\uff09\u6570\u636e\u548c\u5173\u8282\u7f16\u7801\u5668\u6d4b\u91cf\u503c\uff0c\u5e76\u5229\u7528\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\uff08EKF\uff09\u8fdb\u884c\u72b6\u6001\u4f30\u8ba1\u3002\u7136\u540e\uff0c\u5c06\u8be5\u6ee4\u6ce2\u5668\u7684\u901f\u5ea6\u4f30\u8ba1\u4e0e\u76f8\u673a\u6570\u636e\u878d\u5408\uff0c\u5f62\u6210\u4e00\u4e2a\u57fa\u4e8e\u56e0\u5b50\u56fe\u7684\u6ed1\u52a8\u7a97\u53e3\u4f30\u8ba1\u5668\uff0c\u4ece\u800c\u5b9e\u73b0\u89c6\u89c9-\u60ef\u6027-\u817f\u90e8\u91cc\u7a0b\u8ba1\u3002", "result": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5168\u9762\u7684\u7406\u8bba\u5206\u6790\u548c\u4f7f\u7528\u771f\u5b9e\u673a\u5668\u4eba\u6570\u636e\u8fdb\u884c\u7684\u786c\u4ef6\u5b9e\u9a8c\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u5728\u591a\u79cd\u5177\u6709\u6311\u6218\u6027\u7684\u8fd0\u52a8\u4efb\u52a1\u4e2d\uff0c\u5b9e\u73b0\u4e86\u6700\u5c0f\u7684\u4f4d\u7f6e\u504f\u5dee\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u5728\u6d89\u53ca\u5927\u91cf\u5730\u9762\u649e\u51fb\u3001\u811a\u90e8\u6253\u6ed1\u548c\u8eab\u4f53\u7a81\u7136\u65cb\u8f6c\u7684\u60c5\u51b5\u4e0b\uff0c\u5373\u4f7f\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u79fb\u52a8\u4efb\u52a1\u4e2d\uff0c\u4e5f\u80fd\u6301\u7eed\u5b9e\u73b0\u6700\u5c0f\u7684\u4f4d\u7f6e\u504f\u5dee\u3002"}}
{"id": "2507.10619", "categories": ["cs.LG", "cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2507.10619", "abs": "https://arxiv.org/abs/2507.10619", "authors": ["Oluwaseyi Giwa", "Tobi Awodunmila", "Muhammad Ahmed Mohsin", "Ahsan Bilal", "Muhammad Ali Jamshed"], "title": "Meta-Reinforcement Learning for Fast and Data-Efficient Spectrum Allocation in Dynamic Wireless Networks", "comment": "5 pages, 6 figures, under review at IEEE Wireless Communications\n  Letters", "summary": "The dynamic allocation of spectrum in 5G / 6G networks is critical to\nefficient resource utilization. However, applying traditional deep\nreinforcement learning (DRL) is often infeasible due to its immense sample\ncomplexity and the safety risks associated with unguided exploration, which can\ncause severe network interference. To address these challenges, we propose a\nmeta-learning framework that enables agents to learn a robust initial policy\nand rapidly adapt to new wireless scenarios with minimal data. We implement\nthree meta-learning architectures, model-agnostic meta-learning (MAML),\nrecurrent neural network (RNN), and an attention-enhanced RNN, and evaluate\nthem against a non-meta-learning DRL algorithm, proximal policy optimization\n(PPO) baseline, in a simulated dynamic integrated access/backhaul (IAB)\nenvironment. Our results show a clear performance gap. The attention-based\nmeta-learning agent reaches a peak mean network throughput of 48 Mbps, while\nthe PPO baseline decreased drastically to 10 Mbps. Furthermore, our method\nreduces SINR and latency violations by more than 50% compared to PPO. It also\nshows quick adaptation, with a fairness index 0.7, showing better resource\nallocation. This work proves that meta-learning is a very effective and safer\noption for intelligent control in complex wireless systems.", "AI": {"tldr": "\u5143\u5b66\u4e60\u6846\u67b6\u901a\u8fc7MAML\u3001RNN\u548c\u589e\u5f3a\u578bRNN\u67b6\u6784\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfDRL\u57285G/6G\u7f51\u7edc\u52a8\u6001\u9891\u8c31\u5206\u914d\u4e2d\u7684\u6837\u672c\u590d\u6742\u6027\u548c\u5b89\u5168\u98ce\u9669\u95ee\u9898\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5143\u5b66\u4e60\u65b9\u6cd5\u5728\u7f51\u7edc\u541e\u5410\u91cf\u3001SINR\u3001\u5ef6\u8fdf\u548c\u516c\u5e73\u6027\u65b9\u9762\u5747\u4f18\u4e8ePPO\u57fa\u7ebf\uff0c\u662f\u4e00\u79cd\u66f4\u6709\u6548\u3001\u66f4\u5b89\u5168\u7684\u667a\u80fd\u63a7\u5236\u9009\u62e9\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4f20\u7edf\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u57285G/6G\u7f51\u7edc\u52a8\u6001\u9891\u8c31\u5206\u914d\u4e2d\u9762\u4e34\u7684\u5de8\u5927\u6837\u672c\u590d\u6742\u6027\u548c\u65e0\u6307\u5bfc\u63a2\u7d22\u5e26\u6765\u7684\u5b89\u5168\u98ce\u9669\uff08\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u7684\u7f51\u7edc\u5e72\u6270\uff09\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5143\u5b66\u4e60\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u4ee3\u7406\u7684\u9c81\u68d2\u521d\u59cb\u7b56\u7565\u5b66\u4e60\uff0c\u5e76\u80fd\u5728\u6570\u636e\u91cf\u6700\u5c11\u7684\u60c5\u51b5\u4e0b\u5feb\u901f\u9002\u5e94\u65b0\u7684\u65e0\u7ebf\u573a\u666f\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5b9e\u73b0\u4e86\u4e09\u79cd\u5143\u5b66\u4e60\u67b6\u6784\uff1a\u6a21\u578b\u65e0\u5173\u5143\u5b66\u4e60\uff08MAML\uff09\u3001\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff08RNN\uff09\u548c\u589e\u5f3a\u578bRNN\u3002", "result": "\u4e0e\u4ec5\u4f7f\u7528\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08PPO\uff09\u57fa\u7ebf\u7684\u975e\u5143\u5b66\u4e60DRL\u7b97\u6cd5\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u5143\u5b66\u4e60\u65b9\u6cd5\u5728\u6a21\u62df\u7684\u52a8\u6001\u96c6\u6210\u63a5\u5165/\u56de\u4f20\uff08IAB\uff09\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u660e\u663e\u7684\u6027\u80fd\u4f18\u52bf\u3002\u5177\u4f53\u800c\u8a00\uff0c\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u5143\u5b66\u4e60\u4ee3\u7406\u8fbe\u5230\u4e8648 Mbps\u7684\u5cf0\u503c\u5e73\u5747\u7f51\u7edc\u541e\u5410\u91cf\uff0c\u800cPPO\u57fa\u7ebf\u5219\u4e0b\u964d\u81f310 Mbps\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u5c06\u4fe1\u566a\u6bd4\uff08SINR\uff09\u548c\u5ef6\u8fdf\u8fdd\u89c4\u6b21\u6570\u51cf\u5c11\u4e8650%\u4ee5\u4e0a\uff0c\u516c\u5e73\u6027\u6307\u6570\u8fbe\u5230\u4e860.7\uff0c\u8868\u660e\u5176\u5728\u8d44\u6e90\u5206\u914d\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u5e76\u80fd\u5feb\u901f\u9002\u5e94\u65b0\u73af\u5883\u3002", "conclusion": "\u5143\u5b66\u4e60\u662f\u4e00\u79cd\u5728\u590d\u6742\u65e0\u7ebf\u7cfb\u7edf\u4e2d\u8fdb\u884c\u667a\u80fd\u63a7\u5236\u7684\u6709\u6548\u4e14\u66f4\u5b89\u5168\u7684\u9009\u62e9\u3002"}}
{"id": "2507.11001", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11001", "abs": "https://arxiv.org/abs/2507.11001", "authors": ["Yanbo Wang", "Zipeng Fang", "Lei Zhao", "Weidong Chen"], "title": "Learning to Tune Like an Expert: Interpretable and Scene-Aware Navigation via MLLM Reasoning and CVAE-Based Adaptation", "comment": null, "summary": "Service robots are increasingly deployed in diverse and dynamic environments,\nwhere both physical layouts and social contexts change over time and across\nlocations. In these unstructured settings, conventional navigation systems that\nrely on fixed parameters often fail to generalize across scenarios, resulting\nin degraded performance and reduced social acceptance. Although recent\napproaches have leveraged reinforcement learning to enhance traditional\nplanners, these methods often fail in real-world deployments due to poor\ngeneralization and limited simulation diversity, which hampers effective\nsim-to-real transfer. To tackle these issues, we present LE-Nav, an\ninterpretable and scene-aware navigation framework that leverages multi-modal\nlarge language model reasoning and conditional variational autoencoders to\nadaptively tune planner hyperparameters. To achieve zero-shot scene\nunderstanding, we utilize one-shot exemplars and chain-of-thought prompting\nstrategies. Additionally, a conditional variational autoencoder captures the\nmapping between natural language instructions and navigation hyperparameters,\nenabling expert-level tuning. Experiments show that LE-Nav can generate\nhyperparameters achieving human-level tuning across diverse planners and\nscenarios. Real-world navigation trials and a user study on a smart wheelchair\nplatform demonstrate that it outperforms state-of-the-art methods on\nquantitative metrics such as success rate, efficiency, safety, and comfort,\nwhile receiving higher subjective scores for perceived safety and social\nacceptance. Code is available at https://github.com/Cavendish518/LE-Nav.", "AI": {"tldr": "LE-Nav \u4f7f\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u548c\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\u6765\u52a8\u6001\u8c03\u6574\u5bfc\u822a\u8d85\u53c2\u6570\uff0c\u4ee5\u63d0\u9ad8\u670d\u52a1\u673a\u5668\u4eba\u5728\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u7684\u5bfc\u822a\u6027\u80fd\u548c\u7528\u6237\u63a5\u53d7\u5ea6\u3002", "motivation": "\u670d\u52a1\u673a\u5668\u4eba\u5728\u591a\u6837\u5316\u548c\u52a8\u6001\u5316\u7684\u73af\u5883\u4e2d\u90e8\u7f72\u65e5\u76ca\u5e7f\u6cdb\uff0c\u8fd9\u4e9b\u73af\u5883\u4e2d\u7684\u7269\u7406\u5e03\u5c40\u548c\u793e\u4f1a\u80cc\u666f\u4f1a\u968f\u7740\u65f6\u95f4\u63a8\u79fb\u548c\u5730\u70b9\u53d8\u5316\u3002\u5728\u8fd9\u4e9b\u975e\u7ed3\u6784\u5316\u573a\u666f\u4e2d\uff0c\u4f9d\u8d56\u56fa\u5b9a\u53c2\u6570\u7684\u4f20\u7edf\u5bfc\u822a\u7cfb\u7edf\u5f80\u5f80\u65e0\u6cd5\u8de8\u573a\u666f\u6cdb\u5316\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u548c\u793e\u4f1a\u63a5\u53d7\u5ea6\u964d\u4f4e\u3002\u5c3d\u7ba1\u8fd1\u671f\u7684\u65b9\u6cd5\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u6765\u589e\u5f3a\u4f20\u7edf\u89c4\u5212\u5668\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u7531\u4e8e\u6cdb\u5316\u80fd\u529b\u5dee\u548c\u4eff\u771f\u73af\u5883\u591a\u6837\u6027\u6709\u9650\uff0c\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u5e38\u5e38\u5931\u8d25\uff0c\u963b\u788d\u4e86\u6709\u6548\u7684\u4eff\u771f\u5230\u73b0\u5b9e\u8fc1\u79fb\u3002", "method": "LE-Nav \u662f\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u3001\u573a\u666f\u611f\u77e5\u7684\u5bfc\u822a\u6846\u67b6\uff0c\u5b83\u5229\u7528\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u548c\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\u6765\u9002\u5e94\u6027\u5730\u8c03\u6574\u89c4\u5212\u5668\u8d85\u53c2\u6570\u3002\u4e3a\u4e86\u5b9e\u73b0\u96f6\u6b21\u573a\u666f\u7406\u89e3\uff0c\u6211\u4eec\u4f7f\u7528\u4e86\u5355\u6b21\u793a\u4f8b\u548c\u601d\u7ef4\u94fe\u63d0\u793a\u7b56\u7565\u3002\u6b64\u5916\uff0c\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\u6355\u83b7\u4e86\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u548c\u5bfc\u822a\u8d85\u53c2\u6570\u4e4b\u95f4\u7684\u6620\u5c04\u5173\u7cfb\uff0c\u5b9e\u73b0\u4e86\u4e13\u5bb6\u7ea7\u7684\u8c03\u6574\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cLE-Nav \u80fd\u591f\u751f\u6210\u8d85\u53c2\u6570\uff0c\u5728\u5404\u79cd\u89c4\u5212\u5668\u548c\u573a\u666f\u4e2d\u5b9e\u73b0\u4eba\u7c7b\u6c34\u5e73\u7684\u8c03\u6574\u3002\u5728\u667a\u80fd\u8f6e\u6905\u5e73\u53f0\u4e0a\u7684\u771f\u5b9e\u5bfc\u822a\u8bd5\u9a8c\u548c\u7528\u6237\u7814\u7a76\u8868\u660e\uff0cLE-Nav \u5728\u6210\u529f\u7387\u3001\u6548\u7387\u3001\u5b89\u5168\u6027\u4ee5\u53ca\u8212\u9002\u5ea6\u7b49\u91cf\u5316\u6307\u6807\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u5e76\u5728\u611f\u77e5\u7684\u5b89\u5168\u6027\u548c\u793e\u4f1a\u63a5\u53d7\u5ea6\u65b9\u9762\u83b7\u5f97\u66f4\u9ad8\u7684\u4e3b\u89c2\u8bc4\u5206\u3002", "conclusion": "LE-Nav \u5728\u5404\u79cd\u89c4\u5212\u5668\u548c\u573a\u666f\u4e2d\u5b9e\u73b0\u4e86\u8fbe\u5230\u4eba\u7c7b\u6c34\u5e73\u7684\u8d85\u53c2\u6570\u8c03\u6574\u3002\u5728\u667a\u80fd\u8f6e\u6905\u5e73\u53f0\u4e0a\u7684\u771f\u5b9e\u5bfc\u822a\u8bd5\u9a8c\u548c\u7528\u6237\u7814\u7a76\u8868\u660e\uff0cLE-Nav \u5728\u6210\u529f\u7387\u3001\u6548\u7387\u3001\u5b89\u5168\u6027 serta \u8212\u9002\u5ea6\u7b49\u91cf\u5316\u6307\u6807\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u5e76\u5728\u611f\u77e5\u7684\u5b89\u5168\u6027\u548c\u793e\u4f1a\u63a5\u53d7\u5ea6\u65b9\u9762\u83b7\u5f97\u66f4\u9ad8\u7684\u4e3b\u89c2\u8bc4\u5206\u3002"}}
{"id": "2507.11374", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.11374", "abs": "https://arxiv.org/abs/2507.11374", "authors": ["Thorbj\u00f8rn Skovhus", "Varun Rajeev Pavizhakumari", "Thomas Olsen"], "title": "Implementation of the magnetic force theorem for large-scale calculations of magnon bands: application to yttrium iron garnet", "comment": "14 pages, 4 figures, 1 table", "summary": "We present an efficient implementation of the magnetic force theorem which\nallows for direct evaluation of exchange parameters in q-space. The exchange\nparameters are calculated directly from Bloch states and the implementation\ndoes not rely on any mapping onto localized orbitals. This renders the approach\nwell suited for high-throughput computations, where the construction of a\nlocalized basis set (for example Wannier functions) often is impractical. We\ndemonstrate the versatility of the method by applying it to yttrium iron\ngarnet, where we obtain excellent agreement with the experimental magnon\ndispersion without any prior assumptions of important exchange pathways. In\nparticular, the calculations reveal the existence of several inequivalent\nexchange pathways associated with the same interatomic distances. Performing\nsuch calculations in q-space fully accounts for long-range exchange\ninteractions and provides a convenient route for validating models obtained by\nfitting to inelastic neutron scattering data.", "AI": {"tldr": "An efficient method to calculate exchange parameters in q-space using Bloch states, validated on yttrium iron garnet, showing good agreement with experiments and revealing complex exchange pathways.", "motivation": "To present an efficient implementation of the magnetic force theorem for direct evaluation of exchange parameters in q-space, suitable for high-throughput computations.", "method": "The exchange parameters are calculated directly from Bloch states without relying on any mapping onto localized orbitals.", "result": "The method was applied to yttrium iron garnet, showing excellent agreement with experimental magnon dispersion. The calculations revealed multiple inequivalent exchange pathways for the same interatomic distances, fully accounting for long-range interactions.", "conclusion": "We present an efficient implementation of the magnetic force theorem which allows for direct evaluation of exchange parameters in q-space, well suited for high-throughput computations."}}
{"id": "2507.11182", "categories": ["cond-mat.mes-hall", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.11182", "abs": "https://arxiv.org/abs/2507.11182", "authors": ["Yujun Wang", "Shunzhen Wang", "Masashi Kawaguchi", "Jun Uzuhashi", "Akhilesh Kumar Patel", "Kenji Nawa", "Yuya Sakuraba", "Tadakatsu Ohkubo", "Hiroshi Kohno", "Masamitsu Hayashi"], "title": "Significant electron-magnon scattering in layered ferromagnet Cr$_2$Te$_3$", "comment": null, "summary": "A layered ferromagnet Cr$_2$Te$_3$ is attracting growing interest because of\nits unique electronic and magnetic properties. Studies have shown that it\nexhibits sizable anomalous Hall effect (AHE) that changes sign with\ntemperature. The origin of the AHE and the sign change, however, remains\nelusive. Here we show experimentally that electron-magnon scattering\nsignificantly contributes to the AHE in Cr$_2$Te$_3$ through magnon induced\nskew scattering, and that the sign change is caused by the competition with the\nBerry-curvature or impurity-induced side-jump contribution. The electron-magnon\nskew scattering is expected to arise from the exchange interaction between the\nitinerant Te $p$-electrons and the localized Cr $d$-electrons modified by the\nstrong spin-orbit coupling on Te. These results suggest that the magnon-induced\nskew scattering can dominate the AHE in layered ferromagnets with heavy\nelements.", "AI": {"tldr": "\u0412 Cr$_{2}$Te$_{3}$ \u0430\u043d\u043e\u043c\u0430\u043b\u044c\u043d\u044b\u0439 \u0445\u043e\u043b\u043b\u043e\u0432\u0441\u043a\u0438\u0439 \u044d\u0444\u0444\u0435\u043a\u0442 \u0432\u043e\u0437\u043d\u0438\u043a\u0430\u0435\u0442 \u0438\u0437-\u0437\u0430 \u0440\u0430\u0441\u0441\u0435\u044f\u043d\u0438\u044f \u044d\u043b\u0435\u043a\u0442\u0440\u043e\u043d\u043e\u0432 \u043d\u0430 \u043c\u0430\u0433\u043d\u0438\u0442\u043e\u043d\u0430\u0445, \u0430 \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u0435 \u0437\u043d\u0430\u043a\u0430 \u0441\u0432\u044f\u0437\u0430\u043d\u043e \u0441 \u043a\u043e\u043d\u043a\u0443\u0440\u0435\u043d\u0446\u0438\u0435\u0439 \u0441 \u044f\u0433\u043e\u0434\u0430\u043c\u0438/\u043f\u0440\u0438\u043c\u0435\u0441\u044f\u043c\u0438.", "motivation": "\u041d\u0435\u0438\u0437\u0432\u0435\u0441\u0442\u043d\u043e\u0441\u0442\u044c \u043f\u0440\u043e\u0438\u0441\u0445\u043e\u0436\u0434\u0435\u043d\u0438\u044f \u0430\u043d\u043e\u043c\u0430\u043b\u044c\u043d\u043e\u0433\u043e \u0445\u043e\u043b\u043b\u043e\u0432\u0441\u043a\u043e\u0433\u043e \u044d\u0444\u0444\u0435\u043a\u0442\u0430 \u0438 \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u044f \u0435\u0433\u043e \u0437\u043d\u0430\u043a\u0430 \u0432 \u0441\u043b\u043e\u0438\u0441\u0442\u043e\u043c \u0444\u0435\u0440\u0440\u043e\u043c\u0430\u0433\u043d\u0435\u0442\u0438\u043a\u0435 Cr$_{2}$Te$_{3}$, \u043d\u0435\u0441\u043c\u043e\u0442\u0440\u044f \u043d\u0430 \u0435\u0433\u043e \u0443\u043d\u0438\u043a\u0430\u043b\u044c\u043d\u044b\u0435 \u044d\u043b\u0435\u043a\u0442\u0440\u043e\u043d\u043d\u044b\u0435 \u0438 \u043c\u0430\u0433\u043d\u0438\u0442\u043d\u044b\u0435 \u0441\u0432\u043e\u0439\u0441\u0442\u0432\u0430.", "method": "\u042d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u0430\u043b\u044c\u043d\u043e \u043f\u043e\u043a\u0430\u0437\u0430\u043d\u043e, \u0447\u0442\u043e \u0440\u0430\u0441\u0441\u0435\u044f\u043d\u0438\u0435 \u044d\u043b\u0435\u043a\u0442\u0440\u043e\u043d\u043e\u0432 \u043d\u0430 \u043c\u0430\u0433\u043d\u0438\u0442\u043e\u043d\u0430\u0445 \u0437\u043d\u0430\u0447\u0438\u0442\u0435\u043b\u044c\u043d\u043e \u0432\u043b\u0438\u044f\u0435\u0442 \u043d\u0430 \u0430\u043d\u043e\u043c\u0430\u043b\u044c\u043d\u044b\u0439 \u0445\u043e\u043b\u043b\u043e\u0432\u0441\u043a\u0438\u0439 \u044d\u0444\u0444\u0435\u043a\u0442 \u0432 Cr$_{2}$Te$_{3}$ \u0437\u0430 \u0441\u0447\u0435\u0442 \u0438\u043d\u0434\u0443\u0446\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0433\u043e \u043c\u0430\u0433\u043d\u0438\u0442\u043e\u043d\u0430\u043c\u0438 \u0441\u043c\u0435\u0449\u0435\u043d\u0438\u044f.", "result": "\u041f\u0440\u0435\u0434\u043b\u0430\u0433\u0430\u0435\u0442\u0441\u044f, \u0447\u0442\u043e \u0438\u043d\u0434\u0443\u0446\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0435 \u043c\u0430\u0433\u043d\u0438\u0442\u043e\u043d\u0430\u043c\u0438 \u0441\u043c\u0435\u0449\u0435\u043d\u0438\u0435 \u043c\u043e\u0436\u0435\u0442 \u0434\u043e\u043c\u0438\u043d\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0432 \u0430\u043d\u043e\u043c\u0430\u043b\u044c\u043d\u043e\u043c \u0445\u043e\u043b\u043b\u043e\u0432\u0441\u043a\u043e\u043c \u044d\u0444\u0444\u0435\u043a\u0442\u0435 \u0432 \u0441\u043b\u043e\u0438\u0441\u0442\u044b\u0445 \u0444\u0435\u0440\u0440\u043e\u043c\u0430\u0433\u043d\u0435\u0442\u0438\u043a\u0430\u0445 \u0441 \u0442\u044f\u0436\u0435\u043b\u044b\u043c\u0438 \u044d\u043b\u0435\u043c\u0435\u043d\u0442\u0430\u043c\u0438.", "conclusion": "\u7535\u5b50-\u78c1\u7574\u043e\u0442\u043d\u043e\u0441\u044f\u0442\u0441\u044f \u043a \u0430\u043d\u043e\u043c\u0430\u043b\u044c\u043d\u043e\u043c\u0443 \u0445\u043e\u043b\u043b\u043e\u0432\u0441\u043a\u043e\u043c\u0443 \u044d\u0444\u0444\u0435\u043a\u0442\u0443 \u0432 Cr$_{2}$Te$_{3}$ \u0447\u0435\u0440\u0435\u0437 \u0438\u043d\u0434\u0443\u0446\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0435 \u043c\u0430\u0433\u043d\u0438\u0442\u043e\u043d\u0430\u043c\u0438 \u0441\u043c\u0435\u0449\u0435\u043d\u0438\u0435, \u0438 \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u0435 \u0437\u043d\u0430\u043a\u0430 \u0432\u044b\u0437\u0432\u0430\u043d\u043e \u043a\u043e\u043d\u043a\u0443\u0440\u0435\u043d\u0446\u0438\u0435\u0439 \u0441 \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u043e\u043c, \u0432\u044b\u0437\u0432\u0430\u043d\u043d\u044b\u043c \u044f\u0433\u043e\u0434\u0430\u043c\u0438 \u0438\u043b\u0438 \u043f\u0440\u0438\u043c\u0435\u0441\u044f\u043c\u0438."}}
{"id": "2507.10856", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.stat-mech", "cond-mat.supr-con", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2507.10856", "abs": "https://arxiv.org/abs/2507.10856", "authors": ["Suvendu Barik", "Lieuwe Bakker", "Vladimir Gritsev", "Ji\u0159\u00ed Min\u00e1\u0159", "Emil A. Yuzbashyan"], "title": "Higher spin Richardson-Gaudin model with time-dependent coupling: Exact dynamics", "comment": "28 pages, 18 figures", "summary": "We determine the exact asymptotic many-body wavefunction of a spin-$s$\nRichardson-Gaudin model with a coupling inversely proportional to time, for\ntime evolution starting from the ground state at $t = 0^+$ and for arbitrary\n$s$. Contrary to common belief, the resulting wavefunction cannot be derived\nfrom the spin-$1/2$ case by merging spins, but instead requires independent\ntreatment for each spin size. The steady state is non-thermal and, in contrast\nto the spin-$1/2$ case, does not conform to a natural Generalized Gibbs\nEnsemble. We show that mean-field theory is exact for any product of a finite\nnumber of spin operators on different sites. We discuss how these findings can\nbe probed in cavity QED and trapped ion experiments.", "AI": {"tldr": "\u8be5\u7814\u7a76\u786e\u5b9a\u4e86\u81ea\u65cb Richardson-Gaudin \u6a21\u578b\u7684\u7cbe\u786e\u6e10\u8fd1\u591a\u4f53\u6ce2\u51fd\u6570\uff0c\u53d1\u73b0\u5176\u7a33\u6001\u662f\u975e\u70ed\u7684\uff0c\u5e76\u4e14\u4e0d\u7b26\u5408\u5e7f\u4e49 Gbbens Ensemble\uff0c\u8fd9\u4e0e\u81ea\u65cb 1/2 \u7684\u60c5\u51b5\u4e0d\u540c\u3002\u7814\u7a76\u8fd8\u8bc1\u660e\u4e86\u5747\u503c\u573a\u7406\u8bba\u7684\u7cbe\u786e\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\u7684\u65b9\u6cd5\u3002", "motivation": "\u4e0e\u666e\u904d\u7684\u770b\u6cd5\u76f8\u53cd\uff0c Richardson-Gaudin \u6a21\u578b\u7684\u81ea\u65cb s \u7684\u6e10\u8fd1\u591a\u4f53\u6ce2\u51fd\u6570\u4e0d\u80fd\u901a\u8fc7\u5408\u5e76\u81ea\u65cb 1/2 \u7684\u60c5\u51b5\u6765\u83b7\u5f97\uff0c\u800c\u662f\u9700\u8981\u5355\u72ec\u5904\u7406\u6bcf\u4e2a\u81ea\u65cb\u3002", "method": "\u672c\u6587\u63a8\u5bfc\u4e86\u5177\u6709\u4e0e\u65f6\u95f4\u6210\u53cd\u6bd4\u8026\u5408\u7684\u81ea\u65cb Richardson-Gaudin \u6a21\u578b\u7684\u7cbe\u786e\u6e10\u8fd1\u591a\u4f53\u6ce2\u51fd\u6570\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u4ece t = 0+ \u7684\u57fa\u6001\u5f00\u59cb\u7684\u65f6\u95f4\u6f14\u5316\uff0c\u5e76\u4e14\u8be5\u6a21\u578b\u9002\u7528\u4e8e\u4efb\u610f\u81ea\u65cb s\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c Richardson-Gaudin \u6a21\u578b\u7684\u7a33\u6001\u662f\u975e\u70ed\u7684\uff0c\u5e76\u4e14\u4e0d\u7b26\u5408\u5e7f\u4e49 Gbbens Ensemble\u3002\u6b64\u5916\uff0c\u5747\u503c\u573a\u7406\u8bba\u5bf9\u4e8e\u4f5c\u7528\u5728\u4e0d\u540c\u683c\u70b9\u4e0a\u7684\u6709\u9650\u6570\u91cf\u7684\u81ea\u65cb\u7b97\u7b26\u7684\u4e58\u79ef\u662f\u7cbe\u786e\u7684\u3002\u7814\u7a76\u8fd8\u8ba8\u8bba\u4e86\u5982\u4f55\u5728\u8154\u91cf\u5b50\u7535\u52a8\u529b\u5b66\u548c\u6355\u83b7\u79bb\u5b50\u5b9e\u9a8c\u4e2d\u8fdb\u884c\u63a2\u6d4b\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\uff0c\u5bf9\u4e8e\u8026\u5408\u5f3a\u5ea6\u4e0e\u65f6\u95f4\u6210\u53cd\u6bd4\u7684\u81ea\u65cb Richardson-Gaudin \u6a21\u578b\uff0c\u5176\u7a33\u6001\u662f\u201c\u975e\u70ed\u201d\u7684\uff0c\u5e76\u4e14\u4e0d\u7b26\u5408\u5e7f\u4e49 Gbbens Ensemble\uff08\u4e0e\u81ea\u65cb 1/2 \u7684\u60c5\u51b5\u4e0d\u540c\uff09\u3002\u7814\u7a76\u8fd8\u8868\u660e\uff0c\u5747\u503c\u573a\u7406\u8bba\u5bf9\u4e8e\u4f5c\u7528\u5728\u4e0d\u540c\u683c\u70b9\u4e0a\u7684\u6709\u9650\u6570\u91cf\u7684\u81ea\u65cb\u7b97\u7b26\u7684\u4e58\u79ef\u662f\u7cbe\u786e\u7684\u3002"}}
{"id": "2507.10943", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10943", "abs": "https://arxiv.org/abs/2507.10943", "authors": ["Yushun Fang", "Lu Liu", "Xiang Gao", "Qiang Hu", "Ning Cao", "Jianghe Cui", "Gang Chen", "Xiaoyun Zhang"], "title": "Robust ID-Specific Face Restoration via Alignment Learning", "comment": "17 pages, 8 figures", "summary": "The latest developments in Face Restoration have yielded significant\nadvancements in visual quality through the utilization of diverse diffusion\npriors. Nevertheless, the uncertainty of face identity introduced by\nidentity-obscure inputs and stochastic generative processes remains unresolved.\nTo address this challenge, we present Robust ID-Specific Face Restoration\n(RIDFR), a novel ID-specific face restoration framework based on diffusion\nmodels. Specifically, RIDFR leverages a pre-trained diffusion model in\nconjunction with two parallel conditioning modules. The Content Injection\nModule inputs the severely degraded image, while the Identity Injection Module\nintegrates the specific identity from a given image. Subsequently, RIDFR\nincorporates Alignment Learning, which aligns the restoration results from\nmultiple references with the same identity in order to suppress the\ninterference of ID-irrelevant face semantics (e.g. pose, expression, make-up,\nhair style). Experiments demonstrate that our framework outperforms the\nstate-of-the-art methods, reconstructing high-quality ID-specific results with\nhigh identity fidelity and demonstrating strong robustness.", "AI": {"tldr": "RIDFR\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u3001\u7279\u5b9a\u8eab\u4efd\u7684\u4eba\u8138\u6062\u590d\u6846\u67b6\uff0c\u5229\u7528\u6269\u6563\u6a21\u578b\u548c\u4e24\u4e2a\u5e76\u884c\u7684\u6761\u4ef6\u6a21\u5757\uff08\u5185\u5bb9\u6ce8\u5165\u548c\u8eab\u4efd\u6ce8\u5165\uff09\u6765\u89e3\u51b3\u8eab\u4efd\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u3002\u901a\u8fc7\u5bf9\u9f50\u5b66\u4e60\uff0c\u5b83\u80fd\u6709\u6548\u6291\u5236\u65e0\u5173\u7684\u4eba\u8138\u8bed\u4e49\uff0c\u751f\u6210\u9ad8\u4fdd\u771f\u5ea6\u7684\u6062\u590d\u7ed3\u679c\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u73b0\u6709\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u4eba\u8138\u6062\u590d\u65b9\u6cd5\u5728\u5904\u7406\u8eab\u4efd\u6a21\u7cca\u8f93\u5165\u548c\u968f\u673a\u751f\u6210\u8fc7\u7a0b\u65f6\u5f15\u5165\u7684\u8eab\u4efd\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u3002", "method": "RIDFR\u6846\u67b6\u91c7\u7528\u9884\u8bad\u7ec3\u7684\u6269\u6563\u6a21\u578b\uff0c\u7ed3\u5408\u5185\u5bb9\u6ce8\u5165\u6a21\u5757\uff08\u8f93\u5165\u964d\u7ea7\u56fe\u50cf\uff09\u548c\u8eab\u4efd\u6ce8\u5165\u6a21\u5757\uff08\u6574\u5408\u6307\u5b9a\u8eab\u4efd\u4fe1\u606f\uff09\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u5bf9\u9f50\u5b66\u4e60\uff0c\u901a\u8fc7\u5bf9\u9f50\u540c\u4e00\u8eab\u4efd\u7684\u591a\u4e2a\u53c2\u8003\u4eba\u8138\u6062\u590d\u7ed3\u679c\uff0c\u4ee5\u6291\u5236\u4e0e\u8eab\u4efd\u65e0\u5173\u7684\u4eba\u8138\u8bed\u4e49\uff08\u5982\u59ff\u6001\u3001\u8868\u60c5\u3001\u5986\u5bb9\u3001\u53d1\u578b\uff09\u7684\u5e72\u6270\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cRIDFR\u6846\u67b6\u5728\u4eba\u8138\u6062\u590d\u4efb\u52a1\u4e2d\uff0c\u76f8\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u80fd\u591f\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u7279\u5b9a\u8eab\u4efd\u4e14\u8eab\u4efd\u4fdd\u771f\u5ea6\u9ad8\u7684\u4eba\u8138\u6062\u590d\u7ed3\u679c\uff0c\u5e76\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "RIDFR\u6846\u67b6\u5728\u4eba\u8138\u6062\u590d\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u80fd\u591f\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u7279\u5b9a\u8eab\u4efd\u4e14\u8eab\u4efd\u4fdd\u771f\u5ea6\u9ad8\u7684\u4eba\u8138\u6062\u590d\u7ed3\u679c\uff0c\u5e76\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2507.10993", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10993", "abs": "https://arxiv.org/abs/2507.10993", "authors": ["Emir Durakovic", "Min-Hong Shih"], "title": "Modeling Habitat Shifts: Integrating Convolutional Neural Networks and Tabular Data for Species Migration Prediction", "comment": "This paper uses a lightly modified version of the AAAI 2025 LaTeX\n  style for formatting consistency. It is not a submission to AAAI and does not\n  include any AAAI-specific headers, footers, or metadata", "summary": "Due to climate-induced changes, many habitats are experiencing range shifts\naway from their traditional geographic locations (Piguet, 2011). We propose a\nsolution to accurately model whether bird species are present in a specific\nhabitat through the combination of Convolutional Neural Networks (CNNs)\n(O'Shea, 2015) and tabular data. Our approach makes use of satellite imagery\nand environmental features (e.g., temperature, precipitation, elevation) to\npredict bird presence across various climates. The CNN model captures spatial\ncharacteristics of landscapes such as forestation, water bodies, and\nurbanization, whereas the tabular method uses ecological and geographic data.\nBoth systems predict the distribution of birds with an average accuracy of 85%,\noffering a scalable but reliable method to understand bird migration.", "AI": {"tldr": "\u6c14\u5019\u53d8\u5316\u5bfc\u81f4\u9e1f\u7c7b\u6816\u606f\u5730\u8fc1\u79fb\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408CNN\u548c\u8868\u683c\u6570\u636e\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u536b\u661f\u56fe\u50cf\u548c\u73af\u5883\u7279\u5f81\u6765\u9884\u6d4b\u9e1f\u7c7b\u5728\u7279\u5b9a\u6816\u606f\u5730\u7684\u5b58\u5728\u60c5\u51b5\uff0c\u51c6\u786e\u7387\u8fbe85%\u3002", "motivation": "\u7531\u4e8e\u6c14\u5019\u53d8\u5316\u5bfc\u81f4\u6816\u606f\u5730\u8303\u56f4\u53d1\u751f\u53d8\u5316\uff0c\u9700\u8981\u4e00\u79cd\u51c6\u786e\u7684\u6a21\u578b\u6765\u9884\u6d4b\u9e1f\u7c7b\u7269\u79cd\u5728\u7279\u5b9a\u6816\u606f\u5730\u7684\u5b58\u5728\u60c5\u51b5\u3002", "method": "\u7ed3\u5408\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u548c\u8868\u683c\u6570\u636e\uff0c\u5229\u7528\u536b\u661f\u56fe\u50cf\u548c\u73af\u5883\u7279\u5f81\uff08\u5982\u6e29\u5ea6\u3001\u964d precipitation\u3001\u9ad8\u7a0b\uff09\u6765\u9884\u6d4b\u4e0d\u540c\u6c14\u5019\u4e0b\u7684\u9e1f\u7c7b\u5b58\u5728\u60c5\u51b5\u3002CNN\u6a21\u578b\u6355\u6349\u666f\u89c2\u7684\u7a7a\u95f4\u7279\u5f81\uff0c\u800c\u8868\u683c\u65b9\u6cd5\u5219\u5229\u7528\u751f\u6001\u548c\u5730\u7406\u6570\u636e\u3002", "result": "\u8be5\u65b9\u6cd5\u9884\u6d4b\u9e1f\u7c7b\u5206\u5e03\u7684\u5e73\u5747\u51c6\u786e\u7387\u4e3a85%\uff0c\u4e3a\u7406\u89e3\u9e1f\u7c7b\u8fc1\u5f99\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u53ef\u9760\u7684\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u548c\u8868\u683c\u6570\u636e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u4ee5\u5bf9\u9e1f\u7c7b\u7269\u79cd\u5728\u7279\u5b9a\u6816\u606f\u5730\u7684\u5b58\u5728\u60c5\u51b5\u8fdb\u884c\u5efa\u6a21\uff0c\u5e73\u5747\u51c6\u786e\u7387\u4e3a85%\uff0c\u4e3a\u7406\u89e3\u9e1f\u7c7b\u8fc1\u5f99\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u53ef\u9760\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.10958", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.10958", "abs": "https://arxiv.org/abs/2507.10958", "authors": ["Anthony Miyaguchi", "David Guecha", "Yuwen Chiu", "Sidharth Gaur"], "title": "DS@GT at eRisk 2025: From prompts to predictions, benchmarking early depression detection with conversational agent based assessments and temporal attention models", "comment": null, "summary": "This Working Note summarizes the participation of the DS@GT team in two eRisk\n2025 challenges. For the Pilot Task on conversational depression detection with\nlarge language-models (LLMs), we adopted a prompt-engineering strategy in which\ndiverse LLMs conducted BDI-II-based assessments and produced structured JSON\noutputs. Because ground-truth labels were unavailable, we evaluated cross-model\nagreement and internal consistency. Our prompt design methodology aligned model\noutputs with BDI-II criteria and enabled the analysis of conversational cues\nthat influenced the prediction of symptoms. Our best submission, second on the\nofficial leaderboard, achieved DCHR = 0.50, ADODL = 0.89, and ASHR = 0.27.", "AI": {"tldr": "DS@GT\u56e2\u961f\u5728eRisk 2025\u6311\u6218\u8d5b\u4e2d\uff0c\u5229\u7528LLMs\u548c\u63d0\u793a\u5de5\u7a0b\u5728\u5bf9\u8bdd\u5f0f\u6291\u90c1\u75c7\u68c0\u6d4b\u4efb\u52a1\u4e2d\u53d6\u5f97\u7b2c\u4e8c\u540d\u3002", "motivation": "\u672c\u6b21\u5de5\u4f5c\u7b14\u8bb0\u603b\u7ed3\u4e86DS@GT\u56e2\u961f\u5728eRisk 2025\u4e24\u4e2a\u6311\u6218\u4e2d\u7684\u53c2\u4e0e\u60c5\u51b5\uff0c\u91cd\u70b9\u5173\u6ce8\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8fdb\u884c\u5bf9\u8bdd\u5f0f\u6291\u90c1\u75c7\u68c0\u6d4b\u7684\u8bd5\u70b9\u4efb\u52a1\u3002", "method": "DS@GT\u56e2\u961f\u91c7\u7528\u63d0\u793a\u5de5\u7a0b\u7b56\u7565\uff0c\u5229\u7528\u591a\u79cdLLMs\u8fdb\u884c\u57fa\u4e8eBDI-II\u7684\u8bc4\u4f30\uff0c\u5e76\u751f\u6210\u7ed3\u6784\u5316JSON\u8f93\u51fa\u3002\u7531\u4e8e\u7f3a\u4e4f\u771f\u5b9e\u6807\u7b7e\uff0c\u56e2\u961f\u8bc4\u4f30\u4e86\u8de8\u6a21\u578b\u7684\u4e00\u81f4\u6027\u548c\u5185\u90e8\u4e00\u81f4\u6027\u3002", "result": "\u5728\u8bd5\u70b9\u4efb\u52a1\u4e2d\uff0cDS@GT\u56e2\u961f\u7684\u6700\u4f73\u63d0\u4ea4\u5728\u5b98\u65b9\u6392\u884c\u699c\u4e0a\u540d\u5217\u7b2c\u4e8c\uff0c\u53d6\u5f97\u4e86DCHR = 0.50\uff0cADODL = 0.89\uff0cASHR = 0.27\u7684\u6210\u7ee9\u3002", "conclusion": "DS@GT\u56e2\u961f\u5728eRisk 2025\u7684\u4e24\u4e2a\u6311\u6218\u4e2d\uff0c\u4f7f\u7528LLMs\u548c\u63d0\u793a\u5de5\u7a0b\u7b56\u7565\u8fdb\u884c\u4e86\u5bf9\u8bdd\u5f0f\u6291\u90c1\u75c7\u68c0\u6d4b\u3002"}}
{"id": "2507.10620", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10620", "abs": "https://arxiv.org/abs/2507.10620", "authors": ["Chenxi Liu", "Hao Miao", "Cheng Long", "Yan Zhao", "Ziyue Li", "Panos Kalnis"], "title": "LLMs Meet Cross-Modal Time Series Analytics: Overview and Directions", "comment": "Accepted at SSTD 2025 (Tutorial). arXiv admin note: text overlap with\n  arXiv:2505.02583", "summary": "Large Language Models (LLMs) have emerged as a promising paradigm for time\nseries analytics, leveraging their massive parameters and the shared sequential\nnature of textual and time series data. However, a cross-modality gap exists\nbetween time series and textual data, as LLMs are pre-trained on textual\ncorpora and are not inherently optimized for time series. In this tutorial, we\nprovide an up-to-date overview of LLM-based cross-modal time series analytics.\nWe introduce a taxonomy that classifies existing approaches into three groups\nbased on cross-modal modeling strategies, e.g., conversion, alignment, and\nfusion, and then discuss their applications across a range of downstream tasks.\nIn addition, we summarize several open challenges. This tutorial aims to expand\nthe practical application of LLMs in solving real-world problems in cross-modal\ntime series analytics while balancing effectiveness and efficiency.\nParticipants will gain a thorough understanding of current advancements,\nmethodologies, and future research directions in cross-modal time series\nanalytics.", "AI": {"tldr": "LLM\u5728\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u4e2d\u5f88\u6709\u524d\u666f\uff0c\u4f46\u9700\u8981\u89e3\u51b3\u8de8\u6a21\u6001\u95ee\u9898\u3002\u672c\u6559\u7a0b\u6982\u8ff0\u4e86\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u8ba8\u8bba\u4e86\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\u3002", "motivation": "LLM\u5728\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u7531\u4e8e\u5176\u5728\u6587\u672c\u8bed\u6599\u5e93\u4e0a\u9884\u8bad\u7ec3\u4e14\u672a\u9488\u5bf9\u65f6\u95f4\u5e8f\u5217\u8fdb\u884c\u4f18\u5316\uff0c\u5b58\u5728\u8de8\u6a21\u6001\u9e3f\u6c9f\u3002", "method": "\u672c\u6559\u7a0b\u5bf9\u57fa\u4e8eLLM\u7684\u8de8\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u8fdb\u884c\u4e86\u5168\u9762\u7684\u6982\u8ff0\uff0c\u5f15\u5165\u4e86\u4e00\u4e2a\u57fa\u4e8e\u8de8\u6a21\u6001\u5efa\u6a21\u7b56\u7565\uff08\u8f6c\u6362\u3001\u5bf9\u9f50\u3001\u878d\u5408\uff09\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u5e76\u63a2\u8ba8\u4e86\u5b83\u4eec\u5728\u5404\u79cd\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002", "result": "\u672c\u6559\u7a0b\u65e8\u5728\u4e3a\u53c2\u4e0e\u8005\u63d0\u4f9b\u5bf9\u8de8\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u9886\u57df\u5f53\u524d\u8fdb\u5c55\u3001\u65b9\u6cd5\u8bba\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u7684\u900f\u5f7b\u7406\u89e3\uff0c\u4ee5\u6269\u5c55LLM\u5728\u89e3\u51b3\u73b0\u5b9e\u4e16\u754c\u95ee\u9898\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002", "conclusion": "LLM\u5728\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u9886\u57df\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u5b58\u5728\u8de8\u6a21\u6001\u9e3f\u6c9f\u3002\u672c\u6559\u7a0b\u65e8\u5728\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\uff0c\u901a\u8fc7\u5206\u7c7b\u73b0\u6709\u65b9\u6cd5\uff08\u8f6c\u6362\u3001\u5bf9\u9f50\u3001\u878d\u5408\uff09\u5e76\u8ba8\u8bba\u5176\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\uff0c\u540c\u65f6\u603b\u7ed3\u5f00\u653e\u6027\u6311\u6218\uff0c\u4ee5\u671f\u63a8\u52a8LLM\u5728\u8de8\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\uff0c\u5e76\u5e73\u8861\u6709\u6548\u6027\u4e0e\u6548\u7387\u3002"}}
{"id": "2507.11006", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.11006", "abs": "https://arxiv.org/abs/2507.11006", "authors": ["Ashutosh Mishra", "Shreya Santra", "Hazal Gozbasi", "Kentaro Uno", "Kazuya Yoshida"], "title": "Enhancing Autonomous Manipulator Control with Human-in-loop for Uncertain Assembly Environments", "comment": "6 pages, 7 figures. Manuscript accepted at the 2025 IEEE 21st\n  International Conference on Automation Science and Engineering (CASE 2025)", "summary": "This study presents an advanced approach to enhance robotic manipulation in\nuncertain and challenging environments, with a focus on autonomous operations\naugmented by human-in-the-loop (HITL) control for lunar missions. By\nintegrating human decision-making with autonomous robotic functions, the\nresearch improves task reliability and efficiency for space applications. The\nkey task addressed is the autonomous deployment of flexible solar panels using\nan extendable ladder-like structure and a robotic manipulator with real-time\nfeedback for precision. The manipulator relays position and force-torque data,\nenabling dynamic error detection and adaptive control during deployment. To\nmitigate the effects of sinkage, variable payload, and low-lighting conditions,\nefficient motion planning strategies are employed, supplemented by human\ncontrol that allows operators to intervene in ambiguous scenarios. Digital twin\nsimulation enhances system robustness by enabling continuous feedback,\niterative task refinement, and seamless integration with the deployment\npipeline. The system has been tested to validate its performance in simulated\nlunar conditions and ensure reliability in extreme lighting, variable terrain,\nchanging payloads, and sensor limitations.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e86\u201c\u4eba\u5728\u56de\u8def\u201d\uff08HITL\uff09\u63a7\u5236\u7684\u5148\u8fdb\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u6708\u7403\u4efb\u52a1\u7b49\u4e0d\u786e\u5b9a\u73af\u5883\u4e2d\u589e\u5f3a\u673a\u5668\u4eba\u7684\u81ea\u4e3b\u64cd\u4f5c\u548c\u64cd\u7eb5\u80fd\u529b\uff0c\u901a\u8fc7\u6570\u5b57\u5b6a\u751f\u6a21\u62df\u548c\u81ea\u9002\u5e94\u63a7\u5236\u63d0\u9ad8\u4e86\u90e8\u7f72\u592a\u9633\u80fd\u7535\u6c60\u677f\u7b49\u4efb\u52a1\u7684\u53ef\u9760\u6027\u548c\u6548\u7387\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u63d0\u5347\u673a\u5668\u4eba\u5728\u6708\u7403\u7b49\u4e0d\u786e\u5b9a\u548c\u5177\u6709\u6311\u6218\u6027\u73af\u5883\u4e2d\u7684\u81ea\u4e3b\u64cd\u4f5c\u80fd\u529b\uff0c\u7279\u522b\u662f\u901a\u8fc7\u5f15\u5165\u201c\u4eba\u5728\u56de\u8def\u201d\uff08HITL\uff09\u63a7\u5236\u6765\u589e\u5f3a\u673a\u5668\u4eba\u64cd\u7eb5\u7684\u53ef\u9760\u6027\u548c\u6548\u7387\u3002", "method": "\u7814\u7a76\u96c6\u6210\u4e86\u673a\u5668\u4eba\u64cd\u7eb5\u5668\u548c\u53ef\u4f38\u7f29\u7684\u68af\u72b6\u7ed3\u6784\uff0c\u7528\u4e8e\u81ea\u4e3b\u90e8\u7f72\u67d4\u6027\u592a\u9633\u80fd\u7535\u6c60\u677f\uff0c\u5e76\u5229\u7528\u5b9e\u65f6\u53cd\u9988\u8fdb\u884c\u7cbe\u786e\u63a7\u5236\u3002\u8be5\u64cd\u7eb5\u5668\u4f20\u8f93\u4f4d\u7f6e\u548c\u529b-\u626d\u77e9\u6570\u636e\uff0c\u4ee5\u5b9e\u73b0\u52a8\u6001\u8bef\u5dee\u68c0\u6d4b\u548c\u81ea\u9002\u5e94\u63a7\u5236\u3002\u4e3a\u5e94\u5bf9\u6c89\u9677\u3001\u53ef\u53d8\u8d1f\u8f7d\u548c\u4f4e\u5149\u7167\u6761\u4ef6\u7684\u5f71\u54cd\uff0c\u7814\u7a76\u91c7\u7528\u4e86\u9ad8\u6548\u7684\u8fd0\u52a8\u89c4\u5212\u7b56\u7565\uff0c\u5e76\u8f85\u4ee5\u5141\u8bb8\u64cd\u4f5c\u5458\u5e72\u9884\u6a21\u7cca\u573a\u666f\u7684\u4eba\u5de5\u63a7\u5236\u3002\u6570\u5b57\u5b6a\u751f\u6a21\u62df\u901a\u8fc7\u63d0\u4f9b\u6301\u7eed\u53cd\u9988\u3001\u8fed\u4ee3\u4efb\u52a1\u4f18\u5316\u548c\u4e0e\u90e8\u7f72\u6d41\u7a0b\u7684\u65e0\u7f1d\u96c6\u6210\u6765\u589e\u5f3a\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u3002", "result": "\u901a\u8fc7\u5728\u6a21\u62df\u6708\u7403\u7684\u6761\u4ef6\u4e0b\u8fdb\u884c\u6d4b\u8bd5\uff0c\u9a8c\u8bc1\u4e86\u8be5\u7cfb\u7edf\u5728\u6781\u7aef\u5149\u7167\u3001\u53ef\u53d8\u5730\u5f62\u3001\u53d8\u5316\u7684\u6709\u6548\u8f7d\u8377\u548c\u4f20\u611f\u5668\u9650\u5236\u4e0b\u7684\u6027\u80fd\u548c\u53ef\u9760\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u6708\u7403\u4efb\u52a1\u4e2d\u7ed3\u5408\u4e86\u4eba\u5728\u56de\u8def\uff08HITL\uff09\u63a7\u5236\u7684\u81ea\u4e3b\u673a\u5668\u4eba\u64cd\u4f5c\u589e\u5f3a\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u5728\u4e0d\u786e\u5b9a\u548c\u5177\u6709\u6311\u6218\u6027\u73af\u5883\u4e0b\u7684\u673a\u5668\u4eba\u64cd\u7eb5\u80fd\u529b\u3002\u901a\u8fc7\u6574\u5408\u4eba\u7c7b\u51b3\u7b56\u548c\u81ea\u4e3b\u673a\u5668\u4eba\u529f\u80fd\uff0c\u7814\u7a76\u63d0\u9ad8\u4e86\u7a7a\u95f4\u5e94\u7528\u7684\u53ef\u9760\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2507.11409", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2507.11409", "abs": "https://arxiv.org/abs/2507.11409", "authors": ["Yuxuan Sheng", "Menghao Wu"], "title": "Volcano-Like Ferroic Transitions Deviating from the Model of Landau Theory", "comment": null, "summary": "We predict the existence of abnormal volcano-like temperature dependence of\npolarization or magnetization with maxima located at elevated temperature,\ndistinct from classical model based on Landau theory. One case is\nferroelectricity with long ion displacements and quantized polarizations that\ncannot be used for expansion in Landau model, and the switching pathway\ninvolves various metastable phases where the polar phase is higher both in\nenergy and entropy compared with non-polar phase. Another case is compensated\nantiferromagnets with two opposite spin lattices of different spin exchange\nconstants. Such difference can be utilized for a unique type of temperature\ndifferentiated multiferroicity, where large magnetizations can be reversed upon\nferroelectric switching between two Curie temperature with alternating half of\nspins in paramagnetic state. We demonstrate these proposals by first-principles\ncalculations on several paradigmatic systems, including magnetic bilayers\nintercalated by Ag ions or metal molecules.", "AI": {"tldr": "\u672c\u6587\u9884\u6d4b\u5e76\u8bc1\u5b9e\u4e86\u4e24\u79cd\u65b0\u578b\u94c1\u7535\u548c\u94c1\u78c1\u6027\u6750\u6599\uff0c\u5b83\u4eec\u5177\u6709\u53cd\u5e38\u7684\u706b\u5c71\u72b6\u6e29\u5ea6\u4f9d\u8d56\u6027\uff0c\u5e76\u901a\u8fc7\u7b2c\u4e00\u6027\u539f\u7406\u8ba1\u7b97\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "motivation": "\u9884\u6d4b\u5b58\u5728\u53cd\u5e38\u706b\u5c71\u72b6\u6e29\u5ea6\u4f9d\u8d56\u6027\u7684\u6781\u5316\u6216\u78c1\u5316\uff0c\u5176\u6700\u5927\u503c\u4f4d\u4e8e\u9ad8\u6e29\u5904\uff0c\u8fd9\u4e0e\u57fa\u4e8e Landau \u7406\u8bba\u7684\u7ecf\u5178\u6a21\u578b\u4e0d\u540c\u3002", "method": "\u901a\u8fc7\u7b2c\u4e00\u6027\u539f\u7406\u8ba1\u7b97\uff0c\u5728\u51e0\u4e2a\u5178\u578b\u7684\u4f53\u7cfb\u4e2d\uff0c\u5305\u62ec\u88ab\u94f6\u79bb\u5b50\u6216\u91d1\u5c5e\u5206\u5b50\u63d2\u5165\u7684\u78c1\u6027\u53cc\u5c42\uff0c\u8bc1\u660e\u4e86\u8fd9\u4e9b\u8bbe\u60f3\u3002", "result": "\u5c55\u793a\u4e86\u4e24\u79cd\u53ef\u80fd\u51fa\u73b0\u53cd\u5e38\u706b\u5c71\u72b6\u6e29\u5ea6\u4f9d\u8d56\u6027\u7684\u94c1\u7535\u548c\u94c1\u78c1\u6027\u6750\u6599\uff0c\u5176\u4e2d\u94c1\u7535\u6027\u7684\u5f00\u5173\u901a\u8def\u6d89\u53ca\u591a\u79cd\u4e9a\u7a33\u6001\u76f8\uff0c\u800c\u8865\u507f\u53cd\u94c1\u78c1\u6027\u5219\u53ef\u4ee5\u5b9e\u73b0\u4e00\u79cd\u72ec\u7279\u7684\u6e29\u5ea6\u533a\u5206\u591a\u94c1\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u5e76\u8bc1\u5b9e\u4e86\u4e24\u79cd\u53ef\u80fd\u51fa\u73b0\u53cd\u5e38\u706b\u5c71\u72b6\u6e29\u5ea6\u4f9d\u8d56\u6027\u7684\u94c1\u7535\u548c\u94c1\u78c1\u6027\u6750\u6599\uff0c\u4e0e\u57fa\u4e8e Landau \u7406\u8bba\u7684\u7ecf\u5178\u6a21\u578b\u4e0d\u540c\u3002"}}
{"id": "2507.11347", "categories": ["cond-mat.mes-hall", "cond-mat.mtrl-sci", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2507.11347", "abs": "https://arxiv.org/abs/2507.11347", "authors": ["Naitian Liu", "Zhangyuan Chen", "Jing Ding", "Wenqiang Zhou", "Hanxiao Xiang", "Xinjie Fang", "Linfeng Wu", "Xiaowan Zhan", "Le Zhang", "Qianmei Chen", "Kenji Watanabe", "Takashi Taniguchi", "Na Xin", "Shuigang Xu"], "title": "Diverse high-Chern-number quantum anomalous Hall insulators in twisted rhombohedral graphene", "comment": null, "summary": "Quantum anomalous Hall (QAH) insulators with high Chern number (C) enables\nmultiple dissipationless edge channels for low-power-consumption electronics.\nWe report the realization of multiple high-C QAH insulators including C=3,5,6,\nand 7 in twisted monolayer-rhombohedral pentalayer graphene. In twist angles of\napproximately 1.40{\\deg}, we observe QAH effect with C=5 at a filling of one\nelectron per moir\\'e unit cell, persisting up to 2 Kelvin. Furthermore,\nincommensurate QAH insulators with C=5,6, and 7 emerge at partial fillings. In\ntwist angles of 0.89{\\deg}, Chern insulators with C=3 and C=6 appear at\nfillings of two and three electrons, respectively. Our findings establish\ntwisted rhombohedral multilayer graphene as a highly tunable platform for\nmultichannel, dissipationless electronics and for the exploration of exotic\nquantum Hall states beyond traditional Landau level paradigm.", "AI": {"tldr": "\u672c\u7814\u7a76\u5728\u626d\u66f2\u77f3\u58a8\u70ef\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u9648\u6570\u7684\u91cf\u5b50\u53cd\u5e38\u970d\u5c14\u6548\u5e94\uff0c\u4e3a\u5148\u8fdb\u7535\u5b50\u5b66\u548c\u91cf\u5b50\u7269\u7406\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u5e73\u53f0\u3002", "motivation": "\u65e8\u5728\u5b9e\u73b0\u5177\u6709\u9ad8\u9648\u6570\uff08C\uff09\u7684\u91cf\u5b50\u53cd\u5e38\u970d\u5c14\uff08QAH\uff09\u7edd\u7f18\u4f53\uff0c\u4ee5\u5b9e\u73b0\u4f4e\u529f\u8017\u7535\u5b50\u5b66\u6240\u9700\u7684\u591a\u6761\u65e0\u8017\u6563\u8fb9\u7f18\u901a\u9053\u3002", "method": "\u901a\u8fc7\u7cbe\u786e\u63a7\u5236\u626d\u66f2\u89d2\u5ea6\uff08\u7ea61.40\u00b0\u548c0.89\u00b0\uff09\u548c\u7535\u5b50\u586b\u5145\uff0c\u5728\u626d\u66f2\u83f1\u9762\u5f62\u591a\u5c42\u77f3\u58a8\u70ef\u4e2d\u89c2\u6d4b\u5230\u91cf\u5b50\u53cd\u5e38\u970d\u5c14\u6548\u5e94\u3002", "result": "\u5728\u626d\u66f2\u89d2\u5ea6\u7ea61.40\u00b0\u65f6\uff0c\u57281.2\u4e2a\u8f7d\u6d41\u5b50\u6bcf\u83ab\u5c14\u5355\u4f4d\u683c\u7684\u586b\u5145\u4e0b\uff0c\u5728\u9ad8\u8fbe2\u5f00\u5c14\u6587\u7684\u6e29\u5ea6\u4e0b\u5b9e\u73b0\u4e86C=5\u7684QAH\u6548\u5e94\u3002\u6b64\u5916\uff0c\u5728\u90e8\u5206\u586b\u5145\u4e0b\u51fa\u73b0\u4e86C=5, 6, 7\u7684\u975e\u6574\u5468\u671fQAH\u7edd\u7f18\u4f53\u3002\u57280.89\u00b0\u7684\u626d\u66f2\u89d2\u5ea6\u4e0b\uff0c\u5728\u4e24\u4e2a\u548c\u4e09\u4e2a\u7535\u5b50\u7684\u586b\u5145\u4e0b\u5206\u522b\u51fa\u73b0\u4e86C=3\u548cC=6\u7684\u9648\u7edd\u7f18\u4f53\u3002", "conclusion": "\u8be5\u7814\u7a76\u62a5\u544a\u5728\u626d\u66f2\u5355\u5c42\u83f1\u9762\u5f62\u4e94\u5c42\u77f3\u58a8\u70ef\u4e2d\u5b9e\u73b0\u4e86\u591a\u79cd\u9ad8\u9648\u6570\uff08C=3, 5, 6, 7\uff09\u7684\u91cf\u5b50\u53cd\u5e38\u970d\u5c14\uff08QAH\uff09\u7edd\u7f18\u4f53\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u591a\u901a\u9053\u3001\u65e0\u8017\u6563\u7535\u5b50\u5b66\u548c\u63a2\u7d22\u5947\u5f02\u91cf\u5b50\u970d\u5c14\u6001\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.10862", "categories": ["quant-ph", "cond-mat.quant-gas", "gr-qc", "nlin.PS", "physics.optics"], "pdf": "https://arxiv.org/pdf/2507.10862", "abs": "https://arxiv.org/abs/2507.10862", "authors": ["Juan Ram\u00f3n Mu\u00f1oz de Nova", "Fernando Sols"], "title": "Hawking time crystal", "comment": "7 pages, 3 figures, preliminary version", "summary": "We report the numerical observation of a time crystal in a quantum black-hole\nlaser (BHL), where the genuine spontaneous character of the symmetry breaking\nstems from the self-amplification of spontaneous Hawking radiation. The\nresulting Hawking time crystal (HTC) is characterized by the periodic\ndependence of the out-of-time density-density correlation function, while\nequal-time correlations are time-independent because they embody averages over\ndifferent realizations with a random oscillation phase. The HTC can be regarded\nas a nonlinear periodic version of the Andreev-Hawking effect, signaled by\nanticorrelation bands resulting from the spontaneous, quantum emission of pairs\nof dispersive waves and solitons into the upstream and downstream regions.", "AI": {"tldr": "\u5728\u91cf\u5b50\u9ed1\u6d1e\u6fc0\u5149\u5668\u4e2d\u89c2\u5bdf\u5230\u4e86\u65f6\u95f4\u6676\u4f53\uff0c\u8fd9\u662f\u7531\u81ea\u53d1\u970d\u91d1\u8f90\u5c04\u7684\u81ea\u6211\u653e\u5927\u5f15\u8d77\u7684\u3002HTC\u662fAndreev-Hawking\u6548\u5e94\u7684\u975e\u7ebf\u6027\u5468\u671f\u6027\u7248\u672c\u3002", "motivation": "\u5728\u91cf\u5b50\u9ed1\u6d1e\u6fc0\u5149\u5668\uff08BHL\uff09\u4e2d\u6570\u503c\u89c2\u6d4b\u5230\u65f6\u95f4\u6676\u4f53\u3002", "method": "\u901a\u8fc7\u91cf\u5b50\u9ed1\u6d1e\u6fc0\u5149\u5668\uff08BHL\uff09\u4e2d\u7684\u81ea\u53d1\u5bf9\u79f0\u6027\u7834\u7f3a\uff0c\u5b9e\u73b0\u4e86\u970d\u91d1\u65f6\u95f4\u6676\u4f53\uff08HTC\uff09\u3002", "result": "\u91cf\u5b50\u7ea0\u7f20\u7684\u81ea\u53d1\u970d\u91d1\u8f90\u5c04\u7684\u81ea\u6211\u653e\u5927\u5bfc\u81f4\u4e86\u65f6\u95f4\u6676\u4f53\u7684\u5f62\u6210\u3002", "conclusion": "\u65f6\u95f4\u6676\u4f53\uff08HTC\uff09\u53ef\u4ee5\u88ab\u89c6\u4e3aAndreev-Hawking\u6548\u5e94\u7684\u975e\u7ebf\u6027\u5468\u671f\u6027\u7248\u672c\uff0c\u5176\u7279\u5f81\u5728\u4e8e\u81ea\u53d1\u4ea7\u751f\u7684\u6210\u5bf9\u7684\u8272\u6563\u6ce2\u548c\u5b64\u5b50\u8fdb\u5165\u4e0a\u6e38\u548c\u4e0b\u6e38\u533a\u57df\u6240\u4ea7\u751f\u7684\u53cd\u76f8\u5173\u80fd\u5e26\u3002"}}
{"id": "2507.10969", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10969", "abs": "https://arxiv.org/abs/2507.10969", "authors": ["Palash Ray", "Mahuya Sasmal", "Asish Bera"], "title": "Women Sport Actions Dataset for Visual Classification Using Small Scale Training Data", "comment": null, "summary": "Sports action classification representing complex body postures and\nplayer-object interactions is an emerging area in image-based sports analysis.\nSome works have contributed to automated sports action recognition using\nmachine learning techniques over the past decades. However, sufficient image\ndatasets representing women sports actions with enough intra- and inter-class\nvariations are not available to the researchers. To overcome this limitation,\nthis work presents a new dataset named WomenSports for women sports\nclassification using small-scale training data. This dataset includes a variety\nof sports activities, covering wide variations in movements, environments, and\ninteractions among players. In addition, this study proposes a convolutional\nneural network (CNN) for deep feature extraction. A channel attention scheme\nupon local contextual regions is applied to refine and enhance feature\nrepresentation. The experiments are carried out on three different sports\ndatasets and one dance dataset for generalizing the proposed algorithm, and the\nperformances on these datasets are noteworthy. The deep learning method\nachieves 89.15% top-1 classification accuracy using ResNet-50 on the proposed\nWomenSports dataset, which is publicly available for research at Mendeley Data.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86WomenSports\u6570\u636e\u96c6\u548c\u4e00\u79cd\u65b0\u7684CNN\u6a21\u578b\uff0c\u7528\u4e8e\u5973\u6027\u4f53\u80b2\u52a8\u4f5c\u5206\u7c7b\uff0c\u5e76\u5728WomenSports\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e8689.15%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u4f53\u80b2\u52a8\u4f5c\u8bc6\u522b\u6570\u636e\u96c6\u7f3a\u4e4f\u4ee3\u8868\u5973\u6027\u8fd0\u52a8\u7684\u6570\u636e\uff0c\u7279\u522b\u662f\u5305\u542b\u8db3\u591f\u591a\u7684\u7c7b\u5185\u548c\u7c7b\u95f4\u53d8\u5316\u7684\u5973\u6027\u8fd0\u52a8\u6570\u636e\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u672c\u7814\u7a76\u521b\u5efa\u4e86\u4e00\u4e2a\u65b0\u7684\u540d\u4e3aWomenSports\u7684\u6570\u636e\u96c6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eCNN\u548c\u901a\u9053\u6ce8\u610f\u529b\u673a\u5236\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u4e8e\u4f53\u80b2\u52a8\u4f5c\u5206\u7c7b\u3002\u5b9e\u9a8c\u5728\u4e09\u4e2a\u4f53\u80b2\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u821e\u8e48\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "result": "\u5728\u63d0\u51fa\u7684WomenSports\u6570\u636e\u96c6\u4e0a\uff0c\u4f7f\u7528ResNet-50\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u8fbe\u5230\u4e8689.15%\u7684top-1\u5206\u7c7b\u51c6\u786e\u7387\u3002\u8be5\u6a21\u578b\u5728\u5176\u4ed6\u4e09\u4e2a\u4f53\u80b2\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u821e\u8e48\u6570\u636e\u96c6\u4e0a\u4e5f\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aWomenSports\u7684\u65b0\u6570\u636e\u96c6\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u57fa\u4e8eCNN\u548c\u901a\u9053\u6ce8\u610f\u529b\u673a\u5236\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5973\u6027\u4f53\u80b2\u52a8\u4f5c\u7684\u5206\u7c7b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5728WomenSports\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e8689.15%\u7684\u51c6\u786e\u7387\u3002"}}
{"id": "2507.11060", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11060", "abs": "https://arxiv.org/abs/2507.11060", "authors": ["Yilmazcan Ozyurt", "Tunaberk Almaci", "Stefan Feuerriegel", "Mrinmaya Sachan"], "title": "Personalized Exercise Recommendation with Semantically-Grounded Knowledge Tracing", "comment": null, "summary": "We introduce ExRec, a general framework for personalized exercise\nrecommendation with semantically-grounded knowledge tracing. Our method builds\non the observation that existing exercise recommendation approaches simulate\nstudent performance via knowledge tracing (KT) but they often overlook two key\naspects: (a) the semantic content of questions and (b) the sequential,\nstructured progression of student learning. To address this, our ExRec presents\nan end-to-end pipeline, from annotating the KCs of questions and learning their\nsemantic representations to training KT models and optimizing several\nreinforcement learning (RL) methods. Moreover, we improve standard\nQ-learning-based continuous RL methods via a tailored model-based value\nestimation (MVE) approach that directly leverages the components of KT model in\nestimating cumulative knowledge improvement. We validate the effectiveness of\nour ExRec using various RL methods across four real-world tasks with different\neducational goals in online math learning. We further show that ExRec\ngeneralizes robustly to new, unseen questions and that it produces\ninterpretable student learning trajectories. Together, our findings highlight\nthe promise of KT-guided RL for effective personalization in education.", "AI": {"tldr": "ExRec \u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u95ee\u9898\u8bed\u4e49\u548c\u77e5\u8bc6\u8ffd\u8e2a\u6765\u6539\u8fdb\u7ec3\u4e60\u63a8\u8350\uff0c\u5e76\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u4e2a\u6027\u5316\uff0c\u5728\u5728\u7ebf\u6570\u5b66\u5b66\u4e60\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7ec3\u4e60\u63a8\u8350\u65b9\u6cd5\u5728\u6a21\u62df\u5b66\u751f\u8868\u73b0\u65f6\uff0c\u5f80\u5f80\u5ffd\u7565\u4e86\u95ee\u9898\u7684\u8bed\u4e49\u5185\u5bb9\u548c\u5b66\u4e60\u8fc7\u7a0b\u7684\u987a\u5e8f\u3001\u7ed3\u6784\u5316\u8fdb\u5c55\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7406\u89e3\u95ee\u9898\u8bed\u4e49\u5e76\u6355\u6349\u5b66\u4e60\u8fc7\u7a0b\u7ed3\u6784\u7684\u65b0\u65b9\u6cd5\u3002", "method": "ExRec \u6846\u67b6\u901a\u8fc7\u4ee5\u4e0b\u6b65\u9aa4\u5b9e\u73b0\u4e2a\u6027\u5316\u7ec3\u4e60\u63a8\u8350\uff1a1. \u6807\u6ce8\u7ec3\u4e60\u9898\u7684\u77e5\u8bc6\u70b9\uff08KCs\uff09\u5e76\u5b66\u4e60\u5176\u8bed\u4e49\u8868\u793a\u30022. \u8bad\u7ec3\u7ed3\u5408\u4e86\u95ee\u9898\u8bed\u4e49\u4fe1\u606f\u7684\u77e5\u8bc6\u8ffd\u8e2a\uff08KT\uff09\u6a21\u578b\u30023. \u4f18\u5316\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u7684\u4ef7\u503c\u4f30\u8ba1\uff08MVE\uff09\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5229\u7528 KT \u6a21\u578b\u7684\u7ec4\u4ef6\u6765\u4f30\u8ba1\u7d2f\u79ef\u77e5\u8bc6\u589e\u957f\u3002", "result": "ExRec \u6846\u67b6\u5728\u56db\u4e2a\u4e0d\u540c\u5728\u7ebf\u6570\u5b66\u5b66\u4e60\u4efb\u52a1\u4e2d\u5f97\u5230\u9a8c\u8bc1\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u6846\u67b6\u5728\u4e0d\u540c RL \u65b9\u6cd5\u4e0b\u90fd\u8868\u73b0\u51fa\u6709\u6548\u6027\u3002\u6b64\u5916\uff0cExRec \u80fd\u591f\u7a33\u5065\u5730\u6cdb\u5316\u5230\u65b0\u7684\u3001\u672a\u89c1\u8fc7\u7684\u95ee\u9898\uff0c\u5e76\u80fd\u751f\u6210\u53ef\u89e3\u91ca\u7684\u5b66\u751f\u5b66\u4e60\u8f68\u8ff9\u3002", "conclusion": "ExRec \u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u77e5\u8bc6\u8ffd\u8e2a\uff08KT\uff09\u548c\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u6765\u89e3\u51b3\u73b0\u6709\u7ec3\u4e60\u63a8\u8350\u7cfb\u7edf\u5ffd\u89c6\u95ee\u9898\u8bed\u4e49\u548c\u5b66\u4e60\u8fc7\u7a0b\u7ed3\u6784\u5316\u7684\u95ee\u9898\u3002\u8be5\u6846\u67b6\u80fd\u591f\u751f\u6210\u53ef\u89e3\u91ca\u7684\u5b66\u751f\u5b66\u4e60\u8f68\u8ff9\uff0c\u5e76\u80fd\u6cdb\u5316\u5230\u65b0\u7684\u3001\u672a\u89c1\u8fc7\u7684\u95ee\u9898\uff0c\u8bc1\u660e\u4e86 KT \u5f15\u5bfc\u7684 RL \u5728\u4e2a\u6027\u5316\u6559\u80b2\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.10972", "categories": ["cs.CL", "cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2507.10972", "abs": "https://arxiv.org/abs/2507.10972", "authors": ["Zhaoyi An", "Rei Kawakami"], "title": "Teach Me Sign: Stepwise Prompting LLM for Sign Language Production", "comment": "Accepted by IEEE ICIP 2025", "summary": "Large language models, with their strong reasoning ability and rich\nknowledge, have brought revolution to many tasks of AI, but their impact on\nsign language generation remains limited due to its complexity and unique\nrules. In this paper, we propose TEAch Me Sign (TEAM-Sign), treating sign\nlanguage as another natural language. By fine-tuning an LLM, we enable it to\nlearn the correspondence between text and sign language, and facilitate\ngeneration. Considering the differences between sign and spoken language, we\nemploy a stepwise prompting strategy to extract the inherent sign language\nknowledge within the LLM, thereby supporting the learning and generation\nprocess. Experimental results on How2Sign and Phoenix14T datasets demonstrate\nthat our approach effectively leverages both the sign language knowledge and\nreasoning capabilities of LLM to align the different distribution and\ngrammatical rules between sign and spoken language.", "AI": {"tldr": "TEAM-Sign fine-tunes an LLM to generate sign language by treating it as a natural language, using stepwise prompting to bridge the gap between sign and spoken languages.", "motivation": "To address the limited impact of LLMs on sign language generation due to its complexity and unique rules, by treating sign language as a natural language.", "method": "TEAM-Sign, a method that fine-tunes an LLM by treating sign language as a natural language, employing a stepwise prompting strategy to extract inherent sign language knowledge for learning and generation.", "result": "Experimental results on How2Sign and Phoenix14T datasets demonstrate the effectiveness of the approach in aligning different distributions and grammatical rules between sign and spoken languages.", "conclusion": "The proposed TEAM-Sign approach effectively leverages LLM's sign language knowledge and reasoning capabilities to address the distribution and grammatical differences between sign and spoken languages, showing promising results on How2Sign and Phoenix14T datasets."}}
{"id": "2507.10623", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10623", "abs": "https://arxiv.org/abs/2507.10623", "authors": ["Daniel Saragih", "Deyu Cao", "Tejas Balaji"], "title": "Flows and Diffusions on the Neural Manifold", "comment": "40 pages, 6 figures, 13 tables", "summary": "Diffusion and flow-based generative models have achieved remarkable success\nin domains such as image synthesis, video generation, and natural language\nmodeling. In this work, we extend these advances to weight space learning by\nleveraging recent techniques to incorporate structural priors derived from\noptimization dynamics. Central to our approach is modeling the trajectory\ninduced by gradient descent as a trajectory inference problem. We unify several\ntrajectory inference techniques under the framework of gradient flow matching,\nproviding a theoretical framework for treating optimization paths as inductive\nbias. We further explore architectural and algorithmic choices, including\nreward fine-tuning by adjoint matching, the use of autoencoders for latent\nweight representation, conditioning on task-specific context data, and adopting\ninformative source distributions such as Kaiming uniform. Experiments\ndemonstrate that our method matches or surpasses baselines in generating\nin-distribution weights, improves initialization for downstream training, and\nsupports fine-tuning to enhance performance. Finally, we illustrate a practical\napplication in safety-critical systems: detecting harmful covariate shifts,\nwhere our method outperforms the closest comparable baseline.", "AI": {"tldr": "\u901a\u8fc7\u68af\u5ea6\u6d41\u5339\u914d\u5c06\u6269\u6563\u6a21\u578b\u5e94\u7528\u4e8e\u6743\u91cd\u7a7a\u95f4\u5b66\u4e60\uff0c\u4ee5\u6539\u8fdb\u6a21\u578b\u521d\u59cb\u5316\u548c\u68c0\u6d4b\u5f02\u5e38\u3002", "motivation": "\u5c06\u6269\u6563\u548c\u6d41\u6a21\u578b\u5728\u56fe\u50cf\u3001\u89c6\u9891\u548c\u81ea\u7136\u8bed\u8a00\u751f\u6210\u65b9\u9762\u7684\u6210\u529f\u6269\u5c55\u5230\u6743\u91cd\u7a7a\u95f4\u5b66\u4e60\uff0c\u5e76\u5229\u7528\u4f18\u5316\u52a8\u529b\u5b66\u4e2d\u63d0\u53d6\u7684\u7ed3\u6784\u5316\u5148\u9a8c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u68af\u5ea6\u4e0b\u964d\u8f68\u8ff9\u89c6\u4e3a\u8f68\u8ff9\u63a8\u7406\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u5e76\u5c06\u5176\u7edf\u4e00\u5728\u68af\u5ea6\u6d41\u5339\u914d\u6846\u67b6\u4e0b\uff0c\u5c06\u4f18\u5316\u8def\u5f84\u4f5c\u4e3a\u5f52\u7eb3\u504f\u7f6e\u3002\u63a2\u7d22\u4e86\u5305\u62ec\u901a\u8fc7\u4f34\u968f\u5339\u914d\u8fdb\u884c\u5956\u52b1\u5fae\u8c03\u3001\u4f7f\u7528\u81ea\u7f16\u7801\u5668\u8868\u793a\u6f5c\u5728\u6743\u91cd\u3001\u6761\u4ef6\u5316\u4efb\u52a1\u7279\u5b9a\u4e0a\u4e0b\u6587\u6570\u636e\u4ee5\u53ca\u91c7\u7528 Kaiming \u5747\u5300\u5206\u5e03\u7b49\u67b6\u6784\u548c\u7b97\u6cd5\u9009\u62e9\u3002", "result": "\u5728\u751f\u6210\u5206\u5e03\u5185\u6743\u91cd\u3001\u6539\u8fdb\u4e0b\u6e38\u8bad\u7ec3\u521d\u59cb\u5316\u4ee5\u53ca\u901a\u8fc7\u5fae\u8c03\u63d0\u5347\u6027\u80fd\u65b9\u9762\uff0c\u8be5\u65b9\u6cd5\u4e0e\u57fa\u7ebf\u76f8\u5f53\u6216\u66f4\u4f18\u3002\u5728\u68c0\u6d4b\u6709\u5bb3\u534f\u53d8\u91cf\u504f\u79fb\u7684\u5e94\u7528\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4e5f\u4f18\u4e8e\u6700\u63a5\u8fd1\u7684\u53ef\u6bd4\u57fa\u7ebf\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c06\u6269\u6563\u548c\u6d41\u6a21\u578b\u6269\u5c55\u5230\u6743\u91cd\u7a7a\u95f4\u5b66\u4e60\uff0c\u901a\u8fc7\u5c06\u68af\u5ea6\u4e0b\u964d\u8f68\u8ff9\u5efa\u6a21\u4e3a\u8f68\u8ff9\u63a8\u7406\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u68af\u5ea6\u6d41\u5339\u914d\u6846\u67b6\u3002\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u751f\u6210\u6743\u91cd\u3001\u6539\u8fdb\u521d\u59cb\u5316\u548c\u652f\u6301\u5fae\u8c03\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\uff0c\u5e76\u5728\u68c0\u6d4b\u6709\u5bb3\u534f\u53d8\u91cf\u504f\u79fb\u65b9\u9762\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.11069", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11069", "abs": "https://arxiv.org/abs/2507.11069", "authors": ["Jeongyun Kim", "Seunghoon Jeong", "Giseop Kim", "Myung-Hwan Jeon", "Eunji Jun", "Ayoung Kim"], "title": "TRAN-D: 2D Gaussian Splatting-based Sparse-view Transparent Object Depth Reconstruction via Physics Simulation for Scene Update", "comment": null, "summary": "Understanding the 3D geometry of transparent objects from RGB images is\nchallenging due to their inherent physical properties, such as reflection and\nrefraction. To address these difficulties, especially in scenarios with sparse\nviews and dynamic environments, we introduce TRAN-D, a novel 2D Gaussian\nSplatting-based depth reconstruction method for transparent objects. Our key\ninsight lies in separating transparent objects from the background, enabling\nfocused optimization of Gaussians corresponding to the object. We mitigate\nartifacts with an object-aware loss that places Gaussians in obscured regions,\nensuring coverage of invisible surfaces while reducing overfitting.\nFurthermore, we incorporate a physics-based simulation that refines the\nreconstruction in just a few seconds, effectively handling object removal and\nchain-reaction movement of remaining objects without the need for rescanning.\nTRAN-D is evaluated on both synthetic and real-world sequences, and it\nconsistently demonstrated robust improvements over existing GS-based\nstate-of-the-art methods. In comparison with baselines, TRAN-D reduces the mean\nabsolute error by over 39% for the synthetic TRansPose sequences. Furthermore,\ndespite being updated using only one image, TRAN-D reaches a {\\delta} < 2.5 cm\naccuracy of 48.46%, over 1.5 times that of baselines, which uses six images.\nCode and more results are available at https://jeongyun0609.github.io/TRAN-D/.", "AI": {"tldr": "TRAN-D\u662f\u4e00\u79cd\u65b0\u9896\u76842D\u9ad8\u65af\u6cfc\u6e85\u65b9\u6cd5\uff0c\u7528\u4e8e\u4eceRGB\u56fe\u50cf\u91cd\u5efa\u900f\u660e\u7269\u4f53\u76843D\u51e0\u4f55\u5f62\u72b6\u3002\u5b83\u901a\u8fc7\u5c06\u900f\u660e\u7269\u4f53\u4e0e\u80cc\u666f\u5206\u79bb\u5e76\u4f7f\u7528\u5bf9\u8c61\u611f\u77e5\u635f\u5931\u6765\u4f18\u5316\u9ad8\u65af\uff0c\u4ece\u800c\u89e3\u51b3\u53cd\u5c04\u548c\u6298\u5c04\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u5728\u7a00\u758f\u89c6\u56fe\u548c\u52a8\u6001\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5176\u7cbe\u5ea6\u6bd4\u57fa\u7ebf\u9ad8\u51fa1.5\u500d\u4ee5\u4e0a\u3002", "motivation": "\u4eceRGB\u56fe\u50cf\u7406\u89e3\u900f\u660e\u7269\u4f53\u76843D\u51e0\u4f55\u5f62\u72b6\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u5b83\u4eec\u56fa\u6709\u7684\u7269\u7406\u7279\u6027\uff08\u5982\u53cd\u5c04\u548c\u6298\u5c04\uff09\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u56f0\u96be\uff0c\u7279\u522b\u662f\u5728\u89c6\u56fe\u7a00\u758f\u548c\u52a8\u6001\u73af\u5883\u7684\u573a\u666f\u4e2d\uff0c\u6211\u4eec\u5f15\u5165\u4e86TRAN-D\u3002", "method": "TRAN-D\u662f\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e2D\u9ad8\u65af\u6cfc\u6e85\u7684\u900f\u660e\u7269\u4f53\u6df1\u5ea6\u91cd\u5efa\u65b9\u6cd5\uff0c\u5b83\u5c06\u900f\u660e\u7269\u4f53\u4e0e\u80cc\u666f\u5206\u79bb\uff0c\u4ece\u800c\u80fd\u591f\u96c6\u4e2d\u4f18\u5316\u5bf9\u5e94\u4e8e\u7269\u4f53\u7684\n\u9ad8\u65af\u3002\n\u6211\u4eec\u901a\u8fc7\u4e00\u79cd\u4f7f\u9ad8\u65af\u4f4d\u4e8e\u88ab\u906e\u6321\u533a\u57df\u7684\u5bf9\u8c61\u611f\u77e5\u635f\u5931\u6765\u51cf\u8f7b\u4f2a\u5f71\uff0c\u786e\u4fdd\u8986\u76d6\u4e0d\u53ef\u89c1\u8868\u9762\uff0c\u540c\u65f6\u51cf\u5c11\u8fc7\u62df\u5408\u3002\n\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u7ed3\u5408\u4e86\u57fa\u4e8e\u7269\u7406\u7684\u6a21\u62df\uff0c\u80fd\u591f\u5728\u51e0\u79d2\u949f\u5185\u4f18\u5316\u91cd\u5efa\uff0c\u6709\u6548\u5904\u7406\u7269\u4f53\u79fb\u9664\u548c\u5269\u4f59\u7269\u4f53\u7684\u94fe\u5f0f\u53cd\u5e94\u8fd0\u52a8\uff0c\u800c\u65e0\u9700\u91cd\u65b0\u626b\u63cf\u3002", "result": "TRAN-D\u5728\u5408\u6210TRansPose\u5e8f\u5217\u4e0a\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u51cf\u5c11\u4e8639%\u4ee5\u4e0a\u3002\n\u6b64\u5916\uff0c\u5c3d\u7ba1\u4ec5\u4f7f\u7528\u4e00\u5f20\u56fe\u50cf\u8fdb\u884c\u66f4\u65b0\uff0cTRAN-D\u7684{\\delta} < 2.5 cm\u7cbe\u5ea6\u8fbe\u5230\u4e8648.46%\uff0c\u662f\u57fa\u7ebf\uff08\u4f7f\u7528\u516d\u5f20\u56fe\u50cf\uff09\u76841.5\u500d\u4ee5\u4e0a\u3002", "conclusion": "TRAN-D\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u5e8f\u5217\u4e0a\u90fd\u5f97\u5230\u4e86\u8bc4\u4f30\uff0c\u5e76\u4e14\u5728\u57fa\u4e8eGS\u7684\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u65b9\u9762\u6301\u7eed\u5c55\u793a\u51fa\u7a33\u5065\u7684\u6539\u8fdb\u3002\u4e0e\u57fa\u7ebf\u76f8\u6bd4\uff0cTRAN-D\u5728\u5408\u6210TRansPose\u5e8f\u5217\u4e0a\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u51cf\u5c11\u4e8639%\u4ee5\u4e0a\u3002\u6b64\u5916\uff0c\u5c3d\u7ba1\u4ec5\u4f7f\u7528\u4e00\u5f20\u56fe\u50cf\u8fdb\u884c\u66f4\u65b0\uff0cTRAN-D\u7684{\\delta} < 2.5 cm\u7cbe\u5ea6\u8fbe\u5230\u4e8648.46%\uff0c\u662f\u57fa\u7ebf\uff08\u4f7f\u7528\u516d\u5f20\u56fe\u50cf\uff09\u76841.5\u500d\u4ee5\u4e0a\u3002"}}
{"id": "2507.11416", "categories": ["cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.11416", "abs": "https://arxiv.org/abs/2507.11416", "authors": ["Debashish Sur", "Nathan C. Smith", "Elaf A. Anber", "Kaitlyn L. Anderson", "Peter F. Connors", "Daniel Foley", "Mitra L. Taheri", "Junsoo Han", "Christopher M. Wolverton", "John R. Scully"], "title": "Revisiting the Influence of Sn in Cu-Al alloys: A Third Element Effect Enabling Stainless Steel Type Aqueous Passivation Behavior", "comment": null, "summary": "The influence of Sn alloying additions on the aqueous passivation behavior of\nCu-Al alloys was revisited and found to function as a new third element effect\nin acidified 0.1 M Na2SO4 solution. The role of each element during the process\nof aqueous passivation was investigated using electrochemical and\nsurface-sensitive ex-situ and in-operando spectroscopic techniques. The\nconnection between passivation and the atomic arrangements of atoms in the\nsolid solution was supported by first principles based cluster expansion\ncalculations and Monte Carlo simulations probing the chemical short-range order\nin the Cu-Al-Sn system. High purity Sn, like high purity Cu, did not passivate\nin the test environment, whereas high purity Al formed a passive film with a\nstable passive current density of 0.01 mA/cm^2. Cu-xAl-Sn solid solution alloys\nwhere x greater than 18 at.%, containing less than 3 at.% Sn additions\nexhibited lower corrosion rates than Cu-xAl alloys, brought by Al(III) and\nSn(IV, II) unidentified complex oxides formation on the surface. A strong\ninfluence of Sn on Al(III) passivation was observed, i.e., strongly suggesting\na third element effect type behavior. Possible governing processes explaining\nthe stainless steel type corrosion behavior are discussed, providing insights\nfor exploring novel synergies in the design of corrosion resistant alloys.", "AI": {"tldr": "Sn\u5408\u91d1\u6dfb\u52a0\u5242\u80fd\u6539\u5584Cu-Al\u5408\u91d1\u7684\u8010\u8150\u8680\u6027\uff0c\u901a\u8fc7\u5f62\u6210Al(III)\u548cSn(IV, II)\u7684\u7edc\u5408\u7269\u6c27\u5316\u7269\u964d\u4f4e\u8150\u8680\u901f\u7387\uff0c\u5e76\u8868\u73b0\u51fa\u7b2c\u4e09\u5143\u7d20\u6548\u5e94\u3002", "motivation": "\u91cd\u65b0\u5ba1\u89c6\u4e86Sn\u5408\u91d1\u6dfb\u52a0\u5242\u5bf9Cu-Al\u5408\u91d1\u6c34\u6027\u949d\u5316\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u5e76\u53d1\u73b0\u4e86\u5176\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u7b2c\u4e09\u5143\u7d20\u6548\u5e94\u3002", "method": "\u91c7\u7528\u7535\u5316\u5b66\u548c\u8868\u9762\u654f\u611f\u7684\u975e\u539f\u4f4d\u53ca\u5728\u4f4d\u5149\u8c31\u6280\u672f\u7814\u7a76\u4e86\u5404\u5143\u7d20\u5728\u6c34\u6027\u949d\u5316\u8fc7\u7a0b\u4e2d\u7684\u4f5c\u7528\u3002\u7ed3\u5408\u57fa\u4e8e\u7b2c\u4e00\u6027\u539f\u7406\u7684\u56e2\u7c07\u5c55\u5f00\u8ba1\u7b97\u548c\u8499\u7279\u5361\u6d1b\u6a21\u62df\uff0c\u63a2\u7a76\u4e86Cu-Al-Sn\u4f53\u7cfb\u4e2d\u5316\u5b66\u77ed\u7a0b\u6709\u5e8f\u4e0e\u949d\u5316\u4e4b\u95f4\u7684\u8054\u7cfb\u3002", "result": "\u9ad8\u7eaf\u5ea6Sn\u548cCu\u5728\u6d4b\u8bd5\u73af\u5883\u4e2d\u5747\u672a\u949d\u5316\uff0c\u800c\u9ad8\u7eaf\u5ea6Al\u5219\u5f62\u6210\u4e86\u5177\u6709\u7a33\u5b9a\u949d\u5316\u7535\u6d41\u5bc6\u5ea6\uff080.01 mA/cm^2\uff09\u7684\u949d\u5316\u819c\u3002Cu-xAl-Sn\u56fa\u6eb6\u4f53\u5408\u91d1\uff08x > 18 at.%\uff09\u5728\u6dfb\u52a0Sn\uff08< 3 at.%\uff09\u540e\uff0c\u5176\u8150\u8680\u901f\u7387\u4f4e\u4e8e\u76f8\u5e94\u7684Cu-xAl\u5408\u91d1\uff0c\u8fd9\u5f52\u56e0\u4e8e\u8868\u9762\u5f62\u6210\u4e86Al(III)\u548cSn(IV, II)\u7684\u672a\u77e5\u7edc\u5408\u7269\u6c27\u5316\u7269\u3002Sn\u5bf9Al(III)\u949d\u5316\u6709\u5f88\u5f3a\u7684\u5f71\u54cd\uff0c\u8868\u660e\u4e86\u5176\u7b2c\u4e09\u5143\u7d20\u6548\u5e94\u3002", "conclusion": "Sn\u5408\u91d1\u6dfb\u52a0\u5242\u5bf9Cu-Al\u5408\u91d1\u7684\u6c34\u6027\u949d\u5316\u884c\u4e3a\u4ea7\u751f\u4e86\u663e\u8457\u5f71\u54cd\uff0c\u8868\u73b0\u51fa\u4e00\u79cd\u65b0\u7684\u7b2c\u4e09\u5143\u7d20\u6548\u5e94\u3002Sn\u7684\u6dfb\u52a0\u53ef\u4ee5\u964d\u4f4eCu-Al\u5408\u91d1\u7684\u8150\u8680\u901f\u7387\uff0c\u7279\u522b\u662f\u5728Al\u542b\u91cf\u5927\u4e8e18%\u4e14Sn\u542b\u91cf\u5c0f\u4e8e3%\u65f6\uff0c\u901a\u8fc7\u5f62\u6210Al(III)\u548cSn(IV, II)\u7684\u590d\u6742\u6c27\u5316\u7269\u6765\u5b9e\u73b0\u3002Sn\u5bf9Al(III)\u949d\u5316\u6709\u5f88\u5f3a\u7684\u5f71\u54cd\uff0c\u8bc1\u5b9e\u4e86\u5176\u7b2c\u4e09\u5143\u7d20\u6548\u5e94\u3002"}}
{"id": "2507.11425", "categories": ["cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2507.11425", "abs": "https://arxiv.org/abs/2507.11425", "authors": ["Olga Ken", "Dmytro Horiachyi", "Ilya Akimov", "Vladimir Korenev", "Vitalyi Gusev", "Leonid Litvin", "Michael Kahl", "Arne Ludwig", "Nikolai Spitzer", "Andreas D. Wieck", "Manfred Bayer"], "title": "High-frequency surface acoustic waves: Generation with sub-optical wavelength metal gratings and detection at the exciton resonance", "comment": null, "summary": "We demonstrate all-optical generation and detection of high-frequency (up to\n~30 GHz) surface acoustic waves (SAWs) in GaAs/AlGaAs heterostructures with\nshort-period Au gratings on top. We present a sensitive method of SAWs\ndetection by means of a polarization-sensitive pump-probe technique that\nexploits the narrow exciton resonance in high-quality GaAs. The elastic strain\nof the SAW causes modulation of the exciton energy in the time domain. As a\nresult, even a small deformation leads to a noticeable change in the dielectric\nfunction at the detection wavelength leading to an order of magnitude increase\nin the detection sensitivity as compared to detection apart from the resonance.\nA theoretical model is developed that considers two detection schemes: one\naccounting for probe light diffraction and one without.", "AI": {"tldr": "\u901a\u8fc7\u5229\u7528GaAs\u7684\u6fc0\u5b50\u5171\u632f\uff0c\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u79cd\u9ad8\u7075\u654f\u5ea6\u7684all-optical\u65b9\u6cd5\u6765\u751f\u6210\u548c\u68c0\u6d4b\u9ad8\u8fbe30 GHz\u7684\u8868\u9762\u58f0\u6ce2\u3002", "motivation": "\u4e3a\u4e86\u5b9e\u73b0\u9ad8\u9891\u8868\u9762\u58f0\u6ce2\uff08SAW\uff09\u7684all-optical\u751f\u6210\u548c\u68c0\u6d4b\uff0c\u5e76\u63d0\u9ad8\u68c0\u6d4b\u7075\u654f\u5ea6\u3002", "method": "\u5229\u7528\u504f\u632f\u654f\u611f\u6cf5\u6d66-\u63a2\u6d4b\u6280\u672f\uff0c\u901a\u8fc7\u6fc0\u5b50\u5171\u632f\u5f15\u8d77\u7684\u4ecb\u7535\u51fd\u6570\u53d8\u5316\u6765\u68c0\u6d4bSAW\uff0c\u5e76\u5efa\u7acb\u4e86\u4e00\u4e2a\u8003\u8651\u4e86\u63a2\u9488\u5149\u884d\u5c04\u548c\u4e0d\u8003\u8651\u63a2\u9488\u5149\u884d\u5c04\u4e24\u79cd\u60c5\u51b5\u7684\u7406\u8bba\u6a21\u578b\u3002", "result": "\u6210\u529f\u751f\u6210\u548c\u68c0\u6d4b\u4e86\u9ad8\u8fbe~30 GHz\u7684SAW\uff0c\u5e76\u5c06\u68c0\u6d4b\u7075\u654f\u5ea6\u63d0\u9ad8\u4e86\u7ea6\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u6211\u4eec\u5c55\u793a\u4e86\u5728\u5177\u6709\u77ed\u5468\u671fAu\u5149\u6805\u7684GaAs/AlAlOx\u5f02\u8d28\u7ed3\u6784\u4e2d all-optical \u751f\u6210\u548c\u68c0\u6d4b\u9ad8\u9891\uff08\u9ad8\u8fbe~30 GHz\uff09\u8868\u9762\u58f0\u6ce2\uff08SAW\uff09\u7684\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528GaAs\u7a84\u6fc0\u5b50\u5171\u632f\u7684\uff0c\u5bf9SAW\u8fdb\u884c\u68c0\u6d4b\u7684\u504f\u632f\u654f\u611f\u6cf5\u6d66-\u63a2\u6d4b\u6280\u672f\uff0c\u8be5\u6280\u672f\u80fd\u591f\u5b9e\u73b0\u6bd4\u79bb\u5f00\u5171\u632f\u70b9\u68c0\u6d4b\u9ad8\u4e00\u4e2a\u6570\u91cf\u7ea7\u7684\u68c0\u6d4b\u7075\u654f\u5ea6\u3002"}}
{"id": "2507.10977", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10977", "abs": "https://arxiv.org/abs/2507.10977", "authors": ["Quan Bi Pay", "Vishnu Monn Baskaran", "Junn Yong Loo", "KokSheik Wong", "Simon See"], "title": "Conceptualizing Multi-scale Wavelet Attention and Ray-based Encoding for Human-Object Interaction Detection", "comment": "Accepted at International Joint Conference on Neural Networks (IJCNN\n  2025)", "summary": "Human-object interaction (HOI) detection is essential for accurately\nlocalizing and characterizing interactions between humans and objects,\nproviding a comprehensive understanding of complex visual scenes across various\ndomains. However, existing HOI detectors often struggle to deliver reliable\npredictions efficiently, relying on resource-intensive training methods and\ninefficient architectures. To address these challenges, we conceptualize a\nwavelet attention-like backbone and a novel ray-based encoder architecture\ntailored for HOI detection. Our wavelet backbone addresses the limitations of\nexpressing middle-order interactions by aggregating discriminative features\nfrom the low- and high-order interactions extracted from diverse convolutional\nfilters. Concurrently, the ray-based encoder facilitates multi-scale attention\nby optimizing the focus of the decoder on relevant regions of interest and\nmitigating computational overhead. As a result of harnessing the attenuated\nintensity of learnable ray origins, our decoder aligns query embeddings with\nemphasized regions of interest for accurate predictions. Experimental results\non benchmark datasets, including ImageNet and HICO-DET, showcase the potential\nof our proposed architecture. The code is publicly available at\n[https://github.com/henry-pay/RayEncoder].", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u5c0f\u6ce2\u6ce8\u610f\u529b\u548c\u5c04\u7ebf\u7f16\u7801\u5668\u7684 HOI \u68c0\u6d4b\u67b6\u6784\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u6548\u7387\u548c\u6027\u80fd\u95ee\u9898\uff0c\u5e76\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6709\u5e0c\u671b\u7684\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709 HOI \u68c0\u6d4b\u5668\u5728\u9ad8\u6548\u63d0\u4f9b\u53ef\u9760\u9884\u6d4b\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u5b83\u4eec\u4f9d\u8d56\u4e8e\u8d44\u6e90\u5bc6\u96c6\u578b\u7684\u8bad\u7ec3\u65b9\u6cd5\u548c\u6548\u7387\u4f4e\u4e0b\u7684\u67b6\u6784\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u7c7b\u4f3c\u5c0f\u6ce2\u6ce8\u610f\u529b\uff08wavelet attention-like\uff09\u7684\u9aa8\u5e72\u7f51\u7edc\u548c\u4e00\u4e2a\u65b0\u9896\u7684\u57fa\u4e8e\u5c04\u7ebf\uff08ray-based\uff09\u7684\u7f16\u7801\u5668\u67b6\u6784\uff0c\u4e13\u95e8\u7528\u4e8e HOI \u68c0\u6d4b\u3002\u5c0f\u6ce2\u9aa8\u5e72\u7f51\u7edc\u901a\u8fc7\u805a\u5408\u6765\u81ea\u4e0d\u540c\u5377\u79ef\u6ee4\u6ce2\u5668\u63d0\u53d6\u7684\u4f4e\u9636\u548c\u9ad8\u9636\u4ea4\u4e92\u7684\u533a\u5206\u6027\u7279\u5f81\uff0c\u89e3\u51b3\u4e86\u8868\u8fbe\u4e2d\u9636\u4ea4\u4e92\u7684\u5c40\u9650\u6027\u3002\u540c\u65f6\uff0c\u57fa\u4e8e\u5c04\u7ebf\u7684\u7f16\u7801\u5668\u901a\u8fc7\u4f18\u5316\u89e3\u7801\u5668\u5bf9\u76f8\u5173\u611f\u5174\u8da3\u533a\u57df\u7684\u5173\u6ce8\u5e76\u51cf\u8f7b\u8ba1\u7b97\u5f00\u9500\uff0c\u5b9e\u73b0\u4e86\u591a\u5c3a\u5ea6\u6ce8\u610f\u3002\u6211\u4eec\u7684\u89e3\u7801\u5668\u5229\u7528\u53ef\u5b66\u4e60\u5c04\u7ebf\u6e90\u7684\u8870\u51cf\u5f3a\u5ea6\uff0c\u4f7f\u67e5\u8be2\u5d4c\u5165\u4e0e\u5f3a\u5316\u7684\u611f\u5174\u8da3\u533a\u57df\u5bf9\u9f50\uff0c\u4ece\u800c\u5b9e\u73b0\u51c6\u786e\u7684\u9884\u6d4b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u63d0\u51fa\u7684\u67b6\u6784\u5728 HOI \u68c0\u6d4b\u4efb\u52a1\u4e0a\u5177\u6709\u6f5c\u529b\u3002", "conclusion": "\u5728 ImageNet \u548c HICO-DET \u7b49\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u63d0\u51fa\u7684\u67b6\u6784\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2507.11079", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11079", "abs": "https://arxiv.org/abs/2507.11079", "authors": ["Li Wang", "Qizhen Wu", "Lei Chen"], "title": "Tactical Decision for Multi-UGV Confrontation with a Vision-Language Model-Based Commander", "comment": null, "summary": "In multiple unmanned ground vehicle confrontations, autonomously evolving\nmulti-agent tactical decisions from situational awareness remain a significant\nchallenge. Traditional handcraft rule-based methods become vulnerable in the\ncomplicated and transient battlefield environment, and current reinforcement\nlearning methods mainly focus on action manipulation instead of strategic\ndecisions due to lack of interpretability. Here, we propose a vision-language\nmodel-based commander to address the issue of intelligent\nperception-to-decision reasoning in autonomous confrontations. Our method\nintegrates a vision language model for scene understanding and a lightweight\nlarge language model for strategic reasoning, achieving unified perception and\ndecision within a shared semantic space, with strong adaptability and\ninterpretability. Unlike rule-based search and reinforcement learning methods,\nthe combination of the two modules establishes a full-chain process, reflecting\nthe cognitive process of human commanders. Simulation and ablation experiments\nvalidate that the proposed approach achieves a win rate of over 80% compared\nwith baseline models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u548c\u8f7b\u91cf\u7ea7\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6307\u6325\u7cfb\u7edf\uff0c\u7528\u4e8e\u81ea\u4e3b\u5bf9\u6297\u4e2d\u7684\u6001\u52bf\u611f\u77e5\u548c\u6218\u7565\u51b3\u7b56\uff0c\u63d0\u9ad8\u4e86\u9002\u5e94\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u5728\u4eff\u771f\u4e2d\u53d6\u5f97\u4e86\u8d85\u8fc780%\u7684\u80dc\u7387\u3002", "motivation": "\u4f20\u7edf\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u5728\u590d\u6742\u6218\u573a\u73af\u5883\u4e2d\u5bb9\u6613\u5931\u6548\uff0c\u800c\u73b0\u6709\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7531\u4e8e\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u4e3b\u8981\u5173\u6ce8\u52a8\u4f5c\u800c\u975e\u6218\u7565\u51b3\u7b56\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u7684\u6307\u6325\u7cfb\u7edf\uff0c\u6574\u5408\u4e86\u7528\u4e8e\u573a\u666f\u7406\u89e3\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u548c\u7528\u4e8e\u6218\u7565\u63a8\u7406\u7684\u8f7b\u91cf\u7ea7\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u5171\u4eab\u8bed\u4e49\u7a7a\u95f4\u5185\u7684\u7edf\u4e00\u611f\u77e5\u548c\u51b3\u7b56\u3002", "result": "\u4eff\u771f\u548c\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u4e0e\u57fa\u7ebf\u6a21\u578b\u76f8\u6bd4\uff0c\u80dc\u7387\u8d85\u8fc780%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u548c\u8f7b\u91cf\u7ea7\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u7edf\u4e00\u7684\u611f\u77e5\u548c\u51b3\u7b56\uff0c\u5728\u81ea\u4e3b\u5bf9\u6297\u4e2d\u5c55\u73b0\u4e86\u5f3a\u5927\u7684\u9002\u5e94\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2507.10996", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.10996", "abs": "https://arxiv.org/abs/2507.10996", "authors": ["Lin Tian", "Johanne R. Trippas", "Marian-Andrei Rizoiu"], "title": "Mario at EXIST 2025: A Simple Gateway to Effective Multilingual Sexism Detection", "comment": "12 pages, 5 tables, CLEF 2025", "summary": "This paper presents our approach to EXIST 2025 Task 1, addressing text-based\nsexism detection in English and Spanish tweets through hierarchical Low-Rank\nAdaptation (LoRA) of Llama 3.1 8B. Our method introduces conditional adapter\nrouting that explicitly models label dependencies across three hierarchically\nstructured subtasks: binary sexism identification, source intention detection,\nand multilabel sexism categorization. Unlike conventional LoRA applications\nthat target only attention layers, we apply adaptation to all linear\ntransformations, enhancing the model's capacity to capture task-specific\npatterns. In contrast to complex data processing and ensemble approaches, we\nshow that straightforward parameter-efficient fine-tuning achieves strong\nperformance. We train separate LoRA adapters (rank=16, QLoRA 4-bit) for each\nsubtask using unified multilingual training that leverages Llama 3.1's native\nbilingual capabilities. The method requires minimal preprocessing and uses\nstandard supervised learning. Our multilingual training strategy eliminates the\nneed for separate language-specific models, achieving 1.7-2.4\\% F1 improvements\nthrough cross-lingual transfer. With only 1.67\\% trainable parameters compared\nto full fine-tuning, our approach reduces training time by 75\\% and model\nstorage by 98\\%, while achieving competitive performance across all subtasks\n(ICM-Hard: 0.6774 for binary classification, 0.4991 for intention detection,\n0.6519 for multilabel categorization).", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e Llama 3.1 8B \u7684\u5206\u5c42 LoRA \u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u63a8\u6587\u4e2d\u5b58\u5728\u7684\u6027\u522b\u6b67\u89c6\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u9002\u914d\u6240\u6709\u7ebf\u6027\u5c42\u5e76\u5f15\u5165\u6761\u4ef6\u9002\u914d\u5668\u8def\u7531\u6765\u4f18\u5316\u6a21\u578b\u6027\u80fd\uff0c\u540c\u65f6\u901a\u8fc7\u7edf\u4e00\u7684\u591a\u8bed\u8a00\u8bad\u7ec3\u7b56\u7565\u5b9e\u73b0\u4e86\u8de8\u8bed\u8a00\u8fc1\u79fb\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u8f83\u4f4e\u53c2\u6570\u91cf\u548c\u663e\u8457\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\u548c\u5b58\u50a8\u5360\u7528\u7684\u540c\u65f6\uff0c\u53d6\u5f97\u4e86\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u8be5\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u6587\u672c\u4e2d\u7684\u6027\u522b\u6b67\u89c6\u68c0\u6d4b\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u53c2\u6570\u9ad8\u6548\u7684\u5fae\u8c03\u65b9\u6cd5\uff0c\u4ee5\u514b\u670d\u4f20\u7edf\u590d\u6742\u6570\u636e\u5904\u7406\u548c\u96c6\u6210\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u5206\u5c42\u4f4e\u79e9\u81ea\u9002\u5e94\u201d\uff08LoRA\uff09\u7684\u65b9\u6cd5\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u8fdb\u884c\u4e86\u6761\u4ef6\u9002\u914d\u5668\u8def\u7531\u7684\u6539\u8fdb\uff0c\u7528\u4e8e\u5904\u7406\u6587\u672c\u4e2d\u7684\u6027\u522b\u6b67\u89c6\u68c0\u6d4b\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8e Llama 3.1 8B \u6a21\u578b\uff0c\u5e76\u5bf9\u6240\u6709\u7ebf\u6027\u53d8\u6362\u8fdb\u884c\u4e86\u9002\u914d\uff0c\u800c\u975e\u4ec5\u9650\u4e8e\u6ce8\u610f\u529b\u5c42\u3002\u7814\u7a76\u4eba\u5458\u4e3a\u6bcf\u4e2a\u5b50\u4efb\u52a1\uff08\u4e8c\u5143\u6027\u522b\u6b67\u89c6\u8bc6\u522b\u3001\u6765\u6e90\u610f\u56fe\u68c0\u6d4b\u3001\u591a\u6807\u7b7e\u6027\u522b\u6b67\u89c6\u5206\u7c7b\uff09\u8bad\u7ec3\u4e86\u5355\u72ec\u7684 LoRA \u9002\u914d\u5668\uff08\u79e9=16\uff0cQLoRA 4 \u4f4d\uff09\uff0c\u5e76\u91c7\u7528\u4e86\u7edf\u4e00\u7684\u591a\u8bed\u8a00\u8bad\u7ec3\u7b56\u7565\uff0c\u5229\u7528\u4e86 Llama 3.1 \u7684\u53cc\u8bed\u80fd\u529b\u3002\u8be5\u65b9\u6cd5\u4ec5\u9700\u8981\u5f88\u5c11\u7684\u9884\u5904\u7406\uff0c\u5e76\u4f7f\u7528\u6807\u51c6\u7684\u76d1\u7763\u5b66\u4e60\u3002", "result": "\u8be5\u65b9\u6cd5\u5728 EXIST 2025 \u4efb\u52a1 1 \u4e2d\u53d6\u5f97\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u5728\u4e8c\u5143\u5206\u7c7b\u3001\u610f\u56fe\u68c0\u6d4b\u548c\u591a\u6807\u7b7e\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684 ICM-Hard \u5206\u522b\u8fbe\u5230\u4e86 0.6774\u30010.4991 \u548c 0.6519\u3002\u4e0e\u5168\u91cf\u5fae\u8c03\u76f8\u6bd4\uff0c\u53ef\u8bad\u7ec3\u53c2\u6570\u4ec5\u5360 1.67%\uff0c\u8bad\u7ec3\u65f6\u95f4\u7f29\u77ed\u4e86 75%\uff0c\u6a21\u578b\u5b58\u50a8\u51cf\u5c11\u4e86 98%\u3002\u591a\u8bed\u8a00\u8bad\u7ec3\u7b56\u7565\u901a\u8fc7\u8de8\u8bed\u8a00\u8fc1\u79fb\u5b9e\u73b0\u4e86 1.7-2.4% \u7684 F1 \u63d0\u5347\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u5b9e\u73b0\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u540c\u65f6\u5927\u5927\u51cf\u5c11\u4e86\u8bad\u7ec3\u65f6\u95f4\u548c\u6a21\u578b\u5b58\u50a8\u3002"}}
{"id": "2507.10626", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10626", "abs": "https://arxiv.org/abs/2507.10626", "authors": ["Lintao Wang", "Shiwen Xu", "Michael Horton", "Joachim Gudmundsson", "Zhiyong Wang"], "title": "Player-Team Heterogeneous Interaction Graph Transformer for Soccer Outcome Prediction", "comment": null, "summary": "Predicting soccer match outcomes is a challenging task due to the inherently\nunpredictable nature of the game and the numerous dynamic factors influencing\nresults. While it conventionally relies on meticulous feature engineering, deep\nlearning techniques have recently shown a great promise in learning effective\nplayer and team representations directly for soccer outcome prediction.\nHowever, existing methods often overlook the heterogeneous nature of\ninteractions among players and teams, which is crucial for accurately modeling\nmatch dynamics. To address this gap, we propose HIGFormer (Heterogeneous\nInteraction Graph Transformer), a novel graph-augmented transformer-based deep\nlearning model for soccer outcome prediction. HIGFormer introduces a\nmulti-level interaction framework that captures both fine-grained player\ndynamics and high-level team interactions. Specifically, it comprises (1) a\nPlayer Interaction Network, which encodes player performance through\nheterogeneous interaction graphs, combining local graph convolutions with a\nglobal graph-augmented transformer; (2) a Team Interaction Network, which\nconstructs interaction graphs from a team-to-team perspective to model\nhistorical match relationships; and (3) a Match Comparison Transformer, which\njointly analyzes both team and player-level information to predict match\noutcomes. Extensive experiments on the WyScout Open Access Dataset, a\nlarge-scale real-world soccer dataset, demonstrate that HIGFormer significantly\noutperforms existing methods in prediction accuracy. Furthermore, we provide\nvaluable insights into leveraging our model for player performance evaluation,\noffering a new perspective on talent scouting and team strategy analysis.", "AI": {"tldr": "HIGFormer\u901a\u8fc7\u5f02\u6784\u4ea4\u4e92\u56fe\u548cTransformer\u6765\u9884\u6d4b\u8db3\u7403\u6bd4\u8d5b\u7ed3\u679c\uff0c\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u4e86\u7403\u5458\u548c\u7403\u961f\u4e4b\u95f4\u4ea4\u4e92\u7684\u5f02\u6784\u6027\u8d28\uff0c\u800c\u8fd9\u5bf9\u4e8e\u51c6\u786e\u6a21\u62df\u6bd4\u8d5b\u52a8\u6001\u81f3\u5173\u91cd\u8981\u3002", "method": "HIGFormer\uff08\u5f02\u6784\u4ea4\u4e92\u56feTransformer\uff09\u6a21\u578b\uff0c\u4e00\u4e2a\u65b0\u9896\u7684\u56fe\u589e\u5f3aTransformer\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u3002\u8be5\u6a21\u578b\u5305\u542b\u4e09\u4e2a\u90e8\u5206\uff1a\uff081\uff09\u7403\u5458\u4ea4\u4e92\u7f51\u7edc\uff0c\u901a\u8fc7\u5f02\u6784\u4ea4\u4e92\u56fe\u7f16\u7801\u7403\u5458\u8868\u73b0\uff0c\u7ed3\u5408\u5c40\u90e8\u56fe\u5377\u79ef\u548c\u5168\u5c40\u56fe\u589e\u5f3aTransformer\uff1b\uff082\uff09\u7403\u961f\u4ea4\u4e92\u7f51\u7edc\uff0c\u4ece\u7403\u961f\u5230\u7403\u961f\u7684\u89d2\u5ea6\u6784\u5efa\u4ea4\u4e92\u56fe\u4ee5\u6a21\u62df\u5386\u53f2\u6bd4\u8d5b\u5173\u7cfb\uff1b\uff083\uff09\u6bd4\u8d5b\u6bd4\u8f83Transformer\uff0c\u8054\u5408\u5206\u6790\u7403\u961f\u548c\u7403\u5458\u5c42\u9762\u7684\u4fe1\u606f\u4ee5\u9884\u6d4b\u6bd4\u8d5b\u7ed3\u679c\u3002", "result": "\u5728WyScout\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cHIGFormer\u5728\u9884\u6d4b\u51c6\u786e\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "HIGFormer\u5728\u9884\u6d4b\u51c6\u786e\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u80fd\u4e3a\u7403\u5458\u8868\u73b0\u8bc4\u4f30\u3001\u4eba\u624d\u9009\u62d4\u548c\u7403\u961f\u7b56\u7565\u5206\u6790\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2507.11312", "categories": ["quant-ph", "cond-mat.dis-nn", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2507.11312", "abs": "https://arxiv.org/abs/2507.11312", "authors": ["Igor Poboiko", "Igor V. Gornyi", "Alexander D. Mirlin"], "title": "Mesoscopic Fluctuations and Multifractality at and across Measurement-Induced Phase Transition", "comment": "8 + 4 pages, 5 + 4 figures", "summary": "We explore statistical fluctuations over the ensemble of quantum trajectories\nin a model of two-dimensional free fermions subject to projective monitoring of\nlocal charge across the measurement-induced phase transition. Our observables\nare the particle-number covariance between spatially separated regions,\n$G_{AB}$, and the two-point density correlation function, $\\mathcal{C}(r)$. Our\nresults exhibit a remarkable analogy to Anderson localization, with $G_{AB}$\ncorresponding to two-terminal conductance and $\\mathcal{C}(r)$ to two-point\nconductance, albeit with different replica limit and unconventional symmetry\nclass, geometry, and boundary conditions. In the delocalized phase, $G_{AB}$\nexhibits ``universal'', nearly Gaussian, fluctuations with variance of order\nunity. In the localized phase, we find a broad distribution of $G_{AB}$ with\n$\\overline{-\\ln G_{AB}} \\sim L $ (where $L$ is the system size) and the\nvariance $\\mathrm{var}(\\ln G_{AB}) \\sim L^\\mu$, and similarly for\n$\\mathcal{C}(r)$, with $\\mu \\approx 0.5$. At the transition point, the\ndistribution function of $G_{AB}$ becomes scale-invariant and $\\mathcal{C}(r)$\nexhibits multifractal statistics, $\\overline{\\mathcal{C}^{q}(r)}\\sim r^{-q(d+1)\n- \\Delta_{q}}$. We characterize the spectrum of multifractal dimensions\n$\\Delta_q$. Our findings lay the groundwork for mesoscopic theory of monitored\nsystems, paving the way for various extensions.", "AI": {"tldr": "\u53d7\u76d1\u6d4b\u7684\u4e8c\u7ef4\u81ea\u7531\u8d39\u7c73\u5b50\u5728\u6d4b\u91cf\u8bf1\u5bfc\u76f8\u53d8\u4e2d\uff0c\u5176\u7edf\u8ba1\u6da8\u843d\u4e0e Anderson \u5c40\u57df\u5316\u7c7b\u4f3c\u3002\u7814\u7a76\u5206\u6790\u4e86\u7c92\u5b50\u6570\u534f\u65b9\u5dee G_AB \u548c\u5bc6\u5ea6\u5173\u8054\u51fd\u6570 C(r)\uff0c\u53d1\u73b0\u5728\u4e0d\u540c\u76f8\u548c\u76f8\u53d8\u70b9\u5c55\u73b0\u51fa\u4e0d\u540c\u7684\u6da8\u843d\u7279\u6027\u548c\u591a\u91cd\u5206\u5f62\u884c\u4e3a\u3002", "motivation": "\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u63a2\u7d22\u91cf\u5b50\u8f68\u8ff9\u7cfb\u7efc\u4e0a\u7684\u7edf\u8ba1\u6da8\u843d\uff0c\u5e76\u63ed\u793a\u5176\u4e0e Anderson \u5c40\u57df\u5316\u7684\u7c7b\u6bd4\uff0c\u5c24\u5176\u662f\u5728\u6d4b\u91cf\u8bf1\u5bfc\u76f8\u53d8\u7684\u80cc\u666f\u4e0b\uff0c\u4ee5\u7406\u89e3\u53d7\u76d1\u6d4b\u91cf\u5b50\u7cfb\u7edf\u7684\u884c\u4e3a\u3002", "method": "\u7814\u7a76\u5229\u7528\u6295\u5f71\u76d1\u6d4b\u5c40\u90e8\u7535\u8377\u7684\u4e8c\u7ef4\u81ea\u7531\u8d39\u7c73\u5b50\u6a21\u578b\uff0c\u63a2\u7d22\u4e86\u91cf\u5b50\u8f68\u8ff9\u7cfb\u7efc\u4e0a\u7684\u7edf\u8ba1\u6da8\u843d\uff0c\u7279\u522b\u5173\u6ce8\u4e86\u6d4b\u91cf\u8bf1\u5bfc\u76f8\u53d8\u3002\u4e3b\u8981\u5206\u6790\u4e86\u7a7a\u95f4\u5206\u79bb\u533a\u57df\u95f4\u7684\u7c92\u5b50\u6570\u534f\u65b9\u5dee\uff08G_AB\uff09\u548c\u4e24\u70b9\u5bc6\u5ea6\u5173\u8054\u51fd\u6570\uff08C(r)\uff09\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0cG_AB\u5728\u975e\u5c40\u57df\u76f8\u4e2d\u8868\u73b0\u51fa\u63a5\u8fd1\u9ad8\u65af\u5206\u5e03\u7684\u666e\u9002\u6da8\u843d\uff0c\u65b9\u5dee\u7ea6\u4e3a1\u3002\u5728\u5c40\u57df\u76f8\u4e2d\uff0cG_AB\u7684\u5206\u5e03\u5e7f\u6cdb\uff0c\u5176\u5bf9\u6570\u65b9\u5dee\u4e0e\u7cfb\u7edf\u5c3a\u5bf8L\u6210\u6b63\u6bd4\uff0c\u65b9\u5dee\u7684\u5bf9\u6570\u589e\u957f\u7387\u4e0eL^\u03bc\uff08\u03bc\u22480.5\uff09\u6210\u6b63\u6bd4\u3002\u5728\u76f8\u53d8\u70b9\uff0cG_AB\u7684\u5206\u5e03\u51fd\u6570\u5177\u6709\u6807\u5ea6\u4e0d\u53d8\u6027\uff0cC(r)\u8868\u73b0\u51fa\u591a\u91cd\u5206\u5f62\u7edf\u8ba1\u7279\u6027\uff0c\u5e76\u8868\u5f81\u4e86\u591a\u91cd\u5206\u5f62\u7ef4\u6570\u8c31\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u53d7\u91cf\u5b50\u8f68\u8ff9\u7cfb\u7efc\u7edf\u8ba1\u6da8\u843d\u7684\u7c7b\u6bd4\uff0c\u8be5\u6a21\u578b\u4e3a\u4e8c\u7ef4\u81ea\u7531\u8d39\u7c73\u5b50\uff0c\u5728\u6295\u5f71\u76d1\u6d4b\u5c40\u90e8\u7535\u8377\u7684\u60c5\u51b5\u4e0b\uff0c\u7ecf\u5386\u4e86\u6d4b\u91cf\u8bf1\u5bfc\u76f8\u53d8\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5728\u975e\u5c40\u57df\u76f8\u4e2d\uff0c\u7c92\u5b50\u6570\u534f\u65b9\u5dee\uff08G_AB\uff09\u8868\u73b0\u51fa\u63a5\u8fd1\u9ad8\u65af\u5206\u5e03\u7684\u666e\u9002\u6da8\u843d\uff0c\u65b9\u5dee\u7ea6\u4e3a1\u3002\u5728\u5c40\u57df\u76f8\u4e2d\uff0cG_AB\u7684\u5206\u5e03\u5e7f\u6cdb\uff0c\u4e14\u5176\u5bf9\u6570\u65b9\u5dee\u4e0e\u7cfb\u7edf\u5c3a\u5bf8L\u6210\u6b63\u6bd4\uff0c\u65b9\u5dee\u7684\u5bf9\u6570\u589e\u957f\u7387\u4e0eL^\u03bc\uff08\u03bc\u22480.5\uff09\u6210\u6b63\u6bd4\u3002\u5728\u76f8\u53d8\u70b9\uff0cG_AB\u7684\u5206\u5e03\u51fd\u6570\u5177\u6709\u6807\u5ea6\u4e0d\u53d8\u6027\uff0c\u800c\u5bc6\u5ea6\u5173\u8054\u51fd\u6570\uff08C(r)\uff09\u8868\u73b0\u51fa\u591a\u91cd\u5206\u5f62\u7edf\u8ba1\u7279\u6027\u3002\u7814\u7a76\u4e3a\u53d7\u76d1\u6d4b\u7cfb\u7edf\u7684\u4ecb\u89c2\u7406\u8bba\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5e76\u4e3a\u8fdb\u4e00\u6b65\u7684\u6269\u5c55\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002"}}
{"id": "2507.10892", "categories": ["quant-ph", "cond-mat.dis-nn", "cond-mat.stat-mech", "hep-th"], "pdf": "https://arxiv.org/pdf/2507.10892", "abs": "https://arxiv.org/abs/2507.10892", "authors": ["Tanay Pathak", "Masaki Tezuka"], "title": "Entanglement production in the Sachdev-Ye-Kitaev Model and its variants", "comment": "14 pages, 11 figures", "summary": "Understanding how quantum chaotic systems generate entanglement can provide\ninsight into their microscopic chaotic dynamics and can help distinguish\nbetween different classes of chaotic behavior. Using von Neumann entanglement\nentropy, we study a nonentangled state evolved under three variants of the\nSachdev-Ye-Kitaev (SYK) model with a finite number of Majorana fermions $N$.\nAll the variants exhibit linear entanglement growth at early times, which at\nlate times saturates to a universal value consistent with random matrix theory\n(RMT), but their growth rates differ. We interpret this as a large-$N$ effect,\narising from the enhanced non-locality of fermionic operators in SYK and binary\nSYK, absent in spin operators of the spin-SYK model. Numerically, we find that\nthese differences emerge gradually with increasing $N$. Although all variants\nare quantum chaotic, their entanglement dynamics reflect varying degrees of\nchaos and indicate that the entanglement production rate serves as a\nfine-grained probe of chaos beyond conventional measures. To probe its effect\non thermalization properties of these models, we study the two-point\nautocorrelation function, finding no differences between the SYK variants, but\ndeviations from RMT predictions for $N \\geq 24$, particularly near the\ncrossover from exponential decay to saturation regime.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5206\u6790SYK\u6a21\u578b\u53ca\u5176\u53d8\u4f53\u5728\u4e0d\u540cN\u4e0b\u7684\u7ea0\u7f20\u71b5\u548c\u4e24\u70b9\u81ea\u76f8\u5173\u51fd\u6570\uff0c\u63ed\u793a\u4e86\u7ea0\u7f20\u589e\u957f\u7387\u4f5c\u4e3a\u8861\u91cf\u6df7\u6c8c\u7684\u7cbe\u7ec6\u6307\u6807\uff0c\u5e76\u6307\u51fa\u4e86\u8d39\u7c73\u5b50\u7b97\u5b50\u7684\u975e\u5c40\u57df\u6027\u5bf9\u7ea0\u7f20\u52a8\u529b\u5b66\u7684\u5f71\u54cd\u3002", "motivation": "\u7406\u89e3\u91cf\u5b50\u6df7\u6c8c\u7cfb\u7edf\u5982\u4f55\u4ea7\u751f\u7ea0\u7f20\uff0c\u4ee5\u53ca\u8fd9\u5982\u4f55\u53cd\u6620\u5176\u6df7\u6c8c\u52a8\u529b\u5b66\u548c\u533a\u5206\u6df7\u6c8c\u884c\u4e3a\u3002", "method": "\u5229\u7528\u51af\u00b7\u8bfa\u4f9d\u66fc\u7ea0\u7f20\u71b5\uff0c\u7814\u7a76\u4e86\u5728\u4e09\u4e2aSYK\u6a21\u578b\u53d8\u4f53\uff08\u5177\u6709\u6709\u9650\u6570\u91cf\u7684Majorana\u8d39\u7c73\u5b50N\uff09\u4e0b\uff0c\u975e\u7ea0\u7f20\u6001\u7684\u6f14\u5316\u3002", "result": "\u6240\u6709SYK\u6a21\u578b\u53d8\u4f53\u5728\u65e9\u671f\u90fd\u8868\u73b0\u51fa\u7ebf\u6027\u7684\u7ea0\u7f20\u589e\u957f\uff0c\u5728\u540e\u671f\u5219\u9971\u548c\u5230\u4e00\u4e2a\u4e0e\u968f\u673a\u77e9\u9635\u7406\u8bba\uff08RMT\uff09\u4e00\u81f4\u7684\u666e\u9002\u503c\uff0c\u4f46\u589e\u957f\u901f\u7387\u4e0d\u540c\u3002\u8fd9\u79cd\u5dee\u5f02\u6e90\u4e8eSYK\u53ca\u5176\u4e8c\u5143\u53d8\u4f53\u4e2d\u8d39\u7c73\u5b50\u7b97\u5b50\u7684\u975e\u5c40\u57df\u6027\u589e\u5f3a\uff0c\u800c\u81ea\u65cbSYK\u6a21\u578b\u4e2d\u7684\u81ea\u65cb\u7b97\u5b50\u5219\u6ca1\u6709\u8fd9\u79cd\u6548\u5e94\u3002\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u968f\u7740N\u7684\u589e\u52a0\uff0c\u8fd9\u4e9b\u5dee\u5f02\u9010\u6e10\u663e\u73b0\u3002\u867d\u7136\u6240\u6709\u53d8\u4f53\u90fd\u662f\u91cf\u5b50\u6df7\u6c8c\u7684\uff0c\u4f46\u5b83\u4eec\u7684\u7ea0\u7f20\u52a8\u529b\u5b66\u53cd\u6620\u4e86\u4e0d\u540c\u7a0b\u5ea6\u7684\u6df7\u6c8c\uff0c\u5e76\u4e14\u7ea0\u7f20\u4ea7\u751f\u7387\u662f\u8d85\u8d8a\u4f20\u7edf\u6d4b\u91cf\u7684\u6df7\u6c8c\u7684\u7cbe\u7ec6\u63a2\u6d4b\u5668\u3002\u5728N\u226524\u65f6\uff0c\u4e24\u70b9\u81ea\u76f8\u5173\u51fd\u6570\u504f\u79bb\u4e86RMT\u9884\u6d4b\uff0c\u7279\u522b\u662f\u5728\u4ece\u6307\u6570\u8870\u51cf\u5230\u9971\u548c\u7684\u8fc7\u6e21\u533a\u57df\u3002", "conclusion": "\u91cf\u5b50\u6df7\u6c8c\u7cfb\u7edf\u4ea7\u751f\u7ea0\u7f20\u7684\u673a\u5236\u6709\u52a9\u4e8e\u7406\u89e3\u5176\u6df7\u6c8c\u52a8\u529b\u5b66\uff0c\u5e76\u533a\u5206\u4e0d\u540c\u7c7b\u522b\u7684\u6df7\u6c8c\u884c\u4e3a\u3002"}}
{"id": "2507.10978", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10978", "abs": "https://arxiv.org/abs/2507.10978", "authors": ["Ayush Gupta", "Siyuan Huang", "Rama Chellappa"], "title": "Mind the Gap: Bridging Occlusion in Gait Recognition via Residual Gap Correction", "comment": "Accepted at IJCB 2025", "summary": "Gait is becoming popular as a method of person re-identification because of\nits ability to identify people at a distance. However, most current works in\ngait recognition do not address the practical problem of occlusions. Among\nthose which do, some require paired tuples of occluded and holistic sequences,\nwhich are impractical to collect in the real world. Further, these approaches\nwork on occlusions but fail to retain performance on holistic inputs. To\naddress these challenges, we propose RG-Gait, a method for residual correction\nfor occluded gait recognition with holistic retention. We model the problem as\na residual learning task, conceptualizing the occluded gait signature as a\nresidual deviation from the holistic gait representation. Our proposed network\nadaptively integrates the learned residual, significantly improving performance\non occluded gait sequences without compromising the holistic recognition\naccuracy. We evaluate our approach on the challenging Gait3D, GREW and BRIAR\ndatasets and show that learning the residual can be an effective technique to\ntackle occluded gait recognition with holistic retention.", "AI": {"tldr": "RG-Gait\u901a\u8fc7\u6b8b\u5dee\u5b66\u4e60\u89e3\u51b3\u906e\u6321\u6b65\u6001\u8bc6\u522b\u95ee\u9898\uff0c\u5728\u4e0d\u5f71\u54cd\u6574\u4f53\u8bc6\u522b\u51c6\u786e\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u63d0\u9ad8\u4e86\u906e\u6321\u6b65\u6001\u5e8f\u5217\u7684\u8bc6\u522b\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5927\u591a\u6570\u6b65\u6001\u8bc6\u522b\u7814\u7a76\u672a\u80fd\u89e3\u51b3\u906e\u6321\u95ee\u9898\uff0c\u5373\u4f7f\u6709\u90e8\u5206\u7814\u7a76\u89e3\u51b3\u4e86\u8be5\u95ee\u9898\uff0c\u4f46\u5b83\u4eec\u9700\u8981\u6210\u5bf9\u7684\u906e\u6321\u548c\u6574\u4f53\u5e8f\u5217\uff0c\u8fd9\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u96be\u4ee5\u6536\u96c6\u3002\u6b64\u5916\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5728\u5904\u7406\u906e\u6321\u95ee\u9898\u65f6\u4f1a\u727a\u7272\u5728\u6574\u4f53\u8f93\u5165\u4e0a\u7684\u6027\u80fd\u3002", "method": "RG-Gait\u65b9\u6cd5\u5c06\u906e\u6321\u6b65\u6001\u8bc6\u522b\u95ee\u9898\u5efa\u6a21\u4e3a\u4e00\u4e2a\u6b8b\u5dee\u5b66\u4e60\u4efb\u52a1\uff0c\u5c06\u906e\u6321\u6b65\u6001\u7b7e\u540d\u6982\u5ff5\u5316\u4e3a\u4e0e\u6574\u4f53\u6b65\u6001\u8868\u793a\u7684\u6b8b\u5dee\u504f\u5dee\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u591f\u81ea\u9002\u5e94\u96c6\u6210\u6240\u5b66\u6b8b\u5dee\u7684\u65b0\u578b\u7f51\u7edc\u3002", "result": "RG-Gait\u65b9\u6cd5\u5728Gait3D\u3001GREW\u548cBRIAR\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u906e\u6321\u6b65\u6001\u8bc6\u522b\u7684\u6311\u6218\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5bf9\u6574\u4f53\u6b65\u6001\u8f93\u5165\u7684\u8bc6\u522b\u51c6\u786e\u6027\u3002", "conclusion": "RG-Gait\u901a\u8fc7\u5c06\u906e\u6321\u6b65\u6001\u5efa\u6a21\u4e3a\u6574\u4f53\u6b65\u6001\u8868\u793a\u7684\u6b8b\u5dee\u504f\u5dee\uff0c\u5e76\u81ea\u9002\u5e94\u5730\u96c6\u6210\u6240\u5b66\u6b8b\u5dee\uff0c\u6210\u529f\u5730\u63d0\u9ad8\u4e86\u906e\u6321\u6b65\u6001\u5e8f\u5217\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u6574\u4f53\u8bc6\u522b\u7cbe\u5ea6\u3002\u8be5\u65b9\u6cd5\u5728Gait3D\u3001GREW\u548cBRIAR\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u8bc1\u660e\u4e86\u5b66\u4e60\u6b8b\u5dee\u662f\u89e3\u51b3\u5177\u6709\u6574\u4f53\u4fdd\u7559\u80fd\u529b\u7684\u906e\u6321\u6b65\u6001\u8bc6\u522b\u7684\u6709\u6548\u6280\u672f\u3002"}}
{"id": "2507.11083", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.11083", "abs": "https://arxiv.org/abs/2507.11083", "authors": ["Longhui Zhang", "Bin Wang", "Jiahao Wang", "Xiaofeng Zhao", "Min Zhang", "Hao Yang", "Meishan Zhang", "Yu Li", "Jing Li", "Jun Yu", "Min Zhang"], "title": "Function-to-Style Guidance of LLMs for Code Translation", "comment": "This paper has been accepted by ICML 2025. Models and benchmarks can\n  be found at https://www.modelscope.cn/collections/F2STrans-42526ff95dd843", "summary": "Large language models (LLMs) have made significant strides in code\ntranslation tasks. However, ensuring both the correctness and readability of\ntranslated code remains a challenge, limiting their effective adoption in\nreal-world software development. In this work, we propose F2STrans, a\nfunction-to-style guiding paradigm designed to progressively improve the\nperformance of LLMs in code translation. Our approach comprises two key stages:\n(1) Functional learning, which optimizes translation correctness using\nhigh-quality source-target code pairs mined from online programming platforms,\nand (2) Style learning, which improves translation readability by incorporating\nboth positive and negative style examples. Additionally, we introduce a novel\ncode translation benchmark that includes up-to-date source code, extensive test\ncases, and manually annotated ground-truth translations, enabling comprehensive\nfunctional and stylistic evaluations. Experiments on both our new benchmark and\nexisting datasets demonstrate that our approach significantly improves code\ntranslation performance. Notably, our approach enables Qwen-1.5B to outperform\nprompt-enhanced Qwen-32B and GPT-4 on average across 20 diverse code\ntranslation scenarios.", "AI": {"tldr": "F2STrans\u662f\u4e00\u79cd\u65b0\u7684\u4ee3\u7801\u7ffb\u8bd1\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u51fd\u6570\u5b66\u4e60\u548c\u98ce\u683c\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7ffb\u8bd1\u6027\u80fd\u548c\u4ee3\u7801\u53ef\u8bfb\u6027\uff0c\u751a\u81f3\u80fd\u8ba9\u5c0f\u6a21\u578b\u8d85\u8d8a\u5927\u6a21\u578b\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4ee3\u7801\u7ffb\u8bd1\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u8981\u786e\u4fdd\u7ffb\u8bd1\u4ee3\u7801\u7684\u6b63\u786e\u6027\u548c\u53ef\u8bfb\u6027\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728\u5b9e\u9645\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5e94\u7528\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u63d0\u51fa\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u63d0\u5347\u7ffb\u8bd1\u6b63\u786e\u6027\u548c\u53ef\u8bfb\u6027\u7684\u65b9\u6cd5\u3002", "method": "F2STrans\u91c7\u7528\u4e00\u4e2a\u5305\u542b\u4e24\u4e2a\u9636\u6bb5\u7684\u51fd\u6570\u5230\u98ce\u683c\u5f15\u5bfc\u8303\u5f0f\uff1a1. \u51fd\u6570\u5b66\u4e60\uff0c\u901a\u8fc7\u5728\u7ebf\u7f16\u7a0b\u5e73\u53f0\u6316\u6398\u9ad8\u8d28\u91cf\u7684\u6e90\u76ee\u6807\u4ee3\u7801\u5bf9\u6765\u4f18\u5316\u7ffb\u8bd1\u7684\u6b63\u786e\u6027\u30022. \u98ce\u683c\u5b66\u4e60\uff0c\u901a\u8fc7\u6574\u5408\u6b63\u8d1f\u9762\u98ce\u683c\u793a\u4f8b\u6765\u63d0\u5347\u7ffb\u8bd1\u7684\u53ef\u8bfb\u6027\u3002\u6b64\u5916\uff0c\u5f15\u5165\u4e86\u4e00\u4e2a\u5305\u542b\u6700\u65b0\u6e90\u4ee3\u7801\u3001\u5e7f\u6cdb\u6d4b\u8bd5\u7528\u4f8b\u548c\u4eba\u5de5\u6ce8\u91ca\u7684\u771f\u5b9e\u7ffb\u8bd1\u7684\u65b0\u578b\u4ee3\u7801\u7ffb\u8bd1\u57fa\u51c6\uff0c\u7528\u4e8e\u5168\u9762\u7684\u529f\u80fd\u548c\u98ce\u683c\u8bc4\u4f30\u3002", "result": "F2STrans\u663e\u8457\u63d0\u9ad8\u4e86\u4ee3\u7801\u7ffb\u8bd1\u6027\u80fd\u3002\u5728\u65b0\u7684\u57fa\u51c6\u548c\u73b0\u6709\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u4f7fQwen-1.5B\u572820\u79cd\u4e0d\u540c\u7684\u4ee3\u7801\u7ffb\u8bd1\u573a\u666f\u4e0b\uff0c\u5e73\u5747\u6027\u80fd\u4f18\u4e8e\u7ecf\u8fc7\u63d0\u793a\u589e\u5f3a\u7684Qwen-32B\u548cGPT-4\u3002", "conclusion": "F2STrans\u901a\u8fc7\u51fd\u6570\u5230\u98ce\u683c\u7684\u5f15\u5bfc\u8303\u5f0f\uff0c\u5728\u4ee3\u7801\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86LLM\u7684\u6027\u80fd\uff0c\u540c\u65f6\u786e\u4fdd\u4e86\u7ffb\u8bd1\u7684\u6b63\u786e\u6027\u548c\u53ef\u8bfb\u6027\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u4f7f\u8f83\u5c0f\u6a21\u578b\uff08\u5982Qwen-1.5B\uff09\u5728\u591a\u79cd\u4ee3\u7801\u7ffb\u8bd1\u573a\u666f\u4e0b\u8d85\u8d8a\u66f4\u5927\u7684\u6a21\u578b\uff08\u5982Qwen-32B\u548cGPT-4\uff09\u3002"}}
{"id": "2507.11004", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.11004", "abs": "https://arxiv.org/abs/2507.11004", "authors": ["Yejun Yoon", "Jaeyoon Jung", "Seunghyun Yoon", "Kunwoo Park"], "title": "Team HUMANE at AVeriTeC 2025: HerO 2 for Efficient Fact Verification", "comment": "ACL 2025 Workshop (FEVER)", "summary": "This paper presents HerO 2, Team HUMANE's system for the AVeriTeC shared task\nat the FEVER-25 workshop. HerO 2 is an enhanced version of HerO, the\nbest-performing open-source model from the previous year's challenge. It\nimproves evidence quality through document summarization and answer\nreformulation, optimizes veracity prediction via post-training quantization\nunder computational constraints, and enhances overall system performance by\nintegrating updated language model (LM) backbones. HerO 2 ranked second on the\nleaderboard while achieving the shortest runtime among the top three systems,\ndemonstrating both high efficiency and strong potential for real-world fact\nverification. The code is available at https://github.com/ssu-humane/HerO2.", "AI": {"tldr": "HerO 2 \u662f\u4e00\u4e2a\u7528\u4e8e\u4e8b\u5b9e\u6838\u67e5\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u6539\u8fdb\u8bc1\u636e\u8d28\u91cf\u3001\u4f18\u5316\u771f\u5b9e\u6027\u9884\u6d4b\u548c\u96c6\u6210\u66f4\u65b0\u7684 LM \u9aa8\u5e72\u6765\u63d0\u5347\u6027\u80fd\uff0c\u5728 AVeriTeC \u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u7b2c\u4e8c\u540d\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6700\u77ed\u7684\u8fd0\u884c\u65f6\u3002", "motivation": "HerO 2 \u662f HerO \u7684\u589e\u5f3a\u7248\u672c\uff0cHerO \u662f\u53bb\u5e74\u6311\u6218\u4e2d\u8868\u73b0\u6700\u4f73\u7684\u5f00\u6e90\u6a21\u578b\u3002", "method": "HerO 2 \u901a\u8fc7\u6587\u6863\u6458\u8981\u548c\u7b54\u6848\u6539\u5199\u6765\u63d0\u9ad8\u8bc1\u636e\u8d28\u91cf\uff0c\u901a\u8fc7\u8ba1\u7b97\u7ea6\u675f\u4e0b\u7684\u8bad\u7ec3\u540e\u91cf\u5316\u6765\u4f18\u5316\u771f\u5b9e\u6027\u9884\u6d4b\uff0c\u5e76\u901a\u8fc7\u96c6\u6210\u66f4\u65b0\u7684\u8bed\u8a00\u6a21\u578b\uff08LM\uff09\u9aa8\u5e72\u6765\u589e\u5f3a\u6574\u4f53\u7cfb\u7edf\u6027\u80fd\u3002", "result": "HerO 2 \u6392\u540d\u7b2c\u4e8c\uff0c\u8fd0\u884c\u65f6\u6700\u77ed\uff0c\u6548\u7387\u9ad8\u3002", "conclusion": "HerO 2 \u5728 AVeriTeC \u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u7b2c\u4e8c\u540d\u7684\u6210\u7ee9\uff0c\u5e76\u5b9e\u73b0\u4e86\u6700\u5feb\u7684\u8fd0\u884c\u65f6\uff0c\u5c55\u793a\u4e86\u5176\u5728\u73b0\u5b9e\u4e16\u754c\u4e8b\u5b9e\u6838\u67e5\u4e2d\u7684\u9ad8\u6548\u7387\u548c\u5f3a\u5927\u6f5c\u529b\u3002"}}
{"id": "2507.10628", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10628", "abs": "https://arxiv.org/abs/2507.10628", "authors": ["Ziru Liu", "Cheng Gong", "Xinyu Fu", "Yaofang Liu", "Ran Chen", "Shoubo Hu", "Suiyun Zhang", "Rui Liu", "Qingfu Zhang", "Dandan Tu"], "title": "GHPO: Adaptive Guidance for Stable and Efficient LLM Reinforcement Learning", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as\na powerful paradigm for facilitating the self-improvement of large language\nmodels (LLMs), particularly in the domain of complex reasoning tasks. However,\nprevailing on-policy RL methods often contend with significant training\ninstability and inefficiency. This is primarily due to a capacity-difficulty\nmismatch, where the complexity of training data frequently outpaces the model's\ncurrent capabilities, leading to critically sparse reward signals and stalled\nlearning progress. This challenge is particularly acute for smaller, more\nresource-efficient LLMs. To overcome this, we introduce the Guided Hybrid\nPolicy Optimization (GHPO), a novel difficulty-aware reinforcement learning\nframework. GHPO dynamically calibrates task difficulty by employing adaptive\nprompt refinement to provide targeted guidance. This unique approach adaptively\nbalances direct imitation learning for problems currently beyond the model's\nreach with exploration-based reinforcement learning for more manageable tasks,\neffectively creating a smooth and optimized learning curriculum. Extensive\nexperiments demonstrate that GHPO achieves an average performance gain of\napproximately 5% across six challenging mathematics benchmarks, consistently\noutperforming strong on-policy reinforcement learning and curriculum learning\nbaselines. Further analysis confirms that our framework significantly enhances\nboth training stability and final reasoning performance, thus offering a\nscalable and efficient solution for developing powerful and robust reasoning\nmodels.", "AI": {"tldr": "GHPO\u901a\u8fc7\u81ea\u9002\u5e94\u8c03\u6574\u4efb\u52a1\u96be\u5ea6\u548c\u6df7\u5408\u5b66\u4e60\u7b56\u7565\uff0c\u89e3\u51b3\u4e86RL\u5728LLM\u590d\u6742\u63a8\u7406\u8bad\u7ec3\u4e2d\u7684\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u5e94\u5bf9LLM\u7684\u590d\u6742\u63a8\u7406\u4efb\u52a1\u65f6\uff0c\u5e38\u5e38\u9762\u4e34\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u548c\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\uff0c\u8fd9\u4e3b\u8981\u662f\u7531\u4e8e\u80fd\u529b-\u96be\u5ea6\u4e0d\u5339\u914d\uff0c\u5bfc\u81f4\u5956\u52b1\u4fe1\u53f7\u7a00\u758f\uff0c\u5b66\u4e60\u505c\u6ede\uff0c\u5c24\u5176\u5bf9\u8d44\u6e90\u6709\u9650\u7684\u5c0f\u578bLLM\u800c\u8a00\u66f4\u4e3a\u4e25\u5cfb\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u5f15\u5bfc\u6df7\u5408\u7b56\u7565\u4f18\u5316\u201d\uff08GHPO\uff09\u7684\u65b0\u578bRL\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u91c7\u7528\u81ea\u9002\u5e94\u63d0\u793a\u7ec6\u5316\u6280\u672f\u6765\u52a8\u6001\u8c03\u6574\u4efb\u52a1\u96be\u5ea6\uff0c\u5e76\u7ed3\u5408\u6a21\u4eff\u5b66\u4e60\u548c\u57fa\u4e8e\u63a2\u7d22\u7684RL\uff0c\u4ee5\u521b\u5efa\u5e73\u6ed1\u7684\u5b66\u4e60\u8bfe\u7a0b\u3002", "result": "GHPO\u5728\u516d\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5e73\u5747\u6027\u80fd\u63d0\u5347\u4e86\u7ea65%\uff0c\u5e76\u4e14\u5728\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6700\u7ec8\u63a8\u7406\u6027\u80fd\u65b9\u9762\u5747\u663e\u8457\u4f18\u4e8e\u5f3a\u5927\u7684\u540c\u7b56\u7565RL\u548c\u8bfe\u7a0b\u5b66\u4e60\u57fa\u7ebf\u3002", "conclusion": "GHPO\u6846\u67b6\u901a\u8fc7\u81ea\u9002\u5e94\u63d0\u793a\u7ec6\u5316\u548c\u6df7\u5408\u5b66\u4e60\u7b56\u7565\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86LLM\u7684\u6027\u80fd\u548c\u7a33\u5b9a\u6027\uff0c\u5e73\u5747\u63d0\u5347\u7ea65%\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u5f3a\u5316\u5b66\u4e60\u548c\u8bfe\u7a0b\u5b66\u4e60\u65b9\u6cd5\uff0c\u4e3a\u5f00\u53d1\u5f3a\u5927\u4e14\u53ef\u9760\u7684\u63a8\u7406\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.11133", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.11133", "abs": "https://arxiv.org/abs/2507.11133", "authors": ["Luca Beber", "Edoardo Lamon", "Giacomo Moretti", "Matteo Saveriano", "Luca Fambri", "Luigi Palopoli", "Daniele Fontanelli"], "title": "Force-Based Viscosity and Elasticity Measurements for Material Biomechanical Characterisation with a Collaborative Robotic Arm", "comment": null, "summary": "Diagnostic activities, such as ultrasound scans and palpation, are relatively\nlow-cost. They play a crucial role in the early detection of health problems\nand in assessing their progression. However, they are also error-prone\nactivities, which require highly skilled medical staff. The use of robotic\nsolutions can be key to decreasing the inherent subjectivity of the results and\nreducing the waiting list. For a robot to perform palpation or ultrasound\nscans, it must effectively manage physical interactions with the human body,\nwhich greatly benefits from precise estimation of the patient's tissue\nbiomechanical properties. This paper assesses the accuracy and precision of a\nrobotic system in estimating the viscoelastic parameters of various materials,\nincluding some tests on ex vivo tissues as a preliminary proof-of-concept\ndemonstration of the method's applicability to biological samples. The\nmeasurements are compared against a ground truth derived from silicone\nspecimens with different viscoelastic properties, characterised using a\nhigh-precision instrument. Experimental results show that the robotic system's\naccuracy closely matches the ground truth, increasing confidence in the\npotential use of robots for such clinical applications.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528\u673a\u5668\u4eba\u7cfb\u7edf\u7cbe\u786e\u4f30\u7b97\u4e86\u6750\u6599\u7684\u7c98\u5f39\u6027\u53c2\u6570\uff0c\u5e76\u5728\u79bb\u4f53\u7ec4\u7ec7\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u7ed3\u679c\u663e\u793a\u5176\u51c6\u786e\u6027\u9ad8\uff0c\u4e3a\u673a\u5668\u4eba\u8f85\u52a9\u533b\u7597\u8bca\u65ad\u63d0\u4f9b\u4e86\u4fe1\u5fc3\u3002", "motivation": "\u4e3a\u4e86\u964d\u4f4e\u8bca\u65ad\u6d3b\u52a8\u7684\u8bef\u5dee\uff0c\u51cf\u5c11\u4e3b\u89c2\u6027\uff0c\u7f29\u77ed\u7b49\u5f85\u65f6\u95f4\uff0c\u5e76\u63a2\u7d22\u673a\u5668\u4eba\u6280\u672f\u5728\u533b\u7597\u8bca\u65ad\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "method": "\u901a\u8fc7\u673a\u5668\u4eba\u7cfb\u7edf\u8fdb\u884c\u7269\u7406\u4ea4\u4e92\uff0c\u7cbe\u786e\u4f30\u7b97\u4eba\u4f53\u7ec4\u7ec7\u7684\u751f\u7269\u529b\u5b66\u7279\u6027\uff0c\u8bc4\u4f30\u5176\u7c98\u5f39\u6027\u53c2\u6570\u7684\u51c6\u786e\u6027\u548c\u7cbe\u786e\u6027\u3002", "result": "\u673a\u5668\u4eba\u7cfb\u7edf\u4f30\u7b97\u7684\u7c98\u5f39\u6027\u53c2\u6570\u4e0e\u4f7f\u7528\u9ad8\u7cbe\u5ea6\u4eea\u5668\u83b7\u5f97\u7684\u771f\u503c\u975e\u5e38\u63a5\u8fd1\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u673a\u5668\u4eba\u7cfb\u7edf\u5728\u6d4b\u91cf\u4e0d\u540c\u7c98\u5f39\u6027\u53c2\u6570\u7684\u6750\u6599\u65b9\u9762\u5177\u6709\u9ad8\u51c6\u786e\u6027\u548c\u7cbe\u786e\u6027\uff0c\u5e76\u5df2\u5728\u79bb\u4f53\u7ec4\u7ec7\u4e0a\u8fdb\u884c\u4e86\u521d\u6b65\u6982\u5ff5\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u751f\u7269\u6837\u672c\u4e0a\u7684\u9002\u7528\u6027\u3002\u8fd9\u589e\u5f3a\u4e86\u673a\u5668\u4eba\u7528\u4e8e\u6b64\u7c7b\u4e34\u5e8a\u5e94\u7528\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.10908", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.10908", "abs": "https://arxiv.org/abs/2507.10908", "authors": ["Gary J Mooney", "Jedwin Villanueva", "Bhaskar Roy Radhan", "Joydip Ghosh", "Charles D Hill", "Lloyd C L Hollenberg"], "title": "An Optimization-Free Recursive QAOA for the Binary Paint Shop Problem", "comment": null, "summary": "The classical outer optimisation loop of the classical-quantum hybrid Quantum\nApproximate Optimisation Algorithm (QAOA) can be bypassed by transferring\nprecomputed parameters to larger unseen problem instances using the parameter\nconcentration property found in certain classes of problem instances. In this\npaper, parameter transfer is applied to the recursive-QAOA (RQAOA) approach of\nBravyi et al. implementing the Binary Paint Shop Problem (BPSP) -- an\noptimisation problem found in manufacturing where a sequence of cars are to be\npainted under certain constraints while minimising the number of colour changes\nbetween cars. The BPSP can be conveniently formulated as an Ising ground state\nproblem with a symmetric Hamiltonian and Ising graph structure that is\nwell-suited for QAOA parameter-transfer techniques. Throughout our quantum\nsimulated experiments, parameter transfer showed no noticeable reduction in\nsolution quality over optimisation for QAOA and RQAOA while substantially\nimproving the efficiency due to avoiding measurements required for\noptimisation. Additionally, RQAOA only requires measurements of\n$ZZ$-correlations instead of full statevectors, benefiting from the\nreverse-causal-cone feature that leads to circuits with significantly lower\nCNOT counts and depths. The performance of QAOA and RQAOA with parameter\ntransfer is benchmarked against classical solvers and heuristics and their\nresilience to non-optimal parameters is explored. The entanglement entropy and\nbond dimensions are obtained from matrix product state simulations to provide\nan indication of the classical resources required to simulate the quantum\nalgorithms. Circuit sizes and measurement counts are compared between the\nimplementations.", "AI": {"tldr": "\u901a\u8fc7\u5c06\u9884\u8ba1\u7b97\u7684\u53c2\u6570\u4f20\u9012\u7ed9RQAOA\uff0c\u53ef\u4ee5\u63d0\u9ad8BPSP\u95ee\u9898\u7684\u89e3\u51b3\u6548\u7387\uff0c\u5e76\u4e14 CNOT \u8ba1\u6570\u548c\u6df1\u5ea6\u66f4\u4f4e\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8QAOA\u7b97\u6cd5\u5728\u5904\u7406\u66f4\u5927\u3001\u672a\u89c1\u8fc7\u7684BPSP\u5b9e\u4f8b\u65f6\u7684\u6548\u7387\uff0c\u901a\u8fc7\u53c2\u6570\u4f20\u9012\u6280\u672f\u6765\u89c4\u907f\u5916\u5c42\u4f18\u5316\u5faa\u73af\u3002", "method": "\u4f7f\u7528\u53c2\u6570\u4f20\u9012\u6280\u672f\uff0c\u5c06\u9884\u8ba1\u7b97\u7684\u53c2\u6570\u5e94\u7528\u4e8eRQAOA\uff0c\u4ee5\u89e3\u51b3\u4e8c\u5143\u6cb9\u6f06\u8f66\u95f4\u95ee\u9898\uff08BPSP\uff09\u3002BPSP\u88ab\u8f6c\u5316\u4e3a\u5177\u6709\u5bf9\u79f0\u54c8\u5bc6\u987f\u91cf\u548cIsing\u56fe\u7ed3\u6784\u7684Ising\u57fa\u6001\u95ee\u9898\u3002", "result": "\u53c2\u6570\u4f20\u9012\u5728RQAOA\u4e2d\u6ca1\u6709\u660e\u663e\u964d\u4f4e\u89e3\u7684\u8d28\u91cf\uff0c\u540c\u65f6\u901a\u8fc7\u907f\u514d\u4f18\u5316\u6240\u9700\u7684\u6d4b\u91cf\u5927\u5927\u63d0\u9ad8\u4e86\u6548\u7387\u3002RQAOA\u4ec5\u9700\u8981ZZ\u76f8\u5173\u6027\u7684\u6d4b\u91cf\uff0c\u5e76\u4e14\u5177\u6709\u8f83\u4f4e\u7684CNOT\u8ba1\u6570\u548c\u6df1\u5ea6\u3002\u4e0e\u7ecf\u5178\u6c42\u89e3\u5668\u548c\u542f\u53d1\u5f0f\u7b97\u6cd5\u76f8\u6bd4\uff0cQAOA\u548cRQAOA\u7684\u6027\u80fd\u5f97\u5230\u4e86\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c06\u53c2\u6570\u4f20\u9012\u5e94\u7528\u4e8eRQAOA\uff0c\u4ee5\u89e3\u51b3BPSP\u95ee\u9898\uff0c\u5728\u4e0d\u727a\u7272\u89e3\u8d28\u91cf\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u4e86\u6548\u7387\uff0c\u5e76\u964d\u4f4e\u4e86CNOT\u8ba1\u6570\u548c\u6df1\u5ea6\u3002"}}
{"id": "2507.10999", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10999", "abs": "https://arxiv.org/abs/2507.10999", "authors": ["Quan Bi Pay", "Vishnu Monn Baskaran", "Junn Yong Loo", "KokSheik Wong", "Simon See"], "title": "SpaRTAN: Spatial Reinforcement Token-based Aggregation Network for Visual Recognition", "comment": "Accepted at International Joint Conference on Neural Networks (IJCNN\n  2025)", "summary": "The resurgence of convolutional neural networks (CNNs) in visual recognition\ntasks, exemplified by ConvNeXt, has demonstrated their capability to rival\ntransformer-based architectures through advanced training methodologies and\nViT-inspired design principles. However, both CNNs and transformers exhibit a\nsimplicity bias, favoring straightforward features over complex structural\nrepresentations. Furthermore, modern CNNs often integrate MLP-like blocks akin\nto those in transformers, but these blocks suffer from significant information\nredundancies, necessitating high expansion ratios to sustain competitive\nperformance. To address these limitations, we propose SpaRTAN, a lightweight\narchitectural design that enhances spatial and channel-wise information\nprocessing. SpaRTAN employs kernels with varying receptive fields, controlled\nby kernel size and dilation factor, to capture discriminative multi-order\nspatial features effectively. A wave-based channel aggregation module further\nmodulates and reinforces pixel interactions, mitigating channel-wise\nredundancies. Combining the two modules, the proposed network can efficiently\ngather and dynamically contextualize discriminative features. Experimental\nresults in ImageNet and COCO demonstrate that SpaRTAN achieves remarkable\nparameter efficiency while maintaining competitive performance. In particular,\non the ImageNet-1k benchmark, SpaRTAN achieves 77. 7% accuracy with only 3.8M\nparameters and approximately 1.0 GFLOPs, demonstrating its ability to deliver\nstrong performance through an efficient design. On the COCO benchmark, it\nachieves 50.0% AP, surpassing the previous benchmark by 1.2% with only 21.5M\nparameters. The code is publicly available at\n[https://github.com/henry-pay/SpaRTAN].", "AI": {"tldr": "SpaRTAN\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7f51\u7edc\u67b6\u6784\uff0c\u901a\u8fc7\u591a\u611f\u53d7\u91ce\u5377\u79ef\u6838\u548c\u901a\u9053\u805a\u5408\u6a21\u5757\u63d0\u9ad8\u7a7a\u95f4\u548c\u901a\u9053\u4fe1\u606f\u7684\u5904\u7406\u6548\u7387\uff0c\u5b9e\u73b0\u4e86\u4f18\u5f02\u7684\u53c2\u6570\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684CNN\u548cTransformer\u67b6\u6784\u5b58\u5728\u7b80\u5355\u6027\u504f\u89c1\uff0c\u504f\u7231\u7b80\u5355\u7279\u5f81\u800c\u975e\u590d\u6742\u7ed3\u6784\u8868\u793a\u3002\u6b64\u5916\uff0c\u73b0\u4ee3CNN\u4e2d\u7684MLP-like\u5757\u5b58\u5728\u663e\u8457\u7684\u4fe1\u606f\u5197\u4f59\u95ee\u9898\uff0c\u9700\u8981\u9ad8\u6269\u5c55\u7387\u6765\u7ef4\u6301\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSpaRTAN\u7684\u8f7b\u91cf\u7ea7\u67b6\u6784\u8bbe\u8ba1\uff0c\u901a\u8fc7\u91c7\u7528\u5177\u6709\u4e0d\u540c\u611f\u53d7\u91ce\uff08\u901a\u8fc7\u6838\u5927\u5c0f\u548c\u6269\u5f20\u56e0\u5b50\u63a7\u5236\uff09\u7684\u5377\u79ef\u6838\u6765\u6355\u6349\u591a\u9636\u7a7a\u95f4\u7279\u5f81\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8e\u6ce2\u7684\u901a\u9053\u805a\u5408\u6a21\u5757\u6765\u8c03\u5236\u548c\u589e\u5f3a\u50cf\u7d20\u4ea4\u4e92\uff0c\u51cf\u5c11\u901a\u9053\u5197\u4f59\u3002", "result": "SpaRTAN\u5728ImageNet-1k\u4e0a\u5b9e\u73b0\u4e8677.7%\u7684\u51c6\u786e\u7387\uff0c\u4ec5\u4f7f\u75283.8M\u53c2\u6570\u548c\u7ea61.0 GFLOPs\u3002\u5728COCO\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5176AP\u8fbe\u5230\u4e8650.0%\uff0c\u53c2\u6570\u91cf\u4e3a21.5M\uff0c\u4f18\u4e8e\u5148\u524d\u57fa\u51c61.2%\u3002", "conclusion": "SpaRTAN\u901a\u8fc7\u91c7\u7528\u5177\u6709\u4e0d\u540c\u611f\u53d7\u91ce\u7684\u5377\u79ef\u6838\u548c\u57fa\u4e8e\u6ce2\u7684\u901a\u9053\u805a\u5408\u6a21\u5757\uff0c\u6709\u6548\u6355\u83b7\u591a\u9636\u7a7a\u95f4\u7279\u5f81\u5e76\u51cf\u5c11\u901a\u9053\u5197\u4f59\uff0c\u5728\u53c2\u6570\u6548\u7387\u548c\u6027\u80fd\u65b9\u9762\u5747\u8868\u73b0\u51fa\u8272\uff0c\u5728ImageNet-1k\u548cCOCO\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5747\u53d6\u5f97\u4e86\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\u7684\u6210\u679c\u3002"}}
{"id": "2507.11117", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11117", "abs": "https://arxiv.org/abs/2507.11117", "authors": ["Ailiya Borjigin", "Cong He", "Charles CC Lee", "Wei Zhou"], "title": "AI Agent Architecture for Decentralized Trading of Alternative Assets", "comment": "8 Pages, 1 figure", "summary": "Decentralized trading of real-world alternative assets (e.g., gold) requires\nbridging physical asset custody with blockchain systems while meeting strict\nrequirements for compliance, liquidity, and risk management. We present\nGoldMine OS, a research oriented architecture that employs multiple specialized\nAI agents to automate and secure the tokenization and exchange of physical gold\ninto a blockchain based stablecoin (\"OZ\"). Our approach combines on chain smart\ncontracts for critical risk controls with off chain AI agents for decision\nmaking, blending the transparency and reliability of blockchains with the\nflexibility of AI driven automation. We describe four cooperative agents\n(Compliance, Token Issuance, Market Making, and Risk Control) and a\ncoordinating core, and evaluate the system through simulation and a controlled\npilot deployment. In experiments the prototype delivers on demand token\nissuance in under 1.2 s, more than 100 times faster than manual workflows. The\nMarket Making agent maintains tight liquidity with spreads often below 0.5\npercent even under volatile conditions. Fault injection tests show resilience:\nan oracle price spoofing attack is detected and mitigated within 10 s, and a\nsimulated vault mis reporting halts issuance immediately with minimal user\nimpact. The architecture scales to 5000 transactions per second with 10000\nconcurrent users in benchmarks. These results indicate that an AI agent based\ndecentralized exchange for alternative assets can satisfy rigorous performance\nand safety requirements. We discuss broader implications for democratizing\naccess to traditionally illiquid assets and explain how our governance model --\nmulti signature agent updates and on chain community voting on risk parameters\n-- provides ongoing transparency, adaptability, and formal assurance of system\nintegrity.", "AI": {"tldr": "GoldMine OS\u5229\u7528AI\u4ee3\u7406\u5b9e\u73b0\u5b9e\u7269\u9ec4\u91d1\u7684\u53bb\u4e2d\u5fc3\u5316\u4ee3\u5e01\u5316\u548c\u4ea4\u6613\uff0c\u6ee1\u8db3\u9ad8\u6027\u80fd\u3001\u9ad8\u5b89\u5168\u6027\u548c\u5408\u89c4\u6027\u8981\u6c42\u3002", "motivation": "\u53bb\u4e2d\u5fc3\u5316\u4ea4\u6613\u5b9e\u7269\u9ec4\u91d1\u7b49\u73b0\u5b9e\u4e16\u754c\u66ff\u4ee3\u8d44\u4ea7\uff0c\u9700\u8981\u5728\u6ee1\u8db3\u5408\u89c4\u6027\u3001\u6d41\u52a8\u6027\u548c\u98ce\u9669\u7ba1\u7406\u7684\u4e25\u683c\u8981\u6c42\u7684\u540c\u65f6\uff0c\u5c06\u5b9e\u7269\u8d44\u4ea7\u6258\u7ba1\u4e0e\u533a\u5757\u94fe\u7cfb\u7edf\u8fde\u63a5\u8d77\u6765\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGoldMine OS\u7684\u9762\u5411\u7814\u7a76\u7684\u4f53\u7cfb\u7ed3\u6784\uff0c\u8be5\u4f53\u7cfb\u7ed3\u6784\u5229\u7528\u591a\u4e2a\u4e13\u4e1a\u7684AI\u4ee3\u7406\uff08\u5408\u89c4\u3001\u4ee3\u5e01\u53d1\u884c\u3001\u505a\u5e02\u548c\u98ce\u9669\u63a7\u5236\uff09\u4ee5\u53ca\u4e00\u4e2a\u534f\u8c03\u6838\u5fc3\uff0c\u6765\u81ea\u52a8\u6267\u884c\u548c\u4fdd\u62a4\u5b9e\u7269\u9ec4\u91d1\u5230\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u7a33\u5b9a\u5e01\uff08\u201cOZ\u201d\uff09\u7684\u4ee3\u5e01\u5316\u548c\u4ea4\u6613\u3002", "result": "\u6a21\u62df\u548c\u8bd5\u70b9\u90e8\u7f72\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u539f\u578b\u80fd\u591f\u6ee1\u8db3\u9700\u6c42\uff0c\u4ee3\u5e01\u53d1\u884c\u65f6\u95f4\u4e0d\u52301.2\u79d2\uff08\u6bd4\u624b\u52a8\u6d41\u7a0b\u5feb100\u500d\u4ee5\u4e0a\uff09\uff1b\u505a\u5e02\u4ee3\u7406\u80fd\u591f\u5728\u6ce2\u52a8\u6761\u4ef6\u4e0b\u4fdd\u6301\u4f4e\u4e8e0.5%\u7684\u4e70\u5356\u4ef7\u5dee\uff1b\u5bb9\u9519\u6d4b\u8bd5\u8868\u660e\uff0c\u7cfb\u7edf\u80fd\u572810\u79d2\u5185\u68c0\u6d4b\u5e76\u7f13\u89e3\u795e\u8c15\u4ef7\u683c\u6b3a\u9a97\u653b\u51fb\uff1b\u6a21\u62df\u91d1\u5e93\u9519\u8bef\u62a5\u544a\u540e\u53ef\u7acb\u5373\u505c\u6b62\u53d1\u884c\uff0c\u5bf9\u7528\u6237\u5f71\u54cd\u6700\u5c0f\uff1b\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\uff0c\u8be5\u67b6\u6784\u53ef\u6269\u5c55\u81f3\u652f\u63015000 TPS\u548c10000\u5e76\u53d1\u7528\u6237\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8eAI\u4ee3\u7406\u7684\u53bb\u4e2d\u5fc3\u5316\u4ea4\u6613\u6240\u80fd\u591f\u6ee1\u8db3\u4e25\u683c\u7684\u6027\u80fd\u548c\u5b89\u5168\u8981\u6c42\uff0c\u4e3a\u4f20\u7edf\u4e0a\u6d41\u52a8\u6027\u5dee\u7684\u8d44\u4ea7\u63d0\u4f9b\u66f4\u5e7f\u6cdb\u7684\u8bbf\u95ee\uff0c\u5e76\u901a\u8fc7\u5176\u6cbb\u7406\u6a21\u578b\u786e\u4fdd\u7cfb\u7edf\u7684\u6301\u7eed\u900f\u660e\u5ea6\u3001\u9002\u5e94\u6027\u548c\u6b63\u5f0f\u4fdd\u8bc1\u3002"}}
{"id": "2507.11049", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.11049", "abs": "https://arxiv.org/abs/2507.11049", "authors": ["Dahyun Lee", "Jonghyeon Choi", "Jiyoung Han", "Kunwoo Park"], "title": "Journalism-Guided Agentic In-Context Learning for News Stance Detection", "comment": "Preprint. 24 pages", "summary": "As online news consumption grows, personalized recommendation systems have\nbecome integral to digital journalism. However, these systems risk reinforcing\nfilter bubbles and political polarization by failing to incorporate diverse\nperspectives. Stance detection -- identifying a text's position on a target --\ncan help mitigate this by enabling viewpoint-aware recommendations and\ndata-driven analyses of media bias. Yet, existing stance detection research\nremains largely limited to short texts and high-resource languages. To address\nthese gaps, we introduce \\textsc{K-News-Stance}, the first Korean dataset for\narticle-level stance detection, comprising 2,000 news articles with\narticle-level and 19,650 segment-level stance annotations across 47 societal\nissues. We also propose \\textsc{JoA-ICL}, a \\textbf{Jo}urnalism-guided\n\\textbf{A}gentic \\textbf{I}n-\\textbf{C}ontext \\textbf{L}earning framework that\nemploys a language model agent to predict the stances of key structural\nsegments (e.g., leads, quotes), which are then aggregated to infer the overall\narticle stance. Experiments show that \\textsc{JoA-ICL} outperforms existing\nstance detection methods, highlighting the benefits of segment-level agency in\ncapturing the overall position of long-form news articles. Two case studies\nfurther demonstrate its broader utility in promoting viewpoint diversity in\nnews recommendations and uncovering patterns of media bias.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86 K-News-Stance \u6570\u636e\u96c6\u548c JoA-ICL \u6846\u67b6\uff0c\u7528\u4e8e\u97e9\u8bed\u957f\u7bc7\u65b0\u95fb\u6587\u7ae0\u7684\u7acb\u573a\u68c0\u6d4b\uff0c\u5e76\u5728\u65b0\u95fb\u63a8\u8350\u548c\u5a92\u4f53\u504f\u89c1\u5206\u6790\u65b9\u9762\u53d6\u5f97\u4e86\u826f\u597d\u6548\u679c\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u73b0\u6709\u7acb\u573a\u68c0\u6d4b\u7814\u7a76\u4e3b\u8981\u5c40\u9650\u4e8e\u77ed\u6587\u672c\u548c\u9ad8\u8d44\u6e90\u8bed\u8a00\u7684\u95ee\u9898\uff0c\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u97e9\u8bed\u65b0\u95fb\u6587\u7ae0\u7684\u7acb\u573a\u68c0\u6d4b\u6765\u4fc3\u8fdb\u89c2\u70b9\u591a\u6837\u6027\u548c\u63ed\u793a\u5a92\u4f53\u504f\u89c1\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e86 JoA-ICL \u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u9884\u6d4b\u5173\u952e\u7ed3\u6784\u7247\u6bb5\uff08\u5982\u5bfc\u8bed\u3001\u5f15\u8bed\uff09\u7684\u7acb\u573a\uff0c\u7136\u540e\u805a\u5408\u8fd9\u4e9b\u7247\u6bb5\u7684\u7acb\u573a\u4ee5\u63a8\u65ad\u6574\u7bc7\u6587\u7ae0\u7684\u7acb\u573a\u3002", "result": "JoA-ICL \u6846\u67b6\u5728\u7acb\u573a\u68c0\u6d4b\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u9010\u5c42\u5206\u6790\u5728\u6355\u6349\u957f\u7bc7\u65b0\u95fb\u6587\u7ae0\u6574\u4f53\u7acb\u573a\u65b9\u9762\u7684\u4f18\u52bf\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\uff0c\u8bc1\u660e\u4e86\u8be5\u6846\u67b6\u5728\u4fc3\u8fdb\u65b0\u95fb\u63a8\u8350\u4e2d\u7684\u89c2\u70b9\u591a\u6837\u6027\u548c\u63ed\u793a\u5a92\u4f53\u504f\u89c1\u6a21\u5f0f\u65b9\u9762\u7684\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86 K-News-Stance \u6570\u636e\u96c6\u548c JoA-ICL \u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u97e9\u8bed\u957f\u7bc7\u65b0\u95fb\u6587\u7ae0\u7684\u7acb\u573a\u68c0\u6d4b\u95ee\u9898\uff0c\u5e76\u6210\u529f\u5e94\u7528\u4e8e\u65b0\u95fb\u63a8\u8350\u548c\u5a92\u4f53\u504f\u89c1\u5206\u6790\u3002"}}
{"id": "2507.10632", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10632", "abs": "https://arxiv.org/abs/2507.10632", "authors": ["Issei Saito", "Masatoshi Nagano", "Tomoaki Nakamura", "Daichi Mochihashi", "Koki Mimura"], "title": "Scalable Unsupervised Segmentation via Random Fourier Feature-based Gaussian Process", "comment": null, "summary": "In this paper, we propose RFF-GP-HSMM, a fast unsupervised time-series\nsegmentation method that incorporates random Fourier features (RFF) to address\nthe high computational cost of the Gaussian process hidden semi-Markov model\n(GP-HSMM). GP-HSMM models time-series data using Gaussian processes, requiring\ninversion of an N times N kernel matrix during training, where N is the number\nof data points. As the scale of the data increases, matrix inversion incurs a\nsignificant computational cost. To address this, the proposed method\napproximates the Gaussian process with linear regression using RFF, preserving\nexpressive power while eliminating the need for inversion of the kernel matrix.\nExperiments on the Carnegie Mellon University (CMU) motion-capture dataset\ndemonstrate that the proposed method achieves segmentation performance\ncomparable to that of conventional methods, with approximately 278 times faster\nsegmentation on time-series data comprising 39,200 frames.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRFF-GP-HSMM\u7684\u5feb\u901f\u65e0\u76d1\u7763\u65f6\u95f4\u5e8f\u5217\u5206\u5272\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\uff08RFF\uff09\u6765\u8fd1\u4f3c\u9ad8\u65af\u8fc7\u7a0b\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfGP-HSMM\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u901f\u5ea6\u5927\u5e45\u63d0\u5347\u3002", "motivation": "\u4f20\u7edf\u7684\u9ad8\u65af\u8fc7\u7a0b\u9690\u534a\u534a\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\uff08GP-HSMM\uff09\u5728\u5904\u7406\u5927\u89c4\u6a21\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u65f6\uff0c\u7531\u4e8e\u9700\u8981\u5bf9N\u00d7N\u6838\u77e9\u9635\u8fdb\u884c\u6c42\u9006\uff0c\u8ba1\u7b97\u6210\u672c\u975e\u5e38\u9ad8\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u8ba1\u7b97\u74f6\u9888\uff0c\u63d0\u51fa\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u5272\u65b9\u6cd5\u3002", "method": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5f15\u5165\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\uff08RFF\uff09\u6765\u8fd1\u4f3c\u9ad8\u65af\u8fc7\u7a0b\uff0c\u5e76\u7ed3\u5408\u9ad8\u65af\u8fc7\u7a0b\u9690\u534a\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\uff08GP-HSMM\uff09\uff0c\u89e3\u51b3\u4e86GP-HSMM\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5b83\u4f7f\u7528RFF\u5c06\u9ad8\u65af\u8fc7\u7a0b\u8fd1\u4f3c\u4e3a\u7ebf\u6027\u56de\u5f52\uff0c\u4ece\u800c\u907f\u514d\u4e86\u5bf9N\u00d7N\u6838\u77e9\u9635\u8fdb\u884c\u6c42\u9006\u7684\u9700\u6c42\uff0c\u5176\u4e2dN\u662f\u6570\u636e\u70b9\u7684\u6570\u91cf\u3002", "result": "RFF-GP-HSMM\u5728CMU\u8fd0\u52a8\u6355\u6349\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u5f53\u7684\u5206\u5272\u6027\u80fd\uff0c\u540c\u65f6\u5728\u5904\u7406\u5305\u542b39,200\u5e27\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u65f6\uff0c\u5206\u5272\u901f\u5ea6\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5feb\u4e86\u7ea6278\u500d\u3002", "conclusion": "RFF-GP-HSMM\u5728CMU\u8fd0\u52a8\u6355\u6349\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u5f53\u7684\u5206\u5272\u6027\u80fd\uff0c\u5e76\u4e14\u5728\u5305\u542b39,200\u5e27\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e0a\u5206\u5272\u901f\u5ea6\u5feb\u4e86\u7ea6278\u500d\u3002"}}
{"id": "2507.11170", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.11170", "abs": "https://arxiv.org/abs/2507.11170", "authors": ["Giulio Giacomuzzo", "Mohamed Abdelwahab", "Marco Cal\u00ec", "Alberto Dalla Libera", "Ruggero Carli"], "title": "A Robust Controller based on Gaussian Processes for Robotic Manipulators with Unknown Uncertainty", "comment": null, "summary": "In this paper, we propose a novel learning-based robust feedback\nlinearization strategy to ensure precise trajectory tracking for an important\nfamily of Lagrangian systems. We assume a nominal knowledge of the dynamics is\ngiven but no a-priori bounds on the model mismatch are available. In our\napproach, the key ingredient is the adoption of a regression framework based on\nGaussian Processes (GPR) to estimate the model mismatch. This estimate is added\nto the outer loop of a classical feedback linearization scheme based on the\nnominal knowledge available. Then, to compensate for the residual uncertainty,\nwe robustify the controller including an additional term whose size is designed\nbased on the variance provided by the GPR framework. We proved that, with high\nprobability, the proposed scheme is able to guarantee asymptotic tracking of a\ndesired trajectory. We tested numerically our strategy on a 2 degrees of\nfreedom planar robot.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u7684\u9c81\u68d2\u53cd\u9988\u7ebf\u6027\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u62c9\u683c\u6717\u65e5\u7cfb\u7edf\u7684\u7cbe\u786e\u8f68\u8ff9\u8ddf\u8e2a\uff0c\u5e76\u6210\u529f\u5e94\u7528\u4e8e\u53cc\u81ea\u7531\u5ea6\u5e73\u9762\u673a\u5668\u4eba\u3002", "motivation": "\u4e3a\u4e86\u786e\u4fdd\u4e00\u7c7b\u91cd\u8981\u7684\u62c9\u683c\u6717\u65e5\u7cfb\u7edf\u80fd\u591f\u7cbe\u786e\u5730\u8ddf\u8e2a\u8f68\u8ff9\uff0c\u5373\u4f7f\u5728\u6a21\u578b\u4e0d\u5339\u914d\u7684\u754c\u9650\u672a\u77e5\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u5b66\u4e60\u7684\u9c81\u68d2\u53cd\u9988\u7ebf\u6027\u5316\u7b56\u7565\uff0c\u8be5\u7b56\u7565\u91c7\u7528\u57fa\u4e8e\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\uff08GPR\uff09\u7684\u56de\u5f52\u6846\u67b6\u6765\u4f30\u8ba1\u6a21\u578b\u4e0d\u5339\u914d\uff0c\u5e76\u7ed3\u5408\u7ecf\u5178\u53cd\u9988\u7ebf\u6027\u5316\u65b9\u6848\uff0c\u901a\u8fc7\u5f15\u5165\u4e00\u4e2a\u57fa\u4e8eGPR\u65b9\u5dee\u7684\u9644\u52a0\u9879\u6765\u8865\u507f\u6b8b\u4f59\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u5728 k\u00e9t b\u1eadc t\u1ef1 do planar robot \u4e0a\u8fdb\u884c\u4e86\u6570\u503c\u6d4b\u8bd5\uff0c\u8bc1\u660e\u4e86\u8be5\u7b56\u7565\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4fdd\u8bc1\u4e86\u7cfb\u7edf\u80fd\u591f\u6e10\u8fdb\u5730\u8ddf\u8e2a\u671f\u671b\u8f68\u8ff9\u3002"}}
{"id": "2507.10926", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.10926", "abs": "https://arxiv.org/abs/2507.10926", "authors": ["Koichi Miyamoto"], "title": "Quantum algorithm for solving McKean-Vlasov stochastic differential equations", "comment": "14 pages, 4 figures", "summary": "Quantum Monte Carlo integration, a quantum algorithm for calculating\nexpectations that provides a quadratic speed-up compared to its classical\ncounterpart, is now attracting increasing interest in the context of its\nindustrial and scientific applications. In this paper, we propose the first\napplication of QMCI to solving McKean-Vlasov stochastic differential equations\n(MVSDEs), a nonlinear class of SDEs whose drift and diffusion coefficients\ndepend on the law $\\mu_t$ of the solution $X_t$ -- appearing in fields such as\nfinance and fluid mechanics. We focus on the problem setting where the\ncoefficients depend on $\\mu_t$ through expectations of some functions\n$\\mathbb{E}[\\varphi_k(X_t)]$, and the goal is to compute the expectation of a\nfunction $\\mathbb{E}[\\phi(X_T)]$ at a terminal time $T$. We devise a quantum\nalgorithm that leverages QMCI to compute these expectations, combined with a\nhigh-order time discretization method for SDEs and extrapolation of the\nexpectations in time. The proposed algorithm estimates $\\mathbb{E}[\\phi(X_T)]$\nwith accuracy $\\epsilon$, making $O(1/\\epsilon^{1+2/p})$ queries to the quantum\ncircuit for time evolution over one step, where $p\\in(1,2]$ is the weak order\nof the SDE discretization method. This demonstrates the speed-up over the\nwell-known classical algorithm called the particle method with complexity of\n$O(1/\\epsilon^3)$. We conduct a numerical demonstration of our quantum\nalgorithm applied to an example of MVSDEs, with some parts emulated\nclassically, and observe that the accuracy and complexity behave as expected.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5c06\u91cf\u5b50\u8499\u7279\u5361\u6d1b\u79ef\u5206\uff08QMCI\uff09\u5e94\u7528\u4e8e\u6c42\u89e3McKean-Vlasov\u968f\u673a\u5fae\u5206\u65b9\u7a0b\uff08MVSDEs\uff09\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408QMCI\u3001\u9ad8\u9636\u65f6\u95f4\u79bb\u6563\u5316\u548c\u65f6\u95f4\u5916\u63d2\u7684\u91cf\u5b50\u7b97\u6cd5\u3002\u8be5\u7b97\u6cd5\u5728\u7cbe\u5ea6\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u4e0a\u5747\u4f18\u4e8e\u7ecf\u5178\u7684\u7c92\u5b50\u65b9\u6cd5\u3002", "motivation": "\u91cf\u5b50\u8499\u7279\u5361\u6d1b\u79ef\u5206\uff08QMCI\uff09\u4f5c\u4e3a\u4e00\u79cd\u5177\u6709\u4e8c\u6b21\u52a0\u901f\u7684\u91cf\u5b50\u7b97\u6cd5\uff0c\u5728\u5de5\u4e1a\u548c\u79d1\u5b66\u5e94\u7528\u4e2d\u65e5\u76ca\u53d7\u5230\u5173\u6ce8\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22QMCI\u5728\u6c42\u89e3McKean-Vlasov\u968f\u673a\u5fae\u5206\u65b9\u7a0b\uff08MVSDEs\uff09\u8fd9\u4e00\u5177\u6709\u91d1\u878d\u548c\u6d41\u4f53\u529b\u5b66\u7b49\u9886\u57df\u5e94\u7528\u7684\u65b0\u5174\u95ee\u9898\u4e0a\u7684\u9996\u6b21\u5e94\u7528\u3002", "method": "\u901a\u8fc7\u7ed3\u5408\u91cf\u5b50\u8499\u7279\u5361\u6d1b\u79ef\u5206\uff08QMCI\uff09\u3001\u9ad8\u9636\u65f6\u95f4\u79bb\u6563\u5316\u65b9\u6cd5\u4ee5\u53ca\u65f6\u95f4\u5916\u63d2\u6280\u672f\u6765\u8bbe\u8ba1\u91cf\u5b50\u7b97\u6cd5\uff0c\u7528\u4e8e\u8ba1\u7b97MVSDEs\u7684\u671f\u671b\u503c\u3002", "result": "\u8be5\u91cf\u5b50\u7b97\u6cd5\u80fd\u591f\u4ee5 $\\epsilon$ \u7684\u7cbe\u5ea6\u4f30\u8ba1\u7ec8\u7aef\u65f6\u95f4\u7684\u51fd\u6570\u671f\u671b\u503c $\\mathbb{E}[\\phi(X_T)]$\uff0c\u5176\u91cf\u5b50\u7535\u8def\u67e5\u8be2\u590d\u6742\u5ea6\u4e3a $O(1/\\epsilon^{1+2/p})$\uff0c\u5176\u4e2d $p\\in(1,2]$ \u662fSDE\u79bb\u6563\u5316\u65b9\u6cd5\u7684\u65f6\u95f4\u4e00\u9636\u7cbe\u5ea6\u3002\u8fd9\u76f8\u6bd4\u4e8e\u7ecf\u5178\u7684\u7c92\u5b50\u65b9\u6cd5\uff08\u590d\u6742\u5ea6\u4e3a $O(1/\\epsilon^3)$\uff09\u5177\u6709\u663e\u8457\u7684\u52a0\u901f\u3002\u6570\u503c\u5b9e\u9a8c\u4e5f\u9a8c\u8bc1\u4e86\u8be5\u7b97\u6cd5\u7684\u9884\u671f\u8868\u73b0\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u91cf\u5b50\u7b97\u6cd5\u7ed3\u5408\u4e86\u91cf\u5b50\u8499\u7279\u5361\u6d1b\u79ef\u5206\u3001\u9ad8\u9636\u65f6\u95f4\u79bb\u6563\u5316\u65b9\u6cd5\u548c\u65f6\u95f4\u5916\u63d2\u6280\u672f\uff0c\u80fd\u591f\u6709\u6548\u6c42\u89e3McKean-Vlasov\u968f\u673a\u5fae\u5206\u65b9\u7a0b\uff08MVSDEs\uff09\uff0c\u5e76\u5728\u8ba1\u7b97\u7cbe\u5ea6\u548c\u590d\u6742\u5ea6\u65b9\u9762\u5c55\u73b0\u51fa\u4f18\u4e8e\u7ecf\u5178\u7c92\u5b50\u65b9\u6cd5\u7684\u4f18\u52bf\u3002"}}
{"id": "2507.11003", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11003", "abs": "https://arxiv.org/abs/2507.11003", "authors": ["Yuhu Bai", "Jiangning Zhang", "Yunkang Cao", "Guangyuan Lu", "Qingdong He", "Xiangtai Li", "Guanzhong Tian"], "title": "Bridge Feature Matching and Cross-Modal Alignment with Mutual-filtering for Zero-shot Anomaly Detection", "comment": null, "summary": "With the advent of vision-language models (e.g., CLIP) in zero- and few-shot\nsettings, CLIP has been widely applied to zero-shot anomaly detection (ZSAD) in\nrecent research, where the rare classes are essential and expected in many\napplications. This study introduces \\textbf{FiSeCLIP} for ZSAD with\ntraining-free \\textbf{CLIP}, combining the feature matching with the\ncross-modal alignment. Testing with the entire dataset is impractical, while\nbatch-based testing better aligns with real industrial needs, and images within\na batch can serve as mutual reference points. Accordingly, FiSeCLIP utilizes\nother images in the same batch as reference information for the current image.\nHowever, the lack of labels for these references can introduce ambiguity, we\napply text information to \\textbf{fi}lter out noisy features. In addition, we\nfurther explore CLIP's inherent potential to restore its local\n\\textbf{se}mantic correlation, adapting it for fine-grained anomaly detection\ntasks to enable a more accurate filtering process. Our approach exhibits\nsuperior performance for both anomaly classification and segmentation on\nanomaly detection benchmarks, building a stronger baseline for the direction,\ne.g., on MVTec-AD, FiSeCLIP outperforms the SOTA AdaCLIP by\n+4.6\\%$\\uparrow$/+5.7\\%$\\uparrow$ in segmentation metrics AU-ROC/$F_1$-max.", "AI": {"tldr": "FiSeCLIP\u662f\u4e00\u79cd\u65b0\u63d0\u51fa\u7684\u7528\u4e8e\u96f6\u6837\u672c\u5f02\u5e38\u68c0\u6d4b\uff08ZSAD\uff09\u7684\u65b9\u6cd5\uff0c\u5b83\u5229\u7528CLIP\u7684\u8de8\u6a21\u6001\u80fd\u529b\uff0c\u901a\u8fc7\u6279\u5185\u56fe\u50cf\u7684\u76f8\u4e92\u53c2\u8003\u548c\u6587\u672c\u8fc7\u6ee4\u6765\u63d0\u9ad8\u68c0\u6d4b\u7cbe\u5ea6\uff0c\u5e76\u5728MVTec-AD\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u9886\u5148\u7684\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u96f6\u6837\u672c\u5f02\u5e38\u68c0\u6d4b\uff08ZSAD\uff09\u4e2d\u7f55\u89c1\u7c7b\u522b\u7684\u91cd\u8981\u6027\u548c\u5b9e\u9645\u5e94\u7528\u9700\u6c42\uff0c\u5e76\u7ed3\u5408CLIP\u7684\u7279\u5f81\u5339\u914d\u548c\u8de8\u6a21\u6001\u5bf9\u9f50\u80fd\u529b\u3002", "method": "FiSeCLIP\u7ed3\u5408\u4e86\u7279\u5f81\u5339\u914d\u548c\u8de8\u6a21\u6001\u5bf9\u9f50\uff0c\u5229\u7528\u540c\u4e00\u6279\u6b21\u4e2d\u7684\u5176\u4ed6\u56fe\u50cf\u4f5c\u4e3a\u53c2\u8003\u4fe1\u606f\uff0c\u5e76\u901a\u8fc7\u6587\u672c\u4fe1\u606f\u8fc7\u6ee4\u566a\u58f0\u7279\u5f81\uff0c\u540c\u65f6\u5229\u7528CLIP\u6062\u590d\u5c40\u90e8\u8bed\u4e49\u76f8\u5173\u6027\u4ee5\u8fdb\u884c\u7ec6\u7c92\u5ea6\u5f02\u5e38\u68c0\u6d4b\u3002", "result": "FiSeCLIP\u5728\u5f02\u5e38\u5206\u7c7b\u548c\u5206\u5272\u65b9\u9762\u5747\u53d6\u5f97\u4e86\u4f18\u8d8a\u6027\u80fd\uff0c\u4f8b\u5982\u5728MVTec-AD\u6570\u636e\u96c6\u4e0a\uff0c\u5176\u5206\u5272\u6307\u6807AU-ROC\u548cF1-max\u5206\u522b\u6bd4AdaCLIP\u9ad8\u51fa4.6%\u548c5.7%\u3002", "conclusion": "FiSeCLIP\u5728\u5f02\u5e38\u68c0\u6d4b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5728MVTec-AD\u4e0a\uff0c\u5176\u5206\u5272\u6307\u6807AU-ROC\u548cF1-max\u5206\u522b\u4f18\u4e8eSOTA AdaCLIP 4.6%\u548c5.7%\uff0c\u4e3a\u8be5\u65b9\u5411\u5960\u5b9a\u4e86\u66f4\u5f3a\u7684\u57fa\u7ebf\u3002"}}
{"id": "2507.11127", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11127", "abs": "https://arxiv.org/abs/2507.11127", "authors": ["Lennert De Smet", "Luc De Raedt"], "title": "Defining neurosymbolic AI", "comment": null, "summary": "Neurosymbolic AI focuses on integrating learning and reasoning, in\nparticular, on unifying logical and neural representations. Despite the\nexistence of an alphabet soup of neurosymbolic AI systems, the field is lacking\na generally accepted formal definition of what neurosymbolic models and\ninference really are. We introduce a formal definition for neurosymbolic AI\nthat makes abstraction of its key ingredients. More specifically, we define\nneurosymbolic inference as the computation of an integral over a product of a\nlogical and a belief function. We show that our neurosymbolic AI definition\nmakes abstraction of key representative neurosymbolic AI systems.", "AI": {"tldr": "\u795e\u7ecf\u7b26\u53f7AI\u9886\u57df\u7f3a\u4e4f\u7edf\u4e00\u7684\u5f62\u5f0f\u5316\u5b9a\u4e49\u3002\u6211\u4eec\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u5b9a\u4e49\uff0c\u5c06\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u89c6\u4e3a\u903b\u8f91\u51fd\u6570\u4e0e\u4fe1\u5ff5\u51fd\u6570\u4e58\u79ef\u4e0a\u7684\u79ef\u5206\uff0c\u5e76\u8bc1\u660e\u5b83\u9002\u7528\u4e8e\u73b0\u6709\u7cfb\u7edf\u3002", "motivation": "\u5f53\u524d\u795e\u7ecf\u7b26\u53f7AI\u9886\u57df\u7f3a\u4e4f\u4e00\u4e2a\u666e\u904d\u63a5\u53d7\u7684\u5f62\u5f0f\u5316\u5b9a\u4e49\uff0c\u8fd9\u963b\u788d\u4e86\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f62\u5f0f\u5316\u5b9a\u4e49\uff0c\u5373\u5c06\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u5b9a\u4e49\u4e3a\u903b\u8f91\u51fd\u6570\u4e0e\u4fe1\u5ff5\u51fd\u6570\u4e58\u79ef\u4e0a\u7684\u79ef\u5206\u3002", "result": "\u6240\u63d0\u51fa\u7684\u5f62\u5f0f\u5316\u5b9a\u4e49\u80fd\u591f\u6db5\u76d6\u73b0\u6709\u7684\u5173\u952e\u795e\u7ecf\u7b26\u53f7AI\u7cfb\u7edf\uff0c\u4e3a\u8be5\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\u3002 \nTLDR: \u795e\u7ecf\u7b26\u53f7AI\u9886\u57df\u6025\u9700\u4e00\u4e2a\u5f62\u5f0f\u5316\u5b9a\u4e49\u3002\u6211\u4eec\u63d0\u51fa\u5c06\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u5b9a\u4e49\u4e3a\u903b\u8f91\u51fd\u6570\u4e0e\u4fe1\u5ff5\u51fd\u6570\u4e58\u79ef\u4e0a\u7684\u79ef\u5206\uff0c\u5e76\u8bc1\u660e\u8be5\u5b9a\u4e49\u80fd\u6db5\u76d6\u73b0\u6709\u4ee3\u8868\u6027\u7cfb\u7edf\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e3a\u795e\u7ecf\u7b26\u53f7AI\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u7406\u8bba\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u672a\u6765\u7684\u7814\u7a76\u548c\u53d1\u5c55\u3002\u5b83\u89e3\u51b3\u4e86\u8be5\u9886\u57df\u7f3a\u4e4f\u7edf\u4e00\u6807\u51c6\u7684\u75db\u70b9\uff0c\u5e76\u4e3a\u6784\u5efa\u66f4\u5f3a\u5927\u7684AI\u7cfb\u7edf\u94fa\u5e73\u4e86\u9053\u8def\u3002 \n", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u795e\u7ecf\u7b26\u53f7AI\u7684\u5f62\u5f0f\u5316\u5b9a\u4e49\uff0c\u5e76\u5c55\u793a\u4e86\u8be5\u5b9a\u4e49\u5982\u4f55\u6db5\u76d6\u4e86\u5173\u952e\u7684\u795e\u7ecf\u7b26\u53f7AI\u7cfb\u7edf\u3002"}}
{"id": "2507.11052", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11052", "abs": "https://arxiv.org/abs/2507.11052", "authors": ["Haowei Yang", "Ziyu Shen", "Junli Shao", "Luyao Men", "Xinyue Han", "Jing Dong"], "title": "LLM-Augmented Symptom Analysis for Cardiovascular Disease Risk Prediction: A Clinical NLP", "comment": null, "summary": "Timely identification and accurate risk stratification of cardiovascular\ndisease (CVD) remain essential for reducing global mortality. While existing\nprediction models primarily leverage structured data, unstructured clinical\nnotes contain valuable early indicators. This study introduces a novel\nLLM-augmented clinical NLP pipeline that employs domain-adapted large language\nmodels for symptom extraction, contextual reasoning, and correlation from\nfree-text reports. Our approach integrates cardiovascular-specific fine-tuning,\nprompt-based inference, and entity-aware reasoning. Evaluations on MIMIC-III\nand CARDIO-NLP datasets demonstrate improved performance in precision, recall,\nF1-score, and AUROC, with high clinical relevance (kappa = 0.82) assessed by\ncardiologists. Challenges such as contextual hallucination, which occurs when\nplausible information contracts with provided source, and temporal ambiguity,\nwhich is related with models struggling with chronological ordering of events\nare addressed using prompt engineering and hybrid rule-based verification. This\nwork underscores the potential of LLMs in clinical decision support systems\n(CDSS), advancing early warning systems and enhancing the translation of\npatient narratives into actionable risk assessments.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u589e\u5f3a\u7684\u4e34\u5e8aNLP\u6d41\u7a0b\uff0c\u901a\u8fc7\u9886\u57df\u9002\u5e94\u3001\u5fae\u8c03\u548c\u63d0\u793a\u5de5\u7a0b\uff0c\u4ece\u4e34\u5e8a\u7b14\u8bb0\u4e2d\u63d0\u53d6\u4fe1\u606f\u4ee5\u6539\u8fdb\u5fc3\u8840\u7ba1\u75be\u75c5\u98ce\u9669\u8bc4\u4f30\uff0c\u5e76\u5728MIMIC-III\u548cCARDIO-NLP\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u6027\u80fd\u3002", "motivation": "\u53ca\u65f6\u8bc6\u522b\u548c\u51c6\u786e\u8bc4\u4f30\u5fc3\u8840\u7ba1\u75be\u75c5\uff08CVD\uff09\u7684\u98ce\u9669\u5bf9\u4e8e\u964d\u4f4e\u5168\u7403\u6b7b\u4ea1\u7387\u4ecd\u7136\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7684\u9884\u6d4b\u6a21\u578b\u4e3b\u8981\u5229\u7528\u7ed3\u6784\u5316\u6570\u636e\uff0c\u4f46\u975e\u7ed3\u6784\u5316\u7684\u4e34\u5e8a\u7b14\u8bb0\u5305\u542b\u6709\u4ef7\u503c\u7684\u65e9\u671f\u6307\u6807\u3002", "method": "\u672c\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u3001\u7ecf\u5927\u578b\u8bed\u8a00\u6a21\u578b\u589e\u5f3a\u7684\u4e34\u5e8aNLP\u6d41\u7a0b\uff0c\u8be5\u6d41\u7a0b\u91c7\u7528\u9886\u57df\u9002\u5e94\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u75c7\u72b6\u63d0\u53d6\u3001\u4e0a\u4e0b\u6587\u63a8\u7406\u548c\u81ea\u7531\u6587\u672c\u62a5\u544a\u7684\u76f8\u5173\u6027\u5206\u6790\u3002\u8be5\u65b9\u6cd5\u6574\u5408\u4e86\u5fc3\u8840\u7ba1\u7279\u5b9a\u5fae\u8c03\u3001\u57fa\u4e8e\u63d0\u793a\u7684\u63a8\u7406\u548c\u5b9e\u4f53\u611f\u77e5\u63a8\u7406\u3002\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u548c\u6df7\u5408\u57fa\u4e8e\u89c4\u5219\u7684\u9a8c\u8bc1\u6765\u89e3\u51b3\u4e0a\u4e0b\u6587\u5e7b\u89c9\u548c\u65f6\u95f4\u6a21\u7cca\u7b49\u6311\u6218\u3002", "result": "\u5728MIMIC-III\u548cCARDIO-NLP\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u5728\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u3001F1\u5206\u6570\u548cAUROC\u65b9\u9762\u5747\u6709\u6539\u8fdb\uff0c\u5e76\u4e14\u5fc3\u810f\u75c5\u4e13\u5bb6\u8bc4\u4f30\u7684\u4e34\u5e8a\u76f8\u5173\u6027\u9ad8\uff08kappa = 0.82\uff09\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\uff08CDSS\uff09\u4e2d\u6709\u6f5c\u529b\uff0c\u80fd\u591f\u6539\u8fdb\u65e9\u671f\u9884\u8b66\u7cfb\u7edf\uff0c\u5e76\u5c06\u60a3\u8005\u53d9\u8ff0\u8f6c\u5316\u4e3a\u53ef\u884c\u7684\u98ce\u9669\u8bc4\u4f30\u3002"}}
{"id": "2507.11307", "categories": ["cond-mat.mes-hall", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2507.11307", "abs": "https://arxiv.org/abs/2507.11307", "authors": ["Jeong Ha Hwang", "Nicol\u00f2 Bassi", "Mayada Fadel", "Oliver Braun", "Tim Dumslaff", "Carlo Pignedoli", "Michael Stiefel", "Roman Furrer", "Hironobu Hayashi", "Hiroko Yamada", "Akimitsu Narita", "Klaus M\u00fcllen", "Michel Calame", "Mickael L. Perrin", "Roman Fasel", "Pascal Ruffieux", "Vincent Meunier", "Gabriela Borin Barin"], "title": "Optimized Synthesis and Device Integration of Long 17-Atom-Wide Armchair Graphene Nanoribbons", "comment": null, "summary": "Seventeen-carbon-atom-wide armchair graphene nanoribbons (17-AGNRs) are\npromising candidates for high-performance electronic devices due to their\nnarrow electronic bandgap. Atomic precision in edge structure and width control\nis achieved through a bottom-up on-surface synthesis (OSS) approach from\ntailored molecular precursors in ultra-high vacuum (UHV). This synthetic\nprotocol must be optimized to meet the structural requirements for device\nintegration, with ribbon length being the most critical parameter. Here, we\nreport optimized OSS conditions that produce 17-AGNRs with an average length of\napproximately 17 nm. This length enhancement is achieved through a gradual\ntemperature ramping during an extended annealing period, combined with a\ntemplate-like effect driven by monomer assembly at high surface coverage. The\nresulting 17-AGNRs are comprehensively characterized in UHV using scanning\nprobe techniques and Raman spectroscopy. Raman measurements following substrate\ntransfer enabled the characterization of the length distribution of GNRs on the\ndevice substrate and confirmed their stability under ambient conditions and\nharsh chemical environments, including acid vapors and etchants. The increased\nlength and ambient stability of the 17-AGNRs lead to their reliable integration\ninto device architectures. As a proof of concept, we integrate 17-AGNRs into\nfield-effect transistors (FET) with graphene electrodes and confirm that\nelectronic transport occurs through the GNRs. This work demonstrates the\nfeasibility of integrating narrow-bandgap GNRs into functional devices and\ncontributes to advancing the development of carbon-based nanoelectronics.", "AI": {"tldr": "\u901a\u8fc7\u4f18\u5316\u5728\u886c\u5e95\u4e0a\u7684\u5408\u6210\u65b9\u6cd5\uff0c\u6210\u529f\u63d0\u9ad8\u4e8617-AGNRs\u7684\u957f\u5ea6\u548c\u7a33\u5b9a\u6027\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230\u6676\u4f53\u7ba1\u5668\u4ef6\u4e2d\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u78b3\u57fa\u7eb3\u7c73\u7535\u5b50\u5b66\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u4e3a\u4e86\u6ee1\u8db3\u5668\u4ef6\u96c6\u6210\u5bf917-AGNRs\u7684\u7ed3\u6784\u8981\u6c42\uff0c\u7279\u522b\u662f\u957f\u5ea6\u53c2\u6570\uff0c\u9700\u8981\u4f18\u5316\u5176\u5408\u6210\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u5728\u5206\u5b50\u524d\u4f53\u4e0a\u8fdb\u884c\u7cbe\u786e\u63a7\u5236\u7684\u5e95\u7269\u5408\u6210\uff08OSS\uff09\u65b9\u6cd5\uff0c\u5728\u8d85\u9ad8\u771f\u7a7a\uff08UHV\uff09\u4e0b\u5408\u621017-\u78b3\u539f\u5b50\u7684\u6276\u624b\u72b6\u77f3\u58a8\u70ef\u7eb3\u7c73\u5e26\uff0817-AGNRs\uff09\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u5408\u6210\u6761\u4ef6\uff0c\u5982\u7f13\u6162\u5347\u6e29\u548c\u589e\u52a0\u8868\u9762\u8986\u76d6\u7387\uff0c\u663e\u8457\u63d0\u9ad8\u4e8617-AGNRs\u7684\u957f\u5ea6\u81f3\u7ea617\u7eb3\u7c73\u3002\u7814\u7a76\u8fd8\u5229\u7528\u626b\u63cf\u63a2\u9488\u6280\u672f\u548c\u62c9\u66fc\u5149\u8c31\u5bf9\u5408\u6210\u768417-AGNRs\u8fdb\u884c\u4e86\u8868\u5f81\uff0c\u5e76\u8bc4\u4f30\u4e86\u5176\u5728\u4e0d\u540c\u73af\u5883\u4e0b\u7684\u7a33\u5b9a\u6027\u548c\u5728\u573a\u6548\u5e94\u6676\u4f53\u7ba1\uff08FET\uff09\u4e2d\u7684\u96c6\u6210\u5e94\u7528\u3002", "result": "\u4f18\u5316\u540e\u7684OSS\u6761\u4ef6\u53ef\u751f\u4ea7\u5e73\u5747\u957f\u5ea6\u7ea6\u4e3a17\u7eb3\u7c73\u768417-AGNRs\uff0c\u8fd9\u4e9b\u7eb3\u7c73\u5e26\u5728\u886c\u5e95\u8f6c\u79fb\u540e\u4ecd\u8868\u73b0\u51fa\u826f\u597d\u7684\u7a33\u5b9a\u6027\u548c\u73af\u5883\u517c\u5bb9\u6027\uff0c\u5e76\u6210\u529f\u96c6\u6210\u5230\u5177\u6709\u77f3\u58a8\u70ef\u7535\u6781\u7684\u573a\u6548\u5e94\u6676\u4f53\u7ba1\uff08FET\uff09\u4e2d\uff0c\u8bc1\u5b9e\u4e86\u7535\u5b50\u4f20\u8f93\u53d1\u751f\u5728GNRs\u4e2d\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u5c06\u7a84\u5e26\u9699\u768417-AGNRs\u96c6\u6210\u5230\u529f\u80fd\u5668\u4ef6\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u5e76\u4e3a\u78b3\u57fa\u7eb3\u7c73\u7535\u5b50\u5b66\u7684\u53d1\u5c55\u505a\u51fa\u4e86\u8d21\u732e\u3002"}}
{"id": "2507.10939", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.10939", "abs": "https://arxiv.org/abs/2507.10939", "authors": ["Emmanuel Billias", "Nikos Chrisochoides"], "title": "Towards a Utility-Scale Quantum Edge Detection for Real-World Medical Image Data", "comment": null, "summary": "We present a two-level decomposition strategy to enhance the quality and\nperformance of Quantum Hadamard Edge Detection (QHED) for practical image\nanalysis on Noisy Intermediate-Scale Quantum (NISQ) devices. A Data-Level\nDecomposition partitions an input image into P augmented sub-images, each\nencoded into a separate quantum circuit. Each of these circuits is then further\ncut via Circuit-Level Decomposition into Q smaller sub-circuits suitable for\nexecution on near-term quantum devices. The two-level P $\\times$ Q\ndecomposition, along with optimizations we introduced, achieves over 62\\%\nreductions in circuit depth and approximately 93\\% fewer two-qubit operations,\nwhile maintaining a fidelity exceeding 95.6\\% under realistic IBM noise models\nfor 5-qubit data input sizes. These results demonstrate the feasibility of\nperforming high-fidelity QHED on NISQ hardware and provide lessons and early\nevidence of distributed utility scale quantum computing, further illustrated by\nprocessing raw k-space MRI data with an Inverse Quantum Fourier Transform and a\ndistributed simulation of the modified QHED on large 2D and 3D MRI datasets.", "AI": {"tldr": "\u901a\u8fc7\u53cc\u5c42\u5206\u89e3\u548c\u4f18\u5316\uff0cQHED\u5728NISQ\u8bbe\u5907\u4e0a\u7684\u6027\u80fd\u548c\u4fdd\u771f\u5ea6\u5f97\u5230\u4e86\u663e\u8457\u63d0\u5347\uff0c\u4e3a\u5206\u5e03\u5f0f\u91cf\u5b50\u8ba1\u7b97\u5728\u56fe\u50cf\u5206\u6790\uff08\u5982MRI\uff09\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u8bc1\u636e\u3002", "motivation": "\u4e3a\u4e86\u5728\u6709\u566a\u58f0\u7684\u4e2d\u7b49\u89c4\u6a21\u91cf\u5b50\uff08NISQ\uff09\u8bbe\u5907\u4e0a\u4e3a\u5b9e\u9645\u56fe\u50cf\u5206\u6790\u589e\u5f3a\u91cf\u5b50\u54c8\u8fbe\u739b\u8fb9\u7f18\u68c0\u6d4b\uff08QHED\uff09\u7684\u8d28\u91cf\u548c\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u5c42\u5206\u89e3\u7b56\u7565\uff0c\u5305\u62ec\u6570\u636e\u7ea7\u5206\u89e3\uff08\u5c06\u8f93\u5165\u56fe\u50cf\u5212\u5206\u4e3aP\u4e2a\u589e\u5f3a\u5b50\u56fe\u50cf\uff0c\u6bcf\u4e2a\u5b50\u56fe\u50cf\u7f16\u7801\u5230\u5355\u72ec\u7684\u91cf\u5b50\u7535\u8def\u4e2d\uff09\u548c\u7535\u8def\u7ea7\u5206\u89e3\uff08\u5c06\u6bcf\u4e2a\u7535\u8def\u5207\u5272\u6210Q\u4e2a\u66f4\u5c0f\u7684\u5b50\u7535\u8def\uff09\u3002", "result": "\u5728\u771f\u5b9eIBM\u566a\u58f0\u6a21\u578b\u4e0b\uff0c\u5bf9\u4e8e5\u91cf\u5b50\u6bd4\u7279\u6570\u636e\u8f93\u5165\uff0c\u53cc\u5c42P\u00d7Q\u5206\u89e3\u548c\u6211\u4eec\u5f15\u5165\u7684\u4f18\u5316\u5b9e\u73b0\u4e86\u8d85\u8fc762%\u7684\u7535\u8def\u6df1\u5ea6\u51cf\u5c11\u548c\u5927\u7ea693%\u7684\u4e8c\u91cf\u5b50\u6bd4\u7279\u64cd\u4f5c\u51cf\u5c11\uff0c\u540c\u65f6\u4fdd\u6301\u8d85\u8fc795.6%\u7684\u4fdd\u771f\u5ea6\u3002", "conclusion": "\u5728\u771f\u5b9eIBM\u566a\u58f0\u6a21\u578b\u4e0b\uff0c\u5bf9\u4e8e5\u91cf\u5b50\u6bd4\u7279\u6570\u636e\u8f93\u5165\uff0c\u53cc\u5c42P\u00d7Q\u5206\u89e3\u548c\u6211\u4eec\u5f15\u5165\u7684\u4f18\u5316\u5b9e\u73b0\u4e86\u8d85\u8fc762%\u7684\u7535\u8def\u6df1\u5ea6\u51cf\u5c11\u548c\u5927\u7ea693%\u7684\u4e8c\u91cf\u5b50\u6bd4\u7279\u64cd\u4f5c\u51cf\u5c11\uff0c\u540c\u65f6\u4fdd\u6301\u8d85\u8fc795.6%\u7684\u4fdd\u771f\u5ea6\u3002\u8fd9\u8bc1\u660e\u4e86\u5728NISQ\u786c\u4ef6\u4e0a\u6267\u884c\u9ad8\u4fdd\u771fQHED\u7684\u53ef\u884c\u6027\uff0c\u5e76\u901a\u8fc7\u5904\u7406\u5177\u6709\u9006\u91cf\u5b50\u5085\u91cc\u53f6\u53d8\u6362\u7684\u539f\u59cbk\u7a7a\u95f4MRI\u6570\u636e\u4ee5\u53ca\u5728\u5927\u578b2D\u548c3D MRI\u6570\u636e\u96c6\u4e0a\u4fee\u6539\u7684QHED\u7684\u5206\u5e03\u5f0f\u6a21\u62df\uff0c\u8fdb\u4e00\u6b65\u8bc1\u660e\u4e86\u5206\u5e03\u5f0f\u6548\u7528\u89c4\u6a21\u91cf\u5b50\u8ba1\u7b97\u7684\u7ecf\u9a8c\u6559\u8bad\u548c\u65e9\u671f\u8bc1\u636e\u3002"}}
{"id": "2507.11015", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11015", "abs": "https://arxiv.org/abs/2507.11015", "authors": ["Zeyi Hou", "Zeqiang Wei", "Ruixin Yan", "Ning Lang", "Xiuzhuang Zhou"], "title": "Semantically Informed Salient Regions Guided Radiology Report Generation", "comment": null, "summary": "Recent advances in automated radiology report generation from chest X-rays\nusing deep learning algorithms have the potential to significantly reduce the\narduous workload of radiologists. However, due to the inherent massive data\nbias in radiology images, where abnormalities are typically subtle and sparsely\ndistributed, existing methods often produce fluent yet medically inaccurate\nreports, limiting their applicability in clinical practice. To address this\nissue effectively, we propose a Semantically Informed Salient Regions-guided\n(SISRNet) report generation method. Specifically, our approach explicitly\nidentifies salient regions with medically critical characteristics using\nfine-grained cross-modal semantics. Then, SISRNet systematically focuses on\nthese high-information regions during both image modeling and report\ngeneration, effectively capturing subtle abnormal findings, mitigating the\nnegative impact of data bias, and ultimately generating clinically accurate\nreports. Compared to its peers, SISRNet demonstrates superior performance on\nwidely used IU-Xray and MIMIC-CXR datasets.", "AI": {"tldr": "SISRNet\u901a\u8fc7\u5173\u6ce8\u533b\u5b66\u4e0a\u91cd\u8981\u7684\u533a\u57df\u6765\u63d0\u9ad8\u80f8\u90e8X\u5149\u7247\u62a5\u544a\u7684\u51c6\u786e\u6027\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u6570\u636e\u504f\u89c1\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u52a8\u653e\u5c04\u5b66\u62a5\u544a\u751f\u6210\u65b9\u6cd5\u7531\u4e8e\u653e\u5c04\u5b66\u56fe\u50cf\u4e2d\u5b58\u5728\u6570\u636e\u504f\u89c1\uff0c\u751f\u6210\u7684\u62a5\u544a\u867d\u7136\u6d41\u7545\u4f46\u53ef\u80fd\u5728\u533b\u5b66\u4e0a\u4e0d\u51c6\u786e\uff0c\u9650\u5236\u4e86\u5176\u4e34\u5e8a\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSISRNet\u7684\u62a5\u544a\u751f\u6210\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u7ec6\u7c92\u5ea6\u7684\u8de8\u6a21\u6001\u8bed\u4e49\u663e\u5f0f\u8bc6\u522b\u5177\u6709\u533b\u5b66\u5173\u952e\u7279\u5f81\u7684\u663e\u8457\u533a\u57df\uff0c\u5e76\u5728\u56fe\u50cf\u5efa\u6a21\u548c\u62a5\u544a\u751f\u6210\u8fc7\u7a0b\u4e2d\u7cfb\u7edf\u5730\u5173\u6ce8\u8fd9\u4e9b\u9ad8\u4fe1\u606f\u533a\u57df\u3002", "result": "SISRNet\u6709\u6548\u6355\u6349\u7ec6\u5fae\u7684\u5f02\u5e38\u53d1\u73b0\uff0c\u51cf\u8f7b\u4e86\u6570\u636e\u504f\u89c1\u7684\u4e0d\u5229\u5f71\u54cd\uff0c\u5e76\u6700\u7ec8\u751f\u6210\u4e86\u4e34\u5e8a\u51c6\u786e\u7684\u62a5\u544a\u3002", "conclusion": "SISRNet\u5728IU-Xray\u548cMIMIC-CXR\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u80fd\u591f\u751f\u6210\u4e34\u5e8a\u51c6\u786e\u7684\u62a5\u544a\u3002"}}
{"id": "2507.11135", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11135", "abs": "https://arxiv.org/abs/2507.11135", "authors": ["Selma Saidi", "Omar Laimona", "Christoph Schmickler", "Dirk Ziegenbein"], "title": "Collaborative Trustworthiness for Good Decision Making in Autonomous Systems", "comment": null, "summary": "Autonomous systems are becoming an integral part of many application domains,\nlike in the mobility sector. However, ensuring their safe and correct behaviour\nin dynamic and complex environments remains a significant challenge, where\nsystems should autonomously make decisions e.g., about manoeuvring. We propose\nin this paper a general collaborative approach for increasing the level of\ntrustworthiness in the environment of operation and improve reliability and\ngood decision making in autonomous system. In the presence of conflicting\ninformation, aggregation becomes a major issue for trustworthy decision making\nbased on collaborative data sharing. Unlike classical approaches in the\nliterature that rely on consensus or majority as aggregation rule, we exploit\nthe fact that autonomous systems have different quality attributes like\nperception quality. We use this criteria to determine which autonomous systems\nare trustworthy and borrow concepts from social epistemology to define\naggregation and propagation rules, used for automated decision making. We use\nBinary Decision Diagrams (BDDs) as formal models for beliefs aggregation and\npropagation, and formulate reduction rules to reduce the size of the BDDs and\nallow efficient computation structures for collaborative automated reasoning.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u534f\u4f5c\u65b9\u6cd5\uff0c\u5229\u7528\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u8d28\u91cf\u5c5e\u6027\u548c\u501f\u9274\u793e\u4f1a\u8ba4\u8bc6\u8bba\u7684\u805a\u5408/\u4f20\u64ad\u89c4\u5219\uff0c\u901a\u8fc7BDDs\u6a21\u578b\u63d0\u9ad8\u4e86\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u51b3\u7b56\u80fd\u529b\u548c\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u786e\u4fdd\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5728\u52a8\u6001\u590d\u6742\u73af\u5883\u4e2d\u5b89\u5168\u53ef\u9760\u5730\u8fd0\u884c\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u81ea\u4e3b\u51b3\u7b56\uff08\u5982\u673a\u52a8\uff09\u7684\u60c5\u51b5\u4e0b\uff0c\u4ecd\u7136\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002\u5728\u4fe1\u606f\u51b2\u7a81\u7684\u60c5\u51b5\u4e0b\uff0c\u57fa\u4e8e\u534f\u4f5c\u6570\u636e\u5171\u4eab\u7684\u53ef\u4fe1\u51b3\u7b56\u5236\u5b9a\uff0c\u5176\u805a\u5408\u95ee\u9898\u81f3\u5173\u91cd\u8981\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5404\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u4e0d\u540c\u7684\u8d28\u91cf\u5c5e\u6027\uff08\u5982\u611f\u77e5\u8d28\u91cf\uff09\u6765\u786e\u5b9a\u53ef\u4fe1\u8d56\u7cfb\u7edf\u7684\u534f\u4f5c\u65b9\u6cd5\uff0c\u5e76\u501f\u9274\u793e\u4f1a\u8ba4\u8bc6\u8bba\u7684\u6982\u5ff5\u5b9a\u4e49\u4e86\u7528\u4e8e\u81ea\u52a8\u51b3\u7b56\u7684\u805a\u5408\u548c\u4f20\u64ad\u89c4\u5219\u3002\u4f7f\u7528\u4e8c\u5143\u51b3\u7b56\u56fe\uff08BDDs\uff09\u4f5c\u4e3a\u4fe1\u5ff5\u805a\u5408\u548c\u4f20\u64ad\u7684\u6b63\u5f0f\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u7b80\u5316\u89c4\u5219\u51cf\u5c0fBDDs\u7684\u5c3a\u5bf8\u4ee5\u5b9e\u73b0\u9ad8\u6548\u7684\u534f\u4f5c\u81ea\u52a8\u5316\u63a8\u7406\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5229\u7528\u5404\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u4e0d\u540c\u7684\u8d28\u91cf\u5c5e\u6027\u6765\u786e\u5b9a\u53ef\u4fe1\u8d56\u7684\u7cfb\u7edf\uff0c\u5e76\u901a\u8fc7\u793e\u4f1a\u8ba4\u8bc6\u8bba\u7684\u6982\u5ff5\u5b9a\u4e49\u805a\u5408\u548c\u4f20\u64ad\u89c4\u5219\uff0c\u4ece\u800c\u63d0\u9ad8\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6\u3001\u53ef\u9760\u6027\u548c\u51b3\u7b56\u80fd\u529b\u3002\u4f7f\u7528BDDs\u4f5c\u4e3a\u6b63\u5f0f\u6a21\u578b\u548c\u7b80\u5316\u89c4\u5219\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u534f\u4f5c\u81ea\u52a8\u5316\u63a8\u7406\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u534f\u4f5c\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5728\u52a8\u6001\u590d\u6742\u73af\u5883\u4e2d\u7684\u53ef\u4fe1\u5ea6\u3001\u53ef\u9760\u6027\u548c\u51b3\u7b56\u80fd\u529b\u3002\u901a\u8fc7\u5229\u7528\u5404\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u4e0d\u540c\u7684\u8d28\u91cf\u5c5e\u6027\uff08\u5982\u611f\u77e5\u8d28\u91cf\uff09\uff0c\u800c\u975e\u4f20\u7edf\u7684\u5171\u8bc6\u6216\u591a\u6570\u89c4\u5219\uff0c\u6765\u786e\u5b9a\u53ef\u4fe1\u8d56\u7684\u7cfb\u7edf\u3002\u501f\u9274\u793e\u4f1a\u8ba4\u8bc6\u8bba\u7684\u6982\u5ff5\uff0c\u5b9a\u4e49\u4e86\u7528\u4e8e\u81ea\u52a8\u51b3\u7b56\u7684\u805a\u5408\u548c\u4f20\u64ad\u89c4\u5219\u3002\u7814\u7a76\u4f7f\u7528\u4e8c\u5143\u51b3\u7b56\u56fe\uff08BDDs\uff09\u4f5c\u4e3a\u4fe1\u5ff5\u805a\u5408\u548c\u4f20\u64ad\u7684\u6b63\u5f0f\u6a21\u578b\uff0c\u5e76\u63d0\u51fa\u4e86\u7b80\u5316\u89c4\u5219\u4ee5\u51cf\u5c0fBDDs\u7684\u5c3a\u5bf8\uff0c\u4ece\u800c\u5b9e\u73b0\u9ad8\u6548\u7684\u534f\u4f5c\u81ea\u52a8\u5316\u63a8\u7406\u3002"}}
{"id": "2507.11084", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.11084", "abs": "https://arxiv.org/abs/2507.11084", "authors": ["Md. Sabbir Hossen", "Md. Saiduzzaman", "Pabon Shaha"], "title": "Social Media Sentiments Analysis on the July Revolution in Bangladesh: A Hybrid Transformer Based Machine Learning Approach", "comment": "This paper has been accepted and presented at the IEEE ECAI 2025. The\n  final version will be available in the IEEE Xplore Digital Library", "summary": "The July Revolution in Bangladesh marked a significant student-led mass\nuprising, uniting people across the nation to demand justice, accountability,\nand systemic reform. Social media platforms played a pivotal role in amplifying\npublic sentiment and shaping discourse during this historic mass uprising. In\nthis study, we present a hybrid transformer-based sentiment analysis framework\nto decode public opinion expressed in social media comments during and after\nthe revolution. We used a brand new dataset of 4,200 Bangla comments collected\nfrom social media. The framework employs advanced transformer-based feature\nextraction techniques, including BanglaBERT, mBERT, XLM-RoBERTa, and the\nproposed hybrid XMB-BERT, to capture nuanced patterns in textual data.\nPrinciple Component Analysis (PCA) were utilized for dimensionality reduction\nto enhance computational efficiency. We explored eleven traditional and\nadvanced machine learning classifiers for identifying sentiments. The proposed\nhybrid XMB-BERT with the voting classifier achieved an exceptional accuracy of\n83.7% and outperform other model classifier combinations. This study\nunderscores the potential of machine learning techniques to analyze social\nsentiment in low-resource languages like Bangla.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408Transformer\u6a21\u578b\u7684\u60c5\u611f\u5206\u6790\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u5b5f\u52a0\u62c9\u56fd\u4e03\u6708\u9769\u547d\u671f\u95f4\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u516c\u4f17\u610f\u89c1\u3002\u8be5\u6846\u67b6\u5728\u5904\u7406\u5b5f\u52a0\u62c9\u8bed\u6570\u636e\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u51c6\u786e\u7387\u8fbe\u523083.7%\uff0c\u5e76\u5c55\u793a\u4e86\u673a\u5668\u5b66\u4e60\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u60c5\u611f\u5206\u6790\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u4e3a\u4e86\u5206\u6790\u5b5f\u52a0\u62c9\u56fd\u4e03\u6708\u9769\u547d\u671f\u95f4\u53ca\u4e4b\u540e\u793e\u4ea4\u5a92\u4f53\u8bc4\u8bba\u4e2d\u7684\u516c\u4f17\u610f\u89c1\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408Transformer\u6a21\u578b\uff0c\u7ed3\u5408\u4e86BanglaBERT\u3001mBERT\u3001XLM-RoBERTa\u548cXMB-BERT\uff0c\u5e76\u5229\u7528\u4e3b\u6210\u5206\u5206\u6790\uff08PCA\uff09\u8fdb\u884c\u964d\u7ef4\u3002\u7814\u7a76\u8fd8\u63a2\u7d22\u4e86\u5341\u4e00\u79cd\u4f20\u7edf\u548c\u5148\u8fdb\u7684\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u6765\u8bc6\u522b\u60c5\u611f\u3002", "result": "\u63d0\u51fa\u7684\u6df7\u5408XMB-BERT\u6a21\u578b\u4e0e\u6295\u7968\u5206\u7c7b\u5668\u76f8\u7ed3\u5408\uff0c\u5728\u5206\u6790\u793e\u4ea4\u5a92\u4f53\u8bc4\u8bba\u60c5\u611f\u65b9\u9762\u53d6\u5f97\u4e8683.7%\u7684\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86\u673a\u5668\u5b66\u4e60\u6280\u672f\u5728\u5206\u6790\u5b5f\u52a0\u62c9\u8bed\u7b49\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u793e\u4f1a\u60c5\u7eea\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.10637", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10637", "abs": "https://arxiv.org/abs/2507.10637", "authors": ["\u00c9. K\u00fcnzel", "A. Jaziri", "V. Ramesh"], "title": "A Simple Baseline for Stable and Plastic Neural Networks", "comment": "11 pages, 50 figures", "summary": "Continual learning in computer vision requires that models adapt to a\ncontinuous stream of tasks without forgetting prior knowledge, yet existing\napproaches often tip the balance heavily toward either plasticity or stability.\nWe introduce RDBP, a simple, low-overhead baseline that unites two\ncomplementary mechanisms: ReLUDown, a lightweight activation modification that\npreserves feature sensitivity while preventing neuron dormancy, and Decreasing\nBackpropagation, a biologically inspired gradient-scheduling scheme that\nprogressively shields early layers from catastrophic updates. Evaluated on the\nContinual ImageNet benchmark, RDBP matches or exceeds the plasticity and\nstability of state-of-the-art methods while reducing computational cost. RDBP\nthus provides both a practical solution for real-world continual learning and a\nclear benchmark against which future continual learning strategies can be\nmeasured.", "AI": {"tldr": "RDBP\u662f\u4e00\u79cd\u65b0\u7684\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7ReLUDown\u548cDecreasing Backpropagation\u673a\u5236\uff0c\u5728\u4e0d\u727a\u7272\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u4e86\u5851\u5f62\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u5e76\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u6301\u7eed\u5b66\u4e60\u9700\u8981\u6a21\u578b\u9002\u5e94\u8fde\u7eed\u7684\u4efb\u52a1\u6d41\uff0c\u540c\u65f6\u4e0d\u5fd8\u8bb0\u5148\u524d\u7684\u77e5\u8bc6\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u5728\u5851\u5f62\u6027\u548c\u7a33\u5b9a\u6027\u4e4b\u95f4\u5931\u8861\u3002", "method": "RDBP\u7ed3\u5408\u4e86\u4e24\u79cd\u673a\u5236\uff1aReLUDown\uff08\u4e00\u79cd\u8f7b\u91cf\u7ea7\u6fc0\u6d3b\u4fee\u6539\uff0c\u53ef\u4fdd\u6301\u7279\u5f81\u654f\u611f\u6027\u5e76\u9632\u6b62\u795e\u7ecf\u5143\u4f11\u7720\uff09\u548cDecreasing Backpropagation\uff08\u4e00\u79cd\u53d7\u751f\u7269\u5b66\u542f\u53d1\u7684\u68af\u5ea6\u8c03\u5ea6\u65b9\u6848\uff0c\u53ef\u9010\u6b65\u4fdd\u62a4\u65e9\u671f\u5c42\u514d\u53d7\u707e\u96be\u6027\u66f4\u65b0\uff09\u3002", "result": "RDBP\u5728Continual ImageNet\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5851\u5f62\u6027\u548c\u7a33\u5b9a\u6027\u4e0e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u5f53\u6216\u66f4\u4f18\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "RDBP\u662f\u4e00\u79cd\u7b80\u5355\u3001\u4f4e\u5f00\u9500\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728Continual ImageNet\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5176\u5851\u5f62\u6027\u548c\u7a33\u5b9a\u6027\u4e0e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u5f53\u6216\u66f4\u4f18\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002RDBP\u4e3a\u5b9e\u9645\u7684\u6301\u7eed\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u6301\u7eed\u5b66\u4e60\u7b56\u7565\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6e05\u6670\u7684\u57fa\u51c6\u3002"}}
{"id": "2507.11241", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.11241", "abs": "https://arxiv.org/abs/2507.11241", "authors": ["Tobias Kern", "Leon Tolksdorf", "Christian Birkner"], "title": "Comparison of Localization Algorithms between Reduced-Scale and Real-Sized Vehicles Using Visual and Inertial Sensors", "comment": null, "summary": "Physically reduced-scale vehicles are emerging to accelerate the development\nof advanced automated driving functions. In this paper, we investigate the\neffects of scaling on self-localization accuracy with visual and\nvisual-inertial algorithms using cameras and an inertial measurement unit\n(IMU). For this purpose, ROS2-compatible visual and visual-inertial algorithms\nare selected, and datasets are chosen as a baseline for real-sized vehicles. A\ntest drive is conducted to record data of reduced-scale vehicles. We compare\nthe selected localization algorithms, OpenVINS, VINS-Fusion, and RTAB-Map, in\nterms of their pose accuracy against the ground-truth and against data from\nreal-sized vehicles. When comparing the implementation of the selected\nlocalization algorithms to real-sized vehicles, OpenVINS has the lowest average\nlocalization error. Although all selected localization algorithms have\noverlapping error ranges, OpenVINS also performs best when applied to a\nreduced-scale vehicle. When reduced-scale vehicles were compared to real-sized\nvehicles, minor differences were found in translational vehicle motion\nestimation accuracy. However, no significant differences were found when\ncomparing the estimation accuracy of rotational vehicle motion, allowing RSVRs\nto be used as testing platforms for self-localization algorithms.", "AI": {"tldr": "\u5728\u7f29\u5c0f\u7684\u8f66\u8f86\u4e0a\u6d4b\u8bd5\u4e86\u4e09\u79cd\u81ea\u5b9a\u4f4d\u7b97\u6cd5\uff08OpenVINS\u3001VINS-Fusion\u3001RTAB-Map\uff09\uff0c\u53d1\u73b0 OpenVINS \u7684\u6027\u80fd\u6700\u4f73\u3002\u7f29\u5c0f\u7684\u8f66\u8f86\u5728\u5e73\u79fb\u548c\u65cb\u8f6c\u8fd0\u52a8\u4f30\u8ba1\u65b9\u9762\u4e0e\u5168\u5c3a\u5bf8\u8f66\u8f86\u7684\u6027\u80fd\u76f8\u4f3c\uff0c\u53ef\u4ee5\u4f5c\u4e3a\u81ea\u5b9a\u4f4d\u7b97\u6cd5\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002", "motivation": "\u7531\u4e8e\u5148\u8fdb\u7684\u81ea\u52a8\u9a7e\u9a76\u529f\u80fd\u7684\u53d1\u5c55\uff0c\u7269\u7406\u7f29\u5c0f\u6bd4\u4f8b\u7684\u8f66\u8f86\u6b63\u5728\u51fa\u73b0\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u7814\u7a76\u5c3a\u5ea6\u5bf9\u81ea\u5b9a\u4f4d\u51c6\u786e\u6027\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528 ROS2 \u517c\u5bb9\u7684\u89c6\u89c9\u548c\u89c6\u89c9\u60ef\u6027\u7b97\u6cd5\uff08OpenVINS\u3001VINS-Fusion \u548c RTAB-Map\uff09\u4ee5\u53ca\u6444\u50cf\u5934\u548c\u60ef\u6027\u6d4b\u91cf\u5355\u5143\uff08IMU\uff09\u6765\u7814\u7a76\u5c3a\u5ea6\u5bf9\u81ea\u5b9a\u4f4d\u51c6\u786e\u6027\u7684\u5f71\u54cd\u3002\u8bb0\u5f55\u7f29\u5c0f\u6bd4\u4f8b\u8f66\u8f86\u7684\u6570\u636e\uff0c\u5e76\u5c06\u5176\u4e0e\u771f\u5b9e\u6bd4\u4f8b\u8f66\u8f86\u7684\u6570\u636e\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "OpenVINS \u5728\u5e94\u7528\u4e8e\u7f29\u5c0f\u7684\u8f66\u8f86\u65f6\u8868\u73b0\u6700\u4f73\uff0c\u5b9a\u4f4d\u8bef\u5dee\u6700\u4f4e\u3002\u7f29\u5c0f\u6bd4\u4f8b\u7684\u8f66\u8f86\u5728\u5e73\u79fb\u8f66\u8f86\u8fd0\u52a8\u4f30\u8ba1\u51c6\u786e\u6027\u65b9\u9762\u4e0e\u5168\u5c3a\u5bf8\u8f66\u8f86\u7684\u5dee\u5f02\u5f88\u5c0f\uff0c\u800c\u5728\u65cb\u8f6c\u8f66\u8f86\u8fd0\u52a8\u4f30\u8ba1\u51c6\u786e\u6027\u65b9\u9762\u6ca1\u6709\u663e\u7740\u5dee\u5f02\u3002", "conclusion": "\u6240\u9009\u7684\u89c6\u89c9\u548c\u89c6\u89c9\u60ef\u6027\u7b97\u6cd5\u5728\u5e94\u7528\u4e8e\u7f29\u5c0f\u7684\u8f66\u8f86\u65f6\uff0cOpenVINS \u7684\u6027\u80fd\u6700\u4f73\uff0c\u5e76\u4e14\u6240\u9009\u7b97\u6cd5\u5728\u7f29\u5c0f\u8f66\u8f86\u548c\u5168\u5c3a\u5bf8\u8f66\u8f86\u4e4b\u95f4\u7684\u59ff\u6001\u4f30\u8ba1\u51c6\u786e\u6027\u65b9\u9762\u6ca1\u6709\u91cd\u5927\u5dee\u5f02\uff0c\u8fd9\u8868\u660e\u7f29\u5c0f\u7684\u8f66\u8f86\u53ef\u4ee5\u4f5c\u4e3a\u81ea\u5b9a\u4f4d\u7b97\u6cd5\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002"}}
{"id": "2507.10947", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.10947", "abs": "https://arxiv.org/abs/2507.10947", "authors": ["M. Salazar-Ram\u00edrez", "J. A. Mart\u00ednez-Nu\u00f1o", "MR Cordero-L\u00f3pez"], "title": "SU(1,1) coherent states for the Dunkl- Klein-Gordon equation in its canonical form", "comment": "22 pages, 14 figures", "summary": "Using representation-theoretic techniques associated with the\n$\\mathfrak{su}(1,1)$ symmetry algebra, we construct Perelomov coherent states\nfor the Dunkl-Klein-Gordon equation in its canonical form, which is free of\nfirst-order Dunkl derivatives. Our analysis is restricted to the even-parity\nsector and to the regime where the curvature constant $R$ is much smaller than\nthe system's kinetic energy. The equation under consideration emerges from a\nmatrix-operator framework based on Dirac gamma matrices and a universal length\nscale that encodes the curvature of space via the Dunkl operator, thereby\ncircumventing the need for spin connections in the Dirac equation.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.11025", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11025", "abs": "https://arxiv.org/abs/2507.11025", "authors": ["Sung Ho Kang", "Hyun-Cheol Park"], "title": "Human-Guided Shade Artifact Suppression in CBCT-to-MDCT Translation via Schr\u00f6dinger Bridge with Conditional Diffusion", "comment": null, "summary": "We present a novel framework for CBCT-to-MDCT translation, grounded in the\nSchrodinger Bridge (SB) formulation, which integrates GAN-derived priors with\nhuman-guided conditional diffusion. Unlike conventional GANs or diffusion\nmodels, our approach explicitly enforces boundary consistency between CBCT\ninputs and pseudo targets, ensuring both anatomical fidelity and perceptual\ncontrollability. Binary human feedback is incorporated via classifier-free\nguidance (CFG), effectively steering the generative process toward clinically\npreferred outcomes. Through iterative refinement and tournament-based\npreference selection, the model internalizes human preferences without relying\non a reward model. Subtraction image visualizations reveal that the proposed\nmethod selectively attenuates shade artifacts in key anatomical regions while\npreserving fine structural detail. Quantitative evaluations further demonstrate\nsuperior performance across RMSE, SSIM, LPIPS, and Dice metrics on clinical\ndatasets -- outperforming prior GAN- and fine-tuning-based feedback methods --\nwhile requiring only 10 sampling steps. These findings underscore the\neffectiveness and efficiency of our framework for real-time, preference-aligned\nmedical image translation.", "AI": {"tldr": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u859b\u5b9a\u8c14\u6865\uff08SB\uff09\u7684\u6846\u67b6\uff0c\u7528\u4e8eCBCT\u5230MDCT\u7684\u7ffb\u8bd1\uff0c\u5b83\u7ed3\u5408\u4e86GAN\u548c\u4eba\u7c7b\u6307\u5bfc\u7684\u6269\u6563\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u4e8c\u5143\u53cd\u9988\u8fdb\u884c\u6761\u4ef6\u5316\uff0c\u4ee5\u5b9e\u73b0\u89e3\u5256\u4fdd\u771f\u5ea6\u548c\u611f\u77e5\u53ef\u63a7\u6027\u3002", "motivation": "\u4e3a\u4e86\u5b9e\u73b0CBCT\u5230MDCT\u7684\u7ffb\u8bd1\uff0c\u5e76\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u89e3\u5256\u4fdd\u771f\u5ea6\u548c\u611f\u77e5\u53ef\u63a7\u6027\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u540c\u65f6\u6574\u5408\u4eba\u7c7b\u7684\u504f\u597d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684CBCT\u5230MDCT\u7ffb\u8bd1\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u57fa\u4e8e\u859b\u5b9a\u8c14\u6865\uff08SB\uff09\u516c\u5f0f\uff0c\u7ed3\u5408\u4e86GAN\u5148\u9a8c\u548c\u4eba\u7c7b\u6307\u5bfc\u7684\u6761\u4ef6\u6269\u6563\u3002\u901a\u8fc7\u96c6\u6210\u4e8c\u5143\u4eba\u7c7b\u53cd\u9988\u548c\u65e0\u5206\u7c7b\u5668\u6307\u5bfc\uff08CFG\uff09\uff0c\u5e76\u91c7\u7528\u8fed\u4ee3\u4f18\u5316\u548c\u57fa\u4e8e\u9526\u6807\u8d5b\u7684\u504f\u597d\u9009\u62e9\uff0c\u5728\u6ca1\u6709\u5956\u52b1\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u5185\u5316\u4e86\u4eba\u7c7b\u504f\u597d\u3002", "result": "\u8be5\u65b9\u6cd5\u9009\u62e9\u6027\u5730\u8870\u51cf\u4e86\u5173\u952e\u89e3\u5256\u533a\u57df\u7684\u4f2a\u5f71\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u7cbe\u7ec6\u7684\u7ed3\u6784\u7ec6\u8282\uff0c\u5e76\u5728\u4e34\u5e8a\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u5b9a\u91cf\u8bc4\u4f30\u7ed3\u679c\uff0c\u4f18\u4e8e\u5148\u524d\u7684GAN\u548c\u57fa\u4e8e\u5fae\u8c03\u7684\u53cd\u9988\u65b9\u6cd5\uff0c\u4e14\u91c7\u6837\u6b65\u6570\u5c11\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u9009\u62e9\u6027\u8870\u51cf\u4f2a\u5f71\u5e76\u4fdd\u7559\u7ec6\u8282\uff0c\u5728\u4e34\u5e8a\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\u7684CBCT\u5230MDCT\u7ffb\u8bd1\uff0c\u540c\u65f6\u5728RMSE\u3001SSIM\u3001LPIPS\u548cDice\u6307\u6807\u4e0a\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u4e14\u4ec5\u970010\u4e2a\u91c7\u6837\u6b65\u3002"}}
{"id": "2507.11086", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.11086", "abs": "https://arxiv.org/abs/2507.11086", "authors": ["Andres Azqueta-Gavald\u00f3n", "Joaquin Ramos Cosgrove"], "title": "Beyond Traditional Algorithms: Leveraging LLMs for Accurate Cross-Border Entity Identification", "comment": null, "summary": "The growing prevalence of cross-border financial activities in global markets\nhas underscored the necessity of accurately identifying and classifying foreign\nentities. This practice is essential within the Spanish financial system for\nensuring robust risk management, regulatory adherence, and the prevention of\nfinancial misconduct. This process involves a labor-intensive entity-matching\ntask, where entities need to be validated against available reference sources.\nChallenges arise from linguistic variations, special characters, outdated\nnames, and changes in legal forms, complicating traditional matching algorithms\nlike Jaccard, cosine, and Levenshtein distances. These methods struggle with\ncontextual nuances and semantic relationships, leading to mismatches. To\naddress these limitations, we explore Large Language Models (LLMs) as a\nflexible alternative. LLMs leverage extensive training to interpret context,\nhandle abbreviations, and adapt to legal transitions. We evaluate traditional\nmethods, Hugging Face-based LLMs, and interface-based LLMs (e.g., Microsoft\nCopilot, Alibaba's Qwen 2.5) using a dataset of 65 Portuguese company cases.\nResults show traditional methods achieve accuracies over 92% but suffer high\nfalse positive rates (20-40%). Interface-based LLMs outperform, achieving\naccuracies above 93%, F1 scores exceeding 96%, and lower false positives\n(40-80%).", "AI": {"tldr": "LLM \u5728\u8bc6\u522b\u5916\u56fd\u5b9e\u4f53\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u548c F1 \u5206\u6570\u66f4\u9ad8\uff0c\u8bef\u62a5\u7387\u66f4\u4f4e\u3002", "motivation": "\u5728\u5168\u7403\u91d1\u878d\u5e02\u573a\u65e5\u76ca\u589e\u957f\u7684\u8de8\u5883\u91d1\u878d\u6d3b\u52a8\u80cc\u666f\u4e0b\uff0c\u51c6\u786e\u8bc6\u522b\u548c\u5206\u7c7b\u5916\u56fd\u5b9e\u4f53\u5bf9\u4e8e\u897f\u73ed\u7259\u91d1\u878d\u7cfb\u7edf\u7684\u98ce\u9669\u7ba1\u7406\u3001\u5408\u89c4\u6027\u548c\u53cd\u91d1\u878d\u4e0d\u5f53\u884c\u4e3a\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u7684\u5339\u914d\u7b97\u6cd5\u5728\u5904\u7406\u8bed\u8a00\u53d8\u5f02\u3001\u7279\u6b8a\u5b57\u7b26\u3001\u8fc7\u65f6\u540d\u79f0\u548c\u6cd5\u5f8b\u5f62\u5f0f\u53d8\u66f4\u7b49\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002", "method": "\u901a\u8fc7\u6bd4\u8f83\u4f20\u7edf\u5339\u914d\u7b97\u6cd5\uff08Jaccard\u3001cosine\u3001Levenshtein\uff09\u548c\u57fa\u4e8e LLM \u7684\u65b9\u6cd5\uff08Hugging Face LLMs\u3001Microsoft Copilot\u3001Alibaba Qwen 2.5\uff09\u5728\u5904\u7406 65 \u4e2a\u8461\u8404\u7259\u516c\u53f8\u6848\u4f8b\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u6765\u8bc4\u4f30\u3002", "result": "\u4f20\u7edf\u65b9\u6cd5\u51c6\u786e\u7387\u8d85\u8fc7 92%\uff0c\u4f46\u8bef\u62a5\u7387\u8f83\u9ad8\uff0820-40%\uff09\u3002\u57fa\u4e8e LLM \u7684\u63a5\u53e3\u65b9\u6cd5\u8868\u73b0\u66f4\u4f18\uff0c\u51c6\u786e\u7387\u8d85\u8fc7 93%\uff0cF1 \u5206\u6570\u8d85\u8fc7 96%\uff0c\u8bef\u62a5\u7387\u8f83\u4f4e\uff0840-80%\uff09\u3002", "conclusion": "LLMs \u5728\u8bc6\u522b\u548c\u5206\u7c7b\u5916\u56fd\u5b9e\u4f53\u65b9\u9762\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u5177\u4f18\u52bf\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u8bed\u8a00\u53d8\u5f02\u548c\u6cd5\u5f8b\u53d8\u66f4\u65b9\u9762\u3002"}}
{"id": "2507.10638", "categories": ["cs.LG", "I.2.6; I.5.1"], "pdf": "https://arxiv.org/pdf/2507.10638", "abs": "https://arxiv.org/abs/2507.10638", "authors": ["Shim Soon Yong"], "title": "ZClassifier: Temperature Tuning and Manifold Approximation via KL Divergence on Logit Space", "comment": null, "summary": "We introduce a novel classification framework, ZClassifier, that replaces\nconventional deterministic logits with diagonal Gaussian-distributed logits.\nOur method simultaneously addresses temperature scaling and manifold\napproximation by minimizing the Kullback-Leibler (KL) divergence between the\npredicted Gaussian distributions and a unit isotropic Gaussian. This unifies\nuncertainty calibration and latent control in a principled probabilistic\nmanner, enabling a natural interpretation of class confidence and geometric\nconsistency. Experiments on CIFAR-10 and CIFAR-100 show that ZClassifier\nimproves over softmax classifiers in robustness, calibration, and latent\nseparation. We also demonstrate its effectiveness for classifier-guided\ngeneration by interpreting logits as Gaussian semantic potentials.", "AI": {"tldr": "ZClassifier \u662f\u4e00\u79cd\u65b0\u7684\u5206\u7c7b\u6846\u67b6\uff0c\u4f7f\u7528\u9ad8\u65af\u5206\u5e03 logits \u66ff\u4ee3\u786e\u5b9a\u6027 logits\uff0c\u63d0\u9ad8\u4e86\u5206\u7c7b\u5668\u7684\u9c81\u68d2\u6027\u3001\u6821\u51c6\u6027\u548c\u6f5c\u5728\u5206\u79bb\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4f20\u7edf\u786e\u5b9a\u6027 logits \u7684\u5c40\u9650\u6027\uff0c\u5e76\u7edf\u4e00\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u548c\u6f5c\u5728\u63a7\u5236\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5206\u7c7b\u6846\u67b6\u3002", "method": "ZClassifier \u6846\u67b6\u901a\u8fc7\u6700\u5c0f\u5316\u9884\u6d4b\u7684\u9ad8\u65af\u5206\u5e03\u4e0e\u5355\u4f4d\u5404\u5411\u540c\u6027\u9ad8\u65af\u5206\u5e03\u4e4b\u95f4\u7684 KL \u6563\u5ea6\u6765\u540c\u65f6\u5904\u7406\u6e29\u5ea6\u7f29\u653e\u548c\u6d41\u5f62\u903c\u8fd1\u3002", "result": "ZClassifier \u6846\u67b6\u5728 CIFAR-10 \u548c CIFAR-100 \u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5176\u9c81\u68d2\u6027\u3001\u6821\u51c6\u6027\u548c\u6f5c\u5728\u5206\u79bb\u6027\u5747\u4f18\u4e8e softmax \u5206\u7c7b\u5668\uff0c\u5e76\u53ef\u7528\u4e8e\u5206\u7c7b\u5668\u5f15\u5bfc\u751f\u6210\u3002", "conclusion": "ZClassifier \u901a\u8fc7\u5c06\u786e\u5b9a\u6027 logits \u66ff\u6362\u4e3a\u5bf9\u89d2\u9ad8\u65af\u5206\u5e03 logits\uff0c\u5e76\u5728 CIFAR-10 \u548c CIFAR-100 \u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u9c81\u68d2\u6027\u3001\u6821\u51c6\u548c\u6f5c\u5728\u5206\u79bb\u65b9\u9762\u4f18\u4e8e softmax \u5206\u7c7b\u5668\uff0c\u5e76\u6709\u6548\u5730\u7528\u4e8e\u5206\u7c7b\u5668\u5f15\u5bfc\u751f\u6210\u3002"}}
{"id": "2507.11270", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.11270", "abs": "https://arxiv.org/abs/2507.11270", "authors": ["Ting-Wei Ou", "Jia-Hao Jiang", "Guan-Lin Huang", "Kuu-Young Young"], "title": "Development of an Autonomous Mobile Robotic System for Efficient and Precise Disinfection", "comment": "Accepted to the IEEE International Conference on Systems, Man, and\n  Cybernetics (SMC) 2025", "summary": "The COVID-19 pandemic has severely affected public health, healthcare\nsystems, and daily life, especially amid resource shortages and limited\nworkers. This crisis has underscored the urgent need for automation in hospital\nenvironments, particularly disinfection, which is crucial to controlling virus\ntransmission and improving the safety of healthcare personnel and patients.\nUltraviolet (UV) light disinfection, known for its high efficiency, has been\nwidely adopted in hospital settings. However, most existing research focuses on\nmaximizing UV coverage while paying little attention to the impact of human\nactivity on virus distribution. To address this issue, we propose a mobile\nrobotic system for UV disinfection focusing on the virus hotspot. The system\nprioritizes disinfection in high-risk areas and employs an approach for\noptimized UV dosage to ensure that all surfaces receive an adequate level of UV\nexposure while significantly reducing disinfection time. It not only improves\ndisinfection efficiency but also minimizes unnecessary exposure in low-risk\nareas. In two representative hospital scenarios, our method achieves the same\ndisinfection effectiveness while reducing disinfection time by 30.7% and 31.9%,\nrespectively. The video of the experiment is available at:\nhttps://youtu.be/wHcWzOcoMPM.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u79fb\u52a8\u673a\u5668\u4eba\u7d2b\u5916\u7ebf\u6d88\u6bd2\u7cfb\u7edf\uff0c\u901a\u8fc7\u8bc6\u522b\u75c5\u6bd2\u70ed\u70b9\u548c\u4f18\u5316\u7d2b\u5916\u7ebf\u5242\u91cf\uff0c\u80fd\u5728\u4fdd\u8bc1\u6d88\u6bd2\u6548\u679c\u7684\u540c\u65f6\uff0c\u663e\u8457\u7f29\u77ed\u533b\u9662\u6d88\u6bd2\u65f6\u95f4\u3002", "motivation": "\u65b0\u51a0\u75ab\u60c5\u51f8\u663e\u4e86\u533b\u9662\u73af\u5883\u4e2d\u81ea\u52a8\u5316\u6d88\u6bd2\u7684\u5fc5\u8981\u6027\uff0c\u5c24\u5176\u662f\u5728\u8d44\u6e90\u77ed\u7f3a\u548c\u4eba\u5458\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u7d2b\u5916\u7ebf\u8986\u76d6\u8303\u56f4\uff0c\u5ffd\u89c6\u4e86\u4eba\u7c7b\u6d3b\u52a8\u5bf9\u75c5\u6bd2\u5206\u5e03\u7684\u5f71\u54cd\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5173\u6ce8\u75c5\u6bd2\u70ed\u70b9\u5e76\u4f18\u5316\u6d88\u6bd2\u8fc7\u7a0b\u7684\u81ea\u52a8\u5316\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79fb\u52a8\u673a\u5668\u4eba\u7d2b\u5916\u7ebf\u6d88\u6bd2\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u80fd\u591f\u8bc6\u522b\u75c5\u6bd2\u70ed\u70b9\u5e76\u8fdb\u884c\u4f18\u5316\u6d88\u6bd2\uff0c\u901a\u8fc7\u4f18\u5316\u7d2b\u5916\u7ebf\u5242\u91cf\u786e\u4fdd\u6240\u6709\u8868\u9762\u5f97\u5230\u5145\u5206\u6d88\u6bd2\uff0c\u5e76\u6700\u5927\u9650\u5ea6\u5730\u51cf\u5c11\u4f4e\u98ce\u9669\u533a\u57df\u7684\u66b4\u9732\uff0c\u4ece\u800c\u7f29\u77ed\u6d88\u6bd2\u65f6\u95f4\u3002", "result": "\u5728\u4e24\u4e2a\u4ee3\u8868\u6027\u7684\u533b\u9662\u573a\u666f\u4e2d\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u8fbe\u5230\u76f8\u540c\u6d88\u6bd2\u6548\u679c\u7684\u60c5\u51b5\u4e0b\uff0c\u5206\u522b\u5c06\u6d88\u6bd2\u65f6\u95f4\u7f29\u77ed\u4e86 30.7% \u548c 31.9%\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u79fb\u52a8\u673a\u5668\u4eba\u7d2b\u5916\u7ebf\u6d88\u6bd2\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u7f29\u77ed\u6d88\u6bd2\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u8bc1\u6d88\u6bd2\u6548\u679c\uff0c\u5e76\u9488\u5bf9\u533b\u9662\u73af\u5883\u4e2d\u7684\u75c5\u6bd2\u70ed\u70b9\u8fdb\u884c\u4f18\u5316\u6d88\u6bd2\u3002"}}
{"id": "2507.11494", "categories": ["quant-ph", "cond-mat.mtrl-sci", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2507.11494", "abs": "https://arxiv.org/abs/2507.11494", "authors": ["Chanaprom Cholsuk", "Tobias Vogl", "Viktor Iv\u00e1dy"], "title": "Spin Relaxation Mechanisms and Nuclear Spin Entanglement of the V$_B^{-1}$ Center in hBN", "comment": "27 pages, 5 figures", "summary": "The negatively charged boron vacancy $V_B^-$ defect in hexagonal boron\nnitride (hBN) has recently emerged as a promising spin qubit for sensing due to\nits high-temperature spin control and versatile integration into van der Waals\nstructures. While extensive experiments have explored their coherence\nproperties, much less is known about the spin relaxation time $T_1$ and its\ncontrol-parameter dependence. In this work, we develop a parameter-free spin\ndynamics model based on the cluster-expansion technique to investigate $T_1$\nrelaxation mechanisms at low temperature. Our results reveal that the $V_B^-$\ncenter constitutes a strongly coupled electron spin-nuclear spin core, which\nnecessitates the inclusion of the coherent dynamics and derived memory effects\nof the three nearest-neighbor nitrogen nuclear spins. Using this framework,\nthis work closely reproduces the experimentally observed $T_1$ time at $B =\n90\\,\\mathrm{G}$ and further predicts the $T_1$ dependence on external magnetic\nfield in the $0 \\le B \\le 2000\\,\\mathrm{G}$ interval, when the spin relaxation\nis predominantly driven by electron-nuclear and nuclear-nuclear flip-flop\nprocesses mediated by hyperfine and dipolar interactions. This study\nestablishes a reliable and scalable approach for describing $T_1$ relaxation in\n$V_B^-$ centers and offers microscopic insights to support future developments\nin nuclear-spin-based quantum technologies.", "AI": {"tldr": "hBN \u4e2d\u7684 V_B^- \u81ea\u65cb\u91cf\u5b50\u6bd4\u7279\u662f\u4e00\u79cd\u6709\u524d\u9014\u7684\u4f20\u611f\u5de5\u5177\uff0c\u4f46\u5176 T1 \u5f1b\u8c6b\u65f6\u95f4\u4ecd\u4e0d\u6e05\u695a\u3002\u6211\u4eec\u4f7f\u7528\u4e00\u79cd\u65b0\u7684\u81ea\u65cb\u52a8\u529b\u5b66\u6a21\u578b\u6765\u7814\u7a76 T1 \u5f1b\u8c6b\u673a\u5236\uff0c\u53d1\u73b0\u7535\u5b50-\u6838\u548c\u6838-\u6838\u76f8\u4e92\u4f5c\u7528\u5728\u9a71\u52a8\u5f1b\u8c6b\u4e2d\u8d77\u7740\u5173\u952e\u4f5c\u7528\u3002\u6211\u4eec\u7684\u6a21\u578b\u53ef\u4ee5\u51c6\u786e\u5730\u9884\u6d4b T1 \u65f6\u95f4\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u91cf\u5b50\u6280\u672f\u63d0\u4f9b\u89c1\u89e3\u3002", "motivation": "hBN \u4e2d\u5e26\u8d1f\u7535\u7684\u787c\u7a7a\u4f4d V_B^- \u7f3a\u9677\u4f5c\u4e3a\u4e00\u79cd\u6709\u524d\u9014\u7684\u81ea\u65cb\u91cf\u5b50\u6bd4\u7279\uff0c\u5728\u4f20\u611f\u9886\u57df\u5f15\u8d77\u4e86\u4eba\u4eec\u7684\u5173\u6ce8\uff0c\u56e0\u4e3a\u5b83\u5177\u6709\u9ad8\u6e29\u81ea\u65cb\u63a7\u5236\u548c\u8303\u5fb7\u534e\u7ed3\u6784\u4e2d\u7684\u591a\u529f\u80fd\u96c6\u6210\u80fd\u529b\u3002\u5c3d\u7ba1\u5927\u91cf\u5b9e\u9a8c\u63a2\u7d22\u4e86\u5176\u76f8\u5e72\u6027\uff0c\u4f46\u5bf9\u5176\u81ea\u65cb\u5f1b\u8c6b\u65f6\u95f4 T1 \u53ca\u5176\u63a7\u5236\u53c2\u6570\u4f9d\u8d56\u6027\u7684\u4e86\u89e3\u5374\u5c11\u5f97\u591a\u3002", "method": "\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7c07\u5c55\u5f00\u6280\u672f\u7684\u65e0\u53c2\u6570\u81ea\u65cb\u52a8\u529b\u5b66\u6a21\u578b\u6765\u7814\u7a76\u4f4e\u6e29\u4e0b\u7684 T1 \u5f1b\u8c6b\u673a\u5236\u3002", "result": "\u6211\u4eec\u7684\u7ed3\u679c\u8868\u660e\uff0cV_B^- \u4e2d\u5fc3\u6784\u6210\u4e86\u4e00\u4e2a\u5f3a\u8026\u5408\u7684\u7535\u5b50\u81ea\u65cb-\u6838\u81ea\u65cb\u6838\u5fc3\uff0c\u8fd9\u6709\u5fc5\u8981\u5305\u62ec\u4e09\u4e2a\u6700\u8fd1\u90bb\u6c2e\u6838\u81ea\u65cb\u7684\u76f8\u5e72\u52a8\u529b\u5b66\u548c\u6d3e\u751f\u7684\u8bb0\u5fc6\u6548\u5e94\u3002\u5728\u6b64\u6846\u67b6\u5185\uff0c\u672c\u5de5\u4f5c\u5728 B = 90 G \u65f6\u7cbe\u786e\u91cd\u73b0\u4e86\u5b9e\u9a8c\u89c2\u5bdf\u5230\u7684 T1 \u65f6\u95f4\uff0c\u5e76\u8fdb\u4e00\u6b65\u9884\u6d4b\u4e86\u5728 0 \u2264 B \u2264 2000 G \u533a\u95f4\u5185\uff0c\u5f53\u81ea\u65cb\u5f1b\u8c6b\u4e3b\u8981\u7531\u8d85\u7ec6\u548c\u5076\u6781\u76f8\u4e92\u4f5c\u7528\u4ecb\u5bfc\u7684\u7535\u5b50-\u6838\u548c\u6838-\u6838\u7ffb\u8f6c-\u7ffb\u8f6c\u8fc7\u7a0b\u9a71\u52a8\u65f6\uff0cT1 \u5bf9\u5916\u90e8\u78c1\u573a\u7684\u4f9d\u8d56\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u5efa\u7acb\u4e86\u4e00\u4e2a\u53ef\u9760\u4e14\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u6765\u63cf\u8ff0 V_B^- \u4e2d\u5fc3\u7684 T1 \u5f1b\u8c6b\uff0c\u5e76\u63d0\u4f9b\u4e86\u5fae\u89c2\u89c1\u89e3\u4ee5\u652f\u6301\u672a\u6765\u57fa\u4e8e\u6838\u81ea\u65cb\u7684\u91cf\u5b50\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
{"id": "2507.10976", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.10976", "abs": "https://arxiv.org/abs/2507.10976", "authors": ["Thiago Bergamaschi", "Reza Gheissari", "Yunchao Liu"], "title": "Rapid mixing for Gibbs states within a logical sector: a dynamical view of self-correcting quantum memories", "comment": "51 pages, 4 figures", "summary": "Self-correcting quantum memories store logical quantum information for\nexponential time in thermal equilibrium at low temperatures. By definition,\nthese systems are slow mixing. This raises the question of how the memory\nstate, which we refer to as the Gibbs state within a logical sector, is created\nin the first place.\n  In this paper, we show that for a broad class of self-correcting quantum\nmemories on lattices with parity check redundancies, a quasi-local quantum\nGibbs sampler rapidly converges to the corresponding low-temperature Gibbs\nstate within a logical sector when initialized from a ground state. This\nillustrates a dynamical view of self-correcting quantum memories, where the\n\"syndrome sector\" rapidly converges to thermal equilibrium, while the \"logical\nsector\" remains metastable. As a key application, when initialized from a\nrandom ground state, this gives a rapid Gibbs state preparation algorithm for\nthe 4D toric code in $\\mathrm{polylog}(n)$ depth. The main technical\ningredients behind our approach are new, low-temperature decay-of-correlation\nproperties for these metastable states.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5feb\u901f\u751f\u6210\u81ea\u6821\u6b63\u91cf\u5b50\u8bb0\u5fc6\u4f53\u4e2d\u903b\u8f91\u6247\u533a\u5409\u5e03\u65af\u72b6\u6001\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u57284D \u062a\u0648\u0631\u064a\u0643\u7801\u4e2d\u5177\u6709\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u81ea\u6821\u6b63\u91cf\u5b50\u8bb0\u5fc6\u4f53\u7684\u72b6\u6001\uff08\u903b\u8f91\u6247\u533a\u5185\u7684\u5409\u5e03\u65af\u72b6\u6001\uff09\u662f\u5982\u4f55\u5728\u521d\u59cb\u9636\u6bb5\u88ab\u521b\u5efa\u7684\u95ee\u9898\u3002", "method": "\u8be5\u7814\u7a76\u4f7f\u7528\u51c6\u5c40\u90e8\u91cf\u5b50\u5409\u5e03\u65af\u91c7\u6837\u5668\uff0c\u5e76\u5229\u7528\u4e86\u4f4e\u6e29\u4e0b\u4e9a\u7a33\u6001\u7684\u8870\u51cf\u76f8\u5173\u6027\u8d28\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u91c7\u6837\u5668\u80fd\u5feb\u901f\u6536\u655b\u5230\u76ee\u6807\u5409\u5e03\u65af\u72b6\u6001\uff0c\u5e76\u57284D \u062a\u0648\u0631\u064a\u0643\u7801\u4e2d\u5b9e\u73b0\u4e86\u5feb\u901f\u7684\u5409\u5e03\u65af\u72b6\u6001\u5236\u5907\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u5bf9\u4e8e\u4e00\u7c7b\u5177\u6709\u5947\u5076\u6821\u9a8c\u5197\u4f59\u7684\u683c\u4e0a\u7684\u81ea\u6821\u6b63\u91cf\u5b50\u8bb0\u5fc6\u4f53\uff0c\u51c6\u5c40\u90e8\u91cf\u5b50\u5409\u5e03\u65af\u91c7\u6837\u5668\u5728\u4ece\u57fa\u6001\u521d\u59cb\u5316\u65f6\uff0c\u53ef\u4ee5\u5feb\u901f\u6536\u655b\u5230\u76f8\u5e94\u7684\u4f4e\u6e29\u5409\u5e03\u65af\u72b6\u6001\uff08\u5728\u903b\u8f91\u6247\u533a\u5185\uff09\u3002\u8fd9\u63ed\u793a\u4e86\u81ea\u6821\u6b63\u91cf\u5b50\u8bb0\u5fc6\u4f53\u7684\u52a8\u529b\u5b66\u7279\u6027\uff1a"}}
{"id": "2507.11030", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11030", "abs": "https://arxiv.org/abs/2507.11030", "authors": ["Sunghyun Park", "Jungsoo Lee", "Shubhankar Borse", "Munawar Hayat", "Sungha Choi", "Kyuwoong Hwang", "Fatih Porikli"], "title": "Personalized OVSS: Understanding Personal Concept in Open-Vocabulary Semantic Segmentation", "comment": "Accepted to ICCV 2025; 15 pages", "summary": "While open-vocabulary semantic segmentation (OVSS) can segment an image into\nsemantic regions based on arbitrarily given text descriptions even for classes\nunseen during training, it fails to understand personal texts (e.g., `my mug\ncup') for segmenting regions of specific interest to users. This paper\naddresses challenges like recognizing `my mug cup' among `multiple mug cups'.\nTo overcome this challenge, we introduce a novel task termed\n\\textit{personalized open-vocabulary semantic segmentation} and propose a text\nprompt tuning-based plug-in method designed to recognize personal visual\nconcepts using a few pairs of images and masks, while maintaining the\nperformance of the original OVSS. Based on the observation that reducing false\npredictions is essential when applying text prompt tuning to this task, our\nproposed method employs `negative mask proposal' that captures visual concepts\nother than the personalized concept. We further improve the performance by\nenriching the representation of text prompts by injecting visual embeddings of\nthe personal concept into them. This approach enhances personalized OVSS\nwithout compromising the original OVSS performance. We demonstrate the\nsuperiority of our method on our newly established benchmarks for this task,\nincluding FSS$^\\text{per}$, CUB$^\\text{per}$, and ADE$^\\text{per}$.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e2a\u6027\u5316\u5f00\u653e\u8bcd\u6c47\u8bed\u4e49\u5206\u5272\u4efb\u52a1\u548c\u4e00\u79cd\u57fa\u4e8e\u6587\u672c\u63d0\u793a\u8c03\u4f18\u7684\u63d2\u4ef6\u65b9\u6cd5\uff0c\u901a\u8fc7\u8d1f\u63a9\u6a21\u63d0\u8bae\u548c\u6ce8\u5165\u89c6\u89c9\u5d4c\u5165\u6765\u63d0\u5347\u6a21\u578b\u8bc6\u522b\u7528\u6237\u7279\u5b9a\u7269\u4f53\uff08\u5982\u201c\u6211\u7684\u9a6c\u514b\u676f\u201d\uff09\u7684\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u539f\u6709\u5f00\u653e\u8bcd\u6c47\u8bed\u4e49\u5206\u5272\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u5f00\u653e\u8bcd\u6c47\u8bed\u4e49\u5206\u5272\uff08OVSS\uff09\u65b9\u6cd5\u65e0\u6cd5\u7406\u89e3\u7528\u6237\u81ea\u5b9a\u4e49\u7684\u6587\u672c\u63cf\u8ff0\uff08\u4f8b\u5982\uff0c\u201c\u6211\u7684\u9a6c\u514b\u676f\u201d\uff09\uff0c\u5bfc\u81f4\u5728\u5206\u5272\u7528\u6237\u7279\u5b9a\u5174\u8da3\u533a\u57df\u65f6\u9047\u5230\u56f0\u96be\uff0c\u5c24\u5176\u662f\u5728\u56fe\u50cf\u5305\u542b\u591a\u4e2a\u76f8\u4f3c\u7269\u4f53\u65f6\uff0c\u96be\u4ee5\u533a\u5206\u7279\u5b9a\u7269\u4f53\uff08\u4f8b\u5982\uff0c\u201c\u6211\u7684\u9a6c\u514b\u676f\u201d\u548c\u201c\u591a\u4e2a\u9a6c\u514b\u676f\u201d\uff09\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4e2a\u6027\u5316\u5f00\u653e\u8bcd\u6c47\u8bed\u4e49\u5206\u5272\u4efb\u52a1\uff0c\u5e76\u91c7\u7528\u57fa\u4e8e\u6587\u672c\u63d0\u793a\u8c03\u4f18\u7684\u63d2\u4ef6\u65b9\u6cd5\uff0c\u5229\u7528\u5c11\u91cf\u56fe\u50cf\u548c\u63a9\u6a21\u5bf9\u6765\u8bc6\u522b\u4e2a\u6027\u5316\u89c6\u89c9\u6982\u5ff5\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u539f\u59cb\u5f00\u653e\u8bcd\u6c47\u8bed\u4e49\u5206\u5272\u7684\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u201c\u8d1f\u63a9\u6a21\u63d0\u8bae\u201d\u6765\u6355\u6349\u4e2a\u6027\u5316\u6982\u5ff5\u4e4b\u5916\u7684\u89c6\u89c9\u6982\u5ff5\uff0c\u5e76\u901a\u8fc7\u5c06\u4e2a\u6027\u5316\u6982\u5ff5\u7684\u89c6\u89c9\u5d4c\u5165\u6ce8\u5165\u6587\u672c\u63d0\u793a\u6765\u4e30\u5bcc\u5176\u8868\u793a\u3002", "result": "\u5728\u65b0\u589e\u7684\u4e2a\u6027\u5316\u5f00\u653e\u8bcd\u6c47\u8bed\u4e49\u5206\u5272\u6570\u636e\u96c6\uff08\u5305\u62ecFSS$^{\text{per}}$\u3001CUB$^{\text{per}}$\u548cADE$^{\text{per}}$\uff09\u4e0a\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347\u4e2a\u6027\u5316\u5f00\u653e\u8bcd\u6c47\u8bed\u4e49\u5206\u5272\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u5728\u4e0d\u635f\u5bb3\u539f\u59cb\u5f00\u653e\u8bcd\u6c47\u8bed\u4e49\u5206\u5272\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u8d1f\u63a9\u6a21\u63d0\u8bae\u548c\u89c6\u89c9\u6982\u5ff5\u5d4c\u5165\u6765\u4e30\u5bcc\u6587\u672c\u63d0\u793a\u7684\u8868\u793a\u3002"}}
{"id": "2507.11229", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11229", "abs": "https://arxiv.org/abs/2507.11229", "authors": ["Jin Li", "Zezhong Ding", "Xike Xie"], "title": "DuetGraph: Coarse-to-Fine Knowledge Graph Reasoning with Dual-Pathway Global-Local Fusion", "comment": null, "summary": "Knowledge graphs (KGs) are vital for enabling knowledge reasoning across\nvarious domains. Recent KG reasoning methods that integrate both global and\nlocal information have achieved promising results. However, existing methods\noften suffer from score over-smoothing, which blurs the distinction between\ncorrect and incorrect answers and hinders reasoning effectiveness. To address\nthis, we propose DuetGraph, a coarse-to-fine KG reasoning mechanism with\ndual-pathway global-local fusion. DuetGraph tackles over-smoothing by\nsegregating -- rather than stacking -- the processing of local (via message\npassing) and global (via attention) information into two distinct pathways,\npreventing mutual interference and preserving representational discrimination.\nIn addition, DuetGraph introduces a coarse-to-fine optimization, which\npartitions entities into high- and low-score subsets. This strategy narrows the\ncandidate space and sharpens the score gap between the two subsets, which\nalleviates over-smoothing and enhances inference quality. Extensive experiments\non various datasets demonstrate that DuetGraph achieves state-of-the-art (SOTA)\nperformance, with up to an 8.7% improvement in reasoning quality and a\n1.8$\\times$ acceleration in training efficiency.", "AI": {"tldr": "DuetGraph \u901a\u8fc7\u53cc\u901a\u8def\u4fe1\u606f\u878d\u5408\u548c\u7c97\u7ec6\u7c92\u5ea6\u4f18\u5316\u89e3\u51b3\u4e86\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u4e2d\u7684\u5206\u6570\u5e73\u6ed1\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u63a8\u7406\u6548\u679c\u548c\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u65b9\u6cd5\u5728\u96c6\u6210\u5168\u5c40\u548c\u5c40\u90e8\u4fe1\u606f\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u666e\u904d\u5b58\u5728\u5206\u6570\u5e73\u6ed1\u95ee\u9898\uff0c\u8fd9\u6a21\u7cca\u4e86\u6b63\u786e\u7b54\u6848\u548c\u9519\u8bef\u7b54\u6848\u4e4b\u95f4\u7684\u754c\u9650\uff0c\u5e76\u963b\u788d\u4e86\u63a8\u7406\u7684\u6709\u6548\u6027\u3002", "method": "DuetGraph \u63d0\u51fa\u4e86\u4e00\u79cd\u7c97\u7c92\u5ea6\u5230\u7ec6\u7c92\u5ea6\u7684\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u673a\u5236\uff0c\u91c7\u7528\u53cc\u901a\u8def\u878d\u5408\u5168\u5c40\u548c\u5c40\u90e8\u4fe1\u606f\u3002\u8be5\u65b9\u6cd5\u5c06\u5c40\u90e8\u4fe1\u606f\uff08\u901a\u8fc7\u6d88\u606f\u4f20\u9012\uff09\u548c\u5168\u5c40\u4fe1\u606f\uff08\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\uff09\u5206\u79bb\u5230\u4e24\u4e2a\u4e0d\u540c\u7684\u901a\u8def\u4e2d\u8fdb\u884c\u5904\u7406\uff0c\u4ee5\u9632\u6b62\u76f8\u4e92\u5e72\u6270\u5e76\u4fdd\u6301\u8868\u793a\u533a\u5206\u5ea6\u3002\u6b64\u5916\uff0cDuetGraph \u5f15\u5165\u4e86\u7c97\u7c92\u5ea6\u5230\u7ec6\u7c92\u5ea6\u7684\u4f18\u5316\u7b56\u7565\uff0c\u5c06\u5b9e\u4f53\u5212\u5206\u4e3a\u9ad8\u5206\u548c\u4f4e\u5206\u5b50\u96c6\uff0c\u7f29\u5c0f\u5019\u9009\u7a7a\u95f4\u5e76\u589e\u5927\u5206\u6570\u5dee\u8ddd\uff0c\u4ece\u800c\u7f13\u89e3\u4e86\u5206\u6570\u5e73\u6ed1\u95ee\u9898\u5e76\u63d0\u9ad8\u4e86\u63a8\u7406\u8d28\u91cf\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDuetGraph \u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u63a8\u7406\u8d28\u91cf\u63d0\u9ad8\u4e86\u9ad8\u8fbe 8.7%\uff0c\u8bad\u7ec3\u6548\u7387\u63d0\u9ad8\u4e86 1.8 \u500d\u3002", "conclusion": "DuetGraph \u901a\u8fc7\u5206\u79bb\u5c40\u90e8\u548c\u5168\u5c40\u4fe1\u606f\u5904\u7406\u3001\u5f15\u5165\u7c97\u7c92\u5ea6\u5230\u7ec6\u7c92\u5ea6\u4f18\u5316\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u77e5\u8bc6\u56fe\u8c31\u63a8\u7406\u4e2d\u7684\u5206\u6570\u5e73\u6ed1\u95ee\u9898\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u63a8\u7406\u8d28\u91cf\u63d0\u9ad8\u4e86 8.7%\uff0c\u8bad\u7ec3\u6548\u7387\u63d0\u9ad8\u4e86 1.8 \u500d\u3002"}}
{"id": "2507.11097", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.11097", "abs": "https://arxiv.org/abs/2507.11097", "authors": ["Zichen Wen", "Jiashu Qu", "Dongrui Liu", "Zhiyuan Liu", "Ruixi Wu", "Yicun Yang", "Xiangqi Jin", "Haoyun Xu", "Xuyang Liu", "Weijia Li", "Chaochao Lu", "Jing Shao", "Conghui He", "Linfeng Zhang"], "title": "The Devil behind the mask: An emergent safety vulnerability of Diffusion LLMs", "comment": "21 pages, 9 figures, work in progress", "summary": "Diffusion-based large language models (dLLMs) have recently emerged as a\npowerful alternative to autoregressive LLMs, offering faster inference and\ngreater interactivity via parallel decoding and bidirectional modeling.\nHowever, despite strong performance in code generation and text infilling, we\nidentify a fundamental safety concern: existing alignment mechanisms fail to\nsafeguard dLLMs against context-aware, masked-input adversarial prompts,\nexposing novel vulnerabilities. To this end, we present DIJA, the first\nsystematic study and jailbreak attack framework that exploits unique safety\nweaknesses of dLLMs. Specifically, our proposed DIJA constructs adversarial\ninterleaved mask-text prompts that exploit the text generation mechanisms of\ndLLMs, i.e., bidirectional modeling and parallel decoding. Bidirectional\nmodeling drives the model to produce contextually consistent outputs for masked\nspans, even when harmful, while parallel decoding limits model dynamic\nfiltering and rejection sampling of unsafe content. This causes standard\nalignment mechanisms to fail, enabling harmful completions in alignment-tuned\ndLLMs, even when harmful behaviors or unsafe instructions are directly exposed\nin the prompt. Through comprehensive experiments, we demonstrate that DIJA\nsignificantly outperforms existing jailbreak methods, exposing a previously\noverlooked threat surface in dLLM architectures. Notably, our method achieves\nup to 100% keyword-based ASR on Dream-Instruct, surpassing the strongest prior\nbaseline, ReNeLLM, by up to 78.5% in evaluator-based ASR on JailbreakBench and\nby 37.7 points in StrongREJECT score, while requiring no rewriting or hiding of\nharmful content in the jailbreak prompt. Our findings underscore the urgent\nneed for rethinking safety alignment in this emerging class of language models.\nCode is available at https://github.com/ZichenWen1/DIJA.", "AI": {"tldr": "DIJA \u6846\u67b6\u63ed\u793a\u4e86 dLLM \u7684\u65b0\u5b89\u5168\u6f0f\u6d1e\uff0c\u5e76\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u5f3a\u8c03\u4e86\u91cd\u65b0\u601d\u8003 dLLM \u5b89\u5168\u5bf9\u9f50\u7684\u5fc5\u8981\u6027\u3002", "motivation": "\u73b0\u6709\u5bf9\u9f50\u673a\u5236\u65e0\u6cd5\u4fdd\u62a4 dLLM \u514d\u53d7\u7279\u5b9a\u7c7b\u578b\u7684\u5bf9\u6297\u6027\u653b\u51fb\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u7684\u5b89\u5168\u9690\u60a3\u3002", "method": "DIJA \u6784\u5efa\u5bf9\u6297\u6027\u4ea4\u9519\u63a9\u7801-\u6587\u672c\u63d0\u793a\uff0c\u5229\u7528 dLLM \u7684\u6587\u672c\u751f\u6210\u673a\u5236\uff08\u53cc\u5411\u5efa\u6a21\u548c\u5e76\u884c\u89e3\u7801\uff09\u6765\u5229\u7528\u5176\u5b89\u5168\u5f31\u70b9\u3002", "result": "DIJA \u5728 Dream-Instruct \u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe 100% \u7684\u57fa\u4e8e\u5173\u952e\u5b57\u7684 ASR\uff0c\u5728 JailbreakBench \u4e0a\u8d85\u8d8a\u4e86\u6700\u5f3a\u7684\u5148\u524d\u57fa\u7ebf ReNeLLM\uff0c\u5e76\u4e14\u5728 StrongREJECT \u5206\u6570\u4e0a\u63d0\u9ad8\u4e86 37.7 \u4e2a\u70b9\uff0c\u540c\u65f6\u65e0\u9700\u91cd\u5199\u6216\u9690\u85cf\u8d8a\u72f1\u63d0\u793a\u4e2d\u7684\u6709\u5bb3\u5185\u5bb9\u3002", "conclusion": "\u73b0\u6709\u7684\u5bf9\u9f50\u673a\u5236\u672a\u80fd\u4fdd\u62a4 dLLM \u514d\u53d7\u4e0a\u4e0b\u6587\u611f\u77e5\u3001\u63a9\u7801\u8f93\u5165\u5bf9\u6297\u6027\u63d0\u793a\u7684\u5f71\u54cd\uff0c\u66b4\u9732\u4e86\u65b0\u7684\u6f0f\u6d1e\u3002DIJA \u662f\u7b2c\u4e00\u4e2a\u5229\u7528 dLLM \u72ec\u7279\u5b89\u5168\u5f31\u70b9\u7684\u7cfb\u7edf\u6027\u7814\u7a76\u548c\u8d8a\u72f1\u653b\u51fb\u6846\u67b6\u3002"}}
{"id": "2507.10642", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10642", "abs": "https://arxiv.org/abs/2507.10642", "authors": ["Andrew Gascoyne", "Wendy Lomas"], "title": "First-of-its-kind AI model for bioacoustic detection using a lightweight associative memory Hopfield neural network", "comment": "12 pages, 5 figures", "summary": "A growing issue within conservation bioacoustics is the task of analysing the\nvast amount of data generated from the use of passive acoustic monitoring\ndevices. In this paper, we present an alternative AI model which has the\npotential to help alleviate this problem. Our model formulation addresses the\nkey issues encountered when using current AI models for bioacoustic analysis,\nnamely the: limited training data available; environmental impact, particularly\nin energy consumption and carbon footprint of training and implementing these\nmodels; and associated hardware requirements. The model developed in this work\nuses associative memory via a transparent, explainable Hopfield neural network\nto store signals and detect similar signals which can then be used to classify\nspecies. Training is rapid ($3$\\,ms), as only one representative signal is\nrequired for each target sound within a dataset. The model is fast, taking only\n$5.4$\\,s to pre-process and classify all $10384$ publicly available bat\nrecordings, on a standard Apple MacBook Air. The model is also lightweight with\na small memory footprint of $144.09$\\,MB of RAM usage. Hence, the low\ncomputational demands make the model ideal for use on a variety of standard\npersonal devices with potential for deployment in the field via edge-processing\ndevices. It is also competitively accurate, with up to $86\\%$ precision on the\ndataset used to evaluate the model. In fact, we could not find a single case of\ndisagreement between model and manual identification via expert field guides.\nAlthough a dataset of bat echolocation calls was chosen to demo this\nfirst-of-its-kind AI model, trained on only two representative calls, the model\nis not species specific. In conclusion, we propose an equitable AI model that\nhas the potential to be a game changer for fast, lightweight, sustainable,\ntransparent, explainable and accurate bioacoustic analysis.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4eba\u5de5\u667a\u80fd\u6a21\u578b\uff0c\u7528\u4e8e\u89e3\u51b3\u751f\u7269\u58f0\u5b66\u5206\u6790\u4e2d\u7684\u6570\u636e\u91cf\u5927\u3001\u8bad\u7ec3\u6570\u636e\u6709\u9650\u3001\u73af\u5883\u5f71\u54cd\u548c\u786c\u4ef6\u8981\u6c42\u9ad8\u7b49\u95ee\u9898\u3002\u8be5\u6a21\u578b\u91c7\u7528\u970d\u666e\u83f2\u5c14\u5fb7\u795e\u7ecf\u7f51\u7edc\uff0c\u5177\u6709\u8bad\u7ec3\u901f\u5ea6\u5feb\u3001\u5904\u7406\u901f\u5ea6\u5feb\u3001\u5185\u5b58\u5360\u7528\u5c0f\u3001\u7cbe\u5ea6\u9ad8\u7b49\u4f18\u70b9\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u4e2a\u4eba\u8bbe\u5907\uff0c\u5e76\u6709\u6f5c\u529b\u5728\u91ce\u5916\u90e8\u7f72\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u6a21\u578b\u5728\u751f\u7269\u58f0\u5b66\u5206\u6790\u4e2d\u7684\u5e94\u7528\u9762\u4e34\u7740\u8bad\u7ec3\u6570\u636e\u6709\u9650\u3001\u73af\u5883\u5f71\u54cd\uff08\u5c24\u5176\u662f\u80fd\u8017\u548c\u78b3\u8db3\u8ff9\uff09\u4ee5\u53ca\u786c\u4ef6\u8981\u6c42\u9ad8\u8fd9\u51e0\u4e2a\u5173\u952e\u95ee\u9898\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u4ee5\u7f13\u89e3\u8fd9\u4e9b\u95ee\u9898\u7684\u4eba\u5de5\u667a\u80fd\u6a21\u578b\u3002", "method": "\u6211\u4eec\u4f7f\u7528\u900f\u660e\u3001\u53ef\u89e3\u91ca\u7684\u970d\u666e\u83f2\u5c14\u5fb7\u795e\u7ecf\u7f51\u7edc\u901a\u8fc7\u8054\u60f3\u8bb0\u5fc6\u6765\u5b58\u50a8\u4fe1\u53f7\u5e76\u68c0\u6d4b\u76f8\u4f3c\u4fe1\u53f7\uff0c\u7136\u540e\u53ef\u7528\u4e8e\u5bf9\u7269\u79cd\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u8be5\u6a21\u578b\u8bad\u7ec3\u901f\u5ea6\u5feb\uff083\u6beb\u79d2\uff09\uff0c\u4ec5\u9700\u8981\u6bcf\u4e2a\u76ee\u6807\u58f0\u97f3\u7684\u4ee3\u8868\u6027\u4fe1\u53f7\u5373\u53ef\u3002\u8be5\u6a21\u578b\u5904\u7406\u901f\u5ea6\u5feb\uff0c\u5728\u6807\u51c6\u7684Apple MacBook Air\u4e0a\u5904\u7406\u548c\u5206\u7c7b\u6240\u670910384\u4e2a\u516c\u5f00\u7684\u8759\u8760\u5f55\u97f3\u4ec5\u97005.4\u79d2\u3002\u8be5\u6a21\u578b\u5185\u5b58\u5360\u7528\u5c0f\uff0c\u4ec5\u4e3a144.09MB RAM\u3002\u8be5\u6a21\u578b\u7684\u7cbe\u5ea6\u9ad8\u8fbe86%\uff0c\u5e76\u4e14\u5728\u4eba\u5de5\u8bc6\u522b\u65b9\u9762\u6ca1\u6709\u53d1\u73b0\u6a21\u578b\u8bc6\u522b\u4e0d\u4e00\u81f4\u7684\u60c5\u51b5\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u516c\u5e73\u7684\u4eba\u5de5\u667a\u80fd\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u6709\u6f5c\u529b\u6210\u4e3a\u5feb\u901f\u3001\u8f7b\u91cf\u7ea7\u3001\u53ef\u6301\u7eed\u3001\u900f\u660e\u3001\u53ef\u89e3\u91ca\u548c\u51c6\u786e\u7684\u751f\u7269\u58f0\u5b66\u5206\u6790\u7684\u53d8\u9769\u8005\u3002"}}
{"id": "2507.10989", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.10989", "abs": "https://arxiv.org/abs/2507.10989", "authors": ["Miko\u0142aj Sienicki", "Krzysztof Sienicki"], "title": "Critical Reflections on Overcoming a Challenge for Bohmian Mechanics by H. Nikolic and the Experimental Findings of Sharoglazova et al", "comment": "3 pages only, 7 references", "summary": "This paper offers a brief reflection on H. Nikolic's response to the\nexperimental findings of Sharoglazova et al., which challenge Bohmian\nmechanics. While Nikolic's revision satisfies the continuity equation, it\nreintroduces assumptions he seeks to avoid and overlooks key empirical and\nnonlocal aspects of the system. These issues underscore unresolved tensions in\napplying Bohmian mechanics to complex, interacting regimes.", "AI": {"tldr": "Nikolic\u4fee\u6b63Bohmian\u529b\u5b66\u4ee5\u5e94\u5bf9\u5b9e\u9a8c\u6311\u6218\uff0c\u4f46\u5f15\u5165\u4e86\u65b0\u5047\u8bbe\u5e76\u5ffd\u7565\u4e86\u5173\u952e\u7279\u5f81\uff0cBohmian\u529b\u5b66\u4ecd\u6709\u5f85\u5b8c\u5584\u3002", "motivation": "\u8be5\u8bba\u6587\u7684\u52a8\u673a\u662f\u63a2\u8ba8Bohmian\u529b\u5b66\u5728\u89e3\u91caSharoglazova\u7b49\u4eba\u7684\u5b9e\u9a8c\u7ed3\u679c\u65f6\u9047\u5230\u7684\u6311\u6218\uff0c\u4ee5\u53caH. Nikolic\u7684\u56de\u5e94\u5982\u4f55\u672a\u80fd\u5b8c\u5168\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u8be5\u8bba\u6587\u901a\u8fc7\u5206\u6790H. Nikolic\u5bf9Sharoglazova\u7b49\u4eba\u7684\u5b9e\u9a8c\u7ed3\u679c\u7684\u56de\u5e94\uff0c\u5e76\u7740\u91cd\u63a2\u8ba8\u5176\u4fee\u6b63\u65b9\u6848\u5728\u6ee1\u8db3\u8fde\u7eed\u6027\u65b9\u7a0b\u7684\u540c\u65f6\uff0c\u5982\u4f55\u91cd\u65b0\u5f15\u5165\u4e86\u907f\u514d\u7684\u5047\u8bbe\uff0c\u5e76\u5ffd\u7565\u4e86\u5173\u952e\u7684\u7ecf\u9a8c\u548c\u975e\u5b9a\u57df\u65b9\u9762\u6765\u5c55\u5f00\u5206\u6790\u3002", "result": "\u8be5\u8bba\u6587\u7684\u7ed3\u679c\u662f\uff0cNikolic\u7684\u4fee\u6b63\u65b9\u6848\u867d\u7136\u6ee1\u8db3\u4e86\u8fde\u7eed\u6027\u65b9\u7a0b\uff0c\u4f46\u5f15\u5165\u4e86\u65b0\u7684\u5047\u8bbe\u5e76\u5ffd\u7565\u4e86\u91cd\u8981\u7684\u7cfb\u7edf\u7279\u5f81\uff0c\u8868\u660eBohmian\u529b\u5b66\u5728\u5e94\u7528\u4e8e\u590d\u6742\u76f8\u4e92\u4f5c\u7528\u7cfb\u7edf\u65f6\u4ecd\u5b58\u5728\u672a\u89e3\u51b3\u7684\u95ee\u9898\u3002", "conclusion": "\u8be5\u8bba\u6587\u7684\u7ed3\u8bba\u662f\uff0cNikolic\u7684\u4fee\u6b63\u867d\u7136\u6ee1\u8db3\u4e86\u8fde\u7eed\u6027\u65b9\u7a0b\uff0c\u4f46\u91cd\u65b0\u5f15\u5165\u4e86\u4ed6\u8bd5\u56fe\u907f\u514d\u7684\u5047\u8bbe\uff0c\u5e76\u4e14\u5ffd\u7565\u4e86\u7cfb\u7edf\u4e2d\u5173\u952e\u7684\u7ecf\u9a8c\u548c\u975e\u5b9a\u57df\u65b9\u9762\u3002\u8fd9\u4e9b\u95ee\u9898\u7a81\u663e\u4e86\u5c06Bohmian\u529b\u5b66\u5e94\u7528\u4e8e\u590d\u6742\u3001\u76f8\u4e92\u4f5c\u7528\u7684\u4f53\u7cfb\u65f6\u5b58\u5728\u7684\u672a\u89e3\u51b3\u7684\u77db\u76fe\u3002"}}
{"id": "2507.11035", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11035", "abs": "https://arxiv.org/abs/2507.11035", "authors": ["Lirong Zheng", "Yanshan Li", "Rui Yu", "Kaihao Zhang"], "title": "Efficient Dual-domain Image Dehazing with Haze Prior Perception", "comment": "12 pages", "summary": "Transformer-based models exhibit strong global modeling capabilities in\nsingle-image dehazing, but their high computational cost limits real-time\napplicability. Existing methods predominantly rely on spatial-domain features\nto capture long-range dependencies, which are computationally expensive and\noften inadequate under complex haze conditions. While some approaches introduce\nfrequency-domain cues, the weak coupling between spatial and frequency branches\nlimits the overall performance. To overcome these limitations, we propose the\nDark Channel Guided Frequency-aware Dehazing Network (DGFDNet), a novel\ndual-domain framework that performs physically guided degradation alignment\nacross spatial and frequency domains. At its core, the DGFDBlock comprises two\nkey modules: 1) the Haze-Aware Frequency Modulator (HAFM), which generates a\npixel-level haze confidence map from dark channel priors to adaptively enhance\nhaze-relevant frequency components, thereby achieving global degradation-aware\nspectral modulation; 2) the Multi-level Gating Aggregation Module (MGAM), which\nfuses multi-scale features through diverse convolutional kernels and hybrid\ngating mechanisms to recover fine structural details. Additionally, a Prior\nCorrection Guidance Branch (PCGB) incorporates a closed-loop feedback\nmechanism, enabling iterative refinement of the prior by intermediate dehazed\nfeatures and significantly improving haze localization accuracy, especially in\nchallenging outdoor scenes. Extensive experiments on four benchmark haze\ndatasets demonstrate that DGFDNet achieves state-of-the-art performance with\nsuperior robustness and real-time efficiency. Code is available at:\nhttps://github.com/Dilizlr/DGFDNet.", "AI": {"tldr": "DGFDNet\u662f\u4e00\u79cd\u65b0\u578b\u7684\u53cc\u57df\u53bb\u96fe\u7f51\u7edc\uff0c\u901a\u8fc7\u7ed3\u5408\u7a7a\u95f4\u57df\u548c\u9891\u7387\u57df\u7684\u4f18\u52bf\uff0c\u5e76\u5229\u7528\u6697\u901a\u9053\u5148\u9a8c\u548c\u591a\u7ea7\u7279\u5f81\u878d\u5408\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u9c81\u68d2\u7684\u53bb\u96fe\u6548\u679c\uff0c\u5c24\u5176\u5728\u590d\u6742\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u867d\u7136\u5177\u6709\u5f3a\u5927\u7684\u5168\u5c40\u5efa\u6a21\u80fd\u529b\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9650\u5236\u4e86\u5176\u5b9e\u65f6\u5e94\u7528\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4e8e\u7a7a\u95f4\u57df\u7279\u5f81\u6765\u6355\u83b7\u957f\u8ddd\u79bb\u4f9d\u8d56\u5173\u7cfb\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u5728\u590d\u6742\u96fe\u973e\u6761\u4ef6\u4e0b\u4e0d\u8db3\u3002\u4e00\u4e9b\u65b9\u6cd5\u5f15\u5165\u4e86\u9891\u57df\u7ebf\u7d22\uff0c\u4f46\u7a7a\u95f4\u548c\u9891\u57df\u5206\u652f\u4e4b\u95f4\u7684\u5f31\u8026\u5408\u9650\u5236\u4e86\u6574\u4f53\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDGFDNet\u7684\u65b0\u578b\u53cc\u57df\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u8de8\u7a7a\u95f4\u548c\u9891\u7387\u57df\u6267\u884c\u7269\u7406\u5f15\u5bfc\u7684\u9000\u5316\u5bf9\u9f50\u3002\u6838\u5fc3\u7684DGFDBlock\u5305\u542b\u611f\u77e5\u9891\u7387\u8c03\u5236\u5668\uff08HAFM\uff09\u548c\u591a\u7ea7\u95e8\u63a7\u805a\u5408\u6a21\u5757\uff08MGAM\uff09\u3002HAFM\u4ece\u6697\u901a\u9053\u5148\u9a8c\u751f\u6210\u50cf\u7d20\u7ea7\u96fe\u973e\u7f6e\u4fe1\u56fe\uff0c\u4ee5\u81ea\u9002\u5e94\u5730\u589e\u5f3a\u96fe\u973e\u76f8\u5173\u7684\u9891\u7387\u5206\u91cf\u3002MGAM\u901a\u8fc7\u4e0d\u540c\u7684\u5377\u79ef\u6838\u548c\u6df7\u5408\u95e8\u63a7\u673a\u5236\u878d\u5408\u591a\u5c3a\u5ea6\u7279\u5f81\u4ee5\u6062\u590d\u7cbe\u7ec6\u7684\u7ed3\u6784\u7ec6\u8282\u3002\u6b64\u5916\uff0c\u5148\u9a8c\u6821\u6b63\u5f15\u5bfc\u5206\u652f\uff08PCGB\uff09\u5f15\u5165\u4e86\u95ed\u73af\u53cd\u9988\u673a\u5236\uff0c\u901a\u8fc7\u4e2d\u95f4\u53bb\u96fe\u7279\u5f81\u8fed\u4ee3\u5730\u4f18\u5316\u5148\u9a8c\uff0c\u63d0\u9ad8\u4e86\u96fe\u973e\u5b9a\u4f4d\u7cbe\u5ea6\u3002", "result": "DGFDNet\u5728\u56db\u4e2a\u57fa\u51c6\u96fe\u973e\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5177\u6709\u51fa\u8272\u7684\u9c81\u68d2\u6027\u548c\u5b9e\u65f6\u6548\u7387\u3002", "conclusion": "DGFDNet\u5728\u56db\u4e2a\u57fa\u51c6\u96fe\u973e\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5177\u6709\u51fa\u8272\u7684\u9c81\u68d2\u6027\u548c\u5b9e\u65f6\u6548\u7387\u3002"}}
{"id": "2507.11112", "categories": ["cs.CL", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11112", "abs": "https://arxiv.org/abs/2507.11112", "authors": ["Sanhanat Sivapiromrat", "Caiqi Zhang", "Marco Basaldella", "Nigel Collier"], "title": "Multi-Trigger Poisoning Amplifies Backdoor Vulnerabilities in LLMs", "comment": null, "summary": "Recent studies have shown that Large Language Models (LLMs) are vulnerable to\ndata poisoning attacks, where malicious training examples embed hidden\nbehaviours triggered by specific input patterns. However, most existing works\nassume a phrase and focus on the attack's effectiveness, offering limited\nunderstanding of trigger mechanisms and how multiple triggers interact within\nthe model. In this paper, we present a framework for studying poisoning in\nLLMs. We show that multiple distinct backdoor triggers can coexist within a\nsingle model without interfering with each other, enabling adversaries to embed\nseveral triggers concurrently. Using multiple triggers with high embedding\nsimilarity, we demonstrate that poisoned triggers can achieve robust activation\neven when tokens are substituted or separated by long token spans. Our findings\nexpose a broader and more persistent vulnerability surface in LLMs. To mitigate\nthis threat, we propose a post hoc recovery method that selectively retrains\nspecific model components based on a layer-wise weight difference analysis. Our\nmethod effectively removes the trigger behaviour with minimal parameter\nupdates, presenting a practical and efficient defence against multi-trigger\npoisoning.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7814\u7a76LLM\u4e2d\u6bd2\u7684\u6846\u67b6\uff0c\u53d1\u73b0\u4e86\u591a\u89e6\u53d1\u5668\u5171\u5b58\u4e14\u9c81\u68d2\u6027\u5f3a\u7684\u6f0f\u6d1e\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u540e\u9a8c\u6062\u590d\u65b9\u6cd5\u6765\u9632\u5fa1\u6b64\u7c7b\u653b\u51fb\u3002", "motivation": "\u5927\u591a\u6570\u73b0\u6709\u4f5c\u54c1\u90fd\u96c6\u4e2d\u5728\u653b\u51fb\u7684\u6709\u6548\u6027\u4e0a\uff0c\u5bf9\u89e6\u53d1\u5668\u673a\u5236\u4ee5\u53ca\u591a\u4e2a\u89e6\u53d1\u5668\u5728\u6a21\u578b\u4e2d\u7684\u76f8\u4e92\u4f5c\u7528\u77e5\u4e4b\u751a\u5c11\u3002\u672c\u7814\u7a76\u65e8\u5728\u6df1\u5165\u4e86\u89e3LLM\u4e2d\u6bd2\u7684\u89e6\u53d1\u5668\u673a\u5236\u548c\u591a\u89e6\u53d1\u5668\u4ea4\u4e92\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7814\u7a76LLM\u4e2d\u6bd2\u7684\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u591a\u4e2a\u72ec\u7acb\u7684\u540e\u95e8\u89e6\u53d1\u5668\u53ef\u4ee5\u5171\u5b58\u5728\u5355\u4e2a\u6a21\u578b\u4e2d\u800c\u4e0d\u76f8\u4e92\u5e72\u6270\u3002\u6b64\u5916\uff0c\u8fd8\u5c55\u793a\u4e86\u5177\u6709\u9ad8\u5d4c\u5165\u76f8\u4f3c\u6027\u7684\u591a\u4e2a\u89e6\u53d1\u5668\u5373\u4f7f\u5728\u4ee4\u724c\u88ab\u66ff\u6362\u6216\u88ab\u957f\u4ee4\u724c\u8de8\u5ea6\u5206\u9694\u65f6\u4e5f\u80fd\u5b9e\u73b0\u9c81\u68d2\u6fc0\u6d3b\u3002\u6700\u540e\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u540e\u9a8c\u6062\u590d\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u57fa\u4e8e\u5c42\u7ea7\u6743\u91cd\u5dee\u5f02\u5206\u6790\u9009\u62e9\u6027\u5730\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u7ec4\u4ef6\u3002", "result": "\u591a\u4e2a\u72ec\u7acb\u7684\u540e\u95e8\u89e6\u53d1\u5668\u53ef\u4ee5\u5171\u5b58\u5728\u5355\u4e2a\u6a21\u578b\u4e2d\u800c\u4e0d\u76f8\u4e92\u5e72\u6270\u3002\u5177\u6709\u9ad8\u5d4c\u5165\u76f8\u4f3c\u6027\u7684\u591a\u4e2a\u89e6\u53d1\u5668\u5373\u4f7f\u5728\u4ee4\u724c\u88ab\u66ff\u6362\u6216\u88ab\u957f\u4ee4\u724c\u8de8\u5ea6\u5206\u9694\u65f6\u4e5f\u80fd\u5b9e\u73b0\u9c81\u68d2\u6fc0\u6d3b\u3002\u6240\u63d0\u51fa\u7684\u6062\u590d\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u53bb\u9664\u89e6\u53d1\u5668\u884c\u4e3a\uff0c\u5e76\u4e14\u53c2\u6570\u66f4\u65b0\u6700\u5c11\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540e\u9a8c\u6062\u590d\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u57fa\u4e8e\u5c42\u7ea7\u6743\u91cd\u5dee\u5f02\u5206\u6790\u9009\u62e9\u6027\u5730\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u7ec4\u4ef6\uff0c\u53ef\u4ee5\u6709\u6548\u53bb\u9664\u89e6\u53d1\u5668\u884c\u4e3a\uff0c\u5e76\u4e14\u53c2\u6570\u66f4\u65b0\u6700\u5c11\uff0c\u4e3a\u591a\u89e6\u53d1\u5668\u4e2d\u6bd2\u63d0\u4f9b\u4e86\u5b9e\u9645\u4e14\u6709\u6548\u7684\u9632\u5fa1\u3002"}}
{"id": "2507.11296", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.11296", "abs": "https://arxiv.org/abs/2507.11296", "authors": ["Huilin Xu", "Jian Ding", "Jiakun Xu", "Ruixiang Wang", "Jun Chen", "Jinjie Mai", "Yanwei Fu", "Bernard Ghanem", "Feng Xu", "Mohamed Elhoseiny"], "title": "Diffusion-Based Imaginative Coordination for Bimanual Manipulation", "comment": "15 pages, including 10 figures and 16 tables. Accepted at ICCV 2025", "summary": "Bimanual manipulation is crucial in robotics, enabling complex tasks in\nindustrial automation and household services. However, it poses significant\nchallenges due to the high-dimensional action space and intricate coordination\nrequirements. While video prediction has been recently studied for\nrepresentation learning and control, leveraging its ability to capture rich\ndynamic and behavioral information, its potential for enhancing bimanual\ncoordination remains underexplored. To bridge this gap, we propose a unified\ndiffusion-based framework for the joint optimization of video and action\nprediction. Specifically, we propose a multi-frame latent prediction strategy\nthat encodes future states in a compressed latent space, preserving\ntask-relevant features. Furthermore, we introduce a unidirectional attention\nmechanism where video prediction is conditioned on the action, while action\nprediction remains independent of video prediction. This design allows us to\nomit video prediction during inference, significantly enhancing efficiency.\nExperiments on two simulated benchmarks and a real-world setting demonstrate a\nsignificant improvement in the success rate over the strong baseline ACT using\nour method, achieving a \\textbf{24.9\\%} increase on ALOHA, an \\textbf{11.1\\%}\nincrease on RoboTwin, and a \\textbf{32.5\\%} increase in real-world experiments.\nOur models and code are publicly available at\nhttps://github.com/return-sleep/Diffusion_based_imaginative_Coordination.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u89c6\u9891\u548c\u52a8\u4f5c\u9884\u6d4b\u6765\u63d0\u5347\u673a\u5668\u4eba\u53cc\u81c2\u534f\u8c03\u80fd\u529b\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u591a\u5e27\u6f5c\u5728\u9884\u6d4b\u548c\u5355\u5411\u6ce8\u610f\u673a\u5236\uff0c\u5728ALOHA\u3001RoboTwin\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u4e2d\u5747\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6210\u529f\u7387\u63d0\u5347\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u673a\u5668\u4eba\u53cc\u81c2\u64cd\u4f5c\u4e2d\u9ad8\u7ef4\u52a8\u4f5c\u7a7a\u95f4\u548c\u590d\u6742\u534f\u8c03\u7684\u6311\u6218\uff0c\u5e76\u63a2\u7d22\u89c6\u9891\u9884\u6d4b\u5728\u589e\u5f3a\u53cc\u81c2\u534f\u8c03\u65b9\u9762\u7684\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u57fa\u4e8e\u6269\u6563\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8054\u5408\u4f18\u5316\u89c6\u9891\u548c\u52a8\u4f5c\u9884\u6d4b\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u91c7\u7528\u591a\u5e27\u6f5c\u5728\u9884\u6d4b\u7b56\u7565\u5c06\u672a\u6765\u72b6\u6001\u7f16\u7801\u5230\u6f5c\u5728\u7a7a\u95f4\u4e2d\uff0c\u5e76\u5f15\u5165\u5355\u5411\u6ce8\u610f\u673a\u5236\uff0c\u4f7f\u89c6\u9891\u9884\u6d4b\u4f9d\u8d56\u4e8e\u52a8\u4f5c\uff0c\u800c\u52a8\u4f5c\u9884\u6d4b\u72ec\u7acb\u4e8e\u89c6\u9891\u9884\u6d4b\uff0c\u4ece\u800c\u5728\u63a8\u7406\u65f6\u53ef\u4ee5\u7701\u7565\u89c6\u9891\u9884\u6d4b\u4ee5\u63d0\u9ad8\u6548\u7387\u3002", "result": "\u5728ALOHA\u3001RoboTwin\u4e24\u4e2a\u6a21\u62df\u57fa\u51c6\u548c\u771f\u5b9e\u4e16\u754c\u8bbe\u7f6e\u4e0a\u8fdb\u884c\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u6210\u529f\u7387\uff0c\u5206\u522b\u6bd4\u5f3a\u57fa\u7ebfACT\u63d0\u9ad8\u4e8624.9%\u300111.1%\u548c32.5%\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u57fa\u4e8e\u6269\u6563\u7684\u65b9\u6cd5\u6765\u8054\u5408\u4f18\u5316\u89c6\u9891\u548c\u52a8\u4f5c\u9884\u6d4b\uff0c\u4ee5\u63d0\u9ad8\u53cc\u81c2\u534f\u8c03\u80fd\u529b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u57fa\u7ebfACT\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728ALOHA\u3001RoboTwin\u548c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u4e2d\u5206\u522b\u53d6\u5f97\u4e8624.9%\u300111.1%\u548c32.5%\u7684\u6210\u529f\u7387\u63d0\u5347\u3002"}}
{"id": "2507.10992", "categories": ["quant-ph", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.10992", "abs": "https://arxiv.org/abs/2507.10992", "authors": ["Kwassi Joseph Dzahini", "Jeffrey M. Larson", "Matt Menickelly", "Stefan M. Wild"], "title": "A Noise-Aware Scalable Subspace Classical Optimizer for the Quantum Approximate Optimization Algorithm", "comment": null, "summary": "We introduce ANASTAARS, a noise-aware scalable classical optimizer for\nvariational quantum algorithms such as the quantum approximate optimization\nalgorithm (QAOA). ANASTAARS leverages adaptive random subspace strategies to\nefficiently optimize the ansatz parameters of a QAOA circuit, in an effort to\naddress challenges posed by a potentially large number of QAOA layers.\nANASTAARS iteratively constructs random interpolation models within\nlow-dimensional affine subspaces defined via Johnson--Lindenstrauss transforms.\nThis adaptive strategy allows the selective reuse of previously acquired\nmeasurements, significantly reducing computational costs associated with shot\nacquisition. Furthermore, to robustly handle noisy measurements, ANASTAARS\nincorporates noise-aware optimization techniques by estimating noise magnitude\nand adjusts trust-region steps accordingly. Numerical experiments demonstrate\nthe practical scalability of the proposed method for near-term quantum\ncomputing applications.", "AI": {"tldr": "ANASTAARS\u662f\u4e00\u79cd\u65b0\u9896\u7684\u3001\u53ef\u6269\u5c55\u7684\u3001\u566a\u58f0\u611f\u77e5\u7684\u7ecf\u5178\u4f18\u5316\u5668\uff0c\u4e13\u95e8\u7528\u4e8eQAOA\u7b49\u53d8\u5206\u91cf\u5b50\u7b97\u6cd5\u3002\u5b83\u901a\u8fc7\u81ea\u9002\u5e94\u968f\u673a\u5b50\u7a7a\u95f4\u7b56\u7565\u548c\u566a\u58f0\u611f\u77e5\u6280\u672f\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u5e76\u63d0\u9ad8\u4e86\u9c81\u68d2\u6027\uff0c\u5728\u8fd1\u671f\u91cf\u5b50\u8ba1\u7b97\u5e94\u7528\u4e2d\u5c55\u73b0\u51fa\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u91cf\u5b50\u8fd1\u4f3c\u4f18\u5316\u7b97\u6cd5\uff08QAOA\uff09\u4e2d\u6f5c\u5728\u7684\u5927\u91cfQAOA\u5c42\u5e26\u6765\u7684\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u566a\u58f0\u611f\u77e5\u4e14\u53ef\u6269\u5c55\u7684\u7ecf\u5178\u4f18\u5316\u5668\u3002", "method": "ANASTAARS\u5229\u7528\u81ea\u9002\u5e94\u968f\u673a\u5b50\u7a7a\u95f4\u7b56\u7565\u6765\u4f18\u5316QAOA\u7535\u8def\u7684ansatz\u53c2\u6570\uff0c\u901a\u8fc7Johnson-Lindenstrauss\u53d8\u6362\u5728\u4f4e\u7ef4\u4eff\u5c04\u5b50\u7a7a\u95f4\u5185\u6784\u5efa\u968f\u673a\u63d2\u503c\u6a21\u578b\uff0c\u5e76\u7ed3\u5408\u566a\u58f0\u611f\u77e5\u4f18\u5316\u6280\u672f\u6765\u4f30\u8ba1\u566a\u58f0\u5e45\u5ea6\u548c\u8c03\u6574\u4fe1\u4efb\u533a\u57df\u6b65\u957f\u3002", "result": "ANASTAARS\u80fd\u591f\u9009\u62e9\u6027\u5730\u91cd\u7528\u5148\u524d\u83b7\u5f97\u7684\u6d4b\u91cf\u7ed3\u679c\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u4e0e\u6d4b\u91cf\u83b7\u53d6\u76f8\u5173\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u5e76\u4e14\u80fd\u591f\u6709\u6548\u5730\u5904\u7406\u566a\u58f0\u6d4b\u91cf\u3002", "conclusion": "ANASTAARS\u5728\u6570\u503c\u5b9e\u9a8c\u4e2d\u8bc1\u660e\u4e86\u5176\u5728\u8fd1\u671f\u91cf\u5b50\u8ba1\u7b97\u5e94\u7528\u4e2d\u7684\u5b9e\u9645\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2507.11037", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11037", "abs": "https://arxiv.org/abs/2507.11037", "authors": ["Jie-Wen Li", "Zi-Han Ye", "Qingyuan Zhou", "Jiayi Song", "Ying He", "Ben Fei", "Wen-Ming Chen"], "title": "A Multi-View High-Resolution Foot-Ankle Complex Point Cloud Dataset During Gait for Occlusion-Robust 3D Completion", "comment": "15 pages, 10 figures, 2 tables", "summary": "The kinematics analysis of foot-ankle complex during gait is essential for\nadvancing biomechanical research and clinical assessment. Collecting accurate\nsurface geometry data from the foot and ankle during dynamic gait conditions is\ninherently challenging due to swing foot occlusions and viewing limitations.\nThus, this paper introduces FootGait3D, a novel multi-view dataset of\nhigh-resolution ankle-foot surface point clouds captured during natural gait.\nDifferent from existing gait datasets that typically target whole-body or\nlower-limb motion, FootGait3D focuses specifically on the detailed modeling of\nthe ankle-foot region, offering a finer granularity of motion data. To address\nthis, FootGait3D consists of 8,403 point cloud frames collected from 46\nsubjects using a custom five-camera depth sensing system. Each frame includes a\ncomplete 5-view reconstruction of the foot and ankle (serving as ground truth)\nalong with partial point clouds obtained from only four, three, or two views.\nThis structured variation enables rigorous evaluation of 3D point cloud\ncompletion methods under varying occlusion levels and viewpoints. Our dataset\nis designed for shape completion tasks, facilitating the benchmarking of\nstate-of-the-art single-modal (e.g., PointTr, SnowflakeNet, Anchorformer) and\nmulti-modal (e.g., SVDFormer, PointSea, CSDN) completion networks on the\nchallenge of recovering the full foot geometry from occluded inputs. FootGait3D\nhas significant potential to advance research in biomechanics and multi-segment\nfoot modeling, offering a valuable testbed for clinical gait analysis,\nprosthetic design, and robotics applications requiring detailed 3D models of\nthe foot during motion. The dataset is now available at\nhttps://huggingface.co/datasets/ljw285/FootGait3D.", "AI": {"tldr": "FootGait3D\u662f\u4e00\u4e2a\u5305\u542b8403\u4e2a\u70b9\u4e91\u5e27\u7684\u65b0\u578b\u811a\u8e1d\u8fd0\u52a8\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f303D\u70b9\u4e91\u8865\u5168\u65b9\u6cd5\uff0c\u4ee5\u5e94\u5bf9\u6b65\u6001\u5206\u6790\u4e2d\u7684\u906e\u6321\u95ee\u9898\uff0c\u4fc3\u8fdb\u751f\u7269\u529b\u5b66\u548c\u4e34\u5e8a\u5e94\u7528\u7814\u7a76\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5728\u52a8\u6001\u6b65\u6001\u6761\u4ef6\u4e0b\u6536\u96c6\u811a\u8e1d\u533a\u57df\u7cbe\u786e\u8868\u9762\u51e0\u4f55\u6570\u636e\u6240\u9762\u4e34\u7684\u906e\u6321\u548c\u89c6\u89d2\u9650\u5236\u7684\u6311\u6218\uff0c\u5e76\u4e3a\u811a\u8e1d\u533a\u57df\u7684\u8be6\u7ec6\u5efa\u6a21\u63d0\u4f9b\u66f4\u9ad8\u7684\u6570\u636e\u7c92\u5ea6\u3002", "method": "\u4f7f\u7528\u5b9a\u5236\u7684\u4e94\u6444\u50cf\u5934\u6df1\u5ea6\u4f20\u611f\u7cfb\u7edf\uff0c\u4ece46\u540d\u53d7\u8bd5\u8005\u5728\u81ea\u7136\u6b65\u6001\u4e0b\u6536\u96c6\u4e86\u9ad8\u5206\u8fa8\u7387\u811a\u8e1d\u70b9\u4e91\u6570\u636e\uff0c\u6bcf\u4e2a\u5e27\u5305\u542b\u5b8c\u6574\u76845\u89c6\u56fe\u91cd\u5efa\u548c\u90e8\u5206\u70b9\u4e91\uff0c\u4ee5\u6a21\u62df\u4e0d\u540c\u7a0b\u5ea6\u7684\u906e\u6321\u548c\u89c6\u89d2\u53d8\u5316\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b8403\u4e2a\u70b9\u4e91\u5e27\u7684\u6570\u636e\u96c6\uff08FootGait3D\uff09\uff0c\u80fd\u591f\u7528\u4e8e\u8bc4\u4f303D\u70b9\u4e91\u8865\u5168\u65b9\u6cd5\u5728\u4e0d\u540c\u906e\u6321\u7a0b\u5ea6\u4e0b\u7684\u8868\u73b0\uff0c\u5e76\u4e3a\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002", "conclusion": "FootGait3D\u662f\u4e00\u4e2a\u5305\u542b8403\u4e2a\u70b9\u4e91\u5e27\u7684\u65b0\u578b\u591a\u89c6\u56fe\u6570\u636e\u96c6\uff0c\u4e13\u95e8\u7528\u4e8e\u811a\u8e1d\u533a\u57df\u7684\u7cbe\u7ec6\u8fd0\u52a8\u6570\u636e\u5efa\u6a21\uff0c\u53ef\u4ee5\u4fc3\u8fdb\u751f\u7269\u529b\u5b66\u3001\u4e34\u5e8a\u6b65\u6001\u5206\u6790\u3001\u5047\u80a2\u8bbe\u8ba1\u548c\u673a\u5668\u4eba\u6280\u672f\u7b49\u9886\u57df\u7684\u7814\u7a76\u3002"}}
{"id": "2507.11288", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11288", "abs": "https://arxiv.org/abs/2507.11288", "authors": ["Th\u00e9o Fagnoni", "Mahsun Altin", "Chia En Chung", "Phillip Kingston", "Alan Tuning", "Dana O. Mohamed", "In\u00e8s Adnani"], "title": "Opus: A Prompt Intention Framework for Complex Workflow Generation", "comment": "39 pages, 24 figures", "summary": "This paper introduces the Opus Prompt Intention Framework, designed to\nimprove complex Workflow Generation with instruction-tuned Large Language\nModels (LLMs). We propose an intermediate Intention Capture layer between user\nqueries and Workflow Generation, implementing the Opus Workflow Intention\nFramework, which consists of extracting Workflow Signals from user queries,\ninterpreting them into structured Workflow Intention objects, and generating\nWorkflows based on these Intentions. Our results show that this layer enables\nLLMs to produce logical and meaningful outputs that scale reliably as query\ncomplexity increases. On a synthetic benchmark of 1,000 multi-intent\nquery-Workflow(s) pairs, applying the Opus Prompt Intention Framework to\nWorkflow Generation yields consistent improvements in semantic Workflow\nsimilarity metrics. In this paper, we introduce the Opus Prompt Intention\nFramework by applying the concepts of Workflow Signal and Workflow Intention to\nLLM-driven Workflow Generation. We present a reproducible, customizable\nLLM-based Intention Capture system to extract Workflow Signals and Workflow\nIntentions from user queries. Finally, we provide empirical evidence that the\nproposed system significantly improves Workflow Generation quality compared to\ndirect generation from user queries, particularly in cases of Mixed Intention\nElicitation.", "AI": {"tldr": "Opus Prompt Intention Framework\u901a\u8fc7\u589e\u52a0\u4e00\u4e2a\u610f\u56fe\u6355\u83b7\u5c42\u6765\u6539\u8fdbLLM\u7684\u5de5\u4f5c\u6d41\u751f\u6210\uff0c\u63d0\u9ad8\u4e86\u8f93\u51fa\u7684\u903b\u8f91\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u5728\u6df7\u5408\u610f\u56fe\u5f15\u5bfc\u65b9\u9762\u8868\u73b0\u5c24\u4e3a\u51fa\u8272\u3002", "motivation": "\u65e8\u5728\u63d0\u9ad8\u6307\u4ee4\u8c03\u4f18\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u590d\u6742\u5de5\u4f5c\u6d41\u751f\u6210\u65b9\u9762\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faOpus Prompt Intention Framework\uff0c\u5305\u542b\u63d0\u53d6\u5de5\u4f5c\u6d41\u4fe1\u53f7\u3001\u89e3\u91ca\u4e3a\u7ed3\u6784\u5316\u5de5\u4f5c\u6d41\u610f\u56fe\u5bf9\u8c61\u4ee5\u53ca\u57fa\u4e8e\u610f\u56fe\u751f\u6210\u5de5\u4f5c\u6d41\u7684\u4e2d\u95f4\u610f\u56fe\u6355\u83b7\u5c42\u3002", "result": "\u5728\u5305\u542b1000\u4e2a\u591a\u610f\u56fe\u67e5\u8be2-\u5de5\u4f5c\u6d41\u5bf9\u7684\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4e0e\u76f4\u63a5\u751f\u6210\u76f8\u6bd4\uff0c\u8be5\u6846\u67b6\u5728\u8bed\u4e49\u5de5\u4f5c\u6d41\u76f8\u4f3c\u6027\u6307\u6807\u4e0a\u5b9e\u73b0\u4e86\u6301\u7eed\u6539\u8fdb\uff0c\u5c24\u5176\u662f\u5728\u6df7\u5408\u610f\u56fe\u5f15\u5bfc\u7684\u60c5\u51b5\u4e0b\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u5f15\u5165\u4e2d\u95f4\u610f\u56fe\u6355\u83b7\u5c42\uff0c\u663e\u8457\u63d0\u9ad8\u4e86LLM\u5728\u590d\u6742\u5de5\u4f5c\u6d41\u751f\u6210\u65b9\u9762\u7684\u8d28\u91cf\uff0c\u5c24\u5176\u662f\u5728\u6df7\u5408\u610f\u56fe\u5f15\u5bfc\u65b9\u9762\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u3001\u53ef\u5b9a\u5236\u7684\u7cfb\u7edf\u3002"}}
{"id": "2507.11114", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.11114", "abs": "https://arxiv.org/abs/2507.11114", "authors": ["Seif Ahmed", "Mohamed T. Younes", "Abdelrahman Moustafa", "Abdelrahman Allam", "Hamza Moustafa"], "title": "MSA at ImageCLEF 2025 Multimodal Reasoning: Multilingual Multimodal Reasoning With Ensemble Vision Language Models", "comment": null, "summary": "We present a robust ensemble-based system for multilingual multimodal\nreasoning, designed for the ImageCLEF 2025 EXAMS V challenge. Our approach\nintegrates Gemini 2.5 Flash for visual description, Gemini 1.5 Pro for caption\nrefinement and consistency checks, and Gemini 2.5 Pro as a reasoner which\nhandles final answer selection, all coordinated through carefully engineered\nfew-shot and zero-shot prompts. We conducted an extensive ablation study,\ntraining several large language models (Gemini 2.5 Flash, Phi 4, Gemma 3,\nMistral) on an English dataset and its multilingual augmented version.\nAdditionally, we evaluated Gemini 2.5 Flash in a zero-shot setting for\ncomparison and found it to substantially outperform the trained models. Prompt\ndesign also proved critical: enforcing concise, language-normalized formats and\nprohibiting explanatory text boosted model accuracy on the English validation\nset from 55.9% to 61.7%. On the official leaderboard, our system (Team MSA)\nachieved first place overall in the multilingual track with 81.4% accuracy, and\nled 11 out of 13 individual language tracks, with top results such as 95.07%\nfor Croatian and 92.12% for Italian. These findings highlight that lightweight\nOCR-VLM ensembles, when paired with precise prompt strategies and cross-lingual\naugmentation, can outperform heavier end-to-end models in high-stakes,\nmultilingual educational settings.", "AI": {"tldr": "\u901a\u8fc7\u96c6\u6210Gemini\u6a21\u578b\u5e76\u4f18\u5316\u63d0\u793a\u7b56\u7565\uff0c\u8be5\u7cfb\u7edf\u5728\u591a\u8bed\u8a00\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u6210\u7ee9\u3002", "motivation": "\u4e3aImageCLEF 2025 EXAMS V\u6311\u6218\u8d5b\u63d0\u4f9b\u4e00\u4e2a\u591a\u8bed\u8a00\u591a\u6a21\u6001\u63a8\u7406\u7cfb\u7edf\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eGemini\u6a21\u578b\u7684\u9c81\u68d2\u7684\u3001\u591a\u8bed\u8a00\u7684\u3001\u591a\u6a21\u6001\u7684\u63a8\u7406\u7cfb\u7edf\uff0c\u5e76\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u6d88\u878d\u7814\u7a76\uff0c\u5305\u62ec\u5bf9\u4e0d\u540c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08Gemini 2.5 Flash\u3001Phi 4\u3001Gemma 3\u3001Mistral\uff09\u8fdb\u884c\u8bad\u7ec3\u548c\u96f6\u6837\u672c\u8bc4\u4f30\uff0c\u5e76\u91cd\u70b9\u7814\u7a76\u4e86\u63d0\u793a\u8bbe\u8ba1\u7b56\u7565\u3002", "result": "\u8be5\u7cfb\u7edf\u5728\u591a\u8bed\u8a00\u8d5b\u9053\u4e0a\u603b\u4f53\u51c6\u786e\u7387\u8fbe\u523081.4%\uff0c\u572813\u4e2a\u5355\u8bed\u8a00\u8d5b\u9053\u4e2d\u768411\u4e2a\u8d5b\u9053\u4e2d\u4e5f\u540d\u5217\u524d\u8305\uff0c\u5728\u514b\u7f57\u5730\u4e9a\u8bed\u548c\u610f\u5927\u5229\u8bed\u4e0a\u7684\u51c6\u786e\u7387\u5206\u522b\u8fbe\u523095.07%\u548c92.12%\u3002", "conclusion": "\u8f7b\u91cf\u7ea7\u7684OCR-VLM\u96c6\u6210\uff0c\u7ed3\u5408\u7cbe\u786e\u7684\u63d0\u793a\u7b56\u7565\u548c\u8de8\u8bed\u8a00\u589e\u5f3a\uff0c\u5728\u6709\u5229\u5bb3\u5173\u7cfb\u7684\u3001\u591a\u8bed\u8a00\u7684\u6559\u80b2\u73af\u5883\u4e2d\uff0c\u53ef\u4ee5\u4f18\u4e8e\u66f4\u91cd\u7684\u7aef\u5230\u7aef\u6a21\u578b\u3002"}}
{"id": "2507.10714", "categories": ["cs.LG", "q-bio.QM", "stat.ML", "68, 92", "I.6; I.2.6"], "pdf": "https://arxiv.org/pdf/2507.10714", "abs": "https://arxiv.org/abs/2507.10714", "authors": ["Bright Kwaku Manu", "Trevor Reckell", "Beckett Sterner", "Petar Jevtic"], "title": "A Simple Approximate Bayesian Inference Neural Surrogate for Stochastic Petri Net Models", "comment": "12 pages, 10 figures, for all associated codes and files, see\n  https://github.com/BrightManu-lang/SPN-param-recovery.git", "summary": "Stochastic Petri Nets (SPNs) are an increasingly popular tool of choice for\nmodeling discrete-event dynamics in areas such as epidemiology and systems\nbiology, yet their parameter estimation remains challenging in general and in\nparticular when transition rates depend on external covariates and explicit\nlikelihoods are unavailable. We introduce a neural-surrogate\n(neural-network--based approximation of the posterior distribution) framework\nthat predicts the coefficients of known covariate-dependent rate functions\ndirectly from noisy, partially observed token trajectories. Our model employs a\nlightweight 1D Convolutional Residual Network trained end-to-end on\nGillespie-simulated SPN realizations, learning to invert system dynamics under\nrealistic conditions of event dropout. During inference, Monte Carlo dropout\nprovides calibrated uncertainty bounds together with point estimates. On\nsynthetic SPNs with 20% missing events, our surrogate recovers rate-function\ncoefficients with an RMSE = 0.108 and substantially runs faster than\ntraditional Bayesian approaches. These results demonstrate that data-driven,\nlikelihood-free surrogates can enable accurate, robust, and real-time parameter\nrecovery in complex, partially observed discrete-event systems.", "AI": {"tldr": "A neural network surrogate model is proposed for parameter estimation in Stochastic Petri Nets with covariate-dependent rates and partial observations, achieving accurate and fast results with uncertainty quantification.", "motivation": "Parameter estimation for Stochastic Petri Nets (SPNs) is challenging, especially when transition rates depend on external covariates and explicit likelihoods are unavailable.", "method": "We introduce a neural-surrogate framework that predicts the coefficients of known covariate-dependent rate functions directly from noisy, partially observed token trajectories using a lightweight 1D Convolutional Residual Network trained end-to-end on Gillespie-simulated SPN realizations. Monte Carlo dropout is used during inference for uncertainty quantification.", "result": "Our surrogate recovers rate-function coefficients with an RMSE = 0.108 on synthetic SPNs with 20% missing events, and is substantially faster than traditional Bayesian approaches.", "conclusion": "We demonstrate that data-driven, likelihood-free surrogates can enable accurate, robust, and real-time parameter recovery in complex, partially observed discrete-event systems."}}
{"id": "2507.11302", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11302", "abs": "https://arxiv.org/abs/2507.11302", "authors": ["Jesse J. Hagenaars", "Stein Stroobants", "Sander M. Bohte", "Guido C. H. E. De Croon"], "title": "All Eyes, no IMU: Learning Flight Attitude from Vision Alone", "comment": null, "summary": "Vision is an essential part of attitude control for many flying animals, some\nof which have no dedicated sense of gravity. Flying robots, on the other hand,\ntypically depend heavily on accelerometers and gyroscopes for attitude\nstabilization. In this work, we present the first vision-only approach to\nflight control for use in generic environments. We show that a quadrotor drone\nequipped with a downward-facing event camera can estimate its attitude and\nrotation rate from just the event stream, enabling flight control without\ninertial sensors. Our approach uses a small recurrent convolutional neural\nnetwork trained through supervised learning. Real-world flight tests\ndemonstrate that our combination of event camera and low-latency neural network\nis capable of replacing the inertial measurement unit in a traditional flight\ncontrol loop. Furthermore, we investigate the network's generalization across\ndifferent environments, and the impact of memory and different fields of view.\nWhile networks with memory and access to horizon-like visual cues achieve best\nperformance, variants with a narrower field of view achieve better relative\ngeneralization. Our work showcases vision-only flight control as a promising\ncandidate for enabling autonomous, insect-scale flying robots.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u4ec5\u4f7f\u7528\u4e8b\u4ef6\u76f8\u673a\u8fdb\u884c\u89c6\u89c9\u98de\u884c\u63a7\u5236\u7684\u65b9\u6cd5\uff0c\u65e0\u9700\u60ef\u6027\u4f20\u611f\u5668\uff0c\u53ef\u7528\u4e8e\u98de\u884c\u673a\u5668\u4eba\u3002", "motivation": "\u8bb8\u591a\u98de\u884c\u52a8\u7269\u4f9d\u9760\u89c6\u89c9\u8fdb\u884c\u59ff\u6001\u63a7\u5236\uff0c\u800c\u5b83\u4eec\u53ef\u80fd\u6ca1\u6709\u4e13\u95e8\u7684\u91cd\u529b\u611f\u5e94\u3002\u4e0e\u6b64\u76f8\u53cd\uff0c\u98de\u884c\u673a\u5668\u4eba\u901a\u5e38\u4e25\u91cd\u4f9d\u8d56\u52a0\u901f\u5ea6\u8ba1\u548c\u9640\u87ba\u4eea\u8fdb\u884c\u59ff\u6001\u7a33\u5b9a\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4e00\u79cd\u4ec5\u4f9d\u9760\u89c6\u89c9\u8fdb\u884c\u98de\u884c\u63a7\u5236\u7684\u65b9\u6cd5\uff0c\u4ee5\u5e94\u5bf9\u901a\u7528\u73af\u5883\u3002", "method": "\u8be5\u65b9\u6cd5\u4f7f\u7528\u4e86\u4e00\u4e2a\u5c0f\u578b\u5faa\u73af\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u901a\u8fc7\u76d1\u7763\u5b66\u4e60\u8fdb\u884c\u8bad\u7ec3\uff0c\u5b9e\u73b0\u4e86\u4ec5\u4f9d\u8d56\u4e8b\u4ef6\u76f8\u673a\u6570\u636e\u6765\u4f30\u8ba1\u59ff\u6001\u548c\u65cb\u8f6c\u901f\u7387\uff0c\u4ece\u800c\u65e0\u9700\u60ef\u6027\u4f20\u611f\u5668\u5373\u53ef\u8fdb\u884c\u98de\u884c\u63a7\u5236\u3002", "result": "\u73b0\u5b9e\u4e16\u754c\u7684\u98de\u884c\u6d4b\u8bd5\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u4e8b\u4ef6\u76f8\u673a\u548c\u4f4e\u5ef6\u8fdf\u795e\u7ecf\u7f51\u7edc\uff0c\u80fd\u591f\u53d6\u4ee3\u4f20\u7edf\u98de\u884c\u63a7\u5236\u56de\u8def\u4e2d\u7684\u60ef\u6027\u6d4b\u91cf\u5355\u5143\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u63a2\u8ba8\u4e86\u7f51\u7edc\u5728\u4e0d\u540c\u73af\u5883\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4ee5\u53ca\u8bb0\u5fc6\u548c\u4e0d\u540c\u89c6\u91ce\u7684\u5f71\u54cd\uff0c\u5176\u4e2d\u5177\u6709\u8bb0\u5fc6\u548c\u7c7b\u4f3c\u5730\u5e73\u7ebf\u89c6\u89c9\u7ebf\u7d22\u7684\u7f51\u7edc\u6027\u80fd\u6700\u4f73\uff0c\u800c\u5177\u6709\u8f83\u7a84\u89c6\u91ce\u7684\u53d8\u4f53\u5219\u5177\u6709\u66f4\u597d\u7684\u76f8\u5bf9\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u672c\u6587\u5c55\u793a\u4e86\u4ec5\u901a\u8fc7\u89c6\u89c9\u8fdb\u884c\u98de\u884c\u63a7\u5236\uff0c\u53ef\u4f5c\u4e3a\u5b9e\u73b0\u81ea\u4e3b\u3001\u6606\u866b\u5c3a\u5ea6\u98de\u884c\u673a\u5668\u4eba\u7684\u6709\u524d\u666f\u7684\u5019\u9009\u65b9\u6848\u3002"}}
{"id": "2507.11002", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.11002", "abs": "https://arxiv.org/abs/2507.11002", "authors": ["Minwoo Kim", "Kyoung Keun Park", "Uihwan Jeong", "Sanghyeon Lee", "Taehyun Kim"], "title": "A scalable quantum-neural hybrid variational algorithm for ground state estimation", "comment": "13 pages, 4 figures", "summary": "We propose the unitary variational quantum-neural hybrid eigensolver\n(U-VQNHE), which improves upon the original VQNHE by enforcing unitary neural\ntransformations. The non-unitary nature of VQNHE causes normalization issues\nand divergence of the loss function during training, leading to exponential\nscaling of measurement overhead with qubit number. U-VQNHE resolves these\nissues, significantly reduces required measurements, and retains improved\naccuracy and stability over standard variational quantum eigensolvers.", "AI": {"tldr": "U-VQNHE \u901a\u8fc7\u9149\u53d8\u6362\u89e3\u51b3\u4e86 VQNHE \u7684\u8bad\u7ec3\u95ee\u9898\uff0c\u51cf\u5c11\u4e86\u6d4b\u91cf\u5f00\u9500\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3 VQNHE \u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u7684\u8303\u6570\u95ee\u9898\u548c\u635f\u5931\u51fd\u6570\u53d1\u6563\u95ee\u9898\uff0c\u4ee5\u53ca\u968f\u91cf\u5b50\u6bd4\u7279\u6570\u589e\u52a0\u800c\u51fa\u73b0\u7684\u6307\u6570\u7ea7\u6d4b\u91cf\u5f00\u9500\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9149\u53d8\u5206\u91cf\u5b50-\u795e\u7ecf\u6df7\u5408\u672c\u5f81\u6c42\u89e3\u5668 (U-VQNHE)\uff0c\u5b83\u901a\u8fc7\u5f3a\u5236\u6267\u884c\u9149\u795e\u7ecf\u53d8\u6362\u6765\u6539\u8fdb\u539f\u59cb VQNHE\u3002", "result": "U-VQNHE \u89e3\u51b3\u4e86\u8fd9\u4e9b\u95ee\u9898\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u6240\u9700\u7684\u6d4b\u91cf\u6b21\u6570\uff0c\u5e76\u4fdd\u6301\u4e86\u6bd4\u6807\u51c6\u53d8\u5206\u91cf\u5b50\u672c\u5f81\u6c42\u89e3\u5668\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\u3002", "conclusion": "U-VQNHE \u901a\u8fc7\u5f3a\u5236\u6267\u884c\u9149\u53d8\u6362\u89e3\u51b3\u4e86 VQNHE \u7684\u8303\u6570\u95ee\u9898\u548c\u635f\u5931\u51fd\u6570\u53d1\u6563\u95ee\u9898\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u6d4b\u91cf\u5f00\u9500\uff0c\u5e76\u4fdd\u6301\u4e86\u6bd4\u6807\u51c6 VQE \u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\u3002"}}
{"id": "2507.11040", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11040", "abs": "https://arxiv.org/abs/2507.11040", "authors": ["Nicolas Drapier", "Aladine Chetouani", "Aur\u00e9lien Chateigner"], "title": "Combining Transformers and CNNs for Efficient Object Detection in High-Resolution Satellite Imagery", "comment": "11 pages, 9 figures", "summary": "We present GLOD, a transformer-first architecture for object detection in\nhigh-resolution satellite imagery. GLOD replaces CNN backbones with a Swin\nTransformer for end-to-end feature extraction, combined with novel UpConvMixer\nblocks for robust upsampling and Fusion Blocks for multi-scale feature\nintegration. Our approach achieves 32.95\\% on xView, outperforming SOTA methods\nby 11.46\\%. Key innovations include asymmetric fusion with CBAM attention and a\nmulti-path head design capturing objects across scales. The architecture is\noptimized for satellite imagery challenges, leveraging spatial priors while\nmaintaining computational efficiency.", "AI": {"tldr": "GLOD, a transformer-first architecture with Swin Transformer, UpConvMixer, and Fusion Blocks, achieves state-of-the-art results in satellite imagery object detection on xView.", "motivation": "To address challenges in high-resolution satellite imagery object detection by developing a transformer-first architecture that improves feature extraction, upsampling, and multi-scale feature integration.", "method": "GLOD is a transformer-first architecture using a Swin Transformer as backbone, UpConvMixer blocks for upsampling, and Fusion Blocks for multi-scale feature integration. It features asymmetric fusion with CBAM attention and a multi-path head design.", "result": "Achieved 32.95% on xView, outperforming SOTA methods by 11.46%.", "conclusion": "GLOD in satellite imagery object detection achieved 32.95% on xView, outperforming SOTA methods by 11.46%. Key innovations include asymmetric fusion with CBAM attention and a multi-path head design capturing objects across scales."}}
{"id": "2507.11323", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11323", "abs": "https://arxiv.org/abs/2507.11323", "authors": ["Xiang Yin", "Nico Potyka", "Antonio Rago", "Timotheus Kampik", "Francesca Toni"], "title": "Contestability in Quantitative Argumentation", "comment": null, "summary": "Contestable AI requires that AI-driven decisions align with human\npreferences. While various forms of argumentation have been shown to support\ncontestability, Edge-Weighted Quantitative Bipolar Argumentation Frameworks\n(EW-QBAFs) have received little attention. In this work, we show how EW-QBAFs\ncan be deployed for this purpose. Specifically, we introduce the contestability\nproblem for EW-QBAFs, which asks how to modify edge weights (e.g., preferences)\nto achieve a desired strength for a specific argument of interest (i.e., a\ntopic argument). To address this problem, we propose gradient-based relation\nattribution explanations (G-RAEs), which quantify the sensitivity of the topic\nargument's strength to changes in individual edge weights, thus providing\ninterpretable guidance for weight adjustments towards contestability. Building\non G-RAEs, we develop an iterative algorithm that progressively adjusts the\nedge weights to attain the desired strength. We evaluate our approach\nexperimentally on synthetic EW-QBAFs that simulate the structural\ncharacteristics of personalised recommender systems and multi-layer\nperceptrons, and demonstrate that it can solve the problem effectively.", "AI": {"tldr": "EW-QBAFs\u53ef\u901a\u8fc7G-RAE\u548c\u8fed\u4ee3\u7b97\u6cd5\u5b9e\u73b0AI\u53ef\u8fa9\u8bba\u6027\uff0c\u901a\u8fc7\u8c03\u6574\u8fb9\u7f18\u6743\u91cd\u4f7fAI\u51b3\u7b56\u7b26\u5408\u4eba\u7c7b\u504f\u597d\u3002", "motivation": "AI\u53ef\u8fa9\u8bba\u6027\u8981\u6c42AI\u9a71\u52a8\u7684\u51b3\u7b56\u4e0e\u4eba\u7c7b\u504f\u597d\u4e00\u81f4\uff0c\u800cEW-QBAFs\u5728\u6b64\u65b9\u9762\u7684\u5e94\u7528\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u68af\u5ea6\u57fa\u4e8e\u5173\u7cfb\u5f52\u56e0\u89e3\u91ca\uff08G-RAEs\uff09\u6765\u91cf\u5316\u8fb9\u7f18\u6743\u91cd\u53d8\u5316\u5bf9\u76ee\u6807\u53c2\u6570\u5f3a\u5ea6\u7684\u654f\u611f\u6027\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u8fed\u4ee3\u7b97\u6cd5\u6765\u9010\u6b65\u8c03\u6574\u8fb9\u7f18\u6743\u91cd\u4ee5\u8fbe\u5230\u76ee\u6807\u5f3a\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u6a21\u62df\u63a8\u8350\u7cfb\u7edf\u548c\u591a\u5c42\u611f\u77e5\u673a\u7684EW-QBAFs\u4e0a\u80fd\u6709\u6548\u89e3\u51b3\u53ef\u8fa9\u8bba\u6027\u95ee\u9898\u3002", "conclusion": "EW-QBAFs\u53ef\u4ee5\u7528\u4e8eAI\u53ef\u8fa9\u8bba\u6027\uff0c\u901a\u8fc7G-RAE\u548c\u8fed\u4ee3\u7b97\u6cd5\u8c03\u6574\u8fb9\u7f18\u6743\u91cd\u4ee5\u8fbe\u5230\u76ee\u6807\u5f3a\u5ea6\uff0c\u5e76\u5728\u6a21\u62df\u63a8\u8350\u7cfb\u7edf\u548c\u591a\u5c42\u611f\u77e5\u673a\u7684EW-QBAFs\u4e0a\u6709\u6548\u89e3\u51b3\u4e86\u53ef\u8fa9\u8bba\u6027\u95ee\u9898\u3002"}}
{"id": "2507.11128", "categories": ["cs.CL", "cs.CY", "cs.LG", "I.2.6; H.2.8"], "pdf": "https://arxiv.org/pdf/2507.11128", "abs": "https://arxiv.org/abs/2507.11128", "authors": ["Dimitri Staufer"], "title": "What Should LLMs Forget? Quantifying Personal Data in LLMs for Right-to-Be-Forgotten Requests", "comment": "16 pages, 3 figures. Accepted at the 7th Workshop on eXplainable\n  Knowledge Discovery in Data Mining (XKDD 2025), ECML PKDD 2025, Porto,\n  Portugal", "summary": "Large Language Models (LLMs) can memorize and reveal personal information,\nraising concerns regarding compliance with the EU's GDPR, particularly the\nRight to Be Forgotten (RTBF). Existing machine unlearning methods assume the\ndata to forget is already known but do not address how to identify which\nindividual-fact associations are stored in the model. Privacy auditing\ntechniques typically operate at the population level or target a small set of\nidentifiers, limiting applicability to individual-level data inquiries. We\nintroduce WikiMem, a dataset of over 5,000 natural language canaries covering\n243 human-related properties from Wikidata, and a model-agnostic metric to\nquantify human-fact associations in LLMs. Our approach ranks ground-truth\nvalues against counterfactuals using calibrated negative log-likelihood across\nparaphrased prompts. We evaluate 200 individuals across 15 LLMs (410M-70B\nparameters), showing that memorization correlates with subject web presence and\nmodel scale. We provide a foundation for identifying memorized personal data in\nLLMs at the individual level, enabling the dynamic construction of forget sets\nfor machine unlearning and RTBF requests.", "AI": {"tldr": "LLMs\u53ef\u80fd\u6cc4\u9732\u4e2a\u4eba\u4fe1\u606f\uff0c\u4f46\u96be\u4ee5\u8bc6\u522b\u5177\u4f53\u4fe1\u606f\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86WikiMem\u6570\u636e\u96c6\u548c\u4e00\u79cd\u65b0\u6307\u6807\uff0c\u80fd\u5728\u4e2a\u4f53\u5c42\u9762\u8bc6\u522bLLM\u4e2d\u8bb0\u5fc6\u7684\u4e2a\u4eba\u4fe1\u606f\uff0c\u5e76\u5173\u8054\u5230\u6a21\u578b\u89c4\u6a21\u548c\u7f51\u7edc\u5b58\u5728\uff0c\u4e3a\u9057\u5fd8\u4e2a\u4eba\u6570\u636e\u63d0\u4f9b\u57fa\u7840\u3002", "motivation": "\u65e8\u5728\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u53ef\u80fd\u8bb0\u4f4f\u5e76\u6cc4\u9732\u4e2a\u4eba\u4fe1\u606f\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u9075\u5b88\u6b27\u76dfGDPR\u548c\u9057\u5fd8\u6743\uff08RTBF\uff09\u65b9\u9762\u3002\u73b0\u6709\u7684\u673a\u5668\u5b66\u4e60\u9057\u5fd8\u65b9\u6cd5\u5047\u8bbe\u9700\u8981\u9057\u5fd8\u7684\u6570\u636e\u662f\u5df2\u77e5\u7684\uff0c\u4f46\u672a\u80fd\u89e3\u51b3\u5982\u4f55\u8bc6\u522b\u6a21\u578b\u4e2d\u5b58\u50a8\u7684\u4e2a\u4f53\u4e8b\u5b9e\u5173\u8054\u7684\u95ee\u9898\u3002\u9690\u79c1\u5ba1\u8ba1\u6280\u672f\u901a\u5e38\u5728\u603b\u4f53\u5c42\u9762\u64cd\u4f5c\u6216\u9488\u5bf9\u5c11\u91cf\u6807\u8bc6\u7b26\uff0c\u9650\u5236\u4e86\u5176\u5728\u4e2a\u4f53\u5c42\u9762\u6570\u636e\u67e5\u8be2\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aWikiMem\u7684\u6570\u636e\u96c6\uff08\u5305\u542b\u8d85\u8fc75000\u4e2a\u81ea\u7136\u8bed\u8a00\u91d1\u4e1d\u96c0\uff0c\u6db5\u76d6Wikidata\u4e2d\u7684243\u4e2a\u4eba\u7c7b\u76f8\u5173\u5c5e\u6027\uff09\u548c\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u7684\u6307\u6807\uff0c\u7528\u4e8e\u91cf\u5316LLM\u4e2d\u4eba\u7c7b\u4e8b\u5b9e\u7684\u5173\u8054\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5bf9\u91ca\u4e49\u63d0\u793a\u7684\u6821\u51c6\u8d1f\u5bf9\u6570\u4f3c\u7136\u6765\u5bf9\u771f\u5b9e\u503c\u4e0e\u53cd\u4e8b\u5b9e\u8fdb\u884c\u6392\u540d\u3002", "result": "\u5728200\u540d\u4e2a\u4f53\u548c15\u4e2aLLM\uff08\u53c2\u6570\u91cf\u4ece410M\u523070B\uff09\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u8bb0\u5fc6\u60c5\u51b5\u4e0e\u4e3b\u4f53\u7684\u7f51\u7edc\u5b58\u5728\u548c\u6a21\u578b\u89c4\u6a21\u76f8\u5173\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5728\u4e2a\u4f53\u5c42\u9762\u8bc6\u522bLLM\u4e2d\u8bb0\u5fc6\u7684\u4e2a\u4eba\u6570\u636e\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u80fd\u591f\u4e3a\u673a\u5668\u5b66\u4e60\u548c\u9057\u5fd8\u6743\u8bf7\u6c42\u52a8\u6001\u6784\u5efa\u9057\u5fd8\u96c6\u3002"}}
{"id": "2507.11345", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11345", "abs": "https://arxiv.org/abs/2507.11345", "authors": ["Oscar Lima", "Marc Vinci", "Sunandita Patra", "Sebastian Stock", "Joachim Hertzberg", "Martin Atzmueller", "Malik Ghallab", "Dana Nau", "Paolo Traverso"], "title": "Acting and Planning with Hierarchical Operational Models on a Mobile Robot: A Study with RAE+UPOM", "comment": "Accepted in ECMR 2025 conference", "summary": "Robotic task execution faces challenges due to the inconsistency between\nsymbolic planner models and the rich control structures actually running on the\nrobot. In this paper, we present the first physical deployment of an integrated\nactor-planner system that shares hierarchical operational models for both\nacting and planning, interleaving the Reactive Acting Engine (RAE) with an\nanytime UCT-like Monte Carlo planner (UPOM). We implement RAE+UPOM on a mobile\nmanipulator in a real-world deployment for an object collection task. Our\nexperiments demonstrate robust task execution under action failures and sensor\nnoise, and provide empirical insights into the interleaved acting-and-planning\ndecision making process.", "AI": {"tldr": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u96c6\u6210\u7684 actor-planner \u7cfb\u7edf (RAE+UPOM)\uff0c\u7528\u4e8e\u89e3\u51b3\u673a\u5668\u4eba\u4efb\u52a1\u6267\u884c\u4e2d\u7684\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\u3002\u8be5\u7cfb\u7edf\u5728\u79fb\u52a8\u673a\u68b0\u81c2\u7684\u7269\u4f53\u6536\u96c6\u4efb\u52a1\u4e2d\u8fdb\u884c\u4e86\u7269\u7406\u90e8\u7f72\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5728\u52a8\u4f5c\u5931\u8d25\u548c\u4f20\u611f\u5668\u566a\u58f0\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u4eba\u4efb\u52a1\u6267\u884c\u4e2d\uff0c\u7b26\u53f7\u89c4\u5212\u6a21\u578b\u548c\u5b9e\u9645\u8fd0\u884c\u7684\u63a7\u5236\u7ed3\u6784\u4e4b\u95f4\u5b58\u5728\u4e0d\u4e00\u81f4\u6027\u7684\u6311\u6218\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u96c6\u6210\u7684 actor-planner \u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u901a\u8fc7\u4e00\u4e2a\u4ea4\u7ec7\u4e86 RAE\uff08Reactive Acting Engine\uff09\u548c UPOM\uff08anytime UCT-like Monte Carlo planner\uff09\u7684\u5c42\u7ea7\u64cd\u4f5c\u6a21\u578b\u6765\u8fde\u63a5\u7b26\u53f7\u89c4\u5212\u6a21\u578b\u548c\u673a\u5668\u4eba\u5b9e\u9645\u8fd0\u884c\u7684\u63a7\u5236\u7ed3\u6784\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u7684\u7269\u4f53\u6536\u96c6\u4efb\u52a1\u4e2d\uff0c\u6211\u4eec\u5bf9\u4e00\u4e2a\u79fb\u52a8\u673a\u68b0\u81c2\u8fdb\u884c\u4e86 RAE+UPOM \u7684\u5b9e\u73b0\u548c\u5b9e\u9a8c\u3002\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u80fd\u591f\u53ef\u9760\u5730\u6267\u884c\u4efb\u52a1\uff0c\u5e76\u5728\u52a8\u4f5c\u5931\u8d25\u548c\u4f20\u611f\u5668\u566a\u58f0\u7b49\u60c5\u51b5\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u5173\u4e8e\u4ea4\u7ec7\u7684 acting-and-planning \u51b3\u7b56\u8fc7\u7a0b\u7684\u5b9e\u8bc1\u89c1\u89e3\u3002", "conclusion": "\u5728\u673a\u5668\u4eba\u4efb\u52a1\u6267\u884c\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u96c6\u6210\u7684 actor-planner \u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u5728\u7269\u7406\u90e8\u7f72\u4e2d\u5c55\u793a\u4e86\u9c81\u68d2\u7684\u4efb\u52a1\u6267\u884c\u80fd\u529b\uff0c\u80fd\u591f\u5e94\u5bf9\u52a8\u4f5c\u5931\u8d25\u548c\u4f20\u611f\u5668\u566a\u58f0\u3002"}}
{"id": "2507.11016", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.11016", "abs": "https://arxiv.org/abs/2507.11016", "authors": ["Marzieh Asoudeh", "Vahid Karimipour"], "title": "A review of perfect quantum state transfer, from one to two and three dimensional arrays of qubits", "comment": "A short pedagogical review, 21 pages, 10 figures. arXiv admin note:\n  text overlap with arXiv:1106.4829", "summary": "In the light of recent advances in fabricating single layer quantum chips and\na possible road toward development of multi-layer quantum chips, we review, in\na detailed way, the subject of quantum state transfer with particular emphasis\non perfect quantum state transfer in two and three dimensional lattices. We\nshow how one can route an unknown quantum state from one node in a single layer\nof a quantum chip to another one on another layer with unit fidelity.\n  Our method of presentation in this review allows the reader with a modest\nbackground in quantum mechanics to grasp the essential ideas and methods of\nthis important branch of quantum information theory.", "AI": {"tldr": "\u672c\u7bc7\u8bba\u6587\u56de\u987e\u4e86\u91cf\u5b50\u72b6\u6001\u8f6c\u79fb\uff0c\u7279\u522b\u662f\u4e8c\u7ef4\u548c\u4e09\u7ef4\u683c\u5b50\u4e2d\u7684\u5b8c\u7f8e\u91cf\u5b50\u72b6\u6001\u8f6c\u79fb\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u91cf\u5b50\u6bd4\u7279\u7684\u4e0d\u540c\u5c42\u4e4b\u95f4\u4ee5\u5355\u4f4d\u4fdd\u771f\u5ea6\u8def\u7531\u672a\u77e5\u91cf\u5b50\u6001\u7684\u65b9\u6cd5\u3002", "motivation": "\u9274\u4e8e\u5236\u9020\u5355\u5c42\u91cf\u5b50\u82af\u7247\u548c\u53d1\u5c55\u591a\u5c42\u91cf\u5b50\u82af\u7247\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5bf9\u91cf\u5b50\u72b6\u6001\u8f6c\u79fb\u4e3b\u9898\u8fdb\u884c\u56de\u987e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u91cf\u5b50\u6bd4\u7279\u7684\u4e0d\u540c\u5c42\u4e4b\u95f4\u4ee5\u5355\u4f4d\u4fdd\u771f\u5ea6\u8def\u7531\u672a\u77e5\u91cf\u5b50\u6001\u7684\u65b9\u6cd5\u3002", "result": "\u672c\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u91cf\u5b50\u6bd4\u7279\u7684\u4e0d\u540c\u5c42\u4e4b\u95f4\u4ee5\u5355\u4f4d\u4fdd\u771f\u5ea6\u8def\u7531\u672a\u77e5\u91cf\u5b50\u6001\u7684\u65b9\u6cd5\u3002", "conclusion": "\u672c\u7bc7\u8bba\u6587\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u91cf\u5b50\u72b6\u6001\u8f6c\u79fb\uff0c\u7279\u522b\u662f\u4e8c\u7ef4\u548c\u4e09\u7ef4\u683c\u5b50\u4e2d\u7684\u5b8c\u7f8e\u91cf\u5b50\u72b6\u6001\u8f6c\u79fb\u3002"}}
{"id": "2507.11055", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11055", "abs": "https://arxiv.org/abs/2507.11055", "authors": ["Shuchang Ye", "Usman Naseem", "Mingyuan Meng", "Jinman Kim"], "title": "Alleviating Textual Reliance in Medical Language-guided Segmentation via Prototype-driven Semantic Approximation", "comment": "Accepted to ICCV 2025", "summary": "Medical language-guided segmentation, integrating textual clinical reports as\nauxiliary guidance to enhance image segmentation, has demonstrated significant\nimprovements over unimodal approaches. However, its inherent reliance on paired\nimage-text input, which we refer to as ``textual reliance\", presents two\nfundamental limitations: 1) many medical segmentation datasets lack paired\nreports, leaving a substantial portion of image-only data underutilized for\ntraining; and 2) inference is limited to retrospective analysis of cases with\npaired reports, limiting its applicability in most clinical scenarios where\nsegmentation typically precedes reporting. To address these limitations, we\npropose ProLearn, the first Prototype-driven Learning framework for\nlanguage-guided segmentation that fundamentally alleviates textual reliance. At\nits core, in ProLearn, we introduce a novel Prototype-driven Semantic\nApproximation (PSA) module to enable approximation of semantic guidance from\ntextual input. PSA initializes a discrete and compact prototype space by\ndistilling segmentation-relevant semantics from textual reports. Once\ninitialized, it supports a query-and-respond mechanism which approximates\nsemantic guidance for images without textual input, thereby alleviating textual\nreliance. Extensive experiments on QaTa-COV19, MosMedData+ and Kvasir-SEG\ndemonstrate that ProLearn outperforms state-of-the-art language-guided methods\nwhen limited text is available.", "AI": {"tldr": "ProLearn\u901a\u8fc7\u539f\u578b\u9a71\u52a8\u8bed\u4e49\u8fd1\u4f3c\uff08PSA\uff09\u51cf\u8f7b\u4e86\u533b\u5b66\u56fe\u50cf\u5206\u5272\u5bf9\u6587\u672c\u7684\u4f9d\u8d56\uff0c\u5373\u4f7f\u5728\u6587\u672c\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u63d0\u5347\u5206\u5272\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u533b\u5b66\u8bed\u8a00\u5f15\u5bfc\u5206\u5272\u65b9\u6cd5\u867d\u7136\u5728\u63d0\u9ad8\u56fe\u50cf\u5206\u5272\u7cbe\u5ea6\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5bf9\u6210\u5bf9\u56fe\u50cf-\u6587\u672c\u8f93\u5165\u7684\u4f9d\u8d56\u6027\u9650\u5236\u4e86\u5176\u5728\u6570\u636e\u4e0d\u5b8c\u6574\u6216\u9700\u8981\u5b9e\u65f6\u5206\u6790\u7684\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u8bb8\u591a\u6570\u636e\u96c6\u7f3a\u4e4f\u6210\u5bf9\u7684\u62a5\u544a\uff0c\u5bfc\u81f4\u5927\u91cf\u4ec5\u5305\u542b\u56fe\u50cf\u7684\u6570\u636e\u65e0\u6cd5\u5f97\u5230\u6709\u6548\u5229\u7528\uff1b\u540c\u65f6\uff0c\u5728\u4e34\u5e8a\u5b9e\u8df5\u4e2d\uff0c\u5206\u5272\u901a\u5e38\u5148\u4e8e\u62a5\u544a\u751f\u6210\uff0c\u8fd9\u4f7f\u5f97\u5728\u7f3a\u4e4f\u6587\u672c\u62a5\u544a\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u63a8\u7406\u6210\u4e3a\u4e00\u4e2a\u6311\u6218\u3002", "method": "ProLearn\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u539f\u578b\u9a71\u52a8\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u539f\u578b\u9a71\u52a8\u8bed\u4e49\u8fd1\u4f3c\uff08PSA\uff09\u6a21\u5757\u6765\u8fd1\u4f3c\u6587\u672c\u8f93\u5165\u4e2d\u7684\u8bed\u4e49\u5f15\u5bfc\u3002PSA\u9996\u5148\u901a\u8fc7\u4ece\u6587\u672c\u62a5\u544a\u4e2d\u63d0\u53d6\u5206\u5272\u76f8\u5173\u7684\u8bed\u4e49\u6765\u521d\u59cb\u5316\u4e00\u4e2a\u79bb\u6563\u4e14\u7d27\u51d1\u7684\u539f\u578b\u7a7a\u95f4\uff0c\u7136\u540e\u652f\u6301\u4e00\u79cd\u67e5\u8be2\u548c\u54cd\u5e94\u673a\u5236\uff0c\u4e3a\u6ca1\u6709\u6587\u672c\u8f93\u5165\u7684\u56fe\u50cf\u8fd1\u4f3c\u8bed\u4e49\u5f15\u5bfc\uff0c\u4ece\u800c\u51cf\u8f7b\u5bf9\u6587\u672c\u7684\u4f9d\u8d56\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u6709\u9650\u7684\u6587\u672c\u53ef\u7528\u60c5\u51b5\u4e0b\uff0cProLearn\u5728QaTa-COV19\u3001MosMedData+\u548cKvasir-SEG\u7b49\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u8bed\u8a00\u5f15\u5bfc\u65b9\u6cd5\u3002", "conclusion": "ProLearn\u6846\u67b6\u901a\u8fc7\u5176\u6838\u5fc3\u7684ProLearn\u539f\u578b\u9a71\u52a8\u8bed\u4e49\u8fd1\u4f3c\uff08PSA\uff09\u6a21\u5757\uff0c\u6210\u529f\u5730\u51cf\u8f7b\u4e86\u5bf9\u6587\u672c\u7684\u4f9d\u8d56\uff0c\u4e3a\u533b\u5b66\u56fe\u50cf\u5206\u5272\u9886\u57df\u5f00\u8f9f\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2507.11334", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.11334", "abs": "https://arxiv.org/abs/2507.11334", "authors": ["Yuehao Huang", "Liang Liu", "Shuangming Lei", "Yukai Ma", "Hao Su", "Jianbiao Mei", "Pengxiang Zhao", "Yaqing Gu", "Yong Liu", "Jiajun Lv"], "title": "CogDDN: A Cognitive Demand-Driven Navigation with Decision Optimization and Dual-Process Thinking", "comment": "Accepted by ACM MM 2025", "summary": "Mobile robots are increasingly required to navigate and interact within\nunknown and unstructured environments to meet human demands. Demand-driven\nnavigation (DDN) enables robots to identify and locate objects based on\nimplicit human intent, even when object locations are unknown. However,\ntraditional data-driven DDN methods rely on pre-collected data for model\ntraining and decision-making, limiting their generalization capability in\nunseen scenarios. In this paper, we propose CogDDN, a VLM-based framework that\nemulates the human cognitive and learning mechanisms by integrating fast and\nslow thinking systems and selectively identifying key objects essential to\nfulfilling user demands. CogDDN identifies appropriate target objects by\nsemantically aligning detected objects with the given instructions.\nFurthermore, it incorporates a dual-process decision-making module, comprising\na Heuristic Process for rapid, efficient decisions and an Analytic Process that\nanalyzes past errors, accumulates them in a knowledge base, and continuously\nimproves performance. Chain of Thought (CoT) reasoning strengthens the\ndecision-making process. Extensive closed-loop evaluations on the AI2Thor\nsimulator with the ProcThor dataset show that CogDDN outperforms single-view\ncamera-only methods by 15%, demonstrating significant improvements in\nnavigation accuracy and adaptability. The project page is available at\nhttps://yuehaohuang.github.io/CogDDN/.", "AI": {"tldr": "CogDDN\u662f\u4e00\u4e2a\u57fa\u4e8eVLM\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u548c\u5b66\u4e60\u673a\u5236\uff08\u6574\u5408\u5feb\u6162\u601d\u8003\u3001\u53cc\u8fc7\u7a0b\u51b3\u7b56\u3001CoT\u63a8\u7406\uff09\u6765\u6539\u8fdb\u9700\u6c42\u9a71\u52a8\u5bfc\u822a\uff08DDN\uff09\u3002\u5b83\u80fd\u66f4\u597d\u5730\u5904\u7406\u672a\u77e5\u548c\u975e\u7ed3\u6784\u5316\u73af\u5883\uff0c\u5728AI2Thor\u6a21\u62df\u5668\u4e0a\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u63d0\u5347\u4e8615%\u7684\u5bfc\u822a\u51c6\u786e\u6027\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u4f20\u7edf\u6570\u636e\u9a71\u52a8\u7684\u9700\u6c42\u9a71\u52a8\u5bfc\u822a\uff08DDN\uff09\u65b9\u6cd5\u4f9d\u8d56\u9884\u5148\u6536\u96c6\u7684\u6570\u636e\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u548c\u51b3\u7b56\uff0c\u5728\u672a\u89c1\u573a\u666f\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u6709\u9650\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8DDN\u5728\u672a\u77e5\u548c\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\u548c\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCogDDN\u7684\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u6574\u5408\u5feb\u901f\u548c\u6162\u901f\u601d\u7ef4\u7cfb\u7edf\u6765\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u548c\u5b66\u4e60\u673a\u5236\uff0c\u5e76\u6709\u9009\u62e9\u6027\u5730\u8bc6\u522b\u6ee1\u8db3\u7528\u6237\u9700\u6c42\u7684\u5173\u952e\u5bf9\u8c61\u3002CogDDN\u901a\u8fc7\u8bed\u4e49\u5bf9\u9f50\u68c0\u6d4b\u5230\u7684\u5bf9\u8c61\u548c\u7ed9\u5b9a\u7684\u6307\u4ee4\u6765\u8bc6\u522b\u5408\u9002\u7684\u76ee\u6807\u5bf9\u8c61\u3002\u6b64\u5916\uff0c\u5b83\u8fd8\u5305\u542b\u4e00\u4e2a\u53cc\u8fc7\u7a0b\u51b3\u7b56\u6a21\u5757\uff0c\u5305\u62ec\u7528\u4e8e\u5feb\u901f\u9ad8\u6548\u51b3\u7b56\u7684\u542f\u53d1\u5f0f\u8fc7\u7a0b\uff0c\u4ee5\u53ca\u7528\u4e8e\u5206\u6790\u8fc7\u5f80\u9519\u8bef\u3001\u7d2f\u79ef\u77e5\u8bc6\u5e93\u5e76\u6301\u7eed\u6539\u8fdb\u6027\u80fd\u7684\u5206\u6790\u8fc7\u7a0b\u3002\u601d\u7ef4\u94fe\uff08CoT\uff09\u63a8\u7406\u589e\u5f3a\u4e86\u51b3\u7b56\u8fc7\u7a0b\u3002", "result": "CogDDN\u76f8\u6bd4\u5355\u89c6\u56fe\u7eaf\u89c6\u89c9\u65b9\u6cd5\uff0c\u5bfc\u822a\u51c6\u786e\u6027\u548c\u9002\u5e94\u6027\u670915%\u7684\u63d0\u5347\u3002", "conclusion": "CogDDN\u5728AI2Thor\u6a21\u62df\u5668\u548cProcThor\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u7684\u95ed\u73af\u8bc4\u4f30\u663e\u793a\uff0cCogDDN\u76f8\u6bd4\u4ec5\u4f7f\u7528\u5355\u89c6\u56fe\u6444\u50cf\u5934\u7684\u4f20\u7edf\u65b9\u6cd5\uff0c\u5bfc\u822a\u51c6\u786e\u6027\u548c\u9002\u5e94\u6027\u670915%\u7684\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2507.11198", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11198", "abs": "https://arxiv.org/abs/2507.11198", "authors": ["Conrad Borchers", "Bahar Shahrokhian", "Francesco Balzan", "Elham Tajik", "Sreecharan Sankaranarayanan", "Sebastian Simon"], "title": "Temperature and Persona Shape LLM Agent Consensus With Minimal Accuracy Gains in Qualitative Coding", "comment": "Manuscript submitted for review", "summary": "Large Language Models (LLMs) enable new possibilities for qualitative\nresearch at scale, including coding and data annotation. While multi-agent\nsystems (MAS) can emulate human coding workflows, their benefits over\nsingle-agent coding remain poorly understood. We conducted an experimental\nstudy of how agent persona and temperature shape consensus-building and coding\naccuracy of dialog segments based on a codebook with 8 codes. Our open-source\nMAS mirrors deductive human coding through structured agent discussion and\nconsensus arbitration. Using six open-source LLMs (with 3 to 32 billion\nparameters) and 18 experimental configurations, we analyze over 77,000 coding\ndecisions against a gold-standard dataset of human-annotated transcripts from\nonline math tutoring sessions. Temperature significantly impacted whether and\nwhen consensus was reached across all six LLMs. MAS with multiple personas\n(including neutral, assertive, or empathetic), significantly delayed consensus\nin four out of six LLMs compared to uniform personas. In three of those LLMs,\nhigher temperatures significantly diminished the effects of multiple personas\non consensus. However, neither temperature nor persona pairing lead to robust\nimprovements in coding accuracy. Single agents matched or outperformed MAS\nconsensus in most conditions. Only one model (OpenHermesV2:7B) and code\ncategory showed above-chance gains from MAS deliberation when temperature was\n0.5 or lower and especially when the agents included at least one assertive\npersona. Qualitative analysis of MAS collaboration for these configurations\nsuggests that MAS may nonetheless aid in narrowing ambiguous code applications\nthat could improve codebooks and human-AI coding. We contribute new insight\ninto the limits of LLM-based qualitative methods, challenging the notion that\ndiverse MAS personas lead to better outcomes. We open-source our MAS and\nexperimentation code.", "AI": {"tldr": "LLM\u5728\u5b9a\u6027\u7814\u7a76\u4e2d\u5f88\u6709\u7528\uff0c\u4f46\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u5e76\u4e0d\u603b\u662f\u6bd4\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\u66f4\u597d\u3002\u667a\u80fd\u4f53\u89d2\u8272\u548c\u6e29\u5ea6\u4f1a\u5f71\u54cd\u5171\u8bc6\uff0c\u4f46\u5e76\u4e0d\u603b\u662f\u63d0\u9ad8\u51c6\u786e\u6027\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u53ea\u6709\u4e00\u79cd\u6a21\u578b\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u8868\u73b0\u66f4\u597d\uff0c\u4f46MAS\u53ef\u80fd\u6709\u52a9\u4e8e\u6539\u8fdb\u4ee3\u7801\u672c\u3002", "motivation": "\u5728\u5b9a\u6027\u7814\u7a76\u9886\u57df\uff0c\u867d\u7136\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u53ef\u4ee5\u6a21\u62df\u4eba\u7c7b\u7f16\u7801\u5de5\u4f5c\u6d41\u7a0b\uff0c\u4f46\u5b83\u4eec\u76f8\u5bf9\u4e8e\u5355\u667a\u80fd\u4f53\u7f16\u7801\u7684\u4f18\u52bf\u4ecd\u7136\u77e5\u4e4b\u751a\u5c11\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u7814\u7a76\u4e86\u667a\u80fd\u4f53\u89d2\u8272\u548c\u6e29\u5ea6\u5982\u4f55\u5f71\u54cd\u57fa\u4e8e8\u4e2a\u4ee3\u7801\u7684\u4ee3\u7801\u672c\u7684\u5bf9\u8bdd\u7247\u6bb5\u7684\u5171\u8bc6\u5efa\u7acb\u548c\u7f16\u7801\u51c6\u786e\u6027\u3002\u7814\u7a76\u4f7f\u7528\u4e86\u516d\u4e2a\u5f00\u6e90LLM\uff08\u5177\u67093\u5230320\u4ebf\u53c2\u6570\uff09\u548c18\u79cd\u5b9e\u9a8c\u914d\u7f6e\uff0c\u5206\u6790\u4e86\u8d85\u8fc777000\u4e2a\u7f16\u7801\u51b3\u7b56\uff0c\u5e76\u4e0e\u5728\u7ebf\u6570\u5b66\u8f85\u5bfc\u8bfe\u7a0b\u7684\u4eba\u5de5\u6ce8\u91ca\u7684\u6210\u7ee9\u5355\u7684\u91d1\u6807\u51c6\u6570\u636e\u96c6\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "result": "\u6e29\u5ea6\u663e\u8457\u5f71\u54cd\u4e86\u6240\u6709\u516d\u4e2aLLM\u8fbe\u6210\u5171\u8bc6\u7684\u7a0b\u5ea6\u548c\u65f6\u95f4\u3002\u4e0e\u7edf\u4e00\u89d2\u8272\u76f8\u6bd4\uff0c\u5177\u6709\u591a\u4e2a\u89d2\u8272\uff08\u5305\u62ec\u4e2d\u6027\u3001\u81ea\u4fe1\u6216\u5171\u60c5\uff09\u7684MAS\u5728\u56db\u4e2aLLM\u4e2d\u663e\u8457\u5ef6\u8fdf\u4e86\u5171\u8bc6\u3002\u5728\u5176\u4e2d\u4e09\u4e2aLLM\u4e2d\uff0c\u8f83\u9ad8\u7684\u6e29\u5ea6\u663e\u8457\u524a\u5f31\u4e86\u591a\u4e2a\u89d2\u8272\u5bf9\u5171\u8bc6\u7684\u5f71\u54cd\u3002\u7136\u800c\uff0c\u6e29\u5ea6\u548c\u89d2\u8272\u914d\u5bf9\u5747\u672a\u80fd\u5728\u7f16\u7801\u51c6\u786e\u6027\u65b9\u9762\u5e26\u6765\u7a33\u5065\u7684\u6539\u8fdb\u3002", "conclusion": "\u5355\u667a\u80fd\u4f53\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u5339\u914d\u6216\u4f18\u4e8e\u591a\u667a\u80fd\u4f53\u5171\u8bc6\uff0c\u53ea\u6709\u4e00\u79cd\u6a21\u578b\uff08OpenHermesV2:7B\uff09\u548c\u4ee3\u7801\u7c7b\u522b\u5728\u6e29\u5ea6\u8f83\u4f4e\uff080.5\u6216\u66f4\u4f4e\uff09\u4e14\u81f3\u5c11\u5305\u542b\u4e00\u4e2a\u5177\u6709\u8bf4\u670d\u6027\u89d2\u8272\u7684\u667a\u80fd\u4f53\u65f6\uff0c\u8868\u73b0\u51fa\u9ad8\u4e8e\u673a\u4f1a\u7684\u6536\u76ca\u3002\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u5728\u5e2e\u52a9\u7f29\u5c0f\u53ef\u80fd\u6539\u8fdb\u4ee3\u7801\u672c\u548c\u4eba\u7c7b-AI\u7f16\u7801\u7684\u6a21\u7cca\u4ee3\u7801\u5e94\u7528\u65b9\u9762\u53ef\u80fd\u4ecd\u7136\u6709\u7528\u3002\u7814\u7a76\u7ed3\u679c\u6311\u6218\u4e86\u591a\u6837\u5316MAS\u89d2\u8272\u80fd\u591f\u5e26\u6765\u66f4\u597d\u7ed3\u679c\u7684\u89c2\u70b9\u3002"}}
{"id": "2507.10741", "categories": ["cs.LG", "cs.AI", "I.2.6; I.2.4"], "pdf": "https://arxiv.org/pdf/2507.10741", "abs": "https://arxiv.org/abs/2507.10741", "authors": ["Andrew C. Li", "Toryn Q. Klassen", "Andrew Wang", "Parand A. Alamdari", "Sheila A. McIlraith"], "title": "Ground-Compose-Reinforce: Tasking Reinforcement Learning Agents through Formal Language", "comment": null, "summary": "Grounding language in complex perception (e.g. pixels) and action is a key\nchallenge when building situated agents that can interact with humans via\nlanguage. In past works, this is often solved via manual design of the language\ngrounding or by curating massive datasets relating language to elements of the\nenvironment. We propose Ground-Compose-Reinforce, a neurosymbolic framework for\ngrounding formal language from data, and eliciting behaviours by directly\ntasking RL agents through this language. By virtue of data-driven learning, our\nframework avoids the manual design of domain-specific elements like reward\nfunctions or symbol detectors. By virtue of compositional formal language\nsemantics, our framework achieves data-efficient grounding and generalization\nto arbitrary language compositions. Experiments on an image-based gridworld and\na MuJoCo robotics domain show that our approach reliably maps formal language\ninstructions to behaviours with limited data while end-to-end, data-driven\napproaches fail.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGround-Compose-Reinforce\u7684\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u7528\u4e8e\u5c06\u5f62\u5f0f\u8bed\u8a00\u63a5\u5730\u5e76\u6307\u5bfcRL\u4ee3\u7406\u5b8c\u6210\u4efb\u52a1\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u907f\u514d\u4e86\u624b\u52a8\u8bbe\u8ba1\uff0c\u5e76\u901a\u8fc7\u7ec4\u5408\u5f62\u5f0f\u8bed\u8a00\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u6570\u636e\u63a5\u5730\u548c\u6cdb\u5316\u80fd\u529b\u3002\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u5904\u7406\u8bed\u8a00\u6307\u4ee4\u548c\u673a\u5668\u4eba\u63a7\u5236\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u5728\u6784\u5efa\u80fd\u591f\u901a\u8fc7\u8bed\u8a00\u4e0e\u4eba\u7c7b\u4e92\u52a8\u7684\u60c5\u5883\u4ee3\u7406\u65f6\uff0c\u5c06\u8bed\u8a00\u4e0e\u590d\u6742\u611f\u77e5\uff08\u5982\u50cf\u7d20\uff09\u548c\u52a8\u4f5c\u8054\u7cfb\u8d77\u6765\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002\u4ee5\u5f80\u7684\u7814\u7a76\u901a\u5e38\u901a\u8fc7\u624b\u52a8\u8bbe\u8ba1\u8bed\u8a00\u63a5\u5730\u6216\u6574\u7406\u5927\u91cf\u5c06\u8bed\u8a00\u4e0e\u73af\u5883\u5143\u7d20\u5173\u8054\u8d77\u6765\u7684\u6570\u636e\u96c6\u6765\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGround-Compose-Reinforce\u7684\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u6570\u636e\u4e2d\u5b9e\u73b0\u5f62\u5f0f\u8bed\u8a00\u7684\u63a5\u5730\uff0c\u5e76\u901a\u8fc7\u8bed\u8a00\u76f4\u63a5\u7ed9\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u4ee3\u7406\u4efb\u52a1\u6765\u5f15\u53d1\u884c\u4e3a\u3002", "result": "\u5728\u57fa\u4e8e\u56fe\u50cf\u7684\u7f51\u683c\u4e16\u754c\u548cMuJoCo\u673a\u5668\u4eba\u9886\u57df\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u80fd\u591f\u53ef\u9760\u5730\u5c06\u5f62\u5f0f\u8bed\u8a00\u6307\u4ee4\u6620\u5c04\u5230\u884c\u4e3a\uff0c\u800c\u7aef\u5230\u7aef\u7684\u3001\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u5219\u4f1a\u5931\u8d25\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u4ee5\u6570\u636e\u9a71\u52a8\u7684\u65b9\u5f0f\uff0c\u5c06\u5f62\u5f0f\u8bed\u8a00\u53ef\u9760\u5730\u6620\u5c04\u5230\u884c\u4e3a\uff0c\u5e76\u4e14\u5177\u6709\u6570\u636e\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u80fd\u591f\u5904\u7406\u4efb\u610f\u7684\u8bed\u8a00\u7ec4\u5408\u3002"}}
{"id": "2507.11402", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.11402", "abs": "https://arxiv.org/abs/2507.11402", "authors": ["Supun Dissanayaka", "Alexander Ferrein", "Till Hofmann", "Kosuke Nakajima", "Mario Sanz-Lopez", "Jesus Savage", "Daniel Swoboda", "Matteo Tschesche", "Wataru Uemura", "Tarik Viehmann", "Shohei Yasuda"], "title": "From Production Logistics to Smart Manufacturing: The Vision for a New RoboCup Industrial League", "comment": "RoboCup Symposium 2025", "summary": "The RoboCup Logistics League is a RoboCup competition in a smart factory\nscenario that has focused on task planning, job scheduling, and multi-agent\ncoordination. The focus on production logistics allowed teams to develop highly\ncompetitive strategies, but also meant that some recent developments in the\ncontext of smart manufacturing are not reflected in the competition, weakening\nits relevance over the years. In this paper, we describe the vision for the\nRoboCup Smart Manufacturing League, a new competition designed as a larger\nsmart manufacturing scenario, reflecting all the major aspects of a modern\nfactory. It will consist of several tracks that are initially independent but\ngradually combined into one smart manufacturing scenario. The new tracks will\ncover industrial robotics challenges such as assembly, human-robot\ncollaboration, and humanoid robotics, but also retain a focus on production\nlogistics. We expect the reenvisioned competition to be more attractive to\nnewcomers and well-tried teams, while also shifting the focus to current and\nfuture challenges of industrial robotics.", "AI": {"tldr": "RoboCup\u7269\u6d41\u8054\u8d5b\u56e0\u672a\u80fd\u8ddf\u4e0a\u667a\u80fd\u5236\u9020\u7684\u6b65\u4f10\u800c\u8fdb\u884c\u4e86\u6539\u9769\uff0c\u63a8\u51fa\u4e86RoboCup\u667a\u80fd\u5236\u9020\u8054\u8d5b\uff0c\u6db5\u76d6\u4e86\u66f4\u591a\u9886\u57df\uff0c\u5982\u5de5\u4e1a\u673a\u5668\u4eba\u3001\u4eba\u673a\u534f\u4f5c\u548c\u4eba\u5f62\u673a\u5668\u4eba\uff0c\u5e76\u4fa7\u91cd\u4e8e\u5f53\u524d\u548c\u672a\u6765\u7684\u6311\u6218\u3002", "motivation": "RoboCup\u7269\u6d41\u8054\u8d5b\u7531\u4e8e\u8fc7\u4e8e\u5173\u6ce8\u751f\u4ea7\u7269\u6d41\u800c\u672a\u80fd\u53cd\u6620\u667a\u80fd\u5236\u9020\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u524a\u5f31\u4e86\u5176\u76f8\u5173\u6027\u3002", "method": "\u63d0\u51faRoboCup\u667a\u80fd\u5236\u9020\u8054\u8d5b\u7684\u613f\u666f\uff0c\u4e00\u4e2a\u5305\u542b\u591a\u4e2a\u72ec\u7acb\u4f46\u9010\u6e10\u5408\u5e76\u7684\u8d5b\u9053\u7684\u5927\u578b\u667a\u80fd\u5236\u9020\u573a\u666f\u3002", "result": "\u9884\u671f\u8be5\u8054\u8d5b\u5c06\u5438\u5f15\u65b0\u8001\u56e2\u961f\uff0c\u5e76\u5c06\u91cd\u70b9\u8f6c\u79fb\u5230\u5f53\u524d\u548c\u672a\u6765\u7684\u5de5\u4e1a\u673a\u5668\u4eba\u6311\u6218\u4e0a\u3002", "conclusion": "\u8be5\u65b0\u7ade\u8d5b\u65e8\u5728\u901a\u8fc7\u6db5\u76d6\u5de5\u4e1a\u673a\u5668\u4eba\u3001\u4eba\u673a\u534f\u4f5c\u548c\u4eba\u5f62\u673a\u5668\u4eba\u7b49\u9886\u57df\u7684\u591a\u4e2a\u8d5b\u9053\uff0c\u5e76\u7ed3\u5408\u751f\u4ea7\u7269\u6d41\uff0c\u6765\u5438\u5f15\u65b0\u8001\u56e2\u961f\uff0c\u5e76\u5173\u6ce8\u5f53\u524d\u548c\u672a\u6765\u7684\u5de5\u4e1a\u673a\u5668\u4eba\u6311\u6218\uff0c\u4ece\u800c\u63d0\u9ad8\u5176\u5438\u5f15\u529b\u548c\u76f8\u5173\u6027\u3002"}}
{"id": "2507.11020", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.11020", "abs": "https://arxiv.org/abs/2507.11020", "authors": ["Abbaas Sabour", "Fereydoon Khazali", "Soghra Ghanavati"], "title": "New Localizable Entanglement", "comment": null, "summary": "In this study, we have addressed an ambiguity in the concept of localizable\nentanglement (LE) introduced by Verstraete et al in 2004. By doing so, we have\nproposed and explored a unique form of this entanglement, called new\nlocalizable entanglement (NLE). We have shown that NLE is always less than or\nequal to LE. Additionally, we have demonstrated that for systems with three\ncomponents, NLE does not differ significantly from LE. However, when the number\nof components increases to four, there is a possibility of significant\ndifferences between the two methods. Furthermore, as the number of components\nincreases further, this difference becomes slightly more pronounced. It appears\nthat the classical correlation, which is the lower bound for LE, is also a\nlower bound for NLE.", "AI": {"tldr": "\u901a\u8fc7\u63d0\u51faNLE\u5e76\u4e0eLE\u8fdb\u884c\u6bd4\u8f83\uff0c\u7814\u7a76\u4e86\u5176\u4e0eLE\u7684\u5173\u7cfb\uff0c\u53d1\u73b0NLE\u4e0d\u5927\u4e8eLE\uff0c\u4e14\u5728\u7ec4\u5206\u6570\u91cf\u589e\u52a0\u65f6\u4e24\u8005\u5dee\u5f02\u4f1a\u53d8\u5927\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3Verstraete\u7b49\u4eba\u4e8e2004\u5e74\u63d0\u51fa\u7684\u53ef\u5b9a\u4f4d\u7ea0\u7f20\uff08LE\uff09\u6982\u5ff5\u4e2d\u7684\u6b67\u4e49\u3002", "method": "\u63d0\u51fa\u5e76\u63a2\u7d22\u4e86\u4e00\u79cd\u79f0\u4e3a\u201c\u65b0\u7684\u53ef\u5b9a\u4f4d\u7ea0\u7f20\u201d\uff08NLE\uff09\u7684\u7ea0\u7f20\u5f62\u5f0f\uff0c\u5e76\u901a\u8fc7\u4e0e\u201c\u53ef\u5b9a\u4f4d\u7ea0\u7f20\u201d\uff08LE\uff09\u8fdb\u884c\u6bd4\u8f83\u6765\u5206\u6790\u3002", "result": "NLE\u7684\u5927\u5c0f\u4e0d\u5927\u4e8eLE\u3002\u5bf9\u4e8e\u4e09\u7ec4\u5206\u7cfb\u7edf\uff0cNLE\u4e0eLE\u6ca1\u6709\u663e\u8457\u5dee\u5f02\u3002\u7136\u800c\uff0c\u5f53\u7ec4\u5206\u6570\u91cf\u589e\u52a0\u5230\u56db\u65f6\uff0c\u4e24\u8005\u53ef\u80fd\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u5e76\u4e14\u968f\u7740\u7ec4\u5206\u6570\u91cf\u7684\u8fdb\u4e00\u6b65\u589e\u52a0\uff0c\u8fd9\u79cd\u5dee\u5f02\u4f1a\u7565\u5fae\u589e\u5927\u3002\u7ecf\u5178\u76f8\u5173\u6027\u65e2\u662fLE\u7684\u4e0b\u754c\uff0c\u4e5f\u662fNLE\u7684\u4e0b\u754c\u3002", "conclusion": "NLE\u7684\u5927\u5c0f\u4e0d\u5927\u4e8eLE\uff0c\u4e14\u5f53\u7cfb\u7edf\u7ec4\u4ef6\u6570\u91cf\u589e\u52a0\u65f6\uff0cNLE\u4e0eLE\u7684\u5dee\u5f02\u4f1a\u66f4\u660e\u663e\uff0c\u7ecf\u5178\u76f8\u5173\u6027\u540c\u65f6\u4f5c\u4e3aLE\u548cNLE\u7684\u4e0b\u754c\u3002"}}
{"id": "2507.11061", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11061", "abs": "https://arxiv.org/abs/2507.11061", "authors": ["Hayeon Kim", "Ji Ha Jang", "Se Young Chun"], "title": "Robust 3D-Masked Part-level Editing in 3D Gaussian Splatting with Regularized Score Distillation Sampling", "comment": null, "summary": "Recent advances in 3D neural representations and instance-level editing\nmodels have enabled the efficient creation of high-quality 3D content. However,\nachieving precise local 3D edits remains challenging, especially for Gaussian\nSplatting, due to inconsistent multi-view 2D part segmentations and inherently\nambiguous nature of Score Distillation Sampling (SDS) loss. To address these\nlimitations, we propose RoMaP, a novel local 3D Gaussian editing framework that\nenables precise and drastic part-level modifications. First, we introduce a\nrobust 3D mask generation module with our 3D-Geometry Aware Label Prediction\n(3D-GALP), which uses spherical harmonics (SH) coefficients to model\nview-dependent label variations and soft-label property, yielding accurate and\nconsistent part segmentations across viewpoints. Second, we propose a\nregularized SDS loss that combines the standard SDS loss with additional\nregularizers. In particular, an L1 anchor loss is introduced via our Scheduled\nLatent Mixing and Part (SLaMP) editing method, which generates high-quality\npart-edited 2D images and confines modifications only to the target region\nwhile preserving contextual coherence. Additional regularizers, such as\nGaussian prior removal, further improve flexibility by allowing changes beyond\nthe existing context, and robust 3D masking prevents unintended edits.\nExperimental results demonstrate that our RoMaP achieves state-of-the-art local\n3D editing on both reconstructed and generated Gaussian scenes and objects\nqualitatively and quantitatively, making it possible for more robust and\nflexible part-level 3D Gaussian editing.", "AI": {"tldr": "RoMaP \u662f\u4e00\u4e2a\u521b\u65b0\u7684\u5c40\u90e8 3D \u9ad8\u65af\u7f16\u8f91\u6846\u67b6\uff0c\u901a\u8fc7 3D-GALP \u6a21\u5757\u63d0\u4f9b\u51c6\u786e\u7684 3D \u63a9\u7801\uff0c\u5e76\u901a\u8fc7\u6b63\u5219\u5316 SDS \u635f\u5931\u5b9e\u73b0\u7cbe\u786e\u3001\u7075\u6d3b\u7684\u90e8\u5206\u7ea7\u7f16\u8f91\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5c40\u90e8\u7f16\u8f91\u65b9\u9762\u7684\u6311\u6218\u3002", "motivation": "\u5c3d\u7ba1\u795e\u7ecf\u6e32\u67d3\u548c\u5b9e\u4f8b\u7ea7\u7f16\u8f91\u6a21\u578b\u5728 3D \u5185\u5bb9\u521b\u5efa\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u5728\u9ad8\u65af\u6cfc\u6e85 (Gaussian Splatting) \u7b49\u6280\u672f\u4e2d\uff0c\u7cbe\u786e\u7684\u5c40\u90e8 3D \u7f16\u8f91\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\uff0c\u8fd9\u4e3b\u8981\u662f\u7531\u4e8e\u591a\u89c6\u56fe 2D \u90e8\u5206\u5206\u5272\u4e0d\u4e00\u81f4\u4ee5\u53ca\u8bc4\u5206\u84b8\u998f\u91c7\u6837 (SDS) \u635f\u5931\u7684\u56fa\u6709\u6a21\u7cca\u6027\u3002", "method": "RoMaP \u6846\u67b6\u901a\u8fc7\u4e24\u4e2a\u5173\u952e\u6a21\u5757\u5b9e\u73b0\u7cbe\u786e\u7684\u5c40\u90e8 3D \u7f16\u8f91\uff1a1. 3D-GALP \u6a21\u5757\uff0c\u5229\u7528\u7403\u8c10 (SH) \u7cfb\u6570\u6765\u5904\u7406\u89c6\u89d2\u76f8\u5173\u7684\u6807\u7b7e\u53d8\u5316\u548c\u8f6f\u6807\u7b7e\u7279\u6027\uff0c\u751f\u6210\u51c6\u786e\u4e14\u8de8\u89c6\u70b9\u4e00\u81f4\u7684 3D \u63a9\u7801\u30022. \u6b63\u5219\u5316 SDS \u635f\u5931\uff0c\u7ed3\u5408\u4e86\u6807\u51c6 SDS \u635f\u5931\u3001L1 \u951a\u70b9\u635f\u5931\uff08\u901a\u8fc7 SLaMP \u7f16\u8f91\u65b9\u6cd5\u5b9e\u73b0\uff09\u3001\u9ad8\u65af\u5148\u9a8c\u79fb\u9664\u4ee5\u53ca\u9c81\u68d2\u7684 3D \u63a9\u7801\uff0c\u4ee5\u786e\u4fdd\u7f16\u8f91\u7684\u7cbe\u786e\u6027\u548c\u4e0a\u4e0b\u6587\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cRoMaP \u5728\u5b9a\u6027\u548c\u5b9a\u91cf\u65b9\u9762\u5747\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u5c40\u90e8 3D \u7f16\u8f91\u6548\u679c\uff0c\u80fd\u591f\u5b9e\u73b0\u66f4\u9c81\u68d2\u3001\u66f4\u7075\u6d3b\u7684 3D \u9ad8\u65af\u5c40\u90e8\u7f16\u8f91\u3002", "conclusion": "RoMaP \u5728\u91cd\u5efa\u548c\u751f\u6210\u7684 3D \u9ad8\u65af\u573a\u666f\u548c\u5bf9\u8c61\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u5c40\u90e8 3D \u7f16\u8f91\uff0c\u5728\u5b9a\u6027\u548c\u5b9a\u91cf\u4e0a\u90fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2507.11352", "categories": ["cs.AI", "cs.FL"], "pdf": "https://arxiv.org/pdf/2507.11352", "abs": "https://arxiv.org/abs/2507.11352", "authors": ["Yunhao Yang", "Neel P. Bhatt", "Christian Ellis", "Alvaro Velasquez", "Zhangyang Wang", "Ufuk Topcu"], "title": "Foundation Models for Logistics: Toward Certifiable, Conversational Planning Interfaces", "comment": null, "summary": "Logistics operators, from battlefield coordinators rerouting airlifts ahead\nof a storm to warehouse managers juggling late trucks, often face life-critical\ndecisions that demand both domain expertise and rapid and continuous\nreplanning. While popular methods like integer programming yield logistics\nplans that satisfy user-defined logical constraints, they are slow and assume\nan idealized mathematical model of the environment that does not account for\nuncertainty. On the other hand, large language models (LLMs) can handle\nuncertainty and promise to accelerate replanning while lowering the barrier to\nentry by translating free-form utterances into executable plans, yet they\nremain prone to misinterpretations and hallucinations that jeopardize safety\nand cost. We introduce a neurosymbolic framework that pairs the accessibility\nof natural-language dialogue with verifiable guarantees on goal interpretation.\nIt converts user requests into structured planning specifications, quantifies\nits own uncertainty at the field and token level, and invokes an interactive\nclarification loop whenever confidence falls below an adaptive threshold. A\nlightweight model, fine-tuned on just 100 uncertainty-filtered examples,\nsurpasses the zero-shot performance of GPT-4.1 while cutting inference latency\nby nearly 50%. These preliminary results highlight a practical path toward\ncertifiable, real-time, and user-aligned decision-making for complex logistics.", "AI": {"tldr": "\u901a\u8fc7\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u5bf9\u8bdd\u548c\u53ef\u9a8c\u8bc1\u7684\u4fdd\u8bc1\uff0c\u8be5\u6846\u67b6\u53ef\u4ee5\u66f4\u5b89\u5168\u3001\u66f4\u5feb\u901f\u3001\u66f4\u51c6\u786e\u5730\u5904\u7406\u590d\u6742\u7684\u7269\u6d41\u89c4\u5212\u95ee\u9898\uff0c\u5373\u4f7f\u5728 \ubd88\ud655\uc2e4\uc131 \u7684\u60c5\u51b5\u4e0b\u4e5f\u662f\u5982\u6b64\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\uff08\u5982\u6574\u6570\u89c4\u5212\uff09\u5728\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u548c\u5b9e\u65f6 replanning \u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5219\u53ef\u80fd\u51fa\u73b0\u8bef\u89e3\u548c\u5e7b\u89c9\uff0c\u5371\u53ca\u5b89\u5168\u6027\u548c\u6210\u672c\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u5e76\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u4fdd\u8bc1\u7684\u6846\u67b6\u3002", "method": "\u8be5\u6846\u67b6\u5c06\u7528\u6237\u8bf7\u6c42\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u89c4\u5212\u89c4\u8303\uff0c\u91cf\u5316\u5176\u81ea\u8eab\u5728\u73b0\u573a\u548c\u4ee4\u724c\u7ea7\u522b\u7684 \ubd88\ud655\uc2e4\uc131\uff0c\u5e76\u5728\u7f6e\u4fe1\u5ea6\u4f4e\u4e8e\u81ea\u9002\u5e94\u9608\u503c\u65f6\u8c03\u7528\u4ea4\u4e92\u5f0f\u6f84\u6e05\u5faa\u73af\u3002", "result": "\u4e00\u4e2a\u7ecf\u8fc7 100 \u4e2a \ubd88\ud655\uc2e4\uc131 \u8fc7\u6ee4\u793a\u4f8b\u5fae\u8c03\u7684\u8f7b\u91cf\u7ea7\u6a21\u578b\uff0c\u5728\u96f6\u6837\u672c\u6027\u80fd\u4e0a\u8d85\u8d8a\u4e86 GPT-4.1\uff0c\u5e76\u5c06\u63a8\u7406\u5ef6\u8fdf\u7f29\u77ed\u4e86\u8fd1 50%\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u5c06\u53ef\u53ca\u7684\u81ea\u7136\u8bed\u8a00\u5bf9\u8bdd\u4e0e\u5bf9\u76ee\u6807\u89e3\u91ca\u7684\u53ef\u9a8c\u8bc1\u4fdd\u8bc1\u76f8\u7ed3\u5408\uff0c\u4ee5\u5b9e\u73b0\u53ef\u8ba4\u8bc1\u3001\u5b9e\u65f6\u3001\u7528\u6237\u5bf9\u9f50\u7684\u590d\u6742\u7269\u6d41\u51b3\u7b56\u3002"}}
{"id": "2507.11216", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.11216", "abs": "https://arxiv.org/abs/2507.11216", "authors": ["Valle Ruiz-Fern\u00e1ndez", "Mario Mina", "J\u00falia Falc\u00e3o", "Luis Vasquez-Reina", "Anna Sall\u00e9s", "Aitor Gonzalez-Agirre", "Olatz Perez-de-Vi\u00f1aspre"], "title": "EsBBQ and CaBBQ: The Spanish and Catalan Bias Benchmarks for Question Answering", "comment": null, "summary": "Previous literature has largely shown that Large Language Models (LLMs)\nperpetuate social biases learnt from their pre-training data. Given the notable\nlack of resources for social bias evaluation in languages other than English,\nand for social contexts outside of the United States, this paper introduces the\nSpanish and the Catalan Bias Benchmarks for Question Answering (EsBBQ and\nCaBBQ). Based on the original BBQ, these two parallel datasets are designed to\nassess social bias across 10 categories using a multiple-choice QA setting, now\nadapted to the Spanish and Catalan languages and to the social context of\nSpain. We report evaluation results on different LLMs, factoring in model\nfamily, size and variant. Our results show that models tend to fail to choose\nthe correct answer in ambiguous scenarios, and that high QA accuracy often\ncorrelates with greater reliance on social biases.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f15\u5165\u4e86\u897f\u73ed\u7259\u8bed\u548c\u52a0\u6cf0\u7f57\u5c3c\u4e9a\u8bed\u7684\u504f\u89c1\u8bc4\u4f30\u6570\u636e\u96c6\uff08EsBBQ\u548cCaBBQ\uff09\uff0c\u4ee5\u89e3\u51b3\u7f3a\u4e4f\u975e\u82f1\u8bed\u504f\u89c1\u8bc4\u4f30\u8d44\u6e90\u7684\u95ee\uff0c\u8bc4\u4f30\u4e86\u591a\u79cdLLM\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u6a21\u7cca\u573a\u666f\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u5e76\u4e14\u51c6\u786e\u7387\u4e0e\u504f\u89c1\u76f8\u5173\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u82f1\u8bed\u4ee5\u5916\u8bed\u8a00\u548c\u793e\u4f1a\u80cc\u666f\uff08\u5982\u897f\u73ed\u7259\uff09\u7f3a\u4e4f\u793e\u4f1a\u504f\u89c1\u8bc4\u4f30\u8d44\u6e90\u7684\u4e0d\u8db3\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u897f\u73ed\u7259\u8bed\u548c\u52a0\u6cf0\u7f57\u5c3c\u4e9a\u8bed\u504f\u89c1\u95ee\u7b54\u57fa\u51c6\uff08EsBBQ\u548cCaBBQ\uff09\uff0c\u57fa\u4e8e\u539f\u59cbBBQ\u6570\u636e\u96c6\uff0c\u8bbe\u8ba1\u4e86\u5305\u542b10\u4e2a\u7c7b\u522b\u7684\u591a\u9879\u9009\u62e9\u95ee\u7b54\u4efb\u52a1\uff0c\u4ee5\u8bc4\u4f30LLM\u5728\u897f\u73ed\u7259\u8bed\u548c\u52a0\u6cf0\u7f57\u5c3c\u4e9a\u8bed\u4e2d\u7684\u793e\u4f1a\u504f\u89c1\u3002", "result": "\u62a5\u544a\u4e86\u4e0d\u540cLLM\uff08\u8003\u8651\u6a21\u578b\u5bb6\u65cf\u3001\u5927\u5c0f\u548c\u53d8\u4f53\uff09\u7684\u8bc4\u4f30\u7ed3\u679c\uff0c\u8868\u660e\u6a21\u578b\u5728\u6a21\u7cca\u573a\u666f\u4e0b\u5bb9\u6613\u51fa\u9519\uff0c\u4e14\u9ad8\u51c6\u786e\u7387\u4e0e\u66f4\u591a\u7684\u793e\u4f1a\u504f\u89c1\u76f8\u5173\u3002", "conclusion": "LLM\u5728\u897f\u73ed\u7259\u8bed\u548c\u52a0\u6cf0\u7f57\u5c3c\u4e9a\u8bed\u7684\u7279\u5b9a\u793e\u4f1a\u80cc\u666f\u4e0b\uff0c\u5728\u6a21\u7cca\u573a\u666f\u4e0b\u5bb9\u6613\u51fa\u9519\uff0c\u5e76\u4e14\u9ad8\u51c6\u786e\u7387\u5f80\u5f80\u4e0e\u66f4\u5927\u7684\u793e\u4f1a\u504f\u89c1\u76f8\u5173\u8054\u3002"}}
{"id": "2507.10747", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10747", "abs": "https://arxiv.org/abs/2507.10747", "authors": ["Kaustubh Tangsali", "Rishikesh Ranade", "Mohammad Amin Nabian", "Alexey Kamenev", "Peter Sharpe", "Neil Ashton", "Ram Cherukuri", "Sanjay Choudhry"], "title": "A Benchmarking Framework for AI models in Automotive Aerodynamics", "comment": null, "summary": "In this paper, we introduce a benchmarking framework within the open-source\nNVIDIA PhysicsNeMo-CFD framework designed to systematically assess the\naccuracy, performance, scalability, and generalization capabilities of AI\nmodels for automotive aerodynamics predictions. The open extensible framework\nenables incorporation of a diverse set of metrics relevant to the\nComputer-Aided Engineering (CAE) community. By providing a standardized\nmethodology for comparing AI models, the framework enhances transparency and\nconsistency in performance assessment, with the overarching goal of improving\nthe understanding and development of these models to accelerate research and\ninnovation in the field. To demonstrate its utility, the framework includes\nevaluation of both surface and volumetric flow field predictions on three AI\nmodels: DoMINO, X-MeshGraphNet, and FIGConvNet using the DrivAerML dataset. It\nalso includes guidelines for integrating additional models and datasets, making\nit extensible for physically consistent metrics. This benchmarking study aims\nto enable researchers and industry professionals in selecting, refining, and\nadvancing AI-driven aerodynamic modeling approaches, ultimately fostering the\ndevelopment of more efficient, accurate, and interpretable solutions in\nautomotive aerodynamics", "AI": {"tldr": "\u8be5\u6846\u67b6\u901a\u8fc7\u63d0\u4f9b\u6807\u51c6\u5316\u7684\u65b9\u6cd5\u6765\u6bd4\u8f83AI\u6a21\u578b\uff0c\u589e\u5f3a\u4e86\u6027\u80fd\u8bc4\u4f30\u7684\u900f\u660e\u5ea6\u548c\u4e00\u81f4\u6027\uff0c\u65e8\u5728\u52a0\u901f\u8be5\u9886\u57df\u7684\u7814\u53d1\u548c\u521b\u65b0\u3002", "motivation": "\u4e3a\u4e86\u52a0\u901f\u8be5\u9886\u57df\u7684\u7814\u53d1\u548c\u521b\u65b0\uff0c\u63d0\u9ad8\u5bf9\u8fd9\u4e9b\u6a21\u578b\u7684\u7406\u89e3\u548c\u5f00\u53d1\u3002", "method": "\u5728\u5f00\u6e90NVIDIA PhysicsNeMo-CFD\u6846\u67b6\u5185\u5f15\u5165\u4e86\u4e00\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u7528\u4e8e\u7cfb\u7edf\u5730\u8bc4\u4f30AI\u6a21\u578b\u5728\u6c7d\u8f66\u7a7a\u6c14\u52a8\u529b\u5b66\u9884\u6d4b\u65b9\u9762\u7684\u51c6\u786e\u6027\u3001\u6027\u80fd\u3001\u53ef\u6269\u5c55\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002\u8be5\u6846\u67b6\u662f\u5f00\u653e\u4e14\u53ef\u6269\u5c55\u7684\uff0c\u80fd\u591f\u7eb3\u5165\u8ba1\u7b97\u673a\u8f85\u52a9\u5de5\u7a0b\uff08CAE\uff09\u793e\u533a\u76f8\u5173\u7684\u591a\u79cd\u5ea6\u91cf\u6807\u51c6\u3002\u901a\u8fc7\u63d0\u4f9b\u6807\u51c6\u5316\u7684\u65b9\u6cd5\u6765\u6bd4\u8f83AI\u6a21\u578b\uff0c\u8be5\u6846\u67b6\u589e\u5f3a\u4e86\u6027\u80fd\u8bc4\u4f30\u7684\u900f\u660e\u5ea6\u548c\u4e00\u81f4\u6027\u3002", "result": "\u8be5\u6846\u67b6\u901a\u8fc7\u5bf9\u8868\u9762\u548c\u4f53\u79ef\u6d41\u573a\u9884\u6d4b\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u5bf9\u4e09\u79cdAI\u6a21\u578b\uff08DoMINO\u3001X-MeshGraphNet\u548cFIGConvNet\uff09\u4f7f\u7528DrivAerML\u6570\u636e\u96c6\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u4ee5\u5c55\u793a\u5176\u6548\u7528\u3002\u5b83\u8fd8\u5305\u62ec\u4e86\u96c6\u6210\u5176\u4ed6\u6a21\u578b\u548c\u6570\u636e\u96c6\u7684\u6307\u5357\uff0c\u4f7f\u5176\u80fd\u591f\u901a\u8fc7\u7269\u7406\u4e0a\u4e00\u81f4\u7684\u6307\u6807\u8fdb\u884c\u6269\u5c55\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u5bf9\u8868\u9762\u548c\u4f53\u79ef\u6d41\u573a\u9884\u6d4b\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u5bf9\u4e09\u79cdAI\u6a21\u578b\uff08DoMINO\u3001X-MeshGraphNet\u548cFIGConvNet\uff09\u4f7f\u7528DrivAerML\u6570\u636e\u96c6\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u4ee5\u5c55\u793a\u5176\u6548\u7528\u3002\u5b83\u8fd8\u5305\u62ec\u4e86\u96c6\u6210\u5176\u4ed6\u6a21\u578b\u548c\u6570\u636e\u96c6\u7684\u6307\u5357\uff0c\u4f7f\u5176\u80fd\u591f\u901a\u8fc7\u7269\u7406\u4e0a\u4e00\u81f4\u7684\u6307\u6807\u8fdb\u884c\u6269\u5c55\u3002\u8fd9\u9879\u57fa\u51c6\u7814\u7a76\u65e8\u5728\u4f7f\u7814\u7a76\u4eba\u5458\u548c\u884c\u4e1a\u4e13\u4e1a\u4eba\u58eb\u80fd\u591f\u9009\u62e9\u3001\u4f18\u5316\u548c\u63a8\u8fdb\u7531AI\u9a71\u52a8\u7684\u7a7a\u6c14\u52a8\u529b\u5b66\u5efa\u6a21\u65b9\u6cd5\uff0c\u6700\u7ec8\u4fc3\u8fdb\u5728\u6c7d\u8f66\u7a7a\u6c14\u52a8\u529b\u5b66\u9886\u57df\u5f00\u53d1\u66f4\u9ad8\u6548\u3001\u66f4\u51c6\u786e\u548c\u66f4\u5177\u53ef\u89e3\u91ca\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.11089", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.11089", "abs": "https://arxiv.org/abs/2507.11089", "authors": ["Minsoo Kim", "Changhun Oh"], "title": "On the Fundamental Resource for Exponential Advantage in Quantum Channel Learning", "comment": null, "summary": "Quantum resources enable us to achieve an exponential advantage in learning\nthe properties of unknown physical systems by employing quantum memory. While\nentanglement with quantum memory is recognized as a necessary qualitative\nresource, its quantitative role remains less understood. In this work, we\ndistinguish between two fundamental resources provided by quantum memory --\nentanglement and ancilla qubits -- and analyze their separate contributions to\nthe sampling complexity of quantum learning. Focusing on the task of Pauli\nchannel learning, a prototypical example of quantum channel learning,\nremarkably, we prove that vanishingly small entanglement in the input state\nalready suffices to accomplish the learning task with only a polynomial number\nof channel queries in the number of qubits. In contrast, we show that without a\nsufficient number of ancilla qubits, even learning partial information about\nthe channel demands an exponentially large sample complexity. Thus, our\nfindings reveal that while a large amount of entanglement is not necessary, the\ndimension of the quantum memory is a crucial resource. Hence, by identifying\nhow the two resources contribute differently, our work offers deeper insight\ninto the nature of the quantum learning advantage.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.11075", "categories": ["cs.CV", "cs.AI", "I.4.9; I.5.4; J.3"], "pdf": "https://arxiv.org/pdf/2507.11075", "abs": "https://arxiv.org/abs/2507.11075", "authors": ["Chang Peng", "Yifei Zhou", "Huifeng Xi", "Shiqing Huang", "Chuangye Chen", "Jianming Yang", "Bao Yang", "Zhenyu Jiang"], "title": "Joint angle model based learning to refine kinematic human pose estimation", "comment": null, "summary": "Marker-free human pose estimation (HPE) has found increasing applications in\nvarious fields. Current HPE suffers from occasional errors in keypoint\nrecognition and random fluctuation in keypoint trajectories when analyzing\nkinematic human poses. The performance of existing deep learning-based models\nfor HPE refinement is considerably limited by inaccurate training datasets in\nwhich the keypoints are manually annotated. This paper proposed a novel method\nto overcome the difficulty through joint angle-based modeling. The key\ntechniques include: (i) A joint angle-based model of human pose, which is\nrobust to describe kinematic human poses; (ii) Approximating temporal variation\nof joint angles through high order Fourier series to get reliable \"ground\ntruth\"; (iii) A bidirectional recurrent network is designed as a\npost-processing module to refine the estimation of well-established HRNet.\nTrained with the high-quality dataset constructed using our method, the network\ndemonstrates outstanding performance to correct wrongly recognized joints and\nsmooth their spatiotemporal trajectories. Tests show that joint angle-based\nrefinement (JAR) outperforms the state-of-the-art HPE refinement network in\nchallenging cases like figure skating and breaking.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u5173\u8282\u89d2\u5ea6\u5efa\u6a21\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u5e76\u5229\u7528\u53cc\u5411\u5faa\u73af\u7f51\u7edc\u8fdb\u884c\u540e\u5904\u7406\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u65e0\u6807\u8bb0\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u4e2d\u7684\u5173\u952e\u70b9\u8bc6\u522b\u9519\u8bef\u548c\u8f68\u8ff9\u6ce2\u52a8\u95ee\u9898\uff0c\u5e76\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u573a\u666f\u4e2d\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u7684\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\uff08HPE\uff09\u5728\u5904\u7406\u8fd0\u52a8\u5b66\u4eba\u4f53\u59ff\u6001\u65f6\uff0c\u5728\u5173\u952e\u70b9\u8bc6\u522b\u548c\u8f68\u8ff9\u5e73\u6ed1\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002\u73b0\u6709\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u65b9\u6cd5\u53d7\u9650\u4e8e\u624b\u52a8\u6807\u6ce8\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u4e0d\u51c6\u786e\u6027\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u5173\u8282\u89d2\u5ea6\u5efa\u6a21\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u73b0\u6709\u65e0\u6807\u8bb0\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\uff08HPE\uff09\u4e2d\u5b58\u5728\u7684\u5173\u952e\u70b9\u8bc6\u522b\u9519\u8bef\u548c\u8f68\u8ff9\u968f\u673a\u6ce2\u52a8\u95ee\u9898\u3002\u5177\u4f53\u6280\u672f\u5305\u62ec\uff1a1. \u63d0\u51fa\u4e00\u79cd\u7a33\u5065\u7684\u3001\u7528\u4e8e\u63cf\u8ff0\u8fd0\u52a8\u5b66\u4eba\u4f53\u59ff\u6001\u7684\u57fa\u4e8e\u5173\u8282\u89d2\u5ea6\u7684\u6a21\u578b\u30022. \u5229\u7528\u9ad8\u9636\u5085\u91cc\u53f6\u7ea7\u6570\u8fd1\u4f3c\u5173\u8282\u89d2\u5ea6\u7684\u65f6\u95f4\u53d8\u5316\uff0c\u4ee5\u83b7\u5f97\u53ef\u9760\u7684\u201c\u771f\u5b9e\u201d\u6807\u7b7e\u30023. \u8bbe\u8ba1\u4e86\u4e00\u4e2a\u53cc\u5411\u5faa\u73af\u7f51\u7edc\u4f5c\u4e3a\u540e\u5904\u7406\u6a21\u5757\uff0c\u4ee5\u4f18\u5316\u73b0\u6709HRNet\u7684\u4f30\u8ba1\u7ed3\u679c\u3002", "result": "\u5728\u6240\u6784\u5efa\u7684\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u53cc\u5411\u5faa\u73af\u7f51\u7edc\uff0c\u5728\u4fee\u6b63\u9519\u8bef\u8bc6\u522b\u7684\u5173\u8282\u548c\u8f68\u8ff9\u5e73\u6ed1\u65b9\u9762\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u5728\u82b1\u6837\u6ed1\u51b0\u548c\u8857\u821e\u7b49\u5177\u6709\u6311\u6218\u6027\u7684\u573a\u666f\u4e2d\uff0c\u5176\u57fa\u4e8e\u5173\u8282\u89d2\u5ea6\u7684\u4f18\u5316\uff08JAR\uff09\u65b9\u6cd5\u7684\u8868\u73b0\u4f18\u4e8e\u6700\u5148\u8fdb\u7684HPE\u4f18\u5316\u7f51\u7edc\u3002", "conclusion": "\u901a\u8fc7\u4f7f\u7528\u57fa\u4e8e\u5173\u8282\u89d2\u5ea6\u7684\u5efa\u6a21\u548c\u9ad8\u9636\u5085\u91cc\u53f6\u7ea7\u6570\u6765\u8fd1\u4f3c\u5173\u8282\u89d2\u5ea6\u7684\u65f6\u95f4\u53d8\u5316\uff0c\u6211\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u96c6\uff0c\u5e76\u8bad\u7ec3\u4e86\u4e00\u4e2a\u53cc\u5411\u5faa\u73af\u7f51\u7edc\u4f5c\u4e3a\u540e\u5904\u7406\u6a21\u5757\uff0c\u4ee5\u4f18\u5316\u73b0\u6709\u7684\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u65b9\u6cd5\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4fee\u6b63\u9519\u8bef\u8bc6\u522b\u7684\u5173\u8282\u548c \u0924\u094d\u092f\u093e\u0902\u091a\u094d\u092f\u093e\u65f6\u7a7a\u8f68\u8ff9\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e14\u5728\u82b1\u6837\u6ed1\u51b0\u548c\u8857\u821e\u7b49\u5177\u6709\u6311\u6218\u6027\u7684\u573a\u666f\u4e2d\u4f18\u4e8e\u73b0\u6709\u7684\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u4f18\u5316\u7f51\u7edc\u3002"}}
{"id": "2507.11467", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.11467", "abs": "https://arxiv.org/abs/2507.11467", "authors": ["Daniel Nichols", "Konstantinos Parasyris", "Harshitha Menon", "Brian R. Bartoldson", "Giorgis Georgakoudis", "Tal Ben-Nun", "Abhinav Bhatele"], "title": "Modeling Code: Is Text All You Need?", "comment": null, "summary": "Code LLMs have become extremely popular recently for modeling source code\nacross a variety of tasks, such as generation, translation, and summarization.\nHowever, transformer-based models are limited in their capabilities to reason\nthrough structured, analytical properties of code, such as control and data\nflow. Previous work has explored the modeling of these properties with\nstructured data and graph neural networks. However, these approaches lack the\ngenerative capabilities and scale of modern LLMs. In this work, we introduce a\nnovel approach to combine the strengths of modeling both code as text and more\nstructured forms.", "AI": {"tldr": "\u4ee3\u7801\u5927\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u3001\u7ffb\u8bd1\u548c\u6458\u8981\u7b49\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u63a8\u7406\u4ee3\u7801\u7684\u63a7\u5236\u6d41\u548c\u6570\u636e\u6d41\u7b49\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4ee3\u7801\u6587\u672c\u548c\u7ed3\u6784\u5316\u8868\u793a\u7684\u65b0\u65b9\u6cd5\uff0c\u4ee5\u514b\u670d\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8eTransformer\u7684\u4ee3\u7801\u5927\u6a21\u578b\u5728\u7406\u89e3\u548c\u63a8\u7406\u4ee3\u7801\u7684\u7ed3\u6784\u5316\u3001\u5206\u6790\u5c5e\u6027\uff08\u5982\u63a7\u5236\u6d41\u548c\u6570\u636e\u6d41\uff09\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002\u800c\u4ee5\u5f80\u5229\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u7b49\u65b9\u6cd5\u5904\u7406\u7ed3\u6784\u5316\u6570\u636e\u7684\u65b9\u6cd5\uff0c\u53c8\u7f3a\u4e4f\u5927\u6a21\u578b\u7684\u751f\u6210\u80fd\u529b\u548c\u89c4\u6a21\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4ee3\u7801\u6587\u672c\u548c\u7ed3\u6784\u5316\u8868\u793a\u7684\u65b0\u65b9\u6cd5\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u4ee3\u7801\u4f5c\u4e3a\u6587\u672c\u8fdb\u884c\u5efa\u6a21\u548c\u7ed3\u6784\u5316\u8868\u793a\u7684\u4f18\u70b9\u3002", "conclusion": "\u9700\u8981\u7ed3\u5408\u4ee3\u7801\u7684\u6587\u672c\u8868\u793a\u548c\u7ed3\u6784\u5316\u8868\u793a\u7684\u4f18\u70b9\uff0c\u4ee5\u5b9e\u73b0\u66f4\u5f3a\u5927\u7684\u4ee3\u7801\u5927\u6a21\u578b\u3002"}}
{"id": "2507.11222", "categories": ["cs.CL", "cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2507.11222", "abs": "https://arxiv.org/abs/2507.11222", "authors": ["Fares Wael", "Youssef Maklad", "Ali Hamdi", "Wael Elsersy"], "title": "An Agentic Flow for Finite State Machine Extraction using Prompt Chaining", "comment": null, "summary": "Finite-State Machines (FSMs) are critical for modeling the operational logic\nof network protocols, enabling verification, analysis, and vulnerability\ndiscovery. However, existing FSM extraction techniques face limitations such as\nscalability, incomplete coverage, and ambiguity in natural language\nspecifications. In this paper, we propose FlowFSM, a novel agentic framework\nthat leverages Large Language Models (LLMs) combined with prompt chaining and\nchain-of-thought reasoning to extract accurate FSMs from raw RFC documents.\nFlowFSM systematically processes protocol specifications, identifies state\ntransitions, and constructs structured rule-books by chaining agent outputs.\nExperimental evaluation across FTP and RTSP protocols demonstrates that FlowFSM\nachieves high extraction precision while minimizing hallucinated transitions,\nshowing promising results. Our findings highlight the potential of agent-based\nLLM systems in the advancement of protocol analysis and FSM inference for\ncybersecurity and reverse engineering applications.", "AI": {"tldr": "FlowFSM\u5229\u7528LLMs\u548c\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u793a\u94fe\u548c\u601d\u7ef4\u94fe\u63a8\u7406\uff0c\u4eceRFC\u6587\u6863\u4e2d\u63d0\u53d6\u51c6\u786e\u7684FSM\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6280\u672f\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709FSM\u63d0\u53d6\u6280\u672f\u5728\u53ef\u6269\u5c55\u6027\u3001\u8986\u76d6\u8303\u56f4\u548c\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u7684\u6a21\u7cca\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFlowFSM\u7684\u65b0\u578b\u4ee3\u7406\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u3001\u63d0\u793a\u94fe\u548c\u601d\u7ef4\u94fe\u63a8\u7406\uff0c\u7528\u4e8e\u4ece\u539f\u59cbRFC\u6587\u6863\u4e2d\u63d0\u53d6\u7cbe\u786e\u7684\u6709\u9650\u72b6\u6001\u673a\uff08FSM\uff09\u3002FlowFSM\u901a\u8fc7\u94fe\u63a5\u4ee3\u7406\u8f93\u51fa\u6765\u7cfb\u7edf\u5730\u5904\u7406\u534f\u8bae\u89c4\u8303\u3001\u8bc6\u522b\u72b6\u6001\u8f6c\u6362\u548c\u6784\u5efa\u7ed3\u6784\u5316\u89c4\u5219\u624b\u518c\u3002", "result": "FlowFSM\u5728FTP\u548cRTSP\u534f\u8bae\u7684\u5b9e\u9a8c\u8bc4\u4f30\u4e2d\uff0c\u5b9e\u73b0\u4e86\u9ad8\u63d0\u53d6\u7cbe\u5ea6\uff0c\u5e76\u6700\u5927\u9650\u5ea6\u5730\u51cf\u5c11\u4e86\u5e7b\u89c9\u8f6c\u6362\uff0c\u5c55\u793a\u4e86\u5176\u5728\u534f\u8bae\u5206\u6790\u548c\u7f51\u7edc\u5b89\u5168\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "FlowFSM\u5728FTP\u548cRTSP\u534f\u8bae\u7684\u5b9e\u9a8c\u8bc4\u4f30\u4e2d\uff0c\u5b9e\u73b0\u4e86\u9ad8\u63d0\u53d6\u7cbe\u5ea6\uff0c\u5e76\u6700\u5927\u9650\u5ea6\u5730\u51cf\u5c11\u4e86\u5e7b\u89c9\u8f6c\u6362\uff0c\u5c55\u793a\u4e86\u5176\u5728\u534f\u8bae\u5206\u6790\u548c\u7f51\u7edc\u5b89\u5168\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.10768", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10768", "abs": "https://arxiv.org/abs/2507.10768", "authors": ["Bart Pogodzinski", "Christopher Wewer", "Bernt Schiele", "Jan Eric Lenssen"], "title": "Spatial Reasoners for Continuous Variables in Any Domain", "comment": "For the project documentation see https://spatialreasoners.github.io/\n  . The SRM project website is available at\n  https://geometric-rl.mpi-inf.mpg.de/srm/ . The work was published on ICML\n  2025 CODEML workshop", "summary": "We present Spatial Reasoners, a software framework to perform spatial\nreasoning over continuous variables with generative denoising models. Denoising\ngenerative models have become the de-facto standard for image generation, due\nto their effectiveness in sampling from complex, high-dimensional\ndistributions. Recently, they have started being explored in the context of\nreasoning over multiple continuous variables. Providing infrastructure for\ngenerative reasoning with such models requires a high effort, due to a wide\nrange of different denoising formulations, samplers, and inference strategies.\nOur presented framework aims to facilitate research in this area, providing\neasy-to-use interfaces to control variable mapping from arbitrary data domains,\ngenerative model paradigms, and inference strategies. Spatial Reasoners are\nopenly available at https://spatialreasoners.github.io/", "AI": {"tldr": "Spatial Reasoners \u662f\u4e00\u4e2a\u7528\u4e8e\u751f\u6210\u5f0f\u7a7a\u95f4\u63a8\u7406\u7684\u8f6f\u4ef6\u6846\u67b6\uff0c\u7b80\u5316\u4e86\u4f7f\u7528\u53bb\u566a\u6a21\u578b\u5904\u7406\u8fde\u7eed\u53d8\u91cf\u7684\u8fc7\u7a0b\u3002", "motivation": "\u7531\u4e8e\u5b58\u5728\u591a\u79cd\u53bb\u566a\u6a21\u578b\u3001\u91c7\u6837\u5668\u548c\u63a8\u7406\u7b56\u7565\uff0c\u56e0\u6b64\u4e3a\u751f\u6210\u5f0f\u63a8\u7406\u63d0\u4f9b\u57fa\u7840\u8bbe\u65bd\u9700\u8981\u4ed8\u51fa\u5de8\u5927\u7684\u52aa\u529b\u3002\u8be5\u6846\u67b6\u65e8\u5728\u7b80\u5316\u8fd9\u4e00\u8fc7\u7a0b\u3002", "method": "\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u6613\u4e8e\u4f7f\u7528\u7684\u63a5\u53e3\u6765\u63a7\u5236\u53d8\u91cf\u6620\u5c04\uff08\u4ece\u4efb\u610f\u6570\u636e\u57df\u5230\u751f\u6210\u6a21\u578b\u8303\u5f0f\uff09\u548c\u63a8\u7406\u7b56\u7565\u3002", "result": "\u8be5\u6846\u67b6\u5141\u8bb8\u7814\u7a76\u4eba\u5458\u8f7b\u677e\u5730\u5c06\u4efb\u610f\u6570\u636e\u57df\u4e2d\u7684\u53d8\u91cf\u6620\u5c04\u5230\u751f\u6210\u6a21\u578b\u8303\u5f0f\uff0c\u5e76\u63a7\u5236\u63a8\u7406\u7b56\u7565\uff0c\u4ece\u800c\u4fc3\u8fdb\u4e86\u751f\u6210\u5f0f\u63a8\u7406\u7684\u7814\u7a76\u3002", "conclusion": "Spatial Reasoners \u662f\u4e00\u4e2a\u5f00\u6e90\u8f6f\u4ef6\u6846\u67b6\uff0c\u65e8\u5728\u4f7f\u7528\u751f\u6210\u5f0f\u53bb\u566a\u6a21\u578b\u5bf9\u8fde\u7eed\u53d8\u91cf\u8fdb\u884c\u7a7a\u95f4\u63a8\u7406\uff0c\u65e8\u5728\u4fc3\u8fdb\u8be5\u9886\u57df\u7684\u7814\u7a76\u3002"}}
{"id": "2507.11460", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.11460", "abs": "https://arxiv.org/abs/2507.11460", "authors": ["Jacinto Colan", "Ana Davila", "Yutaro Yamada", "Yasuhisa Hasegawa"], "title": "Human-Robot collaboration in surgery: Advances and challenges towards autonomous surgical assistants", "comment": "Accepted at 2025 IEEE International Conference on Robot and Human\n  Interactive Communication (ROMAN)", "summary": "Human-robot collaboration in surgery represents a significant area of\nresearch, driven by the increasing capability of autonomous robotic systems to\nassist surgeons in complex procedures. This systematic review examines the\nadvancements and persistent challenges in the development of autonomous\nsurgical robotic assistants (ASARs), focusing specifically on scenarios where\nrobots provide meaningful and active support to human surgeons. Adhering to the\nPRISMA guidelines, a comprehensive literature search was conducted across the\nIEEE Xplore, Scopus, and Web of Science databases, resulting in the selection\nof 32 studies for detailed analysis. Two primary collaborative setups were\nidentified: teleoperation-based assistance and direct hands-on interaction. The\nfindings reveal a growing research emphasis on ASARs, with predominant\napplications currently in endoscope guidance, alongside emerging progress in\nautonomous tool manipulation. Several key challenges hinder wider adoption,\nincluding the alignment of robotic actions with human surgeon preferences, the\nnecessity for procedural awareness within autonomous systems, the establishment\nof seamless human-robot information exchange, and the complexities of skill\nacquisition in shared workspaces. This review synthesizes current trends,\nidentifies critical limitations, and outlines future research directions\nessential to improve the reliability, safety, and effectiveness of human-robot\ncollaboration in surgical environments.", "AI": {"tldr": "\u672c\u7cfb\u7edf\u7efc\u8ff0\u68c0\u89c6\u4e86\u81ea\u4e3b\u624b\u672f\u673a\u5668\u4eba\u52a9\u624b\uff08ASAR\uff09\u5728\u4eba\u673a\u534f\u4f5c\u5916\u79d1\u624b\u672f\u9886\u57df\u7684\u8fdb\u5c55\u4e0e\u6311\u6218\uff0c\u91cd\u70b9\u5173\u6ce8\u4e86\u673a\u5668\u4eba\u63d0\u4f9b\u6709\u610f\u4e49\u8f85\u52a9\u7684\u573a\u666f\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5c3d\u7ba1ASAR\u5728\u5185\u7aa5\u955c\u5f15\u5bfc\u7b49\u65b9\u9762\u7684\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u4ecd\u9762\u4e34\u52a8\u4f5c\u534f\u8c03\u3001\u624b\u672f\u610f\u8bc6\u3001\u4fe1\u606f\u4ea4\u6362\u548c\u6280\u80fd\u83b7\u53d6\u7b49\u65b9\u9762\u7684\u6311\u6218\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u7684\u65b9\u5411\u3002", "motivation": "\u65e8\u5728\u68c0\u67e5\u81ea\u4e3b\u624b\u672f\u673a\u5668\u4eba\u52a9\u624b\uff08ASAR\uff09\u7684\u53d1\u5c55\u8fdb\u5c55\u548c\u6301\u7eed\u6311\u6218\uff0c\u7279\u522b\u5173\u6ce8\u673a\u5668\u4eba\u4e3a\u4e3b\u7684\u63d0\u4f9b\u6709\u610f\u4e49\u548c\u79ef\u6781\u652f\u6301\u7684\u4eba\u7c7b\u5916\u79d1\u533b\u751f\u3002", "method": "\u91c7\u7528PRISMA\u6307\u5357\uff0c\u5728IEEE Xplore\u3001Scopus\u548cWeb of Science\u6570\u636e\u5e93\u4e2d\u8fdb\u884c\u4e86\u5168\u9762\u7684\u6587\u732e\u68c0\u7d22\uff0c\u6700\u7ec8\u9009\u5b9a\u4e8632\u9879\u7814\u7a76\u8fdb\u884c\u8be6\u7ec6\u5206\u6790\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5bf9ASAR\u7684\u5173\u6ce8\u65e5\u76ca\u589e\u957f\uff0c\u4e3b\u8981\u5e94\u7528\u5728\u5185\u7aa5\u955c\u5f15\u5bfc\uff0c\u5e76\u5728\u81ea\u4e3b\u5de5\u5177\u64cd\u4f5c\u65b9\u9762\u53d6\u5f97\u4e86\u65b0\u8fdb\u5c55\u3002\u7136\u800c\uff0c\u673a\u5668\u4eba\u52a8\u4f5c\u4e0e\u5916\u79d1\u533b\u751f\u504f\u597d\u7684\u4e00\u81f4\u6027\u3001\u81ea\u4e3b\u7cfb\u7edf\u7684\u624b\u672f\u610f\u8bc6\u3001\u65e0\u7f1d\u4eba\u673a\u4fe1\u606f\u4ea4\u6362\u7684\u5efa\u7acb\u4ee5\u53ca\u5728\u5171\u4eab\u5de5\u4f5c\u7a7a\u95f4\u4e2d\u83b7\u5f97\u6280\u80fd\u7684\u590d\u6742\u6027\u7b49\u5173\u952e\u6311\u6218\u963b\u788d\u4e86ASAR\u7684\u5e7f\u6cdb\u5e94\u7528\u3002", "conclusion": "\u8be5\u7efc\u8ff0\u7efc\u5408\u4e86\u5f53\u524d\u8d8b\u52bf\uff0c\u660e\u786e\u4e86\u5173\u952e\u7684\u5c40\u9650\u6027\uff0c\u5e76\u6982\u8ff0\u4e86\u5bf9\u63d0\u9ad8\u624b\u672f\u73af\u5883\u4eba\u673a\u534f\u4f5c\u7684\u53ef\u9760\u6027\u3001\u5b89\u5168\u6027\u548c\u6709\u6548\u6027\u81f3\u5173\u91cd\u8981\u7684\u65b0\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2507.11142", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.11142", "abs": "https://arxiv.org/abs/2507.11142", "authors": ["Viktor Khinevich", "Yasunori Lee", "Nobuyuki Yoshioka", "Wataru Mizukami"], "title": "Quantum Power Iteration Unified Using Generalized Quantum Signal Processing", "comment": null, "summary": "We present a unifying framework for quantum power-method-based algorithms\nthrough the lens of generalized quantum signal processing (GQSP): we apply GQSP\nto realize quantum analogues of classical power iteration, power Lanczos,\ninverse iteration, and folded spectrum methods, all within a single coherent\nframework. Our approach is efficient in terms of the number of queries to the\nblock encoding of a Hamiltonian. Also, our approach can avoid Suzuki-Trotter\ndecomposition. We constructed quantum circuits for GQSP-based quantum power\nmethods, estimated the number of queries, and numerically verified that this\nframework works. We additionally benchmark various quantum power methods with\nmolecular Hamiltonians and demonstrate that Quantum Power Lanczos converges\nfaster and more reliably than standard Quantum Power Iteration, while Quantum\nInverse Iteration outperforms existing inverse iteration variants based on\ntime-evolution operators. We also show that the Quantum Folded Spectrum Method\ncan obtain excited states without variational optimization. Overall, our\nresults indicate that GQSP-based implementations of power methods combine\nscalability, flexibility, and robust convergence, paving the way for practical\ninitial state preparations on fault-tolerant quantum devices.", "AI": {"tldr": "GQSP\u7edf\u4e00\u4e86\u91cf\u5b50\u529f\u7387\u65b9\u6cd5\uff0c\u5728\u6548\u7387\u3001\u6536\u655b\u6027\u548c\u83b7\u5f97\u6fc0\u53d1\u6001\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5e7f\u4e49\u91cf\u5b50\u4fe1\u53f7\u5904\u7406\uff08GQSP\uff09\u6765\u5904\u7406\u57fa\u4e8e\u91cf\u5b50\u529f\u7387\u7684\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5e7f\u4e49\u91cf\u5b50\u4fe1\u53f7\u5904\u7406\uff08GQSP\uff09\u5b9e\u73b0\u4e86\u7ecf\u5178\u529f\u7387\u8fed\u4ee3\u3001\u529f\u7387Lanczos\u3001\u9006\u8fed\u4ee3\u548c\u6298\u53e0\u8c31\u65b9\u6cd5\u7684\u91cf\u5b50\u7c7b\u4f3c\u7269\u3002", "result": "GQSP\u4e3a\u57fa\u7840\u7684\u91cf\u5b50\u529f\u7387\u65b9\u6cd5\u7ed3\u5408\u4e86\u53ef\u6269\u5c55\u6027\u3001\u7075\u6d3b\u6027\u548c\u9c81\u68d2\u7684\u6536\u655b\u6027\uff0c\u5e76\u4e14\u5728\u5206\u5b50\u54c8\u5bc6\u987f\u91cf\u4e0a\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5176\u4e2d\u91cf\u5b50\u529f\u7387Lanczos\u6bd4\u6807\u51c6\u7684\u91cf\u5b50\u529f\u7387\u8fed\u4ee3\u6536\u655b\u66f4\u5feb\u3001\u66f4\u53ef\u9760\uff0c\u800c\u91cf\u5b50\u9006\u8fed\u4ee3\u4f18\u4e8e\u57fa\u4e8e\u65f6\u95f4\u6f14\u5316\u7b97\u5b50\u7684\u73b0\u6709\u9006\u8fed\u4ee3\u53d8\u4f53\u3002\u91cf\u5b50\u6298\u53e0\u8c31\u65b9\u6cd5\u53ef\u4ee5\u5728\u6ca1\u6709\u53d8\u5206\u4f18\u5316\u7684\u524d\u63d0\u4e0b\u83b7\u5f97\u6fc0\u53d1\u6001\u3002", "conclusion": "GQSP\u4f7f\u91cf\u5b50\u529f\u7387\u65b9\u6cd5\u5177\u6709\u53ef\u6269\u5c55\u6027\u3001\u7075\u6d3b\u6027\u548c\u9c81\u68d2\u7684\u6536\u655b\u6027\uff0c\u4e3a\u5bb9\u9519\u91cf\u5b50\u8bbe\u5907\u4e0a\u7684\u5b9e\u9645\u521d\u59cb\u72b6\u6001\u5236\u5907\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2507.11077", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11077", "abs": "https://arxiv.org/abs/2507.11077", "authors": ["Weizhao Ma", "Dong Zhou", "Yuhui Hu", "Zipeng He"], "title": "GKNet: Graph-based Keypoints Network for Monocular Pose Estimation of Non-cooperative Spacecraft", "comment": null, "summary": "Monocular pose estimation of non-cooperative spacecraft is significant for\non-orbit service (OOS) tasks, such as satellite maintenance, space debris\nremoval, and station assembly. Considering the high demands on pose estimation\naccuracy, mainstream monocular pose estimation methods typically consist of\nkeypoint detectors and PnP solver. However, current keypoint detectors remain\nvulnerable to structural symmetry and partial occlusion of non-cooperative\nspacecraft. To this end, we propose a graph-based keypoints network for the\nmonocular pose estimation of non-cooperative spacecraft, GKNet, which leverages\nthe geometric constraint of keypoints graph. In order to better validate\nkeypoint detectors, we present a moderate-scale dataset for the spacecraft\nkeypoint detection, named SKD, which consists of 3 spacecraft targets, 90,000\nsimulated images, and corresponding high-precise keypoint annotations.\nExtensive experiments and an ablation study have demonstrated the high accuracy\nand effectiveness of our GKNet, compared to the state-of-the-art spacecraft\nkeypoint detectors. The code for GKNet and the SKD dataset is available at\nhttps://github.com/Dongzhou-1996/GKNet.", "AI": {"tldr": "\u4e3a\u4e86\u89e3\u51b3\u975e\u5408\u4f5c\u822a\u5929\u5668\u59ff\u6001\u4f30\u8ba1\u7684\u6311\u6218\uff0c\u6211\u4eec\u63d0\u51fa\u4e86GKNet\uff0c\u4e00\u79cd\u5229\u7528\u56fe\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u548c\u5173\u952e\u70b9\u51e0\u4f55\u7ea6\u675f\u7684\u65b9\u6cd5\uff0c\u5e76\u5728\u65b0\u7684SKD\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6210\u679c\u3002", "motivation": "\u4e3a\u4e86\u6ee1\u8db3\u5728\u8f68\u670d\u52a1\u4efb\u52a1\uff08\u5982\u536b\u661f\u7ef4\u62a4\u3001\u7a7a\u95f4\u788e\u7247\u6e05\u9664\u548c\u7a7a\u95f4\u7ad9\u7ec4\u88c5\uff09\u5bf9\u59ff\u6001\u4f30\u8ba1\u7cbe\u5ea6\u7684\u8981\u6c42\uff0c\u4ee5\u53ca\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u975e\u5408\u4f5c\u822a\u5929\u5668\u65f6\u7684\u7ed3\u6784\u5bf9\u79f0\u6027\u548c\u90e8\u5206\u906e\u6321\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGKNet\u7684\u56fe\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u5229\u7528\u5173\u952e\u70b9\u56fe\u7684\u51e0\u4f55\u7ea6\u675f\u6765\u63d0\u9ad8\u59ff\u6001\u4f30\u8ba1\u7684\u7cbe\u5ea6\u3002\u540c\u65f6\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b3\u4e2a\u822a\u5929\u5668\u76ee\u6807\u300190,000\u5f20\u6a21\u62df\u56fe\u50cf\u548c\u5173\u952e\u70b9\u6807\u6ce8\u7684SKD\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u66f4\u597d\u5730\u9a8c\u8bc1\u5173\u952e\u70b9\u68c0\u6d4b\u5668\u3002", "result": "GKNet\u5728SKD\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u548c\u6d88\u878d\u7814\u7a76\uff0c\u8bc1\u660e\u4e86\u5176\u76f8\u6bd4\u4e8e\u6700\u5148\u8fdb\u7684\u822a\u5929\u5668\u5173\u952e\u70b9\u68c0\u6d4b\u5668\u5177\u6709\u66f4\u9ad8\u7684\u7cbe\u5ea6\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aGKNet\u7684\u56fe\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u7528\u4e8e\u89e3\u51b3\u975e\u5408\u4f5c\u822a\u5929\u5668\u7684\u5355\u76ee\u59ff\u6001\u4f30\u8ba1\u95ee\u9898\uff0c\u5e76\u5728SKD\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u7cbe\u5ea6\u548c\u6709\u6548\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.11473", "categories": ["cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.11473", "abs": "https://arxiv.org/abs/2507.11473", "authors": ["Tomek Korbak", "Mikita Balesni", "Elizabeth Barnes", "Yoshua Bengio", "Joe Benton", "Joseph Bloom", "Mark Chen", "Alan Cooney", "Allan Dafoe", "Anca Dragan", "Scott Emmons", "Owain Evans", "David Farhi", "Ryan Greenblatt", "Dan Hendrycks", "Marius Hobbhahn", "Evan Hubinger", "Geoffrey Irving", "Erik Jenner", "Daniel Kokotajlo", "Victoria Krakovna", "Shane Legg", "David Lindner", "David Luan", "Aleksander M\u0105dry", "Julian Michael", "Neel Nanda", "Dave Orr", "Jakub Pachocki", "Ethan Perez", "Mary Phuong", "Fabien Roger", "Joshua Saxe", "Buck Shlegeris", "Mart\u00edn Soto", "Eric Steinberger", "Jasmine Wang", "Wojciech Zaremba", "Bowen Baker", "Rohin Shah", "Vlad Mikulik"], "title": "Chain of Thought Monitorability: A New and Fragile Opportunity for AI Safety", "comment": null, "summary": "AI systems that \"think\" in human language offer a unique opportunity for AI\nsafety: we can monitor their chains of thought (CoT) for the intent to\nmisbehave. Like all other known AI oversight methods, CoT monitoring is\nimperfect and allows some misbehavior to go unnoticed. Nevertheless, it shows\npromise and we recommend further research into CoT monitorability and\ninvestment in CoT monitoring alongside existing safety methods. Because CoT\nmonitorability may be fragile, we recommend that frontier model developers\nconsider the impact of development decisions on CoT monitorability.", "AI": {"tldr": "AI\u5b89\u5168\u65b0\u65b9\u6cd5\uff1a\u901a\u8fc7\u76d1\u6d4b\u201c\u601d\u8003\u201d\u94fe\uff08CoT\uff09\u6765\u53d1\u73b0\u4e0d\u826f\u610f\u56fe\uff0c\u6709\u6f5c\u529b\u4f46\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002", "motivation": "AI\u7cfb\u7edf\u80fd\u591f\u7528\u4eba\u7c7b\u8bed\u8a00\u601d\u8003\uff0c\u4e3aAI\u5b89\u5168\u63d0\u4f9b\u4e86\u65b0\u7684\u9014\u5f84\uff0c\u5373\u901a\u8fc7\u76d1\u6d4b\u5176\u601d\u8003\u94fe\u6765\u53d1\u73b0\u4e0d\u826f\u610f\u56fe\u3002", "method": "\u901a\u8fc7\u76d1\u6d4bAI\u7684\u201c\u601d\u8003\u201d\u94fe\uff08CoT\uff09\u6765\u53d1\u73b0\u5176\u4e0d\u826f\u610f\u56fe\u3002", "result": "CoT\u76d1\u6d4b\u867d\u7136\u4e0d\u5b8c\u7f8e\uff0c\u4f46\u4ecd\u6709\u6f5c\u529b\uff0c\u5efa\u8bae\u8fdb\u4e00\u6b65\u7814\u7a76CoT\u7684\u53ef\u76d1\u6d4b\u6027\uff0c\u5e76\u4e0e\u73b0\u6709\u5b89\u5168\u65b9\u6cd5\u4e00\u540c\u8fdb\u884c\u6295\u5165\u3002\u540c\u65f6\uff0c\u5efa\u8bae\u524d\u7aef\u6a21\u578b\u5f00\u53d1\u8005\u5728\u505a\u5f00\u53d1\u51b3\u7b56\u65f6\u8003\u8651\u5176\u5bf9CoT\u53ef\u76d1\u6d4b\u6027\u7684\u5f71\u54cd\uff0c\u56e0\u4e3a\u8be5\u65b9\u6cd5\u53ef\u80fd\u4e0d\u7a33\u5b9a\u3002", "conclusion": "AI\u7cfb\u7edf\u53ef\u4ee5\u901a\u8fc7\u76d1\u6d4b\u5176\u201c\u601d\u8003\u201d\u94fe\uff08CoT\uff09\u6765\u76d1\u63a7\u4e0d\u826f\u884c\u4e3a\uff0c\u867d\u7136\u6b64\u65b9\u6cd5\u4e0d\u5b8c\u7f8e\uff0c\u4f46\u4ecd\u6709\u6f5c\u529b\uff0c\u5e94\u4e0e\u73b0\u6709\u5b89\u5168\u65b9\u6cd5\u7ed3\u5408\u8fdb\u884c\u7814\u7a76\u548c\u6295\u8d44\u3002"}}
{"id": "2507.11230", "categories": ["cs.CL", "68T50"], "pdf": "https://arxiv.org/pdf/2507.11230", "abs": "https://arxiv.org/abs/2507.11230", "authors": ["Lyzander Marciano Andrylie", "Inaya Rahmanisa", "Mahardika Krisna Ihsani", "Alfan Farizki Wicaksono", "Haryo Akbarianto Wibowo", "Alham Fikri Aji"], "title": "Sparse Autoencoders Can Capture Language-Specific Concepts Across Diverse Languages", "comment": null, "summary": "Understanding the multilingual mechanisms of large language models (LLMs)\nprovides insight into how they process different languages, yet this remains\nchallenging. Existing studies often focus on individual neurons, but their\npolysemantic nature makes it difficult to isolate language-specific units from\ncross-lingual representations. To address this, we explore sparse autoencoders\n(SAEs) for their ability to learn monosemantic features that represent concrete\nand abstract concepts across languages in LLMs. While some of these features\nare language-independent, the presence of language-specific features remains\nunderexplored. In this work, we introduce SAE-LAPE, a method based on feature\nactivation probability, to identify language-specific features within the\nfeed-forward network. We find that many such features predominantly appear in\nthe middle to final layers of the model and are interpretable. These features\ninfluence the model's multilingual performance and language output and can be\nused for language identification with performance comparable to fastText along\nwith more interpretability. Our code is available at\nhttps://github.com/LyzanderAndrylie/language-specific-features .", "AI": {"tldr": "\u901a\u8fc7SAE-LAPE\u65b9\u6cd5\u8bc6\u522b\u4e86Transformer\u6a21\u578b\u4e2d\u7684\u8bed\u8a00\u7279\u5f02\u6027\u7279\u5f81\uff0c\u8fd9\u4e9b\u7279\u5f81\u53ef\u7528\u4e8e\u8bed\u8a00\u8bc6\u522b\uff0c\u6027\u80fd\u4f18\u8d8a\u4e14\u53ef\u89e3\u91ca\u6027\u5f3a\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u96be\u4ee5\u4ece\u591a\u4e49\u7684\u5355\u4e2a\u795e\u7ecf\u5143\u4e2d\u5206\u79bb\u51fa\u7279\u5b9a\u8bed\u8a00\u7684\u5355\u5143\uff0c\u800c\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAE\uff09\u80fd\u591f\u5b66\u4e60\u8de8\u8bed\u8a00\u7684\u5355\u4e49\u7279\u5f81\uff0c\u4f46\u5176\u8bed\u8a00\u7279\u5f02\u6027\u7279\u5f81\u4ecd\u6709\u5f85\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7279\u5f81\u6fc0\u6d3b\u6982\u7387\u7684SAE-LAPE\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc6\u522bTransformer\u6a21\u578b\u524d\u9988\u7f51\u7edc\u4e2d\u7684\u8bed\u8a00\u7279\u5f02\u6027\u7279\u5f81\u3002", "result": "\u53d1\u73b0\u4e86\u5927\u91cf\u53ef\u89e3\u91ca\u7684\u3001\u7279\u5b9a\u8bed\u8a00\u7684\u6fc0\u6d3b\u7279\u5f81\uff0c\u8fd9\u4e9b\u7279\u5f81\u4e3b\u8981\u51fa\u73b0\u5728\u6a21\u578b\u7684\u4e2d\u95f4\u5230\u6700\u540e\u51e0\u5c42\uff0c\u5e76\u4e14\u53ef\u4ee5\u7528\u4e8e\u8bed\u8a00\u8bc6\u522b\uff0c\u6027\u80fd\u4e0efastText\u76f8\u5f53\u4e14\u66f4\u5177\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5728Transformer\u6a21\u578b\u4e2d\uff0c\u5b58\u5728\u5927\u91cf\u53ef\u89e3\u91ca\u7684\u3001\u7279\u5b9a\u8bed\u8a00\u7684\u6fc0\u6d3b\u7279\u5f81\uff0c\u8fd9\u4e9b\u7279\u5f81\u4e3b\u8981\u51fa\u73b0\u5728\u6a21\u578b\u7684\u4e2d\u95f4\u5230\u6700\u540e\u51e0\u5c42\uff0c\u5b83\u4eec\u5f71\u54cd\u7740\u6a21\u578b\u7684\u8de8\u8bed\u8a00\u8868\u73b0\u548c\u8bed\u8a00\u8f93\u51fa\uff0c\u5e76\u4e14\u53ef\u4ee5\u7528\u4e8e\u8bed\u8a00\u8bc6\u522b\u4efb\u52a1\uff0c\u5176\u6027\u80fd\u53ef\u4e0efastText\u5ab2\u7f8e\uff0c\u540c\u65f6\u5177\u6709\u66f4\u597d\u7684\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2507.10792", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10792", "abs": "https://arxiv.org/abs/2507.10792", "authors": ["Yuchen Wang", "Hongjue Zhao", "Haohong Lin", "Enze Xu", "Lifang He", "Huajie Shao"], "title": "A Generalizable Physics-Enhanced State Space Model for Long-Term Dynamics Forecasting in Complex Environments", "comment": "8 pages, 6 figures, accepted in ICML 2025", "summary": "This work aims to address the problem of long-term dynamic forecasting in\ncomplex environments where data are noisy and irregularly sampled. While recent\nstudies have introduced some methods to improve prediction performance, these\napproaches still face a significant challenge in handling long-term\nextrapolation tasks under such complex scenarios. To overcome this challenge,\nwe propose Phy-SSM, a generalizable method that integrates partial physics\nknowledge into state space models (SSMs) for long-term dynamics forecasting in\ncomplex environments. Our motivation is that SSMs can effectively capture\nlong-range dependencies in sequential data and model continuous dynamical\nsystems, while the incorporation of physics knowledge improves generalization\nability. The key challenge lies in how to seamlessly incorporate partially\nknown physics into SSMs. To achieve this, we decompose partially known system\ndynamics into known and unknown state matrices, which are integrated into a\nPhy-SSM unit. To further enhance long-term prediction performance, we introduce\na physics state regularization term to make the estimated latent states align\nwith system dynamics. Besides, we theoretically analyze the uniqueness of the\nsolutions for our method. Extensive experiments on three real-world\napplications, including vehicle motion prediction, drone state prediction, and\nCOVID-19 epidemiology forecasting, demonstrate the superior performance of\nPhy-SSM over the baselines in both long-term interpolation and extrapolation\ntasks. The code is available at https://github.com/511205787/Phy_SSM-ICML2025.", "AI": {"tldr": "\u63d0\u51faPhy-SSM\uff0c\u4e00\u79cd\u7ed3\u5408\u7269\u7406\u77e5\u8bc6\u548c\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff08SSM\uff09\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5904\u7406\u590d\u6742\u73af\u5883\u4e2d\u6570\u636e\u566a\u58f0\u5927\u3001\u91c7\u6837\u4e0d\u89c4\u5219\u7684\u957f\u671f\u52a8\u6001\u9884\u6d4b\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5c06\u90e8\u5206\u7269\u7406\u77e5\u8bc6\u878d\u5165SSM\uff0c\u5e76\u5f15\u5165\u7269\u7406\u72b6\u6001\u6b63\u5219\u5316\u9879\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u548c\u957f\u671f\u9884\u6d4b\u80fd\u529b\uff0c\u5728\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u573a\u666f\u4e0b\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "SSM\u80fd\u591f\u6709\u6548\u5730\u6355\u6349\u5e8f\u5217\u6570\u636e\u4e2d\u7684\u957f\u671f\u4f9d\u8d56\u5173\u7cfb\u5e76\u5bf9\u8fde\u7eed\u52a8\u6001\u7cfb\u7edf\u8fdb\u884c\u5efa\u6a21\uff0c\u800c\u5f15\u5165\u7269\u7406\u77e5\u8bc6\u53ef\u4ee5\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPhy-SSM\u7684\u901a\u7528\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5c06\u90e8\u5206\u7269\u7406\u77e5\u8bc6\u96c6\u6210\u5230\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff08SSM\uff09\u4e2d\uff0c\u7528\u4e8e\u590d\u6742\u73af\u5883\u4e2d\u7684\u957f\u671f\u52a8\u6001\u9884\u6d4b\u3002\u5177\u4f53\u5730\uff0c\u5c06\u90e8\u5206\u5df2\u77e5\u7684\u7cfb\u7edf\u52a8\u6001\u5206\u89e3\u4e3a\u5df2\u77e5\u7684\u548c\u672a\u77e5\u7684\u72b6\u6001\u77e9\u9635\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230Phy-SSM\u5355\u5143\u4e2d\u3002\u6b64\u5916\uff0c\u5f15\u5165\u4e86\u4e00\u4e2a\u7269\u7406\u72b6\u6001\u6b63\u5219\u5316\u9879\uff0c\u4f7f\u4f30\u8ba1\u7684\u6f5c\u5728\u72b6\u6001\u4e0e\u7cfb\u7edf\u52a8\u6001\u5bf9\u9f50\uff0c\u5e76\u4ece\u7406\u8bba\u4e0a\u5206\u6790\u4e86\u8be5\u65b9\u6cd5\u7684\u89e3\u7684\u552f\u4e00\u6027\u3002", "result": "\u5728\u8f66\u8f86\u8fd0\u52a8\u9884\u6d4b\u3001\u65e0\u4eba\u673a\u72b6\u6001\u9884\u6d4b\u548cCOVID-19\u6d41\u884c\u75c5\u5b66\u9884\u6d4b\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\uff0cPhy-SSM\u5728\u957f\u671f\u63d2\u503c\u548c\u5916\u63a8\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "Phy-SSM\u5728\u957f\u671f\u63d2\u503c\u548c\u5916\u63a8\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u5728\u8f66\u8f86\u8fd0\u52a8\u9884\u6d4b\u3001\u65e0\u4eba\u673a\u72b6\u6001\u9884\u6d4b\u548cCOVID-19\u6d41\u884c\u75c5\u5b66\u9884\u6d4b\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u3002"}}
{"id": "2507.11175", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.11175", "abs": "https://arxiv.org/abs/2507.11175", "authors": ["Davide Scalcon", "Matteo Padovan", "Paolo Villoresi", "Giuseppe Vallone", "Marco Avesani"], "title": "Versatile Wavelength-Division Multiplexed Quantum Key Distribution Network Operating Simultaneously in the O and C Bands", "comment": "7 pages, 6 figures", "summary": "Ongoing technological progress is accelerating the commercial and\nglobal-scale deployment of Quantum Key Distribution (QKD). Its ability to\nenable unconditionally secure communication is expected to be a key feature of\nfuture telecommunication networks, and practical demonstrations of QKD network\nimplementations in real-world environments are crucial for ensuring reliable\nadoption. In this work, we demonstrate a four-node photonic QKD network that\nemploys versatile and cost-effective wavelength-division multiplexing across\nthree transmitters in the O and C bands to simultaneously distribute\nquantum-secure keys among all nodes. Specifically, the broadband central\nreceiver node shares all optical and electronic decoding components, except for\nthe single-photon detectors, across the three QKD links, significantly reducing\nsystem costs and enhancing compactness.", "AI": {"tldr": "\u672c\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2a\u56db\u8282\u70b9\u5149\u5b50QKD\u7f51\u7edc\uff0c\u5229\u7528\u6ce2\u5206\u590d\u7528\u6280\u672f\u5b9e\u73b0\u4e86\u5728\u6240\u6709\u8282\u70b9\u95f4\u7684\u540c\u6b65\u5bc6\u94a5\u5206\u53d1\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u4e86\u6210\u672c\u548c\u63d0\u9ad8\u4e86\u7d27\u51d1\u6027\u3002", "motivation": "\u968f\u7740\u6280\u672f\u8fdb\u6b65\uff0c\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08QKD\uff09\u7684\u5546\u4e1a\u548c\u5168\u7403\u90e8\u7f72\u52a0\u901f\uff0c\u5176\u5728\u672a\u6765\u901a\u4fe1\u7f51\u7edc\u4e2d\u5b9e\u73b0\u65e0\u6761\u4ef6\u5b89\u5168\u901a\u4fe1\u7684\u80fd\u529b\u81f3\u5173\u91cd\u8981\u3002\u56e0\u6b64\uff0c\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u8fdb\u884cQKD\u7f51\u7edc\u5b9e\u65bd\u7684\u5b9e\u9645\u6f14\u793a\u5bf9\u4e8e\u786e\u4fdd\u5176\u53ef\u9760\u5e94\u7528\u975e\u5e38\u5173\u952e\u3002", "method": "\u672c\u7814\u7a76\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u56db\u8282\u70b9\u5149\u5b50\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08QKD\uff09\u7f51\u7edc\u3002\u7f51\u7edc\u5229\u7528\u6ce2\u5206\u590d\u7528\uff08WDM\uff09\u6280\u672f\uff0c\u5728O\u9891\u6bb5\u548cC\u9891\u6bb5\u90e8\u7f72\u4e86\u4e09\u4e2a\u53d1\u5c04\u5668\uff0c\u5b9e\u73b0\u4e86\u5728\u6240\u6709\u8282\u70b9\u95f4\u7684\u540c\u6b65\u5bc6\u94a5\u5206\u53d1\u3002\u4e2d\u5fc3\u63a5\u6536\u8282\u70b9\u8bbe\u8ba1\u4e3a\u5171\u4eab\u9664\u5355\u5149\u5b50\u63a2\u6d4b\u5668\u5916\u7684\u6240\u6709\u5149\u5b66\u548c\u7535\u5b50\u89e3\u7801\u7ec4\u4ef6\uff0c\u4ee5\u4f18\u5316\u6210\u672c\u548c\u7a7a\u95f4\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u4e00\u4e2a\u56db\u8282\u70b9\u5149\u5b50QKD\u7f51\u7edc\uff0c\u5b9e\u73b0\u4e86\u5728O\u548cC\u9891\u6bb5\u8de8\u4e09\u4e2a\u53d1\u5c04\u5668\u7684\u6ce2\u5206\u590d\u7528\uff0c\u5e76\u5728\u6240\u6709\u8282\u70b9\u95f4\u540c\u6b65\u5206\u53d1\u4e86\u91cf\u5b50\u5b89\u5168\u5bc6\u94a5\u3002\u901a\u8fc7\u5171\u4eab\u4e2d\u5fc3\u63a5\u6536\u8282\u70b9\u7684\u5149\u5b66\u548c\u7535\u5b50\u89e3\u7801\u7ec4\u4ef6\uff08\u5355\u5149\u5b50\u63a2\u6d4b\u5668\u9664\u5916\uff09\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u7cfb\u7edf\u6210\u672c\u5e76\u63d0\u9ad8\u4e86\u7d27\u51d1\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u4e00\u4e2a\u56db\u8282\u70b9\u5149\u5b50QKD\u7f51\u7edc\uff0c\u8be5\u7f51\u7edc\u5728O\u548cC\u9891\u6bb5\u8de8\u4e09\u4e2a\u53d1\u5c04\u5668\u4f7f\u7528\u591a\u529f\u80fd\u4e14\u5177\u6210\u672c\u6548\u76ca\u7684\u6ce2\u5206\u590d\u7528\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u5728\u6240\u6709\u8282\u70b9\u95f4\u7684\u540c\u6b65\u91cf\u5b50\u5b89\u5168\u5bc6\u94a5\u5206\u53d1\u3002\u4e2d\u5fc3\u63a5\u6536\u8282\u70b9\u5171\u4eab\u6240\u6709\u5149\u5b66\u548c\u7535\u5b50\u89e3\u7801\u7ec4\u4ef6\uff08\u5355\u5149\u5b50\u63a2\u6d4b\u5668\u9664\u5916\uff09\uff0c\u4ece\u800c\u663e\u8457\u964d\u4f4e\u4e86\u7cfb\u7edf\u6210\u672c\u5e76\u63d0\u9ad8\u4e86\u7d27\u51d1\u6027\u3002"}}
{"id": "2507.11081", "categories": ["cs.CV", "cs.AI", "I.4.9; I.5.4; J.2"], "pdf": "https://arxiv.org/pdf/2507.11081", "abs": "https://arxiv.org/abs/2507.11081", "authors": ["Chang Peng", "Bao Yang", "Meiqi Li", "Ge Zhang", "Hui Sun", "Zhenyu Jiang"], "title": "Automatic Road Subsurface Distress Recognition from Ground Penetrating Radar Images using Deep Learning-based Cross-verification", "comment": null, "summary": "Ground penetrating radar (GPR) has become a rapid and non-destructive\nsolution for road subsurface distress (RSD) detection. However, RSD recognition\nfrom GPR images is labor-intensive and heavily relies on inspectors' expertise.\nDeep learning offers the possibility for automatic RSD recognition, but its\ncurrent performance is limited by two factors: Scarcity of high-quality dataset\nfor network training and insufficient capability of network to distinguish RSD.\nIn this study, a rigorously validated 3D GPR dataset containing 2134 samples of\ndiverse types was constructed through field scanning. Based on the finding that\nthe YOLO model trained with one of the three scans of GPR images exhibits\nvarying sensitivity to specific type of RSD, we proposed a novel\ncross-verification strategy with outstanding accuracy in RSD recognition,\nachieving recall over 98.6% in field tests. The approach, integrated into an\nonline RSD detection system, can reduce the labor of inspection by around 90%.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e3D GPR\u6570\u636e\u96c6\u548c\u4ea4\u53c9\u9a8c\u8bc1\u7b56\u7565\u7684\u81ea\u52a8RSD\u8bc6\u522b\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8bc6\u522b\u51c6\u786e\u6027\u5e76\u964d\u4f4e\u4e86\u52b3\u52a8\u5f3a\u5ea6\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5f53\u524d\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728RSD\u8bc6\u522b\u4e2d\u5b58\u5728\u7684\u6311\u6218\uff0c\u5982\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u7684\u7a00\u7f3a\u548c\u7f51\u7edc\u533a\u5206RSD\u7684\u80fd\u529b\u4e0d\u8db3\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63d0\u9ad8RSD\u8bc6\u522b\u7684\u81ea\u52a8\u5316\u7a0b\u5ea6\u548c\u51c6\u786e\u6027\u3002", "method": "\u8be5\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b2134\u4e2a\u6837\u672c\u76843D GPR\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4ea4\u53c9\u9a8c\u8bc1\u7b56\u7565\uff0c\u4ee5\u63d0\u9ad8RSD\u8bc6\u522b\u7684\u51c6\u786e\u6027\u3002", "result": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u4ea4\u53c9\u9a8c\u8bc1\u7b56\u7565\u5728\u7530\u91ce\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u8d85\u8fc798.6%\u7684\u53ec\u56de\u7387\uff0c\u5e76\u5c06\u52b3\u52a8\u5f3a\u5ea6\u964d\u4f4e\u4e86\u7ea690%\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4ea4\u53c9\u9a8c\u8bc1\u7b56\u7565\uff0c\u7528\u4e8e\u4ece\u5730\u9762\u7a7f\u900f\u96f7\u8fbe\u56fe\u50cf\u4e2d\u8bc6\u522b\u9053\u8def\u4e0b\u5c42\u75c5\u5bb3\uff08RSD\uff09\u3002"}}
{"id": "2507.11273", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.11273", "abs": "https://arxiv.org/abs/2507.11273", "authors": ["Luohe Shi", "Zuchao Li", "Lefei Zhang", "Guoming Liu", "Baoyuan Qi", "Hai Zhao"], "title": "KV-Latent: Dimensional-level KV Cache Reduction with Frequency-aware Rotary Positional Embedding", "comment": "To be published in The 63rd Annual Meeting of the Association for\n  Computational Linguistics (ACL 2025)", "summary": "Large language models (LLMs) based on Transformer Decoders have become the\npreferred choice for conversational generative AI. Despite the overall\nsuperiority of the Decoder architecture, the gradually increasing Key-Value\n(KV) cache during inference has emerged as a primary efficiency bottleneck,\nboth in aspects of memory consumption and data transfer bandwidth limitations.\nTo address these challenges, we propose a paradigm called KV-Latent. By\ndown-sampling the Key-Value vector dimensions into a latent space, we can\nsignificantly reduce the KV Cache footprint and improve inference speed, only\nwith a small amount of extra training, less than 1\\% of pre-training takes.\nBesides, we enhanced the stability of Rotary Positional Embedding applied on\nlower-dimensional vectors by modifying its frequency sampling mechanism,\navoiding noise introduced by higher frequencies while retaining position\nattenuation. Our experiments, including both models with Grouped Query\nAttention and those without, have yielded satisfactory results. Finally, we\nconducted comparative experiments to study the impact of separately reducing\nKey and Value components on model's performance. Our approach allows for the\nconstruction of more efficient language model systems, and opens the new\npossibility on KV Cache saving and efficient LLMs. Our code is available at\nhttps://github.com/ShiLuohe/KV-Latent.", "AI": {"tldr": "KV-Latent\u901a\u8fc7\u964d\u7ef4KV Cache\u6765\u4f18\u5316LLM\u63a8\u7406\u6548\u7387\u3002", "motivation": "Transformer\u89e3\u7801\u5668\u867d\u7136\u5728\u751f\u6210\u5f0fAI\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\uff0c\u4f46KV Cache\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u4e0d\u65ad\u589e\u5927\uff0c\u6210\u4e3a\u5185\u5b58\u548c\u5e26\u5bbd\u7684\u74f6\u9888\u3002", "method": "\u63d0\u51faKV-Latent\u65b9\u6cd5\uff0c\u901a\u8fc7\u964d\u91c7\u6837KV\u5411\u91cf\u7ef4\u5ea6\u5230\u6f5c\u5728\u7a7a\u95f4\u6765\u51cf\u5c0fKV Cache\u7684\u5360\u7528\u548c\u63d0\u9ad8\u63a8\u7406\u901f\u5ea6\uff0c\u5e76\u5bf9Rotary Positional Embedding\u8fdb\u884c\u4fee\u6539\u4ee5\u63d0\u9ad8\u5728\u4f4e\u7ef4\u5411\u91cf\u4e0a\u7684\u7a33\u5b9a\u6027\u3002", "result": "KV-Latent\u663e\u8457\u51cf\u5c0f\u4e86KV Cache\u7684\u5360\u7528\u5e76\u63d0\u9ad8\u4e86\u63a8\u7406\u901f\u5ea6\uff0c\u540c\u65f6\u5bf9\u6a21\u578b\u6027\u80fd\u5f71\u54cd\u5f88\u5c0f\uff0c\u5e76\u4e14\u5bf9\u6709\u65e0Grouped Query Attention\u7684\u6a21\u578b\u5747\u9002\u7528\u3002", "conclusion": "KV-Latent\u901a\u8fc7\u964d\u7ef4KV Cache\u3001\u4fee\u6539Rotary Positional Embedding\u7684\u9891\u7387\u91c7\u6837\u673a\u5236\u6765\u63d0\u9ad8LLM\u63a8\u7406\u6548\u7387\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u53ef\u884c\u4e14\u6548\u679c\u826f\u597d\uff0c\u4e3a\u6784\u5efa\u66f4\u9ad8\u6548\u7684\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2507.10797", "categories": ["cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.10797", "abs": "https://arxiv.org/abs/2507.10797", "authors": ["Mohammad Pedramfar", "Siamak Ravanbakhsh"], "title": "Multi-Armed Sampling Problem and the End of Exploration", "comment": null, "summary": "This paper introduces the framework of multi-armed sampling, as the sampling\ncounterpart to the optimization problem of multi-arm bandits. Our primary\nmotivation is to rigorously examine the exploration-exploitation trade-off in\nthe context of sampling. We systematically define plausible notions of regret\nfor this framework and establish corresponding lower bounds. We then propose a\nsimple algorithm that achieves these optimal regret bounds. Our theoretical\nresults demonstrate that in contrast to optimization, sampling does not require\nexploration. To further connect our findings with those of multi-armed bandits,\nwe define a continuous family of problems and associated regret measures that\nsmoothly interpolates and unifies multi-armed sampling and multi-armed bandit\nproblems using a temperature parameter. We believe the multi-armed sampling\nframework, and our findings in this setting can have a foundational role in the\nstudy of sampling including recent neural samplers, akin to the role of\nmulti-armed bandits in reinforcement learning. In particular, our work sheds\nlight on the need for exploration and the convergence properties of algorithm\nfor entropy-regularized reinforcement learning, fine-tuning of pretrained\nmodels and reinforcement learning with human feedback (RLHF).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u591a\u81c2\u91c7\u6837\u6846\u67b6\uff0c\u4f5c\u4e3a\u591a\u81c2\u8001\u864e\u673a\u4f18\u5316\u95ee\u9898\u7684\u91c7\u6837\u5bf9\u5e94\u3002\u7814\u7a76\u4e86\u91c7\u6837\u4e2d\u7684\u63a2\u7d22-\u5229\u7528\u6743\u8861\uff0c\u5efa\u7acb\u4e86\u540e\u6094\u4e0b\u754c\uff0c\u5e76\u63d0\u51fa\u4e86\u6700\u4f18\u7b97\u6cd5\u3002\u53d1\u73b0\u91c7\u6837\u4e0d\u9700\u63a2\u7d22\u3002\u901a\u8fc7\u6e29\u5ea6\u53c2\u6570\u7edf\u4e00\u4e86\u591a\u81c2\u91c7\u6837\u548c\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\u3002\u8be5\u6846\u67b6\u53ef\u4e3a\u91c7\u6837\u7814\u7a76\uff08\u5305\u62ec\u795e\u7ecf\u91c7\u6837\u5668\uff09\u5960\u5b9a\u57fa\u7840\uff0c\u5e76\u6709\u52a9\u4e8e\u7406\u89e3\u71b5\u6b63\u5219\u5316\u5f3a\u5316\u5b66\u4e60\u3001\u6a21\u578b\u5fae\u8c03\u548cRLHF\u7684\u63a2\u7d22\u9700\u6c42\u4e0e\u6536\u655b\u6027\u3002", "motivation": "\u6211\u4eec\u7814\u7a76\u7684\u4e3b\u8981\u52a8\u673a\u662f\u4e3a\u4e86\u4e25\u683c\u5ba1\u89c6\u91c7\u6837\u80cc\u666f\u4e0b\u7684\u63a2\u7d22-\u5229\u7528\u6743\u8861\u3002", "method": "\u6211\u4eec\u5b9a\u4e49\u4e86\u591a\u81c2\u91c7\u6837\u6846\u67b6\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u80fd\u8fbe\u5230\u6700\u4f18\u540e\u6094\u754c\u9650\u7684\u7b97\u6cd5\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u5b9a\u4e49\u4e86\u4e00\u4e2a\u8fde\u7eed\u7684\u95ee\u9898\u65cf\u53ca\u5176\u76f8\u5173\u7684\u540e\u6094\u5ea6\u91cf\uff0c\u8be5\u5ea6\u91cf\u4f7f\u7528\u6e29\u5ea6\u53c2\u6570\u6765\u5e73\u6ed1\u5730\u63d2\u503c\u548c\u7edf\u4e00\u591a\u81c2\u91c7\u6837\u4e0e\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\u3002", "result": "\u6211\u4eec\u4e3a\u591a\u81c2\u91c7\u6837\u6846\u67b6\u5efa\u7acb\u4e86\u76f8\u5e94\u7684\u4e0b\u754c\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u80fd\u8fbe\u5230\u6700\u4f18\u540e\u6094\u754c\u9650\u7684\u7b97\u6cd5\u3002", "conclusion": "\u4e0e\u4f18\u5316\u95ee\u9898\u4e0d\u540c\uff0c\u91c7\u6837\u4e0d\u9700\u8981\u63a2\u7d22\u3002\u6211\u4eec\u63d0\u51fa\u7684\u591a\u81c2\u91c7\u6837\u6846\u67b6\u53ca\u5176\u7ed3\u679c\u53ef\u4ee5\u4e3a\u5305\u62ec\u8fd1\u671f\u795e\u7ecf\u91c7\u6837\u5668\u5728\u5185\u7684\u91c7\u6837\u7814\u7a76\u5960\u5b9a\u57fa\u7840\uff0c\u5c31\u50cf\u591a\u81c2\u8001\u864e\u673a\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u6240\u626e\u6f14\u7684\u89d2\u8272\u4e00\u6837\u3002\u6211\u4eec\u7684\u5de5\u4f5c\u5c24\u5176\u63ed\u793a\u4e86\u71b5\u6b63\u5219\u5316\u5f3a\u5316\u5b66\u4e60\u3001\u9884\u8bad\u7ec3\u6a21\u578b\u5fae\u8c03\u4ee5\u53ca\u5177\u6709\u4eba\u7c7b\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60\uff08RLHF\uff09\u7684\u63a2\u7d22\u9700\u6c42\u548c\u7b97\u6cd5\u6536\u655b\u6027\u3002"}}
{"id": "2507.11498", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.11498", "abs": "https://arxiv.org/abs/2507.11498", "authors": ["Asad Ali Shahid", "Francesco Braghin", "Loris Roveda"], "title": "Robot Drummer: Learning Rhythmic Skills for Humanoid Drumming", "comment": null, "summary": "Humanoid robots have seen remarkable advances in dexterity, balance, and\nlocomotion, yet their role in expressive domains, such as music performance,\nremains largely unexplored. Musical tasks, like drumming, present unique\nchallenges, including split-second timing, rapid contacts, and multi-limb\ncoordination over pieces lasting minutes. In this paper, we introduce Robot\nDrummer, a humanoid system capable of expressive, high-precision drumming\nacross a diverse repertoire of songs. We formulate humanoid drumming as\nsequential fulfillment of timed-contacts and transform drum scores in to a\nRhythmic Contact Chain. To handle the long-horizon nature of musical\nperformance, we decompose each piece into fixed-length segments and train a\nsingle policy across all segments in parallel using reinforcement learning.\nThrough extensive experiments on over thirty popular rock, metal, and jazz\ntracks, our results demonstrate that Robot Drummer consistently achieves high\nF1 scores. The learned behaviors exhibit emergent human-like drumming\nstrategies, such as cross-arm strikes, and adaptive sticks assignments,\ndemonstrating the potential of reinforcement learning to bring humanoid robots\ninto the domain of creative musical performance. Project page:\n\\href{https://robot-drummer.github.io}{robot-drummer.github.io}", "AI": {"tldr": "\u673a\u5668\u4eba\u9f13\u624b\uff1a\u4e00\u4e2a\u80fd\u591f\u8fdb\u884c\u9ad8\u7cbe\u5ea6\u3001\u5bcc\u6709\u8868\u73b0\u529b\u6f14\u594f\u7684\u4eba\u5f62\u673a\u5668\u4eba\u7cfb\u7edf\uff0c\u53ef\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u7c7b\u4f3c\u4eba\u7c7b\u7684\u51fb\u6253\u7b56\u7565\u3002", "motivation": "\u5728\u4eba\u5f62\u673a\u5668\u4eba\u5728\u7075\u6d3b\u6027\u3001\u5e73\u8861\u6027\u548c\u8fd0\u52a8\u6027\u65b9\u9762\u53d6\u5f97\u663e\u8457\u8fdb\u6b65\u7684\u540c\u65f6\uff0c\u5b83\u4eec\u5728\u97f3\u4e50\u8868\u6f14\u7b49\u8868\u8fbe\u6027\u9886\u57df\u7684\u5e94\u7528\u4ecd\u6709\u5f85\u63a2\u7d22\u3002\u7136\u800c\uff0c\u50cf\u51fb\u9f13\u8fd9\u6837\u7684\u97f3\u4e50\u4efb\u52a1\u5177\u6709\u72ec\u7279\u7684\u6311\u6218\uff0c\u4f8b\u5982\u77ac\u65f6\u65f6\u5e8f\u3001\u5feb\u901f\u63a5\u89e6\u548c\u591a\u80a2\u534f\u8c03\u6027\u3002", "method": "\u5c06 the humanoid drumming \u8868\u8ff0\u4e3a\u65f6\u5e8f\u6027\u63a5\u89e6\u70b9\u7684\u6ee1\u8db3\uff0c\u5e76\u5c06\u9f13\u8c31\u8f6c\u5316\u4e3a\u8282\u594f\u63a5\u89e6\u94fe\uff08Rhythmic Contact Chain\uff09\u3002\u901a\u8fc7\u5c06\u4e50\u66f2\u5206\u89e3\u4e3a\u56fa\u5b9a\u957f\u5ea6\u7684\u7247\u6bb5\uff0c\u5e76\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u6280\u672f\uff0c\u8bad\u7ec3\u4e86\u4e00\u4e2a\u80fd\u591f\u5904\u7406\u957f\u65f6\u7a0b\u97f3\u4e50\u8868\u6f14\u7684\u5355\u4e00\u7b56\u7565\u3002", "result": "\u901a\u8fc7\u5728\u6447\u6eda\u3001\u91d1\u5c5e\u548c\u7235\u58eb\u4e50\u7b49\u4e09\u5341\u591a\u9996\u6d41\u884c\u66f2\u76ee\u4e0a\u8fdb\u884c\u7684\u5927\u91cf\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e\u673a\u5668\u4eba\u9f13\u624b\u80fd\u591f\u6301\u7eed\u83b7\u5f97\u9ad8 F1 \u5206\u6570\u3002\u6240\u5b66\u4e60\u5230\u7684\u884c\u4e3a\u8fd8\u5c55\u73b0\u51fa\u7c7b\u4f3c\u4eba\u7c7b\u7684\u6f14\u594f\u7b56\u7565\uff0c\u4f8b\u5982\u4ea4\u53c9\u624b\u81c2\u51fb\u6253\u548c\u81ea\u9002\u5e94\u7684\u9f13\u69cc\u5206\u914d\u3002", "conclusion": "\u673a\u5668\u4eba\u9f13\u624b\u5728\u8282\u594f\u3001\u7cbe\u786e\u5ea6\u548c\u591a\u80a2\u534f\u8c03\u6027\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6210\u6548\uff0c\u5e76\u4e14\u80fd\u591f\u8de8\u591a\u79cd\u97f3\u4e50\u98ce\u683c\u5b9e\u73b0\u7c7b\u4f3c\u4eba\u7c7b\u7684\u6f14\u594f\u7b56\u7565\u3002"}}
{"id": "2507.11180", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.11180", "abs": "https://arxiv.org/abs/2507.11180", "authors": ["Jian Li", "Ye-Chao Liu", "Xiao-Xiao Chen", "Zhe Meng", "Xing-Yan Fan", "Wen-Hao Wang", "Jie Ma", "An-Ning Zhang", "Jiangwei Shang"], "title": "Real-time preparation and verification of nonstabilizer states", "comment": "6+4 pages, 7 figures; comments are welcome!", "summary": "Entanglement lies at the heart of quantum information science, serving as a\nkey resource for quantum communication, computation, and metrology.\nConsequently, high-precision entangled state preparation and efficient\nverification are essential for practical quantum technologies. Quantum state\nverification (QSV) has recently gained much attention as an efficient and\nexperiment-friendly approach for verifying entangled states. In this work, we\nexperimentally demonstrate a QSV protocol for verifying three-qubit\nnonstabilizer $W$ state via a modified homogeneous strategy. Notably, our\nimplementation extends QSV beyond its standard role by integrating the state\npreparation process, thus guiding and validating the real-time generation of\nhigh-fidelity target states. Specifically, we realize the efficient\nverification with a favorable scaling of the required number of copies versus\ninfidelity as $-1.39$, outperforming the standard quantum limit of $-2$.\nMeanwhile, a fidelity of $97.07(\\pm 0.26)\\%$ via direct estimation is achieved\nusing only $9$ measurement settings and $10^4$ samples, which is independently\nconfirmed by quantum state tomography to be $98.58(\\pm 0.12)\\%$ with\napproximately $10^6$ measurements. This work presents the first experimental\ndemonstration of QSV actively assisted with state preparation, establishing it\nas a powerful and resource-efficient alternative to full tomography for\nreal-time quantum state engineering.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.11085", "categories": ["cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2507.11085", "abs": "https://arxiv.org/abs/2507.11085", "authors": ["Tianchi Xu"], "title": "Atmos-Bench: 3D Atmospheric Structures for Climate Insight", "comment": null, "summary": "Atmospheric structure, represented by backscatter coefficients (BC) recovered\nfrom satellite LiDAR attenuated backscatter (ATB), provides a volumetric view\nof clouds, aerosols, and molecules, playing a critical role in human\nactivities, climate understanding, and extreme weather forecasting. Existing\nmethods often rely on auxiliary inputs and simplified physics-based\napproximations, and lack a standardized 3D benchmark for fair evaluation.\nHowever, such approaches may introduce additional uncertainties and\ninsufficiently capture realistic radiative transfer and atmospheric\nscattering-absorption effects. To bridge these gaps, we present Atmos-Bench:\nthe first 3D atmospheric benchmark, along with a novel FourCastX:\nFrequency-enhanced Spatio-Temporal Mixture-of-Experts Network that (a)\ngenerates 921,600 image slices from 3D scattering volumes simulated at 532 nm\nand 355 nm by coupling WRF with an enhanced COSP simulator over 384 land-ocean\ntime steps, yielding high-quality voxel-wise references; (b) embeds ATB-BC\nphysical constraints into the model architecture, promoting energy consistency\nduring restoration; (c) achieves consistent improvements on the Atmos-Bench\ndataset across both 355 nm and 532 nm bands, outperforming state-of-the-art\nbaseline models without relying on auxiliary inputs. Atmos-Bench establishes a\nnew standard for satellite-based 3D atmospheric structure recovery and paves\nthe way for deeper climate insight.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684 3D \u5927\u6c14\u57fa\u51c6 Atmos-Bench \u548c FourCastX \u7f51\u7edc\uff0c\u7528\u4e8e\u5927\u6c14\u7ed3\u6784\u6062\u590d\u3002", "motivation": "\u73b0\u6709\u7684\u65b9\u6cd5\u4f9d\u8d56\u8f85\u52a9\u8f93\u5165\u548c\u7b80\u5316\u7684\u57fa\u4e8e\u7269\u7406\u7684\u8fd1\u4f3c\uff0c\u5e76\u4e14\u7f3a\u4e4f\u6807\u51c6\u5316\u7684 3D \u57fa\u51c6\u6765\u8fdb\u884c\u516c\u5e73\u8bc4\u4f30\uff0c\u8fd9\u53ef\u80fd\u4f1a\u5f15\u5165\u989d\u5916\u7684 \ubd88\ud655\uc2e4\uc131 \u5e76\u672a\u80fd\u5145\u5206\u6355\u6349\u771f\u5b9e\u7684\u8f90\u5c04\u4f20\u8f93\u548c\u5927\u6c14\u6563\u5c04-\u5438\u6536\u6548\u5e94\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684 FourCastX\uff1a\u589e\u5f3a\u9891\u7387\u7684\u65f6\u7a7a\u4e13\u5bb6\u6df7\u5408\u7f51\u7edc\uff0c\u8be5\u7f51\u7edc\u5c06 ATB-BC \u7269\u7406\u7ea6\u675f\u5d4c\u5165\u6a21\u578b\u67b6\u6784\u4e2d\uff0c\u4ee5\u5728\u6062\u590d\u8fc7\u7a0b\u4e2d\u4fc3\u8fdb\u80fd\u91cf\u4e00\u81f4\u6027\uff0c\u5e76\u5728 355 nm \u548c 532 nm \u6ce2\u6bb5\u7684 Atmos-Bench \u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e00\u81f4\u7684\u6539\u8fdb\uff0c\u5176\u6027\u80fd\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u6a21\u578b\uff0c\u800c\u65e0\u9700\u4f9d\u8d56\u8f85\u52a9\u8f93\u5165\u3002", "result": "\u751f\u6210\u4e86 921,600 \u4e2a\u56fe\u50cf\u5207\u7247\uff0c\u8fd9\u4e9b\u5207\u7247\u6765\u81ea\u5728 532 nm \u548c 355 nm \u4e0b\u6a21\u62df\u7684 3D \u6563\u5c04\u4f53\u79ef\uff0c\u901a\u8fc7\u8026\u5408 WRF \u548c\u589e\u5f3a\u7684 COSP \u6a21\u62df\u5668\uff0c\u5728 384 \u4e2a\u9646\u5730-\u6d77\u6d0b\u65f6\u95f4\u6b65\u957f\u4e0a\u4ea7\u751f\u9ad8\u8d28\u91cf\u7684\u4f53\u7d20\u7ea7\u53c2\u8003\u3002", "conclusion": "Atmos-Bench \u5efa\u7acb\u4e86\u4e00\u4e2a\u65b0\u7684\u57fa\u4e8e\u536b\u661f\u7684 3D \u5927\u6c14\u7ed3\u6784\u6062\u590d\u6807\u51c6\uff0c\u5e76\u4e3a\u66f4\u6df1\u5165\u7684\u6c14\u5019\u6d1e\u5bdf\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2507.11482", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11482", "abs": "https://arxiv.org/abs/2507.11482", "authors": ["Mani Hamidi", "Terrence W. Deacon"], "title": "Illuminating the Three Dogmas of Reinforcement Learning under Evolutionary Light", "comment": null, "summary": "Three core tenets of reinforcement learning (RL)--concerning the definition\nof agency, the objective of learning, and the scope of the reward\nhypothesis--have been highlighted as key targets for conceptual revision, with\nmajor implications for theory and application. We propose a framework, inspired\nby open-ended evolutionary theory, to reconsider these three \"dogmas.\" We\nrevisit each assumption and address related concerns raised alongside them. To\nmake our arguments relevant to RL as a model of biological learning, we first\nestablish that evolutionary dynamics can plausibly operate within living brains\nover an individual's lifetime, and are not confined to cross-generational\nprocesses. We begin by revisiting the second dogma, drawing on evolutionary\ninsights to enrich the \"adaptation-rather-than-search\" view of learning. We\nthen address the third dogma regarding the limits of the reward hypothesis,\nusing analogies from evolutionary fitness to illuminate the scalar reward vs.\nmulti-objective debate. After discussing practical implications for exploration\nin RL, we turn to the first--and arguably most fundamental--issue: the absence\nof a formal account of agency. We argue that unlike the other two problems, the\nevolutionary paradigm alone cannot resolve the agency question, though it\ngestures in a productive direction. We advocate integrating ideas from\norigins-of-life theory, where the thermodynamics of sustenance and replication\noffer promising foundations for understanding agency and resource-constrained\nreinforcement learning in biological systems.", "AI": {"tldr": "\u672c\u6587\u501f\u9274\u8fdb\u5316\u7406\u8bba\u6765\u4fee\u8ba2 RL \u7684\u4e09\u4e2a\u6838\u5fc3\u539f\u5219\uff0c\u5e76\u63d0\u51fa\u6574\u5408\u751f\u547d\u8d77\u6e90\u7406\u8bba\u4ee5\u89e3\u51b3\u80fd\u52a8\u6027\u95ee\u9898\uff0c\u4e3a\u751f\u7269\u5b66\u4e60\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002", "motivation": "RL \u7684\u4e09\u4e2a\u6838\u5fc3\u539f\u5219\u2014\u2014\u80fd\u52a8\u6027\u3001\u5b66\u4e60\u76ee\u6807\u548c\u5956\u52b1\u5047\u8bbe\u7684\u8303\u56f4\u2014\u2014\u9700\u8981\u6982\u5ff5\u4e0a\u7684\u4fee\u8ba2\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u501f\u9274\u5f00\u653e\u5f0f\u8fdb\u5316\u7406\u8bba\u6765\u91cd\u65b0\u5ba1\u89c6\u8fd9\u4e9b\u539f\u5219\uff0c\u5e76\u63a2\u7d22\u5176\u5728\u751f\u7269\u5b66\u4e60\u6a21\u578b\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u53d7\u5f00\u653e\u5f0f\u8fdb\u5316\u7406\u8bba\u542f\u53d1\u7684\u6846\u67b6\u6765\u91cd\u65b0\u5ba1\u89c6 RL \u7684\u4e09\u4e2a\u6838\u5fc3\u539f\u5219\uff1a\u80fd\u52a8\u6027\u3001\u5b66\u4e60\u76ee\u6807\u548c\u5956\u52b1\u5047\u8bbe\u7684\u8303\u56f4\u3002\u9996\u5148\uff0c\u6211\u4eec\u501f\u9274\u8fdb\u5316\u89c1\u89e3\u6765\u4e30\u5bcc\u201c\u9002\u5e94\u800c\u975e\u641c\u7d22\u201d\u7684\u5b66\u4e60\u89c2\uff0c\u7136\u540e\u5229\u7528\u8fdb\u5316\u9002\u5e94\u6027\u7684\u7c7b\u6bd4\u6765\u9610\u660e\u6807\u91cf\u5956\u52b1\u4e0e\u591a\u76ee\u6807\u4f18\u5316\u4e4b\u95f4\u7684\u4e89\u8bba\uff0c\u4ee5\u89e3\u51b3\u5956\u52b1\u5047\u8bbe\u7684\u9650\u5236\u3002\u6700\u540e\uff0c\u6211\u4eec\u8ba4\u4e3a\uff0c\u867d\u7136\u8fdb\u5316\u8303\u5f0f\u6307\u660e\u4e86\u89e3\u51b3\u80fd\u52a8\u6027\u95ee\u9898\u7684\u6709\u76ca\u65b9\u5411\uff0c\u4f46\u9700\u8981\u6574\u5408\u751f\u547d\u8d77\u6e90\u7406\u8bba\u7684\u601d\u60f3\uff0c\u7279\u522b\u662f\u7ef4\u6301\u548c\u590d\u5236\u7684\u70ed\u529b\u5b66\uff0c\u4e3a\u7406\u89e3\u751f\u7269\u7cfb\u7edf\u4e2d\u7684\u80fd\u52a8\u6027\u3001\u8d44\u6e90\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u57fa\u7840\u3002", "result": "\u672c\u6587\u901a\u8fc7\u501f\u9274\u8fdb\u5316\u7406\u8bba\u548c\u751f\u547d\u8d77\u6e90\u7406\u8bba\uff0c\u5bf9 RL \u7684\u6838\u5fc3\u539f\u5219\u8fdb\u884c\u4e86\u6982\u5ff5\u4e0a\u7684\u4fee\u8ba2\uff0c\u4e3a\u7406\u89e3\u751f\u7269\u7cfb\u7edf\u4e2d\u7684\u5b66\u4e60\u3001\u80fd\u52a8\u6027\u548c\u8d44\u6e90\u7ea6\u675f\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u6846\u67b6\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7684\u4e09\u4e2a\u6838\u5fc3\u539f\u5219\u2014\u2014\u5173\u4e8e\u80fd\u52a8\u6027\u3001\u5b66\u4e60\u76ee\u6807\u548c\u5956\u52b1\u5047\u8bbe\u7684\u8303\u56f4\u2014\u2014\u5df2\u88ab\u5f3a\u8c03\u4e3a\u6982\u5ff5\u4fee\u6b63\u7684\u5173\u952e\u76ee\u6807\uff0c\u5bf9\u7406\u8bba\u548c\u5e94\u7528\u90fd\u6709\u91cd\u5927\u5f71\u54cd\u3002\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u53d7\u5f00\u653e\u5f0f\u8fdb\u5316\u7406\u8bba\u542f\u53d1\u7684\u6846\u67b6\u6765\u91cd\u65b0\u5ba1\u89c6\u8fd9\u4e09\u4e2a\u201c\u4fe1\u6761\u201d\u3002\u6211\u4eec\u91cd\u65b0\u5ba1\u89c6\u6bcf\u4e2a\u5047\u8bbe\uff0c\u5e76\u89e3\u51b3\u4e0e\u4e4b\u76f8\u5173\u7684\u5173\u5207\u3002\u4e3a\u4e86\u4f7f\u6211\u4eec\u7684\u8bba\u70b9\u4e0e RL \u4f5c\u4e3a\u751f\u7269\u5b66\u4e60\u6a21\u578b\u76f8\u5173\uff0c\u6211\u4eec\u9996\u5148\u5efa\u7acb\u8fdb\u5316\u52a8\u529b\u5b66\u53ef\u4ee5\u5408\u7406\u5730\u5728\u4e2a\u4f53\u4e00\u751f\u4e2d\u4f5c\u7528\u4e8e\u751f\u7269\u5927\u8111\uff0c\u5e76\u4e14\u4e0d\u5c40\u9650\u4e8e\u8de8\u4ee3\u8fc7\u7a0b\u3002\u6211\u4eec\u9996\u5148\u56de\u987e\u7b2c\u4e8c\u4e2a\u4fe1\u6761\uff0c\u5229\u7528\u8fdb\u5316\u89c1\u89e3\u6765\u4e30\u5bcc\u201c\u9002\u5e94\u800c\u975e\u641c\u7d22\u201d\u7684\u5b66\u4e60\u89c2\u3002\u7136\u540e\uff0c\u6211\u4eec\u5229\u7528\u8fdb\u5316\u9002\u5e94\u6027\u7684\u7c7b\u6bd4\u6765\u9610\u660e\u6807\u91cf\u5956\u52b1\u4e0e\u591a\u76ee\u6807\u4f18\u5316\u4e4b\u95f4\u7684\u4e89\u8bba\uff0c\u4ee5\u89e3\u51b3\u5956\u52b1\u5047\u8bbe\u7684\u9650\u5236\u3002\u5728\u8ba8\u8bba\u4e86\u5bf9 RL \u63a2\u7d22\u7684\u5b9e\u9645\u5f71\u54cd\u540e\uff0c\u6211\u4eec\u8f6c\u5411\u7b2c\u4e00\u4e2a\u2014\u2014\u4e5f\u662f\u6700\u6839\u672c\u7684\u2014\u2014\u95ee\u9898\uff1a\u80fd\u52a8\u6027\u8d26\u6237\u7684\u7f3a\u5931\u3002\u6211\u4eec\u8ba4\u4e3a\uff0c\u4e0e\u5176\u4ed6\u4e24\u4e2a\u95ee\u9898\u4e0d\u540c\uff0c\u5355\u72ec\u7684\u8fdb\u5316\u8303\u5f0f\u65e0\u6cd5\u89e3\u51b3\u80fd\u52a8\u6027\u95ee\u9898\uff0c\u5c3d\u7ba1\u5b83\u6307\u660e\u4e86\u4e00\u4e2a\u6709\u76ca\u7684\u65b9\u5411\u3002\u6211\u4eec\u4e3b\u5f20\u6574\u5408\u751f\u547d\u8d77\u6e90\u7406\u8bba\u7684\u601d\u60f3\uff0c\u5176\u4e2d\u7ef4\u6301\u548c\u590d\u5236\u7684\u70ed\u529b\u5b66\u4e3a\u7406\u89e3\u751f\u7269\u7cfb\u7edf\u4e2d\u7684\u80fd\u52a8\u6027\u3001\u8d44\u6e90\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u5e0c\u671b\u7684\u57fa\u7840\u3002"}}
{"id": "2507.11275", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.11275", "abs": "https://arxiv.org/abs/2507.11275", "authors": ["Jiaxuan Xie", "Chengwu Liu", "Ye Yuan", "Siqi Li", "Zhiping Xiao", "Ming Zhang"], "title": "FMC: Formalization of Natural Language Mathematical Competition Problems", "comment": "Accepted in ICML 2025 AI4MATH Workshop", "summary": "Efficient and accurate autoformalization methods, which leverage large-scale\ndatasets of extensive natural language mathematical problems to construct\nformal language datasets, are key to advancing formal mathematical reasoning.\nIn this paper, we propose an autoformalization pipeline based on large language\nmodels with error feedback, achieving a fully automatic and training-free\nformalization approach. Using this pipeline, we curate an Olympiad-level\ndataset aligning natural language problems with Lean formalizations. The\ndataset comprises $3,922$ mathematical problems in natural language and $9,787$\nin Lean, of which $64.46\\%$ were assessed as at least above-average quality,\nmaking it suitable as a benchmark for automated theorem provers. Additionally,\nwe investigate the formalization and reasoning capabilities of various LLMs and\nempirically demonstrate that few-shot learning, error feedback, and increasing\nsampling numbers enhance the autoformalization process. Experiments of three\nautomated theorem provers on the \\dataset\\ dataset also highlight its\nchallenging nature and its value as a benchmark for formal reasoning tasks.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u81ea\u52a8\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u9519\u8bef\u53cd\u9988\uff0c\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u5c06\u81ea\u7136\u8bed\u8a00\u6570\u5b66\u95ee\u9898\u8f6c\u6362\u4e3aLean\u5f62\u5f0f\u3002\u7814\u7a76\u4eba\u5458\u6784\u5efa\u4e86\u4e00\u4e2a\u9ad8\u8d28\u91cf\u7684\u5965\u6570\u7ea7\u522b\u6570\u636e\u96c6\uff0c\u5e76\u8bc4\u4f30\u4e86\u4e0d\u540cLLM\u7684\u8868\u73b0\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u4ee5\u53ca\u6570\u636e\u96c6\u4f5c\u4e3a\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u5668\u57fa\u51c6\u7684\u6f5c\u529b\u3002", "motivation": "\u4e3a\u4e86\u63a8\u8fdb\u5f62\u5f0f\u5316\u6570\u5b66\u63a8\u7406\uff0c\u9700\u8981\u9ad8\u6548\u51c6\u786e\u7684\u81ea\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u4ee5\u5229\u7528\u5927\u89c4\u6a21\u81ea\u7136\u8bed\u8a00\u6570\u5b66\u95ee\u9898\u6570\u636e\u96c6\u6784\u5efa\u5f62\u5f0f\u8bed\u8a00\u6570\u636e\u96c6\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u548c\u9519\u8bef\u53cd\u9988\u7684\u81ea\u5f62\u5f0f\u5316\u6d41\u7a0b\uff0c\u5b9e\u73b0\u5168\u81ea\u52a8\u3001\u65e0\u9700\u8bad\u7ec3\u7684\u5f62\u5f0f\u5316\u3002\u5229\u7528\u6b64\u6d41\u7a0b\uff0c\u7814\u7a76\u4eba\u5458\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u5965\u6797\u5339\u514b\u7ea7\u522b\u6570\u5b66\u95ee\u9898\u7684\u81ea\u7136\u8bed\u8a00\u4e0eLean\u5f62\u5f0f\u5316\u8868\u8ff0\u5bf9\u9f50\u7684\u6570\u636e\u96c6\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u8bc4\u4f30\u4e86\u4e0d\u540cLLM\u7684\u5f62\u5f0f\u5316\u548c\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u5c11\u6837\u672c\u5b66\u4e60\u3001\u9519\u8bef\u53cd\u9988\u548c\u589e\u52a0\u91c7\u6837\u6570\u80fd\u6539\u8fdb\u81ea\u5f62\u5f0f\u5316\u8fc7\u7a0b\u3002", "result": "\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b3,922\u4e2a\u5965\u6570\u7ea7\u522b\u6570\u5b66\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u548c9,787\u4e2aLean\u5f62\u5f0f\u5316\u8868\u8ff0\u7684\u6570\u636e\u96c6\uff0c\u5176\u4e2d64.46%\u7684\u6761\u76ee\u88ab\u8bc4\u4f30\u4e3a\u5177\u6709\u5e73\u5747\u4ee5\u4e0a\u8d28\u91cf\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5c11\u6837\u672c\u5b66\u4e60\u3001\u9519\u8bef\u53cd\u9988\u548c\u589e\u52a0\u91c7\u6837\u6570\u53ef\u4ee5\u63d0\u5347\u81ea\u5f62\u5f0f\u5316\u6548\u679c\u3002\u8be5\u6570\u636e\u96c6\u5bf9\u4e09\u4e2a\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u5668\u7684\u6d4b\u8bd5\u7ed3\u679c\u8868\u660e\u4e86\u5176\u6311\u6218\u6027\u548c\u4f5c\u4e3a\u57fa\u51c6\u7684\u4ef7\u503c\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u9519\u8bef\u53cd\u9988\u7684\u5168\u81ea\u52a8\u3001\u65e0\u9700\u8bad\u7ec3\u7684\u81ea\u5f62\u5f0f\u5316\u6d41\u7a0b\uff0c\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b3,922\u4e2a\u5965\u6570\u7ea7\u522b\u6570\u5b66\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u548c9,787\u4e2aLean\u5f62\u5f0f\u5316\u8868\u8ff0\u7684\u6570\u636e\u96c6\u3002\u8be5\u6570\u636e\u96c664.46%\u7684\u6761\u76ee\u88ab\u8bc4\u4f30\u4e3a\u5177\u6709\u5e73\u5747\u4ee5\u4e0a\u8d28\u91cf\uff0c\u53ef\u4f5c\u4e3a\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u5668\u7684\u57fa\u51c6\u3002\u7814\u7a76\u8fd8\u8868\u660e\uff0c\u5c11\u6837\u672c\u5b66\u4e60\u3001\u9519\u8bef\u53cd\u9988\u548c\u589e\u52a0\u91c7\u6837\u6570\u91cf\u80fd\u63d0\u5347\u81ea\u5f62\u5f0f\u5316\u6548\u679c\uff0c\u5e76\u9a8c\u8bc1\u4e86\u8be5\u6570\u636e\u96c6\u5728\u8bc4\u4f30\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u5668\u4e0a\u7684\u6311\u6218\u6027\u548c\u4ef7\u503c\u3002"}}
{"id": "2507.10809", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.10809", "abs": "https://arxiv.org/abs/2507.10809", "authors": ["Kazi Tasnim Zinat", "Yun Zhou", "Xiang Lyu", "Yawei Wang", "Zhicheng Liu", "Panpan Xu"], "title": "Uncovering Causal Relation Shifts in Event Sequences under Out-of-Domain Interventions", "comment": "Accepted at ICANN 2025", "summary": "Inferring causal relationships between event pairs in a temporal sequence is\napplicable in many domains such as healthcare, manufacturing, and\ntransportation. Most existing work on causal inference primarily focuses on\nevent types within the designated domain, without considering the impact of\nexogenous out-of-domain interventions. In real-world settings, these\nout-of-domain interventions can significantly alter causal dynamics. To address\nthis gap, we propose a new causal framework to define average treatment effect\n(ATE), beyond independent and identically distributed (i.i.d.) data in classic\nRubin's causal framework, to capture the causal relation shift between events\nof temporal process under out-of-domain intervention. We design an unbiased ATE\nestimator, and devise a Transformer-based neural network model to handle both\nlong-range temporal dependencies and local patterns while integrating\nout-of-domain intervention information into process modeling. Extensive\nexperiments on both simulated and real-world datasets demonstrate that our\nmethod outperforms baselines in ATE estimation and goodness-of-fit under\nout-of-domain-augmented point processes.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u56e0\u679c\u6846\u67b6\u548c\u57fa\u4e8eTransformer\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u7528\u4e8e\u5728\u5b58\u5728\u57df\u5916\u5e72\u9884\u7684\u60c5\u51b5\u4e0b\u63a8\u65ad\u65f6\u95f4\u4e8b\u4ef6\u5e8f\u5217\u4e2d\u7684\u56e0\u679c\u5173\u7cfb\u3002", "motivation": "\u73b0\u6709\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u7279\u5b9a\u9886\u57df\u5185\u7684\u4e8b\u4ef6\u7c7b\u578b\uff0c\u5ffd\u89c6\u4e86\u5916\u6e90\u6027\u57df\u5916\u5e72\u9884\u7684\u5f71\u54cd\uff0c\u800c\u8fd9\u79cd\u5f71\u54cd\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u4f1a\u663e\u8457\u6539\u53d8\u56e0\u679c\u52a8\u6001\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u56e0\u679c\u6846\u67b6\u6765\u5b9a\u4e49\u5e73\u5747\u5904\u7406\u6548\u5e94\uff08ATE\uff09\uff0c\u4ee5\u6355\u6349\u5916\u6e90\u6027\u57df\u5916\u5e72\u9884\u4e0b\u65f6\u95f4\u8fc7\u7a0b\u4e8b\u4ef6\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\u8f6c\u79fb\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u65e0\u504fATE\u4f30\u8ba1\u5668\uff0c\u4ee5\u53ca\u4e00\u4e2a\u57fa\u4e8eTransformer\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u6765\u5904\u7406\u957f\u671f\u65f6\u95f4\u4f9d\u8d56\u6027\u548c\u5c40\u90e8\u6a21\u5f0f\uff0c\u540c\u65f6\u5c06\u5916\u6e90\u6027\u57df\u5916\u5e72\u9884\u4fe1\u606f\u6574\u5408\u5230\u8fc7\u7a0b\u5efa\u6a21\u4e2d\u3002", "result": "\u5728\u6a21\u62df\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728ATE\u4f30\u8ba1\u548c\u5916\u6e90\u6027\u57df\u5916\u5e72\u9884\u589e\u5f3a\u70b9\u8fc7\u7a0b\u7684\u62df\u5408\u4f18\u5ea6\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b0\u56e0\u679c\u6846\u67b6\u80fd\u591f\u8d85\u51fa\u7ecf\u5178\u9c81\u5bbe\u56e0\u679c\u6846\u67b6\u5728\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u4e0a\u7684\u9650\u5236\uff0c\u4ee5\u6355\u6349\u5916\u6e90\u6027\u57df\u5916\u5e72\u9884\u4e0b\u65f6\u95f4\u8fc7\u7a0b\u4e8b\u4ef6\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\u8f6c\u79fb\u3002\u6240\u63d0\u51fa\u7684\u65e0\u504fATE\u4f30\u8ba1\u5668\u548c\u57fa\u4e8eTransformer\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u80fd\u591f\u5904\u7406\u957f\u671f\u65f6\u95f4\u4f9d\u8d56\u6027\u548c\u5c40\u90e8\u6a21\u5f0f\uff0c\u5e76\u5c06\u5916\u6e90\u6027\u5e72\u9884\u4fe1\u606f\u6574\u5408\u5230\u8fc7\u7a0b\u5efa\u6a21\u4e2d\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728ATE\u4f30\u8ba1\u548c\u62df\u5408\u4f18\u5ea6\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2507.11525", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.11525", "abs": "https://arxiv.org/abs/2507.11525", "authors": ["Ana Davila", "Jacinto Colan", "Yasuhisa Hasegawa"], "title": "LLM-based ambiguity detection in natural language instructions for collaborative surgical robots", "comment": "Accepted at 2025 IEEE International Conference on Robot and Human\n  Interactive Communication (ROMAN)", "summary": "Ambiguity in natural language instructions poses significant risks in\nsafety-critical human-robot interaction, particularly in domains such as\nsurgery. To address this, we propose a framework that uses Large Language\nModels (LLMs) for ambiguity detection specifically designed for collaborative\nsurgical scenarios. Our method employs an ensemble of LLM evaluators, each\nconfigured with distinct prompting techniques to identify linguistic,\ncontextual, procedural, and critical ambiguities. A chain-of-thought evaluator\nis included to systematically analyze instruction structure for potential\nissues. Individual evaluator assessments are synthesized through conformal\nprediction, which yields non-conformity scores based on comparison to a labeled\ncalibration dataset. Evaluating Llama 3.2 11B and Gemma 3 12B, we observed\nclassification accuracy exceeding 60% in differentiating ambiguous from\nunambiguous surgical instructions. Our approach improves the safety and\nreliability of human-robot collaboration in surgery by offering a mechanism to\nidentify potentially ambiguous instructions before robot action.", "AI": {"tldr": "\"\u5728\u624b\u672f\u4e2d\uff0c\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u53ef\u80fd\u5b58\u5728\u6b67\u4e49\uff0c\u5e26\u6765\u98ce\u9669\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u4e2a\u6846\u67b6\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u548c\u5171\u5f62\u9884\u6d4b\u6765\u68c0\u6d4b\u8fd9\u4e9b\u6b67\u4e49\uff0c\u5e76\u5728\u8bc4\u4f30\u4e2d\u5c55\u73b0\u51fa\u8d85\u8fc760%\u7684\u51c6\u786e\u7387\uff0c\u4ee5\u63d0\u9ad8\u4eba\u673a\u534f\u4f5c\u7684\u5b89\u5168\u6027\u3002\"", "motivation": "\"\u4e3a\u4e86\u89e3\u51b3\u5b89\u5168\u5173\u952e\u7684\u4eba\u673a\u4ea4\u4e92\uff08\u5c24\u5176\u662f\u5728\u624b\u672f\u7b49\u9886\u57df\uff09\u4e2d\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u7684\u6b67\u4e49\u6027\u95ee\u9898\u3002\"", "method": "\"\u63d0\u51fa\u4e00\u4e2a\u6846\u67b6\uff0c\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8fdb\u884c\u7279\u5b9a\u4e8e\u534f\u4f5c\u5916\u79d1\u573a\u666f\u7684\u6b67\u4e49\u68c0\u6d4b\u3002\u8be5\u65b9\u6cd5\u91c7\u7528LLM\u8bc4\u4f30\u5668\u96c6\u6210\uff0c\u7ed3\u5408\u94fe\u5f0f\u601d\u8003\u8bc4\u4f30\u5668\uff0c\u5e76\u901a\u8fc7\u5171\u5f62\u9884\u6d4b\u5408\u6210\u8bc4\u4f30\u7ed3\u679c.\"", "result": "\"\u5728\u5bf9Llama 3.2 11B\u548cGemma 3 12B\u7684\u8bc4\u4f30\u4e2d\uff0c\u533a\u5206\u6a21\u7cca\u4e0e\u975e\u6a21\u7cca\u7684\u5916\u79d1\u624b\u672f\u6307\u4ee4\u7684\u5206\u7c7b\u51c6\u786e\u7387\u8d85\u8fc760%\u3002\"", "conclusion": "\"\u8be5\u6846\u67b6\u901a\u8fc7\u96c6\u6210\u591a\u79cdLLM\u8bc4\u4f30\u5668\u5e76\u5229\u7528\u5171\u5f62\u9884\u6d4b\u6765\u5408\u6210\u8bc4\u4f30\uff0c\u4ece\u800c\u80fd\u591f\u8bc6\u522b\u6a21\u7cca\u7684\u795e\u7ecf\u5916\u79d1\u624b\u672f\u6307\u4ee4\uff0c\u63d0\u9ad8\u4e86\u4eba\u673a\u534f\u4f5c\u7684\u5b89\u5168\u6027\u4e0e\u53ef\u9760\u6027.\""}}
{"id": "2507.11188", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.11188", "abs": "https://arxiv.org/abs/2507.11188", "authors": ["Mustapha Anis Younes", "Sofia Zebboudj", "Abdelhakim Gharbi"], "title": "A Three-Party Lightweight Quantum Key Distribution Protocol in a Restricted Quantum Environment", "comment": "24 pages, 1 figure, 2 tables", "summary": "This study proposes a new lightweight quantum key distribution (LQKD)\nprotocol based on the four-particle cluster state within a quantum-restricted\nenvironment. The protocol enables a quantum-capable user to simultaneously\nestablish two separate secret keys with two \"classical\" users, who are limited\nto performing only the Hadamard operation and measurements in the $Z$ basis. By\nadopting a one-way qubit transmission approach, the proposed protocol addresses\nseveral limitations of existing semi-quantum key distribution (SQKD) schemes\nthat rely on two-way or circular transmission methods: (1) it eliminates the\nneed for classical participants to be equipped with costly quantum devices to\ndefend against quantum Trojan horse attacks; (2) it reduces the qubit\ntransmission distance; and (3) it achieves higher qubit efficiency.\nConsequently, the proposed three-party LQKD protocol is both more lightweight\nand practical than existing SQKD protocols. Furthermore, the security analysis\nshows that, in the ideal case, the protocol achieves the same level of security\nas fully quantum protocols. Finally, the study proves the unconditional\nsecurity of the protocol in the non-ideal case, demonstrating a noise tolerance\nclose to that of the BB84 protocol.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8f7b\u91cf\u7ea7\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08LQKD\uff09\u534f\u8bae\uff0c\u8be5\u534f\u8bae\u4f7f\u7528\u56db\u7c92\u5b50\u7c07\u72b6\u6001\uff0c\u5141\u8bb8\u4e00\u4e2a\u91cf\u5b50\u7528\u6237\u4e0e\u4e24\u4e2a\u7ecf\u5178\u7528\u6237\u540c\u65f6\u5efa\u7acb\u4e24\u4e2a\u72ec\u7acb\u7684\u5bc6\u94a5\u3002\u8be5\u534f\u8bae\u91c7\u7528\u5355\u5411\u4f20\u8f93\uff0c\u514b\u670d\u4e86\u73b0\u6709\u534a\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08SQKD\uff09\u65b9\u6848\u7684\u7f3a\u70b9\uff0c\u66f4\u8f7b\u4fbf\u5b9e\u7528\uff0c\u5b89\u5168\u7ea7\u522b\u4e0e\u5168\u91cf\u5b50\u534f\u8bae\u76f8\u5f53\uff0c\u5e76\u4e14\u5728\u975e\u7406\u60f3\u60c5\u51b5\u4e0b\u5177\u6709\u826f\u597d\u7684\u566a\u58f0\u5bb9\u9650\u3002", "motivation": "\u4e3a\u4e86\u514b\u670d\u73b0\u6709\u534a\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08SQKD\uff09\u65b9\u6848\u7684\u5c40\u9650\u6027\uff0c\u5982\u9700\u8981\u53cc\u5411\u4f20\u8f93\u3001\u7ecf\u5178\u53c2\u4e0e\u8005\u6613\u53d7\u91cf\u5b50\u6728\u9a6c\u653b\u51fb\u4ee5\u53ca\u91cf\u5b50\u6bd4\u7279\u6548\u7387\u8f83\u4f4e\u7b49\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8f7b\u91cf\u7ea7\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08LQKD\uff09\u534f\u8bae\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56db\u7c92\u5b50\u7c07\u72b6\u6001\u7684\u8f7b\u91cf\u7ea7\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08LQKD\uff09\u534f\u8bae\uff0c\u8be5\u534f\u8bae\u5141\u8bb8\u4e00\u4e2a\u6709\u91cf\u5b50\u80fd\u529b\u7684\u53c2\u4e0e\u8005\u540c\u65f6\u4e0e\u4e24\u4e2a\u4ec5\u9650\u4e8e\u6267\u884cHadamard\u64cd\u4f5c\u548cZ\u57fa\u6d4b\u91cf\u7684\u7ecf\u5178\u53c2\u4e0e\u8005\u5efa\u7acb\u4e24\u4e2a\u72ec\u7acb\u7684\u5bc6\u94a5\u3002\u8be5\u534f\u8bae\u91c7\u7528\u5355\u5411\u91cf\u5b50\u6bd4\u7279\u4f20\u8f93\uff0c\u514b\u670d\u4e86\u73b0\u6709\u534a\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08SQKD\uff09\u65b9\u6848\u4e2d\u9700\u8981\u53cc\u5411\u6216\u5faa\u73af\u4f20\u8f93\u7684\u9650\u5236\uff0c\u65e0\u9700\u7ecf\u5178\u53c2\u4e0e\u8005\u914d\u5907\u6602\u8d35\u7684\u91cf\u5b50\u8bbe\u5907\u6765\u9632\u5fa1\u91cf\u5b50\u6728\u9a6c\u653b\u51fb\uff0c\u51cf\u5c11\u4e86\u91cf\u5b50\u6bd4\u7279\u4f20\u8f93\u8ddd\u79bb\uff0c\u5e76\u63d0\u9ad8\u4e86\u91cf\u5b50\u6bd4\u7279\u6548\u7387\u3002", "result": "\u8be5\u534f\u8bae\u5b9e\u73b0\u4e86\u4e09\u65b9\u901a\u4fe1\uff0c\u4f7f\u4e00\u4e2a\u6709\u91cf\u5b50\u80fd\u529b\u7684\u53c2\u4e0e\u8005\u80fd\u591f\u540c\u65f6\u4e0e\u4e24\u4e2a\u7ecf\u5178\u53c2\u4e0e\u8005\u5efa\u7acb\u4e24\u4e2a\u72ec\u7acb\u7684\u5bc6\u94a5\u3002\u4e0e\u73b0\u6709\u65b9\u6848\u76f8\u6bd4\uff0c\u8be5\u534f\u8bae\u66f4\u8f7b\u91cf\u3001\u66f4\u5b9e\u7528\uff0c\u5e76\u4e14\u5728\u7406\u60f3\u60c5\u51b5\u4e0b\u5177\u6709\u4e0e\u5168\u91cf\u5b50\u534f\u8bae\u76f8\u540c\u7684\u5b89\u5168\u7ea7\u522b\u3002\u5728\u975e\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u8be5\u534f\u8bae\u88ab\u8bc1\u660e\u662f\u65e0\u6761\u4ef6\u5b89\u5168\u7684\uff0c\u5e76\u4e14\u5177\u6709\u63a5\u8fd1BB84\u534f\u8bae\u7684\u566a\u58f0\u5bb9\u9650\u3002", "conclusion": "\u8be5\u534f\u8bae\u6bd4\u73b0\u6709\u7684\u534a\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08SQKD\uff09\u534f\u8bae\u66f4\u8f7b\u91cf\u3001\u66f4\u5b9e\u7528\uff0c\u5e76\u4e14\u5728\u7406\u60f3\u60c5\u51b5\u4e0b\u5177\u6709\u4e0e\u5168\u91cf\u5b50\u534f\u8bae\u76f8\u540c\u7684\u5b89\u5168\u7ea7\u522b\u3002\u5728\u975e\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u8be5\u534f\u8bae\u88ab\u8bc1\u660e\u662f\u65e0\u6761\u4ef6\u5b89\u5168\u7684\uff0c\u5e76\u4e14\u5177\u6709\u63a5\u8fd1BB84\u534f\u8bae\u7684\u566a\u58f0\u5bb9\u9650\u3002"}}
{"id": "2507.11099", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11099", "abs": "https://arxiv.org/abs/2507.11099", "authors": ["Qiyang Wan", "Chengzhi Gao", "Ruiping Wang", "Xilin Chen"], "title": "A Survey on Interpretability in Visual Recognition", "comment": "20 pages, 7 figures, 2 tables. Under review", "summary": "In recent years, visual recognition methods have advanced significantly,\nfinding applications across diverse fields. While researchers seek to\nunderstand the mechanisms behind the success of these models, there is also a\ngrowing impetus to deploy them in critical areas like autonomous driving and\nmedical diagnostics to better diagnose failures, which promotes the development\nof interpretability research. This paper systematically reviews existing\nresearch on the interpretability of visual recognition models and proposes a\ntaxonomy of methods from a human-centered perspective. The proposed taxonomy\ncategorizes interpretable recognition methods based on Intent, Object,\nPresentation, and Methodology, thereby establishing a systematic and coherent\nset of grouping criteria for these XAI methods. Additionally, we summarize the\nrequirements for evaluation metrics and explore new opportunities enabled by\nrecent technologies, such as large multimodal models. We aim to organize\nexisting research in this domain and inspire future investigations into the\ninterpretability of visual recognition models.", "AI": {"tldr": "\u672c\u6587\u5bf9\u89c6\u89c9\u8bc6\u522b\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u8fdb\u884c\u4e86\u7efc\u8ff0\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u5206\u7c7b\u65b9\u6cd5\uff0c\u5e76\u8ba8\u8bba\u4e86\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u89c6\u89c9\u8bc6\u522b\u65b9\u6cd5\u5728\u81ea\u52a8\u9a7e\u9a76\u548c\u533b\u7597\u8bca\u65ad\u7b49\u5173\u952e\u9886\u57df\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5bf9\u5176\u8fdb\u884c\u6545\u969c\u8bca\u65ad\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u4ece\u800c\u63a8\u52a8\u4e86\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u7684\u53d1\u5c55\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u4eba\u672c\u4e3b\u4e49\u89d2\u5ea6\u5bf9\u53ef\u89e3\u91ca\u8bc6\u522b\u65b9\u6cd5\u8fdb\u884c\u5206\u7c7b\u7684\u4f53\u7cfb\uff0c\u6839\u636e\u610f\u56fe\u3001\u5bf9\u8c61\u3001\u5448\u73b0\u548c\u65b9\u6cd5\u8bba\u5bf9\u53ef\u89e3\u91ca\u8bc6\u522b\u65b9\u6cd5\u8fdb\u884c\u5206\u7c7b\uff0c\u4e3a\u8fd9\u4e9bXAI\u65b9\u6cd5\u5efa\u7acb\u4e86\u4e00\u5957\u7cfb\u7edf\u3001\u8fde\u8d2f\u7684\u5206\u7c7b\u6807\u51c6\u3002", "result": "\u672c\u6587\u7cfb\u7edf\u5730\u56de\u987e\u4e86\u89c6\u89c9\u8bc6\u522b\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u7684\u73b0\u6709\u7814\u7a76\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u65b9\u6cd5\u5206\u7c7b\u4f53\u7cfb\uff0c\u5e76\u5bf9\u8bc4\u4f30\u6307\u6807\u7684\u9700\u6c42\u8fdb\u884c\u4e86\u603b\u7ed3\uff0c\u540c\u65f6\u63a2\u7d22\u4e86\u591a\u6a21\u6001\u5927\u6a21\u578b\u7b49\u65b0\u6280\u672f\u5e26\u6765\u7684\u65b0\u673a\u9047\u3002", "conclusion": "\u672c\u7bc7\u8bba\u6587\u5bf9\u89c6\u89c9\u8bc6\u522b\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u8fdb\u884c\u4e86\u5168\u9762\u7684\u56de\u987e\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u65b9\u6cd5\u5206\u7c7b\u4f53\u7cfb\uff0c\u5e76\u5bf9\u8bc4\u4f30\u6307\u6807\u7684\u9700\u6c42\u8fdb\u884c\u4e86\u603b\u7ed3\uff0c\u540c\u65f6\u63a2\u7d22\u4e86\u591a\u6a21\u6001\u5927\u6a21\u578b\u7b49\u65b0\u6280\u672f\u5e26\u6765\u7684\u65b0\u673a\u9047\uff0c\u65e8\u5728\u7ec4\u7ec7\u73b0\u6709\u7814\u7a76\u5e76\u542f\u53d1\u672a\u6765\u5de5\u4f5c\u3002"}}
{"id": "2507.11527", "categories": ["cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2507.11527", "abs": "https://arxiv.org/abs/2507.11527", "authors": ["Yinsheng Li", "Zhen Dong", "Yi Shao"], "title": "DrafterBench: Benchmarking Large Language Models for Tasks Automation in Civil Engineering", "comment": "Project page: https://github.com/Eason-Li-AIS/DrafterBench", "summary": "Large Language Model (LLM) agents have shown great potential for solving\nreal-world problems and promise to be a solution for tasks automation in\nindustry. However, more benchmarks are needed to systematically evaluate\nautomation agents from an industrial perspective, for example, in Civil\nEngineering. Therefore, we propose DrafterBench for the comprehensive\nevaluation of LLM agents in the context of technical drawing revision, a\nrepresentation task in civil engineering. DrafterBench contains twelve types of\ntasks summarized from real-world drawing files, with 46 customized\nfunctions/tools and 1920 tasks in total. DrafterBench is an open-source\nbenchmark to rigorously test AI agents' proficiency in interpreting intricate\nand long-context instructions, leveraging prior knowledge, and adapting to\ndynamic instruction quality via implicit policy awareness. The toolkit\ncomprehensively assesses distinct capabilities in structured data\ncomprehension, function execution, instruction following, and critical\nreasoning. DrafterBench offers detailed analysis of task accuracy and error\nstatistics, aiming to provide deeper insight into agent capabilities and\nidentify improvement targets for integrating LLMs in engineering applications.\nOur benchmark is available at https://github.com/Eason-Li-AIS/DrafterBench,\nwith the test set hosted at\nhttps://huggingface.co/datasets/Eason666/DrafterBench.", "AI": {"tldr": "DrafterBench is a new benchmark for evaluating LLM agents in civil engineering drawing revisions, featuring diverse tasks and tools to test AI capabilities and guide improvements for industrial applications.", "motivation": "Need for systematic evaluation of LLM agents for industrial automation, specifically in Civil Engineering, to assess their potential in tasks like technical drawing revision.", "method": "Propose DrafterBench, a benchmark containing 12 task types from real-world drawing files, 46 customized functions/tools, and 1920 tasks, to rigorously test AI agents' proficiency in interpreting instructions, leveraging prior knowledge, and adapting to dynamic instruction quality.", "result": "DrafterBench comprehensively assesses distinct capabilities including structured data comprehension, function execution, instruction following, and critical reasoning, providing detailed analysis of task accuracy and error statistics.", "conclusion": "DrafterBench is an open-source benchmark designed to evaluate LLM agents in technical drawing revision for civil engineering, offering comprehensive assessment of various capabilities and detailed analysis for identifying improvement targets."}}
{"id": "2507.11292", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.11292", "abs": "https://arxiv.org/abs/2507.11292", "authors": ["Zewen Bai", "Liang Yang", "Shengdi Yin", "Yuanyuan Sun", "Hongfei Lin"], "title": "Fine-Grained Chinese Hate Speech Understanding: Span-Level Resources, Coded Term Lexicon, and Enhanced Detection Frameworks", "comment": null, "summary": "The proliferation of hate speech has inflicted significant societal harm,\nwith its intensity and directionality closely tied to specific targets and\narguments. In recent years, numerous machine learning-based methods have been\ndeveloped to detect hateful comments on online platforms automatically.\nHowever, research on Chinese hate speech detection lags behind, and\ninterpretability studies face two major challenges: first, the scarcity of\nspan-level fine-grained annotated datasets limits models' deep semantic\nunderstanding of hate speech; second, insufficient research on identifying and\ninterpreting coded hate speech restricts model explainability in complex\nreal-world scenarios. To address these, we make the following contributions:\n(1) We introduce the Span-level Target-Aware Toxicity Extraction dataset (STATE\nToxiCN), the first span-level Chinese hate speech dataset, and evaluate the\nhate semantic understanding of existing models using it. (2) We conduct the\nfirst comprehensive study on Chinese coded hate terms, LLMs' ability to\ninterpret hate semantics. (3) We propose a method to integrate an annotated\nlexicon into models, significantly enhancing hate speech detection performance.\nOur work provides valuable resources and insights to advance the\ninterpretability of Chinese hate speech detection research.", "AI": {"tldr": "\u672c\u7814\u7a76\u89e3\u51b3\u4e86\u4e2d\u6587\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u4e2d\u7684\u53ef\u89e3\u91ca\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u53d1\u5e03\u65b0\u6570\u636e\u96c6\u3001\u7814\u7a76\u9690\u6666\u4ec7\u6068\u8bcd\u6c47\u548c\u63d0\u51fa\u65b0\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u4e2d\u6587\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u9886\u57df\u5b58\u5728\u7684\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u9488\u5bf9\u4e2d\u6587\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u8d77\u6b65\u8f83\u665a\uff0c\u4ee5\u53ca\u7f3a\u4e4f\u53e5\u67c4\u7ea7\u7ec6\u7c92\u5ea6\u6807\u6ce8\u6570\u636e\u96c6\u548c\u5bf9\u9690\u6666\u4ec7\u6068\u8a00\u8bba\u8bc6\u522b\u4e0e\u89e3\u91ca\u7684\u7814\u7a76\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u65b9\u6cd5\u6574\u5408\u4e86\u4e00\u4e2a\u5e26\u6ce8\u91ca\u7684\u8bcd\u6c47\u8868\u5230\u6a21\u578b\u4e2d\uff0c\u4ee5\u63d0\u9ad8\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u7684\u6027\u80fd\u3002", "result": "\u672c\u7814\u7a76\u5f15\u5165\u4e86\u9996\u4e2a\u53e5\u67c4\u7ea7\u4e2d\u6587\u4ec7\u6068\u8a00\u8bba\u6570\u636e\u96c6STATE ToxiCN\uff0c\u5e76\u5bf9\u73b0\u6709\u6a21\u578b\u8fdb\u884c\u4e86\u8bc4\u4f30\uff1b\u8fdb\u884c\u4e86\u9996\u4e2a\u5168\u9762\u7684\u4e2d\u6587\u9690\u6666\u4ec7\u6068\u8bcd\u6c47\u7814\u7a76\uff0c\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u89e3\u91ca\u4ec7\u6068\u8bed\u4e49\u65b9\u9762\u7684\u80fd\u529b\uff1b\u6240\u63d0\u51fa\u7684\u6574\u5408\u5e26\u6ce8\u91ca\u8bcd\u6c47\u8868\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u6027\u80fd\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u5f15\u5165\u9996\u4e2a\u4e2d\u6587\u53e5\u67c4\u7ea7\u4e2d\u6587\u4ec7\u6068\u8a00\u8bba\u6570\u636e\u96c6STATE ToxiCN\uff0c\u5e76\u8fdb\u884c\u5168\u9762\u7684\u4e2d\u6587\u9690\u6666\u4ec7\u6068\u8bcd\u6c47\u7814\u7a76\uff0c\u4ee5\u53ca\u63d0\u51fa\u5c06\u8bcd\u6c47\u8868\u6574\u5408\u5230\u6a21\u578b\u4e2d\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u6027\u80fd\uff0c\u4e3a\u4e2d\u6587\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u8d44\u6e90\u548c\u89c1\u89e3\u3002"}}
{"id": "2507.10820", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10820", "abs": "https://arxiv.org/abs/2507.10820", "authors": ["Robert M\u00fcller"], "title": "Semantic Context for Tool Orchestration", "comment": "Workshop on Computer Use Agents @ ICML2025", "summary": "This paper demonstrates that Semantic Context (SC), leveraging descriptive\ntool information, is a foundational component for robust tool orchestration.\nOur contributions are threefold. First, we provide a theoretical foundation\nusing contextual bandits, introducing SC-LinUCB and proving it achieves lower\nregret and adapts favourably in dynamic action spaces. Second, we provide\nparallel empirical validation with Large Language Models, showing that SC is\ncritical for successful in-context learning in both static (efficient learning)\nand non-stationary (robust adaptation) settings. Third, we propose the FiReAct\npipeline, and demonstrate on a benchmark with over 10,000 tools that SC-based\nretrieval enables an LLM to effectively orchestrate over a large action space.\nThese findings provide a comprehensive guide to building more sample-efficient,\nadaptive, and scalable orchestration agents.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u4e86\u8bed\u4e49\u4e0a\u4e0b\u6587\uff08SC\uff09\u662f\u5de5\u5177\u7f16\u6392\u7684\u5173\u952e\uff0c\u5e76\u63d0\u51fa\u4e86SC-LinUCB\u548cFiReAct\u6d41\u6c34\u7ebf\uff0c\u4ee5\u63d0\u9ad8LLM\u5728\u5de5\u5177\u9009\u62e9\u548c\u7f16\u6392\u65b9\u9762\u7684\u6548\u7387\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u4e3a\u63d0\u9ad8\u5de5\u5177\u7f16\u6392\u7684\u9c81\u68d2\u6027\uff0c\u672c\u6587\u65e8\u5728\u63a2\u7d22\u548c\u9a8c\u8bc1\u8bed\u4e49\u4e0a\u4e0b\u6587\uff08Semantic Context, SC\uff09\u5728\u5229\u7528\u63cf\u8ff0\u6027\u5de5\u5177\u4fe1\u606f\u65b9\u9762\u7684\u57fa\u7840\u4f5c\u7528\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4f7f\u7528\u4e0a\u4e0b\u6587\u8001\u864e\u673a\uff08contextual bandits\uff09\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5f15\u5165\u4e86SC-LinUCB\u7b97\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5728\u52a8\u6001\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u5177\u6709\u66f4\u4f4e\u7684\u9057\u61be\uff08regret\uff09\u548c\u66f4\u597d\u7684\u9002\u5e94\u6027\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u63d0\u4f9b\u4e86\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5e76\u884c\u5b9e\u8bc1\u9a8c\u8bc1\uff0c\u5e76\u63d0\u51fa\u4e86FiReAct\u6d41\u6c34\u7ebf\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u8bed\u4e49\u4e0a\u4e0b\u6587\uff08SC\uff09\u662f\u5b9e\u73b0\u9c81\u68d2\u5de5\u5177\u7f16\u6392\u7684\u57fa\u7840\u3002SC-LinUCB\u5728\u52a8\u6001\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u8868\u73b0\u51fa\u66f4\u4f4e\u7684\u9057\u61be\u548c\u66f4\u597d\u7684\u9002\u5e94\u6027\u3002\u5728\u9759\u6001\u548c\u975e\u5e73\u7a33\u8bbe\u7f6e\u4e2d\uff0cSC\u5bf9\u4e8e\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u81f3\u5173\u91cd\u8981\u3002FiReAct\u6d41\u6c34\u7ebf\u5728\u5305\u542b\u8d85\u8fc710,000\u4e2a\u5de5\u5177\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8bc1\u660e\u4e86SC\u9a71\u52a8\u7684\u68c0\u7d22\u80fd\u591f\u4f7fLLM\u6709\u6548\u5730\u7f16\u6392\u5927\u578b\u52a8\u4f5c\u7a7a\u95f4\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6784\u5efa\u66f4\u5177\u6837\u672c\u6548\u7387\u3001\u81ea\u9002\u5e94\u6027\u548c\u53ef\u6269\u5c55\u6027\u7684\u5de5\u5177\u7f16\u6392\u4ee3\u7406\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u6307\u5bfc\u3002"}}
{"id": "2507.11204", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.11204", "abs": "https://arxiv.org/abs/2507.11204", "authors": ["Tianqi Xiao", "Yaxin Wang", "Ying Xia", "Zhihao Li", "Xiaoqi Zhou"], "title": "$d+1$ Measurement Bases are Sufficient for Determining $d$-Dimensional Quantum States: Theory and Experiment", "comment": null, "summary": "A long-standing problem in quantum physics is to determine the minimal number\nof measurement bases required for the complete characterization of unknown\nquantum states, a question of particular relevance to high-dimensional quantum\ninformation processing. Here, we propose a quantum state tomography scheme that\nrequires only $d+1$ projective measurement bases to fully reconstruct an\narbitrary $d$-dimensional quantum state. As a proof-of-principle, we\nexperimentally verified this scheme on a silicon photonic chip by\nreconstructing quantum states for $d=6$, in which a complete set of mutually\nunbiased bases does not exist. This approach offers new perspectives for\nquantum state characterization and measurement design, and holds promise for\nfuture applications in quantum information processing.", "AI": {"tldr": "\u91cf\u5b50\u7269\u7406\u5b66\u754c\u957f\u671f\u5173\u6ce8\u5982\u4f55\u7528\u6700\u5c11\u7684\u6d4b\u91cf\u57fa\u6765\u8868\u5f81\u91cf\u5b50\u6001\uff0c\u5c24\u5176\u5728\u9ad8\u7ef4\u91cf\u5b50\u4fe1\u606f\u5904\u7406\u9886\u57df\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u521b\u65b0\u7684\u91cf\u5b50\u6001\u5c42\u6790\u65b9\u6848\uff0c\u4ec5\u7528d+1\u4e2a\u6d4b\u91cf\u57fa\u5c31\u80fd\u5b8c\u6574\u91cd\u6784\u4efb\u610fd\u7ef4\u91cf\u5b50\u6001\u3002\u5b9e\u9a8c\u4e0a\uff0c\u8be5\u65b9\u6848\u5728d=6\u7684\u7845\u5149\u5b50\u82af\u7247\u4e0a\u5f97\u5230\u4e86\u9a8c\u8bc1\uff0c\u5373\u4f7f\u5728\u8be5\u7ef4\u5ea6\u4e0b\u4e0d\u5b58\u5728\u4e92\u8865\u57fa\u3002\u6b64\u65b9\u6cd5\u4e3a\u91cf\u5b50\u6001\u8868\u5f81\u548c\u6d4b\u91cf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u5e76\u9884\u793a\u7740\u5176\u5728\u672a\u6765\u91cf\u5b50\u4fe1\u606f\u5904\u7406\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u786e\u5b9a\u5b8c\u6574\u8868\u5f81\u672a\u77e5\u91cf\u5b50\u6001\u6240\u9700\u7684\u6700\u5c0f\u6d4b\u91cf\u57fa\u6570\u91cf\u662f\u91cf\u5b50\u7269\u7406\u5b66\u4e2d\u7684\u4e00\u4e2a\u957f\u671f\u5b58\u5728\u7684\u95ee\u9898\uff0c\u8fd9\u5bf9\u4e8e\u9ad8\u7ef4\u91cf\u5b50\u4fe1\u606f\u5904\u7406\u5c24\u5176\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4ec5\u9700d+1\u4e2a\u6d4b\u91cf\u57fa\u5373\u53ef\u5b8c\u5168\u91cd\u6784\u4efb\u610fd\u7ef4\u91cf\u5b50\u6001\u7684\u91cf\u5b50\u6001\u5c42\u6790\u65b9\u6848\u3002", "result": "\u901a\u8fc7\u5728\u7845\u5149\u5b50\u82af\u7247\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6848\u6210\u529f\u91cd\u5efa\u4e86d=6\u7684\u91cf\u5b50\u6001\uff0c\u5373\u4f7f\u5728\u4e0d\u5b58\u5728\u5b8c\u5168\u4e92\u8865\u57fa\u7684\u60c5\u51b5\u4e0b\u4e5f\u662f\u5982\u6b64\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u91cf\u5b50\u6001\u8868\u5f81\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5e76\u6709\u671b\u5728\u91cf\u5b50\u4fe1\u606f\u5904\u7406\u7684\u672a\u6765\u5e94\u7528\u4e2d\u53d1\u6325\u4f5c\u7528\u3002"}}
{"id": "2507.11102", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11102", "abs": "https://arxiv.org/abs/2507.11102", "authors": ["Jie Yang", "Wang Zeng", "Sheng Jin", "Lumin Xu", "Wentao Liu", "Chen Qian", "Zhen Li", "Ruimao Zhang"], "title": "KptLLM++: Towards Generic Keypoint Comprehension with Large Language Model", "comment": "Extended Version of KptLLM. arXiv admin note: text overlap with\n  arXiv:2411.01846", "summary": "The emergence of Multimodal Large Language Models (MLLMs) has revolutionized\nimage understanding by bridging textual and visual modalities. However, these\nmodels often struggle with capturing fine-grained semantic information, such as\nthe precise identification and analysis of object keypoints. Keypoints, as\nstructure-aware, pixel-level, and compact representations of objects,\nparticularly articulated ones, play a crucial role in applications such as\nfine-grained image analysis, object retrieval, and behavior recognition. In\nthis paper, we propose KptLLM++, a novel multimodal large language model that\nspecifically designed for generic keypoint comprehension through the\nintegration of diverse input modalities guided by user-defined instructions. By\nunifying keypoint detection across varied contexts, KptLLM++ establishes itself\nas an advanced interface, fostering more effective human-AI collaboration. The\nmodel is built upon a novel identify-then-detect paradigm, which first\ninterprets keypoint semantics and subsequently localizes their precise\npositions through a structured chain-of-thought reasoning mechanism. To push\nthe boundaries of performance, we have scaled up the training dataset to over\n500K samples, encompassing diverse objects, keypoint categories, image styles,\nand scenarios with complex occlusions. This extensive scaling enables KptLLM++\nto unlock its potential, achieving remarkable accuracy and generalization.\nComprehensive experiments on multiple keypoint detection benchmarks demonstrate\nits state-of-the-art performance, underscoring its potential as a unified\nsolution for fine-grained image understanding and its transformative\nimplications for human-AI interaction.", "AI": {"tldr": "KptLLM++ \u662f\u4e00\u4e2a\u65b0\u9896\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u201c\u8bc6\u522b-\u7136\u540e\u68c0\u6d4b\u201d\u8303\u5f0f\u548c\u7ed3\u6784\u5316\u601d\u7ef4\u94fe\u63a8\u7406\uff0c\u80fd\u591f\u7406\u89e3\u548c\u5b9a\u4f4d\u56fe\u50cf\u4e2d\u7684\u5173\u952e\u70b9\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u8bad\u7ec3\uff0c\u5728\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u6790\u548c\u4eba\u673a\u4ea4\u4e92\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u6355\u6349\u7ec6\u7c92\u5ea6\u8bed\u4e49\u4fe1\u606f\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u7cbe\u786e\u8bc6\u522b\u548c\u5206\u6790\u7269\u4f53\u7684\u5173\u952e\u70b9\u65b9\u9762\u3002\u800c\u5173\u952e\u70b9\u4f5c\u4e3a\u7269\u4f53\uff08\u5c24\u5176\u662f\u94f0\u63a5\u7269\u4f53\uff09\u7684\u7ed3\u6784\u611f\u77e5\u3001\u50cf\u7d20\u7ea7\u548c\u7d27\u51d1\u8868\u793a\uff0c\u5728\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u6790\u3001\u7269\u4f53\u68c0\u7d22\u548c\u884c\u4e3a\u8bc6\u522b\u7b49\u5e94\u7528\u4e2d\u81f3\u5173\u91cd\u8981\u3002", "method": "KptLLM++ \u91c7\u7528\u65b0\u9896\u7684\u201c\u8bc6\u522b-\u7136\u540e\u68c0\u6d4b\u201d\u8303\u5f0f\uff0c\u9996\u5148\u89e3\u91ca\u5173\u952e\u70b9\u8bed\u4e49\uff0c\u7136\u540e\u901a\u8fc7\u7ed3\u6784\u5316\u7684\u601d\u7ef4\u94fe\u63a8\u7406\u673a\u5236\u7cbe\u786e\u5b9a\u4f4d\u5176\u4f4d\u7f6e\u3002\u901a\u8fc7\u5c06\u7528\u6237\u5b9a\u4e49\u7684\u6307\u4ee4\u5f15\u5bfc\u4e0b\u7684\u591a\u79cd\u8f93\u5165\u6a21\u5f0f\u76f8\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u8de8\u4e0d\u540c\u4e0a\u4e0b\u6587\u7684\u5173\u952e\u70b9\u68c0\u6d4b\u7684\u7edf\u4e00\u3002", "result": "KptLLM++ \u5728\u591a\u4e2a\u5173\u952e\u70b9\u68c0\u6d4b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5c55\u73b0\u4e86\u5353\u8d8a\u7684\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "KptLLM++ \u5728\u591a\u4e2a\u5173\u952e\u70b9\u68c0\u6d4b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u5176\u4f5c\u4e3a\u7ec6\u7c92\u5ea6\u56fe\u50cf\u7406\u89e3\u7684\u7edf\u4e00\u89e3\u51b3\u65b9\u6848\u7684\u6f5c\u529b\uff0c\u4ee5\u53ca\u5bf9\u4eba\u673a\u4ea4\u4e92\u7684\u53d8\u9769\u6027\u5f71\u54cd\u3002"}}
{"id": "2507.11538", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11538", "abs": "https://arxiv.org/abs/2507.11538", "authors": ["Daniel Jaroslawicz", "Brendan Whiting", "Parth Shah", "Karime Maamari"], "title": "How Many Instructions Can LLMs Follow at Once?", "comment": null, "summary": "Production-grade LLM systems require robust adherence to dozens or even\nhundreds of instructions simultaneously. However, the instruction-following\ncapabilities of LLMs at high instruction densities have not yet been\ncharacterized, as existing benchmarks only evaluate models on tasks with a\nsingle or few instructions. We introduce IFScale, a simple benchmark of 500\nkeyword-inclusion instructions for a business report writing task to measure\nhow instruction-following performance degrades as instruction density\nincreases. We evaluate 20 state-of-the-art models across seven major providers\nand find that even the best frontier models only achieve 68% accuracy at the\nmax density of 500 instructions. Our analysis reveals model size and reasoning\ncapability to correlate with 3 distinct performance degradation patterns, bias\ntowards earlier instructions, and distinct categories of instruction-following\nerrors. Our insights can help inform design of instruction-dense prompts in\nreal-world applications and highlight important performance-latency tradeoffs.\nWe open-source the benchmark and all results for further analysis at\nhttps://distylai.github.io/IFScale.", "AI": {"tldr": "IFScale \u662f\u4e00\u4e2a\u5305\u542b 500 \u6761\u6307\u4ee4\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30 LLM \u5728\u9ad8\u5bc6\u5ea6\u6307\u4ee4\u4e0b\u7684\u8868\u73b0\u3002\u7ed3\u679c\u663e\u793a\uff0c\u5373\u4f7f\u662f\u6700\u597d\u7684\u6a21\u578b\uff0c\u5176\u51c6\u786e\u7387\u4e5f\u53ea\u6709 68%\uff0c\u5e76\u4e14\u5b58\u5728\u6a21\u578b\u89c4\u6a21\u3001\u63a8\u7406\u80fd\u529b\u3001\u5bf9\u65e9\u671f\u6307\u4ee4\u7684\u504f\u89c1\u548c\u9519\u8bef\u7c7b\u522b\u7b49\u5f71\u54cd\u56e0\u7d20\u3002", "motivation": "\u8bc4\u4f30 LLM \u5728\u9ad8\u6307\u4ee4\u5bc6\u5ea6\u4e0b\u7684\u6307\u4ee4\u9075\u5faa\u80fd\u529b\uff0c\u586b\u8865\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u7684\u7a7a\u767d\u3002", "method": "\u63d0\u51fa IFScale \u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b 500 \u6761\u7528\u4e8e\u5546\u4e1a\u62a5\u544a\u5199\u4f5c\u4efb\u52a1\u7684\u5173\u952e\u8bcd\u5305\u542b\u6307\u4ee4\uff0c\u4ee5\u8861\u91cf\u6307\u4ee4\u5bc6\u5ea6\u589e\u52a0\u65f6\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u7684\u4e0b\u964d\u60c5\u51b5\u3002\u8bc4\u4f30\u4e86 20 \u4e2a\u6700\u5148\u8fdb\u7684\u6a21\u578b\u3002", "result": "\u53d1\u73b0\u6a21\u578b\u89c4\u6a21\u548c\u63a8\u7406\u80fd\u529b\u4e0e\u6027\u80fd\u4e0b\u964d\u6a21\u5f0f\u3001\u5bf9\u65e9\u671f\u6307\u4ee4\u7684\u504f\u89c1\u548c\u9519\u8bef\u7c7b\u522b\u76f8\u5173\u3002\u5373\u4f7f\u662f\u6700\u597d\u7684 frontier \u6a21\u578b\uff0c\u5728 500 \u6761\u6307\u4ee4\u7684\u6700\u5927\u5bc6\u5ea6\u4e0b\u51c6\u786e\u7387\u4e5f\u53ea\u6709 68%\u3002", "conclusion": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u672a\u80fd\u5145\u5206\u8bc4\u4f30\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u9ad8\u5bc6\u5ea6\u6307\u4ee4\u4e0b\u7684\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u3002 frontier \u6a21\u578b\u5728 500 \u6761\u6307\u4ee4\u7684\u6700\u5927\u5bc6\u5ea6\u4e0b\u51c6\u786e\u7387\u4ec5\u4e3a 68%\u3002\u6a21\u578b\u89c4\u6a21\u548c\u63a8\u7406\u80fd\u529b\u4e0e\u6027\u80fd\u4e0b\u964d\u6a21\u5f0f\u3001\u5bf9\u65e9\u671f\u6307\u4ee4\u7684\u504f\u89c1\u4ee5\u53ca\u6307\u4ee4\u9075\u5faa\u9519\u8bef\u7c7b\u522b\u76f8\u5173\u3002IFScale \u57fa\u51c6\u6d4b\u8bd5\u6709\u52a9\u4e8e\u8bbe\u8ba1\u9ad8\u5bc6\u5ea6\u6307\u4ee4\u63d0\u793a\u5e76\u4e86\u89e3\u6027\u80fd-\u5ef6\u8fdf\u6743\u8861\u3002"}}
{"id": "2507.11299", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.11299", "abs": "https://arxiv.org/abs/2507.11299", "authors": ["Andrei Niculae", "Adrian Cosma", "Cosmin Dumitrache", "Emilian R\u01cedoi"], "title": "Dr.Copilot: A Multi-Agent Prompt Optimized Assistant for Improving Patient-Doctor Communication in Romanian", "comment": "10 figures, 2 tables, 2 listings", "summary": "Text-based telemedicine has become increasingly common, yet the quality of\nmedical advice in doctor-patient interactions is often judged more on how\nadvice is communicated rather than its clinical accuracy. To address this, we\nintroduce Dr.Copilot , a multi-agent large language model (LLM) system that\nsupports Romanian-speaking doctors by evaluating and enhancing the presentation\nquality of their written responses. Rather than assessing medical correctness,\nDr.Copilot provides feedback along 17 interpretable axes. The system comprises\nof three LLM agents with prompts automatically optimized via DSPy. Designed\nwith low-resource Romanian data and deployed using open-weight models, it\ndelivers real-time specific feedback to doctors within a telemedicine platform.\nEmpirical evaluations and live deployment with 41 doctors show measurable\nimprovements in user reviews and response quality, marking one of the first\nreal-world deployments of LLMs in Romanian medical settings.", "AI": {"tldr": "Dr.Copilot \u662f\u4e00\u4e2a\u652f\u6301\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u533b\u751f\u7684\u591a\u4e3b\u4f53 LLM \u7cfb\u7edf\uff0c\u901a\u8fc7\u4f18\u5316\u56de\u590d\u7684\u8868\u8fbe\u8d28\u91cf\u6765\u63d0\u5347\u6c9f\u901a\u6548\u679c\uff0c\u800c\u975e\u5173\u6ce8\u4e34\u5e8a\u51c6\u786e\u6027\uff0c\u5df2\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u53d6\u5f97\u6210\u6548\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u6587\u672c\u8fdc\u7a0b\u533b\u7597\u4e2d\uff0c\u533b\u7597\u5efa\u8bae\u7684\u8d28\u91cf\u5e38\u5e38\u88ab\u6c9f\u901a\u65b9\u5f0f\u800c\u975e\u4e34\u5e8a\u51c6\u786e\u6027\u6240\u5f71\u54cd\u7684\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa Dr.Copilot \u7cfb\u7edf\u4ee5\u652f\u6301\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u533b\u751f\uff0c\u63d0\u5347\u5176\u4e66\u9762\u56de\u590d\u7684\u8868\u8fbe\u8d28\u91cf\u3002", "method": "Dr.Copilot \u7cfb\u7edf\u5229\u7528\u4e09\u4e2a\u7ecf\u8fc7 DSPy \u4f18\u5316\u7684\u8bed\u8a00\u6a21\u578b\u4e3b\u4f53\uff0c\u4e13\u6ce8\u4e8e\u8bc4\u4f30\u548c\u589e\u5f3a\u533b\u751f\u56de\u590d\u7684\u8868\u8fbe\u8d28\u91cf\uff0c\u800c\u975e\u4e34\u5e8a\u51c6\u786e\u6027\uff0c\u5b83\u63d0\u4f9b\u4e86 17 \u4e2a\u53ef\u89e3\u91ca\u7684\u7ef4\u5ea6\u53cd\u9988\uff0c\u5e76\u9488\u5bf9\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u4f4e\u8d44\u6e90\u73af\u5883\u8fdb\u884c\u4e86\u4f18\u5316\u548c\u90e8\u7f72\u3002", "result": "\u8be5\u7cfb\u7edf\u5728\u7528\u6237\u8bc4\u4ef7\u548c\u56de\u590d\u8d28\u91cf\u65b9\u9762\u5747\u663e\u793a\u51fa\u53ef\u8861\u91cf\u7684\u6539\u8fdb\uff0c\u5e76\u5df2\u6210\u529f\u5e94\u7528\u4e8e\u771f\u5b9e\u4e16\u754c\u7684\u7f57\u9a6c\u5c3c\u4e9a\u533b\u7597\u73af\u5883\u3002", "conclusion": "Dr.Copilot \u4f5c\u4e3a\u4e00\u4e2a\u591a\u4e3b\u4f53\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\uff0c\u5728\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u7684\u533b\u7597\u73af\u5883\u4e2d\u5f97\u5230\u4e86\u9996\u6b21\u5b9e\u9645\u5e94\u7528\uff0c\u5e76\u901a\u8fc7\u4e86 41 \u540d\u533b\u751f\u7684\u5b9e\u9645\u90e8\u7f72\u548c\u8bc4\u4f30\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u63d0\u5347\u533b\u751f\u4e66\u9762\u56de\u590d\u7684\u8868\u8fbe\u8d28\u91cf\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u5e76\u5df2\u5728\u7528\u6237\u8bc4\u4ef7\u548c\u56de\u590d\u8d28\u91cf\u65b9\u9762\u53d6\u5f97\u4e86\u53ef\u8861\u91cf\u7684\u6539\u8fdb\u3002"}}
{"id": "2507.10834", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10834", "abs": "https://arxiv.org/abs/2507.10834", "authors": ["Guokai Li", "Pin Gao", "Stefanus Jasin", "Zizhuo Wang"], "title": "From Small to Large: A Graph Convolutional Network Approach for Solving Assortment Optimization Problems", "comment": "Conference version. The journal version will be updated soon", "summary": "Assortment optimization involves selecting a subset of substitutable products\n(subject to certain constraints) to maximize the expected revenue. It is a\nclassic problem in revenue management and finds applications across various\nindustries. However, the problem is usually NP-hard due to its combinatorial\nand non-linear nature. In this work, we explore how graph concolutional\nnetworks (GCNs) can be leveraged to efficiently solve constrained assortment\noptimization under the mixed multinomial logit choice model. We first develop a\ngraph representation of the assortment problem, then train a GCN to learn the\npatterns of optimal assortments, and lastly propose two inference policies\nbased on the GCN's output. Due to the GCN's inherent ability to generalize\nacross inputs of varying sizes, we can use a GCN trained on small-scale\ninstances to facilitate large-scale instances. Extensive numerical experiments\ndemonstrate that given a GCN trained on small-scale instances (e.g., with 20\nproducts), the proposed policies can achieve superior performance (90%+\noptimality) on large-scale instances (with up to 2,000 products) within\nseconds, which outperform existing heuristic policies in both performance and\nefficiency. Furthermore, we extend our framework to a model-free setting where\nthe underlying choice model is unknown but transaction data is available. We\nalso conduct numerical experiments to demonstrate the effectiveness and\nefficiency of our proposed policies in this setting.", "AI": {"tldr": "\u4f7f\u7528\u56fe\u5377\u79ef\u7f51\u7edc\uff08GCN\uff09\u89e3\u51b3 \u0430\u0441\u0441\u043e\u0440\u0442\u0438\u043c\u0435\u043d\u0442\u4f18\u5316\u95ee\u9898\uff0c\u5728\u5927\u89c4\u6a21\u5b9e\u4f8b\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u6548\u548c\u9ad8\u6027\u80fd\uff0c\u5e76\u53ef\u6269\u5c55\u5230\u6a21\u578b\u65e0\u5173\u7684\u573a\u666f\u3002", "motivation": "\u89e3\u51b3\u7ecf\u5178\u7684\u3001\u901a\u5e38\u662f NP-hard \u7684 \u0430\u0441\u0441\u043e\u0440\u0442\u0438\u043c\u0435\u043d\u0442\u4f18\u5316\u95ee\u9898\uff0c\u8be5\u95ee\u9898\u5728\u6536\u5165\u7ba1\u7406\u548c\u591a\u4e2a\u884c\u4e1a\u4e2d\u6709\u5e94\u7528\u3002", "method": "\u5c06 \u0430\u0441\u0441\u043e\u0440\u0442\u0438\u043c\u0435\u043d\u0442\u95ee\u9898\u8868\u793a\u4e3a\u56fe\uff0c\u7136\u540e\u8bad\u7ec3 GCN \u6765\u5b66\u4e60\u6700\u4f18 \u0430\u0441\u0441\u043e\u0440\u0442\u0438\u043c\u0435\u043d\u0442\u7684\u6a21\u5f0f\uff0c\u6700\u540e\u63d0\u51fa\u4e24\u79cd\u57fa\u4e8e GCN \u8f93\u51fa\u7684\u63a8\u7406\u7b56\u7565\u3002", "result": "\u5728\u5c0f\u89c4\u6a21\u5b9e\u4f8b\u4e0a\u8bad\u7ec3\u7684 GCN \u53ef\u4ee5\u5728\u51e0\u79d2\u949f\u5185\u5904\u7406\u5927\u89c4\u6a21\u5b9e\u4f8b\uff08\u6700\u591a 2,000 \u79cd\u4ea7\u54c1\uff09\uff0c\u8fbe\u5230 90% \u4ee5\u4e0a\u7684\u6700\u4f18\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u542f\u53d1\u5f0f\u7b56\u7565\u3002\u8be5\u65b9\u6cd5\u5728\u6a21\u578b\u65e0\u5173\u7684\u8bbe\u7f6e\u4e2d\u4e5f\u663e\u793a\u51fa\u6709\u6548\u6027\u3002", "conclusion": "\u56fe\u5377\u79ef\u7f51\u7edc\uff08GCN\uff09\u53ef\u4ee5\u6709\u6548\u5730\u89e3\u51b3\u6df7\u5408\u591a\u9879\u5f0f\u903b\u8f91\u65af\u8482\u9009\u62e9\u6a21\u578b\u4e0b\u7684\u7ea6\u675f \u0430\u0441\u0441\u043e\u0440\u0442\u0438\u043c\u0435\u043d\u0442\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u4e14\u8be5\u65b9\u6cd5\u80fd\u591f\u6cdb\u5316\u5230\u5927\u89c4\u6a21\u5b9e\u4f8b\uff0c\u5728\u6548\u7387\u548c\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u542f\u53d1\u5f0f\u7b56\u7565\u3002\u6b64\u5916\uff0c\u8be5\u6846\u67b6\u8fd8\u53ef\u4ee5\u6269\u5c55\u5230\u6a21\u578b\u65e0\u5173\u7684\u8bbe\u7f6e\u3002"}}
{"id": "2507.10843", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.10843", "abs": "https://arxiv.org/abs/2507.10843", "authors": ["Motoki Omura", "Yusuke Mukuta", "Kazuki Ota", "Takayuki Osa", "Tatsuya Harada"], "title": "Offline Reinforcement Learning with Wasserstein Regularization via Optimal Transport Maps", "comment": "Accepted at RLC 2025", "summary": "Offline reinforcement learning (RL) aims to learn an optimal policy from a\nstatic dataset, making it particularly valuable in scenarios where data\ncollection is costly, such as robotics. A major challenge in offline RL is\ndistributional shift, where the learned policy deviates from the dataset\ndistribution, potentially leading to unreliable out-of-distribution actions. To\nmitigate this issue, regularization techniques have been employed. While many\nexisting methods utilize density ratio-based measures, such as the\n$f$-divergence, for regularization, we propose an approach that utilizes the\nWasserstein distance, which is robust to out-of-distribution data and captures\nthe similarity between actions. Our method employs input-convex neural networks\n(ICNNs) to model optimal transport maps, enabling the computation of the\nWasserstein distance in a discriminator-free manner, thereby avoiding\nadversarial training and ensuring stable learning. Our approach demonstrates\ncomparable or superior performance to widely used existing methods on the D4RL\nbenchmark dataset. The code is available at\nhttps://github.com/motokiomura/Q-DOT .", "AI": {"tldr": "\u4e00\u79cd\u65b0\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5229\u7528Wasserstein\u8ddd\u79bb\u548cICNNs\u89e3\u51b3\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u5728D4RL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u4e2d\u7531\u7b56\u7565\u4e0e\u6570\u636e\u96c6\u5206\u5e03\u4e0d\u5339\u914d\u5f15\u8d77\u7684\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u6bd4\u57fa\u4e8ef\u6563\u5ea6\u7b49\u5bc6\u5ea6\u6bd4\u7387\u5ea6\u91cf\u66f4\u9c81\u80fa\u5206\u5e03\u5916\u6570\u636e\u7684\u6b63\u5219\u5316\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u5229\u7528Wasserstein\u8ddd\u79bb\u6765\u5904\u7406\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u5206\u5e03\u504f\u79fb\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4f7f\u7528\u8f93\u5165\u51f8\u795e\u7ecf\u7f51\u7edc\uff08ICNNs\uff09\u6765\u6a21\u62df\u6700\u4f18\u4f20\u8f93\u6620\u5c04\uff0c\u4ece\u800c\u907f\u514d\u4e86\u5bf9\u6297\u6027\u8bad\u7ec3\uff0c\u4fdd\u8bc1\u4e86\u5b66\u4e60\u7684\u7a33\u5b9a\u6027\u3002", "result": "\u5728D4RL\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u76f8\u5f53\u6216\u66f4\u4f18\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728D4RL\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u5f53\u6216\u66f4\u4f18\u7684\u6027\u80fd\u3002"}}
{"id": "2507.11217", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.11217", "abs": "https://arxiv.org/abs/2507.11217", "authors": ["Yu-Chao Hsu", "Kuan-Cheng Chen", "Tai-Yue Li", "Nan-Yow Chen"], "title": "Quantum Adaptive Excitation Network with Variational Quantum Circuits for Channel Attention", "comment": null, "summary": "In this work, we introduce the Quantum Adaptive Excitation Network (QAE-Net),\na hybrid quantum-classical framework designed to enhance channel attention\nmechanisms in Convolutional Neural Networks (CNNs). QAE-Net replaces the\nclassical excitation block of Squeeze-and-Excitation modules with a shallow\nVariational Quantum Circuit (VQC), leveraging quantum superposition and\nentanglement to capture higher-order inter-channel dependencies that are\nchallenging to model with purely classical approaches. We evaluate QAE-Net on\nbenchmark image classification tasks, including MNIST, FashionMNIST, and\nCIFAR-10, and observe consistent performance improvements across all datasets,\nwith particularly notable gains on tasks involving three-channel inputs.\nFurthermore, experimental results demonstrate that increasing the number of\nvariational layers in the quantum circuit leads to progressively higher\nclassification accuracy, underscoring the expressivity benefits of deeper\nquantum models. These findings highlight the potential of integrating VQCs into\nCNN architectures to improve representational capacity while maintaining\ncompatibility with near-term quantum devices. The proposed approach is tailored\nfor the Noisy Intermediate-Scale Quantum (NISQ) era, offering a scalable and\nfeasible pathway for deploying quantum-enhanced attention mechanisms in\npractical deep learning workflows.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aQAE-Net\u7684\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u6846\u67b6\uff0c\u901a\u8fc7\u7528\u53d8\u5206\u91cf\u5b50\u7535\u8def\uff08VQC\uff09\u66ff\u6362CNN\u4e2d\u7684\u7ecf\u5178\u6fc0\u52b1\u5757\u6765\u589e\u5f3a\u901a\u9053\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5e76\u5728\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u4e3a\u4e86\u589e\u5f3a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u4e2d\u7684\u901a\u9053\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5e76\u89e3\u51b3\u7eaf\u7ecf\u5178\u65b9\u6cd5\u96be\u4ee5\u5efa\u6a21\u7684\u9ad8\u9636\u901a\u9053\u95f4\u4f9d\u8d56\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u91cf\u5b50\u81ea\u9002\u5e94\u6fc0\u52b1\u7f51\u7edc\uff08QAE-Net\uff09\u7684\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7528\u6d45\u5c42\u53d8\u5206\u91cf\u5b50\u7535\u8def\uff08VQC\uff09\u66ff\u6362\u4e86CNN\u4e2dSqueeze-and-Excitation\u6a21\u5757\u7684\u7ecf\u5178\u6fc0\u52b1\u5757\uff0c\u4ee5\u5229\u7528\u91cf\u5b50\u53e0\u52a0\u548c\u7ea0\u7f20\u6765\u6355\u6349\u9ad8\u9636\u901a\u9053\u95f4\u4f9d\u8d56\u6027\u3002", "result": "\u5728MNIST\u3001FashionMNIST\u548cCIFAR-10\u7b49\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e0a\u89c2\u5bdf\u5230\u4e86\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u4e09\u901a\u9053\u8f93\u5165\u65f6\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u589e\u52a0\u91cf\u5b50\u7ebf\u8def\u4e2d\u7684\u53d8\u5206\u5c42\u6570\u53ef\u4ee5\u9010\u6b65\u63d0\u9ad8\u5206\u7c7b\u51c6\u786e\u6027\u3002", "conclusion": "QAE-Net\u901a\u8fc7\u5c06CNN\u4e2d\u7684\u7ecf\u5178\u6fc0\u52b1\u5757\u66ff\u6362\u4e3aVQC\uff0c\u5c55\u793a\u4e86\u5728\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e0a\u63d0\u5347\u6027\u80fd\u7684\u6f5c\u529b\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u4e09\u901a\u9053\u8f93\u5165\u65f6\u3002\u589e\u52a0\u91cf\u5b50\u7ebf\u8def\u7684\u53d8\u5206\u5c42\u6570\u53ef\u8fdb\u4e00\u6b65\u63d0\u9ad8\u5206\u7c7b\u51c6\u786e\u6027\uff0c\u8868\u660e\u66f4\u6df1\u7684\u91cf\u5b50\u6a21\u578b\u5177\u6709\u66f4\u597d\u7684\u8868\u8fbe\u80fd\u529b\u3002\u8be5\u65b9\u6cd5\u9002\u7528\u4e8eNISQ\u65f6\u4ee3\uff0c\u4e3a\u5728\u5b9e\u9645\u6df1\u5ea6\u5b66\u4e60\u5de5\u4f5c\u6d41\u4e2d\u90e8\u7f72\u91cf\u5b50\u589e\u5f3a\u7684\u6ce8\u610f\u529b\u673a\u5236\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u9014\u5f84\u3002"}}
{"id": "2507.11116", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11116", "abs": "https://arxiv.org/abs/2507.11116", "authors": ["Md. Sabbir Hossen", "Md. Saiduzzaman", "Pabon Shaha", "Mostofa Kamal Nasir"], "title": "Jellyfish Species Identification: A CNN Based Artificial Neural Network Approach", "comment": "This paper has been accepted at the IEEE QPAIN 2025. The final\n  version will be available in the IEEE Xplore Digital Library", "summary": "Jellyfish, a diverse group of gelatinous marine organisms, play a crucial\nrole in maintaining marine ecosystems but pose significant challenges for\nbiodiversity and conservation due to their rapid proliferation and ecological\nimpact. Accurate identification of jellyfish species is essential for\necological monitoring and management. In this study, we proposed a deep\nlearning framework for jellyfish species detection and classification using an\nunderwater image dataset. The framework integrates advanced feature extraction\ntechniques, including MobileNetV3, ResNet50, EfficientNetV2-B0, and VGG16,\ncombined with seven traditional machine learning classifiers and three\nFeedforward Neural Network classifiers for precise species identification.\nAdditionally, we activated the softmax function to directly classify jellyfish\nspecies using the convolutional neural network models. The combination of the\nArtificial Neural Network with MobileNetV3 is our best-performing model,\nachieving an exceptional accuracy of 98%, significantly outperforming other\nfeature extractor-classifier combinations. This study demonstrates the efficacy\nof deep learning and hybrid frameworks in addressing biodiversity challenges\nand advancing species detection in marine environments.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u591a\u79cd\u7279\u5f81\u63d0\u53d6\u6280\u672f\u548c\u5206\u7c7b\u5668\uff0c\u5b9e\u73b0\u4e86\u5bf9\u6c34\u6bcd\u7269\u79cd\u7684\u9ad8\u6548\u68c0\u6d4b\u548c\u5206\u7c7b\uff0c\u5176\u4e2d\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u4e0eMobileNetV3\u7684\u7ec4\u5408\u8868\u73b0\u6700\u4f73\uff0c\u51c6\u786e\u7387\u9ad8\u8fbe98%\u3002", "motivation": "\u6c34\u6bcd\u5728\u6d77\u6d0b\u751f\u6001\u7cfb\u7edf\u4e2d\u626e\u6f14\u7740\u81f3\u5173\u91cd\u8981\u7684\u89d2\u8272\uff0c\u4f46\u7531\u4e8e\u5176\u5feb\u901f\u7e41\u6b96\u548c\u751f\u6001\u5f71\u54cd\uff0c\u7ed9\u751f\u7269\u591a\u6837\u6027\u548c\u4fdd\u62a4\u5e26\u6765\u4e86\u91cd\u5927\u6311\u6218\u3002\u51c6\u786e\u8bc6\u522b\u6c34\u6bcd\u7269\u79cd\u5bf9\u4e8e\u751f\u6001\u76d1\u6d4b\u548c\u7ba1\u7406\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528MobileNetV3\u3001ResNet50\u3001EfficientNetV2-B0\u548cVGG16\u7b49\u5148\u8fdb\u7279\u5f81\u63d0\u53d6\u6280\u672f\uff0c\u5e76\u7ed3\u5408\u4e86\u4e03\u79cd\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u548c\u4e09\u79cd\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u5206\u7c7b\u5668\uff0c\u4ee5\u5b9e\u73b0\u7cbe\u786e\u7684\u7269\u79cd\u8bc6\u522b\u3002\u6b64\u5916\uff0c\u8fd8\u6fc0\u6d3b\u4e86softmax\u51fd\u6570\uff0c\u76f4\u63a5\u4f7f\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5bf9\u6c34\u6bcd\u7269\u79cd\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc\u4e0eMobileNetV3\u7684\u7ec4\u5408\u662f\u8868\u73b0\u6700\u4f73\u7684\u6a21\u578b\uff0c\u8fbe\u5230\u4e8698%\u7684\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u7279\u5f81\u63d0\u53d6\u5668-\u5206\u7c7b\u5668\u7ec4\u5408\u3002", "conclusion": "\u672c\u7814\u7a76\u5c55\u793a\u4e86\u6df1\u5ea6\u5b66\u4e60\u548c\u6df7\u5408\u6846\u67b6\u5728\u5e94\u5bf9\u751f\u7269\u591a\u6837\u6027\u6311\u6218\u548c\u63a8\u8fdb\u6d77\u6d0b\u73af\u5883\u7269\u79cd\u68c0\u6d4b\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2111.06614", "categories": ["cs.LG", "cs.AI", "cs.MA", "I.2.11; I.2.6"], "pdf": "https://arxiv.org/pdf/2111.06614", "abs": "https://arxiv.org/abs/2111.06614", "authors": ["Ilai Shraga", "Guy Azran", "Matthias Gerstgrasser", "Ofir Abu", "Jeffrey S. Rosenschein", "Sarah Keren"], "title": "Collaboration Promotes Group Resilience in Multi-Agent RL", "comment": "RLC 2025", "summary": "To effectively operate in various dynamic scenarios, RL agents must be\nresilient to unexpected changes in their environment. Previous work on this\nform of resilience has focused on single-agent settings. In this work, we\nintroduce and formalize a multi-agent variant of resilience, which we term\ngroup resilience. We further hypothesize that collaboration with other agents\nis key to achieving group resilience; collaborating agents adapt better to\nenvironmental perturbations in multi-agent reinforcement learning (MARL)\nsettings. We test our hypothesis empirically by evaluating different\ncollaboration protocols and examining their effect on group resilience. Our\nexperiments show that all the examined collaborative approaches achieve higher\ngroup resilience than their non-collaborative counterparts.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u7fa4\u4f53\u5f39\u6027\u7684\u6982\u5ff5\uff0c\u5e76\u8bc1\u660e\u4e86\u534f\u4f5c\u5728\u63d0\u9ad8 MARL \u4e2d\u4ee3\u7406\u5bf9\u73af\u5883\u6270\u52a8\u7684\u9002\u5e94\u6027\u65b9\u9762\u7684\u4f5c\u7528\u3002", "motivation": "\u4e3a\u4e86\u5728\u5404\u79cd\u52a8\u6001\u573a\u666f\u4e2d\u6709\u6548\u8fd0\u884c\uff0cRL\u4ee3\u7406\u5fc5\u987b\u5bf9\u73af\u5883\u7684\u610f\u5916\u53d8\u5316\u5177\u6709\u5f39\u6027\u3002\u6b64\u524d\u7684\u5173\u4e8e\u8fd9\u79cd\u5f62\u5f0f\u5f39\u6027\u7684\u7814\u7a76\u96c6\u4e2d\u5728\u5355\u4ee3\u7406\u8bbe\u7f6e\u4e0a\u3002\u672c\u7814\u7a76\u5de5\u4f5c\u4ecb\u7ecd\u4e86\u5e76\u5f62\u5f0f\u5316\u4e86\u5f39\u6027\u7684\u591a\u4ee3\u7406\u53d8\u4f53\uff0c\u6211\u4eec\u79f0\u4e4b\u4e3a\u7fa4\u4f53\u5f39\u6027\u3002", "method": "\u901a\u8fc7\u8bc4\u4f30\u4e0d\u540c\u7684\u534f\u4f5c\u534f\u8bae\u5e76\u68c0\u67e5\u5b83\u4eec\u5bf9\u7fa4\u4f53\u5f39\u6027\u7684\u5f71\u54cd\u6765\u68c0\u9a8c\u5047\u8bbe\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u975e\u534f\u4f5c\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6240\u6709\u68c0\u67e5\u7684\u534f\u4f5c\u65b9\u6cd5\u90fd\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u7fa4\u4f53\u5f39\u6027\u3002", "conclusion": "\u4e0e\u975e\u534f\u4f5c\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6240\u6709\u68c0\u67e5\u7684\u534f\u4f5c\u65b9\u6cd5\u90fd\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u7fa4\u4f53\u5f39\u6027\u3002"}}
{"id": "2507.11316", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11316", "abs": "https://arxiv.org/abs/2507.11316", "authors": ["Haoran Jin", "Meng Li", "Xiting Wang", "Zhihao Xu", "Minlie Huang", "Yantao Jia", "Defu Lian"], "title": "Internal Value Alignment in Large Language Models through Controlled Value Vector Activation", "comment": "25 pages, 14 figures. Accepted by ACL 2025 (main conference)", "summary": "Aligning Large Language Models (LLMs) with human values has attracted\nincreasing attention since it provides clarity, transparency, and the ability\nto adapt to evolving scenarios. In this paper, we introduce a Controlled Value\nVector Activation (ConVA) method that directly aligns the internal values of\nLLMs by interpreting how a value is encoded in their latent representations and\nmodifies relevant activations to ensure consistent values in LLMs. To ensure an\naccurate and unbiased interpretation, we propose a context-controlled value\nvector identification method. To consistently control values without\nsacrificing model performance, we introduce a gated value vector activation\nmethod for effective and minimum degree of value control. Experiments show that\nour method achieves the highest control success rate across 10 basic values\nwithout hurting LLM performance and fluency, and ensures target values even\nwith opposite and potentially malicious input prompts. Source code and data are\navailable at~ https://github.com/hr-jin/ConVA.", "AI": {"tldr": "ConVA aligns LLMs with human values by modifying their internal representations, achieving high success rates without performance loss and performance loss.", "motivation": "Aligning Large Language Models (LLMs) with human values is important for providing clarity, transparency, and adaptability to changing circumstances.", "method": "The paper introduces a Controlled Value Vector Activation (ConVA) method. This method involves interpreting how values are encoded in LLMs' latent representations and modifying relevant activations. It utilizes a context-controlled value vector identification method for accurate and unbiased interpretation, and a gated value vector activation method for effective and minimal value control.", "result": "ConVA achieves the highest control success rate across 10 basic values without negatively impacting LLM performance and fluency. It also ensures target values are maintained even when faced with opposing or malicious input prompts.", "conclusion": "Aligning LLMs with human values is crucial for clarity, transparency, and adaptability. The ConVA method achieves this by interpreting and modifying internal value encodings in LLM latent representations. Experiments demonstrate ConVA's high control success rate across 10 basic values without compromising model performance or fluency, even against adversarial prompts."}}
{"id": "2507.11243", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.11243", "abs": "https://arxiv.org/abs/2507.11243", "authors": ["Yang-Guang Shan", "Jia-Xuan Li", "Zhen-Qiang Yin", "Shuang Wang", "Wei Chen", "De-Yong He", "Guang-Can Guo", "Zheng-Fu Han"], "title": "Finite-correlation-secure quantum key distribution", "comment": null, "summary": "Correlation between different pulses is a nettlesome problem in quantum key\ndistribution (QKD). All existing solutions for this problem need to\ncharacterize the strength of the correlation, which may reduce the security of\nQKD to an accurate characterization. In this article, we propose a new protocol\nimmune to all correlations of all dimensions, with the only requirements of\nnon-entangled and finite-ranged correlation, and bounded vacuum probability.\nAdditionally, the new protocol is side-channel-secure and\nmeasurement-device-independent, giving high-level security in practical QKD\nsystems. We provide the finite-key security analysis against coherent attacks\nand conduct numerical simulations to see the performance. The result shows that\na small correlation range does not influence the performance a lot and the\nprotocol could tolerate a large correlation range, such as correlations\nspanning over 500 pulses.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u514d\u75ab\u6240\u6709\u7ef4\u5ea6\u76f8\u5173\u6027\u7684\u65b0\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u534f\u8bae\uff0c\u8be5\u534f\u8bae\u5177\u6709\u975e\u7ea0\u7f20\u3001\u6709\u9650\u8303\u56f4\u76f8\u5173\u6027\u548c\u6709\u9650\u771f\u7a7a\u6982\u7387\u7684\u8981\u6c42\uff0c\u540c\u65f6\u5177\u6709\u4fa7\u4fe1\u9053\u5b89\u5168\u548c\u6d4b\u91cf\u8bbe\u5907\u65e0\u5173\u7684\u7279\u6027\uff0c\u53ef\u5bb9\u5fcd\u9ad8\u8fbe500\u4e2a\u8109\u51b2\u7684\u76f8\u5173\u6027\u3002", "motivation": "\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u4e2d\u4e0d\u540c\u8109\u51b2\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u662f\u4e00\u4e2a\u68d8\u624b\u7684\u95ee\u9898\uff0c\u73b0\u6709\u7684\u89e3\u51b3\u65b9\u6848\u9700\u8981\u8868\u5f81\u76f8\u5173\u6027\u7684\u5f3a\u5ea6\uff0c\u8fd9\u53ef\u80fd\u4f1a\u964d\u4f4e\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u7684\u5b89\u5168\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u534f\u8bae\uff0c\u8be5\u534f\u8bae\u514d\u75ab\u6240\u6709\u7ef4\u5ea6\u4e0a\u7684\u6240\u6709\u76f8\u5173\u6027\uff0c\u5177\u6709\u975e\u7ea0\u7f20\u548c\u6709\u9650\u8303\u56f4\u76f8\u5173\u6027\u7684\u8981\u6c42\uff0c\u4ee5\u53ca\u6709\u9650\u7684\u771f\u7a7a\u6982\u7387\u3002", "result": "\u6709\u9650\u5bc6\u94a5\u5b89\u5168\u5206\u6790\u8868\u660e\uff0c\u8be5\u534f\u8bae\u80fd\u591f\u62b5\u6297\u76f8\u5e72\u653b\u51fb\uff0c\u5e76\u4e14\u6570\u503c\u6a21\u62df\u663e\u793a\uff0c\u5373\u4f7f\u5728\u8f83\u5927\u7684\u76f8\u5173\u8303\u56f4\uff08\u4f8b\u5982\u8de8\u8d8a500\u4e2a\u8109\u51b2\uff09\u4e0b\uff0c\u8be5\u534f\u8bae\u7684\u6027\u80fd\u4e5f\u4e0d\u4f1a\u53d7\u5230\u663e\u8457\u5f71\u54cd\uff0c\u5e76\u4e14\u53ef\u4ee5\u5bb9\u5fcd\u8f83\u5927\u7684\u76f8\u5173\u8303\u56f4\u3002", "conclusion": "\u8be5\u534f\u8bae\u514d\u75ab\u6240\u6709\u7ef4\u5ea6\u4e0a\u7684\u6240\u6709\u76f8\u5173\u6027\uff0c\u5177\u6709\u975e\u7ea0\u7f20\u548c\u6709\u9650\u8303\u56f4\u76f8\u5173\u6027\u7684\u8981\u6c42\uff0c\u4ee5\u53ca\u6709\u9650\u7684\u771f\u7a7a\u6982\u7387\u3002\u8be5\u534f\u8bae\u8fd8\u5177\u6709\u4fa7\u4fe1\u9053\u5b89\u5168\u548c\u6d4b\u91cf\u8bbe\u5907\u65e0\u5173\u7684\u7279\u6027\uff0c\u5728\u5b9e\u9645\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\u7cfb\u7edf\u4e2d\u5177\u6709\u9ad8\u5b89\u5168\u6027\u3002"}}
{"id": "2507.11119", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11119", "abs": "https://arxiv.org/abs/2507.11119", "authors": ["Hankun Liu", "Yujian Zhao", "Guanglin Niu"], "title": "Try Harder: Hard Sample Generation and Learning for Clothes-Changing Person Re-ID", "comment": null, "summary": "Hard samples pose a significant challenge in person re-identification (ReID)\ntasks, particularly in clothing-changing person Re-ID (CC-ReID). Their inherent\nambiguity or similarity, coupled with the lack of explicit definitions, makes\nthem a fundamental bottleneck. These issues not only limit the design of\ntargeted learning strategies but also diminish the model's robustness under\nclothing or viewpoint changes. In this paper, we propose a novel\nmultimodal-guided Hard Sample Generation and Learning (HSGL) framework, which\nis the first effort to unify textual and visual modalities to explicitly\ndefine, generate, and optimize hard samples within a unified paradigm. HSGL\ncomprises two core components: (1) Dual-Granularity Hard Sample Generation\n(DGHSG), which leverages multimodal cues to synthesize semantically consistent\nsamples, including both coarse- and fine-grained hard positives and negatives\nfor effectively increasing the hardness and diversity of the training data. (2)\nHard Sample Adaptive Learning (HSAL), which introduces a hardness-aware\noptimization strategy that adjusts feature distances based on textual semantic\nlabels, encouraging the separation of hard positives and drawing hard negatives\ncloser in the embedding space to enhance the model's discriminative capability\nand robustness to hard samples. Extensive experiments on multiple CC-ReID\nbenchmarks demonstrate the effectiveness of our approach and highlight the\npotential of multimodal-guided hard sample generation and learning for robust\nCC-ReID. Notably, HSAL significantly accelerates the convergence of the\ntargeted learning procedure and achieves state-of-the-art performance on both\nPRCC and LTCC datasets. The code is available at\nhttps://github.com/undooo/TryHarder-ACMMM25.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHSGL\u7684\u65b0\u6846\u67b6\uff0c\u5229\u7528\u6587\u672c\u548c\u89c6\u89c9\u4fe1\u606f\u751f\u6210\u548c\u5b66\u4e60\u96be\u4f8b\uff0c\u4ee5\u63d0\u9ad8\u8863\u7740\u53d8\u5316person Re-ID\uff08CC-ReID\uff09\u7684\u6027\u80fd\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728PRCC\u548cLTCC\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6c34\u5e73\u3002", "motivation": "\u96be\u4f8b\u5728 person re-identification\uff08ReID\uff09\u4efb\u52a1\u4e2d\uff0c\u7279\u522b\u662f\u5728\u8863\u7740\u53d8\u5316person Re-ID\uff08CC-ReID\uff09\u4e2d\uff0c\u6784\u6210\u4e86\u663e\u8457\u7684\u6311\u6218\u3002\u96be\u4f8b\u56fa\u6709\u7684\u6b67\u4e49\u6027\u6216\u76f8\u4f3c\u6027\uff0c\u4ee5\u53ca\u7f3a\u4e4f\u660e\u786e\u7684\u5b9a\u4e49\uff0c\u4f7f\u5176\u6210\u4e3a\u6a21\u578b\u6027\u80fd\u63d0\u5347\u7684\u6839\u672c\u74f6\u9888\u3002\u8fd9\u4e9b\u95ee\u9898\u4e0d\u4ec5\u9650\u5236\u4e86\u9488\u5bf9\u6027\u5b66\u4e60\u7b56\u7565\u7684\u8bbe\u8ba1\uff0c\u8fd8\u524a\u5f31\u4e86\u6a21\u578b\u5728\u8863\u7740\u6216\u89c6\u89d2\u53d8\u5316\u65f6\u7684\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u591a\u6a21\u6001\u5f15\u5bfc\u7684\u96be\u4f8b\u751f\u6210\u4e0e\u5b66\u4e60\u201d\uff08HSGL\uff09\u7684\u6846\u67b6\u3002\u8be5\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1. \u53cc\u7c92\u5ea6\u96be\u4f8b\u751f\u6210\uff08DGHSG\uff09\uff0c\u5229\u7528\u591a\u6a21\u6001\u7ebf\u7d22\u5408\u6210\u8bed\u4e49\u4e00\u81f4\u7684\u6837\u672c\uff0c\u5305\u62ec\u7c97\u7c92\u5ea6\u548c\u7ec6\u7c92\u5ea6\u7684\u96be\u4f8b\u6b63\u6837\u672c\u548c\u8d1f\u6837\u672c\uff0c\u4ee5\u589e\u52a0\u8bad\u7ec3\u6570\u636e\u7684\u96be\u5ea6\u548c\u591a\u6837\u6027\u30022. \u96be\u4f8b\u81ea\u9002\u5e94\u5b66\u4e60\uff08HSAL\uff09\uff0c\u5f15\u5165\u4e00\u79cd\u611f\u77e5\u96be\u5ea6\u7684\u4f18\u5316\u7b56\u7565\uff0c\u6839\u636e\u6587\u672c\u8bed\u4e49\u6807\u7b7e\u8c03\u6574\u7279\u5f81\u8ddd\u79bb\uff0c\u9f13\u52b1\u5c06\u96be\u4f8b\u6b63\u6837\u672c\u5206\u79bb\uff0c\u5e76\u5c06\u96be\u4f8b\u8d1f\u6837\u672c\u62c9\u8fd1\u5d4c\u5165\u7a7a\u95f4\uff0c\u4ee5\u589e\u5f3a\u6a21\u578b\u7684\u8fa8\u522b\u80fd\u529b\u548c\u5bf9\u96be\u4f8b\u7684\u9c81\u68d2\u6027\u3002", "result": "\u6240\u63d0\u51fa\u7684HSGL\u6846\u67b6\u5728\u591a\u4e2aCC-ReID\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u6709\u6548\u6027\uff0c\u5e76\u7a81\u663e\u4e86\u591a\u6a21\u6001\u5f15\u5bfc\u7684\u96be\u4f8b\u751f\u6210\u548c\u5b66\u4e60\u5728\u9c81\u68d2CC-ReID\u65b9\u9762\u7684\u6f5c\u529b\u3002\u7279\u522b\u662f\uff0cHSAL\u663e\u8457\u52a0\u901f\u4e86\u76ee\u6807\u5b66\u4e60\u8fc7\u7a0b\u7684\u6536\u655b\uff0c\u5e76\u5728PRCC\u548cLTCC\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u591a\u6a21\u6001\u5f15\u5bfc\u7684\u96be\u4f8b\u751f\u6210\u4e0e\u5b66\u4e60\uff08HSGL\uff09\u6846\u67b6\uff0c\u9996\u6b21\u5c06\u6587\u672c\u548c\u89c6\u89c9\u6a21\u6001\u7edf\u4e00\u8d77\u6765\uff0c\u5728\u4e00\u4e2a\u7edf\u4e00\u7684\u8303\u5f0f\u5185\u660e\u786e\u5b9a\u4e49\u3001\u751f\u6210\u548c\u4f18\u5316\u96be\u4f8b\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u96be\u4f8b\u65f6\u7684\u4e0d\u8db3\uff0c\u5e76\u5728\u591a\u4e2aCC-ReID\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u8fa8\u522b\u80fd\u529b\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2507.11330", "categories": ["cs.CL", "cs.AI", "cs.DL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.11330", "abs": "https://arxiv.org/abs/2507.11330", "authors": ["Wenqing Wu", "Chengzhi Zhang", "Yi Zhao"], "title": "Automated Novelty Evaluation of Academic Paper: A Collaborative Approach Integrating Human and Large Language Model Knowledge", "comment": "Journal of the Association for Information Science and Technology,\n  2025", "summary": "Novelty is a crucial criterion in the peer review process for evaluating\nacademic papers. Traditionally, it's judged by experts or measure by unique\nreference combinations. Both methods have limitations: experts have limited\nknowledge, and the effectiveness of the combination method is uncertain.\nMoreover, it's unclear if unique citations truly measure novelty. The large\nlanguage model (LLM) possesses a wealth of knowledge, while human experts\npossess judgment abilities that the LLM does not possess. Therefore, our\nresearch integrates the knowledge and abilities of LLM and human experts to\naddress the limitations of novelty assessment. The most common novelty in\nacademic papers is the introduction of new methods. In this paper, we propose\nleveraging human knowledge and LLM to assist pretrained language models (PLMs,\ne.g. BERT etc.) in predicting the method novelty of papers. Specifically, we\nextract sentences related to the novelty of the academic paper from peer review\nreports and use LLM to summarize the methodology section of the academic paper,\nwhich are then used to fine-tune PLMs. In addition, we have designed a\ntext-guided fusion module with novel Sparse-Attention to better integrate human\nand LLM knowledge. We compared the method we proposed with a large number of\nbaselines. Extensive experiments demonstrate that our method achieves superior\nperformance.", "AI": {"tldr": "\u901a\u8fc7\u7ed3\u5408\u4eba\u7c7b\u4e13\u5bb6\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u77e5\u8bc6\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5b66\u672f\u8bba\u6587\u65b9\u6cd5\u65b0\u9896\u6027\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5e76\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7684\u65b0\u9896\u6027\u8bc4\u4f30\u65b9\u6cd5\uff08\u4e13\u5bb6\u5224\u65ad\u548c\u72ec\u7279\u53c2\u8003\u6587\u732e\u7ec4\u5408\uff09\u5b58\u5728\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u6709\u6548\u8861\u91cf\u65b0\u9896\u6027\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u62e5\u6709\u4e30\u5bcc\u7684\u77e5\u8bc6\uff0c\u800c\u4eba\u7c7b\u4e13\u5bb6\u62e5\u6709LLM\u6240\u4e0d\u5177\u5907\u7684\u5224\u65ad\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u65e8\u5728\u7ed3\u5408\u4e24\u8005\u7684\u4f18\u52bf\u6765\u514b\u670d\u65b0\u9896\u6027\u8bc4\u4f30\u7684\u5c40\u9650\u6027\u3002", "method": "\u5229\u7528\u4eba\u7c7b\u77e5\u8bc6\u548cLLM\u8f85\u52a9\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff08PLMs\uff09\u9884\u6d4b\u8bba\u6587\u65b9\u6cd5\u7684\u65b0\u9896\u6027\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u63d0\u53d6\u540c\u884c\u8bc4\u5ba1\u62a5\u544a\u4e2d\u4e0e\u65b0\u9896\u6027\u76f8\u5173\u7684\u53e5\u5b50\uff0c\u5e76\u5229\u7528LLM\u603b\u7ed3\u8bba\u6587\u7684\u65b9\u6cd5\u8bba\u90e8\u5206\uff0c\u7136\u540e\u7528\u8fd9\u4e9b\u4fe1\u606f\u5bf9PLMs\u8fdb\u884c\u5fae\u8c03\u3002\u6b64\u5916\uff0c\u8fd8\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5e26\u6709\u65b0\u9896\u7684\u7a00\u758f\u6ce8\u610f\u529b\uff08Sparse-Attention\uff09\u7684\u6587\u672c\u5f15\u5bfc\u878d\u5408\u6a21\u5757\u6765\u6574\u5408\u4eba\u7c7b\u548cLLM\u7684\u77e5\u8bc6\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4e0e\u5927\u91cf\u57fa\u7ebf\u65b9\u6cd5\u7684\u6bd4\u8f83\u4e2d\u53d6\u5f97\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4eba\u7c7b\u77e5\u8bc6\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6765\u8bc4\u4f30\u5b66\u672f\u8bba\u6587\u65b9\u6cd5\u65b0\u9896\u6027\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u4f18\u8d8a\u6027\u3002"}}
{"id": "2507.10861", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10861", "abs": "https://arxiv.org/abs/2507.10861", "authors": ["Edoardo Pinzuti", "Oliver T\u00fcscher", "Andr\u00e9 Ferreira Castro"], "title": "Visually grounded emotion regulation via diffusion models and user-driven reappraisal", "comment": null, "summary": "Cognitive reappraisal is a key strategy in emotion regulation, involving\nreinterpretation of emotionally charged stimuli to alter affective responses.\nDespite its central role in clinical and cognitive science, real-world\nreappraisal interventions remain cognitively demanding, abstract, and primarily\nverbal. This reliance on higher-order cognitive and linguistic processes is\noften impaired in individuals with trauma or depression, limiting the\neffectiveness of standard approaches. Here, we propose a novel, visually based\naugmentation of cognitive reappraisal by integrating large-scale text-to-image\ndiffusion models into the emotional regulation process. Specifically, we\nintroduce a system in which users reinterpret emotionally negative images via\nspoken reappraisals, which are transformed into supportive, emotionally\ncongruent visualizations using stable diffusion models with a fine-tuned\nIP-adapter. This generative transformation visually instantiates users'\nreappraisals while maintaining structural similarity to the original stimuli,\nexternalizing and reinforcing regulatory intent. To test this approach, we\nconducted a within-subject experiment (N = 20) using a modified cognitive\nemotion regulation (CER) task. Participants reappraised or described aversive\nimages from the International Affective Picture System (IAPS), with or without\nAI-generated visual feedback. Results show that AI-assisted reappraisal\nsignificantly reduced negative affect compared to both non-AI and control\nconditions. Further analyses reveal that sentiment alignment between\nparticipant reappraisals and generated images correlates with affective relief,\nsuggesting that multimodal coherence enhances regulatory efficacy. These\nfindings demonstrate that generative visual input can support cogitive\nreappraisal and open new directions at the intersection of generative AI,\naffective computing, and therapeutic technology.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528AI\u751f\u6210\u89c6\u89c9\u53cd\u9988\u6765\u589e\u5f3a\u8ba4\u77e5\u91cd\u8bc4\uff08\u4e00\u79cd\u60c5\u7eea\u8c03\u8282\u6280\u672f\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u7279\u522b\u9002\u7528\u4e8e\u90a3\u4e9b\u96be\u4ee5\u8fdb\u884c\u4f20\u7edf\u8bed\u8a00\u91cd\u8bc4\u7684\u4e2a\u4f53\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cAI\u8f85\u52a9\u91cd\u8bc4\u80fd\u6709\u6548\u964d\u4f4e\u8d1f\u9762\u60c5\u7eea\uff0c\u4e14\u91cd\u8bc4\u5185\u5bb9\u4e0eAI\u751f\u6210\u56fe\u50cf\u7684\u60c5\u611f\u4e00\u81f4\u6027\u8d8a\u9ad8\uff0c\u6548\u679c\u8d8a\u597d\u3002", "motivation": "\u5c3d\u7ba1\u8ba4\u77e5\u91cd\u8bc4\u5728\u4e34\u5e8a\u548c\u8ba4\u77e5\u79d1\u5b66\u4e2d\u8d77\u7740\u6838\u5fc3\u4f5c\u7528\uff0c\u4f46\u73b0\u5b9e\u4e16\u754c\u7684\u91cd\u8bc4\u5e72\u9884\u4ecd\u7136\u9700\u8981\u5927\u91cf\u7684\u8ba4\u77e5\u8d44\u6e90\uff0c\u5e76\u4e14\u4e3b\u8981\u662f\u62bd\u8c61\u548c\u8bed\u8a00\u5316\u7684\u3002\u8fd9\u79cd\u5bf9\u66f4\u9ad8\u8ba4\u77e5\u548c\u8bed\u8a00\u8fc7\u7a0b\u7684\u4f9d\u8d56\u5728\u6709\u521b\u4f24\u6216\u6291\u90c1\u75c7\u7684\u4e2a\u4f53\u4e2d\u5e38\u5e38\u53d7\u635f\uff0c\u8fd9\u9650\u5236\u4e86\u6807\u51c6\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u3001\u57fa\u4e8e\u89c6\u89c9\u7684\u8ba4\u77e5\u91cd\u8bc4\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u6574\u5408\u5927\u578b\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u6765\u589e\u5f3a\u60c5\u7eea\u8c03\u8282\u8fc7\u7a0b\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u4e2a\u7cfb\u7edf\uff0c\u7528\u6237\u901a\u8fc7\u53e3\u5934\u91cd\u8bc4\u6765\u91cd\u65b0\u89e3\u91ca\u8d1f\u9762\u60c5\u7eea\u56fe\u50cf\uff0c\u7136\u540e\u4f7f\u7528\u7ecf\u8fc7\u5fae\u8c03\u7684IP\u9002\u914d\u5668\u7684\u7a33\u5b9a\u6269\u6563\u6a21\u578b\u5c06\u5176\u8f6c\u5316\u4e3a\u652f\u6301\u6027\u7684\u3001\u60c5\u7eea\u4e0a\u4e00\u81f4\u7684\u53ef\u89c6\u5316\u6548\u679c\u3002\u8fd9\u79cd\u751f\u6210\u5f0f\u8f6c\u6362\u5728\u89c6\u89c9\u4e0a\u5b9e\u4f8b\u5316\u4e86\u7528\u6237\u7684\u91cd\u8bc4\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u539f\u59cb\u523a\u6fc0\u7684\u7ed3\u6784\u76f8\u4f3c\u6027\uff0c\u4ece\u800c\u5916\u5316\u548c\u52a0\u5f3a\u4e86\u8c03\u8282\u610f\u56fe\u3002\u4e3a\u4e86\u6d4b\u8bd5\u8fd9\u79cd\u65b9\u6cd5\uff0c\u6211\u4eec\u8fdb\u884c\u4e86\u4e00\u9879\uff08N = 20\uff09\u88ab\u8bd5\u5185\u5b9e\u9a8c\uff0c\u4f7f\u7528\u4fee\u6539\u540e\u7684\u8ba4\u77e5\u60c5\u7eea\u8c03\u8282\uff08CER\uff09\u4efb\u52a1\u3002\u53c2\u4e0e\u8005\u6216\u91cd\u8bc4\u6216\u63cf\u8ff0\u4e86\u6765\u81ea\u56fd\u9645\u5fc3\u667a\u56fe\u7247\u7cfb\u7edf\uff08IAPS\uff09\u7684\u8d1f\u9762\u56fe\u7247\uff0c\u5e76\u8f85\u4ee5\u6216\u4e0d\u8f85\u4ee5\u4eba\u5de5\u667a\u80fd\u751f\u6210\u7684\u89c6\u89c9\u53cd\u9988\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u975e\u4eba\u5de5\u667a\u80fd\u548c\u5bf9\u7167\u7ec4\u76f8\u6bd4\uff0c\u4eba\u5de5\u667a\u80fd\u8f85\u52a9\u91cd\u8bc4\u80fd\u663e\u8457\u964d\u4f4e\u8d1f\u9762\u60c5\u7eea\u3002\u8fdb\u4e00\u6b65\u7684\u5206\u6790\u8868\u660e\uff0c\u53c2\u4e0e\u8005\u91cd\u8bc4\u548c\u751f\u6210\u56fe\u50cf\u4e4b\u95f4\u7684\u60c5\u611f\u4e00\u81f4\u6027\u4e0e\u60c5\u7eea\u7f13\u89e3\u76f8\u5173\uff0c\u8fd9\u8868\u660e\u591a\u6a21\u6001\u4e00\u81f4\u6027\u589e\u5f3a\u4e86\u8c03\u8282\u6548\u679c\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u751f\u6210\u5f0f\u89c6\u89c9\u8f93\u5165\u53ef\u4ee5\u652f\u6301\u8ba4\u77e5\u91cd\u8bc4\uff0c\u5e76\u5728\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u3001\u60c5\u611f\u8ba1\u7b97\u548c\u6cbb\u7597\u6280\u672f\u4ea4\u53c9\u9886\u57df\u5f00\u8f9f\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2507.11287", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2507.11287", "abs": "https://arxiv.org/abs/2507.11287", "authors": ["An-Lun Liu", "Yu-Wei Chao", "Yi-Ting Chen"], "title": "Task-Oriented Human Grasp Synthesis via Context- and Task-Aware Diffusers", "comment": "Accepted by ICCV 2025", "summary": "In this paper, we study task-oriented human grasp synthesis, a new grasp\nsynthesis task that demands both task and context awareness. At the core of our\nmethod is the task-aware contact maps. Unlike traditional contact maps that\nonly reason about the manipulated object and its relation with the hand, our\nenhanced maps take into account scene and task information. This comprehensive\nmap is critical for hand-object interaction, enabling accurate grasping poses\nthat align with the task. We propose a two-stage pipeline that first constructs\na task-aware contact map informed by the scene and task. In the subsequent\nstage, we use this contact map to synthesize task-oriented human grasps. We\nintroduce a new dataset and a metric for the proposed task to evaluate our\napproach. Our experiments validate the importance of modeling both scene and\ntask, demonstrating significant improvements over existing methods in both\ngrasp quality and task performance. See our project page for more details:\nhttps://hcis-lab.github.io/TOHGS/", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9762\u5411\u4efb\u52a1\u7684\u4eba\u7c7b\u6293\u53d6\u5408\u6210\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5f15\u5165\u4efb\u52a1\u611f\u77e5\u63a5\u89e6\u56fe\u6765\u540c\u65f6\u8003\u8651\u4efb\u52a1\u548c\u573a\u666f\u4fe1\u606f\uff0c\u5e76\u5728\u6293\u53d6\u8d28\u91cf\u548c\u4efb\u52a1\u6027\u80fd\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u7814\u7a76\u9762\u5411\u4efb\u52a1\u7684\u4eba\u7c7b\u6293\u53d6\u5408\u6210\uff0c\u8fd9\u662f\u4e00\u4e2a\u9700\u8981\u540c\u65f6\u8003\u8651\u4efb\u52a1\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u65b0\u6293\u53d6\u5408\u6210\u4efb\u52a1\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u65b9\u6cd5\uff0c\u9996\u5148\u6784\u5efa\u8003\u8651\u4e86\u573a\u666f\u548c\u4efb\u52a1\u4fe1\u606f\u7684\u4efb\u52a1\u611f\u77e5\u63a5\u89e6\u56fe\uff0c\u7136\u540e\u5728\u540e\u7eed\u9636\u6bb5\u5229\u7528\u8be5\u63a5\u89e6\u56fe\u6765\u5408\u6210\u9762\u5411\u4efb\u52a1\u7684\u4eba\u7c7b\u6293\u53d6\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u76f8\u5bf9\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u4f18\u52bf\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u540c\u65f6\u8003\u8651\u573a\u666f\u548c\u4efb\u52a1\u4fe1\u606f\u5bf9\u4e8e\u6293\u53d6\u81f3\u5173\u91cd\u8981\uff0c\u5e76\u4e14\u5728\u6293\u53d6\u8d28\u91cf\u548c\u4efb\u52a1\u6027\u80fd\u65b9\u9762\u90fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2507.11251", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.11251", "abs": "https://arxiv.org/abs/2507.11251", "authors": ["Jia-Xuan Li", "Yang-Guang Shan", "Rong Wang", "Feng-Yu Lu", "Zhen-Qiang Yin", "Shuang Wang", "Wei Chen", "De-Yong He", "Guang-Can Guo", "Zheng-Fu Han"], "title": "Secure quantum key distribution against correlated leakage source", "comment": null, "summary": "Quantum key distribution (QKD) provides information theoretic security based\non quantum mechanics, however, its practical deployment is challenged by\nimperfections of source devices. Among various source loopholes, correlations\nbetween transmitted pulses pose a significant yet underexplored security risk,\npotentially compromising QKD's theoretical guarantees. In this work, we propose\na security analysis framework for QKD under correlations, enabling finite-key\nanalysis for the first time by extending and rearranging QKD rounds and\nleveraging the generalized chain rule. Based on this framework, and inspired by\nthe idea of side-channel-secure QKD, we develop a secure QKD against correlated\nleakage source only need the characterization of correlation range and the\nlower bound on the vacuum component of the prepared states. Additionally, our\nframework can be extended to other QKD protocols, offering a general approach\nto consider correlation induced security vulnerabilities. The simulation\nresults demonstrate the effectiveness of our protocol and its significantly\nsuperior tolerance to imperfect parameters compared to existing protocols. This\nwork provides a crucial step toward closing security loopholes in QKD,\nenhancing its practicality, and ensuring long-distance,high-performance secure\ncommunication under real-world constraints.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u5206\u6790\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08QKD\uff09\u4e2d\u8109\u51b2\u76f8\u5173\u6027\u5b89\u5168\u98ce\u9669\u7684\u6846\u67b6\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684QKD\u534f\u8bae\uff0c\u63d0\u9ad8\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08QKD\uff09\u7684\u5b9e\u9645\u90e8\u7f72\u53d7\u5230\u4fe1\u6e90\u8bbe\u5907\u4e0d\u5b8c\u7f8e\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u4f20\u8f93\u8109\u51b2\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u53ef\u80fd\u5371\u53caQKD\u7406\u8bba\u4fdd\u8bc1\u7684\u5b89\u5168\u6027\u3002\u8fd9\u9879\u5de5\u4f5c\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u88ab\u5ffd\u89c6\u7684\u5b89\u5168\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5b89\u5168\u5206\u6790\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u5177\u6709\u76f8\u5173\u6027\u7684\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08QKD\uff09\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u6269\u5c55\u548c\u91cd\u65b0\u6392\u5217QKD\u8f6e\u6b21\u5e76\u5229\u7528\u5e7f\u4e49\u94fe\u5f0f\u6cd5\u5219\uff0c\u9996\u6b21\u5b9e\u73b0\u4e86\u6709\u9650\u5bc6\u94a5\u5206\u6790\u3002\u5728\u6b64\u6846\u67b6\u57fa\u7840\u4e0a\uff0c\u501f\u9274\u4fa7\u4fe1\u9053\u5b89\u5168QKD\u7684\u601d\u60f3\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u9488\u5bf9\u76f8\u5173\u6cc4\u6f0f\u6e90\u7684\u5b89\u5168QKD\u534f\u8bae\u3002", "result": "\u63d0\u51fa\u7684\u5b89\u5168\u5206\u6790\u6846\u67b6\u80fd\u591f\u5bf9\u5177\u6709\u76f8\u5173\u6027\u7684QKD\u8fdb\u884c\u6709\u9650\u5bc6\u94a5\u5206\u6790\u3002\u5f00\u53d1\u7684\u65b0\u578bQKD\u534f\u8bae\u4ec5\u9700\u76f8\u5173\u6027\u8303\u56f4\u548c\u771f\u7a7a\u5206\u91cf\u4e0b\u754c\u7684\u8868\u5f81\u5373\u53ef\u5b9e\u73b0\u5b89\u5168\u3002\u6a21\u62df\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u534f\u8bae\u6bd4\u73b0\u6709\u534f\u8bae\u5177\u6709\u66f4\u597d\u7684\u53c2\u6570\u5bb9\u9519\u80fd\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5728\u5b9e\u9645\u8fd0\u884c\u6761\u4ef6\u4e0b\uff0c\u5982\u4e0d\u5b8c\u7f8e\u53c2\u6570\uff0c\u5b9e\u73b0\u91cf\u5b50\u5bc6\u94a5\u5206\u53d1\uff08QKD\uff09\u7684\u5b89\u5168\u63d0\u4f9b\u4e86\u5173\u952e\u4e00\u6b65\u3002\u901a\u8fc7\u5f00\u53d1\u4e00\u4e2a\u5b89\u5168\u5206\u6790\u6846\u67b6\uff0c\u5e76\u57fa\u4e8e\u6b64\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684QKD\u534f\u8bae\uff0c\u8be5\u534f\u8bae\u4ec5\u9700\u4e86\u89e3\u76f8\u5173\u6027\u8303\u56f4\u548c\u771f\u7a7a\u5206\u91cf\u7684\u4e0b\u754c\u5373\u53ef\u5b9e\u73b0\u9488\u5bf9\u76f8\u5173\u6cc4\u6f0f\u6e90\u7684\u5b89\u5168\u3002\u6a21\u62df\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u534f\u8bae\u76f8\u6bd4\uff0c\u8be5\u534f\u8bae\u5177\u6709\u4f18\u8d8a\u7684\u5bb9\u9519\u80fd\u529b\uff0c\u4e3a\u5728\u771f\u5b9e\u4e16\u754c\u7ea6\u675f\u4e0b\u5b9e\u73b0\u957f\u8ddd\u79bb\u3001\u9ad8\u6027\u80fd\u5b89\u5168\u901a\u4fe1\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.11129", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11129", "abs": "https://arxiv.org/abs/2507.11129", "authors": ["Zhifeng Gu", "Bing Wang"], "title": "MMOne: Representing Multiple Modalities in One Scene", "comment": "Accepted to ICCV 2025", "summary": "Humans perceive the world through multimodal cues to understand and interact\nwith the environment. Learning a scene representation for multiple modalities\nenhances comprehension of the physical world. However, modality conflicts,\narising from inherent distinctions among different modalities, present two\ncritical challenges: property disparity and granularity disparity. To address\nthese challenges, we propose a general framework, MMOne, to represent multiple\nmodalities in one scene, which can be readily extended to additional\nmodalities. Specifically, a modality modeling module with a novel modality\nindicator is proposed to capture the unique properties of each modality.\nAdditionally, we design a multimodal decomposition mechanism to separate\nmulti-modal Gaussians into single-modal Gaussians based on modality\ndifferences. We address the essential distinctions among modalities by\ndisentangling multimodal information into shared and modality-specific\ncomponents, resulting in a more compact and efficient multimodal scene\nrepresentation. Extensive experiments demonstrate that our method consistently\nenhances the representation capability for each modality and is scalable to\nadditional modalities. The code is available at\nhttps://github.com/Neal2020GitHub/MMOne.", "AI": {"tldr": "A new framework, MMOne, tackles challenges in representing multiple senses by separating shared and unique information, improving scene understanding and working with more senses easily.", "motivation": "To address the challenges of property disparity and granularity disparity arising from modality conflicts in multimodal scene representation.", "method": "MMOne framework utilizing a modality modeling module with a novel modality indicator and a multimodal decomposition mechanism to separate multi-modal Gaussians into single-modal Gaussians, disentangling multimodal information into shared and modality-specific components.", "result": "Extensive experiments demonstrate that MMOne consistently enhances the representation capability for each modality and is scalable to additional modalities.", "conclusion": "The proposed MMOne framework effectively addresses modality conflicts by capturing unique properties of each modality and disentangling multimodal information into shared and modality-specific components, leading to enhanced representation capability and scalability."}}
{"id": "2507.11356", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.11356", "abs": "https://arxiv.org/abs/2507.11356", "authors": ["Alexis Brissard", "Fr\u00e9d\u00e9ric Cuppens", "Amal Zouaq"], "title": "What is the Best Process Model Representation? A Comparative Analysis for Process Modeling with Large Language Models", "comment": "12 pages, 7 figures, to be published in AI4BPM 2025 Proceedings", "summary": "Large Language Models (LLMs) are increasingly applied for Process Modeling\n(PMo) tasks such as Process Model Generation (PMG). To support these tasks,\nresearchers have introduced a variety of Process Model Representations (PMRs)\nthat serve as model abstractions or generation targets. However, these PMRs\ndiffer widely in structure, complexity, and usability, and have never been\nsystematically compared. Moreover, recent PMG approaches rely on distinct\nevaluation strategies and generation techniques, making comparison difficult.\nThis paper presents the first empirical study that evaluates multiple PMRs in\nthe context of PMo with LLMs. We introduce the PMo Dataset, a new dataset\ncontaining 55 process descriptions paired with models in nine different PMRs.\nWe evaluate PMRs along two dimensions: suitability for LLM-based PMo and\nperformance on PMG. \\textit{Mermaid} achieves the highest overall score across\nsix PMo criteria, whereas \\textit{BPMN text} delivers the best PMG results in\nterms of process element similarity.", "AI": {"tldr": "LLM \u7684 PMo \u4efb\u52a1\u4e2d\uff0cMermaid \u5728\u5404\u9879\u6807\u51c6\u4e2d\u8868\u73b0\u6700\u4f73\uff0cBPMN text \u5728\u8fc7\u7a0b\u5143\u7d20\u76f8\u4f3c\u6027\u65b9\u9762\u8868\u73b0\u6700\u4f73\u3002", "motivation": "LLM \u8d8a\u6765\u8d8a\u591a\u5730\u5e94\u7528\u4e8e PM \u4efb\u52a1\uff0c\u5982 PMG\u3002\u4e3a\u652f\u6301\u8fd9\u4e9b\u4efb\u52a1\uff0c\u7814\u7a76\u4eba\u5458\u5f15\u5165\u4e86\u591a\u79cd PMR\uff0c\u4f46\u5b83\u4eec\u5728\u7ed3\u6784\u3001\u590d\u6742\u6027\u548c\u53ef\u7528\u6027\u65b9\u9762\u5dee\u5f02\u5f88\u5927\uff0c\u4e14\u4ece\u672a\u7ecf\u8fc7\u7cfb\u7edf\u6bd4\u8f83\u3002\u6b64\u5916\uff0c\u6700\u8fd1\u7684 PMG \u65b9\u6cd5\u4f9d\u8d56\u4e8e\u4e0d\u540c\u7684\u8bc4\u4f30\u7b56\u7565\u548c\u751f\u6210\u6280\u672f\uff0c\u4f7f\u5f97\u6bd4\u8f83\u56f0\u96be\u3002", "method": "\u672c\u7814\u7a76\u9996\u6b21\u5bf9 LLM \u7684 PMo \u4efb\u52a1\u4e2d\u7684\u591a\u4e2a PMR \u8fdb\u884c\u4e86\u5b9e\u8bc1\u8bc4\u4f30\u3002\u6211\u4eec\u5f15\u5165\u4e86 PMo \u6570\u636e\u96c6\uff0c\u5176\u4e2d\u5305\u542b 55 \u4e2a\u8fc7\u7a0b\u63cf\u8ff0\uff0c\u5e76\u914d\u6709\u4e5d\u79cd\u4e0d\u540c PMR \u7684\u6a21\u578b\u3002\u6211\u4eec\u6cbf\u7740\u4e24\u4e2a\u7ef4\u5ea6\u8bc4\u4f30 PMR\uff1aLLM \u7684 PMo \u7684\u9002\u7528\u6027\u4ee5\u53ca PMG \u7684\u6027\u80fd\u3002", "result": "Mermaid \u5728\u516d\u9879 PMo \u6807\u51c6\u4e2d\u5f97\u5206\u6700\u9ad8\uff0c\u800c BPMN text \u5728\u8fc7\u7a0b\u5143\u7d20\u76f8\u4f3c\u6027\u65b9\u9762\u53d6\u5f97\u4e86\u6700\u4f73 PMG \u7ed3\u679c\u3002", "conclusion": "Mermaid \u5728\u516d\u9879 PMo \u6807\u51c6\u4e2d\u5f97\u5206\u6700\u9ad8\uff0c\u800c BPMN text \u5728\u8fc7\u7a0b\u5143\u7d20\u76f8\u4f3c\u6027\u65b9\u9762\u53d6\u5f97\u4e86\u6700\u4f73 PMG \u7ed3\u679c\u3002"}}
{"id": "2507.11143", "categories": ["cs.CV", "cs.LG", "eess.IV"], "pdf": "https://arxiv.org/pdf/2507.11143", "abs": "https://arxiv.org/abs/2507.11143", "authors": ["Lam Pham", "Cam Le", "Hieu Tang", "Khang Truong", "Truong Nguyen", "Jasmin Lampert", "Alexander Schindler", "Martin Boyer", "Son Phan"], "title": "RMAU-NET: A Residual-Multihead-Attention U-Net Architecture for Landslide Segmentation and Detection from Remote Sensing Images", "comment": null, "summary": "In recent years, landslide disasters have reported frequently due to the\nextreme weather events of droughts, floods , storms, or the consequence of\nhuman activities such as deforestation, excessive exploitation of natural\nresources. However, automatically observing landslide is challenging due to the\nextremely large observing area and the rugged topography such as mountain or\nhighland. This motivates us to propose an end-to-end deep-learning-based model\nwhich explores the remote sensing images for automatically observing landslide\nevents. By considering remote sensing images as the input data, we can obtain\nfree resource, observe large and rough terrains by time. To explore the remote\nsensing images, we proposed a novel neural network architecture which is for\ntwo tasks of landslide detection and landslide segmentation. We evaluated our\nproposed model on three different benchmark datasets of LandSlide4Sense, Bijie,\nand Nepal. By conducting extensive experiments, we achieve F1 scores of 98.23,\n93.83 for the landslide detection task on LandSlide4Sense, Bijie datasets; mIoU\nscores of 63.74, 76.88 on the segmentation tasks regarding LandSlide4Sense,\nNepal datasets. These experimental results prove potential to integrate our\nproposed model into real-life landslide observation systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u5229\u7528\u9065\u611f\u56fe\u50cf\u81ea\u52a8\u68c0\u6d4b\u548c\u5206\u5272\u6ed1\u5761\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u826f\u597d\u7684\u6548\u679c\u3002", "motivation": "\u7531\u4e8e\u6781\u7aef\u5929\u6c14\u4e8b\u4ef6\u548c\u4eba\u7c7b\u6d3b\u52a8\uff0c\u6ed1\u5761\u707e\u5bb3\u9891\u53d1\u3002\u7136\u800c\uff0c\u7531\u4e8e\u89c2\u6d4b\u533a\u57df\u5e7f\u9614\u3001\u5730\u5f62\u5d0e\u5c96\uff0c\u81ea\u52a8\u89c2\u6d4b\u6ed1\u5761\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\u7684\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u6a21\u578b\uff0c\u5229\u7528\u9065\u611f\u56fe\u50cf\u8fdb\u884c\u6ed1\u5761\u4e8b\u4ef6\u7684\u81ea\u52a8\u89c2\u6d4b\u3002\u8be5\u6a21\u578b\u5305\u542b\u4e00\u4e2a\u65b0\u9896\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u7528\u4e8e\u6ed1\u5761\u68c0\u6d4b\u548c\u6ed1\u5761\u5206\u5272\u4e24\u4e2a\u4efb\u52a1\u3002", "result": "\u5728LandSlide4Sense\u548cBijie\u6570\u636e\u96c6\u4e0a\uff0c\u6ed1\u5761\u68c0\u6d4b\u4efb\u52a1\u7684F1\u5206\u6570\u5206\u522b\u4e3a98.23%\u548c93.83%\u3002\u5728LandSlide4Sense\u548cNepal\u6570\u636e\u96c6\u4e0a\uff0c\u5206\u5272\u4efb\u52a1\u7684mIoU\u5206\u6570\u5206\u522b\u4e3a63.74%\u548c76.88%\u3002", "conclusion": "\u8be5\u6a21\u578b\u6709\u6f5c\u529b\u6574\u5408\u5230\u73b0\u5b9e\u4e16\u754c\u7684\u6ed1\u5761\u89c2\u6d4b\u7cfb\u7edf\u4e2d\u3002"}}
{"id": "2507.11384", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.11384", "abs": "https://arxiv.org/abs/2507.11384", "authors": ["Xia Cui"], "title": "Addressing Data Imbalance in Transformer-Based Multi-Label Emotion Detection with Weighted Loss", "comment": "10 pages, 1 figure, SemEval 2025", "summary": "This paper explores the application of a simple weighted loss function to\nTransformer-based models for multi-label emotion detection in SemEval-2025\nShared Task 11. Our approach addresses data imbalance by dynamically adjusting\nclass weights, thereby enhancing performance on minority emotion classes\nwithout the computational burden of traditional resampling methods. We evaluate\nBERT, RoBERTa, and BART on the BRIGHTER dataset, using evaluation metrics such\nas Micro F1, Macro F1, ROC-AUC, Accuracy, and Jaccard similarity coefficients.\nThe results demonstrate that the weighted loss function improves performance on\nhigh-frequency emotion classes but shows limited impact on minority classes.\nThese findings underscore both the effectiveness and the challenges of applying\nthis approach to imbalanced multi-label emotion detection.", "AI": {"tldr": "\u901a\u8fc7\u52a0\u6743\u635f\u5931\u51fd\u6570\u4f18\u5316Transformer\u6a21\u578b\u5728\u591a\u6807\u7b7e\u60c5\u611f\u68c0\u6d4b\u4e2d\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u6570\u636e\u4e0d\u5e73\u8861\u65b9\u9762\uff0c\u4f46\u5bf9\u5c11\u6570\u7c7b\u522b\u7684\u6539\u8fdb\u7a7a\u95f4\u4ecd\u9700\u63a2\u7d22\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u591a\u6807\u7b7e\u60c5\u611f\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5e76\u63a2\u7d22\u4e00\u79cd\u65e0\u9700\u4f20\u7edf\u91cd\u91c7\u6837\u65b9\u6cd5\u7684\u8ba1\u7b97\u8d1f\u62c5\u5373\u53ef\u63d0\u5347\u6a21\u578b\u6027\u80fd\u7684\u9014\u5f84\u3002", "method": "\u5e94\u7528\u7b80\u5355\u7684\u52a0\u6743\u635f\u5931\u51fd\u6570\u5230\u57fa\u4e8eTransformer\u7684\u6a21\u578b\uff08BERT\u3001RoBERTa\u3001BART\uff09\u4e2d\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u7c7b\u522b\u6743\u91cd\u6765\u5904\u7406\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u4ee5\u6539\u8fdb\u5c11\u6570\u60c5\u611f\u7c7b\u522b\u7684\u6027\u80fd\u3002", "result": "\u52a0\u6743\u635f\u5931\u51fd\u6570\u63d0\u5347\u4e86\u6a21\u578b\u5728\u9ad8\u9891\u60c5\u611f\u7c7b\u522b\u4e0a\u7684\u6027\u80fd\uff0c\u4f46\u5bf9\u5c11\u6570\u7c7b\u522b\u7684\u5f71\u54cd\u6709\u9650\u3002", "conclusion": "\u52a0\u6743\u635f\u5931\u51fd\u6570\u5728\u5904\u7406\u9ad8\u9891\u7c7b\u522b\u65f6\u6709\u6548\uff0c\u4f46\u5728\u5c11\u6570\u7c7b\u522b\u4e0a\u7684\u6548\u679c\u6709\u9650\uff0c\u51f8\u663e\u4e86\u8be5\u65b9\u6cd5\u5728\u4e0d\u5e73\u8861\u591a\u6807\u7b7e\u60c5\u611f\u68c0\u6d4b\u4e2d\u7684\u4f18\u52bf\u4e0e\u6311\u6218\u3002"}}
{"id": "2507.10880", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.10880", "abs": "https://arxiv.org/abs/2507.10880", "authors": ["Souvik Nath", "Sumit Wadhwa", "Luiz Perez"], "title": "Domain-Adaptive Small Language Models for Structured Tax Code Prediction", "comment": "10 pages, 3 figures", "summary": "Every day, multinational firms process thousands of transactions, each of\nwhich must adhere to tax regulations that vary by jurisdiction and are often\nnuanced. The determination of product and service tax codes, such as HSN or SAC\nis a major use case in Tax compliance. An accurate determination of such codes\nis imperative to avoid any tax penalties. This paper proposes a domain-adaptive\nsmall language model (SLM) with an encoder-decoder architecture for the\nenhanced prediction of product and service tax codes. In this approach, we\naddress the problem of predicting hierarchical tax code sequences using\nunstructured product and services data. We employ an SLM based upon\nencoder-decoder architecture as this enables sequential generation of tax codes\nto capture the hierarchical dependencies present within the tax codes. Our\nexperiments demonstrate that encoder-decoder SLMs can be successfully applied\nto the sequential prediction of structured tax codes, a domain that remains\ncomparatively unexplored in current NLP research. In this paper, we demonstrate\nthe superior performance of the domain-adaptive encoder-decoder SLMs over flat\nclassifiers when applied to the Harmonized System of Nomenclature (HSN), and\nachieve superior results compared to decoder-only and encoder-only\narchitectures for structured sequence generation tasks. This approach can also\nbe scaled to other government-mandated tax commodity codes, such as United\nNations Standard Products and Services Codes (UNSPSC), or Brazil's Nomenclatura\nComum do Mercosul (NCM).", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u57df\u81ea\u9002\u5e94\u5c0f\u578b\u8bed\u8a00\u6a21\u578b (SLM) \u548c\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\u6765\u7cbe\u786e\u9884\u6d4b\u4ea7\u54c1\u548c\u670d\u52a1\u7684\u7a0e\u6536\u4ee3\u7801\uff0c\u89e3\u51b3\u4e86\u8de8\u56fd\u516c\u53f8\u5728\u7a0e\u52a1\u5408\u89c4\u65b9\u9762\u9762\u4e34\u7684\u6311\u6218\u3002", "motivation": "\u8de8\u56fd\u516c\u53f8\u9700\u8981\u5904\u7406\u5927\u91cf\u4ea4\u6613\uff0c\u5e76\u9075\u5b88\u5404\u53f8\u6cd5\u7ba1\u8f96\u533a\u4e0d\u540c\u4e14\u590d\u6742\u7684\u7a0e\u6536\u6cd5\u89c4\u3002\u51c6\u786e\u786e\u5b9a\u4ea7\u54c1\u548c\u670d\u52a1\u7a0e\u6536\u4ee3\u7801\uff08\u5982 HSN \u6216 SAC\uff09\u5bf9\u4e8e\u907f\u514d\u7a0e\u52a1\u5904\u7f5a\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5177\u6709\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\u7684\u57df\u81ea\u9002\u5e94\u5c0f\u578b\u8bed\u8a00\u6a21\u578b (SLM)\uff0c\u7528\u4e8e\u6539\u8fdb\u4ea7\u54c1\u548c\u670d\u52a1\u7684\u7a0e\u6536\u4ee3\u7801\u9884\u6d4b\u3002\u8be5\u65b9\u6cd5\u89e3\u51b3\u4e86\u4f7f\u7528\u975e\u7ed3\u6784\u5316\u4ea7\u54c1\u548c\u670d\u52a1\u6570\u636e\u9884\u6d4b\u5206\u5c42\u7a0e\u6536\u4ee3\u7801\u5e8f\u5217\u7684\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u57fa\u4e8e\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\u7684 SLM \u6210\u529f\u5e94\u7528\u4e8e\u7ed3\u6784\u5316\u7a0e\u6536\u4ee3\u7801\u7684\u987a\u5e8f\u9884\u6d4b\uff0c\u8be5\u9886\u57df\u5728\u5f53\u524d NLP \u7814\u7a76\u4e2d\u63a2\u7d22\u8f83\u5c11\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u57df\u81ea\u9002\u5e94\u7f16\u7801\u5668-\u89e3\u7801\u5668 SLM \u7684\u65b9\u6cd5\u5728 HSN \u7801\u7684\u987a\u5e8f\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u6241\u5e73\u5206\u7c7b\u5668\uff0c\u5e76\u4e14\u5728\u7ed3\u6784\u5316\u5e8f\u5217\u751f\u6210\u4efb\u52a1\u65b9\u9762\u4f18\u4e8e\u4ec5\u89e3\u7801\u5668\u548c\u4ec5\u7f16\u7801\u5668\u67b6\u6784\u3002"}}
{"id": "2507.11322", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2507.11322", "abs": "https://arxiv.org/abs/2507.11322", "authors": ["Wenwen Liu", "Junyao Wu", "Li Zhang", "Oubo You", "Ye Tian", "Wenan Zang", "Hongsheng Chen", "Bumki Min", "Yihao Yang", "Shuang Zhang"], "title": "Quantized decay charges in non-Hermitian networks characterized by directed graphs", "comment": null, "summary": "Non-Hermitian physics has unveiled a realm of exotic phenomena absent in\nHermitian systems, with the non-Hermitian skin effect (NHSE) showcasing\nboundary-localized eigenstates driven by non-reciprocal interactions. Here, we\nintroduce a new class of non-Hermitian systems exhibiting pure decay modes:\neigenstates with pure, smooth exponential decay, devoid of the oscillatory wave\npatterns typical of traditional NHSE. Modeled as directed graphs with\nnon-reciprocal hopping, these systems reveal quantized decay charges, defined\nas the sum of decay constants along edges at each node, offering a novel\ntopological invariant. We derive universal conditions for these modes, enabling\nversatile configurations from one-dimensional rings, directed graphs with\ncomplicated connectivity, to higher-dimensional lattices. Experimental\nvalidation using microwave resonant circuits confirms the predicted pure decay\nprofiles. This discovery paves the way for potential applications in photonics,\nsignal processing, and beyond, harnessing the unique topological properties of\nnon-Hermitian networks.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5177\u6709\u7eaf\u6307\u6570\u8870\u51cf\uff08\u65e0\u632f\u8361\uff09\u7684\u65b0\u578b\u975e\u5384\u7c73\u7cfb\u7edf\uff0c\u53d1\u73b0\u4e86\u4f5c\u4e3a\u62d3\u6251\u4e0d\u53d8\u91cf\u7684\u91cf\u5316\u8870\u51cf\u7535\u8377\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5728\u4e0d\u540c\u7cfb\u7edf\u4e2d\u7684\u5b58\u5728\uff0c\u4e3a\u5149\u5b50\u5b66\u7b49\u9886\u57df\u5f00\u8f9f\u4e86\u65b0\u5e94\u7528\u3002", "motivation": "\u63a2\u7d22\u975e\u5384\u7c73\u7269\u7406\u5b66\u4e2d\u4e0d\u540c\u4e8e\u4f20\u7edf\u975e\u5384\u7c73\u5947\u5f02\u6027\uff08NHSE\uff09\u7684\u5947\u5f02\u73b0\u8c61\uff0c\u7279\u522b\u662f\u5bfb\u627e\u5177\u6709\u7eaf\u6307\u6570\u8870\u51cf\u800c\u65e0\u632f\u8361\u6a21\u5f0f\u7684\u672c\u5f81\u6001\uff0c\u5e76\u63ed\u793a\u5176\u6f5c\u5728\u7684\u62d3\u6251\u6027\u8d28\u548c\u5e94\u7528\u4ef7\u503c\u3002", "method": "\u672c\u7814\u7a76\u5c06\u5177\u6709\u975e\u4e92\u6613\u8dc3\u8fc1\u7684\u7cfb\u7edf\u5efa\u6a21\u4e3a\u5b9a\u5411\u56fe\uff0c\u5e76\u5f15\u5165\u4e86\u91cf\u5316\u8870\u51cf\u7535\u8377\u7684\u6982\u5ff5\uff0c\u5c06\u5176\u5b9a\u4e49\u4e3a\u6bcf\u4e2a\u8282\u70b9\u5904\u6cbf\u8fb9\u7684\u8870\u51cf\u5e38\u6570\u4e4b\u548c\uff0c\u4ee5\u6b64\u4f5c\u4e3a\u65b0\u7684\u62d3\u6251\u4e0d\u53d8\u91cf\u3002\u901a\u8fc7\u63a8\u5bfc\u666e\u9002\u6761\u4ef6\uff0c\u5c06\u6b64\u6a21\u578b\u63a8\u5e7f\u5230\u4e0d\u540c\u7ef4\u5ea6\u548c\u8fde\u63a5\u6027\u7684\u7cfb\u7edf\uff0c\u5e76\u5229\u7528\u5fae\u6ce2\u8c10\u632f\u7535\u8def\u8fdb\u884c\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u6210\u529f\u5f15\u5165\u4e86\u5177\u6709\u7eaf\u8870\u51cf\u6a21\u5f0f\u7684\u65b0\u578b\u975e\u5384\u7c73\u7cfb\u7edf\uff0c\u8be5\u6a21\u5f0f\u8868\u73b0\u4e3a\u65e0\u632f\u8361\u7684\u7eaf\u6307\u6570\u8870\u51cf\u3002\u53d1\u73b0\u4e86\u91cf\u5316\u8870\u51cf\u7535\u8377\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u62d3\u6251\u4e0d\u53d8\u91cf\uff0c\u5e76\u63a8\u5bfc\u4e86\u5176\u666e\u9002\u6761\u4ef6\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u7ef4\u5ea6\u548c\u8fde\u63a5\u6027\u7684\u7cfb\u7edf\u3002\u5fae\u6ce2\u8c10\u632f\u7535\u8def\u7684\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u5b9e\u4e86\u7eaf\u8870\u51cf\u6a21\u5f0f\u7684\u9884\u6d4b\u3002", "conclusion": "\u672c\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u7c7b\u65b0\u7684\u975e\u5384\u7c73\u7cfb\u7edf\uff0c\u5176\u7279\u5f81\u662f\u7eaf\u8870\u51cf\u6a21\u5f0f\uff0c\u5373\u4e0d\u5305\u542b\u4f20\u7edf\u975e\u5384\u7c73\u5947\u5f02\u6027\u4e2d\u7684\u632f\u8361\u6a21\u5f0f\u7684\u7eaf\u6307\u6570\u8870\u51cf\u7684\u672c\u5f81\u6001\u3002\u901a\u8fc7\u5c06\u8fd9\u4e9b\u7cfb\u7edf\u5efa\u6a21\u4e3a\u5177\u6709\u975e\u4e92\u6613\u8dc3\u8fc1\u7684\u5b9a\u5411\u56fe\uff0c\u6211\u4eec\u53d1\u73b0\u4e86\u91cf\u5316\u8870\u51cf\u7535\u8377\uff0c\u5373\u6bcf\u4e2a\u8282\u70b9\u5904\u6cbf\u8fb9\u7684\u8870\u51cf\u5e38\u6570\u4e4b\u548c\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u9896\u7684\u62d3\u6251\u4e0d\u53d8\u91cf\u3002\u6211\u4eec\u63a8\u5bfc\u4e86\u8fd9\u4e9b\u6a21\u5f0f\u7684\u666e\u9002\u6761\u4ef6\uff0c\u5e76\u5c06\u5176\u63a8\u5e7f\u5230\u4e00\u7ef4\u73af\u3001\u590d\u6742\u8fde\u901a\u6027\u7684\u5b9a\u5411\u56fe\u548c\u9ad8\u7ef4\u683c\u70b9\u3002\u901a\u8fc7\u5fae\u6ce2\u8c10\u632f\u7535\u8def\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u8bc1\u5b9e\u4e86\u9884\u6d4b\u7684\u7eaf\u8870\u51cf\u884c\u4e3a\u3002\u672c\u53d1\u73b0\u4e3a\u5149\u5b50\u5b66\u3001\u4fe1\u53f7\u5904\u7406\u7b49\u9886\u57df\u7684\u6f5c\u5728\u5e94\u7528\u5f00\u8f9f\u4e86\u9053\u8def\uff0c\u6709\u671b\u5229\u7528\u975e\u5384\u7c73\u7f51\u7edc\u7684\u72ec\u7279\u62d3\u6251\u6027\u8d28\u3002"}}
{"id": "2507.11152", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11152", "abs": "https://arxiv.org/abs/2507.11152", "authors": ["Duoyou Chen", "Yunqing Chen", "Can Zhang", "Zhou Wang", "Cheng Chen", "Ruoxiu Xiao"], "title": "Latent Space Consistency for Sparse-View CT Reconstruction", "comment": "ACMMM2025 Accepted", "summary": "Computed Tomography (CT) is a widely utilized imaging modality in clinical\nsettings. Using densely acquired rotational X-ray arrays, CT can capture 3D\nspatial features. However, it is confronted with challenged such as significant\ntime consumption and high radiation exposure. CT reconstruction methods based\non sparse-view X-ray images have garnered substantial attention from\nresearchers as they present a means to mitigate costs and risks. In recent\nyears, diffusion models, particularly the Latent Diffusion Model (LDM), have\ndemonstrated promising potential in the domain of 3D CT reconstruction.\nNonetheless, due to the substantial differences between the 2D latent\nrepresentation of X-ray modalities and the 3D latent representation of CT\nmodalities, the vanilla LDM is incapable of achieving effective alignment\nwithin the latent space. To address this issue, we propose the Consistent\nLatent Space Diffusion Model (CLS-DM), which incorporates cross-modal feature\ncontrastive learning to efficiently extract latent 3D information from 2D X-ray\nimages and achieve latent space alignment between modalities. Experimental\nresults indicate that CLS-DM outperforms classical and state-of-the-art\ngenerative models in terms of standard voxel-level metrics (PSNR, SSIM) on the\nLIDC-IDRI and CTSpine1K datasets. This methodology not only aids in enhancing\nthe effectiveness and economic viability of sparse X-ray reconstructed CT but\ncan also be generalized to other cross-modal transformation tasks, such as\ntext-to-image synthesis. We have made our code publicly available at\nhttps://anonymous.4open.science/r/CLS-DM-50D6/ to facilitate further research\nand applications in other domains.", "AI": {"tldr": "CLS-DM\u901a\u8fc7\u8de8\u6a21\u6001\u5bf9\u6bd4\u5b66\u4e60\u89e3\u51b32D X\u5c04\u7ebf\u52303D CT\u91cd\u5efa\u7684\u6f5c\u5728\u7a7a\u95f4\u5bf9\u9f50\u95ee\u9898\uff0c\u5728\u7a00\u758fCT\u91cd\u5efa\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u53ef\u63a8\u5e7f\u5230\u5176\u4ed6\u8de8\u6a21\u6001\u4efb\u52a1\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u73b0\u6709\u6f5c\u5728\u6269\u6563\u6a21\u578b\uff08LDM\uff09\u57282D X\u5c04\u7ebf\u6a21\u6001\u548c3D CT\u6a21\u6001\u7684\u6f5c\u5728\u8868\u793a\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u5bfc\u81f4\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u65e0\u6cd5\u6709\u6548\u5bf9\u9f50\u7684\u95ee\u9898\uff0c\u4ee5\u5e94\u5bf9CT\u626b\u63cf\u65f6\u95f4\u957f\u548c\u8f90\u5c04\u66b4\u9732\u91cf\u5927\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u81f4\u6027\u6f5c\u5728\u7a7a\u95f4\u6269\u6563\u6a21\u578b\uff08CLS-DM\uff09\uff0c\u8be5\u6a21\u578b\u901a\u8fc7\u8de8\u6a21\u6001\u7279\u5f81\u5bf9\u6bd4\u5b66\u4e60\uff0c\u4ece2D X\u5c04\u7ebf\u56fe\u50cf\u4e2d\u6709\u6548\u5730\u63d0\u53d6\u6f5c\u5728\u76843D\u4fe1\u606f\uff0c\u5e76\u5b9e\u73b0\u6a21\u6001\u95f4\u7684\u6f5c\u5728\u7a7a\u95f4\u5bf9\u9f50\u3002", "result": "CLS-DM\u5728LIDC-IDRI\u548cCTSpine1K\u6570\u636e\u96c6\u4e0a\uff0c\u5728PSNR\u548cSSIM\u7b49\u6807\u51c6\u4f53\u7d20\u7ea7\u6307\u6807\u65b9\u9762\uff0c\u4f18\u4e8e\u7ecf\u5178\u548c\u6700\u5148\u8fdb\u7684\u751f\u6210\u6a21\u578b\u3002", "conclusion": "CLS-DM\u5728LIDC-IDRI\u548cCTSpine1K\u6570\u636e\u96c6\u4e0a\uff0c\u5728PSNR\u548cSSIM\u7b49\u6807\u51c6\u4f53\u7d20\u7ea7\u6307\u6807\u65b9\u9762\uff0c\u4f18\u4e8e\u7ecf\u5178\u548c\u6700\u5148\u8fdb\u7684\u751f\u6210\u6a21\u578b\u3002\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u6709\u52a9\u4e8e\u63d0\u9ad8\u7a00\u758fX\u5c04\u7ebf\u91cd\u5efaCT\u7684\u6709\u6548\u6027\u548c\u7ecf\u6d4e\u6027\uff0c\u8fd8\u53ef\u4ee5\u63a8\u5e7f\u5230\u5176\u4ed6\u8de8\u6a21\u6001\u8f6c\u6362\u4efb\u52a1\uff0c\u4f8b\u5982\u6587\u672c\u5230\u56fe\u50cf\u5408\u6210\u3002"}}
{"id": "2507.11405", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.11405", "abs": "https://arxiv.org/abs/2507.11405", "authors": ["Cheng Xu", "Nan Yan", "Shuhao Guan", "Changhong Jin", "Yuke Mei", "Yibing Guo", "M-Tahar Kechadi"], "title": "DCR: Quantifying Data Contamination in LLMs Evaluation", "comment": null, "summary": "The rapid advancement of large language models (LLMs) has heightened concerns\nabout benchmark data contamination (BDC), where models inadvertently memorize\nevaluation data, inflating performance metrics and undermining genuine\ngeneralization assessment. This paper introduces the Data Contamination Risk\n(DCR) framework, a lightweight, interpretable pipeline designed to detect and\nquantify BDC across four granular levels: semantic, informational, data, and\nlabel. By synthesizing contamination scores via a fuzzy inference system, DCR\nproduces a unified DCR Factor that adjusts raw accuracy to reflect\ncontamination-aware performance. Validated on 9 LLMs (0.5B-72B) across\nsentiment analysis, fake news detection, and arithmetic reasoning tasks, the\nDCR framework reliably diagnoses contamination severity and with accuracy\nadjusted using the DCR Factor to within 4% average error across the three\nbenchmarks compared to the uncontaminated baseline. Emphasizing computational\nefficiency and transparency, DCR provides a practical tool for integrating\ncontamination assessment into routine evaluations, fostering fairer comparisons\nand enhancing the credibility of LLM benchmarking practices.", "AI": {"tldr": "DCR\u6846\u67b6\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u53ef\u89e3\u91ca\u7684\u7ba1\u9053\uff0c\u7528\u4e8e\u68c0\u6d4b\u548c\u91cf\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u57fa\u51c6\u6570\u636e\u6c61\u67d3\uff08BDC\uff09\u3002\u5b83\u901a\u8fc7\u8ba1\u7b97\u7edf\u4e00\u7684DCR\u56e0\u5b50\u6765\u8c03\u6574\u51c6\u786e\u6027\uff0c\u4ee5\u53cd\u6620\u611f\u77e5\u6c61\u67d3\u7684\u6027\u80fd\u3002DCR\u6846\u67b6\u57289\u4e2aLLM\u548c3\u4e2a\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u7ed3\u679c\u663e\u793a\u5176\u80fd\u591f\u53ef\u9760\u5730\u8bca\u65ad\u6c61\u67d3\u4e25\u91cd\u7a0b\u5ea6\uff0c\u5e76\u5c06\u51c6\u786e\u6027\u8c03\u6574\u5230\u4e0e\u672a\u6c61\u67d3\u57fa\u7ebf\u76f8\u6bd4\u5e73\u5747\u8bef\u5dee4%\u7684\u8303\u56f4\u5185\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5feb\u901f\u53d1\u5c55\u5f15\u8d77\u4e86\u4eba\u4eec\u5bf9\u57fa\u51c6\u6570\u636e\u6c61\u67d3\uff08BDC\uff09\u7684\u62c5\u5fe7\uff0c\u5373\u6a21\u578b\u65e0\u610f\u4e2d\u8bb0\u4f4f\u4e86\u8bc4\u4f30\u6570\u636e\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u6027\u80fd\u6307\u6807\u5e76\u7834\u574f\u4e86\u771f\u6b63\u7684\u6cdb\u5316\u8bc4\u4f30\u3002", "method": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u6570\u636e\u6c61\u67d3\u98ce\u9669\uff08DCR\uff09\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u53ef\u89e3\u91ca\u7684\u7ba1\u9053\uff0c\u7528\u4e8e\u5728\u56db\u4e2a\u7ec6\u7c92\u5ea6\u7ea7\u522b\u4e0a\u68c0\u6d4b\u548c\u91cf\u5316BDC\uff1a\u8bed\u4e49\u3001\u4fe1\u606f\u3001\u6570\u636e\u548c\u6807\u7b7e\u3002\u901a\u8fc7\u6a21\u7cca\u63a8\u7406\u7cfb\u7edf\u5408\u6210\u6c61\u67d3\u5206\u6570\uff0cDCR\u4ea7\u751f\u7edf\u4e00\u7684DCR\u56e0\u5b50\uff0c\u8be5\u56e0\u5b50\u4f1a\u8c03\u6574\u539f\u59cb\u51c6\u786e\u6027\u4ee5\u53cd\u6620\u611f\u77e5\u6c61\u67d3\u7684\u6027\u80fd\u3002", "result": "DCR\u6846\u67b6\u57289\u4e2aLLM\uff080.5B-72B\uff09\u7684\u6587\u672c\u5206\u7c7b\u3001\u865a\u5047\u65b0\u95fb\u68c0\u6d4b\u548c\u7b97\u672f\u63a8\u7406\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "conclusion": "DCR\u6846\u67b6\u80fd\u591f\u53ef\u9760\u5730\u8bca\u65ad\u6c61\u67d3\u4e25\u91cd\u7a0b\u5ea6\uff0c\u5e76\u4e14\u901a\u8fc7DCR\u56e0\u5b50\u8c03\u6574\u540e\u7684\u51c6\u786e\u6027\u5728\u4e09\u4e2a\u57fa\u51c6\u7684\u5e73\u5747\u8bef\u5dee\u8303\u56f4\u5185\u4e3a4%\uff0c\u4e0e\u672a\u6c61\u67d3\u7684\u57fa\u7ebf\u76f8\u6bd4\u3002"}}
{"id": "2507.10884", "categories": ["cs.LG", "math.DS", "68T07, 68T05, 70G60"], "pdf": "https://arxiv.org/pdf/2507.10884", "abs": "https://arxiv.org/abs/2507.10884", "authors": ["Hyunwoo Cho", "Hyeontae Jo", "Hyung Ju Hwang"], "title": "Learning from Imperfect Data: Robust Inference of Dynamic Systems using Simulation-based Generative Model", "comment": null, "summary": "System inference for nonlinear dynamic models, represented by ordinary\ndifferential equations (ODEs), remains a significant challenge in many fields,\nparticularly when the data are noisy, sparse, or partially observable. In this\npaper, we propose a Simulation-based Generative Model for Imperfect Data\n(SiGMoID) that enables precise and robust inference for dynamic systems. The\nproposed approach integrates two key methods: (1) physics-informed neural\nnetworks with hyper-networks that constructs an ODE solver, and (2) Wasserstein\ngenerative adversarial networks that estimates ODE parameters by effectively\ncapturing noisy data distributions. We demonstrate that SiGMoID quantifies data\nnoise, estimates system parameters, and infers unobserved system components.\nIts effectiveness is validated validated through realistic experimental\nexamples, showcasing its broad applicability in various domains, from\nscientific research to engineered systems, and enabling the discovery of full\nsystem dynamics.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.11342", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.11342", "abs": "https://arxiv.org/abs/2507.11342", "authors": ["Yi-Xin Shen", "Zhou-Kai Cao", "Jian Leng", "Xiang-Bin Wang"], "title": "Channel-loss-independent quantum-enhanced interferometer", "comment": null, "summary": "We propose a channel-loss-independent quantum-enhanced interferometer. In our\nscheme, the Fisher information for phase difference of weak light from a remote\nstar remains constant under arbitrarily large channel loss, and the angular\nresolution of our method is better than that of prior quantum-enhanced methods\nin the long-baseline regime. Moreover, our method requires only threshold\ndetectors and tunable coherent state or two-mode squeezed state sources, both\nof which are matured technologies nowadays.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0e\u4fe1\u9053\u635f\u8017\u65e0\u5173\u7684\u91cf\u5b50\u589e\u5f3a\u5e72\u6d89\u4eea\uff0c\u8be5\u5e72\u6d89\u4eea\u5728\u957f\u57fa\u7ebf\u533a\u57df\u5177\u6709\u66f4\u9ad8\u7684\u89d2\u5206\u8fa8\u7387\uff0c\u5e76\u4e14\u4ec5\u9700\u8981\u6210\u719f\u7684\u6280\u672f\u3002", "motivation": "\u5728\u4efb\u610f\u5927\u7684\u4fe1\u9053\u635f\u8017\u4e0b\uff0c\u4ece\u9065\u8fdc\u661f\u4f53\u53d1\u51fa\u7684\u5f31\u5149\u76f8\u4f4d\u5dee\u7684\u8d39\u820d\u5c14\u4fe1\u606f\u4fdd\u6301\u4e0d\u53d8\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0e\u4fe1\u9053\u635f\u8017\u65e0\u5173\u7684\u91cf\u5b50\u589e\u5f3a\u5e72\u6d89\u4eea\u3002", "result": "\u8be5\u65b9\u6cd5\u7684\u89d2\u5206\u8fa8\u7387\u4f18\u4e8e\u957f\u57fa\u7ebf\u533a\u57df\u7684\u5148\u524d\u91cf\u5b50\u589e\u5f3a\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u957f\u57fa\u7ebf\u533a\u57df\u4f18\u4e8e\u5148\u524d\u6240\u6709\u57fa\u4e8e\u91cf\u5b50\u589e\u5f3a\u7684\u6d4b\u91cf\u65b9\u6cd5\uff0c\u5e76\u4e14\u4ec5\u9700\u8981\u63a2\u6d4b\u5668\u548c\u53ef\u8c03\u8c10\u76f8\u5e72\u6001\u6216\u53cc\u6a21\u538b\u7f29\u6001\u5149\u6e90\uff0c\u8fd9\u4e9b\u90fd\u662f\u6210\u719f\u7684\u6280\u672f\u3002"}}
{"id": "2507.11153", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11153", "abs": "https://arxiv.org/abs/2507.11153", "authors": ["Hongfei Ye", "Bin Chen", "Wenxi Liu", "Yu Zhang", "Zhao Li", "Dandan Ni", "Hongyang Chen"], "title": "Assessing Color Vision Test in Large Vision-language Models", "comment": null, "summary": "With the widespread adoption of large vision-language models, the capacity\nfor color vision in these models is crucial. However, the color vision\nabilities of large visual-language models have not yet been thoroughly\nexplored. To address this gap, we define a color vision testing task for large\nvision-language models and construct a dataset \\footnote{Anonymous Github\nShowing some of the data\nhttps://anonymous.4open.science/r/color-vision-test-dataset-3BCD} that covers\nmultiple categories of test questions and tasks of varying difficulty levels.\nFurthermore, we analyze the types of errors made by large vision-language\nmodels and propose fine-tuning strategies to enhance their performance in color\nvision tests.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u4e00\u4e2a\u989c\u8272\u89c6\u89c9\u6d4b\u8bd5\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u51fa\u4e86\u63d0\u5347\u5927\u578b\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u989c\u8272\u89c6\u89c9\u80fd\u529b\u7684\u5fae\u8c03\u7b56\u7565\u3002", "motivation": "\u5927\u578b\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u7684\u989c\u8272\u89c6\u89c9\u80fd\u529b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5b9a\u4e49\u4e86\u4e00\u4e2a\u989c\u8272\u89c6\u89c9\u6d4b\u8bd5\u4efb\u52a1\uff0c\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u591a\u79cd\u7c7b\u522b\u548c\u4e0d\u540c\u96be\u5ea6\u7ea7\u522b\u6d4b\u8bd5\u95ee\u9898\u53ca\u4efb\u52a1\u7684\u6570\u636e\u96c6\uff0c\u540c\u65f6\u5206\u6790\u4e86\u6a21\u578b\u5728\u989c\u8272\u89c6\u89c9\u6d4b\u8bd5\u4e2d\u5e38\u89c1\u7684\u9519\u8bef\u7c7b\u578b\u3002", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u989c\u8272\u89c6\u89c9\u6d4b\u8bd5\u6570\u636e\u96c6\uff0c\u5e76\u5206\u6790\u4e86\u6a21\u578b\u9519\u8bef\u7c7b\u578b\uff0c\u63d0\u51fa\u4e86\u6539\u8fdb\u7b56\u7565\u3002", "conclusion": "\u901a\u8fc7\u5bf9\u5927\u578b\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u53ef\u4ee5\u63d0\u9ad8\u5176\u5728\u989c\u8272\u89c6\u89c9\u6d4b\u8bd5\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2507.11407", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11407", "abs": "https://arxiv.org/abs/2507.11407", "authors": ["LG AI Research", ":", "Kyunghoon Bae", "Eunbi Choi", "Kibong Choi", "Stanley Jungkyu Choi", "Yemuk Choi", "Kyubeen Han", "Seokhee Hong", "Junwon Hwang", "Taewan Hwang", "Joonwon Jang", "Hyojin Jeon", "Kijeong Jeon", "Gerrard Jeongwon Jo", "Hyunjik Jo", "Jiyeon Jung", "Euisoon Kim", "Hyosang Kim", "Jihoon Kim", "Joonkee Kim", "Seonghwan Kim", "Soyeon Kim", "Sunkyoung Kim", "Yireun Kim", "Yongil Kim", "Youchul Kim", "Edward Hwayoung Lee", "Gwangho Lee", "Haeju Lee", "Honglak Lee", "Jinsik Lee", "Kyungmin Lee", "Sangha Park", "Young Min Paik", "Yongmin Park", "Youngyong Park", "Sanghyun Seo", "Sihoon Yang", "Heuiyeen Yeen", "Sihyuk Yi", "Hyeongu Yun"], "title": "EXAONE 4.0: Unified Large Language Models Integrating Non-reasoning and Reasoning Modes", "comment": "Technical Report, 30 Pages", "summary": "This technical report introduces EXAONE 4.0, which integrates a Non-reasoning\nmode and a Reasoning mode to achieve both the excellent usability of EXAONE 3.5\nand the advanced reasoning abilities of EXAONE Deep. To pave the way for the\nagentic AI era, EXAONE 4.0 incorporates essential features such as agentic tool\nuse, and its multilingual capabilities are extended to support Spanish in\naddition to English and Korean. The EXAONE 4.0 model series consists of two\nsizes: a mid-size 32B model optimized for high performance, and a small-size\n1.2B model designed for on-device applications. The EXAONE 4.0 demonstrates\nsuperior performance compared to open-weight models in its class and remains\ncompetitive even against frontier-class models. The models are publicly\navailable for research purposes and can be easily downloaded via\nhttps://huggingface.co/LGAI-EXAONE.", "AI": {"tldr": "EXAONE 4.0 \u662f\u4e00\u4e2a\u7ed3\u5408\u4e86\u6613\u7528\u6027\u548c\u63a8\u7406\u80fd\u529b\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u652f\u6301\u591a\u8bed\u8a00\u548c\u667a\u80fd\u4f53\u5de5\u5177\u4f7f\u7528\uff0c\u5e76\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u540c\u7c7b\u6a21\u578b\u3002", "motivation": "\u4e3a\u4e86\u5e94\u5bf9\u667a\u80fd\u4f53 AI \u65f6\u4ee3\u7684\u9700\u6c42\uff0cEXAONE 4.0 \u65e8\u5728\u63d0\u4f9b\u5353\u8d8a\u7684\u53ef\u7528\u6027\u548c\u9ad8\u7ea7\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u652f\u6301\u591a\u8bed\u8a00\u548c\u8bbe\u5907\u5e94\u7528\u3002", "method": "EXAONE 4.0 \u662f\u4e00\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7cfb\u5217\uff0c\u5305\u542b 32B \u548c 1.2B \u4e24\u79cd\u5c3a\u5bf8\u300232B \u6a21\u578b\u9488\u5bf9\u9ad8\u6027\u80fd\u8fdb\u884c\u4e86\u4f18\u5316\uff0c\u800c 1.2B \u6a21\u578b\u5219\u4e13\u4e3a\u8bbe\u5907\u5e94\u7528\u8bbe\u8ba1\u3002\u8be5\u6a21\u578b\u5728\u5f00\u653e\u6743\u91cd\u6a21\u578b\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u5e76\u80fd\u4e0e\u524d\u6cbf\u6a21\u578b\u7ade\u4e89\u3002", "result": "EXAONE 4.0 \u5728\u540c\u7c7b\u5f00\u653e\u6743\u91cd\u6a21\u578b\u4e2d\u8868\u73b0\u51fa\u4f17\uff0c\u5e76\u4e14\u5728\u4e0e\u524d\u6cbf\u6a21\u578b\u76f8\u6bd4\u65f6\u4ecd\u5177\u6709\u7ade\u4e89\u529b\u3002\u8be5\u6a21\u578b\u7cfb\u5217\u5305\u542b\u4e24\u79cd\u5c3a\u5bf8\uff0c\u5206\u522b\u9002\u7528\u4e8e\u4e0d\u540c\u573a\u666f\u3002", "conclusion": "EXAONE 4.0 \u6210\u529f\u6574\u5408\u4e86\u975e\u63a8\u7406\u6a21\u5f0f\u548c\u63a8\u7406\u6a21\u5f0f\uff0c\u7ed3\u5408\u4e86 EXAONE 3.5 \u7684\u6613\u7528\u6027\u548c EXAONE Deep \u7684\u9ad8\u7ea7\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u667a\u80fd\u4f53 AI \u65f6\u4ee3\u5960\u5b9a\u4e86\u57fa\u7840\u3002\u5b83\u589e\u52a0\u4e86\u667a\u80fd\u4f53\u5de5\u5177\u4f7f\u7528\u529f\u80fd\uff0c\u5e76\u5c06\u591a\u8bed\u8a00\u80fd\u529b\u6269\u5c55\u5230\u897f\u73ed\u7259\u8bed\u3002"}}
{"id": "2507.10886", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10886", "abs": "https://arxiv.org/abs/2507.10886", "authors": ["Patryk Jasiorski", "Marek Klonowski", "Micha\u0142 Wo\u017aniak"], "title": "How to Protect Models against Adversarial Unlearning?", "comment": null, "summary": "AI models need to be unlearned to fulfill the requirements of legal acts such\nas the AI Act or GDPR, and also because of the need to remove toxic content,\ndebiasing, the impact of malicious instances, or changes in the data\ndistribution structure in which a model works. Unfortunately, removing\nknowledge may cause undesirable side effects, such as a deterioration in model\nperformance. In this paper, we investigate the problem of adversarial\nunlearning, where a malicious party intentionally sends unlearn requests to\ndeteriorate the model's performance maximally. We show that this phenomenon and\nthe adversary's capabilities depend on many factors, primarily on the backbone\nmodel itself and strategy/limitations in selecting data to be unlearned. The\nmain result of this work is a new method of protecting model performance from\nthese side effects, both in the case of unlearned behavior resulting from\nspontaneous processes and adversary actions.", "AI": {"tldr": "\u9057\u5fd8AI\u6a21\u578b\u77e5\u8bc6\u4ee5\u6ee1\u8db3\u6cd5\u5f8b\u548c\u6570\u636e\u9700\u6c42\uff0c\u4f46\u53ef\u80fd\u635f\u5bb3\u6a21\u578b\u6027\u80fd\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5bf9\u6297\u6027\u9057\u5fd8\u65b9\u6cd5\uff0c\u5e76\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u4fdd\u62a4\u6a21\u578b\u6027\u80fd\u514d\u53d7\u9057\u5fd8\u8d1f\u9762\u5f71\u54cd\u7684\u65b9\u6cd5\u3002", "motivation": "AI\u6a21\u578b\u9700\u8981\u6ee1\u8db3\u5982AI\u6cd5\u6848\u6216GDPR\u7b49\u6cd5\u5f8b\u8981\u6c42\uff0c\u4ee5\u53ca\u79fb\u9664\u6709\u6bd2\u5185\u5bb9\u3001\u6d88\u9664\u504f\u89c1\u3001\u5e94\u5bf9\u6076\u610f\u5b9e\u4f8b\u5f71\u54cd\u6216\u6570\u636e\u5206\u5e03\u7ed3\u6784\u53d8\u5316\u7684\u9700\u6c42\uff0c\u4f46\u9057\u5fd8\u77e5\u8bc6\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u4fdd\u62a4\u6a21\u578b\u6027\u80fd\u514d\u53d7\u9057\u5fd8\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u540c\u65f6\u8003\u8651\u4e86\u81ea\u53d1\u8fc7\u7a0b\u548c\u5bf9\u624b\u884c\u4e3a\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5bf9\u6297\u6027\u9057\u5fd8\u73b0\u8c61\u53ca\u5bf9\u624b\u7684\u80fd\u529b\u53d6\u51b3\u4e8e\u6a21\u578b\u67b6\u6784\u548c\u9057\u5fd8\u6570\u636e\u9009\u62e9\u7b56\u7565\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4fdd\u62a4\u6a21\u578b\u6027\u80fd\u7684\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u4fdd\u62a4\u6a21\u578b\u6027\u80fd\uff0c\u4ee5\u5e94\u5bf9\u81ea\u53d1\u8fc7\u7a0b\u548c\u5bf9\u624b\u884c\u4e3a\u5bfc\u81f4\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u5e76\u5f3a\u8c03\u4e86\u6a21\u578b\u67b6\u6784\u548c\u6570\u636e\u9009\u62e9\u7b56\u7565\u5728\u5bf9\u6297\u6027\u9057\u5fd8\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.11395", "categories": ["quant-ph", "cond-mat.quant-gas"], "pdf": "https://arxiv.org/pdf/2507.11395", "abs": "https://arxiv.org/abs/2507.11395", "authors": ["Danish Ali Hamza", "Jan Chwede\u0144czuk"], "title": "Metrology using atoms in an array of double-well potentials", "comment": "11 pages, 4 figures", "summary": "Quantum effects, such as entanglement, Einstein-Podolsky-Rosen steering, and\nBell correlations, can enhance metrological sensitivity beyond the standard\nquantum limit. These correlations are typically generated through interactions\nbetween atoms or molecules, or during the passage of a laser pulse through a\nbirefringent crystal. Here, we consider an alternative method of generating\nscalable, many-body entangled states, and demonstrate their usability for\nquantum-enhanced metrology. Our setup is a one-dimensional (1D) array of\ndouble-well potentials holding independent and uncorrelated Bose-Einstein\ncondensates. The beam-splitting transformation mixes the signal between\nadjacent wells and yields a strongly entangled state through a many-body\nequivalent of the Hong-Ou-Mandel effect. We demonstrate this entanglement can\nimprove the sensitivity of quantum sensors. In our analysis, we account for the\neffects of atomic fluctuations and identify the optimal measurement that\nsaturates the quantum Cramer-Rao bound.", "AI": {"tldr": "\u5229\u7528\u53cc\u9631\u52bf\u9631\u9635\u5217\u548c\u6d2a-\u6b27-\u66fc\u5fb7\u5c14\u6548\u5e94\u7684\u591a\u4f53\u7b49\u6548\u7269\u4ea7\u751f\u7ea0\u7f20\u6001\uff0c\u4ee5\u63d0\u9ad8\u91cf\u5b50\u4f20\u611f\u5668\u7684\u8ba1\u91cf\u7075\u654f\u5ea6\u3002", "motivation": "\u63a2\u7d22\u91cf\u5b50\u6548\u5e94\uff08\u5982\u7ea0\u7f20\u3001\u7231\u56e0\u65af\u5766-\u6ce2\u591a\u5c14\u65af\u57fa-\u7f57\u68ee \u092e\u093f\u0933\u0942\u3001\u8d1d\u5c14\u76f8\u5173\u6027\uff09\u5728\u8d85\u8d8a\u6807\u51c6\u91cf\u5b50\u6781\u9650\u4ee5\u63d0\u9ad8\u8ba1\u91cf\u7075\u654f\u5ea6\u65b9\u9762\u7684\u5e94\u7528\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u751f\u6210\u53ef\u6269\u5c55\u3001\u591a\u4f53\u7ea0\u7f20\u6001\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u91cf\u5b50\u589e\u5f3a\u8ba1\u91cf\u3002", "method": "\u901a\u8fc7\u5305\u542b\u72ec\u7acb\u4e14\u4e0d\u76f8\u5173\u7684\u73bb\u8272-\u7231\u56e0\u65af\u5766\u51dd\u805a\u4f53\u7684\uff081D\uff09\u53cc\u9631\u52bf\u9631\u9635\u5217\uff0c\u5229\u7528\u5206\u675f\u53d8\u6362\u5728\u76f8\u90bb\u9631\u4e4b\u95f4\u6df7\u5408\u4fe1\u53f7\uff0c\u4ea7\u751f\u6d2a-\u6b27-\u66fc\u5fb7\u5c14\u6548\u5e94\u7684\u591a\u4f53\u7b49\u6548\u7269\uff0c\u4ece\u800c\u751f\u6210\u53ef\u6269\u5c55\u7684\u3001\u591a\u4f53\u7ea0\u7f20\u6001\u3002", "result": "\u8bc1\u660e\u4e86\u901a\u8fc7\u6d2a-\u6b27-\u66fc\u5fb7\u5c14\u6548\u5e94\u7684\u591a\u4f53\u7b49\u6548\u7269\u4ea7\u751f\u7684\u7ea0\u7f20\u6001\u53ef\u4ee5\u63d0\u9ad8\u91cf\u5b50\u4f20\u611f\u5668\u7684\u7075\u654f\u5ea6\uff0c\u5e76\u786e\u5b9a\u4e86\u4f7f\u91cf\u5b50\u514b\u62c9\u7f8e-\u7f57\u754c\u9971\u548c\u7684\u6700\u4f73\u6d4b\u91cf\u3002", "conclusion": "\u91cf\u5b50\u7ea0\u7f20\uff08\u5982\u7ea0\u7f20\u3001\u7231\u56e0\u65af\u5766-\u6ce2\u591a\u5c14\u65af\u57fa-\u7f57\u68ee \u092e\u093f\u0933\u0942\u3001\u8d1d\u5c14\u76f8\u5173\u6027\uff09\u53ef\u4ee5\u8d85\u8d8a\u6807\u51c6\u91cf\u5b50\u6781\u9650\u63d0\u9ad8\u8ba1\u91cf\u7075\u654f\u5ea6\u3002\u8fd9\u4e9b\u76f8\u5173\u6027\u901a\u5e38\u901a\u8fc7\u539f\u5b50\u6216\u5206\u5b50\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u6216\u6fc0\u5149\u8109\u51b2\u901a\u8fc7\u53cc\u6298\u5c04\u6676\u4f53\u671f\u95f4\u4ea7\u751f\u3002\u6211\u4eec\u8003\u8651\u4e86\u4e00\u79cd\u66ff\u4ee3\u65b9\u6cd5\u6765\u751f\u6210\u53ef\u6269\u5c55\u7684\u3001\u591a\u4f53\u7ea0\u7f20\u6001\uff0c\u5e76\u5c55\u793a\u4e86\u5b83\u4eec\u5728\u91cf\u5b50\u589e\u5f3a\u8ba1\u91cf\u4e2d\u7684\u53ef\u7528\u6027\u3002\u6211\u4eec\u7684\u88c5\u7f6e\u662f\u5305\u542b\u72ec\u7acb\u4e14\u4e0d\u76f8\u5173\u7684\u73bb\u8272-\u7231\u56e0\u65af\u5766\u51dd\u805a\u4f53\u7684\uff081D\uff09\u53cc\u9631\u52bf\u9631\u9635\u5217\u3002\u5206\u675f\u53d8\u6362\u5728\u76f8\u90bb\u9631\u4e4b\u95f4\u6df7\u5408\u4fe1\u53f7\uff0c\u5e76\u901a\u8fc7\u6d2a-\u6b27-\u66fc\u5fb7\u5c14\u6548\u5e94\u7684\u591a\u4f53\u7b49\u6548\u7269\u4ea7\u751f\u5f3a\u7ea0\u7f20\u6001\u3002\u6211\u4eec\u8bc1\u660e\u4e86\u8fd9\u79cd\u7ea0\u7f20\u53ef\u4ee5\u63d0\u9ad8\u91cf\u5b50\u4f20\u611f\u5668\u7684\u7075\u654f\u5ea6\u3002\u5728\u6211\u4eec\u7684\u5206\u6790\u4e2d\uff0c\u6211\u4eec\u8003\u8651\u4e86\u539f\u5b50\u6da8\u843d\u7684\u5f71\u54cd\uff0c\u5e76\u786e\u5b9a\u4e86\u4f7f\u91cf\u5b50\u514b\u62c9\u7f8e-\u7f57\u754c\u9971\u548c\u7684\u6700\u4f73\u6d4b\u91cf\u3002"}}
{"id": "2507.11171", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11171", "abs": "https://arxiv.org/abs/2507.11171", "authors": ["Jun Chen", "Yonghua Yu", "Weifu Li", "Yaohui Chen", "Hong Chen"], "title": "Clustering-Guided Multi-Layer Contrastive Representation Learning for Citrus Disease Classification", "comment": "11 pages, 5 figures", "summary": "Citrus, as one of the most economically important fruit crops globally,\nsuffers severe yield depressions due to various diseases. Accurate disease\ndetection and classification serve as critical prerequisites for implementing\ntargeted control measures. Recent advancements in artificial intelligence,\nparticularly deep learning-based computer vision algorithms, have substantially\ndecreased time and labor requirements while maintaining the accuracy of\ndetection and classification. Nevertheless, these methods predominantly rely on\nmassive, high-quality annotated training examples to attain promising\nperformance. By introducing two key designs: contrasting with cluster centroids\nand a multi-layer contrastive training (MCT) paradigm, this paper proposes a\nnovel clustering-guided self-supervised multi-layer contrastive representation\nlearning (CMCRL) algorithm. The proposed method demonstrates several advantages\nover existing counterparts: (1) optimizing with massive unannotated samples;\n(2) effective adaptation to the symptom similarity across distinct citrus\ndiseases; (3) hierarchical feature representation learning. The proposed method\nachieves state-of-the-art performance on the public citrus image set CDD,\noutperforming existing methods by 4.5\\%-30.1\\% accuracy. Remarkably, our method\nnarrows the performance gap with fully supervised counterparts (all samples are\nlabeled). Beyond classification accuracy, our method shows great performance on\nother evaluation metrics (F1 score, precision, and recall), highlighting the\nrobustness against the class imbalance challenge.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u805a\u7c7b\u5f15\u5bfc\u81ea\u76d1\u7763\u5b66\u4e60\u7b97\u6cd5\uff08CMCRL\uff09\uff0c\u7528\u4e8e\u67d1\u6a58\u75c5\u5bb3\u7684\u68c0\u6d4b\u548c\u5206\u7c7b\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u80fd\u591f\u5904\u7406\u75c5\u5bb3\u75c7\u72b6\u76f8\u4f3c\u7684\u95ee\u9898\uff0c\u5e76\u5b66\u4e60\u5206\u5c42\u7279\u5f81\u8868\u793a\uff0c\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5f53\u524d\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u7b97\u6cd5\u5728\u67d1\u6a58\u75c5\u5bb3\u68c0\u6d4b\u548c\u5206\u7c7b\u65b9\u9762\u9700\u8981\u5927\u91cf\u9ad8\u8d28\u91cf\u5e26\u6ce8\u91ca\u7684\u8bad\u7ec3\u6837\u672c\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u805a\u7c7b\u5f15\u5bfc\u81ea\u76d1\u7763\u591a\u5c42\u5bf9\u6bd4\u8868\u793a\u5b66\u4e60\uff08CMCRL\uff09\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u901a\u8fc7\u4e24\u4e2a\u5173\u952e\u8bbe\u8ba1\uff1a\u4e0e\u805a\u7c7b\u8d28\u5fc3\u7684\u5bf9\u6bd4\u548c\u591a\u5c42\u5bf9\u6bd4\u8bad\u7ec3\uff08MCT\uff09\u8303\u5f0f\u3002", "result": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u4e14\u5728\u51c6\u786e\u6027\u3001F1\u5206\u6570\u3001\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387\u7b49\u65b9\u9762\u5747\u8868\u73b0\u51fa\u8272\uff0c\u5c24\u5176\u5728\u7c7b\u522b\u4e0d\u5e73\u8861\u7684\u60c5\u51b5\u4e0b\u663e\u793a\u51fa\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728CDD\u516c\u5171\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5728\u51c6\u786e\u6027\u4e0a\u6bd4\u73b0\u6709\u65b9\u6cd5\u9ad8\u51fa4.5%-30.1%\u3002\u6b64\u5916\uff0c\u5728\u7c7b\u522b\u4e0d\u5e73\u8861\u7684\u6311\u6218\u4e0b\uff0c\u8be5\u65b9\u6cd5\u5728F1\u5206\u6570\u3001\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387\u7b49\u5176\u4ed6\u8bc4\u4f30\u6307\u6807\u4e0a\u4e5f\u8868\u73b0\u51fa\u8272\uff0c\u8bc1\u660e\u4e86\u5176\u9c81\u68d2\u6027\u3002"}}
{"id": "2507.11408", "categories": ["cs.CL", "cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2507.11408", "abs": "https://arxiv.org/abs/2507.11408", "authors": ["Soumadeep Saha", "Akshay Chaturvedi", "Saptarshi Saha", "Utpal Garain", "Nicholas Asher"], "title": "KisMATH: Do LLMs Have Knowledge of Implicit Structures in Mathematical Reasoning?", "comment": "15 pages, 9 figures", "summary": "Chain-of-thought traces have been shown to improve performance of large\nlanguage models in a plethora of reasoning tasks, yet there is no consensus on\nthe mechanism through which this performance boost is achieved. To shed more\nlight on this, we introduce Causal CoT Graphs (CCGs), which are directed\nacyclic graphs automatically extracted from reasoning traces that model\nfine-grained causal dependencies in the language model output. A collection of\n$1671$ mathematical reasoning problems from MATH500, GSM8K and AIME, and their\nassociated CCGs are compiled into our dataset -- \\textbf{KisMATH}. Our detailed\nempirical analysis with 15 open-weight LLMs shows that (i) reasoning nodes in\nthe CCG are mediators for the final answer, a condition necessary for\nreasoning; and (ii) LLMs emphasise reasoning paths given by the CCG, indicating\nthat models internally realise structures akin to our graphs. KisMATH enables\ncontrolled, graph-aligned interventions and opens up avenues for further\ninvestigation into the role of chain-of-thought in LLM reasoning.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f15\u5165\u56e0\u679c\u601d\u7ef4\u94fe\u56fe\uff08CCGs\uff09\u6765\u89e3\u91ca\u601d\u7ef4\u94fe\u5982\u4f55\u63d0\u9ad8LLM\u7684\u63a8\u7406\u80fd\u529b\u3002\u901a\u8fc7\u6784\u5efaKisMATH\u6570\u636e\u96c6\uff0c\u53d1\u73b0\u63a8\u7406\u8282\u70b9\u662f\u7b54\u6848\u7684\u5173\u952e\u4e2d\u4ecb\uff0c\u4e14LLM\u4f1a\u9075\u5faaCCG\u7ed3\u6784\u8fdb\u884c\u63a8\u7406\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5c1a\u672a\u5c31\u601d\u7ef4\u94fe\uff08Chain-of-thought\uff09\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u79cd\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u7684\u673a\u5236\u8fbe\u6210\u5171\u8bc6\u3002", "method": "\u63d0\u51fa\u56e0\u679c\u601d\u7ef4\u94fe\u56fe\uff08CCGs\uff09\u7684\u6982\u5ff5\uff0c\u8fd9\u662f\u4e00\u79cd\u4ece\u63a8\u7406\u94fe\u4e2d\u81ea\u52a8\u63d0\u53d6\u7684\u3001\u80fd\u591f\u6a21\u62df\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u4e2d\u7ec6\u7c92\u5ea6\u56e0\u679c\u4f9d\u8d56\u5173\u7cfb\u7684\u5b9a\u5411\u65e0\u73af\u56fe\u3002\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b1671\u4e2a\u6570\u5b66\u63a8\u7406\u95ee\u9898\u53ca\u5176\u76f8\u5173CCGs\u7684\u6570\u636e\u96c6\u2014\u2014KisMATH\u3002", "result": "\u901a\u8fc7\u5bf915\u4e2a\u5f00\u6e90\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8be6\u7ec6\u7684\u5b9e\u8bc1\u5206\u6790\uff0c\u53d1\u73b0CCG\u4e2d\u7684\u63a8\u7406\u8282\u70b9\u662f\u6700\u7ec8\u7b54\u6848\u7684\u5fc5\u8981\u4e2d\u4ecb\uff08\u5373\u63a8\u7406\u8fc7\u7a0b\u7684\u5fc5\u8981\u6761\u4ef6\uff09\uff0c\u5e76\u4e14\u8bed\u8a00\u6a21\u578b\u4f1a\u503e\u5411\u4e8e\u9075\u5faaCCG\u63d0\u4f9b\u7684\u63a8\u7406\u8def\u5f84\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u5f15\u5165\u56e0\u679c\u601d\u7ef4\u94fe\u56fe\uff08CCGs\uff09\u6765\u89e3\u6790\u601d\u7ef4\u94fe\u63a8\u7406\u7684\u673a\u5236\u3002\u5b9e\u9a8c\u8868\u660e\uff0cCCGs\u4e2d\u7684\u63a8\u7406\u8282\u70b9\u662f\u6700\u7ec8\u7b54\u6848\u7684\u5fc5\u8981\u4e2d\u4ecb\uff0c\u5e76\u4e14\u8bed\u8a00\u6a21\u578b\u4f1a\u4f18\u5148\u8003\u8651CCG\u63d0\u4f9b\u7684\u63a8\u7406\u8def\u5f84\uff0c\u8868\u660e\u6a21\u578b\u5185\u90e8\u5b58\u5728\u7c7b\u4f3cCCG\u7684\u7ed3\u6784\u3002"}}
{"id": "2507.10890", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10890", "abs": "https://arxiv.org/abs/2507.10890", "authors": ["Riccardo Savorgnan", "Udaya Ghai", "Carson Eisenach", "Dean Foster"], "title": "Outbound Modeling for Inventory Management", "comment": "KDD - AI for Supply Chain Workshop", "summary": "We study the problem of forecasting the number of units fulfilled (or\n``drained'') from each inventory warehouse to meet customer demand, along with\nthe associated outbound shipping costs. The actual drain and shipping costs are\ndetermined by complex production systems that manage the planning and execution\nof customers' orders fulfillment, i.e. from where and how to ship a unit to be\ndelivered to a customer. Accurately modeling these processes is critical for\nregional inventory planning, especially when using Reinforcement Learning (RL)\nto develop control policies. For the RL usecase, a drain model is incorporated\ninto a simulator to produce long rollouts, which we desire to be\ndifferentiable. While simulating the calls to the internal software systems can\nbe used to recover this transition, they are non-differentiable and too slow\nand costly to run within an RL training environment. Accordingly, we frame this\nas a probabilistic forecasting problem, modeling the joint distribution of\noutbound drain and shipping costs across all warehouses at each time period,\nconditioned on inventory positions and exogenous customer demand. To ensure\nrobustness in an RL environment, the model must handle out-of-distribution\nscenarios that arise from off-policy trajectories. We propose a validation\nscheme that leverages production systems to evaluate the drain model on\ncounterfactual inventory states induced by RL policies. Preliminary results\ndemonstrate the model's accuracy within the in-distribution setting.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6982\u7387\u9884\u6d4b\u6a21\u578b\uff0c\u7528\u4e8e\u51c6\u786e\u9884\u6d4b\u5e93\u5b58\u4ed3\u5e93\u7684\u5355\u4f4d\u6d41\u5931\u548c\u8fd0\u8f93\u6210\u672c\uff0c\u4ee5\u652f\u6301\u5f3a\u5316\u5b66\u4e60\u5728\u5e93\u5b58\u7ba1\u7406\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u9a8c\u8bc1\u65b9\u6848\u6765\u8bc4\u4f30\u6a21\u578b\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u533a\u57df\u5e93\u5b58\u89c4\u5212\u7684\u51c6\u786e\u6027\uff0c\u7279\u522b\u662f\u4e3a\u4e86\u652f\u6301\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u63a7\u5236\u7b56\u7565\u7684\u5f00\u53d1\uff0c\u9700\u8981\u5bf9\u590d\u6742\u7684\u751f\u4ea7\u7cfb\u7edf\u4e2d\u7684\u5355\u4f4d\u6d41\u5931\u548c\u8fd0\u8f93\u6210\u672c\u8fdb\u884c\u5efa\u6a21\u3002\u73b0\u6709\u7684\u6a21\u62df\u65b9\u6cd5\u7531\u4e8e\u5176\u4e0d\u53ef\u5fae\u548c\u6210\u672c\u9ad8\u6602\u7684\u7279\u6027\uff0c\u4e0d\u9002\u7528\u4e8eRL\u8bad\u7ec3\u73af\u5883\u3002", "method": "\u5c06\u5e93\u5b58\u4ed3\u5e93\u7684\u5355\u4f4d\u6d41\u5931\u548c\u76f8\u5173\u8fd0\u8f93\u6210\u672c\u7684\u9884\u6d4b\u95ee\u9898\uff0c\u5efa\u6a21\u4e3a\u6982\u7387\u9884\u6d4b\u95ee\u9898\u3002\u901a\u8fc7\u5bf9\u6240\u6709\u4ed3\u5e93\u7684\u5355\u4f4d\u6d41\u5931\u548c\u8fd0\u8f93\u6210\u672c\u7684\u8054\u5408\u5206\u5e03\u8fdb\u884c\u5efa\u6a21\uff0c\u5e76\u4ee5\u5e93\u5b58\u91cf\u548c\u5916\u6e90\u6027\u5ba2\u6237\u9700\u6c42\u4f5c\u4e3a\u6761\u4ef6\uff0c\u6765\u89e3\u51b3\u590d\u6742\u7684\u751f\u4ea7\u7cfb\u7edf\u548c\u975e\u53ef\u5fae\u7684\u6a21\u62df\u95ee\u9898\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u751f\u4ea7\u7cfb\u7edf\u6765\u8bc4\u4f30\u56e0\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u5f15\u8d77\u7684\u6f5c\u5728\u5e93\u5b58\u72b6\u6001\u7684\u6a21\u578b\u9a8c\u8bc1\u65b9\u6848\u3002", "result": "\u63d0\u51fa\u7684\u6982\u7387\u9884\u6d4b\u6a21\u578b\u5728\u5206\u5e03\u5185\u573a\u666f\u4e0b\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u5355\u4f4d\u6d41\u5931\u548c\u8fd0\u8f93\u6210\u672c\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u7684\u9a8c\u8bc1\u6765\u8bc4\u4f30\u5176\u5728\u5206\u5e03\u5916\u573a\u666f\u548c\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u8868\u73b0\u3002", "conclusion": "\u57fa\u4e8e\u5bf9\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u521d\u6b65\u8bc4\u4f30\uff0c\u8be5\u6a21\u578b\u5728\u5206\u5e03\u5185\u8bbe\u7f6e\u4e0b\u8868\u73b0\u51fa\u51c6\u786e\u6027\uff0c\u4f46\u9700\u8981\u9488\u5bf9\u5b9e\u9645\u5e94\u7528\u8fdb\u884c\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u3002"}}
{"id": "2507.11401", "categories": ["quant-ph", "cs.CV", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11401", "abs": "https://arxiv.org/abs/2507.11401", "authors": ["Mehri Mehrnia", "Mohammed S. M. Elbaz"], "title": "Stochastic Entanglement Configuration for Constructive Entanglement Topologies in Quantum Machine Learning with Application to Cardiac MRI", "comment": "Accepted for publication at IEEE International Conference on Quantum\n  Computing and Engineering (QCE) 2025", "summary": "Efficient entanglement strategies are essential for advancing variational\nquantum circuits (VQCs) for quantum machine learning (QML). However, most\ncurrent approaches use fixed entanglement topologies that are not adaptive to\ntask requirements, limiting potential gains over classical models. We introduce\na novel stochastic entanglement configuration method that systematically\ngenerates diverse entanglement topologies to identify a subspace of\nconstructive entanglement configurations, defined as entanglement topologies\nthat boost hybrid model performance (e.g., classification accuracy) beyond\nclassical baselines. Each configuration is encoded as a stochastic binary\nmatrix, denoting directed entanglement between qubits. This enables scalable\nexploration of the hyperspace of candidate entanglement topologies using\nentanglement density and per-qubit constraints as key metrics. We define\nunconstrained and constrained sampling modes, controlling entanglement per\nqubit. Using our method, 400 stochastic configurations were generated and\nevaluated in a hybrid QML for cardiac MRI disease classification. We identified\n64 (16%) novel constructive entanglement configurations that consistently\noutperformed the classical baseline. Ensemble aggregation of top-performing\nconfigurations achieved ~0.92 classification accuracy, exceeding the classical\nmodel (~0.87) by over 5%. Compared to four conventional topologies (ring,\nnearest neighbor, no entanglement, fully entangled), none surpassed the\nclassical baseline (maximum accuracy ~0.82), while our configurations delivered\nup to ~20% higher accuracy. Thus, highlighting the robustness and\ngeneralizability of the identified constructive entanglements.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u968f\u673a\u7ea0\u7f20\u914d\u7f6e\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316\u53d8\u5206\u91cf\u5b50\u7535\u8def\u7684\u7ea0\u7f20\u7b56\u7565\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u751f\u6210\u548c\u8bc4\u4f30\u591a\u79cd\u7ea0\u7f20\u62d3\u6251\u7ed3\u6784\uff0c\u5728\u5fc3\u810fMRI\u75be\u75c5\u5206\u7c7b\u4efb\u52a1\u4e2d\u53d1\u73b0\u4e86\u4f18\u4e8e\u7ecf\u5178\u6a21\u578b\u548c\u4f20\u7edf\u65b9\u6cd5\u7684\u5efa\u8bbe\u6027\u7ea0\u7f20\u914d\u7f6e\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5206\u7c7b\u51c6\u786e\u7387\u3002", "motivation": "\u5f53\u524d\u91cf\u5b50\u673a\u5668\u5b66\u4e60\uff08QML\uff09\u4e2d\u7684\u53d8\u5206\u91cf\u5b50\u7535\u8def\uff08VQC\uff09\u867d\u7136\u9700\u8981\u6709\u6548\u7684\u7ea0\u7f20\u7b56\u7565\uff0c\u4f46\u5927\u591a\u91c7\u7528\u56fa\u5b9a\u7684\u3001\u4e0d\u9002\u5e94\u4efb\u52a1\u9700\u6c42\u7684\u7ea0\u7f20\u62d3\u6251\u7ed3\u6784\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u8d85\u8d8a\u7ecf\u5178\u6a21\u578b\u7684\u6f5c\u529b\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u81ea\u9002\u5e94\u4efb\u52a1\u9700\u6c42\u3001\u7cfb\u7edf\u5730\u751f\u6210\u548c\u8bc4\u4f30\u591a\u6837\u5316\u7ea0\u7f20\u62d3\u6251\u7ed3\u6784\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u968f\u673a\u7ea0\u7f20\u914d\u7f6e\u65b9\u6cd5\uff0c\u5c06\u7ea0\u7f20\u62d3\u6251\u7f16\u7801\u4e3a\u8868\u793a\u91cf\u5b50\u6bd4\u7279\u4e4b\u95f4\u5b9a\u5411\u7ea0\u7f20\u7684\u968f\u673a\u4e8c\u5143\u77e9\u9635\u3002\u8be5\u65b9\u6cd5\u5141\u8bb8\u4f7f\u7528\u7ea0\u7f20\u5bc6\u5ea6\u548c\u6bcf\u91cf\u5b50\u6bd4\u7279\u7ea6\u675f\u4f5c\u4e3a\u5173\u952e\u6307\u6807\uff0c\u5728\u5047\u8bbe\u7684\u5019\u9009\u7ea0\u7f20\u62d3\u6251\u7a7a\u95f4\u4e2d\u8fdb\u884c\u53ef\u6269\u5c55\u63a2\u7d22\u3002\u8be5\u65b9\u6cd5\u5b9a\u4e49\u4e86\u65e0\u7ea6\u675f\u548c\u6709\u7ea6\u675f\u7684\u91c7\u6837\u6a21\u5f0f\uff0c\u4ee5\u63a7\u5236\u6bcf\u91cf\u5b50\u6bd4\u7279\u7684\u7ea0\u7f20\u3002", "result": "\u7814\u7a76\u4e2d\u751f\u6210\u7684400\u79cd\u968f\u673a\u914d\u7f6e\u5728\u5fc3\u810fMRI\u75be\u75c5\u5206\u7c7b\u4efb\u52a1\u4e2d\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5176\u4e2d64\u79cd\uff0816%\uff09\u88ab\u8bc6\u522b\u4e3a\u5efa\u8bbe\u6027\u914d\u7f6e\uff0c\u5176\u6027\u80fd\u4e00\u81f4\u4f18\u4e8e\u7ecf\u5178\u57fa\u7ebf\u3002\u9876\u5c16\u914d\u7f6e\u7684\u96c6\u6210\u6a21\u578b\u8fbe\u5230\u4e86\u7ea60.92\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u6bd4\u7ecf\u5178\u6a21\u578b\uff08\u7ea60.87\uff09\u9ad8\u51fa5%\u4ee5\u4e0a\u3002\u4e0e\u73af\u72b6\u3001\u6700\u8fd1\u90bb\u3001\u65e0\u7ea0\u7f20\u548c\u5168\u7ea0\u7f20\u7b49\u56db\u79cd\u4f20\u7edf\u62d3\u6251\u7ed3\u6784\u76f8\u6bd4\uff0c\u4f20\u7edf\u7ed3\u6784\u5747\u672a\u8d85\u8d8a\u7ecf\u5178\u57fa\u7ebf\uff08\u6700\u9ad8\u51c6\u786e\u7387\u7ea60.82\uff09\uff0c\u800c\u8be5\u65b9\u6cd5\u8bc6\u522b\u51fa\u7684\u914d\u7f6e\u51c6\u786e\u7387\u6700\u9ad8\u53ef\u63d0\u534720%\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u968f\u673a\u7ea0\u7f20\u914d\u7f6e\u65b9\u6cd5\u80fd\u591f\u7cfb\u7edf\u5730\u751f\u6210\u591a\u6837\u5316\u7684\u7ea0\u7f20\u62d3\u6251\u7ed3\u6784\uff0c\u5e76\u4ece\u4e2d\u8bc6\u522b\u51fa\u80fd\u591f\u63d0\u5347\u6df7\u5408\u6a21\u578b\u6027\u80fd\u7684\u5efa\u8bbe\u6027\u7ea0\u7f20\u914d\u7f6e\u3002\u5728\u5fc3\u810fMRI\u75be\u75c5\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u8be5\u65b9\u6cd5\u53d1\u73b0\u4e86400\u79cd\u914d\u7f6e\u4e2d\u768464\u79cd\uff0816%\uff09\u5efa\u8bbe\u6027\u914d\u7f6e\uff0c\u5176\u6027\u80fd\u4e00\u81f4\u4f18\u4e8e\u7ecf\u5178\u57fa\u7ebf\u3002\u901a\u8fc7\u96c6\u6210\u9876\u5c16\u914d\u7f6e\uff0c\u5b9e\u73b0\u4e86\u7ea60.92\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u663e\u8457\u8d85\u8d8a\u4e86\u7ecf\u5178\u6a21\u578b\uff08\u7ea60.87\uff09\u8d85\u8fc75%\u3002\u4e0e\u56db\u79cd\u4f20\u7edf\u62d3\u6251\u7ed3\u6784\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u8bc6\u522b\u51fa\u7684\u914d\u7f6e\u53ef\u63d0\u4f9b\u9ad8\u8fbe20%\u7684\u51c6\u786e\u7387\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u5176\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2507.11200", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11200", "abs": "https://arxiv.org/abs/2507.11200", "authors": ["Che Liu", "Jiazhen Pan", "Weixiang Shen", "Wenjia Bai", "Daniel Rueckert", "Rossella Arcucci"], "title": "How Far Have Medical Vision-Language Models Come? A Comprehensive Benchmarking Study", "comment": "Accepted by the International Conference on AI in Healthcare 2025", "summary": "Vision-Language Models (VLMs) trained on web-scale corpora excel at natural\nimage tasks and are increasingly repurposed for healthcare; however, their\ncompetence in medical tasks remains underexplored. We present a comprehensive\nevaluation of open-source general-purpose and medically specialised VLMs,\nranging from 3B to 72B parameters, across eight benchmarks: MedXpert,\nOmniMedVQA, PMC-VQA, PathVQA, MMMU, SLAKE, and VQA-RAD. To observe model\nperformance across different aspects, we first separate it into understanding\nand reasoning components. Three salient findings emerge. First, large\ngeneral-purpose models already match or surpass medical-specific counterparts\non several benchmarks, demonstrating strong zero-shot transfer from natural to\nmedical images. Second, reasoning performance is consistently lower than\nunderstanding, highlighting a critical barrier to safe decision support. Third,\nperformance varies widely across benchmarks, reflecting differences in task\ndesign, annotation quality, and knowledge demands. No model yet reaches the\nreliability threshold for clinical deployment, underscoring the need for\nstronger multimodal alignment and more rigorous, fine-grained evaluation\nprotocols.", "AI": {"tldr": "\u8bc4\u4f30\u4e86\u901a\u7528\u548c\u533b\u5b66\u4e13\u7528\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u5728\u533b\u7597\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5927\u578b\u901a\u7528\u6a21\u578b\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u8fc1\u79fb\u80fd\u529b\uff0c\u4f46\u63a8\u7406\u80fd\u529b\u4ecd\u6709\u5f85\u63d0\u9ad8\uff0c\u4e14\u6ca1\u6709\u6a21\u578b\u8fbe\u5230\u4e34\u5e8a\u90e8\u7f72\u7684\u6807\u51c6\u3002", "motivation": "\u8bc4\u4f30\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u5728\u533b\u7597\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\uff0c\u56e0\u4e3a\u5b83\u4eec\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u91cd\u65b0\u7528\u4e8e\u533b\u7597\u4fdd\u5065\u9886\u57df\u3002", "method": "\u5bf9\u5f00\u653e\u6e90\u4ee3\u7801\u7684\u901a\u7528\u548c\u533b\u5b66\u4e13\u4e1a\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u8fdb\u884c\u4e86\u5168\u9762\u7684\u8bc4\u4f30\uff0c\u8fd9\u4e9b\u6a21\u578b\u6db5\u76d6\u4e863B\u523072B\u53c2\u6570\uff0c\u6a2a\u8de8\u516b\u4e2a\u57fa\u51c6\uff1aMedXpert\u3001OmniMedVQA\u3001PMC-VQA\u3001PathVQA\u3001MMMU\u3001SLAKE\u548cVQA-RAD\u3002\u9996\u5148\u5c06\u6a21\u578b\u6027\u80fd\u5206\u4e3a\u7406\u89e3\u548c\u63a8\u7406\u4e24\u4e2a\u7ec4\u6210\u90e8\u5206\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff1a1.\u5927\u578b\u901a\u7528\u6a21\u578b\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u7684\u8868\u73b0\u5df2\u8fbe\u5230\u751a\u81f3\u8d85\u8fc7\u4e86\u533b\u5b66\u4e13\u4e1a\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u4ece\u81ea\u7136\u56fe\u50cf\u5230\u533b\u5b66\u56fe\u50cf\u7684\u5f3a\u5927\u96f6\u6837\u672c\u8fc1\u79fb\u80fd\u529b\u30022.\u63a8\u7406\u6027\u80fd\u59cb\u7ec8\u4f4e\u4e8e\u7406\u89e3\u6027\u80fd\uff0c\u8fd9\u8868\u660e\u5728\u5b89\u5168\u51b3\u7b56\u652f\u6301\u65b9\u9762\u5b58\u5728\u5173\u952e\u969c\u788d\u30023.\u6a21\u578b\u5728\u4e0d\u540c\u57fa\u51c6\u4e0a\u7684\u6027\u80fd\u5dee\u5f02\u5f88\u5927\uff0c\u8fd9\u53cd\u6620\u4e86\u4efb\u52a1\u8bbe\u8ba1\u3001\u6ce8\u91ca\u8d28\u91cf\u548c\u77e5\u8bc6\u9700\u6c42\u65b9\u9762\u7684\u5dee\u5f02\u3002", "conclusion": "\u76ee\u524d\u6ca1\u6709\u6a21\u578b\u8fbe\u5230\u4e34\u5e8a\u90e8\u7f72\u7684\u53ef\u9760\u6027\u9608\u503c\uff0c\u8fd9\u51f8\u663e\u4e86\u52a0\u5f3a\u591a\u6a21\u6001\u5bf9\u9f50\u548c\u66f4\u4e25\u683c\u3001\u66f4\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u534f\u8bae\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2507.11412", "categories": ["cs.CL", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11412", "abs": "https://arxiv.org/abs/2507.11412", "authors": ["Orion Weller", "Kathryn Ricci", "Marc Marone", "Antoine Chaffin", "Dawn Lawrie", "Benjamin Van Durme"], "title": "Seq vs Seq: An Open Suite of Paired Encoders and Decoders", "comment": null, "summary": "The large language model (LLM) community focuses almost exclusively on\ndecoder-only language models, since they are easier to use for text generation.\nHowever, a large subset of the community still uses encoder-only models for\ntasks such as classification or retrieval. Previous work has attempted to\ncompare these architectures, but is forced to make comparisons with models that\nhave different numbers of parameters, training techniques, and datasets. We\nintroduce the SOTA open-data Ettin suite of models: paired encoder-only and\ndecoder-only models ranging from 17 million parameters to 1 billion, trained on\nup to 2 trillion tokens. Using the same recipe for both encoder-only and\ndecoder-only models produces SOTA recipes in both categories for their\nrespective sizes, beating ModernBERT as an encoder and Llama 3.2 and SmolLM2 as\ndecoders. Like previous work, we find that encoder-only models excel at\nclassification and retrieval tasks while decoders excel at generative tasks.\nHowever, we show that adapting a decoder model to encoder tasks (and vice\nversa) through continued training is subpar compared to using only the reverse\nobjective (i.e. a 400M encoder outperforms a 1B decoder on MNLI, and vice versa\nfor generative tasks). We open-source all artifacts of this study including\ntraining data, training order segmented by checkpoint, and 200+ checkpoints to\nallow future work to analyze or extend all aspects of training.", "AI": {"tldr": "Fair comparison of encoder-only and decoder-only LLMs using the Ettin suite, showing SOTA results and task-specific performance advantages, with continued training being suboptimal for cross-task adaptation.", "motivation": "Previous work has attempted to compare encoder-only and decoder-only language models, but is forced to make comparisons with models that have different numbers of parameters, training techniques, and datasets. This study aims to provide a fair comparison using a consistent training methodology.", "method": "Introduction of the SOTA open-data Ettin suite of models: paired encoder-only and decoder-only models ranging from 17 million parameters to 1 billion, trained on up to 2 trillion tokens. Using the same recipe for both encoder-only and decoder-only models.", "result": "The Ettin suite achieved SOTA results in both encoder-only and decoder-only categories for their respective sizes, outperforming ModernBERT, Llama 3.2, and SmolLM2. It was found that encoder-only models are better for classification and retrieval, while decoder-only models are better for generative tasks. Adapting models across tasks through continued training is less effective than using the reverse objective.", "conclusion": "encoder-only models excel at classification and retrieval tasks while decoders excel at generative tasks. Adapting a decoder model to encoder tasks (and vice versa) through continued training is subpar compared to using only the reverse objective."}}
{"id": "2507.10904", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10904", "abs": "https://arxiv.org/abs/2507.10904", "authors": ["Elisa Tsai", "Haizhong Zheng", "Atul Prakash"], "title": "Class-Proportional Coreset Selection for Difficulty-Separable Data", "comment": "This paper has been accepted to the ICCV 2025 Workshop on Curated\n  Data for Efficient Learning (CDEL)", "summary": "High-quality training data is essential for building reliable and efficient\nmachine learning systems. One-shot coreset selection addresses this by pruning\nthe dataset while maintaining or even improving model performance, often\nrelying on training-dynamics-based data difficulty scores. However, most\nexisting methods implicitly assume class-wise homogeneity in data difficulty,\noverlooking variation in data difficulty across different classes.\n  In this work, we challenge this assumption by showing that, in domains such\nas network intrusion detection and medical imaging, data difficulty often\nclusters by class. We formalize this as class-difficulty separability and\nintroduce the Class Difficulty Separability Coefficient (CDSC) as a\nquantitative measure. We demonstrate that high CDSC values correlate with\nperformance degradation in class-agnostic coreset methods, which tend to\noverrepresent easy majority classes while neglecting rare but informative ones.\n  To address this, we introduce class-proportional variants of multiple\nsampling strategies. Evaluated on five diverse datasets spanning security and\nmedical domains, our methods consistently achieve state-of-the-art data\nefficiency. For instance, on CTU-13, at an extreme 99% pruning rate, a\nclass-proportional variant of Coverage-centric Coreset Selection (CCS-CP) shows\nremarkable stability, with accuracy dropping only 2.58%, precision 0.49%, and\nrecall 0.19%. In contrast, the class-agnostic CCS baseline, the next best\nmethod, suffers sharper declines of 7.59% in accuracy, 4.57% in precision, and\n4.11% in recall.\n  We further show that aggressive pruning enhances generalization in noisy,\nimbalanced, and large-scale datasets. Our results underscore that explicitly\nmodeling class-difficulty separability leads to more effective, robust, and\ngeneralizable data pruning, particularly in high-stakes scenarios.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7c7b\u522b-\u96be\u5ea6\u53ef\u5206\u79bb\u6027\u6982\u5ff5\uff0c\u5e76\u5f00\u53d1\u4e86\u76f8\u5e94\u7684\u5ea6\u91cf\u65b9\u6cd5\uff08CDSC\uff09\u548c\u89e3\u51b3\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u7684\u91c7\u6837\u7b56\u7565\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6570\u636e\u96c6\u4fee\u526a\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u4e0d\u5e73\u8861\u548c\u5927\u89c4\u6a21\u6570\u636e\u96c6\u65f6\uff0c\u80fd\u663e\u8457\u63d0\u9ad8\u6a21\u578b\u7684\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u96c6\u4fee\u526a\u65b9\u6cd5\uff08\u5982\u5355\u6b21\u5171\u540c\u4f53\u9009\u62e9\uff09\u901a\u5e38\u5047\u8bbe\u6570\u636e\u96be\u5ea6\u5728\u7c7b\u522b\u4e4b\u95f4\u662f\u540c\u8d28\u7684\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u6570\u636e\u96be\u5ea6\u5728\u4e0d\u540c\u7c7b\u522b\u4e4b\u95f4\u53ef\u80fd\u5b58\u5728\u5dee\u5f02\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u7c7b\u522b\u4e0d\u53ef\u77e5\u65b9\u6cd5\u8fc7\u5ea6\u4ee3\u8868\u6613\u7c7b\u522b\u800c\u5ffd\u7565\u4e86\u7a00\u6709\u4f46\u4fe1\u606f\u4e30\u5bcc\u7684\u7c7b\u522b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u7c7b\u522b\u96be\u5ea6\u53ef\u5206\u79bb\u6027\u7cfb\u6570\uff08CDSC\uff09\u7684\u91cf\u5316\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u4e86\u591a\u79cd\u91c7\u6837\u7b56\u7565\u7684\u7c7b\u522b\u6bd4\u4f8b\u53d8\u4f53\uff0c\u4ee5\u89e3\u51b3\u7c7b\u522b\u4e0d\u53ef\u77e5\u5171\u540c\u4f53\u9009\u62e9\u65b9\u6cd5\u4e2d\u7c7b\u522b-\u96be\u5ea6\u540c\u8d28\u6027\u5047\u8bbe\u7684\u95ee\u9898\u3002", "result": "\u5728\u4e94\u4e2a\u8de8\u8d8a\u5b89\u5168\u548c\u533b\u5b66\u9886\u57df\u7684\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7c7b\u522b\u6bd4\u4f8b\u65b9\u6cd5\u5728\u6570\u636e\u6548\u7387\u65b9\u9762\u59cb\u7ec8\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u3002\u4f8b\u5982\uff0c\u5728CTU-13\u6570\u636e\u96c6\u4e0a\uff0c\u572899%\u7684\u6781\u7aef\u4fee\u526a\u7387\u4e0b\uff0c\u4e00\u79cd\u540d\u4e3aCCS-CP\u7684\u7c7b\u522b\u6bd4\u4f8b\u53d8\u4f53\u5728\u51c6\u786e\u7387\u3001\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387\u65b9\u9762\u7684\u4e0b\u964d\u5e45\u5ea6\u8fdc\u5c0f\u4e8e\u7c7b\u522b\u4e0d\u53ef\u77e5\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u8868\u660e\uff0c\u6fc0\u8fdb\u7684\u4fee\u526a\u53ef\u4ee5\u589e\u5f3a\u6a21\u578b\u5728\u566a\u58f0\u3001\u4e0d\u5e73\u8861\u548c\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u663e\u5f0f\u5730\u5bf9\u7c7b\u522b-\u96be\u5ea6\u53ef\u5206\u79bb\u6027\u8fdb\u884c\u5efa\u6a21\uff0c\u53ef\u4ee5\u5b9e\u73b0\u66f4\u6709\u6548\u3001\u66f4\u9c81\u68d2\u548c\u66f4\u5177\u6cdb\u5316\u80fd\u529b\u7684\u6570\u636e\u4fee\u526a\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u98ce\u9669\u573a\u666f\u4e2d\u3002"}}
{"id": "2507.11424", "categories": ["quant-ph", "cond-mat.other"], "pdf": "https://arxiv.org/pdf/2507.11424", "abs": "https://arxiv.org/abs/2507.11424", "authors": ["Manuel S. Rudolph", "Joseph Tindall"], "title": "Simulating and Sampling from Quantum Circuits with 2D Tensor Networks", "comment": "13 pages, 9 figures", "summary": "Classical simulations of quantum circuits play a vital role in the\ndevelopment of quantum computers and for taking the temperature of the field.\nHere, we classically simulate various physically-motivated circuits using 2D\ntensor network ans\\\"atze for the many-body wavefunction which match the\ngeometry of the underlying quantum processor. We then employ a generalized\nversion of the boundary Matrix Product State contraction algorithm to\ncontrollably generate samples from the resultant tensor network states. Our\napproach allows us to systematically converge both the quality of the final\nstate and the samples drawn from it to the true distribution defined by the\ncircuit. With these methods, we simulate the largest local unitary Jastrow\nansatz circuit taken from recent IBM experiments to numerical precision. We\nalso study a domain-wall quench in a two-dimensional discrete-time Heisenberg\nmodel on large heavy-hex and rotated square lattices, which reflect IBM's and\nGoogle's latest quantum processors respectively. We observe a rapid buildup of\ncomplex loop correlations on the Google Willow geometry which significantly\nimpact the local properties of the system. Meanwhile, we find loop correlations\nbuild up extremely slowly on heavy-hex processors and have almost negligible\nimpact on the local properties of the system, even at large circuit depths. Our\nresults underscore the role the geometry of the quantum processor plays in\nclassical simulability.", "AI": {"tldr": "This paper uses tensor networks matching quantum processor geometry to classically simulate quantum circuits. It finds that lattice geometry heavily influences simulation difficulty and the behavior of physical phenomena like loop correlations, with different effects observed on IBM's and Google's processor geometries.", "motivation": "Classical simulations of quantum circuits are crucial for developing quantum computers and assessing the current state of the field. This work aims to systematically simulate physically-motivated circuits using tensor network ans\"atze that mirror the processor's geometry.", "method": "The paper uses 2D tensor network ans\"atze that match the geometry of the quantum processor to classically simulate quantum circuits. A generalized boundary Matrix Product State contraction algorithm is employed to controllably generate samples from the tensor network states, allowing for systematic convergence to the true distribution.", "result": "The study simulated large local unitary Jastrow ansatz circuits to numerical precision. It also investigated a domain-wall quench in a 2D discrete-time Heisenberg model on heavy-hex and rotated square lattices. The results show rapid buildup of complex loop correlations on the Google Willow geometry, significantly affecting local properties, while loop correlations build up slowly on heavy-hex processors with negligible impact on local properties even at large circuit depths.", "conclusion": "The geometry of the quantum processor plays a significant role in classical simulability. Different lattice geometries (heavy-hex and rotated square) exhibit varying rates of loop correlation buildup, impacting local properties and classical simulation efficiency."}}
{"id": "2507.11202", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11202", "abs": "https://arxiv.org/abs/2507.11202", "authors": ["Xinkui Zhao", "Jinsong Shu", "Yangyang Wu", "Guanjie Cheng", "Zihe Liu", "Naibo Wang", "Shuiguang Deng", "Zhongle Xie", "Jianwei Yin"], "title": "A Robust Incomplete Multimodal Low-Rank Adaptation Approach for Emotion Recognition", "comment": null, "summary": "Multimodal Emotion Recognition (MER) often encounters incomplete\nmultimodality in practical applications due to sensor failures or privacy\nprotection requirements. While existing methods attempt to address various\nincomplete multimodal scenarios by balancing the training of each modality\ncombination through additional gradients, these approaches face a critical\nlimitation: training gradients from different modality combinations conflict\nwith each other, ultimately degrading the performance of the final prediction\nmodel. In this paper, we propose a unimodal decoupled dynamic low-rank\nadaptation method based on modality combinations, named MCULoRA, which is a\nnovel framework for the parameter-efficient training of incomplete multimodal\nlearning models. MCULoRA consists of two key modules, modality combination\naware low-rank adaptation (MCLA) and dynamic parameter fine-tuning (DPFT). The\nMCLA module effectively decouples the shared information from the distinct\ncharacteristics of individual modality combinations. The DPFT module adjusts\nthe training ratio of modality combinations based on the separability of each\nmodality's representation space, optimizing the learning efficiency across\ndifferent modality combinations. Our extensive experimental evaluation in\nmultiple benchmark datasets demonstrates that MCULoRA substantially outperforms\nprevious incomplete multimodal learning approaches in downstream task accuracy.", "AI": {"tldr": "MCULoRA\u901a\u8fc7\u89e3\u8026\u548c\u52a8\u6001\u8c03\u6574\u8bad\u7ec3\u6bd4\u4f8b\u6765\u89e3\u51b3\u4e0d\u5b8c\u6574\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\u7684\u68af\u5ea6\u51b2\u7a81\u95ee\u9898\uff0c\u5e76\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u53d6\u5f97\u66f4\u597d\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u89e3\u51b3\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\uff08MER\uff09\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u56e0\u4f20\u611f\u5668\u6545\u969c\u6216\u9690\u79c1\u4fdd\u62a4\u800c\u5e38\u9047\u5230\u7684\u4e0d\u5b8c\u6574\u591a\u6a21\u6001\u95ee\u9898\uff0c\u4ee5\u53ca\u73b0\u6709\u65b9\u6cd5\u56e0\u8bad\u7ec3\u68af\u5ea6\u51b2\u7a81\u800c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u6001\u7ec4\u5408\u7684\u5355\u6a21\u6001\u89e3\u8026\u52a8\u6001\u4f4e\u79e9\u81ea\u9002\u5e94\u65b9\u6cd5\uff08MCULoRA\uff09\uff0c\u5305\u62ec\u6a21\u6001\u7ec4\u5408\u611f\u77e5\u4f4e\u79e9\u81ea\u9002\u5e94\uff08MCLA\uff09\u548c\u52a8\u6001\u53c2\u6570\u5fae\u8c03\uff08DPFT\uff09\u6a21\u5757\u3002MCLA\u89e3\u8026\u4e86\u5171\u4eab\u4fe1\u606f\u4e0e\u5404\u6a21\u6001\u7ec4\u5408\u7684\u72ec\u6709\u7279\u5f81\uff0cDPFT\u6839\u636e\u6a21\u6001\u8868\u793a\u7a7a\u95f4\u7684\u53ef\u5206\u6027\u8c03\u6574\u6a21\u6001\u7ec4\u5408\u7684\u8bad\u7ec3\u6bd4\u4f8b\u3002", "result": "MCULoRA\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc4\u4f30\u4e2d\uff0c\u5728\u4e0b\u6e38\u4efb\u52a1\u51c6\u786e\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u5148\u524d\u7684\u4e0d\u5b8c\u6574\u591a\u6a21\u6001\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "MCULoRA\u5728\u4e0b\u6e38\u4efb\u52a1\u51c6\u786e\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u5148\u524d\u7684\u4e0d\u5b8c\u6574\u591a\u6a21\u6001\u5b66\u4e60\u65b9\u6cd5\u3002"}}
{"id": "2507.11423", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.11423", "abs": "https://arxiv.org/abs/2507.11423", "authors": ["Yanjian Zhang", "Guillaume Wisniewski", "Nadi Tomeh", "Thierry Charnois"], "title": "Reasoning Strategies in Large Language Models: Can They Follow, Prefer, and Optimize?", "comment": null, "summary": "Human reasoning involves different strategies, each suited to specific\nproblems. Prior work shows that large language model (LLMs) tend to favor a\nsingle reasoning strategy, potentially limiting their effectiveness in diverse\nreasoning challenges. In this work, we investigate whether prompting can\ncontrol LLMs reasoning strategies and assess its impact on logical\nproblem-solving. While our experiments show that no single strategy\nconsistently improves accuracy, performance could be enhanced if models could\nadaptively choose the optimal strategy. We propose methods to guide LLMs in\nstrategy selection, highlighting new ways to refine their reasoning abilities.", "AI": {"tldr": "LLM\u63a8\u7406\u7b56\u7565\u7814\u7a76\uff1a\u63d0\u793a\u8bcd\u53ef\u5f15\u5bfc\u4f46\u975e\u4e07\u80fd\uff0c\u81ea\u9002\u5e94\u9009\u62e9\u662f\u5173\u952e\u3002", "motivation": "LLM\u503e\u5411\u4e8e\u5355\u4e00\u63a8\u7406\u7b56\u7565\uff0c\u53ef\u80fd\u9650\u5236\u5176\u5728\u591a\u6837\u5316\u63a8\u7406\u6311\u6218\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u63a2\u7a76\u63d0\u793a\u8bcd\u662f\u5426\u80fd\u63a7\u5236LLM\u7684\u63a8\u7406\u7b56\u7565\uff0c\u5e76\u8bc4\u4f30\u5176\u5bf9\u903b\u8f91\u89e3\u9898\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6ca1\u6709\u5355\u4e00\u7b56\u7565\u80fd\u6301\u7eed\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u4f46\u6a21\u578b\u81ea\u9002\u5e94\u9009\u62e9\u6700\u4f18\u7b56\u7565\u53ef\u4ee5\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u63d0\u793a\u53ef\u4ee5\u5f15\u5bfcLLM\u9009\u62e9\u4e0d\u540c\u7684\u63a8\u7406\u7b56\u7565\uff0c\u4f46\u6ca1\u6709\u5355\u4e00\u7b56\u7565\u80fd\u6301\u7eed\u63d0\u9ad8\u51c6\u786e\u6027\u3002\u6a21\u578b\u5e94\u80fd\u81ea\u9002\u5e94\u5730\u9009\u62e9\u6700\u4f18\u7b56\u7565\u4ee5\u63d0\u5347\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2507.10955", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10955", "abs": "https://arxiv.org/abs/2507.10955", "authors": ["Chi-en Amy Tai", "Alexander Wong"], "title": "Diffusion Decoding for Peptide De Novo Sequencing", "comment": null, "summary": "Peptide de novo sequencing is a method used to reconstruct amino acid\nsequences from tandem mass spectrometry data without relying on existing\nprotein sequence databases. Traditional deep learning approaches, such as\nCasanovo, mainly utilize autoregressive decoders and predict amino acids\nsequentially. Subsequently, they encounter cascading errors and fail to\nleverage high-confidence regions effectively. To address these issues, this\npaper investigates using diffusion decoders adapted for the discrete data\ndomain. These decoders provide a different approach, allowing sequence\ngeneration to start from any peptide segment, thereby enhancing prediction\naccuracy. We experiment with three different diffusion decoder designs,\nknapsack beam search, and various loss functions. We find knapsack beam search\ndid not improve performance metrics and simply replacing the transformer\ndecoder with a diffusion decoder lowered performance. Although peptide\nprecision and recall were still 0, the best diffusion decoder design with the\nDINOISER loss function obtained a statistically significant improvement in\namino acid recall by 0.373 compared to the baseline autoregressive\ndecoder-based Casanovo model. These findings highlight the potential of\ndiffusion decoders to not only enhance model sensitivity but also drive\nsignificant advancements in peptide de novo sequencing.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u7d22\u4e86\u4f7f\u7528\u6269\u6563\u6a21\u578b\u6539\u8fdb\u80bd\u6bb5 de novo \u6d4b\u5e8f\uff0c\u53d1\u73b0\u7279\u5b9a\u6269\u6563\u89e3\u7801\u5668\u8bbe\u8ba1\u548c DINOISER \u635f\u5931\u51fd\u6570\u80fd\u663e\u8457\u63d0\u9ad8\u6c28\u57fa\u9178\u53ec\u56de\u7387\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4f20\u7edf\u81ea\u56de\u5f52\u6a21\u578b\u5728\u80bd\u6bb5 de novo \u6d4b\u5e8f\u4e2d\u5b58\u5728\u7684\u7ea7\u8054\u9519\u8bef\u548c\u65e0\u6cd5\u6709\u6548\u5229\u7528\u9ad8\u53ef\u4fe1\u5ea6\u533a\u57df\u7684\u95ee\u9898\uff0c\u672c\u7814\u7a76\u5c1d\u8bd5\u4f7f\u7528\u6269\u6563\u6a21\u578b\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u6269\u6563\u6a21\u578b\u8fdb\u884c\u80bd\u6bb5 de novo \u6d4b\u5e8f\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e09\u79cd\u4e0d\u540c\u7684\u6269\u6563\u89e3\u7801\u5668\uff0c\u540c\u65f6\u63a2\u7d22\u4e86 knapsack beam search \u548c\u591a\u79cd\u635f\u5931\u51fd\u6570\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u867d\u7136 knapsack beam search \u672a\u80fd\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u6700\u4f73\u7684\u6269\u6563\u89e3\u7801\u5668\u8bbe\u8ba1\u7ed3\u5408 DINOISER \u635f\u5931\u51fd\u6570\uff0c\u5728\u6c28\u57fa\u9178\u53ec\u56de\u7387\u65b9\u9762\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b Casanovo \u63d0\u9ad8\u4e86 0.373\uff0c\u5c3d\u7ba1\u80bd\u6bb5\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387\u4ecd\u4e3a 0\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u6269\u6563\u6a21\u578b\u6709\u6f5c\u529b\u63d0\u9ad8\u80bd\u6bb5 de novo \u6d4b\u5e8f\u7684\u51c6\u786e\u6027\uff0c\u5c24\u5176\u662f\u5728\u63d0\u9ad8\u6a21\u578b\u654f\u611f\u6027\u65b9\u9762\u3002"}}
{"id": "2507.11458", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.11458", "abs": "https://arxiv.org/abs/2507.11458", "authors": ["Sameer Sharma"], "title": "Entanglement Classification in the Graph States: The generalization to $n$-Qubits States using the Entanglement Matrix", "comment": null, "summary": "Graph states represent a significant class of multi-partite entangled quantum\nstates with applications in quantum error correction, quantum communication,\nand quantum computation. In this work, we introduce a novel formalism called\nthe Entanglement Matrix for quantifying and classifying entanglement in n-qubit\ngraph states. Leveraging concepts from graph theory and quantum information, we\ndevelop a systematic approach to analyze entanglement by identifying primary\nand secondary midpoints in graph representations, where midpoints correspond to\ncontrolled-Z gate operations between qubits. Using Von Neumann entropy as our\nmeasure, we derive precise mathematical relationships for maximum entanglement\nin graph states as a function of qubit number. Our analysis reveals that\nentanglement follows a quadratic relationship with the number of qubits, but\nwith distinct behaviors for odd versus even qubit systems. For odd n-qubit\ngraph states, maximum entanglement follows $E_{\\max} = n^2 - n$, while even\nn-qubit states exhibit higher entanglement with varying formulae depending on\nspecific configurations. Notably, systems with qubit counts that are multiples\nof 12 demonstrate enhanced entanglement properties. This comprehensive\nclassification framework provides valuable insights into the structure of\nmulti-qubit entanglement, establishing an analytical foundation for\nunderstanding entanglement distribution in complex quantum systems that may\ninform future quantum technologies.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u71b5\u7ea0\u7f20\u77e9\u9635\u6765\u91cf\u5316\u56fe\u6001\u7ea0\u7f20\uff0c\u53d1\u73b0\u6700\u5927\u7ea0\u7f20\u5ea6\u4e0e\u91cf\u5b50\u6bd4\u7279\u6570\u5448\u4e8c\u6b21\u65b9\u5173\u7cfb\uff0c\u5947\u5076\u7cfb\u7edf\u884c\u4e3a\u4e0d\u540c\uff0c12\u7684\u500d\u6570\u7cfb\u7edf\u7ea0\u7f20\u5ea6\u66f4\u5f3a\u3002", "motivation": "\u56fe\u6001\u4f5c\u4e3a\u4e00\u7c7b\u91cd\u8981\u7684\u591a\u7c92\u5b50\u91cf\u5b50\u7ea0\u7f20\u6001\uff0c\u5728\u91cf\u5b50\u8bef\u5dee\u6821\u6b63\u3001\u91cf\u5b50\u901a\u4fe1\u548c\u91cf\u5b50\u8ba1\u7b97\u7b49\u9886\u57df\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u3002\u7136\u800c\uff0c\u6709\u6548\u91cf\u5316\u548c\u5206\u7c7b\u8fd9\u4e9b\u590d\u6742\u72b6\u6001\u4e2d\u7684\u7ea0\u7f20\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\u3002\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u6df1\u5165\u7406\u89e3\u548c\u91cf\u5316\u56fe\u6001\u7684\u7ea0\u7f20\u7279\u6027\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u71b5\u7ea0\u7f20\u77e9\u9635\uff08Entanglement Matrix\uff09\u4f5c\u4e3a\u65b0\u9896\u7684\u5206\u6790\u5de5\u5177\uff0c\u7ed3\u5408\u56fe\u8bba\u548c\u91cf\u5b50\u4fe1\u606f\u6982\u5ff5\uff0c\u7cfb\u7edf\u5730\u91cf\u5316\u548c\u5206\u7c7b\u4e86n\u91cf\u5b50\u6bd4\u7279\u56fe\u6001\u4e2d\u7684\u7ea0\u7f20\u3002\u901a\u8fc7\u8bc6\u522b\u56fe\u8868\u793a\u4e2d\u7684\u4e3b\u8981\u548c\u6b21\u8981\u4e2d\u70b9\uff08\u5bf9\u5e94\u4e8e\u91cf\u5b50\u6bd4\u7279\u95f4\u7684\u53d7\u63a7-Z\u95e8\u64cd\u4f5c\uff09\uff0c\u5e76\u5229\u7528\u51af\u8bfa\u4f9d\u66fc\u71b5\u4f5c\u4e3a\u5ea6\u91cf\u6807\u51c6\uff0c\u63a8\u5bfc\u4e86\u6700\u5927\u7ea0\u7f20\u5ea6\u4e0e\u91cf\u5b50\u6bd4\u7279\u6570\u91cf\u4e4b\u95f4\u7684\u7cbe\u786e\u6570\u5b66\u5173\u7cfb\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u56fe\u6001\u4e2d\u7684\u6700\u5927\u7ea0\u7f20\u5ea6\u4e0e\u91cf\u5b50\u6bd4\u7279\u6570\u91cf\u4e4b\u95f4\u5b58\u5728\u4e8c\u6b21\u65b9\u5173\u7cfb\uff0c\u4f46\u5947\u6570\u548c\u5076\u6570\u7cfb\u7edf\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u884c\u4e3a\u6a21\u5f0f\u3002\u5bf9\u4e8e\u5947\u6570n\u91cf\u5b50\u6bd4\u7279\u56fe\u6001\uff0c\u6700\u5927\u7ea0\u7f20\u5ea6\u4e3a $E_{\\max} = n^2 - n$\uff1b\u800c\u5076\u6570\u7cfb\u7edf\u5219\u5c55\u73b0\u51fa\u66f4\u9ad8\u7684\u7ea0\u7f20\u5ea6\uff0c\u4e14\u5176\u5177\u4f53\u516c\u5f0f\u53d6\u51b3\u4e8e\u7279\u5b9a\u7684\u7ed3\u6784\u914d\u7f6e\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5f53\u91cf\u5b50\u6bd4\u7279\u6570\u91cf\u4e3a12\u7684\u500d\u6570\u65f6\uff0c\u7cfb\u7edf\u8868\u73b0\u51fa\u589e\u5f3a\u7684\u7ea0\u7f20\u7279\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u71b5\u7ea0\u7f20\u77e9\u9635\u4e3a\u91cf\u5316\u548c\u5206\u7c7bn\u91cf\u5b50\u6bd4\u7279\u56fe\u6001\u4e2d\u7684\u7ea0\u7f20\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u9896\u4e14\u7cfb\u7edf\u7684\u6846\u67b6\u3002\u901a\u8fc7\u5c06\u56fe\u8bba\u6982\u5ff5\u4e0e\u91cf\u5b50\u4fe1\u606f\u7406\u8bba\u76f8\u7ed3\u5408\uff0c\u6211\u4eec\u53d1\u73b0\u4e86\u91cf\u5b50\u6bd4\u7279\u6570\u91cf\u4e0e\u6700\u5927\u7ea0\u7f20\u5ea6\u4e4b\u95f4\u7684\u7cbe\u786e\u6570\u5b66\u5173\u7cfb\uff0c\u5e76\u63ed\u793a\u4e86\u5947\u5076\u7cfb\u7edf\u5728\u7ea0\u7f20\u7279\u6027\u4e0a\u7684\u5dee\u5f02\u3002\u7279\u522b\u662f\uff0c12\u7684\u500d\u6570\u7cfb\u7edf\u8868\u73b0\u51fa\u589e\u5f3a\u7684\u7ea0\u7f20\u7279\u6027\u3002\u8be5\u6846\u67b6\u4e3a\u7406\u89e3\u590d\u6742\u91cf\u5b50\u7cfb\u7edf\u4e2d\u7684\u7ea0\u7f20\u5206\u5e03\u5960\u5b9a\u4e86\u5206\u6790\u57fa\u7840\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u91cf\u5b50\u6280\u672f\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2507.11245", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11245", "abs": "https://arxiv.org/abs/2507.11245", "authors": ["X. Feng", "H. Yu", "M. Wu", "S. Hu", "J. Chen", "C. Zhu", "J. Wu", "X. Chu", "K. Huang"], "title": "NarrLV: Towards a Comprehensive Narrative-Centric Evaluation for Long Video Generation Models", "comment": "Project Page: https://amap-ml.github.io/NarrLV-Website/", "summary": "With the rapid development of foundation video generation technologies, long\nvideo generation models have exhibited promising research potential thanks to\nexpanded content creation space. Recent studies reveal that the goal of long\nvideo generation tasks is not only to extend video duration but also to\naccurately express richer narrative content within longer videos. However, due\nto the lack of evaluation benchmarks specifically designed for long video\ngeneration models, the current assessment of these models primarily relies on\nbenchmarks with simple narrative prompts (e.g., VBench). To the best of our\nknowledge, our proposed NarrLV is the first benchmark to comprehensively\nevaluate the Narrative expression capabilities of Long Video generation models.\nInspired by film narrative theory, (i) we first introduce the basic narrative\nunit maintaining continuous visual presentation in videos as Temporal Narrative\nAtom (TNA), and use its count to quantitatively measure narrative richness.\nGuided by three key film narrative elements influencing TNA changes, we\nconstruct an automatic prompt generation pipeline capable of producing\nevaluation prompts with a flexibly expandable number of TNAs. (ii) Then, based\non the three progressive levels of narrative content expression, we design an\neffective evaluation metric using the MLLM-based question generation and\nanswering framework. (iii) Finally, we conduct extensive evaluations on\nexisting long video generation models and the foundation generation models.\nExperimental results demonstrate that our metric aligns closely with human\njudgments. The derived evaluation outcomes reveal the detailed capability\nboundaries of current video generation models in narrative content expression.", "AI": {"tldr": "\u63d0\u51faNarrLV\u57fa\u51c6\u548c\u57fa\u4e8eMLLM\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u7528\u4e8e\u8bc4\u4f30\u957f\u89c6\u9891\u751f\u6210\u6a21\u578b\u7684\u53d9\u4e8b\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u957f\u89c6\u9891\u751f\u6210\u6a21\u578b\u7f3a\u4e4f\u4e13\u95e8\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u5f53\u524d\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u4ec5\u5305\u542b\u7b80\u5355\u53d9\u4e8b\u63d0\u793a\u7684\u57fa\u51c6\uff08\u5982VBench\uff09\uff0c\u65e0\u6cd5\u6ee1\u8db3\u957f\u89c6\u9891\u6a21\u578b\u4e0d\u4ec5\u8981\u6269\u5c55\u89c6\u9891\u65f6\u957f\uff0c\u8fd8\u8981\u51c6\u786e\u8868\u8fbe\u66f4\u4e30\u5bcc\u53d9\u4e8b\u5185\u5bb9\u7684\u9700\u6c42\u3002", "method": "(i) \u63d0\u51fa\u65f6\u95f4\u53d9\u4e8b\u539f\u5b50\uff08TNA\uff09\u4f5c\u4e3a\u8861\u91cf\u53d9\u4e8b\u4e30\u5bcc\u5ea6\u7684\u57fa\u672c\u5355\u4f4d\uff0c\u5e76\u6784\u5efa\u4e86\u81ea\u52a8\u63d0\u793a\u751f\u6210\u7ba1\u7ebf\u4ee5\u751f\u6210\u5305\u542b\u53ef\u53d8\u6570\u91cfTNA\u7684\u8bc4\u4f30\u63d0\u793a\u3002(ii) \u57fa\u4e8e\u53d9\u4e8b\u5185\u5bb9\u7684\u4e09\u4e2a\u6e10\u8fdb\u7ea7\u522b\uff0c\u8bbe\u8ba1\u4e86\u4f7f\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\u8fdb\u884c\u95ee\u7b54\u7684\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u8bc4\u4f30\u6307\u6807\u4e0e\u4eba\u7c7b\u5224\u65ad\u9ad8\u5ea6\u76f8\u5173\uff0c\u5e76\u4e14\u63ed\u793a\u4e86\u5f53\u524d\u957f\u89c6\u9891\u751f\u6210\u6a21\u578b\u5728\u53d9\u4e8b\u5185\u5bb9\u8868\u8fbe\u65b9\u9762\u7684\u5177\u4f53\u80fd\u529b\u8fb9\u754c\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86NarrLV\uff0c\u4e00\u4e2a\u65e8\u5728\u5168\u9762\u8bc4\u4f30\u957f\u89c6\u9891\u751f\u6210\u6a21\u578b\u53d9\u4e8b\u8868\u8fbe\u80fd\u529b\u7684\u57fa\u51c6\uff0c\u5e76\u8bbe\u8ba1\u4e86\u76f8\u5e94\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u8be5\u6307\u6807\u4e0e\u4eba\u7c7b\u5224\u65ad\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5e76\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u53d9\u4e8b\u5185\u5bb9\u8868\u8fbe\u65b9\u9762\u7684\u80fd\u529b\u8fb9\u754c\u3002"}}
{"id": "2507.11502", "categories": ["cs.CL", "cs.CE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11502", "abs": "https://arxiv.org/abs/2507.11502", "authors": ["Sirui Han", "Junqi Zhu", "Ruiyuan Zhang", "Yike Guo"], "title": "HKGAI-V1: Towards Regional Sovereign Large Language Model for Hong Kong", "comment": null, "summary": "This paper presents the development of HKGAI-V1, a foundational sovereign\nlarge language model (LLM), developed as part of an initiative to establish\nvalue-aligned AI infrastructure specifically tailored for Hong Kong. Addressing\nthe region's unique multilingual environment (Cantonese, Mandarin, and\nEnglish), its distinct socio-legal context under the \"one country, two systems\"\nframework, and specific local cultural and value considerations, the model is\nbuilt upon the DeepSeek architecture and systematically aligned with regional\nnorms through a multifaceted full parameter fine-tuning process. It is further\nintegrated with a retrieval-augmented generation (RAG) system to ensure timely\nand factually grounded information access. The core contribution lies in the\ndesign and implementation of a comprehensive, region-specific AI alignment and\nsafety framework, demonstrated through two key achievements: 1) The successful\ndevelopment of HKGAI-V1 itself - which outper-forms general-purpose models in\nhandling Hong Kong-specific culturally sensitive queries, and embodies a\n\"governance-embedded\" approach to digital sovereignty - empowers Hong Kong to\nexercise control over AI applications in critical sectors including public\nservices, legal systems, and edu-cation. 2) The development of the proprietary\nAdversarial HK Value Benchmark, a rigorous tool for evaluating model alignment\nwith local ethical and legal stand-ards under challenging conditions. By\ndocumenting these achievements, the paper provides not only a technological\nartifact but also a replicable blueprint for developing advanced, regionally\nfocused AI systems deeply rooted in their local identities.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.10983", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10983", "abs": "https://arxiv.org/abs/2507.10983", "authors": ["Tao Han", "Zahra Taheri", "Hyunwoong Ko"], "title": "Physics-Informed Neural Networks For Semiconductor Film Deposition: A Review", "comment": "11 pages, 1 figure, 3 tables, IDETC-CIE 2025", "summary": "Semiconductor manufacturing relies heavily on film deposition processes, such\nas Chemical Vapor Deposition and Physical Vapor Deposition. These complex\nprocesses require precise control to achieve film uniformity, proper adhesion,\nand desired functionality. Recent advancements in Physics-Informed Neural\nNetworks (PINNs), an innovative machine learning (ML) approach, have shown\nsignificant promise in addressing challenges related to process control,\nquality assurance, and predictive modeling within semiconductor film deposition\nand other manufacturing domains. This paper provides a comprehensive review of\nML applications targeted at semiconductor film deposition processes. Through a\nthematic analysis, we identify key trends, existing limitations, and research\ngaps, offering insights into both the advantages and constraints of current\nmethodologies. Our structured analysis aims to highlight the potential\nintegration of these ML techniques to enhance interpretability, accuracy, and\nrobustness in film deposition processes. Additionally, we examine\nstate-of-the-art PINN methods, discussing strategies for embedding physical\nknowledge, governing laws, and partial differential equations into advanced\nneural network architectures tailored for semiconductor manufacturing. Based on\nthis detailed review, we propose novel research directions that integrate the\nstrengths of PINNs to significantly advance film deposition processes. The\ncontributions of this study include establishing a clear pathway for future\nresearch in integrating physics-informed ML frameworks, addressing existing\nmethodological gaps, and ultimately improving precision, scalability, and\noperational efficiency within semiconductor manufacturing.", "AI": {"tldr": "\u672c\u6587\u56de\u987e\u4e86\u673a\u5668\u5b66\u4e60\uff08\u7279\u522b\u662f\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edcPINNs\uff09\u5728\u534a\u5bfc\u4f53\u8584\u819c\u6c89\u79ef\u4e2d\u7684\u5e94\u7528\uff0c\u6307\u51fa\u4e86\u73b0\u6709\u6280\u672f\u7684\u4f18\u7f3a\u70b9\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u8fd9\u4e9b\u8fc7\u7a0b\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u534a\u5bfc\u4f53\u8584\u819c\u6c89\u79ef\u8fc7\u7a0b\u5bf9\u5b9e\u73b0\u8584\u819c\u5747\u5300\u6027\u3001\u9002\u5f53\u9644\u7740\u529b\u548c\u6240\u9700\u529f\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u590d\u6742\u6027\u5bf9\u8fc7\u7a0b\u63a7\u5236\u63d0\u51fa\u4e86\u6311\u6218\u3002\u673a\u5668\u5b66\u4e60\uff08ML\uff09\uff0c\u7279\u522b\u662f\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINNs\uff09\uff0c\u5728\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u65b9\u9762\u663e\u793a\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u5bf9\u5176\u5728\u534a\u5bfc\u4f53\u8584\u819c\u6c89\u79ef\u4e2d\u7684\u5e94\u7528\u8fdb\u884c\u5168\u9762\u56de\u987e\u548c\u5206\u6790\u3002", "method": "\u672c\u6587\u91c7\u7528\u4e3b\u9898\u5206\u6790\u65b9\u6cd5\uff0c\u5168\u9762\u56de\u987e\u4e86\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u5728\u534a\u5bfc\u4f53\u8584\u819c\u6c89\u79ef\u8fc7\u7a0b\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u662f\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINNs\uff09\u3002\u5206\u6790\u4e86\u5f53\u524d\u65b9\u6cd5\u7684\u4f18\u70b9\u548c\u5c40\u9650\u6027\uff0c\u5e76\u63a2\u8ba8\u4e86\u5c06\u7269\u7406\u77e5\u8bc6\u3001\u63a7\u5236\u5b9a\u5f8b\u548c\u504f\u5fae\u5206\u65b9\u7a0b\u5d4c\u5165\u5230\u9488\u5bf9\u534a\u5bfc\u4f53\u5236\u9020\u4e1a\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u4e2d\u7684\u7b56\u7565\u3002", "result": "\u672c\u6587\u5bf9\u673a\u5668\u5b66\u4e60\u5728\u534a\u5bfc\u4f53\u8584\u819c\u6c89\u79ef\u4e2d\u7684\u5e94\u7528\u8fdb\u884c\u4e86\u5168\u9762\u56de\u987e\uff0c\u8bc6\u522b\u4e86\u5173\u952e\u8d8b\u52bf\u3001\u5c40\u9650\u6027\u548c\u7814\u7a76\u7a7a\u767d\u3002\u8ba8\u8bba\u4e86PINNs\u7684\u5e94\u7528\uff0c\u5e76\u63d0\u51fa\u4e86\u6574\u5408PINNs\u4ee5\u63d0\u9ad8\u8fc7\u7a0b\u6027\u80fd\u548c\u8fd0\u8425\u6548\u7387\u7684\u65b0\u7814\u7a76\u65b9\u5411\uff0c\u4e3a\u8be5\u9886\u57df\u672a\u6765\u7684\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u672c\u6587\u5168\u9762\u56de\u987e\u4e86\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u5728\u534a\u5bfc\u4f53\u8584\u819c\u6c89\u79ef\u8fc7\u7a0b\u4e2d\u7684\u5e94\u7528\uff0c\u91cd\u70b9\u5173\u6ce8\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINNs\uff09\u3002\u901a\u8fc7\u4e3b\u9898\u5206\u6790\uff0c\u8bc6\u522b\u4e86\u5173\u952e\u8d8b\u52bf\u3001\u73b0\u6709\u5c40\u9650\u6027\u548c\u7814\u7a76\u7a7a\u767d\uff0c\u5e76\u63d0\u51fa\u4e86\u6574\u5408PINNs\u4ee5\u63d0\u9ad8\u8584\u819c\u6c89\u79ef\u8fc7\u7a0b\u7684\u89e3\u91ca\u6027\u3001\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u7684\u7b56\u7565\u3002\u6700\u540e\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u5c06PINNs\u7684\u4f18\u52bf\u76f8\u7ed3\u5408\u4ee5\u663e\u8457\u63a8\u8fdb\u8584\u819c\u6c89\u79ef\u8fc7\u7a0b\u7684\u65b0\u7814\u7a76\u65b9\u5411\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u5728\u6574\u5408\u7269\u7406\u4fe1\u606fML\u6846\u67b6\u3001\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u8bba\u5dee\u8ddd\u4ee5\u53ca\u63d0\u9ad8\u534a\u5bfc\u4f53\u5236\u9020\u4e1a\u7684\u7cbe\u5ea6\u3001\u53ef\u6269\u5c55\u6027\u548c\u8fd0\u8425\u6548\u7387\u65b9\u9762\u5efa\u7acb\u4e86\u6e05\u6670\u7684\u8def\u5f84\u3002"}}
{"id": "2507.11481", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.11481", "abs": "https://arxiv.org/abs/2507.11481", "authors": ["Zikang Jia", "Shravan Veerapaneni", "Gokul Subramanian Ravi"], "title": "Enhancing the Clique Local Decoder to Correct Length-2 Space Errors in the Surface Code", "comment": "Accepted to IEEE Quantum Week (QCE) 2025. Copyright \\c{opyright} 2025\n  IEEE", "summary": "The growing demand for fault-tolerant quantum computing drives the need for\nefficient, scalable Quantum Error Correction (QEC) strategies. Conventional\ndecoders designed for worst-case error scenarios incur significant overhead,\nprompting the development of local decoders, that leverage the sparse and often\ntrivial nature of many quantum errors, to support the conventional decoders.\nThe previously proposed Clique decoder addresses this by handling isolated,\nlength-1 space and time errors within the cryogenic environment with minimal\nhardware costs, thereby mitigating I/O bandwidth constraints between cryogenic\nquantum systems and room-temperature processors. Building on this foundation,\nwe propose Clique_L2 that extends the Clique-based approach by relaxing some\noriginal constraints and incorporating additional low-cost logic to also\ncorrect length-2 error chains in space, which become non-trivial occurrences at\nhigher physical error rates and code distances. This enhanced capability not\nonly further reduces out-of-the-fridge data transmission but also adapts more\neffectively to clustered errors observed under a variety of noise models.\nSpecifically, under data-qubit-only errors and uniformly random noise,\nClique_L2 achieves up to 8.95x decoding bandwidth reduction over the original\nClique (or Clique_L1) decoder, especially beneficial at higher code distances.\nWhen clustered errors and longer error chains are more likely to occur,\nClique_L2 achieves up to 18.3x decoding bandwidth reduction over Clique_L1,\nachieving substantial benefits across a wide range of physical qubit error\nrates.", "AI": {"tldr": "Clique_L2 \u662f\u4e00\u79cd\u65b0\u7684\u91cf\u5b50\u7ea0\u9519\u89e3\u7801\u5668\uff0c\u5b83\u901a\u8fc7\u5904\u7406\u66f4\u957f\u7684\u9519\u8bef\u94fe\u6765\u63d0\u9ad8\u6548\u7387\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u6570\u636e\u4f20\u8f93\u91cf\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u7c07\u72b6\u9519\u8bef\u65f6\u3002", "motivation": "\u4e3a\u4e86\u6ee1\u8db3\u5bb9\u9519\u91cf\u5b50\u8ba1\u7b97\u5bf9\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u91cf\u5b50\u7ea0\u9519\uff08QEC\uff09\u7b56\u7565\u65e5\u76ca\u589e\u957f\u7684\u9700\u6c42\uff0c\u5e76\u89e3\u51b3\u4f20\u7edf\u89e3\u7801\u5668\u5728\u6700\u574f\u60c5\u51b5\u4e0b\u7684\u9ad8\u5f00\u9500\u95ee\u9898\uff0c\u5f00\u53d1\u4e86\u5229\u7528\u91cf\u5b50\u9519\u8bef\u7a00\u758f\u6027\u4ee5\u53ca\u8bb8\u591a\u91cf\u5b50\u9519\u8bef\u5177\u6709\u5e73\u51e1\u6027\u8d28\u7684\u5c40\u90e8\u89e3\u7801\u5668\uff0c\u4ee5\u8f85\u52a9\u4f20\u7edf\u89e3\u7801\u5668\u3002", "method": "\u63d0\u51fa Clique_L2 \u89e3\u7801\u5668\uff0c\u8be5\u89e3\u7801\u5668\u5728 Clique \u89e3\u7801\u5668\u7684\u57fa\u7840\u4e0a\u8fdb\u884c\u4e86\u6269\u5c55\uff0c\u653e\u5bbd\u4e86\u90e8\u5206\u539f\u59cb\u7ea6\u675f\uff0c\u5e76\u589e\u52a0\u4e86\u4f4e\u6210\u672c\u903b\u8f91\u4ee5\u7ea0\u6b63\u7a7a\u95f4\u4e2d\u7684\u957f\u5ea6\u4e3a 2 \u7684\u9519\u8bef\u94fe\u3002", "result": "Clique_L2 \u5728\u6570\u636e\u91cf\u5b50\u6bd4\u7279\u9519\u8bef\u548c\u5747\u5300\u968f\u673a\u566a\u58f0\u4e0b\uff0c\u4e0e Clique_L1 \u89e3\u7801\u5668\u76f8\u6bd4\uff0c\u89e3\u7801\u5e26\u5bbd\u51cf\u5c11\u9ad8\u8fbe 8.95 \u500d\uff0c\u5728\u9ad8\u7801\u8ddd\u4e0b\u5c24\u5176\u6709\u5229\u3002\u5728\u7c07\u72b6\u9519\u8bef\u548c\u8f83\u957f\u9519\u8bef\u94fe\u66f4\u53ef\u80fd\u53d1\u751f\u7684\u60c5\u51b5\u4e0b\uff0cClique_L2 \u4e0e Clique_L1 \u89e3\u7801\u5668\u76f8\u6bd4\uff0c\u89e3\u7801\u5e26\u5bbd\u51cf\u5c11\u9ad8\u8fbe 18.3 \u500d\uff0c\u5728\u5e7f\u6cdb\u7684\u7269\u7406\u91cf\u5b50\u6bd4\u7279\u9519\u8bef\u7387\u4e0b\u5747\u80fd\u5b9e\u73b0\u663e\u8457\u6548\u76ca\u3002", "conclusion": "Clique_L2 \u6269\u5c55\u4e86 Clique \u89e3\u7801\u5668\uff0c\u901a\u8fc7\u589e\u52a0\u5904\u7406\u957f\u5ea6\u4e3a 2 \u7684\u7a7a\u95f4\u9519\u8bef\u94fe\u7684\u80fd\u529b\uff0c\u5728\u5904\u7406\u7279\u5b9a\u9519\u8bef\u6a21\u578b\uff08\u5982\u6570\u636e\u91cf\u5b50\u6bd4\u7279\u9519\u8bef\u548c\u5747\u5300\u968f\u673a\u566a\u58f0\uff09\u4ee5\u53ca\u7c07\u72b6\u9519\u8bef\u65f6\uff0c\u4e0e Clique_L1 \u89e3\u7801\u5668\u76f8\u6bd4\uff0c\u89e3\u7801\u5e26\u5bbd\u51cf\u5c11\u9ad8\u8fbe 18.3 \u500d\u3002"}}
{"id": "2507.11247", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11247", "abs": "https://arxiv.org/abs/2507.11247", "authors": ["Veronika Shilova", "Emmanuel Malherbe", "Giovanni Palma", "Laurent Risser", "Jean-Michel Loubes"], "title": "Fairness-Aware Grouping for Continuous Sensitive Variables: Application for Debiasing Face Analysis with respect to Skin Tone", "comment": null, "summary": "Within a legal framework, fairness in datasets and models is typically\nassessed by dividing observations into predefined groups and then computing\nfairness measures (e.g., Disparate Impact or Equality of Odds with respect to\ngender). However, when sensitive attributes such as skin color are continuous,\ndividing into default groups may overlook or obscure the discrimination\nexperienced by certain minority subpopulations. To address this limitation, we\npropose a fairness-based grouping approach for continuous (possibly\nmultidimensional) sensitive attributes. By grouping data according to observed\nlevels of discrimination, our method identifies the partition that maximizes a\nnovel criterion based on inter-group variance in discrimination, thereby\nisolating the most critical subgroups.\n  We validate the proposed approach using multiple synthetic datasets and\ndemonstrate its robustness under changing population distributions - revealing\nhow discrimination is manifested within the space of sensitive attributes.\nFurthermore, we examine a specialized setting of monotonic fairness for the\ncase of skin color. Our empirical results on both CelebA and FFHQ, leveraging\nthe skin tone as predicted by an industrial proprietary algorithm, show that\nthe proposed segmentation uncovers more nuanced patterns of discrimination than\npreviously reported, and that these findings remain stable across datasets for\na given model. Finally, we leverage our grouping model for debiasing purpose,\naiming at predicting fair scores with group-by-group post-processing. The\nresults demonstrate that our approach improves fairness while having minimal\nimpact on accuracy, thus confirming our partition method and opening the door\nfor industrial deployment.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u516c\u5e73\u6027\u7684\u5206\u7ec4\u65b9\u6cd5\uff0c\u7528\u4e8e\u5904\u7406\u8fde\u7eed\u654f\u611f\u5c5e\u6027\uff0c\u901a\u8fc7\u8bc6\u522b\u6b67\u89c6\u6700\u4e25\u91cd\u7684\u5b50\u7fa4\u4f53\u6765\u63d0\u9ad8\u516c\u5e73\u6027\uff0c\u5e76\u53ef\u7528\u4e8e\u6d88\u504f\u3002", "motivation": "\u73b0\u6709\u7684\u516c\u5e73\u6027\u8bc4\u4f30\u65b9\u6cd5\u5728\u5904\u7406\u8fde\u7eed\u654f\u611f\u5c5e\u6027\uff08\u5982\u80a4\u8272\uff09\u65f6\uff0c\u7531\u4e8e\u9884\u8bbe\u5206\u7ec4\u53ef\u80fd\u5ffd\u7565\u67d0\u4e9b\u5c11\u6570\u65cf\u88d4\u5b50\u7fa4\u4f53\u7684\u6b67\u89c6\uff0c\u56e0\u6b64\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u5206\u7ec4\u65b9\u6cd5\u6765\u89e3\u51b3\u6b64\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u516c\u5e73\u6027\u7684\u5206\u7ec4\u65b9\u6cd5\uff0c\u901a\u8fc7\u6839\u636e\u89c2\u5bdf\u5230\u7684\u6b67\u89c6\u6c34\u5e73\u5bf9\u6570\u636e\u8fdb\u884c\u5206\u7ec4\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u6b67\u89c6\u7684\u7ec4\u95f4\u65b9\u5dee\u7684\u65b0\u6807\u51c6\u6765\u8bc6\u522b\u6700\u5173\u952e\u7684\u5b50\u7fa4\u4f53\u3002", "result": "\u63d0\u51fa\u7684\u5206\u7ec4\u65b9\u6cd5\u80fd\u591f\u63ed\u793a\u6bd4\u4ee5\u5f80\u66f4\u7ec6\u81f4\u7684\u6b67\u89c6\u6a21\u5f0f\uff0c\u5e76\u4e14\u8fd9\u4e9b\u53d1\u73b0\u5bf9\u4e8e\u7ed9\u5b9a\u6a21\u578b\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u4fdd\u6301\u7a33\u5b9a\u3002\u6d88\u504f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u51e0\u4e4e\u4e0d\u5f71\u54cd\u51c6\u786e\u6027\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u4e86\u516c\u5e73\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u8bc6\u522b\u6700\u5173\u952e\u7684\u5b50\u7fa4\u4f53\u6765\u89e3\u51b3\u8fde\u7eed\u654f\u611f\u5c5e\u6027\u7684\u516c\u5e73\u6027\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u4e8b\u540e\u5904\u7406\u8fdb\u884c\u6d88\u504f\uff0c\u5728\u51e0\u4e4e\u4e0d\u5f71\u54cd\u51c6\u786e\u6027\u7684\u524d\u63d0\u4e0b\u63d0\u9ad8\u4e86\u516c\u5e73\u6027\uff0c\u9002\u7528\u4e8e\u5de5\u4e1a\u90e8\u7f72\u3002"}}
{"id": "2507.11508", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.11508", "abs": "https://arxiv.org/abs/2507.11508", "authors": ["Patr\u00edcia Schmidtov\u00e1", "Ond\u0159ej Du\u0161ek", "Saad Mahamood"], "title": "Real-World Summarization: When Evaluation Reaches Its Limits", "comment": null, "summary": "We examine evaluation of faithfulness to input data in the context of hotel\nhighlights: brief LLM-generated summaries that capture unique features of\naccommodations. Through human evaluation campaigns involving categorical error\nassessment and span-level annotation, we compare traditional metrics, trainable\nmethods, and LLM-as-a-judge approaches. Our findings reveal that simpler\nmetrics like word overlap correlate surprisingly well with human judgments\n(Spearman correlation rank of 0.63), often outperforming more complex methods\nwhen applied to out-of-domain data. We further demonstrate that while LLMs can\ngenerate high-quality highlights, they prove unreliable for evaluation as they\ntend to severely under- or over-annotate. Our analysis of real-world business\nimpacts shows incorrect and non-checkable information pose the greatest risks.\nWe also highlight challenges in crowdsourced evaluations.", "AI": {"tldr": "LLM\u5728\u9152\u5e97\u6458\u8981\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u8bc4\u4f30\u4e0d\u53ef\u9760\u3002\u7b80\u5355\u7684\u6307\u6807\uff08\u5982\u8bcd\u91cd\u53e0\uff09\u5728\u8bc4\u4f30\u6458\u8981\u5fe0\u5b9e\u5ea6\u65b9\u9762\u6548\u679c\u4e0d\u9519\u3002\u9519\u8bef\u4fe1\u606f\u98ce\u9669\u6700\u9ad8\u3002\u4f17\u5305\u8bc4\u4f30\u5b58\u5728\u6311\u6218\u3002", "motivation": "\u65e8\u5728\u7814\u7a76\u9152\u5e97\u6458\u8981\uff08LLM\u751f\u6210\u7684\u7b80\u77ed\u6458\u8981\uff0c\u6355\u6349\u4f4f\u5bbf\u7684\u72ec\u7279\u529f\u80fd\uff09\u5728\u5fe0\u5b9e\u4e8e\u8f93\u5165\u6570\u636e\u65b9\u9762\u7684\u8bc4\u4f30\u3002", "method": "\u901a\u8fc7\u6d89\u53ca\u5206\u7c7b\u9519\u8bef\u8bc4\u4f30\u548c\u8de8\u5ea6\u7ea7\u522b\u6ce8\u91ca\u7684\u4eba\u7c7b\u8bc4\u4f30\u6d3b\u52a8\uff0c\u6bd4\u8f83\u4e86\u4f20\u7edf\u7684\u3001\u53ef\u8bad\u7ec3\u7684\u548cLLM\u4f5c\u4e3a\u8bc4\u5224\u7684\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u50cf\u8bcd\u91cd\u53e0\u8fd9\u6837\u7684\u7b80\u5355\u6307\u6807\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u76f8\u5173\u6027\u51fa\u5947\u5730\u597d\uff08Spearman\u76f8\u5173\u7b49\u7ea7\u4e3a0.63\uff09\uff0c\u5e76\u4e14\u5728\u5e94\u7528\u4e8e\u975e\u9886\u57df\u6570\u636e\u65f6\uff0c\u901a\u5e38\u4f18\u4e8e\u66f4\u590d\u6742\u7684\u65b9\u6cd5\u3002LLM\u867d\u7136\u80fd\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u6458\u8981\uff0c\u4f46\u4f5c\u4e3a\u8bc4\u4f30\u8005\u65f6\u5e76\u4e0d\u53ef\u9760\u3002", "conclusion": "LLM\u5728\u9152\u5e97\u6458\u8981\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u4f5c\u4e3a\u8bc4\u4f30\u8005\u65f6\u4e0d\u53ef\u9760\uff0c\u5bb9\u6613\u51fa\u73b0\u6807\u6ce8\u4e0d\u8db3\u6216\u8fc7\u5ea6\u6807\u6ce8\u7684\u95ee\u9898\u3002\u5206\u6790\u663e\u793a\uff0c\u9519\u8bef\u548c\u65e0\u6cd5\u6838\u5b9e\u7684\u4fe1\u606f\u4f1a\u5e26\u6765\u6700\u5927\u7684\u98ce\u9669\u3002\u6b64\u5916\uff0c\u4f17\u5305\u8bc4\u4f30\u4e5f\u5b58\u5728\u6311\u6218\u3002"}}
{"id": "2507.10986", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10986", "abs": "https://arxiv.org/abs/2507.10986", "authors": ["Tianyu Su", "Zhiqiang Zou", "Ali Luo", "Xiao Kong", "Qingyu Lu", "Min Li"], "title": "StellarF: A Lora-Adapter Integrated Large Model Framework for Stellar Flare Forecasting with Historical & Statistical Data", "comment": null, "summary": "Stellar flare forecasting, a critical research frontier in astronomy, offers\nprofound insights into stellar activity. However, the field is constrained by\nboth the sparsity of recorded flare events and the absence of domain-specific\nlarge-scale predictive models. To address these challenges, this study\nintroduces StellarF (Stellar Flare Forecasting), a novel large model that\nleverages Low-Rank (LoRA) and Adapter techniques to parameter-efficient\nlearning for stellar flare forecasting. At its core, StellarF integrates an\nflare statistical information module with a historical flare record module,\nenabling multi-scale pattern recognition from observational data. Extensive\nexperiments on our self-constructed datasets (derived from Kepler and TESS\nlight curves) demonstrate that StellarF achieves state-of-the-art performance\ncompared to existing methods. The proposed prediction paradigm establishes a\nnovel methodological framework for advancing astrophysical research and\ncross-disciplinary applications.", "AI": {"tldr": "StellarF\u662f\u4e00\u4e2a\u5229\u7528\u4f4e\u79e9\u548c\u9002\u914d\u5668\u6280\u672f\u8fdb\u884c\u53c2\u6570\u9ad8\u6548\u5b66\u4e60\u7684\u65b0\u578b\u5927\u578b\u6a21\u578b\uff0c\u7528\u4e8e\u592a\u9633\u8000\u6591\u9884\u6d4b\u3002\u5b83\u901a\u8fc7\u7ed3\u5408\u8000\u6591\u7edf\u8ba1\u4fe1\u606f\u548c\u5386\u53f2\u8000\u6591\u8bb0\u5f55\uff0c\u80fd\u591f\u8bc6\u522b\u591a\u5c3a\u5ea6\u6a21\u5f0f\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u5c55\u73b0\u51fa\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u592a\u9633\u8000\u6591\u9884\u6d4b\u9886\u57df\u4e2d\u5df2\u8bb0\u5f55\u8000\u6591\u4e8b\u4ef6\u7a00\u758f\u4ee5\u53ca\u7f3a\u4e4f\u9886\u57df\u7279\u5b9a\u5927\u89c4\u6a21\u9884\u6d4b\u6a21\u578b\u7684\u95ee\u9898\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aStellarF\u7684\u65b0\u578b\u5927\u578b\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5229\u7528\u4f4e\u79e9\uff08LoRA\uff09\u548c\u9002\u914d\u5668\u6280\u672f\u8fdb\u884c\u53c2\u6570\u9ad8\u6548\u5b66\u4e60\uff0c\u4ee5\u5b9e\u73b0\u592a\u9633\u8000\u6591\u9884\u6d4b\u3002StellarF\u96c6\u6210\u4e86\u8000\u6591\u7edf\u8ba1\u4fe1\u606f\u6a21\u5757\u548c\u5386\u53f2\u8000\u6591\u8bb0\u5f55\u6a21\u5757\uff0c\u80fd\u591f\u4ece\u89c2\u6d4b\u6570\u636e\u4e2d\u8bc6\u522b\u591a\u5c3a\u5ea6\u6a21\u5f0f\u3002", "result": "\u5728\u5229\u7528\u5f00\u666e\u52d2\u548cTESS\u5149\u53d8\u66f2\u7ebf\u6784\u5efa\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cStellarF\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684StellarF\u6a21\u578b\u5728\u592a\u9633\u8000\u6591\u9884\u6d4b\u65b9\u9762\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u4e3a\u5929\u4f53\u7269\u7406\u5b66\u7814\u7a76\u548c\u8de8\u5b66\u79d1\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u65b9\u6cd5\u6846\u67b6\u3002"}}
{"id": "2507.11252", "categories": ["cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2507.11252", "abs": "https://arxiv.org/abs/2507.11252", "authors": ["Guanghao Wu", "Chen Xu", "Hai Song", "Chong Wang", "Qixing Zhang"], "title": "MFGDiffusion: Mask-Guided Smoke Synthesis for Enhanced Forest Fire Detection", "comment": "18 pages, 11 figures", "summary": "Smoke is the first visible indicator of a wildfire.With the advancement of\ndeep learning, image-based smoke detection has become a crucial method for\ndetecting and preventing forest fires. However, the scarcity of smoke image\ndata from forest fires is one of the significant factors hindering the\ndetection of forest fire smoke. Image generation models offer a promising\nsolution for synthesizing realistic smoke images. However, current inpainting\nmodels exhibit limitations in generating high-quality smoke representations,\nparticularly manifesting as inconsistencies between synthesized smoke and\nbackground contexts. To solve these problems, we proposed a comprehensive\nframework for generating forest fire smoke images. Firstly, we employed the\npre-trained segmentation model and the multimodal model to obtain smoke masks\nand image captions.Then, to address the insufficient utilization of masks and\nmasked images by inpainting models, we introduced a network architecture guided\nby mask and masked image features. We also proposed a new loss function, the\nmask random difference loss, which enhances the consistency of the generated\neffects around the mask by randomly expanding and eroding the mask\nedges.Finally, to generate a smoke image dataset using random masks for\nsubsequent detection tasks, we incorporated smoke characteristics and use a\nmultimodal large language model as a filtering tool to select diverse and\nreasonable smoke images, thereby improving the quality of the synthetic\ndataset. Experiments showed that our generated smoke images are realistic and\ndiverse, and effectively enhance the performance of forest fire smoke detection\nmodels. Code is available at https://github.com/wghr123/MFGDiffusion.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u751f\u6210\u68ee\u6797\u706b\u707e\u70df\u96fe\u56fe\u50cf\u7684\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3\u70df\u96fe\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\u3002\u901a\u8fc7\u7ed3\u5408\u5206\u5272\u6a21\u578b\u3001\u591a\u6a21\u6001\u6a21\u578b\u548c\u4e00\u79cd\u65b0\u7684\u635f\u5931\u51fd\u6570\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u751f\u6210\u903c\u771f\u4e14\u591a\u6837\u7684\u70df\u96fe\u56fe\u50cf\uff0c\u5e76\u5df2\u8bc1\u660e\u80fd\u6709\u6548\u63d0\u5347\u70df\u96fe\u68c0\u6d4b\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u56fe\u50cf\u7684\u70df\u96fe\u68c0\u6d4b\u662f\u68ee\u6797\u706b\u707e\u68c0\u6d4b\u548c\u9884\u9632\u7684\u5173\u952e\u65b9\u6cd5\uff0c\u4f46\u68ee\u6797\u706b\u707e\u70df\u96fe\u56fe\u50cf\u6570\u636e\u7684\u7a00\u7f3a\u662f\u963b\u788d\u5176\u53d1\u5c55\u7684\u91cd\u8981\u56e0\u7d20\u3002\u73b0\u6709\u7684\u56fe\u50cf\u751f\u6210\u6a21\u578b\u5728\u751f\u6210\u9ad8\u8d28\u91cf\u70df\u96fe\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u5728\u5408\u6210\u70df\u96fe\u4e0e\u80cc\u666f\u7684\u878d\u5408\u4e00\u81f4\u6027\u65b9\u9762\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u751f\u6210\u68ee\u6797\u706b\u707e\u70df\u96fe\u56fe\u50cf\u7684\u6846\u67b6\uff0c\u5305\u62ec\uff1a1. \u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u5206\u5272\u6a21\u578b\u548c\u591a\u6a21\u6001\u6a21\u578b\u83b7\u53d6\u70df\u96fe\u63a9\u819c\u548c\u56fe\u50cf\u6807\u9898\u30022. \u5f15\u5165\u4e00\u79cd\u7531\u63a9\u819c\u548c\u63a9\u819c\u56fe\u50cf\u7279\u5f81\u5f15\u5bfc\u7684\u7f51\u7edc\u67b6\u6784\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u4fee\u590d\u6a21\u578b\u5bf9\u63a9\u819c\u548c\u63a9\u819c\u56fe\u50cf\u5229\u7528\u4e0d\u8db3\u7684\u95ee\u9898\u30023. \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u635f\u5931\u51fd\u6570\u2014\u2014\u63a9\u819c\u968f\u673a\u5dee\u503c\u635f\u5931\uff0c\u901a\u8fc7\u968f\u673a\u6269\u5c55\u548c\u4fb5\u8680\u63a9\u819c\u8fb9\u7f18\u6765\u589e\u5f3a\u751f\u6210\u6548\u679c\u5728\u63a9\u819c\u5468\u56f4\u7684\u4e00\u81f4\u6027\u30024. \u7ed3\u5408\u70df\u96fe\u7279\u5f81\uff0c\u5e76\u4f7f\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u7b5b\u9009\u5de5\u5177\uff0c\u7b5b\u9009\u51fa\u591a\u6837\u5316\u4e14\u5408\u7406\u7684\u70df\u96fe\u56fe\u50cf\uff0c\u4ee5\u751f\u6210\u7528\u4e8e\u540e\u7eed\u68c0\u6d4b\u4efb\u52a1\u7684\u70df\u96fe\u56fe\u50cf\u6570\u636e\u96c6\u3002", "result": "\u751f\u6210\u7684\u70df\u96fe\u56fe\u50cf\u903c\u771f\u4e14\u591a\u6837\u5316\uff0c\u5e76\u6709\u6548\u63d0\u5347\u4e86\u68ee\u6797\u706b\u707e\u70df\u96fe\u68c0\u6d4b\u6a21\u578b\u7684\u6027\u80fd\u3002", "conclusion": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u751f\u6210\u7684\u70df\u96fe\u56fe\u50cf\u903c\u771f\u4e14\u591a\u6837\u5316\uff0c\u80fd\u6709\u6548\u63d0\u5347\u68ee\u6797\u706b\u707e\u70df\u96fe\u68c0\u6d4b\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2507.10990", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10990", "abs": "https://arxiv.org/abs/2507.10990", "authors": ["Rodney Lafuente-Mercado"], "title": "High-Throughput Distributed Reinforcement Learning via Adaptive Policy Synchronization", "comment": null, "summary": "Scaling reinforcement learning (RL) workloads often requires distributing\nenvironment simulation across compute clusters. Existing frameworks entangle\nsimulation, learning logic, and orchestration into monolithic systems, limiting\nmodularity and reusability. We present ClusterEnv, a lightweight,\nlearner-agnostic interface for distributed environment execution that mirrors\nthe Gymnasium API. ClusterEnv introduces the DETACH pattern, which decouples\nsimulation from training by offloading reset() and step() operations to remote\nworkers while keeping learning centralized. To address policy staleness in\ndistributed execution, we propose Adaptive Actor Policy Synchronization (AAPS),\na divergence-triggered update mechanism that reduces synchronization overhead\nwithout sacrificing performance. ClusterEnv integrates cleanly into existing RL\npipelines, supports both on-policy and off-policy methods, and requires minimal\ncode changes. Experiments on discrete control tasks demonstrate that AAPS\nachieves high sample efficiency with significantly fewer weight updates. Source\ncode is available at https://github.com/rodlaf/ClusterEnv.", "AI": {"tldr": "ClusterEnv \u662f\u4e00\u4e2a\u7528\u4e8e\u5206\u5e03\u5f0f RL \u73af\u5883\u6267\u884c\u7684\u8f7b\u91cf\u7ea7\u63a5\u53e3\uff0c\u5b83\u901a\u8fc7 DETACH \u6a21\u5f0f\u5206\u79bb\u6a21\u62df\u548c\u8bad\u7ec3\uff0c\u5e76\u901a\u8fc7 AAPS \u673a\u5236\u89e3\u51b3\u7b56\u7565\u8fc7\u65f6\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u6846\u67b6\u5c06\u6a21\u62df\u3001\u5b66\u4e60\u903b\u8f91\u548c\u7f16\u6392\u5c01\u88c5\u5230\u5355\u4e00\u7684\u7cfb\u7edf\u4e2d\uff0c\u8fd9\u9650\u5236\u4e86\u6a21\u5757\u5316\u548c\u53ef\u91cd\u7528\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u66f4\u8f7b\u91cf\u7ea7\u7684\u63a5\u53e3\u6765\u5206\u5e03\u5f0f\u6267\u884c RL \u5de5\u4f5c\u8d1f\u8f7d\u3002", "method": "ClusterEnv \u5f15\u5165\u4e86 DETACH \u6a21\u5f0f\uff0c\u5c06\u6a21\u62df\u4e0e\u8bad\u7ec3\u5206\u79bb\uff0c\u5c06 reset() \u548c step() \u64cd\u4f5c\u5378\u8f7d\u5230\u8fdc\u7a0b\u5de5\u4f5c\u8282\u70b9\uff0c\u540c\u65f6\u4fdd\u6301\u5b66\u4e60\u7684\u96c6\u4e2d\u5316\u3002\u4e3a\u4e86\u89e3\u51b3\u5206\u5e03\u5f0f\u6267\u884c\u4e2d\u7684\u7b56\u7565\u8fc7\u65f6\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u81ea\u9002\u5e94 Actor \u7b56\u7565\u540c\u6b65\uff08AAPS\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u53d1\u6563\u89e6\u53d1\u7684\u66f4\u65b0\u673a\u5236\uff0c\u53ef\u5728\u4e0d\u727a\u7272\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u51cf\u5c11\u540c\u6b65\u5f00\u9500\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cAAPS \u5728\u6837\u672c\u6548\u7387\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e14\u6240\u9700\u7684\u6743\u91cd\u66f4\u65b0\u6b21\u6570\u663e\u8457\u51cf\u5c11\u3002", "conclusion": "ClusterEnv \u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u3001\u4e0e\u5b66\u4e60\u5668\u65e0\u5173\u7684\u5206\u5e03\u5f0f\u73af\u5883\u6267\u884c\u63a5\u53e3\uff0c\u5b83\u955c\u50cf\u4e86 Gymnasium API\u3002ClusterEnv \u5f15\u5165\u4e86 DETACH \u6a21\u5f0f\uff0c\u5c06\u6a21\u62df\u4e0e\u8bad\u7ec3\u5206\u79bb\uff0c\u5c06 reset() \u548c step() \u64cd\u4f5c\u5378\u8f7d\u5230\u8fdc\u7a0b\u5de5\u4f5c\u8282\u70b9\uff0c\u540c\u65f6\u4fdd\u6301\u5b66\u4e60\u7684\u96c6\u4e2d\u5316\u3002\u4e3a\u4e86\u89e3\u51b3\u5206\u5e03\u5f0f\u6267\u884c\u4e2d\u7684\u7b56\u7565\u8fc7\u65f6\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u81ea\u9002\u5e94 Actor \u7b56\u7565\u540c\u6b65\uff08AAPS\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u53d1\u6563\u89e6\u53d1\u7684\u66f4\u65b0\u673a\u5236\uff0c\u53ef\u5728\u4e0d\u727a\u7272\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u51cf\u5c11\u540c\u6b65\u5f00\u9500\u3002ClusterEnv \u53ef\u4e0e\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u6d41\u7a0b\u65e0\u7f1d\u96c6\u6210\uff0c\u652f\u6301\u540c\u6b65\u548c\u5f02\u6b65\u7b56\u7565\u65b9\u6cd5\uff0c\u5e76\u4e14\u53ea\u9700\u6700\u5c11\u7684\u4ee3\u7801\u66f4\u6539\u3002"}}
{"id": "2507.11534", "categories": ["quant-ph", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.11534", "abs": "https://arxiv.org/abs/2507.11534", "authors": ["Daiki Komoto", "Kenta Kasai"], "title": "Sharp Error-Rate Transitions in Quantum QC-LDPC Codes under Joint BP Decoding", "comment": null, "summary": "In this study, we report that quantum quasi-cyclic low-density parity-check\ncodes decoded via joint belief propagation (BP) exhibit steep error-rate\ncurves, despite the presence of error floors. To the best of our knowledge,\nthis is the first observation of such threshold-like behavior for quantum codes\nwith non-vanishing coding rate, excluding those decoded with non-binary BP\ndecoders. Moreover, we find that dominant error events contributing to the\nerror floor typically involve only a small number of bits. These findings\nsuggest that the error floor is caused by trapping sets -- specific subgraph\nstructures in the Tanner graph -- and indicate that identifying and avoiding\nsuch structures may lead to further reduction of the error floor.", "AI": {"tldr": "\u91cf\u5b50\u62df\u5faa\u73af\u4f4e\u5bc6\u5ea6\u5947\u5076\u6821\u9a8c\u7801\u901a\u8fc7\u8054\u5408\u4fe1\u5ff5\u4f20\u64ad\uff08BP\uff09\u89e3\u7801\u8868\u73b0\u51fa\u9661\u5ced\u7684\u9519\u8bef\u7387\u66f2\u7ebf\uff0c\u8bc1\u660e\u4e86\u9608\u503c\u884c\u4e3a\uff0c\u5c3d\u7ba1\u5b58\u5728\u9519\u8bef\u5c42\u3002\u9519\u8bef\u5c42\u6e90\u4e8e\u6355\u83b7\u96c6\uff0c\u53ef\u901a\u8fc7\u8bc6\u522b\u548c\u907f\u514d\u8fd9\u4e9b\u7ed3\u6784\u6765\u51cf\u5c11\u3002", "motivation": "\u7814\u7a76\u91cf\u5b50\u62df\u5faa\u73af\u4f4e\u5bc6\u5ea6\u5947\u5076\u6821\u9a8c\u7801\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5b83\u4eec\u5728\u5b58\u5728\u9519\u8bef\u5c42\u65f6\u7684\u884c\u4e3a\uff0c\u5e76\u63a2\u7d22\u5bfc\u81f4\u9519\u8bef\u5c42\u7684\u6839\u672c\u539f\u56e0\u3002", "method": "\u91cf\u5b50\u62df\u5faa\u73af\u4f4e\u5bc6\u5ea6\u5947\u5076\u6821\u9a8c\u7801\u901a\u8fc7\u8054\u5408\u4fe1\u5ff5\u4f20\u64ad\uff08BP\uff09\u89e3\u7801\u3002", "result": "\u91cf\u5b50\u62df\u5faa\u73af\u4f4e\u5bc6\u5ea6\u5947\u5076\u6821\u9a8c\u7801\u901a\u8fc7\u8054\u5408\u4fe1\u5ff5\u4f20\u64ad\uff08BP\uff09\u89e3\u7801\u8868\u73b0\u51fa\u9661\u5ced\u7684\u9519\u8bef\u7387\u66f2\u7ebf\uff0c\u8fd9\u662f\u5177\u6709\u975e\u6d88\u5931\u7f16\u7801\u7387\u4e14\u4e0d\u4f7f\u7528\u975e\u4e8c\u8fdb\u5236BP\u89e3\u7801\u5668\u7684\u91cf\u5b50\u7801\u7684\u9996\u6b21\u6b64\u7c7b\u9608\u503c\u884c\u4e3a\u89c2\u5bdf\u3002\u6b64\u5916\uff0c\u5bfc\u81f4\u9519\u8bef\u5c42\u7684\u4e3b\u8981\u9519\u8bef\u4e8b\u4ef6\u901a\u5e38\u53ea\u6d89\u53ca\u5c11\u91cf\u6bd4\u7279\uff0c\u8fd9\u8868\u660e\u9519\u8bef\u5c42\u662f\u7531\u6355\u83b7\u96c6\u5f15\u8d77\u7684\u3002", "conclusion": "\u91cf\u5b50\u62df\u5faa\u73af\u4f4e\u5bc6\u5ea6\u5947\u5076\u6821\u9a8c\u7801\u901a\u8fc7\u8054\u5408\u4fe1\u5ff5\u4f20\u64ad\uff08BP\uff09\u89e3\u7801\u8868\u73b0\u51fa\u9661\u5ced\u7684\u9519\u8bef\u7387\u66f2\u7ebf\uff0c\u5c3d\u7ba1\u5b58\u5728\u9519\u8bef\u5c42\u3002\u8fd9\u8868\u660e\u9519\u8bef\u5c42\u662f\u7531\u6355\u83b7\u96c6\u5f15\u8d77\u7684\uff0c\u8bc6\u522b\u548c\u907f\u514d\u8fd9\u4e9b\u7ed3\u6784\u53ef\u80fd\u4f1a\u8fdb\u4e00\u6b65\u964d\u4f4e\u9519\u8bef\u5c42\u3002"}}
{"id": "2507.11261", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11261", "abs": "https://arxiv.org/abs/2507.11261", "authors": ["Ronggang Huang", "Haoxin Yang", "Yan Cai", "Xuemiao Xu", "Huaidong Zhang", "Shengfeng He"], "title": "ViewSRD: 3D Visual Grounding via Structured Multi-View Decomposition", "comment": "Accepted by ICCV 2025", "summary": "3D visual grounding aims to identify and localize objects in a 3D space based\non textual descriptions. However, existing methods struggle with disentangling\ntargets from anchors in complex multi-anchor queries and resolving\ninconsistencies in spatial descriptions caused by perspective variations. To\ntackle these challenges, we propose ViewSRD, a framework that formulates 3D\nvisual grounding as a structured multi-view decomposition process. First, the\nSimple Relation Decoupling (SRD) module restructures complex multi-anchor\nqueries into a set of targeted single-anchor statements, generating a\nstructured set of perspective-aware descriptions that clarify positional\nrelationships. These decomposed representations serve as the foundation for the\nMulti-view Textual-Scene Interaction (Multi-TSI) module, which integrates\ntextual and scene features across multiple viewpoints using shared, Cross-modal\nConsistent View Tokens (CCVTs) to preserve spatial correlations. Finally, a\nTextual-Scene Reasoning module synthesizes multi-view predictions into a\nunified and robust 3D visual grounding. Experiments on 3D visual grounding\ndatasets show that ViewSRD significantly outperforms state-of-the-art methods,\nparticularly in complex queries requiring precise spatial differentiation.", "AI": {"tldr": "ViewSRD\u901a\u8fc7\u5c06\u67e5\u8be2\u5206\u89e3\u4e3a\u66f4\u7b80\u5355\u7684\u90e8\u5206\u5e76\u6574\u5408\u6765\u81ea\u591a\u4e2a\u89c6\u70b9\u7684\u8de8\u6a21\u6001\u4fe1\u606f\u6765\u89e3\u51b33D\u89c6\u89c9\u57fa\u7840\u4e2d\u7684\u6311\u6218\uff0c\u4ece\u800c\u63d0\u9ad8\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u76843D\u89c6\u89c9\u57fa\u7840\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u7684 Jadi \u951a\u70b9\u67e5\u8be2\u4e2d\u7684\u76ee\u6807\u4e0e\u951a\u70b9\u7684\u89e3\u8026\u4ee5\u53ca\u89e3\u51b3\u7531\u89c6\u89d2\u53d8\u5316\u5f15\u8d77\u0627\u064b\u7684\u7a7a\u95f4\u63cf\u8ff0\u4e0d\u4e00\u81f4\u6027\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002", "method": "ViewSRD\u6846\u67b6\u5c063D\u89c6\u89c9\u57fa\u7840\u4efb\u52a1\u6784\u5efa\u4e3a\u4e00\u4e2a\u7ed3\u6784\u5316\u7684\u591a\u89c6\u56fe\u5206\u89e3\u8fc7\u7a0b\u3002\u9996\u5148\uff0c\u7b80\u5355\u5173\u7cfb\u89e3\u8026\uff08SRD\uff09\u6a21\u5757\u5c06\u590d\u6742\u7684 Jadi \u951a\u70b9\u67e5\u8be2\u91cd\u6784\u4e3a\u4e00\u7ec4\u76ee\u6807\u5355\u951a\u70b9\u8bed\u53e5\uff0c\u751f\u6210\u4e00\u7ec4\u7ed3\u6784\u5316\u7684\u3001\u6ce8\u610f\u89c6\u89d2\u7684\u63cf\u8ff0\uff0c\u4ee5\u9610\u660e\u4f4d\u7f6e\u5173\u7cfb\u3002\u8fd9\u4e9b\u5206\u89e3\u540e\u7684\u8868\u793a\u4e3a\u591a\u89c6\u56fe\u6587\u672c\u573a\u666f\u4ea4\u4e92\uff08Multi-TSI\uff09\u6a21\u5757\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u8be5\u6a21\u5757\u4f7f\u7528\u5171\u4eab\u7684\u3001\u8de8\u6a21\u6001\u4e00\u81f4\u89c6\u56fe\u4ee4\u724c\uff08CCVTs\uff09\u6765\u6574\u5408\u6765\u81ea\u591a\u4e2a\u89c6\u70b9\u7684\u6587\u672c\u548c\u573a\u666f\u7279\u5f81\uff0c\u4ee5\u4fdd\u7559\u7a7a\u95f4\u76f8\u5173\u6027\u3002\u6700\u540e\uff0c\u6587\u672c\u573a\u666f\u63a8\u7406\u6a21\u5757\u5c06\u591a\u89c6\u56fe\u9884\u6d4b\u5408\u6210\u4e3a\u7edf\u4e00\u4e14\u9c81\u68d2\u76843D\u89c6\u89c9\u57fa\u7840\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cViewSRD\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u9700\u8981\u7cbe\u786e\u7a7a\u95f4\u533a\u5206\u7684\u590d\u6742\u67e5\u8be2\u573a\u666f\u4e2d\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "ViewSRD\u57283D\u89c6\u89c9\u57fa\u7840\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u7cbe\u786e\u7a7a\u95f4\u533a\u5206\u7684\u590d\u6742\u67e5\u8be2\u65b9\u9762\u3002"}}
{"id": "2507.10995", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10995", "abs": "https://arxiv.org/abs/2507.10995", "authors": ["Henrik Marklund", "Alex Infanger", "Benjamin Van Roy"], "title": "Misalignment from Treating Means as Ends", "comment": null, "summary": "Reward functions, learned or manually specified, are rarely perfect. Instead\nof accurately expressing human goals, these reward functions are often\ndistorted by human beliefs about how best to achieve those goals. Specifically,\nthese reward functions often express a combination of the human's terminal\ngoals -- those which are ends in themselves -- and the human's instrumental\ngoals -- those which are means to an end. We formulate a simple example in\nwhich even slight conflation of instrumental and terminal goals results in\nsevere misalignment: optimizing the misspecified reward function results in\npoor performance when measured by the true reward function. This example\ndistills the essential properties of environments that make reinforcement\nlearning highly sensitive to conflation of instrumental and terminal goals. We\ndiscuss how this issue can arise with a common approach to reward learning and\nhow it can manifest in real environments.", "AI": {"tldr": "\u5956\u52b1\u51fd\u6570\u5e38\u6df7\u6dc6\u7ec8\u6781\u76ee\u6807\u548c\u5de5\u5177\u76ee\u6807\uff0c\u5bfc\u81f4\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u76ee\u6807\u4e0d\u5bf9\u9f50\uff0c\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u672c\u6587\u7684\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2d\u5956\u52b1\u51fd\u6570\u4e0d\u5b8c\u7f8e\u7684\u666e\u904d\u95ee\u9898\u3002\u4f5c\u8005\u6307\u51fa\uff0c\u5956\u52b1\u51fd\u6570\u5e38\u5e38\u4f1a\u6df7\u6dc6\u7ec8\u6781\u76ee\u6807\u548c\u5de5\u5177\u76ee\u6807\uff0c\u5bfc\u81f4\u6a21\u578b\u8bad\u7ec3\u6548\u679c\u4e0d\u4f73\uff0c\u5e76\u5bf9\u8fd9\u79cd\u73b0\u8c61\u8fdb\u884c\u4e86\u6df1\u5165\u5206\u6790\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u4f8b\u5b50\uff0c\u8bf4\u660e\u4e86\u5373\u4f7f\u662f\u8f7b\u5fae\u7684\u5de5\u5177\u76ee\u6807\u4e0e\u7ec8\u6781\u76ee\u6807\u4e4b\u95f4\u7684\u6df7\u6dc6\u4e5f\u4f1a\u5bfc\u81f4\u4e25\u91cd\u7684\u76ee\u6807\u4e0d\u5bf9\u9f50\u3002\u901a\u8fc7\u5206\u6790\u8fd9\u4e2a\u4f8b\u5b50\uff0c\u53ef\u4ee5\u63d0\u70bc\u51fa\u90a3\u4e9b\u4f7f\u5f97\u5f3a\u5316\u5b66\u4e60\u5bf9\u5de5\u5177\u76ee\u6807\u4e0e\u7ec8\u6781\u76ee\u6807\u4e4b\u95f4\u7684\u6df7\u6dc6\u9ad8\u5ea6\u654f\u611f\u7684\u73af\u5883\u7684\u672c\u8d28\u5c5e\u6027\u3002", "result": "\u901a\u8fc7\u4e00\u4e2a\u7b80\u5355\u7684\u4f8b\u5b50\uff0c\u672c\u6587\u5c55\u793a\u4e86\u5f53\u5956\u52b1\u51fd\u6570\u5305\u542b\u5de5\u5177\u76ee\u6807\u65f6\uff0c\u5373\u4f7f\u662f\u5f88\u5c0f\u7684\u504f\u5dee\u4e5f\u4f1a\u5bfc\u81f4\u4e0e\u771f\u5b9e\u76ee\u6807\u4e25\u91cd\u4e0d\u4e00\u81f4\uff0c\u4ece\u800c\u5728\u771f\u5b9e\u76ee\u6807\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "\u5956\u52b1\u51fd\u6570\uff08\u65e0\u8bba\u662f\u5b66\u4e60\u5230\u7684\u8fd8\u662f\u624b\u52a8\u6307\u5b9a\u7684\uff09\u5f88\u5c11\u662f\u5b8c\u7f8e\u7684\u3002\u5b83\u4eec\u7ecf\u5e38\u5305\u542b\u4eba\u7c7b\u7684\u7ec8\u6781\u76ee\u6807\uff08\u76ee\u7684\u672c\u8eab\uff09\u548c\u4eba\u7c7b\u7684\u5de5\u5177\u76ee\u6807\uff08\u5b9e\u73b0\u76ee\u6807\u7684\u624b\u6bb5\uff09\u3002\u8fd9\u79cd\u5bf9\u5de5\u5177\u76ee\u6807\u7684\u5305\u542b\u4f1a\u5bfc\u81f4\u5956\u52b1\u51fd\u6570\u5931\u771f\uff0c\u5e76\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u7684\u76ee\u6807\u4e0d\u5bf9\u9f50\u3002\u4f18\u5316\u4e00\u4e2a\u9519\u8bef\u7684\u5956\u52b1\u51fd\u6570\uff0c\u5728\u771f\u6b63\u7684\u5956\u52b1\u51fd\u6570\u4e0b\u8868\u73b0\u4f1a\u5f88\u5dee\u3002"}}
{"id": "2507.11536", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2507.11536", "abs": "https://arxiv.org/abs/2507.11536", "authors": ["John Watrous"], "title": "Understanding Quantum Information and Computation", "comment": "498 pages", "summary": "This is a course on the theory of quantum computing. It consists of 16\nlessons, each with a video and written component, covering the basics of\nquantum information, quantum algorithms (including query algorithms, Shor's\nalgorithm for integer factorization, and Grover's algorithm), the general\nformulation of quantum information (including density matrices, quantum\nchannels, and general measurements), and quantum error correction (including\nthe basics, the stabilizer formalism, CSS codes, the toric code, and\nfault-tolerant quantum computation).", "AI": {"tldr": "\u4e00\u95e8\u5173\u4e8e\u91cf\u5b50\u8ba1\u7b97\u7406\u8bba\u7684\u8bfe\u7a0b\uff0c\u5185\u5bb9\u6db5\u76d6\u91cf\u5b50\u4fe1\u606f\u3001\u91cf\u5b50\u7b97\u6cd5\u3001\u91cf\u5b50\u4fe1\u606f\u901a\u7528\u516c\u5f0f\u548c\u91cf\u5b50\u7ea0\u9519\uff0c\u517116\u8bfe\u65f6\u3002", "motivation": "\u672c\u8bfe\u7a0b\u65e8\u5728\u6559\u6388\u91cf\u5b50\u8ba1\u7b97\u7684\u7406\u8bba\u57fa\u7840\u3002", "method": "\u8be5\u8bfe\u7a0b\u5305\u542b16\u4e2a\u8bfe\u65f6\uff0c\u6bcf\u4e2a\u8bfe\u65f6\u90fd\u914d\u6709\u89c6\u9891\u548c\u4e66\u9762\u6750\u6599\u3002", "result": "\u8bfe\u7a0b\u5185\u5bb9\u5168\u9762\uff0c\u6db5\u76d6\u4e86\u91cf\u5b50\u8ba1\u7b97\u7684\u5404\u4e2a\u4e3b\u8981\u65b9\u9762\uff0c\u4ece\u57fa\u7840\u7406\u8bba\u5230\u9ad8\u7ea7\u6982\u5ff5\u3002", "conclusion": "\u8be5\u8bfe\u7a0b\u6db5\u76d6\u4e86\u91cf\u5b50\u4fe1\u606f\u3001\u91cf\u5b50\u7b97\u6cd5\uff08\u5305\u62ec\u67e5\u8be2\u7b97\u6cd5\u3001Shor\u7b97\u6cd5\u548cGrover\u7b97\u6cd5\uff09\u3001\u91cf\u5b50\u4fe1\u606f\u901a\u7528\u516c\u5f0f\uff08\u5305\u62ec\u5bc6\u5ea6\u77e9\u9635\u3001\u91cf\u5b50\u901a\u9053\u548c\u901a\u7528\u6d4b\u91cf\uff09\u4ee5\u53ca\u91cf\u5b50\u7ea0\u9519\uff08\u5305\u62ec\u57fa\u7840\u3001\u7a33\u5b9a\u5668\u5f62\u5f0f\u3001CSS\u7801\u3001\u73af\u5f62\u7801\u548c\u5bb9\u9519\u91cf\u5b50\u8ba1\u7b97\uff09\u7684\u57fa\u7840\u77e5\u8bc6\u3002"}}
{"id": "2507.11267", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11267", "abs": "https://arxiv.org/abs/2507.11267", "authors": ["Aon Safdar", "Usman Akram", "Waseem Anwar", "Basit Malik", "Mian Ibad Ali"], "title": "YOLOatr : Deep Learning Based Automatic Target Detection and Localization in Thermal Infrared Imagery", "comment": "Published in 25th Irish Machine Vision and Image Processing Conf.,\n  Galway, Ireland, Aug 30-Sep 1 2023 Also available at\n  https://doi.org/10.5281/zenodo.8264062", "summary": "Automatic Target Detection (ATD) and Recognition (ATR) from Thermal Infrared\n(TI) imagery in the defense and surveillance domain is a challenging computer\nvision (CV) task in comparison to the commercial autonomous vehicle perception\ndomain. Limited datasets, peculiar domain-specific and TI modality-specific\nchallenges, i.e., limited hardware, scale invariance issues due to greater\ndistances, deliberate occlusion by tactical vehicles, lower sensor resolution\nand resultant lack of structural information in targets, effects of weather,\ntemperature, and time of day variations, and varying target to clutter ratios\nall result in increased intra-class variability and higher inter-class\nsimilarity, making accurate real-time ATR a challenging CV task. Resultantly,\ncontemporary state-of-the-art (SOTA) deep learning architectures underperform\nin the ATR domain. We propose a modified anchor-based single-stage detector,\ncalled YOLOatr, based on a modified YOLOv5s, with optimal modifications to the\ndetection heads, feature fusion in the neck, and a custom augmentation profile.\nWe evaluate the performance of our proposed model on a comprehensive DSIAC MWIR\ndataset for real-time ATR over both correlated and decorrelated testing\nprotocols. The results demonstrate that our proposed model achieves\nstate-of-the-art ATR performance of up to 99.6%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aYOLOatr\u7684\u6539\u8fdb\u578bYOLOv5s\u6a21\u578b\uff0c\u7528\u4e8e\u89e3\u51b3\u70ed\u7ea2\u5916\uff08TI\uff09\u56fe\u50cf\u4e2d\u7684\u81ea\u52a8\u76ee\u6807\u68c0\u6d4b\uff08ATD\uff09\u548c\u8bc6\u522b\uff08ATR\uff09\u7684\u6311\u6218\uff0c\u5e76\u5728DSIAC MWIR\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8699.6%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u4e0e\u5546\u4e1a\u81ea\u52a8\u9a7e\u9a76\u611f\u77e5\u9886\u57df\u76f8\u6bd4\uff0c\u56fd\u9632\u548c\u76d1\u63a7\u9886\u57df\u7684\u81ea\u52a8\u76ee\u6807\u68c0\u6d4b\uff08ATD\uff09\u548c\u8bc6\u522b\uff08ATR\uff09\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\uff08CV\uff09\u4efb\u52a1\u3002\u6709\u9650\u7684\u6570\u636e\u96c6\u3001\u72ec\u7279\u7684\u9886\u57df\u7279\u5b9a\u548cTI\u6a21\u7279\u5b9a\u6311\u6218\uff08\u4f8b\u5982\uff0c\u786c\u4ef6\u9650\u5236\u3001\u7531\u4e8e\u8ddd\u79bb\u8fdc\u5bfc\u81f4\u7684\u5c3a\u5ea6\u4e0d\u53d8\u6027\u95ee\u9898\u3001\u6218\u672f\u8f66\u8f86\u7684\u6545\u610f\u906e\u6321\u3001\u8f83\u4f4e\u7684\u4f20\u611f\u5668\u5206\u8fa8\u7387\u4ee5\u53ca\u76ee\u6807\u7ed3\u6784\u4fe1\u606f\u4e0d\u8db3\u3001\u5929\u6c14\u3001\u6e29\u5ea6\u548c\u4e00\u5929\u4e2d\u7684\u65f6\u95f4\u53d8\u5316\u4ee5\u53ca\u76ee\u6807\u4e0e\u6742\u6ce2\u6bd4\u7684\u53d8\u5316\uff09\u5bfc\u81f4\u4e86\u7c7b\u5185\u5dee\u5f02\u589e\u52a0\u548c\u7c7b\u95f4\u76f8\u4f3c\u6027\u66f4\u9ad8\uff0c\u4f7f\u5f97\u51c6\u786e\u7684\u5b9e\u65f6ATR\u6210\u4e3a\u4e00\u9879\u5177\u6709\u6311\u6218\u6027\u7684CV\u4efb\u52a1\u3002\u56e0\u6b64\uff0c\u5f53\u524d\u6700\u5148\u8fdb\uff08SOTA\uff09\u7684\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u5728ATR\u9886\u57df\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u57fa\u4e8e\u951a\u70b9\u7684\u4e00\u9636\u6bb5\u68c0\u6d4b\u5668YOLOatr\uff0c\u8be5\u68c0\u6d4b\u5668\u57fa\u4e8e\u6539\u8fdb\u7684YOLOv5s\uff0c\u5e76\u5728\u68c0\u6d4b\u5934\u3001\u9888\u90e8\u7279\u5f81\u878d\u5408\u548c\u81ea\u5b9a\u4e49\u589e\u5f3a\u914d\u7f6e\u6587\u4ef6\u65b9\u9762\u8fdb\u884c\u4e86\u4f18\u5316\u3002", "result": "\u6240\u63d0\u51fa\u7684\u6a21\u578b\u5728DSIAC MWIR\u6570\u636e\u96c6\u4e0a\u9488\u5bf9\u5b9e\u65f6ATR\u5728\u76f8\u5173\u548c\u4e0d\u76f8\u5173\u6d4b\u8bd5\u534f\u8bae\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u6a21\u578b\u8fbe\u5230\u4e86\u9ad8\u8fbe99.6%\u7684\u6700\u65b0ATR\u6027\u80fd\u3002", "conclusion": "YOLOatr\u6a21\u578b\u5728DSIAC MWIR\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe99.6%\u7684\u6700\u65b0ATR\u6027\u80fd\u3002"}}
{"id": "2507.10998", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10998", "abs": "https://arxiv.org/abs/2507.10998", "authors": ["Zhipeng He", "Alexander Stevens", "Chun Ouyang", "Johannes De Smedt", "Alistair Barros", "Catarina Moreira"], "title": "Crafting Imperceptible On-Manifold Adversarial Attacks for Tabular Data", "comment": "32 pages", "summary": "Adversarial attacks on tabular data present fundamental challenges distinct\nfrom image or text domains due to the heterogeneous nature of mixed categorical\nand numerical features. Unlike images where pixel perturbations maintain visual\nsimilarity, tabular data lacks intuitive similarity metrics, making it\ndifficult to define imperceptible modifications. Additionally, traditional\ngradient-based methods prioritise $\\ell_p$-norm constraints, often producing\nadversarial examples that deviate from the original data distributions, making\nthem detectable. We propose a latent space perturbation framework using a\nmixed-input Variational Autoencoder (VAE) to generate imperceptible adversarial\nexamples. The proposed VAE integrates categorical embeddings and numerical\nfeatures into a unified latent manifold, enabling perturbations that preserve\nstatistical consistency. We specify In-Distribution Success Rate (IDSR) to\nmeasure the proportion of adversarial examples that remain statistically\nindistinguishable from the input distribution. Evaluation across six publicly\navailable datasets and three model architectures demonstrates that our method\nachieves substantially lower outlier rates and more consistent performance\ncompared to traditional input-space attacks and other VAE-based methods adapted\nfrom image domain approaches. Our comprehensive analysis includes\nhyperparameter sensitivity, sparsity control mechanisms, and generative\narchitectural comparisons, revealing that VAE-based attacks depend critically\non reconstruction quality but offer superior practical utility when sufficient\ntraining data is available. This work highlights the importance of on-manifold\nperturbations for realistic adversarial attacks on tabular data, offering a\nrobust approach for practical deployment. The source code can be accessed\nthrough https://github.com/ZhipengHe/VAE-TabAttack.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8eVAE\u7684\u6f5c\u5728\u7a7a\u95f4\u6270\u52a8\u65b9\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u8868\u683c\u6570\u636e\u7684\u4e0d\u53ef\u611f\u77e5\u5bf9\u6297\u6837\u672c\uff0c\u89e3\u51b3\u4e86\u8868\u683c\u6570\u636e\u5f02\u6784\u6027\u548c\u7f3a\u4e4f\u76f4\u89c2\u76f8\u4f3c\u6027\u5ea6\u91cf\u7684\u6311\u6218\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8bc1\u660e\u4e86\u5176\u4f18\u8d8a\u7684\u6027\u80fd\u548c\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u8868\u683c\u6570\u636e\u7684\u5bf9\u6297\u6027\u653b\u51fb\u7531\u4e8e\u5176\u6df7\u5408\u7684\u7c7b\u522b\u548c\u6570\u503c\u7279\u5f81\uff0c\u5e26\u6765\u4e86\u4e0d\u540c\u4e8e\u56fe\u50cf\u6216\u6587\u672c\u57df\u7684\u6839\u672c\u6027\u6311\u6218\u3002\u7f3a\u4e4f\u76f4\u89c2\u7684\u76f8\u4f3c\u6027\u5ea6\u91cf\u4f7f\u5f97\u751f\u6210\u4e0d\u53ef\u611f\u77e5\u6270\u52a8\u53d8\u5f97\u56f0\u96be\u3002\u6b64\u5916\uff0c\u4f20\u7edf\u7684\u57fa\u4e8e\u68af\u5ea6\u7684$\\ell_p$\u8303\u6570\u7ea6\u675f\u65b9\u6cd5\u5f80\u5f80\u4ea7\u751f\u504f\u79bb\u539f\u59cb\u6570\u636e\u5206\u5e03\u7684\u5bf9\u6297\u6837\u672c\uff0c\u5bb9\u6613\u88ab\u68c0\u6d4b\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6f5c\u5728\u7a7a\u95f4\u6270\u52a8\u7684\u6846\u67b6\uff0c\u5229\u7528\u6df7\u5408\u8f93\u5165\u7684\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u751f\u6210\u5bf9\u6297\u6837\u672c\u3002\u8be5VAE\u80fd\u591f\u6574\u5408\u7c7b\u522b\u5d4c\u5165\u548c\u6570\u503c\u7279\u5f81\uff0c\u5728\u4e00\u4e2a\u7edf\u4e00\u7684\u6f5c\u5728\u6d41\u5f62\u4e2d\u8fdb\u884c\u6270\u52a8\uff0c\u4ee5\u4fdd\u6301\u7edf\u8ba1\u4e00\u81f4\u6027\u3002\u901a\u8fc7\u6307\u5b9a\u201c\u5206\u5e03\u5185\u6210\u529f\u7387\u201d\uff08IDSR\uff09\u6765\u8861\u91cf\u5bf9\u6297\u6837\u672c\u5728\u7edf\u8ba1\u4e0a\u4e0e\u539f\u59cb\u6570\u636e\u5206\u5e03\u7684\u4e0d\u53ef\u533a\u5206\u6027\u3002", "result": "\u5728\u516d\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u548c\u4e09\u79cd\u6a21\u578b\u67b6\u6784\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u663e\u8457\u66f4\u4f4e\u7684\u5f02\u5e38\u503c\u7387\u548c\u66f4\u4e00\u81f4\u7684\u6027\u80fd\uff0c\u4f18\u4e8e\u4f20\u7edf\u7684\u8f93\u5165\u7a7a\u95f4\u653b\u51fb\u548c\u5176\u4ed6\u4ece\u56fe\u50cf\u9886\u57df\u6539\u7f16\u7684VAE\u65b9\u6cd5\u3002\u7814\u7a76\u8fd8\u8fdb\u884c\u4e86\u8d85\u53c2\u6570\u654f\u611f\u6027\u3001\u7a00\u758f\u6027\u63a7\u5236\u548c\u751f\u6210\u67b6\u6784\u7684\u6bd4\u8f83\u5206\u6790\uff0c\u53d1\u73b0VAE\u7c7b\u653b\u51fb\u5bf9\u91cd\u6784\u8d28\u91cf\u9ad8\u5ea6\u654f\u611f\uff0c\u4f46\u5728\u8bad\u7ec3\u6570\u636e\u5145\u8db3\u65f6\u5177\u6709\u4f18\u8d8a\u7684\u5b9e\u9645\u6548\u7528\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6f5c\u5728\u7a7a\u95f4\u6270\u52a8\u7684\u6846\u67b6\uff0c\u4f7f\u7528\u6df7\u5408\u8f93\u5165\u7684\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u751f\u6210\u4e0d\u53ef\u611f\u77e5\u5bf9\u6297\u6837\u672c\u3002\u901a\u8fc7\u5c06\u7c7b\u522b\u5d4c\u5165\u548c\u6570\u503c\u7279\u5f81\u6574\u5408\u5230\u7edf\u4e00\u7684\u6f5c\u5728\u6d41\u5f62\u4e2d\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u4fdd\u6301\u7edf\u8ba1\u4e00\u81f4\u6027\u7684\u6270\u52a8\u3002\u8bc4\u4f30\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u4f20\u7edf\u7684\u8f93\u5165\u7a7a\u95f4\u653b\u51fb\u548c\u5176\u4ed6\u4ece\u56fe\u50cf\u9886\u57df\u6539\u7f16\u7684VAE\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u7edf\u8ba1\u4e0a\u66f4\u96be\u533a\u5206\uff0c\u5e76\u4e14\u5728\u591a\u4e2a\u516c\u5171\u6570\u636e\u96c6\u548c\u6a21\u578b\u67b6\u6784\u4e0a\u8868\u73b0\u51fa\u66f4\u7a33\u5b9a\u3001\u66f4\u4f4e\u7684\u5f02\u5e38\u503c\u7387\u3002\u7814\u7a76\u8fd8\u5f3a\u8c03\u4e86\u5728\u5145\u8db3\u8bad\u7ec3\u6570\u636e\u53ef\u7528\u65f6\uff0cVAE\u7c7b\u653b\u51fb\u5bf9\u91cd\u6784\u8d28\u91cf\u7684\u4f9d\u8d56\u6027\u4ee5\u53ca\u5b83\u4eec\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u4f18\u8d8a\u6027\uff0c\u4e3a\u8868\u683c\u6570\u636e\u4e0a\u7684\u73b0\u5b9e\u5bf9\u6297\u653b\u51fb\u63d0\u4f9b\u4e86\u9c81\u68d2\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.11541", "categories": ["quant-ph", "cond-mat.stat-mech", "hep-th"], "pdf": "https://arxiv.org/pdf/2507.11541", "abs": "https://arxiv.org/abs/2507.11541", "authors": ["James Stokes"], "title": "Koopman-von Neumann Field Theory", "comment": null, "summary": "The classical many-body problem is reformulated as a bosonic quantum field\ntheory. Quantum field operators evolve unitarily in the Heisenberg picture so\nthat a quantum Vlasov equation is satisfied as an operator identity. The\nformalism enables the direct transfer of techniques from quantum information\nand quantum many-body field theory to classical nonequilibrium statistical\nmechanics. Implications for quantum algorithms are discussed.", "AI": {"tldr": "The classical many-body problem is reformulated as a bosonic quantum field theory, enabling the transfer of quantum techniques to classical statistical mechanics and impacting quantum algorithms.", "motivation": "Reformulating the classical many-body problem as a bosonic quantum field theory.", "method": "The classical many-body problem is reformulated as a bosonic quantum field theory, and quantum field operators evolve unitarily in the Heisenberg picture to satisfy a quantum Vlasov equation as an operator identity.", "result": "A quantum Vlasov equation is satisfied as an operator identity.", "conclusion": "The formalism enables the direct transfer of techniques from quantum information and quantum many-body field theory to classical nonequilibrium statistical mechanics, with implications for quantum algorithms."}}
{"id": "2507.11279", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11279", "abs": "https://arxiv.org/abs/2507.11279", "authors": ["Yujie Zhang", "Sabine Struckmeyer", "Andreas Kolb", "Sven Reichardt"], "title": "Tomato Multi-Angle Multi-Pose Dataset for Fine-Grained Phenotyping", "comment": null, "summary": "Observer bias and inconsistencies in traditional plant phenotyping methods\nlimit the accuracy and reproducibility of fine-grained plant analysis. To\novercome these challenges, we developed TomatoMAP, a comprehensive dataset for\nSolanum lycopersicum using an Internet of Things (IoT) based imaging system\nwith standardized data acquisition protocols. Our dataset contains 64,464 RGB\nimages that capture 12 different plant poses from four camera elevation angles.\nEach image includes manually annotated bounding boxes for seven regions of\ninterest (ROIs), including leaves, panicle, batch of flowers, batch of fruits,\naxillary shoot, shoot and whole plant area, along with 50 fine-grained growth\nstage classifications based on the BBCH scale. Additionally, we provide 3,616\nhigh-resolution image subset with pixel-wise semantic and instance segmentation\nannotations for fine-grained phenotyping. We validated our dataset using a\ncascading model deep learning framework combining MobileNetv3 for\nclassification, YOLOv11 for object detection, and MaskRCNN for segmentation.\nThrough AI vs. Human analysis involving five domain experts, we demonstrate\nthat the models trained on our dataset achieve accuracy and speed comparable to\nthe experts. Cohen's Kappa and inter-rater agreement heatmap confirm the\nreliability of automated fine-grained phenotyping using our approach.", "AI": {"tldr": "\u5f00\u53d1\u4e86 TomatoMAP \u6570\u636e\u96c6\u548c\u57fa\u4e8e\u7269\u8054\u7f51\u7684\u7cfb\u7edf\uff0c\u5b9e\u73b0\u4e86\u4e0e\u4e13\u5bb6\u76f8\u5f53\u7684\u690d\u7269\u8868\u578b\u5206\u6790\u7cbe\u5ea6\u548c\u901f\u5ea6\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u690d\u7269\u8868\u578b\u5206\u6790\u65b9\u6cd5\u4e2d\u5b58\u5728\u7684\u89c2\u5bdf\u8005\u504f\u5dee\u548c\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u4ee5\u63d0\u9ad8\u7ec6\u7c92\u5ea6\u690d\u7269\u5206\u6790\u7684\u51c6\u786e\u6027\u548c\u53ef\u91cd\u590d\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7269\u8054\u7f51\uff08IoT\uff09\u7684\u56fe\u50cf\u91c7\u96c6\u7cfb\u7edf\uff0c\u5e76\u4f7f\u7528\u8be5\u7cfb\u7edf\u6536\u96c6\u4e86\u5305\u542b 64,464 \u5f20 RGB \u56fe\u50cf\u7684 TomatoMAP \u6570\u636e\u96c6\uff0c\u5176\u4e2d\u5305\u542b 12 \u79cd\u4e0d\u540c\u7684\u690d\u7269\u59ff\u52bf\u548c 4 \u4e2a\u76f8\u673a\u4fef\u4ef0\u89d2\u3002\u5bf9 7 \u4e2a\u611f\u5174\u8da3\u533a\u57df\uff08ROIs\uff09\u8fdb\u884c\u4e86\u624b\u52a8\u6807\u6ce8\uff0c\u5e76\u57fa\u4e8e BBCH \u91cf\u8868\u8fdb\u884c\u4e86 50 \u79cd\u7ec6\u7c92\u5ea6\u751f\u957f\u9636\u6bb5\u5206\u7c7b\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5305\u542b 3,616 \u5f20\u9ad8\u5206\u8fa8\u7387\u56fe\u50cf\u7684\u5b50\u96c6\uff0c\u7528\u4e8e\u7ec6\u7c92\u5ea6\u8868\u578b\u5206\u6790\u7684\u50cf\u7d20\u7ea7\u8bed\u4e49\u548c\u5b9e\u4f8b\u5206\u5272\u6807\u6ce8\u3002\u4f7f\u7528\u7ed3\u5408\u4e86 MobileNetv3\uff08\u5206\u7c7b\uff09\u3001YOLOv11\uff08\u5bf9\u8c61\u68c0\u6d4b\uff09\u548c MaskRCNN\uff08\u5206\u5272\uff09\u7684\u7ea7\u8054\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u4e86\u6570\u636e\u96c6\u9a8c\u8bc1\u3002", "result": "\u57fa\u4e8e TomatoMAP \u6570\u636e\u96c6\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u51c6\u786e\u6027\u548c\u901f\u5ea6\u65b9\u9762\u8fbe\u5230\u4e86\u4e0e\u9886\u57df\u4e13\u5bb6\u76f8\u5f53\u7684\u6c34\u5e73\uff0c\u901a\u8fc7 AI vs. \u4eba\u7c7b\u5206\u6790\u3001Cohen's Kappa \u548c\u8bc4\u5206\u8005\u95f4\u4e00\u81f4\u6027\u70ed\u56fe\u9a8c\u8bc1\u4e86\u81ea\u52a8\u5316\u7ec6\u7c92\u5ea6\u8868\u578b\u5206\u6790\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86 TomatoMAP \u6570\u636e\u96c6\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8e\u7269\u8054\u7f51\u7684\u56fe\u50cf\u91c7\u96c6\u7cfb\u7edf\u548c\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\u7ec6\u7c92\u5ea6\u8868\u578b\u5206\u6790\uff0c\u5176\u51c6\u786e\u6027\u548c\u901f\u5ea6\u53ef\u4e0e\u9886\u57df\u4e13\u5bb6\u76f8\u5ab2\u7f8e\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u89c2\u5bdf\u8005\u504f\u5dee\u548c\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\u3002"}}
{"id": "2507.11005", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11005", "abs": "https://arxiv.org/abs/2507.11005", "authors": ["Chongjie Si", "Debing Zhang", "Wei Shen"], "title": "AdaMuon: Adaptive Muon Optimizer", "comment": null, "summary": "We propose AdaMuon, an adaptive learning-rate framework built upon the\nrecently validated Muon optimizer, which has demonstrated substantial\nefficiency gains over AdamW in large-scale model training. AdaMuon augments\nMuon with two mutually dependent modules: (1) a per-parameter second-moment\nmodulation that captures orthogonal gradient updates to ensure update-level\nadaptivity, and (2) a RMS-aligned rescaling that regulates the overall update\nmagnitude by aligning it with the intrinsic structure of the parameter space.\nEmpirical results on multiple model scales and learning-rate regimes confirm\nthat AdaMuon consistently outperforms the original Muon, delivering higher\nacceleration in convergence while maintaining training stability. Our method\nintroduces no additional tuning burden and can be seamlessly integrated into\nexisting Muon training pipelines.", "AI": {"tldr": "AdaMuon \u662f\u4e00\u4e2a\u57fa\u4e8e Muon \u4f18\u5316\u5668\u7684\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u6846\u67b6\uff0c\u901a\u8fc7\u6539\u8fdb\u7684\u4e8c\u9636\u77e9\u4f30\u8ba1\u548c\u91cd\u7f29\u653e\u7b56\u7565\uff0c\u5728\u4e0d\u589e\u52a0\u8c03\u4f18\u8d1f\u62c5\u7684\u60c5\u51b5\u4e0b\uff0c\u63d0\u9ad8\u4e86\u8bad\u7ec3\u901f\u5ea6\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u4e3a\u4e86\u5728 Muon \u4f18\u5316\u5668\u7684\u57fa\u7840\u4e0a\u8fdb\u4e00\u6b65\u63d0\u5347\u6a21\u578b\u8bad\u7ec3\u6548\u7387\uff0c\u514b\u670d AdamW \u5728\u5927\u89c4\u6a21\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa AdaMuon\uff0c\u4e00\u4e2a\u57fa\u4e8e Muon \u4f18\u5316\u5668\u7684\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u6846\u67b6\u3002\u8be5\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u6a21\u5757\uff1a1. \u9010\u53c2\u6570\u4e8c\u9636\u77e9\u8c03\u5236\uff0c\u7528\u4e8e\u6355\u6349\u6b63\u4ea4\u68af\u5ea6\u66f4\u65b0\u4ee5\u5b9e\u73b0\u66f4\u65b0\u7ea7\u522b\u7684\u81ea\u9002\u5e94\uff1b2. RMS \u5bf9\u9f50\u91cd\u7f29\u653e\uff0c\u901a\u8fc7\u5c06\u66f4\u65b0\u5e45\u5ea6\u4e0e\u53c2\u6570\u7a7a\u95f4\u7684\u5185\u5728\u7ed3\u6784\u5bf9\u9f50\u6765\u8c03\u8282\u6574\u4f53\u66f4\u65b0\u5e45\u5ea6\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u89c4\u6a21\u548c\u5b66\u4e60\u7387\u73af\u5883\u4e0b\uff0cAdaMuon \u6301\u7eed\u4f18\u4e8e\u539f\u59cb Muon\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6536\u655b\u52a0\u901f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002\u8be5\u65b9\u6cd5\u4e0d\u5f15\u5165\u989d\u5916\u7684\u8c03\u4f18\u8d1f\u62c5\uff0c\u5e76\u4e14\u53ef\u4ee5\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709\u7684 Muon \u8bad\u7ec3\u6d41\u7a0b\u4e2d\u3002", "conclusion": "AdaMuon \u6846\u67b6\u901a\u8fc7\u5f15\u5165\u9010\u53c2\u6570\u4e8c\u9636\u77e9\u8c03\u5236\u548c RMS \u5bf9\u9f50\u91cd\u7f29\u653e\uff0c\u5728 Muon \u4f18\u5316\u5668\u7684\u57fa\u7840\u4e0a\u5b9e\u73b0\u4e86\u81ea\u9002\u5e94\u5b66\u4e60\u7387\uff0c\u4ece\u800c\u5728\u6a21\u578b\u8bad\u7ec3\u4e2d\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6536\u655b\u52a0\u901f\u5ea6\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002\u8be5\u6846\u67b6\u6613\u4e8e\u96c6\u6210\u4e14\u65e0\u9700\u989d\u5916\u7684\u8c03\u4f18\u3002"}}
{"id": "2507.11012", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11012", "abs": "https://arxiv.org/abs/2507.11012", "authors": ["Dipak Dulal", "Joseph J. Charney", "Michael R. Gallagher", "Pitambar Acharya", "Carmeliza Navasca", "Nicholas S. Skowronski"], "title": "Leveraging Advanced Machine Learning to Predict Turbulence Dynamics from Temperature Observations at an Experimental Prescribed Fire", "comment": "arXiv admin note: text overlap with arXiv:2311.05128", "summary": "This study explores the potential for predicting turbulent kinetic energy\n(TKE) from more readily acquired temperature data using temperature profiles\nand turbulence data collected concurrently at 10 Hz during a small experimental\nprescribed burn in the New Jersey Pine Barrens. Machine learning models,\nincluding Deep Neural Networks, Random Forest Regressor, Gradient Boosting, and\nGaussian Process Regressor, were employed to assess the potential to predict\nTKE from temperature perturbations and explore temporal and spatial dynamics of\ncorrelations. Data visualization and correlation analyses revealed patterns and\nrelationships between thermocouple temperatures and TKE, providing insight into\nthe underlying dynamics. More accurate predictions of TKE were achieved by\nemploying various machine learning models despite a weak correlation between\nthe predictors and the target variable. The results demonstrate significant\nsuccess, particularly from regression models, in accurately predicting the TKE.\nThe findings of this study demonstrate a novel numerical approach to\nidentifying new relationships between temperature and airflow processes in and\naround the fire environment. These relationships can help refine our\nunderstanding of combustion environment processes and the coupling and\ndecoupling of fire environment processes necessary for improving fire\noperations strategy and fire and smoke model predictions. The findings of this\nstudy additionally highlight the valuable role of machine learning techniques\nin analyzing the complex large datasets of the fire environments, showcasing\ntheir potential to advance fire research and management practices.", "AI": {"tldr": "\u5229\u7528\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u901a\u8fc7\u6e29\u5ea6\u6570\u636e\u9884\u6d4b\u706b\u573a\u4e2d\u7684\u6e4d\u6d41\u52a8\u80fd\uff0c\u63d0\u9ad8\u4e86\u9884\u6d4b\u7cbe\u5ea6\uff0c\u6709\u52a9\u4e8e\u6539\u8fdb\u706b\u573a\u7ba1\u7406\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5229\u7528\u66f4\u6613\u83b7\u5f97\u7684\u6e29\u5ea6\u6570\u636e\u9884\u6d4b\u6e4d\u6d41\u52a8\u80fd\uff08TKE\uff09\u7684\u6f5c\u529b\uff0c\u4ee5\u671f\u6539\u8fdb\u5bf9\u706b\u573a\u73af\u5883\u7684\u7406\u89e3\u548c\u706b\u573a\u7ba1\u7406\u7b56\u7565\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u4e86\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5305\u62ec\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u3001\u968f\u673a\u68ee\u6797\u56de\u5f52\u5668\u3001\u68af\u5ea6\u63d0\u5347\u548c\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u5668\uff0c\u5229\u7528\u540c\u6b65\u6536\u96c6\u7684\u6e29\u5ea6\u6570\u636e\uff08\u4ee510\u8d6b\u5179\u91c7\u6837\u7387\uff09\u548c\u6e4d\u6d41\u52a8\u80fd\u6570\u636e\u6765\u9884\u6d4b\u6e4d\u6d41\u52a8\u80fd\u3002\u7814\u7a76\u8fd8\u8fdb\u884c\u4e86\u6570\u636e\u53ef\u89c6\u5316\u548c\u76f8\u5173\u6027\u5206\u6790\uff0c\u4ee5\u63a2\u7d22\u6e29\u5ea6\u6270\u52a8\u4e0e\u6e4d\u6d41\u52a8\u80fd\u4e4b\u95f4\u7684\u65f6\u7a7a\u52a8\u6001\u5173\u7cfb\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u80fd\u591f\u4ece\u6e29\u5ea6\u6270\u52a8\u4e2d\u8f83\u4e3a\u51c6\u786e\u5730\u9884\u6d4bTKE\uff0c\u5176\u4e2d\u56de\u5f52\u6a21\u578b\u8868\u73b0\u5c24\u4e3a\u51fa\u8272\u3002\u7814\u7a76\u53d1\u73b0\u4e86\u6e29 TKE \u4e4b\u95f4\u7684\u6a21\u5f0f\u548c\u5173\u7cfb\uff0c\u5e76\u8bc1\u660e\u4e86\u673a\u5668\u5b66\u4e60\u6280\u672f\u5728\u5206\u6790\u706b\u573a\u590d\u6742\u5927\u6570\u636e\u96c6\u65b9\u9762\u7684\u4ef7\u503c\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u5c3d\u7ba1\u9884\u6d4b\u53d8\u91cf\u4e0e\u76ee\u6807\u53d8\u91cf\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u8f83\u5f31\uff0c\u4f46\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08\u5c24\u5176\u662f\u56de\u5f52\u6a21\u578b\uff09\u5728\u51c6\u786e\u9884\u6d4b\u6e4d\u6d41\u52a8\u80fd\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6210\u529f\u3002\u8fd9\u4e3a\u7406\u89e3\u706b\u573a\u73af\u5883\u4e2d\u7684\u71c3\u70e7\u8fc7\u7a0b\u4ee5\u53ca\u706b\u573a\u8fc7\u7a0b\u7684\u8026\u5408\u4e0e\u89e3\u8026\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\uff0c\u6709\u52a9\u4e8e\u6539\u8fdb\u706b\u573a\u7ba1\u7406\u7b56\u7565\u548c\u706b\u707e/\u70df\u96fe\u6a21\u578b\u9884\u6d4b\u3002"}}
{"id": "2507.11293", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11293", "abs": "https://arxiv.org/abs/2507.11293", "authors": ["J. Senthilnath", "Chen Hao", "F. C. Wellstood"], "title": "3D Magnetic Inverse Routine for Single-Segment Magnetic Field Images", "comment": "copyright 2025 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "summary": "In semiconductor packaging, accurately recovering 3D information is crucial\nfor non-destructive testing (NDT) to localize circuit defects. This paper\npresents a novel approach called the 3D Magnetic Inverse Routine (3D MIR),\nwhich leverages Magnetic Field Images (MFI) to retrieve the parameters for the\n3D current flow of a single-segment. The 3D MIR integrates a deep learning\n(DL)-based Convolutional Neural Network (CNN), spatial-physics-based\nconstraints, and optimization techniques. The method operates in three stages:\ni) The CNN model processes the MFI data to predict ($\\ell/z_o$), where $\\ell$\nis the wire length and $z_o$ is the wire's vertical depth beneath the magnetic\nsensors and classify segment type ($c$). ii) By leveraging\nspatial-physics-based constraints, the routine provides initial estimates for\nthe position ($x_o$, $y_o$, $z_o$), length ($\\ell$), current ($I$), and current\nflow direction (positive or negative) of the current segment. iii) An optimizer\nthen adjusts these five parameters ($x_o$, $y_o$, $z_o$, $\\ell$, $I$) to\nminimize the difference between the reconstructed MFI and the actual MFI. The\nresults demonstrate that the 3D MIR method accurately recovers 3D information\nwith high precision, setting a new benchmark for magnetic image reconstruction\nin semiconductor packaging. This method highlights the potential of combining\nDL and physics-driven optimization in practical applications.", "AI": {"tldr": "3D MIR\u662f\u4e00\u79cd\u7ed3\u5408\u4e86CNN\u3001\u7269\u7406\u7ea6\u675f\u548c\u4f18\u5316\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u901a\u8fc7\u78c1\u573a\u56fe\u50cf\uff08MFI\uff09\u7cbe\u786e\u6062\u590d\u534a\u5bfc\u4f53\u5c01\u88c5\u4e2d\u5bfc\u7ebf\u76843D\u4fe1\u606f\uff0c\u5728\u65e0\u635f\u68c0\u6d4b\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002", "motivation": "\u5728\u534a\u5bfc\u4f53\u5c01\u88c5\u4e2d\uff0c\u4e3a\u4e86\u65e0\u635f\u68c0\u6d4b\uff08NDT\uff09\u5b9a\u4f4d\u7535\u8def\u7f3a\u9677\uff0c\u7cbe\u786e\u6062\u590d3D\u4fe1\u606f\u81f3\u5173\u91cd\u8981\u3002", "method": "3D MIR\u65b9\u6cd5\u6574\u5408\u4e86\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\uff08DL\uff09\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u3001\u57fa\u4e8e\u7a7a\u95f4\u7269\u7406\u7684\u7ea6\u675f\u4ee5\u53ca\u4f18\u5316\u6280\u672f\u3002\u8be5\u65b9\u6cd5\u5206\u4e3a\u4e09\u4e2a\u9636\u6bb5\uff1a1. CNN\u6a21\u578b\u5904\u7406\u78c1\u573a\u56fe\u50cf\uff08MFI\uff09\u6570\u636e\uff0c\u9884\u6d4b\u5bfc\u7ebf\u957f\u5ea6\uff08\u2113\uff09\u548c\u5782\u76f4\u6df1\u5ea6\uff08z_o\uff09\uff0c\u5e76\u5bf9\u7ebf\u6bb5\u7c7b\u578b\uff08c\uff09\u8fdb\u884c\u5206\u7c7b\u30022. \u5229\u7528\u7a7a\u95f4\u7269\u7406\u7ea6\u675f\uff0c\u4e3a\u7ebf\u6bb5\u7684\u4f4d\u7f6e\uff08x_o, y_o, z_o\uff09\u3001\u957f\u5ea6\uff08\u2113\uff09\u3001\u7535\u6d41\uff08I\uff09\u548c\u7535\u6d41\u65b9\u5411\u63d0\u4f9b\u521d\u59cb\u4f30\u8ba1\u30023. \u4f18\u5316\u5668\u8c03\u6574\u8fd9\u4e94\u4e2a\u53c2\u6570\uff08x_o, y_o, z_o, \u2113, I\uff09\uff0c\u4ee5\u6700\u5c0f\u5316\u91cd\u5efa\u7684MFI\u4e0e\u5b9e\u9645MFI\u4e4b\u95f4\u7684\u5dee\u5f02\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c3D MIR\u65b9\u6cd5\u80fd\u591f\u9ad8\u7cbe\u5ea6\u5730\u6062\u590d3D\u4fe1\u606f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u6df1\u5ea6\u5b66\u4e60\u548c\u57fa\u4e8e\u7269\u7406\u7684\u4f18\u5316\uff0c\u5728\u534a\u5bfc\u4f53\u5c01\u88c5\u7684\u78c1\u573a\u56fe\u50cf\u91cd\u5efa\u65b9\u9762\u8bbe\u5b9a\u4e86\u65b0\u7684\u57fa\u51c6\uff0c\u5c55\u793a\u4e86\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.11017", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11017", "abs": "https://arxiv.org/abs/2507.11017", "authors": ["Xingyu Zheng", "Haotong Qin", "Yuye Li", "Jiakai Wang", "Jinyang Guo", "Michele Magno", "Xianglong Liu"], "title": "First-Order Error Matters: Accurate Compensation for Quantized Large Language Models", "comment": null, "summary": "Post-training quantization (PTQ) offers an efficient approach to compressing\nlarge language models (LLMs), significantly reducing memory access and\ncomputational costs. Existing compensation-based weight calibration methods\noften rely on a second-order Taylor expansion to model quantization error,\nunder the assumption that the first-order term is negligible in well-trained\nfull-precision models. However, we reveal that the progressive compensation\nprocess introduces accumulated first-order deviations between latent weights\nand their full-precision counterparts, making this assumption fundamentally\nflawed. To address this, we propose FOEM, a novel PTQ method that explicitly\nincorporates first-order gradient terms to improve quantization error\ncompensation. FOEM approximates gradients by directly computing the difference\nbetween latent and full-precision weights, avoiding the high cost and limited\ngeneralization of backpropagation-based gradient computation. This approach\nintroduces minimal additional computational overhead. Moreover, FOEM leverages\nprecomputed Cholesky factors to efficiently recover the inverse of Hessian\nsubmatrices in real time. Extensive experiments across a wide range of models\nand benchmarks demonstrate that FOEM consistently outperforms the classical\nGPTQ method. In 3-bit weight-only quantization, FOEM reduces the perplexity of\nLlama3-8B by 89.6%, and improves the 5-shot MMLU accuracy of Llama3-70B from\n51.7% to 74.9%, approaching the full-precision performance of 78.6%.\nFurthermore, FOEM can be seamlessly integrated with advanced techniques such as\nGPTAQ and SpinQuant, yielding additional improvements under the challenging\nW4A4KV4 setting, and further narrowing the accuracy gap with full-precision\nbaselines beyond what current state-of-the-art methods achieve. The code is\navailable at https://github.com/Xingyu-Zheng/FOEM.", "AI": {"tldr": "FOEM\u662f\u4e00\u79cd\u65b0\u7684PTQ\u65b9\u6cd5\uff0c\u901a\u8fc7\u8003\u8651\u4e00\u9636\u68af\u5ea6\u9879\u6765\u6539\u8fdb\u91cf\u5316\u7cbe\u5ea6\uff0c\u76f8\u6bd4GPTQ\u5728\u591a\u9879\u4efb\u52a1\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u5e76\u80fd\u4e0e\u5176\u5b83\u9ad8\u7ea7\u6280\u672f\u7ed3\u5408\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u8865\u507f\u7684\u6743\u91cd\u6821\u51c6\u65b9\u6cd5\u5728\u91cf\u5316\u8fc7\u7a0b\u4e2d\uff0c\u5047\u8bbe\u4e00\u9636\u9879\u53ef\u5ffd\u7565\uff0c\u4f46\u7814\u7a76\u63ed\u793a\u4e86\u7d2f\u79ef\u7684\u7b2c\u4e00\u9636\u504f\u5dee\u4f7f\u5f97\u8fd9\u4e00\u5047\u8bbe\u5931\u6548\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684PTQ\u65b9\u6cd5\u6765\u66f4\u51c6\u786e\u5730\u8865\u507f\u91cf\u5316\u8bef\u5dee\u3002", "method": "FOEM\u662f\u4e00\u79cd\u65b0\u9896\u7684\u540e\u8bad\u7ec3\u91cf\u5316\uff08PTQ\uff09\u65b9\u6cd5\uff0c\u5b83\u901a\u8fc7\u76f4\u63a5\u8ba1\u7b97\u6f5c\u5728\u6743\u91cd\u548c\u5168\u7cbe\u5ea6\u6743\u91cd\u4e4b\u95f4\u7684\u5dee\u5f02\u6765\u8fd1\u4f3c\u68af\u5ea6\uff0c\u4ece\u800c\u663e\u5f0f\u5730\u5305\u542b\u4e00\u9636\u68af\u5ea6\u9879\u4ee5\u6539\u8fdb\u91cf\u5316\u8bef\u5dee\u8865\u507f\u3002\u8be5\u65b9\u6cd5\u5f15\u5165\u4e86\u6700\u5c0f\u7684\u989d\u5916\u8ba1\u7b97\u5f00\u9500\uff0c\u5e76\u5229\u7528\u9884\u8ba1\u7b97\u7684\u4e54\u52d2\u65af\u57fa\u56e0\u5b50\u6765\u9ad8\u6548\u5730\u5b9e\u65f6\u6062\u590d\u9ed1\u585e\u77e9\u9635\u7684\u9006\u3002", "result": "FOEM\u57283\u4f4d\u6743\u91cd\u91cf\u5316\u65b9\u9762\uff0c\u5c06Llama3-8B\u7684\u56f0\u60d1\u5ea6\u964d\u4f4e\u4e8689.6%\uff0c\u5e76\u5c06Llama3-70B\u76845\u6b21MMLU\u51c6\u786e\u7387\u4ece51.7%\u63d0\u9ad8\u523074.9%\uff0c\u63a5\u8fd1\u5168\u7cbe\u5ea6\u6a21\u578b\u768478.6%\u3002\u6b64\u5916\uff0cFOEM\u4e0eGPTAQ\u548cSpinQuant\u7b49\u6280\u672f\u96c6\u6210\uff0c\u5728W4A4KV4\u8bbe\u7f6e\u4e0b\u53d6\u5f97\u4e86\u8fdb\u4e00\u6b65\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u6709\u6548\u7f29\u5c0f\u4e86\u4e0e\u5168\u7cbe\u5ea6\u57fa\u7ebf\u7684\u7cbe\u5ea6\u5dee\u8ddd\u3002", "conclusion": "FOEM \u65b9\u6cd5\u901a\u8fc7\u663e\u5f0f\u7eb3\u5165\u4e00\u9636\u68af\u5ea6\u9879\u6765\u6539\u8fdb\u91cf\u5316\u8bef\u5dee\u8865\u507f\uff0c\u907f\u514d\u4e86\u57fa\u4e8e\u53cd\u5411\u4f20\u64ad\u7684\u68af\u5ea6\u8ba1\u7b97\u7684\u9ad8\u6210\u672c\u548c\u6cdb\u5316\u6027\u9650\u5236\uff0c\u5e76\u5229\u7528\u9884\u8ba1\u7b97\u7684\u4e54\u52d2\u65af\u57fa\u56e0\u5b50\u5b9e\u65f6\u6709\u6548\u5730\u6062\u590d\u9ed1\u585e\u77e9\u9635\u5b50\u77e9\u9635\u7684\u9006\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cFOEM\u5728\u5404\u79cd\u6a21\u578b\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6301\u7eed\u4f18\u4e8e\u7ecf\u5178\u7684GPTQ\u65b9\u6cd5\uff0c\u5c24\u5176\u662f\u57283\u4f4d\u6743\u91cd\u91cf\u5316\u65b9\u9762\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u56f0\u60d1\u5ea6\u5e76\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\uff0c\u540c\u65f6\u8fd8\u80fd\u4e0eGPTAQ\u548cSpinQuant\u7b49\u5148\u8fdb\u6280\u672f\u65e0\u7f1d\u96c6\u6210\uff0c\u8fdb\u4e00\u6b65\u7f29\u5c0f\u4e86\u4e0e\u5168\u7cbe\u5ea6\u57fa\u7ebf\u7684\u5dee\u8ddd\u3002"}}
{"id": "2507.11301", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11301", "abs": "https://arxiv.org/abs/2507.11301", "authors": ["Pa\u00fal Maji", "Marlon T\u00faquerres", "Stalin Valencia", "Marcela Valenzuela", "Christian Mejia-Escobar"], "title": "Detecci\u00f3n y Cuantificaci\u00f3n de Erosi\u00f3n Fluvial con Visi\u00f3n Artificial", "comment": "18 pages, in Spanish language, 13 figures, 4 tables", "summary": "Fluvial erosion is a natural process that can generate significant impacts on\nsoil stability and strategic infrastructures. The detection and monitoring of\nthis phenomenon is traditionally addressed by photogrammetric methods and\nanalysis in geographic information systems. These tasks require specific\nknowledge and intensive manual processing. This study proposes an artificial\nintelligence-based approach for automatic identification of eroded zones and\nestimation of their area. The state-of-the-art computer vision model YOLOv11,\nadjusted by fine-tuning and trained with photographs and LiDAR images, is used.\nThis combined dataset was segmented and labeled using the Roboflow platform.\nExperimental results indicate efficient detection of erosion patterns with an\naccuracy of 70%, precise identification of eroded areas and reliable\ncalculation of their extent in pixels and square meters. As a final product,\nthe EROSCAN system has been developed, an interactive web application that\nallows users to upload images and obtain automatic segmentations of fluvial\nerosion, together with the estimated area. This tool optimizes the detection\nand quantification of the phenomenon, facilitating decision making in risk\nmanagement and territorial planning.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528YOLOv11\u548cLiDAR\u56fe\u50cf\u5f00\u53d1\u4e86EROSCAN\u7cfb\u7edf\uff0c\u53ef\u81ea\u52a8\u68c0\u6d4b\u548c\u91cf\u5316\u6cb3\u6d41\u4fb5\u8680\u533a\u57df\uff0c\u51c6\u786e\u7387\u8fbe70%\u3002", "motivation": "\u4e3a\u4e86\u514b\u670d\u4f20\u7edf\u65b9\u6cd5\u5728\u68c0\u6d4b\u548c\u76d1\u6d4b\u6cb3\u6d41\u4fb5\u8680\u65b9\u9762\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\u548c\u5927\u91cf\u624b\u52a8\u5904\u7406\u7684\u7f3a\u70b9\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u57fa\u4e8e\u4eba\u5de5\u667a\u80fd\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u57fa\u4e8e\u4eba\u5de5\u667a\u80fd\u7684\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u7ecf\u8fc7\u5fae\u8c03\u548c\u8bad\u7ec3\u7684YOLOv11\u8ba1\u7b97\u673a\u89c6\u89c9\u6a21\u578b\uff0c\u5e76\u7ed3\u5408\u4e86\u7167\u7247\u548cLiDAR\u56fe\u50cf\uff0c\u5229\u7528Roboflow\u5e73\u53f0\u8fdb\u884c\u5206\u5272\u548c\u6807\u6ce8\uff0c\u4ee5\u81ea\u52a8\u8bc6\u522b\u4fb5\u8680\u533a\u57df\u5e76\u4f30\u7b97\u5176\u9762\u79ef\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u4ee570%\u7684\u51c6\u786e\u7387\u6709\u6548\u68c0\u6d4b\u4fb5\u8680\u6a21\u5f0f\uff0c\u7cbe\u786e\u8bc6\u522b\u4fb5\u8680\u533a\u57df\uff0c\u5e76\u53ef\u9760\u5730\u8ba1\u7b97\u5176\u50cf\u7d20\u548c\u5e73\u65b9\u7c73\u7684\u8303\u56f4\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aEROSCAN\u7684\u4ea4\u4e92\u5f0fWeb\u5e94\u7528\u7a0b\u5e8f\uff0c\u53ef\u4ee5\u81ea\u52a8\u8bc6\u522b\u6cb3\u6d41\u4fb5\u8680\u533a\u57df\u5e76\u8ba1\u7b97\u5176\u9762\u79ef\uff0c\u4ece\u800c\u4f18\u5316\u4e86\u98ce\u9669\u7ba1\u7406\u548c\u533a\u57df\u89c4\u5212\u4e2d\u7684\u51b3\u7b56\u3002"}}
{"id": "2507.11019", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11019", "abs": "https://arxiv.org/abs/2507.11019", "authors": ["Claas Voelcker", "Axel Brunnbauer", "Marcel Hussing", "Michal Nauman", "Pieter Abbeel", "Eric Eaton", "Radu Grosu", "Amir-massoud Farahmand", "Igor Gilitschenski"], "title": "Relative Entropy Pathwise Policy Optimization", "comment": null, "summary": "Score-function policy gradients have delivered strong results in\ngame-playing, robotics and language-model fine-tuning. Yet its high-variance\noften undermines training stability. On the other hand, pathwise policy\ngradients alleviate the training variance, but are reliable only when driven by\nan accurate action-conditioned value function which is notoriously hard to\ntrain without relying on past off-policy data. In this paper, we discuss how to\nconstruct a value-gradient driven, on-policy algorithm that allow training\nQ-value models purely from on-policy data, unlocking the possibility of using\npathwise policy updates in the context of on-policy learning. We show how to\nbalance stochastic policies for exploration with constrained policy updates for\nstable training, and evaluate important architectural components that\nfacilitate accurate value function learning. Building on these insights, we\npropose Relative Entropy Pathwise Policy Optimization (REPPO), an efficient\non-policy algorithm that combines the sample-efficiency of pathwise policy\ngradients with the simplicity and minimal memory footprint of standard\non-policy learning. We demonstrate that REPPO provides strong empirical\nperformance at decreased sample requirements, wall-clock time, memory footprint\nas well as high hyperparameter robustness in a set of experiments on two\nstandard GPU-parallelized benchmarks.", "AI": {"tldr": "REPPO\u662f\u4e00\u79cd\u65b0\u7684\u5728\u7ebf\u7b56\u7565\u7b97\u6cd5\uff0c\u5b83\u89e3\u51b3\u4e86\u4f20\u7edf\u5728\u7ebf\u7b56\u7565\u65b9\u6cd5\u7684\u9ad8\u65b9\u5dee\u548c\u8def\u5f84\u7b56\u7565\u68af\u5ea6\u5bf9\u79bb\u7ebf\u6570\u636e\u7684\u4f9d\u8d56\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u6837\u672c\u6548\u7387\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u7684\u7ed3\u5408\u3002", "motivation": "\u5f97\u5206\u51fd\u6570\u7b56\u7565\u68af\u5ea6\u5728\u6e38\u620f\u3001\u673a\u5668\u4eba\u548c\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6210\u679c\uff0c\u4f46\u9ad8\u65b9\u5dee\u5f80\u5f80\u4f1a\u7834\u574f\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u8def\u5f84\u7b56\u7565\u68af\u5ea6\u53ef\u4ee5\u7f13\u89e3\u8bad\u7ec3\u65b9\u5dee\uff0c\u4f46\u4ec5\u5728\u7531\u51c6\u786e\u7684\u52a8\u4f5c\u6761\u4ef6\u4ef7\u503c\u51fd\u6570\u9a71\u52a8\u65f6\u624d\u53ef\u9760\uff0c\u800c\u8fd9\u79cd\u4ef7\u503c\u51fd\u6570\u5728\u6ca1\u6709\u8fc7\u53bb\u7684\u79bb\u7ebf\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u5e38\u5f88\u96be\u8fdb\u884c\u8bad\u7ec3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4ef7\u503c\u68af\u5ea6\u9a71\u52a8\u7684\u5728\u7ebf\u7b56\u7565\u7b97\u6cd5\uff0c\u53ef\u4ee5\u4ec5\u4ece\u5728\u7ebf\u6570\u636e\u4e2d\u8bad\u7ec3Q\u503c\u6a21\u578b\uff0c\u4ece\u800c\u5728\u5728\u7ebf\u5b66\u4e60\u7684\u80cc\u666f\u4e0b\u5b9e\u73b0\u8def\u5f84\u7b56\u7565\u66f4\u65b0\u3002\u8ba8\u8bba\u4e86\u5982\u4f55\u5728\u63a2\u7d22\u7684\u968f\u673a\u7b56\u7565\u4e0e\u7a33\u5b9a\u7684\u8bad\u7ec3\u7ea6\u675f\u7b56\u7565\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u5e76\u8bc4\u4f30\u4e86\u4fc3\u8fdb\u51c6\u786e\u4ef7\u503c\u51fd\u6570\u5b66\u4e60\u7684\u91cd\u8981\u7ed3\u6784\u7ec4\u4ef6\u3002", "result": "REPPO\u5728\u4e24\u4e2a\u6807\u51c6\u7684GPU\u5e76\u884c\u57fa\u51c6\u6d4b\u8bd5\u7684\u5b9e\u9a8c\u4e2d\uff0c\u5c55\u73b0\u4e86\u5f3a\u5927\u7684\u7ecf\u9a8c\u6027\u80fd\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u6837\u672c\u9700\u6c42\u3001\u8fd0\u884c\u65f6\u95f4\u548c\u5185\u5b58\u5360\u7528\uff0c\u5e76\u4e14\u5177\u6709\u9ad8\u8d85\u53c2\u6570\u9c81\u68d2\u6027\u3002", "conclusion": "REPPO\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u5728\u7ebf\u7b56\u7565\u7b97\u6cd5\uff0c\u7ed3\u5408\u4e86\u8def\u5f84\u7b56\u7565\u68af\u5ea6\u7684\u6837\u672c\u6548\u7387\u548c\u6807\u51c6\u5728\u7ebf\u5b66\u4e60\u7684\u7b80\u5355\u6027\u53ca\u6700\u5c0f\u5185\u5b58\u5360\u7528\u3002"}}
{"id": "2507.11321", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11321", "abs": "https://arxiv.org/abs/2507.11321", "authors": ["Haoxuan Qu", "Yujun Cai", "Hossein Rahmani", "Ajay Kumar", "Junsong Yuan", "Jun Liu"], "title": "A Mixed-Primitive-based Gaussian Splatting Method for Surface Reconstruction", "comment": null, "summary": "Recently, Gaussian Splatting (GS) has received a lot of attention in surface\nreconstruction. However, while 3D objects can be of complex and diverse shapes\nin the real world, existing GS-based methods only limitedly use a single type\nof splatting primitive (Gaussian ellipse or Gaussian ellipsoid) to represent\nobject surfaces during their reconstruction. In this paper, we highlight that\nthis can be insufficient for object surfaces to be represented in high quality.\nThus, we propose a novel framework that, for the first time, enables Gaussian\nSplatting to incorporate multiple types of (geometrical) primitives during its\nsurface reconstruction process. Specifically, in our framework, we first\npropose a compositional splatting strategy, enabling the splatting and\nrendering of different types of primitives in the Gaussian Splatting pipeline.\nIn addition, we also design our framework with a mixed-primitive-based\ninitialization strategy and a vertex pruning mechanism to further promote its\nsurface representation learning process to be well executed leveraging\ndifferent types of primitives. Extensive experiments show the efficacy of our\nframework and its accurate surface reconstruction performance.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9ad8\u65af\u55b7\u6d82\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u591a\u79cd\u51e0\u4f55\u56fe\u5143\uff08\u5982\u692d\u5706\u548c\u692d\u7403\uff09\u6765\u63d0\u9ad83D\u8868\u9762\u91cd\u5efa\u7684\u8d28\u91cf\u548c\u7ec6\u8282\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u9ad8\u65af\u55b7\u6d82\uff08GS\uff09\u7684\u65b9\u6cd5\u5728\u8868\u9762\u91cd\u5efa\u65f6\u4ec5\u9650\u4e8e\u4f7f\u7528\u5355\u4e00\u7c7b\u578b\u7684\u55b7\u6d82\u56fe\u5143\uff08\u9ad8\u65af\u692d\u5706\u6216\u9ad8\u65af\u692d\u7403\uff09\uff0c\u8fd9\u5bf9\u4e8e\u8868\u793a\u73b0\u5b9e\u4e16\u754c\u4e2d\u590d\u6742\u591a\u6837\u7684\u7269\u4f53\u8868\u9762\u53ef\u80fd\u4e0d\u591f\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u5229\u7528\u591a\u79cd\u56fe\u5143\u6765\u63d0\u9ad8\u8868\u9762\u91cd\u5efa\u8d28\u91cf\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6846\u67b6\uff0c\u9996\u6b21\u5b9e\u73b0\u4e86\u5728\u9ad8\u65af\u55b7\u6d82\u7684\u8868\u9762\u91cd\u5efa\u8fc7\u7a0b\u4e2d\u6574\u5408\u591a\u79cd\u51e0\u4f55\u56fe\u5143\uff08\u5982\u9ad8\u65af\u692d\u5706\u548c\u9ad8\u65af\u692d\u7403\uff09\u3002\u8be5\u6846\u67b6\u5305\u62ec\u4e00\u4e2a\u7ec4\u5408\u55b7\u6d82\u7b56\u7565\uff0c\u5141\u8bb8\u5728\u55b7\u6d82\u548c\u6e32\u67d3\u8fc7\u7a0b\u4e2d\u4f7f\u7528\u4e0d\u540c\u7c7b\u578b\u7684\u56fe\u5143\uff1b\u4e00\u4e2a\u57fa\u4e8e\u6df7\u5408\u56fe\u5143\u7684\u521d\u59cb\u5316\u7b56\u7565\uff1b\u4ee5\u53ca\u4e00\u4e2a\u9876\u70b9\u4fee\u526a\u673a\u5236\uff0c\u4ee5\u4f18\u5316\u5b66\u4e60\u8fc7\u7a0b\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u4ee5\u53ca\u5176\u5728\u8868\u9762\u91cd\u5efa\u65b9\u9762\u51c6\u786e\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u6574\u5408\u591a\u79cd\u51e0\u4f55\u56fe\u5143\uff0c\u63d0\u9ad8\u4e86\u9ad8\u65af\u55b7\u6d82\u5728\u8868\u9762\u91cd\u5efa\u4e2d\u7684\u8868\u9762\u8868\u793a\u80fd\u529b\u548c\u91cd\u5efa\u8d28\u91cf\u3002\u901a\u8fc7\u7ec4\u5408\u55b7\u6d82\u7b56\u7565\u3001\u6df7\u5408\u56fe\u5143\u521d\u59cb\u5316\u548c\u9876\u70b9\u4fee\u526a\u673a\u5236\uff0c\u8be5\u6846\u67b6\u5728\u4e0d\u540c\u7c7b\u578b\u56fe\u5143\u7684\u5229\u7528\u4e0a\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2507.11515", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.11515", "abs": "https://arxiv.org/abs/2507.11515", "authors": ["Shiyi Yang", "Xiaoxue Yu", "Rongpeng Li", "Jianhang Zhu", "Zhifeng Zhao", "Honggang Zhang"], "title": "AirLLM: Diffusion Policy-based Adaptive LoRA for Remote Fine-Tuning of LLM over the Air", "comment": "11 pages, 8 figures", "summary": "Operating Large Language Models (LLMs) on edge devices is increasingly\nchallenged by limited communication bandwidth and strained computational and\nmemory costs. Thus, cloud-assisted remote fine-tuning becomes indispensable.\nNevertheless, existing Low-Rank Adaptation (LoRA) approaches typically employ\nfixed or heuristic rank configurations, and the subsequent over-the-air\ntransmission of all LoRA parameters could be rather inefficient. To address\nthis limitation, we develop AirLLM, a hierarchical diffusion policy framework\nfor communication-aware LoRA adaptation. Specifically, AirLLM models the rank\nconfiguration as a structured action vector that spans all LoRA-inserted\nprojections. To solve the underlying high-dimensional sequential\ndecision-making problem, a Proximal Policy Optimization (PPO) agent generates\ncoarse-grained decisions by jointly observing wireless states and linguistic\ncomplexity, which are then refined via Denoising Diffusion Implicit Models\n(DDIM) to produce high-resolution, task- and channel-adaptive rank vectors. The\ntwo modules are optimized alternatively, with the DDIM trained under the\nClassifier-Free Guidance (CFG) paradigm to maintain alignment with PPO rewards.\nExperiments under varying signal-to-noise ratios demonstrate that AirLLM\nconsistently enhances fine-tuning performance while significantly reducing\ntransmission costs, highlighting the effectiveness of reinforcement-driven,\ndiffusion-refined rank adaptation for scalable and efficient remote fine-tuning\nover the air.", "AI": {"tldr": "AirLLM\u901a\u8fc7\u5206\u5c42\u6269\u6563\u7b56\u7565\uff0c\u5229\u7528PPO\u548cDDIM\u4f18\u5316LoRA\u7684\u79e9\u914d\u7f6e\uff0c\u89e3\u51b3\u4e86\u8fb9\u7f18\u8bbe\u5907LLM\u8fdc\u7a0b\u5fae\u8c03\u7684\u901a\u4fe1\u6548\u7387\u548c\u6027\u80fd\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u4f4e\u79e9\u81ea\u9002\u5e94\uff08LoRA\uff09\u65b9\u6cd5\u5728\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u90e8\u7f72\u5230\u8fb9\u7f18\u8bbe\u5907\u65f6\uff0c\u9762\u4e34\u901a\u4fe1\u5e26\u5bbd\u6709\u9650\u4ee5\u53ca\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\u9ad8\u6602\u7684\u6311\u6218\u3002\u73b0\u6709\u7684LoRA\u65b9\u6cd5\u901a\u5e38\u91c7\u7528\u56fa\u5b9a\u7684\u6216\u542f\u53d1\u5f0f\u7684\u79e9\u914d\u7f6e\uff0c\u5e76\u4e14\u540e\u7eed\u6240\u6709LoRA\u53c2\u6570\u7684\u65e0\u7ebf\u4f20\u8f93\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAirLLM\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u91c7\u7528\u5206\u5c42\u6269\u6563\u7b56\u7565\u6765\u5904\u7406\u901a\u4fe1\u611f\u77e5\u7684LoRA\u81ea\u9002\u5e94\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5b83\u5c06\u79e9\u914d\u7f6e\u5efa\u6a21\u4e3a\u4e00\u4e2a\u8de8\u8d8a\u6240\u6709LoRA\u63d2\u5165\u6295\u5f71\u7684\u7ed3\u6784\u5316\u52a8\u4f5c\u5411\u91cf\u3002\u8be5\u6846\u67b6\u4f7f\u7528Proximal Policy Optimization\uff08PPO\uff09\u4ee3\u7406\u6765\u751f\u6210\u7c97\u7c92\u5ea6\u7684\u51b3\u7b56\uff0c\u540c\u65f6\u8003\u8651\u65e0\u7ebf\u72b6\u6001\u548c\u8bed\u8a00\u590d\u6742\u5ea6\uff0c\u7136\u540e\u901a\u8fc7Denoising Diffusion Implicit Models\uff08DDIM\uff09\u8fdb\u884c\u7ec6\u5316\uff0c\u751f\u6210\u9ad8\u5206\u8fa8\u7387\u3001\u4efb\u52a1\u548c\u4fe1\u9053\u81ea\u9002\u5e94\u7684\u79e9\u5411\u91cf\u3002PPO\u548cDDIM\u6a21\u5757\u4ea4\u66ff\u4f18\u5316\uff0c\u5176\u4e2dDDIM\u5728Classifier-Free Guidance\uff08CFG\uff09\u8303\u5f0f\u4e0b\u8fdb\u884c\u8bad\u7ec3\uff0c\u4ee5\u4e0ePPO\u5956\u52b1\u4fdd\u6301\u4e00\u81f4\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAirLLM\u5728\u4e0d\u540c\u4fe1\u566a\u6bd4\u4e0b\uff0c\u80fd\u591f\u6301\u7eed\u63d0\u5347\u5fae\u8c03\u6027\u80fd\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4f20\u8f93\u6210\u672c\uff0c\u8bc1\u660e\u4e86\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u9a71\u52a8\u3001\u6269\u6563\u6a21\u578b\u7ec6\u5316\u7684\u79e9\u81ea\u9002\u5e94\u65b9\u6cd5\u5728\u53ef\u6269\u5c55\u548c\u9ad8\u6548\u7684\u65e0\u7ebf\u8fdc\u7a0b\u5fae\u8c03\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "AirLLM\u901a\u8fc7\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u6269\u6563\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u901a\u4fe1\u611f\u77e5\u7684LoRA\u81ea\u9002\u5e94\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u8fdb\u884c\u8fdc\u7a0b\u6a21\u578b\u5fae\u8c03\u7684\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2507.11053", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11053", "abs": "https://arxiv.org/abs/2507.11053", "authors": ["Danish Gufran", "Sudeep Pasricha"], "title": "GATE: Graph Attention Neural Networks with Real-Time Edge Construction for Robust Indoor Localization using Mobile Embedded Devices", "comment": null, "summary": "Accurate indoor localization is crucial for enabling spatial context in smart\nenvironments and navigation systems. Wi-Fi Received Signal Strength (RSS)\nfingerprinting is a widely used indoor localization approach due to its\ncompatibility with mobile embedded devices. Deep Learning (DL) models improve\naccuracy in localization tasks by learning RSS variations across locations, but\nthey assume fingerprint vectors exist in a Euclidean space, failing to\nincorporate spatial relationships and the non-uniform distribution of\nreal-world RSS noise. This results in poor generalization across heterogeneous\nmobile devices, where variations in hardware and signal processing distort RSS\nreadings. Graph Neural Networks (GNNs) can improve upon conventional DL models\nby encoding indoor locations as nodes and modeling their spatial and signal\nrelationships as edges. However, GNNs struggle with non-Euclidean noise\ndistributions and suffer from the GNN blind spot problem, leading to degraded\naccuracy in environments with dense access points (APs). To address these\nchallenges, we propose GATE, a novel framework that constructs an adaptive\ngraph representation of fingerprint vectors while preserving an indoor\nstate-space topology, modeling the non-Euclidean structure of RSS noise to\nmitigate environmental noise and address device heterogeneity. GATE introduces\n1) a novel Attention Hyperspace Vector (AHV) for enhanced message passing, 2) a\nnovel Multi-Dimensional Hyperspace Vector (MDHV) to mitigate the GNN blind\nspot, and 3) an new Real-Time Edge Construction (RTEC) approach for dynamic\ngraph adaptation. Extensive real-world evaluations across multiple indoor\nspaces with varying path lengths, AP densities, and heterogeneous devices\ndemonstrate that GATE achieves 1.6x to 4.72x lower mean localization errors and\n1.85x to 4.57x lower worst-case errors compared to state-of-the-art indoor\nlocalization frameworks.", "AI": {"tldr": " GATE\u662f\u4e00\u79cd\u65b0\u9896\u7684\u5ba4\u5185\u5b9a\u4f4d\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u56fe\u8868\u793a\u548c\u521b\u65b0\u7684\u5411\u91cf\u8bbe\u8ba1\uff0c\u6709\u6548\u89e3\u51b3\u4e86Wi-Fi RSS\u6307\u7eb9\u5b9a\u4f4d\u4e2d\u7684\u8bbe\u5907\u5f02\u8d28\u6027\u548c\u975e\u6b27\u51e0\u91cc\u5f97\u566a\u58f0\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5b9a\u4f4d\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eWi-Fi RSS\u6307\u7eb9\u7684\u5ba4\u5185\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u65e0\u8bba\u662f\u4f20\u7edf\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8fd8\u662f\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u90fd\u672a\u80fd\u6709\u6548\u5904\u7406\u771f\u5b9e\u4e16\u754c\u4e2dRSS\u566a\u58f0\u7684\u975e\u6b27\u51e0\u91cc\u5f97\u5206\u5e03\u4ee5\u53ca\u8bbe\u5907\u5f02\u8d28\u6027\u95ee\u9898\u3002\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5ffd\u7565\u4e86\u7a7a\u95f4\u5173\u7cfb\u548c\u975e\u5747\u5300\u566a\u58f0\uff0c\u800c\u56fe\u795e\u7ecf\u7f51\u7edc\u5219\u5728\u5904\u7406\u975e\u6b27\u51e0\u91cc\u5f97\u566a\u58f0\u548c\u89e3\u51b3AP\u5bc6\u96c6\u73af\u5883\u4e0b\u7684\u76f2\u70b9\u95ee\u9898\u65f6\u5b58\u5728\u4e0d\u8db3\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u6846\u67b6\u6765\u514b\u670d\u8fd9\u4e9b\u6311\u6218\uff0c\u63d0\u9ad8\u5ba4\u5185\u5b9a\u4f4d\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "method": "GATE\u6846\u67b6\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u81ea\u9002\u5e94\u7684\u56fe\u8868\u793a\u6765\u7f16\u7801\u5ba4\u5185\u5b9a\u4f4d\u4fe1\u606f\u3002\u5177\u4f53\u5305\u62ec\uff1a1\uff09\u6ce8\u610f\u529b\u8d85\u7a7a\u95f4\u5411\u91cf\uff08AHV\uff09\uff0c\u7528\u4e8e\u589e\u5f3a\u6d88\u606f\u4f20\u9012\uff1b2\uff09\u591a\u7ef4\u8d85\u7a7a\u95f4\u5411\u91cf\uff08MDHV\uff09\uff0c\u7528\u4e8e\u7f13\u89e3\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u76f2\u70b9\u95ee\u9898\uff1b3\uff09\u5b9e\u65f6\u8fb9\u7f18\u6784\u5efa\uff08RTEC\uff09\uff0c\u7528\u4e8e\u52a8\u6001\u9002\u5e94\u56fe\u7ed3\u6784\u3002\u8fd9\u4e9b\u65b9\u6cd5\u65e8\u5728\u6a21\u62dfRSS\u566a\u58f0\u7684\u975e\u6b27\u51e0\u91cc\u5f97\u7ed3\u6784\uff0c\u4ee5\u51cf\u8f7b\u73af\u5883\u566a\u58f0\u548c\u8bbe\u5907\u5f02\u8d28\u6027\u5e26\u6765\u7684\u5f71\u54cd\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u7684\u591a\u6837\u5316\u5ba4\u5185\u73af\u5883\u4e2d\u8fdb\u884c\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cGATE\u6846\u67b6\u5728\u4e0d\u540c\u8def\u5f84\u957f\u5ea6\u3001AP\u5bc6\u5ea6\u548c\u5f02\u8d28\u8bbe\u5907\u6761\u4ef6\u4e0b\uff0c\u5e73\u5747\u5b9a\u4f4d\u8bef\u5dee\u6bd4\u6700\u5148\u8fdb\u7684\u5ba4\u5185\u5b9a\u4f4d\u6846\u67b6\u4f4e1.6\u500d\u81f34.72\u500d\uff0c\u6700\u574f\u60c5\u51b5\u4e0b\u7684\u8bef\u5dee\u4e5f\u964d\u4f4e\u4e861.85\u500d\u81f34.57\u500d\u3002", "conclusion": "GATE\u6846\u67b6\u901a\u8fc7\u81ea\u9002\u5e94\u56fe\u8868\u793a\u3001\u6ce8\u610f\u529b\u8d85\u7a7a\u95f4\u5411\u91cf\uff08AHV\uff09\u3001\u591a\u7ef4\u8d85\u7a7a\u95f4\u5411\u91cf\uff08MDHV\uff09\u548c\u5b9e\u65f6\u8fb9\u7f18\u6784\u5efa\uff08RTEC\uff09\u7b49\u6280\u672f\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u5ba4\u5185\u5b9a\u4f4d\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u975e\u6b27\u51e0\u91cc\u5f97\u566a\u58f0\u548c\u8bbe\u5907\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5b9a\u4f4d\u8bef\u5dee\uff0c\u5728\u771f\u5b9e\u4e16\u754c\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002"}}
{"id": "2507.11325", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11325", "abs": "https://arxiv.org/abs/2507.11325", "authors": ["Arefin Ittesafun Abian", "Ripon Kumar Debnath", "Md. Abdur Rahman", "Mohaimenul Azam Khan Raiaan", "Md Rafiqul Islam", "Asif Karim", "Reem E. Mohamed", "Sami Azam"], "title": "HANS-Net: Hyperbolic Convolution and Adaptive Temporal Attention for Accurate and Generalizable Liver and Tumor Segmentation in CT Imaging", "comment": "10 figures. Will be submitted to IEEE Transactions on Radiation and\n  Plasma Medical Sciences", "summary": "Accurate liver and tumor segmentation on abdominal CT images is critical for\nreliable diagnosis and treatment planning, but remains challenging due to\ncomplex anatomical structures, variability in tumor appearance, and limited\nannotated data. To address these issues, we introduce Hyperbolic-convolutions\nAdaptive-temporal-attention with Neural-representation and Synaptic-plasticity\nNetwork (HANS-Net), a novel segmentation framework that synergistically\ncombines hyperbolic convolutions for hierarchical geometric representation, a\nwavelet-inspired decomposition module for multi-scale texture learning, a\nbiologically motivated synaptic plasticity mechanism for adaptive feature\nenhancement, and an implicit neural representation branch to model fine-grained\nand continuous anatomical boundaries. Additionally, we incorporate\nuncertainty-aware Monte Carlo dropout to quantify prediction confidence and\nlightweight temporal attention to improve inter-slice consistency without\nsacrificing efficiency. Extensive evaluations of the LiTS dataset demonstrate\nthat HANS-Net achieves a mean Dice score of 93.26%, an IoU of 88.09%, an\naverage symmetric surface distance (ASSD) of 0.72 mm, and a volume overlap\nerror (VOE) of 11.91%. Furthermore, cross-dataset validation on the\n3D-IRCADb-01 dataset obtains an average Dice of 87.45%, IoU of 80.30%, ASSD of\n1.525 mm, and VOE of 19.71%, indicating strong generalization across different\ndatasets. These results confirm the effectiveness and robustness of HANS-Net in\nproviding anatomically consistent, accurate, and confident liver and tumor\nsegmentation.", "AI": {"tldr": "HANS-Net\u662f\u4e00\u500b\u7528\u65bc\u809d\u81df\u548c\u816b\u7624\u5206\u5272\u7684\u65b0\u6846\u67b6\uff0c\u901a\u904e\u7d50\u5408\u591a\u7a2e\u5148\u9032\u6280\u8853\uff0c\u5728\u6e96\u78ba\u6027\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u53d6\u5f97\u4e86\u512a\u7570\u7684\u7d50\u679c\u3002", "motivation": "\u6e96\u78ba\u7684\u809d\u81df\u548c\u816b\u7624\u5206\u5272\u5c0d\u65bc\u53ef\u9760\u7684\u8a3a\u65b7\u548c\u6cbb\u7642\u8a08\u5283\u81f3\u95dc\u91cd\u8981\uff0c\u4f46\u7531\u65bc\u8907\u96dc\u7684\u89e3\u5256\u7d50\u69cb\u3001\u816b\u7624\u5916\u89c0\u7684\u5dee\u7570\u4ee5\u53ca\u6a19\u8a3b\u6578\u64da\u7684\u9650\u5236\uff0c\u4ecd\u7136\u5177\u6709\u6311\u6230\u6027\u3002", "method": "HANS-Net\u662f\u4e00\u500b\u65b0\u7a4e\u7684\u5206\u5272\u6846\u67b6\uff0c\u7d50\u5408\u4e86\u96d9\u66f2\u5377\u7a4d\u3001\u5c0f\u6ce2\u5206\u89e3\u6a21\u584a\u3001\u7a81\u89f8\u53ef\u5851\u6027\u6a5f\u5236\u548c\u96b1\u542b\u795e\u7d93\u8868\u793a\u5206\u652f\u3002\u5b83\u9084\u7d50\u5408\u4e86\u4e0d\u78ba\u5b9a\u6027\u611f\u77e5\u8499\u7279\u5361\u6d1bdropout\u548c\u8f15\u91cf\u7d1a\u6642\u9593\u6ce8\u610f\u529b\u3002", "result": "HANS-Net\u5728LiTS\u6578\u64da\u96c6\u4e0a\u9054\u5230\u4e8693.26%\u7684\u5e73\u5747Dice\u5206\u6578\u300188.09%\u7684IoU\u30010.72\u6beb\u7c73\u7684\u5e73\u5747\u5c0d\u7a31\u8868\u9762\u8ddd\u96e2\uff08ASSD\uff09\u548c11.91%\u7684\u9ad4\u7a4d\u91cd\u758a\u8aa4\u5dee\uff08VOE\uff09\u3002\u57283D-IRCADb-01\u6578\u64da\u96c6\u4e0a\u9032\u884c\u7684\u4ea4\u53c9\u6578\u64da\u96c6\u9a57\u8b49\uff0c\u5e73\u5747Dice\u70ba87.45%\u3001IoU\u70ba80.30%\u3001ASSD\u70ba1.525\u6beb\u7c73\u548cVOE\u70ba19.71%\u3002", "conclusion": "HANS-Net\u5728\u63d0\u4f9b\u89e3\u5256\u4e00\u81f4\u3001\u6e96\u78ba\u4e14\u53ef\u9760\u7684\u809d\u81df\u548c\u816b\u7624\u5206\u5272\u65b9\u9762\uff0c\u6709\u6548\u4e14\u7a69\u5065\u3002"}}
{"id": "2507.11063", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.11063", "abs": "https://arxiv.org/abs/2507.11063", "authors": ["Gwen Maudet", "Gr\u00e9goire Danoy"], "title": "A Distance Metric for Mixed Integer Programming Instances", "comment": "Accepted to ECAI 2025", "summary": "Mixed-integer linear programming (MILP) is a powerful tool for addressing a\nwide range of real-world problems, but it lacks a clear structure for comparing\ninstances. A reliable similarity metric could establish meaningful\nrelationships between instances, enabling more effective evaluation of instance\nset heterogeneity and providing better guidance to solvers, particularly when\nmachine learning is involved. Existing similarity metrics often lack precision\nin identifying instance classes or rely heavily on labeled data, which limits\ntheir applicability and generalization. To bridge this gap, this paper\nintroduces the first mathematical distance metric for MILP instances, derived\ndirectly from their mathematical formulations. By discretizing right-hand\nsides, weights, and variables into classes, the proposed metric draws\ninspiration from the Earth mover's distance to quantify mismatches in\nweight-variable distributions for constraint comparisons. This approach\nnaturally extends to enable instance-level comparisons. We evaluate both an\nexact and a greedy variant of our metric under various parameter settings,\nusing the StrIPLIB dataset. Results show that all components of the metric\ncontribute to class identification, and that the greedy version achieves\naccuracy nearly identical to the exact formulation while being nearly 200 times\nfaster. Compared to state-of-the-art baselines, including feature-based,\nimage-based, and neural network models, our unsupervised method consistently\noutperforms all non-learned approaches and rivals the performance of a\nsupervised classifier on class and subclass grouping tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684MILP\u5b9e\u4f8b\u6570\u5b66\u8ddd\u79bb\u5ea6\u91cf\u65b9\u6cd5\uff0c\u7528\u4e8e\u6bd4\u8f83\u5b9e\u4f8b\u7684\u76f8\u4f3c\u6027\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u91cf\u5316\u6743\u91cd-\u53d8\u91cf\u5206\u5e03\u6765\u6bd4\u8f83\u7ea6\u675f\uff0c\u5e76\u80fd\u8fdb\u884c\u5b9e\u4f8b\u7ea7\u6bd4\u8f83\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5b9e\u4f8b\u5206\u7ec4\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08MILP\uff09\u5b9e\u4f8b\u7f3a\u4e4f\u6bd4\u8f83\u7ed3\u6784\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u76f8\u4f3c\u6027\u5ea6\u91cf\u65b9\u6cd5\uff0c\u4ee5\u4fc3\u8fdb\u5b9e\u4f8b\u96c6\u5f02\u8d28\u6027\u7684\u8bc4\u4f30\uff0c\u5e76\u4e3a\u6c42\u89e3\u5668\u63d0\u4f9b\u66f4\u597d\u7684\u6307\u5bfc\uff0c\u5c24\u5176\u662f\u5728\u673a\u5668\u5b66\u4e60\u573a\u666f\u4e2d\u3002", "method": "\u901a\u8fc7\u79bb\u6563\u5316\u53f3\u4fa7\u3001\u6743\u91cd\u548c\u53d8\u91cf\uff0c\u5e76\u501f\u9274\u4e86Earth mover's distance\u7684\u601d\u8def\u6765\u91cf\u5316\u7ea6\u675f\u6bd4\u8f83\u4e2d\u7684\u6743\u91cd-\u53d8\u91cf\u5206\u5e03\u4e0d\u5339\u914d\u3002", "result": "\u63d0\u51fa\u7684\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5305\u62ec\u7cbe\u786e\u548c\u8d2a\u5a6a\u53d8\u4f53\uff0c\u5728StrIPLIB\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8d2a\u5a6a\u7248\u672c\u5728\u6548\u7387\u4e0a\u662f\u7cbe\u786e\u7248\u672c\u7684\u8fd1200\u500d\uff0c\u540c\u65f6\u51c6\u786e\u6027\u51e0\u4e4e\u76f8\u540c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u5b9e\u4f8b\u5206\u7ec4\u4efb\u52a1\u4e0a\u4f18\u4e8e\u6240\u6709\u975e\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e76\u4e14\u5728\u6027\u80fd\u4e0a\u4e0e\u6709\u76d1\u7763\u5206\u7c7b\u5668\u76f8\u5ab2\u7f8e\u3002"}}
{"id": "2507.11333", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11333", "abs": "https://arxiv.org/abs/2507.11333", "authors": ["Jianfei Jiang", "Qiankun Liu", "Haochen Yu", "Hongyuan Liu", "Liyong Wang", "Jiansheng Chen", "Huimin Ma"], "title": "MonoMVSNet: Monocular Priors Guided Multi-View Stereo Network", "comment": "Accepted by ICCV 2025", "summary": "Learning-based Multi-View Stereo (MVS) methods aim to predict depth maps for\na sequence of calibrated images to recover dense point clouds. However,\nexisting MVS methods often struggle with challenging regions, such as\ntextureless regions and reflective surfaces, where feature matching fails. In\ncontrast, monocular depth estimation inherently does not require feature\nmatching, allowing it to achieve robust relative depth estimation in these\nregions. To bridge this gap, we propose MonoMVSNet, a novel monocular feature\nand depth guided MVS network that integrates powerful priors from a monocular\nfoundation model into multi-view geometry. Firstly, the monocular feature of\nthe reference view is integrated into source view features by the attention\nmechanism with a newly designed cross-view position encoding. Then, the\nmonocular depth of the reference view is aligned to dynamically update the\ndepth candidates for edge regions during the sampling procedure. Finally, a\nrelative consistency loss is further designed based on the monocular depth to\nsupervise the depth prediction. Extensive experiments demonstrate that\nMonoMVSNet achieves state-of-the-art performance on the DTU and\nTanks-and-Temples datasets, ranking first on the Tanks-and-Temples Intermediate\nand Advanced benchmarks. The source code is available at\nhttps://github.com/JianfeiJ/MonoMVSNet.", "AI": {"tldr": "MonoMVSNet\u901a\u8fc7\u6574\u5408\u5355\u76ee\u6df1\u5ea6\u4f30\u8ba1\u7684\u4f18\u52bf\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfMVS\u65b9\u6cd5\u5728\u5904\u7406\u7eb9\u7406\u7f3a\u5931\u548c\u53cd\u5c04\u8868\u9762\u7b49\u6311\u6218\u6027\u533a\u57df\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u89c6\u56fe\u7acb\u4f53\uff08MVS\uff09\u65b9\u6cd5\u5728\u5904\u7406\u7eb9\u7406\u7f3a\u5931\u548c\u53cd\u5c04\u8868\u9762\u7b49\u5177\u6709\u6311\u6218\u6027\u7684\u533a\u57df\u65f6\uff0c\u7531\u4e8e\u7279\u5f81\u5339\u914d\u5931\u8d25\u800c\u6548\u679c\u4e0d\u4f73\u3002\u800c\u5355\u76ee\u6df1\u5ea6\u4f30\u8ba1 inherently \u4e0d\u9700\u8981\u7279\u5f81\u5339\u914d\uff0c\u56e0\u6b64\u5728\u8fd9\u4e9b\u533a\u57df\u53ef\u4ee5\u5b9e\u73b0\u9c81\u68d2\u7684\u76f8\u5bf9\u6df1\u5ea6\u4f30\u8ba1\u3002\u4e3a\u4e86\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\uff0c\u63d0\u51faMonoMVSNet\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5355\u76ee\u7279\u5f81\u548c\u6df1\u5ea6\u5f15\u5bfc\u7684\u591a\u89c6\u56fe\u7acb\u4f53\u7f51\u7edc\uff08MonoMVSNet\uff09\uff0c\u8be5\u7f51\u7edc\u5c06\u5f3a\u5927\u7684\u5148\u9a8c\u77e5\u8bc6\u4ece\u5355\u76ee\u57fa\u7840\u6a21\u578b\u96c6\u6210\u5230\u591a\u89c6\u56fe\u51e0\u4f55\u4e2d\u3002\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\uff1a1. \u5229\u7528\u65b0\u8bbe\u8ba1\u7684\u8de8\u89c6\u56fe\u4f4d\u7f6e\u7f16\u7801\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5c06\u53c2\u8003\u89c6\u56fe\u7684\u5355\u76ee\u7279\u5f81\u96c6\u6210\u5230\u6e90\u89c6\u56fe\u7279\u5f81\u4e2d\u30022. \u901a\u8fc7\u5bf9\u9f50\u53c2\u8003\u89c6\u56fe\u7684\u5355\u76ee\u6df1\u5ea6\uff0c\u5728\u91c7\u6837\u8fc7\u7a0b\u4e2d\u52a8\u6001\u66f4\u65b0\u8fb9\u7f18\u533a\u57df\u7684\u6df1\u5ea6\u5019\u9009\u30023. \u8bbe\u8ba1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5355\u76ee\u6df1\u5ea6\u7684\u76f8\u5bf9\u4e00\u81f4\u6027\u635f\u5931\u6765\u76d1\u7763\u6df1\u5ea6\u9884\u6d4b\u3002", "result": "MonoMVSNet\u5728DTU\u548cTanks-and-Temples\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5728Tanks-and-Temples\u7684Intermediate\u548cAdvanced\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6392\u540d\u7b2c\u4e00\u3002", "conclusion": "MonoMVSNet\u5728DTU\u548cTanks-and-Temples\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5728Tanks-and-Temples\u7684Intermediate\u548cAdvanced\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6392\u540d\u7b2c\u4e00\u3002"}}
{"id": "2507.11071", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11071", "abs": "https://arxiv.org/abs/2507.11071", "authors": ["Isaiah Thompson Ocansey", "Ritwik Bhattacharya", "Tanmay Sen"], "title": "LogTinyLLM: Tiny Large Language Models Based Contextual Log Anomaly Detection", "comment": null, "summary": "Log anomaly detection using traditional rule based or deep learning based\nmethods is often challenging due to the large volume and highly complex nature\nof log sequence. So effective way of detection of anomalous sequence of logs is\ncrucial for system maintenance and development. This paper proposes parameter\nefficient finetuning specifically low rank adaptation (LoRA) and adapter based\napproaches for finding contextual anomalies in sequence of logs in large log\ndata set. It compares different tiny large language models (LLMs) on the\nThunderbird dataset. The results show that LoRA based finetuning provides\nsubstantial performance improvements of 18 to 19 percentage over LogBert based\nfull finetuning approach, achieving accuracy scores between 97.76% and 98.83%\ncompared to 79.37%.", "AI": {"tldr": "\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\uff1aLoRA\u7b49\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u5728Thunderbird\u6570\u636e\u96c6\u4e0a\u51c6\u786e\u7387\u8fbe98.83%\uff0c\u8fdc\u8d85LogBert\u5168\u91cf\u5fae\u8c03\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u6216\u6df1\u5ea6\u5b66\u4e60\u7684\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u56e0\u65e5\u5fd7\u6570\u636e\u91cf\u5927\u3001\u590d\u6742\u5ea6\u9ad8\u800c\u9762\u4e34\u6311\u6218\uff0c\u56e0\u6b64\uff0c\u6709\u6548\u68c0\u6d4b\u5f02\u5e38\u65e5\u5fd7\u5e8f\u5217\u5bf9\u4e8e\u7cfb\u7edf\u7ef4\u62a4\u548c\u5f00\u53d1\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u5e76\u6bd4\u8f83\u4e86\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u4f4e\u79e9\u9002\u914d\uff08LoRA\uff09\u548cAdapter\uff0c\u7528\u4e8e\u68c0\u6d4b\u5927\u578b\u65e5\u5fd7\u6570\u636e\u96c6\u4e2d\u65e5\u5fd7\u5e8f\u5217\u7684\u4e0a\u4e0b\u6587\u5f02\u5e38\uff0c\u5e76\u5bf9\u6bd4\u4e86\u4e0d\u540c\u7684\u5fae\u578b\u8bed\u8a00\u6a21\u578b\u5728Thunderbird\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u3002", "result": "LoRA\u5fae\u8c03\u65b9\u6cd5\u76f8\u6bd4LogBert\u5168\u91cf\u5fae\u8c03\u65b9\u6cd5\uff0c\u6027\u80fd\u63d0\u5347\u4e8618%-19%\uff0c\u51c6\u786e\u7387\u8fbe\u5230\u4e8697.76%-98.83%\uff0c\u800cLogBert\u7684\u51c6\u786e\u7387\u4e3a79.37%\u3002", "conclusion": "LoRA\u7b49\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u5728\u65e5\u5fd7\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5728Thunderbird\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8eLogBert\u7b49\u57fa\u4e8e\u5168\u91cf\u5fae\u8c03\u7684\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u53ef\u8fbe97.76%-98.83%\u3002"}}
{"id": "2507.11336", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11336", "abs": "https://arxiv.org/abs/2507.11336", "authors": ["Peiran Wu", "Yunze Liu", "Zhengdong Zhu", "Enmin Zhou", "Shawn Shen"], "title": "UGC-VideoCaptioner: An Omni UGC Video Detail Caption Model and New Benchmarks", "comment": null, "summary": "Real-world user-generated videos, especially on platforms like TikTok, often\nfeature rich and intertwined audio visual content. However, existing video\ncaptioning benchmarks and models remain predominantly visual centric,\noverlooking the crucial role of audio in conveying scene dynamics, speaker\nintent, and narrative context. This lack of omni datasets and lightweight,\ncapable models hampers progress in fine grained, multimodal video\nunderstanding. To address these challenges, we introduce UGC-VideoCap, a new\nbenchmark and model framework specifically designed for detailed omnimodal\ncaptioning of short form user-generated videos. Unlike prior datasets,\nUGC-VideoCap emphasizes balanced integration of audio and visual modalities,\nfeaturing 1000 TikTok videos annotated through a structured three stage\nhuman-in-the-loop pipeline covering audio only, visual only, and joint audio\nvisual semantics. The benchmark also includes 4000 carefully crafted QA pairs\nprobing both unimodal and cross modal understanding. Alongside the dataset, we\npropose UGC-VideoCaptioner(3B), a 3B parameter captioning model distilled from\nGemini 2.5 Flash. Using a novel two-stage training strategy supervised fine\ntuning followed by Group Relative Policy Optimization (GRPO), our approach\nenables efficient adaptation from limited data while maintaining competitive\nperformance. Together, our benchmark and model offer a high-quality foundation\nand a data-efficient solution for advancing omnimodal video captioning in\nunconstrained real-world UGC settings.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86UGC-VideoCap\u6570\u636e\u96c6\u548cUGC-VideoCaptioner(3B)\u6a21\u578b\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u89c6\u9891\u5b57\u5e55\u65b9\u6cd5\u4fa7\u91cd\u89c6\u89c9\u800c\u5ffd\u7565\u97f3\u9891\u7684\u95ee\u9898\uff0c\u65e8\u5728\u63d0\u5347\u7528\u6237\u751f\u6210\u77ed\u89c6\u9891\u7684\u5168\u6a21\u6001\u7406\u89e3\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u9891\u5b57\u5e55\u57fa\u51c6\u548c\u6a21\u578b\u4e3b\u8981\u4ee5\u89c6\u89c9\u4e3a\u4e2d\u5fc3\uff0c\u5ffd\u89c6\u4e86\u97f3\u9891\u5728\u4f20\u8fbe\u573a\u666f\u52a8\u6001\u3001\u8bf4\u8bdd\u8005\u610f\u56fe\u548c\u53d9\u4e8b\u80cc\u666f\u65b9\u9762\u7684\u91cd\u8981\u4f5c\u7528\uff0c\u8fd9\u963b\u788d\u4e86\u7ec6\u7c92\u5ea6\u3001\u591a\u6a21\u6001\u89c6\u9891\u7406\u89e3\u7684\u8fdb\u5c55\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aUGC-VideoCap\u7684\u65b0\u57fa\u51c6\u548c\u6a21\u578b\u6846\u67b6\uff0c\u7528\u4e8e\u5bf9\u77ed\u683c\u5f0f\u7528\u6237\u751f\u6210\u89c6\u9891\u8fdb\u884c\u8be6\u7ec6\u7684\u5168\u6a21\u6001\u5b57\u5e55\u751f\u6210\u3002\u8be5\u65b9\u6cd5\u5305\u62ec\u4e00\u4e2a\u67091000\u4e2aTikTok\u89c6\u9891\u7684\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u7ed3\u6784\u5316\u7684\u4e09\u9636\u6bb5\u4eba\u673a\u534f\u540c\u6d41\u7a0b\u8fdb\u884c\u6807\u6ce8\uff0c\u6db5\u76d6\u4ec5\u97f3\u9891\u3001\u4ec5\u89c6\u89c9\u548c\u8054\u5408\u97f3\u9891-\u89c6\u89c9\u8bed\u4e49\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u4e2a30\u4ebf\u53c2\u6570\u7684\u5b57\u5e55\u6a21\u578bUGC-VideoCaptioner(3B)\uff0c\u8be5\u6a21\u578b\u91c7\u7528\u65b0\u9896\u7684\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff08\u76d1\u7763\u5fae\u8c03\u540e\u63a5Group Relative Policy Optimization\uff08GRPO\uff09\uff09\uff0c\u53ef\u4ee5\u4ece\u6709\u9650\u7684\u6570\u636e\u4e2d\u8fdb\u884c\u9ad8\u6548\u9002\u5e94\uff0c\u5e76\u4fdd\u6301\u7ade\u4e89\u529b\u3002", "result": "UGC-VideoCap\u662f\u4e00\u4e2a\u5305\u542b1000\u4e2aTikTok\u89c6\u9891\u7684\u6570\u636e\u96c6\uff0c\u5e76\u5305\u542b4000\u4e2a\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u95ee\u7b54\u5bf9\uff0c\u7528\u4e8e\u63a2\u7a76\u5355\u6a21\u6001\u548c\u8de8\u6a21\u6001\u7406\u89e3\u3002\u63d0\u51fa\u7684UGC-VideoCaptioner(3B)\u6a21\u578b\u5728\u6709\u9650\u6570\u636e\u4e0b\u5b9e\u73b0\u4e86\u9ad8\u6548\u9002\u5e94\u548c\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u57fa\u51c6\u548c\u6a21\u578b\u4e3a\u5728\u65e0\u7ea6\u675f\u7684\u771f\u5b9e\u7528\u6237\u751f\u6210\u5185\u5bb9\u573a\u666f\u4e0b\u63a8\u8fdb\u5168\u6a21\u6001\u89c6\u9891\u5b57\u5e55\u751f\u6210\u63d0\u4f9b\u4e86\u9ad8\u8d28\u91cf\u7684\u57fa\u7840\u548c\u6570\u636e\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2507.11173", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11173", "abs": "https://arxiv.org/abs/2507.11173", "authors": ["Deepak Kumar Panda", "Weisi Guo"], "title": "Real-Time Bayesian Detection of Drift-Evasive GNSS Spoofing in Reinforcement Learning Based UAV Deconfliction", "comment": null, "summary": "Autonomous unmanned aerial vehicles (UAVs) rely on global navigation\nsatellite system (GNSS) pseudorange measurements for accurate real-time\nlocalization and navigation. However, this dependence exposes them to\nsophisticated spoofing threats, where adversaries manipulate pseudoranges to\ndeceive UAV receivers. Among these, drift-evasive spoofing attacks subtly\nperturb measurements, gradually diverting the UAVs trajectory without\ntriggering conventional signal-level anti-spoofing mechanisms. Traditional\ndistributional shift detection techniques often require accumulating a\nthreshold number of samples, causing delays that impede rapid detection and\ntimely response. Consequently, robust temporal-scale detection methods are\nessential to identify attack onset and enable contingency planning with\nalternative sensing modalities, improving resilience against stealthy\nadversarial manipulations. This study explores a Bayesian online change point\ndetection (BOCPD) approach that monitors temporal shifts in value estimates\nfrom a reinforcement learning (RL) critic network to detect subtle behavioural\ndeviations in UAV navigation. Experimental results show that this temporal\nvalue-based framework outperforms conventional GNSS spoofing detectors,\ntemporal semi-supervised learning frameworks, and the Page-Hinkley test,\nachieving higher detection accuracy and lower false-positive and false-negative\nrates for drift-evasive spoofing attacks.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u8d1d\u53f6\u65af\u5728\u7ebf\u53d8\u5316\u70b9\u68c0\u6d4b\uff08BOCPD\uff09\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u76d1\u63a7\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u8bc4\u4ef7\u7f51\u7edc\u7684\u503c\u4f30\u8ba1\u4e2d\u7684\u65f6\u95f4\u6f02\u79fb\uff0c\u6709\u6548\u68c0\u6d4b\u65e0\u4eba\u673a\u5bfc\u822a\u4e2d\u7684\u6f02\u79fb\u89c4\u907f\u6b3a\u9a97\u653b\u51fb\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u6548\u679c\u66f4\u4f18\u3002", "motivation": "\u81ea\u4e3b\u65e0\u4eba\u673a\uff08UAV\uff09\u4f9d\u8d56GNSS\u8fdb\u884c\u5bfc\u822a\uff0c\u5bb9\u6613\u53d7\u5230\u6b3a\u9a97\u653b\u51fb\uff0c\u7279\u522b\u662f\u6f02\u79fb\u89c4\u907f\u6b3a\u9a97\u653b\u51fb\uff0c\u5b83\u80fd\u9010\u6e10\u6539\u53d8\u65e0\u4eba\u673a\u8f68\u8ff9\u800c\u4e0d\u89e6\u53d1\u5e38\u89c4\u7684\u4fe1\u53f7\u7ea7\u53cd\u6b3a\u9a97\u673a\u5236\u3002\u4f20\u7edf\u68c0\u6d4b\u65b9\u6cd5\u9700\u8981\u7d2f\u79ef\u6837\u672c\uff0c\u5bfc\u81f4\u68c0\u6d4b\u5ef6\u8fdf\u3002\u56e0\u6b64\uff0c\u9700\u8981\u9c81\u68d2\u7684\u65f6\u95f4\u5c3a\u5ea6\u68c0\u6d4b\u65b9\u6cd5\u6765\u53ca\u65f6\u54cd\u5e94\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u8d1d\u53f6\u65af\u5728\u7ebf\u53d8\u5316\u70b9\u68c0\u6d4b\uff08BOCPD\uff09\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u76d1\u63a7\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u8bc4\u4ef7\u7f51\u7edc\u7684\u503c\u4f30\u8ba1\u4e2d\u7684\u65f6\u95f4\u6f02\u79fb\u6765\u68c0\u6d4b\u65e0\u4eba\u673a\u5bfc\u822a\u4e2d\u7684\u6f02\u79fb\u89c4\u907f\u6b3a\u9a97\u653b\u51fb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u7684\u57fa\u4e8e\u65f6\u95f4\u5c3a\u5ea6\u503c\u4f30\u8ba1\u7684\u6846\u67b6\u5728\u68c0\u6d4b\u6f02\u79fb\u89c4\u907f\u6b3a\u9a97\u653b\u51fb\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u7684GNSS\u6b3a\u9a97\u68c0\u6d4b\u5668\u3001\u65f6\u95f4\u534a\u76d1\u7763\u5b66\u4e60\u6846\u67b6\u548cPage-Hinkley\u68c0\u9a8c\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u68c0\u6d4b\u7cbe\u5ea6\u548c\u66f4\u4f4e\u7684\u8bef\u62a5\u7387\u548c\u6f0f\u62a5\u7387\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u57fa\u4e8e\u8d1d\u53f6\u65af\u5728\u7ebf\u53d8\u5316\u70b9\u68c0\u6d4b\uff08BOCPD\uff09\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u76d1\u63a7\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u8bc4\u4ef7\u7f51\u7edc\u7684\u503c\u4f30\u8ba1\u4e2d\u7684\u65f6\u95f4\u6f02\u79fb\uff0c\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u65e0\u4eba\u673a\u5bfc\u822a\u4e2d\u7684\u7ec6\u5fae\u884c\u4e3a\u504f\u5dee\uff0c\u76f8\u6bd4\u4e8e\u4f20\u7edf\u7684GNSS\u6b3a\u9a97\u68c0\u6d4b\u65b9\u6cd5\u3001\u65f6\u95f4\u534a\u76d1\u7763\u5b66\u4e60\u6846\u67b6\u4ee5\u53caPage-Hinkley\u68c0\u9a8c\uff0c\u5728\u6f02\u79fb\u89c4\u907f\u6b3a\u9a97\u653b\u51fb\u65b9\u9762\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u68c0\u6d4b\u7cbe\u5ea6\u4ee5\u53ca\u66f4\u4f4e\u8bef\u62a5\u548c\u6f0f\u62a5\u7387\u3002"}}
{"id": "2507.11372", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11372", "abs": "https://arxiv.org/abs/2507.11372", "authors": ["Pierrick Leroy", "Antonio Mastropietro", "Marco Nurisso", "Francesco Vaccarino"], "title": "Attributes Shape the Embedding Space of Face Recognition Models", "comment": null, "summary": "Face Recognition (FR) tasks have made significant progress with the advent of\nDeep Neural Networks, particularly through margin-based triplet losses that\nembed facial images into high-dimensional feature spaces. During training,\nthese contrastive losses focus exclusively on identity information as labels.\nHowever, we observe a multiscale geometric structure emerging in the embedding\nspace, influenced by interpretable facial (e.g., hair color) and image\nattributes (e.g., contrast). We propose a geometric approach to describe the\ndependence or invariance of FR models to these attributes and introduce a\nphysics-inspired alignment metric. We evaluate the proposed metric on\ncontrolled, simplified models and widely used FR models fine-tuned with\nsynthetic data for targeted attribute augmentation. Our findings reveal that\nthe models exhibit varying degrees of invariance across different attributes,\nproviding insight into their strengths and weaknesses and enabling deeper\ninterpretability. Code available here:\nhttps://github.com/mantonios107/attrs-fr-embs}{https://github.com/mantonios107/attrs-fr-embs", "AI": {"tldr": "\u4eba\u8138\u8bc6\u522b\uff08FR\uff09\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u5c55\u73b0\u51fa\u591a\u5c3a\u5ea6\u51e0\u4f55\u7ed3\u6784\uff0c\u4f1a\u53d7\u5230\u53d1\u8272\u6216\u5bf9\u6bd4\u5ea6\u7b49\u5c5e\u6027\u7684\u5f71\u54cd\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u51e0\u4f55\u65b9\u6cd5\u548c\u4e00\u79cd\u65b0\u7684\u5bf9\u9f50\u6307\u6807\uff0c\u7528\u4e8e\u91cf\u5316FR\u6a21\u578b\u5728\u8fd9\u4e9b\u5c5e\u6027\u4e0a\u7684\u4e0d\u53d8\u6027\uff0c\u4ece\u800c\u63d0\u9ad8\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u4eba\u8138\u8bc6\u522b\uff08FR\uff09\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u7279\u522b\u662f\u901a\u8fc7\u5c06\u9762\u90e8\u56fe\u50cf\u5d4c\u5165\u9ad8\u7ef4\u7279\u5f81\u7a7a\u95f4\u4e2d\u7684\u57fa\u4e8e\u8fb9\u754c\u7684\u4e09\u5143\u635f\u5931\u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u8fd9\u4e9b\u5bf9\u6bd4\u635f\u5931\u4ec5\u5173\u6ce8\u8eab\u4efd\u4fe1\u606f\u4f5c\u4e3a\u6807\u7b7e\u3002\u7136\u800c\uff0c\u6211\u4eec\u89c2\u5bdf\u5230\u5d4c\u5165\u7a7a\u95f4\u4e2d\u51fa\u73b0\u4e86\u4e00\u4e2a\u591a\u5c3a\u5ea6\u51e0\u4f55\u7ed3\u6784\uff0c\u53d7\u5230\u53ef\u89e3\u91ca\u9762\u90e8\uff08\u4f8b\u5982\uff0c\u53d1\u8272\uff09\u548c\u56fe\u50cf\u5c5e\u6027\uff08\u4f8b\u5982\uff0c\u5bf9\u6bd4\u5ea6\uff09\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u51e0\u4f55\u65b9\u6cd5\u6765\u63cf\u8ff0\u4eba\u8138\u8bc6\u522b\u6a21\u578b\u5bf9\u5c5e\u6027\u7684\u4f9d\u8d56\u6027\u6216\u4e0d\u53d8\u6027\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u79cd\u53d7\u7269\u7406\u5b66\u542f\u53d1\u7684\u5bf9\u9f50\u6307\u6807\u3002", "result": "\u8bc4\u4f30\u4e86\u5728\u53d7\u63a7\u7684\u3001\u7b80\u5316\u7684\u6a21\u578b\u548c\u4f7f\u7528\u5408\u6210\u6570\u636e\u8fdb\u884c\u5fae\u8c03\u7684\u5e7f\u6cdb\u4f7f\u7528\u7684\u4eba\u8138\u8bc6\u522b\u6a21\u578b\u4e0a\u63d0\u51fa\u7684\u6307\u6807\uff0c\u4ee5\u8fdb\u884c\u6709\u9488\u5bf9\u6027\u7684\u5c5e\u6027\u589e\u5f3a\u3002", "conclusion": "\u8be5\u6a21\u578b\u5728\u4e0d\u540c\u5c5e\u6027\u4e0a\u8868\u73b0\u51fa\u4e0d\u540c\u7a0b\u5ea6\u7684\u4e0d\u53d8\u6027\uff0c\u63ed\u793a\u4e86\u5176\u4f18\u70b9\u548c\u7f3a\u70b9\uff0c\u5e76\u5b9e\u73b0\u4e86\u66f4\u6df1\u5c42\u6b21\u7684\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2507.11178", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11178", "abs": "https://arxiv.org/abs/2507.11178", "authors": ["Meiliang Liu", "Huiwen Dong", "Xiaoxiao Yang", "Yunfang Xu", "Zijin Li", "Zhengye Si", "Xinyue Yang", "Zhiwen Zhao"], "title": "Gradient Regularization-based Neural Granger Causality", "comment": "9 pages,3 figures, conference", "summary": "With the advancement of deep learning technologies, various neural\nnetwork-based Granger causality models have been proposed. Although these\nmodels have demonstrated notable improvements, several limitations remain. Most\nexisting approaches adopt the component-wise architecture, necessitating the\nconstruction of a separate model for each time series, which results in\nsubstantial computational costs. In addition, imposing the sparsity-inducing\npenalty on the first-layer weights of the neural network to extract causal\nrelationships weakens the model's ability to capture complex interactions. To\naddress these limitations, we propose Gradient Regularization-based Neural\nGranger Causality (GRNGC), which requires only one time series prediction model\nand applies $L_{1}$ regularization to the gradient between model's input and\noutput to infer Granger causality. Moreover, GRNGC is not tied to a specific\ntime series forecasting model and can be implemented with diverse architectures\nsuch as KAN, MLP, and LSTM, offering enhanced flexibility. Numerical\nsimulations on DREAM, Lorenz-96, fMRI BOLD, and CausalTime show that GRNGC\noutperforms existing baselines and significantly reduces computational\noverhead. Meanwhile, experiments on real-world DNA, Yeast, HeLa, and bladder\nurothelial carcinoma datasets further validate the model's effectiveness in\nreconstructing gene regulatory networks.", "AI": {"tldr": "GRNGC\u662f\u4e00\u79cd\u65b0\u7684\u683c\u5170\u6770\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\uff0c\u901a\u8fc7\u6b63\u5219\u5316\u68af\u5ea6\u6765\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u6355\u6349\u590d\u6742\u4ea4\u4e92\u80fd\u529b\u5f31\u7684\u95ee\u9898\uff0c\u5e76\u5df2\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u683c\u5170\u6770\u56e0\u679c\u5173\u7cfb\u6a21\u578b\u5927\u591a\u91c7\u7528\u9010\u5206\u91cf\u67b6\u6784\uff0c\u9700\u8981\u4e3a\u6bcf\u4e2a\u65f6\u95f4\u5e8f\u5217\u6784\u5efa\u5355\u72ec\u7684\u6a21\u578b\uff0c\u5bfc\u81f4\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff1b\u5e76\u4e14\u5728\u795e\u7ecf\u7f51\u7edc\u7684\u7b2c\u4e00\u5c42\u6743\u91cd\u4e0a\u65bd\u52a0\u7a00\u758f\u6027\u6b63\u5219\u5316\u6765\u63d0\u53d6\u56e0\u679c\u5173\u7cfb\u4f1a\u524a\u5f31\u6a21\u578b\u6355\u6349\u590d\u6742\u4ea4\u4e92\u7684\u80fd\u529b\u3002", "method": "GRNGC\u6a21\u578b\uff0c\u901a\u8fc7\u5c06L1\u6b63\u5219\u5316\u5e94\u7528\u4e8e\u6a21\u578b\u8f93\u5165\u548c\u8f93\u51fa\u4e4b\u95f4\u7684\u68af\u5ea6\u6765\u63a8\u65ad\u683c\u5170\u6770\u56e0\u679c\u5173\u7cfb\uff0c\u5e76\u4e14\u8be5\u6a21\u578b\u4e0d\u4f9d\u8d56\u4e8e\u7279\u5b9a\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\uff0c\u53ef\u4ee5\u4e0eKAN\u3001MLP\u548cLSTM\u7b49\u591a\u79cd\u67b6\u6784\u7ed3\u5408\u4f7f\u7528\u3002", "result": "GRNGC\u5728DREAM\u3001Lorenz-96\u3001fMRI BOLD\u548cCausalTime\u4e0a\u7684\u6570\u503c\u6a21\u62df\u7ed3\u679c\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "GRNGC\u5728\u771f\u5b9e\u4e16\u754cDNA\u3001\u9175\u6bcd\u3001HeLa\u548c\u8180\u80f1\u5c3f\u8def\u4e0a\u76ae\u764c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u8be5\u6a21\u578b\u5728\u91cd\u5efa\u57fa\u56e0\u8c03\u63a7\u7f51\u7edc\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.11441", "categories": ["cs.CV", "cs.LG", "I.2.6; I.5.1; I.4.8; I.2.10"], "pdf": "https://arxiv.org/pdf/2507.11441", "abs": "https://arxiv.org/abs/2507.11441", "authors": ["Kaif Shaikh", "Antoni Kowalczuk", "Franziska Boenisch", "Adam Dziedzic"], "title": "Implementing Adaptations for Vision AutoRegressive Model", "comment": "Accepted at DIG-BUGS: Data in Generative Models Workshop @ ICML 2025", "summary": "Vision AutoRegressive model (VAR) was recently introduced as an alternative\nto Diffusion Models (DMs) in image generation domain. In this work we focus on\nits adaptations, which aim to fine-tune pre-trained models to perform specific\ndownstream tasks, like medical data generation. While for DMs there exist many\ntechniques, adaptations for VAR remain underexplored. Similarly, differentially\nprivate (DP) adaptations-ones that aim to preserve privacy of the adaptation\ndata-have been extensively studied for DMs, while VAR lacks such solutions. In\nour work, we implement and benchmark many strategies for VAR, and compare them\nto state-of-the-art DM adaptation strategies. We observe that VAR outperforms\nDMs for non-DP adaptations, however, the performance of DP suffers, which\nnecessitates further research in private adaptations for VAR. Code is available\nat https://github.com/sprintml/finetuning_var_dp.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86VAR\u5728\u56fe\u50cf\u751f\u6210\u4e2d\u7684\u9002\u5e94\u6027\uff0c\u53d1\u73b0\u5b83\u5728\u975eDP\u4efb\u52a1\u4e0a\u4f18\u4e8eDM\uff0c\u4f46\u5728DP\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22VAR\u6a21\u578b\u5728\u7279\u5b9a\u4e0b\u6e38\u4efb\u52a1\uff08\u5982\u533b\u5b66\u6570\u636e\u751f\u6210\uff09\u7684\u9002\u5e94\u6027\uff0c\u5e76\u89e3\u51b3\u4e86VAR\u5728\u5dee\u5206\u9690\u79c1\uff08DP\uff09\u9002\u5e94\u6027\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u800cDM\u5728\u8fd9\u65b9\u9762\u5df2\u6709\u5e7f\u6cdb\u7814\u7a76\u3002", "method": "\u5b9e\u73b0\u4e86\u591a\u79cdVAR\u9002\u5e94\u6027\u7b56\u7565\uff0c\u5e76\u4e0eDM\u9002\u5e94\u6027\u7b56\u7565\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u548c\u6bd4\u8f83\u3002", "result": "VAR\u5728\u975eDP\u9002\u5e94\u6027\u4efb\u52a1\u4e0a\u4f18\u4e8eDM\uff0c\u4f46\u5728DP\u9002\u5e94\u6027\u4efb\u52a1\u4e0a\u6027\u80fd\u53d7\u5230\u5f71\u54cd\u3002", "conclusion": "VAR\u5728\u975e\u5dee\u5206\u9690\u79c1\uff08DP\uff09\u9002\u5e94\u6027\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8eDM\uff0c\u4f46\u5728DP\u9002\u5e94\u6027\u4efb\u52a1\u4e0a\u6027\u80fd\u6709\u6240\u4e0b\u964d\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76VAR\u7684\u79c1\u6709\u9002\u5e94\u6027\u3002"}}
{"id": "2507.11181", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11181", "abs": "https://arxiv.org/abs/2507.11181", "authors": ["Danyang Zhang", "Junhao Song", "Ziqian Bi", "Yingfang Yuan", "Tianyang Wang", "Joe Yeong", "Junfeng Hao"], "title": "Mixture of Experts in Large Language Models", "comment": null, "summary": "This paper presents a comprehensive review of the Mixture-of-Experts (MoE)\narchitecture in large language models, highlighting its ability to\nsignificantly enhance model performance while maintaining minimal computational\noverhead. Through a systematic analysis spanning theoretical foundations, core\narchitectural designs, and large language model (LLM) applications, we examine\nexpert gating and routing mechanisms, hierarchical and sparse MoE\nconfigurations, meta-learning approaches, multimodal and multitask learning\nscenarios, real-world deployment cases, and recent advances and challenges in\ndeep learning. Our analysis identifies key advantages of MoE, including\nsuperior model capacity compared to equivalent Bayesian approaches, improved\ntask-specific performance, and the ability to scale model capacity efficiently.\nWe also underscore the importance of ensuring expert diversity, accurate\ncalibration, and reliable inference aggregation, as these are essential for\nmaximizing the effectiveness of MoE architectures. Finally, this review\noutlines current research limitations, open challenges, and promising future\ndirections, providing a foundation for continued innovation in MoE architecture\nand its applications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5168\u9762\u56de\u987e\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684MoE\u67b6\u6784\uff0c\u5f3a\u8c03\u4e86\u5176\u5728\u63d0\u5347\u6027\u80fd\u548c\u63a7\u5236\u8ba1\u7b97\u5f00\u9500\u65b9\u9762\u7684\u4f18\u52bf\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u4ecb\u7ecdMoE\u67b6\u6784\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e94\u7528\uff0c\u5f3a\u8c03\u5176\u63d0\u5347\u6a21\u578b\u6027\u80fd\u548c\u63a7\u5236\u8ba1\u7b97\u5f00\u9500\u7684\u80fd\u529b\u3002", "method": "\u5bf9MoE\u67b6\u6784\u8fdb\u884c\u4e86\u7cfb\u7edf\u7684\u5206\u6790\uff0c\u6db5\u76d6\u4e86\u7406\u8bba\u57fa\u7840\u3001\u6838\u5fc3\u8bbe\u8ba1\u3001LLM\u5e94\u7528\u3001\u4e13\u5bb6\u95e8\u63a7\u4e0e\u8def\u7531\u673a\u5236\u3001\u5c42\u6b21\u5316\u4e0e\u7a00\u758fMoE\u914d\u7f6e\u3001\u5143\u5b66\u4e60\u65b9\u6cd5\u3001\u591a\u6a21\u6001\u4e0e\u591a\u4efb\u52a1\u5b66\u4e60\u3001\u5b9e\u9645\u90e8\u7f72\u6848\u4f8b\u4ee5\u53ca\u6df1\u5ea6\u5b66\u4e60\u7684\u6700\u65b0\u8fdb\u5c55\u548c\u6311\u6218\u3002", "result": "MoE\u67b6\u6784\u76f8\u6bd4\u4e8e\u7b49\u6548\u7684\u8d1d\u53f6\u65af\u65b9\u6cd5\u5177\u6709\u66f4\u4f18\u7684\u6a21\u578b\u5bb9\u91cf\u3001\u66f4\u597d\u7684\u4efb\u52a1\u7279\u5b9a\u6027\u80fd\uff0c\u5e76\u80fd\u9ad8\u6548\u5730\u6269\u5c55\u6a21\u578b\u5bb9\u91cf\u3002", "conclusion": "MoE\u67b6\u6784\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u5177\u6709\u63d0\u5347\u6027\u80fd\u548c\u63a7\u5236\u8ba1\u7b97\u5f00\u9500\u7684\u6f5c\u529b\u3002\u4e3a\u4e86\u6700\u5927\u5316\u5176\u6548\u679c\uff0c\u9700\u8981\u786e\u4fdd\u4e13\u5bb6\u591a\u6837\u6027\u3001\u51c6\u786e\u7684\u6821\u51c6\u548c\u53ef\u9760\u7684\u63a8\u7406\u805a\u5408\u3002\u8be5\u7814\u7a76\u4e3aMoE\u67b6\u6784\u7684\u6301\u7eed\u521b\u65b0\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.11443", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11443", "abs": "https://arxiv.org/abs/2507.11443", "authors": ["Haoran Wang", "Hanyu Pei", "Yang Lyu", "Kai Zhang", "Li Li", "Feng-Lei Fan"], "title": "COLI: A Hierarchical Efficient Compressor for Large Images", "comment": null, "summary": "The escalating adoption of high-resolution, large-field-of-view imagery\namplifies the need for efficient compression methodologies. Conventional\ntechniques frequently fail to preserve critical image details, while\ndata-driven approaches exhibit limited generalizability. Implicit Neural\nRepresentations (INRs) present a promising alternative by learning continuous\nmappings from spatial coordinates to pixel intensities for individual images,\nthereby storing network weights rather than raw pixels and avoiding the\ngeneralization problem. However, INR-based compression of large images faces\nchallenges including slow compression speed and suboptimal compression ratios.\nTo address these limitations, we introduce COLI (Compressor for Large Images),\na novel framework leveraging Neural Representations for Videos (NeRV). First,\nrecognizing that INR-based compression constitutes a training process, we\naccelerate its convergence through a pretraining-finetuning paradigm,\nmixed-precision training, and reformulation of the sequential loss into a\nparallelizable objective. Second, capitalizing on INRs' transformation of image\nstorage constraints into weight storage, we implement Hyper-Compression, a\nnovel post-training technique to substantially enhance compression ratios while\nmaintaining minimal output distortion. Evaluations across two medical imaging\ndatasets demonstrate that COLI consistently achieves competitive or superior\nPSNR and SSIM metrics at significantly reduced bits per pixel (bpp), while\naccelerating NeRV training by up to 4 times.", "AI": {"tldr": "COLI\u4f7f\u7528\u795e\u7ecf\u8868\u793a\uff08NeRV\uff09\u6765\u538b\u7f29\u5927\u578b\u56fe\u50cf\uff0c\u901a\u8fc7\u52a0\u901f\u8bad\u7ec3\u548c\u6539\u8fdb\u538b\u7f29\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u538b\u7f29\u6bd4\u548c\u66f4\u5feb\u7684\u901f\u5ea6\u3002", "motivation": "\u4f20\u7edf\u56fe\u50cf\u538b\u7f29\u6280\u672f\u5728\u7ec6\u8282\u4fdd\u7559\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002\u9690\u5f0f\u795e\u7ecf\u8868\u793a\uff08INR\uff09\u4f5c\u4e3a\u4e00\u79cd\u65b0\u5174\u7684\u538b\u7f29\u65b9\u6cd5\uff0c\u867d\u7136\u907f\u514d\u4e86\u6cdb\u5316\u95ee\u9898\uff0c\u4f46\u5728\u538b\u7f29\u5927\u578b\u56fe\u50cf\u65f6\u5b58\u5728\u901f\u5ea6\u6162\u548c\u538b\u7f29\u6bd4\u4e0d\u4f73\u7684\u6311\u6218\u3002", "method": "COLI\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u9884\u8bad\u7ec3-\u5fae\u8c03\u8303\u5f0f\u3001\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u548c\u5e76\u884c\u5316\u76ee\u6807\u51fd\u6570\u6765\u52a0\u901fINR\u7684\u6536\u655b\uff0c\u5e76\u91c7\u7528\u4e86Hyper-Compression\u540e\u8bad\u7ec3\u6280\u672f\u6765\u63d0\u9ad8\u538b\u7f29\u6bd4\u3002", "result": "COLI\u6846\u67b6\u5728\u533b\u5b66\u6210\u50cf\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684PSNR\u548cSSIM\u6307\u6807\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u6bcf\u50cf\u7d20\u6bd4\u7279\u6570\uff08bpp\uff09\uff0c\u5e76\u5c06NeRV\u7684\u8bad\u7ec3\u901f\u5ea6\u63d0\u9ad8\u4e864\u500d\u3002", "conclusion": "COLI\u6846\u67b6\u5229\u7528\u795e\u7ecf\u8868\u793a\uff08NeRV\uff09\u5b9e\u73b0\u4e86\u5bf9\u5927\u578b\u56fe\u50cf\u7684\u9ad8\u6548\u538b\u7f29\uff0c\u901a\u8fc7\u9884\u8bad\u7ec3-\u5fae\u8c03\u8303\u5f0f\u3001\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\u548c\u5e76\u884c\u5316\u76ee\u6807\u51fd\u6570\u52a0\u901f\u4e86\u8bad\u7ec3\u6536\u655b\uff0c\u5e76\u5f15\u5165\u4e86Hyper-Compression\u540e\u8bad\u7ec3\u6280\u672f\u4ee5\u63d0\u9ad8\u538b\u7f29\u6bd4\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6700\u5c0f\u7684\u5931\u771f\u3002\u5728\u533b\u5b66\u6210\u50cf\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cCOLI\u5728\u663e\u8457\u964d\u4f4e\u6bcf\u50cf\u7d20\u6bd4\u7279\u6570\uff08bpp\uff09\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684PSNR\u548cSSIM\u6307\u6807\uff0c\u5e76\u5c06NeRV\u8bad\u7ec3\u901f\u5ea6\u63d0\u9ad8\u4e864\u500d\u3002"}}
{"id": "2507.11183", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11183", "abs": "https://arxiv.org/abs/2507.11183", "authors": ["Dimitrios Kritsiolis", "Constantine Kotropoulos"], "title": "Quantized Rank Reduction: A Communications-Efficient Federated Learning Scheme for Network-Critical Applications", "comment": "In Proceedings of the 2025 IARIA Annual Congress on Frontiers in\n  Science, Technology, Services, and Applications (IARIA Congress 2025),\n  Venice, Italy, July 6-10, 2025", "summary": "Federated learning is a machine learning approach that enables multiple\ndevices (i.e., agents) to train a shared model cooperatively without exchanging\nraw data. This technique keeps data localized on user devices, ensuring privacy\nand security, while each agent trains the model on their own data and only\nshares model updates. The communication overhead is a significant challenge due\nto the frequent exchange of model updates between the agents and the central\nserver. In this paper, we propose a communication-efficient federated learning\nscheme that utilizes low-rank approximation of neural network gradients and\nquantization to significantly reduce the network load of the decentralized\nlearning process with minimal impact on the model's accuracy.", "AI": {"tldr": "Federated learning trains models on decentralized data without sharing raw data, but has high communication overhead. This paper proposes using low-rank approximation and quantization to reduce this overhead with minimal accuracy loss.", "motivation": "Addresses the challenge of communication overhead in federated learning due to frequent exchange of model updates.", "method": "Utilizes low-rank approximation of neural network gradients and quantization to reduce communication overhead.", "result": "Significant reduction in network load in the decentralized learning process.", "conclusion": "The proposed scheme significantly reduces network load with minimal impact on model accuracy."}}
{"id": "2507.11474", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11474", "abs": "https://arxiv.org/abs/2507.11474", "authors": ["Pan Du", "Mingqi Xu", "Xiaozhi Zhu", "Jian-xun Wang"], "title": "HUG-VAS: A Hierarchical NURBS-Based Generative Model for Aortic Geometry Synthesis and Controllable Editing", "comment": "59 pages, 9 figures", "summary": "Accurate characterization of vascular geometry is essential for\ncardiovascular diagnosis and treatment planning. Traditional statistical shape\nmodeling (SSM) methods rely on linear assumptions, limiting their expressivity\nand scalability to complex topologies such as multi-branch vascular structures.\nWe introduce HUG-VAS, a Hierarchical NURBS Generative model for Vascular\ngeometry Synthesis, which integrates NURBS surface parameterization with\ndiffusion-based generative modeling to synthesize realistic, fine-grained\naortic geometries. Trained with 21 patient-specific samples, HUG-VAS generates\nanatomically faithful aortas with supra-aortic branches, yielding biomarker\ndistributions that closely match those of the original dataset. HUG-VAS adopts\na hierarchical architecture comprising a denoising diffusion model that\ngenerates centerlines and a guided diffusion model that synthesizes radial\nprofiles conditioned on those centerlines, thereby capturing two layers of\nanatomical variability. Critically, the framework supports zero-shot\nconditional generation from image-derived priors, enabling practical\napplications such as interactive semi-automatic segmentation, robust\nreconstruction under degraded imaging conditions, and implantable device\noptimization. To our knowledge, HUG-VAS is the first SSM framework to bridge\nimage-derived priors with generative shape modeling via a unified integration\nof NURBS parameterization and hierarchical diffusion processes.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.11185", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11185", "abs": "https://arxiv.org/abs/2507.11185", "authors": ["Md. Emon Akter Sourov", "Md. Sabbir Hossen", "Pabon Shaha", "Mohammad Minoar Hossain", "Md Sadiq Iqbal"], "title": "An Explainable AI-Enhanced Machine Learning Approach for Cardiovascular Disease Detection and Risk Assessment", "comment": "This paper has been accepted at the IEEE QPAIN 2025. The final\n  version will be available in the IEEE Xplore Digital Library", "summary": "Heart disease remains a major global health concern, particularly in regions\nwith limited access to medical resources and diagnostic facilities. Traditional\ndiagnostic methods often fail to accurately identify and manage heart disease\nrisks, leading to adverse outcomes. Machine learning has the potential to\nsignificantly enhance the accuracy, efficiency, and speed of heart disease\ndiagnosis. In this study, we proposed a comprehensive framework that combines\nclassification models for heart disease detection and regression models for\nrisk prediction. We employed the Heart Disease dataset, which comprises 1,035\ncases. To address the issue of class imbalance, the Synthetic Minority\nOversampling Technique (SMOTE) was applied, resulting in the generation of an\nadditional 100,000 synthetic data points. Performance metrics, including\naccuracy, precision, recall, F1-score, R2, MSE, RMSE, and MAE, were used to\nevaluate the model's effectiveness. Among the classification models, Random\nForest emerged as the standout performer, achieving an accuracy of 97.2% on\nreal data and 97.6% on synthetic data. For regression tasks, Linear Regression\ndemonstrated the highest R2 values of 0.992 and 0.984 on real and synthetic\ndatasets, respectively, with the lowest error metrics. Additionally,\nExplainable AI techniques were employed to enhance the interpretability of the\nmodels. This study highlights the potential of machine learning to\nrevolutionize heart disease diagnosis and risk prediction, thereby facilitating\nearly intervention and enhancing clinical decision-making.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u7ed3\u5408\u5206\u7c7b\u548c\u56de\u5f52\u6a21\u578b\uff0c\u5e76\u5229\u7528SMOTE\u548c\u53ef\u89e3\u91caAI\u6280\u672f\uff0c\u5229\u7528\u673a\u5668\u5b66\u4e60\u63d0\u9ad8\u4e86\u5fc3\u810f\u75c5\u8bca\u65ad\u7684\u51c6\u786e\u6027\u548c\u98ce\u9669\u9884\u6d4b\u80fd\u529b\uff0c\u5176\u4e2d\u968f\u673a\u68ee\u6797\u548c\u7ebf\u6027\u56de\u5f52\u8868\u73b0\u7a81\u51fa\u3002", "motivation": "\u5fc3\u810f\u75c5\u662f\u5168\u7403\u4e3b\u8981\u7684\u5065\u5eb7\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u533b\u7597\u8d44\u6e90\u548c\u8bca\u65ad\u8bbe\u65bd\u6709\u9650\u7684\u5730\u533a\u3002\u4f20\u7edf\u8bca\u65ad\u65b9\u6cd5\u5728\u51c6\u786e\u8bc6\u522b\u548c\u7ba1\u7406\u5fc3\u810f\u75c5\u98ce\u9669\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u53ef\u80fd\u5bfc\u81f4\u4e0d\u826f\u540e\u679c\u3002\u673a\u5668\u5b66\u4e60\u5728\u63d0\u9ad8\u5fc3\u810f\u75c5\u8bca\u65ad\u7684\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u901f\u5ea6\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u5206\u7c7b\u6a21\u578b\uff08\u7528\u4e8e\u5fc3\u810f\u75c5\u68c0\u6d4b\uff09\u548c\u56de\u5f52\u6a21\u578b\uff08\u7528\u4e8e\u98ce\u9669\u9884\u6d4b\uff09\u7684\u7efc\u5408\u6846\u67b6\u3002\u7814\u7a76\u91c7\u7528\u4e86\u5305\u542b1035\u4e2a\u75c5\u4f8b\u7684\u5fc3\u810f\u75c5\u6570\u636e\u96c6\u3002\u4e3a\u4e86\u89e3\u51b3\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5e94\u7528\u4e86\u5408\u6210\u5c11\u6570\u7c7b\u8fc7\u91c7\u6837\u6280\u672f\uff08SMOTE\uff09\uff0c\u751f\u6210\u4e86100,000\u4e2a\u5408\u6210\u6570\u636e\u70b9\u3002\u4f7f\u7528\u51c6\u786e\u7387\u3001\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u3001F1\u5206\u6570\u3001R2\u3001MSE\u3001RMSE\u548cMAE\u7b49\u6027\u80fd\u6307\u6807\u6765\u8bc4\u4f30\u6a21\u578b\u6548\u679c\u3002\u6b64\u5916\uff0c\u8fd8\u91c7\u7528\u4e86\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\u6280\u672f\u6765\u589e\u5f3a\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u5728\u5206\u7c7b\u6a21\u578b\u4e2d\uff0c\u968f\u673a\u68ee\u6797\u8868\u73b0\u6700\u4f73\uff0c\u5728\u771f\u5b9e\u6570\u636e\u4e0a\u51c6\u786e\u7387\u4e3a97.2%\uff0c\u5728\u5408\u6210\u6570\u636e\u4e0a\u4e3a97.6%\u3002\u5728\u56de\u5f52\u4efb\u52a1\u4e2d\uff0c\u7ebf\u6027\u56de\u5f52\u5728\u771f\u5b9e\u548c\u5408\u6210\u6570\u636e\u96c6\u4e0a\u5206\u522b\u53d6\u5f97\u4e86\u6700\u9ad8\u7684R2\u503c\uff080.992\u548c0.984\uff09\uff0c\u540c\u65f6\u9519\u8bef\u6307\u6807\u6700\u4f4e\u3002", "conclusion": "\u672c\u7814\u7a76\u5c55\u793a\u4e86\u673a\u5668\u5b66\u4e60\u5728\u5fc3\u810f\u75c5\u8bca\u65ad\u548c\u98ce\u9669\u9884\u6d4b\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u6709\u52a9\u4e8e\u65e9\u671f\u5e72\u9884\u548c\u6539\u5584\u4e34\u5e8a\u51b3\u7b56\u3002"}}
{"id": "2507.11476", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11476", "abs": "https://arxiv.org/abs/2507.11476", "authors": ["Esteban Rom\u00e1n Catafau", "Torbj\u00f6rn E. M. Nordling"], "title": "C-FBI: A Combinatorial method using Convolutions for Circle Fitting in Blurry Images", "comment": "22 pages, 16 figures", "summary": "This paper addresses the fundamental computer vision challenge of robust\ncircle detection and fitting in degraded imaging conditions. We present\nCombinatorial Convolution-based Circle Fitting for Blurry Images (3C-FBI), an\nalgorithm that bridges the gap between circle detection and precise parametric\nfitting by combining (1) efficient combinatorial edge pixel (edgel) sampling\nand (2) convolution-based density estimation in parameter space.\n  We evaluate 3C-FBI across three experimental frameworks: (1) real-world\nmedical data from Parkinson's disease assessments (144 frames from 36 videos),\n(2) controlled synthetic data following established circle-fitting benchmarks,\nand (3) systematic analysis across varying spatial resolutions and outlier\ncontamination levels. Results show that 3C-FBI achieves state-of-the-art\naccuracy (Jaccard index 0.896) while maintaining real-time performance (40.3\nfps), significantly outperforming classical methods like RCD (6.8 fps) on a\nstandard CPU (i7-10875H). It maintains near-perfect accuracy (Jaccard almost\n1.0) at high resolutions (480x480) and reliable performance (Jaccard higher\nthan 0.95) down to 160x160 with up to 20% outliers.\n  In extensive synthetic testing, 3C-FBI achieves a mean Jaccard Index of 0.989\nacross contamination levels, comparable to modern methods like Qi et al. (2024,\n0.991), and surpassing RHT (0.964). This combination of accuracy, speed, and\nrobustness makes 3C-FBI ideal for medical imaging, robotics, and industrial\ninspection under challenging conditions.", "AI": {"tldr": "3C-FBI \u662f\u4e00\u79cd\u65b0\u7684\u5706\u68c0\u6d4b\u548c\u62df\u5408\u7b97\u6cd5\uff0c\u5728\u6a21\u7cca\u56fe\u50cf\u548c\u5b58\u5728\u5f02\u5e38\u503c\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u51fa\u8272\uff0c\u901f\u5ea6\u5feb\u3001\u7cbe\u5ea6\u9ad8\u3002", "motivation": "\u89e3\u51b3\u5728\u6076\u52a3\u6210\u50cf\u6761\u4ef6\u4e0b\u9c81\u68d2\u7684\u5706\u68c0\u6d4b\u548c\u62df\u5408\u8fd9\u4e00\u8ba1\u7b97\u673a\u89c6\u89c9\u57fa\u672c\u6311\u6218\u3002", "method": "3C-FBI \u7b97\u6cd5\u7ed3\u5408\u4e86\u8fb9\u7f18\u50cf\u7d20\uff08edgel\uff09\u91c7\u6837\u548c\u53c2\u6570\u7a7a\u95f4\u4e2d\u7684\u5377\u79ef\u5bc6\u5ea6\u4f30\u8ba1\u3002", "result": "3C-FBI \u5728\u771f\u5b9e\u4e16\u754c\u533b\u5b66\u6570\u636e\u3001\u5408\u6210\u6570\u636e\u548c\u4e0d\u540c\u5206\u8fa8\u7387\u53ca\u5f02\u5e38\u503c\u5e72\u6270\u6c34\u5e73\u7684\u6d4b\u8bd5\u4e2d\u5747\u8868\u73b0\u51fa\u8272\uff0c\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u51c6\u786e\u6027\uff08Jaccard \u6307\u6570 0.896\uff09\uff0c\u5e76\u4fdd\u6301\u5b9e\u65f6\u6027\u80fd\uff0840.3 fps\uff09\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "3C-FBI \u7b97\u6cd5\u7ed3\u5408\u4e86\u8fb9\u7f18\u50cf\u7d20\u91c7\u6837\u548c\u53c2\u6570\u7a7a\u95f4\u4e2d\u7684\u5377\u79ef\u5bc6\u5ea6\u4f30\u8ba1\uff0c\u5728\u6076\u52a3\u6210\u50cf\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u5353\u8d8a\u7684\u5706\u68c0\u6d4b\u548c\u62df\u5408\u7cbe\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u5b9e\u65f6\u6027\u80fd\uff0c\u975e\u5e38\u9002\u5408\u533b\u5b66\u6210\u50cf\u3001\u673a\u5668\u4eba\u548c\u5de5\u4e1a\u68c0\u6d4b\u7b49\u9886\u57df\u3002"}}
{"id": "2507.11187", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11187", "abs": "https://arxiv.org/abs/2507.11187", "authors": ["Shao-Bo Lin", "Xiaotong Liu", "Yao Wang"], "title": "Striking the Perfect Balance: Preserving Privacy While Boosting Utility in Collaborative Medical Prediction Platforms", "comment": null, "summary": "Online collaborative medical prediction platforms offer convenience and\nreal-time feedback by leveraging massive electronic health records. However,\ngrowing concerns about privacy and low prediction quality can deter patient\nparticipation and doctor cooperation. In this paper, we first clarify the\nprivacy attacks, namely attribute attacks targeting patients and model\nextraction attacks targeting doctors, and specify the corresponding privacy\nprinciples. We then propose a privacy-preserving mechanism and integrate it\ninto a novel one-shot distributed learning framework, aiming to simultaneously\nmeet both privacy requirements and prediction performance objectives. Within\nthe framework of statistical learning theory, we theoretically demonstrate that\nthe proposed distributed learning framework can achieve the optimal prediction\nperformance under specific privacy requirements. We further validate the\ndeveloped privacy-preserving collaborative medical prediction platform through\nboth toy simulations and real-world data experiments.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u3001\u6ce8\u91cd\u9690\u79c1\u7684\u5728\u7ebf\u534f\u4f5c\u533b\u7597\u9884\u6d4b\u5e73\u53f0\uff0c\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5b83\u53ef\u4ee5\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u5b9e\u73b0\u6700\u4f73\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5728\u7ebf\u534f\u4f5c\u533b\u7597\u9884\u6d4b\u5e73\u53f0\u4e2d\u5b58\u5728\u7684\u9690\u79c1\u95ee\u9898\u548c\u9884\u6d4b\u8d28\u91cf\u4f4e\u7684\u95ee\u9898\uff0c\u4ee5\u9f13\u52b1\u60a3\u8005\u53c2\u4e0e\u548c\u533b\u751f\u5408\u4f5c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6ce8\u91cd\u9690\u79c1\u7684\u673a\u5236\uff0c\u5e76\u5c06\u5176\u6574\u5408\u5230\u4e00\u4e2a\u65b0\u9896\u7684\u5355\u6b21\u5206\u5e03\u5f0f\u5b66\u4e60\u6846\u67b6\u4e2d\uff0c\u8be5\u6846\u67b6\u5728\u7edf\u8ba1\u5b66\u4e60\u7406\u8bba\u7684\u6846\u67b6\u5185\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\uff0c\u5e76\u8f85\u4ee5\u73a9\u5177\u6a21\u62df\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u5b9e\u9a8c\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u5206\u5e03\u5f0f\u5b66\u4e60\u6846\u67b6\u5728\u7279\u5b9a\u9690\u79c1\u8981\u6c42\u4e0b\u53ef\u4ee5\u5b9e\u73b0\u6700\u4f73\u9884\u6d4b\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u5b9e\u9a8c\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u3001\u6ce8\u91cd\u9690\u79c1\u7684\u5206\u5e03\u5f0f\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u7ebf\u534f\u4f5c\u533b\u7597\u9884\u6d4b\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u5728\u6ee1\u8db3\u9690\u79c1\u8981\u6c42\u7684\u540c\u65f6\u5b9e\u73b0\u6700\u4f73\u9884\u6d4b\u6027\u80fd\u7684\u80fd\u529b\u3002"}}
{"id": "2507.11488", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11488", "abs": "https://arxiv.org/abs/2507.11488", "authors": ["Pakizar Shamoi", "Nuray Toganas", "Muragul Muratbekova", "Elnara Kadyrgali", "Adilet Yerkin", "Ayan Igali", "Malika Ziyada", "Ayana Adilova", "Aron Karatayev", "Yerdauit Torekhan"], "title": "COLIBRI Fuzzy Model: Color Linguistic-Based Representation and Interpretation", "comment": "submitted to IEEE for consideration", "summary": "Colors are omnipresent in today's world and play a vital role in how humans\nperceive and interact with their surroundings. However, it is challenging for\ncomputers to imitate human color perception. This paper introduces the Human\nPerception-Based Fuzzy Color Model, COLIBRI (Color Linguistic-Based\nRepresentation and Interpretation), designed to bridge the gap between\ncomputational color representations and human visual perception. The proposed\nmodel uses fuzzy sets and logic to create a framework for color categorization.\nUsing a three-phase experimental approach, the study first identifies\ndistinguishable color stimuli for hue, saturation, and intensity through\npreliminary experiments, followed by a large-scale human categorization survey\ninvolving more than 1000 human subjects. The resulting data are used to extract\nfuzzy partitions and generate membership functions that reflect real-world\nperceptual uncertainty. The model incorporates a mechanism for adaptation that\nallows refinement based on feedback and contextual changes. Comparative\nevaluations demonstrate the model's alignment with human perception compared to\ntraditional color models, such as RGB, HSV, and LAB. To the best of our\nknowledge, no previous research has documented the construction of a model for\ncolor attribute specification based on a sample of this size or a comparable\nsample of the human population (n = 2496). Our findings are significant for\nfields such as design, artificial intelligence, marketing, and human-computer\ninteraction, where perceptually relevant color representation is critical.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCOLIBRI\u7684\u4eba\u7c7b\u611f\u77e5\u989c\u8272\u6a21\u578b\uff0c\u4f7f\u7528\u6a21\u7cca\u903b\u8f91\u6765\u6a21\u4eff\u4eba\u7c7b\u7684\u989c\u8272\u611f\u77e5\uff0c\u5e76\u901a\u8fc7\u5927\u89c4\u6a21\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u4f18\u4e8e\u4f20\u7edf\u989c\u8272\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5728\u8bbe\u8ba1\u3001\u4eba\u5de5\u667a\u80fd\u3001\u5e02\u573a\u8425\u9500\u548c\u4eba\u673a\u4ea4\u4e92\u7b49\u9886\u57df\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "motivation": "\u4e3a\u4e86\u5f25\u5408\u8ba1\u7b97\u989c\u8272\u8868\u793a\u4e0e\u4eba\u7c7b\u89c6\u89c9\u611f\u77e5\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u672c\u7814\u7a76\u65e8\u5728\u521b\u5efa\u4e00\u4e2a\u80fd\u591f\u6a21\u4eff\u4eba\u7c7b\u989c\u8272\u611f\u77e5\u7684\u8ba1\u7b97\u673a\u6a21\u578b\u3002", "method": "COLIBRI\u6a21\u578b\u91c7\u7528\u4e09\u9636\u6bb5\u5b9e\u9a8c\u65b9\u6cd5\uff0c\u9996\u5148\u901a\u8fc7\u521d\u6b65\u5b9e\u9a8c\u8bc6\u522b\u989c\u8272\u523a\u6fc0\uff0c\u7136\u540e\u8fdb\u884c\u5927\u89c4\u6a21\u4eba\u7c7b\u989c\u8272\u5206\u7c7b\u8c03\u67e5\uff08\u8d85\u8fc71000\u540d\u53d7\u8bd5\u8005\uff09\uff0c\u6700\u540e\u63d0\u53d6\u6a21\u7cca\u5206\u533a\u548c\u751f\u6210\u6210\u5458\u51fd\u6570\u3002\u6a21\u578b\u8fd8\u5305\u542b\u4e00\u4e2a\u9002\u5e94\u673a\u5236\uff0c\u53ef\u6839\u636e\u53cd\u9988\u548c\u4e0a\u4e0b\u6587\u53d8\u5316\u8fdb\u884c\u4f18\u5316\u3002", "result": "COLIBRI\u6a21\u578b\u5728\u989c\u8272\u5206\u7c7b\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6210\u679c\uff0c\u4e0eRGB\u3001HSV\u548cLAB\u7b49\u4f20\u7edf\u6a21\u578b\u76f8\u6bd4\uff0c\u66f4\u7b26\u5408\u4eba\u7c7b\u611f\u77e5\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u8be5\u6a21\u578b\u57fa\u4e8e\u5927\u89c4\u6a21\u6837\u672c\uff08n=2496\uff09\u6784\u5efa\uff0c\u5728\u989c\u8272\u5c5e\u6027\u89c4\u8303\u65b9\u9762\u5177\u6709\u521b\u65b0\u6027\u3002", "conclusion": "\u8be5COLIBRI\u6a21\u578b\u901a\u8fc7\u6a21\u7cca\u96c6\u548c\u903b\u8f91\u6765\u6a21\u62df\u4eba\u7c7b\u7684\u989c\u8272\u611f\u77e5\uff0c\u5e76\u5728\u989c\u8272\u5206\u7c7b\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6210\u679c\uff0c\u4e0eRGB\u3001HSV\u548cLAB\u7b49\u4f20\u7edf\u6a21\u578b\u76f8\u6bd4\uff0c\u66f4\u7b26\u5408\u4eba\u7c7b\u611f\u77e5\u3002"}}
{"id": "2507.11228", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.11228", "abs": "https://arxiv.org/abs/2507.11228", "authors": ["Si Yi Meng", "Baptiste Goujaud", "Antonio Orvieto", "Christopher De Sa"], "title": "Gradient Descent on Logistic Regression: Do Large Step-Sizes Work with Data on the Sphere?", "comment": null, "summary": "Gradient descent (GD) on logistic regression has many fascinating properties.\nWhen the dataset is linearly separable, it is known that the iterates converge\nin direction to the maximum-margin separator regardless of how large the step\nsize is. In the non-separable case, however, it has been shown that GD can\nexhibit a cycling behaviour even when the step sizes is still below the\nstability threshold $2/\\lambda$, where $\\lambda$ is the largest eigenvalue of\nthe Hessian at the solution. This short paper explores whether restricting the\ndata to have equal magnitude is a sufficient condition for global convergence,\nunder any step size below the stability threshold. We prove that this is true\nin a one dimensional space, but in higher dimensions cycling behaviour can\nstill occur. We hope to inspire further studies on quantifying how common these\ncycles are in realistic datasets, as well as finding sufficient conditions to\nguarantee global convergence with large step sizes.", "AI": {"tldr": "\u68af\u5ea6\u4e0b\u964d\u5728\u5177\u6709\u76f8\u7b49\u5e45\u5ea6\u7684\u6570\u636e\u96c6\u4e0a\u7684\u6536\u655b\u6027\u53d6\u51b3\u4e8e\u6570\u636e\u7684\u7ef4\u5ea6\u3002\u5728\u4e00\u7ef4\u7a7a\u95f4\u4e2d\u53ef\u4ee5\u4fdd\u8bc1\u5168\u5c40\u6536\u655b\uff0c\u4f46\u5728\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u4ecd\u7136\u53ef\u80fd\u51fa\u73b0\u5faa\u73af\u884c\u4e3a\u3002", "motivation": "\u63a2\u7a76\u5c06\u6570\u636e\u96c6\u9650\u5236\u4e3a\u5177\u6709\u76f8\u7b49\u5e45\u5ea6\u662f\u5426\u662f\u5168\u5c40\u6536\u655b\u7684\u5145\u5206\u6761\u4ef6\uff0c\u5373\u4f7f\u6b65\u957f\u53ef\u4ee5\u8d85\u8fc7\u7a33\u5b9a\u6027\u9608\u503c\u3002", "method": "\u901a\u8fc7\u5728\u4e0d\u540c\u7ef4\u5ea6\uff08\u4e00\u7ef4\u548c\u9ad8\u7ef4\uff09\u4e0a\u7814\u7a76\u68af\u5ea6\u4e0b\u964d\u7684\u6536\u655b\u884c\u4e3a\u6765\u5206\u6790\u3002", "result": "\u5728\u4e8c\u7ef4\u7a7a\u95f4\u4e2d\uff0c\u68af\u5ea6\u4e0b\u964d\u8868\u73b0\u51fa\u5faa\u73af\u884c\u4e3a\uff0c\u5373\u4f7f\u5728\u7a33\u5b9a\u6027\u9608\u503c\u4ee5\u4e0b\u4f7f\u7528\u4efb\u4f55\u6b65\u957f\u4e5f\u662f\u5982\u6b64\u3002\u7136\u800c\uff0c\u5728\u4e00\u7ef4\u7a7a\u95f4\u4e2d\uff0c\u5f53\u6570\u636e\u96c6\u5177\u6709\u76f8\u7b49\u5e45\u5ea6\u65f6\uff0c\u53ef\u4ee5\u4fdd\u8bc1\u5168\u5c40\u6536\u655b\u3002", "conclusion": "\u5f53\u6570\u636e\u96c6\u5177\u6709\u76f8\u7b49\u5e45\u5ea6\u65f6\uff0c\u5e76\u4e0d\u80fd\u4fdd\u8bc1\u68af\u5ea6\u4e0b\u964d\u5728\u6240\u6709\u7ef4\u5ea6\u4e0a\u90fd\u80fd\u5168\u5c40\u6536\u655b\u3002"}}
{"id": "2507.11522", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11522", "abs": "https://arxiv.org/abs/2507.11522", "authors": ["Tariq Mehmood", "Hamza Ahmad", "Muhammad Haroon Shakeel", "Murtaza Taj"], "title": "CATVis: Context-Aware Thought Visualization", "comment": "Accepted at MICCAI 2025. This is the submitted version prior to peer\n  review. The final Version of Record will appear in the MICCAI 2025\n  proceedings (Springer LNCS)", "summary": "EEG-based brain-computer interfaces (BCIs) have shown promise in various\napplications, such as motor imagery and cognitive state monitoring. However,\ndecoding visual representations from EEG signals remains a significant\nchallenge due to their complex and noisy nature. We thus propose a novel\n5-stage framework for decoding visual representations from EEG signals: (1) an\nEEG encoder for concept classification, (2) cross-modal alignment of EEG and\ntext embeddings in CLIP feature space, (3) caption refinement via re-ranking,\n(4) weighted interpolation of concept and caption embeddings for richer\nsemantics, and (5) image generation using a pre-trained Stable Diffusion model.\nWe enable context-aware EEG-to-image generation through cross-modal alignment\nand re-ranking. Experimental results demonstrate that our method generates\nhigh-quality images aligned with visual stimuli, outperforming SOTA approaches\nby 13.43% in Classification Accuracy, 15.21% in Generation Accuracy and\nreducing Fr\\'echet Inception Distance by 36.61%, indicating superior semantic\nalignment and image quality.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4e94\u9636\u6bb5EEG\u5230\u56fe\u50cf\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u8de8\u6a21\u6001\u5bf9\u9f50\u548c\u91cd\u6392\u5b9e\u73b0\u4e0a\u4e0b\u6587\u611f\u77e5\uff0c\u5e76\u5728\u51c6\u786e\u6027\u548c\u56fe\u50cf\u8d28\u91cf\u65b9\u9762\u8d85\u8d8a\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u89e3\u51b3\u4ece\u590d\u6742\u4e14\u5608\u6742\u7684EEG\u4fe1\u53f7\u89e3\u7801\u89c6\u89c9\u8868\u5f81\u7684\u6311\u6218\uff0c\u5b9e\u73b0\u4e0a\u4e0b\u6587\u611f\u77e5\u7684EEG\u5230\u56fe\u50cf\u751f\u6210\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4e94\u9636\u6bb5\u6846\u67b6\uff0c\u5305\u62ecEEG\u7f16\u7801\u5668\u3001\u8de8\u6a21\u6001\u5bf9\u9f50\u3001\u6807\u9898\u91cd\u6392\u3001\u6982\u5ff5\u548c\u6807\u9898\u5d4c\u5165\u7684\u52a0\u6743\u63d2\u503c\u4ee5\u53ca\u4f7f\u7528Stable Diffusion\u6a21\u578b\u7684\u56fe\u50cf\u751f\u6210\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u751f\u6210\u7684\u56fe\u50cf\u4e0e\u89c6\u89c9\u523a\u6fc0\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5728\u5206\u7c7b\u51c6\u786e\u7387\u3001\u751f\u6210\u51c6\u786e\u7387\u548cFr\u00e9chet Inception Distance\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728EEG\u4fe1\u53f7\u7684\u8de8\u6a21\u6001\u5206\u6790\u548c\u56fe\u50cf\u751f\u6210\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u6846\u67b6\u5b9e\u73b0\u4e86\u4e0a\u4e0b\u6587\u611f\u77e5\u7684EEG\u5230\u56fe\u50cf\u751f\u6210\uff0c\u5e76\u5728\u51c6\u786e\u6027\u548c\u56fe\u50cf\u8d28\u91cf\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002"}}
{"id": "2507.11246", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11246", "abs": "https://arxiv.org/abs/2507.11246", "authors": ["Lingwei Kong", "Lu Wang", "Changping Peng", "Zhangang Lin", "Ching Law", "Jingping Shao"], "title": "Generative Click-through Rate Prediction with Applications to Search Advertising", "comment": "This work was first submitted on February 9, 2024", "summary": "Click-Through Rate (CTR) prediction models are integral to a myriad of\nindustrial settings, such as personalized search advertising. Current methods\ntypically involve feature extraction from users' historical behavior sequences\ncombined with product information, feeding into a discriminative model that is\ntrained on user feedback to estimate CTR. With the success of models such as\nGPT, the potential for generative models to enrich expressive power beyond\ndiscriminative models has become apparent. In light of this, we introduce a\nnovel model that leverages generative models to enhance the precision of CTR\npredictions in discriminative models. To reconcile the disparate data\naggregation needs of both model types, we design a two-stage training process:\n1) Generative pre-training for next-item prediction with the given item\ncategory in user behavior sequences; 2) Fine-tuning the well-trained generative\nmodel within a discriminative CTR prediction framework. Our method's efficacy\nis substantiated through extensive experiments on a new dataset, and its\nsignificant utility is further corroborated by online A/B testing results.\nCurrently, the model is deployed on one of the world's largest e-commerce\nplatforms, and we intend to release the associated code and dataset in the\nfuture.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u751f\u6210\u6a21\u578b\u548c\u5224\u522b\u6a21\u578b\u7684CTR\u9884\u6d4b\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u63d0\u5347\u4e86CTR\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5e76\u5728\u5927\u578b\u7535\u5546\u5e73\u53f0\u6210\u529f\u90e8\u7f72\u3002", "motivation": "\u968f\u7740GPT\u7b49\u6a21\u578b\u53d6\u5f97\u6210\u529f\uff0c\u751f\u6210\u6a21\u578b\u5728\u8d85\u8d8a\u5224\u522b\u6a21\u578b\u65b9\u9762\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u751f\u6210\u6a21\u578b\u589e\u5f3a\u5224\u522b\u6a21\u578bCTR\u9884\u6d4b\u7cbe\u5ea6\u7684\u65b0\u578b\u6a21\u578b\u3002\u8be5\u6a21\u578b\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u8fc7\u7a0b\uff1a1\uff09\u5bf9\u7528\u6237\u884c\u4e3a\u5e8f\u5217\u4e2d\u7684\u7ed9\u5b9a\u9879\u7c7b\u522b\u8fdb\u884c\u4e0b\u4e00\u9879\u9884\u6d4b\u7684\u751f\u6210\u9884\u8bad\u7ec3\uff1b2\uff09\u5728\u5224\u522b\u6a21\u578bCTR\u9884\u6d4b\u6846\u67b6\u5185\u5bf9\u9884\u8bad\u7ec3\u7684\u751f\u6210\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u901a\u8fc7\u5728\u65b0\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u548c\u5728\u7ebfA/B\u6d4b\u8bd5\u7ed3\u679c\u8bc1\u5b9e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u91cd\u8981\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "\u8be5\u6a21\u578b\u5df2\u6210\u529f\u5e94\u7528\u4e8e\u5168\u7403\u6700\u5927\u7684\u7535\u5b50\u5546\u52a1\u5e73\u53f0\u4e4b\u4e00\uff0c\u5e76\u4e14\u672a\u6765\u5c06\u53d1\u5e03\u76f8\u5173\u4ee3\u7801\u548c\u6570\u636e\u96c6\u3002"}}
{"id": "2507.11533", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11533", "abs": "https://arxiv.org/abs/2507.11533", "authors": ["Mengyu Wang", "Henghui Ding", "Jianing Peng", "Yao Zhao", "Yunpeng Chen", "Yunchao Wei"], "title": "CharaConsist: Fine-Grained Consistent Character Generation", "comment": "ICCV 2025 accepted paper, project page:\n  https://murray-wang.github.io/CharaConsist/", "summary": "In text-to-image generation, producing a series of consistent contents that\npreserve the same identity is highly valuable for real-world applications.\nAlthough a few works have explored training-free methods to enhance the\nconsistency of generated subjects, we observe that they suffer from the\nfollowing problems. First, they fail to maintain consistent background details,\nwhich limits their applicability. Furthermore, when the foreground character\nundergoes large motion variations, inconsistencies in identity and clothing\ndetails become evident. To address these problems, we propose CharaConsist,\nwhich employs point-tracking attention and adaptive token merge along with\ndecoupled control of the foreground and background. CharaConsist enables\nfine-grained consistency for both foreground and background, supporting the\ngeneration of one character in continuous shots within a fixed scene or in\ndiscrete shots across different scenes. Moreover, CharaConsist is the first\nconsistent generation method tailored for text-to-image DiT model. Its ability\nto maintain fine-grained consistency, combined with the larger capacity of\nlatest base model, enables it to produce high-quality visual outputs,\nbroadening its applicability to a wider range of real-world scenarios. The\nsource code has been released at https://github.com/Murray-Wang/CharaConsist", "AI": {"tldr": "CharaConsist improves text-to-image generation by ensuring consistent characters and backgrounds, even with large motions, using point-tracking attention and adaptive token merging, and is the first method for DiT models.", "motivation": "Existing training-free methods for text-to-image generation suffer from inconsistent background details and identity/clothing inconsistencies when the foreground character undergoes large motion variations.", "method": "CharaConsist employs point-tracking attention and adaptive token merge along with decoupled control of the foreground and background.", "result": "CharaConsist enables fine-grained consistency for both foreground and background, addressing the limitations of previous methods and producing high-quality visual outputs suitable for various real-world applications.", "conclusion": "CharaConsist enables fine-grained consistency for both foreground and background, supporting the generation of one character in continuous shots within a fixed scene or in discrete shots across different scenes. It is the first consistent generation method tailored for text-to-image DiT model and produces high-quality visual outputs, broadening its applicability to a wider range of real-world scenarios."}}
{"id": "2507.11262", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2507.11262", "abs": "https://arxiv.org/abs/2507.11262", "authors": ["Elmira Mirzabeigi", "Sepehr Rezaee", "Kourosh Parand"], "title": "LyAm: Robust Non-Convex Optimization for Stable Learning in Noisy Environments", "comment": null, "summary": "Training deep neural networks, particularly in computer vision tasks, often\nsuffers from noisy gradients and unstable convergence, which hinder performance\nand generalization. In this paper, we propose LyAm, a novel optimizer that\nintegrates Adam's adaptive moment estimation with Lyapunov-based stability\nmechanisms. LyAm dynamically adjusts the learning rate using Lyapunov stability\ntheory to enhance convergence robustness and mitigate training noise. We\nprovide a rigorous theoretical framework proving the convergence guarantees of\nLyAm in complex, non-convex settings. Extensive experiments on like as CIFAR-10\nand CIFAR-100 show that LyAm consistently outperforms state-of-the-art\noptimizers in terms of accuracy, convergence speed, and stability, establishing\nit as a strong candidate for robust deep learning optimization.", "AI": {"tldr": "LyAm is a new optimizer that improves deep learning training by combining Adam with Lyapunov stability theory, leading to better accuracy, faster convergence, and enhanced stability in computer vision tasks.", "motivation": "Training deep neural networks for computer vision tasks often suffers from noisy gradients and unstable convergence, hindering performance and generalization.", "method": "LyAm, a novel optimizer that integrates Adam's adaptive moment estimation with Lyapunov-based stability mechanisms, dynamically adjusts the learning rate using Lyapunov stability theory to enhance convergence robustness and mitigate training noise. The paper also provides a rigorous theoretical framework proving the convergence guarantees of LyAm in complex, non-convex settings.", "result": "Extensive experiments on CIFAR-10 and CIFAR-100 show that LyAm consistently outperforms state-of-the-art optimizers in accuracy, convergence speed, and stability.", "conclusion": "LyAm Optimizer, which integrates Adam with Lyapunov-based stability mechanisms, demonstrates superior performance over state-of-the-art optimizers in terms of accuracy, convergence speed, and stability, making it a strong candidate for robust deep learning optimization."}}
{"id": "2507.11539", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11539", "abs": "https://arxiv.org/abs/2507.11539", "authors": ["Dong Zhuo", "Wenzhao Zheng", "Jiahe Guo", "Yuqi Wu", "Jie Zhou", "Jiwen Lu"], "title": "Streaming 4D Visual Geometry Transformer", "comment": "Code is available at: https://github.com/wzzheng/StreamVGGT", "summary": "Perceiving and reconstructing 4D spatial-temporal geometry from videos is a\nfundamental yet challenging computer vision task. To facilitate interactive and\nreal-time applications, we propose a streaming 4D visual geometry transformer\nthat shares a similar philosophy with autoregressive large language models. We\nexplore a simple and efficient design and employ a causal transformer\narchitecture to process the input sequence in an online manner. We use temporal\ncausal attention and cache the historical keys and values as implicit memory to\nenable efficient streaming long-term 4D reconstruction. This design can handle\nreal-time 4D reconstruction by incrementally integrating historical information\nwhile maintaining high-quality spatial consistency. For efficient training, we\npropose to distill knowledge from the dense bidirectional visual geometry\ngrounded transformer (VGGT) to our causal model. For inference, our model\nsupports the migration of optimized efficient attention operator (e.g.,\nFlashAttention) from the field of large language models. Extensive experiments\non various 4D geometry perception benchmarks demonstrate that our model\nincreases the inference speed in online scenarios while maintaining competitive\nperformance, paving the way for scalable and interactive 4D vision systems.\nCode is available at: https://github.com/wzzheng/StreamVGGT.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6d41\u5f0f4D\u89c6\u89c9\u51e0\u4f55\u53d8\u6362\u5668\uff0c\u53ef\u4ee5\u5b9e\u65f6\u4ece\u89c6\u9891\u4e2d\u91cd\u5efa4D\u51e0\u4f55\uff0c\u901f\u5ea6\u5feb\u4e14\u8d28\u91cf\u9ad8\u3002", "motivation": "\u4e3a\u4e86\u4fc3\u8fdb\u4ea4\u4e92\u5f0f\u548c\u5b9e\u65f6\u5e94\u7528\uff0c\u7814\u7a76\u5982\u4f55\u4ece\u89c6\u9891\u4e2d\u611f\u77e5\u548c\u91cd\u5efa4D\u65f6\u7a7a\u51e0\u4f55\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6d41\u5f0f4D\u89c6\u89c9\u51e0\u4f55\u53d8\u6362\u5668\uff0c\u91c7\u7528\u56e0\u679c\u53d8\u6362\u5668\u67b6\u6784\uff0c\u5229\u7528\u65f6\u95f4\u56e0\u679c\u6ce8\u610f\u529b\u548c\u7f13\u5b58\u5386\u53f2\u952e\u503c\u4f5c\u4e3a\u9690\u5f0f\u8bb0\u5fc6\uff0c\u4ee5\u5728\u7ebf\u65b9\u5f0f\u5904\u7406\u8f93\u5165\u5e8f\u5217\uff0c\u5e76\u4ece\u5bc6\u96c6\u7684\u53cc\u5411\u89c6\u89c9\u51e0\u4f55\u57fa\u7840\u53d8\u6362\u5668\uff08VGGT\uff09\u4e2d\u84b8\u998f\u77e5\u8bc6\u3002", "result": "\u5728\u5404\u79cd4D\u51e0\u4f55\u611f\u77e5\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u6a21\u578b\u5728\u5728\u7ebf\u573a\u666f\u4e0b\u63d0\u9ad8\u4e86\u63a8\u7406\u901f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u6a21\u578b\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u548c\u4f18\u5316\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728\u4fdd\u6301\u9ad8\u8d28\u91cf\u7a7a\u95f4\u4e00\u81f4\u6027\u7684\u540c\u65f6\uff0c\u63d0\u9ad8\u4e86\u5728\u7ebf\u573a\u666f\u4e0b\u7684\u63a8\u7406\u901f\u5ea6\uff0c\u4e3a\u53ef\u6269\u5c55\u548c\u4ea4\u4e92\u5f0f\u76844D\u89c6\u89c9\u7cfb\u7edf\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2507.11269", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11269", "abs": "https://arxiv.org/abs/2507.11269", "authors": ["Tal Fiskus", "Uri Shaham"], "title": "Turning Sand to Gold: Recycling Data to Bridge On-Policy and Off-Policy Learning via Causal Bound", "comment": "51 pages, 16 figures", "summary": "Deep reinforcement learning (DRL) agents excel in solving complex\ndecision-making tasks across various domains. However, they often require a\nsubstantial number of training steps and a vast experience replay buffer,\nleading to significant computational and resource demands. To address these\nchallenges, we introduce a novel theoretical result that leverages the\nNeyman-Rubin potential outcomes framework into DRL. Unlike most methods that\nfocus on bounding the counterfactual loss, we establish a causal bound on the\nfactual loss, which is analogous to the on-policy loss in DRL. This bound is\ncomputed by storing past value network outputs in the experience replay buffer,\neffectively utilizing data that is usually discarded. Extensive experiments\nacross the Atari 2600 and MuJoCo domains on various agents, such as DQN and\nSAC, achieve up to 2,427% higher reward ratio, outperforming the same agents\nwithout our proposed term, and reducing the experience replay buffer size by up\nto 96%, significantly improving sample efficiency at negligible cost.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5c06\u6f5c\u5728\u7ed3\u679c\u6846\u67b6\u5e94\u7528\u4e8eDRL\uff0c\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\u5e76\u51cf\u5c0f\u4e86\u7ecf\u9a8c\u56de\u653e\u7f13\u51b2\u533a\u7684\u5927\u5c0f\uff0c\u5728Atari\u548cMuJoCo\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6210\u679c\u3002", "motivation": "\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u4ee3\u7406\u5728\u89e3\u51b3\u590d\u6742\u51b3\u7b56\u4efb\u52a1\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u9700\u8981\u5927\u91cf\u7684\u8bad\u7ec3\u6b65\u9aa4\u548c\u7ecf\u9a8c\u56de\u653e\u7f13\u51b2\u533a\uff0c\u5bfc\u81f4\u8ba1\u7b97\u548c\u8d44\u6e90\u9700\u6c42\u5f88\u9ad8\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u5c06Neyman-Rubin\u6f5c\u5728\u7ed3\u679c\u6846\u67b6\u5f15\u5165DRL\uff0c\u5e76\u5efa\u7acb\u4e86\u4e8b\u5b9e\u635f\u5931\u7684\u56e0\u679c\u754c\uff0c\u901a\u8fc7\u5b58\u50a8\u8fc7\u53bb\u7684\u4ef7\u503c\u7f51\u7edc\u8f93\u51fa\u6765\u8ba1\u7b97\u8be5\u754c\u9650\uff0c\u6709\u6548\u5229\u7528\u4e86\u901a\u5e38\u88ab\u4e22\u5f03\u7684\u6570\u636e\u3002", "result": "\u5728Atari 2600\u548cMuJoCo\u57df\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5c06\u5956\u52b1\u7387\u63d0\u9ad8\u9ad8\u8fbe2,427%\uff0c\u5e76\u4e14\u7ecf\u9a8c\u56de\u653e\u7f13\u51b2\u533a\u5927\u5c0f\u51cf\u5c11\u9ad8\u8fbe96%\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\uff0c\u800c\u6210\u672c\u6781\u5c0f\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7406\u8bba\u7ed3\u679c\uff0c\u5c06Neyman-Rubin\u6f5c\u5728\u7ed3\u679c\u6846\u67b6\u5e94\u7528\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\uff0c\u901a\u8fc7\u5bf9\u4e8b\u5b9e\u635f\u5931\uff08\u7c7b\u4f3c\u4e8eDRL\u4e2d\u7684 on-policy loss\uff09\u5efa\u7acb\u56e0\u679c\u754c\uff0c\u4ece\u800c\u63d0\u9ad8\u6837\u672c\u6548\u7387\u5e76\u51cf\u5c11\u5bf9\u7ecf\u9a8c\u56de\u653e\u7f13\u51b2\u533a\u7684\u9700\u6c42\u3002"}}
{"id": "2507.11540", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11540", "abs": "https://arxiv.org/abs/2507.11540", "authors": ["Zhen Xu", "Hongyu Zhou", "Sida Peng", "Haotong Lin", "Haoyu Guo", "Jiahao Shao", "Peishan Yang", "Qinglin Yang", "Sheng Miao", "Xingyi He", "Yifan Wang", "Yue Wang", "Ruizhen Hu", "Yiyi Liao", "Xiaowei Zhou", "Hujun Bao"], "title": "Towards Depth Foundation Model: Recent Trends in Vision-Based Depth Estimation", "comment": null, "summary": "Depth estimation is a fundamental task in 3D computer vision, crucial for\napplications such as 3D reconstruction, free-viewpoint rendering, robotics,\nautonomous driving, and AR/VR technologies. Traditional methods relying on\nhardware sensors like LiDAR are often limited by high costs, low resolution,\nand environmental sensitivity, limiting their applicability in real-world\nscenarios. Recent advances in vision-based methods offer a promising\nalternative, yet they face challenges in generalization and stability due to\neither the low-capacity model architectures or the reliance on domain-specific\nand small-scale datasets. The emergence of scaling laws and foundation models\nin other domains has inspired the development of \"depth foundation models\":\ndeep neural networks trained on large datasets with strong zero-shot\ngeneralization capabilities. This paper surveys the evolution of deep learning\narchitectures and paradigms for depth estimation across the monocular, stereo,\nmulti-view, and monocular video settings. We explore the potential of these\nmodels to address existing challenges and provide a comprehensive overview of\nlarge-scale datasets that can facilitate their development. By identifying key\narchitectures and training strategies, we aim to highlight the path towards\nrobust depth foundation models, offering insights into their future research\nand applications.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u6df1\u5ea6\u4f30\u8ba1\u6280\u672f\u7684\u53d1\u5c55\uff0c\u7279\u522b\u662f\u6df1\u5ea6\u57fa\u7840\u6a21\u578b\u7684\u6f5c\u529b\uff0c\u65e8\u5728\u514b\u670d\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u7814\u7a76\u548c\u5e94\u7528\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "\u4e3a\u4e86\u514b\u670d\u4f20\u7edf\u6df1\u5ea6\u4f30\u8ba1\u65b9\u6cd5\uff08\u5982\u57fa\u4e8e\u6fc0\u5149\u96f7\u8fbe\u7684\u65b9\u6cd5\uff09\u5728\u6210\u672c\u3001\u5206\u8fa8\u7387\u548c\u73af\u5883\u9002\u5e94\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5e76\u89e3\u51b3\u73b0\u6709\u57fa\u4e8e\u89c6\u89c9\u7684\u65b9\u6cd5\u5728\u6cdb\u5316\u6027\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u9762\u4e34\u7684\u6311\u6218\uff0c\u672c\u6587\u65e8\u5728\u63a2\u7d22\u6df1\u5ea6\u57fa\u7840\u6a21\u578b\u7684\u6f5c\u529b\uff0c\u4ee5\u5b9e\u73b0\u66f4\u9c81\u68d2\u7684\u6df1\u5ea6\u4f30\u8ba1\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5bf9\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u548c\u8303\u5f0f\u7684\u6f14\u53d8\u8fdb\u884c\u56de\u987e\uff0c\u4ee5\u53ca\u5bf9\u5927\u89c4\u6a21\u6570\u636e\u96c6\u7684\u6982\u8ff0\uff0c\u6765\u63a2\u8ba8\u6df1\u5ea6\u4f30\u8ba1\u9886\u57df\u7684\u53d1\u5c55\uff0c\u7279\u522b\u662f\u201c\u6df1\u5ea6\u57fa\u7840\u6a21\u578b\u201d\u7684\u6f5c\u529b\u3002", "result": "\u672c\u6587\u5bf9\u6df1\u5ea6\u4f30\u8ba1\u9886\u57df\u8fdb\u884c\u4e86\u5168\u9762\u7684\u6982\u8ff0\uff0c\u91cd\u70b9\u4ecb\u7ecd\u4e86\u6df1\u5ea6\u57fa\u7840\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u5305\u62ec\u5176\u5173\u952e\u67b6\u6784\u3001\u8bad\u7ec3\u7b56\u7565\u4ee5\u53ca\u5927\u89c4\u6a21\u6570\u636e\u96c6\u7684\u652f\u6301\uff0c\u65e8\u5728\u4e3a\u672a\u6765\u7684\u7814\u7a76\u548c\u5e94\u7528\u63d0\u4f9b\u6307\u5bfc\u3002", "conclusion": "\u6df1\u5ea6\u4f30\u8ba1\u4efb\u52a1\u57283D\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u662f\u57283D\u91cd\u5efa\u3001\u81ea\u7531\u89c6\u89d2\u6e32\u67d3\u3001\u673a\u5668\u4eba\u3001\u81ea\u52a8\u9a7e\u9a76\u4ee5\u53caAR/VR\u6280\u672f\u7b49\u9886\u57df\u3002\u867d\u7136\u57fa\u4e8e\u786c\u4ef6\u7684\u65b9\u6cd5\uff08\u5982\u6fc0\u5149\u96f7\u8fbe\uff09\u56e0\u6210\u672c\u9ad8\u3001\u5206\u8fa8\u7387\u4f4e\u548c\u73af\u5883\u654f\u611f\u6027\u800c\u53d7\u5230\u9650\u5236\uff0c\u4f46\u57fa\u4e8e\u89c6\u89c9\u7684\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u524d\u666f\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5c3d\u7ba1\u5728\u6cdb\u5316\u6027\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u4ecd\u9762\u4e34\u6311\u6218\u3002\u53d7\u5176\u4ed6\u9886\u57df\u5c3a\u5ea6\u5b9a\u5f8b\u548c\u57fa\u7840\u6a21\u578b\u7684\u542f\u53d1\uff0c\u672c\u6587\u63a2\u8ba8\u4e86\u7528\u4e8e\u6df1\u5ea6\u4f30\u8ba1\u7684\u201c\u6df1\u5ea6\u57fa\u7840\u6a21\u578b\u201d\uff0c\u5373\u5728\u5927\u578b\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u5e76\u5177\u6709\u5f3a\u5927\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u3002\u6587\u7ae0\u56de\u987e\u4e86\u5355\u76ee\u3001\u7acb\u4f53\u3001\u591a\u89c6\u56fe\u548c\u5355\u76ee\u89c6\u9891\u8bbe\u7f6e\u4e0b\u6df1\u5ea6\u4f30\u8ba1\u7684\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u548c\u8303\u5f0f\u7684\u6f14\u53d8\uff0c\u5e76\u8ba8\u8bba\u4e86\u8fd9\u4e9b\u6a21\u578b\u89e3\u51b3\u73b0\u6709\u6311\u6218\u7684\u6f5c\u529b\u3002\u6b64\u5916\uff0c\u8fd8\u5bf9\u652f\u6301\u8fd9\u4e9b\u6a21\u578b\u53d1\u5c55\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\u8fdb\u884c\u4e86\u5168\u9762\u6982\u8ff0\uff0c\u65e8\u5728\u901a\u8fc7\u8bc6\u522b\u5173\u952e\u67b6\u6784\u548c\u8bad\u7ec3\u7b56\u7565\uff0c\u4e3a\u6784\u5efa\u9c81\u68d2\u7684\u6df1\u5ea6\u57fa\u7840\u6a21\u578b\u6307\u660e\u65b9\u5411\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u7814\u7a76\u548c\u5e94\u7528\u63d0\u4f9b\u89c1\u89e3\u3002"}}
{"id": "2507.11274", "categories": ["cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.11274", "abs": "https://arxiv.org/abs/2507.11274", "authors": ["Amit Attia", "Matan Schliserman", "Uri Sherman", "Tomer Koren"], "title": "Fast Last-Iterate Convergence of SGD in the Smooth Interpolation Regime", "comment": "27 pages", "summary": "We study population convergence guarantees of stochastic gradient descent\n(SGD) for smooth convex objectives in the interpolation regime, where the noise\nat optimum is zero or near zero. The behavior of the last iterate of SGD in\nthis setting -- particularly with large (constant) stepsizes -- has received\ngrowing attention in recent years due to implications for the training of\nover-parameterized models, as well as to analyzing forgetting in continual\nlearning and to understanding the convergence of the randomized Kaczmarz method\nfor solving linear systems. We establish that after $T$ steps of SGD on\n$\\beta$-smooth convex loss functions with stepsize $\\eta \\leq 1/\\beta$, the\nlast iterate exhibits expected excess risk $\\widetilde{O}(1/(\\eta\nT^{1-\\beta\\eta/2}) + \\eta T^{\\beta\\eta/2} \\sigma_\\star^2)$, where\n$\\sigma_\\star^2$ denotes the variance of the stochastic gradients at the\noptimum. In particular, for a well-tuned stepsize we obtain a near optimal\n$\\widetilde{O}(1/T + \\sigma_\\star/\\sqrt{T})$ rate for the last iterate,\nextending the results of Varre et al. (2021) beyond least squares regression;\nand when $\\sigma_\\star=0$ we obtain a rate of $O(1/\\sqrt{T})$ with\n$\\eta=1/\\beta$, improving upon the best-known $O(T^{-1/4})$ rate recently\nestablished by Evron et al. (2025) in the special case of realizable linear\nregression.", "AI": {"tldr": "\u7814\u7a76SGD\u5728\u63d2\u503c\u6a21\u578b\u4e0b\u7684\u6536\u655b\u6027\uff0c\u7ed9\u51fa\u4e86\u7406\u8bba\u4fdd\u8bc1\u548c\u6539\u8fdb\u7684\u6536\u655b\u7387\u3002", "motivation": "\u7814\u7a76SGD\u5728\u63d2\u503c\u6a21\u578b\u4e0b\u7684\u6536\u655b\u6027\uff0c\u7279\u522b\u5173\u6ce8\u6700\u540e\u4e00\u4e2a\u8fed\u4ee3\u7684\u884c\u4e3a\uff0c\u8fd9\u5bf9\u4e8e\u7406\u89e3\u8fc7\u53c2\u6570\u6a21\u578b\u8bad\u7ec3\u3001\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u9057\u5fd8\u4ee5\u53ca\u968f\u673aKaczmarz\u65b9\u6cd5\u81f3\u5173\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\uff0c\u63a8\u5bfc\u4e86SGD\u6700\u540e\u4e00\u4e2a\u8fed\u4ee3\u5728$\beta$-\u5149\u6ed1\u51f8\u76ee\u6807\u51fd\u6570\u548c\u7279\u5b9a\u6b65\u957f\u4e0b\u7684\u9884\u671f\u8d85\u98ce\u9669\u4e0a\u754c\uff0c\u5f62\u5f0f\u4e3a$\\widetilde{O}(1/(\\eta T^{1-\\beta\\eta/2}) + \\eta T^{\\beta\\eta/2} \tau_\tars\tars^2)$\u3002", "result": "\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\uff0c\u5f53\u6b65\u957f\u8c03\u6574\u5f97\u5f53\u65f6\uff0cSGD\u6700\u540e\u4e00\u4e2a\u8fed\u4ee3\u7684\u9884\u671f\u8d85\u98ce\u9669\u63a5\u8fd1\u6700\u4f18\u7684$\\widetilde{O}(1/T + \tau_\tars/\bott\tars)$\u3002\u5f53$\tau_\tars=0$\u4e14\u6b65\u957f\u4e3a$\bot/\beta$\u65f6\uff0c\u6536\u655b\u7387\u4e3a$O(1/\bott)$\uff0c\u4f18\u4e8e\u5148\u524d\u5728\u7279\u5b9a\u7ebf\u6027\u56de\u5f52\u95ee\u9898\u4e0a\u5f97\u5230\u7684\u7ed3\u679c\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aSGD\u7684\u6700\u540e\u4e00\u4e2a\u8fed\u4ee3\u5728\u63d2\u503c\u6a21\u578b\u4e0b\u63d0\u4f9b\u4e86\u6536\u655b\u4fdd\u8bc1\uff0c\u5e76\u63a8\u5bfc\u4e86\u76f8\u5e94\u7684\u6536\u655b\u7387\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u4f18\u4e8e\u73b0\u6709\u7ed3\u679c\u3002"}}
{"id": "2507.11344", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11344", "abs": "https://arxiv.org/abs/2507.11344", "authors": ["Zara Hall", "Melanie Subbiah", "Thomas P Zollo", "Kathleen McKeown", "Richard Zemel"], "title": "Guiding LLM Decision-Making with Fairness Reward Models", "comment": null, "summary": "Large language models are increasingly used to support high-stakes decisions,\npotentially influencing who is granted bail or receives a loan. Naive\nchain-of-thought sampling can improve average decision accuracy, but has also\nbeen shown to amplify unfair bias. To address this challenge and enable the\ntrustworthy use of reasoning models in high-stakes decision-making, we propose\na framework for training a generalizable Fairness Reward Model (FRM). Our model\nassigns a fairness score to LLM reasoning, enabling the system to down-weight\nbiased trajectories and favor equitable ones when aggregating decisions across\nreasoning chains. We show that a single Fairness Reward Model, trained on\nweakly supervised, LLM-annotated examples of biased versus unbiased reasoning,\ntransfers across tasks, domains, and model families without additional\nfine-tuning. Applied to real-world decision-making tasks including recidivism\nprediction and social media moderation, we show that our approach consistently\nimproves fairness while matching, or even surpassing, baseline accuracy.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u516c\u5e73\u6027\u5956\u52b1\u6a21\u578b\uff08FRM\uff09\uff0c\u901a\u8fc7\u5f31\u76d1\u7763\u5b66\u4e60\u8bad\u7ec3\uff0c\u80fd\u591f\u8bc6\u522b\u5e76\u964d\u4f4e\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u51b3\u7b56\u4e2d\u7684\u504f\u89c1\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u8de8\u4efb\u52a1\u3001\u8de8\u9886\u57df\u548c\u8de8\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5728\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u88ab\u7528\u4e8e\u9ad8\u98ce\u9669\u51b3\u7b56\uff08\u5982\u4fdd\u91ca\u6216\u8d37\u6b3e\u5ba1\u6279\uff09\u65f6\uff0c\u6734\u7d20\u7684\u601d\u7ef4\u94fe\u91c7\u6837\u53ef\u80fd\u653e\u5927\u6570\u636e\u4e2d\u7684\u4e0d\u516c\u5e73\u504f\u89c1\u7684\u95ee\u9898\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5b9e\u73b0\u53ef\u4fe1\u8d56\u7684\u63a8\u7406\u6a21\u578b\u5728\u8fd9\u4e9b\u51b3\u7b56\u4e2d\u7684\u5e94\u7528\u3002", "method": "FRM\u6a21\u578b\u901a\u8fc7\u5f31\u76d1\u7763\u3001LLM\u6807\u6ce8\u7684\u6709\u504f\u89c1\u4e0e\u65e0\u504f\u89c1\u63a8\u7406\u793a\u4f8b\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u4e0d\u540c\u4efb\u52a1\u3001\u9886\u57df\u548c\u6a21\u578b\u5bb6\u65cf\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "result": "FRM\u5728\u5b9e\u9645\u7684\u51b3\u7b56\u5236\u5b9a\u4efb\u52a1\uff08\u5305\u62ec\u7d2f\u72af\u9884\u6d4b\u548c\u793e\u4ea4\u5a92\u4f53\u5185\u5bb9\u5ba1\u6838\uff09\u4e2d\uff0c\u80fd\u591f\u4e00\u81f4\u5730\u63d0\u9ad8\u516c\u5e73\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u8d85\u8d8a\u57fa\u7ebf\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u516c\u5e73\u6027\u5956\u52b1\u6a21\u578b\uff08FRM\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u8bad\u7ec3\u80fd\u591f\u5206\u914d\u516c\u5e73\u6027\u5206\u6570\u7684LLM\uff0c\u4ece\u800c\u5728\u805a\u5408\u51b3\u7b56\u65f6\u964d\u4f4e\u6709\u504f\u89c1\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u504f\u5411\u516c\u5e73\u7684\u8f68\u8ff9\u3002"}}
{"id": "2507.11357", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.11357", "abs": "https://arxiv.org/abs/2507.11357", "authors": ["Emile van Krieken", "Pasquale Minervini", "Edoardo Ponti", "Antonio Vergari"], "title": "Neurosymbolic Reasoning Shortcuts under the Independence Assumption", "comment": "Accepted at NeSy 2025", "summary": "The ubiquitous independence assumption among symbolic concepts in\nneurosymbolic (NeSy) predictors is a convenient simplification: NeSy predictors\nuse it to speed up probabilistic reasoning. Recent works like van Krieken et\nal. (2024) and Marconato et al. (2024) argued that the independence assumption\ncan hinder learning of NeSy predictors and, more crucially, prevent them from\ncorrectly modelling uncertainty. There is, however, scepticism in the NeSy\ncommunity around the scenarios in which the independence assumption actually\nlimits NeSy systems (Faronius and Dos Martires, 2025). In this work, we settle\nthis question by formally showing that assuming independence among symbolic\nconcepts entails that a model can never represent uncertainty over certain\nconcept combinations. Thus, the model fails to be aware of reasoning shortcuts,\ni.e., the pathological behaviour of NeSy predictors that predict correct\ndownstream tasks but for the wrong reasons.", "AI": {"tldr": "The ubiquitous independence assumption in neuro-symbolic predictors hinders uncertainty modeling and causes models to succeed for the wrong reasons, a problem formally proven in this work.", "motivation": "To settle the question of whether the independence assumption among symbolic concepts in neuro-symbolic predictors actually limits their capabilities, as argued by recent works but met with skepticism in the community.", "method": "Formal proof showing that the independence assumption entails that a model can never represent uncertainty over certain concept combinations.", "result": "The paper demonstrates that the independence assumption leads to a failure in modeling uncertainty and results in reasoning shortcuts, a pathological behavior in neuro-symbolic predictors.", "conclusion": "The paper formally shows that the independence assumption among symbolic concepts in neuro-symbolic predictors prevents them from correctly modeling uncertainty and leads to reasoning shortcuts, where models succeed on tasks for the wrong reasons."}}
{"id": "2507.11367", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.11367", "abs": "https://arxiv.org/abs/2507.11367", "authors": ["Daniel Tanneberg"], "title": "Local Pairwise Distance Matching for Backpropagation-Free Reinforcement Learning", "comment": "accepted at the European Conference on Artificial Intelligence (ECAI\n  2025)", "summary": "Training neural networks with reinforcement learning (RL) typically relies on\nbackpropagation (BP), necessitating storage of activations from the forward\npass for subsequent backward updates. Furthermore, backpropagating error\nsignals through multiple layers often leads to vanishing or exploding\ngradients, which can degrade learning performance and stability. We propose a\nnovel approach that trains each layer of the neural network using local signals\nduring the forward pass in RL settings. Our approach introduces local,\nlayer-wise losses leveraging the principle of matching pairwise distances from\nmulti-dimensional scaling, enhanced with optional reward-driven guidance. This\nmethod allows each hidden layer to be trained using local signals computed\nduring forward propagation, thus eliminating the need for backward passes and\nstoring intermediate activations. Our experiments, conducted with policy\ngradient methods across common RL benchmarks, demonstrate that this\nbackpropagation-free method achieves competitive performance compared to their\nclassical BP-based counterpart. Additionally, the proposed method enhances\nstability and consistency within and across runs, and improves performance\nespecially in challenging environments.", "AI": {"tldr": "\u4e00\u79cd\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u65e0\u53cd\u5411\u4f20\u64ad\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5229\u7528\u524d\u5411\u4f20\u64ad\u4e2d\u7684\u5c40\u90e8\u4fe1\u53f7\u548c\u591a\u7ef4\u7f29\u653e\u7684\u6210\u5bf9\u8ddd\u79bb\u5339\u914d\u6765\u9010\u5c42\u8bad\u7ec3\u7f51\u7edc\uff0c\u5b9e\u73b0\u4e86\u4e0e\u57fa\u4e8e\u53cd\u5411\u4f20\u64ad\u7684\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u5e76\u63d0\u9ad8\u4e86\u7a33\u5b9a\u6027\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u53cd\u5411\u4f20\u64ad\uff08BP\uff09\u901a\u5e38\u9700\u8981\u5b58\u50a8\u524d\u5411\u4f20\u64ad\u7684\u6fc0\u6d3b\u4ee5\u8fdb\u884c\u540e\u7eed\u7684\u540e\u5411\u66f4\u65b0\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u591a\u4e2a\u5c42\u53cd\u5411\u4f20\u64ad\u8bef\u5dee\u4fe1\u53f7\u53ef\u80fd\u5bfc\u81f4\u68af\u5ea6\u6d88\u5931\u6216\u7206\u70b8\uff0c\u4ece\u800c\u964d\u4f4e\u5b66\u4e60\u6027\u80fd\u548c\u7a33\u5b9a\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u5728\u5f3a\u5316\u5b66\u4e60\u8bbe\u7f6e\u4e2d\uff0c\u5229\u7528\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\u7684\u5c40\u90e8\u4fe1\u53f7\u6765\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u5404\u5c42\u7684 novel \u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u5f15\u5165\u4e86\u5229\u7528\u591a\u7ef4\u7f29\u653e\u7684\u6210\u5bf9\u8ddd\u79bb\u5339\u914d\u539f\u7406\u7684\u5c40\u90e8\u3001\u9010\u5c42\u635f\u5931\uff0c\u5e76\u8f85\u4ee5\u53ef\u9009\u7684\u5956\u52b1\u9a71\u52a8\u6307\u5bfc\u3002\u6b64\u65b9\u6cd5\u5141\u8bb8\u4f7f\u7528\u5728\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\u8ba1\u7b97\u51fa\u7684\u5c40\u90e8\u4fe1\u53f7\u6765\u8bad\u7ec3\u6bcf\u4e2a\u9690\u85cf\u5c42\uff0c\u4ece\u800c\u65e0\u9700\u53cd\u5411\u4f20\u64ad\u548c\u5b58\u50a8\u4e2d\u95f4\u6fc0\u6d3b\u3002", "result": "\u901a\u8fc7\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u5728\u5e38\u89c1\u7684\u5f3a\u5316\u5b66\u4e60\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u8fd9\u79cd\u65e0\u53cd\u5411\u4f20\u64ad\u7684\u65b9\u6cd5\u53ef\u4ee5\u8fbe\u5230\u4e0e\u5176\u7ecf\u5178\u7684\u57fa\u4e8e\u53cd\u5411\u4f20\u64ad\u7684\u5bf9\u5e94\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u8fd0\u884c\u5185\u5916\u548c\u8de8\u8fd0\u884c\u7684\u7a33\u5b9a\u6027\u548c\u4e00\u81f4\u6027\uff0c\u5e76\u4e14\u5728\u66f4\u5177\u6311\u6218\u6027\u7684\u73af\u5883\u4e2d\u63d0\u9ad8\u4e86\u6027\u80fd\u3002", "conclusion": "\u672c\u65b9\u6cd5\u5728\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u548c\u5e38\u89c1\u5f3a\u5316\u5b66\u4e60\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u4e0e\u7ecf\u5178\u57fa\u4e8e\u53cd\u5411\u4f20\u64ad\u7684\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u63d0\u9ad8\u4e86\u8fd0\u884c\u5185\u5916\u548c\u8de8\u8fd0\u884c\u7684\u7a33\u5b9a\u6027\u548c\u4e00\u81f4\u6027\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u73af\u5883\u4e2d\u3002"}}
{"id": "2507.11393", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11393", "abs": "https://arxiv.org/abs/2507.11393", "authors": ["James P Jun", "Vijay Marupudi", "Raj Sanjay Shah", "Sashank Varma"], "title": "A Neural Network Model of Complementary Learning Systems: Pattern Separation and Completion for Continual Learning", "comment": "Accepted to CogSci 2025. 7 pages, 7 figures", "summary": "Learning new information without forgetting prior knowledge is central to\nhuman intelligence. In contrast, neural network models suffer from catastrophic\nforgetting: a significant degradation in performance on previously learned\ntasks when acquiring new information. The Complementary Learning Systems (CLS)\ntheory offers an explanation for this human ability, proposing that the brain\nhas distinct systems for pattern separation (encoding distinct memories) and\npattern completion (retrieving complete memories from partial cues). To capture\nthese complementary functions, we leverage the representational generalization\ncapabilities of variational autoencoders (VAEs) and the robust memory storage\nproperties of Modern Hopfield networks (MHNs), combining them into a neurally\nplausible continual learning model. We evaluate this model on the Split-MNIST\ntask, a popular continual learning benchmark, and achieve close to\nstate-of-the-art accuracy (~90%), substantially reducing forgetting.\nRepresentational analyses empirically confirm the functional dissociation: the\nVAE underwrites pattern completion, while the MHN drives pattern separation. By\ncapturing pattern separation and completion in scalable architectures, our work\nprovides a functional template for modeling memory consolidation,\ngeneralization, and continual learning in both biological and artificial\nsystems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u53d7\u5927\u8111\u542f\u53d1\u7684\u6301\u7eed\u5b66\u4e60\u6a21\u578b\uff0c\u7ed3\u5408\u4e86VAE\u548cMHN\uff0c\u4ee5\u89e3\u51b3\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u5e76\u5728MNIST\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u826f\u597d\u6548\u679c\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u795e\u7ecf\u7f51\u7edc\u5728\u5b66\u4e60\u65b0\u4fe1\u606f\u65f6\u4f1a\u707e\u96be\u6027\u9057\u5fd8\u5148\u524d\u77e5\u8bc6\u7684\u95ee\u9898\uff0c\u501f\u9274\u4e86\u4e92\u8865\u5b66\u4e60\u7cfb\u7edf\uff08CLS\uff09\u7406\u8bba\uff0c\u8be5\u7406\u8bba\u63d0\u51fa\u5927\u8111\u5177\u6709\u6a21\u5f0f\u5206\u79bb\u548c\u6a21\u5f0f\u8865\u5168\u7684\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u548c\u73b0\u4ee3\u970d\u666e\u83f2\u5c14\u5fb7\u7f51\u7edc\uff08MHN\uff09\u7684\u6301\u7eed\u5b66\u4e60\u6a21\u578b\uff0c\u4ee5\u6a21\u62df\u4eba\u7c7b\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u6a21\u5f0f\u5206\u79bb\u548c\u6a21\u5f0f\u8865\u5168\u7684\u4e92\u8865\u529f\u80fd\u3002", "result": "\u6a21\u578b\u5728\u5206\u5272MNIST\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u7ea690%\u7684\u51c6\u786e\u7387\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u9057\u5fd8\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u8868\u793a\u5206\u6790\u9a8c\u8bc1\u4e86VAE\u5728\u6a21\u5f0f\u8865\u5168\u548cMHN\u5728\u6a21\u5f0f\u5206\u79bb\u65b9\u9762\u7684\u529f\u80fd\u6027\u5206\u79bb\u3002", "conclusion": "\u8be5\u6a21\u578b\u901a\u8fc7\u7ed3\u5408\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u548c\u73b0\u4ee3\u970d\u666e\u83f2\u5c14\u5fb7\u7f51\u7edc\uff08MHN\uff09\uff0c\u5728\u5206\u5272MNIST\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u5148\u8fdb\u6c34\u5e73\u7684\u51c6\u786e\u7387\uff08\u7ea690%\uff09\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u9057\u5fd8\u3002\u5b9e\u9a8c\u5206\u6790\u8bc1\u5b9e\u4e86VAE\u5728\u6a21\u5f0f\u8865\u5168\u548cMHN\u5728\u6a21\u5f0f\u5206\u79bb\u65b9\u9762\u7684\u529f\u80fd\u5206\u79bb\u3002"}}
{"id": "2507.11411", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11411", "abs": "https://arxiv.org/abs/2507.11411", "authors": ["Seyedsaman Emami", "Gonzalo Mart\u00ednez-Mu\u00f1oz", "Daniel Hern\u00e1ndez-Lobato"], "title": "Robust-Multi-Task Gradient Boosting", "comment": null, "summary": "Multi-task learning (MTL) has shown effectiveness in exploiting shared\ninformation across tasks to improve generalization. MTL assumes tasks share\nsimilarities that can improve performance. In addition, boosting algorithms\nhave demonstrated exceptional performance across diverse learning problems,\nprimarily due to their ability to focus on hard-to-learn instances and\niteratively reduce residual errors. This makes them a promising approach for\nlearning multi-task problems. However, real-world MTL scenarios often involve\ntasks that are not well-aligned (known as outlier or adversarial tasks), which\ndo not share beneficial similarities with others and can, in fact, deteriorate\nthe performance of the overall model. To overcome this challenge, we propose\nRobust-Multi-Task Gradient Boosting (R-MTGB), a novel boosting framework that\nexplicitly models and adapts to task heterogeneity during training. R-MTGB\nstructures the learning process into three sequential blocks: (1) learning\nshared patterns, (2) partitioning tasks into outliers and non-outliers with\nregularized parameters, and (3) fine-tuning task-specific predictors. This\narchitecture enables R-MTGB to automatically detect and penalize outlier tasks\nwhile promoting effective knowledge transfer among related tasks. Our method\nintegrates these mechanisms seamlessly within gradient boosting, allowing\nrobust handling of noisy or adversarial tasks without sacrificing accuracy.\nExtensive experiments on both synthetic benchmarks and real-world datasets\ndemonstrate that our approach successfully isolates outliers, transfers\nknowledge, and consistently reduces prediction errors for each task\nindividually, and achieves overall performance gains across all tasks. These\nresults highlight robustness, adaptability, and reliable convergence of R-MTGB\nin challenging MTL environments.", "AI": {"tldr": "R-MTGB \u662f\u4e00\u79cd\u65b0\u7684\u68af\u5ea6\u63d0\u5347\u6846\u67b6\uff0c\u53ef\u4ee5\u7a33\u5065\u5730\u5904\u7406\u591a\u4efb\u52a1\u5b66\u4e60\u4e2d\u7684\u5f02\u5e38\u4efb\u52a1\uff0c\u901a\u8fc7\u5c06\u4efb\u52a1\u5206\u4e3a\u5f02\u5e38\u548c\u975e\u5f02\u5e38\u6765\u63d0\u9ad8\u6027\u80fd\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7684\u591a\u4efb\u52a1\u5b66\u4e60\u573a\u666f\u901a\u5e38\u6d89\u53ca\u4efb\u52a1\u4e0d\u5bf9\u9f50\uff08\u5f02\u5e38\u6216\u5bf9\u6297\u6027\u4efb\u52a1\uff09\u7684\u60c5\u51b5\uff0c\u8fd9\u4e9b\u4efb\u52a1\u4e0e\u5176\u4ed6\u4efb\u52a1\u6ca1\u6709\u6709\u76ca\u7684\u76f8\u4f3c\u6027\uff0c\u5e76\u4e14\u5b9e\u9645\u4e0a\u4f1a\u964d\u4f4e\u6574\u4f53\u6a21\u578b\u7684\u6027\u80fd\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e2a\u6311\u6218\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 R-MTGB\u3002", "method": "R-MTGB \u6846\u67b6\u5c06\u5b66\u4e60\u8fc7\u7a0b\u7ed3\u6784\u5316\u4e3a\u4e09\u4e2a\u987a\u5e8f\u5757\uff1a(1) \u5b66\u4e60\u5171\u4eab\u6a21\u5f0f\uff0c(2) \u4f7f\u7528\u6b63\u5219\u5316\u53c2\u6570\u5c06\u4efb\u52a1\u5212\u5206\u4e3a\u5f02\u5e38\u548c\u975e\u5f02\u5e38\u4efb\u52a1\uff0c(3) \u5fae\u8c03\u7279\u5b9a\u4efb\u52a1\u7684\u9884\u6d4b\u5668\u3002\u8be5\u67b6\u6784\u4f7f R-MTGB \u80fd\u591f\u81ea\u52a8\u68c0\u6d4b\u548c\u60e9\u7f5a\u5f02\u5e38\u4efb\u52a1\uff0c\u540c\u65f6\u4fc3\u8fdb\u76f8\u5173\u4efb\u52a1\u4e4b\u95f4\u7684\u6709\u6548\u77e5\u8bc6\u8f6c\u79fb\u3002\u8be5\u65b9\u6cd5\u5c06\u8fd9\u4e9b\u673a\u5236\u65e0\u7f1d\u96c6\u6210\u5230\u68af\u5ea6\u63d0\u5347\u4e2d\uff0c\u4ece\u800c\u5728\u4e0d\u727a\u7272\u51c6\u786e\u6027\u7684\u60c5\u51b5\u4e0b\u7a33\u5065\u5730\u5904\u7406\u566a\u58f0\u6216\u5bf9\u6297\u6027\u4efb\u52a1\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u6210\u529f\u5730\u5206\u79bb\u4e86\u5f02\u5e38\u4efb\u52a1\uff0c\u8f6c\u79fb\u4e86\u77e5\u8bc6\uff0c\u5e76\u6301\u7eed\u964d\u4f4e\u4e86\u6bcf\u4e2a\u4efb\u52a1\u7684\u9884\u6d4b\u8bef\u5dee\uff0c\u540c\u65f6\u5728\u6240\u6709\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6574\u4f53\u6027\u80fd\u7684\u63d0\u5347\u3002", "conclusion": "R-MTGB \u5728\u5177\u6709\u6311\u6218\u6027\u7684\u591a\u4efb\u52a1\u5b66\u4e60\u73af\u5883\u4e2d\u5c55\u73b0\u4e86\u9c81\u68d2\u6027\u3001\u9002\u5e94\u6027\u548c\u53ef\u9760\u7684\u6536\u655b\u6027\uff0c\u6210\u529f\u5730\u5206\u79bb\u4e86\u5f02\u5e38\u4efb\u52a1\u3001\u8f6c\u79fb\u4e86\u77e5\u8bc6\uff0c\u5e76\u6301\u7eed\u964d\u4f4e\u4e86\u6bcf\u4e2a\u4efb\u52a1\u7684\u9884\u6d4b\u8bef\u5dee\uff0c\u540c\u65f6\u5728\u6240\u6709\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6574\u4f53\u6027\u80fd\u7684\u63d0\u5347\u3002"}}
{"id": "2507.11436", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11436", "abs": "https://arxiv.org/abs/2507.11436", "authors": ["Behtom Adeli", "John McLinden", "Pankaj Pandey", "Ming Shao", "Yalda Shahriari"], "title": "Toward Improving fNIRS Classification: A Study on Activation Functions in Deep Neural Architectures", "comment": null, "summary": "Activation functions are critical to the performance of deep neural networks,\nparticularly in domains such as functional near-infrared spectroscopy (fNIRS),\nwhere nonlinearity, low signal-to-noise ratio (SNR), and signal variability\nposes significant challenges to model accuracy. However, the impact of\nactivation functions on deep learning (DL) performance in the fNIRS domain\nremains underexplored and lacks systematic investigation in the current\nliterature. This study evaluates a range of conventional and field-specific\nactivation functions for fNIRS classification tasks using multiple deep\nlearning architectures, including the domain-specific fNIRSNet, AbsoluteNet,\nMDNN, and shallowConvNet (as the baseline), all tested on a single dataset\nrecorded during an auditory task. To ensure fair a comparison, all networks\nwere trained and tested using standardized preprocessing and consistent\ntraining parameters. The results show that symmetrical activation functions\nsuch as Tanh and the Absolute value function Abs(x) can outperform commonly\nused functions like the Rectified Linear Unit (ReLU), depending on the\narchitecture. Additionally, a focused analysis of the role of symmetry was\nconducted using a Modified Absolute Function (MAF), with results further\nsupporting the effectiveness of symmetrical activation functions on performance\ngains. These findings underscore the importance of selecting proper activation\nfunctions that align with the signal characteristics of fNIRS data.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.11439", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11439", "abs": "https://arxiv.org/abs/2507.11439", "authors": ["Hongming Tan", "Ting Chen", "Ruochong Jin", "Wai Kin Chan"], "title": "Data Augmentation in Time Series Forecasting through Inverted Framework", "comment": null, "summary": "Currently, iTransformer is one of the most popular and effective models for\nmultivariate time series (MTS) forecasting. Thanks to its inverted framework,\niTransformer effectively captures multivariate correlation. However, the\ninverted framework still has some limitations. It diminishes temporal\ninterdependency information, and introduces noise in cases of nonsignificant\nvariable correlation. To address these limitations, we introduce a novel data\naugmentation method on inverted framework, called DAIF. Unlike previous data\naugmentation methods, DAIF stands out as the first real-time augmentation\nspecifically designed for the inverted framework in MTS forecasting. We first\ndefine the structure of the inverted sequence-to-sequence framework, then\npropose two different DAIF strategies, Frequency Filtering and Cross-variation\nPatching to address the existing challenges of the inverted framework.\nExperiments across multiple datasets and inverted models have demonstrated the\neffectiveness of our DAIF.", "AI": {"tldr": "DAIF\u901a\u8fc7\u9891\u7387\u6ee4\u6ce2\u548c\u4ea4\u53c9\u53d8\u5f02\u6253\u8865\u4e01\u7b56\u7565\uff0c\u89e3\u51b3\u4e86iTransformer\u5012\u7f6e\u6846\u67b6\u5728MTS\u9884\u6d4b\u4e2d\u7684\u4e0d\u8db3\uff0c\u63d0\u5347\u4e86\u9884\u6d4b\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684iTransformer\u6a21\u578b\u867d\u7136\u5728\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\uff08MTS\uff09\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u5012\u7f6e\u6846\u67b6\u5728\u524a\u5f31\u65f6\u95f4\u4f9d\u8d56\u6027\u4fe1\u606f\u548c\u5f15\u5165\u566a\u58f0\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDAIF\u7684\u65b0\u578b\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5305\u542b\u9891\u7387\u6ee4\u6ce2\u548c\u4ea4\u53c9\u53d8\u5f02\u6253\u8865\u4e01\u4e24\u79cd\u7b56\u7565\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u5012\u7f6e\u6846\u67b6\u4ee5\u589e\u5f3aMTS\u9884\u6d4b\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDAIF\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u5012\u7f6e\u6a21\u578b\u4e0a\u5747\u6709\u6548\uff0c\u8bc1\u660e\u4e86\u5176\u5728MTS\u9884\u6d4b\u4e2d\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "DAIF\u662f\u4e00\u79cd\u65b0\u9896\u7684\u3001\u4e13\u95e8\u4e3aMTS\u9884\u6d4b\u7684\u5012\u7f6e\u6846\u67b6\u8bbe\u8ba1\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u901a\u8fc7\u9891\u7387\u6ee4\u6ce2\u548c\u4ea4\u53c9\u53d8\u5f02\u6253\u8865\u4e01\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5012\u7f6e\u6846\u67b6\u4e2d\u65f6\u95f4\u4f9d\u8d56\u6027\u4fe1\u606f\u51cf\u5f31\u548c\u566a\u58f0\u5f15\u5165\u7684\u95ee\u9898\u3002"}}
{"id": "2507.11457", "categories": ["cs.LG", "eess.IV"], "pdf": "https://arxiv.org/pdf/2507.11457", "abs": "https://arxiv.org/abs/2507.11457", "authors": ["Yaoxian Dong", "Yifan Gao", "Haoyue Li", "Yanfen Cui", "Xin Gao"], "title": "LRMR: LLM-Driven Relational Multi-node Ranking for Lymph Node Metastasis Assessment in Rectal Cancer", "comment": null, "summary": "Accurate preoperative assessment of lymph node (LN) metastasis in rectal\ncancer guides treatment decisions, yet conventional MRI evaluation based on\nmorphological criteria shows limited diagnostic performance. While some\nartificial intelligence models have been developed, they often operate as black\nboxes, lacking the interpretability needed for clinical trust. Moreover, these\nmodels typically evaluate nodes in isolation, overlooking the patient-level\ncontext. To address these limitations, we introduce LRMR, an LLM-Driven\nRelational Multi-node Ranking framework. This approach reframes the diagnostic\ntask from a direct classification problem into a structured reasoning and\nranking process. The LRMR framework operates in two stages. First, a multimodal\nlarge language model (LLM) analyzes a composite montage image of all LNs from a\npatient, generating a structured report that details ten distinct radiological\nfeatures. Second, a text-based LLM performs pairwise comparisons of these\nreports between different patients, establishing a relative risk ranking based\non the severity and number of adverse features. We evaluated our method on a\nretrospective cohort of 117 rectal cancer patients. LRMR achieved an area under\nthe curve (AUC) of 0.7917 and an F1-score of 0.7200, outperforming a range of\ndeep learning baselines, including ResNet50 (AUC 0.7708). Ablation studies\nconfirmed the value of our two main contributions: removing the relational\nranking stage or the structured prompting stage led to a significant\nperformance drop, with AUCs falling to 0.6875 and 0.6458, respectively. Our\nwork demonstrates that decoupling visual perception from cognitive reasoning\nthrough a two-stage LLM framework offers a powerful, interpretable, and\neffective new paradigm for assessing lymph node metastasis in rectal cancer.", "AI": {"tldr": "LRMR\u6846\u67b6\u5229\u7528\u4e24\u9636\u6bb5LLM\uff08\u591a\u6a21\u6001\u5206\u6790\u751f\u6210\u7ed3\u6784\u5316\u62a5\u544a\uff0c\u6587\u672c\u6a21\u578b\u8fdb\u884c\u8de8\u60a3\u8005\u76f8\u5bf9\u6392\u5e8f\uff09\u63d0\u5347\u76f4\u80a0\u764c\u6dcb\u5df4\u7ed3\u8f6c\u79fb\u8bc4\u4f30\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u7684\u57fa\u4e8e\u5f62\u6001\u5b66\u6307\u6807\u7684MRI\u8bc4\u4f30\u5728\u76f4\u80a0\u764c\u6dcb\u5df4\u7ed3\u8f6c\u79fb\u7684\u672f\u524d\u8bc4\u4f30\u4e2d\u8bca\u65ad\u6027\u80fd\u6709\u9650\uff0c\u4e14\u73b0\u6709AI\u6a21\u578b\u5e38\u4f5c\u4e3a\u9ed1\u7bb1\u7f3a\u4e4f\u4e34\u5e8a\u53ef\u4fe1\u5ea6\uff0c\u5e76\u5ffd\u89c6\u60a3\u8005\u5c42\u9762\u7684\u80cc\u666f\u4fe1\u606f\u3002", "method": "\u63d0\u51faLRMR\u6846\u67b6\uff0c\u4e00\u4e2aLLM\u9a71\u52a8\u7684\u5173\u7cfb\u591a\u8282\u70b9\u6392\u5e8f\u6846\u67b6\uff0c\u5c06\u8bca\u65ad\u4efb\u52a1\u4ece\u76f4\u63a5\u5206\u7c7b\u91cd\u6784\u4e3a\u7ed3\u6784\u5316\u63a8\u7406\u548c\u6392\u5e8f\u8fc7\u7a0b\u3002\u8be5\u6846\u67b6\u5206\u4e24\u9636\u6bb5\uff1a1.\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5206\u6790\u60a3\u8005\u6240\u6709\u6dcb\u5df4\u7ed3\u7684\u7ec4\u5408\u8499\u592a\u5947\u56fe\u50cf\uff0c\u751f\u6210\u5305\u542b\u5341\u4e2a\u4e0d\u540c\u653e\u5c04\u5b66\u7279\u5f81\u7684\u7ed3\u6784\u5316\u62a5\u544a\u30022.\u57fa\u4e8e\u6587\u672c\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u4e0d\u540c\u60a3\u8005\u7684\u62a5\u544a\u8fdb\u884c\u6210\u5bf9\u6bd4\u8f83\uff0c\u57fa\u4e8e\u4e0d\u826f\u7279\u5f81\u7684\u4e25\u91cd\u6027\u548c\u6570\u91cf\u5efa\u7acb\u76f8\u5bf9\u98ce\u9669\u6392\u5e8f\u3002", "result": "\u5728117\u540d\u76f4\u80a0\u764c\u60a3\u8005\u7684\u56de\u987e\u6027\u961f\u5217\u4e2d\uff0cLRMR\u8fbe\u5230\u4e860.7917\u7684AUC\u548c0.7200\u7684F1\u5206\u6570\uff0c\u4f18\u4e8eResNet50\u7b49\u6df1\u5ea6\u5b66\u4e60\u57fa\u7ebf\uff08AUC 0.7708\uff09\u3002\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0c\u79fb\u9664\u5173\u7cfb\u6392\u5e8f\u6216\u7ed3\u6784\u5316\u63d0\u793a\u9636\u6bb5\u90fd\u4f1a\u5bfc\u81f4\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff08AUC\u5206\u522b\u964d\u81f30.6875\u548c0.6458\uff09\u3002", "conclusion": "LRMR\u6846\u67b6\u901a\u8fc7\u89e3\u8026\u89c6\u89c9\u611f\u77e5\u4e0e\u8ba4\u77e5\u63a8\u7406\u7684\u4e24\u9636\u6bb5LLM\u65b9\u6cd5\uff0c\u4e3a\u8bc4\u4f30\u76f4\u80a0\u764c\u6dcb\u5df4\u7ed3\u8f6c\u79fb\u63d0\u4f9b\u4e86\u4e00\u79cd\u5f3a\u5927\u3001\u53ef\u89e3\u91ca\u4e14\u6709\u6548\u7684\u65b0\u8303\u5f0f\u3002"}}
{"id": "2507.11486", "categories": ["cs.LG", "I.2.1"], "pdf": "https://arxiv.org/pdf/2507.11486", "abs": "https://arxiv.org/abs/2507.11486", "authors": ["Jeremi Levesque", "Antoine Th\u00e9berge", "Maxime Descoteaux", "Pierre-Marc Jodoin"], "title": "Exploring the robustness of TractOracle methods in RL-based tractography", "comment": "38 pages, 8 figures. Submitted to Medical Image Analysis", "summary": "Tractography algorithms leverage diffusion MRI to reconstruct the fibrous\narchitecture of the brain's white matter. Among machine learning approaches,\nreinforcement learning (RL) has emerged as a promising framework for\ntractography, outperforming traditional methods in several key aspects.\nTractOracle-RL, a recent RL-based approach, reduces false positives by\nincorporating anatomical priors into the training process via a reward-based\nmechanism. In this paper, we investigate four extensions of the original\nTractOracle-RL framework by integrating recent advances in RL, and we evaluate\ntheir performance across five diverse diffusion MRI datasets. Results\ndemonstrate that combining an oracle with the RL framework consistently leads\nto robust and reliable tractography, regardless of the specific method or\ndataset used. We also introduce a novel RL training scheme called Iterative\nReward Training (IRT), inspired by the Reinforcement Learning from Human\nFeedback (RLHF) paradigm. Instead of relying on human input, IRT leverages\nbundle filtering methods to iteratively refine the oracle's guidance throughout\ntraining. Experimental results show that RL methods trained with oracle\nfeedback significantly outperform widely used tractography techniques in terms\nof accuracy and anatomical validity.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7ed3\u5408 Oracle \u4e0e\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u6846\u67b6\uff0c\u5e76\u5f15\u5165\u8fed\u4ee3\u5956\u52b1\u8bad\u7ec3\uff08IRT\uff09\u65b9\u6848\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8111\u767d\u8d28\u7ea4\u7ef4\u8ffd\u8e2a\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u57fa\u4e8e\u6269\u6563 MRI \u7684\u795e\u7ecf\u675f\u8ffd\u8e2a\u7b97\u6cd5\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u51cf\u5c11\u5047\u9633\u6027\u548c\u63d0\u9ad8\u51c6\u786e\u6027\u4e0e\u89e3\u5256\u5b66\u6709\u6548\u6027\u65b9\u9762\uff0c\u672c\u6587\u63a2\u7d22\u4e86\u5f3a\u5316\u5b66\u4e60 (RL) \u6846\u67b6\uff0c\u7279\u522b\u662f TractOracle-RL \u53ca\u5176\u6539\u8fdb\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u56db\u79cd TractOracle-RL \u6846\u67b6\u7684\u6269\u5c55\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u8fed\u4ee3\u5956\u52b1\u8bad\u7ec3 (IRT) \u65b9\u6848\uff0c\u8be5\u65b9\u6848\u501f\u9274\u4e86\u4eba\u7c7b\u53cd\u9988\u5f3a\u5316\u5b66\u4e60 (RLHF) \u7684\u601d\u60f3\uff0c\u5229\u7528\u675f\u8fc7\u6ee4\u65b9\u6cd5\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u8fed\u4ee3\u5730\u4f18\u5316 Oracle \u7684\u6307\u5bfc\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u7ed3\u5408 Oracle \u7684 RL \u6846\u67b6\u5728\u5404\u79cd\u6570\u636e\u96c6\u4e0a\u5747\u8868\u73b0\u51fa\u7a33\u5065\u4e14\u53ef\u9760\u7684\u8ffd\u8e2a\u6027\u80fd\u3002IRT \u8bad\u7ec3\u65b9\u6848\u8bad\u7ec3\u7684 RL \u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u89e3\u5256\u5b66\u6709\u6548\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u5e38\u7528\u7684\u795e\u7ecf\u675f\u8ffd\u8e2a\u6280\u672f\u3002", "conclusion": "\u7ed3\u5408 Oracle \u4e0e RL \u6846\u67b6\uff0c\u5e76\u91c7\u7528 IRT \u8bad\u7ec3\u65b9\u6848\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u795e\u7ecf\u675f\u8ffd\u8e2a\u7684\u51c6\u786e\u6027\u548c\u89e3\u5256\u5b66\u6709\u6548\u6027\uff0c\u4e14\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u7a33\u5065\u3002"}}
{"id": "2507.11531", "categories": ["cs.LG", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2507.11531", "abs": "https://arxiv.org/abs/2507.11531", "authors": ["Yue Song", "T. Anderson Keller", "Yisong Yue", "Pietro Perona", "Max Welling"], "title": "Langevin Flows for Modeling Neural Latent Dynamics", "comment": "Full version of the Cognitive Computational Neuroscience (CCN) 2025\n  poster", "summary": "Neural populations exhibit latent dynamical structures that drive\ntime-evolving spiking activities, motivating the search for models that capture\nboth intrinsic network dynamics and external unobserved influences. In this\nwork, we introduce LangevinFlow, a sequential Variational Auto-Encoder where\nthe time evolution of latent variables is governed by the underdamped Langevin\nequation. Our approach incorporates physical priors -- such as inertia,\ndamping, a learned potential function, and stochastic forces -- to represent\nboth autonomous and non-autonomous processes in neural systems. Crucially, the\npotential function is parameterized as a network of locally coupled\noscillators, biasing the model toward oscillatory and flow-like behaviors\nobserved in biological neural populations. Our model features a recurrent\nencoder, a one-layer Transformer decoder, and Langevin dynamics in the latent\nspace. Empirically, our method outperforms state-of-the-art baselines on\nsynthetic neural populations generated by a Lorenz attractor, closely matching\nground-truth firing rates. On the Neural Latents Benchmark (NLB), the model\nachieves superior held-out neuron likelihoods (bits per spike) and forward\nprediction accuracy across four challenging datasets. It also matches or\nsurpasses alternative methods in decoding behavioral metrics such as hand\nvelocity. Overall, this work introduces a flexible, physics-inspired,\nhigh-performing framework for modeling complex neural population dynamics and\ntheir unobserved influences.", "AI": {"tldr": "LangevinFlow\u662f\u4e00\u79cd\u65b0\u7684\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff0c\u5b83\u4f7f\u7528Langevin\u52a8\u529b\u5b66\u6765\u6a21\u62df\u795e\u7ecf\u5143\u7fa4\u4f53\u6d3b\u52a8\uff0c\u5e76\u7ed3\u5408\u7269\u7406\u539f\u7406\uff0c\u5728\u5404\u79cd\u6570\u636e\u96c6\u4e0a\u5747\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u795e\u7ecf\u5143\u7fa4\u4f53\u8868\u73b0\u51fa\u6f5c\u5728\u7684\u52a8\u529b\u5b66\u7ed3\u6784\uff0c\u9a71\u52a8\u7740\u968f\u65f6\u95f4\u53d8\u5316\u7684\u653e\u7535\u6d3b\u52a8\uff0c\u8fd9\u4fc3\u4f7f\u4eba\u4eec\u5bfb\u627e\u80fd\u591f\u540c\u65f6\u6355\u6349\u5185\u5728\u7f51\u7edc\u52a8\u529b\u5b66\u548c\u5916\u90e8\u672a\u89c2\u6d4b\u5f71\u54cd\u7684\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLangevinFlow\u7684\u5e8f\u5217\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff0c\u5176\u6f5c\u5728\u53d8\u91cf\u7684\u65f6\u95f4\u6f14\u5316\u7531\u6b20\u963b\u5c3cLangevin\u65b9\u7a0b\u63a7\u5236\uff0c\u5e76\u7ed3\u5408\u4e86\u7269\u7406\u5148\u9a8c\uff08\u60ef\u6027\u3001\u963b\u5c3c\u3001\u5b66\u4e60\u52bf\u51fd\u6570\u548c\u968f\u673a\u529b\uff09\u6765\u8868\u793a\u795e\u7ecf\u7cfb\u7edf\u4e2d\u7684\u81ea\u4e3b\u548c\u975e\u81ea\u4e3b\u8fc7\u7a0b\u3002\u52bf\u51fd\u6570\u88ab\u53c2\u6570\u5316\u4e3a\u5c40\u90e8\u8026\u5408\u632f\u8361\u5668\u7684\u7f51\u7edc\uff0c\u4ee5\u504f\u5411\u751f\u7269\u795e\u7ecf\u5143\u7fa4\u4f53\u4e2d\u89c2\u5bdf\u5230\u7684\u632f\u8361\u548c\u6d41\u52a8\u884c\u4e3a\u3002\u8be5\u6a21\u578b\u5305\u542b\u4e00\u4e2a\u9012\u5f52\u7f16\u7801\u5668\u3001\u4e00\u4e2a\u5355\u5c42Transformer\u89e3\u7801\u5668\u4ee5\u53ca\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684Langevin\u52a8\u529b\u5b66\u3002", "result": "\u5728\u7531\u6d1b\u4f26\u5179\u5438\u5f15\u5b50\u751f\u6210\u7684\u5408\u6210\u795e\u7ecf\u5143\u7fa4\u4f53\u4e0a\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u7cbe\u786e\u5339\u914d\u4e86\u771f\u5b9e\u7684\u653e\u7535\u7387\u3002\u5728\u795e\u7ecf\u6f5c\u5728\u57fa\u51c6\uff08NLB\uff09\u4e0a\uff0c\u8be5\u6a21\u578b\u5728\u56db\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\uff08\u6bcf\u8109\u51b2\u6bd4\u7279\uff09\u9884\u6d4b\u51c6\u786e\u6027\u548c\u524d\u5411\u9884\u6d4b\u51c6\u786e\u6027\u3002\u6b64\u5916\uff0c\u5b83\u5728\u89e3\u7801\u884c\u4e3a\u6307\u6807\uff08\u5982\u624b\u90e8\u901f\u5ea6\uff09\u65b9\u9762\u4e0e\u66ff\u4ee3\u65b9\u6cd5\u76f8\u5f53\u6216\u66f4\u4f18\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u7406\u89e3\u795e\u7ecf\u5143\u7fa4\u4f53\u52a8\u529b\u5b66\u53ca\u5176\u672a\u89c2\u6d4b\u5f71\u54cd\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7075\u6d3b\u3001\u53d7\u7269\u7406\u5b66\u542f\u53d1\u7684\u3001\u9ad8\u6027\u80fd\u7684\u6846\u67b6\u3002"}}
