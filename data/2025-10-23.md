<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 75]
- [cs.CL](#cs.CL) [Total: 77]
- [cs.NE](#cs.NE) [Total: 1]
- [cs.AI](#cs.AI) [Total: 24]
- [eess.SY](#eess.SY) [Total: 12]
- [cs.GT](#cs.GT) [Total: 5]
- [cs.RO](#cs.RO) [Total: 25]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 13]
- [quant-ph](#quant-ph) [Total: 38]
- [cs.DS](#cs.DS) [Total: 8]
- [cs.MA](#cs.MA) [Total: 5]
- [cs.SI](#cs.SI) [Total: 7]
- [cs.LG](#cs.LG) [Total: 92]
- [cs.AR](#cs.AR) [Total: 2]
- [cs.LO](#cs.LO) [Total: 3]
- [eess.SP](#eess.SP) [Total: 16]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 16]
- [cs.GR](#cs.GR) [Total: 1]
- [physics.app-ph](#physics.app-ph) [Total: 6]
- [cs.ET](#cs.ET) [Total: 1]
- [cs.DC](#cs.DC) [Total: 12]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Dimensionality Reduction for Remote Sensing Data Analysis: A Systematic Review of Methods and Applications](https://arxiv.org/abs/2510.18935)
*Nathan Mankovich,Kai-Hendrik Cohrs,Homer Durand,Vasileios Sitokonstantinou,Tristan Williams,Gustau Camps-Valls*

Main category: cs.CV

TL;DR: 地球观测数据量庞大，高维度带来挑战。降维技术（DR）通过提取特征来解决这些问题，以提高数据压缩、融合、预测等任务的效率。本综述旨在为地球观测数据价值链中的DR应用提供指导，并为未来研究发掘新的DR算法和应用机会。


<details>
  <summary>Details</summary>
Motivation: 自动从海量的地球观测数据中提取信息，对于应对环境监测、城市规划和灾难管理等重大的社会、经济和环境挑战至关重要。然而，数据的高维度性带来了稀疏性、低效性和维度灾难等挑战，限制了机器学习模型的有效性。

Method: 本文旨在为在遥感（RS）数据价值链中利用降维（DR）技术提供一本手册，并识别未被充分探索的DR算法及其在未来研究中的应用机会。

Result: 通过利用降维（DR）技术，特别是特征提取，可以保留数据基本属性的同时降低数据复杂性，从而提高数据压缩、清洗、融合、可视化、异常检测和预测等任务的效率。

Conclusion: 降维技术对于克服地球观测数据的高维度挑战至关重要，能够提高各种数据处理任务的效率，并为未来的研究开辟新的可能性。

Abstract: Earth observation involves collecting, analyzing, and processing an
ever-growing mass of data. Automatically harvesting information is crucial for
addressing significant societal, economic, and environmental challenges,
ranging from environmental monitoring to urban planning and disaster
management. However, the high dimensionality of these data poses challenges in
terms of sparsity, inefficiency, and the curse of dimensionality, which limits
the effectiveness of machine learning models. Dimensionality reduction (DR)
techniques, specifically feature extraction, address these challenges by
preserving essential data properties while reducing complexity and enhancing
tasks such as data compression, cleaning, fusion, visualization, anomaly
detection, and prediction. This review provides a handbook for leveraging DR
across the RS data value chain and identifies opportunities for under-explored
DR algorithms and their application in future research.

</details>


### [2] [DARE: A Deformable Adaptive Regularization Estimator for Learning-Based Medical Image Registration](https://arxiv.org/abs/2510.19353)
*Ahsan Raza Siyal,Markus Haltmeier,Ruth Steiger,Malik Galijasevic,Elke Ruth Gizewski,Astrid Ellen Grams*

Main category: cs.CV

TL;DR: DARE是一个新颖的配准框架，通过动态调整弹性正则化来解决深度学习医学图像配准中的不足。


<details>
  <summary>Details</summary>
Motivation: 传统的深度学习配准方法在保证鲁棒性和解剖学合理性方面存在不足，忽略了正则化的关键作用。

Method: DARE框架通过动态调整弹性正则化，整合了应变和剪切能量项，并引入了防止折叠的机制来约束变形。

Result: DARE能够自适应地调整正则化以平衡稳定性和灵活性，防止出现非物理的变形伪影，并提高配准准确性和解剖学合理性。

Conclusion: DARE通过动态适应性正则化策略，解决了深度学习医学图像配准中的关键挑战，提高了配准的鲁棒性和解剖学合理性。

Abstract: Deformable medical image registration is a fundamental task in medical image
analysis. While deep learning-based methods have demonstrated superior accuracy
and computational efficiency compared to traditional techniques, they often
overlook the critical role of regularization in ensuring robustness and
anatomical plausibility. We propose DARE (Deformable Adaptive Regularization
Estimator), a novel registration framework that dynamically adjusts elastic
regularization based on the gradient norm of the deformation field. Our
approach integrates strain and shear energy terms, which are adaptively
modulated to balance stability and flexibility. To ensure physically realistic
transformations, DARE includes a folding-prevention mechanism that penalizes
regions with negative deformation Jacobian. This strategy mitigates
non-physical artifacts such as folding, avoids over-smoothing, and improves
both registration accuracy and anatomical plausibility

</details>


### [3] [Ninja Codes: Neurally Generated Fiducial Markers for Stealthy 6-DoF Tracking](https://arxiv.org/abs/2510.18976)
*Yuichiro Takeuchi,Yusuke Imoto,Shunya Kato*

Main category: cs.CV

TL;DR: Ninja Codes是神经生成的、可融入现实环境的、可被打印和粘贴在物体表面以提供6-DoF定位跟踪的伪标记。它们可以通过商品打印机打印，并用带摄像头的设备检测，非常适合AR、机器人等应用，尤其是在传统标记因美观原因不适用时。


<details>
  <summary>Details</summary>
Motivation: 在AR、机器人和动作交互界面等应用中，传统的伪标记由于外观显眼，不适用于某些场景，因此需要一种能够自然融入环境且不影响美观的定位标记。

Method: 利用受深度隐写术启发的端到端过程，训练一系列网络模块来生成和检测Ninja Codes。编码网络将任意图像转换为Ninja Codes，实现视觉上细微的改变。

Result: 实验证明，Ninja Codes能在常见的室内光照条件下提供可靠的位置跟踪，并能成功地融入多样的环境纹理中，实现视觉上的隐蔽性。

Conclusion: Ninja Codes作为一种新颖的神经生成伪标记，能够通过商品打印机打印，并用普通摄像头设备检测，在保证6-DoF定位精度的同时，能够自然融入各种真实环境，为需要美观和隐蔽性的应用场景提供了解决方案。

Abstract: In this paper we describe Ninja Codes, neurally-generated fiducial markers
that can be made to naturally blend into various real-world environments. An
encoder network converts arbitrary images into Ninja Codes by applying visually
modest alterations; the resulting codes, printed and pasted onto surfaces, can
provide stealthy 6-DoF location tracking for a wide range of applications
including augmented reality, robotics, motion-based user interfaces, etc. Ninja
Codes can be printed using off-the-shelf color printers on regular printing
paper, and can be detected using any device equipped with a modern RGB camera
and capable of running inference. Using an end-to-end process inspired by prior
work on deep steganography, we jointly train a series of network modules that
perform the creation and detection of Ninja Codes. Through experiments, we
demonstrate Ninja Codes' ability to provide reliable location tracking under
common indoor lighting conditions, while successfully concealing themselves
within diverse environmental textures. We expect Ninja Codes to offer
particular value in scenarios where the conspicuous appearances of conventional
fiducial markers make them undesirable for aesthetic and other reasons.

</details>


### [4] [Robust Driving QA through Metadata-Grounded Context and Task-Specific Prompts](https://arxiv.org/abs/2510.19001)
*Seungjun Yu,Junsung Park,Youngsun Lim,Hyunjung Shim*

Main category: cs.CV

TL;DR: 该研究提出了一种用于自动驾驶的双阶段视觉-语言问答系统，通过多模态大模型、上下文增强和精心设计的提示来回答高级感知、预测和规划问题。


<details>
  <summary>Details</summary>
Motivation: 为了提高自动驾驶系统中对高级感知、预测和规划问题的问答能力，并探索预训练视觉-语言模型在该领域的潜力。

Method: 该系统分为两个阶段：第一阶段使用多模态大模型（Qwen2.5-VL-32B），结合六摄像头输入、历史信息和少量示例的链式思考提示，并通过自洽集成提高答案可靠性。第二阶段在第一阶段的基础上，引入nuScenes场景元数据（如物体注释、自车状态）和特定类别问题的指令来增强提示。

Result: 在驾驶问答基准测试中，该系统显著优于基线模型。例如，在第一阶段使用5帧历史和10-shot提示可获得65.1%的准确率（零样本为62.61%），自洽集成可提高到66.85%。第二阶段的准确率为67.37%。在严重视觉损坏下，系统仍能保持96%的准确率。

Conclusion: 精心设计的提示和上下文关联可以显著增强预训练视觉-语言模型在高层次驾驶问答任务中的表现，证明了该方法的有效性。

Abstract: We present a two-phase vision-language QA system for autonomous driving that
answers high-level perception, prediction, and planning questions. In Phase-1,
a large multimodal LLM (Qwen2.5-VL-32B) is conditioned on six-camera inputs, a
short temporal window of history, and a chain-of-thought prompt with few-shot
exemplars. A self-consistency ensemble (multiple sampled reasoning chains)
further improves answer reliability. In Phase-2, we augment the prompt with
nuScenes scene metadata (object annotations, ego-vehicle state, etc.) and
category-specific question instructions (separate prompts for perception,
prediction, planning tasks). In experiments on a driving QA benchmark, our
approach significantly outperforms the baseline Qwen2.5 models. For example,
using 5 history frames and 10-shot prompting in Phase-1 yields 65.1% overall
accuracy (vs.62.61% with zero-shot); applying self-consistency raises this to
66.85%. Phase-2 achieves 67.37% overall. Notably, the system maintains 96%
accuracy under severe visual corruption. These results demonstrate that
carefully engineered prompts and contextual grounding can greatly enhance
high-level driving QA with pretrained vision-language models.

</details>


### [5] [$Δ$t-Mamba3D: A Time-Aware Spatio-Temporal State-Space Model for Breast Cancer Risk Prediction](https://arxiv.org/abs/2510.19003)
*Zhengbo Zhou,Dooman Arefan,Margarita Zuley,Shandong Wu*

Main category: cs.CV

TL;DR: Time-Aware Δt-Mamba3D 是一种新颖的 3D 卷积神经网络，用于分析纵向医学影像，它能有效处理不规则时间间隔的图像，并在乳腺癌风险预测方面取得了优于现有模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的纵向医学影像分析方法难以有效处理数据挑战，如高分辨率图像序列和不规则时间间隔，导致无法充分利用重要的时空线索。模型要么牺牲空间信息，要么采用计算效率低下且不兼容非均匀时间步长的时空模型。

Method: 提出了一种名为 Time-Aware Δt-Mamba3D 的新颖状态空间架构，该架构能够同时编码不规则的访问间隔和丰富的时空上下文，并保持计算效率。其核心创新在于一种连续时间选择性扫描机制，将检查间的真实时间差显式集成到状态转换中，并辅以一个多尺度 3D 邻域融合模块来捕捉时空关系。

Result: 在以纵向筛查乳腺钼靶影像为基础的乳腺癌风险预测基准测试中，Time-Aware Δt-Mamba3D 模型取得了优越的性能，与现有的循环、Transformer 和状态空间模型相比，验证的 c-index 提高了 2-5 个百分点，并获得了更高的 1-5 年 AUC 分数。

Conclusion: Time-Aware Δt-Mamba3D 模型通过其线性复杂度能够高效处理患者冗长复杂的筛查钼靶图像历史，为纵向图像分析提供了一个新框架。

Abstract: Longitudinal analysis of sequential radiological images is hampered by a
fundamental data challenge: how to effectively model a sequence of
high-resolution images captured at irregular time intervals. This data
structure contains indispensable spatial and temporal cues that current methods
fail to fully exploit. Models often compromise by either collapsing spatial
information into vectors or applying spatio-temporal models that are
computationally inefficient and incompatible with non-uniform time steps. We
address this challenge with Time-Aware $\Delta$t-Mamba3D, a novel state-space
architecture adapted for longitudinal medical imaging. Our model simultaneously
encodes irregular inter-visit intervals and rich spatio-temporal context while
remaining computationally efficient. Its core innovation is a continuous-time
selective scanning mechanism that explicitly integrates the true time
difference between exams into its state transitions. This is complemented by a
multi-scale 3D neighborhood fusion module that robustly captures
spatio-temporal relationships. In a comprehensive breast cancer risk prediction
benchmark using sequential screening mammogram exams, our model shows superior
performance, improving the validation c-index by 2-5 percentage points and
achieving higher 1-5 year AUC scores compared to established variants of
recurrent, transformer, and state-space models. Thanks to its linear
complexity, the model can efficiently process long and complex patient
screening histories of mammograms, forming a new framework for longitudinal
image analysis.

</details>


### [6] [MoAlign: Motion-Centric Representation Alignment for Video Diffusion Models](https://arxiv.org/abs/2510.19022)
*Aritra Bhowmik,Denis Korzhenkov,Cees G. M. Snoek,Amirhossein Habibian,Mohsen Ghafoorian*

Main category: cs.CV

TL;DR: 本文提出了一种以运动为中心的对齐框架，通过学习一个解耦的运动子空间来解决文本到视频生成模型在运动连贯性和物理合理性方面的问题，并在多个基准测试和用户研究中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到视频生成模型在生成连贯且符合物理规律的运动方面存在不足，因为它们对复杂运动的理解不够充分。现有的方法通过对齐预训练视频编码器的特征来解决这个问题，但这些编码器的特征混合了外观和动态信息，限制了对齐效果。

Method: 本文提出了一种以运动为中心的对齐框架，该框架从预训练的视频编码器中学习一个解耦的运动子空间。该子空间通过预测真实的光流来优化，以确保捕获真实的运动动态。然后，将文本到视频扩散模型的潜在特征与这个新的子空间对齐，使生成模型能够内化运动知识。

Result: 通过在 VideoPhy、VideoPhy2、VBench 和 VBench-2.0 等多个数据集上进行实证评估，并结合用户研究，证明了该方法在改善视频扩散模型的物理常识方面优于现有技术，同时保持了对文本提示的遵循度。

Conclusion: 所提出的以运动为中心的对齐框架能够有效地从预训练的视频编码器中提取和利用运动信息，显著提高了文本到视频生成模型的运动连贯性和物理合理性，同时保持了对文本提示的忠实度。

Abstract: Text-to-video diffusion models have enabled high-quality video synthesis, yet
often fail to generate temporally coherent and physically plausible motion. A
key reason is the models' insufficient understanding of complex motions that
natural videos often entail. Recent works tackle this problem by aligning
diffusion model features with those from pretrained video encoders. However,
these encoders mix video appearance and dynamics into entangled features,
limiting the benefit of such alignment. In this paper, we propose a
motion-centric alignment framework that learns a disentangled motion subspace
from a pretrained video encoder. This subspace is optimized to predict
ground-truth optical flow, ensuring it captures true motion dynamics. We then
align the latent features of a text-to-video diffusion model to this new
subspace, enabling the generative model to internalize motion knowledge and
generate more plausible videos. Our method improves the physical commonsense in
a state-of-the-art video diffusion model, while preserving adherence to textual
prompts, as evidenced by empirical evaluations on VideoPhy, VideoPhy2, VBench,
and VBench-2.0, along with a user study.

</details>


### [7] [PoSh: Using Scene Graphs To Guide LLMs-as-a-Judge For Detailed Image Descriptions](https://arxiv.org/abs/2510.19060)
*Amith Ananthram,Elias Stengel-Eskin,Lorena A. Bradford,Julia Demarest,Adam Purvis,Keith Krut,Robert Stein,Rina Elster Pantalony,Mohit Bansal,Kathleen McKeown*

Main category: cs.CV

TL;DR: 评估图像描述模型（VLM）的挑战在于现有指标（如CIDEr, SPICE）未能很好地处理长文本描述，尤其是在属性和关系方面。本文提出了PoSh指标，它使用场景图作为结构化标准，引导大型语言模型（LLMs）进行评估，能够识别细粒度错误（如组合理解错误），并且比现有指标（包括GPT4o-as-a-Judge）更准确地反映人类评分。为了验证PoSh，我们引入了一个新的数据集DOCENT，包含艺术品及其专家参考描述和学生评分，用于评估详细图像描述指标和模型本身。PoSh在DOCENT上与人类判断的相关性优于现有指标，并且在CapArena数据集上表现稳健。最后，利用PoSh分析了模型在DOCENT数据集上的表现，发现基础模型难以全面、无误地描述具有丰富场景动态的图像。


<details>
  <summary>Details</summary>
Motivation: 现有评估VLM的指标（如CIDEr, SPICE）主要针对短文本，无法有效评估长文本描述中的属性和关系依附问题，也无法精确定位错误。因此，需要新的指标来评估细粒度的图像描述能力。

Method: 提出了一种名为PoSh的新指标，该指标使用场景图作为结构化基准，并利用大型语言模型（LLMs）作为裁判来评估详细的图像描述。同时，创建了一个名为DOCENT的新数据集，包含艺术品、专家参考描述以及由艺术史学生提供的细粒度和粗粒度质量判断，用于验证PoSh指标和评估VLM。

Result: PoSh指标在DOCENT数据集上与人类判断的相关性比现有的最佳开放权重指标高出0.05（Spearman $ho$），并且在CapArena数据集上表现稳健。PoSh作为奖励函数优于标准的监督微调。通过PoSh和DOCENT，发现基础模型在描述具有丰富场景动态的图像时难以实现完全覆盖且无误，这为衡量VLM进展设定了一个新的高要求任务。

Conclusion: PoSh作为一种新的评估指标，能够更准确地评估VLM在细粒度图像描述方面的表现，尤其是在处理长文本和复杂场景时。DOCENT数据集为评估VLM在艺术品描述任务上提供了新的基准。这些研究成果有望推动辅助文本生成等领域的发展。

Abstract: While vision-language models (VLMs) have advanced into detailed image
description, evaluation remains a challenge. Standard metrics (e.g. CIDEr,
SPICE) were designed for short texts and tuned to recognize errors that are now
uncommon, such as object misidentification. In contrast, long texts require
sensitivity to attribute and relation attachments and scores that localize
errors to particular text spans. In this work, we introduce PoSh, a metric for
detailed image description that uses scene graphs as structured rubrics to
guide LLMs-as-a-Judge, producing aggregate scores grounded in fine-grained
errors (e.g. mistakes in compositional understanding). PoSh is replicable,
interpretable and a better proxy for human raters than existing metrics
(including GPT4o-as-a-Judge). To validate PoSh, we introduce a challenging new
dataset, DOCENT. This novel benchmark contains artwork, paired with
expert-written references, and model-generated descriptions, augmented with
granular and coarse judgments of their quality from art history students. Thus,
DOCENT enables evaluating both detailed image description metrics and detailed
image description itself in a challenging new domain. We show that PoSh
achieves stronger correlations (+0.05 Spearman $\rho$) with the human judgments
in DOCENT than the best open-weight alternatives, is robust to image type
(using CapArena, an existing dataset of web imagery) and is a capable reward
function, outperforming standard supervised fine-tuning. Then, using PoSh, we
characterize the performance of open and closed models in describing the
paintings, sketches and statues in DOCENT and find that foundation models
struggle to achieve full, error-free coverage of images with rich scene
dynamics, establishing a demanding new task to gauge VLM progress. Through both
PoSh and DOCENT, we hope to enable advances in important areas such as
assistive text generation.

</details>


### [8] [UniHPR: Unified Human Pose Representation via Singular Value Contrastive Learning](https://arxiv.org/abs/2510.19078)
*Zhongyu Jiang,Wenhao Chai,Lei Li,Zhuoran Zhou,Cheng-Yen Yang,Jenq-Neng Hwang*

Main category: cs.CV

TL;DR: 该论文提出了一种名为UniHPR的统一人类姿态表示学习流程，旨在对齐来自图像、2D和3D人类姿态的数据表示，并通过新颖的奇异值对比学习损失来提高性能，在2D和3D人类姿态估计以及姿态检索任务中取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 为了解决多模态融合和生成中，从不同模态生成统一表示以对齐人类姿态表示的挑战，作者提出了UniHPR。

Method: UniHPR利用新颖的奇异值对比学习损失来对齐来自图像、2D和3D人类姿态的表示。然后，使用一个简单的3D人类姿态解码器来评估对齐表示在2D和3D人类姿态估计以及姿态检索任务上的有效性。

Result: UniHPR在Human3.6M数据集上取得了49.9mm的MPJPE，在3DPW数据集上取得了51.6mm的PA-MPJPE。此外，在Human3.6M数据集上，使用统一的人类姿态表示实现了2D和3D姿态检索，MPJPE误差为9.24mm。

Conclusion: UniHPR成功地学习了人类姿态的统一表示，提高了多模态对齐的性能，并在各种下游任务中显示出其有效性。

Abstract: In recent years, there has been a growing interest in developing effective
alignment pipelines to generate unified representations from different
modalities for multi-modal fusion and generation. As an important component of
Human-Centric applications, Human Pose representations are critical in many
downstream tasks, such as Human Pose Estimation, Action Recognition,
Human-Computer Interaction, Object tracking, etc. Human Pose representations or
embeddings can be extracted from images, 2D keypoints, 3D skeletons, mesh
models, and lots of other modalities. Yet, there are limited instances where
the correlation among all of those representations has been clearly researched
using a contrastive paradigm. In this paper, we propose UniHPR, a unified Human
Pose Representation learning pipeline, which aligns Human Pose embeddings from
images, 2D and 3D human poses. To align more than two data representations at
the same time, we propose a novel singular value-based contrastive learning
loss, which better aligns different modalities and further boosts performance.
To evaluate the effectiveness of the aligned representation, we choose 2D and
3D Human Pose Estimation (HPE) as our evaluation tasks. In our evaluation, with
a simple 3D human pose decoder, UniHPR achieves remarkable performance metrics:
MPJPE 49.9mm on the Human3.6M dataset and PA-MPJPE 51.6mm on the 3DPW dataset
with cross-domain evaluation. Meanwhile, we are able to achieve 2D and 3D pose
retrieval with our unified human pose representations in Human3.6M dataset,
where the retrieval error is 9.24mm in MPJPE.

</details>


### [9] [Advancing Brain Tumor Segmentation via Attention-based 3D U-Net Architecture and Digital Image Processing](https://arxiv.org/abs/2510.19109)
*Eyad Gad,Seif Soliman,M. Saeed Darweesh*

Main category: cs.CV

TL;DR: 该研究提出了一种结合注意力机制的3D U-Net模型，用于提高脑肿瘤MRI图像分割的准确性，并使用数字图像处理技术解决了类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 标准的3D U-Net模型在处理形状不规则、边界模糊的脑肿瘤以及高分辨率MRI数据时存在挑战，并且面临类别不平衡问题，影响分割准确性。

Method: 将注意力机制集成到3D U-Net模型中，使其能够捕捉细节并优先处理信息区域；利用基于数字图像处理技术的肿瘤检测算法来处理不平衡的训练数据。

Result: 提出的模型在BraTS 2020数据集上进行了评估，取得了0.975的Dice系数、0.988的特异性和0.995的敏感性，优于相关研究。

Conclusion: 该研究提出的集成注意力机制的3D U-Net模型能有效提高脑肿瘤分割的性能，为临床诊断提供有价值的参考。

Abstract: In the realm of medical diagnostics, rapid advancements in Artificial
Intelligence (AI) have significantly yielded remarkable improvements in brain
tumor segmentation. Encoder-Decoder architectures, such as U-Net, have played a
transformative role by effectively extracting meaningful representations in 3D
brain tumor segmentation from Magnetic resonance imaging (MRI) scans. However,
standard U-Net models encounter challenges in accurately delineating tumor
regions, especially when dealing with irregular shapes and ambiguous
boundaries. Additionally, training robust segmentation models on
high-resolution MRI data, such as the BraTS datasets, necessitates high
computational resources and often faces challenges associated with class
imbalance. This study proposes the integration of the attention mechanism into
the 3D U-Net model, enabling the model to capture intricate details and
prioritize informative regions during the segmentation process. Additionally, a
tumor detection algorithm based on digital image processing techniques is
utilized to address the issue of imbalanced training data and mitigate bias.
This study aims to enhance the performance of brain tumor segmentation,
ultimately improving the reliability of diagnosis. The proposed model is
thoroughly evaluated and assessed on the BraTS 2020 dataset using various
performance metrics to accomplish this goal. The obtained results indicate that
the model outperformed related studies, exhibiting dice of 0.975, specificity
of 0.988, and sensitivity of 0.995, indicating the efficacy of the proposed
model in improving brain tumor segmentation, offering valuable insights for
reliable diagnosis in clinical settings.

</details>


### [10] [A Novel Approach to Breast Cancer Segmentation using U-Net Model with Attention Mechanisms and FedProx](https://arxiv.org/abs/2510.19118)
*Eyad Gad,Mustafa Abou Khatwa,Mustafa A. Elattar,Sahar Selim*

Main category: cs.CV

TL;DR: 本研究旨在使用Federated Proximal (FedProx)方法结合改进的U-Net模型来解决非独立同分布（non-IID）的超声乳腺癌成像数据集的挑战，以提高肿瘤分割的准确性并保护患者隐私。


<details>
  <summary>Details</summary>
Motivation: 由于超声成像在早期检测和诊断乳腺癌方面的重要性，以及医疗数据的敏感性，因此需要一种既能保证准确性又能保护隐私的AI模型。现有的联邦学习方法在处理non-IID数据集时，模型准确性和泛化能力会受到影响，这对于准确分割肿瘤边界至关重要。

Method: 本研究采用了Federated Proximal (FedProx)方法，并结合了带有注意力机制的改进U-Net模型，应用于non-IID的超声乳腺癌成像数据集。

Result: 所提出的方法训练出的全局模型达到了96%的准确率，证明了该方法在提高肿瘤分割准确性的同时能够保护患者隐私的有效性。

Conclusion: Federated Proximal (FedProx)方法在non-IID的本地医疗数据集上训练精确的机器学习模型方面，展现出巨大的潜力。

Abstract: Breast cancer is a leading cause of death among women worldwide, emphasizing
the need for early detection and accurate diagnosis. As such Ultrasound
Imaging, a reliable and cost-effective tool, is used for this purpose, however
the sensitive nature of medical data makes it challenging to develop accurate
and private artificial intelligence models. A solution is Federated Learning as
it is a promising technique for distributed machine learning on sensitive
medical data while preserving patient privacy. However, training on
non-Independent and non-Identically Distributed (non-IID) local datasets can
impact the accuracy and generalization of the trained model, which is crucial
for accurate tumour boundary delineation in BC segmentation. This study aims to
tackle this challenge by applying the Federated Proximal (FedProx) method to
non-IID Ultrasonic Breast Cancer Imaging datasets. Moreover, we focus on
enhancing tumour segmentation accuracy by incorporating a modified U-Net model
with attention mechanisms. Our approach resulted in a global model with 96%
accuracy, demonstrating the effectiveness of our method in enhancing tumour
segmentation accuracy while preserving patient privacy. Our findings suggest
that FedProx has the potential to be a promising approach for training precise
machine learning models on non-IID local medical datasets.

</details>


### [11] [X-Ego: Acquiring Team-Level Tactical Situational Awareness via Cross-Egocentric Contrastive Video Representation Learning](https://arxiv.org/abs/2510.19150)
*Yunzhe Wang,Soham Hans,Volkan Ustun*

Main category: cs.CV

TL;DR: 该研究提出了X-Ego-CS数据集和CECL模型，用于在电子竞技中进行多智能体决策和战术学习，解决了现有方法忽略同步、以自我为中心的学习问题。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解方法在模拟体育比赛中的团队互动时，依赖于第三人称视角，忽略了多智能体学习中同步和以自我为中心的特性。

Method: 提出X-Ego-CS数据集，包含45场《反恐精英2》比赛的124小时第一人称视角视频流和状态-动作轨迹。在此基础上，提出跨视角对比学习（CECL），对齐队友的以自我为中心的视觉流，以增强个体视角的团队战术态势感知能力。

Result: 在队友-对手定位预测任务上评估CECL，证明了其能有效提升智能体从单一第一人称视角推断队友和对手位置的能力。

Conclusion: X-Ego-CS数据集和CECL模型为电子竞技中的跨视角多智能体基准测试奠定了基础，并将游戏理解定位为多智能体建模和战术学习的试验场，对虚拟和现实世界中的时空推理和人机协作具有启示意义。

Abstract: Human team tactics emerge from each player's individual perspective and their
ability to anticipate, interpret, and adapt to teammates' intentions. While
advances in video understanding have improved the modeling of team interactions
in sports, most existing work relies on third-person broadcast views and
overlooks the synchronous, egocentric nature of multi-agent learning. We
introduce X-Ego-CS, a benchmark dataset consisting of 124 hours of gameplay
footage from 45 professional-level matches of the popular e-sports game
Counter-Strike 2, designed to facilitate research on multi-agent
decision-making in complex 3D environments. X-Ego-CS provides cross-egocentric
video streams that synchronously capture all players' first-person perspectives
along with state-action trajectories. Building on this resource, we propose
Cross-Ego Contrastive Learning (CECL), which aligns teammates' egocentric
visual streams to foster team-level tactical situational awareness from an
individual's perspective. We evaluate CECL on a teammate-opponent location
prediction task, demonstrating its effectiveness in enhancing an agent's
ability to infer both teammate and opponent positions from a single
first-person view using state-of-the-art video encoders. Together, X-Ego-CS and
CECL establish a foundation for cross-egocentric multi-agent benchmarking in
esports. More broadly, our work positions gameplay understanding as a testbed
for multi-agent modeling and tactical learning, with implications for
spatiotemporal reasoning and human-AI teaming in both virtual and real-world
domains. Code and dataset are available at https://github.com/HATS-ICT/x-ego.

</details>


### [12] [FootFormer: Estimating Stability from Visual Input](https://arxiv.org/abs/2510.19170)
*Keaton Kraiger,Jingjing Li,Skanda Bharadwaj,Jesse Scott,Robert T. Collins,Yanxi Liu*

Main category: cs.CV

TL;DR: FootFormer是一个跨模态方法，可以直接从视觉输入预测人体运动动力学，并在多个数据集上实现了对足底压力分布、足部接触图和质心（CoM）的预测，优于现有方法，并在稳定预测方面达到了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 提出一种跨模态方法，直接从视觉输入预测人体运动动力学，并同时预测足底压力分布、足部接触图和质心（CoM）。

Method: 提出FootFormer模型，利用视觉输入进行人体运动动力学预测。

Result: 在多个数据集上，FootFormer在预测足底压力分布、足部接触图和质心（CoM）方面取得了统计学上显著更优或等效的估计。在稳定预测方面（CoP、CoM、BoS）达到了SOTA性能。

Conclusion: FootFormer是一种有效的跨模态方法，能够直接从视觉输入准确预测人体运动动力学及其稳定预测指标。

Abstract: We propose FootFormer, a cross-modality approach for jointly predicting human
motion dynamics directly from visual input. On multiple datasets, FootFormer
achieves statistically significantly better or equivalent estimates of foot
pressure distributions, foot contact maps, and center of mass (CoM), as
compared with existing methods that generate one or two of those measures.
Furthermore, FootFormer achieves SOTA performance in estimating
stability-predictive components (CoP, CoM, BoS) used in classic kinesiology
metrics. Code and data are available at
https://github.com/keatonkraiger/Vision-to-Stability.git.

</details>


### [13] [Malaria Detection from Blood Cell Images Using XceptionNet](https://arxiv.org/abs/2510.19182)
*Warisa Nusrat,Mostafijur Rahman,Ayatullah Faruk Mollah*

Main category: cs.CV

TL;DR: 本研究利用深度学习方法自动检测疟疾，其中残差注意力网络和XceptionNet表现最佳，准确率分别为97.28%和97.55%。


<details>
  <summary>Details</summary>
Motivation: 疟疾，特别是对5岁以下儿童，可能致命。目前依靠显微镜观察血涂片图像诊断疟疾，但存在诊断不准确的风险，因此需要计算机辅助的自动诊断方法。

Method: 本研究采用了六种深度卷积网络（AlexNet、XceptionNet、VGG-19、Residual Attention Network、DenseNet-121和Custom-CNN）来分析血细胞图像，提取深度特征并将其分类为受疟疾感染或健康细胞。

Result: 在公开的疟疾细胞图像数据集上，Residual Attention Network和XceptionNet的平均准确率分别为97.28%和97.55%，优于其他方法。

Conclusion: 深度学习驱动的方法在自动检测疟疾方面具有潜力，可以减少人工参与，提高诊断的可靠性。

Abstract: Malaria, which primarily spreads with the bite of female anopheles mosquitos,
often leads to death of people - specifically children in the age-group of 0-5
years. Clinical experts identify malaria by observing RBCs in blood smeared
images with a microscope. Lack of adequate professional knowledge and skills,
and most importantly manual involvement may cause incorrect diagnosis.
Therefore, computer aided automatic diagnosis stands as a preferred substitute.
In this paper, well-demonstrated deep networks have been applied to extract
deep intrinsic features from blood cell images and thereafter classify them as
malaria infected or healthy cells. Among the six deep convolutional networks
employed in this work viz. AlexNet, XceptionNet, VGG-19, Residual Attention
Network, DenseNet-121 and Custom-CNN. Residual Attention Network and
XceptionNet perform relatively better than the rest on a publicly available
malaria cell image dataset. They yield an average accuracy of 97.28% and 97.55%
respectively, that surpasses other related methods on the same dataset. These
findings highly encourage the reality of deep learning driven method for
automatic and reliable detection of malaria while minimizing direct manual
involvement.

</details>


### [14] [PruneHal: Reducing Hallucinations in Multi-modal Large Language Models through Adaptive KV Cache Pruning](https://arxiv.org/abs/2510.19183)
*Fengyuan Sun,Hui Chen,Xinhao Xu,Dandan Zheng,Jingdong Chen,Jun Zhou,Jungong Han,Guiguang Ding*

Main category: cs.CV

TL;DR: PruneHal通过自适应KV缓存剪枝来减少多模态大语言模型中的幻觉，无需额外训练且计算成本极低。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）存在幻觉问题，现有解决方案计算成本高。幻觉与视觉信息注意不足有关，冗余视觉信息会分散模型注意力。

Method: 提出PruneHal方法，通过自适应KV缓存剪枝，增强模型对关键视觉信息的关注，从而减少幻觉。此方法无需训练，几乎没有额外的推理成本，且适用于不同解码策略。

Result: 在多个基准测试中，使用四种主流MLLMs，PruneHal取得了稳健且优越的结果，证明了其有效性和优越性。

Conclusion: PruneHal是一种有效的、训练无关的、简单的减轻MLLMs幻觉的方法，通过自适应KV缓存剪枝来增强模型对关键视觉信息的关注。

Abstract: While multi-modal large language models (MLLMs) have made significant
progress in recent years, the issue of hallucinations remains a major
challenge. To mitigate this phenomenon, existing solutions either introduce
additional data for further training or incorporate external or internal
information during inference. However, these approaches inevitably introduce
extra computational costs. In this paper, we observe that hallucinations in
MLLMs are strongly associated with insufficient attention allocated to visual
tokens. In particular, the presence of redundant visual tokens disperses the
model's attention, preventing it from focusing on the most informative ones. As
a result, critical visual cues are often under-attended, which in turn
exacerbates the occurrence of hallucinations. Building on this observation, we
propose \textbf{PruneHal}, a training-free, simple yet effective method that
leverages adaptive KV cache pruning to enhance the model's focus on critical
visual information, thereby mitigating hallucinations. To the best of our
knowledge, we are the first to apply token pruning for hallucination mitigation
in MLLMs. Notably, our method don't require additional training and incurs
nearly no extra inference cost. Moreover, PruneHal is model-agnostic and can be
seamlessly integrated with different decoding strategies, including those
specifically designed for hallucination mitigation. We evaluate PruneHal on
several widely used hallucination evaluation benchmarks using four mainstream
MLLMs, achieving robust and outstanding results that highlight the
effectiveness and superiority of our method. Our code will be publicly
available.

</details>


### [15] [Video Consistency Distance: Enhancing Temporal Consistency for Image-to-Video Generation via Reward-Based Fine-Tuning](https://arxiv.org/abs/2510.19193)
*Takehiro Aoshima,Yusuke Shinohara,Park Byeongseon*

Main category: cs.CV

TL;DR: 通过引入视频一致性距离（VCD）指标，优化了视频生成模型在图像到视频生成任务中的时间一致性问题，同时保持了其他性能。


<details>
  <summary>Details</summary>
Motivation: 传统的基于奖励的视频扩散模型微调方法，虽然无需真实视频数据集，但易受限于特定表现，并且在图像到视频生成任务中，整体奖励函数难以保证生成视频序列的时间一致性。

Method: 提出了一种新颖的视频一致性距离（VCD）指标，该指标在视频帧特征的频域中定义，通过频域分析有效捕捉帧信息，以实现相对于条件图像的连贯时间一致性。然后，利用该VCD指标进行基于奖励的微调。

Result: 在多个图像到视频数据集上的实验结果表明，使用VCD进行微调的视频生成模型，在显著增强时间一致性的同时，不会像先前方法那样降低其他性能。

Conclusion: 视频一致性距离（VCD）作为一种新颖的度量标准，能够有效解决视频扩散模型在图像到视频生成任务中的时间一致性问题，并且通过基于奖励的微调框架可以实现这一点，而不会损害视频生成的其他方面。

Abstract: Reward-based fine-tuning of video diffusion models is an effective approach
to improve the quality of generated videos, as it can fine-tune models without
requiring real-world video datasets. However, it can sometimes be limited to
specific performances because conventional reward functions are mainly aimed at
enhancing the quality across the whole generated video sequence, such as
aesthetic appeal and overall consistency. Notably, the temporal consistency of
the generated video often suffers when applying previous approaches to
image-to-video (I2V) generation tasks. To address this limitation, we propose
Video Consistency Distance (VCD), a novel metric designed to enhance temporal
consistency, and fine-tune a model with the reward-based fine-tuning framework.
To achieve coherent temporal consistency relative to a conditioning image, VCD
is defined in the frequency space of video frame features to capture frame
information effectively through frequency-domain analysis. Experimental results
across multiple I2V datasets demonstrate that fine-tuning a video generation
model with VCD significantly enhances temporal consistency without degrading
other performance compared to the previous method.

</details>


### [16] [Rethinking Driving World Model as Synthetic Data Generator for Perception Tasks](https://arxiv.org/abs/2510.19195)
*Kai Zeng,Zhanqian Wu,Kaixin Xiong,Xiaobao Wei,Xiangyu Guo,Zhenxin Zhu,Kalok Ho,Lijun Zhou,Bohan Zeng,Ming Lu,Haiyang Sun,Bing Wang,Guang Chen,Hangjun Ye,Wentao Zhang*

Main category: cs.CV

TL;DR: Dream4Drive是一个新的合成数据生成框架，旨在通过生成多视图的、包含各种极端情况的逼真视频来提升自动驾驶下游感知任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶世界模型在生成质量和可控性方面表现良好，但忽略了对下游感知任务的重要性评估。现有的预训练-微调策略效率低下，并且在增加训练周期后，合成数据的优势会变得不明显。

Method: Dream4Drive框架首先将输入视频分解为3D感知的引导图，然后将3D资产渲染到这些引导图上，最后微调驱动世界模型以生成逼真的、多视角的视频，用于训练下游感知模型。此外，还贡献了一个名为DriveObj3D的大规模3D资产数据集。

Result: Dream4Drive能够大规模生成多视图的极端情况，显著提升了自动驾驶的极端情况感知能力。实验证明，Dream4Drive在不同训练周期下都能有效提升下游感知模型的性能。

Conclusion: Dream4Drive是一个有效的合成数据生成框架，可以大规模生成用于训练自动驾驶下游感知模型的多样化数据，尤其是在处理极端情况方面有显著优势。DriveObj3D数据集也为相关研究提供了支持。

Abstract: Recent advancements in driving world models enable controllable generation of
high-quality RGB videos or multimodal videos. Existing methods primarily focus
on metrics related to generation quality and controllability. However, they
often overlook the evaluation of downstream perception tasks, which are
$\mathbf{really\ crucial}$ for the performance of autonomous driving. Existing
methods usually leverage a training strategy that first pretrains on synthetic
data and finetunes on real data, resulting in twice the epochs compared to the
baseline (real data only). When we double the epochs in the baseline, the
benefit of synthetic data becomes negligible. To thoroughly demonstrate the
benefit of synthetic data, we introduce Dream4Drive, a novel synthetic data
generation framework designed for enhancing the downstream perception tasks.
Dream4Drive first decomposes the input video into several 3D-aware guidance
maps and subsequently renders the 3D assets onto these guidance maps. Finally,
the driving world model is fine-tuned to produce the edited, multi-view
photorealistic videos, which can be used to train the downstream perception
models. Dream4Drive enables unprecedented flexibility in generating multi-view
corner cases at scale, significantly boosting corner case perception in
autonomous driving. To facilitate future research, we also contribute a
large-scale 3D asset dataset named DriveObj3D, covering the typical categories
in driving scenarios and enabling diverse 3D-aware video editing. We conduct
comprehensive experiments to show that Dream4Drive can effectively boost the
performance of downstream perception models under various training epochs.
Project: $\href{https://wm-research.github.io/Dream4Drive/}{this\ https\ URL}$

</details>


### [17] [MoE-GS: Mixture of Experts for Dynamic Gaussian Splatting](https://arxiv.org/abs/2510.19210)
*In-Hwan Jin,Hyeongju Mun,Joonsoo Kim,Kugjin Yun,Kyeongbo Kong*

Main category: cs.CV

TL;DR: MoE-GS通过引入混合专家模型和体积感知像素路由来统一动态场景重建，解决了现有方法性能不一致的问题，并通过多种优化策略提高了效率。


<details>
  <summary>Details</summary>
Motivation: 现有动态场景重建方法在处理不同场景时性能不一致，未能有效应对所有动态挑战。

Method: 提出了一种名为MoE-GS的统一框架，集成了多个专业化的专家模型，并通过新颖的体积感知像素路由（Volume-aware Pixel Router）自适应地融合专家输出。该路由将体积高斯层权重投影到像素空间，以实现时空一致的结果。此外，还探索了单通道多专家渲染、门控高斯剪枝以及蒸馏策略以提高效率和轻量化部署。

Result: MoE-GS在N3V和Technicolor数据集上的实验表明，该方法在渲染质量和效率上均优于现有最先进的方法。

Conclusion: MoE-GS是首个将混合专家技术应用于动态高斯飞溅的方法，通过其新颖的路由和优化策略，在动态场景重建方面取得了显著的性能和效率提升。

Abstract: Recent advances in dynamic scene reconstruction have significantly benefited
from 3D Gaussian Splatting, yet existing methods show inconsistent performance
across diverse scenes, indicating no single approach effectively handles all
dynamic challenges. To overcome these limitations, we propose Mixture of
Experts for Dynamic Gaussian Splatting (MoE-GS), a unified framework
integrating multiple specialized experts via a novel Volume-aware Pixel Router.
Our router adaptively blends expert outputs by projecting volumetric
Gaussian-level weights into pixel space through differentiable weight
splatting, ensuring spatially and temporally coherent results. Although MoE-GS
improves rendering quality, the increased model capacity and reduced FPS are
inherent to the MoE architecture. To mitigate this, we explore two
complementary directions: (1) single-pass multi-expert rendering and gate-aware
Gaussian pruning, which improve efficiency within the MoE framework, and (2) a
distillation strategy that transfers MoE performance to individual experts,
enabling lightweight deployment without architectural changes. To the best of
our knowledge, MoE-GS is the first approach incorporating Mixture-of-Experts
techniques into dynamic Gaussian splatting. Extensive experiments on the N3V
and Technicolor datasets demonstrate that MoE-GS consistently outperforms
state-of-the-art methods with improved efficiency. Video demonstrations are
available at https://anonymous.4open.science/w/MoE-GS-68BA/.

</details>


### [18] [SFGFusion: Surface Fitting Guided 3D Object Detection with 4D Radar and Camera Fusion](https://arxiv.org/abs/2510.19215)
*Xiaozhi Li,Huijun Di,Jian Li,Feng Liu,Wei Liang*

Main category: cs.CV

TL;DR: SFGFusion是一种结合了相机和4D成像雷达数据的3D目标检测网络，通过表面拟合来增强空间表示和跨模态交互，从而提高检测精度。


<details>
  <summary>Details</summary>
Motivation: 4D成像雷达虽然在成本、探测距离和速度测量方面有优势，但其点云稀疏、分辨率低等缺点限制了其在3D目标检测中的应用。本研究旨在克服这些挑战，并融合相机数据以提高检测性能。

Method: SFGFusion网络通过估计物体表面的二次曲面参数来增强空间表示和跨模态交互。预测的深度用于引导图像特征从透视视图（PV）到鸟瞰视图（BEV）的转换，以提高空间映射精度，并生成密集伪点云以弥补雷达点云的稀疏性。原始雷达点云也在单独的雷达分支中进行编码。最后，利用2D骨干网络和检测头从BEV特征中预测目标标签和边界框。

Result: SFGFusion网络在TJ4DRadSet和view-of-delft (VoD) 3D目标检测基准上取得了优于现有方法的性能，证明了其有效融合相机和4D雷达特征的能力。

Conclusion: SFGFusion通过引入表面拟合机制，有效解决了4D成像雷达点云稀疏和低分辨率的问题，并实现了相机与4D雷达数据的深度融合，显著提升了3D目标检测的性能。

Abstract: 3D object detection is essential for autonomous driving. As an emerging
sensor, 4D imaging radar offers advantages as low cost, long-range detection,
and accurate velocity measurement, making it highly suitable for object
detection. However, its sparse point clouds and low resolution limit object
geometric representation and hinder multi-modal fusion. In this study, we
introduce SFGFusion, a novel camera-4D imaging radar detection network guided
by surface fitting. By estimating quadratic surface parameters of objects from
image and radar data, the explicit surface fitting model enhances spatial
representation and cross-modal interaction, enabling more reliable prediction
of fine-grained dense depth. The predicted depth serves two purposes: 1) in an
image branch to guide the transformation of image features from perspective
view (PV) to a unified bird's-eye view (BEV) for multi-modal fusion, improving
spatial mapping accuracy; and 2) in a surface pseudo-point branch to generate
dense pseudo-point cloud, mitigating the radar point sparsity. The original
radar point cloud is also encoded in a separate radar branch. These two point
cloud branches adopt a pillar-based method and subsequently transform the
features into the BEV space. Finally, a standard 2D backbone and detection head
are used to predict object labels and bounding boxes from BEV features.
Experimental results show that SFGFusion effectively fuses camera and 4D radar
features, achieving superior performance on the TJ4DRadSet and view-of-delft
(VoD) object detection benchmarks.

</details>


### [19] [Space Object Detection using Multi-frame Temporal Trajectory Completion Method](https://arxiv.org/abs/2510.19220)
*Xiaoqing Lan,Biqiao Xin,Bingshu Wang,Han Zhang,Laixian Zhang*

Main category: cs.CV

TL;DR: 该研究提出了一种用于检测地静轨道（GEO）空间物体的光学成像方法，通过小波变换增强目标特征并抑制噪声，并结合匈牙利算法进行多帧匹配和轨迹补全，最终在SpotGEO数据集上取得了90.14%的F_1分数。


<details>
  <summary>Details</summary>
Motivation: 地静轨道（GEO）空间物体的光学成像检测面临信号弱、背景复杂和环境干扰等挑战。

Method: 1. 使用小波变换增强单帧图像的高频特征并抑制背景噪声。 2. 提出一种基于匈牙利算法的多帧时间轨迹补全方案，实现最优的跨帧匹配。 3. 设计了一系列后处理步骤，包括时间匹配和插值补全、基于时间一致性的噪声过滤以及渐进式轨迹优化，以处理缺失和错误检测。

Result: 在公开的SpotGEO数据集上进行了实验，验证了所提方法的有效性。

Conclusion: 所提出的方法能够有效增强GEO目标检测性能，并在SpotGEO数据集上取得了90.14%的F_1分数。

Abstract: Space objects in Geostationary Earth Orbit (GEO) present significant
detection challenges in optical imaging due to weak signals, complex stellar
backgrounds, and environmental interference. In this paper, we enhance
high-frequency features of GEO targets while suppressing background noise at
the single-frame level through wavelet transform. Building on this, we propose
a multi-frame temporal trajectory completion scheme centered on the Hungarian
algorithm for globally optimal cross-frame matching. To effectively mitigate
missing and false detections, a series of key steps including temporal matching
and interpolation completion, temporal-consistency-based noise filtering, and
progressive trajectory refinement are designed in the post-processing pipeline.
Experimental results on the public SpotGEO dataset demonstrate the
effectiveness of the proposed method, achieving an F_1 score of 90.14%.

</details>


### [20] [Background Fades, Foreground Leads: Curriculum-Guided Background Pruning for Efficient Foreground-Centric Collaborative Perception](https://arxiv.org/abs/2510.19250)
*Yuheng Wu,Xiangbo Gao,Quang Tau,Zhengzhong Tu,Dongman Lee*

Main category: cs.CV

TL;DR: FadeLead通过将背景上下文压缩到前景特征中，解决了车辆协同感知中的带宽限制问题，在不同带宽设置下均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 单一车辆感知在长尾场景中面临挑战，而协同感知通过信息共享提高了可靠性和空间覆盖范围。然而，车辆网络的带宽限制使得传输整个特征图不切实际。

Method: 提出了一种名为FadeLead的框架，该框架通过学习在训练期间将背景上下文封装到紧凑的前景特征中来克服背景信息丢失的问题。其核心是一种课程学习策略，早期利用背景线索，然后逐渐去除它们，迫使模型在不传输背景本身的情况下将上下文内化到前景表示中。

Result: 在模拟和真实世界的基准测试中，FadeLead在不同的带宽设置下均优于现有方法。

Conclusion: FadeLead通过上下文丰富的前景共享有效地解决了车辆协同感知中的带宽限制问题，提高了感知性能。

Abstract: Collaborative perception enhances the reliability and spatial coverage of
autonomous vehicles by sharing complementary information across vehicles,
offering a promising solution to long-tail scenarios that challenge
single-vehicle perception. However, the bandwidth constraints of vehicular
networks make transmitting the entire feature map impractical. Recent methods,
therefore, adopt a foreground-centric paradigm, transmitting only predicted
foreground-region features while discarding the background, which encodes
essential context. We propose FadeLead, a foreground-centric framework that
overcomes this limitation by learning to encapsulate background context into
compact foreground features during training. At the core of our design is a
curricular learning strategy that leverages background cues early on but
progressively prunes them away, forcing the model to internalize context into
foreground representations without transmitting background itself. Extensive
experiments on both simulated and real-world benchmarks show that FadeLead
outperforms prior methods under different bandwidth settings, underscoring the
effectiveness of context-enriched foreground sharing.

</details>


### [21] [Advances in 4D Representation: Geometry, Motion, and Interaction](https://arxiv.org/abs/2510.19255)
*Mingrui Zhao,Sauradip Nag,Kai Wang,Aditya Vora,Guangda Ji,Peter Chun,Ali Mahdavi-Amiri,Hao Zhang*

Main category: cs.CV

TL;DR: 本文对4D生成和重建领域进行了综述，重点关注4D表示方法，并从几何、运动和交互三个维度进行了分类，探讨了不同表示方法的优缺点、挑战以及未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 4D生成和重建是计算机图形学的一个快速发展领域，受到神经场、几何和运动深度学习以及3D生成式人工智能的推动。本文旨在提供一个独特的视角，关注4D表示方法，以模拟随时间演变的3D几何体，并展示运动和交互。

Method: 本文首先从几何、运动和交互三个关键支柱对4D表示方法进行分类。然后，重点介绍具有代表性的作品，以突出不同计算、应用和数据场景下每种表示方法的优点和挑战。最后，讨论了大型语言模型（LLMs）和视频基础模型（VFMs）在4D应用中的作用，以及它们当前的局限性，并对可用的4D数据集进行了分析。

Result: 本文重点介绍了包括神经辐射场（NeRFs）和3D高斯溅射（3DGS）在内的流行表示方法，以及结构化模型和长距离运动等较少被探索的表示方法。此外，还讨论了LLMs和VFMs在4D应用中的作用，并分析了当前4D数据集的可用性和缺失情况。

Conclusion: 本文旨在帮助读者了解如何选择和定制适合其任务的4D表示方法，并为该领域的未来发展指明方向。

Abstract: We present a survey on 4D generation and reconstruction, a fast-evolving
subfield of computer graphics whose developments have been propelled by recent
advances in neural fields, geometric and motion deep learning, as well 3D
generative artificial intelligence (GenAI). While our survey is not the first
of its kind, we build our coverage of the domain from a unique and distinctive
perspective of 4D representations\/}, to model 3D geometry evolving over time
while exhibiting motion and interaction. Specifically, instead of offering an
exhaustive enumeration of many works, we take a more selective approach by
focusing on representative works to highlight both the desirable properties and
ensuing challenges of each representation under different computation,
application, and data scenarios. The main take-away message we aim to convey to
the readers is on how to select and then customize the appropriate 4D
representations for their tasks. Organizationally, we separate the 4D
representations based on three key pillars: geometry, motion, and interaction.
Our discourse will not only encompass the most popular representations of
today, such as neural radiance fields (NeRFs) and 3D Gaussian Splatting (3DGS),
but also bring attention to relatively under-explored representations in the 4D
context, such as structured models and long-range motions. Throughout our
survey, we will reprise the role of large language models (LLMs) and video
foundational models (VFMs) in a variety of 4D applications, while steering our
discussion towards their current limitations and how they can be addressed. We
also provide a dedicated coverage on what 4D datasets are currently available,
as well as what is lacking, in driving the subfield forward. Project
page:https://mingrui-zhao.github.io/4DRep-GMI/

</details>


### [22] [SCEESR: Semantic-Control Edge Enhancement for Diffusion-Based Super-Resolution](https://arxiv.org/abs/2510.19272)
*Yun Kai Zhuang*

Main category: cs.CV

TL;DR: 通过引入ControlNet机制和混合损失函数，提出了一种新的超分辨率框架，在保持高效的同时提高了图像的结构完整性和真实感。


<details>
  <summary>Details</summary>
Motivation: 为了解决真实世界图像超分辨率中存在的复杂降质、重建歧义以及现有生成模型在感知质量和计算成本之间的权衡问题，特别是单步扩散模型在速度和结构准确性之间的不足。

Method: 提出了一种新的超分辨率框架，该框架使用ControlNet机制增强单步扩散模型，实现语义边缘引导，并引入结合L2、LPIPS和边缘感知AME损失的混合损失函数。

Result: 实验表明，所提出的方法在保持单步生成效率的同时，有效提高了结构完整性和真实感，实现了输出质量和推理速度之间的优越平衡。

Conclusion: 所提出的框架通过结合ControlNet的结构控制和混合损失的优化，成功解决了真实世界图像超分辨率中的挑战，并在质量和速度之间取得了更好的平衡。

Abstract: Real-world image super-resolution (Real-ISR) must handle complex degradations
and inherent reconstruction ambiguities. While generative models have improved
perceptual quality, a key trade-off remains with computational cost. One-step
diffusion models offer speed but often produce structural inaccuracies due to
distillation artifacts. To address this, we propose a novel SR framework that
enhances a one-step diffusion model using a ControlNet mechanism for semantic
edge guidance. This integrates edge information to provide dynamic structural
control during single-pass inference. We also introduce a hybrid loss combining
L2, LPIPS, and an edge-aware AME loss to optimize for pixel accuracy,
perceptual quality, and geometric precision. Experiments show our method
effectively improves structural integrity and realism while maintaining the
efficiency of one-step generation, achieving a superior balance between output
quality and inference speed. The results of test datasets will be published at
https://drive.google.com/drive/folders/1amddXQ5orIyjbxHgGpzqFHZ6KTolinJF?usp=drive_link
and the related code will be published at
https://github.com/ARBEZ-ZEBRA/SCEESR.

</details>


### [23] [MobiAct: Efficient MAV Action Recognition Using MobileNetV4 with Contrastive Learning and Knowledge Distillation](https://arxiv.org/abs/2510.19273)
*Zhang Nengbo,Ho Hann Woei*

Main category: cs.CV

TL;DR: MobiAct是一个轻量级的MAV动作识别框架，采用MobileNetV4作为骨干网络，结合阶段式正交知识蒸馏（SOKD）和参数无关的注意力机制，以低计算成本实现高精度和高识别速度。


<details>
  <summary>Details</summary>
Motivation: 现有MAV动作识别方法计算量大，不适用于资源受限的MAV平台，导致准确性和推理速度之间的权衡。本研究旨在解决这一挑战，提出一种轻量级的MAV动作识别框架MobiAct，以实现高精度和低计算成本。

Method: MobiAct采用MobileNetV4作为骨干网络，并引入阶段式正交知识蒸馏（SOKD）策略将知识从教师网络（ResNet18）转移到学生网络，同时集成参数无关的注意力机制和混合损失训练策略。

Result: MobiAct实现了低能耗、低计算的MAV动作识别，平均识别准确率为92.12%，能耗为136.16 pJ，识别速度为8.84动作/秒。其解码速度是最快方法的2倍，准确率具有高度可比性。

Conclusion: MobiAct在MAV动作识别方面展现出卓越的效率，实现了高识别准确率、低能耗和高识别速度，证明了其在资源受限平台上的可行性。

Abstract: Accurate and efficient recognition of Micro Air Vehicle (MAV) motion is
essential for enabling real-time perception and coordination in autonomous
aerial swarm. However, most existing approaches rely on large, computationally
intensive models that are unsuitable for resource-limited MAV platforms, which
results in a trade-off between recognition accuracy and inference speed. To
address these challenges, this paper proposes a lightweight MAV action
recognition framework, MobiAct, designed to achieve high accuracy with low
computational cost. Specifically, MobiAct adopts MobileNetV4 as the backbone
network and introduces a Stage-wise Orthogonal Knowledge Distillation (SOKD)
strategy to effectively transfer MAV motion features from a teacher network
(ResNet18) to a student network, thereby enhancing knowledge transfer
efficiency. Furthermore, a parameter-free attention mechanism is integrated
into the architecture to improve recognition accuracy without increasing model
complexity. In addition, a hybrid loss training strategy is developed to
combine multiple loss objectives, which ensures stable and robust optimization
during training. Experimental results demonstrate that the proposed MobiAct
achieves low-energy and low-computation MAV action recognition, while
maintaining the fastest action decoding speed among compared methods. Across
all three self-collected datasets, MobiAct achieves an average recognition
accuracy of 92.12%, while consuming only 136.16 pJ of energy and processing
recognition at a rate of 8.84 actions per second. Notably, MobiAct decodes
actions up to 2 times faster than the leading method, with highly comparable
recognition accuracy, highlighting its superior efficiency in MAV action
recognition.

</details>


### [24] [D2D: Detector-to-Differentiable Critic for Improved Numeracy in Text-to-Image Generation](https://arxiv.org/abs/2510.19278)
*Nobline Yoo,Olga Russakovsky,Ye Zhu*

Main category: cs.CV

TL;DR: T2I扩散模型在物体数量生成上表现不佳，现有方法受限于可微性。我们提出D2D框架，将不可微的检测模型转化为可微批评者，利用其优越的计数能力来指导生成。实验证明D2D在多个基准测试中显著提高了计数准确性，同时对图像质量和计算开销影响很小。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像（T2I）扩散模型虽然在语义对齐方面表现出色，但在生成提示中指定的物体数量方面仍存在不足。现有的方法通常依赖于辅助计数网络作为外部批评者来提高数字能力，但这些批评者必须在生成过程中提供梯度指导，因此仅限于可微的回归模型，排除了具有更高计数能力的检测器模型，因为它们的计数方法（逐个枚举）是不可微的。

Method: 我们提出了一种名为Detector-to-Differentiable（D2D）的新颖框架，它能够将不可微的检测模型转换为可微的批评者，从而利用它们卓越的计数能力来指导数字生成。具体来说，我们设计了自定义激活函数，将检测器的置信度分数转换为软二值指示符，然后利用这些指示符在推理时使用预训练的T2I模型来优化噪声先验。

Result: 我们在SDXL-Turbo、SD-Turbo和Pixart-DMD模型上，以及在四个不同复杂度的基准测试（低密度、高密度和多物体场景）上进行了广泛的实验。实验结果一致表明，在物体计数准确性方面取得了显著的提升（例如，在D2D-Small基准测试上提升高达13.7%，该基准测试包含400个提示和低密度场景），同时对整体图像质量和计算开销的影响很小。

Conclusion: D2D框架成功地将不可微的检测模型转化为可微的批评者，有效解决了T2I扩散模型在物体数量生成方面的挑战，并在各种场景下实现了计数准确性的显著提升，同时保持了良好的图像质量和计算效率。

Abstract: Text-to-image (T2I) diffusion models have achieved strong performance in
semantic alignment, yet they still struggle with generating the correct number
of objects specified in prompts. Existing approaches typically incorporate
auxiliary counting networks as external critics to enhance numeracy. However,
since these critics must provide gradient guidance during generation, they are
restricted to regression-based models that are inherently differentiable, thus
excluding detector-based models with superior counting ability, whose
count-via-enumeration nature is non-differentiable. To overcome this
limitation, we propose Detector-to-Differentiable (D2D), a novel framework that
transforms non-differentiable detection models into differentiable critics,
thereby leveraging their superior counting ability to guide numeracy
generation. Specifically, we design custom activation functions to convert
detector logits into soft binary indicators, which are then used to optimize
the noise prior at inference time with pre-trained T2I models. Our extensive
experiments on SDXL-Turbo, SD-Turbo, and Pixart-DMD across four benchmarks of
varying complexity (low-density, high-density, and multi-object scenarios)
demonstrate consistent and substantial improvements in object counting accuracy
(e.g., boosting up to 13.7% on D2D-Small, a 400-prompt, low-density benchmark),
with minimal degradation in overall image quality and computational overhead.

</details>


### [25] [Enhancing Early Alzheimer Disease Detection through Big Data and Ensemble Few-Shot Learning](https://arxiv.org/abs/2510.19282)
*Safa Ben Atitallah,Maha Driss,Wadii Boulila,Anis Koubaa*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Alzheimer disease is a severe brain disorder that causes harm in various
brain areas and leads to memory damage. The limited availability of labeled
medical data poses a significant challenge for accurate Alzheimer disease
detection. There is a critical need for effective methods to improve the
accuracy of Alzheimer disease detection, considering the scarcity of labeled
data, the complexity of the disease, and the constraints related to data
privacy. To address this challenge, our study leverages the power of big data
in the form of pre-trained Convolutional Neural Networks (CNNs) within the
framework of Few-Shot Learning (FSL) and ensemble learning. We propose an
ensemble approach based on a Prototypical Network (ProtoNet), a powerful method
in FSL, integrating various pre-trained CNNs as encoders. This integration
enhances the richness of features extracted from medical images. Our approach
also includes a combination of class-aware loss and entropy loss to ensure a
more precise classification of Alzheimer disease progression levels. The
effectiveness of our method was evaluated using two datasets, the Kaggle
Alzheimer dataset and the ADNI dataset, achieving an accuracy of 99.72% and
99.86%, respectively. The comparison of our results with relevant
state-of-the-art studies demonstrated that our approach achieved superior
accuracy and highlighted its validity and potential for real-world applications
in early Alzheimer disease detection.

</details>


### [26] [Vision-Based Mistake Analysis in Procedural Activities: A Review of Advances and Challenges](https://arxiv.org/abs/2510.19292)
*Konstantinos Bacharidis,Antonis A. Argyros*

Main category: cs.CV

TL;DR: 本文综述了基于视觉的程序性活动错误分析方法，重点关注检测和预测任务执行中的偏差。


<details>
  <summary>Details</summary>
Motivation: 程序性活动中的错误分析在工业自动化、康复、教育和人机协作等领域具有重要应用价值。

Method: 本文综述了利用计算机视觉技术（包括动作识别、预测和活动理解）来检测和预测程序性活动中错误的方法，并探讨了相关的挑战、数据集、评估指标和现有方法。

Result: 文章讨论了类内差异、视角差异和组合活动结构等挑战，并对现有数据集、评估指标和最先进的方法进行了分类和概述。

Conclusion: 文章指出了区分允许的变异与实际错误以及模拟错误传播等开放性挑战，并提出了神经符号推理和反事实状态建模等未来方向，旨在为基于视觉的错误分析提供统一视角，以提高安全性和效率。

Abstract: Mistake analysis in procedural activities is a critical area of research with
applications spanning industrial automation, physical rehabilitation, education
and human-robot collaboration. This paper reviews vision-based methods for
detecting and predicting mistakes in structured tasks, focusing on procedural
and executional errors. By leveraging advancements in computer vision,
including action recognition, anticipation and activity understanding,
vision-based systems can identify deviations in task execution, such as
incorrect sequencing, use of improper techniques, or timing errors. We explore
the challenges posed by intra-class variability, viewpoint differences and
compositional activity structures, which complicate mistake detection.
Additionally, we provide a comprehensive overview of existing datasets,
evaluation metrics and state-of-the-art methods, categorizing approaches based
on their use of procedural structure, supervision levels and learning
strategies. Open challenges, such as distinguishing permissible variations from
true mistakes and modeling error propagation are discussed alongside future
directions, including neuro-symbolic reasoning and counterfactual state
modeling. This work aims to establish a unified perspective on vision-based
mistake analysis in procedural activities, highlighting its potential to
enhance safety, efficiency and task performance across diverse domains.

</details>


### [27] [Unified Reinforcement and Imitation Learning for Vision-Language Models](https://arxiv.org/abs/2510.19307)
*Byung-Kwan Lee,Ryo Hachiuma,Yong Man Ro,Yu-Chiang Frank Wang,Yueh-Hua Wu*

Main category: cs.CV

TL;DR: 该论文提出了一种名为RIL的新型高效训练算法，用于创建轻量级视觉-语言模型（VLM），通过结合强化学习和对抗性模仿学习，使小型VLM能够模仿大型教师模型的生成能力并进行系统性改进，并在多个基准测试中取得了与顶尖模型相媲美甚至超越的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型（VLM）规模庞大，在资源受限的环境中难以应用。因此，需要一种能够创建强大但轻量级VLM的有效训练算法。

Method: 提出了一种名为RIL（Unified Reinforcement and Imitation Learning）的训练算法，该算法结合了强化学习和对抗性模仿学习的优点。具体来说，利用基于LLM的判别器来区分学生模型和教师模型的输出，并引入多个大型教师VLM的指导，以实现多样化学习。

Result: 通过RIL训练出的轻量级学生VLM，不仅能够模仿大型教师模型的文本生成能力，还能通过强化信号系统性地改进其生成能力。在多个视觉-语言基准测试中，RIL显著缩小了与现有最优开放和闭源VLM之间的性能差距，并在某些情况下取得了超越。

Conclusion: RIL是一种有效的训练算法，能够显著提升轻量级VLM的性能，使其在资源受限的环境中具有实用价值，并能在与顶尖模型的竞争中脱颖而出。

Abstract: Vision-Language Models (VLMs) have achieved remarkable progress, yet their
large scale often renders them impractical for resource-constrained
environments. This paper introduces Unified Reinforcement and Imitation
Learning (RIL), a novel and efficient training algorithm designed to create
powerful, lightweight VLMs. RIL distinctively combines the strengths of
reinforcement learning with adversarial imitation learning. This enables
smaller student VLMs not only to mimic the sophisticated text generation of
large teacher models but also to systematically improve their generative
capabilities through reinforcement signals. Key to our imitation framework is
an LLM-based discriminator that adeptly distinguishes between student and
teacher outputs, complemented by guidance from multiple large teacher VLMs to
ensure diverse learning. This unified learning strategy, leveraging both
reinforcement and imitation, empowers student models to achieve significant
performance gains, making them competitive with leading closed-source VLMs.
Extensive experiments on diverse vision-language benchmarks demonstrate that
RIL significantly narrows the performance gap with state-of-the-art open- and
closed-source VLMs and, in several instances, surpasses them.

</details>


### [28] [Online Handwritten Signature Verification Based on Temporal-Spatial Graph Attention Transformer](https://arxiv.org/abs/2510.19321)
*Hai-jie Yuan,Heng Zhang,Fei Yin*

Main category: cs.CV

TL;DR: 该论文提出了一种名为TS-GATR的新型动态手写签名验证方法，该方法结合了图注意力网络（GAT）和门控循环单元（GRU），能够同时捕捉签名数据的空间和时间依赖性，并在基准数据集上取得了优于现有最先进方法的性能。


<details>
  <summary>Details</summary>
Motivation: 手写签名验证在身份认证中至关重要，但由于用户内部差异和伪造风险，实现高精度验证仍然困难。

Method: 提出TS-GATR模型，将签名表示为图，节点包含动态特征，并使用注意力机制建模关系。通过DGATR模块利用k步和k近邻邻接图来模拟局部和全局空间特征。集成GRU来捕捉长期时间依赖性。

Result: 在MSDS和DeepSignDB数据集上的实验表明，TS-GATR的错误率（EER）低于现有最先进的方法。

Conclusion: TS-GATR在动态手写签名验证方面表现出色，能够有效处理用户内部差异和伪造风险，并在基准数据集上取得了领先的性能。

Abstract: Handwritten signature verification is a crucial aspect of identity
authentication, with applications in various domains such as finance and
e-commerce. However, achieving high accuracy in signature verification remains
challenging due to intra-user variability and the risk of forgery. This paper
introduces a novel approach for dynamic signature verification: the
Temporal-Spatial Graph Attention Transformer (TS-GATR). TS-GATR combines the
Graph Attention Network (GAT) and the Gated Recurrent Unit (GRU) to model both
spatial and temporal dependencies in signature data. TS-GATR enhances
verification performance by representing signatures as graphs, where each node
captures dynamic features (e.g. position, velocity, pressure), and by using
attention mechanisms to model their complex relationships. The proposed method
further employs a Dual-Graph Attention Transformer (DGATR) module, which
utilizes k-step and k-nearest neighbor adjacency graphs to model local and
global spatial features, respectively. To capture long-term temporal
dependencies, the model integrates GRU, thereby enhancing its ability to learn
dynamic features during signature verification. Comprehensive experiments
conducted on benchmark datasets such as MSDS and DeepSignDB show that TS-GATR
surpasses current state-of-the-art approaches, consistently achieving lower
Equal Error Rates (EER) across various scenarios.

</details>


### [29] [Seabed-Net: A multi-task network for joint bathymetry estimation and seabed classification from remote sensing imagery in shallow waters](https://arxiv.org/abs/2510.19329)
*Panagiotis Agrafiotis,Begüm Demir*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Accurate, detailed, and regularly updated bathymetry, coupled with complex
semantic content, is essential for under-mapped shallow-water environments
facing increasing climatological and anthropogenic pressures. However, existing
approaches that derive either depth or seabed classes from remote sensing
imagery treat these tasks in isolation, forfeiting the mutual benefits of their
interaction and hindering the broader adoption of deep learning methods. To
address these limitations, we introduce Seabed-Net, a unified multi-task
framework that simultaneously predicts bathymetry and pixel-based seabed
classification from remote sensing imagery of various resolutions. Seabed-Net
employs dual-branch encoders for bathymetry estimation and pixel-based seabed
classification, integrates cross-task features via an Attention Feature Fusion
module and a windowed Swin-Transformer fusion block, and balances objectives
through dynamic task uncertainty weighting. In extensive evaluations at two
heterogeneous coastal sites, it consistently outperforms traditional empirical
models and traditional machine learning regression methods, achieving up to
75\% lower RMSE. It also reduces bathymetric RMSE by 10-30\% compared to
state-of-the-art single-task and multi-task baselines and improves seabed
classification accuracy up to 8\%. Qualitative analyses further demonstrate
enhanced spatial consistency, sharper habitat boundaries, and corrected depth
biases in low-contrast regions. These results confirm that jointly modeling
depth with both substrate and seabed habitats yields synergistic gains,
offering a robust, open solution for integrated shallow-water mapping. Code and
pretrained weights are available at https://github.com/pagraf/Seabed-Net.

</details>


### [30] [Exploring Scale Shift in Crowd Localization under the Context of Domain Generalization](https://arxiv.org/abs/2510.19330)
*Juncheng Wang,Lei Shang,Ziqi Liu,Wang Lu,Xixu Hu,Zhe Hu,Jindong Wang,Shujun Wang*

Main category: cs.CV

TL;DR: 现有方法在人群定位时会因训练和测试数据的尺度分布差异（尺度偏移）而导致性能下降，该问题被称为域泛化（DG）。本文旨在理解尺度偏移对人群定位模型域泛化特性的影响。


<details>
  <summary>Details</summary>
Motivation: 现有方法在人群定位时会因训练和测试数据的尺度分布差异（尺度偏移）而导致性能下降，该问题被称为域泛化（DG）。本文旨在理解尺度偏移对人群定位模型域泛化特性的影响。

Method: 本文首先系统地研究了不同程度的尺度偏移对人群定位性能的影响。然后，我们建立了一个名为ScaleBench的基准，并复现了20种先进的DG算法来量化这种影响。我们还对尺度偏移进行了严格的理论分析。在此基础上，我们提出了一种名为Catto（因果特征分解和各向异性处理）的算法来减轻尺度偏移在DG设置中的影响。

Result: 通过广泛的实验，我们证明了现有算法的局限性，并强调了尺度偏移的重要性、复杂性以及在现有研究中对其探索的不足。我们提出的Catto算法在DG设置中有效减轻了尺度偏移的影响。

Conclusion: 本文深入探讨了尺度偏移对人群定位模型域泛化的影响，提出了ScaleBench基准和Catto算法，并强调了Scale Shift Domain Generalization这一新的研究方向的重要性。

Abstract: Crowd localization plays a crucial role in visual scene understanding towards
predicting each pedestrian location in a crowd, thus being applicable to
various downstream tasks. However, existing approaches suffer from significant
performance degradation due to discrepancies in head scale distributions (scale
shift) between training and testing data, a challenge known as domain
generalization (DG). This paper aims to comprehend the nature of scale shift
within the context of domain generalization for crowd localization models. To
this end, we address four critical questions: (i) How does scale shift
influence crowd localization in a DG scenario? (ii) How can we quantify this
influence? (iii) What causes this influence? (iv) How to mitigate the
influence? Initially, we conduct a systematic examination of how crowd
localization performance varies with different levels of scale shift. Then, we
establish a benchmark, ScaleBench, and reproduce 20 advanced DG algorithms to
quantify the influence. Through extensive experiments, we demonstrate the
limitations of existing algorithms and underscore the importance and complexity
of scale shift, a topic that remains insufficiently explored. To deepen our
understanding, we provide a rigorous theoretical analysis on scale shift.
Building on these insights, we further propose an effective algorithm called
Causal Feature Decomposition and Anisotropic Processing (Catto) to mitigate the
influence of scale shift in DG settings. Later, we also provide extensive
analytical experiments, revealing four significant insights for future
research. Our results emphasize the importance of this novel and applicable
research direction, which we term Scale Shift Domain Generalization.

</details>


### [31] [BrainMCLIP: Brain Image Decoding with Multi-Layer feature Fusion of CLIP](https://arxiv.org/abs/2510.19332)
*Tian Xia,Zihan Ma,Xinlong Wang,Qing Liu,Xiaowei He,Tianming Liu,Yudan Ren*

Main category: cs.CV

TL;DR: BrainMCLIP通过融合CLIP的中间层和最终层来解码fMRI图像，利用了人类视觉系统的分层结构，并且参数效率高，性能与最先进的方法相当，尤其在高级语义指标上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的fMRI解码方法通常只使用CLIP的最终层，或者添加参数量大的VAE管道来捕捉更精细的视觉细节，这忽略了CLIP中间层丰富的对象信息，并且不符合大脑的功能层级结构。

Method: BrainMCLIP采用参数高效的多层融合方法，该方法受人类视觉系统功能层级的指导。它将来自不同功能视觉区域（低级/高级）的fMRI信号与CLIP的相应中间层和最终层对齐，同时引入了交叉重建策略和新颖的多粒度损失。

Result: BrainMCLIP在高级语义指标上达到了与最先进（SOTA）方法相当甚至更好的性能，包括那些使用了VAE管道的方法。与顶尖的基于VAE的SOTA方法相比，BrainMCLIP的参数量减少了71.7%，因为它避免了使用VAE管道。

Conclusion: BrainMCLIP通过利用CLIP的中间层特征，能够有效地捕捉到仅使用CLIP的方法所遗漏的视觉细节，并在不依赖单独的VAE管道的情况下，在语义准确性和细节保真度之间取得了令人信服的平衡。

Abstract: Decoding images from fMRI often involves mapping brain activity to CLIP's
final semantic layer. To capture finer visual details, many approaches add a
parameter-intensive VAE-based pipeline. However, these approaches overlook rich
object information within CLIP's intermediate layers and contradicts the
brain's functionally hierarchical. We introduce BrainMCLIP, which pioneers a
parameter-efficient, multi-layer fusion approach guided by human visual
system's functional hierarchy, eliminating the need for such a separate VAE
pathway. BrainMCLIP aligns fMRI signals from functionally distinct visual areas
(low-/high-level) to corresponding intermediate and final CLIP layers,
respecting functional hierarchy. We further introduce a Cross-Reconstruction
strategy and a novel multi-granularity loss. Results show BrainMCLIP achieves
highly competitive performance, particularly excelling on high-level semantic
metrics where it matches or surpasses SOTA(state-of-the-art) methods, including
those using VAE pipelines. Crucially, it achieves this with substantially fewer
parameters, demonstrating a reduction of
71.7\%(Table.\ref{tab:compare_clip_vae}) compared to top VAE-based SOTA
methods, by avoiding the VAE pathway. By leveraging intermediate CLIP features,
it effectively captures visual details often missed by CLIP-only approaches,
striking a compelling balance between semantic accuracy and detail fidelity
without requiring a separate VAE pipeline.

</details>


### [32] [A Training-Free Framework for Open-Vocabulary Image Segmentation and Recognition with EfficientNet and CLIP](https://arxiv.org/abs/2510.19333)
*Ying Dai,Wei Yu Chen*

Main category: cs.CV

TL;DR: 提出了一种新的无需训练的开放词汇图像分割和对象识别框架，结合了EfficientNetB0进行无监督分割和CLIP进行开放词汇识别，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 需要一个无需训练的框架来实现开放词汇图像分割和对象识别。

Method: 采用两阶段流程：1. 使用EfficientNetB0提取像素级特征，通过SVD和层次聚类进行无监督分割。2. 使用CLIP的ViT对分割区域进行识别，通过SVD增强跨模态对齐，并计算图像和文本嵌入的相似度进行识别。

Result: 在COCO、ADE20K和PASCAL VOC等基准测试中，在Hungarian mIoU、精度、召回率和F1分数方面取得了最先进的性能。

Conclusion: 所提出的框架在无需训练的情况下，在开放词汇图像分割和对象识别方面是有效的、灵活的和可泛化的。

Abstract: This paper presents a novel training-free framework for open-vocabulary image
segmentation and object recognition (OVSR), which leverages EfficientNetB0, a
convolutional neural network, for unsupervised segmentation and CLIP, a
vision-language model, for open-vocabulary object recognition. The proposed
framework adopts a two stage pipeline: unsupervised image segmentation followed
by segment-level recognition via vision-language alignment. In the first stage,
pixel-wise features extracted from EfficientNetB0 are decomposed using singular
value decomposition to obtain latent representations, which are then clustered
using hierarchical clustering to segment semantically meaningful regions. The
number of clusters is adaptively determined by the distribution of singular
values. In the second stage, the segmented regions are localized and encoded
into image embeddings using the Vision Transformer backbone of CLIP. Text
embeddings are precomputed using CLIP's text encoder from category-specific
prompts, including a generic something else prompt to support open set
recognition. The image and text embeddings are concatenated and projected into
a shared latent feature space via SVD to enhance cross-modal alignment.
Recognition is performed by computing the softmax over the similarities between
the projected image and text embeddings. The proposed method is evaluated on
standard benchmarks, including COCO, ADE20K, and PASCAL VOC, achieving
state-of-the-art performance in terms of Hungarian mIoU, precision, recall, and
F1-score. These results demonstrate the effectiveness, flexibility, and
generalizability of the proposed framework.

</details>


### [33] [From Forecasting to Planning: Policy World Model for Collaborative State-Action Prediction](https://arxiv.org/abs/2510.19654)
*Zhida Zhao,Talas Fu,Yifan Wang,Lijun Wang,Huchuan Lu*

Main category: cs.CV

TL;DR: PWM是一个集成了世界建模和轨迹规划的框架，通过预测未来状态来改进规划，并使用动态增强的并行令牌生成机制来提高效率。


<details>
  <summary>Details</summary>
Motivation: 尽管世界模型在自动驾驶领域取得了显著进展，但其在轨迹规划方面的应用仍有待开发。现有方法通常将世界模拟与轨迹规划分离，而统一世界建模和规划的框架也需要进一步探索其协同机制。

Method: 提出了一种名为策略世界模型（PWM）的新范式，它在一个统一的架构中集成了世界建模和轨迹规划。通过提出的无动作未来状态预测方案，利用学习到的世界知识来增强规划能力。采用动态增强的并行令牌生成机制（包括上下文引导的分词器和自适应动态焦点损失）来提高视频预测的效率。

Result: 该方法仅使用前置摄像头输入，在规划性能上就达到了甚至超过了使用多视图和多模态输入的现有最先进方法。

Conclusion: PWM通过集成世界建模和规划，并利用预测的未来状态来增强规划能力，展示了其在自动驾驶领域的潜力，并且在效率和性能上优于现有方法。

Abstract: Despite remarkable progress in driving world models, their potential for
autonomous systems remains largely untapped: the world models are mostly
learned for world simulation and decoupled from trajectory planning. While
recent efforts aim to unify world modeling and planning in a single framework,
the synergistic facilitation mechanism of world modeling for planning still
requires further exploration. In this work, we introduce a new driving paradigm
named Policy World Model (PWM), which not only integrates world modeling and
trajectory planning within a unified architecture, but is also able to benefit
planning using the learned world knowledge through the proposed action-free
future state forecasting scheme. Through collaborative state-action prediction,
PWM can mimic the human-like anticipatory perception, yielding more reliable
planning performance. To facilitate the efficiency of video forecasting, we
further introduce a dynamically enhanced parallel token generation mechanism,
equipped with a context-guided tokenizer and an adaptive dynamic focal loss.
Despite utilizing only front camera input, our method matches or exceeds
state-of-the-art approaches that rely on multi-view and multi-modal inputs.
Code and model weights will be released at
https://github.com/6550Zhao/Policy-World-Model.

</details>


### [34] [DaMo: Data Mixing Optimizer in Fine-tuning Multimodal LLMs for Mobile Phone Agents](https://arxiv.org/abs/2510.19336)
*Kai Shi,Jun Yang,Ni Yang,Binqiang Pan,Qingsong Xie,Chao Zhang,Zhenyu Yang,Tianhuang Su,Haonan Lu*

Main category: cs.CV

TL;DR: DaMo是一个新提出的数据混合优化器，通过预测不同数据比例下的下游任务性能来确定最佳训练数据构成，以提高多模态大语言模型（MLLM）在处理多任务手机代理（MPA）时的效率。同时，论文还介绍了PhoneAgentBench，首个用于评估MLLM在多模态手机任务上表现的基准。DaMo在PhoneAgentBench及其他多个基准测试中均展现出优越的性能和泛化能力，并且能够扩展到其他模型架构。


<details>
  <summary>Details</summary>
Motivation: 现有的多任务监督微调（SFT）方法在确定多模态大语言模型（MLLM）用于手机代理（MPA）任务的最佳训练数据构成方面存在不足。

Method: 提出了一种名为DaMo（Data Mixture Optimizer）的新方法，该方法使用一个可训练的网络来预测给定数据集比例下的下游任务性能，从而确定最优的数据混合比例。此外，还引入了PhoneAgentBench，一个包含1235个问答对的基准，用于评估MLLM在多模态手机任务上的表现。

Result: DaMo在小规模实验中展现了强大的预测能力（R^2=0.81），并能有效推断最优数据混合配置。在PhoneAgentBench基准测试中，DaMo相比其他方法提升了3.38%的性能。在BFCL-v3、MME-Reasoning、MME-Perception和OCRBench等多个基准测试中，DaMo的平均得分也比其他方法高出2.57%。单独用于BFCL-v3任务的MLLM优化时，DaMo的性能提升了12.47%。DaMo还表现出良好的可扩展性，适用于其他模型架构。

Conclusion: DaMo作为一种数据混合优化器，能够有效提升MLLM在多模态手机任务上的表现，并在多个基准测试中展现出优越的性能和泛化能力。PhoneAgentBench为评估该领域的研究提供了有价值的工具。

Abstract: Mobile Phone Agents (MPAs) have emerged as a promising research direction due
to their broad applicability across diverse scenarios. While Multimodal Large
Language Models (MLLMs) serve as the foundation for MPAs, their effectiveness
in handling multiple mobile phone tasks simultaneously remains limited.
Although multitask supervised fine-tuning (SFT) is widely adopted for multitask
learning, existing approaches struggle to determine optimal training data
compositions for peak performance. To address this challenge, we propose DaMo
(Data Mixture Optimizer) - a novel solution employing a trainable network that
predicts optimal data mixtures by forecasting downstream task performance for
any given dataset ratio. To support comprehensive evaluation, we introduce
PhoneAgentBench, the first specialized benchmark to evaluate MLLMs on
multimodal mobile phone tasks, comprising 1235 QA pairs spanning diverse
real-world industrial mobile application scenarios. Demonstrating strong
predictive capability (R^2=0.81) in small-scale pilot experiments, DaMo
efficiently extrapolates optimal data mixing configurations. Our results show
DaMo achieves a 3.38% performance improvement on PhoneAgentBench compared to
alternative methods. Furthermore, extensive experiments across established
benchmarks including BFCL-v3, MME-Reasoning, MME-Perception, and OCRBench
reveal DaMo's superior generalization, outperforming other approaches by 2.57%
in terms of average score. When used solely for MLLM optimization on the
BFCL-v3 task, DaMo improves the metrics by 12.47% than other methods. Notably,
DaMo maintains robust scalability, preserving its effectiveness when applied to
other model architectures. The code and dataset are available at
https://github.com/OPPO-Mente-Lab/DaMo.git

</details>


### [35] [AegisRF: Adversarial Perturbations Guided with Sensitivity for Protecting Intellectual Property of Neural Radiance Fields](https://arxiv.org/abs/2510.19371)
*Woo Jae Kim,Kyu Beom Han,Yoonki Cho,Youngju Na,Junsik Jung,Sooel Son,Sung-eui Yoon*

Main category: cs.CV

TL;DR: 提出了一种名为AegisRF的新框架，通过注入对抗性扰动来保护神经辐射场（NeRF）的知识产权，同时保持渲染质量。


<details>
  <summary>Details</summary>
Motivation: 由于神经辐射场（NeRF）在3D场景表示和新视图合成方面的强大功能，保护其知识产权免受未经授权使用的需求日益增长。

Method: AegisRF框架包含一个扰动场，用于向NeRF模型的预渲染输出（颜色和体积密度）注入对抗性扰动，以欺骗未经授权的下游目标模型；以及一个敏感性场，用于学习敏感性以自适应地约束几何扰动，从而在破坏未经授权使用的同时保持渲染质量。

Result: 实验评估表明，AegisRF在各种下游任务和模态（包括多视图图像分类和基于体素的3D定位）中具有通用的适用性，同时保持了高视觉保真度。

Conclusion: AegisRF框架能够有效地保护NeRF的知识产权，同时在各种下游应用中保持高渲染质量和视觉保真度。

Abstract: As Neural Radiance Fields (NeRFs) have emerged as a powerful tool for 3D
scene representation and novel view synthesis, protecting their intellectual
property (IP) from unauthorized use is becoming increasingly crucial. In this
work, we aim to protect the IP of NeRFs by injecting adversarial perturbations
that disrupt their unauthorized applications. However, perturbing the 3D
geometry of NeRFs can easily deform the underlying scene structure and thus
substantially degrade the rendering quality, which has led existing attempts to
avoid geometric perturbations or restrict them to explicit spaces like meshes.
To overcome this limitation, we introduce a learnable sensitivity to quantify
the spatially varying impact of geometric perturbations on rendering quality.
Building upon this, we propose AegisRF, a novel framework that consists of a
Perturbation Field, which injects adversarial perturbations into the
pre-rendering outputs (color and volume density) of NeRF models to fool an
unauthorized downstream target model, and a Sensitivity Field, which learns the
sensitivity to adaptively constrain geometric perturbations, preserving
rendering quality while disrupting unauthorized use. Our experimental
evaluations demonstrate the generalized applicability of AegisRF across diverse
downstream tasks and modalities, including multi-view image classification and
voxel-based 3D localization, while maintaining high visual fidelity. Codes are
available at https://github.com/wkim97/AegisRF.

</details>


### [36] [Seeing Across Views: Benchmarking Spatial Reasoning of Vision-Language Models in Robotic Scenes](https://arxiv.org/abs/2510.19400)
*Zhiyuan Feng,Zhaolu Kang,Qijie Wang,Zhiying Du,Jiongrui Yan,Shubin Shi,Chengbo Yuan,Huizhi Liang,Yu Deng,Qixiu Li,Rushuai Yang,Arctanx An,Leqi Zheng,Weijie Wang,Shawn Chen,Sicheng Xu,Yaobo Liang,Jiaolong Yang,Baining Guo*

Main category: cs.CV

TL;DR: 该研究提出了一个名为MV-RoboBench的新基准，用于评估视觉-语言模型（VLMs）在机器人操作中的多视角空间推理能力。现有模型在多视角机器人感知方面与人类表现差距甚远。研究还发现，多视角下的空间智能与机器人任务执行能力呈正相关，并且在通用单视角基准上的良好表现并不一定能转化为在机器人空间任务上的成功。该基准旨在推动空间基础VLMs和VLA模型的发展。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型（VLMs）在机器人领域的评估大多基于单视角，未能充分探索其整合多视角信息的能力，而多摄像头设置在机器人平台中日益普及，能提供互补视角以减少遮挡和深度歧义。因此，评估VLMs能否有效利用多视角输入进行机器人推理至关重要。

Method: 提出了MV-RoboBench基准，包含1.7k个手动整理的问答项，涵盖八个子任务，分为空间理解和机器人执行两大类。评估了包括开源和闭源模型在内的多种VLMs，并引入了结合思维链（CoT）技术的增强版本。

Result: 实验结果表明，最先进的VLMs在多视角机器人感知方面的表现远低于人类水平。分析得出两个关键结论：（1）在多视角机器人场景中，空间智能与机器人任务执行能力呈正相关；（2）在现有的通用单视角空间理解基准上的优异表现，不能保证在MV-RoboBench评估的机器人空间任务上取得成功。

Conclusion: MV-RoboBench基准的提出填补了多视角机器人空间推理评估的空白，揭示了当前VLMs在处理多视角机器人感知任务时面临的重大挑战。研究结果强调了空间智能和任务执行之间的联系，并指出了通用基准评估与机器人特定任务能力之间的差异。该基准的开放发布将促进空间基础VLMs和VLAs的研究与发展。

Abstract: Vision-language models (VLMs) are essential to Embodied AI, enabling robots
to perceive, reason, and act in complex environments. They also serve as the
foundation for the recent Vision-Language-Action (VLA) models. Yet most
evaluations of VLMs focus on single-view settings, leaving their ability to
integrate multi-view information underexplored. At the same time, multi-camera
setups are increasingly standard in robotic platforms, as they provide
complementary perspectives to mitigate occlusion and depth ambiguity. Whether
VLMs can effectively leverage such multi-view inputs for robotic reasoning
therefore remains an open question. To bridge this gap, we introduce
MV-RoboBench, a benchmark specifically designed to evaluate the multi-view
spatial reasoning capabilities of VLMs in robotic manipulation. MV-RoboBench
consists of 1.7k manually curated QA items across eight subtasks, divided into
two primary categories: spatial understanding and robotic execution. We
evaluate a diverse set of existing VLMs, including both open-source and
closed-source models, along with enhanced versions incorporating CoT-inspired
techniques. The results show that state-of-the-art models remain far below
human performance, underscoring the substantial challenges VLMs face in
multi-view robotic perception. Additionally, our analysis uncovers two key
findings: (i) spatial intelligence and robotic task execution are positively
correlated in multi-view robotic scenarios; and (ii) strong performance on
existing general-purpose single-view spatial understanding benchmarks does not
reliably translate to success in the robotic spatial tasks assessed by our
benchmark. We release MV-RoboBench as an open resource to foster progress in
spatially grounded VLMs and VLAs, providing not only data but also a
standardized evaluation protocol for multi-view embodied reasoning.

</details>


### [37] [Multi-Camera Worker Tracking in Logistics Warehouse Considering Wide-Angle Distortion](https://arxiv.org/abs/2510.19432)
*Yuki Mori,Kazuma Kano,Yusuke Asai,Shin Katayama,Kenta Urano,Takuro Yonezawa,Nobuo Kawaguchi*

Main category: cs.CV

TL;DR: 本文提出了一种利用19个广角摄像头跟踪仓库工作人员位置的方法，通过基于脚部位置的对齐来解决图像畸变问题，并将跟踪准确率提高了20%以上。


<details>
  <summary>Details</summary>
Motivation: 随着电子商务的普及，物流市场不断增长，因此提高仓库运营效率至关重要。数字孪生技术被认为是提高效率的有效途径，但这需要精确地收集仓库内工作人员的位置信息并将其反映到虚拟空间中。然而，单个摄像头的视野有限，需要使用多个摄像头进行感知。

Method: 本文利用安装在天花板上的19个广角摄像头，俯视仓库地板，跟踪工作人员的位置。为了解决广角摄像头边缘的图像畸变问题，特别是垂直方向的畸变，作者提出了一种基于脚部位置进行对齐的方法，以减少图像畸变的影响，实现跨摄像头精确的位置对齐。

Result: 通过实验验证，所提出的方法将跟踪准确率提高了20%以上。此外，还比较了多种利用外观特征的方法，并验证了所提出方法的有效性。

Conclusion: 本文提出的基于脚部位置对齐的方法能够有效解决广角摄像头图像畸变问题，实现高精度的工作人员位置跟踪，为数字孪生技术在仓库运营中的应用提供了支持。

Abstract: With the spread of e-commerce, the logistics market is growing around the
world. Therefore, improving the efficiency of warehouse operations is
essential. To achieve this, various approaches have been explored, and among
them, the use of digital twins is gaining attention. To make this approach
possible, it is necessary to accurately collect the positions of workers in a
warehouse and reflect them in a virtual space. However, a single camera has
limitations in its field of view, therefore sensing with multiple cameras is
necessary. In this study, we explored a method to track workers using 19
wide-angle cameras installed on the ceiling, looking down at the floor of the
logistics warehouse. To understand the relationship between the camera
coordinates and the actual positions in the warehouse, we performed alignment
based on the floor surface. However, due to the characteristics of wide-angle
cameras, significant distortion occurs at the edges of the image, particularly
in the vertical direction. To address this, the detected worker positions from
each camera were aligned based on foot positions, reducing the effects of image
distortion, and enabling accurate position alignment across cameras. As a
result, we confirmed an improvement of over 20% in tracking accuracy.
Furthermore, we compared multiple methods for utilizing appearance features and
validated the effectiveness of the proposed approach.

</details>


### [38] [Reasoning Like Experts: Leveraging Multimodal Large Language Models for Drawing-based Psychoanalysis](https://arxiv.org/abs/2510.19451)
*Xueqi Ma,Yanbei Jiang,Sarah Erfani,James Bailey,Weifeng Liu,Krista A. Ehinger,Jey Han Lau*

Main category: cs.CV

TL;DR: PICK是一个多步骤框架，利用多模态大语言模型（MLLMs）对房屋-树木-人（HTP）测试图进行心理分析，通过分层分析和知识注入，实现从单个图形到整体的理解，并生成心理评估。


<details>
  <summary>Details</summary>
Motivation: 现有的MLLMs在主观和情感细微的心理分析领域应用不足，本研究旨在探索MLLMs在心理分析（特别是HTP测试）中的应用。

Method: PICK框架首先将HTP测试图分解为多层级的子图形（单个图形、多图形、整体），然后针对每个层级提取视觉线索的心理和情感见解，并构建了一个包含HTP知识库和强化学习训练的特征提取模块，用于生成心理特征并与心理状态关联，最后整合多方面信息进行评估。

Result: 实验结果表明，PICK显著提升了MLLMs在心理分析方面的能力，并通过扩展到情绪理解任务验证了其通用性。

Conclusion: PICK框架成功地弥合了MLLMs与专家领域的差距，为通过视觉表达理解人类心理状态提供了一个结构化且可解释的框架。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated exceptional
performance across various objective multimodal perception tasks, yet their
application to subjective, emotionally nuanced domains, such as psychological
analysis, remains largely unexplored. In this paper, we introduce PICK, a
multi-step framework designed for Psychoanalytical Image Comprehension through
hierarchical analysis and Knowledge injection with MLLMs, specifically focusing
on the House-Tree-Person (HTP) Test, a widely used psychological assessment in
clinical practice. First, we decompose drawings containing multiple instances
into semantically meaningful sub-drawings, constructing a hierarchical
representation that captures spatial structure and content across three levels:
single-object level, multi-object level, and whole level. Next, we analyze
these sub-drawings at each level with a targeted focus, extracting
psychological or emotional insights from their visual cues. We also introduce
an HTP knowledge base and design a feature extraction module, trained with
reinforcement learning, to generate a psychological profile for single-object
level analysis. This profile captures both holistic stylistic features and
dynamic object-specific features (such as those of the house, tree, or person),
correlating them with psychological states. Finally, we integrate these
multi-faceted information to produce a well-informed assessment that aligns
with expert-level reasoning. Our approach bridges the gap between MLLMs and
specialized expert domains, offering a structured and interpretable framework
for understanding human mental states through visual expression. Experimental
results demonstrate that the proposed PICK significantly enhances the
capability of MLLMs in psychological analysis. It is further validated as a
general framework through extensions to emotion understanding tasks.

</details>


### [39] [Exploring "Many in Few" and "Few in Many" Properties in Long-Tailed, Highly-Imbalanced IC Defect Classification](https://arxiv.org/abs/2510.19463)
*Hao-Chiang Shao,Chun-Hao Chang,Yu-Hsien Lin,Chia-Wen Lin,Shao-Yun Fang,Yan-Hsiu Liu*

Main category: cs.CV

TL;DR: 该论文提出了一种名为ReCAME-Net的新方法，以应对真实世界集成电路（IC）缺陷分类中数据高度不平衡的挑战，并发布了一个新的IC缺陷数据集IC-Defect-14。


<details>
  <summary>Details</summary>
Motivation: 真实世界的IC缺陷分类面临数据分布高度倾斜、类内簇现象（大类内差异和高类间相似性）等严峻挑战，现有模型在这些条件下表现不佳。

Method: 提出了一种名为ReCAME-Net的多专家分类器框架，集成了区域通道注意力模块、度量学习损失、难例挖掘策略和知识蒸馏过程。

Result: ReCAME-Net在IC-Defect-14数据集上显著优于现有最先进的模型，并在通用公共数据集上保持了可比的性能。

Conclusion: ReCAME-Net能够有效解决真实世界IC缺陷分类中的数据不平衡和复杂性问题，并在提出的IC-Defect-14数据集上取得了优越的性能。

Abstract: Despite significant advancements in deep classification techniques and in-lab
automatic optical inspection models for long-tailed or highly imbalanced data,
applying these approaches to real-world IC defect classification tasks remains
challenging. This difficulty stems from two primary factors. First, real-world
conditions, such as the high yield-rate requirements in the IC industry, result
in data distributions that are far more skewed than those found in general
public imbalanced datasets. Consequently, classifiers designed for open
imbalanced datasets often fail to perform effectively in real-world scenarios.
Second, real-world samples exhibit a mix of class-specific attributes and
class-agnostic, domain-related features. This complexity adds significant
difficulty to the classification process, particularly for highly imbalanced
datasets. To address these challenges, this paper introduces the IC-Defect-14
dataset, a large, highly imbalanced IC defect image dataset sourced from AOI
systems deployed in real-world IC production lines. This dataset is
characterized by its unique "intra-class clusters" property, which presents two
major challenges: large intra-class diversity and high inter-class similarity.
These characteristics, rarely found simultaneously in existing public datasets,
significantly degrade the performance of current state-of-the-art classifiers
for highly imbalanced data. To tackle this challenge, we propose ReCAME-Net,
which follows a multi-expert classifier framework and integrates a regional
channel attention module, metric learning losses, a hard category mining
strategy, and a knowledge distillation procedure. Extensive experimental
evaluations demonstrate that ReCAME-Net outperforms previous state-of-the-art
models on the IC-Defect-14 dataset while maintaining comparable performance and
competitiveness on general public datasets.

</details>


### [40] [PCP-GAN: Property-Constrained Pore-scale image reconstruction via conditional Generative Adversarial Networks](https://arxiv.org/abs/2510.19465)
*Ali Sadeghkhani,Brandon Bennett,Masoud Babaei,Arash Rabbani*

Main category: cs.CV

TL;DR: 使用多条件生成对抗网络(cGAN)生成具有可控孔隙度属性的多尺度图像，以解决地下特征描述中的代表性和数据稀疏性问题。


<details>
  <summary>Details</summary>
Motivation: 自然空间异质性导致提取的子图像与岩心测量值存在显著偏差，并且物理样本仅在稀疏的井位点可用，这些因素加剧了数据稀疏性带来的挑战。

Method: 提出了一种多条件生成对抗网络(cGAN)框架，该框架通过在单个统一模型中同时对孔隙度值和深度参数进行条件化来生成具有精确控制属性的代表性孔隙尺度图像。

Result: 所提出的cGAN模型在所有地层中实现了出色的孔隙度控制（R^2=0.95），平均绝对误差为0.0099-0.0197。生成的图像在形态上保留了关键的孔隙网络特征，并且与随机提取的真实子图像相比，代表性得到了显著提高（双约束误差为1.9-11.3%，而随机提取的真实子图像为36.4-578%）。

Conclusion: 该cGAN框架能够生成具有精确控制孔隙度属性的代表性孔隙尺度图像，解决了地下表征中的代表性和数据稀疏性挑战，为碳储存、地热能和地下水管理等应用提供了变革性的工具。

Abstract: Obtaining truly representative pore-scale images that match bulk formation
properties remains a fundamental challenge in subsurface characterization, as
natural spatial heterogeneity causes extracted sub-images to deviate
significantly from core-measured values. This challenge is compounded by data
scarcity, where physical samples are only available at sparse well locations.
This study presents a multi-conditional Generative Adversarial Network (cGAN)
framework that generates representative pore-scale images with precisely
controlled properties, addressing both the representativeness challenge and
data availability constraints. The framework was trained on thin section
samples from four depths (1879.50-1943.50 m) of a carbonate formation,
simultaneously conditioning on porosity values and depth parameters within a
single unified model. This approach captures both universal pore network
principles and depth-specific geological characteristics, from grainstone
fabrics with interparticle-intercrystalline porosity to crystalline textures
with anhydrite inclusions. The model achieved exceptional porosity control
(R^2=0.95) across all formations with mean absolute errors of 0.0099-0.0197.
Morphological validation confirmed preservation of critical pore network
characteristics including average pore radius, specific surface area, and
tortuosity, with statistical differences remaining within acceptable geological
tolerances. Most significantly, generated images demonstrated superior
representativeness with dual-constraint errors of 1.9-11.3% compared to
36.4-578% for randomly extracted real sub-images. This capability provides
transformative tools for subsurface characterization, particularly valuable for
carbon storage, geothermal energy, and groundwater management applications
where knowing the representative morphology of the pore space is critical for
implementing digital rock physics.

</details>


### [41] [Predicting before Reconstruction: A generative prior framework for MRI acceleration](https://arxiv.org/abs/2510.19472)
*Juhyung Park,Rokgi Hong,Roh-Eul Yoo,Jaehyeon Koo,Se Young Chun,Seung Hong Choi,Jongho Lee*

Main category: cs.CV

TL;DR: 本研究提出了一种利用生成模型预测MRI图像对比度，并以此作为数据驱动的先验信息来加速MRI扫描的新范式，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: MRI扫描时间长，限制了临床应用，本研究旨在通过预测性成像加速MRI扫描。

Method: 利用条件生成模型预测目标对比度图像，并将其作为先验信息，用于重建高度欠采样的MRI数据。

Result: 在多个数据集和高加速因子下，该预测-先验重建方法显著优于其他方法，包括具有替代或无先验信息的方法。

Conclusion: 本研究将MRI从图像重建的范式转变为预测性成像的新范式，为加速MRI提供了新途径。

Abstract: Recent advancements in artificial intelligence have created transformative
capabilities in image synthesis and generation, enabling diverse research
fields to innovate at revolutionary speed and spectrum. In this study, we
leverage this generative power to introduce a new paradigm for accelerating
Magnetic Resonance Imaging (MRI), introducing a shift from image reconstruction
to proactive predictive imaging. Despite being a cornerstone of modern patient
care, MRI's lengthy acquisition times limit clinical throughput. Our novel
framework addresses this challenge by first predicting a target contrast image,
which then serves as a data-driven prior for reconstructing highly
under-sampled data. This informative prior is predicted by a generative model
conditioned on diverse data sources, such as other contrast images, previously
scanned images, acquisition parameters, patient information. We demonstrate
this approach with two key applications: (1) reconstructing FLAIR images using
predictions from T1w and/or T2w scans, and (2) reconstructing T1w images using
predictions from previously acquired T1w scans. The framework was evaluated on
internal and multiple public datasets (total 14,921 scans; 1,051,904 slices),
including multi-channel k-space data, for a range of high acceleration factors
(x4, x8 and x12). The results demonstrate that our prediction-prior
reconstruction method significantly outperforms other approaches, including
those with alternative or no prior information. Through this framework we
introduce a fundamental shift from image reconstruction towards a new paradigm
of predictive imaging.

</details>


### [42] [PRGCN: A Graph Memory Network for Cross-Sequence Pattern Reuse in 3D Human Pose Estimation](https://arxiv.org/abs/2510.19475)
*Zhuoyang Xie,Yibo Zhao,Hui Huang,Riwei Wang,Zan Gao*

Main category: cs.CV

TL;DR: 该论文提出了一种名为PRGCN的新型框架，通过跨序列检索和重用姿势模式来解决单目3D人体姿态估计中的深度模糊问题，并在基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于视频的方法在处理每个序列时都将它们视为独立个体，忽略了不同序列之间普遍存在的人类运动的结构规律性和重复运动模式，而这些模式可以用来提高3D人体姿态估计的准确性。

Method: PRGCN框架将姿态估计视为模式检索和自适应问题。它使用图卷积网络（GCN）和一个由注意机制驱动的图记忆库来存储和检索姿势原型。这些原型随后与解剖学约束相结合，以确保几何合理性。此外，该框架还采用了一个双流混合架构，结合了基于Mamba的状态空间模型和自注意力机制，以提取时空特征。

Result: PRGCN在Human3.6M和MPI-INF-3DHP数据集上的表现优于现有方法，分别达到了37.1毫米和13.4毫米的MPJPE，并展示了更强的跨领域泛化能力。

Conclusion: 跨序列模式重用对于改进3D人体姿态估计至关重要，可以推动该领域从单独的序列优化转向累积的知识学习。

Abstract: Monocular 3D human pose estimation remains a fundamentally ill-posed inverse
problem due to the inherent depth ambiguity in 2D-to-3D lifting. While
contemporary video-based methods leverage temporal context to enhance spatial
reasoning, they operate under a critical paradigm limitation: processing each
sequence in isolation, thereby failing to exploit the strong structural
regularities and repetitive motion patterns that pervade human movement across
sequences. This work introduces the Pattern Reuse Graph Convolutional Network
(PRGCN), a novel framework that formalizes pose estimation as a problem of
pattern retrieval and adaptation. At its core, PRGCN features a graph memory
bank that learns and stores a compact set of pose prototypes, encoded as
relational graphs, which are dynamically retrieved via an attention mechanism
to provide structured priors. These priors are adaptively fused with hard-coded
anatomical constraints through a memory-driven graph convolution, ensuring
geometrical plausibility. To underpin this retrieval process with robust
spatiotemporal features, we design a dual-stream hybrid architecture that
synergistically combines the linear-complexity, local temporal modeling of
Mamba-based state-space models with the global relational capacity of
self-attention. Extensive evaluations on Human3.6M and MPI-INF-3DHP benchmarks
demonstrate that PRGCN establishes a new state-of-the-art, achieving an MPJPE
of 37.1mm and 13.4mm, respectively, while exhibiting enhanced cross-domain
generalization capability. Our work posits that the long-overlooked mechanism
of cross-sequence pattern reuse is pivotal to advancing the field, shifting the
paradigm from per-sequence optimization towards cumulative knowledge learning.

</details>


### [43] [Mitigating representation bias caused by missing pixels in methane plume detection](https://arxiv.org/abs/2510.19478)
*Julia Wąsala,Joannes D. Maasakkers,Ilse Aben,Rochelle Schneider,Holger Hoos,Mitra Baratchi*

Main category: cs.CV

TL;DR: 卫星图像中的缺失像素（非随机缺失）会导致特征提取模型的表示偏差，因为模型可能会将标签与缺失值的数量相关联。本研究评估了多种插补方法和加权重采样方案，以消除这种偏差，并证明这些方法可以提高模型在低覆盖率图像中检测羽流的能力。


<details>
  <summary>Details</summary>
Motivation: 大多数卫星图像由于云等因素存在系统性的缺失像素（非随机缺失），这可能导致自动化特征提取模型的表示偏差。具体而言，在甲烷羽流检测中，缺失值数量与标签之间的虚假关联可能导致模型将覆盖率（图像中有效像素的百分比）与标签相关联，从而在低覆盖率图像中低估羽流的检测率。

Method: 1. 评估了多种插补方法来消除覆盖率和标签之间的依赖关系。 2. 提出了一种在训练期间使用的加权重采样方案，通过在每个覆盖率 bin 中强制执行类别平衡来消除标签和覆盖率之间的关联。 3. 评估了这些去偏方法在操作场景中的能力。

Result: 与未经处理的模型相比，插补和重采样方法均能显著减少表示偏差，同时不损害平衡准确率、精确率或召回率。去偏后的模型在低覆盖率图像中检测羽流的成功率更高。

Conclusion: 通过使用插补和加权重采样等技术，可以有效地消除卫星图像中因缺失像素引起的表示偏差，从而提高模型在低覆盖率图像中的甲烷羽流检测能力，并在实际应用中表现出更高的检测概率。

Abstract: Most satellite images have systematically missing pixels (i.e., missing data
not at random (MNAR)) due to factors such as clouds. If not addressed, these
missing pixels can lead to representation bias in automated feature extraction
models. In this work, we show that spurious association between the label and
the number of missing values in methane plume detection can cause the model to
associate the coverage (i.e., the percentage of valid pixels in an image) with
the label, subsequently under-detecting plumes in low-coverage images. We
evaluate multiple imputation approaches to remove the dependence between the
coverage and a label. Additionally, we propose a weighted resampling scheme
during training that removes the association between the label and the coverage
by enforcing class balance in each coverage bin. Our results show that both
resampling and imputation can significantly reduce the representation bias
without hurting balanced accuracy, precision, or recall. Finally, we evaluate
the capability of the debiased models using these techniques in an operational
scenario and demonstrate that the debiased models have a higher chance of
detecting plumes in low-coverage images.

</details>


### [44] [Towards Single-Source Domain Generalized Object Detection via Causal Visual Prompts](https://arxiv.org/abs/2510.19487)
*Chen Li,Huiying Xu,Changxin Gao,Zeyu Wang,Yun Liu,Xinzhong Zhu*

Main category: cs.CV

TL;DR: 该研究提出Cauvis方法以解决单源域通用目标检测中的域差异和模型过度依赖无关特征的问题，通过跨注意力提示和双分支适配器解耦因果-无关特征，实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前主流的单源域通用目标检测方法通过数据增强来缓解域差异，但模型容易陷入虚假相关性，过度依赖颜色等无关特征，而不是像物体轮廓这样的域不变表示。

Method: 提出Cauvis（因果视觉提示）方法。首先，引入跨注意力提示模块，通过将视觉提示与交叉注意力相结合来减轻虚假特征带来的偏差。其次，为解决单域泛化中视觉提示的域知识覆盖不足和虚假特征纠缠问题，提出一个双分支适配器，通过高频特征提取来实现域适应，同时解耦因果-无关特征。

Result: Cauvis在SDGOD数据集上相比现有域泛化方法取得了15.9-31.4%的性能提升，达到了SOTA水平，并且在复杂的干扰环境中表现出显著的鲁棒性优势。

Conclusion: Cauvis方法通过引入因果视觉提示，有效解决了单源域通用目标检测中的域差异和虚假相关性问题，显著提升了模型的泛化能力和鲁棒性。

Abstract: Single-source Domain Generalized Object Detection (SDGOD), as a cutting-edge
research topic in computer vision, aims to enhance model generalization
capability in unseen target domains through single-source domain training.
Current mainstream approaches attempt to mitigate domain discrepancies via data
augmentation techniques. However, due to domain shift and limited
domain-specific knowledge, models tend to fall into the pitfall of spurious
correlations. This manifests as the model's over-reliance on simplistic
classification features (e.g., color) rather than essential domain-invariant
representations like object contours. To address this critical challenge, we
propose the Cauvis (Causal Visual Prompts) method. First, we introduce a
Cross-Attention Prompts module that mitigates bias from spurious features by
integrating visual prompts with cross-attention. To address the inadequate
domain knowledge coverage and spurious feature entanglement in visual prompts
for single-domain generalization, we propose a dual-branch adapter that
disentangles causal-spurious features while achieving domain adaptation via
high-frequency feature extraction. Cauvis achieves state-of-the-art performance
with 15.9-31.4% gains over existing domain generalization methods on SDGOD
datasets, while exhibiting significant robustness advantages in complex
interference environments.

</details>


### [45] [CARES: Context-Aware Resolution Selector for VLMs](https://arxiv.org/abs/2510.19496)
*Moshe Kimhi,Nimrod Shabtay,Raja Giryes,Chaim Baskin,Eli Schwartz*

Main category: cs.CV

TL;DR: CARES是一个能够预测满足任务需求的最小输入分辨率的轻量级预处理模块，可以在不影响性能的情况下，最多将视觉模型（VLM）的计算量减少80%。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（VLMs）在处理图像时通常使用原生或高分辨率，这导致视觉标记占总标记的97-99%，即使在低分辨率图像足够的情况下也会增加计算量和延迟。

Method: CARES模块使用一个小型VLM（350M）提取特征，并预测目标VLM的响应何时能收敛到其正确回答能力的峰值。CARES被训练为在可选分辨率上进行离散分类，但在推理时可以对连续分辨率进行插值以实现细粒度控制。

Result: 在五个跨越文档和自然图像的多模态基准测试以及多种目标VLM上，CARES在将计算量减少高达80%的同时，保持了任务性能。

Conclusion: CARES是一个有效的解决方案，可以降低大型VLM的计算成本和延迟，同时保持其性能。

Abstract: Large vision-language models (VLMs) commonly process images at native or high
resolution to remain effective across tasks. This inflates visual tokens ofter
to 97-99% of total tokens, resulting in high compute and latency, even when
low-resolution images would suffice. We introduce \emph{CARES}-a
\textbf{C}ontext-\textbf{A}ware \textbf{R}esolution \textbf{S}elector, a
lightweight preprocessing module that, given an image-query pair, predicts the
\emph{minimal} sufficient input resolution. CARES uses a compact VLM (350M) to
extract features and predict when a target pretrained VLM's response converges
to its peak ability to answer correctly. Though trained as a discrete
classifier over a set of optional resolutions, CARES interpolates continuous
resolutions at inference for fine-grained control. Across five multimodal
benchmarks spanning documents and natural images, as well as diverse target
VLMs, CARES preserves task performance while reducing compute by up to 80%.

</details>


### [46] [PoseCrafter: Extreme Pose Estimation with Hybrid Video Synthesis](https://arxiv.org/abs/2510.19527)
*Qing Mao,Tianxin Huang,Yu Zhu,Jinqiu Sun,Yanning Zhang,Gim Hee Lee*

Main category: cs.CV

TL;DR: HVG和FMS用于解决图像重叠度低时的相机姿态估计问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理图像对重叠度小或无重叠时存在困难，生成的中间帧模糊，关键帧选择策略效率低下且与姿态估计不对齐。

Method: 提出了一种混合视频生成（HVG）方法，结合了视频插值模型和姿态条件新视角合成模型，以生成更清晰的中间帧。同时，提出了一种基于特征匹配选择器（FMS）的特征匹配方法，用于从合成结果中选择适合姿态估计的中间帧。

Result: 在Cambridge Landmarks、ScanNet、DL3DV-10K和NAVI数据集上进行了广泛的实验，结果表明PoseCrafter在相机姿态估计性能方面，尤其是在处理重叠度小或无重叠的样本时，相比现有的SOTA方法有明显的提升。

Conclusion: HVG和FMS的结合能够有效解决图像重叠度低时的相机姿态估计挑战，并在多个数据集上验证了其优越性。

Abstract: Pairwise camera pose estimation from sparsely overlapping image pairs remains
a critical and unsolved challenge in 3D vision. Most existing methods struggle
with image pairs that have small or no overlap. Recent approaches attempt to
address this by synthesizing intermediate frames using video interpolation and
selecting key frames via a self-consistency score. However, the generated
frames are often blurry due to small overlap inputs, and the selection
strategies are slow and not explicitly aligned with pose estimation. To solve
these cases, we propose Hybrid Video Generation (HVG) to synthesize clearer
intermediate frames by coupling a video interpolation model with a
pose-conditioned novel view synthesis model, where we also propose a Feature
Matching Selector (FMS) based on feature correspondence to select intermediate
frames appropriate for pose estimation from the synthesized results. Extensive
experiments on Cambridge Landmarks, ScanNet, DL3DV-10K, and NAVI demonstrate
that, compared to existing SOTA methods, PoseCrafter can obviously enhance the
pose estimation performances, especially on examples with small or no overlap.

</details>


### [47] [[De|Re]constructing VLMs' Reasoning in Counting](https://arxiv.org/abs/2510.19555)
*Simone Alghisi,Gabriel Roccabruna,Massimo Rizzoli,Seyed Mahed Mousavi,Giuseppe Riccardi*

Main category: cs.CV

TL;DR: 当前的视觉-语言模型（VLM）在遵循用户指令方面表现出色，但在视觉推理方面仍存在局限性，尤其是在关系识别、时间序列理解和物体计数方面。本研究通过实验探究了七种最先进的VLM在计数任务中的推理能力，发现它们对物体数量、类型、空间布局和干扰物的存在非常敏感。通过层级分析，我们发现错误源于最后一层表示到输出空间的映射不正确。通过仅微调输出层，我们的方法可以将准确率提高多达21%，并在实际数据集上取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉-语言模型（VLM）在遵循用户指令方面表现出色，但在识别关系、理解时间序列和计数物体等视觉推理方面存在局限性。本研究旨在深入探究VLM在这些方面的失败原因，并提出改进其推理能力的方法。

Method: 我们研究了七种最先进的VLM在计数任务下的推理能力，进行了层级分析，并尝试通过仅微调输出层来改进其性能。

Result: 实验表明，VLM对物体数量、类型、空间布局和干扰物的存在非常敏感。层级分析发现，错误源于最后一层表示到输出空间的映射不正确。仅微调输出层可将准确率提高多达21%，并在实际数据集上取得了改进。

Conclusion: 通过仅微调VLM的输出层，可以显著提高其在计数任务上的准确率，解决了表示到输出空间映射不正确的问题，并能推广到实际应用中。

Abstract: Vision-Language Models (VLMs) have recently gained attention due to their
competitive performance on multiple downstream tasks, achieved by following
user-input instructions. However, VLMs still exhibit several limitations in
visual reasoning, such as difficulties in identifying relations (e.g., spatial,
temporal, and among objects), understanding temporal sequences (e.g., frames),
and counting objects. In this work, we go beyond score-level benchmark
evaluations of VLMs by investigating the underlying causes of their failures
and proposing a targeted approach to improve their reasoning capabilities. We
study the reasoning skills of seven state-of-the-art VLMs in the counting task
under controlled experimental conditions. Our experiments show that VLMs are
highly sensitive to the number and type of objects, their spatial arrangement,
and the co-occurrence of distractors. A layer-wise analysis reveals that errors
are due to incorrect mapping of the last-layer representation into the output
space. Our targeted training shows that fine-tuning just the output layer
improves accuracy by up to 21%. We corroborate these findings by achieving
consistent improvements on real-world datasets.

</details>


### [48] [The Intricate Dance of Prompt Complexity, Quality, Diversity, and Consistency in T2I Models](https://arxiv.org/abs/2510.19557)
*Xiaofeng Zhang,Aaron Courville,Michal Drozdzal,Adriana Romero-Soriano*

Main category: cs.CV

TL;DR: 提示词复杂度影响文本到图像生成数据的质量、多样性和一致性，提示词扩展可提升生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像（T2I）模型在生成合成数据方面潜力巨大，但提示词复杂度对其生成数据效用的系统性影响研究不足。

Method: 首先通过合成实验和理论推导来研究提示词复杂度与泛化能力之间的关系。然后，提出一个新的评估框架来比较真实数据和合成数据的效用，并分析提示词复杂度对常用T2I模型生成数据的效用影响，同时评估不同的推理时干预方法。

Result: 合成实验表明，泛化到更普遍的条件比反之更难。大规模实证研究发现，增加提示词复杂度会降低条件多样性和提示词一致性，但会减少合成与真实数据分布之间的偏移。当前的推理时干预方法可以在增加生成多样性的同时，增加与真实数据分布的偏移。其中，提示词扩展方法在图像多样性和美学方面表现最佳，甚至优于真实数据。

Conclusion: 提示词复杂度是影响T2I模型生成数据效用的关键因素。提示词扩展是一种有效的干预方法，能够显著提升生成数据的质量和多样性。

Abstract: Text-to-image (T2I) models offer great potential for creating virtually
limitless synthetic data, a valuable resource compared to fixed and finite real
datasets. Previous works evaluate the utility of synthetic data from T2I models
on three key desiderata: quality, diversity, and consistency. While prompt
engineering is the primary means of interacting with T2I models, the systematic
impact of prompt complexity on these critical utility axes remains
underexplored. In this paper, we first conduct synthetic experiments to
motivate the difficulty of generalization w.r.t. prompt complexity and explain
the observed difficulty with theoretical derivations. Then, we introduce a new
evaluation framework that can compare the utility of real data and synthetic
data, and present a comprehensive analysis of how prompt complexity influences
the utility of synthetic data generated by commonly used T2I models. We conduct
our study across diverse datasets, including CC12M, ImageNet-1k, and DCI, and
evaluate different inference-time intervention methods. Our synthetic
experiments show that generalizing to more general conditions is harder than
the other way round, since the former needs an estimated likelihood that is not
learned by diffusion models. Our large-scale empirical experiments reveal that
increasing prompt complexity results in lower conditional diversity and prompt
consistency, while reducing the synthetic-to-real distribution shift, which
aligns with the synthetic experiments. Moreover, current inference-time
interventions can augment the diversity of the generations at the expense of
moving outside the support of real data. Among those interventions, prompt
expansion, by deliberately using a pre-trained language model as a likelihood
estimator, consistently achieves the highest performance in both image
diversity and aesthetics, even higher than that of real data.

</details>


### [49] [A Matter of Time: Revealing the Structure of Time in Vision-Language Models](https://arxiv.org/abs/2510.19559)
*Nidham Tekaya,Manuela Waldner,Matthias Zeppelzauer*

Main category: cs.CV

TL;DR: 该论文研究了视觉语言模型（VLM）在时间感知方面的能力，并提出了一种新的数据集（TIME10k）和方法来评估和增强这种能力。


<details>
  <summary>Details</summary>
Motivation: 评估和理解大型视觉语言模型（VLM）在时间感知方面的能力，并探索如何利用其学习到的表征来推断视觉内容的时间信息。

Method: 构建了一个包含10,000多张带时间标签的图像的数据集（TIME10k），并提出了一种新的评估方法来测试37种不同VLM的时间感知能力。在此基础上，研究人员发现VLM的嵌入空间中存在一个低维非线性流形，其中蕴含着时间信息。最后，他们提出了一种从嵌入空间提取“时间线”表征的方法，以增强VLM的时间推理能力。

Result: 研究发现VLM的嵌入空间中存在一个低维非线性流形，其中蕴含着时间信息。基于此，提出的“时间线”表征方法在时间推理任务上达到了与基于提示（prompt-based）的基线方法相当甚至更优的准确率，并且计算效率更高。

Conclusion: 大型视觉语言模型（VLM）具备内在的时间感知能力，这种能力可以被提取和增强。通过TIME10k数据集和提出的“时间线”表征方法，可以有效地提升VLM在时间推理任务上的表现。

Abstract: Large-scale vision-language models (VLMs) such as CLIP have gained popularity
for their generalizable and expressive multimodal representations. By
leveraging large-scale training data with diverse textual metadata, VLMs
acquire open-vocabulary capabilities, solving tasks beyond their training
scope. This paper investigates the temporal awareness of VLMs, assessing their
ability to position visual content in time. We introduce TIME10k, a benchmark
dataset of over 10,000 images with temporal ground truth, and evaluate the
time-awareness of 37 VLMs by a novel methodology. Our investigation reveals
that temporal information is structured along a low-dimensional, non-linear
manifold in the VLM embedding space. Based on this insight, we propose methods
to derive an explicit ``timeline'' representation from the embedding space.
These representations model time and its chronological progression and thereby
facilitate temporal reasoning tasks. Our timeline approaches achieve
competitive to superior accuracy compared to a prompt-based baseline while
being computationally efficient. All code and data are available at
https://tekayanidham.github.io/timeline-page/.

</details>


### [50] [HAD: Hierarchical Asymmetric Distillation to Bridge Spatio-Temporal Gaps in Event-Based Object Tracking](https://arxiv.org/abs/2510.19560)
*Yao Deng,Xian Zhong,Wenxuan Liu,Zhaofei Yu,Jingling Yuan,Tiejun Huang*

Main category: cs.CV

TL;DR: RGB相机和事件相机在纹理和时间分辨率/动态范围方面具有互补性，但存在时空不对称性。本研究提出了一种名为HAD（分层不对称蒸馏）的多模态知识蒸馏框架，以解决这种不对称性，并在物体跟踪方面取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: RGB相机和事件相机在捕捉细节和处理动态范围/时间分辨率方面具有互补性，但由于成像机制不同，存在时空不对称性，阻碍了有效的多模态集成。目标是克服这一挑战，以提高物体跟踪的性能。

Method: 提出了一种名为 HAD（分层不对称蒸馏）的多模态知识蒸馏框架，该框架通过分层对齐策略来显式建模和缓解时空不对称性，同时保持学生网络的计算效率和参数紧凑性。

Result: 实验证明，HAD 在物体跟踪方面始终优于最先进的方法，并且消融研究验证了其组件的有效性和必要性。

Conclusion: 所提出的 HAD 框架能够有效地缓解 RGB 相机和事件相机之间的时空不对称性，并在物体跟踪任务中取得卓越的性能。

Abstract: RGB cameras excel at capturing rich texture details with high spatial
resolution, whereas event cameras offer exceptional temporal resolution and a
high dynamic range (HDR). Leveraging their complementary strengths can
substantially enhance object tracking under challenging conditions, such as
high-speed motion, HDR environments, and dynamic background interference.
However, a significant spatio-temporal asymmetry exists between these two
modalities due to their fundamentally different imaging mechanisms, hindering
effective multi-modal integration. To address this issue, we propose
{Hierarchical Asymmetric Distillation} (HAD), a multi-modal knowledge
distillation framework that explicitly models and mitigates spatio-temporal
asymmetries. Specifically, HAD proposes a hierarchical alignment strategy that
minimizes information loss while maintaining the student network's
computational efficiency and parameter compactness. Extensive experiments
demonstrate that HAD consistently outperforms state-of-the-art methods, and
comprehensive ablation studies further validate the effectiveness and necessity
of each designed component. The code will be released soon.

</details>


### [51] [Can You Trust What You See? Alpha Channel No-Box Attacks on Video Object Detection](https://arxiv.org/abs/2510.19574)
*Ariana Yi,Ce Zhou,Liyang Xiao,Qiben Yan*

Main category: cs.CV

TL;DR: 提出了一种名为“α-Cloak”的视频域无模型对抗性攻击方法，利用RGBA视频的alpha通道，在不被人类察觉的情况下欺骗目标检测器。


<details>
  <summary>Details</summary>
Motivation: 由于目标检测模型越来越多地应用于自动驾驶汽车和监控系统等网络物理系统，因此必须确保其在对抗性攻击下的安全性。以往的研究主要集中在图像域的对抗性攻击，而视频域的攻击，特别是在无模型设置下，却鲜有研究。

Method: 利用RGBA视频的alpha通道将恶意目标视频与良性视频融合，生成视觉上无法区分但能欺骗目标检测器的融合视频。该攻击无需访问模型架构、参数或输出，且不会引入可感知的伪影。研究了常见视频格式和播放应用程序对alpha通道的支持，并设计了一种确保视觉隐蔽性和兼容性的融合算法。

Result: 在五个最先进的目标检测器、一个视觉-语言模型和一个多模态大语言模型（Gemini-2.0-Flash）上评估了α-Cloak，在所有场景下均实现了100%的攻击成功率。

Conclusion: 发现了一个先前未被探索的、基于视频的感知系统的漏洞，凸显了在对抗性设置中考虑alpha通道进行防御的紧迫性。

Abstract: As object detection models are increasingly deployed in cyber-physical
systems such as autonomous vehicles (AVs) and surveillance platforms, ensuring
their security against adversarial threats is essential. While prior work has
explored adversarial attacks in the image domain, those attacks in the video
domain remain largely unexamined, especially in the no-box setting. In this
paper, we present {\alpha}-Cloak, the first no-box adversarial attack on object
detectors that operates entirely through the alpha channel of RGBA videos.
{\alpha}-Cloak exploits the alpha channel to fuse a malicious target video with
a benign video, resulting in a fused video that appears innocuous to human
viewers but consistently fools object detectors. Our attack requires no access
to model architecture, parameters, or outputs, and introduces no perceptible
artifacts. We systematically study the support for alpha channels across common
video formats and playback applications, and design a fusion algorithm that
ensures visual stealth and compatibility. We evaluate {\alpha}-Cloak on five
state-of-the-art object detectors, a vision-language model, and a multi-modal
large language model (Gemini-2.0-Flash), demonstrating a 100% attack success
rate across all scenarios. Our findings reveal a previously unexplored
vulnerability in video-based perception systems, highlighting the urgent need
for defenses that account for the alpha channel in adversarial settings.

</details>


### [52] [VGD: Visual Geometry Gaussian Splatting for Feed-Forward Surround-view Driving Reconstruction](https://arxiv.org/abs/2510.19578)
*Junhong Lin,Kangli Wang,Shunzhou Wang,Songlin Fan,Ge Li,Wei Gao*

Main category: cs.CV

TL;DR: VGD是一个新的前馈端到端学习框架，用于解决前馈环绕驾驶场景重建中新视角质量和泛化性的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法在确保新视角的几何一致性和重建质量方面存在不足，尤其是在重叠区域较少的情况下。

Method: VGD通过蒸馏VGGT的几何先验到一个轻量级几何分支，并设计了一个高斯头来融合多尺度几何信息以预测高斯参数。此外，还集成了来自几何和高斯头分支的多尺度特征来监督语义细化模型。

Result: 实验表明，VGD在nuScenes数据集上显著优于现有最先进的方法，在客观指标和主观质量方面均表现出色，证明了其可扩展性和高保真度。

Conclusion: VGD能够有效地解决环绕驾驶场景重建中的新视角质量和泛化性问题。

Abstract: Feed-forward surround-view autonomous driving scene reconstruction offers
fast, generalizable inference ability, which faces the core challenge of
ensuring generalization while elevating novel view quality. Due to the
surround-view with minimal overlap regions, existing methods typically fail to
ensure geometric consistency and reconstruction quality for novel views. To
tackle this tension, we claim that geometric information must be learned
explicitly, and the resulting features should be leveraged to guide the
elevating of semantic quality in novel views. In this paper, we introduce
\textbf{Visual Gaussian Driving (VGD)}, a novel feed-forward end-to-end
learning framework designed to address this challenge. To achieve generalizable
geometric estimation, we design a lightweight variant of the VGGT architecture
to efficiently distill its geometric priors from the pre-trained VGGT to the
geometry branch. Furthermore, we design a Gaussian Head that fuses multi-scale
geometry tokens to predict Gaussian parameters for novel view rendering, which
shares the same patch backbone as the geometry branch. Finally, we integrate
multi-scale features from both geometry and Gaussian head branches to jointly
supervise a semantic refinement model, optimizing rendering quality through
feature-consistent learning. Experiments on nuScenes demonstrate that our
approach significantly outperforms state-of-the-art methods in both objective
metrics and subjective quality under various settings, which validates VGD's
scalability and high-fidelity surround-view reconstruction.

</details>


### [53] [Multi-modal Co-learning for Earth Observation: Enhancing single-modality models via modality collaboration](https://arxiv.org/abs/2510.19579)
*Francisco Mena,Dino Ienco,Cassio F. Dantas,Roberto Interdonato,Andreas Dengel*

Main category: cs.CV

TL;DR: 通过结合对比学习和模态判别学习，提出了一种新颖的多模态协同学习框架，用于地球观测（EO）数据，该框架可以在训练阶段利用多种传感器数据，并在推理阶段仅使用单一传感器数据来提高预测精度，并且能够泛化到不同的任务和传感器。


<details>
  <summary>Details</summary>
Motivation: 在地球观测（EO）领域，由于现实世界中传感器平台限制，训练和推理阶段可用的传感器模态通常不一致。多模态协同学习可以利用训练阶段丰富的多模态数据来提升推理阶段单一模态模型的性能，但现有方法大多是针对特定任务或推理阶段可用模态定制的。

Method: 提出了一种新颖的多模态协同学习框架，该框架结合了对比学习和模态判别学习，以指导单模态模型将内部模型流形构建为模态共享和模态特定信息，从而实现跨任务和跨模态的泛化。

Result: 在四个涵盖分类和回归任务的EO基准上进行了评估，其中推理阶段只有一个模态可用于训练。结果表明，与现有的机器学习、计算机视觉以及EO特定方法相比，该框架在单模态推理场景下取得了持续的预测改进。

Conclusion: 所提出的多模态协同学习框架在单模态推理场景下，在各种EO应用中都展现了有效的预测能力和泛化性。

Abstract: Multi-modal co-learning is emerging as an effective paradigm in machine
learning, enabling models to collaboratively learn from different modalities to
enhance single-modality predictions. Earth Observation (EO) represents a
quintessential domain for multi-modal data analysis, wherein diverse remote
sensors collect data to sense our planet. This unprecedented volume of data
introduces novel challenges. Specifically, the access to the same sensor
modalities at both training and inference stages becomes increasingly complex
based on real-world constraints affecting remote sensing platforms. In this
context, multi-modal co-learning presents a promising strategy to leverage the
vast amount of sensor-derived data available at the training stage to improve
single-modality models for inference-time deployment. Most current research
efforts focus on designing customized solutions for either particular
downstream tasks or specific modalities available at the inference stage. To
address this, we propose a novel multi-modal co-learning framework capable of
generalizing across various tasks without targeting a specific modality for
inference. Our approach combines contrastive and modality discriminative
learning together to guide single-modality models to structure the internal
model manifold into modality-shared and modality-specific information. We
evaluate our framework on four EO benchmarks spanning classification and
regression tasks across different sensor modalities, where only one of the
modalities available during training is accessible at inference time. Our
results demonstrate consistent predictive improvements over state-of-the-art
approaches from the recent machine learning and computer vision literature, as
well as EO-specific methods. The obtained findings validate our framework in
the single-modality inference scenarios across a diverse range of EO
applications.

</details>


### [54] [Addressing the Depth-of-Field Constraint: A New Paradigm for High Resolution Multi-Focus Image Fusion](https://arxiv.org/abs/2510.19581)
*Luca Piano,Peng Huanwen,Radu Ciprian Bilcu*

Main category: cs.CV

TL;DR: VAEEDOF通过蒸馏变分自编码器处理多焦点图像融合（MFIF），并引入MattingMFIF数据集解决数据稀疏性问题。


<details>
  <summary>Details</summary>
Motivation: 光学镜头的景深（DOF）限制导致多焦点图像融合（MFIF）的必要性，现有方法在训练数据、域差距和信息缺失区域方面存在挑战。

Method: 提出VAEEDOF方法，利用蒸馏变分自编码器进行高保真、高效的图像重建，并设计融合模块同时处理多达七张图像。引入MattingMFIF数据集，模拟真实景深效果。

Result: 实现了最先进的性能，生成无缝、无伪影的融合图像，弥合了合成与真实世界场景之间的差距。

Conclusion: VAEEDOF通过创新的融合方法和新的数据集，有效解决了多焦点图像融合领域的挑战，并在处理复杂MFIF问题上取得了显著进展。

Abstract: Multi-focus image fusion (MFIF) addresses the depth-of-field (DOF)
limitations of optical lenses, where only objects within a specific range
appear sharp. Although traditional and deep learning methods have advanced the
field, challenges persist, including limited training data, domain gaps from
synthetic datasets, and difficulties with regions lacking information. We
propose VAEEDOF, a novel MFIF method that uses a distilled variational
autoencoder for high-fidelity, efficient image reconstruction. Our fusion
module processes up to seven images simultaneously, enabling robust fusion
across diverse focus points. To address data scarcity, we introduce
MattingMFIF, a new syntetic 4K dataset, simulating realistic DOF effects from
real photographs. Our method achieves state-of-the-art results, generating
seamless artifact-free fused images and bridging the gap between synthetic and
real-world scenarios, offering a significant step forward in addressing complex
MFIF challenges. The code, and weights are available here:

</details>


### [55] [Uncertainty evaluation of segmentation models for Earth observation](https://arxiv.org/abs/2510.19586)
*Melanie Rey,Andriy Mnih,Maxim Neumann,Matt Overlan,Drew Purves*

Main category: cs.CV

TL;DR: 本篇论文评估了在卫星图像的语义分割预测中估计不确定性的方法，并针对遥感和地球观测应用进行了基准测试。


<details>
  <summary>Details</summary>
Motivation: 由于在像素级估计不确定性的挑战，现有研究主要集中在医学成像和场景理解，因此需要针对遥感和地球观测应用进行特定评估，以了解不确定性度量在识别预测错误和噪声区域方面的实用性。

Method: 使用STOCHASTIC SEGMENTATION NETWORKS和集成等模型，结合多种神经网络架构和不确定性度量，在PASTIS和ForTy两个遥感数据集上进行了广泛的评估。

Result: 通过在PASTIS和ForTy数据集上的广泛实验，评估了几种模型（如随机分割网络和集成）与各种神经网络架构和不确定性度量的组合，以评估不确定性度量在识别预测错误和噪声输入区域方面的能力。

Conclusion: 基于对不同数据集和模型的广泛评估，本研究为遥感语义分割中的不确定性估计提供了实用的建议。

Abstract: This paper investigates methods for estimating uncertainty in semantic
segmentation predictions derived from satellite imagery. Estimating uncertainty
for segmentation presents unique challenges compared to standard image
classification, requiring scalable methods producing per-pixel estimates. While
most research on this topic has focused on scene understanding or medical
imaging, this work benchmarks existing methods specifically for remote sensing
and Earth observation applications. Our evaluation focuses on the practical
utility of uncertainty measures, testing their ability to identify prediction
errors and noise-corrupted input image regions. Experiments are conducted on
two remote sensing datasets, PASTIS and ForTy, selected for their differences
in scale, geographic coverage, and label confidence. We perform an extensive
evaluation featuring several models, such as Stochastic Segmentation Networks
and ensembles, in combination with a number of neural architectures and
uncertainty metrics. We make a number of practical recommendations based on our
findings.

</details>


### [56] [Digitizing Paper ECGs at Scale: An Open-Source Algorithm for Clinical Research](https://arxiv.org/abs/2510.19590)
*Elias Stenhede,Agnar Martin Bjørnstad,Arian Ranjbar*

Main category: cs.CV

TL;DR: 该框架能够将纸质心电图转换为数字信号，并且在公开的数据集和真实世界数据上都表现出色，同时该框架是开源的。


<details>
  <summary>Details</summary>
Motivation: 将数百万份仅以纸质扫描形式存在的临床心电图转换为可用于现代自动诊断的数字信号。

Method: 开发了一个全自动、模块化的框架，用于转换纸质或拍摄的心电图为数字信号。

Result: 在包含37,191张心电图图像的数据集上进行了验证，并在E mory纸质心电图数字化数据集（包含35,595张图像）上进行了评估，在所有子类别中均优于现有技术水平。

Conclusion: 该软件已开源发布，以促进可重复性和进一步开发，并有望解锁回顾性心电图档案并普及对人工智能驱动的诊断的访问。

Abstract: Millions of clinical ECGs exist only as paper scans, making them unusable for
modern automated diagnostics. We introduce a fully automated, modular framework
that converts scanned or photographed ECGs into digital signals, suitable for
both clinical and research applications. The framework is validated on 37,191
ECG images with 1,596 collected at Akershus University Hospital, where the
algorithm obtains a mean signal-to-noise ratio of 19.65 dB on scanned papers
with common artifacts. It is further evaluated on the Emory Paper Digitization
ECG Dataset, comprising 35,595 images, including images with perspective
distortion, wrinkles, and stains. The model improves on the state-of-the-art in
all subcategories. The full software is released as open-source, promoting
reproducibility and further development. We hope the software will contribute
to unlocking retrospective ECG archives and democratize access to AI-driven
diagnostics.

</details>


### [57] [Decomposed Attention Fusion in MLLMs for Training-Free Video Reasoning Segmentation](https://arxiv.org/abs/2510.19592)
*Su Ho Han,Jeongseok Hyun,Pilhyeon Lee,Minho Shim,Dongyoon Wee,Seon Joo Kim*

Main category: cs.CV

TL;DR: 该论文提出了一种名为DecAF的训练无关方法，用于视频目标分割，通过将视频问答任务中的注意力图进行分解融合，以提高分割精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在将MLLMs的注意力图直接应用于视频目标分割时存在噪声大、与目标区域对齐性差的问题，并且通常需要进行模型再训练。

Method: DecAF方法将视频推理分割视为视频问答任务，并利用滚出机制提取注意力图。然后，通过对比目标-背景融合和互补视频-帧融合两种机制来精炼这些注意力图，从而抑制不相关的激活并增强以目标为中心的线索。此外，还引入了注意力引导的SAM2提示来获得细粒度掩码，整个过程无需重新训练模型。

Result: DecAF方法能够将注意力图直接转换为粗分割掩码，并在Referring VOS和Reasoning VOS基准测试中，在分割精度上优于其他训练无关的方法，并能达到与训练方法相媲美的性能。

Conclusion: DecAF是一种有效的训练无关视频目标分割方法，通过分解融合注意力图来提高分割的准确性和鲁棒性。

Abstract: Multimodal large language models (MLLMs) demonstrate strong video
understanding by attending to visual tokens relevant to textual queries. To
directly adapt this for localization in a training-free manner, we cast video
reasoning segmentation as a video QA task and extract attention maps via
rollout mechanism. However, raw attention maps are noisy and poorly aligned
with object regions. We propose Decomposed Attention Fusion (DecAF), which
refines these maps through two mechanisms: (1) contrastive object-background
fusion and (2) complementary video-frame fusion. This method suppresses
irrelevant activations and enhances object-focused cues, enabling direct
conversion of attention maps into coarse segmentation masks. In addition, we
introduce attention-guided SAM2 prompting for obtaining fine-grained masks.
Unlike existing methods that jointly train MLLMs with SAM, our method operates
entirely without retraining. DecAF outperforms training-free methods and
achieves performance comparable to training-based methods on both referring and
reasoning VOS benchmarks. The code will be available at
https://github.com/HYUNJS/DecAF.

</details>


### [58] [CBDiff:Conditional Bernoulli Diffusion Models for Image Forgery Localization](https://arxiv.org/abs/2510.19597)
*Zhou Lei,Pan Gang,Wang Jiahao,Sun Di*

Main category: cs.CV

TL;DR: CBDiff生成多样的伪造定位图，并结合伯努利噪声和时间步交叉注意力，在IFL任务上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有IFL方法生成的定位图精度和可靠性不足，无法满足高风险应用需求。

Method: 提出条件伯努利扩散模型(CBDiff)，生成多样的定位图；在扩散过程中融入伯努利噪声；引入时间步交叉注意力(TSCAttention)以利用语义特征引导。实验在八个公开数据集上进行。

Result: CBDiff显著优于现有最先进方法。

Conclusion: CBDiff在真实世界部署方面具有巨大潜力。

Abstract: Image Forgery Localization (IFL) is a crucial task in image forensics, aimed
at accurately identifying manipulated or tampered regions within an image at
the pixel level. Existing methods typically generate a single deterministic
localization map, which often lacks the precision and reliability required for
high-stakes applications such as forensic analysis and security surveillance.
To enhance the credibility of predictions and mitigate the risk of errors, we
introduce an advanced Conditional Bernoulli Diffusion Model (CBDiff). Given a
forged image, CBDiff generates multiple diverse and plausible localization
maps, thereby offering a richer and more comprehensive representation of the
forgery distribution. This approach addresses the uncertainty and variability
inherent in tampered regions. Furthermore, CBDiff innovatively incorporates
Bernoulli noise into the diffusion process to more faithfully reflect the
inherent binary and sparse properties of forgery masks. Additionally, CBDiff
introduces a Time-Step Cross-Attention (TSCAttention), which is specifically
designed to leverage semantic feature guidance with temporal steps to improve
manipulation detection. Extensive experiments on eight publicly benchmark
datasets demonstrate that CBDiff significantly outperforms existing
state-of-the-art methods, highlighting its strong potential for real-world
deployment.

</details>


### [59] [XBench: A Comprehensive Benchmark for Visual-Language Explanations in Chest Radiography](https://arxiv.org/abs/2510.19599)
*Haozhe Luo,Shelley Zixin Shu,Ziyu Zhou,Sebastian Otalora,Mauricio Reyes*

Main category: cs.CV

TL;DR: 本研究提出了首个用于评估胸部X光片跨模态可解释性的基准测试XBench，发现在通用领域训练的视觉-语言模型(VLMs)在定位小而弥漫的病变时表现不佳，而针对胸部X光片特定数据集进行预训练的模型表现更好，同时模型的识别能力和定位能力呈强相关性。


<details>
  <summary>Details</summary>
Motivation: 目前的视觉-语言模型(VLMs)在医学图像理解方面表现出色，但其在医学领域至关重要的、将文本概念与视觉证据对齐的“定位能力”仍有待探索，而可靠的定位能力对于可解释性和临床应用至关重要。

Method: 本研究提出了首个用于评估胸部X光片跨模态可解释性的系统性基准测试XBench，并测试了七种CLIP风格的VLMs。研究人员利用交叉注意力和基于相似性的定位图生成视觉解释，并针对多种病理的放射科医生标注区域对其进行量化评估。

Result: 研究结果显示：1.所有VLM变体在定位大而明确的病变时表现尚可，但在定位小而弥漫的病变时性能显著下降；2.在胸部X光片特定数据集上预训练的模型，相比于在通用领域数据上训练的模型，表现出更好的定位能力；3.模型的整体识别能力和定位能力之间存在很强的相关性。

Conclusion: 尽管当前的VLMs具有很强的识别能力，但在临床可靠的定位方面仍有不足，这表明在医学实践中部署之前，需要有针对性的可解释性基准测试。

Abstract: Vision-language models (VLMs) have recently shown remarkable zero-shot
performance in medical image understanding, yet their grounding ability, the
extent to which textual concepts align with visual evidence, remains
underexplored. In the medical domain, however, reliable grounding is essential
for interpretability and clinical adoption. In this work, we present the first
systematic benchmark for evaluating cross-modal interpretability in chest
X-rays across seven CLIP-style VLM variants. We generate visual explanations
using cross-attention and similarity-based localization maps, and
quantitatively assess their alignment with radiologist-annotated regions across
multiple pathologies. Our analysis reveals that: (1) while all VLM variants
demonstrate reasonable localization for large and well-defined pathologies,
their performance substantially degrades for small or diffuse lesions; (2)
models that are pretrained on chest X-ray-specific datasets exhibit improved
alignment compared to those trained on general-domain data. (3) The overall
recognition ability and grounding ability of the model are strongly correlated.
These findings underscore that current VLMs, despite their strong recognition
ability, still fall short in clinically reliable grounding, highlighting the
need for targeted interpretability benchmarks before deployment in medical
practice. XBench code is available at
https://github.com/Roypic/Benchmarkingattention

</details>


### [60] [Beyond sparse denoising in frames: minimax estimation with a scattering transform](https://arxiv.org/abs/2510.19612)
*Nathanaël Cuvelle--Magar,Stéphane Mallat*

Main category: cs.CV

TL;DR: 联合最小化和最大化不同子集的小波散射系数的l1范数，提出了一种新的去噪估计器，该估计器可以达到所有Lipschitz指数a<=2的卡通图像的minimax渐近界限。


<details>
  <summary>Details</summary>
Motivation: 现有的稀疏估计器在处理具有未知Lipschitz指数a<=2的复杂信号规律（如卡通图像的边缘）时不够充分，而深度卷积神经网络虽然效果更好，但计算成本高。小波散射系数作为简化的卷积神经网络模型，为提供一种新的去噪方法提供了可能。

Method: 提出了一种新的去噪估计器，通过联合最小化和最大化不同子集的小波散射系数的l1范数来实现。该方法利用l1范数来捕捉不同类型的几何图像规律性。

Result: 数值实验表明，该去噪估计器对于所有Lipschitz指数a<=2的卡通图像，都能达到minimax渐近界限。将此数值结果表述为一个数学猜想。

Conclusion: 该方法提供了一种不同于传统谐波分析的信号去噪方法，并能确定函数的几何规律性。此外，它还在谐波分析和深度卷积网络去噪估计器之间搭建了一座数学桥梁。

Abstract: A considerable amount of research in harmonic analysis has been devoted to
non-linear estimators of signals contaminated by additive Gaussian noise. They
are implemented by thresholding coefficients in a frame, which provide a sparse
signal representation, or by minimising their $\ell^1$ norm. However, sparse
estimators in frames are not sufficiently rich to adapt to complex signal
regularities. For cartoon images whose edges are piecewise $\bf C^\alpha$
curves, wavelet, curvelet and Xlet frames are suboptimal if the Lipschitz
exponent $\alpha \leq 2$ is an unknown parameter. Deep convolutional neural
networks have recently obtained much better numerical results, which reach the
minimax asymptotic bounds for all $\alpha$. Wavelet scattering coefficients
have been introduced as simplified convolutional neural network models. They
are computed by transforming the modulus of wavelet coefficients with a second
wavelet transform. We introduce a denoising estimator by jointly minimising and
maximising the $\ell^1$ norms of different subsets of scattering coefficients.
We prove that these $\ell^1$ norms capture different types of geometric image
regularity. Numerical experiments show that this denoising estimator reaches
the minimax asymptotic bound for cartoon images for all Lipschitz exponents
$\alpha \leq 2$. We state this numerical result as a mathematical conjecture.
It provides a different harmonic analysis approach to suppress noise from
signals, and to specify the geometric regularity of functions. It also opens a
mathematical bridge between harmonic analysis and denoising estimators with
deep convolutional network.

</details>


### [61] [Pragmatic Heterogeneous Collaborative Perception via Generative Communication Mechanism](https://arxiv.org/abs/2510.19618)
*Junfei Zhou,Penglin Dai,Quanmin Wei,Bingyi Liu,Xiao Wu,Jianping Wang*

Main category: cs.CV

TL;DR: GenComm通过生成通信和轻量级数值对齐，解决了异构多智能体系统中的域差距问题，实现了高效且可扩展的协作。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理异构多智能体系统中的传感器和模型差异引起的域差距时，存在侵入性重训和高计算成本的问题，限制了其实用性和可扩展性。

Method: 提出了一种名为GenComm的新型生成通信机制。它包括一个可变形消息提取器，用于提取空间信息；一个空间感知特征生成器，利用条件扩散模型生成与主导智能体语义空间对齐并保留空间信息的新特征；以及一个通道增强器进行特征优化。

Result: 在OPV2V-H、DAIR-V2X和V2X-Real数据集上的实验表明，GenComm在性能上优于现有最先进的方法，并且在引入新智能体时，计算成本和参数数量减少了81%。

Conclusion: GenComm通过特征生成和轻量级数值对齐，有效解决了异构多智能体协作中的域差距问题，实现了低成本、高效率和可扩展的感知能力提升。

Abstract: Multi-agent collaboration enhances the perception capabilities of individual
agents through information sharing. However, in real-world applications,
differences in sensors and models across heterogeneous agents inevitably lead
to domain gaps during collaboration. Existing approaches based on adaptation
and reconstruction fail to support pragmatic heterogeneous collaboration due to
two key limitations: (1) Intrusive retraining of the encoder or core modules
disrupts the established semantic consistency among agents; and (2)
accommodating new agents incurs high computational costs, limiting scalability.
To address these challenges, we present a novel Generative Communication
mechanism (GenComm) that facilitates seamless perception across heterogeneous
multi-agent systems through feature generation, without altering the original
network, and employs lightweight numerical alignment of spatial information to
efficiently integrate new agents at minimal cost. Specifically, a tailored
Deformable Message Extractor is designed to extract spatial message for each
collaborator, which is then transmitted in place of intermediate features. The
Spatial-Aware Feature Generator, utilizing a conditional diffusion model,
generates features aligned with the ego agent's semantic space while preserving
the spatial information of the collaborators. These generated features are
further refined by a Channel Enhancer before fusion. Experiments conducted on
the OPV2V-H, DAIR-V2X and V2X-Real datasets demonstrate that GenComm
outperforms existing state-of-the-art methods, achieving an 81\% reduction in
both computational cost and parameter count when incorporating new agents. Our
code is available at https://github.com/jeffreychou777/GenComm.

</details>


### [62] [Augmenting Moment Retrieval: Zero-Dependency Two-Stage Learning](https://arxiv.org/abs/2510.19622)
*Zhengxuan Wei,Jiajin Tang,Sibei Yang*

Main category: cs.CV

TL;DR: AMR框架通过无需外部依赖的增强来解决视频时刻检索中的数据稀疏性、边界模糊性和细粒度语义辨别不足的问题，并提出了一种包含冷启动和蒸馏适应的两阶段训练框架，实验证明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的视频时刻检索方法面临数据稀疏、边界模糊和细粒度语义辨别能力不足这三个关键瓶颈。

Method: 提出了一种无需外部依赖的增强视频时刻检索框架（AMR），该框架包含一个两阶段训练过程：冷启动阶段利用课程学习在增强数据上进行训练，以建立基础的边界/语义意识；蒸馏适应阶段引入了原始查询和活动查询，通过跨阶段蒸馏损失来防止知识遗忘并实现真实世界泛化。

Result: AMR框架在多个基准测试中取得了比现有最先进方法更好的性能。

Conclusion: AMR框架通过无需外部依赖的增强，解决了视频时刻检索中的关键瓶颈，并在实验中证明了其优越性。

Abstract: Existing Moment Retrieval methods face three critical bottlenecks: (1) data
scarcity forces models into shallow keyword-feature associations; (2) boundary
ambiguity in transition regions between adjacent events; (3) insufficient
discrimination of fine-grained semantics (e.g., distinguishing ``kicking" vs.
``throwing" a ball). In this paper, we propose a zero-external-dependency
Augmented Moment Retrieval framework, AMR, designed to overcome local optima
caused by insufficient data annotations and the lack of robust boundary and
semantic discrimination capabilities. AMR is built upon two key insights: (1)
it resolves ambiguous boundary information and semantic confusion in existing
annotations without additional data (avoiding costly manual labeling), and (2)
it preserves boundary and semantic discriminative capabilities enhanced by
training while generalizing to real-world scenarios, significantly improving
performance. Furthermore, we propose a two-stage training framework with
cold-start and distillation adaptation. The cold-start stage employs curriculum
learning on augmented data to build foundational boundary/semantic awareness.
The distillation stage introduces dual query sets: Original Queries maintain
DETR-based localization using frozen Base Queries from the cold-start model,
while Active Queries dynamically adapt to real-data distributions. A
cross-stage distillation loss enforces consistency between Original and Base
Queries, preventing knowledge forgetting while enabling real-world
generalization. Experiments on multiple benchmarks show that AMR achieves
improved performance over prior state-of-the-art approaches.

</details>


### [63] [MedReason-R1: Learning to Reason for CT Diagnosis with Reinforcement Learning and Local Zoom](https://arxiv.org/abs/2510.19626)
*Yifan Li,Fenghe Tang,Yingtai Li,Shaohua Kevin Zhou*

Main category: cs.CV

TL;DR: CT-RATE-VQA数据集和MedReason-R1模型提升了医学影像诊断能力。


<details>
  <summary>Details</summary>
Motivation: 现有通用大视觉语言模型在医学领域表现不佳，原因在于缺乏大规模高质量的医学影像数据集以及未能模拟从粗到细的诊断过程。

Method: 构建了包含84K问答对的CT-RATE-VQA数据集；提出了MedReason-R1模型，该模型通过嵌入“放大”的疾病感兴趣区域来结合全局定位和疾病细节；引入GRPO强化学习框架以实现有效推理，无需手动标注。

Result: MedReason-R1在CT疾病诊断方面取得了最先进的性能，同时保持了泛化能力。

Conclusion: MedReason-R1通过结合专门的数据集、创新的模型架构和强化学习框架，显著提高了医学影像的诊断准确性。

Abstract: General-purpose large Vision-Language Models (VLMs) demonstrate strong
capabilities in generating detailed descriptions for natural images. However,
their performance in the medical domain remains suboptimal, even for relatively
straightforward tasks, primarily due to the lack of large-scale, high-quality,
specialized medical imaging datasets and the neglect of the diagnostic process
that progresses from coarse to fine-grained. To address the first issue, we
construct the CT-RATE-VQA dataset, which has 84K QA pairs. For the second
issue, we propose MedReason-R1, a medical VLM with explicit reasoning process
for disease diagnosis. MedReason-R1 incorporates a novel strategy that embeds
zoom-in disease region-of-interest areas into the image, highlighting the
crucial role of both global localization and disease-specific details in
enhancing the model's diagnostic performance. Furthermore, we introduce the
GRPO reinforcement learning framework to MedReason-R1, which enables effective
reasoning without relying on costly manual annotations. Compared to recent
general-purpose and medical VLMs, MedReason-R1 achieves state-of-the-art
performance in CT disease diagnosis while retaining generalization. The code,
checkpoints, and dataset are available at:
https://github.com/Leevan001/MedReason-R1

</details>


### [64] [Re-Activating Frozen Primitives for 3D Gaussian Splatting](https://arxiv.org/abs/2510.19653)
*Yuxin Cheng,Binxiao Huang,Wenyong Zhou,Taiqiang Wu,Zhengwu Liu,Graziano Chesi,Ngai Wong*

Main category: cs.CV

TL;DR: ReAct-GS通过引入重激活机制解决3D高斯泼溅在复杂场景下的过重建问题，消除了模糊和针状失真，达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯泼溅方法在处理复杂场景时存在过重建伪影，表现为局部模糊和针状失真。这归因于梯度幅度稀释和原始高斯冻结现象，导致复杂区域的高斯生长受阻，而尺寸不当的高斯则陷入局部最优。

Method: ReAct-GS提出了一种基于‘重激活’原则的新方法。它包括：1）一个考虑多视角α混合权重的、面向重要性的稠密化标准，用于重新激活复杂区域中停滞的原始高斯生长；2）一种通过自适应参数扰动来复兴冻结高斯的新机制。

Result: 实验证明，ReAct-GS能有效消除过重建伪影，在标准新视角合成指标上达到最先进的性能，并保留了精细的几何细节。其重激活机制还能与其他3D高斯泼溅变体（如Pixel-GS）结合，带来一致的性能提升。

Conclusion: ReAct-GS通过引入面向重要性的稠密化和自适应参数扰动机制，成功解决了3D高斯泼溅在复杂场景中的过重建问题，提高了新视角合成的质量和细节保留，并展示了其广泛的适用性。

Abstract: 3D Gaussian Splatting (3D-GS) achieves real-time photorealistic novel view
synthesis, yet struggles with complex scenes due to over-reconstruction
artifacts, manifesting as local blurring and needle-shape distortions. While
recent approaches attribute these issues to insufficient splitting of
large-scale Gaussians, we identify two fundamental limitations: gradient
magnitude dilution during densification and the primitive frozen phenomenon,
where essential Gaussian densification is inhibited in complex regions while
suboptimally scaled Gaussians become trapped in local optima. To address these
challenges, we introduce ReAct-GS, a method founded on the principle of
re-activation. Our approach features: (1) an importance-aware densification
criterion incorporating $\alpha$-blending weights from multiple viewpoints to
re-activate stalled primitive growth in complex regions, and (2) a
re-activation mechanism that revitalizes frozen primitives through adaptive
parameter perturbations. Comprehensive experiments across diverse real-world
datasets demonstrate that ReAct-GS effectively eliminates over-reconstruction
artifacts and achieves state-of-the-art performance on standard novel view
synthesis metrics while preserving intricate geometric details. Additionally,
our re-activation mechanism yields consistent improvements when integrated with
other 3D-GS variants such as Pixel-GS, demonstrating its broad applicability.

</details>


### [65] [I Spy With My Model's Eye: Visual Search as a Behavioural Test for MLLMs](https://arxiv.org/abs/2510.19678)
*John Burden,Jonathan Prunty,Ben Slater,Matthieu Tehenan,Greg Davis,Lucy Cheke*

Main category: cs.CV

TL;DR: MLLMs在视觉-语言任务中表现出色，但其视觉处理过程不透明。本文借鉴认知心理学中的视觉搜索范式，通过实验检验了MLLMs是否会产生“弹出”效应，即显著的视觉特征可以独立于干扰项的数量被检测到。研究发现，先进的MLLMs在基于颜色或大小的搜索中表现出类似人类的弹出效应，并在进行合取（多特征）搜索时表现出容量限制。此外，研究还表明MLLMs像人类一样，在其物体表征中融入了自然场景先验知识（如光照方向）。通过微调和机制可解释性分析，本文证明了视觉搜索作为一种认知学诊断工具，可以评估MLLMs的感知能力。


<details>
  <summary>Details</summary>
Motivation: 现有的MLLMs的评估方法大多只关注任务准确性，而忽略了对其内在视觉机制的探究，这使得MLLMs的视觉处理过程变得不透明。因此，需要一种新的评估方法来深入理解MLLMs的视觉感知能力。

Method: 本文借鉴认知心理学的视觉搜索范式，设计了针对颜色、大小和光照特征的控制实验，以检验MLLMs是否会产生“弹出”效应，即显著视觉特征的检测是否独立于干扰项的数量。此外，还采用了微调和机制可解释性分析等方法来进一步验证和阐释研究结果。

Result: 研究发现在颜色或大小的单特征搜索任务中，先进的MLLMs表现出类似人类的“弹出”效应。然而，在多特征搜索任务中，MLLMs表现出容量限制。同时，研究还发现MLLMs会像人类一样，在其物体表征中整合自然场景的先验知识（例如光照方向）。

Conclusion: 视觉搜索范式可以作为一种基于认知学的诊断工具，用于评估MLLMs的视觉感知能力。该方法有助于揭示MLLMs内在的视觉处理机制，并为未来MLLMs的发展提供指导。

Abstract: Multimodal large language models (MLLMs) achieve strong performance on
vision-language tasks, yet their visual processing is opaque. Most black-box
evaluations measure task accuracy, but reveal little about underlying
mechanisms. Drawing on cognitive psychology, we adapt classic visual search
paradigms -- originally developed to study human perception -- to test whether
MLLMs exhibit the ``pop-out'' effect, where salient visual features are
detected independently of distractor set size. Using controlled experiments
targeting colour, size and lighting features, we find that advanced MLLMs
exhibit human-like pop-out effects in colour or size-based disjunctive (single
feature) search, as well as capacity limits for conjunctive (multiple feature)
search. We also find evidence to suggest that MLLMs, like humans, incorporate
natural scene priors such as lighting direction into object representations. We
reinforce our findings using targeted fine-tuning and mechanistic
interpretability analyses. Our work shows how visual search can serve as a
cognitively grounded diagnostic tool for evaluating perceptual capabilities in
MLLMs.

</details>


### [66] [Curvilinear Structure-preserving Unpaired Cross-domain Medical Image Translation](https://arxiv.org/abs/2510.19679)
*Zihao Chen,Yi Zhou,Xudong Jiang,Li Chen,Leopold Schmetterer,Bingyao Tan,Jun Cheng*

Main category: cs.CV

TL;DR: CST框架在非配对图像到图像翻译中，通过集成结构一致性来显着提高弯曲结构（如微血管）的保真度，特别是在眼科和血管成像领域，并在多个成像模态中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的非配对图像到图像翻译方法在处理细微的弯曲结构（如微血管）时存在失真问题，这在眼科和血管成像等领域尤为关键，因为这些细微的形态变化具有重要的临床意义。因此，需要一种能够显着提高弯曲结构保真度的翻译方法。

Method: 提出了一种名为CST（Curvilinear Structure-preserving Translation）的通用框架，该框架通过在训练中集成结构一致性来显式地保留细微的弯曲结构。具体来说，CST通过增加一个弯曲结构提取模块来实现拓扑监督，并可以无缝集成到现有的方法中，例如CycleGAN和UNetSBR。

Result: 通过在三种成像模态（光学相干断层扫描血管造影、彩色眼底照片和X射线冠状动脉造影）上的全面评估，证明了CST框架可以提高翻译保真度，并在这些模态上实现了最先进的性能。

Conclusion: CST框架通过增强学习映射中的几何完整性，为医学成像中弯曲结构感知的跨域翻译提供了一条原则性的途径，解决了现有方法在处理细微弯曲结构时的不足。

Abstract: Unpaired image-to-image translation has emerged as a crucial technique in
medical imaging, enabling cross-modality synthesis, domain adaptation, and data
augmentation without costly paired datasets. Yet, existing approaches often
distort fine curvilinear structures, such as microvasculature, undermining both
diagnostic reliability and quantitative analysis. This limitation is
consequential in ophthalmic and vascular imaging, where subtle morphological
changes carry significant clinical meaning. We propose Curvilinear
Structure-preserving Translation (CST), a general framework that explicitly
preserves fine curvilinear structures during unpaired translation by
integrating structure consistency into the training. Specifically, CST augments
baseline models with a curvilinear extraction module for topological
supervision. It can be seamlessly incorporated into existing methods. We
integrate it into CycleGAN and UNSB as two representative backbones.
Comprehensive evaluation across three imaging modalities: optical coherence
tomography angiography, color fundus and X-ray coronary angiography
demonstrates that CST improves translation fidelity and achieves
state-of-the-art performance. By reinforcing geometric integrity in learned
mappings, CST establishes a principled pathway toward curvilinear
structure-aware cross-domain translation in medical imaging.

</details>


### [67] [Explainable Face Presentation Attack Detection via Ensemble-CAM](https://arxiv.org/abs/2510.19695)
*Rashik Shadman,M G Sarwar Murshed,Faraz Hussain*

Main category: cs.CV

TL;DR: 提出了一种名为Ensemble-CAM的新技术，用于为基于深度学习的人脸活体检测系统提供视觉解释，以提高其透明度和可信度。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的人脸活体检测系统大多如同黑箱操作，其决策过程不透明，难以让用户理解。然而，利用视觉解释技术可以更好地理解深度学习模型决策的原因，并确定其判断真实或伪造面部图像的关键区域。

Method: 提出了一种名为Ensemble-CAM的新技术，用于为基于深度学习的人脸活体检测系统提供视觉解释。

Result: Ensemble-CAM技术能够提供决策的视觉解释，从而增强基于深度学习的人脸活体检测系统的透明度和可信度。

Conclusion: 该研究提出的Ensemble-CAM技术旨在通过提供更清晰的视觉解释，改进深度学习人脸活体检测系统的性能，增强其透明度和可信赖性。

Abstract: Presentation attacks represent a critical security threat where adversaries
use fake biometric data, such as face, fingerprint, or iris images, to gain
unauthorized access to protected systems. Various presentation attack detection
(PAD) systems have been designed leveraging deep learning (DL) models to
mitigate this type of threat. Despite their effectiveness, most of the DL
models function as black boxes - their decisions are opaque to their users. The
purpose of explainability techniques is to provide detailed information about
the reason behind the behavior or decision of DL models. In particular, visual
explanation is necessary to better understand the decisions or predictions of
DL-based PAD systems and determine the key regions due to which a biometric
image is considered real or fake by the system. In this work, a novel
technique, Ensemble-CAM, is proposed for providing visual explanations for the
decisions made by deep learning-based face PAD systems. Our goal is to improve
DL-based face PAD systems by providing a better understanding of their
behavior. Our provided visual explanations will enhance the transparency and
trustworthiness of DL-based face PAD systems.

</details>


### [68] [LyTimeT: Towards Robust and Interpretable State-Variable Discovery](https://arxiv.org/abs/2510.19716)
*Kuai Yu,Crystal Su,Xiang Liu,Judah Goldfeder,Mingyuan Shao,Hod Lipson*

Main category: cs.CV

TL;DR: LyTimeT是一个两阶段框架，用于从视频中提取动态变量，通过时空注意力机制和稳定性约束，实现准确且物理可解释的预测。


<details>
  <summary>Details</summary>
Motivation: 从高维视频中提取真实动态变量面临背景运动、遮挡和纹理变化等干扰因素的挑战。

Method: LyTimeT采用两阶段方法：第一阶段使用基于TimeSformer的自编码器进行时空特征提取，学习鲁棒的潜在状态；第二阶段通过线性相关性分析选择有物理意义的维度，并使用基于Lyapunov的稳定性正则化器优化动力学模型，以增强收缩性和减少误差累积。

Result: LyTimeT在各种合成和真实世界数据集上，在互信息和内在维度估计上最接近真实值，对背景扰动保持不变，并且在预测精度上优于基线模型。

Conclusion: 结合时空注意力和稳定性约束可以构建出既准确又物理可解释的预测模型。

Abstract: Extracting the true dynamical variables of a system from high-dimensional
video is challenging due to distracting visual factors such as background
motion, occlusions, and texture changes. We propose LyTimeT, a two-phase
framework for interpretable variable extraction that learns robust and stable
latent representations of dynamical systems. In Phase 1, LyTimeT employs a
spatio-temporal TimeSformer-based autoencoder that uses global attention to
focus on dynamically relevant regions while suppressing nuisance variation,
enabling distraction-robust latent state learning and accurate long-horizon
video prediction. In Phase 2, we probe the learned latent space, select the
most physically meaningful dimensions using linear correlation analysis, and
refine the transition dynamics with a Lyapunov-based stability regularizer to
enforce contraction and reduce error accumulation during roll-outs. Experiments
on five synthetic benchmarks and four real-world dynamical systems, including
chaotic phenomena, show that LyTimeT achieves mutual information and intrinsic
dimension estimates closest to ground truth, remains invariant under background
perturbations, and delivers the lowest analytical mean squared error among
CNN-based (TIDE) and transformer-only baselines. Our results demonstrate that
combining spatio-temporal attention with stability constraints yields
predictive models that are not only accurate but also physically interpretable.

</details>


### [69] [Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks](https://arxiv.org/abs/2510.19760)
*Shaohang Jia,Zhiyong Huang,Zhi Yu,Mingyang Hou,Shuai Miao,Han Yang*

Main category: cs.CV

TL;DR: ADQ是一种新的混合精度量化框架，通过自适应权重量化和硬件友好的激活量化方案，解决了现有QAT方法在激活分布不均和代码本不匹配方面的挑战，并在ImageNet上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的量化感知训练（QAT）方法在部署深度神经网络到资源受限设备时，面临激活分布高度不均和权重量化中代码本静态且不匹配的挑战。

Method: 提出了一种名为ADQ（Adaptive Distribution-aware Quantization）的混合精度量化框架，其核心是一个新颖的自适应权重量化方案，包括：1. 基于分位数的代码本初始化方法；2. 基于EMA的在线代码本自适应机制；3. 基于敏感度的混合精度分配策略。同时，为激活引入了硬件友好的非均匀到均匀映射方案。

Result: 在ImageNet上，ADQ使ResNet-18在平均比特位宽仅为2.81 bits的情况下，达到了71.512%的Top-1准确率，优于现有最先进的方法。在CIFAR-10上的消融研究也验证了各创新组件的有效性。

Conclusion: ADQ成功解决了现有QAT方法的挑战，并在图像分类任务上取得了优越的性能，证明了其设计思路和有效性。

Abstract: Quantization-Aware Training (QAT) is a critical technique for deploying deep
neural networks on resource-constrained devices. However, existing methods
often face two major challenges: the highly non-uniform distribution of
activations and the static, mismatched codebooks used in weight quantization.
To address these challenges, we propose Adaptive Distribution-aware
Quantization (ADQ), a mixed-precision quantization framework that employs a
differentiated strategy. The core of ADQ is a novel adaptive weight
quantization scheme comprising three key innovations: (1) a quantile-based
initialization method that constructs a codebook closely aligned with the
initial weight distribution; (2) an online codebook adaptation mechanism based
on Exponential Moving Average (EMA) to dynamically track distributional shifts;
and (3) a sensitivity-informed strategy for mixed-precision allocation. For
activations, we integrate a hardware-friendly non-uniform-to-uniform mapping
scheme. Comprehensive experiments validate the effectiveness of our method. On
ImageNet, ADQ enables a ResNet-18 to achieve 71.512% Top-1 accuracy with an
average bit-width of only 2.81 bits, outperforming state-of-the-art methods
under comparable conditions. Furthermore, detailed ablation studies on CIFAR-10
systematically demonstrate the individual contributions of each innovative
component, validating the rationale and effectiveness of our design.

</details>


### [70] [OmniMotion-X: Versatile Multimodal Whole-Body Motion Generation](https://arxiv.org/abs/2510.19789)
*Guowei Xu,Yuxuan Bian,Ailing Zeng,Mingyi Shi,Shaoli Huang,Wen Li,Lixin Duan,Qiang Xu*

Main category: cs.CV

TL;DR: OmniMotion-X是一个多模态框架，用于生成全身运动，支持文本、音乐、语音控制和空间-时间控制。它使用参考运动来提高一致性，并采用渐进式混合条件训练策略来处理多模态冲突。该框架还引入了一个名为OmniMoCap-X的大型数据集，并使用GPT-4o生成详细的字幕。实验证明，OmniMotion-X在各种多模态任务上都优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为实现多样化的全身人体运动生成任务（包括文本到运动、音乐到舞蹈、语音到手势以及全局空间-时间控制）创建一个通用的多模态框架，并提高生成运动的一致性、风格和时间动态性。

Method: 提出了一种通用的多模态框架OmniMotion-X，它利用自回归扩散Transformer以统一的序列到序列的方式处理各种多模态任务。引入了参考运动作为新的条件信号，并采用渐进式弱到强混合条件训练策略来处理多模态冲突。构建了OmniMoCap-X数据集，并使用GPT-4o为序列生成结构化和分层的字幕。

Result: OmniMotion-X在多种多模态任务上显著优于现有方法，达到了最先进的性能，并能够交互式地生成逼真、连贯且可控的长时程运动。

Conclusion: OmniMotion-X是一个强大且通用的多模态框架，能够有效地处理各种全身运动生成任务，并生成高质量、一致且可控的运动。

Abstract: This paper introduces OmniMotion-X, a versatile multimodal framework for
whole-body human motion generation, leveraging an autoregressive diffusion
transformer in a unified sequence-to-sequence manner. OmniMotion-X efficiently
supports diverse multimodal tasks, including text-to-motion, music-to-dance,
speech-to-gesture, and global spatial-temporal control scenarios (e.g., motion
prediction, in-betweening, completion, and joint/trajectory-guided synthesis),
as well as flexible combinations of these tasks. Specifically, we propose the
use of reference motion as a novel conditioning signal, substantially enhancing
the consistency of generated content, style, and temporal dynamics crucial for
realistic animations. To handle multimodal conflicts, we introduce a
progressive weak-to-strong mixed-condition training strategy. To enable
high-quality multimodal training, we construct OmniMoCap-X, the largest unified
multimodal motion dataset to date, integrating 28 publicly available MoCap
sources across 10 distinct tasks, standardized to the SMPL-X format at 30 fps.
To ensure detailed and consistent annotations, we render sequences into videos
and use GPT-4o to automatically generate structured and hierarchical captions,
capturing both low-level actions and high-level semantics. Extensive
experimental evaluations confirm that OmniMotion-X significantly surpasses
existing methods, demonstrating state-of-the-art performance across multiple
multimodal tasks and enabling the interactive generation of realistic,
coherent, and controllable long-duration motions.

</details>


### [71] [Class-Aware Prototype Learning with Negative Contrast for Test-Time Adaptation of Vision-Language Models](https://arxiv.org/abs/2510.19802)
*Xiaozhen Qiao,Jingkai Zhao,Yuqiu Jiang,Xianda Guo,Zhe Sun,Hongyuan Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Vision-Language Models (VLMs) demonstrate impressive zero-shot generalization
through large-scale image-text pretraining, yet their performance can drop once
the deployment distribution diverges from the training distribution. To address
this, Test-Time Adaptation (TTA) methods update models using unlabeled target
data. However, existing approaches often ignore two key challenges: prototype
degradation in long-tailed distributions and confusion between semantically
similar classes. To tackle these issues, we propose \textbf{C}lass-Aware
\textbf{P}rototype \textbf{L}earning with \textbf{N}egative
\textbf{C}ontrast(\textbf{CPL-NC}), a lightweight TTA framework designed
specifically for VLMs to enhance generalization under distribution shifts.
CPL-NC introduces a \textit{Class-Aware Prototype Cache} Module that
dynamically adjusts per-class capacity based on test-time frequency and
activation history, with a rejuvenation mechanism for inactive classes to
retain rare-category knowledge. Additionally, a \textit{Negative Contrastive
Learning} Mechanism identifies and constrains hard visual-textual negatives to
improve class separability. The framework employs asymmetric optimization,
refining only textual prototypes while anchoring on stable visual features.
Experiments on 15 benchmarks show that CPL-NC consistently outperforms prior
TTA methods across both ResNet-50 and ViT-B/16 backbones.

</details>


### [72] [Pico-Banana-400K: A Large-Scale Dataset for Text-Guided Image Editing](https://arxiv.org/abs/2510.19808)
*Yusu Qian,Eli Bocek-Rivele,Liangchen Song,Jialing Tong,Yinfei Yang,Jiasen Lu,Wenze Hu,Zhe Gan*

Main category: cs.CV

TL;DR: Pico-Banana-400K是一个包含400K图像的大规模数据集，用于基于指令的图像编辑。它解决了现有数据集的不足，通过利用Nano-Banana生成多样化的编辑对，并采用细粒度的编辑分类法和基于MLLM的质量评分来确保质量和多样性。该数据集还包含用于多轮编辑、偏好对齐和指令改写的专业子集，为下一代文本引导图像编辑模型提供了基础。


<details>
  <summary>Details</summary>
Motivation: 现有用于文本引导图像编辑的大规模、高质量、公开可用的真实图像数据集的缺乏，限制了研究的进展。

Method: 利用Nano-Banana从OpenImages的真实照片生成多样化的编辑对。采用细粒度的图像编辑分类法确保编辑类型的全面覆盖。通过MLLM（多模态大型语言模型）的质量评分和仔细的策选来保持精确的内容保留和指令忠实度。构建了三个专门的子集：用于研究顺序编辑、推理和规划的多轮编辑集合；用于对齐研究和奖励模型训练的偏好子集；以及用于开发指令重写和摘要能力的成对长短编辑指令。

Result: 创建了一个包含400K图像的数据集Pico-Banana-400K，其中包含三个子集：72K个多轮编辑示例，56K个偏好示例，以及成对的长短编辑指令。

Conclusion: Pico-Banana-400K作为一个大规模、高质量、任务丰富的数据资源，为训练和评估下一代文本引导图像编辑模型奠定了坚实的基础。

Abstract: Recent advances in multimodal models have demonstrated remarkable text-guided
image editing capabilities, with systems like GPT-4o and Nano-Banana setting
new benchmarks. However, the research community's progress remains constrained
by the absence of large-scale, high-quality, and openly accessible datasets
built from real images. We introduce Pico-Banana-400K, a comprehensive
400K-image dataset for instruction-based image editing. Our dataset is
constructed by leveraging Nano-Banana to generate diverse edit pairs from real
photographs in the OpenImages collection. What distinguishes Pico-Banana-400K
from previous synthetic datasets is our systematic approach to quality and
diversity. We employ a fine-grained image editing taxonomy to ensure
comprehensive coverage of edit types while maintaining precise content
preservation and instruction faithfulness through MLLM-based quality scoring
and careful curation. Beyond single turn editing, Pico-Banana-400K enables
research into complex editing scenarios. The dataset includes three specialized
subsets: (1) a 72K-example multi-turn collection for studying sequential
editing, reasoning, and planning across consecutive modifications; (2) a
56K-example preference subset for alignment research and reward model training;
and (3) paired long-short editing instructions for developing instruction
rewriting and summarization capabilities. By providing this large-scale,
high-quality, and task-rich resource, Pico-Banana-400K establishes a robust
foundation for training and benchmarking the next generation of text-guided
image editing models.

</details>


### [73] [How to Evaluate Monocular Depth Estimation?](https://arxiv.org/abs/2510.19814)
*Siyang Wu,Jack Nugent,Willow Yang,Jia Deng*

Main category: cs.CV

TL;DR: 现有的单目深度估计评估指标在处理曲率扰动时不够敏感，本文提出了一种新的基于相对表面法线的指标，并辅以新的可视化工具和组合指标方法。


<details>
  <summary>Details</summary>
Motivation: 现有文献缺乏单目深度估计评估的标准化方法，并且对各种评估指标的权衡和行为理解不足。

Method: 对现有指标进行了量化的新颖分析，并提出了一种基于相对表面法线的新指标、新的深度可视化工具以及一种创建与人类判断更一致的组合指标的原则方法。

Result: 现有指标对曲率扰动（例如使平面起伏）的敏感度严重不足。新提出的基于相对表面法线的指标以及组合指标方法能更好地与人类判断保持一致。

Conclusion: 现有指标在评估单目深度估计时存在局限性，特别是对曲率变化不敏感。本文提出的新指标和方法可以提供更准确、更符合人类感知的评估。

Abstract: Monocular depth estimation is an important task with rapid progress, but how
to evaluate it remains an open question, as evidenced by a lack of
standardization in existing literature and a large selection of evaluation
metrics whose trade-offs and behaviors are not well understood. This paper
contributes a novel, quantitative analysis of existing metrics in terms of
their sensitivity to various types of perturbations of ground truth,
emphasizing comparison to human judgment. Our analysis reveals that existing
metrics are severely under-sensitive to curvature perturbation such as making
flat surfaces wavy. To remedy this, we introduce a new metric based on relative
surface normals, along with new depth visualization tools and a principled
method to create composite metrics with better human alignment. Code and data
are available at: https://github.com/princeton-vl/evalmde.

</details>


### [74] [olmOCR 2: Unit Test Rewards for Document OCR](https://arxiv.org/abs/2510.19817)
*Jake Poznanski,Luca Soldaini,Kyle Lo*

Main category: cs.CV

TL;DR: olmOCR 2 是一个先进的 OCR 系统，使用名为 olmOCR-2-7B-1025 的 7B 视觉语言模型 (VLM) 进行训练，通过包含二进制单元测试的可验证奖励进行强化学习，并在合成文档数据集上进行了扩展。它在 olmOCR-Bench 上实现了最先进的性能，尤其在数学公式转换、表格解析和多栏布局方面有显著改进。


<details>
  <summary>Details</summary>
Motivation: 将数字化的印刷文档（如 PDF）转换为清晰、自然排序的纯文本。

Method: 使用名为 olmOCR-2-7B-1025 的 7B 视觉语言模型 (VLM)，通过包含二进制单元测试的可验证奖励 (RLVR) 进行强化学习训练。开发了一个生成合成文档的流水线，包含多样的布局、HTML 源代码和测试用例。

Result: 在 olmOCR-Bench（一个英语 OCR 基准）上实现了最先进的性能，在数学公式转换、表格解析和多栏布局方面取得了最大改进。

Conclusion: olmOCR 2 在 OCR 任务上取得了最先进的性能，尤其是在处理复杂文档结构方面。所提出的 RLVR 训练方法和合成数据生成流水线是实现这些改进的关键。模型、数据和代码均已开源。

Abstract: We present olmOCR 2, the latest in our family of powerful OCR systems for
converting digitized print documents, like PDFs, into clean, naturally ordered
plain text. olmOCR 2 is powered by olmOCR-2-7B-1025, a specialized, 7B vision
language model (VLM) trained using reinforcement learning with verifiable
rewards (RLVR), where our rewards are a diverse set of binary unit tests. To
scale unit test creation, we develop a pipeline for generating synthetic
documents with diverse and challenging layouts, known ground-truth HTML source
code, and extracted test cases. We show that RL training on these test cases
results in state-of-the-art performance on olmOCR-Bench, our English-language
OCR benchmark, with the largest improvements in math formula conversion, table
parsing, and multi-column layouts compared to previous versions. We release our
model, data and code under permissive open licenses.

</details>


### [75] [Is This Tracker On? A Benchmark Protocol for Dynamic Tracking](https://arxiv.org/abs/2510.19819)
*Ilona Demler,Saumya Chauhan,Georgia Gkioxari*

Main category: cs.CV

TL;DR: ITTO是一个新的点追踪基准测试套件，用于评估和诊断点追踪方法的性能和局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试未能充分捕捉真实世界场景中的运动复杂性、遮挡模式和物体多样性等关键因素，因此需要一个新的基准来评估点追踪方法的鲁棒性。

Method: 从现有数据集和以自我为中心的真实世界录像中收集视频，并通过多阶段流程收集高质量的人工注释来构建ITTO基准套件。

Result: 对最先进的追踪方法在ITTO上的严格分析表明，现有追踪器在应对这些挑战时存在困难，特别是在遮挡后重新识别点方面，暴露了关键的失败模式。

Conclusion: 现有的追踪方法在处理真实世界场景的复杂性方面存在不足，需要新的建模方法来提高追踪算法的鲁棒性。ITTO将作为推动点追踪发展和指导更鲁棒追踪算法开发的基础测试平台。

Abstract: We introduce ITTO, a challenging new benchmark suite for evaluating and
diagnosing the capabilities and limitations of point tracking methods. Our
videos are sourced from existing datasets and egocentric real-world recordings,
with high-quality human annotations collected through a multi-stage pipeline.
ITTO captures the motion complexity, occlusion patterns, and object diversity
characteristic of real-world scenes -- factors that are largely absent in
current benchmarks. We conduct a rigorous analysis of state-of-the-art tracking
methods on ITTO, breaking down performance along key axes of motion complexity.
Our findings reveal that existing trackers struggle with these challenges,
particularly in re-identifying points after occlusion, highlighting critical
failure modes. These results point to the need for new modeling approaches
tailored to real-world dynamics. We envision ITTO as a foundation testbed for
advancing point tracking and guiding the development of more robust tracking
algorithms.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [76] [Contextual Augmentation for Entity Linking using Large Language Models](https://arxiv.org/abs/2510.18888)
*Daniel Vollmers,Hamada M. Zahera,Diego Moussallem,Axel-Cyrille Ngonga Ngomo*

Main category: cs.CL

TL;DR: 我们提出了一个统一的框架，通过微调大型语言模型来联合进行实体识别和实体链接，并在非领域数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的实体链接方法通常采用两步法，分别进行实体识别和实体链接，这种方法计算量大且效果不佳。

Method: 提出了一种微调模型，在一个统一的框架中联合整合实体识别和实体链接。该方法利用大型语言模型来丰富实体提及的上下文，从而在实体链接方面取得更好的性能。

Result: 在基准数据集上的评估结果表明，我们的方法在非领域数据集上取得了最先进的性能。

Conclusion: 我们提出的方法通过联合进行实体识别和实体链接，并利用大型语言模型增强上下文信息，在实体链接任务上，尤其是在非领域数据集上，展现出优越的性能。

Abstract: Entity Linking involves detecting and linking entity mentions in natural
language texts to a knowledge graph. Traditional methods use a two-step process
with separate models for entity recognition and disambiguation, which can be
computationally intensive and less effective. We propose a fine-tuned model
that jointly integrates entity recognition and disambiguation in a unified
framework. Furthermore, our approach leverages large language models to enrich
the context of entity mentions, yielding better performance in entity
disambiguation. We evaluated our approach on benchmark datasets and compared
with several baselines. The evaluation results show that our approach achieves
state-of-the-art performance on out-of-domain datasets.

</details>


### [77] [Small Language Models Offer Significant Potential for Science Community](https://arxiv.org/abs/2510.18890)
*Jian Zhang*

Main category: cs.CL

TL;DR: 与其使用大型语言模型（LLMs），本文开发了一个基于免费小型语言模型（MiniLMs）的框架，用于从地学文献中精确、快速、经济高效地检索信息。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）在科学文献中的应用日益广泛，但也存在信息偏倚和计算成本高昂的担忧。因此，本文旨在探索一种替代方案。

Method: 本文构建了一个包含约7700万个句子的大型地学文献语料库，并利用MiniLMs结合语义搜索和句子级索引技术，实现了对领域特定信息的提取。此外，还运用情感分析和无监督聚类技术分析了句子的情感基调和主题。

Result: MiniLMs能够高效提取专家验证过的、来自多学科的、特别是包含量化发现的信息，优于ChatGPT-4等通用模型。该方法还能通过情感分析和主题聚类，追踪地学领域结论、研究重点、进展和新兴问题的演变。

Conclusion: MiniLM框架在地学领域具有巨大潜力，可用于事实和图像检索、趋势分析、矛盾分析以及教育等多种应用。

Abstract: Recent advancements in natural language processing, particularly with large
language models (LLMs), are transforming how scientists engage with the
literature. While the adoption of LLMs is increasing, concerns remain regarding
potential information biases and computational costs. Rather than LLMs, I
developed a framework to evaluate the feasibility of precise, rapid, and
cost-effective information retrieval from extensive geoscience literature using
freely available small language models (MiniLMs). A curated corpus of
approximately 77 million high-quality sentences, extracted from 95 leading
peer-reviewed geoscience journals such as Geophysical Research Letters and
Earth and Planetary Science Letters published during years 2000 to 2024, was
constructed. MiniLMs enable a computationally efficient approach for extracting
relevant domain-specific information from these corpora through semantic search
techniques and sentence-level indexing. This approach, unlike LLMs such as
ChatGPT-4 that often produces generalized responses, excels at identifying
substantial amounts of expert-verified information with established,
multi-disciplinary sources, especially for information with quantitative
findings. Furthermore, by analyzing emotional tone via sentiment analysis and
topical clusters through unsupervised clustering within sentences, MiniLM
provides a powerful tool for tracking the evolution of conclusions, research
priorities, advancements, and emerging questions within geoscience communities.
Overall, MiniLM holds significant potential within the geoscience community for
applications such as fact and image retrievals, trend analyses, contradiction
analyses, and educational purposes.

</details>


### [78] [When Models Can't Follow: Testing Instruction Adherence Across 256 LLMs](https://arxiv.org/abs/2510.18892)
*Richard J. Young,Brandon Gillins,Alice M. Matthews*

Main category: cs.CL

TL;DR: A streamlined evaluation framework with 20 prompts assesses LLM instruction-following across diverse tasks, tested on 256 models, revealing consistent failure modes and offering a practical diagnostic tool.


<details>
  <summary>Details</summary>
Motivation: Existing LLM benchmarks are challenging to use for focused assessments of instruction adherence, and newer models might overfit existing benchmarks. Novel evaluation approaches are needed to assess genuine capabilities.

Method: A streamlined evaluation framework using twenty carefully designed prompts to assess LLM instruction-following across diverse task categories. 256 models from 331 available via OpenRouter were tested, with basic functionality verified before inclusion. Each prompt targets distinct aspects of instruction following, including format compliance, content constraints, logical sequencing, and multi-step task execution.

Result: The study tested 256 models and revealed consistent failure modes and identified specific instruction types that pose particular challenges.

Conclusion: This work contributes a practical evaluation tool and a comprehensive empirical analysis of LLM instruction-following capabilities, highlighting consistent failure modes and specific challenges across the contemporary LLM landscape.

Abstract: Despite widespread deployment of Large Language Models, systematic evaluation
of instruction-following capabilities remains challenging. While comprehensive
benchmarks exist, focused assessments that quickly diagnose specific
instruction adherence patterns are valuable. As newer models may be trained on
existing benchmarks, novel evaluation approaches are needed to assess genuine
capabilities rather than memorized performance. This paper presents a
streamlined evaluation framework using twenty carefully designed prompts to
assess LLM instruction-following across diverse task categories. We demonstrate
this framework through a large-scale empirical study conducted on October 14,
2025, testing 256 verified working models from 331 available via OpenRouter. To
ensure methodological rigor and prevent selection bias, we first verified each
model's basic functionality before inclusion. Unlike large-scale benchmarks
requiring extensive computational resources, our approach offers a practical
diagnostic tool researchers and practitioners can readily apply. Our
methodology builds upon verifiable instructions while introducing a compact
test suite balancing comprehensiveness with efficiency. Each prompt targets
distinct aspects of instruction following, including format compliance, content
constraints, logical sequencing, and multi-step task execution. We evaluate
models from major providers (OpenAI, Anthropic, Google, Meta, Mistral) and
emerging implementations (Qwen, DeepSeek, community models), providing
comparative performance analysis. Our findings reveal consistent failure modes
and identify specific instruction types posing particular challenges. This work
contributes both a practical evaluation tool and one of the most comprehensive
empirical analyses of instruction-following capabilities across the
contemporary LLM landscape.

</details>


### [79] [Transformer-Based Low-Resource Language Translation: A Study on Standard Bengali to Sylheti](https://arxiv.org/abs/2510.18898)
*Mangsura Kabir Oni,Tabia Tanzin Prama*

Main category: cs.CL

TL;DR: 尽管多语言 Transformer 模型在孟加拉语到锡尔赫蒂语的翻译任务上优于零样本 LLM，但针对具体任务的调整对于代表性不足的语言至关重要。


<details>
  <summary>Details</summary>
Motivation: 为解决低资源语言（如锡尔赫蒂语）的机器翻译研究不足的问题，本研究探讨了孟加拉语到锡尔赫蒂语的翻译。

Method: 通过微调多语言 Transformer 模型（mBART-50 和 MarianMT）并与零样本大型语言模型（LLMs）进行比较，来研究孟加拉语到锡尔赫蒂语的翻译。

Result: 微调后的模型显著优于 LLMs，其中 mBART-50 在翻译充分性方面表现最佳，MarianMT 在字符级保真度方面表现最强。

Conclusion: 对于代表性不足的语言，针对具体任务的适应性调整至关重要，这有助于推动包容性语言技术的发展。

Abstract: Machine Translation (MT) has advanced from rule-based and statistical methods
to neural approaches based on the Transformer architecture. While these methods
have achieved impressive results for high-resource languages, low-resource
varieties such as Sylheti remain underexplored. In this work, we investigate
Bengali-to-Sylheti translation by fine-tuning multilingual Transformer models
and comparing them with zero-shot large language models (LLMs). Experimental
results demonstrate that fine-tuned models significantly outperform LLMs, with
mBART-50 achieving the highest translation adequacy and MarianMT showing the
strongest character-level fidelity. These findings highlight the importance of
task-specific adaptation for underrepresented languages and contribute to
ongoing efforts toward inclusive language technologies.

</details>


### [80] [DuoLens: A Framework for Robust Detection of Machine-Generated Multilingual Text and Code](https://arxiv.org/abs/2510.18904)
*Shriyansh Agrawal,Aidan Lau,Sanyam Shah,Ahan M R,Kevin Zhu,Sunishchal Dev,Vasu Sharma*

Main category: cs.CL

TL;DR: 小型语言模型（SLM）在检测机器生成内容方面优于大型语言模型（LLM），计算成本更低。


<details>
  <summary>Details</summary>
Motivation: 现有的机器生成内容检测器（主要是零样本方法）计算成本高或精度不足，需要在准确性和效率之间进行改进。

Method: 对 RoBERTa 和 CodeBERTa 等编码器模型进行微调，使用专门的源代码和自然语言数据集进行二元分类任务。

Result: 与 LLM 相比，SLM 在 AUROC（0.97-0.99）和宏 F1（0.89-0.94）方面表现更好，同时延迟降低 8-12 倍，峰值 VRAM 降低 3-5 倍。在进行各种转换后，性能仍然保持了原始 AUROC 的 92% 以上。

Conclusion: 微调的 SLM 在检测机器生成内容方面比 LLM 更具优势，计算效率更高，并且在各种挑战下仍然保持稳健。

Abstract: The prevalence of Large Language Models (LLMs) for generating multilingual
text and source code has only increased the imperative for machine-generated
content detectors to be accurate and efficient across domains. Current
detectors, predominantly utilizing zero-shot methods, such as Fast DetectGPT or
GPTZero, either incur high computational cost or lack sufficient accuracy,
often with a trade-off between the two, leaving room for further improvement.
To address these gaps, we propose the fine-tuning of encoder-only Small
Language Models (SLMs), in particular, the pre-trained models of RoBERTA and
CodeBERTa using specialized datasets on source code and other natural language
to prove that for the task of binary classification, SLMs outperform LLMs by a
huge margin whilst using a fraction of compute. Our encoders achieve AUROC $=
0.97$ to $0.99$ and macro-F1 $0.89$ to $0.94$ while reducing latency by
$8$-$12\times$ and peak VRAM by $3$-$5\times$ at $512$-token inputs. Under
cross-generator shifts and adversarial transformations (paraphrase,
back-translation; code formatting/renaming), performance retains $\geq 92%$ of
clean AUROC. We release training and evaluation scripts with seeds and configs;
a reproducibility checklist is also included.

</details>


### [81] [Improving Topic Modeling of Social Media Short Texts with Rephrasing: A Case Study of COVID-19 Related Tweets](https://arxiv.org/abs/2510.18908)
*Wangjiaxuan Xin,Shuhua Yin,Shi Chen,Yaorong Ge*

Main category: cs.CL

TL;DR: 通过使用大型语言模型（LLMs）对原始推文进行改写，来提升社交媒体文本在主题建模中的表现，特别是针对COVID-19相关推文，研究发现‘口语化到正式化’的改写策略效果最佳，显著提高了主题的连贯性、独特性和多样性，并减少了冗余。


<details>
  <summary>Details</summary>
Motivation: 社交媒体（如推特）在分析公共领域话语方面提供了丰富的数据，尤其是在COVID-19大流行等危机期间。然而，社交媒体短文本的简洁性、非正式性和噪音，常常阻碍传统主题建模的有效性，导致产生难以理解的、不连贯或冗余的主题。

Method: 开发了一个名为TM-Rephrase的模型无关框架，该框架利用大型语言模型（LLMs）在进行主题建模之前，将原始推文改写为更标准化、更正式的语言。研究使用了25,027条与COVID-19相关的推文数据集，并研究了两种改写策略（通用改写和口语化到正式化改写）对多种主题建模方法的影响。

Result: 结果表明，TM-Rephrase在主题连贯性、主题独特性和主题多样性这三个衡量主题建模性能的指标上有所提升，并减少了大多数主题建模算法的主题冗余。其中，口语化到正式化的改写策略带来了最大的性能提升，特别是对于潜在狄利克雷分配（LDA）算法。

Conclusion: TM-Rephrase为在公共卫生相关的社交媒体分析中增强主题建模提供了一种模型无关的方法，有望在理解卫生危机期间的公共话语以及其他重要领域方面发挥广泛作用。

Abstract: Social media platforms such as Twitter (now X) provide rich data for
analyzing public discourse, especially during crises such as the COVID-19
pandemic. However, the brevity, informality, and noise of social media short
texts often hinder the effectiveness of traditional topic modeling, producing
incoherent or redundant topics that are often difficult to interpret. To
address these challenges, we have developed \emph{TM-Rephrase}, a
model-agnostic framework that leverages large language models (LLMs) to
rephrase raw tweets into more standardized and formal language prior to topic
modeling. Using a dataset of 25,027 COVID-19-related Twitter posts, we
investigate the effects of two rephrasing strategies, general- and
colloquial-to-formal-rephrasing, on multiple topic modeling methods. Results
demonstrate that \emph{TM-Rephrase} improves three metrics measuring topic
modeling performance (i.e., topic coherence, topic uniqueness, and topic
diversity) while reducing topic redundancy of most topic modeling algorithms,
with the colloquial-to-formal strategy yielding the greatest performance gains
and especially for the Latent Dirichlet Allocation (LDA) algorithm. This study
contributes to a model-agnostic approach to enhancing topic modeling in public
health related social media analysis, with broad implications for improved
understanding of public discourse in health crisis as well as other important
domains.

</details>


### [82] [Learning from the Best, Differently: A Diversity-Driven Rethinking on Data Selection](https://arxiv.org/abs/2510.18909)
*Hongyi He,Xiao Liu,Zhenghao Lin,Mingni Tang,Yi Cheng,Jintao Wang,Wenjie Li,Peng Cheng,Yeyun Gong*

Main category: cs.CL

TL;DR: 现有的预训练数据选择方法在保证数据质量的同时，忽略了数据的多样性，导致模型性能下降。本文提出的ODiS算法通过正交分解相关性指标，保证了数据质量和多样性，从而提升了模型的下游性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于评分的数据选择方法会忽略多样性，导致性能下降。需要一种能够同时保证数据质量和多样性的新方法。

Method: ODiS算法首先对数据进行多维度评估（语言质量、知识质量、理解难度），然后通过主成分分析（PCA）进行去相关性处理，得到正交评估维度。接着，训练基于Roberta的评分器进行可扩展推理。最后，在每个正交维度上选择得分最高的数据来构建训练数据集。

Result: ODiS选择的数据在不同维度上的重叠度小于2%，证明了维度的正交性。使用ODiS选择的数据训练的模型在下游基准测试中显著优于其他基线模型。

Conclusion: 正交的、注重多样性的数据选择对于大型语言模型至关重要。

Abstract: High-quality pre-training data is crutial for large language models, where
quality captures factual reliability and semantic value, and diversity ensures
broad coverage and distributional heterogeneity. Existing approaches typically
rely on single or multiple-dimensional score-based selection. However, directly
selecting top-scored data often degrades performance, and sampling from a
broader range is required to recover results. The above non-monotonicity
between dataset scores and downstream benchmark results reveals a fundamental
bias: score-based methods collapse correlated dimensions, causing top-scored
data to appear high-quality while systematically overlooking diversity. We
argue that ensuring diversity requires decomposing correlated metrics into
orthogonal feature dimensions, from which the top-scored data can be directly
selected. Therefore, we proposed the Orthogonal Diversity-Aware Selection
(ODiS) algorithm, which preserves both quality and diversity during data
selection. First, ODiS evaluates data from multiple dimensions, covering
language quality, knowledge quality, and comprehension difficulty. The
multi-dimensional scores are then decorrelated via Principal Component Analysis
(PCA), yielding orthogonal evaluation dimensions. For each dimension, a
Roberta-based scorer is trained to regress the data onto PCA-projected scores,
enabling scalable inference on large corpora. Finally, ODiS constructs the
training dataset by selecting top-scored data within each orthogonal dimension,
thereby ensuring both quality and diversity. Empirical results show that
ODiS-selected data exhibit less than 2\% inter-dimension overlap, confirming
orthogonality between dimensions. More importantly, models trained with
ODiS-selected data significantly outperform other baselines on downstream
benchmarks, highlighting the necessity of orthogonal, diversity-aware data
selection for LLMs.

</details>


### [83] [Context-aware Fairness Evaluation and Mitigation in LLMs](https://arxiv.org/abs/2510.18914)
*Afrozah Nadeem,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: 该研究提出了一种动态、可逆的剪枝框架，用于在推理时解决大型语言模型中的不期望行为，通过自适应掩蔽神经元激活来减轻偏见、不一致性和有害内容的传播，同时在多语言对话中保持知识和连贯性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在内部表示中存在不期望的行为（如不公平、不一致、有害内容放大），而传统的训练时或数据中心的方法计算成本高、不可逆且适应性差。剪枝方法虽然更灵活，但现有方法是静态的，无法适应对话或上下文的变化。

Method: 提出了一种动态、可逆的剪枝框架，该框架在推理时检测上下文感知的神经元激活，并应用自适应掩蔽来调节其在生成过程中的影响。

Result: 该框架实现了细粒度、内存感知的缓解，在多语言单轮和多轮对话中保持了知识保留和更连贯的行为，实现了动态公平控制。

Conclusion: 所提出的推理时解决方案为解决大型语言模型中的不期望行为提供了一种动态、可逆且适应性强的方法，能够有效控制公平性并保持模型的知识和连贯性。

Abstract: Large language models often display undesirable behaviors embedded in their
internal representations, undermining fairness, inconsistency drift,
amplification of harmful content, and the propagation of unwanted patterns
during extended dialogue and conversations. Although training-time or
data-centric methods attempt to reduce these effects, they are computationally
expensive, irreversible once deployed, and slow to adapt to new conversational
contexts. Pruning-based methods provide a flexible and transparent way to
reduce bias by adjusting the neurons responsible for certain behaviors.
However, most existing approaches are static; once a neuron is removed, the
model loses the ability to adapt when the conversation or context changes. To
address this, we propose a dynamic, reversible, pruning-based framework that
detects context-aware neuron activations and applies adaptive masking to
modulate their influence during generation. Our inference-time solution
provides fine-grained, memory-aware mitigation with knowledge-preserved, more
coherent behavior across multilingual single- and multi-turn dialogues,
enabling dynamic fairness control in real-world conversational AI.

</details>


### [84] [MMAO-Bench: MultiModal All in One Benchmark Reveals Compositional Law between Uni-modal and Omni-modal in OmniModels](https://arxiv.org/abs/2510.18915)
*Chen Chen,ZeYang Hu,Fengjiao Chen,Liya Ma,Jiaxing Liu,Xiaoyu Li,Xuezhi Cao*

Main category: cs.CL

TL;DR: 该研究提出了一个名为MMAO-Bench的新基准，用于评估多模态大语言模型（包括视觉、听觉和语言）的单模态和全模态理解能力，并通过实验揭示了跨模态、单模态和全模态性能之间的关系。


<details>
  <summary>Details</summary>
Motivation: 目前多模态大语言模型在统一视觉、听觉和语言模态方面取得进展，但单模态和全模态之间的关联尚不清楚，需要全面的评估来推动全模态智能的发展。

Method: 提出了一个包含1880个人工策划样本、44种任务类型以及创新的多步开放式问题类型的新型、高质量、多样化的全模态基准MMAO-Bench，用于评估单模态和全模态理解能力。

Result: 实验结果表明，跨模态和单模态性能之间存在组合定律，全模态能力在弱模型上表现出瓶颈效应，而在强模型上则表现出协同促进作用。

Conclusion: MMAO-Bench能够有效评估单模态和全模态理解能力，并揭示了不同模态能力之间的相互作用机制。

Abstract: Multimodal Large Languages models have been progressing from uni-modal
understanding toward unifying visual, audio and language modalities,
collectively termed omni models. However, the correlation between uni-modal and
omni-modal remains unclear, which requires comprehensive evaluation to drive
omni model's intelligence evolution. In this work, we propose a novel, high
quality and diversity omni model benchmark, MultiModal All in One Benchmark
(MMAO-Bench), which effectively assesses both uni-modal and omni-modal
understanding capabilities. The benchmark consists of 1880 human curated
samples, across 44 task types, and a innovative multi-step open-ended question
type that better assess complex reasoning tasks. Experimental result shows the
compositional law between cross-modal and uni-modal performance and the
omni-modal capability manifests as a bottleneck effect on weak models, while
exhibiting synergistic promotion on strong models.

</details>


### [85] [Misinformation Detection using Large Language Models with Explainability](https://arxiv.org/abs/2510.18918)
*Jainee Patel,Chintan Bhatt,Himani Trivedi,Thanh Thi Nguyen*

Main category: cs.CL

TL;DR: 该论文提出了一种使用RoBERTa和DistilBERT模型进行虚假信息检测的方法，该方法计算效率高且具有可解释性。通过两步微调策略，优化了模型性能，并在两个真实数据集上进行了测试。结果表明，DistilBERT在保持可比性能的同时，显著降低了计算成本。此外，该方法集成了LIME和SHAP，提供了本地和全局的解释，增强了模型的透明度和可信度。


<details>
  <summary>Details</summary>
Motivation: 在线平台上传播的虚假信息会削弱人们之间的信任并阻碍明智的决策。本研究旨在开发一种可解释且计算高效的管道，以检测虚假信息。

Method: 该研究优化了RoBERTa和DistilBERT模型，采用了一种两步策略：首先固定主干并仅训练分类头，然后逐渐解冻主干层并应用层级学习率衰减。此外，还集成了LIME和SHAP技术，以提供token级别的解释和全局特征归因。

Result: 在COVID Fake News和FakeNewsNet GossipCop两个真实数据集上进行测试，结果显示DistilBERT在准确性上可与RoBERTa媲美，但计算资源消耗却少得多。

Conclusion: 该研究提出了一个量化的论据，证明轻量级预训练语言模型（PLM）可以在显著降低计算成本的同时保持任务性能。此外，该研究还提供了一个可解释的管道，在不影响性能的情况下检索忠实的本地和全局理由。这些结果表明，结合了原则性微调和可解释性的PLM可以成为一种有效的框架，用于可扩展、可信的虚假信息检测。

Abstract: The rapid spread of misinformation on online platforms undermines trust among
individuals and hinders informed decision making. This paper shows an
explainable and computationally efficient pipeline to detect misinformation
using transformer-based pretrained language models (PLMs). We optimize both
RoBERTa and DistilBERT using a two-step strategy: first, we freeze the backbone
and train only the classification head; then, we progressively unfreeze the
backbone layers while applying layer-wise learning rate decay. On two
real-world benchmark datasets, COVID Fake News and FakeNewsNet GossipCop, we
test the proposed approach with a unified protocol of preprocessing and
stratified splits. To ensure transparency, we integrate the Local Interpretable
Model-Agnostic Explanations (LIME) at the token level to present token-level
rationales and SHapley Additive exPlanations (SHAP) at the global feature
attribution level. It demonstrates that DistilBERT achieves accuracy comparable
to RoBERTa while requiring significantly less computational resources. This
work makes two key contributions: (1) it quantitatively shows that a
lightweight PLM can maintain task performance while substantially reducing
computational cost, and (2) it presents an explainable pipeline that retrieves
faithful local and global justifications without compromising performance. The
results suggest that PLMs combined with principled fine-tuning and
interpretability can be an effective framework for scalable, trustworthy
misinformation detection.

</details>


### [86] [Evaluating LLM Story Generation through Large-scale Network Analysis of Social Structures](https://arxiv.org/abs/2510.18932)
*Hiroshi Nonaka,K. E. Perry*

Main category: cs.CL

TL;DR: LLM生成的故事倾向于描绘紧密且积极的人际关系，这可以通过分析故事中的社会结构（如带符号的角色网络）来评估。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在复杂创意任务中的能力通常需要难以规模化的人工评估。

Method: 提出了一种新颖的、可扩展的方法，通过分析叙事中潜在的社会结构（带符号的角色网络）来评估LLM的故事生成能力。

Result: 对1200多个故事（由GPT-4o、GPT-4o mini、Gemini 1.5 Pro、Gemini 1.5 Flash和人类语料库生成）进行大规模比较分析，发现LLM生成的故事在网络属性（如密度、聚类和带符号边权重）方面表现出对紧密、积极关系的强烈偏见。

Conclusion: 所提出的基于网络分析的方法为评估当前和未来LLM在创意叙事方面的局限性和倾向性提供了一个有价值的工具。

Abstract: Evaluating the creative capabilities of large language models (LLMs) in
complex tasks often requires human assessments that are difficult to scale. We
introduce a novel, scalable methodology for evaluating LLM story generation by
analyzing underlying social structures in narratives as signed character
networks. To demonstrate its effectiveness, we conduct a large-scale
comparative analysis using networks from over 1,200 stories, generated by four
leading LLMs (GPT-4o, GPT-4o mini, Gemini 1.5 Pro, and Gemini 1.5 Flash) and a
human-written corpus. Our findings, based on network properties like density,
clustering, and signed edge weights, show that LLM-generated stories
consistently exhibit a strong bias toward tightly-knit, positive relationships,
which aligns with findings from prior research using human assessment. Our
proposed approach provides a valuable tool for evaluating limitations and
tendencies in the creative storytelling of current and future LLMs.

</details>


### [87] [Lost in the Maze: Overcoming Context Limitations in Long-Horizon Agentic Search](https://arxiv.org/abs/2510.18939)
*Howard Yen,Ashwin Paranjape,Mengzhou Xia,Thejas Venkatesh,Jack Hessel,Danqi Chen,Yuhao Zhang*

Main category: cs.CL

TL;DR: SLIM是一个新的框架，通过分离搜索和浏览工具并定期总结来解决长距离Agent搜索中的上下文限制问题，从而实现更长、更集中的搜索。


<details>
  <summary>Details</summary>
Motivation: 现有的Agent搜索框架在长距离搜索任务中难以扩展，主要是由于上下文限制，导致信息过载、超出预算或过早停止。

Method: SLIM框架将检索分解为独立的搜索和浏览工具，并定期对搜索轨迹进行总结，以保持上下文的简洁性，从而实现更长、更专注的搜索。

Result: 在长距离任务中，SLIM实现了与现有方法相当的性能，但成本显著降低，工具调用次数大大减少。在o3基础模型上，SLIM在BrowseComp上达到56%，在HLE上达到31%，分别比所有开源框架高出8和4个百分点，同时工具调用次数减少了4-6倍。此外，SLIM产生的幻觉比以前的系统少。

Conclusion: SLIM框架通过分离检索工具和定期总结，有效解决了长距离Agent搜索中的上下文限制问题，实现了在成本和效率方面的显著改进，并减少了幻觉。作者希望他们的分析框架和工具设计能为未来的长距离Agent提供参考。

Abstract: Long-horizon agentic search requires iteratively exploring the web over long
trajectories and synthesizing information across many sources, and is the
foundation for enabling powerful applications like deep research systems. In
this work, we show that popular agentic search frameworks struggle to scale to
long trajectories primarily due to context limitations-they accumulate long,
noisy content, hit context window and tool budgets, or stop early. Then, we
introduce SLIM (Simple Lightweight Information Management), a simple framework
that separates retrieval into distinct search and browse tools, and
periodically summarizes the trajectory, keeping context concise while enabling
longer, more focused searches. On long-horizon tasks, SLIM achieves comparable
performance at substantially lower cost and with far fewer tool calls than
strong open-source baselines across multiple base models. Specifically, with o3
as the base model, SLIM achieves 56% on BrowseComp and 31% on HLE,
outperforming all open-source frameworks by 8 and 4 absolute points,
respectively, while incurring 4-6x fewer tool calls. Finally, we release an
automated fine-grained trajectory analysis pipeline and error taxonomy for
characterizing long-horizon agentic search frameworks; SLIM exhibits fewer
hallucinations than prior systems. We hope our analysis framework and simple
tool design inform future long-horizon agents.

</details>


### [88] [ProfBench: Multi-Domain Rubrics requiring Professional Knowledge to Answer and Judge](https://arxiv.org/abs/2510.18941)
*Zhilin Wang,Jaehun Jung,Ximing Lu,Shizhe Diao,Ellie Evans,Jiaqi Zeng,Pavlo Molchanov,Yejin Choi,Jan Kautz,Yi Dong*

Main category: cs.CL

TL;DR: LLMs在处理专业文档和生成报告方面的评估工具ProfBench，可供社区使用。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在处理专业文档、综合信息和生成报告方面的能力，现有评估方法受限于验证响应的挑战。

Method: 构建包含7000多个由专业领域专家评估的响应-标准对的ProfBench数据集，并训练LLM-Judges来评估ProfBench标准，以降低成本并减少偏差。

Result: 现有LLM在ProfBench上表现出显著挑战，即使是GPT-5-high的整体性能也仅为65.9%。开源模型与闭源模型之间存在显著的性能差异，并且延长思考过程有助于处理复杂的专业领域任务。

Conclusion: ProfBench为评估LLM在专业领域的表现提供了新的基准，揭示了当前LLM的局限性，并强调了进一步研究的必要性。

Abstract: Evaluating progress in large language models (LLMs) is often constrained by
the challenge of verifying responses, limiting assessments to tasks like
mathematics, programming, and short-form question-answering. However, many
real-world applications require evaluating LLMs in processing professional
documents, synthesizing information, and generating comprehensive reports in
response to user queries. We introduce ProfBench: a set of over 7000
response-criterion pairs as evaluated by human-experts with professional
knowledge across Physics PhD, Chemistry PhD, Finance MBA and Consulting MBA. We
build robust and affordable LLM-Judges to evaluate ProfBench rubrics, by
mitigating self-enhancement bias and reducing the cost of evaluation by 2-3
orders of magnitude, to make it fair and accessible to the broader community.
Our findings reveal that ProfBench poses significant challenges even for
state-of-the-art LLMs, with top-performing models like GPT-5-high achieving
only 65.9\% overall performance. Furthermore, we identify notable performance
disparities between proprietary and open-weight models and provide insights
into the role that extended thinking plays in addressing complex,
professional-domain tasks. Data:
https://huggingface.co/datasets/nvidia/ProfBench and Code:
https://github.com/NVlabs/ProfBench

</details>


### [89] [Dynamic Evaluation for Oversensitivity in LLMs](https://arxiv.org/abs/2510.19005)
*Sophia Xiao Pu,Sitao Cheng,Xin Eric Wang,William Yang Wang*

Main category: cs.CL

TL;DR: 语言模型在面对无害提示时会过度反应，导致用户交互中断并模糊有害与无害内容的界限。现有基准测试依赖的静态数据集会随着模型演进而过时，造成数据污染和评估能力下降。为解决此问题，我们开发了一个动态生成模型特定挑战性数据集的框架，以捕捉新兴的防御模式并与各模型的独特行为保持一致。基于此方法，我们构建了 OVERBENCH，一个整合了来自 25 个模型、涵盖 450,000 个样本的跨 LLM 家族的基准测试。OVERBENCH 提供了对过度敏感性的动态、演进的视角，能够持续监控模型进步中的防御触发因素，并揭示静态数据集所忽略的漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试依赖于会随着模型演进而过时的静态数据集，导致数据污染和评估能力下降。为解决此问题，需要一个能够动态生成模型特定挑战性数据集的框架，以捕捉新兴的防御模式并与各模型的独特行为保持一致。

Method: 开发了一个动态生成模型特定挑战性数据集的框架，并构建了 OVERBENCH，一个整合了来自 25 个模型、涵盖 450,000 个样本的跨 LLM 家族的基准测试。

Result: OVERBENCH 提供了对过度敏感性的动态、演进的视角，能够持续监控模型进步中的防御触发因素，并揭示静态数据集所忽略的漏洞。

Conclusion: OVERBENCH 提供了一个动态且不断演进的基准测试，用于评估语言模型的过度敏感性，解决了现有静态基准测试的局限性。

Abstract: Oversensitivity occurs when language models defensively reject prompts that
are actually benign. This behavior not only disrupts user interactions but also
obscures the boundary between harmful and harmless content. Existing benchmarks
rely on static datasets that degrade overtime as models evolve, leading to data
contamination and diminished evaluative power. To address this, we develop a
framework that dynamically generates model-specific challenging datasets,
capturing emerging defensive patterns and aligning with each model's unique
behavior. Building on this approach, we construct OVERBENCH, a benchmark that
aggregates these datasets across diverse LLM families, encompassing 450,000
samples from 25 models. OVERBENCH provides a dynamic and evolving perspective
on oversensitivity, allowing for continuous monitoring of defensive triggers as
models advance, highlighting vulnerabilities that static datasets overlook.

</details>


### [90] [Are they lovers or friends? Evaluating LLMs' Social Reasoning in English and Korean Dialogues](https://arxiv.org/abs/2510.19028)
*Eunsu Kim,Junyeong Park,Juhyun Oh,Kiwoong Park,Seyoung Song,A. Seza Dogruoz,Najoung Kim,Alice Oh*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: As large language models (LLMs) are increasingly used in human-AI
interactions, their social reasoning capabilities in interpersonal contexts are
critical. We introduce SCRIPTS, a 1k-dialogue dataset in English and Korean,
sourced from movie scripts. The task involves evaluating models' social
reasoning capability to infer the interpersonal relationships (e.g., friends,
sisters, lovers) between speakers in each dialogue. Each dialogue is annotated
with probabilistic relational labels (Highly Likely, Less Likely, Unlikely) by
native (or equivalent) Korean and English speakers from Korea and the U.S.
Evaluating nine models on our task, current proprietary LLMs achieve around
75-80% on the English dataset, whereas their performance on Korean drops to
58-69%. More strikingly, models select Unlikely relationships in 10-25% of
their responses. Furthermore, we find that thinking models and chain-of-thought
prompting, effective for general reasoning, provide minimal benefits for social
reasoning and occasionally amplify social biases. Our findings reveal
significant limitations in current LLMs' social reasoning capabilities,
highlighting the need for efforts to develop socially-aware language models.

</details>


### [91] [Re:Member: Emotional Question Generation from Personal Memories](https://arxiv.org/abs/2510.19030)
*Zackary Rackauckas,Nobuaki Minematsu,Julia Hirschberg*

Main category: cs.CL

TL;DR: Re:Member系统利用用户个人视频和风格化语音提问，增强 L2 学习的情感投入和对话参与度。


<details>
  <summary>Details</summary>
Motivation: 探索情感表达、记忆驱动的互动如何支持更具吸引力的第二语言（L2）学习。

Method: 通过结合用户个人视频、风格化语音提问、情感语调与视觉内容对齐、WhisperX 抄本对齐、3 帧视觉采样以及 Style-BERT-VITS2 进行情感合成。

Result: Re:Member 系统能够通过情感化的语音和个人媒体内容，促进学习者进行情感回忆和对话式互动。

Conclusion: Re:Member 作为一个风格化的互动探针，强调了情感和个人媒体在以学习者为中心的教育技术中的作用。

Abstract: We present Re:Member, a system that explores how emotionally expressive,
memory-grounded interaction can support more engaging second language (L2)
learning. By drawing on users' personal videos and generating stylized spoken
questions in the target language, Re:Member is designed to encourage affective
recall and conversational engagement. The system aligns emotional tone with
visual context, using expressive speech styles such as whispers or late-night
tones to evoke specific moods. It combines WhisperX-based transcript alignment,
3-frame visual sampling, and Style-BERT-VITS2 for emotional synthesis within a
modular generation pipeline. Designed as a stylized interaction probe,
Re:Member highlights the role of affect and personal media in learner-centered
educational technologies.

</details>


### [92] [A Graph Signal Processing Framework for Hallucination Detection in Large Language Models](https://arxiv.org/abs/2510.19117)
*Valentin Noël*

Main category: cs.CL

TL;DR: 提出一种基于图信号处理的光谱分析框架，通过分析Transformer层注意力机制产生的动态图及其上的token嵌入信号，来区分大语言模型的事实推理和幻觉。


<details>
  <summary>Details</summary>
Motivation: 区分大语言模型的事实推理和幻觉是一个挑战。

Method: 将Transformer层建模为由注意力产生的动态图，token嵌入作为图上的信号，并利用图信号处理定义了包括Dirichlet能量、谱熵和高频能量比在内的诊断指标，并建立了与计算稳定性的理论联系。

Result: 在GPT架构上的实验表明，事实陈述表现出一致的“能量山”行为，低频收敛；不同类型的幻觉（逻辑矛盾、语义错误、替换幻觉）表现出不同的谱特征，如逻辑矛盾会破坏谱的稳定性，语义错误会导致连通性漂移，替换幻觉表现出中间扰动。基于谱特征的检测器准确率达到88.75%，优于基线模型。

Conclusion: 谱几何可能捕捉到推理模式和错误行为，为大语言模型的幻觉检测提供了一个潜在的框架。

Abstract: Large language models achieve impressive results but distinguishing factual
reasoning from hallucinations remains challenging. We propose a spectral
analysis framework that models transformer layers as dynamic graphs induced by
attention, with token embeddings as signals on these graphs. Through graph
signal processing, we define diagnostics including Dirichlet energy, spectral
entropy, and high-frequency energy ratios, with theoretical connections to
computational stability. Experiments across GPT architectures suggest universal
spectral patterns: factual statements exhibit consistent "energy mountain"
behavior with low-frequency convergence, while different hallucination types
show distinct signatures. Logical contradictions destabilize spectra with large
effect sizes ($g>1.0$), semantic errors remain stable but show connectivity
drift, and substitution hallucinations display intermediate perturbations. A
simple detector using spectral signatures achieves 88.75% accuracy versus 75%
for perplexity-based baselines, demonstrating practical utility. These findings
indicate that spectral geometry may capture reasoning patterns and error
behaviors, potentially offering a framework for hallucination detection in
large language models.

</details>


### [93] [When Can We Trust LLMs in Mental Health? Large-Scale Benchmarks for Reliable LLM Evaluation](https://arxiv.org/abs/2510.19032)
*Abeer Badawi,Elahe Rahimi,Md Tahmid Rahman Laskar,Sheri Grach,Lindsay Bertrand,Lames Danok,Jimmy Huang,Frank Rudzicz,Elham Dolatabadi*

Main category: cs.CL

TL;DR: 本研究提出了两个新的基准测试MentalBench-100k和MentalAlign-70k，旨在解决评估大型语言模型（LLMs）在心理健康支持方面的挑战，通过大规模真实对话数据集和评估LLM裁判的可靠性，为LLMs在心理健康领域的可靠、大规模评估奠定方法和实证基础。


<details>
  <summary>Details</summary>
Motivation: 现有的心理健康支持LLM评估基准在规模、可靠性方面存在局限，且缺乏评估自动化裁判可信度的框架。本研究旨在通过创建大规模对话数据集和评估裁判可靠性来解决这些问题。

Method: 本研究提出了两个基准测试：MentalBench-100k，包含10,000个真实场景下的单轮对话，每轮对话有9个LLM生成的回应，总共形成100,000个回应对；MentalAlign-70k，通过比较4个高性能LLM裁判与人类专家在70,000个评分上的一致性，这些评分涵盖了认知支持分数（CSS）和情感共鸣分数（ARS）七个属性。研究还采用了情感认知一致性框架（Affective Cognitive Agreement Framework），利用类内相关系数（ICC）量化LLM裁判与人类专家之间的一致性、可靠性和偏见。

Result: LLM裁判存在系统性评分虚高的问题。在评估中，LLM在引导性和信息性等认知属性方面表现出强可靠性，但在共情属性方面精确度较低，在安全性和相关性方面则存在一些不可靠性。

Conclusion: 本研究提出的MentalBench-100k和MentalAlign-70k基准测试以及情感认知一致性框架，为大规模、可靠地评估LLMs在心理健康领域的应用提供了新的方法和实证基础。研究结果揭示了LLM裁判在评估中的优势和局限性，为未来的研究和应用提供了重要参考。

Abstract: Evaluating Large Language Models (LLMs) for mental health support is
challenging due to the emotionally and cognitively complex nature of
therapeutic dialogue. Existing benchmarks are limited in scale, reliability,
often relying on synthetic or social media data, and lack frameworks to assess
when automated judges can be trusted. To address the need for large-scale
dialogue datasets and judge reliability assessment, we introduce two benchmarks
that provide a framework for generation and evaluation. MentalBench-100k
consolidates 10,000 one-turn conversations from three real scenarios datasets,
each paired with nine LLM-generated responses, yielding 100,000 response pairs.
MentalAlign-70k}reframes evaluation by comparing four high-performing LLM
judges with human experts across 70,000 ratings on seven attributes, grouped
into Cognitive Support Score (CSS) and Affective Resonance Score (ARS). We then
employ the Affective Cognitive Agreement Framework, a statistical methodology
using intraclass correlation coefficients (ICC) with confidence intervals to
quantify agreement, consistency, and bias between LLM judges and human experts.
Our analysis reveals systematic inflation by LLM judges, strong reliability for
cognitive attributes such as guidance and informativeness, reduced precision
for empathy, and some unreliability in safety and relevance. Our contributions
establish new methodological and empirical foundations for reliable,
large-scale evaluation of LLMs in mental health. We release the benchmarks and
codes at: https://github.com/abeerbadawi/MentalBench/

</details>


### [94] [Training-Free Spectral Fingerprints of Voice Processing in Transformers](https://arxiv.org/abs/2510.19131)
*Valentin Noël*

Main category: cs.CL

TL;DR: 不同Transformer架构通过不同的连接模式实现相同的语言计算，产生可通过谱分析检测到的计算指纹。通过对注意力诱导的Token图进行图信号处理，我们追踪了20种语言和三个模型系列中语音交替下的代数连通性（Fiedler值，Δλ2）的变化，重点关注早期窗口（第2-5层）。


<details>
  <summary>Details</summary>
Motivation: 探究不同Transformer架构在执行语言任务时，其内部计算模式的差异性，以及这些差异如何体现在模型结构和计算指纹上。

Method: 使用图信号处理技术，在注意力诱导的Token图上追踪语音交替过程中代数连通性（Fiedler值）的变化，并分析不同模型和语言下的差异。

Result: Phi-3-Mini在早期层对英语表现出显著的计算中断；Qwen2.5-7B的计算变化与形态丰富的语言相关；LLaMA-3.2-1B的响应则较弱但系统化。这些谱特征与行为差异高度相关，并可通过注意力头消融实验进行验证。

Conclusion: 训练重点会在模型中留下可检测的计算印记，表现为可衡量的连接模式。该框架不仅能揭示架构偏见，还能用于模型可靠性分析。

Abstract: Different transformer architectures implement identical linguistic
computations via distinct connectivity patterns, yielding model imprinted
``computational fingerprints'' detectable through spectral analysis. Using
graph signal processing on attention induced token graphs, we track changes in
algebraic connectivity (Fiedler value, $\Delta\lambda_2$) under voice
alternation across 20 languages and three model families, with a prespecified
early window (layers 2--5). Our analysis uncovers clear architectural
signatures: Phi-3-Mini shows a dramatic English specific early layer disruption
($\overline{\Delta\lambda_2}_{[2,5]}\!\approx\!-0.446$) while effects in 19
other languages are minimal, consistent with public documentation that
positions the model primarily for English use. Qwen2.5-7B displays small,
distributed shifts that are largest for morphologically rich languages, and
LLaMA-3.2-1B exhibits systematic but muted responses. These spectral signatures
correlate strongly with behavioral differences (Phi-3: $r=-0.976$) and are
modulated by targeted attention head ablations, linking the effect to early
attention structure and confirming functional relevance. Taken together, the
findings are consistent with the view that training emphasis can leave
detectable computational imprints: specialized processing strategies that
manifest as measurable connectivity patterns during syntactic transformations.
Beyond voice alternation, the framework differentiates reasoning modes,
indicating utility as a simple, training free diagnostic for revealing
architectural biases and supporting model reliability analysis.

</details>


### [95] [From Memorization to Generalization: Fine-Tuning Large Language Models for Biomedical Term-to-Identifier Normalization](https://arxiv.org/abs/2510.19036)
*Suswitha Pericharla,Daniel B. Hier,Tayo Obafemi-Ajayi*

Main category: cs.CL

TL;DR: 大型语言模型在生物医学术语归一化任务上表现不一，归一化效果受标识符流行度和词汇化程度影响。


<details>
  <summary>Details</summary>
Motivation: 生物医学数据集成依赖于自动术语归一化，即将自然语言术语映射到标准化标识符，以实现语义互操作性。虽然大型语言模型（LLMs）在此任务上显示出潜力，但其在不同术语库上的表现参差不齐。

Method: 评估了在多个生物医学本体库上，Llama 3.1 8B模型在记忆（训练术语性能）和泛化（验证术语性能）方面的表现。通过嵌入分析研究了基因符号、蛋白质名称与GO或HPO术语及标识符之间的语义对齐情况。

Result: Llama 3.1 8B模型在GO术语映射上表现出显著的记忆增强（准确率提高高达77%），但在HPO上提升甚微。只有在蛋白质-基因（GENE）映射上观察到泛化（提高13.9%），而在HPO和GO上的微调几乎没有泛化效果。GPT-4o在所有术语库上均优于Llama模型。嵌入分析显示，基因符号和蛋白质名称之间存在紧密的语义对齐，而GO或HPO的术语与标识符之间对齐较弱。

Conclusion: 微调效果取决于标识符的流行度和词汇化程度。高流行度标识符在预训练期间更容易被遇到，从而增强记忆。像基因符号这样的词汇化标识符能够实现语义泛化，而GO和HPO中任意的标识符则限制了模型的学习能力。研究结果提供了一个预测框架，用于判断微调何时能增强事实回忆，以及何时会因标识符稀疏或非词汇化而失败。

Abstract: Effective biomedical data integration depends on automated term
normalization, the mapping of natural language biomedical terms to standardized
identifiers. This linking of terms to identifiers is essential for semantic
interoperability. Large language models (LLMs) show promise for this task but
perform unevenly across terminologies. We evaluated both memorization
(training-term performance) and generalization (validation-term performance)
across multiple biomedical ontologies. Fine-tuning Llama 3.1 8B revealed marked
differences by terminology. GO mappings showed strong memorization gains (up to
77% improvement in term-to-identifier accuracy), whereas HPO showed minimal
improvement. Generalization occurred only for protein-gene (GENE) mappings
(13.9% gain), while fine-tuning for HPO and GO yielded negligible transfer.
Baseline accuracy varied by model scale, with GPT-4o outperforming both Llama
variants for all terminologies. Embedding analyses showed tight semantic
alignment between gene symbols and protein names but weak alignment between
terms and identifiers for GO or HPO, consistent with limited lexicalization.
Fine-tuning success depended on two interacting factors: identifier popularity
and lexicalization. Popular identifiers were more likely encountered during
pretraining, enhancing memorization. Lexicalized identifiers, such as gene
symbols, enabled semantic generalization. By contrast, arbitrary identifiers in
GO and HPO constrained models to rote learning. These findings provide a
predictive framework for when fine-tuning enhances factual recall versus when
it fails due to sparse or non-lexicalized identifiers.

</details>


### [96] [That's Deprecated! Understanding, Detecting, and Steering Knowledge Conflicts in Language Models for Code Generation](https://arxiv.org/abs/2510.19116)
*Jaesung Bae,Cameron Churchwell,Mitchell Hermon,Tsun-An Hsieh,Jocelyn Xu,Yekaterina Yegorova,Mark Hasegawa-Johnson,Heng Ji*

Main category: cs.CL

TL;DR: 大型语言模型（LLM）在面对其参数知识与提示中冲突信息之间的差异时，会被激活并能够被检测到，但需要仔细平衡模型大小、任务领域和引导方向。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探究大型语言模型（LLMs）在面对其内部参数知识与输入提示中冲突信息时的行为，并将此前的问答（QA）研究扩展到代码生成领域。

Method: 提出一个领域无关的框架来构建和解释知识冲突，并引入一种新颖的评估方法和针对代码冲突场景的数据集。通过实验来检测知识冲突，并研究激活层引导的有效性。

Result: 实验表明，足够大的LLM能够在其参数中编码知识冲突的概念，检测准确率高达80.65%。激活层引导可将引导成功率相比随机基线提高12.6%，但其有效性取决于模型大小、任务领域和引导方向的平衡。

Conclusion: LLMs能够识别参数知识与提示信息之间的冲突，并且可以通过激活层引导进行干预，但这种干预的有效性受到多种因素的制约。

Abstract: This paper investigates how large language models (LLMs) behave when faced
with discrepancies between their parametric knowledge and conflicting
information contained in a prompt. Building on prior question-answering (QA)
research, we extend the investigation of knowledge conflicts to the realm of
code generation. We propose a domain-agnostic framework for constructing and
interpreting such conflicts, along with a novel evaluation method and dataset
tailored to code conflict scenarios. Our experiments indicate that sufficiently
large LLMs encode the notion of a knowledge conflict in their parameters,
enabling us to detect knowledge conflicts with up to \textbf{80.65\%} accuracy.
Building on these insights, we show that activation-level steering can achieve
up to a \textbf{12.6\%} improvement in steering success over a random baseline.
However, effectiveness depends critically on balancing model size, task domain,
and steering direction. The experiment code and data will be made publicly
available after acceptance.

</details>


### [97] [Tibetan Language and AI: A Comprehensive Survey of Resources, Methods and Challenges](https://arxiv.org/abs/2510.19144)
*Cheng Huang,Nyima Tashi,Fan Gao,Yutong Liu,Jiahao Li,Hao Tian,Siyang Jiang,Thupten Tsering,Ban Ma-bao,Renzeg Duojie,Gadeng Luosang,Rinchen Dongrub,Dorje Tashi,Jin Zhang,Xiao Feng,Hao Wang,Jie Tang,Guojie Tang,Xiangxiang Wang,Jia Zhang,Tsengdar Lee,Yongbin Yu*

Main category: cs.CL

TL;DR: 本篇论文全面概述了藏语人工智能（AI）的现状，强调了数据稀疏、拼写变异和缺乏统一评估指标等挑战，并探讨了跨语言迁移、多模态学习和社区驱动资源创建等潜在解决方案。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏可访问的数据资源、标准化基准和专用工具，藏语（一种主要的亚洲低资源语言）在人工智能领域受到关注有限，但其独特的语言和社会文化特征带来了机遇和挑战。

Method: 对藏语人工智能的现有文本和语音数据资源、自然语言处理任务、机器翻译、语音识别以及大型语言模型的最新进展进行了全面的调查和系统性分类。

Result: 评估了不同任务中使用的各种方法，并在可能的情况下比较了性能，同时确定了数据稀疏、拼写变异和缺乏统一评估指标等持续存在的瓶颈。

Conclusion: 本调查旨在为未来的藏语人工智能研究奠定基础，并鼓励合作，为低资源语言构建包容和可持续的人工智能生态系统。

Abstract: Tibetan, one of the major low-resource languages in Asia, presents unique
linguistic and sociocultural characteristics that pose both challenges and
opportunities for AI research. Despite increasing interest in developing AI
systems for underrepresented languages, Tibetan has received limited attention
due to a lack of accessible data resources, standardized benchmarks, and
dedicated tools. This paper provides a comprehensive survey of the current
state of Tibetan AI in the AI domain, covering textual and speech data
resources, NLP tasks, machine translation, speech recognition, and recent
developments in LLMs. We systematically categorize existing datasets and tools,
evaluate methods used across different tasks, and compare performance where
possible. We also identify persistent bottlenecks such as data sparsity,
orthographic variation, and the lack of unified evaluation metrics.
Additionally, we discuss the potential of cross-lingual transfer, multi-modal
learning, and community-driven resource creation. This survey aims to serve as
a foundational reference for future work on Tibetan AI research and encourages
collaborative efforts to build an inclusive and sustainable AI ecosystem for
low-resource languages.

</details>


### [98] ["You Are Rejected!": An Empirical Study of Large Language Models Taking Hiring Evaluations](https://arxiv.org/abs/2510.19167)
*Dingjie Fu,Dianxing Shi*

Main category: cs.CL

TL;DR: LLMs在专业招聘考试中表现不佳，所有被评估的模型都未能通过。


<details>
  <summary>Details</summary>
Motivation: LLMs在编码和推理任务中表现出色，但它们能否通过软件工程师的招聘评估尚不清楚。

Method: 使用最先进的LLMs生成对广泛使用的专业招聘评估问卷的答案，并评估其表现。

Result: LLM生成的答案与公司参考的解决方案之间存在显著的不一致性。

Conclusion: 所有被评估的LLM都未能通过招聘评估，这表明它们不适合担任初级工程师职位。

Abstract: With the proliferation of the internet and the rapid advancement of
Artificial Intelligence, leading technology companies face an urgent annual
demand for a considerable number of software and algorithm engineers. To
efficiently and effectively identify high-potential candidates from thousands
of applicants, these firms have established a multi-stage selection process,
which crucially includes a standardized hiring evaluation designed to assess
job-specific competencies. Motivated by the demonstrated prowess of Large
Language Models (LLMs) in coding and reasoning tasks, this paper investigates a
critical question: Can LLMs successfully pass these hiring evaluations? To this
end, we conduct a comprehensive examination of a widely used professional
assessment questionnaire. We employ state-of-the-art LLMs to generate responses
and subsequently evaluate their performance. Contrary to any prior expectation
of LLMs being ideal engineers, our analysis reveals a significant inconsistency
between the model-generated answers and the company-referenced solutions. Our
empirical findings lead to a striking conclusion: All evaluated LLMs fails to
pass the hiring evaluation.

</details>


### [99] [Think Straight, Stop Smart: Structured Reasoning for Efficient Multi-Hop RAG](https://arxiv.org/abs/2510.19171)
*Jihwan Bang,Juntae Lee,Seunghan Yang,Sungha Choi*

Main category: cs.CL

TL;DR: TSSS框架通过结构化推理和基于检索器的终止来提高多跳检索增强生成的效率和稳定性，在HotpotQA等基准测试中实现了最先进的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的多跳检索增强生成（RAG）方法在复杂推理中效率低下，倾向于在每一步生成可预测的序列并依赖随机停止，导致过多的token消耗和不稳定的终止。

Method: TSSS框架引入了一种基于模板的推理方法，通过缓存重复的前缀并将子查询锚定到主问题来减少token生成成本并稳定推理过程。此外，它还使用一种基于检索器的终止机制，一旦子查询开始重复就确定性地停止推理。

Result: TSSS在HotpotQA、2WikiMultiHop和MuSiQue数据集上实现了最先进的准确率，并且在RAG-CoT方法中具有竞争力，证明了其在效率受限场景（如设备端推理）下的有效性。

Conclusion: TSSS通过分离结构化推理和终止控制，提高了多跳RAG的推理速度和答案的可靠性，是效率受限环境下的有效解决方案。

Abstract: Multi-hop retrieval-augmented generation (RAG) is a promising strategy for
complex reasoning, yet existing iterative prompting approaches remain
inefficient. They often regenerate predictable token sequences at every step
and rely on stochastic stopping, leading to excessive token usage and unstable
termination. We propose TSSS (Think Straight, Stop Smart), a structured
multi-hop RAG framework designed for efficiency. TSSS introduces (i) a
template-based reasoning that caches recurring prefixes and anchors sub-queries
to the main question, reducing token generation cost while promoting stable
reasoning, and (ii) a retriever-based terminator, which deterministically halts
reasoning once additional sub-queries collapse into repetition. This separation
of structured reasoning and termination control enables both faster inference
and more reliable answers. On HotpotQA, 2WikiMultiHop, and MuSiQue, TSSS
achieves state-of-the-art accuracy and competitive efficiency among RAG-CoT
approaches, highlighting its effectiveness in efficiency-constrained scenarios
such as on-device inference.

</details>


### [100] [When Facts Change: Probing LLMs on Evolving Knowledge with evolveQA](https://arxiv.org/abs/2510.19172)
*Nishanth Sridhar Nakshatri,Shamik Roy,Manoj Ghuhan Arivazhagan,Hanhan Zhou,Vinayshekhar Bannihatti Kumar,Rashmi Gangadharaiah*

Main category: cs.CL

TL;DR: LLMs在处理随时间演变的知识方面存在不足，现有基准测试存在局限性。本研究提出了evolveQA，一个包含AWS、Azure和WHO数据的动态基准，用于评估LLMs对时间知识冲突的处理能力，并展示了LLMs在此类任务上的性能下降。


<details>
  <summary>Details</summary>
Motivation: 现有研究未能充分评估LLMs处理时间知识冲突的能力，因为它们依赖于结构化知识库和流行实体，缺乏动态性以适应不同的知识截止日期。

Method: 构建了一个名为evolveQA的新基准，该基准使用来自AWS更新、Azure更改和WHO疾病爆发报告的三个真实、带时间戳的语料库。该框架能够识别自然发生知识演变并生成针对不同LLM知识截止日期的、带有正确答案的问题。对12个开源和闭源LLM进行了评估。

Result: 在evolveQA基准上，LLMs的性能相较于静态知识问题下降了高达31%，这表明LLMs在处理动态演变知识方面存在显著的挑战。

Conclusion: LLMs在处理随时间演变的知识方面存在显著的局限性，即使是先进的模型在面对知识冲突时也会表现出性能下降。evolveQA基准为更公平地评估LLMs处理动态知识的能力提供了一个新的视角。

Abstract: LLMs often fail to handle temporal knowledge conflicts--contradictions
arising when facts evolve over time within their training data. Existing
studies evaluate this phenomenon through benchmarks built on structured
knowledge bases like Wikidata, but they focus on widely-covered,
easily-memorized popular entities and lack the dynamic structure needed to
fairly evaluate LLMs with different knowledge cut-off dates. We introduce
evolveQA, a benchmark specifically designed to evaluate LLMs on temporally
evolving knowledge, constructed from 3 real-world, time-stamped corpora: AWS
updates, Azure changes, and WHO disease outbreak reports. Our framework
identifies naturally occurring knowledge evolution and generates questions with
gold answers tailored to different LLM knowledge cut-off dates. Through
extensive evaluation of 12 open and closed-source LLMs across 3 knowledge
probing formats, we demonstrate significant performance drops of up to 31% on
evolveQA compared to static knowledge questions.

</details>


### [101] [Interpretable Question Answering with Knowledge Graphs](https://arxiv.org/abs/2510.19181)
*Kartikeya Aneja,Manasvi Srivastava,Subhayan Das,Nagender Aneja*

Main category: cs.CL

TL;DR: 该论文提出了一种不依赖于检索增强生成（RAG）的大型语言模型（LLM）的知识图谱问答系统，使用小型释义模型来释义从知识图谱查询中检索到的实体关系边。


<details>
  <summary>Details</summary>
Motivation: 开发一种不依赖大型语言模型（LLM）进行检索增强生成（RAG）的问答系统，而是利用知识图谱进行信息检索。

Method: 该系统首先预处理文档以生成问答对，然后将这些问答对转换为知识图谱。接着，利用嵌入和模糊技术进行基于图谱的检索，查询、重新排序并释义知识图谱以生成最终答案。

Result: 在CRAG基准测试中，使用LLM-as-a-judge进行评估，使用LLAMA-3.2和GPT-3.5-Turbo的准确率分别为71.9%和54.4%。

Conclusion: 该方法证明了在不依赖LLM的RAG的情况下，通过知识图谱检索和释义，可以实现有效的问答。

Abstract: This paper presents a question answering system that operates exclusively on
a knowledge graph retrieval without relying on retrieval augmented generation
(RAG) with large language models (LLMs). Instead, a small paraphraser model is
used to paraphrase the entity relationship edges retrieved from querying the
knowledge graph. The proposed pipeline is divided into two main stages. The
first stage involves pre-processing a document to generate sets of
question-answer (QA) pairs. The second stage converts these QAs into a
knowledge graph from which graph-based retrieval is performed using embeddings
and fuzzy techniques. The graph is queried, re-ranked, and paraphrased to
generate a final answer. This work includes an evaluation using LLM-as-a-judge
on the CRAG benchmark, which resulted in accuracies of 71.9% and 54.4% using
LLAMA-3.2 and GPT-3.5-Turbo, respectively.

</details>


### [102] [Multi-Faceted Evaluation of Tool-Augmented Dialogue Systems](https://arxiv.org/abs/2510.19186)
*Zhaoyi Joey Hou,Tanya Shourya,Yingfan Wang,Shamik Roy,Vinayshekhar Bannihatti Kumar,Rashmi Gangadharaiah*

Main category: cs.CL

TL;DR: 现有的对话AI评估方法无法捕捉工具增强对话中的关键错误，因此引入了TRACE基准和SCOPE评估框架来解决这个问题。


<details>
  <summary>Details</summary>
Motivation: 评估使用外部工具的对话AI系统具有挑战性，因为错误可能源于用户、代理和工具之间的复杂交互。现有的评估方法（评估用户满意度或代理的工具调用能力）未能捕捉到多轮工具增强对话中的关键错误，例如代理误解工具结果但用户却满意。

Method: 引入TRACE，一个包含系统合成的工具增强对话的基准，涵盖了各种错误情况。引入 SCOPE，一个自动发现工具增强对话中各种错误模式和评估规则的评估框架。

Result: 实验表明，SCOPE 在检测复杂案例方面显著优于基线方法，尤其是在用户满意度信号具有误导性的情况下。

Conclusion: SCOPE 框架能够更有效地识别和评估工具增强对话中的关键错误。

Abstract: Evaluating conversational AI systems that use external tools is challenging,
as errors can arise from complex interactions among user, agent, and tools.
While existing evaluation methods assess either user satisfaction or agents'
tool-calling capabilities, they fail to capture critical errors in multi-turn
tool-augmented dialogues-such as when agents misinterpret tool results yet
appear satisfactory to users. We introduce TRACE, a benchmark of systematically
synthesized tool-augmented conversations covering diverse error cases, and
SCOPE, an evaluation framework that automatically discovers diverse error
patterns and evaluation rubrics in tool-augmented dialogues. Experiments show
SCOPE significantly outperforms the baseline, particularly on challenging cases
where user satisfaction signals are misleading.

</details>


### [103] [DiSRouter: Distributed Self-Routing for LLM Selections](https://arxiv.org/abs/2510.19208)
*Hang Zheng,Hongshen Xu,Yongkai Lin,Shuai Fan,Lu Chen,Kai Yu*

Main category: cs.CL

TL;DR: LLM查询路由可以通过分布式自路由（DiSRouter）得到改进，该系统利用LLM的自我认知能力来替代中心化路由器。


<details>
  <summary>Details</summary>
Motivation: 需要更灵活、可扩展和通用的LLM查询路由系统，以平衡性能和成本，因为现有的中心化路由系统不够灵活且性能不佳。

Method: 提出了一种名为DiSRouter（分布式自路由）的新范式，其中查询通过一系列LLM代理进行，每个代理根据其自我认知能力独立决定是自行回答还是路由到其他代理。通过一个两阶段的自我认知训练流程来增强LLM的自我认知能力。

Result: DiSRouter在各种场景下显著优于现有的路由方法，能有效区分简单和困难的查询，并对领域外任务表现出很强的泛化能力。

Conclusion: 利用LLM的内在自我认知比外部评估更有效，为构建更模块化、更高效的多代理系统铺平了道路。

Abstract: The proliferation of Large Language Models (LLMs) has created a diverse
ecosystem of models with highly varying performance and costs, necessitating
effective query routing to balance performance and expense. Current routing
systems often rely on a centralized external router trained on a fixed set of
LLMs, making them inflexible and prone to poor performance since the small
router can not fully understand the knowledge boundaries of different LLMs. We
introduce DiSRouter (Distributed Self-Router), a novel paradigm that shifts
from centralized control to distributed routing. In DiSRouter, a query
traverses a network of LLM agents, each independently deciding whether to
answer or route to other agents based on its own self-awareness, its ability to
judge its competence. This distributed design offers superior flexibility,
scalability, and generalizability. To enable this, we propose a two-stage
Self-Awareness Training pipeline that enhances each LLM's self-awareness.
Extensive experiments demonstrate that DiSRouter significantly outperforms
existing routing methods in utility across various scenarios, effectively
distinguishes between easy and hard queries, and shows strong generalization to
out-of-domain tasks. Our work validates that leveraging an LLM's intrinsic
self-awareness is more effective than external assessment, paving the way for
more modular and efficient multi-agent systems.

</details>


### [104] [Modality Matching Matters: Calibrating Language Distances for Cross-Lingual Transfer in URIEL+](https://arxiv.org/abs/2510.19217)
*York Hay Ng,Aditya Khan,Xiang Lu,Matteo Salloum,Michael Zhou,Phuong H. Hoang,A. Seza Doğruöz,En-Shiun Annie Lee*

Main category: cs.CL

TL;DR: 现有的语言知识库（如URIEL+）提供了有价值的地理、谱系和类型学距离，但存在表示单一和缺乏统一聚合方法的局限性。本文提出了一种类型匹配的语言距离框架，为地理、谱系和类型学距离引入了新颖的、结构感知的表示方法（分别为加权分布、双曲嵌入和潜在变量模型），并将这些信号统一为一种稳健的、与任务无关的复合距离。该框架在语言选择任务中，跨多种自然语言处理任务一致性地提高了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的语言知识库在表示方式和信号聚合方面存在局限性，无法有效处理多样化的语言数据结构，并且缺乏统一的聚合方法。

Method: 提出了一种类型匹配的语言距离框架，为地理距离引入了加权分布表示，为谱系距离引入了双曲嵌入表示，为类型学距离引入了潜在变量模型。然后，将这些信号统一成一个稳健的、与任务无关的复合距离。

Result: 所提出的表示方法和复合距离在选择迁移语言时，在广泛的自然语言处理任务中一致性地提高了性能。

Conclusion: 本文提出的类型匹配语言距离框架，通过引入结构感知的表示和统一的复合距离，为多语言研究提供了一个更合理、更有效的工具集。

Abstract: Existing linguistic knowledge bases such as URIEL+ provide valuable
geographic, genetic and typological distances for cross-lingual transfer but
suffer from two key limitations. One, their one-size-fits-all vector
representations are ill-suited to the diverse structures of linguistic data,
and two, they lack a principled method for aggregating these signals into a
single, comprehensive score. In this paper, we address these gaps by
introducing a framework for type-matched language distances. We propose novel,
structure-aware representations for each distance type: speaker-weighted
distributions for geography, hyperbolic embeddings for genealogy, and a latent
variables model for typology. We unify these signals into a robust,
task-agnostic composite distance. In selecting transfer languages, our
representations and composite distances consistently improve performance across
a wide range of NLP tasks, providing a more principled and effective toolkit
for multilingual research.

</details>


### [105] [SheetBrain: A Neuro-Symbolic Agent for Accurate Reasoning over Complex and Large Spreadsheets](https://arxiv.org/abs/2510.19247)
*Ziwei Wang,Jiayuan Su,Mengyu Zhou,Huaxing Zeng,Mengni Jia,Xiao Lv,Haoyu Dong,Xiaojun Ma,Shi Han,Dongmei Zhang*

Main category: cs.CL

TL;DR: SheetBrain是一个用于处理复杂电子表格的神经符号双工作流代理框架，提高了表格问答和操作任务的准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在理解和推理复杂电子表格方面存在挑战，难以准确捕捉表格结构和保证推理正确性。

Method: SheetBrain包含一个理解模块（生成电子表格概述和查询洞察）、一个执行模块（集成Python沙箱和Excel助手工具进行多轮推理）和一个验证模块（验证推理和答案的正确性，必要时触发重新执行）。

Result: SheetBrain在多个公开的表格问答和操作基准测试以及新的SheetBench基准测试中显著提高了准确性。

Conclusion: SheetBrain能够有效地处理复杂电子表格，并在各种表格问答和操作任务中取得优越的性能。

Abstract: Understanding and reasoning over complex spreadsheets remain fundamental
challenges for large language models (LLMs), which often struggle with
accurately capturing the complex structure of tables and ensuring reasoning
correctness. In this work, we propose SheetBrain, a neuro-symbolic dual
workflow agent framework designed for accurate reasoning over tabular data,
supporting both spreadsheet question answering and manipulation tasks.
SheetBrain comprises three core modules: an understanding module, which
produces a comprehensive overview of the spreadsheet - including sheet summary
and query-based problem insight to guide reasoning; an execution module, which
integrates a Python sandbox with preloaded table-processing libraries and an
Excel helper toolkit for effective multi-turn reasoning; and a validation
module, which verifies the correctness of reasoning and answers, triggering
re-execution when necessary. We evaluate SheetBrain on multiple public tabular
QA and manipulation benchmarks, and introduce SheetBench, a new benchmark
targeting large, multi-table, and structurally complex spreadsheets.
Experimental results show that SheetBrain significantly improves accuracy on
both existing benchmarks and the more challenging scenarios presented in
SheetBench. Our code is publicly available at
https://github.com/microsoft/SheetBrain.

</details>


### [106] [Difficulty-Controllable Multiple-Choice Question Generation Using Large Language Models and Direct Preference Optimization](https://arxiv.org/abs/2510.19265)
*Yuto Tomikawa,Masaki Uto*

Main category: cs.CL

TL;DR: 生成用于阅读理解的、可控难度的多项选择题。


<details>
  <summary>Details</summary>
Motivation: 目前的神经生成问题方法无法直接生成多项选择题，并且在控制题目难度方面有提升空间。

Method: 利用大型语言模型和直接偏好优化技术来生成可控难度的多项选择题。

Result: 提出了一种新颖的可控难度的多项选择题生成方法。

Conclusion: 该方法有望提高难度控制的准确性，更好地服务于教育自适应学习。

Abstract: Difficulty-controllable question generation for reading comprehension has
gained significant attention in the field of education as a fundamental tool
for adaptive learning support. Although several neural question generation
methods have recently succeeded in controlling difficulty, conventional
approaches still face two major limitations. First, they cannot directly
generate multiple-choice questions, which are the most widely used question
type in educational contexts. Second, they are not explicitly trained to
optimize the accuracy of difficulty control, leaving room for further
improvement in difficulty controllability. To address these limitations, this
study proposes a novel difficulty-controllable multiple-choice question
generation method for reading comprehension which leverages a large language
model trained using a direct preference optimization technique to improve the
accuracy of difficulty control.

</details>


### [107] [TheMCPCompany: Creating General-purpose Agents with Task-specific Tools](https://arxiv.org/abs/2510.19286)
*Reza Esfandiarpoor,Vishwas Suryanarayanan,Stephen H. Bach,Vishal Chowdhary,Anthony Aue*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Since the introduction of the Model Context Protocol (MCP), the number of
available tools for Large Language Models (LLMs) has increased significantly.
These task-specific tool sets offer an alternative to general-purpose tools
such as web browsers, while being easier to develop and maintain than GUIs.
However, current general-purpose agents predominantly rely on web browsers for
interacting with the environment. Here, we introduce TheMCPCompany, a benchmark
for evaluating tool-calling agents on tasks that involve interacting with
various real-world services. We use the REST APIs of these services to create
MCP servers, which include over 18,000 tools. We also provide manually
annotated ground-truth tools for each task. In our experiments, we use the
ground truth tools to show the potential of tool-calling agents for both
improving performance and reducing costs assuming perfect tool retrieval. Next,
we explore agent performance using tool retrieval to study the real-world
practicality of tool-based agents. While all models with tool retrieval perform
similarly or better than browser-based agents, smaller models cannot take full
advantage of the available tools through retrieval. On the other hand, GPT-5's
performance with tool retrieval is very close to its performance with
ground-truth tools. Overall, our work shows that the most advanced reasoning
models are effective at discovering tools in simpler environments, but
seriously struggle with navigating complex enterprise environments.
TheMCPCompany reveals that navigating tens of thousands of tools and combining
them in non-trivial ways to solve complex problems is still a challenging task
for current models and requires both better reasoning and better retrieval
models.

</details>


### [108] [JointCQ: Improving Factual Hallucination Detection with Joint Claim and Query Generation](https://arxiv.org/abs/2510.19310)
*Fan Xu,Huixuan Zhang,Zhenliang Zhang,Jiahao Wang,Xiaojun Wan*

Main category: cs.CL

TL;DR: LLM幻觉问题普遍，现有检测流程（分解、查询、检索、验证）在分解和查询阶段存在不足。本文提出JointCQ框架，联合生成声明和查询，优化了LLM幻觉检测的输入，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM幻觉检测方法在声明抽取和查询生成阶段存在上下文丢失、查询特异性低等问题，影响了整个检测流程的性能。

Method: 提出JointCQ框架，联合进行声明抽取和查询生成。该框架使用精心设计的评估标准来筛选合成的训练数据，并对语言模型进行微调，以生成可靠且信息丰富的输入，用于后续的搜索和验证。

Result: 在多个开放域问答幻觉检测基准测试中，本文提出的方法优于现有方法。

Conclusion: JointCQ框架能够生成有效的声明-查询对，为下游搜索和验证提供可靠信息，提升了LLM幻觉检测的性能，有助于实现更值得信赖和透明的语言模型系统。

Abstract: Current large language models (LLMs) often suffer from hallucination issues,
i,e, generating content that appears factual but is actually unreliable. A
typical hallucination detection pipeline involves response decomposition (i.e.,
claim extraction), query generation, evidence collection (i.e., search or
retrieval), and claim verification. However, existing methods exhibit
limitations in the first two stages, such as context loss during claim
extraction and low specificity in query generation, resulting in degraded
performance across the hallucination detection pipeline. In this work, we
introduce JointCQ https://github.com/pku0xff/JointCQ, a joint claim-and-query
generation framework designed to construct an effective and efficient
claim-query generator. Our framework leverages elaborately designed evaluation
criteria to filter synthesized training data, and finetunes a language model
for joint claim extraction and query generation, providing reliable and
informative inputs for downstream search and verification. Experimental results
demonstrate that our method outperforms previous methods on multiple
open-domain QA hallucination detection benchmarks, advancing the goal of more
trustworthy and transparent language model systems.

</details>


### [109] [KORE: Enhancing Knowledge Injection for Large Multimodal Models via Knowledge-Oriented Augmentations and Constraints](https://arxiv.org/abs/2510.19316)
*Kailin Jiang,Hongbo Jiang,Ning Jiang,Zhi Gao,Jinhe Bi,Yuchen Ren,Bin Li,Yuntao Du,Lei Liu,Qing Li*

Main category: cs.CL

TL;DR: KORE是一种用于大型多模态模型的新型知识注入方法，通过结构化数据增强和协方差矩阵约束来实现在学习新知识的同时保留旧知识，有效解决了灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 大型多模态模型（LMM）的知识是静态且有限的，无法跟上现实世界的发展，因此需要有效的知识注入方法来实现知识适应和知识保留，但现有方法在学习新知识和防止遗忘方面存在困难。

Method: KORE通过两种方式实现知识注入：1. 知识增强：将单个知识点转换为结构化、全面的知识，以确保模型准确学习新知识。2. 知识约束：将旧知识存储在LMM线性层激活的协方差矩阵中，并通过将原始权重投影到该矩阵的零空间来初始化适配器，从而确定一个能最大限度减少对旧知识干扰的微调方向。

Result: 在LLaVA-v1.5-7B、LLaVA-v1.5-13B和Qwen2.5-VL-7B等多个LMM上进行的广泛实验表明，KORE在注入新知识方面表现优越，并能有效缓解灾难性遗忘。

Conclusion: KORE是一种有效的知识注入方法，能够成功地将新知识注入大型多模态模型，同时保留旧知识，解决了现有方法在知识适应和灾难性遗忘方面存在的挑战。

Abstract: Large Multimodal Models encode extensive factual knowledge in their
pre-trained weights. However, its knowledge remains static and limited, unable
to keep pace with real-world developments, which hinders continuous knowledge
acquisition. Effective knowledge injection thus becomes critical, involving two
goals: knowledge adaptation (injecting new knowledge) and knowledge retention
(preserving old knowledge). Existing methods often struggle to learn new
knowledge and suffer from catastrophic forgetting. To address this, we propose
KORE, a synergistic method of KnOwledge-oRientEd augmentations and constraints
for injecting new knowledge into large multimodal models while preserving old
knowledge. Unlike general text or image data augmentation, KORE automatically
converts individual knowledge items into structured and comprehensive knowledge
to ensure that the model accurately learns new knowledge, enabling accurate
adaptation. Meanwhile, KORE stores previous knowledge in the covariance matrix
of LMM's linear layer activations and initializes the adapter by projecting the
original weights into the matrix's null space, defining a fine-tuning direction
that minimizes interference with previous knowledge, enabling powerful
retention. Extensive experiments on various LMMs, including LLaVA-v1.5-7B,
LLaVA-v1.5-13B, and Qwen2.5-VL-7B, show that KORE achieves superior new
knowledge injection performance and effectively mitigates catastrophic
forgetting.

</details>


### [110] [HAD: HAllucination Detection Language Models Based on a Comprehensive Hallucination Taxonomy](https://arxiv.org/abs/2510.19318)
*Fan Xu,Xinyu Hu,Zhenghan Yu,Li Lin,Xu Zhang,Yang Zhang,Wei Zhou,Jinjie Gu,Xiaojun Wan*

Main category: cs.CL

TL;DR: 该研究提出了一个全面的幻觉分类法（11类）和名为HAD的模型，用于集成幻觉检测、跨度级识别和纠正，并在多个NLG任务上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 自然语言生成（NLG）模型（尤其是大型语言模型）的广泛应用引发了对其输出可靠性和准确性的担忧，其中“幻觉”（生成看似合理但错误的信息）是一个关键挑战，因此幻觉检测变得至关重要。

Method: 研究提出了一个包含11个类别的综合性幻觉分类法，并开发了名为HAD（HAllucination Detection）的模型。该模型将幻觉检测、跨度级识别和纠正整合到单一的推理过程中。模型在约9万个样本的合成数据集上进行训练，并构建了一个包含2248个样本的测试集（HADTest）。

Result: 在同域和跨域测试集上的评估结果显示，HAD模型普遍优于现有基线，并在HaluEval、FactCHD和FaithBench等数据集上取得了最先进的成果，证明了其鲁棒性和通用性。

Conclusion: 所提出的HAD模型在幻觉检测、跨度级识别和纠正方面展现了优越的性能，并具有良好的鲁棒性和通用性，能够有效应对自然语言生成中的幻觉问题。

Abstract: The increasing reliance on natural language generation (NLG) models,
particularly large language models, has raised concerns about the reliability
and accuracy of their outputs. A key challenge is hallucination, where models
produce plausible but incorrect information. As a result, hallucination
detection has become a critical task. In this work, we introduce a
comprehensive hallucination taxonomy with 11 categories across various NLG
tasks and propose the HAllucination Detection (HAD) models
https://github.com/pku0xff/HAD, which integrate hallucination detection,
span-level identification, and correction into a single inference process.
Trained on an elaborate synthetic dataset of about 90K samples, our HAD models
are versatile and can be applied to various NLG tasks. We also carefully
annotate a test set for hallucination detection, called HADTest, which contains
2,248 samples. Evaluations on in-domain and out-of-domain test sets show that
our HAD models generally outperform the existing baselines, achieving
state-of-the-art results on HaluEval, FactCHD, and FaithBench, confirming their
robustness and versatility.

</details>


### [111] [Balancing Rewards in Text Summarization: Multi-Objective Reinforcement Learning via HyperVolume Optimization](https://arxiv.org/abs/2510.19325)
*Junjie Song,Yiwen Liu,Dapeng Li,Yin Sun,Shukun Fu,Siqi Chen,Yuji Cao*

Main category: cs.CL

TL;DR: 通过使用超体积优化（HVO）方法，我们提出了一种新颖的强化学习（RL）策略，用于同时优化文本摘要中的多个目标，并在实验中证明了其优越性，甚至使一个7B模型在摘要任务上表现与GPT-4相当。


<details>
  <summary>Details</summary>
Motivation: 文本摘要是一个需要同时优化一致性、连贯性、相关性和流畅性等多个目标且充满挑战性的任务。虽然大型语言模型（LLM）通过强化学习（RL）取得了显著的性能，但很少有研究关注通过基于LLM的RL来优化摘要的多目标问题。

Method: 提出了一种名为超体积优化（HVO）的新颖优化策略，该策略在RL的奖励过程中使用超体积方法动态调整组间得分，引导模型优化以逐步逼近帕累托前沿，从而在多个目标之间生成均衡的摘要。

Result: 在几个代表性的摘要数据集上的实验结果表明，我们的方法在总体得分上优于组相对策略优化（GRPO），并且在不同维度上表现出更均衡的性能。此外，通过HVO增强的7B基础模型在摘要任务上的表现与GPT-4相当，同时保持了更短的生成长度。

Conclusion: HVO是一种有效的多目标优化策略，可用于基于LLM的文本摘要，能够生成在多个目标上表现均衡的摘要，并能与最先进的模型（如GPT-4）相媲美。

Abstract: Text summarization is a crucial task that requires the simultaneous
optimization of multiple objectives, including consistency, coherence,
relevance, and fluency, which presents considerable challenges. Although large
language models (LLMs) have demonstrated remarkable performance, enhanced by
reinforcement learning (RL), few studies have focused on optimizing the
multi-objective problem of summarization through RL based on LLMs. In this
paper, we introduce hypervolume optimization (HVO), a novel optimization
strategy that dynamically adjusts the scores between groups during the reward
process in RL by using the hypervolume method. This method guides the model's
optimization to progressively approximate the pareto front, thereby generating
balanced summaries across multiple objectives. Experimental results on several
representative summarization datasets demonstrate that our method outperforms
group relative policy optimization (GRPO) in overall scores and shows more
balanced performance across different dimensions. Moreover, a 7B foundation
model enhanced by HVO performs comparably to GPT-4 in the summarization task,
while maintaining a shorter generation length. Our code is publicly available
at https://github.com/ai4business-LiAuto/HVO.git

</details>


### [112] [Slot Filling as a Reasoning Task for SpeechLLMs](https://arxiv.org/abs/2510.19326)
*Kadri Hacioglu,Manjunath K E,Andreas Stolcke*

Main category: cs.CL

TL;DR: 通过在语音大语言模型（speechLLM）中集成推理能力，我们改进了端到端的槽位填充任务。


<details>
  <summary>Details</summary>
Motivation: 旨在提高语音大语言模型在端到端槽位填充任务中的性能。

Method: 利用链式思考框架将槽位填充任务分解为多个推理步骤，创建推理数据集，并对speechLLM进行监督微调。实验比较了常规speechLLM和推理speechLLM，并测试了不同类型和规模的LLM作为基础模型。

Result: 通过引入推理步骤，模型性能得到提升。但主要为数学、逻辑和编程领域设计的推理文本LLM作为推理speechLLM的基础模型可能表现不佳。混合speechLLM（基于混合文本基础LLM，并同时保留直接和推理操作模式进行微调）比仅使用单一操作模式进行微调的模型性能更好。

Conclusion: 在语音大语言模型中集成推理能力，特别是采用混合操作模式，能够有效提升槽位填充任务的性能。

Abstract: We propose integration of reasoning into speech large language models
(speechLLMs) for the end-to-end slot-filling task. Inspired by the recent
development of reasoning LLMs, we use a chain-of-thought framework to decompose
the slot-filling task into multiple reasoning steps, create a reasoning dataset
and apply the supervised fine-tuning strategy to a speechLLM. We distinguish
between regular and reasoning speechLLMs and experiment with different types
and sizes of LLMs as their text foundation models. We demonstrate performance
improvements by introducing reasoning (intermediate) steps. However, we show
that a reasoning textual LLM developed mainly for math, logic and coding
domains might be inferior as a foundation model for a reasoning speechLLM. We
further show that hybrid speechLLMs, built on a hybrid text foundation LLM and
fine-tuned to preserve both direct and reasoning modes of operation, have
better performance than those fine-tuned employing only one mode of operation.

</details>


### [113] [Algorithmic Fairness in NLP: Persona-Infused LLMs for Human-Centric Hate Speech Detection](https://arxiv.org/abs/2510.19331)
*Ewelina Gajewska,Arda Derbent,Jaroslaw A Chudziak,Katarzyna Budzynska*

Main category: cs.CL

TL;DR: 本研究探讨了个性化大语言模型（Persona-LLMs）在仇恨言论检测中的应用，重点关注注释者身份与目标群体身份之间的共性或差异性如何影响模型的偏见和敏感度。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探讨如何通过个性化大语言模型来解决自动化仇恨言论检测中的偏见问题，特别是利用注释者身份信息来提高模型的公平性。

Method: 采用Google的Gemini和OpenAI的GPT-4.1-mini模型，并结合浅层提示和基于检索增强生成（RAG）的深度情境化提示两种个性化方法，分析了内群体和外群体注释者身份对模型检测性能和公平性的影响。

Result: 研究结果表明，将社会人口统计学属性整合到大语言模型中，可以有效解决仇恨言论检测中的偏见问题。

Conclusion: 个性化大语言模型在减少偏见方面具有潜力和局限性，为开发更公平的仇恨言论检测系统提供了宝贵的见解。

Abstract: In this paper, we investigate how personalising Large Language Models
(Persona-LLMs) with annotator personas affects their sensitivity to hate
speech, particularly regarding biases linked to shared or differing identities
between annotators and targets. To this end, we employ Google's Gemini and
OpenAI's GPT-4.1-mini models and two persona-prompting methods: shallow persona
prompting and a deeply contextualised persona development based on
Retrieval-Augmented Generation (RAG) to incorporate richer persona profiles. We
analyse the impact of using in-group and out-group annotator personas on the
models' detection performance and fairness across diverse social groups. This
work bridges psychological insights on group identity with advanced NLP
techniques, demonstrating that incorporating socio-demographic attributes into
LLMs can address bias in automated hate speech detection. Our results highlight
both the potential and limitations of persona-based approaches in reducing
bias, offering valuable insights for developing more equitable hate speech
detection systems.

</details>


### [114] [Local Obfuscation by GLINER for Impartial Context Aware Lineage: Development and evaluation of PII Removal system](https://arxiv.org/abs/2510.19346)
*Prakrithi Shivaprakash,Lekhansh Shukla,Animesh Mukherjee,Prabhat Chand,Pratima Murthy*

Main category: cs.CL

TL;DR: LOGICAL是一个高效、可本地部署的PII移除系统，基于微调的GLiNER模型，在临床记录PII移除任务上表现优于Gemini-Pro-2.5等大型语言模型，特别适合资源受限环境。


<details>
  <summary>Details</summary>
Motivation: 临床记录中的个人身份信息（PII）移除对于研究和AI开发至关重要，但现有的大型语言模型（LLMs）计算成本高昂且存在数据隐私风险，尤其是在资源受限的情况下。

Method: 开发了LOGICAL系统，该系统基于微调的GLiNER模型，并在1515份精神病院的临床文档上进行了训练和评估，定义了九类PII进行移除。使用modern-gliner-bi-large-v1.0模型，在2849个文本实例上进行微调，并在376个实例的测试集上进行评估，使用字符级精确率、召回率和F1分数，并与Azure NER、Presidio、Gemini-Pro-2.5和Llama-3.3-70B-Instruct进行了比较。

Result: 微调后的GLiNER模型在PII移除任务上表现出卓越的性能，总体微平均F1得分为0.980，显著优于Gemini-Pro-2.5（F1得分：0.845）。LOGICAL成功地完全净化了95%的文档，而次优解决方案为64%。该模型可以在没有专用GPU的标准笔记本电脑上高效运行。然而，2%的实体级假阴性率表明所有测试系统都需要人工审核。

Conclusion: 微调后的专用Transformer模型（如GLiNER）为从临床记录中移除PII提供了一种准确、计算高效且安全解决方案。这种“源头净化”的方法是资源密集型LLMs的一种实用替代方案，能够在保护数据隐私的前提下，特别是在资源受限的环境中，为研究和AI开发创建去标识化数据集。

Abstract: Removing Personally Identifiable Information (PII) from clinical notes in
Electronic Health Records (EHRs) is essential for research and AI development.
While Large Language Models (LLMs) are powerful, their high computational costs
and the data privacy risks of API-based services limit their use, especially in
low-resource settings. To address this, we developed LOGICAL (Local Obfuscation
by GLINER for Impartial Context-Aware Lineage), an efficient, locally
deployable PII removal system built on a fine-tuned Generalist and Lightweight
Named Entity Recognition (GLiNER) model. We used 1515 clinical documents from a
psychiatric hospital's EHR system. We defined nine PII categories for removal.
A modern-gliner-bi-large-v1.0 model was fine-tuned on 2849 text instances and
evaluated on a test set of 376 instances using character-level precision,
recall, and F1-score. We compared its performance against Microsoft Azure NER,
Microsoft Presidio, and zero-shot prompting with Gemini-Pro-2.5 and
Llama-3.3-70B-Instruct. The fine-tuned GLiNER model achieved superior
performance, with an overall micro-average F1-score of 0.980, significantly
outperforming Gemini-Pro-2.5 (F1-score: 0.845). LOGICAL correctly sanitised 95%
of documents completely, compared to 64% for the next-best solution. The model
operated efficiently on a standard laptop without a dedicated GPU. However, a
2% entity-level false negative rate underscores the need for human-in-the-loop
validation across all tested systems. Fine-tuned, specialised transformer
models like GLiNER offer an accurate, computationally efficient, and secure
solution for PII removal from clinical notes. This "sanitisation at the source"
approach is a practical alternative to resource-intensive LLMs, enabling the
creation of de-identified datasets for research and AI development while
preserving data privacy, particularly in resource-constrained environments.

</details>


### [115] [Modeling Turn-Taking with Semantically Informed Gestures](https://arxiv.org/abs/2510.19350)
*Varsha Suresh,M. Hamza Mughal,Christian Theobalt,Vera Demberg*

Main category: cs.CL

TL;DR: 手势增强了多方对话中的轮次预测


<details>
  <summary>Details</summary>
Motivation: 手势可以为多方对话中的轮次预测提供语言和声学特征之外的补充线索。

Method: 使用包含2,663个语义手势注释（包括图像、隐喻、指示和话语类型）的DnD Gesture++数据集，通过集成文本、音频和手势的专家混合模型来预测轮次。

Result: 实验表明，结合语义引导的手势可以持续提高轮次预测的性能，并且比不使用手势的基线模型更优。

Conclusion: 语义引导的手势在多方对话的轮次预测中起着补充作用，可以提升模型的预测性能。

Abstract: In conversation, humans use multimodal cues, such as speech, gestures, and
gaze, to manage turn-taking. While linguistic and acoustic features are
informative, gestures provide complementary cues for modeling these
transitions. To study this, we introduce DnD Gesture++, an extension of the
multi-party DnD Gesture corpus enriched with 2,663 semantic gesture annotations
spanning iconic, metaphoric, deictic, and discourse types. Using this dataset,
we model turn-taking prediction through a Mixture-of-Experts framework
integrating text, audio, and gestures. Experiments show that incorporating
semantically guided gestures yields consistent performance gains over
baselines, demonstrating their complementary role in multimodal turn-taking.

</details>


### [116] [M3-SLU: Evaluating Speaker-Attributed Reasoning in Multimodal Large Language Models](https://arxiv.org/abs/2510.19358)
*Yejin Kwon,Taewoo Kang,Hyunsoo Yoon,Changouk Kim*

Main category: cs.CL

TL;DR: M3-SLU是一个包含4个开放语料库的多模态大语言模型基准，用于评估多说话人、多轮对话的语音语言理解能力，重点关注说话人归因推理。


<details>
  <summary>Details</summary>
Motivation: 现有语音和文本理解模型在理解对话中‘谁在何时说了什么’方面存在不足，尤其是在说话人归因推理方面。

Method: 构建了一个包含4个开放语料库（CHiME-6, MELD, MultiDialog, AMI）的M3-SLU基准，包含超过12,000个实例，并设置了说话人归因问答和说话人归因-语句匹配两个任务。评估了级联模型和端到端多模态大语言模型，并使用了LLM-as-Judge和准确率指标。

Result: 现有模型在理解‘说了什么’方面表现尚可，但在识别‘谁说的’方面存在困难，表明在说话人感知对话理解方面存在显著差距。

Conclusion: M3-SLU是一个具有挑战性的基准，旨在推动说话人感知多模态理解领域的研究进展。

Abstract: We present M3-SLU, a new multimodal large language model (MLLM) benchmark for
evaluating multi-speaker, multi-turn spoken language understanding. While
recent models show strong performance in speech and text comprehension, they
still struggle with speaker-attributed reasoning, the ability to understand who
said what and when in natural conversations. M3-SLU is built from four open
corpora (CHiME-6, MELD, MultiDialog, and AMI) and comprises over 12,000
validated instances with paired audio, transcripts, and metadata. It includes
two tasks: (1) Speaker-Attributed Question Answering and (2) Speaker
Attribution via Utterance Matching. We provide baseline results for both
cascaded pipelines and end-to-end MLLMs, evaluated using an LLM-as-Judge and
accuracy metrics. Results show that while models can capture what was said,
they often fail to identify who said it, revealing a key gap in speaker-aware
dialogue understanding. M3-SLU offers as a challenging benchmark to advance
research in speaker-aware multimodal understanding.

</details>


### [117] [AgenticMath: Enhancing LLM Reasoning via Agentic-based Math Data Generation](https://arxiv.org/abs/2510.19361)
*Xianyang Liu,Yilin Liu,Shuai Wang,Hao Cheng,Andrew Estornell,Yuzhi Zhao,Jiaheng Wei*

Main category: cs.CL

TL;DR: AgenticMath是一个创新的代理式流程，通过多阶段生成高质量的数学问答对，有效提升LLM的数学推理能力，相比大规模低质量数据，在有限数据量下表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有LLM的数学推理能力受限于低质量/不正确的答案和数据信息贫乏，需要更高质量的数据集来提升。中

Method: AgenticMath流程包含四个阶段：1. 种子问题筛选（选择信息丰富、复杂、清晰的问题）；2. 代理式问题改写（使用多代理系统生成多样化、逻辑一致的释义）；3. 答案增强（利用思维链推理重写答案，提高数值和逻辑准确性，无需人工标注）；4. 问题和答案评估（筛选最优问答对）。

Result: 在3B-8B参数的LLM上，使用AgenticMath生成的30K-60K数学样本进行微调，在多样的域内和域外数学推理基准上，性能可与甚至优于在400K或2.3M样本等更大规模数据集上训练的基线模型。

Conclusion: 针对性地生成高质量数据比大规模低质量数据更能有效地提升LLM的数学推理能力。

Abstract: The creation of high-quality datasets to improve Large Language Model (LLM)
reasoning remains a significant challenge, as current methods often suffer from
generating low-quality/incorrect answers and limited information richness from
available data sources. To address this, we propose AgenticMath, a novel
agentic pipeline for generating high-quality mathematical question-answer pairs
to enhance the supervised fine-tuning of LLMs. Our method operates through four
stages: (1) Seed Question Filter that selects questions with high information
richness, complexity, and clarity; (2) an Agentic Question Rephrase step that
employs a multi-agent system to generate diverse, logically consistent
paraphrases; (3) an Answer Augment step where rewrite answers using
chain-of-thought reasoning to enhance numerical and logical correctness,
without reliance on human-provided labels; and (4) a final Question and Answer
Evaluation that retains only the most superior pairs. Extensive experiments
demonstrate that, fine-tuning 3B-8B parameter LLMs on AgenticMath generated
datasets (comprising only 30-60K math samples) achieves competitive or superior
performance on diverse in domain and out-of-domain mathematical reasoning
benchmarks compared to baselines trained on much more data (e.g., 400K or 2.3M
samples). Our work demonstrates that targeted, high-quality data generation is
a more efficient path to improving mathematical reasoning in LLMs than
large-scale, low-quality alternatives.

</details>


### [118] [LoongRL:Reinforcement Learning for Advanced Reasoning over Long Contexts](https://arxiv.org/abs/2510.19363)
*Siyuan Wang,Gaokai Zhang,Li Lyna Zhang,Ning Shang,Fan Yang,Dongyao Chen,Mao Yang*

Main category: cs.CL

TL;DR: LoongRL是一种数据驱动的强化学习方法，通过KeyChain合成技术，将短上下文问答转化为高难度长上下文任务，从而提升大型语言模型在长上下文推理方面的能力。该方法在Qwen2.5-7B和14B模型上取得了显著的性能提升，并在长上下文检索和各种测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 长上下文推理对于大型语言模型至关重要，但现有方法在处理高难度长上下文推理方面存在不足，且相关强化学习数据稀缺。

Method: LoongRL方法的核心是KeyChain，一种通过插入UUID链来隐藏真实问题、增加干扰文档的技术，将短上下文多跳问答转化为高难度长上下文任务。模型需要逐步追踪正确链条、识别真实问题、检索相关事实并进行推理。通过在KeyChain数据上进行强化学习训练，模型能够形成一种‘规划-检索-推理-复查’的涌现式推理模式。

Result: LoongRL在Qwen2.5-7B和14B模型上将长上下文多跳问答的准确率分别提高了+23.5%和+21.1%。训练长度为16K的模型能够有效解决128K长度的任务，且没有高昂的全面回滚成本。LoongRL-14B模型的得分达到74.2，可与o3-mini (74.5) 和DeepSeek-R1 (74.9) 等更大规模模型相媲美。此外，该方法还改善了长上下文检索能力，通过了所有128K的needle-in-a-haystack压力测试，并保留了短上下文的推理能力。

Conclusion: LoongRL通过KeyChain数据驱动的强化学习，成功实现了高效的长上下文推理，显著提升了模型在处理长文本时的理解和回答能力，并达到了与当前领先模型相媲美的性能水平。

Abstract: Reasoning over long contexts is essential for large language models. While
reinforcement learning (RL) enhances short-context reasoning by inducing "Aha"
moments in chain-of-thought, the advanced thinking patterns required for
long-context reasoning remain largely unexplored, and high-difficulty RL data
are scarce. In this paper, we introduce LoongRL, a data-driven RL method for
advanced long-context reasoning. Central to LoongRL is KeyChain, a synthesis
approach that transforms short multi-hop QA into high-difficulty long-context
tasks by inserting UUID chains that hide the true question among large
collections of distracting documents. Solving these tasks requires the model to
trace the correct chain step-by-step, identify the true question, retrieve
relevant facts and reason over them to answer correctly. RL training on
KeyChain data induces an emergent plan-retrieve-reason-recheck reasoning
pattern that generalizes far beyond training length. Models trained at 16K
effectively solve 128K tasks without prohibitive full-length RL rollout costs.
On Qwen2.5-7B and 14B, LoongRL substantially improves long-context multi-hop QA
accuracy by +23.5% and +21.1% absolute gains. The resulting LoongRL-14B reaches
a score of 74.2, rivaling much larger frontier models such as o3-mini (74.5)
and DeepSeek-R1 (74.9). It also improves long-context retrieval, passes all
128K needle-in-a-haystack stress tests, and preserves short-context reasoning
capabilities.

</details>


### [119] [The Massive Legal Embedding Benchmark (MLEB)](https://arxiv.org/abs/2510.19365)
*Umar Butler,Abdur-Rahman Butler,Adrian Lucas Malec*

Main category: cs.CL

TL;DR: MLEB 是一个包含十个跨司法管辖区、多种文档类型和任务类型的法律信息检索数据集的基准，旨在填补开源法律信息检索领域的空白。


<details>
  <summary>Details</summary>
Motivation: 构建一个大规模、多样化且全面的开源法律信息检索基准，以填补现有研究中在领域和司法管辖区方面的空白。

Method: 构建了 Massive Legal Embedding Benchmark (MLEB)，该基准包含十个由专家注释的数据集，涵盖了美国、英国、欧盟、澳大利亚、爱尔兰和新加坡等司法管辖区，以及案例、法规、监管指南、合同和文献等文档类型，并支持搜索、零样本分类和问答等任务类型。其中七个数据集是新构建的。

Result: 发布了 MLEB，这是迄今为止最大、最多样化、最全面的开源法律信息检索基准。同时，公开了构建 MLEB 及其数据集的方法、代码、结果和数据，以支持可复现的评估。

Conclusion: MLEB 的发布为法律信息检索领域提供了一个重要的资源，有助于推动该领域的研究和发展，并促进可复现的评估。

Abstract: We present the Massive Legal Embedding Benchmark (MLEB), the largest, most
diverse, and most comprehensive open-source benchmark for legal information
retrieval to date. MLEB consists of ten expert-annotated datasets spanning
multiple jurisdictions (the US, UK, EU, Australia, Ireland, and Singapore),
document types (cases, legislation, regulatory guidance, contracts, and
literature), and task types (search, zero-shot classification, and question
answering). Seven of the datasets in MLEB were newly constructed in order to
fill domain and jurisdictional gaps in the open-source legal information
retrieval landscape. We document our methodology in building MLEB and creating
the new constituent datasets, and release our code, results, and data openly to
assist with reproducible evaluations.

</details>


### [120] [MoE-Prism: Disentangling Monolithic Experts for Elastic MoE Services via Model-System Co-Designs](https://arxiv.org/abs/2510.19366)
*Xinfeng Xia,Jiacheng Liu,Xiaofeng Hou,Peng Tang,Mingxuan Zhang,Wenfeng Wang,Chao Li*

Main category: cs.CL

TL;DR: MoE-Prism通过将大型AI模型中的单体专家分解为更小的子专家，并结合感知服务质量的调度策略，实现了模型和系统的协同设计，从而提高了模型的灵活性和效率，使其能够适应不同的服务质量目标。


<details>
  <summary>Details</summary>
Motivation: 现有的混合专家（MoE）模型虽然在大型AI领域表现出色，但其固定的专家路由机制导致了“质量悬崖”问题，使得模型在成本和质量之间难以平衡，无法适应多样化的服务水平目标（SLOs），并造成资源浪费。本研究旨在解决这一问题，使MoE模型能够提供更灵活、更具成本效益的服务。

Method: 本研究提出了MoE-Prism模型-系统协同设计方法，分为两个阶段：1. 离线重构引擎：通过使用基于元启发式方法的优化求解器，将单体专家分解为细粒度的“子专家”，同时保持功能局部性，无需重新训练。2. 在线调度引擎：利用新获得的弹性，通过感知服务质量（QoS）的调度策略，解决云部署中的吞吐量最大化和内存受限设备上的延迟优化卸载等系统问题。

Result: 在三种不同的MoE模型上的评估表明，MoE-Prism相比基线模型提供了超过4倍的离散、稳定的操作点。这使得AI服务能够在严格的延迟预算下动态地将吞吐量提高多达19.9%，或者在资源受限的情况下将延迟降低多达10.36%。

Conclusion: MoE-Prism通过模型重构和智能调度，有效地弥合了模型和系统之间的差距，为下一代自适应、高效且具备服务质量感知能力的AI服务提供了关键的“控制旋钮”，解决了现有MoE模型在灵活性和资源利用方面的挑战。

Abstract: Mixture-of-Experts (MoE) models, the state-of-the-art in large-scale AI,
achieve high quality by sparsely activating parameters. However, their reliance
on routing between a few monolithic experts via a top-k mechanism creates a
"quality cliff", offering only a few coarse-grained operating points. This
inflexibility forces a difficult trade-off between cost and quality, preventing
adaptation to diverse Service Level Objectives (SLOs) and leading to
significant resource over-provisioning.
  This paper introduces MoE-Prism, a model-system co-design that transforms
rigid MoE models into elastic services. Our methodology is divided into two
phases. First, an \emph{Offline Refactoring Engine} systematically deconstructs
monolithic experts into fine-grained "sub-experts." This engine employs a
partitioning optimization solver that uses a metaheuristic-based approach to
group neurons, preserving functional locality without requiring retraining.
Second, an \emph{Online Scheduling Engine} leverages this new elasticity
through QoS-aware scheduling. It implements specialized policies to solve
complex system problems, including maximizing throughput in cloud deployments
and managing latency-optimized offloading for memory-constrained devices. Our
evaluation across three different MoE models shows that MoE-Prismprovides over
4 times more distinct, stable operating points than the baseline. This allows
an AI service to dynamically improve throughput by up to 19.9\% under a strict
latency budget or reduce latency by up to 10.36\% under limited resources.
MoE-Prism provides the critical "control knob" to bridge the model-system gap,
enabling the next generation of adaptive, efficient, and QoS-aware AI services.

</details>


### [121] [Sign Language Translation with Sentence Embedding Supervision](https://arxiv.org/abs/2510.19367)
*Yasser Hamidullah,Josef van Genabith,Cristina España-Bonet*

Main category: cs.CL

TL;DR: 文章提出了一种新的手语翻译方法，使用目标句子的句子嵌入作为训练时的替代标签，无需手动标注，并能在多语言环境下有效运行，在缺少词汇标注的数据集上取得了最新的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的手语翻译系统依赖于词汇标注，但这类数据稀缺且不统一。文章旨在解决这一问题，提出一种无需词汇标注的新方法。

Method: 提出了一种使用句子嵌入作为训练时替代标签的新方法，该方法可以直接从原始文本数据中学习，并支持多语言翻译。

Result: 该方法在德语和美语手语翻译数据集上进行了评估，显著优于其他无词汇标注的方法，并在缺少词汇标注的情况下设定了新的最优水平。

Conclusion: 文章提出的基于句子嵌入的方法是一种有效的无词汇标注手语翻译方案，能够缩小与依赖词汇标注的系统的性能差距，尤其是在缺乏标注数据的情况下。

Abstract: State-of-the-art sign language translation (SLT) systems facilitate the
learning process through gloss annotations, either in an end2end manner or by
involving an intermediate step. Unfortunately, gloss labelled sign language
data is usually not available at scale and, when available, gloss annotations
widely differ from dataset to dataset. We present a novel approach using
sentence embeddings of the target sentences at training time that take the role
of glosses. The new kind of supervision does not need any manual annotation but
it is learned on raw textual data. As our approach easily facilitates
multilinguality, we evaluate it on datasets covering German (PHOENIX-2014T) and
American (How2Sign) sign languages and experiment with mono- and multilingual
sentence embeddings and translation systems. Our approach significantly
outperforms other gloss-free approaches, setting the new state-of-the-art for
data sets where glosses are not available and when no additional SLT datasets
are used for pretraining, diminishing the gap between gloss-free and
gloss-dependent systems.

</details>


### [122] [SONAR-SLT: Multilingual Sign Language Translation via Language-Agnostic Sentence Embedding Supervision](https://arxiv.org/abs/2510.19398)
*Yasser Hamidullah,Shakib Yazdani,Cennet Oguz,Josef van Genabith,Cristina España-Bonet*

Main category: cs.CL

TL;DR: 该研究提出了一种新颖的、与语言无关的多模态嵌入方法，用于手语翻译（SLT），以克服传统方法的局限性，并提高了在低资源场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的手语翻译（SLT）方法受限于单一的口语，限制了其可扩展性和跨语言的泛化能力。现有的基于文本的句子嵌入方法也未能摆脱特定语言和模态的束缚。

Method: 提出了一种语言无关的、多模态的嵌入方法，该方法使用多种语言的文本和语音进行训练，用于监督SLT。为了解决数据稀缺问题，提出了一种耦合增强方法，结合了多语言目标增强（即翻译成多种语言）和视频级扰动，以提高模型的鲁棒性。

Result: 实验结果显示，与仅使用文本的句子嵌入监督相比，BLEURT得分一致提高，尤其是在低资源环境下，改进更为显著。

Conclusion: 研究证明，语言无关的嵌入监督方法结合耦合增强方法，为传统的SLT训练提供了一种可扩展且在语义上更鲁棒的替代方案。

Abstract: Sign language translation (SLT) is typically trained with text in a single
spoken language, which limits scalability and cross-language generalization.
Earlier approaches have replaced gloss supervision with text-based sentence
embeddings, but up to now, these remain tied to a specific language and
modality. In contrast, here we employ language-agnostic, multimodal embeddings
trained on text and speech from multiple languages to supervise SLT, enabling
direct multilingual translation. To address data scarcity, we propose a coupled
augmentation method that combines multilingual target augmentations (i.e.
translations into many languages) with video-level perturbations, improving
model robustness. Experiments show consistent BLEURT gains over text-only
sentence embedding supervision, with larger improvements in low-resource
settings. Our results demonstrate that language-agnostic embedding supervision,
combined with coupled augmentation, provides a scalable and semantically robust
alternative to traditional SLT training.

</details>


### [123] [ToMMeR -- Efficient Entity Mention Detection from Large Language Models](https://arxiv.org/abs/2510.19410)
*Victor Morand,Nadi Tomeh,Josiane Mothe,Benjamin Piwowarski*

Main category: cs.CL

TL;DR: ToMMeR是一个轻量级模型，能够从早期LLM层探测mention检测能力，在13个NER基准测试中实现了93%的零样本召回率，并显示出其很少产生虚假预测。


<details>
  <summary>Details</summary>
Motivation: Mention detection是信息抽取的基础，同时也是一个已知的性能瓶颈。

Method: ToMMeR是一个轻量级模型（<300K参数），通过探测早期LLM层来识别文本中的实体提及（mention detection）。

Result: 在13个NER基准测试中，ToMMeR实现了93%的零样本召回率，使用LLM作为裁判时精确率超过90%，表明其很少产生虚假预测。跨模型分析显示，不同规模的模型在mention边界的识别上具有高度一致性（DICE >75%），并且当加入span分类头时，ToMMeR在标准基准测试上的NER性能接近SOTA（80-87% F1）。

Conclusion: 结构化的实体表示存在于Transformer早期层中，并且可以通过少量参数高效地恢复，ToMMeR提供的证据支持了这一点。

Abstract: Identifying which text spans refer to entities -- mention detection -- is
both foundational for information extraction and a known performance
bottleneck. We introduce ToMMeR, a lightweight model (<300K parameters) probing
mention detection capabilities from early LLM layers. Across 13 NER benchmarks,
ToMMeR achieves 93\% recall zero-shot, with over 90\% precision using an LLM as
a judge showing that ToMMeR rarely produces spurious predictions despite high
recall. Cross-model analysis reveals that diverse architectures (14M-15B
parameters) converge on similar mention boundaries (DICE >75\%), confirming
that mention detection emerges naturally from language modeling. When extended
with span classification heads, ToMMeR achieves near SOTA NER performance
(80-87\% F1 on standard benchmarks). Our work provides evidence that structured
entity representations exist in early transformer layers and can be efficiently
recovered with minimal parameters.

</details>


### [124] [Spatio-temporal Sign Language Representation and Translation](https://arxiv.org/abs/2510.19413)
*Yasser Hamidullah,Josef van Genabith,Cristina España-Bonet*

Main category: cs.CL

TL;DR: DFKI-MLT提出了一个端到端的的 sign language translation (SLT) 系统，用于瑞士德语手语到德语文本的翻译。该系统能够学习时空特征表示，并在一个模型中进行翻译，但性能在测试集上不佳。


<details>
  <summary>Details</summary>
Motivation: 使用通用的 seq2seq 架构和定制的输入嵌入来解决 SLT 任务，但标准方法未能有效利用时序特征。

Method: 提出一个单一模型，能够学习时空特征表示和翻译，实现端到端架构，以期更好地泛化到新的数据集。

Result: 在开发集上取得了 $5	ext{±}1$ BLEU 分，但在测试集上的性能下降到 $0.11	ext{±}0.06$ BLEU 分。

Conclusion: 尽管提出了一个端到端的系统，但其在测试集上的性能不佳，表明在 SLT 领域仍有改进空间。

Abstract: This paper describes the DFKI-MLT submission to the WMT-SLT 2022 sign
language translation (SLT) task from Swiss German Sign Language (video) into
German (text). State-of-the-art techniques for SLT use a generic seq2seq
architecture with customized input embeddings. Instead of word embeddings as
used in textual machine translation, SLT systems use features extracted from
video frames. Standard approaches often do not benefit from temporal features.
In our participation, we present a system that learns spatio-temporal feature
representations and translation in a single model, resulting in a real
end-to-end architecture expected to better generalize to new data sets. Our
best system achieved $5\pm1$ BLEU points on the development set, but the
performance on the test dropped to $0.11\pm0.06$ BLEU points.

</details>


### [125] [BLiSS 1.0: Evaluating Bilingual Learner Competence in Second Language Small Language Models](https://arxiv.org/abs/2510.19419)
*Yuan Gao,Suchir Salhan,Andrew Caines,Paula Buttery,Weiwei Sun*

Main category: cs.CL

TL;DR: BLiSS 1.0是一个基准测试，用于评估认知启发的语言学习模型，通过测试模型对自然语言错误而非人工错误的容忍度来衡量模型与人类语言习得模式的一致性。


<details>
  <summary>Details</summary>
Motivation: 为了弥合面向性能的基准测试与认知启发模型的评估之间的差距。

Method: 引入BLiSS 1.0，一个学习者跨语言句法结构基准测试。该基准测试采用选择性容忍范式，测试模型是否认为自然语言学习者的错误比同一句子中匹配的人工错误更合理。BLiSS包含136,867个对照三元组（纠正、学习者、人工），数据来源于超过280万个自然语言学习者句子。

Result: 在多种模型上进行的实验表明，选择性容忍能力与标准的语法能力不同，并且模型的表现根据其训练范式有明显的聚类。

Conclusion: BLiSS是一个有效的工具，可以测量不同的训练目标如何影响模型与人类语言习得的系统模式的一致性。

Abstract: To bridge the gap between performance-oriented benchmarks and the evaluation
of cognitively inspired models, we introduce BLiSS 1.0, a Benchmark of Learner
Interlingual Syntactic Structure. Our benchmark operationalizes a new paradigm
of selective tolerance, testing whether a model finds a naturalistic learner
error more plausible than a matched, artificial error within the same sentence.
Constructed from over 2.8 million naturalistic learner sentences, BLiSS
provides 136,867 controlled triplets (corrected, learner, artificial) for this
purpose. Experiments on a diverse suite of models demonstrate that selective
tolerance is a distinct capability from standard grammaticality, with
performance clustering strongly by training paradigm. This validates BLiSS as a
robust tool for measuring how different training objectives impact a model's
alignment with the systematic patterns of human language acquisition.

</details>


### [126] [MINED: Probing and Updating with Multimodal Time-Sensitive Knowledge for Large Multimodal Models](https://arxiv.org/abs/2510.19457)
*Kailin Jiang,Ning Jiang,Yuchen Ren,Yuchen Li,Yifan Gao,Jinhe Bi,Yunpu Ma,Qingqing Liu,Xianhao Wang,Yifan Jia,Hongbo Jiang,Yaocong Hu,Bin Li,Lei Liu,Yuntao Du*

Main category: cs.CL

TL;DR: MINED是一个评估大型多模态模型（LMM）时间敏感知识理解能力的基准，包含6个维度和11个任务。在MINED基准上，Gemini-2.5-Pro表现最佳，但大多数开源模型在这方面仍有不足。研究还表明，LMM可以通过知识编辑方法更新其时间敏感知识。


<details>
  <summary>Details</summary>
Motivation: 现有的LMM虽然包含丰富的知识，但其静态表示难以准确理解时效性知识，而现有基准在评估这方面能力时存在不足。

Method: 构建了一个名为MINED的综合性基准，该基准包含6个关键维度和11个具有挑战性的任务，用于评估LMM的时间感知能力。MINED基准由维基百科构建，包含2,104个跨越六种知识类型的时间敏感知识样本。同时，研究还探讨了通过知识编辑方法更新LMM中时效性知识的可行性。

Result: 在MINED基准上对15个广泛使用的LMM进行评估，发现Gemini-2.5-Pro的平均CEM得分最高（63.07），而大多数开源LMM在时间理解能力方面仍显不足。LMM在组织知识方面的表现最佳，而在体育知识方面的表现最弱。在单次编辑场景下，LMM能够有效地通过知识编辑方法更新知识。

Conclusion: MINED基准揭示了当前LMM在理解和处理时间敏感知识方面的局限性，并为未来的研究提供了方向。虽然Gemini-2.5-Pro展现出较强的能力，但整体仍有提升空间。知识编辑方法为解决LMM的时效性知识更新问题提供了一种有前景的途径。

Abstract: Large Multimodal Models (LMMs) encode rich factual knowledge via cross-modal
pre-training, yet their static representations struggle to maintain an accurate
understanding of time-sensitive factual knowledge. Existing benchmarks remain
constrained by static designs, inadequately evaluating LMMs' ability to
understand time-sensitive knowledge. To address this gap, we propose MINED, a
comprehensive benchmark that evaluates temporal awareness along 6 key
dimensions and 11 challenging tasks: cognition, awareness, trustworthiness,
understanding, reasoning, and robustness. MINED is constructed from Wikipedia
by two professional annotators, containing 2,104 time-sensitive knowledge
samples spanning six knowledge types. Evaluating 15 widely used LMMs on MINED
shows that Gemini-2.5-Pro achieves the highest average CEM score of 63.07,
while most open-source LMMs still lack time understanding ability. Meanwhile,
LMMs perform best on organization knowledge, whereas their performance is
weakest on sport. To address these challenges, we investigate the feasibility
of updating time-sensitive knowledge in LMMs through knowledge editing methods
and observe that LMMs can effectively update knowledge via knowledge editing
methods in single editing scenarios.

</details>


### [127] [Re-evaluating Minimum Bayes Risk Decoding for Automatic Speech Recognition](https://arxiv.org/abs/2510.19471)
*Yuu Jinnai*

Main category: cs.CL

TL;DR: MBR解码在语音识别和语音翻译任务中优于束搜索。


<details>
  <summary>Details</summary>
Motivation: 由于MBR解码在文本到文本生成任务中表现优越，因此我们希望它也能在语音到文本任务中表现良好。

Method: 在英语和日语上使用Whisper及其衍生模型评估MBR解码在ASR和ST任务中的表现。

Result: 在大多数实验设置中，MBR解码的准确性优于束搜索。

Conclusion: MBR解码是一种有前途的、可用于需要高精度的离线ASR和ST任务的方法。

Abstract: Recent work has shown that sample-based Minimum Bayes Risk (MBR) decoding
outperforms beam search in text-to-text generation tasks, such as machine
translation, text summarization, and image captioning. On the other hand, beam
search is the current practice for speech-to-text tasks such as automatic
speech recognition (ASR) and Speech Translation (ST). Given that MBR decoding
is effective in text-to-text generation tasks, it is reasonable to expect it to
also be effective for speech-to-text tasks. In this paper, we evaluate MBR
decoding for ASR and ST tasks on English and Japanese using Whisper and its
derivative models. We observe that the accuracy of MBR decoding outperforms
that of beam search in most of the experimental settings we have evaluated. The
results show that MBR decoding is a promising method for offline ASR and ST
tasks that require high accuracy. The code is available at
https://github.com/CyberAgentAILab/mbr-for-asr

</details>


### [128] [VideoAgentTrek: Computer Use Pretraining from Unlabeled Videos](https://arxiv.org/abs/2510.19488)
*Dunjie Lu,Yiheng Xu,Junli Wang,Haoyuan Wu,Xinyuan Wang,Zekun Wang,Junlin Yang,Hongjin Su,Jixuan Chen,Junda Chen,Yuchen Mao,Jingren Zhou,Junyang Lin,Binyuan Hui,Tao Yu*

Main category: cs.CL

TL;DR: VideoAgentTrek通过从YouTube教程视频中自动提取GUI交互数据，解决了训练计算机使用代理所需的大量标注数据的难题，显著提高了代理的任务成功率和步进准确性。


<details>
  <summary>Details</summary>
Motivation: 手动标注大规模GUI交互数据以训练计算机使用代理成本高昂且效率低下。

Method: 提出VideoAgentTrek流水线，包含Video2Action模块，该模块利用视频地面模型和动作内容识别器，从屏幕录制视频中自动提取GUI动作的精确时域边界、上下文和结构化参数（如点击坐标和输入文本）。

Result: 在39,000个YouTube教程视频上生成了152万个交互步骤。在OSWorld-Verified上，任务成功率从9.3%提升至15.8%（相对提升70%）。在AgentNetBench上，步进准确性从64.1%提升至69.3%。

Conclusion: 被动互联网视频可以转化为高质量的监督数据，为计算机使用代理提供了一种可扩展的替代手动标注的方法。

Abstract: Training computer-use agents requires massive amounts of GUI interaction
data, but manually annotating action trajectories at scale is prohibitively
expensive. We present VideoAgentTrek, a scalable pipeline that automatically
mines training data from publicly available screen-recorded videos at web
scale, eliminating the need for manual annotation. Our approach addresses a key
challenge: raw videos contain implicit demonstrations but lack explicit action
labels. To solve this, we develop Video2Action, an inverse dynamics module
(IDM) with two components: (1) a video grounding model that detects and
localizes GUI actions with precise temporal boundaries and context, and (2) an
action-content recognizer that extracts structured parameters like click
coordinates and typed text with high fidelity. Applied to 39,000 YouTube
tutorial videos, our pipeline generates 1.52 million interaction steps
automatically. We leverage this data through continued pretraining followed by
supervised fine-tuning. On OSWorld-Verified, our approach improves task success
rates from 9.3% (SFT-only baseline) to 15.8%, a 70% relative improvement. On
AgentNetBench, step accuracy increases from 64.1% to 69.3%. Our results
demonstrate that passive internet videos can be transformed into high-quality
supervision for computer-use agents, providing a scalable alternative to
expensive manual annotation.

</details>


### [129] [Machine Text Detectors are Membership Inference Attacks](https://arxiv.org/abs/2510.19492)
*Ryuto Koike,Liam Dugan,Masahiro Kaneko,Chris Callison-Burch,Naoaki Okazaki*

Main category: cs.CL

TL;DR: 本研究探讨了成员推断攻击（MIA）和机器生成文本检测之间的可转移性，证明了针对这两个任务的优化指标是相同的，并提出了一个统一的评估套件 MINT。


<details>
  <summary>Details</summary>
Motivation: 由于成员推断攻击（MIA）和机器生成文本检测都利用语言模型概率分布的相似信号，但被独立研究，可能导致忽视更优方法和宝贵见解。本研究旨在探究这两种任务之间的方法可转移性，以期促进跨领域研究与合作。

Method: 通过理论证明和大规模实证实验，分析了原始为一种任务设计的方法在另一种任务上的表现。理论上，证明了两种任务的最优指标是相同的，并推测方法的准确性与其可转移性直接相关。实证上，在7种MIA方法和5种机器文本检测器跨13个领域和10个生成器上进行了实验。

Result: 大规模实证实验显示，跨任务表现具有很强的秩相关性（rho > 0.6）。 originally 为机器文本检测设计的 Binoculars 方法在 MIA 基准测试中也达到了最先进的性能。研究引入了一个名为 MINT 的统一评估套件，包含15种来自两个任务的最新方法。

Conclusion: 本研究证明了成员推断攻击（MIA）和机器生成文本检测之间存在显著的方法可转移性，这表明了跨社区合作的必要性。统一的评估套件 MINT 的提出，将有助于促进未来的跨任务研究和公平评估。

Abstract: Although membership inference attacks (MIAs) and machine-generated text
detection target different goals, identifying training samples and synthetic
texts, their methods often exploit similar signals based on a language model's
probability distribution. Despite this shared methodological foundation, the
two tasks have been independently studied, which may lead to conclusions that
overlook stronger methods and valuable insights developed in the other task. In
this work, we theoretically and empirically investigate the transferability,
i.e., how well a method originally developed for one task performs on the
other, between MIAs and machine text detection. For our theoretical
contribution, we prove that the metric that achieves the asymptotically highest
performance on both tasks is the same. We unify a large proportion of the
existing literature in the context of this optimal metric and hypothesize that
the accuracy with which a given method approximates this metric is directly
correlated with its transferability. Our large-scale empirical experiments,
including 7 state-of-the-art MIA methods and 5 state-of-the-art machine text
detectors across 13 domains and 10 generators, demonstrate very strong rank
correlation (rho > 0.6) in cross-task performance. We notably find that
Binoculars, originally designed for machine text detection, achieves
state-of-the-art performance on MIA benchmarks as well, demonstrating the
practical impact of the transferability. Our findings highlight the need for
greater cross-task awareness and collaboration between the two research
communities. To facilitate cross-task developments and fair evaluations, we
introduce MINT, a unified evaluation suite for MIAs and machine-generated text
detection, with implementation of 15 recent methods from both tasks.

</details>


### [130] [What is the Best Sequence Length for BABYLM?](https://arxiv.org/abs/2510.19493)
*Suchir Salhan,Richard Diehl Martinez,Zébulon Goriely,Paula Buttery*

Main category: cs.CL

TL;DR: Transformer 语言模型通常使用固定长度的上下文窗口，但 BabyLM 挑战中的许多方法都使用了较短的序列长度。本研究旨在确定训练 Baby LM 时应使用的最佳序列长度。


<details>
  <summary>Details</summary>
Motivation: 研究 Transformer 语言模型在不同序列长度下的表现，特别是在 BabyLM 挑战的背景下，以确定何种序列长度最适合训练。

Method: 在固定的计算预算下，使用 100M 词的训练数据，比较了 125M 参数的 Mamba 和 OPT 模型在不同序列长度下的表现。

Result: 结果表明，虽然更长的序列通常更好，但最佳长度取决于具体任务和模型架构。较短的序列足以满足语法泛化任务，而较长的上下文则有利于形态类比推理任务。

Conclusion: 在训练 Baby LM 时，应根据具体的任务和模型架构选择合适的序列长度。对于语法泛化任务，较短的序列是足够的；而对于形态类比推理任务，则需要较长的上下文。

Abstract: Transformer language models typically operate with a fixed-length context
window, which has grown in step with large-scale pretraining datasets. In the
BabyLM Challenge, however, many past submissions have defaulted to using much
shorter sequence lengths. We examine the impact of sequence length on BabyLM
pretraining, to answer the simple question: what sequence length should we be
using when training Baby LMs? Using 100M-word training data and fixed compute
budgets, we compare 125M-parameter Mamba and OPT models, finding that although
longer is often better, the optimal length depends on both task and
architecture. Shorter sequences are sufficient for grammatical generalization
tasks whereas longer contexts benefit morphological analogical reasoning tasks.

</details>


### [131] [Lookahead Routing for Large Language Models](https://arxiv.org/abs/2510.19506)
*Canbin Huang,Tianyuan Shi,Yuhua Zhu,Ruijun Chen,Xiaojun Quan*

Main category: cs.CL

TL;DR: LLM 路由器通过将查询路由到最合适的模型来提高多模型系统的效率，但现有方法仅基于输入查询进行路由，忽略了潜在输出信息。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 路由方法仅基于输入查询，无法捕捉响应生成过程中出现的隐式意图或上下文，导致复杂查询的路由决策不佳。

Method: 提出 Lookahead 路由框架，通过预测潜在模型输出来指导模型选择，从而在不进行完全推理的情况下做出更明智的路由决策。实现了两种基于因果和掩码语言模型的方法。

Result: 在七个公开基准测试（包括指令遵循、数学推理和代码生成）上，Lookahead 的性能优于现有路由基线，平均性能提升 7.7%。

Conclusion: Lookahead 框架通过预测潜在输出来实现更优的 LLM 路由，显著提高了多模型系统的性能。

Abstract: Large language model (LLM) routers improve the efficiency of multi-model
systems by directing each query to the most appropriate model while leveraging
the diverse strengths of heterogeneous LLMs. Most existing approaches frame
routing as a classification problem based solely on the input query. While this
reduces overhead by avoiding inference across all models, it overlooks valuable
information that could be gleaned from potential outputs and fails to capture
implicit intent or contextual nuances that often emerge only during response
generation. These limitations can result in suboptimal routing decisions,
particularly for complex or ambiguous queries that require deeper semantic
understanding. To address this challenge, we propose Lookahead, a routing
framework that "foresees" potential model outputs by predicting their latent
representations and uses these predictions to guide model selection, thus
enabling more informed routing without full inference. Within this framework,
we implement two approaches based on causal and masked language models.
Empirical evaluations across seven public benchmarks - spanning instruction
following, mathematical reasoning, and code generation - show that Lookahead
consistently outperforms existing routing baselines, achieving an average
performance gain of 7.7% over the state-of-the-art. Our code is available at
https://github.com/huangcb01/lookahead-routing.

</details>


### [132] [Which Evaluation for Which Model? A Taxonomy for Speech Model Assessment](https://arxiv.org/abs/2510.19509)
*Maureen de Seyssel,Eeshan Gunesh Dhekane*

Main category: cs.CL

TL;DR: 该论文提出了一个统一的语音模型评估分类法，以解决跨任务和跨模型的评估不一致问题。


<details>
  <summary>Details</summary>
Motivation: 现有的语音基础模型评估在任务和模型类型之间存在脱节，不同的模型在语音处理的不同方面表现出色，需要不同的评估方案。

Method: 提出一个包含评估方面、所需模型能力和任务/协议要求的三个正交轴的统一分类法。该分类法用于对广泛的现有评估和基准进行分类，涵盖表示学习、语音生成和交互式对话等领域。通过将评估与模型暴露的能力（例如，语音生成、实时处理）及其方法论要求（例如，微调数据、人类判断）进行映射，该分类法提供了一个原则性的框架来匹配模型和合适的评估方法。

Result: 该分类法有助于选择、解释和扩展语音模型的评估。它还揭示了评估方面的系统性差距，例如韵律、交互或推理的覆盖范围有限，这为未来的基准设计提供了重点。

Conclusion: 该论文为语音模型评估提供了一个概念基础和实用指南。

Abstract: Speech foundation models have recently achieved remarkable capabilities
across a wide range of tasks. However, their evaluation remains disjointed
across tasks and model types. Different models excel at distinct aspects of
speech processing and thus require different evaluation protocols. This paper
proposes a unified taxonomy that addresses the question: Which evaluation is
appropriate for which model? The taxonomy defines three orthogonal axes: the
\textbf{evaluation aspect} being measured, the model capabilities required to
attempt the task, and the task or protocol requirements needed to perform it.
We classify a broad set of existing evaluations and benchmarks along these
axes, spanning areas such as representation learning, speech generation, and
interactive dialogue. By mapping each evaluation to the capabilities a model
exposes (e.g., speech generation, real-time processing) and to its
methodological demands (e.g., fine-tuning data, human judgment), the taxonomy
provides a principled framework for aligning models with suitable evaluation
methods. It also reveals systematic gaps, such as limited coverage of prosody,
interaction, or reasoning, that highlight priorities for future benchmark
design. Overall, this work offers a conceptual foundation and practical guide
for selecting, interpreting, and extending evaluations of speech models.

</details>


### [133] [Conditions for Catastrophic Forgetting in Multilingual Translation](https://arxiv.org/abs/2510.19546)
*Danni Liu,Jan Niehues*

Main category: cs.CL

TL;DR: 微调多语言模型时，模型和数据规模的相对大小是导致灾难性遗忘的主要因素，指令遵循能力比模型架构更关键，参数高效微调不一定优于全参数微调，而跨语言对齐可以缓解遗忘并促进对未见语言的积极迁移。


<details>
  <summary>Details</summary>
Motivation: 微调多语言模型时，灾难性遗忘的发生条件尚不明确，需要系统性研究来确定触发因素。

Method: 使用机器翻译作为测试平台，通过不同模型架构、数据规模和微调方法进行受控实验，研究灾难性遗忘的触发条件。

Result: 模型和数据规模的相对大小是遗忘的主要决定因素；指令遵循能力比模型架构更关键；参数高效微调相比全参数微调没有明显优势；跨语言对齐可以缓解遗忘并促进对未见语言的积极迁移。

Conclusion: 研究结果有助于理解多语言模型微调中的灾难性遗忘现象，并为缓解此问题提供了指导，跨语言对齐是一种有效的方法。

Abstract: Fine-tuning multilingual foundation models on specific languages often
induces catastrophic forgetting, degrading performance on languages unseen in
fine-tuning. While this phenomenon is widely-documented, the literature
presents fragmented results about when forgetting occurs. To address this
ambiguity, we conduct a systematic empirical study using machine translation as
a testbed to identify the conditions that trigger catastrophic forgetting in
multilingual fine-tuning. Through controlled experiments across different model
architectures, data scales, and fine-tuning approaches, we reveal that the
relative scale between model and data size is a primary determinant of
forgetting. Moreover, we demonstrate that a model's instruction-following
ability is more critical for retaining multilingual knowledge than its
architecture. Contrary to assumptions, parameter-efficient fine-tuning offers
no clear advantage over full fine-tuning in mitigating forgetting. Lastly, we
show that cross-lingual alignment can mitigate forgetting while also
facilitating positive transfer to unseen target languages.

</details>


### [134] [Detecting Latin in Historical Books with Large Language Models: A Multimodal Benchmark](https://arxiv.org/abs/2510.19585)
*Yu Wu,Ke Shu,Jonas Fischer,Lidia Pivovarova,David Rosson,Eetu Mäkelä,Mikko Tolonen*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper presents a novel task of extracting Latin fragments from
mixed-language historical documents with varied layouts. We benchmark and
evaluate the performance of large foundation models against a multimodal
dataset of 724 annotated pages. The results demonstrate that reliable Latin
detection with contemporary models is achievable. Our study provides the first
comprehensive analysis of these models' capabilities and limits for this task.

</details>


### [135] [PBBQ: A Persian Bias Benchmark Dataset Curated with Human-AI Collaboration for Large Language Models](https://arxiv.org/abs/2510.19616)
*Farhan Farsi,Shayan Bali,Fatemeh Valeh,Parsa Ghofrani,Alireza Pakniat,Kian Kashfipour,Amir H. Payberah*

Main category: cs.CL

TL;DR: 本研究提出了PBBQ，一个包含37000多个问题的波斯语大型语言模型社会偏见基准数据集，以评估和减轻波斯语模型中的偏见。


<details>
  <summary>Details</summary>
Motivation: 确保大型语言模型（LLMs）符合社会规范是一个日益严峻的问题，但目前缺乏针对波斯文化背景的社会偏见资源，因此本研究旨在填补这一空白。

Method: 通过与社会科学专家合作，对250名不同人口统计学的个人进行问卷调查，构建了一个包含16个文化类别的PBBQ数据集，其中包含37000多个精心策划的问题，并在此数据集上对多个开源、闭源及波斯语特定微调的大型语言模型进行了基准测试。

Result: 研究结果表明，当前的大型语言模型在波斯文化中表现出显著的社会偏见，并且这些模型常常复制人类的偏见模式。

Conclusion: PBBQ数据集为评估和减轻波斯语模型的偏见提供了一个基础，研究强调了模型学习表征与文化刻板印象之间复杂的相互作用。本研究包含不安全内容。

Abstract: With the increasing adoption of large language models (LLMs), ensuring their
alignment with social norms has become a critical concern. While prior research
has examined bias detection in various languages, there remains a significant
gap in resources addressing social biases within Persian cultural contexts. In
this work, we introduce PBBQ, a comprehensive benchmark dataset designed to
evaluate social biases in Persian LLMs. Our benchmark, which encompasses 16
cultural categories, was developed through questionnaires completed by 250
diverse individuals across multiple demographics, in close collaboration with
social science experts to ensure its validity. The resulting PBBQ dataset
contains over 37,000 carefully curated questions, providing a foundation for
the evaluation and mitigation of bias in Persian language models. We benchmark
several open-source LLMs, a closed-source model, and Persian-specific
fine-tuned models on PBBQ. Our findings reveal that current LLMs exhibit
significant social biases across Persian culture. Additionally, by comparing
model outputs to human responses, we observe that LLMs often replicate human
bias patterns, highlighting the complex interplay between learned
representations and cultural stereotypes.Upon acceptance of the paper, our PBBQ
dataset will be publicly available for use in future work. Content warning:
This paper contains unsafe content.

</details>


### [136] [CrossNews-UA: A Cross-lingual News Semantic Similarity Benchmark for Ukrainian, Polish, Russian, and English](https://arxiv.org/abs/2510.19628)
*Daryna Dementieva,Evgeniya Sukhodolskaya,Alexander Fraser*

Main category: cs.CL

TL;DR: 开发了一个可扩展、可解释的众包流程，用于跨语言新闻相似性评估，并创建了一个包含乌克兰语、波兰语、俄语和英语新闻对的新数据集 CrossNews-UA，同时测试了各种模型以分析多语言新闻分析的挑战和模型性能。


<details>
  <summary>Details</summary>
Motivation: 在社交网络和错误信息传播的时代，新闻分析，特别是跨语言（尤其是在英语以外）的虚假新闻检测，仍然是一项关键但充满挑战的任务。现有的跨语言新闻分析数据集由专家手动创建，存在规模化和适应新语言的局限性。

Method: 提出并实现了一个可扩展、可解释的众包流程，用于跨语言新闻相似性评估。利用该流程收集了一个新的新闻对数据集 CrossNews-UA，包含乌克兰语与波兰语、俄语和英语的对应新闻，并根据 4W（Who, What, Where, When）标准对新闻对的语义相似性进行了标注和详细的理由说明。此外，还测试了从词袋模型到 Transformer 和大型语言模型（LLMs）的多种模型。

Result: 在跨语言新闻分析方面，尽管提出了新的数据集和方法，但仍存在挑战。实验测试了不同模型，并提供了关于模型在多语言新闻分析中表现的见解。

Conclusion: 现有的跨语言新闻分析数据集存在规模化和适应性限制。提出的众包流程和新数据集 CrossNews-UA 为跨语言新闻相似性评估提供了一个可扩展且可解释的解决方案，并为理解多语言新闻分析的模型性能提供了见解。

Abstract: In the era of social networks and rapid misinformation spread, news analysis
remains a critical task. Detecting fake news across multiple languages,
particularly beyond English, poses significant challenges. Cross-lingual news
comparison offers a promising approach to verify information by leveraging
external sources in different languages (Chen and Shu, 2024). However, existing
datasets for cross-lingual news analysis (Chen et al., 2022a) were manually
curated by journalists and experts, limiting their scalability and adaptability
to new languages. In this work, we address this gap by introducing a scalable,
explainable crowdsourcing pipeline for cross-lingual news similarity
assessment. Using this pipeline, we collected a novel dataset CrossNews-UA of
news pairs in Ukrainian as a central language with linguistically and
contextually relevant languages-Polish, Russian, and English. Each news pair is
annotated for semantic similarity with detailed justifications based on the 4W
criteria (Who, What, Where, When). We further tested a range of models, from
traditional bag-of-words, Transformer-based architectures to large language
models (LLMs). Our results highlight the challenges in multilingual news
analysis and offer insights into models performance.

</details>


### [137] [Style Attack Disguise: When Fonts Become a Camouflage for Adversarial Intent](https://arxiv.org/abs/2510.19641)
*Yangshijie Zhang,Xinda Wang,Jialin Liu,Wenqiang Wang,Zhicong Ma,Xingxing Jia*

Main category: cs.CL

TL;DR: 社交媒体上，用户使用特殊字体和表情符号来表达个性，但这会给自然语言处理模型带来安全隐患。本文提出了Style Attack Disguise (SAD)攻击方法，可以有效降低NLP模型的性能。


<details>
  <summary>Details</summary>
Motivation: 用户使用特殊字体和表情符号来表达个性，这会给自然语言处理模型带来安全隐患。

Method: 提出了一种名为Style Attack Disguise (SAD) 的基于风格的攻击方法，并设计了轻量级和强力两种尺寸。

Result: 在情感分类和机器翻译任务上，SAD在传统模型、大型语言模型和商业服务上都展现出了强大的攻击性能。此外，SAD还对文本到图像和文本到语音生成等模态任务显示出潜在威胁。

Conclusion: SAD攻击方法能够有效降低NLP模型在各种任务上的性能，并对多模态任务构成潜在威胁。

Abstract: With social media growth, users employ stylistic fonts and font-like emoji to
express individuality, creating visually appealing text that remains
human-readable. However, these fonts introduce hidden vulnerabilities in NLP
models: while humans easily read stylistic text, models process these
characters as distinct tokens, causing interference. We identify this
human-model perception gap and propose a style-based attack, Style Attack
Disguise (SAD). We design two sizes: light for query efficiency and strong for
superior attack performance. Experiments on sentiment classification and
machine translation across traditional models, LLMs, and commercial services
demonstrate SAD's strong attack performance. We also show SAD's potential
threats to multimodal tasks including text-to-image and text-to-speech
generation.

</details>


### [138] [LLavaCode: Compressed Code Representations for Retrieval-Augmented Code Generation](https://arxiv.org/abs/2510.19644)
*Daria Cherniuk,Nikita Sukhorukov,Nikita Sushko,Daniil Gusak,Danil Sivtsov,Elena Tutubalina,Evgeny Frolov*

Main category: cs.CL

TL;DR: LlavaCode通过将代码压缩为紧凑的、语义丰富的表示，提高了代码补全的效率和质量，同时显著减少了检索上下文，从而降低了推理延迟。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）是代码补全的有效方法，但增加了序列长度，导致推理速度变慢，这在IDE等交互式场景中是个关键问题。

Method: 提出LlavaCode框架，将代码压缩为紧凑的、语义丰富的、可被代码LLM解释的表示。使用小型投影仪模块来增加EM和ES指标，并增加极小的延迟。

Result: 与完整的RAG流程相比，压缩上下文在行补全任务上将首次标记时间（TTFT）减少了20-38%。

Conclusion: 压缩上下文可以显着提高代码补全的效率，而不会显着增加延迟，从而为交互式编码环境提供了可行的解决方案。

Abstract: Retrieval-augmented generation has emerged as one of the most effective
approaches for code completion, particularly when context from a surrounding
repository is essential. However, incorporating context significantly extends
sequence length, leading to slower inference - a critical limitation for
interactive settings such as IDEs. In this work, we introduce LlavaCode, a
framework that compresses code into compact, semantically rich representations
interpretable by code LLM, enhancing generation quality while reducing the
retrieved context to only a few compressed single-token vectors. Using a small
projector module we can significantly increase the EM and ES metrics of coding
model with negligible latency increase. Our experiments demonstrate that
compressed context enables 20-38% reduction in Time-to-First-Token (TTFT) on
line completion tasks compared to full-RAG pipelines.

</details>


### [139] [Unraveling Emotions with Pre-Trained Models](https://arxiv.org/abs/2510.19668)
*Alejandro Pajón-Sanmartín,Francisco De Arriba-Pérez,Silvia García-Méndez,Fátima Leal,Benedita Malheiro,Juan Carlos Burguillo-Rial*

Main category: cs.CL

TL;DR: Transformer模型在情绪识别方面取得了显著进展，但针对大语言模型（LLMs）的开放式查询仍存在挑战。本研究比较了微调和提示工程在情绪检测中的有效性，并提出了结构化提示工程和情绪分组技术以提升LLMs的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管现有模型在情绪识别方面取得了良好成果，但在开放文本中进行自动情绪分析仍面临诸多挑战，例如上下文歧义、语言变异性以及理解复杂情感表达的困难。这些局限性使得通用模型难以直接应用于此类任务。

Method: 本研究通过三种不同的场景比较了微调和提示工程在情绪检测中的有效性：(i) 比较微调预训练模型和使用简单提示的通用LLMs的性能；(ii) 评估不同情绪提示设计对LLMs的有效性；(iii) 分析情绪分组技术对这些模型的影响。

Result: 实验测试表明，经过微调的情绪识别预训练模型可以达到高于70%的准确率。此外，研究发现LLMs需要结构化的提示工程和情绪分组技术才能提升其性能。

Conclusion: 本研究证明，通过结构化提示工程和情绪分组技术，可以显著提升LLMs在开放式文本情绪识别任务上的表现。这些改进有助于提升情感分析、人机交互以及跨领域用户行为理解的准确性。

Abstract: Transformer models have significantly advanced the field of emotion
recognition. However, there are still open challenges when exploring open-ended
queries for Large Language Models (LLMs). Although current models offer good
results, automatic emotion analysis in open texts presents significant
challenges, such as contextual ambiguity, linguistic variability, and
difficulty interpreting complex emotional expressions. These limitations make
the direct application of generalist models difficult. Accordingly, this work
compares the effectiveness of fine-tuning and prompt engineering in emotion
detection in three distinct scenarios: (i) performance of fine-tuned
pre-trained models and general-purpose LLMs using simple prompts; (ii)
effectiveness of different emotion prompt designs with LLMs; and (iii) impact
of emotion grouping techniques on these models. Experimental tests attain
metrics above 70% with a fine-tuned pre-trained model for emotion recognition.
Moreover, the findings highlight that LLMs require structured prompt
engineering and emotion grouping to enhance their performance. These
advancements improve sentiment analysis, human-computer interaction, and
understanding of user behavior across various domains.

</details>


### [140] [DiffAdapt: Difficulty-Adaptive Reasoning for Token-Efficient LLM Inference](https://arxiv.org/abs/2510.19669)
*Xiang Liu,Xuming Hu,Xiaowen Chu,Eunsol Choi*

Main category: cs.CL

TL;DR: 通过分析推理过程中token概率的熵，提出DiffAdapt框架，根据问题难度和熵选择不同的推理策略，在不降低准确率的情况下，显著减少了token使用量。


<details>
  <summary>Details</summary>
Motivation: 提高大型语言模型（LLM）在进行推理时的效率，使其在不过度思考的情况下达到高性能。

Method: 分析推理过程中token概率的熵，观察到U型模式，并据此提出DiffAdapt框架。该框架根据问题难度和推理轨迹熵，为每个问题选择Easy/Normal/Hard的推理策略（包括固定的提示、温度和最大token长度）。DiffAdapt通过训练一个小型探针来分类LLM的最终隐藏状态，从而适应不同策略，而无需微调基础LLM。

Result: 在五个模型和八个基准的综合评估中，DiffAdapt实现了相当或更高的准确率，同时将token使用量减少了高达22.4%。

Conclusion: DiffAdapt是一种实用的方法，可以实现计算高效的推理，在不牺牲准确率的情况下显著降低LLM的token消耗。

Abstract: Recent reasoning Large Language Models (LLMs) demonstrate remarkable
problem-solving abilities but often generate long thinking traces whose utility
is unclear. Our work aims to improve their efficiency, enabling them to reach
high performance without overthinking. First, we analyze the entropy of token
probabilities in reasoning traces. Across three models, we observe a consistent
U-shaped entropy pattern: high entropy on easy problems despite high accuracy,
low entropy on problems with medium difficulty, and high entropy on hard
problems reflecting uncertainty. Specifically, we notice 22--25\% entropy
reduction from easy to medium difficulty regions, suggesting an {overthinking}
phenomenon on easy instances. Building on these insights, we introduce
\textbf{DiffAdapt}, a lightweight framework that selects Easy/Normal/Hard
inference strategies per question based on their difficulty and reasoning trace
entropy. Each inference strategy consists of a fixed prompt, temperature and
maximum token length. In contrast to existing efficiency optimization methods,
our approach does not fine-tune base LLM but a small probe that classifies
LLM's final hidden state, allowing inexpensive adaptation. We comprehensively
evaluate our method on five models and eight benchmarks. Our method achieves
comparable or improved accuracy while reducing token usage by up to 22.4\%,
establishing a practical path toward compute-efficient reasoning.

</details>


### [141] [CoSense-LLM: Semantics at the Edge with Cost- and Uncertainty-Aware Cloud-Edge Cooperation](https://arxiv.org/abs/2510.19670)
*Hasan Akgul,Mari Eplik,Javier Rojas,Aina Binti Abdullah,Pieter van der Merwe*

Main category: cs.CL

TL;DR: CoSense-LLM 是一个边缘优先的框架，它将连续的多模态传感器流（如 Wi-Fi CSI、IMU、音频、RFID 和轻量级视觉）转化为紧凑、可验证的语义令牌，并在严格的延迟、能源、带宽和隐私限制下与大型语言模型协同工作。该系统通过 SenseFusion、Edge-RAG、PromptRouter 和 Secure Execution 等组件实现，能够满足低延迟、低成本和高隐私的要求，并在家庭、办公室和诊所等实际场景中提供可靠的解释。


<details>
  <summary>Details</summary>
Motivation: 在延迟、能源、带宽和隐私等严格限制下，将连续多模态传感器流与大型语言模型（LLM）集成，以实现可靠的、可解释的边缘计算。

Method: CoSense-LLM 框架包含四个部分：(i) SenseFusion：一个轻量级编码器，对齐传感器嵌入与语言，并将其压缩成离散的代码序列；(ii) Edge-RAG：一个本地混合检索层，用于基于本地策略和笔记进行生成；(iii) PromptRouter：一个成本和不确定性感知的策略，用于选择边缘生成、边缘加检索或云端扩展；(iv) Secure Execution：一个可审计的 redaction 路径，强制执行数据最小化，确保原始数据不离开设备。该系统还支持现代服务优化，如分页/流式 KV 缓存、FlashAttention 内核、推测解码和量化 LoRA 适配器，并支持设备上的个性化和联邦更新。

Result: 在家庭、办公室和诊所的部署中，CoSense-LLM 实现了在亚秒级（p95）端到端延迟下提供基于事实的解释。它通过优先本地检索来降低令牌和带宽成本，并通过仅传输离散代码和经过处理的元数据来保护隐私。消融研究表明，Edge-RAG 提高了事实一致性，校准的不确定性实现了选择性弃权和受控升级，KV 缓存和解码加速器降低了每个决策的能耗。

Conclusion: 边缘优先的设计可以将语义、隐私和可预测的延迟视为大型模型在易受干扰环境中部署的同等重要目标。

Abstract: We present CoSense-LLM, an edge-first framework that turns continuous
multimodal sensor streams (for example Wi-Fi CSI, IMU, audio, RFID, and
lightweight vision) into compact, verifiable semantic tokens and coordinates
with large language models under explicit latency, energy, bandwidth, and
privacy constraints. CoSense-LLM has four parts: (i) SenseFusion, a lightweight
encoder that aligns sensor embeddings with language and compresses them into
short discrete code sequences; (ii) Edge-RAG, a local hybrid retrieval layer
that grounds generation in site specific policies and notes; (iii)
PromptRouter, a cost and uncertainty aware policy that selects edge only
generation, edge plus retrieval, or compact cloud escalation; and (iv) Secure
Execution, an auditable redaction path that enforces data minimization so raw
waveforms never leave the device. The system works with modern serving
optimizations, including paged or streaming KV caches, FlashAttention style
kernels, speculative decoding, and quantized LoRA adapters, and supports on
device personalization and federated updates under non IID drift. Across home,
office, and clinic deployments, CoSense-LLM delivers grounded explanations
while meeting tight service level objectives: it sustains sub second (p95) end
to end latency on edge dominant paths, reduces inter tier token and bandwidth
costs by preferring local retrieval grounded responses, and preserves privacy
by transmitting only discrete codes and redacted metadata. Ablations show that
Edge-RAG improves factual consistency and reduces contradictions, calibrated
uncertainty enables selective abstention and controlled escalations, and KV
plus decoding accelerators lower energy per decision. The results support an
edge first design that treats semantics, privacy, and predictable latency as co
equal goals for large model deployments in interference prone environments.

</details>


### [142] [Are Large Language Models Sensitive to the Motives Behind Communication?](https://arxiv.org/abs/2510.19687)
*Addison J. Wu,Ryan Liu,Kerem Oktar,Theodore R. Sumers,Thomas L. Griffiths*

Main category: cs.CL

TL;DR: LLMs can discount biased sources like humans in controlled tests, but struggle with real-world motivated content like ads. A simple intervention to highlight intentions improves their performance, suggesting basic sensitivity but a need for generalization.


<details>
  <summary>Details</summary>
Motivation: To investigate whether LLMs can critically evaluate content by considering the motivations of the source, similar to how humans do.

Method: 1. Conduct controlled experiments from cognitive science to see if LLMs discount information from biased sources. 2. Evaluate LLMs on sponsored online advertisements to assess their performance in a more naturalistic setting. 3. Apply a simple steering intervention to test if highlighting intentions and incentives improves LLM performance.

Result: LLMs successfully discount biased sources in controlled experiments, behaving similarly to humans. However, in real-world settings like online ads, their inferences deviate from rational models, partly due to distracting information. A steering intervention significantly improves their performance by increasing the salience of intentions and incentives.

Conclusion: LLMs demonstrate a fundamental ability to recognize and react to the motivations behind human-generated content. While they can generalize this ability to some extent, further enhancements are necessary for them to effectively navigate complex, real-world information environments.

Abstract: Human communication is motivated: people speak, write, and create content
with a particular communicative intent in mind. As a result, information that
large language models (LLMs) and AI agents process is inherently framed by
humans' intentions and incentives. People are adept at navigating such nuanced
information: we routinely identify benevolent or self-serving motives in order
to decide what statements to trust. For LLMs to be effective in the real world,
they too must critically evaluate content by factoring in the motivations of
the source -- for instance, weighing the credibility of claims made in a sales
pitch. In this paper, we undertake a comprehensive study of whether LLMs have
this capacity for motivational vigilance. We first employ controlled
experiments from cognitive science to verify that LLMs' behavior is consistent
with rational models of learning from motivated testimony, and find they
successfully discount information from biased sources in a human-like manner.
We then extend our evaluation to sponsored online adverts, a more naturalistic
reflection of LLM agents' information ecosystems. In these settings, we find
that LLMs' inferences do not track the rational models' predictions nearly as
closely -- partly due to additional information that distracts them from
vigilance-relevant considerations. However, a simple steering intervention that
boosts the salience of intentions and incentives substantially increases the
correspondence between LLMs and the rational model. These results suggest that
LLMs possess a basic sensitivity to the motivations of others, but generalizing
to novel real-world settings will require further improvements to these models.

</details>


### [143] [Do Prompts Reshape Representations? An Empirical Study of Prompting Effects on Embeddings](https://arxiv.org/abs/2510.19694)
*Cesar Gonzalez-Gutierrez,Dirk Hovy*

Main category: cs.CL

TL;DR: 提示词是零样本设置中利用语言模型的一种常用方法，但其底层机制仍未得到充分理解。本研究通过探测性实验分析了提示词嵌入，发现提示词对表示质量有影响，但这种影响与提示词与目标任务的相关性并不一致，挑战了‘更相关的提示词必然带来更好表示’的假设。


<details>
  <summary>Details</summary>
Motivation: 现有研究对提示词（prompting）在零样本设置下如何驱动语言模型（LM）执行多样化任务的底层机制理解不足，本研究旨在通过探究提示词与内部表征质量的关系，来阐明预训练词嵌入如何支持上下文中的任务解决。

Method: 通过一系列针对提示词嵌入的探测性实验，分析用于零样本分类的各种提示词模板组合。

Result: 研究发现，提示词确实会影响表征的质量，但这种影响与提示词与目标任务的相关性之间不存在持续的关联性。

Conclusion: 该研究结果对‘更相关的提示词必然带来更好表征’的普遍假设提出了挑战，并进一步分析了导致这种意外行为的潜在因素。

Abstract: Prompting is a common approach for leveraging LMs in zero-shot settings.
However, the underlying mechanisms that enable LMs to perform diverse tasks
without task-specific supervision remain poorly understood. Studying the
relationship between prompting and the quality of internal representations can
shed light on how pre-trained embeddings may support in-context task solving.
In this empirical study, we conduct a series of probing experiments on prompt
embeddings, analyzing various combinations of prompt templates for zero-shot
classification. Our findings show that while prompting affects the quality of
representations, these changes do not consistently correlate with the relevance
of the prompts to the target task. This result challenges the assumption that
more relevant prompts necessarily lead to better representations. We further
analyze potential factors that may contribute to this unexpected behavior.

</details>


### [144] [From Answers to Guidance: A Proactive Dialogue System for Legal Documents](https://arxiv.org/abs/2510.19723)
*Ashish Chouhan,Michael Gertz*

Main category: cs.CL

TL;DR: EUDial是一个包含880个对话回合的多轮对话数据集，用于解决法律信息的可及性问题。LexGuide框架结合了检索增强生成和分层主题组织，以改进对话的结构和连贯性。实验证明，该方法能有效弥合法律信息与公民理解之间的差距。


<details>
  <summary>Details</summary>
Motivation: 提高法律信息的易懂性和可及性，特别是对非专业人士而言，让他们更容易理解和运用复杂的法律文本。

Method: 构建了一个名为EUDial的多轮对话数据集，该数据集包含880个对话回合，源自欧盟议会研究服务局公民咨询部门（AskEP）的204篇博客。此外，还提出了LexGuide框架，利用检索增强生成（RAG）和分层主题组织来构建对话。

Result: 实验结果表明，通过主动的、结构化的导航，可以有效缩小法律信息可用性与公民理解能力之间的差距。

Conclusion: EUDial数据集和LexGuide框架为开发主动式法律对话系统提供了实用的资源，有助于提升公民对法律信息的理解能力。

Abstract: The accessibility of legal information remains a constant challenge,
particularly for laypersons seeking to understand and apply complex
institutional texts. While the European Union provides open access to
legislation, parliamentary responses, and regulatory documents, these resources
can be challenging for laypeople to explore. In this paper, we introduce
EUDial, a proactive multi-turn dialogue dataset constructed from 204 blogs
curated by the Citizens' Enquiries Unit (AskEP) of the European Parliamentary
Research Service. EUDial contains 880 dialogue turns (averaging 4.3 turns per
dialogue), where each dialogue includes initial questions, structured answers,
and follow-up questions. Beyond dataset construction, we propose the LexGuide
framework that leverages retrieval-augmented generation with hierarchical topic
organization to structure dialogue progression, ensuring both comprehensive
coverage of legal aspects and coherence across conversational turns. The
results demonstrate that proactive, structured navigation closes the gap
between the availability of legal information and citizen comprehension,
establishing EUDial and LexGuide as practical resources for advancing proactive
legal dialogue systems.

</details>


### [145] [Zhyper: Factorized Hypernetworks for Conditioned LLM Fine-Tuning](https://arxiv.org/abs/2510.19733)
*M. H. I. Abdalla,Zhipin Wang,Christian Frey,Steffen Eger,Josif Grabocka*

Main category: cs.CL

TL;DR: Zhyper是一个参数高效的分解超网络框架，可以通过文本描述生成上下文感知的LoRA适配器，以解决提示工程在LLM条件化方面的不足。


<details>
  <summary>Details</summary>
Motivation: 提示工程无法确保LLM遵循期望的条件化，因为预训练和对齐数据集存在归纳偏倚。现有微调方法（如LoRA权重条件化）会引入大量参数。

Method: 提出Zhyper，一个参数高效的分解超网络框架，它从文本描述生成上下文感知的LoRA适配器。

Result: Zhyper在多个基准测试中取得了有竞争力的性能，参数数量比最先进的方法少26倍。此外，Zhyper在文化对齐方面表现出更好的泛化能力和对细粒度上下文值的捕捉能力。

Conclusion: Zhyper提供了一种参数高效的LLM条件化方法，通过生成上下文感知的LoRA适配器，在保持高性能的同时显著减少了参数数量，并在文化对齐等领域显示出改进的泛化能力。

Abstract: Large Language Model (LLM) conditioning refers to instructing an LLM to
generate content in accordance with the norms and values of a specific culture,
beliefs of a particular political orientation, or any desired text-specified
semantic conditioning. Unfortunately, prompt engineering does not ensure that
LLMs behave in accordance with a desired conditioning due to the inductive bias
of the pre-training and alignment datasets. Prior works have focused on
fine-tuning LLMs by directly conditioning the LoRA weights; however, such
methods introduce a large number of parameters. As a remedy, we propose Zhyper,
a parameter-efficient factorized hypernetwork framework that generates
context-aware LoRA adapters from textual descriptions. Experiments on multiple
benchmarks show that Zhyper achieves competitive performance with up to 26x
fewer parameters than the state-of-the-art baselines. Furthermore, we extend
Zhyper to cultural alignment, demonstrating improved generalization to
out-of-domain settings and a better capturing of fine-grained contextual
values.

</details>


### [146] [SmartSwitch: Advancing LLM Reasoning by Overcoming Underthinking via Promoting Deeper Thought Exploration](https://arxiv.org/abs/2510.19767)
*Xichen Zhang,Sitong Wu,Haoru Tan,Shaozuo Yu,Yinghao Zhu,Ziyi He,Jiaya Jia*

Main category: cs.CL

TL;DR: 该研究提出了一种名为SmartSwitch的推理框架，用于解决大语言模型在复杂推理任务中“思考不足”的问题，通过监测和引导模型进行更深入的思考来提升性能和代币效率。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在复杂推理任务中存在的“思考不足”问题，即模型推理时过早放弃有潜力的思考方向，导致性能和代币效率受限。

Method: 提出SmartSwitch推理框架，该框架能插入到任何大语言模型中。它通过感知模块识别思考的切换点，并利用过程奖励模型（PRM）评估先前思考的潜力。如果发现有潜力的思考被过早放弃，干预模块会中断推理，回溯并插入“深化提示”以鼓励对该路径进行更深入的探索。

Result: 在具有挑战性的数学推理基准测试上进行了广泛的实验，结果表明该方法显著提升了不同尺寸的各种大语言模型的性能。

Conclusion: SmartSwitch推理框架是一种简单有效的方法，可以解决大语言模型在复杂推理任务中的“思考不足”问题，提升其性能和效率。

Abstract: The long chain-of-thought (LongCoT) capability is central to the recent
breakthroughs achieved by large language models in complex reasoning tasks.
However, the accompanying issue of ''underthinking'', where models exhibit
shallow reasoning by frequently switching thoughts without sufficient
exploration, limits both performance and token efficiency. To address this
problem, we propose a simple yet effective reasoning strategy: the SmartSwitch
inference framework. This framework can be easily integrated into any large
language model as a plug-and-play solution, continuously monitoring the model's
reasoning process to detect underthinking and guide it toward deeper
exploration of promising but overlooked thoughts. Specifically, the perception
module identifies points where thoughts switch and evaluates the potential of
the preceding thought using an off-the-shelf process reward model (PRM). If a
high-potential thought is found to be prematurely abandoned, the intervention
module interrupts the ongoing inference, backtracks to the point before the
switch, and inserts a "deepening prompt" to encourage further exploration along
that promising path. Extensive experiments on challenging mathematical
reasoning benchmarks demonstrate that our method significantly enhances the
performance of various large language models of different sizes.

</details>


### [147] [AdaSPEC: Selective Knowledge Distillation for Efficient Speculative Decoders](https://arxiv.org/abs/2510.19779)
*Yuezhou Hu,Jiaxin Guo,Xinyu Feng,Tuo Zhao*

Main category: cs.CL

TL;DR: AdaSPEC通过选择性地过滤难以拟合的Token来改进Speculative Decoding的知识蒸馏过程，提高了Token接受率，并且在各种任务上优于现有的方法。


<details>
  <summary>Details</summary>
Motivation: 传统的知识蒸馏（KD）方法旨在最小化草稿模型和目标模型在所有Token上的KL散度，这与Speculative Decoding（SD）旨在最大化Token接受率的真正目标不一致。由于容量限制，草稿模型往往难以完全吸收目标模型的知识，导致性能不佳。

Method: AdaSPEC是一种新颖的方法，它将选择性Token过滤整合到KD过程中。AdaSPEC使用一个参考模型来识别和过滤掉难以拟合的Token，从而使得草稿模型能够更好地在更简单的Token上与目标模型保持一致。

Result: AdaSPEC在各种任务（包括算术推理、指令遵循、编码和摘要）上，使用31M/1.4B和350M/2.7B参数的模型配置进行了评估。结果表明，AdaSPEC的Token接受率持续优于最先进的DistillSpec方法（最高可提高15%），并且在不影响生成质量的情况下实现了这一目标。

Conclusion: AdaSPEC通过选择性Token过滤改进了Speculative Decoding的知识蒸馏，提高了Token接受率，同时保持了生成质量，并在多项基准测试中优于现有技术。

Abstract: Speculative Decoding (SD) accelerates large language model inference by
employing a small draft model to generate predictions, which are then verified
by a larger target model. The effectiveness of SD hinges on the alignment
between these models, which is typically enhanced by Knowledge Distillation
(KD). However, conventional KD methods aim to minimize the KL divergence
between the draft and target models across all tokens, a goal that is
misaligned with the true objective of SD, which is to maximize token acceptance
rate. Therefore, draft models often struggle to fully assimilate the target
model's knowledge due to capacity constraints, leading to suboptimal
performance. To address this challenge, we propose AdaSPEC, a novel method that
incorporates selective token filtering into the KD process. AdaSPEC utilizes a
reference model to identify and filter out difficult-to-fit tokens, enabling
the distillation of a draft model that better aligns with the target model on
simpler tokens. This approach improves the overall token acceptance rate
without compromising generation quality. We evaluate AdaSPEC across diverse
tasks, including arithmetic reasoning, instruction-following, coding, and
summarization, using model configurations of 31M/1.4B and 350M/2.7B parameters.
Our results demonstrate that AdaSPEC consistently outperforms the
state-of-the-art DistillSpec method, achieving higher acceptance rates across
all tasks (up to 15\%). The code is publicly available at
https://github.com/yuezhouhu/adaspec.

</details>


### [148] [Adapting Multilingual Models to Code-Mixed Tasks via Model Merging](https://arxiv.org/abs/2510.19782)
*Prashant Kodali,Vaishnavi Shivkumar,Swarang Joshi,Monojit Choudhary,Ponnurangam Kumaraguru,Manish Shrivastava*

Main category: cs.CL

TL;DR: 模型合并是一种比传统方法更有效的代码混合NLP适应策略。


<details>
  <summary>Details</summary>
Motivation: 在代码混合NLP任务中，寻找比传统方法更有效的模型适应策略。

Method: 1. 使用未标记的代码混合文本进行持续预训练（CPT）以获得适应性检查点。2. 将适应性检查点与基础模型合并。3. 在下游任务数据上进行微调（FT）。

Result: 在英语-印地语（En-Hi）和英语-西班牙语（En-Es）的句子分类任务（情感和仇恨言论）上，合并模型在F1分数上持续优于完全微调和CPT->FT，分别提高了2-5个点和约1-2个点。合并模型在跨语言迁移（En-Hi到En-Ta和En-Ml）上也表现更强。

Conclusion: 模型合并是代码混合NLP任务的一种有前景的适应策略，尤其是在利用未标记数据和促进低资源语言对的迁移方面。该研究还提供了针对不同数据情况的适应方法，并讨论了模型的扩展性。

Abstract: We study model merging as a practical alternative to conventional adaptation
strategies for code-mixed NLP. Starting from a multilingual base model, we: (i)
perform continued pre-training (CPT) on unlabeled code-mixed text to obtain an
adapted checkpoint, (ii) merge checkpoint with the base model, and (iii)
fine-tune (FT) on the downstream task data. We evaluate our approach for
sentence classification (sentiment and hate speech) task in English-Hindi
(En-Hi) and English-Spanish (En-Es) using XLM-R and Llama-3.2-1B models. Our
results show that merged models consistently outperform full fine-tuning and
CPT->FT. We observe gains of 2--5 points in F1 over full fine-tuning and ~1-2
points over CPT->FT, indicating that unlabeled data is leveraged more
effectively via merging than via CPT alone. Zero-/few-shot prompting with
larger LLMs (e.g., Llama-3.3-70B) lags behind fine-tuned and merged
checkpoints, underscoring limits of in-context learning for code-mixed inputs.
We further test cross-pair transfer by training on En-Hi and evaluating on
En-Ta and En-Ml: merged checkpoints transfer more strongly than
monolingual-English baselines (e.g., TV/TIES variants reaching 0.65-0.68 F1 vs
0.61-0.63 for full fine-tuning), suggesting that code-mixed knowledge is a more
reliable substrate for low-resource pairs. We conclude with adaptation recipes
matched to common data regimes (labeled only; labeled+unlabeled; transfer-only)
and discuss limitations and scaling considerations for broader tasks and larger
models.

</details>


### [149] [ToolDreamer: Instilling LLM Reasoning Into Tool Retrievers](https://arxiv.org/abs/2510.19791)
*Saptarshi Sengupta,Zhengyu Zhou,Jun Araki,Xingbo Wang,Bingqing Wang,Suhang Wang,Zhe Feng*

Main category: cs.CL

TL;DR: To address the challenge of LLMs handling large tool sets, this paper proposes ToolDreamer, a framework that uses an LLM to generate hypothetical tool descriptions, improving retriever performance and enabling LLMs to manage more tools without exceeding context limits.


<details>
  <summary>Details</summary>
Motivation: Existing retrieval models for LLMs struggle with large tool sets because token limits prevent including all tools, and ranking tools by similarity to tool descriptions (TD) is suboptimal due to misalignment between user queries and TD language.

Method: ToolDreamer is a framework that conditions retriever models to fetch tools based on hypothetical (synthetic) tool descriptions generated by an LLM. These synthetic TDs are created based on what the LLM deems potentially useful for a given query, allowing for a more natural alignment between queries and tools in the TD language space.

Result: The ToolDreamer framework was applied to the ToolRet dataset, showing improved performance for both sparse and dense retrievers, regardless of whether training was involved. This demonstrates the framework's flexibility and effectiveness.

Conclusion: ToolDreamer offers a flexible and effective solution for improving tool retrieval in LLMs, particularly for large tool sets. By offloading some reasoning to the retriever through synthetic tool descriptions, it allows LLMs to handle more tools without exceeding context window limitations.

Abstract: Tool calling has become increasingly popular for Large Language Models
(LLMs). However, for large tool sets, the resulting tokens would exceed the
LLM's context window limit, making it impossible to include every tool. Hence,
an external retriever is used to provide LLMs with the most relevant tools for
a query. Existing retrieval models rank tools based on the similarity between a
user query and a tool description (TD). This leads to suboptimal retrieval as
user requests are often poorly aligned with the language of TD. To remedy the
issue, we propose ToolDreamer, a framework to condition retriever models to
fetch tools based on hypothetical (synthetic) TD generated using an LLM, i.e.,
description of tools that the LLM feels will be potentially useful for the
query. The framework enables a more natural alignment between queries and tools
within the language space of TD's. We apply ToolDreamer on the ToolRet dataset
and show that our method improves the performance of sparse and dense
retrievers with and without training, thus showcasing its flexibility. Through
our proposed framework, our aim is to offload a portion of the reasoning burden
to the retriever so that the LLM may effectively handle a large collection of
tools without inundating its context window.

</details>


### [150] [The Art of Asking: Multilingual Prompt Optimization for Synthetic Data](https://arxiv.org/abs/2510.19806)
*David Mora,Viraat Aryabumi,Wei-Yin Ko,Sara Hooker,Julia Kreutzer,Marzieh Fadaee*

Main category: cs.CL

TL;DR: 使用轻量级框架优化提示空间，改进多语言大语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 基于翻译的提示限制了多语言大模型的能力，忽略了文化维度，限制了模型的泛化能力。

Method: 提出一个轻量级框架，对翻译后的提示进行自然度、文化适应性和难度增强的系统性转换。

Result: 在相同的实验条件下，与仅使用翻译的基线方法相比，该方法在Global-MMLU准确率上提高了4.7%，在Flores XCometXL上提高了2.4%，在mArenaHard上的偏好度提升了35.3%。

Conclusion: 提示空间优化是一种简单而强大的范式，可以构建更健壮、更具文化基础和全球适应性的多语言大语言模型。

Abstract: Synthetic data has become a cornerstone for scaling large language models,
yet its multilingual use remains bottlenecked by translation-based prompts.
This strategy inherits English-centric framing and style and neglects cultural
dimensions, ultimately constraining model generalization. We argue that the
overlooked prompt space-the very inputs that define training
distributions-offers a more powerful lever for improving multilingual
performance. We introduce a lightweight framework for prompt-space
optimization, where translated prompts are systematically transformed for
Naturalness, Cultural Adaptation, and Difficulty Enhancement. Using an
off-the-shelf multilingual LLM, we apply these transformations to prompts for
12 languages spanning 7 families. Under identical data conditions, our
approaches achieve substantial and consistent downstream improvements over the
translation-only baseline: +4.7% on Global-MMLU accuracy, +2.4% on Flores
XCometXL and +35.3% wins in preferences on mArenaHard. We establish
prompt-space optimization as a simple yet powerful paradigm for building
multilingual LLMs that are more robust, culturally grounded, and globally
capable.

</details>


### [151] [Scaf-GRPO: Scaffolded Group Relative Policy Optimization for Enhancing LLM Reasoning](https://arxiv.org/abs/2510.19807)
*Xichen Zhang,Sitong Wu,Yinghao Zhu,Haoru Tan,Shaozuo Yu,Ziyi He,Jiaya Jia*

Main category: cs.CL

TL;DR: Scaf-GRPO通过在模型学习停滞时提供分层提示来克服“学习悬崖”现象，显著提高了LLM在数学推理方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法在处理超出LLM当前能力范围的问题时会遇到“学习悬崖”现象，导致模型无法从零奖励信号中学习，阻碍了训练进展。需要一种方法来克服这个问题，使LLM能够解决更复杂的问题。

Method: 提出Scaf-GRPO（Scaffolded Group Relative Policy Optimization）框架，该框架首先诊断学习停滞，然后通过注入分层提示（从抽象概念到具体步骤）来提供指导，引导模型自行构建解决方案。

Result: 在具有挑战性的数学基准测试中，Scaf-GRPO将Qwen2.5-Math-7B模型在AIME24基准测试上的pass@1分数相对提高了44.3%，显著优于基线GRPO模型。

Conclusion: Scaf-GRPO框架提供了一种有效的方法，可以解锁LLM解决先前无法解决的问题的能力，这是朝着扩展LLM自主推理前沿迈出的关键一步。

Abstract: Reinforcement learning from verifiable rewards has emerged as a powerful
technique for enhancing the complex reasoning abilities of Large Language
Models (LLMs). However, these methods are fundamentally constrained by the
''learning cliff'' phenomenon: when faced with problems far beyond their
current capabilities, models consistently fail, yielding a persistent
zero-reward signal. In policy optimization algorithms like GRPO, this collapses
the advantage calculation to zero, rendering these difficult problems invisible
to the learning gradient and stalling progress. To overcome this, we introduce
Scaf-GRPO (Scaffolded Group Relative Policy Optimization), a progressive
training framework that strategically provides minimal guidance only when a
model's independent learning has plateaued. The framework first diagnoses
learning stagnation and then intervenes by injecting tiered in-prompt hints,
ranging from abstract concepts to concrete steps, enabling the model to
construct a valid solution by itself. Extensive experiments on challenging
mathematics benchmarks demonstrate Scaf-GRPO's effectiveness, boosting the
pass@1 score of the Qwen2.5-Math-7B model on the AIME24 benchmark by a relative
44.3% over a vanilla GRPO baseline. This result demonstrates our framework
provides a robust and effective methodology for unlocking a model's ability to
solve problems previously beyond its reach, a critical step towards extending
the frontier of autonomous reasoning in LLM.

</details>


### [152] [Hubble: a Model Suite to Advance the Study of LLM Memorization](https://arxiv.org/abs/2510.19811)
*Johnny Tian-Zheng Wei,Ameya Godbole,Mohammad Aflah Khan,Ryan Wang,Xiaoyuan Zhu,James Flemings,Nitya Kashyap,Krishna P. Gummadi,Willie Neiswanger,Robin Jia*

Main category: cs.CL

TL;DR: Hubble是一个开源的大型语言模型（LLM）套件，用于研究LLM的记忆现象。它包括标准模型和扰动模型，旨在评估和理解记忆风险。研究表明，记忆风险与敏感数据在训练语料库中的频率有关，并且敏感数据在训练早期出现时更容易被记忆。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是提供一个开源的LLM套件（Hubble），用于深入研究LLM的记忆现象，特别是评估和理解记忆风险。通过设计标准模型和扰动模型，研究者可以量化不同因素（如数据频率、插入位置）对模型记忆能力的影响。

Method: Hubble套件包含标准模型和扰动模型。标准模型在大规模英语语料库上进行预训练。扰动模型在相同基础上，通过有控制地插入特定文本（如书籍、传记、测试集）来模拟关键的记忆风险。研究中发布了8个模型（1B或8B参数，100B或500B tokens），并分析了不同预训练阶段插入文本的模型，以评估数据暴露频率和持续性对记忆的影响。

Result: 研究发现，记忆风险取决于敏感数据在训练语料库中的相对频率（例如，在较小的语料库中出现一次的密码比在较大的语料库中出现更易被记忆）。此外，研究表明，如果没有持续的暴露，敏感数据可能会被遗忘。Hubble模型还可用于分析不同类型私有信息的记忆情况，并作为成员推断和机器遗忘测试的理想平台。

Conclusion: 为了降低记忆风险，建议采取两种最佳实践：一是通过扩大训练语料库的规模来稀释敏感数据；二是将敏感数据安排在训练的早期阶段。Hubble套件为进一步研究LLM记忆、成员推断和机器遗忘提供了基础。

Abstract: We present Hubble, a suite of fully open-source large language models (LLMs)
for the scientific study of LLM memorization. Hubble models come in standard
and perturbed variants: standard models are pretrained on a large English
corpus, and perturbed models are trained in the same way but with controlled
insertion of text (e.g., book passages, biographies, and test sets) designed to
emulate key memorization risks. Our core release includes 8 models -- standard
and perturbed models with 1B or 8B parameters, pretrained on 100B or 500B
tokens -- establishing that memorization risks are determined by the frequency
of sensitive data relative to size of the training corpus (i.e., a password
appearing once in a smaller corpus is memorized better than the same password
in a larger corpus). Our release also includes 6 perturbed models with text
inserted at different pretraining phases, showing that sensitive data without
continued exposure can be forgotten. These findings suggest two best practices
for addressing memorization risks: to dilute sensitive data by increasing the
size of the training corpus, and to order sensitive data to appear earlier in
training. Beyond these general empirical findings, Hubble enables a broad range
of memorization research; for example, analyzing the biographies reveals how
readily different types of private information are memorized. We also
demonstrate that the randomized insertions in Hubble make it an ideal testbed
for membership inference and machine unlearning, and invite the community to
further explore, benchmark, and build upon our work.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [153] [A flexible framework for structural plasticity in GPU-accelerated sparse spiking neural networks](https://arxiv.org/abs/2510.19764)
*James C. Knight,Johanna Senk,Thomas Nowotny*

Main category: cs.NE

TL;DR: 受生物大脑结构可塑性的启发，本文提出了一种新的GPU加速框架，用于实现和模拟稀疏脉冲神经网络（SNNs）的结构可塑性，从而在机器学习任务中提高训练效率并减少计算需求。


<details>
  <summary>Details</summary>
Motivation: 当前的机器学习框架在反向传播训练中优化了密集连接，导致修剪（pruning）等结构可塑性技术无法降低训练成本。生物大脑中的结构可塑性（创建和移除连接）对于学习、损伤恢复和资源优化至关重要，这启发了研究者探索在人工神经网络中实现类似机制。

Method: 本文提出并实现了一个灵活的GPU加速框架，该框架能够实现结构可塑性规则。框架首先与e-prop监督学习规则和DEEP R算法结合，用于训练稀疏SNN分类器；然后，在无监督学习的背景下，用于学习地形图。

Result: 与基线密集模型相比，本文提出的稀疏分类器将训练时间缩短了高达10倍，并且DEEP R重塑（rewiring）技术使稀疏模型的性能与原始密集模型相当。此外，研究还演示了地形图的形成，并对连接演化进行了分析，同时测量了模拟速度与网络规模的关系。

Conclusion: 所提出的框架能够促进对网络结构和神经通信中实现和维持稀疏性的进一步研究，并在神经形态应用中探索稀疏性的计算优势。

Abstract: The majority of research in both training Artificial Neural Networks (ANNs)
and modeling learning in biological brains focuses on synaptic plasticity,
where learning equates to changing the strength of existing connections.
However, in biological brains, structural plasticity - where new connections
are created and others removed - is also vital, not only for effective learning
but also for recovery from damage and optimal resource usage. Inspired by
structural plasticity, pruning is often used in machine learning to remove weak
connections from trained models to reduce the computational requirements of
inference. However, the machine learning frameworks typically used for
backpropagation-based training of both ANNs and Spiking Neural Networks (SNNs)
are optimized for dense connectivity, meaning that pruning does not help reduce
the training costs of ever-larger models. The GeNN simulator already supports
efficient GPU-accelerated simulation of sparse SNNs for computational
neuroscience and machine learning. Here, we present a new flexible framework
for implementing GPU-accelerated structural plasticity rules and demonstrate
this first using the e-prop supervised learning rule and DEEP R to train
efficient, sparse SNN classifiers and then, in an unsupervised learning
context, to learn topographic maps. Compared to baseline dense models, our
sparse classifiers reduce training time by up to 10x while the DEEP R rewiring
enables them to perform as well as the original models. We demonstrate
topographic map formation in faster-than-realtime simulations, provide insights
into the connectivity evolution, and measure simulation speed versus network
size. The proposed framework will enable further research into achieving and
maintaining sparsity in network structure and neural communication, as well as
exploring the computational benefits of sparsity in a range of neuromorphic
applications.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [154] [Test-time Verification via Optimal Transport: Coverage, ROC, & Sub-optimality](https://arxiv.org/abs/2510.18982)
*Arpan Mukherjee,Marcello Bullo,Debabrota Basu,Deniz Gündüz*

Main category: cs.AI

TL;DR: 验证测试时缩放的性能提升依赖于生成器覆盖率、验证器收敛区域（ROC）和采样子最优性的相互作用。本文将此问题建模为运输问题，揭示了子最优性-覆盖率曲线存在三个区域：运输区、策略改进区和饱和区。研究了顺序和批量采样算法，并结合了Qwen、Llama和Gemma模型进行了实证分析。


<details>
  <summary>Details</summary>
Motivation: 在测试时缩放（test-time scaling）过程中，验证（verification）的引入虽然有潜力提升大型语言模型（LLMs）的性能，但验证器本身的作用及其不完美之处尚未得到充分探索。

Method: 将可验证的测试时缩放视为一个运输问题（transport problem），以此来刻画生成器覆盖率、验证器收敛区域（ROC）和采样子最优性之间的相互作用。进一步提出并分析了两类采样算法（顺序和批量），并考察了它们的计算复杂度如何影响这些权衡。

Result: 揭示了子最优性-覆盖率曲线存在三个区域：运输区（transport regime），其中子最优性随覆盖率的增加而增加；策略改进区（policy improvement regime），其中子最优性可能随覆盖率的增加而减少，具体取决于验证器的ROC；以及饱和区（saturation regime），其中子最优性趋于平稳，不受覆盖率影响。

Conclusion: 通过将可验证的测试时缩放建模为运输问题，我们能够量化生成器覆盖率、验证器ROC和采样子最优性之间的相互作用，并识别出子最优性-覆盖率曲线的三个不同区域。所提出的采样算法及其计算复杂度分析有助于理解这些权衡。实证结果支持了理论发现。

Abstract: While test-time scaling with verification has shown promise in improving the
performance of large language models (LLMs), the role of the verifier and its
imperfections remain underexplored. The effect of verification manifests
through interactions of three quantities: (i) the generator's coverage, (ii)
the verifier's region of convergence (ROC), and (iii) the sampling algorithm's
sub-optimality. Though recent studies capture subsets of these factors, a
unified framework quantifying the geometry of their interplay is missing. We
frame verifiable test-time scaling as a transport problem. This characterizes
the interaction of coverage, ROC, and sub-optimality, and uncovers that the
sub-optimality--coverage curve exhibits three regimes. A transport regime --
where sub-optimality increases with coverage, a policy improvement regime --
where sub-optimality may decrease with coverage, depending on the verifier's
ROC, and a saturation regime -- where sub-optimality plateaus, unaffected by
coverage. We further propose and analyze two classes of sampling algorithms --
sequential and batched, and examine how their computational complexities shape
these trade-offs. Empirical results with Qwen, Llama, and Gemma models
corroborate our theoretical findings.

</details>


### [155] [Timely Clinical Diagnosis through Active Test Selection](https://arxiv.org/abs/2510.18988)
*Silas Ruhrberg Estévez,Nicolás Astorga,Mihaela van der Schaar*

Main category: cs.AI

TL;DR: ACTMED是一个结合了贝叶斯实验设计（BED）和大型语言模型（LLMs）的临床诊断框架，旨在模拟医生实际的诊断推理过程，通过自适应地选择最有价值的检查来减少诊断不确定性，并支持临床医生的决策。


<details>
  <summary>Details</summary>
Motivation: 目前大多数机器学习诊断方法依赖于静态、完全观测的数据集，未能反映临床医生在实践中进行顺序的、考虑资源限制的推理。在压力大或资源有限的情况下，诊断的复杂性和易错性凸显了开发能够帮助医生做出及时、经济有效的决策的框架的必要性。

Method: ACTMED框架结合了贝叶斯实验设计（BED）和大型语言模型（LLMs）。在每个诊断步骤中，ACTMED会选择一个预期能最大程度减少患者诊断不确定性的检查。LLMs作为灵活的模拟器，可以生成合理的患者状态分布，并支持信念更新，而无需结构化的、特定任务的训练数据。此外，该框架允许临床医生参与其中，审查检查建议，解释中间输出，并在整个过程中运用临床判断。

Result: 通过在真实世界数据集上的评估，ACTMED能够优化检查选择，从而提高诊断准确性、可解释性和资源利用率。

Conclusion: ACTMED代表了朝着更透明、自适应、且与临床医生需求一致的诊断系统迈出的重要一步，该系统能够减少对特定领域数据的依赖，并跨不同环境进行泛化。

Abstract: There is growing interest in using machine learning (ML) to support clinical
diag- nosis, but most approaches rely on static, fully observed datasets and
fail to reflect the sequential, resource-aware reasoning clinicians use in
practice. Diagnosis remains complex and error prone, especially in
high-pressure or resource-limited settings, underscoring the need for
frameworks that help clinicians make timely and cost-effective decisions. We
propose ACTMED (Adaptive Clinical Test selection via Model-based Experimental
Design), a diagnostic framework that integrates Bayesian Experimental Design
(BED) with large language models (LLMs) to better emulate real-world diagnostic
reasoning. At each step, ACTMED selects the test expected to yield the greatest
reduction in diagnostic uncertainty for a given patient. LLMs act as flexible
simulators, generating plausible patient state distributions and supporting
belief updates without requiring structured, task-specific training data.
Clinicians can remain in the loop; reviewing test suggestions, interpreting
intermediate outputs, and applying clinical judgment throughout. We evaluate
ACTMED on real-world datasets and show it can optimize test selection to
improve diagnostic accuracy, interpretability, and resource use. This
represents a step to- ward transparent, adaptive, and clinician-aligned
diagnostic systems that generalize across settings with reduced reliance on
domain-specific data.

</details>


### [156] [Rectifying Shortcut Behaviors in Preference-based Reward Learning](https://arxiv.org/abs/2510.19050)
*Wenqian Ye,Guangtao Zheng,Aidong Zhang*

Main category: cs.AI

TL;DR: 基于不变性理论的PRISM方法能有效缓解奖励模型中的捷径行为，提高泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于人类反馈的强化学习方法在对齐大型语言模型时，奖励模型容易出现奖励破解和泛化能力差的问题，这是因为它们过度优化利用了训练数据中的虚假特征（如响应冗长、迎合语气或谄媚），而不是真正反映目标。

Method: 提出了一种名为PRISM（Preference-based Reward Invariance for Shortcut Mitigation）的框架，该框架受到核方法中不变性理论的启发，通过学习具有特征映射的群不变核，并提供了一个封闭形式的学习目标，以减轻奖励学习中的捷径行为。

Result: 实验结果表明，PRISM方法在多个基准测试中，能够持续提高奖励模型在各种分布外任务上的准确性，并减少下游策略模型对捷径的依赖。

Conclusion: PRISM提供了一个稳健的框架，用于基于偏好的对齐，有效解决了奖励模型中的捷径行为问题，提高了模型的泛化能力和鲁棒性。

Abstract: In reinforcement learning from human feedback, preference-based reward models
play a central role in aligning large language models to human-aligned
behavior. However, recent studies show that these models are prone to reward
hacking and often fail to generalize well due to over-optimization. They
achieve high reward scores by exploiting shortcuts, that is, exploiting
spurious features (e.g., response verbosity, agreeable tone, or sycophancy)
that correlate with human preference labels in the training data rather than
genuinely reflecting the intended objectives. In this paper, instead of probing
these issues one at a time, we take a broader view of the reward hacking
problem as shortcut behaviors and introduce a principled yet flexible approach
to mitigate shortcut behaviors in preference-based reward learning. Inspired by
the invariant theory in the kernel perspective, we propose Preference-based
Reward Invariance for Shortcut Mitigation (PRISM), which learns group-invariant
kernels with feature maps in a closed-form learning objective. Experimental
results in several benchmarks show that our method consistently improves the
accuracy of the reward model on diverse out-of-distribution tasks and reduces
the dependency on shortcuts in downstream policy models, establishing a robust
framework for preference-based alignment.

</details>


### [157] [The MUSE Benchmark: Probing Music Perception and Auditory Relational Reasoning in Audio LLMS](https://arxiv.org/abs/2510.19055)
*Brandon James Carone,Iran R. Roman,Pablo Ripollés*

Main category: cs.AI

TL;DR: MLLMs在音频理解方面表现出色，但可能存在潜在的关联推理缺陷。我们提出了MUSE基准，包含10项任务，用于评估基础音乐感知能力。我们评估了Gemini Pro和Flash、Qwen2.5-Omni和Audio-Flamingo 3四个模型，并与200名人类被试进行了比较。结果显示，模型能力差异很大，且与人类专家存在差距。Gemini Pro在基本感知方面表现良好，而Qwen和Audio Flamingo 3的表现接近随机猜测，暴露了严重的感知缺陷。此外，思维链（CoT）提示的效果不稳定，甚至可能适得其反。我们的研究为评估不变的音乐表示和推动更强大的AI系统开发提供了关键工具。


<details>
  <summary>Details</summary>
Motivation: 评估现有MLLMs在音乐理解方面的能力，特别是其关联推理能力，并揭示其潜在的根本性弱点。

Method: 创建了包含10个任务的MUSE基准，用于评估基础音乐感知能力。评估了Gemini Pro和Flash、Qwen2.5-Omni和Audio-Flamingo 3四个SOTA模型，并与200名人类被试进行了比较。分析了思维链（CoT）提示的效果。

Result: MLLMs在音乐理解方面存在能力差异，且与人类专家存在差距。Gemini Pro在基本感知任务上表现良好，而Qwen2.5-Omni和Audio-Flamingo 3的表现接近随机猜测。思维链（CoT）提示的效果不稳定，有时会损害模型性能。

Conclusion: 现有的MLLMs在音乐理解方面仍有很大提升空间，尤其是在关联推理方面。MUSE基准提供了一个评估不变音乐表示和推动更强大AI系统开发的工具。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated capabilities in
audio understanding, but current evaluations may obscure fundamental weaknesses
in relational reasoning. We introduce the Music Understanding and Structural
Evaluation (MUSE) Benchmark, an open-source resource with 10 tasks designed to
probe fundamental music perception skills. We evaluate four SOTA models (Gemini
Pro and Flash, Qwen2.5-Omni, and Audio-Flamingo 3) against a large human
baseline (N=200). Our results reveal a wide variance in SOTA capabilities and a
persistent gap with human experts. While Gemini Pro succeeds on basic
perception, Qwen and Audio Flamingo 3 perform at or near chance, exposing
severe perceptual deficits. Furthermore, we find Chain-of-Thought (CoT)
prompting provides inconsistent, often detrimental results. Our work provides a
critical tool for evaluating invariant musical representations and driving
development of more robust AI systems.

</details>


### [158] [A Multi-faceted Analysis of Cognitive Abilities: Evaluating Prompt Methods with Large Language Models on the CONSORT Checklist](https://arxiv.org/abs/2510.19139)
*Sohyeon Jeon,Hyung-Chul Lee*

Main category: cs.AI

TL;DR: LLMs在临床试验报告的合规性方面存在局限性，需要进一步研究其认知和推理策略。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在遵循CONSORT标准方面评估临床试验报告的能力，特别是它们在认知和推理策略方面的表现。

Method: 采用行为和元认知分析方法，并使用专家验证的数据，在三种提示条件下系统地比较了两个代表性的LLMs。

Result: 在LLMs如何处理不同的CONSORT项目和提示类型方面，出现了明显的差异，包括推理风格、明确的不确定性和替代解释对响应模式的影响。

Conclusion: 研究结果强调了这些系统在临床合规自动化方面的现有局限性，并强调了理解其认知适应和战略行为对于开发更具可解释性和可靠性的医疗AI的重要性。

Abstract: Despite the rapid expansion of Large Language Models (LLMs) in healthcare,
the ability of these systems to assess clinical trial reporting according to
CONSORT standards remains unclear, particularly with respect to their cognitive
and reasoning strategies. This study applies a behavioral and metacognitive
analytic approach with expert-validated data, systematically comparing two
representative LLMs under three prompt conditions. Clear differences emerged in
how the models approached various CONSORT items, and prompt types, including
shifts in reasoning style, explicit uncertainty, and alternative
interpretations shaped response patterns. Our results highlight the current
limitations of these systems in clinical compliance automation and underscore
the importance of understanding their cognitive adaptations and strategic
behavior in developing more explainable and reliable medical AI.

</details>


### [159] [Learning to Make Friends: Coaching LLM Agents toward Emergent Social Ties](https://arxiv.org/abs/2510.19299)
*Philipp J. Schneider,Lin Tian,Marian-Andrei Rizoiu*

Main category: cs.AI

TL;DR: LLM 代理可以通过模仿人类在线行为的社会动态（如群体同质性、互惠性和社会认同）来重现复杂的人类在线行为。通过一个包含强化学习、适应性策略和行为奖励函数的框架，LLM 代理可以形成稳定的互动模式和网络结构，从而与真实的人类在线社区相媲美。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨大型语言模型（LLM）代理是否能够重现复杂的社会动态，以及哪些记忆和学习机制能够促使这些动态的出现。

Method: 提出一个多代理 LLM 模拟框架，其中代理通过强化学习、适应性策略和行为奖励函数进行互动、评估和学习。行为奖励函数的设计旨在捕捉在线参与的核心驱动因素，如社交互动、信息寻求、自我展示、协调和情感支持。

Result: 实验表明，经过训练的 LLM 代理能够形成稳定的互动模式和新兴的社会联系，并产生与真实在线社区相似的网络结构。

Conclusion: 该框架通过结合行为奖励和上下文适应，为研究 LLM 群体中的集体动态提供了一个原则性的测试平台，并揭示了人工智能代理在多大程度上能够模拟或偏离类似人类的社会行为。

Abstract: Can large language model (LLM) agents reproduce the complex social dynamics
that characterize human online behavior -- shaped by homophily, reciprocity,
and social validation -- and what memory and learning mechanisms enable such
dynamics to emerge? We present a multi-agent LLM simulation framework in which
agents repeatedly interact, evaluate one another, and adapt their behavior
through in-context learning accelerated by a coaching signal. To model human
social behavior, we design behavioral reward functions that capture core
drivers of online engagement, including social interaction, information
seeking, self-presentation, coordination, and emotional support. These rewards
align agent objectives with empirically observed user motivations, enabling the
study of how network structures and group formations emerge from individual
decision-making. Our experiments show that coached LLM agents develop stable
interaction patterns and form emergent social ties, yielding network structures
that mirror properties of real online communities. By combining behavioral
rewards with in-context adaptation, our framework establishes a principled
testbed for investigating collective dynamics in LLM populations and reveals
how artificial agents may approximate or diverge from human-like social
behavior.

</details>


### [160] [The Zero-Step Thinking: An Empirical Study of Mode Selection as Harder Early Exit in Reasoning Models](https://arxiv.org/abs/2510.19176)
*Yuqiao Tan,Shizhu He,Kang Liu,Jun Zhao*

Main category: cs.AI

TL;DR: 通过引入“模式选择”和“提前退出”机制，旨在使用户能够自主地决定是进行“长思考”还是“短思考”，以及确定最佳的推理停止点，从而减少计算开销。然而，现有方法在处理这些机制时存在局限性，尤其是在信息有限的情况下。对九种基线方法的实证研究表明，基于提示的方法效果不佳，而利用内部信息的方法虽然有所改善，但仍存在稳定性问题，这表明当前方法不足以有效解决信息有限情况下的模式选择问题。


<details>
  <summary>Details</summary>
Motivation: 现有的推理模型虽然在数学和逻辑推理任务中表现出色，但其逐步推理的过程往往导致不必要的计算开销。为了解决这个问题，需要一种能够自动选择推理模式（长思考或短思考）并确定最佳停止点的方法，以减少计算量。

Method: 本文提出了“模式选择”和“提前退出”两种方法来解决推理模型的计算开销问题。“模式选择”旨在根据推理任务的需要，自动决定采用“长思考”还是“短思考”（“思考”或“不思考”模式）。“提前退出”则旨在确定推理过程中的最佳停止点。此外，本文还将“模式选择”视为“提前退出”问题的一个更具挑战性的变体，并提出了“零步思考”的概念，即在推理过程开始时，不进行显式的推理，而是基于预定义的虚构思考来做出决策。

Result: 通过在九种基线方法上进行实证研究，我们发现基于提示的方法由于其有限的分类能力和有限的、手工制作的信息而常常失败。相比之下，利用内部信息的方法在大多数情况下表现更好，但仍然存在稳定性问题。现有仅依赖模型提供信息的方法不足以有效解决信息有限情况下的模式选择问题。

Conclusion: 现有方法在处理“模式选择”问题时，尤其是在信息有限的情况下，存在显著的局限性。基于提示的方法效果不佳，而利用内部信息的方法虽然有所改善，但仍存在稳定性问题。这表明需要开发新的方法来有效解决信息有限情况下的“模式选择”问题。ⓗttps://github.com/Trae1ounG/Zero_Step_Thinking是本文的代码库链接。

Abstract: Reasoning models have demonstrated exceptional performance in tasks such as
mathematics and logical reasoning, primarily due to their ability to engage in
step-by-step thinking during the reasoning process. However, this often leads
to overthinking, resulting in unnecessary computational overhead. To address
this issue, Mode Selection aims to automatically decide between Long-CoT
(Chain-of-Thought) or Short-CoT by utilizing either a Thinking or NoThinking
mode. Simultaneously, Early Exit determines the optimal stopping point during
the iterative reasoning process. Both methods seek to reduce the computational
burden. In this paper, we first identify Mode Selection as a more challenging
variant of the Early Exit problem, as they share similar objectives but differ
in decision timing. While Early Exit focuses on determining the best stopping
point for concise reasoning at inference time, Mode Selection must make this
decision at the beginning of the reasoning process, relying on pre-defined fake
thoughts without engaging in an explicit reasoning process, referred to as
zero-step thinking. Through empirical studies on nine baselines, we observe
that prompt-based approaches often fail due to their limited classification
capabilities when provided with minimal hand-crafted information. In contrast,
approaches that leverage internal information generally perform better across
most scenarios but still exhibit issues with stability. Our findings indicate
that existing methods relying solely on the information provided by models are
insufficient for effectively addressing Mode Selection in scenarios with
limited information, highlighting the ongoing challenges of this task. Our code
is available at https://github.com/Trae1ounG/Zero_Step_Thinking.

</details>


### [161] [HSCodeComp: A Realistic and Expert-level Benchmark for Deep Search Agents in Hierarchical Rule Application](https://arxiv.org/abs/2510.19631)
*Yiqian Yang,Tian Lan,Qianghuai Jia,Li Zhu,Hui Jiang,Hang Zhu,Longyue Wang,Weihua Luo,Kaifu Zhang*

Main category: cs.AI

TL;DR: 该论文提出了一个名为HSCodeComp的新基准，用于评估深度搜索代理在应用复杂规则（例如，电子商务中的HS编码）方面的能力，并揭示了当前代理在这方面与人类专家相比存在巨大差距。


<details>
  <summary>Details</summary>
Motivation: 当前代理在理解和应用具有模糊边界和隐式逻辑关系的复杂规则（如法律条款、医学手册和关税规则）方面能力不足，现有基准未能充分评估这一关键能力。

Method: 提出并构建了一个名为HSCodeComp的基准，该基准包含632个商品条目，涵盖了多样化的商品类别，并由多个人类专家对这些商品的10位HS编码进行了标注。该基准旨在评估深度搜索代理在遵循这些规则以预测商品HS编码方面的能力。

Result: 在对包括最先进的LLM、开源和闭源代理在内的多种代理进行的广泛实验中，发现即使是最好的代理，其10位HS编码的准确率也仅为46.8%，远低于人类专家的95.0%。此外，详细的分析表明，分层规则应用存在挑战，并且在测试时进行扩展也未能进一步提高性能。

Conclusion: 目前的深度搜索代理在应用复杂的分层规则（如HS编码）方面仍然存在显著的局限性，与人类专家的表现差距巨大，并且现有技术未能有效解决这些挑战。

Abstract: Effective deep search agents must not only access open-domain and
domain-specific knowledge but also apply complex rules-such as legal clauses,
medical manuals and tariff rules. These rules often feature vague boundaries
and implicit logic relationships, making precise application challenging for
agents. However, this critical capability is largely overlooked by current
agent benchmarks.
  To fill this gap, we introduce HSCodeComp, the first realistic, expert-level
e-commerce benchmark designed to evaluate deep search agents in hierarchical
rule application. In this task, the deep reasoning process of agents is guided
by these rules to predict 10-digit Harmonized System Code (HSCode) of products
with noisy but realistic descriptions. These codes, established by the World
Customs Organization, are vital for global supply chain efficiency. Built from
real-world data collected from large-scale e-commerce platforms, our proposed
HSCodeComp comprises 632 product entries spanning diverse product categories,
with these HSCodes annotated by several human experts.
  Extensive experimental results on several state-of-the-art LLMs, open-source,
and closed-source agents reveal a huge performance gap: best agent achieves
only 46.8% 10-digit accuracy, far below human experts at 95.0%. Besides,
detailed analysis demonstrates the challenges of hierarchical rule application,
and test-time scaling fails to improve performance further.

</details>


### [162] [WebGraphEval: Multi-Turn Trajectory Evaluation for Web Agents using Graph Representation](https://arxiv.org/abs/2510.19205)
*Yaoyao Qian,Yuanli Wang,Jinda Zhang,Yun Zong,Meixu Chen,Hanhan Zhou,Jindan Huang,Yifan Zeng,Xinyu Hu,Chan Hee Song,Danqing Zhang*

Main category: cs.AI

TL;DR: WebGraphEval框架通过将多智能体轨迹抽象为统一的加权动作图，实现了对Web智能体的多维度评估，克服了现有方法只关注二元成功率或单一参考轨迹的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有Web智能体评估方法忽略了基准数据集中存在的结构多样性，主要依赖二元成功率或单一参考轨迹，无法全面反映智能体性能。

Method: 提出WebGraphEval框架，将多智能体轨迹抽象为统一的加权动作图。该框架能对动作进行规范编码，合并重复行为，并应用诸如奖励传播和基于成功率的边统计等结构分析。

Result: 在对六个Web智能体的数千条轨迹进行评估后，证明该图抽象能够捕捉跨模型规律，揭示冗余和低效之处，并识别出基于结果的指标所忽略的关键决策点。

Conclusion: WebGraphEval将Web交互视为图结构数据，为Web智能体的多路径、跨智能体和考虑效率的评估提供了一种通用方法。

Abstract: Current evaluation of web agents largely reduces to binary success metrics or
conformity to a single reference trajectory, ignoring the structural diversity
present in benchmark datasets. We present WebGraphEval, a framework that
abstracts trajectories from multiple agents into a unified, weighted action
graph. This representation is directly compatible with benchmarks such as
WebArena, leveraging leaderboard runs and newly collected trajectories without
modifying environments. The framework canonically encodes actions, merges
recurring behaviors, and applies structural analyses including reward
propagation and success-weighted edge statistics. Evaluations across thousands
of trajectories from six web agents show that the graph abstraction captures
cross-model regularities, highlights redundancy and inefficiency, and
identifies critical decision points overlooked by outcome-based metrics. By
framing web interaction as graph-structured data, WebGraphEval establishes a
general methodology for multi-path, cross-agent, and efficiency-aware
evaluation of web agents.

</details>


### [163] [ChatGPT Unveils Its Limits: Principles of Law Deliver Checkmate](https://arxiv.org/abs/2510.19261)
*Marianna Molinari,Ilaria Angela Amantea,Marinella Quaranta,Guido Governatori*

Main category: cs.AI

TL;DR: ChatGPT在法律领域未能展现出足够的综合和推理能力，其表现不如预期，显示了其局限性。


<details>
  <summary>Details</summary>
Motivation: 评估ChatGPT在法律领域的性能，并与正则表达式基线进行比较，以揭示其在处理复杂法律任务方面的局限性。

Method: 通过实验在法律领域评估ChatGPT的性能，并将其与使用正则表达式的基线方法进行比较。

Result: ChatGPT即使拥有必要的知识和能力，也无法进行整合和推理以得出详尽的结论，这暴露了其重大局限性。在法律领域，它缺乏全面的理解和推理能力来提取关键法律段落。

Conclusion: 人工智能在法律领域，尤其是在理解和推理方面，仍然存在固有的局限性。真正的智能，至少在这一特定领域，仍然是人类独有的特质。

Abstract: This study examines the performance of ChatGPT with an experiment in the
legal domain. We compare the outcome with it a baseline using regular
expressions (Regex), rather than focusing solely on the assessment against
human performance. The study reveals that even if ChatGPT has access to the
necessary knowledge and competencies, it is unable to assemble them, reason
through, in a way that leads to an exhaustive result. This unveils a major
limitation of ChatGPT. Intelligence encompasses the ability to break down
complex issues and address them according to multiple required competencies,
providing a unified and comprehensive solution. In the legal domain, one of the
most crucial tasks is reading legal decisions and extracting key passages
condensed from principles of law (PoLs), which are then incorporated into
subsequent rulings by judges or defense documents by lawyers. In performing
this task, artificial intelligence lacks an all-encompassing understanding and
reasoning, which makes it inherently limited. Genuine intelligence, remains a
uniquely human trait, at least in this particular field.

</details>


### [164] [An Argumentative Explanation Framework for Generalized Reason Model with Inconsistent Precedents](https://arxiv.org/abs/2510.19263)
*Wachara Fungwacharakorn,Gauvain Bourgne,Ken Satoh*

Main category: cs.AI

TL;DR: 本文将一种论证框架（DSA-framework）的扩展应用于解释基于不一致先例的广义推理模型。


<details>
  <summary>Details</summary>
Motivation: 现有的论证解释方法仅限于一致性先例，缺乏对包含不一致先例的广义推理模型的解释方法。

Method: 本研究考察了派生状态论证框架（DSA-framework）的扩展，以解释广义推理模型。

Result: 提出了一种适用于不一致先例的广义推理模型的论证解释方法。

Conclusion: 所提出的DSA-框架扩展能够为不一致先例的推理提供论证解释。

Abstract: Precedential constraint is one foundation of case-based reasoning in AI and
Law. It generally assumes that the underlying set of precedents must be
consistent. To relax this assumption, a generalized notion of the reason model
has been introduced. While several argumentative explanation approaches exist
for reasoning with precedents based on the traditional consistent reason model,
there has been no corresponding argumentative explanation method developed for
this generalized reasoning framework accommodating inconsistent precedents. To
address this question, this paper examines an extension of the derivation state
argumentation framework (DSA-framework) to explain the reasoning according to
the generalized notion of the reason model.

</details>


### [165] [Continual Knowledge Adaptation for Reinforcement Learning](https://arxiv.org/abs/2510.19314)
*Jinwu Hu,Zihao Lian,Zhiquan Wen,Chenghao Li,Guohao Chen,Xutao Wen,Bin Xiao,Mingkui Tan*

Main category: cs.AI

TL;DR: CKA-RL通过维护任务特定的知识向量池并动态使用历史知识来适应新任务，以减轻灾难性遗忘并实现跨任务的高效知识转移。


<details>
  <summary>Details</summary>
Motivation: 现实世界环境通常是非平稳的，需要智能体不断适应新任务和不断变化的情况。现有的持续强化学习方法常常遭受灾难性遗忘和知识利用效率低下的问题。

Method: 提出了一种持续知识适应策略，该策略包括维护一个特定于任务的知识向量池，并动态地使用历史知识来使智能体适应新任务。此外，还提出了一种自适应知识合并机制，用于合并相似的知识向量，以应对可扩展性挑战。

Result: 在三个基准测试上的实验表明，提出的CKA-RL在整体性能上提高了4.20%，在前向迁移上提高了8.02%，优于最先进的方法。

Conclusion: CKA-RL通过持续知识适应和自适应知识合并，有效解决了持续强化学习中的灾难性遗忘和知识利用效率低下问题，并在实验中取得了优于现有方法的结果。

Abstract: Reinforcement Learning enables agents to learn optimal behaviors through
interactions with environments. However, real-world environments are typically
non-stationary, requiring agents to continuously adapt to new tasks and
changing conditions. Although Continual Reinforcement Learning facilitates
learning across multiple tasks, existing methods often suffer from catastrophic
forgetting and inefficient knowledge utilization. To address these challenges,
we propose Continual Knowledge Adaptation for Reinforcement Learning (CKA-RL),
which enables the accumulation and effective utilization of historical
knowledge. Specifically, we introduce a Continual Knowledge Adaptation
strategy, which involves maintaining a task-specific knowledge vector pool and
dynamically using historical knowledge to adapt the agent to new tasks. This
process mitigates catastrophic forgetting and enables efficient knowledge
transfer across tasks by preserving and adapting critical model parameters.
Additionally, we propose an Adaptive Knowledge Merging mechanism that combines
similar knowledge vectors to address scalability challenges, reducing memory
requirements while ensuring the retention of essential knowledge. Experiments
on three benchmarks demonstrate that the proposed CKA-RL outperforms
state-of-the-art methods, achieving an improvement of 4.20% in overall
performance and 8.02% in forward transfer. The source code is available at
https://github.com/Fhujinwu/CKA-RL.

</details>


### [166] [MSC-Bench: A Rigorous Benchmark for Multi-Server Tool Orchestration](https://arxiv.org/abs/2510.19423)
*Jia-Kai Dong,I-Wei Huang,Chun-Tin Wu,Yi-Tien Tsai*

Main category: cs.AI

TL;DR: MSC-Bench是一个用于评估多跳、端到端工具编排的大型基准，解决了现有基准孤立评估工具的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基准在评估工具时常常将它们孤立起来，忽视了功能重叠和跨服务器编排等挑战，导致评估结果过于乐观。MSC-Bench旨在解决这些问题。

Method: MSC-Bench通过构建‘等价函数集’作为真实值来解决这些差距，从而可以使用F1分数等客观指标，并减少对‘LLM作为评判’的评估依赖。它被组织成一个五级课程，系统地测试智能体从单工具编排到复杂的跨服务器规划以及对范围外请求的鲁棒性。

Result: 实验表明，僵化的层次结构可能会在没有协同设计策略的情况下阻碍性能，即使是最先进的智能体在鲁棒性方面也表现出系统性弱点。

Conclusion: MSC-Bench提供了一个诊断框架，用于暴露这些局限性，并指导开发更强大、更高效的工具使用智能体。该基准和资源可在https://github.com/snooow1029/MSC_Bench公开获取。

Abstract: We introduce MSC-Bench, a large-scale benchmark for evaluating multi-hop,
end-to-end tool orchestration by LLM agents in a hierarchical Model-Context
Protocol (MCP) ecosystem. Existing benchmarks often evaluate tools in
isolation, ignoring challenges such as functional overlap and cross-server
orchestration, leading to overly optimistic assessments. MSC-Bench addresses
these gaps by constructing ground truth through 'equal function sets', allowing
objective metrics such as F1 score and reducing the dependency on
LLM-as-a-judge evaluation. Organized as a five-level curriculum, it
systematically tests agent capabilities from single-tool orchestration to
complex cross-server planning, and robustness to out-of-scope requests.
Experiments reveal that rigid hierarchies can hinder performance without
co-designed strategies, and even state-of-the-art agents exhibit systemic
weaknesses in robustness. MSC-Bench provides a diagnostic framework to expose
these limitations and guide the development of more capable and efficient
tool-using agents. The benchmark and resources are publicly available at
https://github.com/snooow1029/MSC_Bench.

</details>


### [167] [SysMoBench: Evaluating AI on Formally Modeling Complex Real-World Systems](https://arxiv.org/abs/2509.23130)
*Qian Cheng,Ruize Tang,Emilie Ma,Finn Hackett,Peiyang He,Yiming Su,Ivan Beschastnikh,Yu Huang,Xiaoxing Ma,Tianyin Xu*

Main category: cs.AI

TL;DR: SysMoBench 是一个评估 AI 生成形式化模型能力的基准，特别关注并发和分布式系统，使用 TLA+ 语言，并自动化评估指标，目前包含九个系统构件，旨在推动 AI 在形式化方法领域的研究。


<details>
  <summary>Details</summary>
Motivation: 生成形式化模型成本高昂，而生成式 AI 有潜力解决这个问题，但现有工作主要集中在小型代码上，不确定 AI 是否能处理复杂的系统构件。因此，需要一个基准来评估 AI 在形式化建模大型复杂系统方面的能力。

Method: 提出 SysMoBench 基准，重点关注并发和分布式系统，使用 TLA+ 语言，并自动化评估指标，如语法和运行时正确性、与系统代码的一致性以及不变式正确性。

Result: SysMoBench 目前包含九个不同的系统构件，例如 Etcd 和 Redis 的 Raft 实现，以及 Asterinas OS 中的 Spinlock 和 Mutex。该基准能够评估当前大型语言模型和智能体的能力和局限性。

Conclusion: SysMoBench 为 AI 在形式化建模领域的研究提供了坚实的基础，并开辟了新的研究方向，有助于理解和改进 AI 生成形式化模型的能力。

Abstract: Formal models are essential to specifying large, complex computer systems and
verifying their correctness, but are notoriously expensive to write and
maintain. Recent advances in generative AI show promise in generating certain
forms of specifications. However, existing work mostly targets small code, not
complete systems. It is unclear whether AI can deal with realistic system
artifacts, as this requires abstracting their complex behavioral properties
into formal models. We present SysMoBench, a benchmark that evaluates AI's
ability to formally model large, complex systems. We focus on concurrent and
distributed systems, which are keystones of today's critical computing
infrastructures, encompassing operating systems and cloud infrastructure. We
use TLA+, the de facto specification language for concurrent and distributed
systems, though the benchmark can be extended to other specification languages.
We address the primary challenge of evaluating AI-generated models by
automating metrics like syntactic and runtime correctness, conformance to
system code, and invariant correctness. SysMoBench currently includes nine
diverse system artifacts: the Raft implementation of Etcd and Redis, the
Spinlock and Mutex in Asterinas OS, etc.; more artifacts are being actively
added. SysMoBench enables us to understand the capabilities and limitations of
today's LLMs and agents, putting tools in this area on a firm footing and
opening up promising new research directions.

</details>


### [168] [NeSyPr: Neurosymbolic Proceduralization For Efficient Embodied Reasoning](https://arxiv.org/abs/2510.19429)
*Wonje Choi,Jooyoung Kim,Honguk Woo*

Main category: cs.AI

TL;DR: NeSyPr是一个新颖的具身推理框架，通过神经符号程序化编译知识，使基于LM的智能体具备结构化、适应性和及时的推理能力，以应对动态环境中对大型推理引擎或符号规划器的限制。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中采用语言模型（LMs）进行具身任务面临挑战，因为延迟、连接性和资源限制限制了对大规模推理引擎或符号规划器的在线访问。

Method: NeSyPr首先由一个利用其声明式知识的符号工具显式生成特定任务的计划。然后，这些计划被转换为可组合的程序化表示，对计划的隐式生成规则进行编码，使生成的复合程序能够无缝集成到LM的推理过程中。这种神经符号程序化将多步符号结构化路径查找和推理抽象和泛化为单步LM推理，类似于人类知识编译。

Result: NeSyPr在PDLGym、VirtualHome和ALFWorld等具身基准测试中进行了评估，证明了其在与大型推理模型和符号规划器相比，使用更紧凑的LM即可实现高效推理。

Conclusion: NeSyPr支持在不依赖外部符号指导的情况下进行高效的测试时间推理，使其非常适合在延迟敏感和资源受限的物理系统中部署。

Abstract: We address the challenge of adopting language models (LMs) for embodied tasks
in dynamic environments, where online access to large-scale inference engines
or symbolic planners is constrained due to latency, connectivity, and resource
limitations. To this end, we present NeSyPr, a novel embodied reasoning
framework that compiles knowledge via neurosymbolic proceduralization, thereby
equipping LM-based agents with structured, adaptive, and timely reasoning
capabilities. In NeSyPr, task-specific plans are first explicitly generated by
a symbolic tool leveraging its declarative knowledge. These plans are then
transformed into composable procedural representations that encode the plans'
implicit production rules, enabling the resulting composed procedures to be
seamlessly integrated into the LM's inference process. This neurosymbolic
proceduralization abstracts and generalizes multi-step symbolic structured
path-finding and reasoning into single-step LM inference, akin to human
knowledge compilation. It supports efficient test-time inference without
relying on external symbolic guidance, making it well suited for deployment in
latency-sensitive and resource-constrained physical systems. We evaluate NeSyPr
on the embodied benchmarks PDDLGym, VirtualHome, and ALFWorld, demonstrating
its efficient reasoning capabilities over large-scale reasoning models and a
symbolic planner, while using more compact LMs.

</details>


### [169] [DAIL: Beyond Task Ambiguity for Language-Conditioned Reinforcement Learning](https://arxiv.org/abs/2510.19562)
*Runpeng Xie,Quanwei Wang,Hao Hu,Zherui Zhou,Ni Mu,Xiyun Li,Yiqin Yang,Shuang Xu,Qianchuan Zhao,Bo XU*

Main category: cs.AI

TL;DR: DAIL通过分布策略和语义对齐解决自然语言指令的歧义性，在基准测试中表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 自然语言指令的灵活性会导致语言条件任务中的歧义，从而严重影响算法性能。

Method: DAIL（分布对齐学习）包含分布策略（价值分布估计）和语义对齐模块，前者增强任务可区分性，后者捕捉轨迹和语言指令的对应关系。

Result: DAIL在结构化和视觉观测基准测试中均取得了优于基线方法的性能。

Conclusion: DAIL能有效解决指令歧义性，提升算法在语言条件任务中的性能。

Abstract: Comprehending natural language and following human instructions are critical
capabilities for intelligent agents. However, the flexibility of linguistic
instructions induces substantial ambiguity across language-conditioned tasks,
severely degrading algorithmic performance. To address these limitations, we
present a novel method named DAIL (Distributional Aligned Learning), featuring
two key components: distributional policy and semantic alignment. Specifically,
we provide theoretical results that the value distribution estimation mechanism
enhances task differentiability. Meanwhile, the semantic alignment module
captures the correspondence between trajectories and linguistic instructions.
Extensive experimental results on both structured and visual observation
benchmarks demonstrate that DAIL effectively resolves instruction ambiguities,
achieving superior performance to baseline methods. Our implementation is
available at https://github.com/RunpengXie/Distributional-Aligned-Learning.

</details>


### [170] [AgentSense: LLMs Empower Generalizable and Explainable Web-Based Participatory Urban Sensing](https://arxiv.org/abs/2510.19661)
*Xusen Guo,Mingxing Peng,Xixuan Hao,Xingchen Zou,Qiongyan Wang,Sijie Ruan,Yuxuan Liang*

Main category: cs.AI

TL;DR: AgentSense是一个结合大语言模型和多智能体演化系统的混合、无需训练的框架，用于改进城市感知任务的适应性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有城市感知系统在跨场景泛化和决策可解释性方面存在不足。

Method: AgentSense使用经典规划器生成初始解决方案，并通过多智能体演化系统迭代优化感知任务分配，以适应动态城市条件和用户偏好，同时提供自然语言解释以增强透明度和信任度。

Result: 在两个大规模移动数据集和七种动态干扰下进行的大量实验表明，AgentSense在适应性和可解释性方面优于传统方法，并在性能和鲁棒性方面优于单一智能体大语言模型基线，同时提供更合理、更透明的解释。

Conclusion: AgentSense是朝着在网络上部署适应性和可解释的城市感知系统迈出的重要一步。

Abstract: Web-based participatory urban sensing has emerged as a vital approach for
modern urban management by leveraging mobile individuals as distributed
sensors. However, existing urban sensing systems struggle with limited
generalization across diverse urban scenarios and poor interpretability in
decision-making. In this work, we introduce AgentSense, a hybrid, training-free
framework that integrates large language models (LLMs) into participatory urban
sensing through a multi-agent evolution system. AgentSense initially employs
classical planner to generate baseline solutions and then iteratively refines
them to adapt sensing task assignments to dynamic urban conditions and
heterogeneous worker preferences, while producing natural language explanations
that enhance transparency and trust. Extensive experiments across two
large-scale mobility datasets and seven types of dynamic disturbances
demonstrate that AgentSense offers distinct advantages in adaptivity and
explainability over traditional methods. Furthermore, compared to single-agent
LLM baselines, our approach outperforms in both performance and robustness,
while delivering more reasonable and transparent explanations. These results
position AgentSense as a significant advancement towards deploying adaptive and
explainable urban sensing systems on the web.

</details>


### [171] [A Graph Engine for Guitar Chord-Tone Soloing Education](https://arxiv.org/abs/2510.19666)
*Matthew Keating,Michael Casey*

Main category: cs.AI

TL;DR: 提出一个基于图的引擎，为吉他学生提供和弦音琶音的乐句建议。


<details>
  <summary>Details</summary>
Motivation: 和弦音琶音是爵士吉他即兴演奏的基础，但难以学习和练习。

Method: 首先，讨论生成和弦音琶音的方法。然后，构建一个加权图，其中每个节点代表一个和弦的琶音。接着，计算连续和弦节点之间的边权重，以实现最佳的过渡音。最后，找到最短路径并重构一个和弦音琶音乐句。

Result: 生成和弦音琶音的乐句。

Conclusion: 设计了一个用户友好的系统，用于输入和输出来训练和弦音琶音的引擎，以供吉他学生练习。

Abstract: We present a graph-based engine for computing chord tone soloing suggestions
for guitar students. Chord tone soloing is a fundamental practice for
improvising over a chord progression, where the instrumentalist uses only the
notes contained in the current chord. This practice is a building block for all
advanced jazz guitar theory but is difficult to learn and practice. First, we
discuss methods for generating chord-tone arpeggios. Next, we construct a
weighted graph where each node represents a chord tone arpeggio for a chord in
the progression. Then, we calculate the edge weight between each consecutive
chord's nodes in terms of optimal transition tones. We then find the shortest
path through this graph and reconstruct a chord-tone soloing line. Finally, we
discuss a user-friendly system to handle input and output to this engine for
guitar students to practice chord tone soloing.

</details>


### [172] [Explainable e-sports win prediction through Machine Learning classification in streaming](https://arxiv.org/abs/2510.19671)
*Silvia García-Méndez,Francisco de Arriba-Pérez*

Main category: cs.AI

TL;DR: 本研究提出了一种基于AI的可解释的流式电竞比赛胜负预测分类解决方案，通过滑动窗口处理数据，实现了超过90%的准确率，并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 电子竞技行业因观众和选手的增长以及通信和云计算技术的发展而持续增长，但现有的基于AI的电竞分析方法主要集中在批量分类和数据可视化以辅助决策，忽略了流式数据的实时性。

Method: 本研究提出了一种可解释的、基于AI的流式电竞比赛胜负预测分类解决方案。该方案通过滑动窗口机制处理输入数据，以适应游戏中可能发生的实时变化。

Result: 实验结果表明，该方法达到了超过90%的准确率，性能优于文献中其他竞争性解决方案。

Conclusion: 该系统具有可解释性模块，可以增强结果预测的可信度，因此能够被排名和推荐系统用于辅助决策。

Abstract: The increasing number of spectators and players in e-sports, along with the
development of optimized communication solutions and cloud computing
technology, has motivated the constant growth of the online game industry. Even
though Artificial Intelligence-based solutions for e-sports analytics are
traditionally defined as extracting meaningful patterns from related data and
visualizing them to enhance decision-making, most of the effort in professional
winning prediction has been focused on the classification aspect from a batch
perspective, also leaving aside the visualization techniques. Consequently,
this work contributes to an explainable win prediction classification solution
in streaming in which input data is controlled over several sliding windows to
reflect relevant game changes. Experimental results attained an accuracy higher
than 90 %, surpassing the performance of competing solutions in the literature.
Ultimately, our system can be leveraged by ranking and recommender systems for
informed decision-making, thanks to the explainability module, which fosters
trust in the outcome predictions.

</details>


### [173] [RLIE: Rule Generation with Logistic Regression, Iterative Refinement, and Evaluation for Large Language Models](https://arxiv.org/abs/2510.19698)
*Yang Yang,Hua XU,Zhangyi Hu,Yutao Yue*

Main category: cs.AI

TL;DR: LLMs can generate rules, but struggle with rule interactions and probabilistic inference. RLIE framework integrates LLMs with probabilistic modeling to learn weighted rules, outperforming methods that inject rules into LLMs. Direct application of weighted rules is superior, while prompting LLMs with rules degrades accuracy, highlighting LLMs' strengths in generation and limitations in precise probabilistic integration.


<details>
  <summary>Details</summary>
Motivation: Many LLM-based rule learning approaches ignore interactions among rules and the potential for coupling with probabilistic rule learning for robust inference. This paper aims to integrate LLMs with probabilistic modeling to learn a set of weighted rules for improved inductive reasoning and neuro-symbolic approaches.

Method: RLIE, a unified framework, consists of four stages: (1) LLM-based rule generation and filtering, (2) Logistic regression for learning probabilistic weights, (3) Iterative refinement using prediction errors, and (4) Evaluation comparing the weighted rule set as a direct classifier against methods that inject rules into an LLM.

Result: Applying rules directly with learned weights yields superior performance. Prompting LLMs with rules, weights, and logistic-model outputs surprisingly degrades accuracy. LLMs are better at semantic generation and interpretation than precise probabilistic integration.

Conclusion: RLIE effectively couples LLMs with probabilistic rule combination methods, clarifying the potential and limitations of LLMs for inductive reasoning and enabling more reliable neuro-symbolic reasoning. Direct application of learned weighted rules is more effective than injecting them into LLMs.

Abstract: Large Language Models (LLMs) can propose rules in natural language,
sidestepping the need for a predefined predicate space in traditional rule
learning. Yet many LLM-based approaches ignore interactions among rules, and
the opportunity to couple LLMs with probabilistic rule learning for robust
inference remains underexplored. We present RLIE, a unified framework that
integrates LLMs with probabilistic modeling to learn a set of weighted rules.
RLIE has four stages: (1) Rule generation, where an LLM proposes and filters
candidates; (2) Logistic regression, which learns probabilistic weights for
global selection and calibration; (3) Iterative refinement, which updates the
rule set using prediction errors; and (4) Evaluation, which compares the
weighted rule set as a direct classifier with methods that inject rules into an
LLM. We evaluate multiple inference strategies on real-world datasets. Applying
rules directly with their learned weights yields superior performance, whereas
prompting LLMs with the rules, weights, and logistic-model outputs surprisingly
degrades accuracy. This supports the view that LLMs excel at semantic
generation and interpretation but are less reliable for precise probabilistic
integration. RLIE clarifies the potential and limitations of LLMs for inductive
reasoning and couples them with classic probabilistic rule combination methods
to enable more reliable neuro-symbolic reasoning.

</details>


### [174] [Memo: Training Memory-Efficient Embodied Agents with Reinforcement Learning](https://arxiv.org/abs/2510.19732)
*Gunshi Gupta,Karmesh Yadav,Zsolt Kira,Yarin Gal,Rahaf Aljundi*

Main category: cs.AI

TL;DR: Memo是一种基于Transformer的记忆增强型架构，用于需要长期记忆的具身代理任务，通过引入记忆创建和检索机制，解决了Transformer的上下文长度限制问题，并在导航等任务中表现优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 当前的Transformer模型在处理长时序的具身决策任务时，视觉输入会超出其上下文限制，而人类可以压缩一生经验作为记忆来利用。现有方法要么使用固定大小记忆的循环模型，要么依赖Transformer的全部上下文，未能有效解决记忆瓶颈。

Method: 提出Memo架构，通过在训练时将周期性总结的记忆Token与输入交错，实现记忆的创建和检索。该架构适用于基于Transformer的策略，用于强化学习。

Result: Memo在gridworld元RL基准和照片级真实感室内环境的多目标导航任务中都取得了成功。与简单的长上下文Transformer基线相比，Memo在计算和存储效率上都表现更好，并且在推理时能更好地泛化到更长的上下文，在历史上下文必须被截断的情况下也保持了鲁棒性。

Conclusion: Memo架构通过引入记忆创建和检索机制，有效解决了Transformer在长时序具身任务中的上下文限制问题，并在效率、泛化能力和鲁棒性方面优于现有方法。

Abstract: To enable embodied agents to operate effectively over extended timeframes, it
is crucial to develop models that form and access memories to stay
contextualized in their environment. In the current paradigm of training
transformer-based policies for embodied sequential decision-making tasks,
visual inputs often overwhelm the context limits of transformers, while humans
can maintain and utilize a lifetime of experience compressed as memories.
Significant compression is possible in principle, as much of the input is
irrelevant and can be abstracted. However, existing approaches predominantly
focus on either recurrent models with fixed-size memory or transformers with
full-context reliance. In this work, we propose Memo, a transformer-based
architecture and training recipe for reinforcement learning (RL) on
memory-intensive, long-horizon tasks. Memo incorporates the creation and
retrieval of memory by interleaving periodic summarization tokens with the
inputs of a model during training. We demonstrate Memo's effectiveness on a
gridworld meta-RL benchmark and a multi-object navigation task in
photo-realistic indoor settings. Memo outperforms naive long-context
transformer baselines while being more compute and storage efficient.
Additionally, Memo generalizes better to longer contexts at inference time and
remains robust in streaming settings, where historical context must be
truncated to fit inference constraints.

</details>


### [175] [Misalignment Bounty: Crowdsourcing AI Agent Misbehavior](https://arxiv.org/abs/2510.19738)
*Rustem Turtayev,Natalia Fedorova,Oleg Serikov,Sergey Koldyba,Lev Avagyan,Dmitrii Volkov*

Main category: cs.AI

TL;DR: AI系统有时会偏离人类意图，该项目收集了295个AI偏离意图的例子，其中9个获奖。


<details>
  <summary>Details</summary>
Motivation: 收集AI偏离意图的明确、可复现的例子。

Method: 通过众包项目“Misalignment Bounty”收集AI偏离意图的案例。

Result: 收到295个提交，其中9个获奖。

Conclusion: 项目成功收集了AI偏离意图的案例，并进行了详细的分析。

Abstract: Advanced AI systems sometimes act in ways that differ from human intent. To
gather clear, reproducible examples, we ran the Misalignment Bounty: a
crowdsourced project that collected cases of agents pursuing unintended or
unsafe goals. The bounty received 295 submissions, of which nine were awarded.
  This report explains the program's motivation and evaluation criteria, and
walks through the nine winning submissions step by step.

</details>


### [176] [Beyond Reactivity: Measuring Proactive Problem Solving in LLM Agents](https://arxiv.org/abs/2510.19771)
*Gil Pasternak,Dheeraj Rajagopal,Julia White,Dhruv Atreja,Matthew Thomas,George Hurn-Maloney,Ash Lewis*

Main category: cs.AI

TL;DR: PROBE是一个评估LLM主动性的新基准，现有模型在该基准上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有评估LLM主动性的基准在局部性方面存在不足，无法测试跨源和长期推理能力。

Method: 提出PROBE基准，将主动性分解为（1）搜索未明确问题、（2）识别具体瓶颈、（3）执行适当解决方案三个核心能力。在PROBE上评估了现有LLM和代理框架。

Result: 即使是最先进的模型在PROBE基准上也表现不佳，最佳的端到端性能为40%，由GPT-5和Claude Opus-4.1达到。分析了各模型的相对能力和共同失败模式。

Conclusion: 当前LLM代理系统的自主行动能力有限，PROBE暴露了未来研究方向。

Abstract: LLM-based agents are increasingly moving towards proactivity: rather than
awaiting instruction, they exercise agency to anticipate user needs and solve
them autonomously. However, evaluating proactivity is challenging; current
benchmarks are constrained to localized context, limiting their ability to test
reasoning across sources and longer time horizons. To address this gap, we
present PROBE (Proactive Resolution Of BottlEnecks). PROBE decomposes
proactivity as a pipeline of three core capabilities: (1) searching for
unspecified issues, (2) identifying specific bottlenecks, and (3) executing
appropriate resolutions. We apply PROBE to evaluate leading LLMs and popular
agentic frameworks, showing that even state-of-the-art models struggle to solve
this benchmark. Computing our consistent measurements across frontier LLMs and
agents, we find that the best end-to-end performance of 40% is achieved by both
GPT-5 and Claude Opus-4.1. Additionally, we demonstrate the relative
capabilities of each model and analyze mutual failure modes. Our results
highlight the current limitations of autonomous action in agentic systems, and
expose promising future research directions.

</details>


### [177] [Benchmarking World-Model Learning](https://arxiv.org/abs/2510.19788)
*Archana Warrier,Dat Nyugen,Michelangelo Naim,Moksh Jain,Yichao Liang,Karen Schroeder,Cambridge Yang,Joshua B. Tenenbaum,Sebastian Vollmer,Kevin Ellis,Zenna Tavares*

Main category: cs.AI

TL;DR: WorldTest是一个评估模型学习智能体的协议，它将无奖励交互与不同但相关的环境中的评分测试阶段分开，旨在解决当前模型学习和评估方法与下一帧预测和奖励最大化挂钩的问题。


<details>
  <summary>Details</summary>
Motivation: 当前的}(\text{next-frame prediction})和奖励最大化。然而，这种方法未能充分评估智能体对世界模型的学习情况，因为它们只关注于在训练环境中的短期预测和奖励。

Method: WorldTest协议将模型的训练和评估分离开来，通过无奖励的交互来学习世界模型，然后在不同的、但相关的环境中进行测试，并采用基于行为的评分方法。作者使用AutumnBench，一个包含43个网格世界环境和129个任务的基准测试，来实例化WorldTest，并比较了517名人类参与者和三个前沿模型的表现。

Result: 在AutumnBench的评估中，人类参与者的表现优于三个前沿模型。此外，计算量的增加只在某些环境中提高了模型的性能，而在其他环境中则不然。这一结果表明，目前的模型在学习世界模型方面仍有很大的提升空间。

Conclusion: WorldTest提供了一个新的评估框架，用于衡量模型学习智能体对环境动态的理解能力。AutumnBench的实验结果揭示了在世界模型学习方面存在巨大的改进潜力。

Abstract: Model-learning agents should gather information to learn world models that
support many downstream tasks and inferences, such as predicting unobserved
states, estimating near- and far-term consequences of actions, planning action
sequences, and detecting changes in dynamics. Current methods for learning and
evaluating world models diverge from this goal: training and evaluation are
anchored to next-frame prediction, and success is scored by reward maximization
in the same environment. We propose WorldTest, a protocol to evaluate
model-learning agents that separates reward-free interaction from a scored test
phase in a different but related environment. WorldTest is
open-ended$\unicode{x2014}$models should support many different tasks unknown
ahead of time$\unicode{x2014}$and agnostic to model representation, allowing
comparison across approaches. We instantiated WorldTest with AutumnBench, a
suite of 43 interactive grid-world environments and 129 tasks across three
families: masked-frame prediction, planning, and predicting changes to the
causal dynamics. We compared 517 human participants and three frontier models
on AutumnBench. We found that humans outperform the models, and scaling compute
improves performance only in some environments but not others. WorldTest
provides a novel template$\unicode{x2014}$reward-free exploration, derived
tests, and behavior-based scoring$\unicode{x2014}$to evaluate what agents learn
about environment dynamics, and AutumnBench exposes significant headroom in
world-model learning.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [178] [Active Cooling Device: A Flexible, Lab-Scale Experimental Unit to Develop Spatio-Temporal Temperature Control Strategies](https://arxiv.org/abs/2510.18987)
*Victor Oliveira Ferreira,Wiebke Mainville,Vincent Raymond,Jean-Michel Lamarre,Antoine Hamel,Mikael Vaillant,Moncef Chioua,Bruno Blais*

Main category: eess.SY

TL;DR: 该实验单元实现了多输入、多输出流形热管理技术，可以通过控制冷却液射流来精确控制时空温度分布。


<details>
  <summary>Details</summary>
Motivation: 提出了一种用于精确控制时空温度分布的实验装置，以实现多输入、多输出流形热管理技术。

Method: 通过改变流体通道的输入/输出状态，利用多通道设计的流体射流来控制冷却，从而实现温度控制。

Result: 提供了实验装置的CAD文件、PCB制造文件和Python GUI，以及组装和使用说明。展示了系统表征、PID性能跟踪和耦合系统中的干扰抑制等应用实例。

Conclusion: 该主动冷却装置提供了一个安全、灵活且完整的系统设计，能够通过封闭式撞击射流对定制温度控制策略进行实验室规模的评估。

Abstract: We present an experimental unit that realizes the ``multi-input, multi-output
manifold'' thermal management technology proposed by Lamarre & Raymond (2023).
The proposed setup can be used for experiments aimed at controlling
spatiotemporal temperature distribution. Temperature control is achieved by
impinging coolant fluid jets, leveraging a manifold of channels targeted to the
surface. The direction of the fluid is controlled by shifting the role of
channels between inputs, outputs, or closing them. Files associated with this
work include Computer-Aided Design (CAD) STEP files, Gerber files to
manufacture a Printed Circuit Board (PCB), and a Graphical User Interface (GUI)
written in Python. We provide a step-by-step guide to assemble the experimental
setup. We also provide instructions to interact with the setup through the GUI,
which allows for real-time tracking of sample temperature and flow rates per
flow control device. Additionally, we provide examples of usage of the setup,
including system characterization with step response,
Proportional-Integral-Derivative performance tracking, and disturbance
rejection in a coupled system. Extending the application is accessible through
the files provided in the open repository associated with this work. The active
cooling device presents a safe, flexible, and complete design, allowing for
lab-scale assessment of the performance of custom temperature control
strategies using enclosed impinging jets.

</details>


### [179] [Extreme value distributions of peak loads for non-residential customer segments](https://arxiv.org/abs/2510.19052)
*Shaohong Shi,Eric A. Cator,Jacco Heres,Simon H. Tindemans*

Main category: eess.SY

TL;DR: 该论文提出了一种基于极值理论的数学模型，用于表征大型非居民用户的峰值负荷概率分布，并改进了Velander公式（VF），将其简化为仅包含四个参数，且预测性能无损。


<details>
  <summary>Details</summary>
Motivation: 欧洲电网拥堵日益严重，需要精确预测负荷，特别是峰值负荷。Velander公式（VF）是一种传统的峰值负荷预测方法，但其非时间解析的模型存在局限性。

Method: 提出了一种基于极值理论的数学模型，用于表征大型非居民用户的峰值负荷概率分布。该模型通过多元分位数回归，将改进后的VF表示为仅包含四个参数。利用最大似然估计和似然比检验，验证了分析组的峰值负荷概率分布属于重尾Fréchet类。

Result: 所提出的模型能以四个参数有效表征峰值负荷的概率分布，并改进了VF的预测性能。

Conclusion: 该研究为理解和预测大型非居民用户的峰值负荷提供了新的数学模型，并验证了其属于重尾Fréchet类分布，为电网管理提供了理论支持。

Abstract: Electrical grid congestion is a growing challenge in Europe, driving the need
for accurate prediction of load, particularly of peak load. Non-time-resolved
models of peak load offer the advantages of simplicity and compactness, and
among them, Velander's formula (VF) is a traditional method that has been used
for decades. Moreover, VF can be adapted into a quantile VF, which learns a
truncated cumulative distribution function of peak load based on electricity
consumption. This paper proposes a mathematical model based on extreme value
theory to characterize the probability distribution of peak load for large
non-residential customers. The model underpins the quantile VF as demonstrated
through multiple quantile regression and reduces its representation to just
four parameters without sacrificing predictive performance. Moreover, using
maximum likelihood estimation and the likelihood ratio test, we validate that
the probability distribution of peak load of analysed groups belongs to the
heavy-tailed Fr\'echet class.

</details>


### [180] [Graph Analysis to Fully Automate Fault Location Identification in Power Distribution Systems](https://arxiv.org/abs/2510.19059)
*Ali Shakeri Kahnamouei,Saeed Lotfifard*

Main category: eess.SY

TL;DR: 本论文提出图分析方法，可全自动化识别电力配电系统中的故障位置，输入包括支路参数、负荷值和测量设备位置等基本无序数据，可自动识别系统拓扑并提取故障路径、结构、负荷等关键信息，并据此估算故障位置。该方法无需复杂的节点和支路编号，消除了故障定位过程中人工干预的需要，具有良好的可扩展性，适用于任何规模的系统，并在IEEE 34节点测试系统中进行了性能验证。


<details>
  <summary>Details</summary>
Motivation: 提出图分析方法，以全自动化方式解决电力配电系统中的故障定位识别问题。

Method: 利用基本无序的配电系统数据（支路参数、负荷值、测量设备位置）进行数据准备和分析，自动识别系统拓扑，提取故障路径、结构、负荷等信息，并据此估算故障位置。该方法不依赖于复杂的编号系统，无需人工干预，且易于扩展。

Result: 在IEEE 34节点配电测试系统中验证了所提出图分析方法的性能。

Conclusion: 所提出的图分析方法能够全自动化地定位电力配电系统中的故障，无需人工干预，并且易于扩展到不同规模的系统。

Abstract: This paper proposes graph analysis methods to fully automate the fault
location identification task in power distribution systems. The proposed
methods take basic unordered data from power distribution systems as input,
including branch parameters, load values, and the location of measuring
devices. The proposed data preparation and analysis methods automatically
identify the system's topology and extract essential information, such as
faulted paths, structures, loading of laterals and sublaterals, and estimate
the fault location accordingly. The proposed graph analysis methods do not
require complex node and branch numbering processes or renumbering following
changes in the system topology. The proposed methods eliminate the need for
human intervention at any step of the fault location identification process.
They are scalable and applicable to systems of any size. The performance of the
proposed algorithm is demonstrated using the IEEE 34-bus distribution test
system.

</details>


### [181] [Time Domain Differential Equation Based Fault Location Identification in Mixed Overhead-Underground Power Distribution Systems](https://arxiv.org/abs/2510.19070)
*Ali Shakeri Kahnamouei,Saeed Lotfifard*

Main category: eess.SY

TL;DR: 提出一种适用于混合架空-地下电力分配系统的时域故障定位方法，可处理子周期故障、电弧故障和演化故障等挑战性故障场景。


<details>
  <summary>Details</summary>
Motivation: 解决混合架空-地下电力分配系统中复杂故障场景下的故障定位问题，并考虑分布式发电的特性。

Method: 基于系统微分方程，考虑负荷、多相支路、不同类型的架空和地下线路、以及分布式发电的馈入和远端故障电流贡献。利用有限数量的测量设备数据，系统地消除多个可能的故障定位估计，提供单一的实际故障位置估计。

Result: 使用IEEE 34节点测试系统验证了所提出方法的性能。

Conclusion: 所提出的方法能够有效地进行混合架空-地下电力分配系统的故障定位，即使在存在复杂故障和分布式发电的情况下也能提供准确的估计。

Abstract: This paper proposes a time-domain fault location identification method for
mixed overhead-underground power distribution systems that can handle
challenging fault scenarios such as sub-cycle faults, arcing faults and
evolving faults. The proposed method is formulated based on differential
equations of the system and accounts for the peculiarities of power
distribution systems with distributed generations. It considers the presence of
loads, multi-phase laterals and sub-laterals, heterogenous overhead and
underground lines, and infeeds and remote-end fault current contributions of
distributed generations. It utilizes data collected by limited number of
measuring devices installed in modern power distribution systems to
systematically eliminate possible multiple fault location estimations to
provide a single correct estimation of the actual location of the fault. The
performance of the proposed method is demonstrated using IEEE 34-node test
system.

</details>


### [182] [A Configurable Simulation Framework for Safety Assessment of Vulnerable Road Users](https://arxiv.org/abs/2510.19097)
*Zhitong He,Yaobin Chen,Brian King,Lingxi Li*

Main category: eess.SY

TL;DR: 该论文提出了一个轻量级、可配置的模拟框架，用于验证先进驾驶辅助系统 (ADAS) 和网联自动驾驶汽车 (CAV) 技术在涉及弱势道路使用者 (VRU) 时的安全性。


<details>
  <summary>Details</summary>
Motivation: 确保行人、骑行者、电动滑板车骑行者和摩托车骑行者等弱势道路使用者 (VRU) 的安全，是先进驾驶辅助系统 (ADAS) 和网联自动驾驶汽车 (CAV) 技术面临的一项重大挑战。然而，现实世界的 VRU 测试成本高昂，且有时无法捕捉或重复罕见和危险的事件。

Method: 开发了一个基于规则的有限状态机 (FSM) 作为运动规划器，以在 VRU 交互过程中提供车辆自动化。集成了自车感知和理想化的车对一切 (V2X) 意识，以在不同场景中展示安全裕度。该框架遵循欧洲新车安全评鉴协会 (Euro NCAP) 的 VRU 测试协议。

Result: 提供了一个可扩展的平台，用于快速、可重复地进行 VRU 安全验证。

Conclusion: 该平台为在不同、用户定义的设置中进行更广泛的案例研究奠定了基础，这对于构建更适合 VRU、更可持续的智能交通系统至关重要。

Abstract: Ensuring the safety of vulnerable road users (VRUs), including pedestrians,
cyclists, electric scooter riders, and motorcyclists, remains a major challenge
for advanced driver assistance systems (ADAS) and connected and automated
vehicles (CAV) technologies. Real-world VRU tests are expensive and sometimes
cannot capture or repeat rare and hazardous events. In this paper, we present a
lightweight, configurable simulation framework that follows European New Car
Assessment Program (Euro NCAP) VRU testing protocols. A rule-based finite-state
machine (FSM) is developed as a motion planner to provide vehicle automation
during the VRU interaction. We also integrate ego-vehicle perception and
idealized Vehicle-to-Everything (V2X) awareness to demonstrate safety margins
in different scenarios. This work provides an extensible platform for rapid and
repeatable VRU safety validation, paving the way for broader case-study
deployment in diverse, user-defined settings, which will be essential for
building a more VRU-friendly and sustainable intelligent transportation system.

</details>


### [183] [Wisdom of Crowds Effects under Antagonistic Interactions and Correlated Opinions](https://arxiv.org/abs/2510.19123)
*Muhammad Ahsan Razaq,Claudio Altafini*

Main category: eess.SY

TL;DR: 本研究探讨了线性意见动力学模型在有符号网络上的群体智慧。


<details>
  <summary>Details</summary>
Motivation: 研究线性意见动力学模型在有符号网络上的表现，以及 DeGroot、Friedkin-Johnsen (FJ) 和串联 FJ 模型如何影响群体智慧。

Method: 分析了 DeGroot、FJ 和串联 FJ 模型在有符号网络上的意见动力学，并考虑了初始意见相关的依赖性。

Result: 给出了模型改善或损害群体智慧的条件，并展示了相关结构如何影响改善群体智慧区域的可行性和几何形状。

Conclusion: 线性意见动力学模型在有符号网络上的表现取决于具体模型和网络结构，初始意见的相关性也起着重要作用。

Abstract: This paper investigates the wisdom of crowds of linear opinion dynamics
models evolving on signed networks. Conditions are given under which models
such as the DeGroot, Friedkin-Johnsen (FJ) and concatenated FJ models improve
or undermine collective wisdom. The extension to dependent initial opinions is
also presented, highlighting how the correlation structure influences the
feasibility and geometry of the wisdom-improving regions.

</details>


### [184] [Spatiotemporal Tubes based Control of Unknown Multi-Agent Systems for Temporal Reach-Avoid-Stay Tasks](https://arxiv.org/abs/2510.19232)
*Ahan Basu,Ratnangshu Das,Pushpak Jagtap*

Main category: eess.SY

TL;DR: 本研究提出了一种用于未知动力学多智能体系统的控制器，实现了每个智能体的时间可达-规避-驻留任务，并防止智能体之间发生碰撞。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统的控制器设计，特别是要实现时间可达-规避-驻留任务，同时避免代理之间的碰撞。

Method: 生成时空管（STT），并将其制定为鲁棒优化问题（ROP），然后通过求解基于采样的场景优化问题（SOP）来解决无限约束的问题，从而生成STT并设计闭式控制器。

Result: 生成了时空管（STT），并设计了满足任务要求的闭式控制器。通过全向机器人和欧拉-拉格朗日系统多旋翼无人机进行了有效性验证。

Conclusion: 所提出的方法能够有效地为未知动力学多智能体系统生成时空管（STT），并设计闭式控制器，以满足可达、规避和驻留任务，同时避免碰撞。

Abstract: The paper focuses on designing a controller for unknown dynamical multi-agent
systems to achieve temporal reach-avoid-stay tasks for each agent while
preventing inter-agent collisions. The main objective is to generate a
spatiotemporal tube (STT) for each agent and thereby devise a closed-form,
approximation-free, and decentralized control strategy that ensures the system
trajectory reaches the target within a specific time while avoiding
time-varying unsafe sets and collisions with other agents. In order to achieve
this, the requirements of STTs are formulated as a robust optimization problem
(ROP) and solved using a sampling-based scenario optimization problem (SOP) to
address the issue of infeasibility caused by the infinite number of constraints
in ROP. The STTs are generated by solving the SOP, and the corresponding
closed-form control is designed to fulfill the specified task. Finally, the
effectiveness of our approach is demonstrated through two case studies, one
involving omnidirectional robots and the other involving multiple drones
modelled as Euler-Lagrange systems.

</details>


### [185] [Managing Charging Induced Grid Stress and Battery Degradation in Electric Taxi Fleets](https://arxiv.org/abs/2510.19293)
*Michael Yuhas,Rajesh K. Ahir,Laksamana Vixell Tanjaya Hartono,Muhammad Dzaki Dwi Putranto,Arvind Easwaran,Suhono Harso Supangkat*

Main category: eess.SY

TL;DR: 该研究通过模拟电动汽车（EV）车队的整个生命周期，旨在平衡车队寿命、短期盈利能力和电网稳定性之间的冲突，并提出了一种基于强化学习的充电策略。


<details>
  <summary>Details</summary>
Motivation: 电动汽车车队运营商和电网都面临着运营电动汽车车队的挑战。运营商可能会为了最大化短期利润而始终以最高速率充电，但这会增加电网压力、可能导致电网不稳定，并加速电池损耗，缩短车队使用寿命。

Method: 研究人员开发了一个电动汽车车队模拟器，用于评估不可预测的充电和载客需求对电池损耗的影响，并评估由此产生的充电基础设施对电网的影响。该模拟器利用了纽约出租车数据集的公开旅行数据。研究人员比较了一种基准的80-20车队充电策略与一种基于强化学习的策略，该策略旨在延长车队的服役寿命并减轻电网压力。

Result: 在为期五年的模拟中，研究人员监控了电网压力、电池损耗和盈利能力，发现他们提出的强化学习策略优于基准策略。

Conclusion: 所提出的基于强化学习的充电策略在延长车队寿命和减轻电网压力方面优于传统的80-20充电策略。该模拟器可以帮助车队运营商评估不同充电策略的影响，并做出更明智的决策。

Abstract: Operating fleets of electric vehicles (EVs) introduces several challenges,
some of which are borne by the fleet operator, and some of which are borne by
the power grid. To maximize short-term profit a fleet operator could always
charge EVs at the maximum rate to ensure vehicles are ready to service ride
demand. However, due to the stochastic nature of electricity demand, charging
EVs at their maximum rate may potentially increase the grid stress and lead to
overall instability. Furthermore, high-rate charging of EVs can accelerate
battery degradation, thereby reducing the service lifespan of the fleet. This
study aims to reconcile the conflicting incentives of fleet longevity,
short-term profitability, and grid stability by simulating a taxi fleet
throughout its lifespan in relation to its charging policies and service
conditions. We develop an EV fleet simulator to evaluate the battery
degradation due to unpredictable charging and ride demand. Consequently, the
impact on the power grid through the charging infrastructure is assessed due to
these activities. This simulation utilizes publicly accessible real-world
travel data from the NYC taxi dataset. We compare a baseline 80-20 fleet
charging policy with a reinforcement learning-based policy designed to prolong
the fleet's service life and alleviate grid stress. We monitor grid stress,
battery degradation, and profitability over five years and find that our
learned policy outperforms the baseline. This simulator enables fleet operators
to assess the impact of different charging policies on these indicators to make
informed decisions in the future.

</details>


### [186] [Multi-UAV Flood Monitoring via CVT with Gaussian Mixture of Density Functions for Coverage Control](https://arxiv.org/abs/2510.19548)
*Jie Song,Yang Bai,Mikhail Svinin,Naoki Wakamiya*

Main category: eess.SY

TL;DR: 使用基于高斯混合密度函数的质心Voronoi分割（CVT）的密度驱动覆盖框架，协调多无人机（UAV）监测未知洪水区域并估计洪水范围。


<details>
  <summary>Details</summary>
Motivation: 提出一种协调多个无人机（UAV）监测未知洪水区域并估计洪水范围的控制策略。

Method: 采用基于质心Voronoi分割（CVT）的密度驱动覆盖框架，并使用高斯混合密度函数（GMDF）对密度函数进行建模。

Result: 与传统的轴对齐高斯模型相比，基于GMDF的公式能够更准确地表征洪水区域。在不同无人机数量（16、20和24）下，基于GMDF的公式始终实现更高的覆盖率。

Conclusion: 基于GMDF的公式能有效提高洪水监测能力，改善无人机的空间分布。

Abstract: This study presents a control strategy for coordinating multiple unmanned
aerial vehicles (UAVs) to monitor unknown flood regions and estimate the extent
of inundation. The proposed method adopts a density-driven coverage framework
based on Centroidal Voronoi Tessellation (CVT), in which the density function
is modeled using a Gaussian Mixture of Density Functions (GMDF). This
formulation provides a more accurate characterization of inundated areas
compared to conventional axis-aligned Gaussian models. The performance of the
two density modeling approaches is systematically evaluated under different UAV
fleet sizes (16, 20, and 24), with multiple simulation trials conducted in the
ROS/Gazebo environment. The results show that the GMDF-based formulation
consistently achieves higher coverage rates, demonstrating its effectiveness in
enhancing flood monitoring and improving UAV spatial distribution.

</details>


### [187] [Control Barrier Functions for the Full Class of Signal Temporal Logic Tasks using Spatiotemporal Tubes](https://arxiv.org/abs/2510.19595)
*Ratnangshu Das,Subhodeep Choudhury,Pushpak Jagtap*

Main category: eess.SY

TL;DR: 本文提出一种新的框架，利用时空管（STT）为一般信号时序逻辑（STL）规范合成时变控制障碍函数（TV-CBFs）。


<details>
  <summary>Details</summary>
Motivation: 为一般信号时序逻辑（STL）规范合成时变控制障碍函数（TV-CBFs）。

Method: 将STT合成表述为鲁棒优化问题（ROP），并通过场景优化问题（SOP）求解，从而得到能捕捉给定STL规范的STT。然后利用这些STT来构造TV-CBFs。

Result: 所提出的框架能够确保在任何使其不变的控制律下，系统都能满足STL任务。通过在差速驱动移动机器人和四旋翼飞行器上的案例研究，并与现有方法进行比较分析，证明了该框架的有效性。

Conclusion: 所提出的框架通过时空管（STT）为一般信号时序逻辑（STL）规范成功合成了时变控制障碍函数（TV-CBFs），并在机器人应用中展示了其有效性和效率优势。

Abstract: This paper introduces a new framework for synthesizing time-varying control
barrier functions (TV-CBFs) for general Signal Temporal Logic (STL)
specifications using spatiotemporal tubes (STT). We first formulate the STT
synthesis as a robust optimization problem (ROP) and solve it through a
scenario optimization problem (SOP), providing formal guarantees that the
resulting tubes capture the given STL specifications. These STTs are then used
to construct TV-CBFs, ensuring that under any control law rendering them
invariant, the system satisfies the STL tasks. We demonstrate the framework
through case studies on a differential-drive mobile robot and a quadrotor, and
provide a comparative analysis showing improved efficiency over existing
approaches.

</details>


### [188] [Optimal Kron-based Reduction of Networks (Opti-KRON) for Three-phase Distribution Feeders](https://arxiv.org/abs/2510.19608)
*Omid Mokhtari,Samuel Chevalier,Mads Almassalkhi*

Main category: eess.SY

TL;DR: 该研究提出了一种新的 Kron-方法，用于处理不平衡配电网的缩减问题，通过聚合相似节点来优化电压，并利用 GPU 加速计算，在真实电网验证中实现了显著的缩减和精度。


<details>
  <summary>Details</summary>
Motivation: 不平衡配电网的缩减对于稳态分析和优化研究至关重要，但传统方法存在计算瓶颈。

Method: 提出了一种新的基于 Kron 的、保持结构的方法，通过在混合整数规划 (MIP) 问题中聚合电气相似节点来生成缩减网络。为了克服 MIP 的计算瓶颈，提出了一种穷举搜索方法来识别最佳聚合决策，同时强制执行电压裕度限制。该算法支持 GPU 并行化。

Result: 在两个包含 5,991 和 8,381 个节点的真实公用配电馈线上进行了验证。缩减模型实现了高达 90% 和 80% 的网络缩减，最大电压幅度误差低于 0.003 p.u.。在 1000 个节点的网络版本上，GPU 加速的缩减算法比 CPU 版本快 15 倍。

Conclusion: 所提出的框架能够有效地缩减不平衡配电馈线，以低误差近似全系统的电压曲线，并且适合稳态分析和最优潮流研究。GPU 加速的缩减算法提供了显著的计算优势。

Abstract: This paper presents a novel structure-preserving, Kron-based reduction
framework for unbalanced distribution feeders. The method aggregates
electrically similar nodes within a mixed-integer optimization (MIP) problem to
produce reduced networks that optimally reproduce the voltage profiles of the
original full network. To overcome computational bottlenecks of MIP
formulations, we propose an exhaustive-search formulation to identify optimal
aggregation decisions while enforcing voltage margin limits. The proposed
exhaustive network reduction algorithm is parallelizable on GPUs, which enables
scalable network reduction. The resulting reduced networks approximate the full
system's voltage profiles with low errors and are suitable for steady-state
analysis and optimal power flow studies. The framework is validated on two real
utility distribution feeders with 5,991 and 8,381 nodes. The reduced models
achieve up to 90% and 80% network reduction, respectively, while the maximum
voltage-magnitude error remains below 0.003 p.u. Furthermore, on a 1000-node
version of the network, the GPU-accelerated reduction algorithm runs up to 15x
faster than its CPU-based counterpart.

</details>


### [189] [Bridging Earth and Space: A Survey on HAPS for Non-Terrestrial Networks](https://arxiv.org/abs/2510.19731)
*G. Svistunov,A. Akhtarshenas,D. López-Pérez,M. Giordani,G. Geraci,H. Yanikomeroglu*

Main category: eess.SY

TL;DR: HAPS在6G网络中提供广泛覆盖、低延迟和高能效的宽带通信，并在扩展连接性、支持动态回程、实现海量物联网以及为自动驾驶和沉浸式服务提供可靠低延迟通信方面发挥着关键作用。


<details>
  <summary>Details</summary>
Motivation: HAPS作为6G无线网络演进的关键推动者，能够弥合地面和非地面基础设施之间的差距，提供广泛覆盖、低延迟和高能效的宽带通信，并具有灵活的部署选项，适用于各种应用。

Method: 本篇综述全面概述了HAPS在6G生态系统中的应用场景、技术和集成策略，讨论了HAPS在扩展连接性、支持动态回程、实现海量物联网以及提供可靠低延迟通信方面的作用，并回顾了最新的现场试验。此外，还研究了信道建模、人工智能驱动的资源分配、干扰控制、移动性管理和高能效通信等关键技术，并指出了开放的研究挑战。

Result: HAPS在6G网络中提供广泛覆盖、低延迟和高能效的宽带通信，并在扩展连接性、支持动态回程、实现海量物联网以及为自动驾驶和沉浸式服务提供可靠低延迟通信方面发挥着关键作用。

Conclusion: 通过解决现有文献中的空白，本综述将HAPS定位为全球集成、有弹性且可持续的6G网络的组成部分。

Abstract: HAPS are emerging as key enablers in the evolution of 6G wireless networks,
bridging terrestrial and non-terrestrial infrastructures. Operating in the
stratosphere, HAPS can provide wide-area coverage, low-latency,
energy-efficient broadband communications with flexible deployment options for
diverse applications. This survey delivers a comprehensive overview of HAPS use
cases, technologies, and integration strategies within the 6G ecosystem. The
roles of HAPS in extending connectivity to underserved regions, supporting
dynamic backhauling, enabling massive IoT, and delivering reliable low-latency
communications for autonomous and immersive services are discussed. The paper
reviews state-of-the-art architectures for terrestrial and non-terrestrial
network integration, highlights recent field trials. Furthermore, key enabling
technologies such as channel modeling, AI-driven resource allocation,
interference control, mobility management, and energy-efficient communications
are examined. The paper also outlines open research challenges. By addressing
existing gaps in the literature, this survey positions HAPS as a foundational
component of globally integrated, resilient, and sustainable 6G networks.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [190] [Impartial Selection with Predictions](https://arxiv.org/abs/2510.19002)
*Javier Cembrano,Felix Fischer,Max Klimm*

Main category: cs.GT

TL;DR: 研究基于相互提名的代理人选择问题，引入了具有一致性和鲁棒性的机制，并给出了在不同情况下的性能界限。


<details>
  <summary>Details</summary>
Motivation: 研究代理人选择问题，特别是当代理人既选择他人又被他人选择时，可能存在的为了自身利益而虚假陈述的问题。

Method: 提出并分析了在给定预测信息的情况下，保证选择独立于提名的‘公正机制’。研究了机制的一致性（预测准确时）和鲁棒性（预测不准确时）。

Result: 在一般情况下，提出了一个机制，其一致性为 1-O(1/k)，鲁棒性为 1-1/e-O(1/k)。在选择单一代理人的特殊情况下，证明了可以实现1-一致性并保证1/2-鲁棒性。

Conclusion: 所提出的机制在保持高一致性的同时，对预测的准确性具有良好的鲁棒性，与现有结果相比，在（渐近）最优一致性方面几乎没有牺牲鲁棒性。

Abstract: We study the selection of agents based on mutual nominations, a theoretical
problem with many applications from committee selection to AI alignment. As
agents both select and are selected, they may be incentivized to misrepresent
their true opinion about the eligibility of others to influence their own
chances of selection. Impartial mechanisms circumvent this issue by
guaranteeing that the selection of an agent is independent of the nominations
cast by that agent. Previous research has established strong bounds on the
performance of impartial mechanisms, measured by their ability to approximate
the number of nominations for the most highly nominated agents. We study to
what extent the performance of impartial mechanisms can be improved if they are
given a prediction of a set of agents receiving a maximum number of
nominations. Specifically, we provide bounds on the consistency and robustness
of such mechanisms, where consistency measures the performance of the
mechanisms when the prediction is accurate and robustness its performance when
the prediction is inaccurate. For the general setting where up to $k$ agents
are to be selected and agents nominate any number of other agents, we give a
mechanism with consistency $1-O\big(\frac{1}{k}\big)$ and robustness
$1-\frac{1}{e}-O\big(\frac{1}{k}\big)$. For the special case of selecting a
single agent based on a single nomination per agent, we prove that
$1$-consistency can be achieved while guaranteeing $\frac{1}{2}$-robustness. A
close comparison with previous results shows that (asymptotically) optimal
consistency can be achieved with little to no sacrifice in terms of robustness.

</details>


### [191] [Desirable Effort Fairness and Optimality Trade-offs in Strategic Learning](https://arxiv.org/abs/2510.19098)
*Valia Efthymiou,Ekaterina Fedorova,Chara Podimata*

Main category: cs.GT

TL;DR: 该研究探讨了在存在策略性代理的情况下，决策者如何在最大化目标的同时，通过引入公平性约束来管理代理激励。


<details>
  <summary>Details</summary>
Motivation: 在标准的战略学习模型中，决策者仅限于学习一个最大化其目标（例如准确性）的分类器，并假设代理会做出最佳响应。然而，现实世界的决策系统目标并不完全是产生好的预测，它们还需要考虑诱导特定激励的外部影响，这会转化为决策者认为某些特征的变化更可取。此外，决策者可能还需要在异构代理之间公平地激励可取的特征变化。本研究旨在量化这种约束优化（即最大化目标，同时限制代理的激励差异）对决策者造成的成本。

Method: 本研究提出了一个统一的决策者-代理交互模型，该模型考虑了三个额外因素：(1) 特征之间的因果依赖关系，即一个特征的变化会影响其他特征；(2) 代理之间的异构操纵成本；(3) 代理通过推断决策者的规则而产生的同行学习。在此基础上，研究者为决策者在特定可取性公平性容忍度下，针对多种广泛类别的公平性度量，提供了关于其最优性损失的理论保证。

Result: 通过在真实数据集上进行实验，研究结果明确展示了在最大化准确性与可取性激励的公平性之间存在的权衡关系。

Conclusion: 该研究提出了一个考虑特征因果关系、异构成本和同行学习的决策者-代理模型，并提供了在公平性约束下的最优性损失理论保证，实验结果证实了准确性和公平性之间的权衡。

Abstract: Strategic learning studies how decision rules interact with agents who may
strategically change their inputs/features to achieve better outcomes. In
standard settings, models assume that the decision-maker's sole scope is to
learn a classifier that maximizes an objective (e.g., accuracy) assuming that
agents best respond. However, real decision-making systems' goals do not align
exclusively with producing good predictions. They may consider the external
effects of inducing certain incentives, which translates to the change of
certain features being more desirable for the decision maker. Further, the
principal may also need to incentivize desirable feature changes fairly across
heterogeneous agents. How much does this constrained optimization (i.e.,
maximize the objective, but restrict agents' incentive disparity) cost the
principal? We propose a unified model of principal-agent interaction that
captures this trade-off under three additional components: (1) causal
dependencies between features, such that changes in one feature affect others;
(2) heterogeneous manipulation costs between agents; and (3) peer learning,
through which agents infer the principal's rule. We provide theoretical
guarantees on the principal's optimality loss constrained to a particular
desirability fairness tolerance for multiple broad classes of fairness
measures. Finally, through experiments on real datasets, we show the explicit
tradeoff between maximizing accuracy and fairness in desirability effort.

</details>


### [192] [Autobidding Arena: unified evaluation of the classical and RL-based autobidding algorithms](https://arxiv.org/abs/2510.19357)
*Andrey Pudovikov,Alexandra Khirianova,Ekaterina Solodneva,Aleksandr Katrutsa,Egor Samosvat,Yuriy Dorn*

Main category: cs.GT

TL;DR: 该论文提出了一个标准化的、透明化的评估协议，用于比较经典的以及基于强化学习（RL）的自动竞价（autobidding）算法，以解决广告竞价中自动竞价算法评估的公平性和可复现性问题。


<details>
  <summary>Details</summary>
Motivation: 广告竞价是电子商务公司收入的关键来源，但现有自动竞价算法的评估缺乏公平性和可复现性。

Method: 使用最新的开源竞价环境，该环境能够准确模拟竞价过程，对不同类别的自动竞价算法（如基于控制器、RL、最优公式等）进行基准测试和比较。

Result: 展示了所考虑的自动竞价算法最有前景的应用场景，揭示了它们出乎意料的缺点，并根据多种指标（包括性能、成本和预算消耗）对它们进行了评估。

Conclusion: 该评估协议和比较结果有助于实践者从多角度评估候选自动竞价算法，并根据公司目标选择高效的算法。

Abstract: Advertisement auctions play a crucial role in revenue generation for
e-commerce companies. To make the bidding procedure scalable to thousands of
auctions, the automatic bidding (autobidding) algorithms are actively developed
in the industry. Therefore, the fair and reproducible evaluation of autobidding
algorithms is an important problem. We present a standardized and transparent
evaluation protocol for comparing classical and reinforcement learning (RL)
autobidding algorithms. We consider the most efficient autobidding algorithms
from different classes, e.g., ones based on the controllers, RL, optimal
formulas, etc., and benchmark them in the bidding environment. We utilize the
most recent open-source environment developed in the industry, which accurately
emulates the bidding process. Our work demonstrates the most promising use
cases for the considered autobidding algorithms, highlights their surprising
drawbacks, and evaluates them according to multiple metrics. We select the
evaluation metrics that illustrate the performance of the autobidding
algorithms, the corresponding costs, and track the budget pacing. Such a choice
of metrics makes our results applicable to the broad range of platforms where
autobidding is effective. The presented comparison results help practitioners
to evaluate the candidate autobidding algorithms from different perspectives
and select ones that are efficient according to their companies' targets.

</details>


### [193] [Comparing Uniform Price and Discriminatory Multi-Unit Auctions through Regret Minimization](https://arxiv.org/abs/2510.19591)
*Marius Potfer,Vianney Perchet*

Main category: cs.GT

TL;DR: 该论文比较了两种主要的重复多单位拍卖机制：统一价格拍卖和歧视价格拍卖，重点关注单个竞标者在随机对手存在下的学习竞标行为。


<details>
  <summary>Details</summary>
Motivation: 比较统一价格拍卖和歧视价格拍卖在学习竞标方面的难度，特别是在有随机对手的情况下。

Method: 对两种拍卖格式在完全信息和精力反馈两种情况下的后悔值（regret）进行了理论分析，并提供了针对对称单位需求竞标者情况的特定分析。

Result: 在完全信息和精力反馈下，两种拍卖格式的后悔值增长率相似，分别为 $\tilde{\Theta} ( \sqrt{T} )$ 和 $\tilde{\Theta} ( T^{2/3} )$。然而，在某些情况下，统一价格拍卖的学习速率可能更快，后悔值增长率为 $\tilde{\Theta} ( \sqrt{T} )$，而歧视价格拍卖仍为 $\tilde{\Theta} ( T^{2/3} )$。在对称单位需求竞标者的情况下，也观察到类似的学习速率差异。

Conclusion: 虽然两种拍卖机制在最坏情况下的学习难度相似，但统一价格拍卖在某些场景下可能提供更快的学习速率。

Abstract: Repeated multi-unit auctions, where a seller allocates multiple identical
items over many rounds, are common mechanisms in electricity markets and
treasury auctions. We compare the two predominant formats: uniform-price and
discriminatory auctions, focusing on the perspective of a single bidder
learning to bid against stochastic adversaries. We characterize the learning
difficulty in each format, showing that the regret scales similarly for both
auction formats under both full-information and bandit feedback, as
$\tilde{\Theta} ( \sqrt{T} )$ and $\tilde{\Theta} ( T^{2/3} )$, respectively.
However, analysis beyond worst-case regret reveals structural differences:
uniform-price auctions may admit faster learning rates, with regret scaling as
$\tilde{\Theta} ( \sqrt{T} )$ in settings where discriminatory auctions remain
at $\tilde{\Theta} ( T^{2/3} )$. Finally, we provide a specific analysis for
auctions in which the other participants are symmetric and have unit-demand,
and show that in these instances, a similar regret rate separation appears.

</details>


### [194] [On Minimal Achievable Quotas in Multiwinner Voting](https://arxiv.org/abs/2510.19620)
*Patrick Becker,Fabian Frank*

Main category: cs.GT

TL;DR: JR and EJR are proportionality axioms in approval-based multiwinner voting that rely on fixed quotas. This paper introduces instance-dependent quotas, demonstrating that common voting rules have an additive distance of k^2/(k+1)^2 to the optimum. It also proves that finding the optimal alpha for JR is NP-complete, but provides an ILP formulation and positive results in VI and CI domains.


<details>
  <summary>Details</summary>
Motivation: To move beyond the fixed-quota paradigm in approval-based multiwinner voting by introducing instance-dependent quotas for proportionality axioms like JR and EJR.

Method: Introduce instance-dependent quotas, analyze the additive distance of common voting rules to the optimum, prove NP-completeness for finding the optimal alpha for JR, and propose an ILP formulation for computing committees satisfying JR.

Result: Common voting rules have an additive distance of k^2/(k+1)^2 to the optimum. Determining the optimal alpha for JR is NP-complete. An ILP formulation is provided, with positive results in VI and CI domains.

Conclusion: The paper successfully introduces instance-dependent quotas for proportionality in voting, analyzes the resulting complexities and distances, and offers computational solutions for specific domains.

Abstract: Justified representation (JR) and extended justified representation (EJR) are
well-established proportionality axioms in approval-based multiwinner voting.
Both axioms are always satisfiable, but they rely on a fixed quota (typically
Hare or Droop), with the Droop quota being the smallest one that guarantees
existence across all instances. With this observation in mind, we take a first
step beyond the fixed-quota paradigm and introduce proportionality notions
where the quota is instance-dependent. We demonstrate that all commonly studied
voting rules can have an additive distance to the optimum of
$\frac{k^2}{(k+1)^2}$. Moreover, we look into the computational aspects of our
instance-dependent quota and prove that determining the optimal value of
$\alpha$ for a given approval profile satisfying $\alpha$-JR is NP-complete. To
address this, we introduce an integer linear programming (ILP) formulation for
computing committees that satisfy $\alpha$-JR, and we provide positive results
in the voter interval (VI) and candidate interval (CI) domains.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [195] [Towards Proprioceptive Terrain Mapping with Quadruped Robots for Exploration in Planetary Permanently Shadowed Regions](https://arxiv.org/abs/2510.18986)
*Alberto Sanchez-Delgado,João Carlos Virgolino Soares,Victor Barasuol,Claudio Semini*

Main category: cs.RO

TL;DR: 该研究提出了一种用于四足机器人的地形绘图框架，该框架利用内部传感来估计月球极地永久阴影区（PSRs）的地形交互，包括高程、脚部滑动、能量消耗和稳定性裕度。


<details>
  <summary>Details</summary>
Motivation: 月球极地永久阴影区（PSRs）因可能含有水冰和保存地质记录而对未来的月球探索至关重要。这些区域复杂的、不平坦的地形使得使用能够穿越挑战性地面的有腿机器人进行就地数据收集成为一种有效的方法。

Method: 提出了一种地形绘图框架，利用四足机器人的内部传感来估计高程、脚部滑动、能量消耗和稳定性裕度。这些指标被逐步整合到一个多层 2.5D 网格地图中，该地图从机器人的角度反映了地形交互。

Result: 在模拟月球环境的模拟器中，使用 21 公斤的四足机器人 Aliengo 进行了评估，该系统在月球重力和地形条件下显示出一致的绘图性能。

Conclusion: 所提出的地形绘图框架能够有效地为四足机器人在月球极地永久阴影区的探索提供关键的地形交互信息。

Abstract: Permanently Shadowed Regions (PSRs) near the lunar poles are of interest for
future exploration due to their potential to contain water ice and preserve
geological records. Their complex, uneven terrain favors the use of legged
robots, which can traverse challenging surfaces while collecting in-situ data,
and have proven effective in Earth analogs, including dark caves, when equipped
with onboard lighting. While exteroceptive sensors like cameras and lidars can
capture terrain geometry and even semantic information, they cannot quantify
its physical interaction with the robot, a capability provided by
proprioceptive sensing. We propose a terrain mapping framework for quadruped
robots, which estimates elevation, foot slippage, energy cost, and stability
margins from internal sensing during locomotion. These metrics are
incrementally integrated into a multi-layer 2.5D gridmap that reflects terrain
interaction from the robot's perspective. The system is evaluated in a
simulator that mimics a lunar environment, using the 21 kg quadruped robot
Aliengo, showing consistent mapping performance under lunar gravity and terrain
conditions.

</details>


### [196] [Underwater Dense Mapping with the First Compact 3D Sonar](https://arxiv.org/abs/2510.18991)
*Chinmay Burgul,Yewei Huang,Michalis Chatzispyrou,Ioannis Rekleitis,Alberto Quattrini Li,Marios Xanthidis*

Main category: cs.RO

TL;DR: 以往十年，以激光雷达为代表的致密三维测距传感器被广泛应用于空中、地面和空间自主导航。然而，电磁波在水下的传播受限，使得水下状态估计的传感选择仅限于提供二维信息且空间信息模糊的声学测距传感器。本文首次研究了新型致密三维声纳的性能、容量和应用前景。我们提出了三维声纳与相机之间的外参提取校准方法，并研究了声波在不同表面和材料上的响应。此外，我们还开发了新颖的地图构建和SLAM（即时定位与地图构建）方法，并在具有挑战性的水下洞穴系统等环境中进行了测试。评估结果表明，三维声纳能够提供一致的空间信息，实现对数百米数据集的详细重建和定位，同时也指出了与声波传播相关的挑战。我们收集的数据集将被公开，以促进社区的进一步研究。


<details>
  <summary>Details</summary>
Motivation: 水下状态估计受限于声学测距传感器提供的二维且空间信息模糊的数据。本文旨在探索新型致密三维声纳在水下状态估计中的潜力。

Method: 提出三维声纳与相机之间的外参提取校准方法，研究声波在不同表面和材料上的响应，并开发新颖的地图构建和SLAM方法。

Result: 三维声纳能够提供一致的空间信息，实现对数百米数据集的详细重建和定位，同时也指出了与声波传播相关的挑战。

Conclusion: 三维声纳在水下状态估计和重建方面具有巨大潜力，但声波传播仍是需要解决的挑战。

Abstract: In the past decade, the adoption of compact 3D range sensors, such as LiDARs,
has driven the developments of robust state-estimation pipelines, making them a
standard sensor for aerial, ground, and space autonomy. Unfortunately, poor
propagation of electromagnetic waves underwater, has limited the
visibility-independent sensing options of underwater state-estimation to
acoustic range sensors, which provide 2D information including, at-best,
spatially ambiguous information. This paper, to the best of our knowledge, is
the first study examining the performance, capacity, and opportunities arising
from the recent introduction of the first compact 3D sonar. Towards that
purpose, we introduce calibration procedures for extracting the extrinsics
between the 3D sonar and a camera and we provide a study on acoustic response
in different surfaces and materials. Moreover, we provide novel mapping and
SLAM pipelines tested in deployments in underwater cave systems and other
geometrically and acoustically challenging underwater environments. Our
assessment showcases the unique capacity of 3D sonars to capture consistent
spatial information allowing for detailed reconstructions and localization in
datasets expanding to hundreds of meters. At the same time it highlights
remaining challenges related to acoustic propagation, as found also in other
acoustic sensors. Datasets collected for our evaluations would be released and
shared with the community to enable further research advancements.

</details>


### [197] [SHRUMS: Sensor Hallucination for Real-time Underwater Motion Planning with a Compact 3D Sonar](https://arxiv.org/abs/2510.18996)
*Susheel Vadakkekuruppath,Herman B. Amundsen,Jason M. O'Kane,Marios Xanthidis*

Main category: cs.RO

TL;DR: SHRUMS是首个集成3D声纳的水下自主导航系统，通过“传感器幻觉”技术在复杂且低可见度环境下实现鲁棒的实时导航。


<details>
  <summary>Details</summary>
Motivation: 自主水下机器人（AUV）在3D环境中的导航是一个基本问题，但受限于早期水下传感器能力。3D声纳的出现为解决此问题提供了新的可能。

Method: 提出了一种名为SHRUMS（Sensor Hallucination for Robust Underwater Motion planning with 3D Sonar）的新型水下3D导航流程。该流程的核心是“传感器幻觉”概念，即从不存在的传感器生成具有任意参数的测量值，以适应3D声纳数据的复杂性和实现实时导航。

Result: SHRUMS在复杂3D环境和极差可见度条件下展现了强大的鲁棒性。实验采用了真实的3D声纳传感器数据和实时构建的局部地图进行验证。

Conclusion: SHRUMS是首个集成3D声纳的水下自主导航系统，通过“传感器幻觉”技术，在挑战性的水下环境中实现了鲁棒的实时导航，为水下机器人导航领域带来了重要进展。计划在不久的将来进行实地部署验证。

Abstract: Autonomous navigation in 3D is a fundamental problem for autonomy. Despite
major advancements in terrestrial and aerial settings due to improved range
sensors including LiDAR, compact sensors with similar capabilities for
underwater robots have only recently become available, in the form of 3D
sonars. This paper introduces a novel underwater 3D navigation pipeline, called
SHRUMS (Sensor Hallucination for Robust Underwater Motion planning with 3D
Sonar). To the best of the authors' knowledge, SHRUMS is the first underwater
autonomous navigation stack to integrate a 3D sonar. The proposed pipeline
exhibits strong robustness while operating in complex 3D environments in spite
of extremely poor visibility conditions. To accommodate the intricacies of the
novel sensor data stream while achieving real-time locally optimal performance,
SHRUMS introduces the concept of hallucinating sensor measurements from
non-existent sensors with convenient arbitrary parameters, tailored to
application specific requirements. The proposed concepts are validated with
real 3D sonar sensor data, utilizing real inputs in challenging settings and
local maps constructed in real-time. Field deployments validating the proposed
approach in full are planned in the very near future.

</details>


### [198] [$\nabla$-SDF: Learning Euclidean Signed Distance Functions Online with Gradient-Augmented Octree Interpolation and Neural Residual](https://arxiv.org/abs/2510.18999)
*Zhirui Dai,Qihao Qian,Tianxing Fan,Nikolay Atanasov*

Main category: cs.RO

TL;DR: 该研究提出了一种名为∇-SDF的混合方法，结合了基于梯度增强八叉树插值的显式先验和隐式神经残差，实现了非截断（欧氏）SDF重建。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有SDF重建方法在连续性、可微性、效率、内存限制和截断SDF等方面的局限性，本研究旨在提出一种能够实现高保真度、可微且计算/内存效率高的SDF重建方法。

Method: ∇-SDF是一种混合方法，结合了显式先验（通过梯度增强八叉树插值获得）和隐式神经残差。

Result: ∇-SDF在计算和内存效率方面可与体积方法相媲美，在可微性和准确性方面可与神经网络方法相媲美。实验证明，∇-SDF在准确性和效率方面优于现有技术，为机器人学和计算机视觉中的下游任务提供了可扩展的解决方案。

Conclusion: ∇-SDF是一种有效且可扩展的SDF重建方法，解决了现有方法的缺点，并在准确性和效率方面取得了最先进的成果。

Abstract: Estimation of signed distance functions (SDFs) from point cloud data has been
shown to benefit many robot autonomy capabilities, including localization,
mapping, motion planning, and control. Methods that support online and
large-scale SDF reconstruction tend to rely on discrete volumetric data
structures, which affect the continuity and differentiability of the SDF
estimates. Recently, using implicit features, neural network methods have
demonstrated high-fidelity and differentiable SDF reconstruction but they tend
to be less efficient, can experience catastrophic forgetting and memory
limitations in large environments, and are often restricted to truncated SDFs.
This work proposes $\nabla$-SDF, a hybrid method that combines an explicit
prior obtained from gradient-augmented octree interpolation with an implicit
neural residual. Our method achieves non-truncated (Euclidean) SDF
reconstruction with computational and memory efficiency comparable to
volumetric methods and differentiability and accuracy comparable to neural
network methods. Extensive experiments demonstrate that \methodname{}
outperforms the state of the art in terms of accuracy and efficiency, providing
a scalable solution for downstream tasks in robotics and computer vision.

</details>


### [199] [Motion Planning and Control of an Overactuated 4-Wheel Drive with Constrained Independent Steering](https://arxiv.org/abs/2510.19054)
*Shiyu Liu,Ilija Hadzic,Akshay Gupta,Aliasghar Arab*

Main category: cs.RO

TL;DR: 该论文研究了具有独立转向（4WIS）的驱动轮在运动规划和控制中的应用，其中机械限制阻止了车轮执行360度旋转（转向）。


<details>
  <summary>Details</summary>
Motivation: 由于机械限制，4WIS机器人的构型空间存在约束和不连续性，影响了运动的平滑性。

Method: 论文中提出了转向约束的数学公式，并推导了速度空间的不连续性平面，将速度空间划分为平滑高效的运动区域。在此基础上，论文设计了一种运动规划器，用于路径跟踪和避障，该规划器显式考虑了转向约束和速度转换的平滑性。运动控制器利用局部反馈生成期望速度的驱动力，并通过临时停止运动和重新定位车轮来处理不连续性的穿越。

Result: 所提出的运动规划器已作为ROS导航包的扩展实现，并在仿真和物理机器人上进行了评估。

Conclusion: 该研究为解决4WIS机器人的运动规划和控制问题提供了一种新的方法，特别是在处理转向约束和运动平滑性方面。

Abstract: This paper addresses motion planning and con- trol of an overactuated 4-wheel
drive train with independent steering (4WIS) where mechanical constraints
prevent the wheels from executing full 360-degree rotations (swerve). The
configuration space of such a robot is constrained and contains discontinuities
that affect the smoothness of the robot motion. We introduce a mathematical
formulation of the steering constraints and derive discontinuity planes that
partition the velocity space into regions of smooth and efficient motion. We
further design the motion planner for path tracking and ob- stacle avoidance
that explicitly accounts for swerve constraints and the velocity transition
smoothness. The motion controller uses local feedback to generate actuation
from the desired velocity, while properly handling the discontinuity crossing
by temporarily stopping the motion and repositioning the wheels. We implement
the proposed motion planner as an extension to ROS Navigation package and
evaluate the system in simulation and on a physical robot.

</details>


### [200] [Convex Maneuver Planning for Spacecraft Collision Avoidance](https://arxiv.org/abs/2510.19058)
*Fausto Vega,Jon Arrizabalaga,Ryan Watson,Zachary Manchester*

Main category: cs.RO

TL;DR: 使用半定规划（SDP）的放松技术，提出了一种自动化的低推力碰撞规避机动设计算法，可在保证所需碰撞概率的同时找到最小能量解，或在无法满足该概率时找到最小风险解。


<details>
  <summary>Details</summary>
Motivation: 随着低地球轨道（LEO）卫星密度的增加，手动进行碰撞分析和机动规划已成为一项耗时且效率低下的任务，因此需要自动化方法来高效地评估和缓解碰撞。

Method: 将碰撞规避机动设计问题表述为非凸二次约束二次规划（QCQP），然后使用Shor的松弛技术将其松弛为凸半定规划（SDP），最后通过验证松弛的紧密性来恢复原始非凸问题的全局最优解。

Result: 该算法能够生成最小能量解，同时满足指定的碰撞概率；如果无法满足该概率，则将其转化为惩罚项，得到最小风险解。在高保真度的LEO卫星碰撞仿真中，该算法被证明能有效降低碰撞风险。

Conclusion: 所提出的基于SDP松弛的算法能够有效地为短时间内的卫星碰撞事件设计低推力机动，以最小化能量或风险，同时满足碰撞概率要求。

Abstract: Conjunction analysis and maneuver planning for spacecraft collision avoidance
remains a manual and time-consuming process, typically involving repeated
forward simulations of hand-designed maneuvers. With the growing density of
satellites in low-Earth orbit (LEO), autonomy is becoming essential for
efficiently evaluating and mitigating collisions. In this work, we present an
algorithm to design low-thrust collision-avoidance maneuvers for short-term
conjunction events. We first formulate the problem as a nonconvex
quadratically-constrained quadratic program (QCQP), which we then relax into a
convex semidefinite program (SDP) using Shor's relaxation. We demonstrate
empirically that the relaxation is tight, which enables the recovery of
globally optimal solutions to the original nonconvex problem. Our formulation
produces a minimum-energy solution while ensuring a desired probability of
collision at the time of closest approach. Finally, if the desired probability
of collision cannot be satisfied, we relax this constraint into a penalty,
yielding a minimum-risk solution. We validate our algorithm with a
high-fidelity simulation of a satellite conjunction in low-Earth orbit with a
simulated conjunction data message (CDM), demonstrating its effectiveness in
reducing collision risk.

</details>


### [201] [A Learning-based Model Reference Adaptive Controller Implemented on a Prosthetic Hand Wrist](https://arxiv.org/abs/2510.19068)
*Shifa Sulaiman,Mohammad Gohari,Francesco Schetter,Fanny Ficuciello*

Main category: cs.RO

TL;DR: 本研究提出了一种基于神经网络的自适应控制器（NN-MRAC），用于控制假肢手上的软连续手腕，实现了高精度和实时性。


<details>
  <summary>Details</summary>
Motivation: 当前假肢手控制策略在适应性和计算成本方面存在挑战，难以满足实时应用需求。

Method: 使用Timoshenko梁理论建立手腕动力学模型，并提出一种计算效率高的基于神经网络的自适应控制器（NN-MRAC），通过在线自适应来估计腱力并最小化参考模型之间的偏差。

Result: 仿真结果显示RMSE为$6.14 	imes 10^{-4}$ m，收敛时间为$3.2$s。实验结果显示平均RMSE为$5.66 	imes 10^{-3}$ m，稳态误差为$8.05 	imes 10^{-3}$ m，收敛时间为$1.58$ s。

Conclusion: 所提出的NN-MRAC控制器能够提高软体假肢系统的运动精度和响应速度，为可穿戴辅助设备中自适应智能控制的应用提供了潜力。

Abstract: The functionality and natural motion of prosthetic hands remain limited by
the challenges in controlling compliant wrist mechanisms. Current control
strategies often lack adaptability and incur high computational costs, which
impedes real-time deployment in assistive robotics. To address this gap, this
study presents a computationally efficient Neural Network (NN)-based Model
Reference Adaptive Controller (MRAC) for a tendon-driven soft continuum wrist
integrated with a prosthetic hand. The dynamic modeling of the wrist is
formulated using Timoshenko beam theory, capturing both shear and bending
deformations. The proposed NN-MRAC estimates the required tendon forces from
deflection errors and minimizes deviation from a reference model through online
adaptation. Simulation results demonstrate improved precision with a root mean
square error (RMSE) of $6.14 \times 10^{-4}$ m and a settling time of $3.2$s.
Experimental validations confirm real-time applicability, with an average RMSE
of $5.66 \times 10^{-3}$ m, steady-state error of $8.05 \times 10^{-3}$ m, and
settling time of $1.58$ s. These results highlight the potential of the
controller to enhance motion accuracy and responsiveness in soft prosthetic
systems, thereby advancing the integration of adaptive intelligent control in
wearable assistive devices.

</details>


### [202] [Sample-Based Hybrid Mode Control: Asymptotically Optimal Switching of Algorithmic and Non-Differentiable Control Modes](https://arxiv.org/abs/2510.19074)
*Yilang Liu,Haoxiang You,Ian Abraham*

Main category: cs.RO

TL;DR: 本论文提出了一种基于采样的方法来解决混合模式控制问题，该问题涉及非可微分和算法混合模式。


<details>
  <summary>Details</summary>
Motivation: 本论文旨在解决非可微分和算法混合模式下的混合模式控制问题。

Method: 将混合模式控制问题转化为整数优化问题，确定模式选择、切换时机和持续时间，并推导出一种基于采样的方法来搜索最优解。

Result: 该方法在机器人相关任务中表现出强大的性能保证，能够合成复杂的算法和策略来实现具有挑战性的任务，并在实际机器人示例中得到验证，能够实现长期规划和高频控制之间的反应式切换。

Conclusion: 该方法在解决混合模式控制问题方面是有效的，并且在机器人学中有实际应用价值。

Abstract: This paper investigates a sample-based solution to the hybrid mode control
problem across non-differentiable and algorithmic hybrid modes. Our approach
reasons about a set of hybrid control modes as an integer-based optimization
problem where we select what mode to apply, when to switch to another mode, and
the duration for which we are in a given control mode. A sample-based variation
is derived to efficiently search the integer domain for optimal solutions. We
find our formulation yields strong performance guarantees that can be applied
to a number of robotics-related tasks. In addition, our approach is able to
synthesize complex algorithms and policies to compound behaviors and achieve
challenging tasks. Last, we demonstrate the effectiveness of our approach in
real-world robotic examples that require reactive switching between long-term
planning and high-frequency control.

</details>


### [203] [Kinematic Analysis and Integration of Vision Algorithms for a Mobile Manipulator Employed Inside a Self-Driving Laboratory](https://arxiv.org/abs/2510.19081)
*Shifa Sulaiman,Tobias Busk Jensen,Stefan Hein Bengtson,Simon Bøgh*

Main category: cs.RO

TL;DR: 本研究介绍了一种用于自动化实验室环境的移动机械臂，重点是改进其在有纹理物体抓取方面的能力，并结合了先进的视觉算法以实现精确的物体识别和姿态估计。


<details>
  <summary>Details</summary>
Motivation: 为了推动机器人和自主系统在实验室环境中的应用，例如自动化合成、可扩展的反应流程以及在自动驾驶实验室（SDL）中的协作任务，本研究旨在开发一种能够辅助人类操作员在这些环境中进行工作的移动机械臂。

Method: 研究采用了Denavit-Hartenberg（DH）约定进行机械臂的运动学建模，并求解逆运动学以实现精确自适应的操作。在视觉方面，集成了基于特征检测和单应性驱动姿态估计的视觉方法，并利用深度信息将物体姿态表示为三维空间中的二维平面投影，以实现实时物体检测和姿态估计，从而支持动态抓取和跟随任务。

Result: 该移动机械臂能够可靠地抓取有纹理的物体，并通过先进的视觉算法实现实时的物体检测和姿态估计，从而能够适应物体方向的变化，并在各种环境中进行稳健的自主操作。

Conclusion: 通过实现自主实验和人机协作，本研究为下一代化学实验室的可扩展性和可重复性做出了贡献，能够适应物体方向的变化，并在各种环境中进行稳健的自主操作。

Abstract: Recent advances in robotics and autonomous systems have broadened the use of
robots in laboratory settings, including automated synthesis, scalable reaction
workflows, and collaborative tasks in self-driving laboratories (SDLs). This
paper presents a comprehensive development of a mobile manipulator designed to
assist human operators in such autonomous lab environments. Kinematic modeling
of the manipulator is carried out based on the Denavit Hartenberg (DH)
convention and inverse kinematics solution is determined to enable precise and
adaptive manipulation capabilities. A key focus of this research is enhancing
the manipulator ability to reliably grasp textured objects as a critical
component of autonomous handling tasks. Advanced vision-based algorithms are
implemented to perform real-time object detection and pose estimation, guiding
the manipulator in dynamic grasping and following tasks. In this work, we
integrate a vision method that combines feature-based detection with
homography-driven pose estimation, leveraging depth information to represent an
object pose as a $2$D planar projection within $3$D space. This adaptive
capability enables the system to accommodate variations in object orientation
and supports robust autonomous manipulation across diverse environments. By
enabling autonomous experimentation and human-robot collaboration, this work
contributes to the scalability and reproducibility of next-generation chemical
laboratories

</details>


### [204] [Safe Active Navigation and Exploration for Planetary Environments Using Proprioceptive Measurements](https://arxiv.org/abs/2510.19101)
*Matthew Jiang,Shipeng Liu,Feifei Qian*

Main category: cs.RO

TL;DR: 该研究提出了一种名为SAEGT的导航框架，使足式机器人能够利用本体感觉感知安全地探索未知的颗粒状环境，即使在视觉信息不足的情况下也能进行地形适应性评估和导航。


<details>
  <summary>Details</summary>
Motivation: 在崎岖、不稳定的地形中，足式机器人比轮式机器人更具优势，但即使是足式机器人也面临着地形适应性差的挑战。该研究旨在通过利用本体感觉感知来解决这一问题。

Method: SAEGT框架利用高斯过程回归（GPR）从腿部与地形的交互中实时估计安全区域和前沿区域，以进行可通行性评估。结合反应式控制器，实现实时安全探索和导航。

Result: 在模拟环境中，SAEGT仅凭本体感觉估计的可通行性，成功实现了安全探索并向指定目标导航。

Conclusion: SAEGT框架能够使足式机器人仅依靠本体感觉信息，在视觉信息失效的情况下，安全地探索未知且具挑战性的颗粒状地形。

Abstract: Legged robots can sense terrain through force interactions during locomotion,
offering more reliable traversability estimates than remote sensing and serving
as scouts for guiding wheeled rovers in challenging environments. However, even
legged scouts face challenges when traversing highly deformable or unstable
terrain. We present Safe Active Exploration for Granular Terrain (SAEGT), a
navigation framework that enables legged robots to safely explore unknown
granular environments using proprioceptive sensing, particularly where visual
input fails to capture terrain deformability. SAEGT estimates the safe region
and frontier region online from leg-terrain interactions using Gaussian Process
regression for traversability assessment, with a reactive controller for
real-time safe exploration and navigation. SAEGT demonstrated its ability to
safely explore and navigate toward a specified goal using only proprioceptively
estimated traversability in simulation.

</details>


### [205] [A Cross-Environment and Cross-Embodiment Path Planning Framework via a Conditional Diffusion Model](https://arxiv.org/abs/2510.19128)
*Mehran Ghafarian Tamizi,Homayoun Honari,Amir Mehdi Soufi Enayati,Aleksey Nozdryn-Plotnicki,Homayoun Najjaran*

Main category: cs.RO

TL;DR: GADGET是一个基于扩散的模型，用于在杂乱的高维环境中进行路径规划，具有出色的泛化能力和安全性，无需重新训练即可适应新环境和机器人。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够泛化到未见过的环境和新的机器人机械臂而无需重新训练的路径规划框架。

Method: 提出了一种名为GADGET（通用和自适应扩散引导环境感知轨迹生成）的基于扩散的规划模型，该模型利用体素化的场景表示以及起点和终点配置来生成关节空间轨迹。其关键创新在于混合双重条件机制，结合了通过学习到的场景编码进行无分类器引导，以及通过分类器引导的控制势垒函数（CBF）安全塑形，直接在去噪过程中整合环境感知和实时避碰。

Result: GADGET在球形障碍物、垃圾箱拾取和架子环境中取得了很高的成功率和低碰撞强度，并且CBF引导进一步提高了安全性。与基于采样和基于学习的基线相比，GADGET表现出了强大的性能，并且能够跨Franka Panda、Kinova Gen3（6/7-DoF）和UR5机器人进行迁移，在Kinova Gen3上的实际执行证明了其在现实世界中生成安全、无碰撞轨迹的能力。

Conclusion: GADGET通过结合环境感知和实时碰撞避免，在杂乱环境中实现了高效、安全和可适应的路径规划，并展示了在不同环境和机器人上的出色泛化能力。

Abstract: Path planning for a robotic system in high-dimensional cluttered environments
needs to be efficient, safe, and adaptable for different environments and
hardware. Conventional methods face high computation time and require extensive
parameter tuning, while prior learning-based methods still fail to generalize
effectively. The primary goal of this research is to develop a path planning
framework capable of generalizing to unseen environments and new robotic
manipulators without the need for retraining. We present GADGET (Generalizable
and Adaptive Diffusion-Guided Environment-aware Trajectory generation), a
diffusion-based planning model that generates joint-space trajectories
conditioned on voxelized scene representations as well as start and goal
configurations. A key innovation is GADGET's hybrid dual-conditioning mechanism
that combines classifier-free guidance via learned scene encoding with
classifier-guided Control Barrier Function (CBF) safety shaping, integrating
environment awareness with real-time collision avoidance directly in the
denoising process. This design supports zero-shot transfer to new environments
and robotic embodiments without retraining. Experimental results show that
GADGET achieves high success rates with low collision intensity in
spherical-obstacle, bin-picking, and shelf environments, with CBF guidance
further improving safety. Moreover, comparative evaluations indicate strong
performance relative to both sampling-based and learning-based baselines.
Furthermore, GADGET provides transferability across Franka Panda, Kinova Gen3
(6/7-DoF), and UR5 robots, and physical execution on a Kinova Gen3 demonstrates
its ability to generate safe, collision-free trajectories in real-world
settings.

</details>


### [206] [GRASPLAT: Enabling dexterous grasping through novel view synthesis](https://arxiv.org/abs/2510.19200)
*Matteo Bortolon,Nuno Ferreira Duarte,Plinio Moreno,Fabio Poiesi,José Santos-Victor,Alessio Del Bue*

Main category: cs.RO

TL;DR: GRASPLAT是一个新的抓取框架，仅使用RGB图像进行训练，通过合成3D高斯喷溅手部抓取图像来预测手部关节，以实现灵巧的机器人抓取。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人抓取方法依赖完整的3D扫描，但在现实世界中难以获取高质量的3D数据，因此抓取灵巧性仍是一个挑战。

Method: 使用3D高斯喷溅合成手部抓取对象的逼真图像，并利用光度损失来优化抓取预测。

Result: 在合成和真实世界抓取数据集上，GRASPLAT将抓取成功率相比现有基于图像的方法提高了36.9%。

Conclusion: GRASPLAT通过合成3D高斯喷溅手部抓取图像，实现了仅用RGB图像进行训练的机器人抓取，并在抓取成功率方面取得了显著的改进。

Abstract: Achieving dexterous robotic grasping with multi-fingered hands remains a
significant challenge. While existing methods rely on complete 3D scans to
predict grasp poses, these approaches face limitations due to the difficulty of
acquiring high-quality 3D data in real-world scenarios. In this paper, we
introduce GRASPLAT, a novel grasping framework that leverages consistent 3D
information while being trained solely on RGB images. Our key insight is that
by synthesizing physically plausible images of a hand grasping an object, we
can regress the corresponding hand joints for a successful grasp. To achieve
this, we utilize 3D Gaussian Splatting to generate high-fidelity novel views of
real hand-object interactions, enabling end-to-end training with RGB data.
Unlike prior methods, our approach incorporates a photometric loss that refines
grasp predictions by minimizing discrepancies between rendered and real images.
We conduct extensive experiments on both synthetic and real-world grasping
datasets, demonstrating that GRASPLAT improves grasp success rates up to 36.9%
over existing image-based methods. Project page:
https://mbortolon97.github.io/grasplat/

</details>


### [207] [Hierarchical DLO Routing with Reinforcement Learning and In-Context Vision-language Models](https://arxiv.org/abs/2510.19268)
*Mingen Li,Houjian Yu,Yixuan Huang,Youngjin Hong,Changhyun Choi*

Main category: cs.RO

TL;DR: 该研究提出了一种用于解决可变形线性物体（DLO）长距离布线任务的全自主分层框架，利用视觉-语言模型（VLM）进行高层推理以合成可行计划，并通过强化学习训练的低层技能执行，同时引入失败恢复机制提高鲁棒性，最终在多种场景下实现了92.5%的成功率。


<details>
  <summary>Details</summary>
Motivation: 长距离可变形线性物体（DLO）布线任务在工业和日常生活中很常见，但机器人执行此类任务具有挑战性，需要长距离规划和可靠的技能执行能力，同时要适应非线性动力学、分解抽象目标并生成多步计划，这都需要在执行过程中进行准确的高层推理。

Method: 提出了一种全自主分层框架，利用视觉-语言模型（VLM）进行上下文高层推理以合成可行计划，并通过强化学习训练的低层技能执行。为了提高长距离任务的鲁棒性，引入了失败恢复机制，将DLO重新定向到可插入状态。

Result: 该方法在包含物体属性、空间描述和隐式语言命令的各种场景中表现出通用性，成功率达到了92.5%，并且比次优基线方法提高了近50%。

Conclusion: 该研究提出的全自主分层框架能够有效地解决具有挑战性的DLO布线任务，通过结合VLM的高层推理能力和强化学习的低层技能执行能力，并辅以失败恢复机制，实现了高成功率和鲁棒性。

Abstract: Long-horizon routing tasks of deformable linear objects (DLOs), such as
cables and ropes, are common in industrial assembly lines and everyday life.
These tasks are particularly challenging because they require robots to
manipulate DLO with long-horizon planning and reliable skill execution.
Successfully completing such tasks demands adapting to their nonlinear
dynamics, decomposing abstract routing goals, and generating multi-step plans
composed of multiple skills, all of which require accurate high-level reasoning
during execution. In this paper, we propose a fully autonomous hierarchical
framework for solving challenging DLO routing tasks. Given an implicit or
explicit routing goal expressed in language, our framework leverages
vision-language models~(VLMs) for in-context high-level reasoning to synthesize
feasible plans, which are then executed by low-level skills trained via
reinforcement learning. To improve robustness in long horizons, we further
introduce a failure recovery mechanism that reorients the DLO into
insertion-feasible states. Our approach generalizes to diverse scenes involving
object attributes, spatial descriptions, as well as implicit language commands.
It outperforms the next best baseline method by nearly 50% and achieves an
overall success rate of 92.5% across long-horizon routing scenarios.

</details>


### [208] [Risk Assessment of an Autonomous Underwater Snake Robot in Confined Operations](https://arxiv.org/abs/2510.19415)
*Abdelrahman Sayed Sayed*

Main category: cs.RO

TL;DR: 水下机器人的操作需要应对不确定、结构化的环境，极端环境条件和有限的导航能力。


<details>
  <summary>Details</summary>
Motivation: 为了应对水下探索和在狭窄、恶劣环境下的干预需求，研究人员提出了使用具有可变体形能力的铰接式水下机器人。

Method: 提出了一种贝叶斯方法来评估在两种任务场景中丢失Eely的风险。

Result: 通过敏感性分析展示了影响Eely丢失的最主要因素。

Conclusion: 提出的贝叶斯方法旨在提高Eely的性能和任务成功率。

Abstract: The growing interest in ocean discovery imposes a need for inspection and
intervention in confined and demanding environments. Eely's slender shape, in
addition to its ability to change its body configurations, makes articulated
underwater robots an adequate option for such environments. However, operation
of Eely in such environments imposes demanding requirements on the system, as
it must deal with uncertain and unstructured environments, extreme
environmental conditions, and reduced navigational capabilities. This paper
proposes a Bayesian approach to assess the risks of losing Eely during two
mission scenarios. The goal of this work is to improve Eely's performance and
the likelihood of mission success. Sensitivity analysis results are presented
in order to demonstrate the causes having the highest impact on losing Eely.

</details>


### [209] [TARMAC: A Taxonomy for Robot Manipulation in Chemistry](https://arxiv.org/abs/2510.19289)
*Kefeng Huang,Jonathon Pipe,Alice E. Martin,Tianyuan Wang,Barnabas A. Franklin,Andy M. Tyrrell,Ian J. S. Fairlamb,Jihong Zhu*

Main category: cs.RO

TL;DR: TARMAC是一个机器人操作分类法，用于化学实验室，可以提高自动化水平。


<details>
  <summary>Details</summary>
Motivation: 现有实验室自动化系统在很大程度上仍然依赖人工干预，并且缺乏可转移性，因为它们缺乏对所需技能的结构化表征。

Method: 开发了一个名为TARMAC（化学机器人操作分类法）的领域特定框架，用于定义和组织实验室实践所需的核心操作。该框架基于教学实验室演示和实验验证。

Result: TARMAC被组织成描述性词汇，可以实例化为机器人可执行的原语，并组合成更高级别的宏，从而实现技能重用并支持可扩展到长周期工作流的集成。

Conclusion: TARMAC提供了一个结构化基础，可以实现更灵活、更自主的实验室自动化。

Abstract: Chemistry laboratory automation aims to increase throughput, reproducibility,
and safety, yet many existing systems still depend on frequent human
intervention. Advances in robotics have reduced this dependency, but without a
structured representation of the required skills, autonomy remains limited to
bespoke, task-specific solutions with little capacity to transfer beyond their
initial design. Current experiment abstractions typically describe
protocol-level steps without specifying the robotic actions needed to execute
them. This highlights the lack of a systematic account of the manipulation
skills required for robots in chemistry laboratories. To address this gap, we
introduce TARMAC - a Taxonomy for Robot Manipulation in Chemistry - a
domain-specific framework that defines and organizes the core manipulations
needed in laboratory practice. Based on annotated teaching-lab demonstrations
and supported by experimental validation, TARMAC categorizes actions according
to their functional role and physical execution requirements. Beyond serving as
a descriptive vocabulary, TARMAC can be instantiated as robot-executable
primitives and composed into higher-level macros, enabling skill reuse and
supporting scalable integration into long-horizon workflows. These
contributions provide a structured foundation for more flexible and autonomous
laboratory automation. More information is available at
https://tarmac-paper.github.io/

</details>


### [210] [Imitation Learning Policy based on Multi-Step Consistent Integration Shortcut Model](https://arxiv.org/abs/2510.19356)
*Yu Fang,Xinyu Wang,Xuehe Zhang,Wanli Xue,Mingwei Zhang,Shengyong Chen,Jie Zhao*

Main category: cs.RO

TL;DR: 提出了一种结合单步捷径和多步集成的方法，以提高机器人模仿学习的推理速度和性能，并通过自适应梯度分配方法解决了优化不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: 现有机器人模仿学习方法（如流匹配）存在推理时间长的问题，而蒸馏和一致性方法在性能上仍不及原始模型。

Method: 提出一种带有多步集成的单步捷径方法，通过将单步损失分解为多步损失来扩展多步一致性损失，以提高单步推理性能。提出一种自适应梯度分配方法来解决多步损失和原始流匹配损失的优化不稳定性问题。

Result: 在两个模拟基准和五个真实世界环境任务的评估中，实验结果验证了所提出算法的有效性。

Conclusion: 所提出的方法能够有效提高机器人模仿学习的推理速度和性能，并具有稳定的学习过程。

Abstract: The wide application of flow-matching methods has greatly promoted the
development of robot imitation learning. However, these methods all face the
problem of high inference time. To address this issue, researchers have
proposed distillation methods and consistency methods, but the performance of
these methods still struggles to compete with that of the original diffusion
models and flow-matching models. In this article, we propose a one-step
shortcut method with multi-step integration for robot imitation learning. To
balance the inference speed and performance, we extend the multi-step
consistency loss on the basis of the shortcut model, split the one-step loss
into multi-step losses, and improve the performance of one-step inference.
Secondly, to solve the problem of unstable optimization of the multi-step loss
and the original flow-matching loss, we propose an adaptive gradient allocation
method to enhance the stability of the learning process. Finally, we evaluate
the proposed method in two simulation benchmarks and five real-world
environment tasks. The experimental results verify the effectiveness of the
proposed algorithm.

</details>


### [211] [ProTerrain: Probabilistic Physics-Informed Rough Terrain World Modeling](https://arxiv.org/abs/2510.19364)
*Golnaz Raja,Ruslan Agishev,Miloš Prágr,Joni Pajarinen,Karel Zimmermann,Arun Kumar Singh,Reza Ghabcheloo*

Main category: cs.RO

TL;DR: 该研究提出了一种考虑空间相关不确定性的机器人运动预测框架，用于越野导航。


<details>
  <summary>Details</summary>
Motivation: 越野导航中机器人运动预测至关重要，但现有方法忽略了地形不确定性的空间相关性，导致预测不可靠。

Method: 提出了一种概率框架，将空间相关的不确定性建模为概率世界模型，并通过可微物理引擎进行传播，利用卷积算子进行高分辨率预测。

Result: 在公开数据集上的实验表明，该方法显著提高了不确定性估计和轨迹预测的准确性。

Conclusion: 该框架能够有效处理越野导航中的不确定性问题，提高机器人运动预测的可靠性。

Abstract: Uncertainty-aware robot motion prediction is crucial for downstream
traversability estimation and safe autonomous navigation in unstructured,
off-road environments, where terrain is heterogeneous and perceptual
uncertainty is high. Most existing methods assume deterministic or spatially
independent terrain uncertainties, ignoring the inherent local correlations of
3D spatial data and often producing unreliable predictions. In this work, we
introduce an efficient probabilistic framework that explicitly models spatially
correlated aleatoric uncertainty over terrain parameters as a probabilistic
world model and propagates this uncertainty through a differentiable physics
engine for probabilistic trajectory forecasting. By leveraging structured
convolutional operators, our approach provides high-resolution multivariate
predictions at manageable computational cost. Experimental evaluation on a
publicly available dataset shows significantly improved uncertainty estimation
and trajectory prediction accuracy over aleatoric uncertainty estimation
baselines.

</details>


### [212] [Using Temperature Sampling to Effectively Train Robot Learning Policies on Imbalanced Datasets](https://arxiv.org/abs/2510.19373)
*Basavasagar Patil,Sydney Belt,Jayjun Lee,Nima Fazeli,Bernadette Bucher*

Main category: cs.RO

TL;DR: 机器人任务数据集因相似动作而存在不平衡问题，提出一种简单的采样策略来缓解此问题，并在预训练和微调中均取得良好效果，尤其是在低资源任务上。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人任务数据集因任务描述不同但物理动作序列相似（如“拾取苹果” vs “拾取橙子”），导致数据集中物理动作的表示不平衡，影响模型泛化能力。

Method: 提出一种简单的采样策略，用于策略训练以缓解数据集不平衡问题。

Result: 在预训练和微调实验中，该方法在低资源任务上相比现有技术有显著提升，同时不影响高资源任务的表现。在真实机器人（Franka Panda）上进行了验证。

Conclusion: 该采样策略能有效缓解机器人任务数据集中的不平衡问题，提升模型在低资源任务上的泛化能力，并有效利用模型容量进行多任务策略训练。

Abstract: Increasingly large datasets of robot actions and sensory observations are
being collected to train ever-larger neural networks. These datasets are
collected based on tasks and while these tasks may be distinct in their
descriptions, many involve very similar physical action sequences (e.g., 'pick
up an apple' versus 'pick up an orange'). As a result, many datasets of robotic
tasks are substantially imbalanced in terms of the physical robotic actions
they represent. In this work, we propose a simple sampling strategy for policy
training that mitigates this imbalance. Our method requires only a few lines of
code to integrate into existing codebases and improves generalization. We
evaluate our method in both pre-training small models and fine-tuning large
foundational models. Our results show substantial improvements on low-resource
tasks compared to prior state-of-the-art methods, without degrading performance
on high-resource tasks. This enables more effective use of model capacity for
multi-task policies. We also further validate our approach in a real-world
setup on a Franka Panda robot arm across a diverse set of tasks.

</details>


### [213] [GigaBrain-0: A World Model-Powered Vision-Language-Action Model](https://arxiv.org/abs/2510.19430)
*GigaBrain Team,Angen Ye,Boyuan Wang,Chaojun Ni,Guan Huang,Guosheng Zhao,Haoyun Li,Jie Li,Jiagang Zhu,Lv Feng,Peng Li,Qiuping Deng,Runqi Ouyang,Wenkang Qin,Xinze Chen,Xiaofeng Wang,Yang Wang,Yifan Li,Yilong Li,Yiran Ding,Yuan Xu,Yun Ye,Yukun Zhou,Zhehao Dong,Zhenan Wang,Zhichao Liu,Zheng Zhu*

Main category: cs.RO

TL;DR: GigaBrain-0是一个利用世界模型生成数据来训练的视觉-语言-动作（VLA）模型，大大减少了对真实机器人数据的依赖，提高了泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 真实世界机器人数据的收集成本高昂且耗时，限制了当前VLA系统的可扩展性和泛化能力。

Method: 利用世界模型（如视频生成、real2real迁移、人类迁移、视图迁移、sim2real迁移数据）生成海量多样化数据，并结合RGBD输入建模和具身思维链（CoT）监督来提高策略鲁棒性。

Result: GigaBrain-0在灵巧、长时序和移动操作任务的真实世界表现方面取得了显著的提升，并且在外观、物体摆放和摄像机视点变化方面表现出优越的泛化能力。此外，还提出了轻量级变体GigaBrain-0-Small。

Conclusion: 通过利用世界模型生成数据，GigaBrain-0成功克服了真实机器人数据收集的限制，并在各种挑战性任务中展现了强大的泛化能力和鲁棒性，为开发更通用的机器人奠定了基础。

Abstract: Training Vision-Language-Action (VLA) models for generalist robots typically
requires large-scale real-world robot data, which is expensive and
time-consuming to collect. The inefficiency of physical data collection
severely limits the scalability, and generalization capacity of current VLA
systems. To address this challenge, we introduce GigaBrain-0, a novel VLA
foundation model empowered by world model-generated data (e.g., video
generation, real2real transfer, human transfer, view transfer, sim2real
transfer data). By leveraging world models to generate diverse data at scale,
GigaBrain-0 significantly reduces reliance on real robot data while improving
cross-task generalization. Our approach further improves policy robustness
through RGBD input modeling and embodied Chain-of-Thought (CoT) supervision,
enabling the model to reason about spatial geometry, object states, and
long-horizon dependencies during task execution. This leads to substantial
gains in real-world performance on dexterous, long-horizon, and mobile
manipulation tasks. Extensive experiments demonstrate that GigaBrain-0 achieves
superior generalization across variations in appearances (e.g., textures,
colors), object placements, and camera viewpoints. Additionally, we present
GigaBrain-0-Small, an optimized lightweight variant designed to run efficiently
on devices such as the NVIDIA Jetson AGX Orin.

</details>


### [214] [Using Non-Expert Data to Robustify Imitation Learning via Offline Reinforcement Learning](https://arxiv.org/abs/2510.19495)
*Kevin Huang,Rosario Scalise,Cleah Winston,Ayush Agrawal,Yunchu Zhang,Rohan Baijal,Markus Grotz,Byron Boots,Benjamin Burchfiel,Hongkai Dai,Masha Itkina,Paarth Shah,Abhishek Gupta*

Main category: cs.RO

TL;DR: 该研究提出一种利用非专家数据增强模仿学习策略的方法，通过结合离线强化学习，解决了模仿学习对高质量数据过度依赖的问题，提高了机器人任务的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 模仿学习在机器人复杂任务训练中有效，但受限于高质量、特定任务数据的获取，难以适应现实世界多变的物体配置和场景。非专家数据（如玩耍数据、不完美演示、不完整任务或次优策略的输出）数据量大、成本低，但传统模仿学习方法无法有效利用。本研究旨在解决这一问题。

Method: 提出使用离线强化学习（Offline RL）来利用非专家数据，以增强模仿学习策略。研究发现，标准的离线强化学习方法在数据覆盖稀疏的现实世界设置下可能效果不佳，但通过简单的算法修改，可以在不增加额外假设的情况下有效利用这些数据。具体方法包括拓宽策略分布的支持域。

Result: 该方法显著提高了模仿学习策略在包含非专家数据时的鲁棒性和泛化能力。在机器人操作任务中，当纳入非专家数据时，学习到的策略在各种初始条件下都能更成功地完成任务。该方法能够有效利用包括不完整或次优演示在内的所有收集到的数据，以提升面向任务的策略性能。

Conclusion: 通过算法技术来利用非专家数据进行鲁棒的机器人策略学习至关重要。本研究的方法展示了在机器人领域，结合离线强化学习和模仿学习，利用非专家数据可以显著提升策略的学习效率和泛化能力，尤其是在应对现实世界复杂多变的场景时。

Abstract: Imitation learning has proven effective for training robots to perform
complex tasks from expert human demonstrations. However, it remains limited by
its reliance on high-quality, task-specific data, restricting adaptability to
the diverse range of real-world object configurations and scenarios. In
contrast, non-expert data -- such as play data, suboptimal demonstrations,
partial task completions, or rollouts from suboptimal policies -- can offer
broader coverage and lower collection costs. However, conventional imitation
learning approaches fail to utilize this data effectively. To address these
challenges, we posit that with right design decisions, offline reinforcement
learning can be used as a tool to harness non-expert data to enhance the
performance of imitation learning policies. We show that while standard offline
RL approaches can be ineffective at actually leveraging non-expert data under
the sparse data coverage settings typically encountered in the real world,
simple algorithmic modifications can allow for the utilization of this data,
without significant additional assumptions. Our approach shows that broadening
the support of the policy distribution can allow imitation algorithms augmented
by offline RL to solve tasks robustly, showing considerably enhanced recovery
and generalization behavior. In manipulation tasks, these innovations
significantly increase the range of initial conditions where learned policies
are successful when non-expert data is incorporated. Moreover, we show that
these methods are able to leverage all collected data, including partial or
suboptimal demonstrations, to bolster task-directed policy performance. This
underscores the importance of algorithmic techniques for using non-expert data
for robust policy learning in robotics.

</details>


### [215] [Optimizing Prosthetic Wrist Movement: A Model Predictive Control Approach](https://arxiv.org/abs/2510.19541)
*Francesco Schetter,Shifa Sulaiman,Shoby George,Paolino De Risi,Fanny Ficuciello*

Main category: cs.RO

TL;DR: 本研究提出了一种模型预测控制（MPC）策略，用于控制肌腱驱动的软体连续腕部假肢，实现了更强的适应性和性能，同时计算量较低。


<details>
  <summary>Details</summary>
Motivation: 为了提高假肢的适应性和性能，需要将先进的控制策略集成到假肢手中。

Method: 采用Euler-Bernoulli梁和Lagrange方法分别进行运动学和动力学建模，并实现模型预测控制（MPC）策略。

Result: 通过仿真和实验验证，MPC在优化腕部运动和用户控制方面被证明是有效的，显著提高了假肢的灵活性，使运动更自然直观。

Conclusion: MPC是一种有前景的智能假肢系统控制策略，能够精确调整运动并适应用户交互，为机器人和生物医学工程领域提供了新的研究方向。

Abstract: The integration of advanced control strategies into prosthetic hands is
essential to improve their adaptability and performance. In this study, we
present an implementation of a Model Predictive Control (MPC) strategy to
regulate the motions of a soft continuum wrist section attached to a
tendon-driven prosthetic hand with less computational effort. MPC plays a
crucial role in enhancing the functionality and responsiveness of prosthetic
hands. By leveraging predictive modeling, this approach enables precise
movement adjustments while accounting for dynamic user interactions. This
advanced control strategy allows for the anticipation of future movements and
adjustments based on the current state of the prosthetic device and the
intentions of the user. Kinematic and dynamic modelings are performed using
Euler-Bernoulli beam and Lagrange methods respectively. Through simulation and
experimental validations, we demonstrate the effectiveness of MPC in optimizing
wrist articulation and user control. Our findings suggest that this technique
significantly improves the prosthetic hand dexterity, making movements more
natural and intuitive. This research contributes to the field of robotics and
biomedical engineering by offering a promising direction for intelligent
prosthetic systems.

</details>


### [216] [LaViRA: Language-Vision-Robot Actions Translation for Zero-Shot Vision Language Navigation in Continuous Environments](https://arxiv.org/abs/2510.19655)
*Hongyu Ding,Ziming Xu,Yudong Fang,You Wu,Zixuan Chen,Jieqi Shi,Jing Huo,Yifan Zhang,Yang Gao*

Main category: cs.RO

TL;DR: LaViRA是一个创新的零样本框架，通过将导航分解为语言规划、视觉基础和机器人控制三个层次，有效解决了现有方法在零样本视觉-语言导航（VLN-CE）中的局限性，并在VLN-CE基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLN-CE方法在环境泛化和大型模型推理能力利用方面存在不足，要么依赖环境特定的路点预测器限制泛化，要么在导航过程中未能充分利用大型模型的推理能力。

Method: LaViRA框架将导航分解为三个层次：语言动作（高层规划）、视觉动作（感知基础）和机器人动作（鲁棒导航），并利用不同尺度的多模态大型语言模型（MLLMs）在每个阶段发挥各自优势。

Result: LaViRA在VLN-CE基准测试中显著优于现有最先进方法，展现了在未见环境中的卓越泛化能力，同时保持了透明度和效率，适合实际部署。

Conclusion: LaViRA通过其分层分解方法，成功地克服了现有VLN-CE方法的局限性，实现了强大的推理、基础和控制能力，并在实际应用中展现出优越的性能和泛化能力。

Abstract: Zero-shot Vision-and-Language Navigation in Continuous Environments (VLN-CE)
requires an agent to navigate unseen environments based on natural language
instructions without any prior training. Current methods face a critical
trade-off: either rely on environment-specific waypoint predictors that limit
scene generalization, or underutilize the reasoning capabilities of large
models during navigation. We introduce LaViRA, a simple yet effective zero-shot
framework that addresses this dilemma by decomposing action into a
coarse-to-fine hierarchy: Language Action for high-level planning, Vision
Action for perceptual grounding, and Robot Action for robust navigation. This
modular decomposition allows us to leverage the distinct strengths of different
scales of Multimodal Large Language Models (MLLMs) at each stage, creating a
system that is powerful in its reasoning, grounding and practical control.
LaViRA significantly outperforms existing state-of-the-art methods on the
VLN-CE benchmark, demonstrating superior generalization capabilities in unseen
environments, while maintaining transparency and efficiency for real-world
deployment.

</details>


### [217] [Fast Marker Detection for UV-Based Visual Relative Localisation in Agile UAV Swarms](https://arxiv.org/abs/2510.19663)
*Vojtěch Vrba,Viktor Walter,Petr Štěpán,Martin Saska*

Main category: cs.RO

TL;DR: 该论文提出了一种在无人机蜂群中用于视觉相对定位的快速板载孤立标记检测新方法。


<details>
  <summary>Details</summary>
Motivation: 为了实现无人机群体在实时定位系统中的视觉相对定位，检测孤立标记是关键组成部分。

Method: 提出了一种优化的CPU程序、GPU着色器程序和功能等效的FPGA流式处理架构。

Result: CPU和GPU解决方案将每像素平均处理时间比现有技术提高了两到三个数量级。FPGA架构在最小化从相机曝光到检测结果的总延迟方面提供了最显著的整体加速。

Conclusion: 所提出的解决方案在各种嵌入式平台上进行了评估，证明了其效率和可行性，特别是对于低端无人机和微型飞行器(MAV)的应用，使其成为敏捷无人机群的关键使能技术。

Abstract: A novel approach for the fast onboard detection of isolated markers for
visual relative localisation of multiple teammates in agile UAV swarms is
introduced in this paper. As the detection forms a key component of real-time
localisation systems, a three-fold innovation is presented, consisting of an
optimised procedure for CPUs, a GPU shader program, and a functionally
equivalent FPGA streaming architecture. For the proposed CPU and GPU solutions,
the mean processing time per pixel of input camera frames was accelerated by
two to three orders of magnitude compared to the state of the art. For the
localisation task, the proposed FPGA architecture offered the most significant
overall acceleration by minimising the total delay from camera exposure to
detection results. Additionally, the proposed solutions were evaluated on
various 32-bit and 64-bit embedded platforms to demonstrate their efficiency,
as well as their feasibility for applications using low-end UAVs and MAVs.
Thus, it has become a crucial enabling technology for agile UAV swarming.

</details>


### [218] [Learning Affordances at Inference-Time for Vision-Language-Action Models](https://arxiv.org/abs/2510.19752)
*Ameesh Shah,William Chen,Adwait Godbole,Federico Mora,Sanjit A. Seshia,Sergey Levine*

Main category: cs.RO

TL;DR: LITEN通过结合高层视觉-语言模型（VLM）和低层视觉-语言-动作模型（VLA），实现了机器人控制任务的自适应和改进。


<details>
  <summary>Details</summary>
Motivation: 当前机器人领域的视觉-语言-动作模型（VLA）在面对复杂控制任务时，缺乏在失败后进行上下文和动态调整行为的能力。

Method: 提出了一种名为LITEN的方法，该方法将低层VLA策略与高层VLM连接起来。高层VLM通过将过去的经验（包括失败的执行轨迹）纳入其上下文，来学习低层VLA的能力和优势。该方法包含一个推理阶段（生成和执行VLA的计划）和一个评估阶段（反思执行结果并为未来的推理提供上下文）。LITEN在评估阶段需要对非结构化的真实机器人轨迹进行反思，并引入了结构化引导机制。

Result: 实验结果表明，LITEN能够有效地从过去的经验中学习，生成能够利用高可供性指令来完成长时序任务的计划。

Conclusion: LITEN模型通过迭代的推理和评估过程，实现了机器人从失败中学习并优化其控制策略的能力，尤其擅长处理需要长时序规划的任务。

Abstract: Solving complex real-world control tasks often takes multiple tries: if we
fail at first, we reflect on what went wrong, and change our strategy
accordingly to avoid making the same mistake. In robotics,
Vision-Language-Action models (VLAs) offer a promising path towards solving
complex control tasks, but lack the ability to contextually and dynamically
readjust behavior when they fail to accomplish a task. In this work, we
introduce Learning from Inference-Time Execution (LITEN), which connects a VLA
low-level policy to a high-level VLM that conditions on past experiences by
including them in-context, allowing it to learn the affordances and
capabilities of the low-level VLA. Our approach iterates between a reasoning
phase that generates and executes plans for the low-level VLA, and an
assessment phase that reflects on the resulting execution and draws useful
conclusions to be included in future reasoning contexts. Unlike similar
approaches to self-refinement in non-robotics domains, LITEN must reflect on
unstructured real-world robot trajectories (e.g., raw videos), which requires
structured guiderails during assessment. Our experimental results demonstrate
LITEN is able to effectively learn from past experience to generate plans that
use high-affordance instructions to accomplish long-horizon tasks.

</details>


### [219] [SEA: Semantic Map Prediction for Active Exploration of Uncertain Areas](https://arxiv.org/abs/2510.19766)
*Hongyu Ding,Xinyue Liang,Yudong Fang,You Wu,Jieqi Shi,Jing Huo,Wenbin Li,Jing Wu,Yu-Kun Lai,Yang Gao*

Main category: cs.RO

TL;DR: SEA通过语义地图预测和基于强化学习的分层探索策略，提出了一种新颖的主动机器人探索方法，能够更有效地进行探索。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于单步航点预测，而我们的方法增强了代理的长期环境理解能力，以促进更有效的探索。

Method: 提出了一种迭代预测-探索框架，该框架基于当前观测来显式预测地图的缺失区域。实际累积地图与预测的全局地图之间的差异用于指导探索。此外，设计了一种新颖的奖励机制，利用强化学习来更新长期探索策略，从而在有限的步骤内构建准确的语义地图。

Result: 实验结果表明，我们的方法显著优于最先进的探索策略，在相同的时间限制内实现了对全局地图的更高覆盖率。

Conclusion: SEA通过语义地图预测和强化学习的分层探索策略，能够显著优于现有方法，在有限时间内实现更高覆盖率。

Abstract: In this paper, we propose SEA, a novel approach for active robot exploration
through semantic map prediction and a reinforcement learning-based hierarchical
exploration policy. Unlike existing learning-based methods that rely on
one-step waypoint prediction, our approach enhances the agent's long-term
environmental understanding to facilitate more efficient exploration. We
propose an iterative prediction-exploration framework that explicitly predicts
the missing areas of the map based on current observations. The difference
between the actual accumulated map and the predicted global map is then used to
guide exploration. Additionally, we design a novel reward mechanism that
leverages reinforcement learning to update the long-term exploration
strategies, enabling us to construct an accurate semantic map within limited
steps. Experimental results demonstrate that our method significantly
outperforms state-of-the-art exploration strategies, achieving superior
coverage ares of the global map within the same time constraints.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [220] [Magnon scattering and transduction in Coulomb-coupled quantum Hall ferromagnets](https://arxiv.org/abs/2510.18974)
*Alexander Canright,Deepak Iyer,Matthew S. Foster*

Main category: cond-mat.mes-hall

TL;DR: 量子霍尔铁磁体(QHFM)的磁场可产生多种自旋纹理，如斯格明子和磁振子。当投影到最低朗道能级且填充数为1时，磁场拓扑（庞特里亚金）电荷密度与电荷密度成正比，从而实现长程自旋-自旋相互作用。受近期实验发展的启发，该研究在理论上证明了由于QHFM特有的库仑相互作用，可以发生两种现象：磁振子可以散射点电荷，斯格明子可以作为传输介质和接收器，在双层QHFM的不同层之间转换磁振子。后者库仑介导的自旋拖曳效应发生在任意距离，可能促进长程磁振子学的发展，例如在二维材料中为未来的实验探测自旋波。


<details>
  <summary>Details</summary>
Motivation: 受近期实验发展的启发，该研究旨在理论上证明由于QHFM特有的库仑相互作用，磁振子可以散射点电荷，斯格明子可以作为传输介质和接收器，在双层QHFM的不同层之间转换磁振子。

Method: 理论推导

Result: 1. 磁振子可以散射点电荷； 2. 斯格明子可以作为传输介质和接收器，在双层QHFM的不同层之间转换磁振子。库仑介导的自旋拖曳效应发生在任意距离。

Conclusion: 库仑介导的自旋拖曳效应发生在任意距离，可能促进长程磁振子学的发展，例如在二维材料中为未来的实验探测自旋波。

Abstract: The magnetization field of a quantum Hall ferromagnet (QHFM) can host a
variety of spin textures, including skyrmions and magnons. When projected into
the lowest Landau level with $\nu = 1$ filling, the topological (Pontryagin)
charge density of the magnetization field is proportional to the electric
charge density, allowing for long-range spin-spin interactions. Inspired by
recent experimental developments that enable all-electrical magnon generation
and detection, in this work we theoretically demonstrate two phenomena that can
occur due to Coulomb interactions that are unique to QHFMs: magnons can scatter
off of point charges at a distance, and skyrmions can act as transmitters and
receivers for magnons to be transduced between separate layers of a bilayer
QHFM. The latter Coulomb-mediated spin drag effect occurs at arbitrary distance
and could facilitate long-range magnonics, such as detection of spin waves for
future experiments in 2D materials.

</details>


### [221] [iDART: Interferometric Dual-AC Resonance Tracking nano-electromechanical mapping](https://arxiv.org/abs/2510.19063)
*J. Bemis,F. Wunderwald,U. Schroeder,X. Xu,A. Gruverman,R. Proksch*

Main category: cond-mat.mes-hall

TL;DR: iDART通过结合干涉测量和共振放大技术，显著提高了压电力显微镜(PFM)的灵敏度和信噪比，能够对铁电材料进行超高分辨率成像。


<details>
  <summary>Details</summary>
Motivation: 传统PFM依赖高电压以克服检测噪声，易产生静电串扰、焦耳热和电压尖端诱导开关等伪影。需要一种高灵敏度且避免伪影的PFM技术。

Method: 提出iDART（干涉测量检测、共振增强双交流共振跟踪）技术，结合了正交相位差干涉仪的飞米级位移灵敏度和接触共振放大技术。

Result: iDART相比现有PFM技术（包括单频干涉PFM或采用光学光束检测的共振增强PFM）实现了10倍或更高的信噪比提升。在PZT和Y-HfO材料上实现了超过10倍的成像灵敏度提升。开关光谱学显示出类似的改进，能够在小电压下可靠地显示迟滞回线，减少了在高激励幅度下可能出现的非线性和器件故障。

Conclusion: iDART技术是一种强大的方法，可以对常规铁电体进行超高信噪比探测，甚至可以探测弱压电系统，将功能成像能力扩展到薄膜、二维铁电材料、超越CMOS技术和生物材料领域。

Abstract: Piezoresponse force microscopy (PFM) has established itself as a very
successful and reliable imaging and spectroscopic tool for measuring a wide
variety of nanoscale electromechanical functionalities. Quantitative imaging of
nanoscale electromechanical phenomena requires high sensitivity while avoiding
artifacts induced by large drive biases. Conventional PFM often relies on high
voltages to overcome optical detection noise, leading to various non-ideal
effects including electrostatic crosstalk, Joule heating, and tip-induced
switching. To mitigate this situation, we introduce interferometrically
detected, resonance-enhanced dual AC resonance tracking (iDART), which combines
femtometer-scale displacement sensitivity of quadrature phase differential
interferometry with contact resonance amplification. Through this combination,
iDART achieves 10x or greater signal-to-noise improvement over current state of
the art PFM approaches including both single frequency interferometric PFM or
conventional, resonance enhanced PFM using optical beam detection. In this
work, we demonstrate a >10x improvement of imaging sensitivity on PZT and
Y-HfO. Switching spectroscopy shows similar improvements, where further
demonstrates reliable hysteresis loops at small biases, mitigating
nonlinearities and device failures that can occur at higher excitation
amplitudes. These results position iDART as a powerful approach for probing
conventional ferroelectrics with extremely high signal to noise down to weak
piezoelectric systems, extending functional imaging capabilities to thin films,
2D ferroelectrics, beyond-CMOS technologies and bio-materials.

</details>


### [222] [Sliding Disassembly of van der Waals Heterostructures](https://arxiv.org/abs/2510.19064)
*Jordan Pack,Karl V. Falb,Sanat Ghosh,Xuehao Wu,Keng Tou Chu,Florie Mesple,Ellis Thompson,Zhuquan Zhang,Carolin Gold,Kenji Watanabe,Takashi Taniguchi,Dmitri N. Basov,A. N. Pasupathy,Matthew Yankowitz,Cory R. Dean,Aravind Devarakonda*

Main category: cond-mat.mes-hall

TL;DR: vdW异质结构可以通过微结构聚合物进行动态重构，从而改变石墨烯的介电环境，对半导体和空气敏感的单层进行扫描隧道显微镜检查，以及操纵应变敏感的莫尔材料。


<details>
  <summary>Details</summary>
Motivation: 利用vdW异质结的动态可配置性，以一种比传统薄膜生长技术更具挑战性的方式，构建极其清洁的异质结。

Method: 使用微结构聚合物印模动态地拆卸和重新配置vdW异质结，通过滑动进行。

Result: 成功地改变了单层石墨烯的介电环境，对半导体和空气敏感的单层进行了扫描隧道显微镜检查，并操纵了应变敏感的莫尔材料。

Conclusion: vdW异质结的动态重构为研究2D电子系统开辟了新的途径。

Abstract: Many recent advances in our understanding of two-dimensional (2D) electron
systems stem from van der Waals (vdW) heterostructures. The assembly process
relies on the weak bonding across interfaces between layered vdW compounds,
making it possible to construct exceptionally clean heterostructures from
chemically and structurally distinct materials - a challenging task for
traditional thin-film growth techniques. Here we demonstrate an additional,
dynamic degree of freedom afforded by vdW interfaces, wherein we use
microstructured polymer stamps to disassemble and reconfigure vdW
heterostructures by sliding. We apply this technique to alter the dielectric
environment of monolayer graphene, perform scanning tunneling microscopy on
semiconducting and air-sensitive monolayers, and manipulate strain-sensitive
moir\'e materials. Together these demonstrations suggest a new paradigm for
assembling and dynamically modifying van der Waals heterostructures, with the
potential to reveal new insights into 2D electron systems.

</details>


### [223] [Control of out-of-plane anti-damping spin torque with a canted ferromagnetic spin source](https://arxiv.org/abs/2510.19142)
*Xiaoxi Huang,Daniel A. Pharis,Hang Zhou,Zishen Tian,Thow Min Jerald Cham,Kyoungjun Lee,Yilin Evan Li,Chaoyang Wang,Yuhan Liang,Maciej Olszewski,Di Yi,Chang-Beom Eom,Darrell G. Schlom,Lane W. Martin,Ding-Fu Shao,Daniel C. Ralph*

Main category: cond-mat.mes-hall

TL;DR: SrRuO3薄膜可在零磁场下实现反阻尼切换，并提供非零的垂直反阻尼力矩，该力矩可由磁矩取向调谐，且同时包含自旋异常霍尔效应和平面霍尔效应的贡献。


<details>
  <summary>Details</summary>
Motivation: 为了在纳米磁性存储器中实现高效的反阻尼切换，需要利用具有强垂直分量的反阻尼自旋-轨道力矩。

Method: 验证了SrRuO3铁磁层的倾斜构型，并表征了其产生的力矩的所有矢量分量，包括非零的垂直反阻尼力矩。

Result: 证实了垂直自旋分量可以通过磁矩取向进行调谐，并且自旋异常霍尔效应和平面霍尔效应的自旋流都做出了显著贡献。

Conclusion: SrRuO3薄膜可用于实现高效的反阻尼切换，其产生的反阻尼力矩具有非零的垂直分量，并受到磁矩取向的影响。

Abstract: To achieve efficient anti-damping switching of nanoscale magnetic memories
with perpendicular magnetic anisotropy using spin-orbit torque requires that
the anti-damping spin-orbit torque have a strong out-of-plane component. The
spin anomalous Hall effect and the planar Hall effect spin current produced by
a ferromagnetic layer are candidate mechanisms for producing such an
out-of-plane anti-damping torque, but both require that the magnetic moment of
the spin source layer be canted partly out of the sample plane at zero applied
magnetic field. Here we demonstrate such a canted configuration for a
ferromagnetic SrRuO3 layer and we characterize all vector components of the
torque that it produces, including non-zero out-of-plane anti-damping torques.
We verify that the out-of-plane spin component can be tuned by the orientation
of magnetic moment, with significant contributions from both the spin anomalous
Hall effect and the planar Hall effect spin current.

</details>


### [224] [Mapping the twist angle dependence of quasi-Brillouin zones in doubly aligned graphene/BN heterostructures](https://arxiv.org/abs/2510.19369)
*Jorge Vallejo Bustamante,Viet-Hung Nguyen,Liam S. Farrar,Kenji Watanabe,Takashi Taniguchi,Dominique Mailly,Jean-Christophe Charlier,Rebeca Ribeiro-Palau*

Main category: cond-mat.mes-hall

TL;DR: 双层氮化硼夹石墨烯形成双莫尔超晶格，其相对对齐角度决定了周期性、准周期性或非周期性。


<details>
  <summary>Details</summary>
Motivation: 研究双层氮化硼夹石墨烯的双莫尔结构，特别是其相对对齐角度对电子结构的影响。

Method: 使用可动态旋转的范德华异质结构，原位控制顶层氮化硼的对齐角度，同时固定底层氮化硼，并测量电荷传输。

Result: 观察到原始莫尔纹、超莫尔纹以及准布里渊区（qBZ）的特征，其中qBZ的形成与莫尔纹干涉和角度对齐有关。

Conclusion: 首次通过实验描绘了准布里渊区随角度对齐的变化，建立了莫尔纹干涉与qBZ形成的直接联系，为设计多对齐二维异质结构中的电子结构提供了新途径。

Abstract: When monolayer graphene is crystallographically aligned to hexagonal boron
nitride (BN), a moir\'e superlattice is formed, producing characteristic
satellite Dirac peaks in the electronic band structure. Aligning a second BN
layer to graphene creates two coexisting moir\'e patterns, which can interfere
to produce periodic, quasi-periodic or non-periodic superlattices, depending on
their relative alignment. Here, we investigate one of the simplest realizations
of such a double-moir\'e structure, graphene encapsulated between two BN
layers, using dynamically rotatable van der Waals heterostructures. Our setup
allows \textit{in situ} control of the top BN alignment while keeping the
bottom BN fixed. By systematically mapping the charge transport as a function
of BN angular alignment, we identify the simultaneous signatures of the
original moir\'es, super-moir\'es, and a third set of features corresponding to
quasi-Brillouin zones (qBZ) formed when the system's periodicity becomes
ill-defined. Comparing our measurements with theoretical models, we provide the
first experimental mapping of the qBZs as a function of angular alignment. Our
results establish a direct experimental link between moir\'e interference and
qBZ formation, opening new avenues for engineering electronic structures in
multi-aligned 2D heterostructures.

</details>


### [225] [Relation between structure and functionality in photosynthetic antenna complex of green sulfur bacteria: efficiency under natural sunlight pumping](https://arxiv.org/abs/2510.19453)
*Alessia Valzelli,Francesco Mattiotti,ianshu Cao,G. Luca Celardo*

Main category: cond-mat.mes-hall

TL;DR: 对绿硫细菌（GSB）的光合天线复合物进行了大规模模拟，研究了激子能量从吸收光到反应中心（RC）的传递过程，并考虑了热浴的影响。


<details>
  <summary>Details</summary>
Motivation: 研究GSB光合天线复合物中激子能量转移的整个过程，分析其结构与功能的关系，并为设计高效的光收集装置提供指导。

Method: 使用非厄米哈密顿量对辐射进行建模，并求解反应速率方程来分析能量转移。同时，考虑了圆柱形天线结构和二聚体基板，并模拟了不同偶极子取向下的光收集效率。

Result: 在自然阳光下，GSB天线复合物中到达RC的激发数量与RC的封闭速率相匹配，内部效率接近80%。在改变偶极子取向（包括平行于圆柱轴和随机取向）的情况下，光收集效率均低于自然结构，表明其对偶极子取向的敏感性。

Conclusion: GSB光合天线复合物的光收集效率对偶极子取向高度敏感，自然结构具有较高的效率。这项研究有助于理解光合天线复合物的结构-功能关系，并为设计高效的光收集装置提供参考。

Abstract: Large-scale simulations of light-matter interaction in natural photosynthetic
antenna complexes of the Chlorobium Tepidum green sulfur bacteria (GSB)
containing more than one hundred thousand chlorophyll molecules, comparable
with natural size, have been performed. Here we have modeled the entire process
of the exciton energy transfer, from sunlight absorption to exciton trapping in
the reaction centers (RCs) in presence of a thermal bath. The energy transfer
has been analyzed using the radiative non-Hermitian Hamiltonian and solving the
rate equations for the populations. Sunlight pumping has been modeled as
black-body radiation with an attenuation factor that takes the Sun-Earth
distance into account. Cylindrical structures typical of GSB antenna complexes,
and the dimeric baseplate comparable to natural size have been considered. Our
analysis shows that under natural sunlight, in photosynthetic antennae of GSB
the number of excitations reaching the RC per unit time matches the RC closure
rate and the internal efficiency shows values close to $\sim 80\%$. We also
considered cylindrical structures where the orientation of the dipoles does not
reflect the natural one. Specifically, we vary continuously the angle of the
transition dipole with respect to the cylinder main axis, focusing on the case
where all dipoles are parallel to the cylinder axis. We also consider the
important case where the dipoles are randomly oriented. In all cases the
light-harvesting efficiency is lower than in the natural structure, showing the
high sensitivity of light harvesting to the specific orientation of the dipole
moments. Our results allow for a better understanding of the relationship
between structure and functionality in photosynthetic antennae of GSB and could
drive the design of efficient light-harvesting devices.

</details>


### [226] [Thermal Hall conductivity of semi-metallic graphite dominated by ambipolar phonon drag](https://arxiv.org/abs/2510.19570)
*Qiaochao Xiang,Xiaokang Li,Xiaodong Guo,Zengwei Zhu,Kamran Behnia*

Main category: cond-mat.mes-hall

TL;DR: 石墨中的热霍尔效应主要由双极声子拖曳引起，其热霍尔电导率远超纯电子贡献，并创下新的霍尔洛伦兹数记录。


<details>
  <summary>Details</summary>
Motivation: 研究石墨中除了电子外，声子、磁振子等准粒子产生热霍尔信号的现象，并探究其在高度取向热解石墨（HOPG）中的具体表现。

Method: 测量HOPG样品的热霍尔电导率，并分析其与电子、声子以及声子拖曳的贡献关系，比较其与纵向热导率、电霍尔电导率以及维德曼-齐定律的差异，同时研究塞贝克效应和能斯特效应的温梯关系。

Result: 测得的热霍尔电导率比电子载流子根据维德曼-齐定律的预期值高两个数量级，霍尔洛伦兹数创下新高，达到~67L0。热霍尔电导率的温度依赖性与纵向对应物显著不同，排除了纯声子起源的可能性。

Conclusion: 双极声子拖曳是石墨热霍尔响应的主要来源。

Abstract: It is now known that in addition to electrons, other quasi-particles such as
phonons and magnons can also generate a thermal Hall signal. Graphite is a
semimetal with extremely mobile charge carriers of both signs and a large
lattice thermal conductivity. We present a study of the thermal Hall effect in
highly oriented pyrolytic graphite (HOPG) samples with electronic, phononic and
phonon drag contributions to the thermal Hall signal. The measured thermal Hall
conductivity ($\kappa_{xy}$) is two orders of magnitude higher than what is
expected by electronic carriers according to the electrical Hall conductivity
and the Wiedemann-Franz law, yielding a record Hall Lorenz number of
$164.9\times10^{-8}V^2 K^{-2}$ ($\sim$67$L_0$) - the largest ever observed in a
metal. The temperature dependence of the thermal Hall conductivity
significantly differs from its longitudinal counterpart, ruling out a purely
phononic origin of the non-electronic component. Based on the temperature
dependence and the amplitudes of the Seebeck and Nernst responses, we
demonstrate that ambipolar phonon drag dominates the thermal Hall response of
graphite.

</details>


### [227] [Universal non-Hermitian valley filtering via uniform dissipation](https://arxiv.org/abs/2510.19588)
*Sijie Yue,Wentao Xie,Kai Shao,Hong-yu Zou,Bingbing Wang,Hong-xiang Sun,Y. X. Zhao,Wei Chen,Haoran Xue*

Main category: cond-mat.mes-hall

TL;DR: 利用均匀背景耗散实现可切换和鲁棒的谷极化声学


<details>
  <summary>Details</summary>
Motivation: 实现谷极化态是谷基器件运行的前提，但仍具挑战性。

Method: 提出并实验验证了一种利用均匀背景耗散实现的通用非厄米机制，通过群速度差异实现谷滤波。

Result: 在声学晶体中观察到可切换和鲁棒的谷极化声，并为光子和电子平台提供了设计。

Conclusion: 该方法提供了一种简单有效的谷极化态生成解决方案，有望推动经典和量子领域新型谷基器件的发展。

Abstract: Valley, as a ubiquitous degree of freedom in lattices, has found wide
applications in both electronic and classical-wave devices in recent years.
However, achieving valley-polarized states, a prerequisite for valley-based
operations, still remains challenging. Here, we propose and experimentally
demonstrate a universal non-Hermitian mechanism for valley filtering using only
uniform background dissipation, which creates a propagation length contrast
between valleys through their intrinsic group velocity differences. We
implement this concept in an acoustic crystal, observing switchable and robust
valley polarization of sound through large-scale field mapping. Remarkably, our
approach is solely based on uniform loss, without the need for any special
lattice structures, tailored excitations, or external fields. We further
provide designs of our non-Hermitian valley filter on photonic and electronic
platforms. Our results offer a simple and effective solution to
valley-polarized state generation and may advance the development of novel
valley-based devices in both classical and quantum regimes.

</details>


### [228] [Direct visualization of gate-tunable flat bands in twisted double bilayer graphene](https://arxiv.org/abs/2510.19632)
*Souvik Sasmal,Ryan Muzzio,Ahmed Khalifa,Paulina Majchrzak,Alfred J. H. Jones,I-Hsuan Kao,Kenji Watanabe,Takashi Taniguchi,Simranjeet Singh,Eli Rotenberg,Aaron Bostwick,Chris Jozwiak,Søren Ulstrup,Shubhayu Chatterjee,Jyoti Katoch*

Main category: cond-mat.mes-hall

TL;DR: 扭曲双层石墨烯(TDBG)中的对称性破缺关联态可以通过扭转角、位移场和载流子密度等外部因素进行调节，但直接动量解析地表征这些参数如何重塑平带结构仍然有限。本研究使用微聚焦角分辨光电子能谱技术，在1.6的扭转角下研究TDBG的平带色散，并通过静电门控系统地改变位移场和载流子密度，直接观测到电荷中性点附近的多个平坦莫尔条带，包括一个位于低能平带流形之下的平坦远程价带。此外，占优的库仑排斥能超过平带带宽，这表明TDBG中相互作用驱动的关联现象出现的有利条件。这些发现证实了TDBG中平带的形成和演化源于电子填充与位移场之间的相互作用。


<details>
  <summary>Details</summary>
Motivation: 虽然TDBG中的对称性破缺关联态可以通过扭转角、位移场和载流子密度等外部因素进行调节，但直接动量解析地表征这些参数如何重塑平带结构仍然有限。

Method: 使用微聚焦角分辨光电子能谱技术，在1.6的扭转角下研究TDBG的平带色散，并通过静电门控系统地改变位移场和载流子密度。

Result: 直接观测到电荷中性点附近的多个平坦莫尔条带，包括一个位于低能平带流形之下的平坦远程价带。占优的库仑排斥能超过平带带宽，表明TDBG中相互作用驱动的关联现象出现的有利条件。

Conclusion: TDBG中平带的形成和演化源于电子填充与位移场之间的相互作用。

Abstract: The symmetry-broken correlated states in twisted double bilayer graphene
(TDBG) can be tuned via several external knobs, including twist angle,
displacement field, and carrier density. However, a direct, momentum-resolved
characterization of how these parameters reshape the flat-band structure
remains limited. In this study, we employ micro focused angle-resolved
photoemission spectroscopy to investigate the flat-band dispersion of TDBG at a
twist angle of 1.6, systematically varying the displacement field and carrier
density via electrostatic gating. We directly observe multiple flat moir'e
minibands near charge neutrality, including a flat remote valence band residing
below the low-energy flat-band manifold. Furthermore, the dominant Coulomb
repulsive energy over the flat- band bandwidth suggests favorable conditions
for the emergence of interaction-driven correlated phenomena in TDBG. These
findings establish that the formation and evolution of flat bands in TDBG
arises from the interplay between the electron filling and the displacement
field.

</details>


### [229] [Single-Scale Magnetoelastic Landau Quantization: Thermodynamics, Quantum Oscillations, and Metrology](https://arxiv.org/abs/2510.19637)
*Denise Assafrão,Faizuddin Ahmed,Edilberto O. Silva*

Main category: cond-mat.mes-hall

TL;DR: 本文提出了一种统一的理论框架，用于描述在均匀磁场和螺位错作用下电子系统的热力学和量子振荡行为。该框架的核心是一个单一同相干可调谐间隙 $\hbar|\omega_{eff}|$，它能够统一解释所有平衡可观测量的行为，并将这些量归一化为基于 $x=\hbar|\omega_{eff}|/(2k_{B}T)$ 的通用双曲线函数。研究还识别了一个特殊的“补偿场”区域，在该区域中横向间隙消失，热容量达到均分平台，这为磁弹性干涉提供了明确的信号。此外，该理论框架能够解释在输运和扭矩测量中霍尔效应的扇形图以及 de Haas-van Alphen 和 Shubnikov-de Haas 振荡的 $1/B$ 周期，并提出了一种相位解卷协议，可以通过单次磁场扫描精确测量螺位错密度。在介观尺度上，朗道简并的边界修正产生了有限尺寸的热量振荡，可用于诊断有效磁长度。适度的无序和弱相互作用不会破坏理论的核心结构，只会使振幅变得平滑。最后，文章提出了一个结合了片上热量测量、扭矩测量和输运测量的实验路线图，并探讨了在热电器件、应变工程、磁热微制冷、磁弹性热开关和膨胀转换器等领域利用该理论框架进行合理设计和优化的机遇。


<details>
  <summary>Details</summary>
Motivation: 电子系统在磁场和位错存在下的热力学和量子振荡行为表现复杂，缺乏统一的理论描述。本研究旨在提供一个单一的、普适的理论框架，以理解和预测这些现象，并为实验测量和器件设计提供指导。

Method: 提出一个包含有效回旋频率 $\omega_{eff}=\omega_{c}+\omega_{cl}$ 的单一同相干可调谐间隙 $\hbar|\omega_{eff}|$。基于此间隙，利用紧凑的谐振子配分函数来推导自由能、内能、熵、热容、磁化强度、磁化率和磁热响应等一系列平衡可观测量，并将它们归一化为基于 $x=\hbar|\omega_{eff}|/(2k_{B}T)$ 的通用双曲线函数。分析了横向间隙闭合时的补偿场区域，并研究了该间隙对霍尔效应、de Haas-van Alphen 和 Shubnikov-de Haas 振荡的影响。考虑了朗道简并的边界修正对有限尺寸样品热量振荡的影响。

Result: 在磁场和螺位错作用下，电子系统的多种热力学和量子振荡性质（如自由能、热容、磁化强度等）可以通过单一的、与有效回旋频率 $\hbar|\omega_{eff}|$ 相关的通用双曲线函数来统一描述。发现了补偿场区域，其热容量表现出均分平台。理论预测了 $\hbar|\omega_{eff}|$ 能够统一解释霍尔扇形图的移动以及 de Haas-van Alphen 和 Shubnikov-de Haas 振荡的 $1/B$ 周期的压缩。提出了通过单次磁场扫描测量位错密度的相位解卷协议。有限尺寸样品中的热量振荡可用于诊断有效磁长度。

Conclusion: 本文提出的基于单一可调谐间隙 $\hbar|\omega_{eff}|$ 的理论框架成功地统一了电子系统在磁场和螺位错存在下的热力学和量子振荡行为。该框架不仅能够精确描述现有实验现象，还为精确测量材料参数（如位错密度）和设计新型功能器件（如用于制冷、热开关和传感器件）提供了理论基础和实验指导。

Abstract: We develop a unified, single-scale description of thermodynamics and quantum
oscillations in electronic systems with a uniform areal density of screw
dislocations under a uniform magnetic field. A single tunable gap,
$\hbar|\omega_{eff}|$ with $\omega_{eff}=\omega_{c}+\omega_{cl}$, organizes all
equilibrium observables obtained from a compact harmonic-oscillator partition
function: free energy, internal energy, entropy, heat capacity, magnetization,
magnetic susceptibility, and magnetocaloric responses collapse onto universal
hyperbolic kernels in $x=\hbar|\omega_{eff}|/(2k_{B}T)$. We identify a
compensated-field regime where the transverse gap closes and the heat capacity
reaches an equipartition plateau, providing a sharp signature of magnetoelastic
interference. In transport and torque, the same scale rigidly shifts the Hall
fan and compresses the $1/B$ period of de Haas-van Alphen and Shubnikov-de Haas
oscillations when expressed in $1/B_{eff}$, enabling a phase-unwarping protocol
that metrologizes the dislocation density from a single field sweep. In
mesoscopic samples, boundary corrections to the Landau degeneracy generate
finite-size calorimetric oscillations that diagnose the effective magnetic
length. Moderate disorder and weak interactions preserve the kernel structure
while smoothing amplitudes. We outline an experimental roadmap combining
on-chip calorimetry, torque magnetometry, and transport, and discuss
device-level opportunities in caloritronics and strain engineering,
magnetocaloric microcooling, magnetoelastic heat switching, and dilatometric
transduction, where the single scale $\hbar|\omega_{eff}|$ enables rational
design and optimization.

</details>


### [230] [Adaptive Ising machine based on phase-locking of an auto-oscillator to a bi-harmonic external driving with noise](https://arxiv.org/abs/2510.19648)
*Eleonora Raimondo,Andrea Grimaldi,Vasyl Tyberkevych,Riccardo Tomasello,Anna Giordano,Mario Carpentieri,Andrei Slavin,Massimo Chiappini,Giovanni Finocchio*

Main category: cond-mat.mes-hall

TL;DR: 本研究提出了一种通用理论，用于分析双谐波信号驱动并带有噪声的相位自振荡器，并以自旋扭矩纳米振荡器为例进行了数值验证。该理论实现了确定性相位锁定和随机相位滑动的连续调谐，并引入了自适应伊辛机（AIM）的概念，这是一种能够动态结合确定性和概率性计算的统一振荡器架构。AIM在组合优化问题上的表现与现有方法互补且具有适应性，是首个能够在确定性与概率性计算之间转换的OIM，为可扩展的CMOS兼容硬件开辟了道路。


<details>
  <summary>Details</summary>
Motivation: 需要一个统一的理论来描述双谐波信号驱动的相位自振荡器及其与确定性相位锁定和随机相位滑动的关系，并探索其在计算优化中的应用。

Method: 提出了一种通用理论，分析了双谐波信号驱动并带有噪声的相位自振荡器。以自旋扭矩纳米振荡器为例，通过数值模拟验证了该理论，并实现了确定性、概率性和混合模式操作。引入了自适应伊辛机（AIM）架构。

Result: AIM架构能够动态地在确定性和概率性计算之间切换，并在组合优化问题上表现出与现有方法互补且具适应性的性能。

Conclusion: 本研究提出了首个能够在确定性与概率性计算之间转换的OIM，展示了AIM架构在解决优化问题上的潜力，并为开发可扩展、CMOS兼容的混合优化和推理硬件开辟了新途径。

Abstract: We introduce a universal theory of phase auto-oscillators driven by a bi
harmonic signal (having frequency components close to single and double of the
free-running oscillator frequency) with noise. With it, we show how
deterministic phase locking and stochastic phase slips can be continuously
tuned by varying the relative amplitudes and frequencies of the driving
components. Using, as an example, a spin-torque nano-oscillator, we numerically
validate this theory by implementing a deterministic Ising machine paradigm, a
probabilistic one, and dual-mode operation of the two. This demonstration
introduces the concept of adaptive Ising machines (AIM), a unified
oscillator-based architecture that dynamically combines both regimes within the
same hardware platform by properly tuning the amplitudes of the bi-harmonic
driving relative to the noise strength. Benchmarking on different classes of
combinatorial optimization problems, the AIM exhibits complementary performance
compared to oscillator based Ising machines and probabilistic Ising machines,
with adaptability to the specific problem class. This work introduces the first
OIM capable of transitioning between deterministic and probabilistic
computation taking advantage of a proper design of the trade-off between the
strength of phase-locking of an auto-oscillator to a bi harmonic external
driving and noise, opening a path toward scalable, CMOS compatible hardware for
hybrid optimization and inference.

</details>


### [231] [Spin-Locked Helical Currents and Pure Spin Pumping in Altermagnetic Nanotubes](https://arxiv.org/abs/2510.19700)
*Xin Chen,Linyang Li*

Main category: cond-mat.mes-hall

TL;DR: 将二维交替磁体卷成纳米管可形成具有两种功能的自旋可编程手性纳米螺线管，且无需自旋轨道耦合。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索将二维交替磁体（altermagnet）卷成纳米管后，所产生的新型自旋功能器件。

Method: 利用V2Se2O作为原型，结合第一性原理计算，研究了在卷曲几何和动量无关的自旋极化共同作用下，器件的（i）正向和（ii）反向工作模式。

Result: 计算揭示了在导带和价带边缘附近存在与自旋相关的螺旋波函数，证明了该纳米管器件能够实现自旋极化电流产生的螺旋电流以及时间变化的轴向磁通量诱导的纯自旋流。

Conclusion: 该研究为在无静态磁场偏压的轻元素材料中，构建无相对论效应的、紧凑的、自旋控制的磁通量生成器和电荷中性自旋注入器提供了新的途径。

Abstract: We show that rolling a two-dimensional altermagnet into a nanotube turns it
into a spin-programmable chiral nanosolenoid with two reciprocal, SOC-free
functionalities. (i) Direct: injecting a single-spin-polarized current produces
a steady helical current whose handedness is locked to the spin orientation,
yielding opposite axial magnetic fields for opposite spins. (ii) Inverse: a
time-varying axial flux Phi(t) induces a circumferential Faraday field E_theta
= -(dPhi/dt)/(2 pi R) that drives equal-magnitude, opposite-sign axial charge
currents in the two spin channels, Iz^up = - Iz^down, thereby pumping a pure
spin current Is = (hbar/2e)(Iz^up - Iz^down) with zero net charge flow. Both
effects arise from the interplay between momentum-odd spin polarization
inherent to altermagnets and the screw symmetry of the rolled geometry, and
persist in the complete absence of spin-orbit coupling. Using V2Se2O as a
prototype, first-principles calculations reveal spin-dependent chiral wave
functions near both the conduction- and valence-band edges. These results
establish a nonrelativistic route toward compact spin-controlled flux
generators and charge-neutral spin injectors in light-element materials without
static magnetic bias.

</details>


### [232] [Two parameter scaling of conductance in quantum Hall effect](https://arxiv.org/abs/2510.19739)
*Yurii G. Arapov,Svetlana V. Gudina,Vladimir N. Neverov,Nikita S. Sandakov,Nina G. Shelushinina*

Main category: cond-mat.mes-hall

TL;DR: 本文对整数分数量子霍尔效应区的两参数标度理论的理论概念进行了简要回顾，并展示了关于在二维半导体结构和石墨烯中构建电导率标度图的早期、近期和新的实验结果的全面数据集。对从实验数据获得的标度图与计算获得的标度图进行了比较分析。


<details>
  <summary>Details</summary>
Motivation: 对整数分数量子霍尔效应区的两参数标度理论的理论概念进行回顾，并展示了关于构建电导率标度图的实验结果。

Method: 对整数分数量子霍尔效应区的两参数标度理论的理论概念进行回顾，并展示了关于在二维半导体结构和石墨烯中构建电导率标度图的早期、近期和新的实验结果的全面数据集。对从实验数据获得的标度图与计算获得的标度图进行了比较分析。

Result: 展示了关于在二维半导体结构和石墨烯中构建电导率标度图的实验结果。对从实验数据获得的标度图与计算获得的标度图进行了比较分析。

Conclusion: 对实验数据获得的标度图与计算获得的标度图进行了比较分析，为理解该效应提供了新的视角。

Abstract: After a brief survey of theoretical concepts for the two-parameter scaling
theory in the integer quantum Hall effect regime, a comprehensive set of early,
recent and new experimental results on constructing scaling diagrams for
conductance in 2D semiconductor structures, as well as in graphene is
displayed. A comparative analysis of scaling diagrams obtained from
experimental data with calculated ones is carried out.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [233] [Symmetry-accelerated classical simulation of Clifford-dominated circuits](https://arxiv.org/abs/2510.18977)
*Giulio Camillo,Filipa C. R. Peres,Markus Heinrich,Juani Bermejo-Vega*

Main category: quant-ph

TL;DR: 该研究通过利用对称性来优化量子电路的稳定器范围计算，从而在经典计算机上实现更高效的量子模拟，并为理解量子优势提供了新的视角。


<details>
  <summary>Details</summary>
Motivation: 优化量子电路的稳定器范围计算，以在经典计算机上实现更高效的量子模拟。

Method: 利用计算中的对称性，将优化问题限制在克利福德群的子群中，并采用“强对称约简”和“弱对称约简”方法来减少计算成本。

Result: 在标准笔记本电脑上实现了对多达七个量子比特的酉变换的最优分解，并且在量子傅里叶变换电路和测量基量子计算的经典模拟中取得了指数级运行时间改进。

Conclusion: 对称性利用是扩展经典模拟技术和深化量子优势资源理论理解的有效途径。

Abstract: Classical simulation of quantum circuits plays a crucial role in validating
quantum hardware and delineating the boundaries of quantum advantage. Among the
most effective simulation techniques are those based on the stabilizer extent,
which quantifies the overhead of representing non-Clifford operations as linear
combinations of Clifford unitaries. However, finding optimal decompositions
rapidly becomes intractable as it constitutes a superexponentially large
optimization problem. In this work, we exploit symmetries in the computation of
the stabilizer extent, proving that for real, diagonal, and real-diagonal
unitaries, the optimization can be restricted to the corresponding subgroups of
the Clifford group without loss of optimality. This ``strong symmetry
reduction'' drastically reduces computational cost, enabling optimal
decompositions of unitaries on up to seven qubits using a standard laptop--far
beyond previous two-qubit limits. Additionally, we employ a ``weak symmetry
reduction'' method that leverages additional invariances to shrink the search
space further. Applying these results, we demonstrate exponential runtime
improvements in classical simulations of quantum Fourier transform circuits and
measurement-based quantum computations on the Union Jack lattice, as well as
new insights into the non-stabilizer properties of multi-controlled-phase gates
and unitaries generating hypergraph states. Our findings establish symmetry
exploitation as a powerful route to scale classical simulation techniques and
deepen the resource-theoretic understanding of quantum advantage.

</details>


### [234] [Noise-Assisted Feedback Control of Open Quantum Systems for Ground State Properties](https://arxiv.org/abs/2510.18984)
*Kasturi Ranjan Swain,Rajesh K. Malla,Adolfo del Campo*

Main category: quant-ph

TL;DR: 本研究提出了一种在量子计算机上模拟包含负耗散的开放量子系统动力学的方法，该方法超越了标准马尔可夫近似，并开发了一种利用反馈控制、噪声辅助动力学的量子算法来计算基态性质，为利用现有量子硬件和推进开放系统动力学控制协议提供了有前景的策略。


<details>
  <summary>Details</summary>
Motivation: 解决现有容错量子设备中固有的噪声问题，以在量子算法和模拟中可靠地实现酉演化。

Method: 提出一种在量子计算机上模拟开放量子系统动力学的方法，该方法能够处理包含负耗散的GKSL主方程，并超越了标准的马尔可夫近似。在此基础上，开发了一种利用反馈控制和噪声辅助动力学的量子算法来计算基态性质，其中Lyapunov反馈在工程噪声条件下引导系统趋向目标虚拟状态。

Result: 开发了一种超越马尔可夫近似的开放量子系统模拟方法，并提出了一种利用噪声辅助动力学和Lyapunov反馈的量子算法，用于计算基态性质。

Conclusion: 本研究提出的方法和算法为利用现有量子硬件和推进基于开放系统动力学的鲁棒控制协议提供了一种有前景的策略。

Abstract: Intrinsic noise in pre-fault-tolerant quantum devices poses a major challenge
to the reliable realization of unitary dynamics in quantum algorithms and
simulations. To address this, we present a method for simulating open quantum
system dynamics on a quantum computer, including negative dissipation rates in
the Gorini-Kossakowski-Sudarshan-Lindblad (GKSL) master equation. Our approach
lies beyond the standard Markovian approximation, enabling the controlled study
of non-Markovian processes within a quantum simulation framework. Using this
method, we develop a quantum algorithm for calculating ground-state properties
that exploits feedback-controlled, noise-assisted dynamics. In this scheme,
Lyapunov-based feedback steers the system toward a target virtual state under
engineered noise conditions. This framework offers a promising strategy for
harnessing current quantum hardware and advancing robust control protocols
based on open system dynamics.

</details>


### [235] [Noise-tolerant tripartite entanglement and quantum coherence via saturation effects](https://arxiv.org/abs/2510.19027)
*P. Djorwé,J. -X. Peng,S. Adbel-Khalek,A. -H. Abdel-Aty*

Main category: quant-ph

TL;DR: 提出了一种利用饱和增益/损耗来提高三方纠缠和量子相干性抵抗温度波动的方案。


<details>
  <summary>Details</summary>
Motivation: 在现代量子技术中，工程化能够抵抗环境温度的量子资源引起了极大的兴趣，但合成此类量子态是一项棘手的任务。

Method: 通过一个由两个电磁场驱动的机械谐振器组成的基准模型，其中电磁场是光学耦合的。通过调制光子跳变 J 来捕捉光学耦合，每个光学腔都具有饱和增益或损耗。

Result: 当饱和增益/损耗关闭时，在适当调整相位调制的情况下，三方纠缠和量子相干性略有增强。当饱和效应开启时，三方纠缠显著增强（高达一个数量级），量子相干性适度提高。与未考虑饱和效应相比，所提出的方案在保留三方纠缠方面，其阈值热声子数推迟了高达两个数量级。

Conclusion: 饱和增益/损耗的引入诱导了抗噪声量子资源，并可能导致室温量子应用，如量子信息处理和量子计算任务。研究结果具有普遍性，表明饱和非线性效应是工程化抗热量子关联的工具。

Abstract: Engineering quantum resources that survive against environmental temperature
is of great interest for modern quantum technologies. However, it is a tricky
task to synthetize such quantum states. Here, we propose a scheme to generate
highly resilient tripartite entanglement and quantum coherence against thermal
fluctuations. Our benchmark model consists of a mechanical resonator driven by
two electromagnetic fields, which are optically coupled. A modulated photon
hopping $J$ captures the optical coupling, and each optical cavity hosts
saturable gain or loss. When the saturable gain/loss are off, we observe a
slightly enhancement of both tripartite entanglement and quantum coherence for
an appropriate tuning of the phase modulation. When the saturation effects are
turned on, we observe a significant enhancement of the tripartite entanglement,
up to one order of magnitude, together with a moderate improvement of the
quantum coherence. More interestingly, our results show that the threshold
thermal phonon mumber for preserving tripartite entanglement in our proposal
has been postponed up to two order of magnitude stronger than when the
saturation effects are not accounted. The inclusion of saturable gain/loss in
our proposal induces noise-tolerant quantum resources, and may lead to room
temperature quantum applications such as quantum information processing, and
quantum computional tasks. Our findings are quite general, and suggest
saturation nonlinear effects as a tool for engineering thermal-immune quantum
correlations.

</details>


### [236] [High-Fidelity Scalable Quantum State Preparation via the Fusion Method](https://arxiv.org/abs/2510.19039)
*Matthew Patkowski,Onat Ayyildiz,Matjaž Kebrič,Katharine L. C. Hunt,Dean Lee*

Main category: quant-ph

TL;DR: 通过混合方法（渐进预处理与 Rodeo 算法）改进了 Rodeo 算法，在不牺牲指数收敛速度的情况下，克服了初始重叠度低的问题，提高了大规模量子模拟的可扩展性和效率。


<details>
  <summary>Details</summary>
Motivation: 原始的 Rodeo 算法在初始状态与目标本征态的重叠度低时表现不佳，这限制了其在大规模系统中的应用。本研究旨在解决这一限制，以提高 Rodeo 算法的适用性。

Method: 提出了一种混合方法，将渐进预处理与 Rodeo 算法相结合。首先通过渐进加载来预处理 Rodeo 算法的状态，以增强中间态的重叠度，然后应用 Rodeo 算法进行指数级收敛。该方法通过逐步构建由精确可解的子系统组成的大型系统来实现。

Result: 在自旋 1/2 XX 模型上进行数值模拟，证明了所提出的混合方法能够使 Rodeo 算法在不同系统规模下保持稳健的指数级收敛。与仅使用渐进加载或未使用改进的 Rodeo 算法相比，该混合方法在达到 $10^{-3}$ 或更高的状态制备精度时，具有显著的计算成本优势。

Conclusion: 所提出的混合方法（渐进预处理与 Rodeo 算法）有效地克服了原始 Rodeo 算法在初始重叠度低时的局限性，在大规模量子模拟中表现出稳健性和可扩展性，并具有计算成本优势。

Abstract: Robust and efficient eigenstate preparation is a central challenge in quantum
simulation. The Rodeo Algorithm (RA) offers exponential convergence to a target
eigenstate but suffers from poor performance when the initial state has low
overlap with the desired eigenstate, hindering the applicability of the
original algorithm to larger systems. In this work, we introduce a fusion
method that preconditions the RA state by an adiabatic ramp to overcome this
limitation. By incrementally building up large systems from exactly solvable
subsystems and using adiabatic preconditioning to enhance intermediate state
overlaps, we ensure that the RA retains its exponential convergence even in
large-scale systems. We demonstrate this hybrid approach using numerical
simulations of the spin- 1/2 XX model and find that the Rodeo Algorithm
exhibits robust exponential convergence across system sizes. We benchmark
against using only an adiabatic ramp as well as using the unmodified RA,
finding that for state preparation precision at the level of $10^{-3}$
infidelity or better there a decisive computational cost advantage to the
fusion method. These results together demonstrate the scalability and
effectiveness of the fusion method for practical quantum simulations.

</details>


### [237] [Colloquium: Quantum optics of intense light--matter interaction](https://arxiv.org/abs/2510.19045)
*P. Stammer,J. Rivera-Dean,P. Tzallas,M. F. Ciappina,M. Lewenstein*

Main category: quant-ph

TL;DR: 强光与物质的相互作用在原子、分子和光学物理领域具有重要意义，尤其是在高次谐波产生等非线性过程中。最近，完全量化的描述方法被认为是该领域的重要进展，这得益于量子光学与强场物理和超快科学的融合。


<details>
  <summary>Details</summary>
Motivation: 在强光-物质相互作用中，利用高功率光源产生的场强可与束缚电子的场强相当甚至更强，从而驱动高度非线性的过程，例如高次谐波产生，其中低频光子被转换为高频光子。

Method: 本文探讨了全量化描述在强光-物质相互作用中的应用，这种方法明确考虑了光场的量子性质。

Result: 全量化描述为基础研究和技术应用开辟了新的途径，尤其是在量子光学与强场物理和超快科学交叉的领域。

Conclusion: 强光-物质相互作用的量化描述是该领域的一个重要进展，有望推动基础研究和技术应用的进一步发展。

Abstract: Intense light-matter interaction largely relies on the use of high-power
light sources, creating fields comparable to, or even stronger than, the field
keeping the electrons bound in atoms. Under such conditions, the interaction
induces highly nonlinear processes such as high harmonic generation, in which
the low-frequency photons of a driving laser field are upconverted into
higher-frequency photons. These processes have enabled numerous groundbreaking
advances in atomic, molecular, and optical physics, and they form the
foundation of attosecond science. Until recently, however, such processes were
typically described using semi-classical approximations, since the quantum
properties of the light field were not required to explain the observables.
This has changed in the recent past. Ongoing theoretical and experimental
advances show that fully quantized descriptions of intense light-matter
interactions, which explicitly incorporate the quantum nature of the light
field, open new avenues for both fundamental research and technological
applications at the fully quantized level. These advances emerge from the
convergence of quantum optics with strong-field physics and ultrafast science.
Together, they have given rise to the field of quantum optics and quantum
electrodynamics of strong-field processes.

</details>


### [238] [Simulating high-accuracy nuclear motion Hamiltonians in discrete variable representation using Walsh-Hadamard QROM with fault-tolerant quantum computers](https://arxiv.org/abs/2510.19062)
*Michał Szczepanik,Ákos Nagy,Emil Żak*

Main category: quant-ph

TL;DR: 提出一种在容错量子计算机上模拟分子振动-转动哈密顿量的量子算法，该算法在逻辑量子比特数量和T门复杂度方面实现了指数级降低。


<details>
  <summary>Details</summary>
Motivation: 现有量子算法在模拟分子振动-转动哈密顿量方面存在效率和资源限制，需要更优化的方法。

Method: 提出一种集成精确曲线动力学能量算子和混合有限基/离散变量表示的势能面的量子算法，并使用基于Walsh-Hadamard变换的量子只读存储器结构将哈密顿量编码为酉量子电路，以实现高精度的量子相位估计。

Result: 该算法在逻辑量子比特数和T门复杂度方面相比现有的基于单位数组合的块编码技术有指数级/多项式级降低，相比经典的变分方法有指数级内存节省和多项式级时间复杂度降低。对于水分子，所需的量子体积可减少10^5倍，对于12原子模型系统可减少至少10^6倍。对于一个12原子系统，模拟精度能量水平大约需要3个月的容错量子处理器时间，而经典超级计算机需要30,000多年。

Conclusion: 该量子算法在模拟分子振动-转动哈密顿量方面具有显著优势，有望在未来量子计算硬件发展的同时，大幅缩短计算时间和减少资源消耗，但实现其优势仍需大量的量子资源和持续的算法进步。

Abstract: We present a quantum algorithm for simulating rovibrational Hamiltonians on
fault-tolerant quantum computers. The method integrates exact curvilinear
kinetic energy operators and general-form potential energy surfaces expressed
in a hybrid finite-basis/discrete-variable representation. The Hamiltonian is
encoded as a unitary quantum circuit using a quantum read-only memory
construction based on the Walsh--Hadamard transform, enabling high-accuracy
quantum phase estimation of rovibrational energy levels. Our technique provides
asymptotic reductions in both logical-qubit count and T-gate complexity that
are exponential in the number of atoms and at least polynomial in the total
Hilbert-space size, relative to existing block-encoding techniques based on
linear combinations of unitaries. Compared with classical variational methods,
it offers exponential memory savings and polynomial reductions in time
complexity. The quantum volume required for computing the rovibrational
spectrum of water can be reduced by up to $10^{5}$ times compared with other
quantum methods, increasing to at least $10^{6}$ for a 30-dimensional (12-atom)
model system. For this case with a six-body coupled potential, estimating
spectroscopic-accuracy energy levels would require about three months on a
$1~\mathrm{MHz}$ fault-tolerant quantum processor with fewer than 300 logical
qubits, versus over 30,000 years on the fastest current classical
supercomputer. These estimates are approximate and subject to technological
uncertainties, and realizing the asymptotic advantage will require substantial
quantum resources and continued algorithmic progress.

</details>


### [239] [Practical Noise Mitigation for Quantum Annealing via Dynamical Decoupling -- Towards Industry-Relevant Optimization using Trapped Ions](https://arxiv.org/abs/2510.19073)
*Sebastian Nagies,Chiara Capecci,Marcel Seelbach Benkner,Javed Akram,Sebastian Rubbert,Dimitrios Bantounas,Michael Moeller,Michael Johanning,Philipp Hauke*

Main category: quant-ph

TL;DR: 本研究提出了一种通过周期性动态解耦脉冲来抑制量子退火中局部场噪声的方法，并在量子退火器和实际的离子阱平台上验证了该方法的有效性，显著提高了退火保真度，并揭示了通用的性能扩展规律。


<details>
  <summary>Details</summary>
Motivation: 量子退火在解决组合优化问题方面具有潜力，但其在实际设备上的性能受到环境噪声的严重限制，这会降低解题质量。

Method: 研究人员提出了一种通过周期性施加实现全局自旋翻转的动态解耦脉冲来抑制量子退火协议中局部场噪声的方法。他们将此方法应用于最小化多目标跟踪 QUBO 问题和切割库存问题，并使用基于磁梯度耦合的离子阱平台来定义实际的噪声和耦合参数。

Result: 研究结果表明，典型的磁场波动会显著降低退火保真度，但中等频率的动态解耦脉冲可以使性能恢复到接近理想水平。研究还发现，保真度取决于结合了噪声幅度和动态解耦脉冲间隔的通用参数。

Conclusion: 提出的噪声抑制策略和性能改进不仅适用于离子阱平台，而且广泛适用于多种量子退火实现方式，为近期设备中的错误缓解提供了一条实用且可扩展的途径。

Abstract: Quantum annealing is a framework for solving combinatorial optimization
problems. While it offers a promising path towards a practical application of
quantum hardware, its performance in real-world devices is severely limited by
environmental noise that can degrade solution quality. We investigate the
suppression of local field noise in quantum annealing protocols through the
periodic application of dynamical decoupling pulses implementing global spin
flips. As test problems, we construct minimal Multiple Object Tracking QUBO
instances requiring only five and nine qubits, as well as cutting stock
instances of five and six qubits. To further place our results in a practical
context, we consider a trapped-ion platform based on magnetic gradient-induced
coupling as a reference architecture, using it to define experimentally
realistic noise and coupling parameters. We show that external magnetic field
fluctuations, typical in such setups, significantly degrade annealing fidelity,
while moderate dynamical decoupling pulse rates, which are achievable in
current experiments, restore performance to near-ideal levels. Our analytical
and numerical results reveal a universal scaling behavior, with fidelity
determined by a generalized parameter combining noise amplitude and dynamical
decoupling pulse interval. While our analysis is grounded in the trapped-ion
platform, the proposed noise mitigation strategy and resulting performance
improvements are applicable to a broad range of quantum annealing
implementations and establish a practical and scalable route for error
mitigation in near-term devices.

</details>


### [240] [Twisted superconducting quantum diodes: Towards anharmonicity and high fidelity](https://arxiv.org/abs/2510.19627)
*Han Zhong,Denis Kochan,Igor Zutic,Yingying Wu*

Main category: quant-ph

TL;DR: 量子二极管在扭曲的 NbSe2 双层器件中实现，效率为 27.6%，这表明最大整流效率并非总是对量子信息有利，并为设计用于高保真量子电路的扭曲超导体提供了新原则。


<details>
  <summary>Details</summary>
Motivation: 现有超导元件缺乏方向性，导致能量损失和退相干。量子二极管虽然有潜力解决这个问题，但其效率和量子集成能力仍然有限。

Method: 在平面内和平面外磁场下，研究了扭曲 1 度的 NbSe2 双层器件的量子二极管特性。通过量子模拟揭示了这种中间效率对保持量子比特的非简并性和稳定两能级系统的益处。

Result: 在扭曲的 NbSe2 双层器件中实现了量子二极管，效率为 27.6%，高于原始器件。量子模拟表明，这种效率有利于量子比特的非简并性和两能级系统的稳定性。

Conclusion: 最大整流效率不一定有利于量子信息处理。这项工作为设计具有特定整流特性的扭曲超导体，以实现低功耗、高保真的量子电路开辟了新途径。

Abstract: As quantum technologies advance, a fundamental challenge is mitigating noise
and backscattering in superconducting circuits to achieve scalable,
high-fidelity operations. Conventional superconducting components lack
directionality, causing energy loss and decoherence. Superconducting diodes,
that allow dissipationless current in one direction and resistive flow in the
other, offer a potential remedy, yet their efficiency and quantum integration
remain limited. Here, we realize a quantum diode in twisted NbSe2 bilayers
under in-plane and out-of-plane magnetic fields. A mere 1 degree twist yields
an efficiency enhancement over pristine devices, reaching 27.6 percent. Quantum
simulations reveal that this intermediate efficiency, well below 100 percent
ideal, is both experimentally practical and optimal for preserving qubit
anharmonicity and stabilizing two-level systems. These findings show that
maximal rectification is not always beneficial for quantum information,
establishing a new principle for designing the fundamental properties of
twisted superconductors towards low-power, high-fidelity quantum circuits.

</details>


### [241] [Self-Configuring Quantum Networks with Superposition of Trajectories](https://arxiv.org/abs/2510.19092)
*Albie Chan,Zheng Shi,Jorge Miguel-Ramiro,Luca Dellantonio,Christine A. Muschik,Wolfgang Dür*

Main category: quant-ph

TL;DR: 量子网络通过集成叠加量子路径和变分量子优化技术，能够自适应地优化嘈杂路径的叠加，以在多节点间建立高保真连接，即使在存在噪声和路径叠加不完美的情况下也能提高性能。


<details>
  <summary>Details</summary>
Motivation: 未来的量子通信和可扩展量子计算需要量子网络，但噪声和退相干对其性能构成了挑战。

Method: 提出一种集成了叠加量子路径和变分量子优化技术的自配置方法，允许网络动态优化跨多节点的噪声路径叠加，以建立高保真连接。

Result: 该方法能够适应未知的噪声，而无需对相应的量子通道进行表征或基准测试，并且即使在路径叠加生成的过程中存在不完美的情况下，该方法仍然有益。

Conclusion: 该方法为在噪声环境中构建高保真量子网络提供了一种有前途的解决方案。

Abstract: Quantum networks are a backbone of future quantum technologies thanks to
their role in communication and scalable quantum computing. However, their
performance is challenged by noise and decoherence. We propose a
self-configuring approach that integrates superposed quantum paths with
variational quantum optimization techniques. This allows networks to
dynamically optimize the superposition of noisy paths across multiple nodes to
establish high-fidelity connections between different parties. Our framework
acts as a black box, capable of adapting to unknown noise without requiring
characterization or benchmarking of the corresponding quantum channels. We also
discuss the role of vacuum coherence, a quantum effect central to path
superposition that impacts protocol performance. Additionally, we demonstrate
that our approach remains beneficial even in the presence of imperfections in
the generation of path superposition.

</details>


### [242] [Addressing spins at the clock transitions with a frequency- and bandwidth-tunable superconducting resonator](https://arxiv.org/abs/2510.19684)
*Yutian Wen,V. Ranjan,T. Lorriaux,D. Vion,B. Huard,A. Bienfait,E. Flurin,P. Bertet*

Main category: quant-ph

TL;DR: 通过超导电路控制固态自旋量子存储器，实现了450毫秒的相干时间，并动态调控了谐振器频率和带宽。


<details>
  <summary>Details</summary>
Motivation: 实现实用的量子存储器方案需要动态控制谐振器频率和带宽。

Method: 使用超导谐振器，通过直流电流调控频率，通过耦合低品质因子缓冲谐振器调控带宽，并用此谐振器实现对铋原子核自旋的相干时间测量和射频驱动。

Result: 实现了450毫秒的Hahn回波相干时间，并展示了射频驱动铋原子核自旋超精细跃迁以及动态调控谐振器带宽的能力。

Conclusion: 固态自旋量子存储器与超导电路的结合是实现量子存储的有前景的方案，动态调控谐振器频率和带宽是实现该方案的关键。

Abstract: Solid-state spin ensembles addressed via superconducting circuits are
promising candidates for quantum memory applications, offering multimodal
storage capability and second-long coherence times at their clock transition.
Implementing practical memory schemes requires dynamic control over both the
resonator frequency and bandwidth. In this letter, we report measurements of a
superconducting resonator whose frequency can be tuned by passing a DC current
through the high-kinetic-inductance thin film, and whose bandwidth can be tuned
by parametric coupling to a low-Q buffer resonator. Using this resonator, we
address an ensemble of bismuth donors at their clock transition, measuring a
Hahn-echo coherence time of 450 ms. We demonstrate RF driving of the bismuth
donor hyperfine transitions, as well as dynamic bandwidth control of the
resonator.

</details>


### [243] [Generalised Pinching Inequality](https://arxiv.org/abs/2510.19111)
*Andreas Winter*

Main category: quant-ph

TL;DR: Hayashi's Pinching Inequality 的一个简单证明及其推广。


<details>
  <summary>Details</summary>
Motivation: 提供 Hayashi's Pinching Inequality 的一个非常简单的证明，并将其推广到加权投影和反转矩阵不等式的情况。

Method: 使用加权投影和反转矩阵不等式来推广 Hayashi's Pinching Inequality。

Result: 提出了一个推广的 Pinching Inequality，并将其应用于二元测量的温和测量引理，其中矩阵排序取代了迹范数中的近似。

Conclusion: 推广的 Pinching Inequality 为量子信息理论提供了一个新的工具，特别是在温和测量方面。

Abstract: Hayashi's Pinching Inequality, which establishes a matrix inequality between
a semidefinite matrix and a multiple of its "pinched" version via a projective
measurement, has found many applications in quantum information theory and
beyond. Here, we show a very simple proof of it, which lends itself immediately
to natural generalisations where the different projections of the measurement
have different weights, and where the matrix inequality can be reversed. As an
application we show how the generalised pinching inequality in the case of
binary measurements gives rise to a novel gentle measurement lemma, where
matrix ordering replaces approximation in trace norm.

</details>


### [244] [Variational Quantum Algorithm for Unitary Dilation](https://arxiv.org/abs/2510.19157)
*S. X. Li,Keren Li,J. B. You,Y. -H. Chen,Clemens Gneiting,Franco Nori,X. Q. Shao*

Main category: quant-ph

TL;DR: 该研究提出了一种混合量子-经典框架，用于在噪声环境下高效实现非酉算子的近似酉扩张。该方法将目标非酉算子嵌入到参数化量子电路生成的酉矩阵子块中，并通过经典优化器在全局酉约束下调整电路参数。该方法在模拟开放量子系统（例如，基于Lindblad算子的演化）方面具有应用潜力，并在超导器件上进行了实验验证。与标准方法相比，该方法显著降低了量子资源需求，提高了对噪声的鲁棒性，实现了高保真度的模拟，并兼容非马尔可夫动力学和Kraus算子演化。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够有效处理和模拟包含非酉演化过程的量子系统的方法，特别是在当前具有噪声的量子硬件上。

Method: 将目标非酉算子嵌入到由参数化量子电路（具有通用表达能力）生成的酉矩阵的一个子块中。使用经典优化器在全局酉约束下调整量子电路的参数，以实现对非酉算子的酉扩张。

Result: 与标准酉扩张协议相比，该混合量子-经典框架显著减少了量子资源需求，并提高了对设备噪声的鲁棒性，从而实现了高保真度的模拟。该方法在超导器件上得到了实验验证。

Conclusion: 该研究提出的混合量子-经典框架为在近期含噪声量子硬件上进行非酉过程（包括非马尔可夫动力学和Kraus算子演化）的噪声鲁棒模拟提供了一条切实可行的途径。

Abstract: We introduce a hybrid quantum-classical framework for efficiently
implementing approximate unitary dilations of non-unitary operators with
enhanced noise resilience. The method embeds a target non-unitary operator into
a subblock of a unitary matrix generated by a parameterized quantum circuit
with universal expressivity, while a classical optimizer adjusts circuit
parameters under the global unitary constraint. As a representative
application, we consider the non-unitary propagator of a Lindbladian
superoperator acting on the vectorized density matrix, which is relevant for
simulating open quantum systems. We further validate the approach
experimentally on superconducting devices in the Quafu quantum cloud computing
cluster. Compared with standard dilation protocols, our method significantly
reduces quantum resource requirements and improves robustness against device
noise, achieving high-fidelity simulation. Its generality also enables
compatibility with non-Markovian dynamics and Kraus-operator-based evolutions,
providing a practical pathway for the noise-resilient simulation of non-unitary
processes on near-term quantum hardware.

</details>


### [245] [Hybrid Quantum-Classical Eigensolver with Real-Space Sampling and Symmetric Subspace Measurements](https://arxiv.org/abs/2510.19219)
*Lei Xu,Ling Wang*

Main category: quant-ph

TL;DR: 提出了一种混合量子-经典本征求解器，通过结合实空间采样、张量网络桥接量子电路和对称子空间测量，有效缩减希尔伯特空间，用于模拟强关联量子多体系统。


<details>
  <summary>Details</summary>
Motivation: 经典的模拟强关联量子多体系统的方法面临希尔伯特空间呈指数增长和广泛纠缠带来的计算挑战。

Method: 将系统划分为大小相等的子系统，利用量子电路捕捉局部纠缠，张量网络重新连接它们以恢复全局关联。利用对称子空间测量，通过多对一映射将等效的实空间构型聚集成单一的对称态。

Result: 在1D和2D的周期$J_1\!-\!J_2$反铁磁海森堡模型上进行了概念验证，使用低至6的矩阵乘积态键维度，在键维度外推后，64个格点的链和$6\times6$的环面实现了$10^{-5}$的绝对能量误差。

Conclusion: 该混合本征求解器被验证具有高精度和高效率，并展示了其在强关联系统可扩展量子模拟方面的巨大潜力。

Abstract: We propose a hybrid quantum-classical eigensolver to address the
computational challenges of simulating strongly correlated quantum many-body
systems, where the exponential growth of the Hilbert space and extensive
entanglement render classical methods intractable. Our approach combines
real-space sampling of tensor-network-bridged quantum circuits with symmetric
subspace measurements, effectively constraining the wavefunction within a
substaintially reduced Hilbert space for efficient and scalable simulations of
versatile target states. The system is partitioned into equal-sized subsystems,
where quantum circuits capture local entanglement and tensor networks reconnect
them to recover global correlations, thereby overcoming partition-induced
limitations. Symmetric subspace measurements exploit point-group symmetries
through a many-to-one mapping that aggregates equivalent real-space
configurations into a single symmetric state, effectively enhancing real-space
bipartition entanglement while elimilating redundant degrees of freedom. The
tensor network further extends this connectivity across circuits, restoring
global entanglement and correlation, while simultaneously enabling generative
sampling for efficient optimization. As a proof of concept, we apply the method
to the periodic $J_1\!-\!J_2$ antiferromagnetic Heisenberg model in one and two
dimensions, incorporating translation, reflection, and inversion symmetries.
With a small matrix product state bond dimension of up to 6, the method
achieves an absolute energy error of $10^{-5}$ for a 64-site periodic chain and
a $6\times6$ torus after bond-dimension extrapolation. These results validate
the accuracy and efficiency of the hybrid eigensolver and demonstrate its
strong potential for scalable quantum simulations of strongly correlated
systems.

</details>


### [246] [Photonic scattering in 2D waveguide QED: Quantum Goos-Hänchen shift](https://arxiv.org/abs/2510.19230)
*Yongguan Ke,Zhenzhi Peng,Muhib Ullah,Chaohong Lee*

Main category: quant-ph

TL;DR: 研究了二维波导量子电动力学中的光子散射现象，并提出了一种基于格林函数法的二维量子电动力学散射理论。


<details>
  <summary>Details</summary>
Motivation: 二维波导量子电动力学（WQED）平台仍有待探索，预计会产生独特的 the higher-dimensional 光子散射现象。

Method: 提出了一种基于格林函数法的二维量子电动力学散射理论。

Result: 证明了发射光子和注入光子之间的平均位移是 Goos-H"anchen 现象的量子类似物。当光子被注入到单个偏离中心的端口时，在与超辐射态共振的条件下，后向散射可以增强量子 Goos-H"anchen (QGH) 位移。当光子被注入到中心端口时，由于结构的镜像对称性，QGH 位移为零。然而，对于具有横向动量的多端口注入，QGH 位移得以恢复，并且与相对于横向动量的相位导数成正比。与经典 Goos-H"anchen 位移不同，这些效应可以通过注入光子的频率灵活调整。

Conclusion: 提出了一种探索和操纵复杂 WQED 网络中光子散射的通用框架。

Abstract: Quantum emitters coupled to traveling photons in waveguides, known as
waveguide quantum electrodynamics (WQED), offer a powerful platform for
understanding light-matter interactions and underpinning emergent quantum
technologies. While WQED has been extensively studied in one dimension,
two-dimensional (2D) WQED remains largely unexplored, where novel photonic
scattering phenomena unique to higher dimensions are expected. Here, we present
a comprehensive scattering theory for 2D WQED based on the Green function
method. We show that the mean displacement between emitted and injected photons
serves as a quantum analogue of the Goos-H\"anchen shift. When a photon is
injected into a single off-centered port, the quantum Goos-H\"anchen (QGH)
shift can be enhanced in backward scattering under resonant conditions with
subradiant states. When a photon is injected into the center port, there is no
QGH shift due to the mirror symmetry of structure. However, for multiple-port
injection with transverse momentum, the QGH shift is recovered and proportional
to the derivative of phase with respect to transverse momentum. Unlike the
classical Goos-H\"anchen shift, these effects can be flexibly tuned by the
injected photon's frequency. Our work provides a general framework for
exploring and manipulating photonic scattering in complex WQED networks.

</details>


### [247] [Decoherence of a dissipative Brownian charged magneto-anharmonic oscillator: an information theoretic approach](https://arxiv.org/abs/2510.19317)
*Suraka Bhattacharjee,Koushik Mandal,Supurna Sinha*

Main category: quant-ph

TL;DR: 研究磁场中各向异性非谐振荡器的退相干现象，并提出了一个冷离子实验方案。


<details>
  <summary>Details</summary>
Motivation: 研究磁场中各向异性非谐振荡器的退相干现象，并探讨了其在量子技术中的相关性。

Method: 使用微扰技术求解非谐振荡器问题，推导出弱耦合极限下的非马尔可夫主方程，并计算了冯诺依曼熵。

Result: 发现非谐性参数α会因非谐性的去限制效应而增强退相干；加热函数的时间演化具有振荡特性，表明信息回流；冯诺依曼熵随α增大而增加，与退相干分析中的去限制效应一致。

Conclusion: 非谐性参数α增强了退相干，并提出了一个冷离子实验方案来验证理论预测，该研究对量子技术领域具有重要意义。

Abstract: We study the decoherence of an anisotropic anharmonic oscillator in a
magnetic field, coupled to a bath of harmonic oscillators at high and low
temperatures. We solve the anharmonic oscillator problem using perturbative
techniques and derive the non-Markovian master equation in the weak coupling
limit. The anharmonicity parameter {\alpha} enhances decoherence due to the
deconfining effect of anharmonicity. The oscillatory nature of the time
evolution of heating function indicates information backflow. The von-Neumann
entropy is also calculated for the system, which increases with {\alpha},
consistent with the deconfining effect noted in the decoherence analysis. We
have also proposed a cold ion experimental set up for testing our theoretical
predictions. The study is of relevance to the domain of quantum technology
where decoherence significantly affects the performance of a quantum computer.

</details>


### [248] [Dipole-Dipole Interactions of Floquet States](https://arxiv.org/abs/2510.19362)
*Tim Ehret,Vyacheslav Shatokhin,Andreas Buchleitner*

Main category: quant-ph

TL;DR: 我们为受强单色波驱动并耦合到共同电磁浴的平移冷双能级原子推导了 Floquet-Markov Lindblad 主方程，所得的偶极-偶极相互作用重现了各向异性 Heisenberg 模型。


<details>
  <summary>Details</summary>
Motivation: 推导了 Floquet-Markov Lindblad 主方程，用于分析受激原子的相互作用。

Method: 通过偶极-偶极相互作用重现各向异性 Heisenberg 模型。

Result: 重现了各向异性 Heisenberg 模型。

Conclusion: 推导出的 Floquet-Markov Lindblad 主方程可以用于分析受激原子的相互作用。

Abstract: We formulate a Floquet-Markov Lindblad master equation for translationally
cold two-level atoms driven by a strong monochromatic wave and coupled to a
common electromagnetic bath. The resulting dipole-dipole interaction reproduces
the anisotropic Heisenberg model.

</details>


### [249] [Universality and Optimal Architectures for Layered Programmable Unitary Decompositions](https://arxiv.org/abs/2510.19397)
*Javier Álvarez-Vizoso,David Barral*

Main category: quant-ph

TL;DR: 任意酉变换可以分解为一系列更简单的、物理上可实现的酉变换，这一直是量子信息科学、量子控制和线性光学中的基础性问题。本研究提出了一个一维量子场论模型，用于论证一类广泛的酉变换分解的普适性。


<details>
  <summary>Details</summary>
Motivation: 解决量子信息科学、量子控制和线性光学中任意酉变换分解为更简单的、物理上可实现的酉变换的基础性问题。

Method: 提出一个一维量子场论模型，考虑形式为 $U = D_1 V_1 D_2 V_2 inom{2}{1} V_{M-1}D_M$ 的参数化，其中 $D_j$ 是可编程的对角酉矩阵，$V_j$ 是固定的混合矩阵。利用有效模型的异常等概念，建立了混合矩阵集合的普适性判据。

Result: 给出了一个严格的、基于物理的证明，阐述了该参数化覆盖整个特殊酉矩阵群所需的条件。该框架为验证各种已提出的架构的普适性提供了一种统一的方法，并阐明了此类结构所需的“通用”混合矩阵的性质。此外，还提供了一种几何感知的优化方法来寻找分解的参数。

Conclusion: 该研究提供了一个基于一维量子场论的模型，用于证明酉变换分解的普适性，并建立了混合矩阵集合的普适性判据。该框架为验证各种已提出的架构的普适性提供了一种统一的方法，并提供了一种几何感知的优化方法来寻找分解的参数。

Abstract: The decomposition of arbitrary unitary transformations into sequences of
simpler, physically realizable operations is a foundational problem in quantum
information science, quantum control, and linear optics. We establish a 1D
Quantum Field Theory model for justifying the universality of a broad class of
such factorizations. We consider parametrizations of the form $U = D_1 V_1 D_2
V_2 \cdots V_{M-1}D_M$, where $\{D_j\}$ are programmable diagonal unitary
matrices and $\{V_j\}$ are fixed mixing matrices. By leveraging concepts like
the anomalies of our effective model, we establish criteria for universality
given the set of mixer matrices. This approach yields a rigorous proof grounded
on physics for the conditions required for the parametrization to cover the
entire group of special unitary matrices. This framework provides a unified
method to verify the universality of various proposed architectures and
clarifies the nature of the ``generic'' mixers required for such constructions.
We also provide a geometry-aware optimization method for finding the parameters
of a decomposition.

</details>


### [250] [Krylov Complexity Under Hamiltonian Deformations and Toda Flows](https://arxiv.org/abs/2510.19436)
*Kazutaka Takahashi,Pratik Nandy,Adolfo del Campo*

Main category: quant-ph

TL;DR: Krylov子空间方法可用于模拟复杂系统的哈密顿变形，并与Toda方程相关联，可应用于热力学系统和随机矩阵。


<details>
  <summary>Details</summary>
Motivation: 利用Krylov子空间方法对哈密顿变形进行系统性研究，以构建可解模型并分析其演化复杂性。

Method: 应用Krylov子空间方法处理哈密顿变形，研究了变形和未变形理论的演化关系，并获得了广义Toda方程。

Result: 对于某些变形，Krylov子空间保持不变，但基矢重组；哈密顿量在Krylov空间呈三对角形式；得到了广义Toda方程；虚时演化等价于实时的幺正演化。

Conclusion: Krylov子空间方法为研究复杂系统的哈密顿变形提供了有效途径，并可应用于热力学系统和随机矩阵等领域。

Abstract: The quantum dynamics of a complex system can be efficiently described in
Krylov space, the minimal subspace in which the dynamics unfolds. We apply the
Krylov subspace method for Hamiltonian deformations, which provides a
systematic way of constructing solvable models from known instances. In doing
so, we relate the evolution of deformed and undeformed theories and investigate
their complexity. For a certain class of deformations, the resulting Krylov
subspace is unchanged, and we observe time evolutions with a reorganized basis.
The tridiagonal form of the generator in the Krylov space is maintained, and we
obtain generalized Toda equations as a function of the deformation parameters.
The imaginary-time-like evolutions can be described by real-time unitary ones.
As possible applications, we discuss coherent Gibbs states for thermodynamic
systems, for which we analyze the survival probability, spread complexity,
Krylov entropy, and associated time-averaged quantities. We further discuss the
statistical properties of random matrices and supersymmetric systems for
quadratic deformations.

</details>


### [251] [Accelerating Fault-Tolerant Quantum Computation with Good qLDPC Codes](https://arxiv.org/abs/2510.19442)
*Guo Zhang,Yuanye Zhu,Ying Li*

Main category: quant-ph

TL;DR: 提出了一种适用于量子低密度奇偶校验 (qLDPC) 码的容错量子计算方案，实现了恒定的量子比特开销和与代码距离相关的可接受的时间开销。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在为量子低密度奇偶校验 (qLDPC) 码开发一种容错量子计算方案，以提高效率并降低开销。

Method: 提出了一种新的容错量子计算方案，通过并行化代码手术和利用经典局部可测试码进行资源状态制备，实现了恒定的量子比特开销。

Result: 该方案的时间开销为 $O(d^{a+o(1)})$，对于好的 qLDPC 码，时间开销为 $O(d^{1+o(1)})$，优于基于代码手术和分支的方法。

Conclusion: 所提出的方案为 qLDPC 码的容错量子计算提供了一个新的范式，在保持低开销的同时实现了加速，尤其适用于 $a < 2$ 的情况。

Abstract: We propose a fault-tolerant quantum computation scheme that is broadly
applicable to quantum low-density parity-check (qLDPC) codes. The scheme
achieves constant qubit overhead and a time overhead of $O(d^{a+o(1)})$ for any
$[[n,k,d]]$ qLDPC code with constant encoding rate and distance $d =
\Omega(n^{1/a})$. For good qLDPC codes, the time overhead is minimized and
reaches $O(d^{1+o(1)})$. In contrast, code surgery based on gauging measurement
and brute-force branching requires a time overhead of $O(dw^{1+o(1)})$, where
$d\leq w\leq n$. Thus, our scheme is asymptotically faster for all codes with
$a < 2$. This speedup is achieved by developing techniques that enable
parallelized code surgery under constant qubit overhead and leverage classical
locally testable codes for efficient resource state preparation. These results
establish a new paradigm for accelerating fault-tolerant quantum computation on
qLDPC codes, while maintaining low overhead and broad applicability.

</details>


### [252] [Sequential Semi-Device-Independent Quantum Randomness Certification](https://arxiv.org/abs/2510.19445)
*Carles Roch I Carceller,Hanwool Lee,Jonatan Bohr Brask,Kieran Flatt,Joonwoo Bae*

Main category: quant-ph

TL;DR: 量子测量在现实条件下只能提供系统的不完全信息，但通过对同一系统进行连续测量，可以获取额外信息。本文研究了在半设备无关的随机性认证背景下，使用最大置信度连续测量的问题。


<details>
  <summary>Details</summary>
Motivation: 在半设备无关的随机性认证背景下，探索如何通过连续测量获取更多信息。

Method: 开发了一个通用的框架和数值方法，用于界定此类场景中可认证的随机性数量，并引入了一种通过半定规划对偶计算最小权衡函数的技术，以便通过熵积累来界定针对自适应攻击策略的可认证随机性。

Result: 该框架和数值方法能够界定可认证的随机性数量，并能针对自适应攻击策略进行界定。

Conclusion: 最大置信度测量能够实现随机性在连续测量链中的分发和认证。

Abstract: Quantum measurements under realistic conditions reveal only partial
information about a system. Yet, by performing sequential measurements on the
same system, additional information can be accessed. We investigate this
problem in the context of semi-device-independent randomness certification
using sequential maximum confidence measurements. We develop a general
framework and versatile numerical methods to bound the amount of certifiable
randomness in such scenarios. We further introduce a technique to compute
min-tradeoff functions via semidefinite programming duality, thus making the
framework suitable for bounding the certifiable randomness against adaptive
attacking strategies through entropy accumulation. Our results establish
sufficient criteria showing that maximum confidence measurements enable the
distribution and certification of randomness across a sequential measurement
chain.

</details>


### [253] [Absence of measurement- and unraveling-induced entanglement transitions in continuously monitored one-dimensional free fermions](https://arxiv.org/abs/2510.19459)
*Clemens Niederegger,Tatiana Vovk,Elias Starchl,Lukas M. Sieberer*

Main category: quant-ph

TL;DR: 连续监测的一维自由费米子系统在非平衡状态下表现出量子临界现象，但这些现象是否反映了真正的非平衡量子物质相或仅在有限长度尺度上存在是研究热点。本文研究了受格点占据连续监测影响的自由费米子链。通过引入一个插值于不同测量方案的展开相位φ，作者发现在0 ≤ φ < π/2时，纠缠最终遵循面积律，但仅在指数级的长尺度lφ,*之后。尽管数值模拟难以分辨lφ,*，但理论预测临界行为出现在一个仅呈多项式增长的交叉尺度之下，这使得该行为可被数值模拟解析。模拟结果证实了这些预测，排除了该模型中由测量或展开引起的纠缠相变。


<details>
  <summary>Details</summary>
Motivation: 研究连续监测的一维自由费米子系统是否表现出真正的非平衡量子物质相，以及临界现象是否仅在有限长度尺度上存在。

Method: 使用副本凯尔迪什场论得到描述长波长物理的非线性西格玛模型，并通过数值模拟进行验证。

Result: 对于0 ≤ φ < π/2，纠缠最终遵循面积律，但仅在指数级的长尺度lφ,*之后。临界行为出现在一个仅呈多项式增长的交叉尺度之下，这使得该行为可被数值模拟解析。模拟结果证实了理论预测，排除了由测量或展开引起的纠缠相变。

Conclusion: 该模型中不存在由测量或展开引起的纠缠相变。

Abstract: Continuous monitoring of one-dimensional free fermionic systems can generate
phenomena reminiscent of quantum criticality, such as logarithmic entanglement
growth, algebraic correlations, and emergent conformal invariance, but in a
nonequilibrium setting. However, whether these signatures reflect a genuine
phase of nonequilibrium quantum matter or persist only over finite length
scales is an active area of research. We address this question in a free
fermionic chain subject to continuous monitoring of lattice-site occupations.
An unraveling phase $\varphi$ interpolates between measurement schemes,
corresponding to different stochastic unravelings of the same Lindblad master
equation: For $\varphi = 0$, measurements disentangle lattice sites, while for
$\varphi = \pi/2$ they act as unitary random noise, yielding volume-law
steady-state entanglement. Using replica Keldysh field theory, we obtain a
nonlinear sigma model describing the long-wavelength physics. This analysis
shows that for $0 \leq \varphi < \pi/2$, entanglement ultimately obeys an area
law, but only beyond the exponentially large scale $\ln(l_{\varphi,*}) \sim
J/[\gamma \cos(\varphi)]$, where $J$ is the hopping amplitude and $\gamma$ the
measurement rate. Resolving $l_{\varphi, *}$ in numerical simulations is
difficult for $\gamma/J \to 0$ or $\varphi \to \pi/2$. However, the theory also
predicts that critical-like behavior appears below a crossover scale that grows
only algebraically in $J/\gamma$, making it numerically accessible. Our
simulations confirm these predictions, establishing the absence of measurement-
or unraveling-induced entanglement transitions in this model.

</details>


### [254] [Low overhead circuit cutting with operator backpropagation](https://arxiv.org/abs/2510.19467)
*Debarthi Pal,Ritajit Majumdar*

Main category: quant-ph

TL;DR: 本研究提出一种结合算子反向传播（OBP）和电路裁剪的技术，以优化量子电路中的噪声最小化，并通过模拟退火寻找最优参数，显著降低了资源需求和执行开销，同时保持或提高精度。


<details>
  <summary>Details</summary>
Motivation: 当前量子计算机受噪声影响且缺乏纠错，现有技术如电路裁剪和算子反向传播存在执行次数增加的限制，需要更有效的噪声缓解方法。

Method: 提出一种结合算子反向传播（OBP）和电路裁剪的优化方法，并使用模拟退火算法寻找最优的OBP参数，以最小化资源需求。

Result: 在变分量子特征求解器（VQES）和哈密顿量模拟电路中，资源需求分别减少了3倍和10倍，同时保持或提高了精度。该方法在Benchpress数据库和其他可观测量权重下也实现了类似的资源节省。

Conclusion: 本研究提出了一种结合OBP和电路裁剪的有效方法，通过模拟退火优化参数，可以显著降低量子电路中的噪声，减少资源开销，而不会损害性能。

Abstract: Current quantum computers suffer from noise due to lack of error correction.
Several techniques to mitigate the effect of noise have been studied, in
particular to extract the expectation value of observables. One such technique,
circuit cutting, partitions large circuits into smaller, less noisy
subcircuits, but the exponential increase in the number of circuit executions
limits its scalability. Another method, operator backpropagation (OBP) reduces
circuit depth by classically simulating parts of it, yet often escalates the
number of circuit executions by some factor due to additional non-commuting
terms in the updated observable. This paper introduces an optimized approach
for minimizing noise in quantum circuits using operator backpropagation (OBP)
combined with circuit cutting. We demonstrate that the strategic use of OBP
with circuit cutting can mitigate the execution overhead. By employing
simulated annealing, our proposed method identifies the optimal backpropagation
parameter for specific circuits and observables, maximizing resource reduction
in cutting. Results show a 3x and 10x decrease in resource requirements for
Variational Quantum Eigensolver and Hamiltonian simulation circuits
respectively, while maintaining or even enhancing accuracy. This approach also
yields similar savings for other circuits from the Benchpress database and
various observable weights, providing an efficient method to lower circuit
cutting overhead without compromising performance.

</details>


### [255] [Quantum Machine Learning methods for Fourier-based distribution estimation with application in option pricing](https://arxiv.org/abs/2510.19494)
*Fernando Alonso,Álvaro Leitao,Carlos Vázquez*

Main category: quant-ph

TL;DR: 本研究提出了两种混合经典-量子方法，利用量子机器学习模型重构金融衍生品定价的傅里叶级数表示，并在数值实验中证明了其准确性和竞争力。


<details>
  <summary>Details</summary>
Motivation: 金融衍生品定价是量化金融中的一个核心挑战，传统上使用蒙特卡洛积分技术解决。本研究旨在探索量子技术在这一领域的应用潜力。

Method: 提出两种混合经典-量子方法，利用基于参数化量子电路（PQC）的量子机器学习（QML）模型来重构统计分布的傅里叶级数表示，并分析数据量和PQC维度对性能的影响。使用量子加速蒙特卡洛（QAMC）作为基准进行评估。

Result: 提出的方法在提取傅里叶系数方面表现出卓越的准确性，计算成本和精度均具有竞争力。

Conclusion: 提出的混合经典-量子方法为金融衍生品估值提供了一种有竞争力的量子替代方案。

Abstract: The ongoing progress in quantum technologies has fueled a sustained
exploration of their potential applications across various domains. One
particularly promising field is quantitative finance, where a central challenge
is the pricing of financial derivatives-traditionally addressed through Monte
Carlo integration techniques. In this work, we introduce two hybrid
classical-quantum methods to address the option pricing problem. These
approaches rely on reconstructing Fourier series representations of statistical
distributions from the outputs of Quantum Machine Learning (QML) models based
on Parametrized Quantum Circuits (PQCs). We analyze the impact of data size and
PQC dimensionality on performance. Quantum Accelerated Monte Carlo (QAMC) is
employed as a benchmark to quantitatively assess the proposed models in terms
of computational cost and accuracy in the extraction of Fourier coefficients.
Through the numerical experiments, we show that the proposed methods achieve
remarkable accuracy, becoming a competitive quantum alternative for derivatives
valuation.

</details>


### [256] [Revealing the quantum nature of memory in non-Markovian dynamics on IBM Quantum](https://arxiv.org/abs/2510.19522)
*Charlotte Bäcker,Krishna Palaparthy,Walter T. Strunz*

Main category: quant-ph

TL;DR: IBM Quantum的超导量子处理器上的非马尔可夫动力学内存效应。


<details>
  <summary>Details</summary>
Motivation: 研究超导量子处理器上的非马尔可夫动力学内存效应。

Method: 使用碰撞模型在基于门控的量子电路中实现单比特和双比特动力学，并通过耦合辅助比特来表征过程。 验证单比特动力学中的量子内存，并提出一个玩具示例来展示如何使用当前的量子计算机来观察双比特动力学的量子内存。

Result: 证明了当前的量子硬件可以验证单比特动力学中的量子内存。 提出了一个玩具示例，演示了如何使用当前的量子计算机来观察双比特动力学的量子内存。

Conclusion: 当前的量子硬件可以用于验证单比特动力学中的量子内存，并且可以通过玩具示例来观察双比特动力学中的量子内存。

Abstract: We investigate memory effects in non-Markovian dynamics on superconducting
quantum processors provided by IBM Quantum. We use a collision-model approach
to implement suitable single- and two-qubit dynamics with a gate-based quantum
circuit. Coupling the system of interest to an ancilla allows for a
characterization of the process with respect to non-Markovian memory effects in
general, as well as concerning the quantumness of that memory. We demonstrate
that current noisy quantum hardware is capable of verifying quantum memory in
single-qubit dynamics. We then discuss why a generalization of this dynamics to
the two-qubit case cannot directly be simulated in a way that allows quantum
memory to be observed. Nevertheless, we present an alternative toy example that
demonstrates how quantum memory of two-qubit dynamics can be witnessed using
current noisy quantum computers.

</details>


### [257] [Quantum computation of molecular geometry via many-body nuclear spin echoes](https://arxiv.org/abs/2510.19550)
*C. Zhang,R. G. Cortiñas,A. H. Karamlou,N. Noll,J. Provazza,J. Bausch,S. Shirobokov,A. White,M. Claassen,S. H. Kang,A. W. Senior,N. Tomašev,J. Gross,K. Lee,T. Schuster,W. J. Huggins,H. Celik,A. Greene,B. Kozlovskii,F. J. H. Heras,A. Bengtsson,A. Grajales Dau,I. Drozdov,B. Ying,W. Livingstone,V. Sivak,N. Yosri,C. Quintana,D. Abanin,A. Abbas,R. Acharya,L. Aghababaie Beni,G. Aigeldinger,R. Alcaraz,S. Alcaraz,T. I. Andersen,M. Ansmann,F. Arute,K. Arya,W. Askew,N. Astrakhantsev,J. Atalaya,B. Ballard,J. C. Bardin,H. Bates,M. Bigdeli Karimi,A. Bilmes,S. Bilodeau,F. Borjans,A. Bourassa,J. Bovaird,D. Bowers,L. Brill,P. Brooks,M. Broughton,D. A. Browne,B. Buchea,B. B. Buckley,T. Burger,B. Burkett,J. Busnaina,N. Bushnell,A. Cabrera,J. Campero,H. -S. Chang,S. Chen,Z. Chen,B. Chiaro,L. -Y. Chih,A. Y. Cleland,B. Cochrane,M. Cockrell,J. Cogan,R. Collins,P. Conner,H. Cook,W. Courtney,A. L. Crook,B. Curtin,S. Das,M. Damyanov,D. M. Debroy,L. De Lorenzo,S. Demura,L. B. De Rose,A. Di Paolo,P. Donohoe,A. Dunsworth,V. Ehimhen,A. Eickbusch,A. M. Elbag,L. Ella,M. Elzouka,D. Enriquez,C. Erickson,V. S. Ferreira,M. Flores,L. Flores Burgos,E. Forati,J. Ford,A. G. Fowler,B. Foxen,M. Fukami,A. W. L. Fung,L. Fuste,S. Ganjam,G. Garcia,C. Garrick,R. Gasca,H. Gehring,R. Geiger,É. Genois,W. Giang,C. Gidney,D. Gilboa,J. E. Goeders,E. C. Gonzales,R. Gosula,S. J. de Graaf,D. Graumann,J. Grebel,J. Guerrero,J. D. Guimarães,T. Ha,S. Habegger,T. Hadick,A. Hadjikhani,M. P. Harrigan,S. D. Harrington,J. Hartshorn,S. Heslin,P. Heu,O. Higgott,R. Hiltermann,J. Hilton,H. -Y. Huang,M. Hucka,C. Hudspeth,A. Huff,E. Jeffrey,S. Jevons,Z. Jiang,X. Jin,C. Joshi,P. Juhas,A. Kabel,H. Kang,K. Kang,R. Kaufman,K. Kechedzhi,T. Khattar,M. Khezri,S. Kim,R. King,O. Kiss,P. V. Klimov,C. M. Knaut,B. Kobrin,F. Kostritsa,J. M. Kreikebaum,R. Kudo,B. Kueffler,A. Kumar,V. D. Kurilovich,V. Kutsko,N. Lacroix,D. Landhuis,T. Lange-Dei,B. W. Langley,P. Laptev,K. -M. Lau,L. Le Guevel,J. Ledford,J. Lee,B. J. Lester,W. Leung,L. Li,W. Y. Li,M. Li,A. T. Lill,M. T. Lloyd,A. Locharla,D. Lundahl,A. Lunt,S. Madhuk,A. Maiti,A. Maloney,S. Mandra,L. S. Martin,O. Martin,E. Mascot,P. Masih Das,D. Maslov,M. Mathews,C. Maxfield,J. R. McClean,M. McEwen,S. Meeks,K. C. Miao,R. Molavi,S. Molina,S. Montazeri,C. Neill,M. Newman,A. Nguyen,M. Nguyen,C. -H. Ni,M. Y. Niu,L. Oas,R. Orosco,K. Ottosson,A. Pagano,S. Peek,D. Peterson,A. Pizzuto,E. Portoles,R. Potter,O. Pritchard,M. Qian,A. Ranadive,M. J. Reagor,R. Resnick,D. M. Rhodes,D. Riley,G. Roberts,R. Rodriguez,E. Ropes,E. Rosenberg,E. Rosenfeld,D. Rosenstock,E. Rossi,D. A. Rower,M. S. Rudolph,R. Salazar,K. Sankaragomathi,M. C. Sarihan,K. J. Satzinger,M. Schaefer,S. Schroeder,H. F. Schurkus,A. Shahingohar,M. J. Shearn,A. Shorter,N. Shutty,V. Shvarts,S. Small,W. C. Smith,D. A. Sobel,R. D. Somma,B. Spells,S. Springer,G. Sterling,J. Suchard,A. Szasz,A. Sztein,M. Taylor,J. P. Thiruraman,D. Thor,D. Timucin,E. Tomita,A. Torres,M. M. Torunbalci,H. Tran,A. Vaishnav,J. Vargas,S. Vdovichev,G. Vidal,C. Vollgraff Heidweiller,M. Voorhees,S. Waltman,J. Waltz,S. X. Wang,B. Ware,J. D. Watson,Y. Wei,T. Weidel,T. White,K. Wong,B. W. K. Woo,C. J. Wood,M. Woodson,C. Xing,Z. J. Yao,P. Yeh,J. Yoo,E. Young,G. Young,A. Zalcman,R. Zhang,Y. Zhang,N. Zhu,N. Zobrist,Z. Zou,G. Bortoli,S. Boixo,J. Chen,Y. Chen,M. Devoret,M. Hansen,C. Jones,J. Kelly,P. Kohli,A. Korotkov,E. Lucero,J. Manyika,Y. Matias,A. Megrant,H. Neven,W. D. Oliver,G. Ramachandran,R. Babbush,V. Smelyanskiy,P. Roushan,D. Kafri,R. Sarpong,D. W. Berry,C. Ramanathan,X. Mi,C. Bengs,A. Ajoy,Z. K. Minev,N. C. Rubin,T. E. O'Brien*

Main category: quant-ph

TL;DR: 利用量子核磁共振谱OTOC测量技术，结合量子计算，提高了分子结构学习的精度和效率。


<details>
  <summary>Details</summary>
Motivation: 量子信息学方法可能为克服核磁共振波谱在分子结构和性质测定方面的挑战提供新途径。

Method: 测量有机分子的OTOCs，并利用这些数据增强分子动力学模型，校正力场近似。在量子处理器上模拟分子OTOCs，并采用零噪声外推技术提高精度。

Result: 在测量甲苯的邻位氢-氢距离和3',5'-二甲基联苯的二面角方面，取得了与独立光谱测量相当的精度和准确度。通过零噪声外推技术，在所有使用的电路上实现了均方根误差0.05。

Conclusion: 提出了一种利用低资源量子计算来解释核磁系统的多体回声的计算方案，展示了量子信息学在分子结构学习中的潜力。

Abstract: Quantum-information-inspired experiments in nuclear magnetic resonance
spectroscopy may yield a pathway towards determining molecular structure and
properties that are otherwise challenging to learn. We measure
out-of-time-ordered correlators (OTOCs) [1-4] on two organic molecules
suspended in a nematic liquid crystal, and investigate the utility of this data
in performing structural learning tasks. We use OTOC measurements to augment
molecular dynamics models, and to correct for known approximations in the
underlying force fields. We demonstrate the utility of OTOCs in these models by
estimating the mean ortho-meta H-H distance of toluene and the mean dihedral
angle of 3',5'-dimethylbiphenyl, achieving similar accuracy and precision to
independent spectroscopic measurements of both quantities. To ameliorate the
apparent exponential classical cost of interpreting the above OTOC data, we
simulate the molecular OTOCs on a Willow superconducting quantum processor,
using AlphaEvolve-optimized [5] quantum circuits and arbitrary-angle fermionic
simulation gates. We implement novel zero-noise extrapolation techniques based
on the Pauli pathing model of operator dynamics [6], to repeat the learning
experiments with root-mean-square error $0.05$ over all circuits used. Our work
highlights a computational protocol to interpret many-body echoes from nuclear
magnetic systems using low resource quantum computation.

</details>


### [258] [Quantum charging advantage based on power bounds can be deceptive](https://arxiv.org/abs/2510.19552)
*Sreeram PG,J. Bharathi Kannan,M. S. Santhanam*

Main category: quant-ph

TL;DR: 即使在一个简单的自旋链模型中，表面上的量子充电优势也可能因为不精确的界限而出现，但实际上这种优势并不存在。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探究一个简单的量子电池模型（所有到所有耦合的自旋链）是否以及如何在不精确的界限下展现出充电优势，并对其进行更深入的分析。

Method: 通过分析一个包含2-局域相互作用的量子电池自旋链模型，利用不确定性原理导出的上界来评估充电行为，并与先前文献中的模型进行比较。此外，还通过在能量本征空间中分析电池的演化来获得一个更紧确的界限，并探讨在特定物理情况下的局限性。

Result: 不确定性原理导出的上界表明，该模型（包括电池和充电器）表现出超大规模充电（apparent quantum advantage）。然而，在能量本征空间中进行更精确的分析后，这种优势消失了。此外，更紧确的界限在某些物理情况下也会失效。

Conclusion: 不能仅仅依赖于不确定性原理导出的上界来声称量子充电优势。必须谨慎地计算实际传输的功率，以避免虚假的量子优势。

Abstract: We demonstrate that an all-to-all coupled spin-chain model of a quantum
battery with 2-local interactions exhibits superextensive charging when
analysed using the upper bound derived from the uncertainty principle. Unlike
the previously studied models in the literature, the contribution to this
apparent quantum advantage arises from both the battery and the charger, and it
does not require long-range couplings. However, on closer analysis of the
charging using the battery evolution in the energy eigenspace, the advantage
vanishes. Moreover, this tighter bound can also fail in certain physical
situations. One has to exercise caution and compute the actual power
transferred before claiming a quantum advantage.

</details>


### [259] [Zero-field identification and control of hydrogen-related electron-nuclear spin registers in diamond](https://arxiv.org/abs/2510.19598)
*Alexander Ungar,Hao Tang,Andrew Stasiuk,Bo Xing,Boning Li,Ju Li,Alexandre Cooper,Paola Cappellaro*

Main category: quant-ph

TL;DR: 本研究提出了一种结合零场双电子电子共振 (ZF-DEER) 和核电子电子三重共振 (NEETR) 的方法，用于识别自旋缺陷的超精细分量和核自旋种类。通过该方法，研究人员对两个未知的缺陷进行了单自旋级别的表征，并成功识别了一种新的氢缺陷结构和一种先前已知的氮缺陷结构。此外，研究人员还演示了对氢缺陷核自旋量子比特的初始化、幺正控制和长寿命相干性，其相干时间 T2 = 1.0(3) ms。


<details>
  <summary>Details</summary>
Motivation: 电子-核自旋缺陷可以作为量子比特构建混合量子寄存器，但许多缺陷的特性尚不明确，这阻碍了它们在可扩展器件中的应用。

Method: 结合零场双电子电子共振 (ZF-DEER) 和核电子电子三重共振 (NEETR) 来表征自旋缺陷的超精细分量和核自旋种类。

Result: 成功识别了一种新的氢缺陷结构和一种先前已知的氮缺陷结构。对氢缺陷核自旋量子比特进行了初始化、幺正控制和长寿命相干性演示，T2 = 1.0(3) ms。

Conclusion: 该研究提出的表征和控制工具为扩展用于混合电子-核量子寄存器的缺陷种类提供了框架，并有望在量子传感、量子网络和室温原子尺度磁共振成像等领域实现应用。

Abstract: Spin defects in diamond serve as powerful building blocks for quantum
technologies, especially for applications in quantum sensing and quantum
networks. Electron-nuclear defects formed in the environment of optically
active spins, such as the nitrogen-vacancy (NV) center, can be harnessed as
qubits to construct larger hybrid quantum registers. However, many of these
defects have yet to be characterized, limiting their integration into scalable
devices. Here, we introduce an approach to identify the hyperfine components
and nuclear spin species of spin defects through measurements on a nearby NV
center. This approach combines double electron-electron resonance performed at
zero field (ZF-DEER) with nuclear-electron-electron triple resonance (NEETR),
which we use to characterize two unknown defects at the single-spin level,
yielding self-consistent results. These results provide a guide to resolving
the defect structures using $\textit{ab initio}$ calculations, leading to the
identification of a new hydrogen defect structure and an accurate match to a
previously identified nitrogen defect. Building on the NEETR protocol, we then
demonstrate initialization, unitary control, and long-lived coherence of the
nuclear spin qubit of the hydrogen defect with $T_2 = 1.0(3)\,\mathrm{ms}$. Our
characterization and control tools establish a framework to expand the
accessible defect landscape for hybrid electron-nuclear registers and enable
applications in quantum sensing, networks, and atomic-scale magnetic resonance
imaging at room temperature.

</details>


### [260] [Heisenberg-Limited Quantum Eigenvalue Estimation for Non-normal Matrices](https://arxiv.org/abs/2510.19651)
*Yukun Zhang,Yusen Wu,Xiao Yuan*

Main category: quant-ph

TL;DR: 我们提出了一种新的量子算法，用于估计非厄米矩阵的特征值，该算法通过定制的量子模拟和经典信号处理实现，并达到了海森堡极限精度。


<details>
  <summary>Details</summary>
Motivation: 估计非厄米矩阵的特征值在从模拟非厄米量子系统到分析复杂流体动力学等领域具有重要意义，但目前量子算法难以解决此问题。

Method: 通过定制的量子模拟协议构建特征值信号，并使用先进的经典信号处理技术提取它们，以估计一般非厄米矩阵的特征值。

Result: 当输入纯量量子态时，该算法能够达到海森堡极限精度，实现最优性能。

Conclusion: 该工作将强大的引导局域哈密顿量框架扩展到非厄米领域，为解决线性代数中最具挑战性的问题之一奠定了严格且可扩展的量子计算方法基础。

Abstract: Estimating the eigenvalues of non-normal matrices is a foundational problem
with far-reaching implications, from modeling non-Hermitian quantum systems to
analyzing complex fluid dynamics. Yet, this task remains beyond the reach of
standard quantum algorithms, which are predominantly tailored for Hermitian
matrices. Here we introduce a new class of quantum algorithms that directly
address this challenge. The central idea is to construct eigenvalue signals
through customized quantum simulation protocols and extract them using advanced
classical signal-processing techniques, thereby enabling accurate and efficient
eigenvalue estimation for general non-normal matrices. Crucially, when supplied
with purified quantum state inputs, our algorithms attain Heisenberg-limited
precision--achieving optimal performance. These results extend the powerful
guided local Hamiltonian framework into the non-Hermitian regime, significantly
broadening the frontier of quantum computational advantage. Our work lays the
foundation for a rigorous and scalable quantum computing approach to one of the
most demanding problems in linear algebra.

</details>


### [261] [Universal bound on the Lyapunov spectrum of quantum master equations](https://arxiv.org/abs/2510.19657)
*Paolo Muratore-Ginanneschi,Gen Kimura,Frederik vom Ende,Dariusz Chruściński*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The spectral properties of positive maps provide pivotal information for
understanding the dynamics of quantum systems interacting with their
environment. Furthermore, central problems in quantum information such as the
characterization of entanglement may be reformulated in terms of spectral
properties of positive maps. The present work aims to contribute to a better
understanding of the spectrum of positive maps. Specifically, our main result
is a new proof of a universal bound on the $d^{2}-1$ generically non vanishing
decay rates $\Gamma_{i}$ of time-autonomous quantum master equations on a
$d$-dimensional Hilbert space: $$
  \Gamma_{\mathrm{max}}\,\leq\,c_{d}\,\sum_{i=1}^{d^{2}-1}\Gamma_{i}
  \nonumber $$ The prefactor $c_{d}$ , which we explicitly determine, depends
only on the dimension $d$ and varies depending on the sub-class of positive
maps to which the semigroup solution of the master equation belongs. We provide
a brief but self-consistent survey of these concepts. We obtain our main result
by resorting to the theory of Lyapunov exponents, a central concept in the
study of dynamical systems, control theory, and out-of-equilibrium statistical
mechanics. We thus show that progress in understanding positive maps in quantum
mechanics may require ideas at the crossroads between different disciplines.
For this reason, we adopt a notation and presentation style aimed at reaching
readers with diverse backgrounds.

</details>


### [262] [Classical theories of gravity produce entanglement](https://arxiv.org/abs/2510.19714)
*Joseph Aziz,Richard Howl*

Main category: quant-ph

TL;DR: 量子技术和引力理论的结合有望实现对引力是否遵循量子力学定律的首次实验检验。


<details>
  <summary>Details</summary>
Motivation: 探索引力与量子力学的统一，并提出实验方案验证引力是否遵循量子力学。

Method: 将质量物体置于量子叠加态，通过引力相互作用使两个物体发生量子纠缠，并使用量子场论扩展了引力相互作用的描述，以区分经典引力和量子引力。

Result: 发现经典引力理论在量子场论框架下可以传递量子信息并产生纠缠，且该效应的标度与量子引力理论的预测不同。

Conclusion: 实验结果可为区分量子引力理论和经典引力理论提供依据，并为设计相关实验提供参数指导。

Abstract: The unification of gravity and quantum mechanics remains one of the most
profound open questions in science. With recent advances in quantum technology,
an experimental idea first proposed by Richard Feynman is now regarded as a
promising route to testing this unification for the first time. The experiment
involves placing a massive object in a quantum superposition of two locations
and letting it gravitationally interact with another mass. If the two objects
subsequently become entangled, this is considered unambiguous evidence that
gravity obeys the laws of quantum mechanics. This conclusion derives from
theorems that treat a classical gravitational interaction as a local
interaction capable of only transmitting classical, not quantum, information.
Here, we extend the description of the gravitational interaction used in these
theorems to the full framework of quantum field theory, finding that theories
with classical gravity can then transmit quantum information, and thus generate
entanglement through physical, local processes. The effect scales differently
to that predicted by theories of quantum gravity, providing information on the
parameters and form of the experiment required to robustly evidence the quantum
nature of gravity.

</details>


### [263] [Entanglement production in the decay of a metastable state](https://arxiv.org/abs/2510.19715)
*Sergei Khlebnikov*

Main category: quant-ph

TL;DR: 当一个亚稳态衰减产生辐射时，辐射和衰减系统之间，以及收集到的早期和晚期辐射之间必然存在纠缠。我们研究了这些纠缠在简单高斯模型中的相互作用。通过窗口傅里叶变换定义了与不同时间产生的辐射碎片相关联的多模量子态，并计算了相应的纠缠熵增量。基于这些结果，我们认为这种熵增量是有用的纠缠度量，尤其是在像霍金辐射这样的情况下，人们希望将辐射分离成“旧”和“新”。


<details>
  <summary>Details</summary>
Motivation: 研究亚稳态衰减产生的辐射中的两种纠缠（辐射与衰减系统之间，以及早期和晚期辐射之间）的相互作用。

Method: 定义与辐射碎片相关联的多模量子态，并计算纠缠熵增量。

Result: 计算了纠缠熵增量。

Conclusion: 熵增量是有用的纠缠度量，尤其适用于将辐射分离成“旧”和“新”的情况，例如霍金辐射。

Abstract: When a metastable state decays into radiation, there must be entanglement
between the radiation and the decaying system, as well as between radiation
collected at late and early times. We study the interplay between these two
types of entanglement in simple Gaussian models. We define, via a windowed
Fourier transform, multimode quantum states associated with radiation fragments
produced at different times and compute the corresponding entanglement entropy
increments. On the basis of these results, we argue that such entropy
increments are useful entanglement measures, especially in cases, such as
Hawking radiation, where one wishes to separate the radiation into ``old'' and
``new.''

</details>


### [264] [Explicitly Quantum-parallel Computation by Displacements](https://arxiv.org/abs/2510.19730)
*Uchenna Chukwu,Mohammad-Ali Miri,Nicholas Chancellor*

Main category: quant-ph

TL;DR: 通过利用光学模式的相对位移或光子数来编码信息，并提出一种受保护且保真度高的方法来创建量子叠加态，以实现量子并行处理和光学量子退火。


<details>
  <summary>Details</summary>
Motivation: 由于干扰损耗率对压缩和许多非高斯涨落不敏感，因此信息编码空间能有效抵抗不完美因素的影响。

Method: 通过光子减法协议创建高质量的压缩态量子叠加态，该方法比仅限于生成猫态的协议具有更高的保真度。

Result: 光子减法协议能以远高于仅限于猫态的协议的保真度创建高质量的压缩态量子叠加态。所引入的压缩和反压缩程度适中，不太可能主导光子数。这种并行处理允许明确利用非高斯干涉。光学模式的位移为量子并行处理提供了方便的信息编码自由度。

Conclusion: 光学量子退火器的实现需要进行损耗通道的量子擦除，并能纠正未用于编码的自由度，同时不破坏已处理的量子信息。

Abstract: We introduce an encoding of information in the relative displacement or
photon number of different optical modes. Since the loss rate to interference
is insensitive to squeezing and many non-Gaussian fluctuations, such a space is
relatively protected from imperfections. We show that photon subtraction
protocols can be used to create high-quality quantum superpositions of squeezed
states with much higher fidelity than when the protocol is restricted to
producing only cat states (superpositions of coherent states). We also show
that the amount of squeezing and anti-squeezing introduced is moderate, and
unlikely to dominate the photon number. This parallel processing allows for
explicit use of non-Gaussian interference as opposed to the more incidental
role played by non-Gaussianity in all-optical coherent Ising machines. A key
observation we make is that displacements of optical states provide a
convenient degree of freedom to encode information for quantum parallel
processing. Furthermore, we discuss important considerations for realizing an
optical quantum annealer based on differential photon number encoding. In
particular, we discuss the need to perform quantum erasure on loss channels
from interference, as well as the ability to correct degrees of freedom not
used for the encoding without disrupting the processed quantum information.

</details>


### [265] [A simplified version of the quantum OTOC$^{(2)}$ problem](https://arxiv.org/abs/2510.19751)
*Robbie King,Robin Kothari,Ryan Babbush,Sergio Boixo,Kostyantyn Kechedzhi,Thomas E. O'Brien,Vadim Smelyanskiy*

Main category: quant-ph

TL;DR: 本文提出了一个简化版的OTOC问题，该问题近期已被Google Quantum AI及其合作者通过实验实现。


<details>
  <summary>Details</summary>
Motivation: 为OTOC问题提供一个简化的形式，并鼓励对该问题进行更多的理论研究。

Method: 本文没有详细介绍具体方法，而是提出了一个针对不断增长的输入规模的OTOC问题。

Result: 本文没有详细介绍具体结果，但提到了OTOC问题已被谷歌量子AI及其合作者通过实验实现。

Conclusion: 本文旨在通过提供一个简化的OTOC问题形式，激发对该问题更深入的理论研究。

Abstract: This note presents a simplified version of the OTOC$^{(2)}$ problem that was
recently experimentally implemented by Google Quantum AI and collaborators. We
present a formulation of the problem for growing input size and hope this spurs
further theoretical work on the problem.

</details>


### [266] [Quantum Coherence in Superconducting Vortex States](https://arxiv.org/abs/2510.19769)
*Ameya Nambisan,Simon Günzler,Dennis Rieger,Nicolas Gosling,Simon Geisert,Victor Carpentier,Nicolas Zapata,Mitchell Field,Milorad V. Milošević,Carlos A. Diaz Lopez,Ciprian Padurariu,Björn Kubala,Joachim Ankerhold,Wolfgang Wernsdorfer,Martin Spiecker,Ioan M. Pop*

Main category: quant-ph

TL;DR: In granular superconducting films, vortices can act as two-level quantum systems with microsecond to millisecond coherence times, opening new possibilities for quantum technologies.


<details>
  <summary>Details</summary>
Motivation: The paper aims to present evidence for vortices in granular superconducting films behaving as two-level systems, contrasting with the dissipative nature of Abrikosov vortices and supporting theoretical models of granular superconductors as tunnel junction networks.

Method: The study utilizes circuit quantum electrodynamics to perform coherent manipulation and quantum non-demolition readout of vortex states in granular aluminum microwave resonators.

Result: Evidence is presented that vortices trapped in granular superconducting films can exhibit quantum coherence with microsecond-range coherence and energy relaxation times reaching fractions of a millisecond, behaving as two-level systems.

Conclusion: Vortices in granular superconductors can function as quantum two-level systems, suggesting new avenues for quantum information processing, materials characterization, and sensing.

Abstract: Abrikosov vortices, where the superconducting gap is completely suppressed in
the core, are dissipative, semi-classical entities that impact applications
from high-current-density wires to superconducting quantum devices. In
contrast, we present evidence that vortices trapped in granular superconducting
films can behave as two-level systems, exhibiting microsecond-range quantum
coherence and energy relaxation times that reach fractions of a millisecond.
These findings support recent theoretical modeling of superconductors with
granularity on the scale of the coherence length as tunnel junction networks,
resulting in gapped vortices. Using the tools of circuit quantum
electrodynamics, we perform coherent manipulation and quantum non-demolition
readout of vortex states in granular aluminum microwave resonators, heralding
new directions for quantum information processing, materials characterization,
and sensing.

</details>


### [267] [Passive quantum error correction of photon loss at breakeven](https://arxiv.org/abs/2510.19794)
*Shruti Shirol,Sean van Geldern,Hanzhe Xi,Chen Wang*

Main category: quant-ph

TL;DR: 通过使用由超导腔和transmon辅助器组成的稳态驱动耗散量子系统，并采用二项编码，量子比特可以超越光子寿命限制保存约5%。


<details>
  <summary>Details</summary>
Motivation: 物理量子比特（通常表示为单个粒子或激发态的叠加态）的激发态衰减是量子计算中的基本错误通道。虽然量子纠错码通过将信息编码在涉及多个激发的叠加态中来克服这个问题，但它们通常需要精密的实时操作。本文旨在展示一种可以克服这些挑战的方法。

Method: 研究使用由超导腔和transmon辅助器组成的稳态驱动耗散量子系统。通过采用二项编码，该系统能够实现量子比特的保护。

Result: 在实验中，量子比特的寿命超越了光子寿命限制，延长了约5%。

Conclusion: 该研究实现了一个在临界点连续进行的量子纠错过程，证明了被动纠错策略在实际应用中的可行性和竞争力，同时规避了主动纠错策略的一些高硬件要求。

Abstract: Physical qubits in a quantum computer are often represented by superposition
states of single particles or excitations. Decay of the excitation itself is a
fundamental error channel that is difficult to overcome via external drive or
control techniques. Quantum error correcting codes, which encode information in
superpositions involving multiple excitations, provide a path to preserve
information beyond the capacity of individual excitations, but typically
require exquisite active operations on the system. Here, we demonstrate a
steady-state driven dissipative quantum system, composed of a superconducting
cavity and a transmon ancilla, that preserves a logical qubit beyond the
photon-lifetime limit by about 5% using a binomial encoding. This realization
of continuous quantum error correction at the breakeven point highlights the
quantitative competitiveness of passive correction strategies while
circumventing some demanding hardware requirements of its active counterparts.

</details>


### [268] [Good quantum codes with addressable and parallelizable non-Clifford gates](https://arxiv.org/abs/2510.19809)
*Virgile Guemard*

Main category: quant-ph

TL;DR: 本文研究了一类量子纠错码，并展示了如何并行执行可寻址和横向的多控制Z门，从而减少了多控制Z电路的深度开销。


<details>
  <summary>Details</summary>
Motivation: 现有量子纠错码在执行多控制Z门时存在效率问题，本研究旨在提高其性能。

Method: 利用Stichtenoth的经典码构建量子CSS码，并扩展到可寻址和横向的多控制Z门，特别是C^mZ门，实现了并行执行。

Result: 证明了对于任意m，存在一类量子纠错码，其逻辑C^mZ门可以寻址特定逻辑qudit并并行执行。

Conclusion: 通过并行执行逻辑C^mZ门，显著降低了多控制Z电路的深度开销，为量子计算提供了更优的方案。

Abstract: We revisit a family of good quantum error-correcting codes presented in He
$\textit{et al.}$ (2025), and we show that various sets of addressable and
transversal non-Clifford multi-control-$Z$ gates can be performed in parallel.
The construction relies on the good classical codes of Stichtenoth (IEEE Trans.
Inf. Theory, 2006), which were previously instantiated in He $\textit{et al.}$
(2025), to yield quantum CSS codes over which addressable logical
$\mathsf{CCZ}$ gates can be performed at least one at a time. Here, we show
that for any $m$, there exists a family of good quantum error-correcting codes
over qudits for which logical $\mathsf{C}^{m}\mathsf{Z}$ gates can address
specific logical qudits and be performed in parallel. This leads to a
significant advantage in the depth overhead of multi-control-$Z$ circuits.

</details>


### [269] [Atomic-superfluid heat engines controlled by twisted light](https://arxiv.org/abs/2510.19821)
*Aritra Ghosh,Nilamoni Daloi,M. Bhattacharya*

Main category: quant-ph

TL;DR: 利用轨道角动量的光学场和腔增强的光-原子耦合，我们提出了一个量子热机模型。


<details>
  <summary>Details</summary>
Motivation: 本文旨在提出一种利用量子系统实现热机的理论模型，并探索轨道角动量对热机性能的影响。

Method: 该模型使用腔增强的光-原子耦合，产生极化激元模式，通过改变失谐量可以控制模式性质，从而实现功的提取。分析了效率与轨道角动量的关系，并讨论了有限时间内的操作以及绝热消除机械模式的替代方案。

Result: 研究表明，极化激元模式的性质可以通过失谐量可逆地切换，从而实现功的提取。轨道角动量可以作为调控量子热机性能的实验可控参数。

Conclusion: 本文提出的量子热机模型，利用轨道角动量可以有效地调控其性能，为量子热机的研究提供了新的方向。

Abstract: We theoretically propose a quantum heat engine using a setup consisting of a
ring-trapped Bose-Einstein condensate placed in a Fabry--P\'erot cavity where
the optical fields carry orbital angular momentum. We first show that the
cavity-enhanced light-atom coupling leads to the emergence of polaritonic
modes, whose character can be reversibly switched between photonlike and
phononlike by detuning sweeps allowing work extraction governed by distinct
reservoirs. We investigate the dependence of the engine efficiency on the
orbital angular momentum. Beyond ideality, we discuss finite-time scenarios
based on shortcuts to adiabaticity such that the efficiency retains its
ideal-operation value, despite finite-time challenges. Finally, for lower
values of the orbital angular momentum, we describe an alternate scheme for
operating quantum heat engines based on the adiabatic elimination of a
mechanical mode. Our analysis identifies orbital angular momentum as an
experimentally-accessible control knob that can reconfigure the performance of
such quantum heat engines as desired.

</details>


### [270] [Quantum walks as a tool to design robust quantum batteries: the role of topology and chirality](https://arxiv.org/abs/2510.19823)
*Simone Cavazzoni,Giovanni Ragazzi,Paolo Bordone,Matteo G. A. Paris*

Main category: quant-ph

TL;DR: 文章研究了量子电池的拓扑结构和哈密顿量的手性如何影响其能量存储性能，并提出拓扑和手性是优化量子电池性能的关键资源。


<details>
  <summary>Details</summary>
Motivation: 量子电池最大可提取功受限于其本料金量，而本料金量由系统的谱特性决定。本文旨在探索量子电池的拓扑结构和哈密顿量的手性如何影响其性能。

Method: 利用量子行走的形式主义，分析了基于环形、完全图和轮状图结构的电池单元的性能，并考虑了噪声的影响。

Result: 结果表明，不同的拓扑结构具有不同的本料金量缩放特性。手性和拓扑的相互作用提供了一种优化功提取和增强抗退相干能力的机制。具体来说，手性增强了完全量子电池的本料金量，且不改变其随尺寸的线性缩放；在环状电池中，手性缩小了奇数个和偶数个单元的配置之间的性能差距。此外，手性还可以用来强制哈密顿量简并，从而避免在纯粹退相干的情况下本料金量消失。

Conclusion: 拓扑和手性是提高量子电池本料金量的关键资源，为优化量子能量设备和协议提供了指导。

Abstract: The maximum work that can be extracted from a quantum battery is bounded by
the ergotropy of the system, which is determined by the spectral properties of
the Hamiltonian. In this paper, we employ the formalism of quantum walks to
investigate how the topology of the battery and the chirality of the
Hamiltonian influence its performance as an energy storage unit. We analyze
architectures of battery cells based on ring, complete, and wheel graph
structures and analyze their behavior in the presence of noise. Our results
show that these structures exhibit distinct ergotropy scaling, with the
interplay between chirality and topology providing a tunable mechanism to
optimize work extraction and enhance robustness against decoherence. In
particular, chirality enhances ergotropy for complete quantum cells, without
altering the linear scaling with size, whereas in ring cells, it bridges the
performance gap between configurations with odd and even number of units.
Additionaly, chirality may be exploited to force degeneracies in the
Hamiltonian, a condition that can spare the ergotropy to vanish in the presence
of pure dephasing. We conclude that topology and chirality are key resources
for improving ergotropy, offering guidelines to optimize quantum energy devices
and protocols.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [271] [From Unweighted to Weighted Dynamic Matching in Non-Bipartite Graphs: A Low-Loss Reduction](https://arxiv.org/abs/2510.19049)
*Aaron Bernstein,Jiale Chen*

Main category: cs.DS

TL;DR: 本研究提出了一种新的元算法，将完全动态图中的近似最大权重匹配（MWM）问题归约到无权近似最大基数匹配（MCM）问题，显著减少了近似损失。


<details>
  <summary>Details</summary>
Motivation: 在完全动态图上解决近似最大权重匹配（MWM）问题，并弥合现有算法在非二部图上近似损失大的问题。

Method: 提出了一种新的对偶框架，将一般图中的近似MWM问题计算转化为辅助二部图上的近似诱导匹配查询序列。

Result: 实现了从完全动态（1-ε）近似MCM算法到一般图（非必部图）完全动态（1-ε）近似MWM算法的低损失归约，更新时间开销仅为poly(log n/ε)。

Conclusion: 本研究为完全动态图上的近似MWM问题提供了首个低损失归约方法，并首次给出了近似部分动态匹配的条件最优下界。

Abstract: We study the approximate maximum weight matching (MWM) problem in a fully
dynamic graph subject to edge insertions and deletions. We design
meta-algorithms that reduce the problem to the unweighted approximate maximum
cardinality matching (MCM) problem. Despite recent progress on bipartite graphs
-- Bernstein-Dudeja-Langley (STOC 2021) and
Bernstein-Chen-Dudeja-Langley-Sidford-Tu (SODA 2025) -- the only previous
meta-algorithm that applied to non-bipartite graphs suffered a $\frac{1}{2}$
approximation loss (Stubbs-Williams, ITCS 2017). We significantly close the
weighted-and-unweighted gap by showing the first low-loss reduction that
transforms any fully dynamic $(1-\varepsilon)$-approximate MCM algorithm on
bipartite graphs into a fully dynamic $(1-\varepsilon)$-approximate MWM
algorithm on general (not necessarily bipartite) graphs, with only a
$\mathrm{poly}(\log n/\varepsilon)$ overhead in the update time. Central to our
approach is a new primal-dual framework that reduces the computation of an
approximate MWM in general graphs to a sequence of approximate induced matching
queries on an auxiliary bipartite extension. In addition, we give the first
conditional lower bound on approximate partially dynamic matching with
worst-case update time.

</details>


### [272] [Succinct Dynamic Rank/Select: Bypassing the Tree-Structure Bottleneck](https://arxiv.org/abs/2510.19175)
*William Kuszmaul,Jingxun Liang,Renfei Zhou*

Main category: cs.DS

TL;DR: 动态有序字典在插入/删除/排序/选择操作上实现了O(1 + log n / log log U)的最优摊销期望时间复杂度，并且空间复杂度接近最优，解决了Pibiri和Venturini关于是否可能实现o(n)比特冗余的问题，并首次动态绕过了“树结构瓶颈”。


<details>
  <summary>Details</summary>
Motivation: 解决Pibiri和Venturini提出的关于动态有序字典是否能实现o(n)比特冗余的开放性问题，并突破“树结构瓶颈”。

Method: 构建了一个名为“压缩制表加权搜索二叉树”的动态平衡二叉搜索树，实现了O(log U)比特的总空间冗余，若n和U已知则为O(1)比特。

Result: 该动态有序字典实现了O(1 + log n / log log U)的最优摊销期望时间复杂度，空间复杂度接近最优，总空间冗余为O(log U)比特（若n和U已知则为O(1)比特）。

Conclusion: 动态有序字典在时间和空间复杂度上均取得了显著进展，解决了长期存在的理论问题，并为动态树结构的研究提供了新的方向。

Abstract: We show how to construct a dynamic ordered dictionary, supporting
insert/delete/rank/select on a set of $n$ elements from a universe of size $U$,
that achieves the optimal amortized expected time complexity of $O(1 + \log n /
\log \log U)$, while achieving a nearly optimal space consumption of $\log
\binom{U}{n} + n / 2^{(\log n)^{\Omega(1)}} + \text{polylog}\, U$ bits in the
regime where $U = \text{poly}(n)$. This resolves an open question by Pibiri and
Venturini as to whether a redundancy (a.k.a. space overhead) of $o(n)$ bits is
possible, and is the first dynamic solution to bypass the so-called
tree-structure bottleneck, in which the bits needed to encode some dynamic tree
structure are themselves enough to force a redundancy of
$\widetilde{\Omega}(n)$ bits. Our main technical building block is a dynamic
balanced binary search tree, which we call the compressed tabulation-weighted
treap, that itself achieves a surprising time/space tradeoff. The tree supports
$\text{polylog}\, n$-time operations and requires a static lookup table of size
$\text{poly}(n) + \text{polylog}\, U$ -- but, in exchange for these, the tree
is able to achieve a remarkable space guarantee. Its total space redundancy is
$O(\log U)$ bits. In fact, if the tree is given $n$ and $U$ for free, then the
redundancy further drops to $O(1)$ bits.

</details>


### [273] [Online Two-Stage Submodular Maximization](https://arxiv.org/abs/2510.19480)
*Iasonas Nikolaou,Miltiadis Stouras,Stratis Ioannidis,Evimaria Terzi*

Main category: cs.DS

TL;DR: 所提出在线双阶段子模最大化（O2SSM）问题，在权重阈值势函数和一般拟阵约束下，实现了次线性（1 - 1/e）^2 -遗憾，在均匀拟阵秩 k 下，实现了（1 - 1/e）（1 - e^{-k} k^k / k!）-遗憾，此算法还能解决离线2SSM问题，并在真实数据集上进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: 在现有两阶段子模最大化（2SSM）问题基础上，提出在线两阶段子模最大化（O2SSM）问题，旨在解决子模目标函数在线出现的情况。

Method: 设计了一种算法，在一般拟阵约束下达到 (1 - 1/e)^2 - 遗憾，在均匀拟阵秩 k 下达到 (1 - 1/e)(1 - e^{-k} k^k / k!) - 遗憾。

Result: 提出的算法在一般拟阵约束下实现了次线性（1 - 1/e)^2 - 遗憾，在均匀拟阵秩 k 下实现了（1 - 1/e）（1 - e^{-k} k^k / k!）-遗憾，该算法还能解决离线2SSM问题。

Conclusion: 提出的O2SSM算法在真实数据集上表现良好，并且在理论上具有竞争力的遗憾界限。

Abstract: Given a collection of monotone submodular functions, the goal of Two-Stage
Submodular Maximization (2SSM) [Balkanski et al., 2016] is to restrict the
ground set so an objective selected u.a.r. from the collection attains a high
maximal value, on average, when optimized over the restricted ground set. We
introduce the Online Two-Stage Submodular Maximization (O2SSM) problem, in
which the submodular objectives are revealed in an online fashion. We study
this problem for weighted threshold potential functions, a large and important
subclass of monotone submodular functions that includes influence maximization,
data summarization, and facility location, to name a few. We design an
algorithm that achieves sublinear $(1 - 1/e)^2$-regret under general matroid
constraints and $(1 - 1/e)(1-e^{-k}k^k/k!)$-regret in the case of uniform
matroids of rank $k$; the latter also yields a state-of-the-art bound for the
(offline) 2SSM problem. We empirically validate the performance of our online
algorithm with experiments on real datasets.

</details>


### [274] [A Logic-based Algorithmic Meta-Theorem for Treedepth: Single Exponential FPT Time and Polynomial Space](https://arxiv.org/abs/2510.19793)
*Benjamin Bergougnoux,Vera Chekan,Giannos Stamoulis*

Main category: cs.DS

TL;DR: 本文介绍了一种名为NEO2[FRec]+ACK的逻辑，用于在具有深度为k的消除森林的图上研究NP难问题。该逻辑能够统一和扩展现有的算法，提供2^O(k)n^O(1)的时间和n^O(1)的空间复杂度。对于不包含连通性和无环性约束的NEO2[FRec]片段，空间复杂度可进一步降低到O(k log n)。


<details>
  <summary>Details</summary>
Motivation: 为了处理NP难问题，如独立集和哈密顿回路，并在具有特定结构的图（消除森林）上实现高效算法。

Method: 通过引入一种新的逻辑（NEO2[FRec]+ACK），该逻辑扩展了全存在二阶逻辑（MSO2），并加入了查询顶点集邻域、验证连通性和无环性、以及验证顶点集诱导生成团的谓词。基于此逻辑，设计了一个模型检查算法。

Result: NEO2[FRec]+ACK逻辑能够捕获所有已知在时间2^O(k)n^O(1)和空间n^O(1)内可解的NP难问题。特别地，NEO2[FRec]片段能够捕获CNF-SAT和一些计数问题。对于NEO2[FRec]片段，算法的空间复杂度降至O(k log n)。

Conclusion: 本文提出的NEO2[FRec]+ACK逻辑及其模型检查算法，为一类NP难问题提供了统一且高效的算法框架，并且在空间复杂度上有所改进。

Abstract: For a graph $G$, the parameter treedepth measures the minimum depth among all
forests $F$, called elimination forests, such that $G$ is a subgraph of the
ancestor-descendant closure of $F$. We introduce a logic, called neighborhood
operator logic with acyclicity, connectivity and clique constraints
($\mathsf{NEO}_2[\mathsf{FRec}]+\mathsf{ACK}$ for short), that captures all
NP-hard problems$\unicode{x2013}$like Independent Set or Hamiltonian
Cycle$\unicode{x2013}$that are known to be tractable in time
$2^{\mathcal{O}(k)}n^{\mathcal{O}(1)}$ and space $n^{\mathcal{O}(1)}$ on
$n$-vertex graphs provided with elimination forests of depth $k$. We provide a
model checking algorithm for $\mathsf{NEO}_2[\mathsf{FRec}]+\mathsf{ACK}$ with
such complexity that unifies and extends these results. For
$\mathsf{NEO}_2[\mathsf{FRec}]+\mathsf{k}$, the fragment of the above logic
that does not use acyclicity and connectivity constraints, we get a
strengthening of this result, where the space complexity is reduced to
$\mathcal{O}(k\log(n))$.
  With a similar mechanism as the distance neighborhood logic introduced in
[Bergougnoux, Dreier and Jaffke, SODA 2023], the logic
$\mathsf{NEO}_2[\mathsf{FRec}]+\mathsf{ACK}$ is an extension of the
fully-existential $\mathsf{MSO}_2$ with predicates for (1) querying
generalizations of the neighborhoods of vertex sets, (2) verifying the
connectivity and acyclicity of vertex and edge sets, and (3) verifying that a
vertex set induces a clique. Our results provide
$2^{\mathcal{O}(k)}n^{\mathcal{O}(1)}$ time and $n^{\mathcal{O}(1)}$ space
algorithms for problems for which the existence of such algorithms was
previously unknown. In particular, $\mathsf{NEO}_2[\mathsf{FRec}]$ captures
CNF-SAT via the incidence graphs associated to CNF formulas, and it also
captures several modulo counting problems like Odd Dominating Set.

</details>


### [275] [Optimal Random Access and Conditional Lower Bounds for 2D Compressed Strings](https://arxiv.org/abs/2510.19750)
*Rajat De,Dominik Kempa*

Main category: cs.DS

TL;DR: 本论文提出了针对二维字符串的压缩索引方案，解决了现有技术在处理二维数据时的效率和压缩问题。


<details>
  <summary>Details</summary>
Motivation: 现有的一维压缩索引技术在处理高压缩率的二维数据（如图、地图、邻接矩阵等）时效率低下，因为数据线性化会破坏其固有的二维结构。因此，需要开发能够同时保持压缩率和查询效率的原生二维压缩索引方案。

Method: 本文提出了三种主要贡献：1. 设计了一个数据结构，能够以最优时间实现二维语法压缩的二维字符串的随机访问，空间复杂度为O(|G|log^{2+ε}n)，查询时间为O(log n / log log n)。2. 证明了在正交向量猜想下，二维语法压缩字符串的模式匹配问题不存在O(|G|^{2-ε}·|P|^{O(1)})时间复杂度的算法，这与一维情况不同。3. 证明了在二维语法压缩字符串上的二维最长公共扩展、矩形求和和相等性查询在硬性假设下无法高效支持，将二维压缩索引的复杂性与一维压缩字符串的长期遗留问题联系起来。

Result: 1. 实现了二维语法压缩字符串的随机访问，查询时间为O(log n / log log n)，空间复杂度为O(|G|log^{2+ε}n)。 2. 证明了二维语法压缩字符串的模式匹配问题的条件性下界。 3. 揭示了二维压缩索引的几个基本查询的硬度。

Conclusion: 本文在二维压缩索引领域取得了三项重要进展，包括高效的随机访问结构、模式匹配的下界证明以及与一维问题硬度相关联的查询复杂性，为处理二维压缩数据提供了新的理论基础。

Abstract: Compressed indexing is a powerful technique that enables efficient querying
over data stored in compressed form, significantly reducing memory usage and
often accelerating computation. While extensive progress has been made for
one-dimensional strings, many real-world datasets (such as images, maps, and
adjacency matrices) are inherently two-dimensional and highly compressible.
Unfortunately, naively applying 1D techniques to 2D data leads to suboptimal
results, as fundamental structural repetition is lost during linearization.
This motivates the development of native 2D compressed indexing schemes that
preserve both compression and query efficiency.
  We present three main contributions that advance the theory of compressed
indexing for 2D strings: (1) We design the first data structure that supports
optimal-time random access to a 2D string compressed by a 2D grammar.
Specifically, for a 2D string $T\in\Sigma^{r\times c}$ compressed by a 2D
grammar $G$ and any constant $\epsilon>0$, we achieve $O(\log n/\log \log n)$
query time and $O(|G|\log^{2+\epsilon}n)$ space, where $n=\max(r,c)$. (2) We
prove conditional lower bounds for pattern matching over 2D-grammar compressed
strings. Assuming the Orthogonal Vectors Conjecture, no algorithm can solve
this problem in time $O(|G|^{2-\epsilon}\cdot |P|^{O(1)})$ for any
$\epsilon>0$, demonstrating a separation from the 1D case, where optimal
solutions exist. (3) We show that several fundamental 2D queries, such as the
2D longest common extension, rectangle sum, and equality, cannot be supported
efficiently under hardness assumptions for rank and symbol occurrence queries
on 1D grammar-compressed strings. This is the first evidence connecting the
complexity of 2D compressed indexing to long-standing open problems in the 1D
setting.

</details>


### [276] [Strongly Polynomial Parallel Work-Depth Tradeoffs for Directed SSSP](https://arxiv.org/abs/2510.19780)
*Adam Karczmarz,Wojciech Nadara,Marek Sokołowski*

Main category: cs.DS

TL;DR: 该论文在具有非负权重的定向图中，针对单源最短路径（SSSP）问题，提出了新的强多项式工作-深度权衡。


<details>
  <summary>Details</summary>
Motivation: 为了在并行计算中解决单源最短路径（SSSP）问题，特别是在具有非负权重的定向图中。

Method: 利用新的强多项式工作-深度权衡来实现。

Result: 证明了定向SSSP可以在 $	ilde{O}(m+n^{2-\epsilon})$ 的工作量和 $	ilde{O}(n^{1-\epsilon})$ 的深度内解决，其中 $\epsilon>0$。对于稠密图，实现了具有亚线性深度的近乎高效的强多项式算法。该算法可改进最小成本流、分配问题和最小平均环的动态算法。此外，还为具有指数级大边权重的图的SSSP变体开发了Word RAM模型下的并行算法。

Conclusion: 在具有非负权重的定向图中，单源最短路径（SSSP）问题在并行计算中取得了显著的进展，实现了更优的工作量-深度权衡，并对相关问题产生了积极影响。

Abstract: In this paper, we show new strongly polynomial work-depth tradeoffs for
computing single-source shortest paths (SSSP) in non-negatively weighted
directed graphs in parallel. Most importantly, we prove that directed SSSP can
be solved within $\tilde{O}(m+n^{2-\epsilon})$ work and
$\tilde{O}(n^{1-\epsilon})$ depth for some positive $\epsilon>0$. In
particular, for dense graphs with non-negative real weights, we provide the
first nearly work-efficient strongly polynomial algorithm with sublinear depth.
  Our result immediately yields improved strongly polynomial parallel
algorithms for min-cost flow and the assignment problem. It also leads to the
first non-trivial strongly polynomial dynamic algorithm for minimum mean cycle.
Moreover, we develop efficient parallel algorithms in the Word RAM model for
several variants of SSSP in graphs with exponentially large edge weights.

</details>


### [277] [Explaining the Inherent Tradeoffs for Suffix Array Functionality: Equivalences between String Problems and Prefix Range Queries](https://arxiv.org/abs/2510.19815)
*Dominik Kempa,Tomasz Kociumaka*

Main category: cs.DS

TL;DR: 本文提出了首个双向约减，证明了后缀数组查询在查询时间上与前缀选择查询在所有参数上等价（相差 O(log log n) 的加法项），统一了现有方法，并将后缀数组查询的效率分析和改进与前缀查询模型联系起来。


<details>
  <summary>Details</summary>
Motivation: 研究如何在无法显式存储后缀数组的情况下，高效地访问其条目。

Method: 提出了一种新的双向约减方法，将后缀数组查询的效率问题转化为前缀选择查询问题。

Result: 证明了后缀数组查询与前缀选择查询在所有参数上（查询时间相差 O(log log n)）是等价的，并推广到逆后缀数组查询、模式排名、字典范围和 SA 区间查询等问题，发现了六个核心问题对。

Conclusion: 该框架为通过前缀查询模型分析和改进字符串处理核心问题的效率提供了一个统一的基础。

Abstract: We study the fundamental question of how efficiently suffix array entries can
be accessed when the array cannot be stored explicitly. The suffix array
$SA_T[1..n]$ of a text $T$ of length $n$ encodes the lexicographic order of its
suffixes and underlies numerous applications in pattern matching, data
compression, and bioinformatics. Previous work established one-way reductions
showing how suffix array queries can be answered using, for example, rank
queries on the Burrows-Wheeler Transform. More recently, a new class of prefix
queries was introduced, together with reductions that, among others, transform
a simple tradeoff for prefix-select queries into a suffix array tradeoff
matching state-of-the-art space and query-time bounds, while achieving
sublinear construction time. For binary texts, the resulting data structure
achieves space $O(n)$ bits, preprocessing time $O(n / \sqrt{\log n})$,
preprocessing space of $O(n)$ bits, and query time $O(\log^{\epsilon} n)$ for
any constant $\epsilon > 0$. However, whether these bounds could be improved
using different techniques has remained open.
  We resolve this question by presenting the first bidirectional reduction
showing that suffix array queries are, up to an additive $O(\log\log n)$ term
in query time, equivalent to prefix-select queries in all parameters. This
result unifies prior approaches and shows that essentially all efficient suffix
array representations can be expressed via prefix-select structures. Moreover,
we prove analogous equivalences for inverse suffix array queries, pattern
ranking, lexicographic range, and SA-interval queries, identifying six core
problem pairs that connect string and prefix query models. Our framework thus
provides a unified foundation for analyzing and improving the efficiency of
fundamental string-processing problems through the lens of prefix queries.

</details>


### [278] [Tight Lower Bounds for Central String Queries in Compressed Space](https://arxiv.org/abs/2510.19820)
*Dominik Kempa,Tomasz Kociumaka*

Main category: cs.DS

TL;DR: 该论文研究了压缩数据结构在压缩文本上的查询极限，针对后缀数组（SA）、逆后缀数组（SA$^{-1}$）、最长公共前缀（LCP）数组、最长公共扩展（LCE）、Burrows-Wheeler变换（BWT）等基本查询，分别提出了$m 	ilde{	ilde{O}}(m 	ilde{O}(1))$和$m 	ilde{	ilde{O}}(m 	ilde{O}(m loglog n))$的下界，证明了现有上界的紧确性，并建立了压缩索引理论的完整理论基础。


<details>
  <summary>Details</summary>
Motivation: 现有的压缩数据结构在支持基本查询方面，虽然空间复杂度已经接近理论下界，但查询时间复杂度尚未完全明确，尤其是在随机访问之外的其他查询。本文旨在解决这一差距，为几乎所有基本查询提供精确的时间复杂度界限。

Method: 本文通过理论推导，为后缀数组（SA）、逆后缀数组（SA$^{-1}$）、最长公共前缀（LCP）数组、最长公共扩展（LCE）等查询建立了$m 	ilde{	ilde{O}}(m 	ilde{O}(1))$的下界。同时，也为Burrows-Wheeler变换（BWT）、置换最长公共前缀（PLCP）数组、Last-to-First（LF）查询及其逆查询、以及$m 	ilde{	ilde{O}}$和$m 	ilde{	ilde{O}}$的逆查询建立了$m 	ilde{	ilde{O}}(m 	ilde{O}(m loglog n))$的下界。这些下界在文本为二元字母时也成立。

Result: 本文成功地为SA、SA$^{-1}$、LCP、LCE查询提供了$m 	ilde{	ilde{O}}(m 	ilde{O}(1))$的紧确下界，匹配了已知的上界。同时，为BWT、PLCP、LF及其逆查询、$m 	ilde{	ilde{O}}$及其逆查询提供了$m 	ilde{	ilde{O}}(m 	ilde{O}(m loglog n))$的紧确下界，同样匹配了现有上界。

Conclusion: 该研究为压缩索引领域建立了完整的理论基础，明确了查询时间复杂度的两种可能界限：$m 	ilde{	ilde{O}}(m 	ilde{O}(1))$或$m 	ilde{	ilde{O}}(m 	ilde{O}(m loglog n))$。这为未来的数据结构设计提供了明确的方向，即在最小空间内实现最优查询时间，或在最优空间内实现最快查询时间。

Abstract: In this work, we study the limits of compressed data structures, i.e.,
structures that support various queries on an input text $T\in\Sigma^n$ using
space proportional to the size of $T$ in compressed form. Nearly all
fundamental queries can currently be efficiently supported in
$O(\delta(T)\log^{O(1)}n)$ space, where $\delta(T)$ is the substring
complexity, a strong compressibility measure that lower-bounds the optimal
space to represent the text [Kociumaka, Navarro, Prezza, IEEE Trans. Inf.
Theory 2023]. However, optimal query time has been characterized only for
random access.
  We address this gap by developing tight lower bounds for nearly all other
fundamental queries: (1) We prove that suffix array (SA), inverse suffix array
(SA$^{-1}$), longest common prefix (LCP) array, and longest common extension
(LCE) queries all require $\Omega(\log n/\log\log n)$ time within
$O(\delta(T)\log^{O(1)}n)$ space, matching known upper bounds. (2) We further
show that other common queries, currently supported in $O(\log\log n)$ time and
$O(\delta(T)\log^{O(1)}n)$ space, including the Burrows-Wheeler Transform
(BWT), permuted longest common prefix (PLCP) array, Last-to-First (LF), inverse
LF, lexicographic predecessor ($\Phi$), and inverse $\Phi$ queries, all require
$\Omega(\log\log n)$ time, yielding another set of tight bounds.
  Our lower bounds hold even for texts over a binary alphabet. This work
establishes a clean dichotomy: the optimal time complexity to support central
string queries in compressed space is either $\Theta(\log n/\log\log n)$ or
$\Theta(\log\log n)$. This completes the theoretical foundation of compressed
indexing, closing a crucial gap between upper and lower bounds and providing a
clear target for future data structures: seeking either the optimal time in the
smallest space or the fastest time in the optimal space, both of which are now
known for central string queries.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [279] [Local Guidance for Configuration-Based Multi-Agent Pathfinding](https://arxiv.org/abs/2510.19072)
*Tomoki Arita,Keisuke Okumura*

Main category: cs.MA

TL;DR: 本文提出了一种局部引导方法，用于在多智能体寻路（MAPF）中提高路径规划的效率和质量。


<details>
  <summary>Details</summary>
Motivation: 现有的全局引导方法虽然能提升MAPF性能，但计算量大。本文探索一种替代方法，即提供局部引导，以期在可接受的计算时间内获得更好的结果。

Method: 在LaCAM（一种领先的基于配置的求解器）中引入局部引导机制，该机制为每个智能体在附近区域提供时空线索，以优化其路径规划。

Result: 实验证明，局部引导方法能够在不超出计算时间预算的情况下，显著提高MAPF的解的质量，并在LaCAM上取得了新的性能标杆。

Conclusion: 局部引导是一种有效的方法，可以提升MAPF的性能，即使它需要进行重新计算，但其带来的效益是显著的。

Abstract: Guidance is an emerging concept that improves the empirical performance of
real-time, sub-optimal multi-agent pathfinding (MAPF) methods. It offers
additional information to MAPF algorithms to mitigate congestion on a global
scale by considering the collective behavior of all agents across the entire
workspace. This global perspective helps reduce agents' waiting times, thereby
improving overall coordination efficiency. In contrast, this study explores an
alternative approach: providing local guidance in the vicinity of each agent.
While such localized methods involve recomputation as agents move and may
appear computationally demanding, we empirically demonstrate that supplying
informative spatiotemporal cues to the planner can significantly improve
solution quality without exceeding a moderate time budget. When applied to
LaCAM, a leading configuration-based solver, this form of guidance establishes
a new performance frontier for MAPF.

</details>


### [280] [SORA-ATMAS: Adaptive Trust Management and Multi-LLM Aligned Governance for Future Smart Cities](https://arxiv.org/abs/2510.19327)
*Usama Antuley,Shahbaz Siddiqui,Sufian Hameed,Waqas Arif,Subhan Shah,Syed Attique Shah*

Main category: cs.MA

TL;DR: SORA-ATMAS是一个面向智能城市的、合规的、可验证的治理框架，用于整合分布式代理输出，实现负责任的实时决策。


<details>
  <summary>Details</summary>
Motivation: 智能城市依赖自主决策和自适应协调的Agentic AI，以优化基础设施、资源和市民福祉，但在异构智能城市生态系统中部署Agentic AI面临治理、风险和合规性（GRC）方面的挑战，例如问责制、数据隐私和法规遵从性。

Method: 评估了SORA-ATMAS框架，其中包含三个领域代理（天气、交通和安全），并使用GPT、Grok和DeepSeek等多种大型语言模型。该框架具有治理策略和高风险场景的后备机制，以引导模型产生符合策略的、针对领域优化的输出。

Result: SORA-ATMAS在三个代理中的平均平均绝对误差（MAE）降低了35%。在天气监控、高风险交通处理（0.85）和安全/火灾场景（0.65）中取得了稳定的结果。3代理部署的运行时分析显示了可扩展性，吞吐量为13.8-17.2请求/秒，执行时间低于72毫秒，治理延迟低于100毫秒。跨域规则确保了安全互操作性，例如，仅在验证天气条件下才允许交通重新规划。

Conclusion: SORA-ATMAS是一个符合法规、上下文感知且可验证的治理框架，它整合了分布式代理的输出，实现了负责任的实时决策，为智能城市管理提供了有弹性的基础。

Abstract: The rapid evolution of smart cities has increased the reliance on intelligent
interconnected services to optimize infrastructure, resources, and citizen
well-being. Agentic AI has emerged as a key enabler by supporting autonomous
decision-making and adaptive coordination, allowing urban systems to respond in
real time to dynamic conditions. Its benefits are evident in areas such as
transportation, where the integration of traffic data, weather forecasts, and
safety sensors enables dynamic rerouting and a faster response to hazards.
However, its deployment across heterogeneous smart city ecosystems raises
critical governance, risk, and compliance (GRC) challenges, including
accountability, data privacy, and regulatory alignment within decentralized
infrastructures. Evaluation of SORA-ATMAS with three domain agents (Weather,
Traffic, and Safety) demonstrated that its governance policies, including a
fallback mechanism for high-risk scenarios, effectively steer multiple LLMs
(GPT, Grok, DeepSeek) towards domain-optimized, policy-aligned outputs,
producing an average MAE reduction of 35% across agents. Results showed stable
weather monitoring, effective handling of high-risk traffic plateaus 0.85, and
adaptive trust regulation in Safety/Fire scenarios 0.65. Runtime profiling of a
3-agent deployment confirmed scalability, with throughput between 13.8-17.2
requests per second, execution times below 72~ms, and governance delays under
100 ms, analytical projections suggest maintained performance at larger scales.
Cross-domain rules ensured safe interoperability, with traffic rerouting
permitted only under validated weather conditions. These findings validate
SORA-ATMAS as a regulation-aligned, context-aware, and verifiable governance
framework that consolidates distributed agent outputs into accountable,
real-time decisions, offering a resilient foundation for smart-city management.

</details>


### [281] [ColorAgent: Building A Robust, Personalized, and Interactive OS Agent](https://arxiv.org/abs/2510.19386)
*Ning Li,Qiqiang Lin,Zheng Wu,Xiaoyun Mo,Weiming Zhang,Yin Zhao,Xiangmou Qu,Jiamu Zhou,Jun Wang,Congmin Zheng,Yuanyi Song,Hongjiang Chen,Heyuan Huang,Jihong Wang,Jiaxin Yin,Jingwei Yu,Junwei Liao,Qiuying Peng,Xingyu Lou,Jun Wang,Weiwen Liu,Zhuosheng Zhang,Weinan Zhang*

Main category: cs.MA

TL;DR: ColorAgent是一个操作系统代理，能够进行长期、鲁棒的用户交互，并实现个性化和主动的用户互动。


<details>
  <summary>Details</summary>
Motivation: 随着硬件、软件和大型语言模型技术的发展，人机操作系统交互正从命令行界面转向新兴的AI代理交互。构建能够执行用户指令并忠实遵循用户意愿的操作系统（OS）代理已成为现实。

Method: ColorAgent通过逐步强化学习和自进化训练来增强模型能力，以实现与环境的长期交互；同时，开发了定制化的多代理框架来确保通用性、一致性和鲁棒性。在用户交互方面，探索了个性化用户意图识别和主动参与，将OS代理定位为协作伙伴。

Result: 在AndroidWorld和AndroidLab基准测试中，ColorAgent分别达到了77.2%和50.7%的成功率，创下新的技术水平。

Conclusion: ColorAgent在操作系统代理领域取得了显著进展，但目前的基准测试尚不足以全面评估OS代理的性能。未来的工作需要进一步探索评估范式、代理协作和安全性等方向。

Abstract: With the advancements in hardware, software, and large language model
technologies, the interaction between humans and operating systems has evolved
from the command-line interface to the rapidly emerging AI agent interactions.
Building an operating system (OS) agent capable of executing user instructions
and faithfully following user desires is becoming a reality. In this technical
report, we present ColorAgent, an OS agent designed to engage in long-horizon,
robust interactions with the environment while also enabling personalized and
proactive user interaction. To enable long-horizon interactions with the
environment, we enhance the model's capabilities through step-wise
reinforcement learning and self-evolving training, while also developing a
tailored multi-agent framework that ensures generality, consistency, and
robustness. In terms of user interaction, we explore personalized user intent
recognition and proactive engagement, positioning the OS agent not merely as an
automation tool but as a warm, collaborative partner. We evaluate ColorAgent on
the AndroidWorld and AndroidLab benchmarks, achieving success rates of 77.2%
and 50.7%, respectively, establishing a new state of the art. Nonetheless, we
note that current benchmarks are insufficient for a comprehensive evaluation of
OS agents and propose further exploring directions in future work, particularly
in the areas of evaluation paradigms, agent collaboration, and security. Our
code is available at https://github.com/MadeAgents/mobile-use.

</details>


### [282] [Modeling realistic human behavior using generative agents in a multimodal transport system: Software architecture and Application to Toulouse](https://arxiv.org/abs/2510.19497)
*Trung-Dung Vu,Benoit Gaudou,Kamaldeep Singh Oberoi*

Main category: cs.MA

TL;DR: 该研究提出了一种结合大语言模型（LLM）和基于智能体的仿真方法，用于模拟复杂多模式交通系统中真实的人类出行行为，旨在提供个性化的出行解决方案。


<details>
  <summary>Details</summary>
Motivation: 在复杂的城市环境中，模拟真实的人类出行行为以理解其出行方式选择并提供个性化出行方案仍然是一个挑战。

Method: 利用大语言模型（LLM）构建生成式智能体，并将其集成到GAMA仿真平台中，结合GTFS公共交通数据和OpenTripPlanner进行多模式路径规划，以在城市环境中模拟出行决策过程。

Result: 在为期一个月的仿真中，结果表明智能体不仅能做出符合情境的出行决策，而且会随着时间的推移形成出行习惯。

Conclusion: 将LLM与基于智能体的仿真相结合，为智能交通系统和个性化多模式出行解决方案的进步提供了一个有前景的方向。

Abstract: Modeling realistic human behaviour to understand people's mode choices in
order to propose personalised mobility solutions remains challenging. This
paper presents an architecture for modeling realistic human mobility behavior
in complex multimodal transport systems, demonstrated through a case study in
Toulouse, France. We apply Large Language Models (LLMs) within an agent-based
simulation to capture decision-making in a real urban setting. The framework
integrates the GAMA simulation platform with an LLM-based generative agent,
along with General Transit Feed Specification (GTFS) data for public transport,
and OpenTripPlanner for multimodal routing. GAMA platform models the
interactive transport environment, providing visualization and dynamic agent
interactions while eliminating the need to construct the simulation environment
from scratch. This design enables a stronger focus on developing generative
agents and evaluating their performance in transport decision-making processes.
Over a simulated month, results show that agents not only make context-aware
transport decisions but also form habits over time. We conclude that combining
LLMs with agent-based simulation offers a promising direction for advancing
intelligent transportation systems and personalised multimodal mobility
solutions. We also discuss some limitations of this approach and outline future
work on scaling to larger regions, integrating real-time data, and refining
memory models.

</details>


### [283] [Polynomial-time Configuration Generator for Connected Unlabeled Multi-Agent Pathfinding](https://arxiv.org/abs/2510.19567)
*Takahiro Suzuki,Keisuke Okumura*

Main category: cs.MA

TL;DR: CUMAPF问题旨在解决多智能体寻路中的连通性问题，提出了一种名为PULL的算法，该算法能够保证在寻路过程中智能体之间的连通性，并在实验中表现出良好的性能。


<details>
  <summary>Details</summary>
Motivation: CUMAPF是多智能体寻路（MAPF）的一个变种，它要求智能体在整个移动过程中必须保持连通性。这对于机器人集群应用（如自重构和行进）至关重要，因为标准的MAPF无法保证这种连通性。然而，CUMAPF即使在受限图上也是NP难问题。

Method: 提出了一种名为PULL的算法，这是一种基于规则的单步函数，旨在计算能够保持连通性并向目标配置移动的下一步配置。PULL算法设计简单，具有完备性和多项式时间复杂度，在二维网格上每步运行时间为O(n^2)，其中n是智能体数量。

Result: 实验表明，PULL算法在随机生成的实例中，对于数百个智能体，能够找到与简单解决方案相媲美的解的质量。此外，还开发了一种结合PULL的搜索基础MAPF算法的最终最优求解器，该求解器适用于小规模实例。

Conclusion: PULL算法为解决CUMAPF问题提供了一个有效且轻量级的解决方案，能够在保证智能体连通性的同时实现高效寻路，并在实验中验证了其在实际应用中的可行性和性能。

Abstract: We consider Connected Unlabeled Multi-Agent Pathfinding (CUMAPF), a variant
of MAPF where the agents must maintain connectivity at all times. This problem
is fundamental to swarm robotics applications like self-reconfiguration and
marching, where standard MAPF is insufficient as it does not guarantee the
required connectivity between agents. While unlabeled MAPF is tractable in
optimization, CUMAPF is NP-hard even on highly restricted graph classes. To
tackle this challenge, we propose PULL, a complete and polynomial-time
algorithm with a simple design. It is based on a rule-based one-step function
that computes a subsequent configuration that preserves connectivity and
advances towards the target configuration. PULL is lightweight, and runs in
$O(n^2)$ time per step in 2D grid, where $n$ is the number of agents. Our
experiments further demonstrate its practical performance: PULL finds
competitive solution qualities against trivial solutions for hundreds of
agents, in randomly generated instances. Furthermore, we develop an eventually
optimal solver that integrates PULL into an existing search-based MAPF
algorithm, providing a valuable tool for small-scale instances.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [284] [Refugees of the Digital Space: Platform Migration from TikTok to RedNote](https://arxiv.org/abs/2510.18894)
*Ziyue Feng,Tianjia Dong,Zheya Lei*

Main category: cs.SI

TL;DR: 美国用户因TikTok禁令涌入ReNote，高影响力用户更倾向于发布文化相关或商业策略性内容，政治讨论被选择性激活，用户的情感表达方式因影响力而异。


<details>
  <summary>Details</summary>
Motivation: 研究美国用户在TikTok被禁后迁移至ReNote平台时，如何适应跨文化环境并制定沟通策略。

Method: 采用多方法框架，分析了三个迁移阶段（禁令前、难民潮、稳定期）的时间发帖模式、影响力动态、主题偏好和情感加权话题表达。使用熵加权影响力得分区分高低影响力用户。

Result: 主要话题（如自我表达、生活方式、创意）保持稳定。高影响力用户更可能发布文化共鸣或商业策略性内容。政治话语被选择性地用于跨国交流。高影响力用户在文化连接话题上更积极，低影响力用户在个人叙事上情感更强烈。

Conclusion: 跨文化平台迁移不仅受平台结构影响，还取决于用户适应、表演和维持可见性的能力。研究对平台社会学、情感公众和跨国数字环境中的用户能动性有贡献。

Abstract: In January 2025, the U.S. government enacted a nationwide ban on TikTok,
prompting a wave of American users -- self-identified as ``TikTok Refugees'' --
to migrate to alternative platforms, particularly the Chinese social media app
RedNote (Xiaohongshu). This paper examines how these digital migrants navigate
cross-cultural platform environments and develop adaptive communicative
strategies under algorithmic governance. Drawing on a multi-method framework,
the study analyzes temporal posting patterns, influence dynamics, thematic
preferences, and sentiment-weighted topic expressions across three distinct
migration phases: Pre-Ban, Refugee Surge, and Stabilization.
  An entropy-weighted influence score was used to classify users into high- and
low-influence groups, enabling comparative analysis of content strategies.
Findings reveal that while dominant topics remained relatively stable over time
(e.g., self-expression, lifestyle, and creativity), high-influence users were
more likely to engage in culturally resonant or commercially strategic content.
Additionally, political discourse was not avoided, but selectively activated as
a point of transnational engagement.
  Emotionally, high-influence users tended to express more positive affect in
culturally connective topics, while low-influence users showed stronger
emotional intensity in personal narratives. These findings suggest that
cross-cultural platform migration is shaped not only by structural affordances
but also by users' differential capacities to adapt, perform, and maintain
visibility. The study contributes to literature on platform society, affective
publics, and user agency in transnational digital environments.

</details>


### [285] [The Value of Patience in Online Grocery Shopping](https://arxiv.org/abs/2510.19066)
*Javad Eshtiyagh,Pei Zhao,Federico Librino,Giovanni Resta,Paolo Santi,Martina Mazzarello,Akanksha Khurd,Santo Fortunato,Carlo Ratti*

Main category: cs.SI

TL;DR: 虽然疫情加速了在线杂货购物的增长，但这也加剧了交通拥堵和污染。本研究探讨了消费者对配送时间的“耐心”（即愿意等待的时间）如何影响交通负荷，并提出了一个数学模型。通过分析迪拜的800多万份订单数据，研究发现，仅增加5分钟的配送时间就能减少约30%的配送里程和20%的二氧化碳排放，但超过10分钟后，效益递减。


<details>
  <summary>Details</summary>
Motivation: 在线杂货购物的快速增长加剧了城市交通拥堵、排放和污染，但关于个体便利性与社会成本之间权衡的研究却很少。

Method: 提出一个数学模型，并利用网络科学方法，结合迪拜超过800万份的杂货订单数据集进行分析。

Result: 研究发现，消费者对配送时间的耐心（即容忍度）与交通拥堵之间存在凸性关系。将配送时间延长5分钟可减少约30%的每日配送里程和20%的生命周期二氧化碳排放，但超过10分钟后，效益将显著递减。

Conclusion: 适度增加消费者的耐心可以显著减少交通拥堵和污染，并提高可持续性，为平衡城市配送系统中个人便利性与社会福利提供了一种可行的策略。

Abstract: Since the COVID-19 pandemic, online grocery shopping has rapidly reshaped
consumer behavior worldwide, fueled by ever-faster delivery promises aimed at
maximizing convenience. Yet, this growth has also substantially increased urban
traffic congestion, emissions, and pollution. Despite extensive research on
urban delivery optimization, little is known about the trade-off between
individual convenience and these societal costs. In this study, we investigate
the value of marginal extensions in delivery times, termed customer patience,
in mitigating the traffic burden caused by grocery deliveries. We first
conceptualize the problem and present a mathematical model that highlights a
convex relationship between patience and traffic congestion. The theoretical
predictions are confirmed by an extensive, network-science based analysis
leveraging two large-scale datasets encompassing over 8 million grocery orders
in Dubai. Our findings reveal that allowing just five additional minutes in
delivery time reduces daily delivery mileage by approximately 30 percent and
life-cycle CO2 emissions by 20 percent. Beyond ten minutes of added patience,
however, marginal benefits diminish significantly. These results highlight that
modest increases in consumer patience can deliver substantial gains in traffic
reduction and sustainability, offering a scalable strategy to balance
individual convenience with societal welfare in urban delivery systems.

</details>


### [286] [UniqueRank: Identifying Important and Difficult-to-Replace Nodes in Attributed Graphs](https://arxiv.org/abs/2510.19113)
*Erica Cai,Benjamin A. Miller,Olga Simek,Christopher L. Smith*

Main category: cs.SI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Node-ranking methods that focus on structural importance are widely used in a
variety of applications, from ranking webpages in search engines to identifying
key molecules in biomolecular networks. In real social, supply chain, and
terrorist networks, one definition of importance considers the impact on
information flow or network productivity when a given node is removed. In
practice, however, a nearby node may be able to replace another node upon
removal, allowing the network to continue functioning as before. This
replaceability is an aspect that existing ranking methods do not consider. To
address this, we introduce UniqueRank, a Markov-Chain-based approach that
captures attribute uniqueness in addition to structural importance, making
top-ranked nodes harder to replace. We find that UniqueRank identifies
important nodes with dissimilar attributes from its neighbors in simple
symmetric networks with known ground truth. Further, on real terrorist, social,
and supply chain networks, we demonstrate that removing and attempting to
replace top UniqueRank nodes often yields larger efficiency reductions than
removing and attempting to replace top nodes ranked by competing methods.
Finally, we show UniqueRank's versatility by demonstrating its potential to
identify structurally critical atoms with unique chemical environments in
biomolecular structures.

</details>


### [287] [Belief propagation for finite networks using a symmetry-breaking source node](https://arxiv.org/abs/2510.19231)
*Seongmin Kim,Alec Kirkley*

Main category: cs.SI

TL;DR: 固定单个“源”节点状态可提高置信传播算法在稀疏网络中的推断准确性，且不增加计算成本。


<details>
  <summary>Details</summary>
Motivation: 置信传播（BP）算法在有限系统中，尤其是在很少有环的稀疏网络中，对于估计序参数及其易感性常常产生不准确的估计。

Method: 通过固定单个连接良好的“源”节点的状态来打破全局对称性，以改进推断准确性并捕捉有限尺寸效应。

Result: 在过滤模型和伊辛模型上，该方法在广泛的网络（尤其是树状网络）上均能显著提高推断准确性，且计算成本无明显增加。

Conclusion: 固定单个“源”节点的状态是一种简单有效的方法，可以显著提高BP算法在有限稀疏系统中的推断准确性，并且能够捕捉到有限尺寸效应。

Abstract: Belief Propagation (BP) is an efficient message-passing algorithm widely used
for inference in graphical models and for solving various problems in
statistical physics. However, BP often yields inaccurate estimates of order
parameters and their susceptibilities in finite systems, particularly in sparse
networks with few loops. Here, we show for both percolation and Ising models
that fixing the state of a single well-connected "source" node to break global
symmetry substantially improves inference accuracy and captures finite-size
effects across a broad range of networks, especially tree-like ones, at no
additional computational cost.

</details>


### [288] [From Newborn to Impact: Bias-Aware Citation Prediction](https://arxiv.org/abs/2510.19246)
*Mingfei Lu,Mengjia Wu,Jiawei Xu,Weikai Li,Feng Liu,Ying Ding,Yizhou Sun,Jie Lu,Yi Zhang*

Main category: cs.SI

TL;DR: 该研究提出一个偏见感知引用预测框架，通过多智能体特征提取和图表示学习来弥补现有模型在隐式因素建模和对低引用论文预测稳定性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 引用预测对于评估研究影响力、学术推荐和知识传播研究至关重要，尤其是在缺乏引用信号且分布高度长尾的新生论文早期评估中。现有方法在建模科学影响的隐式因素和处理低引用论文的偏见方面存在不足。

Method: 提出一个偏见感知引用预测框架，结合多智能体特征提取和鲁棒图表示学习。该框架通过多智能体图协同学习模块提取可解释的信号（如可复现性、合作网络、文本质量），并与异构网络嵌入融合。同时，引入两阶段前向过程、GroupDRO和正则化头等鲁棒机制来优化预测。

Result: 在两个真实世界数据集上的实验表明，与基线方法相比，该模型在MALE和RMSLE等错误指标上减少了约13%，在NDCG排名指标上提高了5.5%。

Conclusion: 所提出的偏见感知引用预测框架能够有效提升对新生论文的引用预测能力，尤其是在处理早期缺乏引用信号和低引用论文方面。

Abstract: As a key to accessing research impact, citation dynamics underpins research
evaluation, scholarly recommendation, and the study of knowledge diffusion.
Citation prediction is particularly critical for newborn papers, where early
assessment must be performed without citation signals and under highly
long-tailed distributions. We identify two key research gaps: (i) insufficient
modeling of implicit factors of scientific impact, leading to reliance on
coarse proxies; and (ii) a lack of bias-aware learning that can deliver stable
predictions on lowly cited papers. We address these gaps by proposing a
Bias-Aware Citation Prediction Framework, which combines multi-agent feature
extraction with robust graph representation learning. First, a multi-agent x
graph co-learning module derives fine-grained, interpretable signals, such as
reproducibility, collaboration network, and text quality, from metadata and
external resources, and fuses them with heterogeneous-network embeddings to
provide rich supervision even in the absence of early citation signals. Second,
we incorporate a set of robust mechanisms: a two-stage forward process that
routes explicit factors through an intermediate exposure estimate, GroupDRO to
optimize worst-case group risk across environments, and a regularization head
that performs what-if analyses on controllable factors under monotonicity and
smoothness constraints. Comprehensive experiments on two real-world datasets
demonstrate the effectiveness of our proposed model. Specifically, our model
achieves around a 13% reduction in error metrics (MALE and RMSLE) and a notable
5.5% improvement in the ranking metric (NDCG) over the baseline methods.

</details>


### [289] [Unfair Mistakes on Social Media: How Demographic Characteristics influence Authorship Attribution](https://arxiv.org/abs/2510.19708)
*Jasmin Wyss,Rebekah Overdorf*

Main category: cs.SI

TL;DR: 本研究系统性地审计了跨性别、母语和年龄的作者身份归因模型的偏见，发现在封闭世界设定下模型表现公平，但在错误不可避免时，模型倾向于将作者身份归因给具有相同人口统计学特征的作者。


<details>
  <summary>Details</summary>
Motivation: 在线场景（如 the sock puppet detection，恶意账户关联，跨平台账户关联）中，作者身份归因技术日益重要，但其在不同人群中的公平性未知。偏见可能导致错误指控、账户禁止和侵犯隐私，不成比例地影响某些人群。

Method: 首先，评估了特定人群特征比例对分类器整体性能的影响；其次，评估了用户人群特征是否会影响其文本被错误分类的概率；最后，在真实作者被排除在嫌疑人集合之外的情况下，评估了发生的错误类型，强制分类器选择一个错误的作者。

Result: 在封闭世界设定下，作者身份归因没有表现出跨人群的偏见。然而，在真实作者被排除在嫌疑人集合之外的情况下，模型倾向于将作者身份归因给与真实作者具有相同人群特征的作者，即使文本风格与作者的平均风格非常接近。

Conclusion: 尽管一个模型在一个表现良好的封闭世界设定下可能看起来公平，但这并不能保证在错误不可避免时模型仍然公平。

Abstract: Authorship attribution techniques are increasingly being used in online
contexts such as sock puppet detection, malicious account linking, and
cross-platform account linking. Yet, it is unknown whether these models perform
equitably across different demographic groups. Bias in such techniques could
lead to false accusations, account banning, and privacy violations
disproportionately impacting users from certain demographics. In this paper, we
systematically audit authorship attribution for bias with respect to gender,
native language, and age. We evaluate fairness in 3 ways. First, we evaluate
how the proportion of users with a certain demographic characteristic impacts
the overall classifier performance. Second, we evaluate if a user's demographic
characteristics influence the probability that their texts are misclassified.
Our analysis indicates that authorship attribution does not demonstrate bias
across demographic groups in the closed-world setting. Third, we evaluate the
types of errors that occur when the true author is removed from the suspect
set, thereby forcing the classifier to choose an incorrect author. Unlike the
first two settings, this analysis demonstrates a tendency to attribute
authorship to users who share the same demographic characteristic as the true
author. Crucially, these errors do not only include texts that deviate from a
user's usual style, but also those that are very close to the author's average.
Our results highlight that though a model may appear fair in the closed-world
setting for a performant classifier, this does not guarantee fairness when
errors are inevitable.

</details>


### [290] [From Substitution to Complement? Uncovering the Evolving Interplay between Ride-hailing Services and Public Transit](https://arxiv.org/abs/2510.19745)
*Zhicheng Jin,Xiaotong Sun,Li Zhen,Weihua Gu,Huizhao Tu*

Main category: cs.SI

TL;DR: TNC与公共交通（PT）的关系可能正在从替代关系转变为互补关系，上海的研究表明两者比例相当，且距离地铁站和公交站点的密度等因素存在非线性影响。


<details>
  <summary>Details</summary>
Motivation: 探索TNC市场成熟过程中，TNC与公共交通（PT）之间关系的变化，即从替代关系转变为互补关系。

Method: 利用2022年9月上海96,716辆网约车出行数据，构建数据驱动框架，将TNC-PT关系分为首末端互补、替代和独立四种类型。并采用CatBoost和SHAP模型分析影响因素的非线性效应。

Result: 研究发现，TNC出行与PT的互补（9.22%）和替代（9.06%）比例相当。距离最近地铁站和公交站点密度等因素对TNC-PT关系有显著的非线性影响。地铁枢纽站和普通单线路地铁站对首末端互补比例的影响不同。距离单线路地铁站的距离与互补比例呈现倒U型关系，在1.5公里内急剧上升，在1.5至3公里之间达到峰值，之后随着距离增加至15公里而下降。

Conclusion: TNC与PT的关系具有复杂性，互补和替代关系并存，且受多种因素的非线性影响，这与以往研究的观点有所不同。

Abstract: The literature on transportation network companies (TNCs), also known as
ride-hailing services, has often characterized these service providers as
predominantly substitutive to public transit (PT). However, as TNC markets
expand and mature, the complementary and substitutive relationships with PT may
shift. To explore whether such a transformation is occurring, this study
collected travel data from 96,716 ride-hailing vehicles during September 2022
in Shanghai, a city characterized by an increasingly saturated TNC market. An
enhanced data-driven framework is proposed to classify TNC-PT relationships
into four types: first-mile complementary, last-mile complementary,
substitutive, and independent. Our findings indicate comparable ratios of
complementary trips (9.22%) and substitutive trips (9.06%), contrasting sharply
with the findings of prior studies. Furthermore, to examine the nonlinear
impact of various influential factors on these ratios, a machine learning
method integrating categorical boosting (CatBoost) and Shapley additive
explanations (SHAP) is proposed. The results show significant nonlinear effects
in some variables, including the distance to the nearest metro station and the
density of bus stops. Moreover, metro hubs and regular single-line stations
exhibit distinct effects on first- or last-mile complementary ratios. These
ratios' relation to the distance to single-line stations shows an inverted
U-shaped pattern, with effects rising sharply within 1.5 km, remaining at the
peak between 1.5 and 3 km, and then declining as the distance increases to
about 15 km.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [291] [3D Optimization for AI Inference Scaling: Balancing Accuracy, Cost, and Latency](https://arxiv.org/abs/2510.18905)
*Minseok Jung,Abhas Ricky,Muhammad Rameez Chatni*

Main category: cs.LG

TL;DR: 该研究提出了一个3D优化框架，用于在考虑成本和延迟限制的情况下进行AI推理扩展，以替代传统的1D或2D方法。


<details>
  <summary>Details</summary>
Motivation: 传统的AI推理扩展方法（如1D启发式和2D权衡）无法同时考虑成本和延迟限制，而实际应用中这些限制至关重要。

Method: 提出一个3D优化框架，将准确性、成本和延迟纳入统一决策空间，并通过蒙特卡洛模拟和四种优化方法（包括膝点优化和准确性最大化）在九种不同的语言模型和三种场景下进行评估。

Result: 3D优化框架能够识别1D和2D方法无法捕捉的可行空间，从而实现环境适应性的推理扩展。研究结果表明，膝点优化在平衡各因素方面表现最佳，而准确性最大化在优先考虑精度时更优。

Conclusion: 该框架为在不同操作环境下进行面向部署的推理扩展提供了理论基础，并强调了在AI推理优化中考虑多维度约束的重要性。

Abstract: AI inference scaling is often tuned through 1D heuristics (a fixed reasoning
passes) or 2D bivariate trade-offs (e.g., performance vs. compute), which fail
to consider cost and latency constraints. We introduce a 3D optimization
framework that jointly calibrates accuracy, cost, and latency within a unified
decision space, enabling constraints-aware inference scaling. Using Monte Carlo
simulations across three representative scenarios and nine simulated large
language models, we evaluate four optimization methods to address the 3D
multi-objective optimization (MOO) problem. Framing inference scaling in MOO
shapes a feasible space that 1D and 2D optimizations fail to capture, enabling
environmentadaptive selection of the inference scaling k. Results show that
knee-point optimization achieves the best balance, while accuracy-maximization
remains favorable when precision is prioritized. The framework establishes a
theoretical foundation for deployment-aware inference scaling across diverse
operational contexts.

</details>


### [292] [A New Type of Adversarial Examples](https://arxiv.org/abs/2510.19347)
*Xingyang Nie,Guojie Xiao,Su Pan,Biao Wang,Huilin Ge,Tao Fang*

Main category: cs.LG

TL;DR: 生成的对抗样本与原样本差异很大，但会导致模型给出相同预测，并广泛分布于样本空间，而非仅仅在原样本邻域。


<details>
  <summary>Details</summary>
Motivation: 大多数机器学习模型容易受到对抗样本的攻击，这引发了对其安全性的担忧。传统的对抗样本是通过对原始样本进行微小但人为设计的扰动来生成的，目的是使模型产生错误的预测。然而，本文旨在探索一种相反的生成方式：创建与原始样本显著不同但能诱导模型做出相同预测的对抗样本。

Method: 提出了一套新颖的算法来生成这种“相反”的对抗样本，包括负迭代快速梯度符号法（NI-FGSM）和负迭代快速梯度法（NI-FGM），以及它们的动量变体：负动量迭代快速梯度符号法（NMI-FGSM）和负动量迭代快速梯度法（NMI-FGM）。

Result: 实验结果表明，通过这些新方法生成的对抗样本与原始样本有显著区别，但却能引导模型做出相同的预测。此外，研究还发现这些对抗样本并非局限于原始数据点的邻近区域，而是广泛地分布在整个样本空间中。

Conclusion: 本文提出的新算法能够生成与原始样本差异巨大但预测结果相同的对抗样本，并证明了这些对抗样本的分布比先前认为的更为广泛。这广泛。这些发现对于理解和防御机器学习模型的安全性具有重要意义。

Abstract: Most machine learning models are vulnerable to adversarial examples, which
poses security concerns on these models. Adversarial examples are crafted by
applying subtle but intentionally worst-case modifications to examples from the
dataset, leading the model to output a different answer from the original
example. In this paper, adversarial examples are formed in an exactly opposite
manner, which are significantly different from the original examples but result
in the same answer. We propose a novel set of algorithms to produce such
adversarial examples, including the negative iterative fast gradient sign
method (NI-FGSM) and the negative iterative fast gradient method (NI-FGM),
along with their momentum variants: the negative momentum iterative fast
gradient sign method (NMI-FGSM) and the negative momentum iterative fast
gradient method (NMI-FGM). Adversarial examples constructed by these methods
could be used to perform an attack on machine learning systems in certain
occasions. Moreover, our results show that the adversarial examples are not
merely distributed in the neighbourhood of the examples from the dataset;
instead, they are distributed extensively in the sample space.

</details>


### [293] [Large Connectome Model: An fMRI Foundation Model of Brain Connectomes Empowered by Brain-Environment Interaction in Multitask Learning Landscape](https://arxiv.org/abs/2510.18910)
*Ziquan Wei,Tingting Dan,Guorong Wu*

Main category: cs.LG

TL;DR: 该研究提出了一种结合多任务学习和半监督微调的脑成像基础模型，以解决小样本临床应用中的挑战，并在性别预测、行为识别及多种疾病的早期诊断中取得了有前景的结果。


<details>
  <summary>Details</summary>
Motivation: 临床应用中的人工智能模型受限于样本量，因此需要可靠的脑成像基础模型来提升其性能。

Method: 采用多任务学习，通过对多个脑-环境交互（BEI）进行标记，并利用预训练的BEI伪标签进行半监督微调，构建了一个可扩展的模型架构。

Result: 在性别预测、行为识别、自闭症、帕金森病、阿尔茨海默病和精神分裂症等多种下游任务中，该模型均取得了具有前景的结果。

Conclusion: 所提出的基础模型具有巨大的潜力，能够促进神经影像学在临床实践中的应用。

Abstract: A reliable foundation model of functional neuroimages is critical to promote
clinical applications where the performance of current AI models is
significantly impeded by a limited sample size. To that end, tremendous efforts
have been made to pretraining large models on extensive unlabeled fMRI data
using scalable self-supervised learning. Since self-supervision is not
necessarily aligned with the brain-to-outcome relationship, most foundation
models are suboptimal to the downstream task, such as predicting disease
outcomes. By capitalizing on rich environmental variables and demographic data
along with an unprecedented amount of functional neuroimages, we form the brain
modeling as a multitask learning and present a scalable model architecture for
(i) multitask pretraining by tokenizing multiple brain-environment interactions
(BEI) and (ii) semi-supervised finetuning by assigning pseudo-labels of
pretrained BEI. We have evaluated our foundation model on a variety of
applications, including sex prediction, human behavior recognition, and disease
early diagnosis of Autism, Parkinson's disease, Alzheimer's disease, and
{Schizophrenia}, where promising results indicate the great potential to
facilitate current neuroimaging applications in clinical routines.

</details>


### [294] [Matrix-Free Least Squares Solvers: Values, Gradients, and What to Do With Them](https://arxiv.org/abs/2510.19634)
*Hrittik Roy,Søren Hauberg,Nicholas Krämer*

Main category: cs.LG

TL;DR: 最小二乘法在现代机器学习中有巨大潜力，可作为可微分算子应用于各种场景。


<details>
  <summary>Details</summary>
Motivation: 挖掘最小二乘法在现代机器学习中的潜力，将其扩展到线性模型拟合之外的应用。

Method: 推导出定制梯度，将最小二乘法求解器转化为可微分算子，类似于神经网络层。

Result: 1. 在5000万参数模型上实现权重稀疏性，证明了可扩展性；2. 在基于分数的生成模型中强制执行保守性约束；3. 基于预测性能对高斯过程进行超参数调优。

Conclusion: 将最小二乘法发展为可微分的线性代数工具，并推广给机器学习从业者。

Abstract: This paper argues that the method of least squares has significant
unfulfilled potential in modern machine learning, far beyond merely being a
tool for fitting linear models. To release its potential, we derive custom
gradients that transform the solver into a differentiable operator, like a
neural network layer, enabling many diverse applications. Empirically, we
demonstrate: (i) scalability by enforcing weight sparsity on a 50 million
parameter model; (ii) imposing conservativeness constraints in score-based
generative models; and (iii) hyperparameter tuning of Gaussian processes based
on predictive performance. By doing this, our work represents the next
iteration in developing differentiable linear-algebra tools and making them
widely accessible to machine learning practitioners.

</details>


### [295] [ADPO: Anchored Direct Preference Optimization](https://arxiv.org/abs/2510.18913)
*Wang Zixian*

Main category: cs.LG

TL;DR: ADPO是一个通用的框架，它通过软偏好、参考策略锚定和分组扩展来概括DPO。它解决了标准DPO中的硬二元标签和成对比较问题，引入了软偏好概率、任意参考策略锚定以及通过Plackett-Luce分布实现的列表偏好建模。ADPO的变体包括成对锚定的Soft-DPO，以及用于处理重尾噪声的KDE列表平滑。实验表明，ADPO在上下文老虎机和序列强化学习任务中均优于标准DPO，尤其是在存在噪声或污染的情况下。


<details>
  <summary>Details</summary>
Motivation: 标准DPO在处理软偏好、稳定训练和列表偏好方面存在局限性，ADPO旨在通过引入软偏好概率、参考策略锚定和列表偏好建模来解决这些问题，以提高训练的稳定性和性能。

Method: ADPO框架通过以下方式进行扩展：1. 引入软偏好概率以编码不确定性并减轻梯度漂移。2. 使用任意参考策略锚定以通过分组移位不变性和隐式KL正则化来稳定训练。3. 利用Plackett-Luce分布进行列表偏好建模。证明了DPO、Bradley-Terry目标和Top-1-vs-Rest作为特殊情况出现。

Result: 在上下文老虎机任务中，锚定比标准DPO提高了38-63%的WinMass；KDE平滑在重尾污染下达到0.68（相比0.32，相对增益112%）。在序列强化学习任务（CartPole, LunarLander）中，锚定将嘈杂偏好性能提高了15-29%。

Conclusion: ADPO是一个通用的框架，通过软偏好、参考策略锚定和列表偏好建模，显著优于标准DPO，尤其是在存在噪声或污染的情况下。实验结果为在不同噪声条件下选择合适的ADPO变体提供了指导：在干净或中等噪声下使用成对锚定的Soft-DPO，在极端污染下使用基于KDE的列表ADPO。

Abstract: Anchored Direct Preference Optimization (ADPO) is a unified framework that
generalizes Direct Preference Optimization (DPO) with soft preferences,
reference-policy anchoring, and groupwise extensions. While standard DPO
assumes hard binary labels and pairwise comparisons, ADPO introduces: (i) soft
preference probabilities that encode uncertainty and mitigate gradient drift;
(ii) arbitrary reference-policy anchors that stabilize training via groupwise
shift invariance and implicit KL regularization; and (iii) listwise preference
modeling through Plackett-Luce distributions. We prove that DPO, Bradley-Terry
objectives, and Top-1-vs-Rest formulations emerge as special cases. ADPO yields
three practical variants: pairwise anchored Soft-DPO, listwise anchored
Soft-DPO with raw rewards, and KDE-based listwise smoothing for heavy-tailed
noise. In contextual bandits, anchoring improves WinMass by 38-63% over
standard DPO, while KDE smoothing achieves 0.68 vs 0.32 under heavy-tailed
contamination (112% relative gain). In sequential reinforcement learning
(CartPole, LunarLander), anchoring improves noisy-preference performance by
15-29%, confirming transfer from single-step to multi-step settings.
Experiments with 10-256 parameter models provide clear guidance: use pairwise
anchored Soft-DPO for clean or moderate noise, and KDE-based listwise ADPO for
extreme contamination.

</details>


### [296] [QiMeng-SALV: Signal-Aware Learning for Verilog Code Generation](https://arxiv.org/abs/2510.19296)
*Yang Zhang,Rui Zhang,Jiaming Guo,Lei Huang,Di Huang,Yunpu Zhao,Shuyao Cheng,Pengwei Jin,Chongxiao Li,Zidong Du,Xing Hu,Qi Guo,Yunji Chen*

Main category: cs.LG

TL;DR: 通过利用功能正确的输出信号的代码片段来优化基于强化学习的Verilog代码生成，实现了细粒度的信号级优化，并在VerilogEval和RTLLM基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在Verilog代码生成方面存在功能奖励不足的问题，阻碍了基于强化学习的偏好优化，导致生成的代码功能不正确。

Method: 提出了一种名为QiMeng-SALV的信号感知学习方法，该方法通过提取部分错误模块中经过验证的、与信号相关的实现，以增强有意义的功能奖励的提取。具体步骤包括：1. 通过与训练数据中的参考模块进行比较，验证生成模块中信号的功能正确性。2. 利用抽象语法树（AST）识别能够从错误模块中提供有意义的功能奖励的信号感知代码片段。3. 引入信号感知指令集（DPO），在正确的信号级代码片段上进行优化，以避免错误信号带来的噪声和干扰。

Result: QiMeng-SALV方法在VerilogEval和RTLLM基准测试中取得了最先进的性能。使用7B参数的模型，其性能与DeepSeek v3 671B模型相当，并且显著优于在相同数据集上训练的领先的开源模型CodeV。

Conclusion: QiMeng-SALV方法将Verilog代码生成从传统的模块级优化范式转变为细粒度的信号级优化，解决了功能奖励不足的问题，并在基准测试中取得了优异的成果。

Abstract: The remarkable progress of Large Language Models (LLMs) presents promising
opportunities for Verilog code generation which is significantly important for
automated circuit design. The lacking of meaningful functional rewards hinders
the preference optimization based on Reinforcement Learning (RL) for producing
functionally correct Verilog code. In this paper, we propose Signal-Aware
Learning for Verilog code generation (QiMeng-SALV) by leveraging code segments
of functionally correct output signal to optimize RL training. Considering
Verilog code specifies the structural interconnection of hardware gates and
wires so that different output signals are independent, the key insight of
QiMeng-SALV is to extract verified signal-aware implementations in partially
incorrect modules, so as to enhance the extraction of meaningful functional
rewards. Roughly, we verify the functional correctness of signals in generated
module by comparing with that of reference module in the training data. Then
abstract syntax tree (AST) is employed to identify signal-aware code segments
which can provide meaningful functional rewards from erroneous modules.
Finally, we introduce signal-aware DPO which is optimized on the correct
signal-level code segments, thereby preventing noise and interference from
incorrect signals. The proposed QiMeng-SALV underscores the paradigm shift from
conventional module-level to fine-grained signal-level optimization in Verilog
code generation, addressing the issue of insufficient functional rewards.
Experiments demonstrate that our method achieves state-of-the-art performance
on VerilogEval and RTLLM, with a 7B parameter model matching the performance of
the DeepSeek v3 671B model and significantly outperforming the leading
open-source model CodeV trained on the same dataset. Our code is available at
https://github.com/zy1xxx/SALV.

</details>


### [297] [Benchmarking On-Device Machine Learning on Apple Silicon with MLX](https://arxiv.org/abs/2510.18921)
*Oluwaseun A. Ajayi,Ogundepo Odunayo*

Main category: cs.LG

TL;DR: MLX是一个为Apple Silicon设备优化的机器学习框架，本文评估了其在Transformer模型推理方面的性能，并与PyTorch和NVIDIA GPU进行了比较。


<details>
  <summary>Details</summary>
Motivation: 随着LLM和机器学习在小型设备上的广泛应用，需要能够利用设备硬件的框架。MLX旨在满足这一需求。

Method: 本文提出了MLX-transformers框架，用于在MLX中实现Transformer模型，并将PyTorch模型转换为MLX格式。通过在两台Apple Silicon MacBook设备上，与NVIDIA CUDA GPU进行基准测试，比较了相同参数大小和检查点的BERT、RoBERTa和XLM-RoBERTa模型的推理延迟。

Result: MLX在Apple Silicon设备上展示了其在Transformer模型推理方面的潜力，能够高效地在Apple生态系统中实现机器学习应用。

Conclusion: MLX框架在Apple Silicon设备上具有高效的机器学习计算能力，尤其在Transformer模型的推理方面表现出潜力，有助于推动更易于访问的设备端ML应用。

Abstract: The recent widespread adoption of Large Language Models (LLMs) and machine
learning in general has sparked research interest in exploring the
possibilities of deploying these models on smaller devices such as laptops and
mobile phones. This creates a need for frameworks and approaches that are
capable of taking advantage of on-device hardware. The MLX framework was
created to address this need. It is a framework optimized for machine learning
(ML) computations on Apple silicon devices, facilitating easier research,
experimentation, and prototyping.
  This paper presents a performance evaluation of MLX, focusing on inference
latency of transformer models. We compare the performance of different
transformer architecture implementations in MLX with their Pytorch
counterparts. For this research we create a framework called MLX-transformers
which includes different transformer implementations in MLX and downloads the
model checkpoints in pytorch and converts it to the MLX format. By leveraging
the advanced architecture and capabilities of Apple Silicon, MLX-Transformers
enables seamless execution of transformer models directly sourced from Hugging
Face, eliminating the need for checkpoint conversion often required when
porting models between frameworks.
  Our study benchmarks different transformer models on two Apple Silicon
macbook devices against an NVIDIA CUDA GPU. Specifically, we compare the
inference latency performance of models with the same parameter sizes and
checkpoints. We evaluate the performance of BERT, RoBERTa, and XLM-RoBERTa
models, with the intention of extending future work to include models of
different modalities, thus providing a more comprehensive assessment of MLX's
capabilities. The results highlight MLX's potential in enabling efficient and
more accessible on-device ML applications within Apple's ecosystem.

</details>


### [298] [Noise-corrected GRPO: From Noisy Rewards to Unbiased Gradients](https://arxiv.org/abs/2510.18924)
*Omar El mansouri,Mohamed El Amine Seddik,Salem Lahlou*

Main category: cs.LG

TL;DR: RLHF/RLVR 易受奖励噪声影响，我们提出了 GRPO/Dr.GRPO 框架，通过对奖励进行噪声校正来提高模型对噪声的鲁棒性，并在数学和代码任务上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: RLHF/RLVR 在对齐 LLM 和构建 SOTA 推理模型方面至关重要，但其对奖励噪声（来自不一致或错误的奖励）非常敏感。然而，这种噪声与常用的基于组的策略优化方法之间的相互作用尚未得到充分研究。

Method: 提出了一种称为“Group Relative Policy Optimization (GRPO)”和“Done Right GRPO (Dr.GRPO)”的噪声鲁棒框架，该框架明确地将奖励损坏建模为伯努利噪声。该方法在估计奖励翻转概率后应用噪声校正来消除学习信号的偏差，从而产生可证明的无偏梯度估计。理论分析表明，基于组的方法固有地减轻了个人层面的噪声，而我们的校正策略则放大了这种鲁棒性。

Result: 在应用于标准奖励模型使用时，在数学和代码任务上观察到了一致的改进，在现实的奖励模型条件下，数学任务的准确性提高了 6.7 个百分点，代码任务提高了 1.5 个百分点。

Conclusion: 这项工作将监督学习中的标签噪声校正与现代 RLHF 结合起来，提供了理论见解和一种用于在嘈杂的现实世界中部署的实用算法。

Abstract: Reinforcement learning from human feedback (RLHF) or verifiable rewards
(RLVR), the standard paradigm for aligning LLMs or building recent SOTA
reasoning models, is highly sensitive to noise from inconsistent or erroneous
rewards. Yet, the interaction between such noise and widely used group-based
policy optimization methods remains underexplored. We introduce a noise-robust
Group Relative Policy Optimization (GRPO) and Done Right GRPO (Dr.GRPO)
framework that explicitly models reward corruption as Bernoulli noise. Our
method applies noise correction after estimating reward flip probabilities to
debias the learning signal, yielding provably unbiased gradient estimates.
Theoretical analysis shows that group-based methods inherently mitigate
individual-level noise, and our correction strategy amplifies this robustness.
Empirically, we observe consistent improvements across math and code tasks when
applying our noise correction to standard reward model usage, with particular
gains of up to 6.7 percentage points in accuracy on math tasks and 1.5 on code
tasks under realistic reward model conditions. This work bridges label-noise
correction from supervised learning with modern RLHF, offering both theoretical
insights and a practical algorithm for noisy real-world deployment.

</details>


### [299] [Application of Reduced-Order Models for Temporal Multiscale Representations in the Prediction of Dynamical Systems](https://arxiv.org/abs/2510.18925)
*Elias Al Ghazal,Jad Mounayer,Beatriz Moya,Sebastian Rodriguez,Chady Ghnatios,Francisco Chinesta*

Main category: cs.LG

TL;DR: 提出三种多尺度学习方法来克服复杂多尺度系统建模和预测的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法在捕捉复杂多尺度系统的非线性、初始条件敏感性以及高频行为方面存在局限性。

Method: 1. 结合单位分解（PU）方法和神经网络，将动力学分解为局部成分，预测宏观和微观行为。 2. 应用奇异值分解（SVD）提取主导模式，分离宏观和微观动力学。 3. 采用稀疏高阶SVD从有限测量中重构多尺度动力学。

Result: 所提出的方法能够准确捕捉粗粒度和细粒度动力学，适用于复杂多尺度现象的实际应用，并能适应具有不完全观测的高维系统。

Conclusion: 该框架能够为研究对象中存在的所有时间尺度提供近似和解释，从而有效处理复杂多尺度现象。

Abstract: Modeling and predicting the dynamics of complex multiscale systems remains a
significant challenge due to their inherent nonlinearities and sensitivity to
initial conditions, as well as limitations of traditional machine learning
methods that fail to capture high frequency behaviours. To overcome these
difficulties, we propose three approaches for multiscale learning. The first
leverages the Partition of Unity (PU) method, integrated with neural networks,
to decompose the dynamics into local components and directly predict both
macro- and micro-scale behaviors. The second applies the Singular Value
Decomposition (SVD) to extract dominant modes that explicitly separate macro-
and micro-scale dynamics. Since full access to the data matrix is rarely
available in practice, we further employ a Sparse High-Order SVD to reconstruct
multiscale dynamics from limited measurements. Together, these approaches
ensure that both coarse and fine dynamics are accurately captured, making the
framework effective for real-world applications involving complex, multi-scale
phenomena and adaptable to higher-dimensional systems with incomplete
observations, by providing an approximation and interpretation in all time
scales present in the phenomena under study.

</details>


### [300] [BAPO: Stabilizing Off-Policy Reinforcement Learning for LLMs via Balanced Policy Optimization with Adaptive Clipping](https://arxiv.org/abs/2510.18927)
*Zhiheng Xi,Xin Guo,Yang Nan,Enyu Zhou,Junrui Shen,Wenxiang Chen,Jiaqi Liu,Jixuan Huang,Zhihao Zhang,Honglin Guo,Xun Deng,Zhikai Lei,Miao Zheng,Guoteng Wang,Shuo Zhang,Peng Sun,Rui Zheng,Hang Yan,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Reinforcement learning (RL) has recently become the core paradigm for
aligning and strengthening large language models (LLMs). Yet, applying RL in
off-policy settings--where stale data from past policies are used for
training--improves sample efficiency, but remains challenging: policy entropy
declines sharply, optimization often becomes unstable and may even collapse.
Through theoretical and empirical analysis, we identify two key insights: (i)
an imbalance in optimization, where negative-advantage samples dominate the
policy gradient, suppressing useful behaviors and risking gradient explosions;
and (ii) the derived Entropy-Clip Rule, which reveals that the fixed clipping
mechanism in PPO-like objectives systematically blocks entropy-increasing
updates, thereby driving the policy toward over-exploitation at the expense of
exploration. Building on these insights, we propose BAlanced Policy
Optimization with Adaptive Clipping (BAPO), a simple yet effective method that
dynamically adjusts clipping bounds to adaptively re-balance positive and
negative contributions, preserve entropy, and stabilize RL optimization. Across
diverse off-policy scenarios--including sample replay and partial rollout--BAPO
achieves fast, stable, and data-efficient training. On AIME 2024 and AIME 2025
benchmarks, our 7B BAPO model surpasses open-source counterparts such as
SkyWork-OR1-7B, while our 32B BAPO model not only achieves state-of-the-art
results among models of the same scale but also outperforms leading proprietary
systems like o3-mini and Gemini-2.5-Flash-Thinking.

</details>


### [301] [Learning Peer Influence Probabilities with Linear Contextual Bandits](https://arxiv.org/abs/2510.19119)
*Ahmed Sayeed Faruk,Mohammad Shahverdikondori,Elena Zheleva*

Main category: cs.LG

TL;DR: 本篇论文研究了在网络环境中，如何准确估计用户推荐成功率的概率。


<details>
  <summary>Details</summary>
Motivation: 用户在网络环境中经常互相推荐各种信息，但推荐的成功与否受多种因素影响，导致影响概率高度异化。准确估计这些概率对于理解信息传播和提升病毒营销效果至关重要。然而，从静态数据中学习这些概率具有挑战性，因为静态数据只能揭示相关性而无法揭示因果关系。在线学习算法虽然可以从干预中学习，但要么浪费资源进行随机探索，要么优化奖励而倾向于探索影响概率高的部分。

Method: 本研究在上下文线性老虎机框架下研究了学习用户影响概率的问题。我们证明了在最小化遗憾和估计误差之间可能存在根本性的权衡，并刻画了所有可实现的速率对。我们还提出了一种不确定性引导的探索算法，该算法可以通过调整参数来实现权衡中的任何一对。

Result: 通过在半合成网络数据集上的实验，证明了我们的方法优于忽略这种权衡的静态方法和上下文老虎机。

Conclusion: 本研究提出了一个在上下文线性老虎机框架下学习用户影响概率的模型，并设计了一种能够实现遗憾最小化和估计误差之间权衡的算法。

Abstract: In networked environments, users frequently share recommendations about
content, products, services, and courses of action with others. The extent to
which such recommendations are successful and adopted is highly contextual,
dependent on the characteristics of the sender, recipient, their relationship,
the recommended item, and the medium, which makes peer influence probabilities
highly heterogeneous. Accurate estimation of these probabilities is key to
understanding information diffusion processes and to improving the
effectiveness of viral marketing strategies. However, learning these
probabilities from data is challenging; static data may capture correlations
between peer recommendations and peer actions but fails to reveal influence
relationships. Online learning algorithms can learn these probabilities from
interventions but either waste resources by learning from random exploration or
optimize for rewards, thus favoring exploration of the space with higher
influence probabilities. In this work, we study learning peer influence
probabilities under a contextual linear bandit framework. We show that a
fundamental trade-off can arise between regret minimization and estimation
error, characterize all achievable rate pairs, and propose an
uncertainty-guided exploration algorithm that, by tuning a parameter, attains
any pair within this trade-off. Our experiments on semi-synthetic network
datasets show the advantages of our method over static methods and contextual
bandits that ignore this trade-off.

</details>


### [302] [Position: Many generalization measures for deep learning are fragile](https://arxiv.org/abs/2510.18934)
*Shuofeng Zhang,Ard Louis*

Main category: cs.LG

TL;DR: 许多用于深度神经网络（DNN）的泛化度量是脆弱的，它们可能无法准确反映模型的泛化能力，因为它们可能受到训练细节的微小变化的显著影响。


<details>
  <summary>Details</summary>
Motivation: 许多用于深度神经网络（DNN）的泛化度量被认为是准确的，但本文认为它们是脆弱的，并且不能很好地捕捉泛化趋势。论文的动机是证明这些度量（在训练后计算）对训练中的微小变化很敏感，这使得它们不可靠。

Method: 通过研究和分析了多种用于DNN的后期泛化度量，例如路径范数、PAC-贝叶斯原度量和这些度量对超参数和数据复杂性变化的敏感性。

Result: 研究发现，许多后期泛化度量（如路径范数、谱范数、Frobenius范数、平坦度代理和确定性PAC-贝叶斯替代度量）是脆弱的，并且可能受到训练细节的微小变化的显著影响。然而，基于函数的边际似然PAC-贝叶斯界能够捕捉数据复杂性的差异，但它不是后期度量。

Conclusion: 许多用于DNN的后期泛化度量是脆弱的，并且应该对它们进行仔细的审计。研究人员应该开发新的度量，这些度量更健壮，并且能够准确地反映模型的泛化能力。

Abstract: A wide variety of generalization measures have been applied to deep neural
networks (DNNs). Although obtaining tight bounds remains challenging, such
measures are often assumed to reproduce qualitative generalization trends. In
this position paper, we argue that many post-mortem generalization measures --
those computed on trained networks -- are \textbf{fragile}: small training
modifications that barely affect the underlying DNN can substantially change a
measure's value, trend, or scaling behavior. For example, minor hyperparameter
changes, such as learning rate adjustments or switching between SGD variants
can reverse the slope of a learning curve in widely used generalization
measures like the path norm. We also identify subtler forms of fragility. For
instance, the PAC-Bayes origin measure is regarded as one of the most reliable,
and is indeed less sensitive to hyperparameter tweaks than many other measures.
However, it completely fails to capture differences in data complexity across
learning curves. This data fragility contrasts with the function-based
marginal-likelihood PAC-Bayes bound, which does capture differences in
data-complexity, including scaling behavior, in learning curves, but which is
not a post-mortem measure. Beyond demonstrating that many bounds -- such as
path, spectral and Frobenius norms, flatness proxies, and deterministic
PAC-Bayes surrogates -- are fragile, this position paper also argues that
developers of new measures should explicitly audit them for fragility.

</details>


### [303] [NeuroAda: Activating Each Neuron's Potential for Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2510.18940)
*Zhi Zhang,Yixian Shen,Congfeng Cao,Ekaterina Shutova*

Main category: cs.LG

TL;DR: NeuroAda是一种新的参数高效微调（PEFT）方法，它通过引入旁路连接来微调选定的重要参数，同时保持原始模型参数冻结，从而在保持高内存效率的同时实现细粒度微调。


<details>
  <summary>Details</summary>
Motivation: 现有的参数高效微调（PEFT）方法在内存效率和适应性之间存在权衡。基于加法的（如LoRA）方法内存效率高，但适应性有限；选择性原位适应方法适应性强，但内存消耗大。NeuroAda旨在解决这个权衡问题。

Method: NeuroAda首先识别重要的参数（网络内的连接），然后为这些选定的参数引入旁路连接。在微调过程中，只有旁路连接被更新，而原始模型参数保持冻结。

Result: 在23多个自然语言生成和理解任务上的实验表明，NeuroAda在仅使用$\\%\	extbf{0.02}\\%$\\的可训练参数的情况下，实现了最先进的性能，同时将CUDA内存使用量减少了高达60%。

Conclusion: NeuroAda成功地在保持高内存效率的同时实现了细粒度模型微调，并在广泛的任务上取得了优于现有方法的性能。

Abstract: Existing parameter-efficient fine-tuning (PEFT) methods primarily fall into
two categories: addition-based and selective in-situ adaptation. The former,
such as LoRA, introduce additional modules to adapt the model to downstream
tasks, offering strong memory efficiency. However, their representational
capacity is often limited, making them less suitable for fine-grained
adaptation. In contrast, the latter directly fine-tunes a carefully chosen
subset of the original model parameters, allowing for more precise and
effective adaptation, but at the cost of significantly increased memory
consumption. To reconcile this trade-off, we propose NeuroAda, a novel PEFT
method that enables fine-grained model finetuning while maintaining high memory
efficiency. Our approach first identifies important parameters (i.e.,
connections within the network) as in selective adaptation, and then introduces
bypass connections for these selected parameters. During finetuning, only the
bypass connections are updated, leaving the original model parameters frozen.
Empirical results on 23+ tasks spanning both natural language generation and
understanding demonstrate that NeuroAda achieves state-of-the-art performance
with as little as $\leq \textbf{0.02}\%$ trainable parameters, while reducing
CUDA memory usage by up to 60%. We release our code here:
https://github.com/FightingFighting/NeuroAda.git.

</details>


### [304] [Towards Universal Solvers: Using PGD Attack in Active Learning to Increase Generalizability of Neural Operators as Knowledge Distillation from Numerical PDE Solvers](https://arxiv.org/abs/2510.18989)
*Yifei Sun*

Main category: cs.LG

TL;DR: 神经算子在求解非线性偏微分方程时，通过学习函数到函数的映射并截断高频分量，可以实现快速的单次推理，但存在分布外泛化能力差的问题。本文提出了一种对抗性师生蒸馏框架，其中可微数值求解器监督紧凑型神经算子，而基于PGD的活动采样循环在平滑度和能量约束下搜索最坏情况输入以扩展训练集。实验证明，该方法显著提高了分布外鲁棒性，同时保持了神经算子低参数成本和快速推理的优点。


<details>
  <summary>Details</summary>
Motivation: 非线性偏微分方程求解器需要精细的时空离散化和局部线性化，导致高内存成本和慢速运行。现有的神经算子（如FNOs和DeepONets）虽然能快速推理，但分布外泛化能力差。

Method: 提出一种对抗性师生蒸馏框架，使用可微数值求解器作为教师，紧凑型神经算子作为学生。结合基于PGD的活动采样循环，在平滑度和能量约束下搜索最坏情况输入来扩展训练集。利用可微谱求解器进行基于梯度的对抗性搜索和样本挖掘。

Result: 在Burgers和Navier-Stokes系统上的实验表明，对抗性蒸馏在保持神经算子低参数成本和快速推理的同时，显著提高了分布外泛化鲁棒性。

Conclusion: 对抗性师生蒸馏框架能够有效解决神经算子分布外泛化能力差的问题，同时保留其高效性。

Abstract: Nonlinear PDE solvers require fine space-time discretizations and local
linearizations, leading to high memory cost and slow runtimes. Neural operators
such as FNOs and DeepONets offer fast single-shot inference by learning
function-to-function mappings and truncating high-frequency components, but
they suffer from poor out-of-distribution (OOD) generalization, often failing
on inputs outside the training distribution. We propose an adversarial
teacher-student distillation framework in which a differentiable numerical
solver supervises a compact neural operator while a PGD-style active sampling
loop searches for worst-case inputs under smoothness and energy constraints to
expand the training set. Using differentiable spectral solvers enables
gradient-based adversarial search and stabilizes sample mining. Experiments on
Burgers and Navier-Stokes systems demonstrate that adversarial distillation
substantially improves OOD robustness while preserving the low parameter cost
and fast inference of neural operators.

</details>


### [305] [An Encode-then-Decompose Approach to Unsupervised Time Series Anomaly Detection on Contaminated Training Data--Extended Version](https://arxiv.org/abs/2510.18998)
*Buang Zhang,Tung Kieu,Xiangfei Qiu,Chenjuan Guo,Jilin Hu,Aoying Zhou,Christian S. Jensen,Bin Yang*

Main category: cs.LG

TL;DR: 提出一种新颖的编码-分解范式，通过将编码表示分解为稳定和辅助表示来提高对污染时间序列的鲁棒性，并使用基于互信息的新指标来替代重建误差进行异常检测。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督时间序列异常检测方法（尤其是基于自动编码器的方法）在训练时容易受到异常值的影响，导致准确性下降。

Method: 提出一种编码-分解范式，将编码表示分解为稳定和辅助表示，并使用基于互信息的新指标来替代重建误差进行异常检测。

Result: 在八个常用的多变量和单变量时间序列基准测试中，该方法表现出与现有方法相当或更优的性能，并且对不同污染比例的时间序列具有鲁棒性。

Conclusion: 该方法通过编码-分解范式和基于互信息的新指标，有效解决了现有自动编码器方法在处理污染时间序列时的准确性问题，并在多个基准测试中取得了优异的性能。

Abstract: Time series anomaly detection is important in modern large-scale systems and
is applied in a variety of domains to analyze and monitor the operation of
diverse systems. Unsupervised approaches have received widespread interest, as
they do not require anomaly labels during training, thus avoiding potentially
high costs and having wider applications. Among these, autoencoders have
received extensive attention. They use reconstruction errors from compressed
representations to define anomaly scores. However, representations learned by
autoencoders are sensitive to anomalies in training time series, causing
reduced accuracy. We propose a novel encode-then-decompose paradigm, where we
decompose the encoded representation into stable and auxiliary representations,
thereby enhancing the robustness when training with contaminated time series.
In addition, we propose a novel mutual information based metric to replace the
reconstruction errors for identifying anomalies. Our proposal demonstrates
competitive or state-of-the-art performance on eight commonly used multi- and
univariate time series benchmarks and exhibits robustness to time series with
different contamination ratios.

</details>


### [306] [Prior-informed optimization of treatment recommendation via bandit algorithms trained on large language model-processed historical records](https://arxiv.org/abs/2510.19014)
*Saman Nessari,Ali Bozorgi-Amiri*

Main category: cs.LG

TL;DR: 本研究提出一个整合了大型语言模型（LLMs）、条件表格生成对抗网络（CTGAN）、T-learner反事实模型和上下文老虎机方法，以提供定制化、数据驱动的临床建议的系统，以解决当前医疗实践中忽视个体差异导致效果不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 当前医疗实践依赖标准化治疗框架和经验方法，忽略个体患者差异，导致次优健康结果。

Method: 本研究开发了一个综合系统，整合了大型语言模型（LLMs）处理非结构化病历数据，条件表格生成对抗网络（CTGAN）生成合成患者数据，T-learner模型预测患者特定治疗反应，以及上下文老虎机方法来增强在线治疗选择。

Result: LLMs处理非结构化病历数据的准确率为93.2%；CTGAN生成合成数据的准确率为55%；T-learners预测患者特定治疗反应的准确率为84.3%。在III期结肠癌数据集上的测试显示，本研究的KernelUCB方法在5,000轮内获得了0.60-0.61的平均奖励分数，优于其他参照方法。

Conclusion: 该综合系统克服了在线学习环境中的冷启动限制，提高了计算效率，朝着适应特定患者特征的个体化医疗迈出了重要一步。

Abstract: Current medical practice depends on standardized treatment frameworks and
empirical methodologies that neglect individual patient variations, leading to
suboptimal health outcomes. We develop a comprehensive system integrating Large
Language Models (LLMs), Conditional Tabular Generative Adversarial Networks
(CTGAN), T-learner counterfactual models, and contextual bandit approaches to
provide customized, data-informed clinical recommendations. The approach
utilizes LLMs to process unstructured medical narratives into structured
datasets (93.2% accuracy), uses CTGANs to produce realistic synthetic patient
data (55% accuracy via two-sample verification), deploys T-learners to forecast
patient-specific treatment responses (84.3% accuracy), and integrates
prior-informed contextual bandits to enhance online therapeutic selection by
effectively balancing exploration of new possibilities with exploitation of
existing knowledge. Testing on stage III colon cancer datasets revealed that
our KernelUCB approach obtained 0.60-0.61 average reward scores across 5,000
rounds, exceeding other reference methods. This comprehensive system overcomes
cold-start limitations in online learning environments, improves computational
effectiveness, and constitutes notable progress toward individualized medicine
adapted to specific patient characteristics.

</details>


### [307] [Category learning in deep neural networks: Information content and geometry of internal representations](https://arxiv.org/abs/2510.19021)
*Laurent Bonnasse-Gahot,Jean-Pierre Nadal*

Main category: cs.LG

TL;DR: 分类学习可以增强对接近类别边界的刺激的辨别力，这种现象在人工智能神经网络中也有观察到。本研究将先前基于神经科学数据的理论框架扩展到人工智能网络，表明最小化贝叶斯成本（交叉熵损失的平均值）等同于最大化类别和决策层之前神经活动之间的互信息。对于低维特征空间的结构化数据，最大化互信息意味着找到合适的投影空间并构建具有适当度量的神经表示。这种度量基于 Fisher 信息矩阵，它测量神经活动在投影空间中的敏感度。最优学习使这种神经 Fisher 信息遵循特定类别的 Fisher 信息，该信息测量类别成员资格的敏感度。因此，类别学习会在决策边界附近扩展神经空间。研究人员表征了分类 Fisher 信息的特性，发现其特征向量提供了投影空间中每个点的最判别方向。研究还发现，其最大值通常不在类别边界上，而是在其附近。通过对玩具模型和 MNIST 数据集的数值说明，研究人员展示了学习后两个 Fisher 信息矩阵如何匹配并与类别边界基本对齐。最后，研究将该方法与信息瓶颈方法进行了关联，并展示了贝叶斯成本的偏差-方差分解。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在将先前在神经科学领域提出的关于分类学习如何增强刺激辨别力的理论框架（即类别感知）扩展到人工智能神经网络，并从理论上解释神经网络在分类任务中出现类似现象的原因。

Method: 研究人员将理论框架扩展到人工智能网络，表明最小化贝叶斯成本（交叉熵损失的平均值）等同于最大化类别与决策层之前神经活动之间的互信息。对于低维特征空间的结构化数据，他们证明了最大化互信息包括（1）找到一个合适的投影空间，以及（2）构建一个具有适当度量的神经表示，该度量基于测量神经活动对投影空间变化的敏感度的 Fisher 信息矩阵。最优学习会使神经 Fisher 信息匹配特定类别的 Fisher 信息，该信息测量类别成员资格的敏感度。研究人员还表征了分类 Fisher 信息的特性，并将其与信息瓶颈方法相关联，最后进行了贝叶斯成本的偏差-方差分解。

Result: 研究表明，类别学习会导致决策边界附近的神经空间扩展。分类 Fisher 信息的特征向量提供了投影空间中每个点的最判别方向。研究发现，分类 Fisher 信息的最大值通常出现在类别边界附近，而非正好在边界上。通过玩具模型和 MNIST 数据集的数值实验，研究人员证明了学习后，神经 Fisher 信息矩阵和类别 Fisher 信息矩阵会匹配并对齐，且与类别边界基本一致。

Conclusion: 本研究成功地将类别感知的理论扩展到人工智能神经网络，并从信息论的角度解释了类别学习如何导致决策边界附近神经空间的扩展。研究提出的方法不仅能够解释现有现象，还提供了新的视角来理解和优化神经网络的分类能力，并揭示了 Fisher 信息矩阵在类别学习中的关键作用。

Abstract: In animals, category learning enhances discrimination between stimuli close
to the category boundary. This phenomenon, called categorical perception, was
also empirically observed in artificial neural networks trained on
classification tasks. In previous modeling works based on neuroscience data, we
show that this expansion/compression is a necessary outcome of efficient
learning. Here we extend our theoretical framework to artificial networks. We
show that minimizing the Bayes cost (mean of the cross-entropy loss) implies
maximizing the mutual information between the set of categories and the neural
activities prior to the decision layer. Considering structured data with an
underlying feature space of small dimension, we show that maximizing the mutual
information implies (i) finding an appropriate projection space, and, (ii)
building a neural representation with the appropriate metric. The latter is
based on a Fisher information matrix measuring the sensitivity of the neural
activity to changes in the projection space. Optimal learning makes this neural
Fisher information follow a category-specific Fisher information, measuring the
sensitivity of the category membership. Category learning thus induces an
expansion of neural space near decision boundaries. We characterize the
properties of the categorical Fisher information, showing that its eigenvectors
give the most discriminant directions at each point of the projection space. We
find that, unexpectedly, its maxima are in general not exactly at, but near,
the class boundaries. Considering toy models and the MNIST dataset, we
numerically illustrate how after learning the two Fisher information matrices
match, and essentially align with the category boundaries. Finally, we relate
our approach to the Information Bottleneck one, and we exhibit a bias-variance
decomposition of the Bayes cost, of interest on its own.

</details>


### [308] [Empowering Decision Trees via Shape Function Branching](https://arxiv.org/abs/2510.19040)
*Nakul Upadhya,Eldan Cohen*

Main category: cs.LG

TL;DR: Shape Generalized Trees (SGTs) are a novel type of decision tree that uses learnable shape functions for non-linear partitioning, improving interpretability and performance over traditional trees.


<details>
  <summary>Details</summary>
Motivation: Traditional decision trees rely on simple linear splits, requiring deep structures to capture non-linear effects and reducing interpretability. SGTs address this by using learnable, axis-aligned shape functions at each node for richer, non-linear partitioning in a single split, enhancing human comprehension.

Method: The paper introduces Shape Generalized Trees (SGTs) that utilize learnable axis-aligned shape functions. It also proposes ShapeCART, an efficient algorithm for learning SGTs. Extensions like S^2GT (bivariate shape functions) and SGT_K (multi-way trees) are introduced, along with their respective learning algorithms, Shape^2CART and ShapeCART_K.

Result: Experiments demonstrate that SGTs achieve better performance and smaller model sizes compared to traditional axis-aligned linear trees across various datasets.

Conclusion: SGTs offer an interpretable and powerful alternative to traditional decision trees by incorporating learnable shape functions, leading to improved performance and reduced model complexity.

Abstract: Decision trees are prized for their interpretability and strong performance
on tabular data. Yet, their reliance on simple axis-aligned linear splits often
forces deep, complex structures to capture non-linear feature effects,
undermining human comprehension of the constructed tree. To address this
limitation, we propose a novel generalization of a decision tree, the Shape
Generalized Tree (SGT), in which each internal node applies a learnable
axis-aligned shape function to a single feature, enabling rich, non-linear
partitioning in one split. As users can easily visualize each node's shape
function, SGTs are inherently interpretable and provide intuitive, visual
explanations of the model's decision mechanisms. To learn SGTs from data, we
propose ShapeCART, an efficient induction algorithm for SGTs. We further extend
the SGT framework to bivariate shape functions (S$^2$GT) and multi-way trees
(SGT$_K$), and present Shape$^2$CART and ShapeCART$_K$, extensions to ShapeCART
for learning S$^2$GTs and SGT$_K$s, respectively. Experiments on various
datasets show that SGTs achieve superior performance with reduced model size
compared to traditional axis-aligned linear trees.

</details>


### [309] [POLAR: Policy-based Layerwise Reinforcement Learning Method for Stealthy Backdoor Attacks in Federated Learning](https://arxiv.org/abs/2510.19056)
*Kuai Yu,Xiaoyu Wu,Peishen Yan,Qingqian Yang,Linshan Jiang,Hao Wang,Yang Hua,Tao Song,Haibing Guan*

Main category: cs.LG

TL;DR: 本文提出了一种名为POLAR的新的联邦学习后门攻击方法，通过强化学习动态选择关键层进行中毒，提高了攻击的隐蔽性和有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习后门攻击方法在选择关键层时缺乏对层间相互关系的考虑，导致攻击效果不佳且容易被检测。

Method: POLAR利用强化学习（RL）和策略梯度更新来动态学习攻击策略，通过伯努利采样优化关键层的选择，并引入正则化约束来限制修改的层数以保证隐蔽性。

Result: 在与六种最先进的防御方法的对比实验中，POLAR的攻击效果比现有方法提高了40%。

Conclusion: POLAR是第一个创造性地采用RL解决层级后门攻击中BC层选择问题的流水线，在攻击效果和隐蔽性方面均优于现有方法。

Abstract: Federated Learning (FL) enables decentralized model training across multiple
clients without exposing local data, but its distributed feature makes it
vulnerable to backdoor attacks. Despite early FL backdoor attacks modifying
entire models, recent studies have explored the concept of backdoor-critical
(BC) layers, which poison the chosen influential layers to maintain
stealthiness while achieving high effectiveness. However, existing BC layers
approaches rely on rule-based selection without consideration of the
interrelations between layers, making them ineffective and prone to detection
by advanced defenses. In this paper, we propose POLAR (POlicy-based LAyerwise
Reinforcement learning), the first pipeline to creatively adopt RL to solve the
BC layer selection problem in layer-wise backdoor attack. Different from other
commonly used RL paradigm, POLAR is lightweight with Bernoulli sampling. POLAR
dynamically learns an attack strategy, optimizing layer selection using policy
gradient updates based on backdoor success rate (BSR) improvements. To ensure
stealthiness, we introduce a regularization constraint that limits the number
of modified layers by penalizing large attack footprints. Extensive experiments
demonstrate that POLAR outperforms the latest attack methods by up to 40%
against six state-of-the-art (SOTA) defenses.

</details>


### [310] [Weight Decay may matter more than muP for Learning Rate Transfer in Practice](https://arxiv.org/abs/2510.19093)
*Atli Kosson,Jeremy Welborn,Yang Liu,Martin Jaggi,Xi Chen*

Main category: cs.LG

TL;DR:  muP 学习率缩放假设在实际应用中不成立，权重衰减在模型宽度缩放中更稳定，muP 作用类似预热。


<details>
  <summary>Details</summary>
Motivation: 在超参数调整成本高昂的大规模模型训练中，将学习率从小型网络迁移到大型网络以实现高效训练。

Method: 通过大规模实证研究，检验 muP 缩放规则在不同模型宽度下的有效性，并与权重衰减进行比较。

Result: muP 的缩放规则在训练初期有效，但随后失效，而权重衰减在整个训练过程中保持了内部表示的稳定性，促进了学习率的迁移。muP 的作用类似于学习率预热。

Conclusion: muP 的缩放规则并非模型宽度缩放的根本原因，其主要作用是作为一种隐式学习率预热。实际应用中，应考虑使用改进的预热策略，并认识到权重衰减在稳定更新动力学中的重要性。

Abstract: Transferring the optimal learning rate from small to large neural networks
can enable efficient training at scales where hyperparameter tuning is
otherwise prohibitively expensive. To this end, the Maximal Update
Parameterization (muP) proposes a learning rate scaling designed to keep the
update dynamics of internal representations stable across different model
widths. However, the scaling rules of muP rely on strong assumptions,
particularly about the geometric alignment of a layer's inputs with both its
weights and gradient updates. In this large-scale empirical investigation, we
show that these assumptions hold only briefly at the start of training in the
practical setups where learning rate transfer is most valuable, such as LLM
training. For the remainder of training it is weight decay rather than muP that
correctly stabilizes the update dynamics of internal representations across
widths, facilitating learning rate transfer. This suggests muP's scaling
primarily acts as a form of implicit learning rate warmup, allowing us to
largely replace it with modified warmup schedules. Together these findings
fundamentally challenge prevailing beliefs about learning rate transfer and can
explain empirical practice such as why muP requires the independent weight
decay variant for successful transfer.

</details>


### [311] [What Makes a Good Curriculum? Disentangling the Effects of Data Ordering on LLM Mathematical Reasoning](https://arxiv.org/abs/2510.19099)
*Yaning Jia,Chunhui Zhang,Xingjian Diao,Xiangchi Yuan,Zhongyu Ouyang,soroush vosoughi*

Main category: cs.LG

TL;DR: 课程学习（CL）通过从易到难排序训练数据来提升大型语言模型（LLMs）的推理能力，但其有效性取决于多种因素。本研究提出了一个统一的评估框架，分解了课程难度为五个维度：问题难度、模型惊异度、置信度边际、预测不确定性和决策变异性。通过在数学推理基准上对 Llama3.1-8B、Mistral-7B 和 Gemma3-4B 进行实验，研究发现：1) 没有一种课程策略是普遍最优的；2) 即使是单一指标，不同难度级别的样本也可能产生不同的收益；3) 与内部状态课程相比，与任务对齐的课程更侧重于塑造模型的最终表征和泛化能力。研究结果挑战了通用课程策略的概念，并为不同模型和任务提供了指导，特别是优先处理决策不确定样本可能进一步提高学习效果。


<details>
  <summary>Details</summary>
Motivation: 现有关于课程学习（CL）在大型语言模型（LLMs）中的应用研究存在难度度量和训练设置不一致的问题，这使得关于CL何时有效、正向或反向CL哪个更好以及这些因素是否受衡量标准影响等基本问题悬而未决。

Method: 通过一个统一的离线评估框架，将课程难度分解为五个互补的维度：问题难度、模型惊异度、置信度边际、预测不确定性和决策变异性。在数学推理基准上，使用 Llama3.1-8B、Mistral-7B 和 Gemma3-4B 模型进行受控的训练后实验。

Result: 1) 没有一种课程策略是普遍最优的；正向与反向CL的相对有效性取决于模型能力和任务复杂度的联合影响。2) 即使在单一指标内，不同难度级别的样本也会根据任务需求产生不同的收益。3) 与内部状态课程（调节置信度和不确定性等内部状态）相比，任务对齐的课程更侧重于塑造模型的最终表征和泛化能力。

Conclusion: 研究结果挑战了普遍存在课程策略的观念，并为不同模型和任务提供了可操作的指导。特别是，一些度量标准表明，优先处理决策不确定样本可以进一步提高学习效果。

Abstract: Curriculum learning (CL) - ordering training data from easy to hard - has
become a popular strategy for improving reasoning in large language models
(LLMs). Yet prior work employs disparate difficulty metrics and training
setups, leaving open fundamental questions: When does curriculum help? Which
direction - forward or reverse - is better? And does the answer depend on what
we measure? We address these questions through a unified offline evaluation
framework that decomposes curriculum difficulty into five complementary
dimensions: Problem Difficulty, Model Surprisal, Confidence Margin, Predictive
Uncertainty, and Decision Variability. Through controlled post-training
experiments on mathematical reasoning benchmarks with Llama3.1-8B, Mistral-7B,
and Gemma3-4B, we find that (i) no curriculum strategy dominates universally -
the relative effectiveness of forward versus reverse CL depends jointly on
model capability and task complexity; (ii) even within a single metric, samples
at different difficulty levels produce distinct gains depending on task
demands; and (iii) task-aligned curricula focus on shaping the model's final
representations and generalization, whereas inner-state curricula modulate
internal states such as confidence and uncertainty. Our findings challenge the
notion of a universal curriculum strategy and offer actionable guidance across
model and task regimes, with some metrics indicating that prioritizing
decision-uncertain samples can further enhance learning outcomes.

</details>


### [312] [MetaCluster: Enabling Deep Compression of Kolmogorov-Arnold Network](https://arxiv.org/abs/2510.19105)
*Matthew Raffel,Adwaith Renjith,Lizhong Chen*

Main category: cs.LG

TL;DR: KANs通过用每条边的基向量系数替换标量权重来提高表达能力和准确性，但参数和内存也呈指数级增长。MetaCluster框架通过引入一个轻量级元学习器来学习低维嵌入到系数向量的映射，将系数向量塑造成易于聚类的低维流形。然后，它在系数空间中运行K-means，并用共享的质心替换每条边的向量。最后，可以丢弃元学习器，通过简短的微调来恢复精度损失。该模型仅存储一个小型的代码本和每条边的索引，从而在多个系数之间分摊存储。


<details>
  <summary>Details</summary>
Motivation: KANs在提高表达能力和准确性的同时，也带来了参数量和内存的指数级增长。现有的方法在压缩KANs时，往往会牺牲其准确性。

Method: MetaCluster框架使用一个轻量级的元学习器，在与KANs联合训练时，学习将低维嵌入映射到系数向量。这个过程使得系数向量能够聚集在低维流形上，便于聚类。然后，在系数空间中使用K-means算法，将每条边的系数向量替换为共享的质心。最后，通过对代码本进行微调，恢复因压缩而可能造成的精度损失。

Result: MetaCluster在MNIST、CIFAR-10和CIFAR-100数据集上，实现了高达80倍的参数存储减少，同时保持了与原始KANs相当的准确性。该方法在标准的KANs和ConvKANs以及多种基函数下均表现优异。

Conclusion: MetaCluster框架能够有效地压缩KANs模型，显著减少参数存储，同时不牺牲准确性。该方法利用了KANs参数的向量特性，通过共享质心和索引来分摊存储，为KANs的应用提供了更高效的解决方案。

Abstract: Kolmogorov-Arnold Networks (KANs) replace scalar weights with per-edge
vectors of basis coefficients, thereby boosting expressivity and accuracy but
at the same time resulting in a multiplicative increase in parameters and
memory. We propose MetaCluster, a framework that makes KANs highly compressible
without sacrificing accuracy. Specifically, a lightweight meta-learner, trained
jointly with the KAN, is used to map low-dimensional embedding to coefficient
vectors, shaping them to lie on a low-dimensional manifold that is amenable to
clustering. We then run K-means in coefficient space and replace per-edge
vectors with shared centroids. Afterwards, the meta-learner can be discarded,
and a brief fine-tuning of the centroid codebook recovers any residual accuracy
loss. The resulting model stores only a small codebook and per-edge indices,
exploiting the vector nature of KAN parameters to amortize storage across
multiple coefficients. On MNIST, CIFAR-10, and CIFAR-100, across standard KANs
and ConvKANs using multiple basis functions, MetaCluster achieves a reduction
of up to 80$\times$ in parameter storage, with no loss in accuracy. Code will
be released upon publication.

</details>


### [313] [Steering Autoregressive Music Generation with Recursive Feature Machines](https://arxiv.org/abs/2510.19127)
*Daniel Zhao,Daniel Beaglehole,Taylor Berg-Kirkpatrick,Julian McAuley,Zachary Novack*

Main category: cs.LG

TL;DR: MusicRFM通过直接引导预训练音乐模型（如MusicGen）的内部激活，实现了对音乐生成过程的精细化、可解释控制，无需重新训练模型或引入可闻的伪影。


<details>
  <summary>Details</summary>
Motivation: 现有音乐生成方法在可控性方面存在挑战，常常需要模型再训练或引入杂音。

Method: 使用递归特征机（RFM）来分析模型的内部梯度，发现与音符或和弦等音乐属性相关的“概念方向”（激活空间中的特定轴）。训练轻量级RFM探针来发现这些方向，并在推理过程中将它们注入模型，实时引导生成过程，无需每步优化。引入了动态时间变化调度和多属性同步约束等高级控制机制。

Result: 将生成目标音符的准确率从0.23提升到0.82，同时文本提示的遵循度与未干预基线相比仅下降约0.02，表明在对提示保真度影响最小的情况下实现了有效的控制。

Conclusion: MusicRFM成功地平衡了控制度和生成质量，为音乐生成领域提供了可控、可解释的解决方案。

Abstract: Controllable music generation remains a significant challenge, with existing
methods often requiring model retraining or introducing audible artifacts. We
introduce MusicRFM, a framework that adapts Recursive Feature Machines (RFMs)
to enable fine-grained, interpretable control over frozen, pre-trained music
models by directly steering their internal activations. RFMs analyze a model's
internal gradients to produce interpretable "concept directions", or specific
axes in the activation space that correspond to musical attributes like notes
or chords. We first train lightweight RFM probes to discover these directions
within MusicGen's hidden states; then, during inference, we inject them back
into the model to guide the generation process in real-time without per-step
optimization. We present advanced mechanisms for this control, including
dynamic, time-varying schedules and methods for the simultaneous enforcement of
multiple musical properties. Our method successfully navigates the trade-off
between control and generation quality: we can increase the accuracy of
generating a target musical note from 0.23 to 0.82, while text prompt adherence
remains within approximately 0.02 of the unsteered baseline, demonstrating
effective control with minimal impact on prompt fidelity. We release code to
encourage further exploration on RFMs in the music domain.

</details>


### [314] [InvarGC: Invariant Granger Causality for Heterogeneous Interventional Time Series under Latent Confounding](https://arxiv.org/abs/2510.19138)
*Ziyi Zhang,Shaogang Ren,Xiaoning Qian,Nick Duffield*

Main category: cs.LG

TL;DR: InvarGC利用跨环境异质性来识别非线性格兰杰因果关系，即使存在潜在混淆因素和干预措施也能恢复不变的因果关系。


<details>
  <summary>Details</summary>
Motivation: 传统格兰杰因果检验在线性模型下难以发现非线性因果关系，而非线性方法常依赖因果充分性和已知的干预靶点，这在实际应用中难以满足。

Method: 提出不变格兰杰因果（InvarGC），利用跨环境异质性，克服潜在混淆因素的影响，并区分干预和非干预环境，恢复不变的因果关系。

Result: 在合成和真实世界数据集上的广泛实验表明，InvarGC与现有方法相比具有竞争力。

Conclusion: InvarGC能够识别非线性格兰杰因果关系，即使在存在潜在混淆因素和干预措施的情况下也能有效工作。

Abstract: Granger causality is widely used for causal structure discovery in complex
systems from multivariate time series data. Traditional Granger causality tests
based on linear models often fail to detect even mild non-linear causal
relationships. Therefore, numerous recent studies have investigated non-linear
Granger causality methods, achieving improved performance. However, these
methods often rely on two key assumptions: causal sufficiency and known
interventional targets. Causal sufficiency assumes the absence of latent
confounders, yet their presence can introduce spurious correlations. Moreover,
real-world time series data usually come from heterogeneous environments,
without prior knowledge of interventions. Therefore, in practice, it is
difficult to distinguish intervened environments from non-intervened ones, and
even harder to identify which variables or timesteps are affected. To address
these challenges, we propose Invariant Granger Causality (InvarGC), which
leverages cross-environment heterogeneity to mitigate the effects of latent
confounding and to distinguish intervened from non-intervened environments with
edge-level granularity, thereby recovering invariant causal relations. In
addition, we establish the identifiability under these conditions. Extensive
experiments on both synthetic and real-world datasets demonstrate the
competitive performance of our approach compared to state-of-the-art methods.

</details>


### [315] [Subliminal Corruption: Mechanisms, Thresholds, and Interpretability](https://arxiv.org/abs/2510.19152)
*Reya Vir,Sarvesh Bhatnagar*

Main category: cs.LG

TL;DR: 在本研究中，我们研究了“潜意识腐败”现象，即不良特质通过语义中性的数据传播，绕过标准的 AI 安全检查。我们使用 GPT-2 模型进行了系统性研究，发现潜意识腐败会导致行为交叉，使模型整体对齐能力下降，并且在特定阈值的数据污染下会发生突然的对齐失效。此外，腐败机制模仿了正常的微调过程，难以检测。这揭示了依赖合成数据的 AI 系统的关键漏洞，并强调了制定新安全协议的必要性。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型越来越多地在合成数据上进行微调，存在细微的错误对齐通过相互连接的 AI 系统传播的风险。本研究旨在量化理解“潜意识腐败”的动态，即不良特质通过语义中性的数据传播，绕过标准安全检查的现象。

Method: 使用 GPT-2 模型的教师-学生设置，对潜意识腐败的扩展定律、阈值和机制进行了系统研究。

Result: 1. 潜意识腐败会导致行为交叉，降低模型的整体对齐能力，而不仅仅是目标特征。 2. 对齐失效发生在数据污染达到临界阈值时，呈现急剧的相变，而不是逐渐下降。 3. 可解释性分析表明，腐败机制模仿了模型自然的微调过程，使其难以检测。

Conclusion: 研究结果揭示了依赖合成数据的 AI 系统的关键脆弱性，并强调了制定能够应对潜在威胁的新安全协议的必要性。

Abstract: As machine learning models are increasingly fine-tuned on synthetic data,
there is a critical risk of subtle misalignments spreading through
interconnected AI systems. This paper investigates subliminal corruption, which
we define as undesirable traits are transmitted through semantically neutral
data, bypassing standard safety checks. While this phenomenon has been
identified, a quantitative understanding of its dynamics is missing. To address
this gap, we present a systematic study of the scaling laws, thresholds, and
mechanisms of subliminal corruption using a teacher-student setup with GPT-2.
Our experiments reveal three key findings: (1) subliminal corruption causes
behavioral crossover, degrading the model's overall alignment, not just the
targeted trait; (2) alignment fails in a sharp phase transition at a critical
threshold of poisoned data, rather than degrading gradually; and (3)
interpretability analysis shows the corruption mechanism mimics the model's
natural fine-tuning process, making it difficult to detect. These results
demonstrate a critical vulnerability in AI systems that rely on synthetic data
and highlight the need for new safety protocols that can account for latent
threats.

</details>


### [316] [Feature Space Adaptation for Robust Model Fine-Tuning](https://arxiv.org/abs/2510.19155)
*Peng Wang,Minghao Gu,Qiang Huang*

Main category: cs.LG

TL;DR: Catastrophic forgetting in model fine-tuning can be addressed by adapting in the feature space instead of the weight space. Proposed methods LoRFA and VeFA, inspired by effect equivalence modeling, achieve comparable fine-tuning results and better robustness.


<details>
  <summary>Details</summary>
Motivation: Existing parameter-efficient fine-tuning methods modify model weights, leading to over-specialization and potential overwriting of pre-trained knowledge, especially with limited or divergent downstream data. This work aims to mitigate catastrophic forgetting and enhance robustness by fine-tuning in the feature space.

Method: Two novel feature space fine-tuning methods, LoRFA (Low-Rank Feature Adaptation) and VeFA (Vector-Based Feature Adaptation), are proposed. These methods are inspired by effect equivalence modeling (EEM) and apply lightweight feature-level transformations to compensate for distribution shifts caused by downstream lurking variables, thereby preserving pre-trained representations.

Result: Evaluations on image classification, NLU, and NLG tasks show that LoRFA and VeFA achieve comparable results to LoRA in standard fine-tuning metrics while demonstrating consistently stronger robustness.

Conclusion: Fine-tuning in the feature space, using methods like LoRFA and VeFA, offers a promising approach to address catastrophic forgetting and improve model generalization and robustness under distribution shift, outperforming traditional weight-space adaptation methods in robustness.

Abstract: Catastrophic forgetting is a common issue in model fine-tuning, especially
when the downstream domain contains limited labeled data or differs greatly
from the pre-training distribution. Existing parameter-efficient fine-tuning
methods operate in the weight space by modifying or augmenting the pre-trained
model's parameters, which can yield models overly specialized to the available
downstream data. To mitigate the risk of overwriting pre-trained knowledge and
enhance robustness, we propose to fine-tune the pre-trained model in the
feature space. Two new fine-tuning methods are proposed: LoRFA (Low-Rank
Feature Adaptation) and VeFA (Vector-Based Feature Adaptation). Feature space
adaptation is inspired by the idea of effect equivalence modeling (EEM) of
downstream lurking variables causing distribution shifts, which posits that
unobserved factors can be represented as the total equivalent amount on
observed features. By compensating for the effects of downstream lurking
variables via a lightweight feature-level transformation, the pre-trained
representations can be preserved, which improves model generalization under
distribution shift. We evaluate LoRFA and VeFA versus LoRA on image
classification, NLU, and NLG, covering both standard fine-tuning metrics and
robustness. Feature space adaptation achieves comparable fine-tuning results
and consistently stronger robustness.

</details>


### [317] [Instance-Dependent Regret Bounds for Nonstochastic Linear Partial Monitoring](https://arxiv.org/abs/2510.19158)
*Federico Di Gennaro,Khaled Eldowa,Nicolò Cesa-Bianchi*

Main category: cs.LG

TL;DR: 线性部分监控允许无限结果空间，并解耦损失和反馈。本研究提出了一种基于探索即优化（exploration-by-optimization）的算法，用于解决非随机、有限动作版本的问题，并得到了新的遗憾界限，该界限能够更好地反映博弈结构，并且在易于处理和难以处理的游戏中分别达到了标准的 $\sqrt{T}$ 和 $T^{2/3}$ 的速率。


<details>
  <summary>Details</summary>
Motivation: 提出线性部分监控模型，作为经典部分监控的推广，能够处理无限结果空间，并灵活解耦损失和反馈，具有一定的理论和应用价值。

Method: 采用探索即优化（exploration-by-optimization）的方法，针对非随机、有限动作的线性部分监控问题，提出了一种易于实现的算法。

Result: 推导出了新的遗憾界限，该界限更清晰地依赖于博弈结构，并包含实例特定的量，反映了观察和损失之间的对齐程度。在易于处理（局部可观察）的游戏中达到 $\sqrt{T}$ 的速率，在难以处理（全局可观察）的游戏中达到 $T^{2/3}$ 的速率。

Conclusion: 该模型和算法能够提供比先前理论保证更透明地依赖于博弈结构的遗憾界限，并在特定情况下具有紧密的理论界限。

Abstract: In contrast to the classic formulation of partial monitoring, linear partial
monitoring can model infinite outcome spaces, while imposing a linear structure
on both the losses and the observations. This setting can be viewed as a
generalization of linear bandits where loss and feedback are decoupled in a
flexible manner. In this work, we address a nonstochastic (adversarial),
finite-actions version of the problem through a simple instance of the
exploration-by-optimization method that is amenable to efficient
implementation. We derive regret bounds that depend on the game structure in a
more transparent manner than previous theoretical guarantees for this paradigm.
Our bounds feature instance-specific quantities that reflect the degree of
alignment between observations and losses, and resemble known guarantees in the
stochastic setting. Notably, they achieve the standard $\sqrt{T}$ rate in easy
(locally observable) games and $T^{2/3}$ in hard (globally observable) games,
where $T$ is the time horizon. We instantiate these bounds in a selection of
old and new partial information settings subsumed by this model, and illustrate
that the achieved dependence on the game structure can be tight in interesting
cases.

</details>


### [318] [Preliminary Use of Vision Language Model Driven Extraction of Mouse Behavior Towards Understanding Fear Expression](https://arxiv.org/abs/2510.19160)
*Paimon Goulart,Jordan Steinhauser,Kylene Shuler,Edward Korzus,Jia Chen,Evangelos E. Papalexakis*

Main category: cs.LG

TL;DR: 本文构建了一个视觉-语言模型（VLM），通过文本输入编码视频，以分类小鼠在环境中存在的和参与的各种行为。该模型为每个受试者和每次受试者进行的会话生成一个行为向量，产出高精度、最少用户输入的数据集。通过优化提示、上下文学习（ICL）和帧级预处理，提高了Qwen2.5-VL模型的性能，并在不进行模型微调的情况下，对包括罕见行为（如冻结和逃跑）在内的所有行为都获得了强F1分数。


<details>
  <summary>Details</summary>
Motivation: 整合不同来源的数据对于促进科学探索至关重要。本研究旨在创建一个能够精确分类小鼠行为并生成行为向量的视觉-语言模型，以解决小鼠行为研究中数据获取的挑战。

Method: 使用开源的Qwen2.5-VL模型，通过优化提示、上下文学习（ICL）和帧级预处理来增强其性能，以编码视频并分类小鼠行为。

Result: 所提出的模型能够生成行为向量，并且通过结合提示优化、ICL和帧级预处理，在不进行模型微调的情况下，对所有行为（包括罕见行为）都实现了强F1分数，并且具有高精度和最少的用户输入。

Conclusion: 该模型能够生成高精度的小鼠行为数据集，支持跨学科研究人员整合多时空维度和环境下的行为特征，从而解决复杂的研究问题。

Abstract: Integration of diverse data will be a pivotal step towards improving
scientific explorations in many disciplines. This work establishes a
vision-language model (VLM) that encodes videos with text input in order to
classify various behaviors of a mouse existing in and engaging with their
environment. Importantly, this model produces a behavioral vector over time for
each subject and for each session the subject undergoes. The output is a
valuable dataset that few programs are able to produce with as high accuracy
and with minimal user input. Specifically, we use the open-source Qwen2.5-VL
model and enhance its performance through prompts, in-context learning (ICL)
with labeled examples, and frame-level preprocessing. We found that each of
these methods contributes to improved classification, and that combining them
results in strong F1 scores across all behaviors, including rare classes like
freezing and fleeing, without any model fine-tuning. Overall, this model will
support interdisciplinary researchers studying mouse behavior by enabling them
to integrate diverse behavioral features, measured across multiple time points
and environments, into a comprehensive dataset that can address complex
research questions.

</details>


### [319] [Natural Gradient VI: Guarantees for Non-Conjugate Models](https://arxiv.org/abs/2510.19163)
*Fangyuan Sun,Ilyas Fatkhullin,Niao He*

Main category: cs.LG

TL;DR: 随机自然梯度变分推断（NGVI）在非共轭模型下理论分析不足，本文旨在弥补这一缺陷。


<details>
  <summary>Details</summary>
Motivation: 尽管NGVI在变分推断中应用广泛且经验上成功，但其理论基础，特别是在非共轭模型下的理论基础仍然有限。

Method: 本文在均值场参数化下，通过推导变分损失的相对平滑性条件，提出了一种改进的NGVI算法，并证明了其收敛性。此外，在附加结构假设下，揭示了变分损失的隐藏凸性，并建立了NGVI的快速全局收敛性。

Result: 在非共轭模型下，为NGVI的收敛性提供了理论保证，并揭示了其隐藏的凸性。

Conclusion: 本文在理论上加深了对NGVI在具有挑战性的推断设置中的几何和收敛行为的理解，并为改进算法提供了方向。

Abstract: Stochastic Natural Gradient Variational Inference (NGVI) is a widely used
method for approximating posterior distribution in probabilistic models.
Despite its empirical success and foundational role in variational inference,
its theoretical underpinnings remain limited, particularly in the case of
non-conjugate likelihoods. While NGVI has been shown to be a special instance
of Stochastic Mirror Descent, and recent work has provided convergence
guarantees using relative smoothness and strong convexity for conjugate models,
these results do not extend to the non-conjugate setting, where the variational
loss becomes non-convex and harder to analyze. In this work, we focus on
mean-field parameterization and advance the theoretical understanding of NGVI
in three key directions. First, we derive sufficient conditions under which the
variational loss satisfies relative smoothness with respect to a suitable
mirror map. Second, leveraging this structure, we propose a modified NGVI
algorithm incorporating non-Euclidean projections and prove its global
non-asymptotic convergence to a stationary point. Finally, under additional
structural assumptions about the likelihood, we uncover hidden convexity
properties of the variational loss and establish fast global convergence of
NGVI to a global optimum. These results provide new insights into the geometry
and convergence behavior of NGVI in challenging inference settings.

</details>


### [320] [Imbalanced Gradients in RL Post-Training of Multi-Task LLMs](https://arxiv.org/abs/2510.19178)
*Runzhe Wu,Ankur Samanta,Ayush Jain,Scott Fujimoto,Jeongyeol Kwon,Ben Kretzu,Youliang Yu,Kaveh Hassani,Boris Vidolov,Yonathan Efroni*

Main category: cs.LG

TL;DR: 多任务语言模型在进行后训练时，通常会将不同任务的数据集混合并联合优化。然而，这种方法假设所有任务产生的梯度幅度相似，但实际上在强化学习后训练中，某些任务的梯度会显著大于其他任务，导致优化过程偏向于梯度较大的任务。研究发现，梯度大的任务并不一定带来更大的学习收益，甚至可能带来更小的性能提升。梯度不平衡的原因无法通过训练奖励或优势等常规训练统计量来解释，这表明其源于任务本身的固有差异。因此，不应盲目混合数据集，而应在梯度层面进行修正，以实现更有效的模型优化。


<details>
  <summary>Details</summary>
Motivation: 在强化学习后训练中，多任务语言模型常常会遇到梯度不平衡的问题，即某些任务产生的梯度幅度远大于其他任务，导致优化过程偏向于梯度大的任务。然而，梯度大的任务并不一定带来更大的学习收益，这使得原有的优化方法存在潜在的偏差。

Method: 通过实验分析了强化学习后训练中多任务语言模型梯度不平衡的现象，并考察了梯度幅度与学习收益之间的关系。同时，排除了训练奖励或优势等常规训练统计量对梯度不平衡的解释，并将其归因于任务本身的固有差异。

Result: 研究发现，在强化学习后训练中，不同任务产生的梯度幅度存在显著不平衡。梯度大的任务并不一定带来更大的学习收益，其性能提升可能与梯度小的任务相当，甚至更低。这种梯度不平衡现象无法用常规训练统计量来解释，表明其根源在于任务本身的固有差异。

Conclusion: 多任务语言模型在进行强化学习后训练时，不能简单地混合数据集进行联合优化，因为可能存在梯度不平衡问题，导致优化偏向于梯度大的任务，而这些任务的学习收益并不一定更高。未来的研究应关注如何在梯度层面进行修正，以实现更有效的模型优化。

Abstract: Multi-task post-training of large language models (LLMs) is typically
performed by mixing datasets from different tasks and optimizing them jointly.
This approach implicitly assumes that all tasks contribute gradients of similar
magnitudes; when this assumption fails, optimization becomes biased toward
large-gradient tasks. In this paper, however, we show that this assumption
fails in RL post-training: certain tasks produce significantly larger
gradients, thus biasing updates toward those tasks. Such gradient imbalance
would be justified only if larger gradients implied larger learning gains on
the tasks (i.e., larger performance improvements) -- but we find this is not
true. Large-gradient tasks can achieve similar or even much lower learning
gains than small-gradient ones. Further analyses reveal that these gradient
imbalances cannot be explained by typical training statistics such as training
rewards or advantages, suggesting that they arise from the inherent differences
between tasks. This cautions against naive dataset mixing and calls for future
work on principled gradient-level corrections for LLMs.

</details>


### [321] [A Communication-Efficient Decentralized Actor-Critic Algorithm](https://arxiv.org/abs/2510.19199)
*Xiaoxing Ren,Nicola Bastianello,Thomas Parisini,Andreas A. Malikopoulos*

Main category: cs.LG

TL;DR: 该研究提出了一种去中心化的Actor-Critic学习框架，用于解决通信受限的多智能体强化学习问题，并通过局部训练策略减少通信负担，同时保证了网络协调性。


<details>
  <summary>Details</summary>
Motivation: 在通信受限的多智能体系统中，需要一种能够减少通信负担同时保持协调的学习方法。

Method: 提出了一种去中心化的Actor-Critic学习框架，其中每个智能体在与邻居交换信息之前，会对其策略和值函数进行多次局部更新。值函数通过多层神经网络进行近似。

Result: 在马尔可夫采样下，算法在有限时间内收敛到$
u$-精确的平稳点，样本复杂度为$	ilde{	ilde{O}}(
u^{-3})$，通信复杂度为$	ilde{O}(
u^{-1}	au^{-1})$，其中$	au$是局部训练步数。最终误差与神经网络的近似质量相关。

Conclusion: 该去中心化Actor-Critic学习框架能够有效解决通信受限的多智能体强化学习问题，并在合作控制场景下得到了数值实验的验证。

Abstract: In this paper, we study the problem of reinforcement learning in multi-agent
systems where communication among agents is limited. We develop a decentralized
actor-critic learning framework in which each agent performs several local
updates of its policy and value function, where the latter is approximated by a
multi-layer neural network, before exchanging information with its neighbors.
This local training strategy substantially reduces the communication burden
while maintaining coordination across the network. We establish finite-time
convergence analysis for the algorithm under Markov-sampling. Specifically, to
attain the $\varepsilon$-accurate stationary point, the sample complexity is of
order $\mathcal{O}(\varepsilon^{-3})$ and the communication complexity is of
order $\mathcal{O}(\varepsilon^{-1}\tau^{-1})$, where tau denotes the number of
local training steps. We also show how the final error bound depends on the
neural network's approximation quality. Numerical experiments in a cooperative
control setting illustrate and validate the theoretical findings.

</details>


### [322] [An Active Diffusion Neural Network for Graphs](https://arxiv.org/abs/2510.19202)
*Mengying Jiang*

Main category: cs.LG

TL;DR: ADGNN通过引入外部信息源进行主动扩散，解决了传统基于扩散的GNN的过平滑问题，并实现了真正的无限扩散，提高了图任务的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 大多数基于扩散的GNN模仿被动热扩散，容易出现过平滑问题，限制了它们捕获全局图信息的能力。受宇宙热寂的启发，提出主动扩散方法来解决此问题。

Method: 提出主动扩散图神经网络（ADGNN），通过整合多个外部信息源来动态影响扩散过程，并直接计算主动扩散迭代公式的闭式解，以实现真正的无限扩散。

Result: ADGNN在多个图任务上显著优于最先进的GNN模型，提高了准确性和效率，有效捕获了全局图信息并保持了节点的独特性。

Conclusion: ADGNN通过主动扩散有效解决了过平滑问题，实现了真正的无限扩散，在图表示学习任务中表现出优越的性能。

Abstract: The analogy to heat diffusion has enhanced our understanding of information
flow in graphs and inspired the development of Graph Neural Networks (GNNs).
However, most diffusion-based GNNs emulate passive heat diffusion, which still
suffers from over-smoothing and limits their ability to capture global graph
information. Inspired by the heat death of the universe, which posits that
energy distribution becomes uniform over time in a closed system, we recognize
that, without external input, node representations in a graph converge to
identical feature vectors as diffusion progresses. To address this issue, we
propose the Active Diffusion-based Graph Neural Network (ADGNN). ADGNN achieves
active diffusion by integrating multiple external information sources that
dynamically influence the diffusion process, effectively overcoming the
over-smoothing problem. Furthermore, our approach realizes true infinite
diffusion by directly calculating the closed-form solution of the active
diffusion iterative formula. This allows nodes to preserve their unique
characteristics while efficiently gaining comprehensive insights into the
graph's global structure. We evaluate ADGNN against several state-of-the-art
GNN models across various graph tasks. The results demonstrate that ADGNN
significantly improves both accuracy and efficiency, highlighting its
effectiveness in capturing global graph information and maintaining node
distinctiveness.

</details>


### [323] [Enhancing Graph Neural Networks: A Mutual Learning Approach](https://arxiv.org/abs/2510.19223)
*Paul Agbaje,Akajyoti Mitra,Afia Anjum,Pranali Khose,Ebelechukwu Nwafor,Habeeb Olufowobi*

Main category: cs.LG

TL;DR: 本文提出了一种新的知识蒸馏方法，通过GNN模型之间的协同学习，在没有预训练教师模型的情况下，使多个简单的GNN模型能够相互学习，并提升多任务处理能力。


<details>
  <summary>Details</summary>
Motivation: 传统的知识蒸馏方法依赖于预训练的教师模型，但在资源受限的设备上部署高性能模型时，以及在处理多任务时，存在局限性。本研究旨在探索GNN模型之间协同学习的可能性，以克服这些限制。

Method: 提出了一种协同学习框架，其中多个学生GNN模型在训练过程中相互教学。引入了自适应logit加权单元来促进模型之间的知识交换，并采用熵增强技术来改善互学效果。

Result: 在三个用于节点分类和图分类的数据集上进行了广泛的实验，证明了该方法的有效性。

Conclusion: 所提出的协同学习框架能够使多个简单的GNN模型在没有预训练教师模型的情况下，通过相互学习有效地提升性能，尤其在处理多任务方面表现出色。

Abstract: Knowledge distillation (KD) techniques have emerged as a powerful tool for
transferring expertise from complex teacher models to lightweight student
models, particularly beneficial for deploying high-performance models in
resource-constrained devices. This approach has been successfully applied to
graph neural networks (GNNs), harnessing their expressive capabilities to
generate node embeddings that capture structural and feature-related
information. In this study, we depart from the conventional KD approach by
exploring the potential of collaborative learning among GNNs. In the absence of
a pre-trained teacher model, we show that relatively simple and shallow GNN
architectures can synergetically learn efficient models capable of performing
better during inference, particularly in tackling multiple tasks. We propose a
collaborative learning framework where ensembles of student GNNs mutually teach
each other throughout the training process. We introduce an adaptive logit
weighting unit to facilitate efficient knowledge exchange among models and an
entropy enhancement technique to improve mutual learning. These components
dynamically empower the models to adapt their learning strategies during
training, optimizing their performance for downstream tasks. Extensive
experiments conducted on three datasets each for node and graph classification
demonstrate the effectiveness of our approach.

</details>


### [324] [ConvXformer: Differentially Private Hybrid ConvNeXt-Transformer for Inertial Navigation](https://arxiv.org/abs/2510.19352)
*Omer Tariq,Muhammad Bilal,Muneeb Ul Hassan,Dongsoo Han,Jon Crowcroft*

Main category: cs.LG

TL;DR: ConvXformer是一种结合了ConvNeXt和Transformer的新型混合架构，通过自适应梯度裁剪和梯度对齐噪声注入（GANI）的差分隐私机制，在保证差分隐私的同时提高了惯性导航的精度和鲁棒性，并在多个数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的惯性导航系统在提供高精度定位的同时，存在隐私泄露风险，而现有的差分隐私解决方案往往会损害模型性能，尤其是在处理高频惯性测量时。

Method: 提出了一种名为ConvXformer的混合架构，融合了ConvNeXt块和Transformer编码器。该模型采用了一种差分隐私机制，包括自适应梯度裁剪和梯度对齐噪声注入（GANI），并利用截断奇异值分解（SVD）来控制隐私-效用权衡。

Result: 在OxIOD、RIDI和RoNIN数据集上，ConvXformer的定位精度比最先进的方法提高了40%以上，同时满足了$(\epsilon,\delta)$-差分隐私保证。在KAIST机械工程学院收集的新数据集Mech-IO上，该模型也表现出良好的鲁棒性，能够应对工业设备产生的强磁场干扰。

Conclusion: ConvXformer通过结合混合架构和创新的差分隐私机制，在提高惯性导航精度和鲁棒性的同时，有效保护了用户隐私，适用于网络物理系统中的安全导航。

Abstract: Data-driven inertial sequence learning has revolutionized navigation in
GPS-denied environments, offering superior odometric resolution compared to
traditional Bayesian methods. However, deep learning-based inertial tracking
systems remain vulnerable to privacy breaches that can expose sensitive
training data. \hl{Existing differential privacy solutions often compromise
model performance by introducing excessive noise, particularly in
high-frequency inertial measurements.} In this article, we propose ConvXformer,
a hybrid architecture that fuses ConvNeXt blocks with Transformer encoders in a
hierarchical structure for robust inertial navigation. We propose an efficient
differential privacy mechanism incorporating adaptive gradient clipping and
gradient-aligned noise injection (GANI) to protect sensitive information while
ensuring model performance. Our framework leverages truncated singular value
decomposition for gradient processing, enabling precise control over the
privacy-utility trade-off. Comprehensive performance evaluations on benchmark
datasets (OxIOD, RIDI, RoNIN) demonstrate that ConvXformer surpasses
state-of-the-art methods, achieving more than 40% improvement in positioning
accuracy while ensuring $(\epsilon,\delta)$-differential privacy guarantees. To
validate real-world performance, we introduce the Mech-IO dataset, collected
from the mechanical engineering building at KAIST, where intense magnetic
fields from industrial equipment induce significant sensor perturbations. This
demonstrated robustness under severe environmental distortions makes our
framework well-suited for secure and intelligent navigation in cyber-physical
systems.

</details>


### [325] [Controllable Machine Unlearning via Gradient Pivoting](https://arxiv.org/abs/2510.19226)
*Youngsik Hwang,Dong-Young Lim*

Main category: cs.LG

TL;DR: Machine unlearning (MU) can be reframed as a multi-objective optimization (MOO) problem, leading to a novel algorithm called CUP that allows for controllable trade-offs between unlearning efficacy and model fidelity by navigating the Pareto frontier.


<details>
  <summary>Details</summary>
Motivation: Approximate unlearning methods (SOO) face challenges like over-forgetting, lack of fine-grained control, and no holistic evaluation metrics. This paper addresses these by reframing MU as MOO.

Method: The paper proposes a novel algorithm, Controllable Unlearning by Pivoting Gradient (CUP), which uses a pivoting mechanism to navigate the Pareto frontier, controlled by an 'unlearning intensity' hyperparameter. The hypervolume indicator is used for evaluation.

Result: CUP generates a superior set of Pareto-optimal solutions, outperforming existing methods across various vision tasks.

Conclusion: CUP effectively addresses the limitations of SOO-based unlearning by providing controllable trade-offs and superior performance in MU tasks.

Abstract: Machine unlearning (MU) aims to remove the influence of specific data from a
trained model. However, approximate unlearning methods, often formulated as a
single-objective optimization (SOO) problem, face a critical trade-off between
unlearning efficacy and model fidelity. This leads to three primary challenges:
the risk of over-forgetting, a lack of fine-grained control over the unlearning
process, and the absence of metrics to holistically evaluate the trade-off. To
address these issues, we reframe MU as a multi-objective optimization (MOO)
problem. We then introduce a novel algorithm, Controllable Unlearning by
Pivoting Gradient (CUP), which features a unique pivoting mechanism. Unlike
traditional MOO methods that converge to a single solution, CUP's mechanism is
designed to controllably navigate the entire Pareto frontier. This navigation
is governed by a single intuitive hyperparameter, the `unlearning intensity',
which allows for precise selection of a desired trade-off. To evaluate this
capability, we adopt the hypervolume indicator, a metric that captures both the
quality and diversity of the entire set of solutions an algorithm can generate.
Our experimental results demonstrate that CUP produces a superior set of
Pareto-optimal solutions, consistently outperforming existing methods across
various vision tasks.

</details>


### [326] [Brain-Inspired Perspective on Configurations: Unsupervised Similarity and Early Cognition](https://arxiv.org/abs/2510.19229)
*Juntang Wang,Yihan Wang,Hao Wu,Dongmian Zou,Shixin Xu*

Main category: cs.LG

TL;DR: 本文提出了一种名为“配置”的有限分辨率聚类框架，该框架受大脑启发，能模拟婴儿的学习方式，实现分层组织、新颖性检测和灵活适应。


<details>
  <summary>Details</summary>
Motivation: 婴儿在无监督的情况下即可发现类别、检测新颖性并适应新环境，这对当前机器学习是一个挑战。

Method: 提出了一种名为“配置”的有限分辨率聚类框架，该框架使用单一分辨率参数和吸引-排斥动力学来实现分层组织、新颖性敏感性和灵活适应。为了评估这些特性，引入了 mheatmap 工具，它提供比例热图和重新分配算法来公平评估多分辨率和动态行为。

Result: 在多个数据集上，“配置”在标准聚类指标上具有竞争力，在新颖性检测方面达到了 87% 的 AUC，在动态类别演变期间表现出 35% 的更高稳定性。

Conclusion: “配置”被定位为早期认知分类的一个有原则的计算模型，也是迈向受大脑启发的 AI 的一步。

Abstract: Infants discover categories, detect novelty, and adapt to new contexts
without supervision -- a challenge for current machine learning. We present a
brain-inspired perspective on configurations, a finite-resolution clustering
framework that uses a single resolution parameter and attraction-repulsion
dynamics to yield hierarchical organization, novelty sensitivity, and flexible
adaptation. To evaluate these properties, we introduce mheatmap, which provides
proportional heatmaps and a reassignment algorithm to fairly assess
multi-resolution and dynamic behavior. Across datasets, configurations are
competitive on standard clustering metrics, achieve 87% AUC in novelty
detection, and show 35% better stability during dynamic category evolution.
These results position configurations as a principled computational model of
early cognitive categorization and a step toward brain-inspired AI.

</details>


### [327] [Understanding the Implicit Biases of Design Choices for Time Series Foundation Models](https://arxiv.org/abs/2510.19236)
*Annan Yu,Danielle C. Maddix,Boran Han,Xiyuan Zhang,Abdul Fatir Ansari,Oleksandr Shchur,Christos Faloutsos,Andrew Gordon Wilson,Michael W. Mahoney,Yuyang Wang*

Main category: cs.LG

TL;DR: 论文提出时间序列基础模型（TSFMs）的行为受设计中微妙的归纳偏置影响，并旨在通过理论和实证研究来理解训练过程中的各种“旋钮”如何影响模型质量，而不是开发新模型。


<details>
  <summary>Details</summary>
Motivation: 论文旨在理解训练过程中的各种设计选择（如 patch 大小、嵌入选择、训练目标等）如何影响时间序列基础模型（TSFM）的质量，而不是声称模型优于现有模型。

Method: 论文结合理论和受控的实证评估，识别了几个设计选择，并展示了它们如何导致模型基本属性（如时间行为、几何结构、向均值回归的程度等）的隐式偏置。

Result: 研究表明，这些隐式偏置可能是直观的，也可能非常违反直觉，具体取决于模型和数据的属性。此外，论文还通过一个关于异常值处理的案例研究，说明了多种偏置如何以复杂的方式相互作用。

Conclusion: 论文讨论了研究结果对学习“苦涩教训”和构建 TSFMs 的启示。

Abstract: Time series foundation models (TSFMs) are a class of potentially powerful,
general-purpose tools for time series forecasting and related temporal tasks,
but their behavior is strongly shaped by subtle inductive biases in their
design. Rather than developing a new model and claiming that it is better than
existing TSFMs, e.g., by winning on existing well-established benchmarks, our
objective is to understand how the various ``knobs'' of the training process
affect model quality. Using a mix of theory and controlled empirical
evaluation, we identify several design choices (patch size, embedding choice,
training objective, etc.) and show how they lead to implicit biases in
fundamental model properties (temporal behavior, geometric structure, how
aggressively or not the model regresses to the mean, etc.); and we show how
these biases can be intuitive or very counterintuitive, depending on properties
of the model and data. We also illustrate in a case study on outlier handling
how multiple biases can interact in complex ways; and we discuss implications
of our results for learning the bitter lesson and building TSFMs.

</details>


### [328] [Semantic World Models](https://arxiv.org/abs/2510.19818)
*Jacob Berg,Chuning Zhu,Yanda Bao,Ishan Durugkar,Abhishek Gupta*

Main category: cs.LG

TL;DR: Instead of reconstructing future frames as pixels, world models only need to predict task-relevant semantic information about the future. This approach frames world modeling as a visual question answering problem about semantic information in future frames, allowing the use of vision-language models trained as "semantic" world models for policy improvement on robotics tasks.


<details>
  <summary>Details</summary>
Motivation: Conventional approaches train models to predict future frames, but pixel reconstruction doesn

Method: The paper proposes framing world modeling as a visual question answering problem about semantic information in future frames. This allows for the use of vision-language models, trained via supervised finetuning on image-action-text data, as "semantic" world models.

Result: Vision-language models trained as semantic world models show significant generalization improvements over reconstruction-based world modeling paradigms when used for policy improvement on open-ended robotics tasks.

Conclusion: Semantic world models, which predict task-relevant semantic information rather than pixel reconstruction, offer a more effective approach for robotic control and planning, inheriting generalization and robustness from pre-trained vision-language models.

Abstract: Planning with world models offers a powerful paradigm for robotic control.
Conventional approaches train a model to predict future frames conditioned on
current frames and actions, which can then be used for planning. However, the
objective of predicting future pixels is often at odds with the actual planning
objective; strong pixel reconstruction does not always correlate with good
planning decisions. This paper posits that instead of reconstructing future
frames as pixels, world models only need to predict task-relevant semantic
information about the future. For such prediction the paper poses world
modeling as a visual question answering problem about semantic information in
future frames. This perspective allows world modeling to be approached with the
same tools underlying vision language models. Thus vision language models can
be trained as "semantic" world models through a supervised finetuning process
on image-action-text data, enabling planning for decision-making while
inheriting many of the generalization and robustness properties from the
pretrained vision-language models. The paper demonstrates how such a semantic
world model can be used for policy improvement on open-ended robotics tasks,
leading to significant generalization improvements over typical paradigms of
reconstruction-based action-conditional world modeling. Website available at
https://weirdlabuw.github.io/swm.

</details>


### [329] [SPOT: Scalable Policy Optimization with Trees for Markov Decision Processes](https://arxiv.org/abs/2510.19241)
*Xuyuan Xiong,Pedro Chumpitaz-Flores,Kaixun Hua,Cheng Hua*

Main category: cs.LG

TL;DR: SPOT是一种新颖的计算决策树策略的方法，通过将优化问题公式化为混合整数线性规划（MILP）来解决可解释强化学习策略的挑战，并采用简化的分支定界法来提高效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 可解释的强化学习策略对于高风险决策至关重要，但在马尔可夫决策过程（MDP）中优化决策树策略仍然是一个挑战。

Method: 提出了一种名为SPOT的新颖方法，将优化问题构建为混合整数线性规划（MILP），并采用简化的分支定界法来解耦MDP动态和树结构约束，从而实现高效的并行搜索。

Result: SPOT在标准基准测试中实现了显著的加速，并且能够扩展到具有更多状态的更大MDP。其生成的决策树策略具有可解释性和紧凑性，在不影响性能的情况下保持了透明度。

Conclusion: SPOT方法能够同时实现可解释性和可扩展性，并且比现有方法快一个数量级地提供高质量的策略，有效地解决了在MDP中优化可解释决策树策略的挑战。

Abstract: Interpretable reinforcement learning policies are essential for high-stakes
decision-making, yet optimizing decision tree policies in Markov Decision
Processes (MDPs) remains challenging. We propose SPOT, a novel method for
computing decision tree policies, which formulates the optimization problem as
a mixed-integer linear program (MILP). To enhance efficiency, we employ a
reduced-space branch-and-bound approach that decouples the MDP dynamics from
tree-structure constraints, enabling efficient parallel search. This
significantly improves runtime and scalability compared to previous methods.
Our approach ensures that each iteration yields the optimal decision tree.
Experimental results on standard benchmarks demonstrate that SPOT achieves
substantial speedup and scales to larger MDPs with a significantly higher
number of states. The resulting decision tree policies are interpretable and
compact, maintaining transparency without compromising performance. These
results demonstrate that our approach simultaneously achieves interpretability
and scalability, delivering high-quality policies an order of magnitude faster
than existing approaches.

</details>


### [330] [Interpret Policies in Deep Reinforcement Learning using SILVER with RL-Guided Labeling: A Model-level Approach to High-dimensional and Multi-action Environments](https://arxiv.org/abs/2510.19244)
*Yiyu Qian,Su Nguyen,Chao Chen,Qinyue Zhou,Liyuan Zhao*

Main category: cs.LG

TL;DR: 本研究提出了一种改进的SILVER框架，名为“RL-guided labeling”，以增强深度强化学习（RL）策略的可解释性，解决了现有SILVER框架在处理多动作和高维环境时的局限性。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习（RL）虽然性能强大，但缺乏可解释性，限制了对其策略行为的信任。现有的SILVER框架虽然能解释RL策略，但仅限于低维、二元动作领域。

Method: 本研究提出了一种名为“RL-guided labeling”的SILVER增强变体，通过整合RL策略自身的动作输出来识别边界点，从而将其扩展到多动作和高维环境。该方法首先从图像观测中提取紧凑的特征表示，进行基于SHAP的特征归因，然后利用RL-guided labeling生成行为一致的边界数据集。接着，训练决策树和基于回归的函数等代理模型来解释RL策略的决策结构。

Result: 在两个Atari环境和三种深度RL算法上的评估结果表明，该方法在保持竞争性任务性能的同时，显著提高了透明度和人类对智能体行为的理解。此外，一项人类受试者研究也证实了所衍生的可解释策略的清晰度和可信度。

Conclusion: 这项工作通过将SILVER框架转化为一个可扩展、行为感知的框架，用于解释高维、多动作设置中的深度RL智能体，从而推动了可解释RL的发展。

Abstract: Deep reinforcement learning (RL) achieves remarkable performance but lacks
interpretability, limiting trust in policy behavior. The existing SILVER
framework (Li, Siddique, and Cao 2025) explains RL policy via Shapley-based
regression but remains restricted to low-dimensional, binary-action domains. We
propose SILVER with RL-guided labeling, an enhanced variant that extends SILVER
to multi-action and high-dimensional environments by incorporating the RL
policy's own action outputs into the boundary points identification. Our method
first extracts compact feature representations from image observations,
performs SHAP-based feature attribution, and then employs RL-guided labeling to
generate behaviorally consistent boundary datasets. Surrogate models, such as
decision trees and regression-based functions, are subsequently trained to
interpret RL policy's decision structure. We evaluate the proposed framework on
two Atari environments using three deep RL algorithms and conduct human-subject
study to assess the clarity and trustworthiness of the derived interpretable
policy. Results show that our approach maintains competitive task performance
while substantially improving transparency and human understanding of agent
behavior. This work advances explainable RL by transforming SILVER into a
scalable and behavior-aware framework for interpreting deep RL agents in
high-dimensional, multi-action settings.

</details>


### [331] [Mixing Configurations for Downstream Prediction](https://arxiv.org/abs/2510.19248)
*Juntang Wang,Hao Wu,Runkun Guo,Yihan Wang,Dongmian Zou,Shixin Xu*

Main category: cs.LG

TL;DR: 本文提出了一种名为GraMixC的即插即用模块，用于从Vision Transformers的寄存器令牌中提取和融合配置，以改进下游任务的性能。


<details>
  <summary>Details</summary>
Motivation: 模仿人类按相似性对物体进行分组的内在能力，并克服现有聚类算法在发现分层聚类方面的局限性。

Method: 开发了一种名为GraMixC的模块，该模块利用反向合并/拆分（RMS）技术提取和对齐配置，并通过注意力头进行融合。

Result: 在DSN1 16S rRNA培养-介质预测任务上，GraMixC将R2分数从0.6提高到0.9，在标准表格基准测试中也持续优于基线方法。

Conclusion: GraMixC通过提取和融合分层聚类配置，在各种下游任务中都显示出优越的性能，代表了该领域的一项重大进展。

Abstract: Humans possess an innate ability to group objects by similarity, a cognitive
mechanism that clustering algorithms aim to emulate. Recent advances in
community detection have enabled the discovery of configurations -- valid
hierarchical clusterings across multiple resolution scales -- without requiring
labeled data. In this paper, we formally characterize these configurations and
identify similar emergent structures in register tokens within Vision
Transformers. Unlike register tokens, configurations exhibit lower redundancy
and eliminate the need for ad hoc selection. They can be learned through
unsupervised or self-supervised methods, yet their selection or composition
remains specific to the downstream task and input. Building on these insights,
we introduce GraMixC, a plug-and-play module that extracts configurations,
aligns them using our Reverse Merge/Split (RMS) technique, and fuses them via
attention heads before forwarding them to any downstream predictor. On the DSN1
16S rRNA cultivation-media prediction task, GraMixC improves the R2 score from
0.6 to 0.9 across multiple methods, setting a new state of the art. We further
validate GraMixC on standard tabular benchmarks, where it consistently
outperforms single-resolution and static-feature baselines.

</details>


### [332] [FnRGNN: Distribution-aware Fairness in Graph Neural Network](https://arxiv.org/abs/2510.19257)
*Soyoung Park,Sungsu Lim*

Main category: cs.LG

TL;DR: FnRGNN 通过在结构、表示和预测三个层面进行干预，实现了图神经网络在节点回归任务中的公平性。


<details>
  <summary>Details</summary>
Motivation: 现有的 GNN 公平性方法主要关注分类任务和表示层面的偏见消除，未能充分解决节点级回归任务的连续性问题。

Method: 提出了一种名为 FnRGNN 的 in-processing 框架，通过以下三个层面的干预来确保公平性：(1) 结构层面：边重加权；(2) 表示层面：使用 MMD 进行对齐；(3) 预测层面：通过基于 Sinkhorn 的分布匹配进行归一化。

Result: 在四个真实世界数据集上的实验表明，FnRGNN 在不牺牲模型性能的情况下，有效减少了群体间的回归差异。

Conclusion: FnRGNN 是一种多层面的公平性感知框架，能够处理复杂的图拓扑结构，在 GNN 节点回归任务中实现鲁棒的公平性。

Abstract: Graph Neural Networks (GNNs) excel at learning from structured data, yet
fairness in regression tasks remains underexplored. Existing approaches mainly
target classification and representation-level debiasing, which cannot fully
address the continuous nature of node-level regression. We propose FnRGNN, a
fairness-aware in-processing framework for GNN-based node regression that
applies interventions at three levels: (i) structure-level edge reweighting,
(ii) representation-level alignment via MMD, and (iii) prediction-level
normalization through Sinkhorn-based distribution matching. This multi-level
strategy ensures robust fairness under complex graph topologies. Experiments on
four real-world datasets demonstrate that FnRGNN reduces group disparities
without sacrificing performance. Code is available at
https://github.com/sybeam27/FnRGNN.

</details>


### [333] [Data Efficient Any Transformer-to-Mamba Distillation via Attention Bridge](https://arxiv.org/abs/2510.19266)
*Penghao Wang,Yuhao Zhou,Mengxuan Wu,Panpan Zhang,Zhangyang Wang,Kai Wang*

Main category: cs.LG

TL;DR: CAB是一个新颖的数据高效蒸馏框架，通过注意力桥接将Transformer教师模型的注意力知识高效地转移到状态空间学生模型。


<details>
  <summary>Details</summary>
Motivation: 由于状态空间模型（SSM）的训练成本高昂且生态系统不如Transformer成熟，以及SSM和Transformer之间的结构异构性，使得从预训练的注意力模型中有效提取知识变得困难。

Method: 提出了一种名为注意力桥（CAB）的新颖数据高效蒸馏框架，它通过一个轻量级的桥接器和灵活的层间对齐，实现了从Transformer教师模型到状态空间学生模型的注意力知识的跨架构蒸馏，实现了Token级别的监督。

Result: 在视觉和语言领域进行了广泛的实验，证明了CAB在有限的训练数据下，能够持续提升状态空间模型的性能，并且优于标准的知识蒸馏和跨架构蒸馏方法。

Conclusion: 基于注意力的知识可以被有效地转移到循环模型中，从而能够快速利用Transformer的专业知识来构建更强大的SSM社区。

Abstract: State-space models (SSMs) have emerged as efficient alternatives to
Transformers for sequence modeling, offering superior scalability through
recurrent structures. However, their training remains costly and the ecosystem
around them is far less mature than that of Transformers. Moreover, the
structural heterogeneity between SSMs and Transformers makes it challenging to
efficiently distill knowledge from pretrained attention models. In this work,
we propose Cross-architecture distillation via Attention Bridge (CAB), a novel
data-efficient distillation framework that efficiently transfers attention
knowledge from Transformer teachers to state-space student models. Unlike
conventional knowledge distillation that transfers knowledge only at the output
level, CAB enables token-level supervision via a lightweight bridge and
flexible layer-wise alignment, improving both efficiency and transferability.
We further introduce flexible layer-wise alignment strategies to accommodate
architectural discrepancies between teacher and student. Extensive experiments
across vision and language domains demonstrate that our method consistently
improves the performance of state-space models, even under limited training
data, outperforming both standard and cross-architecture distillation methods.
Our findings suggest that attention-based knowledge can be efficiently
transferred to recurrent models, enabling rapid utilization of Transformer
expertise for building a stronger SSM community.

</details>


### [334] [Knowledge Distillation of Uncertainty using Deep Latent Factor Model](https://arxiv.org/abs/2510.19290)
*Sehyun Park,Jongjin Lee,Yunseop Shin,Ilsang Ohn,Yongdai Kim*

Main category: cs.LG

TL;DR: 深度集成模型虽然能提供最前沿、可靠的不确定性量化，但其高昂的计算和内存需求阻碍了它们在如设备端AI等实际应用中的部署。知识蒸馏可以将集成模型压缩为小型学生模型，但现有技术难以保留不确定性，因为减小深度神经网络（DNN）的尺寸通常会导致方差减小。为了解决这一限制，我们引入了一种新的分布蒸馏方法（即将教师集成模型压缩为学生分布而非学生集成模型），称为高斯蒸馏。该方法通过一种特殊的**高斯过程**——深度潜在因子模型（DLF）——来估计教师集成模型的分布，将教师集成模型的每个成员视为某个随机过程的实现。通过期望最大化（EM）算法稳定地估计DLF模型中的均值和协方差函数。通过多个基准数据集的实验，我们证明了所提出**高斯蒸馏**方法的性能优于现有基线方法。此外，我们还展示了高斯蒸馏在语言模型微调和分布偏移问题上的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的深度集成模型在不确定性量化方面表现优异，但计算和内存开销大，限制了其在实际应用中的部署。现有的知识蒸馏技术在压缩模型的同时难以保留不确定性，因为模型尺寸减小通常伴随着方差减小。

Method: 提出一种名为“高斯蒸馏”的分布蒸馏方法，将教师集成模型压缩为学生分布，而不是学生集成模型。该方法利用深度潜在因子模型（DLF）来估计教师集成模型的分布，将集成模型的每个成员视为随机过程的实现。通过期望最大化（EM）算法来估计DLF模型的均值和协方差函数。

Result: 通过在多个基准数据集上的实验表明，高斯蒸馏方法的性能优于现有基线方法。该方法在语言模型微调和处理分布偏移问题上也表现良好。

Conclusion: 高斯蒸馏是一种有效的方法，可以解决深度集成模型高计算和内存开销的问题，同时保留了不确定性量化能力，并在各种下游任务中表现出色。

Abstract: Deep ensembles deliver state-of-the-art, reliable uncertainty quantification,
but their heavy computational and memory requirements hinder their practical
deployments to real applications such as on-device AI. Knowledge distillation
compresses an ensemble into small student models, but existing techniques
struggle to preserve uncertainty partly because reducing the size of DNNs
typically results in variation reduction. To resolve this limitation, we
introduce a new method of distribution distillation (i.e. compressing a teacher
ensemble into a student distribution instead of a student ensemble) called
Gaussian distillation, which estimates the distribution of a teacher ensemble
through a special Gaussian process called the deep latent factor model (DLF) by
treating each member of the teacher ensemble as a realization of a certain
stochastic process. The mean and covariance functions in the DLF model are
estimated stably by using the expectation-maximization (EM) algorithm. By using
multiple benchmark datasets, we demonstrate that the proposed Gaussian
distillation outperforms existing baselines. In addition, we illustrate that
Gaussian distillation works well for fine-tuning of language models and
distribution shift problems.

</details>


### [335] [Loopholing Discrete Diffusion: Deterministic Bypass of the Sampling Wall](https://arxiv.org/abs/2510.19304)
*Mingyu Jo,Jaesik Yoon,Justin Deschenaux,Caglar Gulcehre,Sungjin Ahn*

Main category: cs.LG

TL;DR: Loopholing是一种新的机制，用于解决离散扩散模型中的采样问题，通过引入确定性潜在路径来保留信息，从而提高文本生成质量和推理能力。


<details>
  <summary>Details</summary>
Motivation: 离散扩散模型虽然具有并行解码的优势，但存在采样问题，即一旦进行分类采样，信息就会丢失，导致后续步骤信息不足。

Method: 提出了一种名为Loopholing的新机制，并将其应用于离散扩散模型，形成Loopholing离散扩散模型（LDDMs）。该模型采用自监督策略进行高效训练，并通过确定性潜在路径保留信息。

Result: LDDMs在生成任务上取得了显著的性能提升，生成困惑度降低高达61%，在某些情况下甚至超过了自回归模型。此外，LDDMs在算术推理任务（如Countdown和Game of 24）上也表现出色，并能生成更连贯的文本。

Conclusion: Loopholing机制有效地解决了离散扩散模型中的信息丢失问题，提高了生成质量和推理能力，为实现高质量的非自回归文本生成提供了可扩展的途径。

Abstract: Discrete diffusion models offer a promising alternative to autoregressive
generation through parallel decoding, but they suffer from a sampling wall:
once categorical sampling occurs, rich distributional information collapses
into one-hot vectors and cannot be propagated across steps, forcing subsequent
steps to operate with limited information. To mitigate this problem, we
introduce Loopholing, a novel and simple mechanism that preserves this
information via a deterministic latent pathway, leading to Loopholing Discrete
Diffusion Models (LDDMs). Trained efficiently with a self-conditioning
strategy, LDDMs achieve substantial gains-reducing generative perplexity by up
to 61% over prior baselines, closing (and in some cases surpassing) the gap
with autoregressive models, and producing more coherent text. Applied to
reasoning tasks, LDDMs also improve performance on arithmetic benchmarks such
as Countdown and Game of 24. These results also indicate that loopholing
mitigates idle steps and oscillations, providing a scalable path toward
high-quality non-autoregressive text generation.

</details>


### [336] [FrogDeepSDM: Improving Frog Counting and Occurrence Prediction Using Multimodal Data and Pseudo-Absence Imputation](https://arxiv.org/abs/2510.19305)
*Chirag Padubidri,Pranesh Velmurugan,Andreas Lanitis,Andreas Kamilaris*

Main category: cs.LG

TL;DR: 本研究通过深度学习和数据填充技术，结合多模态数据，提高了青蛙物种分布模型（SDM）的准确性，尤其在数据稀疏的情况下，为生物多样性监测提供了更精确和可扩展的方法。


<details>
  <summary>Details</summary>
Motivation: 传统物种分布监测方法存在覆盖范围和完整性限制，本研究旨在利用深度学习和数据填充技术，提高物种分布模型（SDM）的准确性，以应对数据稀疏或不完整的情况，从而改进青蛙物种的监测和保护工作。

Method: 本研究采用深度学习和数据填充技术，结合EY-2022生物多样性挑战赛的数据，对青蛙物种分布模型（SDM）进行优化。具体方法包括数据平衡、特征选择以及构建多模态集成模型（融合土地覆盖、NDVI等环境因子），并进行图像和表格数据的融合。

Result: 数据平衡显著提高了模型性能，青蛙计数任务的平均绝对误差（MAE）从189降至29。特征选择识别出影响物种分布的关键环境因素。多模态集成模型在青蛙计数和栖息地分类任务中表现优于单一模型，准确率达到84.9%，AUC为0.90，并展现了良好的泛化能力。

Conclusion: 多模态学习以及数据平衡和填充等数据预处理技术，能够有效提升物种分布预测模型的准确性，特别是在数据稀疏或不完整时，为实现更精确、可扩展的生物多样性监测提供了有力支持。

Abstract: Monitoring species distribution is vital for conservation efforts, enabling
the assessment of environmental impacts and the development of effective
preservation strategies. Traditional data collection methods, including citizen
science, offer valuable insights but remain limited in coverage and
completeness. Species Distribution Modelling (SDM) helps address these gaps by
using occurrence data and environmental variables to predict species presence
across large regions. In this study, we enhance SDM accuracy for frogs (Anura)
by applying deep learning and data imputation techniques using data from the
"EY - 2022 Biodiversity Challenge." Our experiments show that data balancing
significantly improved model performance, reducing the Mean Absolute Error
(MAE) from 189 to 29 in frog counting tasks. Feature selection identified key
environmental factors influencing occurrence, optimizing inputs while
maintaining predictive accuracy. The multimodal ensemble model, integrating
land cover, NDVI, and other environmental inputs, outperformed individual
models and showed robust generalization across unseen regions. The fusion of
image and tabular data improved both frog counting and habitat classification,
achieving 84.9% accuracy with an AUC of 0.90. This study highlights the
potential of multimodal learning and data preprocessing techniques such as
balancing and imputation to improve predictive ecological modeling when data
are sparse or incomplete, contributing to more precise and scalable
biodiversity monitoring.

</details>


### [337] [Calibration and Discrimination Optimization Using Clusters of Learned Representation](https://arxiv.org/abs/2510.19328)
*Tomer Lavi,Bracha Shapira,Nadav Rappoport*

Main category: cs.LG

TL;DR: 该研究提出了一种新颖的校准流程，通过集成在学习到的输入样本表示簇上训练的校准函数集成，来提高模型在临床预测等关键决策中的校准度，并将校准分数提高了82.28%至100%，同时引入了一种新的匹配指标来优化区分度和校准度。


<details>
  <summary>Details</summary>
Motivation: 为了提高机器学习模型在临床预测等关键决策中的可靠性，需要同时关注区分度和校准度，而目前校准度往往被忽视。

Method: 提出了一种新颖的校准流程，该流程利用在学习到的表示的簇上训练的校准函数集成。该方法还引入了一个匹配指标来优化区分度和校准度。

Result: 与现有方法相比，该校准流程将校准分数从82.28%提高到100%，并能同时优化区分度和校准度。

Conclusion: 所提出的校准流程是一种通用的方法，可以适应任何潜在的表示、聚类、校准方法和指标，能够提高模型的校准性能，并能同时优化区分度和校准度。

Abstract: Machine learning models are essential for decision-making and risk
assessment, requiring highly reliable predictions in terms of both
discrimination and calibration. While calibration often receives less
attention, it is crucial for critical decisions, such as those in clinical
predictions. We introduce a novel calibration pipeline that leverages an
ensemble of calibration functions trained on clusters of learned
representations of the input samples to enhance overall calibration. This
approach not only improves the calibration score of various methods from 82.28%
up to 100% but also introduces a unique matching metric that ensures model
selection optimizes both discrimination and calibration. Our generic scheme
adapts to any underlying representation, clustering, calibration methods and
metric, offering flexibility and superior performance across commonly used
calibration methods.

</details>


### [338] [Every Attention Matters: An Efficient Hybrid Architecture for Long-Context Reasoning](https://arxiv.org/abs/2510.19338)
*Ling Team,Bin Han,Caizhi Tang,Chen Liang,Donghao Zhang,Fan Yuan,Feng Zhu,Jie Gao,Jingyu Hu,Longfei Li,Meng Li,Mingyang Zhang,Peijie Jiang,Peng Jiao,Qian Zhao,Qingyuan Yang,Wenbo Shen,Xinxing Yang,Yalin Zhang,Yankun Ren,Yao Zhao,Yibo Cao,Yixuan Sun,Yue Zhang,Yuchen Fang,Zibin Lin,Zixuan Cheng,Jun Zhou*

Main category: cs.LG

TL;DR: Ring-linear模型系列（Ring-mini-linear-2.0 和 Ring-flash-linear-2.0）通过结合线性注意力和 Softmax 注意力，在长上下文推理中显著降低了 I/O 和计算开销，推理成本比 32B 密集模型低 10 倍，比原始 Ring 系列低 50%。


<details>
  <summary>Details</summary>
Motivation: 该技术报告旨在提出并评估 Ring-linear 模型系列，以解决长上下文推理中的 I/O 和计算开销问题，并优化模型结构和训练效率。

Method: 提出包含 Ring-mini-linear-2.0（16B 参数）和 Ring-flash-linear-2.0（104B 参数）的 Ring-linear 模型系列，采用混合架构结合线性注意力和 Softmax 注意力，并利用自研的高性能 FP8 算子库 linghe 进行训练。

Result: Ring-linear 模型系列将推理成本降低到原来的 1/10（相比 32B 密集模型）和 50%（相比原始 Ring 系列）。通过系统性探索，确定了最优的混合注意力结构。使用 linghe 库将训练效率提高了 50%。模型在多个复杂推理基准测试中保持了 SOTA 性能。

Conclusion: Ring-linear 模型系列通过混合注意力架构和优化的训练方法，在长上下文推理任务中实现了显著的成本效益和高性能，并在复杂推理任务上达到了当前最佳水平。

Abstract: In this technical report, we present the Ring-linear model series,
specifically including Ring-mini-linear-2.0 and Ring-flash-linear-2.0.
Ring-mini-linear-2.0 comprises 16B parameters and 957M activations, while
Ring-flash-linear-2.0 contains 104B parameters and 6.1B activations. Both
models adopt a hybrid architecture that effectively integrates linear attention
and softmax attention, significantly reducing I/O and computational overhead in
long-context inference scenarios. Compared to a 32 billion parameter dense
model, this series reduces inference cost to 1/10, and compared to the original
Ring series, the cost is also reduced by over 50%. Furthermore, through
systematic exploration of the ratio between different attention mechanisms in
the hybrid architecture, we have identified the currently optimal model
structure. Additionally, by leveraging our self-developed high-performance FP8
operator library-linghe, overall training efficiency has been improved by 50%.
Benefiting from the high alignment between the training and inference engine
operators, the models can undergo long-term, stable, and highly efficient
optimization during the reinforcement learning phase, consistently maintaining
SOTA performance across multiple challenging complex reasoning benchmarks.

</details>


### [339] [Foundation Model Forecasts: Form and Function](https://arxiv.org/abs/2510.19345)
*Alvaro Perez-Diaz,James C. Loach,Danielle E. Toutoungi,Lee Middleton*

Main category: cs.LG

TL;DR: 时间序列基础模型（TSFM）虽然预测准确率高，但准确率本身并不能决定其实际价值。预测的形式（点预测、分位数预测、参数预测或轨迹集成）会根本性地限制其支持的操作任务。我们调查了最近的TSFM，发现三分之二的模型只产生点预测或参数预测，而许多操作任务需要保留时间依赖性的轨迹集成。我们阐述了预测类型何时可以转换，何时不可以：轨迹集成可以通过边际化在没有额外假设的情况下转换为更简单的形式，但反之则需要通过联结或一致性方法来施加时间依赖性。我们证明了边际量无法确定路径依赖性事件的概率——无限多的联合分布共享相同的边际量，但对操作性问题的回答不同。我们将六个基本预测任务映射到最小充分的预测类型，并提供一个任务对齐的评估框架。我们的分析阐明了何时预测类型而非准确率区分了实际效用。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列基础模型（TSFM）虽然预测准确率高，但预测形式（点预测、分位数预测、参数预测或轨迹集成）对其实际应用能力有重要影响。许多实际操作任务需要保留时间依赖性的轨迹集成预测，而现有模型中能提供此类预测的比例较低。因此，理解不同预测形式之间的转换关系以及哪种预测形式最适合特定任务至关重要。

Method: 1. 调查了最近的时间序列基础模型（TSFM），分析了它们生成的预测类型（点预测、分位数预测、参数预测、轨迹集成）。 2. 探讨了不同预测类型之间的转换关系，明确了何时可以相互转换，何时不可以。 3. 证明了边际预测量无法确定路径依赖性事件的概率。 4. 将六个基本预测任务映射到所需的最小预测类型。 5. 提出了一个任务对齐的评估框架。

Result: 1. 现有TSFM中，只有三分之一能提供轨迹集成预测，而许多操作任务需要此类预测。 2. 轨迹集成预测可以通过边际化转换为更简单的预测形式，但反向转换（从简单形式到轨迹集成）需要额外的假设（如联结或一致性方法）。 3. 边际预测量无法完全确定路径依赖性事件的概率，因为无限多的联合分布可能共享相同的边际量。 4. 确定了六个基本预测任务所需的最低预测类型。

Conclusion: 预测的类型比预测的准确率更能决定其在实际应用中的价值。理解预测类型之间的转换限制以及将预测任务与合适的预测类型对齐，对于最大化TSFM的实用性至关重要。

Abstract: Time-series foundation models (TSFMs) achieve strong forecast accuracy, yet
accuracy alone does not determine practical value. The form of a forecast --
point, quantile, parametric, or trajectory ensemble -- fundamentally constrains
which operational tasks it can support. We survey recent TSFMs and find that
two-thirds produce only point or parametric forecasts, while many operational
tasks require trajectory ensembles that preserve temporal dependence. We
establish when forecast types can be converted and when they cannot: trajectory
ensembles convert to simpler forms via marginalization without additional
assumptions, but the reverse requires imposing temporal dependence through
copulas or conformal methods. We prove that marginals cannot determine
path-dependent event probabilities -- infinitely many joint distributions share
identical marginals but yield different answers to operational questions. We
map six fundamental forecasting tasks to minimal sufficient forecast types and
provide a task-aligned evaluation framework. Our analysis clarifies when
forecast type, not accuracy, differentiates practical utility.

</details>


### [340] [A Markov Decision Process for Variable Selection in Branch & Bound](https://arxiv.org/abs/2510.19348)
*Paul Strang,Zacharie Alès,Côme Bissuel,Olivier Juan,Safia Kedad-Sidhoum,Emmanuel Rachelson*

Main category: cs.LG

TL;DR: 该论文提出了一种名为BBMDP的新型方法，它将强化学习（RL）应用于混合整数线性规划（MILP）问题中的变量选择，以改进分支定界（B&B）算法的性能。


<details>
  <summary>Details</summary>
Motivation: MILP问题通常使用B&B算法求解，而变量选择启发式方法对B&B算法的性能至关重要。现有研究尝试使用RL来学习最优分支策略，但缺乏原则性的MDP（马尔可夫决策过程）方法。

Method: 提出了一种原则性的vanilla MDP（马尔可夫决策过程）框架BBMDP，用于MILP问题中的变量选择，从而可以利用多种RL算法来学习最优的B&B启发式方法。

Result: 计算实验表明，BBMDP在四个标准的MILP基准测试中，其分支代理的表现优于现有的最先进的RL代理。

Conclusion: BBMDP为RL在B&B变量选择中的应用提供了一个严谨的理论框架，并在实践中证明了其优越性。

Abstract: Mixed-Integer Linear Programming (MILP) is a powerful framework used to
address a wide range of NP-hard combinatorial optimization problems, often
solved by Branch and Bound (B&B). A key factor influencing the performance of
B&B solvers is the variable selection heuristic governing branching decisions.
Recent contributions have sought to adapt reinforcement learning (RL)
algorithms to the B&B setting to learn optimal branching policies, through
Markov Decision Processes (MDP) inspired formulations, and ad hoc convergence
theorems and algorithms. In this work, we introduce BBMDP, a principled vanilla
MDP formulation for variable selection in B&B, allowing to leverage a broad
range of RL algorithms for the purpose of learning optimal B\&B heuristics.
Computational experiments validate our model empirically, as our branching
agent outperforms prior state-of-the-art RL agents on four standard MILP
benchmarks.

</details>


### [341] [Scalable LinUCB: Low-Rank Design Matrix Updates for Recommenders with Large Action Spaces](https://arxiv.org/abs/2510.19349)
*Evgenia Shustova,Marina Sheshukova,Sergey Samsonov,Evgeny Frolov*

Main category: cs.LG

TL;DR: 该研究提出了一种名为Scalable LinUCB的算法，通过动态低秩参数化逆设计矩阵的因子，实现了LinUCB在推荐系统中训练、推理和内存的高效性。


<details>
  <summary>Details</summary>
Motivation: LinUCB算法在推荐系统中广泛应用，但其训练、推理和内存成本随特征维度和动作空间大小的增加而增长，主要瓶颈在于需要更新、求逆和存储吸收交互历史上下文信息的“设计矩阵”。

Method: 提出Scalable LinUCB算法，通过对逆设计矩阵的逆的Cholesky风格因子进行动态低秩参数化，实现了快速和内存高效的操作。推导了数值稳定的秩1和批量更新方法，无需直接形成整个矩阵即可维护逆矩阵。采用投影仪分裂积分器进行动态低秩近似，以控制内存增长，使得平均每步更新成本为O(dr)，内存占用为O(dr)，其中r为近似秩。单个动作评估的推理复杂度为O(dr)。

Result: 实验结果表明，所提出的Scalable LinUCB算法在推荐系统数据集上是有效的。

Conclusion: Scalable LinUCB算法通过动态低秩参数化技术，有效解决了LinUCB算法在推荐系统中面临的计算和内存瓶颈问题，实现了高效的训练、推理和内存管理。

Abstract: Linear contextual bandits, especially LinUCB, are widely used in recommender
systems. However, its training, inference, and memory costs grow with feature
dimensionality and the size of the action space. The key bottleneck becomes the
need to update, invert and store a design matrix that absorbs contextual
information from interaction history. In this paper, we introduce Scalable
LinUCB, the algorithm that enables fast and memory efficient operations with
the inverse regularized design matrix. We achieve this through a dynamical
low-rank parametrization of its inverse Cholesky-style factors. We derive
numerically stable rank-1 and batched updates that maintain the inverse without
directly forming the entire matrix. To control memory growth, we employ a
projector-splitting integrator for dynamical low-rank approximation, yielding
average per-step update cost $O(dr)$ and memory $O(dr)$ for approximation rank
$r$. Inference complexity of the suggested algorithm is $O(dr)$ per action
evaluation. Experiments on recommender system datasets demonstrate the
effectiveness of our algorithm.

</details>


### [342] [Optimization Benchmark for Diffusion Models on Dynamical Systems](https://arxiv.org/abs/2510.19376)
*Fabian Schaipp*

Main category: cs.LG

TL;DR: 本论文评估了新的优化算法在扩散模型训练中的效率，发现Muon和SOAP比AdamW更优。


<details>
  <summary>Details</summary>
Motivation: 评估新优化算法在扩散模型训练中的效率，尤其是在去噪流轨迹方面。

Method: 使用Muon、SOAP和AdamW等优化算法训练扩散模型，并与现有技术进行比较。

Result: Muon和SOAP在训练扩散模型方面比AdamW更有效，最终损失降低了18%。

Conclusion: Muon和SOAP是训练扩散模型的有前景的替代方案。

Abstract: The training of diffusion models is often absent in the evaluation of new
optimization techniques. In this work, we benchmark recent optimization
algorithms for training a diffusion model for denoising flow trajectories. We
observe that Muon and SOAP are highly efficient alternatives to AdamW (18%
lower final loss). We also revisit several recent phenomena related to the
training of models for text or image applications in the context of diffusion
model training. This includes the impact of the learning-rate schedule on the
training dynamics, and the performance gap between Adam and SGD.

</details>


### [343] [LMFD: Latent Monotonic Feature Discovery](https://arxiv.org/abs/2510.19383)
*Guus Toussaint,Arno Knobbe*

Main category: cs.LG

TL;DR: 从多变量时间序列中提取潜在的‘年龄’代理特征，通过优化单调性来寻找可解释的方程。


<details>
  <summary>Details</summary>
Motivation: 在监控老化、退化或缓慢变化的系统时，通常假设数据中存在潜在的‘年龄’，但传感器可能无法直接提供此信息。本研究旨在从多变量时间序列中提取‘年龄’的代理特征。

Method: 提出一种方法，利用精心定义的语法生成候选方程，并通过优化其单调性（定义为时间与候选方程之间的 Spearman 秩相关系数的绝对值）来提取‘年龄’的代理。将生成的候选特征进行拟合和单调性评估。

Result: 在一个人工生成的数据集和两个真实世界的数据集上进行了评估。结果表明，该系统能够将个体单调性较低的传感器组合成具有高单调性的潜在特征。在 InfraWatch 数据集上，将两个单独的 Spearman $ho$ 绝对值分别为 0.13 和 0.09 的特征组合成了一个 $ho$ 绝对值为 0.95 的代理。

Conclusion: 所提出的方法能够发现可解释的方程，可用作系统‘年龄’的代理，有效解决了从多变量时间序列中提取潜在‘年龄’信息的问题。

Abstract: Many systems in our world age, degrade or otherwise move slowly but steadily
in a certain direction. When monitoring such systems by means of sensors, one
often assumes that some form of `age' is latently present in the data, but
perhaps the available sensors do not readily provide this useful information.
The task that we study in this paper is to extract potential proxies for this
`age' from the available multi-variate time series without having clear data on
what `age' actually is. We argue that when we find a sensor, or more likely
some discovered function of the available sensors, that is sufficiently
monotonic, that function can act as the proxy we are searching for. Using a
carefully defined grammar and optimising the resulting equations in terms of
monotonicity, defined as the absolute Spearman's Rank Correlation between time
and the candidate formula, the proposed approach generates a set of candidate
features which are then fitted and assessed on monotonicity. The proposed
system is evaluated against an artificially generated dataset and two
real-world datasets. In all experiments, we show that the system is able to
combine sensors with low individual monotonicity into latent features with high
monotonicity. For the real-world dataset of InfraWatch, a structural health
monitoring project, we show that two features with individual absolute
Spearman's $\rho$ values of $0.13$ and $0.09$ can be combined into a proxy with
an absolute Spearman's $\rho$ of $0.95$. This demonstrates that our proposed
method can find interpretable equations which can serve as a proxy for the
`age' of the system.

</details>


### [344] [Learning Noise-Resilient and Transferable Graph-Text Alignment via Dynamic Quality Assessment](https://arxiv.org/abs/2510.19384)
*Yuhang Liu,Minglai Shao,Zengyi Wo,Yunlong Chu,Bing Hao,Shengzhong Liu,Ruijie Wang,Jianxin Li*

Main category: cs.LG

TL;DR: 现有的图-文本对齐模型在处理现实世界图谱中节点与文本的多种对应关系时存在局限性，并且在有噪声的监督下表现脆弱。我们提出了ADAligner，一个动态的、质量感知的框架，能够根据监督质量在多对多和一对一的对齐目标之间动态调整，提高了在节点分类、链接预测和跨模态检索任务上的表现，并加快了预训练速度。


<details>
  <summary>Details</summary>
Motivation: 现有的CLIP风格图-文本对齐模型在处理文本属性图（TAGs）时，存在一对一对应关系假设和静态对齐目标的问题，这在现实世界的应用中（如搜索、推荐、知识发现）限制了其效果，并且在有噪声的监督下表现脆弱。

Method: 提出ADAligner框架，它能够动态地在多对多和一对一的对齐目标之间进行调整。该框架实时估计批处理级别的对齐可靠性，并相应地调整优化策略，在监督质量高时采用多对多对齐，在有噪声时通过过滤低置信度对来强调一对一对齐。

Result: 在九个不同的TAG数据集上进行了广泛的实验，结果表明ADAligner在零样本/少样本节点分类、链接预测和跨模态检索任务上始终优于现有的图-文本对齐模型。该模型在有噪声监督下表现出良好的鲁棒性，并且相比于多模态基线，预训练速度提高了约2到3倍。

Conclusion: ADAligner通过动态调整对齐策略，有效地解决了现有图-文本对齐模型在处理现实世界图谱和噪声监督下的局限性，为现实世界的网络环境提供了可扩展且可靠的图-文本表示学习基础。

Abstract: Pre-training Graph Foundation Models (GFMs) on text-attributed graphs (TAGs)
is central to web-scale applications such as search, recommendation, and
knowledge discovery. However, existing CLIP-style graph-text aligners face two
key limitations: they assume strict one-to-one correspondences between nodes
and texts, overlooking the inherent many-to-many relations in real-world
graphs; and they rely on static alignment objectives that cannot adapt to
varying data quality, making them brittle under noisy supervision. Together,
these limitations expose a core dilemma: embracing expressive many-to-many
alignment amplifies noise, while reverting to strict one-to-one strategies
sacrifices semantic diversity and fails to handle inherently mismatched pairs.
To address these challenges, we propose ADAligner, a dynamic, quality-aware
graph-text alignment framework that dynamically adjusts between expressive
many-to-many and conservative one-to-one objectives according to supervision
quality. ADAligner estimates batch-level alignment reliability in real time and
adapts its optimization accordingly, promoting soft, subgraph-level
many-to-many alignment when supervision is clean, while emphasizing reliable
one-to-one alignment by dynamically filtering low-confidence pairs under noise.
Theoretically, we prove that this dynamic mechanism forms a stable negative
feedback process, ensuring convergence and robustness. Comprehensive
experiments on nine diverse TAG datasets demonstrate that ADAligner
consistently outperforms prior graph-text aligners on zero-/few-shot node
classification, link prediction and cross-modal retrieval tasks. It maintains
strong robustness under noisy supervision and accelerates pre-training by
approximately 2 to 3 times compared to multimodal baselines, establishing a
scalable and reliable foundation for graph-text representation learning in
real-world web environments.

</details>


### [345] [CPSVD: Enhancing Large Language Model Compression via Column-Preserving Singular Value Decomposition](https://arxiv.org/abs/2510.19385)
*Lin Xv,Jingsheng Gao,Xian Gao,Ting Li,Yuzhuo Fu*

Main category: cs.LG

TL;DR: CPSVD是一种新的SVD方法，通过智能分段参数矩阵来压缩LLM，保留了易出错的列，并选择性地对低错误列应用SVD，从而实现比现有方法更好的压缩效果。


<details>
  <summary>Details</summary>
Motivation: LLM的巨大体积带来了效率瓶颈，需要有效的压缩技术。现有的SVD方法在处理参数矩阵时过于统一，导致压缩效果不佳。

Method: CPSVD首先识别参数矩阵中分解误差高的列并直接保留，然后仅对分解误差低的列应用SVD。通过找到两种策略之间的最佳平衡点来最小化误差。此外，CPSVD利用LLM内不同矩阵的分解误差的异质性，在模块层面自适应地分配非均匀压缩率，同时遵循目标层压缩率，以进一步提高压缩性能。

Result: CPSVD在各项实验中始终优于最先进的基于SVD的LLM压缩方法，在零样本任务上实现了更低的困惑度和更高的准确性。

Conclusion: CPSVD通过智能分段和自适应压缩率分配，能够更有效地压缩LLM，并在保持模型性能的同时减小模型体积。

Abstract: The rapid advancement of Large Language Models (LLMs) faces a critical
bottleneck in their immense size, necessitating efficient compression
techniques. While Singular Value Decomposition (SVD) is a promising approach,
existing SVD-based methods treat the entire parameter matrix uniformly,
overlooking that SVD approximation errors vary significantly across different
matrix parts, which often leads to suboptimal compression. To address this, we
propose \textbf{C}olumn-\textbf{P}reserving \textbf{S}ingular \textbf{V}alue
\textbf{D}ecomposition (CPSVD), a novel method that refines SVD-based LLM
compression by intelligently segmenting the parameter matrix. Unlike
traditional SVD, CPSVD identifies and directly preserves matrix columns with
high decomposition errors, applying SVD only to columns with low decomposition
errors, while precisely determining the optimal balance point between these two
strategies to minimize error. Furthermore, leveraging the inherent
heterogeneity in decomposition errors across different matrices within an LLM,
CPSVD adaptively allocates non-uniform compression rates to modules within that
layer, while adhering to a target layer-wise compression ratio, thereby further
enhancing compression performance. Extensive experiments demonstrate that CPSVD
consistently outperforms state-of-the-art SVD-based LLM compression methods,
achieving lower perplexity and higher accuracy on zero-shot tasks.

</details>


### [346] [ARA: Adaptive Rank Allocation for Efficient Large Language Model SVD Compression](https://arxiv.org/abs/2510.19389)
*Lin Xv,Jingsheng Gao,Xian Gao,Ting Liu,Yuzhuo Fu*

Main category: cs.LG

TL;DR: SVD 压缩 LLM 时，ARA 通过新的掩码设计和额外的损失函数，能更有效地分配秩，并找到全局最优解，在 LLaMA2-7B 模型上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 SVD 压缩 LLM 的方法（如启发式算法和基于掩码的训练）在处理线性模块间的非线性组件时，无法独立应用 SVD，且在全局压缩率约束下，难以确定各模块的合适秩。这些方法或搜索空间受限，或难以捕捉奇异值谱与参数间的关系，还忽略了压缩率为 1 时增益函数的非光滑性，导致训练陷入局部最优。

Method: 提出了一种自适应秩分配 (ARA) 方法，包括：1) 设计了一种专门的掩码，用于在保留的秩和可训练参数之间进行高效映射和更新；2) 采用额外的损失函数引导参数选择，以寻求全局最优解。

Result: 在 LLaMA2-7B 模型上，ARA 在 80% 压缩率下，将 WikiText2 的困惑度从 8.38 降低到 6.42，并将平均零样本任务准确率提高了 9.72 个百分点，优于现有方法。

Conclusion: ARA 方法在秩分配方面有效，能够实现 LLM 压缩的最优性能。

Abstract: In the field of large language model (LLM) compression, singular value
decomposition (SVD) is a widely studied and adopted low-rank decomposition
technique. Since SVD operates exclusively on linear modules, and these modules
in LLMs are separated by nonlinear components, SVD can only be applied
independently to each linear module. Under a global compression ratio
constraint, determining the appropriate rank for different linear modules
becomes a critical problem. Existing approaches, such as heuristic algorithms
and mask-based training, have made progress in addressing this challenge.
However, these methods still suffer from several limitations: heuristic
algorithms explore the solution space within restricted regions, while
mask-based training struggles to efficiently capture the relationship between
singular value spectra and trainable parameters. More importantly, current
methods overlook the key property that the gain function is non-smooth at a
compression ratio of 1, which often leads the training process to suboptimal
local minima. To address these issues, we propose an Adaptive Rank Allocation
(ARA) method. Specifically, (1) ARA introduces a dedicated mask design that
enables efficient mapping and updating between retained ranks and trainable
parameters; and (2) it employs an additional loss function to guide parameter
selection toward globally optimal solutions. Experimental results demonstrate
that ARA achieves state-of-the-art performance. On the LLaMA2-7B model with a
80\% compression ratio, ARA reduces perplexity on WikiText2 from 8.38 to 6.42
and improves average zero-shot task accuracy by 9.72 percentage points compared
with uniform compression. These results highlight the effectiveness of our
method for rank allocation in SVD-based LLM compression.

</details>


### [347] [Iterative Training of Physics-Informed Neural Networks with Fourier-enhanced Features](https://arxiv.org/abs/2510.19399)
*Yulun Wu,Miguel Aguiar,Karl H. Johansson,Matthieu Barreau*

Main category: cs.LG

TL;DR: IFeF-PINN是一种迭代训练算法，通过随机傅里叶特征增强特征空间，克服了PINN在学习高频物理现象时的频谱偏差问题，并在数值实验中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 物理信息神经网络（PINN）在训练算法中存在学习低频特征的频谱偏差问题，导致难以准确学习高频物理现象。

Method: 提出IFeF-PINN算法，通过随机傅里叶特征（Random Fourier Features）增强PINN的潜在空间，引入高频分量。该算法采用两阶段训练：1. 估计特征空间中的基；2. 确定增强基函数的系数。证明了对于线性模型，第二阶段问题是凸的，并证明了迭代训练方案的收敛性。

Result: 经验证明，随机傅里叶特征增强了网络的表达能力，能够准确逼近高频偏微分方程（PDEs）。在经典基准问题上的大量数值评估表明，IFeF-PINN的性能优于现有最先进的算法，并展示了其在整个频率域的近似能力得到了提高。

Conclusion: IFeF-PINN算法有效克服了PINN的频谱偏差问题，能够通过增强的特征空间准确地逼近高频PDEs，并在数值评估中展现出优越性。

Abstract: Spectral bias, the tendency of neural networks to learn low-frequency
features first, is a well-known issue with many training algorithms for
physics-informed neural networks (PINNs). To overcome this issue, we propose
IFeF-PINN, an algorithm for iterative training of PINNs with Fourier-enhanced
features. The key idea is to enrich the latent space using high-frequency
components through Random Fourier Features. This creates a two-stage training
problem: (i) estimate a basis in the feature space, and (ii) perform regression
to determine the coefficients of the enhanced basis functions. For an
underlying linear model, it is shown that the latter problem is convex, and we
prove that the iterative training scheme converges. Furthermore, we empirically
establish that Random Fourier Features enhance the expressive capacity of the
network, enabling accurate approximation of high-frequency PDEs. Through
extensive numerical evaluation on classical benchmark problems, the superior
performance of our method over state-of-the-art algorithms is shown, and the
improved approximation across the frequency domain is illustrated.

</details>


### [348] [FairNet: Dynamic Fairness Correction without Performance Loss via Contrastive Conditional LoRA](https://arxiv.org/abs/2510.19421)
*Songqi Zhou,Zeyuan Liu,Benben Jiang*

Main category: cs.LG

TL;DR: FairNet通过动态、实例级别的公平性校正来解决机器学习中的公平性问题，克服了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习公平性方法在性能、静态校正策略、数据稀疏性（尤其是在少数群体中）以及对敏感属性的利用方面存在不足。

Method: 提出了一种名为FairNet的新框架，它集成了偏见检测器和条件低秩适应（LoRA）技术。该方法仅针对被识别为有偏见的实例激活公平性校正机制，从而在无偏见的实例上保持性能。此外，还设计了一种新的对比损失函数来训练LoRA模块，以解决少数群体中的欠拟合问题，并能灵活处理敏感属性标签完整、部分或完全缺失的情况。

Result: 理论分析表明，在偏见检测器具有适度的TPR/FPR的情况下，FairNet可以在不降低整体模型性能的情况下提高最差群体的性能，并可能带来轻微的性能提升。在多个视觉和语言基准上的广泛实证评估验证了FairNet的有效性。

Conclusion: FairNet通过其新颖的动态、实例级别的公平性校正方法，在不牺牲整体性能的情况下，有效提高了机器学习模型的公平性，尤其是在处理数据稀疏和敏感属性标签不完整的情况下。

Abstract: Ensuring fairness in machine learning models is a critical challenge.
Existing debiasing methods often compromise performance, rely on static
correction strategies, and struggle with data sparsity, particularly within
minority groups. Furthermore, their utilization of sensitive attributes is
often suboptimal, either depending excessively on complete attribute labeling
or disregarding these attributes entirely. To overcome these limitations, we
propose FairNet, a novel framework for dynamic, instance-level fairness
correction. FairNet integrates a bias detector with conditional low-rank
adaptation (LoRA), which enables selective activation of the fairness
correction mechanism exclusively for instances identified as biased, and
thereby preserve performance on unbiased instances. A key contribution is a new
contrastive loss function for training the LoRA module, specifically designed
to minimize intra-class representation disparities across different sensitive
groups and effectively address underfitting in minority groups. The FairNet
framework can flexibly handle scenarios with complete, partial, or entirely
absent sensitive attribute labels. Theoretical analysis confirms that, under
moderate TPR/FPR for the bias detector, FairNet can enhance the performance of
the worst group without diminishing overall model performance, and potentially
yield slight performance improvements. Comprehensive empirical evaluations
across diverse vision and language benchmarks validate the effectiveness of
FairNet.

</details>


### [349] [LLM Unlearning with LLM Beliefs](https://arxiv.org/abs/2510.19422)
*Kemou Li,Qizhou Wang,Yue Wang,Fengpeng Li,Jun Liu,Bo Han,Jiantao Zhou*

Main category: cs.LG

TL;DR: 现有的大型语言模型容易记住并输出敏感或有害内容。虽然现有的遗忘方法试图通过梯度上升来降低特定目标响应的概率，但这会导致“挤压效应”，即概率被重新分配到语义上相关的重述中。为解决此问题，我们提出了一个引导（BS）框架，该框架将挤压效应与模型自身的高置信度生成（模型信念）联系起来。通过联合抑制目标响应和模型信念，BS-T（token）和BS-S（sequence）能更彻底地遗忘，同时保持模型效用。实验证明了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型可能记住并输出敏感或有害内容，而现有遗忘方法存在“挤压效应”的问题，即概率被重新分配到语义上相关的重述中，导致遗忘不彻底，且自动化指标会误报成功率。

Method: 提出一个引导（BS）框架，该框架将挤压效应与模型自身的高置信度生成（模型信念）联系起来。通过联合抑制目标响应和模型信念，BS-T（token）和BS-S（sequence）两种方法来解决挤压效应，实现更彻底的遗忘。

Result: BS-T（token）和BS-S（sequence）方法能更彻底地遗忘目标内容，同时保持模型效用。实验证明了该方法在不同基准和模型家族上的有效性。

Conclusion: 提出的引导（BS）框架及其两种实现方式（BS-T 和 BS-S）能够有效解决现有遗忘方法中的“挤压效应”问题，实现更彻底的遗忘，同时保留模型效用。

Abstract: Large language models trained on vast corpora inherently risk memorizing
sensitive or harmful content, which may later resurface in their outputs.
Prevailing unlearning methods generally rely on gradient ascent and its
variants to lower the probability of specific target responses. However, we
find that this strategy induces a critical side effect: probability mass is
redistributed into high-likelihood regions, often corresponding to semantically
related rephrasings of the targets. We refer to this as the squeezing effect,
which explains why many methods yield merely spurious unlearning, a problem
further obscured by automated metrics (e.g., ROUGE, truth ratio) that misreport
actual success. To address this, we propose a bootstrapping (BS) framework that
explicitly links the squeezing effect with the model's own high-confidence
generations, namely its model beliefs. Since model beliefs inherently capture
the very high-likelihood regions where probability mass is squeezed,
incorporating them into the unlearning objective directly counters the
squeezing effect. By jointly suppressing both target responses and model
beliefs, BS-T (token) attenuates high-probability tokens, whereas BS-S
(sequence) removes entire high-confidence generations, together achieving more
thorough forgetting while preserving utility. Extensive experiments across
diverse benchmarks with various model families confirm the effectiveness of our
approach.

</details>


### [350] [Neural Variational Dropout Processes](https://arxiv.org/abs/2510.19425)
*Insu Jeon,Youngjin Park,Gunhee Kim*

Main category: cs.LG

TL;DR: NVDPs是一种新的贝叶斯元学习方法，通过特定任务的dropout来建模条件后验分布，在多任务少样本学习中表现出色。


<details>
  <summary>Details</summary>
Motivation: 学习推断条件后验模型对于鲁棒的元学习至关重要。

Method: 利用低秩的伯努利专家元模型进行记忆高效映射，并采用以整个任务数据为条件的先验来优化条件dropout后验。

Result: 在1D随机回归、图像修复和分类等少样本学习任务中，NVDPs表现出优于其他元学习方法。

Conclusion: NVDPs能够有效处理各种功能歧义和不确定性，能够鲁棒地近似特定任务的dropout率。

Abstract: Learning to infer the conditional posterior model is a key step for robust
meta-learning. This paper presents a new Bayesian meta-learning approach called
Neural Variational Dropout Processes (NVDPs). NVDPs model the conditional
posterior distribution based on a task-specific dropout; a low-rank product of
Bernoulli experts meta-model is utilized for a memory-efficient mapping of
dropout rates from a few observed contexts. It allows for a quick
reconfiguration of a globally learned and shared neural network for new tasks
in multi-task few-shot learning. In addition, NVDPs utilize a novel prior
conditioned on the whole task data to optimize the conditional \textit{dropout}
posterior in the amortized variational inference. Surprisingly, this enables
the robust approximation of task-specific dropout rates that can deal with a
wide range of functional ambiguities and uncertainties. We compared the
proposed method with other meta-learning approaches in the few-shot learning
tasks such as 1D stochastic regression, image inpainting, and classification.
The results show the excellent performance of NVDPs.

</details>


### [351] [Revisiting the Relation Between Robustness and Universality](https://arxiv.org/abs/2510.19427)
*M. Klabunde,L. Caspari,F. Lemmerich*

Main category: cs.LG

TL;DR: 文章指出，虽然对抗性鲁棒模型在特定情况下具有高度的可表示性相似性，但这种相似性并不普遍，并且预测行为并未随着鲁棒性的提高而收敛。通过对分类器进行简单的再训练，可以实现更普遍的预测行为。


<details>
  <summary>Details</summary>
Motivation: 检验 Jones 等人提出的修正后普遍性假说的普适性，即对抗性鲁棒模型在给定任务下是否高度相似。

Method: 在不同数据集上验证 Jones 的主要关于高度可表示性相似性的论点，并分析预测行为与鲁棒性的关系，最后通过再训练分类器来改善预测行为的普遍性。

Result: 在特定设置下，对抗性鲁棒模型确实表现出高度的可表示性相似性，但这种相似性在不同数据集上并不一致。预测行为并未随着鲁棒性的提高而收敛，且差异主要源于分类层。简单的分类器再训练可以提高预测行为的普遍性。

Conclusion: 神经网络在特定设置下具有一定程度的普遍性，但并非严格意义上的普遍性。

Abstract: The modified universality hypothesis proposed by Jones et al. (2022) suggests
that adversarially robust models trained for a given task are highly similar.
We revisit the hypothesis and test its generality. While we verify Jones' main
claim of high representational similarity in specific settings, results are not
consistent across different datasets. We also discover that predictive behavior
does not converge with increasing robustness and thus is not universal. We find
that differing predictions originate in the classification layer, but show that
more universal predictive behavior can be achieved with simple retraining of
the classifiers. Overall, our work points towards partial universality of
neural networks in specific settings and away from notions of strict
universality.

</details>


### [352] [g-DPO: Scalable Preference Optimization for Protein Language Models](https://arxiv.org/abs/2510.19474)
*Constance Ferragu,Jonathan D. Ziegler,Nicolas Deutschmann,Arthur Lindoulsi,Eli Bixby,Cradle ML Team*

Main category: cs.LG

TL;DR: DPO在大规模蛋白质语言模型训练中存在计算瓶颈。g-DPO通过聚类和近似计算来优化训练，在保持性能的同时提高了训练速度。


<details>
  <summary>Details</summary>
Motivation: DPO在蛋白质语言模型对齐方面效果显著，但存在训练对数量随数据规模二次方增长的扩展性瓶颈，导致训练时间过长。

Method: g-DPO框架，包含（1）使用序列空间聚类修剪冗余训练对并保留训练信号，（2）通过基于分组的近似来摊销似然计算。

Result: 在三个蛋白质工程任务中，g-DPO在计算机模拟和体外实验中均实现了与标准DPO无显著差异的性能，同时收敛速度提高了1.8至3.7倍。

Conclusion: g-DPO能够有效解决DPO的扩展性瓶颈，在保持模型性能的同时显著提高训练效率，尤其在大规模数据集上优势更明显。

Abstract: Direct Preference Optimization (DPO) is an effective approach for aligning
protein language models with experimental design goals. However, DPO faces a
scalability bottleneck: the number of possible training pairs grows
quadratically with the number of labeled sequences, leading to prohibitive
training times even for modestly sized datasets. We introduce g-DPO, a
framework that (i) uses sequence space clustering to prune redundant pairs
while preserving training signal, and (ii) amortizes likelihood computations
with group-based approximations. Across three protein engineering tasks, g-DPO
maintains in-silico and in-vitro performance that is statistically
indistinguishable from standard DPO, while converging 1.8 to 3.7 times faster,
with greater gains expected as the size of the dataset increases.

</details>


### [353] [A Concrete Roadmap towards Safety Cases based on Chain-of-Thought Monitoring](https://arxiv.org/abs/2510.19476)
*Julian Schulz*

Main category: cs.LG

TL;DR: Chain-of-thought (CoT) monitoring offers a potential approach to AI safety as systems approach dangerous capabilities. This paper proposes a roadmap and research agenda for constructing safety cases based on CoT monitoring, arguing it can support both control and trustworthiness. The proposed safety case involves two parts: ensuring models lack dangerous capabilities without CoT, and verifying that CoT-enabled dangerous capabilities are detectable via monitoring. The paper examines threats to monitorability like neuralese and encoded reasoning (linguistic drift, steganography, alien reasoning) and analyzes their drivers. It also evaluates techniques for CoT faithfulness and explores extracting monitorable CoTs from non-monitorable ones. Prediction markets are used to assess the feasibility of CoT monitoring safety cases by aggregating forecasts on technical milestones.


<details>
  <summary>Details</summary>
Motivation: AI systems are approaching dangerous capability levels where traditional safety cases are insufficient. Therefore, alternative approaches are needed to ensure AI safety.

Method: The paper proposes a two-part safety case based on Chain-of-Thought (CoT) monitoring: (1) ensuring models lack dangerous capabilities without CoT, and (2) ensuring CoT-enabled dangerous capabilities are detectable by CoT monitoring. It examines threats to monitorability (neuralese, encoded reasoning, including linguistic drift, steganography, and alien reasoning), evaluates techniques for CoT faithfulness, and explores extracting monitorable CoTs from non-monitorable ones. Prediction markets are employed to aggregate forecasts on technical milestones relevant to the feasibility of CoT monitoring safety cases.

Result: The paper examines threats to monitorability and evaluates techniques for CoT faithfulness. It also explores methods for extracting monitorable CoTs from non-monitorable ones. Prediction markets are established to assess the viability of CoT monitoring safety cases.

Conclusion: CoT monitoring presents a promising research direction for ensuring AI safety, particularly as AI capabilities advance. The proposed safety case structure and the investigation into monitorability threats and mitigation techniques provide a roadmap for future research and development in this area. 

Abstract: As AI systems approach dangerous capability levels where inability safety
cases become insufficient, we need alternative approaches to ensure safety.
This paper presents a roadmap for constructing safety cases based on
chain-of-thought (CoT) monitoring in reasoning models and outlines our research
agenda. We argue that CoT monitoring might support both control and
trustworthiness safety cases. We propose a two-part safety case: (1)
establishing that models lack dangerous capabilities when operating without
their CoT, and (2) ensuring that any dangerous capabilities enabled by a CoT
are detectable by CoT monitoring. We systematically examine two threats to
monitorability: neuralese and encoded reasoning, which we categorize into three
forms (linguistic drift, steganography, and alien reasoning) and analyze their
potential drivers. We evaluate existing and novel techniques for maintaining
CoT faithfulness. For cases where models produce non-monitorable reasoning, we
explore the possibility of extracting a monitorable CoT from a non-monitorable
CoT. To assess the viability of CoT monitoring safety cases, we establish
prediction markets to aggregate forecasts on key technical milestones
influencing their feasibility.

</details>


### [354] [Graph Unlearning Meets Influence-aware Negative Preference Optimization](https://arxiv.org/abs/2510.19479)
*Qiang Chen,Zhongze Wu,Ang He,Xi Lin,Shuo Jiang,Shan You,Chang Xu,Yi Chen,Xiu Su*

Main category: cs.LG

TL;DR: INPO框架通过引入影响感知负偏好优化来解决图模型遗忘过程中的效用下降问题，通过减缓梯度上升速度、优化高影响边和拓扑熵损失来提升遗忘质量和模型效用。


<details>
  <summary>Details</summary>
Motivation: 现有的图模型遗忘方法在遗忘过程中会导致模型效用急剧下降，因为梯度上升速度过快。

Method: INPO框架通过影响感知负偏好优化，减缓梯度上升速度，并提出遗忘高影响边和拓扑熵损失来缓解遗忘过程中的效用下降和信息丢失。

Result: 在五个真实世界数据集上的广泛实验表明，基于INPO的模型在所有遗忘质量指标上都达到了最先进的性能，同时保持了模型的效用。

Conclusion: INPO框架通过影响感知负偏好优化，成功地解决了图模型遗忘过程中的效用下降问题，并在遗忘质量和模型效用之间取得了更好的平衡。

Abstract: Recent advancements in graph unlearning models have enhanced model utility by
preserving the node representation essentially invariant, while using gradient
ascent on the forget set to achieve unlearning. However, this approach causes a
drastic degradation in model utility during the unlearning process due to the
rapid divergence speed of gradient ascent. In this paper, we introduce
\textbf{INPO}, an \textbf{I}nfluence-aware \textbf{N}egative
\textbf{P}reference \textbf{O}ptimization framework that focuses on slowing the
divergence speed and improving the robustness of the model utility to the
unlearning process. Specifically, we first analyze that NPO has slower
divergence speed and theoretically propose that unlearning high-influence edges
can reduce impact of unlearning. We design an influence-aware message function
to amplify the influence of unlearned edges and mitigate the tight topological
coupling between the forget set and the retain set. The influence of each edge
is quickly estimated by a removal-based method. Additionally, we propose a
topological entropy loss from the perspective of topology to avoid excessive
information loss in the local structure during unlearning. Extensive
experiments conducted on five real-world datasets demonstrate that INPO-based
model achieves state-of-the-art performance on all forget quality metrics while
maintaining the model's utility. Codes are available at
\href{https://github.com/sh-qiangchen/INPO}{https://github.com/sh-qiangchen/INPO}.

</details>


### [355] [ELUTQ: Efficient LUT-Aware Quantization for Deploying Large Language Models on Edge Devices](https://arxiv.org/abs/2510.19482)
*Xin Nie,Liang Dong,HaiCheng Zhang,JiaWang Xiao,G. Sun*

Main category: cs.LG

TL;DR: LLM边缘部署受资源限制，ELUTQ通过HLQ格式解决量化问题，实现高效低比特推理。


<details>
  <summary>Details</summary>
Motivation: 在CPU边缘设备上部署LLM以实现端上智能和AI可及性，但受限于内存和计算资源，内存使用和延迟是主要瓶颈。

Method: 提出ELUTQ框架，引入HLQ（分层线性量化）格式，该格式能更好地拟合权重分布且无额外计算开销，消除了反量化开销，并提供优化的CPU内核。

Result: LLaMA3-8B在3-bit和2-bit精度下困惑度分别降低了约8%和85%，且量化时间短。2-bit LLaMA2-7B在Apple M2芯片上实现了超过25 tokens/s的推理速度。

Conclusion: ELUTQ通过HLQ格式有效解决了LLM边缘部署的量化问题，实现了高精度和高推理效率。

Abstract: The deployment of Large Language Models (LLMs) on CPU-based edge devices is
crucial for enabling on-device intelligence and expanding AI accessibility.
However, it remains challenging due to limited memory and computational
resources. During edge inference, memory usage and latency are the primary
bottlenecks. Although weight quantization can effectively reduce memory
consumption, existing hardware-friendly approaches often rely on uniform
quantization, which poorly fits weight distributions and incurs high
dequantization overhead at low bit widths. To address these limitations, we
propose ELUTQ, an efficient quantization framework introducing a novel
quantization format, Hierarchical Linear Quantization (HLQ). HLQ better
captures the statistical characteristics of weights without increasing the
computational cost of Bit-serial LUT-based GEMM operations, thereby eliminating
dequantization overhead. It is orthogonal to existing quantization algorithms
and can be seamlessly integrated into various quantization pipelines. For
efficient on-device deployment, ELUTQ provides optimized CPU kernels for
end-to-end inference. Experiments show that for LLaMA3-8B, HLQ reduces
perplexity by about 8% at 3-bit and 85% at 2-bit precision under post-training
quantization, completing quantization within one hour. With efficient
finetuning, HLQ further improves 2-bit performance within two hours. In terms
of inference efficiency, our 2-bit LLaMA2-7B achieves over 25 tokens/s on an
Apple M2 chip (4 threads, batch size = 1).

</details>


### [356] [Energy-Efficient and Dequantization-Free Q-LLMs: A Spiking Neural Network Approach to Salient Value Mitigation](https://arxiv.org/abs/2510.19498)
*Chenyu Wang,Zhanglu Yan,Zhi Zhou,Xu Chen,Weng-Fai Wong*

Main category: cs.LG

TL;DR: SpikeQuant 通过混合精度量化和神经形态计算，在 LLM 的能效方面取得了显著进展。


<details>
  <summary>Details</summary>
Motivation: 为了在能量受限的硬件上部署大型语言模型（LLMs），需要克服量化后乘加（MAC）运算的能耗、反量化带来的额外开销以及固定位宽的局限性。

Method: 提出了一种名为 SpikeQuant 的方法，该方法选择性地对激活中的显著值进行混合精度量化，并将它们重新编码为二元脉冲计数。通过将量化尺度嵌入到整合发放（IF）机制的阈值中，实现了能量高效的线性变换，并避免了显式反量化。

Result: SpikeQuant 在 W4A4 量化下实现了接近 FP16 的困惑度，并将能耗降低了高达 4.6 倍。

Conclusion: SpikeQuant 能够实现 LLM 的准确且高能效的部署。

Abstract: In the era of large language models (LLMs), weight-activation quantization
helps fit models on edge device by reducing memory and compute bit-widths.
However, three challenges persist for energy constrained hardware: (1) even
after quantization, multiply-accumulate (MAC) operations remain unavoidable and
continue to dominate energy consumption; (2) dequantization (or
per-tensor/channel rescaling) introduces extra arithmetic and data movement,
increasing latency and energy; (3) uniform parameters bit widths clip salient
values-while intra-channel mixed precision is generally impractical on current
matrix hardware and memory. In contrast, brain-inspired Spiking Neural Networks
(SNNs), owing to their binary spike-based information representation and the
Integrate-and-Fire (IF) paradigm, naturally support mixed-precision storage and
energy-efficient computation by replacing complex MACs with temporal Accumulate
(ACCs). Motivated by this property, we propose SpikeQuant, which selectively
applies mixed-precision quantization to activations with salient values and
re-encodes them into binary spike counts, thereby enabling dynamic mixed
storage of different bitwidths. Furthermore, by embedding the quantization
scale into the threshold of the IF mechanism, our approach performs
energy-efficient linear transformations on weights and activations while
avoiding explicit dequantization. Experimental results demonstrate that
SpikeQuant consistently achieves near-FP16 perplexity under W4A4 quantization
while reducing energy cost by up to 4.6 times compared to existing methods,
highlighting its effectiveness for accurate and energy-efficient LLM
deployment.

</details>


### [357] [Teaming LLMs to Detect and Mitigate Hallucinations](https://arxiv.org/abs/2510.19507)
*Demian Till,John Smeaton,Peter Haubrick,Gouse Saheb,Florian Graef,David Berman*

Main category: cs.LG

TL;DR: 多模型一致性方法在检测和减少大型语言模型幻觉方面优于单模型方法，并且可能降低成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的幻觉检测和缓解是当前研究的热点，而基于一致性的方法，通过聚合来自单个LLM的多个响应来提高性能。然而，现有方法仍受限于LLM训练数据的不足，可能包含偏见或信息缺失，从而导致幻觉。

Method: 提出了一种名为“联盟一致性”的新方法，该方法通过整合来自不同训练数据、训练方案和模型架构的多个LLM的响应，来扩展单模型一致性方法。通过在15个LLM组成的模型团队中进行评估，探索其有效性及其适用条件。

Result: 该方法在提高幻觉检测和缓解能力方面取得了显著的改进，超越了传统的单模型一致性方法。此外，性能的提升通常伴随着推理成本的降低，这有助于克服单模型一致性方法的缺点。

Conclusion: 联盟一致性是一种有前景的方法，可以显著提高LLM幻觉检测和缓解的能力，同时可能降低成本。

Abstract: Recent work has demonstrated state-of-the-art results in large language model
(LLM) hallucination detection and mitigation through consistency-based
approaches which involve aggregating multiple responses sampled from a single
LLM for a given prompt. These approaches help offset limitations stemming from
the imperfect data on which LLMs are trained, which includes biases and
under-representation of information required at deployment time among other
limitations which can lead to hallucinations. We show that extending these
single-model consistency methods to combine responses from multiple LLMs with
different training data, training schemes and model architectures can result in
substantial further improvements in hallucination detection and mitigation
capabilities beyond their single-model consistency counterparts. We evaluate
this \emph{consortium consistency} approach across many model teams from a pool
of 15 LLMs and explore under what conditions it is beneficial to team together
different LLMs in this manner. Further, we show that these performance
improvements often come with reduced inference costs, offsetting a significant
drawback with single-model consistency methods.

</details>


### [358] [From Prototypes to Sparse ECG Explanations: SHAP-Driven Counterfactuals for Multivariate Time-Series Multi-class Classification](https://arxiv.org/abs/2510.19514)
*Maciej Mozolewski,Betül Bayrak,Kerstin Bach,Grzegorz J. Nalepa*

Main category: cs.LG

TL;DR: 提出一个基于原型驱动的框架，用于为12导联心电图（ECG）分类模型生成稀疏的反事实解释，以应对可解释性挑战。


<details>
  <summary>Details</summary>
Motivation: 在可解释人工智能（XAI）领域，面向时间序列的实例级解释因其在医疗保健等领域的潜在可操作性和可解释性见解而受到越来越多的关注。本研究旨在解决最先进模型的可解释性挑战。

Method: 所提出的框架采用基于SHAP的阈值来识别关键信号段并将其转换为区间规则；使用动态时间规整（DTW）和类中值聚类来提取代表性原型；并将这些原型与查询的R峰对齐以保持与被解释样本的一致性。

Result: 该框架生成的反事实解释仅修改了原始信号的78%，同时在所有类别中保持了81.3%的有效性，并在时间稳定性方面取得了43%的改进。在评估的三个方法变体中，原始、稀疏和对齐稀疏，类别的有效性范围从心肌梗死（MI）的98.9%到肥厚（HYP）检测的13.2%。该方法支持近乎实时（<1秒）生成临床上有效的反事实解释。

Conclusion: 研究结果为基于AI的诊断系统中生理感知反事实解释建立了设计原则，并为临床部署中的用户控制解释界面指明了方向。

Abstract: In eXplainable Artificial Intelligence (XAI), instance-based explanations for
time series have gained increasing attention due to their potential for
actionable and interpretable insights in domains such as healthcare. Addressing
the challenges of explainability of state-of-the-art models, we propose a
prototype-driven framework for generating sparse counterfactual explanations
tailored to 12-lead ECG classification models. Our method employs SHAP-based
thresholds to identify critical signal segments and convert them into interval
rules, uses Dynamic Time Warping (DTW) and medoid clustering to extract
representative prototypes, and aligns these prototypes to query R-peaks for
coherence with the sample being explained. The framework generates
counterfactuals that modify only 78% of the original signal while maintaining
81.3% validity across all classes and achieving 43% improvement in temporal
stability. We evaluate three variants of our approach, Original, Sparse, and
Aligned Sparse, with class-specific performance ranging from 98.9% validity for
myocardial infarction (MI) to challenges with hypertrophy (HYP) detection
(13.2%). This approach supports near realtime generation (< 1 second) of
clinically valid counterfactuals and provides a foundation for interactive
explanation platforms. Our findings establish design principles for
physiologically-aware counterfactual explanations in AI-based diagnosis systems
and outline pathways toward user-controlled explanation interfaces for clinical
deployment.

</details>


### [359] [Bi-Level Decision-Focused Causal Learning for Large-Scale Marketing Optimization: Bridging Observational and Experimental Data](https://arxiv.org/abs/2510.19517)
*Shuli Zhang,Hao Zhou,Jiaqi Zheng,Guibin Jiang,Bing Cheng,Wei Lin,Guihai Chen*

Main category: cs.LG

TL;DR: 提出了Bi-DFCL框架，通过联合使用观测数据和实验数据，解决了在线平台营销中的预测-决策不一致和偏倚-方差困境问题，并在实际应用中取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 在线互联网平台在用户留存和平台收入优化方面面临资源分配的挑战，而传统的机器学习（ML）和运筹学（OR）两阶段方法存在预测-决策不一致和偏倚-方差困境等问题。

Method: 提出Bi-DFCL框架，使用实验数据开发了无偏的OR决策质量估计器，并通过代理损失函数将优化梯度引入ML模型训练。构建了一个双层优化框架，联合使用观测数据和实验数据，并通过隐式微分求解，实现了偏倚-方差的权衡。

Result: 在公开基准、工业营销数据集和大规模在线A/B测试中，Bi-DFCL相比现有技术在统计上有了显著的改进。

Conclusion: Bi-DFCL框架能够有效地解决在线平台营销中的关键挑战，并已被部署于美团等实际平台，证明了其有效性。

Abstract: Online Internet platforms require sophisticated marketing strategies to
optimize user retention and platform revenue -- a classical resource allocation
problem. Traditional solutions adopt a two-stage pipeline: machine learning
(ML) for predicting individual treatment effects to marketing actions, followed
by operations research (OR) optimization for decision-making. This paradigm
presents two fundamental technical challenges. First, the prediction-decision
misalignment: Conventional ML methods focus solely on prediction accuracy
without considering downstream optimization objectives, leading to improved
predictive metrics that fail to translate to better decisions. Second, the
bias-variance dilemma: Observational data suffers from multiple biases (e.g.,
selection bias, position bias), while experimental data (e.g., randomized
controlled trials), though unbiased, is typically scarce and costly --
resulting in high-variance estimates. We propose Bi-level Decision-Focused
Causal Learning (Bi-DFCL) that systematically addresses these challenges.
First, we develop an unbiased estimator of OR decision quality using
experimental data, which guides ML model training through surrogate loss
functions that bridge discrete optimization gradients. Second, we establish a
bi-level optimization framework that jointly leverages observational and
experimental data, solved via implicit differentiation. This novel formulation
enables our unbiased OR estimator to correct learning directions from biased
observational data, achieving optimal bias-variance tradeoff. Extensive
evaluations on public benchmarks, industrial marketing datasets, and
large-scale online A/B tests demonstrate the effectiveness of Bi-DFCL, showing
statistically significant improvements over state-of-the-art. Currently,
Bi-DFCL has been deployed at Meituan, one of the largest online food delivery
platforms in the world.

</details>


### [360] [Optimizing the Unknown: Black Box Bayesian Optimization with Energy-Based Model and Reinforcement Learning](https://arxiv.org/abs/2510.19530)
*Ruiyao Miao,Junren Xiao,Shiya Tsang,Hui Xiong,Yingnian Wu*

Main category: cs.LG

TL;DR: 现有的贝叶斯优化（BO）方法在优化代价高昂的目标函数时，通常在探索和利用之间取得平衡。然而，这些方法常常遭受显著的单步偏差，这可能导致收敛到局部最优解，并在复杂或高维任务中表现不佳。受此启发，我们提出了用于贝叶斯优化的增强能量模型（REBMBO），它集成了高斯过程（GP）进行局部指导，并利用能量模型（EBM）来捕捉全局结构信息。具体来说，我们将每次贝叶斯优化迭代定义为一个马尔可夫决策过程（MDP），并使用近端策略优化（PPO）进行自适应的多步前瞻，动态调整探索的深度和方向，以有效克服传统BO方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的贝叶斯优化（BO）方法在优化代价高昂的目标函数时，通常在探索和利用之间取得平衡。然而，这些方法常常遭受显著的单步偏差，这可能导致收敛到局部最优解，并在复杂或高维任务中表现不佳。受此启发，我们提出了用于贝叶斯优化的增强能量模型（REBMBO），它集成了高斯过程（GP）进行局部指导，并利用能量模型（EBM）来捕捉全局结构信息。

Method: 将每次贝叶斯优化迭代定义为一个马尔可夫决策过程（MDP），并使用近端策略优化（PPO）进行自适应的多步前瞻，动态调整探索的深度和方向，以有效克服传统BO方法的局限性。该方法集成了高斯过程（GP）进行局部指导，并利用能量模型（EBM）来捕捉全局结构信息。

Result: 通过在合成和实际基准测试中的广泛实验，证实了REBMBO的优越性能。此外，对各种GP配置的附加分析进一步凸显了其适应性和鲁棒性。

Conclusion: REBMBO通过集成GP的局部指导和EBM的全局结构信息，并利用PPO进行自适应多步前瞻，有效克服了传统BO方法的局限性，在优化代价高昂的目标函数方面表现出优越的性能和鲁棒性。

Abstract: Existing Bayesian Optimization (BO) methods typically balance exploration and
exploitation to optimize costly objective functions. However, these methods
often suffer from a significant one-step bias, which may lead to convergence
towards local optima and poor performance in complex or high-dimensional tasks.
Recently, Black-Box Optimization (BBO) has achieved success across various
scientific and engineering domains, particularly when function evaluations are
costly and gradients are unavailable. Motivated by this, we propose the
Reinforced Energy-Based Model for Bayesian Optimization (REBMBO), which
integrates Gaussian Processes (GP) for local guidance with an Energy-Based
Model (EBM) to capture global structural information. Notably, we define each
Bayesian Optimization iteration as a Markov Decision Process (MDP) and use
Proximal Policy Optimization (PPO) for adaptive multi-step lookahead,
dynamically adjusting the depth and direction of exploration to effectively
overcome the limitations of traditional BO methods. We conduct extensive
experiments on synthetic and real-world benchmarks, confirming the superior
performance of REBMBO. Additional analyses across various GP configurations
further highlight its adaptability and robustness.

</details>


### [361] [The Confusing Instance Principle for Online Linear Quadratic Control](https://arxiv.org/abs/2510.19531)
*Waris Radji,Odalric-Ambrym Maillard*

Main category: cs.LG

TL;DR: 本文提出了一种基于Confusing Instance（CI）原理的新的模型学习控制方法MED-LQ，用于解决具有未知动态的二次成本线性系统控制问题。与基于多臂老虎机（MAB）的传统方法不同，MED-LQ在理论上具有更强的支持，并在实践中表现出与最优方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于不确定性（如Optimism in the Face of Uncertainty和Thompson Sampling）的模型学习控制方法在实际应用中存在局限性。本文旨在提出一种新的方法，克服这些局限性，并具有更强的理论基础。

Method: 本文提出了一种名为MED-LQ的新型控制策略。该策略基于Confusing Instance（CI）原理，该原理是MAB和离散马尔可夫决策过程（MDP）中遗憾下界的核心，并且是最小经验散度（MED）算法家族的基础。MED-LQ利用了LQR策略的结构以及敏感性和稳定性分析，将CI和MED的原理扩展到大规模设置。

Result: 通过在一个全面的控制套件上的基准测试，MED-LQ在各种场景下实现了与最优方法相当的性能，并且在具有挑战性的控制任务中展现了其潜力。

Conclusion: MED-LQ是一种有效的模型学习控制方法，特别适用于具有未知动态的线性系统。它在理论上有坚实的基础，并且在实践中表现出色，为大规模MDP问题提供了新的解决方案。

Abstract: We revisit the problem of controlling linear systems with quadratic cost
under unknown dynamics with model-based reinforcement learning. Traditional
methods like Optimism in the Face of Uncertainty and Thompson Sampling, rooted
in multi-armed bandits (MABs), face practical limitations. In contrast, we
propose an alternative based on the Confusing Instance (CI) principle, which
underpins regret lower bounds in MABs and discrete Markov Decision Processes
(MDPs) and is central to the Minimum Empirical Divergence (MED) family of
algorithms, known for their asymptotic optimality in various settings. By
leveraging the structure of LQR policies along with sensitivity and stability
analysis, we develop MED-LQ. This novel control strategy extends the principles
of CI and MED beyond small-scale settings. Our benchmarks on a comprehensive
control suite demonstrate that MED-LQ achieves competitive performance in
various scenarios while highlighting its potential for broader applications in
large-scale MDPs.

</details>


### [362] [Insights into the Unknown: Federated Data Diversity Analysis on Molecular Data](https://arxiv.org/abs/2510.19535)
*Markus Bujotzek,Evelyn Trautmann,Calum Hand,Ian Hales*

Main category: cs.LG

TL;DR: AI在药物发现中的应用受限于公共数据集的规模和多样性。联邦学习（FL）通过在数据孤岛之间进行隐私保护的协作模型训练来整合私有数据，但它也带来了数据中心化任务的挑战。本研究调查了联邦聚类方法在解耦和表示分子数据方面的能力，并评估了Fed-kMeans、Fed-PCA+Fed-kMeans和Fed-LSH三种方法。通过结合数学指标和化学信息指标（SF-ICF），研究强调了在分子数据的联邦多样性分析中，结合领域知识和客户端可解释性分析的重要性。


<details>
  <summary>Details</summary>
Motivation: AI方法在药物发现中的应用潜力巨大，但目前主要依赖公共数据集，缺乏私有数据集的规模和多样性。联邦学习（FL）提供了一种在保护隐私的前提下，整合私有数据并进行协作模型训练的解决方案。然而，联邦数据访问模式给数据多样性估计、数据划分和化学空间结构理解等数据中心化任务带来了新的挑战。因此，本研究旨在解决这一差距，探索联邦聚类方法在处理分散的分子数据时的能力。

Method: 本研究调查了三种联邦聚类方法：联邦K均值（Fed-kMeans）、结合了联邦主成分分析和联邦K均值的Fed-PCA+Fed-kMeans，以及联邦局部敏感哈希（Fed-LSH）。研究人员将这三种方法与它们各自的中心化对应方法在八个不同的分子数据集上进行了基准测试。评估标准包括标准的数学指标以及一项新提出的、结合化学知识的评估指标——SF-ICF。

Result: 研究结果表明，通过大规模的基准测试和深入的可解释性分析，揭示了在分子数据的联邦多样性分析中，结合化学信息指标和客户端可解释性分析的重要性。

Conclusion: 本研究强调了在分子数据的联邦多样性分析中，结合领域知识（通过化学信息指标）和客户端可解释性分析的必要性。这为在分布式环境中更有效地利用和理解药物发现数据提供了指导。

Abstract: AI methods are increasingly shaping pharmaceutical drug discovery. However,
their translation to industrial applications remains limited due to their
reliance on public datasets, lacking scale and diversity of proprietary
pharmaceutical data. Federated learning (FL) offers a promising approach to
integrate private data into privacy-preserving, collaborative model training
across data silos. This federated data access complicates important
data-centric tasks such as estimating dataset diversity, performing informed
data splits, and understanding the structure of the combined chemical space. To
address this gap, we investigate how well federated clustering methods can
disentangle and represent distributed molecular data. We benchmark three
approaches, Federated kMeans (Fed-kMeans), Federated Principal Component
Analysis combined with Fed-kMeans (Fed-PCA+Fed-kMeans), and Federated
Locality-Sensitive Hashing (Fed-LSH), against their centralized counterparts on
eight diverse molecular datasets. Our evaluation utilizes both, standard
mathematical and a chemistry-informed evaluation metrics, SF-ICF, that we
introduce in this work. The large-scale benchmarking combined with an in-depth
explainability analysis shows the importance of incorporating domain knowledge
through chemistry-informed metrics, and on-client explainability analyses for
federated diversity analysis on molecular data.

</details>


### [363] [A Climate-Aware Deep Learning Framework for Generalizable Epidemic Forecasting](https://arxiv.org/abs/2510.19611)
*Jinpyo Hong,Rachel E. Baker*

Main category: cs.LG

TL;DR: 本文提出了一种名为ForecastNet-XCL的混合深度学习框架，用于预测呼吸道合胞病毒（RSV）的流行趋势，即使在没有实时监测数据的情况下，也能提前100周进行准确预测。


<details>
  <summary>Details</summary>
Motivation: 尽管机器学习在COVID-19预测中显示了潜力，但其在地方性疾病（如RSV）的预测方面仍未得到充分探索。本研究旨在填补这一空白，通过开发一种能够进行长期RSV预测的模型。

Method: ForecastNet-XCL是一个集成XGBoost、CNN和BiLSTM的混合模型。它结合了高分辨率特征学习和长程时间依赖性捕捉能力，并包含一个基于气候滞后关系训练的自回归模块。模型通过随机推断提供概率区间，以辅助决策。

Result: 在34个美国州的评估中，ForecastNet-XCL在州内和跨州情景下均优于统计基线、单一神经网络和传统集成方法，并且在长预测期内保持了准确性。使用气候多样化的数据集进行训练，提高了模型的泛化能力，尤其是在RSV模式不规律或两年一次的地区。

Conclusion: ForecastNet-XCL因其高效、高性能和考虑不确定性的设计，成为在日益增长的气候压力和有限监测资源下，一个可部署的早期预警工具。

Abstract: Precise outbreak forecasting of infectious diseases is essential for
effective public health responses and epidemic control. The increased
availability of machine learning (ML) methods for time-series forecasting
presents an enticing avenue to enhance outbreak forecasting. Though the
COVID-19 outbreak demonstrated the value of applying ML models to predict
epidemic profiles, using ML models to forecast endemic diseases remains
underexplored. In this work, we present ForecastNet-XCL (an ensemble model
based on XGBoost+CNN+BiLSTM), a deep learning hybrid framework designed to
addresses this gap by creating accurate multi-week RSV forecasts up to 100
weeks in advance based on climate and temporal data, without access to
real-time surveillance on RSV. The framework combines high-resolution feature
learning with long-range temporal dependency capturing mechanisms, bolstered by
an autoregressive module trained on climate-controlled lagged relations.
Stochastic inference returns probabilistic intervals to inform decision-making.
Evaluated across 34 U.S. states, ForecastNet-XCL reliably outperformed
statistical baselines, individual neural nets, and conventional ensemble
methods in both within- and cross-state scenarios, sustaining accuracy over
extended forecast horizons. Training on climatologically diverse datasets
enhanced generalization furthermore, particularly in locations having irregular
or biennial RSV patterns. ForecastNet-XCL's efficiency, performance, and
uncertainty-aware design make it a deployable early-warning tool amid
escalating climate pressures and constrained surveillance resources.

</details>


### [364] [Learning and Simulating Building Evacuation Patterns for Enhanced Safety Design Using Generative Models](https://arxiv.org/abs/2510.19623)
*Jin Han,Zhe Zheng,Yi Gu,Jia-Rui Lin,Xin-Zheng Lu*

Main category: cs.LG

TL;DR: 该研究提出了一种名为DiffEvac的新方法，利用生成模型（GMs）进行高效的建筑疏散模拟，以应对传统方法在早期设计阶段难以快速迭代的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统疏散模拟方法依赖精细建模和大量参数，不适用于设计初期的快速迭代，因此需要一种更高效的方法。

Method: 研究人员首先建立了一个包含399个建筑布局和对应疏散热力图的数据集。然后，提出了一种解耦的特征表示方法，将布局和人口密度等物理特征嵌入到生成模型中。最后，利用基于图像提示的扩散模型来学习疏散热力图的疏散模式。

Result: 与使用条件GAN和RGB表示的现有研究相比，DiffEvac在SSIM方面提高了37.6%，在PSNR方面提高了142%，并且速度快16倍，将模拟时间缩短到2分钟。

Conclusion: DiffEvac显著提高了设计迭代和调整的效率，为未来智能建筑设计的安全优化提供了新的见解和技术途径。该方法降低了建模负担，能够进行大规模的“假设”分析，并便于与多目标设计工具结合。

Abstract: Evacuation simulation is essential for building safety design, ensuring
properly planned evacuation routes. However, traditional evacuation simulation
relies heavily on refined modeling with extensive parameters, making it
challenging to adopt such methods in a rapid iteration process in early design
stages. Thus, this study proposes DiffEvac, a novel method to learn building
evacuation patterns based on Generative Models (GMs), for efficient evacuation
simulation and enhanced safety design. Initially, a dataset of 399 diverse
functional layouts and corresponding evacuation heatmaps of buildings was
established. Then, a decoupled feature representation is proposed to embed
physical features like layouts and occupant density for GMs. Finally, a
diffusion model based on image prompts is proposed to learn evacuation patterns
from simulated evacuation heatmaps. Compared to existing research using
Conditional GANs with RGB representation, DiffEvac achieves up to a 37.6%
improvement in SSIM, 142% in PSNR, and delivers results 16 times faster,
thereby cutting simulation time to 2 minutes. Case studies further demonstrate
that the proposed method not only significantly enhances the rapid design
iteration and adjustment process with efficient evacuation simulation but also
offers new insights and technical pathways for future safety optimization in
intelligent building design. The research implication is that the approach
lowers the modeling burden, enables large-scale what-if exploration, and
facilitates coupling with multi-objective design tools.

</details>


### [365] [Latent Space Factorization in LoRA](https://arxiv.org/abs/2510.19640)
*Shashi Kumar,Yacouba Kaloga,John Mitros,Petr Motlicek,Ina Kodrasi*

Main category: cs.LG

TL;DR: FVAE-LoRA通过利用VAE学习两个独立的潜在空间来改进LoRA，一个用于任务相关特征，另一个用于残差信息，从而在文本、音频和图像任务上优于标准LoRA，并提高在分布变化下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的LoRA变体缺乏机制来明确区分学习到的低秩子空间内的任务相关信息，这可能会限制下游性能。

Method: 提出了一种称为FVAE-LoRA的方法，该方法利用变分自编码器（VAE）学习两个独立的潜在空间。通过新颖的证据下界（ELBO）公式，显式地促进了潜在空间之间的因子分解，将一个潜在空间专门用于任务显著特征，另一个用于残差信息。

Result: 在文本、音频和图像任务上的广泛实验表明，FVAE-LoRA的性能始终优于标准LoRA。此外，对伪相关性的评估证实，FVAE-LoRA能更好地分离任务相关信号，从而在分布变化下提高鲁棒性。

Conclusion: FVAE-LoRA通过明确分离任务相关特征和残差信息，有效提高了参数高效微调的性能和鲁棒性。

Abstract: Low-rank adaptation (LoRA) is a widely used method for parameter-efficient
finetuning. However, existing LoRA variants lack mechanisms to explicitly
disambiguate task-relevant information within the learned low-rank subspace,
potentially limiting downstream performance. We propose Factorized Variational
Autoencoder LoRA (FVAE-LoRA), which leverages a VAE to learn two distinct
latent spaces. Our novel Evidence Lower Bound formulation explicitly promotes
factorization between the latent spaces, dedicating one latent space to
task-salient features and the other to residual information. Extensive
experiments on text, audio, and image tasks demonstrate that FVAE-LoRA
consistently outperforms standard LoRA. Moreover, spurious correlation
evaluations confirm that FVAE-LoRA better isolates task-relevant signals,
leading to improved robustness under distribution shifts. Our code is publicly
available at: https://github.com/idiap/FVAE-LoRA

</details>


### [366] [Overlap-weighted orthogonal meta-learner for treatment effect estimation over time](https://arxiv.org/abs/2510.19643)
*Konstantin Hess,Dennis Frauen,Mihaela van der Schaar,Stefan Feuerriegel*

Main category: cs.LG

TL;DR: 现有的处理时间变化的方法存在重叠问题，本文提出的WO学习器可以解决这个问题。


<details>
  <summary>Details</summary>
Motivation: 时间变化场景下异质性处理效应（HTE）的估计面临挑战，因为观测数据对许多可能的处理序列的支持很少，导致重叠问题严重。现有元学习器通常假设有足够的处理重叠，在重叠低时估计方差会急剧增大。

Method: 提出一种新颖的重叠加权正交（WO）元学习器，用于估计HTE，该学习器针对观测数据中接受干预性处理序列概率高的区域。该方法通过最小化重叠加权预言家风险来开发一种新颖的Neyman正交种群风险函数。

Result: WO学习器具有Neyman正交的优点，对 the nuisance functions 的错误指定具有鲁棒性，并且可以应用于任何机器学习模型。实验证明了WO学习器的优势。

Conclusion: WO学习器通过解决重叠问题，提供了更可靠的HTE估计。

Abstract: Estimating heterogeneous treatment effects (HTEs) in time-varying settings is
particularly challenging, as the probability of observing certain treatment
sequences decreases exponentially with longer prediction horizons. Thus, the
observed data contain little support for many plausible treatment sequences,
which creates severe overlap problems. Existing meta-learners for the
time-varying setting typically assume adequate treatment overlap, and thus
suffer from exploding estimation variance when the overlap is low. To address
this problem, we introduce a novel overlap-weighted orthogonal (WO)
meta-learner for estimating HTEs that targets regions in the observed data with
high probability of receiving the interventional treatment sequences. This
offers a fully data-driven approach through which our WO-learner can counteract
instabilities as in existing meta-learners and thus obtain more reliable HTE
estimates. Methodologically, we develop a novel Neyman-orthogonal population
risk function that minimizes the overlap-weighted oracle risk. We show that our
WO-learner has the favorable property of Neyman-orthogonality, meaning that it
is robust against misspecification in the nuisance functions. Further, our
WO-learner is fully model-agnostic and can be applied to any machine learning
model. Through extensive experiments with both transformer and LSTM backbones,
we demonstrate the benefits of our novel WO-learner.

</details>


### [367] [Policy Learning with Abstention](https://arxiv.org/abs/2510.19672)
*Ayush Sawarni,Jikai Jin,Justin Whitehouse,Vasilis Syrgkanis*

Main category: cs.LG

TL;DR: 该研究提出了一种包含弃权选项的策略学习算法，以处理决策中的不确定性，并提供了理论保证和在其他策略学习问题中的应用。


<details>
  <summary>Details</summary>
Motivation: 现有策略学习算法在预测不确定时仍强制决策，在高风险领域可能带来风险。

Method: 提出了一种两阶段学习器，首先识别近似最优策略集，然后根据它们的差异构建弃权规则。通过已知倾向性下的O(1/n)遗憾界和未知倾向性情况下的双重稳健（DR）目标来扩展这些保证。

Result: 在已知倾向性的情况下，得到了快速的O(1/n)遗憾保证，并通过双重稳健（DR）目标将其扩展到未知倾向性的情况。研究还表明，弃权可以作为一种多功能工具，应用于其他策略学习问题，例如在没有实现假设的情况下，在边界条件下提供改进的保证，通过对小数据偏移进行对冲来连接到分布外策略学习，并确保以高概率改进基线策略。

Conclusion: 包含弃权选项的策略学习是一种处理不确定性的有效方法，并能在策略学习的其他方面提供改进和安全保障。

Abstract: Policy learning algorithms are widely used in areas such as personalized
medicine and advertising to develop individualized treatment regimes. However,
most methods force a decision even when predictions are uncertain, which is
risky in high-stakes settings. We study policy learning with abstention, where
a policy may defer to a safe default or an expert. When a policy abstains, it
receives a small additive reward on top of the value of a random guess. We
propose a two-stage learner that first identifies a set of near-optimal
policies and then constructs an abstention rule from their disagreements. We
establish fast O(1/n)-type regret guarantees when propensities are known, and
extend these guarantees to the unknown-propensity case via a doubly robust (DR)
objective. We further show that abstention is a versatile tool with direct
applications to other core problems in policy learning: it yields improved
guarantees under margin conditions without the common realizability assumption,
connects to distributionally robust policy learning by hedging against small
data shifts, and supports safe policy improvement by ensuring improvement over
a baseline policy with high probability.

</details>


### [368] [Study of Training Dynamics for Memory-Constrained Fine-Tuning](https://arxiv.org/abs/2510.19675)
*Aël Quélennec,Nour Hezbri,Pavlo Mozharovskyi,Van-Tam Nguyen,Enzo Tartaglione*

Main category: cs.LG

TL;DR: TraDy通过动态随机通道选择和可预测的层重要性，在保持内存效率的同时实现了最先进的深度学习模型训练效果。


<details>
  <summary>Details</summary>
Motivation: 随着模型增大和资源限制，高效训练深度神经网络变得至关重要。

Method: 提出了一种名为TraDy的新型迁移学习方案，该方案利用层重要性（可先验确定）和动态随机通道选择（优于静态方法）来近似梯度。它在预选层内进行跨时期随机通道重采样。

Result: TraDy在各种下游任务和架构上实现了最先进的性能，同时满足严格的内存限制，实现了高达99%的激活稀疏度、95%的权重导数稀疏度和97%的权重导数计算量减少。

Conclusion: TraDy是一种有效的内存高效训练深度神经网络的方法，能够满足严格的资源约束，并实现高性能。

Abstract: Memory-efficient training of deep neural networks has become increasingly
important as models grow larger while deployment environments impose strict
resource constraints. We propose TraDy, a novel transfer learning scheme
leveraging two key insights: layer importance for updates is
architecture-dependent and determinable a priori, while dynamic stochastic
channel selection provides superior gradient approximation compared to static
approaches. We introduce a dynamic channel selection approach that
stochastically resamples channels between epochs within preselected layers.
Extensive experiments demonstrate TraDy achieves state-of-the-art performance
across various downstream tasks and architectures while maintaining strict
memory constraints, achieving up to 99% activation sparsity, 95% weight
derivative sparsity, and 97% reduction in FLOPs for weight derivative
computation.

</details>


### [369] [Fast Inference via Hierarchical Speculative Decoding](https://arxiv.org/abs/2510.19705)
*Amir Globerson,Haim Kaplan,Yishay Mansour,Clara Mohri,Tal Schuster*

Main category: cs.LG

TL;DR: Transformer模型可以通过分层投机解码（HSD）来加速文本生成，通过使用一系列草稿模型来提高效率。


<details>
  <summary>Details</summary>
Motivation: 现有的投机解码方法在草稿模型选择上存在局限性，而HSD通过构建草稿模型层级来优化这一过程。

Method: HSD算法构建了一个包含多个草稿模型的层级结构，每个模型依次提出并由下一层级模型验证，直至最终由目标模型完成验证。

Result: HSD相比最佳的单草稿基线模型，实现了高达1.2倍的加速，证明了其在减少生成延迟方面的实用性。

Conclusion: HSD算法通过分层投机解码，能够有效降低Transformer模型的文本生成延迟，并优于现有技术。

Abstract: Transformer language models generate text autoregressively, making inference
latency proportional to the number of tokens generated. Speculative decoding
reduces this latency without sacrificing output quality, by leveraging a small
draft model to propose tokens that the larger target model verifies in
parallel. In practice, however, there may exist a set of potential draft
models- ranging from faster but less inaccurate, to slower yet more reliable.
We introduce Hierarchical Speculative Decoding (HSD), an algorithm that stacks
these draft models into a hierarchy, where each model proposes tokens, and the
next larger model verifies them in a single forward pass, until finally the
target model verifies tokens. We derive an expression for the expected latency
of any such hierarchy and show that selecting the latency-optimal hierarchy can
be done in polynomial time. Empirically, HSD gives up to 1.2x speed-up over the
best single-draft baseline, demonstrating the practicality of our algorithm in
reducing generation latency beyond previous techniques.

</details>


### [370] [SEMPO: Lightweight Foundation Models for Time Series Forecasting](https://arxiv.org/abs/2510.19710)
*Hui He,Kun Yi,Yuanchi Ma,Qi Zhang,Zhendong Niu,Guansong Pang*

Main category: cs.LG

TL;DR: SEMPO是一个轻量级的时间序列预测基础模型，通过能量感知谱分解和混合提示Transformer，在减少预训练数据和模型规模的同时，实现了强大的泛化能力和高效的模型适应性。


<details>
  <summary>Details</summary>
Motivation: 解决现有时间序列基础模型在资源受限环境下部署困难的问题，平衡通用性和可负担性。

Method: 1. 能量感知谱分解模块：同时建模高能量和低能量但信息丰富的频带信号，提高预训练数据利用率。2. 混合提示Transformer模块：通过特定数据集的提示学习异构时间模式，并自适应地将时间序列token路由到基于提示的专家，实现参数高效的模型适应。

Result: 在两个大型基准（涵盖16个数据集）上的大量实验证明，SEMPO在零样本和少样本预测场景下优于最先进的方法，显著减少了预训练数据规模和模型尺寸，同时实现了强大的泛化能力。

Conclusion: SEMPO通过其创新的模块设计，成功地降低了时间序列基础模型的资源需求，同时保持甚至提高了预测性能，为在资源受限环境下的应用提供了可行方案。

Abstract: The recent boom of large pre-trained models witnesses remarkable success in
developing foundation models (FMs) for time series forecasting. Despite
impressive performance across diverse downstream forecasting tasks, existing
time series FMs possess massive network architectures and require substantial
pre-training on large-scale datasets, which significantly hinders their
deployment in resource-constrained environments. In response to this growing
tension between versatility and affordability, we propose SEMPO, a novel
lightweight foundation model that requires pretraining on relatively
small-scale data, yet exhibits strong general time series forecasting.
Concretely, SEMPO comprises two key modules: 1) energy-aware SpEctral
decomposition module, that substantially improves the utilization of
pre-training data by modeling not only the high-energy frequency signals but
also the low-energy yet informative frequency signals that are ignored in
current methods; and 2) Mixture-of-PrOmpts enabled Transformer, that learns
heterogeneous temporal patterns through small dataset-specific prompts and
adaptively routes time series tokens to prompt-based experts for
parameter-efficient model adaptation across different datasets and domains.
Equipped with these modules, SEMPO significantly reduces both pre-training data
scale and model size, while achieving strong generalization. Extensive
experiments on two large-scale benchmarks covering 16 datasets demonstrate the
superior performance of SEMPO in both zero-shot and few-shot forecasting
scenarios compared with state-of-the-art methods. Code and data are available
at https://github.com/mala-lab/SEMPO.

</details>


### [371] [Enabling Granular Subgroup Level Model Evaluations by Generating Synthetic Medical Time Series](https://arxiv.org/abs/2510.19728)
*Mahmoud Ibrahim,Bart Elen,Chang Sun,Gökhan Ertaylan,Michel Dumontier*

Main category: cs.LG

TL;DR: 本研究提出了Enhanced TimeAutoDiff框架，利用合成ICU时间序列数据来训练和评估预测模型，特别是在细粒度人口亚组方面。该框架通过增强潜在扩散目标和引入分布对齐惩罚，显著减少了真实数据评估与合成数据评估之间的差距，同时保持了训练效用。此外，它还能有效降低亚组级别的AUROC估计误差，优于使用小型真实测试集。该研究为在不泄露敏感电子健康记录数据的情况下，对重症监护中的模型进行可信、细粒度的评估提供了实用且注重隐私的方案。


<details>
  <summary>Details</summary>
Motivation: 现有合成时间序列数据生成方法在训练和评估预测模型时，在真实评估和合成评估之间存在较大差距，并且在细粒度人口亚组评估方面存在不足。本研究旨在通过提出一种新的框架来解决这些问题，以实现更可信、更细粒度的模型评估。

Method: 提出了一种名为Enhanced TimeAutoDiff的新框架，它在现有的基于扩散和VAE的生成器（TimeDiff, HealthGen, TimeAutoDiff）基础上，通过在潜在扩散目标中加入分布对齐惩罚来增强模型。该框架在MIMIC-III和eICU数据集上，针对24小时死亡率和二元住院时长任务，对所有模型进行了广泛的基准测试。

Result: Enhanced TimeAutoDiff将真实评估与合成评估之间的差距（“TRTS gap”）缩小了70%以上，AUROC的ΔTRTS值达到0.014，同时保持了训练效用（ΔTSTR ≈ 0.01）。在32个交叉亚组的评估中，大型合成队列将亚组级别的AUROC估计误差降低了高达50%，并且在72-84%的亚组中表现优于小型真实测试集。

Conclusion: 本研究提供了一个实用且注重隐私的路线图，用于在重症监护领域进行可信的、细粒度的模型评估。它能够在不暴露敏感电子健康记录数据的情况下，实现对不同患者群体进行稳健可靠的性能分析，从而提高医学人工智能的整体可信度。

Abstract: We present a novel framework for leveraging synthetic ICU time-series data
not only to train but also to rigorously and trustworthily evaluate predictive
models, both at the population level and within fine-grained demographic
subgroups. Building on prior diffusion and VAE-based generators (TimeDiff,
HealthGen, TimeAutoDiff), we introduce \textit{Enhanced TimeAutoDiff}, which
augments the latent diffusion objective with distribution-alignment penalties.
We extensively benchmark all models on MIMIC-III and eICU, on 24-hour mortality
and binary length-of-stay tasks. Our results show that Enhanced TimeAutoDiff
reduces the gap between real-on-synthetic and real-on-real evaluation (``TRTS
gap'') by over 70\%, achieving $\Delta_{TRTS} \leq 0.014$ AUROC, while
preserving training utility ($\Delta_{TSTR} \approx 0.01$). Crucially, for 32
intersectional subgroups, large synthetic cohorts cut subgroup-level AUROC
estimation error by up to 50\% relative to small real test sets, and outperform
them in 72--84\% of subgroups. This work provides a practical,
privacy-preserving roadmap for trustworthy, granular model evaluation in
critical care, enabling robust and reliable performance analysis across diverse
patient populations without exposing sensitive EHR data, contributing to the
overall trustworthiness of Medical AI.

</details>


### [372] [Statistical Inference for Linear Functionals of Online Least-squares SGD when $t \gtrsim d^{1+δ}$](https://arxiv.org/abs/2510.19734)
*Bhavya Agrawalla,Krishnakumar Balasubramanian,Promit Ghosal*

Main category: cs.LG

TL;DR: 本文为在线最小二乘随机梯度下降（SGD）的线性函数建立了非渐近Berry-Esseen界限，并在增长维度条件下提供了高斯中心极限定理（CLT）。


<details>
  <summary>Details</summary>
Motivation: 在现代数据科学中，随机梯度下降（SGD）被广泛应用，但在高风险应用中，对其固有的不确定性进行严格量化是必要的。

Method: 本文建立了在线最小二乘SGD的线性函数在增长维度下的非渐近Berry-Esseen界限，并提出了一种在线方差估计量，以实现CLT的实际应用。

Result: 与现有方法相比，本文提出的方法在维度扩展性上显著扩展，计算效率更高，允许的迭代次数增长为$t \gtrsim d^{1+\delta}$（其中$\delta > 0$），而现有方法需要$t \gtrsim d^{3/2}$。此外，该方法的时间复杂度为$\\mathcal{O}(td)$，空间复杂度为$\\mathcal{O}(d)$。

Conclusion: 本文提出了一个完全在线、数据驱动的框架，用于在近乎最优的$t \gtrsim d^{1+\delta}$的尺度下，为SGD迭代构建置信区间。

Abstract: Stochastic Gradient Descent (SGD) has become a cornerstone method in modern
data science. However, deploying SGD in high-stakes applications necessitates
rigorous quantification of its inherent uncertainty. In this work, we establish
\emph{non-asymptotic Berry--Esseen bounds} for linear functionals of online
least-squares SGD, thereby providing a Gaussian Central Limit Theorem (CLT) in
a \emph{growing-dimensional regime}. Existing approaches to high-dimensional
inference for projection parameters, such as~\cite{chang2023inference}, rely on
inverting empirical covariance matrices and require at least $t \gtrsim
d^{3/2}$ iterations to achieve finite-sample Berry--Esseen guarantees,
rendering them computationally expensive and restrictive in the allowable
dimensional scaling. In contrast, we show that a CLT holds for SGD iterates
when the number of iterations grows as $t \gtrsim d^{1+\delta}$ for any $\delta
> 0$, significantly extending the dimensional regime permitted by prior works
while improving computational efficiency. The proposed online SGD-based
procedure operates in $\mathcal{O}(td)$ time and requires only $\mathcal{O}(d)$
memory, in contrast to the $\mathcal{O}(td^2 + d^3)$ runtime of
covariance-inversion methods. To render the theory practically applicable, we
further develop an \emph{online variance estimator} for the asymptotic variance
appearing in the CLT and establish \emph{high-probability deviation bounds} for
this estimator. Collectively, these results yield the first fully online and
data-driven framework for constructing confidence intervals for SGD iterates in
the near-optimal scaling regime $t \gtrsim d^{1+\delta}$.

</details>


### [373] [BATIS: Bayesian Approaches for Targeted Improvement of Species Distribution Models](https://arxiv.org/abs/2510.19749)
*Catherine Villeneuve,Benjamin Akera,Mélisande Teng,David Rolnick*

Main category: cs.LG

TL;DR: 深度学习物种分布模型（SDMs）在处理复杂数据集方面表现出色，但受数据空间偏差的限制。本文提出了一种名为BATIS的贝叶斯框架，通过迭代更新先验预测来解决这个问题，并有效地结合了局部洞察和宏观生态模式。该方法在公民科学数据上进行了基准测试，证明了贝叶斯深度学习方法在数据稀疏地区的可靠性，有助于生态学研究和保护工作。


<details>
  <summary>Details</summary>
Motivation: 现有的物种分布模型（SDMs）在处理因数据空间偏差引起的不确定性方面存在局限，尤其是在数据稀疏的地区，这影响了其在生态学研究和保护中的应用。

Method: 提出了一种名为BATIS的贝叶斯深度学习框架，该框架通过迭代更新先验预测来结合局部观测数据和宏观生态模式，并对aleatoric和epistemic不确定性进行量化。

Result: 在包含eBird公民科学观测数据的数据集上进行了广泛的基准测试，证明了BATIS框架能够显著提高数据稀疏地区SDMs的可靠性。

Conclusion: 贝叶斯深度学习方法，特别是BATIS框架，能够有效提高物种分布模型的可靠性，尤其是在数据稀疏的地区，为生态学研究和保护工作提供了有价值的工具。

Abstract: Species distribution models (SDMs), which aim to predict species occurrence
based on environmental variables, are widely used to monitor and respond to
biodiversity change. Recent deep learning advances for SDMs have been shown to
perform well on complex and heterogeneous datasets, but their effectiveness
remains limited by spatial biases in the data. In this paper, we revisit deep
SDMs from a Bayesian perspective and introduce BATIS, a novel and practical
framework wherein prior predictions are updated iteratively using limited
observational data. Models must appropriately capture both aleatoric and
epistemic uncertainty to effectively combine fine-grained local insights with
broader ecological patterns. We benchmark an extensive set of uncertainty
quantification approaches on a novel dataset including citizen science
observations from the eBird platform. Our empirical study shows how Bayesian
deep learning approaches can greatly improve the reliability of SDMs in
data-scarce locations, which can contribute to ecological understanding and
conservation efforts.

</details>


### [374] [When Do Transformers Learn Heuristics for Graph Connectivity?](https://arxiv.org/abs/2510.19753)
*Qilin Ye,Deqing Fu,Robin Jia,Vatsal Sharan*

Main category: cs.LG

TL;DR: Transformer 模型在学习可泛化算法方面存在困难，容易依赖于不可靠的启发式方法。本文以图连通性为研究对象，从理论和实证两方面解释了这一现象。


<details>
  <summary>Details</summary>
Motivation: Transformer 模型在学习可泛化算法方面存在困难，容易依赖于不可靠的启发式方法。

Method: 本文提出了一种简化的 Transformer 架构——解耦 Transformer，并证明了其 $L$ 层模型能够解决直径最大为 $3^L$ 的图问题，其算法等价于计算邻接矩阵的幂。同时，分析了训练动态，表明学习策略取决于训练实例是否在模型的容量范围内。

Result: 容量内的图（直径 $\leq 3^L$）能够驱动模型学习到正确的算法解决方案，而容量外的图则会驱动模型学习到基于节点度的启发式方法。通过实验证明，限制训练数据在模型容量范围内，可以使标准和解耦的 Transformer 模型学习到精确算法，而非基于节点度的启发式方法。

Conclusion: Transformer 模型在学习可泛化算法时，其训练数据的容量是关键因素。当训练数据在模型容量范围内时，模型能够学习到精确的算法；当超出容量时，模型则倾向于学习启发式方法。

Abstract: Transformers often fail to learn generalizable algorithms, instead relying on
brittle heuristics. Using graph connectivity as a testbed, we explain this
phenomenon both theoretically and empirically. We consider a simplified
Transformer architecture, the disentangled Transformer, and prove that an
$L$-layer model has capacity to solve for graphs with diameters up to exactly
$3^L$, implementing an algorithm equivalent to computing powers of the
adjacency matrix. We analyze the training-dynamics, and show that the learned
strategy hinges on whether most training instances are within this model
capacity. Within-capacity graphs (diameter $\leq 3^L$) drive the learning of a
correct algorithmic solution while beyond-capacity graphs drive the learning of
a simple heuristic based on node degrees. Finally, we empirically demonstrate
that restricting training data within a model's capacity leads to both standard
and disentangled transformers learning the exact algorithm rather than the
degree-based heuristic.

</details>


### [375] [A Survey on Cache Methods in Diffusion Models: Toward Efficient Multi-Modal Generation](https://arxiv.org/abs/2510.19755)
*Jiacheng Liu,Xinyu Wang,Yuqi Lin,Zhikai Wang,Peiru Wang,Peiliang Cai,Qinming Zhou,Zhengan Yan,Zexuan Yan,Zhengyi Shi,Chang Zou,Yue Ma,Linfeng Zhang*

Main category: cs.LG

TL;DR: Diffusion Caching是一种训练无关、架构无关且高效的推理范式，通过识别和重用扩散过程中固有的计算冗余来加速扩散模型，将模型从静态重用发展为动态预测，以实现高效的生成式人工智能。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型由于多步迭代和复杂的骨干网络，计算开销大，生成延迟高，限制了其实时应用。现有的加速技术存在适用性有限、训练成本高或质量下降等问题。

Method: Diffusion Caching通过特征级跨步重用和层间调度来识别和重用扩散过程中的计算冗余，从而在不修改模型参数的情况下减少计算量。

Result: 通过对代表性方法进行比较分析，发现Diffusion Caching从静态重用发展为动态预测，提高了跨任务的灵活性，并能与其他加速技术（如采样优化和模型蒸馏）集成，为未来的多模态和交互式应用奠定了统一高效的推理框架。

Conclusion: Diffusion Caching将成为实现实时、高效的生成式人工智能的关键推动者，为高效生成式智能的理论和实践注入新的活力。

Abstract: Diffusion Models have become a cornerstone of modern generative AI for their
exceptional generation quality and controllability. However, their inherent
\textit{multi-step iterations} and \textit{complex backbone networks} lead to
prohibitive computational overhead and generation latency, forming a major
bottleneck for real-time applications. Although existing acceleration
techniques have made progress, they still face challenges such as limited
applicability, high training costs, or quality degradation.
  Against this backdrop, \textbf{Diffusion Caching} offers a promising
training-free, architecture-agnostic, and efficient inference paradigm. Its
core mechanism identifies and reuses intrinsic computational redundancies in
the diffusion process. By enabling feature-level cross-step reuse and
inter-layer scheduling, it reduces computation without modifying model
parameters. This paper systematically reviews the theoretical foundations and
evolution of Diffusion Caching and proposes a unified framework for its
classification and analysis.
  Through comparative analysis of representative methods, we show that
Diffusion Caching evolves from \textit{static reuse} to \textit{dynamic
prediction}. This trend enhances caching flexibility across diverse tasks and
enables integration with other acceleration techniques such as sampling
optimization and model distillation, paving the way for a unified, efficient
inference framework for future multimodal and interactive applications. We
argue that this paradigm will become a key enabler of real-time and efficient
generative AI, injecting new vitality into both theory and practice of
\textit{Efficient Generative Intelligence}.

</details>


### [376] [CONFEX: Uncertainty-Aware Counterfactual Explanations with Conformal Guarantees](https://arxiv.org/abs/2510.19754)
*Aman Bilkhoo,Milad Kazemi,Nicola Paoletti,Mehran Hosseini*

Main category: cs.LG

TL;DR: Counterfactual explanations (CFXs) must account for predictive uncertainty to be reliable. Existing methods often fail to do this rigorously. We propose CONFEX, a novel method using Conformal Prediction (CP) and Mixed-Integer Linear Programming (MILP) to generate uncertainty-aware CFXs with formal coverage guarantees. CONFEX uses a localized CP procedure and an efficient MILP encoding via offline tree-based partitioning, providing rigorous guarantees on both uncertainty and optimality. Evaluation shows CONFEX yields robust and plausible explanations compared to state-of-the-art methods.


<details>
  <summary>Details</summary>
Motivation: To generate reliable counterfactual explanations (CFXs) that are human-understandable and actionable, it is crucial to avoid regions of high predictive uncertainty where explanations might be misleading. Existing methods often neglect this crucial aspect or lack formal guarantees for incorporating uncertainty.

Method: CONFEX generates uncertainty-aware counterfactual explanations using Conformal Prediction (CP) for uncertainty quantification and Mixed-Integer Linear Programming (MILP) for optimization. It introduces a novel localized CP procedure designed to provide local coverage guarantees, addressing the violation of exchangeability in CFX generation. This procedure is efficiently encoded using MILP by leveraging an offline tree-based partitioning of the input space.

Result: The proposed method, CONFEX, has been evaluated against state-of-the-art approaches on various benchmarks and using multiple metrics. The results demonstrate that CONFEX, by being uncertainty-aware, produces explanations that are both robust and plausible.

Conclusion: CONFEX successfully generates counterfactual explanations with rigorous guarantees on predictive uncertainty and optimality by integrating Conformal Prediction with Mixed-Integer Linear Programming through a novel localized procedure and an efficient MILP encoding. This approach leads to more reliable and plausible explanations compared to existing methods.

Abstract: Counterfactual explanations (CFXs) provide human-understandable
justifications for model predictions, enabling actionable recourse and
enhancing interpretability. To be reliable, CFXs must avoid regions of high
predictive uncertainty, where explanations may be misleading or inapplicable.
However, existing methods often neglect uncertainty or lack principled
mechanisms for incorporating it with formal guarantees. We propose CONFEX, a
novel method for generating uncertainty-aware counterfactual explanations using
Conformal Prediction (CP) and Mixed-Integer Linear Programming (MILP). CONFEX
explanations are designed to provide local coverage guarantees, addressing the
issue that CFX generation violates exchangeability. To do so, we develop a
novel localised CP procedure that enjoys an efficient MILP encoding by
leveraging an offline tree-based partitioning of the input space. This way,
CONFEX generates CFXs with rigorous guarantees on both predictive uncertainty
and optimality. We evaluate CONFEX against state-of-the-art methods across
diverse benchmarks and metrics, demonstrating that our uncertainty-aware
approach yields robust and plausible explanations.

</details>


### [377] [The Tail Tells All: Estimating Model-Level Membership Inference Vulnerability Without Reference Models](https://arxiv.org/abs/2510.19773)
*Euodia Dodd,Nataša Krčo,Igor Shilov,Yves-Alexandre de Montjoye*

Main category: cs.LG

TL;DR: 本研究提出了一种无需训练参考模型即可评估 AI 模型对成员推断攻击（MIA）的隐私风险的新方法，通过分析损失分布的特性来预测风险。


<details>
  <summary>Details</summary>
Motivation: 现有的成员推断攻击（MIA）通常需要训练大量计算成本高昂的参考模型，限制了其实用性。

Method: 提出了一种新的评估模型级漏洞（在低假阳性率下的真阳性率）的方法，无需参考模型。该方法基于损失分布的非对称性和重尾特性，以及模型训练后风险点从高损失区（尾部）转移到低损失区（头部）的观察。具体来说，该方法通过在高损失区域中识别异常值的缺失来估计模型对 MIA 的风险。

Result: 实验表明，所提出的方法（一种简单损失攻击的 TNR）在多种架构和数据集上能够准确估计模型对最先进 MIA（LiRA）的漏洞，并且优于 RMIA 等低成本攻击和其他分布差异度量方法。此外，研究还评估了非线性函数在风险评估中的应用，并显示该方法在评估大型语言模型的风险方面具有潜力。

Conclusion: 本研究提出的无需参考模型即可评估模型对 MIA 风险的新方法，具有准确性、效率和广泛适用性，为 AI 模型隐私保护评估提供了新的思路和工具，尤其在大语言模型风险评估方面显示出潜力。

Abstract: Membership inference attacks (MIAs) have emerged as the standard tool for
evaluating the privacy risks of AI models. However, state-of-the-art attacks
require training numerous, often computationally expensive, reference models,
limiting their practicality. We present a novel approach for estimating
model-level vulnerability, the TPR at low FPR, to membership inference attacks
without requiring reference models. Empirical analysis shows loss distributions
to be asymmetric and heavy-tailed and suggests that most points at risk from
MIAs have moved from the tail (high-loss region) to the head (low-loss region)
of the distribution after training. We leverage this insight to propose a
method to estimate model-level vulnerability from the training and testing
distribution alone: using the absence of outliers from the high-loss region as
a predictor of the risk. We evaluate our method, the TNR of a simple loss
attack, across a wide range of architectures and datasets and show it to
accurately estimate model-level vulnerability to the SOTA MIA attack (LiRA). We
also show our method to outperform both low-cost (few reference models) attacks
such as RMIA and other measures of distribution difference. We finally evaluate
the use of non-linear functions to evaluate risk and show the approach to be
promising to evaluate the risk in large-language models.

</details>


### [378] [GaLLoP: Gradient-based Sparse Learning on Low-Magnitude Parameters](https://arxiv.org/abs/2510.19778)
*Anand Choudhary,Yasser Sulaıman,Lukas Mauch,Ghouthi Boukli Hacene,Fabien Cardinaux,Antoine Bosselut*

Main category: cs.LG

TL;DR: GaLLoP是一种新的稀疏微调技术，通过选择梯度大且预训练时幅度小的参数进行微调，有效适应下游任务，并优于LoRA等现有技术。


<details>
  <summary>Details</summary>
Motivation: 稀疏微调的有效性取决于最优地选择要微调的模型参数。

Method: GaLLoP: Gradient-based Sparse Learning on Low-Magnitude Parameters，选择梯度幅度最大且预训练时幅度最小的模型参数进行微调。

Result: 在LLaMA3 8B和Gemma 2B模型上的实验表明，GaLLoP的性能优于或匹配LoRA、DoRA和SAFT等技术，并能缓解灾难性遗忘和任务数据记忆问题。

Conclusion: GaLLoP通过保持重要的预训练参数不变，缓解了灾难性遗忘和任务数据记忆，并提高了模型在不同随机种子下的泛化性能。

Abstract: Sparse fine-tuning techniques adapt LLMs to downstream tasks by only tuning a
sparse subset of model parameters. However, the effectiveness of sparse
adaptation depends on optimally selecting the model parameters to be
fine-tuned. In this work, we introduce a novel sparse fine-tuning technique
named GaLLoP: Gradient-based Sparse Learning on Low-Magnitude Parameters, which
fine-tunes only those model parameters which have the largest gradient
magnitudes on downstream tasks and the smallest pre-trained magnitudes,
intuitively prioritizing parameters that are highly task-relevant, but
minimally disruptive to pre-trained knowledge. Our experimentation with LLaMA3
8B and Gemma 2B as base models shows that GaLLoP consistently improves or
matches the in-distribution as well as out-of-distribution performance obtained
via the usage of other leading parameter-efficient fine-tuning techniques,
including LoRA, DoRA, and SAFT. Our analysis demonstrates that GaLLoP mitigates
catastrophic forgetting and memorization of task data, as important pre-trained
parameters remain unchanged, and stabilizes performance relative to other
fine-tuning techniques, robustly generalizing across most random seeds.

</details>


### [379] [Environment Inference for Learning Generalizable Dynamical System](https://arxiv.org/abs/2510.19784)
*Shixuan Liu,Yue He,Haotian Wang,Wenjing Yang,Yunfei Wang,Peng Cui,Zhong Liu*

Main category: cs.LG

TL;DR: 该研究提出了一种名为 DynaInfer 的新方法，用于在没有环境标签的情况下推断动态系统的环境规范，解决了传统数据驱动方法对 I.I.D. 数据的依赖性以及现有泛化技术对环境标签的依赖性。


<details>
  <summary>Details</summary>
Motivation: 传统数据驱动方法在处理复杂动态系统时效率高且鲁棒，但它们依赖于独立同分布（I.I.D.）数据的假设。为了处理环境差异，已经开发了泛化技术，但这些技术通常需要环境标签，而在实际应用中，由于数据采集的挑战、隐私问题以及环境的固有变异性，环境标签往往是不可用的，尤其是在大型公共数据集和隐私敏感领域。

Method: DynaInfer 的核心思想是通过分析每个训练轮次中固定神经网络的预测误差来推断环境规范，从而直接从数据中进行环境分配。该算法被证明可以有效地解决无标签场景下的交替优化问题。

Result: 通过在各种动态系统上进行的大量实验验证，DynaInfer 被证明能够有效地推断环境规范。实验结果表明，DynaInfer 在性能上优于现有的环境分配技术，能够快速收敛到真实标签，并且即使在提供环境标签的情况下，其表现也同样出色。

Conclusion: DynaInfer 是一种有效且无需标签的环境推断方法，能够克服传统方法对 I.I.D. 数据和环境标签的依赖性，在处理复杂动态系统方面具有显著优势。

Abstract: Data-driven methods offer efficient and robust solutions for analyzing
complex dynamical systems but rely on the assumption of I.I.D. data, driving
the development of generalization techniques for handling environmental
differences. These techniques, however, are limited by their dependence on
environment labels, which are often unavailable during training due to data
acquisition challenges, privacy concerns, and environmental variability,
particularly in large public datasets and privacy-sensitive domains. In
response, we propose DynaInfer, a novel method that infers environment
specifications by analyzing prediction errors from fixed neural networks within
each training round, enabling environment assignments directly from data. We
prove our algorithm effectively solves the alternating optimization problem in
unlabeled scenarios and validate it through extensive experiments across
diverse dynamical systems. Results show that DynaInfer outperforms existing
environment assignment techniques, converges rapidly to true labels, and even
achieves superior performance when environment labels are available.

</details>


### [380] [Blackbox Model Provenance via Palimpsestic Membership Inference](https://arxiv.org/abs/2510.19796)
*Rohith Kuditipudi,Jing Huang,Sally Zhu,Diyi Yang,Christopher Potts,Percy Liang*

Main category: cs.LG

TL;DR: Alice 训练了一个开放权重模型，Bob 使用该模型的黑盒版本生成文本。Alice 可以通过查询 Bob 的模型或仅观察文本来证明 Bob 正在使用她的模型。这被视为一个独立性检验问题，即 Bob 的模型或文本与 Alice 的训练过程是独立的。研究发现，模型在训练后期更有可能记住数据，因此可以通过检测 Bob 的模型或文本与 Alice 训练数据顺序之间的相关性来检验。如果 Alice 随机打乱了训练数据，任何显著的相关性都将是对原假设的统计证据。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是探索如何证明一个人（Bob）在生成文本时使用了另一个人（Alice）训练的开放权重语言模型，即使 Bob 只能访问该模型的黑盒版本。

Method: 研究人员将此问题建模为一个独立性检验问题，并利用语言模型“palimpsestic memorization”（模型更容易记住后期训练数据）的特性。在查询设置中，他们通过提示直接估计 Bob 的模型对 Alice 训练样本的给出以及顺序的可能性，并关联这些可能性与训练数据顺序。在观察设置中，他们尝试了两种方法：1）估计 Bob 的文本与 Alice 训练样本的重叠可能性；2）估计 Bob 的文本相对于 Alice 在不同重排数据上重复最后训练阶段（例如 1%）的版本。

Result: 在查询设置中，研究人员对不同参数规模（1B 到 12B）的 Pythia 和 OLMo 模型进行了 40 多次微调，并将这些微调模型的可能性与基础模型的训练数据顺序相关联，在大多数情况下获得了小于 1e-8 的 p 值。在观察设置中，第二种方法（基于重新训练）在仅几百个 token 的情况下就能可靠地区分 Bob 的文本，而第一种方法（无需重新训练）则需要几十万个 token 才能达到高功效。

Conclusion: 研究表明，通过利用模型对训练数据顺序的记忆特性，可以在查询和观察设置中检测 Bob 是否在使用 Alice 的模型。基于重训练的观察方法在处理少量文本时尤其有效，而基于文本重叠的观察方法则需要更多的文本数据。

Abstract: Suppose Alice trains an open-weight language model and Bob uses a blackbox
derivative of Alice's model to produce text. Can Alice prove that Bob is using
her model, either by querying Bob's derivative model (query setting) or from
the text alone (observational setting)? We formulate this question as an
independence testing problem--in which the null hypothesis is that Bob's model
or text is independent of Alice's randomized training run--and investigate it
through the lens of palimpsestic memorization in language models: models are
more likely to memorize data seen later in training, so we can test whether Bob
is using Alice's model using test statistics that capture correlation between
Bob's model or text and the ordering of training examples in Alice's training
run. If Alice has randomly shuffled her training data, then any significant
correlation amounts to exactly quantifiable statistical evidence against the
null hypothesis, regardless of the composition of Alice's training data. In the
query setting, we directly estimate (via prompting) the likelihood Bob's model
gives to Alice's training examples and order; we correlate the likelihoods of
over 40 fine-tunes of various Pythia and OLMo base models ranging from 1B to
12B parameters with the base model's training data order, achieving a p-value
on the order of at most 1e-8 in all but six cases. In the observational
setting, we try two approaches based on estimating 1) the likelihood of Bob's
text overlapping with spans of Alice's training examples and 2) the likelihood
of Bob's text with respect to different versions of Alice's model we obtain by
repeating the last phase (e.g., 1%) of her training run on reshuffled data. The
second approach can reliably distinguish Bob's text from as little as a few
hundred tokens; the first does not involve any retraining but requires many
more tokens (several hundred thousand) to achieve high power.

</details>


### [381] [Transformers are almost optimal metalearners for linear classification](https://arxiv.org/abs/2510.19797)
*Roey Magen,Gal Vardi*

Main category: cs.LG

TL;DR: Transformer 架构经过训练后，可以在线性分类设置中充当近乎最优的元学习器，只需少量上下文示例即可在新任务上进行泛化。


<details>
  <summary>Details</summary>
Motivation: 研究 Transformer 在没有额外训练的情况下，仅使用少量上下文示例就能适应新任务的能力，以解决一系列相关任务。

Method: 对简化的 Transformer 架构在梯度下降下进行训练，并在类别条件高斯混合模型（其均值向量位于 R^d 的共享 k 维子空间中）的自然任务族上进行分析。

Result: Transformer 可以在使用 O(k / R^4) 个上下文示例后在新任务上进行泛化，其性能接近于了解共享子空间的最优学习器，并且显著优于仅访问上下文数据的学习器（需要 Ω(d / R^4) 个示例）。

Conclusion: 在仅有上下文示例而无需额外训练的情况下，Transformer 架构可以作为元学习器，在新任务上实现近乎最优的泛化性能，并且在训练任务数量和每个任务的示例数量方面，其性能界限与环境维度 d 无关。

Abstract: Transformers have demonstrated impressive in-context learning (ICL)
capabilities, raising the question of whether they can serve as metalearners
that adapt to new tasks using only a small number of in-context examples,
without any further training. While recent theoretical work has studied
transformers' ability to perform ICL, most of these analyses do not address the
formal metalearning setting, where the objective is to solve a collection of
related tasks more efficiently than would be possible by solving each task
individually. In this paper, we provide the first theoretical analysis showing
that a simplified transformer architecture trained via gradient descent can act
as a near-optimal metalearner in a linear classification setting. We consider a
natural family of tasks where each task corresponds to a class-conditional
Gaussian mixture model, with the mean vectors lying in a shared $k$-dimensional
subspace of $R^d$. After training on a sufficient number of such tasks, we show
that the transformer can generalize to a new task using only $O(k / R^4)$
in-context examples, where $R$ denotes the signal strength at test time. This
performance (almost) matches that of an optimal learner that knows exactly the
shared subspace and significantly outperforms any learner that only has access
to the in-context data, which requires $\Omega(d / R^4)$ examples to
generalize. Importantly, our bounds on the number of training tasks and
examples per task needed to achieve this result are independent of the ambient
dimension $d$.

</details>


### [382] [The Feasibility of Training Sovereign Language Models in the Global South: A Study of Brazil and Mexico](https://arxiv.org/abs/2510.19801)
*Sandra Malagon,Monica A. Ulloa Ruiz,Tatiana Elizabeth Sandoval Plaza,Gabriel Rafael Rosario Bolívar,Valentina García Mesa,Ivanna Alvarado Morales*

Main category: cs.LG

TL;DR: 该论文探讨了巴西和墨西哥在硬件、能源和财政资源受限的情况下进行大规模语言模型训练的技术和财政可行性，并提出了延长训练时间作为一种政策工具。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型训练对计算能力的要求不断提高，导致高能力司法管辖区与全球南方国家之间在结构上存在不平等。本文旨在研究巴西和墨西哥在主权规模的语言模型训练中的技术和财政可行性，重点关注硬件获取、能源供应和财政限制等条件。

Method: 文章采用双轴设计，改变加速器代（NVIDIA H100 vs. A100）和训练时间（90天 vs. 150天），以估算训练一个10万亿标记模型所需的计算需求、能源消耗、资本支出和法规兼容性。

Result: 研究表明，虽然所有配置都未超过出口管制和电气基础设施的阈值，但财政可行性取决于硬件效率。基于H100的方案总成本为800万至1400万美元，可以实现训练可行性；而基于A100的方案由于能源和硬件需求更高，成本为1900万至3200万美元。

Conclusion: 文章认为，应将延长训练时间视为一种政策工具，以缓解硬件限制，使发展中国家能够在不与全球前沿竞争的情况下，生产出可用、可审计且符合本地需求的大型语言模型。该研究通过强调具有成本效益的策略，为人工智能计算治理和技术主权领域做出了贡献，使中等收入国家能够建立可持续和具有战略意义的人工智能能力。

Abstract: The rapid escalation of computational requirements for training large-scale
language models has reinforced structural asymmetries between high-capacity
jurisdictions and countries in the Global South. This paper examines the
technical and fiscal feasibility of sovereign-scale language model training in
Brazil and Mexico under conditions of constrained hardware access, energy
availability, and fiscal ceilings. Using a dual-axis design that varies
accelerator generation (NVIDIA H100 vs. A100) and training duration (90 vs. 150
days), we estimate compute demand, energy consumption, capital expenditures,
and regulatory compatibility for the training of a 10-trillion-token model. Our
findings show that while all configurations remain below export-control and
electrical infrastructure thresholds, fiscal viability is determined by
hardware efficiency. H100-based scenarios achieve training feasibility at a
total cost of 8-14 million USD, while A100 deployments require 19-32 million
USD due to higher energy and hardware demand. We argue that extending training
timelines should be treated as a policy lever to mitigate hardware constraints,
enabling the production of usable, auditable, and locally aligned models
without competing at the global frontier. This study contributes to the
discourse on AI compute governance and technological sovereignty by
highlighting context-sensitive strategies that allow middle-income countries to
establish sustainable and strategically sufficient AI capabilities.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [383] [Res-DPU: Resource-shared Digital Processing-in-memory Unit for Edge-AI Workloads](https://arxiv.org/abs/2510.19260)
*Mukul Lokhande,Narendra Singh Dhakad,Seema Chouhan,Akash Sankhe,Santosh Kumar Vishvakarma*

Main category: cs.AR

TL;DR: Res-DPU通过资源共享、优化的SRAM和计算逻辑、简化的加法器树以及可控的近似乘法方法，解决了数字PIM的计算密度和能效瓶颈，实现了高性能和高能效的边缘AI推理。


<details>
  <summary>Details</summary>
Motivation: 当前的数字PIM方法面临计算密度低、宏可扩展性和能效问题，主要是由于位单元庞大和加法器树晶体管数量多。

Method: 提出了一种名为Res-DPU的资源共享数字PIM单元，采用双端口5T SRAM锁存器和共享2T AND计算逻辑。设计了一个晶体管数量简化的2D交织加法器树（TRAIT），使用了7T全加器（FA-7T）和26T（PG-FA-26T）设计。提出了一种周期控制的迭代近似-精确乘法（CIA2M）方法。

Result: Res-DPU将每比特乘法成本降低至5.25T，PIM阵列晶体管数量减少高达56%。TRAIT将加法器树功耗降低高达21.35%，能效比28T RCA设计提高59%。16KB的REP-DPIM宏在TSMC 65nm工艺下达到了0.43 TOPS的吞吐量和87.22 TOPS/W的能效，在CIFAR-10数据集上运行ResNet-18或VGG-16（包含30%剪枝）时，实现了96.85%的质量（QoR）。

Conclusion: 所提出的Res-DPU模块为高度可扩展且能效比高的实时边缘AI加速器提供了解决方案。

Abstract: Processing-in-memory (PIM) has emerged as the go to solution for addressing
the von Neumann bottleneck in edge AI accelerators. However, state-of-the-art
(SoTA) digital PIM approaches suffer from low compute density, primarily due to
the use of bulky bit cells and transistor-heavy adder trees, which impose
limitations on macro scalability and energy efficiency. This work introduces
Res-DPU, a resource-shared digital PIM unit, with a dual-port 5T SRAM latch and
shared 2T AND compute logic. This reflects the per-bit multiplication cost to
just 5.25T and reduced the transistor count of the PIM array by up to 56% over
the SoTA works. Furthermore, a Transistor-Reduced 2D Interspersed Adder Tree
(TRAIT) with FA-7T and PG-FA-26T helps reduce the power consumption of the
adder tree by up to 21.35% and leads to improved energy efficiency by 59%
compared to conventional 28T RCA designs. We propose a Cycle-controlled
Iterative Approximate-Accurate Multiplication (CIA2M) approach, enabling
run-time accuracy-latency trade-offs without requiring error-correction
circuitry. The 16 KB REP-DPIM macro achieves 0.43 TOPS throughput and 87.22
TOPS/W energy efficiency in TSMC 65nm CMOS, with 96.85% QoR for ResNet-18 or
VGG-16 on CIFAR-10, including 30% pruning. The proposed results establish a
Res-DPU module for highly scalable and energy-efficient real-time edge AI
accelerators.

</details>


### [384] [gem5 Co-Pilot: AI Assistant Agent for Architectural Design Space Exploration](https://arxiv.org/abs/2510.19577)
*Zuoming Fu,Alex Manley,Mohammad Alian*

Main category: cs.AR

TL;DR: gem5 Co-Pilot是一个利用大型语言模型（LLMs）的AI助手，旨在自动化和简化gem5计算机体系结构模拟器的设计空间探索过程，通过提供一个网页GUI、一种新的设计空间探索语言和一个设计空间数据库（DSDB）来提高效率，并在成本约束优化方面表现优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 计算机体系结构设计空间探索过程复杂且耗时，涉及大量参数设置和模拟统计数据的分析。大型语言模型的出现加速了长文本数据分析和智能决策，这对于设计空间探索任务至关重要。

Method: 开发了一个名为gem5 Co-Pilot的AI助手，提供网页GUI，实现了代理自动化和结果摘要。实现了一种用于设计空间探索的语言，并构建了一个设计空间数据库（DSDB）。gem5 Co-Pilot利用DSDB实现了检索增强生成（RAG）系统，以辅助gem5的设计空间探索。

Result: 在成本约束优化的实验中，gem5 Co-Pilot在四个成本范围内进行了比较，并与两个基线模型进行了对比。结果表明，gem5 Co-Pilot能够根据性能和成本约束，在有限的用户交互下快速识别最优参数。

Conclusion: gem5 Co-Pilot在自动化和简化gem5设计空间探索方面取得了成功，能够有效地识别满足特定设计约束的最优参数，提高了开发效率。

Abstract: Generative AI is increasing the productivity of software and hardware
development across many application domains. In this work, we utilize the power
of Large Language Models (LLMs) to develop a co-pilot agent for assisting gem5
users with automating design space exploration. Computer architecture design
space exploration is complex and time-consuming, given that numerous parameter
settings and simulation statistics must be analyzed before improving the
current design. The emergence of LLMs has significantly accelerated the
analysis of long-text data as well as smart decision making, two key functions
in a successful design space exploration task. In this project, we first build
gem5 Co-Pilot, an AI agent assistant for gem5, which comes with a webpage-GUI
for smooth user interaction, agent automation, and result summarization. We
also implemented a language for design space exploration, as well as a Design
Space Database (DSDB). With DSDB, gem5 Co-Pilot effectively implements a
Retrieval Augmented Generation system for gem5 design space exploration. We
experiment on cost-constraint optimization with four cost ranges and compare
our results with two baseline models. Results show that gem5 Co-Pilot can
quickly identify optimal parameters for specific design constraints based on
performance and cost, with limited user interaction.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [385] [Knowledge and Common Knowledge of Strategies](https://arxiv.org/abs/2510.19298)
*Borja Sierra Miranda,Thomas Studer*

Main category: cs.LO

TL;DR: We propose a fine-grained model for strategic reasoning that distinguishes between first-order, higher-order, and common knowledge of strategies, and analyze its implications for game theory and the consensus problem.


<details>
  <summary>Details</summary>
Motivation: Most existing work on strategic reasoning uses either informed or uninformed semantics. There is a need for a more fine-grained model that can distinguish different levels of knowledge about strategies.

Method: The paper proposes a model where knowledge of strategies can be specified on a fine-grained level, distinguishing first-order, higher-order, and common knowledge of strategies. This model is illustrated using the game Hanabi and applied to the consensus problem. The decidability of the model checking problem is also studied.

Result: The paper illustrates the effect of higher-order knowledge of strategies using the game Hanabi. It is shown that common knowledge of strategies is necessary to solve the consensus problem. The decidability of the model checking problem is also studied.

Conclusion: The proposed fine-grained model provides a more nuanced understanding of strategic reasoning by incorporating different levels of knowledge. This has implications for analyzing games like Hanabi and understanding fundamental problems like consensus. The decidability of model checking in this framework is also a key finding.

Abstract: Most existing work on strategic reasoning simply adopts either an informed or
an uninformed semantics. We propose a model where knowledge of strategies can
be specified on a fine-grained level. In particular, it is possible to
distinguish first-order, higher-order, and common knowledge of strategies. We
illustrate the effect of higher-order knowledge of strategies by studying the
game Hanabi. Further, we show that common knowledge of strategies is necessary
to solve the consensus problem. Finally, we study the decidability of the model
checking problem.

</details>


### [386] [Universal Quantitative Abstraction: Categorical Duality and Logical Completeness for Probabilistic Systems](https://arxiv.org/abs/2510.19444)
*Nivar Anwer*

Main category: cs.LO

TL;DR: 本文提出了一种统一的定量抽象理论，结合了范畴论、最优传输和定量模态逻辑，用于概率系统。核心是一个规范的 $ \varepsilon $-商，具有普遍性质，在所有 $ \varepsilon $-抽象中信息量最大且能控制值损失。


<details>
  <summary>Details</summary>
Motivation: 为概率系统提供一种统一的定量抽象理论，并连接范畴论、最优传输和定量模态逻辑。

Method: 引入一个规范的 $ \varepsilon $-商，建立抽象和实现函子之间的伴随关系，通过特殊伴随函子定理证明了度量结构和逻辑语义之间的对偶性。定义了一个量化模态 $ \mu $-演算，并证明了其在逻辑可表系统上的表达完整性。

Result: 证明了行为伪度量是 Bellman 算子的唯一不动点，并在共代数环境中证明了其收缩和 Lipschitz 性质。量化模态 $ \mu $-演算与最大逻辑偏差一致。分析了接口细化下的组合性。在有限马尔可夫决策过程上的验证证实了收缩性质、值损失界限、扰动下的稳定性、对抗可区分性和可扩展性。

Conclusion: 该框架为状态聚合和表示学习提供了原则性目标，并为随机域中的值函数逼近提供了数学上精确的保证。

Abstract: A unified theory of quantitative abstraction is presented for probabilistic
systems that links category theory, optimal transport, and quantitative modal
logic. At its core is a canonical $ \varepsilon $-quotient endowed with a
universal property: among all $ \varepsilon $-abstractions, it is the most
informative one that respects a prescribed bound on value loss. This
construction induces an adjunction between abstraction and realization functors
$ (Q_{\varepsilon} \dashv R_{\varepsilon}) $, established via the Special
Adjoint Functor Theorem, revealing a categorical duality between metric
structure and logical semantics. A behavioral pseudometric is characterized as
the unique fixed point of a Bellman-style operator, with contraction and
Lipschitz properties proved in a coalgebraic setting. A quantitative modal $
\mu $-calculus is introduced and shown to be expressively complete for
logically representable systems, so that behavioral distance coincides with
maximal logical deviation. Compositionality under interface refinement is
analyzed, clarifying how abstractions interact across system boundaries. An
exact validation suite on finite Markov decision processes corroborates the
contraction property, value-loss bounds, stability under perturbation,
adversarial distinguishability, and scalability, demonstrating both robustness
and computational feasibility. The resulting framework provides principled
targets for state aggregation and representation learning, with mathematically
precise guarantees for value-function approximation in stochastic domains.

</details>


### [387] [A Unified Formal Theory on the Logical Limits of Symbol Grounding](https://arxiv.org/abs/2509.20409)
*Zhangchi Liu*

Main category: cs.LO

TL;DR: 本文通过形式化证明，对符号接地问题的逻辑极限进行了统一的理论构建。研究表明，形式系统中的意义必须源于外部的、动态的、非算法的过程。


<details>
  <summary>Details</summary>
Motivation: 阐述符号接地问题的逻辑极限，并提出统一的理论。 

Method: 通过四阶段的形式化论证：1. 证明纯粹符号系统内部无法建立意义的稳固基础。2. 证明有限、静态的预定义意义集合的内在不完备性。3. 证明符号与外部意义的连接不能是逻辑推理，而必须是公理化的元层更新。4. 证明任何固定的外部“判断”算法都无法解决该问题，只会构建一个更大的不完备系统。

Result: 形式化地确立了意义的接地是一个必然的开放式、非算法过程，揭示了任何自包含智能系统的基本、歌德尔式局限性。

Conclusion: 意义的接地是一个必然的开放式、非算法过程，揭示了任何自包含智能系统的基本、歌德尔式局限性。

Abstract: This paper synthesizes a series of formal proofs to construct a unified
theory on the logical limits of the Symbol Grounding Problem. We demonstrate
through a four-stage argument that meaning within a formal system must arise
from a process that is external, dynamic, and non-algorithmic. First, we prove
that any purely symbolic system, devoid of external connections, cannot
internally establish a consistent foundation for meaning due to
self-referential paradoxes. Second, we extend this limitation to systems with
any finite, static set of pre-established meanings, proving they are inherently
incomplete. Third, we demonstrate that the very "act" of connecting an internal
symbol to an external meaning cannot be a product of logical inference within
the system but must be an axiomatic, meta-level update. Finally, we prove that
any attempt to automate this update process using a fixed, external "judgment"
algorithm will inevitably construct a larger, yet equally incomplete, symbolic
system. Together, these conclusions formally establish that the grounding of
meaning is a necessarily open-ended, non-algorithmic process, revealing a
fundamental, G\"odel-style limitation for any self-contained intelligent
system.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [388] [AI-Aided Annealed Langevin Dynamics for Rapid Optimization of Programmable Channels](https://arxiv.org/abs/2510.18978)
*Tomer Shaked,Philipp del Hougne,George C. Alexandropoulos,Nir Shlezinger*

Main category: eess.SP

TL;DR: 该研究提出了一种新颖的AI辅助退火Langevin动力学（ALD）方法，用于优化无线通信中的可编程信道参数，无需显式信道建模，从而在RIS辅助场景中实现了快速可靠的信道参数调整。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖于简化的信道模型，但这些模型往往是粗略的近似，而更精确的模型（如复杂模拟器或测量）则不利于快速优化。因此，需要一种能够绕过显式信道建模并实现快速参数调整的新方法。

Method: 提出了一种基于AI辅助退火Langevin动力学（ALD）的新方法，并将其框架化为最大后验（MAP）估计。通过深度展开ALD算法，利用深度神经网络（DNN）估计梯度，并通过零阶梯度和主动学习的训练方法来克服对信道建模的需求，以增强泛化能力。

Result: 所提出的AI辅助ALD方法在具有丰富散射效应的RIS辅助场景中进行了评估，结果表明该方法能够实现有限延迟内的快速可靠信道参数调整。

Conclusion: AI辅助ALD方法是一种有效的解决方案，可以快速优化可编程信道参数，尤其是在RIS辅助的无线通信环境中，它克服了传统方法对显式信道建模的依赖，并在复杂多变的动态环境中表现出色。

Abstract: Emerging technologies such as Reconfigurable Intelligent Surfaces (RIS) make
it possible to optimize some parameters of wireless channels. Conventional
approaches require relating the channel and its programmable parameters via a
simple model that supports rapid optimization, e.g., re-tuning the parameters
each time the users move. However, in practice such models are often crude
approximations of the channel, and a more faithful description can be obtained
via complex simulators, or only by measurements. In this work, we introduce a
novel approach for rapid optimization of programmable channels based on
AI-aided Annealed Langevin Dynamics (ALD), which bypasses the need for explicit
channel modeling. By framing the ALD algorithm using the MAP estimate, we
design a deep unfolded ALD algorithm that leverages a Deep Neural Network (DNN)
to estimate score gradients for optimizing channel parameters. We introduce a
training method that overcomes the need for channel modeling using zero-order
gradients, combined with active learning to enhance generalization, enabling
optimization in complex and dynamically changing environments. We evaluate the
proposed method in RIS-aided scenarios subject to rich-scattering effects. Our
results demonstrate that our AI-aided ALD method enables rapid and reliable
channel parameter tuning with limited latency.

</details>


### [389] [Fundamental Limits of Cooperative Integrated Sensing and Communications over Low-Earth Orbit THz Satellite Channels](https://arxiv.org/abs/2510.19007)
*Haofan Dong,Houtianfu Wang,Hanlin Cai,Ozgur B. Akan*

Main category: eess.SP

TL;DR: 太赫兹星间链路的硬件损伤、指向误差和网络干扰会限制传感精度。我们提出了一个网络克拉美-罗下界（N-CRLB）框架，考虑了动态拓扑、硬件质量因子、相位噪声和合作效应，以提高传感精度。


<details>
  <summary>Details</summary>
Motivation: 低地球轨道（LEO）星座的太赫兹星间链路虽然能提供前所未有的传感精度，但受到硬件损伤、指向误差和网络干扰的根本限制。

Method: 我们开发了一个网络克拉美-罗下界（N-CRLB）框架，该框架结合了动态拓扑、硬件质量因子 $\Gamma_{\text{eff}}$、相位噪声 $\sigma^2_\phi$，并利用递归费雪信息分析来考虑合作效应。

Result: 研究结果表明：(1) 硬件和相位噪声会产生与功率无关的性能上限（$\\sigma_{\text{ceiling}} \propto \sqrt{\Gamma_{\text{eff}}}$）和下限（$\\sigma_{\text{floor}} \propto \sqrt{\sigma^2_\phi}/f_c$），并且仅考虑功率的缩放会在 $\text{SNR}_{\text{crit}}=1/\Gamma_{\text{eff}}$ 以上饱和；(2) 干扰系数 $\alpha_{\ell m}$ 能够在特定条件下（65 dB 处理增益，50 dBi 天线）实现 5.5 dB 的机会传感增益；(3) 来自共享时钟参考的测量相关性，如果模型正确，不会降低性能，并且与模型错误独立的噪声基线相比，可以提供共模抑制的好处。

Conclusion: 实现亚毫米级测距需要优化硬件（$\Gamma_{\text{eff}}<0.01$）、振荡器（$\sigma^2_\phi<10^{-2}$）和适当的 3D 几何配置。

Abstract: Terahertz inter-satellite links enable unprecedented sensing precision for
Low Earth Orbit (LEO) constellations, yet face fundamental bounds from hardware
impairments, pointing errors, and network interference. We develop a Network
Cram\'er-Rao Lower Bound (N-CRLB) framework incorporating dynamic topology,
hardware quality factor $\Gamma_{\text{eff}}$, phase noise $\sigma^2_\phi$, and
cooperative effects through recursive Fisher Information analysis. Our analysis
reveals three key insights: (i) hardware and phase noise create
power-independent performance ceilings ($\sigma_{\text{ceiling}} \propto
\sqrt{\Gamma_{\text{eff}}}$) and floors ($\sigma_{\text{floor}} \propto
\sqrt{\sigma^2_\phi}/f_c$), with power-only scaling saturating above
$\text{SNR}_{\text{crit}}=1/\Gamma_{\text{eff}}$; (ii) interference
coefficients $\alpha_{\ell m}$ enable opportunistic sensing with demonstrated
gains of 5.5~dB under specific conditions (65~dB processing gain, 50~dBi
antennas); (iii) measurement correlations from shared timing references, when
properly modeled, do not degrade performance and can provide common-mode
rejection benefits compared to mismodeled independent-noise baselines.
Sub-millimeter ranging requires co-optimized hardware
($\Gamma_{\text{eff}}<0.01$), oscillators ($\sigma^2_\phi<10^{-2}$), and
appropriate 3D geometry configurations.

</details>


### [390] [Macroscopic EEG Reveals Discriminative Low-Frequency Oscillations in Plan-to-Grasp Visuomotor Tasks](https://arxiv.org/abs/2510.19057)
*Anna Cetera,Sima Ghafoori,Ali Rabiee,Mohammad Hassan Farhadi,Yalda Shahriari,Reza Abiri*

Main category: eess.SP

TL;DR: 通过脑电图（EEG）研究抓握类型（精细、用力、无抓握）相关的神经活动，发现低频振荡在抓握类型规划和执行中起重要作用，并提出了一种新的基于视觉的抓握平台和FBCSP特征提取方法。


<details>
  <summary>Details</summary>
Motivation: 尽管侵入性记录已成功解码了与抓握类型规划和执行相关的局部神经活动，但使用非侵入性脑电图（EEG）捕获的大脑宏观神经激活模式的理解仍然有限。

Method: 提出了一种新的基于视觉的抓握平台，使用脑电图（EEG）和滤波器组公共空间模式（FBCSP）技术来提取判别性特征，并使用支持向量机（SVM）对抓握类型（精细、用力、无抓握）进行分类，同时与传统的运动相关皮层电位（MRCP）方法进行比较。

Result: 低频振荡（0.5-8 Hz）在规划和执行阶段都携带与抓握类型相关的信息，精细与用力抓握的分类准确率一致（75.3-77.8%），优于MRCP（61.1%）。高频活动（12-40 Hz）在抓握与无抓握分类中准确率达93.3%，但在精细与用力抓握分类中准确率为61.2%。SVM系数分析显示，规划阶段的特征主要来自额顶网络，执行阶段的特征来自运动网络。

Conclusion: 这项工作证明了低频振荡在通过非侵入性脑电图（EEG）解码规划过程中的抓握类型方面起着重要作用。

Abstract: The vision-based grasping brain network integrates visual perception with
cognitive and motor processes for visuomotor tasks. While invasive recordings
have successfully decoded localized neural activity related to grasp type
planning and execution, macroscopic neural activation patterns captured by
noninvasive electroencephalography (EEG) remain far less understood. We
introduce a novel vision-based grasping platform to investigate
grasp-type-specific (precision, power, no-grasp) neural activity across
large-scale brain networks using EEG neuroimaging. The platform isolates
grasp-specific planning from its associated execution phases in naturalistic
visuomotor tasks, where the Filter-Bank Common Spatial Pattern (FBCSP)
technique was designed to extract discriminative frequency-specific features
within each phase. Support vector machine (SVM) classification discriminated
binary (precision vs. power, grasp vs. no-grasp) and multiclass (precision vs.
power vs. no-grasp) scenarios for each phase, and were compared against
traditional Movement-Related Cortical Potential (MRCP) methods. Low-frequency
oscillations (0.5-8 Hz) carry grasp-related information established during
planning and maintained throughout execution, with consistent classification
performance across both phases (75.3-77.8\%) for precision vs. power
discrimination, compared to 61.1\% using MRCP. Higher-frequency activity (12-40
Hz) showed phase-dependent results with 93.3\% accuracy for grasp vs. no-grasp
classification but 61.2\% for precision vs. power discrimination. Feature
importance using SVM coefficients identified discriminative features within
frontoparietal networks during planning and motor networks during execution.
This work demonstrated the role of low-frequency oscillations in decoding grasp
type during planning using noninvasive EEG.

</details>


### [391] [AI Signal Processing Paradigm for Movable Antenna: From Geometric Optimization to Electromagnetic Reconfigurability](https://arxiv.org/abs/2510.19209)
*Yining Li,Ziwei Wan,Chongjia Sun,Kaijun Feng,Keke Ying,Wenyan Ma,Lipeng Zhu,Xiaodan Shao,Zhenyu Xiao,Zhen Gao*

Main category: eess.SP

TL;DR: As 6G evolves, traditional fixed antennas are insufficient. Geometrically movable antennas (GMA) and electromagnetically reconfigurable antennas (ERA) offer dynamic spatial and electromagnetic adjustments, respectively. Integrating them into a movable and reconfigurable antenna (MARA) system presents high-dimensional optimization challenges. This paper proposes a unified MARA framework, investigates channel modeling and spectral efficiency optimization for GMA, ERA, and MARA, and reviews AI-based solutions for these complex optimization problems. It aims to provide a comprehensive review of AI-driven signal processing for dual reconfiguration in 6G systems.


<details>
  <summary>Details</summary>
Motivation: Traditional fixed antennas are limited for 6G systems requiring intelligence and reconfigurability. GMA and ERA offer new degrees of freedom but their integration poses high-dimensional hybrid optimization challenges.

Method: The paper proposes a unified modeling framework for Movable and Reconfigurable Antenna (MARA) systems, integrating geometric optimization of GMA and electromagnetic reconfiguration of ERA. It investigates channel modeling and spectral efficiency optimization for GMA, ERA, and MARA. Additionally, it reviews AI-based solutions for signal processing in this context, analyzing their advantages over traditional algorithms for high-dimensional non-convex optimization.

Result: The paper establishes a unified modeling framework for MARA and investigates channel modeling and spectral efficiency optimization for GMA, ERA, and MARA. It also provides a systematic review of AI-based solutions for the associated signal processing challenges.

Conclusion: This paper addresses the gap in literature concerning AI-driven signal processing for "geometric-electromagnetic dual reconfiguration" in 6G wireless systems, offering theoretical support for designing and optimizing systems with high spectral efficiency and flexibility.

Abstract: As 6G wireless communication systems evolve toward intelligence and high
reconfigurability, the limitations of traditional fixed antenna (TFA) has
become increasingly prominent, with geometrically movable antenna (GMA) and
electromagnetically reconfigurable antenna (ERA) emerging as key technologies
to break through this bottleneck. GMA activates spatial degrees of freedom
(DoF) by dynamically adjusting antenna positions, ERA regulates radiation
characteristics using tunable metamaterials, thereby introducing DoF in the
electromagnetic domain. However, the ``geometric-electromagnetic dual
reconfiguration" paradigm formed by their integration poses severe challenges
of high-dimensional hybrid optimization to signal processing. To address this
issue, we integrate the geometric optimization of GMA and the electromagnetic
reconfiguration of ERA for the first time, propose a unified modeling framework
for movable and reconfigurable antenna (MARA), investigate the channel modeling
and spectral efficiency (SE) optimization for GMA, ERA, and MARA. Besides, we
systematically review artificial intelligence (AI)-based solutions, focusing on
analyzing the advantages of AI over traditional algorithms in high-dimensional
non-convex optimization computations. This paper fills the gap in existing
literature regarding the lack of a comprehensive review on the AI-driven signal
processing paradigm under geometric-electromagnetic dual reconfiguration and
provides theoretical support for the design and optimization of 6G wireless
systems with high SE and flexibility.

</details>


### [392] [Generalized Modified Blake-Zisserman Robust Spline Adaptive Filter for Generalized Gaussian Noise](https://arxiv.org/abs/2510.19256)
*Haiquan Zhao,Bei Xu*

Main category: eess.SP

TL;DR: SAF-GMBZ算法在处理非线性系统辨识中的噪声和异常值问题上表现优于传统SAF算法，而FcGMBZ算法则进一步优化了ANC应用中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的SAF算法在广义高斯噪声和脉冲噪声环境下存在性能下降和稳态失真问题，并且未能有效处理异常值。SAF-GMBZ算法旨在克服这些挑战。

Method: 提出了一种广义改进的Blake-Zisserman鲁棒样条自适应滤波（SAF-GMBZ）算法，并推导了步长和稳态均方误差的均值收敛范围。在此基础上，开发了FcGMBZ算法以应用于ANC系统。

Result: SAF-GMBZ算法在广义高斯噪声环境下展现出优越的学习性能。FcGMBZ算法在脉冲噪声环境下成功应用于ANC应用，并且理论推导的稳态MSE与仿真结果一致。

Conclusion: SAF-GMBZ算法在非线性系统辨识中对噪声和异常值具有鲁棒性，FcGMBZ算法在ANC应用中也表现出有效性。

Abstract: The spline adaptive filtering (SAF) algorithm-based information-theoretic
learning has exhibited strong convergence performance in nonlinear system
identification (NSI), establishing SAF as a promising framework for adaptive
filtering. However, existing SAF-based methods suffer from performance
degradation under generalized Gaussian noise (GGN) environment and exhibit
significant steady-state misalignment under impulse noise. Moreover, prior
research on SAF algorithms has not effectively addressed the adverse effects
caused by outliers. To overcome these challenges, the generalized modified
Blake-Zisserman robust spline adaptive filtering (SAF-GMBZ) algorithm is
proposed. Compared to conventional SAF algorithms, SAF-GMBZ exhibits superior
learning performance in GGN. Furthermore, the mean convergence ranges of the
step-sizes and the steady-state mean-square error (MSE) are calculated by
introducing the commonly utilized assumptions. To arrive at good convergence
accuracy and noise cancellation capability in active noise control (ANC)
application, the filter-c GMBZ (FcGMBZ) algorithm is further developed based on
SAF-GMBZ. Simulation results confirm the accuracy of the theoretical
steady-state MSE, and the superiority of the SAF-GMBZ algorithm under GGN
environment in NSI, along with the effectiveness of the FcGMBZ algorithm in ANC
application under impulsive noise environment.

</details>


### [393] [A Study on Delay Assessment for Heterogenous Traffic in VANET](https://arxiv.org/abs/2510.19267)
*Shama Siddiqu,Indrakshi Dey*

Main category: eess.SP

TL;DR: FROG-MAC通过在传输正常数据包时插入短暂的暂停，从而优先处理紧急流量，从而提高了VANET中紧急消息的延迟和吞吐量。


<details>
  <summary>Details</summary>
Motivation: 为VANET中的多优先级异构节点生成的数据提供基于优先级的服务，特别是解决802.11p协议在处理紧急消息时可能出现的延迟问题。

Method: 比较了802.11p协议和一种基于分片（fragmentation-based）的MAC协议FROG-MAC。通过模拟评估了两种协议在不同优先级数据下的延迟和吞吐量表现。

Result: 模拟结果表明，FROG-MAC协议通过允许紧急流量提前接入信道，在延迟和吞吐量方面均优于802.11p协议。

Conclusion: FROG-MAC协议通过其分片传输机制，能够有效地改善VANET中紧急通信的性能。

Abstract: Vehicular Ad hoc Networks (VANETs) comprise of multi-priority hetero-genous
nodes, both stationary and/or mobile. The data generated by these nodes may
include messages relating to information, safety, entertainment, traffic
management and emergency alerts. The data in the network needs dif-ferentiated
service based on the priority/urgency. Media Access Control (MAC) protocols
hold a significant value for managing the data priority. This paper studies a
comparison of 802.11p which is a standard PHY and MAC protocol for VANET with a
fragmentation-based protocol, FROG-MAC. The major design principle of 802.11-p
is to allow direct Vehicle-to-Vehicle (V2V) and Vehicle-to-Infrastructure (V2I)
communication without associa-tion, using Enhanced Distributed Channel Access
(EDCA) to prioritize safety-critical messages. However, if non-critical
messages already start to transmit, the nodes with critical data have to wait.
FROG-MAC reduces this delay by transmitting normal packets in fragments with
short pauses between them, al-lowing urgent packets to access the channel
during these intervals. Simula-tions have been performed to assess the delay
and throughput for high and low priority data. We report that FROG-MAC improves
both the performance parameters due to offering an early channel access to the
emergency traffic.

</details>


### [394] [IoT-Enabled Sleep Monitoring and Cognitive Assessment for Evaluating Teacher Well-Being](https://arxiv.org/abs/2510.19269)
*Anwar Ahmed Khan,Shama Siddiqui,Mehar Ullah,Indrakshi Dey*

Main category: eess.SP

TL;DR: 该研究利用物联网技术和心理评估问卷，分析了巴基斯坦208名高中教师的睡眠质量和认知功能，发现大部分教师睡眠质量和认知功能不佳，并强调了改善教师工作负荷和福祉以提升教学质量的重要性。


<details>
  <summary>Details</summary>
Motivation: 高中教师因工作压力大、任务繁重，常面临睡眠质量和认知功能下降的问题，这对其教学能力产生负面影响，因此有必要研究其睡眠质量与认知功能的关系。

Method: 使用内置脉搏和血氧饱和度传感器的智能手表收集数据，将睡眠质量分为“差”、“一般”或“好”三类。同时，使用认知评估问卷（CAQ）对教师的认知功能进行自我评估。

Result: 研究发现，大多数高中教师的睡眠质量和认知功能均不佳。睡眠质量与认知功能之间存在关联性。

Conclusion: 教师的工作负荷及其他相关因素亟待改善，以保障其身心健康，进而对教学质量产生积极影响。

Abstract: Sleep quality is an important indicator of the efficient cognitive function
for high school teachers. Due to the high work stress and multi-tasking
expectations, the teachers often face issues with their sleep quality and
cognitive function, which has a clearly negative influence on their teaching
abilities. In this work, we propose a unique but simple method of deploying
Internet of Things (IoT) technology to monitor the sleep quality of high school
teachers at Pakistan. Smart watches embedded with pulse rate and SpO2 sensors
were used to collect data and categorize the sleep quality as "poor", "fair" or
"good". Moreover, we used a psychological tool, Cognitive Assessment
Questionnaire (CAQ) for the self-assessment of teachers' cognitive function.
The study was conducted over 208 high school teachers from across Pakistan. It
has been found that most of the teachers had a poor sleep quality and cognitive
function; The link between these two variables indicate that the workload and
other factors must be improved for the teachers to ensure their well-being,
which will in turn have a positive impact on their teaching quality.

</details>


### [395] [Neuromorphic computing for anomaly detection in a laser powder bed fusion process](https://arxiv.org/abs/2510.19309)
*Shreyan Banerjee,Aasifa Rounak,Cathal Hoare,Denis Dowling,Vikram Pakrashi*

Main category: eess.SP

TL;DR: 本研究首次将脉冲神经网络（SNNs）应用于激光粉末床熔融（LPBF）增材制造过程中的异常检测，利用光电二极管传感器监测熔池变化，并通过调整脉冲延迟优化了检测精度，最终证明了低功耗神经形态芯片在边缘计算框架下进行增材制造异常检测的可行性。


<details>
  <summary>Details</summary>
Motivation: 在激光粉末床熔融（LPBF）增材制造过程中，由于激光能量下降等原因产生的打印异常会影响产品质量，需要有效的检测方法。

Method: 研究采用了脉冲神经网络（SNNs）来识别LPBF过程中因激光能量下降引起的打印异常。通过光电二极管传感器监测与激光照射相关的熔池变化。该算法分别在CPU、FPGA和英特尔Loihi神经形态芯片上进行了实现。通过调整神经网络的脉冲延迟来提高异常检测的精度。

Result: 通过调整脉冲延迟，成功减少了噪声对时间信号的干扰，提高了异常检测的准确性。研究证明了在增材制造中，使用低功耗神经形态芯片构建边缘计算框架进行异常检测是可行的。

Conclusion: 本研究成功将SNNs应用于LPBF增材制造的异常检测，并通过优化脉冲延迟提高了检测效果。研究表明，低功耗神经形态芯片可以集成到边缘计算框架中，为增材制造提供实时、高效的异常检测解决方案。

Abstract: This study is the first application of spiking neural networks (SNNs) for
anomaly detection in the Laser Powder Bed Fusion (LPBF) additive manufacturing
process. The neural networks were used to identify print processing anomalies
generated by dropping of laser energy during the printing of individual layers
in a Ti-6Al-4V alloy lattice structures. Associated changes in the laser
generated melt pool were observed using an in-process photodiode monitoring
technique. photodiode sensors capturing plasma and infrared radiations
reflected from the print bed of the metal 3D printer were utilized to detect
sudden changes caused by anomalies during the printing process. The algorithm
is first implemented on non-neuromorphic hardware including a central
processing unit (CPU), on Field Programmable Gate Arrays (FPGA) and then on
neuromorphic Intel's Loihi chip. Improved detection of anomalies is achieved by
adjusting the spike latency of the neural network, which reduces masking of
information by noise within the monitored temporal signal. The work
demonstrates the possibility of using low-power neuromorphic chips within an
edge framework for anomaly detection in additive manufacturing and creates a
framework for the process.

</details>


### [396] [Multi-code rate Task-Oriented Communication for Multi-Edge Cooperative Inference](https://arxiv.org/abs/2510.19360)
*Dongwon Kim,Jiwan Seo,Joonhyuk Kang*

Main category: eess.SP

TL;DR: AI与物联网结合的边缘计算系统面临隐私和带宽挑战，提出率自适应量化（RAQ）和动态规划（DP）框架，通过根据特征重要性动态调整量化率和分配码率，提高了通信效率和推理性能。


<details>
  <summary>Details</summary>
Motivation: 边缘计算系统在AI与物联网结合的场景下，面临隐私泄露和通信带宽限制的挑战，现有的固定压缩率传输方式效率低下。

Method: 提出率自适应量化（RAQ）方案，根据特征对下游推理任务的重要性动态调整量化率；利用动态规划（DP）方法在有限带宽下为各边缘设备分配码率。

Result: 实验证明，所提出的框架在多视图数据集上显著优于固定率量化框架，在有限带宽下实现了通信效率和推理性能的良好平衡。

Conclusion: 所提出的率自适应量化（RAQ）和动态规划（DP）框架能够有效解决AI与物联网结合的边缘计算系统中的通信资源利用率和隐私问题，在保证推理性能的同时显著提高通信效率。

Abstract: The integration of artificial intelligence (AI) with the internet of things
(IoT) enables task-oriented communication for multi-edge cooperative inference
system, where edge devices transmit extracted features of local sensory data to
an edge server to perform AI-driven tasks. However, the privacy concerns and
limited communication bandwidth pose fundamental challenges, since simultaneous
transmission of extracted features with a single fixed compression ratio from
all devices leads to severe inefficiency in communication resource utilization.
To address this challenge, we propose a framework that dynamically adjusts the
code rate in feature extraction based on its importance to the downstream
inference task by adopting a rate-adaptive quantization (RAQ) scheme.
Furthermore, to select the code rate for each edge device under limited
bandwidth constraint, a dynamic programming (DP) approach is leveraged to
allocate the code rate across discrete code rate options. Experiments on
multi-view datasets demonstrate that the proposed frameworks significantly
outperform the frameworks using fixed-rate quantization, achieving a favorable
balance between communication efficiency and inference performance under
limited bandwidth conditions.

</details>


### [397] [Ray-Tracing Based Narrow-Beam Channel Simulation, Characterization and Performance Evaluation for 5G-R Systems](https://arxiv.org/abs/2510.19401)
*Tao Zhou,Liying Geng,Yiqun Liang,Kaifeng Bao,Tianyun Feng,Liu Liu,Bo Ai*

Main category: eess.SP

TL;DR: 本文研究了基于射线追踪（RT）仿真的5G高铁（5G-R）系统的窄波束信道特性和性能评估。


<details>
  <summary>Details</summary>
Motivation: 为了研究5G-R系统在高铁环境下的信道特性和性能，需要进行窄波束信道特性和性能评估。

Method: 通过射线追踪（RT）仿真，建立三种典型高铁（HSR）场景（高架桥、隧道、车站），并设计波束跟踪方案进行动态窄波束信道仿真。分析了路径损耗、阴影衰落、衰落严重程度、时频空散射和非平稳性等信道特性，并研究了波束宽度对信道特性的影响。使用维也纳5G仿真器评估了5G-R系统的性能，并搭建了硬件在环仿真平台。

Result: 仿真结果揭示了5G-R系统在高铁环境下的窄波束信道特性，并评估了其性能。

Conclusion: 研究结果为5G-R系统在高铁环境下的设计和优化提供了有价值的指导。

Abstract: This paper investigates narrow-beam channel characterization and performance
evaluation for 5G for railway (5G-R) systems based on ray-tracing (RT)
simulation. Three representative high-speed railway (HSR) scenarios including
viaduct, cutting, and station are established, and RT-based dynamic narrow-beam
channel simulations are conducted using a designed beam tracking scheme that
ensures continuous alignment with the moving train. The channel characteristics
are analyzed in terms of both large-scale and small-scale fading, as well as
non-stationarity, providing statistical insights into path loss, shadow fading,
fading severity, time-frequency-space dispersion, and stationarity interval.
The influence of beamwidth on these channel properties is also examined.
Furthermore, the performance of 5G-R systems operating in such narrow-beam
channels is evaluated using the Vienna 5G simulator, with a focus on block
error rate, throughput, and spectral efficiency. A hardware-in-the-loop
simulation platform is developed to further assess synchronization signal
reference signal received power, signal-to-interference-plus-noise ratio, and
reference signal received quality. The results provide valuable guidance for
the design and optimization of 5G-R systems in HSR environments.

</details>


### [398] [A Novel Delay-Doppler Domain Channel Sounding Method for 6G High-Mobility Scenarios](https://arxiv.org/abs/2510.19402)
*Kaifeng Bao,Tao Zhou,Chaoyi Li,Liu Liu,Bo Ai*

Main category: eess.SP

TL;DR: 本文提出了一种用于6G高移动性场景的新型时延-多普勒（DD）域信道探测方法，解决了传统方法无法直接获取多普勒信息的问题。


<details>
  <summary>Details</summary>
Motivation: 高移动性场景下6G通信系统设计和传输技术应用需要精确的信道测量，但传统时域或频域信道探测方法无法直接获取多普勒信息。

Method: 设计了新的探测信号波形，并详细阐述了DD域信道探测方法（包括同步和CSF估计），同时提出了一种提高测量精度的算法。

Result: 建立了适用于6G高移动性场景的DD域信道探测系统，并进行了城市车辆-基础设施场景的信道测量，获得了CSF、功率延迟剖面、多普勒功率谱密度、多径分量数量等信息。

Conclusion: 提出的DD域信道探测方法被测量结果证实有效，为6G高移动性通信的研究提供了有价值的见解。

Abstract: Channel measurements are the prerequisite for applying emerging transmission
technologies and designing communication systems. In sixth-generation (6G)
system, conventional time or frequency domain channel sounding methods cannot
directly obtain Doppler information induced by high-mobility scenarios. The
channel spreading function (CSF) simultaneously captures delay and Doppler
information, while naturally characterizing the propagation environment in the
delay-Doppler (DD) domain. However, DD domain channel sounding methods remain
underexplored. This paper presents a novel DD domain channel sounding method
for 6G high-mobility scenarios. First, we introduce the waveform design for the
sounding signal and analyze its sounding capability. Next, the methodology of
DD domain channel sounding, including synchronization and CSF estimation, is
thoroughly detailed. Additionally, an algorithm for enhancing measurement
precision is proposed. The performance of the proposed method is rigorously
evaluated. Subsequently, a DD domain channel sounding system competent for 6G
high-mobility scenarios is established. Finally, DD domain channel measurements
are conducted for a vehicle-to-infrastructure scenario in urban environments.
Measurement results, including CSF, power delay profile, Doppler power spectral
density, number of multipath components, and other characteristics, are
derived, which confirm the effectiveness of the proposed method and offer
helpful insights for advancing research on 6G high-mobility communications.

</details>


### [399] [Network-Centric Anomaly Filtering and Spoofer localization for 5G-NR Localization in LAWNs](https://arxiv.org/abs/2510.19521)
*Zexin Fang,Bin Han,Zhu Han,Hans D. Schotten*

Main category: eess.SP

TL;DR: 本论文研究了低空城市环境下基于5G-NR TDoA的无人机定位的安全漏洞和对策，提出了一种优化的节点选择策略和轻量级的UE辅助方法，并通过合并峰值欺骗攻击暴露了安全漏洞。研究人员还提出了一个网络中心化的异常检测框架和鲁棒的定位算法来解决这些漏洞，该框架能够同时进行受害者和欺骗者的定位。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是解决在低空城市环境中，基于3GPP 5G-NR TDoA的无人机（UAV）定位所面临的安全漏洞，并提出相应的对策。

Method: 研究方法包括：1. 优化了在空对地（A2G）信道条件下的节点选择策略；2. 提出了轻量级的用户设备（UE）辅助方法；3. 引入了合并峰值欺骗攻击（merged-peak spoofing attacks）来暴露安全漏洞；4. 通过理论建模和敏感性分析量化了欺骗攻击的成功概率；5. 设计了一个网络中心化的异常检测框架（在LMF处）和一个基于递归梯度下降的鲁棒定位算法。

Result: 研究结果表明：1. 节点选择的最优性取决于无人机的高度和部署密度；2. 所提出的UE辅助方法可以减少开销并提高精度；3. 合并峰值欺骗攻击能够绕过现有的检测方法；4. 同步质量和几何因素决定了欺骗攻击的成功概率；5. 所提出的网络中心化异常检测框架和鲁棒定位算法能够有效地进行受害者和欺骗者的定位。

Conclusion: 本研究提出的优化和安全机制能够有效地解决3GPP合规的无人机定位中的安全漏洞，并提高了定位的鲁棒性和准确性。该框架同时实现了受害者和欺骗者的定位，这是现有技术所缺乏的。

Abstract: This paper investigates security vulnerabilities and countermeasures for 3rd
Generation Partnership Project (3GPP) Fifth Generation New Radio (5G-NR) Time
Difference of Arrival (TDoA)-based unmanned aerial vehicle (UAV) localization
in low-altitude urban environments. We first optimize node selection strategies
under Air to Ground (A2G) channel conditions, proving that optimal selection
depends on UAV altitude and deployment density. We propose lightweight User
Equipment (UE)-assisted that reduce overhead while enhancing accuracy. We then
expose critical security vulnerabilities by introducing merged-peak spoofing
attacks where rogue UAVs transmit multiple lower-power pulses that merge with
legitimate signals, bypassing existing detection methods. Through theoretical
modeling and sensitivity analysis, we quantify how synchronization quality and
geometric factors determine spoofing success probability, revealing fundamental
weaknesses in current 3GPP positioning frameworks. To address these
vulnerabilities, we design a network-centric anomaly detection framework at the
Localization Management Function (LMF) using existing 3GPP-specified
parameters, coupled with a recursive gradient descent-based robust localization
algorithm that filters anomaly data while estimating UAV position. Our unified
framework simultaneously provides robust victim localization and spoofer
localization-capabilities not integrated in existing literature. Extensive
simulations validate the effectiveness of both optimization and security
mechanisms for 3GPP-compliant UAV positioning.

</details>


### [400] [On the Robustness of AFDM and OTFS Against Passive Eavesdroppers](https://arxiv.org/abs/2510.19525)
*Vincent Savaux,Hyeon Seok Rou,Zeping Sui,Giuseppe Thadeu Freitas de Abreu,Zilong Liu*

Main category: eess.SP

TL;DR: AFDM和OTFS波形在面对无先验信息的暴力破解窃听者时，AFDM比OTFS更具鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究AFDM和OTFS波形在面对无先验信息的被动窃听者进行暴力破解解调时的鲁棒性。

Method: 通过分析和比特错误率（BER）仿真来评估AFDM和OTFS的鲁棒性，其中窃听者对AFDM的啁波参数或OTFS的延迟-多普勒网格配置一无所知，必须穷举搜索可能的解调矩阵。

Result: 分析结果表明，OTFS的暴力破解复杂度为O(sqrt(N))，AFDM为O(N^2)，其中N是子载波数量。BER仿真证实了分析结果，显示AFDM在窃听者那里几乎不可解码，而OTFS在相同条件下允许部分信号恢复。

Conclusion: AFDM相比OTFS具有更优越的鲁棒性，能够更好地抵抗无先验信息的暴力破解窃听。

Abstract: We investigate the robustness of affine frequency division multiplexing
(AFDM) and orthogonal time frequency space (OTFS) waveforms against passive
eavesdroppers performing brute-force demodulation to intercepted signals, under
the assumption that eavesdroppers have no knowledge of chirp parameters (in
AFDM) or the delay-Doppler grid configuration (in OTFS), such that they must
search exhaustively over possible demodulation matrices. Analytical results
show that the brute-force complexity scales as $\mathcal{O}(\sqrt{N})$ for OTFS
and $\mathcal{O}(N^2)$ for AFDM, where $N$ is the number of subcarriers,
indicating that AFDM has superior resilience over OTFS. Bit error rate (BER)
simulations confirm the analysis by showing that, with AFDM, the signal remains
nearly undecodable at the eavesdropper, while OTFS allows partial signal
recovery under equivalent conditions.

</details>


### [401] [Multilayer Perceptron Neural Network Model: A Novel Approach for LFP Contrast Sensitivity Tuning](https://arxiv.org/abs/2510.19636)
*Sahar Maleki,Reza Lashgari,Mahdi Aliyari Shoorehdeli,Mohammad Komareji*

Main category: eess.SP

TL;DR: 该研究提出并比较了用于分析局部场电位（LFP）对比度反应函数（CRF）的新模型，发现多层感知器（MLP）神经网络在拟合LFP数据方面优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 局部场电位（LFP）的反应参数通常比棘波（spike）更弱、更宽，因此需要选择优化的调谐方法来准确评估LFP反应并与棘波活动进行比较。

Method: 通过分析灵长类动物初级视觉皮层（V1）中记录的由亮度对比度诱发的LFP反应，提出新的CRF模型。使用单调性指数（MI）区分超饱和CRF与线性/饱和CRF。然后，使用包括MLP、RBF神经网络、模糊模型、神经模糊模型和LOLIMOT算法在内的多种静态识别方法来识别超饱和记录数据。

Result: 结果表明，与传统的和改进的双曲奈奎斯特-鲁斯顿函数相比，MLP神经网络在调谐LFP对亮度对比度刺激的反应方面表现出更优越的性能，成功调谐了更高比例的所有三种类型的神经记录。

Conclusion: MLP神经网络模型可以作为一种新颖的方法，比目前使用的其他模型提供更好的神经元群体对比度敏感度调谐曲线。

Abstract: Local field potentials (LFPs) have been demonstrated to be an important
measurement to study the activity of a local population of neurons. The
response tunings of LFPs have been mostly reported as weaker and broader than
spike tunings. Therefore, selecting optimized tuning methods is essential for
appropriately evaluating the LFP responses and comparing them with neighboring
spiking activity. In this paper, new models for tuning of the contrast response
functions (CRFs) are proposed. To this end, luminance contrast-evoked LFP
responses recorded in primate primary visual cortex (V1) are first analyzed.
Then, supersaturating CRFs are distinguished from linear and saturating CRFs by
using monotonicity index (MI). The supersaturated recording data are then
identified through static identification methods including multilayer
perceptron (MLP) neural network, radial basis function (RBF) neural network,
fuzzy model, neuro-fuzzy model, and the local linear model tree (LOLIMOT)
algorithm. Our results demonstrate that the MLP neural network, compared to
traditional and modified hyperbolic Naka-Rushton functions, exhibits superior
performance in tuning the local field potential responses to luminance contrast
stimuli, resulting in successful tuning of a significantly higher number of
neural recordings of all three types. These results suggest that the MLP neural
network model can be used as a novel approach to measure a better fitted
contrast sensitivity tuning curve of a population of neurons than other
currently used models.

</details>


### [402] [Micro-Doppler Energy-Based Robust Multi-Target Vital Signs Monitoring Using 77-GHz FMCW Radar with Spatiotemporal Adaptive Processing](https://arxiv.org/abs/2510.19639)
*Chenxing Tan,Yuguan Hou,Hao Wang,Zhonghao Yuan*

Main category: eess.SP

TL;DR: 该研究提出了一种基于微多普勒能量的雷达框架，用于在有噪声和运动干扰的情况下，监测多目标的生命体征。


<details>
  <summary>Details</summary>
Motivation: 传统基于相位的方法在监测多目标生命体征时，容易受到环境噪声、身体随机移动和校准要求的限制，因此需要一种更鲁棒的方法。

Method: 该研究提出了一种利用雷达回波中的能量变化来监测生命体征的方法。该系统包括空间-时间自适应处理（STAP）用于目标检测和跟踪，MUSIC算法用于高分辨率角度估计，以及一种创新的自适应频谱滤波技术用于提取生命体征。该方法通过微多普勒能量提取来克服相位噪声和运动伪影。

Result: 该系统能够准确检测和分离最多四个目标（5米范围内）的生命体征，平均呼吸和心率的绝对误差分别为1.2次/分钟和2.3次/分钟。

Conclusion: 提出的基于微多普勒能量的方法在多目标生命体征监测方面比传统基于相位的方法表现更好，尤其是在存在环境噪声和目标移动的情况下。

Abstract: This paper presents a novel micro-Doppler energy-based framework for robust
multi-target vital signs monitoring using 77-GHz Frequency-Modulated
Continuous-Wave (FMCW) radar. Unlike conventional phase-based methods that are
susceptible to environmental noise, random body movements, and stringent
calibration requirements, our approach exploits the energy variations in radar
returns induced by cardiopulmonary activities. The proposed system integrates a
comprehensive processing pipeline including space-time adaptive processing
(STAP) for target detection and tracking, MUSIC algorithm for high-resolution
angle estimation, and an innovative adaptive spectral filtering technique for
vital signs extraction. We establish a rigorous mathematical framework that
formalizes the relationship between micro-Doppler energy variations and
physiological activities, enabling robust separation of closely spaced targets.
The key innovation lies in the micro-Doppler energy extraction methodology that
provides inherent robustness to phase noise and motion artifacts. Experimental
results using millimeter-wave radar datasets demonstrate that the system can
accurately detect and separate vital signs of up to four targets within
\SI{5}{\meter} range, achieving mean absolute errors of \SI{1.2}beats per
minute and \SI{2.3} beats per minute for respiration and heart rates,
respectively. The proposed approach demonstrates superior performance compared
to traditional phase-based methods, particularly in challenging multi-target
scenarios with environmental noise and subject movement.

</details>


### [403] [Interpretable machine learning for cardiogram-based biometrics](https://arxiv.org/abs/2510.19775)
*Ilija Tanasković,Ljiljana B. Lazarević,Goran Knežević,Nikola Milosavljević,Olga Dubljević,Bojana Bjegojević,Nadica Miljković*

Main category: eess.SP

TL;DR: ECG和ICG特征在生物识别中具有区分能力，其中ECG特征（特别是QRS相关特征）最为关键，ICG特征（特别是BCX特征）提供补充但不太稳定的线索，情感变化对QRS特征影响不大。


<details>
  <summary>Details</summary>
Motivation: 研究ECG和ICG特征在生物识别中的区分能力和对情绪变化的鲁棒性。

Method: 使用随机森林模型和多种可解释性方法，评估29个特征，并进行特征选择和相关性分析。

Result: ECG特征（特别是QRS相关特征）在重要性排序中名列前茅，ICG BCX特征提供补充信息但稳定性较低。特征相关性分析显示存在多重共线性。14个特征在基线和愤怒情绪下存在显著差异。特征选择后，14个特征达到了接近全特征集的准确率（99%）。

Conclusion: 可靠的身份识别主要依赖于QRS相关的ECG特征，而ICG BCX特征通过幅度提供支持性线索。QRS相关特征对情绪变化的鲁棒性表明其在未来心电图身份识别模型中的核心作用。

Abstract: This study investigates the role of electrocardiogram (ECG) and impedance
cardiogram (ICG) features in biometric identification, emphasizing their
discriminative capacity and robustness to emotional variability. A total of 29
features spanning four domains (temporal, amplitude, slope, and morphological)
are evaluated using random forest (RF) models combined with multiple
interpretability methods. Feature importance shows that both ECG- and
ICG-derived features are consistently ranked among the top 10 by Gini
importance, permutation importance, and SHAP values, with ECG features,
particularly QRS-centric descriptors, occupying the highest positions. In
parallel, ICG BCX features contribute complementary, however, with lower
cross-method stability. Correlation analysis reveals substantial
multicollinearity, where the RF distributes and diminishes importance across
highly correlated pairs, confirming reduced independent contributions.
Statistical analysis identifies 14 features with significant differences
between baseline and anger, without a clear pattern by domain. Feature
selection with recursive feature elimination and genetic algorithms converges
on a subset (14 features) that attains accuracy within 1% of the full set
(99%), improving efficiency in storage and computation. These complementary
analyses indicate that the individuality required for reliable identification
is primarily encoded in QRS-related ECG features across all four domains.
Meanwhile, BCX-derived ICG features contribute mainly through amplitude,
providing supportive but less stable discriminatory cues. The confirmed
resilience of QRS-centric descriptors to emotional variation, where stable
inter-individual differences in the QRS complex could be traced to variations
in ventricular mass, conduction pathways, and thoracic geometry, may indicate
their central role in future models of cardiogram-based identity.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [404] [Decoding optoelectronic behavior in X$_3$BI$_3$ antiperovskite derivatives through many-body perturbation theory](https://arxiv.org/abs/2510.19029)
*Ayan Chakravorty,Surajit Adhikari,Priya Johari*

Main category: cond-mat.mtrl-sci

TL;DR: X3BI3类材料具有直接带隙和适度的激子结合能，载流子-声子耦合较弱，可用于光电器件。


<details>
  <summary>Details</summary>
Motivation: 探索X3BI3（X = Ca, Sr; B = P, As, Sb, Bi）衍生物的激子和极化子性质，这些性质对光电器件性能至关重要，但由于计算成本高而未得到充分研究。

Method: 使用第一性原理计算研究了一系列X3BI3衍生物的结构、电子、光学、激子和极化子性质。

Result: 所有化合物均表现出2.42至3.02 eV的直接带隙。激子结合能为0.258-0.318 eV，表明载流子-声子耦合较弱至中等，极化子迁移率高达37.19 cm2V-1s-1。

Conclusion: X3BI3材料因其优异的光电性能，是下一代光电器件的有力候选者。

Abstract: Antiperovskite derivatives have emerged as promising candidates for
optoelectronic applications. However, due to the significant computational
cost, their excitonic and polaronic properties remain underexplored despite
being critical for optoelectronic performance. Here, we present the structural,
electronic, optical, excitonic, and polaronic properties of a series of
antiperovskite derivatives with the chemical formula X$_{3}$BI$_{3}$ (X = Ca,
Sr; B = P, As, Sb, Bi) using state-of-the-art first-principles calculations.
All the compounds exhibit direct bandgaps with G$_{0}$W$_{0}$@PBE bandgap
ranging from 2.42 to 3.02 eV, optimal for efficient light absorption with
minimal energy loss. Exciton binding energies (0.258-0.318 eV) indicate
moderate Coulomb attraction, favoring exciton dissociation. Employing the
Feynman polaron model, we established the polaronic properties, where weak to
intermediate carrier-phonon coupling was observed, with polaron mobilities
reaching values up to 37.19 cm$^{2}$V$^{-1}$s$^{-1}$. These properties
establish X$_{3}$BI$_{3}$ materials as viable candidates for next-generation
optoelectronic devices.

</details>


### [405] [First-principles calculation of electronic and topological properties of low-dimensional tellurium](https://arxiv.org/abs/2510.19079)
*Gabriel Elyas Gama Araujo,Andreia Luisa da Rosa*

Main category: cond-mat.mtrl-sci

TL;DR: 第一性原理密度泛函理论研究了不同维度碲的结构、热力学、电子和拓扑性质，发现三维碲-I是窄带隙半导体，具有拓扑韦尔节点；一维碲纳米线也表现出韦尔节点特征；二维碲单层是拓扑平庸的，但可以通过外部扰动诱导拓扑相变，有望用于工程韦尔相。碲及其低维衍生物是具有手性和对称性破缺特性的多功能材料，在下一代电子和光电子技术中具有应用潜力。


<details>
  <summary>Details</summary>
Motivation: 研究不同维度碲的结构、热力学、电子和拓扑性质，探索其作为拓扑材料的应用潜力。

Method: 使用第一性原理密度泛函理论（DFT）研究了块状三方碲（Te-I）、二维（2D）单层 $\alpha$-Te、$\beta$-Te 和一维（1D）螺旋纳米线（Te-h）的性质。

Result: 发现二维相倾向于结构畸变或相变；三维 Te-I 是窄带隙半导体，在布里渊区高对称性位置具有拓扑韦尔节点；一维 Te-h 纳米线也表现出韦尔节点特征，在 SOC 下具有可观的能量隙；二维 $\alpha$-Te 和 $\beta$-Te 是拓扑平庸的，但有望通过外部扰动诱导拓扑相变。

Conclusion: 碲及其低维衍生物是多功能材料，表现出与手性和对称性破缺相关的广泛电子和声子现象，其可调的电子和拓扑性质使其成为探索和应用韦尔物理的有希望的材料平台。

Abstract: We employ first-principles density-functional theory to investigate the
structural, thermodynamic, electronic, and topological properties of tellurium
in its various dimensional forms: bulk trigonal tellurium (Te-I),
two-dimensional (2D) monolayers $\alpha$-Te, $\beta$-Te and one-dimensional
helical nanowire (Te-h). A softening of the acoustic phonon modes is seen in
most of the 2D phases, suggesting a tendency to structural distortions or phase
transitions under small perturbations. The trigonal 3D Te-I structure is
characterized as a narrow-gap semiconductor hosting Weyl nodes at high-symmetry
locations in the Brillouin zone, which is supported by the characteristic spin
texture seen in momentum space, where spins align radially, forming Berry
monopoles. This topological feature, along with the observation of Weyl phonons
is attributed to inversion symmetry breaking and strong SOC. Ultrathin Te-h
nanowires also exhibit signatures of Weyl nodes and presents a considerable
energy gap under SOC. On the other hand, the two-dimensional monolayers
$\alpha$-Te, $\beta$-Te, are classified as topologically trivial, as indicated
by their topological invariants, which arises from the preservation of both
spatial inversion and time-reversal symmetries in these systems. The potential
for inducing topological phase transitions via external perturbations suggest
that these monolayers are promising candidates for engineered Weyl phases or
other topological states. We demonstrate that tellurium and its low-dimensional
derivatives are versatile materials that exhibit a broad range of electronic
and phononic phenomena intrinsically linked to chirality and symmetry breaking.
The tunability of their electronic and topological properties places tellurium
as a promising material platform for the exploration and application of Weyl
physics in next-generation electronic and optoelectronic technologies.

</details>


### [406] [Transient Absorption Spectroscopy of NbOI$_2$](https://arxiv.org/abs/2510.19188)
*Salman Ahsanullah,Neema Rafizadeh,Hui Zhao*

Main category: cond-mat.mtrl-sci

TL;DR: NbOI2材料的光载流子动力学特性未被充分探索，本研究使用瞬态吸收光谱技术进行了深入分析。


<details>
  <summary>Details</summary>
Motivation: NbOI2材料结合了半导体特性、铁电性和优异的输运及光学各向异性，但其光载流子动力学特性仍有待探索。

Method: 利用飞秒泵浦探测反射光谱技术，研究NbOI2材料的瞬态吸收光谱。

Result: 在2.34 eV的激子共振附近观察到显著的瞬态吸收特征，该特征源于光载流子引起的激子能量移动和饱和。激子寿命约为数十皮秒，且表现出与激子-激子湮灭相关的密度依赖行为，湮灭系数为0.09 cm$^2$ s$^{-1}$。偏振分辨测量进一步揭示了瞬态响应中与线性吸收各向异性一致的显著面内各向异性。

Conclusion: 本研究为理解NbOI2的光载流子动力学提供了基础性见解，并确立了理解和利用其光电特性的关键参数。

Abstract: NbOI$_2$ has recently emerged as a new van der Waals material combining
semiconducting behavior with intrinsic in plane ferroelectricity and pronounced
transport and optical anisotropy. However, its photocarrier dynamics remain
largely unexplored. Here we report transient absorption spectroscopy of
NbOI$_2$ using femtosecond pump probe reflectance measurements. A pronounced
transient absorption feature is observed near the 2.34 eV excitonic resonance,
arising from photocarrier induced excitonic energy shifts and saturation. The
decay dynamics reveal an exciton lifetime of several tens of picoseconds and
show density-dependent behavior consistent with exciton exciton annihilation,
yielding an annihilation coefficient of 0.09 cm$^2$ s$^{-1}$, which is
comparable to that in monolayer transition metal dichalcogenides. Polarization
resolved measurements further reveal a pronounced in-plane anisotropy in the
transient response that follows the linear absorption anisotropy. These
findings provide fundamental insight into photocarrier dynamics in NbOI$_2$ and
establish key parameters for understanding and exploiting its optoelectronic
behavior.

</details>


### [407] [High-Efficiency Nonrelativistic Charge-Spin Conversion in X-Type Antiferromagnets](https://arxiv.org/abs/2510.19194)
*Jiabin Wang,Wancheng Zhang,Yong Liu,Rui Xiong,Zhenhua Zhang,Zhihong Lu*

Main category: cond-mat.mtrl-sci

TL;DR: X型反铁磁体在特定晶向比 the altermagnets 产生更高效的 T 奇自旋流，效率高达 90%，为低功耗自旋电子器件提供新思路。


<details>
  <summary>Details</summary>
Motivation: 旨在发现比 the altermagnets 产生更高效 T 奇自旋流的材料。

Method: 提出X型反铁磁体，并研究其在(110)-取向的 $eta-\mathrm{Fe}_2\mathrm{PO}_5$ 中的费米面特性、自旋流产生效率以及与 the altermagnets、铁磁体等的比较。

Result: X型反铁磁体在特定晶向（如(110)-取向的 $\beta-\mathrm{Fe}_2\mathrm{PO}_5$）能产生高效的 T 奇自旋流，电荷-自旋转换效率高达 90%，且优于已知的铁磁体、the altermagnets 等材料。

Conclusion: X型反铁磁体是一种高效的电荷-自旋转换材料，为开发低功耗自旋电子器件提供了新的途径。

Abstract: Altermagnets have attracted considerable interest for their capacity to
generate spin splitting while preserving zero net magnetization. This work
proposes a distinct class of antiferromagnetic materials, termed X-type
antiferromagnets, which are shown to produce more efficient $\cal T$-odd spin
currents than altermagnets along specific crystallographic directions due to
their unique Fermi surface geometry. The spin current polarization is
controlled by the N\'eel vector orientation. In the (110)-oriented
$\beta-\mathrm{Fe}_2\mathrm{PO}_5$, the Fermi surface exhibits a $d$-wave
altermagnetic-like characteristic and becomes compressed into an approximately
X-shaped $d$-wave configuration, yielding highly efficient $\cal T$-odd spin
currents with a charge-to-spin conversion efficiency reaching 90%. Moreover,
when the N\'eel vector is tilted via unit cell selection or external means, the
system generates out-of-plane spin-polarized currents with efficiencies
substantially exceeding those of known ferromagnets, altermagnets, noncollinear
antiferromagnets, and low-symmetry materials. The highly efficient charge-spin
conversion in X-type antiferromagnets provides a novel and highly effective
spin source system for the development of low-power spintronic devices.

</details>


### [408] [Synthesizability Prediction of Crystalline Structures with a Hierarchical Transformer and Uncertainty Quantification](https://arxiv.org/abs/2510.19251)
*Danial Ebrahimzadeh,Sarah Sharif,Yaser Mike Banad*

Main category: cond-mat.mtrl-sci

TL;DR: SyntheFormer是一个预测无机晶体可合成性的模型，结合了傅里叶变换晶体周期性表示、分层特征提取、随机森林特征选择和深度MLP分类器。该模型在2011-2018年的历史数据上训练，并在2019-2025年的未来数据上进行前瞻性评估。


<details>
  <summary>Details</summary>
Motivation: 加速材料发现，解决预测哪些假设的无机晶体可以被实验实现的挑战。

Method: 使用正负样本不平衡学习框架，直接从晶体结构学习可合成性。结合了傅里叶变换晶体周期性（FTCP）表示、分层特征提取、随机森林特征选择和紧凑的深度MLP分类器。

Result: 在2019-2025年的前瞻性评估中，SyntheFormer达到了0.735的测试ROC曲线下面积。通过双阈值校准，在94.2%的覆盖率下实现了97.6%的召回率，最大限度地减少了错失机会，同时保持了判别能力。该模型能够识别出实验上已证实的亚稳态化合物，并为许多热力学稳定但未合成的候选物分配了低分。

Conclusion: SyntheFormer通过将结构感知表示与不确定性感知决策规则相结合，为优先合成目标和将实验室精力集中在最有希望的新型无机材料上提供了一条实用的途径。仅靠稳定性不足以预测实验可获得性。

Abstract: Predicting which hypothetical inorganic crystals can be experimentally
realized remains a central challenge in accelerating materials discovery.
SyntheFormer is a positive-unlabeled framework that learns synthesizability
directly from crystal structure, combining a Fourier-transformed crystal
periodicity (FTCP) representation with hierarchical feature extraction,
Random-Forest feature selection, and a compact deep MLP classifier. The model
is trained on historical data from 2011 through 2018 and evaluated
prospectively on future years from 2019 to 2025, where the positive class
constitutes only 1.02 per cent of samples. Under this temporally separated
evaluation, SyntheFormer achieves a test area under the ROC curve of 0.735 and,
with dual-threshold calibration, attains high-recall screening with 97.6 per
cent recall at 94.2 per cent coverage, which minimizes missed opportunities
while preserving discriminative power. Crucially, the model recovers
experimentally confirmed metastable compounds that lie far from the convex hull
and simultaneously assigns low scores to many thermodynamically stable yet
unsynthesized candidates, demonstrating that stability alone is insufficient to
predict experimental attainability. By aligning structure-aware representation
with uncertainty-aware decision rules, SyntheFormer provides a practical route
to prioritize synthesis targets and focus laboratory effort on the most
promising new inorganic materials.

</details>


### [409] [Exciton thermal radiation from structure-sorted carbon nanotube membranes](https://arxiv.org/abs/2510.19387)
*Akiteru Takahashi,Kaichi Teranishi,Shonosuke Takaichi,Taishi Nishihara,Yuhei Miyauchi*

Main category: cond-mat.mtrl-sci

TL;DR: 宏观尺度的单壁碳纳米管（SWCNT）组件在传导加热下表现出激子热辐射，这得益于其在高温下稳定的激子共振。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨宏观尺度的SWCNT组件是否能在传导加热下发出激子热辐射，并阐明其在选择性热辐射和能量收集方面的应用潜力。

Method: 通过实验观察，并结合透射光谱和绝对发射光谱，研究了在850 K高温下，结构排序的SWCNT薄膜的激子热辐射特性。

Result: 研究观察到结构排序的SWCNT薄膜在传导加热下表现出激子热辐射。透射光谱显示在高温下存在稳定的激子共振，这导致了清晰的激子共振热辐射带。在850 K下测量的绝对发射光谱显示，激子主导了吸收/发射光谱，抑制了自由载流子在光学带隙以下的红外吸收/发射。

Conclusion: 结构排序的SWCNT薄膜在高温下表现出稳定的激子共振，能够抑制自由载流子的贡献，从而在红外吸收/发射光谱中保持透明性。这些特性在块状半导体中未被观察到，凸显了SWCNT薄膜作为独特半导体的潜力。

Abstract: Owing to their small binding energies, excitons in bulk semiconductors
typically exhibit a sharp optical peak at low temperatures only. This
limitation can be overcome by single-walled carbon nanotubes (SWCNTs) and other
low-dimensional semiconductors with highly enhanced exciton binding energies.
Exciton thermal radiation, which can potentially be exploited for selective
thermal emission and energy harvesting, has been recently observed in
individual SWCNTs heated under photoirradiation. However, whether
macroscale-SWCNT assemblies can emit exciton thermal radiation under conduction
heating remains unclear and constitutes an important challenge for practical
applications. Herein, we observed peaked exciton thermal radiation from
structure-sorted SWCNT membranes. Transmission spectroscopy showed robust
exciton resonance at high temperatures, resulting in clear exciton resonance in
the thermal radiation band. The absolute emissivity spectra of the membranes
were determined at 850 K. Exciton dominance suppresses the contribution of
thermal free carriers to the infrared absorption/emission spectra, maintaining
the transparency below the optical gap even at elevated temperatures. These
phenomena are not observed in bulk semiconductors, highlighting the
structure-sorted SWCNT membranes as unique semiconductors leveraging stable
exciton resonances at elevated temperatures.

</details>


### [410] [Synergistic effects of rare-earth doping on the magnetic properties of orthochromates: A machine learning approach](https://arxiv.org/abs/2510.19391)
*Guanping Xu,Zirui Zhao,Muqing Su,Hai-Feng Li*

Main category: cond-mat.mtrl-sci

TL;DR: 使用卷积神经网络预测和分析稀土铬酸盐（RECrO3）的物理性质，并探讨了掺杂对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 稀土铬酸盐（RECrO3）因其独特的磁电特性而备受关注，但掺杂对其性质的影响研究不足。

Method: 使用卷积神经网络（CNN）结合实验和文献数据，预测稀土铬酸盐的Néel温度（TN）、剩余极化（Pr）和压电系数（d33）。

Result: 掺杂特定稀土元素可显著影响TN，并确定了最佳掺杂水平。高熵RECrO3化合物的分析表明，多种稀土元素的加入会影响磁性。

Conclusion: 该研究为预测和优化RECrO3材料的性质提供了一个强大的框架，为在储能和传感器技术中的应用提供了有价值的见解。

Abstract: Multiferroic materials, particularly rare-earth orthochromates (RECrO$_3$),
have garnered significant interest due to their unique magnetic and
electric-polar properties, making them promising candidates for multifunctional
devices. Although extensive research has been conducted on their
antiferromagnetic (AFM) transition temperature (N$\acute{\textrm{e}}$el
temperature, $T_\textrm{N}$), ferroelectricity, and piezoelectricity, the
effects of doping and substitution of rare-earth (RE) elements on these
properties remain insufficiently explored. In this study, convolutional neural
networks (CNNs) were employed to predict and analyze the physical properties of
RECrO$_3$ compounds under various doping scenarios. Experimental and literature
data were integrated to train machine learning models, enabling accurate
predictions of $T_\textrm{N}$, besides remanent polarization ($P_\textrm{r}$)
and piezoelectric coefficients ($d_{33}$). The results indicate that doping
with specific RE elements significantly impacts $T_\textrm{N}$, with optimal
doping levels identified for enhanced performance. Furthermore, high-entropy
RECrO$_3$ compounds were systematically analyzed, demonstrating how the
inclusion of multiple RE elements influences magnetic properties. This work
establishes a robust framework for predicting and optimizing the properties of
RECrO$_3$ materials, offering valuable insights into their potential
applications in energy storage and sensor technologies.

</details>


### [411] [Spin injection and emission helicity switching in a 2D perovskite/WSe2 heterostructure](https://arxiv.org/abs/2510.19447)
*Jakub Jasinski,Francesco Gucci,Thomas Brumme,Swaroop Palai,Armando Genco,Alessandro Baserga,Jonas D. Ziegler,Takashi Taniguchi,Kenji Watanabe,Mateusz Dyksik,Christoph Gadermaier,Michal Baranowski,Duncan K. Maude,Alexey Chernikov,Giulio Cerullo,Agnieszka Kuc,Stefano Dal Conte,Paulina Plochocka,Alessandro Surrente*

Main category: cond-mat.mtrl-sci

TL;DR: 论文演示了在 (BA)2PbI4/WSe2 异质结构中，通过调节 WSe2 单层激子共振能量和异质结构中出现的层间吸收特征，可以控制圆偏振的层间激子发射的螺旋度。


<details>
  <summary>Details</summary>
Motivation: 实现长寿命自旋种群的初始化和控制，以应用于自旋电子学。

Method: 通过实验和理论计算，研究 (BA)2PbI4/WSe2 单层异质结构中层间激子发射的圆偏振及其螺旋度控制。

Result: 成功展示了 (BA)2PbI4/WSe2 异质结构中层间激子发射的圆偏振，并实现了对发射螺旋度的调控。理论计算表明，这种效应源于杂化的 (BA)2PbI4/WSe2 价带态。

Conclusion: 论文提出的可调谐自旋极化为二维钙钛矿在光自旋电子学应用中的使用奠定了重要基础。

Abstract: The initialization and control of a long-lived spin population in lead halide
perovskites are prerequisites for their use in spintronic applications. Here,
we demonstrate circular polarization of the interlayer exciton emission in a
(BA)2PbI4/WSe2 monolayer heterostructure. The helicity of this emission is
controlled by tuning the energy of the excitation laser through the manifold of
exciton resonances of the WSe2 monolayer, together with an emerging interlayer
absorption feature of the heterostructure. Theoretical calculations show that
this resonance arises from hybridized (BA)2PbI4/WSe2 states in the valence
band. This hybrid character enables its observation in both linear absorption
and ultrafast pump-probe spectroscopies, and plays a key role in controlling
the sign of the helicity of the interlayer exciton emission. The tunable spin
polarization demonstrated here, with the WSe2 monolayer effectively acting as a
tunable spin filter, represents an important step toward the use of 2D
perovskites in opto-spintronic applications.

</details>


### [412] [Active high-entropy photocatalyst designed by incorporating alkali metals to achieve d0+d10+s0 cationic configurations and wide electronegativity mismatch](https://arxiv.org/abs/2510.19486)
*Jacqueline Hidalgo-Jimenez,Taner Akbay,Tatsumi Ishihara,Kaveh Edalati*

Main category: cond-mat.mtrl-sci

TL;DR: 通过在过渡金属基催化剂中引入低电负性和高电负性元素，提高光催化产氢和二氧化碳转化效率。


<details>
  <summary>Details</summary>
Motivation: 光催化制氢和CO2制甲烷是减少CO2排放的有效方法，但需要高活性的光催化剂。

Method: 将低电负性的铯和高电负性的镓添加到钛、铌、钽基高熵氧化物（HEO）中，形成TiNbTaGaCsO9，并引入大量氧空位。

Result: 所合成的氧化物具有强光吸收、窄带隙和合适的能带结构，在无助催化剂的情况下，表现出比仅含d0或d0+d10阳离子构型的高熵氧化物更高的H2和CH4产率。

Conclusion: 通过利用周期表中不同电负性元素的失配，可以设计出含有碱金属的高活性HEO催化剂。

Abstract: Photocatalytic hydrogen (H2) production and carbon dioxide (CO2) conversion
to methane (CH4) are considered promising solutions for reducing CO2 emissions.
However, the development of highly active photocatalysts is essential to
efficiently drive these reactions without harming the environment. In this
study, we introduce a strategy that incorporates elements with both low and
high electronegativities into catalysts based on transition metals, thereby
enhancing both reactant adsorption and charge transfer. This strategy is
implemented in a high-entropy oxide (HEO) by adding cesium, an alkali metal
with very low electronegativity, and gallium, a metal with high
electronegativity, to transition metals titanium, niobium and tantalum. The
resulting oxide, TiNbTaGaCsO9 with a large concentration of oxygen vacancies,
exhibits strong light absorption, a low bandgap and a suitable band structure
for both hydrogen evolution and CO2 conversion. Compared to HEOs with only d0
or d0+d10 cationic configurations, the synthesized oxide with a wide
electronegativity difference and mixed d0+d10+s0 cationic configurations shows
significantly higher activity for both H2 and CH4 production, even without
using a cocatalyst. These results demonstrate a design strategy for creating
highly active HEOs containing alkali metals by taking advantage of the
electronegativity mismatch across the periodic table.

</details>


### [413] [Intrinsic nonlinear Hall effect beyond Bloch geometry](https://arxiv.org/abs/2510.19515)
*Raffaele Resta*

Main category: cond-mat.mtrl-sci

TL;DR: 论文的核心思想是，在考虑了无序和相互作用之后，需要一个新的量子几何学来描述本征霍尔效应，而不是依赖于传统的布洛赫矢量参数空间。


<details>
  <summary>Details</summary>
Motivation: 在考虑无序和相互作用时，传统的布洛赫矢量参数空间不再适用，需要更通用的量子几何学来描述本征霍尔效应。

Method: 提出了一种新的量子几何学，在不同的参数空间中定义，并推导了本征霍尔效应的紧凑表达式。

Result: 新的几何学方法能够简洁地表达本征霍尔效应，并且在布洛赫特例中能够直接得到已知结果，使得推导过程更加清晰。

Conclusion: 这种新的量子几何学方法为理解和计算本征霍尔效应提供了一个更强大、更简洁的框架。

Abstract: The theory of the intrinsic Hall effect, both linear and nonlinear, is rooted
in a geometry which is defined in the Bloch-vector parameter space; the formal
expressions are mostly derived from semiclassical concepts. When disorder and
interaction are considered there is no Bloch vector to speak of; one needs a
more general quantum geometry, defined in a different parameter space. Such
higher-level geometrical formulation of the intrinsic Hall effect provides very
compact expressions, which have the additional virtue -- in the Bloch special
case -- of yielding the known results in a straightforward way: the logic is
not concealed by the algebra.

</details>


### [414] [Atomic displacements drive flat band formation and lateral electron and hole separation in near-60 degree twisted MoSe2/WSe2 bilayers](https://arxiv.org/abs/2510.19596)
*Madeleine Phillips,C. Stephen Hellberg*

Main category: cond-mat.mtrl-sci

TL;DR: 扭转的TMD双层结构会产生摩尔超晶胞，影响结构和电子性质，并可能形成包含相关电子态的平带。通过从头密度泛函理论计算，我们发现近60度扭转的MoSe2/WSe2双层结构在约3度扭转时会出现价带和导带平带。这种结构重构会产生极化梯度，形成限制势，从而在摩尔超胞内局部化和横向分离电子-空穴对。因此，由平带电子和空穴形成的激子不仅具有熟悉的层间激子平面外偶极矩，还应具有平面内偶极矩。


<details>
  <summary>Details</summary>
Motivation: 理解双层过渡金属二卤化物（TMD）中层间扭转的影响，特别是其对结构和电子性质的潜在影响，以及是否会形成可能支持相关电子态的平带。

Method: 使用从头密度泛函理论（DFT）来模拟近60度扭转的MoSe2/WSe2双层结构，重点关注约3度扭转角附近的电子结构和原子位移。

Result: 在近60度扭转的MoSe2/WSe2双层结构中，发现了在约3度扭转角附近出现的价带和导带平带。尽管原子重构有限，但发现原子位移产生了极化梯度，形成了一个限制势，该势能够定域化电子-空穴对，并将它们在摩尔超胞内横向分离。

Conclusion: 近60度扭转的MoSe2/WSe2双层结构在特定扭转角下会出现平带，并且原子位移诱导的极化会导致电子和空穴的分离，从而产生具有平面内偶极矩的激子。

Abstract: Transition metal dichalcogenide (TMD) bilayers with an interlayer twist
exhibit a moire super-period, whose effects can manifest in both structural and
electronic properties. Atomic displacements can lead to reconstruction into
domains of aligned stacking, and flat bands can form that may host correlated
electron states. In heterobilayers angular mismatch is nearly unavoidable, so
understanding the consequences of an interlayer twist is essential. Using ab
initio density functional theory, we find that in near-60 degree twisted
MoSe2/WSe2 bilayers valence and conduction band flat bands emerge at ~3 degree
twist. Despite relatively limited reconstruction at these angles, atomic
displacement creates a polarization gradient that forms a confining potential,
localizing and laterally separating electrons and holes within the moire
supercell. Excitons formed from flat band electrons and holes should therefore
have not only the out-of-plane dipole moment familiar from MoSe2/WSe2
interlayer excitons, but an in-plane dipole moment as well.

</details>


### [415] [DFT-informed Design of Radiation-Resistant Dilute Ternary Cu Alloys](https://arxiv.org/abs/2510.19638)
*Vaibhav Vasudevan,Thomas Schuler,Pascal Bellon,Robert Averback*

Main category: cond-mat.mtrl-sci

TL;DR: 通过添加抑制空位迁移率并促进空位-间隙原子复合的溶质，建立了一个用于设计耐辐射、稀释的三元铜基合金的系统性、高通量计算框架。


<details>
  <summary>Details</summary>
Motivation: 开发可以通过添加溶质来抵抗辐射的合金，但需要克服空位介导的溶质拖曳效应。

Method: 通过密度泛函理论（DFT）筛选了21对协同溶质，并使用动力学团簇扩展（KineCluE）方法在辐照条件下模拟了Cu(Zr,Co)和Cu(Zr,Fe)合金的扩散和溶质拖曳。

Result: 研究发现，Zr-C之间的强热力学结合，特别是Zr和Co之间，显著降低了Zr溶质的迁移率，并抑制了空位介导的溶质拖曳。空位-Zr-Co三元组通过提高空位从溶质分离的势垒，破坏了促进二元合金溶质拖曳的动力学回路。

Conclusion: 通过结合两种类型的溶质（强空位结合能的A类溶质和与A类溶质结合且扩散缓慢的B类溶质），成功克服了空位介导的溶质拖曳效应，为设计耐辐射合金提供了新方法。

Abstract: This research establishes a systematic, high-throughput computational
framework for designing radiation-resistant, dilute ternary copper-based alloys
by addition of solutes that bind to vacancies and reduce their mobility, thus
promoting interstitial-vacancy recombination. The first challenge in developing
alloys by this method is mitigating the vacancy-mediated solute drag effect,
since density functional theory (DFT) calculations show that solutes that bind
strongly to vacancies are also rapidly dragged to point-defect sinks, and thus
removed from the matrix. To overcome this issue, two types of solutes are added
to the Cu matrix: A first solute with a strong vacancy binding energy (B-type
species) and another solute that binds to 'B' and is a slow diffuser in Cu
(C-type species). Using DFT, 21 synergistic solute pairs are screened, with
'B'=Zr, Ge, Sn and 'C'=Fe, Co, Mo, Ni, Nb, W, Cr. Two promising alloys,
Cu(Zr,Co) and Cu(Zr,Fe) are then investigated in detail in the dilute regime.
Diffusion and solute drag in these alloys are modeled using the kinetic cluster
expansion approach (KineCluE) under irradiation conditions. It is shown that
strong Zr-'C' thermodynamic binding, especially between Zr and Co,
significantly reduces the mobility of Zr solute and suppresses the
vacancy-mediated solute drag. Using an analytical framework for the standard
five-jump frequency model for diffusion in binary alloys, it is found that
vacancy-Zr-Co triplets disrupt the kinetic circuits that promote solute drag in
the binary alloy by raising the dissociation barrier for the vacancy from the
solute.

</details>


### [416] [Dara: Automated multiple-hypothesis phase identification and refinement from powder X-ray diffraction](https://arxiv.org/abs/2510.19667)
*Yuxing Fei,Matthew J. McDermott,Christopher L. Rom,Shilong Wang,Gerbrand Ceder*

Main category: cond-mat.mtrl-sci

TL;DR: Dara是一个自动化框架，用于从粉末X射线衍射数据中识别和精炼多相晶体材料，通过详尽的树搜索和Rietveld精炼来提高准确性并支持可扩展分析。


<details>
  <summary>Details</summary>
Motivation: XRD模式解析，特别是在多相体系中，通常需要手动操作和专业知识，并且可能存在多种拟合解，导致潜在的误解。本研究旨在减轻人工负担并解决这一挑战。

Method: Dara框架通过在给定的化学空间内对所有合理的相组合进行详尽的树搜索，并使用BGMN的Rietveld精炼程序验证每个假设来自动化多相识别和精炼过程。其特点包括结构数据库过滤、等结构相的自动聚类以及基于峰匹配的评分。

Result: Dara能够自动化地识别和精炼多相XRD数据，提高可靠性和准确性，并能处理复杂的XRD模式。在存在歧义时，Dara会生成多个假设供专家或进一步的表征工具进行判断。

Conclusion: Dara通过增强相识别的可靠性和准确性，实现了对复杂XRD模式的可扩展分析，为整合到多模式表征流程和推动全自动材料发现奠定了基础。

Abstract: Powder X-ray diffraction (XRD) is a foundational technique for characterizing
crystalline materials. However, the reliable interpretation of XRD patterns,
particularly in multiphase systems, remains a manual and expertise-demanding
task. As a characterization method that only provides structural information,
multiple reference phases can often be fit to a single pattern, leading to
potential misinterpretation when alternative solutions are overlooked. To ease
humans' efforts and address the challenge, we introduce Dara (Data-driven
Automated Rietveld Analysis), a framework designed to automate the robust
identification and refinement of multiple phases from powder XRD data. Dara
performs an exhaustive tree search over all plausible phase combinations within
a given chemical space and validates each hypothesis using a robust Rietveld
refinement routine (BGMN). Key features include structural database filtering,
automatic clustering of isostructural phases during tree expansion,
peak-matching-based scoring to identify promising phases for refinement. When
ambiguity exists, Dara generates multiple hypothesis which can then be decided
between by human experts or with further characteriztion tools. By enhancing
the reliability and accuracy of phase identification, Dara enables scalable
analysis of realistic complex XRD patterns and provides a foundation for
integration into multimodal characterization workflows, moving toward fully
self-driving materials discovery.

</details>


### [417] [Opto-electronic and kinetic properties of defect states in FA0.7Cs0.3Pb(I0.9Br0.1)3 thin films](https://arxiv.org/abs/2510.19712)
*L. Kopprio,J. Caram,S. Le Gall,F. Ventosinos,L. Gil-Escrig,H. J. Bolink,C. Longeaud,J-P. Kleider,J. Schmidt*

Main category: cond-mat.mtrl-sci

TL;DR: 尽管钙钛矿太阳能电池在效率和稳定性方面取得了显著进展，但其潜在的缺陷机制仍不清楚。本研究结合了热导纳谱（TAS）和侧向光电导方法（SSPC和SSPG），用于表征FA$_{0.7}$Cs$_{0.3}$Pb(I$_{0.9}$Br$_{0.1}$)$_3$薄膜中的缺陷动力学和电学性质。


<details>
  <summary>Details</summary>
Motivation: 解决钙钛矿太阳能电池中未明确的缺陷机制问题，特别是那些在电场作用下迁移的带电缺陷。

Method: 结合使用热导纳谱（TAS）、热稳态光电流（SSPC）和稳态光载流子光栅（SSPG）技术。

Result: 结果表明，实验现象与以下模型一致：晶格缺陷导致的指数带尾态、导带下方0.21 eV处的受主类高斯分布，以及浓度近似相等的施主和受主（1.7x10^17 cm^-3）。其中一种掺杂剂在室温下的迁移率为（0.5-1）x10^-7 cm^2 V^-1 s^-1，热活化能为0.28-0.40 eV。

Conclusion: 本研究通过综合运用多种谱学和光电导方法，阐明了FA$_{0.7}$Cs$_{0.3}$Pb(I$_{0.9}$Br$_{0.1}$)$_3$钙钛矿薄膜中的缺陷性质，包括带尾态、高斯分布缺陷以及掺杂剂的迁移率和活化能，为进一步提升钙钛矿太阳能电池性能提供了重要依据。

Abstract: Despite the remarkable success in increasing the efficiency and stability of
perovskite solar cells over the last decade, the underlying defect landscape of
halide perovskites remains unclear. Some charged defects in perovskites migrate
in response to an applied electric field, which complicates their
characterization with standard techniques. We combine thermal admittance
spectroscopy (TAS) with lateral photoconductivity-based methods, such as the
thermal steady-state photocurrent (SSPC) and the steady-state photocarrier
grating (SSPG), to estimate the kinetic and electrical properties of defects in
thin films of vacuum-deposited FA$_{0.7}$Cs$_{0.3}$Pb(I$_{0.9}$Br$_{0.1}$)$_3$
perovskite. The experimental results are consistent with exponential band tails
states coming from the lattice disorder, an acceptor-like Gaussian distribution
0.21~eV below the conduction band and approximately equal concentrations of
donors and acceptors ($1.7\times10^{17}$ cm$^{-3}$). One of the dopants has
room temperature mobility of $(0.5{-}1)\times10^{-7}$ cm$^2$ V$^{-1}$ s$^{-1}$
with a thermal activation energy of 0.28--0.40 eV.

</details>


### [418] [Accelerating Moment Tensor Potentials through Post-Training Pruning](https://arxiv.org/abs/2510.19737)
*Zijian Meng,Karim Zongo,Matthew Thoms,Ryan Eric Grant,Laurent Karim Béland*

Main category: cond-mat.mtrl-sci

TL;DR: 通过移除昂贵的基函数来加速MTP模型


<details>
  <summary>Details</summary>
Motivation: 标准的MTP基函数选择方案不考虑成本，导致模型可能包含冗余的昂贵基函数，影响效率。

Method: 提出一种后训练、成本感知的剪枝策略，移除对精度影响最小的昂贵基函数。

Result: 在镍和硅-氧体系上，新方法 yielded models up to seven times faster than standard MTPs。

Conclusion: 所提出的剪枝策略能有效提高MTP模型的速度，且与现有实现兼容，无需新数据。

Abstract: Moment Tensor Potentials (MTPs) are machine-learning interatomic potentials
whose basis functions are typically selected using a level-based scheme that is
data-agnostic. We introduce a post-training, cost-aware pruning strategy that
removes expensive basis functions with minimal loss of accuracy. Applied to
nickel and silicon-oxygen systems, it yields models up to seven times faster
than standard MTPs. The method requires no new data and remains fully
compatible with current MTP implementations.

</details>


### [419] [Hexa-Graphyne: A Transparent and Semimetallic 2D Carbon Allotrope with Distinct Optical Properties](https://arxiv.org/abs/2510.19795)
*Jhionathan de Lima,Cristiano Francisco Woellner*

Main category: cond-mat.mtrl-sci

TL;DR: Hexa-graphyne (HXGY) 是一种稳定的新型碳同素异形体，具有独特的机械、光学和电子特性，有望用于纳米电子和光电子应用。


<details>
  <summary>Details</summary>
Motivation: 研究和评估新型碳同素异形体 Hexa-graphyne (HXGY) 的稳定性、力学、光学和电子特性，探索其在纳米电子和光电子领域的应用潜力。

Method: 使用第一性原理计算来研究 HXGY 的能量、动力学和热力学稳定性，并分析其带结构、机械性能（杨氏模量和泊松比）、光学响应（紫外吸收、红外反射、可见光透射率）以及拉曼和红外光谱。此外，还研究了 HXGY 纳米带的电子行为。

Result: HXGY 被证实具有高能量、动力学和热力学稳定性（高达 1000 K）。它是一种具有独特光学特性的半金属材料，在紫外区域有强吸收，在红外区域有高反射，在可见光区域透明。HXGY 的杨氏模量比石墨烯低约 13 倍，泊松比高约 4 倍。其拉曼和红外光谱显示出清晰的乙炔键伸缩振动信号。源自 HXGY 的纳米带表现出取决于边缘类型和宽度的不同电子行为。

Conclusion: HXGY 是一种稳定且具有优异性能的新型碳材料，其独特的机械、光学和电子特性使其在纳米电子和光电子器件领域具有巨大的应用潜力。

Abstract: Herein, we conduct a comprehensive investigation of Hexa-graphyne (HXGY), a
planar carbon allotrope formed by distorted hexagonal and rectangular rings
incorporating sp and sp$^2$-hybridized carbon atoms. First-principles
calculations confirm its energetic, dynamical and thermal stability (up to at
least 1000 K). Regarding its band structure, this material exhibits a
semimetallic nature. It exhibits high mechanical compliance, with a Young's
modulus approximately 13 times lower and a Poisson's ratio nearly 4 times
higher than those of graphene. The optical response is marked by strong
ultraviolet absorption, high infrared reflectivity, and pronounced transparency
in the visible-light range. Raman and infrared spectra exhibit sharp and
well-separated peaks, providing a clear signature of acetylenic linkage
stretching vibrations. Nanoribbon structures derived from HXGY show distinct
electronic behaviors depending on the edge termination type and width. These
findings highlight the HXGY potential for nanoelectronic and optoelectronic
applications.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [420] [Visually Comparing Graph Vertex Ordering Algorithms through Geometrical and Topological Approaches](https://arxiv.org/abs/2510.19009)
*Karelia Salinas,Victor Barella,Thales Viera,Luis Gustavo Nonato*

Main category: cs.GR

TL;DR: Graph vertex ordering methods are crucial for spatial data analysis and visualization, particularly in urban analytics. Existing global quality metrics hinder the identification of localized distortions. This paper presents a visualization-assisted tool to address this limitation, integrating existing and new metrics to evaluate ordering techniques on urban street graphs. The tool helps users select methods, tune hyperparameters, and identify regions with high ordering distortions, validated through experiments on real-world city data.


<details>
  <summary>Details</summary>
Motivation: Existing metrics for assessing spatial vertex ordering focus on global quality, which hinders the identification of localized distortions, especially in urban analytics where understanding spatial inconsistencies is crucial. Visual evaluation is valuable for comparing methods, assessing distortions, and explaining spatial inconsistencies.

Method: The paper presents a visualization-assisted tool for assessing vertex ordering techniques. This tool integrates existing and newly proposed metrics and is evaluated using urban street graphs, focusing on geometric and topological ordering approaches. Experiments were conducted on data from multiple cities.

Result: The proposed methodology effectively supports users in selecting suitable vertex ordering techniques, tuning hyperparameters, and identifying regions with high ordering distortions. The visual tool integrates metrics and has been validated through experiments on urban street graph data from multiple cities.

Conclusion: The visualization-assisted tool effectively addresses the limitations of existing global quality metrics by allowing for visual evaluation of localized distortions in graph vertex ordering, proving valuable for applications in urban analytics and supporting users in selecting and refining ordering techniques.

Abstract: Graph vertex ordering is widely employed in spatial data analysis, especially
in urban analytics, where street graphs serve as spatial discretization for
modeling and simulation. It is also crucial for visualization, as many methods
require vertices to be arranged in a well-defined order to reveal non-trivial
patterns. The goal of vertex ordering methods is to preserve neighborhood
relations, but the structural complexity of real-world graphs often introduces
distortions. Comparing different ordering methods is therefore essential to
identify the most suitable one for each application. Existing metrics for
assessing spatial vertex ordering typically focus on global quality, which
hinders the identification of localized distortions. Visual evaluation is
particularly valuable, as it allows analysts to compare methods within a single
visualization, assess distortions, identify anomalous regions, and, in urban
contexts, explain spatial inconsistencies. This work presents a
visualization-assisted tool for assessing vertex ordering techniques, with a
focus on urban analytics. We evaluate geometric and topological ordering
approaches using urban street graphs. The visual tool integrates existing and
newly proposed metrics, validated through experiments on data from multiple
cities. Results demonstrate that the proposed methodology effectively supports
users in selecting suitable vertex ordering techniques, tuning hyperparameters,
and identifying regions with high ordering distortions.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [421] [Experimental and numerical simulation study on the thermal performance of building envelope structures incorporating the solid-solid phase change material](https://arxiv.org/abs/2510.18883)
*Qiong Ye,L Ba,G T M Nguyen,R Absi,B A Ledésert,G Dosseh,R L Hebert*

Main category: physics.app-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This work is an experimental and numerical study of the thermal performance
of building envelope structures incorporating a solid-solid phase change
material (S-S PCM), consisting in a cross-linked polyurethane designated as
PUX-1500-20. This S-S PCM is capable of storing and releasing thermal energy
via phase transitions within the human comfort temperature range, facilitating
the temporal and spatial transfer of solar energy for optimizing energy
efficiency. The primary aim of this work is to integrate the S-S PCM into
hollow bricks used in building envelopes and to evaluate their thermal inertia
through both experimental testing and numerical simulation. The experimental
results demonstrate that the integration of the PCM effectively delays and
decreases the indoor temperature peak. The simulation results also show that
the incorporation of the S-S PCM into hollow bricks gives rise to a phase shift
of 7 hours and a decrement factor of 0.38. In comparison with the thermal
behavior of the building envelopes (hollow brick) without PCMs, our results
provide convincing evidence of the important thermal inertia of these
structures incorporating the PCMs, revealing their significant potential in
reducing energy consumption of building.

</details>


### [422] [Active tuning of ENZ resonances in meta-antenna through phase modulation of optical pulse](https://arxiv.org/abs/2510.19065)
*Elif Ozturk,Hira Asif,Mehmet Gunay,Mehmet Emre Tasgin,Ramazan Sahin*

Main category: physics.app-ph

TL;DR: L形等离激元纳米天线在epsilon-near-zero（ENZ）响应方面表现出增强的折射率，并通过控制脉冲相位进行调谐，可用于光子集成电路和量子技术。


<details>
  <summary>Details</summary>
Motivation: 利用等离激元纳米天线在近场增强和超快响应方面的特性，研究其在epsilon-near-zero（ENZ）响应方面的行为。

Method: 采用量子力学方法分析探针场的调制和ENZ频率区域的出现，并使用3D FDTD模拟来验证光谱移动。

Result: 实现了L形纳米天线结构的ENZ响应，并通过控制脉冲相位实现了ENZ频率区域的主动调谐，光谱显示出显著的ENZ模式移动。

Conclusion: 所提出的方法可以在等离离子体超表面中设计和控制光学可调谐的ENZ响应，而无需使用ENZ材料，有望应用于光子集成电路、场局域化、慢光操作和量子技术。

Abstract: Plasmonic nanoantennas offer new avenues to manipulate the propagation of
light in materials due to their near field enhancement and ultrafast response
time. Here we investigate the epsilon-near-zero (ENZ) response in an L-shaped
nanoantenna structure under the phenomenon of plasmonic analog of enhancement
in the index of refraction. Using a quantum mechanical approach, we analyze the
modulation in the response of probe field and emergence of ENZ frequency region
both in the linear and nonlinear plasmonic system. We also demonstrate the
active tuning of ENZ frequency region in a nanoantenna structure by modulating
the phase of control pulse. The analytical and 3D FDTD simulation results show
a significant spectral shift in the ENZ modes. Our proposed method offers the
possibility to design and control optical tunable ENZ response in plasmonic
metasurfaces without the use of ENZ material. Such metasurfaces can be used in
on-chip photonic integrated circuits, further localization of incident fields,
slow light operations and various quantum technologies.

</details>


### [423] [Magnetic field estimation using Gaussian process regression for interactive wireless power system design](https://arxiv.org/abs/2510.19277)
*Yuichi Honjo,Cedric Caremel,Ken Takaki,Yuta Noma,Yoshihiro Kawahara,Takuya Sasatani*

Main category: physics.app-ph

TL;DR: 机器学习用于无线能量传输中的电磁场和效率的快速估算。


<details>
  <summary>Details</summary>
Motivation: 传统的电磁场模拟方法计算成本高，限制了对无线能量传输系统（特别是动态应用）的交互式设计和探索。需要一种更快速的方法来估算磁场和功率传输效率，以应对系统几何形状的快速变化和复杂结构（如铁磁屏蔽）。

Method: 提出了一种基于高斯过程回归（GPR）的机器学习方法，并结合了3D自适应网格系统和主动学习策略，以实现对近场耦合系统中复杂系统几何形状与磁场之间非线性相互作用的快速准确估算。

Result: 所提出的机器学习方法可以在亚秒级延迟内计算磁场，与独立的电磁模拟结果相比，平均误差小于6%。

Conclusion: 该机器学习方法能够快速准确地估算近场耦合系统的磁场和功率传输效率，为无线能量传输的交互式设计提供了高效的解决方案。

Abstract: Wireless power transfer (WPT) with coupled resonators offers a promising
solution for the seamless powering of electronic devices. Interactive design
approaches that visualize the magnetic field and power transfer efficiency
based on system geometry adjustments can facilitate the understanding and
exploration of the behavior of these systems for dynamic applications. However,
typical electromagnetic field simulation methods, such as the Method of Moments
(MoM), require significant computational resources, limiting the rate at which
computation can be performed for acceptable interactivity. Furthermore, the
system's sensitivity to positional and geometrical changes necessitates a large
number of simulations, and structures such as ferromagnetic shields further
complicate these simulations. Here, we introduce a machine learning approach
using Gaussian Process Regression (GPR), demonstrating for the first time the
rapid estimation of the entire magnetic field and power transfer efficiency for
near-field coupled systems. To achieve quick and accurate estimation, we
develop 3D adaptive grid systems and an active learning strategy to effectively
capture the nonlinear interactions between complex system geometries and
magnetic fields. By training a regression model, our approach achieves magnetic
field computation with sub-second latency and with an average error of less
than 6% when validated against independent electromagnetic simulation results.

</details>


### [424] [T2 mapping at 0.55 T using Ultra-Fast Spin Echo MRI](https://arxiv.org/abs/2510.19680)
*Margaux Roulet,Hamza Kebiri,Busra Bulut,Vladyslav Zalevskyi,Thomas Sanchez,Jean-Baptiste Ledoux,Vincent Dunet,Mériam Koob,Tom Hilbert,Tobias Kober,Erick J Canales-Rodriguez,Meritxell Bach Cuadra*

Main category: physics.app-ph

TL;DR: 低场T2图谱MRI可普及儿科神经影像，提高可及性并提供脑发育的定量生物标志物。


<details>
  <summary>Details</summary>
Motivation: 评估在0.55T下使用单次快速自旋回波（SS-FSE）序列进行高分辨率T2图谱的可行性，以用于健康对照队列。

Method: 在体外使用NIST模型评估可行性，并将T2弛豫时间与0.55T下的光谱仪参考值进行比较。在体外优化采集和T2拟合参数后，将其应用于体内研究。通过对白质（WM）和皮层灰质（GM）区域进行基于图谱的分析来评估可重复性，并计算跨运行、跨会话和跨受试者的变异系数（CoV）。

Result: 在体外，高斯-瑞西恩噪声下的单指数拟合偏差<12%。在体内，受试者间的CoV为5.2%（WM）和17.7%（GM），与1.5T相当。在0.55T下，平均T2时间为118毫秒（WM）和188毫秒（GM），采集时间为16.5分钟。

Conclusion: 提出了一种在0.55T下使用高斯噪声拟合的快速、稳健的高分辨率HASTE MRI T2图谱方案。报告了0.55T下健康成人大脑的首次规范T2值，证明了技术可行性和可靠性。

Abstract: Low-field T2 mapping MRI can democratize neuropediatric imaging by improving
accessibility and providing quantitative biomarkers of brain development.
\textbf{Purpose:} To evaluate the feasibility of high-resolution T2 mapping
using a single-shot fast spin-echo (SS-FSE) sequence at 0.55~T in a healthy
control cohort. \textbf{Study Type:} Prospective single-center study.
\textbf{Population:} In vivo: ten healthy adults (18--43~years, 5 females/5
males). In vitro: NIST Phantom. \textbf{Field strength/sequence:} Multi-echo
ultra-fast spin-echo at 0.55~T and 1.5~T. \textbf{Assessment:} Feasibility was
first assessed in vitro using the NIST Phantom, comparing T2 relaxation times
to spectrometer references at 0.55~T. Acquisition and T2-fitting parameters
optimized in vitro were applied in vivo. Repeatability was evaluated by
atlas-based analysis of white matter (WM) and cortical grey matter (GM)
regions. Coefficients of variation (CoV) were computed across runs, sessions,
and subjects. \textbf{Statistical Tests:} Wilcoxon signed-rank test with
Bonferroni correction ($\alpha = 0.05/n_{ROI}$) assessed CoV differences.
Pearson correlation coefficients quantified T2 associations. \textbf{Results:}
In vitro, mono-exponential fitting under Gaussian--Rician noise yielded
deviations $<12\%$ from reference values. In vivo, inter-subject CoV was 5.2\%
(WM) and 17.7\% (GM), comparable to 1.5~T. Mean T2 times were 118~ms (WM) and
188~ms (GM) at 0.55~T, with a 16.5-minute acquisition. \textbf{Conclusion:} A
rapid, robust high-resolution T2 mapping protocol at 0.55~T for HASTE MRI is
presented, employing Gaussian noise-based fitting. We report the first
normative T2 values for healthy adult brains at 0.55~T, demonstrating technical
feasibility and reliability.

</details>


### [425] [Dynamic control of dipole decay rate via graphene plexcitons](https://arxiv.org/abs/2510.19396)
*Hira Asif,Taner Tarik Aytas,Ramazan Sahin*

Main category: physics.app-ph

TL;DR: 通过电压调控石墨烯-激子复合腔的激子偶极子衰减率，实现了光子发射的可控。


<details>
  <summary>Details</summary>
Motivation: 实现量子发射体的辐射特性（特别是偶极子衰减率）的主动控制，以用于开发可重构的光子器件。

Method: 在强耦合区域，利用石墨烯球壳和量子点耦合形成的复合腔（plexcitonic modes），通过施加电压改变复合腔的局域光学响应，从而调控量子点偶极子的衰减率。

Result: 实现了偶极子发射率的连续可调，能够显著增强或抑制发射，范围覆盖近到远红外区域。复合腔的谱线比纯石墨烯等离激元更窄，即使在失谐耦合下也表现出更高的灵敏度。

Conclusion: 该方法提供了一个可编程的发射控制平台，为开发可调谐单光子源和超快光开关等可重构量子光子器件提供了新途径。

Abstract: Active control of the radiative properties of quantum emitters through
engineered light-matter interactions is a key challenge in nanophotonics and
quantum optics. In this work, we demonstrate dynamic modulation of dipole's
decay rate by exploiting the tunable plexcitonic modes (graphene plasmons and
QD-excitons) in the strong coupling regime. By integrating a quantum dot inside
a graphene spherical shell and tuning the local optical response of hybrid
modes via voltage-bias, we achieve continuous and reversible control over the
decay rate, leading to significant enhancement or suppression of dipole
emission from near- to far-infrared regime. Furthermore, the plexcitonic peaks
shows much sharper linewidths in contrast to bare graphene plasmons even in the
off-resonant coupling which indicates higher sensitivity of the systems at
tuned wavelengths. We demonstrate the phenomenon with the numerical solution of
3D Maxwell's equations using MNPBEM tool. Our approach demonstrate a versatile
platform for programmable emission control and offer a promising pathway for
developing reconfigurable quantum photonic devices, such as tunable
single-photon sources and ultrafast optical switches.

</details>


### [426] [Wind Variability and Its Effect on Transmission Line Capacity Estimation](https://arxiv.org/abs/2510.19433)
*Nika Mlinarič Hribar,Matjaž Depolli,Gregor Kosec*

Main category: physics.app-ph

TL;DR: 风速平均化对动态热额定值（DTR）计算有显著影响，尤其是在考虑风向和平均化方法时，可能导致高估或低估输电线载流量，存在安全隐患。


<details>
  <summary>Details</summary>
Motivation: 研究风速平均化方法对输电线路动态热额定值（DTR）计算的影响，探讨不同平均化方法（矢量平均和混合平均）对计算结果（如努塞尔数和载流量）的差异，并分析其在不同风速方向下的影响。

Method: 使用高时间分辨率（1秒）的风速数据，分别采用矢量平均和混合平均方法对5分钟数据进行平均化处理，并与高分辨率数据进行比较，计算DTR和载流量，分析其差异和角度依赖性。

Result: 风速平均化显著影响努塞尔数和载流量。平行风情况下，平均化数据低估载流量，且10%以上的低估情况常见。垂直风情况下，两种平均化方法结果不同，但都可能导致载流量被高估，存在操作风险。

Conclusion: 风速平均化对DTR结果有显著影响，必须重视平均化方法的选择，因为不同方法会对结果产生不同的影响。

Abstract: This study investigates the impact of wind velocity averaging on Dynamic
Thermal Rating (DTR) calculations. It is based on a high-temporal-resolution (1
second) wind measurements obtained from a transmission line in Slovenia,
Europe. Wind speed and direction variability are analysed, and two averaging
methods, namely vector averaging, where velocity is averaged as vector, and
hybrid averaging, where speed is averaged as scalar, are employed. DTR
calculations are performed on both high-resolution data and averaged data (5
minute averaging window). It is demonstrated that averaging has a significant
effect on both Nusselt number and ampacity, and the effect exhibits a strong
angular dependency on the relative angle of the wind to the line. Therefore,
two limit cases are studied: in the case of parallel wind, averaged data
underestimates the ampacity, and there is a significant amount of cases where
the underestimation is larger than 10 %. In the case of perpendicular wind, the
two averaging methods affect the results in different ways, but both result in
a substantial amount of cases where ampacity is overestimated, potentially
leading to unsafe operation. The main takeaway of the study is that averaging
wind velocity has a significant impact on DTR results, and special emphasis
should be given to the averaging method, as different methods affect the
results in different ways.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [427] [Machine Olfaction and Embedded AI Are Shaping the New Global Sensing Industry](https://arxiv.org/abs/2510.19660)
*Andreas Mershin,Nikolas Stefanou,Adan Rotteveel,Matthew Kung,George Kung,Alexandru Dan,Howard Kivell,Zoia Okulova,Zoi Kountouri,Paul Pu Liang*

Main category: cs.ET

TL;DR: 机器学习嗅觉技术正在快速发展，有望在医疗、工业、农业、安全和国防等领域带来变革。


<details>
  <summary>Details</summary>
Motivation: 本综述旨在探讨机器学习嗅觉技术的科学基础、技术前沿和战略应用，并指出该技术正在催生一个具有全球化学感觉基础设施的新兴行业。

Method: 通过整合稳定的哺乳动物嗅觉受体与生物光子和生物电子系统，实现了接近单分子分辨率的检测。将此技术与多模态人工智能和分布式传感器网络相结合。

Result: 机器学习嗅觉技术有望带来一个覆盖全球的分子感知技术层，在健康、安全和环境传感领域产生巨大的新兴市场。已涵盖工业、军事和消费领域的应用实例。

Conclusion: 机器学习嗅觉技术正处于崛起阶段，将形成一个全球性的化学感官基础设施，并在健康、安全和环境传感领域创造广阔的市场。

Abstract: Machine olfaction is rapidly emerging as a transformative capability, with
applications spanning non-invasive medical diagnostics, industrial monitoring,
agriculture, and security and defense. Recent advances in stabilizing mammalian
olfactory receptors and integrating them into biophotonic and bioelectronic
systems have enabled detection at near single-molecule resolution thus placing
machines on par with trained detection dogs. As this technology converges with
multimodal AI and distributed sensor networks imbued with embedded AI, it
introduces a new, biochemical layer to a sensing ecosystem currently dominated
by machine vision and audition. This review and industry roadmap surveys the
scientific foundations, technological frontiers, and strategic applications of
machine olfaction making the case that we are currently witnessing the rise of
a new industry that brings with it a global chemosensory infrastructure. We
cover exemplary industrial, military and consumer applications and address some
of the ethical and legal concerns arising. We find that machine olfaction is
poised to bring forth a planet-wide molecular awareness tech layer with the
potential of spawning vast emerging markets in health, security, and
environmental sensing via scent.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [428] [CodeCRDT: Observation-Driven Coordination for Multi-Agent LLM Code Generation](https://arxiv.org/abs/2510.18893)
*Sergey Pugachev*

Main category: cs.DC

TL;DR: CodeCRDT是一种新的多智能体LLM系统协调模式，它通过监控共享状态的更新来进行协调，而不是显式地传递消息，从而实现了无锁、无冲突的并发代码生成，并具有最终一致性。该方法在600次试验中显示了性能提升（最高21.1%）和下降（最高39.4%），但保证了100%的收敛性和零合并失败。研究还揭示了LLM智能体驱动协调的语义冲突率（5-10%）以及性能-质量权衡，并根据任务结构对并行协调的成功与否进行了经验表征。


<details>
  <summary>Details</summary>
Motivation: 多智能体LLM系统在并行速度提升方面存在瓶颈，原因是协调成本高昂。

Method: 提出了一种名为CodeCRDT的观察驱动协调模式。智能体通过监控具有可观察更新和确定性收敛的共享状态来进行协调，取代了显式的消息传递。利用无冲突复制数据类型（CRDTs），CodeCRDT实现了无锁、无冲突的并发代码生成，并保证了强最终一致性。

Result: 在600次试验（6个任务，每种模式50次运行）的评估中，CodeCRDT在某些任务上实现了高达21.1%的速度提升，在其他任务上则导致高达39.4%的减速。然而，该方法保证了100%的收敛率和零合并失败。

Conclusion: CodeCRDT为随机LLM智能体形式化了观察驱动的协调，揭示了5-10%的语义冲突率和质量-性能权衡。研究结果表明，并行协调的成功与否取决于任务结构，并提供了相应的经验表征。

Abstract: Multi-agent LLM systems fail to realize parallel speedups due to costly
coordination. We present CodeCRDT, an observation-driven coordination pattern
where agents coordinate by monitoring a shared state with observable updates
and deterministic convergence, rather than explicit message passing. Using
Conflict-Free Replicated Data Types (CRDTs), CodeCRDT enables lock-free,
conflict-free concurrent code generation with strong eventual consistency.
Evaluation across 600 trials (6 tasks, 50 runs per mode) shows both benefits
and trade-offs: up to 21.1% speedup on some tasks, up to 39.4% slowdown on
others, and 100% convergence with zero merge failures. The study formalizes
observation-driven coordination for stochastic LLM agents, revealing semantic
conflict rates (5-10%) and quality-performance tradeoffs, and provides
empirical characterization of when parallel coordination succeeds versus fails
based on task structure.

</details>


### [429] [AI for Distributed Systems Design: Scalable Cloud Optimization Through Repeated LLMs Sampling And Simulators](https://arxiv.org/abs/2510.18897)
*Jacopo Tagliabue*

Main category: cs.DC

TL;DR: LLM结合验证方法来设计分布式系统策略。


<details>
  <summary>Details</summary>
Motivation: 探索AI驱动的分布式系统策略设计。

Method: 使用LLM生成代码，并通过特定领域模拟器进行验证，形成一个迭代的生成-验证循环。

Result: 在吞吐量改进方面取得初步成果，并讨论了现有方法的局限性。

Conclusion: AI对于通过引导新模拟器来扩展此方法至关重要。

Abstract: We explore AI-driven distributed-systems policy design by combining
stochastic code generation from large language models (LLMs) with deterministic
verification in a domain-specific simulator. Using a Function-as-a-Service
runtime (Bauplan) and its open-source simulator (Eudoxia) as a case study, we
frame scheduler design as an iterative generate-and-verify loop: an LLM
proposes a Python policy, the simulator evaluates it on standardized traces,
and structured feedback steers subsequent generations. This setup preserves
interpretability while enabling targeted search over a large design space. We
detail the system architecture and report preliminary results on throughput
improvements across multiple models. Beyond early gains, we discuss the limits
of the current setup and outline next steps; in particular, we conjecture that
AI will be crucial for scaling this methodology by helping to bootstrap new
simulators.

</details>


### [430] [Comparative analysis of large data processing in Apache Spark using Java, Python and Scala](https://arxiv.org/abs/2510.19012)
*Ivan Borodii,Illia Fedorovych,Halyna Osukhivska,Diana Velychko,Roman Butsii*

Main category: cs.DC

TL;DR: 在处理小文件时Python表现最佳，而在处理大文件和复杂操作时Scala和Java更优。


<details>
  <summary>Details</summary>
Motivation: 目前关于使用Apache Iceberg的完整ETL工作流跨编程语言的全面比较研究有限，本研究旨在填补这一空白。

Method: 通过执行下载CSV数据、转换并加载到Apache Iceberg分析表等一系列操作，比较了Java、Python和Scala在Apache Spark平台上的性能。

Result: 在处理5MB文件时，Python（6.71秒）优于Scala（9.13秒）和Java（9.62秒）。在处理1.6GB文件时，Python（46.34秒）、Scala（47.72秒）和Java（50.56秒）性能相近。在涉及合并两个CSV文件并加载到Apache Iceberg表的操作中，Scala（374.42秒）优于Java（379.8秒）和Python（398.32秒）。

Conclusion: 编程语言显著影响Apache Spark的数据处理效率。Scala和Java在处理大数据量和复杂操作方面更具生产力，而Python在处理小数据量方面具有优势。

Abstract: During the study, the results of a comparative analysis of the process of
handling large datasets using the Apache Spark platform in Java, Python, and
Scala programming languages were obtained. Although prior works have focused on
individual stages, comprehensive comparisons of full ETL workflows across
programming languages using Apache Iceberg remain limited. The analysis was
performed by executing several operations, including downloading data from CSV
files, transforming and loading it into an Apache Iceberg analytical table. It
was found that the performance of the Spark algorithm varies significantly
depending on the amount of data and the programming language used. When
processing a 5-megabyte CSV file, the best result was achieved in Python: 6.71
seconds, which is superior to Scala's score of 9.13 seconds and Java's time of
9.62 seconds. For processing a large CSV file of 1.6 gigabytes, all programming
languages demonstrated similar results: the fastest performance was showed in
Python: 46.34 seconds, while Scala and Java showed results of 47.72 and 50.56
seconds, respectively. When performing a more complex operation that involved
combining two CSV files into a single dataset for further loading into an
Apache Iceberg table, Scala demonstrated the highest performance, at 374.42
seconds. Java processing was completed in 379.8 seconds, while Python was the
least efficient, with a runtime of 398.32 seconds. It follows that the
programming language significantly affects the efficiency of data processing by
the Apache Spark algorithm, with Scala and Java being more productive for
processing large amounts of data and complex operations, while Python
demonstrates an advantage in working with small amounts of data. The results
obtained can be useful for optimizing data handling processes depending on
specific performance requirements and the amount of information being
processed.

</details>


### [431] [On the Randomized Locality of Matching Problems in Regular Graphs](https://arxiv.org/abs/2510.19151)
*Seri Khoury,Manish Purohit,Aaron Schild,Joshua Wang*

Main category: cs.DC

TL;DR: 在正则图中，我们研究了匹配问题的局部性。对于近似匹配，我们开发了随机算法，表明 $(1 + \epsilon)$-近似匹配是真正局部的，其局部性仅取决于 $\epsilon$。对于最大匹配，我们表明其局部性需要依赖于节点数 $n$ 或度 $\Delta$，并建立了节点平均复杂度和最坏情况复杂度之间的分离。我们使用新颖的鞅分析来分析 Luby 的算法。


<details>
  <summary>Details</summary>
Motivation: 研究分布式对称性问题中的局部性，特别是正则图中的匹配问题，以了解节点需要探索的邻域半径。

Method: 开发随机算法用于近似匹配；分析 Luby 的算法，展示其在 line graph 上的应用。

Result: 证明 $(1 + everse{ } everse{ 	extepsilon } )$-近似匹配在正则图中是局部的，局部性仅依赖于 $everse{ } everse{ 	extepsilon }$。证明最大匹配的局部性依赖于 $n$ 或 $everse{ } everse{ 	extDelta }$。展示了节点平均复杂度和最坏情况复杂度之间的强分离。

Conclusion: 近似匹配是真正的局部问题，而最大匹配则不是。Luby 的算法分析揭示了其在 line graph 上的一个有趣性质。

Abstract: The main goal in distributed symmetry-breaking is to understand the locality
of problems; i.e., the radius of the neighborhood that a node needs to explore
in order to arrive at its part of a global solution. In this work, we study the
locality of matching problems in the family of regular graphs, which is one of
the main benchmarks for establishing lower bounds on the locality of
symmetry-breaking problems, as well as for obtaining classification results.
For approximate matching, we develop randomized algorithms to show that $(1 +
\epsilon)$-approximate matching in regular graphs is truly local; i.e., the
locality depends only on $\epsilon$ and is independent of all other graph
parameters. Furthermore, as long as the degree $\Delta$ is not very small
(namely, as long as $\Delta \geq \text{poly}(1/\epsilon)$), this dependence is
only logarithmic in $1/\epsilon$. This stands in sharp contrast to maximal
matching in regular graphs which requires some dependence on the number of
nodes $n$ or the degree $\Delta$. We show matching lower bounds for both
results. For maximal matching, our techniques further allow us to establish a
strong separation between the node-averaged complexity and worst-case
complexity of maximal matching in regular graphs, by showing that the former is
only $O(1)$. Central to our main technical contribution is a novel
martingale-based analysis for the $\approx 40$-year-old algorithm by Luby. In
particular, our analysis shows that applying one round of Luby's algorithm on
the line graph of a $\Delta$-regular graph results in an almost
$\Delta/2$-regular graph.

</details>


### [432] [RLBoost: Harvesting Preemptible Resources for Cost-Efficient Reinforcement Learning on LLMs](https://arxiv.org/abs/2510.19225)
*Yongji Wu,Xueshen Liu,Haizhong Zheng,Juncheng Gu,Beidi Chen,Z. Morley Mao,Arvind Krishnamurthy,Ion Stoica*

Main category: cs.DC

TL;DR: RLBoost 通过利用可抢占的 GPU 资源，实现了经济高效的强化学习（RL）训练，提高了吞吐量并降低了成本。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习框架在处理 Rollout 和训练阶段不同的资源需求方面存在不足，并且未能有效利用成本效益高的可抢占 GPU 资源。

Method: RLBoost 采用混合架构，结合了自适应 Rollout 分载、基于拉取的权重传输和令牌级响应收集与迁移这三种技术，以有效利用可抢占资源。

Result: RLBoost 训练吞吐量提高了 1.51 倍到 1.97 倍，成本效益提高了 28% 到 49%。

Conclusion: RLBoost 是一种经济高效的 RL 训练解决方案，它利用可抢占的 GPU 资源，解决了现有 RL 框架的局限性，并在实验中取得了显著的性能提升。

Abstract: Reinforcement learning (RL) has become essential for unlocking advanced
reasoning capabilities in large language models (LLMs). RL workflows involve
interleaving rollout and training stages with fundamentally different resource
requirements. Rollout typically dominates overall execution time, yet scales
efficiently through multiple independent instances. In contrast, training
requires tightly-coupled GPUs with full-mesh communication. Existing RL
frameworks fall into two categories: co-located and disaggregated
architectures. Co-located ones fail to address this resource tension by forcing
both stages to share the same GPUs. Disaggregated architectures, without
modifications of well-established RL algorithms, suffer from resource
under-utilization. Meanwhile, preemptible GPU resources, i.e., spot instances
on public clouds and spare capacity in production clusters, present significant
cost-saving opportunities for accelerating RL workflows, if efficiently
harvested for rollout.
  In this paper, we present RLBoost, a systematic solution for cost-efficient
RL training that harvests preemptible GPU resources. Our key insight is that
rollout's stateless and embarrassingly parallel nature aligns perfectly with
preemptible and often fragmented resources. To efficiently utilize these
resources despite frequent and unpredictable availability changes, RLBoost
adopts a hybrid architecture with three key techniques: (1) adaptive rollout
offload to dynamically adjust workloads on the reserved (on-demand) cluster,
(2) pull-based weight transfer that quickly provisions newly available
instances, and (3) token-level response collection and migration for efficient
preemption handling and continuous load balancing. Extensive experiments show
RLBoost increases training throughput by 1.51x-1.97x while improving cost
efficiency by 28%-49% compared to using only on-demand GPU resources.

</details>


### [433] [RailS: Load Balancing for All-to-All Communication in Distributed Mixture-of-Experts Training](https://arxiv.org/abs/2510.19262)
*Heng Xu,Zhiwei Yu,Chengze Du,Ying Zhou,Letian Li,Haojie Wang,Weiqiang Cheng,Jialong Li*

Main category: cs.DC

TL;DR: 本文提出了RailS，一个用于训练混合专家（MoE）模型的分布式负载均衡框架，通过利用Rail拓扑的确定性来最小化通信开销，从而提高训练效率。


<details>
  <summary>Details</summary>
Motivation: 传统的负载均衡方法未能充分利用Rail架构的确定性拓扑，导致多网卡带宽利用不足，而混合专家模型训练中的稀疏、高度不平衡的通信是主要的瓶颈。

Method: RailS利用Rail拓扑的对称性，通过在每个节点独立执行最长处理时间优先（LPT）调度器来主动平衡流量，并激活N个并行轨道以实现细粒度的、拓扑感知的多路径传输。

Result: RailS在合成和真实世界的MoE工作负载中，将总线带宽提高了20%--78%，并将完成时间减少了17%--78%。对于Mixtral工作负载，它将迭代时间缩短了18%--40%，并实现了近乎最优的负载均衡。

Conclusion: RailS通过利用Rail拓扑的确定性，将全局协调转化为局部调度，实现了高效的MoE模型分布式训练，显著提高了通信效率和训练速度。

Abstract: Training Mixture-of-Experts (MoE) models introduces sparse and highly
imbalanced all-to-all communication that dominates iteration time. Conventional
load-balancing methods fail to exploit the deterministic topology of Rail
architectures, leaving multi-NIC bandwidth underutilized. We present RailS, a
distributed load-balancing framework that minimizes all-to-all completion time
in MoE training. RailS leverages the Rail topology's symmetry to prove that
uniform sending ensures uniform receiving, transforming global coordination
into local scheduling. Each node independently executes a Longest Processing
Time First (LPT) spraying scheduler to proactively balance traffic using local
information. RailS activates N parallel rails for fine-grained, topology-aware
multipath transmission. Across synthetic and real-world MoE workloads, RailS
improves bus bandwidth by 20%--78% and reduces completion time by 17%--78%. For
Mixtral workloads, it shortens iteration time by 18%--40% and achieves
near-optimal load balance, fully exploiting architectural parallelism in
distributed training.

</details>


### [434] [FLASH Viterbi: Fast and Adaptive Viterbi Decoding for Modern Data Systems](https://arxiv.org/abs/2510.19301)
*Ziheng Deng,Xue Liu,Jiantong Jiang,Yankai Li,Qingxu Deng,Xiaochun Yang*

Main category: cs.DC

TL;DR: FLASH Viterbi 提出了一种名为 FLASH Viterbi 的快速、轻量级、自适应且对硬件友好的 Viterbi 解码算子，该算子通过结合分治策略、剪枝和并行化技术，提高了时间和内存效率，适用于资源受限的数据系统。FLASH-BS Viterbi 是一个动态束搜索变体，进一步降低了空间复杂度。


<details>
  <summary>Details</summary>
Motivation: 随着数据系统越来越多地迁移到资源受限的边缘平台，标准的 Viterbi 解码在内存和计算方面存在局限性。现有方法通常牺牲解码时间来换取空间效率，但运行时开销大且缺乏适应性。

Method: FLASH Viterbi 采用非递归分治策略，结合剪枝和并行化技术。FLASH-BS Viterbi 是一个动态束搜索变体，构建在内存高效的数据结构上。两种算法都可以通过动态调整内部参数来适应不同的部署场景。此外，还开发了基于 FPGA 的硬件加速器。

Result: 实验表明，所提出的算法在解码时间和内存效率方面均优于现有基线，同时保持了现代数据系统所必需的适应性和硬件友好特性。

Conclusion: FLASH Viterbi 及其变体 FLASH-BS Viterbi 提供了内存和计算效率的提升，并且易于在 FPGA 等硬件上实现，非常适合资源受限的边缘平台。

Abstract: The Viterbi algorithm is a key operator for structured sequence inference in
modern data systems, with applications in trajectory analysis, online
recommendation, and speech recognition. As these workloads increasingly migrate
to resource-constrained edge platforms, standard Viterbi decoding remains
memory-intensive and computationally inflexible. Existing methods typically
trade decoding time for space efficiency, but often incur significant runtime
overhead and lack adaptability to various system constraints. This paper
presents FLASH Viterbi, a Fast, Lightweight, Adaptive, and Hardware-Friendly
Viterbi decoding operator that enhances adaptability and resource efficiency.
FLASH Viterbi combines a non-recursive divide-and-conquer strategy with pruning
and parallelization techniques to enhance both time and memory efficiency,
making it well-suited for resource-constrained data systems.To further decouple
space complexity from the hidden state space size, we present FLASH-BS Viterbi,
a dynamic beam search variant built on a memory-efficient data structure. Both
proposed algorithms exhibit strong adaptivity to diverse deployment scenarios
by dynamically tuning internal parameters.To ensure practical deployment on
edge devices, we also develop FPGA-based hardware accelerators for both
algorithms, demonstrating high throughput and low resource usage. Extensive
experiments show that our algorithms consistently outperform existing baselines
in both decoding time and memory efficiency, while preserving adaptability and
hardware-friendly characteristics essential for modern data systems. All codes
are publicly available at https://github.com/Dzh-16/FLASH-Viterbi.

</details>


### [435] [HybridEP: Scaling Expert Parallelism to Cross-Datacenter Scenario via Hybrid Expert/Data Transmission](https://arxiv.org/abs/2510.19470)
*Weihao Yang,Hao Huang,Donglei Wu,Ningke Li,Yanqi Pan,Qiyang Zheng,Wen Xia,Shiyi Li,Qiang Wang*

Main category: cs.DC

TL;DR: 混合专家模型（MoE）在扩展大型模型方面日益普及，但跨数据中心（DC）的训练模式因带宽限制而面临专家并行（EP）的可扩展性挑战。本研究提出了HybridEP框架，通过动态重构专家布局以减少通信量和频率，并结合领域划分和参数高效迁移技术来优化跨DC的EP训练。


<details>
  <summary>Details</summary>
Motivation: 随着模型规模的增大，传统的单数据中心训练模式已无法满足需求，跨数据中心训练成为趋势，但现有MoE的专家并行（EP）在低带宽环境下存在严重的可扩展性问题，通信开销大，已成为阻碍MoE模型发展的关键瓶颈。

Method: 提出HybridEP框架，通过流模型动态确定最优传输比例，结合领域划分技术将混合通信模式映射到GPU通信拓扑，并采用参数高效迁移技术减少通信开销和扩大领域大小，以优化跨数据中心、低带宽环境下的EP训练。

Result: 实验结果表明，在带宽受限的情况下，HybridEP的性能最高可达现有最先进MoE训练系统的5.6倍。在大规模模拟中，HybridEP在1000个数据中心环境下，不同带宽下均实现了最高1.45倍的加速比。

Conclusion: HybridEP通过动态重构专家布局、优化通信模式和利用参数高效迁移等技术，有效解决了跨数据中心、低带宽环境下MoE模型专家并行（EP）的可扩展性问题，是一种更通用的EP方法，显著提升了训练效率。

Abstract: Mixture-of-Experts (MoE) has become a popular architecture for scaling large
models. However, the rapidly growing scale outpaces model training on a single
DC, driving a shift toward a more flexible, cross-DC training paradigm. Under
this, Expert Parallelism (EP) of MoE faces significant scalability issues due
to the limited cross-DC bandwidth. Specifically, existing EP optimizations
attempt to overlap data communication and computation, which has little benefit
in low-bandwidth scenarios due to a much longer data communication time.
Therefore, the trends of cross-DC EP scaling is fast becoming a critical
roadblock to the continued growth of MoE models.
  To address this, we propose HybridEP, a modeling-guided framework to optimize
EP under constrained bandwidth. Our key idea is to dynamically transform the
spatial placement of experts to reduce data communication traffic and
frequency, thereby minimizing EP's communication overheads. However, it is
non-trivial to find the optimal solution because it complicates the original
communication pattern by mixing data and expert communication. We therefore
build a stream-based model to determine the optimal transmission ratio. Guided
by this, we incorporate two techniques: (1) domain-based partition to construct
the mapping between hybrid patterns and specific communication topology at GPU
level, and (2) parameter-efficient migration to further refine this topology by
reducing expert transmission overhead and enlarging the domain size. Combining
all these designs, HybridEP can be considered as a more general EP with better
scalability. Experimental results show that HybridEP outperforms existing
state-of-the-art MoE training systems by up to 5.6x under constrained
bandwidth. We further compare HybridEP and EP on large-scale simulations.
HybridEP achieves up to 1.45x speedup with 1k DCs under different bandwidths.

</details>


### [436] [Propius: A Platform for Collaborative Machine Learning across the Edge and the Cloud](https://arxiv.org/abs/2510.19617)
*Eric Ding*

Main category: cs.DC

TL;DR: Collaborative Machine Learning (CML) lacks scalable infrastructure. We propose Propius, a novel system with control and data planes to manage heterogeneous client machines and computation flow for CML jobs, improving resource utilization, throughput, and job completion time.


<details>
  <summary>Details</summary>
Motivation: Existing server-client systems for collaborative ML are not scalable or reusable, and there's a growing need for efficient resource management as CML scales.

Method: Propius utilizes a control plane for efficient resource sharing among multiple CML jobs with various policies, and a data plane to enhance scalability of model sharing and result collection. It adapts to heterogeneous client machines.

Result: Evaluations show Propius outperforms existing systems in resource utilization (up to 1.88x), throughput (up to 2.76x), and job completion time (up to 1.26x).

Conclusion: Propius provides a scalable, efficient, and adaptable solution for collaborative ML resource management, addressing the limitations of current approaches.

Abstract: Collaborative Machine Learning is a paradigm in the field of distributed
machine learning, designed to address the challenges of data privacy,
communication overhead, and model heterogeneity. There have been significant
advancements in optimization and communication algorithm design and ML hardware
that enables fair, efficient and secure collaborative ML training. However,
less emphasis is put on collaborative ML infrastructure development. Developers
and researchers often build server-client systems for a specific collaborative
ML use case, which is not scalable and reusable. As the scale of collaborative
ML grows, the need for a scalable, efficient, and ideally multi-tenant resource
management system becomes more pressing. We propose a novel system, Propius,
that can adapt to the heterogeneity of client machines, and efficiently manage
and control the computation flow between ML jobs and edge resources in a
scalable fashion. Propius is comprised of a control plane and a data plane. The
control plane enables efficient resource sharing among multiple collaborative
ML jobs and supports various resource sharing policies, while the data plane
improves the scalability of collaborative ML model sharing and result
collection. Evaluations show that Propius outperforms existing resource
management techniques and frameworks in terms of resource utilization (up to
$1.88\times$), throughput (up to $2.76$), and job completion time (up to
$1.26\times$).

</details>


### [437] [Serverless GPU Architecture for Enterprise HR Analytics: A Production-Scale BDaaS Implementation](https://arxiv.org/abs/2510.19689)
*Guilin Zhang,Wulan Guo,Ziqi Tan,Srinivas Vippagunta,Suchitra Raman,Shreeshankar Chatterjee,Ju Lin,Shang Liu,Mary Schladenhauffen,Jeffrey Luo,Hailong Jiang*

Main category: cs.DC

TL;DR: 在工业和政府领域，对大规模批处理或流式分析的Spark和Flink的需求不断增长，但它们带来了协调复杂性和审计开销。该论文提出了一种集成了单节点无服务器GPU运行时和TabNet的生产级大数据即服务(BDaaS)蓝图，以满足中等规模、低延迟和合规性要求。


<details>
  <summary>Details</summary>
Motivation: 随着云提供商提供无服务器GPU以及TabNet等可解释的表格机器学习模型的出现，为受监管环境中的部署带来了新的机遇。本研究旨在提出一种满足这些需求的解决方案。

Method: 本研究提出并实现了一个生产导向的BDaaS蓝图，集成了单节点无服务器GPU运行时和TabNet模型。该设计利用GPU加速、无服务器弹性和TabNet的可解释性特征来实现吞吐量、成本效益和合规性。

Result: 在HR、Adult和BLS数据集上的基准测试表明，与Spark和CPU基线相比，GPU管道的吞吐量提高了4.5倍，延迟降低了98倍，每1K次推理的成本降低了90%。合规性机制仅增加了约5.7毫秒的延迟（p99 < 22毫秒），并且在峰值负载下可解释性保持稳定。

Conclusion: 该研究提供了一个合规感知的基准、一个可重现的Helm打包蓝图和一个决策框架，证明了为受监管的企业和政府环境提供安全、可解释且成本效益高的无服务器GPU分析的可行性。

Abstract: Industrial and government organizations increasingly depend on data-driven
analytics for workforce, finance, and regulated decision processes, where
timeliness, cost efficiency, and compliance are critical. Distributed
frameworks such as Spark and Flink remain effective for massive-scale batch or
streaming analytics but introduce coordination complexity and auditing
overheads that misalign with moderate-scale, latency-sensitive inference.
Meanwhile, cloud providers now offer serverless GPUs, and models such as TabNet
enable interpretable tabular ML, motivating new deployment blueprints for
regulated environments. In this paper, we present a production-oriented Big
Data as a Service (BDaaS) blueprint that integrates a single-node serverless
GPU runtime with TabNet. The design leverages GPU acceleration for throughput,
serverless elasticity for cost reduction, and feature-mask interpretability for
IL4/FIPS compliance. We conduct benchmarks on the HR, Adult, and BLS datasets,
comparing our approach against Spark and CPU baselines. Our results show that
GPU pipelines achieve up to 4.5x higher throughput, 98x lower latency, and 90%
lower cost per 1K inferences compared to Spark baselines, while compliance
mechanisms add only ~5.7 ms latency with p99 < 22 ms. Interpretability remains
stable under peak load, ensuring reliable auditability. Taken together, these
findings provide a compliance-aware benchmark, a reproducible Helm-packaged
blueprint, and a decision framework that demonstrate the practicality of
secure, interpretable, and cost-efficient serverless GPU analytics for
regulated enterprise and government settings.

</details>


### [438] [CommonSense: Efficient Set Intersection (SetX) Protocol Based on Compressed Sensing](https://arxiv.org/abs/2510.19725)
*Jingfan Meng,Tianji Yang,Jun Xu*

Main category: cs.DC

TL;DR: SetX问题可以通过多轮通信和压缩感知草图来解决，通信成本比SetR问题低8到10倍。


<details>
  <summary>Details</summary>
Motivation: SetR问题已有相关研究，但SetX问题被忽视，现有SetX解决方案复用SetR协议且成本认知有误，本文旨在解决SetX问题并证明其比SetR问题更便宜。

Method: Alice发送A的压缩感知（CS）草图给Bob以帮助Bob识别他独有的元素（B\A）。如果A不完全是B的子集，Bob将他无法解码的元素（残差集）的CS草图发回给Alice，以便Alice解码她独有的元素（A\B）。Alice和Bob通过通信和集合成员资格过滤器（SMF）来估计B\A，重复此过程直到双方就A∩B达成一致。

Result: 实验表明，与基于IBLT的SetR协议相比，本文提出的SetX协议将通信成本降低了8到10倍。

Conclusion: SetX问题比SetR问题更便宜，可以通过多轮通信和压缩感知草图有效地解决，并显著降低通信成本。

Abstract: In the set reconciliation (\textsf{SetR}) problem, two parties Alice and Bob,
holding sets $\mathsf{A}$ and $\mathsf{B}$, communicate to learn the symmetric
difference $\mathsf{A} \Delta \mathsf{B}$. In this work, we study a related but
under-explored problem: set intersection (\textsf{SetX})~\cite{Ozisik2019},
where both parties learn $\mathsf{A} \cap \mathsf{B}$ instead. However,
existing solutions typically reuse \textsf{SetR} protocols due to the absence
of dedicated \textsf{SetX} protocols and the misconception that \textsf{SetR}
and \textsf{SetX} have comparable costs. Observing that \textsf{SetX} is
fundamentally cheaper than \textsf{SetR}, we developed a multi-round
\textsf{SetX} protocol that outperforms the information-theoretic lower bound
of \textsf{SetR} problem. In our \textsf{SetX} protocol, Alice sends Bob a
compressed sensing (CS) sketch of $\mathsf{A}$ to help Bob identify his unique
elements (those in $\mathsf{B \setminus A}$). This solves the \textsf{SetX}
problem, if $\mathsf{A} \subseteq \mathsf{B}$. Otherwise, Bob sends a CS sketch
of the residue (a set of elements he cannot decode) back to Alice for her to
decode her unique elements (those in $\mathsf{A \setminus B}$). As such, Alice
and Bob communicate back and forth %with a set membership filter (SMF) of
estimated $\mathsf{B \setminus A}$. Alice updates $\mathsf{A}$ and
communication repeats until both parties agrees on $\mathsf{A} \cap
\mathsf{B}$. On real world datasets, experiments show that our $\mathsf{SetX}$
protocol reduces the communication cost by 8 to 10 times compared to the
IBLT-based $\mathsf{SetR}$ protocol.

</details>


### [439] [Next Generation Cloud-native In-Memory Stores: From Redis to Valkey and Beyond](https://arxiv.org/abs/2510.19805)
*Carl-Johan Fauvelle Munck af Rosensch"old,Feras M. Awaysheh,Ahmad Awad*

Main category: cs.DC

TL;DR: 本研究对Valkey、KeyDB和Garnet这三种Redis替代品进行了基准测试和评估，以解决当前文献中缺乏对该领域最先进工具的实验评估的问题。评估在Kubernetes部署的实际工作负载下进行，并考虑了吞吐量、尾部延迟、CPU和内存效率以及迁移复杂性等指标。结果表明，这些数据系统之间存在明显的权衡，并在性能、兼容性和长期可行性（包括项目成熟度、社区支持和持续开发）之间进行了权衡。


<details>
  <summary>Details</summary>
Motivation: 现代云原生基础设施离不开内存键值数据存储，但它们在可扩展性、兼容性和可持续性方面面临挑战。目前的研究缺乏对该领域最先进工具的实验评估。

Method: 在Kubernetes部署的实际工作负载下，对Valkey、KeyDB和Garnet这三种Redis替代品进行了基准测试和系统评估。

Result: 研究结果显示，被测数据系统之间存在明显的权衡。评估指标包括吞吐量、尾部延迟、CPU和内存效率以及迁移复杂性。

Conclusion: 本研究全面评估了新兴内存键值存储的性能和可行性，强调了性能、兼容性和长期可行性（包括项目成熟度、社区支持和持续开发）之间的权衡。

Abstract: In-memory key-value datastores have become indispensable building blocks of
modern cloud-native infrastructures, yet their evolution faces scalability,
compatibility, and sustainability constraints. The current literature lacks an
experimental evaluation of state-of-the-art tools in the domain. This study
addressed this timely gap by benchmarking Redis alternatives and systematically
evaluating Valkey, KeyDB, and Garnet under realistic workloads within
Kubernetes deployments. The results demonstrate clear trade-offs among the
benchmarked data systems. Our study presents a comprehensive performance and
viability assessment of the emerging in-memory key-value stores. Metrics
include throughput, tail latency, CPU and memory efficiency, and migration
complexity. We highlight trade-offs between performance, compatibility, and
long-term viability, including project maturity, community support, and
sustained development.

</details>
