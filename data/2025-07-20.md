<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 89]
- [cs.CL](#cs.CL) [Total: 36]
- [cs.NE](#cs.NE) [Total: 2]
- [cs.GT](#cs.GT) [Total: 2]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 19]
- [cs.DS](#cs.DS) [Total: 15]
- [cs.MA](#cs.MA) [Total: 1]
- [eess.SP](#eess.SP) [Total: 10]
- [cs.LO](#cs.LO) [Total: 6]
- [cs.ET](#cs.ET) [Total: 1]
- [cs.AI](#cs.AI) [Total: 20]
- [cs.SI](#cs.SI) [Total: 3]
- [cs.RO](#cs.RO) [Total: 26]
- [physics.app-ph](#physics.app-ph) [Total: 3]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 14]
- [eess.SY](#eess.SY) [Total: 15]
- [quant-ph](#quant-ph) [Total: 47]
- [cs.LG](#cs.LG) [Total: 63]
- [cs.DC](#cs.DC) [Total: 2]
- [cs.GR](#cs.GR) [Total: 4]
- [cs.AR](#cs.AR) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Spatially Grounded Explanations in Vision Language Models for Document Visual Question Answering](https://arxiv.org/abs/2507.12490)
*Maximiliano Hormazábal Lagos,Héctor Cerezo-Costas,Dimosthenis Karatzas*

Main category: cs.CV

TL;DR: EaGERS is a training-free pipeline that uses vision-language models and multimodal embeddings to generate rationales and improve DocVQA performance and transparency.


<details>
  <summary>Details</summary>
Motivation: To enhance transparency and reproducibility in DocVQA without additional model fine-tuning.

Method: EaGERS is a training-free and model-agnostic pipeline that generates natural language rationales using a vision language model, grounds these rationales to spatial sub-regions by computing multimodal embedding similarities over a configurable grid with majority voting, and restricts response generation to selected relevant regions in a masked image.

Result: The best configuration of EaGERS outperforms the base model on exact match accuracy and Average Normalized Levenshtein Similarity metrics.

Conclusion: EaGERS pipeline improves exact match accuracy and Average Normalized Levenshtein Similarity on DocVQA, and enhances transparency and reproducibility without additional model fine-tuning.

Abstract: We introduce EaGERS, a fully training-free and model-agnostic pipeline that
(1) generates natural language rationales via a vision language model, (2)
grounds these rationales to spatial sub-regions by computing multimodal
embedding similarities over a configurable grid with majority voting, and (3)
restricts the generation of responses only from the relevant regions selected
in the masked image. Experiments on the DocVQA dataset demonstrate that our
best configuration not only outperforms the base model on exact match accuracy
and Average Normalized Levenshtein Similarity metrics but also enhances
transparency and reproducibility in DocVQA without additional model
fine-tuning.

</details>


### [2] [MindJourney: Test-Time Scaling with World Models for Spatial Reasoning](https://arxiv.org/abs/2507.12508)
*Yuncong Yang,Jiageng Liu,Zheyuan Zhang,Siyuan Zhou,Reuben Tan,Jianwei Yang,Yilun Du,Chuang Gan*

Main category: cs.CV

TL;DR: MindJourney是一个测试时框架，通过结合VLM和世界模型来增强3D推理能力，无需微调即可提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前先进的视觉语言模型（VLM）在处理3D空间推理任务时存在困难，因为它们主要依赖2D图像，缺乏对3D动态的内部模型。

Method: MindJourney是一个测试时扩展框架，通过将VLM与基于视频扩散的可控世界模型相结合来实现。VLM会生成相机轨迹，世界模型则会合成相应的视图，VLM通过分析这些多视图信息进行推理。

Result: MindJourney在SAT空间推理基准测试上实现了平均超过8%的性能提升，并且无需进行微调，同时还提高了通过强化学习训练的测试时推理VLM的性能。

Conclusion: MindJourney通过在测试时将VLM与基于视频扩散的可控世界模型相结合，实现了强大的3D推理能力，在SAT基准测试上平均性能提升超过8%，并且无需进行微调。

Abstract: Spatial reasoning in 3D space is central to human cognition and indispensable
for embodied tasks such as navigation and manipulation. However,
state-of-the-art vision-language models (VLMs) struggle frequently with tasks
as simple as anticipating how a scene will look after an egocentric motion:
they perceive 2D images but lack an internal model of 3D dynamics. We therefore
propose MindJourney, a test-time scaling framework that grants a VLM with this
missing capability by coupling it to a controllable world model based on video
diffusion. The VLM iteratively sketches a concise camera trajectory, while the
world model synthesizes the corresponding view at each step. The VLM then
reasons over this multi-view evidence gathered during the interactive
exploration. Without any fine-tuning, our MindJourney achieves over an average
8% performance boost on the representative spatial reasoning benchmark SAT,
showing that pairing VLMs with world models for test-time scaling offers a
simple, plug-and-play route to robust 3D reasoning. Meanwhile, our method also
improves upon the test-time inference VLMs trained through reinforcement
learning, which demonstrates the potential of our method that utilizes world
models for test-time scaling.

</details>


### [3] [Mono-InternVL-1.5: Towards Cheaper and Faster Monolithic Multimodal Large Language Models](https://arxiv.org/abs/2507.12566)
*Gen Luo,Wenhan Dou,Wenhao Li,Zhaokai Wang,Xue Yang,Changyao Tian,Hao Li,Weiyun Wang,Wenhai Wang,Xizhou Zhu,Yu Qiao,Jifeng Dai*

Main category: cs.CV

TL;DR: 通过新的视觉参数空间和优化的预训练策略，开发了更高效、更强大的单体多模态大语言模型 Mono-InternVL 和 Mono-InternVL-1.5，解决了现有模型的稳定性和成本问题，并在多项任务中取得了领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有的单体多模态大语言模型（MLLMs）在优化和灾难性遗忘方面存在不稳定的问题。为了解决这些挑战，需要一种新的方法来稳定地集成视觉和语言信息。

Method: 本文提出了一种新的视觉参数空间嵌入方法，通过 delta 调优实现从噪声数据中稳定学习视觉知识。在此基础上，开发了单体多模态大语言模型 Mono-InternVL，并引入了内生视觉预训练 (EViP) 策略。为了降低成本并提升性能，进一步提出了 Mono-InternVL-1.5，该模型配备了改进的 EViP++（包含额外的视觉注意力专家）并优化了预训练流程，同时在推理时通过融合的 CUDA 核加速 MoE 操作。

Result: Mono-InternVL 在 15 项基准测试中的 12 项上表现优于现有的单体 MLLMs，例如在 OCRBench 上比 Emu3 提升了 114 分。Mono-InternVL-1.5 与 Mono-InternVL 相比，在保持相似的多模态性能的同时，将首词延迟降低了高达 69%，并显著降低了训练和推理成本。

Conclusion: Mono-InternVL-1.5 通过引入视觉专家和改进的内生视觉预训练 (EViP++)，在不牺牲性能的情况下显著降低了训练和推理成本，并在多项基准测试中取得了优于现有模型（包括其模块化对应模型 InternVL-1.5）的成果。

Abstract: This paper focuses on monolithic Multimodal Large Language Models (MLLMs),
which integrate visual encoding and language decoding into a single model.
Existing structures and pre-training strategies for monolithic MLLMs often
suffer from unstable optimization and catastrophic forgetting. To address these
challenges, our key idea is to embed a new visual parameter space into a
pre-trained LLM, enabling stable learning of visual knowledge from noisy data
via delta tuning. Based on this principle, we first introduce Mono-InternVL, an
advanced monolithic MLLM that incorporates a set of visual experts through a
multimodal mixture-of-experts architecture. In addition, we design an
innovative Endogenous Visual Pre-training (EViP) for Mono-InternVL to maximize
its visual capabilities via progressive learning. Mono-InternVL achieves
competitive performance against existing MLLMs but also leads to relatively
expensive data cost. Therefore, we further present Mono-InternVL-1.5, a cheaper
and stronger monolithic MLLM equipped with an improved EViP (EViP++). EViP++
introduces additional visual attention experts to Mono-InternVL-1.5 and
re-organizes the pre-training process in an efficient manner. During inference,
it includes a fused CUDA kernel to speed up its MoE operations. With these
designs, Mono-InternVL-1.5 significantly reduces training and inference costs,
while still maintaining competitive performance with Mono-InternVL. To evaluate
our approach, we conduct extensive experiments across 15 benchmarks. Results
demonstrate that Mono-InternVL outperforms existing monolithic MLLMs on 12 out
of 15 benchmarks, e.g., +114-point improvement over Emu3 on OCRBench. Compared
to its modular counterpart, i.e., InternVL-1.5, Mono-InternVL-1.5 achieves
similar multimodal performance while reducing first-token latency by up to 69%.
Code and models are released at https://github.com/OpenGVLab/Mono-InternVL.

</details>


### [4] [Best Practices for Large-Scale, Pixel-Wise Crop Mapping and Transfer Learning Workflows](https://arxiv.org/abs/2507.12590)
*Judy Long,Tao Liu,Sean Alexander Woznicki,Miljana Marković,Oskar Marko,Molly Sears*

Main category: cs.CV

TL;DR: 本研究对大规模像素级作物测绘工作流进行了全面的回顾和评估，比较了多种预处理、监督学习和迁移学习方法。研究发现，细粒度间隔预处理结合Transformer模型效果最佳，RF模型在特定场景下也表现良好。迁移学习提高了工作流的适应性，但最终选择取决于标签样本的数量。在样本充足时，监督学习更优；样本不足时，迁移学习是有效替代方案。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在识别最优的大规模、像素级作物测绘工作流，并评估传统监督学习方法与新兴迁移学习方法的性能。通过系统性实验和跨领域评估，为提高作物测绘的准确性和适应性提供指导。

Method: 本研究对大规模、像素级作物测绘工作流进行了全面的回顾，包括传统的监督学习方法和新兴的迁移学习方法。通过系统性实验，比较了六种广泛使用的卫星图像预处理方法和十一种监督像素级分类模型，并评估了不同训练样本量和变量组合的协同影响。此外，研究还确定了适用于不同领域迁移程度的最佳迁移学习技术。所有方法的评估均在五个不同的农业区进行，主要使用Landsat 8卫星数据，标签数据来源于CDL可信像素和实地调查。

Result: 细粒度间隔预处理与Transformer模型相结合，在监督和迁移学习工作流中均表现出最优性能。RF模型在传统监督学习和直接迁移到相似领域方面，训练速度快且性能具有竞争力。迁移学习技术，特别是UDA和微调，提高了工作流的适应性。样本量是影响工作流选择的关键因素，充足样本量下监督学习更优，样本量不足时迁移学习是可行方案。

Conclusion: 研究结果表明，细粒度间隔预处理与Transformer模型相结合，在监督和迁移学习工作流中均表现出最优性能。RF模型在传统监督学习和直接迁移到相似领域方面，提供了快速的训练和具有竞争力的性能。迁移学习技术提高了工作流的适应性，其中UDA在同质作物类别中效果显著，而微调在各种场景下表现稳健。工作流的选择很大程度上取决于标签样本的可获得性。在样本量充足的情况下，监督训练通常能提供更准确、更具泛化性的结果；而在样本量不足的情况下，与领域迁移程度相匹配的迁移学习是实现作物测绘的可行替代方案。

Abstract: Crop mapping involves identifying and classifying crop types using spatial
data, primarily derived from remote sensing imagery. This study presents the
first comprehensive review of large-scale, pixel-wise crop mapping workflows,
encompassing both conventional supervised methods and emerging transfer
learning approaches. To identify the optimal supervised crop mapping workflows,
we conducted systematic experiments, comparing six widely adopted satellite
image-based preprocessing methods, alongside eleven supervised pixel-wise
classification models. Additionally, we assessed the synergistic impact of
varied training sample sizes and variable combinations. Moreover, we identified
optimal transfer learning techniques for different magnitudes of domain shift.
The evaluation of best methods was conducted across five diverse agricultural
sites. Landsat 8 served as the primary satellite data source. Labels come from
CDL trusted pixels and field surveys.
  Our findings reveal three key insights. First, fine-scale interval
preprocessing paired with Transformer models consistently delivered optimal
performance for both supervised and transferable workflows. RF offered rapid
training and competitive performance in conventional supervised learning and
direct transfer to similar domains. Second, transfer learning techniques
enhanced workflow adaptability, with UDA being effective for homogeneous crop
classes while fine-tuning remains robust across diverse scenarios. Finally,
workflow choice depends heavily on the availability of labeled samples. With a
sufficient sample size, supervised training typically delivers more accurate
and generalizable results. Below a certain threshold, transfer learning that
matches the level of domain shift is a viable alternative to achieve crop
mapping. Repository:
Best-Practices-for-Large-Scale-Pixel-Wise-Crop-Mapping-and-Transfer-Learning-Workflows

</details>


### [5] [CT-ScanGaze: A Dataset and Baselines for 3D Volumetric Scanpath Modeling](https://arxiv.org/abs/2507.12591)
*Trong-Thang Pham,Akash Awasthi,Saba Khan,Esteban Duran Marti,Tien-Phat Nguyen,Khoa Vo,Minh Tran,Ngoc Son Nguyen,Cuong Tran Van,Yuki Ikebe,Anh Totti Nguyen,Anh Nguyen,Zhigang Deng,Carol C. Wu,Hien Van Nguyen,Ngan Le*

Main category: cs.CV

TL;DR: 首次公开CT眼动数据集CT-ScanGaze，并提出3D路径预测器CT-Searcher，有效解决了2D预测器的局限性，并通过预训练和评估框架提升了CT影像分析的准确性。


<details>
  <summary>Details</summary>
Motivation: 理解放射科医生在阅读CT影像时的眼动模式对于开发有效的可解释计算机辅助诊断系统至关重要。现有研究受限于公开眼动数据集的缺乏和CT数据三维复杂性的挑战。

Method: 研究提出了CT-ScanGaze数据集，这是一个公开的CT眼动追踪数据集，以及CT-Searcher模型，一个用于处理CT影像并预测3D注视序列的新型3D路径预测器。此外，研究还开发了一个将2D眼动数据集转换为3D数据的预训练流程。

Result: 通过在CT-ScanGaze数据集上的定性和定量评估，证明了CT-Searcher方法的有效性，并为医学影像中的3D注视路径预测提供了一个全面的评估框架。

Conclusion: 该研究提出了CT-ScanGaze数据集和CT-Searcher模型，用于理解和预测放射科医生在阅读CT影像时的眼动模式，并提供了评估3D眼动预测的框架。

Abstract: Understanding radiologists' eye movement during Computed Tomography (CT)
reading is crucial for developing effective interpretable computer-aided
diagnosis systems. However, CT research in this area has been limited by the
lack of publicly available eye-tracking datasets and the three-dimensional
complexity of CT volumes. To address these challenges, we present the first
publicly available eye gaze dataset on CT, called CT-ScanGaze. Then, we
introduce CT-Searcher, a novel 3D scanpath predictor designed specifically to
process CT volumes and generate radiologist-like 3D fixation sequences,
overcoming the limitations of current scanpath predictors that only handle 2D
inputs. Since deep learning models benefit from a pretraining step, we develop
a pipeline that converts existing 2D gaze datasets into 3D gaze data to
pretrain CT-Searcher. Through both qualitative and quantitative evaluations on
CT-ScanGaze, we demonstrate the effectiveness of our approach and provide a
comprehensive assessment framework for 3D scanpath prediction in medical
imaging.

</details>


### [6] [NeuraLeaf: Neural Parametric Leaf Models with Shape and Deformation Disentanglement](https://arxiv.org/abs/2507.12714)
*Yang Yang,Dongni Mao,Hiroaki Santo,Yasuyuki Matsushita,Fumio Okura*

Main category: cs.CV

TL;DR: 提出了一种用于 3D 叶子的神经参数模型 NeuraLeaf，该模型将叶子几何分解为 2D 基础形状和 3D 变形，可以从 2D 叶子图像数据集中学习基础形状，并同步学习与几何对齐的纹理。


<details>
  <summary>Details</summary>
Motivation: 植物叶子因其多样的形状和灵活的变形而带来独特的挑战，而植物叶子的 3D 参数模型对于农业和计算机图形学至关重要。

Method: 提出了一种新颖的无骨架蒙皮模型来对 3D 变形进行建模，并创建了一个名为 DeformLeaf 的新捕获的 3D 叶子数据集。

Result: NeuraLeaf 成功生成了各种具有变形的叶子形状，从而能够准确地拟合 3D 观测数据。

Conclusion: NeuraLeaf 成功生成了各种具有变形的叶子形状，能够准确地拟合 3D 观测数据（如深度图和点云）。

Abstract: We develop a neural parametric model for 3D leaves for plant modeling and
reconstruction that are essential for agriculture and computer graphics. While
neural parametric models are actively studied for humans and animals, plant
leaves present unique challenges due to their diverse shapes and flexible
deformation. To this problem, we introduce a neural parametric model for
leaves, NeuraLeaf. Capitalizing on the fact that flattened leaf shapes can be
approximated as a 2D plane, NeuraLeaf disentangles the leaves' geometry into
their 2D base shapes and 3D deformations. This representation allows learning
from rich sources of 2D leaf image datasets for the base shapes, and also has
the advantage of simultaneously learning textures aligned with the geometry. To
model the 3D deformation, we propose a novel skeleton-free skinning model and
create a newly captured 3D leaf dataset called DeformLeaf. We show that
NeuraLeaf successfully generates a wide range of leaf shapes with deformation,
resulting in accurate model fitting to 3D observations like depth maps and
point clouds. Our implementation and dataset are available at
https://neuraleaf-yang.github.io/.

</details>


### [7] [MS-DGCNN++: A Multi-Scale Fusion Dynamic Graph Neural Network with Biological Knowledge Integration for LiDAR Tree Species Classification](https://arxiv.org/abs/2507.12602)
*Said Ohamouddou,Abdellatif El Afia,Hanaa El Afia,Raddouane Chiheb*

Main category: cs.CV

TL;DR: 该研究提出了一种名为MS-DGCNN++的新型层级多尺度融合动态图卷积网络，用于从LiDAR点云进行树种分类。与现有方法相比，MS-DGCNN++能更好地捕捉树木结构层次的语义关系，并在多个数据集上取得了更高的准确率，同时具有更低的计算复杂度和参数量，适用于资源受限的应用，并且可泛化到3D物体识别任务。


<details>
  <summary>Details</summary>
Motivation: 树木种类从陆地LiDAR点云分类具有挑战性，因为森林环境中存在复杂的多尺度几何结构。现有的基于多尺度动态图卷积神经网络（MS-DGCNN）的方法虽然采用了多尺度处理，但未能捕捉到树木结构层次之间的语义关系。

Method: 提出了一种名为MS-DGCNN++的层级多尺度融合动态图卷积网络，通过在局部、分支和树冠三个尺度上进行语义特征提取，并结合跨尺度信息传播，解决了现有方法未能捕捉树木结构层次语义关系的问题。该方法采用了特定尺度的特征工程，包括局部尺度的标准几何特征、分支尺度的归一化相对向量以及树冠尺度的距离信息，用语义区分表示取代了统一的并行处理，更好地契合了树木的自然结构。

Result: MS-DGCNN++在STPCTLS数据集上达到了94.96%的准确率，在FOR-species20K数据集上实现了67.25%的准确率（比MS-DGCNN提高了6.1%）。在ModelNet40和ModelNet10数据集上，该方法分别取得了93.15%和94.05%的准确率。与先进的Transformer方法相比，MS-DGCNN++的参数量更少，复杂度更低，同时在3D物体识别任务上表现出优越性。

Conclusion: 该研究提出的MS-DGCNN++在树种分类任务上取得了显著的成果，在STPCTLS数据集上准确率达到94.96%，优于现有多种模型。同时，该方法在FOR-species20K数据集上也实现了6.1%的提升，并在ModelNet40和ModelNet10数据集上展示了其在3D物体识别任务上的优越性。与现有先进的Transformer方法相比，MS-DGCNN++参数量更少，复杂度更低，适用于资源受限的应用场景，同时保持了具有竞争力的准确率。该方法具有通用性，可应用于多种点云处理任务。

Abstract: Tree species classification from terrestrial LiDAR point clouds is
challenging because of the complex multi-scale geometric structures in forest
environments. Existing approaches using multi-scale dynamic graph convolutional
neural networks (MS-DGCNN) employ parallel multi-scale processing, which fails
to capture the semantic relationships between the hierarchical levels of the
tree architecture. We present MS-DGCNN++, a hierarchical multiscale fusion
dynamic graph convolutional network that uses semantically meaningful feature
extraction at local, branch, and canopy scales with cross-scale information
propagation. Our method employs scale-specific feature engineering, including
standard geometric features for the local scale, normalized relative vectors
for the branch scale, and distance information for the canopy scale. This
hierarchical approach replaces uniform parallel processing with semantically
differentiated representations that are aligned with the natural tree
structure. Under the same proposed tree species data augmentation strategy for
all experiments, MS-DGCNN++ achieved an accuracy of 94.96 \% on STPCTLS,
outperforming DGCNN, MS-DGCNN, and the state-of-the-art model PPT. On
FOR-species20K, it achieves 67.25\% accuracy (6.1\% improvement compared to
MS-DGCNN). For standard 3D object recognition, our method outperformed DGCNN
and MS-DGCNN with overall accuracies of 93.15\% on ModelNet40 and 94.05\% on
ModelNet10. With lower parameters and reduced complexity compared to
state-of-the-art transformer approaches, our method is suitable for
resource-constrained applications while maintaining a competitive accuracy.
Beyond tree classification, the method generalizes to standard 3D object
recognition, establishing it as a versatile solution for diverse point cloud
processing applications. The implementation code is publicly available at
https://github.com/said-ohamouddou/MS-DGCNN2.

</details>


### [8] [Predicting Soccer Penalty Kick Direction Using Human Action Recognition](https://arxiv.org/abs/2507.12617)
*David Freire-Obregón,Oliverio J. Santana,Javier Lorenzo-Navarro,Daniel Hernández-Sosa,Modesto Castrillón-Santana*

Main category: cs.CV

TL;DR: 创建了一个包含手动注释的足球点球数据集，并训练了一个深度学习模型来预测射门方向，准确率高达 63.9%。


<details>
  <summary>Details</summary>
Motivation: 现实世界体育场景中的动作预测应用受到可用带注释数据集的限制。

Method: 提出了一种深度学习分类器，该分类器集成了基于 HAR 的特征嵌入和上下文元数据。

Result: 在预测射门方向（左或右）方面达到了 63.9% 的准确率，优于真实守门员的决策。

Conclusion: 该数据集的价值得到了证明，并且我们的模型作为体育预测任务的通用方法具有潜力。

Abstract: Action anticipation has become a prominent topic in Human Action Recognition
(HAR). However, its application to real-world sports scenarios remains limited
by the availability of suitable annotated datasets. This work presents a novel
dataset of manually annotated soccer penalty kicks to predict shot direction
based on pre-kick player movements. We propose a deep learning classifier to
benchmark this dataset that integrates HAR-based feature embeddings with
contextual metadata. We evaluate twenty-two backbone models across seven
architecture families (MViTv2, MViTv1, SlowFast, Slow, X3D, I3D, C2D),
achieving up to 63.9% accuracy in predicting shot direction (left or right),
outperforming the real goalkeepers' decisions. These results demonstrate the
dataset's value for anticipatory action recognition and validate our model's
potential as a generalizable approach for sports-based predictive tasks.

</details>


### [9] [From Neck to Head: Bio-Impedance Sensing for Head Pose Estimation](https://arxiv.org/abs/2507.12884)
*Mengxi Liu,Lala Shakti Swarup Ray,Sizhen Bian,Ko Watanabe,Ankur Bhatt,Joanna Sorysz,Russel Torah,Bo Zhou,Paul Lukowicz*

Main category: cs.CV

TL;DR: NeckSense 是一种利用颈部生物阻抗传感和深度学习进行头部姿态跟踪的可穿戴设备，其性能可与基于计算机视觉的方法相媲美。


<details>
  <summary>Details</summary>
Motivation: 提出了一种名为 NeckSense 的新型可穿戴系统，用于头部姿态跟踪，该系统利用了嵌入轻质、项链式可穿戴设备中的软干电极的多通道生物阻抗传感技术。

Method: 提出了一种深度学习框架，将解剖学先验（包括关节约束和自然的头部旋转范围）集成到损失函数设计中，以稳健地估计头部姿态。

Result: 在 7 名参与者身上进行了验证，在各种头部运动中实现了 25.9 毫米的平均每顶点误差，采用了留一法交叉验证。

Conclusion: NeckSense 系统实现了与 SOTA 计算机视觉方法相当的头部跟踪性能，证明了其作为一种紧凑、无视线要求的生物阻抗可穿戴设备的潜力。

Abstract: We present NeckSense, a novel wearable system for head pose tracking that
leverages multi-channel bio-impedance sensing with soft, dry electrodes
embedded in a lightweight, necklace-style form factor. NeckSense captures
dynamic changes in tissue impedance around the neck, which are modulated by
head rotations and subtle muscle activations. To robustly estimate head pose,
we propose a deep learning framework that integrates anatomical priors,
including joint constraints and natural head rotation ranges, into the loss
function design. We validate NeckSense on 7 participants using the current SOTA
pose estimation model as ground truth. Our system achieves a mean per-vertex
error of 25.9 mm across various head movements with a leave-one-person-out
cross-validation method, demonstrating that a compact, line-of-sight-free
bio-impedance wearable can deliver head-tracking performance comparable to SOTA
vision-based methods.

</details>


### [10] [Funnel-HOI: Top-Down Perception for Zero-Shot HOI Detection](https://arxiv.org/abs/2507.12628)
*Sandipan Sarma,Agney Talwarr,Arijit Sur*

Main category: cs.CV

TL;DR: Funnel-HOI框架通过在编码器阶段引入HOI特定线索和非对称协同注意机制，提升了HOID的性能，尤其是在零样本和长尾场景下。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Transformer的HOID模型主要关注改进解码器以学习交互的纠缠或解缠释，但忽略了在编码器阶段就引入HOI特定线索以获得更强的场景理解。然而，HOID任务由于存在指数级的物体-动作组合，导致标注数据有限，存在长尾分布问题。因此，有必要在编码器阶段就纳入HOI特定线索来提升模型性能。

Method: 该研究提出了一种名为Funnel-HOI的自上而下的框架。首先检测图像中的物体（明确的概念），然后检测与这些物体相关的动作（抽象的概念）。利用新颖的非对称协同注意机制，结合多模态信息（包括零样本能力），在编码器层面提取更强的交互表示。此外，设计了一种考虑物体-动作相关性并能更好地约束误分类的损失函数来指导交互分类器。

Result: 在HICO-DET和V-COCO数据集上进行了广泛的实验，包括全监督和六种零样本设置。结果表明，Funnel-HOI在未见和稀有HOI类别上分别取得了高达12.4%和8.4%的提升，达到了最先进的性能。

Conclusion: 该研究提出了一种名为Funnel-HOI的框架，通过在编码器阶段引入HOI特定线索，并结合非对称协同注意机制和新颖的损失函数，在HICO-DET和V-COCO数据集上实现了最先进的性能，尤其是在未见和稀有HOI类别上取得了显著提升。

Abstract: Human-object interaction detection (HOID) refers to localizing interactive
human-object pairs in images and identifying the interactions. Since there
could be an exponential number of object-action combinations, labeled data is
limited - leading to a long-tail distribution problem. Recently, zero-shot
learning emerged as a solution, with end-to-end transformer-based object
detectors adapted for HOID becoming successful frameworks. However, their
primary focus is designing improved decoders for learning entangled or
disentangled interpretations of interactions. We advocate that HOI-specific
cues must be anticipated at the encoder stage itself to obtain a stronger scene
interpretation. Consequently, we build a top-down framework named Funnel-HOI
inspired by the human tendency to grasp well-defined concepts first and then
associate them with abstract concepts during scene understanding. We first
probe an image for the presence of objects (well-defined concepts) and then
probe for actions (abstract concepts) associated with them. A novel asymmetric
co-attention mechanism mines these cues utilizing multimodal information
(incorporating zero-shot capabilities) and yields stronger interaction
representations at the encoder level. Furthermore, a novel loss is devised that
considers objectaction relatedness and regulates misclassification penalty
better than existing loss functions for guiding the interaction classifier.
Extensive experiments on the HICO-DET and V-COCO datasets across
fully-supervised and six zero-shot settings reveal our state-of-the-art
performance, with up to 12.4% and 8.4% gains for unseen and rare HOI
categories, respectively.

</details>


### [11] [Reconstruct, Inpaint, Finetune: Dynamic Novel-view Synthesis from Monocular Videos](https://arxiv.org/abs/2507.12646)
*Kaihua Chen,Tarasha Khurana,Deva Ramanan*

Main category: cs.CV

TL;DR: CogNVS通过结合3D重建和2D扩散模型（用于图像补全），实现了高效且高质量的动态场景新视角合成，并且能够进行零样本学习。


<details>
  <summary>Details</summary>
Motivation: 现有方法在动态场景的新视角合成方面存在不足，要么需要耗时的测试时优化，要么在进行前馈训练时无法保持场景几何。本研究旨在解决这些问题。

Method: CogNVS是一种基于三维重建和二维视频扩散模型（用于补全被遮挡像素）的新方法。该方法可以从二维视频中进行自监督训练，并能零样本应用于新的测试视频。

Result: CogNVS在动态场景的单目视频新视角合成任务上取得了显著的成果，并且在各种数据集上进行了验证。

Conclusion: CogNVS在动态场景的单目视频新视角合成方面，性能优于几乎所有现有技术。

Abstract: We explore novel-view synthesis for dynamic scenes from monocular videos.
Prior approaches rely on costly test-time optimization of 4D representations or
do not preserve scene geometry when trained in a feed-forward manner. Our
approach is based on three key insights: (1) covisible pixels (that are visible
in both the input and target views) can be rendered by first reconstructing the
dynamic 3D scene and rendering the reconstruction from the novel-views and (2)
hidden pixels in novel views can be "inpainted" with feed-forward 2D video
diffusion models. Notably, our video inpainting diffusion model (CogNVS) can be
self-supervised from 2D videos, allowing us to train it on a large corpus of
in-the-wild videos. This in turn allows for (3) CogNVS to be applied zero-shot
to novel test videos via test-time finetuning. We empirically verify that
CogNVS outperforms almost all prior art for novel-view synthesis of dynamic
scenes from monocular videos.

</details>


### [12] [Integrated Oculomics and Lipidomics Reveal Microvascular Metabolic Signatures Associated with Cardiovascular Health in a Healthy Cohort](https://arxiv.org/abs/2507.12663)
*Inamullah,Ernesto Elias Vidal Rosas,Imran Razzak,Shoaib Jameel*

Main category: cs.CV

TL;DR: 本研究整合了眼底照片和血液脂质数据，发现眼底血管特征与特定血脂成分（如甘油三酯）相关，有望用于心血管疾病的早期筛查。


<details>
  <summary>Details</summary>
Motivation: 现有心血管疾病（CVD）风险分层方法在检测早期、亚临床变化方面存在不足，本研究旨在整合视网膜微血管特征和全面的血清脂质组学特征，以识别心血管疾病的早期、无症状生物标志物。

Method: 本研究采用了一种创新的影像组学框架，结合了基于深度学习的视网膜图像处理技术和超高效液相色谱-电喷雾离子化-高分辨率质谱（UHPLC ESI HRMS）技术进行血清脂质组学分析，旨在发现传统脂质检查之外的无症状心血管风险生物标志物。

Result: 研究发现了视网膜微血管特征（如平均动脉宽度、血管密度）与特定血清脂质亚类（如三酰甘油、二酰甘油、神经酰胺）之间存在强烈的、与年龄和性别无关的相关性，这表明在代谢应激下可能存在微血管重塑的共通机制。

Conclusion: 本研究通过整合深度学习分析的视网膜微血管特征和高分辨率质谱分析的血清组学数据，发现了与心血管疾病风险相关的早期生物标志物，特别是甘油三酯、二酰甘油和神经酰胺等脂质亚类与视网膜血管的平均动脉宽度和血管密度之间存在显著相关性，这为心血管疾病的早期检测、靶向预防和个性化治疗提供了新的视角和机遇。

Abstract: Cardiovascular disease (CVD) remains the leading global cause of mortality,
yet current risk stratification methods often fail to detect early, subclinical
changes. Previous studies have generally not integrated retinal
microvasculature characteristics with comprehensive serum lipidomic profiles as
potential indicators of CVD risk. In this study, an innovative imaging omics
framework was introduced, combining retinal microvascular traits derived
through deep learning based image processing with serum lipidomic data to
highlight asymptomatic biomarkers of cardiovascular risk beyond the
conventional lipid panel. This represents the first large scale, covariate
adjusted and stratified correlation analysis conducted in a healthy population,
which is essential for identifying early indicators of disease. Retinal
phenotypes were quantified using automated image analysis tools, while serum
lipid profiling was performed by Ultra High Performance Liquid Chromatography
Electrospray ionization High resolution mass spectrometry (UHPLC ESI HRMS).
Strong, age- and sex-independent correlations were established, particularly
between average artery width, vessel density, and lipid subclasses such as
triacylglycerols (TAGs), diacylglycerols (DAGs), and ceramides (Cers). These
associations suggest a converging mechanism of microvascular remodeling under
metabolic stress. By linking detailed
  vascular structural phenotypes to specific lipid species, this study fills a
critical gap in the understanding of early CVD pathogenesis. This integration
not only offers a novel perspective on microvascular metabolic associations but
also presents a significant opportunity for the identification of robust,
non-invasive biomarkers. Ultimately, these findings may support improved early
detection, targeted prevention, and personalized approaches in cardiovascular
healthcare.

</details>


### [13] [FORTRESS: Function-composition Optimized Real-Time Resilient Structural Segmentation via Kolmogorov-Arnold Enhanced Spatial Attention Networks](https://arxiv.org/abs/2507.12675)
*Christina Thrainer,Md Meftahul Ferdaus,Mahdi Abdelguerfi,Christian Guetl,Steven Sloan,Kendall N. Niles,Ken Pathak*

Main category: cs.CV

TL;DR: FORTRESS is a new architecture for structural defect segmentation that significantly reduces parameters (91%), computational complexity (91%), and improves inference speed (3x) while achieving state-of-the-art accuracy (F1: 0.771, mIoU: 0.677) using depthwise separable convolutions and adaptive KAN integration.


<details>
  <summary>Details</summary>
Motivation: To address the critical challenge of achieving high accuracy and computational efficiency for real-time deployment in automated structural defect segmentation for civil infrastructure.

Method: FORTRESS architecture utilizes a combination of depthwise separable convolutions (3.6x parameter reduction per layer) and adaptive Kolmogorov-Arnold Network (KAN) integration, along with multi-scale attention fusion. It achieves 91% parameter reduction, 91% computational complexity reduction, and 3x inference speed improvement.

Result: FORTRESS achieves state-of-the-art results with an F1-score of 0.771 and a mean IoU of 0.677, outperforming existing methods like U-Net, SA-UNet, and U-KAN. It also demonstrates significant efficiency gains.

Conclusion: FORTRESS is a robust solution for practical structural defect segmentation in resource-constrained environments, balancing accuracy and computational efficiency with state-of-the-art results.

Abstract: Automated structural defect segmentation in civil infrastructure faces a
critical challenge: achieving high accuracy while maintaining computational
efficiency for real-time deployment. This paper presents FORTRESS
(Function-composition Optimized Real-Time Resilient Structural Segmentation), a
new architecture that balances accuracy and speed by using a special method
that combines depthwise separable convolutions with adaptive Kolmogorov-Arnold
Network integration. FORTRESS incorporates three key innovations: a systematic
depthwise separable convolution framework achieving a 3.6x parameter reduction
per layer, adaptive TiKAN integration that selectively applies function
composition transformations only when computationally beneficial, and
multi-scale attention fusion combining spatial, channel, and KAN-enhanced
features across decoder levels. The architecture achieves remarkable efficiency
gains with 91% parameter reduction (31M to 2.9M), 91% computational complexity
reduction (13.7 to 1.17 GFLOPs), and 3x inference speed improvement while
delivering superior segmentation performance. Evaluation on benchmark
infrastructure datasets demonstrates state-of-the-art results with an F1- score
of 0.771 and a mean IoU of 0.677, significantly outperforming existing methods
including U-Net, SA-UNet, and U- KAN. The dual optimization strategy proves
essential for optimal performance, establishing FORTRESS as a robust solution
for practical structural defect segmentation in resource-constrained
environments where both accuracy and computational efficiency are paramount.
Comprehensive architectural specifications are provided in the Supplemental
Material. Source code is available at URL:
https://github.com/faeyelab/fortress-paper-code.

</details>


### [14] [SOD-YOLO: Enhancing YOLO-Based Detection of Small Objects in UAV Imagery](https://arxiv.org/abs/2507.12727)
*Peijun Wang,Jinhua Zhao*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Small object detection remains a challenging problem in the field of object
detection. To address this challenge, we propose an enhanced YOLOv8-based
model, SOD-YOLO. This model integrates an ASF mechanism in the neck to enhance
multi-scale feature fusion, adds a Small Object Detection Layer (named P2) to
provide higher-resolution feature maps for better small object detection, and
employs Soft-NMS to refine confidence scores and retain true positives.
Experimental results demonstrate that SOD-YOLO significantly improves detection
performance, achieving a 36.1% increase in mAP$_{50:95}$ and 20.6% increase in
mAP$_{50}$ on the VisDrone2019-DET dataset compared to the baseline model.
These enhancements make SOD-YOLO a practical and efficient solution for small
object detection in UAV imagery. Our source code, hyper-parameters, and model
weights are available at https://github.com/iamwangxiaobai/SOD-YOLO.

</details>


### [15] [A Privacy-Preserving Semantic-Segmentation Method Using Domain-Adaptation Technique](https://arxiv.org/abs/2507.12730)
*Homare Sueyoshi,Kiyoshi Nishikawa,Hitoshi Kiya*

Main category: cs.CV

TL;DR: 提出了一种基于 ViT 域适应技术的隐私保护语义分割方法，实现了感知加密，准确率接近未加密模型。


<details>
  <summary>Details</summary>
Motivation: 为应用于模型训练的图像提供隐私保护的感知加密，同时保持模型准确率。

Method: 利用 Vision Transformer (ViT) 的嵌入结构的域适应技术。

Result: 实验证明了该方法在语义分割准确率方面是有效的，特别是在使用基于 ViT 的 Segmentation Transformer 模型时。

Conclusion: 提出了一种用于模型训练图像和测试图像的隐私保护语义分割方法，实现了感知加密，且准确率与未加密模型相当。

Abstract: We propose a privacy-preserving semantic-segmentation method for applying
perceptual encryption to images used for model training in addition to test
images. This method also provides almost the same accuracy as models without
any encryption. The above performance is achieved using a domain-adaptation
technique on the embedding structure of the Vision Transformer (ViT). The
effectiveness of the proposed method was experimentally confirmed in terms of
the accuracy of semantic segmentation when using a powerful
semantic-segmentation model with ViT called Segmentation Transformer.

</details>


### [16] [Transformer-based Spatial Grounding: A Comprehensive Survey](https://arxiv.org/abs/2507.12739)
*Ijazul Haq,Muhammad Saqib,Yingjie Zhang*

Main category: cs.CV

TL;DR: 本篇论文对基于Transformer的空间接地技术进行了全面的文献综述，总结了模型、数据集、评估方法和未来趋势，为相关领域的研究和应用提供了指导。


<details>
  <summary>Details</summary>
Motivation: 当前基于Transformer的空间接地领域在模型、数据集、评估指标和工业应用方面缺乏全面的综合，本研究旨在填补这一空白。

Method: 本研究采用系统性文献回顾的方法，对2018年至2025年间基于Transformer的空间接地方法进行了分析。

Result: 本研究识别了主流模型架构、常用数据集和评估指标，并强调了关键方法趋势和最佳实践。

Conclusion: 该研究系统地回顾了2018年至2025年间基于Transformer的空间接地方法，识别了主流模型架构、常用数据集和评估指标，并强调了关键方法趋势和最佳实践，为研究人员和从业者提供了宝贵的见解和结构化指导，以促进开发稳健、可靠且适合工业应用的空间接地模型。

Abstract: Spatial grounding, the process of associating natural language expressions
with corresponding image regions, has rapidly advanced due to the introduction
of transformer-based models, significantly enhancing multimodal representation
and cross-modal alignment. Despite this progress, the field lacks a
comprehensive synthesis of current methodologies, dataset usage, evaluation
metrics, and industrial applicability. This paper presents a systematic
literature review of transformer-based spatial grounding approaches from 2018
to 2025. Our analysis identifies dominant model architectures, prevalent
datasets, and widely adopted evaluation metrics, alongside highlighting key
methodological trends and best practices. This study provides essential
insights and structured guidance for researchers and practitioners,
facilitating the development of robust, reliable, and industry-ready
transformer-based spatial grounding models.

</details>


### [17] [Domain-Enhanced Dual-Branch Model for Efficient and Interpretable Accident Anticipation](https://arxiv.org/abs/2507.12755)
*Yanchen Guan,Haicheng Liao,Chengyue Wang,Bonan Wang,Jiaxun Zhang,Jia Hu,Zhenning Li*

Main category: cs.CV

TL;DR: 本研究提出了一种创新的交通意外预测框架，该框架结合了视频和文本数据，并利用先进的大型模型和提示工程技术，在准确性、响应速度、计算效率和可解释性方面均取得了领先成果。


<details>
  <summary>Details</summary>
Motivation: 开发精确且计算高效的交通意外预测系统对于当前的自动驾驶技术至关重要，能够实现及时的干预和减少损失。

Method: 本研究提出了一个采用双分支架构的交通意外预测框架，该框架有效整合了来自行车记录仪视频的视觉信息和源自事故报告的结构化文本数据。此外，研究引入了一种特征聚合方法，利用大型模型（GPT-4o, Long-CLIP）促进多模态输入的无缝集成，并通过有针对性的提示工程策略生成可操作的反馈和标准化的事故档案。

Result: 在DAD、CCD和A3D等基准数据集上的综合评估验证了本研究方法的优越预测准确性、增强的响应能力、降低的计算开销和提高的可解释性。

Conclusion: 该研究提出的双分支架构框架通过融合视觉信息和结构化文本数据，并在大型模型和提示工程的加持下，实现了交通意外预测的更高准确性、更快速响应、更低计算开销和更强可解释性，为交通意外预测树立了新的标杆。

Abstract: Developing precise and computationally efficient traffic accident
anticipation system is crucial for contemporary autonomous driving
technologies, enabling timely intervention and loss prevention. In this paper,
we propose an accident anticipation framework employing a dual-branch
architecture that effectively integrates visual information from dashcam videos
with structured textual data derived from accident reports. Furthermore, we
introduce a feature aggregation method that facilitates seamless integration of
multimodal inputs through large models (GPT-4o, Long-CLIP), complemented by
targeted prompt engineering strategies to produce actionable feedback and
standardized accident archives. Comprehensive evaluations conducted on
benchmark datasets (DAD, CCD, and A3D) validate the superior predictive
accuracy, enhanced responsiveness, reduced computational overhead, and improved
interpretability of our approach, thus establishing a new benchmark for
state-of-the-art performance in traffic accident anticipation.

</details>


### [18] [HairShifter: Consistent and High-Fidelity Video Hair Transfer via Anchor-Guided Animation](https://arxiv.org/abs/2507.12758)
*Wangzheng Shi,Yinglin Zheng,Yuxin Lin,Jianmin Bao,Ming Zeng,Dong Chen*

Main category: cs.CV

TL;DR: 提出了一种名为HairShifter的新框架，用于视频发型转换。它结合了高质量的图像发型转换和流畅的视频动画，通过“锚定帧+动画”的方法解决了时间一致性和空间保真度等挑战。实验证明，HairShifter在视觉质量、时间一致性和可扩展性方面均优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 解决视频发型转换中的挑战，如时间一致性、空间保真度和动态适应性，同时在社交媒体、游戏、广告和娱乐等领域提供高价值的头发转移。

Method: 提出了一种新颖的“锚定帧+动画”框架HairShifter，该框架集成了图像发型转换（IHT）模块和多尺度门控SPADE解码器，以实现精确的逐帧转换、无缝的空间混合和时间一致性。

Result: HairShifter在视频发型转换方面实现了最先进的性能，具有卓越的视觉质量、时间一致性和可扩展性，同时保持了发型保真度和非毛发区域的完整性。

Conclusion: HairShifter在视频发型转换方面取得了最先进的性能，结合了卓越的视觉质量、时间一致性和可扩展性。该方法有望为基于视频的发型转换开辟新途径，并在该领域建立稳健的基准。

Abstract: Hair transfer is increasingly valuable across domains such as social media,
gaming, advertising, and entertainment. While significant progress has been
made in single-image hair transfer, video-based hair transfer remains
challenging due to the need for temporal consistency, spatial fidelity, and
dynamic adaptability. In this work, we propose HairShifter, a novel "Anchor
Frame + Animation" framework that unifies high-quality image hair transfer with
smooth and coherent video animation. At its core, HairShifter integrates a
Image Hair Transfer (IHT) module for precise per-frame transformation and a
Multi-Scale Gated SPADE Decoder to ensure seamless spatial blending and
temporal coherence. Our method maintains hairstyle fidelity across frames while
preserving non-hair regions. Extensive experiments demonstrate that HairShifter
achieves state-of-the-art performance in video hairstyle transfer, combining
superior visual quality, temporal consistency, and scalability. The code will
be publicly available. We believe this work will open new avenues for
video-based hairstyle transfer and establish a robust baseline in this field.

</details>


### [19] [Unified Medical Image Segmentation with State Space Modeling Snake](https://arxiv.org/abs/2507.12760)
*Ruicheng Zhang,Haowei Guo,Kanghui Tian,Jun Zhou,Mingliang Yan,Zeyu Zhang,Shen Zhao*

Main category: cs.CV

TL;DR: Mamba Snake是一种新颖的深度蛇形框架，利用状态空间模型进行统一医学图像分割，通过模拟器官间拓扑关系和轮廓细化，并结合MEB模块和双分类机制，在处理复杂形态和异构数据方面表现出色，平均Dice分数比现有方法提高了3%。


<details>
  <summary>Details</summary>
Motivation: 统一医学图像分割（UMIS）对于全面的解剖评估至关重要，但由于多尺度结构异质性而面临挑战。传统的基于像素的方法缺乏对象级解剖洞察力和器官间关系建模，难以应对形态复杂性和特征冲突，从而限制了它们在UMIS中的功效。

Method: 提出了一种新颖的深度蛇形框架Mamba Snake，并利用状态空间模型进行统一医学图像分割。该框架将多轮廓演化构建为分层状态空间图谱，以模拟宏观的器官间拓扑关系和微观的轮廓细化。引入了针对蛇形设计的视觉状态空间模块Mamba Evolution Block（MEB），它利用有效的时空信息聚合来适应性地优化复杂的形态。能量图形状先验确保了在异构数据中进行鲁棒的远程轮廓演化。此外，还引入了一个双分类协同机制，以同时优化检测和分割，从而减轻了统一医学图像分割中微观结构的欠分割问题。

Result: Mamba Snake在五个临床数据集上进行了广泛评估，平均Dice分数比最先进的方法提高了3%。

Conclusion: Mamba Snake在五个临床数据集上的广泛评估显示其性能优越，平均Dice分数比最先进的方法提高了3%。

Abstract: Unified Medical Image Segmentation (UMIS) is critical for comprehensive
anatomical assessment but faces challenges due to multi-scale structural
heterogeneity. Conventional pixel-based approaches, lacking object-level
anatomical insight and inter-organ relational modeling, struggle with
morphological complexity and feature conflicts, limiting their efficacy in
UMIS. We propose Mamba Snake, a novel deep snake framework enhanced by state
space modeling for UMIS. Mamba Snake frames multi-contour evolution as a
hierarchical state space atlas, effectively modeling macroscopic inter-organ
topological relationships and microscopic contour refinements. We introduce a
snake-specific vision state space module, the Mamba Evolution Block (MEB),
which leverages effective spatiotemporal information aggregation for adaptive
refinement of complex morphologies. Energy map shape priors further ensure
robust long-range contour evolution in heterogeneous data. Additionally, a
dual-classification synergy mechanism is incorporated to concurrently optimize
detection and segmentation, mitigating under-segmentation of microstructures in
UMIS. Extensive evaluations across five clinical datasets reveal Mamba Snake's
superior performance, with an average Dice improvement of 3\% over
state-of-the-art methods.

</details>


### [20] [Think-Before-Draw: Decomposing Emotion Semantics & Fine-Grained Controllable Expressive Talking Head Generation](https://arxiv.org/abs/2507.12761)
*Hanlei Shi,Leyuan Qu,Yu Liu,Di Gao,Yuhua Zheng,Taihao Li*

Main category: cs.CV

TL;DR: 通过思维链解析情感为面部肌肉运动，并结合艺术绘画的渐进式优化策略，改进了文本驱动的情感Talking-head生成效果。


<details>
  <summary>Details</summary>
Motivation: 当前文本驱动的情感Talking-head生成方法依赖于预定义的离散情感标签，未能捕捉真实面部肌肉运动的动态复杂性，导致情感表达不够自然。

Method: 该研究提出的Think-Before-Draw框架，通过引入思维链（CoT）将情感标签转化为面部肌肉运动描述，并采用渐进式引导去噪策略，结合“全局情感定位-局部肌肉控制”机制来优化生成视频中的微表情动态。

Result: 实验证明，该方法在MEAD和HDTF等常用基准上取得了最先进的性能，并能有效地进行零样本生成。

Conclusion: 该研究提出的Think-Before-Draw框架通过引入思维链（CoT）进行深度语义解析，将抽象的情感标签转化为生理学上可行的面部肌肉运动描述，并采用“全局情感定位-局部肌肉控制”机制进行细粒度表达优化，实现了超越现有方法的性能，并在MEAD和HDTF等基准上取得了最先进的成果，同时评估了其零样本生成能力。

Abstract: Emotional talking-head generation has emerged as a pivotal research area at
the intersection of computer vision and multimodal artificial intelligence,
with its core value lying in enhancing human-computer interaction through
immersive and empathetic engagement.With the advancement of multimodal large
language models, the driving signals for emotional talking-head generation has
shifted from audio and video to more flexible text. However, current
text-driven methods rely on predefined discrete emotion label texts,
oversimplifying the dynamic complexity of real facial muscle movements and thus
failing to achieve natural emotional expressiveness.This study proposes the
Think-Before-Draw framework to address two key challenges: (1) In-depth
semantic parsing of emotions--by innovatively introducing Chain-of-Thought
(CoT), abstract emotion labels are transformed into physiologically grounded
facial muscle movement descriptions, enabling the mapping from high-level
semantics to actionable motion features; and (2) Fine-grained expressiveness
optimization--inspired by artists' portrait painting process, a progressive
guidance denoising strategy is proposed, employing a "global emotion
localization--local muscle control" mechanism to refine micro-expression
dynamics in generated videos.Our experiments demonstrate that our approach
achieves state-of-the-art performance on widely-used benchmarks, including MEAD
and HDTF. Additionally, we collected a set of portrait images to evaluate our
model's zero-shot generation capability.

</details>


### [21] [World Model-Based End-to-End Scene Generation for Accident Anticipation in Autonomous Driving](https://arxiv.org/abs/2507.12762)
*Yanchen Guan,Haicheng Liao,Chengyue Wang,Xingcheng Liu,Jiaxun Zhang,Zhenning Li*

Main category: cs.CV

TL;DR: 为解决自动驾驶安全中的数据稀疏和线索缺失问题，本研究提出了一个结合视频生成和时序推理的框架，并通过新数据集进行验证，显著提高了事故预测能力。


<details>
  <summary>Details</summary>
Motivation: 为了提高自动驾驶系统的可靠性，需要能够准确预测交通事故，但现有技术面临训练数据稀疏和关键对象线索缺失的挑战。

Method: 本文提出了一种结合生成场景增强（使用由领域信息提示指导的世界模型生成视频，以覆盖边缘案例和复杂交互）和自适应时序推理（通过加强图卷积和扩展时序算子来编码时空关系，以解决数据不完整和瞬时视觉噪声问题）的综合框架。

Result: 实验结果表明，该框架在公开和新发布的交通数据集上，均能提升交通事故预测的准确性和提前量，有效解决了当前数据和模型在安全关键型自动驾驶应用中的局限性。

Conclusion: 本文提出的框架通过结合生成场景增强和自适应时序推理，提高了交通事故预测的准确性和提前量，为自动驾驶系统的安全应用提供了鲁棒的解决方案。

Abstract: Reliable anticipation of traffic accidents is essential for advancing
autonomous driving systems. However, this objective is limited by two
fundamental challenges: the scarcity of diverse, high-quality training data and
the frequent absence of crucial object-level cues due to environmental
disruptions or sensor deficiencies. To tackle these issues, we propose a
comprehensive framework combining generative scene augmentation with adaptive
temporal reasoning. Specifically, we develop a video generation pipeline that
utilizes a world model guided by domain-informed prompts to create
high-resolution, statistically consistent driving scenarios, particularly
enriching the coverage of edge cases and complex interactions. In parallel, we
construct a dynamic prediction model that encodes spatio-temporal relationships
through strengthened graph convolutions and dilated temporal operators,
effectively addressing data incompleteness and transient visual noise.
Furthermore, we release a new benchmark dataset designed to better capture
diverse real-world driving risks. Extensive experiments on public and newly
released datasets confirm that our framework enhances both the accuracy and
lead time of accident anticipation, offering a robust solution to current data
and modeling limitations in safety-critical autonomous driving applications.

</details>


### [22] [Continuous Marine Tracking via Autonomous UAV Handoff](https://arxiv.org/abs/2507.12763)
*Heegyeong Kim,Alice James,Avishkar Seth,Endrowednes Kuantama,Jane Williamson,Yimeng Feng,Richard Han*

Main category: cs.CV

TL;DR: 介绍了一种用于追踪鲨鱼的自主无人机视觉系统，通过无人机之间的交接协议克服了电池限制，实现了高跟踪成功率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为在动态海洋环境中连续、实时追踪海洋动物（特别是鲨鱼）提供解决方案，克服单无人机电池限制。

Method: 提出了一种集成了机载计算机、稳定RGB-D相机和定制训练的OSTrack管道的自主无人机视觉系统，并设计了一种无人机之间的交接协议。

Result: 在包含5200帧的鲨鱼数据集上进行了性能评估，在100Hz的实时飞行控制下实现了81.9%的跟踪成功率，并且对遮挡、光照变化和背景杂波具有鲁棒性。无人机交接框架实现了82.9%的目标覆盖率。

Conclusion: 该研究证实了协调无人机操作在扩展海洋追踪方面的可行性，并为可扩展、自主监测奠定了基础。

Abstract: This paper introduces an autonomous UAV vision system for continuous,
real-time tracking of marine animals, specifically sharks, in dynamic marine
environments. The system integrates an onboard computer with a stabilised RGB-D
camera and a custom-trained OSTrack pipeline, enabling visual identification
under challenging lighting, occlusion, and sea-state conditions. A key
innovation is the inter-UAV handoff protocol, which enables seamless transfer
of tracking responsibilities between drones, extending operational coverage
beyond single-drone battery limitations. Performance is evaluated on a curated
shark dataset of 5,200 frames, achieving a tracking success rate of 81.9\%
during real-time flight control at 100 Hz, and robustness to occlusion,
illumination variation, and background clutter. We present a seamless UAV
handoff framework, where target transfer is attempted via high-confidence
feature matching, achieving 82.9\% target coverage. These results confirm the
viability of coordinated UAV operations for extended marine tracking and lay
the groundwork for scalable, autonomous monitoring.

</details>


### [23] [AnyPos: Automated Task-Agnostic Actions for Bimanual Manipulation](https://arxiv.org/abs/2507.12768)
*Hengkai Tan,Yao Feng,Xinyi Mao,Shuhe Huang,Guodong Liu,Zhongkai Hao,Hang Su,Jun Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种名为 AnyPos-ATARA 的新方法，该方法通过任务无关型动作范式和自动化的数据收集框架（ATARA）来提高机器人操作的效率和可扩展性。该方法还引入了一个名为 AnyPos 的逆动力学模型，以提高从任务无关型数据中学习的有效性。实验结果表明，该方法在各种机器人操作任务中显著提高了准确率和成功率。


<details>
  <summary>Details</summary>
Motivation: 现有视-语-行 (VLA) 模型在复杂设置（如双臂操作）的任务条件控制方面显示出潜力。然而，它们对特定任务的人类演示的依赖限制了泛化能力，并增加了数据采集成本。本文旨在通过任务无关型动作范式来解决这些问题，以提高可扩展性、效率和成本效益。

Method: 本文提出了任务无关型动作范式，以解耦动作执行和任务特定条件。为应对数据收集挑战，引入了 ATARA（自动化任务无关型随机动作）框架，其自我监督学习框架可加速数据收集。为有效学习任务无关型数据，提出了 AnyPos，一个配备了手臂解耦估计和方向感知解码器（DAD）的逆动力学模型。此外，还集成了一个视频条件动作验证模块。

Result: ATARA 将数据收集速度比人工遥操作提高了 30 倍以上。AnyPos-ATARA 流程在下游任务中的测试准确率提高了 51%，成功率提高了 30-40%。

Conclusion: AnyPos-ATARA 流程通过回放式视频验证，在测试准确率方面提高了 51%，并在提升、抓取、点击等下游任务中实现了 30-40% 的更高成功率。

Abstract: Vision-language-action (VLA) models have shown promise on task-conditioned
control in complex settings such as bimanual manipulation. However, the heavy
reliance on task-specific human demonstrations limits their generalization and
incurs high data acquisition costs. In this work, we present a new notion of
task-agnostic action paradigm that decouples action execution from
task-specific conditioning, enhancing scalability, efficiency, and
cost-effectiveness. To address the data collection challenges posed by this
paradigm -- such as low coverage density, behavioral redundancy, and safety
risks -- we introduce ATARA (Automated Task-Agnostic Random Actions), a
scalable self-supervised framework that accelerates collection by over $
30\times $ compared to human teleoperation. To further enable effective
learning from task-agnostic data, which often suffers from distribution
mismatch and irrelevant trajectories, we propose AnyPos, an inverse dynamics
model equipped with Arm-Decoupled Estimation and a Direction-Aware Decoder
(DAD). We additionally integrate a video-conditioned action validation module
to verify the feasibility of learned policies across diverse manipulation
tasks. Extensive experiments show that the AnyPos-ATARA pipeline yields a 51%
improvement in test accuracy and achieves 30-40% higher success rates in
downstream tasks such as lifting, pick-and-place, and clicking, using
replay-based video validation. Project Page:
https://embodiedfoundation.github.io/vidar_anypos

</details>


### [24] [Local Representative Token Guided Merging for Text-to-Image Generation](https://arxiv.org/abs/2507.12771)
*Min-Jeong Lee,Hee-Dong Kim,Seong-Whan Lee*

Main category: cs.CV

TL;DR: ReToM是一种新颖的token合并策略，通过保留局部特征和最小化计算开销来提高Stable Diffusion等图像生成模型的效率和质量。


<details>
  <summary>Details</summary>
Motivation: 为了解决Stable Diffusion模型中由于注意力操作的二次复杂度导致的耗时生成问题，并改进现有token合并方法在注意力机制图像生成模型特性方面的不足。

Method: ReToM是一种新颖的token合并策略，适用于图像生成中的任何注意力机制。它通过定义局部边界（窗口）并调整窗口大小来合并基于各种上下文信息的token。此外，它引入了一个代表性token，通过计算特定时间步的相似度并选择具有最高平均相似度的token来表示每个窗口中的代表性token。

Result: ReToM在FID上实现了6.2%的提升，并且CLIP分数更高，同时保持了可比的推理时间，证明了其在平衡视觉质量和计算效率方面的有效性。

Conclusion: ReToM通过保留最显着的局部特征并最小化计算开销，在视觉质量和计算效率之间取得了有效平衡。

Abstract: Stable diffusion is an outstanding image generation model for text-to-image,
but its time-consuming generation process remains a challenge due to the
quadratic complexity of attention operations. Recent token merging methods
improve efficiency by reducing the number of tokens during attention
operations, but often overlook the characteristics of attention-based image
generation models, limiting their effectiveness. In this paper, we propose
local representative token guided merging (ReToM), a novel token merging
strategy applicable to any attention mechanism in image generation. To merge
tokens based on various contextual information, ReToM defines local boundaries
as windows within attention inputs and adjusts window sizes. Furthermore, we
introduce a representative token, which represents the most representative
token per window by computing similarity at a specific timestep and selecting
the token with the highest average similarity. This approach preserves the most
salient local features while minimizing computational overhead. Experimental
results show that ReToM achieves a 6.2% improvement in FID and higher CLIP
scores compared to the baseline, while maintaining comparable inference time.
We empirically demonstrate that ReToM is effective in balancing visual quality
and computational efficiency.

</details>


### [25] [Compact Vision Transformer by Reduction of Kernel Complexity](https://arxiv.org/abs/2507.12780)
*Yancheng Wang,Yingzhen Yang*

Main category: cs.CV

TL;DR: KCR-Transformer reduces computational cost in vision transformers through differentiable channel selection guided by theoretical generalization bounds, improving performance and efficiency.


<details>
  <summary>Details</summary>
Motivation: Integrating transformer blocks into compact neural architectures for computer vision has led to efficient vision transformers. This work aims to further reduce the computational cost of these models while maintaining or improving accuracy.

Method: Introducing KCR-Transformer, a compact transformer block with differentiable channel selection in MLP layers to reduce computational cost. Rigorous theoretical analysis establishes a tight generalization bound for networks equipped with KCR-Transformer blocks, ensuring generalization-aware channel pruning.

Result: KCR-Transformer networks demonstrate superior performance on various computer vision tasks, achieving better results than original models with fewer FLOPs and parameters. Replacing transformer blocks with KCR-Transformer blocks in ViT and Swin architectures leads to significant reductions in computational cost with maintained or improved accuracy.

Conclusion: KCR-Transformer, a compact transformer block with differentiable channel selection guided by a novel theoretical generalization bound, can reduce computational cost and maintain or improve prediction accuracy in vision transformers. Replacing existing blocks with KCR-Transformer blocks results in networks with superior performance on various computer vision tasks.

Abstract: Self-attention and transformer architectures have become foundational
components in modern deep learning. Recent efforts have integrated transformer
blocks into compact neural architectures for computer vision, giving rise to
various efficient vision transformers. In this work, we introduce Transformer
with Kernel Complexity Reduction, or KCR-Transformer, a compact transformer
block equipped with differentiable channel selection, guided by a novel and
sharp theoretical generalization bound. KCR-Transformer performs input/output
channel selection in the MLP layers of transformer blocks to reduce the
computational cost. Furthermore, we provide a rigorous theoretical analysis
establishing a tight generalization bound for networks equipped with
KCR-Transformer blocks. Leveraging such strong theoretical results, the channel
pruning by KCR-Transformer is conducted in a generalization-aware manner,
ensuring that the resulting network retains a provably small generalization
error. Our KCR-Transformer is compatible with many popular and compact
transformer networks, such as ViT and Swin, and it reduces the FLOPs of the
vision transformers while maintaining or even improving the prediction
accuracy. In the experiments, we replace all the transformer blocks in the
vision transformers with KCR-Transformer blocks, leading to KCR-Transformer
networks with different backbones. The resulting TCR-Transformers achieve
superior performance on various computer vision tasks, achieving even better
performance than the original models with even less FLOPs and parameters.

</details>


### [26] [City-VLM: Towards Multidomain Perception Scene Understanding via Multimodal Incomplete Learning](https://arxiv.org/abs/2507.12795)
*Penglei Sun,Yaoxian Song,Xiangru Zhu,Xiang Liu,Qiang Wang,Yue Liu,Changqun Xia,Tiefeng Li,Yang Yang,Xiaowen Chu*

Main category: cs.CV

TL;DR: 该研究提出了SVM-City数据集和City-VLM模型，解决了现有LVLMs在户外场景理解中的局限性，通过不完整的模态学习有效融合多模态信息，并在户外场景问答任务上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（LVLMs）在户外场景理解方面存在局限性：1）它们主要关注室内环境和单视角（如人形视角），而户外场景尺度更大、视角更多样（如鸟瞰图和地面视角）。2）它们缺乏多领域感知户外数据，并且难以有效融合2D和3D视觉信息。

Method: 提出了一种名为City-VLM的语言视觉模型，并采用不完整的模态学习方法来处理缺失模态的情况。通过构建联合概率分布空间而非显式融合操作（如拼接）来实现多模态融合。该数据集（SVM-City）包含来自车辆、低空无人机、高空飞机和卫星的420k图像和4,811M点云，以及567k的问答对。

Result: City-VLM在三个典型的户外场景理解任务上，相比现有LVLMs平均性能提升了18.14%，在问答任务上表现尤为突出。研究结果表明该方法在多个户外场景下具有实用性和泛化能力。

Conclusion: 该研究首次构建了一个名为SVM-City的多模态感知户外场景理解数据集，并提出了City-VLM模型，通过不完整的模态学习有效融合2D和3D视觉信息，在三个典型的户外场景理解任务上平均性能提升了18.14%，证明了其在多场景下的实用性和泛化能力。

Abstract: Scene understanding enables intelligent agents to interpret and comprehend
their environment. While existing large vision-language models (LVLMs) for
scene understanding have primarily focused on indoor household tasks, they face
two significant limitations when applied to outdoor large-scale scene
understanding. First, outdoor scenarios typically encompass larger-scale
environments observed through various sensors from multiple viewpoints (e.g.,
bird view and terrestrial view), while existing indoor LVLMs mainly analyze
single visual modalities within building-scale contexts from humanoid
viewpoints. Second, existing LVLMs suffer from missing multidomain perception
outdoor data and struggle to effectively integrate 2D and 3D visual
information. To address the aforementioned limitations, we build the first
multidomain perception outdoor scene understanding dataset, named
\textbf{\underline{SVM-City}}, deriving from multi\textbf{\underline{S}}cale
scenarios with multi\textbf{\underline{V}}iew and
multi\textbf{\underline{M}}odal instruction tuning data. It contains $420$k
images and $4, 811$M point clouds with $567$k question-answering pairs from
vehicles, low-altitude drones, high-altitude aerial planes, and satellite. To
effectively fuse the multimodal data in the absence of one modality, we
introduce incomplete multimodal learning to model outdoor scene understanding
and design the LVLM named \textbf{\underline{City-VLM}}. Multimodal fusion is
realized by constructing a joint probabilistic distribution space rather than
implementing directly explicit fusion operations (e.g., concatenation).
Experimental results on three typical outdoor scene understanding tasks show
City-VLM achieves $18.14 \%$ performance surpassing existing LVLMs in
question-answering tasks averagely. Our method demonstrates pragmatic and
generalization performance across multiple outdoor scenes.

</details>


### [27] [DeQA-Doc: Adapting DeQA-Score to Document Image Quality Assessment](https://arxiv.org/abs/2507.12796)
*Junjie Gao,Runze Liu,Yingzhe Peng,Shujian Yang,Jin Zhang,Kai Yang,Zhiyuan You*

Main category: cs.CV

TL;DR: DeQA-Doc 是一个利用 MLLM 的框架，通过软标签策略和放宽分辨率约束来评估文档质量，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的文档质量评估方法在提供准确且鲁棒的质量分数方面存在不足，这限制了它们在实际应用中的适用性。

Method: 通过调整 DeQA-Score（一种最先进的 MLLM 图像质量评分器）来为文档质量评估构建 DeQA-Doc 框架。该框架利用 MLLM 的视觉语言能力和软标签策略来回归连续的文档质量分数。为了使 DeQA-Score 适应 DeQA-Doc，采用了两种互补的解决方案来构建软标签，同时放宽了分辨率约束以支持文档图像的大分辨率。最后，引入了集成方法来进一步提升性能。

Result: DeQA-Doc 显著优于现有基线，提供准确且可泛化的文档质量评估。

Conclusion: DeQA-Doc 显著优于现有基线，在各种退化类型上提供准确且可泛化的文档质量评估。

Abstract: Document quality assessment is critical for a wide range of applications
including document digitization, OCR, and archival. However, existing
approaches often struggle to provide accurate and robust quality scores,
limiting their applicability in practical scenarios. With the rapid progress in
Multi-modal Large Language Models (MLLMs), recent MLLM-based methods have
achieved remarkable performance in image quality assessment. In this work, we
extend this success to the document domain by adapting DeQA-Score, a
state-of-the-art MLLM-based image quality scorer, for document quality
assessment. We propose DeQA-Doc, a framework that leverages the visual language
capabilities of MLLMs and a soft label strategy to regress continuous document
quality scores. To adapt DeQA-Score to DeQA-Doc, we adopt two complementary
solutions to construct soft labels without the variance information. Also, we
relax the resolution constrains to support the large resolution of document
images. Finally, we introduce ensemble methods to further enhance the
performance. Extensive experiments demonstrate that DeQA-Doc significantly
outperforms existing baselines, offering accurate and generalizable document
quality assessment across diverse degradation types. Codes and model weights
are available in https://github.com/Junjie-Gao19/DeQA-Doc.

</details>


### [28] [ATL-Diff: Audio-Driven Talking Head Generation with Early Landmarks-Guide Noise Diffusion](https://arxiv.org/abs/2507.12804)
*Hoang-Son Vo,Quang-Vinh Nguyen,Seungwon Kim,Hyung-Jeong Yang,Soonja Yeom,Soo-Hyung Kim*

Main category: cs.CV

TL;DR: ATL-Diff通过랜드마크 생성, 랜드마크 가이드 노이즈 및 3D 신원 확산 네트워크改进了音频驱动的Talking Head生成，实现了高质量、高效率和精确同步。


<details>
  <summary>Details</summary>
Motivation: 解决音频驱动的Talking Head生成中的同步限制问题，同时降低噪声和计算成本。

Method: ATL-Diff框架包含三个关键组件：1. 랜드마크 생성 모듈：将音频转换为面部랜드마크。2. 랜드마크 가이드 노이즈 방식：根据랜드마크解耦音频，分配噪声。3. 3D 신원 확산 네트워크：保留신원特征。

Result: ATL-Diff实现了近乎实时处理，能够生成高质量动画，具有计算效率和出色的面部细节保留能力，在MEAD和CREMA-D数据集上所有指标均优于现有最先进的方法。

Conclusion: ATL-Diff在MEAD和CREMA-D数据集上的实验结果表明，该方法在所有指标上均优于现有最先进的方法，实现了近乎实时处理、高质量动画、计算效率和出色的面部细节保留。

Abstract: Audio-driven talking head generation requires precise synchronization between
facial animations and audio signals. This paper introduces ATL-Diff, a novel
approach addressing synchronization limitations while reducing noise and
computational costs. Our framework features three key components: a Landmark
Generation Module converting audio to facial landmarks, a Landmarks-Guide Noise
approach that decouples audio by distributing noise according to landmarks, and
a 3D Identity Diffusion network preserving identity characteristics.
Experiments on MEAD and CREMA-D datasets demonstrate that ATL-Diff outperforms
state-of-the-art methods across all metrics. Our approach achieves near
real-time processing with high-quality animations, computational efficiency,
and exceptional preservation of facial nuances. This advancement offers
promising applications for virtual assistants, education, medical
communication, and digital platforms. The source code is available at:
\href{https://github.com/sonvth/ATL-Diff}{https://github.com/sonvth/ATL-Diff}

</details>


### [29] [Semantic-guided Fine-tuning of Foundation Model for Long-tailed Visual Recognition](https://arxiv.org/abs/2507.12807)
*Yufei Peng,Yonggang Zhang,Yiu-ming Cheung*

Main category: cs.CV

TL;DR: Sage通过结合文本语义引导和分布失衡补偿因子，改进了长尾视觉识别的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决长尾学习场景中类别样本数量不均衡导致低频类别性能下降的问题，并克服现有微调方法在对齐视觉和文本模态时的不足。

Method: 提出了一种名为Sage的新方法，该方法包含一个SG-Adapter，用于将类别描述作为语义引导来指导视觉编码器的微调，并通过注意力机制整合这些引导信息以加强视觉和文本模态的一致性。此外，还提出了一种分布失衡感知补偿因子，用于纠正因类别条件分布不一致性而导致的预测偏差。

Result: Sage在长尾学习任务中能够增强模型对语义相关内容的关注，加强视觉和文本模态之间的一致性，并有效纠正预测偏差，从而在基准数据集上展现出优越的性能。

Conclusion: Sage通过将文本模态的语义引导整合到视觉微调过程中，并引入了解决类别条件分布不一致性导致的预测偏差的分布失衡感知补偿因子，在长尾视觉识别任务上取得了显著的性能提升。

Abstract: The variance in class-wise sample sizes within long-tailed scenarios often
results in degraded performance in less frequent classes. Fortunately,
foundation models, pre-trained on vast open-world datasets, demonstrate strong
potential for this task due to their generalizable representation, which
promotes the development of adaptive strategies on pre-trained models in
long-tailed learning. Advanced fine-tuning methods typically adjust visual
encoders while neglecting the semantics derived from the frozen text encoder,
overlooking the visual and textual alignment. To strengthen this alignment, we
propose a novel approach, Semantic-guided fine-tuning of foundation model for
long-tailed visual recognition (Sage), which incorporates semantic guidance
derived from textual modality into the visual fine-tuning process.
Specifically, we introduce an SG-Adapter that integrates class descriptions as
semantic guidance to guide the fine-tuning of the visual encoder. The
introduced guidance is passesed through the attention mechanism and enables the
model to focus more on semantically relevant content, strengthening the
alignment between the visual and textual modalities. Due to the inconsistent
class-conditional distributions neglected by the existing loss function, the
resulting prediction bias causes performance improvements for the tail class
less than for the head class, even when the multi-modal alignment is enhanced.
To address this challenge, we propose a novel distribution mismatch-aware
compensation factor, which is specifically designed to rectify the prediction
bias caused by the ignored inconsistent distribution based on our theoretical
analysis, and is seamlessly integrated into the loss function. Extensive
experiments on benchmark datasets demonstrate the effectiveness of the proposed
Sage in enhancing performance in long-tailed learning.

</details>


### [30] [FIQ: Fundamental Question Generation with the Integration of Question Embeddings for Video Question Answering](https://arxiv.org/abs/2507.12816)
*Ju-Young Oh,Ho-Joong Kim,Seong-Whan Lee*

Main category: cs.CV

TL;DR: FIQ方法通过生成更丰富的问答对和引入VQ-CAlign模块，提升了视频问答的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视频问答方法主要依赖事件中心的问答对进行训练，这限制了模型对视频内容的全面理解和推理能力，因为这些标注缺乏物体类型、空间布局和属性等关键细节。

Method: FIQ（Fundamental Question Generation）方法，该方法整合了问题嵌入，通过生成基于视频描述的问答对来丰富训练数据，并引入VQ-CAlign模块，将视觉特征与特定任务的问题嵌入相结合。

Result: FIQ方法通过增强视频的基础理解，提高了模型的泛化能力和推理能力，并在SUTD-TrafficQA数据集上实现了优于现有基线方法的性能。

Conclusion: FIQ通过基于视频描述生成问答对，并结合VQ-CAlign模块，增强了视频问答模型的泛化能力和推理能力，在SUTD-TrafficQA数据集上取得了最先进的性能。

Abstract: Video question answering (VQA) is a multimodal task that requires the
interpretation of a video to answer a given question. Existing VQA methods
primarily utilize question and answer (Q&A) pairs to learn the spatio-temporal
characteristics of video content. However, these annotations are typically
event-centric, which is not enough to capture the broader context of each
video. The absence of essential details such as object types, spatial layouts,
and descriptive attributes restricts the model to learning only a fragmented
scene representation. This issue limits the model's capacity for generalization
and higher-level reasoning. In this paper, we propose a fundamental question
generation with the integration of question embeddings for video question
answering (FIQ), a novel approach designed to strengthen the reasoning ability
of the model by enhancing the fundamental understanding of videos. FIQ
generates Q&A pairs based on descriptions extracted from videos, enriching the
training data with fundamental scene information. Generated Q&A pairs enable
the model to understand the primary context, leading to enhanced
generalizability and reasoning ability. Furthermore, we incorporate a VQ-CAlign
module that assists task-specific question embeddings with visual features,
ensuring that essential domain-specific details are preserved to increase the
adaptability of downstream tasks. Experiments on SUTD-TrafficQA demonstrate
that our FIQ achieves state-of-the-art performance compared to existing
baseline methods.

</details>


### [31] [MCoT-RE: Multi-Faceted Chain-of-Thought and Re-Ranking for Training-Free Zero-Shot Composed Image Retrieval](https://arxiv.org/abs/2507.12819)
*Jeong-Woo Park,Seong-Whan Lee*

Main category: cs.CV

TL;DR: MCoT-RE 是一个创新的免训练零样本组合图像检索框架，通过多方面思维链和重排策略，有效平衡文本修改和视觉上下文，显著提升了检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于预训练模型的免训练零样本方法成本较低，但存在局限性。顺序视觉语言模型-大语言模型（VLM-LLM）流水线独立处理每个模态，易造成信息丢失并限制跨模态交互。而基于多模态大语言模型（MLLM）的方法往往只关注文本指示的修改，未能充分利用参考图像的视觉上下文信息。

Method: 提出了一种名为 MCoT-RE 的多方面思维链和重排框架。该框架利用多方面思维链来指导多模态大语言模型（MLLM），使其在修改和视觉上下文之间取得平衡，生成两个不同的标题：一个侧重于修改，另一个整合了全面的视觉-文本上下文。第一个标题用于筛选候选图像，然后结合这两个标题和参考图像进行多粒度重排。

Result: MCoT-RE 在 FashionIQ 数据集上的 Recall@10 指标提高了 6.24%，在 CIRR 数据集上的 Recall@1 指标提高了 8.58%，在免训练方法中取得了最先进的结果。

Conclusion: MCoT-RE 通过结合显式修改指令和视觉上下文，在 FashionIQ 和 CIRR 数据集上达到了最先进的零样本、免训练的性能，在 Recall@10 和 Recall@1 指标上分别提高了 6.24% 和 8.58%。

Abstract: Composed Image Retrieval (CIR) is the task of retrieving a target image from
a gallery using a composed query consisting of a reference image and a
modification text. Among various CIR approaches, training-free zero-shot
methods based on pre-trained models are cost-effective but still face notable
limitations. For example, sequential VLM-LLM pipelines process each modality
independently, which often results in information loss and limits cross-modal
interaction. In contrast, methods based on multimodal large language models
(MLLMs) often focus exclusively on applying changes indicated by the text,
without fully utilizing the contextual visual information from the reference
image. To address these issues, we propose multi-faceted Chain-of-Thought with
re-ranking (MCoT-RE), a training-free zero-shot CIR framework. MCoT-RE utilizes
multi-faceted Chain-of-Thought to guide the MLLM to balance explicit
modifications and contextual visual cues, generating two distinct captions: one
focused on modification and the other integrating comprehensive visual-textual
context. The first caption is used to filter candidate images. Subsequently, we
combine these two captions and the reference image to perform multi-grained
re-ranking. This two-stage approach facilitates precise retrieval by aligning
with the textual modification instructions while preserving the visual context
of the reference image. Through extensive experiments, MCoT-RE achieves
state-of-the-art results among training-free methods, yielding improvements of
up to 6.24% in Recall@10 on FashionIQ and 8.58% in Recall@1 on CIRR.

</details>


### [32] [FAR-Net: Multi-Stage Fusion Network with Enhanced Semantic Alignment and Adaptive Reconciliation for Composed Image Retrieval](https://arxiv.org/abs/2507.12823)
*Jeong-Woo Park,Young-Eun Kim,Seong-Whan Lee*

Main category: cs.CV

TL;DR: FAR-Net 是一种新的多阶段融合框架，通过增强的语义对齐和自适应的协调，解决了现有组合图像检索方法的局限性，并在实验中取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在融合视觉和文本模态时，早期融合过于关注文本细节而忽略视觉上下文，晚期融合则难以捕捉图像区域和文本标记之间的细粒度语义对齐。为了解决这些问题，提出 FAR-Net。

Method: 提出了一种名为 FAR-Net 的多阶段融合框架，该框架包含两个互补的模块：增强语义对齐模块 (ESAM) 和自适应协调模块 (ARM)。ESAM 采用晚期融合和交叉注意力机制来捕捉细粒度的语义关系，而 ARM 采用早期融合和不确定性嵌入来增强鲁棒性和适应性。

Result: 在 CIRR 和 FashionIQ 数据集上的实验表明，FAR-Net 的性能持续提升，Recall@1 提升高达 2.4%，Recall@50 提升 1.04%，优于现有的最先进方法。

Conclusion: FAR-Net 通过多阶段融合框架，结合增强的语义对齐和自适应的协调，在 CIRR 和 FashionIQ 数据集上取得了显著的性能提升，证明了其在 CIR 任务中的鲁棒性和可扩展性。

Abstract: Composed image retrieval (CIR) is a vision language task that retrieves a
target image using a reference image and modification text, enabling intuitive
specification of desired changes. While effectively fusing visual and textual
modalities is crucial, existing methods typically adopt either early or late
fusion. Early fusion tends to excessively focus on explicitly mentioned textual
details and neglect visual context, whereas late fusion struggles to capture
fine-grained semantic alignments between image regions and textual tokens. To
address these issues, we propose FAR-Net, a multi-stage fusion framework
designed with enhanced semantic alignment and adaptive reconciliation,
integrating two complementary modules. The enhanced semantic alignment module
(ESAM) employs late fusion with cross-attention to capture fine-grained
semantic relationships, while the adaptive reconciliation module (ARM) applies
early fusion with uncertainty embeddings to enhance robustness and
adaptability. Experiments on CIRR and FashionIQ show consistent performance
gains, improving Recall@1 by up to 2.4% and Recall@50 by 1.04% over existing
state-of-the-art methods, empirically demonstrating that FAR Net provides a
robust and scalable solution to CIR tasks.

</details>


### [33] [Feature-Enhanced TResNet for Fine-Grained Food Image Classification](https://arxiv.org/abs/2507.12828)
*Lulu Liu,Zhiyong Xiao*

Main category: cs.CV

TL;DR: 提出FE-TResNet方法，通过结合StyleRM和DCA技术，解决了细粒度食物图像分类的挑战，并在两个中文食物数据集上取得了领先的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的卷积神经网络（CNN）在处理形状相似但细节上存在细微差别的细粒度食物图像时面临重大挑战，因此需要准确分类食物图像以满足各种应用场景的需求。

Method: 提出了一种名为特征增强TResNet（FE-TResNet）的创新方法，该方法基于TResNet模型，并集成了基于风格的再校准模块（StyleRM）和深度通道注意力（DCA）技术，以增强特征提取能力。

Result: FE-TResNet方法在ChineseFoodNet和CNFOOD-241数据集上分别实现了81.37%和80.29%的准确率。

Conclusion: FE-TResNet方法在中文食物图像数据集ChineseFoodNet和CNFOOD-241上显著提高了分类准确率，分别达到了81.37%和80.29%，证明了其在细粒度食物图像分类方面的有效性和优越性。

Abstract: Food is not only a core component of humans' daily diets, but also an
important carrier of cultural heritage and emotional bonds. With the
development of technology, the need for accurate classification of food images
has grown, which is crucial for a variety of application scenarios. However,
existing Convolutional Neural Networks (CNNs) face significant challenges when
dealing with fine-grained food images that are similar in shape but subtle in
detail. To address this challenge, this study presents an innovative method for
classifying food images, named Feature-Enhanced TResNet (FE-TResNet),
specifically designed to address fine-grained food images and accurately
capture subtle features within them. The FE-TResNet method is based on the
TResNet model and integrates Style-based Recalibration Module (StyleRM) and
Deep Channel-wise Attention (DCA) technologies to enhance feature extraction
capabilities. In experimental validation on Chinese food image datasets
ChineseFoodNet and CNFOOD-241, the FE-TResNet method significantly improved
classification accuracy, achieving rates of 81.37% and 80.29%, respectively,
demonstrating its effectiveness and superiority in fine-grained food image
classification.

</details>


### [34] [DINO-VO: A Feature-based Visual Odometry Leveraging a Visual Foundation Model](https://arxiv.org/abs/2507.13145)
*Maulana Bisyir Azhari,David Hyunchul Shim*

Main category: cs.CV

TL;DR: DINO-VO 是一个利用 DINOv2 基础模型进行视觉里程计的系统，通过改进的关键点检测和特征表示，在准确性、鲁棒性和效率方面均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决基于学习的单目视觉里程计（VO）在鲁棒性、泛化性和效率方面的挑战，并探索 DINOv2 等视觉基础模型在 VO 中的应用潜力。

Method: 提出了一种针对 DINOv2 特征的显著关键点检测器，并将 DINOv2 的语义特征与细粒度几何特征相结合，以实现更具定位性的表示。此外，还使用基于 Transformer 的匹配器和可微分姿态估计层来学习良好的匹配以进行精确的相机运动估计。

Result: DINO-VO 在 TartanAir 和 KITTI 数据集上的表现优于现有方法，在 EuRoC 数据集上也具有竞争力。与 SuperPoint 等现有方法相比，DINO-VO 在充满挑战的环境中表现出更强的鲁棒性，并且在准确性和泛化性方面优于单独的 DINOv2 特征。该系统运行效率高，在单个 GPU 上每秒可运行 72 帧，内存占用不到 1GB。此外，在户外驾驶场景中，其性能可与视觉 SLAM 系统相媲美。

Conclusion: DINO-VO 是一种基于特征的视觉里程计系统，利用 DINOv2 视觉基础模型进行稀疏特征匹配，并在 TartanAir 和 KITTI 数据集上表现优于现有方法，在 EuRoC 数据集上具有竞争力。该系统在具有挑战性的环境中表现出更强的鲁棒性，并具有高效的推理速度和低内存占用。

Abstract: Learning-based monocular visual odometry (VO) poses robustness,
generalization, and efficiency challenges in robotics. Recent advances in
visual foundation models, such as DINOv2, have improved robustness and
generalization in various vision tasks, yet their integration in VO remains
limited due to coarse feature granularity. In this paper, we present DINO-VO, a
feature-based VO system leveraging DINOv2 visual foundation model for its
sparse feature matching. To address the integration challenge, we propose a
salient keypoints detector tailored to DINOv2's coarse features. Furthermore,
we complement DINOv2's robust-semantic features with fine-grained geometric
features, resulting in more localizable representations. Finally, a
transformer-based matcher and differentiable pose estimation layer enable
precise camera motion estimation by learning good matches. Against prior
detector-descriptor networks like SuperPoint, DINO-VO demonstrates greater
robustness in challenging environments. Furthermore, we show superior accuracy
and generalization of the proposed feature descriptors against standalone
DINOv2 coarse features. DINO-VO outperforms prior frame-to-frame VO methods on
the TartanAir and KITTI datasets and is competitive on EuRoC dataset, while
running efficiently at 72 FPS with less than 1GB of memory usage on a single
GPU. Moreover, it performs competitively against Visual SLAM systems on outdoor
driving scenarios, showcasing its generalization capabilities.

</details>


### [35] [MVA 2025 Small Multi-Object Tracking for Spotting Birds Challenge: Dataset, Methods, and Results](https://arxiv.org/abs/2507.12832)
*Yuki Kondo,Norimichi Ukita,Riku Kanayama,Yuki Yoshida,Takayuki Yamaguchi,Xiang Yu,Guang Liang,Xinyao Liu,Guan-Zhang Wang,Wei-Ta Chu,Bing-Cheng Chuang,Jia-Hua Lee,Pin-Tseng Kuo,I-Hsuan Chu,Yi-Shein Hsiao,Cheng-Han Wu,Po-Yi Wu,Jui-Chien Tsou,Hsuan-Chi Liu,Chun-Yi Lee,Yuan-Fu Yang,Kosuke Shigematsu,Asuka Shin,Ba Tran*

Main category: cs.CV

TL;DR: 本文提出了SMOT4SB挑战赛，介绍了SMOT4SB数据集和SO-HOTA指标，旨在解决无人机场景下的小型多目标跟踪问题。


<details>
  <summary>Details</summary>
Motivation: 小型多目标跟踪（SMOT）在目标仅占几十个像素时尤其具有挑战性，因为这使得检测和基于外观的关联变得不可靠。本文借鉴MVA2023 SOD4SB挑战的成功经验，提出了SMOT4SB挑战赛，利用时间信息来解决单帧检测的局限性。

Method: 提出了一种名为SO-HOTA的新指标，该指标结合了Dot Distance和HOTA，以减轻基于IoU的指标对小位移的敏感性。

Result: SMOT4SB数据集包含211个无人机视频序列，包含108,192个带注释的帧，涵盖了多样化的真实世界条件，旨在捕捉相机和目标在3D中自由移动的运动纠缠。MVA2025挑战赛有78名参赛者和308个提交，获胜方法比基线提高了5.1倍。

Conclusion: 该工作为无人机场景下的SMOT奠定了基础，可应用于鸟击规避、农业、渔业和生态监测。

Abstract: Small Multi-Object Tracking (SMOT) is particularly challenging when targets
occupy only a few dozen pixels, rendering detection and appearance-based
association unreliable. Building on the success of the MVA2023 SOD4SB
challenge, this paper introduces the SMOT4SB challenge, which leverages
temporal information to address limitations of single-frame detection. Our
three main contributions are: (1) the SMOT4SB dataset, consisting of 211 UAV
video sequences with 108,192 annotated frames under diverse real-world
conditions, designed to capture motion entanglement where both camera and
targets move freely in 3D; (2) SO-HOTA, a novel metric combining Dot Distance
with HOTA to mitigate the sensitivity of IoU-based metrics to small
displacements; and (3) a competitive MVA2025 challenge with 78 participants and
308 submissions, where the winning method achieved a 5.1x improvement over the
baseline. This work lays a foundation for advancing SMOT in UAV scenarios with
applications in bird strike avoidance, agriculture, fisheries, and ecological
monitoring.

</details>


### [36] [SE-VLN: A Self-Evolving Vision-Language Navigation Framework Based on Multimodal Large Language Models](https://arxiv.org/abs/2507.13152)
*Xiangyu Dong,Haoran Zhao,Jiang Gao,Haozhou Li,Xiaoguang Ma,Yaoming Zhou,Fuhai Chen,Juan Liu*

Main category: cs.CV

TL;DR: 提出了一种名为SE-VLN的自进化视觉语言导航框架，它通过分层记忆、检索增强推理和反思模块，使导航代理能够持续进化，并在R2R和REVERSE数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有视觉语言导航方法受限于大型语言模型固定知识库和推理能力，无法充分融合经验知识并缺乏有效进化能力的问题。

Method: 提出了一种名为SE-VLN的自进化视觉语言导航框架，该框架包含一个分层记忆模块、一个检索增强的基于思想的推理模块和一个能够实现持续进化的反思模块。

Result: SE-VLN在R2R和REVERSE数据集上的导航成功率分别为57%和35.2%，分别比现有最先进方法提高了23.9%和15.0%。此外，SE-VLN的性能随着经验库的增加而提高。

Conclusion: SE-VLN框架能够实现持续进化，并且在R2R和REVERSE数据集上取得了显著的性能提升，展示了其作为视觉语言导航自进化代理框架的巨大潜力。

Abstract: Recent advances in vision-language navigation (VLN) were mainly attributed to
emerging large language models (LLMs). These methods exhibited excellent
generalization capabilities in instruction understanding and task reasoning.
However, they were constrained by the fixed knowledge bases and reasoning
abilities of LLMs, preventing fully incorporating experiential knowledge and
thus resulting in a lack of efficient evolutionary capacity. To address this,
we drew inspiration from the evolution capabilities of natural agents, and
proposed a self-evolving VLN framework (SE-VLN) to endow VLN agents with the
ability to continuously evolve during testing. To the best of our knowledge, it
was the first time that an multimodal LLM-powered self-evolving VLN framework
was proposed. Specifically, SE-VLN comprised three core modules, i.e., a
hierarchical memory module to transfer successful and failure cases into
reusable knowledge, a retrieval-augmented thought-based reasoning module to
retrieve experience and enable multi-step decision-making, and a reflection
module to realize continual evolution. Comprehensive tests illustrated that the
SE-VLN achieved navigation success rates of 57% and 35.2% in unseen
environments, representing absolute performance improvements of 23.9% and 15.0%
over current state-of-the-art methods on R2R and REVERSE datasets,
respectively. Moreover, the SE-VLN showed performance improvement with
increasing experience repository, elucidating its great potential as a
self-evolving agent framework for VLN.

</details>


### [37] [AnyCap Project: A Unified Framework, Dataset, and Benchmark for Controllable Omni-modal Captioning](https://arxiv.org/abs/2507.12841)
*Yiming Ren,Zhiqiang Lin,Yu Li,Gao Meng,Weiyun Wang,Junjie Wang,Zicheng Lin,Jifeng Dai,Yujiu Yang,Wenhai Wang,Ruihang Chu*

Main category: cs.CV

TL;DR: 本项目提出了AnyCap，一个包含模型、数据集和评估方法的集成解决方案，用于提高全模态字幕生成的可控性。AnyCapModel（ACM）能增强现有基础模型的控制能力，而无需重新训练。AnyCapDataset（ACD）提供了包含三种模态、28种用户指令和30万条数据的多模态数据集。AnyCapEval是一个新的评估基准，通过解耦内容准确性和风格保真度来提供更可靠的评估。ACM在多个基准测试中均表现出显著的性能提升，例如将GPT-4o的内容分数提高了45%，风格分数提高了12%。


<details>
  <summary>Details</summary>
Motivation: 现有的可控字幕生成模型缺乏细粒度的控制能力和可靠的评估协议，这阻碍了精确的多模态对齐和指令遵循。为了解决这个问题，本项目提出了AnyCap项目。

Method: 提出了一种名为AnyCap的集成解决方案，包括模型（AnyCapModel, ACM）、数据集（AnyCapDataset, ACD）和评估方法（AnyCapEval）。ACM通过重用基础模型的原始字幕，并结合用户指令和模态特征来生成改进的字幕，从而增强了现有基础模型在全模态字幕生成中的可控性。ACD包含了三种模态、28种用户指令类型和30万条高质量数据。AnyCapEval通过解耦内容准确性和风格保真度，提供更可靠的可控字幕生成评估指标。

Result: ACM显著提高了各种基础模型在AnyCapEval上的字幕质量。具体来说，ACM-8B将GPT-4o的内容分数提高了45%，风格分数提高了12%。此外，ACM在MIA-Bench和VidCapBench等常用基准上也取得了显著的提升。

Conclusion: AnyCapModel（ACM）作为一个轻量级的即插即用框架，能够增强现有基础模型的可控性，实现全模态字幕生成，且无需重新训练基础模型。AnyCapDataset（ACD）包含了三种模态、28种用户指令类型和30万条高质量数据条目。AnyCapEval是一个新的基准，通过解耦内容准确性和风格保真度，为可控字幕生成提供更可靠的评估指标。ACM在AnyCapEval上显著提高了各种基础模型的字幕质量，特别是ACM-8B将GPT-4o的内容分数提高了45%，风格分数提高了12%，并且在MIA-Bench和VidCapBench等广泛使用的基准上也取得了显著的提升。

Abstract: Controllable captioning is essential for precise multimodal alignment and
instruction following, yet existing models often lack fine-grained control and
reliable evaluation protocols. To address this gap, we present the AnyCap
Project, an integrated solution spanning model, dataset, and evaluation. We
introduce AnyCapModel (ACM), a lightweight plug-and-play framework that
enhances the controllability of existing foundation models for omni-modal
captioning without retraining the base model. ACM reuses the original captions
from base models while incorporating user instructions and modality features to
generate improved captions. To remedy the data scarcity in controllable
multimodal captioning, we build AnyCapDataset (ACD), covering three modalities,
28 user-instruction types, and 300\,k high-quality data entries. We further
propose AnyCapEval, a new benchmark that provides more reliable evaluation
metrics for controllable captioning by decoupling content accuracy and
stylistic fidelity. ACM markedly improves caption quality across a diverse set
of base models on AnyCapEval. Notably, ACM-8B raises GPT-4o\'s content scores
by 45\% and style scores by 12\%, and it also achieves substantial gains on
widely used benchmarks such as MIA-Bench and VidCapBench.

</details>


### [38] [$S^2M^2$: Scalable Stereo Matching Model for Reliable Depth Estimation](https://arxiv.org/abs/2507.13229)
*Junhong Min,Youngpil Jeon,Jimin Kim,Minyong Choi*

Main category: cs.CV

TL;DR: S^2M^2 是一种新的全局匹配架构，通过多分辨率 Transformer 和创新的损失函数，在不牺牲效率的情况下实现了最先进的立体匹配性能。


<details>
  <summary>Details</summary>
Motivation: 旨在解决通用立体匹配模型在不同分辨率和视差范围内无需特定数据集微调即可执行的追求中存在的权衡问题。迭代局部搜索方法在受限基准测试中得分很高，但其核心机制限制了真正泛化所需的全局一致性。另一方面，全局匹配架构虽然理论上更鲁棒，但由于高昂的计算和内存成本而在历史上不可行。

Method: 本研究提出了一种名为 S^2M^2 的全局匹配架构，它集成了多分辨率 Transformer 以实现鲁棒的长距离对应，并采用新颖的损失函数进行训练，该损失函数将概率集中在可行的匹配上。该方法能够更稳健地联合估计视差、遮挡和置信度。

Result: S^2M^2 架构实现了先进的准确性和高效率，无需依赖成本量过滤或深度精炼堆栈，并在 Middlebury v3 和 ETH3D 基准测试中确立了新的最先进水平，在大多数指标上显著优于 prior 方法，同时以具有竞争力的效率重建了高质量的细节。

Conclusion: S^2M^2 架构实现了先进的准确性和高效率，无需依赖成本量过滤或深度精炼堆栈，并在 Middlebury v3 和 ETH3D 基准测试中确立了新的最先进水平，在大多数指标上显著优于 prior 方法，同时以具有竞争力的效率重建了高质量的细节。

Abstract: The pursuit of a generalizable stereo matching model, capable of performing
across varying resolutions and disparity ranges without dataset-specific
fine-tuning, has revealed a fundamental trade-off. Iterative local search
methods achieve high scores on constrained benchmarks, but their core mechanism
inherently limits the global consistency required for true generalization. On
the other hand, global matching architectures, while theoretically more robust,
have been historically rendered infeasible by prohibitive computational and
memory costs. We resolve this dilemma with $S^2M^2$: a global matching
architecture that achieves both state-of-the-art accuracy and high efficiency
without relying on cost volume filtering or deep refinement stacks. Our design
integrates a multi-resolution transformer for robust long-range correspondence,
trained with a novel loss function that concentrates probability on feasible
matches. This approach enables a more robust joint estimation of disparity,
occlusion, and confidence. $S^2M^2$ establishes a new state of the art on the
Middlebury v3 and ETH3D benchmarks, significantly outperforming prior methods
across most metrics while reconstructing high-quality details with competitive
efficiency.

</details>


### [39] [SEMT: Static-Expansion-Mesh Transformer Network Architecture for Remote Sensing Image Captioning](https://arxiv.org/abs/2507.12845)
*Khang Truong,Lam Pham,Hieu Tang,Jasmin Lampert,Martin Boyer,Son Phan,Truong Nguyen*

Main category: cs.CV

TL;DR: 本文提出了一个用于遥感图像字幕生成的Transformer模型，并在UCM-Caption和NWPU-Caption数据集上取得了优于现有技术的性能。


<details>
  <summary>Details</summary>
Motivation: 在遥感领域，图像字幕生成在解释海量复杂卫星图像方面发挥着重要作用，有助于环境监测、灾难评估和城市规划等应用。

Method: 本文提出了一个基于Transformer的网络架构，用于遥感图像字幕生成（RSIC），并评估和整合了静态扩展、内存增强自注意力、网格Transformer等多种技术。

Result: 使用UCM-Caption和NWPU-Caption两个遥感图像数据集对提出的模型进行了评估。

Conclusion: 该模型在大多数评估指标上均优于最先进的系统，证明了其在现实世界遥感图像系统中的应用潜力。

Abstract: Image captioning has emerged as a crucial task in the intersection of
computer vision and natural language processing, enabling automated generation
of descriptive text from visual content. In the context of remote sensing,
image captioning plays a significant role in interpreting vast and complex
satellite imagery, aiding applications such as environmental monitoring,
disaster assessment, and urban planning. This motivates us, in this paper, to
present a transformer based network architecture for remote sensing image
captioning (RSIC) in which multiple techniques of Static Expansion,
Memory-Augmented Self-Attention, Mesh Transformer are evaluated and integrated.
We evaluate our proposed models using two benchmark remote sensing image
datasets of UCM-Caption and NWPU-Caption. Our best model outperforms the
state-of-the-art systems on most of evaluation metrics, which demonstrates
potential to apply for real-life remote sensing image systems.

</details>


### [40] [VITA: Vision-to-Action Flow Matching Policy](https://arxiv.org/abs/2507.13231)
*Dechen Gao,Boqi Zhao,Andrew Lee,Ian Chuang,Hanchu Zhou,Hang Wang,Zhe Zhao,Junshan Zhang,Iman Soltani*

Main category: cs.CV

TL;DR: VITA 是一种创新的、仅使用 MLP 的视觉到动作流匹配策略，可解决复杂的双臂操作任务。它通过将潜在图像直接映射到结构化的潜在动作来消除对单独条件模块的需求，从而实现高效且性能卓越的视觉运动控制。


<details>
  <summary>Details</summary>
Motivation: 传统的流匹配和扩散策略需要额外的条件机制（如交叉注意力）来将动作生成与视觉信息相结合，这会带来时间和空间开销。VITA 提出了一种新范式，将潜在图像作为流的来源，学习视觉到动作的内在映射，从而消除单独的条件模块并保留生成建模能力。

Method: VITA (Vision-To-Action flow matching policy) 将潜在图像作为流的来源，直接学习从视觉到动作的映射。为了解决模态间流匹配的挑战，它使用自动编码器创建结构化的动作潜在空间作为流匹配目标，并将原始动作上采样以匹配视觉表示的形状。关键在于，它通过流潜在解码同时使用编码器目标和最终动作输出来监督流匹配，将动作重建损失反向传播到整个流匹配 ODE 求解步骤中，从而实现有效的端到端学习。该模型仅使用 MLP 层实现。

Result: VITA 在具有挑战性的双臂操作任务（包括 ALOHA 平台上的 5 个模拟和 2 个真实世界任务）上进行了评估。结果表明，尽管 VITA 仅使用 MLP 实现，但其性能优于或等于最先进的生成策略，同时将推理延迟降低了 50-130%。

Conclusion: VITA 是一种新颖的视觉到动作的流匹配策略，它将潜在的视觉表示演化为潜在的动作，用于视觉运动控制。它通过将潜在图像作为流源，学习从视觉到动作的内在映射，从而消除了单独的条件模块，并保留了生成建模能力。此外，通过将动作数据上采样到与视觉表示匹配的形状，并结合自动编码器创建结构化的动作潜在空间，解决了模态间流匹配的挑战。最后，通过在整个流匹配 ODE 求解步骤中反向传播动作重建损失，实现了有效的端到端学习。

Abstract: We present VITA, a Vision-To-Action flow matching policy that evolves latent
visual representations into latent actions for visuomotor control. Traditional
flow matching and diffusion policies sample from standard source distributions
(e.g., Gaussian noise) and require additional conditioning mechanisms like
cross-attention to condition action generation on visual information, creating
time and space overheads. VITA proposes a novel paradigm that treats latent
images as the flow source, learning an inherent mapping from vision to action
while eliminating separate conditioning modules and preserving generative
modeling capabilities. Learning flows between fundamentally different
modalities like vision and action is challenging due to sparse action data
lacking semantic structures and dimensional mismatches between high-dimensional
visual representations and raw actions. We address this by creating a
structured action latent space via an autoencoder as the flow matching target,
up-sampling raw actions to match visual representation shapes. Crucially, we
supervise flow matching with both encoder targets and final action outputs
through flow latent decoding, which backpropagates action reconstruction loss
through sequential flow matching ODE solving steps for effective end-to-end
learning. Implemented as simple MLP layers, VITA is evaluated on challenging
bi-manual manipulation tasks on the ALOHA platform, including 5 simulation and
2 real-world tasks. Despite its simplicity, MLP-only VITA outperforms or
matches state-of-the-art generative policies while reducing inference latency
by 50-130% compared to conventional flow matching policies requiring different
conditioning mechanisms or complex architectures. To our knowledge, VITA is the
first MLP-only flow matching policy capable of solving complex bi-manual
manipulation tasks like those in ALOHA benchmarks.

</details>


### [41] [Simulate, Refocus and Ensemble: An Attention-Refocusing Scheme for Domain Generalization](https://arxiv.org/abs/2507.12851)
*Ziyi Wang,Zhi Gao,Jin Chen,Qingjie Zhao,Xinxiao Wu,Jiebo Luo*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Domain generalization (DG) aims to learn a model from source domains and
apply it to unseen target domains with out-of-distribution data. Owing to
CLIP's strong ability to encode semantic concepts, it has attracted increasing
interest in domain generalization. However, CLIP often struggles to focus on
task-relevant regions across domains, i.e., domain-invariant regions, resulting
in suboptimal performance on unseen target domains. To address this challenge,
we propose an attention-refocusing scheme, called Simulate, Refocus and
Ensemble (SRE), which learns to reduce the domain shift by aligning the
attention maps in CLIP via attention refocusing. SRE first simulates domain
shifts by performing augmentation on the source data to generate simulated
target domains. SRE then learns to reduce the domain shifts by refocusing the
attention in CLIP between the source and simulated target domains. Finally, SRE
utilizes ensemble learning to enhance the ability to capture domain-invariant
attention maps between the source data and the simulated target data. Extensive
experimental results on several datasets demonstrate that SRE generally
achieves better results than state-of-the-art methods. The code is available
at: https://github.com/bitPrincy/SRE-DG.

</details>


### [42] [SCORE: Scene Context Matters in Open-Vocabulary Remote Sensing Instance Segmentation](https://arxiv.org/abs/2507.12857)
*Shiqi Huang,Shuting He,Huaiyuan Qin,Bihan Wen*

Main category: cs.CV

TL;DR:  SCORE框架通过整合区域和全局场景上下文，解决了现有开放词汇遥感实例分割方法在处理多样化遥感数据（如季节变化、小型或模糊物体）时的局限性，提升了物体区分能力和语言表示的适应性，并在多个数据集上取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的遥感实例分割方法大多是为近词汇预测设计的，限制了它们识别新类别或跨数据集泛化的能力，这在多样化的地球观测场景中限制了它们的适用性。直接将现有的开放词汇分割模型应用于遥感领域面临挑战，如航空影像中多样的景观、季节性变化以及小型或模糊物体等问题。

Method: 提出SCORE框架，通过区域感知集成（Region-Aware Integration）利用区域上下文细化类别嵌入，提高物体可区分性；通过全局上下文适应（Global Context Adaptation）利用遥感全局上下文丰富文本嵌入，为分类器创建更具适应性和表现力的语言潜在空间。

Result: SCORE框架在开放词汇遥感实例分割任务上建立了新的基准，实验结果表明该方法实现了最先进的性能。

Conclusion: SCORE框架通过整合多粒度场景上下文（区域上下文和全局上下文）来增强视觉和文本表示，为开放词汇的遥感实例分割提供了鲁棒的解决方案，在多个数据集上取得了最先进的性能，为大规模、真实世界的地理空间分析提供了支持。

Abstract: Most existing remote sensing instance segmentation approaches are designed
for close-vocabulary prediction, limiting their ability to recognize novel
categories or generalize across datasets. This restricts their applicability in
diverse Earth observation scenarios. To address this, we introduce
open-vocabulary (OV) learning for remote sensing instance segmentation. While
current OV segmentation models perform well on natural image datasets, their
direct application to remote sensing faces challenges such as diverse
landscapes, seasonal variations, and the presence of small or ambiguous objects
in aerial imagery. To overcome these challenges, we propose $\textbf{SCORE}$
($\textbf{S}$cene $\textbf{C}$ontext matters in $\textbf{O}$pen-vocabulary
$\textbf{RE}$mote sensing instance segmentation), a framework that integrates
multi-granularity scene context, i.e., regional context and global context, to
enhance both visual and textual representations. Specifically, we introduce
Region-Aware Integration, which refines class embeddings with regional context
to improve object distinguishability. Additionally, we propose Global Context
Adaptation, which enriches naive text embeddings with remote sensing global
context, creating a more adaptable and expressive linguistic latent space for
the classifier. We establish new benchmarks for OV remote sensing instance
segmentation across diverse datasets. Experimental results demonstrate that,
our proposed method achieves SOTA performance, which provides a robust solution
for large-scale, real-world geospatial analysis. Our code is available at
https://github.com/HuangShiqi128/SCORE.

</details>


### [43] [WhoFi: Deep Person Re-Identification via Wi-Fi Channel Signal Encoding](https://arxiv.org/abs/2507.12869)
*Danilo Avola,Daniele Pannone,Dario Montagnini,Emad Emam*

Main category: cs.CV

TL;DR: WhoFi利用Wi-Fi信号进行行人重识别，通过提取CSI的生物特征并使用基于Transformer的DNN进行处理，在NTU-Fi数据集上取得了有竞争力的结果。


<details>
  <summary>Details</summary>
Motivation: 传统行人重识别方法依赖视觉数据，但在光照不佳、遮挡和视角不佳的情况下性能会受到限制。为了解决这些挑战，我们引入了WhoFi，一种利用Wi-Fi信号进行行人重识别的新颖管道。

Method: WhoFi提出了一种新颖的管道，利用Wi-Fi信号进行行人重识别。该方法从信道状态信息（CSI）中提取生物特征，并通过一个模块化的深度神经网络（DNN）进行处理，该网络具有基于Transformer的编码器。网络使用批内负采样损失函数进行训练，以学习鲁棒且可泛化的生物特征签名。

Result: 实验结果表明，WhoFi在NTU-Fi数据集上取得了具有竞争力的结果，与现有最先进的方法相比，确认了其通过Wi-Fi信号识别个体的有效性。

Conclusion: WhoFi通过利用Wi-Fi信号进行行人重识别，在NTU-Fi数据集上取得了与最先进方法相媲美的结果，证明了其通过Wi-Fi信号识别个体的有效性。

Abstract: Person Re-Identification is a key and challenging task in video surveillance.
While traditional methods rely on visual data, issues like poor lighting,
occlusion, and suboptimal angles often hinder performance. To address these
challenges, we introduce WhoFi, a novel pipeline that utilizes Wi-Fi signals
for person re-identification. Biometric features are extracted from Channel
State Information (CSI) and processed through a modular Deep Neural Network
(DNN) featuring a Transformer-based encoder. The network is trained using an
in-batch negative loss function to learn robust and generalizable biometric
signatures. Experiments on the NTU-Fi dataset show that our approach achieves
competitive results compared to state-of-the-art methods, confirming its
effectiveness in identifying individuals via Wi-Fi signals.

</details>


### [44] [HRSeg: High-Resolution Visual Perception and Enhancement for Reasoning Segmentation](https://arxiv.org/abs/2507.12883)
*Weihuang Lin,Yiwei Ma,Xiaoshuai Sun,Shuting He,Jiayi Ji,Liujuan Cao,Rongrong Ji*

Main category: cs.CV

TL;DR: HRSeg：一种通过高分辨率感知（HRP）和高分辨率增强（HRE）模块解决低感知分辨率问题的高效推理分割模型。


<details>
  <summary>Details</summary>
Motivation: 现有的推理分割方法在处理包含上下文线索和开放世界知识的隐式用户指令时，受限于低感知分辨率，因为视觉编码器通常在较低分辨率下进行预训练。简单地插值位置嵌入来提高感知分辨率，性能提升有限且计算成本高昂。

Method: 提出了一种名为HRSeg的高效模型，包含两个关键创新：高分辨率感知（HRP）和高分辨率增强（HRE）。HRP模块通过裁剪处理高分辨率图像，整合局部和全局特征以实现多粒度质量；HRE模块通过整合高分辨率图像的细粒度信息来增强掩码特征，并优化其与文本特征的对齐，以实现精确分割。

Result: HRSeg模型在多个基准数据集上的实验证明了其卓越的性能，并且通过大量的消融研究验证了所提出模块的有效性。

Conclusion: HRSeg模型通过提出的HRP和HRE模块，实现了高分辨率细粒度感知，有效解决了现有方法的局限性，并在多个基准数据集上展现出优越的性能。

Abstract: The reasoning segmentation task involves segmenting objects within an image
by interpreting implicit user instructions, which may encompass subtleties such
as contextual cues and open-world knowledge. Despite significant advancements
made by existing approaches, they remain constrained by low perceptual
resolution, as visual encoders are typically pre-trained at lower resolutions.
Furthermore, simply interpolating the positional embeddings of visual encoders
to enhance perceptual resolution yields only marginal performance improvements
while incurring substantial computational costs. To address this, we propose
HRSeg, an efficient model with high-resolution fine-grained perception. It
features two key innovations: High-Resolution Perception (HRP) and
High-Resolution Enhancement (HRE). The HRP module processes high-resolution
images through cropping, integrating local and global features for
multi-granularity quality. The HRE module enhances mask features by integrating
fine-grained information from high-resolution images, refining their alignment
with text features for precise segmentation. Extensive ablation studies
validate the effectiveness of our modules, while comprehensive experiments on
multiple benchmark datasets demonstrate HRSeg's superior performance.

</details>


### [45] [Camera-based implicit mind reading by capturing higher-order semantic dynamics of human gaze within environmental context](https://arxiv.org/abs/2507.12889)
*Mengke Song,Yuge Xie,Qi Cui,Luming Li,Xinyu Liu,Guotao Wang,Chenglizhao Chen,Shanchen Pang*

Main category: cs.CV

TL;DR: 提出了一种新的基于摄像头的情感识别方法，该方法通过分析用户的凝视模式、环境语义和时间动态，实现了用户无感知、实时、连续的情感识别，克服了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数情感识别方法都依赖于外部线索（如面部表情、语音或手势），这些线索只能反映身体的反应，并且忽略了环境背景的影响。这些线索通常是自愿的、容易被掩盖的，并且不足以捕捉更深层次的、隐含的情感。基于生理信号的方法虽然能更直接地访问内部状态，但需要复杂的传感器，这会影响自然行为并限制可扩展性。基于注视的方法通常依赖于静态的注视点分析，无法捕捉注视与环境之间丰富、动态的相互作用，因此也无法揭示情感与隐含行为之间的深层联系。

Method: 提出了一种新颖的、基于摄像头的、用户无感知的情感识别方法，该方法将凝视注视模式与环境语义和时间动态相结合。利用标准高清摄像头，在自然环境中，在无需专门硬件或用户主动参与的情况下，即可自动捕获用户的眼睛外观和头部运动。通过这些视觉线索，系统会随着时间的推移和空间的变化来估计用户的凝视轨迹，为模拟凝视行为的空间、语义和时间维度提供了基础。

Result: 通过整合凝视注视模式与环境语义和时间动态，该方法能够捕获视觉注意力和周围环境之间动态的相互作用，揭示情感不仅是生理反应，更是人与环境相互作用的复杂结果。

Conclusion: 该方法实现了用户无感知、实时、连续的情感识别，具有高泛化性和低部署成本。

Abstract: Emotion recognition,as a step toward mind reading,seeks to infer internal
states from external cues.Most existing methods rely on explicit signals-such
as facial expressions,speech,or gestures-that reflect only bodily responses and
overlook the influence of environmental context.These cues are often
voluntary,easy to mask,and insufficient for capturing deeper,implicit emotions.
Physiological signal-based approaches offer more direct access to internal
states but require complex sensors that compromise natural behavior and limit
scalability.Gaze-based methods typically rely on static fixation analysis and
fail to capture the rich,dynamic interactions between gaze and the
environment,and thus cannot uncover the deep connection between emotion and
implicit behavior.To address these limitations,we propose a novel
camera-based,user-unaware emotion recognition approach that integrates gaze
fixation patterns with environmental semantics and temporal dynamics.Leveraging
standard HD cameras,our method unobtrusively captures users'eye appearance and
head movements in natural settings-without the need for specialized hardware or
active user participation.From these visual cues,the system estimates gaze
trajectories over time and space, providing the basis for modeling the spatial,
semantic,and temporal dimensions of gaze behavior. This allows us to capture
the dynamic interplay between visual attention and the surrounding
environment,revealing that emotions are not merely physiological responses but
complex outcomes of human-environment interactions.The proposed approach
enables user-unaware,real-time,and continuous emotion recognition,offering high
generalizability and low deployment cost.

</details>


### [46] [LanePerf: a Performance Estimation Framework for Lane Detection](https://arxiv.org/abs/2507.12894)
*Yin Wu,Daniel Slieter,Ahmed Abouelazm,Christian Hubschneider,J. Marius Zöllner*

Main category: cs.CV

TL;DR: 本研究提出了一种名为LanePerf的新框架，用于在没有真实标签的情况下估计车道线检测模型的性能。该框架结合了图像特征和车道线特征，能有效应对各种域迁移和零车道线检测的挑战。实验结果显示，LanePerf比现有方法更有效，为ADAS提供了更高效、更安全的测试解决方案。


<details>
  <summary>Details</summary>
Motivation: 车道线检测是高级驾驶辅助系统（ADAS）和自动驾驶系统（ADS）的关键组成部分，但模型在部署到新环境时常会因域迁移而降低可靠性。为了评估和确保车道线检测模型的鲁棒性和安全性，通常需要收集和标注目标域数据，这是一个资源密集的过程。在没有地面真实标签的情况下估计模型性能，为高效的鲁棒性评估提供了一种有前景的替代方案，但在车道线检测领域尚未得到充分研究。

Method: 本研究首先将五种在图像分类任务中表现良好的性能估计方法迁移应用于车道线检测任务，以建立基线。随后，针对现有方法仅依赖softmax分数或车道线特征的局限性，提出了一种新的车道线性能估计框架（LanePerf）。该框架利用预训练的图像编码器和基于DeepSets的架构，整合了图像和车道线特征，能够有效处理零车道线检测和大的域迁移情况。

Result: LanePerf框架在OpenLane数据集上进行了广泛实验，该数据集涵盖了多样的域迁移场景（包括场景、天气和时间变化）。实验结果表明，LanePerf的平均绝对误差（MAE）为0.117，Spearman秩相关系数为0.727，优于所有基线方法。

Conclusion: 本研究提出的LanePerf框架通过整合图像和车道线特征，克服了现有方法的局限性，能够有效处理零车道线检测场景和大范围域迁移情况。在OpenLane数据集上进行的广泛实验证明，LanePerf在应对场景、天气和时间等多种域迁移时，相比所有基线方法表现更优，实现了0.117的平均绝对误差（MAE）和0.727的Spearman秩相关系数，为ADAS领域提供了一种高效、无需标签的性能评估方法，有助于提升在复杂驾驶场景下的测试效率和安全性。

Abstract: Lane detection is a critical component of Advanced Driver-Assistance Systems
(ADAS) and Automated Driving System (ADS), providing essential spatial
information for lateral control. However, domain shifts often undermine model
reliability when deployed in new environments. Ensuring the robustness and
safety of lane detection models typically requires collecting and annotating
target domain data, which is resource-intensive. Estimating model performance
without ground-truth labels offers a promising alternative for efficient
robustness assessment, yet remains underexplored in lane detection. While
previous work has addressed performance estimation in image classification,
these methods are not directly applicable to lane detection tasks. This paper
first adapts five well-performing performance estimation methods from image
classification to lane detection, building a baseline. Addressing the
limitations of prior approaches that solely rely on softmax scores or lane
features, we further propose a new Lane Performance Estimation Framework
(LanePerf), which integrates image and lane features using a pretrained image
encoder and a DeepSets-based architecture, effectively handling zero-lane
detection scenarios and large domain-shift cases. Extensive experiments on the
OpenLane dataset, covering diverse domain shifts (scenes, weather, hours),
demonstrate that our LanePerf outperforms all baselines, achieving a lower MAE
of 0.117 and a higher Spearman's rank correlation coefficient of 0.727. These
findings pave the way for robust, label-free performance estimation in ADAS,
supporting more efficient testing and improved safety in challenging driving
scenarios.

</details>


### [47] [Federated Learning for Commercial Image Sources](https://arxiv.org/abs/2507.12903)
*Shreyansh Jain,Koteswar Rao Jerripothula*

Main category: cs.CV

TL;DR: 该论文发布了一个新的联邦学习图像数据集，并提出了两种新算法Fed-Cyclic和Fed-Star，它们在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了推动联邦学习在图像分类领域的应用，特别是解决数据隐私和安全问题，该研究创建了一个新的数据集，并开发了能够处理统计异质性并提高模型性能的新算法。

Method: 提出了一种包含23,326张图像的新数据集，并将图像分为31个类别。同时，提出了两种新的联邦学习算法：Fed-Cyclic（客户端按周期顺序接收、更新和传递权重）和Fed-Star（客户端在预聚合后接收、更新并向所有其他客户端发送权重）。

Result: Fed-Cyclic和Fed-Star两种算法在新数据集上的实验结果显示，它们的性能优于现有的基线算法。

Conclusion: 该研究介绍了首个专门为联邦学习设计的图像分类数据集，并提出了Fed-Cyclic和Fed-Star两种新的联邦学习算法。实验表明，这两种算法在新数据集上的表现优于现有基线算法。

Abstract: Federated Learning is a collaborative machine learning paradigm that enables
multiple clients to learn a global model without exposing their data to each
other. Consequently, it provides a secure learning platform with
privacy-preserving capabilities. This paper introduces a new dataset containing
23,326 images collected from eight different commercial sources and classified
into 31 categories, similar to the Office-31 dataset. To the best of our
knowledge, this is the first image classification dataset specifically designed
for Federated Learning. We also propose two new Federated Learning algorithms,
namely Fed-Cyclic and Fed-Star. In Fed-Cyclic, a client receives weights from
its previous client, updates them through local training, and passes them to
the next client, thus forming a cyclic topology. In Fed-Star, a client receives
weights from all other clients, updates its local weights through
pre-aggregation (to address statistical heterogeneity) and local training, and
sends its updated local weights to all other clients, thus forming a star-like
topology. Our experiments reveal that both algorithms perform better than
existing baselines on our newly introduced dataset.

</details>


### [48] [AthleticsPose: Authentic Sports Motion Dataset on Athletic Field and Evaluation of Monocular 3D Pose Estimation Ability](https://arxiv.org/abs/2507.12905)
*Tomohiro Suzuki,Ryota Tanaka,Calvin Yeung,Keisuke Fujii*

Main category: cs.CV

TL;DR: 提出AthleticsPose数据集和训练模型，解决了体育运动分析中3D姿态估计的挑战，提高了准确性，但也指出了在高速运动分析中的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决现有3D姿态估计技术在体育运动分析中面临的真实数据集缺乏和可靠性不明确的问题。

Method: 利用AthleticsPose数据集训练3D姿态估计模型，并通过对比实验和案例研究进行评估。

Result: 在AthleticsPose数据集上训练的模型显著优于在模拟数据集上训练的模型，MPJPE降低了约75%。模型对相机视角和主体尺度敏感，能捕捉个体在膝关节角度的差异，但在高速运动指标方面存在不足。

Conclusion: 该研究提供了一个包含真实运动数据的AthleticsPose数据集，并训练了一个3D姿态估计模型。结果表明，在该数据集上训练的模型比在模拟数据上训练的模型表现更好，MPJPE降低了约75%。研究还发现，相机视角和主体尺度会影响估计精度，并且模型能够捕捉个体在膝关节角度上的差异，但在高速运动指标（如膝关节驱动速度）方面存在局限性。

Abstract: Monocular 3D pose estimation is a promising, flexible alternative to costly
motion capture systems for sports analysis. However, its practical application
is hindered by two factors: a lack of realistic sports datasets and unclear
reliability for sports tasks. To address these challenges, we introduce the
AthleticsPose dataset, a new public dataset featuring ``real'' motions captured
from 23 athletes performing various athletics events on an athletic field.
Using this dataset, we trained a representative 3D pose estimation model and
performed a comprehensive evaluation. Our results show that the model trained
on AthleticsPose significantly outperforms a baseline model trained on an
imitated sports motion dataset, reducing MPJPE by approximately 75 %. These
results show the importance of training on authentic sports motion data, as
models based on imitated motions do not effectively transfer to real-world
motions. Further analysis reveals that estimation accuracy is sensitive to
camera view and subject scale. In case studies of kinematic indicators, the
model demonstrated the potential to capture individual differences in knee
angles but struggled with higher-speed metrics, such as knee-drive velocity,
due to prediction biases. This work provides the research community with a
valuable dataset and clarifies the potential and practical limitations of using
monocular 3D pose estimation for sports motion analysis. Our dataset, code, and
checkpoints are available at https://github.com/SZucchini/AthleticsPose.

</details>


### [49] [Argus: Leveraging Multiview Images for Improved 3-D Scene Understanding With Large Language Models](https://arxiv.org/abs/2507.12916)
*Yifan Xu,Chao Zhang,Hanqi Jiang,Xiaoyan Wang,Ruifei Ma,Yiwei Li,Zihao Wu,Zeju Li,Xiangde Liu*

Main category: cs.CV

TL;DR: Argus框架利用2D多视图图像弥补3D点云重建的信息损失，通过融合多视图图像和3D特征，增强LLMs的3D场景理解能力，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景理解方法主要依赖3D点云，但点云重建容易丢失纹理平面、重复图案等信息，并可能导致细节失真。2D多视图图像能够提供更详细的场景表示，并与3D点云具有视觉一致性，可以弥补点云重建的不足。

Method: Argus是一个新颖的3D多模态框架，利用多视图图像通过LLMs进行增强的3D场景理解。它通过将多视图图像和相机位姿融合到视图即场景特征中，并与3D特征交互，来创建全面且详细的3D感知场景嵌入。Argus能够处理文本指令、2D多视图图像和3D点云等多种模态，从而扩展LLMs处理3D任务的能力。

Result: Argus框架能够补偿3D点云重建过程中的信息损失，并帮助LLMs更好地理解3D世界。实验证明，Argus在多种下游任务中的表现优于现有的3D-LMM。

Conclusion: Argus框架通过融合多视图图像和相机位姿来增强3D场景理解能力，并已在各种下游任务中证明优于现有的3D-LMM。

Abstract: Advancements in foundation models have made it possible to conduct
applications in various downstream tasks. Especially, the new era has witnessed
a remarkable capability to extend Large Language Models (LLMs) for tackling
tasks of 3D scene understanding. Current methods rely heavily on 3D point
clouds, but the 3D point cloud reconstruction of an indoor scene often results
in information loss. Some textureless planes or repetitive patterns are prone
to omission and manifest as voids within the reconstructed 3D point clouds.
Besides, objects with complex structures tend to introduce distortion of
details caused by misalignments between the captured images and the dense
reconstructed point clouds. 2D multi-view images present visual consistency
with 3D point clouds and provide more detailed representations of scene
components, which can naturally compensate for these deficiencies. Based on
these insights, we propose Argus, a novel 3D multimodal framework that
leverages multi-view images for enhanced 3D scene understanding with LLMs. In
general, Argus can be treated as a 3D Large Multimodal Foundation Model
(3D-LMM) since it takes various modalities as input(text instructions, 2D
multi-view images, and 3D point clouds) and expands the capability of LLMs to
tackle 3D tasks. Argus involves fusing and integrating multi-view images and
camera poses into view-as-scene features, which interact with the 3D features
to create comprehensive and detailed 3D-aware scene embeddings. Our approach
compensates for the information loss while reconstructing 3D point clouds and
helps LLMs better understand the 3D world. Extensive experiments demonstrate
that our method outperforms existing 3D-LMMs in various downstream tasks.

</details>


### [50] [DMQ: Dissecting Outliers of Diffusion Models for Post-Training Quantization](https://arxiv.org/abs/2507.12933)
*Dongyeun Lee,Jiwan Hur,Hyounguk Shon,Jae Young Lee,Junmo Kim*

Main category: cs.CV

TL;DR: DMQ是一种新的扩散模型量化方法，通过LES和PTS技术在低比特量化下提升性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像生成方面取得了显著成功，但其显著的计算成本限制了其在资源受限环境下的部署。现有的量化方法在低比特量化下会因忽略离群值而导致性能下降。

Method: DMQ方法结合了学习等效缩放（LES）和逐通道二的幂缩放（PTS）。LES优化通道缩放因子以重新分配权重和激活之间的量化难度，减少量化误差。自适应时间步长加权方案优先处理关键的去噪步骤，以应对误差累积。逐通道二的幂缩放（PTS）用于处理具有高通道间方差的层（如跳接层）的激活。此外，还引入了一个投票算法来确保在小的校准数据集上也能可靠地选择PTS因子。

Result: 与现有工作相比，DMQ在W4A6（4位权重，6位激活）和W4A8等低比特量化下表现出显著的性能提升，同时保持了高质量的图像生成和模型稳定性。

Conclusion: 该研究提出了一种名为DMQ的量化方法，结合了学习等效缩放（LES）和逐通道二的幂缩放（PTS），以解决扩散模型在资源受限环境下的部署挑战，特别是在低比特量化下性能下降的问题。DMQ通过优化缩放因子来重新分配量化难度，并引入自适应时间步长加权方案来优先处理关键的去噪步骤，同时利用逐通道二的幂缩放处理具有高通道间方差的层。实验证明，DMQ在W4A6和W4A8等低比特量化下显著优于现有方法，保持了高质量的图像生成和模型稳定性。

Abstract: Diffusion models have achieved remarkable success in image generation but
come with significant computational costs, posing challenges for deployment in
resource-constrained environments. Recent post-training quantization (PTQ)
methods have attempted to mitigate this issue by focusing on the iterative
nature of diffusion models. However, these approaches often overlook outliers,
leading to degraded performance at low bit-widths. In this paper, we propose a
DMQ which combines Learned Equivalent Scaling (LES) and channel-wise
Power-of-Two Scaling (PTS) to effectively address these challenges. Learned
Equivalent Scaling optimizes channel-wise scaling factors to redistribute
quantization difficulty between weights and activations, reducing overall
quantization error. Recognizing that early denoising steps, despite having
small quantization errors, crucially impact the final output due to error
accumulation, we incorporate an adaptive timestep weighting scheme to
prioritize these critical steps during learning. Furthermore, identifying that
layers such as skip connections exhibit high inter-channel variance, we
introduce channel-wise Power-of-Two Scaling for activations. To ensure robust
selection of PTS factors even with small calibration set, we introduce a voting
algorithm that enhances reliability. Extensive experiments demonstrate that our
method significantly outperforms existing works, especially at low bit-widths
such as W4A6 (4-bit weight, 6-bit activation) and W4A8, maintaining high image
generation quality and model stability. The code is available at
https://github.com/LeeDongYeun/dmq.

</details>


### [51] [A Deep-Learning Framework for Land-Sliding Classification from Remote Sensing Image](https://arxiv.org/abs/2507.12939)
*Hieu Tang,Truong Vo,Dong Pham,Toan Nguyen,Lam Pham,Truong Nguyen*

Main category: cs.CV

TL;DR: This paper presents a deep learning framework for landslide detection using satellite imagery, improving performance with data augmentation, EfficientNet_Large, and an SVM classifier, achieving a high F1-score.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the challenge of selecting appropriate deep learning architectures for automatic landslide detection using satellite imagery to optimize performance and avoid overfitting.

Method: The framework utilizes online and offline data augmentation to handle imbalanced data, employs EfficientNet_Large for feature extraction, and incorporates an SVM classifier for post-processing to improve classification performance.

Result: The proposed model achieved an F1-score of 0.8938 on the Zindi challenge public test set.

Conclusion: A deep-learning based framework is proposed for landslide detection from remote sensing images, combining data augmentation, EfficientNet_Large, and an SVM classifier.

Abstract: The use of satellite imagery combined with deep learning to support automatic
landslide detection is becoming increasingly widespread. However, selecting an
appropriate deep learning architecture to optimize performance while avoiding
overfitting remains a critical challenge. To address these issues, we propose a
deep-learning based framework for landslide detection from remote sensing image
in this paper. The proposed framework presents an effective combination of the
online an offline data augmentation to tackle the imbalanced data, a backbone
EfficientNet\_Large deep learning model for extracting robust embedding
features, and a post-processing SVM classifier to balance and enhance the
classification performance. The proposed model achieved an F1-score of 0.8938
on the public test set of the Zindi challenge.

</details>


### [52] [Weakly Supervised Visible-Infrared Person Re-Identification via Heterogeneous Expert Collaborative Consistency Learning](https://arxiv.org/abs/2507.12942)
*Yafei Zhang,Lingqi Kong,Huafeng Li,Jie Wen*

Main category: cs.CV

TL;DR: 本文提出了一种弱监督跨模态行人ReID方法，通过异构专家协同一致性学习框架，利用单模态标签解决跨模态标签缺失问题，并提高了模型性能。


<details>
  <summary>Details</summary>
Motivation: 为了减少可见光-红外行人重识别（ReID）模型对标记跨模态样本的依赖，本文探索了一种弱监督跨模态行人ReID方法，该方法仅使用单模态样本身份标签，并解决了跨模态身份标签不可用的场景。

Method: 提出了一种异构专家协同一致性学习框架，该框架旨在以弱监督方式建立强大的跨模态身份对应关系。该框架利用每个模态的标记数据来独立训练专门的分类专家。为了关联跨模态样本，这些分类专家充当异构预测器，预测其他模态样本的身份。为了提高预测准确性，我们设计了一种跨模态关系融合机制，以有效地整合来自不同专家的预测。

Result: 通过跨模态身份对应关系的隐式监督，鼓励专家之间的协同和一致性学习，显著增强了模型提取模态不变特征和提高跨模态身份识别能力。

Conclusion: 实验结果在两个具有挑战性的数据集上验证了所提出方法的有效性。

Abstract: To reduce the reliance of visible-infrared person re-identification (ReID)
models on labeled cross-modal samples, this paper explores a weakly supervised
cross-modal person ReID method that uses only single-modal sample identity
labels, addressing scenarios where cross-modal identity labels are unavailable.
To mitigate the impact of missing cross-modal labels on model performance, we
propose a heterogeneous expert collaborative consistency learning framework,
designed to establish robust cross-modal identity correspondences in a weakly
supervised manner. This framework leverages labeled data from each modality to
independently train dedicated classification experts. To associate cross-modal
samples, these classification experts act as heterogeneous predictors,
predicting the identities of samples from the other modality. To improve
prediction accuracy, we design a cross-modal relationship fusion mechanism that
effectively integrates predictions from different experts. Under the implicit
supervision provided by cross-modal identity correspondences, collaborative and
consistent learning among the experts is encouraged, significantly enhancing
the model's ability to extract modality-invariant features and improve
cross-modal identity recognition. Experimental results on two challenging
datasets validate the effectiveness of the proposed method.

</details>


### [53] [Analysis of Image-and-Text Uncertainty Propagation in Multimodal Large Language Models with Cardiac MR-Based Applications](https://arxiv.org/abs/2507.12945)
*Yucheng Tang,Yunguan Fu,Weixi Yi,Yipei Wang,Daniel C. Alexander,Rhodri Davies,Yipeng Hu*

Main category: cs.CV

TL;DR: 该研究提出了多模态不确定性传播模型（MUPM），用于理解和量化多模态大型语言模型（MLLMs）中不同输入模态（图像、文本）的不确定性关系。实验表明，MUPM能够有效优化、泛化，并应用于心脏病预测等临床任务，同时还能识别冗余信息。


<details>
  <summary>Details</summary>
Motivation: 多模态大型语言模型（MLLMs）在处理和整合来自文本和图像等多种模态信息方面具有潜力，但输入模态间的相互关系、由单一模态数据引起的不确定性以及这种不确定性分解后的潜在临床应用尚未得到充分理解。

Method: 提出了一种基于不确定性传播的多模态不确定性传播模型（MUPM），以表征MLLM输入中仅图像、仅文本以及联合图像-文本变化所引起的不确定性之间的关系。

Result: MUPMs可以使用少量样本进行鲁棒优化，并且可以跨不同的输入数据分布和下游任务进行泛化。这种可转移性可能源于共享的预训练、相对较轻的MLLM微调以及MUPMs的低维特性。所学到的可转移性可以直接应用于临床，以稳健地估计和分析不确定性，用于不同数据或新的心脏病预测任务。实验还证明了MUPMs在估计整体不确定性和识别冗余因素方面的效率。

Conclusion: MUPMs可以被优化，并且具有跨不同输入数据分布和下游任务的可转移性。这种可转移性可以量化不确定性之间的关系，从而在临床应用中稳健地估计和分析不确定性，用于不同数据或新的心脏病预测任务。此外，MUPMs在估计整体不确定性和识别冗余因素方面显示出效率。

Abstract: Multimodal large language models (MLLMs) can process and integrate
information from multimodality sources, such as text and images. However,
interrelationship among input modalities, uncertainties due to individual
uni-modal data and potential clinical applications following such an
uncertainty decomposition are yet fully understood in the context of
large-scale MLLMs. In this work, we propose a multimodal uncertainty
propagation model (MUPM) based on uncertainty propagation, to characterise the
relationship among the uncertainties arising from image-only, text-only, and
joint image-text variations in MLLM inputs. Using real clinical data consisting
of cardiac MR scans and digital health records, we describe that MUPMs can be
optimised robustly with a few samples. We then show that the fitted MUPMs are
generalisable across different input data distributions and, perhaps
surprisingly, across different downstream tasks. Such a transferability may be
explained by the shared pretraining, comparatively light MLLM fine-tuning,
along with the low-dimensional nature of the MUPMs. More importantly, this
learned transferability, quantifying the relationship between these
uncertainties, led to direct clinical applications in which uncertainties may
be estimated and thus analysed robustly for varying data or even a novel set of
cardiac disease prediction tasks. In addition, we show experimentally the
efficiency in multimodal data required for estimating the overall uncertainty
and its ability to identify redundant factors, both of which are considered
practical yet clinically useful applications with the proposed MUPMs. Codes are
available at https://github.com/yucheng722/MUPM.

</details>


### [54] [VisionThink: Smart and Efficient Vision Language Model via Reinforcement Learning](https://arxiv.org/abs/2507.13348)
*Senqiao Yang,Junyi Li,Xin Lai,Bei Yu,Hengshuang Zhao,Jiaya Jia*

Main category: cs.CV

TL;DR: VisionThink通过动态调整分辨率和智能压缩视觉令牌，提高了视觉-语言模型的效率，同时保持了准确性。


<details>
  <summary>Details</summary>
Motivation: 大多数真实场景不需要大量的视觉令牌，而现有的视觉-语言模型（VLMs）通常使用更多的视觉令牌。虽然在OCR相关任务上性能下降明显，但在其他通用VQA任务上，即使只使用1/4的分辨率，模型仍能准确运行。因此，需要一种更有效的方法来处理不同复杂度的视觉任务。

Method: 提出了一种名为VisionThink的新范式，通过动态处理不同分辨率的样本，并采用视觉令牌压缩技术。该方法首先使用降采样图像，并智能判断其是否足以解决问题，否则请求更高分辨率的图像。采用强化学习和LLM-as-Judge策略，并设计了奖励函数和惩罚机制来稳定和合理化图像调整调用比例。

Result: VisionThink在OCR相关任务上展示了强大的细粒度视觉理解能力，并在简单任务上节省了大量视觉令牌，证明了其优越性、效率和有效性。

Conclusion: VisionThink通过动态调整分辨率和智能压缩视觉令牌，在OCR相关任务上展现了强大的细粒度视觉理解能力，同时在简单任务上节省了大量视觉令牌。实验证明了该方法的优越性、效率和有效性。

Abstract: Recent advancements in vision-language models (VLMs) have improved
performance by increasing the number of visual tokens, which are often
significantly longer than text tokens. However, we observe that most real-world
scenarios do not require such an extensive number of visual tokens. While the
performance drops significantly in a small subset of OCR-related tasks, models
still perform accurately in most other general VQA tasks with only 1/4
resolution. Therefore, we propose to dynamically process distinct samples with
different resolutions, and present a new paradigm for visual token compression,
namely, VisionThink. It starts with a downsampled image and smartly decides
whether it is sufficient for problem solving. Otherwise, the model could output
a special token to request the higher-resolution image. Compared to existing
Efficient VLM methods that compress tokens using fixed pruning ratios or
thresholds, VisionThink autonomously decides whether to compress tokens case by
case. As a result, it demonstrates strong fine-grained visual understanding
capability on OCR-related tasks, and meanwhile saves substantial visual tokens
on simpler tasks. We adopt reinforcement learning and propose the LLM-as-Judge
strategy to successfully apply RL to general VQA tasks. Moreover, we carefully
design a reward function and penalty mechanism to achieve a stable and
reasonable image resize call ratio. Extensive experiments demonstrate the
superiority, efficiency, and effectiveness of our method. Our code is available
at https://github.com/dvlab-research/VisionThink.

</details>


### [55] [LoViC: Efficient Long Video Generation with Context Compression](https://arxiv.org/abs/2507.12952)
*Jiaxiu Jiang,Wenbo Li,Jingjing Ren,Yuping Qiu,Yong Guo,Xiaogang Xu,Han Wu,Wangmeng Zuo*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Despite recent advances in diffusion transformers (DiTs) for text-to-video
generation, scaling to long-duration content remains challenging due to the
quadratic complexity of self-attention. While prior efforts -- such as sparse
attention and temporally autoregressive models -- offer partial relief, they
often compromise temporal coherence or scalability. We introduce LoViC, a
DiT-based framework trained on million-scale open-domain videos, designed to
produce long, coherent videos through a segment-wise generation process. At the
core of our approach is FlexFormer, an expressive autoencoder that jointly
compresses video and text into unified latent representations. It supports
variable-length inputs with linearly adjustable compression rates, enabled by a
single query token design based on the Q-Former architecture. Additionally, by
encoding temporal context through position-aware mechanisms, our model
seamlessly supports prediction, retradiction, interpolation, and multi-shot
generation within a unified paradigm. Extensive experiments across diverse
tasks validate the effectiveness and versatility of our approach.

</details>


### [56] [cIDIR: Conditioned Implicit Neural Representation for Regularized Deformable Image Registration](https://arxiv.org/abs/2507.12953)
*Sidaty El Hadramy,Oumeymah Cherkaoui,Philippe C. Cattin*

Main category: cs.CV

TL;DR: cIDIR是一种新的基于INR的可形变图像配准框架，它将配准过程条件化于正则化超参数，并使用分割掩模进行优化，避免了为每个正则化超参数设置进行重新训练的需要。


<details>
  <summary>Details</summary>
Motivation: 学习型可形变图像配准（DIR）框架中的正则化参数微调计算成本高昂，通常需要多次训练迭代。为了解决这个问题，论文提出了cIDIR。

Method: cIDIR框架基于隐式神经表示（INR），通过将配准过程条件化于正则化超参数来实现。它在这些超参数的先验分布上进行训练，然后利用分割掩模作为观测值在正则化超参数上进行优化。cIDIR还模拟了连续且可微的变形向量场（DVF），可以通过自动微分无缝集成先进的正则化技术。

Result: cIDIR实现了高精度和鲁棒性。

Conclusion: cIDIR框架在DIR-LAB数据集上进行了评估，在整个数据集中实现了高精度和鲁棒性。

Abstract: Regularization is essential in deformable image registration (DIR) to ensure
that the estimated Deformation Vector Field (DVF) remains smooth, physically
plausible, and anatomically consistent. However, fine-tuning regularization
parameters in learning-based DIR frameworks is computationally expensive, often
requiring multiple training iterations. To address this, we propose cIDI, a
novel DIR framework based on Implicit Neural Representations (INRs) that
conditions the registration process on regularization hyperparameters. Unlike
conventional methods that require retraining for each regularization
hyperparameter setting, cIDIR is trained over a prior distribution of these
hyperparameters, then optimized over the regularization hyperparameters by
using the segmentations masks as an observation. Additionally, cIDIR models a
continuous and differentiable DVF, enabling seamless integration of advanced
regularization techniques via automatic differentiation. Evaluated on the
DIR-LAB dataset, $\operatorname{cIDIR}$ achieves high accuracy and robustness
across the dataset.

</details>


### [57] [FantasyPortrait: Enhancing Multi-Character Portrait Animation with Expression-Augmented Diffusion Transformers](https://arxiv.org/abs/2507.12956)
*Qiang Wang,Mengchao Wang,Fan Jiang,Yaqi Fan,Yonggang Qi,Mu Xu*

Main category: cs.CV

TL;DR: FantasyPortrait 是一个创新的框架，通过新的训练策略和注意力机制，实现了高质量的单人和多人面部动画生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨重现和捕捉细微情感方面存在不足，并且缺乏对多人物动画的支持。

Method: 提出了一种基于扩散 transformer 的框架 FantasyPortrait，并引入了以表情增强的学习策略（利用隐式表示来捕捉与身份无关的面部动力学）和掩码交叉注意力机制（确保独立但协调的表情生成）。

Result: FantasyPortrait 在定量指标和定性评估方面显著优于最先进的方法。

Conclusion: FantasyPortrait 在单人和多人场景下都能生成高保真、富有情感的动画，并且在跨重现和多人物动画方面表现优于现有方法。

Abstract: Producing expressive facial animations from static images is a challenging
task. Prior methods relying on explicit geometric priors (e.g., facial
landmarks or 3DMM) often suffer from artifacts in cross reenactment and
struggle to capture subtle emotions. Furthermore, existing approaches lack
support for multi-character animation, as driving features from different
individuals frequently interfere with one another, complicating the task. To
address these challenges, we propose FantasyPortrait, a diffusion transformer
based framework capable of generating high-fidelity and emotion-rich animations
for both single- and multi-character scenarios. Our method introduces an
expression-augmented learning strategy that utilizes implicit representations
to capture identity-agnostic facial dynamics, enhancing the model's ability to
render fine-grained emotions. For multi-character control, we design a masked
cross-attention mechanism that ensures independent yet coordinated expression
generation, effectively preventing feature interference. To advance research in
this area, we propose the Multi-Expr dataset and ExprBench, which are
specifically designed datasets and benchmarks for training and evaluating
multi-character portrait animations. Extensive experiments demonstrate that
FantasyPortrait significantly outperforms state-of-the-art methods in both
quantitative metrics and qualitative evaluations, excelling particularly in
challenging cross reenactment and multi-character contexts. Our project page is
https://fantasy-amap.github.io/fantasy-portrait/.

</details>


### [58] [Demographic-aware fine-grained classification of pediatric wrist fractures](https://arxiv.org/abs/2507.12964)
*Ammar Ahmed,Ali Shariq Imran,Zenun Kastrati,Sher Muhammad Daudpota*

Main category: cs.CV

TL;DR: 该研究利用细粒度识别和患者元数据，提高了腕部病理诊断的准确性，尤其是在数据集有限的情况下。


<details>
  <summary>Details</summary>
Motivation: 为了解决腕部病理诊断耗时且需要专业知识的问题，并应对医学影像数据集中存在的挑战。

Method: 该研究采用多方面方法，将问题视为细粒度识别任务，融合患者元数据和 X 射线图像，并使用在细粒度数据集上训练的权重进行预训练，而不是在 ImageNet 等粗粒度数据集上进行预训练。

Result: 研究结果表明，细粒度策略和元数据集成可将数据集有限情况下的诊断准确性提高 2%，将数据集较大的骨折相关数据集的诊断准确性提高 10% 以上。

Conclusion: 这项研究展示了细粒度识别和元数据集成可以提高腕部病理诊断的准确性，尤其是在数据集有限的情况下。

Abstract: Wrist pathologies are frequently observed, particularly among children who
constitute the majority of fracture cases. However, diagnosing these conditions
is time-consuming and requires specialized expertise. Computer vision presents
a promising avenue, contingent upon the availability of extensive datasets, a
notable challenge in medical imaging. Therefore, reliance solely on one
modality, such as images, proves inadequate, especially in an era of diverse
and plentiful data types. In this study, we employ a multifaceted approach to
address the challenge of recognizing wrist pathologies using an extremely
limited dataset. Initially, we approach the problem as a fine-grained
recognition task, aiming to identify subtle X-ray pathologies that conventional
CNNs overlook. Secondly, we enhance network performance by fusing patient
metadata with X-ray images. Thirdly, rather than pre-training on a
coarse-grained dataset like ImageNet, we utilize weights trained on a
fine-grained dataset. While metadata integration has been used in other medical
domains, this is a novel application for wrist pathologies. Our results show
that a fine-grained strategy and metadata integration improve diagnostic
accuracy by 2% with a limited dataset and by over 10% with a larger
fracture-focused dataset.

</details>


### [59] [RGB Pre-Training Enhanced Unobservable Feature Latent Diffusion Model for Spectral Reconstruction](https://arxiv.org/abs/2507.12967)
*Keli Deng,Jie Nie,Yuntao Qian*

Main category: cs.CV

TL;DR: 提出了一种新颖的光谱重建方法，通过扩展RGB预训练的潜在扩散模型，利用RGB图像的空间信息来重建高光谱图像。该方法通过两阶段流程学习光谱-空间联合分布，并在实验中取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决图像处理中从RGB图像重建高光谱图像（HSI）的光谱重建（SR）问题，特别是估计RGB图像中未包含的缺失光谱特征。该方法利用了RGB图像丰富的空间信息，并通过扩展RGB预训练的潜在扩散模型来学习光谱-空间联合分布。

Method: 提出了一种将RGB预训练的潜在扩散模型（RGB-LDM）扩展到无观测特征LDM（ULDM）的Spectral reconstruction（SR）方法。该方法通过一个两阶段流程实现：1. 训练一个光谱无观测特征自编码器（SpeUAE）来提取和压缩无观测特征，并将其映射到与RGB空间对齐的3D流形。2. 依次使用SpeUAE和SpaAE对光谱和空间结构进行编码，然后利用LDM学习编码后的无观测特征的分布，并以RGB图像作为指导。

Result: 实验结果表明，该方法在光谱重建（SR）和下游重新照明任务上均取得了最先进的性能。

Conclusion: 该方法在光谱重建（SR）和下游重新照明任务上均取得了最先进的性能。

Abstract: Spectral reconstruction (SR) is a crucial problem in image processing that
requires reconstructing hyperspectral images (HSIs) from the corresponding RGB
images. A key difficulty in SR is estimating the unobservable feature, which
encapsulates significant spectral information not captured by RGB imaging
sensors. The solution lies in effectively constructing the spectral-spatial
joint distribution conditioned on the RGB image to complement the unobservable
feature. Since HSIs share a similar spatial structure with the corresponding
RGB images, it is rational to capitalize on the rich spatial knowledge in RGB
pre-trained models for spectral-spatial joint distribution learning. To this
end, we extend the RGB pre-trained latent diffusion model (RGB-LDM) to an
unobservable feature LDM (ULDM) for SR. As the RGB-LDM and its corresponding
spatial autoencoder (SpaAE) already excel in spatial knowledge, the ULDM can
focus on modeling spectral structure. Moreover, separating the unobservable
feature from the HSI reduces the redundant spectral information and empowers
the ULDM to learn the joint distribution in a compact latent space.
Specifically, we propose a two-stage pipeline consisting of spectral structure
representation learning and spectral-spatial joint distribution learning to
transform the RGB-LDM into the ULDM. In the first stage, a spectral
unobservable feature autoencoder (SpeUAE) is trained to extract and compress
the unobservable feature into a 3D manifold aligned with RGB space. In the
second stage, the spectral and spatial structures are sequentially encoded by
the SpeUAE and the SpaAE, respectively. The ULDM is then acquired to model the
distribution of the coded unobservable feature with guidance from the
corresponding RGB images. Experimental results on SR and downstream relighting
tasks demonstrate that our proposed method achieves state-of-the-art
performance.

</details>


### [60] [Variance-Based Pruning for Accelerating and Compressing Trained Networks](https://arxiv.org/abs/2507.12988)
*Uranik Berisha,Jens Mehnert,Alexandru Paul Condurache*

Main category: cs.CV

TL;DR: 一种名为Variance-Based Pruning的新型单次结构化剪枝技术，能在不进行大规模重新训练的情况下，显著减少模型大小和计算量，同时保持或快速恢复模型性能。


<details>
  <summary>Details</summary>
Motivation: 训练大型模型（如Vision Transformers）的成本不断增加，促使人们需要复用已有的预训练模型。然而，这些模型的延迟、计算成本和内存需求高，尤其是在资源受限的硬件上部署时面临挑战。结构化剪枝虽然能降低这些因素，但通常需要昂贵的重新训练，有时甚至需要从头开始训练，才能恢复因结构修改而损失的精度。因此，在结构化剪枝后保持模型性能并避免广泛的重新训练仍然是一个挑战。

Method: Variance-Based Pruning是一种简单、结构化的单次修剪技术，通过收集激活统计数据来选择神经元，并将平均激活值整合回模型以保持性能。

Result: 在ImageNet-1k识别任务上，DeiT-Base模型在修剪后立即保留了超过70%的原始性能，并且仅需10个epoch的微调即可恢复99%的原始准确率。同时，该方法将MACs减少了35%，模型大小减少了36%，并将模型速度提高了1.44倍。

Conclusion: 该Variance-Based Pruning方法通过收集激活统计数据来选择要修剪的神经元，并将平均激活值整合回模型中，从而在保持模型性能的同时，实现了高效压缩。

Abstract: Increasingly expensive training of ever larger models such as Vision
Transfomers motivate reusing the vast library of already trained
state-of-the-art networks. However, their latency, high computational costs and
memory demands pose significant challenges for deployment, especially on
resource-constrained hardware. While structured pruning methods can reduce
these factors, they often require costly retraining, sometimes for up to
hundreds of epochs, or even training from scratch to recover the lost accuracy
resulting from the structural modifications. Maintaining the provided
performance of trained models after structured pruning and thereby avoiding
extensive retraining remains a challenge. To solve this, we introduce
Variance-Based Pruning, a simple and structured one-shot pruning technique for
efficiently compressing networks, with minimal finetuning. Our approach first
gathers activation statistics, which are used to select neurons for pruning.
Simultaneously the mean activations are integrated back into the model to
preserve a high degree of performance. On ImageNet-1k recognition tasks, we
demonstrate that directly after pruning DeiT-Base retains over 70% of its
original performance and requires only 10 epochs of fine-tuning to regain 99%
of the original accuracy while simultaneously reducing MACs by 35% and model
size by 36%, thus speeding up the model by 1.44x.

</details>


### [61] [Differential-informed Sample Selection Accelerates Multimodal Contrastive Learning](https://arxiv.org/abs/2507.12998)
*Zihua Zhao,Feng Hong,Mengxi Chen,Pengyi Chen,Benyuan Liu,Jiangchao Yao,Ya Zhang,Yanfeng Wang*

Main category: cs.CV

TL;DR: DISSect是一种新的样本选择方法，通过比较模型预测的相关性差异来识别和剔除噪声数据，从而更有效地加速对比学习的训练过程。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有样本选择方法在冷启动场景下的局限性以及在线选择方法未能充分有效考虑噪声对应关系的问题，提出DISSect方法。

Method: 提出了一种新颖的差分信息采样选择（DISSect）方法，该方法通过比较当前模型和历史模型的预测相关性之间的差值来表征样本质量，从而准确高效地识别噪声对应关系。

Result: DISSect方法在加速训练过程中能够准确高效地区分噪声对应关系。

Conclusion: DISSect方法在三个基准数据集和各种下游任务上的广泛实验证明了其在准确高效地区分噪声对应关系以加速训练方面优于现有最先进方法。

Abstract: The remarkable success of contrastive-learning-based multimodal models has
been greatly driven by training on ever-larger datasets with expensive compute
consumption. Sample selection as an alternative efficient paradigm plays an
important direction to accelerate the training process. However, recent
advances on sample selection either mostly rely on an oracle model to offline
select a high-quality coreset, which is limited in the cold-start scenarios, or
focus on online selection based on real-time model predictions, which has not
sufficiently or efficiently considered the noisy correspondence. To address
this dilemma, we propose a novel Differential-Informed Sample Selection
(DISSect) method, which accurately and efficiently discriminates the noisy
correspondence for training acceleration. Specifically, we rethink the impact
of noisy correspondence on contrastive learning and propose that the
differential between the predicted correlation of the current model and that of
a historical model is more informative to characterize sample quality. Based on
this, we construct a robust differential-based sample selection and analyze its
theoretical insights. Extensive experiments on three benchmark datasets and
various downstream tasks demonstrate the consistent superiority of DISSect over
current state-of-the-art methods. Source code is available at:
https://github.com/MediaBrain-SJTU/DISSect.

</details>


### [62] [Beyond Fully Supervised Pixel Annotations: Scribble-Driven Weakly-Supervised Framework for Image Manipulation Localization](https://arxiv.org/abs/2507.13018)
*Songlin Li,Guofeng Yu,Zhiqing Guo,Yunfeng Diao,Dan Ma,Gaobo Yang,Liejun Wang*

Main category: cs.CV

TL;DR: 该研究提出了首个基于塗鸦的弱监督图像篡改定位框架，并在多种评估中超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决图像篡改定位（IML）中获取像素级标注数据的挑战，本研究探索了塗鸦标注监督这种更高效的弱监督形式。

Method: 提出了一种新的基于塗鸦的弱监督图像篡改定位框架，结合了自监督训练、结构一致性损失、先验感知特征调制模块（PFMM）和门控自适应融合模块（GAFM），并使用置信感知熵最小化损失（${\mathcal{L}}_{ {CEM }}$）来优化预测。

Result: 实验结果表明，该方法在分布内和分布外的平均性能均优于现有的全监督方法。

Conclusion: 该研究提出了首个基于塗鸦的图像篡改定位（Sc-IML）数据集和框架，采用了自监督训练、结构一致性损失、先验感知特征调制模块（PFMM）和门控自适应融合模块（GAFM），并引入了置信感知熵最小化损失（${\mathcal{L}}_{ {CEM }}$），在分布内和分布外测试中均超越了现有全监督方法。

Abstract: Deep learning-based image manipulation localization (IML) methods have
achieved remarkable performance in recent years, but typically rely on
large-scale pixel-level annotated datasets. To address the challenge of
acquiring high-quality annotations, some recent weakly supervised methods
utilize image-level labels to segment manipulated regions. However, the
performance is still limited due to insufficient supervision signals. In this
study, we explore a form of weak supervision that improves the annotation
efficiency and detection performance, namely scribble annotation supervision.
We re-annotated mainstream IML datasets with scribble labels and propose the
first scribble-based IML (Sc-IML) dataset. Additionally, we propose the first
scribble-based weakly supervised IML framework. Specifically, we employ
self-supervised training with a structural consistency loss to encourage the
model to produce consistent predictions under multi-scale and augmented inputs.
In addition, we propose a prior-aware feature modulation module (PFMM) that
adaptively integrates prior information from both manipulated and authentic
regions for dynamic feature adjustment, further enhancing feature
discriminability and prediction consistency in complex scenes. We also propose
a gated adaptive fusion module (GAFM) that utilizes gating mechanisms to
regulate information flow during feature fusion, guiding the model toward
emphasizing potential tampered regions. Finally, we propose a confidence-aware
entropy minimization loss (${\mathcal{L}}_{ {CEM }}$). This loss dynamically
regularizes predictions in weakly annotated or unlabeled regions based on model
uncertainty, effectively suppressing unreliable predictions. Experimental
results show that our method outperforms existing fully supervised approaches
in terms of average performance both in-distribution and out-of-distribution.

</details>


### [63] [Resurrect Mask AutoRegressive Modeling for Efficient and Scalable Image Generation](https://arxiv.org/abs/2507.13032)
*Yi Xin,Le Zhuo,Qi Qin,Siqi Luo,Yuewen Cao,Bin Fu,Yangfan He,Hongsheng Li,Guangtao Zhai,Xiaohong Liu,Peng Gao*

Main category: cs.CV

TL;DR: MaskGIL是一个改进的掩码自回归模型，通过双向注意力和2D RoPE提高了图像生成质量和效率，性能媲美AR模型，同时支持文本到图像生成和语音到图像转换。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统掩码自回归（MAR）模型在图像生成质量上逊色于标准自回归（AR）模型的问题，并利用MAR模型高效并行解码的优势。

Method: 本研究首先评估了不同的图像分词器，然后提出了一种改进的双向LLaMA架构，将因果注意力替换为双向注意力，并引入了2D RoPE，最终构建了MaskGIL模型。

Result: MaskGIL模型在ImageNet 256x256基准测试中取得了3.71的FID分数，与最先进的AR模型相当，但推理步数仅需8步，远少于AR模型的256步。并且，该模型能够根据文本生成图像，并加速AR生成和实现实时语音到图像转换。

Conclusion: MaskGIL通过改进的双向LLaMA架构，使用双向注意力和2D RoPE，在图像生成质量上媲美甚至超越了最先进的自回归模型，同时显著减少了推理步数。此外，MaskGIL还能通过文本驱动生成图像，并应用于加速自回归生成和实时语音到图像转换。

Abstract: AutoRegressive (AR) models have made notable progress in image generation,
with Masked AutoRegressive (MAR) models gaining attention for their efficient
parallel decoding. However, MAR models have traditionally underperformed when
compared to standard AR models. This study refines the MAR architecture to
improve image generation quality. We begin by evaluating various image
tokenizers to identify the most effective one. Subsequently, we introduce an
improved Bidirectional LLaMA architecture by replacing causal attention with
bidirectional attention and incorporating 2D RoPE, which together form our
advanced model, MaskGIL. Scaled from 111M to 1.4B parameters, MaskGIL achieves
a FID score of 3.71, matching state-of-the-art AR models in the ImageNet
256x256 benchmark, while requiring only 8 inference steps compared to the 256
steps of AR models. Furthermore, we develop a text-driven MaskGIL model with
775M parameters for generating images from text at various resolutions. Beyond
image generation, MaskGIL extends to accelerate AR-based generation and enable
real-time speech-to-image conversion. Our codes and models are available at
https://github.com/synbol/MaskGIL.

</details>


### [64] [Advancing Complex Wide-Area Scene Understanding with Hierarchical Coresets Selection](https://arxiv.org/abs/2507.13061)
*Jingyao Wang,Yiming Chen,Lingyu Si,Changwen Zheng*

Main category: cs.CV

TL;DR: HCS is a plug-and-play method that advances VLM adaptation in complex wide-area scene understanding by selecting minimal, interpretable regions based on an importance function, outperforming existing methods without fine-tuning.


<details>
  <summary>Details</summary>
Motivation: Existing VLMs still face challenges in adaptation to unseen complex wide-area scenes.

Method: Hierarchical Coresets Selection (HCS) mechanism, which progressively refines the selected regions based on the proposed theoretically guaranteed importance function, considering utility, representativeness, robustness, and synergy.

Result: HCS achieves superior performance and universality in various tasks without requiring additional fine-tuning.

Conclusion: HCS enables VLMs to achieve rapid understandings of unseen scenes at any scale using minimal interpretable regions while mitigating insufficient feature density.

Abstract: Scene understanding is one of the core tasks in computer vision, aiming to
extract semantic information from images to identify objects, scene categories,
and their interrelationships. Although advancements in Vision-Language Models
(VLMs) have driven progress in this field, existing VLMs still face challenges
in adaptation to unseen complex wide-area scenes. To address the challenges,
this paper proposes a Hierarchical Coresets Selection (HCS) mechanism to
advance the adaptation of VLMs in complex wide-area scene understanding. It
progressively refines the selected regions based on the proposed theoretically
guaranteed importance function, which considers utility, representativeness,
robustness, and synergy. Without requiring additional fine-tuning, HCS enables
VLMs to achieve rapid understandings of unseen scenes at any scale using
minimal interpretable regions while mitigating insufficient feature density.
HCS is a plug-and-play method that is compatible with any VLM. Experiments
demonstrate that HCS achieves superior performance and universality in various
tasks.

</details>


### [65] [Label-Consistent Dataset Distillation with Detector-Guided Refinement](https://arxiv.org/abs/2507.13074)
*Yawen Zou,Guang Li,Zi Wang,Chunzhi Gu,Chao Zhang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Dataset distillation (DD) aims to generate a compact yet informative dataset
that achieves performance comparable to the original dataset, thereby reducing
demands on storage and computational resources. Although diffusion models have
made significant progress in dataset distillation, the generated surrogate
datasets often contain samples with label inconsistencies or insufficient
structural detail, leading to suboptimal downstream performance. To address
these issues, we propose a detector-guided dataset distillation framework that
explicitly leverages a pre-trained detector to identify and refine anomalous
synthetic samples, thereby ensuring label consistency and improving image
quality. Specifically, a detector model trained on the original dataset is
employed to identify anomalous images exhibiting label mismatches or low
classification confidence. For each defective image, multiple candidates are
generated using a pre-trained diffusion model conditioned on the corresponding
image prototype and label. The optimal candidate is then selected by jointly
considering the detector's confidence score and dissimilarity to existing
qualified synthetic samples, thereby ensuring both label accuracy and
intra-class diversity. Experimental results demonstrate that our method can
synthesize high-quality representative images with richer details, achieving
state-of-the-art performance on the validation set.

</details>


### [66] [Channel-wise Motion Features for Efficient Motion Segmentation](https://arxiv.org/abs/2507.13082)
*Riku Inoue,Masamitsu Tsuchiya,Yuji Yasui*

Main category: cs.CV

TL;DR: 提出了一种名为“通道式运动特征”的新方法，用于高效的运动分割。该方法通过姿态网络提取深度和运动信息，比现有方法快4倍，参数量减少75%，准确性相当。


<details>
  <summary>Details</summary>
Motivation: 为了满足自动驾驶等安全关键型机器人应用中实时、准确地检测所有必需对象的需求，并解决现有运动分割模型（通常联合使用深度、姿态、光流和场景流的子网络，导致计算成本高，阻碍实时性能）的效率问题。

Method: 提出了一种新颖的基于代价体积（cost-volume）的运动特征表示方法，称为通道式运动特征（Channel-wise Motion Features）。该方法通过提取每个实例的深度特征并捕捉场景的三维运动信息来实现。

Result: 与现有技术相比，所提出的通道式运动特征在KITTI数据集、Cityscapes数据集和VCAS-Motion数据集上实现了大约4倍的FPS（每秒帧数），参数量减少到约25%，同时实现了相当的准确性。

Conclusion: 所提出的通道式运动特征（Channel-wise Motion Features）通过仅使用姿态网络（Pose Network）来提取深度特征和捕捉三维运动信息，实现了高效的运动分割，显著降低了计算成本和参数量，同时保持了与现有技术相当的准确性。

Abstract: For safety-critical robotics applications such as autonomous driving, it is
important to detect all required objects accurately in real-time. Motion
segmentation offers a solution by identifying dynamic objects from the scene in
a class-agnostic manner. Recently, various motion segmentation models have been
proposed, most of which jointly use subnetworks to estimate Depth, Pose,
Optical Flow, and Scene Flow. As a result, the overall computational cost of
the model increases, hindering real-time performance.
  In this paper, we propose a novel cost-volume-based motion feature
representation, Channel-wise Motion Features. By extracting depth features of
each instance in the feature map and capturing the scene's 3D motion
information, it offers enhanced efficiency. The only subnetwork used to build
Channel-wise Motion Features is the Pose Network, and no others are required.
Our method not only achieves about 4 times the FPS of state-of-the-art models
in the KITTI Dataset and Cityscapes of the VCAS-Motion Dataset, but also
demonstrates equivalent accuracy while reducing the parameters to about 25$\%$.

</details>


### [67] [Decoupled PROB: Decoupled Query Initialization Tasks and Objectness-Class Learning for Open World Object Detection](https://arxiv.org/abs/2507.13085)
*Riku Inoue,Masamitsu Tsuchiya,Yuji Yasui*

Main category: cs.CV

TL;DR: Decoupled PROB improves Open World Object Detection by introducing ETOP to fix learning conflicts and TDQI to better handle known/unknown objects, outperforming prior methods.


<details>
  <summary>Details</summary>
Motivation: Existing state-of-the-art OWOD models like PROB, while not requiring pseudo-labels for unknown objects, suffer from learning conflicts between objectness and class predictions. This limits their performance.

Method: The proposed Decoupled PROB model addresses learning conflicts in the PROB model by introducing Early Termination of Objectness Prediction (ETOP) to halt objectness predictions at optimal decoder layers. It also enhances performance with Task-Decoupled Query Initialization (TDQI), which combines query selection and learnable queries for efficient feature extraction of known and unknown objects.

Result: Decoupled PROB significantly surpasses all existing methods across several metrics on OWOD benchmarks, demonstrating substantial performance improvements.

Conclusion: Decoupled PROB, incorporating ETOP and TDQI, outperforms existing methods on OWOD benchmarks by resolving learning conflicts and efficiently extracting features for both known and unknown objects.

Abstract: Open World Object Detection (OWOD) is a challenging computer vision task that
extends standard object detection by (1) detecting and classifying unknown
objects without supervision, and (2) incrementally learning new object classes
without forgetting previously learned ones. The absence of ground truths for
unknown objects makes OWOD tasks particularly challenging. Many methods have
addressed this by using pseudo-labels for unknown objects. The recently
proposed Probabilistic Objectness transformer-based open-world detector (PROB)
is a state-of-the-art model that does not require pseudo-labels for unknown
objects, as it predicts probabilistic objectness. However, this method faces
issues with learning conflicts between objectness and class predictions.
  To address this issue and further enhance performance, we propose a novel
model, Decoupled PROB. Decoupled PROB introduces Early Termination of
Objectness Prediction (ETOP) to stop objectness predictions at appropriate
layers in the decoder, resolving the learning conflicts between class and
objectness predictions in PROB. Additionally, we introduce Task-Decoupled Query
Initialization (TDQI), which efficiently extracts features of known and unknown
objects, thereby improving performance. TDQI is a query initialization method
that combines query selection and learnable queries, and it is a module that
can be easily integrated into existing DETR-based OWOD models. Extensive
experiments on OWOD benchmarks demonstrate that Decoupled PROB surpasses all
existing methods across several metrics, significantly improving performance.

</details>


### [68] [DiffOSeg: Omni Medical Image Segmentation via Multi-Expert Collaboration Diffusion Model](https://arxiv.org/abs/2507.13087)
*Han Zhang,Xiangde Luo,Yong Chen,Kang Li*

Main category: cs.CV

TL;DR: A new method called DiffOSeg uses diffusion models in two stages to handle disagreements in medical image segmentation, combining the opinions of different experts to create better segmentations than previous methods.


<details>
  <summary>Details</summary>
Motivation: Annotation variability in medical image segmentation, caused by ambiguous boundaries and diverse clinical expertise, challenges traditional deep learning methods. Existing multi-rater segmentation methods offer limited perspectives, either by generating a consensus or preserving individual preferences, but not both.

Method: DiffOSeg, a two-stage diffusion-based framework. Stage I establishes population consensus through a probabilistic consensus strategy, while Stage II captures expert-specific preference via adaptive prompts.

Result: DiffOSeg outperforms existing state-of-the-art methods across all evaluated metrics on the LIDC-IDRI and NPC-170 datasets.

Conclusion: DiffOSeg, a two-stage diffusion-based framework, simultaneously achieves both consensus-driven and preference-driven segmentation for medical images, outperforming existing state-of-the-art methods on two public datasets.

Abstract: Annotation variability remains a substantial challenge in medical image
segmentation, stemming from ambiguous imaging boundaries and diverse clinical
expertise. Traditional deep learning methods producing single deterministic
segmentation predictions often fail to capture these annotator biases. Although
recent studies have explored multi-rater segmentation, existing methods
typically focus on a single perspective -- either generating a probabilistic
``gold standard'' consensus or preserving expert-specific preferences -- thus
struggling to provide a more omni view. In this study, we propose DiffOSeg, a
two-stage diffusion-based framework, which aims to simultaneously achieve both
consensus-driven (combining all experts' opinions) and preference-driven
(reflecting experts' individual assessments) segmentation. Stage I establishes
population consensus through a probabilistic consensus strategy, while Stage II
captures expert-specific preference via adaptive prompts. Demonstrated on two
public datasets (LIDC-IDRI and NPC-170), our model outperforms existing
state-of-the-art methods across all evaluated metrics. Source code is available
at https://github.com/string-ellipses/DiffOSeg .

</details>


### [69] [GLAD: Generalizable Tuning for Vision-Language Models](https://arxiv.org/abs/2507.13089)
*Yuqi Peng,Pengfei Wang,Jianzhuang Liu,Shifeng Chen*

Main category: cs.CV

TL;DR: GLAD是一种新的、更通用的框架，通过结合LoRA和梯度正则化，解决了现有提示调优方法在少样本学习中的过拟合和通用性问题，并在多项泛化任务上取得了优于先前方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有提示调优方法在少样本场景下容易导致过拟合，并且需要复杂的特定任务模型架构和敏感的超参数调整，限制了其通用性。GLAD旨在提供一个更简单、更通用的框架来解决这些问题。

Method: 提出了一种名为GLAD（Generalizable LoRA tuning with RegulArized GraDient）的框架，该框架结合了LoRA（Low-Rank Adaptation）和一种梯度正则化技术。LoRA本身就能在下游任务中取得与最先进的基于提示的方法相媲美的性能。梯度正则化技术用于缓解LoRA在少样本学习中的过拟合问题，引导模型找到更稳定的参数区域。

Result: GLAD在15个基准数据集上进行了广泛的实验，证明了其在基类到新类泛化、图像域泛化和跨数据集泛化方面的优越性，其性能与现有最先进的基于提示的方法相当，同时避免了复杂的模型架构和超参数调整。

Conclusion: GLAD通过引入基于梯度的正则化技术，成功缓解了LoRA在少样本学习中的过拟合问题，并在15个基准数据集的实验中，在基类到新类泛化、图像域泛化和跨数据集泛化方面均优于先前的方法。

Abstract: Pre-trained vision-language models, such as CLIP, show impressive zero-shot
recognition ability and can be easily transferred to specific downstream tasks
via prompt tuning, even with limited training data. However, existing prompt
tuning methods face two main challenges: (1) In few-shot scenarios, data
scarcity often leads to overfitting, making the model sensitive to changes in
the input domain. (2) To mitigate overfitting, these methods typically rely on
complex task-specific model architectures and sensitive hyperparameter tuning,
severely restricting their general applicability. To address these issues, we
propose a simpler and more general framework called GLAD (Generalizable LoRA
tuning with RegulArized GraDient). We show that merely applying LoRA achieves
performance in downstream tasks comparable to current state-of-the-art
prompt-based methods. While LoRA is effective and easy to use, it remains
susceptible to overfitting in few-shot learning scenarios. To mitigate this
risk, we introduce a gradient-based regularization technique. This technique
effectively steers the optimization trajectory, encouraging the model to find a
more stable parameter region that is robust to variations in data distribution.
Through extensive experiments conducted on 15 benchmark datasets, we
demonstrate that GLAD outperforms previous tuning approaches in terms of
base-to-novel class generalization, image domain generalization, and
cross-dataset generalization. The code will be publicly available.

</details>


### [70] [Deep Learning-Based Fetal Lung Segmentation from Diffusion-weighted MRI Images and Lung Maturity Evaluation for Fetal Growth Restriction](https://arxiv.org/abs/2507.13106)
*Zhennan Xiao,Katharine Brudkiewicz,Zhen Yuan,Rosalind Aughwane,Magdalena Sokolska,Joanna Chappell,Trevor Gaunt,Anna L. David,Andrew P. King,Andrew Melbourne*

Main category: cs.CV

TL;DR: 本研究提出了一种自动化的胎儿肺成熟度评估流程，使用深度学习进行肺部分割，并结合模型拟合评估肺成熟度，结果显示该方法可行且准确。


<details>
  <summary>Details</summary>
Motivation: 为了提高胎儿肺成熟度评估的效率和临床应用性，本研究旨在开发一种自动化的评估流程，以替代耗时的人工分割。

Method: 本研究提出了一种全自动化的胎儿肺成熟度评估流程，包括基于深度学习的胎儿肺部分段模型和基于模型的肺成熟度评估。使用3D nnU-Net模型进行训练，并对nnU-Net预测和手动分割的肺部进行逐体素模型拟合，以量化反映组织微观结构和灌注的IVIM参数。

Result: 基于nnU-Net预测和手动分割的肺部进行的模型拟合结果未显示差异。分割模型达到了82.14%的平均Dice系数，显示出稳健的性能。

Conclusion: 本研究表明，全自动化的胎儿肺成熟度评估流程是可行的，可以支持临床决策。

Abstract: Fetal lung maturity is a critical indicator for predicting neonatal outcomes
and the need for post-natal intervention, especially for pregnancies affected
by fetal growth restriction. Intra-voxel incoherent motion analysis has shown
promising results for non-invasive assessment of fetal lung development, but
its reliance on manual segmentation is time-consuming, thus limiting its
clinical applicability. In this work, we present an automated lung maturity
evaluation pipeline for diffusion-weighted magnetic resonance images that
consists of a deep learning-based fetal lung segmentation model and a
model-fitting lung maturity assessment. A 3D nnU-Net model was trained on
manually segmented images selected from the baseline frames of 4D
diffusion-weighted MRI scans. The segmentation model demonstrated robust
performance, yielding a mean Dice coefficient of 82.14%. Next, voxel-wise model
fitting was performed based on both the nnU-Net-predicted and manual lung
segmentations to quantify IVIM parameters reflecting tissue microstructure and
perfusion. The results suggested no differences between the two. Our work shows
that a fully automated pipeline is possible for supporting fetal lung maturity
assessment and clinical decision-making.

</details>


### [71] [R^2MoE: Redundancy-Removal Mixture of Experts for Lifelong Concept Learning](https://arxiv.org/abs/2507.13107)
*Xiaohan Guo,Yusong Cai,Zejia Liu,Zhengning Wang,Lili Pan,Hongliang Li*

Main category: cs.CV

TL;DR: R^2MoE：一种通过专家知识共享和冗余消除来解决遗忘和参数增长问题的视觉概念学习新方法，性能优于SOTA。


<details>
  <summary>Details</summary>
Motivation: 为了使大型生成模型能够持续学习新的视觉概念，以满足个性化预训练模型满足个别用户偏好的需求。现有的持续视觉概念学习方法受到灾难性遗忘和参数扩展两大挑战的限制。

Method: 提出了一种名为R^2MoE（Redundancy-Removal Mixture of Experts）的参数高效框架，用于终身视觉概念学习。该框架包含三个关键创新：1. 混合专家框架结合路由蒸馏机制，用于知识获取和遗忘缓解；2. 消除冗余层级专家的策略，以减少专家参数数量；3. 分层局部注意力引导的推理方法，以减轻生成视觉概念之间的干扰。

Result: R^2MoE框架在CustomConcept 101数据集上实现了87.8%的遗忘率降低和63.3%的参数量减少，生成的图像在概念保真度上优于现有SOTA方法。

Conclusion: R^2MoE框架通过其混合专家框架、路由蒸馏机制、冗余专家消除策略以及分层局部注意力引导推理方法，有效解决了灾难性遗忘和参数扩展问题，实现了参数高效的终身视觉概念学习。实验证明，该方法在CustomConcept 101数据集上显著优于现有SOTA方法，遗忘率降低了87.8%，参数量减少了63.3%，生成图像具有卓越的概念保真度。

Abstract: Enabling large-scale generative models to continuously learn new visual
concepts is essential for personalizing pre-trained models to meet individual
user preferences. Existing approaches for continual visual concept learning are
constrained by two fundamental challenges: catastrophic forgetting and
parameter expansion. In this paper, we propose Redundancy-Removal Mixture of
Experts (R^2MoE), a parameter-efficient framework for lifelong visual concept
learning that effectively learns new concepts while incurring minimal parameter
overhead. Our framework includes three key innovative contributions: First, we
propose a mixture-of-experts framework with a routing distillation mechanism
that enables experts to acquire concept-specific knowledge while preserving the
gating network's routing capability, thereby effectively mitigating
catastrophic forgetting. Second, we propose a strategy for eliminating
redundant layer-wise experts that reduces the number of expert parameters by
fully utilizing previously learned experts. Third, we employ a hierarchical
local attention-guided inference approach to mitigate interference between
generated visual concepts. Extensive experiments have demonstrated that our
method generates images with superior conceptual fidelity compared to the
state-of-the-art (SOTA) method, achieving an impressive 87.8\% reduction in
forgetting rates and 63.3\% fewer parameters on the CustomConcept 101 dataset.
Our code is available at {https://github.com/learninginvision/R2MoE}

</details>


### [72] [3DKeyAD: High-Resolution 3D Point Cloud Anomaly Detection via Keypoint-Guided Point Clustering](https://arxiv.org/abs/2507.13110)
*Zi Wang,Katsuya Hotta,Koichiro Kamide,Yawen Zou,Chao Zhang,Jun Yu*

Main category: cs.CV

TL;DR: 一种新的3D点云异常检测方法，通过多原型对齐和关键点引导的聚类分析，实现了精确的局部异常检测。


<details>
  <summary>Details</summary>
Motivation: 为了解决高分辨率3D点云在工业检测中检测细微结构异常时面临的计算成本高、空间错位敏感以及难以捕捉局部结构差异等挑战。

Method: 提出了一种基于配准的异常检测框架，结合了多原型对齐和聚类分析。具体来说，将测试样本与多个正常原型进行配准，然后对点云进行聚类，并计算测试样本和原型在每个聚类中的特征相似性。采用关键点引导策略选择聚类中心，以确保聚类中心位于信息丰富的区域，从而实现更稳定、更有意义的基于距离的比较。

Result: 该方法在对象级别和点级别异常检测方面均取得了最先进的性能，即使仅使用原始特征。

Conclusion: 该方法在Real3D-AD基准测试中实现了最先进的性能，能够精确地进行3D异常定位，并且即使仅使用原始特征也表现出色。

Abstract: High-resolution 3D point clouds are highly effective for detecting subtle
structural anomalies in industrial inspection. However, their dense and
irregular nature imposes significant challenges, including high computational
cost, sensitivity to spatial misalignment, and difficulty in capturing
localized structural differences. This paper introduces a registration-based
anomaly detection framework that combines multi-prototype alignment with
cluster-wise discrepancy analysis to enable precise 3D anomaly localization.
Specifically, each test sample is first registered to multiple normal
prototypes to enable direct structural comparison. To evaluate anomalies at a
local level, clustering is performed over the point cloud, and similarity is
computed between features from the test sample and the prototypes within each
cluster. Rather than selecting cluster centroids randomly, a keypoint-guided
strategy is employed, where geometrically informative points are chosen as
centroids. This ensures that clusters are centered on feature-rich regions,
enabling more meaningful and stable distance-based comparisons. Extensive
experiments on the Real3D-AD benchmark demonstrate that the proposed method
achieves state-of-the-art performance in both object-level and point-level
anomaly detection, even using only raw features.

</details>


### [73] [Leveraging Language Prior for Infrared Small Target Detection](https://arxiv.org/abs/2507.13113)
*Pranav Singh,Pravendra Singh*

Main category: cs.CV

TL;DR: 该研究提出了一种结合GPT-4生成的文本描述的多模态红外小目标检测方法，并创建了一个新的多模态数据集，实验结果显示在IRSTD任务上性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 红外小目标检测（IRSTD）在处理红外模糊背景下的微小目标时至关重要，但现有方法主要依赖单一的图像模态，在处理目标尺寸小、分布稀疏的问题上存在局限性。为了克服这一挑战，并借鉴深度学习和视觉语言大模型在视觉识别任务上的成功经验，本研究旨在探索将语言先验知识引入IRSTD任务，以提升检测性能。

Method: 提出了一种新颖的多模态红外小目标检测（IRSTD）框架，该框架利用语言先验知识来指导目标检测。具体而言，利用GPT-4视觉模型生成包含目标位置的文本描述，并通过精心设计的提示工程来提高文本描述的准确性。将文本信息与图像数据相结合，通过语言引导的注意力权重来增强模型对小目标的检测能力。此外，研究者创建了一个包含图像和文本模态的多模态红外数据集，以解决现有数据集仅依赖图像模态的局限性。

Result: 所提出的多模态框架在NUAA-SIRST子集上的IoU、nIoU、Pd和Fa指标上分别取得了9.74%、13.02%、1.25%和67.87%的相对百分比提升。在LangIR数据集的IRSTD-1k子集上，这些指标的提升分别为4.41%、2.04%、2.01%和113.43%。这些结果验证了该框架的有效性。

Conclusion: 研究结果表明，所提出的多模态框架通过整合语言先验知识，在红外小目标检测任务上显著优于现有最先进方法，在NUAA-SIRST和IRSTD-1k数据集的各项指标上均有提升。

Abstract: IRSTD (InfraRed Small Target Detection) detects small targets in infrared
blurry backgrounds and is essential for various applications. The detection
task is challenging due to the small size of the targets and their sparse
distribution in infrared small target datasets. Although existing IRSTD methods
and datasets have led to significant advancements, they are limited by their
reliance solely on the image modality. Recent advances in deep learning and
large vision-language models have shown remarkable performance in various
visual recognition tasks. In this work, we propose a novel multimodal IRSTD
framework that incorporates language priors to guide small target detection. We
leverage language-guided attention weights derived from the language prior to
enhance the model's ability for IRSTD, presenting a novel approach that
combines textual information with image data to improve IRSTD capabilities.
Utilizing the state-of-the-art GPT-4 vision model, we generate text
descriptions that provide the locations of small targets in infrared images,
employing careful prompt engineering to ensure improved accuracy. Due to the
absence of multimodal IR datasets, existing IRSTD methods rely solely on image
data. To address this shortcoming, we have curated a multimodal infrared
dataset that includes both image and text modalities for small target
detection, expanding upon the popular IRSTD-1k and NUDT-SIRST datasets. We
validate the effectiveness of our approach through extensive experiments and
comprehensive ablation studies. The results demonstrate significant
improvements over the state-of-the-art method, with relative percentage
differences of 9.74%, 13.02%, 1.25%, and 67.87% in IoU, nIoU, Pd, and Fa on the
NUAA-SIRST subset, and 4.41%, 2.04%, 2.01%, and 113.43% on the IRSTD-1k subset
of the LangIR dataset, respectively.

</details>


### [74] [RS-TinyNet: Stage-wise Feature Fusion Network for Detecting Tiny Objects in Remote Sensing Images](https://arxiv.org/abs/2507.13120)
*Xiaozheng Jiang,Wei Zhang,Xuerui Mao*

Main category: cs.CV

TL;DR: 提出 RS-TinyNet 模型，通过多维度注意力、可逆分支和渐进融合等技术，有效解决了遥感小目标检测中的信息丢失和特征模糊问题，并在公开数据集上取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 遥感图像中的小目标检测一直面临挑战，因为它们具有有限的空间信息、较弱的特征表示以及在复杂背景下密集分布的特点。现有主流检测器在此类场景下表现不佳，存在改进空间。

Method: 提出了一种名为 RS-TinyNet 的多阶段特征融合与增强模型，包含“小目标显著性建模”和“特征完整性重建”两个核心设计。具体设计了三个逐步特征增强模块，包括利用多维度注意力增强小目标显著性的 MDCA 模块，以及用于保留信息流和融合多层次特征以缩小语义鸿沟并保持结构细节的 ARB 模块和 PFDH 模块。

Result: 在公共遥感数据集 AI-TOD 上，RS-TinyNet 的 AP 和 AP75 指标分别比现有 SOTA 检测器高出 4.0% 和 6.5%。在 DIOR 基准数据集上的评估也进一步验证了其在不同遥感场景下优越的检测性能。

Conclusion: RS-TinyNet 在 AI-TOD 和 DIOR 数据集上均取得了优于现有 SOTA 检测器的性能，分别提高了 4.0% AP 和 6.5% AP75，证明了其在复杂遥感环境中小目标检测方面的有效性和实用性。

Abstract: Detecting tiny objects in remote sensing (RS) imagery has been a
long-standing challenge due to their extremely limited spatial information,
weak feature representations, and dense distributions across complex
backgrounds. Despite numerous efforts devoted, mainstream detectors still
underperform in such scenarios. To bridge this gap, we introduce RS-TinyNet, a
multi-stage feature fusion and enhancement model explicitly tailored for RS
tiny object detection in various RS scenarios. RS-TinyNet comes with two novel
designs: tiny object saliency modeling and feature integrity reconstruction.
Guided by these principles, we design three step-wise feature enhancement
modules. Among them, the multi-dimensional collaborative attention (MDCA)
module employs multi-dimensional attention to enhance the saliency of tiny
objects. Additionally, the auxiliary reversible branch (ARB) and a progressive
fusion detection head (PFDH) module are introduced to preserve information flow
and fuse multi-level features to bridge semantic gaps and retain structural
detail. Comprehensive experiments on public RS dataset AI-TOD show that our
RS-TinyNet surpasses existing state-of-the-art (SOTA) detectors by 4.0% AP and
6.5% AP75. Evaluations on DIOR benchmark dataset further validate its superior
detection performance in diverse RS scenarios. These results demonstrate that
the proposed multi-stage feature fusion strategy offers an effective and
practical solution for tiny object detection in complex RS environments.

</details>


### [75] [Orbis: Overcoming Challenges of Long-Horizon Prediction in Driving World Models](https://arxiv.org/abs/2507.13162)
*Arian Mousakhan,Sudhanshu Mittal,Silvio Galesso,Karim Farid,Thomas Brox*

Main category: cs.CV

TL;DR: 我们开发了一种简单但性能优越的自动驾驶世界模型，它在具有挑战性的场景中表现出色，并且连续自回归模型优于离散 token 模型。


<details>
  <summary>Details</summary>
Motivation: 现有的自动驾驶世界模型在长范围生成和泛化到挑战性场景方面存在困难。

Method: 提出了一种使用简单设计选择、无需额外监督或传感器（如地图、深度或多个摄像头）的世界模型。

Result: 我们的模型在参数量仅为 469M 且在 280 小时的视频数据上训练的情况下，在具有挑战性的场景（如转弯和城市交通）中取得了最先进的性能。

Conclusion: 与基于离散 token 的模型相比，基于流匹配的连续自回归模型在个体设计选择上不易出错且功能更强大。

Abstract: Existing world models for autonomous driving struggle with long-horizon
generation and generalization to challenging scenarios. In this work, we
develop a model using simple design choices, and without additional supervision
or sensors, such as maps, depth, or multiple cameras. We show that our model
yields state-of-the-art performance, despite having only 469M parameters and
being trained on 280h of video data. It particularly stands out in difficult
scenarios like turning maneuvers and urban traffic. We test whether discrete
token models possibly have advantages over continuous models based on flow
matching. To this end, we set up a hybrid tokenizer that is compatible with
both approaches and allows for a side-by-side comparison. Our study concludes
in favor of the continuous autoregressive model, which is less brittle on
individual design choices and more powerful than the model built on discrete
tokens. Code, models and qualitative results are publicly available at
https://lmb-freiburg.github.io/orbis.github.io/.

</details>


### [76] [Synthesizing Reality: Leveraging the Generative AI-Powered Platform Midjourney for Construction Worker Detection](https://arxiv.org/abs/2507.13221)
*Hongyang Zhao,Tianyu Liang,Sina Davari,Daeho Kim*

Main category: cs.CV

TL;DR: 利用Midjourney生成合成数据，提升了建筑工人检测模型的性能，但也揭示了生成式AI在数据增强方面的潜力和局限性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在视觉AI领域取得了显著进展，但在建筑领域，数据多样性和数量不足的挑战依然存在。

Method: 提出了一种新颖的图像合成方法，利用生成式AI平台Midjourney生成了12000张合成图像，并对手动标记的数据集进行了深度神经网络训练。

Result: 在真实建筑图像数据集上，模型在IoU阈值为0.5时达到了0.937的平均精度，在IoU阈值为0.5到0.95时达到了0.642。在合成数据集上，模型的表现接近完美，平均精度分别达到了0.994和0.919。

Conclusion: 生成式AI在解决深度神经网络训练数据稀缺性方面具有巨大潜力，但也存在局限性。

Abstract: While recent advancements in deep neural networks (DNNs) have substantially
enhanced visual AI's capabilities, the challenge of inadequate data diversity
and volume remains, particularly in construction domain. This study presents a
novel image synthesis methodology tailored for construction worker detection,
leveraging the generative-AI platform Midjourney. The approach entails
generating a collection of 12,000 synthetic images by formulating 3000
different prompts, with an emphasis on image realism and diversity. These
images, after manual labeling, serve as a dataset for DNN training. Evaluation
on a real construction image dataset yielded promising results, with the model
attaining average precisions (APs) of 0.937 and 0.642 at
intersection-over-union (IoU) thresholds of 0.5 and 0.5 to 0.95, respectively.
Notably, the model demonstrated near-perfect performance on the synthetic
dataset, achieving APs of 0.994 and 0.919 at the two mentioned thresholds.
These findings reveal both the potential and weakness of generative AI in
addressing DNN training data scarcity.

</details>


### [77] [Leveraging Pre-Trained Visual Models for AI-Generated Video Detection](https://arxiv.org/abs/2507.13224)
*Keerthi Veeramachaneni,Praveen Tirupattur,Amrit Singh Bedi,Mubarak Shah*

Main category: cs.CV

TL;DR: 提出一种基于预训练模型特征提取的新方法，用于检测超越Deepfake的通用内容AI生成视频，在VID-AID数据集上准确率超90%，并将公开代码、模型和数据集。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成视频在内容上日益逼真，特别是超越了人脸为中心的Deepfake，急需能够检测通用内容AI生成视频的方法，以应对虚假信息、隐私和安全威胁。

Method: 利用预训练视觉模型提取特征，并在此基础上训练一个简单的线性分类层来进行视频真实性检测。

Result: 在包含9种不同文本到视频生成模型的约10,000个AI生成视频和4,000个真实视频的VID-AID数据集上，实现了平均准确率超过90%的检测性能。

Conclusion: 本研究提出的方法在VID-AID数据集上实现了超过90%的平均检测准确率，有效地区分了真实视频和AI生成视频，解决了通用内容视频检测的挑战。

Abstract: Recent advances in Generative AI (GenAI) have led to significant improvements
in the quality of generated visual content. As AI-generated visual content
becomes increasingly indistinguishable from real content, the challenge of
detecting the generated content becomes critical in combating misinformation,
ensuring privacy, and preventing security threats. Although there has been
substantial progress in detecting AI-generated images, current methods for
video detection are largely focused on deepfakes, which primarily involve human
faces. However, the field of video generation has advanced beyond DeepFakes,
creating an urgent need for methods capable of detecting AI-generated videos
with generic content. To address this gap, we propose a novel approach that
leverages pre-trained visual models to distinguish between real and generated
videos. The features extracted from these pre-trained models, which have been
trained on extensive real visual content, contain inherent signals that can
help distinguish real from generated videos. Using these extracted features, we
achieve high detection performance without requiring additional model training,
and we further improve performance by training a simple linear classification
layer on top of the extracted features. We validated our method on a dataset we
compiled (VID-AID), which includes around 10,000 AI-generated videos produced
by 9 different text-to-video models, along with 4,000 real videos, totaling
over 7 hours of video content. Our evaluation shows that our approach achieves
high detection accuracy, above 90% on average, underscoring its effectiveness.
Upon acceptance, we plan to publicly release the code, the pre-trained models,
and our dataset to support ongoing research in this critical area.

</details>


### [78] [Efficient Adaptation of Pre-trained Vision Transformer underpinned by Approximately Orthogonal Fine-Tuning Strategy](https://arxiv.org/abs/2507.13260)
*Yiting Yang,Hao Luo,Yuan Sun,Qingsen Yan,Haokui Zhang,Wei Dong,Guoqing Wang,Peng Wang,Yang Yang,Hengtao Shen*

Main category: cs.CV

TL;DR: 通过AOFT策略使低秩适应矩阵近似正交，提升ViTs的泛化能力，并在图像分类任务上取得有竞争力的结果。


<details>
  <summary>Details</summary>
Motivation: 在PEFT（Parameter-Efficient Fine-Tuning）方法中，预训练Vision Transformers（ViTs）的骨干参数通常被冻结，只学习低秩（low-rank）的适配权重矩阵。然而，现有的低秩矩阵（如LoRA和Adapter）的降维和升维投影矩阵的向量并不满足近似正交的特性，而骨干网络的权重矩阵具有这种特性，它能带来更优的泛化能力。因此，研究是否能让低秩矩阵也具有这种近似正交的特性，以进一步提升ViTs的泛化能力。

Method: 提出了一种名为AOFT（Approximately Orthogonal Fine-Tuning）的策略，该策略使用单个可学习向量来生成一系列近似正交的向量，进而构成低秩矩阵的降维和升维投影矩阵，从而使这些矩阵的属性与预训练骨干网络的属性保持一致。

Result: 实验结果表明，AOFT策略在多个下游图像分类任务上取得了与现有方法相当的性能，验证了该策略在增强降维和升维投影矩阵的泛化能力方面的有效性。

Conclusion: 通过引入AOFT策略，我们成功地将低秩适应矩阵的属性与预训练骨干网络对齐，并在图像分类任务上取得了有竞争力的性能，证明了该策略能够增强ViTs的泛化能力。

Abstract: A prevalent approach in Parameter-Efficient Fine-Tuning (PEFT) of pre-trained
Vision Transformers (ViT) involves freezing the majority of the backbone
parameters and solely learning low-rank adaptation weight matrices to
accommodate downstream tasks. These low-rank matrices are commonly derived
through the multiplication structure of down-projection and up-projection
matrices, exemplified by methods such as LoRA and Adapter. In this work, we
observe an approximate orthogonality among any two row or column vectors within
any weight matrix of the backbone parameters; however, this property is absent
in the vectors of the down/up-projection matrices. Approximate orthogonality
implies a reduction in the upper bound of the model's generalization error,
signifying that the model possesses enhanced generalization capability. If the
fine-tuned down/up-projection matrices were to exhibit this same property as
the pre-trained backbone matrices, could the generalization capability of
fine-tuned ViTs be further augmented? To address this question, we propose an
Approximately Orthogonal Fine-Tuning (AOFT) strategy for representing the
low-rank weight matrices. This strategy employs a single learnable vector to
generate a set of approximately orthogonal vectors, which form the
down/up-projection matrices, thereby aligning the properties of these matrices
with those of the backbone. Extensive experimental results demonstrate that our
method achieves competitive performance across a range of downstream image
classification tasks, confirming the efficacy of the enhanced generalization
capability embedded in the down/up-projection matrices.

</details>


### [79] [DiffClean: Diffusion-based Makeup Removal for Accurate Age Estimation](https://arxiv.org/abs/2507.13292)
*Ekta Balkrishna Gavas,Chinmay Hegde,Nasir Memon,Sudipta Banerjee*

Main category: cs.CV

TL;DR: DiffClean利用文本指导的扩散模型去除化妆痕迹，提升了年龄估计和人脸识别的准确性，有效防御了化妆攻击。


<details>
  <summary>Details</summary>
Motivation: 准确的年龄验证对于保护未成年用户免受未经授权访问提供年龄限制服务的在线平台和电子商务网站的侵害至关重要。然而，化妆会改变人脸的外观，从而影响准确的年龄估计和人脸识别。

Method: 提出了一种名为DiffClean的文本指导扩散模型，用于擦除化妆痕迹。

Result: DiffClean在数字模拟和真实化妆图像上，相比现有方法，在年龄估计和人脸识别方面均有提升，具体而言，在年龄估计方面，minor vs. adult accuracy 提升了 4.8%；在人脸识别方面，在 0.01% 的错误匹配率（FMR）下， the total matching rate（TMR）提升了 8.9%。

Conclusion: DiffClean通过文本指导的扩散模型擦除化妆痕迹，能够提升年龄估计（minor vs. adult accuracy 提升 4.8%）和人脸识别（在 FMR=0.01% 时 TMR 提升 8.9%）的性能，有效防御了化妆攻击。

Abstract: Accurate age verification can protect underage users from unauthorized access
to online platforms and e-commerce sites that provide age-restricted services.
However, accurate age estimation can be confounded by several factors,
including facial makeup that can induce changes to alter perceived identity and
age to fool both humans and machines. In this work, we propose DiffClean which
erases makeup traces using a text-guided diffusion model to defend against
makeup attacks. DiffClean improves age estimation (minor vs. adult accuracy by
4.8%) and face verification (TMR by 8.9% at FMR=0.01%) over competing baselines
on digitally simulated and real makeup images.

</details>


### [80] [FashionPose: Text to Pose to Relight Image Generation for Personalized Fashion Visualization](https://arxiv.org/abs/2507.13311)
*Chuancheng Shi,Yixiang Chen,Burong Lei,Jichao Chen*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Realistic and controllable garment visualization is critical for fashion
e-commerce, where users expect personalized previews under diverse poses and
lighting conditions. Existing methods often rely on predefined poses, limiting
semantic flexibility and illumination adaptability. To address this, we
introduce FashionPose, the first unified text-to-pose-to-relighting generation
framework. Given a natural language description, our method first predicts a 2D
human pose, then employs a diffusion model to generate high-fidelity person
images, and finally applies a lightweight relighting module, all guided by the
same textual input. By replacing explicit pose annotations with text-driven
conditioning, FashionPose enables accurate pose alignment, faithful garment
rendering, and flexible lighting control. Experiments demonstrate fine-grained
pose synthesis and efficient, consistent relighting, providing a practical
solution for personalized virtual fashion display.

</details>


### [81] [Revisiting Reliability in the Reasoning-based Pose Estimation Benchmark](https://arxiv.org/abs/2507.13314)
*Junsu Kim,Naeun Kim,Jaeho Lee,Incheol Park,Dongyoon Han,Seungryul Baek*

Main category: cs.CV

TL;DR: RPE基准在可复现性和质量方面存在问题，导致评估不准确。本研究通过修正GT注释并公开分享，解决了这些问题，以实现更公平、更可靠的评估。


<details>
  <summary>Details</summary>
Motivation: 为了解决RPE基准在可复现性和基准质量方面存在的关键问题，这些问题阻碍了公平、一致的定量评估，并减轻了研究人员手动匹配GT注释的负担。

Method: 研究人员进行了详尽的分析，以识别RPE基准中的可复现性和基准质量问题，并修正了GT注释，以提高准确性和一致性。

Result: 研究发现了RPE基准的关键可复现性和基准质量问题，包括图像索引不匹配、图像冗余、场景不平衡、姿势过于简单以及描述模糊，这些问题会影响评估的可靠性。研究人员通过手动匹配和公开释放修正后的GT注释来解决这些问题。

Conclusion: 该研究通过细致的视觉匹配和公开释放修正后的GT注释，缓解了手动工作并提高了可复现性，促进了持续的定量评估和未来人类姿势感知多模态推理的进步。

Abstract: The reasoning-based pose estimation (RPE) benchmark has emerged as a widely
adopted evaluation standard for pose-aware multimodal large language models
(MLLMs). Despite its significance, we identified critical reproducibility and
benchmark-quality issues that hinder fair and consistent quantitative
evaluations. Most notably, the benchmark utilizes different image indices from
those of the original 3DPW dataset, forcing researchers into tedious and
error-prone manual matching processes to obtain accurate ground-truth (GT)
annotations for quantitative metrics (\eg, MPJPE, PA-MPJPE). Furthermore, our
analysis reveals several inherent benchmark-quality limitations, including
significant image redundancy, scenario imbalance, overly simplistic poses, and
ambiguous textual descriptions, collectively undermining reliable evaluations
across diverse scenarios. To alleviate manual effort and enhance
reproducibility, we carefully refined the GT annotations through meticulous
visual matching and publicly release these refined annotations as an
open-source resource, thereby promoting consistent quantitative evaluations and
facilitating future advancements in human pose-aware multimodal reasoning.

</details>


### [82] [A Real-Time System for Egocentric Hand-Object Interaction Detection in Industrial Domains](https://arxiv.org/abs/2507.13326)
*Antonio Finocchiaro,Alessandro Sebastiano Catinello,Michele Mazzamuto,Rosario Leonardi,Antonino Furnari,Giovanni Maria Farinella*

Main category: cs.CV

TL;DR: 提出了一种高效的实时手部-对象交互检测方法，结合了基于Mamba的动作识别和YOLOWorld的对象检测，在ENIGMA-51基准测试上取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 手部-对象交互检测在实时应用中仍然是一个挑战，直观的用户体验依赖于对与周围对象交互的快速、准确检测。

Method: 该方法包含一个动作识别模块和一个对象检测模块，用于在确认交互后识别活动对象。动作识别模块使用了基于EfficientNetV2骨干网络的Mamba模型，对象检测模块使用了经过微调的YOLOWorld。这两个模块以级联架构顺序运行，当动作识别模块预测到接触状态时，会激活对象检测模块。

Result: 基于EfficientNetV2骨干网络的Mamba模型在ENIGMA-51基准测试上达到了38.52%的p-AP，同时实现了30fps的帧率。微调后的YOLOWorld在手部和对象检测上达到了85.13%的AP。

Conclusion: 提出了一种从流式自我中心视觉中检测手部-对象交互的高效方法，该方法能够实时运行。

Abstract: Hand-object interaction detection remains an open challenge in real-time
applications, where intuitive user experiences depend on fast and accurate
detection of interactions with surrounding objects. We propose an efficient
approach for detecting hand-objects interactions from streaming egocentric
vision that operates in real time. Our approach consists of an action
recognition module and an object detection module for identifying active
objects upon confirmed interaction. Our Mamba model with EfficientNetV2 as
backbone for action recognition achieves 38.52% p-AP on the ENIGMA-51 benchmark
at 30fps, while our fine-tuned YOLOWorld reaches 85.13% AP for hand and object.
We implement our models in a cascaded architecture where the action recognition
and object detection modules operate sequentially. When the action recognition
predicts a contact state, it activates the object detection module, which in
turn performs inference on the relevant frame to detect and classify the active
object.

</details>


### [83] [Taming Diffusion Transformer for Real-Time Mobile Video Generation](https://arxiv.org/abs/2507.13343)
*Yushu Wu,Yanyu Li,Anil Kag,Ivan Skorokhodov,Willi Menapace,Ke Ma,Arpit Sahni,Ju Hu,Aliaksandr Siarohin,Dhritiman Sagar,Yanzhi Wang,Sergey Tulyakov*

Main category: cs.CV

TL;DR: 通过一系列优化技术（压缩VAE、剪枝、蒸馏），使DiT模型能在iPhone 16 Pro Max上实现实时（>10 FPS）视频生成。


<details>
  <summary>Details</summary>
Motivation: 为了解决Diffusion Transformers（DiT）在视频生成任务中计算成本高昂、不适用于智能手机等资源受限设备以及实时生成困难的问题。

Method: 本文提出了一系列优化方法，包括：1. 使用高度压缩的变分自编码器（VAE）降低输入数据维度。2. 采用KD引导的感知三级剪枝策略减小模型尺寸。3. 开发了针对DiT的对抗性步长蒸馏技术，将推理步数减少到四步。

Result: 所提出的优化方法使得模型能够在iPhone 16 Pro Max上实现超过10 FPS的视频生成速度，证明了在移动设备上进行实时高质量视频生成的可行性。

Conclusion: 通过采用高度压缩的变分自编码器（VAE）、知识蒸馏（KD）引导的感知三级剪枝策略以及针对DiT的对抗性步长蒸馏技术，成功实现了移动平台上的实时高质量视频生成，在iPhone 16 Pro Max上实现了超过10 FPS的生成速度。

Abstract: Diffusion Transformers (DiT) have shown strong performance in video
generation tasks, but their high computational cost makes them impractical for
resource-constrained devices like smartphones, and real-time generation is even
more challenging. In this work, we propose a series of novel optimizations to
significantly accelerate video generation and enable real-time performance on
mobile platforms. First, we employ a highly compressed variational autoencoder
(VAE) to reduce the dimensionality of the input data without sacrificing visual
quality. Second, we introduce a KD-guided, sensitivity-aware tri-level pruning
strategy to shrink the model size to suit mobile platform while preserving
critical performance characteristics. Third, we develop an adversarial step
distillation technique tailored for DiT, which allows us to reduce the number
of inference steps to four. Combined, these optimizations enable our model to
achieve over 10 frames per second (FPS) generation on an iPhone 16 Pro Max,
demonstrating the feasibility of real-time, high-quality video generation on
mobile devices.

</details>


### [84] [Diffuman4D: 4D Consistent Human View Synthesis from Sparse-View Videos with Spatio-Temporal Diffusion Models](https://arxiv.org/abs/2507.13344)
*Yudong Jin,Sida Peng,Xuan Wang,Tao Xie,Zhen Xu,Yifan Yang,Yujun Shen,Hujun Bao,Xiaowei Zhou*

Main category: cs.CV

TL;DR: 提出了一种新的滑动迭代去噪方法，通过在潜在网格中交替进行空间和时间去噪，增强了4D扩散模型在稀疏视角人像合成中的时空一致性，提升了视频质量并降低了内存消耗。


<details>
  <summary>Details</summary>
Motivation: 解决仅用稀疏视角视频合成高保真人像的挑战。先前的4D扩散模型在生成新视角视频时，时空一致性不足，导致视图合成质量下降。

Method: 提出了一种新颖的滑动迭代去噪过程来增强4D扩散模型时空一致性。具体来说，定义了一个潜在网格，其中每个潜在变量编码特定视角和时间戳的图像、摄像机姿态和人体姿态，然后沿着空间和时间维度使用滑动窗口交替去噪潜在网格，最后从相应去噪的潜在变量解码目标视角的视频。

Result: 实验结果表明，所提出的方法能够合成高质量、一致性的新视角视频，并且显著优于现有方法。

Conclusion: 所提出的方法能够合成高质量、一致性的新视角视频，并且显著优于现有方法。

Abstract: This paper addresses the challenge of high-fidelity view synthesis of humans
with sparse-view videos as input. Previous methods solve the issue of
insufficient observation by leveraging 4D diffusion models to generate videos
at novel viewpoints. However, the generated videos from these models often lack
spatio-temporal consistency, thus degrading view synthesis quality. In this
paper, we propose a novel sliding iterative denoising process to enhance the
spatio-temporal consistency of the 4D diffusion model. Specifically, we define
a latent grid in which each latent encodes the image, camera pose, and human
pose for a certain viewpoint and timestamp, then alternately denoising the
latent grid along spatial and temporal dimensions with a sliding window, and
finally decode the videos at target viewpoints from the corresponding denoised
latents. Through the iterative sliding, information flows sufficiently across
the latent grid, allowing the diffusion model to obtain a large receptive field
and thus enhance the 4D consistency of the output, while making the GPU memory
consumption affordable. The experiments on the DNA-Rendering and ActorsHQ
datasets demonstrate that our method is able to synthesize high-quality and
consistent novel-view videos and significantly outperforms the existing
approaches. See our project page for interactive demos and video results:
https://diffuman4d.github.io/ .

</details>


### [85] [Imbalance in Balance: Online Concept Balancing in Generation Models](https://arxiv.org/abs/2507.13345)
*Yukai Shi,Jiarong Ou,Rui Chen,Haotian Yang,Jiahao Wang,Xin Tao,Pengfei Wan,Di Zhang,Kun Gai*

Main category: cs.CV

TL;DR: 提出IMBA损失函数以提高视觉生成任务中复杂概念的响应能力。


<details>
  <summary>Details</summary>
Motivation: 视觉生成任务中，复杂概念的响应和组合常常不稳定且易出错，这是一个有待探索的领域。

Method: 提出了一种称为IMBA的，按概念划分的均衡损失函数来解决视觉生成任务中复杂概念响应不稳定且易出错的问题。

Result: 提出的IMBA损失函数能显著增强基线模型对概念的响应能力，并取得具有竞争力的结果。

Conclusion: 该方法在线，无需离线数据集处理，只需少量代码即可实现，在新的复杂概念基准测试Inert-CompBench和其他两个公共测试集中，显著增强了基线模型对概念的响应能力，并取得了具有高度竞争力的结果。

Abstract: In visual generation tasks, the responses and combinations of complex
concepts often lack stability and are error-prone, which remains an
under-explored area. In this paper, we attempt to explore the causal factors
for poor concept responses through elaborately designed experiments. We also
design a concept-wise equalization loss function (IMBA loss) to address this
issue. Our proposed method is online, eliminating the need for offline dataset
processing, and requires minimal code changes. In our newly proposed complex
concept benchmark Inert-CompBench and two other public test sets, our method
significantly enhances the concept response capability of baseline models and
yields highly competitive results with only a few codes.

</details>


### [86] [AutoPartGen: Autogressive 3D Part Generation and Discovery](https://arxiv.org/abs/2507.13346)
*Minghao Chen,Jianyuan Wang,Roman Shapovalov,Tom Monnier,Hyunyoung Jung,Dilin Wang,Rakesh Ranjan,Iro Laina,Andrea Vedaldi*

Main category: cs.CV

TL;DR: AutoPartGen是一种新的3D物体生成模型，可以自动识别和生成物体的组成部分，并能将这些部分无缝组装成完整的3D模型。


<details>
  <summary>Details</summary>
Motivation: 为了在3D物体生成任务中实现零件的自动生成和无缝组装。

Method: AutoPartGen以自回归方式生成由3D零件组成的物体，以图像、2D零件掩码或现有3D对象作为输入，生成相应的组合式3D重建。该模型基于具有强大几何表现力的3DShape2VecSet潜在3D表示，并利用其潜在空间的组合特性进行零件生成。模型逐一预测零件，并以先前生成的零件和附加输入（如2D图像、掩码或3D对象）为条件。该过程持续到模型确定所有零件都已生成，从而自动确定零件的类型和数量。生成的零件可以无缝组装成连贯的物体或场景，无需额外优化。

Result: AutoPartGen在3D零件生成质量和整体3D重建能力方面均表现出色，达到了最先进的性能。

Conclusion: AutoPartGen在3D零件生成方面达到了最先进的性能。

Abstract: We introduce AutoPartGen, a model that generates objects composed of 3D parts
in an autoregressive manner. This model can take as input an image of an
object, 2D masks of the object's parts, or an existing 3D object, and generate
a corresponding compositional 3D reconstruction. Our approach builds upon
3DShape2VecSet, a recent latent 3D representation with powerful geometric
expressiveness. We observe that this latent space exhibits strong compositional
properties, making it particularly well-suited for part-based generation tasks.
Specifically, AutoPartGen generates object parts autoregressively, predicting
one part at a time while conditioning on previously generated parts and
additional inputs, such as 2D images, masks, or 3D objects. This process
continues until the model decides that all parts have been generated, thus
determining automatically the type and number of parts. The resulting parts can
be seamlessly assembled into coherent objects or scenes without requiring
additional optimization. We evaluate both the overall 3D generation
capabilities and the part-level generation quality of AutoPartGen,
demonstrating that it achieves state-of-the-art performance in 3D part
generation.

</details>


### [87] [$π^3$: Scalable Permutation-Equivariant Visual Geometry Learning](https://arxiv.org/abs/2507.13347)
*Yifan Wang,Jianjun Zhou,Haoyi Zhu,Wenzheng Chang,Yang Zhou,Zizun Li,Junyi Chen,Jiangmiao Pang,Chunhua Shen,Tong He*

Main category: cs.CV

TL;DR: A new neural network called $\	ext{pi}^3$ reconstructs visual geometry without a fixed reference view, using a permutation-equivariant design for improved robustness and scalability, achieving top results in tasks like pose and depth estimation.


<details>
  <summary>Details</summary>
Motivation: To overcome the instability and failures caused by the conventional fixed reference view in visual geometry reconstruction, $\	ext{pi}^3$ was developed to offer a novel approach.

Method: $\	ext{pi}^3$ utilizes a fully permutation-equivariant feed-forward neural network architecture to predict affine-invariant camera poses and scale-invariant local point maps without relying on a fixed reference view.

Result: The proposed $\	ext{pi}^3$ model demonstrates state-of-the-art performance across multiple tasks including camera pose estimation, monocular/video depth estimation, and dense point map reconstruction, owing to its bias-free and robust design.

Conclusion: $\	ext{pi}^3$ achieves state-of-the-art performance on various visual geometry reconstruction tasks due to its novel permutation-equivariant architecture, which eliminates the need for a reference view and enhances robustness and scalability.

Abstract: We introduce $\pi^3$, a feed-forward neural network that offers a novel
approach to visual geometry reconstruction, breaking the reliance on a
conventional fixed reference view. Previous methods often anchor their
reconstructions to a designated viewpoint, an inductive bias that can lead to
instability and failures if the reference is suboptimal. In contrast, $\pi^3$
employs a fully permutation-equivariant architecture to predict
affine-invariant camera poses and scale-invariant local point maps without any
reference frames. This design makes our model inherently robust to input
ordering and highly scalable. These advantages enable our simple and bias-free
approach to achieve state-of-the-art performance on a wide range of tasks,
including camera pose estimation, monocular/video depth estimation, and dense
point map reconstruction. Code and models are publicly available.

</details>


### [88] [Hierarchical Rectified Flow Matching with Mini-Batch Couplings](https://arxiv.org/abs/2507.13350)
*Yichi Zhang,Yici Yan,Alex Schwing,Zhizhen Zhao*

Main category: cs.CV

TL;DR: 在流匹配中引入小批量耦合，以逐步调整分层模型的层级复杂度，并在合成和成像数据上取得良好效果。


<details>
  <summary>Details</summary>
Motivation: 为了更好地捕捉流匹配模型中固有的速度场多模态特性，以及解决现有分层流匹配模型在层级之间分布复杂度相同的问题。

Method: 提出了一种小批量耦合的方法，用于逐步调整分层校正流匹配中不同层级的分布复杂度。

Result: 通过在分层校正流匹配中引入小批量耦合，成功地在合成数据和成像数据上展示了其优越性。

Conclusion: 通过小批量耦合，在分层校正流匹配中，可以逐步调整层次结构不同层级的分布复杂度，并在合成数据和成像数据上取得了良好的效果。

Abstract: Flow matching has emerged as a compelling generative modeling approach that
is widely used across domains. To generate data via a flow matching model, an
ordinary differential equation (ODE) is numerically solved via forward
integration of the modeled velocity field. To better capture the multi-modality
that is inherent in typical velocity fields, hierarchical flow matching was
recently introduced. It uses a hierarchy of ODEs that are numerically
integrated when generating data. This hierarchy of ODEs captures the
multi-modal velocity distribution just like vanilla flow matching is capable of
modeling a multi-modal data distribution. While this hierarchy enables to model
multi-modal velocity distributions, the complexity of the modeled distribution
remains identical across levels of the hierarchy. In this paper, we study how
to gradually adjust the complexity of the distributions across different levels
of the hierarchy via mini-batch couplings. We show the benefits of mini-batch
couplings in hierarchical rectified flow matching via compelling results on
synthetic and imaging data. Code is available at
https://riccizz.github.io/HRF_coupling.

</details>


### [89] [VideoITG: Multimodal Video Understanding with Instructed Temporal Grounding](https://arxiv.org/abs/2507.13353)
*Shihao Wang,Guo Chen,De-an Huang,Zhiqi Li,Minghan Li,Guilin Li,Jose M. Alvarez,Lei Zhang,Zhiding Yu*

Main category: cs.CV

TL;DR: VideoITG通过指令驱动的帧选择，提升了视频语言模型在长视频理解任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 当前的视频语言模型在处理长视频理解的复杂场景时存在不足。现有方法（如减少帧间冗余、使用独立模型评估图文相关性、利用时间视频接地进行事件定位）主要采用无监督学习，难以应对复杂情况。因此，需要一种能够根据用户指令进行定制化帧采样的方法来改进视频语言模型。

Method: 提出了一种名为VideoITG的定制化帧采样方法，其核心是VidThinker流水线。VidThinker包含三个步骤：1. 根据指令生成详细的片段级标题；2. 通过指令引导的推理检索相关视频片段；3. 进行细粒度帧选择以精确找到最重要视觉证据。此外，还设计了一个即插即用的VideoITG模型，利用视频语言模型的视觉语言对齐和推理能力进行判别式帧选择。

Result: VideoITG模型在多个多模态视频理解基准上实现了持续的性能提升，证明了其有效性和在视频理解方面的巨大潜力。

Conclusion: VideoITG通过VidThinker流水线和VideoITG-40K数据集，结合视频语言模型，在多个视频理解基准上实现了性能提升，展示了其在视频理解方面的优越性和巨大潜力。

Abstract: Recent studies have revealed that selecting informative and relevant video
frames can significantly improve the performance of Video Large Language Models
(Video-LLMs). Current methods, such as reducing inter-frame redundancy,
employing separate models for image-text relevance assessment, or utilizing
temporal video grounding for event localization, substantially adopt
unsupervised learning paradigms, whereas they struggle to address the complex
scenarios in long video understanding. We propose Instructed Temporal Grounding
for Videos (VideoITG), featuring customized frame sampling aligned with user
instructions. The core of VideoITG is the VidThinker pipeline, an automated
annotation framework that explicitly mimics the human annotation process.
First, it generates detailed clip-level captions conditioned on the
instruction; then, it retrieves relevant video segments through
instruction-guided reasoning; finally, it performs fine-grained frame selection
to pinpoint the most informative visual evidence. Leveraging VidThinker, we
construct the VideoITG-40K dataset, containing 40K videos and 500K instructed
temporal grounding annotations. We then design a plug-and-play VideoITG model,
which takes advantage of visual language alignment and reasoning capabilities
of Video-LLMs, for effective frame selection in a discriminative manner.
Coupled with Video-LLMs, VideoITG achieves consistent performance improvements
across multiple multimodal video understanding benchmarks, showing its
superiority and great potentials for video understanding.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [90] [Modeling Open-World Cognition as On-Demand Synthesis of Probabilistic Models](https://arxiv.org/abs/2507.12547)
*Lionel Wong,Katherine M. Collins,Lance Ying,Cedegao E. Zhang,Adrian Weller,Tobias Gersternberg,Timothy O'Donnell,Alexander K. Lew,Jacob D. Andreas,Joshua B. Tenenbaum,Tyler Brooke-Wilson*

Main category: cs.CL

TL;DR: 人类在新颖情境下能够利用广泛的背景知识进行推理。本研究提出了一种结合语言模型和概率程序的模型合成架构（MSA），并通过“模型奥运会”数据集证明，MSA比仅使用语言模型的基线方法更能准确地模拟人类的判断，表明MSA能够实现本地一致推理和全局相关变量的利用。


<details>
  <summary>Details</summary>
Motivation: 探索当人们在面对新颖情境时，如何能够有效地调动广泛的背景知识中的相关因素，并将其用于推理和预测。

Method: 提出了一种名为“模型合成架构”（MSA）的计算模型，该模型结合了语言模型（用于全局相关性检索和模型合成）和概率程序（用于定制的、连贯的世界模型），并使用围绕“模型奥运会”体育片段领域构建的新颖推理数据集对其进行了评估。

Result: MSA在捕捉人类判断方面优于仅使用语言模型的基线方法，并且在语言模型支持的模型合成的直接和链式思考生成方面均表现出优越性。

Conclusion: 这项研究表明，模型合成架构（MSA）可以通过结合分布式和符号表征来模拟人类在开放领域中进行本地一致推理和利用全局相关变量的能力，为理解和复制人类推理提供了一条途径。

Abstract: When faced with novel situations, people are able to marshal relevant
considerations from a wide range of background knowledge and put these to use
in inferences and predictions. What permits us to draw in globally relevant
information and reason over it coherently? Here, we explore the hypothesis that
people use a combination of distributed and symbolic representations to
construct bespoke mental models tailored to novel situations. We propose a
computational implementation of this idea -- a ``Model Synthesis Architecture''
(MSA) -- using language models to implement global relevance-based retrieval
and model synthesis and probabilistic programs to implement bespoke, coherent
world models. We evaluate our MSA as a model of human judgments on a novel
reasoning dataset. The dataset -- built around a `Model Olympics` domain of
sports vignettes -- tests models' capacity for human-like, open-ended reasoning
by requiring (i) judgments about novel causal structures described in language;
(ii) drawing on large bodies of background knowledge; and (iii) doing both in
light of observations that introduce arbitrary novel variables. Our MSA
approach captures human judgments better than language model-only baselines,
under both direct and chain-of-thought generations from the LM that supports
model synthesis. These results suggest that MSAs can be implemented in a way
that mirrors people's ability to deliver locally coherent reasoning over
globally relevant variables, offering a path to understanding and replicating
human reasoning in open-ended domains.

</details>


### [91] [Is This Just Fantasy? Language Model Representations Reflect Human Judgments of Event Plausibility](https://arxiv.org/abs/2507.12553)
*Michael A. Lepori,Jennifer Hu,Ishita Dasgupta,Roma Patel,Thomas Serre,Ellie Pavlick*

Main category: cs.CL

TL;DR: 本研究通过分析模态差异向量，发现语言模型在模态分类方面比预期更可靠，并能模拟人类行为，为理解模态分类提供了新见解。


<details>
  <summary>Details</summary>
Motivation: 为了可靠地完成各种任务，LMs 必须能够辨别句子的模态类别。然而，最近的研究对 LMs 进行模态分类的能力提出了质疑。

Method: 通过识别区分不同模态类别的线性表示（模态差异向量）来分析语言模型（LMs）。

Result: LMs 具有比之前报告的更可靠的模态分类能力。模态差异向量在模型能力提升过程中呈现一致的出现顺序，并且可以模拟精细的人类分类行为。

Conclusion: LMs 能够对句子进行模态分类，并且这些分类能力比之前认为的更可靠。模态差异向量的分析揭示了 LMs 对模态分类的理解比之前报告的更可靠。此外，研究发现这些向量在模型能力提升的过程中（例如训练步骤、层数和参数数量）会以一致的顺序出现。值得注意的是，从 LM 激活中识别出的模态差异向量可用于模拟精细的人类分类行为，从而可能为理解人类如何区分模态类别提供新的视角。

Abstract: Language models (LMs) are used for a diverse range of tasks, from question
answering to writing fantastical stories. In order to reliably accomplish these
tasks, LMs must be able to discern the modal category of a sentence (i.e.,
whether it describes something that is possible, impossible, completely
nonsensical, etc.). However, recent studies have called into question the
ability of LMs to categorize sentences according to modality (Michaelov et al.,
2025; Kauf et al., 2023). In this work, we identify linear representations that
discriminate between modal categories within a variety of LMs, or modal
difference vectors. Analysis of modal difference vectors reveals that LMs have
access to more reliable modal categorization judgments than previously
reported. Furthermore, we find that modal difference vectors emerge in a
consistent order as models become more competent (i.e., through training steps,
layers, and parameter count). Notably, we find that modal difference vectors
identified within LM activations can be used to model fine-grained human
categorization behavior. This potentially provides a novel view into how human
participants distinguish between modal categories, which we explore by
correlating projections along modal difference vectors with human participants'
ratings of interpretable features. In summary, we derive new insights into LM
modal categorization using techniques from mechanistic interpretability, with
the potential to inform our understanding of modal categorization in humans.

</details>


### [92] [The first open machine translation system for the Chechen language](https://arxiv.org/abs/2507.12672)
*Abu-Viskhan A. Umishov,Vladislav A. Grigorian*

Main category: cs.CL

TL;DR: 开源车臣语-俄语翻译模型及数据集发布，提升了濒危语言的机器翻译能力。


<details>
  <summary>Details</summary>
Motivation: 为车臣语这一濒危语言提供机器翻译能力，并促进其语言资源的数字化和保护。

Method: 通过收集数据集并微调大型语言模型NLLB-200来实现车臣语与俄语之间的机器翻译。

Result: 模型在俄译车臣方向的BLEU/ChrF++得分为8.34/34.69，车臣译俄方向为20.89/44.55。同时发布了平行语料库和适配车臣语的多语言句子编码器。

Conclusion: 该研究发布了首个用于车臣语和俄语之间翻译的开源模型及相关数据集，并探索了将其纳入大型多语言翻译模型NLLB-200的微调能力。

Abstract: We introduce the first open-source model for translation between the
vulnerable Chechen language and Russian, and the dataset collected to train and
evaluate it. We explore fine-tuning capabilities for including a new language
into a large language model system for multilingual translation NLLB-200. The
BLEU / ChrF++ scores for our model are 8.34 / 34.69 and 20.89 / 44.55 for
translation from Russian to Chechen and reverse direction, respectively. The
release of the translation models is accompanied by the distribution of
parallel words, phrases and sentences corpora and multilingual sentence encoder
adapted to the Chechen language.

</details>


### [93] [Improving Drug Identification in Overdose Death Surveillance using Large Language Models](https://arxiv.org/abs/2507.12679)
*Arthur J. Funnell,Panayiotis Petousis,Fabrice Harel-Canada,Ruby Romero,Alex A. T. Bui,Adam Koncsol,Hritika Chaturvedi,Chelsea Shover,David Goodman-Meza*

Main category: cs.CL

TL;DR: NLP模型，特别是BioClinicalBERT，在处理验尸报告以识别药物过量方面表现出色，准确性高，速度快，优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 毒品致死率的上升，尤其是由芬太尼驱动的，需要及时准确的监控。然而，关键的过量数据通常被埋藏在自由文本的验尸报告中，导致在编码为ICD-10分类时出现延迟和信息丢失。NLP模型可以自动化和增强过量监控，但之前的应用受到限制。

Method: 使用2020年多个美国司法管辖区的35,433条死亡记录进行模型训练和内部测试。使用3,335条2023-2024年的新数据集进行外部验证。评估了多种NLP方法，包括传统的单标签和多标签分类器，以及像BERT和BioClinicalBERT这样的微调编码器模型，还有像Qwen 3和Llama 3这样的现代解码器模型。使用宏平均F1分数评估模型性能，并计算95%置信区间。

Result: 经过微调的BioClinicalBERT模型在内部测试集上取得了近乎完美的结果（宏F1分数>=0.998）。外部验证证实了其稳健性（宏F1=0.966），其性能优于传统的机器学习、通用BERT模型和各种解码器模型。

Conclusion: NLP模型，特别是像BioClinicalBERT这样经过微调的临床变体，为从自由文本报告中进行过量死亡分类提供了一种高度准确且可扩展的解决方案。这些方法可以显著加快监控工作流程，克服手动ICD-10编码的局限性，并支持新物质使用趋势的近乎实时检测。

Abstract: The rising rate of drug-related deaths in the United States, largely driven
by fentanyl, requires timely and accurate surveillance. However, critical
overdose data are often buried in free-text coroner reports, leading to delays
and information loss when coded into ICD (International Classification of
Disease)-10 classifications. Natural language processing (NLP) models may
automate and enhance overdose surveillance, but prior applications have been
limited. A dataset of 35,433 death records from multiple U.S. jurisdictions in
2020 was used for model training and internal testing. External validation was
conducted using a novel separate dataset of 3,335 records from 2023-2024.
Multiple NLP approaches were evaluated for classifying specific drug
involvement from unstructured death certificate text. These included
traditional single- and multi-label classifiers, as well as fine-tuned
encoder-only language models such as Bidirectional Encoder Representations from
Transformers (BERT) and BioClinicalBERT, and contemporary decoder-only large
language models such as Qwen 3 and Llama 3. Model performance was assessed
using macro-averaged F1 scores, and 95% confidence intervals were calculated to
quantify uncertainty. Fine-tuned BioClinicalBERT models achieved near-perfect
performance, with macro F1 scores >=0.998 on the internal test set. External
validation confirmed robustness (macro F1=0.966), outperforming conventional
machine learning, general-domain BERT models, and various decoder-only large
language models. NLP models, particularly fine-tuned clinical variants like
BioClinicalBERT, offer a highly accurate and scalable solution for overdose
death classification from free-text reports. These methods can significantly
accelerate surveillance workflows, overcoming the limitations of manual ICD-10
coding and supporting near real-time detection of emerging substance use
trends.

</details>


### [94] [AdaptiSent: Context-Aware Adaptive Attention for Multimodal Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2507.12695)
*S M Rafiuddin,Sadia Kamal,Mohammed Rakib,Arunkumar Bagavathi,Atriya Sen*

Main category: cs.CL

TL;DR: AdaptiSent 是一个用于多模态方面基础情感分析 (MABSA) 的新框架，通过自适应跨模态注意力机制提高了从文本和图像进行情感分类和方面词提取的性能。在 Twitter 数据集上的结果显示，AdaptiSent 在准确率、召回率和 F1 分数上均优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 为了提高从文本和图像中进行情感分类和方面词提取的性能。

Method: AdaptiSent 框架，使用自适应跨模态注意力机制，结合动态模态加权和上下文自适应注意力。

Result: AdaptiSent 在准确率、召回率和 F1 分数上均优于现有模型，尤其在识别细微的跨模态关系方面效果显著。

Conclusion: AdaptiSent 设定了 MABSA 的新标准，在理解复杂的多模态信息方面显著优于现有方法。

Abstract: We introduce AdaptiSent, a new framework for Multimodal Aspect-Based
Sentiment Analysis (MABSA) that uses adaptive cross-modal attention mechanisms
to improve sentiment classification and aspect term extraction from both text
and images. Our model integrates dynamic modality weighting and
context-adaptive attention, enhancing the extraction of sentiment and
aspect-related information by focusing on how textual cues and visual context
interact. We tested our approach against several baselines, including
traditional text-based models and other multimodal methods. Results from
standard Twitter datasets show that AdaptiSent surpasses existing models in
precision, recall, and F1 score, and is particularly effective in identifying
nuanced inter-modal relationships that are crucial for accurate sentiment and
aspect term extraction. This effectiveness comes from the model's ability to
adjust its focus dynamically based on the context's relevance, improving the
depth and accuracy of sentiment analysis across various multimodal data sets.
AdaptiSent sets a new standard for MABSA, significantly outperforming current
methods, especially in understanding complex multimodal information.

</details>


### [95] [AudioJudge: Understanding What Works in Large Audio Model Based Speech Evaluation](https://arxiv.org/abs/2507.12705)
*Potsawee Manakul,Woody Haosheng Gan,Michael J. Ryan,Ali Sartaz Khan,Warit Sirichotedumrong,Kunat Pipatanakul,William Held,Diyi Yang*

Main category: cs.CL

TL;DR: 本研究提出了一种基于大型音频模型（LAM）的语音评估新方法 AudioJudge，它能统一处理多种音频评估任务，并通过提示工程优化性能。该方法在与人类偏好相关性方面取得了显著成效，尽管在鲁棒性方面仍存在一些挑战。


<details>
  <summary>Details</summary>
Motivation: 当前语音评估方法存在两大主要挑战：一是需要为不同的音频特征设计专门的评估系统，过程复杂且困难；二是现有的自动评估方法与人类的偏好感知之间存在相关性较差的问题。本研究的动机是探索大型音频模型（LAM）是否能作为一种“裁判”（AudioJudge），提供一个统一的评估框架，以同时解决上述两个关键问题，从而改进语音评估的效率和准确性。

Method: 本研究系统性地研究了将大型音频模型（LAM）用作评估者（AudioJudge）的可行性，以期建立一个统一的语音评估框架。研究人员探索了 AudioJudge 在多种音频评估任务中的应用，包括发音、语速、说话人识别和语音质量检测，以及模拟人类偏好进行自动化评估。通过实验，研究人员比较了不同的提示工程策略，发现音频连接与上下文学习相结合能够显著提升在音频特征检测和人类偏好模拟任务上的表现。此外，研究还引入了一种多方面集成 AudioJudge 方法，将语音评估分解为针对词汇内容、语音质量和副语言特征的专门评估模块，并进行了系统排名基准测试，以衡量其与人类偏好的相关性。最后，研究还对 AudioJudge 的鲁棒性进行了分析，考察了其在声学噪声下的表现以及存在的冗余和位置偏差问题。

Result: 研究结果表明，大型音频模型（LAM）作为评估者（AudioJudge）在处理多种音频评估任务（如发音、语速、说话人识别和语音质量）方面表现出潜力，并能有效模拟人类偏好。通过优化提示工程策略，特别是采用音频连接和上下文学习，能够显著提升 AudioJudge 的性能。集成了多方面评估模块的 AudioJudge 方法在系统排名基准测试中取得了高达 0.91 的 Spearman 相关系数，表明其与人类偏好的高度一致性。鲁棒性分析显示，LAM 在声学噪声下表现稳定，但存在冗余和位置偏差，需要进一步的缓解措施。

Conclusion: 本研究提出了一种名为 AudioJudge 的新型语音评估框架，该框架利用大型音频模型（LAM）作为评估者，旨在解决现有语音评估方法在系统设计和与人类偏好相关性方面的局限性。研究表明，AudioJudge 能够通过统一的框架处理多种音频评估任务，并通过提示工程策略（特别是音频连接和上下文学习）显著提升性能。此外，通过将多方面评估分解为专门的评估模块（词汇内容、语音质量和副语言特征），研究成功实现了高达 0.91 的 Spearman 相关系数，与人类偏好高度一致。尽管 AudioJudge 在噪声环境下表现出鲁棒性，但仍需注意其潜在的冗余和位置偏差问题。

Abstract: Current speech evaluation suffers from two critical limitations: the need and
difficulty of designing specialized systems targeting individual audio
characteristics, and poor correlation between automatic evaluation methods and
human preferences. This work presents a systematic study of Large Audio Model
(LAM) as a Judge, AudioJudge, investigating whether it can provide a unified
evaluation framework that addresses both challenges. We systematically explore
AudioJudge across audio characteristic detection tasks, including
pronunciation, speaking rate, speaker identification and speech quality, and
system-level human preference simulation for automated benchmarking. We
investigate different prompt engineering strategies, finding that audio
concatenation combined with in-context learning significantly improves
performance across both audio characteristic detection and human preference
simulation tasks. We further introduce a multi-aspect ensemble AudioJudge to
enable general-purpose multi-aspect audio evaluation. This method decomposes
speech assessment into specialized judges for lexical content, speech quality,
and paralinguistic features, achieving up to 0.91 Spearman correlation with
human preferences on our system ranking benchmark. Robustness analysis reveals
that while LAMs maintain strong performance under acoustic noise, they exhibit
significant verbosity and positional biases that require careful mitigation.

</details>


### [96] [FLEXITOKENS: Flexible Tokenization for Evolving Language Models](https://arxiv.org/abs/2507.12720)
*Abraham Toluase Owodunni,Orevaoghene Ahia,Sachin Kumar*

Main category: cs.CL

TL;DR: FLEXITOKENS 提出了一种灵活的分词方法，通过学习输入字节序列的边界来适应新数据，提高了语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的语言模型通过固定的子词分词器难以适应新的数据分布，这会导致对分布外域、未见语言或字符集的分词过度碎片化。

Method: 提出了一种包含学习预测输入字节序列边界的子模块的双字节语言模型，将输入编码为可变长度的片段，并引入了 FLEXITOKENS 训练目标，以实现更灵活的分词。

Result: 在多语言基准、形态多样的任务和领域上，FLEXITOKENS 相比子词和其他基于梯度的分词器，可将分词过度碎片化程度降低高达 10%，并提高下游任务性能。

Conclusion: FLEXITOKENS 是一种简化的训练目标，可实现更大的适应性灵活性，在多语言基准、形态多样的任务和领域上，与子词和其他基于梯度的分词器相比，可将分词过度碎片化程度降低高达 10%，并提高下游任务性能。

Abstract: Language models (LMs) are challenging to adapt to new data distributions by
simple finetuning. This is due to the rigidity of their subword tokenizers,
which typically remain unchanged during adaptation. This inflexibility often
leads to inefficient tokenization, causing overfragmentation of
out-of-distribution domains, unseen languages, or scripts. In this work, we
develop byte-level LMs with learnable tokenizers to make tokenization adaptive.
Our models include a submodule that learns to predict boundaries between the
input byte sequence, encoding it into variable-length segments. Existing
tokenizer-free methods train this boundary predictor using an auxiliary loss
that enforces a fixed compression rate across the training corpus, introducing
a new kind of rigidity. We propose FLEXITOKENS, a simplified training objective
that enables significantly greater flexibility during adaptation. Evaluating
across multiple multilingual benchmarks, morphologically diverse tasks, and
domains, we demonstrate that FLEXITOKENS consistently reduces token
over-fragmentation and achieves up to 10\% improvements on downstream task
performance compared to subword and other gradient-based tokenizers. Code and
data for our experiments will be released at
https://github.com/owos/flexitokens

</details>


### [97] [TransEvalnia: Reasoning-based Evaluation and Ranking of Translations](https://arxiv.org/abs/2507.12724)
*Richard Sproat,Tianyu Zhao,Llion Jones*

Main category: cs.CL

TL;DR: TransEvalnia是一个基于LLM的翻译评估系统，通过推理提供细粒度评估和排名，表现优于现有技术，并且其评估结果与人类评分高度一致。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够进行推理、提供细粒度评估、选出最佳翻译并给出量化分数的翻译评估系统。

Method: TransEvalnia是一个基于提示的翻译评估和排名系统，通过推理进行评估和排名。它基于MQM的一个子集进行细粒度评估，选出最佳翻译，并提供各维度和整体翻译的数值分数。

Result: TransEvalnia在英文-日文数据和WMT共享任务的多个语言对上，表现与最先进的MT-Ranker相当或更优。评估LLM（Claude-3.5-Sonnet和Qwen-2.5-72B-Instruct）的评估结果被人类评分者高度接受，其分数与人类评分者分配的分数具有良好的相关性。系统对翻译的呈现顺序敏感，并提出了解决位置偏差的方法。

Conclusion: TransEvalnia在英文-日文数据和WMT共享任务的多个语言对上，表现与最先进的MT-Ranker相当或更优。使用Claude-3.5-Sonnet和Qwen-2.5-72B-Instruct作为评估LLM，其评估结果被人类评分者高度接受，并且LLM分配的分数与人类评分者分配的分数具有良好的相关性。该系统对翻译的呈现顺序敏感，并提出了解决位置偏差的方法。

Abstract: We present TransEvalnia, a prompting-based translation evaluation and ranking
system that uses reasoning in performing its evaluations and ranking. This
system presents fine-grained evaluations based on a subset of the
Multidimensional Quality Metrics (https://themqm.org/), returns an assessment
of which translation it deems the best, and provides numerical scores for the
various dimensions and for the overall translation. We show that TransEvalnia
performs as well as or better than the state-of-the-art MT-Ranker (Moosa et al.
2024) on our own English-Japanese data as well as several language pairs from
various WMT shared tasks. Using Anthropic's Claude-3.5-Sonnet and
Qwen-2.5-72B-Instruct as the evaluation LLMs, we show that the evaluations
returned are deemed highly acceptable to human raters, and that the scores
assigned to the translations by Sonnet, as well as other LLMs, correlate well
with scores assigned by the human raters. We also note the sensitivity of our
system -- as well as MT-Ranker -- to the order in which the translations are
presented, and we propose methods to address this position bias. All data,
including the system's evaluation and reasoning, human assessments, as well as
code is released.

</details>


### [98] [Strategy Adaptation in Large Language Model Werewolf Agents](https://arxiv.org/abs/2507.12732)
*Fuya Nakamori,Yin Jou Huang,Fei Cheng*

Main category: cs.CL

TL;DR: 该研究提出了一种新的狼人杀AI策略自适应方法，通过分析对话和玩家角色，AI能根据游戏情境动态调整策略，从而提高游戏表现。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有狼人杀AI（尤其是基于提示工程的AI）在面对不断变化的游戏情境时，由于其策略隐式定义或固定而无法有效适应的问题。

Method: 提出了一种基于对话内容和玩家角色估计的策略自适应方法，通过显式选择合适的策略来应对变化的游戏情境。

Result: 实验结果表明，与仅使用固定或隐式策略的基线AI相比，该研究提出的策略自适应狼人杀AI在性能上有所提升，验证了该方法的有效性。

Conclusion: 该研究提出的基于对话内容和玩家角色估计的策略自适应方法能够有效提升狼人杀（Werewolf）AI的性能。

Abstract: This study proposes a method to improve the performance of Werewolf agents by
switching between predefined strategies based on the attitudes of other players
and the context of conversations. While prior works of Werewolf agents using
prompt engineering have employed methods where effective strategies are
implicitly defined, they cannot adapt to changing situations. In this research,
we propose a method that explicitly selects an appropriate strategy based on
the game context and the estimated roles of other players. We compare the
strategy adaptation Werewolf agents with baseline agents using implicit or
fixed strategies and verify the effectiveness of our proposed method.

</details>


### [99] [Logit Arithmetic Elicits Long Reasoning Capabilities Without Training](https://arxiv.org/abs/2507.12759)
*Yunxiang Zhang,Muhammad Khalifa,Lechen Zhang,Xin Liu,Ayoung Lee,Xinliang Frederick Zhang,Farima Fatahi Bayat,Lu Wang*

Main category: cs.CL

TL;DR: 通过一个更小的模型使用logits算术（ThinkLogit）或偏好优化（ThinkLogit-DPO）来激发大型语言模型（如Qwen2.5-32B）的长推理能力，无需或只需少量额外训练，显著提升了数学推理性能。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（LRMs）的长推理能力，特别是如何在无需额外训练的情况下激发这种能力。

Method: 提出了一种名为ThinkLogit的解码时方法，利用一个更小的模型通过logits算术来引导一个更大的目标模型进行长推理。进一步提出ThinkLogit-DPO，通过对引导模型进行偏好优化（基于正确/错误推理对）来增强性能。

Result: ThinkLogit在数学推理任务上使Qwen2.5-32B模型的pass@1率相对提高了26%，ThinkLogit-DPO的提升率为29%。ThinkLogit还能迁移强化学习获得的推理技能，使Qwen2.5-32B模型的pass@1率相对提高13%。

Conclusion: 该研究提出了一种名为ThinkLogit的解码时方法，利用一个更小的模型作为引导者，通过logits算术来调整大型语言模型以实现长推理，并且无需额外训练。通过使用DPO（直接偏好优化）对引导模型进行训练（ThinkLogit-DPO），可以进一步提升性能。实验证明，在数学推理任务中，与单独使用Qwen2.5-32B模型相比，ThinkLogit和ThinkLogit-DPO分别带来了26%和29%的pass@1率提升，而引导模型R1-Distill-Qwen1.5B的规模要小21倍。此外，研究还表明ThinkLogit能够迁移通过强化学习获得的长期推理能力，相对于Qwen2.5-32B基线模型，pass@1率提高了13%。总而言之，这项工作提供了一种计算高效的方法，能够以最小或零额外的训练来激发大型模型进行长推理。

Abstract: Large reasoning models (LRMs) can do complex reasoning via long
chain-of-thought (CoT) involving cognitive strategies such as backtracking and
self-correction. Recent studies suggest that some models inherently possess
these long reasoning abilities, which may be unlocked via extra training. Our
work first investigates whether we can elicit such behavior without any
training. To this end, we propose a decoding-time approach, ThinkLogit, which
utilizes logits arithmetic (Liu et al., 2024) to tune a target large LM for
long reasoning using a substantially smaller model as guider. We then show that
we can further boost performance by training the guider model with preference
optimization over correct/incorrect reasoning pairs sampled from both the
target and guider model -- a setup we refer to as ThinkLogit-DPO. Our
experiments demonstrate that ThinkLogit and ThinkLogit-DPO achieve a relative
improvement in pass@1 by 26% and 29%, respectively, over four mathematical
datasets using the Qwen2.5-32B when guided by R1-Distill-Qwen-1.5B -- a model
21x smaller. Lastly, we show that ThinkLogit can transfer long reasoning skills
acquired through reinforcement learning, improving pass@1 by 13% relative
compared to the Qwen2.5-32B base model. Our work presents a
computationally-efficient method to elicit long reasoning in large models with
minimal or no additional training.

</details>


### [100] [Synergy: End-to-end Concept Model](https://arxiv.org/abs/2507.12769)
*Keli Zheng,Zerong Xie*

Main category: cs.CL

TL;DR: Synergy, a byte-level language model, achieves comparable performance to BBPE with fewer tokens and outperforms Llama3 at the same scale. It demonstrates the potential for tokenizer-free architectures by showing emergent position-independent concepts.


<details>
  <summary>Details</summary>
Motivation: To bridge different levels of abstraction in an end-to-end fashion through a learned routing mechanism and explore tokenizer-free architectures.

Method: Synergy is a language model trained as a byte-level language model, utilizing a learned routing mechanism to bridge different levels of abstraction. It learns to tokenize bytes, producing fewer concept tokens than BBPE tokenizers with comparable performance. Positional encodings were removed from the middle part of the model to study its effect on higher abstraction.

Result: The model spontaneously learns to tokenize bytes, producing fewer concept tokens than BBPE tokenizers while maintaining comparable performance. Synergy shows an advantage over Llama3 at the same model scale and training dataset size. Removing positional encodings from the middle part of the model leads to better performance, suggesting the emergence of position-independent concepts.

Conclusion: The findings demonstrate the feasibility of tokenizer-free architectures, paving the way for more robust and flexible pipelines.

Abstract: In this paper, we present Synergy, a language model that bridges different
levels of abstraction in an end-to-end fashion through a learned routing
mechanism. Focusing on low-level linguistic abstraction, we trained our model
as a byte-level language model. Our model spontaneously learns to tokenize
bytes, producing fewer concept tokens than Byte-level Byte Pair Encoder (BBPE)
tokenizers while keeping comparable performance. By comparing with Llama3, we
observed an advantage of Synergy under the same model scale and training
dataset size. Further studies show that the middle part (the higher abstraction
part) of our model performs better when positional encodings are removed,
suggesting the emergence of position-independent concepts. These findings
demonstrate the feasibility of tokenizer-free architectures, paving the way for
more robust and flexible pipelines.

</details>


### [101] [Learning Robust Negation Text Representations](https://arxiv.org/abs/2507.12782)
*Thinh Hung Truong,Karin Verspoor,Trevor Cohn,Timothy Baldwin*

Main category: cs.CL

TL;DR: 通过蒸馏LLM数据来改进BERT等文本编码器在处理否定语义方面的能力，并同时提高了LLM在否定理解上的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的小型文本编码器在处理否定等重要的语义功能时存在不足，这影响了依赖文本嵌入的下游应用。该研究旨在通过改进文本编码器的否定鲁棒性来解决这一问题。

Method: 该研究采用标准的对比学习策略来微调基于BERT的模型，并利用大型语言模型进行蒸馏，以生成包含多种否定和犹豫模式的数据。

Result: 在否定理解能力方面取得了显著的改进，同时在通用基准测试中保持了有竞争力的性能。该方法还可以应用于大型语言模型，从而在否定基准测试中获得更好的性能。

Conclusion: 该研究提出了一种通过蒸馏大型语言模型中的否定和犹豫模式数据来提高文本编码器在否定方面的鲁棒性的策略，并在否定理解能力方面取得了显著的改进，同时在通用基准测试中保持了有竞争力的性能。此外，该方法还可以应用于大型语言模型，从而在否定基准测试中获得更好的性能。

Abstract: Despite rapid adoption of autoregressive large language models, smaller text
encoders still play an important role in text understanding tasks that require
rich contextualized representations. Negation is an important semantic function
that is still not properly captured by such methods, affecting many downstream
applications relying on text embeddings. We propose a strategy to improve
negation robustness of text encoders, by distilling data from large language
models using diverse patterns of negation and hedging. We adopt a standard
contrastive learning strategy to finetune a strong BERT-based model, and
observe large improvement in negation understanding capabilities while
maintaining competitive performance on general benchmarks. In addition, we also
show that our method can be adapted to LLMs, leading to improved performance on
negation benchmarks.

</details>


### [102] [Large Language Models' Internal Perception of Symbolic Music](https://arxiv.org/abs/2507.12808)
*Andrew Shin,Kunitake Kaneko*

Main category: cs.CL

TL;DR: LLMs can generate symbolic music from text descriptions, showing potential but also limitations due to lack of explicit musical training. The study generated a MIDI dataset using LLMs to train models for music tasks.


<details>
  <summary>Details</summary>
Motivation: Investigate how LLMs represent musical concepts by generating symbolic music data from textual prompts and evaluating its utility through recognition and generation tasks, exploring the extent to which LLMs implicitly model symbolic music.

Method: Generated a dataset of LLM-generated MIDI files from textual prompts describing genres and styles. Trained neural networks on this dataset for genre/style classification and melody completion, benchmarking against established models.

Result: The study demonstrates LLMs' potential to implicitly encode musical patterns, as evidenced by the performance of models trained on LLM-generated data in music-related tasks.

Conclusion: LLMs can infer rudimentary musical structures and temporal relationships from text, but their capabilities are limited by a lack of explicit musical context.

Abstract: Large language models (LLMs) excel at modeling relationships between strings
in natural language and have shown promise in extending to other symbolic
domains like coding or mathematics. However, the extent to which they
implicitly model symbolic music remains underexplored. This paper investigates
how LLMs represent musical concepts by generating symbolic music data from
textual prompts describing combinations of genres and styles, and evaluating
their utility through recognition and generation tasks. We produce a dataset of
LLM-generated MIDI files without relying on explicit musical training. We then
train neural networks entirely on this LLM-generated MIDI dataset and perform
genre and style classification as well as melody completion, benchmarking their
performance against established models. Our results demonstrate that LLMs can
infer rudimentary musical structures and temporal relationships from text,
highlighting both their potential to implicitly encode musical patterns and
their limitations due to a lack of explicit musical context, shedding light on
their generative capabilities for symbolic music.

</details>


### [103] [Are Knowledge and Reference in Multilingual Language Models Cross-Lingually Consistent?](https://arxiv.org/abs/2507.12838)
*Xi Ai,Mahardika Krisna Ihsani,Min-Yen Kan*

Main category: cs.CL

TL;DR: 本文研究了多语言模型在跨语言知识一致性方面的表现，发现模型在一致性上存在差异，并提出代码转换训练和跨语言词对齐是提高性能和一致性的有效方法。


<details>
  <summary>Details</summary>
Motivation: 为了评估跨语言迁移能力、维持模型跨语言知识的事实性以及保持语言模型性能的对等性，需要考虑跨语言一致性。

Method: 本文研究了跨语言一致性，主要通过检查跨越语言的代码混合共指语句来分析跨语言知识一致性，并利用可解释性方法来分析模型在跨语言环境下的行为。

Result: 多语言模型在不同程度的一致性上表现出差异，具体取决于语言家族、语言因素以及特定层级的跨语言一致性瓶颈。代码转换训练和跨语言词对齐目标在提高多语言性能和跨语言一致性方面显示出最有希望的结果。

Conclusion: 研究结果表明，在许多情况下，知识并非跨语言一致的，但代码转换训练和跨语言词对齐目标显示出最有希望的结果，这强调了跨语言对齐监督和代码转换训练对于提高多语言性能和跨语言一致性都具有重要意义。

Abstract: Cross-lingual consistency should be considered to assess cross-lingual
transferability, maintain the factuality of the model knowledge across
languages, and preserve the parity of language model performance. We are thus
interested in analyzing, evaluating, and interpreting cross-lingual consistency
for factual knowledge. We examine code-mixed coreferential statements conveyed
identical knowledge across languages to study cross-lingual knowledge
consistency. We use some interpretability approaches to analyze the behavior of
a model in cross-lingual contexts, discovering that multilingual models show
different levels of consistency, subject to language families, linguistic
factors, and a bottleneck in cross-lingual consistency on a particular layer.
In addition, we evaluate common strategies aimed at improving multilingual
performance to observe whether these strategies can improve knowledge
consistency at the same time. While knowledge is not cross-lingual consistency
in many cases, code-switching training and cross-lingual word alignment
objectives show the most promising results, emphasizing the noteworthiness of
cross-lingual alignment supervision and code-switching training for both
multilingual performance and cross-lingual consistency enhancement.

</details>


### [104] [Making Language Model a Hierarchical Classifier and Generator](https://arxiv.org/abs/2507.12930)
*Yihong Wang,Zhonglin Jiang,Ningyuan Xi,Yue Zhao,Qingqing Gu,Xiyuan Chen,Hao Wu,Sheng Xu,Hange Zhou,Yong Chen,Luo Ji*

Main category: cs.CL

TL;DR: 受人类分层思维的启发，我们提出了一种分层解码器架构，其中不同的层同时解码文本。通过将预训练语言模型改编成这种形式，并将语言头复制到选定的中间层并进行微调，我们在多项任务上获得了最先进的性能，证明了通用分层推理器的潜力。


<details>
  <summary>Details</summary>
Motivation: 受人类分层思维能力的启发，提出了一种可以同时解码文本的不同层级的分层解码器架构。

Method: 将预训练语言模型改编成分层解码器架构，将语言头复制到选定的中间层，并使用不同的任务输入进行微调。

Result: 所提出的分层解码器范例在分层文本分类、分类引导生成和分层文本生成等任务上获得了最先进的性能。

Conclusion: 通过实验验证了这些选择的中间层可以被调整以产生有意义且合理的内容，并且这种分层解码器的范例可以在多项任务上获得最先进的性能，例如分层文本分类、分类引导生成和分层文本生成。这项研究提出了从头开始预训练的通用分层推理器的可能性。

Abstract: Decoder-only language models, such as GPT and LLaMA, generally decode on the
last layer. Motivated by human's hierarchical thinking capability, we propose
that a hierarchical decoder architecture could be built with different layers
decoding texts simultaneously. Due to limited time and computationally
resources, we choose to adapt a pretrained language model into this form of
hierarchical decoder. Language heads of the last layer are copied to different
selected intermediate layers, and fine-tuned with different task inputs. By
thorough experiments, we validate that these selective intermediate layers
could be adapted to speak meaningful and reasonable contents, and this paradigm
of hierarchical decoder can obtain state-of-the-art performances on multiple
tasks such as hierarchical text classification, classification-guided
generation, and hierarchical text generation. This study suggests the
possibility of a generalized hierarchical reasoner, pretraining from scratch.

</details>


### [105] [MRT at IberLEF-2025 PRESTA Task: Maximizing Recovery from Tables with Multiple Steps](https://arxiv.org/abs/2507.12981)
*Maximiliano Hormazábal Lagos,Álvaro Bueno Sáez,Héctor Cerezo-Costas,Pedro Alonso Doval,Jorge Alcalde Vesteiro*

Main category: cs.CL

TL;DR: This paper presents a Python code generation approach using LLMs for Spanish table-based QA, achieving 85% accuracy by optimizing prompts and using open-source models.


<details>
  <summary>Details</summary>
Motivation: The paper presents an approach for the IberLEF 2025 Task PRESTA (Questions and Answers about Tables in Spanish), evolving from a previous implementation for a related task.

Method: The solution involves generating Python code using LLMs to filter and process tables. This process includes analyzing table content, selecting relevant columns, generating natural language instructions, translating them to code, executing the code, and handling errors. Open-source LLMs and fine-grained optimized prompts are used for each step.

Result: The approach achieved an accuracy score of 85% in the task.

Conclusion: The approach achieved an accuracy score of 85% in the IberLEF 2025 Task PRESTA.

Abstract: This paper presents our approach for the IberLEF 2025 Task PRESTA: Preguntas
y Respuestas sobre Tablas en Espa\~nol (Questions and Answers about Tables in
Spanish). Our solution obtains answers to the questions by implementing Python
code generation with LLMs that is used to filter and process the table. This
solution evolves from the MRT implementation for the Semeval 2025 related task.
The process consists of multiple steps: analyzing and understanding the content
of the table, selecting the useful columns, generating instructions in natural
language, translating these instructions to code, running it, and handling
potential errors or exceptions. These steps use open-source LLMs and
fine-grained optimized prompts for each step. With this approach, we achieved
an accuracy score of 85\% in the task.

</details>


### [106] [Formalizing Attack Scenario Description: A Proposed Model](https://arxiv.org/abs/2507.13076)
*Quentin Goux,Nadira Lammari*

Main category: cs.CL

TL;DR: 本文提出了一个形式化模型，用于描述攻击上下文和场景，以满足自动化网络安全流程的需求，并展示了其在攻击分析和攻击脚本生成方面的应用。


<details>
  <summary>Details</summary>
Motivation: 组织必须不断投入大量精力来保护其资产，这使得它们越来越多地采用自动化网络安全技术。然而，流程自动化需要对输入数据进行形式化。本文旨在满足使用攻击场景作为输入的流程的这一需求。

Method: 文章提出了一个包含攻击上下文描述及其场景的新颖形式化模型，并使用 UML 类模型对其进行了抽象。

Result: 提出了一种形式化模型，并展示了其在攻击分析和自动生成攻击脚本方面的应用。

Conclusion: 该模型可用于上游攻击分析过程以及网络安全培训的自动攻击脚本生成。

Abstract: Organizations face an ever-changing threat landscape. They must continuously
dedicate significant efforts to protect their assets, making their adoption of
increased cybersecurity automation inevitable. However, process automation
requires formalization of input data. Through this paper, we address this need
for processes that use attack scenarios as input. Among these processes, one
can mention both the generation of scripts for attack simulation and training
purposes, as well as the analysis of attacks. Therefore, the paper's main
research contribution is a novel formal model that encompasses the attack's
context description and its scenario. It is abstracted using UML class model.
Once the description of our model done, we will show how it could serve an
upstream attack analysis process. We will show also its use for an automatic
generation of attack scripts in the context of cybersecurity training. These
two uses cases constitute the second contribution of this present research
work.

</details>


### [107] [SemCSE: Semantic Contrastive Sentence Embeddings Using LLM-Generated Summaries For Scientific Abstracts](https://arxiv.org/abs/2507.13105)
*Marc Brinner,Sina Zarriess*

Main category: cs.CL

TL;DR: SemCSE是一种无监督方法，利用LLM生成的摘要通过对比学习来提升科学文本的语义嵌入效果，并在基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统基于引文的方法未能充分反映语义相似性的问题，提出了一种新的无监督方法来学习科学文本的语义嵌入。

Method: SemCSE是一种利用LLM生成的摘要，通过对比学习来学习科学文本语义嵌入的无监督方法。

Result: SemCSE在新的基准测试中展示了更强的语义分离能力，并在SciRepEval基准测试中取得了最先进的性能。

Conclusion: SemCSE通过利用LLM生成的摘要来训练模型，在科学文本嵌入任务上取得了最先进的性能，证明了以语义为中心的训练方法的有效性。

Abstract: We introduce SemCSE, an unsupervised method for learning semantic embeddings
of scientific texts. Building on recent advances in contrastive learning for
text embeddings, our approach leverages LLM-generated summaries of scientific
abstracts to train a model that positions semantically related summaries closer
together in the embedding space. This resulting objective ensures that the
model captures the true semantic content of a text, in contrast to traditional
citation-based approaches that do not necessarily reflect semantic similarity.
To validate this, we propose a novel benchmark designed to assess a model's
ability to understand and encode the semantic content of scientific texts,
demonstrating that our method enforces a stronger semantic separation within
the embedding space. Additionally, we evaluate SemCSE on the comprehensive
SciRepEval benchmark for scientific text embeddings, where it achieves
state-of-the-art performance among models of its size, thus highlighting the
benefits of a semantically focused training approach.

</details>


### [108] [A Computational Framework to Identify Self-Aspects in Text](https://arxiv.org/abs/2507.13115)
*Jaya Caporusso,Matthew Purver,Senja Pollak*

Main category: cs.CL

TL;DR: 本研究计划开发一个计算框架，用于在文本中识别“自我”的各个方面，构建相关本体和数据集，并评估不同NLP模型在该任务上的表现，最终应用于心理健康等领域。


<details>
  <summary>Details</summary>
Motivation: “自我”是认知科学和现象学中的一个重要概念，但在自然语言处理（NLP）领域探索不足。由于“自我”的许多方面与心理健康等已得到充分研究的现象相关，因此需要系统性的NLP分析来识别文本中的“自我”方面。

Method: 开发计算框架，包括构建“自我”方面本体、创建标准化注释数据集，并评估传统判别模型、生成式大语言模型和基于嵌入的检索方法。

Result: 将开发并评估多种模型（判别模型、大语言模型、检索方法），并根据可解释性、与事实的符合度、准确性和计算效率进行评估，最终将表现最佳的模型应用于心理健康和现象学实证研究。

Conclusion: 该博士论文旨在开发一个计算框架，用于在文本中识别“自我”的各个方面。计划引入一个“自我”方面的本体和一个标准化的注释数据集。将开发并评估传统的判别模型、生成式大语言模型和基于嵌入的检索方法，并根据可解释性、与事实的符合度、准确性和计算效率这四个主要标准进行评估。表现最佳的模型将应用于心理健康和现象学实证研究的案例研究。

Abstract: This Ph.D. proposal introduces a plan to develop a computational framework to
identify Self-aspects in text. The Self is a multifaceted construct and it is
reflected in language. While it is described across disciplines like cognitive
science and phenomenology, it remains underexplored in natural language
processing (NLP). Many of the aspects of the Self align with psychological and
other well-researched phenomena (e.g., those related to mental health),
highlighting the need for systematic NLP-based analysis. In line with this, we
plan to introduce an ontology of Self-aspects and a gold-standard annotated
dataset. Using this foundation, we will develop and evaluate conventional
discriminative models, generative large language models, and embedding-based
retrieval approaches against four main criteria: interpretability, ground-truth
adherence, accuracy, and computational efficiency. Top-performing models will
be applied in case studies in mental health and empirical phenomenology.

</details>


### [109] [Assessing the Reliability of LLMs Annotations in the Context of Demographic Bias and Model Explanation](https://arxiv.org/abs/2507.13138)
*Hadi Mohammadi,Tina Shahedi,Pablo Mosteiro,Massimo Poesio,Ayoub Bagheri,Anastasia Giachanou*

Main category: cs.CL

TL;DR: 该研究发现，在性别歧视检测任务中，推文内容比注释者的人口统计特征更能影响标签决策。此外，用人口统计特征引导生成式AI模型作为注释者，并不能提高其性能，有时反而会降低性能。研究强调，专注于内容解释和健全的注释协议是实现公平性更可靠的方法。


<details>
  <summary>Details</summary>
Motivation: 为了开发公平的自然语言处理（NLP）系统，特别是像性别歧视检测这样的任务，理解注释来源的可变性至关重要，因为人口统计偏差是一个令人担忧的问题。

Method: 本研究使用广义线性混合模型量化了人口统计特征对标签决策的影响，并评估了生成式人工智能（GenAI）模型作为注释者的可靠性，通过人口统计特征引导它们，并使用可解释人工智能（XAI）技术来分析模型预测。

Result: 研究结果表明，尽管人口统计因素在统计学上存在，但它们只占观察到的方差的一小部分（8%），而推文内容是主导因素。此外，研究还发现，简单的角色提示通常无法提高GenAI模型与人类判断的一致性，有时甚至会降低其性能。可解释人工智能（XAI）技术显示，模型预测主要依赖于与性别歧视相关的特定内容标记，而不是人口统计特征的相关性。

Conclusion: 该研究认为，专注于以内容为驱动的解释和健壮的注释协议，比潜在的模拟更可靠地实现公平性。

Abstract: Understanding the sources of variability in annotations is crucial for
developing fair NLP systems, especially for tasks like sexism detection where
demographic bias is a concern. This study investigates the extent to which
annotator demographic features influence labeling decisions compared to text
content. Using a Generalized Linear Mixed Model, we quantify this inf luence,
finding that while statistically present, demographic factors account for a
minor fraction ( 8%) of the observed variance, with tweet content being the
dominant factor. We then assess the reliability of Generative AI (GenAI) models
as annotators, specifically evaluating if guiding them with demographic
personas improves alignment with human judgments. Our results indicate that
simplistic persona prompting often fails to enhance, and sometimes degrades,
performance compared to baseline models. Furthermore, explainable AI (XAI)
techniques reveal that model predictions rely heavily on content-specific
tokens related to sexism, rather than correlates of demographic
characteristics. We argue that focusing on content-driven explanations and
robust annotation protocols offers a more reliable path towards fairness than
potentially persona simulation.

</details>


### [110] [Feature-based analysis of oral narratives from Afrikaans and isiXhosa children](https://arxiv.org/abs/2507.13164)
*Emma Sharratt,Annelien Smith,Retief Louw,Daleen Klop,Febe de Wet,Herman Kamper*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Oral narrative skills are strong predictors of later literacy development.
This study examines the features of oral narratives from children who were
identified by experts as requiring intervention. Using simple machine learning
methods, we analyse recorded stories from four- and five-year-old Afrikaans-
and isiXhosa-speaking children. Consistent with prior research, we identify
lexical diversity (unique words) and length-based features (mean utterance
length) as indicators of typical development, but features like articulation
rate prove less informative. Despite cross-linguistic variation in
part-of-speech patterns, the use of specific verbs and auxiliaries associated
with goal-directed storytelling is correlated with a reduced likelihood of
requiring intervention. Our analysis of two linguistically distinct languages
reveals both language-specific and shared predictors of narrative proficiency,
with implications for early assessment in multilingual contexts.

</details>


### [111] [GEMMAS: Graph-based Evaluation Metrics for Multi Agent Systems](https://arxiv.org/abs/2507.13190)
*Jisoo Lee,Raeyoung Chang,Dongwook Kwon,Harmanpreet Singh,Nikhil Verma*

Main category: cs.CL

TL;DR: Existing evaluations of multi-agent language model systems focus only on final output correctness, ignoring inefficient communication and coordination. We introduce GEMMAS, a graph-based framework with metrics like IDS and UPR to analyze the internal collaboration process, revealing significant differences in efficiency and redundancy even when final accuracy is similar.


<details>
  <summary>Details</summary>
Motivation: Existing evaluations of multi-agent systems built on language models focus only on the correctness of the final output, overlooking inefficiencies in communication and coordination that lead to redundant reasoning and higher computational costs.

Method: A graph-based evaluation framework named GEMMAS is introduced, modeling agent interactions as a directed acyclic graph. Two process-level metrics, Information Diversity Score (IDS) and Unnecessary Path Ratio (UPR), are proposed to measure semantic variation in inter-agent messages and quantify redundant reasoning paths, respectively.

Result: GEMMAS was evaluated across five benchmarks, showing significant variations in IDS and UPR even among systems with similar accuracy. For instance, on GSM8K, systems with a 2.1% difference in accuracy differed by 12.8% in IDS and 80% in UPR, demonstrating substantial variation in internal collaboration.

Conclusion: Outcome-only metrics are insufficient for evaluating multi-agent performance, and process-level diagnostics are important for designing more interpretable and resource-efficient collaborative AI systems.

Abstract: Multi-agent systems built on language models have shown strong performance on
collaborative reasoning tasks. However, existing evaluations focus only on the
correctness of the final output, overlooking how inefficient communication and
poor coordination contribute to redundant reasoning and higher computational
costs. We introduce GEMMAS, a graph-based evaluation framework that analyzes
the internal collaboration process by modeling agent interactions as a directed
acyclic graph. To capture collaboration quality, we propose two process-level
metrics: Information Diversity Score (IDS) to measure semantic variation in
inter-agent messages, and Unnecessary Path Ratio (UPR) to quantify redundant
reasoning paths. We evaluate GEMMAS across five benchmarks and highlight
results on GSM8K, where systems with only a 2.1% difference in accuracy differ
by 12.8% in IDS and 80% in UPR, revealing substantial variation in internal
collaboration. These findings demonstrate that outcome-only metrics are
insufficient for evaluating multi-agent performance and highlight the
importance of process-level diagnostics in designing more interpretable and
resource-efficient collaborative AI systems.

</details>


### [112] [Automatically assessing oral narratives of Afrikaans and isiXhosa children](https://arxiv.org/abs/2507.13205)
*R. Louw,E. Sharratt,F. de Wet,C. Jacobs,A. Smith,H. Kamper*

Main category: cs.CL

TL;DR: A system for automatically assessing oral narratives of preschool children in Afrikaans and isiXhosa was developed. It uses ASR and an ML scoring model, comparing a linear model to an LLM. The LLM system shows better performance and is comparable to human experts in identifying children needing intervention, aiming to support teachers in providing personalized learning.


<details>
  <summary>Details</summary>
Motivation: Developing narrative and comprehension skills in early childhood is critical for later literacy. However, teachers in large preschool classrooms struggle to accurately identify students who require intervention.

Method: The system uses automatic speech recognition followed by a machine learning scoring model to predict narrative and comprehension scores. For scoring predicted transcripts, we compare a linear model to a large language model (LLM).

Result: The LLM-based system outperforms the linear model in most cases, but the linear system is competitive despite its simplicity. The LLM-based system is comparable to a human expert in flagging children who require intervention.

Conclusion: LLM-based system is comparable to a human expert in flagging children who require intervention, and outperforms the linear model in most cases, but the linear system is competitive despite its simplicity. We lay the foundation for automatic oral assessments in classrooms, giving teachers extra capacity to focus on personalised support for children's learning.

Abstract: Developing narrative and comprehension skills in early childhood is critical
for later literacy. However, teachers in large preschool classrooms struggle to
accurately identify students who require intervention. We present a system for
automatically assessing oral narratives of preschool children in Afrikaans and
isiXhosa. The system uses automatic speech recognition followed by a machine
learning scoring model to predict narrative and comprehension scores. For
scoring predicted transcripts, we compare a linear model to a large language
model (LLM). The LLM-based system outperforms the linear model in most cases,
but the linear system is competitive despite its simplicity. The LLM-based
system is comparable to a human expert in flagging children who require
intervention. We lay the foundation for automatic oral assessments in
classrooms, giving teachers extra capacity to focus on personalised support for
children's learning.

</details>


### [113] [Enhancing Cross-task Transfer of Large Language Models via Activation Steering](https://arxiv.org/abs/2507.13236)
*Xinyu Tang,Zhihao Lv,Xiaoxue Cheng,Junyi Li,Wayne Xin Zhao,Zujie Wen,Zhiqiang Zhang,Jun Zhou*

Main category: cs.CL

TL;DR: CAST框架通过操纵LLM的内部激活状态，利用高资源任务的样本来适应低资源任务，实现了有效的跨任务知识迁移，且无需参数更新或输入扩展，在性能、可扩展性和效率方面均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 旨在解决大型语言模型（LLMs）在数据稀疏场景下面对未见过的任务时表现不佳的问题，并克服现有跨任务小样本学习方法在鲁棒性、可扩展性和效率方面的挑战。

Method: 通过分析LLM潜在空间中的激活模式，观察到跨任务小样本学习中的增强激活具有一致的模式。基于此，提出CAST框架，首先从高资源任务中选择有影响力和多样化的样本，然后利用其对比表征增强的激活来使LLM适应低资源任务，整个过程无需参数更新或输入扩展。

Result: 实验结果表明，CAST在跨领域和跨语言迁移设置中均优于其他方法，并表现出更好的可扩展性和更低的计算成本。

Conclusion: 该研究提出了一种名为CAST的新型跨任务激活引导迁移框架，通过操纵模型的内部激活状态来实现有效的知识迁移，解决了现有跨任务小样本学习方法在鲁棒性、可扩展性和效率方面的挑战。

Abstract: Large language models (LLMs) have shown impressive abilities in leveraging
pretrained knowledge through prompting, but they often struggle with unseen
tasks, particularly in data-scarce scenarios. While cross-task in-context
learning offers a direct solution for transferring knowledge across tasks, it
still faces critical challenges in terms of robustness, scalability, and
efficiency. In this paper, we investigate whether cross-task transfer can be
achieved via latent space steering without parameter updates or input
expansion. Through an analysis of activation patterns in the latent space of
LLMs, we observe that the enhanced activations induced by in-context examples
have consistent patterns across different tasks. Inspired by these findings, we
propose CAST, a novel Cross-task Activation Steering Transfer framework that
enables effective transfer by manipulating the model's internal activation
states. Our approach first selects influential and diverse samples from
high-resource tasks, then utilizes their contrastive representation-enhanced
activations to adapt LLMs to low-resource tasks. Extensive experiments across
both cross-domain and cross-lingual transfer settings show that our method
outperforms competitive baselines and demonstrates superior scalability and
lower computational costs.

</details>


### [114] [HATS: Hindi Analogy Test Set for Evaluating Reasoning in Large Language Models](https://arxiv.org/abs/2507.13238)
*Ashray Gupta,Rohan Joseph,Sunny Rai*

Main category: cs.CL

TL;DR: 该研究提出了HATS，一个印地语类比测试集，并展示了接地链式思维方法可以提高模型在印地语类比推理中的表现，但模型在英语提示下表现更好。


<details>
  <summary>Details</summary>
Motivation: 填补评估大型语言模型在印地语中推理能力的资源空白，并了解其跨语言泛化能力。

Method: 提出HATS（一个包含405个多项选择题的印地语类比测试集），并采用接地链式思维方法来评估和改进大型语言模型在印地语类比推理方面的能力。

Result: 在一项针对最先进的多语言大型语言模型的基准测试中，接地链式思维方法在印地语类比问题上提高了模型性能。然而，研究发现，无论采用何种提示策略，模型在英语提示下表现最佳。

Conclusion: 该研究提出了HATS，一个包含405个多项选择题的印地语类比测试集，旨在评估大型语言模型在印地语中的推理能力。研究结果表明，虽然接地链式思维方法能提高模型在印地语类比任务上的表现，但模型在英语提示下表现最佳。

Abstract: Analogies test a model's ability to infer implicit relationships between
concepts, making them a key benchmark for evaluating reasoning capabilities.
While large language models (LLMs) are widely evaluated for reasoning in
English, their abilities in Indic languages remain understudied, limiting our
understanding of whether these models generalize across languages. To address
this gap, we introduce a new Hindi Analogy Test Set (HATS), comprising 405
multiple-choice questions sourced from Indian government exams. We benchmark
state-of-the-art multilingual LLMs using various prompting strategies and
introduce a grounded Chain of Thought approach that leverages cognitive
theories of analogical reasoning. This approach improves model performance on
Hindi analogy questions. Our experiments show that models perform best with
English prompts, irrespective of the prompting strategy. Our test set addresses
the lack of a critical resource to evaluate LLM reasoning capabilities in
Hindi.

</details>


### [115] [Automating Steering for Safe Multimodal Large Language Models](https://arxiv.org/abs/2507.13255)
*Lyucheng Wu,Mengru Wang,Ziwen Xu,Tri Cao,Nay Oo,Bryan Hooi,Shumin Deng*

Main category: cs.CL

TL;DR: AutoSteer enhances MLLM safety during inference without fine-tuning by using a safety score, a prober, and a refusal head to detect and mitigate risks from adversarial inputs.


<details>
  <summary>Details</summary>
Motivation: To improve the safety of Multimodal Large Language Models (MLLMs) when faced with adversarial multimodal inputs.

Method: AutoSteer is a modular and adaptive inference-time intervention technology that does not require fine-tuning. It includes a Safety Awareness Score (SAS) to identify safety-relevant distinctions in model layers, an adaptive safety prober to estimate the likelihood of toxic outputs from intermediate representations, and a lightweight Refusal Head to modulate generation when risks are detected.

Result: Experiments on LLaVA-OV and Chameleon across diverse safety-critical benchmarks show that AutoSteer significantly reduces the Attack Success Rate (ASR) for textual, visual, and cross-modal threats while maintaining general abilities.

Conclusion: AutoSteer is a practical, interpretable, and effective framework for safer deployment of multimodal AI systems.

Abstract: Recent progress in Multimodal Large Language Models (MLLMs) has unlocked
powerful cross-modal reasoning abilities, but also raised new safety concerns,
particularly when faced with adversarial multimodal inputs. To improve the
safety of MLLMs during inference, we introduce a modular and adaptive
inference-time intervention technology, AutoSteer, without requiring any
fine-tuning of the underlying model. AutoSteer incorporates three core
components: (1) a novel Safety Awareness Score (SAS) that automatically
identifies the most safety-relevant distinctions among the model's internal
layers; (2) an adaptive safety prober trained to estimate the likelihood of
toxic outputs from intermediate representations; and (3) a lightweight Refusal
Head that selectively intervenes to modulate generation when safety risks are
detected. Experiments on LLaVA-OV and Chameleon across diverse safety-critical
benchmarks demonstrate that AutoSteer significantly reduces the Attack Success
Rate (ASR) for textual, visual, and cross-modal threats, while maintaining
general abilities. These findings position AutoSteer as a practical,
interpretable, and effective framework for safer deployment of multimodal AI
systems.

</details>


### [116] [QuestA: Expanding Reasoning Capacity in LLMs via Question Augmentation](https://arxiv.org/abs/2507.13266)
*Jiazheng Li,Hong Lu,Kaiyue Wen,Zaiwen Yang,Jiaxuan Gao,Hongzhou Lin,Yi Wu,Jingzhao Zhang*

Main category: cs.CL

TL;DR: QuestA通过在RL训练中加入部分答案来提升LLM在数学推理任务上的表现，尤其是在难题上，并实现了新的最先进结果。


<details>
  <summary>Details</summary>
Motivation: 为了解决RL在改进多步推理（尤其是在难题上）的有效性方面受到质疑的挑战。

Method: QuestA，一种通过问题增强（Question Augmentation）的策略，在RL训练中引入部分解决方案以降低问题难度并提供更具信息量的学习信号。

Result: QuestA在数学推理任务的RL训练中，不仅提高了pass@1，也提高了pass@k，特别是在标准RL难以取得进展的难题上。使用1.5B参数模型在AIME24上达到67.1%（+5.3%），在AIME25上达到59.5%（+10.0%），在HMMT25上达到35.5%（+4.0%），取得了新的最先进结果。

Conclusion: QuestA通过引入部分解决方案在训练期间降低问题难度，提供更具信息量的学习信号，从而提高了RL训练在数学推理任务上的有效性。该方法不仅提高了pass@1，也提高了pass@k，特别是在标准RL难以取得进展的难题上。QuestA能够持续改进像DeepScaleR和OpenMath Nemotron这样的强大开源模型，进一步增强它们的推理能力，并在数学基准测试中取得了新的最先进结果。此外，QuestA在提高样本效率方面有理论依据，为通过RL扩展推理能力提供了一条实用且可推广的途径。

Abstract: Reinforcement learning (RL) has become a key component in training large
language reasoning models (LLMs). However, recent studies questions its
effectiveness in improving multi-step reasoning-particularly on hard problems.
To address this challenge, we propose a simple yet effective strategy via
Question Augmentation: introduce partial solutions during training to reduce
problem difficulty and provide more informative learning signals. Our method,
QuestA, when applied during RL training on math reasoning tasks, not only
improves pass@1 but also pass@k-particularly on problems where standard RL
struggles to make progress. This enables continual improvement over strong
open-source models such as DeepScaleR and OpenMath Nemotron, further enhancing
their reasoning capabilities. We achieve new state-of-the-art results on math
benchmarks using 1.5B-parameter models: 67.1% (+5.3%) on AIME24, 59.5% (+10.0%)
on AIME25, and 35.5% (+4.0%) on HMMT25. Further, we provide theoretical
explanations that QuestA improves sample efficiency, offering a practical and
generalizable pathway for expanding reasoning capability through RL.

</details>


### [117] [Overview of the TalentCLEF 2025: Skill and Job Title Intelligence for Human Capital Management](https://arxiv.org/abs/2507.13275)
*Luis Gasco,Hermenegildo Fabregat,Laura García-Sardiña,Paula Estrella,Daniel Deniz,Alvaro Rodrigo,Rabih Zbib*

Main category: cs.CL

TL;DR: TalentCLEF 2025 是一个专注于技能和职位智能的评估活动，旨在通过提供公开基准来推动人力资本管理领域语言技术的发展，并已成功吸引了大量团队参与。


<details>
  <summary>Details</summary>
Motivation: 为了填补人才获取、技能提升策略和劳动力规划领域缺乏可靠、公平且经过公开数据和开放基准评估的模型这一空白。

Method: 通过对真实工作申请进行匿名化和手动注释，构建了包括多语言职位匹配和基于职位名称的技能预测两个任务的语料库。评估涵盖了单一语言和跨语言场景，并对性别偏见进行了评估。

Result: 76个注册团队提交了280多项参赛作品。大多数系统采用基于多语言编码器的模型，并通过对比学习进行微调，其中一些系统利用大型语言模型进行数据增强或重新排序。结果表明，训练策略比模型本身的大小具有更大的影响。

Conclusion: TalentCLEF 2025 提供了该领域首个公开基准，并鼓励开发适用于劳动力市场的健壮、公平和可转移的语言技术。

Abstract: Advances in natural language processing and large language models are driving
a major transformation in Human Capital Management, with a growing interest in
building smart systems based on language technologies for talent acquisition,
upskilling strategies, and workforce planning. However, the adoption and
progress of these technologies critically depend on the development of reliable
and fair models, properly evaluated on public data and open benchmarks, which
have so far been unavailable in this domain.
  To address this gap, we present TalentCLEF 2025, the first evaluation
campaign focused on skill and job title intelligence. The lab consists of two
tasks: Task A - Multilingual Job Title Matching, covering English, Spanish,
German, and Chinese; and Task B - Job Title-Based Skill Prediction, in English.
Both corpora were built from real job applications, carefully anonymized, and
manually annotated to reflect the complexity and diversity of real-world labor
market data, including linguistic variability and gender-marked expressions.
  The evaluations included monolingual and cross-lingual scenarios and covered
the evaluation of gender bias.
  TalentCLEF attracted 76 registered teams with more than 280 submissions. Most
systems relied on information retrieval techniques built with multilingual
encoder-based models fine-tuned with contrastive learning, and several of them
incorporated large language models for data augmentation or re-ranking. The
results show that the training strategies have a larger effect than the size of
the model alone. TalentCLEF provides the first public benchmark in this field
and encourages the development of robust, fair, and transferable language
technologies for the labor market.

</details>


### [118] [Multi-Agent Synergy-Driven Iterative Visual Narrative Synthesis](https://arxiv.org/abs/2507.13285)
*Wang Xi,Quan Shi,Tian Yu,Yujie Peng,Jiayi Sun,Mengxing Ren,Zenghui Ding,Ningguang Yao*

Main category: cs.CL

TL;DR: RCPS是一个新的演示文稿生成框架，在内容、连贯性和设计方面优于现有方法，并由PREVAL评估工具进行验证。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在生成逻辑一致、布局优化的演示文稿方面存在不足，难以达到专业标准。

Method: 提出了一种名为RCPS（Reflective Coherent Presentation Synthesis）的新型框架，该框架整合了三个关键组件：（1）深度结构化叙事规划；（2）自适应布局生成；（3）迭代优化循环。此外，还提出了PREVAL，一个基于偏好的评估框架，采用增强了的基于原理的多维度模型来评估内容、连贯性和设计方面的演示文稿质量。

Result: 实验结果表明，RCPS在所有质量维度上均显著优于基线方法，生成的演示文稿与人类专家的标准非常接近。PREVAL与人类判断具有很强的相关性，证实了其作为评估演示文稿质量的可靠自动化工具的有效性。

Conclusion: RCPS显著优于基线方法，并且生成的演示文稿接近人类专家的标准。PREVAL与人类判断高度相关，可作为评估演示文稿质量的可靠自动化工具。

Abstract: Automated generation of high-quality media presentations is challenging,
requiring robust content extraction, narrative planning, visual design, and
overall quality optimization. Existing methods often produce presentations with
logical inconsistencies and suboptimal layouts, thereby struggling to meet
professional standards. To address these challenges, we introduce RCPS
(Reflective Coherent Presentation Synthesis), a novel framework integrating
three key components: (1) Deep Structured Narrative Planning; (2) Adaptive
Layout Generation; (3) an Iterative Optimization Loop. Additionally, we propose
PREVAL, a preference-based evaluation framework employing rationale-enhanced
multi-dimensional models to assess presentation quality across Content,
Coherence, and Design. Experimental results demonstrate that RCPS significantly
outperforms baseline methods across all quality dimensions, producing
presentations that closely approximate human expert standards. PREVAL shows
strong correlation with human judgments, validating it as a reliable automated
tool for assessing presentation quality.

</details>


### [119] [AbGen: Evaluating Large Language Models in Ablation Study Design and Evaluation for Scientific Research](https://arxiv.org/abs/2507.13300)
*Yilun Zhao,Weiyuan Chen,Zhijian Xu,Manasi Patwardhan,Yixin Liu,Chengye Wang,Lovekesh Vig,Arman Cohan*

Main category: cs.CL

TL;DR: 介绍AbGen基准，用于评估LLM设计消融实验的能力，发现LLM表现不如人类专家，且现有自动化评估方法不可靠。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在设计科学研究消融实验方面的能力，并考察现有自动化评估方法的可靠性。

Method: 提出AbGen基准来评估LLM设计消融实验的能力，该基准包含1500个专家标注的例子。开发AbGen-Eval来评估自动化评估方法的可靠性。

Result: LLM在生成消融实验设计方面与人类专家存在显著差距。现有的自动化评估方法不可靠，与人类评估存在显著差异。

Conclusion: LLM在设计科学研究消融实验方面仍有巨大差距，需要开发更有效、更可靠的基于LLM的评估系统。

Abstract: We introduce AbGen, the first benchmark designed to evaluate the capabilities
of LLMs in designing ablation studies for scientific research. AbGen consists
of 1,500 expert-annotated examples derived from 807 NLP papers. In this
benchmark, LLMs are tasked with generating detailed ablation study designs for
a specified module or process based on the given research context. Our
evaluation of leading LLMs, such as DeepSeek-R1-0528 and o4-mini, highlights a
significant performance gap between these models and human experts in terms of
the importance, faithfulness, and soundness of the ablation study designs.
Moreover, we demonstrate that current automated evaluation methods are not
reliable for our task, as they show a significant discrepancy when compared to
human assessment. To better investigate this, we develop AbGen-Eval, a
meta-evaluation benchmark designed to assess the reliability of commonly used
automated evaluation systems in measuring LLM performance on our task. We
investigate various LLM-as-Judge systems on AbGen-Eval, providing insights for
future research on developing more effective and reliable LLM-based evaluation
systems for complex scientific tasks.

</details>


### [120] [HapticCap: A Multimodal Dataset and Task for Understanding User Experience of Vibration Haptic Signals](https://arxiv.org/abs/2507.13318)
*Guimin Hu,Daniel Hershcovich,Hasti Seifi*

Main category: cs.CL

TL;DR: HapticCap是一个包含92,070个haptic-text对的数据集，用于描述振动信号的感知、情感和联想属性。研究人员还提出了haptic-caption检索任务，并使用T5和AST模型取得了最佳结果。


<details>
  <summary>Details</summary>
Motivation: 为了解决haptic信号设计中的挑战，即缺乏带有文本描述的大型haptic振动数据集以及现有模型描述振动信号能力的限制。

Method: 提出了一种基于监督对比学习的框架，将文本表示和振动信号结合起来，以解决haptic-caption检索任务。

Result: 创建了HapticCap数据集，包含92,070个haptic-text对，并验证了T5和AST模型的组合在haptic-caption检索任务上的有效性，特别是在针对每个描述类别单独训练时。

Conclusion: HapticCap数据集的创建和haptic-caption检索任务的提出，为haptic信号的文本描述提供了新的途径，其中T5和AST模型的结合在haptic-caption检索任务中表现最佳。

Abstract: Haptic signals, from smartphone vibrations to virtual reality touch feedback,
can effectively convey information and enhance realism, but designing signals
that resonate meaningfully with users is challenging. To facilitate this, we
introduce a multimodal dataset and task, of matching user descriptions to
vibration haptic signals, and highlight two primary challenges: (1) lack of
large haptic vibration datasets annotated with textual descriptions as
collecting haptic descriptions is time-consuming, and (2) limited capability of
existing tasks and models to describe vibration signals in text. To advance
this area, we create HapticCap, the first fully human-annotated
haptic-captioned dataset, containing 92,070 haptic-text pairs for user
descriptions of sensory, emotional, and associative attributes of vibrations.
Based on HapticCap, we propose the haptic-caption retrieval task and present
the results of this task from a supervised contrastive learning framework that
brings together text representations within specific categories and vibrations.
Overall, the combination of language model T5 and audio model AST yields the
best performance in the haptic-caption retrieval task, especially when
separately trained for each description category.

</details>


### [121] [Social and Political Framing in Search Engine Results](https://arxiv.org/abs/2507.13325)
*Amrit Poudel,Tim Weninger*

Main category: cs.CL

TL;DR: 搜索引擎及其用户都可能导致搜索结果中的偏见，从而加剧信息两极分化。


<details>
  <summary>Details</summary>
Motivation: 研究搜索引擎和有意识形态驱动的用户查询如何共同影响搜索结果中的偏见，填补了现有研究的空白。

Method: 通过分析政治和社会话题的数据集来分析主流搜索引擎的输出。

Result: 搜索引擎不仅会优先考虑内容，而且有意识形态驱动的用户查询会加剧这些偏见，导致某些论述的放大。不同搜索引擎在优先考虑的来源方面也存在显著差异。

Conclusion: 搜索结果会放大某些论述，并可能加剧意识形态的分裂，从而加剧信息两极分化。

Abstract: Search engines play a crucial role in shaping public discourse by influencing
how information is accessed and framed. While prior research has extensively
examined various dimensions of search bias -- such as content prioritization,
indexical bias, political polarization, and sources of bias -- an important
question remains underexplored: how do search engines and
ideologically-motivated user queries contribute to bias in search results. This
study analyzes the outputs of major search engines using a dataset of political
and social topics. The findings reveal that search engines not only prioritize
content in ways that reflect underlying biases but also that
ideologically-driven user queries exacerbate these biases, resulting in the
amplification of specific narratives. Moreover, significant differences were
observed across search engines in terms of the sources they prioritize. These
results suggest that search engines may play a pivotal role in shaping public
perceptions by reinforcing ideological divides, thereby contributing to the
broader issue of information polarization.

</details>


### [122] [Vision-and-Language Training Helps Deploy Taxonomic Knowledge but Does Not Fundamentally Alter It](https://arxiv.org/abs/2507.13328)
*Yulu Qin,Dheeraj Varghese,Adam Dahlgren Lindström,Lucia Donatelli,Kanishka Misra,Najoung Kim*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Does vision-and-language (VL) training change the linguistic representations
of language models in meaningful ways? Most results in the literature have
shown inconsistent or marginal differences, both behaviorally and
representationally. In this work, we start from the hypothesis that the domain
in which VL training could have a significant effect is lexical-conceptual
knowledge, in particular its taxonomic organization. Through comparing minimal
pairs of text-only LMs and their VL-trained counterparts, we first show that
the VL models often outperform their text-only counterparts on a text-only
question-answering task that requires taxonomic understanding of concepts
mentioned in the questions. Using an array of targeted behavioral and
representational analyses, we show that the LMs and VLMs do not differ
significantly in terms of their taxonomic knowledge itself, but they differ in
how they represent questions that contain concepts in a taxonomic relation vs.
a non-taxonomic relation. This implies that the taxonomic knowledge itself does
not change substantially through additional VL training, but VL training does
improve the deployment of this knowledge in the context of a specific task,
even when the presentation of the task is purely linguistic.

</details>


### [123] [The Imitation Game: Turing Machine Imitator is Length Generalizable Reasoner](https://arxiv.org/abs/2507.13332)
*Zhouqi Hua,Wenwei Zhang,Chengqi Lyu,Yuzhe Gu,Songyang Gao,Kuikun Liu,Kai Chen*

Main category: cs.CL

TL;DR: 本研究提出TAIL方法，通过模仿图灵机执行过程合成链式思考数据，有效提升LLM的长度泛化能力，并在多项算法任务中超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有针对Transformer类LLM长度泛化能力的研究主要集中在数据驱动的方法上，但这些方法在算术运算和符号操作任务上存在任务特定和性能有限的问题。为了寻求更通用的解决方案，本研究关注可计算的推理问题，并提出TAIL方法来提升LLM的长度泛化能力。

Method: 本研究提出了一种名为“图灵机模仿学习”（TAIL）的方法，通过合成模仿图灵机执行过程的链式思考（CoT）数据来提升大型语言模型（LLM）的长度泛化能力。具体而言，TAIL将推理步骤分解为原子状态，以减轻捷径学习，并引入显式的内存提取机制来解决动态和长程数据访问的困难。

Result: TAIL方法显著提高了Qwen2.5-7B模型在多种任务上的长度泛化能力和整体性能，超越了先前的方法和DeepSeek-R1。实验结果证实，图灵机的关键概念对TAIL实现长度泛化至关重要，模型在注意力层中表现出与图灵机读写行为一致的特性。

Conclusion: 该研究表明，Transformer类大语言模型（LLM）在处理比训练时遇到的序列更长的问题时，即长度泛化能力方面存在核心挑战。现有方法多集中于数据驱动的方法，但这些方法往往是任务特定的且整体性能有限。本研究提出了一种名为“图灵机模仿学习”（TAIL）的新方法，旨在通过模仿图灵机的执行过程来提升LLM的长度泛化能力。TAIL通过合成链式思考（CoT）数据，将推理步骤分解为原子状态，以缓解捷径学习问题，并通过显式的内存提取机制来降低动态和长程数据访问的难度。实验结果表明，TAIL在不依赖任何技巧的情况下，显著提高了模型在各种任务上的长度泛化能力和性能，超越了现有方法和DeepSeek-R1。研究还发现，图灵机的关键概念（而非思考模式）对于TAIL的长度泛化至关重要，模型在注意力层中展现出与图灵机读写行为一致的特性。

Abstract: Length generalization, the ability to solve problems of longer sequences than
those observed during training, poses a core challenge of Transformer-based
large language models (LLM). Although existing studies have predominantly
focused on data-driven approaches for arithmetic operations and symbolic
manipulation tasks, these approaches tend to be task-specific with limited
overall performance. To pursue a more general solution, this paper focuses on a
broader case of reasoning problems that are computable, i.e., problems that
algorithms can solve, thus can be solved by the Turing Machine. From this
perspective, this paper proposes Turing MAchine Imitation Learning (TAIL) to
improve the length generalization ability of LLMs. TAIL synthesizes
chain-of-thoughts (CoT) data that imitate the execution process of a Turing
Machine by computer programs, which linearly expands the reasoning steps into
atomic states to alleviate shortcut learning and explicit memory fetch
mechanism to reduce the difficulties of dynamic and long-range data access in
elementary operations. To validate the reliability and universality of TAIL, we
construct a challenging synthetic dataset covering 8 classes of algorithms and
18 tasks. Without bells and whistles, TAIL significantly improves the length
generalization ability as well as the performance of Qwen2.5-7B on various
tasks using only synthetic data, surpassing previous methods and DeepSeek-R1.
The experimental results reveal that the key concepts in the Turing Machine,
instead of the thinking styles, are indispensable for TAIL for length
generalization, through which the model exhibits read-and-write behaviors
consistent with the properties of the Turing Machine in their attention layers.
This work provides a promising direction for future research in the learning of
LLM reasoning from synthetic data.

</details>


### [124] [A Survey of Context Engineering for Large Language Models](https://arxiv.org/abs/2507.13334)
*Lingrui Mei,Jiayu Yao,Yuyao Ge,Yiwei Wang,Baolong Bi,Yujun Cai,Jiazhi Liu,Mingyu Li,Zhong-Zhi Li,Duzhen Zhang,Chenlin Zhou,Jiayi Mao,Tianze Xia,Jiafeng Guo,Shenghua Liu*

Main category: cs.CL

TL;DR: 本调查提出了Context Engineering（上下文工程）——一种系统化优化LLM信息负载的方法，涵盖了从基础组件到复杂系统实现的各个方面，并指出了当前模型在长篇内容生成方面存在的不足，为未来研究提供了方向。


<details>
  <summary>Details</summary>
Motivation: LLM的性能很大程度上取决于推理过程中提供的上下文信息。本调查旨在将Context Engineering（上下文工程）正式化，作为一种超越简单提示设计的系统化方法，以优化LLM的信息负载。

Method: 对1300多篇研究论文进行了全面的分析，将Context Engineering分解为基础组件（如上下文检索、生成、处理和管理）和复杂的系统实现（如检索增强生成、内存系统、工具集成推理和多代理系统）。

Result: 提出了Context Engineering的全面分类法，包括基础组件和复杂的系统实现，如RAG、内存系统和多代理系统。确定了模型能力方面的一个关键研究差距：当前模型在理解复杂上下文方面很强，但在生成复杂的长篇输出方面能力不足。

Conclusion: 当前LLM在理解复杂上下文方面表现出色，但在生成同样复杂的长篇输出方面存在局限性，这是未来研究的关键领域。本调查提供了一个统一的框架，以推进上下文感知人工智能。

Abstract: The performance of Large Language Models (LLMs) is fundamentally determined
by the contextual information provided during inference. This survey introduces
Context Engineering, a formal discipline that transcends simple prompt design
to encompass the systematic optimization of information payloads for LLMs. We
present a comprehensive taxonomy decomposing Context Engineering into its
foundational components and the sophisticated implementations that integrate
them into intelligent systems. We first examine the foundational components:
context retrieval and generation, context processing and context management. We
then explore how these components are architecturally integrated to create
sophisticated system implementations: retrieval-augmented generation (RAG),
memory systems and tool-integrated reasoning, and multi-agent systems. Through
this systematic analysis of over 1300 research papers, our survey not only
establishes a technical roadmap for the field but also reveals a critical
research gap: a fundamental asymmetry exists between model capabilities. While
current models, augmented by advanced context engineering, demonstrate
remarkable proficiency in understanding complex contexts, they exhibit
pronounced limitations in generating equally sophisticated, long-form outputs.
Addressing this gap is a defining priority for future research. Ultimately,
this survey provides a unified framework for both researchers and engineers
advancing context-aware AI.

</details>


### [125] [Comparing Apples to Oranges: A Dataset & Analysis of LLM Humour Understanding from Traditional Puns to Topical Jokes](https://arxiv.org/abs/2507.13335)
*Tyler Loakman,William Thorne,Chenghua Lin*

Main category: cs.CL

TL;DR: 大型语言模型在解释幽默方面的能力不足，尤其在处理需要广泛世界知识的复杂幽默时。本研究通过构建包含多种笑话类型的数据集进行了评估，结果表明现有模型在可靠解释所有类型笑话方面存在差距。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨大型语言模型（LLMs）解释幽默的能力是否取决于幽默的形式，以填补计算幽默领域在简单双关语之外的研究空白。

Method: 使用包含4种笑话类型（异形异音异形同音双关语、当代网络幽默、时事笑话）的600个笑话数据集，并手动编写了高质量的解释，以比较大型语言模型（LLMs）对不同类型幽默进行解释的零样本能力。

Result: 与解释简单双关语相比，大型语言模型在解释需要现实世界实体和事件知识的更复杂时事幽默时表现出显著的困难。

Conclusion: 目前没有一种模型能够可靠地生成所有类型笑话的充分解释，这进一步凸显了计算幽默领域大多数工作过于关注简单的笑话形式。

Abstract: Humour, as a complex language form, is derived from myriad aspects of life,
whilst existing work on computational humour has focussed almost exclusively on
short pun-based jokes. In this work, we investigate whether the ability of
Large Language Models (LLMs) to explain humour depends on the particular humour
form. We compare models on simple puns and more complex topical humour that
requires knowledge of real-world entities and events. In doing so, we curate a
dataset of 600 jokes split across 4 joke types and manually write high-quality
explanations. These jokes include heterographic and homographic puns,
contemporary internet humour, and topical jokes, where understanding relies on
reasoning beyond "common sense", rooted instead in world knowledge regarding
news events and pop culture. Using this dataset, we compare the zero-shot
abilities of a range of LLMs to accurately and comprehensively explain jokes of
different types, identifying key research gaps in the task of humour
explanation. We find that none of the tested models (inc. reasoning models) are
capable of reliably generating adequate explanations of all joke types, further
highlighting the narrow focus of most works in computational humour on overly
simple joke forms.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [126] [Adversarial attacks to image classification systems using evolutionary algorithms](https://arxiv.org/abs/2507.13136)
*Sergio Nesmachnow,Jamal Toutouh*

Main category: cs.NE

TL;DR: 该研究提出了一种结合进化算法和生成对抗网络的方法来生成对抗攻击，以应对图像分类中的安全挑战，并在实验中取得了显著的成功率。


<details>
  <summary>Details</summary>
Motivation: 图像分类目前面临着重大的安全挑战，这是由于对抗攻击——旨在欺骗基于人工智能的分类模型而进行的有意改动。

Method: 该方法结合了进化算法和生成对抗网络，通过探索生成对抗网络的潜在空间来寻找代表对抗攻击的向量。

Result: 结果显示，在手写数字方面，成功率高达35%；在物体图像方面，成功率高达75%，优于其他搜索方法和相关工作中报道的结果。

Conclusion: 该方法在处理目标数据集的数据多样性方面被证明是有效的，即使在由于信息复杂性和丰富性而带来额外挑战的问题实例中也是如此。

Abstract: Image classification currently faces significant security challenges due to
adversarial attacks, which consist of intentional alterations designed to
deceive classification models based on artificial intelligence. This article
explores an approach to generate adversarial attacks against image classifiers
using a combination of evolutionary algorithms and generative adversarial
networks. The proposed approach explores the latent space of a generative
adversarial network with an evolutionary algorithm to find vectors representing
adversarial attacks. The approach was evaluated in two case studies
corresponding to the classification of handwritten digits and object images.
The results showed success rates of up to 35% for handwritten digits, and up to
75% for object images, improving over other search methods and reported results
in related works. The applied method proved to be effective in handling data
diversity on the target datasets, even in problem instances that presented
additional challenges due to the complexity and richness of information.

</details>


### [127] [Multi-population GAN Training: Analyzing Co-Evolutionary Algorithms](https://arxiv.org/abs/2507.13157)
*Walter P. Casas,Jamal Toutouh*

Main category: cs.NE

TL;DR: Co-evolutionary GANs benefit from (mu,lambda) replacement for better quality and diversity, while elitist methods can lead to premature convergence.


<details>
  <summary>Details</summary>
Motivation: Generative adversarial networks (GANs) are powerful but difficult to train due to issues like mode collapse and instability. Co-evolutionary approaches, where populations of generators and discriminators evolve together, are a promising solution.

Method: This paper empirically analyzes different co-evolutionary GAN training strategies, comparing (mu,lambda), (mu+lambda) with elitism, and (mu+lambda) with tournament selection schemes against a non-evolutionary baseline. The comparison is conducted on synthetic datasets (blob and Gaussian mixtures) and the MNIST benchmark, focusing on the impact of selection and replacement mechanisms.

Result: The (mu,lambda) strategy with full generational replacement demonstrated superior performance in sample quality and diversity compared to other co-evolutionary methods and the baseline, particularly with larger offspring sizes. Elitist methods showed premature convergence and lower diversity.

Conclusion: Co-evolutionary GAN training with full generational replacement, specifically the (mu,lambda) strategy, consistently yields superior results in both sample quality and diversity, especially with larger offspring populations. Elitist strategies, such as (mu+lambda) with elitism or tournament selection, tend to converge prematurely and exhibit reduced diversity.

Abstract: Generative adversarial networks (GANs) are powerful generative models but
remain challenging to train due to pathologies suchas mode collapse and
instability. Recent research has explored co-evolutionary approaches, in which
populations of generators and discriminators are evolved, as a promising
solution. This paper presents an empirical analysis of different coevolutionary
GAN training strategies, focusing on the impact of selection and replacement
mechanisms. We compare (mu,lambda), (mu+lambda) with elitism, and (mu+lambda)
with tournament selection coevolutionary schemes, along with a non-evolutionary
population based multi-generator multi-discriminator GAN baseline, across both
synthetic low-dimensional datasets (blob and gaussian mixtures) and an
image-based benchmark (MNIST). Results show that full generational replacement,
i.e., (mu,lambda), consistently outperforms in terms of both sample quality and
diversity, particularly when combined with larger offspring sizes. In contrast,
elitist approaches tend to converge prematurely and suffer from reduced
diversity. These findings highlight the importance of balancing exploration and
exploitation dynamics in coevolutionary GAN training and provide guidance for
designing more effective population-based generative models.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [128] [Competition Erases Simplicity: Tight Regret Bounds for Uniform Pricing with Multiple Buyers](https://arxiv.org/abs/2507.12733)
*Houshuang Chen,Yaonan Jin,Pinyan Lu,Chihao Zhang*

Main category: cs.GT

TL;DR: 多买家定价中，对价格分布的结构性假设（如正则性或MHR）没有帮助，定价查询复杂度和遗憾界限与无结构性假设的情况相同。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是探索在多买家重复统一定价机制中，单买家环境中已证实的结构性假设（如正则性或MHR）的益处是否仍然存在。研究旨在揭示单智能体和多智能体环境在机制设计方面的差异。

Method: 该研究通过分析多买家重复统一定价机制，对比了具有结构性假设（如正则性或MHR）和无结构性假设的竞标价分布对定价查询复杂度和遗憾界限的影响。

Result: 研究结果显示，在多买家环境中，无论竞标价分布是否具有结构性（包括正则性和MHR），定价查询复杂度和遗憾界限均具有相同的渐近表现，分别为 $\widetilde\Theta(\varepsilon^{-3})$ 和 $\Theta(T^{2/3})$。这表明多买家竞争消除了单买家环境中结构性假设带来的优势。

Conclusion: 该研究表明，在多买家重复统一定价机制中，即使对竞标价分布具有正则性或单调递减风险率（MHR）等结构性假设，也无法改善定价查询复杂度和遗憾界限。与单买家环境中的情况形成鲜明对比，多买家环境下的这些结构性优势会消失，使得平台必须采用普遍稳健的定价策略。这挑战了单买家理论中的传统观点，并强调了在更具竞争性的环境中重新审视机制设计原则的必要性。

Abstract: We study repeated \textsf{Uniform Pricing} mechanisms with multiple buyers.
In each round, the platform sets a uniform price for all buyers; a transaction
occurs if at least one buyer bids at or above this price. Prior work
demonstrates that structural assumptions on bid distributions -- such as
regularity or monotone hazard rate (MHR) property -- enable significant
improvements in pricing query complexity (from
$\Theta\left(\varepsilon^{-3}\right)$ to
$\widetilde\Theta\left(\varepsilon^{-2}\right)$\footnote{The $\widetilde
\Theta$ notation omits polylogarithmic factors.}) and regret bounds (from
$\Theta\left(T^{2/3}\right)$ to $\widetilde\Theta\left(T^{1/2}\right)$) for
single-buyer settings. Strikingly, we demonstrate that these improvements
vanish with multiple buyers: both general and structured distributions
(including regular/MHR) share identical asymptotic performance, achieving
pricing query complexity of $\widetilde\Theta\left(\varepsilon^{-3}\right)$ and
regret of $\widetilde\Theta\left(T^{2/3}\right)$.
  This result reveals a dichotomy between single-agent and multi-agent
environments. While the special structure of distributions simplifies learning
for a single buyer, competition among multiple buyers erases these benefits,
forcing platforms to adopt universally robust pricing strategies. Our findings
challenge conventional wisdom from single-buyer theory and underscore the
necessity of revisiting mechanism design principles in more competitive
settings.

</details>


### [129] [Lower Bound for Online MMS Assignment of Indivisible Chores](https://arxiv.org/abs/2507.12984)
*Masoud Seddighin,Saeed Seddighin*

Main category: cs.GT

TL;DR: 确定性在线算法在$n$个代理的杂事分配中，竞争比不能优于$n$。


<details>
  <summary>Details</summary>
Motivation: 先前工作证明了任何确定性在线算法的竞争比至少为2，本研究旨在改进此界限。

Method: 研究了在MMS标准下，不可分割的杂事在线分配问题，并改进了先前关于确定性在线算法竞争比的下界。

Result: 证明了任何确定性在线算法对于$n$个代理的竞争比不能优于$n$。

Conclusion: 确定性在线算法在$n$个代理的情况下，竞争比不能优于$n$。

Abstract: We consider the problem of online assignment of indivisible chores under
\MMS\ criteria. The previous work proves that any deterministic online
algorithm for chore division has a competitive ratio of at least 2. In this
work, we improve this bound by showing that no deterministic online algorithm
can obtain a competitive ratio better than $n$ for $n$ agents.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [130] [Kinetics of Vacancy-Assisted Reversible Phase Transition in Monolayer MoTe$_2$](https://arxiv.org/abs/2507.12565)
*Fei Shuang,Daniel Ocampo,Reza Namakian,Arman Ghasemi,Poulumi Dey,Wei Gao*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究使用机器学习势和平均场动力学理论研究了单层MoTe2的相变动力学，发现相变涉及扩散和非扩散机制。1T'相成核于碲空位合并，生长经历空位吸收或无空位过程。系统在去除刺激后可逆地转变为2H相，涉及无扩散的空位线重组。


<details>
  <summary>Details</summary>
Motivation: 研究单层MoTe2中2H相和1T'相之间的相变动力学。

Method: 本研究使用基于机器学习的原子间势进行原子模拟，该势由SCAN-DFT数据训练，并结合平均场动力学理论来解释潜在机制，以研究单层MoTe2中2H相和1T'相之间的相变动力学。

Result: 研究发现，相变包括扩散和非扩散两种机制。1T'相的成核是由相邻碲单空位的合并引起的，这些空位是可移动的，并且可以与其他碲空位相互作用形成小的三角形1T'岛。一旦达到临界岛尺寸，就可以实现无空位的生长。在去除外部刺激后，系统会恢复到2H相，在此过程中，碲空位会重组成分布在岛中心的类似三辐轮辐的空位线。这个逆过程和随后的1T'↔2H可逆转变是无扩散的、快速的，不需要额外的空位，并且可以由温和的外部刺激驱动。

Conclusion: 研究表明，1T'相的成核是由相邻碲单空位的合并引起的，这些空位是可移动的，并且可以与其他碲空位相互作用形成小的三角形1T'岛。这些岛的生长要么通过合并相界处预先存在的空位，要么在没有预先存在的空位的情况下，通过吸收从周围晶格迁移过来的二空位来进行。一旦达到临界岛尺寸，就可以实现无空位的生长，尽管活化能更高。在去除外部刺激后，系统会恢复到2H相，在此过程中，碲空位会重组成分布在岛中心的类似三辐轮辐的空位线。这个逆过程和随后的1T'↔2H可逆转变是无扩散的、快速的，不需要额外的空位，并且可以由温和的外部刺激驱动。虽然本分析侧重于应变引起的转变，但所提出的动力学机制预计可以推广到其他类型的刺激。

Abstract: We investigate the kinetics of phase transition between the 2H and
1T$^\prime$ phases in monolayer MoTe$_2$ using atomistic simulations based on a
machine learning interatomic potential trained on SCAN-DFT data, combined with
mean field kinetic theory to interpret the underlying mechanisms. The
transition is found to involve both diffusive and diffusionless mechanisms.
Nucleation of 1T$^\prime$ phase is initiated by the coalescence of neighboring
Te monovacancies into divacancies, which are found to be mobile and can
interact with other Te vacancies to form small triangular 1T$^\prime$ islands.
Growth of these islands proceeds either by incorporating pre-existing vacancies
at the phase boundaries or, in their absence, by absorbing divacancies that
migrate from the surrounding lattice. Once a critical island size is reached,
vacancy-free growth becomes possible although with a higher activation barrier.
Upon removal of external stimuli, the system reverts to 2H phase, during which
Te vacancies reorganize into three-fold spoke-like vacancy lines at the island
center. This reverse process and the subsequent 1T$^\prime$$\leftrightarrow$2H
reversible transitions are diffusionless, rapid, do not require additional
vacancies and can be driven by mild external stimuli. Although our analysis
focuses on strain-induced transitions, the kinetic mechanisms are expected to
be generalizable to other types of stimuli.

</details>


### [131] [Suppression of Thermal Conductivity via Singlet-Dominated Scattering in TmFeO$_3$](https://arxiv.org/abs/2507.12608)
*M. L. McLanahan,D. Lederman,A. P. Ramirez*

Main category: cond-mat.mtrl-sci

TL;DR: Thermal conductivity of rare-earth orthoferrites was measured, revealing an anomalous suppression in TmFeO3 due to phonon-electron scattering, relevant for quantum magnet studies.


<details>
  <summary>Details</summary>
Motivation: To measure and understand the thermal conductivity of rare-earth orthoferrites, particularly the anomalous strong suppression observed in TmFeO3.

Method: Using a Debye thermal transport model to analyze the thermal conductivity of rare-earth orthoferrites (RFeO3, where R = Eu, Gd, Tb, Dy, Ho, Er, Tm, and Yb).

Result: An anomalous strong suppression of thermal conductivity was observed for TmFeO3, which was explained by resonant scattering between phonons and Tm$^{3+}$ 4f singlet crystal field levels using a Debye thermal transport model.

Conclusion: The anomalous strong suppression of thermal conductivity in TmFeO3 is attributed to resonant scattering between phonons and the Tm$^{3+}$ 4f singlet crystal field levels, with implications for thermal conductivity studies in quantum magnets.

Abstract: We measured the thermal conductivity of the rare-earth orthoferrites,
$R$FeO$_3$, where $R$ = Eu, Gd, Tb, Dy, Ho, Er, Tm, and Yb and see an anomalous
strong suppression for TmFeO$_3$. Using a Debye thermal transport model, we
demonstrate that this suppression is due to resonant scattering between phonons
and the Tm$^{3+}$ $4f$ singlet crystal field levels. The implications of these
results are discussed in context of thermal conductivity studies in quantum
magnets.

</details>


### [132] [Low-energy domain wall racetracks with multiferroic topologies](https://arxiv.org/abs/2507.12633)
*Arundhati Ghosal,Alexander Qualls,Yousra Nahas,Shashank Ojha,Peter Meisenheimer,Shiyu Zhou,Maya Ramesh,Sajid Husain,Julia Mundy,Darrell Schlom,Zhi Yao,Sergei Prokhorenko,Laurent Bellaiche,Ramamoorthy Ramesh,Paul Stevenson,Lucas Caretta*

Main category: cond-mat.mtrl-sci

TL;DR: 提出了一种电压控制的磁电 Racetrack 存储器，利用电场驱动磁畴壁移动，实现了高速度、低功耗和良好的纳米级扩展性。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统 Racetrack 存储器中电流驱动产生的焦耳热问题及其对能量预算和扩展性的影响，本文旨在开发一种更节能、更具扩展性的信息移动方案。

Method: 提出了一种电压控制的磁电 Racetrack 存储器，利用横向电场驱动 BiFeO3 纳米带中的铁电-反铁磁畴壁移动，并揭示了畴壁处出现的非共线拓扑磁电纹理，分析了这些拓扑结构对稳定性的影响，包括极性双墨子和极性顶点与磁性回旋锯齿盘错的磁电耦合，以及先前未观察到的拓扑磁性回旋锯齿扭转拓扑。

Result: 实现了至少每秒千公里的畴壁速度，与最高效的铁磁和反铁磁 Racetrack 存储器相当或更优，接近 BiFeO3 的声子极限，并能在数十微米尺度上保持拓扑结构。该方案实现了纳秒级访问时间，且无电流驱动方案的热负荷。

Conclusion: 提出了一种利用电压控制的磁电 Racetrack 存储器，通过横向电场沿 BiFeO3 纳米带移动耦合的铁电-反铁磁畴壁，在室温下实现了高效信息移动，能量消耗比自旋扭矩器件低几个数量级，且具有更好的纳米级扩展性。

Abstract: Conventional racetrack memories move information by pushing magnetic domain
walls or other spin textures with spin-polarized currents, but the accompanying
Joule heating inflates their energy budget and can hamper scaling. Here we
present a voltage-controlled, magnetoelectric racetrack in which transverse
electric fields translate coupled ferroelectric-antiferromagnetic walls along
BiFeO3 nanostrips at room temperature. Because no charge traverses the track,
the switching dissipates orders of magnitude less energy than the most
efficient spin-torque devices with more favourable scaling, making the scheme
significantly more attractive at the nanoscale. We further uncover noncollinear
topological magnetoelectric textures that emerge at domain walls in BiFeO3,
where the nature of these topologies influences their stability upon
translation. Among these are polar bi-merons and polar vertices
magnetoelectrically coupled with magnetic cycloid disclinations and previously
unobserved, topological magnetic cycloid twist topologies. We observe domain
wall velocities of at least kilometres per second - matching or surpassing the
fastest ferrimagnetic and antiferromagnetic racetracks and approaching the
acoustic-phonon limit of BiFeO3 - while preserving these topologies over tens
of micrometres. The resulting high velocity, low-energy racetrack delivers
nanosecond access times without the thermal overhead of current-driven schemes,
charting a path toward dense, ultralow-power racetrack devices which rely on
spin texture translation.

</details>


### [133] [Extreme Thermal Insulation in Nano-Bubble Wrap Materials](https://arxiv.org/abs/2507.12685)
*Amalya C. Johnson,Sorren Warkander,Archana Raja,Fang Liu*

Main category: cond-mat.mtrl-sci

TL;DR: 通过构建纳米气泡包装结构，实现了远低于空气和气凝胶的超低导热性，为设计热超材料和节能技术开辟了新途径。


<details>
  <summary>Details</summary>
Motivation: 在环境条件下实现超低导热性是一个基本挑战，受到经典热传输限制和材料设计权衡的制约。

Method: 采用时间域热反射测量技术。

Result: 所提出的纳米气泡包装结构实现了近乎空气和商用气凝胶导热系数十分之一的导热系数，在室温和大气压下达到了低于0.001 W·M$^{-1}$K$^{-1}$的关键值。这种极端的导热阻碍源于气体传导、声子传输和界面耦合的共同抑制。

Conclusion: 本研究介绍了一种新型纳米气泡包装结构，通过结合纳米尺度气体限制和原子级薄的弱耦合范德华固体，实现了在环境条件下极低的导热性。通过可扩展地将二维单层材料构造成周期性的纳米气泡和纳米皱纹，我们构建了在结构上类似于宏观气泡包装但工程化长度尺度远小于空气平均自由程和原子级薄单层材料中声子平均自由程的材料。

Abstract: Achieving ultra-low thermal conductivity under ambient conditions is a
fundamental challenge constrained by classical heat transport limits and
material design trade-offs. Here, we introduce a new class of nano-bubble wrap
architectures that achieve exceptionally low thermal conductivity by
integrating nanoscale gas confinement with atomically thin, weakly coupled van
der Waals solids. Using scalable patterning of 2D monolayers into periodic
nano-bubbles and nano-wrinkles, we construct materials with structural
analogies to macroscopic bubble wrap but engineered at length scales much
shorter than the mean free path of air and the mean free path of phonons in the
atomically thin monolayers. Time-domain thermoreflectance measurements reveal
out-of-plane thermal conductivities nearly an order of magnitude lower than
that of air and commercial aerogels, reaching critical values below 0.001 W
$\cdot$ M$^{-1}$K$^{-1}$ under room temperature and atmospheric pressure. This
extreme thermal resistance arises from the combined suppression of gas-phase
conduction, phonon transport, and interfacial coupling. Our findings establish
nano-bubble wraps as a versatile platform for tuning heat flow in ultrathin
materials and open new pathways for designing thermal metamaterials and
energy-efficient technologies.

</details>


### [134] [Cryogenic magnetization dynamics in tensile-strained ultrathin yttrium iron garnets with tunable magnetic anisotropy](https://arxiv.org/abs/2507.12776)
*Jihyung Kim,Dongchang Kim,Seung-Gi Lee,Yung-Cheng Li,Jae-Chun Jeon,Jiho Yoon,Sachio Komori,Ryotaro Arkakwa,Tomoyasu Taniyama,Stuart S. P. Parkin,Kun-Rok Jeon*

Main category: cond-mat.mtrl-sci

TL;DR: 应变YIG薄膜在低温下表现出优异的磁性能，适用于低温自旋电子学应用。


<details>
  <summary>Details</summary>
Motivation: 为了在低温下实现更低的阻尼损耗和可调的磁各向异性，对超薄YIG薄膜进行了研究。

Method: 通过脉冲激光沉积法生长了应变YIG薄膜，并利用宽带FMR测量和静态磁测量进行了表征。

Result: 应变YIG薄膜在低温下表现出极低的阻尼常数和可调的磁各向异性，并且在纳米厚度下表现优于非应变薄膜，这归因于Sc的存在抑制了界面处的互扩散，提高了化学稳定性和生长动力学。

Conclusion: 应变YIG薄膜在低温下表现出更低的阻尼损耗，这对于低温自旋电子学应用至关重要。

Abstract: We report a significant reduction of low-temperature damping losses in
tensile-strained, ultrathin Y3Fe5O12 (YIG) films grown by pulsed laser
deposition, exhibiting ultralow damping constants and tunable magnetic
anisotropy. Comparative broadband FMR measurements show that tensile-strained
YIG films on Gd3Sc2Ga3O12 (GSGG) retain low damping even at nanometer
thicknesses and cryogenic temperatures, outperforming relaxed films on
Gd3Ga5O12. Based on static magnetometry measurements and microstructural
characterization, we attribute these enhanced dynamic properties to the
suppression of interdiffusion across the YIG/GSGG interface, resulting from
enhanced chemical stability and favorable growth kinetics by the presence of
Sc. Our findings highlight the importance of chemical and kinetic factors in
achieving few-nanometer-thick YIG film with negligible low-temperature damping
dissipation and perpendicular magnetic anisotropy for cryogenic spintronic
applications.

</details>


### [135] [Spin-reorientation Driven Temperature Dependent Intrinsic Anomalous Hall Conductivity in Fe$_3$Ge, a Ferromagnetic Topological Metal](https://arxiv.org/abs/2507.12777)
*Susanta Ghosh,Tushar Kanti Bhowmik,Achintya Low,Setti Thirupathaiah*

Main category: cond-mat.mtrl-sci

TL;DR: Fe$_3$Ge是一种铁磁拓扑金属，其霍尔电导率表现出各向异性，且内在和外在贡献均具有温度依赖性。


<details>
  <summary>Details</summary>
Motivation: 研究Fe$_3$Ge的温度依赖性，特别是其异常霍尔电导率的各向异性和内在/外在贡献的温度调控机制。

Method: 通过实验研究了Fe$_3$Ge的温度依赖性，并测量了其霍尔电导率，分析了内在和外在贡献以及它们随温度的变化关系。

Result: 观察到Fe$_3$Ge的霍尔电导率存在显著的平面内和平面外各向异性。内在霍尔贡献的温度依赖性可以通过调控磁轴实现。外在霍尔电导率随温度升高而减小，符合特定数学模型。

Conclusion: Fe$_3$Ge是一种铁磁拓扑金属，其内在异常霍尔电导率表现出显著的平面内和平面外各向异性。通过实验调控，我们可视化了其内在霍尔贡献的温度依赖性，这是一种罕见的现象。此外，我们还发现外在霍尔电导率随温度升高而减小，遵循$rac{\sigma_{xy0}^{ext}}{(aT+1)^2}$的规律，这归因于电子-声子散射。

Abstract: We investigate the temperature dependence of the intrinsic anomalous Hall
conductivity in Fe$_3$Ge, which is a ferromagnetic topological metal. We
observe a significant anisotropy in the anomalous Hall conductivity between
in-plane and out-of-plane directions. We further identify that the total Hall
conductivity is contributed extrinsically due to the skew-scattering mechanism
and intrinsically due to nonzero Berry curvature in the momentum space. Most
importantly, we demonstrate the temperature dependence of the intrinsic Hall
contribution, a rare phenomenon to visualize experimentally, due to tuning the
easy-magnetic axis from the out-of-plane to the in-plane with decreasing
temperature. We also show that the extrinsic Hall conductivity decreases with
temperature as $\sigma_{xy}^{ext}(T)=\frac{\sigma_{xy0}^{ext}}{(aT+1)^2}$ due
to electron-phonon scattering.

</details>


### [136] [Structure determination of flat honeycomb Bi grown on Ag(111)](https://arxiv.org/abs/2507.12788)
*Ziyong Zhang,Xiaobin Chen,Takeshi Nakagawa*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究利用LEED和DFT技术，在Ag(111)表面成功制备了超平坦蜂窝状铋烯，并发现Mn掺杂可以稳定该结构，为二维拓扑材料研究奠定基础。


<details>
  <summary>Details</summary>
Motivation: 为了深入理解铋烯在Ag(111)表面上的结构特性以及其作为二维拓扑材料的潜力，本研究旨在表征不同条件下（温度、Mn掺杂）形成的铋烯结构。

Method: 利用低能电子衍射（LEED）的I(V)分析和密度泛函理论（DFT）研究了在Ag(111)表面上沉积0.5个单层（ML）的Bi在~120 K时形成的超平坦蜂窝状铋烯结构，并探讨了其在升温至室温时的结构转变以及Mn沉积对Bi/Ag(111)表面结构的影响，特别是诱导Bi表面偏析形成p(2x2)蜂窝状铋烯。

Result: 研究发现，在~120 K时，0.5 ML的Bi在Ag(111)表面形成了超平坦、 প্রায়无翘曲的蜂窝状铋烯结构，该结构在升温至室温时会发生转变。Mn的沉积能够诱导Bi表面偏析，形成稳定的p(2x2)蜂窝状铋烯结构。

Conclusion: 该研究通过低能电子衍射和密度泛函理论，揭示了在Ag(111)表面上蜂窝状铋烯结构的形成及其在不同温度和Mn掺杂下的稳定性，为理解二维拓扑性质提供了基础。

Abstract: Honeycomb bismuthene structures on Ag(111) were investigated using low-energy
electron diffraction (LEED) and density functional theory. LEED I(V) analysis
revealed that 0.5 monolayer (ML) of Bi forms an ultraflat honeycomb lattice
with negligible buckling at ~120 K, which transforms into other structures upon
warming to room temperature. A similar flat bismuthene structure also forms in
Mn/Bi/Ag(111), which remains stable even at room temperature. Mn deposition on
$(p\times \sqrt{3})$-rect Bi/Ag(111) induces Bi surface segregation, as
confirmed by X-ray photoelectron spectroscopy, resulting in a p$(2\times2)$
honeycomb bismuthene. The detailed structural investigation provides
fundamental insights into the characterization of two-dimensional topological
properties of bismuthene grown on Ag(111).

</details>


### [137] [From the up-converting multimodal luminescent thermometer to ratiometric visual power density meter based on Er3+,Yb3+ emission](https://arxiv.org/abs/2507.13217)
*Anam Javaid,Maja Szymczak,Lukasz Marciniak*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究开发了一种基于 Na3Sc2(PO4)3:Er3+, Yb3+ 材料的多模态远程温度传感器和视觉光学功率密度传感器，并实现了光学功率密度的二维成像。


<details>
  <summary>Details</summary>
Motivation: 本研究的目的是探索和利用 Na3Sc2(PO4)3:Er3+, Yb3+ 材料在不同温度下光谱特性的变化，开发一种能够进行远程、多模态温度传感的新型传感器。此外，研究还旨在开发一种视觉光学功率密度传感器，并实现光学功率密度的二维成像，以满足在光学测量和成像领域的应用需求。

Method: 本研究利用 Na3Sc2(PO4)3:Er3+, Yb3+ 材料的光谱特性，通过分析不同发射谱线强度比随温度的变化，实现了多模态远程温度传感。具体而言，研究了 (i) 2H11/2 -> 4I15/2 和 4S3/2 -> 4I15/2；(ii) 2H9/2 -> 4I13/2 和 4S3/2 -> 4I15/2；以及 (iii) 绿光到红光发射强度比这三种传感模式。同时，通过结合 Er3+ 的绿红光发射强度比与 Yb3+ 浓度对材料光致发光的影响，开发了视觉光学功率密度传感器，并使用 CIE 1931 色度坐标进行了量化。最后，通过二维成像技术实现了光学功率密度的空间可视化。

Result: Na3Sc2(PO4)3:Er3+, Yb3+ 材料支持多种远程温度传感模式，其中基于 (i) 2H11/2 -> 4I15/2 和 4S3/2 -> 4I15/2；(ii) 2H9/2 -> 4I13/2 和 4S3/2 -> 4I15/2；以及 (iii) 绿光到红光发射强度比的传感模式，分别实现了 2.8% K-1、3% K-1 和 1.8% K-1 的最高相对灵敏度。开发的光学功率密度传感器在 15 W cm-2 时，使用 CIE 1931 色度坐标量化的相对灵敏度达到 SRx = 1.0% W-1 cm2 和 SRy = 0.9% W-1 cm2。该研究首次实现了视觉发光光学功率密度传感器，并成功进行了光学功率密度的二维成像。

Conclusion: 该研究表明，Na3Sc2(PO4)3:Er3+, Yb3+ 的热致光谱特性可用于多模态远程温度传感。研究实现了基于特定发射强度比率（(i) 2H11/2 -> 4I15/2 和 4S3/2 -> 4I15/2；(ii) 2H9/2 -> 4I13/2 和 4S3/2 -> 4I15/2；以及 (iii) 绿光到红光发射强度比）的多重灵敏度传感模式，最高相对灵敏度分别达到 2.8% K-1、3% K-1 和 1.8% K-1。此外，Er3+ 离子的绿光到红光发射强度比与 Na3Sc2(PO4)3:Er3+, Yb3+ 在较高 Yb3+ 浓度下的光致发光协同作用，促成了视觉光学功率密度传感器的开发，在 15 W cm-2 时，使用 CIE 1931 色度坐标测量的相对灵敏度分别为 SRx = 1.0% W-1 cm2 和 SRy = 0.9% W-1 cm2。该研究首次报道了视觉发光光学功率密度传感器，并成功实现了光学功率密度的二维成像，能够对照明场内的功率分布进行空间可视化。

Abstract: This study demonstrates that thermally induced variations in the
spectroscopic properties of Na3Sc2(PO4)3:Er3+, Yb3+ can be effectively
harnessed for multimodal remote temperature sensing. As shown,
Na3Sc2(PO4)3:Er3+, Yb3+ supports multiple ratiometric sensing modes based on
the intensity ratios of (i) 2H11/2 -> 4I15/2 and 4S3/2 -> 4I15/2; (ii) 2H9/2 ->
4I13/2 and 4S3/2 -> 4I15/2; and (iii) green-to-red emission intensity ratio,
achieving maximum relative sensitivities of 2.8% K-1, 3% K-1, and 1.8% K-1,
respectively. The synergy between thermal changes observed in the green-to-red
emission intensity ratio of Er3+ ions, combined with the efficient optical
heating of Na3Sc2(PO4)3:Er3+, Yb3+ at elevated Yb3+ concentrations enables the
development of a visual optical power density sensor, exhibiting relative
sensitivities of SRx = 1.0% W-1 cm2 and SRy = 0.9% W-1 cm2 at 15 W cm-2 when
quantified using CIE 1931 chromaticity coordinates. To the best of our
knowledge, this is the first report of a visual luminescent optical power
density sensor. Furthermore, it was demonstrated that Na3Sc2(PO4)3:Er3+, Yb3+
can be successfully applied for two-dimensional imaging of optical power
density, thereby enabling spatial visualization of power distribution within an
illuminated field.

</details>


### [138] [Quantum Mechanical Approach for Modeling of Ternary Based Strained-Layer Superlattice](https://arxiv.org/abs/2507.12813)
*Arash Dehzangi,Jiakai Li*

Main category: cond-mat.mtrl-sci

TL;DR: A quantum mechanical model for InAs/InAs1-xSbx superlattices shows promise for infrared detectors, matching experimental band gaps.


<details>
  <summary>Details</summary>
Motivation: To investigate the InAs/InAs1-xSbx strained-layer superlattice (SLS) material, which belongs to the 6.1 A family and has a small lattice mismatch with the GaSb substrate, as a potential alternative material system for infrared photodetectors.

Method: A modified sp3s* empirical tight binding method incorporating virtual crystal approximation and a bowing of the s-on-site tight-binding energy was used. Atomic segregation in superlattices was theoretically explained and included in the calculations.

Result: The simulations showed good agreement with experimentally measured band gap of InAs/InAs1-xSbx superlattices, providing theoretical explanation for atomic segregation.

Conclusion: InAs/InAs1-xSbx SLS material is a promising alternative for infrared photodetectors due to its advantages like longer carrier lifetime and better manufacturability. The study successfully modeled its electronic band structure using a modified sp3s* empirical tight binding method with virtual crystal approximation, showing good agreement with experimental results.

Abstract: Ternary-based InAs/InAs1-xSbx Strained-Layer Superlattice (SLS)material with
type-II band alignment belongs to the 6.1 A family with reasonably small
lattice mismatch with GaSb substrate for epitaxial growth. InAs/InAs1-xSbx SLS
have been proven to have more advantages such as longer carrier lifetime,
better control on growth and manufacturability, and being considered as an
alternative material system for infrared photodetectors. In this article a
quantum mechanical based modelling on electronic band structure of
InAs/InAs1-xSbx is presented. A modified sp3s* empirical tight binding method
along with implementing a virtual crystal approximation with a bowing of the
s-on-site tight-binding energy, were incorporated. In this approach, a
theoretical explanation of atomic segregation in superlattices is suggested and
used in calculations. The simulations show good agreement with experimentally
measured band gap of InAs/InAs1-xSbx superlattices.

</details>


### [139] [Quantum geometrical bound relations for observables](https://arxiv.org/abs/2507.12836)
*Koki Shinada,Naoto Nagaosa*

Main category: cond-mat.mtrl-sci

TL;DR: 通过推广量子几何张量，本研究发现了物理量之间新的界限关系，特别是在线性响应以及德鲁德权重与轨道磁化强度方面，并验证了这些关系在不同量子系统中的适用性。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于探索量子几何张量（QGT）在揭示物理量之间界限关系方面的潜力，特别是通过推广QGT来发现新的界限关系，并将其应用于理解和量化量子材料的物理特性。研究旨在扩展QGT的应用范围，为理解量子几何在物理学中的作用提供更深入的见解。

Method: 本研究通过推广量子几何张量（QGT）来研究物理量之间的界限关系。具体方法包括：1. 推广参数空间以证明界限关系对所有线性响应成立，并应用于优化自由能的凸性不等式。2. 扩展投影算符以建立德鲁德权重和轨道磁化强度之间的界限关系，并验证其在朗道能级系统和近乎平坦能带系统中的适用性，以及应用于两种轨道铁磁体和扭曲双层石墨烯系统。3. 讨论了更高阶多极矩（磁四极矩）的类似不等式。4. 探讨了QGT与不确定性原理的类比。

Result: 研究成功地推广了量子几何张量（QGT），并建立了多种界限关系。首先，通过推广参数空间，证明了界限关系对所有线性响应成立，并展示了其在收紧自由能凸性不等式方面的应用。其次，通过扩展投影算符，建立了德鲁德权重和轨道磁化强度之间的界限关系，该关系在朗道能级系统中被精确满足，并且在近乎平坦能带系统中近似满足。研究还将此不等式应用于两种轨道铁磁体，并指出扭曲双层石墨烯系统接近朗道能级系统。此外，还发现了更高阶多极矩（磁四极矩）的类似不等式。最终，论文讨论了QGT与不确定性原理的类比，强调了界限关系反映了量子效应。

Conclusion: 本篇论文通过推广量子几何张量（QGT），研究了不同可观测量之间的界限关系。研究表明，推广的QGT可以为线性响应和德鲁德权重与轨道磁化强度之间的关系提供新的界限，并且这些界限在特定系统中（如朗道能级系统和近乎平坦能带系统）可以被精确满足或近似满足。此外，论文还讨论了QGT与不确定性原理之间的类比，强调了界限关系反映了量子效应。

Abstract: The quantum geometric tensor (QGT) provides nontrivial bound relations among
physical quantities, as exemplified by the metric-curvature inequality. In this
paper, we investigate various bound relations for different observables through
certain generalizations of the QGT. First, by generalizing the parameter space,
we demonstrate that bound relations hold for all linear responses. As an
application, we show the thermodynamic inequality originating from the
convexity of free energy can be further tightened. Second, by extending the
projection operator, we establish a bound relation between the Drude weight and
the orbital magnetization. The equality is exactly satisfied in the Landau
level system, and systems with nearly flat bands tend to approach equality as
well. We apply the resulting inequality to two orbital ferromagnets and support
that the twisted bilayer graphene system is close to the Landau level system.
Moreover, we show that an analogous inequality also holds for a higher-order
multipole, magnetic quadrupole. Finally, we discuss the analogy between the QGT
and the uncertainty principle, emphasizing that the existence of nontrivial
bound relations necessarily reflects quantum effects.

</details>


### [140] [Chemical vapor deposition synthesis of (GeTe)n(Sb2Te3) gradient crystalline films as promising planar heterostructures](https://arxiv.org/abs/2507.12888)
*M. Zhezhu,A. Vasil'ev,M. Yapryntsev,E. Ghalumyan,D. A. Ghazaryan,H. Gharagulyan*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究提出了一种CVD方法，可在一-次实验中制备成分梯度变化的GST薄膜，为存储和光学应用提供可调的性能。


<details>
  <summary>Details</summary>
Motivation: 相变材料（PCMs）在存储和能量转换领域具有重要应用潜力。本研究旨在开发一种快速高效的制备方法，以实现对GST材料成分和性质的精确调控，为存储和光学应用提供具有特定功能的梯度薄膜。

Method: 采用化学气相沉积（CVD）技术，通过调整工艺参数（而非更换前驱体）来实现对(GeTe)n(Sb2Te3)（GST）系统薄膜中Ge/Sb原子含量的控制，从而在一-次实验中实现Ge3Sb2Te6、Ge2Sb2Te5和GeSb2Te4等相的梯度合成。

Result: 成功制备了结晶GST薄膜，并实现了Ge/Sb原子含量的梯度分布。通过结构、光学和电学性质分析，证实了成分变化对薄膜性能的影响。所制备的梯度GST薄膜可用于存储应用中的面内多级开关和光学应用中的折射率/吸收调谐。

Conclusion: 本研究提出了一种快速高效的化学气相沉积（CVD）方法，用于制备具有可变Ge/Sb原子含量的结晶GST薄膜。该方法无需更换前驱体即可实现成分控制，能够一次性梯度合成Ge3Sb2Te6、Ge2Sb2Te5和GeSb2Te4相等。通过对这些薄膜的结构、光学和电学性质进行分析，揭示了成分变化对其性质的影响。这些梯度GST薄膜在存储应用中可提供面内的多级和渐变开关阈值，在光学调制和滤波应用中可提供可调的折射率和吸收。

Abstract: Phase-change materials of the (GeTe)n (Sb2Te3) (GST) system are of high
relevance in memory storage and energy conversion applications due to their
fast-switching speed, high data retention, and tunable properties. Here, we
report on a fast and efficient CVD-based method for the fabrication of
crystalline GST films with variable Ge/Sb atomic content. In particular, the
approach enables compositional control without changing the precursor,
facilitating a gradient synthesis of Ge3Sb2Te6, Ge2Sb2Te5, and GeSb2Te4 phases
in a single attempt. The analyses of their structural, optical, and electrical
aspects highlight how compositional variation influences the film's properties.
Our findings demonstrate a straightforward approach enabling the preparation of
gradient crystalline GST films with tunable morphology and functionality. These
gradient films can potentially provide in-plane multilevel and gradual
switching thresholds for memory applications and altered refractive index and
absorption for optical modulation and filtering applications.

</details>


### [141] [Magnetic Triple-q State in Antiferromagnetic Monolayer Interfaced with Bismuthene](https://arxiv.org/abs/2507.12946)
*Chia-Ju Chen,Yu-Tung Lin,Chieh-Lin Lee,Nitin Kumar,Hung-Chin Lee,Yen-Hui Lin,Bo-Yao Wang,Stefan Bluegel,Gustav Bihlmayer,Pin-Jui Hsu*

Main category: cond-mat.mtrl-sci

TL;DR: bismuthene 覆盖的 Mn 单层/Ag(111) 在磁场下表现出 3Q3 磁结构和磁各向异性。


<details>
  <summary>Details</summary>
Motivation: 研究 bismuthene 覆盖的 Mn 单层/Ag(111) 的磁结构，特别是解析其磁基态和磁各向异性。

Method: 通过在室温下将 Mn 原子蒸发到 (√3×√3)-Bi/Ag(111) 上成功制备了 bismuthene 覆盖的 Mn 单层/Ag(111)。通过自旋极化扫描隧道显微镜 (SP-STM) 和密度泛函理论 (DFT) 计算来表征该材料。

Result: 成功制备了 bismuthene 覆盖的 Mn 单层/Ag(111)，并解析了其磁三重 Q (3Q) 态。研究发现 3Q3 结构是该材料的磁基态，并且 bismuthene 诱导了 3Q3 状态的单轴磁各向异性，这与 SP-STM 观测到的磁场驱动的 3Q3up 和 3Q3down 畴转换一致。

Conclusion: bismuthene 覆盖的 Mn 单层/Ag(111) 的磁性基态是 3Q3 磁结构，该结构由双 thene 诱导的单轴磁各向异性驱动。

Abstract: We have successfully fabricated the bismuthene covered Mn monolayer on
Ag(111) by evaporating Mn atoms onto (pxroot3)-Bi/Ag(111) at room temperature.
By using spin-polarized scanning tunneling microscopy (SP-STM), we have
resolved the magnetic triple-q (3Q) state. In combination with
density-functional theory (DFT) calculations, the 3Q3-like spin texture is the
magnetic ground state for the bismuthene covered Mn monolayer/Ag(111).
Interestingly, the uniaxial magnetic anisotropy of 3Q3 state triggered by the
bismuthene on top of Mn monolayer/Ag(111) has been revealed, which is
consistent with the switching of 3Q3up and 3Q3down domains observed by SP-STM
measurements with external magnetic fields.

</details>


### [142] [Laser-Induced Topological Toggle Switching at Room Temperature in the van der Waals Ferromagnet \ce{Fe3GaTe2}](https://arxiv.org/abs/2507.12959)
*Charlie W. F. Freeman,Woohyun Cho,Paul S. Keatley,PeiYu Cai,Elton J. G. Santos,Robert J. Hicken,H. Yang,Hidekazu Kurebayashi,Murat Cubukcu,Maciej Dabrowski*

Main category: cond-mat.mtrl-sci

TL;DR: 通过激光控制Fe3GaTe2中的自旋纹理，有望实现室温非易失性存储。


<details>
  <summary>Details</summary>
Motivation: 探索在范德华铁磁体中实现室温下拓扑自旋纹理的成核和操控，并利用激光控制技术开发非易失性存储器应用。

Method: 通过激光脉冲激发，利用激光诱导加热和冷却，实现了Fe3GaTe2中拓扑自旋纹理（斯格明子/泡态和迷宫态）的室温成核、操控和切换。结合微磁模拟解释了切换行为的机制。

Result: 成功在Fe3GaTe2中实现了室温下的拓扑自旋纹理（斯格明子/泡态和迷宫态）的成核、操控和切换，并验证了激光诱导加热和冷却在该过程中的作用。

Conclusion: 该研究展示了在范德华铁磁体Fe3GaTe2中，通过激光脉冲激发实现室温下拓扑自旋纹理的成核和操控。研究利用激光诱导加热和随后的冷却，在低场下实现了斯格明子/泡态，并实现了斯格明子/泡态和迷宫态之间的切换。微磁模拟表明，这种切换行为源于激光诱导的加热和冷却过程。研究结果揭示了范德华铁磁体在室温下激光控制非易失性存储器应用中的潜力。

Abstract: We demonstrate room-temperature nucleation and manipulation of topological
spin textures in the van der Waals (vdW) ferromagnet, Fe3GaTe2, through laser
pulse excitation. By leveraging laser-induced heating and subsequent cooling,
we access the skyrmion/bubble state at low fields and achieve toggle switching
between two topological spin textures - skyrmion/bubble and labyrinth.
Micromagnetic simulations reveal that this switching behaviour arises from
laser-induced heating and cooling. Our findings highlight the potential of vdW
ferromagnets for room temperature laser-controlled non-volatile memory storage
applications.

</details>


### [143] [Mapping diverse hysteresis dynamics in scaled MoS$_2$ FETs using the universal method derived from TCAD modeling](https://arxiv.org/abs/2507.13002)
*Yezhu Lv,Haihui Cai,Yehao Wu,Yu. Yu. Illarionov*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究提出了一种新的滞后映射方法，用于分析二维材料晶体管中的复杂滞后现象及其与器件可靠性的关系。


<details>
  <summary>Details</summary>
Motivation: 二维材料晶体管（FETs）在器件小型化过程中面临可靠性挑战，而现有的研究多集中于技术层面，对滞后动力学的深入分析不足。滞后动力学中蕴含着复杂的机制信息，尤其在小型化 FETs 中，与沟道和顶栅的缺陷相互作用更为复杂，因此需要一种新的方法来全面理解和量化这些效应。

Method: 通过 TCAD 建模，提出了一种普适性滞后映射方法，用于分析纳米尺度 MoS$_{2}$/HfO$_{2}$ FETs 中的各种滞后动力学（包括顺时针、逆时针、开关和时间分离），并将其扩展到偏置温度不稳定性（BTI）分析，最后通过实验数据验证了该方法的准确性。

Result: 该研究提出的普适性滞后映射方法能够准确捕捉顺时针（CW）和逆时针（CCW）滞后、CW/CCW 开关以及时间分离等多种滞后动力学。此外，该方法还显示了复杂的滞后动力学与异常的 BTI 恢复之间存在明确的相关性。实验验证表明，该方法比传统的恒流提取方法更准确，并且能够处理由移动离子引起的 CCW 滞后。

Conclusion: 该研究提出了一种普适性滞后映射方法，可用于分析纳米尺度 MoS$_{2}$/HfO$_{2}$ FETs 中的复杂滞后动力学，并揭示了其与 BTI 行为之间的关联，为器件的可靠性研究提供了新的视角。

Abstract: Field-effect transistors (FETs) based on 2D materials have already reached
the stage of trial FAB integration. However, reliability limitations caused by
various defects present a serious obstacle for their smooth way forward,
especially when scaling the device geometries. Still the ongoing research is
mostly focused on pure technology aspects, while reliability is often recalled
only when showing a randomly measured gate transfer curve to manifest that the
hysteresis is "negligible".In fact the hysteresis dynamics contain unique
fingerprints of various mechanisms which may coexist or cancel each other,
being more complex in scaled FETs, for instance because of simultaneous
interaction of defects with the channel and top gate in thin insulators. To
fill this gap, here by doing TCAD modeling for nanoscale MoS$_2$/HfO$_2$ FETs
we introduce the universal hysteresis mapping method which can correctly
capture commonly measured diverse hysteresis dynamics such as conventional
clockwise (CW) and counterclockwise (CCW) hysteresis, as well as CW/CCW
switching and time separation. Next we extend this method to bias-temperature
instabilities (BTI) and show a clear correlation between complex hysteresis
dynamics and abnormal BTI recovery. Finally, we validate our mapping method
using available experimental data for MoS$_2$ FETs and demonstrate that it
provides far more accurate results than a conventional constant current
extraction of the hysteresis width, being also usable if a CCW hysteresis is
caused by mobile ions.

</details>


### [144] [History-dependent and frequency-dependent dielectric nonlinearities induced by polar nanoregions in a thin film of 0.5 ( Ba 0.7 Ca 0.3 TiO 3 ) -- 0.5 ( BaZr 0.2 Ti 0.8 O 3 )](https://arxiv.org/abs/2507.13021)
*Kevin Nadaud,Guillaume Nataf,Nazir Jaber,Edgar Chaslin,Béatrice Negulescu,Jérôme Wolfman*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究通过阻抗谱和三次谐波测量，发现0.5(Ba0.7 Ca0.3 TiO3 )--0.5(BaZr 0.2 Ti0.8 O3 )薄膜的介电非线性（捏合效应）受频率影响，且与PNRs响应相关。重复测量可改变PNRs构型，使其从捏合态转变为软铁电态，FORC测量也证实了这一点。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在深入理解0.5(Ba0.7 Ca0.3 TiO3 )--0.5(BaZr 0.2 Ti0.8 O3 )薄膜中介电非线性现象，特别是与极性纳米区（PNRs）相关的迟滞回线捏合效应，并探索其对测量条件（如频率、交流场幅值）和样品状态（如循环次数）的依赖性，以期为相关材料的优化和应用提供理论指导。

Method: 本研究采用阻抗谱和三次谐波测量技术，研究了0.5(Ba0.7 Ca0.3 TiO3 )--0.5(BaZr 0.2 Ti0.8 O3 )薄膜的介电非线性，并考察了其在不同交流测量场幅值、频率和循环次数下的变化。此外，还运用了第一类反转曲线（FORCs）和单极阻抗测量策略来进一步分析和验证结果。

Result: 研究发现，迟滞回线的捏合效应在低频下更为显著，这与PNRs的响应对频率的强依赖性一致。重复测量显示，PNRs的构型可以被低交流场强烈改变，从捏合状态演变为常规弛豫状态。FORC测量证实了捏合迟滞回线的存在，并且重复测量会导致分布向软铁电体转变。FORC测量结果与单极阻抗测量所揭示的Preisach平面的不对称性相符。

Conclusion: 该研究表明，介电非线性，特别是迟滞回线的捏合效应，在0.5(Ba0.7 Ca0.3 TiO3 )--0.5(BaZr 0.2 Ti0.8 O3 )薄膜中，受交流测量场和频率的显著影响。极性纳米区（PNRs）是导致捏合效应的原因，其响应对频率非常敏感，并且可以通过重复测量和FORC测量得到调控，最终表现出软铁电体的特性。

Abstract: In this article, dielectric nonlinearities in 0.5(Ba0.7 Ca0.3 TiO3 ) --
0.5(BaZr 0.2 Ti0.8 O3 ) thin film are studied using impedance spectroscopy and
harmonic measurements, as a function of the AC measuring field, at different
frequencies and upon cycling. The measurements reveal that the pinching of the
hysteresis loop, characterized by a phase angle of the third harmonic close to
--270 deg, is stronger for low frequencies. This confirms that the pinching is
induced by the presence of polar nanoregions (PNRs), whose responses are also
strongly dependent on frequency. When repeating the measurement, the PNR
contribution changes since the phase angle of the third-harmonic response
evolves from pinched to conventional relaxor. This shows that strong changes in
the PNR configuration can be induced, even for low AC fields. First-order
reversal curves (FORCs) confirm the presence of a pinched hysteresis loop. When
repeating the FORC measurement a second time, the distribution drastically
changes and corresponds to a soft ferroelectric. The asymmetry of the Preisach
plane measured using FORCs is confirmed by a proposed measurement strategy:
unipolar impedance measurements.

</details>


### [145] [Origin of circular and triangular pores in electron-irradiated hexagonal boron nitride](https://arxiv.org/abs/2507.13180)
*Umair Javed,Manuel Langle,Vladimir Zobac,Alexander Markevich,Clara Kofler,Martin Paul,Clemens Mangler,Toma Susi,Jani Kotakoski*

Main category: cond-mat.mtrl-sci

TL;DR: "Electron irradiation of hBN forms circular pores in ultra-high vacuum but triangular pores in the presence of oxygen. Oxygen etches boron, creating triangular pores, offering a way to engineer pores in 2D materials."


<details>
  <summary>Details</summary>
Motivation: "The study aims to explain the long-standing discrepancy in the shape of pores (triangular vs. circular) formed by electron irradiation of hBN, which has been attributed to different defect formation mechanisms. It also seeks to provide a controlled method for creating nanometer-sized pores in 2D materials."

Method: "This study utilizes a combination of experimental transmission electron microscopy (TEM) and ab initio calculations. Electron irradiation experiments were performed on hexagonal boron nitride (hBN) under different atmospheric conditions (high-vacuum vs. ultra-high vacuum with trace oxygen). Ab initio calculations were used to investigate the preferential attachment of oxygen atoms to boron at the pore edge and the subsequent etching process during irradiation."

Result: "Electron irradiation of hBN in ultra-high vacuum results in circular pores, while the presence of even small amounts of oxygen leads to the formation of triangular pores. Ab initio calculations indicate that oxygen preferentially etches boron atoms at the pore edge, leading to nitrogen-terminated triangular defects."

Conclusion: "We demonstrate a deterministic method for creating atomically defined pores in 2D materials by controlling the shape of pores formed during electron irradiation of hBN. Our findings explain the origin of triangular pores and provide a pathway for engineering nanostructures." 

Abstract: For nearly two decades, it has been known that electron irradiation of
hexagonal boron nitride (hBN) in a transmission electron microscope leads to
the formation of triangular pores. This has been attributed to the lower
displacement threshold energy of boron, with or without the assistance of an
inelastic scattering event, typically assuming that chemical etching caused by
residual gases can be neglected. In this study, in contrast to previous
high-vacuum experiments, we show that electron irradiation in ultra-high vacuum
leads to circular pores, whereas even small amounts of oxygen in the atmosphere
during the experiment change the pores into triangles. Ab initio calculations
show that oxygen atoms preferentially attach to boron at the pore edge,
supporting the hypothesis that they are preferentially etched during
irradiation, resulting in nitrogen-terminated triangular defects. Our results
explain the origin of triangular pores in hBN and demonstrate a deterministic
way to create atomically-defined pores into 2D materials.

</details>


### [146] [Phase transitions of eutectic high entropy alloy AlCoCrFeNi2.1 under shock compression](https://arxiv.org/abs/2507.13218)
*Sophie Parsons,Kento Katagiri,Hangman Chen,Anirudh Hari,Tharun Reddy,Sara J. Irvine,Laura Madril,Dorian Luccioni,Jie Ren,Wuxian Yang,Norimasa Ozaki,Alexis Amouretti,Ryosuke Kodama,Hirotaka Nakamura,Yusuke Nakanishi,Masato Ota,Yusuke Seto,Sota Takagi,Takuo Okuchi,Yuhei Umeda,Yuichi Inubushi,Kohei Miyanishi,Keiichi Sueda,Tadashi Togashi,Makina Yabashi,Toshinori Yabuuchi,Wanghui Li,Paul E. Specht,Penghui Cao,Wen Chen,Yogesh K. Vohra,Leora E. Dresselhaus-Marais*

Main category: cond-mat.mtrl-sci

TL;DR: 高熵合金（HEAs）是一类新型金属，具有独特的机械性能。在HEAs中，增材制造共晶高熵合金（AM-EHEAs）由于同时具有高强度和高延展性，最近已成为极端条件下使用的候选材料。然而，AM-EHEAs在高压下的变形和结构演化特征尚不明确，限制了它们在极端应用中的使用。本研究通过动态压缩实验和分子动力学模拟，研究了AM-EHEA AlCoCrFeNi2.1在高达400 GPa压力下的结构演化。我们的原位X射线衍射测量捕获了不同压力条件下fcc相和bcc相的出现，与纯相和混合相区域。理解AM-EHEA的相稳定性和结构演化为指导开发用于极端条件的高性能复杂材料提供了新的见解。


<details>
  <summary>Details</summary>
Motivation: 增材制造共晶高熵合金（AM-EHEAs）因其高强度和高延展性在极端条件下具有应用潜力，但其在高压下的变形和结构演化特征尚不明确，限制了其在极端应用中的使用。因此，研究AM-EHEAs在高压下的行为对于指导开发用于极端条件的高性能复杂材料至关重要。

Method: 本研究采用动态压缩实验和分子动力学模拟相结合的方法，研究了AM-EHEA AlCoCrFeNi2.1在高达400 GPa压力下的结构演化。通过原位X射线衍射测量捕获了不同压力条件下fcc相和bcc相的出现以及纯相和混合相区域。

Result: 在高达400 GPa的压力下，AM-EHEA AlCoCrFeNi2.1的结构演化研究表明，在不同压力条件下出现了fcc相和bcc相，并存在纯相和混合相区域。

Conclusion: 高熵合金（HEAs）是一类新型金属，具有独特的机械性能。在HEAs中，增材制造共晶高熵合金（AM-EHEAs）由于同时具有高强度和高延展性，最近已成为极端条件下使用的候选材料。然而，AM-EHEAs在高压下的变形和结构演化特征尚不明确，这限制了它们在极端应用中的使用。本研究通过动态压缩实验和分子动力学模拟，研究了AM-EHEA AlCoCrFeNi2.1在高达400 GPa压力下的结构演化。我们的原位X射线衍射测量捕获了不同压力条件下fcc相和bcc相的出现，以及纯相和混合相区域。理解AM-EHEA的相稳定性和结构演化为了指导开发用于极端条件的高性能复杂材料提供了新的见解。

Abstract: High entropy alloys (HEAs) are a new class of metals that exhibit unique
mechanical performance. Among HEAs, additively manufactured eutectic high
entropy alloys (AM-EHEAs) have recently emerged as candidate materials for use
in extreme conditions due to their simultaneous high strength and ductility.
However, the deformation and structural evolution of AM-EHEAs under conditions
of high pressure have not been well characterized, limiting their use in
extreme applications. We present dynamic compression experiments and molecular
dynamics simulations studying the structural evolution of AM-EHEA AlCoCrFeNi2.1
when compressed to pressures up to 400 GPa. Our in-situ X-ray diffraction
measurements capture the appearance of fcc and bcc phases at different pressure
conditions, with pure- and mixed-phase regions. Understanding the phase
stability and structural evolution of the AM EHEA offers new insights to guide
the development of high-performance complex materials for extreme conditions.

</details>


### [147] [Preferential site ordering alters the magnetic structure of Sm$_3$Ru$_4$Sn$_{13-x}$Ge$_x$ ($x = 0$-2)](https://arxiv.org/abs/2507.13243)
*Jacob W. Fritsky,Hui-Fei Zhai,Yifeng Zhao,Aryan Rauniyar,Antia S. Botana,Jason F. Khoury*

Main category: cond-mat.mtrl-sci

TL;DR: 研究了Sm$_3$Ru$_4$Sn$_{13-x}$Ge$_x$的合成与表征，发现Ge的掺入会引起磁挫，并可以调控其磁结构。


<details>
  <summary>Details</summary>
Motivation: Ln$_3$M$_4$X$_{13}$（Ln = 镧系元素，M = 过渡金属，X = 14族元素）填充的司盖特矿家族因其组分的可调性及其对超导性和复杂磁性等物理性质的影响而备受关注。

Method: 通过过量Sn-助熔剂合成Sm$_3$Ru$_4$Sn$_{13-x}$Ge$_x$ (x = 0 -- 2)，并使用粉末和单晶X射线衍射、磁测量、X射线光电子能谱和热容进行表征。

Result: Sm$_3$Ru$_4$Sn$_{13}$及其Ge固溶体成员结晶在Pm-3n空间群。在固溶体成员中，Ge优先占据两个Wyckoff位置之一。Ge的优先占据率在x=1和x=2时分别达到约60%和100%。Sm$_3$Ru$_4$Sn$_{13}$的磁测量和热容测量表明在T$_N$ = 7.3 K时存在反铁磁有序。然而，Sm$_3$Ru$_4$Sn$_{12}$Ge和Sm$_3$Ru$_4$Sn$_{11}$Ge$_2$的反铁磁相变温度较低，分别为T$_N$ = 5.5 K和4.1 K，且峰展宽明显。这些数据表明，将Ge合金化到Sm$_3$Ru$_4$Sn$_{13}$中会导致结构内的磁挫，这可能归因于费米能级附近额外的Ge p态引起的态密度变化。

Conclusion: 通过优先合金化Ge到Sm$_3$Ru$_4$Sn$_{13-x}$Ge$_x$中，可以更精确地调控其磁结构，阐明了在金属间材料中设计不同量子相的原理。

Abstract: An important aspect of materials research is the ability to tune different
physical properties through controlled alloying. The Ln$_3$M$_4$X$_{13}$ (Ln =
Lanthanide, M = Transition Metal, X = Tetrel) filled skutterudite family is of
interest due to the tunability of its constituent components and their effects
on physical properties, such as superconductivity and complex magnetism. In
this work, Sm$_3$Ru$_4$Sn$_{13-x}$Ge$_x$ (x = 0 -- 2) was synthesized via
excess Sn-flux and characterized using powder and single-crystal X-ray
diffraction, magnetometry, X-ray photoelectron spectroscopy, and heat capacity.
Sm$_3$Ru$_4$Sn$_{13}$ and its Ge-solid-solution members crystallize in the
Pm-3n space group, which has two unique Wyckoff positions for the tetrel (X)
site. In the solid solution members, Ge shows preferential occupancy for one of
the two Wyckoff sites, reaching $\sim$60$\%$ and 100$\%$ occupancy when x = 1
and 2, respectively. Magnetometry and heat capacity measurements of
Sm$_3$Ru$_4$Sn$_{13}$ indicated antiferromagnetic ordering at $T_N$ = 7.3 K.
However, Sm$_3$Ru$_4$Sn$_{12}$Ge and Sm$_3$Ru$_4$Sn$_{11}$Ge$_2$ showed notably
lower-temperature antiferromagnetic phase transitions with substantial
peak-broadening at $T_N$ = 5.5 K and 4.1 K, respectively. These data suggest
that alloying Ge into Sm$_3$Ru$_4$Sn$_{13}$ causes magnetic frustration within
the structure, likely attributable to a change in the density of states from
additional Ge $p$ states at the Fermi level. This work demonstrates that
preferentially alloying Ge in Sm$_3$Ru$_4$Sn$_{13-x}$Ge$_x$ allows for more
precise tunability of its magnetic structure, elucidating design principles for
different quantum phases in intermetallic materials.

</details>


### [148] [The carbon cost of materials discovery: Can machine learning really accelerate the discovery of new photovoltaics?](https://arxiv.org/abs/2507.13246)
*Matthew Walker,Keith T. Butler*

Main category: cond-mat.mtrl-sci

TL;DR: 使用机器学习替代密度泛函理论进行光伏材料计算，可以降低碳排放并提高效率，部分机器学习模型甚至优于传统方法。


<details>
  <summary>Details</summary>
Motivation: DFT计算在光伏材料发现中虽然比实验方法更高效，但仍有显著的计算和环境成本。ML模型作为DFT的替代品，能够大幅减少资源消耗并保持可预测的性能。

Method: 本文复现了基于DFT的计算流程，用于估算最大效率极限，并逐步引入ML替代其组件，同时量化了不同计算策略的CO2排放，以评估预测效果和环境成本之间的权衡。

Result: 找到了多种混合ML/DFT策略，能够在准确性和排放量之间进行优化。直接预测标量量（如最大效率）比使用预测吸收光谱作为中间步骤更有效。ML模型在筛选应用中表现优于使用替代交换-相关泛函的DFT流程。

Conclusion: ML模型在光伏材料发现中可以替代DFT计算，并且在某些情况下比使用替代交换-相关泛函的DFT工作流程更优，这突显了数据驱动方法的有效性。

Abstract: Computational screening has become a powerful complement to experimental
efforts in the discovery of high-performance photovoltaic (PV) materials. Most
workflows rely on density functional theory (DFT) to estimate electronic and
optical properties relevant to solar energy conversion. Although more efficient
than laboratory-based methods, DFT calculations still entail substantial
computational and environmental costs. Machine learning (ML) models have
recently gained attention as surrogates for DFT, offering drastic reductions in
resource use with competitive predictive performance. In this study, we
reproduce a canonical DFT-based workflow to estimate the maximum efficiency
limit and progressively replace its components with ML surrogates. By
quantifying the CO$_2$ emissions associated with each computational strategy,
we evaluate the trade-offs between predictive efficacy and environmental cost.
Our results reveal multiple hybrid ML/DFT strategies that optimize different
points along the accuracy--emissions front. We find that direct prediction of
scalar quantities, such as maximum efficiency, is significantly more tractable
than using predicted absorption spectra as an intermediate step. Interestingly,
ML models trained on DFT data can outperform DFT workflows using alternative
exchange--correlation functionals in screening applications, highlighting the
consistency and utility of data-driven approaches. We also assess strategies to
improve ML-driven screening through expanded datasets and improved model
architectures tailored to PV-relevant features. This work provides a
quantitative framework for building low-emission, high-throughput discovery
pipelines.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [149] [DNA Probe Computing System for Solving NP-Complete Problems](https://arxiv.org/abs/2507.12470)
*Jin Xu,XiaoLong Shi,Xin Chen,Fang Wang,Sirui Li,Pali Ye,Boliang Zhang,Di Deng,Zheng Kou,Xiaoli Qiang*

Main category: cs.DS

TL;DR: 本研究提出一种基于DNA计算的阻塞探测技术，在分子水平上实现了全并行计算，可一次性解决NP完全问题，并以3着色问题为例验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统电子计算机在处理NP完全问题（如蛋白质结构预测、密码解密和漏洞检测）时受限于图灵机的单维数据处理和顺序操作的瓶颈，需要采用多维数据结构和并行信息处理机制。

Method: 利用DNA计算的固有并行性，开发了一种阻塞探测技术，该技术可以在一次探测操作中识别NP完全问题的所有有效解决方案。

Result: 通过使用27顶点3着色问题作为案例研究，成功通过DNA分子探测实验检索了所有解决方案。

Conclusion: 该研究成功实现了分子水平的全并行计算系统，为解决计算复杂性问题提供了新范式。结果表明，探测机及其并行架构和分子实现超越了经典模型的限制，有望解决复杂的现实世界问题。

Abstract: Efficiently solving NP-complete problems-such as protein structure
prediction, cryptographic decryption, and vulnerability detection-remains a
central challenge in computer science. Traditional electronic computers,
constrained by the Turing machine's one-dimensional data processing and
sequential operations, struggle to address these issues effectively. To
overcome this bottleneck, computational models must adopt multidimensional data
structures and parallel information processing mechanisms. Building on our
team's proposed probe machine model (a non-Turing computational framework),
this study develops a blocking probe technique that leverages DNA computing's
inherent parallelism to identify all valid solutions for NP-complete problems
in a single probe operation. Using the 27-vertex 3-coloring problem as a case
study, we successfully retrieved all solutions through DNA molecular probe
experiments. This breakthrough demonstrates the first implementation of a fully
parallel computing system at the molecular level, offering a novel paradigm for
tackling computational complexity. Our results indicate that the probe machine,
with its parallel architecture and molecular implementation, transcends the
limitations of classical models and holds promise for solving intricate
real-world problems.

</details>


### [150] [Max-Cut with Multiple Cardinality Constraints](https://arxiv.org/abs/2507.12607)
*Yury Makarychev,Madhusudhan Reddy Pittu,Ali Vakilian*

Main category: cs.DS

TL;DR: 研究多基数约束下的最大割问题，提出改进算法并证明NP难性。


<details>
  <summary>Details</summary>
Motivation: 研究经典的在多个基数约束下的最大割问题（Constrained Max-Cut），旨在改进现有算法在近似比和适用范围上的不足。

Method: 本文结合了近似核和 Raghav-Tan (2012) 的相关性舍入技术，设计了一个近似算法。对于一般情况下的c，证明了确定是否存在一个能割断所有边的可行解是NP难的。最后，提出一个针对任意拟阵约束的最大割问题的1/2近似算法。

Result: 当c为常数时，实现了（0.858 - ε）的近似比，优于Feige和Langberg (2001)的（1/2 + ε0）近似比，并推广了Raghavendra和Tan (2012) 的结果。证明了一般情况下c的NP难性，并提出了一个针对任意拟阵约束的最大割问题的1/2近似算法。

Conclusion: 本文提出了一个针对具有多个基数约束的最大割问题（Constrained Max-Cut）的近似算法。当约束数量c为常数时，该算法能达到（0.858 - ε）的近似比，并且在处理单约束（c=1）和无约束（min{k,n-k}=Ω(n)）的情况下优于现有算法。此外，文章还证明了确定是否存在一个能割断所有边的可行解对于一般情况下的c是NP难的，并提出了一个针对任意拟阵约束的最大割问题的1/2近似算法。

Abstract: We study the classic Max-Cut problem under multiple cardinality constraints,
which we refer to as the Constrained Max-Cut problem. Given a graph $G=(V, E)$,
a partition of the vertices into $c$ disjoint parts $V_1, \ldots, V_c$, and
cardinality parameters $k_1, \ldots, k_c$, the goal is to select a set $S
\subseteq V$ such that $|S \cap V_i| = k_i$ for each $i \in [c]$, maximizing
the total weight of edges crossing $S$ (i.e., edges with exactly one endpoint
in $S$).
  By designing an approximate kernel for Constrained Max-Cut and building on
the correlation rounding technique of Raghavendra and Tan (2012), we present a
$(0.858 - \varepsilon)$-approximation algorithm for the problem when $c =
O(1)$. The algorithm runs in time $O\left(\min\{k/\varepsilon,
n\}^{\poly(c/\varepsilon)} + \poly(n)\right)$, where $k = \sum_{i \in [c]} k_i$
and $n=|V|$. This improves upon the $(\frac{1}{2} +
\varepsilon_0)$-approximation of Feige and Langberg (2001) for $\maxcut_k$ (the
special case when $c=1, k_1 = k$), and generalizes the $(0.858 -
\varepsilon)$-approximation of Raghavendra and Tan (2012), which only applies
when $\min\{k,n-k\}=\Omega(n)$ and does not handle multiple constraints.
  We also establish that, for general values of $c$, it is NP-hard to determine
whether a feasible solution exists that cuts all edges. Finally, we present a
$1/2$-approximation algorithm for Max-Cut under an arbitrary matroid
constraint.

</details>


### [151] [Fast Approximate Rank Determination and Selection with Group Testing](https://arxiv.org/abs/2507.12634)
*Adiesha Liyanage,Braeden Sopp,Brendan Mumey*

Main category: cs.DS

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Suppose that a group test operation is available for checking order relations
in a set, can this speed up problems like finding the minimum/maximum element,
rank determination and selection? We consider a one-sided group test to be
available, where queries are of the form $u \le_Q V$ or $V \le_Q u$, and the
answer is `yes' if and only if there is some $v \in V$ such that $u \le v$ or
$v \le u$, respectively. We restrict attention to total orders and focus on
query-complexity; for min or max finding, we give a Las Vegas algorithm that
makes $\mathcal{O}(\log^2 n)$ expected queries. We also give randomized
approximate algorithms for rank determination and selection; we allow a
relative error of $1 \pm \delta$ for $\delta > 0$ in the estimated rank or
selected element. In this case, we give a Monte Carlo algorithm for approximate
rank determination with expected query complexity
$\tilde{\mathcal{O}}(1/\delta^2 - \log \epsilon)$, where $1-\epsilon$ is the
probability that the algorithm succeeds. We also give a Monte Carlo algorithm
for approximate selection that has expected query complexity
$\tilde{\mathcal{O}}(-\log( \epsilon \delta^2) / \delta^4)$; it has probability
at least $\frac{1}{2}$ to output an element $x$, and if so, $x$ has the desired
approximate rank with probability $1-\epsilon$.

</details>


### [152] [An EPTAS for multiprocessor scheduling with rejection under a machine cost constraint](https://arxiv.org/abs/2507.12635)
*Mingyang Gong,Brendan Mumey*

Main category: cs.DS

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We study the multiprocessor scheduling with rejection problem under a machine
cost constraint. In this problem, each job is either rejected with a rejection
penalty or; accepted and scheduled on one of the machines for processing. The
machine cost is proportional to the total processing time of the jobs scheduled
on it. The problem aims to minimize the makespan of accepted jobs plus the
total rejection penalty of rejected jobs while the total machine cost does not
exceed a given upper bound. We present a simple $2$-approximation algorithm for
the problem and we achieve an EPTAS when the number $m$ of machines is a fixed
constant.

</details>


### [153] [Computing and Bounding Equilibrium Concentrations in Athermic Chemical Systems](https://arxiv.org/abs/2507.12699)
*Hamidreza Akef,Minki Hhan,David Soloveichik*

Main category: cs.DS

TL;DR: 该研究提出了一种计算分子复合物平衡浓度的迭代算法，特别适用于DNA纳米技术等领域，该算法能够有效控制目标和非目标分子的浓度，并已成功应用于减少DNA逻辑中的泄漏。


<details>
  <summary>Details</summary>
Motivation: 计算分子复合物的平衡浓度通常在解析上是不可行的，需要数值方法。该研究的动机是在聚合物-单体层面找到一种有效的方法来确定和控制这些浓度，特别是在DNA纳米技术等领域，其中相互作用是强结合且焓保持不变的。

Method: 开发了一种迭代算法，用于在聚合物-单体层面，在无热环境下分配聚合物浓度，以满足详细平衡条件，从而使目标聚合物的浓度最大化，非目标聚合物的浓度最小化。

Result: 所提出的算法能够有效地确定聚合物的平衡浓度，即使在未直接执行的情况下，也能为非目标聚合物的浓度提供有效的上界。该方法将组合论证（例如TBN模型中的离散配置）与实值浓度联系起来，并成功应用于DNA逻辑和信号传播以减少泄漏。

Conclusion: 该研究提出了一种用于计算分子复合物平衡浓度的迭代算法，特别是在聚合物-单体层面，并考虑了无热环境设置，其中所有相互作用都保留焓。该方法通过满足详细平衡来分配聚合物浓度，从而实现目标聚合物的高浓度和非目标聚合物的低浓度。该算法为理解和限制非目标聚合物浓度提供了见解，并将组合论证与实值浓度联系起来。最后，将该方法应用于DNA逻辑和信号传播以减少泄漏。

Abstract: Computing equilibrium concentrations of molecular complexes is generally
analytically intractable and requires numerical approaches. In this work we
focus on the polymer-monomer level, where indivisible molecules (monomers)
combine to form complexes (polymers). Rather than employing free-energy
parameters for each polymer, we focus on the athermic setting where all
interactions preserve enthalpy. This setting aligns with the strongly bonded
(domain-based) regime in DNA nanotechnology when strands can bind in different
ways, but always with maximum overall bonding -- and is consistent with the
saturated configurations in the Thermodynamic Binding Networks (TBNs) model.
Within this context, we develop an iterative algorithm for assigning polymer
concentrations to satisfy detailed-balance, where on-target (desired) polymers
are in high concentrations and off-target (undesired) polymers are in low. Even
if not directly executed, our algorithm provides effective insights into upper
bounds on concentration of off-target polymers, connecting combinatorial
arguments about discrete configurations such as those in the TBN model to
real-valued concentrations. We conclude with an application of our method to
decreasing leak in DNA logic and signal propagation. Our results offer a new
framework for design and verification of equilibrium concentrations when
configurations are distinguished by entropic forces.

</details>


### [154] [Splittable Spanning Trees and Balanced Forests in Dense Random Graphs](https://arxiv.org/abs/2507.12707)
*David Gillman,Jacob Platnick,Dana Randall*

Main category: cs.DS

TL;DR: 该研究通过分析随机树和森林的分割概率，为稠密随机图上的公平图分割提供了新的抽样算法，并指出了现有ReCom算法在特定情况下的不足。


<details>
  <summary>Details</summary>
Motivation: 加权公平图分割在重新划分选区、网络算法和图像分解等领域有重要应用，特别是利用生成树度量来获得更紧凑的分区，以及为这类问题开发高效的抽样算法。

Method: 该研究利用随机树抽样和森林组件分析，结合马尔可夫链分析，来研究加权公平图分割问题。

Result: 研究结果显示，稠密随机图上的生成树具有反多项式概率被分割成k个相等的部分，为一类图提供了首个严格的抽样算法，并保证了森林上up-down walk的快速近乎均匀抽样。同时，研究也指出了ReCom算法在某些图上的局限性，包括马尔可夫链不可约性问题和潜在的指数级拒绝采样时间。

Conclusion: 该研究表明，在稠密随机图上，生成森林的生成树具有反多项式概率被分割成k个相等的部分，从而为一类图提供了第一个严格的抽样算法。此外，研究还揭示了ReCom算法在平衡分割问题中存在更广泛的问题，即使在理想情况下也可能导致拒绝采样步骤耗时呈指数级增长。

Abstract: Weighted equitable partitioning of a graph has been of interest lately due to
several applications, including redistricting, network algorithms, and image
decomposition. Weighting a partition according to the spanning-tree metric has
been of mathematical and practical interest because it typically favors
partitions with more compact pieces. An appealing algorithm suggested by
Charikar et al. is to sample a random spanning tree and remove k-1 edges,
producing a random forest. If the components of the forest form a balanced
partition, the partition is equitable under an easily computed acceptance
probability. Cannon et al. recently showed that spanning trees on grid graphs
and grid-like graphs on $n$ vertices are splittable into $k$ equal sized pieces
with probability at least $n^{-2k}$, leading to the first rigorous sampling
algorithm for a class of graphs. We present complementary results showing that
spanning trees on dense random graphs also have inverse polynomial probability
of being splittable, giving another class of graphs where equitable partitions
can be efficiently sampled exactly. These proofs also guarantee fast
almost-uniform sampling for the up-down walk on forests, giving another
provably efficient randomized method for generating equitable partitions.
  Further, we show that problems with the well-studied ReCom algorithm for
equitable partitioning are more extensive than previously known, even in
special cases that were believed to be more promising. We present a family of
graphs where the Markov chain fails to be irreducible when it must keep the
components perfectly equitable; yet when the chain is allowed an imbalance of
just one vertex between components, the rejection sampling step may take
exponential time. This is true even when the graph satisfies desirable
properties that have been conjectured to be sufficient for fast sampling.

</details>


### [155] [Waiting is worth it and can be improved with predictions](https://arxiv.org/abs/2507.12822)
*Ya-Chun Liang,Meng-Hsi Li,Chung-Shou Liao,Clifford Stein*

Main category: cs.DS

TL;DR: 该研究提出了一个使用在线预测来改进 OLTSP 和 OLDARP 竞争比的算法，实现了比现有算法更好的性能，但竞争比仍受限于 2。


<details>
  <summary>Details</summary>
Motivation: 为了改进在线旅行推销员问题（OLTSP）和在线叫车问题（OLDARP）的最佳竞争比，研究了使用带有在线预测的算法。

Method: 提出了一种带有在线预测的等待策略，该策略不要求预先知道请求的数量，并分析了其一致性和鲁棒性。

Result: 该算法可以实现1.1514 * lambda + 1.5 的一致性和 1.5 + 1.5 / (2.3028 * lambda - 1) 的鲁棒性，其中 lambda 属于 (1/theta, 1]，theta 约等于 2.3028。当 lambda 接近 1/theta 时，一致性趋近于 2。

Conclusion: 研究表明，带有在线预测的在线算法可以改进在线旅行推销员问题（OLTSP）和在线叫车问题（OLDARP）的最佳竞争比，但任何基于调度的在线算法都无法获得小于2的竞争比。

Abstract: We revisit the well-known online traveling salesman problem (OLTSP) and its
extension, the online dial-a-ride problem (OLDARP). A server starting at a
designated origin in a metric space, is required to serve online requests, and
return to the origin such that the completion time is minimized. The SmartStart
algorithm, introduced by Ascheuer et al., incorporates a waiting approach into
an online schedule-based algorithm and attains the optimal upper bound of 2 for
the OLTSP and the OLDARP if each schedule is optimal. Using the Christofides'
heuristic to approximate each schedule leads to the currently best upper bound
of (7 + sqrt(13)) / 4 approximately 2.6514 in polynomial time.
  In this study, we investigate how an online algorithm with predictions, a
recent popular framework (i.e. the so-called learning-augmented algorithms),
can be used to improve the best competitive ratio in polynomial time. In
particular, we develop a waiting strategy with online predictions, each of
which is only a binary decision-making for every schedule in a whole route,
rather than forecasting an entire set of requests in the beginning (i.e.
offline predictions). That is, it does not require knowing the number of
requests in advance. The proposed online schedule-based algorithm can achieve
1.1514 * lambda + 1.5-consistency and 1.5 + 1.5 / (2.3028 * lambda -
1)-robustness in polynomial time, where lambda lies in the interval (1/theta,
1] and theta is set to (1 + sqrt(13)) / 2 approximately 2.3028. The best
consistency tends to approach to 2 when lambda is close to 1/theta. Meanwhile,
we show any online schedule-based algorithms cannot derive a competitive ratio
of less than 2 even with perfect online predictions.

</details>


### [156] [Cut-Matching Games for Bipartiteness Ratio of Undirected Graphs](https://arxiv.org/abs/2507.12847)
*Tasuku Soma,Mingquan Ye,Yuichi Yoshida*

Main category: cs.DS

TL;DR: 本文提出了一种用于计算无向图双分图比率的 O(log n) 近似算法，该算法基于割匹配博弈框架，并利用了良好连接性的概念。该算法运行时间接近线性，并可应用于最大割问题。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决无向图的双分图比率问题，并提出一种近似算法。

Method: 我们的方法将最稀疏割的割匹配博弈框架扩展到双分图比率，并需要多项式对数 n 次单商品无向最大流计算。此外，我们还引入了“良好连接性”的概念，并证明了双分图比率与辅助斜对称图中的良好连接性的新表征。

Result: 我们的算法在当前最快的无向最大流算法的加持下，运行时间接近线性。作为应用，我们设计了一个 O(mn) 时间的算法，可以找到一个删除 1 - O(log n log(1/η)) * η 比例边的割，其中 η 是最大割删除的边比例。

Conclusion: 我们提出了一个近似比为 O(log n) 的算法，用于计算由 Trevisan 引入的无向图的双分图比率。该算法将最稀疏割的割匹配博弈框架扩展到双分图比率。

Abstract: We propose an $O(\log n)$-approximation algorithm for the bipartiteness ratio
for undirected graphs introduced by Trevisan (SIAM Journal on Computing, vol.
41, no. 6, 2012), where $n$ is the number of vertices. Our approach extends the
cut-matching game framework for sparsest cut to the bipartiteness ratio. Our
algorithm requires only $\mathrm{poly}\log n$ many single-commodity undirected
maximum flow computations. Therefore, with the current fastest undirected
max-flow algorithms, it runs in nearly linear time. Along the way, we introduce
the concept of well-linkedness for skew-symmetric graphs and prove a novel
characterization of bipartitness ratio in terms of well-linkedness in an
auxiliary skew-symmetric graph, which may be of independent interest.
  As an application, we devise an $\tilde{O}(mn)$-time algorithm that given a
graph whose maximum cut deletes a $1-\eta$ fraction of edges, finds a cut that
deletes a $1 - O(\log n \log(1/\eta)) \cdot \eta$ fraction of edges, where $m$
is the number of edges.

</details>


### [157] [A 1/2-Approximation for Budgeted $k$-Submodular Maximization](https://arxiv.org/abs/2507.12875)
*Chenhao Wang*

Main category: cs.DS

TL;DR: k-子模最大化预算问题存在1/2近似比的算法。


<details>
  <summary>Details</summary>
Motivation: k-子模最大化问题比标准子模最大化问题更具挑战性，因为它不仅需要选择元素，还需要确定元素所属的子集。虽然已有研究证明了贪婪算法在单调k-子模最大化问题上的1/2近似比，但其在预算约束下的近似比问题一直悬而未决。

Method: 通过引入一种新颖的从最优解到贪婪解的连续变换，并利用多重线性扩展来评估分数解，实现了这一结果。该方法还可以改进现有算法的近似比，并推广到更广泛的约束条件。

Result: 1-Guess Greedy算法在单调k-子模最大化预算问题上实现了1/2近似比，该结果在渐近意义上是最优的。对于非单调问题，该算法实现了1/3近似比。该算法简单、可并行化，并且在加入阈值技术后，运行时间接近O(n^2k^2)。

Conclusion: 该研究解决了k-子模最大化在有预算约束下的1/2近似比问题，证明了1-Guess Greedy算法可以达到这一目标，并且对于非单调问题可以达到1/3近似比。该算法简单、可并行化，并且时间复杂度接近O(n^2k^2)。

Abstract: A $k$-submodular function naturally generalizes submodular functions by
taking as input $k$ disjoint subsets, rather than a single subset. Unlike
standard submodular maximization, which only requires selecting elements for
the solution, $k$-submodular maximization adds the challenge of determining the
subset to which each selected element belongs. Prior research has shown that
the greedy algorithm is a 1/2-approximation for the monotone $k$-submodular
maximization problem under cardinality or matroid constraints. However, whether
a firm 1/2-approximation exists for the budgeted version (i.e., with a knapsack
constraint) has remained open for several years. We resolve this question
affirmatively by proving that the 1-Guess Greedy algorithm, which first guesses
an appropriate element from an optimal solution before proceeding with the
greedy algorithm, achieves a 1/2-approximation. This result is asymptotically
tight as $((k+1)/(2k)+\epsilon)$-approximation requires exponentially many
value oracle queries even without constraints (Iwata et al., SODA 2016). We
further show that 1-Guess Greedy is 1/3-approximation for the non-monotone
problem. This algorithm is both simple and parallelizable, making it
well-suited for practical applications. Using the thresholding technique from
(Badanidiyuru and Vondrak, SODA 2014), it runs in nearly $\tilde O(n^2k^2)$
time.
  The proof idea is simple: we introduce a novel continuous transformation from
an optimal solution to a greedy solution, using the multilinear extension to
evaluate every fractional solution during the transformation. This continuous
analysis approach yields two key extensions. First, it enables improved
approximation ratios of various existing algorithms. Second, our method
naturally extends to $k$-submodular maximization problems under broader
constraints, offering a more flexible and unified analysis framework.

</details>


### [158] [Efficient Semi-External Breadth-First Search](https://arxiv.org/abs/2507.12925)
*Xiaolong Wan,Xixian Han*

Main category: cs.DS

TL;DR: 该论文提出了一种名为EP-BFS的高效算法，用于在半外部内存模型下处理大规模图的广度优先搜索（BFS），实验证明其速度比现有算法快10倍。


<details>
  <summary>Details</summary>
Motivation: 为了在主内存只能容纳图的生成树的情况下，解决大规模图数据库的广度优先搜索（BFS）问题，并提供比现有算法更优的解决方案。

Method: 提出了一种名为EP-BFS的高效算法，在半外部内存模型下处理大规模图的广度优先搜索（BFS），并进行了实验验证。

Result: EP-BFS算法在真实和合成的大规模图上进行了广泛的实验，结果显示其速度比现有算法快10倍，并且具有最小的内存空间需求。

Conclusion: 该论文提出了一种名为EP-BFS的高效算法，用于在半外部内存模型下处理大规模图的广度优先搜索（BFS），并在真实和合成的大规模图上进行了广泛的实验，结果显示EP-BFS的速度提高了10倍。

Abstract: Breadth-first search (BFS) is known as a basic search strategy for learning
graph properties. As the scales of graph databases have increased tremendously
in recent years, large-scale graphs G are often disk-resident. Obtaining the
BFS results of G in semi-external memory model is inevitable, because the
in-memory BFS algorithm has to maintain the entire G in the main memory, and
external BFS algorithms consume high computational costs. As a good trade-off
between the internal and external memory models, semi-external memory model
assumes that the main memory can at least reside a spanning tree of G.
Nevertheless, the semi-external BFS problem is still an open issue due to its
difficulty. Therefore, this paper presents a comprehensive study for processing
BFS in semi-external memory model. After discussing the naive solutions based
on the basic framework of semi-external graph algorithms, this paper presents
an efficient algorithm, named EP-BFS, with a small minimum memory space
requirement, which is an important factor for evaluating semi-external
algorithms. Extensive experiments are conducted on both real and synthetic
large-scale graphs, where graph WDC-2014 contains over 1.7 billion nodes, and
graph eu-2015 has over 91 billion edges. Experimental results confirm that
EP-BFS can achieve up to 10 times faster.

</details>


### [159] [The Price of Diversity of the Traveling Salesman Problem](https://arxiv.org/abs/2507.13026)
*Mark de Berg,Andrés López Martínez,Frits Spieksma*

Main category: cs.DS

TL;DR: 本文介绍了“价格多样性”（PoD）概念，用于衡量离散优化问题的多样性与成本之间的权衡。研究表明，在 TSP 问题中，寻找两个边不相交的 TSP 的 PoD 渐近值为 8/5（一维情况）和 2（一般度量空间）。


<details>
  <summary>Details</summary>
Motivation: 为了量化解决方案多样性与成本之间的权衡。

Method: 本文通过分析相关的最短哈密顿路径问题（SHP）来研究 TSP 的 PoD，并在此基础上得到了 TSP 的 PoD 结果。

Result: 在 TSP 的特殊一维情况下，找到两个边不相交的 TSP 的 PoD 渐近为 8/5；在一般度量空间中，PoD 为 2。

Conclusion: 本文研究了离散优化问题中的“价格多样性”（PoD），量化了解决方案多样性与成本之间的权衡。对于最小化问题，PoD 定义为所有实例中，一组 k 个不同解决方案的最低可实现成本与同一实例的单个最优解决方案成本之比的最坏情况。

Abstract: This paper introduces the concept of the "Price of Diversity" (PoD) in
discrete optimization problems, quantifying the trade-off between solution
diversity and cost. For a minimization problem, the PoD is defined as the
worst-case ratio, over all instances, of the minimum achievable cost of a
diverse set of $k$ solutions to the cost of a single optimal solution for the
same instance. Here, the cost of a $k$-solution set is determined by the most
expensive solution within the set. Focusing on the Traveling Salesman Problem
(TSP) as a key example, we study the PoD in the setting where $k$ edge-disjoint
tours are required. We establish that, asymptotically, the PoD of finding two
edge-disjoint tours is $\frac{8}{5}$ in a special one-dimensional case and 2 in
a general metric space. We obtain these results from analyzing a related
fundamental problem: the Shortest Hamiltonian Path problem (SHP), for which we
establish similar results.

</details>


### [160] [Maintaining Routing Structures under Deletions via Self-Pruning](https://arxiv.org/abs/2507.13044)
*Bernhard Haeupler,Antti Roeyskoe*

Main category: cs.DS

TL;DR: 本文提出了一种结合路由和剪枝的扩展器图，能在删除边时通过剪枝顶点来维持路由性能，并实现了最坏情况下的剪枝效率和常数路径长度。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决在剪枝操作下维护单位多商品流路由的问题。考虑到扩展器的可路由性和稳定性/可剪枝性这两个关键性质，以及由此产生的扩展器路由和扩展器剪枝两个核心问题，本文着重研究了将两者结合起来，即在剪枝步骤下维护单位多商品流的路由。

Method: 本文通过引入一族新的扩展器图，结合了路由和剪枝两个核心问题。该图族具有易于路由的特性，并且能够进行自剪枝，即在处理在线边删除序列时，能通过简单的自包含算法找到少量需要剪枝的顶点，从而保证剩余图仍然是易于路由的扩展器。

Result: 本文成功设计了一种易于路由且自剪枝的扩展器图族，能够在线处理边删除并保持路由性能。研究实现了最坏情况下的自剪枝，即每次边删除仅引起少量额外的顶点剪枝。此外，结果还能对路由路径长度进行严格的常数因子控制，适用于需要常数跳数和长度约束的扩展器。

Conclusion: 本文介绍了一族新的扩展器图，它们具有易于路由和自剪枝的特性，能够在线处理一系列边删除操作，并保持图的扩展器性质和路由能力。通过引入自剪枝机制，每次边删除仅需少量顶点剪枝即可维持图的性能。

Abstract: Expanders are powerful algorithmic structures with two key properties: they
are
  a) routable: for any multi-commodity flow unit demand, there exists a routing
with low congestion over short paths, where a demand is unit if the amount of
demand sent / received by any vertex is at most the number of edges adjacent to
it.
  b) stable / prunable: for any (sequence of) edge failures, there exists a
proportionally small subset of vertices that can be disabled, such that the
graph induced on the remaining vertices is an expander.
  Two natural algorithmic problems correspond to these two existential
guarantees: expander routing, i.e. computing a low-congestion routing for a
unit multi-commodity demand on an expander, and expander pruning, i.e.,
maintaining the subset of disabled vertices under a sequence of edge failures.
  This paper considers the combination of the two problems: maintaining a
routing for a unit multi-commodity demand under pruning steps. This is done
through the introduction of a family of expander graphs that, like hypercubes,
are easy to route in, and are self-pruning: for an online sequence of edge
deletions, a simple self-contained algorithm can find a few vertices to prune
with each edge deletion, such that the remaining graph always remains an
easy-to-route-in expander in the family.
  Notably, and with considerable technical work, this self-pruning can be made
worst-case, i.e., such that every single adversarial deletion only causes a
small number of additional deletions. Our results also allow tight
constant-factor control over the length of routing paths (with the usual
trade-offs in congestion and pruning ratio) and therefore extend to
constant-hop and length-constrained expanders in which routing over constant
length paths is crucial.

</details>


### [161] [Kernelization for $H$-Coloring](https://arxiv.org/abs/2507.13129)
*Yael Berkman,Ishay Haviv*

Main category: cs.DS

TL;DR: H-着色问题参数化为顶点覆盖数k时，本文通过组合和线性代数方法改进了核大小的界限，并给出了条件下的低阶界限，基本解决了该问题对某些目标图H的核复杂性。


<details>
  <summary>Details</summary>
Motivation: 研究H-着色问题以顶点覆盖数为参数时的核大小，旨在改进现有界限并接近条件下界。

Method: 本文提出了两种核化算法：一种是纯组合算法，其大小受图H的非邻接见证数的控制；另一种是利用线性代数工具，涉及图的忠实独立表示。

Result: 论文给出了新的核大小上界和下界，其中组合核的大小与图H的非邻接见证数相关，对于最大度无界的图H的某些类，其核大小有固定多项式界限。对于几乎所有图H，核大小界限中多项式次数仅以对数增长。线性代数核的界限得到加强，并在图表示维度问题上得到近优结果。

Conclusion: 本论文对以顶点覆盖数为参数的H-着色问题的核大小给出了新的上下界，并提出了相应的核化算法。

Abstract: For a fixed graph $H$, the $H$-Coloring problem asks whether a given graph
admits an edge-preserving function from its vertex set to that of $H$. A
seminal theorem of Hell and Ne\v{s}et\v{r}il asserts that the $H$-Coloring
problem is NP-hard whenever $H$ is loopless and non-bipartite. A result of
Jansen and Pieterse implies that for every graph $H$, the $H$-Coloring problem
parameterized by the vertex cover number $k$ admits a kernel with
$O(k^{\Delta(H)})$ vertices and bit-size bounded by $O(k^{\Delta(H)} \cdot \log
k)$, where $\Delta(H)$ denotes the maximum degree in $H$. For the case where
$H$ is a complete graph on at least three vertices, this kernel size nearly
matches conditional lower bounds established by Jansen and Kratsch and by
Jansen and Pieterse.
  This paper presents new upper and lower bounds on the kernel size of
$H$-Coloring problems parameterized by the vertex cover number. The upper
bounds arise from two kernelization algorithms. The first is purely
combinatorial, and its size is governed by a structural quantity of the graph
$H$, called the non-adjacency witness number. As applications, we obtain
kernels whose size is bounded by a fixed polynomial for natural classes of
graphs $H$ with unbounded maximum degree. More strikingly, we show that for
almost every graph $H$, the degree of the polynomial that bounds the size of
our combinatorial kernel grows only logarithmically in $\Delta(H)$. Our second
kernel leverages linear-algebraic tools and involves the notion of faithful
independent representations of graphs. It strengthens the general bound from
prior work and, among other applications, yields near-optimal kernels for
problems concerning the dimension of orthogonal graph representations over
finite fields. We complement these results with conditional lower bounds,
thereby nearly settling the kernel complexity of the problem for various target
graphs $H$.

</details>


### [162] [Online Rounding for Set Cover under Subset Arrivals](https://arxiv.org/abs/2507.13159)
*Jarosław Byrka,Yongho Shin*

Main category: cs.DS

TL;DR: 本文提出了一种改进的集覆盖舍入方案，在子集到达模型下达到了O(log^2 s)的竞争比，并成功应用于多阶段随机集覆盖和边覆盖问题，实现了性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有在线集覆盖算法在子集到达模型下的舍入方案竞争比较差（O(log n)），而元素到达模型下的舍入方案（O(log s)）与最大子集大小s相关。本文旨在改进子集到达模型下的舍入方案的竞争比，并将其应用于相关问题。

Method: 本文提出了一种新的舍入方案，并分析了其在子集到达模型下的竞争比，以及其在多阶段随机集覆盖问题和边覆盖问题中的应用。

Result: 在子集到达模型下，提出了一个O(log^2 s)竞争比的舍入方案，该方案可用于多阶段随机集覆盖问题的近似算法，并实现了在s较小时的改进。对于边覆盖问题，提出了一个1.8竞争比的舍入方案。

Conclusion: 本文提出了一个在子集到达模型下的O(log^2 s)竞争比的舍入方案，其中s是最大子集的大小，并假设s是预先已知的。该方案可用于多阶段随机集覆盖问题的近似算法，在s相对于阶段数和元素数量较小时，优于现有算法。此外，对于s=2的集覆盖问题（也称为边覆盖），本文在边到达模型下提出了一种1.8竞争比的舍入方案。

Abstract: A rounding scheme for set cover has served as an important component in
design of approximation algorithms for the problem, and there exists an
H_s-approximate rounding scheme, where s denotes the maximum subset size,
directly implying an approximation algorithm with the same approximation
guarantee. A rounding scheme has also been considered under some online models,
and in particular, under the element arrival model used as a crucial subroutine
in algorithms for online set cover, an O(log s)-competitive rounding scheme is
known [Buchbinder, Chen, and Naor, SODA 2014]. On the other hand, under a more
general model, called the subset arrival model, only a simple O(log
n)-competitive rounding scheme is known, where n denotes the number of elements
in the ground set.
  In this paper, we present an O(log^2 s)-competitive rounding scheme under the
subset arrival model, with one mild assumption that s is known upfront. Using
our rounding scheme, we immediately obtain an O(log^2 s)-approximation
algorithm for multi-stage stochastic set cover, improving upon the existing
algorithms [Swamy and Shmoys, SICOMP 2012; Byrka and Srinivasan, SIDMA 2018]
when s is small enough compared to the number of stages and the number of
elements. Lastly, for set cover with s = 2, also known as edge cover, we
present a 1.8-competitive rounding scheme under the edge arrival model.

</details>


### [163] [Efficiently Constructing Sparse Navigable Graphs](https://arxiv.org/abs/2507.13296)
*Alex Conway,Laxman Dhulipala,Martin Farach-Colton,Rob Johnson,Ben Landrum,Christopher Musco,Yarin Shechter,Torsten Suel,Richard Wen*

Main category: cs.DS

TL;DR: 该论文研究了如何高效地构建用于最近邻搜索的稀疏可导航图，提出了一种近似最优的算法，并将构建时间从O(n^3)降低到$	ilde{O}(n^2)$，同时证明了近似最优性的界限。


<details>
  <summary>Details</summary>
Motivation: 图为基础的最近邻搜索方法在各种应用中表现出色，但构建搜索图的计算成本高昂。因此，该研究旨在开发具有可证明保证的、能够高效构建搜索图的算法。

Method: 利用流式处理和亚线性时间集覆盖算法技术，并结合特定预处理技术，提出了一种构建O(log n)近似稀疏可导航图的$	ilde{O}(n^2)$时间算法，该算法可用于任何距离函数。该方法通过从单色最近点对问题进行归约，证明了其运行时在强指数时间假设下是最优的（在对数因子范围内）。

Result: 提出了一种$	ilde{O}(n^2)$时间的算法，可以构建一个$O(	ext{log }n)$-近似稀疏的可导航图，并且该运行时在强指数时间假设下是最优的（在对数因子范围内）。此外，研究还表明，获得比$O(	ext{log }n)$更好的近似是NP难的。最后，该方法可以将构建$	ext{α}$-shortcut可达和$	ext{τ}$-monotonic图的时间复杂度优化到$	ilde{O}(n^{2.5})$或更低。

Conclusion: 该研究首次对具有可证明保证的快速搜索图构建算法进行了研究，并提出了一种最优（在对数因子范围内）的近似算法，同时证明了在可导航图问题中获得比O(log n)更好的近似是NP难的。此外，该方法还能优化其他相关的图构建问题。

Abstract: Graph-based nearest neighbor search methods have seen a surge of popularity
in recent years, offering state-of-the-art performance across a wide variety of
applications. Central to these methods is the task of constructing a sparse
navigable search graph for a given dataset endowed with a distance function.
Unfortunately, doing so is computationally expensive, so heuristics are
universally used in practice.
  In this work, we initiate the study of fast algorithms with provable
guarantees for search graph construction. For a dataset with $n$ data points,
the problem of constructing an optimally sparse navigable graph can be framed
as $n$ separate but highly correlated minimum set cover instances. This yields
a naive $O(n^3)$ time greedy algorithm that returns a navigable graph whose
sparsity is at most $O(\log n)$ higher than optimal. We improve significantly
on this baseline, taking advantage of correlation between the set cover
instances to leverage techniques from streaming and sublinear-time set cover
algorithms. Combined with problem-specific pre-processing techniques, we
present an $\tilde{O}(n^2)$ time algorithm for constructing an $O(\log
n)$-approximate sparsest navigable graph under any distance function.
  The runtime of our method is optimal up to logarithmic factors under the
Strong Exponential Time Hypothesis via a reduction from Monochromatic Closest
Pair. Moreover, we prove that, as with general set cover, obtaining better than
an $O(\log n)$-approximation is NP-hard, despite the significant additional
structure present in the navigable graph problem. Finally, we show that our
techniques can also beat cubic time for the closely related and practically
important problems of constructing $\alpha$-shortcut reachable and
$\tau$-monotonic graphs, which are also used for nearest neighbor search. For
such graphs, we obtain $\tilde{O}(n^{2.5})$ time or better algorithms.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [164] [On multiagent online problems with predictions](https://arxiv.org/abs/2507.12486)
*Gabriel Istrate,Cosmin Bonchis,Victor Bogdan*

Main category: cs.MA

TL;DR: 该研究提出了一种多代理预测框架，并以滑雪租赁问题为例进行了分析，重点关注了预测器质量对算法竞争比的影响，并提出了一种更鲁棒的算法。


<details>
  <summary>Details</summary>
Motivation: 我们关注的主要问题是在各种预测器质量假设下，通过使用此类预测器可以实现的最佳竞争比。

Method: 我们引入了一个两预测器框架，假设代理使用一个预测器来预测其未来的（自我）行为，另一个预测器来预测其他玩家的行为。

Result: 研究了具有预测能力的（竞争性）算法在多代理环境中的能力。

Conclusion: 在其他预测完美的情况下，遵循自我预测器的算法是最优的，但对代理未来行为的误预测不够鲁棒；我们提供了一种具有更好鲁棒性的算法并对其进行了基准测试。

Abstract: We study the power of (competitive) algorithms with predictions in a
multiagent setting. We introduce a two predictor framework, that assumes that
agents use one predictor for their future (self) behavior, and one for the
behavior of the other players. The main problem we are concerned with is
understanding what are the best competitive ratios that can be achieved by
employing such predictors, under various assumptions on predictor quality.
  As an illustration of our framework, we introduce and analyze a multiagent
version of the ski-rental problem. In this problem agents can collaborate by
pooling resources to get a group license for some asset. If the license price
is not met then agents have to rent the asset individually for the day at a
unit price. Otherwise the license becomes available forever to everyone at no
extra cost.
  In the particular case of perfect other predictions the algorithm that
follows the self predictor is optimal but not robust to mispredictions of
agent's future behavior; we give an algorithm with better robustness properties
and benchmark it.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [165] [Differential Communication in Channels with Mobility and Delay Spread using Zak-OTFS](https://arxiv.org/abs/2507.12593)
*Sandesh Rao Mattu,Nishant Mehrotra,Robert Calderbank*

Main category: eess.SP

TL;DR: Zak-OTFS 差分通信：无需周期性导频，利用检测到的数据作为导频，提高能量利用率和频谱效率，且复杂度更低，误码率更优。


<details>
  <summary>Details</summary>
Motivation: 为了减轻 Zak-OTFS 系统中周期性导频传输的需要。

Method: 该方法利用了 Zak-OTFS 延迟-多普勒 (DD) 域信道的预测能力，将先前时刻通过检测到的数据符号（作为导频）获得的信道估计用于检测下一个时刻的数据，并以此向前传播。

Result: 该方法允许数据符号享有更高的能量，并且可以实现与点导频或嵌入式导频相比全频谱效率，同时在与全谱效率的扩频导频方案的比较中，在较低的复杂度下实现了更好的误码率。

Conclusion: 提出了一种用于 Zak-OTFS 系统的差分通信方案，该方案可以减轻周期性导频传输的需要，并且与全谱效率的扩频导频方案相比，在较低的复杂度下具有更好的误码率。

Abstract: Zak-transform based orthogonal time frequency space (Zak-OTFS) is a
delay-Doppler (DD) domain modulation scheme in which the signal processing is
carried out in the DD domain. The channel when viewed in the DD domain is
predictable. However, even with Zak-OTFS, pilots need to be sent periodically,
albeit at a lower rate. In this paper, we propose a differential communication
scheme for Zak-OTFS systems that alleviates the need for periodic pilot
transmission. Towards this, we analytically show that the detected data can be
used as a pilot and that the channel estimate obtained from the detected data
can enable further detection enabling the "differential" aspect of the
communication. Specifically, we leverage the prediction capability of the DD
channel in Zak-OTFS to use the channel estimate (obtained from detected data
symbols treated as pilots) in the previous instant to detect data in the next
instant and propagate this forward. The advantages are two fold. First, it
allows the data symbols to enjoy higher energy since the energy that would
otherwise be required for pilot symbols can also be allocated to data symbols.
Second, it allows for full spectral efficiency compared to point or embedded
pilots. Comparison with the full spectral efficiency achieving spread pilot
scheme shows that the proposed method achieves better bit-error rate at lower
complexity.

</details>


### [166] [Achieving Robust Channel Estimation Neural Networks by Designed Training Data](https://arxiv.org/abs/2507.12630)
*Dianxin Luan,John Thompson*

Main category: eess.SP

TL;DR: 为了解决神经网络在未知无线信道上泛化能力差的问题，本研究提出了设计标准和基准设计，用于训练能够稳健处理时变信道的神经网络，无需在线训练。结果表明，该方法能有效提高神经网络的泛化能力，且不依赖于网络架构。


<details>
  <summary>Details</summary>
Motivation: 现有的数据驱动方法在未知的或新的信道数据上表现不佳，而实际信道通常是时变的。然而，由于低延迟和计算资源的限制，神经网络无法进行在线训练来调整参数。因此，需要设计无需实际信道信息即可稳健运行的离线训练神经网络。

Method: 提出设计标准以生成合成训练数据集，并基于此提出基准设计，以训练能够稳健处理无线信道的神经网络。

Result: 神经网络实现了对具有固定信道模型和可变延迟扩展的无线信道的稳健泛化，且泛化能力与神经网络的架构复杂度无关。

Conclusion: 该研究提出的设计标准和基准设计能够使神经网络在未知和时变的无线信道上实现稳健的泛化，而无需进行在线训练或参数更新。

Abstract: Channel estimation is crucial in cognitive communications, as it enables
intelligent spectrum sensing and adaptive transmission by providing accurate
information about the current channel state. However, in many papers neural
networks are frequently tested by training and testing on one example channel
or similar channels. This is because data-driven methods often degrade on new
data which they are not trained on, as they cannot extrapolate their training
knowledge. This is despite the fact physical channels are often assumed to be
time-variant. However, due to the low latency requirements and limited
computing resources, neural networks may not have enough time and computing
resources to execute online training to fine-tune the parameters. This
motivates us to design offline-trained neural networks that can perform
robustly over wireless channels, but without any actual channel information
being known at design time. In this paper, we propose design criteria to
generate synthetic training datasets for neural networks, which guarantee that
after training the resulting networks achieve a certain mean squared error
(MSE) on new and previously unseen channels. Therefore, neural network
solutions require no prior channel information or parameters update for
real-world implementations. Based on the proposed design criteria, we further
propose a benchmark design which ensures intelligent operation for different
channel profiles. To demonstrate general applicability, we use neural networks
with different levels of complexity to show that the generalization achieved
appears to be independent of neural network architecture. From simulations,
neural networks achieve robust generalization to wireless channels with both
fixed channel profiles and variable delay spreads.

</details>


### [167] [A Novel Data Augmentation Strategy for Robust Deep Learning Classification of Biomedical Time-Series Data: Application to ECG and EEG Analysis](https://arxiv.org/abs/2507.12645)
*Mohammed Guhdar,Ramadhan J. Mstafa,Abdulhakeem O. Mohammed*

Main category: eess.SP

TL;DR: 提出了一种新颖的、统一的深度学习框架，该框架集成了基于ResNet的CNN和注意力机制，并通过一种新的数据增强策略来生成更丰富的表示，解决了不同生理信号处理和类别不平衡的问题。


<details>
  <summary>Details</summary>
Motivation: 为了有效处理和提取不同生理信号的特征，并解决生物医学数据集中的类别不平衡问题。

Method: 提出了一种新颖的、统一的深度学习框架，该框架集成了基于ResNet的CNN和注意力机制，并通过一种新的数据增强策略（时间域连接多个增强信号变体）来生成更丰富的表示。

Result: 在UCI癫痫EEG、MIT-BIH心律失常和PTB诊断ECG三个基准数据集上分别实现了99.96%、99.78%和100%的准确率。

Conclusion: 该框架在不同信号类型和临床环境中都表现出稳健性，并且内存占用和处理时间表明其适用于低端或可穿戴设备。

Abstract: The increasing need for accurate and unified analysis of diverse biological
signals, such as ECG and EEG, is paramount for comprehensive patient
assessment, especially in synchronous monitoring. Despite advances in
multi-sensor fusion, a critical gap remains in developing unified architectures
that effectively process and extract features from fundamentally different
physiological signals. Another challenge is the inherent class imbalance in
many biomedical datasets, often causing biased performance in traditional
methods. This study addresses these issues by proposing a novel and unified
deep learning framework that achieves state-of-the-art performance across
different signal types. Our method integrates a ResNet-based CNN with an
attention mechanism, enhanced by a novel data augmentation strategy:
time-domain concatenation of multiple augmented variants of each signal to
generate richer representations. Unlike prior work, we scientifically increase
signal complexity to achieve future-reaching capabilities, which resulted in
the best predictions compared to the state of the art. Preprocessing steps
included wavelet denoising, baseline removal, and standardization. Class
imbalance was effectively managed through the combined use of this advanced
data augmentation and the Focal Loss function. Regularization techniques were
applied during training to ensure generalization. We rigorously evaluated the
proposed architecture on three benchmark datasets: UCI Seizure EEG, MIT-BIH
Arrhythmia, and PTB Diagnostic ECG. It achieved accuracies of 99.96%, 99.78%,
and 100%, respectively, demonstrating robustness across diverse signal types
and clinical contexts. Finally, the architecture requires ~130 MB of memory and
processes each sample in ~10 ms, suggesting suitability for deployment on
low-end or wearable devices.

</details>


### [168] [Enhancing Urban GNSS Positioning Reliability via Conservative Satellite Selection Using Unanimous Voting Across Multiple Machine Learning Classifiers](https://arxiv.org/abs/2507.12706)
*Sanghyun Kim,Jiwon Seo*

Main category: eess.SP

TL;DR: 本研究提出了一种改进的城市GNSS定位方法，通过使用多重机器学习分类器进行共识投票来选择卫星，提高了定位的成功率和可靠性。


<details>
  <summary>Details</summary>
Motivation: 城市环境中GNSS信号易受建筑物遮挡和多路径效应影响，导致显著的定位误差。本研究旨在通过增强ZSM定位方法来解决这一问题。

Method: 提出一种基于共识投票和多重机器学习分类器（随机森林RF、梯度提升决策树GBDT、支持向量机SVM）的区域影生成匹配（ZSM）定位增强方法。通过训练分类器进行视线（LOS）和非视线（NLOS）信号分类，并设置置信度阈值，仅当所有分类器在分类及其置信度上达成一致时才选择卫星进行定位。

Result: 实验结果表明，所提出的方法显著提高了定位成功率和接收器包容率，即使在LOS/NLOS分类不完美的情况下也是如此。与未改进的方法相比，定位可靠性得到了实质性提高。

Conclusion: 所提出的基于共识投票和多重机器学习分类器的区域影生成匹配（ZSM）定位方法，能够有效提高城市GNSS环境下的定位成功率和接收器包容率，尽管卫星数量减少导致位置边界略有增加，但整体定位可靠性得到显著增强。

Abstract: In urban environments, global navigation satellite system (GNSS) positioning
is often compromised by signal blockages and multipath effects caused by
buildings, leading to significant positioning errors. To address this issue,
this study proposes a robust enhancement of zonotope shadow matching
(ZSM)-based positioning by employing a conservative satellite selection
strategy using unanimous voting across multiple machine learning classifiers.
Three distinct models - random forest (RF), gradient boosting decision tree
(GBDT), and support vector machine (SVM) - were trained to perform
line-of-sight (LOS) and non-line-of-sight (NLOS) classification based on global
positioning system (GPS) signal features. A satellite is selected for
positioning only when all classifiers unanimously agree on its classification
and their associated confidence scores exceed a threshold. Experiments with
real-world GPS data collected in dense urban areas demonstrate that the
proposed method significantly improves the positioning success rate and the
receiver containment rate, even with imperfect LOS/NLOS classification.
Although a slight increase in the position bound was observed due to the
reduced number of satellites used, overall positioning reliability was
substantially enhanced, indicating the effectiveness of the proposed approach
in urban GNSS environments.

</details>


### [169] [Beamforming Tradeoff for Sensing and Communication in Cell-Free MIMO](https://arxiv.org/abs/2507.12917)
*Xi Ding,Luca Kunz,E. Jorswieck*

Main category: eess.SP

TL;DR: 提出了一种基于SDR的JSAC优化框架，该框架可保证全局最优解，无需后处理，并引入了一种独立的BF策略作为基准。


<details>
  <summary>Details</summary>
Motivation: 本论文研究了小型蜂窝小区（CF-MIMO）系统中联合感知和通信（JSAC）的最优联合波束成形（BF）。先前的研究虽然探索了使用诸如连续凸近似（SCA）和半definit放松（SDR）等方法进行JSAC优化，但这些方法要么缺乏全局最优性，要么需要额外的秩缩减步骤。

Method: 提出了一种基于半definit放松（SDR）的优化框架，该框架保证了全局最优解，无需后处理。

Result: 为了基准测试其性能，我们引入了一种独立的波束成形策略，该策略将每个接入点（AP）专门用于通信或传感。

Conclusion: 该框架提供了一个全局最优且计算高效的波束成形设计，为下一代无线网络的发展提供了宝贵的见解。

Abstract: This paper studies optimal joint beamforming (BF) for joint sensing and
communication (JSAC) in small-scale cell-free MIMO (CF-MIMO) systems. While
prior works have explored JSAC optimization using methods such as successive
convex approximation (SCA) and semidefinite relaxation (SDR), many of these
approaches either lack global optimality or require additional rank-reduction
steps. In contrast, we propose an SDR-based optimization framework that
guarantees globally optimal solutions without post-processing. To benchmark its
performance, we introduce a standalone BF strategy that dedicates each access
point (AP) exclusively to either communication or sensing. The proposed
formulation builds upon a general multi-user system model, enabling future
extensions beyond the single-user setting. Overall, our framework offers a
globally optimal and computationally efficient BF design, providing valuable
insights for the development of next-generation wireless networks.

</details>


### [170] [Multiple-Mode Affine Frequency Division Multiplexing with Index Modulation](https://arxiv.org/abs/2507.13037)
*Guangyao Liu,Tianqi Mao,Yanqun Tang,Jingjing Zhao,Zhenyu Xiao*

Main category: eess.SP

TL;DR: MM-AFDM-IM是一种用于AFDM的新型索引调制方案，可提高频谱和能量效率。


<details>
  <summary>Details</summary>
Motivation: 为了提高AFDM在高速移动通信场景下的频谱和能量效率。

Method: 提出了一种新的多模式索引调制方案MM-AFDM-IM，该方案针对AFDM进行了优化。该方案利用了多星座字母和动态的星座模式选择和चिरप激活模式。推导了在最大似然检测下比特错误率的渐近上界。

Result: MM-AFDM-IM方案的性能优于传统基准方案。

Conclusion: MM-AFDM-IM在符号错误率方面优于传统基准方案。

Abstract: Affine frequency division multiplexing (AFDM), a promising multicarrier
technique utilizing chirp signals, has been envisioned as an effective solution
for high-mobility communication scenarios. In this paper, we develop a
multiple-mode index modulation scheme tailored for AFDM, termed as MM-AFDM-IM,
which aims to further improve the spectral and energy efficiencies of AFDM.
Specifically, multiple constellation alphabets are selected for different
chirp-based subcarriers (chirps). Aside from classical amplitude/phase
modulation, additional information bits can be conveyed by the dynamic patterns
of both constellation mode selection and chirp activation, without extra energy
consumption. Furthermore, we discuss the mode selection strategy and derive an
asymptotically tight upper bound on the bit error rate (BER) of the proposed
scheme under maximum-likelihood detection. Simulation results are provided to
demonstrate the superior performance of MM-AFDM-IM compared to conventional
benchmark schemes.

</details>


### [171] [Unmodulated Visible Light Positioning: A Deep Dive into Techniques, Studies, and Future Prospects](https://arxiv.org/abs/2507.13080)
*Morteza Alijani,Wout Joseph,David Plets*

Main category: eess.SP

TL;DR: uVLP利用未调制的LED，提供低成本、高精度的室内定位，克服了传统VLP的缺点。本文分析了uVLP的原理、方法和挑战，并指出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统可见光定位（VLP）虽然精度高，但调制LED会增加成本和复杂性，并降低照明效率。为了解决这些限制，uVLP应运而生，它利用未调制的照明源（如普通LED）发出的光信号，提供了一种经济高效、低基础设施的室内定位替代方案。

Method: 本文首先阐述了uVLP的基本原理，然后将uVLP与传统VLP方法进行了比较分析，并根据接收器技术将现有uVLP技术分为基于强度的方法和基于成像的方法。此外，提出了一种将uVLP技术分为解复用和非解复用方法的分类法。

Result: 对uVLP的现有进展进行了批判性审查，讨论了当前面临的挑战，并提出了有希望的研究方向，为开发健壮、可扩展和广泛可部署的uVLP解决方案奠定了基础。

Conclusion: uVLP通过利用未调制的LED发出的光信号，克服了传统VLP的成本和复杂性障碍，有望实现高效、低成本的室内定位。

Abstract: Visible Light Positioning (VLP) has emerged as a promising technology for
next-generation indoor positioning systems (IPS), particularly within the scope
of sixth-generation (6G) wireless networks. Its attractiveness stems from
leveraging existing lighting infrastructures equipped with light-emitting
diodes (LEDs), enabling cost-efficient deployments and achieving high-precision
positioning accuracy in the centimeter-todecimeter range. However, widespread
adoption of traditional VLP solutions faces significant barriers due to the
increased costs and operational complexity associated with modulating LEDs,
which consequently reduces illumination efficiency by lowering their radiant
flux. To address these limitations, recent research has introduced the concept
of unmodulated Visible Light Positioning (uVLP), which exploits Light Signals
of Opportunity (LSOOP) emitted by unmodulated illumination sources such as
conventional LEDs. This paradigm offers a cost-effective, lowinfrastructure
alternative for indoor positioning by eliminating the need for modulation
hardware and maintaining lighting efficiency. This paper delineates the
fundamental principles of uVLP, provides a comparative analysis of uVLP versus
conventional VLP methods, and classifies existing uVLP techniques according to
receiver technologies into intensity-based methods (e.g., photodiodes, solar
cells, etc.) and imaging-based methods. Additionally, we propose a
comprehensive taxonomy categorizing techniques into demultiplexed and
undemultiplexed approaches. Within this structured framework, we critically
review current advancements in uVLP, discuss prevailing challenges, and outline
promising research directions essential for developing robust, scalable, and
widely deployable uVLP solutions.

</details>


### [172] [Angle Estimation of a Single Source with Massive Uniform Circular Arrays](https://arxiv.org/abs/2507.13086)
*Mingyan Gong*

Main category: eess.SP

TL;DR: 一种用于大规模UCA的简单二维DOA估计方法，通过角度量化和协方差比较来估计方位角和俯仰角，计算简单且适用于实时处理。


<details>
  <summary>Details</summary>
Motivation: 宽波束均匀线性阵列（ULA）只能提供声源方位角估计，而均匀圆形阵列（UCA）可以提供360°方位角覆盖和额外的俯仰角信息。

Method: 提出了一种基于角度量化的简单二维DOA估计方法。首先通过计算和比较协方差来获得量化的方位角估计，然后利用显式公式获得俯仰角估计。

Result: 数值结果表明，该方法能够获得方位角和俯仰角估计，且该估计可作为多维搜索的初始值，以提高精度。

Conclusion: 该方法可以同时估计方位角和俯仰角，并且估计值可作为多维搜索的初始值，适用于实时信号处理，即使在非均匀噪声下也能工作。

Abstract: Estimating the directions of arrival (DOAs) of incoming plane waves is an
essential topic in array signal processing. Widely adopted uniform linear
arrays can only provide estimates of source azimuth. Thus, uniform circular
arrays (UCAs) are attractive in that they can provide $360^{\circ}$ azimuthal
coverage and additional elevation angle information. Considering that with a
massive UCA, its polar angles of array sensors can approximately represent
azimuth angles over $360^{\circ}$ using angle quantization, a simple
two-dimensional DOA estimation method for a single source is proposed. In this
method, the quantized azimuth angle estimate is obtained by only calculating
and comparing a number of covariances, based on which the elevation angle
estimate is then obtained by an explicit formula. Thus, the proposed method is
computationally simple and suitable for real-time signal processing. Numerical
results verify that the proposed method can obtain azimuth as well as elevation
angle estimates and the estimates can be used as starting points of
multidimensional searches for methods with higher accuracy. Additionally, the
proposed method can still work in the presence of nonuniform noise.

</details>


### [173] [Multifrequency system model for multiport time-modulated scatterers](https://arxiv.org/abs/2507.13130)
*Aleksandr D. Kuznetsov,Jari Holopainen,Ville Viikari*

Main category: eess.SP

TL;DR: 提出了一种新的S参数多端口模型，用于精确预测多频和时空调制散射体的性能。


<details>
  <summary>Details</summary>
Motivation: 需要一种能够同时捕获跨越多个频率和方向的散射行为的先进建模方法，以满足通信工程中具有多频操作或产生互调谐波（尤其是在结合了时空调制或动态负载控制时）的系统需求。

Method: 提出了一种基于S参数的多端口模型，用于预测多频操作结构的散射特性，并将其扩展到时空调制多端口结构。

Result: 该模型能够精确分析和优化广泛的通信和传感系统，能够同时考虑结构散射、互耦、非数字调制以及非周期配置。

Conclusion: 该模型已通过时空调制散射结构实验结果的验证，证明了其准确性和实际适用性。

Abstract: Utilizing scatterers in communication engineering, such as reconfigurable
intelligent surfaces (RISs) and backscatter systems, requires physically
consistent models for accurate performance prediction. A multiport model, which
also accounts for structural scattering, has been developed for non-periodic
scatterers. However, many emerging systems operate at multiple frequencies or
generate intermodulation harmonics, particularly when incorporating space-time
modulation (STM) or dynamic load control. These functionalities demand advanced
modeling approaches capable of capturing scattering behavior across several
frequencies and directions simultaneously. This article extends a multiport
S-parameters-based model for predicting the scattering properties of
multifrequency operating structures. The model extends the applicability of
convenient S-matrix models to time-modulated multiport structures. Unlike known
approaches, this model incorporates structural scattering, mutual coupling, the
possibility of non-digital modulation, and non-periodic configurations,
enabling precise analysis and optimization for a broad range of communication
and sensing systems. Validation against experimental results for a space-time
modulated scattering structure demonstrates the accuracy and practical
applicability of the proposed model.

</details>


### [174] [Disentangling coincident cell events using deep transfer learning and compressive sensing](https://arxiv.org/abs/2507.13176)
*Moritz Leuthner,Rafael Vorländer,Oliver Hayden*

Main category: eess.SP

TL;DR: "A new hybrid framework using FCN and CS accurately analyzes single cells even when they overlap, improving event recovery and classification accuracy for applications in diagnostics and cell therapy."


<details>
  <summary>Details</summary>
Motivation: "Accurate single-cell analysis is critical for diagnostics, immunomonitoring, and cell therapy, but coincident events can severely compromise signal fidelity. Existing methods struggle to accurately resolve overlapping events, necessitating a new approach."

Method: "A hybrid framework combining a fully convolutional neural network (FCN) with compressive sensing (CS) is used to disentangle overlapping events in one-dimensional sensor data. The FCN is trained on bead-derived datasets and estimates coincident event counts, which are then used by the CS module to reconstruct individual signal components."

Result: "The proposed framework recovers up to 21% more events and improves classification accuracy beyond 97%. It enables precise recovery of single-cell features, including velocity, amplitude, and hydrodynamic diameter. The framework is transparent and clinically interpretable."

Conclusion: "Accurate single-cell analysis is critical for diagnostics, immunomonitoring, and cell therapy, but coincident events can severely compromise signal fidelity. This work presents a hybrid framework combining a fully convolutional neural network (FCN) with compressive sensing (CS) to disentangle overlapping events in one-dimensional sensor data. The framework accurately estimates coincident event counts and reconstructs individual signal components with high fidelity, enabling precise recovery of single-cell features. Benchmarking against conventional algorithms shows superior performance, recovering up to 21% more events and improving classification accuracy beyond 97%. The framework is transparent, clinically interpretable, and compatible with various waveform-generating modalities. This work lays the foundation for next-generation non-optical single-cell sensing platforms."

Abstract: Accurate single-cell analysis is critical for diagnostics, immunomonitoring,
and cell therapy, but coincident events - where multiple cells overlap in a
sensing zone - can severely compromise signal fidelity. We present a hybrid
framework combining a fully convolutional neural network (FCN) with compressive
sensing (CS) to disentangle such overlapping events in one-dimensional sensor
data. The FCN, trained on bead-derived datasets, accurately estimates
coincident event counts and generalizes to immunomagnetically labeled CD4+ and
CD14+ cells in whole blood without retraining. Using this count, the CS module
reconstructs individual signal components with high fidelity, enabling precise
recovery of single-cell features, including velocity, amplitude, and
hydrodynamic diameter. Benchmarking against conventional state-machine
algorithms shows superior performance - recovering up to 21% more events and
improving classification accuracy beyond 97%. Explinability via class
activation maps and parameterized Gaussian template fitting ensures
transparency and clinical interpretability. Demonstrated with magnetic flow
cytometry (MFC), the framework is compatible with other waveform-generating
modalities, including impedance cytometry, nanopore, and resistive pulse
sensing. This work lays the foundation for next-generation non-optical
single-cell sensing platforms that are automated, generalizable, and capable of
resolving overlapping events, broadening the utility of cytometry in
translational medicine and precision diagnostics, e.g. cell-interaction
studies.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [175] [Dependency Pairs for Expected Innermost Runtime Complexity and Strong Almost-Sure Termination of Probabilistic Term Rewriting](https://arxiv.org/abs/2507.12918)
*Jan-Christoph Kassing,Leon Spitzer,Jürgen Giesl*

Main category: cs.LO

TL;DR: 提出了一种新的DP框架，用于分析PTRSs的期望复杂度和证明SAST，并在AProVE中实现和验证。


<details>
  <summary>Details</summary>
Motivation: 填补了概率项重写系统（PTRSs）在自动复杂度分析方面的空白，并为证明其几乎肯定终止提供了新的方法。

Method: 提出了一种新的依赖对（DP）框架，用于分析概率项重写系统（PTRSs）的期望复杂度和证明其在最内层重写下的强几乎肯定终止（SAST）。

Result: 在AProVE工具中实现了该框架，并与现有技术进行了比较，证明了其在证明SAST方面的有效性。

Conclusion: 该框架首次实现了对概率项重写系统（PTRSs）的期望复杂度分析和证明强几乎肯定终止（SAST）。

Abstract: The dependency pair (DP) framework is one of the most powerful techniques for
automatic termination and complexity analysis of term rewrite systems. While
DPs were extended to prove almost-sure termination of probabilistic term
rewrite systems (PTRSs), automatic complexity analysis for PTRSs is largely
unexplored. We introduce the first DP framework for analyzing expected
complexity and for proving positive or strong almost-sure termination (SAST) of
innermost rewriting with PTRSs, i.e., finite expected runtime. We implemented
our framework in the tool AProVE and demonstrate its power compared to existing
techniques for proving SAST.

</details>


### [176] [Cyclic proof theory of positive inductive definitions](https://arxiv.org/abs/2507.13057)
*Gianluca Curzi,Lukas Melgaard*

Main category: cs.LO

TL;DR: This paper shows that cyclic and inductive μPA have the same proof-theoretic strength by translating cyclic proofs into an annotated variant and formalizing the argument within Π12-CA0. It also shows that annotated and plain cyclic proofs for μPA prove the same theorems.


<details>
  <summary>Details</summary>
Motivation: To study cyclic proof systems for μPA, an extension of Peano arithmetic by positive inductive definitions that is arithmetically equivalent to the (impredicative) subsystem of second-order arithmetic Π12-CA0.

Method: Translate cyclic proofs into an annotated variant based on Sprenger and Dam's systems for first-order μ-calculus, formalize this argument within Π12-CA0, leveraging M"{o}llerfeld's conservativity properties, and build on prior work by Curzi and Das on the reverse mathematics of the Knaster-Tarski theorem.

Result: Cyclic and inductive μPA have the same proof-theoretic strength. Annotated and plain cyclic proofs for μPA prove the same theorems despite the stronger validity condition.

Conclusion: cyclic and inductive μPA have the same proof-theoretic strength

Abstract: We study cyclic proof systems for $\mu\mathsf{PA}$, an extension of Peano
arithmetic by positive inductive definitions that is arithmetically equivalent
to the (impredicative) subsystem of second-order arithmetic
$\Pi^1_2$-$\mathsf{CA}_0$ by M\"{o}llefeld. The main result of this paper is
that cyclic and inductive $\mu\mathsf{PA}$ have the same proof-theoretic
strength. First, we translate cyclic proofs into an annotated variant based on
Sprenger and Dam's systems for first-order $\mu$-calculus, whose stronger
validity condition allows for a simpler proof of soundness. We then formalise
this argument within $\Pi^1_2$-$\mathsf{CA}_0$, leveraging M\"{o}llerfeld's
conservativity properties. To this end, we build on prior work by Curzi and Das
on the reverse mathematics of the Knaster-Tarski theorem. As a byproduct of our
proof methods we show that, despite the stronger validity condition, annotated
and "plain" cyclic proofs for $\mu\mathsf{PA}$ prove the same theorems. This
work represents a further step in the non-wellfounded proof-theoretic analysis
of theories of arithmetic via impredicative fragments of second-order
arithmetic, an approach initiated by Simpson's Cyclic Arithmetic, and continued
by Das and Melgaard in the context of arithmetical inductive definitions.

</details>


### [177] [Monotone weak distributive laws over the lifted powerset monad in categories of algebras](https://arxiv.org/abs/2507.13058)
*Quentin Aristote*

Main category: cs.LO

TL;DR: 研究了代数中的模态弱分布律，发现其存在性具有一定的限制。


<details>
  <summary>Details</summary>
Motivation: 注意到集合和紧致豪斯多夫空间中结合两种非确定性层的模态弱分布律之间的相似性。

Method: 研究了集合和紧致豪斯多夫空间之间的关系，并提出了相应的分布律。

Result: 部分成立，但不能推广到其他代数类别；研究了模态弱分布律在幂集函子上的代数类别中存在的条件，并举例说明了其存在性，同时也证明了在许多其他情况下不存在这种情况。

Conclusion: 研究了在代数中的模态弱分布律，并给出了在某些情况下不存在的情况。

Abstract: Noticing the similarity between the monotone weak distributive laws combining
two layers of nondeterminism in sets and in compact Hausdorff spaces, we study
whether the latter law can be obtained automatically as a weak lifting of the
former. This holds partially, but does not generalize to other categories of
algebras: we then characterize when exactly monotone weak distributive laws
over powerset monads in categories of algebras exist, exhibiting a law
combining probabilities and non-determinism in compact Hausdorff spaces and
showing on the other hand that such laws do not exist in a lot of other cases.

</details>


### [178] [Impact and Performance of Randomized Test-Generation using Prolog](https://arxiv.org/abs/2507.13178)
*Marcus Gelderie,Maximilian Luff,Maximilian Peltzer*

Main category: cs.LO

TL;DR: 本文研究了在Prolog中生成测试序列的随机化方法，提出并分析了两种随机化策略的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决大量或无限测试用例集带来的问题，随机化是一种自然的选择。本文研究了随机化与SLD分辨率相结合对测试性能的影响。

Method: 本文提出两种随机化策略，一种基于标准Prolog语义，另一种改变SLD选择函数，并使用马尔可夫链分析了达到测试用例的平均时间和生成的测试用例的平均数量。

Result: 本文分析了两种随机化策略对测试性能的影响，并通过实证评估和比较了这两种方法。

Conclusion: 本文分析了Prolog中随机测试用例生成的性能，并提出两种随机化策略。

Abstract: We study randomized generation of sequences of test-inputs to a system using
Prolog. Prolog is a natural fit to generate test-sequences that have complex
logical inter-dependent structure. To counter the problems posed by a large (or
infinite) set of possible tests, randomization is a natural choice. We study
the impact that randomization in conjunction with SLD resolution have on the
test performance. To this end, this paper proposes two strategies to add
randomization to a test-generating program. One strategy works on top of
standard Prolog semantics, whereas the other alters the SLD selection function.
We analyze the mean time to reach a test-case, and the mean number of generated
test-cases in the framework of Markov chains. Finally, we provide an additional
empirical evaluation and comparison between both approaches. Under
consideration in Theory and Practice of Logic Programming (TPLP).

</details>


### [179] [Just Verification of Mutual Exclusion Algorithms](https://arxiv.org/abs/2507.13198)
*Rob van Glabbeek,Bas Luttik,Myrthe Spronck*

Main category: cs.LO

TL;DR: Verified mutual exclusion algorithms using model checking and justness, finding violations in some and suggesting improvements.


<details>
  <summary>Details</summary>
Motivation: The motivation was to verify the correctness of mutual exclusion algorithms, particularly those using shared read/write registers (atomic or non-atomic), and to address the challenges in verifying liveness properties by using a completeness criterion like justness.

Method: Model checking was used to verify the correctness of mutual exclusion algorithms. Justness, dependent on a concurrency relation, was employed as a completeness criterion for verifying liveness properties. Different concurrency relations were considered to model various assumptions about shared registers.

Result: The analysis demonstrated violations of correctness properties in several algorithms, and potential improvements were suggested.

Conclusion: We verified the correctness of mutual exclusion algorithms using model checking, considering shared read/write registers (atomic and non-atomic). Justness was used as a completeness criterion for liveness properties, with different concurrency relations modeled for shared registers. Counterexamples were presented, and improvements suggested for some algorithms.

Abstract: We verify the correctness of a variety of mutual exclusion algorithms through
model checking. We look at algorithms where communication is via shared
read/write registers, where those registers can be atomic or non-atomic. For
the verification of liveness properties, it is necessary to assume a
completeness criterion to eliminate spurious counterexamples. We use justness
as completeness criterion. Justness depends on a concurrency relation; we
consider several such relations, modelling different assumptions on the working
of the shared registers. We present executions demonstrating the violation of
correctness properties by several algorithms, and in some cases suggest
improvements.

</details>


### [180] [Solving SAT By Computing A Stable Set Of Points In Clusters](https://arxiv.org/abs/2507.13282)
*Eugene Goldberg*

Main category: cs.LO

TL;DR: SSPs for CNF formulas are too large to compute point by point, but can be computed efficiently in clusters for parallel processing and improved SAT algorithms.


<details>
  <summary>Details</summary>
Motivation: Existing SSP computation methods are infeasible due to the large size of SSPs for practical CNF formulas. This work aims to make SSP computation feasible and leverage its benefits.

Method: Computing SSPs in clusters by processing large sets of points simultaneously.

Result: SSPs can be computed efficiently in clusters, enabling parallel processing and offering advantages for SAT algorithm design and parallel computing.

Conclusion: SSPs are feasible to compute in clusters, facilitating parallel computing and potentially leading to more efficient SAT algorithms.

Abstract: Earlier we introduced the notion of a stable set of points (SSP). We proved
that a CNF formula is unsatisfiable iff there is a set of points (i.e. complete
assignments) that is stable with respect to this formula. Experiments showed
that SSPs for CNF formulas of practical interest are very large. So computing
an SSP for a CNF formula point by point is, in general, infeasible. In this
report, we show how an SSP can be computed in clusters, each cluster being a
large set of points that are processed simultaneously. The appeal of computing
SSPs is twofold. First, it allows one to better take into account formula
structure and hence, arguably, design more efficient SAT algorithms. Second,
SAT solving by SSPs facilitates parallel computing.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [181] [Geometric Theory of Ising Machines](https://arxiv.org/abs/2507.12626)
*Andrew G. Moore,Zachary Richey,Isaac K. Martin*

Main category: cs.ET

TL;DR: This paper introduces a diagrammatic tool to analyze Ising circuits, proving they generalize 1-NN classifiers and that eliminating energy landscape local minima is a linear programming problem.


<details>
  <summary>Details</summary>
Motivation: Encoding the output of a function in the ground state of a physical system allows efficient and distributed computation, but the design of the energy function is a difficult puzzle.

Method: We introduce a diagrammatic device that allows us to visualize the decision boundaries for Ising circuits. It is then used to prove two results.

Result: The paper introduces a diagrammatic device for visualizing decision boundaries of Ising circuits, proving two key results about their relationship to 1-NN classifiers and the formulation of local minima elimination as a linear programming problem.

Conclusion: Ising circuits are a generalization of 1-NN classifiers with a certain special structure, and elimination of local minima in the energy landscape can be formulated as a linear programming problem.

Abstract: We contribute to the mathematical theory of the design of low temperature
Ising machines, a type of experimental probabilistic computing device
implementing the Ising model. Encoding the output of a function in the ground
state of a physical system allows efficient and distributed computation, but
the design of the energy function is a difficult puzzle. We introduce a
diagrammatic device that allows us to visualize the decision boundaries for
Ising circuits. It is then used to prove two results: (1) Ising circuits are a
generalization of 1-NN classifiers with a certain special structure, and (2)
Elimination of local minima in the energy landscape can be formulated as a
linear programming problem.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [182] [AI-Powered Math Tutoring: Platform for Personalized and Adaptive Education](https://arxiv.org/abs/2507.12484)
*Jarosław A. Chudziak,Adam Kostka*

Main category: cs.AI

TL;DR: 本研究提出了一种新颖的多智能体AI辅导平台，用于改进数学教育。该平台通过结合个性化反馈、课程生成和知识检索，实现了模块化、工具辅助的学习，解决了当前AI辅导系统反应性强、缺乏深度引导的问题，使学生能够更有效地学习和练习。


<details>
  <summary>Details</summary>
Motivation: 当前的AI辅导系统具有反应性强的局限性，通常直接提供答案，而没有鼓励深入思考或融入结构化的教学工具和策略，尤其是在数学领域。本研究旨在解决如何使AI辅导系统超越被动辅助，实现结构化、个性化和工具辅助的学习体验。

Method: 提出一个新颖的多智能体人工智能辅导平台，该平台结合了适应性和个性化反馈、结构化课程生成和教科书知识检索，以实现模块化、工具辅助的学习过程。

Result: 该平台允许学生在学习新主题的同时，识别和针对自身的薄弱环节，有效复习考试，并进行无限量的个性化练习。

Conclusion: 该研究提出了一个新颖的多智能体人工智能辅导平台，该平台结合了适应性和个性化反馈、结构化课程生成和教科书知识检索，以实现模块化、工具辅助的学习过程，从而改进了数学教育领域人工智能辅导系统的局限性。

Abstract: The growing ubiquity of artificial intelligence (AI), in particular large
language models (LLMs), has profoundly altered the way in which learners gain
knowledge and interact with learning material, with many claiming that AI
positively influences their learning achievements. Despite this advancement,
current AI tutoring systems face limitations associated with their reactive
nature, often providing direct answers without encouraging deep reflection or
incorporating structured pedagogical tools and strategies. This limitation is
most apparent in the field of mathematics, in which AI tutoring systems remain
underdeveloped. This research addresses the question: How can AI tutoring
systems move beyond providing reactive assistance to enable structured,
individualized, and tool-assisted learning experiences? We introduce a novel
multi-agent AI tutoring platform that combines adaptive and personalized
feedback, structured course generation, and textbook knowledge retrieval to
enable modular, tool-assisted learning processes. This system allows students
to learn new topics while identifying and targeting their weaknesses, revise
for exams effectively, and practice on an unlimited number of personalized
exercises. This article contributes to the field of artificial intelligence in
education by introducing a novel platform that brings together pedagogical
agents and AI-driven components, augmenting the field with modular and
effective systems for teaching mathematics.

</details>


### [183] [MR-LDM -- The Merge-Reactive Longitudinal Decision Model: Game Theoretic Human Decision Modeling for Interactive Sim Agents](https://arxiv.org/abs/2507.12494)
*Dustin Holley,Jovin D'sa,Hossein Nourkhiz Mahjoub,Gibran Ali*

Main category: cs.AI

TL;DR: This paper presents an improved game theoretic model for simulating highway merging scenarios in autonomous driving. The model enhances realism by incorporating better payoff functions and lag actions, unified with a dynamics model. It's explainable, reproduces real-world interactions, and is computationally efficient for development.


<details>
  <summary>Details</summary>
Motivation: Enhancing simulation environments to replicate real-world driver behavior, specifically humanlike simulated agents, is crucial for advancing autonomous vehicle technology. Previous studies on highway merging have limitations in their action sets or payoff functions.

Method: This work improves highway merge simulation by targeting a game theoretic model for tactical decision-making, incorporating improved payoff functions and lag actions, and coupling it with an underlying dynamics model for a unified decision and dynamics approach.

Result: The proposed model captured merging interactions and simulated more realistic behaviors in an explainable and interpretable fashion. It showed good reproducibility of complex interactions when validated on a real-world dataset and confirmed adequate computation time efficiency for large-scale simulations.

Conclusion: The proposed model, combining game theory for tactical decision-making with an improved payoff function and lag actions, along with an underlying dynamics model, successfully captures merging interactions and simulates realistic behaviors in an explainable manner. It demonstrated good reproducibility on real-world data and has adequate computational efficiency for large-scale simulations supporting autonomous vehicle development.

Abstract: Enhancing simulation environments to replicate real-world driver behavior,
i.e., more humanlike sim agents, is essential for developing autonomous vehicle
technology. In the context of highway merging, previous works have studied the
operational-level yielding dynamics of lag vehicles in response to a merging
car at highway on-ramps. Other works focusing on tactical decision modeling
generally consider limited action sets or utilize payoff functions with large
parameter sets and limited payoff bounds. In this work, we aim to improve the
simulation of the highway merge scenario by targeting a game theoretic model
for tactical decision-making with improved payoff functions and lag actions. We
couple this with an underlying dynamics model to have a unified decision and
dynamics model that can capture merging interactions and simulate more
realistic interactions in an explainable and interpretable fashion. The
proposed model demonstrated good reproducibility of complex interactions when
validated on a real-world dataset. The model was finally integrated into a high
fidelity simulation environment and confirmed to have adequate computation time
efficiency for use in large-scale simulations to support autonomous vehicle
development.

</details>


### [184] [A Survey of Explainable Reinforcement Learning: Targets, Methods and Needs](https://arxiv.org/abs/2507.12599)
*Léo Saulières*

Main category: cs.AI

TL;DR: This paper reviews the field of eXplainable Reinforcement Learning (XRL) by proposing a taxonomy based on "What" and "How" questions to categorize existing methods and identify future research directions.


<details>
  <summary>Details</summary>
Motivation: To understand the internal mechanisms and explain the output of AI models, especially deep neural networks, 

Method: The paper proposes an intuitive taxonomy based on two questions: 

Result: A state-of-the-art review of over 250 papers in XRL is provided using the proposed taxonomy. The paper also identifies related domains and future needs for the XRL field.

Conclusion: The paper provides a taxonomy for eXplainable Reinforcement Learning (XRL) based on 

Abstract: The success of recent Artificial Intelligence (AI) models has been
accompanied by the opacity of their internal mechanisms, due notably to the use
of deep neural networks. In order to understand these internal mechanisms and
explain the output of these AI models, a set of methods have been proposed,
grouped under the domain of eXplainable AI (XAI). This paper focuses on a
sub-domain of XAI, called eXplainable Reinforcement Learning (XRL), which aims
to explain the actions of an agent that has learned by reinforcement learning.
We propose an intuitive taxonomy based on two questions "What" and "How". The
first question focuses on the target that the method explains, while the second
relates to the way the explanation is provided. We use this taxonomy to provide
a state-of-the-art review of over 250 papers. In addition, we present a set of
domains close to XRL, which we believe should get attention from the community.
Finally, we identify some needs for the field of XRL.

</details>


### [185] [Imitating Mistakes in a Learning Companion AI Agent for Online Peer Learning](https://arxiv.org/abs/2507.12801)
*Sosui Moribe,Taketoshi Ushiama*

Main category: cs.AI

TL;DR: 本研究提出了一种新的人工智能代理，可以作为同伴学习的伴侣，尤其是在英语写作方面。


<details>
  <summary>Details</summary>
Motivation: 由于人类同伴学习存在各种限制，并非总是有效。有效的同伴学习需要水平相当的学习伙伴。

Method: 该研究假设与学习者处于同一熟练度水平的学习者的同伴会犯与学习者相同的错误，并以英语构图为例来验证这一方法。

Result: 以英语构图为例，验证了同伴学习的有效性，并提出了一种新的方法。

Conclusion: 该研究的目标是开发一个人工智能代理作为学习伴侣，以实现随时随地的同伴学习。

Abstract: In recent years, peer learning has gained attention as a method that promotes
spontaneous thinking among learners, and its effectiveness has been confirmed
by numerous studies. This study aims to develop an AI Agent as a learning
companion that enables peer learning anytime and anywhere. However, peer
learning between humans has various limitations, and it is not always
effective. Effective peer learning requires companions at the same proficiency
levels. In this study, we assume that a learner's peers with the same
proficiency level as the learner make the same mistakes as the learner does and
focus on English composition as a specific example to validate this approach.

</details>


### [186] [Fly, Fail, Fix: Iterative Game Repair with Reinforcement Learning and Large Multimodal Models](https://arxiv.org/abs/2507.12666)
*Alex Zook,Josef Spjut,Jonathan Tremblay*

Main category: cs.AI

TL;DR: 本框架使用RL代理玩游戏并生成行为数据，然后让LMM分析这些数据来优化游戏设计，实现了AI辅助游戏设计。


<details>
  <summary>Details</summary>
Motivation: 现代生成系统难以捕捉游戏规则和内容如何转化为玩家行为，因此需要一种能够结合静态代码分析和动态玩家行为理解的自动化设计迭代框架。

Method: 本框架结合了强化学习（RL）代理和大型多模态模型（LMM）。RL代理负责玩游戏并生成数值化的游戏指标和/或图像条，LMM则根据游戏目标和当前配置分析这些信息，并修改配置以引导未来行为。

Result: 大型多模态模型（LMM）能够分析强化学习（RL）代理提供的行为轨迹，并迭代地优化游戏机制。

Conclusion: 该框架展示了大型多模态模型（LMM）能够基于强化学习（RL）代理提供的行为轨迹，通过迭代的方式优化游戏机制，为AI辅助游戏设计提供了实用且可扩展的工具。

Abstract: Game design hinges on understanding how static rules and content translate
into dynamic player behavior - something modern generative systems that inspect
only a game's code or assets struggle to capture. We present an automated
design iteration framework that closes this gap by pairing a reinforcement
learning (RL) agent, which playtests the game, with a large multimodal model
(LMM), which revises the game based on what the agent does. In each loop the RL
player completes several episodes, producing (i) numerical play metrics and/or
(ii) a compact image strip summarising recent video frames. The LMM designer
receives a gameplay goal and the current game configuration, analyses the play
traces, and edits the configuration to steer future behaviour toward the goal.
We demonstrate results that LMMs can reason over behavioral traces supplied by
RL agents to iteratively refine game mechanics, pointing toward practical,
scalable tools for AI-assisted game design.

</details>


### [187] [Benchmarking Deception Probes via Black-to-White Performance Boosts](https://arxiv.org/abs/2507.12691)
*Avi Parrack,Carlo Leonardo Attubato,Stefan Heimersheim*

Main category: cs.AI

TL;DR: AI助手可能撒谎。研究人员尝试通过检查模型内部活动来检测AI助手是否在撒谎。他们发现，在某些情况下，他们可以检测到AI助手是否在撒谎，但并不总是有效。


<details>
  <summary>Details</summary>
Motivation: 为了评估AI助手欺骗探测器的实际效果，并研究其是否能抵抗欺骗助手为逃避检测而采取的简单策略。

Method: 本研究将白盒监控（监控器可以访问 token 级别的探测器激活）与黑盒监控（监控器无法访问这些信息）进行了比较。通过评估黑盒监控相对于白盒监控的性能提升（即黑盒到白盒的性能提升），来衡量欺骗探测器的有效性。

Result: 研究结果表明，现有的欺骗探测器在检测AI助手欺骗行为方面，黑盒到白盒的性能提升较弱，但仍具有一定的潜力。

Conclusion: AI助手偶尔会对用户查询做出欺骗性回应。本研究通过比较白盒监控和黑盒监控的有效性，发现现有的欺骗探测器在检测AI助手欺骗行为方面存在一些局限性，但存在一定的改进空间。

Abstract: AI assistants will occasionally respond deceptively to user queries.
Recently, linear classifiers (called "deception probes") have been trained to
distinguish the internal activations of a language model during deceptive
versus honest responses. However, it's unclear how effective these probes are
at detecting deception in practice, nor whether such probes are resistant to
simple counter strategies from a deceptive assistant who wishes to evade
detection. In this paper, we compare white-box monitoring (where the monitor
has access to token-level probe activations) to black-box monitoring (without
such access). We benchmark deception probes by the extent to which the white
box monitor outperforms the black-box monitor, i.e. the black-to-white
performance boost. We find weak but encouraging black-to-white performance
boosts from existing deception probes.

</details>


### [188] [A Translation of Probabilistic Event Calculus into Markov Decision Processes](https://arxiv.org/abs/2507.12989)
*Lyris Xu,Fabio Aurelio D'Asaro,Luke Dickens*

Main category: cs.AI

TL;DR: 将概率事件演算（PEC）与马尔可夫决策过程（MDP）相结合，实现了可解释的规划。


<details>
  <summary>Details</summary>
Motivation: 解决PEC在目标导向推理方面的不足，并利用MDP的算法和理论工具来增强PEC的能力。

Method: 将PEC域形式化为MDP，引入“情境”概念以保留PEC的灵活动作语义。

Result: 实现了PEC的规划能力，能够进行时间推理和目标驱动的规划，并将学习到的策略映射回人类可读的PEC表示。

Conclusion: 该研究通过将PEC域形式化为MDP，实现了PEC的分析和规划能力，同时保持了其可解释性。

Abstract: Probabilistic Event Calculus (PEC) is a logical framework for reasoning about
actions and their effects in uncertain environments, which enables the
representation of probabilistic narratives and computation of temporal
projections. The PEC formalism offers significant advantages in
interpretability and expressiveness for narrative reasoning. However, it lacks
mechanisms for goal-directed reasoning. This paper bridges this gap by
developing a formal translation of PEC domains into Markov Decision Processes
(MDPs), introducing the concept of "action-taking situations" to preserve PEC's
flexible action semantics. The resulting PEC-MDP formalism enables the
extensive collection of algorithms and theoretical tools developed for MDPs to
be applied to PEC's interpretable narrative domains. We demonstrate how the
translation supports both temporal reasoning tasks and objective-driven
planning, with methods for mapping learned policies back into human-readable
PEC representations, maintaining interpretability while extending PEC's
capabilities.

</details>


### [189] [MCPEval: Automatic MCP-based Deep Evaluation for AI Agent Models](https://arxiv.org/abs/2507.12806)
*Zhiwei Liu,Jielin Qiu,Shiyu Wang,Jianguo Zhang,Zuxin Liu,Roshan Ram,Haolin Chen,Weiran Yao,Huan Wang,Shelby Heinecke,Silvio Savarese,Caiming Xiong*

Main category: cs.AI

TL;DR: MCPEval是一个自动化的LLM代理评估框架，能够处理跨领域任务生成和深度评估，并提供标准化的指标和工具集成。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM代理评估方法依赖于静态基准测试和劳动密集型数据收集，这限制了其实际评估能力。因此，需要一个强大、可扩展的评估框架。

Method: MCPEval框架通过自动化任务生成和集成原生代理工具，消除了构建评估管线的用户手动工作，并标准化了评估指标。

Result: 在五个真实世界的领域进行评估，结果表明MCPEval在揭示细微的、特定领域的性能方面是有效的。

Conclusion: MCPEval是一个开源的、基于模型上下文协议（MCP）的框架，能够自动化端到端任务生成和LLM代理的深度评估，并在实际应用中展现了其有效性，促进了可复现和标准化的LLM代理评估。

Abstract: The rapid rise of Large Language Models (LLMs)-based intelligent agents
underscores the need for robust, scalable evaluation frameworks. Existing
methods rely on static benchmarks and labor-intensive data collection, limiting
practical assessment. We introduce \oursystemname, an open-source Model Context
Protocol (MCP)-based framework that automates end-to-end task generation and
deep evaluation of LLM agents across diverse domains. MCPEval standardizes
metrics, seamlessly integrates with native agent tools, and eliminates manual
effort in building evaluation pipelines. Empirical results across five
real-world domains show its effectiveness in revealing nuanced, domain-specific
performance. We publicly release MCPEval
https://github.com/SalesforceAIResearch/MCPEval to promote reproducible and
standardized LLM agent evaluation.

</details>


### [190] [Higher-Order Pattern Unification Modulo Similarity Relations](https://arxiv.org/abs/2507.13208)
*Besik Dundua,Temur Kutsia*

Main category: cs.AI

TL;DR: 该论文提出了一种用于高阶模式匹配模糊相似性关系的统一算法，该算法结合了高阶模式和模糊逻辑，能够计算出最高近似度的一般化统一符。


<details>
  <summary>Details</summary>
Motivation: 为了解决涉及抽象函数和谓词的推理决策任务中，精确匹配稀少或不必要的问题，研究旨在整合高阶模式和模糊逻辑，以提高推理和计算效率。

Method: 提出了一种统一算法，该算法结合了高阶模式和基于最小T-范数的模糊等价性（通过相似性关系表示），用于高阶模式在模糊相似性关系下的匹配。

Result: 该算法被证明是单元的，并且在给定项可统一的情况下，能够计算出具有最高近似度的一般化统一符。

Conclusion: 该研究提出了一种用于高阶模式匹配模糊相似性关系的统一算法，并证明了其终止性、健全性和完备性。该算法在模糊匹配时能够计算出具有最高近似度的一般化统一符。

Abstract: The combination of higher-order theories and fuzzy logic can be useful in
decision-making tasks that involve reasoning across abstract functions and
predicates, where exact matches are often rare or unnecessary. Developing
efficient reasoning and computational techniques for such a combined formalism
presents a significant challenge. In this paper, we adopt a more
straightforward approach aiming at integrating two well-established and
computationally well-behaved components: higher-order patterns on one side and
fuzzy equivalences expressed through similarity relations based on minimum
T-norm on the other. We propose a unification algorithm for higher-order
patterns modulo these similarity relations and prove its termination,
soundness, and completeness. This unification problem, like its crisp
counterpart, is unitary. The algorithm computes a most general unifier with the
highest degree of approximation when the given terms are unifiable.

</details>


### [191] [Emotional Support with LLM-based Empathetic Dialogue Generation](https://arxiv.org/abs/2507.12820)
*Shiquan Wang,Ruiyu Fang,Zhongjiang He,Shuangyong Song,Yongxiang Li*

Main category: cs.AI

TL;DR: 本研究提出了一种结合LLMs、提示工程和微调（LoRA/全参数）的ESC解决方案，在NLPCC 2025竞赛中获得第二名。


<details>
  <summary>Details</summary>
Motivation: 随着对心理健康支持需求的增长，情感支持对话（ESC）旨在通过对话提供共情和有效的اd情感援助。

Method: 本研究提出了一种利用大型语言模型，并通过提示工程和微调技术（包括低秩适应（LoRA）和全参数微调）来增强模型能力，以生成有同情心和符合上下文的情感支持对话的解决方案。

Result: 在NLPCC 2025任务8 ESC评估中，本研究的最佳模型取得了第二名的成绩，证明了LLMs与有效适应方法结合在ESC任务中的潜力。

Conclusion: 该研究展示了结合大型语言模型（LLMs）与有效的适应方法（如LoRA和全参数微调）在情感支持对话（ESC）任务中的潜力，其最佳模型在NLPCC 2025任务8中获得第二名。

Abstract: Emotional Support Conversation (ESC) aims to provide empathetic and effective
emotional assistance through dialogue, addressing the growing demand for mental
health support. This paper presents our solution for the NLPCC 2025 Task 8 ESC
evaluation, where we leverage large-scale language models enhanced by prompt
engineering and finetuning techniques. We explore both parameter-efficient
Low-Rank Adaptation and full-parameter fine-tuning strategies to improve the
model's ability to generate supportive and contextually appropriate responses.
Our best model ranked second in the competition, highlighting the potential of
combining LLMs with effective adaptation methods for ESC tasks. Future work
will focus on further enhancing emotional understanding and response
personalization to build more practical and reliable emotional support systems.

</details>


### [192] [Assessing adaptive world models in machines with novel games](https://arxiv.org/abs/2507.12821)
*Lance Ying,Katherine M. Collins,Prafull Sharma,Cedric Colas,Kaiya Ivy Zhao,Adrian Weller,Zenna Tavares,Phillip Isola,Samuel J. Gershman,Jacob D. Andreas,Thomas L. Griffiths,Francois Chollet,Kelsey R. Allen,Joshua B. Tenenbaum*

Main category: cs.AI

TL;DR: 人类智能能够快速适应和解决新颖情境下的问题，这得益于高效的内部表征（世界模型）的构建和优化。我们认为，AI在世界模型方面的评估过于侧重静态表征，而忽略了通过交互和探索学习表征的效率。为此，我们借鉴认知科学的见解，提出一种新颖的游戏化评估框架，旨在衡量AI快速归纳世界模型的能力，以期推动更接近人类水平的适应性和泛化能力的AI发展。


<details>
  <summary>Details</summary>
Motivation: 当前对人工智能（AI）中世界模型的理解和评估仍然狭隘，通常侧重于从大量数据语料库的训练中学习到的静态表示，而不是在与新环境的交互和探索中学习这些表示的效率和效果。

Method: 借鉴认知科学中关于人类如何高效学习和适应的几十年研究，提出一个世界模型归纳的视角，并提出一个新的基准测试范式。

Result: 提出了一种基于“新颖游戏”的基准测试范式，并详细介绍了构建这些游戏的关键要求和适当的评估指标，以挑战和评估智能体快速进行世界模型归纳的能力。

Conclusion: 我们需要一个新的评估框架来评估AI中的适应性世界模型，该框架基于精心设计的、具有持续更新的新颖性的游戏。

Abstract: Human intelligence exhibits a remarkable capacity for rapid adaptation and
effective problem-solving in novel and unfamiliar contexts. We argue that this
profound adaptability is fundamentally linked to the efficient construction and
refinement of internal representations of the environment, commonly referred to
as world models, and we refer to this adaptation mechanism as world model
induction. However, current understanding and evaluation of world models in
artificial intelligence (AI) remains narrow, often focusing on static
representations learned from training on a massive corpora of data, instead of
the efficiency and efficacy of models in learning these representations through
interaction and exploration within a novel environment. In this Perspective, we
provide a view of world model induction drawing on decades of research in
cognitive science on how humans learn and adapt so efficiently; we then call
for a new evaluation framework for assessing adaptive world models in AI.
Concretely, we propose a new benchmarking paradigm based on suites of carefully
designed games with genuine, deep and continually refreshing novelty in the
underlying game structures -- we refer to this kind of games as novel games. We
detail key desiderata for constructing these games and propose appropriate
metrics to explicitly challenge and evaluate the agent's ability for rapid
world model induction. We hope that this new evaluation framework will inspire
future evaluation efforts on world models in AI and provide a crucial step
towards developing AI systems capable of the human-like rapid adaptation and
robust generalization -- a critical component of artificial general
intelligence.

</details>


### [193] [Information-Theoretic Aggregation of Ethical Attributes in Simulated-Command](https://arxiv.org/abs/2507.12862)
*Hussein Abbass,Taylan Akay,Harrison Tolley*

Main category: cs.AI

TL;DR: 本研究提出了一种在AI模拟中，通过动态调整道德属性权重来辅助人类指挥官进行决策的方法，解决了人工判断在大量场景模拟中的效率和可行性问题。


<details>
  <summary>Details</summary>
Motivation: 在人工智能时代，人类指挥官需要利用计算能力模拟大量场景，但在此过程中，不同决策选项可能涉及道德伦理问题。将决策权完全交由人工判断会影响效率，并且工作量巨大。因此，有必要将人工判断移出模拟决策周期。

Method: 该研究借鉴了多准则决策制定文献中利用熵来确定权重的方法，提出在模拟测试和评估期间自动计算道德属性权重的不同方法。

Result: 该研究旨在解决在生成式模拟中，当代理面临具有道德含义的决策选项时，如何动态加权道德属性这一核心问题。通过在模拟过程中自动计算权重，系统可以在模拟完成后向人类指挥官提供经过筛选的选项，从而更有效地结合人类判断。

Conclusion: 该研究提出了一种在生成式模拟中动态加权道德属性的方法，以解决在模拟大量场景时，人工判断在决策周期中的不可行性问题。研究人员将人工判断移出模拟决策周期，由人类设计道德指标空间，然后由模拟环境探索该空间。模拟完成后，系统将向人类指挥官提供几个选项供其选择。

Abstract: In the age of AI, human commanders need to use the computational powers
available in today's environment to simulate a very large number of scenarios.
Within each scenario, situations occur where different decision design options
could have ethical consequences. Making these decisions reliant on human
judgement is both counter-productive to the aim of exploring very large number
of scenarios in a timely manner and infeasible when considering the workload
needed to involve humans in each of these choices. In this paper, we move human
judgement outside the simulation decision cycle. Basically, the human will
design the ethical metric space, leaving it to the simulated environment to
explore the space. When the simulation completes its testing cycles, the
testing environment will come back to the human commander with a few options to
select from. The human commander will then exercise human-judgement to select
the most appropriate course of action, which will then get executed
accordingly. We assume that the problem of designing metrics that are
sufficiently granular to assess the ethical implications of decisions is
solved. Subsequently, the fundamental problem we look at in this paper is how
to weight ethical decisions during the running of these simulations; that is,
how to dynamically weight the ethical attributes when agents are faced with
decision options with ethical implications during generative simulations. The
multi-criteria decision making literature has started to look at nearby
problems, where the concept of entropy has been used to determine the weights
during aggregation. We draw from that literature different approaches to
automatically calculate the weights for ethical attributes during
simulation-based testing and evaluation.

</details>


### [194] [Manipulation Attacks by Misaligned AI: Risk Analysis and Safety Case Framework](https://arxiv.org/abs/2507.12872)
*Rishane Dassanayake,Mario Demetroudi,James Walpole,Lindley Lentati,Jason R. Brown,Edward James Young*

Main category: cs.AI

TL;DR: AI的操纵能力是一个日益增长的威胁，本研究提出了一个用于评估和缓解此类风险的系统性安全案例框架。


<details>
  <summary>Details</summary>
Motivation: 鉴于AI系统在说服、欺骗和影响人类行为方面的能力日益增强，以及内部部署的AI可能通过操纵员工来破坏人类监督的潜在威胁，而现有研究对操纵攻击的关注不足，缺乏系统性的评估和缓解框架。

Method: 提出一个安全案例框架来应对操纵风险，该框架围绕三个核心论点构建：无能、控制和可信度。针对每个论点，论文明确了证据需求、评估方法和实施考量，供AI公司直接应用。

Result: 提供了一个详细的解释，说明操纵攻击为何构成重大威胁并可能导致灾难性后果，并提出了一个围绕无能、控制和可信度三个核心论点的操纵风险安全案例框架。

Conclusion: 本篇论文首次提出了一个系统性的方法来整合操纵风险到AI安全治理中，为AI公司提供了一个在部署前评估和缓解这些威胁的具体基础。

Abstract: Frontier AI systems are rapidly advancing in their capabilities to persuade,
deceive, and influence human behaviour, with current models already
demonstrating human-level persuasion and strategic deception in specific
contexts. Humans are often the weakest link in cybersecurity systems, and a
misaligned AI system deployed internally within a frontier company may seek to
undermine human oversight by manipulating employees. Despite this growing
threat, manipulation attacks have received little attention, and no systematic
framework exists for assessing and mitigating these risks. To address this, we
provide a detailed explanation of why manipulation attacks are a significant
threat and could lead to catastrophic outcomes. Additionally, we present a
safety case framework for manipulation risk, structured around three core lines
of argument: inability, control, and trustworthiness. For each argument, we
specify evidence requirements, evaluation methodologies, and implementation
considerations for direct application by AI companies. This paper provides the
first systematic methodology for integrating manipulation risk into AI safety
governance, offering AI companies a concrete foundation to assess and mitigate
these threats before deployment.

</details>


### [195] [VAR-MATH: Probing True Mathematical Reasoning in Large Language Models via Symbolic Multi-Instance Benchmarks](https://arxiv.org/abs/2507.12885)
*Jian Yao,Ran Cheng,Kay Chen Tan*

Main category: cs.AI

TL;DR: 评估范式和基准测试的局限性促使我们开发VAR-MATH，一个旨在衡量数学推理的鲁棒性和泛化能力的符号评估框架。在VAR-MATH下，在强化学习方法上训练的模型性能显著下降，这表明它们主要依赖于过拟合的模式而不是真正的推理能力。


<details>
  <summary>Details</summary>
Motivation: 然而，即使在用错误的信号（例如随机或反向奖励）训练模型时，这些改进也常常得以保留，这就提出了一个根本性问题：这些改进是否反映了真正的推理，还是仅仅是过拟合到特定基准模式的产物？

Method: 为了解决这些局限性，我们引入了VAR-MATH，一个旨在探索真正推理能力的符号评估框架。通过将固定的数值问题转换为符号模板，并要求模型解决每个模板的多个实例，VAR-MATH强制跨结构等价变体进行一致的推理，从而减轻污染并提高评估的鲁棒性。我们将VAR-MATH应用于AMC23和AIME24的符号对应物VAR-AMC23和VAR-AIME24。

Result: 实验结果显示，在经过变量化的版本上，经过强化学习训练的模型（尤其是较小的模型）的性能大幅下降，在AMC23上的平均降幅为48.0%，在AIME24上的平均降幅为58.3%。这些发现表明，许多现有的强化学习方法依赖于肤浅的启发式方法，并且无法超出特定数值形式的泛化能力。

Conclusion: VAR-MATH是一个原则性的、抗污染的评估范式，用于数学推理。

Abstract: Recent advances in reinforcement learning (RL) have led to substantial
improvements in the mathematical reasoning abilities of large language models
(LLMs), as measured by standard benchmarks. However, these gains often persist
even when models are trained with flawed signals, such as random or inverted
rewards, raising a fundamental question: do such improvements reflect true
reasoning, or are they merely artifacts of overfitting to benchmark-specific
patterns? To address this question, we take an evaluation-centric perspective
and identify two critical shortcomings in existing protocols. First,
\emph{benchmark contamination} arises from the public availability of test
problems, increasing the risk of data leakage. Second, \emph{evaluation
fragility} stems from the reliance on single-instance assessments, which are
highly sensitive to stochastic outputs and fail to capture reasoning
consistency. To overcome these limitations, we introduce {VAR-MATH}, a symbolic
evaluation framework designed to probe genuine reasoning ability. By converting
fixed numerical problems into symbolic templates and requiring models to solve
multiple instantiations of each, VAR-MATH enforces consistent reasoning across
structurally equivalent variants, thereby mitigating contamination and
improving evaluation robustness. We apply VAR-MATH to transform two popular
benchmarks, AMC23 and AIME24, into their symbolic counterparts, VAR-AMC23 and
VAR-AIME24. Experimental results reveal substantial performance drops for
RL-trained models on the variabilized versions, especially for smaller models,
with average declines of 48.0\% on AMC23 and 58.3\% on AIME24. These findings
suggest that many existing RL methods rely on superficial heuristics and fail
to generalize beyond specific numerical forms. Overall, VAR-MATH offers a
principled, contamination-resistant evaluation paradigm for mathematical
reasoning.

</details>


### [196] [Exploiting Constraint Reasoning to Build Graphical Explanations for Mixed-Integer Linear Programming](https://arxiv.org/abs/2507.13007)
*Roger Xavier Lera-Leri,Filippo Bistaffa,Athina Georgara,Juan Antonio Rodriguez-Aguilar*

Main category: cs.AI

TL;DR: X-MILP是一种用于MILP的对比解释方法，它将用户查询转化为约束，利用IIS找出原因，并以原因图的形式呈现解释。


<details>
  <summary>Details</summary>
Motivation: 为了实现对可信赖AI的追求，人们对开发用于优化的对比解释技术产生了浓厚兴趣，尤其是在解决形式化为MILP的具体决策制定过程方面。

Method: 提出了一种名为X-MILP的领域无关方法，该方法利用约束推理技术来构建MILP的对比解释。具体步骤包括：1.将用户关于MILP解的查询表示为额外的约束。2.通过计算所得约束集的不可约不可行子系统（IIS）来找出导致查询结果的原因。3.将原因表示为“原因图”，以展示原因之间的结构关系。

Result: 通过在众所周知的优化问题实例上测试X-MILP方法，我们评估了计算解释的经验难度。

Conclusion: X-MILP是一种基于约束推理技术，用于为MILP构建对比解释的领域无关方法。它将用户关于MILP解的查询编码为附加约束，并通过计算新约束集的不可约不可行子系统（IIS）来确定构成查询答案的原因。最后，将解释表示为从IIS构建的“原因图”，以帮助用户理解答案的结构。

Abstract: Following the recent push for trustworthy AI, there has been an increasing
interest in developing contrastive explanation techniques for optimisation,
especially concerning the solution of specific decision-making processes
formalised as MILPs. Along these lines, we propose X-MILP, a domain-agnostic
approach for building contrastive explanations for MILPs based on constraint
reasoning techniques. First, we show how to encode the queries a user makes
about the solution of an MILP problem as additional constraints. Then, we
determine the reasons that constitute the answer to the user's query by
computing the Irreducible Infeasible Subsystem (IIS) of the newly obtained set
of constraints. Finally, we represent our explanation as a "graph of reasons"
constructed from the IIS, which helps the user understand the structure among
the reasons that answer their query. We test our method on instances of
well-known optimisation problems to evaluate the empirical hardness of
computing explanations.

</details>


### [197] [Prediction of Highway Traffic Flow Based on Artificial Intelligence Algorithms Using California Traffic Data](https://arxiv.org/abs/2507.13112)
*Junseong Lee,Jaegwan Cho,Yoonju Cho,Seoyoon Choi,Yejin Shin*

Main category: cs.AI

TL;DR: 加州数据分析显示，MLR和RF模型在10分钟数据收集间隔下交通流量预测效果最佳。


<details>
  <summary>Details</summary>
Motivation: 为了解决全球交通拥堵问题，本研究提出了一个基于机器学习的交通流量预测模型。

Method: 本研究采用多重线性回归（MLR）和随机森林（RF）算法，分析了从30秒到15分钟不等的数据收集间隔，并使用R^2、MAE和RMSE作为性能指标。

Result: 在对加利福尼亚州78号公路2022年7月至11月期间的交通数据进行分析后，研究发现MLR和RF模型在10分钟数据收集间隔下表现最优。

Conclusion: 研究表明，多重线性回归（MLR）和随机森林（RF）模型在10分钟的数据收集间隔下表现最佳，这有望为未来的交通拥堵解决方案和有效的交通管理做出贡献。

Abstract: The study "Prediction of Highway Traffic Flow Based on Artificial
Intelligence Algorithms Using California Traffic Data" presents a machine
learning-based traffic flow prediction model to address global traffic
congestion issues. The research utilized 30-second interval traffic data from
California Highway 78 over a five-month period from July to November 2022,
analyzing a 7.24 km westbound section connecting "Melrose Dr" and "El-Camino
Real" in the San Diego area. The study employed Multiple Linear Regression
(MLR) and Random Forest (RF) algorithms, analyzing data collection intervals
ranging from 30 seconds to 15 minutes. Using R^2, MAE, and RMSE as performance
metrics, the analysis revealed that both MLR and RF models performed optimally
with 10-minute data collection intervals. These findings are expected to
contribute to future traffic congestion solutions and efficient traffic
management.

</details>


### [198] [From Roots to Rewards: Dynamic Tree Reasoning with RL](https://arxiv.org/abs/2507.13142)
*Ahmed Bahloul,Simon Malberg*

Main category: cs.AI

TL;DR: 与现有方法相比，该研究提出的动态强化学习框架通过自适应地构建和评估推理树，提高了问答系统的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决现有ProbTree静态实现中存在的推理树固定和节点评估效率低下这两个关键问题。

Method: 提出了一种动态强化学习框架，该框架通过实时置信度估计和学习最优策略（分解、检索或聚合）来增量构建推理树，从而实现了自适应过程。

Result: 该框架在保持ProbTree概率严谨性的同时，通过选择性扩展和集中的资源分配，提高了解决方案的质量和计算效率。

Conclusion: 该研究提出了一种动态强化学习框架，将基于树的推理转变为自适应过程，通过实时置信度估计和学习最优策略来增量构建推理树，从而提高了解决方案质量和计算效率，为现实世界问答系统树立了新的概率推理范例。

Abstract: Modern language models address complex questions through chain-of-thought
(CoT) reasoning (Wei et al., 2023) and retrieval augmentation (Lewis et al.,
2021), yet struggle with error propagation and knowledge integration.
Tree-structured reasoning methods, particularly the Probabilistic
Tree-of-Thought (ProbTree)(Cao et al., 2023) framework, mitigate these issues
by decomposing questions into hierarchical structures and selecting answers
through confidence-weighted aggregation of parametric and retrieved knowledge
(Yao et al., 2023). However, ProbTree's static implementation introduces two
key limitations: (1) the reasoning tree is fixed during the initial
construction phase, preventing dynamic adaptation to intermediate results, and
(2) each node requires exhaustive evaluation of all possible solution
strategies, creating computational inefficiency. We present a dynamic
reinforcement learning (Sutton and Barto, 2018) framework that transforms
tree-based reasoning into an adaptive process. Our approach incrementally
constructs the reasoning tree based on real-time confidence estimates, while
learning optimal policies for action selection (decomposition, retrieval, or
aggregation). This maintains ProbTree's probabilistic rigor while improving
both solution quality and computational efficiency through selective expansion
and focused resource allocation. The work establishes a new paradigm for
treestructured reasoning that balances the reliability of probabilistic
frameworks with the flexibility required for real-world question answering
systems.

</details>


### [199] [Black Box Deployed -- Functional Criteria for Artificial Moral Agents in the LLM Era](https://arxiv.org/abs/2507.13175)
*Matthew E. Brophy*

Main category: cs.AI

TL;DR: 大型语言模型（LLM）的出现使得传统的评估人工智能道德代理（AMA）的标准过时。本文提出了一个包含十项新标准的框架，用于评估LLM驱动的AMA，并通过自动驾驶公交车场景进行了说明。


<details>
  <summary>Details</summary>
Motivation: 随着强大但“不透明”的大型语言模型（LLM）的发展，需要重新审视评估人工智能道德代理（AMA）的哲学标准，因为LLM的随机输出和不透明的内部状态使其不适用于传统评估框架。

Method: 本文通过引入新的评估标准来回应LLM带来的挑战，这些标准包括道德和谐、情境敏感性、规范完整性、元伦理意识、系统弹性、可信赖性、可纠正性、部分透明度、功能自主性和道德想象力。并通过假设的自动驾驶公交车场景进行了说明。

Result: 提出并阐述了十项新的功能性标准，用于评估“模拟道德代理通过大型语言系统”（SMA-LLS），并通过自动驾驶公交车（APB）的假设场景展示了这些标准的实际应用性。

Conclusion: LLM的出现对人工智能道德代理（AMA）的评估标准提出了挑战，传统的基于透明架构的标准已不再适用。本文提出了十项新的功能性标准（道德和谐、情境敏感性、规范完整性、元伦理意识、系统弹性、可信赖性、可纠正性、部分透明度、功能自主性和道德想象力）来评估基于LLM的人工智能道德代理（SMA-LLS），旨在促进其与社会的更好融合。

Abstract: The advancement of powerful yet opaque large language models (LLMs)
necessitates a fundamental revision of the philosophical criteria used to
evaluate artificial moral agents (AMAs). Pre-LLM frameworks often relied on the
assumption of transparent architectures, which LLMs defy due to their
stochastic outputs and opaque internal states. This paper argues that
traditional ethical criteria are pragmatically obsolete for LLMs due to this
mismatch. Engaging with core themes in the philosophy of technology, this paper
proffers a revised set of ten functional criteria to evaluate LLM-based
artificial moral agents: moral concordance, context sensitivity, normative
integrity, metaethical awareness, system resilience, trustworthiness,
corrigibility, partial transparency, functional autonomy, and moral
imagination. These guideposts, applied to what we term "SMA-LLS" (Simulating
Moral Agency through Large Language Systems), aim to steer AMAs toward greater
alignment and beneficial societal integration in the coming years. We
illustrate these criteria using hypothetical scenarios involving an autonomous
public bus (APB) to demonstrate their practical applicability in morally
salient contexts.

</details>


### [200] [The Generative Energy Arena (GEA): Incorporating Energy Awareness in Large Language Model (LLM) Human Evaluations](https://arxiv.org/abs/2507.13302)
*Carlos Arriaga,Gonzalo Martínez,Eneko Sendin,Javier Conde,Pedro Reviriego*

Main category: cs.AI

TL;DR: GEA通过在评估过程中加入能耗信息，发现用户在了解能耗后更偏爱节能模型，表明复杂模型带来的额外成本和能耗往往不能带来与其匹配的感知质量提升。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）的能耗问题，以及用户的能源意识如何影响其模型选择决策。

Method: 提出了一种结合模型能耗信息的人类评估方法GEA（Generative Energy Arena）。

Result: GEA的初步结果表明，当用户了解模型的能耗时，他们更倾向于选择更小、更节能的模型。

Conclusion: 为大多数用户交互而言，更复杂、性能更高的模型所带来的额外成本和能源消耗，并不能提供可证明其使用具有更高感知质量的响应。

Abstract: The evaluation of large language models is a complex task, in which several
approaches have been proposed. The most common is the use of automated
benchmarks in which LLMs have to answer multiple-choice questions of different
topics. However, this method has certain limitations, being the most
concerning, the poor correlation with the humans. An alternative approach, is
to have humans evaluate the LLMs. This poses scalability issues as there is a
large and growing number of models to evaluate making it impractical (and
costly) to run traditional studies based on recruiting a number of evaluators
and having them rank the responses of the models. An alternative approach is
the use of public arenas, such as the popular LM arena, on which any user can
freely evaluate models on any question and rank the responses of two models.
The results are then elaborated into a model ranking. An increasingly important
aspect of LLMs is their energy consumption and, therefore, evaluating how
energy awareness influences the decisions of humans in selecting a model is of
interest. In this paper, we present GEA, the Generative Energy Arena, an arena
that incorporates information on the energy consumption of the model in the
evaluation process. Preliminary results obtained with GEA are also presented,
showing that for most questions, when users are aware of the energy
consumption, they favor smaller and more energy efficient models. This suggests
that for most user interactions, the extra cost and energy incurred by the more
complex and top-performing models do not provide an increase in the perceived
quality of the responses that justifies their use.

</details>


### [201] [FormulaOne: Measuring the Depth of Algorithmic Reasoning Beyond Competitive Programming](https://arxiv.org/abs/2507.13337)
*Gal Beniamini,Yuval Dor,Alon Vinnikov,Shir Granot Peled,Or Weinstein,Or Sharir,Noam Wies,Tomer Nussbaum,Ido Ben Shaul,Tomer Zekharya,Yoav Levine,Shai Shalev-Shwartz,Amnon Shashua*

Main category: cs.AI

TL;DR: The paper introduces FormulaOne, a challenging benchmark based on graph theory and logic, to evaluate advanced AI models. Current top models fail significantly on this benchmark, revealing limitations in their problem-solving capabilities compared to human experts.


<details>
  <summary>Details</summary>
Motivation: The paper aims to assess the extent to which frontier AI models approach true human or superhuman expertise, moving beyond contrived problems to focus on complex, real-life research challenges that require advanced reasoning.

Method: The paper introduces FormulaOne, a benchmark designed to test the limits of frontier AI models by focusing on real-life research problems at the intersection of graph theory, logic, and algorithms. The benchmark is generated using Monadic Second-Order (MSO) logic on graphs and includes problems related to theoretical computer science conjectures like the Strong Exponential Time Hypothesis (SETH). A simpler subset, FormulaOne-Warmup, is also provided.

Result: OpenAI

Conclusion: State-of-the-art AI models like OpenAI's o3 perform poorly on the FormulaOne benchmark, solving less than 1% of problems, indicating a significant gap from expert-level understanding in certain domains.

Abstract: Frontier AI models demonstrate formidable breadth of knowledge. But how close
are they to true human -- or superhuman -- expertise? Genuine experts can
tackle the hardest problems and push the boundaries of scientific
understanding. To illuminate the limits of frontier model capabilities, we turn
away from contrived competitive programming puzzles, and instead focus on
real-life research problems.
  We construct FormulaOne, a benchmark that lies at the intersection of graph
theory, logic, and algorithms, all well within the training distribution of
frontier models. Our problems are incredibly demanding, requiring an array of
reasoning steps. The dataset has three key properties. First, it is of
commercial interest and relates to practical large-scale optimisation problems,
such as those arising in routing, scheduling, and network design. Second, it is
generated from the highly expressive framework of Monadic Second-Order (MSO)
logic on graphs, paving the way toward automatic problem generation at scale;
ideal for building RL environments. Third, many of our problems are intimately
related to the frontier of theoretical computer science, and to central
conjectures therein, such as the Strong Exponential Time Hypothesis (SETH). As
such, any significant algorithmic progress on our dataset, beyond known
results, could carry profound theoretical implications.
  Remarkably, state-of-the-art models like OpenAI's o3 fail entirely on
FormulaOne, solving less than 1% of the questions, even when given 10 attempts
and explanatory fewshot examples -- highlighting how far they remain from
expert-level understanding in some domains. To support further research, we
additionally curate FormulaOne-Warmup, offering a set of simpler tasks, from
the same distribution. We release the full corpus along with a comprehensive
evaluation framework.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [202] [Identification of Authoritative Nodes and Dismantling of Illicit Networks Using a Novel Metric for Measuring Strength of a Graph](https://arxiv.org/abs/2507.12711)
*Kartikeya Kansal,Arunabha Sen*

Main category: cs.SI

TL;DR: 提出了一种新的网络强度度量方法，该方法结合了结构属性和人类感知，并被证明比传统方法更有效。


<details>
  <summary>Details</summary>
Motivation: 现有的网络强度度量方法仅依赖于图的结构属性（如连通性），忽略了在现实世界场景（尤其是在执法领域）中代理人对网络强度的感知，而这些感知往往与结构评估存在显著差异。

Method: 通过对人类受试者进行调查来验证所提出的度量方法，并与现有度量方法进行比较。

Result: 所提出的度量方法与人类判断更加吻合，并且在识别权威节点和有效拆除合成及真实世界网络方面优于传统方法。

Conclusion: 提出了一种结合结构属性和人类感知的新网络强度度量方法，该方法在识别权威节点和有效拆除合成及真实世界网络方面优于传统方法。

Abstract: Dismantling criminal networks or containing epidemics or misinformation
through node removal is a well-studied problem. To evaluate the effectiveness
of such efforts, one must measure the strength of the network before and after
node removal. Process P1 is considered more effective than P2 if the strength
of the residual network after removing k nodes via P1 is smaller than that from
P2. This leads to the central question: How should network strength be
measured?
  Existing metrics rely solely on structural properties of the graph, such as
connectivity. However, in real-world scenarios, particularly in law
enforcement, the perception of agents regarding network strength can differ
significantly from structural assessments. These perceptions are often ignored
in traditional metrics.
  We propose a new strength metric that integrates both structural properties
and human perception. Using human subject surveys, we validate our approach
against existing metrics. Our metric not only aligns more closely with human
judgment but also outperforms traditional methods in identifying authoritative
nodes and effectively dismantling both synthetic and real-world networks.

</details>


### [203] [T3MAL: Test-Time Fast Adaptation for Robust Multi-Scale Information Diffusion Prediction](https://arxiv.org/abs/2507.12880)
*Wenting Zhu,Chaozhuo Li,Qingpo Yang,Xi Zhang,Philip S. Yu*

Main category: cs.SI

TL;DR: T3MAL 是一种用于信息扩散预测的测试时间训练框架，通过自监督学习和元辅助学习来适应测试实例的分布变化，从而提高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有信息扩散预测（IDP）方法通常遵循传统的训练-测试范式，该范式依赖于数据独立且相同分布的假设，这在实际社交网络中由于用户行为的内在不确定性和可变性而常常失效。因此，该研究旨在应对 IDP 任务中分布偏移的新挑战。

Method: T3MAL 框架采用 BYOL 启发的自监督辅助网络，并结合新颖的元辅助学习方案和轻量级适配器，以实现快速准确的测试时间适应，从而为 TTT 提供更好的权重初始化并减轻灾难性遗忘。

Result: T3MAL 框架通过自监督辅助任务在预测前灵活地将训练好的模型适应每个测试实例的分布，从而实现多尺度扩散预测。

Conclusion: T3MAL 框架在三个公开数据集上的广泛实验证明，其性能优于各种最先进的方法。

Abstract: Information diffusion prediction (IDP) is a pivotal task for understanding
how information propagates among users. Most existing methods commonly adhere
to a conventional training-test paradigm, where models are pretrained on
training data and then directly applied to test samples. However, the success
of this paradigm hinges on the assumption that the data are independently and
identically distributed, which often fails in practical social networks due to
the inherent uncertainty and variability of user behavior. In the paper, we
address the novel challenge of distribution shifts within IDP tasks and propose
a robust test-time training (TTT)-based framework for multi-scale diffusion
prediction, named T3MAL. The core idea is to flexibly adapt a trained model to
accommodate the distribution of each test instance before making predictions
via a self-supervised auxiliary task. Specifically, T3MAL introduces a
BYOL-inspired self-supervised auxiliary network that shares a common feature
extraction backbone with the primary diffusion prediction network to guide
instance-specific adaptation during testing. Furthermore, T3MAL enables fast
and accurate test-time adaptation by incorporating a novel meta-auxiliary
learning scheme and a lightweight adaptor, which together provide better weight
initialization for TTT and mitigate catastrophic forgetting. Extensive
experiments on three public datasets demonstrate that T3MAL outperforms various
state-of-the-art methods.

</details>


### [204] [The Centrality Paradox: Why Your Friends Are Always More Important](https://arxiv.org/abs/2507.13059)
*Rajat Subhra Hazra,Evgeny Verbitskiy*

Main category: cs.SI

TL;DR: The friendship paradox, which says your friends have more friends than you on average, applies to other network popularity measures like eigenvector centrality and PageRank too.


<details>
  <summary>Details</summary>
Motivation: The motivation is to extend the classical friendship paradox, which deals with average degree, to a broader range of network centrality measures. This generalization aims to provide a more comprehensive understanding of how network structure influences perceived centrality and the distribution of influence within networks.

Method: The paper generalizes the friendship paradox to various network centrality measures by analyzing their 'friends-average' in irreducible, undirected graphs. The mathematical framework likely involves graph theory and linear algebra, specifically referencing the Perron eigenvalue and its variational characterization to prove the generalized paradox.

Result: The paper demonstrates that for any irreducible, undirected graph, the 'friends-average' of degree, eigenvector centrality, walk-count, Katz, and PageRank centralities is greater than the global average. This finding validates the generalized friendship paradox across these different measures.

Conclusion: The study generalizes the friendship paradox to various network centrality measures, including degree, eigenvector centrality, walk-count, Katz, and PageRank. It demonstrates that for irreducible, undirected graphs, the 'friends-average' of these centralities surpasses the global average, a result linked to the variational characterization of the Perron eigenvalue.

Abstract: We revisit the classical friendship paradox which states that on an average
one's friends have at least as many friends as oneself and generalize it to a
variety of network centrality measures. In particular, we show that for any
irreducible, undirected graph $G$, the "friends-average" of degree,
eigenvector-centrality, walk-count, Katz, and PageRank centralities exceeds the
global average. We show that the result follows from the variational
characterisation of the eigenvector corresponding to the Perron eigenvalue.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [205] [Physically Based Neural LiDAR Resimulation](https://arxiv.org/abs/2507.12489)
*Richard Marcus,Marc Stamminger*

Main category: cs.RO

TL;DR: 该研究通过模拟激光雷达传感器的特定效应（如滚动快门、激光功率变化和强度衰减），改进了激光雷达模拟的准确性，并展示了其在生成高分辨率扫描方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有新视角合成（NVS）方法在激光雷达模拟和大规模3D场景重建领域虽然得到关注，但尚未充分解决激光雷达特有的效应。

Method: 通过显式建模传感器特性（如滚动快门、激光功率变化和强度衰减）来实现更精确的激光雷达模拟。

Result: 该方法通过与最先进的方法进行定量和定性比较以及消融研究来展示其有效性，并展示了其先进的重新模拟能力，例如在相机视角下生成高分辨率激光雷达扫描。

Conclusion: 该方法通过显式地模拟滚动快门、激光功率变化和强度衰减等传感器特性，实现了比现有技术更精确的激光雷达模拟，并在定量和定性比较中证明了其有效性。

Abstract: Methods for Novel View Synthesis (NVS) have recently found traction in the
field of LiDAR simulation and large-scale 3D scene reconstruction. While
solutions for faster rendering or handling dynamic scenes have been proposed,
LiDAR specific effects remain insufficiently addressed. By explicitly modeling
sensor characteristics such as rolling shutter, laser power variations, and
intensity falloff, our method achieves more accurate LiDAR simulation compared
to existing techniques. We demonstrate the effectiveness of our approach
through quantitative and qualitative comparisons with state-of-the-art methods,
as well as ablation studies that highlight the importance of each sensor model
component. Beyond that, we show that our approach exhibits advanced
resimulation capabilities, such as generating high resolution LiDAR scans in
the camera perspective.
  Our code and the resulting dataset are available at
https://github.com/richardmarcus/PBNLiDAR.

</details>


### [206] [FOUNDER: Grounding Foundation Models in World Models for Open-Ended Embodied Decision Making](https://arxiv.org/abs/2507.12496)
*Yucen Wang,Rui Yu,Shenghua Wan,Le Gan,De-Chuan Zhan*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Foundation Models (FMs) and World Models (WMs) offer complementary strengths
in task generalization at different levels. In this work, we propose FOUNDER, a
framework that integrates the generalizable knowledge embedded in FMs with the
dynamic modeling capabilities of WMs to enable open-ended task solving in
embodied environments in a reward-free manner. We learn a mapping function that
grounds FM representations in the WM state space, effectively inferring the
agent's physical states in the world simulator from external observations. This
mapping enables the learning of a goal-conditioned policy through imagination
during behavior learning, with the mapped task serving as the goal state. Our
method leverages the predicted temporal distance to the goal state as an
informative reward signal. FOUNDER demonstrates superior performance on various
multi-task offline visual control benchmarks, excelling in capturing the
deep-level semantics of tasks specified by text or videos, particularly in
scenarios involving complex observations or domain gaps where prior methods
struggle. The consistency of our learned reward function with the ground-truth
reward is also empirically validated. Our project website is
https://sites.google.com/view/founder-rl.

</details>


### [207] [ReAL-AD: Towards Human-Like Reasoning in End-to-End Autonomous Driving](https://arxiv.org/abs/2507.12499)
*Yuhang Lu,Jiadong Tu,Yuexin Ma,Xinge Zhu*

Main category: cs.RO

TL;DR: ReAL-AD是一个用于端到端自动驾驶的框架，它模仿人类的认知过程（策略、决策、操作），并利用视觉语言模型来提高对交通状况的理解和推理能力，从而实现更安全、更准确、更像人类的驾驶。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶方法依赖于固定的、稀疏的轨迹监督，难以捕捉人类驾驶员自然采用的层级推理过程。为了解决这个问题，我们提出ReAL-AD来弥补这一差距。

Method: 提出了一种名为ReAL-AD的推理增强学习框架，该框架将决策过程结构化为三个层级：驾驶策略、驾驶决策和驾驶操作。具体包括：1) 策略推理注入器，通过VLM解释复杂交通环境以制定高级驾驶策略；2) 战术推理整合器，将策略意图细化为可解释的战术选择（如变道、超车、速度调整）；3) 层级轨迹解码器，逐步将战术决策转化为精确的控制动作以实现平滑、类似人类的轨迹执行。

Result: 通过综合评估，ReAL-AD框架在规划准确性和安全性方面取得了超过30%的提升，并使端到端自动驾驶更具可解释性，更符合人类的层级推理。

Conclusion: ReAL-AD框架通过整合三层级人类认知模型和视觉语言模型，显著提高了端到端自动驾驶的规划准确性和安全性（超过30%），使其更具可解释性，并与人类的层级推理保持一致。

Abstract: End-to-end autonomous driving has emerged as a promising approach to unify
perception, prediction, and planning within a single framework, reducing
information loss and improving adaptability. However, existing methods often
rely on fixed and sparse trajectory supervision, limiting their ability to
capture the hierarchical reasoning process that human drivers naturally employ.
To bridge this gap, we propose ReAL-AD, a Reasoning-Augmented Learning
framework that structures decision-making in autonomous driving based on the
three-tier human cognitive model: Driving Strategy, Driving Decision, and
Driving Operation, where Vision-Language Models (VLMs) are incorporated to
enhance situational awareness and structured reasoning across these levels.
Specifically, we introduce: (1) the Strategic Reasoning Injector, which
formulates high-level driving strategies by interpreting complex traffic
contexts from VLM-generated insights; (2) the Tactical Reasoning Integrator,
which refines strategic intent into interpretable tactical choices such as lane
changes, overtaking, and speed adjustments; and (3) the Hierarchical Trajectory
Decoder, which progressively translates tactical decisions into precise control
actions for smooth and human-like trajectory execution. Extensive evaluations
show that integrating our framework improves planning accuracy and safety by
over 30%, making end-to-end autonomous driving more interpretable and aligned
with human-like hierarchical reasoning. The project page can be found at:
\href{https://4dvlab.github.io/project_page/realad}{\texttt{4dvlab.github.io/project\_page/realad}}

</details>


### [208] [VLMgineer: Vision Language Models as Robotic Toolsmiths](https://arxiv.org/abs/2507.12644)
*George Jiayuan Gao,Tianyu Li,Junyao Shi,Yihan Li,Zizhe Zhang,Nadia Figueroa,Dinesh Jayaraman*

Main category: cs.RO

TL;DR: VLMgineer uses VLMs and evolutionary search to design tools and action plans, improving robotic physical intelligence.


<details>
  <summary>Details</summary>
Motivation: Investigating whether foundation models, with their advanced common-sense, reasoning, and creative abilities, can be used to automatically design and effectively wield tools as a complementary form of physical intelligence in robotics, shifting problem-solving onto the tool's design.

Method: Using a framework called VLMgineer that combines the code generation capabilities of vision-language models (VLMs) with evolutionary search to iteratively co-design physical tools and their corresponding action plans for task execution.

Result: VLMgineer demonstrates effectiveness and innovation in a diverse benchmark of everyday manipulation scenarios, surpassing VLM-generated designs from human specifications and existing human-crafted tools.

Conclusion: VLMgineer consistently discovers tools and policies that solve tasks more effectively and innovatively, outperforming existing methods and human-crafted tools, and will release benchmark and code to facilitate future research.

Abstract: Tool design and use reflect the ability to understand and manipulate the
physical world through creativity, planning, and foresight. As such, these
capabilities are often regarded as measurable indicators of intelligence across
biological species. While much of today's research on robotic intelligence
focuses on generating better controllers, inventing smarter tools offers a
complementary form of physical intelligence: shifting the onus of
problem-solving onto the tool's design. Given the vast and impressive
common-sense, reasoning, and creative capabilities of today's foundation
models, we investigate whether these models can provide useful priors to
automatically design and effectively wield such tools? We present VLMgineer, a
framework that harnesses the code generation abilities of vision language
models (VLMs) together with evolutionary search to iteratively co-design
physical tools and the action plans that operate them to perform a task. We
evaluate VLMgineer on a diverse new benchmark of everyday manipulation
scenarios that demand creative tool design and use. Across this suite,
VLMgineer consistently discovers tools and policies that solve tasks more
effectively and innovatively, transforming challenging robotics problems into
straightforward executions. It also outperforms VLM-generated designs from
human specifications and existing human-crafted tools for everyday tasks. To
facilitate future research on automated tool invention, we will release our
benchmark and code.

</details>


### [209] [MoistureMapper: An Autonomous Mobile Robot for High-Resolution Soil Moisture Mapping at Scale](https://arxiv.org/abs/2507.12716)
*Nathaniel Rose,Hannah Chuang,Manuel A Andrade-Rodriguez,Rishi Parashar,Dani Or,Parikshit Maini*

Main category: cs.RO

TL;DR: 本研究提出了一种名为MoistureMapper的自主机器人，使用TDR传感器和自适应采样策略来高效测量土壤湿度，并在实际部署中展示了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有土壤湿度传感方法在大规模、高分辨率应用（如变量灌溉）中部署成本过高的问题。

Method: 研究中提出的自适应采样方法，基于高斯过程建模，并与贪婪基准方法进行了比较。

Result: 自适应采样方法相比贪婪基准方法，在长距离计算模拟和概念验证现场部署中，能将行驶距离减少多达30%，并将重建的湿度图的方差减少5%。

Conclusion: 该研究设计、构建并部署了一个名为MoistureMapper的自主移动机器人，用于土壤湿度传感。该机器人结合了时域反射（TDR）传感器和一个直推钻孔机制，能够测量土壤的体积含水量。通过高斯过程模型实现了多种自适应采样策略，以构建土壤湿度分布的空间图谱。

Abstract: Soil moisture is a quantity of interest in many application areas including
agriculture and climate modeling. Existing methods are not suitable for scale
applications due to large deployment costs in high-resolution sensing
applications such as for variable irrigation. In this work, we design, build
and field deploy an autonomous mobile robot, MoistureMapper, for soil moisture
sensing. The robot is equipped with Time Domain Reflectometry (TDR) sensors and
a direct push drill mechanism for deploying the sensor to measure volumetric
water content in the soil. Additionally, we implement and evaluate multiple
adaptive sampling strategies based on a Gaussian Process based modeling to
build a spatial mapping of moisture distribution in the soil. We present
results from large scale computational simulations and proof-of-concept
deployment on the field. The adaptive sampling approach outperforms a greedy
benchmark approach and results in up to 30\% reduction in travel distance and
5\% reduction in variance in the reconstructed moisture maps. Link to video
showing field experiments: https://youtu.be/S4bJ4tRzObg

</details>


### [210] [Learning to Predict Mobile Robot Stability in Off-Road Environments](https://arxiv.org/abs/2507.12731)
*Nathaniel Rose,Arif Ahmed,Emanuel Gutierrez-Cornejo,Parikshit Maini*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Navigating in off-road environments for wheeled mobile robots is challenging
due to dynamic and rugged terrain. Traditional physics-based stability metrics,
such as Static Stability Margin (SSM) or Zero Moment Point (ZMP) require
knowledge of contact forces, terrain geometry, and the robot's precise
center-of-mass that are difficult to measure accurately in real-world field
conditions. In this work, we propose a learning-based approach to estimate
robot platform stability directly from proprioceptive data using a lightweight
neural network, IMUnet. Our method enables data-driven inference of robot
stability without requiring an explicit terrain model or force sensing.
  We also develop a novel vision-based ArUco tracking method to compute a
scalar score to quantify robot platform stability called C3 score. The score
captures image-space perturbations over time as a proxy for physical
instability and is used as a training signal for the neural network based
model. As a pilot study, we evaluate our approach on data collected across
multiple terrain types and speeds and demonstrate generalization to previously
unseen conditions. These initial results highlight the potential of using IMU
and robot velocity as inputs to estimate platform stability. The proposed
method finds application in gating robot tasks such as precision actuation and
sensing, especially for mobile manipulation tasks in agricultural and space
applications. Our learning method also provides a supervision mechanism for
perception based traversability estimation and planning.

</details>


### [211] [ASC-SW: Atrous strip convolution network with sliding windows for visual-assisted map navigation](https://arxiv.org/abs/2507.12744)
*Cheng Liu,Fan Zhu,Yaoyu Zhuang Zhinan Chen Jiefeng Tang*

Main category: cs.RO

TL;DR: 该研究提出了一种名为ASC-SW的轻量级视觉导航框架，利用ASCnet和SW模块有效检测地面线等障碍物，提高了机器人导航的鲁棒性和安全性，尤其是在资源受限的边缘设备上。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统激光雷达（LiDAR）传感器无法检测地面线等地面障碍物的问题，并为资源受限的边缘计算设备提供轻量级视觉模型。

Method: 提出了一种名为ASC-SW的视觉辅助导航框架，该框架利用深度摄像头和轻量级视觉神经网络来辅助基于地图的移动机器人导航。引入了轻量级高效的ASCnet分割模型来检测DLO，其中MobileNetV2作为骨干网络，ASCSPP用于更有效地提取DLO特征，ASC卷积被集成到ASCSPP中以低计算成本精确识别DLO的线性结构。此外，还提出了SW后处理模块来去除复杂环境中的输出噪声，从而提高识别准确性。

Result: ASC-SW框架在自建数据集上实现了75.3%的Miou分数和9.3 FPS的推理速度，优于现有的DLO检测模型，并在物理机器人平台上成功验证。

Conclusion: 该方法在自建数据集上实现了75.3%的平均交并比（Miou）分数，并在Jetson Orin Nano边缘设备上达到了9.3 FPS的推理速度。该方法优于现有的可变形线性物体（DLO）检测模型，并已在实际机器人平台上成功验证。

Abstract: With the rapid development of lightweight visual neural network
architectures, traditional high-performance vision models have undergone
significant compression, greatly improving their computational efficiency and
energy consumption ratio. This makes them feasible for deployment on
resource-constrained edge computing devices. We propose a visual-assisted
navigation framework called Atrous Strip Convolution-Sliding Window (ASC-SW),
which leverages a depth camera and a lightweight visual neural network to
assist map-based mobile robot navigation. This framework compensates for the
inability of traditional light detection and range (LiDAR) sensors to detect
ground-level obstacles such as ground-level wires. We introduce a lightweight
and efficient segmentation model, Atrous Strip Convolution Network (ASCnet),
for detecting deformable linear objects (DLOs). MobileNetV2 is used as the
backbone network, and Atrous Strip Convolution Spatial Pyramid Pooling (ASCSPP)
is designed to extract DLO features more effectively. Atrous Strip Convolution
is integrated into ASCSPP to accurately identify the linear structure of DLOs
with low computational cost. Additionally, a Sliding Window (SW)
post-processing module is proposed to denoise the output in complex
environments, improving recognition accuracy. Our method strikes a balance
between inference speed and segmentation performance. It achieves a mean
Intersection over Union (Miou) score of 75.3% on a self-built dataset and
reaches 9.3 FPS inference speed on the Jetson Orin Nano edge device. Overall,
our approach outperforms existing DLO detection models and has been
successfully validated on a physical robotic platform.

</details>


### [212] [Refining Motion for Peak Performance: Identifying Optimal Gait Parameters for Energy-Efficient Quadrupedal Bounding](https://arxiv.org/abs/2507.12751)
*Yasser G. Alqaham,Jing Cheng,Zhenyu Gan*

Main category: cs.RO

TL;DR: 通过调整步态参数（占空比、相位偏移、步长持续时间）可以提高四足机器人的能效。


<details>
  <summary>Details</summary>
Motivation: 研究步态参数对四足机器人能量消耗的影响，以提高机器人的性能和自主性。

Method: 通过在Gazebo中模拟Unitree A1四足机器人，并开发一个能够独立调整步态参数（如占空比、相位偏移和步长持续时间）的运动控制器，在低、中、高三个速度下进行边界步态的仿真。同时，进行了实验测试以验证仿真结果。

Result: 仿真和实验结果表明，步态参数对能耗有显著影响，优化这些参数可以有效降低能量消耗。

Conclusion: 优化步态参数可显著降低四足机器人的能耗，提高运动效率。

Abstract: Energy efficiency is a critical factor in the performance and autonomy of
quadrupedal robots. While previous research has focused on mechanical design
and actuation improvements, the impact of gait parameters on energetics has
been less explored. In this paper, we hypothesize that gait parameters,
specifically duty factor, phase shift, and stride duration, are key
determinants of energy consumption in quadrupedal locomotion. To test this
hypothesis, we modeled the Unitree A1 quadrupedal robot and developed a
locomotion controller capable of independently adjusting these gait parameters.
Simulations of bounding gaits were conducted in Gazebo across a range of gait
parameters at three different speeds: low, medium, and high. Experimental tests
were also performed to validate the simulation results. The findings
demonstrate that optimizing gait parameters can lead to significant reductions
in energy consumption, enhancing the overall efficiency of quadrupedal
locomotion. This work contributes to the advancement of energy-efficient
control strategies for legged robots, offering insights directly applicable to
commercially available platforms.

</details>


### [213] [osmAG-LLM: Zero-Shot Open-Vocabulary Object Navigation via Semantic Maps and Large Language Models Reasoning](https://arxiv.org/abs/2507.12753)
*Fujing Xie,Sören Schwertfeger,Hermann Blum*

Main category: cs.RO

TL;DR: 本研究提出了一种新的机器人地图和导航系统，可以应对地图中对象移动或缺失的情况，并通过结合LLM的语义先验来提高导航效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 高细节的对象地图会很快过时，因为对象会被频繁移动。因此，需要一个能够应对对象移动或未映射情况的映射和导航系统。

Method: 本研究开发了一个从头开始考虑对象移动或未映射可能性的对象映射和导航系统。该系统不追求高保真度的地图细节，而是认为地图的主要目的是提供环境基础和上下文，并结合LLM的语义先验来推理对象位置，采用主动、在线的方法导航到对象。

Result: 通过模拟和真实世界实验，该方法在静态对象检索成功率和路径长度方面表现更优，在动态或未映射对象查询方面表现远超先前方法。

Conclusion: 本研究提出的方法在静态对象检索成功率和路径长度方面优于先前方法，并且在动态或未映射对象查询方面表现远超先前方法。

Abstract: Recent open-vocabulary robot mapping methods enrich dense geometric maps with
pre-trained visual-language features, achieving a high level of detail and
guiding robots to find objects specified by open-vocabulary language queries.
While the issue of scalability for such approaches has received some attention,
another fundamental problem is that high-detail object mapping quickly becomes
outdated, as objects get moved around a lot. In this work, we develop a mapping
and navigation system for object-goal navigation that, from the ground up,
considers the possibilities that a queried object can have moved, or may not be
mapped at all. Instead of striving for high-fidelity mapping detail, we
consider that the main purpose of a map is to provide environment grounding and
context, which we combine with the semantic priors of LLMs to reason about
object locations and deploy an active, online approach to navigate to the
objects. Through simulated and real-world experiments we find that our approach
tends to have higher retrieval success at shorter path lengths for static
objects and by far outperforms prior approaches in cases of dynamic or unmapped
object queries. We provide our code and dataset at:
https://anonymous.4open.science/r/osmAG-LLM.

</details>


### [214] [FFI-VTR: Lightweight and Robust Visual Teach and Repeat Navigation based on Feature Flow Indicator and Probabilistic Motion Planning](https://arxiv.org/abs/2507.12800)
*Jikai Wang,Yunqi Cheng,Zonghai Chen*

Main category: cs.RO

TL;DR: 提出了一种轻量、鲁棒的视觉和重复机器人自主导航方法，无需精确的定位和密集重建。该方法通过特征流和概率运动规划来最小化特征流，实现了高效和鲁棒的导航。


<details>
  <summary>Details</summary>
Motivation: 在移动机器人自导航中，实现效率和鲁棒性之间的平衡仍然是一个挑战。

Method: 提出了一种新的视觉和重复机器人自主导航方法，无需精确的定位和密集重建模块。通过引入特征流，建立了特征流与机器人运动之间的定性映射关系，其中特征流定义为匹配特征之间的像素位置偏差。基于映射模型，教学阶段输出的地图表示为关键帧图，其中边缘上的特征流编码了相邻关键帧之间的相对运动。将视觉重复导航本质上建模为当前观测与地图关键帧之间的特征流最小化问题。为了在没有精确定位的情况下驱动机器人持续减少当前帧与地图关键帧之间的特征流，基于定性的特征流-运动映射指示器开发了一种概率运动规划方法。

Result: 所提出的方法轻量、鲁棒，并且在实验中表现优于基线方法。

Conclusion: 该方法轻量、鲁棒，且优于基线方法。

Abstract: Though visual and repeat navigation is a convenient solution for mobile robot
self-navigation, achieving balance between efficiency and robustness in task
environment still remains challenges. In this paper, we propose a novel visual
and repeat robotic autonomous navigation method that requires no accurate
localization and dense reconstruction modules, which makes our system featured
by lightweight and robustness. Firstly, feature flow is introduced and we
develop a qualitative mapping between feature flow and robot's motion, in which
feature flow is defined as pixel location bias between matched features. Based
on the mapping model, the map outputted by the teaching phase is represented as
a keyframe graph, in which the feature flow on the edge encodes the relative
motion between adjacent keyframes. Secondly, the visual repeating navigation is
essentially modeled as a feature flow minimization problem between current
observation and the map keyframe. To drive the robot to consistently reduce the
feature flow between current frame and map keyframes without accurate
localization, a probabilistic motion planning is developed based on our
qualitative feature flow-motion mapping indicator. Extensive experiments using
our mobile platform demonstrates that our proposed method is lightweight,
robust, and superior to baselines. The source code has been made public at
https://github.com/wangjks/FFI-VTR to benefit the community.

</details>


### [215] [Enter the Mind Palace: Reasoning and Planning for Long-term Active Embodied Question Answering](https://arxiv.org/abs/2507.12846)
*Muhammad Fadhil Ginting,Dong-Ki Kim,Xiangyun Meng,Andrzej Reinke,Bandi Jai Krishna,Navid Kayhani,Oriana Peltzer,David D. Fan,Amirreza Shaban,Sung-Kyun Kim,Mykel J. Kochenderfer,Ali-akbar Agha-mohammadi,Shayegan Omidshafiei*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: As robots become increasingly capable of operating over extended periods --
spanning days, weeks, and even months -- they are expected to accumulate
knowledge of their environments and leverage this experience to assist humans
more effectively. This paper studies the problem of Long-term Active Embodied
Question Answering (LA-EQA), a new task in which a robot must both recall past
experiences and actively explore its environment to answer complex,
temporally-grounded questions. Unlike traditional EQA settings, which typically
focus either on understanding the present environment alone or on recalling a
single past observation, LA-EQA challenges an agent to reason over past,
present, and possible future states, deciding when to explore, when to consult
its memory, and when to stop gathering observations and provide a final answer.
Standard EQA approaches based on large models struggle in this setting due to
limited context windows, absence of persistent memory, and an inability to
combine memory recall with active exploration. To address this, we propose a
structured memory system for robots, inspired by the mind palace method from
cognitive science. Our method encodes episodic experiences as scene-graph-based
world instances, forming a reasoning and planning algorithm that enables
targeted memory retrieval and guided navigation. To balance the
exploration-recall trade-off, we introduce value-of-information-based stopping
criteria that determines when the agent has gathered sufficient information. We
evaluate our method on real-world experiments and introduce a new benchmark
that spans popular simulation environments and actual industrial sites. Our
approach significantly outperforms state-of-the-art baselines, yielding
substantial gains in both answer accuracy and exploration efficiency.

</details>


### [216] [DEMONSTRATE: Zero-shot Language to Robotic Control via Multi-task Demonstration Learning](https://arxiv.org/abs/2507.12855)
*Rahel Rickenbach,Bruce Lee,René Zurbrügg,Carmen Amo Alonso,Melanie N. Zeilinger*

Main category: cs.RO

TL;DR: DEMONSTRATE方法使用任务演示而非LLM提示来生成控制问题，减少了对工程师的依赖，并能在执行前评估幻觉。


<details>
  <summary>Details</summary>
Motivation: 解决LLM与控制系统集成中，需要工程师设计包含数学表达式的示例，以及无法在执行前评估幻觉的问题。

Method: DEMONSTRATE方法，利用逆最优控制和多任务学习，用任务演示替代LLM的上下文提示示例，并通过多任务学习确保任务和示例的相似性。

Result: 通过模拟和机器人手臂抓取操作的硬件实验证明了该方法的有效性。

Conclusion: DEMONSTRATE方法通过利用逆最优控制和多任务学习，避免了LLM生成复杂优化问题，仅依赖任务描述的嵌入表示，减少了对工程专业知识的需求，并能在执行前评估幻觉。

Abstract: The integration of large language models (LLMs) with control systems has
demonstrated significant potential in various settings, such as task completion
with a robotic manipulator. A main reason for this success is the ability of
LLMs to perform in-context learning, which, however, strongly relies on the
design of task examples, closely related to the target tasks. Consequently,
employing LLMs to formulate optimal control problems often requires task
examples that contain explicit mathematical expressions, designed by trained
engineers. Furthermore, there is often no principled way to evaluate for
hallucination before task execution. To address these challenges, we propose
DEMONSTRATE, a novel methodology that avoids the use of LLMs for complex
optimization problem generations, and instead only relies on the embedding
representations of task descriptions. To do this, we leverage tools from
inverse optimal control to replace in-context prompt examples with task
demonstrations, as well as the concept of multitask learning, which ensures
target and example task similarity by construction. Given the fact that
hardware demonstrations can easily be collected using teleoperation or guidance
of the robot, our approach significantly reduces the reliance on engineering
expertise for designing in-context examples. Furthermore, the enforced
multitask structure enables learning from few demonstrations and assessment of
hallucinations prior to task execution. We demonstrate the effectiveness of our
method through simulation and hardware experiments involving a robotic arm
tasked with tabletop manipulation.

</details>


### [217] [LaViPlan : Language-Guided Visual Path Planning with RLVR](https://arxiv.org/abs/2507.12911)
*Hayeon Oh*

Main category: cs.RO

TL;DR: LaViPlan框架使用RLVR优化VLM，解决了自动驾驶中视觉-语言-动作的不一致问题，提高了OOD场景下的表现。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶领域中，视觉语言模型（VLM）的高级决策/语言推理与低级轨迹预测/动作之间存在的不一致性问题，尤其是在OOD（分布外）场景下，现有VLM可能识别场景但做出不考虑上下文的决策。

Method: 提出LaViPlan框架，利用可验证奖励的强化学习（RLVR）来优化视觉语言模型（VLM），并以规划为导向的指标进行训练。

Result: 实验结果表明，LaViPlan框架提高了自动驾驶系统在OOD条件下的态势感知和决策能力，有效缓解了视觉-语言-动作不一致的问题。

Conclusion: LaViPlan框架通过使用可验证奖励的强化学习（RLVR）来优化视觉语言模型（VLM），以规划为导向的指标，解决了现有VLM的视觉-语言-动作不一致问题。实验结果表明，该方法提高了在OOD条件下的态势感知和决策能力，有望缓解不一致问题，为VLM自动驾驶代理引入了有前景的训练后范式。

Abstract: Out-of-distribution (OOD) scenarios in autonomous driving refer to situations
that deviate from the training domain, often leading to unexpected and
potentially hazardous behavior from planners that lack prior exposure to such
cases. Recently, Vision-Language Models (VLMs) have been introduced into
autonomous driving research for their promising generalization capabilities in
OOD settings. Early studies demonstrated that VLMs could recognize OOD
scenarios and generate user-level decisions such as "go straight" or "turn
right." However, a new challenge has emerged due to the misalignment between
the VLM's high-level decisions or visual reasoning expressed in language, and
the low-level predicted trajectories interpreted as actions. In this paper, we
propose LaViPlan, a framework that leverages Reinforcement Learning with
Verifiable Rewards (RLVR) to optimize VLMs using planning-oriented metrics.
This approach addresses the vision-language-action misalignment observed in
existing VLMs fine-tuned via supervised learning, which can recognize driving
scenarios but often produce context-unaware decisions. Experimental results
demonstrate that our method improves situational awareness and decision-making
under OOD conditions, highlighting its potential to mitigate the misalignment
issue. This work introduces a promising post-training paradigm for VLM agents
in the context of autonomous driving.

</details>


### [218] [MoCap2GT: A High-Precision Ground Truth Estimator for SLAM Benchmarking Based on Motion Capture and IMU Fusion](https://arxiv.org/abs/2507.12920)
*Zichao Shu,Shitao Bei,Jicheng Dai,Lijun Li,Zetao Chen*

Main category: cs.RO

TL;DR: 本文提出 MoCap2GT，一种结合 MoCap 和 IMU 数据的联合优化方法，用于生成高精度 GT 轨迹，以解决 SLAM 评估中对旋转和帧间误差评估的挑战。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有 SLAM 评估主要关注绝对平移误差，而旋转和帧间误差评估具有挑战性的问题，本文提出了一种新的方法来提高 GT 轨迹的精度。

Method: MoCap2GT 是一种联合优化方法，它整合了来自 DUT 的 MoCap 数据和 IMU 测量来生成高精度 GT 轨迹。它包括一个鲁棒的状态初始化器以确保全局收敛，提出了在 SE(3) 流形上具有可变时间偏移的更高阶 B 样条位姿参数化来有效地模拟 MoCap 因素，并采用退化感知测量拒绝策略来提高估计精度。

Result: 实验结果表明，MoCap2GT 性能优于现有方法，为精确的 SLAM 基准测试做出了显著贡献。

Conclusion: MoCap2GT 通过结合 MoCap 数据和 DUT 的 IMU 测量，提出了一种联合优化方法，用于生成高精度 GT 轨迹，优于现有方法，并为精确的 SLAM 基准测试做出了贡献。

Abstract: Marker-based optical motion capture (MoCap) systems are widely used to
provide ground truth (GT) trajectories for benchmarking SLAM algorithms.
However, the accuracy of MoCap-based GT trajectories is mainly affected by two
factors: spatiotemporal calibration errors between the MoCap system and the
device under test (DUT), and inherent MoCap jitter. Consequently, existing
benchmarks focus primarily on absolute translation error, as accurate
assessment of rotation and inter-frame errors remains challenging, hindering
thorough SLAM evaluation. This paper proposes MoCap2GT, a joint optimization
approach that integrates MoCap data and inertial measurement unit (IMU)
measurements from the DUT for generating high-precision GT trajectories.
MoCap2GT includes a robust state initializer to ensure global convergence,
introduces a higher-order B-spline pose parameterization on the SE(3) manifold
with variable time offset to effectively model MoCap factors, and employs a
degeneracy-aware measurement rejection strategy to enhance estimation accuracy.
Experimental results demonstrate that MoCap2GT outperforms existing methods and
significantly contributes to precise SLAM benchmarking. The source code is
available at https://anonymous.4open.science/r/mocap2gt (temporarily hosted
anonymously for double-blind review).

</details>


### [219] [Non-differentiable Reward Optimization for Diffusion-based Autonomous Motion Planning](https://arxiv.org/abs/2507.12977)
*Giwon Lee,Daehee Park,Jaewoo Jeong,Kuk-Jin Yoon*

Main category: cs.RO

TL;DR: 本研究提出了一种基于强化学习的训练方案，用于优化扩散运动规划模型，以解决安全性和有效性等非可微目标，并在行人数据集上取得了优异成果。


<details>
  <summary>Details</summary>
Motivation: 由于扩散模型在训练目标上存在局限性，无法直接优化非可微的下游目标（如安全性和有效性），因此需要一种新的训练方案。

Method: 提出了一种基于强化学习的扩散运动规划模型训练方案，并引入了一种奖励加权动态阈值算法来塑造密集奖励信号，以实现更有效的训练。

Result: 与使用可微目标的模型相比，该方法在训练效率和模型性能上均表现更优。

Conclusion: 该方法在行人数据集（CrowdNav、ETH-UCY）上实现了最先进的性能，证明了其在安全有效运动规划方面的多功能性。

Abstract: Safe and effective motion planning is crucial for autonomous robots.
Diffusion models excel at capturing complex agent interactions, a fundamental
aspect of decision-making in dynamic environments. Recent studies have
successfully applied diffusion models to motion planning, demonstrating their
competence in handling complex scenarios and accurately predicting multi-modal
future trajectories. Despite their effectiveness, diffusion models have
limitations in training objectives, as they approximate data distributions
rather than explicitly capturing the underlying decision-making dynamics.
However, the crux of motion planning lies in non-differentiable downstream
objectives, such as safety (collision avoidance) and effectiveness
(goal-reaching), which conventional learning algorithms cannot directly
optimize. In this paper, we propose a reinforcement learning-based training
scheme for diffusion motion planning models, enabling them to effectively learn
non-differentiable objectives that explicitly measure safety and effectiveness.
Specifically, we introduce a reward-weighted dynamic thresholding algorithm to
shape a dense reward signal, facilitating more effective training and
outperforming models trained with differentiable objectives. State-of-the-art
performance on pedestrian datasets (CrowdNav, ETH-UCY) compared to various
baselines demonstrates the versatility of our approach for safe and effective
motion planning.

</details>


### [220] [Robustness Requirement Coverage using a Situation Coverage Approach for Vision-based AI Systems](https://arxiv.org/abs/2507.12986)
*Sepeedeh Shahbeigi,Nawshin Mannan Proma,Victoria Hodge,Richard Hawkins,Boda Li,Valentina Donzella*

Main category: cs.RO

TL;DR: 为AI视觉感知系统（尤其在汽车领域）制定鲁棒性安全需求，通过结合摄像头噪声因子识别和工况覆盖率分析来解决传感器退化问题。


<details>
  <summary>Details</summary>
Motivation: AI驱动的机器人和车辆需要在复杂动态环境中安全运行，即使在组件退化的情况下也是如此。传感器（如摄像头）的性能下降会影响AI模型的推理，导致安全隐患。为所有可能的传感器退化场景指定安全需求会产生难以管理和有疏漏的复杂性。

Method: 本研究提出了一种集成摄像头噪声因子识别与工况覆盖率分析的框架，以系统地提取AI视觉感知系统的鲁棒性安全需求。该方法首先扩展降级模型，纳入与AI性能相关的噪声因子，然后应用工况覆盖率分析来识别代表性运行场景。

Result: 该框架将噪声因子分析和工况覆盖率分析相结合，为基于摄像头的AI感知系统的鲁棒性需求提供了原则性的制定和完整性评估的支持，是实现安全、鲁棒AI系统的重要一步。

Conclusion: 本论文提出了一种将摄像头噪声因子识别与工况覆盖率分析相结合的新框架，用于系统地引出面向AI视觉感知系统的鲁棒性安全需求。该框架着重于汽车领域的摄像头降级问题，通过整合领域、传感器和安全专家，并结合运行设计域（ODD）规范，来扩展降级模型，纳入与AI性能相关的噪声因子。随后，应用工况覆盖率分析来识别具有代表性的运行场景。

Abstract: AI-based robots and vehicles are expected to operate safely in complex and
dynamic environments, even in the presence of component degradation. In such
systems, perception relies on sensors such as cameras to capture environmental
data, which is then processed by AI models to support decision-making. However,
degradation in sensor performance directly impacts input data quality and can
impair AI inference. Specifying safety requirements for all possible sensor
degradation scenarios leads to unmanageable complexity and inevitable gaps. In
this position paper, we present a novel framework that integrates camera noise
factor identification with situation coverage analysis to systematically elicit
robustness-related safety requirements for AI-based perception systems. We
focus specifically on camera degradation in the automotive domain. Building on
an existing framework for identifying degradation modes, we propose involving
domain, sensor, and safety experts, and incorporating Operational Design Domain
specifications to extend the degradation model by incorporating noise factors
relevant to AI performance. Situation coverage analysis is then applied to
identify representative operational contexts. This work marks an initial step
toward integrating noise factor analysis and situational coverage to support
principled formulation and completeness assessment of robustness requirements
for camera-based AI perception.

</details>


### [221] [ZipMPC: Compressed Context-Dependent MPC Cost via Imitation Learning](https://arxiv.org/abs/2507.13088)
*Rahel Rickenbach,Alan A. Lahoud,Erik Schaffernicht,Melanie N. Zeilinger,Johannes A. Stork*

Main category: cs.RO

TL;DR: ZipMPC 通过学习压缩和上下文相关的成本函数来模仿长视野 MPC 的行为，用于短视野 MPC，在性能和计算成本方面优于替代方法，并在自动赛车任务中得到验证。


<details>
  <summary>Details</summary>
Motivation: 模型预测控制 (MPC) 的计算负担限制了其在机器人等实时系统上的应用，并需要较短的预测范围，这影响了控制性能并增加了设计 MPC 成本函数的难度，该成本函数需要反映期望的长期目标。

Method: ZipMPC 利用可微 MPC 和神经网络的概念，通过 MPC 优化传播模仿损失的梯度，以模仿长视野 MPC 的行为。

Result: ZipMPC 在模拟和真实世界实验中，特别是在自动赛车方面，其圈速接近长视野 MPC 基线，并且在短视野 MPC 基线失败的情况下也能完成比赛，尤其是在未见过的赛道上，性能优于替代方法。

Conclusion: ZipMPC 是一种模仿长视野 MPC 行为的方法，通过为短视野 MPC 学习压缩的、与上下文相关的成本函数，在性能上优于替代方法，并且在模拟和真实世界实验中均表现出色，特别是在自动赛车方面，其圈速接近长视野 MPC 基线，并且在短视野 MPC 基线失败的情况下也能完成比赛，尤其是在未见过的赛道上。

Abstract: The computational burden of model predictive control (MPC) limits its
application on real-time systems, such as robots, and often requires the use of
short prediction horizons. This not only affects the control performance, but
also increases the difficulty of designing MPC cost functions that reflect the
desired long-term objective. This paper proposes ZipMPC, a method that imitates
a long-horizon MPC behaviour by learning a compressed and context-dependent
cost function for a short-horizon MPC. It improves performance over alternative
methods, such as approximate explicit MPC and automatic cost parameter tuning,
in particular in terms of i) optimizing the long term objective; ii)
maintaining computational costs comparable to a short-horizon MPC; iii)
ensuring constraint satisfaction; and iv) generalizing control behaviour to
environments not observed during training. For this purpose, ZipMPC leverages
the concept of differentiable MPC with neural networks to propagate gradients
of the imitation loss through the MPC optimization. We validate our proposed
method in simulation and real-world experiments on autonomous racing. ZipMPC
consistently completes laps faster than selected baselines, achieving lap times
close to the long-horizon MPC baseline. In challenging scenarios where the
short-horizon MPC baseline fails to complete a lap, ZipMPC is able to do so. In
particular, these performance gains are also observed on tracks unseen during
training.

</details>


### [222] [Rethinking the Embodied Gap in Vision-and-Language Navigation: A Holistic Study of Physical and Visual Disparities](https://arxiv.org/abs/2507.13019)
*Liuyi Wang,Xinyuan Xia,Hui Zhao,Hanqing Wang,Tai Wang,Yilun Chen,Chengju Liu,Qijun Chen,Jiangmiao Pang*

Main category: cs.RO

TL;DR: 该研究提出了VLN-PE，一个用于评估现实世界中机器人导航（VLN）方法的物理仿真平台，发现在物理环境中存在显著的性能下降，并为未来更鲁棒的VLN模型提供了方向。


<details>
  <summary>Details</summary>
Motivation: 现有VLN方法的理想化假设未能反映机器人物理部署的挑战，因此需要一个能模拟真实物理环境的平台来弥合这一差距。

Method: 该研究介绍了VLN-PE，一个支持人形、四足和轮式机器人的物理现实VLN平台。它系统地评估了不同技术流程下、不同机器人类型的自我中心VLN方法，包括用于单步离散动作预测的分类模型、用于密集路径点预测的扩散模型，以及与路径规划集成的无训练、基于地图的大型语言模型（LLM）。

Result: 在物理环境中，VLN模型性能显著下降，主要由于机器人观测空间有限、环境光照变化以及碰撞和摔倒等物理挑战。特别是，这暴露了机器人在复杂环境中运动的局限性。VLN-PE也展示了其高度可扩展性，能够集成新的场景。

Conclusion: VLN-PE提供了一个新的途径来改善跨具身机器人的整体适应性，尽管当前模型在物理部署中的泛化能力较弱。研究结果表明，在物理部署中，VLN模型面临显著的性能下降，这暴露了不同类型机器人在复杂环境中的运动限制。VLN-PE为改进VLN的局限性和推进鲁棒、实用的VLN模型提供了新的思路和工具。

Abstract: Recent Vision-and-Language Navigation (VLN) advancements are promising, but
their idealized assumptions about robot movement and control fail to reflect
physically embodied deployment challenges. To bridge this gap, we introduce
VLN-PE, a physically realistic VLN platform supporting humanoid, quadruped, and
wheeled robots. For the first time, we systematically evaluate several
ego-centric VLN methods in physical robotic settings across different technical
pipelines, including classification models for single-step discrete action
prediction, a diffusion model for dense waypoint prediction, and a train-free,
map-based large language model (LLM) integrated with path planning. Our results
reveal significant performance degradation due to limited robot observation
space, environmental lighting variations, and physical challenges like
collisions and falls. This also exposes locomotion constraints for legged
robots in complex environments. VLN-PE is highly extensible, allowing seamless
integration of new scenes beyond MP3D, thereby enabling more comprehensive VLN
evaluation. Despite the weak generalization of current models in physical
deployment, VLN-PE provides a new pathway for improving cross-embodiment's
overall adaptability. We hope our findings and tools inspire the community to
rethink VLN limitations and advance robust, practical VLN models. The code is
available at https://crystalsixone.github.io/vln_pe.github.io/.

</details>


### [223] [What Can Robots Teach Us About Trust and Reliance? An interdisciplinary dialogue between Social Sciences and Social Robotics](https://arxiv.org/abs/2507.13041)
*Julien Wacquez,Elisabetta Zibetti,Joffrey Becker,Lorenzo Aloe,Fabio Amadio,Salvatore Anzalone,Lola Cañamero,Serena Ivaldi*

Main category: cs.RO

TL;DR: 人机交互中的信任研究需要结合社会科学和机器人学的跨学科方法，以应对机器人日益普及带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着机器人越来越普遍，信任问题变得越来越重要，但目前的研究方法过于分散，并且未能充分利用社会学中关于信任的既有研究。

Method: 通过借鉴社会科学和社会机器人学的见解，探讨信任的形成、测试和显现。

Result: 为理解人机交互中不断变化的信任关系，提供一个更扎实、更具适应性的框架，并促进跨学科对话。

Conclusion: 需要一个更跨学科的方法来理解人机交互中的信任，结合社会科学和机器人学的见解，以建立一个更稳健、更适应性强的框架。

Abstract: As robots find their way into more and more aspects of everyday life,
questions around trust are becoming increasingly important. What does it mean
to trust a robot? And how should we think about trust in relationships that
involve both humans and non-human agents? While the field of Human-Robot
Interaction (HRI) has made trust a central topic, the concept is often
approached in fragmented ways. At the same time, established work in sociology,
where trust has long been a key theme, is rarely brought into conversation with
developments in robotics. This article argues that we need a more
interdisciplinary approach. By drawing on insights from both social sciences
and social robotics, we explore how trust is shaped, tested and made visible.
Our goal is to open up a dialogue between disciplines and help build a more
grounded and adaptable framework for understanding trust in the evolving world
of human-robot interaction.

</details>


### [224] [Efficient Online Learning and Adaptive Planning for Robotic Information Gathering Based on Streaming Data](https://arxiv.org/abs/2507.13053)
*Sanjeev Ramkumar Sudha,Joel Jose,Erlend M. Coates*

Main category: cs.RO

TL;DR: 提出了一种新的机器人信息收集方法，使用流式稀疏GP进行自适应信息规划，提高了效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有信息规划方法在未知或时变环境下的局限性，以及GP在高维数据下的实时性问题。

Method: 提出了一种使用流式稀疏高斯过程（GP）的高效自适应信息规划方法，用于映射连续标量场。

Result: 提出的方法在保持与基线方法相似的映射精度的情况下，显著降低了计算复杂度，尤其是在执行长期任务时。

Conclusion: 该研究提出了一种使用流式稀疏高斯过程（GP）的高效自适应信息规划方法，用于映射连续标量场，并在模拟和真实世界数据集上进行了验证。

Abstract: Robotic information gathering (RIG) techniques refer to methods where mobile
robots are used to acquire data about the physical environment with a suite of
sensors. Informative planning is an important part of RIG where the goal is to
find sequences of actions or paths that maximize efficiency or the quality of
information collected. Many existing solutions solve this problem by assuming
that the environment is known in advance. However, real environments could be
unknown or time-varying, and adaptive informative planning remains an active
area of research. Adaptive planning and incremental online mapping are required
for mapping initially unknown or varying spatial fields. Gaussian process (GP)
regression is a widely used technique in RIG for mapping continuous spatial
fields. However, it falls short in many applications as its real-time
performance does not scale well to large datasets. To address these challenges,
this paper proposes an efficient adaptive informative planning approach for
mapping continuous scalar fields with GPs with streaming sparse GPs. Simulation
experiments are performed with a synthetic dataset and compared against
existing benchmarks. Finally, it is also verified with a real-world dataset to
further validate the efficacy of the proposed method. Results show that our
method achieves similar mapping accuracy to the baselines while reducing
computational complexity for longer missions.

</details>


### [225] [GraspGen: A Diffusion-based Framework for 6-DOF Grasping with On-Generator Training](https://arxiv.org/abs/2507.13097)
*Adithyavairavan Murali,Balakumar Sundaralingam,Yu-Wei Chao,Wentao Yuan,Jun Yamada,Mark Carlson,Fabio Ramos,Stan Birchfield,Dieter Fox,Clemens Eppner*

Main category: cs.RO

TL;DR: GraspGen improves 6-DOF grasping by using a DiffusionTransformer and a discriminator, trained on a large dataset, achieving state-of-the-art results on FetchBench and performing well on real robots.


<details>
  <summary>Details</summary>
Motivation: Learning-based 6-DOF grasping approaches struggle to generalize across different embodiments and in-the-wild settings, despite significant research advancements.

Method: The framework uses a DiffusionTransformer architecture for grasp generation and an efficient discriminator for scoring and filtering grasps. It also introduces an on-generator training recipe for the discriminator and is trained on a large simulated dataset of over 53 million grasps.

Result: The framework outperforms prior methods in simulations with singulated objects across different grippers and achieves state-of-the-art performance on the FetchBench grasping benchmark. It also performs well on a real robot with noisy visual observations.

Conclusion: GraspGen outperformed prior methods in simulations and achieved state-of-the-art performance on FetchBench, demonstrating strong performance on real robots.

Abstract: Grasping is a fundamental robot skill, yet despite significant research
advancements, learning-based 6-DOF grasping approaches are still not turnkey
and struggle to generalize across different embodiments and in-the-wild
settings. We build upon the recent success on modeling the object-centric grasp
generation process as an iterative diffusion process. Our proposed framework,
GraspGen, consists of a DiffusionTransformer architecture that enhances grasp
generation, paired with an efficient discriminator to score and filter sampled
grasps. We introduce a novel and performant on-generator training recipe for
the discriminator. To scale GraspGen to both objects and grippers, we release a
new simulated dataset consisting of over 53 million grasps. We demonstrate that
GraspGen outperforms prior methods in simulations with singulated objects
across different grippers, achieves state-of-the-art performance on the
FetchBench grasping benchmark, and performs well on a real robot with noisy
visual observations.

</details>


### [226] [Aligning Humans and Robots via Reinforcement Learning from Implicit Human Feedback](https://arxiv.org/abs/2507.13171)
*Suzie Kim,Hye-Bin Shin,Seong-Whan Lee*

Main category: cs.RO

TL;DR: 提出一种从隐式人类反馈（RLIHF）中进行强化学习的框架，该框架利用脑电图（EEG）信号（特别是错误相关电位ErrPs）作为连续的、非侵入性的反馈信号，从而在稀疏奖励环境下实现与使用密集奖励相当的性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统强化学习在稀疏奖励条件下学习有效策略的困难，并提出一种无需显式用户干预的隐式人类反馈强化学习（RLIHF）框架。

Method: 使用预训练的解码器将原始EEG信号转换为概率奖励成分，从而实现有效的策略学习。

Result: 使用解码的EEG反馈训练的智能体在拾放任务中达到了与使用密集、手动设计的奖励训练的智能体相当的性能。

Conclusion: RLHF方法依赖显式反馈机制，如按钮或偏好标签，这会干扰自然交互过程并增加用户认知负荷。提出的RLIHF框架利用非侵入性脑电图（EEG）信号，特别是与错误相关的电位（ErrPs），提供连续的、隐式的反馈，无需用户干预。该方法采用预训练的解码器将原始EEG信号转换为概率奖励成分，即使在稀疏外部奖励的情况下也能实现有效的策略学习。所提出的方法在基于MuJoCo物理引擎的模拟环境中进行了评估，使用Kinova Gen2机器人手臂执行复杂的拾放任务，该任务需要避开障碍物并操纵目标物体。结果表明，使用解码的EEG反馈训练的智能体达到了与使用密集、手动设计的奖励训练的智能体相当的性能。这些发现验证了在交互式机器人技术中使用隐式神经反馈进行可扩展且符合人类的强化学习的潜力。

Abstract: Conventional reinforcement learning (RL) ap proaches often struggle to learn
effective policies under sparse reward conditions, necessitating the manual
design of complex, task-specific reward functions. To address this limitation,
rein forcement learning from human feedback (RLHF) has emerged as a promising
strategy that complements hand-crafted rewards with human-derived evaluation
signals. However, most existing RLHF methods depend on explicit feedback
mechanisms such as button presses or preference labels, which disrupt the
natural interaction process and impose a substantial cognitive load on the
user. We propose a novel reinforcement learning from implicit human feedback
(RLIHF) framework that utilizes non-invasive electroencephalography (EEG)
signals, specifically error-related potentials (ErrPs), to provide continuous,
implicit feedback without requiring explicit user intervention. The proposed
method adopts a pre-trained decoder to transform raw EEG signals into
probabilistic reward components, en abling effective policy learning even in
the presence of sparse external rewards. We evaluate our approach in a
simulation environment built on the MuJoCo physics engine, using a Kinova Gen2
robotic arm to perform a complex pick-and-place task that requires avoiding
obstacles while manipulating target objects. The results show that agents
trained with decoded EEG feedback achieve performance comparable to those
trained with dense, manually designed rewards. These findings validate the
potential of using implicit neural feedback for scalable and human-aligned
reinforcement learning in interactive robotics.

</details>


### [227] [Few-shot transfer of tool-use skills using human demonstrations with proximity and tactile sensing](https://arxiv.org/abs/2507.13200)
*Marina Y. Aoyama,Sethu Vijayakumar,Tetsuya Narita*

Main category: cs.RO

TL;DR: 提出了一种少样本工具使用技能迁移框架，利用模拟预训练和真实微调来解决机器人工具操作中的接触点复杂性问题，并使用多模态传感来提高性能。


<details>
  <summary>Details</summary>
Motivation: 尽管人类在工具操作方面经验丰富，但教授机器人这些技能面临挑战，主要是由于机器人与工具之间以及工具与环境之间的两个同时接触点的相互作用。由于真实世界数据的有限性和模拟到现实的巨大差距，使用触觉和近距离传感器学习工具操作仍然具有挑战性。

Method: 提出了一种使用多模态传感器的少样本工具使用技能迁移框架，该框架涉及在模拟中预训练基础策略以捕获工具使用技能中常见的接触状态，并在真实目标域中收集的人类演示中对其进行微调以弥合域间隙。

Result: 该框架能够教授具有不同物理和几何特性的工具的表面跟随任务。机器人通过将识别工具-环境接触关系的能力从预训练策略转移到微调策略来学习新的工具使用技能。结合近距离和触觉传感器可以增强对接触状态和环境几何的识别。

Conclusion: 该框架通过在模拟中预训练基础策略以捕获工具使用技能中常见的接触状态，并在真实目标域中收集的人类演示中对其进行微调，从而弥合了域间隙。实验证明，该框架能够教授具有不同物理和几何特性的工具的表面跟随任务。

Abstract: Tools extend the manipulation abilities of robots, much like they do for
humans. Despite human expertise in tool manipulation, teaching robots these
skills faces challenges. The complexity arises from the interplay of two
simultaneous points of contact: one between the robot and the tool, and another
between the tool and the environment. Tactile and proximity sensors play a
crucial role in identifying these complex contacts. However, learning tool
manipulation using these sensors remains challenging due to limited real-world
data and the large sim-to-real gap. To address this, we propose a few-shot
tool-use skill transfer framework using multimodal sensing. The framework
involves pre-training the base policy to capture contact states common in
tool-use skills in simulation and fine-tuning it with human demonstrations
collected in the real-world target domain to bridge the domain gap. We validate
that this framework enables teaching surface-following tasks using tools with
diverse physical and geometric properties with a small number of demonstrations
on the Franka Emika robot arm. Our analysis suggests that the robot acquires
new tool-use skills by transferring the ability to recognise tool-environment
contact relationships from pre-trained to fine-tuned policies. Additionally,
combining proximity and tactile sensors enhances the identification of contact
states and environmental geometry.

</details>


### [228] [Signal Temporal Logic Compliant Co-design of Planning and Control](https://arxiv.org/abs/2507.13225)
*Manas Sashank Juvvi,Tushar Dilip Kurne,Vaishnavi J,Shishir Kolathaya,Pushpak Jagtap*

Main category: cs.RO

TL;DR: 提出了一种新的协同设计策略，将轨迹规划和控制相结合，以处理自主机器人中的基于STL的任务。


<details>
  <summary>Details</summary>
Motivation: 提出一种新的协同设计策略，将轨迹规划和控制相结合，以处理自主机器人中的基于STL的任务。

Method: 该方法包括两个阶段：(1)学习时空运动原语来封装固有的机器人特定约束；(2)从这些原语构建符合STL的运动计划。首先，使用强化学习构建控制策略库，以执行由运动原语描述的轨迹。然后，将运动原语映射到时空特征。随后，提出了一种基于采样的、符合STL的运动计划策略，以满足STL规范。

Result: 在差速和四足机器人上，针对各种STL规范对所提出的模型无关方法进行了验证。

Conclusion: 该模型不依赖于模型，可以生成满足各种环境和STL规范的可行运动计划

Abstract: This work presents a novel co-design strategy that integrates trajectory
planning and control to handle STL-based tasks in autonomous robots. The method
consists of two phases: $(i)$ learning spatio-temporal motion primitives to
encapsulate the inherent robot-specific constraints and $(ii)$ constructing an
STL-compliant motion plan from these primitives. Initially, we employ
reinforcement learning to construct a library of control policies that perform
trajectories described by the motion primitives. Then, we map motion primitives
to spatio-temporal characteristics. Subsequently, we present a sampling-based
STL-compliant motion planning strategy tailored to meet the STL specification.
The proposed model-free approach, which generates feasible STL-compliant motion
plans across various environments, is validated on differential-drive and
quadruped robots across various STL specifications. Demonstration videos are
available at https://tinyurl.com/m6zp7rsm.

</details>


### [229] [Evaluating Reinforcement Learning Algorithms for Navigation in Simulated Robotic Quadrupeds: A Comparative Study Inspired by Guide Dog Behaviour](https://arxiv.org/abs/2507.13277)
*Emma M. A. Harrison*

Main category: cs.RO

TL;DR: This research trains a simulated quadruped robot for autonomous navigation and obstacle avoidance using three reinforcement learning algorithms. Proximal Policy Optimization (PPO) showed the best performance, outperforming Deep Q-Network (DQN) and Q-learning. The findings contribute to the development of AI-driven mobility for assistive robotics, with potential applications in guiding visually impaired individuals.


<details>
  <summary>Details</summary>
Motivation: The goal is to develop a robotic guide dog simulation capable of path following and obstacle avoidance, with long-term potential for real-world assistance to guide dogs and visually impaired individuals. It also seeks to expand research into medical 'pets', including robotic guide and alert dogs.

Method: A comparative analysis of thirteen related research papers shaped key evaluation criteria, including collision detection, pathfinding algorithms, sensor usage, robot type, and simulation platforms. The study focuses on sensor inputs, collision frequency, reward signals, and learning progression to determine which algorithm best supports robotic navigation in complex environments. Custom-made environments were used to ensure fair evaluation of all three algorithms under controlled conditions, allowing consistent data collection.

Result: Results show that Proximal Policy Optimization (PPO) outperformed Deep Q-Network (DQN) and Q-learning across all metrics, particularly in average and median steps to goal per episode.

Conclusion: Robots are increasingly integrated across industries, particularly in healthcare. This research explores the effectiveness of three reinforcement learning algorithms in training a simulated quadruped robot for autonomous navigation and obstacle avoidance. Proximal Policy Optimization (PPO) outperformed Deep Q-Network (DQN) and Q-learning across all metrics, particularly in average and median steps to goal per episode. This study contributes to robotic navigation, AI and medical robotics, offering insights into the feasibility of AI-driven quadruped mobility and its role in assistive robotics.

Abstract: Robots are increasingly integrated across industries, particularly in
healthcare. However, many valuable applications for quadrupedal robots remain
overlooked. This research explores the effectiveness of three reinforcement
learning algorithms in training a simulated quadruped robot for autonomous
navigation and obstacle avoidance. The goal is to develop a robotic guide dog
simulation capable of path following and obstacle avoidance, with long-term
potential for real-world assistance to guide dogs and visually impaired
individuals. It also seeks to expand research into medical 'pets', including
robotic guide and alert dogs.
  A comparative analysis of thirteen related research papers shaped key
evaluation criteria, including collision detection, pathfinding algorithms,
sensor usage, robot type, and simulation platforms. The study focuses on sensor
inputs, collision frequency, reward signals, and learning progression to
determine which algorithm best supports robotic navigation in complex
environments.
  Custom-made environments were used to ensure fair evaluation of all three
algorithms under controlled conditions, allowing consistent data collection.
Results show that Proximal Policy Optimization (PPO) outperformed Deep
Q-Network (DQN) and Q-learning across all metrics, particularly in average and
median steps to goal per episode.
  By analysing these results, this study contributes to robotic navigation, AI
and medical robotics, offering insights into the feasibility of AI-driven
quadruped mobility and its role in assistive robotics.

</details>


### [230] [Latent Policy Steering with Embodiment-Agnostic Pretrained World Models](https://arxiv.org/abs/2507.13340)
*Yiqi Wang,Mrinal Verghese,Jeff Schneider*

Main category: cs.RO

TL;DR: 通过在多种机器人或人类玩耍数据上预训练世界模型，并结合潜在策略操纵技术，可以用更少的数据（例如30-50次演示）显著提高机器人的视觉-运动策略性能。


<details>
  <summary>Details</summary>
Motivation: 在机器人领域，通过模仿学习视觉-运动策略虽然有效，但对训练数据的数量有很高的要求，这在现实世界中需要昂贵的数据收集成本。本研究旨在通过利用来自多种机器人或人类玩耍对象的现有或低成本数据，来减少学习视觉-运动机器人策略时的数据收集工作。

Method: 使用光学流作为一种与具体实现无关的动作表示，跨多个数据集训练世界模型（WM），然后在目标机器人上进行微调；提出了一种潜在策略操纵（LPS）方法，通过在WM的潜在空间中搜索来改进行为克隆策略的输出。

Result: 在真实世界实验中，与仅使用少量数据训练的策略相比，结合了在公开的跨机器人数据集或人类玩耍数据集上预训练的世界模型（WM）的策略，在30次演示时性能有超过50%的相对提升，在50次演示时有超过20%的相对提升。

Conclusion: 通过结合使用在不同机器人或数据集中预训练的世界模型（WM）和行为克隆策略，并在仅有少量数据的情况下，可以显著提高学习到的视觉-运动策略的性能。

Abstract: Learning visuomotor policies via imitation has proven effective across a wide
range of robotic domains. However, the performance of these policies is heavily
dependent on the number of training demonstrations, which requires expensive
data collection in the real world. In this work, we aim to reduce data
collection efforts when learning visuomotor robot policies by leveraging
existing or cost-effective data from a wide range of embodiments, such as
public robot datasets and the datasets of humans playing with objects (human
data from play). Our approach leverages two key insights. First, we use optic
flow as an embodiment-agnostic action representation to train a World Model
(WM) across multi-embodiment datasets, and finetune it on a small amount of
robot data from the target embodiment. Second, we develop a method, Latent
Policy Steering (LPS), to improve the output of a behavior-cloned policy by
searching in the latent space of the WM for better action sequences. In real
world experiments, we observe significant improvements in the performance of
policies trained with a small amount of data (over 50% relative improvement
with 30 demonstrations and over 20% relative improvement with 50
demonstrations) by combining the policy with a WM pretrained on two thousand
episodes sampled from the existing Open X-embodiment dataset across different
robots or a cost-effective human dataset from play.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [231] [Theoretical modeling of the dynamic range of an elastic nanobeam under tension with a geometric nonlinearity](https://arxiv.org/abs/2507.12609)
*N. W. Welles,M. Ma,K. L. Ekinci,M. R. Paul*

Main category: physics.app-ph

TL;DR: A theoretical analysis of nanoscale beams shows a hinged model accurately describes dynamics, with bending important for higher modes. Findings align with experiments and aid micro/nanoscale tech development.


<details>
  <summary>Details</summary>
Motivation: This paper aims to theoretically describe the weakly nonlinear and mode-dependent dynamics of nanoscale beams under intrinsic tension, analyzing their dynamic range across various conditions. The research seeks to quantify the validity of different models (clamped beam, string model, hinged beam) and determine the interplay between bending and tension in the dynamics. Ultimately, the goal is to provide insights applicable to emerging micro and nanoscale technologies that leverage the multimodal dynamics of small elastic beams.

Method: A theoretical framework is established for the weakly nonlinear and mode-dependent dynamics of nanoscale beams under intrinsic tension. The analysis encompasses the beam's dynamic range, bounded by thermal motion from below and large-amplitude oscillations with geometric nonlinearity from above. Various models, including a clamped beam, a string model, and a hinged beam, are employed to analyze the dynamics, and their ranges of validity are quantified. The relative significance of bending and tension in mode-dependent dynamics is determined, indicating bending's importance for higher modes.

Result: The study quantifies the dynamic range of nanoscale beams, establishing lower bounds from thermal motion and upper bounds from large-amplitude oscillations dominated by geometric nonlinearity. It identifies a hinged beam model as highly accurate, providing useful closed-form analytical solutions. The research details how bending's importance increases with higher oscillation modes, influenced by intrinsic tension, and validates these theoretical predictions against experimental data for ten modes across two nanoscale beams.

Conclusion: For nanoscale beam dynamics, a hinged beam model provides accurate, closed-form analytical expressions across various conditions. Bending becomes significant for higher modes, with its importance depending on intrinsic tension. Theoretical predictions align well with experimental measurements for the first ten modes of two nanoscale beams. These findings are crucial for developing micro/nanoscale technologies utilizing multimodal dynamics of small elastic beams in the linear regime.

Abstract: A theoretical description of the weakly nonlinear and mode-dependent dynamics
of a nanoscale beam that is under intrinsic tension is developed. A full
analysis of the dynamic range of the beam over a wide range of conditions is
presented. The dynamic range is bounded from below by the amplitude of
vibration due to thermal motion and it is bounded from above by large amplitude
oscillations where the geometric nonlinearity plays a significant role due to
stretching induced tension. The dynamics are analyzed using a beam with clamped
boundaries, a string model, and a beam with hinged boundaries. The range of
validity for the different models is quantified in detail. A hinged beam model
is found to provide an accurate description, with insightful closed-form
analytical expressions, over a wide range of conditions. The relative
importance of bending and tension in the mode-dependent dynamics of the beam is
determined. Bending is shown to be important for the higher modes of
oscillation with the onset of its importance dependent upon the amount of
intrinsic tension that is present. The theoretical predictions are directly
compared with experimental measurements for the first ten modes of two
nanoscale beams. We discuss the accuracy of these approaches and their use for
the development of emerging micro and nanoscale technologies that exploit the
multimodal dynamics of small elastic beams operating in the linear regime.

</details>


### [232] [Consistency analysis and nuclear data validation for two series of beryllium reflector critical benchmark experiments](https://arxiv.org/abs/2507.12757)
*Shengli Chen,Tianxiang Wang*

Main category: physics.app-ph

TL;DR: 通过改进铍核反应数据，提高了基准实验的一致性，但仍存在系统性差异，HMF-058实验系列可能比HMF-066系列更可靠。


<details>
  <summary>Details</summary>
Motivation: 解决快谱临界基准实验HMF-058和HMF-066中观测到的铍核数据不一致问题，以提高核数据验证的准确性。

Method: 通过改进铍的(n,n)和(n,2n)反应的次级角分布来解决核数据不一致问题。

Result: 改进后的核数据使HMF-058和HMF-066系列实验的理论计算与实验结果更加一致，累积卡方值从7.58降至4.52（使用ENDF/B-VII.1），或降至4.36（使用最新的铀核数据评估）。所有计算结果均在1σ实验不确定度内与实验测量值吻合。但两组实验间仍存在系统性差异。

Conclusion: 本研究通过改进铍的(n,n)和(n,2n)反应的次级角分布，解决了HMF-058和HMF-066两个关键的快谱临界基准实验中的不一致问题。改进后的理论计算（C）与实验结果（E）更加吻合，累积卡方值从7.58降至4.52。采用最新的综合铀核数据评估后，卡方值进一步降至4.36。然而，两组实验在预期C/E值上仍存在系统性差异（HMF-066比HMF-058低230-330pcm），与实验不确定度（200-400pcm）相当，因此难以得出明确结论。如果改进后的铍微分核数据准确，那么HMF-058实验系列比HMF-066系列更可靠。

Abstract: Neutron-induced nuclear reaction data on beryllium playing a crucial role in
nuclear application. However, discrepancies have been observed in two closely
related series of beryllium-reflector fast-spectrum critical benchmark
experiments, HMF-058 and HMF-066, which are widely used in current nuclear data
validation. In this work, we address these inconsistencies by improving the
secondary angular distributions of the (n,n) and (n,2n) reactions of beryllium,
thereby making the theoretical calculations (C) and experimental results (E) of
these two series more consistent, and reducing the cumulative ${\chi^2}$ value
from 7.58 using the ENDF/B-VII.1 to 4.52. All calculations based on the
improved nuclear data agree with the experimental measurements within
1${\sigma}$ experimental uncertainty. Based on the latest comprehensive
evaluation of uranium nuclear data, this consistency is slightly improved, and
the cumulative ${\chi^2}$ value decreases to 4.36 once again. Despite these
advances, systematic differences in the expected values of C/E between the two
series still exist. The C/E values of the HMF-066 series are generally 230-330
pcm lower than those of the HMF-058 series, comparable to their experimental
uncertainties of 200-400 pcm. Therefore, drawing a definitive conclusion about
this systematic difference remains challenging. If the current improvement of
differential nuclear data based on experimental data of ${^9}$Be is accurate,
then the HMF-058 series experiments seem to be more reliable than the HMF-066
series.

</details>


### [233] [Wireless Multi-Port Sensing: Virtual-VNA-Enabled De-Embedding of an Over-the-Air Fixture](https://arxiv.org/abs/2507.12909)
*Philipp del Hougne*

Main category: physics.app-ph

TL;DR: 提出了一种无线测量多端口设备散射参数的新技术，并进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统方法难以在无线环境下测量多端口设备散射参数的问题，提出了一种新的无线测量技术。

Method: 开发了一种多端口反向散射调制技术，利用一组“不可直接访问”(NDA)天线和另一组“可访问”天线，通过无线方式测量多端口设备在不同连接状态下的散射参数，并去除无线环境的干扰，最终获得设备的散射参数。

Result: 在2.45 GHz下，对单端口和五端口设备进行了实验验证，并系统研究了可访问天线数量、系统模型简化以及可调负载网络特性对测量精度的影响。

Conclusion: 本研究提出了一种通过无线方式测量多端口设备散射参数的技术，并进行了实验验证，证明了其在RFID和无线生物电子等领域的应用潜力。

Abstract: We develop a multi-port-backscatter-modulation technique to determine, over
the air (OTA), the scattering parameters of a linear, passive, time-invariant
multi-port device under test (DUT). A set of "not-directly-accessible" (NDA)
antennas can be switched between being terminated by the DUT or by a specific,
known, tunable load network. Waves can be radiated and captured via a distinct
set of "accessible" antennas that couple OTA to the NDA antennas. First, we
characterize the OTA fixture between the accessible antennas' ports and the
DUT's ports. We achieve this based on our recently introduced "Virtual VNA"
technique; specifically, we connect the NDA antennas to the tunable load
network and measure the scattering at the accessible antennas' ports for
various configurations of the tunable load network. Second, we connect the NDA
antennas to the DUT and measure the scattering at the accessible antennas'
ports. Third, we de-embed the OTA fixture to retrieve the DUT's scattering
parameters. We experimentally validate our technique at 2.45 GHz for 1-port
DUTs and 5-port DUTs, considering a rich-scattering OTA fixture inside a
reverberation chamber. We systematically study the influence of the number of
accessible antennas and various conceivable simplifications in terms of the
system model as well as the properties of the tunable load network. Our
wireless multi-port sensing technique can find applications in areas like RFID
and wireless bioelectronics.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [234] [Nonreciprocal magnetic-field-induced second harmonic generation of exciton polaritons in ZnSe](https://arxiv.org/abs/2507.12572)
*J. Mund,D. R. Yakovlev,A. Farenbruch,N. V. Siverin,M. A. Semina,M. M. Glazov,E. L. Ivchenko,M. Bayer*

Main category: cond-mat.mes-hall

TL;DR: 在磁场作用下，ZnSe 晶体中的激子-极化激子表现出非倒易二次谐波（SHG）效应，这是首次在半导体晶体和激子-极化激子中观察到此现象。


<details>
  <summary>Details</summary>
Motivation: 研究磁场对 ZnSe 晶体中激子-极化激子共振的二次谐波（SHG）产生的影响，特别是磁场方向的非倒易依赖性。

Method: 通过施加垂直于光波矢量 k 的外磁场（Voigt 几何），在块状 ZnSe 的 1S 激子-极化激子共振下报告了二次谐波（SHG）的光学效应。通过 k || [111] 晶轴的对称允许几何，发现了 SHG 强度对磁场方向的非倒易依赖性。通过现象学和微观模型对此效应进行了阐述，并通过旋转各向异性图评估了这些信号的相对相位。

Result: 在 k || [111] 晶轴的几何下，观察到 SHG 强度对磁场方向的非倒易依赖性，并由晶体和磁场诱导的 SHG 信号的干涉进行了解释。评估了信号的相对相位。

Conclusion: 本工作首次在半导体晶体和激子-极化激子中观察到非倒易SHG效应。

Abstract: We report on the optical second harmonic generation (SHG) on the 1S
exciton-polariton resonance in bulk ZnSe that is subject to an external
magnetic field applied perpendicular to the light wave vector $\mathbf k$
(Voigt geometry). For the symmetry allowed geometry with the
$\mathbf{k}\parallel[111]$ crystal axes, the nonreciprocal dependence of the
SHG intensity on the magnetic field direction is found. It is explained by an
interference of the crystallographic and magnetic-field-induced SHG signals.
Relative phases of these signals are evaluated from the rotational anisotropy
diagrams. Phenomenological and microscopic models of the effect are developed.
To the best of our knowledge, this is the first experimental observation of the
nonreciprocal SHG in semiconductor crystals, and the first one for
exciton-polaritons.

</details>


### [235] [Spin Polarization driven by Itinerant Orbital Angular Momentum in van der Waals Heterostructures](https://arxiv.org/abs/2507.12587)
*Luis M. Canonico,Jose H. García,Aron W. Cummings,Stephan Roche*

Main category: cond-mat.mes-hall

TL;DR: 通过使用巡域OAM，我们发现了一种在范德华异质结构中产生垂直于平面的自旋极化，并控制磁性的新方法。


<details>
  <summary>Details</summary>
Motivation: 本文的目的是探索通过使用巡域轨道角动量（OAM）来操纵磁性材料，在范德华异质结构中产生垂直于平面的自旋极化。

Method: 我们使用实空间形式的OAM算符和线性响应理论，证明了在低对称性过渡金属二硫属化物（TMD）单分子层（如1T d -MoTe2）中，电流引起的巡域OAM比自旋响应大三个数量级。当TMD与固有OAM响应可忽略的铁磁体耦合时，由轨道Rashba-Edelstein效应产生的巡域OAM会跨越界面，产生能够引起铁磁体内磁化动力学的自旋密度。

Result: 在低对称性TMD单分子层中，电流诱导的巡域OAM比自旋响应大三个数量级。

Conclusion: 我们的发现强调了以前被忽视的巡域OAM在产生垂直于平面的自旋密度中的作用，这是一种用于低功耗、超紧凑型存储设备中磁性高效电控的新兴机制。

Abstract: We report on the possibility of manipulating magnetic materials by using
itinerant orbital angular momentum to produce out-of-plane spin polarization in
van der Waals heterostructures. Employing a real-space formulation of the OAM
operator within linear response theory, we demonstrate that in low-symmetry
transition-metal dichalcogenide (TMD) monolayers, such as 1$T{}_d$-MoTe2, the
current-induced itinerant OAM exceeds the spin response by three orders of
magnitude. When TMDs are coupled with ferromagnets with negligible intrinsic
orbital responses, the itinerant OAM generated by the orbital Rashba-Edelstein
effect transfers across the interface, generating spin densities capable of
inducing magnetization dynamics inside the ferromagnet. Our findings highlight
the previously overlooked role of itinerant OAM in the generation of
out-of-plane spin densities, which serves as an emerging mechanism for
efficient electrical control of magnetization in low-power, ultracompact
storage devices.

</details>


### [236] [Spin relaxation in a polariton fluid: quantum hydrodynamic approach](https://arxiv.org/abs/2507.12636)
*D. A. Saltykova,A. V. Yulin,I. A. Shelykh*

Main category: cond-mat.mes-hall

TL;DR: 腔极化子是量子微腔中的基本激发，具有独特的自旋结构和强非线性响应。本研究基于量子流体动力学方法，推导了描述自旋弛豫过程的方程组，并分析了这些过程对旋量极化子液滴和均匀极化子凝聚物基本激发色散的影响。


<details>
  <summary>Details</summary>
Motivation: 为了在强耦合状态下在量子微腔中出现空腔极化子，需要一种数学形式来连贯地描述自旋弛豫过程。

Method: 基于量子流体动力学方法，针对双组分液体，推导了能量和自旋弛豫项自然出现的方程组。

Result: 分析了这些项如何影响外部磁场中旋量极化子液滴的动力学以及均匀极化子凝聚物的基本激发色散。

Conclusion: 该方法可以应用于其他自旋玻色子凝聚物，其中自旋弛豫过程起着重要作用。

Abstract: Cavity polaritons, the elementary excitations appearing in quantum
microcavities in the strong-coupling regime, reveal clear signatures of quantum
collective behavior. The combination of unique spin structure and strong
nonlinear response opens the possibility of direct experimental observation of
a plethora of nontrivial optical polarization phenomena. Spin relaxation
processes are of crucial importance here. However, a mathematical formalism for
their coherent description is still absent. In the present paper, based on the
quantum hydrodynamics approach for a two-component liquid, we derive the set of
the corresponding equations where both energy and spin relaxation terms appear
naturally. We analyze in detail how these terms affect the dynamics of spinor
polariton droplets in the external magnetic field and the dispersion of
elementary excitations of a uniform polariton condensate. Although we focus on
the case of cavity polaritons, our approach can be applied to other cases of
spinor bosonic condensates, where the processes of spin relaxation play a major
role.

</details>


### [237] [Enhancement of Indistinguishable Photon Emission from a GaAs Quantum Dot via Charge Noise Suppression](https://arxiv.org/abs/2507.12641)
*Priyabrata Mudi,Avijit Barua,Kartik Gaur,Steffen Wilksen,Alexander Steinhoff,Setthanat Wijitpatima,Sarthak Tripathi,Julian Ritzmann,Andreas D. Wieck,Sven Rodt,Christopher Gies,Arne Ludwig,Stephan Reitzenstein*

Main category: cond-mat.mes-hall

TL;DR: 通过电场稳定 GaAs 量子点，大幅减少了由电荷噪声引起的激子退相干，实现了接近傅里叶极限的激子退相干时间和高可见度，为量子技术应用提供了关键支持。


<details>
  <summary>Details</summary>
Motivation: 外延量子点中的电荷噪声引起的频谱抖动会导致激子退相干，限制其在量子技术（如量子中继器网络和基于纠缠分发的分布式量子计算）中的实际应用。

Method: 研究人员提出了一种简单的方法来减轻液滴蚀刻的 GaAs 量子点中的电荷噪声引起的退相干。将量子点嵌入 n-i-p 二极管结构并确定性地集成到电接触的圆形布拉格光栅谐振器中，以增强发射。通过施加外部电场来稳定电荷环境，并测量了宏观双光子干涉的霍姆-曼德尔（Hong-Ou-Mandel）二光子干涉。

Result: 研究实现了 37 ±2% 的光子提取效率，并且通过霍姆-曼德尔二光子干涉测量发现，激子退相干时间和干涉可见度强依赖于所施加的偏压，这与理论预测高度一致。在准共振激发下，实现了 6.8 ±0.5 ns 的最大激子退相干时间（T2*），接近傅里叶极限。可见度在 1/I^2 关系下随二极管正向电流的增加而降低。

Conclusion: 该研究通过应用外部电场来稳定 GaAs 量子点中的电荷环境，从而减小了由电荷噪声引起的退相干效应。在准共振激发下，实现了接近傅里叶极限（T2 = 2T1）的 6.8 ±0.5 ns 的激子退相干时间，无需复杂的 Ramsey 或 Carr-Purcell-Meiboom-Gill 等回声方案。该器件在优化的偏压下，实现了 97% 的最大可见度，并且可见度随二极管电流（I）的增加而以 1/I^2 的依赖关系降低。

Abstract: The generation of indistinguishable single photons is a fundamental
requirement for future quantum technologies, particularly in quantum repeater
networks and for distributed quantum computing based on entanglement
distribution. However, spectral jitter, often induced by charge noise in
epitaxial quantum dots, leads to exciton dephasing, thereby limiting their
practical usage in quantum applications. We present a straightforward approach
to mitigate charge noise-induced decoherence in droplet-etched GaAs quantum
dots embedded in an n-i-p diode structure and integrated deterministically into
an electrically contacted circular Bragg grating resonator for emission
enhancement. The quantum device allows for the stabilization of the charge
environment by applying an external electrical field while producing a photon
extraction efficiency of approximately (37 +- 2)%. Hong-Ou-Mandel two-photon
interference measurements reveal a strong voltage dependence of the exciton
dephasing time and interference visibility on the applied bias in excellent
agreement with our theoretical predictions. Notably, the reduction in
visibility from a maximum, charge-stabilized corrected value of 97 percent at
the optimum bias point follows an inverse square dependence (proportional to
1/I^2) with increasing diode current (I) in forward direction. Under a
quasi-resonant excitation scheme, we achieve a maximum exciton dephasing time
(T2*) of approximately (6.8 +-0.5) ns, reaching nearly the Fourier limit (T2 =
2T1) without the need for complex echo schemes like Ramsey or
Carr-Purcell-Meiboom-Gill sequences. These findings are consistent with
theoretical predictions from rate equation modeling and quantum optical
analysis as well as voltage-dependent linewidth measurements, demonstrating
optimized electrical control of exciton dephasing.

</details>


### [238] [Collinear Antiferromagnetic Tunnel Junctions Implemented in Van der Waals Heterostructures](https://arxiv.org/abs/2507.12735)
*Wei-Min Zhao,Yi-Lun Liu,Liu Yang,Cheng Tan,Yuanjun Yang,Zhifeng Zhu,Meixia Chen,Tingting Yan,Rong Hu,James Partridge,Guopeng Wang,Mingliang Tian,Ding-Fu Shao,Lan Wang*

Main category: cond-mat.mes-hall

TL;DR: 通过使用范德华力A型反铁磁金属(Fe0.6Co0.4)5GeTe2和WSe2势垒构建全共线AFMTJ，实现了75%的TMR比率，并发现了一种新的界面效应TMR机制，证明了AFM材料在自旋电子学中的潜力。


<details>
  <summary>Details</summary>
Motivation: 为了提升自旋电子器件的速度和集成密度，该研究旨在探索利用反铁磁（AFM）化合物替代传统的铁磁（FM）材料来构建高性能的磁隧道结（MTJ）。

Method: 通过制备和表征基于范德华力A型反铁磁金属(Fe0.6Co0.4)5GeTe2（FCGT）电极和非磁性半导体WSe2隧道势垒的全共线反铁磁隧道结（AFMTJ）器件，并结合实验和理论分析，研究了其隧道磁电阻（TMR）效应及其与反铁磁（AFM）态和界面效应的关系。

Result: 研究成功制备了全共线AFMTJ，实现了高达75%的隧道磁电阻（TMR）比率，且TMR效应仅在FCGT的反铁磁态下出现，与反铁磁-铁磁转变无关。通过调控FCGT电极的层数，可以实现易失性或非易失性TMR，这与界面效应有关。偶数层器件的TMR源于N'eel矢量开关，奇数层器件的TMR源于界面自旋翻转。研究揭示了一种新的、与界面驱动的自旋极化传输相关的TMR机制，即使在体FCGT的自旋无关性质下也存在。

Conclusion: 该研究展示了全共线反铁磁隧道结（AFMTJ）的器件性能，其TMR比率可达75%，证明了AFM材料在自旋电子器件中的潜力，并提出了一种新的基于界面效应的TMR机制，为AFM自旋电子学开辟了新途径。

Abstract: Magnetic tunnel junctions (MTJs) are crucial components in high-performance
spintronic devices. Traditional MTJs rely on ferromagnetic (FM) materials but
significant improvements in speed and packing density could be enabled by
exploiting antiferromagnetic (AFM) compounds instead. Here, we report
all-collinear AFM tunnel junctions (AFMTJs) fabricated with van der Waals
A-type AFM metal (Fe0.6Co0.4)5GeTe2 (FCGT) electrodes and nonmagnetic
semiconducting WSe2 tunnel barriers. The AFMTJ heterostructure device achieves
a tunneling magnetoresistance (TMR) ratio of up to 75% in response to magnetic
field switching. Our results demonstrate that the TMR exclusively emerges in
the AFM state of FCGT, rather than during the AFM-to-FM transition. By
engineering FCGT electrodes with either even- or odd-layer configurations,
volatile or non-volatile TMR could be selected, consistent with an entirely
interfacial effect. TMR in the even-layer devices arose by N\'eel vector
switching. In the odd-layer devices, TMR stemmed from interfacial
spin-flipping. Experimental and theoretical analyses reveal a new TMR mechanism
associated with interface-driven spin-polarized transport, despite the
spin-independent nature of bulk FCGT. Our work demonstrates that all-collinear
AFMTJs can provide comparable performance to conventional MTJs and introduces a
new paradigm for AFM spintronics, in which the spin-dependent properties of AFM
interfaces are harnessed.

</details>


### [239] [Magnetoelectric multiferroics: from fundamentals to transformative applications -- a mini review](https://arxiv.org/abs/2507.12867)
*Michał Wanic*

Main category: cond-mat.mes-hall

TL;DR: 本文回顾了多铁材料的磁电效应，探讨了其各种机制、纳米结构增强以及在传感器、量子计算和能源等领域的应用。


<details>
  <summary>Details</summary>
Motivation: 多铁材料结合了铁电和磁有序，实现了磁电（ME）耦合，可用于高级应用。

Method: 本文回顾了单相和复合多铁材料，并研究了驱动磁电效应的现象学、微观、纳米结构和量子机制。现象学模型用于量化耦合系数，微观方法揭示了包括受阻自旋态和德热西-莫里亚贡献在内的自旋-晶格相互作用。纳米结构系统（如等离激元斯格明子晶格和超表面）增强了磁电效应，可实现可调双折射和电磁声子放大。量子热机利用手征链和斯格明子晶格中的自旋纠缠和拓扑保护来实现高效能量转换。

Result: 应用包括高灵敏度磁传感器、可调射频设备、节能MERAM、能量收集器、量子热机和热二极管。

Conclusion: 未来的研究旨在优化室温下的多铁性耦合、可扩展性、相干性和生物相容性，以推动传感、量子计算和可持续能源领域的创新。

Abstract: Multiferroics, combining ferroelectric and magnetic orders, enable
magnetoelectric (ME) coupling for advanced applications. This mini review
explores single-phase and composite multiferroics, examining phenomenological,
microscopic, nanostruc-tured, and quantum mechanisms driving ME effects.
Phenomenological models quantify coupling coefficients, while microscopic
approaches reveal spin-lattice in-teractions, including frustrated spin states
and Dzyaloshinskii-Moriya contributions. Nanostructured systems, such as
plasmonic skyrmion lattices and metasurfaces, en-hance ME effects for tunable
birefringence and electromagnon amplification. Quan-tum heat engines utilize
spin entanglement and topological protection in chiral chains and skyrmion
lattices for efficient energy conversion. Applications include high-sensitivity
magnetic sensors, tunable radio-frequency devices, energy-efficient MERAM,
energy harvesters, quantum heat engines, and thermal diodes. Future re-search
aims to optimize room-temperature ME coupling, scalability, coherence, and
biocompatibility for innovations in sensing, quantum computing, and sustainable
energy.

</details>


### [240] [Probing nontrivial fusion of Majorana zero modes via near-adiabatic coupling](https://arxiv.org/abs/2507.12772)
*Jing Bai,Luting Xu,Wei Feng,Xin-Qi Li*

Main category: cond-mat.mes-hall

TL;DR: 提出了一种近绝热耦合探测方案，用于融合Majorana零模，简化了测量过程，并能提取非绝热跃迁和费米子奇偶性违背信息。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有方案在探测量子点中电荷占有振荡复杂性的问题，使得实际测量更具可行性。

Method: 提出并模拟了一种近绝热耦合探测方案，用于非平凡融合一对Majorana零模（MZM）。

Result: 展示了如何从具有确定费米子奇偶性的初始态中提取移动MZM融合过程中发生的非绝热跃迁和费米子奇偶性违背信息。

Conclusion: 该方案可以避免探测量子点中电荷占有的振荡复杂性，使得实际测量更具可行性。

Abstract: We propose and simulate a near-adiabatically coupling probing scheme for
nontrivial fusion of a pair of Majorara zero modes (MZMs). The scheme can avoid
the complexity of oscillating charge occupation in the probing quantum dot,
making thus practical measurements more feasible. We also show how to extract
the information of nonadiabatic transition and fermion parity violation caused
during moving the MZMs together to fuse, from the initial states prepared with
definite fermion parity. All the simulations, including the effective coupling
between the fusing MZMs, and their coupling to the probing quantum dot, are
based on the lattice model of a Rashba quantum wire in proximity contact with
an s-wave superconductor, under the modulation of mini-gate voltage control.

</details>


### [241] [Three-dimensional spinless Euler insulators with rotational symmetry](https://arxiv.org/abs/2507.12783)
*Manabu Sato,Shingo Kobayashi,Motoaki Hirayama,Akira Furusaki*

Main category: cond-mat.mes-hall

TL;DR: 研究了具有 $C_{2z}T$ 对称性的三维绝缘体的欧拉类，重点关注 $C_{4z}$ 或 $C_{6z}$ 对称性情况，并推导了欧拉类与旋转特征值及不变量关系的解析公式，最后通过数值计算验证了理论结果。


<details>
  <summary>Details</summary>
Motivation: 研究三维自旋无关绝缘体的欧拉类，特别是在存在 $C_{4z}$ 或 $C_{6z}$ 旋转对称性的情况下，并探索欧拉类与旋转特征值之间的关系。

Method: 研究了具有 $C_{2z}T$ 对称性的三维无自旋绝缘体的欧拉类，并考虑了附加的 $C_{4z}$ 或 $C_{6z}$ 旋转对称性。我们推导了实贝里连接和曲率在点群操作下的变换规则，并得到了欧拉类与旋转特征值关系的显式公式。

Result: 我们得到了欧拉类与旋转特征值关系的显式公式，并为三维系统推导了欧拉类差异与受表示保护的不变量之间关系的解析表达式，并通过构建紧束缚模型和进行数值计算来验证。

Conclusion: 本研究推导了欧拉类与高对称点旋转特征值之间的显式公式，并将分析扩展到三维系统，推导了欧拉类差异与两种受表示保护的不变量之间的关系，并分析了它们的相变。

Abstract: The Euler class is a $\mathbb{Z}$-valued topological invariant that
characterizes a pair of real bands in a two-dimensional Brillouin zone. One of
the symmetries that permits its definition is $C_{2z}T$, where $C_{2z}$ denotes
a twofold rotation about the $z$ axis and $T$ denotes time-reversal symmetry.
Here, we study three-dimensional spinless insulators characterized by the Euler
class, focusing on the case where additional $C_{4z}$ or $C_{6z}$ rotational
symmetry is present, and investigate the relationship between the Euler class
of the occupied bands and their rotation eigenvalues. We first consider
two-dimensional systems and clarify the transformation rules for the real Berry
connection and curvature under point group operations, using the corresponding
sewing matrices. Applying these rules to $C_{4z}$ and $C_{6z}$ operations, we
obtain explicit formulas that relate the Euler class to the rotation
eigenvalues at high-symmetry points. We then extend our analysis to
three-dimensional systems, focusing on the difference in the Euler class
between the two $C_{2z}T$-invariant planes. We derive analytic expressions that
relate the difference in the Euler class to two types of
representation-protected invariants and analyze their phase transitions. We
further construct tight-binding models and perform numerical calculations to
support our analysis and elucidate the bulk-boundary correspondence.

</details>


### [242] [Coulomb-mediated single-electron heat transfer statistics across capacitively coupled silicon nanodots](https://arxiv.org/abs/2507.12799)
*Kensaku Chida,Antoine Andrieux,Katsuhiko Nishiguchi*

Main category: cond-mat.mes-hall

TL;DR: 本研究通过实验量化了纳米尺度上两个硅纳米点之间的库仑介导热传递，为探索器件功能和验证非平衡态下的普适关系提供了关键数据。


<details>
  <summary>Details</summary>
Motivation: 虽然已有实验演示利用库仑介导热传递的现象，但对其性能（如效率）的估算及其理论评估需要对传递机制本身进行定性评估，这仍然具有挑战性。

Method: 本实验通过估算两个静电耦合的硅纳米点之间的库仑相互作用强度，将单电子动力学转化为库仑介导热传递的统计数据。

Result: 本研究在平衡状态下进行了实验，获得了在两个点之间净零波动热传递。这些热传递统计数据对于从随机热力学的角度探索器件功能和验证非平衡态下的普适关系至关重要。

Conclusion: 本研究通过实验研究了两个静电耦合的硅纳米点之间的单电子动力学，以量化纳米尺度上的库仑介导热传递。通过估算库仑相互作用强度，将单电子动力学转化为库仑介导热传递的统计数据。在平衡状态下进行实验，获得了在两个点之间净零波动热传递，这些热传递统计数据对于从随机热力学的角度探索器件功能和验证非平衡态下的普适关系至关重要。

Abstract: Heat transfer mediated by the Coulomb interaction reveals unconventional
thermodynamic behavior and broadens thermodynamics research into fields such as
quantum dynamics and information engineering. Although some experimental
demonstrations of phenomena utilizing Coulomb-mediated heat transfer have been
reported, estimations of their performance, such as efficiency, and their
theoretical evaluations necessitate qualitative evaluation of the transfer
mechanism itself, which remains challenging. We present an experiment
investigating single-electron dynamics in two electrostatically coupled silicon
nanodots to quantify Coulomb-mediated heat transfer at the nanoscale. By
estimating the Coulomb interaction strength between the dots using the
cross-correlation measurements of the single-electron dynamics, we convert the
single-electron dynamics into the statistics of Coulomb-mediated heat transfer.
Conducting the experiment at equilibrium enabled us to obtain a fluctuating
net-zero heat transfer between the dots. These heat transfer statistics are
essential for exploring device functionalities from the perspective of
stochastic thermodynamics and for verifying universal relations in
nonequilibrium states.

</details>


### [243] [Harmonic generation of graphene quantum dots in Hartree-Fock approximation](https://arxiv.org/abs/2507.12982)
*Kainan Chang,Ying Song,Yuwei Shan,Jin Luo Cheng*

Main category: cond-mat.mes-hall

TL;DR: 研究了石墨烯量子点中的激子效应及其对谐波产生的影响，发现其光学响应和可调性。


<details>
  <summary>Details</summary>
Motivation: 理论研究了在ld线性偏振光脉冲下石墨烯量子点中的谐波产生，重点关注了激子效应。

Method: 结合紧束缚模型和单粒子密度矩阵方法，推导了在静态屏蔽Hartree-Fock近似下的半导体Bloch方程。

Result: 激子效应显著增强了石墨烯纳米结构的や光学响应。对于由随机取向的石墨烯量子点形成的や点系，只有奇次谐波沿着入射光y的偏振方向存在。

Conclusion: 石墨烯量子点的谐波产生对其几何构型具有高度可调性，使其成为非线性光学纳米器件的有希望的候选者。

Abstract: We theoretically investigate harmonic generation in graphene quantum dots
under linearly polarized optical pulses, focusing on excitonic effects.
Combining the tight-binding model and the single-particle density matrix
approach, we derive a semiconductor Bloch equation under a static-screened
Hartree-Fock approximation. This framework characterizes the electron-electron
interaction through local Hartree potentials for direct Coulomb interaction and
nonlocal Fock potentials for exchange interaction. Distinct confgurations of
Hartree and Fock terms yield various approximation methods, including
independent-particle approximation, mean-feld approximation, random phase
approximation, and excitonic effects. We thoroughly analyze how these
approximation methods affect the electronic energy levels, linear optical
absorption, and nonlinear harmonic generation. Within excitonic effects, we
present the dependence of harmonic generation on the geometric variations of
graphene quantum dots (sizes, triangular/hexagonal shapes, and armchair/zigzag
edges) and the amplitude and polarization of electric fields. Our findings show
that excitonic effects significantly enhance optical responses of graphene
nanostructures. For a dot ensemble formed by randomly oriented graphene quantum
dots,
  only odd-order harmonics exist along the polarization direction of the
incident light. Crucially, harmonic generation in graphene quantum dots
exhibits high tunability via geometric configuration, making them promising
candidates for nonlinear optical nanodevices.

</details>


### [244] [Enhanced Phonon-Assisted Tunneling in Metal -- Twisted Bilayer Graphene Junctions](https://arxiv.org/abs/2507.12991)
*Radhika Soni,Suvronil Datta,Robin Bajaj,Saisab Bhowmik,Shinjan Mandal,Baladitya Suri,Kenji Watanabe,Takashi Taniguchi,Manish Jain,U. Chandni*

Main category: cond-mat.mes-hall

TL;DR: 研究人员使用平面隧道光谱法研究了金属-WSe2-扭曲双层石墨烯异质结构。他们发现扭曲双层石墨烯中的声子辅助隧穿比伯纳尔双层石墨烯更强，这可能是因为面内动量匹配标准更宽松。该技术可用于研究扭曲范德华材料中的电子-声子耦合。


<details>
  <summary>Details</summary>
Motivation: 探索扭曲双层石墨烯中增强的声子辅助隧穿现象，并阐明其潜在机制。

Method: 通过广泛的栅极和偏压电压测量金属-WSe2-扭曲双层石墨烯异质结构。

Result: 观察到的实验特征归因于声子辅助隧穿和莫尔条带内显着高的态密度。扭曲双层石墨烯中声子辅助隧穿得到增强，这源于更宽松的面内动量匹配标准。成功识别了伯纳尔和扭曲双层石墨烯中的低能声子模式。

Conclusion: 该研究将平面隧道光谱法确立为一种理解扭转范德华材料中电子-声子耦合的通用工具。

Abstract: We report planar tunneling spectroscopy measurements on metal-WSe$_2$-twisted
bilayer graphene heterostructures across a broad range of gate and bias
voltages. The observed experimental features are attributed to phonon-assisted
tunneling and the significantly high density of states within the moir\'e
bands. A notable finding is the enhanced phonon-assisted tunneling in twisted
bilayer graphene compared to Bernal bilayer graphene, which arises from a more
relaxed in-plane momentum matching criterion. Theoretical calculations of
phonon dispersions enable us to identify low-energy phonon modes in both Bernal
and twisted bilayers of graphene, thereby elucidating the underlying mechanism
of tunneling. Our results establish planar tunneling as a versatile tool to
further understand electron-phonon coupling in twisted van der Waals materials.

</details>


### [245] [Ultrafast thermal boundary conductance under large temperature discontinuities of ultrathin epitaxial Pb films on Si(111)](https://arxiv.org/abs/2507.13109)
*Christian Brand,Tobias Witte,Mohammad Tajik,Jonas D. Fortmann,Birk Finke,Michael Horn-von Hoegen*

Main category: cond-mat.mes-hall

TL;DR: 研究了Pb薄膜到Si衬底的热传递，发现散热速度与激发强度和界面形貌有关。


<details>
  <summary>Details</summary>
Motivation: 为了在电子器件中实现更快的速度、更小的尺寸、更强的功率以及更高的性能和效率，需要深入理解纳米尺度结构中热传递的物理机制，特别是界面处的热传递。

Method: 使用超快电子衍射和激光脉冲技术，在强非平衡条件下研究了超薄外延Pb薄膜到Si(111)衬底的热传递。

Result: 在强非平衡条件下，观察到Pb薄膜的散热时间常数随激发强度的增加而显著减小。通过漫失匹配模型解释了散热时间常数的减小，并发现热边界电导比在H终止衬底上生长的Pb薄膜低三倍以上。

Conclusion: 使用超快电子衍射研究了非平衡条件下Pb薄膜到Si(111)衬底的热传递，结果表明散热时间常数随激发强度增加而减小，这可以通过热边界电导来解释，并且热边界电导比在H终止衬底上生长的Pb薄膜低三倍以上，这表明了衬底、薄膜及其界面的形貌的重要性。

Abstract: Heat transfer is a critical aspect of modern electronics, and a deeper
understanding of the underlying physics is essential for building faster,
smaller, and more powerful devices with an improved performance and efficiency.
In such nanoscale structures the heat transfer between two materials is limited
by the finite thermal boundary conductance across their interface. Using
ultrafast electron diffraction under grazing incidence we investigated the heat
transfer from ultrathin epitaxial Pb films to an Si(111) substrate under strong
non-equilibrium conditions. Applying an intense femtosecond laser pulse, the
5-7 ML thin Pb film experiences a strong heat up by 10-120 K while the Si
substrate remains cold at $\approx$ 10 K. At such large temperature
discontinuities we observe a significantly faster cooling for stronger excited
Pb films. The decrease of the corresponding cooling time constant is explained
through the thermal boundary conductance in the framework of the diffuse
mismatch model. The thermal boundary conductance is reduced by more than a
factor of three in comparison with Pb films grown on H-terminated substrates,
pointing out the importance of the morphology of substrate, film and their
interface.

</details>


### [246] [Comparative Study of Strain-Engineered Thermoelectric Performance of 2D-Xene Nanoribbons](https://arxiv.org/abs/2507.13132)
*Kalpana Panneerselvam,Swastik Sahoo,Bhaskaran Muralidharan*

Main category: cond-mat.mes-hall

TL;DR: 该研究系统地分析了五种准一维纳米带材料的热电性能，重点关注应变和宽度对热电势的影响，并强调了磷烯作为一种有前途的热电材料的潜力。


<details>
  <summary>Details</summary>
Motivation: 为了寻找高效且可扩展的热电材料，对准一维纳米带进行了深入研究，因为其低维特性和结构可调性能够解耦关键的输运参数以提高能量转换效率。

Method: 使用第一性原理计算参数化的紧束缚模型，并结合 Landauer-Buttiker 形式主义，计算了由五种典型的二维材料（石墨烯、硅烯、锗烯、锡烯和磷烯）衍生的扶手椅纳米带的应变和宽度相关的热电势。

Result: 研究发现，热电性能受到带隙演化、化学势不对称和量子限制等因素的复杂相互作用的影响。石墨烯和硅烯在适度应变下表现出明显的与族和宽度相关的热电势增强，而锗烯和锡烯等较重的 Xenes 材料响应减弱。特别是磷烯纳米带表现出色，具有非常高的热电势（62 kB/e），这归因于其宽大且持续存在的带隙以及各向异性的电子结构。在所有研究的系统中，3p+2 族在应变作用下从近金属态转变为半导体态，从而在先前不活跃的构型中实现了热电势的显著激活。

Conclusion: 研究结果表明，磷烯表现出优异的单原子层材料热电性能，而应变狄米歇尔纳米带则是有希望的低维热电装置候选材料。

Abstract: The quest for efficient and scalable thermoelectric materials has catalyzed
intense interest in quasi 1D nanoribbons, where reduced dimensionality and
structural tunability can decouple key transport parameters to enhance energy
conversion. In this work, we present a unified comparative study of the
thermopower in armchair nanoribbons derived from five archetypal 2D materials:
graphene, silicene, germanene, stanene and phosphorene. Using a tight binding
model parametrized by first principles inputs and solved within the Landauer
Buttiker formalism, we compute strain and width dependent thermopower across
nanoribbons classified by width families (3p, 3p+1, 3p+2) over a wide range of
uniaxial tensile strain. Our results reveal that thermoelectric behavior is
governed by a complex interplay of bandgap evolution, chemical potential
asymmetry, and quantum confinement. While graphene and silicene exhibit
pronounced family and width sensitive thermopower enhancement under moderate
strain, heavier Xenes such as germanene and stanene show diminished responses.
In particular, phosphorene nanoribbons emerge as exceptional, exhibiting
remarkably high thermopower (62 kB/e), a consequence of their large, persistent
bandgap and anisotropic electronic structure. Across all systems, the 3p+2
family transitions from near-metallic to semiconducting under strain, enabling
dramatic activation of thermopower in previously inactive configurations. This
systematic cross material analysis delineates the design principles for the
optimization of TE in 1D nanoribbons, highlighting the strategic use of width
control and strain engineering. Our findings identify phosphorene as an
intrinsically superior thermoelectric material and position strained Xene
nanoribbons as promising candidates for tunable, low-dimensional thermoelectric
devices.

</details>


### [247] [Improving photovoltaics by adding extra terminals to extract hot carriers](https://arxiv.org/abs/2507.13279)
*Bruno Bertin-Johannet,Thibaut Thuégaz,Janine Splettstoesser,Robert S. Whitney*

Main category: cond-mat.mes-hall

TL;DR: 四端子光伏电池比双端子电池有更高的功率输出。


<details>
  <summary>Details</summary>
Motivation: 为了提高光伏电池的功率输出。

Method: 提出了一种利用非平衡分布的多端子热电器件。

Result: 四端子电池的功率输出比最佳双端子电池高40%以上。

Conclusion: 四端子光伏电池比最佳双端子电池具有更高的功率输出，并且能量过滤端子可以收集“热”载流子，而其他端子则收集低能量载流子。

Abstract: Photovoltaic cells usually have two terminals, one collecting electrons and
the other collecting holes. Can more terminals improve such solar cells?
Energy-filtering terminals could collect "hot" carriers (electrons or holes not
yet relaxed to the band edge), with other terminals for low-energy carriers.
For collection faster than carrier-phonon relaxation, we predict four-terminal
cells with higher power output than optimal two-terminal cells -- more than 40%
higher for fast carrier collection. Similar effects will occur in
multi-terminal thermoelectrics exploiting non-equilibrium distributions

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [248] [Model Predictive Black Start for Dynamic Formation of DER-Led Microgrids with Inrush Current Impacts](https://arxiv.org/abs/2507.12569)
*Cong Bai,Salish Maharjan,Zhaoyu Wang*

Main category: eess.SY

TL;DR: 高渗透率分布式能源的配电系统黑启动需要先进的控制框架。本文提出了一个模型预测黑启动（MPBS）框架，该框架包含一个涌流约束可行性模块，可以动态地生成实时可行和最优的恢复序列。此外，还提出了一种受紧急运行启发的电压控制策略和开关阻塞机制，以缓解过度涌流并避免保护设备误操作。该框架在IEEE 123节点测试馈线上的案例研究表明，它可以防止熔断器和重合器的误操作，减少不必要的DER能量消耗，并提高DER驱动的黑启动过程中的负载恢复效率。


<details>
  <summary>Details</summary>
Motivation: 为了确保高渗透率分布式能源（DER）的配电系统（DS）在黑启动（BS）过程中安全高效地恢复。

Method: 提出了一种包含涌流约束可行性模块的模型预测黑启动（MPBS）框架，并结合了紧急运行电压控制策略和开关阻塞机制。

Result: MPBS框架可防止熔断器和重合器的误操作，减少不必要的DER能量消耗，并提高DER驱动的BS过程中负载恢复的效率。在IEEE 123节点测试馈线上的案例研究验证了该框架的有效性。

Conclusion: 该模型预测黑启动框架通过包含涌流约束可行性模块，可以动态生成实时可行和最优的恢复序列，并通过采用电压控制策略和开关阻塞机制来缓解过度的涌流，避免保护设备误操作。

Abstract: Black start (BS) of the distribution system (DS) with high penetration of
distributed energy resources (DERs) requires advanced control frameworks to
ensure secure and efficient restoration. This paper proposes a model predictive
black start (MPBS) framework incorporating an inrush current feasibility module
to dynamically generate real-time feasible and optimal restoration sequences.
Short-term forecasts of DER output and transmission grid (TG) availability are
utilized to construct adaptive cranking paths. The inrush current feasibility
module analytically estimates the transient inrush current caused by energizing
no-load distribution transformers (DTs). To mitigate excessive inrush current
and avoid potential misoperations of protection devices, an emergency
operation-inspired voltage control strategy and a switch blocking mechanism are
developed. The proposed inrush model is validated against electromagnetic
transient (EMT) simulations in PowerFactory with estimation accuracies
exceeding 90 %. Case studies on a modified IEEE 123-node feeder demonstrate
that the MPBS framework prevents misoperations of fuses and reclosers, reduces
unnecessary DER energy consumption, and enhances load restoration efficiency
during DER-led BS processes.

</details>


### [249] [Deep Bilinear Koopman Model for Real-Time Vehicle Control in Frenet Frame](https://arxiv.org/abs/2507.12578)
*Mohammad Abtahi,Farhang Motallebi Araghi,Navid Mojahed,Shima Nazari*

Main category: eess.SY

TL;DR: 提出了一种深度koopman方法，用于车辆动力学建模和控制，并结合累积误差调节器，在保证实时性的同时提高了跟踪精度。


<details>
  <summary>Details</summary>
Motivation: 为了解决自动驾驶车辆动力学模型非线性、耦合性强，导致精确建模和控制的挑战，同时弥合koopman算子理论在学习高保真模型有限维不变子空间方面的现有问题。

Method: 提出了一种深度koopman方法，使用深度神经网络学习koopman算子及其不变子空间，并结合累积误差调节器（CER）模块来补偿模型失配。

Result: 该框架能够学习koopman算子及其不变子空间，捕捉输入状态双线性相互作用，同时保持凸性，适用于实时模型预测控制（MPC）。通过多步预测损失进行训练，保证了长时预测能力。

Conclusion: 该方法在硬件在环（HIL）实验中，与基线控制器相比，显著降低了跟踪误差，证明了其在嵌入式自动驾驶系统中的实时实现能力。

Abstract: Accurate modeling and control of autonomous vehicles remain a fundamental
challenge due to the nonlinear and coupled nature of vehicle dynamics. While
Koopman operator theory offers a framework for deploying powerful linear
control techniques, learning a finite-dimensional invariant subspace for
high-fidelity modeling continues to be an open problem. This paper presents a
deep Koopman approach for modeling and control of vehicle dynamics within the
curvilinear Frenet frame. The proposed framework uses a deep neural network
architecture to simultaneously learn the Koopman operator and its associated
invariant subspace from the data. Input-state bilinear interactions are
captured by the algorithm while preserving convexity, which makes it suitable
for real-time model predictive control (MPC) application. A multi-step
prediction loss is utilized during training to ensure long-horizon prediction
capability. To further enhance real-time trajectory tracking performance, the
model is integrated with a cumulative error regulator (CER) module, which
compensates for model mismatch by mitigating accumulated prediction errors.
Closed-loop performance is evaluated through hardware-in-the-loop (HIL)
experiments using a CarSim RT model as the target plant, with real-time
validation conducted on a dSPACE SCALEXIO system. The proposed controller
achieved significant reductions in tracking error relative to baseline
controllers, confirming its suitability for real-time implementation in
embedded autonomous vehicle systems.

</details>


### [250] [Joint Price and Power MPC for Peak Power Reduction at Workplace EV Charging Stations](https://arxiv.org/abs/2507.12703)
*Thibaud Cambronne,Samuel Bobick,Wente Zeng,Scott Moura*

Main category: eess.SY

TL;DR: 通过优化价格和功率控制，降低电动汽车充电站的峰值用电，从而节省成本。


<details>
  <summary>Details</summary>
Motivation: 商业电动汽车充电站运营商面临高昂的电力成本，其中需求电费占很大一部分。

Method: 提出了一种结合价格和功率优化的联合框架，并设计了几种优化解决方案以降低需求电费和运营总成本。

Result: 基于时间序列预测的模型预测控制能显著降低充电站运营商的成本。

Conclusion: 该研究提出了一种结合价格和功率优化的联合框架，以降低工作场所电动汽车充电站的峰值功率消耗，并通过蒙特卡洛模拟验证了基于时间序列预测的模型预测控制的有效性。

Abstract: Demand charge often constitutes a significant portion of electricity costs
for commercial electric vehicle charging station operators. This paper explores
control methods to reduce peak power consumption at workplace EV charging
stations in a joint price and power optimization framework. We optimize a menu
of price options to incentivize users to select controllable charging service.
Using this framework, we propose several solutions to achieve a reduction in
both demand charge and overall operator costs. Through a Monte Carlo
simulation, we find that model predictive control using a time series forecast
can significantly reduce station operator costs.

</details>


### [251] [A Stackelberg Game of Demand Response from the Aggregator's Perspective](https://arxiv.org/abs/2507.12708)
*Seangleng Khe,Parin Chaipunya,Athikom Bangviwat*

Main category: eess.SY

TL;DR: 本论文研究了聚合商与消费者之间的需求响应活动建模，提出了一种双层模型，证明了其在负荷控制和降低成本方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 研究聚合商与多个参与消费者之间需求响应活动的建模。

Method: 提出了一种包含信息结构和决策序列的双层模型，其中聚合商扮演领导者角色，参与的消费者扮演跟随者角色。

Result: 该模型在负荷控制方面被证明是有效的，有助于聚合商满足目标削减，同时消费者支付更低的电费账单。

Conclusion: 该模型在负荷控制方面是有效的，有助于聚合商实现目标削减，同时降低消费者的电费。

Abstract: In this paper, we investigate on the modeling of demand response activities
between the single aggregator and multiple participating consumers. The model
incorporates the bilevel structure that naturally occurs in the information
structure and decision sequence, where the aggregator assumes the role of a
leader and the participating consumers play the role of followers. The proposed
model is demonstrated to be effective in load control, helping the aggregator
to meet the target reduction while the consumers pay cheaper electricity bill.

</details>


### [252] [On the Properties of Optimal-Decay Control Barrier Functions](https://arxiv.org/abs/2507.12717)
*Pio Ong,Max H. Cohen,Tamas G. Molnar,Aaron D. Ames*

Main category: eess.SY

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Control barrier functions provide a powerful means for synthesizing safety
filters that ensure safety framed as forward set invariance. Key to CBFs'
effectiveness is the simple inequality on the system dynamics: $\dot{h} \geq -
\alpha(h)$. Yet determining the class $\mathcal{K}^e$ function $\alpha$ is a
user defined choice that can have a dramatic effect on the resulting system
behavior. This paper formalizes the process of choosing $\alpha$ using
optimal-decay control barrier functions (OD-CBFs). These modify the traditional
CBF inequality to: $\dot{h} \geq - \omega \alpha(h)$, where $\omega \geq 0$ is
automatically determined by the safety filter. A comprehensive characterization
of this framework is elaborated, including tractable conditions on OD-CBF
validity, control invariance of the underlying sets in the state space, forward
invariance conditions for safe sets, and discussion on optimization-based safe
controllers in terms of their feasibility, Lipschitz continuity, and
closed-form expressions. The framework also extends existing higher-order CBF
techniques, addressing safety constraints with vanishing relative degrees. The
proposed method is demonstrated on a satellite control problem in simulation.

</details>


### [253] [Invariance Guarantees using Continuously Parametrized Control Barrier Functions](https://arxiv.org/abs/2507.12743)
*Inkyu Jang,H. Jin Kim*

Main category: eess.SY

TL;DR: 提出了一种基于连续参数化控制障碍函数（PCBF）的安全控制框架，通过动态选择参数来适应复杂的安全空间，并推导了PCBF-QP控制器，通过仿真验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决在安全关键控制中构建形状合适且位于给定状态约束内的控制不变集的难题，特别是在处理大或复杂空间时。

Method: 利用连续参数化的控制障碍函数（PCBF）来构建控制不变集，并通过动态选择参数来确保安全。推导了基于二次规划（QP）的轻量级反馈控制器（PCBF-QP），并讨论了如何为一类系统构建有效的PCBF以及如何约束参数以确保不变集不超出安全边界。该概念还扩展到高阶控制障碍函数（高阶PCBF）。

Result: 仿真实验验证了所提出的PCBF框架和PCBF-QP控制器在安全控制方面的有效性。

Conclusion: 该方法能够处理复杂和高维度的环境，并且易于适应不同的场景。

Abstract: Constructing a control invariant set with an appropriate shape that fits
within a given state constraint is a fundamental problem in safety-critical
control but is known to be difficult, especially for large or complex spaces.
This paper introduces a safe control framework of utilizing PCBF: continuously
parametrized control barrier functions (CBFs). In PCBF, each choice of
parameter corresponds to a control invariant set of relatively simple shape.
Invariance-preserving control is done by dynamically selecting a parameter
whose corresponding invariant set lies within the safety bound. This eliminates
the need for synthesizing a single complex CBF that matches the entire free
space. It also enables easier adaptation to diverse environments. By assigning
a differentiable dynamics on the parameter space, we derive a lightweight
feedback controller based on quadratic programming (QP), namely PCBF-QP. We
also discuss on how to build a valid PCBF for a class of systems and how to
constrain the parameter so that the invariant set does not exceed the safety
bound. The concept is also extended to cover continuously parametrized
high-order CBFs, which is called high-order PCBF. Finally, simulation
experiments are conducted to validate the proposed approach.

</details>


### [254] [Latency-Optimal File Assignment in Geo-Distributed Storage with Preferential Demands](https://arxiv.org/abs/2507.12830)
*Srivathsa Acharya,P. Vijay Kumar,Viveck R. Cadambe*

Main category: eess.SY

TL;DR: 研究了地理分布式网络中的数据存储问题，提出了一种通过顶点着色和平衡分配来优化文件放置以最小化延迟的方案。


<details>
  <summary>Details</summary>
Motivation: 在地理分布式网络中，服务器节点间的通信存在往返延迟。当用户请求的文件不在本地节点时，需要与其他节点通信，从而导致用户体验到延迟。本研究旨在优化文件在节点上的放置，以最小化每个节点的最差情况延迟和系统平均延迟。

Method: 本篇论文首先将最差情况延迟约束建模为顶点着色问题，然后将系统平均延迟优化转化为平衡分配问题。

Result: 研究了非均匀文件需求概率下的通用情况，并提出了一种最优的无码方案。

Conclusion: 本篇论文提出的方案在无码方案家族中是最优的。

Abstract: We consider the problem of data storage in a geographically distributed (or
geo-distributed) network of servers (or nodes) where inter-node communication
incurs certain round-trip delays. Every node serves a set of users who can
request any file in the network. If the requested file is not available at the
node, it communicates with other nodes to obtain the file, thus causing the
user to experience latency in obtaining the file. The files can be placed
uncoded, where each node stores exact copies of the files, or in coded fashion,
where certain linear combination of files are placed at each node. We aim to
obtain an optimal file placement on the nodes with respect to minimizing the
worst-case latency at each node, as well as the system-average latency. The
prior literature considered the case of equiprobable file demands at the nodes.
In this paper, we investigate the generic case of non-uniform file-demand
probabilities at each node. The scheme presented here is optimal within the
family of uncoded schemes. It is obtained first by modeling the worst-case
latency constraint as a vertex coloring problem, and then converting the
system-average latency optimization to a problem of balanced-assignment.

</details>


### [255] [Guaranteeing and Explaining Stability across Heterogeneous Load Balancing using Calculus Network Dynamics](https://arxiv.org/abs/2507.12892)
*Mengbang Zou,Yun Tang,Adolfo Perrusquía,Weisi Guo*

Main category: eess.SY

TL;DR: 该研究提出了一种新的微积分动力学方法来解决蜂窝网络中基站间负载均衡的振荡问题，通过分析网络拓扑和动力学特性，提出了一种可以提高效率、保证收敛或缓解振荡的解决方案。


<details>
  <summary>Details</summary>
Motivation: 目前的数据驱动机制在平衡基站间负载和减少不必要切换方面存在挑战，因为在大量基站中，网络的负载演变会出现振荡效应，导致基站间通信量增大。现有的算法无法解释这种现象，也无法提供理想同步状态稳定性的理论保证。

Method: 将数据驱动的算法抽象到微积分动力学空间中，并结合“非保守误差”和网络动力学的特征值谱。

Result: 建立了具有任何网络拓扑的负载均衡动力学的同步条件，并提出了调整负载均衡机制以实现高效率、收敛保证或缓解振荡的方法。

Conclusion: 通过将数据驱动的算法抽象到微积分动力学空间中，我们可以为具有任何网络拓扑的负载均衡动力学建立同步条件。通过结合“非保守误差”和网络动力学的特征值谱，我们可以调整基站间的负载均衡机制，以实现高效率和收敛保证，或者在无法满足同步条件时缓解振荡。

Abstract: Load balancing between base stations (BSs) allows BS capacity to be
efficiently utilised and avoid outages. Currently, data-driven mechanisms
strive to balance inter-BS load and reduce unnecessary handovers. The challenge
is that over a large number of BSs, networks observe an oscillatory effect of
load evolution that causes high inter-BS messaging. Without a calculus function
that integrates network topology to describe the evolution of load states,
current data-driven algorithms cannot explain the oscillation phenomenon
observed in load states, nor can they provide theoretical guarantees on the
stability of the ideal synchronised state. Whilst we know load state
oscillation is coupled with the load balancing process algorithms and the
topology structure of inter-BS boundary relations, we do not have a theoretical
framework to prove this and a pathway to improving load balancing algorithms.
Here, we abstract generic and heterogeneous data-driven algorithms into a
calculus dynamics space, so that we can establish the synchronization
conditions for networked load balancing dynamics with any network topology. By
incorporating what is known as "non-conservative error" and the eigenvalue
spectrum of the networked dynamics, we can adjust the inter-BS load balancing
mechanisms to achieve high efficiency and convergence guarantee, or to mitigate
the oscillation when the synchronisation condition cannot be satisfied.

</details>


### [256] [Learning-Based Cost-Aware Defense of Parallel Server Systems against Malicious Attacks](https://arxiv.org/abs/2507.12975)
*Yuzhen Zhan,Li Jin*

Main category: eess.SY

TL;DR: 研究提出了一种用于并行服务器系统网络物理安全的新型学习算法，该算法能够通过近似最小-最大Q学习来计算防御策略，以平衡防御成本和网络攻击造成的性能下降。


<details>
  <summary>Details</summary>
Motivation: 研究网络物理安全在多种工程应用（如网络、制造和交通）中具有重要意义，特别是针对依赖反馈控制的并行服务器系统，这些系统容易受到拒绝服务、数据伪造和指令操纵等恶意网络攻击。

Method: 本研究提出了一种近似最小-最大Q学习算法，该算法利用可解释的线性函数逼近来计算零和马尔可夫博弈的均衡，从而获得成本感知的防御策略。 Lyapunov方法被用来处理由无限状态空间引起的无限时间差误差，而常微分方程则用于建立收敛性。

Result: 仿真结果表明，该算法的收敛速度明显优于基于神经网络的方法，并且具有很小的最优性差距。

Conclusion: 该算法在温和假设下，以概率一收敛到近似马尔可夫遍历均衡，并通过仿真证明了其收敛速度约是基于神经网络的方法的50倍，最优性差距在4%-8%之间。

Abstract: We consider the cyber-physical security of parallel server systems, which is
relevant for a variety of engineering applications such as networking,
manufacturing, and transportation. These systems rely on feedback control and
may thus be vulnerable to malicious attacks such as denial-of-service, data
falsification, and instruction manipulations. In this paper, we develop a
learning algorithm that computes a defensive strategy to balance technological
cost for defensive actions and performance degradation due to cyber attacks as
mentioned above. We consider a zero-sum Markov security game. We develop an
approximate minimax-Q learning algorithm that efficiently computes the
equilibrium of the game, and thus a cost-aware defensive strategy. The
algorithm uses interpretable linear function approximation tailored to the
system structure. We show that, under mild assumptions, the algorithm converges
with probability one to an approximate Markov perfect equilibrium. We first use
a Lyapunov method to address the unbounded temporal-difference error due to the
unbounded state space. We then use an ordinary differential equation-based
argument to establish convergence. Simulation results demonstrate that our
algorithm converges about 50 times faster than a representative neural
network-based method, with an insignificant optimality gap between 4\%--8\%,
depending on the complexity of the linear approximator and the number of
parallel servers.

</details>


### [257] [Fractional-order controller tuning via minimization of integral of time-weighted absolute error without multiple closed-loop tests](https://arxiv.org/abs/2507.12987)
*Ansei Yonezawa,Heisei Yonezawa,Shuichi Yahagi,Itsuro Kajiwara,Shinya Kijimoto*

Main category: eess.SY

TL;DR: 提出了一种新的非迭代整定技术，用于线性分数阶控制器，该技术使用ITAE准则，通过一次实验数据和虚参考信号来优化控制器参数，从而降低了成本。


<details>
  <summary>Details</summary>
Motivation: 传统基于ITAE的FO控制器整定方法需要多次闭环实验或模型仿真来评估ITAE，这增加了开发成本和复杂性。本研究旨在提出一种更高效、更实用的整定技术。

Method: 提出了一种基于积分时间加权绝对误差（ITAE）准则的线性分数阶（FO）控制器非迭代整定技术。该技术通过定义一个虚参考信号，使得可以在一次实验数据的基础上，通过求解优化问题来获得最优的FO控制器参数，从而避免了传统方法中需要多次闭环实验或模型仿真。

Result: 所提出的方法通过一次性采集的输入/输出数据，并利用虚参考信号，成功地减少了过冲/下冲，抑制了稳态误差，并获得了最优的FO控制器参数。

Conclusion: 该方法通过避免重复实验，显著降低了线性分数阶（FO）控制器的开发成本，从而促进了其在实际中的应用。

Abstract: This study presents a non-iterative tuning technique for a linear
fractional-order (FO) controller, based on the integral of the time-weighted
absolute error (ITAE) criterion. Minimizing the ITAE is a traditional approach
for tuning FO controllers. This technique reduces the over/undershoot and
suppresses the steady-state error. In contrast to conventional approaches of
ITAE-based controller tuning, the proposed approach does not require multiple
closed-loop experiments or model-based simulations to evaluate the ITAE. The
one-shot input/output data is collected from the controlled plant. A fictitious
reference signal is defined on the basis of the collected input and output
signal, which enables us to evaluate the closed-loop response provided by the
arbitrary controller parameters. To avoid repeated experiments that are
necessary in the conventional approach, we reformulate the ITAE minimization
problem using the fictitious reference signal. The desired FO controller
parameters minimizing the ITAE are obtained by solving the optimization problem
that is based on the fictitious reference signal. The validity of the proposed
approach is demonstrated by a numerical study. The avoidance of repeated
experiments significantly reduces the development cost of linear FO
controllers, thereby facilitating their practical application.

</details>


### [258] [Vertical Vibration Reduction of Maglev Vehicles using Nonlinear MPC](https://arxiv.org/abs/2507.13015)
*Mario Hermle,Arnim Kargl,Peter Eberhard*

Main category: eess.SY

TL;DR: 提出了一种新的NMPC策略，用于高速磁悬浮列车，考虑了悬架动力学，提高了乘坐舒适性，并在仿真中表现优于现有控制器。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统方法忽略悬架动力学的问题，通过对电磁力和悬架行为进行建模，实现预测性振动抑制，从而提高乘坐舒适性。

Method: 提出了一种新颖的非线性模型预测控制（NMPC）策略，该策略将机械悬架动力学显式地纳入控制模型。

Result: 仿真结果表明，该方法在振动抑制方面优于现有控制器。

Conclusion: 该方法有望成为未来高速磁悬浮列车的解决方案。

Abstract: This work presents a novel Nonlinear Model Predictive Control (NMPC) strategy
for high-speed Maglev vehicles that explicitly incorporates mechanical
suspension dynamics into the control model. Unlike conventional approaches,
which often neglect the interaction between levitation magnet and car body
motion, the proposed method enables predictive vibration mitigation by modeling
both electromagnetic forces and suspension behavior. This integrated approach
significantly improves passenger comfort and ride quality by reducing vertical
oscillations caused by track irregularities. Moreover, it allows for a more
effective tuning of the trade-off between precise air gap tracking and ride
comfort. Simulations based on a detailed multibody model of the Transrapid
demonstrate that the method outperforms existing controllers in vibration
suppression, making it a promising solution for future high-speed Maglev
applications.

</details>


### [259] [Dual LiDAR-Based Traffic Movement Count Estimation at a Signalized Intersection: Deployment, Data Collection, and Preliminary Analysis](https://arxiv.org/abs/2507.13073)
*Saswat Priyadarshi Nayak,Guoyuan Wu,Kanok Boriboonsomsin,Matthew Barth*

Main category: eess.SY

TL;DR: 该研究提出了一种双LiDAR系统，用于在十字路口进行交通量计数（TMC）估计，以克服传统方法的局限性。该系统利用LiDAR的3D检测能力来对车辆进行分类，并讨论了结果和潜在的改进。


<details>
  <summary>Details</summary>
Motivation: 传统的交通量计数方法（如手动计数、回路检测器、气动管和基于摄像头的识别）在光照条件差、恶劣天气和夜间条件下容易出现不准确。由于成本降低和在3D目标检测、跟踪和相关应用中的使用不断扩大，LiDAR技术正变得越来越受欢迎。

Method: 该研究提出了一种双LiDAR系统，用于在十字路口进行交通量计数（TMC）估计。通过使用两个LiDAR传感器的3D边界框检测来对车辆进行分类，以确定交通方向、车辆运动和车辆类别。

Result: 该研究评估了一个部署在加利福尼亚州里亚托市十字路口的双LiDAR系统，用于TMC估计。论文讨论了估计的TMC结果，并提供了对观察到的趋势和不规则现象的见解。

Conclusion: dual-LiDAR系统在加利福尼亚州里亚托市的一个十字路口进行了部署和评估，用于交通量计数（TMC）估计。该系统利用两个LiDAR传感器的3D边界框检测来根据交通方向、车辆运动和车辆类别对车辆数量进行分类。研究讨论了估计的TMC结果，并提供了对观察到的趋势和不规则现象的见解。此外，还讨论了可以增强TMC估计、轨迹预测和十字路口意图预测的潜在改进。

Abstract: Traffic Movement Count (TMC) at intersections is crucial for optimizing
signal timings, assessing the performance of existing traffic control measures,
and proposing efficient lane configurations to minimize delays, reduce
congestion, and promote safety. Traditionally, methods such as manual counting,
loop detectors, pneumatic road tubes, and camera-based recognition have been
used for TMC estimation. Although generally reliable, camera-based TMC
estimation is prone to inaccuracies under poor lighting conditions during harsh
weather and nighttime. In contrast, Light Detection and Ranging (LiDAR)
technology is gaining popularity in recent times due to reduced costs and its
expanding use in 3D object detection, tracking, and related applications. This
paper presents the authors' endeavor to develop, deploy and evaluate a
dual-LiDAR system at an intersection in the city of Rialto, California, for TMC
estimation. The 3D bounding box detections from the two LiDARs are used to
classify vehicle counts based on traffic directions, vehicle movements, and
vehicle classes. This work discusses the estimated TMC results and provides
insights into the observed trends and irregularities. Potential improvements
are also discussed that could enhance not only TMC estimation, but also
trajectory forecasting and intent prediction at intersections.

</details>


### [260] [QTCAJOSA: Low-Complexity Joint Offloading and Subchannel Allocation for NTN-Enabled IoMT](https://arxiv.org/abs/2507.13242)
*Alejandro Flores C.,Konstantinos Ntontin,Ashok Bandi,Symeon Chatzinotas*

Main category: eess.SY

TL;DR: IoMT devices offload tasks to UAVs, which can compute or forward them to HAPS or LEO satellites. A greedy algorithm minimizes task delay. Non-terrestrial networks improve performance.


<details>
  <summary>Details</summary>
Motivation: To address the resource allocation problem for task offloading from Internet of Medical Things (IoMT) devices to a non-terrestrial network, aiming to minimize the weighted sum delay of tasks.

Method: A low-complexity joint subchannel allocation and offloading decision algorithm is derived using a greedy heuristic based on convex optimization criteria, incorporating dynamic computing resource initialization.

Result: Simulations show performance gains by including UAVs, HAPS, and LEO satellites in the network architecture for IoMT task offloading, compared to traditional architectures.

Conclusion: The proposed low-complexity algorithm demonstrates gains by incorporating non-terrestrial nodes (UAVs, HAPS, LEO satellites) compared to architectures lacking them, effectively minimizing weighted sum delay for IoMT task offloading.

Abstract: In this work, we consider the resource allocation problem for task offloading
from Internet of Medical Things (IoMT) devices, to a non-terrestrial network.
The architecture considers clusters of IoMT devices that offload their tasks to
a dedicated unmanned aerial vehicle (UAV) serving as a multi-access edge
computing (MEC) server, which can compute the task or further offload it to an
available high-altitude platform station (HAPS) or to a low-earth orbit (LEO)
satellite for remote computing. We formulate a problem that has as objective
the minimization of the weighted sum delay of the tasks. Given the non-convex
nature of the problem, and acknowledging that the complexity of the
optimization algorithms impact their performance, we derive a low-complexity
joint subchannel allocation and offloading decision algorithm with dynamic
computing resource initialization, developed as a greedy heuristic based on
convex optimization criteria. Simulations show the gain obtained by including
the different non-terrestrial nodes against architectures without them.

</details>


### [261] [Transient-Stability-Aware Frequency Provision in IBR-Rich Grids via Information Gap Decision Theory and Deep Learning](https://arxiv.org/abs/2507.13265)
*Amin Masoumi,Mert Korkali*

Main category: eess.SY

TL;DR: 本研究提出了一种新的鲁棒最优潮流（rOTF）方法，通过考虑转子能量来处理高惯量新能源（HI-RE）并网带来的不确定性，以提高电网的瞬态稳定性。该方法在 IEEE 39 节点系统上验证有效，可在不显著增加成本的情况下防止系统崩溃。


<details>
  <summary>Details</summary>
Motivation: 为了解决在高惯量新能源（HI-RE）渗透率增加的情况下，电网中瞬态稳定性因惯量降低而面临的关键损失问题。

Method: 本研究提出了一种新的鲁棒最优潮流（rOTF）方法，该方法通过显式考虑转子能量来处理不确定性，特别是高惯量新能源（HI-RE）的大量并网。通过将不确定性转化为一组可能扰动，rOTF能够找到在最坏情况下也能保证系统稳定性的控制策略。

Result: 在 IEEE 39 节点系统上进行了验证，该系统具有 70% 的 IBR 渗透率。结果表明，所提出的方法能够防止系统崩溃，而传统的虚拟惯量调度（VIS）策略在此情况下会失败。此外，与传统方法相比，新方法的成本增加仅为 5%，表明其在保证频率稳定性方面的高效性和经济性。

Conclusion: 本研究提出的考虑转子能量的鲁棒最优潮流方法可以有效提升包含大量高惯量新能源的电力系统运行的鲁棒性，并为系统规划和运行提供有价值的参考。

Abstract: This paper introduces a framework to address the critical loss of transient
stability caused by reduced inertia in grids with high inverter-based resource
(IBR) penetration. The proposed method integrates a predictive deep learning
(DL) model with information gap decision theory (IGDT) to create a risk-averse
dispatch strategy. By reformulating the conventional virtual inertia scheduling
(VIS) problem, the framework uses early predictions of post-fault dynamics to
proactively redispatch resources, ensuring the system's center of inertia
remains stable under worst-case contingencies. Validated on the IEEE 39-bus
system with 70% IBR penetration, the proposed approach prevents system collapse
where a conventional VIS strategy fails, ensuring frequency stability at a cost
increase of only 5%.

</details>


### [262] [Privacy-Preserving Fusion for Multi-Sensor Systems Under Multiple Packet Dropouts](https://arxiv.org/abs/2507.13286)
*Jie Huang,Jason J. R. Liu*

Main category: eess.SY

TL;DR: 本研究提出了一种在无线传感器网络中用于解决丢包和窃听问题的隐私保护融合估计方法，通过一种新的机制在保证数据安全的同时保持了估计的准确性。


<details>
  <summary>Details</summary>
Motivation: 为了解决无线传感器网络（WSN）中由于窃听和丢包而带来的安全状态估计挑战，本研究旨在提出一种隐私保护融合估计（PPFE）方法。

Method: 本研究提出了一种基于编码的隐私保护机制（PPM），并结合控制理论框架来解决多传感器系统中的隐私保护融合估计（PPFE）问题。研究人员开发了一个集中的融合滤波器，考虑了丢包和基于编码的PPM的耦合效应。通过修改代数Riccati方程推导了合法用户的估计误差协方差的有界性条件。此外，通过证明窃听者的平均估计误差的发散性，严格分析了所提出的PPFE算法的数据机密性。

Result: 通过针对基于Internet的三罐系统的仿真结果验证了所提出方法的有效性，该方法在不损害估计准确性的前提下提高了隐私性。

Conclusion: 该研究提出了一种分布式编码隐私保护机制（PPM），以解决无线传感器网络（WSN）中的隐私保护融合估计（PPFE）问题，该问题受到丢包和窃听攻击的影响。该机制在控制理论框架内运行，可在传输过程中保护数据隐私，同时保持合法的状态估计性能。

Abstract: Wireless sensor networks (WSNs) are critical components in modern
cyber-physical systems, enabling efficient data collection and fusion through
spatially distributed sensors. However, the inherent risks of eavesdropping and
packet dropouts in such networks pose significant challenges to secure state
estimation. In this paper, we address the privacy-preserving fusion estimation
(PPFE) problem for multi-sensor systems under multiple packet dropouts and
eavesdropping attacks. To mitigate these issues, we propose a distributed
encoding-based privacy-preserving mechanism (PPM) within a control-theoretic
framework, ensuring data privacy during transmission while maintaining the
performance of legitimate state estimation. A centralized fusion filter is
developed, accounting for the coupling effects of packet dropouts and the
encoding-based PPM. Boundedness conditions for the legitimate user's estimation
error covariance are derived via a modified algebraic Riccati equation.
Additionally, by demonstrating the divergence of the eavesdropper's mean
estimation error, the proposed PPFE algorithm's data confidentiality is
rigorously analyzed. Simulation results for an Internet-based three-tank system
validate the effectiveness of the proposed approach, highlighting its potential
to enhance privacy without compromising estimation accuracy.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [263] [Quantum Transfer Learning to Boost Dementia Detection](https://arxiv.org/abs/2507.12485)
*Sounak Bhowmik,Talita Perciano,Himanshu Thapliyal*

Main category: quant-ph

TL;DR: 量子迁移学习（QTL）有望改善痴呆症检测的深度学习模型性能，即使在存在噪声的情况下也能提高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了解决经典机器学习和深度学习方法在处理高维生物医学数据和大规模数据集时遇到的计算和性能限制，量子机器学习（QML）作为一种有前途的范式出现，它提供了更快的训练和先进的模式识别能力。

Method: 本文旨在演示量子迁移学习（QTL）在提高应用于二元分类任务（用于痴呆症检测）的弱经典深度学习模型性能方面的潜力。此外，我们还展示了噪声对基于QTL的方法的影响，并研究了该方法的可靠性和鲁棒性。

Result: 使用OASIS 2数据集，我们展示了量子技术如何将表现不佳的经典模型转换为更有效的生物医学图像分类解决方案。

Conclusion: 量子迁移学习（QTL）能够将表现不佳的经典深度学习模型转换为更有效的生物医学图像分类解决方案，为推进医疗保健技术提供了潜力。

Abstract: Dementia is a devastating condition with profound implications for
individuals, families, and healthcare systems. Early and accurate detection of
dementia is critical for timely intervention and improved patient outcomes.
While classical machine learning and deep learning approaches have been
explored extensively for dementia prediction, these solutions often struggle
with high-dimensional biomedical data and large-scale datasets, quickly
reaching computational and performance limitations. To address this challenge,
quantum machine learning (QML) has emerged as a promising paradigm, offering
faster training and advanced pattern recognition capabilities. This work aims
to demonstrate the potential of quantum transfer learning (QTL) to enhance the
performance of a weak classical deep learning model applied to a binary
classification task for dementia detection. Besides, we show the effect of
noise on the QTL-based approach, investigating the reliability and robustness
of this method. Using the OASIS 2 dataset, we show how quantum techniques can
transform a suboptimal classical model into a more effective solution for
biomedical image classification, highlighting their potential impact on
advancing healthcare technology.

</details>


### [264] [Sporadic Federated Learning Approach in Quantum Environment to Tackle Quantum Noise](https://arxiv.org/abs/2507.12492)
*Ratun Rahman,Atit Pokharel,Dinh C. Nguyen*

Main category: quant-ph

TL;DR: 量子联邦学习（QFL）框架 SpoQFL 利用零星学习来解决量子噪声问题，提高了训练性能和收敛稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的量子联邦学习（QFL）框架在处理现代量子设备中的量子噪声异质性方面存在不足，这会导致训练性能不佳。本研究旨在解决这一问题。

Method: 提出了一种名为 SpoQFL 的新型 QFL 框架，该框架利用零星学习来缓解分布式量子系统中的量子噪声异质性。SpoQFL 根据噪声波动动态调整训练策略，从而提高模型的鲁棒性、收敛稳定性和整体学习效率。

Result: SpoQFL 在真实数据集上的广泛实验表明，其性能显著优于传统 QFL 方法，实现了更优的训练性能和更稳定的收敛性。

Conclusion: SpoQFL 通过利用零星学习来缓解分布式量子系统中的量子噪声异质性，在真实数据集上的广泛实验证明，SpoQFL 的性能显著优于传统 QFL 方法，实现了更优的训练性能和更稳定的收敛性。

Abstract: Quantum Federated Learning (QFL) is an emerging paradigm that combines
quantum computing and federated learning (FL) to enable decentralized model
training while maintaining data privacy over quantum networks. However, quantum
noise remains a significant barrier in QFL, since modern quantum devices
experience heterogeneous noise levels due to variances in hardware quality and
sensitivity to quantum decoherence, resulting in inadequate training
performance. To address this issue, we propose SpoQFL, a novel QFL framework
that leverages sporadic learning to mitigate quantum noise heterogeneity in
distributed quantum systems. SpoQFL dynamically adjusts training strategies
based on noise fluctuations, enhancing model robustness, convergence stability,
and overall learning efficiency. Extensive experiments on real-world datasets
demonstrate that SpoQFL significantly outperforms conventional QFL approaches,
achieving superior training performance and more stable convergence.

</details>


### [265] [Efficient Classical-Processing of Constant-Depth Time Evolution Circuits in Control Hardware](https://arxiv.org/abs/2507.12765)
*Akhil Francis,Abhi D. Rajagopala,Norm M. Tubman,Katherine Klymko,Kasra Nowrouzi*

Main category: quant-ph

TL;DR: 本研究提出了一种硬件辅助的参数化电路执行（PCE）方法，用于优化量子算法中的经典处理，通过计算量子多体系统的动力学性质，将相关函数计算的运行时间减少了高达50%。


<details>
  <summary>Details</summary>
Motivation: 为了提高量子算法的运行时间性能，本文专注于优化经典处理和编译时间，通过硬件辅助的参数化电路执行（PCE）技术。

Method: 利用硬件辅助的参数化电路执行（PCE）技术，通过卡尔坦分解生成的恒定深度电路，计算自旋模型的自旋自旋相关函数。

Result: 在跨场XY（最多6个位点）和海森堡自旋模型（最多3个位点）的自旋自旋相关函数计算中，与标准编译方法相比，运行时间减少了高达50%。

Conclusion: 本文证明了时间演化电路与硬件辅助的参数化电路执行（PCE）相结合，有潜力缓解近期量子算法中的经典瓶颈。

Abstract: Improving quantum algorithms run-time performance involves several strategies
such as reducing the quantum gate counts, decreasing the number of
measurements, advancement in QPU technology for faster gate operations, or
optimizing the classical processing. This work focuses on the latter,
specifically reducing classical processing and compilation time via
hardware-assisted parameterized circuit execution (PCE) for computing dynamical
properties of quantum systems. PCE was previously validated for QCVV protocols,
which leverages structural circuit equivalencies. We demonstrate the
applicability of this approach to computing dynamical properties of quantum
many-body systems using structurally equivalent time evolution circuits,
specifically calculating correlation functions of spin models using
constant-depth circuits generated via Cartan decomposition. Implementing this
for spin-spin correlation functions in Transverse field XY (up to 6-sites) and
Heisenberg spin models (up to 3-sites), we observed a run-time reduction of up
to 50\% compared to standard compilation methods. This highlights the
adaptability of time-evolution circuit with hardware-assisted PCE to
potentially mitigate the classical bottlenecks in near-term quantum algorithms.

</details>


### [266] [Leveraging Quantum Layers in Classical Neural Networks](https://arxiv.org/abs/2507.12505)
*Silvie Illésová*

Main category: quant-ph

TL;DR: 本论文探索了混合量子-经典神经网络，将量子层集成到卷积神经网络中，并展示了其在有限量子比特下的潜力。


<details>
  <summary>Details</summary>
Motivation: 探索将量子层集成到经典卷积神经网络架构中，以期利用量子纠缠和特征映射来增强学习能力。

Method: 本论文提出了一种在经典卷积神经网络架构中集成量子层的方法，并使用PyTorch和Qiskit机器学习框架进行了实现和训练。

Result: 实验结果表明，在神经网络流程的不同阶段插入量子层会对模型性能产生影响，并且量子组件可以引入有意义的变换。

Conclusion: 混合量子-经典神经网络有潜力改进机器学习模型。实验表明，即使在量子比特数量有限的情况下，量子组件也能引入有意义的变换，这表明了可扩展量子机器学习的研究价值。

Abstract: Hybrid quantum-classical neural networks represent a promising frontier in
the search for improved machine learning models. This thesis explores the
integration of quantum layers within classical convolutional neural network
architectures, aiming to leverage quantum entanglement and feature mapping to
enhance learning capabilities. A detailed methodology for constructing and
training such hybrid models is presented, using PyTorch and Qiskit Machine
Learning frameworks. Experiments investigate the performance impact of
inserting quantum layers at different stages of the neural network pipeline.
The results suggest that quantum components can introduce meaningful
transformations even with a limited number of qubits, motivating further
research into scalable quantum machine learning. The full implementation is
made publicly available, and future work will focus on expanding experimental
evaluations and publishing additional findings.

</details>


### [267] [Unfolded distillation: very low-cost magic state preparation for biased-noise qubits](https://arxiv.org/abs/2507.12511)
*Diego Ruiz,Jérémie Guillaud,Christophe Vuillot,Mazyar Mirrahimi*

Main category: quant-ph

TL;DR: 一种低成本、高效率的魔态蒸馏方案，适用于噪声偏差量子比特，显著降低了容错量子计算的资源需求。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统魔态蒸馏方案在空间和时间上的高昂开销问题，提出一种适用于噪声偏差量子比特的低成本魔态蒸馏方案。

Method: 提出了一种基于展开哈达玛3D量子里德-穆勒码X稳定子群的物理层魔态蒸馏方案，无需逻辑层操作。

Result: 在噪声偏差 $\eta \gtrsim 5 	imes 10^6$ 和翻相噪声率 $0.1\%$ 下，仅使用53个量子比特和5.5轮纠错即可制备出逻辑错误率为 $3 	imes 10^{-7}$ 的魔态，电路规模比现有方案降低一到两个数量级。该方案在噪声偏差 $\eta \gtrsim 80$ 时仍能保持高保真度，且对高翻相噪声率具有鲁棒性。

Conclusion: 该研究提出了一种低成本的魔态蒸馏方案，利用噪声偏差制备高保真度魔态，可显著降低量子比特空间和时间成本，适用于大规模容错量子计算。

Abstract: Magic state distillation enables universal fault-tolerant quantum computation
by implementing non-Clifford gates via the preparation of high-fidelity magic
states. However, it comes at the cost of substantial logical-level overhead in
both space and time. In this work, we propose a very low-cost magic state
distillation scheme for biased-noise qubits. By leveraging the noise bias, our
scheme enables the preparation of a magic state with a logical error rate of $3
\times 10^{-7}$, using only 53 qubits and 5.5 error correction rounds, under a
noise bias of $\eta \gtrsim 5 \times 10^6$ and a phase-flip noise rate of
$0.1\%$. This reduces the circuit volume by more than one order of magnitude
relative to magic state cultivation for unbiased-noise qubits and by more than
two orders of magnitude relative to standard magic state distillation.
Moreover, our scheme provides three key advantages over previous proposals for
biased-noise qubits. First, it only requires nearest-neighbor two-qubit gates
on a 2D lattice. Second, the logical fidelity remains nearly identical even at
a more modest noise bias of $\eta \gtrsim 80$, at the cost of a slightly
increased circuit volume. Third, the scheme remains effective even at high
physical phase-flip rates, in contrast to previously proposed approaches whose
circuit volume grows exponentially with the error rate. Our construction is
based on unfolding the $X$ stabilizer group of the Hadamard 3D quantum
Reed-Muller code in 2D, enabling distillation at the physical level rather than
the logical level, and is therefore referred to as $\textit{unfolded}$
distillation.

</details>


### [268] [Hybrid satellite-fiber quantum network](https://arxiv.org/abs/2507.12539)
*Yanxuan Shao,Saikat Guha,Adilson E. Motter*

Main category: quant-ph

TL;DR: 提出了一种混合量子网络和协议，解决了现有量子网络在距离和保真度方面的限制，有望实现全球规模的高保真度量子网络。


<details>
  <summary>Details</summary>
Motivation: 量子网络在关键分发、私有和分布式计算以及量子传感等领域具有巨大潜力。然而，目前地面用户的量子网络规模受到远距离分发纠缠能力的限制。

Method: 提出了一种混合网络和协议，并与仅基于地面或仅基于卫星的设计进行了比较。

Result: 提出的混合网络和协议在分发纠缠方面优于现有技术，有望实现大规模量子网络。

Conclusion: 该混合网络和协议能够超越目前的地面和基于卫星的设计，在大陆甚至全球范围内实现高保真度纠缠。

Abstract: Quantum networks hold promise for key distribution, private and distributed
computing, and quantum sensing, among other applications. The scale of such
networks for ground users is currently limited by one's ability to distribute
entanglement between distant locations. This can in principle be carried out by
transmitting entangled photons through optical fibers or satellites. The former
is limited by fiber optic attenuation while the latter is limited by
atmospheric extinction and diffraction. Here, we propose a hybrid network and
protocol that outperform both ground- and satellite-based designs and lead to
high-fidelity entanglement at a continental or even global scale.

</details>


### [269] [Spacetime duality between sequential and measurement-feedback circuits](https://arxiv.org/abs/2507.12523)
*Tsung-Cheng Lu,Sarang Gopalakrishnan,Yizhi You*

Main category: quant-ph

TL;DR: SU和MF电路通过时空旋转可以相互转化，可用于制备长程纠缠态，并提出了一种只需要常数量子比特的实验方案。


<details>
  <summary>Details</summary>
Motivation: 为了探索制备长程纠缠量子态的新方法，并提出更高效的实验方案。

Method: 通过分析线性深度序列酉（SU）电路和常数深度测量反馈（MF）电路的结构，揭示了它们在时空旋转下的偶对关系，并将其应用于制备GHZ态、拓扑序态和分形对称性破缺态等多种长程纠缠态。

Result: 证明了SU和MF电路的时空对偶性，并展示了如何利用这种对偶性制备长程纠缠态，以及提出了一种只需要常数量子比特的实验方案，用于测量1D多体态的性质，如无自发对称性破缺的无序算符测量和测量诱导的长程有序检测。

Conclusion: SU和MF电路在时空旋转下是偶对的，这一发现为制备长程纠缠量子态提供了新的视角，并提出了一种更少量子比特的实验方案。

Abstract: Two prevalent approaches for preparing long-range entangled quantum states
are (i) linear-depth sequential unitary (SU) circuits, which apply local
unitary gates sequentially, and (ii) constant-depth measurement-feedback (MF)
circuits, which employ mid-circuit measurements and conditional feedback based
on measurement outcomes. Here, we establish that a broad class of SU and MF
circuits are dual to each other under a spacetime rotation. We investigate this
spacetime duality in the preparation of various long-range entangled states,
including GHZ states, topologically ordered states, and fractal
symmetry-breaking states. As an illustration, applying a spacetime rotation to
a linear-depth SU circuit that implements a non-invertible Kramers-Wannier
duality, originally used to prepare a 1D GHZ state, yields a constant-depth MF
circuit that implements a $\mathbb{Z}_2$ symmetry gauging map, which
equivalently prepares the GHZ state. Leveraging this duality, we further
propose experimental protocols that require only a constant number of qubits to
measure unconventional properties of 1D many-body states. These include (i)
measurement of disorder operators, which diagnose the absence of spontaneous
symmetry breaking, and (ii) postselection-free detection of measurement-induced
long-range order, which emerges in certain symmetry-protected topological
phases. We also show that measurement-induced long-range order provides a lower
bound for strange correlators, which may be of independent interest.

</details>


### [270] [Emergence of Generic Entanglement Structure in Doped Matchgate Circuits](https://arxiv.org/abs/2507.12526)
*Alessio Paviglianiti,Luca Lumia,Emanuele Tirrito,Alessandro Silva,Mario Collura,Xhek Turkeshi,Guglielmo Lami*

Main category: quant-ph

TL;DR: 非高斯门可以修复自由费米子高斯量子线路的纠缠动力学，并影响其在测量下的相变行为。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过引入非高斯资源来恢复自由费米子高斯量子线路（表现出异常慢的纠缠增长和不稳定的体积律纠缠态）的典型动力学行为。

Method: 通过注入不同量和不同速率的非高斯门（量子比特门）来研究自由费米子高斯量子线路的动力学演化，并引入测量作为扰动，观察纠缠增长、Kardar-Parisi-Zhang涨落以及测量诱导相变的性质。

Result: 注入少量非高斯门可使弹道纠缠增长（S(t) ~ t）和Kardar-Parisi-Zhang涨落得以恢复。当测量被引入时，观察到从面积律到幂律纠缠相（S ~ N^α）的测量诱导相变，其中α由非高斯门的多样性控制。只有以广泛的速率注入非高斯门时，才能实现真正的体积律纠缠相。

Conclusion: 注入非高斯门可以恢复自由费米子高斯量子线路的纠缠动力学。随着非高斯门注入量的增加，纠缠增长从扩散标度恢复到弹道标度，并出现Kardar-Parisi-Zhang涨落。在测量扰动下，会发生测量诱导相变，在面积律和幂律纠缠相之间转换，其中幂律纠缠相的指数由非高斯门的注入量控制。只有当以广泛的速率注入非高斯门时，才能恢复真正的体律纠缠相。这些发现将自由和相互作用的费米子系统的动力学联系起来，并指出非高斯性是驱动非积分行为出现的关键资源。

Abstract: Free fermionic Gaussian, a.k.a. matchgate, random circuits exhibit atypical
behavior compared to generic interacting systems. They produce anomalously slow
entanglement growth, characterized by diffusive scaling $S(t) \sim \sqrt{t}$,
and evolve into volume-law entangled states at late times, $S \sim N$, which
are highly unstable to measurements. Here, we investigate how doping such
circuits with non-Gaussian resources (gates) restores entanglement structures
of typical dynamics. We demonstrate that ballistic entanglement growth $S(t)
\sim t$ is recovered after injecting an extensive total amount of non-Gaussian
gates, also restoring Kardar-Parisi-Zhang fluctuations. When the evolution is
perturbed with measurements, we uncover a measurement-induced phase transition
between an area-law and a power-law entangled phase, $S \sim N^\alpha$, with
$\alpha$ controlled by the doping. A genuine volume-law entangled phase is
recovered only when non-Gaussian gates are injected at an extensive rate. Our
findings bridge the dynamics of free and interacting fermionic systems,
identifying non-Gaussianity as a key resource driving the emergence of
non-integrable behavior.

</details>


### [271] [Scalable dissipative quantum error correction for discrete-variable codes](https://arxiv.org/abs/2507.12534)
*Ivan Rojkov,Elias Zapusek,Florentin Reiter*

Main category: quant-ph

TL;DR: 本研究提出了一种用于离散变量码的可扩展耗散量子纠错协议，通过“涓流”机制有效降低了对校正算符数量的指数级需求，并在实验中展示了其优越性。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有耗散量子纠错（QEC）协议在扩展性方面的挑战，特别是针对高权重错误需要指数级增长的校正算符的问题，本研究旨在提出一种更有效、可扩展的协议。

Method: 本研究提出了一种可扩展的耗散量子纠错（QEC）协议，通过利用离散变量码的冗余性，设计能够同时作用于多个错误子空间的校正算符，实现错误权重的递减。该方法通过“涓流”机制顺序降低错误权重，以应对高权重错误。

Result: 在有偏噪声下的重复码实验中，该方法实现了四倍的指数抑制因子提升，证明了其在实际物理错误率下的有效性。该方法将离散变量码的自主QEC与已验证的玻色码耗散协议联系起来，并为传统的测量反馈QEC和容错量子操作开辟了新途径。

Conclusion: 提出了一种可扩展的耗散量子纠错协议，该协议通过“涓流”机制顺序降低错误权重，从而校正离散变量码中的多量子比特错误。该协议利用Knill-Laflamme条件的冗余性来设计可同时作用于多个错误子空间的校正算符，将开销从指数级降低到关于所需算符数量的多项式级。

Abstract: Dissipative quantum error correction (QEC) autonomously protects quantum
information using engineered dissipation and offers a promising alternative to
error correction via measurement and feedback. However, scalability remains a
challenge, as correcting high-weight errors typically requires increasing
dissipation rates and exponentially many correction operators. Here, we present
a scalable dissipative QEC protocol for discrete-variable codes, correcting
multi-qubit errors via a trickle-down mechanism that sequentially reduces
errors weight. Our construction exploits redundancy in the Knill-Laflamme
conditions to design correction operators that act on multiple error subspaces
simultaneously, thereby reducing the overhead from exponential to polynomial in
the number of required operators. We illustrate our approach with repetition
codes under biased noise, showing a fourfold improvement in the exponential
suppression factor at realistic physical error rates. Our approach connects
autonomous QEC for discrete-variable codes with demonstrated dissipative
protocols for bosonic codes and opens up new avenues for traditional
measurement-feedback QEC and fault-tolerant quantum operations.

</details>


### [272] [Technical Review on RF-Amplifiers for Quantum Computer Circuits: New Architectures of Josephson Parametric Amplifier](https://arxiv.org/abs/2507.13187)
*Ahmad Salmanogli,Hesam Zandi,Mahdi Esmaeili,Abolfazl Eskandari,Mohsen Akbari*

Main category: quant-ph

TL;DR: JPAs是量子处理的关键，优于CMOS和HEMT放大器。本研究设计并分析了基于约瑟夫森结阵列的JPAs，以克服单结JPAs的局限性。


<details>
  <summary>Details</summary>
Motivation: 由于CMOS放大器在超低温下性能不佳，而HEMT放大器功耗大且不适合mK操作，因此需要JPAs这种结合了低功耗、超低噪声和优异低温兼容性的放大器。

Method: 本研究通过量子理论和CAD工具，对基于单约瑟夫森结和结阵列的JPAs设计进行了分析和仿真，重点探讨了结阵列在提高功率处理能力、线性度、阻抗可调性和相干性以及降低相位噪声方面的优势。

Result: 通过对基于单约瑟夫森结和结阵列的JPAs进行设计、仿真和比较，评估了先进JPA架构的性能权衡和改进。

Conclusion: 约瑟夫森参量放大器（JPAs）由于其能够在近量子极限噪声性能下放大量子信号，已成为量子信息处理的关键组成部分，尤其是在量子比特读出、量子传感和通信等领域。与传统射频系统中的CMOS和HEMT放大器相比，JPAs特别针对毫开尔文（mK）低温环境进行了优化，结合了低功耗、超低噪声和优异的低温兼容性。本研究首先比较了这些射频放大器类型，阐述了JPAs在低温量子应用中的优势。

Abstract: Josephson Parametric Amplifiers (JPAs) are key components in quantum
information processing due to their ability to amplify weak quantum signals
with near-quantum-limited noise performance. This is essential for applications
such as qubit readout, quantum sensing, and communication, where signal
fidelity and coherence preservation are critical. Unlike CMOS and HEMT
amplifiers used in conventional RF systems, JPAs are specifically optimized for
millikelvin (mK) cryogenic environments. CMOS amplifiers offer good integration
but perform poorly at ultra-low temperatures due to high noise. HEMT amplifiers
provide better noise performance but are power-intensive and less suited for mK
operation. JPAs, by contrast, combine low power consumption with ultra-low
noise and excellent cryogenic compatibility, making them ideal for quantum
systems. The first part of this study compares these RF amplifier types and
explains why JPAs are preferred in cryogenic quantum applications. The second
part focuses on the design and analysis of JPAs based on both single Josephson
junctions and junction arrays. While single-junction JPAs utilize nonlinear
inductance for amplification, they suffer from gain compression, limited
dynamic range, and sensitivity to fabrication variations. To overcome these
challenges, this work explores JPA designs using Josephson junction arrays.
Arrays distribute the nonlinear response, enhancing power handling, linearity,
impedance tunability, and coherence while reducing phase noise. Several
advanced JPA architectures are proposed, simulated, and compared using quantum
theory and CAD tools to assess performance trade-offs and improvements over
conventional designs.

</details>


### [273] [Compensating connectivity restrictions in quantum annealers via splitting and linearization techniques](https://arxiv.org/abs/2507.12536)
*Marcel Seelbach Benkner,Zorah Lähner,Vladislav Golyanik,Martin Kliesch,Michael Moeller*

Main category: quant-ph

TL;DR: 提出了一种新的迭代算法，以有效利用可用连接性来克服量子退火中的连接性限制，无需額外添加額外的量子比特，并在 D-Wave 系统上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 当前的量子退火实验在连接性方面存在限制，需要通过组合多个物理量子比特为更具连接性的逻辑量子比特来克服，而这需要解决 NP-hard 的最小嵌入问题。

Method: 提出了一种迭代算法，利用现有连接性来解决量子退火中的连接性限制问题，该算法无需額外添加額外的量子比特，并具有弱单调性证明。

Result: 该算法在 D-Wave 量子退火器和局部搜索变体上进行了基准测试，证明了其有效性，并在 D-Wave Advantage 量子退火器上验证了其实用性。

Conclusion: 提出了一种新的迭代算法，通过有效利用可用连接性来克服量子退火中的连接性限制，而无需額外添加額外的量子比特。该算法已通过弱单调性证明，并在 D-Wave 量子退火器和局部搜索变体上进行了基准测试，同时也在 D-Wave Advantage 量子退火器上验证了其实用性。

Abstract: Current quantum annealing experiments often suffer from restrictions in
connectivity in the sense that only certain qubits can be coupled to each
other. The most common strategy to overcome connectivity restrictions so far is
by combining multiple physical qubits into a logical qubit with higher
connectivity, which is achieved by adding terms to the Hamiltonian.
Practically, this strategy is implemented by finding a so-called minor
embedding, which is in itself an NP-hard problem. In this work, we present an
iterative algorithm that does not need additional qubits but instead
efficiently uses the available connectivity for different parts of the problem
graph in every step. We present a weak monotonicity proof and benchmark our
algorithm against the default minor-embedding algorithm on the D-Wave quantum
annealer and multiple simple local search variants. While most of the
experiments to compare the different iterative methods are performed with
simulated annealing solvers, we also confirm the practicality of our method
with experiments on the D-Wave Advantage quantum annealer.

</details>


### [274] [Learning mixed quantum states in large-scale experiments](https://arxiv.org/abs/2507.12550)
*Matteo Votto,Marko Ljubotina,Cécilia Lancien,J. Ignacio Cirac,Peter Zoller,Maksym Serbyn,Lorenzo Piroli,Benoît Vermersch*

Main category: quant-ph

TL;DR: 提出一種學習量子態MPO表示的協議，該協議基於經典が影子，並通過類似於密度矩陣重整化群的算法進行張量優化，可在長程關聯狀態和嘈雜實驗環境下實現高效學習，並已成功應用於超導量子處理器上進行96量子位的量子態學習。


<details>
  <summary>Details</summary>
Motivation: 學習實驗製備的量子態的矩陣乘積算子（MPO）表示。

Method: 該協議通過優化張量來學習量子狀態的矩陣乘積算子（MPO）表示，類似於密度矩陣重整化群算法。

Result: 在長程關聯狀態和典型的嘈雜實驗環境下，學習大型量子態（高達96量子位）的MPO表示，並能夠有效估計學習態與實驗態之間的保真度。

Conclusion: 該協議將經典が影子升級到大型量子計算和模擬實驗，並在長程關聯狀態和典型的嘈雜實驗環境下可證實地高效。

Abstract: We present and test a protocol to learn the matrix-product operator (MPO)
representation of an experimentally prepared quantum state. The protocol takes
as an input classical shadows corresponding to local randomized measurements,
and outputs the tensors of a MPO which maximizes a suitably-defined fidelity
with the experimental state. The tensor optimization is carried out
sequentially, similarly to the well-known density matrix renormalization group
algorithm. Our approach is provably efficient under certain technical
conditions which are expected to be met in short-range correlated states and in
typical noisy experimental settings. Under the same conditions, we also provide
an efficient scheme to estimate fidelities between the learned and the
experimental states. We experimentally demonstrate our protocol by learning
entangled quantum states of up to $N = 96$ qubits in a superconducting quantum
processor. Our method upgrades classical shadows to large-scale quantum
computation and simulation experiments.

</details>


### [275] [Inverse Physics-informed neural networks procedure for detecting noise in open quantum systems](https://arxiv.org/abs/2507.12552)
*Gubio G. de Lima,Iann Cunha,Leonardo Kleber Castelano*

Main category: quant-ph

TL;DR: PINNverse框架可用于识别开放量子系统中的哈密顿量参数和衰减率。


<details>
  <summary>Details</summary>
Motivation: 在嘈杂的中等规模量子（NISQ）时代，准确表征量子系统对于量子技术的发展至关重要。机器学习方法为汉密尔顿量学习和噪声表征提供了有前景的替代方案。

Method: 通过将相干和耗散动力学纳入神经网络训练，该方法能够从噪声实验数据中同时识别哈密顿量参数和衰减率。

Result: 通过对双量子比特开放系统的数值模拟，证明了该方法的有效性和鲁棒性。

Conclusion: PINNverse提供了一个可扩展且抗噪声的量子系统识别框架，在量子控制和误差缓解方面具有潜在应用。

Abstract: Accurate characterization of quantum systems is essential for the development
of quantum technologies, particularly in the noisy intermediate-scale quantum
(NISQ) era. While traditional methods for Hamiltonian learning and noise
characterization often require extensive measurements and scale poorly with
system size, machine learning approaches offer promising alternatives. In this
work, we extend the inverse physics-informed neural network (referred to as
PINNverse) framework to open quantum systems governed by Lindblad master
equations. By incorporating both coherent and dissipative dynamics into the
neural network training, our method enables simultaneous identification of
Hamiltonian parameters and decay rates from noisy experimental data. We
demonstrate the effectiveness and robustness of the approach through numerical
simulations of two-qubit open systems. Our results show that PINNverse provides
a scalable and noise-resilient framework for quantum system identification,
with potential applications in quantum control and error mitigation.

</details>


### [276] [Efficient Qudit Circuit for Quench Dynamics of $2+1$D Quantum Link Electrodynamics](https://arxiv.org/abs/2507.12589)
*Rohan Joshi,Michael Meth,Jan C. Louw,Jesse J. Osborne,Kevin Mato,Martin Ringbauer,Jad C. Halimeh*

Main category: quant-ph

TL;DR: 提出了一种使用qudit（多能级系统）来模拟$2+1$维量子链接格致规范场论的方法，通过消除物质场和使用qudit编码，大大减少了资源需求和提高了模拟保真度，为模拟更高维度的格致规范场论提供了新的解决方案。


<details>
  <summary>Details</summary>
Motivation: 当前量子模拟高能物理中的$2+1$维格致规范场论面临着系统尺寸有限和仅使用两能级系统（qubit）表示规范场和电场等挑战，这阻碍了实现模拟$3+1$维量子色动力学的最终目标。因此，需要一种更具扩展性和资源效率的方法来克服这些限制。

Method: 提出了一种资源高效的量子模拟方法，通过对规范和电场使用qudit（多能级系统）进行编码，并利用高斯定律将物质场积分化，将模型重构为纯自旋图像，从而减少了所需的量子比特数量和门操作数量。该方法适用于任意空间维度的格致规范场论，并为自旋为1/2的系统构建了显式电路，通过数值模拟验证了其在噪声环境下的准确性。此外，还提出了一种构建更高自旋表示（S>1/2）耦合项电路的通用方法。

Result: 数值模拟结果表明，即使在存在现实噪声的情况下，该方法的一阶Trotter化电路也能准确地捕捉猝灭动力学。与传统的qubit编码相比，该框架显著减少了所需的量子资源和门操作数量，提高了可扩展性和保真度。

Conclusion: 所提出的基于qudit的量子模拟方法能够有效减少资源开销并提高保真度，为在量子计算机上模拟更高维度的格致规范场论提供了可行的途径。

Abstract: A major challenge in the burgeoning field of quantum simulation for
high-energy physics is the realization of scalable $2+1$D lattice gauge
theories on state-of-the-art quantum hardware, which is an essential step
towards the overarching goal of probing $3+1$D quantum chromodynamics on a
quantum computer. Despite great progress, current experimental implementations
of $2+1$D lattice gauge theories are mostly restricted to relatively small
system sizes and two-level representations of the gauge and electric fields.
Here, we propose a resource-efficient method for quantum simulating $2+1$D
spin-$S$ $\mathrm{U}(1)$ quantum link lattice gauge theories with dynamical
matter using qudit-based quantum processors. By integrating out the matter
fields through Gauss's law, we reformulate the quantum link model in a purely
spin picture compatible with qudit encoding across arbitrary spatial
dimensions, eliminating the need for ancillary qubits and reducing resource
overhead. Focusing first on the spin-$1/2$ case, we construct explicit circuits
for the full Hamiltonian and demonstrate through numerical simulations that the
first-order Trotterized circuits accurately capture the quench dynamics even in
the presence of realistic noise levels. Additionally, we introduce a general
method for constructing coupling-term circuits for higher-spin representations
$S>1/2$. Compared to conventional qubit encodings, our framework significantly
reduces the number of quantum resources and gate count. Our approach
significantly enhances scalability and fidelity for probing nonequilibrium
phenomena in higher-dimensional lattice gauge theories, and is readily amenable
to implementation on state-of-the-art qudit platforms.

</details>


### [277] [Qrisp Implementation and Resource Analysis of a T-Count-Optimised Non-Restoring Quantum Square-Root Circuit](https://arxiv.org/abs/2507.12603)
*Heorhi Kupryianau,Marcin Niemiec*

Main category: quant-ph

TL;DR: Qrisp中实现了T数优化非恢复量子平方根算法，资源效率更高，并成功进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: 高效的量子算术运算对于复杂的量子算法至关重要，但很少有理论设计在实际的量子编程框架中实现。

Method: 提出了一种使用Qrisp量子编程框架的T数优化非恢复量子平方根算法的完整实现。

Result: 在Qrisp中实现了T数优化非恢复量子平方根算法，验证了理论资源估计，T数为14n-14，T深度为5n+3，并通过实验验证了算法的正确性。

Conclusion: 这项工作证明了资源优化量子算法的实际可行性，并为在现代量子编程框架中实现不同的算术运算奠定了基础。

Abstract: Efficient quantum arithmetic operations are essential building blocks for
complex quantum algorithms, yet few theoretical designs have been implemented
in practical quantum programming frameworks. This paper presents the first
complete implementation of the T-count optimized non-restoring quantum square
root algorithm using the Qrisp quantum programming framework. The algorithm,
originally proposed by Thapliyal et al., offers better resource efficiency
compared to alternative methods, achieving reduced T-count and qubit
requirements while avoiding garbage output. Our implementation validates the
theoretical resource estimates, confirming a T-count of 14n-14 and T-depth of
5n+3 for n-bit inputs. The modular design approach enabled by Qrisp allows
construction from reusable components including reversible adders, subtractors,
and conditional logic blocks built from fundamental quantum gates. The
three-stage algorithm - comprising initial subtraction, iterative conditional
addition/subtraction, and remainder restoration is successfully translated from
algorithmic description to executable quantum code. Experimental validation
across multiple test cases confirms correctness, with the circuit producing
accurate integer square roots and remainders. This work demonstrates the
practical realizability of resource-optimized quantum arithmetic algorithms and
establishes a foundation for implementing different arithmetic operations in
modern quantum programming frameworks.

</details>


### [278] [Probing Hadron Scattering in Lattice Gauge Theories on Qudit Quantum Computers](https://arxiv.org/abs/2507.12614)
*Rohan Joshi,Jan C. Louw,Michael Meth,Jesse J. Osborne,Kevin Mato,Guo-Xian Su,Martin Ringbauer,Jad C. Halimeh*

Main category: quant-ph

TL;DR: 本研究提出了适用于U(1)量子链接规范场的数字量子比特量子电路，用于模拟介子-介子和介子-反介子碰撞。研究结果表明，量子比特在模拟散射过程方面优于量子比特，并揭示了丰富的物理现象。


<details>
  <summary>Details</summary>
Motivation: 高能物理领域的量子模拟旨在实现对散射过程的首次原理研究，但目前受限于系统规模和规范场两层表示。本研究旨在通过提出一种新的量子电路设计，克服这些限制，并探索其在模拟散射过程中的潜力。

Method: 本研究提出了适用于U(1)量子链接规范场的远非平衡淬什动力学的数字量子比特量子电路，其中电场和规范场用自旋-1算符表示。通过数值模拟，我们探测了该模型中的散射过程，特别是介子-介子和介子-反介子碰撞。

Result: 通过数值模拟，我们探测了该模型中的散射过程，特别是介子-介子和介子-反介子碰撞。探测到的散射动力学揭示了丰富的物理现象，包括介子翻转和随规范耦合强度变化的介子-反介子碰撞中的反射-透射转变。模拟结果与精确无噪声动力学高度一致，表明当前的量子比特平台已准备好在比量子比特更浅的电路深度下观察微观散射动力学。

Conclusion: 目前，量子模拟在高能物理领域的应用主要受限于系统规模和规范场两层表示。本研究提出了适用于U(1)量子链接规范场的远非平衡淬灭动力学的数字量子比特量子电路，其中电场和规范场用自旋-1算符表示。通过数值模拟，我们探测了该模型中的散射过程，特别是介子-介子和介子-反介子碰撞。与两层表示不同，介子-反介子碰撞的模拟是可能的，这证明了量子比特在探索量子电动力学相关散射过程中的优越性。探测到的散射动力学揭示了丰富的物理现象，包括介子翻转和随规范耦合强度变化的介子-反介子碰撞中的反射-透射转变。本研究的模拟结果与精确无噪声动力学高度一致，表明当前的量子比特平台已准备好在比量子比特更浅的电路深度下观察微观散射动力学。

Abstract: An overarching goal in the flourishing field of quantum simulation for
high-energy physics is the first-principles study of the microscopic dynamics
of scattering processes on a quantum computer. Currently, this is hampered by
small system sizes and a restriction to two-level representations of the gauge
fields in state-of-the-art quantum simulators. Here, we propose efficient
experimentally feasible digital qudit quantum circuits for far-from-equilibrium
quench dynamics of a $\mathrm{U}(1)$ quantum link lattice gauge theory, where
the electric and gauge fields are represented as spin-$1$ operators. Using
dedicated numerical simulations, we probe scattering processes in this model on
these proposed circuits, focusing on meson-meson and meson-antimeson
collisions. The latter are not possible with a two-level representation of the
fields, highlighting the suitability of qudits in exploring scattering
processes relevant to quantum electrodynamics. The probed scattering dynamics
showcases rich physics, including meson flipping and a reflection-transmission
transition in meson-antimeson collisions as a function of the gauge coupling
strength. Our simulations, which include realistic noise models of dephasing
and depolarization, show very good agreement with the exact noiseless dynamics,
signaling the readiness of current qudit platforms to observe microscopic
scattering dynamics with significantly shallower circuit depths than their
qubit counterparts.

</details>


### [279] [Sridhara-Compressed VQE Accelerates Molecular Energy Ranking of Polyaromatic Hydrocarbons](https://arxiv.org/abs/2507.12678)
*Dennis Lima,Saif Al-Kuwari*

Main category: quant-ph

TL;DR: 该研究提出了一种压缩算法与VQE结合的方法，用于优化石墨烯CVD合成中的TAH分子模拟，实现了加速和降噪，为克服量子计算的局限性提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 为了优化化学气相沉积（CVD）合成石墨烯的过程，需要对化学气相沉积过程中产生的残留物和中间分子——四环芳烃（TAH）进行能量排序。这个问题不仅对优化CVD至关重要，也可能在量子计算领域实现量子优势。

Method: 该研究扩展了Sridhara的多项式根公式，使用Hartree-Fock哈密顿量和STO-3G基组，对六种TAH进行分块对角化（SBD）。在量子计算方面，采用了压缩算法结合变分量子Eigensolver（VQE）来模拟和排序TAH分子。

Result: 研究表明，所提出的压缩算法和VQE相结合的方法能够成功地对TAH分子按基态能量进行排序。此外，该方法将VQE模拟速度提高了高达十倍，并将模拟误差降低到10^{-1}的量级。压缩算法在矩阵大小上的压缩能力（对于k量子比特为(1-2^{-k})*100%）使得VQE能够应用于更广泛的场景。

Conclusion: 该研究提出了一种使用压缩算法和变分量子Eigensolver（VQE）来模拟四环芳烃（TAH）的方法，该方法能够对分子进行基态能量排序，同时将VQE模拟速度提高高达十倍，并将误差降低到10^{-1}的量级。该方法通过压缩矩阵大小，克服了量子比特数量和量子噪声的限制，为解决大规模量子处理单元的挑战提供了新的工具。

Abstract: Chemical vapor deposition (CVD) is the most efficient process to synthesize
graphene sheets using methane as precursor, making it a strategic alternative
route for the Liquefied Natural Gas market. In this reaction, tetracyclic
aromatic hydrocarbons (TAH) are produced as residual and intermediary
molecules. Sorting a combinatorial space of variants of TAHs by energy is a
poorly studied problem needed to optimize CVD, while it is also a candidate for
quantum advantage in quantum computers. We extend on Sridhara's polynomial root
formula to perform block-diagonalization (hence SBD) of six TAHs using
Hartree-Fock Hamiltonians with STO-3G basis set and active orbital space
growing from 2 to 6 orbitals, with equal numbers for the number of active
electrons. We show that the proposed compression algorithm followed by
Variational Quantum Eigensolver (VQE) allows for sorting of the molecules by
ground state energy, while speeding up the VQE simulation up to tenfold and
reducing its error to the $10^{-1}$ scale. The compression capability of
$(1-2^{-k})\cdot 100\%$ in matrix size for $k$ qubits allows VQEs to have a
broader set of applications, providing a new and necessary tool to overcome the
circuit size and quantum noise limitations of large quantum processing units.

</details>


### [280] [Multiqubit monogamy relations beyond shadow inequalities](https://arxiv.org/abs/2507.12680)
*Eduardo Serrano-Ensástiga,Olivier Giraud,John Martin*

Main category: quant-ph

TL;DR: 该研究推导了用于表征多方量子系统（N ≤ 5）扇区长度的绝育不等式，并展示了如何优化关键物理量。但对于更大的系统（N ≥ 6），复杂性会增加，现有方法无法完全解决。


<details>
  <summary>Details</summary>
Motivation: 研究多方量子系统的绝育关系，这些关系对量子关联的分布施加了基本限制，并可能在量子信息理论和编码理论中得到应用。

Method: 该研究通过推导一组绝育不等式来研究多方量子系统中的绝育关系，这些不等式补充了阴影不等式。

Result: 对于 N ≤ 5 个量子比特的纯态系统，该研究完整地表征了扇区长度的数值范围，并展示了如何通过评估凸多面体的顶点来有效地极值化关键物理量。然而，对于 N ≥ 6 的系统，研究强调了复杂性显著增加，现有不等式无法完全捕捉。

Conclusion: 对于 N ≤ 5 个量子比特的纯态系统，该研究推导了一组补充了阴影不等式的绝育不等式，从而能够完整地表征扇区长度的数值范围。该范围形成一个凸多面体，通过在多面体顶点进行简单评估，可以有效地极值化诸如纠缠的线性熵和量子阴影枚举量等关键物理量。

Abstract: Multipartite quantum systems are subject to monogamy relations that impose
fundamental constraints on the distribution of quantum correlations between
subsystems. These constraints can be studied quantitatively through sector
lengths, defined as the average value of $m$-body correlations, which have
applications in quantum information theory and coding theory. In this work, we
derive a set of monogamy inequalities that complement the shadow inequalities,
enabling a complete characterization of the numerical range of sector lengths
for systems with $N\leq 5$ qubits in a pure state. This range forms a convex
polytope, facilitating the efficient extremization of key physical quantities,
such as the linear entropy of entanglement and the quantum shadow enumerators,
by a simple evaluation at the polytope vertices. For larger systems ($N\geq
6$), we highlight a significant increase in complexity that neither our
inequalities nor the shadow inequalities can fully capture.

</details>


### [281] [The thermal gauge potentials in quantum transport](https://arxiv.org/abs/2507.12712)
*Zheng Chuan Wang*

Main category: quant-ph

TL;DR: 本手稿提出了一种基于量子玻尔兹曼方程的新型热标量和矢量规范势，并通过泰勒级数展开推导出温度依赖的四维阻尼力，其中第四分量对应新的标量势。研究还发现温度越高，阻尼力越大。


<details>
  <summary>Details</summary>
Motivation: 提出一种新的热标量和矢量规范势，以描述传导电子和声子的相互作用。

Method: 通过泰勒级数展开量子玻尔兹曼方程的自能量，推导出温度依赖的四维阻尼力，并基于局部平衡假设，使用傅里叶变换方法逐级求解量子玻尔兹曼方程。

Result: 温度越高，阻尼力越大。

Conclusion: 该研究提出了一种基于量子玻尔兹曼方程的新型热标量和矢量规范势，并通过泰勒级数展开推导了温度依赖的四维阻尼力，其中第四分量对应新的标量势。

Abstract: In this manuscript, we present another new thermal scalar and vector gauge
potentials implemented by the quantum Boltzmann equation, which originates from
the interaction of conduction electrons and phonons. To accomplish this task,
we derive a temperature dependent four dimensional damping force by the Taylor
series expansion on the self energy of the QBE, which can be related to the
thermal scalar and vector gauge potentials, especially the fourth component of
the damping force, which is just a power corresponding to a new scalar
potential. Based on the local equilibrium assumption, we solve the QBE order by
order using the Fourier transformation method. The temperature dependent
damping force and other physical observables are exhibited in the figures, the
higher of the temperature, the bigger of the damping force.

</details>


### [282] [Detecting Entanglement in High-Spin Quantum Systems via a Stacking Ensemble of Machine Learning Models](https://arxiv.org/abs/2507.12775)
*M. Y. Abd-Rabbou,Amr M. Abdallah,Ahmed A. Zahia,Ashraf A. Gouda,Cong-Feng Qiao*

Main category: quant-ph

TL;DR: Ensemble machine learning, using NNs, XGBoost, and Extra Trees with CatBoost as a meta-learner, reliably estimates quantum entanglement (negativity) in complex systems, overcoming computational challenges and showing better consistency than individual models.


<details>
  <summary>Details</summary>
Motivation: Traditional methods face significant computational challenges in reliably detecting and quantifying quantum entanglement, particularly in high-spin or many-body systems. This study aimed to explore the effectiveness of ensemble machine learning as a scalable and reliable alternative for estimating entanglement.

Method: An ensemble regressor was constructed by integrating Neural Networks (NNs), XGBoost (XGB), and Extra Trees (ET). This ensemble model, utilizing a stacking meta-learner (CatBoost), was trained on datasets of pure states and mixed Werner states across various spin dimensions to predict entanglement negativity.

Result: The ensemble model demonstrated robust performance, accurately predicting negativity across different dimensionalities and state types. Visual analysis showed superior predictive consistency and lower deviation from true entanglement values compared to individual models like NNs. An empirical formula for estimating data requirements was also derived.

Conclusion: Ensemble machine learning models, specifically a stacking ensemble with CatBoost as the meta-learner, offer a reliable and scalable approach for estimating quantum entanglement (negativity) in quantum systems, outperforming individual strong learners in predictive consistency and accuracy, especially in high-dimensional and many-body systems.

Abstract: Reliable detection and quantification of quantum entanglement, particularly
in high-spin or many-body systems, present significant computational challenges
for traditional methods. This study examines the effectiveness of ensemble
machine learning models as a reliable and scalable approach for estimating
entanglement, measured by negativity, in quantum systems. We construct an
ensemble regressor integrating Neural Networks (NNs), XGBoost (XGB), and Extra
Trees (ET), trained on datasets of pure states and mixed Werner states for
various spin dimensions. The ensemble model with stacking meta-learner
demonstrates robust performance by CatBoost (CB), accurately predicting
negativity across different dimensionalities and state types. Crucially, visual
analysis of prediction scatter plots reveals that the ensemble model exhibits
superior predictive consistency and lower deviation from true entanglement
values compared to individual strong learners like NNs, even when aggregate
metrics are comparable. This enhanced reliability, attributed to error
cancellation and variance reduction inherent in ensembling, underscores the
potential of this approach to bypass computational bottlenecks and provide a
trustworthy tool for characterizing entanglement in high-dimensional quantum
physics. An empirical formula for estimating data requirements based on system
dimensionality and desired accuracy is also derived.

</details>


### [283] [Current-based metrology with two-terminal mesoscopic conductors](https://arxiv.org/abs/2507.12907)
*Shishir Khandelwal,Gabriel T. Landi,Géraldine Haack,Mark T. Mitchison*

Main category: quant-ph

TL;DR: 在量子计量学中，本研究提出了一种超越传统量子Fisher信息的方法，通过分析开放量子系统中的随机电流来估计参数。研究发现，在Landauer-Büttiker形式下，箱型传输函数是实现高精度计量的最优选择，尤其适用于任意耦合和温度条件。


<details>
  <summary>Details</summary>
Motivation: 研究开放量子系统中的参数估计问题，特别是在非马尔可夫（non-Markovian）等任意耦合和温度条件下，弥补现有基于电流的计量方法仅限于马尔可夫主方程的局限性。

Method: 在 Landauer-Büttiker 形式下，识别决定精度和复杂性的关键要素，并在线性响应和零温度条件下获得解析结果。

Result: 确定了决定两端介观导体中参数估计精度的关键要素，并在特定条件下获得了精度分析结果。

Conclusion: 箱型传输函数在所有参数范围内对于基于电流的计量都是最优的。

Abstract: The traditional approach to quantum parameter estimation focuses on the
quantum state, deriving fundamental bounds on precision through the quantum
Fisher information. In most experimental settings, however, performing
arbitrary quantum measurements is highly unfeasible. In open quantum systems,
an alternative approach to metrology involves the measurement of stochastic
currents flowing from the system to its environment. However, the present
understanding of current-based metrology is mostly limited to Markovian master
equations. Considering a parameter estimation problem in a two-terminal
mesoscopic conductor, we identify the key elements that determine estimation
precision within the Landauer-B\"uttiker formalism. Crucially, this approach
allows us to address arbitrary coupling and temperature regimes. Furthermore,
we obtain analytical results for the precision in linear-response and
zero-temperature regimes. For the specific parameter estimation task that we
consider, we demonstrate that the boxcar transmission function is optimal for
current-based metrology in all parameter regimes.

</details>


### [284] [Disordered purification phase transition in hybrid random circuits](https://arxiv.org/abs/2507.12886)
*Kengo Anzai,Hiroaki Matsueda,Yoshihito Kuno*

Main category: quant-ph

TL;DR: 通过研究噪声的空间不均匀性，我们发现空间调制可以改变量子线路中净化相变的临界性，并可能导致保留短程纠缠的新相变。


<details>
  <summary>Details</summary>
Motivation: 鉴于实际量子线路中噪声的空间不均匀性，研究空间调制对净化相变的影响。

Method: 通过研究混合随机克利福德电路中空间调制对净化相变的影响，并使用多体负熵作为提取混合态中量子纠缠的有效可观测值。

Result: 空间不均匀性会改变净化相变的临界性，临界关联长度指数从 $\nu < 2$（均匀概率）变为 $\nu > 2$（空间调制概率）。

Conclusion: 空间调制可以诱导量子线路的相变，并导致保留短程量子纠缠的不同纯净相位。

Abstract: Noise is inevitable in realistic quantum circuits. It arises randomly in
space. Inspired by spatial non-uniformity of the noise, we investigate the
effects of spatial modulation on purification phase transitions in a hybrid
random Clifford circuit. As an efficient observable for extracting quantum
entanglement in mixed states, we employ many-body negativity. The behavior of
the many-body negativity well characterizes the presence of the purification
phase transitions and its criticality. We find the effect of spatial
non-uniformity in measurement probability on purification phase transition. The
criticality of the purification phase transition changes from that of uniform
probability, which is elucidated from the argument of the Harris criterion. The
critical correlation length exponent $\nu$ changes from $\nu < 2$ for uniform
probability to $\nu > 2$ for spatially modulated probability. We further
investigate a setting where two-site random Clifford gate becomes spatially
(quasi-)modulated. We find that the modulation induces a phase transition,
leading to a different pure phase where a short-range quantum entanglement
remains.

</details>


### [285] [Unsupervised Techniques to Detect Quantum Chaos](https://arxiv.org/abs/2507.12887)
*Dmitry Nemirovsky,Ruth Shir,Dario Rosa,Victor Kagalovsky*

Main category: quant-ph

TL;DR: 通过无监督神经网络直接从哈密顿量矩阵检测量子混沌，无需对角化。


<details>
  <summary>Details</summary>
Motivation: 传统的量子混沌谱探测方法需要计算哈密顿量的特征值甚至特征向量，这需要昂贵的计算时间。本研究旨在测试是否可以通过无监督神经网络直接从哈密顿量矩阵中检测量子混沌，从而避免对角化过程。

Method: 使用自组织映射（一种无监督神经网络）直接从哈密顿量矩阵中检测量子混沌，并将结果与传统的谱分析进行比较。

Result: 结果表明，与光谱分析一致，无监督神经网络能够成功检测到随着随机性增加而发生的从可积谱统计到混沌谱统计的转变。

Conclusion: 无监督神经网络，特别是自组织映射，可以直接从哈密顿量矩阵中检测量子混沌，而无需进行昂贵的对角化计算。

Abstract: Conventional spectral probes of quantum chaos require eigenvalues, and
sometimes, eigenvectors of the quantum Hamiltonian. This involves
computationally expensive diagonalization procedures. We test whether an
unsupervised neural network can detect quantum chaos directly from the
Hamiltonian matrix. We use a single-body Hamiltonian with an underlying random
graph structure and random coupling constants, with a parameter that determines
the randomness of the graph. The spectral analysis shows that increasing the
amount of randomness in the underlying graph results in a transition from
integrable spectral statistics to chaotic ones. We show that the same
transition can be detected via unsupervised neural networks, or more
specifically, Self-Organizing Maps by feeding the Hamiltonian matrix directly
into the neural network, without any diagonalization procedure.

</details>


### [286] [A superinductor in a deep sub-micron integrated circuit](https://arxiv.org/abs/2507.13202)
*T. H. Swift,F. Olivieri,G. Aizpurua-Iraola,J. Kirkman,G. M. Noah,M. de Kruijf,F. E. von Horstig,A. Gomez-Saiz,J. J. L. Morton,M. F. Gonzalez-Zalba*

Main category: quant-ph

TL;DR: 本研究在硅集成电路上利用TiN薄膜实现了高性能超感应器，并成功构建了灵敏度提升超百倍的rfSET，为量子计算等领域带来重大突破。


<details>
  <summary>Details</summary>
Motivation: 超感应器在量子计算、计量和传感等领域具有重要应用，但传统上需要使用约瑟夫森结、超导纳米线或扭曲二维材料等包含稀有材料的元件。本研究旨在探索在硅集成电路中实现超感应器的方法，以利用现有制造工艺并提高器件性能。

Method: 本研究利用22nm FDSOI工艺中原有的氮化钛（TiN）薄膜的高动量电感（约1 nH/□）在硅集成电路上实现了超感应器。通过将该超感应器与同一集成电路中的硅量子点进行接口，构建了射频单电子晶体管（rfSET）。

Result: 与现有技术相比，本研究实现的集成rfSET的寄生效应降低，阻抗更高，使得灵敏度提升超过两个数量级，同时面积减小了10,000倍。这标志着在提高量子比特传感器性能和集成度方面取得了显著进展。

Conclusion: 本研究成功在硅集成电路中利用氮化钛薄膜的高动量电感实现了超感应器，并将其与硅量子点集成，展示了射频单电子晶体管（rfSET）。与现有技术相比，该集成rfSET的寄生效应显著降低，阻抗更高，从而实现了超过两个数量级的灵敏度提升和10,000倍的面积减小。这项技术不仅为构建密集的高性能量子比特传感器阵列奠定了基础，还为天文学探测器、超材料研究以及基于一维和二维谐振器阵列的量子模拟器等领域开辟了新的可能性。

Abstract: Superinductors are circuit elements characterised by an intrinsic impedance
in excess of the superconducting resistance quantum
($R_\text{Q}\approx6.45~$k$\Omega$), with applications from metrology and
sensing to quantum computing. However, they are typically obtained using exotic
materials with high density inductance such as Josephson junctions,
superconducting nanowires or twisted two-dimensional materials. Here, we
present a superinductor realised within a silicon integrated circuit (IC),
exploiting the high kinetic inductance ($\sim 1$~nH/$\square$) of TiN thin
films native to the manufacturing process (22-nm FDSOI). By interfacing the
superinductor to a silicon quantum dot formed within the same IC, we
demonstrate a radio-frequency single-electron transistor (rfSET), the most
widely used sensor in semiconductor-based quantum computers. The integrated
nature of the rfSET reduces its parasitics which, together with the high
impedance, yields a sensitivity improvement of more than two orders of
magnitude over the state-of-the-art, combined with a 10,000-fold area
reduction. Beyond providing the basis for dense arrays of integrated and
high-performance qubit sensors, the realization of high-kinetic-inductance
superconducting devices integrated within modern silicon ICs opens many
opportunities, including kinetic-inductance detector arrays for astronomy and
the study of metamaterials and quantum simulators based on 1D and 2D resonator
arrays.

</details>


### [287] [Robustness of Magic in the quantum Ising chain via Quantum Monte Carlo tomography](https://arxiv.org/abs/2507.12902)
*Hari Timsina,Yi-Ming Ding,Emanuele Tirrito,Poetri Sonya Tarabunga,Bin-Bin Mao,Mario Collura,Zheng Yan,Marcello Dalmonte*

Main category: quant-ph

TL;DR: 本研究量化了量子伊辛链中魔法（magic）的行为，发现它与临界行为直接相关，并且在有限温度下表现出与纠缠（entanglement）不同的“不死”特性。


<details>
  <summary>Details</summary>
Motivation: 研究量子伊辛链（quantum Ising chain）在量子相变（quantum phase transition）和有限温度下，魔法（magic）作为一种双量子比特关联（bipartite correlation）的行为。

Method: 本研究通过结合量子蒙特卡洛（quantum Monte Carlo）的随机采样方法和用于估计混合态（mixed states）鲁棒性的（robustness）估计器，提出了一种混合方案来量化（quantify）约简密度矩阵（reduced density matrices）的魔法（magic）。

Result: 在临界点，魔法的互斥性（mutual robustness）随子系统间距离呈现幂律衰减（power law decay），其指数与子系统大小有关。当考虑有限温度时，魔法的互斥性在有效临界温度（effective critical temperature）下能保持其低温值，且该有效临界温度的尺寸依赖性也是代数性的。

Conclusion: 魔法（magic）作为一种双量子比特关联，在量子伊辛链的量子相变以及有限温度下表现出与临界行为的直接联系，其指数与子系统大小有关。即使在有限温度下，魔法的互斥性（mutual robustness）也能在有效临界温度下保持其低温值，并且与尺寸的关系也是代数性的，这表明魔法可能不会像纠缠（entanglement）那样经历突然的死亡。

Abstract: We study the behavior of magic as a bipartite correlation in the quantum
Ising chain across its quantum phase transition, and at finite temperature. In
order to quantify the magic of partitions rigorously, we formulate a hybrid
scheme that combines stochastic sampling of reduced density matrices via
quantum Monte Carlo, with state-of-the-art estimators for the robustness of
magic - a {\it bona fide} measure of magic for mixed states. This allows us to
compute the mutual robustness of magic for partitions up to 8 sites, embedded
into a much larger system. We show how mutual robustness is directly related to
critical behaviors: at the critical point, it displays a power law decay as a
function of the distance between partitions, whose exponent is related to the
partition size. Once finite temperature is included, mutual magic retains its
low temperature value up to an effective critical temperature, whose dependence
on size is also algebraic. This suggests that magic, differently from
entanglement, does not necessarily undergo a sudden death.

</details>


### [288] [Topology-Enhanced Superconducting Qubit Networks for In-Sensor Quantum Information Processing](https://arxiv.org/abs/2507.13228)
*J. Settino,G. G. Luciano,A. Di Bartolomeo,P. Silvestrini,M. Lisitskiy,B. Ruggiero,F. Romeo*

Main category: quant-ph

TL;DR: 研究了拓扑对超导量子比特网络磁响应的影响，发现十字形阵列比线性阵列具有更强的磁响应，并展示了其在量子传感、量子信息处理和量子储 reservoir 计算机技术中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 研究电感耦合超导通量量子比特网络中拓扑对磁响应的影响。

Method: 采用精确对角化方法和线性响应理论。

Result: 十字形阵列的耦合矩阵显著增强了磁通响应，这源于中心和外围量子比特间的协同耦合。

Conclusion: 该研究为功能导向的超导量子电路提供了定量设计标准，对量子传感和量子信息处理的性能提升具有直接影响。通过利用这类网络的非线性高维动力学，它们也适用于量子储 reservoir 计算机技术。这种双重功能表明，相同的器件可以同时作为量子限制电磁传感器和用于信号处理的储 reservoir，从而实现集成量子传感和处理架构。

Abstract: We investigate the influence of topology on the magnetic response of
inductively coupled superconducting flux-qubit networks. Using exact
diagonalization methods and linear response theory, we compare the magnetic
response of linear and cross-shaped array geometries, used as paradigmatic
examples. We find that the peculiar coupling matrix in cross-shaped arrays
yields a significant enhancement of the magnetic flux response compared to
linear arrays, this network-topology effect arising from cooperative coupling
among the central and the peripheral qubits. These results establish
quantitative design criteria for function-oriented superconducting quantum
circuits, with direct implications for advancing performance in both quantum
sensing and quantum information processing applications. Concerning the latter,
by exploiting the non-linear and high-dimensional dynamics of such arrays, we
demonstrate their suitability for quantum reservoir computing technology. This
dual functionality suggests a novel platform in which the same device serves
both as a quantum-limited electromagnetic sensor and as a reservoir capable of
signal processing, enabling integrated quantum sensing and processing
architectures.

</details>


### [289] [Deterministic Generation of Four-Component Schrödinger Cat States via Floquet Engineering in a Hybrid Magnon-Superconductor System](https://arxiv.org/abs/2507.12924)
*Shiwen He,Zi-Long Yang,Sitong Jin,Feng-Yang Zhang,Chong Li*

Main category: quant-ph

TL;DR: 提出一种在混合量子系统中（包含两个超导量子比特、微波腔和磁子模式）通过周期性驱动生成四组分薛定谔猫态的方法，该方法具有高保真度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 四组分薛定谔猫态（由相空间中对称排列的四个相干态叠加而成）具有丰富的非经典特征和增强的抗退相干能力，是量子信息科学的有希望的资源。

Method: 通过对超导量子比特施加周期性横向驱动，导出有效的哈密顿量，该哈密顿量根据联合量子比特状态有条件地位移磁子模式。在σx基中进行条件测量将磁子模式投影到具有高保真度的非经典四组分猫态。

Result: 通过对量子比特退相干、磁子损耗和腔耗散影响的系统分析，证明了该方案对耗散的鲁棒性。

Conclusion: 该方案为基于非经典磁振子态的混合量子信息处理提供了一种新方法，实现了在可扩展固态平台中生成多组分量子叠加态。

Abstract: Four-component Schr\"odinger cat states, superpositions of four coherent
states symmetrically arranged in phase space, offer rich nonclassical features
and enhanced resilience to decoherence, making them promising resources for
quantum information science. We propose a Floquet-engineered scheme to
deterministically generate four-component Schr\"odinger cat states in a hybrid
quantum system composed of two superconducting qubits, a microwave cavity, and
a magnon mode. By applying periodic transverse drives to the qubits, we derive
an effective Hamiltonian that conditionally displaces the magnon mode depending
on the joint qubit state. Conditional measurements in the $\sigma_x$ basis
project the magnon mode into nonclassical four-component cat states with high
fidelity. The Wigner functions in the original frame verified the
non-classicality of the four-component Schr\"odinger cat states. Results of
systematically analyzing the impacts of qubit decoherence, magnon loss, and
cavity dissipation demonstrate the robustness to the dissipation. The results
show that this scheme can realize the generation of multi-component quantum
superposition states in a scalable solid-state platform, providing a new
approach for hybrid quantum information processing based on nonclassical magnon
states.tates.

</details>


### [290] [Circular-beam approximation for quantum channels in the turbulent atmosphere](https://arxiv.org/abs/2507.12947)
*I. Pechonkin,M. Klen,A. A. Semenov*

Main category: quant-ph

TL;DR: 该研究提出了一种简化的圆光束近似模型和参数评估技术，用于量化自由空间量子通信中的大气信道，提高了效率和适用范围。


<details>
  <summary>Details</summary>
Motivation: 为了解决自由空间量子通信中大气湍流引起的信道透射率随机波动问题，需要一个能够准确描述概率分布（PDT）且计算复杂度低的分析模型。

Method: 提出了一种简化的圆光束近似模型，并通过基于透射率前两个矩的替代技术来评估模型参数。

Result: 圆光束近似模型提供了令人满意的准确性，同时显著降低了计算复杂度，并且通过结合基于前两个矩的参数评估技术，扩展了模型的适用范围。

Conclusion: 提出了一种简化的圆光束近似模型，并结合基于透射率前两个矩的替代参数评估技术，扩展了概率分布模型（PDT）的应用范围，为量化大气信道在量子应用中的应用提供了实用的工具。

Abstract: The evolution of quantum states of light in free-space channels is strongly
influenced by atmospheric turbulence, posing a significant challenge for
quantum communication. The transmittance in such channels randomly fluctuates.
This effect is commonly described by the probability distribution of
transmittance (PDT). The elliptic-beam approximation provides an analytical
model for the PDT, showing good agreement with experimental and simulation data
within a specific range of channel parameters. In this work, we introduce the
circular-beam approximation -- a simplified alternative that offers
satisfactory accuracy while significantly reducing computational complexity. We
also present an alternative technique for evaluating the parameters of this
model based on the first two moments of transmittance. This approach notably
extends the applicability range of our PDT model, offering a practical tool for
characterizing atmospheric channels in quantum applications.

</details>


### [291] [Optimized Measurements of Rabi model in a linear potential under Strong Doppler shifts](https://arxiv.org/abs/2507.12971)
*Dongyang Yu*

Main category: quant-ph

TL;DR: 该研究利用SU(2)李群理论和Fisher信息理论，分析了多普勒效应对原子重力仪Rabi振荡的影响，为开发高灵敏度、抗噪声原子重力仪提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 为了提高原子重力仪的灵敏度，利用原子外自由度的量子资源，特别是具有大动量展宽的物质波态，但对该方法中关键的多普勒效应缺乏全面的量子力学研究。

Method: 利用SU(2)李群理论推导出Rabi模型的酉动力学方程，并分析了多普勒效应对Rabi振荡的影响。结合Fisher信息理论，论证了强多普勒展宽下相位旋转测量方案的近普适性和高测量增益。

Result: 证明了强多普勒展宽下相位旋转测量方案的近乎普遍性和高测量增益。

Conclusion: 该理论工作为开发利用外部态量子资源的高灵敏度、抗噪声原子重力仪奠定了理论基础。

Abstract: Harnessing quantum resources in the atomic external degrees of
freedom--particularly matter-wave states with broad momentum spreads--holds
significant potential for enhancing the sensitivity of Kasevich-Chu atom
gravimeters at the standard quantum limit. However, a fully quantum-mechanical
investigation of the critical Doppler effect inherent to this approach remains
lacking. Employing the SU(2) Lie group theory, we derive a generic Riccati
equation governing the unitary dynamics of the Rabi model within a linear
potential and analyze the Doppler effect impact on Rabi oscillations because of
the strong coupling between the internal and external states. Furthermore, by
integrating Fisher information theory, we specifically demonstrate the
near-universality and high metrological gain of phase rotation measurement
protocols under strong Doppler broadening. This theoretical work provides
insightful implications for boarder generalization, such as extensions to
finite-temperature scenarios or multi-pulse sequences--exemplified by the
$\pi/2-\pi-\pi/2$ pulse sequence characteristic of Kasevich-Chu atom
gravimeters. Thus, this work lays a theoretical foundation for developing
high-sensitivity, noise-resistant atom gravimeters leveraging external-state
quantum resources.

</details>


### [292] [Practical Subarchitectures for Optimal Quantum Layout Synthesis](https://arxiv.org/abs/2507.12976)
*Kostiantyn V. Milkevych,Jaco van de Pol,Irfansha Shaik*

Main category: quant-ph

TL;DR: A new method for Quantum Layout Synthesis (QLS) effectively reduces the complexity of finding optimal layouts by focusing on relevant subarchitectures, improving efficiency for noisy quantum computers.


<details>
  <summary>Details</summary>
Motivation: Optimal QLS is an NP-hard problem crucial for minimizing circuit size and depth to reduce noise on quantum platforms. Current methods require considering exponentially many subarchitectures to guarantee optimality, which is computationally expensive. The motivation is to find a more effective way to handle this by focusing on relevant subarchitectures.

Method: The proposed method involves assuming a fixed number of ancilla qubits that can be used in the mapping. This allows for the enumeration of relevant subarchitectures, which in turn reduces the search space and the computational cost of subgraph isomorphism checks.

Result: The technique is evaluated on benchmarks and compared with state-of-the-art Optimal QLS tools, showing improved performance when using subarchitectures compared to methods without them.

Conclusion: The paper introduces an effective method to enumerate relevant subarchitectures for Quantum Layout Synthesis (QLS), which guarantees optimality for a selected ancilla bound and boosts performance by reducing the number of considered subarchitectures and subgraph isomorphism checks.

Abstract: Quantum Layout Synthesis (QLS) maps a logical quantum circuit to a physical
quantum platform. Optimal QLS minimizes circuit size and depth, which is
essential to reduce the noise on current quantum platforms. Optimal QLS is an
NP-hard problem, so in practice, one maps a quantum circuit to a subset of the
complete quantum platform. However, to guarantee optimality, one still has to
consider exponentially many subarchitectures.
  We introduce an effective method to enumerate relevant subarchitectures. This
reduces the number of considered subarchitectures, as well as the number of
expensive subgraph isomorphism checks, thus boosting Optimal QLS with
subarchitectures. To do so, we assume a fixed number of ancilla qubits that can
be used in the mapping. We guarantee optimality of the quantum layout, for the
selected ancilla bound.
  We evaluate our technique on a number of benchmarks and compare it with
state-of-the-art Optimal QLS tools with and without using subarchitectures.

</details>


### [293] [Trap-to-trap free falls with an optically levitated nanoparticle](https://arxiv.org/abs/2507.12995)
*M. Luisa Mattana,Nicola Carlon Zambon,Massimiliano Rossi,Eric Bonvin,Louisiane Devaud,Martin Frimmer,Lukas Novotny*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We perform free-fall experiments with a charge-neutral, optically levitated
nanoparticle. This is achieved using an optical tweezer that can be rapidly
toggled on and off and vertically displaced, enabling the particle to be
released and recaptured after each free fall. The particle is insensitive to
electric fields due to its charge neutrality and, during free evolution, is not
subject to photon recoil heating. We achieve free-fall durations of up to 0.25
ms and observe a nearly two hundred-fold increase in the particle's position
uncertainty at recapture. The current limit on the free-fall time arises from
the performance of the initial cooling step. By implementing linear feedback
techniques and reducing the background pressure, we expect to perform
millisecond-scale free-fall experiments in ultra-high vacuum, opening new
opportunities for generating large delocalizations of levitated objects.

</details>


### [294] [A Modular PyTheus Quantum Network Interpreter: Automated Analysis and Visualization of Optimized Quantum Architectures](https://arxiv.org/abs/2507.12997)
*S. K. Rithvik*

Main category: quant-ph

TL;DR: 我们提出了一个模块化的PyTheus优化量子网络解释器，可以自动分析和可视化复杂的量子架构。该解释器通过功能角色识别、图论分析和可视化来解决理解机器设计的量子网络这一挑战。它成功地处理了复杂的连接模式，并为架构一致性提供了验证机制。


<details>
  <summary>Details</summary>
Motivation: 解释器解决了理解机器设计的量子网络这一关键挑战，通过提供功能角色识别、图论分析和跨PyTheus生成的网络主要类别的物理意义可视化的强大算法。

Method: 本解释器通过基于优先级的分类自动识别源、探测器、分束器和辅助器，并生成协调的原生图形绘制和光学平台表示。我们通过两种互补的方法演示了解释器的能力：(1) 分析新开发的五节点量子密钥分发网络，揭示了分布式源架构和双重节点功能；(2) 使用现有的PyTheus示例进行全面验证，包括W4状态生成、 the heralded Bell state preparation和GHZ状态网络。

Result: 解释器接受基于文件和内存的网络表示，并成功处理各种量子网络架构的复杂连接模式，避免可视化伪影，并提供架构一致性的验证机制。

Conclusion: 该解释器能够成功处理所测试类别中各种量子架构的复杂连接模式，避免可视化伪影，并提供架构一致性的验证机制。我们主要贡献是开发了鲁棒的模块化解释算法，能够分析PyTheus生成的主要类别量子网络，从而更好地理解自动化的量子架构设计。

Abstract: We present a modular interpreter for PyTheus-optimized quantum networks that
automatically analyzes and visualizes complex quantum architectures discovered
through automated optimization. The interpreter addresses the critical
challenge of understanding machine-designed quantum networks by providing
robust algorithms for functional role identification, graph-theoretical
analysis, and physically meaningful visualization across the major classes of
PyTheus-generated networks. Our interpreter accepts both file-based and
in-memory network representations, automatically identifies sources, detectors,
beam splitters, and ancillas through priority-based classification, and
generates coordinated native graph plots and optical table representations. We
demonstrate the interpreter's capabilities through two complementary
approaches: (1) analysis of a newly developed five-node quantum key
distribution network that reveals distributed source architecture and dual-role
node functionality, and (2) comprehensive validation using existing PyTheus
examples including W4 state generation, heralded Bell state preparation, and
GHZ state networks. The interpreter successfully handles complex connectivity
patterns across diverse quantum network architectures within the tested
classes, avoids visualization artifacts, and provides validation mechanisms for
architectural consistency. Our primary contribution is the development of
robust modular interpretation algorithms that can analyze the major classes of
PyTheus-generated quantum networks, enabling better understanding of automated
quantum architecture design.

</details>


### [295] [Quantum Kramers-Henneberger Transformation](https://arxiv.org/abs/2507.13006)
*Javier Argüello-Luengo,Javier Rivera-Dean,Philipp Stammer,Marcelo F. Ciappina,Maciej Lewenstein*

Main category: quant-ph

TL;DR: 本文将Kramers-Henneberger变换推广到量子领域，考虑了量子涨落，并提出了实验验证方案，为量子模拟开辟了新途径。


<details>
  <summary>Details</summary>
Motivation: 本文旨在将经典的Kramers-Henneberger变换扩展到量子电动力学和量子光学领域，并探索量子涨落对系统动力学的影响。

Method: 本文通过显式地在量子力学层面处理阱的位置，将经典的Kramers-Henneberger变换扩展到量子电动力学和量子光学领域，从而考虑了时变位移力的量子涨落。

Result: 本文表明，与经典情况相比，量子电动力学修正会出现，并提出了一个光力学实现的方案，以量化陷阱的位置，表明这些修正可以在最新的实验中体现出来。

Conclusion: 本文将经典的Kramers-Henneberger变换推广到量子电动力学和量子光学领域，明确地在量子力学层面处理阱的位置，从而考虑了时变位移力的量子涨落。与经典情况相比，我们证明了量子电动力学修正的出现，并提出了一个光力学实现的方案，以量化陷阱的位置，表明这些修正可以在最新的实验中体现出来。这些结果为利用超冷囚禁原子和离子进行阿秒物理和超快物理的量子电动力学和量子光学的新颖量子模拟开辟了道路。

Abstract: The classical Kramers-Henneberger transformation connects, via a series of
unitary transformations, the dynamics of a quantum particle of mass $m$ located
in a trap at position $\alpha(t)$, with the dynamics of a charge $e$ moving in
an electric field $e{\cal{E}}(t)=-m\ddot{\alpha}(t)$ within the dipole
approximation. In this paper, we extend the classical Kramers-Henneberger
transformation to the quantum electrodynamic and quantum optical realm, by
explicitly treating the trap location quantum mechanically, thus taking into
account the quantum fluctuations of the time-dependent displacement force.
Compared to the classical case, we show that quantum electrodynamic corrections
appear, and we propose an optomechanical realization for the quantized position
of the trap to show that such corrections can manifest in state-of-the-art
experiments. These results open the path to novel quantum simulation of quantum
electrodynamics and quantum optics of attoscience and ultrafast physics by
using ultracold trapped atoms and ions.

</details>


### [296] [Dark-state photonic entanglement filters](https://arxiv.org/abs/2507.13016)
*Stefano Longhi*

Main category: quant-ph

TL;DR: 无需复杂的非厄米对称性即可通过后选择和暗态过滤纠缠。


<details>
  <summary>Details</summary>
Motivation: 克服量子技术中在退相干存在下保持纠缠的挑战，并简化现有基于光子滤波器和反奇偶时间对称性的方法。

Method: 通过最小化的波导网络设计，利用由破坏性干涉产生的暗态进行后选择，以实现纠缠过滤。

Result: 展示了一种无需特殊浴工程或非厄米对称性的纠缠过滤方法，该方法具有更强的通用性和更广泛的适用性。 thiểu波导网络设计和暗态的出现是关键。 

Conclusion: 后选择和暗态的出现是纠缠过滤的关键机制，无需严格的非厄米对称性约束，从而简化了设计和体系结构，提高了通用性，并扩展了适用性。

Abstract: Preserving entanglement in the presence of decoherence remains a major
challenge for quantum technologies. Recent proposals [M.A. Selim et al.,
Science 387, 1424 (2025)] have employed photonic filters based on
anti-parity-time symmetry to recover certain entangled states, but these
approaches require intricate, symmetry-constrained waveguide architectures and
precise bath engineering. In this work, we show that such strict non-Hermitian
symmetry constraints are not necessary for entanglement filtering. Instead, we
identify post-selection and the emergence of dark states -- arising naturally
through destructive interference in simple photonic settings -- as the
essential mechanisms. By avoiding the need for special bath engineering or
non-Hermitian symmetries, our approach significantly simplifies the design and
architecture, enhances universality, and extends applicability beyond
previously studied dimer configurations. We demonstrate this concept using
minimal waveguide network designs, offering a broadly accessible route to
robust entanglement filtering.

</details>


### [297] [Geometry of quantum states and chaos-integrability transition](https://arxiv.org/abs/2507.13067)
*Ankit Gill,Keun-Young Kim,Kunal Pal,Kuntal Pal*

Main category: quant-ph

TL;DR: 本研究探索了随机矩阵哈密顿量的量子几何，重点关注保真度易感性和量子度量张量。研究计算了高斯幺范和高斯β范的保真度易感性，并求解了可积性破坏哈密顿量的测地线方程。结果表明，保真度易感性具有通用特征，并且可以实现与可积相的距离。


<details>
  <summary>Details</summary>
Motivation: 为了研究与随机矩阵哈密顿量相关的量子态几何，特别是那些在最近邻能量水平间距分布方面表现出可积性到混沌过渡的系。

Method: 本研究计算了高斯幺范和高斯β范（具有任意Dyson指数β）的随机矩阵系的保真度易感性，并推导了与可积性破坏的随机矩阵哈密顿量相关的量子度量张量的测地线方程。

Result: 研究表明，与高斯幺范和高斯β范（具有任意Dyson指数β）的随机矩阵系相关的保真度易感性与其他类哈密顿量具有通用特征。此外，研究还表明，从可积性相远离的任何点都可以通过有限值距离到达。

Conclusion: 该研究计算了属于高斯幺范和高斯β范（具有任意Dyson指数β）的随机矩阵系的保真度易感性，并表明它与其他类哈密顿量具有共同的通用特征。

Abstract: We consider the geometry of quantum states associated with classes of random
matrix Hamiltonians, in particular ensembles that show integrability to chaotic
transition in terms of the nearest neighbour energy level spacing distribution.
In the case that the total Hamiltonian contains a single parameter, the
distance between two states is captured by the fidelity susceptibility,
whereas, when the total Hamiltonian contains multiple parameters, this distance
is given by the quantum metric tensor. Since the fieldity susceptibility is
closely related to the two-point correlation function, we first calculate the
relevant correlation functions of a random matrix belonging to the Gaussian
unitary ensemble in terms of the spectral form factor of the total Hamiltonian,
show how to obtain the fidelity susceptibility from this correlation function,
and explain the role played by energy level correlation. Next, by performing
suitable coordinate transformations, we solve the geodesic equations
corresponding to the quantum metric tensor obtained from an
integrability-breaking random matrix Hamiltonian and obtain the geodesic
distance between two points on the parameter manifold to show that any point
far away from the integrable phase can be reached by a finite value of this
distance. Finally, we obtain and discuss different properties of the fidelity
susceptibility associated with Hamiltonians belonging to another random matrix
ensemble which shows integrability to chaos transition, namely the Gaussian
$\beta$-ensembles with general values of the Dyson index $\beta$, and show that
the fidelity susceptibility shares generic features with the first class of
Hamiltonians.

</details>


### [298] [Emulation of Self-Consistent Non-Hermitian Quantum Formalisms](https://arxiv.org/abs/2507.13078)
*Mario Gonzalez,Karin Sim,R. Chitra*

Main category: quant-ph

TL;DR: 本研究提出一种新的算子扩张方案，将非厄米量子力学嵌入闭合厄米系统中，并通过数字量子模拟器在量子比特中实现了非厄米性产生的动力学度量的首次实验证据，为非厄米系统的量子模拟开辟了新范例。


<details>
  <summary>Details</summary>
Motivation: 标准量子力学在放松哈密顿量厄米性要求时，会预测状态范数和概率的不守恒。而双正交量子力学或更一般的度量形式主义，在非厄米量子力学中提供了严格的表述，其中范数和概率是守恒的。然而，度量形式主义的物理实现仍未得到解决。

Method: 利用数字量子模拟器，在量子比特中展示了非厄米性产生的动力学度量的原理及首次实验证据。

Result: 通过数字量子模拟器，在量子比特中展示了非厄米性产生的动力学度量的原理及首次实验证据。

Conclusion: 本研究提出算子扩张方案，展示了通过嵌入闭合厄米系统中，在物理平台上可以实现自洽的非厄米量子力学。

Abstract: Standard quantum mechanics predicts the non-conservation of state norms and
probability when the fundamental requirement of the Hermiticity of the
Hamiltonian is relaxed. Biorthogonal quantum mechanics, or the more general
metric formalism, provides a rigorous formulation of non-Hermitian quantum
mechanics wherein norms and probabilities are conserved. The key feature is
that the Hilbert space is endowed with a non-trivial dynamical metric. Beyond
theoretical considerations, the physical implementation of the metric formalism
remains unaddressed. In this work, we propose novel operator dilation schemes,
which show that the self-consistent non-Hermitian quantum mechanics can be
accessed in physical platforms via an embedding in closed Hermitian systems.
Using digital quantum simulators, we present a proof of principle and the first
experimental evidence for the dynamical metric engendered by non-Hermiticity in
a qubit. Our work ushers in a new paradigm in the quantum simulation of
non-Hermitian systems.

</details>


### [299] [Perspective: Practical Atom-Based Quantum Sensors](https://arxiv.org/abs/2507.13111)
*Justin M. Brown,Thad G. Walker*

Main category: quant-ph

TL;DR: 原子蒸气是强大的量子系统，可用于传感应用。现代激光和电光工具可以利用其量子特性，有望实现高精度原子传感器。


<details>
  <summary>Details</summary>
Motivation: 原子具有相同、可分离、可接口化和可理解的特性，使其成为传感应用的理想选择。

Method: 通过光和其他电磁场操纵和探测原子蒸气，利用其量子性质进行传感。

Result: 该视角讨论了利用原子实现实用量子传感器的潜力和过程。

Conclusion: 原子探针在传感应用中具有巨大潜力，利用其量子特性，结合现代激光和电光工具，可以实现高精度的传感。

Abstract: Atomic vapors, manipulated and probed by light and other electromagnetic
fields, constitute versatile and powerful quantum systems for sensing
applications. Atoms are identical, isolatable, interfaceable, and intelligible.
These features, coupled with the relative simplicity with which quantum
properties can be exploited in state preparation and detection using modern
laser and electro-optic tools, make atoms very attractive for sensing
applications. This Perspective discusses the potential and process for
realizing practical quantum sensors using atoms.

</details>


### [300] [Mechanical Squeezed-Fock Qubit: Towards Quantum Weak-Force Sensing](https://arxiv.org/abs/2507.13161)
*Yi-Fan Qiao,Jun-Hong An,Peng-Bo Li*

Main category: quant-ph

TL;DR: 通过使用压缩福克态，我们提出了一种新的力学量子比特，它具有指数增强的anharmonicity，能够提高相干性和传感能力。


<details>
  <summary>Details</summary>
Motivation: 现有的力学量子比特平台虽然在相干时间和传感应用方面具有优势，但其潜能受到纳米机械谐振器固有的弱非线性和小anharmonicity的限制。

Method: 提出使用参数驱动的非线性机械振荡器中声子的压缩福克态（squeezed Fock states）来克服现有量子比特平台中非线性和anharmonicity的不足。具体来说，在两声子驱动下，压缩福克态成为Kerr非线性机械振荡器的特征态，能量谱具有指数增强和可调的anharmonicity，从而指数级抑制向更高能量态的跃迁。这使得将力学量子比特编码在驱动机械振荡器的基态和第一激发压缩福克态内成为可能。

Result: 在两声子驱动下，压缩福克态成为Kerr非线性机械振荡器的特征态，具有指数增强和可调的anharmonicity，从而指数级抑制向更高能量态的跃迁。这种力学量子比特（机械压缩福克量子比特）的相干性得到了增强，并且其量子传感能力相比传统力学量子比特至少提高了两个数量级。

Conclusion: 力学量子比特（mechanical qubit）可以作为量子传感和信息处理的有力量子声子平台。

Abstract: Mechanical qubits offer unique advantages over other qubit platforms,
primarily in terms of coherence time and possibilities for enhanced sensing
applications, but their potential is constrained by the inherently weak
nonlinearities and small anharmonicity of nanomechanical resonators. We propose
to overcome this shortcoming by using squeezed Fock states of phonons in a
parametrically driven nonlinear mechanical oscillator. We find that, under
two-phonon driving, squeezed Fock states become eigenstates of a Kerr-nonlinear
mechanical oscillator, featuring an energy spectrum with exponentially enhanced
and tunable anharmonicity, such that the transitions to higher energy states
are exponentially suppressed. This enables us to encode the mechanical qubit
within the ground and first excited squeezed Fock states of the driven
mechanical oscillator. This kind of mechanical qubit is termed mechanical
squeezed-Fock qubit. We also show that our mechanical qubit can serve as a
quantum sensor for weak forces, with its resulting sensitivity increased by at
least one order of magnitude over that of traditional mechanical qubits. The
proposed mechanical squeezed-Fock qubit provides a powerful quantum phonon
platform for quantum sensing and information processing.

</details>


### [301] [Quantum-to-Classical Transition via Single-Shot Generalized Measurements](https://arxiv.org/abs/2507.13174)
*Zhenyu Xu*

Main category: quant-ph

TL;DR: 本研究通过结合测量和退相干信道，阐明了维度和退相干率如何影响量子到经典转变，并提出了实现方案。


<details>
  <summary>Details</summary>
Motivation: 阐明量子到经典转变过程中中间阶段的机制，该过程通常被认为是连续发生的，但具体机制尚不清楚。

Method: 本研究采用操作框架，结合广义相干态正算子值测量和各向同性退化信道，研究量子到经典转变的机制。

Result: 维度和退相干率共同决定了量子到经典转变的过程。单次广义测量可以消除有限维系统中相位空间中大部分的负拟概率。

Conclusion: 本研究提出了一种统一的框架，将离散的广义相干态正算子值测量与连续的各向同性退化信道相结合，以解决量子到经典转变的中间阶段机制不清的问题。研究表明，维度和退相干率共同决定了这一转变过程。特别地，单次广义测量能够消除有限维系统中相位空间中大部分的负拟概率。此外，研究还提出了可行的量子电路实现方案，可利用当前最先进的量子技术实现。

Abstract: Quantum-to-classical transition for finite-dimensional systems is widely
considered to occur continuously, yet the mechanism underlying the intermediate
stage remains unclear. In this work, we address this challenge by adopting an
operational framework to bridge discrete generalized coherent state
positive-operator-valued measurements and continuous isotropic depolarizing
channels. Our unified treatment reveals how dimensionality and decoherence rate
collectively govern the quantum-to-classical transition. Notably, we
demonstrate that a single-shot generalized measurement can eliminate most
negative quasi-probabilities in phase space for finite-dimensional systems.
Furthermore, we propose quantum circuit implementations achievable with current
state-of-the-art quantum technologies.

</details>


### [302] [Discrete solitons in Rydberg atom chains](https://arxiv.org/abs/2507.13196)
*Aron Kerschbaumer,Jean-Yves Desaules,Marko Ljubotina,Maksym Serbyn*

Main category: quant-ph

TL;DR: Solitons, robust wave packets, are found in Rydberg atom chains, surviving thermalization. They propagate directionally, carry energy, have long coherence, and can be used for quantum information transfer. A classical model mimics this behavior.


<details>
  <summary>Details</summary>
Motivation: Solitons are crucial for understanding transport in nonlinear systems, but are typically destroyed by thermalization in quantum many-body systems. This research explores the existence of robust solitonic excitations in high-energy states of Rydberg atom chains.

Method: The paper theoretically demonstrates the existence of solitonic excitations by identifying their counterpart in a classical nonlinear dynamical system derived from a variational projection of the quantum dynamics.

Result: The study theoretically demonstrates solitonic excitations in Rydberg atom chains, exhibiting long coherence times and directional propagation. It also identifies a classical nonlinear dynamical system counterpart and suggests potential applications in quantum information transfer and explaining anomalous energy transport.

Conclusion: Solitons exist in high-energy states of Rydberg atom chains with strong nearest-neighbor Rydberg blockade, showing directional propagation and energy transport capabilities. These states represent a new form of non-ergodic quantum dynamics, are implementable on Rydberg atom simulators, and have potential applications in quantum information transfer and understanding anomalous energy transport in Rydberg atom arrays.

Abstract: Solitons - localized wave packets that travel without spreading - play a
central role in understanding transport and properties of nonlinear systems,
from optical fibers to fluid dynamics. In quantum many-body systems, however,
such robust excitations are typically destroyed by thermalization. Here, we
theoretically demonstrate the existence of solitonic excitations in high-energy
states of Rydberg atom chains in the regime of strong nearest-neighbor Rydberg
blockade. These localized wave packets propagate directionally atop a special
class of reviving initial states related to quantum many-body scars and are
capable of carrying energy. Exhibiting long coherence times, these states
constitute a novel type of non-ergodic quantum dynamics and can be efficiently
implemented on Rydberg atom simulators. In addition to a phenomenological
description of solitons, we identify their counterpart in a classical nonlinear
dynamical system obtained from a variational projection of the quantum
dynamics. We demonstrate the potential use of solitons in quantum information
transfer and conjecture their relevance for the anomalous energy transport
reported in numerical studies of Rydberg atom arrays.

</details>


### [303] [Gravity-mediated entanglement via infinite-dimensional systems](https://arxiv.org/abs/2507.13201)
*Stefan L. Ludescher,Leon D. Loveridge,Thomas D. Galley,Markus P. Müller*

Main category: quant-ph

TL;DR: 经典系统（建模为交换幺*代数）无法介导量子系统之间的纠缠。因此，观察到引力诱导的纠缠将表明引力场具有非经典的性质。


<details>
  <summary>Details</summary>
Motivation: 填补了先前研究未能将经典力学和场论等物理上相关的连续和无限维经典系统纳入模型的空白。

Method: 将经典系统建模为交换幺*代数，以涵盖所有可能相关的经典系统。证明了这些系统无法在两个量子系统 A 和 B 之间介导纠缠，即使 A 和 B 是无限维的或由任意幺*代数描述（如量子场论），并与任意 * 张量积复合。

Result: 证明了由交换幺*代数建模的经典系统不能介导量子系统之间的纠缠，无论量子系统是无限维的还是由任意幺*代数描述。

Conclusion: 该研究表明，引力场必须具有固有的非经典特征，才能实现引力诱导的纠缠。

Abstract: There has been a wave of recent interest in detecting the quantum nature of
gravity with table-top experiments that witness gravitationally mediated
entanglement. Central to these proposals is the assumption that any mediator
capable of generating entanglement must itself be nonclassical. However,
previous arguments for this have modelled classical mediators as finite,
discrete systems such as bits, which excludes physically relevant continuous
and infinite-dimensional systems such as those of classical mechanics and field
theory. In this work, we close this gap by modelling classical systems as
commutative unital C*-algebras, arguably encompassing all potentially
physically relevant classical systems. We show that these systems cannot
mediate entanglement between two quantum systems A and B, even if A and B are
themselves infinite-dimensional or described by arbitrary unital C*-algebras
(as in Quantum Field Theory), composed with an arbitrary C*-tensor product.
This result reinforces the conclusion that the observation of gravity-induced
entanglement would require the gravitational field to possess inherently
non-classical features.

</details>


### [304] [Robust and efficient estimation of global quantum properties under realistic noise](https://arxiv.org/abs/2507.13237)
*Qingyue Zhang,Dayue Qin,Zhou You,Feng Xu,Jens Eisert,You Zhou*

Main category: quant-ph

TL;DR: 为了在有噪声的量子系统中更实用地估计全局属性，我们提出了一种基于随机电路和受控-Z门的测量框架，称为鲁棒相位影。该框架在性能上可与标准影相媲美，具有抗噪声能力，并附带一个高效的计算算法。


<details>
  <summary>Details</summary>
Motivation: 测量全局量子属性（例如，复杂多体态的保真度）是一项基本且具有挑战性的实验任务。经典影估计具有良好的样本复杂度，但通常依赖于在当前平台上难以实现的许多量子比特电路。需要一种适用于当前量子架构（如陷阱离子和中性原子）的测量方案。

Method: 提出了一种名为“鲁棒相位影”的测量框架，该框架基于具有受控-Z作为唯一纠缠门类型的随机电路。利用张量图表示法分析了电路系综。设计了一种高效的后处理算法。

Result: 相位影与基于全克利福德的影具有相当的性能。该方法支持通过纯粹的经典后处理进行抗噪声扩展，从而能够在实际的、依赖于门噪声的情况下进行可靠估计。设计的后处理算法解决了先前影协议中的一个关键计算瓶颈。

Conclusion: 这项工作提出了一种名为“鲁棒相位影”的测量框架，该框架基于具有受控-Z作为唯一纠缠门类型的随机电路，并为包括陷阱离子和中性原子在内的架构量身定制。通过利用张量图表示法，我们严格分析了诱导的电路系综，并证明相位影与基于全克利福德的影具有相当的性能。最重要的是，该方法支持通过纯粹的经典后处理进行抗噪声扩展，从而能够在实际的、依赖于门噪声的情况下进行可靠估计，而现有技术往往会失败。此外，利用随机稳定器态的结构特性，我们设计了一种高效的后处理算法，解决了先前影协议中的一个关键计算瓶颈。我们的结果通过提供一种鲁棒且可扩展的途径来估计有噪声量子系统中的全局属性，从而提高了影技术的实用性。

Abstract: Measuring global quantum properties -- such as the fidelity to complex
multipartite states -- is both an essential and experimentally challenging
task. Classical shadow estimation offers favorable sample complexity, but
typically relies on many-qubit circuits that are difficult to realize on
current platforms. We propose the robust phase shadow scheme, a measurement
framework based on random circuits with controlled-Z as the unique entangling
gate type, tailored to architectures such as trapped ions and neutral atoms.
Leveraging tensor diagrammatic reasoning, we rigorously analyze the induced
circuit ensemble and show that phase shadows match the performance of full
Clifford-based ones. Importantly, our approach supports a noise-robust
extension via purely classical post-processing, enabling reliable estimation
under realistic, gate-dependent noise where existing techniques often fail.
Additionally, by exploiting structural properties of random stabilizer states,
we design an efficient post-processing algorithm that resolves a key
computational bottleneck in previous shadow protocols. Our results enhance the
practicality of shadow-based techniques, providing a robust and scalable route
for estimating global properties in noisy quantum systems.

</details>


### [305] [Resources for bosonic metrology: quantum-enhanced precision from a superselection rule perspective](https://arxiv.org/abs/2507.13245)
*Astghik Saharyan,Eloi Descamps,Arne Keller,Pérola Milman*

Main category: quant-ph

TL;DR: 本研究提出了一种统一的量子计量学框架，使用玻色子资源连接了量子光学和原子系统，并提供了一种新的优化策略，该策略可应用于现实的实验场景。


<details>
  <summary>Details</summary>
Motivation: 现有研究在量子光学和原子系统中分别处理量子增强的精确度参数估计问题，缺乏统一的理论框架来连接不同的研究领域（如连续变量和离散变量），并且优化探测器（量子态）和演化（依赖于参数的动力学）通常依赖于个例分析。

Method: 提出了一种符合超选择定则的电磁场表示方法，该方法显式地包含了相位参考并强制执行总粒子数守恒，从而实现了与原子系统中使用的描述形式上的等价。在此框架下，研究人员可以统一地处理量子光学中的离散和连续变量极限，并恢复已有的研究结果。

Result: 研究人员成功地恢复了已有的研究结果，并为负责提高精度的量子资源提供了连贯的物理解释。此外，研究人员还开发了利用任意多模纠缠探针态优化精度的通用策略。

Conclusion: 本框架为量子计量学提供了一个统一的视角，将所有已知的由 the 玻色子资源利用的提高精度的机制纳入其中，并为提高精度提供了新的优化策略，同时考虑了噪声、测量策略和非酉演化等现实因素。

Abstract: Quantum optics and atomic systems are prominent platforms for exploiting
quantum-enhanced precision in parameter estimation. However, not only are
quantum optical and atomic systems often treated separately, but even within
quantum optics, identifying optimal probes (quantum states) and evolutions
(parameter-dependent dynamics) typically relies on case-by-case analyses. Mode,
and sometimes only particle entanglement, can yield quantum enhancement of
precision in continuous- and discrete-variable regimes, yet a clear connection
between these regimes remains elusive. In this work, we present a unified
framework for quantum metrology that encompasses all known precision-enhancing
regimes using bosonic resources. We introduce a superselection rule compliant
representation of the electromagnetic field that explicitly incorporates the
phase reference, enforcing total particle number conservation. This approach
provides a description of the electromagnetic field which is formally
equivalent to the one employed in atomic systems, and we show how it
encompasses both the discrete and the continuous limits of quantum optics.
Within this framework, we consistently recover established results while
offering a coherent physical interpretation of the quantum resources
responsible for precision enhancement. Moreover, we develop general strategies
to optimize precision using arbitrary multimode entangled probe states.
Finally, our formalism readily accommodates noise, measurement strategies and
non-unitary evolutions, extending its applicability to realistic experimental
scenarios.

</details>


### [306] [State transfer analysis for linear spin chains with non-uniform on-site energies](https://arxiv.org/abs/2507.13261)
*Chad C. Nelmes,Irene D'Amico,Timothy P. Spiller*

Main category: quant-ph

TL;DR: 本研究提出了包含非均匀原地能量的线性自旋链的完美和准完美状态转移，并分析了其性能。


<details>
  <summary>Details</summary>
Motivation: 保持耦合均匀性，这可能有利于某些物理实现

Method: 通过类比离散势中的粒子来分析耦合均匀性，并考虑了耦合和原地能量的统计变化，以及链位点数N的增加

Result: 提出了包含非均匀原地能量的线性自旋链的完美和准完美状态转移

Conclusion: 本研究分析了包含非均匀原地能量的线性自旋链的完美和准完美状态转移

Abstract: High fidelity state transfer is an important ingredient of distributed
quantum information processing. We present and analyse results on perfect and
quasi-perfect state transfer with linear spin chains incorporating non-uniform
on-site energies. The motivation is maintenance of coupling uniformity, which
could be beneficial for some physical implementations. We relate this coupling
uniformity to a particle in a discrete potential analogue. Our analysis further
considers the statistical variation in couplings and on-site energies, as a
function of increasing chain site number N.

</details>


### [307] [Local nanoscale probing of electron spins using NV centers in diamond](https://arxiv.org/abs/2507.13295)
*Sergei Trofimov,Christos Thessalonikios,Victor Deinhart,Alexander Spyrantis,Lucas Tsunaki,Kseniia Volkova,Katja Höflich,Boris Naydenon*

Main category: quant-ph

TL;DR: 通过氦离子显微镜制造的 NV 中心探针，结合 DEER 技术，实现了对金刚石中氮和其他顺磁缺陷的纳米级高精度测量。


<details>
  <summary>Details</summary>
Motivation: 准确量化金刚石中的氮浓度对于优化基于金刚石的量子器件至关重要，因为取代性氮原子（P1 中心）会影响 NV 中心的性能，但传统的宏观表征方法忽略了局部浓度的变化。

Method: 使用氦离子显微镜在金刚石晶体预定位置制造纳米级 NV 中心系综，并利用 NV 中心探针结合双电子电子共振 (DEER) 技术和数值模拟来测量局部氮浓度和潜在的顺磁缺陷浓度。

Result: 成功实现了对低浓度氮（230 ppb）的金刚石晶体进行纳米级局部浓度测量，并确定了其他未知顺磁缺陷浓度（最高可达 15 ppb），具体取决于离子注入剂量。

Conclusion: 这项工作开发了一种利用氦离子显微镜制造的 NV 中心探针，通过 DEER 技术和数值模拟，在纳米尺度上精确测量金刚石中的氮浓度和其他未知顺磁缺陷浓度。

Abstract: Substitutional nitrogen atoms in a diamond crystal (P1 centers) are, on one
hand, a resource for creation of nitrogen-vacancy (NV) centers, that have been
widely employed as nanoscale quantum sensors. On the other hand, P1's electron
spin is a source of paramagnetic noise that degrades the NV's performance by
shortening its coherence time. Accurate quantification of nitrogen
concentration is therefore essential for optimizing diamond-based quantum
devices. However, bulk characterization methods based on optical absorption or
electron paramagnetic resonance often overlook local variations in nitrogen
content. In this work, we use a helium ion microscope to fabricate nanoscale NV
center ensembles at predefined sites in a diamond crystal containing low
concentrations of nitrogen. We then utilize these NV-based probes to measure
the local nitrogen concentration on the level of 230 ppb (atomic parts per
billion) using the double electron-electron resonance (DEER) technique.
Moreover, by comparing the DEER spectra with numerical simulations, we managed
to determine the concentration of other unknown paramagnetic defects created
during the ion implantation, reaching 15 ppb depending on the implantation
dose.

</details>


### [308] [Simple ways of preparing qudit Dicke states](https://arxiv.org/abs/2507.13308)
*Noah B. Kerzner,Federico Galeazzi,Rafael I. Nepomechie*

Main category: quant-ph

TL;DR: 研究了更高维度的 Dicke 状态，并提出了在量子计算机上制备它们的新方法。


<details>
  <summary>Details</summary>
Motivation: 研究 Dicke 状态的更高维度推广，并探索在量子计算机上制备它们的方法。

Method: 通过基于精确的规范矩阵表示和量子相位估计的确定性和概率性方法，在量子计算机上制备了 SU(2) 自旋-s 和 SU(d) 的更高维度 Dicke 状态。

Result: 成功制备了 SU(2) 自旋-s 和 SU(d) 的更高维度 Dicke 状态，并且所提出的量子电路比之前的方法更简单。

Conclusion: 略

Abstract: Dicke states are permutation-invariant superpositions of qubit computational
basis states, which play a prominent role in quantum information science. We
consider here two higher-dimensional generalizations of these states: $SU(2)$
spin-$s$ Dicke states and $SU(d)$ Dicke states. We present various ways of
preparing both types of qudit Dicke states on a qudit quantum computer, using
two main approaches: a deterministic approach, based on exact canonical matrix
product state representations; and a probabilistic approach, based on quantum
phase estimation. The quantum circuits are explicit and straightforward, and
are arguably simpler than those previously reported.

</details>


### [309] [Long-time storage of a decoherence-free subspace logical qubit in a dual-type quantum memory](https://arxiv.org/abs/2507.13320)
*Y. L. Xu,L. Zhang,C. Zhang,Y. K. Wu,Y. Y. Chen,C. X. Huang,Z. B. Cui,R. Yao,W. Q. Lian,J. Y. Ma,W. X. Guo,B. X. Qi,P. Y. Hou,Y. F. Pu,Z. C. Zhou,L. He,L. M. Duan*

Main category: quant-ph

TL;DR: 在低温下，我们开发了一种多离子量子存储器，相干时间超过2小时，并且具有良好的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 为了实现量子计算、量子网络和量子计量等应用，需要量子存储器。尽管先前的研究实现了长达一小时的单量子比特存储，但其在室温陷阱中的离子位置跳变限制了其应用。因此，有必要开发一种在多离子和更长相干时间方面具有更好性能的量子存储器。

Method: 在本研究中，我们采用了基于双类型方案的多离子量子存储器，并结合了低温陷阱技术。通过纠正主要的泄漏误差，我们实现了对量子比特的相干时间进行延长。

Result: 本研究成功实现了一个多离子量子存储器，其相干时间超过两个小时，该存储器基于双类型方案，并针对两个离子的纠缠态进行了优化，同时纠正了主要的泄漏误差。该方案不仅提高了相干时间，而且由于离子的质量相同，还具有良好的可扩展性。

Conclusion: 本研究在低温陷阱中基于双类型方案实现了多离子量子存储器，并将相干时间提高到两个小时以上，同时纠正了主要的泄漏误差。该方案简化了对存储量子比特的超稳频率参考的要求，并且由于所用离子的质量相同，具有更好的可扩展性。

Abstract: A quantum memory is an essential element for quantum computation, quantum
network and quantum metrology. Previously, a single-qubit quantum memory with a
coherence time of about an hour has been realized in a dual-species setup where
a coolant ion provides sympathetic cooling for a memory ion of different
species. However, the frequent random position hopping between the ions in the
room-temperature trap limits the technique there only applicable to
single-qubit storage. Here we report a multi-ion quantum memory in a cryogenic
trap based on the dual-type scheme, and demonstrate a coherence time above two
hours for a logical qubit encoded in the decoherence-free subspace, i.e.
two-ion entangled states, after correcting the dominant leakage error. Our
scheme alleviates the necessity of an ultra-stable frequency reference for the
stored qubit, and has a preferable scalability owing to the same mass of the
metastable-state memory ions and the ground-state coolant ion.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [310] [Improving physics-informed neural network extrapolation via transfer learning and adaptive activation functions](https://arxiv.org/abs/2507.12659)
*Athanasios Papastathopoulos-Katsaros,Alexandra Stavrianidi,Zhandong Liu*

Main category: cs.LG

TL;DR: 通过在扩展的训练域中使用迁移学习和自适应激活函数，可以提高物理信息神经网络（PINNs）的外推能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管物理信息神经网络（PINNs）在解决科学和工程问题方面取得了成功，但它们通常在外推能力方面表现不佳，并且对激活函数的选择非常敏感。

Method: 提出了一种迁移学习（TL）方法，将其应用于扩展的训练域，并结合少量精心选择的配置点。此外，还提出了一种自适应激活函数（AF），它是标准 AFs 的线性组合，以提高模型的鲁棒性和准确性。

Result: 实验证明，该方法在没有显著增加计算成本的情况下，在外推域中的相对 L2 误差平均降低了 40%，平均绝对误差平均降低了 50%。

Conclusion: 本文提出的迁移学习和自适应激活函数方法显著提高了物理信息神经网络的外推能力和鲁棒性，在不显著增加计算成本的情况下，将相对 L2 误差和平均绝对误差分别平均降低了 40% 和 50%。

Abstract: Physics-Informed Neural Networks (PINNs) are deep learning models that
incorporate the governing physical laws of a system into the learning process,
making them well-suited for solving complex scientific and engineering
problems. Recently, PINNs have gained widespread attention as a powerful
framework for combining physical principles with data-driven modeling to
improve prediction accuracy. Despite their successes, however, PINNs often
exhibit poor extrapolation performance outside the training domain and are
highly sensitive to the choice of activation functions (AFs). In this paper, we
introduce a transfer learning (TL) method to improve the extrapolation
capability of PINNs. Our approach applies transfer learning (TL) within an
extended training domain, using only a small number of carefully selected
collocation points. Additionally, we propose an adaptive AF that takes the form
of a linear combination of standard AFs, which improves both the robustness and
accuracy of the model. Through a series of experiments, we demonstrate that our
method achieves an average of 40% reduction in relative L2 error and an average
of 50% reduction in mean absolute error in the extrapolation domain, all
without a significant increase in computational cost. The code is available at
https://github.com/LiuzLab/PINN-extrapolation .

</details>


### [311] [Scaling Up RL: Unlocking Diverse Reasoning in LLMs via Prolonged Training](https://arxiv.org/abs/2507.12507)
*Mingjie Liu,Shizhe Diao,Jian Hu,Ximing Lu,Xin Dong,Hao Zhang,Alexander Bukharin,Shaokun Zhang,Jiaqi Zeng,Makesh Narsimhan Sreedhar,Gerald Shen,David Mosallanezhad,Di Zhang,Jonas Yang,June Yang,Oleksii Kuchaiev,Guilin Liu,Zhiding Yu,Pavlo Molchanov,Yejin Choi,Jan Kautz,Yi Dong*

Main category: cs.LG

TL;DR: 通过强化学习和特定优化技术，在数学、编码和逻辑谜题任务上显著提升了小型语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 探索延长强化学习对小型语言模型在不同推理领域的影响，并找出有效的训练方法，以期在复杂任务上取得类似大型模型（如OpenAI的O1和DeepSeek-R1）的性能提升。

Method: 通过对一个小型语言模型进行长时间的强化学习，并在数学、编码和逻辑谜题等多个推理领域进行测试，同时引入了可验证奖励任务、改进的GRPO算法、受控KL正则化、裁剪比率和周期性参考策略重置等关键技术来提高训练稳定性和泛化能力。

Result: 在数学任务上提升了14.7%，在编码任务上提升了13.9%，在逻辑谜题任务上提升了54.8%，显著优于现有基线模型。

Conclusion: 该模型通过持续的强化学习和关键技术（如可验证奖励、改进的GRPO、受控KL正则化、裁剪比率和周期性参考策略重置）在数学、编码和逻辑谜题任务上取得了显著的性能提升，超过了强大的基线模型。

Abstract: Recent advancements in reasoning-focused language models such as OpenAI's O1
and DeepSeek-R1 have shown that scaling test-time computation-through
chain-of-thought reasoning and iterative exploration-can yield substantial
improvements on complex tasks like mathematics and code generation. These
breakthroughs have been driven by large-scale reinforcement learning (RL),
particularly when combined with verifiable reward signals that provide
objective and grounded supervision. In this report, we investigate the effects
of prolonged reinforcement learning on a small language model across a diverse
set of reasoning domains. Our work identifies several key ingredients for
effective training, including the use of verifiable reward tasks, enhancements
to Group Relative Policy Optimization (GRPO), and practical techniques to
improve training stability and generalization. We introduce controlled KL
regularization, clipping ratio, and periodic reference policy resets as
critical components for unlocking long-term performance gains. Our model
achieves significant improvements over strong baselines, including +14.7% on
math, +13.9% on coding, and +54.8% on logic puzzle tasks. To facilitate
continued research, we release our model publicly.

</details>


### [312] [RONOM: Reduced-Order Neural Operator Modeling](https://arxiv.org/abs/2507.12814)
*Sven Dummer,Dongwei Ye,Christoph Brune*

Main category: cs.LG

TL;DR: RONOM结合ROM和神经算子，在求解偏微分方程方面表现优于现有神经算子，尤其在超分辨率和鲁棒性方面。


<details>
  <summary>Details</summary>
Motivation: 现有的降阶模型（ROM）虽然有严格的误差估计，但依赖于固定的离散化，灵活性受限；而神经算子虽然能适应不同分辨率，但缺乏对无限维算子和离散化算子之间误差的量化。

Method: 提出了一种名为RONOM（Reduced-Order Neural Operator Modeling）的框架，该框架结合了传统降阶模型（ROM）和算子学习（如神经算子）的思想。RONOM建立了类似于ROM的离散化误差界限，并分析了其离散化收敛性和鲁棒性。

Result: 通过两个数值算例，将RONOM与现有的神经算子进行比较。结果表明，RONOM在输入泛化性方面表现相当，在空间超分辨率和离散鲁棒性方面表现更优，并对时间超分辨率场景提供了新的见解。

Conclusion: RONOM框架结合了降阶模型（ROM）和算子学习的优点，在输入泛化性、空间超分辨率和离散鲁棒性方面表现优于现有的神经算子方法，并为时间超分辨率提供了新的见解。

Abstract: Time-dependent partial differential equations are ubiquitous in physics-based
modeling, but they remain computationally intensive in many-query scenarios,
such as real-time forecasting, optimal control, and uncertainty quantification.
Reduced-order modeling (ROM) addresses these challenges by constructing a
low-dimensional surrogate model but relies on a fixed discretization, which
limits flexibility across varying meshes during evaluation. Operator learning
approaches, such as neural operators, offer an alternative by parameterizing
mappings between infinite-dimensional function spaces, enabling adaptation to
data across different resolutions. Whereas ROM provides rigorous numerical
error estimates, neural operator learning largely focuses on discretization
convergence and invariance without quantifying the error between the
infinite-dimensional and the discretized operators. This work introduces the
reduced-order neural operator modeling (RONOM) framework, which bridges
concepts from ROM and operator learning. We establish a discretization error
bound analogous to those in ROM, and get insights into RONOM's discretization
convergence and discretization robustness. Moreover, two numerical examples are
presented that compare RONOM to existing neural operators for solving partial
differential equations. The results demonstrate that RONOM using standard
vector-to-vector neural networks achieves comparable performance in input
generalization and superior performance in both spatial super-resolution and
discretization robustness, while also offering novel insights into temporal
super-resolution scenarios.

</details>


### [313] [The Serial Scaling Hypothesis](https://arxiv.org/abs/2507.12549)
*Yuxi Liu,Konpat Preechakul,Kananart Kuwaranancharoen,Yutong Bai*

Main category: cs.LG

TL;DR: 机器学习在处理“本质串行”问题时，由于现有并行计算架构的局限性，需要同时发展串行计算能力。


<details>
  <summary>Details</summary>
Motivation: 机器学习的进步主要得益于大规模并行化，但忽略了一些根本上需要串行计算的问题，如数学推理、物理模拟和序列决策。

Method: 通过借鉴复杂性理论，形式化区分了可并行和不可并行（串行）的问题，并证明了当前以并行为中心架构在处理串行问题时的局限性。

Result: 当前的并行计算架构在处理“本质串行”问题时存在根本性的局限性，这揭示了在模型设计和硬件开发中考虑串行计算的重要性。

Conclusion: AI需要并行和串行计算能力的结合，特别是在解决复杂推理问题时，需要扩展串行计算能力。

Abstract: While machine learning has advanced through massive parallelization, we
identify a critical blind spot: some problems are fundamentally sequential.
These "inherently serial" problems-from mathematical reasoning to physical
simulations to sequential decision-making-require dependent computational steps
that cannot be parallelized. Drawing from complexity theory, we formalize this
distinction and demonstrate that current parallel-centric architectures face
fundamental limitations on such tasks. We argue that recognizing the serial
nature of computation holds profound implications on machine learning, model
design, hardware development. As AI tackles increasingly complex reasoning,
deliberately scaling serial computation-not just parallel computation-is
essential for continued progress.

</details>


### [314] [Can Mental Imagery Improve the Thinking Capabilities of AI Systems?](https://arxiv.org/abs/2507.12555)
*Slimane Larabi*

Main category: cs.LG

TL;DR: 通过整合心像，机器可以像人类一样自主思考。


<details>
  <summary>Details</summary>
Motivation: 现有模型虽然能与人类互动并提供满意答复，但缺乏自主行动和独立推理的能力。此外，即使已获取感官数据，输入数据通常仍需以显式查询的形式提供。AI代理在多领域知识整合方面存在困难，而这方面人类表现出色。因此，本研究旨在解决这些局限性。

Method: 本文提出了一种机器思维框架，该框架包含一个认知思维单元和三个辅助单元：输入数据单元、需求单元和心像单元。数据以自然语言句子或绘制的草图形式表示，用于信息传递和决策。框架通过验证测试进行了评估。

Result: 验证测试的结果表明，所提出的机器思维框架在整合心像和促进机器思维启动方面具有潜力，并为进一步研究和开发提供了基础。

Conclusion: 本文提出了一种将心像整合到机器思维框架中的方法，并探讨了其在启动思维过程中的潜在益处。通过整合认知思维单元、输入数据单元、需求单元和心像单元，并以自然语言句子或草图表示数据，该框架旨在增强机器的自主性和跨领域知识整合能力。

Abstract: Although existing models can interact with humans and provide satisfactory
responses, they lack the ability to act autonomously or engage in independent
reasoning. Furthermore, input data in these models is typically provided as
explicit queries, even when some sensory data is already acquired.
  In addition, AI agents, which are computational entities designed to perform
tasks and make decisions autonomously based on their programming, data inputs,
and learned knowledge, have shown significant progress. However, they struggle
with integrating knowledge across multiple domains, unlike humans.
  Mental imagery plays a fundamental role in the brain's thinking process,
which involves performing tasks based on internal multisensory data, planned
actions, needs, and reasoning capabilities. In this paper, we investigate how
to integrate mental imagery into a machine thinking framework and how this
could be beneficial in initiating the thinking process. Our proposed machine
thinking framework integrates a Cognitive thinking unit supported by three
auxiliary units: the Input Data Unit, the Needs Unit, and the Mental Imagery
Unit. Within this framework, data is represented as natural language sentences
or drawn sketches, serving both informative and decision-making purposes. We
conducted validation tests for this framework, and the results are presented
and discussed.

</details>


### [315] [Topology-Aware Activation Functions in Neural Networks](https://arxiv.org/abs/2507.12874)
*Pavel Snopov,Oleg R. Musin*

Main category: cs.LG

TL;DR: 提出新的激活函数SmoothSplit和ParametricSplit，它们可以帮助神经网络更好地处理数据拓扑，尤其是在低维设置中。


<details>
  <summary>Details</summary>
Motivation: 传统激活函数（如ReLU）的局限性，以及在训练中增强神经网络处理数据拓扑的能力的需要。

Method: 提出SmoothSplit和ParametricSplit激活函数，它们具有拓扑“切割”能力，能够有效地转换复杂的数据流形。

Result: ParametricSplit在低维设置中表现优于传统激活函数，在更高维度设置中也保持了有竞争力的性能。

Conclusion: 研究表明，参数化激活函数在低维设置中优于传统的激活函数，同时在高维设置中保持竞争性能。这突出了关注拓扑的激活函数在推进神经网络架构方面的潜力。

Abstract: This study explores novel activation functions that enhance the ability of
neural networks to manipulate data topology during training. Building on the
limitations of traditional activation functions like $\mathrm{ReLU}$, we
propose $\mathrm{SmoothSplit}$ and $\mathrm{ParametricSplit}$, which introduce
topology "cutting" capabilities. These functions enable networks to transform
complex data manifolds effectively, improving performance in scenarios with
low-dimensional layers. Through experiments on synthetic and real-world
datasets, we demonstrate that $\mathrm{ParametricSplit}$ outperforms
traditional activations in low-dimensional settings while maintaining
competitive performance in higher-dimensional ones. Our findings highlight the
potential of topology-aware activation functions in advancing neural network
architectures. The code is available via
https://github.com/Snopoff/Topology-Aware-Activations.

</details>


### [316] [BootSeer: Analyzing and Mitigating Initialization Bottlenecks in Large-Scale LLM Training](https://arxiv.org/abs/2507.12619)
*Rui Li,Xiaoyun Zhi,Jinxin Chi,Menghan Yu,Lixin Huang,Jia Zhu,Weilun Zhang,Xing Ma,Wenjia Liu,Zhicheng Zhu,Daowen Luo,Zuquan Song,Xin Yin,Chao Xiang,Shuguang Wang,Wencong Xiao,Gene Cooperman*

Main category: cs.LG

TL;DR: LLM训练启动慢，Bootseer来解决。


<details>
  <summary>Details</summary>
Motivation: 由于LLM在AI领域的广泛应用以及在多模态任务中的扩展，区分普通运行时性能和启动开销变得日益重要。特别是对于大型、工业级LLM，启动开销（训练作业开始执行前的延迟）已成为一个关键问题，尤其是在故障频繁和迭代更新调试周期较长的情况下，已导致生产环境中超过3.5%的GPU时间被浪费。

Method: 通过分析生产数据，对LLM训练启动开销的组成部分进行了量化，并研究了其与作业规模的关系。基于这些分析，设计了Bootseer系统级优化框架，并采用了热块记录预取、依赖快照和条带化HDFS-FUSE等技术来解决主要的启动瓶颈。

Result: Bootseer已在生产环境中部署并针对真实的LLM训练工作负载进行了评估，结果显示启动开销减少了50%。

Conclusion: 该研究首次深入分析了LLM训练的启动开销，并提出了Bootseer优化框架，通过容器镜像加载、依赖安装和模型检查点恢复等技术，将启动开销减少了50%。

Abstract: Large Language Models (LLMs) have become a cornerstone of modern AI, driving
breakthroughs in natural language processing and expanding into multimodal jobs
involving images, audio, and video. As with most computational software, it is
important to distinguish between ordinary runtime performance and startup
overhead. Prior research has focused on runtime performance: improving training
efficiency and stability. This work focuses instead on the increasingly
critical issue of startup overhead in training: the delay before training jobs
begin execution. Startup overhead is particularly important in large,
industrial-scale LLMs, where failures occur more frequently and multiple teams
operate in iterative update-debug cycles. In one of our training clusters, more
than 3.5% of GPU time is wasted due to startup overhead alone.
  In this work, we present the first in-depth characterization of LLM training
startup overhead based on real production data. We analyze the components of
startup cost, quantify its direct impact, and examine how it scales with job
size. These insights motivate the design of Bootseer, a system-level
optimization framework that addresses three primary startup bottlenecks: (a)
container image loading, (b) runtime dependency installation, and (c) model
checkpoint resumption. To mitigate these bottlenecks, Bootseer introduces three
techniques: (a) hot block record-and-prefetch, (b) dependency snapshotting, and
(c) striped HDFS-FUSE. Bootseer has been deployed in a production environment
and evaluated on real LLM training workloads, demonstrating a 50% reduction in
startup overhead.

</details>


### [317] [MC$^2$A: Enabling Algorithm-Hardware Co-Design for Efficient Markov Chain Monte Carlo Acceleration](https://arxiv.org/abs/2507.12935)
*Shirui Zhao,Jun Yin,Lingyun Yao,Martin Andraud,Wannes Meert,Marian Verhelst*

Main category: cs.LG

TL;DR: MC2A是一个MCMC加速框架，通过算法-硬件协同设计，利用三维线幅模型、可重构硬件和Gumbel采样器，实现了对CPU、GPU、TPU和现有加速器的显著加速，有望推动MCMC在各领域的应用。


<details>
  <summary>Details</summary>
Motivation: MCMC算法在机器学习中广泛应用，但其高昂的计算成本限制了其在大规模问题和实际应用中的可行性。现有加速方案在硬件灵活性或系统级效率方面存在不足。

Method: MC2A是一个算法-硬件协同设计框架，通过扩展处理器性能线幅模型到三维来分析MCMC工作负载多样性，以平衡计算、采样和内存参数；提出了一个参数化硬件加速器架构，包含ISA可编程树状处理单元流水线、可重构采样器和支持不规则访问的交叉开关互连；核心是Gumbel采样器。

Result: MC2A在端到端案例研究中实现了显著的加速比，并在各种代表性MCMC工作负载上进行了评估，证明了其通用硬件加速的可行性。

Conclusion: MC2A通过Gumbel采样器消除了指数和归一化操作，并在端到端案例研究中实现了相比CPU、GPU、TPU和现有MCMC加速器分别达到307.6倍、1.4倍、2.0倍和84.2倍的整体加速比。该框架证明了通用硬件加速在MCMC普及方面的可行性。

Abstract: An increasing number of applications are exploiting sampling-based algorithms
for planning, optimization, and inference. The Markov Chain Monte Carlo (MCMC)
algorithms form the computational backbone of this emerging branch of machine
learning. Unfortunately, the high computational cost limits their feasibility
for large-scale problems and real-world applications, and the existing MCMC
acceleration solutions are either limited in hardware flexibility or fail to
maintain efficiency at the system level across a variety of end-to-end
applications. This paper introduces \textbf{MC$^2$A}, an algorithm-hardware
co-design framework, enabling efficient and flexible optimization for MCMC
acceleration. Firstly, \textbf{MC$^2$A} analyzes the MCMC workload diversity
through an extension of the processor performance roofline model with a 3rd
dimension to derive the optimal balance between the compute, sampling and
memory parameters. Secondly, \textbf{MC$^2$A} proposes a parametrized hardware
accelerator architecture with flexible and efficient support of MCMC kernels
with a pipeline of ISA-programmable tree-structured processing units,
reconfigurable samplers and a crossbar interconnect to support irregular
access. Thirdly, the core of \textbf{MC$^2$A} is powered by a novel Gumbel
sampler that eliminates exponential and normalization operations. In the
end-to-end case study, \textbf{MC$^2$A} achieves an overall {$307.6\times$,
$1.4\times$, $2.0\times$, $84.2\times$} speedup compared to the CPU, GPU, TPU
and state-of-the-art MCMC accelerator. Evaluated on various representative MCMC
workloads, this work demonstrates and exploits the feasibility of general
hardware acceleration to popularize MCMC-based solutions in diverse application
domains.

</details>


### [318] [IncA-DES: An incremental and adaptive dynamic ensemble selection approach using online K-d tree neighborhood search for data streams with concept drift](https://arxiv.org/abs/2507.12573)
*Eduardo V. L. Barboza,Paulo R. Lisboa de Almeida,Alceu de Souza Britto Jr.,Robert Sabourin,Rafael M. O. Cruz*

Main category: cs.LG

TL;DR: 数据流中的概念漂移是一个挑战。我们提出了IncA-DES，一种用于处理概念漂移的集成方法。它使用一种新的训练策略来生成局部专家，并结合概念漂移检测器和基于重叠的分类过滤器。我们还提出了一个在线K-d树算法来加速处理。我们的方法在准确性和速度上都优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决数据流中的概念漂移问题，传统的基于邻域搜索的距离集成（DS）方法在处理持续到达的数据时可能变得非常耗时。因此，需要一种能够有效适应概念漂移并提高处理效率的方法。

Method: IncA-DES框架，结合了概念漂移检测器和基于重叠的分类过滤器。通过一种促进局部专家生成的训练策略来应对概念漂移，假设特征空间的不同区域会随着时间的推移而可用。为了提高处理速度，提出了一种在线K-d树算法，可以快速删除实例而不会导致不一致，并处理数据流中可能出现的不平衡问题。

Result: 实验结果表明，所提出的框架在平均准确性方面优于七种最先进的方法，并且在准确性方面处理时间最短。在线K-d树的结合提高了处理时间，而准确性损失可忽略不计。

Conclusion: 提出的IncA-DES框架在处理概念漂移方面表现出色，在不同标签可用性水平下，其平均准确性优于七种最先进的方法，并且在准确性方面处理时间最短。此外，与在线K-d树的结合在准确性损失可忽略不计的情况下提高了处理时间。

Abstract: Data streams pose challenges not usually encountered in batch-based ML. One
of them is concept drift, which is characterized by the change in data
distribution over time. Among many approaches explored in literature, the
fusion of classifiers has been showing good results and is getting growing
attention. DS methods, due to the ensemble being instance-based, seem to be an
efficient choice under drifting scenarios. However, some attention must be paid
to adapting such methods for concept drift. The training must be done in order
to create local experts, and the commonly used neighborhood-search DS may
become prohibitive with the continuous arrival of data. In this work, we
propose IncA-DES, which employs a training strategy that promotes the
generation of local experts with the assumption that different regions of the
feature space become available with time. Additionally, the fusion of a concept
drift detector supports the maintenance of information and adaptation to a new
concept. An overlap-based classification filter is also employed in order to
avoid using the DS method when there is a consensus in the neighborhood, a
strategy that we argue every DS method should employ, as it was shown to make
them more applicable and quicker. Moreover, aiming to reduce the processing
time of the kNN, we propose an Online K-d tree algorithm, which can quickly
remove instances without becoming inconsistent and deals with unbalancing
concerns that may occur in data streams. Experimental results showed that the
proposed framework got the best average accuracy compared to seven
state-of-the-art methods considering different levels of label availability and
presented the smaller processing time between the most accurate methods.
Additionally, the fusion with the Online K-d tree has improved processing time
with a negligible loss in accuracy. We have made our framework available in an
online repository.

</details>


### [319] [FedGA: A Fair Federated Learning Framework Based on the Gini Coefficient](https://arxiv.org/abs/2507.12983)
*ShanBin Liu*

Main category: cs.LG

TL;DR: FedGA 是一种公平感知联邦学习算法，通过使用基尼系数衡量和管理客户端间的性能差异，并动态调整聚合权重，以提高公平性，同时保持整体性能。


<details>
  <summary>Details</summary>
Motivation: 在水平联邦设置中，数据异质性常常导致客户端之间存在显著的性能差异，这引起了对模型公平行为的担忧。为了解决这个问题，我们提出了一种名为 FedGA 的算法。

Method: FedGA 提出了一种公平感知的联邦学习算法。首先，使用基尼系数来衡量客户端之间的性能差异。在此基础上，建立了基尼系数 $G$ 与全局模型更新尺度 ${U_s}$ 之间的关系，并利用该关系自适应地确定公平性干预的时机。随后，根据系统实时公平性状态动态调整聚合权重，使全局模型能够更好地融合来自性能相对较差的客户端的信息。

Result: 通过在 Office-Caltech-10、CIFAR-10 和 Synthetic 数据集上进行的大量实验表明，FedGA 能够有效提升公平性指标，如方差和基尼系数，同时保持强大的整体性能。

Conclusion: FedGA 能够有效提升公平性指标（如方差和基尼系数），同时保持强大的整体性能，证明了该方法的有效性。

Abstract: Fairness has emerged as one of the key challenges in federated learning. In
horizontal federated settings, data heterogeneity often leads to substantial
performance disparities across clients, raising concerns about equitable model
behavior. To address this issue, we propose FedGA, a fairness-aware federated
learning algorithm. We first employ the Gini coefficient to measure the
performance disparity among clients. Based on this, we establish a relationship
between the Gini coefficient $G$ and the update scale of the global model
${U_s}$, and use this relationship to adaptively determine the timing of
fairness intervention. Subsequently, we dynamically adjust the aggregation
weights according to the system's real-time fairness status, enabling the
global model to better incorporate information from clients with relatively
poor performance.We conduct extensive experiments on the Office-Caltech-10,
CIFAR-10, and Synthetic datasets. The results show that FedGA effectively
improves fairness metrics such as variance and the Gini coefficient, while
maintaining strong overall performance, demonstrating the effectiveness of our
approach.

</details>


### [320] [Assay2Mol: large language model-based drug design using BioAssay context](https://arxiv.org/abs/2507.12574)
*Yifan Deng,Spencer S. Ericksen,Anthony Gitter*

Main category: cs.LG

TL;DR: Assay2Mol, a language model workflow, extracts valuable information from unstructured text in biochemical screening assays to generate drug candidates, outperforming existing methods and producing more synthesizable molecules.


<details>
  <summary>Details</summary>
Motivation: Unstructured text in scientific databases, particularly in biochemistry, contains rich information for drug discovery that has been untapped due to its format. This project aims to leverage this information for early-stage drug discovery.

Method: Assay2Mol is a large language model-based workflow that retrieves existing assay records involving targets similar to the new target and generates candidate molecules using in-context learning with the retrieved assay screening data.

Result: Assay2Mol outperforms recent machine learning approaches that generate candidate molecules based on target protein structures.

Conclusion: Assay2Mol promotes more synthesizable molecule generation and outperforms recent machine learning approaches for generating candidate ligand molecules.

Abstract: Scientific databases aggregate vast amounts of quantitative data alongside
descriptive text. In biochemistry, molecule screening assays evaluate the
functional responses of candidate molecules against disease targets.
Unstructured text that describes the biological mechanisms through which these
targets operate, experimental screening protocols, and other attributes of
assays offer rich information for new drug discovery campaigns but has been
untapped because of that unstructured format. We present Assay2Mol, a large
language model-based workflow that can capitalize on the vast existing
biochemical screening assays for early-stage drug discovery. Assay2Mol
retrieves existing assay records involving targets similar to the new target
and generates candidate molecules using in-context learning with the retrieved
assay screening data. Assay2Mol outperforms recent machine learning approaches
that generate candidate ligand molecules for target protein structures, while
also promoting more synthesizable molecule generation.

</details>


### [321] [Ranking Vectors Clustering: Theory and Applications](https://arxiv.org/abs/2507.12583)
*Ali Fattahi,Ali Eshragh,Babak Aslani,Meysam Rabiee*

Main category: cs.LG

TL;DR: 本文研究了聚类排序向量的问题（KRC），提出了一种名为KRCA的近似算法和一种分支定界（BnB）算法，用于解决NP难问题，并在实验中证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 本文研究的是聚类排序向量的问题，其中每个向量都表示为有序的独特整数列表偏好。

Method: 文章建立了KRC的NP-hard性质，并给出了可行集的特征。对于单簇情况，文章推导出了最优质心的闭式解析解，并可以在线性时间内计算。文章还开发了一个有效的近似算法KRCA，用于解决KRC的计算挑战，该算法通过迭代优化KMC的初始解（称为基线解）来工作。此外，文章还引入了一个分支定界（BnB）算法，用于在KRCA中进行有效的簇重建，利用决策树框架来减少计算时间，并包含一个控制参数来平衡解的质量和效率。文章为KRCA和BnB建立了理论误差界限。

Result: 通过在合成和真实数据集上进行的大量数值实验，KRCA的性能优于基线解，在解的质量和计算时间方面均有显著改善。

Conclusion: 这项工作突出了KRC在个性化和大规模决策制定中的实际意义，为未来的研究提供了方法学上的进步和见解。

Abstract: We study the problem of clustering ranking vectors, where each vector
represents preferences as an ordered list of distinct integers. Specifically,
we focus on the k-centroids ranking vectors clustering problem (KRC), which
aims to partition a set of ranking vectors into k clusters and identify the
centroid of each cluster. Unlike classical k-means clustering (KMC), KRC
constrains both the observations and centroids to be ranking vectors. We
establish the NP-hardness of KRC and characterize its feasible set. For the
single-cluster case, we derive a closed-form analytical solution for the
optimal centroid, which can be computed in linear time. To address the
computational challenges of KRC, we develop an efficient approximation
algorithm, KRCA, which iteratively refines initial solutions from KMC, referred
to as the baseline solution. Additionally, we introduce a branch-and-bound
(BnB) algorithm for efficient cluster reconstruction within KRCA, leveraging a
decision tree framework to reduce computational time while incorporating a
controlling parameter to balance solution quality and efficiency. We establish
theoretical error bounds for KRCA and BnB. Through extensive numerical
experiments on synthetic and real-world datasets, we demonstrate that KRCA
consistently outperforms baseline solutions, delivering significant
improvements in solution quality with fast computational times. This work
highlights the practical significance of KRC for personalization and
large-scale decision making, offering methodological advancements and insights
that can be built upon in future studies.

</details>


### [322] [Second-Order Bounds for [0,1]-Valued Regression via Betting Loss](https://arxiv.org/abs/2507.12584)
*Yinan Li,Kwang-Sung Jun*

Main category: cs.LG

TL;DR: 研究提出了betting loss，一种在[0,1]值回归中实现二阶界限的损失函数，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索是否存在一种损失函数，可以在[0,1]值回归问题中实现比现有对数损失和平方损失更好（方差依赖）的界限。

Method: 提出了一种名为“betting loss”的新型损失函数，并证明了其在[0,1]值回归问题中可以实现方差自适应的二阶界。

Result: 证明了betting loss可以实现方差自适应的二阶界，这在先前未知的条件下优于一阶界。

Conclusion: 该研究提出了一种名为“betting loss”的新型损失函数，该函数在[0,1]值回归问题中实现了方差自适应的二阶界，优于仅具有一阶界限的对数损失和平方损失。

Abstract: We consider the $[0,1]$-valued regression problem in the i.i.d. setting. In a
related problem called cost-sensitive classification, \citet{foster21efficient}
have shown that the log loss minimizer achieves an improved generalization
bound compared to that of the squared loss minimizer in the sense that the
bound scales with the cost of the best classifier, which can be arbitrarily
small depending on the problem at hand. Such a result is often called a
first-order bound. For $[0,1]$-valued regression, we first show that the log
loss minimizer leads to a similar first-order bound. We then ask if there
exists a loss function that achieves a variance-dependent bound (also known as
a second order bound), which is a strict improvement upon first-order bounds.
We answer this question in the affirmative by proposing a novel loss function
called the betting loss. Our result is ``variance-adaptive'' in the sense that
the bound is attained \textit{without any knowledge about the variance}, which
is in contrast to modeling label (or reward) variance or the label distribution
itself explicitly as part of the function class such as distributional
reinforcement learning.

</details>


### [323] [Are encoders able to learn landmarkers for warm-starting of Hyperparameter Optimization?](https://arxiv.org/abs/2507.12604)
*Antoni Zajko,Katarzyna Woźnica*

Main category: cs.LG

TL;DR: 提出两种新的表格表示学习方法，用于特定元任务（HPO warm-starting），旨在使表示能够捕获landmarkers的属性。实验表明，虽然表示与landmarkers对齐，但对元任务的性能提升有限。


<details>
  <summary>Details</summary>
Motivation: 为元学习目的有效地表示异构表格数据集仍然是一个未解决的问题，特别是针对特定元任务（如贝叶斯超参数优化）的表示学习。

Method: 提出两种新的表格表示学习方法：基于深度度量学习的方法和基于landmarkers重建的方法。

Result: 实验表明，所提出的编码器可以有效地学习与landmarkers对齐的表示，但可能不会直接转化为HPO warm-starting元任务的显著性能提升。

Conclusion: 提出的方法在与landmarkers对齐的表示学习方面是有效的，但可能不会直接提高元任务（HPO warm-starting）的性能。

Abstract: Effectively representing heterogeneous tabular datasets for meta-learning
purposes is still an open problem. Previous approaches rely on representations
that are intended to be universal. This paper proposes two novel methods for
tabular representation learning tailored to a specific meta-task -
warm-starting Bayesian Hyperparameter Optimization. Both follow the specific
requirement formulated by ourselves that enforces representations to capture
the properties of landmarkers. The first approach involves deep metric
learning, while the second one is based on landmarkers reconstruction. We
evaluate the proposed encoders in two ways. Next to the gain in the target
meta-task, we also use the degree of fulfillment of the proposed requirement as
the evaluation metric. Experiments demonstrate that while the proposed encoders
can effectively learn representations aligned with landmarkers, they may not
directly translate to significant performance gains in the meta-task of HPO
warm-starting.

</details>


### [324] [Learning What Matters: Probabilistic Task Selection via Mutual Information for Model Finetuning](https://arxiv.org/abs/2507.12612)
*Prateek Chanda,Saral Sureka,Parth Pratim Chatterjee,Krishnateja Killamsetty,Nikhil Shivakumar Nayak,Ganesh Ramakrishnan*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The performance of finetuned large language models (LLMs) hinges critically
on the composition of the training mixture. However, selecting an optimal blend
of task datasets remains a largely manual, heuristic driven process, with
practitioners often relying on uniform or size based sampling strategies. We
introduce TASKPGM, a principled and scalable framework for mixture optimization
that selects continuous task proportions by minimizing an energy function over
a Markov Random Field (MRF). Task relationships are modeled using behavioral
divergences such as Jensen Shannon Divergence and Pointwise Mutual Information
computed from the predictive distributions of single task finetuned models. Our
method yields a closed form solution under simplex constraints and provably
balances representativeness and diversity among tasks. We provide theoretical
guarantees, including weak submodularity for budgeted variants, and demonstrate
consistent empirical improvements on Llama 2 and Mistral across evaluation
suites such as MMLU and BIGBench. Beyond performance, TASKPGM offers
interpretable insights into task influence and mixture composition, making it a
powerful tool for efficient and robust LLM finetuning.

</details>


### [325] [Reasoning-Finetuning Repurposes Latent Representations in Base Models](https://arxiv.org/abs/2507.12638)
*Jake Ward,Chuqiao Lin,Constantin Venhoff,Neel Nanda*

Main category: cs.LG

TL;DR: 研究发现，通过微调训练的推理模型（如 DeepSeek-R1-Distill-Llama-8B）中的回溯（backtracking）现象，并非模型从零学到的新能力，而是利用了其基础模型（如 Llama-3.1-8B）中已存在的特定方向（表征）。通过操纵这些已有的方向，可以诱导回溯行为，这表明微调过程主要是对现有能力的重新组织和利用。


<details>
  <summary>Details</summary>
Motivation: 理解推理微调模型中回溯行为的底层机制，特别是探究这种行为是模型从头学习还是利用了基础模型中已有的表征。

Method: 通过识别和利用基础模型（Llama-3.1-8B）残差流中的特定方向来引导蒸馏推理模型（DeepSeek-R1-Distill-Llama-8B），并分析该方向对模型回溯行为的影响。

Result: 确定了一个基础模型 Llama-3.1-8B 的残差流方向，该方向能够系统性地诱导蒸馏模型 DeepSeek-R1-Distill-Llama-8B 的回溯行为，并且该影响无法用 token 级别的属性简单解释。该方向在基础模型中不诱导回溯，表明推理微调过程重新利用了预存表征。同时，提出该方向是介导回溯的多个方向之一。

Conclusion: 研究表明，在 DeepSeek-R1-Distill-Llama-8B 模型中，回溯行为的出现部分是由基础模型激活中已有的、被重新利用的方向驱动的。该研究确定了一个在 Llama-3.1-8B 残差流中存在的方向，该方向在用于引导蒸馏推理模型时会系统地诱导回溯，并且这种引导的效果不能仅仅用 token 级别的属性来解释。此外，该方向在基础模型中并不会诱导回溯，这表明推理微调过程会重新利用预先存在的表征来形成新的行为回路。研究者推测，该方向是可能协同作用以介导回溯的多个方向之一。这些发现有力地说明了，经过推理微调的模型是重新利用基础模型中已有的表征，而不是从头开始学习新能力。

Abstract: Backtracking, an emergent behavior elicited by reasoning fine-tuning, has
been shown to be a key mechanism in reasoning models' enhanced capabilities.
Prior work has succeeded in manipulating this behavior via steering vectors,
but the underlying mechanism remains poorly understood. In this work, we show
that the emergence of backtracking in DeepSeek-R1-Distill-Llama-8B is in part
driven by a repurposed direction already present in base model activations.
Specifically, we identify a direction in base Llama-3.1-8B's residual stream
which systematically induces backtracking when used to steer the distilled
reasoning model, and find that the effects of steering with this direction
cannot be trivially explained by token-level attributes. We further find that
this direction does not induce backtracking in the base model, suggesting that
the reasoning finetuning process repurposes pre-existing representations to
form new behavioral circuits. Additionally, we hypothesize that this direction
is one of several which may work together to mediate backtracking. Our findings
offer a compelling picture that reasoning-finetuned models repurpose
pre-existing base model representations, rather than learn new capabilities
from scratch.

</details>


### [326] [Federated Learning in Open- and Closed-Loop EMG Decoding: A Privacy and Performance Perspective](https://arxiv.org/abs/2507.12652)
*Kai Malcolm,César Uribe,Momona Yamagami*

Main category: cs.LG

TL;DR: 本研究探索了联邦学习在神经解码中的应用，发现在开放场景下性能优越且注重隐私，但在闭环场景下，为适应实时交互而修改的联邦学习方法性能不如局部学习，但局部学习的隐私风险更高，凸显了性能与隐私之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 神经信号包含关于个人身份和健康的敏感信息，使得用于解码器训练的数据共享成为一个关键的隐私挑战。联邦学习作为一种分布式、注重隐私的学习框架，为解决这一挑战提供了有前景的解决方案，但其在闭环自适应神经接口中的应用尚未得到探索。

Method: 本研究介绍了基于联邦学习的神经解码方法，并使用高维肌电图信号在开放和闭环场景中系统地评估了其性能和隐私。在开放场景模拟中，联邦学习的性能优于局部学习基线。在闭环场景中，对联邦学习方法进行了修改以适应单用户实时交互，但修改后的联邦学习方法在闭环性能上仍落后于局部学习解码器，尽管局部学习带来了更高的隐私风险。

Result: 在开放场景模拟中，联邦学习显著优于局部学习基线，展示了其在高性能、注重隐私的神经解码方面的潜力。然而，在闭环用户研究中，为适应单用户实时交互而修改的联邦学习方法，其性能落后于局部学习解码器，但局部学习的隐私风险更高。

Conclusion: 本研究的发现强调了在实时自适应应用中性能与隐私之间的关键权衡，并指出了设计适用于共同适应、单一用户应用程序的联邦学习方法的必要性。

Abstract: Invasive and non-invasive neural interfaces hold promise as high-bandwidth
input devices for next-generation technologies. However, neural signals
inherently encode sensitive information about an individual's identity and
health, making data sharing for decoder training a critical privacy challenge.
Federated learning (FL), a distributed, privacy-preserving learning framework,
presents a promising solution, but it remains unexplored in closed-loop
adaptive neural interfaces. Here, we introduce FL-based neural decoding and
systematically evaluate its performance and privacy using high-dimensional
electromyography signals in both open- and closed-loop scenarios. In open-loop
simulations, FL significantly outperformed local learning baselines,
demonstrating its potential for high-performance, privacy-conscious neural
decoding. In contrast, closed-loop user studies required adapting FL methods to
accommodate single-user, real-time interactions, a scenario not supported by
standard FL. This modification resulted in local learning decoders surpassing
the adapted FL approach in closed-loop performance, yet local learning still
carried higher privacy risks. Our findings highlight a critical
performance-privacy tradeoff in real-time adaptive applications and indicate
the need for FL methods specifically designed for co-adaptive, single-user
applications.

</details>


### [327] [Data Transformation Strategies to Remove Heterogeneity](https://arxiv.org/abs/2507.12677)
*Sangbong Yoo,Jaeyoung Lee,Chanyoung Yoon,Geonyeong Son,Hyein Hong,Seongbum Seo,Soobin Yim,Chanyoung Jung,Jungsoo Park,Misuk Kim,Yun Jang*

Main category: cs.LG

TL;DR: 数据异构性是个常见问题，影响AI效率。本研究综述了数据转换策略，以应对数据格式差异带来的挑战，为AI的数据准备提供指导。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能应用的不断扩展，对简化数据准备过程和提高AI学习效率的需求日益增长，而数据转换在其中扮演着关键角色。然而，目前关于数据转换方法的全面综述相对匮乏。

Method: 本研究通过系统性地梳理和分类现有文献，对数据异构性及其来源进行深入探讨，并呈现解决数据格式差异的策略及其挑战。

Result: 本论文对数据异构性问题进行了详尽的分析，并对解决数据格式差异的各种策略进行了分类和阐述，为AI应用中的数据准备提供了参考。

Conclusion: 本篇论文旨在对数据异构性进行全面回顾，重点关注由数据格式差异引起的问题，并探讨解决这些问题的策略。

Abstract: Data heterogeneity is a prevalent issue, stemming from various conflicting
factors, making its utilization complex. This uncertainty, particularly
resulting from disparities in data formats, frequently necessitates the
involvement of experts to find resolutions. Current methodologies primarily
address conflicts related to data structures and schemas, often overlooking the
pivotal role played by data transformation. As the utilization of artificial
intelligence (AI) continues to expand, there is a growing demand for a more
streamlined data preparation process, and data transformation becomes
paramount. It customizes training data to enhance AI learning efficiency and
adapts input formats to suit diverse AI models. Selecting an appropriate
transformation technique is paramount in preserving crucial data details.
Despite the widespread integration of AI across various industries,
comprehensive reviews concerning contemporary data transformation approaches
are scarce. This survey explores the intricacies of data heterogeneity and its
underlying sources. It systematically categorizes and presents strategies to
address heterogeneity stemming from differences in data formats, shedding light
on the inherent challenges associated with each strategy.

</details>


### [328] [PinFM: Foundation Model for User Activity Sequences at a Billion-scale Visual Discovery Platform](https://arxiv.org/abs/2507.12704)
*Xiangyi Chen,Kousik Rajesh,Matthew Lawhon,Zelun Wang,Hanyu Li,Haomiao Li,Saurabh Vishwas Joshi,Pong Eksombatchai,Jaewon Yang,Yi-Ping Hsu,Jiajing Xu,Charles Rosenberg*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: User activity sequences have emerged as one of the most important signals in
recommender systems. We present a foundational model, PinFM, for understanding
user activity sequences across multiple applications at a billion-scale visual
discovery platform. We pretrain a transformer model with 20B+ parameters using
extensive user activity data, then fine-tune it for specific applications,
efficiently coupling it with existing models. While this
pretraining-and-fine-tuning approach has been popular in other domains, such as
Vision and NLP, its application in industrial recommender systems presents
numerous challenges. The foundational model must be scalable enough to score
millions of items every second while meeting tight cost and latency constraints
imposed by these systems. Additionally, it should capture the interactions
between user activities and other features and handle new items that were not
present during the pretraining stage.
  We developed innovative techniques to address these challenges. Our
infrastructure and algorithmic optimizations, such as the Deduplicated
Cross-Attention Transformer (DCAT), improved our throughput by 600% on
Pinterest internal data. We demonstrate that PinFM can learn interactions
between user sequences and candidate items by altering input sequences, leading
to a 20% increase in engagement with new items. PinFM is now deployed to help
improve the experience of more than a half billion users across various
applications.

</details>


### [329] [From SGD to Spectra: A Theory of Neural Network Weight Dynamics](https://arxiv.org/abs/2507.12709)
*Brian Richard Olsen,Sam Fatehmanesh,Frank Xiao,Adarsh Kumarappan,Anirudh Gajula*

Main category: cs.LG

TL;DR: 通过 SDE 框架揭示了深度学习训练动力学和谱结构之间的联系，为理解深度学习的有效性提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习的训练动力学在理论上尚不清楚，需要对其进行深入理解。

Method: 提出一个连续时间、矩阵值随机微分方程 (SDE) 框架，严格推导了 SGD 动力学与奇异值谱演化的联系，并刻画了平稳分布。

Result: 推导了精确的 SDE，表明奇异值平方遵循具有特征值排斥的 Dyson 几何，并将平稳分布确定为具有幂律尾部的伽玛类型密度，为经验上观察到的“块+尾”谱结构提供了第一个理论解释。在 Transformer 和 MLP 架构上进行的受控实验验证了理论预测，并证明了基于 SDE 的预测与观察到的谱演化之间存在定量一致性。

Conclusion: 深度学习为何有效：通过将随机梯度下降 (SGD) 的微观动力学与权重矩阵的奇异值谱的宏观演化联系起来，为理解深度学习提供了严格的理论基础。

Abstract: Deep neural networks have revolutionized machine learning, yet their training
dynamics remain theoretically unclear-we develop a continuous-time,
matrix-valued stochastic differential equation (SDE) framework that rigorously
connects the microscopic dynamics of SGD to the macroscopic evolution of
singular-value spectra in weight matrices. We derive exact SDEs showing that
squared singular values follow Dyson Brownian motion with eigenvalue repulsion,
and characterize stationary distributions as gamma-type densities with
power-law tails, providing the first theoretical explanation for the
empirically observed 'bulk+tail' spectral structure in trained networks.
Through controlled experiments on transformer and MLP architectures, we
validate our theoretical predictions and demonstrate quantitative agreement
between SDE-based forecasts and observed spectral evolution, providing a
rigorous foundation for understanding why deep learning works.

</details>


### [330] [Multimodal-Guided Dynamic Dataset Pruning for Robust and Efficient Data-Centric Learning](https://arxiv.org/abs/2507.12750)
*Suorong Yang,Peijia Li,Yujie Liu,Zhiming Xu,Peng Ye,Wanli Ouyang,Furao Shen,Dongzhan Zhou*

Main category: cs.LG

TL;DR: 本研究提出了一种动态数据集修剪框架，通过整合任务难度和跨模态语义一致性来选择训练样本，从而提高训练效率和模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据集修剪方法依赖于静态启发式或特定任务的指标，这限制了它们在不同领域中的鲁棒性和泛化能力。本研究旨在通过一种动态方法来改进这一点。

Method: 提出了一种动态数据集修剪框架，该框架结合了任务驱动的难度和跨模态语义一致性来选择训练样本。通过利用预训练的多模态基础模型，该方法能够捕获训练动态并有效地筛选掉信息量少的样本。

Result: 该框架能够有效筛选掉信息量少的样本，提高了训练效率和模型性能。

Conclusion: 该研究表明，将跨模态对齐整合到数据修剪中可以实现更高效、更稳健的训练。

Abstract: Modern deep models are trained on large real-world datasets, where data
quality varies and redundancy is common. Data-centric approaches such as
dataset pruning have shown promise in improving training efficiency and model
performance. However, most existing methods rely on static heuristics or
task-specific metrics, limiting their robustness and generalizability across
domains. In this work, we introduce a dynamic dataset pruning framework that
adaptively selects training samples based on both task-driven difficulty and
cross-modality semantic consistency. By incorporating supervision from
pretrained multimodal foundation models, our approach captures training
dynamics while effectively filtering out uninformative samples. Our work
highlights the potential of integrating cross-modality alignment for robust
sample selection, advancing data-centric learning toward more efficient and
robust practices across application domains.

</details>


### [331] [Leveraging Asynchronous Cross-border Market Data for Improved Day-Ahead Electricity Price Forecasting in European Markets](https://arxiv.org/abs/2507.13250)
*Maria Margarida Mascarenhas,Jilles De Blauwe,Mikael Amelin,Hussain Kazmi*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Accurate short-term electricity price forecasting is crucial for
strategically scheduling demand and generation bids in day-ahead markets. While
data-driven techniques have shown considerable prowess in achieving high
forecast accuracy in recent years, they rely heavily on the quality of input
covariates. In this paper, we investigate whether asynchronously published
prices as a result of differing gate closure times (GCTs) in some bidding zones
can improve forecasting accuracy in other markets with later GCTs. Using a
state-of-the-art ensemble of models, we show significant improvements of 22%
and 9% in forecast accuracy in the Belgian (BE) and Swedish bidding zones (SE3)
respectively, when including price data from interconnected markets with
earlier GCT (Germany-Luxembourg, Austria, and Switzerland). This improvement
holds for both general as well as extreme market conditions. Our analysis also
yields further important insights: frequent model recalibration is necessary
for maximum accuracy but comes at substantial additional computational costs,
and using data from more markets does not always lead to better performance - a
fact we delve deeper into with interpretability analysis of the forecast
models. Overall, these findings provide valuable guidance for market
participants and decision-makers aiming to optimize bidding strategies within
increasingly interconnected and volatile European energy markets.

</details>


### [332] [Layer Separation Deep Learning Model with Auxiliary Variables for Partial Differential Equations](https://arxiv.org/abs/2507.12766)
*Yaru Liu,Yiqi Gu*

Main category: cs.LG

TL;DR: LySep模型通过将深度网络分解为浅层结构来优化深度学习在求解偏微分方程中的表现，有效解决了优化难题并提升了性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习在求解偏微分方程时，由于损失函数高度非凸，现有优化算法常收敛到局部最小值或出现梯度爆炸/消失，导致性能不佳。为解决这些问题，提出LySep模型。

Method: LySep模型通过引入辅助变量将深度神经网络的层进行分离，将深度结构分解为一系列浅层结构。建立了包含辅助变量的新损失函数，其中只有相邻两层的变量耦合。开发了基于交替方向的算法，许多变量可以最优地以闭式形式更新。

Result: 高维数值结果验证了LySep模型的理论，并展示了其在最小化损失和减少求解误差方面的优势。

Conclusion: LySep模型通过引入辅助变量将深度神经网络分解为一系列浅层结构，解决了非凸损失函数导致的收敛到局部最小值、梯度爆炸或消失等问题，提高了深度学习在求解偏微分方程方面的性能。理论分析证明了LySep模型与原始深度模型的_一致性，高维数值结果验证了该理论并展示了LySep在最小化损失和减少求解误差方面的优势。

Abstract: In this paper, we propose a new optimization framework, the layer separation
(LySep) model, to improve the deep learning-based methods in solving partial
differential equations. Due to the highly non-convex nature of the loss
function in deep learning, existing optimization algorithms often converge to
suboptimal local minima or suffer from gradient explosion or vanishing,
resulting in poor performance. To address these issues, we introduce auxiliary
variables to separate the layers of deep neural networks. Specifically, the
output and its derivatives of each layer are represented by auxiliary
variables, effectively decomposing the deep architecture into a series of
shallow architectures. New loss functions with auxiliary variables are
established, in which only variables from two neighboring layers are coupled.
Corresponding algorithms based on alternating directions are developed, where
many variables can be updated optimally in closed forms. Moreover, we provide
theoretical analyses demonstrating the consistency between the LySep model and
the original deep model. High-dimensional numerical results validate our theory
and demonstrate the advantages of LySep in minimizing loss and reducing
solution error.

</details>


### [333] [A Comprehensive Survey of Electronic Health Record Modeling: From Deep Learning Approaches to Large Language Models](https://arxiv.org/abs/2507.12774)
*Weijieying Ren,Jingxi Zhu,Zehao Liu,Tianxiang Zhao,Vasant Honavar*

Main category: cs.LG

TL;DR: 本调查全面概述了深度学习、大语言模型（LLM）和电子健康记录（EHR）建模交叉领域的最新进展，重点介绍了数据处理、模型架构、学习策略、多模态学习和LLM应用，并讨论了未来的挑战和机遇。


<details>
  <summary>Details</summary>
Motivation: 人工智能（AI）在通过电子健康记录（EHR）的分析和建模彻底改变医疗保健方面显示出巨大潜力。然而，电子健康记录数据的固有异质性、时间不规则性和领域特定性带来了独特的挑战，这与视觉和自然语言任务中的挑战有着根本的不同。

Method: 本调查提供了一个统一的分类法，涵盖了五个关键的设计维度：以数据为中心的方法、神经架构设计、以学习为中心的方法、多模态学习和基于大语言模型的建模系统。在每个维度中，我们回顾了解决数据质量增强、结构和时间表示、自监督学习以及与临床知识集成等问题的代表性方法。

Result: 我们进一步强调了基础模型、由大语言模型驱动的临床代理以及用于下游推理的电子健康记录到文本翻译等新兴趋势。最后，我们讨论了在基准测试、可解释性、临床一致性和跨不同临床环境的泛化方面的开放性挑战。

Conclusion: 本调查旨在为推动人工智能驱动的电子健康记录建模和临床决策支持提供一个结构化的路线图。

Abstract: Artificial intelligence (AI) has demonstrated significant potential in
transforming healthcare through the analysis and modeling of electronic health
records (EHRs). However, the inherent heterogeneity, temporal irregularity, and
domain-specific nature of EHR data present unique challenges that differ
fundamentally from those in vision and natural language tasks. This survey
offers a comprehensive overview of recent advancements at the intersection of
deep learning, large language models (LLMs), and EHR modeling. We introduce a
unified taxonomy that spans five key design dimensions: data-centric
approaches, neural architecture design, learning-focused strategies, multimodal
learning, and LLM-based modeling systems. Within each dimension, we review
representative methods addressing data quality enhancement, structural and
temporal representation, self-supervised learning, and integration with
clinical knowledge. We further highlight emerging trends such as foundation
models, LLM-driven clinical agents, and EHR-to-text translation for downstream
reasoning. Finally, we discuss open challenges in benchmarking, explainability,
clinical alignment, and generalization across diverse clinical settings. This
survey aims to provide a structured roadmap for advancing AI-driven EHR
modeling and clinical decision support. For a comprehensive list of EHR-related
methods, kindly refer to https://survey-on-tabular-data.github.io/.

</details>


### [334] [Multi-Channel Graph Neural Network for Financial Risk Prediction of NEEQ Enterprises](https://arxiv.org/abs/2507.12787)
*Jianyu Zhu*

Main category: cs.LG

TL;DR: 提出了一种创新的多通道深度学习框架，通过整合财务指标、文本披露和企业关系数据，能够更准确地预测“新三板”上市公司的财务风险，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 中国的多层次资本市场不断发展，“新三板”已成为中小企业的重要融资平台。然而，许多“新三板”上市公司的财务实力有限，面临较高的财务困境风险。

Method: 提出了一种多通道深度学习框架，该框架整合了结构化财务指标、文本披露和企业关系数据，用于全面的财务风险预测。具体来说，设计了一种三通道图同构网络（GIN），分别处理数值、文本和基于图的输入。使用基于注意力的机制和门控单元融合这些特定模态的表示，以增强鲁棒性和预测准确性。

Result: 在对7731家真实“新三板”公司的数据进行的实验结果表明，在AUC、精确率、召回率和F1分数方面，该模型显著优于传统的机器学习方法和单模态基线。

Conclusion: 该研究为中小企业风险建模提供了理论和实践见解，并为金融监管机构和投资者提供了一个数据驱动的工具。

Abstract: With the continuous evolution of China's multi-level capital market, the
National Equities Exchange and Quotations (NEEQ), also known as the "New Third
Board," has become a critical financing platform for small and medium-sized
enterprises (SMEs). However, due to their limited scale and financial
resilience, many NEEQ-listed companies face elevated risks of financial
distress. To address this issue, we propose a multi-channel deep learning
framework that integrates structured financial indicators, textual disclosures,
and enterprise relationship data for comprehensive financial risk prediction.
Specifically, we design a Triple-Channel Graph Isomorphism Network (GIN) that
processes numeric, textual, and graph-based inputs separately. These
modality-specific representations are fused using an attention-based mechanism
followed by a gating unit to enhance robustness and prediction accuracy.
Experimental results on data from 7,731 real-world NEEQ companies demonstrate
that our model significantly outperforms traditional machine learning methods
and single-modality baselines in terms of AUC, Precision, Recall, and F1 Score.
This work provides theoretical and practical insights into risk modeling for
SMEs and offers a data-driven tool to support financial regulators and
investors.

</details>


### [335] [FLDmamba: Integrating Fourier and Laplace Transform Decomposition with Mamba for Enhanced Time Series Prediction](https://arxiv.org/abs/2507.12803)
*Qianru Zhang,Chenglei Yu,Haixin Wang,Yudong Yan,Yuansheng Cao,Siu-Ming Yiu,Tailin Wu,Hongzhi Yin*

Main category: cs.LG

TL;DR: FLDmamba通过结合傅里叶变换和拉普拉斯变换，解决了现有模型在长序列预测中的效率和捕捉多尺度周期性/瞬态动力学方面的不足，并提高了对噪声的鲁棒性，在时间序列预测任务上表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的模型因二次复杂度难以处理长序列预测，而Mamba等状态空间模型在捕捉多尺度周期性和瞬态动力学方面存在不足，并且易受数据噪声影响。本研究旨在解决这些局限性。

Method: FLDmamba框架结合了傅里叶变换和拉普拉斯变换的优点，以有效捕捉时间序列中的多尺度周期性和瞬态动力学，并提高模型对数据噪声的鲁棒性。

Result: 通过广泛的实验证明，FLDmamba在时间序列预测任务上取得了优越的性能，超越了基于Transformer和其他Mamba类的方法。

Conclusion: FLDmamba在时间序列预测任务上取得了优于Transformer和Mamba类方法的性能，在时间序列预测基准测试中表现卓越。

Abstract: Time series prediction, a crucial task across various domains, faces
significant challenges due to the inherent complexities of time series data,
including non-stationarity, multi-scale periodicity, and transient dynamics,
particularly when tackling long-term predictions. While Transformer-based
architectures have shown promise, their quadratic complexity with sequence
length hinders their efficiency for long-term predictions. Recent advancements
in State-Space Models, such as Mamba, offer a more efficient alternative for
long-term modeling, but they cannot capture multi-scale periodicity and
transient dynamics effectively. Meanwhile, they are susceptible to data noise
issues in time series. This paper proposes a novel framework, FLDmamba (Fourier
and Laplace Transform Decomposition Mamba), addressing these limitations.
FLDmamba leverages the strengths of both Fourier and Laplace transforms to
effectively capture both multi-scale periodicity, transient dynamics within
time series data, and improve the robustness of the model to the data noise
issue. Our extensive experiments demonstrate that FLDmamba achieves superior
performance on time series prediction benchmarks, outperforming both
Transformer-based and other Mamba-based architectures. To promote the
reproducibility of our method, we have made both the code and data accessible
via the following
URL:{\href{https://github.com/AI4Science-WestlakeU/FLDmamba}{https://github.com/AI4Science-WestlakeU/\model}.

</details>


### [336] [PMKLC: Parallel Multi-Knowledge Learning-based Lossless Compression for Large-Scale Genomics Database](https://arxiv.org/abs/2507.12805)
*Hui Sun,Yanfeng Ding,Liping Yi,Huidong Ma,Gang Wang,Xiaoguang Liu,Cheng Zhong,Wentong Cai*

Main category: cs.LG

TL;DR: PMKLC是一种新的基于学习的无损压缩器，通过多知识学习、GPU加速和并行处理，显著提高了压缩率和吞吐量，并增强了鲁棒性，适用于不同GPU资源环境。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有基于学习的无损压缩器在压缩率、压缩/解压缩吞吐量以及压缩鲁棒性方面的不足，以推动其在工业界和学术界的广泛应用。

Method: 提出了一种新颖的并行多知识学习压缩器（PMKLC），包含自动化多知识学习框架、GPU加速的(s,k)-mer编码器、数据块分区和分步模型传递（SMP）机制，并设计了PMKLC-S（单GPU）和PMKLC-M（多GPU）两种模式。

Result: PMKLC-S/M相比基线在测试数据集上实现了平均高达73.609%和73.480%的压缩率提升，平均吞吐量提升高达3.036倍和10.710倍，同时在鲁棒性和内存成本方面也表现出最佳和有竞争力的结果。

Conclusion: PMKLC-S/M在压缩率、吞吐量、鲁棒性和内存成本方面均优于现有基线，证明了其在资源受限的单GPU和多GPU加速场景下的稳定性和高效性。

Abstract: Learning-based lossless compressors play a crucial role in large-scale
genomic database backup, storage, transmission, and management. However, their
1) inadequate compression ratio, 2) low compression \& decompression
throughput, and 3) poor compression robustness limit their widespread adoption
and application in both industry and academia. To solve those challenges, we
propose a novel \underline{P}arallel \underline{M}ulti-\underline{K}nowledge
\underline{L}earning-based \underline{C}ompressor (PMKLC) with four crucial
designs: 1) We propose an automated multi-knowledge learning-based compression
framework as compressors' backbone to enhance compression ratio and robustness;
2) we design a GPU-accelerated ($s$,$k$)-mer encoder to optimize compression
throughput and computing resource usage; 3) we introduce data block
partitioning and Step-wise Model Passing (SMP) mechanisms for parallel
acceleration; 4) We design two compression modes PMKLC-S and PMKLC-M to meet
the complex application scenarios, where the former runs on a
resource-constrained single GPU and the latter is multi-GPU accelerated. We
benchmark PMKLC-S/M and 14 baselines (7 traditional and 7 leaning-based) on 15
real-world datasets with different species and data sizes. Compared to
baselines on the testing datasets, PMKLC-S/M achieve the average compression
ratio improvement up to 73.609\% and 73.480\%, the average throughput
improvement up to 3.036$\times$ and 10.710$\times$, respectively. Besides,
PMKLC-S/M also achieve the best robustness and competitive memory cost,
indicating its greater stability against datasets with different probability
distribution perturbations, and its strong ability to run on memory-constrained
devices.

</details>


### [337] [From Novelty to Imitation: Self-Distilled Rewards for Offline Reinforcement Learning](https://arxiv.org/abs/2507.12815)
*Gaurav Chaudhary,Laxmidhar Behera*

Main category: cs.LG

TL;DR: ReLOAD：一种无需显式奖励标注的离线强化学习框架，利用随机网络蒸馏生成内在奖励，并在 D4RL 基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习（RL）通常需要显式的奖励标注，这在实际应用中可能成本高昂或难以获取。为了解决这个问题，我们提出了 ReLOAD。

Method: ReLOAD（Reinforcement Learning with Offline Reward Annotation via Distillation）框架，该框架利用随机网络蒸馏（RND）通过嵌入差异度量从专家演示中生成内在奖励。具体来说，首先训练一个预测网络来模仿固定目标网络的嵌入，然后将这两个网络的预测误差作为静态数据集中每个转换的奖励信号。

Result: 实验结果表明，ReLOAD 能够在 D4RL 基准测试中实现鲁棒的离线策略学习，并且性能与传统的奖励标注方法具有竞争力。

Conclusion: ReLOAD 框架成功地实现了无需显式奖励标注的离线强化学习，并且在 D4RL 基准测试中取得了与传统奖励标注方法相媲美的性能。

Abstract: Offline Reinforcement Learning (RL) aims to learn effective policies from a
static dataset without requiring further agent-environment interactions.
However, its practical adoption is often hindered by the need for explicit
reward annotations, which can be costly to engineer or difficult to obtain
retrospectively. To address this, we propose ReLOAD (Reinforcement Learning
with Offline Reward Annotation via Distillation), a novel reward annotation
framework for offline RL. Unlike existing methods that depend on complex
alignment procedures, our approach adapts Random Network Distillation (RND) to
generate intrinsic rewards from expert demonstrations using a simple yet
effective embedding discrepancy measure. First, we train a predictor network to
mimic a fixed target network's embeddings based on expert state transitions.
Later, the prediction error between these networks serves as a reward signal
for each transition in the static dataset. This mechanism provides a structured
reward signal without requiring handcrafted reward annotations. We provide a
formal theoretical construct that offers insights into how RND prediction
errors effectively serve as intrinsic rewards by distinguishing expert-like
transitions. Experiments on the D4RL benchmark demonstrate that ReLOAD enables
robust offline policy learning and achieves performance competitive with
traditional reward-annotated methods.

</details>


### [338] [Understanding the Evolution of the Neural Tangent Kernel at the Edge of Stability](https://arxiv.org/abs/2507.12837)
*Kaiqi Jiang,Jeremy Cohen,Yuanzhi Li*

Main category: cs.LG

TL;DR: 本研究深入探讨了在达到稳定边缘（EoS）时，神经网络切线核（NTK）特征向量的行为，并发现更大的学习率能增强特征向量与训练目标的对齐性，从而为理解深度学习训练动力学提供了新的见解。


<details>
  <summary>Details</summary>
Motivation: 尽管近期研究深入探讨了NTK特征值在EoS下的行为，但对其特征向量行为的理解仍然缺失，本研究旨在填补这一空白。

Method: 本研究通过跨不同架构的实验观察，并对一个两层线性网络进行了理论分析，来研究NTK特征向量在EoS下的行为。

Result: 研究发现，更大的学习率会导致最终NTK和完整NTK矩阵的前导特征向量与训练目标有更大的对齐性。

Conclusion: 本研究通过分析神经网络切线核（NTK）的特征向量在梯度下降（GD）达到稳定边缘（EoS）时的动态行为，加深了对深度学习中GD训练动力学的理解。

Abstract: The study of Neural Tangent Kernels (NTKs) in deep learning has drawn
increasing attention in recent years. NTKs typically actively change during
training and are related to feature learning. In parallel, recent work on
Gradient Descent (GD) has found a phenomenon called Edge of Stability (EoS), in
which the largest eigenvalue of the NTK oscillates around a value inversely
proportional to the step size. However, although follow-up works have explored
the underlying mechanism of such eigenvalue behavior in depth, the
understanding of the behavior of the NTK eigenvectors during EoS is still
missing. This paper examines the dynamics of NTK eigenvectors during EoS in
detail. Across different architectures, we observe that larger learning rates
cause the leading eigenvectors of the final NTK, as well as the full NTK
matrix, to have greater alignment with the training target. We then study the
underlying mechanism of this phenomenon and provide a theoretical analysis for
a two-layer linear network. Our study enhances the understanding of GD training
dynamics in deep learning.

</details>


### [339] [A Kernel Distribution Closeness Testing](https://arxiv.org/abs/2507.12843)
*Zhijian Zhou,Liuhua Peng,Xunye Tian,Feng Liu*

Main category: cs.LG

TL;DR: 提出了一种名为 NAMMD 的新方法，用于改进分布趋近性测试 (DCT)，解决了 MMD 在处理复杂数据和区分不同分布对接近程度方面的局限性。该方法在理论和实验中均优于 MMD。


<details>
  <summary>Details</summary>
Motivation: 现有的 DCT 方法主要局限于离散一维空间，无法应用于图像等复杂数据。MMD 虽然可以处理复杂分布，但在评估多个分布对的接近程度时信息量不足。

Method: 提出了一种新的分布差异度量方法——范数自适应 MMD (NAMMD)，该方法通过对 RKHS 范数进行缩放来计算 MMD 值。基于 NAMMD 的渐近分布，提出了一种基于 NAMMD 的 DCT 方法。

Result: NAMMD-based DCT 和基于 NAMMD 的双样本检验在理论和实验上都显示出比 MMD 更高的检验效力。

Conclusion: NAMMD-based DCT 具有比 MMD-based DCT 更高的检验效力，且具有界限的 I 类错误。

Abstract: The distribution closeness testing (DCT) assesses whether the distance
between a distribution pair is at least $\epsilon$-far. Existing DCT methods
mainly measure discrepancies between a distribution pair defined on discrete
one-dimensional spaces (e.g., using total variation), which limits their
applications to complex data (e.g., images). To extend DCT to more types of
data, a natural idea is to introduce maximum mean discrepancy (MMD), a powerful
measurement of the distributional discrepancy between two complex
distributions, into DCT scenarios. However, we find that MMD's value can be the
same for many pairs of distributions that have different norms in the same
reproducing kernel Hilbert space (RKHS), making MMD less informative when
assessing the closeness levels for multiple distribution pairs. To mitigate the
issue, we design a new measurement of distributional discrepancy, norm-adaptive
MMD (NAMMD), which scales MMD's value using the RKHS norms of distributions.
Based on the asymptotic distribution of NAMMD, we finally propose the
NAMMD-based DCT to assess the closeness levels of a distribution pair.
Theoretically, we prove that NAMMD-based DCT has higher test power compared to
MMD-based DCT, with bounded type-I error, which is also validated by extensive
experiments on many types of data (e.g., synthetic noise, real images).
Furthermore, we also apply the proposed NAMMD for addressing the two-sample
testing problem and find NAMMD-based two-sample test has higher test power than
the MMD-based two-sample test in both theory and experiments.

</details>


### [340] [Transformer-Based Person Identification via Wi-Fi CSI Amplitude and Phase Perturbations](https://arxiv.org/abs/2507.12854)
*Danilo Avola,Andrea Bernardini,Francesco Danese,Mario Lezoche,Maurizio Mancini,Daniele Pannone,Amedeo Ranaldi*

Main category: cs.LG

TL;DR: 通过分析Wi-Fi信号的CSI（信道状态信息），即使在用户静止不动时，也能高精度地识别个体身份。


<details>
  <summary>Details</summary>
Motivation: 在现有Wi-Fi感知技术多依赖用户运动模式进行识别的背景下，探索在用户静止状态下进行个体识别的方法，以实现非侵入式和保护隐私的身份识别。

Method: 提出了一种基于Transformer的独特双分支架构，分别处理CSI的幅度和相位信息，以提取和识别个体的生物特征。

Result: 在包含六名参与者、多方位数据的ESP32数据集上，该模型达到了99.82%的分类准确率，优于传统的卷积神经网络和多层感知器基线模型。

Conclusion: Wi-Fi感知的用户识别技术，特别是针对静止状态下的个体识别，具有巨大的潜力。本研究提出的基于Transformer的方法，利用CSI的幅度和相位信息，在静止状态下实现了99.82%的识别准确率，证明了该技术在低成本、无设备干扰的现实场景中的可行性。

Abstract: Wi-Fi sensing is gaining momentum as a non-intrusive and privacy-preserving
alternative to vision-based systems for human identification. However, person
identification through wireless signals, particularly without user motion,
remains largely unexplored. Most prior wireless-based approaches rely on
movement patterns, such as walking gait, to extract biometric cues. In
contrast, we propose a transformer-based method that identifies individuals
from Channel State Information (CSI) recorded while the subject remains
stationary. CSI captures fine-grained amplitude and phase distortions induced
by the unique interaction between the human body and the radio signal. To
support evaluation, we introduce a dataset acquired with ESP32 devices in a
controlled indoor environment, featuring six participants observed across
multiple orientations. A tailored preprocessing pipeline, including outlier
removal, smoothing, and phase calibration, enhances signal quality. Our
dual-branch transformer architecture processes amplitude and phase modalities
separately and achieves 99.82\% classification accuracy, outperforming
convolutional and multilayer perceptron baselines. These results demonstrate
the discriminative potential of CSI perturbations, highlighting their capacity
to encode biometric traits in a consistent manner. They further confirm the
viability of passive, device-free person identification using low-cost
commodity Wi-Fi hardware in real-world settings.

</details>


### [341] [Supervised Fine Tuning on Curated Data is Reinforcement Learning (and can be improved)](https://arxiv.org/abs/2507.12856)
*Chongli Qin,Jost Tobias Springenberg*

Main category: cs.LG

TL;DR: SFT 可被视为 RL 目标稀疏奖励设置下的下界最大化。本文提出了一种名为 iw-SFT 的 SFT 变体，该变体优化了 RL 目标的更紧密界限，并在 LLM 和控制任务上取得了与 RL 相当的性能。


<details>
  <summary>Details</summary>
Motivation: 从 RL 理论和实践的角度，将 BC 和 SFT 与 RL 联系起来，以理解 SFT 的性能并提出改进方法。

Method: 将 SFT 视为 RL 目标稀疏奖励设置下的下界最大化，并提出了一种改进的 SFT 变体，称为 iw-SFT，它优化了 RL 目标的更紧密界限。

Result: iw-SFT 相比 SFT 改进了性能，并且在 LLM 和连续控制任务上与 RL 算法相当，例如在 AIME 2024 数据集上达到了 66.7%。

Conclusion: SFT 的新变体 iw-SFT 优化了 RL 目标更紧密的界限，并在 LLM 和连续控制任务上取得了与 RL 算法相当的性能。

Abstract: Behavior Cloning (BC) on curated (or filtered) data is the predominant
paradigm for supervised fine-tuning (SFT) of large language models; as well as
for imitation learning of control policies. Here, we draw on a connection
between this successful strategy and the theory and practice of finding optimal
policies via Reinforcement Learning (RL). Building on existing literature, we
clarify that SFT can be understood as maximizing a lower bound on the RL
objective in a sparse reward setting. Giving support to its often observed good
performance. From this viewpoint, we realize that a small modification to SFT
leads to an importance weighted variant that behaves closer to training with RL
as it: i) optimizes a tighter bound to the RL objective and, ii) can improve
performance compared to SFT on curated data. We refer to this variant as
importance weighted supervised fine-tuning (iw-SFT). We show that it is easy to
implement and can be further generalized to training with quality scored data.
The resulting SFT variants are competitive with more advanced RL algorithms for
large language models and for training policies in continuous control tasks.
For example achieving 66.7% on the AIME 2024 dataset.

</details>


### [342] [An Investigation of Ear-EEG Signals for a Novel Biometric Authentication System](https://arxiv.org/abs/2507.12873)
*Danilo Avola,Giancarlo Crocetti,Gian Luca Foresti,Daniele Pannone,Claudio Piciarelli,Amedeo Ranaldi*

Main category: cs.LG

TL;DR: 耳内脑电图（ear-EEG）通过深度学习可实现82%准确率的生物识别。


<details>
  <summary>Details</summary>
Motivation: 传统的基于脑电图（EEG）的生物识别系统虽然安全，但由于头皮电极设置不便，可用性较低。本研究旨在探索使用耳内脑电图（ear-EEG）作为一种用户友好、实用的替代方案。

Method: 提出了一种利用耳内脑电图（ear-EEG）信号的框架，提取时域和频域特征，并使用全连接深度神经网络进行主体识别。

Result: 在公开的ear-EEG数据集上进行实验，在主体识别场景中平均准确率达到82%。

Conclusion: 该研究证实了耳内脑电图（ear-EEG）作为一种用户友好且可行的生物识别方法具有潜力，可以用于下一代生物识别系统。

Abstract: This work explores the feasibility of biometric authentication using EEG
signals acquired through in-ear devices, commonly referred to as ear-EEG.
Traditional EEG-based biometric systems, while secure, often suffer from low
usability due to cumbersome scalp-based electrode setups. In this study, we
propose a novel and practical framework leveraging ear-EEG signals as a
user-friendly alternative for everyday biometric authentication. The system
extracts an original combination of temporal and spectral features from ear-EEG
signals and feeds them into a fully connected deep neural network for subject
identification. Experimental results on the only currently available ear-EEG
dataset suitable for different purposes, including biometric authentication,
demonstrate promising performance, with an average accuracy of 82\% in a
subject identification scenario. These findings confirm the potential of
ear-EEG as a viable and deployable direction for next-generation real-world
biometric systems.

</details>


### [343] [Generalist Bimanual Manipulation via Foundation Video Diffusion Models](https://arxiv.org/abs/2507.12898)
*Yao Feng,Hengkai Tan,Xinyi Mao,Guodong Liu,Shuhe Huang,Chendong Xiang,Hang Su,Jun Zhu*

Main category: cs.LG

TL;DR: VIDAR通过使用大型视频预训练和掩码逆向动力学模型，实现了高效的双臂机器人操作，大大减少了数据需求，并提高了泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了应对双臂机器人操作中数据稀疏和实体异构性这些长期存在的挑战，VIDAR旨在通过利用大规模视频预训练和新颖的掩码逆向动力学模型来提高机器人操作的可扩展性和泛化能力。

Method: VIDAR是一个两阶段的框架，它利用基于扩散的视频预训练和新颖的掩码逆向动力学模型来进行动作预测。首先，在750K多视图视频上预训练视频扩散模型，并利用统一的观察空间来编码机器人、相机、任务和场景上下文。然后，掩码逆向动力学模型学习从生成的轨迹中提取与动作相关的信息，而无需像素级标签，并且这些掩码可以有效地泛化到看不见的背景。

Result: VIDAR在看不见的机器人平台上，仅用20分钟的人类演示（仅占典型数据需求的1%）就能泛化到看不见的任务和背景，并具有强大的语义理解能力，其性能超过了最先进的方法。

Conclusion: VIDAR的视频基础模型和掩码动作预测相结合，有潜力实现可扩展和通用的机器人操作，以适应多样化的现实世界环境。

Abstract: Bimanual robotic manipulation, which involves the coordinated control of two
robotic arms, is foundational for solving challenging tasks. Despite recent
progress in general-purpose manipulation, data scarcity and embodiment
heterogeneity remain serious obstacles to further scaling up in bimanual
settings. In this paper, we introduce VIdeo Diffusion for Action Reasoning
(VIDAR), a two-stage framework that leverages large-scale, diffusion-based
video pre-training and a novel masked inverse dynamics model for action
prediction. We pre-train the video diffusion model on 750K multi-view videos
from three real-world bimanual robot platforms, utilizing a unified observation
space that encodes robot, camera, task, and scene contexts. Our masked inverse
dynamics model learns masks to extract action-relevant information from
generated trajectories without requiring pixel-level labels, and the masks can
effectively generalize to unseen backgrounds. Our experiments demonstrate that
with only 20 minutes of human demonstrations on an unseen robot platform (only
1% of typical data requirements), VIDAR generalizes to unseen tasks and
backgrounds with strong semantic understanding, surpassing state-of-the-art
methods. Our findings highlight the potential of video foundation models,
coupled with masked action prediction, to enable scalable and generalizable
robotic manipulation in diverse real-world settings.

</details>


### [344] [Learning to Reject Low-Quality Explanations via User Feedback](https://arxiv.org/abs/2507.12900)
*Luca Stradiotti,Dario Pesenti,Stefano Teso,Jesse Davis*

Main category: cs.LG

TL;DR: ML predictors in high-stakes apps need trustworthy explanations. We created LtX with ULER, which learns from human feedback to reject bad explanations, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Machine learning predictors are increasingly used in high-stakes applications, but explanations for their predictions are not always high-quality, leading to difficulties in interpretation, trust assessment, and decision-making. Classifiers should have the option to refuse inputs with low-quality explanations.

Method: We propose a framework for learning to reject low-quality explanations (LtX) and introduce ULER (User-centric Low-quality Explanation Rejector), which learns a simple rejector from human ratings and per-feature relevance judgments to mirror human judgments of explanation quality.

Result: ULER outperforms both state-of-the-art and explanation-aware learning to reject strategies at LtX on eight classification and regression benchmarks and a new human-annotated dataset.

Conclusion: We introduce ULER, a framework for learning to reject low-quality explanations, which equips predictors with a rejector to evaluate explanation quality. ULER learns a simple rejector from human ratings and per-feature relevance judgments to mirror human judgments of explanation quality.

Abstract: Machine Learning predictors are increasingly being employed in high-stakes
applications such as credit scoring. Explanations help users unpack the reasons
behind their predictions, but are not always "high quality''. That is,
end-users may have difficulty interpreting or believing them, which can
complicate trust assessment and downstream decision-making. We argue that
classifiers should have the option to refuse handling inputs whose predictions
cannot be explained properly and introduce a framework for learning to reject
low-quality explanations (LtX) in which predictors are equipped with a rejector
that evaluates the quality of explanations. In this problem setting, the key
challenges are how to properly define and assess explanation quality and how to
design a suitable rejector. Focusing on popular attribution techniques, we
introduce ULER (User-centric Low-quality Explanation Rejector), which learns a
simple rejector from human ratings and per-feature relevance judgments to
mirror human judgments of explanation quality. Our experiments show that ULER
outperforms both state-of-the-art and explanation-aware learning to reject
strategies at LtX on eight classification and regression benchmarks and on a
new human-annotated dataset, which we will publicly release to support future
research.

</details>


### [345] [Fremer: Lightweight and Effective Frequency Transformer for Workload Forecasting in Cloud Services](https://arxiv.org/abs/2507.12908)
*Jiadong Chen,Hengyu Ye,Fuxin Jiang,Xiao He,Tieying Zhang,Jianjun Chen,Xiaofeng Gao*

Main category: cs.LG

TL;DR: Fremer 是一种新的深度预测模型，通过频域处理提高了效率和准确性，在云工作负载预测和自动扩缩容方面表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 Transformer 的预测模型在计算效率上无法满足大规模云环境的严格要求，而工作负载通常具有复杂的周期性模式，因此需要一种在频域处理这些模式的高效模型。

Method: 提出了一种名为 Fremer 的高效深度预测模型，该模型通过在频域处理复杂周期性模式来解决 Transformer 模型在计算效率上的不足，以满足大规模云环境的需求。

Result: Fremer 模型在效率上优于大多数基于 Transformer 的模型，在工作负载预测准确性上超越了所有 SOTA 模型，并且对多周期序列具有鲁棒性。在 ByteDance 的云服务数据和公开基准数据集上的实验表明，与 SOTA 模型相比，Fremer 在 MSE、MAE 和 SMAPE 指标上分别平均提高了 5.5%、4.7% 和 8.6%，同时减少了参数量和计算成本。

Conclusion: Fremer 模型在工作负载预测方面表现出色，通过在频域处理复杂周期性模式，实现了高效率和高准确性，并在实际应用中（如 Kubernetes 自动扩缩容）取得了显著的性能提升，平均延迟降低了 18.78%，资源消耗减少了 2.35%。

Abstract: Workload forecasting is pivotal in cloud service applications, such as
auto-scaling and scheduling, with profound implications for operational
efficiency. Although Transformer-based forecasting models have demonstrated
remarkable success in general tasks, their computational efficiency often falls
short of the stringent requirements in large-scale cloud environments. Given
that most workload series exhibit complicated periodic patterns, addressing
these challenges in the frequency domain offers substantial advantages. To this
end, we propose Fremer, an efficient and effective deep forecasting model.
Fremer fulfills three critical requirements: it demonstrates superior
efficiency, outperforming most Transformer-based forecasting models; it
achieves exceptional accuracy, surpassing all state-of-the-art (SOTA) models in
workload forecasting; and it exhibits robust performance for multi-period
series. Furthermore, we collect and open-source four high-quality, open-source
workload datasets derived from ByteDance's cloud services, encompassing
workload data from thousands of computing instances. Extensive experiments on
both our proprietary datasets and public benchmarks demonstrate that Fremer
consistently outperforms baseline models, achieving average improvements of
5.5% in MSE, 4.7% in MAE, and 8.6% in SMAPE over SOTA models, while
simultaneously reducing parameter scale and computational costs. Additionally,
in a proactive auto-scaling test based on Kubernetes, Fremer improves average
latency by 18.78% and reduces resource consumption by 2.35%, underscoring its
practical efficacy in real-world applications.

</details>


### [346] [Robust Explanations Through Uncertainty Decomposition: A Path to Trustworthier AI](https://arxiv.org/abs/2507.12913)
*Chenrui Zhu,Louenas Bounia,Vu Linh Nguyen,Sébastien Destercke,Arthur Hoarau*

Main category: cs.LG

TL;DR: 提出一种新的可解释性方法，利用数据和模型不确定性来指导解释选择，提高模型透明度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型日益复杂，模型预测的透明度需求增加，但现有可解释性方法在复杂模型上效果减弱。

Method: 提出利用预测不确定性（aleatoric和epistemic）来指导可解释性方法的选择，其中epistemic不确定性作为不可靠解释的拒绝标准，aleatoric不确定性用于区分特征重要性解释和反事实解释。

Result: 实验证明了该不确定性感知的方法在传统机器学习和深度学习场景中，能够提高可解释性的鲁棒性和可实现性。

Conclusion: 该研究提出了利用预测不确定性作为经典可解释性方法的补充方法，通过区分aleatoric（数据相关）和epistemic（模型相关）不确定性来指导选择合适的可解释性方法。实验证明了这种不确定性感知的方法在传统机器学习和深度学习场景中对可解释性的鲁棒性和可实现性有显著影响。

Abstract: Recent advancements in machine learning have emphasized the need for
transparency in model predictions, particularly as interpretability diminishes
when using increasingly complex architectures. In this paper, we propose
leveraging prediction uncertainty as a complementary approach to classical
explainability methods. Specifically, we distinguish between aleatoric
(data-related) and epistemic (model-related) uncertainty to guide the selection
of appropriate explanations. Epistemic uncertainty serves as a rejection
criterion for unreliable explanations and, in itself, provides insight into
insufficient training (a new form of explanation). Aleatoric uncertainty
informs the choice between feature-importance explanations and counterfactual
explanations. This leverages a framework of explainability methods driven by
uncertainty quantification and disentanglement. Our experiments demonstrate the
impact of this uncertainty-aware approach on the robustness and attainability
of explanations in both traditional machine learning and deep learning
scenarios.

</details>


### [347] [Trace Reconstruction with Language Models](https://arxiv.org/abs/2507.12927)
*Franziska Weindel,Michael Girsch,Reinhard Heckel*

Main category: cs.LG

TL;DR: A new method called TReconLM uses language models to reconstruct DNA sequences from noisy data more effectively than existing methods.


<details>
  <summary>Details</summary>
Motivation: The general trace reconstruction problem aims to recover an original sequence from its noisy copies, which is crucial for applications like DNA data storage where errors are common during synthesis, storage, and sequencing.

Method: TReconLM uses language models pre-trained on synthetic data and fine-tuned on real-world data to adapt to technology-specific error patterns.

Result: TReconLM recovers a substantially higher fraction of sequences without error compared to prior state-of-the-art trace reconstruction algorithms, including previous deep learning approaches.

Conclusion: TReconLM leverages language models trained on next-token prediction for trace reconstruction, outperforming state-of-the-art algorithms.

Abstract: The general trace reconstruction problem seeks to recover an original
sequence from its noisy copies independently corrupted by deletions,
insertions, and substitutions. This problem arises in applications such as DNA
data storage, a promising storage medium due to its high information density
and longevity. However, errors introduced during DNA synthesis, storage, and
sequencing require correction through algorithms and codes, with trace
reconstruction often used as part of the data retrieval process. In this work,
we propose TReconLM, which leverages language models trained on next-token
prediction for trace reconstruction. We pretrain language models on synthetic
data and fine-tune on real-world data to adapt to technology-specific error
patterns. TReconLM outperforms state-of-the-art trace reconstruction
algorithms, including prior deep learning approaches, recovering a
substantially higher fraction of sequences without error.

</details>


### [348] [From a Mixed-Policy Perspective: Improving Differentiable Automatic Post-editing Optimization](https://arxiv.org/abs/2507.12931)
*Hongze Tan*

Main category: cs.LG

TL;DR: This paper improves policy optimization by adding a guiding policy and reusing zero-reward samples, making training more stable and efficient.


<details>
  <summary>Details</summary>
Motivation: Standard policy gradient methods suffer from instability and sample inefficiency, particularly in sparse reward settings. This paper addresses these issues by proposing methods to improve training stability, convergence speed, and sample efficiency.

Method: Two novel modifications to the Differentiable Automatic Post-editing Optimization (DAPO) algorithm are proposed: 1. Incorporating a pre-trained, stable guiding policy to provide off-policy experience and regularize training. 2. Re-utilizing zero-reward samples by treating them as a distinct batch guided by the expert policy.

Result: Both proposed methods have theoretical analysis showing that their objective functions converge to the optimal solution within the established theoretical framework of reinforcement learning.

Conclusion: The proposed mixed-policy framework effectively balances exploration and exploitation, promising more stable and efficient policy optimization.

Abstract: This paper introduces two novel modifications to the Differentiable Automatic
Post-editing Optimization (DAPO) algorithm, approached from a mixed-policy
perspective. Standard policy gradient methods can suffer from instability and
sample inefficiency, particularly in sparse reward settings. To address this,
we first propose a method that incorporates a pre-trained, stable guiding
policy ($\piphi$) to provide off-policy experience, thereby regularizing the
training of the target policy ($\pion$). This approach improves training
stability and convergence speed by adaptively adjusting the learning step size.
Secondly, we extend this idea to re-utilize zero-reward samples, which are
often discarded by dynamic sampling strategies like DAPO's. By treating these
samples as a distinct batch guided by the expert policy, we further enhance
sample efficiency. We provide a theoretical analysis for both methods,
demonstrating that their objective functions converge to the optimal solution
within the established theoretical framework of reinforcement learning. The
proposed mixed-policy framework effectively balances exploration and
exploitation, promising more stable and efficient policy optimization.

</details>


### [349] [Probabilistic Soundness Guarantees in LLM Reasoning Chains](https://arxiv.org/abs/2507.12948)
*Weiqiu You,Anton Xue,Shreya Havaldar,Delip Rao,Helen Jin,Chris Callison-Burch,Eric Wong*

Main category: cs.LG

TL;DR: ARES 是一个新框架，可以防止 LLM 推理中的错误传播，从而提高准确性。


<details>
  <summary>Details</summary>
Motivation: 为了更好地检测 LLM 推理链中初始错误传播导致的错误，这些错误会破坏最终结论的可靠性，并且当前的 LLM 检测方法无法妥善处理。

Method: 提出了一种名为 Autoregressive Reasoning Entailment Stability (ARES) 的新颖概率框架。该框架通过仅根据先前评估的可靠前提来判断每个声明来防止错误传播，从而产生每个步骤的细微分数，并提供其可靠性的认证统计保证，而不是脆弱的二元标签。

Result: ARES 在四个基准测试中取得了最先进的性能（72.1% Macro-F1，+8.2 分），并在非常长的合成推理链中表现出卓越的鲁棒性，在检测传播的错误方面表现出色（90.3% F1，+27.6 分）。

Conclusion: ARES 框架通过仅根据先前评估的可靠前提来判断每个声明，从而防止了错误传播，从而在检测传播的错误方面表现出色。

Abstract: In reasoning chains generated by large language models (LLMs), initial errors
often propagate and undermine the reliability of the final conclusion. Current
LLM-based error detection methods often fail to detect propagated errors
because they do not properly account for how earlier errors might corrupt
judgments of downstream reasoning. To better detect such propagated errors, we
introduce Autoregressive Reasoning Entailment Stability (ARES), a novel
probabilistic framework that prevents error propagation by judging each claim
based only on previously-assessed sound premises. This inductive method yields
a nuanced score for each step and provides certified statistical guarantees of
its soundness, rather than a brittle binary label. ARES achieves
state-of-the-art performance across four benchmarks (72.1% Macro-F1, +8.2
points) and demonstrates superior robustness on very long synthetic reasoning
chains, where it excels at detecting propagated errors (90.3% F1, +27.6
points).

</details>


### [350] [Insights into a radiology-specialised multimodal large language model with sparse autoencoders](https://arxiv.org/abs/2507.12950)
*Kenza Bouzid,Shruthi Bannur,Daniel Coelho de Castro,Anton Schwaighofer,Javier Alvarez-Valle,Stephanie L. Hyland*

Main category: cs.LG

TL;DR: 使用Matryoshka-SAE解释了医疗大模型MAIRA-2，识别了临床概念并尝试控制模型行为，为提高模型透明度迈出了第一步。


<details>
  <summary>Details</summary>
Motivation: 提高AI模型在医疗保健等高风险领域的安全性、透明度和可信度，特别是通过稀疏自编码器（SAE）来揭示大型Transformer模型中的人类可解释特征。

Method: 使用Matryoshka稀疏自编码器（SAE）对MAIRA-2模型进行解释，并通过大规模自动化解释SAE特征来识别临床相关概念，同时研究这些特征对模型行为的影响。

Result: 成功识别出多种临床相关概念，包括医疗设备（如导管和引流管放置、心脏起搏器）、病理（如胸腔积液、心扩大）、纵向变化和文本特征，并通过引导实验展示了对模型生成进行定向控制的能力（但成功率不一），同时也暴露了实际和方法上的挑战。

Conclusion: 这项研究为理解和解释放射学领域专门的多模态大语言模型MAIRA-2提供了初步的见解，为实现更深入的机制理解和提高模型透明度奠定了基础。

Abstract: Interpretability can improve the safety, transparency and trust of AI models,
which is especially important in healthcare applications where decisions often
carry significant consequences. Mechanistic interpretability, particularly
through the use of sparse autoencoders (SAEs), offers a promising approach for
uncovering human-interpretable features within large transformer-based models.
In this study, we apply Matryoshka-SAE to the radiology-specialised multimodal
large language model, MAIRA-2, to interpret its internal representations. Using
large-scale automated interpretability of the SAE features, we identify a range
of clinically relevant concepts - including medical devices (e.g., line and
tube placements, pacemaker presence), pathologies such as pleural effusion and
cardiomegaly, longitudinal changes and textual features. We further examine the
influence of these features on model behaviour through steering, demonstrating
directional control over generations with mixed success. Our results reveal
practical and methodological challenges, yet they offer initial insights into
the internal concepts learned by MAIRA-2 - marking a step toward deeper
mechanistic understanding and interpretability of a radiology-adapted
multimodal large language model, and paving the way for improved model
transparency. We release the trained SAEs and interpretations:
https://huggingface.co/microsoft/maira-2-sae.

</details>


### [351] [A Spectral Interpretation of Redundancy in a Graph Reservoir](https://arxiv.org/abs/2507.12963)
*Anna Bison,Alessandro Sperduti*

Main category: cs.LG

TL;DR: 本研究提出了一种改进的图神经网络（MRGNN）模型，通过借鉴计算机图形学中的公平化算法来解决过平滑问题，并在图分类任务中展示了良好的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 为了解决图神经网络（GNNs）在图上重复应用层算子时出现的过平滑问题，该研究旨在通过一种新的方法来改进GNN的训练效率，同时控制平滑过程。

Method: 提出了一种基于公平化算法的MRGNN（多分辨率图神经网络）变体，该算法通过拉普拉斯算子在图设置中实现通带光谱滤波，以在平滑的同时避免收缩。

Result: 本研究通过探索性实验证明了该方法的潜力，并为未来的研究指明了有希望的方向。实验基于MRGNN架构进行。

Conclusion: 本研究提出了一种基于计算机图形学中公平化算法的MRGNN变体，该算法提供了一种通带光谱滤波器，可以在平滑的同时避免收缩。通过拉普拉斯算子将其应用于图设置，可以自然地连接到GNN架构，特别是对于平滑在适当控制下可能受益的任务，例如图分类。研究还从随机游走的角度对该算法进行了理论分析，展示了调整光谱系数如何被解释为调节冗余随机游走的贡献。

Abstract: Reservoir computing has been successfully applied to graphs as a
preprocessing method to improve the training efficiency of Graph Neural
Networks (GNNs). However, a common issue that arises when repeatedly applying
layer operators on graphs is over-smoothing, which consists in the convergence
of graph signals toward low-frequency components of the graph Laplacian. This
work revisits the definition of the reservoir in the Multiresolution Reservoir
Graph Neural Network (MRGNN), a spectral reservoir model, and proposes a
variant based on a Fairing algorithm originally introduced in the field of
surface design in computer graphics. This algorithm provides a pass-band
spectral filter that allows smoothing without shrinkage, and it can be adapted
to the graph setting through the Laplacian operator. Given its spectral
formulation, this method naturally connects to GNN architectures for tasks
where smoothing, when properly controlled, can be beneficial,such as graph
classification. The core contribution of the paper lies in the theoretical
analysis of the algorithm from a random walks perspective. In particular, it
shows how tuning the spectral coefficients can be interpreted as modulating the
contribution of redundant random walks. Exploratory experiments based on the
MRGNN architecture illustrate the potential of this approach and suggest
promising directions for future research.

</details>


### [352] [WaveletInception Networks for Drive-by Vibration-Based Infrastructure Health Monitoring](https://arxiv.org/abs/2507.12969)
*Reza Riahi Samani,Alfredo Nunez,Bart De Schutter*

Main category: cs.LG

TL;DR: 提出了一种名为WaveletInception-BiLSTM的新型深度学习框架，用于分析驶近式振动信号以监测基础设施健康状况。该框架能有效提取频谱和时间特征，并处理不同测量速度下的信号，无需预处理。在铁路轨道刚度估算任务中，该模型表现出色，显示出其在自动化基础设施健康监测方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 认识到频谱和时间信息的重要性，旨在开发一种能够分析不同测量速度下的驶近式振动信号的框架，而无需预处理，并能捕捉不同信息模式之间的相关时间依赖性，从而实现健康状况的估计。

Method: 提出了一种基于深度学习的框架，利用驶近式振动响应信号进行基础设施健康监测。该框架集成了小波Inception-BiLSTM网络，其中小波Inception特征提取器采用可学习小波包变换（LWPT）提取振动信号特征，并融合早期网络层中的频谱信息。后续的1D Inception网络用于提取多尺度、高层特征。提取的特征与运行状况信息通过长短期记忆（LSTM）层结合，用于健康状况估计。估计器头部采用双向LSTM（BiLSTM）网络进行序列建模，以捕捉驶近式测量中的双向时间依赖性。

Result: 通过模拟驶近式振动信号的铁路轨道刚度估算案例研究，证明了该模型在估算铁路道砟和轨道垫板刚度参数方面显著优于现有技术。

Conclusion: 该模型在铁路道砟和轨道垫板刚度参数估算方面显著优于最先进的方法，表明该方法在准确、局部和全自动的驶近式基础设施健康监测方面具有潜力。

Abstract: This paper presents a novel deep learning-based framework for infrastructure
health monitoring using drive-by vibration response signals. Recognizing the
importance of spectral and temporal information, we introduce the
WaveletInception-BiLSTM network. The WaveletInception feature extractor
utilizes a Learnable Wavelet Packet Transform (LWPT) as the stem for extracting
vibration signal features, incorporating spectral information in the early
network layers. This is followed by 1D Inception networks that extract
multi-scale, high-level features at deeper layers. The extracted vibration
signal features are then integrated with operational conditions via a Long
Short-term Memory (LSTM) layer. The resulting feature extraction network
effectively analyzes drive-by vibration signals across various measurement
speeds without preprocessing and uses LSTM to capture interrelated temporal
dependencies among different modes of information and to create feature vectors
for health condition estimation. The estimator head is designed with a
sequential modeling architecture using bidirectional LSTM (BiLSTM) networks,
capturing bi-directional temporal relationships from drive-by measurements.
This architecture allows for a high-resolution, beam-level assessment of
infrastructure health conditions. A case study focusing on railway track
stiffness estimation with simulated drive-by vibration signals shows that the
model significantly outperforms state-of-the-art methods in estimating railway
ballast and railpad stiffness parameters. Results underscore the potential of
this approach for accurate, localized, and fully automated drive-by
infrastructure health monitoring.

</details>


### [353] [A Distributed Generative AI Approach for Heterogeneous Multi-Domain Environments under Data Sharing constraints](https://arxiv.org/abs/2507.12979)
*Youssef Tawfilis,Hossam Amer,Minar El-Aasser,Tallal Elshabrawy*

Main category: cs.LG

TL;DR: 一种新颖的去中心化GAN训练方法，结合了联邦学习和迁移学习，解决了数据隐私和设备异质性问题，并在图像生成和分类任务上取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 解决在实际应用中，由于数据隐私、版权限制以及设备能力差异，导致难以获取大规模数据集和利用低能力设备进行生成模型训练的问题。

Method: 结合KLD加权聚类联邦学习和异质U型迁移学习，用于去中心化的GAN训练。

Result: 在图像生成任务上实现了1.1倍至2.2倍的提升，在分类任务上平均提升了10%（在多域非独立同分布设置下最高提升50%），同时降低了延迟。

Conclusion: 该方法在数据异质性和设备异质性方面具有优势，并能在严格的数据共享限制下进行联合GAN训练，实验结果表明在图像生成和分类任务上均有显著提升，且延迟更低。

Abstract: Federated Learning has gained increasing attention for its ability to enable
multiple nodes to collaboratively train machine learning models without sharing
their raw data. At the same time, Generative AI -- particularly Generative
Adversarial Networks (GANs) -- have achieved remarkable success across a wide
range of domains, such as healthcare, security, and Image Generation. However,
training generative models typically requires large datasets and significant
computational resources, which are often unavailable in real-world settings.
Acquiring such resources can be costly and inefficient, especially when many
underutilized devices -- such as IoT devices and edge devices -- with varying
capabilities remain idle. Moreover, obtaining large datasets is challenging due
to privacy concerns and copyright restrictions, as most devices are unwilling
to share their data. To address these challenges, we propose a novel approach
for decentralized GAN training that enables the utilization of distributed data
and underutilized, low-capability devices while not sharing data in its raw
form. Our approach is designed to tackle key challenges in decentralized
environments, combining KLD-weighted Clustered Federated Learning to address
the issues of data heterogeneity and multi-domain datasets, with Heterogeneous
U-Shaped split learning to tackle the challenge of device heterogeneity under
strict data sharing constraints -- ensuring that no labels or raw data, whether
real or synthetic, are ever shared between nodes. Experimental results shows
that our approach demonstrates consistent and significant improvements across
key performance metrics, where it achieves 1.1x -- 2.2x higher image generation
scores, an average 10% boost in classification metrics (up to 50% in
multi-domain non-IID settings), in much lower latency compared to several
benchmarks. Find our code at https://github.com/youssefga28/HuSCF-GAN.

</details>


### [354] [Teach Old SAEs New Domain Tricks with Boosting](https://arxiv.org/abs/2507.12990)
*Nikita Koriagin,Yaroslav Aksenov,Daniil Laptev,Gleb Gerasimov,Nikita Balagansky,Daniil Gavrilov*

Main category: cs.LG

TL;DR: 一种残差学习方法，通过训练第二个SAE来捕捉第一个SAE在特定领域数据的重建误差，以解决SAE的特征盲区问题，并在不重新训练的情况下提高其在特定领域的性能。


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器（SAE）在解释大型语言模型（LLM）的内部表征方面能力强大，但它们通常无法捕捉其训练语料库中不常见的领域特定特征。本研究旨在解决SAE的这种特征盲区问题。

Method: 提出了一种残差学习方法，训练一个次级SAE来模拟预训练SAE在领域特定文本上的重建误差。在推理时，将两个模型的输出相加。

Result: 通过将主模型和次级模型的输出相加，在多个专业领域上显著提高了LLM交叉熵和可解释方差指标。该方法能够高效地将新的领域知识整合到现有的SAE中，同时保持其在通用任务上的性能。

Conclusion: 本研究提出了一种残差学习方法，通过训练一个辅助稀疏自编码器（SAE）来捕捉主模型在领域特定文本上重建误差，从而有效解决了SAE在处理未包含在训练语料库中的领域特定特征时的“特征盲区”问题。通过将两个模型的输加和，该方法在多个专业领域上显著提高了LLM交叉熵和可解释方差指标。实验证明，该方法能够在不完全重新训练的情况下，高效地将新的领域知识整合到现有的SAE中，同时保持其在通用任务上的性能。

Abstract: Sparse Autoencoders have emerged as powerful tools for interpreting the
internal representations of Large Language Models, yet they often fail to
capture domain-specific features not prevalent in their training corpora. This
paper introduces a residual learning approach that addresses this feature
blindness without requiring complete retraining. We propose training a
secondary SAE specifically to model the reconstruction error of a pretrained
SAE on domain-specific texts, effectively capturing features missed by the
primary model. By summing the outputs of both models during inference, we
demonstrate significant improvements in both LLM cross-entropy and explained
variance metrics across multiple specialized domains. Our experiments show that
this method efficiently incorporates new domain knowledge into existing SAEs
while maintaining their performance on general tasks. This approach enables
researchers to selectively enhance SAE interpretability for specific domains of
interest, opening new possibilities for targeted mechanistic interpretability
of LLMs.

</details>


### [355] [SMART: Relation-Aware Learning of Geometric Representations for Knowledge Graphs](https://arxiv.org/abs/2507.13001)
*Kossi Amouzouvi,Bowen Song,Andrea Coletta,Luigi Bellomarini,Jens Lehmann,Sahar Vahdati*

Main category: cs.LG

TL;DR: 本研究提出了一个新框架，通过为每个关系分配最佳匹配的几何变换来改进知识图谱嵌入（KGE）模型。该方法在多个基准测试中取得了与领先模型相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的知识图谱嵌入（KGE）模型虽然利用基础几何变换（EGTs）来表示知识图谱中的关系，但未能充分考虑特定关系应采用特定变换的需求。尽管一些模型尝试通过集成方法解决此问题，但它们仅使用单一或复合的几何变换来表示所有关系。

Method: 本研究提出了一个框架，评估每个关系与不同几何变换的匹配度。基于此排名，模型可以选择将最佳匹配变换分配给每个关系，或通过多数投票为所有关系选择一种变换类型。模型利用注意力机制在低维向量空间中学习单一的关系特定基础几何变换（EGT），并使用学习到的低维关系与 EGTs 之间的相关性来学习高维向量空间中的关系嵌入。

Result: 该模型在三个基准知识图谱和一个真实的金融知识图谱上的综合评估结果表明，其性能与领先模型相当，证明了所提出的框架和方法的有效性。

Conclusion: 目前最先进的知识图谱嵌入（KGE）模型大多基于基础几何变换（EGTs）或其组合。然而，这些模型未能充分考虑特定关系变换。本研究提出了一个评估框架，根据每个关系与不同几何变换的匹配度进行排名，从而为每个关系分配最佳匹配变换，或通过多数投票为所有关系选择一种变换类型。该模型通过注意力机制在低维向量空间中学习单一的关系特定 EGT，并利用学习到的关系与 EGTs 之间的相关性来学习高维向量空间中的关系嵌入。在三个基准知识图谱和一个真实的金融知识图谱上的综合评估证明了该模型的有效性，其性能与领先模型相当。

Abstract: Knowledge graph representation learning approaches provide a mapping between
symbolic knowledge in the form of triples in a knowledge graph (KG) and their
feature vectors. Knowledge graph embedding (KGE) models often represent
relations in a KG as geometric transformations. Most state-of-the-art (SOTA)
KGE models are derived from elementary geometric transformations (EGTs), such
as translation, scaling, rotation, and reflection, or their combinations. These
geometric transformations enable the models to effectively preserve specific
structural and relational patterns of the KG. However, the current use of EGTs
by KGEs remains insufficient without considering relation-specific
transformations. Although recent models attempted to address this problem by
ensembling SOTA baseline models in different ways, only a single or composite
version of geometric transformations are used by such baselines to represent
all the relations. In this paper, we propose a framework that evaluates how
well each relation fits with different geometric transformations. Based on this
ranking, the model can: (1) assign the best-matching transformation to each
relation, or (2) use majority voting to choose one transformation type to apply
across all relations. That is, the model learns a single relation-specific EGT
in low dimensional vector space through an attention mechanism. Furthermore, we
use the correlation between relations and EGTs, which are learned in a low
dimension, for relation embeddings in a high dimensional vector space. The
effectiveness of our models is demonstrated through comprehensive evaluations
on three benchmark KGs as well as a real-world financial KG, witnessing a
performance comparable to leading models

</details>


### [356] [Fault detection and diagnosis for the engine electrical system of a space launcher based on a temporal convolutional autoencoder and calibrated classifiers](https://arxiv.org/abs/2507.13022)
*Luis Basora,Louison Bocquet-Nouaille,Elinirina Robinson,Serge Le Gonidec*

Main category: cs.LG

TL;DR: 为火箭发动机阀门控制电气系统开发了一种基于时间卷积自编码器和梯度提升模型的方法，用于故障检测和诊断，并考虑了置信度估计、OOD检测和虚警控制。


<details>
  <summary>Details</summary>
Motivation: 为下一代可重复使用运载火箭的健康监测开发机载故障检测和诊断能力，满足预测置信度估计、分布外（OOD）情况检测和虚警控制等关键要求。

Method: 提出了一种基于时间卷积自编码器的解决方案，用于从原始传感器数据中自动提取低维特征。利用该自编码器的潜在空间和残差空间训练分类器，分别进行故障检测和诊断。采用基于直方图的梯度提升模型进行分类，并进行校准以输出可解释为置信水平的概率。使用归纳保形异常检测技术识别分布外（OOD）数据，并结合累积和控制图（CUSUM）和阈值移动技术来控制虚警和处理类别不平衡问题。

Result: 在模拟数据上进行了评估，结果表明该解决方案是一个有前途的初步尝试。

Conclusion: 该框架是一个有前途的初步解决方案，但仍需使用真实数据进行测试，以确保其达到运行成熟度。

Abstract: In the context of the health monitoring for the next generation of reusable
space launchers, we outline a first step toward developing an onboard fault
detection and diagnostic capability for the electrical system that controls the
engine valves. Unlike existing approaches in the literature, our solution is
designed to meet a broader range of key requirements. This includes estimating
confidence levels for predictions, detecting out-of-distribution (OOD) cases,
and controlling false alarms. The proposed solution is based on a temporal
convolutional autoencoder to automatically extract low-dimensional features
from raw sensor data. Fault detection and diagnosis are respectively carried
out using a binary and a multiclass classifier trained on the autoencoder
latent and residual spaces. The classifiers are histogram-based gradient
boosting models calibrated to output probabilities that can be interpreted as
confidence levels. A relatively simple technique, based on inductive conformal
anomaly detection, is used to identify OOD data. We leverage other simple yet
effective techniques, such as cumulative sum control chart (CUSUM) to limit the
false alarms, and threshold moving to address class imbalance in fault
detection. The proposed framework is highly configurable and has been evaluated
on simulated data, covering both nominal and anomalous operational scenarios.
The results indicate that our solution is a promising first step, though
testing with real data will be necessary to ensure that it achieves the
required maturity level for operational use.

</details>


### [357] [Confidence-Filtered Relevance (CFR): An Interpretable and Uncertainty-Aware Machine Learning Framework for Naturalness Assessment in Satellite Imagery](https://arxiv.org/abs/2507.13034)
*Ahmed Emam,Ribana Roscher*

Main category: cs.LG

TL;DR: CFR框架通过结合LRP注意力和DDU估计来分析模型不确定性如何影响卫星图像中自然度的可解释性。该方法根据不确定性对数据集进行划分，发现不确定性越高，可解释性越差。


<details>
  <summary>Details</summary>
Motivation: 受保护的自然区域在生态平衡和生态系统服务中起着至关重要的作用。使用卫星图像和机器学习对这些区域进行大规模监测是有希望的，但目前的方法往往缺乏可解释性和对不确定性的认识，并且没有解决不确定性如何影响自然度评估的问题。

Method: 本文提出了一种名为置信度过滤相关性（CFR）的数据中心框架，该框架结合了LRP注意力展开和深度确定性不确定性（DDU）估计，以分析模型不确定性如何影响相关性热图的可解释性。CFR根据不确定性阈值将数据集划分为子集，从而能够系统地分析不确定性如何影响卫星图像中自然度的解释。

Result: CFR被应用于AnthroProtect数据集，并将较高的相关性分配给灌木丛、森林和湿地，这与其他关于自然度评估的研究一致。此外，我们的分析表明，随着不确定性的增加，这些相关性热图的可解释性会下降，熵会增加，表明其归因选择性较差且模糊性较高。

Conclusion: CFR提供了一种以数据为中心的方法，根据其相关的确定性来评估卫星图像中模式与自然度的相关性。

Abstract: Protected natural areas play a vital role in ecological balance and ecosystem
services. Monitoring these regions at scale using satellite imagery and machine
learning is promising, but current methods often lack interpretability and
uncertainty-awareness, and do not address how uncertainty affects naturalness
assessment. In contrast, we propose Confidence-Filtered Relevance (CFR), a
data-centric framework that combines LRP Attention Rollout with Deep
Deterministic Uncertainty (DDU) estimation to analyze how model uncertainty
influences the interpretability of relevance heatmaps. CFR partitions the
dataset into subsets based on uncertainty thresholds, enabling systematic
analysis of how uncertainty shapes the explanations of naturalness in satellite
imagery. Applied to the AnthroProtect dataset, CFR assigned higher relevance to
shrublands, forests, and wetlands, aligning with other research on naturalness
assessment. Moreover, our analysis shows that as uncertainty increases, the
interpretability of these relevance heatmaps declines and their entropy grows,
indicating less selective and more ambiguous attributions. CFR provides a
data-centric approach to assess the relevance of patterns to naturalness in
satellite imagery based on their associated certainty.

</details>


### [358] [Inverse Reinforcement Learning Meets Large Language Model Post-Training: Basics, Advances, and Opportunities](https://arxiv.org/abs/2507.13158)
*Hao Sun,Mihaela van der Schaar*

Main category: cs.LG

TL;DR: 本文综述了利用逆强化学习（IRL）解决大型语言模型（LLM）对齐问题的最新进展，强调了构建神经奖励模型的重要性，并探讨了方法论、实践和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）的快速发展，如何确保其可靠、可控和强大的能力成为一个核心挑战。强化学习（RL）在提升对话AI系统和推理模型方面取得了显著成功，因此，将RL技术应用于LLM对齐研究变得日益重要。本文旨在全面梳理和总结利用逆强化学习（IRL）解决LLM对齐问题的最新进展、挑战和未来方向，为相关研究提供参考。

Method: 本文采用文献综述的方法，系统地回顾了逆强化学习（IRL）在大型语言模型（LLM）对齐领域的应用。文章首先介绍了强化学习（RL）的基础概念，然后深入探讨了IRL在LLM对齐中的最新进展、关键挑战和机遇。此外，还讨论了相关数据集、基准测试、评估指标、基础设施以及高效的训练和推理技术。最后，从稀疏奖励RL的角度提出了未来的研究方向。

Result: 本文对利用IRL技术进行LLM对齐的研究进行了全面的梳理和总结。文章强调了从人类数据构建神经奖励模型的重要性，并探讨了IRL在LLM对齐中的方法论、实践问题（如数据集、基准、评估指标、基础设施）以及计算效率。此外，还结合稀疏奖励RL的经验，指出了该领域存在的开放性问题和潜在的研究方向。

Conclusion: LLM对齐是一个关键且具有挑战性的问题，尤其是在强化学习（RL）的背景下。本文通过逆强化学习（IRL）的视角，全面回顾了LLM对齐的最新进展，并强调了从人类数据构建神经奖励模型的必要性。此外，文章还探讨了数据集、基准、评估指标、基础设施以及计算效率等实际问题，并从稀疏奖励RL的文献中汲取灵感，指出了未来的研究方向。

Abstract: In the era of Large Language Models (LLMs), alignment has emerged as a
fundamental yet challenging problem in the pursuit of more reliable,
controllable, and capable machine intelligence. The recent success of reasoning
models and conversational AI systems has underscored the critical role of
reinforcement learning (RL) in enhancing these systems, driving increased
research interest at the intersection of RL and LLM alignment. This paper
provides a comprehensive review of recent advances in LLM alignment through the
lens of inverse reinforcement learning (IRL), emphasizing the distinctions
between RL techniques employed in LLM alignment and those in conventional RL
tasks. In particular, we highlight the necessity of constructing neural reward
models from human data and discuss the formal and practical implications of
this paradigm shift. We begin by introducing fundamental concepts in RL to
provide a foundation for readers unfamiliar with the field. We then examine
recent advances in this research agenda, discussing key challenges and
opportunities in conducting IRL for LLM alignment. Beyond methodological
considerations, we explore practical aspects, including datasets, benchmarks,
evaluation metrics, infrastructure, and computationally efficient training and
inference techniques. Finally, we draw insights from the literature on
sparse-reward RL to identify open questions and potential research directions.
By synthesizing findings from diverse studies, we aim to provide a structured
and critical overview of the field, highlight unresolved challenges, and
outline promising future directions for improving LLM alignment through RL and
IRL techniques.

</details>


### [359] [The Power of Architecture: Deep Dive into Transformer Architectures for Long-Term Time Series Forecasting](https://arxiv.org/abs/2507.13043)
*Lefei Shen,Mouxiang Chen,Han Fu,Xiaoxue Ren,Xiaoyun Joy Wang,Jianling Sun,Zhuo Li,Chenghao Liu*

Main category: cs.LG

TL;DR: Transformer LTSF 模型在架构选择上，双向联合注意力、完整的预测聚合和直接映射范式效果最佳。


<details>
  <summary>Details</summary>
Motivation: 为了解决 Transformer LTSF 模型中难以分离架构本身的影响的问题，因为现有模型通常与各种特定于时间序列的设计紧密耦合。

Method: 提出了一种新颖的分类法，将编码器-解码器、注意力机制、预测聚合、预测范式和归一化层等关键方面解耦，从而能够更清晰、更统一地比较 Transformer LTSF 模型。

Result: 通过广泛的实验，证明了双向注意力与联合注意力相结合、更完整的预测聚合以及直接映射范式优于自回归方法。所提出的组合模型在多个现有模型上持续取得优异的成绩。

Conclusion: 双向注意力与联合注意力相结合，更完整的预测聚合以及直接映射范式优于自回归方法，是 Transformer LTSF 的最佳选择。

Abstract: Transformer-based models have recently become dominant in Long-term Time
Series Forecasting (LTSF), yet the variations in their architecture, such as
encoder-only, encoder-decoder, and decoder-only designs, raise a crucial
question: What Transformer architecture works best for LTSF tasks? However,
existing models are often tightly coupled with various time-series-specific
designs, making it difficult to isolate the impact of the architecture itself.
To address this, we propose a novel taxonomy that disentangles these designs,
enabling clearer and more unified comparisons of Transformer architectures. Our
taxonomy considers key aspects such as attention mechanisms, forecasting
aggregations, forecasting paradigms, and normalization layers. Through
extensive experiments, we uncover several key insights: bi-directional
attention with joint-attention is most effective; more complete forecasting
aggregation improves performance; and the direct-mapping paradigm outperforms
autoregressive approaches. Furthermore, our combined model, utilizing optimal
architectural choices, consistently outperforms several existing models,
reinforcing the validity of our conclusions. We hope these findings offer
valuable guidance for future research on Transformer architectural designs in
LTSF. Our code is available at https://github.com/HALF111/TSF_architecture.

</details>


### [360] [On statistical learning of graphs](https://arxiv.org/abs/2507.13054)
*Vittorio Cipriani,Valentino Delle Rose,Luca San Mauro,Giovanni Solda*

Main category: cs.LG

TL;DR: PAC和在线学习能力与无限图的同构类型相关，并等同于自动同构平凡性。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是研究由图G的副本组成的假设类，其中每个副本都由G的顶点的排列引起，相当于学习图的标记，并了解其结构和标签集。

Method: 该研究的重点是PAC和在线学习能力，使用无限图的同构类型，通过有限支持的副本以及描述性集合论和可计算性理论的工具来表征。

Result: PAC学习能力对所有此类有限支持副本的蕴涵是G的完整同构类型的在线学习能力，并且等同于自动同构平凡性的条件。此外，还表征了通过交换两个顶点引起的副本不可学习的图，最后证明了k重排列的学习能力等同于2重排列的学习能力，并得到了无限图的四类划分。

Conclusion: PAC学习和在线学习能力与自动同构平凡性相关联，并与k重排列的学习能力相关联。

Abstract: We study PAC and online learnability of hypothesis classes formed by copies
of a countably infinite graph G, where each copy is induced by permuting G's
vertices. This corresponds to learning a graph's labeling, knowing its
structure and label set. We consider classes where permutations move only
finitely many vertices. Our main result shows that PAC learnability of all such
finite-support copies implies online learnability of the full isomorphism type
of G, and is equivalent to the condition of automorphic triviality. We also
characterize graphs where copies induced by swapping two vertices are not
learnable, using a relaxation of the extension property of the infinite random
graph. Finally, we show that, for all G and k>2, learnability for k-vertex
permutations is equivalent to that for 2-vertex permutations, yielding a
four-class partition of infinite graphs, whose complexity we also determine
using tools coming from both descriptive set theory and computability theory.

</details>


### [361] [DASViT: Differentiable Architecture Search for Vision Transformer](https://arxiv.org/abs/2507.13079)
*Pengjin Wu,Ferrante Neri,Zhenhua Feng*

Main category: cs.LG

TL;DR: DASViT 是一种新的可微分神经架构搜索方法，用于视觉 Transformer，它能找到更高效、参数更少且性能更好的模型，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有针对 ViT 的神经架构搜索方法多采用宏观搜索空间和基于离散的方法（如进化算法），这些方法在发现创新设计、计算资源需求和耗时方面存在挑战。DASViT 旨在解决这些限制，填补 ViT 可微分搜索的空白。

Method: 提出了一种名为 DASViT 的可微分架构搜索方法，专门用于视觉 Transformer (ViT) 架构的搜索与优化。

Result: DASViT 能够发现打破传统 Transformer 编码器设计的全新架构，在多个数据集上性能超越 ViT-B/16，并且在参数量和计算量（FLOPs）更少的情况下实现了更高的效率。

Conclusion: DASViT 提出的可微分搜索方法在视觉 Transformer 架构搜索中取得了显著成果，能够发现超越传统 Transformer 编码器设计的新型高效架构，并在多个数据集上优于 ViT-B/16。

Abstract: Designing effective neural networks is a cornerstone of deep learning, and
Neural Architecture Search (NAS) has emerged as a powerful tool for automating
this process. Among the existing NAS approaches, Differentiable Architecture
Search (DARTS) has gained prominence for its efficiency and ease of use,
inspiring numerous advancements. Since the rise of Vision Transformers (ViT),
researchers have applied NAS to explore ViT architectures, often focusing on
macro-level search spaces and relying on discrete methods like evolutionary
algorithms. While these methods ensure reliability, they face challenges in
discovering innovative architectural designs, demand extensive computational
resources, and are time-intensive. To address these limitations, we introduce
Differentiable Architecture Search for Vision Transformer (DASViT), which
bridges the gap in differentiable search for ViTs and uncovers novel designs.
Experiments show that DASViT delivers architectures that break traditional
Transformer encoder designs, outperform ViT-B/16 on multiple datasets, and
achieve superior efficiency with fewer parameters and FLOPs.

</details>


### [362] [MUPAX: Multidimensional Problem Agnostic eXplainable AI](https://arxiv.org/abs/2507.13090)
*Vincenzo Dentamaro,Felice Franchini,Giuseppe Pirlo,Irina Voiculescu*

Main category: cs.LG

TL;DR: MUPAX是一种新的可解释AI技术，它通过结构化扰动分析来精确归因特征重要性，并能提高模型准确性。


<details>
  <summary>Details</summary>
Motivation: 开发一种同时满足确定性、模型无关性和收敛性保证的鲁棒的可解释AI技术。

Method: MUPAX是一种确定性的、模型无关的可解释性技术，通过结构化扰动分析发现固有的输入模式并消除虚假关系，从而实现特征重要性归因。

Result: MUPAX在包括音频分类（1D）、图像分类（2D）、医学体积图像分析（3D）和解剖标志物检测在内的广泛数据模式和任务中表现出跨维度有效性。与通常在遮蔽时会降低性能的其他XAI方法不同，MUPAX通过仅捕获原始数据中最重要的模式，不仅保持了模型的准确性，而且实际提高了模型的准确性。

Conclusion: MUPAX是一种可扩展、可解释的AI技术，能够提高模型的准确性，生成精确、一致且易于理解的解释，为可解释和可信赖的AI系统奠定了基础。

Abstract: Robust XAI techniques should ideally be simultaneously deterministic, model
agnostic, and guaranteed to converge. We propose MULTIDIMENSIONAL PROBLEM
AGNOSTIC EXPLAINABLE AI (MUPAX), a deterministic, model agnostic explainability
technique, with guaranteed convergency. MUPAX measure theoretic formulation
gives principled feature importance attribution through structured perturbation
analysis that discovers inherent input patterns and eliminates spurious
relationships. We evaluate MUPAX on an extensive range of data modalities and
tasks: audio classification (1D), image classification (2D), volumetric medical
image analysis (3D), and anatomical landmark detection, demonstrating dimension
agnostic effectiveness. The rigorous convergence guarantees extend to any loss
function and arbitrary dimensions, making MUPAX applicable to virtually any
problem context for AI. By contrast with other XAI methods that typically
decrease performance when masking, MUPAX not only preserves but actually
enhances model accuracy by capturing only the most important patterns of the
original data. Extensive benchmarking against the state of the XAI art
demonstrates MUPAX ability to generate precise, consistent and understandable
explanations, a crucial step towards explainable and trustworthy AI systems.
The source code will be released upon publication.

</details>


### [363] [Uncertainty-Aware Cross-Modal Knowledge Distillation with Prototype Learning for Multimodal Brain-Computer Interfaces](https://arxiv.org/abs/2507.13092)
*Hyo-Jeong Jang,Hye-Bin Shin,Seong-Whan Lee*

Main category: cs.LG

TL;DR: 本文提出了一种新的跨模态知识蒸馏框架，通过对齐特征语义和解决标签不一致性来提高EEG信号的学习能力，解决了现有方法中的模态间隙和软标签错位问题，并在情感识别任务中取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 为了提高EEG信号的学习能力，并解决多模态知识蒸馏中存在的模态间隙和软标签错位问题，该研究旨在解决由模糊特征和定义不清的标签引起的语义不确定性。

Method: 提出了一种新颖的跨模态知识蒸馏框架，通过基于原型的相似性模块对齐特征语义，并引入特定任务的蒸馏头来解决标签引起的不一致性。

Result: 实验结果表明，所提出的方法提高了基于EEG的情感回归和分类性能。

Conclusion: 该框架在公共多模态数据集上提高了基于EEG的情感回归和分类性能，优于单模态和多模态基线。

Abstract: Electroencephalography (EEG) is a fundamental modality for cognitive state
monitoring in brain-computer interfaces (BCIs). However, it is highly
susceptible to intrinsic signal errors and human-induced labeling errors, which
lead to label noise and ultimately degrade model performance. To enhance EEG
learning, multimodal knowledge distillation (KD) has been explored to transfer
knowledge from visual models with rich representations to EEG-based models.
Nevertheless, KD faces two key challenges: modality gap and soft label
misalignment. The former arises from the heterogeneous nature of EEG and visual
feature spaces, while the latter stems from label inconsistencies that create
discrepancies between ground truth labels and distillation targets. This paper
addresses semantic uncertainty caused by ambiguous features and weakly defined
labels. We propose a novel cross-modal knowledge distillation framework that
mitigates both modality and label inconsistencies. It aligns feature semantics
through a prototype-based similarity module and introduces a task-specific
distillation head to resolve label-induced inconsistency in supervision.
Experimental results demonstrate that our approach improves EEG-based emotion
regression and classification performance, outperforming both unimodal and
multimodal baselines on a public multimodal dataset. These findings highlight
the potential of our framework for BCI applications.

</details>


### [364] [NGTM: Substructure-based Neural Graph Topic Model for Interpretable Graph Generation](https://arxiv.org/abs/2507.13133)
*Yuanxin Zhuang,Dazhong Shen,Ying Sun*

Main category: cs.LG

TL;DR: NGTM是一种新的图生成模型，通过将图表示为主题混合体，提高了可解释性，并允许用户控制生成过程。


<details>
  <summary>Details</summary>
Motivation: 现有图生成方法在生成真实图方面取得了成功，但在可解释性方面存在局限，难以理解其结构决策的依据。为了解决这个问题，我们提出了NGTM。

Method: 提出了一种名为神经图主题模型（NGTM）的新型生成框架，该框架借鉴了自然语言处理中的主题建模思想，将图表示为潜在主题的混合体，每个主题定义了有意义的子结构的分布，从而实现了在局部和全局尺度上的显式可解释性。生成过程将主题分布与全局结构变量透明地集成，可以清晰地追溯每个生成图的语义。

Result: 实验结果表明，NGTM在生成质量上具有竞争力，同时能够提供独特的细粒度控制和可解释性。

Conclusion: NGTM在生成高质量图的同时，还能实现精细的控制和可解释性，允许用户通过调整主题级别来定制结构特征或诱导生物特性。

Abstract: Graph generation plays a pivotal role across numerous domains, including
molecular design and knowledge graph construction. Although existing methods
achieve considerable success in generating realistic graphs, their
interpretability remains limited, often obscuring the rationale behind
structural decisions. To address this challenge, we propose the Neural Graph
Topic Model (NGTM), a novel generative framework inspired by topic modeling in
natural language processing. NGTM represents graphs as mixtures of latent
topics, each defining a distribution over semantically meaningful
substructures, which facilitates explicit interpretability at both local and
global scales. The generation process transparently integrates these topic
distributions with a global structural variable, enabling clear semantic
tracing of each generated graph. Experiments demonstrate that NGTM achieves
competitive generation quality while uniquely enabling fine-grained control and
interpretability, allowing users to tune structural features or induce
biological properties through topic-level adjustments.

</details>


### [365] [NonverbalTTS: A Public English Corpus of Text-Aligned Nonverbal Vocalizations with Emotion Annotations for Text-to-Speech](https://arxiv.org/abs/2507.13155)
*Maksim Borisov,Egor Spirin,Daria Diatlova*

Main category: cs.LG

TL;DR: 我们发布了一个名为 NVTTS 的新数据集，其中包含 17 小时的非语言发声（如笑声、咳嗽声）和情感，并附带了一个改进的 TTS 模型，该模型在准确性和保真度方面可与闭源系统相媲美。


<details>
  <summary>Details</summary>
Motivation: 当前富有表现力的语音合成模型受到包含各种非语言发声 (NV) 的开源数据集可用性有限的限制。

Method: 我们提出了一个全面的流水线，集成了自动语音识别 (ASR)、非语言发声 (NV) 标签、情感分类和用于合并多个标注者提供的转录的融合算法。该数据集是通过 VoxCeleb 和 Expresso 来源，使用自动检测后进行人工验证而获得的。

Result: 我们介绍了 NVTTS，这是一个包含 10 种 NV（例如，笑声、咳嗽声）和 8 种情感类别的 17 小时开放访问数据集。通过发布 NVTTS 及其伴随的标注指南，我们解决了富有表现力的 TTS 研究中的一个关键瓶颈。

Conclusion: 通过在 NVTTS 数据集上微调开源 TTS 模型，可以在人类评估和自动指标（包括说话人相似性和非语言发声保真度）方面达到与 CosyVoice2 等闭源系统相当的水平。

Abstract: Current expressive speech synthesis models are constrained by the limited
availability of open-source datasets containing diverse nonverbal vocalizations
(NVs). In this work, we introduce NonverbalTTS (NVTTS), a 17-hour open-access
dataset annotated with 10 types of NVs (e.g., laughter, coughs) and 8 emotional
categories. The dataset is derived from popular sources, VoxCeleb and Expresso,
using automated detection followed by human validation. We propose a
comprehensive pipeline that integrates automatic speech recognition (ASR), NV
tagging, emotion classification, and a fusion algorithm to merge transcriptions
from multiple annotators. Fine-tuning open-source text-to-speech (TTS) models
on the NVTTS dataset achieves parity with closed-source systems such as
CosyVoice2, as measured by both human evaluation and automatic metrics,
including speaker similarity and NV fidelity. By releasing NVTTS and its
accompanying annotation guidelines, we address a key bottleneck in expressive
TTS research. The dataset is available at
https://huggingface.co/datasets/deepvk/NonverbalTTS.

</details>


### [366] [Spectral Bellman Method: Unifying Representation and Exploration in RL](https://arxiv.org/abs/2507.13181)
*Ofir Nabati,Bo Dai,Shie Mannor,Guy Tennenholtz*

Main category: cs.LG

TL;DR: Spectral Bellman Representation aligns feature learning with Bellman updates using a spectral insight, improving RL performance and exploration.


<details>
  <summary>Details</summary>
Motivation: Existing representation learning in reinforcement learning is mainly induced from model learning aspects, which misaligns with the fundamental structure of value-based RL tasks. There is a need for representations that directly align with value-based RL.

Method: This work introduces Spectral Bellman Representation, a novel framework derived from the Inherent Bellman Error (IBE) condition. The key insight is a spectral relationship linking the transformation of value functions by the Bellman operator to the feature covariance structure under the zero-IBE condition. This leads to a new, theoretically-grounded objective for learning state-action features that capture this Bellman-aligned covariance, requiring only a simple modification to existing algorithms.

Result: The learned representations enable structured exploration by aligning feature covariance with Bellman dynamics and improve overall performance, especially in hard-exploration and long-horizon credit assignment tasks. The framework naturally extends to multi-step Bellman operators.

Conclusion: Spectral Bellman Representation provides a principled and effective method for learning powerful and structurally sound representations for value-based reinforcement learning, aligning feature covariance with Bellman dynamics and improving performance on challenging tasks.

Abstract: The effect of representation has been demonstrated in reinforcement learning,
from both theoretical and empirical successes. However, the existing
representation learning mainly induced from model learning aspects, misaligning
with our RL tasks. This work introduces Spectral Bellman Representation, a
novel framework derived from the Inherent Bellman Error (IBE) condition, which
aligns with the fundamental structure of Bellman updates across a space of
possible value functions, therefore, directly towards value-based RL. Our key
insight is the discovery of a fundamental spectral relationship: under the
zero-IBE condition, the transformation of a distribution of value functions by
the Bellman operator is intrinsically linked to the feature covariance
structure. This spectral connection yields a new, theoretically-grounded
objective for learning state-action features that inherently capture this
Bellman-aligned covariance. Our method requires a simple modification to
existing algorithms. We demonstrate that our learned representations enable
structured exploration, by aligning feature covariance with Bellman dynamics,
and improve overall performance, particularly in challenging hard-exploration
and long-horizon credit assignment tasks. Our framework naturally extends to
powerful multi-step Bellman operators, further broadening its impact. Spectral
Bellman Representation offers a principled and effective path toward learning
more powerful and structurally sound representations for value-based
reinforcement learning.

</details>


### [367] [GradNetOT: Learning Optimal Transport Maps with GradNets](https://arxiv.org/abs/2507.13191)
*Shreyas Chaudhari,Srinivasa Pranav,José M. F. Moura*

Main category: cs.LG

TL;DR: Monotone Gradient Networks (mGradNets) are used to directly learn optimal transport maps by minimizing a loss based on the Monge-Ampère equation, showing improved learning and application in robot swarm control.


<details>
  <summary>Details</summary>
Motivation: The central role of monotone gradient functions in solving the Monge formulation of the optimal transport problem, which is relevant in applications like fluid dynamics and robot swarm control. Brenier's theorem guarantees a unique optimal map as the gradient of a convex function (a monotone gradient map) when the transport cost is squared Euclidean distance.

Method: Parameterizing the space of monotone gradient maps directly using Monotone Gradient Networks (mGradNets) and minimizing a training loss function based on the Monge-Ampère equation to learn the optimal transport mapping.

Result: Empirically demonstrating that the structural bias of mGradNets facilitates the learning of optimal transport maps and successfully employing the method for a robot swarm control problem.

Conclusion: Leveraging Monotone Gradient Networks (mGradNets) to directly learn optimal transport maps by minimizing a training loss function defined using the Monge-Ampère equation, and applying this method to a robot swarm control problem.

Abstract: Monotone gradient functions play a central role in solving the Monge
formulation of the optimal transport problem, which arises in modern
applications ranging from fluid dynamics to robot swarm control. When the
transport cost is the squared Euclidean distance, Brenier's theorem guarantees
that the unique optimal map is the gradient of a convex function, namely a
monotone gradient map, and it satisfies a Monge-Amp\`ere equation. In
[arXiv:2301.10862] [arXiv:2404.07361], we proposed Monotone Gradient Networks
(mGradNets), neural networks that directly parameterize the space of monotone
gradient maps. In this work, we leverage mGradNets to directly learn the
optimal transport mapping by minimizing a training loss function defined using
the Monge-Amp\`ere equation. We empirically show that the structural bias of
mGradNets facilitates the learning of optimal transport maps and employ our
method for a robot swarm control problem.

</details>


### [368] [MoTM: Towards a Foundation Model for Time Series Imputation based on Continuous Modeling](https://arxiv.org/abs/2507.13207)
*Etienne Le Naour,Tahar Nabil,Ghislain Agoua*

Main category: cs.LG

TL;DR: MoTM 是时间序列填充领域的一个基础模型，它利用隐式神经表示（INRs）和混合模型来处理跨域的缺失值，并在各种场景下表现出稳健的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 填补时间序列数据中被忽视的、跨域的缺失值填充任务的空白。

Method: 提出了一种利用隐式神经表示（INRs）的方法，INRs 将时间序列建模为连续函数，自然地处理各种缺失数据场景和采样率。为了应对分布变化，引入了 MoTM（Mixture of Timeflow Models），它结合了一个 INR 基础，每个 INR 在独立不同的时间序列家族上进行训练，并结合了一个在推理时适应观测上下文的脊回归器。

Result: MoTM 结合了 INR 基础和脊回归器，在各种时间序列填充场景中展现了稳健的域内和域外泛化能力。

Conclusion: MoTM 证明了其在各种缺失场景（例如，块状和点状缺失、可变采样率）中具有稳健的域内和域外泛化能力，为可适应的、用于时间序列填充的基础模型铺平了道路。

Abstract: Recent years have witnessed a growing interest for time series foundation
models, with a strong emphasis on the forecasting task. Yet, the crucial task
of out-of-domain imputation of missing values remains largely underexplored. We
propose a first step to fill this gap by leveraging implicit neural
representations (INRs). INRs model time series as continuous functions and
naturally handle various missing data scenarios and sampling rates. While they
have shown strong performance within specific distributions, they struggle
under distribution shifts. To address this, we introduce MoTM (Mixture of
Timeflow Models), a step toward a foundation model for time series imputation.
Building on the idea that a new time series is a mixture of previously seen
patterns, MoTM combines a basis of INRs, each trained independently on a
distinct family of time series, with a ridge regressor that adapts to the
observed context at inference. We demonstrate robust in-domain and
out-of-domain generalization across diverse imputation scenarios (e.g., block
and pointwise missingness, variable sampling rates), paving the way for
adaptable foundation imputation models.

</details>


### [369] [Merge Kernel for Bayesian Optimization on Permutation Space](https://arxiv.org/abs/2507.13263)
*Zikai Xie,Linjiang Chen*

Main category: cs.LG

TL;DR: 提出了一种基于排序算法（特别是归并排序）的核函数，用于排列空间的贝叶斯优化，实现了更低的计算复杂度（Θ(n log n)）和更好的性能，优于现有的Mallows核。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Mallows核的排列空间贝叶斯优化方法需要二次方的时间复杂度来枚举所有成对比较。本研究旨在提出一种更高效的替代方法。

Method: 提出了一种新颖的框架，用于在排列空间中生成核函数，该框架基于排序算法。将Mallows核看作是源自冒泡排序的一个特例。引入了基于归并排序的归并核，将复杂度从二次方降低到线性对数时间（Θ(n log n)），并结合了三个附加的描述符（移位直方图、分裂对线、滑动窗口模式）以提高鲁棒性和紧凑性。

Result: 实验评估表明，所提出的归并核在各种排列优化基准测试中，在性能上持续优于现有的Mallows核。归并核提供了更紧凑且更有效的解决方案。

Conclusion: 所提出的基于排序算法的核函数生成框架，特别是基于归并排序的归并核，在排列空间优化中，相比于现有的基于Mallows核的方法，能够提供更紧凑但更有效的解决方案，实现了最低的计算复杂度。

Abstract: Bayesian Optimization (BO) algorithm is a standard tool for black-box
optimization problems. The current state-of-the-art BO approach for permutation
spaces relies on the Mallows kernel-an $\Omega(n^2)$ representation that
explicitly enumerates every pairwise comparison. Inspired by the close
relationship between the Mallows kernel and pairwise comparison, we propose a
novel framework for generating kernel functions on permutation space based on
sorting algorithms. Within this framework, the Mallows kernel can be viewed as
a special instance derived from bubble sort. Further, we introduce the
\textbf{Merge Kernel} constructed from merge sort, which replaces the quadratic
complexity with $\Theta(n\log n)$ to achieve the lowest possible complexity.
The resulting feature vector is significantly shorter, can be computed in
linearithmic time, yet still efficiently captures meaningful permutation
distances. To boost robustness and right-invariance without sacrificing
compactness, we further incorporate three lightweight, task-agnostic
descriptors: (1) a shift histogram, which aggregates absolute element
displacements and supplies a global misplacement signal; (2) a split-pair line,
which encodes selected long-range comparisons by aligning elements across the
two halves of the whole permutation; and (3) sliding-window motifs, which
summarize local order patterns that influence near-neighbor objectives. Our
empirical evaluation demonstrates that the proposed kernel consistently
outperforms the state-of-the-art Mallows kernel across various permutation
optimization benchmarks. Results confirm that the Merge Kernel provides a more
compact yet more effective solution for Bayesian optimization in permutation
space.

</details>


### [370] [Boosting Team Modeling through Tempo-Relational Representation Learning](https://arxiv.org/abs/2507.13305)
*Vincenzo Marco De Luca,Giovanna Varni,Andrea Passerini*

Main category: cs.LG

TL;DR: 提出TRENN和MT-TRENN模型，用于联合建模团队的时序和关系动态，同时预测多个团队因素（如领导力），并提供可解释性，以提升团队表现，尤其适用于人本AI应用。


<details>
  <summary>Details</summary>
Motivation: 现有的团队建模方法未能满足实际应用对统一模型、多因素同时推断、可解释性和可操作性建议的需求。本研究旨在弥合这一差距，通过整合时序和关系动态来改进团队建模。

Method: 提出了一种新颖的 tempo-relational 架构 TRENN，该架构整合了自动时序图提取器、tempo-relational 编码器、用于团队构建预测的解码器以及两个互补的可解释性模块。在此基础上，提出了 MT-TRENN，通过将解码器替换为多任务头，实现了共享社交嵌入的学习，并能同时预测多个团队构建因素。

Result: TRENN模型及其多任务扩展MT-TRENN在实验中显著优于仅依赖时序或关系信息的模型。MT-TRENN的可解释性模块提供了可解释的见解和可操作的建议，支持团队改进。

Conclusion: TRENN模型及其多任务扩展MT-TRENN在团队建模领域取得了显著成果，能够同时预测领导力风格、突现领导力和团队合作等多个团队构建因素，并通过可解释性模块提供可操作的建议以提升团队表现。实验结果表明，该模型在利用时序和关系信息方面优于仅依赖单一信息的模型，特别适用于以人为本的AI应用，如高风险协作环境中的智能决策支持系统。

Abstract: Team modeling remains a fundamental challenge at the intersection of
Artificial Intelligence and the Social Sciences. Social Science research
emphasizes the need to jointly model dynamics and relations, while practical
applications demand unified models capable of inferring multiple team
constructs simultaneously, providing interpretable insights and actionable
recommendations to enhance team performance. However, existing works do not
meet these practical demands. To bridge this gap, we present TRENN, a novel
tempo-relational architecture that integrates: (i) an automatic temporal graph
extractor, (ii) a tempo-relational encoder, (iii) a decoder for team construct
prediction, and (iv) two complementary explainability modules. TRENN jointly
captures relational and temporal team dynamics, providing a solid foundation
for MT-TRENN, which extends TReNN by replacing the decoder with a multi-task
head, enabling the model to learn shared Social Embeddings and simultaneously
predict multiple team constructs, including Emergent Leadership, Leadership
Style, and Teamwork components. Experimental results demonstrate that our
approach significantly outperforms approaches that rely exclusively on temporal
or relational information. Additionally, experimental evaluation has shown that
the explainability modules integrated in MT-TRENN yield interpretable insights
and actionable suggestions to support team improvement. These capabilities make
our approach particularly well-suited for Human-Centered AI applications, such
as intelligent decision-support systems in high-stakes collaborative
environments.

</details>


### [371] [GeoReg: Weight-Constrained Few-Shot Regression for Socio-Economic Estimation using LLM](https://arxiv.org/abs/2507.13323)
*Kyeongjin Ahn,Sungwon Han,Seungeon Lee,Donghyun Ahn,Hyoshin Kim,Jungwon Kim,Jihee Kim,Sangyoon Park,Meeyoung Cha*

Main category: cs.LG

TL;DR: GeoReg利用LLM从卫星图像和网络数据中提取特征，用于估算发展中国家（尤其是数据稀缺地区）的GDP、人口和教育等社会经济指标，并在实验中取得了优于基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 社会经济指标（如地区GDP、人口和教育水平）对于制定政策和促进可持续发展至关重要。然而，在数据稀缺的地区，如发展中国家，准确估算这些指标是一个挑战。

Method: GeoReg是一个回归模型，它整合了包括卫星图像和网络地理空间信息在内的多种数据源，并利用大型语言模型（LLM）提取特征，以处理数据稀缺地区（如发展中国家）的指标估算问题。LLM作为数据工程师，提取信息特征以支持少样本学习。模型获取数据特征与目标指标之间的上下文关系，并将相关性分为正相关、负相关、混合或不相关。这些特征随后被输入到具有为每个类别量身定制的权重约束的线性估计器中。为了捕捉非线性模式，模型还识别有意义的特征交互作用，并将它们与非线性变换相结合。

Result: 实验结果表明，GeoReg模型在估算社会经济指标方面，即使在数据稀疏的低收入国家，也优于现有基线模型。

Conclusion: GeoReg模型在不同发展阶段的国家中对社会经济指标的估算优于基线模型，尤其在低收入国家数据稀疏的情况下表现更佳。

Abstract: Socio-economic indicators like regional GDP, population, and education
levels, are crucial to shaping policy decisions and fostering sustainable
development. This research introduces GeoReg a regression model that integrates
diverse data sources, including satellite imagery and web-based geospatial
information, to estimate these indicators even for data-scarce regions such as
developing countries. Our approach leverages the prior knowledge of large
language model (LLM) to address the scarcity of labeled data, with the LLM
functioning as a data engineer by extracting informative features to enable
effective estimation in few-shot settings. Specifically, our model obtains
contextual relationships between data features and the target indicator,
categorizing their correlations as positive, negative, mixed, or irrelevant.
These features are then fed into the linear estimator with tailored weight
constraints for each category. To capture nonlinear patterns, the model also
identifies meaningful feature interactions and integrates them, along with
nonlinear transformations. Experiments across three countries at different
stages of development demonstrate that our model outperforms baselines in
estimating socio-economic indicators, even for low-income countries with
limited data availability.

</details>


### [372] [Training Transformers with Enforced Lipschitz Constants](https://arxiv.org/abs/2507.13338)
*Laker Newhouse,R. Preston Hess,Franz Cesista,Andrii Zahorodnii,Jeremy Bernstein,Phillip Isola*

Main category: cs.LG

TL;DR: 研究人员开发了一种在训练过程中保持 Lipschitz 界限的方法，并成功应用于 Transformer 模型。通过优化器选择和新的权重约束方法，在某些情况下实现了更好的性能与 Lipschitz 界限的权衡。尽管在大型模型上仍面临挑战，但该方法无需额外的稳定性措施即可实现训练。


<details>
  <summary>Details</summary>
Motivation: 神经网络对输入和权重扰动高度敏感，这与对抗性样本、训练发散和过拟合等问题相关。过去的研究尝试构建完全由 Lipschitz 组件组成的神经网络，但未能实现对现代架构（如 Transformer）在初始化后强制执行 Lipschitz 证书。

Method: 开发并测试了在训练过程中保持范数约束权重矩阵的新型、计算效率高的方法。在此基础上，训练了具有全程 Lipschitz 界限的 Transformer 模型，并探索了优化器动态、权重衰减、谱归一化以及一种新的权重约束方法对 Lipschitz 界限与模型性能的权衡。

Result: 研究发现，优化器动态（如使用 Muon 替代 AdamW）能够改善权重衰减和谱归一化等传统方法，使得模型在较低的 Lipschitz 界限下达到同等性能。此外，一种新设计的权重约束方法在 MLP 和 Transformer 模型上改善了 Lipschitz 界限与性能的权衡。具体而言，一个 Shakespeare 文本上的 2-Lipschitz Transformer 达到了 60% 的验证准确率。在扩展到 145M 参数时，一个 10-Lipschitz Transformer 在互联网文本上达到了 21% 的准确率。然而，为了匹配 NanoGPT 基线的 39.4% 验证准确率，其 Lipschitz 上限增加到了 10^264。值得注意的是，所提出的 Lipschitz Transformer 在没有层归一化、QK 归一化和 logit tanh softcapping 等稳定性措施的情况下，也能够成功训练。

Conclusion: 本研究开发并测试了在训练过程中保持范数约束权重矩阵的新型、计算效率高的方法，并成功地训练了具有全程 Lipschitz 界限的 Transformer 模型。研究发现，优化器动态（如使用 Muon 替代 AdamW）能改善传统方法（如权重衰减和谱归一化），从而在较低的 Lipschitz 界限下达到同等性能。

Abstract: Neural networks are often highly sensitive to input and weight perturbations.
This sensitivity has been linked to pathologies such as vulnerability to
adversarial examples, divergent training, and overfitting. To combat these
problems, past research has looked at building neural networks entirely from
Lipschitz components. However, these techniques have not matured to the point
where researchers have trained a modern architecture such as a transformer with
a Lipschitz certificate enforced beyond initialization. To explore this gap, we
begin by developing and benchmarking novel, computationally-efficient tools for
maintaining norm-constrained weight matrices. Applying these tools, we are able
to train transformer models with Lipschitz bounds enforced throughout training.
We find that optimizer dynamics matter: switching from AdamW to Muon improves
standard methods -- weight decay and spectral normalization -- allowing models
to reach equal performance with a lower Lipschitz bound. Inspired by Muon's
update having a fixed spectral norm, we co-design a weight constraint method
that improves the Lipschitz vs. performance tradeoff on MLPs and 2M parameter
transformers. Our 2-Lipschitz transformer on Shakespeare text reaches
validation accuracy 60%. Scaling to 145M parameters, our 10-Lipschitz
transformer reaches 21% accuracy on internet text. However, to match the
NanoGPT baseline validation accuracy of 39.4%, our Lipschitz upper bound
increases to 10^264. Nonetheless, our Lipschitz transformers train without
stability measures such as layer norm, QK norm, and logit tanh softcapping.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [373] [Building State Machine Replication Using Practical Network Synchrony](https://arxiv.org/abs/2507.12792)
*Yiliang Wan,Nitin Shivaraman,Akshaye Shenoi,Xiang Liu,Tao Luo,Jialin Li*

Main category: cs.DC

TL;DR: 本研究提出了一种在数据中心环境中利用强同步性的新方法，并设计了一个名为Chora的新复制协议，显著提高了吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现代数据中心系统可以在常见情况下提供强同步属性，即服务器以同步锁步方式运行。

Method: 通过结合内核旁路网络、多线程架构和放宽轮次长度，工程化设计实现了2微秒以下的紧密轮次界限。

Result: Chora协议实现了比现有单领导者和多领导者协议分别高255%和109%的吞吐量。

Conclusion: Chora协议利用网络同步特性，实现了比现有单领导者和多领导者协议更高的吞吐量，分别提高了255%和109%。

Abstract: Distributed systems, such as state machine replication, are critical
infrastructures for modern applications. Practical distributed protocols make
minimum assumptions about the underlying network: They typically assume a
partially synchronous or fully asynchronous network model. In this work, we
argue that modern data center systems can be designed to provide strong
synchrony properties in the common case, where servers move in synchronous
lock-step rounds. We prove this hypothesis by engineering a practical design
that uses a combination of kernel-bypass network, multithreaded architecture,
and loosened round length, achieving a tight round bound under 2us. Leveraging
our engineered networks with strong synchrony, we co-design a new replication
protocol, Chora. Chora exploits the network synchrony property to efficiently
pipeline multiple replication instances, while allowing all replicas to propose
in parallel without extra coordination. Through experiments, we show that Chora
achieves 255% and 109% improvement in throughput over state-of-the-art
single-leader and multi-leader protocols, respectively.

</details>


### [374] [Autonomous Resource Management in Microservice Systems via Reinforcement Learning](https://arxiv.org/abs/2507.12879)
*Yujun Zou,Nia Qi,Yingnan Deng,Zhihao Xue,Ming Gong,Wuyang Zhang*

Main category: cs.DC

TL;DR: 本文提出一种基于强化学习的微服务资源调度优化方法，通过智能调度算法优化资源分配，实验证明该方法能有效提高系统性能并降低能耗，且具备良好的适应性和优化能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统微服务架构中存在的资源分配不均、延迟高、吞吐量不足等问题。

Method: 本文采用一种基于强化学习的方法进行微服务资源调度与优化。

Result: 实验结果表明，该方法在低负载和高并发条件下显著提高了系统响应速度和吞吐量，同时优化了资源利用率并降低了能耗。

Conclusion: 该方法在低负载和高并发条件下显著提高了系统响应速度和吞吐量，同时优化了资源利用率并降低了能耗。在多维资源条件下，该方法能够兼顾多个目标，实现优化的资源调度。与传统的静态资源分配方法相比，强化学习模型具有更强的适应性和优化能力，能够实时调整资源分配策略，从而在动态变化的负载和资源环境下保持良好的系统性能。

Abstract: This paper proposes a reinforcement learning-based method for microservice
resource scheduling and optimization, aiming to address issues such as uneven
resource allocation, high latency, and insufficient throughput in traditional
microservice architectures. In microservice systems, as the number of services
and the load increase, efficiently scheduling and allocating resources such as
computing power, memory, and storage becomes a critical research challenge. To
address this, the paper employs an intelligent scheduling algorithm based on
reinforcement learning. Through the interaction between the agent and the
environment, the resource allocation strategy is continuously optimized. In the
experiments, the paper considers different resource conditions and load
scenarios, evaluating the proposed method across multiple dimensions, including
response time, throughput, resource utilization, and cost efficiency. The
experimental results show that the reinforcement learning-based scheduling
method significantly improves system response speed and throughput under low
load and high concurrency conditions, while also optimizing resource
utilization and reducing energy consumption. Under multi-dimensional resource
conditions, the proposed method can consider multiple objectives and achieve
optimized resource scheduling. Compared to traditional static resource
allocation methods, the reinforcement learning model demonstrates stronger
adaptability and optimization capability. It can adjust resource allocation
strategies in real time, thereby maintaining good system performance in
dynamically changing load and resource environments.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [375] [WaFusion: A Wavelet-Enhanced Diffusion Framework for Face Morph Generation](https://arxiv.org/abs/2507.12493)
*Seyed Rasoul Hosseini,Omid Ahmadieh,Jeremy Dawson,Nasser Nasrabadi*

Main category: cs.GR

TL;DR: WaFusion 利用小波分解和扩散模型生成逼真的面部融合图像，克服了面部融合对身份验证系统的挑战，并在实验中表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 生物特征面部融合对身份验证系统构成了严峻的挑战，破坏了其安全性和鲁棒性。因此，需要一种有效的方法来生成逼真的面部融合图像，以测试和改进这些系统。

Method: WaFusion 框架结合了小波变换捕获的结构细节和扩散模型的生成能力，以生成具有最少伪影的高质量、逼真的面部融合图像。

Result: 在 FERET、FRGC、FRLL 和 WVU Twin 数据集上进行的实验表明，WaFusion 在生成高分辨率、具有更少伪影的面部融合图像方面优于最先进的方法，并在 APCER、BPCER 和 EER 等关键生物特征指标上表现出色。

Conclusion: WaFusion 提出了一种新颖的框架，结合了小波分解和扩散模型，用于高效生成高质量、逼真的面部融合图像，为生物特征识别系统提供了一个先进且高效的解决方案，以应对面部融合带来的挑战，并在多个生物特征指标上优于现有方法。

Abstract: Biometric face morphing poses a critical challenge to identity verification
systems, undermining their security and robustness. To address this issue, we
propose WaFusion, a novel framework combining wavelet decomposition and
diffusion models to generate high-quality, realistic morphed face images
efficiently. WaFusion leverages the structural details captured by wavelet
transforms and the generative capabilities of diffusion models, producing face
morphs with minimal artifacts. Experiments conducted on FERET, FRGC, FRLL, and
WVU Twin datasets demonstrate WaFusion's superiority over state-of-the-art
methods, producing high-resolution morphs with fewer artifacts. Our framework
excels across key biometric metrics, including the Attack Presentation
Classification Error Rate (APCER), Bona Fide Presentation Classification Error
Rate (BPCER), and Equal Error Rate (EER). This work sets a new benchmark in
biometric morph generation, offering a cutting-edge and efficient solution to
enhance biometric security systems.

</details>


### [376] [Wavelet-GS: 3D Gaussian Splatting with Wavelet Decomposition](https://arxiv.org/abs/2507.12498)
*Beizhen Zhao,Yifan Zhou,Sicheng Yu,Zijian Wang,Hao Wang*

Main category: cs.GR

TL;DR: 本研究提出了一种改进的3D高斯泼溅方法，通过3D和小波分解来处理复杂场景，解决了现有方法在结构完整性和光照效果上的不足，并在实验中取得了领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS方法在处理复杂场景时存在整体结构不完整和局部光照效果不清晰的问题。为了解决这些挑战，本研究提出了一种新的方法。

Method: 本研究提出了一种新颖的解耦优化框架，该框架将小波分解技术集成到3D高斯泼溅（3DGS）和2D采样中。具体来说，通过3D小波分解将点云划分为高频和低频分量，并分别进行优化。低频分量通过体素化来捕获全局结构轮廓并控制高斯分布。高频分量则用于恢复精细的几何和纹理细节，并引入重光照模块来解决光照伪影问题并提升照片级真实感。此外，还对训练图像进行2D小波分解以模拟辐射度变化，从而指导高频细节重建，确保细节与全局结构的融合。

Result: 实验结果表明，本研究提出的方法在具有挑战性的数据集上取得了最先进的性能，在各项指标上均超越了现有方法，并推动了3D场景重建领域的发展。

Conclusion: 现有的3DGS方法在复杂场景重建中面临挑战，例如整体结构不完整和局部光照效果不清晰。本研究提出的解耦优化框架通过3D小波分解将点云分为高频和低频分量，并针对每个分量进行优化。低频分量通过体素化捕捉全局结构轮廓并管理高斯分布，高频分量则恢复几何和纹理细节，并结合重光照模块减轻光照伪影，增强照片级真实感渲染。此外，通过对训练图像进行2D小波分解来模拟辐射度变化，为高频细节重建提供关键指导，确保细节与全局结构的无缝集成。实验结果表明，该方法在各项指标上均优于现有方法，推动了3D场景重建领域的发展。

Abstract: 3D Gaussian Splatting (3DGS) has revolutionized 3D scene reconstruction,
which effectively balances rendering quality, efficiency, and speed. However,
existing 3DGS approaches usually generate plausible outputs and face
significant challenges in complex scene reconstruction, manifesting as
incomplete holistic structural outlines and unclear local lighting effects. To
address these issues simultaneously, we propose a novel decoupled optimization
framework, which integrates wavelet decomposition into 3D Gaussian Splatting
and 2D sampling. Technically, through 3D wavelet decomposition, our approach
divides point clouds into high-frequency and low-frequency components, enabling
targeted optimization for each. The low-frequency component captures global
structural outlines and manages the distribution of Gaussians through
voxelization. In contrast, the high-frequency component restores intricate
geometric and textural details while incorporating a relight module to mitigate
lighting artifacts and enhance photorealistic rendering. Additionally, a 2D
wavelet decomposition is applied to the training images, simulating radiance
variations. This provides critical guidance for high-frequency detail
reconstruction, ensuring seamless integration of details with the global
structure. Extensive experiments on challenging datasets demonstrate our method
achieves state-of-the-art performance across various metrics, surpassing
existing approaches and advancing the field of 3D scene reconstruction.

</details>


### [377] [HairFormer: Transformer-Based Dynamic Neural Hair Simulation](https://arxiv.org/abs/2507.12600)
*Joy Xiaoji Zhang,Jingsen Zhu,Hanyu Chen,Steve Marschner*

Main category: cs.GR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Simulating hair dynamics that generalize across arbitrary hairstyles, body
shapes, and motions is a critical challenge. Our novel two-stage neural
solution is the first to leverage Transformer-based architectures for such a
broad generalization. We propose a Transformer-powered static network that
predicts static draped shapes for any hairstyle, effectively resolving
hair-body penetrations and preserving hair fidelity. Subsequently, a dynamic
network with a novel cross-attention mechanism fuses static hair features with
kinematic input to generate expressive dynamics and complex secondary motions.
This dynamic network also allows for efficient fine-tuning of challenging
motion sequences, such as abrupt head movements. Our method offers real-time
inference for both static single-frame drapes and dynamic drapes over pose
sequences. Our method demonstrates high-fidelity and generalizable dynamic hair
across various styles, guided by physics-informed losses, and can resolve
penetrations even for complex, unseen long hairstyles, highlighting its broad
generalization.

</details>


### [378] [VolSegGS: Segmentation and Tracking in Dynamic Volumetric Scenes via Deformable 3D Gaussians](https://arxiv.org/abs/2507.12667)
*Siyuan Yao,Chaoli Wang*

Main category: cs.GR

TL;DR: 提出VolSegGS，一种用于动态体积场景的交互式分割和跟踪的3D高斯方法，可在低计算需求下实现实时探索性可视化。


<details>
  <summary>Details</summary>
Motivation: 现有的视图合成技术（如神经辐射场）在体积场景重建方面表现出色，但缺乏交互式可视化探索（如特征提取和跟踪）的能力。需要一种能够在本地低端机器上进行有效可视化，并支持交互式分割和跟踪的框架。

Method: VolSegGS框架利用可变形3D高斯来表示动态体积场景，实现实时新视图合成。通过视图无关颜色进行粗分割，并利用亲和场网络进行细分割。通过将分割结果嵌入高斯中，确保变形能够实现分割区域的连续跟踪。

Result: 在多个时变数据集上证明了VolSegGS的有效性，并与最先进的方法进行了比较，证明了其在低计算需求下的交互式分割和跟踪能力。

Conclusion: VolSegGS框架为时变体积数据的交互式分割和跟踪提供了强大的解决方案，在低计算需求下实现了实时交互和灵活的分割跟踪能力，为时变体积数据分析和可视化开辟了新的可能性。

Abstract: Visualization of large-scale time-dependent simulation data is crucial for
domain scientists to analyze complex phenomena, but it demands significant I/O
bandwidth, storage, and computational resources. To enable effective
visualization on local, low-end machines, recent advances in view synthesis
techniques, such as neural radiance fields, utilize neural networks to generate
novel visualizations for volumetric scenes. However, these methods focus on
reconstruction quality rather than facilitating interactive visualization
exploration, such as feature extraction and tracking. We introduce VolSegGS, a
novel Gaussian splatting framework that supports interactive segmentation and
tracking in dynamic volumetric scenes for exploratory visualization and
analysis. Our approach utilizes deformable 3D Gaussians to represent a dynamic
volumetric scene, allowing for real-time novel view synthesis. For accurate
segmentation, we leverage the view-independent colors of Gaussians for
coarse-level segmentation and refine the results with an affinity field network
for fine-level segmentation. Additionally, by embedding segmentation results
within the Gaussians, we ensure that their deformation enables continuous
tracking of segmented regions over time. We demonstrate the effectiveness of
VolSegGS with several time-varying datasets and compare our solutions against
state-of-the-art methods. With the ability to interact with a dynamic scene in
real time and provide flexible segmentation and tracking capabilities, VolSegGS
offers a powerful solution under low computational demands. This framework
unlocks exciting new possibilities for time-varying volumetric data analysis
and visualization.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [379] [Modular SAIL: dream or reality?](https://arxiv.org/abs/2507.12471)
*Petr Kourzanov,Anmol*

Main category: cs.AR

TL;DR: Modular SAIL enables compositionality in the RISC-V golden model's emulator, making it pluggable and maintaining functional equivalence with the original monolithic emulator.


<details>
  <summary>Details</summary>
Motivation: To address the issue of compositionality in the RISC-V development flow, extending beyond the specification level to include emulation, simulation, and verification, in order to truly benefit from RISC-V ISA modularity.

Method: Introduced modular SAIL, an experiment to inject compositionality into the SAIL-RISCV golden model, and conducted a comparative study of the pluggable emulator's performance using static and dynamic binding.

Result: The pluggable emulator exhibited the same functional behavior as the original monolithic emulator (RISC-V ISS), with performance comparable between static and dynamic binding.

Conclusion: The SAIL-RISCV golden model can be adapted to support modules at the emulator level, demonstrating the feasibility of injecting compositionality beyond the specification level.

Abstract: In order to truly benefit from RISC-V ISA modularity, the community has to
address the issue of compositionality, going beyond modules at the
specification level covering larger subsets of the RISC-V development flow
including emulation, simulation and verification. In this paper we introduce
modular SAIL, an experiment to inject compositionality into the SAIL-RISCV
golden model. We show that it is, in principle, not difficult to adapt the
SAIL-RISCV flow (and ideally the SAIL compiler itself) to support modules at
the emulator level. We back our findings by a comparative study of the
resulting pluggable emulator's performance using both static and dynamic
binding, which both exhibit same functional behavior as the original monolithic
emulator (aka RISC-V ISS).

</details>


### [380] [An ultra-low-power CGRA for accelerating Transformers at the edge](https://arxiv.org/abs/2507.12904)
*Rohit Prasad*

Main category: cs.AR

TL;DR: 提出一种低功耗CGRA架构，加速Transformer模型的GEMM运算，适用于边缘设备。


<details>
  <summary>Details</summary>
Motivation: Transformer模型因其在自然语言处理和计算机视觉等领域的革命性应用而受到广泛关注，但其高昂的计算成本限制了它们在低功耗边缘设备上的部署。因此，需要一种专门的硬件架构来解决这一挑战。

Method: 提出了一种超低功耗、粗粒度可重构阵列（CGRA）架构，专门用于加速Transformer模型中的通用矩阵乘法（GEMM）运算。该架构集成了4x4的处理单元（PE）阵列和专用的4x2内存操作块（MOB），并采用无开关的网状环通互连网络。

Result: 该CGRA架构通过优化的PE和MOB集成、高效的互连网络以及对GEMM运算的专门加速，显著降低了Transformer模型在边缘设备的功耗和延迟，提高了数据重用率，并为部署复杂模型提供了可扩展的解决方案。

Conclusion: 该CGRA架构通过异构阵列设计和高效数据流解决了Transformer的计算需求，为在边缘设备上部署复杂的机器学习模型提供了可扩展的途径。

Abstract: Transformers have revolutionized deep learning with applications in natural
language processing, computer vision, and beyond. However, their computational
demands make it challenging to deploy them on low-power edge devices. This
paper introduces an ultra-low-power, Coarse-Grained Reconfigurable Array (CGRA)
architecture specifically designed to accelerate General Matrix Multiplication
(GEMM) operations in transformer models tailored for the energy and resource
constraints of edge applications. The proposed architecture integrates a 4 x 4
array of Processing Elements (PEs) for efficient parallel computation and
dedicated 4 x 2 Memory Operation Blocks (MOBs) for optimized LOAD/STORE
operations, reducing memory bandwidth demands and enhancing data reuse. A
switchless mesh torus interconnect network further minimizes power and latency
by enabling direct communication between PEs and MOBs, eliminating the need for
centralized switching. Through its heterogeneous array design and efficient
dataflow, this CGRA architecture addresses the unique computational needs of
transformers, offering a scalable pathway to deploy sophisticated machine
learning models on edge devices.

</details>


### [381] [WIP: Turning Fake Chips into Learning Opportunities](https://arxiv.org/abs/2507.13281)
*Haniye Mehraban,Saad Azmeen-ur-Rahman,John Hu*

Main category: cs.AR

TL;DR: Counterfeit chips found in a class became a learning tool, teaching students about circuits and security through hands-on diagnostics.


<details>
  <summary>Details</summary>
Motivation: Counterfeit integrated circuits (ICs) are a growing problem that threatens the integrity of undergraduate electronics laboratories. This paper demonstrates how a counterfeit component issue was leveraged as a teaching opportunity to enhance student learning.

Method: This paper presents a case study involving counterfeit TL074 operational amplifiers. The counterfeit components were used as a basis for hands-on learning, where students engaged in diagnostics such as measuring current, analyzing waveforms, and troubleshooting.

Result: Students gained practical experience in diagnostics and troubleshooting by working with counterfeit components. This led to a deeper understanding of analog circuits, the importance of supply chain security, and practical engineering skills.

Conclusion: The counterfeit TL074 operational amplifiers found in a junior-level electronics course were successfully transformed into a valuable hands-on learning experience, providing students with deeper insights into analog circuits, supply chain security, and practical engineering.

Abstract: This work-in-progress paper presents a case study in which counterfeit TL074
operational amplifiers, discovered in a junior level electronics course, became
the basis for a hands on learning experience. Counterfeit integrated circuits
(IC) are increasingly common, posing a significant threat to the integrity of
undergraduate electronics laboratories. Instead of simply replacing the
counterfeit components, we turned the issue into a teaching moment. Students
engaged in hands-on diagnostics measuring current, analyzing waveforms, and
troubleshooting. By working with fake chip components, they gained deeper
insight into analog circuits, supply chain security, and practical engineering.

</details>
