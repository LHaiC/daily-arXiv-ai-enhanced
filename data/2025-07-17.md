<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 86]
- [cs.CL](#cs.CL) [Total: 49]
- [cs.MA](#cs.MA) [Total: 3]
- [physics.app-ph](#physics.app-ph) [Total: 2]
- [cs.SI](#cs.SI) [Total: 3]
- [cond-mat.soft](#cond-mat.soft) [Total: 1]
- [cs.RO](#cs.RO) [Total: 24]
- [cs.AI](#cs.AI) [Total: 13]
- [cs.DC](#cs.DC) [Total: 12]
- [cs.ET](#cs.ET) [Total: 1]
- [cs.AR](#cs.AR) [Total: 4]
- [quant-ph](#quant-ph) [Total: 50]
- [cs.LG](#cs.LG) [Total: 71]
- [cs.GT](#cs.GT) [Total: 3]
- [cs.GR](#cs.GR) [Total: 6]
- [cs.DS](#cs.DS) [Total: 6]
- [eess.IV](#eess.IV) [Total: 3]
- [cs.HC](#cs.HC) [Total: 1]
- [eess.SP](#eess.SP) [Total: 15]
- [eess.SY](#eess.SY) [Total: 14]
- [cs.LO](#cs.LO) [Total: 5]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 10]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 15]
- [cs.NE](#cs.NE) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [An Memory-Efficient Framework for Deformable Transformer with Neural Architecture Search](https://arxiv.org/abs/2507.11549)
*Wendong Mao,Mingfan Zhao,Jianfeng Guan,Qiwei Dong,Zhongfeng Wang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Deformable Attention Transformers (DAT) have shown remarkable performance in
computer vision tasks by adaptively focusing on informative image regions.
However, their data-dependent sampling mechanism introduces irregular memory
access patterns, posing significant challenges for efficient hardware
deployment. Existing acceleration methods either incur high hardware overhead
or compromise model accuracy. To address these issues, this paper proposes a
hardware-friendly optimization framework for DAT. First, a neural architecture
search (NAS)-based method with a new slicing strategy is proposed to
automatically divide the input feature into uniform patches during the
inference process, avoiding memory conflicts without modifying model
architecture. The method explores the optimal slice configuration by jointly
optimizing hardware cost and inference accuracy. Secondly, an FPGA-based
verification system is designed to test the performance of this framework on
edge-side hardware. Algorithm experiments on the ImageNet-1K dataset
demonstrate that our hardware-friendly framework can maintain have only 0.2%
accuracy drop compared to the baseline DAT. Hardware experiments on Xilinx FPGA
show the proposed method reduces DRAM access times to 18% compared with
existing DAT acceleration methods.

</details>


### [2] [Deformable Dynamic Convolution for Accurate yet Efficient Spatio-Temporal Traffic Prediction](https://arxiv.org/abs/2507.11550)
*Hyeonseok Jin,Geonmin Kim,Kyungbaek Kim*

Main category: cs.CV

TL;DR: DDCN是一种基于CNN的新型模型，通过可变形卷积和注意力机制，在准确性和效率方面优于现有方法，能够解决交通预测中的异质性和可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有图神经网络（GNN）在交通预测中需要预定义邻接矩阵、难以捕捉区域和时间段变化的交通模式异质性以及在处理大规模数据时存在的可扩展性限制等问题。

Method: 提出了一种称为Deformable Dynamic Convolution Network (DDCN)的模型。该模型采用类似Transformer的CNN编码器-解码器结构，并通过动态应用基于偏移量的可变形滤波器来解决传统CNN在建模非欧几里得空间结构和时空异质性方面的局限性。DDCN通过在编码器的空间和时空注意力模块中应用提出的方法来强调重要特征，并使用前馈模块的解码器来补充编码器的输出。

Result: DDCN在四个真实世界数据集上的实验结果具有竞争力，证明了其在准确性和效率方面的优势。

Conclusion: DDCN在四个真实世界数据集上的综合实验表明，它具有竞争力，强调了基于CNN的方法在时空交通预测中的潜力和有效性。

Abstract: Spatio-temporal traffic prediction plays a key role in intelligent
transportation systems by enabling accurate prediction in complex urban areas.
Although not only accuracy but also efficiency for scalability is important,
some previous methods struggle to capture heterogeneity such as varying traffic
patterns across regions and time periods. Moreover, Graph Neural Networks
(GNNs), which are the mainstream of traffic prediction, not only require
predefined adjacency matrix, but also limit scalability to large-scale data
containing many nodes due to their inherent complexity. To overcome these
limitations, we propose Deformable Dynamic Convolution Network (DDCN) for
accurate yet efficient traffic prediction. Traditional Convolutional Neural
Networks (CNNs) are limited in modeling non-Euclidean spatial structures and
spatio-temporal heterogeneity, DDCN overcomes these challenges by dynamically
applying deformable filters based on offset. Specifically, DDCN decomposes
transformer-style CNN to encoder-decoder structure, and applies proposed
approaches to the spatial and spatio-temporal attention blocks of the encoder
to emphasize important features. The decoder, composed of feed-forward module,
complements the output of the encoder. This novel structure make DDCN can
perform accurate yet efficient traffic prediction. In comprehensive experiments
on four real-world datasets, DDCN achieves competitive performance, emphasizing
the potential and effectiveness of CNN-based approaches for spatio-temporal
traffic prediction.

</details>


### [3] [Inversion-DPO: Precise and Efficient Post-Training for Diffusion Models](https://arxiv.org/abs/2507.11554)
*Zejian Li,Yize Li,Chenye Meng,Zhongni Liu,Yang Ling,Shengyuan Zhang,Guang Yang,Changyuan Yang,Zhiyuan Yang,Lingyun Sun*

Main category: cs.CV

TL;DR: Inversion-DPO 是一种新颖的扩散模型对齐框架，通过结合 DPO 和 DDIM 反演，无需奖励模型即可实现高效精确的对齐，并在图像生成任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有对齐方法需要计算密集型的基础模型和奖励模型训练，以及可能影响模型准确性和训练效率的限制。

Method: Inversion-DPO 框架，它将 DPO 与 DDIM 反演相结合，通过确定性反演将获胜和失败样本转换为噪声，从而进行后验采样。

Result: Inversion-DPO 在文本到图像生成和组合图像生成任务上取得了显著的性能提升，能够生成高保真度和组合一致性的图像。

Conclusion: Inversion-DPO 提出了一种新颖的对齐框架，通过将 DPO 与 DDIM 反演相结合，消除了对奖励建模的需求，从而实现了更高效、更精确的对齐。

Abstract: Recent advancements in diffusion models (DMs) have been propelled by
alignment methods that post-train models to better conform to human
preferences. However, these approaches typically require computation-intensive
training of a base model and a reward model, which not only incurs substantial
computational overhead but may also compromise model accuracy and training
efficiency. To address these limitations, we propose Inversion-DPO, a novel
alignment framework that circumvents reward modeling by reformulating Direct
Preference Optimization (DPO) with DDIM inversion for DMs. Our method conducts
intractable posterior sampling in Diffusion-DPO with the deterministic
inversion from winning and losing samples to noise and thus derive a new
post-training paradigm. This paradigm eliminates the need for auxiliary reward
models or inaccurate appromixation, significantly enhancing both precision and
efficiency of training. We apply Inversion-DPO to a basic task of text-to-image
generation and a challenging task of compositional image generation. Extensive
experiments show substantial performance improvements achieved by Inversion-DPO
compared to existing post-training methods and highlight the ability of the
trained generative models to generate high-fidelity compositionally coherent
images. For the post-training of compostitional image geneation, we curate a
paired dataset consisting of 11,140 images with complex structural annotations
and comprehensive scores, designed to enhance the compositional capabilities of
generative models. Inversion-DPO explores a new avenue for efficient,
high-precision alignment in diffusion models, advancing their applicability to
complex realistic generation tasks. Our code is available at
https://github.com/MIGHTYEZ/Inversion-DPO

</details>


### [4] [Reprogramming Vision Foundation Models for Spatio-Temporal Forecasting](https://arxiv.org/abs/2507.11558)
*Changlu Chen,Yanbin Liu,Chaoxi Niu,Ling Chen,Tianqing Zhu*

Main category: cs.CV

TL;DR: 该论文提出了 ST-VFM，一个用于时空预测的框架，它通过双分支架构和专门的重编程阶段来适配视觉基础模型（VFMs），解决了 VFMs 在时间建模和模态差距方面的挑战。实验证明 ST-VFM 在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 虽然大型语言模型（LLMs）在时间序列预测方面取得了进展，但它们主要捕捉一维序列依赖关系，难以模拟准确的时空预测所必需的更丰富的时空（ST）相关性。视觉基础模型（VFMs）提供了强大的空间先验，但在应用于 ST 任务时存在两个关键挑战：(1) 缺乏固有的时间建模能力和 (2) 视觉与 ST 数据之间的模态差距。因此，有必要开发一种能够有效利用 VFMs 进行时空预测的框架。

Method: ST-VFM 采用一种双分支架构，集成了原始 ST 输入和辅助 ST 流输入，其中流编码了轻量级的时间差信号，可解释为动态空间线索。为了有效地处理这些双分支输入，ST-VFM 引入了两个专门的重编程阶段：预 VFM 重编程阶段应用时间感知令牌适配器来嵌入时间上下文并将两个分支对齐到 VFM 兼容的特征空间；后 VFM 重编程阶段引入双边交叉提示协调模块，通过基于提示的条件动态地实现分支之间的交互，从而在不修改冻结的 VFM 主干的情况下丰富联合表示学习。

Result: ST-VFM 在十个时空数据集上进行了广泛的实验，结果显示其优于最先进的基线，在 VFM 主干（例如 DINO、CLIP、DEIT）上表现出有效性和鲁棒性，并通过了验证性分析。

Conclusion: ST-VFM 是一个新颖的框架，它系统地重新编程视觉基础模型（VFMs）用于通用的时空预测，并在十个时空数据集上取得了优于最先进基线的效果，证明了其在 VFM 主干（例如 DINO、CLIP、DEIT）上的有效性和鲁棒性，并进行了相关的验证性分析，确立了其作为时空预测的强大通用框架的地位。

Abstract: Foundation models have achieved remarkable success in natural language
processing and computer vision, demonstrating strong capabilities in modeling
complex patterns. While recent efforts have explored adapting large language
models (LLMs) for time-series forecasting, LLMs primarily capture
one-dimensional sequential dependencies and struggle to model the richer
spatio-temporal (ST) correlations essential for accurate ST forecasting. In
this paper, we present \textbf{ST-VFM}, a novel framework that systematically
reprograms Vision Foundation Models (VFMs) for general-purpose spatio-temporal
forecasting. While VFMs offer powerful spatial priors, two key challenges arise
when applying them to ST tasks: (1) the lack of inherent temporal modeling
capacity and (2) the modality gap between visual and ST data. To address these,
ST-VFM adopts a \emph{dual-branch architecture} that integrates raw ST inputs
with auxiliary ST flow inputs, where the flow encodes lightweight temporal
difference signals interpretable as dynamic spatial cues. To effectively
process these dual-branch inputs, ST-VFM introduces two dedicated reprogramming
stages. The \emph{pre-VFM reprogramming} stage applies a Temporal-Aware Token
Adapter to embed temporal context and align both branches into VFM-compatible
feature spaces. The \emph{post-VFM reprogramming} stage introduces a Bilateral
Cross-Prompt Coordination module, enabling dynamic interaction between branches
through prompt-based conditioning, thus enriching joint representation learning
without modifying the frozen VFM backbone. Extensive experiments on ten
spatio-temporal datasets show that ST-VFM outperforms state-of-the-art
baselines, demonstrating effectiveness and robustness across VFM backbones
(e.g., DINO, CLIP, DEIT) and ablation studies, establishing it as a strong
general framework for spatio-temporal forecasting.

</details>


### [5] [Expert Operational GANS: Towards Real-Color Underwater Image Restoration](https://arxiv.org/abs/2507.11562)
*Ozer Can Devecioglu,Serkan Kiranyaz,Mehmet Yamac,Moncef Gabbouj*

Main category: cs.CV

TL;DR: xOp-GAN 是一种包含多个专家生成器的新型 GAN 模型，可解决水下图像恢复中的异构域问题，并在 LSUI 数据集上取得了优于现有模型的性能。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统 GAN 模型难以处理异构域中广泛的图像退化问题，因为单一生成器网络不足以捕捉全部视觉退化。

Method: 提出了一种名为 xOp-GAN 的新型 GAN 模型，该模型包含多个专家生成器网络，每个网络专门针对特定图像质量子集进行训练。在训练完成后，每个生成器都可以恢复输入图像，然后由判别器根据其感知置信度分数选择最佳恢复图像。

Result: xOp-GAN 能够实现高达 25.16 dB 的 PSNR，超越了所有单一回归模型，并且复杂度更低。

Conclusion: xOp-GAN 在 LSUI 数据集上实现了高达 25.16 dB 的 PSNR，超越了所有单一回归模型，并且复杂度更低。

Abstract: The wide range of deformation artifacts that arise from complex light
propagation, scattering, and depth-dependent attenuation makes the underwater
image restoration to remain a challenging problem. Like other single deep
regressor networks, conventional GAN-based restoration methods struggle to
perform well across this heterogeneous domain, since a single generator network
is typically insufficient to capture the full range of visual degradations. In
order to overcome this limitation, we propose xOp-GAN, a novel GAN model with
several expert generator networks, each trained solely on a particular subset
with a certain image quality. Thus, each generator can learn to maximize its
restoration performance for a particular quality range. Once a xOp-GAN is
trained, each generator can restore the input image and the best restored image
can then be selected by the discriminator based on its perceptual confidence
score. As a result, xOP-GAN is the first GAN model with multiple generators
where the discriminator is being used during the inference of the regression
task. Experimental results on benchmark Large Scale Underwater Image (LSUI)
dataset demonstrates that xOp-GAN achieves PSNR levels up to 25.16 dB,
surpassing all single-regressor models by a large margin even, with reduced
complexity.

</details>


### [6] [Data-Driven Meta-Analysis and Public-Dataset Evaluation for Sensor-Based Gait Age Estimation](https://arxiv.org/abs/2507.11571)
*Varun Velankar*

Main category: cs.CV

TL;DR: 本研究通过元分析和实验，为从步态估计年龄提供了性能基线和实用指南，旨在将真实世界场景中的年龄估计误差降低到三年以下。


<details>
  <summary>Details</summary>
Motivation: 从步态估计一个人的年龄在医疗保健、安全和人机交互方面具有重要的应用价值。

Method: 本研究首先对涉及视频、可穿戴设备和雷达传感器记录的七万五千多名受试者的五十九项研究进行了回顾，然后分析了 OU-ISIR 大规模人口数据集中六万三千八百四十六个步态周期，量化了年龄与步长、步行速度、步频、步长时间变异性和关节角度熵这五个关键指标之间的相关性。最后，研究对 VersatileGait 数据库的十万个样本子集进行了支持向量机、决策树、随机森林、多层感知器和卷积神经网络的比较。

Result: 卷积神经网络的平均误差约为 4.2 年，惯性传感器模型的平均误差约为 4.5 年，而多传感器融合的误差低至 3.4 年，并且在实验室和真实世界数据之间存在显著差异。研究发现，所提出的模型能够达到高达 96% 的准确率，同时处理每个样本的时间不到 0.1 秒。

Conclusion: 本研究结合了广泛的元分析和新进行的、大规模的实验以及可解释的可视化，建立了可靠的性能基线，并为在真实世界场景中将步态年龄误差减少到三年以下提供了实用的指导。

Abstract: Estimating a person's age from their gait has important applications in
healthcare, security and human-computer interaction. In this work, we review
fifty-nine studies involving over seventy-five thousand subjects recorded with
video, wearable and radar sensors. We observe that convolutional neural
networks produce an average error of about 4.2 years, inertial-sensor models
about 4.5 years and multi-sensor fusion as low as 3.4 years, with notable
differences between lab and real-world data. We then analyse sixty-three
thousand eight hundred forty-six gait cycles from the OU-ISIR Large-Population
dataset to quantify correlations between age and five key metrics: stride
length, walking speed, step cadence, step-time variability and joint-angle
entropy, with correlation coefficients of at least 0.27. Next, we fine-tune a
ResNet34 model and apply Grad-CAM to reveal that the network attends to the
knee and pelvic regions, consistent with known age-related gait changes.
Finally, on a one hundred thousand sample subset of the VersatileGait database,
we compare support vector machines, decision trees, random forests, multilayer
perceptrons and convolutional neural networks, finding that deep networks
achieve up to 96 percent accuracy while processing each sample in under 0.1
seconds. By combining a broad meta-analysis with new large-scale experiments
and interpretable visualizations, we establish solid performance baselines and
practical guidelines for reducing gait-age error below three years in
real-world scenarios.

</details>


### [7] [What cat is that? A re-id model for feral cats](https://arxiv.org/abs/2507.11575)
*Victor Caquilpan*

Main category: cs.CV

TL;DR: 野猫对澳大利亚野生动物构成威胁，本研究使用改进的PPGNet模型（PPGNet-Cat）通过摄像头陷阱图像识别野猫，实现了高精度识别。


<details>
  <summary>Details</summary>
Motivation: 由于野猫对澳大利亚野生动物构成重大且有害的影响，因此对其进行密切监测对于减轻其影响至关重要。本研究旨在探索计算机视觉方法，以提高对这些动物的监测能力。

Method: 本研究修改了用于阿穆尔虎重新识别的部分姿势引导网络（PPGNet）模型，以创建一个能够识别野外单独野猫的重新识别模型，并进行了包括对比学习方法（如ArcFace损失）在内的各种实验。

Result: PPGNet-Cat在识别野猫方面表现出色，平均精度均值（mAP）为0.86，排名第一的准确率为0.95。

Conclusion: PPGNet-Cat在野外识别猫方面表现出色，在重新识别领域具有竞争力。

Abstract: Feral cats exert a substantial and detrimental impact on Australian wildlife,
placing them among the most dangerous invasive species worldwide. Therefore,
closely monitoring these cats is essential labour in minimising their effects.
In this context, the potential application of Re-Identification (re-ID) emerges
to enhance monitoring activities for these animals, utilising images captured
by camera traps. This project explores different CV approaches to create a
re-ID model able to identify individual feral cats in the wild. The main
approach consists of modifying a part-pose guided network (PPGNet) model,
initially used in the re-ID of Amur tigers, to be applicable for feral cats.
This adaptation, resulting in PPGNet-Cat, which incorporates specific
modifications to suit the characteristics of feral cats images. Additionally,
various experiments were conducted, particularly exploring contrastive learning
approaches such as ArcFace loss. The main results indicate that PPGNet-Cat
excels in identifying feral cats, achieving high performance with a mean
Average Precision (mAP) of 0.86 and a rank-1 accuracy of 0.95. These outcomes
establish PPGNet-Cat as a competitive model within the realm of re-ID.

</details>


### [8] [SketchDNN: Joint Continuous-Discrete Diffusion for CAD Sketch Generation](https://arxiv.org/abs/2507.11579)
*Sathvik Chereddy,John Femiani*

Main category: cs.CV

TL;DR: SketchDNN是一种新的生成模型，通过高斯-softmax扩散联合处理连续和离散变量，解决了CAD草图中的异质性和排列不变性问题，并在SketchGraphs数据集上取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 解决CAD草图生成的两个关键挑战：原始参数化的异质性和原始的排列不变性。

Method: 提出了一种名为高斯-softmax扩散的新型生成模型，该模型通过统一的连续-离散扩散过程联合建模连续参数和离散类标签。

Result: FID从16.04降低到7.80，NLL从84.8降低到81.33，显著提高了生成质量。

Conclusion: SketchDNN在SketchGraphs数据集上在CAD草图生成方面树立了新的标杆。

Abstract: We present SketchDNN, a generative model for synthesizing CAD sketches that
jointly models both continuous parameters and discrete class labels through a
unified continuous-discrete diffusion process. Our core innovation is
Gaussian-Softmax diffusion, where logits perturbed with Gaussian noise are
projected onto the probability simplex via a softmax transformation,
facilitating blended class labels for discrete variables. This formulation
addresses 2 key challenges, namely, the heterogeneity of primitive
parameterizations and the permutation invariance of primitives in CAD sketches.
Our approach significantly improves generation quality, reducing Fr\'echet
Inception Distance (FID) from 16.04 to 7.80 and negative log-likelihood (NLL)
from 84.8 to 81.33, establishing a new state-of-the-art in CAD sketch
generation on the SketchGraphs dataset.

</details>


### [9] [Interpretable Prediction of Lymph Node Metastasis in Rectal Cancer MRI Using Variational Autoencoders](https://arxiv.org/abs/2507.11638)
*Benjamin Keel,Aaron Quyn,David Jayne,Maryam Mohsin,Samuel D. Relton*

Main category: cs.CV

TL;DR: 该研究使用变分自编码器（VAE）替代卷积神经网络（CNN）来提高直肠癌淋巴结转移的MRI诊断准确性，提出的VAE-MLP模型在168名患者的数据集上取得了0.86的AUC，证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了提高基于淋巴结（LN）的大小、形状和纹理形态的放射学标准在淋巴结转移（LNM）分期中的诊断准确性，特别是利用VAE作为特征编码器，因为其生成模型旨在重建图像，能够直接编码有意义的视觉特征和模式，从而产生比CNN更具可解释性的、解缠结的、结构化的潜在空间。

Method: 提出了一种基于变分自编码器（VAE）的特征编码模型，以替代现有的基于大容量预训练卷积神经网络（CNN）的方法，用于直肠癌淋巴结转移（LNM）的放射学分期。

Result: 在包含168名未接受新辅助治疗的患者的内部MRI数据集上，VAE-MLP模型达到了最先进的性能，交叉验证的评估指标包括AUC 0.86 +/- 0.05，敏感性0.79 +/- 0.06，特异性0.85 +/- 0.05。

Conclusion: 该研究提出的VAE-MLP模型在直肠癌淋巴结转移的MRI诊断方面取得了最先进的性能，AUC达到0.86 +/- 0.05，显示出其在临床应用中的潜力。

Abstract: Effective treatment for rectal cancer relies on accurate lymph node
metastasis (LNM) staging. However, radiological criteria based on lymph node
(LN) size, shape and texture morphology have limited diagnostic accuracy. In
this work, we investigate applying a Variational Autoencoder (VAE) as a feature
encoder model to replace the large pre-trained Convolutional Neural Network
(CNN) used in existing approaches. The motivation for using a VAE is that the
generative model aims to reconstruct the images, so it directly encodes visual
features and meaningful patterns across the data. This leads to a disentangled
and structured latent space which can be more interpretable than a CNN. Models
are deployed on an in-house MRI dataset with 168 patients who did not undergo
neo-adjuvant treatment. The post-operative pathological N stage was used as the
ground truth to evaluate model predictions. Our proposed model 'VAE-MLP'
achieved state-of-the-art performance on the MRI dataset, with cross-validated
metrics of AUC 0.86 +/- 0.05, Sensitivity 0.79 +/- 0.06, and Specificity 0.85
+/- 0.05. Code is available at:
https://github.com/benkeel/Lymph_Node_Classification_MIUA.

</details>


### [10] [Posture-Driven Action Intent Inference for Playing style and Fatigue Assessment](https://arxiv.org/abs/2507.11642)
*Abhishek Jaiswal,Nisheeth Srivastava*

Main category: cs.CV

TL;DR: 本研究提出了一种基于姿势的方法，通过分析运动来识别板球比赛中的人类意图，并在区分攻击性和防御性射门方面取得了很高的准确率。


<details>
  <summary>Details</summary>
Motivation: 姿势可以用于推断心理状态，例如疲劳和运动损伤，但由于对人类受试者数据的敏感性，这种视觉诊断面临着挑战。为了解决这个问题，研究人员在板球比赛中收集数据，以测试他们关于姿势可以作为可行替代方案的假设，以积累来自经历各种情绪状态的人类受试者的数据。

Method: 本研究提出了一种基于姿势的解决方案，通过动作分析来识别人类意图，并通过现有数据统计作为弱监督来验证我们的发现。

Result: 在区分攻击性和防御性射门意图方面，我们的方法实现了超过 75% 的 F1 分数和超过 80% 的 AUC-ROC。

Conclusion: 本研究表明，姿势可以提供强大的意图推断信号，即使在数据管道存在固有噪声的情况下也是如此。此外，我们利用现有的数据统计作为弱监督来验证我们的发现，为克服数据标记限制提供了潜在的解决方案。这项研究有助于运动分析的通用技术，并为跨不同领域的行为分析开辟了可能性。

Abstract: Posture-based mental state inference has significant potential in diagnosing
fatigue, preventing injury, and enhancing performance across various domains.
Such tools must be research-validated with large datasets before being
translated into practice. Unfortunately, such vision diagnosis faces serious
challenges due to the sensitivity of human subject data. To address this, we
identify sports settings as a viable alternative for accumulating data from
human subjects experiencing diverse emotional states. We test our hypothesis in
the game of cricket and present a posture-based solution to identify human
intent from activity videos. Our method achieves over 75\% F1 score and over
80\% AUC-ROC in discriminating aggressive and defensive shot intent through
motion analysis. These findings indicate that posture leaks out strong signals
for intent inference, even with inherent noise in the data pipeline.
Furthermore, we utilize existing data statistics as weak supervision to
validate our findings, offering a potential solution for overcoming data
labelling limitations. This research contributes to generalizable techniques
for sports analytics and also opens possibilities for applying human behavior
analysis across various fields.

</details>


### [11] [VISTA: Monocular Segmentation-Based Mapping for Appearance and View-Invariant Global Localization](https://arxiv.org/abs/2507.11653)
*Hannah Shafferman,Annika Thomas,Jouko Kinnari,Michael Ricard,Jose Nino,Jonathan How*

Main category: cs.CV

TL;DR: VISTA 是一种新的全局定位框架，通过基于对象的分割和跟踪以及子图对应搜索来解决非结构化环境中的定位挑战。它在各种条件下都能实现一致的定位，并在性能和内存使用方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 全局定位对于自主导航至关重要，尤其是在代理必须在由不同会话或另一个代理生成的地图中进行定位的情况下，因为代理通常不知道参考系之间的相关性。然而，由于传统场景识别方法的已知失效模式（如视点变化、季节变化、空间混淆和遮挡）引起的视觉变化，在非结构化环境中执行此任务仍然具有挑战性。

Method: VISTA (View-Invariant Segmentation-Based Tracking for Frame Alignment) 是一个新颖的、开放集、单目的全局定位框架。它结合了：1) 一个前端、基于对象的分割和跟踪流程，以及 2) 一个子图对应搜索，利用环境地图之间的几何一致性来对齐车辆坐标系。

Result: VISTA 在季节性和斜角航空数据集上进行了评估，其召回率比基线方法提高了 69%。此外，VISTA 维护了一个紧凑的、仅包含 0.6% 内存的基于对象的地图，使其能够在资源受限的平台上进行实时实现。

Conclusion: VISTA 框架能够在不同的摄像头视角和季节变化中实现一致的定位，并且不需要任何特定领域的训练或微调。在季节性和斜角航空数据集上进行评估，其召回率比基线方法提高了 69%。此外，VISTA 维护了一个紧凑的、仅包含 0.6% 内存的基于对象的地图，使其能够在资源受限的平台上进行实时实现。

Abstract: Global localization is critical for autonomous navigation, particularly in
scenarios where an agent must localize within a map generated in a different
session or by another agent, as agents often have no prior knowledge about the
correlation between reference frames. However, this task remains challenging in
unstructured environments due to appearance changes induced by viewpoint
variation, seasonal changes, spatial aliasing, and occlusions -- known failure
modes for traditional place recognition methods. To address these challenges,
we propose VISTA (View-Invariant Segmentation-Based Tracking for Frame
Alignment), a novel open-set, monocular global localization framework that
combines: 1) a front-end, object-based, segmentation and tracking pipeline,
followed by 2) a submap correspondence search, which exploits geometric
consistencies between environment maps to align vehicle reference frames. VISTA
enables consistent localization across diverse camera viewpoints and seasonal
changes, without requiring any domain-specific training or finetuning. We
evaluate VISTA on seasonal and oblique-angle aerial datasets, achieving up to a
69% improvement in recall over baseline methods. Furthermore, we maintain a
compact object-based map that is only 0.6% the size of the most
memory-conservative baseline, making our approach capable of real-time
implementation on resource-constrained platforms.

</details>


### [12] [Seeing the Signs: A Survey of Edge-Deployable OCR Models for Billboard Visibility Analysis](https://arxiv.org/abs/2507.11730)
*Maciej Szankin,Vidhyananth Venkatasamy,Lihang Ying*

Main category: cs.CV

TL;DR: 本研究对VLM和CNN在户外广告文本识别方面的性能进行了基准测试，发现在计算成本和性能之间存在权衡。


<details>
  <summary>Details</summary>
Motivation: 准确验证户外广告牌文本可见性仍然是一个挑战，因为传统的OCR方法在复杂户外场景、多变字体和天气引起的视觉噪声方面存在不足。因此，需要探索像VLM这样更有效的替代方案。

Method: 对精选的VLM（包括Qwen 2.5 VL 3B、InternVL3和SmolVLM2）与紧凑型CNN（PaddleOCRv4）在两个公共数据集（ICDAR 2015和SVT）上进行了基准测试，并通过添加合成天气失真来模拟真实世界的退化。

Result: 所选的VLM在整体场景推理方面表现出色，但轻量级CNN管道在裁剪文本识别方面仍然具有竞争力，计算成本却低得多，这对于边缘部署而言是一个重要的考量因素。

Conclusion: 轻量级CNN管道在计算成本的一小部分即可实现裁剪文本的竞争力，这对于边缘部署来说是一个重要的考虑因素。

Abstract: Outdoor advertisements remain a critical medium for modern marketing, yet
accurately verifying billboard text visibility under real-world conditions is
still challenging. Traditional Optical Character Recognition (OCR) pipelines
excel at cropped text recognition but often struggle with complex outdoor
scenes, varying fonts, and weather-induced visual noise. Recently, multimodal
Vision-Language Models (VLMs) have emerged as promising alternatives, offering
end-to-end scene understanding with no explicit detection step. This work
systematically benchmarks representative VLMs - including Qwen 2.5 VL 3B,
InternVL3, and SmolVLM2 - against a compact CNN-based OCR baseline
(PaddleOCRv4) across two public datasets (ICDAR 2015 and SVT), augmented with
synthetic weather distortions to simulate realistic degradation. Our results
reveal that while selected VLMs excel at holistic scene reasoning, lightweight
CNN pipelines still achieve competitive accuracy for cropped text at a fraction
of the computational cost-an important consideration for edge deployment. To
foster future research, we release our weather-augmented benchmark and
evaluation code publicly.

</details>


### [13] [Beyond Task-Specific Reasoning: A Unified Conditional Generative Framework for Abstract Visual Reasoning](https://arxiv.org/abs/2507.11761)
*Fan Shi,Bin Li,Xiangyang Xue*

Main category: cs.CV

TL;DR: 提出了一种名为UCGS的统一条件生成模型，它能在一个框架内解决多个抽象视觉推理任务，并能在未见过的新任务上实现零样本推理，克服了现有方法需要针对不同任务进行额外训练的缺点。


<details>
  <summary>Details</summary>
Motivation: 当前的深度AVR求解器通常需要针对不同任务进行特定设计或参数调整，导致解决新任务时需要重新训练甚至调整模型架构，增加了成本。本研究旨在开发一种统一的框架，以应对这一挑战。

Method: 提出了一种统一的条件生成模型（UCGS），将抽象视觉推理任务（AVR）重新表述为估计问题面板中目标图像的可预测性。通过训练一个条件生成模型，该模型能够在一个统一的框架内解决多个AVR任务。

Result: UCGS在单一轮次的多任务训练后，能够跨越多个AVR任务展现抽象推理能力。特别地，UCGS表现出零样本推理的能力，可以在测试阶段处理未见过的AVR任务。

Conclusion: 该研究提出了一个统一的条件生成模型（UCGS），旨在通过单一框架解决多个抽象视觉推理任务。UCGS通过将AVR任务重新表述为估计问题面板中目标图像的可预测性，并训练一个条件生成模型来处理不同任务，展示了跨任务的抽象推理能力，甚至在未见过的AVR任务上也能实现零样本推理。

Abstract: Abstract visual reasoning (AVR) enables humans to quickly discover and
generalize abstract rules to new scenarios. Designing intelligent systems with
human-like AVR abilities has been a long-standing topic in the artificial
intelligence community. Deep AVR solvers have recently achieved remarkable
success in various AVR tasks. However, they usually use task-specific designs
or parameters in different tasks. In such a paradigm, solving new tasks often
means retraining the model, and sometimes retuning the model architectures,
which increases the cost of solving AVR problems. In contrast to task-specific
approaches, this paper proposes a novel Unified Conditional Generative Solver
(UCGS), aiming to address multiple AVR tasks in a unified framework. First, we
prove that some well-known AVR tasks can be reformulated as the problem of
estimating the predictability of target images in problem panels. Then, we
illustrate that, under the proposed framework, training one conditional
generative model can solve various AVR tasks. The experiments show that with a
single round of multi-task training, UCGS demonstrates abstract reasoning
ability across various AVR tasks. Especially, UCGS exhibits the ability of
zero-shot reasoning, enabling it to perform abstract reasoning on problems from
unseen AVR tasks in the testing phase.

</details>


### [14] [CorrMoE: Mixture of Experts with De-stylization Learning for Cross-Scene and Cross-Domain Correspondence Pruning](https://arxiv.org/abs/2507.11834)
*Peiwen Xia,Tangfei Liao,Wei Zhu,Danhuai Zhao,Jianjun Ke,Kaihao Zhang,Tong Lu,Tao Wang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Establishing reliable correspondences between image pairs is a fundamental
task in computer vision, underpinning applications such as 3D reconstruction
and visual localization. Although recent methods have made progress in pruning
outliers from dense correspondence sets, they often hypothesize consistent
visual domains and overlook the challenges posed by diverse scene structures.
In this paper, we propose CorrMoE, a novel correspondence pruning framework
that enhances robustness under cross-domain and cross-scene variations. To
address domain shift, we introduce a De-stylization Dual Branch, performing
style mixing on both implicit and explicit graph features to mitigate the
adverse influence of domain-specific representations. For scene diversity, we
design a Bi-Fusion Mixture of Experts module that adaptively integrates
multi-perspective features through linear-complexity attention and dynamic
expert routing. Extensive experiments on benchmark datasets demonstrate that
CorrMoE achieves superior accuracy and generalization compared to
state-of-the-art methods. The code and pre-trained models are available at
https://github.com/peiwenxia/CorrMoE.

</details>


### [15] [ProtoConNet: Prototypical Augmentation and Alignment for Open-Set Few-Shot Image Classification](https://arxiv.org/abs/2507.11845)
*Kexuan Shi,Zhuang Qi,Jingjing Zhu,Lei Meng,Yaochen Zhang,Haibei Huang,Xiangxu Meng*

Main category: cs.CV

TL;DR: ProtoConNet通过整合背景上下文信息和原型对齐，提升了开放集少样本图像分类的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖单一图像的视觉信息来区分已知和未知类别，但忽略了整合丰富的上下文信息所带来的优势。

Method: 本文提出了一种原型增强与对齐方法（ProtoConNet），包括基于聚类的类别选择（CDS）模块、基于上下文的语义细化（CSR）模块和原型对齐（PA）模块，以整合不同样本的背景信息，丰富特征空间，打破上下文与图像主体的虚假关联，并缩小图像表示与类别原型之间的差距。

Result: 实验结果表明，ProtoConNet在少样本场景下增强了表示学习的有效性，并能识别开放集样本，其性能优于现有方法。

Conclusion: 所提出的ProtoConNet方法通过结合背景信息和原型对齐，有效提升了开放集少样本图像分类的性能，优于现有方法。

Abstract: Open-set few-shot image classification aims to train models using a small
amount of labeled data, enabling them to achieve good generalization when
confronted with unknown environments. Existing methods mainly use visual
information from a single image to learn class representations to distinguish
known from unknown categories. However, these methods often overlook the
benefits of integrating rich contextual information. To address this issue,
this paper proposes a prototypical augmentation and alignment method, termed
ProtoConNet, which incorporates background information from different samples
to enhance the diversity of the feature space, breaking the spurious
associations between context and image subjects in few-shot scenarios.
Specifically, it consists of three main modules: the clustering-based data
selection (CDS) module mines diverse data patterns while preserving core
features; the contextual-enhanced semantic refinement (CSR) module builds a
context dictionary to integrate into image representations, which boosts the
model's robustness in various scenarios; and the prototypical alignment (PA)
module reduces the gap between image representations and class prototypes,
amplifying feature distances for known and unknown classes. Experimental
results from two datasets verified that ProtoConNet enhances the effectiveness
of representation learning in few-shot scenarios and identifies open-set
samples, making it superior to existing methods.

</details>


### [16] [From Coarse to Nuanced: Cross-Modal Alignment of Fine-Grained Linguistic Cues and Visual Salient Regions for Dynamic Emotion Recognition](https://arxiv.org/abs/2507.11892)
*Yu Liu,Leyuan Qu,Hanlei Shi,Di Gao,Yuhua Zheng,Taihao Li*

Main category: cs.CV

TL;DR: GRACE通过集成动态运动建模、文本精炼和跨模态对齐来改进面部表情识别，解决了现有方法在利用文本线索和过滤无关面部动态方面的局限性，并在基准测试中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的基于视觉语言的方法在利用生成文本中蕴含的细微情感线索以及过滤掉与情感表达无关的面部动态方面存在不足。

Method: GRACE通过结合动态运动建模、语义文本精炼和令牌级跨模态对齐来整合，以促进情感线索的时空特征的精确定位。该方法通过粗细粒度情感文本增强（CATE）模块构建情感感知的文本描述，并通过运动差异加权机制突出与表情相关的人脸运动。这些精炼的语义和视觉信号通过熵正则化最优传输在令牌级别进行对齐。

Result: GRACE在三个基准数据集上显著提高了识别性能，特别是在具有模糊或不平衡情感类别的挑战性环境中，在UAR和WAR方面均创下了新的最先进（SOTA）成果。

Conclusion: GRACE在三个基准数据集上显著提高了识别性能，特别是在具有模糊或不平衡情感类别的挑战性环境中，在UAR和WAR方面均创下了新的最先进（SOTA）成果。

Abstract: Dynamic Facial Expression Recognition (DFER) aims to identify human emotions
from temporally evolving facial movements and plays a critical role in
affective computing. While recent vision-language approaches have introduced
semantic textual descriptions to guide expression recognition, existing methods
still face two key limitations: they often underutilize the subtle emotional
cues embedded in generated text, and they have yet to incorporate sufficiently
effective mechanisms for filtering out facial dynamics that are irrelevant to
emotional expression. To address these gaps, We propose GRACE, Granular
Representation Alignment for Cross-modal Emotion recognition that integrates
dynamic motion modeling, semantic text refinement, and token-level cross-modal
alignment to facilitate the precise localization of emotionally salient
spatiotemporal features. Our method constructs emotion-aware textual
descriptions via a Coarse-to-fine Affective Text Enhancement (CATE) module and
highlights expression-relevant facial motion through a motion-difference
weighting mechanism. These refined semantic and visual signals are aligned at
the token level using entropy-regularized optimal transport. Experiments on
three benchmark datasets demonstrate that our method significantly improves
recognition performance, particularly in challenging settings with ambiguous or
imbalanced emotion classes, establishing new state-of-the-art (SOTA) results in
terms of both UAR and WAR.

</details>


### [17] [Spatial Frequency Modulation for Semantic Segmentation](https://arxiv.org/abs/2507.11893)
*Linwei Chen,Ying Fu,Lin Gu,Dezhi Zheng,Jifeng Dai*

Main category: cs.CV

TL;DR: SFM是一种通过调制和解调高频特征来提高深度学习模型（尤其是语义分割）准确性的新方法，能有效保留图像细节。


<details>
  <summary>Details</summary>
Motivation: 解决在深度学习模型（特别是卷积神经网络和Transformer）的下采样层中，高空间频率信息（如纹理细节）容易因奈奎斯特定理而产生混叠或失真的问题，从而提高语义分割等任务的准确性。

Method: 提出了一种新颖的空间频率调制（SFM）方法，通过自适应重采样（ARS）将高频特征调制到较低频率，以避免下采样过程中的混叠失真；并通过多尺度自适应上采样（MSAU）在恢复高频信息时利用多尺度信息交互。

Result: SFM成功缓解了混叠问题，并在上采样后成功恢复了高频细节。该方法已被验证可扩展到图像分类、对抗鲁棒性、实例分割和全景分割等任务。

Conclusion: SFM通过自适应重采样（ARS）和多尺度自适应上采样（MSAU）有效缓解了混叠问题，成功保留了高频细节，并广泛应用于多种分割和识别任务，展示了其有效性和通用性。

Abstract: High spatial frequency information, including fine details like textures,
significantly contributes to the accuracy of semantic segmentation. However,
according to the Nyquist-Shannon Sampling Theorem, high-frequency components
are vulnerable to aliasing or distortion when propagating through downsampling
layers such as strided-convolution. Here, we propose a novel Spatial Frequency
Modulation (SFM) that modulates high-frequency features to a lower frequency
before downsampling and then demodulates them back during upsampling.
Specifically, we implement modulation through adaptive resampling (ARS) and
design a lightweight add-on that can densely sample the high-frequency areas to
scale up the signal, thereby lowering its frequency in accordance with the
Frequency Scaling Property. We also propose Multi-Scale Adaptive Upsampling
(MSAU) to demodulate the modulated feature and recover high-frequency
information through non-uniform upsampling This module further improves
segmentation by explicitly exploiting information interaction between densely
and sparsely resampled areas at multiple scales. Both modules can seamlessly
integrate with various architectures, extending from convolutional neural
networks to transformers. Feature visualization and analysis confirm that our
method effectively alleviates aliasing while successfully retaining details
after demodulation. Finally, we validate the broad applicability and
effectiveness of SFM by extending it to image classification, adversarial
robustness, instance segmentation, and panoptic segmentation tasks. The code is
available at
\href{https://github.com/Linwei-Chen/SFM}{https://github.com/Linwei-Chen/SFM}.

</details>


### [18] [SEPose: A Synthetic Event-based Human Pose Estimation Dataset for Pedestrian Monitoring](https://arxiv.org/abs/2507.11910)
*Kaustav Chanda,Aayush Atul Verma,Arpitsinh Vaghela,Yezhou Yang,Bharatesh Chakravarthi*

Main category: cs.CV

TL;DR: SEPose is a synthetic dataset for event-based human pose estimation, useful for traffic and pedestrian monitoring, showing good sim-to-real transfer.


<details>
  <summary>Details</summary>
Motivation: Addresses the limited availability of event-based human pose estimation data for challenging pedestrian and traffic monitoring conditions, despite the promise of event-based sensors in such scenarios.

Method: Generated a synthetic event-based dataset (SEPose) using the CARLA simulator with dynamic vision sensors, featuring ~350K annotated pedestrians with body pose keypoints from fixed camera perspectives across diverse scenarios. Trained and evaluated state-of-the-art models (RVT, YOLOv8) on this dataset and real event-based data.

Result: Trained existing state-of-the-art models on SEPose and evaluated them on real event-based data, demonstrating the dataset's effectiveness for sim-to-real generalization.

Conclusion: The SEPose dataset enables training and evaluation of event-based human pose estimation models, demonstrating strong sim-to-real generalization capabilities.

Abstract: Event-based sensors have emerged as a promising solution for addressing
challenging conditions in pedestrian and traffic monitoring systems. Their
low-latency and high dynamic range allow for improved response time in
safety-critical situations caused by distracted walking or other unusual
movements. However, the availability of data covering such scenarios remains
limited. To address this gap, we present SEPose -- a comprehensive synthetic
event-based human pose estimation dataset for fixed pedestrian perception
generated using dynamic vision sensors in the CARLA simulator. With nearly 350K
annotated pedestrians with body pose keypoints from the perspective of fixed
traffic cameras, SEPose is a comprehensive synthetic multi-person pose
estimation dataset that spans busy and light crowds and traffic across diverse
lighting and weather conditions in 4-way intersections in urban, suburban, and
rural environments. We train existing state-of-the-art models such as RVT and
YOLOv8 on our dataset and evaluate them on real event-based data to demonstrate
the sim-to-real generalization capabilities of the proposed dataset.

</details>


### [19] [Dark-EvGS: Event Camera as an Eye for Radiance Field in the Dark](https://arxiv.org/abs/2507.11931)
*Jingqian Wu,Peiqi Duan,Zongqiang Wang,Changwei Wang,Boxin Shi,Edmund Y. Lam*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In low-light environments, conventional cameras often struggle to capture
clear multi-view images of objects due to dynamic range limitations and motion
blur caused by long exposure. Event cameras, with their high-dynamic range and
high-speed properties, have the potential to mitigate these issues.
Additionally, 3D Gaussian Splatting (GS) enables radiance field reconstruction,
facilitating bright frame synthesis from multiple viewpoints in low-light
conditions. However, naively using an event-assisted 3D GS approach still faced
challenges because, in low light, events are noisy, frames lack quality, and
the color tone may be inconsistent. To address these issues, we propose
Dark-EvGS, the first event-assisted 3D GS framework that enables the
reconstruction of bright frames from arbitrary viewpoints along the camera
trajectory. Triplet-level supervision is proposed to gain holistic knowledge,
granular details, and sharp scene rendering. The color tone matching block is
proposed to guarantee the color consistency of the rendered frames.
Furthermore, we introduce the first real-captured dataset for the event-guided
bright frame synthesis task via 3D GS-based radiance field reconstruction.
Experiments demonstrate that our method achieves better results than existing
methods, conquering radiance field reconstruction under challenging low-light
conditions. The code and sample data are included in the supplementary
material.

</details>


### [20] [Hyperphantasia: A Benchmark for Evaluating the Mental Visualization Capabilities of Multimodal LLMs](https://arxiv.org/abs/2507.11932)
*Mohammad Shahab Sepehri,Berk Tinaz,Zalan Fabian,Mahdi Soltanolkotabi*

Main category: cs.CV

TL;DR: Hyperphantasia是一个新的基准，用于评估多模态大语言模型的心理可视化能力，发现现有模型与人类相比存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 当前基准主要评估被动视觉感知，对模型内部构建视觉模式以支持解决问题的能力了解有限，而心理可视化对人类来说是一项关键的认知技能。

Method: 通过四个精心设计的谜题（每个谜题都有三个难度级别）引入了一个名为Hyperphantasia的合成基准，用于评估多模态大语言模型的心理可视化能力。

Result: 对最先进的模型进行的全面评估揭示了人类和多模态大语言模型之间存在的巨大差距，并探索了强化学习在提高视觉模拟能力方面的潜力。

Conclusion: 尽管一些模型在识别视觉模式方面表现出部分能力，但强大的心理可视化能力仍然是当前多模态大语言模型的开放性挑战。

Abstract: Mental visualization, the ability to construct and manipulate visual
representations internally, is a core component of human cognition and plays a
vital role in tasks involving reasoning, prediction, and abstraction. Despite
the rapid progress of Multimodal Large Language Models (MLLMs), current
benchmarks primarily assess passive visual perception, offering limited insight
into the more active capability of internally constructing visual patterns to
support problem solving. Yet mental visualization is a critical cognitive skill
in humans, supporting abilities such as spatial navigation, predicting physical
trajectories, and solving complex visual problems through imaginative
simulation. To bridge this gap, we introduce Hyperphantasia, a synthetic
benchmark designed to evaluate the mental visualization abilities of MLLMs
through four carefully constructed puzzles. Each task is procedurally generated
and presented at three difficulty levels, enabling controlled analysis of model
performance across increasing complexity. Our comprehensive evaluation of
state-of-the-art models reveals a substantial gap between the performance of
humans and MLLMs. Additionally, we explore the potential of reinforcement
learning to improve visual simulation capabilities. Our findings suggest that
while some models exhibit partial competence in recognizing visual patterns,
robust mental visualization remains an open challenge for current MLLMs.

</details>


### [21] [Traffic-Aware Pedestrian Intention Prediction](https://arxiv.org/abs/2507.12433)
*Fahimeh Orvati Nia,Hai Lin*

Main category: cs.CV

TL;DR: 该研究提出了一种新的TA-STGCN模型，通过整合动态交通信号灯信息来提高自动驾驶汽车对行人意图的预测准确性，并在实验中取得了显著成效。


<details>
  <summary>Details</summary>
Motivation: 准确的行人意图估计对于自动驾驶汽车（AV）的安全导航至关重要，但现有模型往往未能充分考虑动态交通信号和上下文场景信息，而这些信息对实际应用至关重要。

Method: 本文提出了一种交通感知时空图卷积网络（TA-STGCN），将交通信号灯及其状态（红、黄、绿）整合到行人意图预测中。该方法整合了动态交通信号状态和边界框大小作为关键特征，能够捕捉复杂城市环境中的空间和时间依赖性。

Result: TA-STGCN在PIE数据集上的准确率比基线模型高4.75%，在提高行人意图预测方面表现出优越性。

Conclusion: TA-STGCN模型在PIE数据集上准确率比基线模型高4.75%，证明了其在改进行人意图预测方面的有效性。

Abstract: Accurate pedestrian intention estimation is crucial for the safe navigation
of autonomous vehicles (AVs) and hence attracts a lot of research attention.
However, current models often fail to adequately consider dynamic traffic
signals and contextual scene information, which are critical for real-world
applications. This paper presents a Traffic-Aware Spatio-Temporal Graph
Convolutional Network (TA-STGCN) that integrates traffic signs and their states
(Red, Yellow, Green) into pedestrian intention prediction. Our approach
introduces the integration of dynamic traffic signal states and bounding box
size as key features, allowing the model to capture both spatial and temporal
dependencies in complex urban environments. The model surpasses existing
methods in accuracy. Specifically, TA-STGCN achieves a 4.75% higher accuracy
compared to the baseline model on the PIE dataset, demonstrating its
effectiveness in improving pedestrian intention prediction.

</details>


### [22] [RaDL: Relation-aware Disentangled Learning for Multi-Instance Text-to-Image Generation](https://arxiv.org/abs/2507.11947)
*Geon Park,Seon Bin Kim,Gunho Jung,Seong-Whan Lee*

Main category: cs.CV

TL;DR: RaDL framework addresses challenges in text-to-image generation for multiple instances by improving positional accuracy and attribute consideration through relation-aware disentangled learning.


<details>
  <summary>Details</summary>
Motivation: Existing text-to-image (T2I) methods struggle to account for relationship discrepancy and multiple attributes leakage when generating multiple instances within a single image prompt.

Method: RaDL enhances instance-specific attributes through learnable parameters and generates relation-aware image features via Relation Attention, utilizing action verbs extracted from the global prompt.

Result: RaDL outperforms existing methods, showing significant improvements in positional accuracy, multiple attributes consideration, and the relationships between instances, as demonstrated through extensive evaluations on COCO-Position, COCO-MIG, and DrawBench.

Conclusion: RaDL is a solution for generating images that consider both the relationships and multiple attributes of each instance within the multi-instance image.

Abstract: With recent advancements in text-to-image (T2I) models, effectively
generating multiple instances within a single image prompt has become a crucial
challenge. Existing methods, while successful in generating positions of
individual instances, often struggle to account for relationship discrepancy
and multiple attributes leakage. To address these limitations, this paper
proposes the relation-aware disentangled learning (RaDL) framework. RaDL
enhances instance-specific attributes through learnable parameters and
generates relation-aware image features via Relation Attention, utilizing
action verbs extracted from the global prompt. Through extensive evaluations on
benchmarks such as COCO-Position, COCO-MIG, and DrawBench, we demonstrate that
RaDL outperforms existing methods, showing significant improvements in
positional accuracy, multiple attributes consideration, and the relationships
between instances. Our results present RaDL as the solution for generating
images that consider both the relationships and multiple attributes of each
instance within the multi-instance image.

</details>


### [23] [Prototypical Progressive Alignment and Reweighting for Generalizable Semantic Segmentation](https://arxiv.org/abs/2507.11955)
*Yuhang Zhang,Zhengyu Zhang,Muxin Liao,Shishun Tian,Wenbin Zou,Lu Zhang,Chen Xu*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Generalizable semantic segmentation aims to perform well on unseen target
domains, a critical challenge due to real-world applications requiring high
generalizability. Class-wise prototypes, representing class centroids, serve as
domain-invariant cues that benefit generalization due to their stability and
semantic consistency. However, this approach faces three challenges. First,
existing methods often adopt coarse prototypical alignment strategies, which
may hinder performance. Second, naive prototypes computed by averaging source
batch features are prone to overfitting and may be negatively affected by
unrelated source data. Third, most methods treat all source samples equally,
ignoring the fact that different features have varying adaptation difficulties.
To address these limitations, we propose a novel framework for generalizable
semantic segmentation: Prototypical Progressive Alignment and Reweighting
(PPAR), leveraging the strong generalization ability of the CLIP model.
Specifically, we define two prototypes: the Original Text Prototype (OTP) and
Visual Text Prototype (VTP), generated via CLIP to serve as a solid base for
alignment. We then introduce a progressive alignment strategy that aligns
features in an easy-to-difficult manner, reducing domain gaps gradually.
Furthermore, we propose a prototypical reweighting mechanism that estimates the
reliability of source data and adjusts its contribution, mitigating the effect
of irrelevant or harmful features (i.e., reducing negative transfer). We also
provide a theoretical analysis showing the alignment between our method and
domain generalization theory. Extensive experiments across multiple benchmarks
demonstrate that PPAR achieves state-of-the-art performance, validating its
effectiveness.

</details>


### [24] [Language-Guided Contrastive Audio-Visual Masked Autoencoder with Automatically Generated Audio-Visual-Text Triplets from Videos](https://arxiv.org/abs/2507.11967)
*Yuchi Ishikawa,Shota Nakada,Hokuto Munakata,Kazuhiro Saito,Tatsuya Komatsu,Yoshimitsu Aoki*

Main category: cs.CV

TL;DR: 提出LG-CAV-MAE模型，通过集成文本编码器和自动生成音频-视觉-文本三元组，显著提升了音频-视觉表示学习在检索和分类任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 旨在提高音频-视觉表示学习的性能。

Method: 提出了一种名为语言引导对比音频-视觉掩码自动编码器（LG-CAV-MAE）的模型，该模型将预训练的文本编码器集成到对比音频-视觉掩码自动编码器中，实现了跨音频、视觉和文本模态的学习。为了训练LG-CAV-MAE，提出了一种从无标签视频生成音频-视觉-文本三元组的自动方法，首先使用图像字幕模型生成帧级字幕，然后使用基于CLAP的过滤来确保音频和字幕之间的强对齐。

Result: LG-CAV-MAE在音频-视觉检索任务和音频-视觉分类任务上的表现优于现有方法。

Conclusion: 该方法在音频-视觉检索和音频-视觉分类任务上显著优于现有方法，分别在检索任务的recall@10和分类任务上提高了5.6%和3.2%。

Abstract: In this paper, we propose Language-Guided Contrastive Audio-Visual Masked
Autoencoders (LG-CAV-MAE) to improve audio-visual representation learning.
LG-CAV-MAE integrates a pretrained text encoder into contrastive audio-visual
masked autoencoders, enabling the model to learn across audio, visual and text
modalities. To train LG-CAV-MAE, we introduce an automatic method to generate
audio-visual-text triplets from unlabeled videos. We first generate frame-level
captions using an image captioning model and then apply CLAP-based filtering to
ensure strong alignment between audio and captions. This approach yields
high-quality audio-visual-text triplets without requiring manual annotations.
We evaluate LG-CAV-MAE on audio-visual retrieval tasks, as well as an
audio-visual classification task. Our method significantly outperforms existing
approaches, achieving up to a 5.6% improvement in recall@10 for retrieval tasks
and a 3.2% improvement for the classification task.

</details>


### [25] [Watch, Listen, Understand, Mislead: Tri-modal Adversarial Attacks on Short Videos for Content Appropriateness Evaluation](https://arxiv.org/abs/2507.11968)
*Sahid Hossain Mustakim,S M Jishanul Islam,Ummay Maria Muna,Montasir Chowdhury,Mohammed Jawwadul Islam,Sadia Ahmmed,Tashfia Sikder,Syed Tasdid Azam Dhrubo,Swakkhar Shatabda*

Main category: cs.CV

TL;DR: 本研究通过SVMA数据集和ChimeraBreak攻击策略，发现了多模态大语言模型在短视频内容审核中的三模态安全漏洞，提高了模型安全性评估的全面性。


<details>
  <summary>Details</summary>
Motivation: 当前对多模态大语言模型在短视频内容审核方面的鲁棒性研究不足，现有的安全评估方法依赖单模态攻击，未能充分解决组合攻击的脆弱性。

Method: 提出了一种评估多模态大语言模型三模态安全性的综合框架，包括构建包含人类指导的合成对抗性攻击的短视频多模态对抗（SVMA）数据集，并提出了一种同时挑战视觉、听觉和语义推理通路的三模态攻击策略ChimeraBreak。

Result: 实验结果表明，最先进的多模态大语言模型在面对ChimeraBreak攻击时表现出显著的脆弱性，攻击成功率高，并暴露出模型在误分类良性或违规内容方面的偏见。通过LLM-as-a-judge评估证实了攻击的有效性。

Conclusion: 本研究提出的SVMA数据集和ChimeraBreak攻击策略揭示了多模态大语言模型在短视频内容审核方面存在的显著安全漏洞，为开发更鲁棒、更安全的多模态大语言模型提供了关键见解。

Abstract: Multimodal Large Language Models (MLLMs) are increasingly used for content
moderation, yet their robustness in short-form video contexts remains
underexplored. Current safety evaluations often rely on unimodal attacks,
failing to address combined attack vulnerabilities. In this paper, we introduce
a comprehensive framework for evaluating the tri-modal safety of MLLMs. First,
we present the Short-Video Multimodal Adversarial (SVMA) dataset, comprising
diverse short-form videos with human-guided synthetic adversarial attacks.
Second, we propose ChimeraBreak, a novel tri-modal attack strategy that
simultaneously challenges visual, auditory, and semantic reasoning pathways.
Extensive experiments on state-of-the-art MLLMs reveal significant
vulnerabilities with high Attack Success Rates (ASR). Our findings uncover
distinct failure modes, showing model biases toward misclassifying benign or
policy-violating content. We assess results using LLM-as-a-judge, demonstrating
attack reasoning efficacy. Our dataset and findings provide crucial insights
for developing more robust and safe MLLMs.

</details>


### [26] [GS-Bias: Global-Spatial Bias Learner for Single-Image Test-Time Adaptation of Vision-Language Models](https://arxiv.org/abs/2507.11969)
*Zhaohong Huang,Yuxin Zhang,Jingjing Xie,Fei Chao,Rongrong Ji*

Main category: cs.CV

TL;DR: GS-Bias是一种高效的TTA方法，通过引入全局和空间偏置来提高VLMs的零样本泛化能力，实现了优越的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的针对视觉语言模型（VLMs）的测试时自适应（TTA）方法在性能和效率之间未能取得令人满意的平衡，原因在于调整文本提示的开销过大，或手工制作的、无需训练的视觉特征增强带来的效益不稳定。

Method: GS-Bias通过学习一致性来捕获测试图像的全局语义特征，并学习图像空间视觉表示中区域之间的语义一致性。这两种偏置直接添加到预训练VLMs的logits输出上，从而避免了对VLM进行完全反向传播。

Result: GS-Bias在15个基准数据集上取得了最先进的性能，在跨数据集泛化方面比TPT提高了2.23%，在领域泛化方面提高了2.72%，同时在ImageNet上的内存使用量仅为TPT的6.5%。

Conclusion: GS-Bias是一种高效且有效的测试时自适应（TTA）范式，通过引入全局偏置和空间偏置，直接加到预训练视觉语言模型（VLMs）的输出logits上，避免了对整个VLM进行反向传播，从而实现了高效率。GS-Bias在15个基准数据集上取得了最先进的性能，在跨数据集泛化方面比TPT提高了2.23%，在领域泛化方面提高了2.72%，同时在ImageNet上的内存使用量仅为TPT的6.5%。

Abstract: Recent advances in test-time adaptation (TTA) for Vision-Language Models
(VLMs) have garnered increasing attention, particularly through the use of
multiple augmented views of a single image to boost zero-shot generalization.
Unfortunately, existing methods fail to strike a satisfactory balance between
performance and efficiency, either due to excessive overhead of tuning text
prompts or unstable benefits from handcrafted, training-free visual feature
enhancement. In this paper, we present Global-Spatial Bias Learner (GS-Bias),
an efficient and effective TTA paradigm that incorporates two learnable biases
during TTA, unfolded as the global bias and spatial bias. Particularly, the
global bias captures the global semantic features of a test image by learning
consistency across augmented views, while spatial bias learns the semantic
coherence between regions in the image's spatial visual representation. It is
worth highlighting that these two sets of biases are directly added to the
logits outputed by the pretrained VLMs, which circumvent the full
backpropagation through VLM that hinders the efficiency of existing TTA
methods. This endows GS-Bias with extremely high efficiency while achieving
state-of-the-art performance on 15 benchmark datasets. For example, it achieves
a 2.23% improvement over TPT in cross-dataset generalization and a 2.72%
improvement in domain generalization, while requiring only 6.5% of TPT's memory
usage on ImageNet.

</details>


### [27] [EC-Diff: Fast and High-Quality Edge-Cloud Collaborative Inference for Diffusion Models](https://arxiv.org/abs/2507.11980)
*Jiajian Xie,Shengyu Zhang,Zhou Zhao,Fan Wu,Fei Wu*

Main category: cs.CV

TL;DR: EC-Diff通过梯度估计和优化的云边切换策略，加速了扩散模型的推理过程，提高了生成质量和速度。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有混合边缘-云协作框架中，云端模型过度去噪导致推理时间过长，或去噪不足导致语义模糊和边缘模型输出不一致的问题。

Method: 提出了一种名为EC-Diff的框架，该框架通过梯度下降的噪声估计来加速云端推理，并采用双阶段贪婪搜索算法来优化噪声估计和边缘模型切换的参数。具体而言，设计了一种K步噪声近似策略，利用噪声梯度来减少云端推理的频率，并周期性地进行云端推理以纠正误差。

Result: EC-Diff显著提高了生成质量，同时实现了高达2倍的推理速度提升。

Conclusion: EC-Diff通过基于梯度的噪声估计加速云推理，并确定了云-边切换的最佳点，以在保持生成质量的同时降低延迟。实验证明，与仅在边缘进行推理相比，EC-Diff显著提高了生成质量，与仅在云端推理相比，推理速度平均提高了2倍。

Abstract: Diffusion Models have shown remarkable proficiency in image and video
synthesis. As model size and latency increase limit user experience, hybrid
edge-cloud collaborative framework was recently proposed to realize fast
inference and high-quality generation, where the cloud model initiates
high-quality semantic planning and the edge model expedites later-stage
refinement. However, excessive cloud denoising prolongs inference time, while
insufficient steps cause semantic ambiguity, leading to inconsistency in edge
model output. To address these challenges, we propose EC-Diff that accelerates
cloud inference through gradient-based noise estimation while identifying the
optimal point for cloud-edge handoff to maintain generation quality.
Specifically, we design a K-step noise approximation strategy to reduce cloud
inference frequency by using noise gradients between steps and applying cloud
inference periodically to adjust errors. Then we design a two-stage greedy
search algorithm to efficiently find the optimal parameters for noise
approximation and edge model switching. Extensive experiments demonstrate that
our method significantly enhances generation quality compared to edge
inference, while achieving up to an average $2\times$ speedup in inference
compared to cloud inference. Video samples and source code are available at
https://ec-diff.github.io/.

</details>


### [28] [Unsupervised Part Discovery via Descriptor-Based Masked Image Restoration with Optimized Constraints](https://arxiv.org/abs/2507.11985)
*Jiahao Xia,Yike Wu,Wenjian Huang,Jianguo Zhang,Jian Zhang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Part-level features are crucial for image understanding, but few studies
focus on them because of the lack of fine-grained labels. Although unsupervised
part discovery can eliminate the reliance on labels, most of them cannot
maintain robustness across various categories and scenarios, which restricts
their application range. To overcome this limitation, we present a more
effective paradigm for unsupervised part discovery, named Masked Part
Autoencoder (MPAE). It first learns part descriptors as well as a feature map
from the inputs and produces patch features from a masked version of the
original images. Then, the masked regions are filled with the learned part
descriptors based on the similarity between the local features and descriptors.
By restoring these masked patches using the part descriptors, they become
better aligned with their part shapes, guided by appearance features from
unmasked patches. Finally, MPAE robustly discovers meaningful parts that
closely match the actual object shapes, even in complex scenarios. Moreover,
several looser yet more effective constraints are proposed to enable MPAE to
identify the presence of parts across various scenarios and categories in an
unsupervised manner. This provides the foundation for addressing challenges
posed by occlusion and for exploring part similarity across multiple
categories. Extensive experiments demonstrate that our method robustly
discovers meaningful parts across various categories and scenarios. The code is
available at the project https://github.com/Jiahao-UTS/MPAE.

</details>


### [29] [Style Composition within Distinct LoRA modules for Traditional Art](https://arxiv.org/abs/2507.11986)
*Jaehyun Lee,Wonhark Park,Wonsik Shin,Hyunho Lee,Hyoung Min Na,Nojun Kwak*

Main category: cs.CV

TL;DR: 一种新的零样本扩散方法，可以通过空间掩码和深度图控制，在不同风格的扩散模型之间进行区域性风格混合。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型虽然在文本到图像合成和风格个性化方面表现出色，但其纠缠的潜在空间和缺乏平滑插值使得难以以可控的、区域性的方式应用不同的绘画技术，并且常常导致一种风格压倒其他风格。

Method: 提出了一种零样本扩散管线，通过在单独训练的、风格专门化的模型进行去噪过程中，在去噪后的潜在空间中进行风格合成，并使用空间掩码跨异构扩散管线融合低噪声潜在信息。引入了通过ControlNet的深度图条件来确保跨不同模型的结构一致性。

Result: 定性和定量实验证明，该方法能够根据给定的掩码成功实现特定区域的风格混合。

Conclusion: 该方法能够根据用户提供的掩码，在不同模型之间实现特定区域的风格混合，并保持每种风格的保真度。

Abstract: Diffusion-based text-to-image models have achieved remarkable results in
synthesizing diverse images from text prompts and can capture specific artistic
styles via style personalization. However, their entangled latent space and
lack of smooth interpolation make it difficult to apply distinct painting
techniques in a controlled, regional manner, often causing one style to
dominate. To overcome this, we propose a zero-shot diffusion pipeline that
naturally blends multiple styles by performing style composition on the
denoised latents predicted during the flow-matching denoising process of
separately trained, style-specialized models. We leverage the fact that
lower-noise latents carry stronger stylistic information and fuse them across
heterogeneous diffusion pipelines using spatial masks, enabling precise,
region-specific style control. This mechanism preserves the fidelity of each
individual style while allowing user-guided mixing. Furthermore, to ensure
structural coherence across different models, we incorporate depth-map
conditioning via ControlNet into the diffusion framework. Qualitative and
quantitative experiments demonstrate that our method successfully achieves
region-specific style mixing according to the given masks.

</details>


### [30] [SGLoc: Semantic Localization System for Camera Pose Estimation from 3D Gaussian Splatting Representation](https://arxiv.org/abs/2507.12027)
*Beining Xu,Siting Zhu,Hesheng Wang*

Main category: cs.CV

TL;DR: SGLoc 是一种新的定位系统，它利用语义信息直接从 3D高斯泼溅（3DGS）表示回归相机位姿，无需初始姿态先验。它通过多层次姿态回归和基于语义的全局检索来实现精确的全局定位。


<details>
  <summary>Details</summary>
Motivation: 提出一种利用语义信息直接从 3D高斯泼溅（3DGS）表示回归相机位姿的定位系统，以在没有初始姿态先验信息的情况下估计 6DoF 位姿。

Method: SGLoc 通过利用语义信息，直接从 3D高斯泼溅（3DGS）表示回归相机位姿。该方法引入了多层次姿态回归策略，从全局 3DGS 地图中逐步估计和优化查询图像的位姿，无需初始姿态先验。此外，还引入了一种基于语义的全局检索算法，以建立 2D（图像）和 3D（3DGS 地图）之间的对应关系。通过匹配 2D 查询图像的语义描述符和 3DGS 语义表示，将图像与全局 3DGS 地图的局部区域对齐，从而获得粗略的位姿估计。随后，通过迭代优化查询图像与从 3DGS 渲染的图像之间的差异来优化粗略位姿。

Result: SGLoc 证明了其在 12scenes 和 7scenes 数据集上的性能优于基线方法，在没有初始姿态先验的情况下展现了出色的全局定位能力。

Conclusion: SGLoc 证明了其在 12scenes 和 7scenes 数据集上的性能优于基线方法，在没有初始姿态先验的情况下展现了出色的全局定位能力。

Abstract: We propose SGLoc, a novel localization system that directly regresses camera
poses from 3D Gaussian Splatting (3DGS) representation by leveraging semantic
information. Our method utilizes the semantic relationship between 2D image and
3D scene representation to estimate the 6DoF pose without prior pose
information. In this system, we introduce a multi-level pose regression
strategy that progressively estimates and refines the pose of query image from
the global 3DGS map, without requiring initial pose priors. Moreover, we
introduce a semantic-based global retrieval algorithm that establishes
correspondences between 2D (image) and 3D (3DGS map). By matching the extracted
scene semantic descriptors of 2D query image and 3DGS semantic representation,
we align the image with the local region of the global 3DGS map, thereby
obtaining a coarse pose estimation. Subsequently, we refine the coarse pose by
iteratively optimizing the difference between the query image and the rendered
image from 3DGS. Our SGLoc demonstrates superior performance over baselines on
12scenes and 7scenes datasets, showing excellent capabilities in global
localization without initial pose prior. Code will be available at
https://github.com/IRMVLab/SGLoc.

</details>


### [31] [ID-EA: Identity-driven Text Enhancement and Adaptation with Textual Inversion for Personalized Text-to-Image Generation](https://arxiv.org/abs/2507.11990)
*Hyun-Jun Jin,Young-Eun Kim,Seong-Whan Lee*

Main category: cs.CV

TL;DR: 提出ID-EA框架，通过对齐文本和视觉身份嵌入，显著提高个性化人像生成中的身份保持能力，并实现15倍的速度提升。


<details>
  <summary>Details</summary>
Motivation: 现有的Textual Inversion方法在保持面部身份一致性方面存在困难，主要是由于文本和视觉嵌入空间在身份表示上存在语义不匹配。

Method: ID-EA框架包含ID-驱动增强器（ID-Enhancer）和ID条件适配器（ID-Adapter）。ID-Enhancer将身份嵌入与文本ID锚点结合，利用代表性文本嵌入来优化从人脸识别模型获得的视觉身份嵌入。ID-Adapter利用身份增强嵌入来调整预训练UNet模型的交叉注意力模块，以匹配文本条件，从而实现身份保持。

Result: ID-EA在身份保持指标上大幅优于现有最先进方法，同时实现了显著的计算效率，生成个性化人像的速度比现有方法快约15倍。

Conclusion: ID-EA通过引导文本嵌入与视觉身份嵌入对齐，显著提高了个性化人像生成中的身份保持能力，并且在计算效率上远超现有方法。

Abstract: Recently, personalized portrait generation with a text-to-image diffusion
model has significantly advanced with Textual Inversion, emerging as a
promising approach for creating high-fidelity personalized images. Despite its
potential, current Textual Inversion methods struggle to maintain consistent
facial identity due to semantic misalignments between textual and visual
embedding spaces regarding identity. We introduce ID-EA, a novel framework that
guides text embeddings to align with visual identity embeddings, thereby
improving identity preservation in a personalized generation. ID-EA comprises
two key components: the ID-driven Enhancer (ID-Enhancer) and the ID-conditioned
Adapter (ID-Adapter). First, the ID-Enhancer integrates identity embeddings
with a textual ID anchor, refining visual identity embeddings derived from a
face recognition model using representative text embeddings. Then, the
ID-Adapter leverages the identity-enhanced embedding to adapt the text
condition, ensuring identity preservation by adjusting the cross-attention
module in the pre-trained UNet model. This process encourages the text features
to find the most related visual clues across the foreground snippets. Extensive
quantitative and qualitative evaluations demonstrate that ID-EA substantially
outperforms state-of-the-art methods in identity preservation metrics while
achieving remarkable computational efficiency, generating personalized
portraits approximately 15 times faster than existing approaches.

</details>


### [32] [Foresight in Motion: Reinforcing Trajectory Prediction with Reward Heuristics](https://arxiv.org/abs/2507.12083)
*Muleilan Pei,Shaoshuai Shi,Xuesong Chen,Xu Liu,Shaojie Shen*

Main category: cs.CV

TL;DR: 该研究提出了一种“先推理，后预测”的方法，通过逆向强化学习（IRL）明确纳入行为意图作为空间指导，以提高自动驾驶中的运动预测精度和置信度。


<details>
  <summary>Details</summary>
Motivation: 为了确保自动驾驶系统的安全，对道路交通代理进行运动预测是一项重大挑战，也是关键需求。与大多数直接预测未来轨迹的现有数据驱动方法不同，该研究从规划的角度重新思考了这项任务，提倡“先推理，后预测”的策略，将行为意图明确地作为空间指导纳入轨迹预测。

Method: 该方法首先将交通代理和场景元素编码为统一的向量表示，然后通过以查询为中心的范例聚合上下文特征。这使得能够通过逆向强化学习（IRL）推导出奖励分布，该分布是目标代理在给定场景上下文中的行为的紧凑而信息丰富的表示。在奖励启发式指导下，该方法执行策略滚动以推理多个可能的意图，为后续的轨迹生成提供有价值的先验。最后，开发了一个集成了双向选择性状态空间模型的类似DETR的层次化解码器，以生成准确的未来轨迹及其相关的概率。

Result: 实验结果表明，与现有最先进的方法相比，该方法显著提高了轨迹预测的置信度，并取得了具有高度竞争力的性能。

Conclusion: 该方法在Argoverse和nuScenes大型数据集上进行了广泛的实验，证明了其显著提高了轨迹预测的置信度，并取得了与最先进方法高度竞争的性能。

Abstract: Motion forecasting for on-road traffic agents presents both a significant
challenge and a critical necessity for ensuring safety in autonomous driving
systems. In contrast to most existing data-driven approaches that directly
predict future trajectories, we rethink this task from a planning perspective,
advocating a "First Reasoning, Then Forecasting" strategy that explicitly
incorporates behavior intentions as spatial guidance for trajectory prediction.
To achieve this, we introduce an interpretable, reward-driven intention
reasoner grounded in a novel query-centric Inverse Reinforcement Learning (IRL)
scheme. Our method first encodes traffic agents and scene elements into a
unified vectorized representation, then aggregates contextual features through
a query-centric paradigm. This enables the derivation of a reward distribution,
a compact yet informative representation of the target agent's behavior within
the given scene context via IRL. Guided by this reward heuristic, we perform
policy rollouts to reason about multiple plausible intentions, providing
valuable priors for subsequent trajectory generation. Finally, we develop a
hierarchical DETR-like decoder integrated with bidirectional selective state
space models to produce accurate future trajectories along with their
associated probabilities. Extensive experiments on the large-scale Argoverse
and nuScenes motion forecasting datasets demonstrate that our approach
significantly enhances trajectory prediction confidence, achieving highly
competitive performance relative to state-of-the-art methods.

</details>


### [33] [SAMST: A Transformer framework based on SAM pseudo label filtering for remote sensing semi-supervised semantic segmentation](https://arxiv.org/abs/2507.11994)
*Jun Yin,Fei Wu,Yupeng Ren,Jisheng Huang,Qiankun Li,Heng jin,Jianhai Fu,Chanjie Cui*

Main category: cs.CV

TL;DR: 提出SAMST半监督学习方法，利用SAM模型处理遥感数据，通过自训练和SAM伪标签优化器提升语义分割精度，尤其在标签数据有限的情况下。


<details>
  <summary>Details</summary>
Motivation: 为了利用海量的未标记遥感数据，并解决公共遥感数据集在泛化性方面因分辨率变化和土地覆盖类别定义不一致而面临的限制，提出SAMST方法。

Method: SAMST是一种半监督语义分割方法，通过两个主要组件迭代地优化伪标签：1. 使用标签和伪标签数据进行监督模型自训练；2. 基于SAM的伪标签优化器。伪标签优化器包含三个模块：用于预处理的阈值过滤模块、用于提取连接区域和为SAM生成提示的提示生成模块，以及用于最终标签缝合的标签优化模块。

Result: SAMST提高了伪标签的准确性，从而提升了整体模型性能。在Potsdam数据集上的实验证明了SAMST的有效性和可行性。

Conclusion: SAMST方法通过结合SAM模型的泛化能力和监督模型的训练效率，提高了伪标签的准确性，进而提升了整体模型性能。在Potsdam数据集上的实验验证了SAMST的有效性和可行性，证明了其在解决遥感语义分割中有限标签数据挑战方面的潜力。

Abstract: Public remote sensing datasets often face limitations in universality due to
resolution variability and inconsistent land cover category definitions. To
harness the vast pool of unlabeled remote sensing data, we propose SAMST, a
semi-supervised semantic segmentation method. SAMST leverages the strengths of
the Segment Anything Model (SAM) in zero-shot generalization and boundary
detection. SAMST iteratively refines pseudo-labels through two main components:
supervised model self-training using both labeled and pseudo-labeled data, and
a SAM-based Pseudo-label Refiner. The Pseudo-label Refiner comprises three
modules: a Threshold Filter Module for preprocessing, a Prompt Generation
Module for extracting connected regions and generating prompts for SAM, and a
Label Refinement Module for final label stitching. By integrating the
generalization power of large models with the training efficiency of small
models, SAMST improves pseudo-label accuracy, thereby enhancing overall model
performance. Experiments on the Potsdam dataset validate the effectiveness and
feasibility of SAMST, demonstrating its potential to address the challenges
posed by limited labeled data in remote sensing semantic segmentation.

</details>


### [34] [AutoVDC: Automated Vision Data Cleaning Using Vision-Language Models](https://arxiv.org/abs/2507.12414)
*Santosh Vasa,Aditi Ramadwar,Jnana Rama Krishna Darabattula,Md Zafar Anwar,Stanislaw Antol,Andrei Vatavu,Thomas Monninger,Sihao Ding*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Training of autonomous driving systems requires extensive datasets with
precise annotations to attain robust performance. Human annotations suffer from
imperfections, and multiple iterations are often needed to produce high-quality
datasets. However, manually reviewing large datasets is laborious and
expensive. In this paper, we introduce AutoVDC (Automated Vision Data Cleaning)
framework and investigate the utilization of Vision-Language Models (VLMs) to
automatically identify erroneous annotations in vision datasets, thereby
enabling users to eliminate these errors and enhance data quality. We validate
our approach using the KITTI and nuImages datasets, which contain object
detection benchmarks for autonomous driving. To test the effectiveness of
AutoVDC, we create dataset variants with intentionally injected erroneous
annotations and observe the error detection rate of our approach. Additionally,
we compare the detection rates using different VLMs and explore the impact of
VLM fine-tuning on our pipeline. The results demonstrate our method's high
performance in error detection and data cleaning experiments, indicating its
potential to significantly improve the reliability and accuracy of large-scale
production datasets in autonomous driving.

</details>


### [35] [AU-Blendshape for Fine-grained Stylized 3D Facial Expression Manipulation](https://arxiv.org/abs/2507.12001)
*Hao Li,Ju Dai,Feng Zhou,Kaida Ning,Lei Li,Junjun Pan*

Main category: cs.CV

TL;DR: 该研究提出了 AUBlendSet 数据集和 AUBlendNet 网络，解决了 3D 面部表情操控的挑战，实现了细粒度的风格化面部表情操控。


<details>
  <summary>Details</summary>
Motivation: 现有的 3D 面部动画技术在实现细粒度风格化 3D 面部表情操控方面仍存在挑战，主要是由于缺乏合适的数据集。

Method: 提出 AUBlendSet 数据集，包含 32 个面部动作单元 (AUs) 的融合形状数据，覆盖 500 个身份。提出 AUBlendNet 网络，学习不同风格的 AU-融合形状基向量，能够为给定的身份网格预测相应风格的 AU-融合形状基向量，实现风格化的 3D 情绪面部操控。

Result: AUBlendSet 和 AUBlendNet 在风格化面部表情操控、语音驱动情绪面部动画和情绪识别数据增强等任务中得到了有效验证，实验结果表明了其在 3D 面部动画任务中的潜力和重要性。

Conclusion: AUBlendSet 是第一个用于精细化面部表情操控的 3D 面部数据集，AUBlendNet 是第一个用于通过面部 AU 实现任意身份的连续 3D 面部表情操控的网络。该方法在风格化面部表情操控、语音驱动情绪面部动画和情绪识别数据增强等任务中展现出巨大潜力。

Abstract: While 3D facial animation has made impressive progress, challenges still
exist in realizing fine-grained stylized 3D facial expression manipulation due
to the lack of appropriate datasets. In this paper, we introduce the
AUBlendSet, a 3D facial dataset based on AU-Blendshape representation for
fine-grained facial expression manipulation across identities. AUBlendSet is a
blendshape data collection based on 32 standard facial action units (AUs)
across 500 identities, along with an additional set of facial postures
annotated with detailed AUs. Based on AUBlendSet, we propose AUBlendNet to
learn AU-Blendshape basis vectors for different character styles. AUBlendNet
predicts, in parallel, the AU-Blendshape basis vectors of the corresponding
style for a given identity mesh, thereby achieving stylized 3D emotional facial
manipulation. We comprehensively validate the effectiveness of AUBlendSet and
AUBlendNet through tasks such as stylized facial expression manipulation,
speech-driven emotional facial animation, and emotion recognition data
augmentation. Through a series of qualitative and quantitative experiments, we
demonstrate the potential and importance of AUBlendSet and AUBlendNet in 3D
facial animation tasks. To the best of our knowledge, AUBlendSet is the first
dataset, and AUBlendNet is the first network for continuous 3D facial
expression manipulation for any identity through facial AUs. Our source code is
available at https://github.com/wslh852/AUBlendNet.git.

</details>


### [36] [Frequency-Dynamic Attention Modulation for Dense Prediction](https://arxiv.org/abs/2507.12006)
*Linwei Chen,Lin Gu,Ying Fu*

Main category: cs.CV

TL;DR: FDAM 是一种电路理论启发的新方法，通过反转注意力和动态缩放来解决 ViT 的频率衰减问题，提升了模型在各种视觉任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 Vision Transformer (ViT) 模型虽然在计算机视觉任务中表现出色，但其注意力机制会导致每层都表现为低通滤波器，堆叠的层结构会造成频率衰减，从而丢失关键的细节和纹理信息。

Method: 提出了一种名为“频域动态注意力调制”（FDAM）的新策略，该策略受电路理论启发，包含“注意力反转”（AttInv）和“频域动态缩放”（FreqScale）两种技术。AttInv 通过反转注意力矩阵中的低通滤波器来生成互补的高通滤波，并动态地组合两者。FreqScale 用于对不同频率分量进行加权，以实现对目标响应函数的细粒度调整。

Result: FDAM 能够避免表示坍塌，并通过特征相似性分析和有效秩评估得到证实。该方法在 SegFormer、DeiT 和 MaskDINO 等多种模型上均实现了性能一致性提升，并在语义分割、目标检测和实例分割等任务中表现优异。此外，在遥感检测任务中，FDAM 在单尺度设置下取得了先进水平的成果。

Conclusion: FDAM 通过引入 AttInv 和 FreqScale 技术，可以轻松集成到现有的 Vision Transformer 模型中，有效解决了 ViT 中由于注意力机制导致的频率衰减问题，避免了表示坍塌，并在语义分割、目标检测和实例分割等多种任务上实现了性能提升，尤其在遥感检测任务中取得了先进水平的成果。

Abstract: Vision Transformers (ViTs) have significantly advanced computer vision,
demonstrating strong performance across various tasks. However, the attention
mechanism in ViTs makes each layer function as a low-pass filter, and the
stacked-layer architecture in existing transformers suffers from frequency
vanishing. This leads to the loss of critical details and textures. We propose
a novel, circuit-theory-inspired strategy called Frequency-Dynamic Attention
Modulation (FDAM), which can be easily plugged into ViTs. FDAM directly
modulates the overall frequency response of ViTs and consists of two
techniques: Attention Inversion (AttInv) and Frequency Dynamic Scaling
(FreqScale). Since circuit theory uses low-pass filters as fundamental
elements, we introduce AttInv, a method that generates complementary high-pass
filtering by inverting the low-pass filter in the attention matrix, and
dynamically combining the two. We further design FreqScale to weight different
frequency components for fine-grained adjustments to the target response
function. Through feature similarity analysis and effective rank evaluation, we
demonstrate that our approach avoids representation collapse, leading to
consistent performance improvements across various models, including SegFormer,
DeiT, and MaskDINO. These improvements are evident in tasks such as semantic
segmentation, object detection, and instance segmentation. Additionally, we
apply our method to remote sensing detection, achieving state-of-the-art
results in single-scale settings. The code is available at
\href{https://github.com/Linwei-Chen/FDAM}{https://github.com/Linwei-Chen/FDAM}.

</details>


### [37] [Dual form Complementary Masking for Domain-Adaptive Image Segmentation](https://arxiv.org/abs/2507.12008)
*Jiawen Wang,Yinda Chen,Xiaoyu Liu,Che Liu,Dong Liu,Jianqing Gao,Zhiwei Xiong*

Main category: cs.CV

TL;DR: MaskTwins 框架将掩码重构视为稀疏信号重构问题，理论证明互补掩码提取域不变特征的能力更强，并通过强制执行互补掩码图像预测的一致性，实现了有效的域泛化和特征提取。


<details>
  <summary>Details</summary>
Motivation: 当前工作将掩码图像建模（MIM）与无监督域适应（UDA）中的一致性正则化相关联，但仅将掩码视为输入图像上的变形，忽视了理论分析，导致对掩码重建的理解肤浅，未能充分发掘其在增强特征提取和表示学习方面的潜力。

Method: 提出 MaskTwins 框架，将掩码重构直接整合到主训练流程中，通过强制执行互补掩码图像预测的一致性来提取域不变特征。

Result: MaskTwins 在自然和生物图像分割方面优于基线方法，成功提取了域不变特征，无需单独预训练。

Conclusion: MaskTwins 通过强制执行互补掩码预测的一致性，揭示了跨不同域的内在结构模式，从而实现了端到端的域泛化。实验证明 MaskTwins 在自然和生物图像分割方面优于基线方法，展示了其在提取域不变特征方面的优势，无需单独预训练，为域适应性分割提供了一种新范例。

Abstract: Recent works have correlated Masked Image Modeling (MIM) with consistency
regularization in Unsupervised Domain Adaptation (UDA). However, they merely
treat masking as a special form of deformation on the input images and neglect
the theoretical analysis, which leads to a superficial understanding of masked
reconstruction and insufficient exploitation of its potential in enhancing
feature extraction and representation learning. In this paper, we reframe
masked reconstruction as a sparse signal reconstruction problem and
theoretically prove that the dual form of complementary masks possesses
superior capabilities in extracting domain-agnostic image features. Based on
this compelling insight, we propose MaskTwins, a simple yet effective UDA
framework that integrates masked reconstruction directly into the main training
pipeline. MaskTwins uncovers intrinsic structural patterns that persist across
disparate domains by enforcing consistency between predictions of images masked
in complementary ways, enabling domain generalization in an end-to-end manner.
Extensive experiments verify the superiority of MaskTwins over baseline methods
in natural and biological image segmentation. These results demonstrate the
significant advantages of MaskTwins in extracting domain-invariant features
without the need for separate pre-training, offering a new paradigm for
domain-adaptive segmentation.

</details>


### [38] [Deep Neural Encoder-Decoder Model to Relate fMRI Brain Activity with Naturalistic Stimuli](https://arxiv.org/abs/2507.12009)
*Florian David,Michael Chan,Elenor Morgenroth,Patrik Vuilleumier,Dimitri Van De Ville*

Main category: cs.CV

TL;DR: 使用深度学习模型分析fMRI数据，以了解大脑如何处理电影中的视觉信息。


<details>
  <summary>Details</summary>
Motivation: 利用来自连续电影帧的时间相关输入，并弥合自然电影刺激和fMRI采集之间的时间分辨率差距。

Method: 提出了一种端到端的深度神经网络编码器-解码器模型，利用时间卷积层来编码和解码fMRI数据，以响应自然主义刺激。

Result: 模型能够预测视觉皮层内外的神经元活动，并从神经活动中重建相应的视觉输入。研究发现，对视觉解码贡献最大的脑区是枕中区、梭状回区和距状沟区，它们分别负责形状感知、复杂识别（特别是面部识别）以及边缘和对比度等基本视觉特征。

Conclusion: 该模型表明，通过深度学习模型（如本文提出的模型）的行为，可以探究我们对电影中视觉处理的理解。

Abstract: We propose an end-to-end deep neural encoder-decoder model to encode and
decode brain activity in response to naturalistic stimuli using functional
magnetic resonance imaging (fMRI) data. Leveraging temporally correlated input
from consecutive film frames, we employ temporal convolutional layers in our
architecture, which effectively allows to bridge the temporal resolution gap
between natural movie stimuli and fMRI acquisitions. Our model predicts
activity of voxels in and around the visual cortex and performs reconstruction
of corresponding visual inputs from neural activity. Finally, we investigate
brain regions contributing to visual decoding through saliency maps. We find
that the most contributing regions are the middle occipital area, the fusiform
area, and the calcarine, respectively employed in shape perception, complex
recognition (in particular face perception), and basic visual features such as
edges and contrasts. These functions being strongly solicited are in line with
the decoder's capability to reconstruct edges, faces, and contrasts. All in
all, this suggests the possibility to probe our understanding of visual
processing in films using as a proxy the behaviour of deep learning models such
as the one proposed in this paper.

</details>


### [39] [SS-DC: Spatial-Spectral Decoupling and Coupling Across Visible-Infrared Gap for Domain Adaptive Object Detection](https://arxiv.org/abs/2507.12017)
*Xiwei Zhang,Chunjin Yang,Yiming Xiao,Runtong Zhang,Fanman Meng*

Main category: cs.CV

TL;DR: 该研究提出了一种新的SS-DC框架，通过解耦-耦合策略和SAID模块，有效处理RGB-IR域自适应目标检测中的多子域问题，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的RGB-IR域自适应目标检测方法将RGB域视为单一域，忽略了其内部存在的白天、黑夜、雾天等多个子域。作者认为，跨越这些子域解耦域不变（DI）和域特定（DS）特征，对RGB-IR域适应性具有积极作用。

Method: 提出了一种新的SS-DC框架，包含解耦和耦合两个核心部分。解耦方面，设计了光谱自适应幂等解耦（SAID）模块，通过滤波银行和自蒸馏解耦损失来分离域不变（DI）和域特定（DS）特征。耦合方面，提出了一种新的空间-光谱耦合方法，利用空间和光谱的DI特征金字塔进行联合耦合，并引入DS以减少域偏差。

Result: 实验证明，所提出的SS-DC框架显著优于基线方法，并在包含FLIR-ADAS数据集的新实验协议下，在多个RGB-IR数据集上超越了现有的UDAOD方法。

Conclusion: 所提出的SS-DC框架通过解耦-耦合策略，在处理RGB-IR域自适应目标检测时，能够显著提升基线性能，并在多个RGB-IR数据集上超越现有方法。

Abstract: Unsupervised domain adaptive object detection (UDAOD) from the visible domain
to the infrared (RGB-IR) domain is challenging. Existing methods regard the RGB
domain as a unified domain and neglect the multiple subdomains within it, such
as daytime, nighttime, and foggy scenes. We argue that decoupling the
domain-invariant (DI) and domain-specific (DS) features across these multiple
subdomains is beneficial for RGB-IR domain adaptation. To this end, this paper
proposes a new SS-DC framework based on a decoupling-coupling strategy. In
terms of decoupling, we design a Spectral Adaptive Idempotent Decoupling (SAID)
module in the aspect of spectral decomposition. Due to the style and content
information being highly embedded in different frequency bands, this module can
decouple DI and DS components more accurately and interpretably. A novel filter
bank-based spectral processing paradigm and a self-distillation-driven
decoupling loss are proposed to improve the spectral domain decoupling. In
terms of coupling, a new spatial-spectral coupling method is proposed, which
realizes joint coupling through spatial and spectral DI feature pyramids.
Meanwhile, this paper introduces DS from decoupling to reduce the domain bias.
Extensive experiments demonstrate that our method can significantly improve the
baseline performance and outperform existing UDAOD methods on multiple RGB-IR
datasets, including a new experimental protocol proposed in this paper based on
the FLIR-ADAS dataset.

</details>


### [40] [Dataset Ownership Verification for Pre-trained Masked Models](https://arxiv.org/abs/2507.12022)
*Yuechen Xie,Jie Song,Yicheng Shan,Xiaoyan Zhang,Yuanyu Wan,Shengxuming Zhang,Jiarui Duan,Mingli Song*

Main category: cs.CV

TL;DR: 提出了一种名为DOV4MM的新方法，用于验证掩码模型是否使用了特定的未标记数据集，以保护数据集所有者的权益。该方法通过分析重建掩码信息的难易程度来工作，并在实验中证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的数据集所有权验证技术不适用于日益增长的掩码模型，因此需要一种新的方法来保护数据集所有者的权益。

Method: DOV4MM是一种基于嵌入空间中重建掩码信息的难易程度差异的方法，用于验证可疑黑盒模型是否在特定的未标记数据集上进行了预训练。

Result: 通过在ImageNet-1K上的十个掩码图像模型和在WikiText-103上的四个掩码语言模型上进行验证，DOV4MM证明了其有效性。

Conclusion: DOV4MM成功验证了其有效性，拒绝了零假设，p值远低于0.05，并且优于之前所有的方法。

Abstract: High-quality open-source datasets have emerged as a pivotal catalyst driving
the swift advancement of deep learning, while facing the looming threat of
potential exploitation. Protecting these datasets is of paramount importance
for the interests of their owners. The verification of dataset ownership has
evolved into a crucial approach in this domain; however, existing verification
techniques are predominantly tailored to supervised models and contrastive
pre-trained models, rendering them ill-suited for direct application to the
increasingly prevalent masked models. In this work, we introduce the inaugural
methodology addressing this critical, yet unresolved challenge, termed Dataset
Ownership Verification for Masked Modeling (DOV4MM). The central objective is
to ascertain whether a suspicious black-box model has been pre-trained on a
particular unlabeled dataset, thereby assisting dataset owners in safeguarding
their rights. DOV4MM is grounded in our empirical observation that when a model
is pre-trained on the target dataset, the difficulty of reconstructing masked
information within the embedding space exhibits a marked contrast to models not
pre-trained on that dataset. We validated the efficacy of DOV4MM through ten
masked image models on ImageNet-1K and four masked language models on
WikiText-103. The results demonstrate that DOV4MM rejects the null hypothesis,
with a $p$-value considerably below 0.05, surpassing all prior approaches. Code
is available at https://github.com/xieyc99/DOV4MM.

</details>


### [41] [MVAR: MultiVariate AutoRegressive Air Pollutants Forecasting Model](https://arxiv.org/abs/2507.12023)
*Xu Fan,Zhihao Wang,Yuetan Lin,Yan Zhang,Yang Xiang,Hao Li*

Main category: cs.CV

TL;DR: 提出了一种名为MVAR的多变量空气污染物预测模型，该模型通过减少对长输入窗口的依赖和提高数据利用效率，实现了120小时的长期预测。该模型还能耦合气象预报，学习污染物间的相互作用及其空间响应。此外，还构建了一个包含75个中国北方城市6种主要污染物和气象数据的数据集，实验证明了该模型的优越性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注单一污染物预测，忽略了不同污染物之间的相互作用及其不同的空间响应。为了满足预测多种空气污染物这一实际需求，因此需要提出一种新的预测模型。

Method: 提出了一种多变量自回归空气污染物预测模型（MVAR），该模型减少了对长时间窗口输入的依赖，并提高了数据利用效率。该模型还设计了多变量自回归训练范式，实现了120小时的长期序列预测。此外，MVAR开发了气象耦合空间转换器块，能够灵活地耦合基于人工智能的气象预测，同时学习污染物之间的相互作用及其不同的空间响应。

Result: 与最先进的方法相比，所提出的MVAR模型表现更优，并验证了所提出架构的有效性。

Conclusion: 实验结果表明，所提出的模型优于最先进的方法，并验证了所提出架构的有效性。

Abstract: Air pollutants pose a significant threat to the environment and human health,
thus forecasting accurate pollutant concentrations is essential for pollution
warnings and policy-making. Existing studies predominantly focus on
single-pollutant forecasting, neglecting the interactions among different
pollutants and their diverse spatial responses. To address the practical needs
of forecasting multivariate air pollutants, we propose MultiVariate
AutoRegressive air pollutants forecasting model (MVAR), which reduces the
dependency on long-time-window inputs and boosts the data utilization
efficiency. We also design the Multivariate Autoregressive Training Paradigm,
enabling MVAR to achieve 120-hour long-term sequential forecasting.
Additionally, MVAR develops Meteorological Coupled Spatial Transformer block,
enabling the flexible coupling of AI-based meteorological forecasts while
learning the interactions among pollutants and their diverse spatial responses.
As for the lack of standardized datasets in air pollutants forecasting, we
construct a comprehensive dataset covering 6 major pollutants across 75 cities
in North China from 2018 to 2023, including ERA5 reanalysis data and FuXi-2.0
forecast data. Experimental results demonstrate that the proposed model
outperforms state-of-the-art methods and validate the effectiveness of the
proposed architecture.

</details>


### [42] [3D-MoRe: Unified Modal-Contextual Reasoning for Embodied Question Answering](https://arxiv.org/abs/2507.12026)
*Rongtao Xu,Han Gao,Mingming Yu,Dong An,Shunpeng Chen,Changwei Wang,Li Guo,Xiaodan Liang,Shibiao Xu*

Main category: cs.CV

TL;DR: 3D-MoRe 是一个利用基础模型生成大规模 3D-语言数据集的新范例，可提高室内场景问答和密集字幕的性能。


<details>
  <summary>Details</summary>
Motivation: 随着室内场景任务（如问答和密集字幕）对多样化和可扩展数据的需求不断增长，需要新的方法来生成 3D-语言数据集。

Method: 3D-MoRe 框架整合了多模态嵌入、跨模态交互和语言模型解码器，以处理自然语言指令和 3D 场景数据，利用基础模型生成大规模 3D-语言数据集。

Result: 使用 ScanNet 3D 场景数据集以及来自 ScanQA 和 ScanRefer 的文本注释，3D-MoRe 生成了 62,000 个问答对和 73,000 个跨越 1,513 个场景的对象描述。在 ScanQA 上，CIDEr 分数提高了 2.15%；在 ScanRefer 上，CIDEr@0.5 提高了 1.84%。

Conclusion: 3D-MoRe 在 ScanQA 和 ScanRefer 上显著优于最先进的基线，分别将 CIDEr 分数提高了 2.15% 和 1.84%，证明了其在两项任务中的有效性。

Abstract: With the growing need for diverse and scalable data in indoor scene tasks,
such as question answering and dense captioning, we propose 3D-MoRe, a novel
paradigm designed to generate large-scale 3D-language datasets by leveraging
the strengths of foundational models. The framework integrates key components,
including multi-modal embedding, cross-modal interaction, and a language model
decoder, to process natural language instructions and 3D scene data. This
approach facilitates enhanced reasoning and response generation in complex 3D
environments. Using the ScanNet 3D scene dataset, along with text annotations
from ScanQA and ScanRefer, 3D-MoRe generates 62,000 question-answer (QA) pairs
and 73,000 object descriptions across 1,513 scenes. We also employ various data
augmentation techniques and implement semantic filtering to ensure high-quality
data. Experiments on ScanQA demonstrate that 3D-MoRe significantly outperforms
state-of-the-art baselines, with the CIDEr score improving by 2.15\%.
Similarly, on ScanRefer, our approach achieves a notable increase in CIDEr@0.5
by 1.84\%, highlighting its effectiveness in both tasks. Our code and generated
datasets will be publicly released to benefit the community, and both can be
accessed on the https://3D-MoRe.github.io.

</details>


### [43] [Intra-view and Inter-view Correlation Guided Multi-view Novel Class Discovery](https://arxiv.org/abs/2507.12029)
*Xinhang Wan,Jiyuan Liu,Qian Qu,Suyuan Liu,Chuyu Zhang,Fangdi Wang,Xinwang Liu,En Zhu,Kunlun He*

Main category: cs.CV

TL;DR: 该研究提出了一种新的多视图新类别发现（NCD）框架（IICMVNCD），解决了现有方法只关注单视图数据和依赖不稳定的伪标签的问题。该框架通过视图内（矩阵分解）和视图间（视图关系引导）的相关性来提高性能，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有NCD方法主要关注单视图数据，忽略了多视图数据的普遍性，并且过度依赖伪标签进行聚类，导致性能不稳定。

Method: 提出了一种名为“视图内和视图间相关性引导的多视图新类别发现”（IICMVNCD）的框架。该框架在视图内层面利用矩阵分解来分解特征，以捕捉数据分布的一致性并建立样本间的成对关系。在视图间层面，利用已知类别间的视图关系来指导新类别的聚类，包括通过加权融合因子矩阵生成预测标签，并根据监督损失动态调整已知类别的视图权重，然后将这些权重转移到新类别的学习中。

Result: 实验结果验证了所提出方法（IICMVNCD）的有效性。

Conclusion: 该方法在多视图新类别发现（NCD）方面取得了有效性。

Abstract: In this paper, we address the problem of novel class discovery (NCD), which
aims to cluster novel classes by leveraging knowledge from disjoint known
classes. While recent advances have made significant progress in this area,
existing NCD methods face two major limitations. First, they primarily focus on
single-view data (e.g., images), overlooking the increasingly common multi-view
data, such as multi-omics datasets used in disease diagnosis. Second, their
reliance on pseudo-labels to supervise novel class clustering often results in
unstable performance, as pseudo-label quality is highly sensitive to factors
such as data noise and feature dimensionality. To address these challenges, we
propose a novel framework named Intra-view and Inter-view Correlation Guided
Multi-view Novel Class Discovery (IICMVNCD), which is the first attempt to
explore NCD in multi-view setting so far. Specifically, at the intra-view
level, leveraging the distributional similarity between known and novel
classes, we employ matrix factorization to decompose features into
view-specific shared base matrices and factor matrices. The base matrices
capture distributional consistency among the two datasets, while the factor
matrices model pairwise relationships between samples. At the inter-view level,
we utilize view relationships among known classes to guide the clustering of
novel classes. This includes generating predicted labels through the weighted
fusion of factor matrices and dynamically adjusting view weights of known
classes based on the supervision loss, which are then transferred to novel
class learning. Experimental results validate the effectiveness of our proposed
approach.

</details>


### [44] [MoViAD: Modular Visual Anomaly Detection](https://arxiv.org/abs/2507.12049)
*Manuel Barusco,Francesco Borsatti,Arianna Stropeni,Davide Dalle Pezze,Gian Antonio Susto*

Main category: cs.CV

TL;DR: MoViAD是一个用于VAD的库，支持各种场景和部署，易于使用和扩展。


<details>
  <summary>Details</summary>
Motivation: 加速VAD领域的研究和部署，解决VAD数据稀缺和无监督训练的挑战。

Method: MoViAD是一个包含最先进VAD模型、训练器、数据集和工具的库，支持持续学习、半监督、少样本、噪声等多种场景，并针对边缘和物联网部署进行了优化，提供量化和压缩工具。

Result: MoViAD提供了一个灵活且可扩展的平台，使机器学习工程师能够轻松部署定制模型，研究人员能够快速实验新方法。

Conclusion: MoViAD是一个全面的、模块化的库，旨在为VAD研究和部署提供快速简便的访问，支持多种场景和部署挑战。

Abstract: VAD is a critical field in machine learning focused on identifying deviations
from normal patterns in images, often challenged by the scarcity of anomalous
data and the need for unsupervised training. To accelerate research and
deployment in this domain, we introduce MoViAD, a comprehensive and highly
modular library designed to provide fast and easy access to state-of-the-art
VAD models, trainers, datasets, and VAD utilities. MoViAD supports a wide array
of scenarios, including continual, semi-supervised, few-shots, noisy, and many
more. In addition, it addresses practical deployment challenges through
dedicated Edge and IoT settings, offering optimized models and backbones, along
with quantization and compression utilities for efficient on-device execution
and distributed inference. MoViAD integrates a selection of backbones, robust
evaluation VAD metrics (pixel-level and image-level) and useful profiling tools
for efficiency analysis. The library is designed for fast, effortless
deployment, enabling machine learning engineers to easily use it for their
specific setup with custom models, datasets, and backbones. At the same time,
it offers the flexibility and extensibility researchers need to develop and
experiment with new methods.

</details>


### [45] [InstructFLIP: Exploring Unified Vision-Language Model for Face Anti-spoofing](https://arxiv.org/abs/2507.12060)
*Kun-Hsiang Lin,Yu-Wen Tseng,Kang-Yang Huang,Jhih-Ciang Wu,Wen-Huang Cheng*

Main category: cs.CV

TL;DR: InstructFLIP利用视觉语言模型和元域策略，通过文本指导增强人脸反欺骗的跨域泛化能力，提升准确性并减少训练冗余。


<details>
  <summary>Details</summary>
Motivation: 现有的人脸反欺骗（FAS）技术在跨域泛化方面存在局限，主要体现在对攻击类型的语义理解不足以及跨域训练冗余。本研究旨在通过引入VLM和元域策略来克服这些挑战。

Method: InstructFLIP是一个新颖的、经过指令微调的框架，它集成VLM来增强对视觉输入的感知，并通过元域策略学习一个能跨多个域泛化的统一模型。该框架将指令显式解耦为内容和风格组件，分别关注欺骗的核心语义以及环境和摄像头的变化。

Result: 实验证明，InstructFLIP在人脸反欺骗任务中表现出色，其准确性超越了现有最优（SOTA）模型，并显著降低了跨不同FAS域的训练冗余。

Conclusion: InstructFLIP通过利用视觉语言模型（VLM）和元域策略，在人脸反欺骗（FAS）领域取得了显著进展，有效解决了跨域泛化中的语义理解和训练冗余挑战。

Abstract: Face anti-spoofing (FAS) aims to construct a robust system that can withstand
diverse attacks. While recent efforts have concentrated mainly on cross-domain
generalization, two significant challenges persist: limited semantic
understanding of attack types and training redundancy across domains. We
address the first by integrating vision-language models (VLMs) to enhance the
perception of visual input. For the second challenge, we employ a meta-domain
strategy to learn a unified model that generalizes well across multiple
domains. Our proposed InstructFLIP is a novel instruction-tuned framework that
leverages VLMs to enhance generalization via textual guidance trained solely on
a single domain. At its core, InstructFLIP explicitly decouples instructions
into content and style components, where content-based instructions focus on
the essential semantics of spoofing, and style-based instructions consider
variations related to the environment and camera characteristics. Extensive
experiments demonstrate the effectiveness of InstructFLIP by outperforming SOTA
models in accuracy and substantially reducing training redundancy across
diverse domains in FAS. Project website is available at
https://kunkunlin1221.github.io/InstructFLIP.

</details>


### [46] [MS-DETR: Towards Effective Video Moment Retrieval and Highlight Detection by Joint Motion-Semantic Learning](https://arxiv.org/abs/2507.12062)
*Hongxu Ma,Guanshuo Wang,Fufu Yu,Qiong Jia,Shouhong Ding*

Main category: cs.CV

TL;DR: 提出MS-DETR框架，通过结合运动和语义信息，并采用去噪学习策略，提高了视频矩检索和高亮检测的性能。


<details>
  <summary>Details</summary>
Motivation: DETR类联合框架在视频矩检索（MR）和高亮检测（HD）任务方面取得了显著进展，但视频内容中时间运动和空间语义之间的复杂关系仍有待挖掘。

Method: 提出了一种名为MS-DETR的框架，该框架通过统一学习来捕获丰富的运动-语义特征，以完成MR/HD任务。编码器首先明确地在运动和语义维度内对模型进行解耦的模式内相关性，并以给定的文本查询为指导。随后，解码器利用跨时间运动和空间语义维度的任务相关性，以实现MR的精确查询引导定位和HD的精细高亮边界划分。此外，为了解决MR/HD数据集中固有的稀疏困境，通过生成策略丰富了两个维度的语料库，并提出对比去噪学习，以确保上述组件能够稳健有效地学习。

Result: MS-DETR在四个MR/HD基准测试中取得了优于现有最先进方法的性能。

Conclusion: MS-DETR在四个MR/HD基准测试中表现优于现有最先进模型。

Abstract: Video Moment Retrieval (MR) and Highlight Detection (HD) aim to pinpoint
specific moments and assess clip-wise relevance based on the text query. While
DETR-based joint frameworks have made significant strides, there remains
untapped potential in harnessing the intricate relationships between temporal
motion and spatial semantics within video content. In this paper, we propose
the Motion-Semantics DETR (MS-DETR), a framework that captures rich
motion-semantics features through unified learning for MR/HD tasks. The encoder
first explicitly models disentangled intra-modal correlations within motion and
semantics dimensions, guided by the given text queries. Subsequently, the
decoder utilizes the task-wise correlation across temporal motion and spatial
semantics dimensions to enable precise query-guided localization for MR and
refined highlight boundary delineation for HD. Furthermore, we observe the
inherent sparsity dilemma within the motion and semantics dimensions of MR/HD
datasets. To address this issue, we enrich the corpus from both dimensions by
generation strategies and propose contrastive denoising learning to ensure the
above components learn robustly and effectively. Extensive experiments on four
MR/HD benchmarks demonstrate that our method outperforms existing
state-of-the-art models by a margin. Our code is available at
https://github.com/snailma0229/MS-DETR.git.

</details>


### [47] [YOLOv8-SMOT: An Efficient and Robust Framework for Real-Time Small Object Tracking via Slice-Assisted Training and Adaptive Association](https://arxiv.org/abs/2507.12087)
*Xiang Yu,Xinyao Liu,Guang Liang*

Main category: cs.CV

TL;DR: 该研究提出了一种用于无人机视角下小型、敏捷多目标跟踪（SMOT）的创新方法，解决了目标外观特征稀疏、运动纠缠和频繁遮挡等难题。通过名为SliceTrain的训练框架和不依赖外观信息的OC-SORT改进跟踪器（包含EMA和自适应相似度度量），在SMOT4SB挑战赛中取得了优异成绩。


<details>
  <summary>Details</summary>
Motivation: 从无人机（UAV）视角跟踪小型、敏捷的多目标（SMOT），例如鸟类，是一个极具挑战性的计算机视觉任务。其困难主要源于三个方面：目标外观特征的极端稀疏性、由相机和目标自身动力学引起的复杂运动纠缠，以及密集群体行为导致的频繁遮挡和身份模糊。

Method: 该方法采用了跟踪检测范式，并在检测和关联层面进行了创新。在检测方面，提出了一种名为SliceTrain的系统性训练增强框架，通过确定性全覆盖切片和切片级随机增强来解决高分辨率图像训练中小型物体学习不足的问题。在跟踪方面，设计了一个完全独立于外观信息的鲁棒跟踪器，通过集成运动方向维持（EMA）机制和结合边界框扩展与距离惩罚的自适应相似度度量到OC-SORT框架中，能够稳定处理不规则运动并保持目标身份。

Result: 在SMOT4SB公共测试集上取得了55.205的SO-HOTA分数，达到了最先进的性能。

Conclusion: 该方法在SMOT4SB公共测试集上达到了55.205的SO-HOTA分数，验证了其在解决复杂现实世界SMOT问题上的有效性和先进性。

Abstract: Tracking small, agile multi-objects (SMOT), such as birds, from an Unmanned
Aerial Vehicle (UAV) perspective is a highly challenging computer vision task.
The difficulty stems from three main sources: the extreme scarcity of target
appearance features, the complex motion entanglement caused by the combined
dynamics of the camera and the targets themselves, and the frequent occlusions
and identity ambiguity arising from dense flocking behavior. This paper details
our championship-winning solution in the MVA 2025 "Finding Birds" Small
Multi-Object Tracking Challenge (SMOT4SB), which adopts the
tracking-by-detection paradigm with targeted innovations at both the detection
and association levels. On the detection side, we propose a systematic training
enhancement framework named \textbf{SliceTrain}. This framework, through the
synergy of 'deterministic full-coverage slicing' and 'slice-level stochastic
augmentation, effectively addresses the problem of insufficient learning for
small objects in high-resolution image training. On the tracking side, we
designed a robust tracker that is completely independent of appearance
information. By integrating a \textbf{motion direction maintenance (EMA)}
mechanism and an \textbf{adaptive similarity metric} combining \textbf{bounding
box expansion and distance penalty} into the OC-SORT framework, our tracker can
stably handle irregular motion and maintain target identities. Our method
achieves state-of-the-art performance on the SMOT4SB public test set, reaching
an SO-HOTA score of \textbf{55.205}, which fully validates the effectiveness
and advancement of our framework in solving complex real-world SMOT problems.
The source code will be made available at
https://github.com/Salvatore-Love/YOLOv8-SMOT.

</details>


### [48] [BRUM: Robust 3D Vehicle Reconstruction from 360 Sparse Images](https://arxiv.org/abs/2507.12095)
*Davide Di Nucci,Matteo Tomei,Guido Borghi,Luca Ciuffreda,Roberto Vezzani,Rita Cucchiara*

Main category: cs.CV

TL;DR: 该研究提出了一种改进高斯泼溅的方法，使用稀疏视图进行车辆三维重建，并取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有三维重建方法依赖密集输入视图的局限性，以提高其在车辆检查、预测性维护和城市规划等实际应用中的可用性。

Method: 通过集成选择性光度损失和使用DUSt3R架构替代标准的Structure-from-Motion流水线来增强高斯泼溅技术，以提高相机姿态估计的准确性，并利用深度图和鲁棒的姿态估计架构来合成新视图和增强训练数据。

Result: 实验结果表明，该方法在稀疏视图输入条件下，能够实现高质量的三维重建，性能优于现有方法。

Conclusion: 该方法在稀疏视图输入的条件下，实现了高质量的车辆三维重建，并在多个基准测试中展现了最先进的性能。

Abstract: Accurate 3D reconstruction of vehicles is vital for applications such as
vehicle inspection, predictive maintenance, and urban planning. Existing
methods like Neural Radiance Fields and Gaussian Splatting have shown
impressive results but remain limited by their reliance on dense input views,
which hinders real-world applicability. This paper addresses the challenge of
reconstructing vehicles from sparse-view inputs, leveraging depth maps and a
robust pose estimation architecture to synthesize novel views and augment
training data. Specifically, we enhance Gaussian Splatting by integrating a
selective photometric loss, applied only to high-confidence pixels, and
replacing standard Structure-from-Motion pipelines with the DUSt3R architecture
to improve camera pose estimation. Furthermore, we present a novel dataset
featuring both synthetic and real-world public transportation vehicles,
enabling extensive evaluation of our approach. Experimental results demonstrate
state-of-the-art performance across multiple benchmarks, showcasing the
method's ability to achieve high-quality reconstructions even under constrained
input conditions.

</details>


### [49] [DeepShade: Enable Shade Simulation by Text-conditioned Image Generation](https://arxiv.org/abs/2507.12103)
*Longchao Da,Xiangrui Liu,Mithun Shivakoti,Thirulogasankar Pranav Kutralingam,Yezhou Yang,Hua Wei*

Main category: cs.CV

TL;DR: 该研究通过3D模拟和名为DeepShade的扩散模型，学习并生成城市遮阳信息，以改善路线规划和城市规划，应对热浪威胁。


<details>
  <summary>Details</summary>
Motivation: 为了应对全球变暖背景下热浪对公众健康构成的威胁，并改进现有的路线规划系统（如在线地图）未能充分考虑遮阳信息的问题，本研究旨在开发一种能够生成准确遮阳信息的模型。

Method: 提出了一种名为DeepShade的基于扩散的模型，该模型结合了RGB图像和Canny边缘层，并通过对比学习来捕捉遮阳的动态变化。同时，利用Blender进行3D模拟生成了包含遮阳信息的丰富数据集，并解决了从卫星图像中提取遮阳信息的挑战。

Result: 通过在亚利桑那州坦佩市的实际路线规划中应用遮阳预测，证明了该方法的有效性，并认为该研究成果对极端高温天气下的城市规划和环境应用具有重要意义。

Conclusion: 该研究通过结合3D模拟和深度学习，解决了在城市规划和路线规划中利用遮阳信息的技术难题，并展示了其在实际应用中的潜力。

Abstract: Heatwaves pose a significant threat to public health, especially as global
warming intensifies. However, current routing systems (e.g., online maps) fail
to incorporate shade information due to the difficulty of estimating shades
directly from noisy satellite imagery and the limited availability of training
data for generative models. In this paper, we address these challenges through
two main contributions. First, we build an extensive dataset covering diverse
longitude-latitude regions, varying levels of building density, and different
urban layouts. Leveraging Blender-based 3D simulations alongside building
outlines, we capture building shadows under various solar zenith angles
throughout the year and at different times of day. These simulated shadows are
aligned with satellite images, providing a rich resource for learning shade
patterns. Second, we propose the DeepShade, a diffusion-based model designed to
learn and synthesize shade variations over time. It emphasizes the nuance of
edge features by jointly considering RGB with the Canny edge layer, and
incorporates contrastive learning to capture the temporal change rules of
shade. Then, by conditioning on textual descriptions of known conditions (e.g.,
time of day, solar angles), our framework provides improved performance in
generating shade images. We demonstrate the utility of our approach by using
our shade predictions to calculate shade ratios for real-world route planning
in Tempe, Arizona. We believe this work will benefit society by providing a
reference for urban planning in extreme heat weather and its potential
practical applications in the environment.

</details>


### [50] [Out-of-distribution data supervision towards biomedical semantic segmentation](https://arxiv.org/abs/2507.12105)
*Yiquan Gao,Duohui Xu*

Main category: cs.CV

TL;DR: Med-OoD框架通过引入OoD数据监督，解决了生物医学图像分割中的误分类问题，无需额外数据或标注，并在Lizard数据集上提升了性能，同时探索了仅使用OoD数据训练的新范式。


<details>
  <summary>Details</summary>
Motivation: 生物医学分割网络在处理有限和不完美的数据集时，容易在前景和背景对象之间产生意外的误分类。受 OoD 数据在其他视觉任务中强大能力的启发，需要一种方法来解决这个问题。

Method: 提出了一种名为 Med-OoD 的数据中心框架，通过引入 OoD（分布外）数据监督来解决生物医学分割中的误分类问题，且无需外部数据源、特征正则化目标或额外注释，可无缝集成到现有分割网络而无需修改架构。

Result: Med-OoD 框架能有效防止各种分割网络在医学图像上出现像素误分类，并在 Lizard 数据集上取得了显著的性能改进。此外，仅使用不含前景类别标签的 OoD 数据训练出的医学分割网络，测试结果达到了 76.1% 的 mIoU。

Conclusion: Med-OoD 框架通过引入OoD数据监督，成功解决了生物医学分割网络在有限和不完美数据集上遇到的前景/背景误分类问题，并在 Lizard 数据集上实现了显著的性能提升。此外，研究还提出了一种仅使用不含前景类别标签的OoD数据训练医学分割网络的新范式，并取得了令人惊讶的 76.1% mIoU 的测试结果，有望引发对OoD数据作用的重新思考。

Abstract: Biomedical segmentation networks easily suffer from the unexpected
misclassification between foreground and background objects when learning on
limited and imperfect medical datasets. Inspired by the strong power of
Out-of-Distribution (OoD) data on other visual tasks, we propose a data-centric
framework, Med-OoD to address this issue by introducing OoD data supervision
into fully-supervised biomedical segmentation with none of the following needs:
(i) external data sources, (ii) feature regularization objectives, (iii)
additional annotations. Our method can be seamlessly integrated into
segmentation networks without any modification on the architectures. Extensive
experiments show that Med-OoD largely prevents various segmentation networks
from the pixel misclassification on medical images and achieves considerable
performance improvements on Lizard dataset. We also present an emerging
learning paradigm of training a medical segmentation network completely using
OoD data devoid of foreground class labels, surprisingly turning out 76.1% mIoU
as test result. We hope this learning paradigm will attract people to rethink
the roles of OoD data. Code is made available at
https://github.com/StudioYG/Med-OoD.

</details>


### [51] [Non-Adaptive Adversarial Face Generation](https://arxiv.org/abs/2507.12107)
*Sunpill Kim,Seunghun Paik,Chanwoo Hwang,Minsu Kim,Jae Hong Seo*

Main category: cs.CV

TL;DR: 提出一种新的对抗性人脸生成方法，利用人脸识别系统特征空间的结构特性，无需迭代优化和模型可转移性，即可实现高成功率和可控属性。


<details>
  <summary>Details</summary>
Motivation: 为了应对人脸识别系统（FRS）面临的对抗性攻击带来的安全和隐私威胁，特别是当这些系统用于身份验证时，提出一种新的对抗性人脸生成方法。

Method: 该方法利用人脸识别系统特征空间中的结构特性，特别是同一属性个体的子球体，生成对抗性人脸。与基于迭代优化的方法不同，它只需要一次非自适应查询（100张人脸图像），无需依赖可转移性或开源模型。

Result: 该方法在仅需一次非自适应查询（100张人脸图像）的情况下，针对AWS的CompareFaces API实现了超过93%的高成功率。此外，该方法还能生成具有攻击者选择的高层属性的对抗性人脸。

Conclusion: 该方法通过利用人脸识别系统（FRS）特征空间中具有相同属性（例如性别或种族）的个体形成的子球体，实现了高成功率（超过93%）的单次非自适应查询，并能生成具有可控高层属性的对抗性人脸。

Abstract: Adversarial attacks on face recognition systems (FRSs) pose serious security
and privacy threats, especially when these systems are used for identity
verification. In this paper, we propose a novel method for generating
adversarial faces-synthetic facial images that are visually distinct yet
recognized as a target identity by the FRS. Unlike iterative optimization-based
approaches (e.g., gradient descent or other iterative solvers), our method
leverages the structural characteristics of the FRS feature space. We figure
out that individuals sharing the same attribute (e.g., gender or race) form an
attributed subsphere. By utilizing such subspheres, our method achieves both
non-adaptiveness and a remarkably small number of queries. This eliminates the
need for relying on transferability and open-source surrogate models, which
have been a typical strategy when repeated adaptive queries to commercial FRSs
are impossible. Despite requiring only a single non-adaptive query consisting
of 100 face images, our method achieves a high success rate of over 93% against
AWS's CompareFaces API at its default threshold. Furthermore, unlike many
existing attacks that perturb a given image, our method can deliberately
produce adversarial faces that impersonate the target identity while exhibiting
high-level attributes chosen by the adversary.

</details>


### [52] [LidarPainter: One-Step Away From Any Lidar View To Novel Guidance](https://arxiv.org/abs/2507.12114)
*Yuzhou Ji,Ke Ma,Hong Cai,Anchun Zhang,Lizhuang Ma,Xin Tan*

Main category: cs.CV

TL;DR: LidarPainter is a fast and efficient diffusion model for dynamic driving scene reconstruction that improves view consistency and quality, and allows for stylized generation.


<details>
  <summary>Details</summary>
Motivation: Dynamic driving scene reconstruction is of great importance in fields like digital twin system and autonomous driving simulation. However, existing methods suffer from unacceptable degradation on novel trajectories due to inconsistency, deformation, and time consumption.

Method: LidarPainter, a one-step diffusion model

Result: Extensive experiments show that LidarPainter outperforms state-of-the-art methods in speed (7x faster than StreetCrafter), quality and resource efficiency (using one fifth of GPU memory). It also supports stylized generation using text prompts.

Conclusion: LidarPainter is a one-step diffusion model that recovers consistent driving views from sparse LiDAR condition and artifact-corrupted renderings in real-time, enabling high-fidelity lane shifts in driving scene reconstruction. It outperforms state-of-the-art methods in speed, quality and resource efficiency, and supports stylized generation using text prompts.

Abstract: Dynamic driving scene reconstruction is of great importance in fields like
digital twin system and autonomous driving simulation. However, unacceptable
degradation occurs when the view deviates from the input trajectory, leading to
corrupted background and vehicle models. To improve reconstruction quality on
novel trajectory, existing methods are subject to various limitations including
inconsistency, deformation, and time consumption. This paper proposes
LidarPainter, a one-step diffusion model that recovers consistent driving views
from sparse LiDAR condition and artifact-corrupted renderings in real-time,
enabling high-fidelity lane shifts in driving scene reconstruction. Extensive
experiments show that LidarPainter outperforms state-of-the-art methods in
speed, quality and resource efficiency, specifically 7 x faster than
StreetCrafter with only one fifth of GPU memory required. LidarPainter also
supports stylized generation using text prompts such as "foggy" and "night",
allowing for a diverse expansion of the existing asset library.

</details>


### [53] [Open-Vocabulary Indoor Object Grounding with 3D Hierarchical Scene Graph](https://arxiv.org/abs/2507.12123)
*Sergey Linok,Gleb Naumov*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We propose OVIGo-3DHSG method - Open-Vocabulary Indoor Grounding of objects
using 3D Hierarchical Scene Graph. OVIGo-3DHSG represents an extensive indoor
environment over a Hierarchical Scene Graph derived from sequences of RGB-D
frames utilizing a set of open-vocabulary foundation models and sensor data
processing. The hierarchical representation explicitly models spatial relations
across floors, rooms, locations, and objects. To effectively address complex
queries involving spatial reference to other objects, we integrate the
hierarchical scene graph with a Large Language Model for multistep reasoning.
This integration leverages inter-layer (e.g., room-to-object) and intra-layer
(e.g., object-to-object) connections, enhancing spatial contextual
understanding. We investigate the semantic and geometry accuracy of
hierarchical representation on Habitat Matterport 3D Semantic multi-floor
scenes. Our approach demonstrates efficient scene comprehension and robust
object grounding compared to existing methods. Overall OVIGo-3DHSG demonstrates
strong potential for applications requiring spatial reasoning and understanding
of indoor environments. Related materials can be found at
https://github.com/linukc/OVIGo-3DHSG.

</details>


### [54] [Block-based Symmetric Pruning and Fusion for Efficient Vision Transformers](https://arxiv.org/abs/2507.12125)
*Yi-Kuan Hsieh,Jun-Wei Hsieh,Xin Li,Yu-Ming Chang,Yu-Chee Tseng*

Main category: cs.CV

TL;DR: 提出 BSPF-ViT 来解决 ViT 的高计算成本问题，通过块状对称修剪和融合联合优化 Q/K 标记，在提高准确率的同时显著降低了计算开销。


<details>
  <summary>Details</summary>
Motivation: ViT 的高计算成本限制了其实际应用。现有的通过修剪标记来降低 ViT 复杂性的方法，常常因为独立修剪 Q/K 标记而牺牲准确性，忽略了标记间的交互。

Method: 提出了一种新颖的块状对称修剪和融合（BSPF-ViT）方法，通过联合优化 Q/K 标记来降低 ViT 的计算复杂度。该方法考虑了标记交互，并通过相似性融合压缩保留的标记。它利用 Q/K 标记的共享权重来加速修剪过程，仅修剪上三角部分。

Result: BSPF-ViT 在所有修剪水平上持续优于最先进的 ViT 方法，在 DeiT-T 上将 ImageNet 分类准确率提高了 1.3%，在 DeiT-S 上提高了 2.0%，同时将计算开销降低了 50%。它在各种 ViT 上实现了 40% 的加速和准确率的提升。

Conclusion: BSPF-ViT 通过联合优化 Q/K 标记的修剪，在效率和准确性方面优于最先进的 ViT 方法，在 ImageNet 分类上实现了准确率的提高和计算成本的降低。

Abstract: Vision Transformer (ViT) has achieved impressive results across various
vision tasks, yet its high computational cost limits practical applications.
Recent methods have aimed to reduce ViT's $O(n^2)$ complexity by pruning
unimportant tokens. However, these techniques often sacrifice accuracy by
independently pruning query (Q) and key (K) tokens, leading to performance
degradation due to overlooked token interactions. To address this limitation,
we introduce a novel {\bf Block-based Symmetric Pruning and Fusion} for
efficient ViT (BSPF-ViT) that optimizes the pruning of Q/K tokens jointly.
Unlike previous methods that consider only a single direction, our approach
evaluates each token and its neighbors to decide which tokens to retain by
taking token interaction into account. The retained tokens are compressed
through a similarity fusion step, preserving key information while reducing
computational costs. The shared weights of Q/K tokens create a symmetric
attention matrix, allowing pruning only the upper triangular part for speed up.
BSPF-ViT consistently outperforms state-of-the-art ViT methods at all pruning
levels, increasing ImageNet classification accuracy by 1.3% on DeiT-T and 2.0%
on DeiT-S, while reducing computational overhead by 50%. It achieves 40%
speedup with improved accuracy across various ViTs.

</details>


### [55] [Learning Pixel-adaptive Multi-layer Perceptrons for Real-time Image Enhancement](https://arxiv.org/abs/2507.12135)
*Junyu Lou,Xiaorui Zhao,Kexuan Shi,Shuhang Gu*

Main category: cs.CV

TL;DR: 提出了一种新的BPAM框架，结合了双边网格和像素自适应多层感知机，解决了颜色关系建模和局部变化处理的挑战，实现了高性能和实时处理。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的双边网格处理方法仅限于线性变换，难以对复杂的颜色关系进行建模；而传统的多层感知机方法由于使用全局共享参数，难以处理局部变化。

Method: 提出了一种双边网格像素自适应多层感知机（BPAM）框架，该框架生成包含多层感知机参数的双边网格，允许每个像素根据其空间坐标和强度值动态检索独特的变换参数，并提出了一种新的网格分解策略，将多层感知机参数分类存储在单独的子网格中，并使用多通道引导图从相应的子网格中提取特定类别的参数。

Result: BPAM框架在公共数据集上的广泛实验表明，该方法在性能上优于最先进的方法，同时保持了实时处理能力。

Conclusion: BPAM框架通过结合双边网格的空间建模能力和多层感知机的非线性映射能力，解决了现有方法的局限性，实现了对复杂颜色关系的建模和局部变化的适应，并在性能和实时性方面优于现有方法。

Abstract: Deep learning-based bilateral grid processing has emerged as a promising
solution for image enhancement, inherently encoding spatial and intensity
information while enabling efficient full-resolution processing through slicing
operations. However, existing approaches are limited to linear affine
transformations, hindering their ability to model complex color relationships.
Meanwhile, while multi-layer perceptrons (MLPs) excel at non-linear mappings,
traditional MLP-based methods employ globally shared parameters, which is hard
to deal with localized variations. To overcome these dual challenges, we
propose a Bilateral Grid-based Pixel-Adaptive Multi-layer Perceptron (BPAM)
framework. Our approach synergizes the spatial modeling of bilateral grids with
the non-linear capabilities of MLPs. Specifically, we generate bilateral grids
containing MLP parameters, where each pixel dynamically retrieves its unique
transformation parameters and obtain a distinct MLP for color mapping based on
spatial coordinates and intensity values. In addition, we propose a novel grid
decomposition strategy that categorizes MLP parameters into distinct types
stored in separate subgrids. Multi-channel guidance maps are used to extract
category-specific parameters from corresponding subgrids, ensuring effective
utilization of color information during slicing while guiding precise parameter
generation. Extensive experiments on public datasets demonstrate that our
method outperforms state-of-the-art methods in performance while maintaining
real-time processing capabilities.

</details>


### [56] [AD-GS: Object-Aware B-Spline Gaussian Splatting for Self-Supervised Autonomous Driving](https://arxiv.org/abs/2507.12137)
*Jiawei Xu,Kai Deng,Zexin Fan,Shenlong Wang,Jin Xie,Jian Yang*

Main category: cs.CV

TL;DR: AD-GS是一个无需注释的自监督框架，通过创新的运动建模和场景分解技术，实现了高质量的驾驶场景渲染，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了在自动驾驶模拟中实现高质量的动态城市驾驶场景建模和渲染，同时克服当前方法依赖昂贵手动注释或自监督方法在运动建模和场景分解方面的不足，提出了AD-GS。

Method: AD-GS是一个新颖的自监督框架，利用可学习运动模型（结合了局部感知的B样条曲线和全局感知的三角函数）来精确建模动态对象。它通过简化的伪2D分割自动分割场景，并使用动态高斯和双向时间可见性掩码来表示对象。此外，该模型还包括可见性推理和物理刚性正则化以增强鲁棒性。

Result: AD-GS在无需注释的情况下，显著优于当前最先进的无注释方法，并且在性能上可与依赖注释的方法相媲美。

Conclusion: AD-GS通过其创新的可学习运动模型、简化的伪2D分割以及可见性推理和物理刚性正则化，实现了高质量的自由视角渲染，无需手动注释，性能优于现有无注释方法，并可与有注释方法相媲美。

Abstract: Modeling and rendering dynamic urban driving scenes is crucial for
self-driving simulation. Current high-quality methods typically rely on costly
manual object tracklet annotations, while self-supervised approaches fail to
capture dynamic object motions accurately and decompose scenes properly,
resulting in rendering artifacts. We introduce AD-GS, a novel self-supervised
framework for high-quality free-viewpoint rendering of driving scenes from a
single log. At its core is a novel learnable motion model that integrates
locality-aware B-spline curves with global-aware trigonometric functions,
enabling flexible yet precise dynamic object modeling. Rather than requiring
comprehensive semantic labeling, AD-GS automatically segments scenes into
objects and background with the simplified pseudo 2D segmentation, representing
objects using dynamic Gaussians and bidirectional temporal visibility masks.
Further, our model incorporates visibility reasoning and physically rigid
regularization to enhance robustness. Extensive evaluations demonstrate that
our annotation-free model significantly outperforms current state-of-the-art
annotation-free methods and is competitive with annotation-dependent
approaches.

</details>


### [57] [Neural Human Pose Prior](https://arxiv.org/abs/2507.12138)
*Michal Heker,Sefy Kararlitsky,David Tolpin*

Main category: cs.CV

TL;DR: 提出了一种基于归一化流和RealNVP的人类姿态建模方法，解决了6D旋转流形上的分布建模问题，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 介绍一种基于数据驱动的、原则性的方法来对人类姿态的神经先验进行建模。

Method: 使用归一化流（normalizing flows）对人类姿态进行建模，并利用RealNVP学习姿态的灵活密度，通过在训练过程中逆转Gram-Schmidt过程来解决在有效6D旋转流形上进行分布建模的挑战。

Result: 通过定性和定量评估证明了学习到的先验的有效性，并通过消融研究分析了其影响。

Conclusion: 本工作为将姿态先验集成到人体运动捕捉和重建流程中提供了坚实的概率基础。

Abstract: We introduce a principled, data-driven approach for modeling a neural prior
over human body poses using normalizing flows. Unlike heuristic or
low-expressivity alternatives, our method leverages RealNVP to learn a flexible
density over poses represented in the 6D rotation format. We address the
challenge of modeling distributions on the manifold of valid 6D rotations by
inverting the Gram-Schmidt process during training, enabling stable learning
while preserving downstream compatibility with rotation-based frameworks. Our
architecture and training pipeline are framework-agnostic and easily
reproducible. We demonstrate the effectiveness of the learned prior through
both qualitative and quantitative evaluations, and we analyze its impact via
ablation studies. This work provides a sound probabilistic foundation for
integrating pose priors into human motion capture and reconstruction pipelines.

</details>


### [58] [Fine-Grained Image Recognition from Scratch with Teacher-Guided Data Augmentation](https://arxiv.org/abs/2507.12157)
*Edwin Arkel Rios,Fernando Mikael,Oswin Gosal,Femiloye Oyerinde,Hao-Chun Liang,Bo-Cheng Lai,Min-Chun Hu*

Main category: cs.CV

TL;DR: 本研究提出了TGDA框架，可以从头开始训练高性能的细粒度图像识别（FGIR）模型，无需依赖预训练模型。该框架通过数据增强和知识蒸馏实现，并支持L-RNets和ViTFS等高效特定任务架构。实验证明，TGDA方法在准确性方面可与预训练模型相媲美，同时显著减少了参数量、计算量和训练数据需求，尤其是在低分辨率场景下。


<details>
  <summary>Details</summary>
Motivation: 传统的FGIR方法依赖于在大型数据集（如ImageNet）上预训练的模型，这限制了其在资源受限环境中的适应性，并阻碍了针对FGIR独特挑战量身定制的特定任务架构的发展。本研究旨在挑战这种对预训练模型的依赖，并证明可以从头开始训练高性能的FGIR系统。

Method: TGDA框架集成数据感知增强和通过细粒度感知教师模型的弱监督（通过知识蒸馏实现）。该框架支持特定任务和硬件感知的架构设计，如用于低分辨率FGIR的LRNets和用于高效推理的ViTFS系列Vision Transformer。

Result: 在三个FGIR基准的各种低分辨率和高分辨率输入设置下进行的广泛实验表明，TGDA框架训练的模型在性能上持续匹配或超越了最先进的预训练模型。特别是在低分辨率设置下，使用TGDA训练的LRNets的准确率比先前的方法提高了23%，同时参数量减少了多达20.6倍，FLOPs更低，并且所需的训练数据也显著减少。同样，ViTFS-T在使用的可训练参数数量减少15.3倍且所需数据量减少多个数量级的情况下，可以匹配在ImageNet-21k上预训练的ViT B-16的性能。

Conclusion: TGDA框架有潜力成为预训练的适应性替代方案，为更高效的细粒度视觉系统铺平道路。

Abstract: Fine-grained image recognition (FGIR) aims to distinguish visually similar
sub-categories within a broader class, such as identifying bird species. While
most existing FGIR methods rely on backbones pretrained on large-scale datasets
like ImageNet, this dependence limits adaptability to resource-constrained
environments and hinders the development of task-specific architectures
tailored to the unique challenges of FGIR.
  In this work, we challenge the conventional reliance on pretrained models by
demonstrating that high-performance FGIR systems can be trained entirely from
scratch. We introduce a novel training framework, TGDA, that integrates
data-aware augmentation with weak supervision via a fine-grained-aware teacher
model, implemented through knowledge distillation. This framework unlocks the
design of task-specific and hardware-aware architectures, including LRNets for
low-resolution FGIR and ViTFS, a family of Vision Transformers optimized for
efficient inference.
  Extensive experiments across three FGIR benchmarks over diverse settings
involving low-resolution and high-resolution inputs show that our method
consistently matches or surpasses state-of-the-art pretrained counterparts. In
particular, in the low-resolution setting, LRNets trained with TGDA improve
accuracy by up to 23\% over prior methods while requiring up to 20.6x less
parameters, lower FLOPs, and significantly less training data. Similarly,
ViTFS-T can match the performance of a ViT B-16 pretrained on ImageNet-21k
while using 15.3x fewer trainable parameters and requiring orders of magnitudes
less data. These results highlight TGDA's potential as an adaptable alternative
to pretraining, paving the way for more efficient fine-grained vision systems.

</details>


### [59] [Hybrid Ensemble Approaches: Optimal Deep Feature Fusion and Hyperparameter-Tuned Classifier Ensembling for Enhanced Brain Tumor Classification](https://arxiv.org/abs/2507.12177)
*Zahid Ullah,Dragan Pamucar,Jihie Kim*

Main category: cs.CV

TL;DR: 通过结合深度学习特征提取和机器学习分类，并优化超参数，该研究提出的双集成框架提高了脑肿瘤MRI诊断的准确性。


<details>
  <summary>Details</summary>
Motivation: 由于人类专家在解读MRI图像时可能存在疲劳、经验不足或图像细节限制等问题，导致脑肿瘤诊断的准确性受到影响（例如漏诊小肿瘤或误识别），因此需要一种更精确、更可靠的诊断方法。

Method: 该研究提出了一种新颖的双集成框架，结合了预训练深度学习（DL）模型的集成以提取特征，以及经过微调的机器学习（ML）模型的集成以进行分类。具体方法包括：1. 预处理和增强MRI图像；2. 利用预训练的深度卷积神经网络和视觉Transformer网络提取图像的深度特征（迁移学习）；3. 对机器学习分类器进行超参数微调；4. 集成深度特征和机器学习分类器以提高分类性能。实验在三个公开的Kaggle脑部MRI肿瘤数据集上进行评估，并通过消融研究验证了各组件的有效性。

Result: 该研究提出的双集成框架在脑肿瘤分类任务上取得了优于现有技术的成果，其中超参数微调相比单纯的集成方法能带来显著的性能提升。

Conclusion: 该研究提出的双集成框架通过融合深度特征和机器学习分类器，并进行超参数微调，在脑肿瘤分类任务上取得了优于现有技术的成果，并验证了各组成部分对提高诊断准确性的贡献。

Abstract: Magnetic Resonance Imaging (MRI) is widely recognized as the most reliable
tool for detecting tumors due to its capability to produce detailed images that
reveal their presence. However, the accuracy of diagnosis can be compromised
when human specialists evaluate these images. Factors such as fatigue, limited
expertise, and insufficient image detail can lead to errors. For example, small
tumors might go unnoticed, or overlap with healthy brain regions could result
in misidentification. To address these challenges and enhance diagnostic
precision, this study proposes a novel double ensembling framework, consisting
of ensembled pre-trained deep learning (DL) models for feature extraction and
ensembled fine-tuned hyperparameter machine learning (ML) models to efficiently
classify brain tumors. Specifically, our method includes extensive
preprocessing and augmentation, transfer learning concepts by utilizing various
pre-trained deep convolutional neural networks and vision transformer networks
to extract deep features from brain MRI, and fine-tune hyperparameters of ML
classifiers. Our experiments utilized three different publicly available Kaggle
MRI brain tumor datasets to evaluate the pre-trained DL feature extractor
models, ML classifiers, and the effectiveness of an ensemble of deep features
along with an ensemble of ML classifiers for brain tumor classification. Our
results indicate that the proposed feature fusion and classifier fusion improve
upon the state of the art, with hyperparameter fine-tuning providing a
significant enhancement over the ensemble method. Additionally, we present an
ablation study to illustrate how each component contributes to accurate brain
tumor classification.

</details>


### [60] [Wavelet-based Decoupling Framework for low-light Stereo Image Enhancement](https://arxiv.org/abs/2507.12188)
*Shuangli Du,Siming Yan,Zhenghao Shi,Zhenzhen You,Lu Sun*

Main category: cs.CV

TL;DR: 本文提出了一种创新的低光立体图像增强方法，通过小波变换解耦特征，分别处理光照和纹理，并利用跨视图信息和交叉注意力机制提升效果。


<details>
  <summary>Details</summary>
Motivation: 低光图像存在复杂的降质问题，现有方法将所有降质因素编码到单一潜在空间，导致特征纠缠和黑盒特性，容易引发模型捷径学习。为了解决这些问题，需要一种能够解耦特征、有效处理光照和纹理信息的方法。

Method: 本文提出了一种基于小波变换的低光立体图像增强方法，该方法的核心在于特征空间解耦。具体来说，利用小波变换将图像分解为低频和高频分量，低频分量用于光照调整，高频分量用于纹理恢复。在此基础上，设计了高频引导跨视图交互模块（HF-CIM）来促进双目视图间的高频信息交互，以及细节和纹理增强模块（DTEM）来增强纹理细节。模型在包含均匀和非均匀光照的图像数据集上进行训练。

Result: 实验结果表明，该算法在光照调整方面具有显著优势，同时能有效恢复高频信息，在真实和合成图像上都表现出优于现有方法的性能。

Conclusion: 该研究提出了一种基于小波变换和特征空间解耦的低光立体图像增强方法，通过独立处理低频和高频信息，实现了更好的光照调整和纹理恢复效果。该方法通过高频引导跨视图交互模块（HF-CIM）有效利用另一视图的信息，并利用基于交叉注意力机制的细节和纹理增强模块（DTEM）来提升高频信息。实验结果表明，该算法在光照调整和高频信息恢复方面表现出色。

Abstract: Low-light images suffer from complex degradation, and existing enhancement
methods often encode all degradation factors within a single latent space. This
leads to highly entangled features and strong black-box characteristics, making
the model prone to shortcut learning. To mitigate the above issues, this paper
proposes a wavelet-based low-light stereo image enhancement method with feature
space decoupling. Our insight comes from the following findings: (1) Wavelet
transform enables the independent processing of low-frequency and
high-frequency information. (2) Illumination adjustment can be achieved by
adjusting the low-frequency component of a low-light image, extracted through
multi-level wavelet decomposition. Thus, by using wavelet transform the feature
space is decomposed into a low-frequency branch for illumination adjustment and
multiple high-frequency branches for texture enhancement. Additionally, stereo
low-light image enhancement can extract useful cues from another view to
improve enhancement. To this end, we propose a novel high-frequency guided
cross-view interaction module (HF-CIM) that operates within high-frequency
branches rather than across the entire feature space, effectively extracting
valuable image details from the other view. Furthermore, to enhance the
high-frequency information, a detail and texture enhancement module (DTEM) is
proposed based on cross-attention mechanism. The model is trained on a dataset
consisting of images with uniform illumination and images with non-uniform
illumination. Experimental results on both real and synthetic images indicate
that our algorithm offers significant advantages in light adjustment while
effectively recovering high-frequency information. The code and dataset are
publicly available at: https://github.com/Cherisherr/WDCI-Net.git.

</details>


### [61] [Revealing the Ancient Beauty: Digital Reconstruction of Temple Tiles using Computer Vision](https://arxiv.org/abs/2507.12195)
*Arkaprabha Basu*

Main category: cs.CV

TL;DR: 本研究提出分形卷积、自敏感瓷砖填充和超分辨率技术，结合马赛克切片数据增强，用于修复印度文化遗产，尤其关注Bankura的赤陶庙，旨在平衡传统与创新，提高保护效率和美学质量。


<details>
  <summary>Details</summary>
Motivation: 为了应对现代数字化保存和修复文化遗产的挑战，特别是针对印度 monumento 的独特之处，如其建筑技艺和美学吸引力。

Method: 本研究提出了三种技术：1. 分形卷积（Fractal Convolution）方法，一种基于图像处理的分割方法，用于揭示建筑的细微模式。 2. 自敏感瓷砖填充（Self-Sensitive Tile Filling, SSTF）方法，并结合了新的数据增强方法——马赛克切片（MosaicSlice），专门用于修复Bankura的赤陶庙。 3. 超分辨率（Super Resolution）策略，用于在不损失过多信息的情况下提高图像质量。

Result: 所提出的方法能够生成无缝的区域填充和高细节的瓷砖，同时通过新颖的数据增强策略在可控成本内保持真实性并实现自动化，提高了文化遗产保护的效率和美学质量。

Conclusion: 本研究提出的三种方法（分形卷积、自敏感瓷砖填充和马赛克切片数据增强，以及超分辨率）为文化遗产保护提供了有效的解决方案，实现了传统与创新的平衡，提高了效率和美观性。

Abstract: Modern digitised approaches have dramatically changed the preservation and
restoration of cultural treasures, integrating computer scientists into
multidisciplinary projects with ease. Machine learning, deep learning, and
computer vision techniques have revolutionised developing sectors like 3D
reconstruction, picture inpainting,IoT-based methods, genetic algorithms, and
image processing with the integration of computer scientists into
multidisciplinary initiatives. We suggest three cutting-edge techniques in
recognition of the special qualities of Indian monuments, which are famous for
their architectural skill and aesthetic appeal. First is the Fractal
Convolution methodology, a segmentation method based on image processing that
successfully reveals subtle architectural patterns within these irreplaceable
cultural buildings. The second is a revolutionary Self-Sensitive Tile Filling
(SSTF) method created especially for West Bengal's mesmerising Bankura
Terracotta Temples with a brand-new data augmentation method called MosaicSlice
on the third. Furthermore, we delve deeper into the Super Resolution strategy
to upscale the images without losing significant amount of quality. Our methods
allow for the development of seamless region-filling and highly detailed tiles
while maintaining authenticity using a novel data augmentation strategy within
affordable costs introducing automation. By providing effective solutions that
preserve the delicate balance between tradition and innovation, this study
improves the subject and eventually ensures unrivalled efficiency and aesthetic
excellence in cultural heritage protection. The suggested approaches advance
the field into an era of unmatched efficiency and aesthetic quality while
carefully upholding the delicate equilibrium between tradition and innovation.

</details>


### [62] [RODS: Robust Optimization Inspired Diffusion Sampling for Detecting and Reducing Hallucination in Generative Models](https://arxiv.org/abs/2507.12201)
*Yiqi Tian,Pengfei Jin,Mingze Yuan,Na Li,Bo Zeng,Quanzheng Li*

Main category: cs.CV

TL;DR: RODS 是一种新的扩散采样方法，通过优化视角，利用损失景观的几何线索来检测和纠正幻觉，从而提高采样保真度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成建模方面取得了最先进的性能，但其采样过程仍然容易出现幻觉，这通常源于评分近似中的不准确性。

Method: RODS (Robust Optimization-inspired Diffusion Sampler) 是一种新颖的方法，通过优化视角重新解释扩散采样，利用损失景观的几何线索来检测和纠正高风险的采样步骤。

Result: RODS 强制执行更平滑的采样轨迹并自适应地调整扰动，检测到超过 70% 的幻觉样本并纠正了超过 25% 的样本，同时避免了引入新的伪影。

Conclusion: RODS 通过利用损失景观的几何线索，在不重新训练的情况下，以最小的推理成本，在 AFHQv2、FFHQ 和 11k-hands 的采样保真度和鲁棒性方面取得了显著的改进，同时避免了引入新的伪影。

Abstract: Diffusion models have achieved state-of-the-art performance in generative
modeling, yet their sampling procedures remain vulnerable to hallucinations,
often stemming from inaccuracies in score approximation. In this work, we
reinterpret diffusion sampling through the lens of optimization and introduce
RODS (Robust Optimization-inspired Diffusion Sampler), a novel method that
detects and corrects high-risk sampling steps using geometric cues from the
loss landscape. RODS enforces smoother sampling trajectories and adaptively
adjusts perturbations, reducing hallucinations without retraining and at
minimal additional inference cost. Experiments on AFHQv2, FFHQ, and 11k-hands
demonstrate that RODS improves both sampling fidelity and robustness, detecting
over 70% of hallucinated samples and correcting more than 25%, all while
avoiding the introduction of new artifacts.

</details>


### [63] [MGFFD-VLM: Multi-Granularity Prompt Learning for Face Forgery Detection with VLM](https://arxiv.org/abs/2507.12232)
*Tao Chen,Jingyi Zhang,Decheng Liu,Chunlei Peng*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recent studies have utilized visual large language models (VLMs) to answer
not only "Is this face a forgery?" but also "Why is the face a forgery?" These
studies introduced forgery-related attributes, such as forgery location and
type, to construct deepfake VQA datasets and train VLMs, achieving high
accuracy while providing human-understandable explanatory text descriptions.
However, these methods still have limitations. For example, they do not fully
leverage face quality-related attributes, which are often abnormal in forged
faces, and they lack effective training strategies for forgery-aware VLMs. In
this paper, we extend the VQA dataset to create DD-VQA+, which features a
richer set of attributes and a more diverse range of samples. Furthermore, we
introduce a novel forgery detection framework, MGFFD-VLM, which integrates an
Attribute-Driven Hybrid LoRA Strategy to enhance the capabilities of Visual
Large Language Models (VLMs). Additionally, our framework incorporates
Multi-Granularity Prompt Learning and a Forgery-Aware Training Strategy. By
transforming classification and forgery segmentation results into prompts, our
method not only improves forgery classification but also enhances
interpretability. To further boost detection performance, we design multiple
forgery-related auxiliary losses. Experimental results demonstrate that our
approach surpasses existing methods in both text-based forgery judgment and
analysis, achieving superior accuracy.

</details>


### [64] [Generate to Ground: Multimodal Text Conditioning Boosts Phrase Grounding in Medical Vision-Language Models](https://arxiv.org/abs/2507.12236)
*Felix Nützel,Mischa Dombrowski,Bernhard Kainz*

Main category: cs.CV

TL;DR: 本研究利用生成式扩散模型和BBM技术，在医学影像的短语定位任务中取得了比现有方法更好的性能。


<details>
  <summary>Details</summary>
Motivation: 探索生成模型在医学影像的短语定位任务中的潜力，以期获得比现有判别式方法更好的性能。

Method: 本研究提出了一种利用生成文本到图像扩散模型（通过交叉注意力图）进行零样本短语定位的方法，并引入了一种名为Bimodal Bias Merging（BBM）的新型后处理技术，以对齐文本和图像偏差来识别高确定性区域。

Result: 与当前最先进的判别式自监督对比模型相比，所提出的生成式方法在零样本短语定位任务上表现出优越的性能，mIoU分数翻倍。通过BBM技术进一步提高了定位精度。

Conclusion: 本研究表明，生成式方法在医学影像的短语定位任务中是一种更有效的范式，为临床实践中更鲁棒、更可解释的应用铺平了道路。

Abstract: Phrase grounding, i.e., mapping natural language phrases to specific image
regions, holds significant potential for disease localization in medical
imaging through clinical reports. While current state-of-the-art methods rely
on discriminative, self-supervised contrastive models, we demonstrate that
generative text-to-image diffusion models, leveraging cross-attention maps, can
achieve superior zero-shot phrase grounding performance. Contrary to prior
assumptions, we show that fine-tuning diffusion models with a frozen,
domain-specific language model, such as CXR-BERT, substantially outperforms
domain-agnostic counterparts. This setup achieves remarkable improvements, with
mIoU scores doubling those of current discriminative methods. These findings
highlight the underexplored potential of generative models for phrase grounding
tasks. To further enhance performance, we introduce Bimodal Bias Merging (BBM),
a novel post-processing technique that aligns text and image biases to identify
regions of high certainty. BBM refines cross-attention maps, achieving even
greater localization accuracy. Our results establish generative approaches as a
more effective paradigm for phrase grounding in the medical imaging domain,
paving the way for more robust and interpretable applications in clinical
practice. The source code and model weights are available at
https://github.com/Felix-012/generate_to_ground.

</details>


### [65] [Calisthenics Skills Temporal Video Segmentation](https://arxiv.org/abs/2507.12245)
*Antonio Finocchiaro,Giovanni Maria Farinella,Antonino Furnari*

Main category: cs.CV

TL;DR: 本研究提出了一个肌力训练静态技能视频数据集和一种用于解决技能时间分割问题的基线方法，旨在为肌力训练领域的自动化工具提供支持。


<details>
  <summary>Details</summary>
Motivation: 为了实现肌力训练领域的自动化工具，包括协助运动员训练和裁判在比赛中进行评估，本研究旨在解决肌力训练技能的时间视频分割问题。

Method: 提出一个包含肌力训练静态技能视频的数据集，并对每个视频进行时间分割标注，以确定每个技能的范围。然后，报告了一个用于在所提出数据集上解决技能时间分割问题的基线方法。

Result: 基线方法在所提出的数据集上的结果突出了所提出问题是可行的，但仍有改进的空间。

Conclusion: 本研究提出了一个用于肌力训练静态技能的视频数据集，并报告了一个用于解决技能时间分割问题的基线方法。结果表明该问题是可行的，但仍有改进空间。

Abstract: Calisthenics is a fast-growing bodyweight discipline that consists of
different categories, one of which is focused on skills. Skills in calisthenics
encompass both static and dynamic elements performed by athletes. The
evaluation of static skills is based on their difficulty level and the duration
of the hold. Automated tools able to recognize isometric skills from a video by
segmenting them to estimate their duration would be desirable to assist
athletes in their training and judges during competitions. Although the video
understanding literature on action recognition through body pose analysis is
rich, no previous work has specifically addressed the problem of calisthenics
skill temporal video segmentation. This study aims to provide an initial step
towards the implementation of automated tools within the field of Calisthenics.
To advance knowledge in this context, we propose a dataset of video footage of
static calisthenics skills performed by athletes. Each video is annotated with
a temporal segmentation which determines the extent of each skill. We hence
report the results of a baseline approach to address the problem of skill
temporal segmentation on the proposed dataset. The results highlight the
feasibility of the proposed problem, while there is still room for improvement.

</details>


### [66] [Comparative Analysis of CNN Performance in Keras, PyTorch and JAX on PathMNIST](https://arxiv.org/abs/2507.12248)
*Anida Nezović,Jalal Romano,Nada Marić,Medina Kapo,Amila Akagić*

Main category: cs.CV

TL;DR: 本研究对 Keras、PyTorch 和 JAX 中的 CNN 在医学图像分类任务上的表现进行了比较，重点关注效率、准确性和速度，并提供了关于速度与准确性之间权衡的见解。


<details>
  <summary>Details</summary>
Motivation: 为了探索和比较 Keras、PyTorch 和 JAX 在医学图像分类任务中基于 CNN 的实现，因为不同框架的相对性能仍未得到充分研究。

Method: 使用 PathMNIST 数据集，评估 Keras、PyTorch 和 JAX 中 CNN 实现的训练效率、分类准确性和推理速度。

Result: 研究结果揭示了计算速度和模型准确性之间的权衡，为医学图像分析领域的研究人员和从业者提供了宝贵的见解。

Conclusion: 本研究全面分析了 Keras、PyTorch 和 JAX 在医学图像分类任务中基于卷积神经网络（CNN）的实现。我们评估了训练效率、分类准确性和推理速度，并以 PathMNIST 数据集为基准。

Abstract: Deep learning has significantly advanced the field of medical image
classification, particularly with the adoption of Convolutional Neural Networks
(CNNs). Various deep learning frameworks such as Keras, PyTorch and JAX offer
unique advantages in model development and deployment. However, their
comparative performance in medical imaging tasks remains underexplored. This
study presents a comprehensive analysis of CNN implementations across these
frameworks, using the PathMNIST dataset as a benchmark. We evaluate training
efficiency, classification accuracy and inference speed to assess their
suitability for real-world applications. Our findings highlight the trade-offs
between computational speed and model accuracy, offering valuable insights for
researchers and practitioners in medical image analysis.

</details>


### [67] [Site-Level Fine-Tuning with Progressive Layer Freezing: Towards Robust Prediction of Bronchopulmonary Dysplasia from Day-1 Chest Radiographs in Extremely Preterm Infants](https://arxiv.org/abs/2507.12269)
*Sybelle Goedicke-Fritz,Michelle Bous,Annika Engel,Matthias Flotho,Pascal Hirsch,Hannah Wittig,Dino Milanovic,Dominik Mohr,Mathias Kaspar,Sogand Nemat,Dorothea Kerner,Arno Bücker,Andreas Keller,Sascha Meyer,Michael Zemlin,Philipp Flotho*

Main category: cs.CV

TL;DR: 该研究利用深度学习分析新生儿第一天的胸部X光片，以预测支气管肺发育不良（BPD）的风险，结果显示该方法比传统方法更有效。


<details>
  <summary>Details</summary>
Motivation: 为了避免对低风险婴儿产生不必要的毒副作用，及早预测BPD及其结局至关重要，因为现有的预防性干预措施存在严重的风险。利用新生儿入院初期（24小时内）的X光片作为无创预测工具具有重要意义。

Method: 本研究采用深度学习方法，利用163名极低出生体重婴儿（$\\\leq$32周胎龄，401-999克）出生24小时内的胸部X光片，对ResNet-50模型进行了微调。研究中采用了渐进式层冻结、判别性学习率、CutMix数据增强和线性探测等技术来防止过拟合。

Result: 研究结果显示，在预测中/重度BPD结局方面，表现最佳的模型达到了0.78 $\\%\'+\'+/- 0.10的AUROC，0.69 $\\%\'+\'+/- 0.10的平衡准确率和0.67 $\\%\'+\'+/- 0.11的F1分数。领域特定预训练显著优于ImageNet初始化（p = 0.031），表明领域特定预训练对于BPD结局预测的重要性。而常规的IRDS分级预测价值有限（AUROC 0.57 $\\%\'+\'+/- 0.11）。

Conclusion: 该研究表明，通过对新生儿第一天的胸部X光片进行领域特定预训练，可以准确预测支气管肺发育不良（BPD）的结局。该方法通过渐进式冻结和线性探测，在计算上是可行的，并且可以进行现场实施和未来的联邦学习部署。

Abstract: Bronchopulmonary dysplasia (BPD) is a chronic lung disease affecting 35% of
extremely low birth weight infants. Defined by oxygen dependence at 36 weeks
postmenstrual age, it causes lifelong respiratory complications. However,
preventive interventions carry severe risks, including neurodevelopmental
impairment, ventilator-induced lung injury, and systemic complications.
Therefore, early BPD prognosis and prediction of BPD outcome is crucial to
avoid unnecessary toxicity in low risk infants. Admission radiographs of
extremely preterm infants are routinely acquired within 24h of life and could
serve as a non-invasive prognostic tool. In this work, we developed and
investigated a deep learning approach using chest X-rays from 163 extremely
low-birth-weight infants ($\leq$32 weeks gestation, 401-999g) obtained within
24 hours of birth. We fine-tuned a ResNet-50 pretrained specifically on adult
chest radiographs, employing progressive layer freezing with discriminative
learning rates to prevent overfitting and evaluated a CutMix augmentation and
linear probing. For moderate/severe BPD outcome prediction, our best performing
model with progressive freezing, linear probing and CutMix achieved an AUROC of
0.78 $\pm$ 0.10, balanced accuracy of 0.69 $\pm$ 0.10, and an F1-score of 0.67
$\pm$ 0.11. In-domain pre-training significantly outperformed ImageNet
initialization (p = 0.031) which confirms domain-specific pretraining to be
important for BPD outcome prediction. Routine IRDS grades showed limited
prognostic value (AUROC 0.57 $\pm$ 0.11), confirming the need of learned
markers. Our approach demonstrates that domain-specific pretraining enables
accurate BPD prediction from routine day-1 radiographs. Through progressive
freezing and linear probing, the method remains computationally feasible for
site-level implementation and future federated learning deployments.

</details>


### [68] [FADE: Adversarial Concept Erasure in Flow Models](https://arxiv.org/abs/2507.12283)
*Zixuan Fu,Yan Ren,Finn Carter,Chenyue Wang,Ze Niu,Dacheng Yu,Emily Davis,Bo Zhang*

Main category: cs.CV

TL;DR: FADE 是一种新的扩散模型概念擦除方法，可以安全地移除模型中的敏感概念，同时保持图像质量，并且优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于扩散模型可能通过记忆敏感概念或固化偏见而带来隐私和公平性风险，因此需要一种方法来移除模型中的特定概念，例如私人个体或有害的刻板印象。

Method: FADE（Fair Adversarial Diffusion Erasure）是一种新颖的概念擦除方法，结合了轨迹感知微调策略和对抗性目标，旨在从文本到图像的扩散模型中移除指定的概念。该方法通过理论证明，能够最小化擦除概念与模型输出之间的互信息，从而确保隐私和公平性。

Result: FADE 在 Stable Diffusion 和 FLUX 上取得了最先进的概念移除性能，在移除效果和图像质量方面均优于 ESD、UCE、MACE 和 ANT 等近期基线方法。实验表明，FADE 在概念移除和保真度的调和平均值方面比现有最佳方法提高了 5-10%。此外，消融研究证实了其对抗性和轨迹保持目标对提升性能的贡献。

Conclusion: FADE 是一种新颖的文本到图像扩散模型概念擦除方法，通过结合轨迹感知微调策略和对抗性目标，可以可靠地移除指定概念（例如，私人个人或有害的刻板印象），同时保持整体模型保真度。该方法在 Stable Diffusion 和 FLUX 上进行了评估，并在概念移除效果和图像质量方面优于现有基线。FADE 通过非对抗性和轨迹保持目标，在不进行从头重新训练的情况下，实现了指定概念的遗忘，为安全和公平的生成模型树立了新的标准。

Abstract: Diffusion models have demonstrated remarkable image generation capabilities,
but also pose risks in privacy and fairness by memorizing sensitive concepts or
perpetuating biases. We propose a novel \textbf{concept erasure} method for
text-to-image diffusion models, designed to remove specified concepts (e.g., a
private individual or a harmful stereotype) from the model's generative
repertoire. Our method, termed \textbf{FADE} (Fair Adversarial Diffusion
Erasure), combines a trajectory-aware fine-tuning strategy with an adversarial
objective to ensure the concept is reliably removed while preserving overall
model fidelity. Theoretically, we prove a formal guarantee that our approach
minimizes the mutual information between the erased concept and the model's
outputs, ensuring privacy and fairness. Empirically, we evaluate FADE on Stable
Diffusion and FLUX, using benchmarks from prior work (e.g., object, celebrity,
explicit content, and style erasure tasks from MACE). FADE achieves
state-of-the-art concept removal performance, surpassing recent baselines like
ESD, UCE, MACE, and ANT in terms of removal efficacy and image quality.
Notably, FADE improves the harmonic mean of concept removal and fidelity by
5--10\% over the best prior method. We also conduct an ablation study to
validate each component of FADE, confirming that our adversarial and
trajectory-preserving objectives each contribute to its superior performance.
Our work sets a new standard for safe and fair generative modeling by
unlearning specified concepts without retraining from scratch.

</details>


### [69] [Efficient Calisthenics Skills Classification through Foreground Instance Selection and Depth Estimation](https://arxiv.org/abs/2507.12292)
*Antonio Finocchiaro,Giovanni Maria Farinella,Antonino Furnari*

Main category: cs.CV

TL;DR: 一种利用深度估计和运动员图像块检索的健美操技能识别新方法，比传统姿势估计方法更快、更准确。


<details>
  <summary>Details</summary>
Motivation: 传统的健美操技能识别方法依赖姿势估计，计算成本高、推理时间长、设置复杂，限制了其在实时应用或移动设备上的使用。因此，本研究旨在提出一种更有效、更快速的健美操技能识别方法。

Method: 本研究提出了一种直接的健美操技能识别方法，利用深度估计和运动员图像块检索来替代计算量大的姿势估计模块。具体来说，它使用了 Depth Anything V2 进行深度估计，并使用 YOLOv10 进行运动员定位，从而将运动员从背景中分割出来，而不是依赖传统的姿势估计技术。

Result: 使用 RGB 图像块时，该方法比基于骨骼的方法快 38.3 倍；使用深度图像块时，分类准确率从 0.815 提高到 0.837。

Conclusion: 该方法在避免了计算量大的姿态估计模块后，在区分不同健美操技能方面取得了更好的效果，与基于骨骼的方法相比，使用 RGB 图像块的推理速度提高了 38.3 倍，使用深度图像块的分类准确率也从 0.815 提高到 0.837。此外，该方法的模块化设计易于未来改进和适应实际应用。

Abstract: Calisthenics skill classification is the computer vision task of inferring
the skill performed by an athlete from images, enabling automatic performance
assessment and personalized analytics. Traditional methods for calisthenics
skill recognition are based on pose estimation methods to determine the
position of skeletal data from images, which is later fed to a classification
algorithm to infer the performed skill. Despite the progress in human pose
estimation algorithms, they still involve high computational costs, long
inference times, and complex setups, which limit the applicability of such
approaches in real-time applications or mobile devices. This work proposes a
direct approach to calisthenics skill recognition, which leverages depth
estimation and athlete patch retrieval to avoid the computationally expensive
human pose estimation module. Using Depth Anything V2 for depth estimation and
YOLOv10 for athlete localization, we segment the subject from the background
rather than relying on traditional pose estimation techniques. This strategy
increases efficiency, reduces inference time, and improves classification
accuracy. Our approach significantly outperforms skeleton-based methods,
achieving 38.3x faster inference with RGB image patches and improved
classification accuracy with depth patches (0.837 vs. 0.815). Beyond these
performance gains, the modular design of our pipeline allows for flexible
replacement of components, enabling future enhancements and adaptation to
real-world applications.

</details>


### [70] [Compositional Discrete Latent Code for High Fidelity, Productive Diffusion Models](https://arxiv.org/abs/2507.12318)
*Samuel Lavoie,Michael Noukhovitch,Aaron Courville*

Main category: cs.CV

TL;DR: Discrete Latent Codes (DLCs) improve diffusion models for image generation and enable text-to-image synthesis by offering better representation properties like compositionality.


<details>
  <summary>Details</summary>
Motivation: To investigate image representations for diffusion models, focusing on improving sample fidelity, ease of generation, and compositionality for out-of-training sample generation.

Method: Introduced Discrete Latent Code (DLC), a sequence of discrete tokens derived from Simplicial Embeddings trained with self-supervised learning. Diffusion models were trained using DLCs, and their performance was evaluated on unconditional image generation (ImageNet) and text-to-image generation tasks.

Result: Diffusion models trained with DLCs achieved improved generation fidelity, setting a new state-of-the-art for unconditional image generation on ImageNet. DLC compositionality enabled the generation of novel out-of-distribution samples with combined semantics. Text-to-image generation was successfully demonstrated by fine-tuning a text diffusion model to generate DLCs.

Conclusion: DLCs, a novel discrete latent code representation derived from Simplicial Embeddings, improve diffusion model performance by enhancing sample fidelity, ease of generation, and compositionality. This allows for out-of-distribution sample generation and enables text-to-image synthesis by leveraging pretrained language models.

Abstract: We argue that diffusion models' success in modeling complex distributions is,
for the most part, coming from their input conditioning. This paper
investigates the representation used to condition diffusion models from the
perspective that ideal representations should improve sample fidelity, be easy
to generate, and be compositional to allow out-of-training samples generation.
We introduce Discrete Latent Code (DLC), an image representation derived from
Simplicial Embeddings trained with a self-supervised learning objective. DLCs
are sequences of discrete tokens, as opposed to the standard continuous image
embeddings. They are easy to generate and their compositionality enables
sampling of novel images beyond the training distribution. Diffusion models
trained with DLCs have improved generation fidelity, establishing a new
state-of-the-art for unconditional image generation on ImageNet. Additionally,
we show that composing DLCs allows the image generator to produce
out-of-distribution samples that coherently combine the semantics of images in
diverse ways. Finally, we showcase how DLCs can enable text-to-image generation
by leveraging large-scale pretrained language models. We efficiently finetune a
text diffusion language model to generate DLCs that produce novel samples
outside of the image generator training distribution.

</details>


### [71] [Unsupervised Monocular 3D Keypoint Discovery from Multi-View Diffusion Priors](https://arxiv.org/abs/2507.12336)
*Subin Jeon,In Cho,Junyoung Hong,Seon Joo Kim*

Main category: cs.CV

TL;DR: KeyDiff3D：利用扩散模型进行单目3D关键点估计和3D对象操作。


<details>
  <summary>Details</summary>
Motivation: 现有的单目3D关键点估计方法需要昂贵的手动注释或标定好的多视角图像，而KeyDiff3D旨在仅使用单视角图像集合实现此目标。

Method: KeyDiff3D框架利用预训练的多视角扩散模型，通过生成多视角图像作为监督信号，并提取其中间表示以构建3D特征体，从而实现单目3D关键点估计。

Result: 实验结果表明，KeyDiff3D在准确性、泛化能力以及3D对象操作方面均表现出色，并且能够处理各种数据集，包括在野外和非领域数据集。

Conclusion: KeyDiff3D是一个无需手动注释或多视角标定即可进行单目3D关键点估计的框架。它利用预训练的多视角扩散模型生成多视角图像作为监督信号，并提取2D多视角特征构建3D特征体，将扩散模型隐式学习的3D先验转化为显式3D特征。此外，该框架还支持对扩散模型生成的3D对象进行操作。在Human3.6M、Stanford Dogs等数据集上的实验证明了该方法的有效性。

Abstract: This paper introduces KeyDiff3D, a framework for unsupervised monocular 3D
keypoints estimation that accurately predicts 3D keypoints from a single image.
While previous methods rely on manual annotations or calibrated multi-view
images, both of which are expensive to collect, our method enables monocular 3D
keypoints estimation using only a collection of single-view images. To achieve
this, we leverage powerful geometric priors embedded in a pretrained multi-view
diffusion model. In our framework, this model generates multi-view images from
a single image, serving as a supervision signal to provide 3D geometric cues to
our model. We also use the diffusion model as a powerful 2D multi-view feature
extractor and construct 3D feature volumes from its intermediate
representations. This transforms implicit 3D priors learned by the diffusion
model into explicit 3D features. Beyond accurate keypoints estimation, we
further introduce a pipeline that enables manipulation of 3D objects generated
by the diffusion model. Experimental results on diverse aspects and datasets,
including Human3.6M, Stanford Dogs, and several in-the-wild and out-of-domain
datasets, highlight the effectiveness of our method in terms of accuracy,
generalization, and its ability to enable manipulation of 3D objects generated
by the diffusion model from a single image.

</details>


### [72] [Improving Lightweight Weed Detection via Knowledge Distillation](https://arxiv.org/abs/2507.12344)
*Ahmet Oğuz Saltık,Max Voigt,Sourav Modak,Mike Beckworth,Anthony Stein*

Main category: cs.CV

TL;DR: 本研究提出并验证了通道知识蒸馏（CWD）和掩码生成蒸馏（MGD）这两种方法，以提高轻量级模型在精准农业和植物表型分析中的杂草检测性能。实验结果表明，这两种方法能够有效提升模型的准确性，并且在实际部署中具有可行性。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的平台上部署精确的目标检测模型仍然是一个挑战，特别是在区分植物表型分析中常见的视觉上相似的杂草物种时。

Method: 本研究调查了通道知识蒸馏（CWD）和掩码生成蒸馏（MGD），以提高轻量级模型在实时智能喷洒系统中的性能。使用YOLO11x作为教师模型，YOLO11n作为参考和学生模型。

Result: 实验表明，CWD和MGD有效地将知识从教师模型转移到学生模型，在所有类别的AP50上都提高了性能。蒸馏后的CWD学生模型在mAP50上比基线模型提高了2.5%，MGD提高了1.9%，而没有增加模型复杂度。此外，研究验证了CWD和MGD在Jetson Orin Nano和Raspberry Pi 5嵌入式设备上的实时部署可行性。

Conclusion: CWD和MGD是提高农业和植物表型分析中基于深度学习的杂草检测准确性的有效、高效且实用的方法。

Abstract: Weed detection is a critical component of precision agriculture, facilitating
targeted herbicide application and reducing environmental impact. However,
deploying accurate object detection models on resource-limited platforms
remains challenging, particularly when differentiating visually similar weed
species commonly encountered in plant phenotyping applications. In this work,
we investigate Channel-wise Knowledge Distillation (CWD) and Masked Generative
Distillation (MGD) to enhance the performance of lightweight models for
real-time smart spraying systems. Utilizing YOLO11x as the teacher model and
YOLO11n as both reference and student, both CWD and MGD effectively transfer
knowledge from the teacher to the student model. Our experiments, conducted on
a real-world dataset comprising sugar beet crops and four weed types (Cirsium,
Convolvulus, Fallopia, and Echinochloa), consistently show increased AP50
across all classes. The distilled CWD student model achieves a notable
improvement of 2.5% and MGD achieves 1.9% in mAP50 over the baseline without
increasing model complexity. Additionally, we validate real-time deployment
feasibility by evaluating the student YOLO11n model on Jetson Orin Nano and
Raspberry Pi 5 embedded devices, performing five independent runs to evaluate
performance stability across random seeds. These findings confirm CWD and MGD
as an effective, efficient, and practical approach for improving deep
learning-based weed detection accuracy in precision agriculture and plant
phenotyping scenarios.

</details>


### [73] [Cluster Contrast for Unsupervised Visual Representation Learning](https://arxiv.org/abs/2507.12359)
*Nikolaos Giakoumoglou,Tania Stathaki*

Main category: cs.CV

TL;DR: CueCo是一种新的无监督视觉表示学习方法，结合了对比学习和聚类。


<details>
  <summary>Details</summary>
Motivation: CueCo旨在有效结合对比学习和聚类方法的优点，同时在特征空间中分散和对齐特征表示。

Method: CueCo采用两个神经网络（查询和键），其中键网络通过查询输的慢移平均值进行更新。它利用对比损失来分离不同的特征，增强类间分离性，并利用聚类目标将同一簇的特征拉到一起，促进类内紧密度。

Result: CueCo在CIFAR-10上实现了91.40%的top-1分类准确率，在CIFAR-100上实现了68.56%，在ImageNet-100上使用ResNet-18骨干网络和线性评估实现了78.65%。

Conclusion: CueCo通过整合对比学习和聚类，为无监督视觉表示学习设定了新的方向。

Abstract: We introduce Cluster Contrast (CueCo), a novel approach to unsupervised
visual representation learning that effectively combines the strengths of
contrastive learning and clustering methods. Inspired by recent advancements,
CueCo is designed to simultaneously scatter and align feature representations
within the feature space. This method utilizes two neural networks, a query and
a key, where the key network is updated through a slow-moving average of the
query outputs. CueCo employs a contrastive loss to push dissimilar features
apart, enhancing inter-class separation, and a clustering objective to pull
together features of the same cluster, promoting intra-class compactness. Our
method achieves 91.40% top-1 classification accuracy on CIFAR-10, 68.56% on
CIFAR-100, and 78.65% on ImageNet-100 using linear evaluation with a ResNet-18
backbone. By integrating contrastive learning with clustering, CueCo sets a new
direction for advancing unsupervised visual representation learning.

</details>


### [74] [Text-driven Multiplanar Visual Interaction for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2507.12382)
*Kaiwen Huang,Yi Zhou,Huazhu Fu,Yizhe Zhang,Chen Gong,Tao Zhou*

Main category: cs.CV

TL;DR: 提出Text-SemiSeg框架，利用文本信息提升半监督三维医学图像分割效果。


<details>
  <summary>Details</summary>
Motivation: 在标注数据有限的情况下，利用文本信息提供额外上下文以增强视觉语义理解，对于半监督医学图像分割至关重要。然而，目前探索利用文本数据增强三维医学成像任务中的视觉语义嵌入的研究仍然很少。

Method: 本文提出了一种新颖的文本驱动的多平面视觉交互框架Text-SemiSeg，包含文本增强多平面表示（TMR）、类别感知语义对齐（CSA）和动态认知增强（DCA）三个模块。TMR通过平面映射促进文本-视觉交互，增强视觉特征的类别感知能力。CSA通过引入可学习变量对文本特征和视觉特征中间层进行跨模态语义对齐。DCA通过数据交互减小了标注和未标注数据之间的分布差异，提高了模型的鲁棒性。

Result: 实验结果表明，本文提出的模型能够有效利用文本信息增强视觉特征，并且在三个公开数据集上取得了优于其他方法的性能。

Conclusion: 本文提出的Text-SemiSeg框架通过融合文本信息有效增强了三维医学图像分割的视觉特征，并在三个公开数据集上的实验证明了其优越性。

Abstract: Semi-supervised medical image segmentation is a crucial technique for
alleviating the high cost of data annotation. When labeled data is limited,
textual information can provide additional context to enhance visual semantic
understanding. However, research exploring the use of textual data to enhance
visual semantic embeddings in 3D medical imaging tasks remains scarce. In this
paper, we propose a novel text-driven multiplanar visual interaction framework
for semi-supervised medical image segmentation (termed Text-SemiSeg), which
consists of three main modules: Text-enhanced Multiplanar Representation (TMR),
Category-aware Semantic Alignment (CSA), and Dynamic Cognitive Augmentation
(DCA). Specifically, TMR facilitates text-visual interaction through planar
mapping, thereby enhancing the category awareness of visual features. CSA
performs cross-modal semantic alignment between the text features with
introduced learnable variables and the intermediate layer of visual features.
DCA reduces the distribution discrepancy between labeled and unlabeled data
through their interaction, thus improving the model's robustness. Finally,
experiments on three public datasets demonstrate that our model effectively
enhances visual features with textual information and outperforms other
methods. Our code is available at https://github.com/taozh2017/Text-SemiSeg.

</details>


### [75] [OD-VIRAT: A Large-Scale Benchmark for Object Detection in Realistic Surveillance Environments](https://arxiv.org/abs/2507.12396)
*Hayat Ullah,Abbas Khan,Arslan Munir,Hari Kalva*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Realistic human surveillance datasets are crucial for training and evaluating
computer vision models under real-world conditions, facilitating the
development of robust algorithms for human and human-interacting object
detection in complex environments. These datasets need to offer diverse and
challenging data to enable a comprehensive assessment of model performance and
the creation of more reliable surveillance systems for public safety. To this
end, we present two visual object detection benchmarks named OD-VIRAT Large and
OD-VIRAT Tiny, aiming at advancing visual understanding tasks in surveillance
imagery. The video sequences in both benchmarks cover 10 different scenes of
human surveillance recorded from significant height and distance. The proposed
benchmarks offer rich annotations of bounding boxes and categories, where
OD-VIRAT Large has 8.7 million annotated instances in 599,996 images and
OD-VIRAT Tiny has 288,901 annotated instances in 19,860 images. This work also
focuses on benchmarking state-of-the-art object detection architectures,
including RETMDET, YOLOX, RetinaNet, DETR, and Deformable-DETR on this object
detection-specific variant of VIRAT dataset. To the best of our knowledge, it
is the first work to examine the performance of these recently published
state-of-the-art object detection architectures on realistic surveillance
imagery under challenging conditions such as complex backgrounds, occluded
objects, and small-scale objects. The proposed benchmarking and experimental
settings will help in providing insights concerning the performance of selected
object detection models and set the base for developing more efficient and
robust object detection architectures.

</details>


### [76] [QuRe: Query-Relevant Retrieval through Hard Negative Sampling in Composed Image Retrieval](https://arxiv.org/abs/2507.12416)
*Jaehyun Kwak,Ramahdani Muhammad Izaaz Inhar,Se-Young Yun,Sung-Ju Lee*

Main category: cs.CV

TL;DR: QuRe 是一种新的复合图像检索方法，通过减少错误负例和引入硬负例采样策略来提高检索相关性，并在实验中证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的复合图像检索（CIR）方法仅关注检索目标图像，而忽略了其他图像的相关性，这可能导致检索不相关的图像并降低用户满意度。

Method: 提出了一种名为 QuRe 的新方法，该方法通过优化奖励模型目标来减少错误负例，并采用了一种硬负例采样策略来有效过滤错误负例。

Result: QuRe 在 FashionIQ 和 CIRR 数据集上取得了最先进的性能，并在 HP-FashionIQ 数据集上展现了与人类偏好的最强一致性。

Conclusion: QuRe 实现了最先进的性能，并在 HP-FashionIQ 数据集上与人类偏好表现出最强的一致性。

Abstract: Composed Image Retrieval (CIR) retrieves relevant images based on a reference
image and accompanying text describing desired modifications. However, existing
CIR methods only focus on retrieving the target image and disregard the
relevance of other images. This limitation arises because most methods
employing contrastive learning-which treats the target image as positive and
all other images in the batch as negatives-can inadvertently include false
negatives. This may result in retrieving irrelevant images, reducing user
satisfaction even when the target image is retrieved. To address this issue, we
propose Query-Relevant Retrieval through Hard Negative Sampling (QuRe), which
optimizes a reward model objective to reduce false negatives. Additionally, we
introduce a hard negative sampling strategy that selects images positioned
between two steep drops in relevance scores following the target image, to
effectively filter false negatives. In order to evaluate CIR models on their
alignment with human satisfaction, we create Human-Preference FashionIQ
(HP-FashionIQ), a new dataset that explicitly captures user preferences beyond
target retrieval. Extensive experiments demonstrate that QuRe achieves
state-of-the-art performance on FashionIQ and CIRR datasets while exhibiting
the strongest alignment with human preferences on the HP-FashionIQ dataset. The
source code is available at https://github.com/jackwaky/QuRe.

</details>


### [77] [InterpIoU: Rethinking Bounding Box Regression with Interpolation-Based IoU Optimization](https://arxiv.org/abs/2507.12420)
*Haoyuan Liu,Hiroshi Watanabe*

Main category: cs.CV

TL;DR: 提出InterpIoU和Dynamic InterpIoU损失函数，用插值框的IoU替代手工几何惩罚，解决了边界框回归中小目标检测和边界框放大的问题，并在多项基准测试中取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于IoU的损失函数通常包含手工设计的几何惩罚项，以解决IoU在非重叠情况下的不可微性问题并提升边界框回归性能。然而，这些惩罚项对框的形状、大小和分布敏感，常常导致优化不理想，尤其是在小目标检测方面，并且可能因与IoU目标不匹配而产生边界框放大的问题。为了解决这些局限性，需要一种新的方法。

Method: 提出了一种名为InterpIoU的新型损失函数，该函数用插值框与目标框之间IoU的项来替代手工设计的几何惩罚项。通过使用插值框来连接预测框和真实框之间的差异，InterpIoU在非重叠情况下提供了有意义的梯度，并能固有地避免因不匹配的惩罚项导致的边界框放大问题。在此基础上，进一步提出了Dynamic InterpIoU，该方法根据IoU值动态调整插值系数，增强了对不同目标分布场景的适应性。

Result: 仿真结果表明，IoU本身可以作为一个理想的回归目标，而现有的几何惩罚项是不必要的且次优的。InterpIoU通过插值框有效解决了非重叠情况下的梯度问题，并避免了边界框放大。Dynamic InterpIoU通过动态调整插值系数进一步提高了性能。

Conclusion: InterpIoU及其动态版本Dynamic InterpIoU在COCO、VisDrone和PASCAL VOC数据集上进行了测试，并与最先进的基于IoU的损失函数进行了比较。实验结果表明，我们的方法在各种检测框架下始终优于现有的基于IoU的损失函数，尤其在小目标检测方面表现出显著的改进，验证了其有效性。

Abstract: Bounding box regression (BBR) is fundamental to object detection, where the
regression loss is crucial for accurate localization. Existing IoU-based losses
often incorporate handcrafted geometric penalties to address IoU's
non-differentiability in non-overlapping cases and enhance BBR performance.
However, these penalties are sensitive to box shape, size, and distribution,
often leading to suboptimal optimization for small objects and undesired
behaviors such as bounding box enlargement due to misalignment with the IoU
objective. To address these limitations, we propose InterpIoU, a novel loss
function that replaces handcrafted geometric penalties with a term based on the
IoU between interpolated boxes and the target. By using interpolated boxes to
bridge the gap between predictions and ground truth, InterpIoU provides
meaningful gradients in non-overlapping cases and inherently avoids the box
enlargement issue caused by misaligned penalties. Simulation results further
show that IoU itself serves as an ideal regression target, while existing
geometric penalties are both unnecessary and suboptimal. Building on InterpIoU,
we introduce Dynamic InterpIoU, which dynamically adjusts interpolation
coefficients based on IoU values, enhancing adaptability to scenarios with
diverse object distributions. Experiments on COCO, VisDrone, and PASCAL VOC
show that our methods consistently outperform state-of-the-art IoU-based losses
across various detection frameworks, with particularly notable improvements in
small object detection, confirming their effectiveness.

</details>


### [78] [DVFL-Net: A Lightweight Distilled Video Focal Modulation Network for Spatio-Temporal Action Recognition](https://arxiv.org/abs/2507.12426)
*Hayat Ullah,Muhammad Ali Shafique,Abbas Khan,Arslan Munir*

Main category: cs.CV

TL;DR: DVFL-Net是一种轻量级的视频识别模型，通过知识蒸馏和时空特征调制，在保持高精度的同时显著降低了计算成本，适用于设备部署。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer模型在视频识别方面取得了最先进的性能，但它们在计算上仍然非常昂贵，尤其是在处理密集视频数据时。需要一种更高效的模型来实现设备部署。

Method: 提出了一种轻量级的视频焦点调制网络（DVFL-Net），通过知识蒸馏和时空特征调制，将知识从大型预训练教师模型转移到紧凑的学生模型中，以实现高效的设备部署。采用前向 Kullback-Leibler (KL) 散度与时空焦点调制来有效传递上下文。

Result: DVFL-Net在UCF50、UCF101、HMDB51、SSV2和Kinetics-400数据集上进行了评估，并在人类动作识别（HAR）方面与最新的最先进方法进行了基准测试，证明了其在性能和效率方面的优势。

Conclusion: DVFL-Net在性能和效率之间取得了最佳平衡，展示了更低的内存使用量、减少的GFLOPs和强大的准确性，使其成为实时人类动作识别（HAR）应用的实用解决方案。

Abstract: The landscape of video recognition has evolved significantly, shifting from
traditional Convolutional Neural Networks (CNNs) to Transformer-based
architectures for improved accuracy. While 3D CNNs have been effective at
capturing spatiotemporal dynamics, recent Transformer models leverage
self-attention to model long-range spatial and temporal dependencies. Despite
achieving state-of-the-art performance on major benchmarks, Transformers remain
computationally expensive, particularly with dense video data. To address this,
we propose a lightweight Video Focal Modulation Network, DVFL-Net, which
distills spatiotemporal knowledge from a large pre-trained teacher into a
compact nano student model, enabling efficient on-device deployment. DVFL-Net
utilizes knowledge distillation and spatial-temporal feature modulation to
significantly reduce computation while preserving high recognition performance.
We employ forward Kullback-Leibler (KL) divergence alongside spatio-temporal
focal modulation to effectively transfer both local and global context from the
Video-FocalNet Base (teacher) to the proposed VFL-Net (student). We evaluate
DVFL-Net on UCF50, UCF101, HMDB51, SSV2, and Kinetics-400, benchmarking it
against recent state-of-the-art methods in Human Action Recognition (HAR).
Additionally, we conduct a detailed ablation study analyzing the impact of
forward KL divergence. The results confirm the superiority of DVFL-Net in
achieving an optimal balance between performance and efficiency, demonstrating
lower memory usage, reduced GFLOPs, and strong accuracy, making it a practical
solution for real-time HAR applications.

</details>


### [79] [Describe Anything Model for Visual Question Answering on Text-rich Images](https://arxiv.org/abs/2507.12441)
*Yen-Linh Vu,Dinh-Thang Duong,Truong-Binh Duong,Anh-Khoi Nguyen,Thanh-Huy Nguyen,Le Thien Phuc Nguyen,Jianhua Xing,Xingjian Li,Tianyang Wang,Ulas Bagci,Min Xu*

Main category: cs.CV

TL;DR: DAM-QA 是一个利用 DAM 的区域感知能力来解决文本丰富 VQA 问题的框架，通过聚合多区域答案来提高准确性，在 DocVQA 等任务上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 由于在包含密集文本的图像中，细粒度地提取文本信息对于 VQA 任务至关重要，因此我们假设 DAM 的区域级描述能力对 VQA 任务有益，特别是在这些具有挑战性的场景中。

Method: DAM-QA 框架利用 DAM 的区域感知能力，通过聚合来自图像不同区域的答案来解决文本丰富的 VQA 问题。它包含一个机制来整合多区域视图的答案，从而更有效地识别与文本相关的证据。

Result: 实验结果表明，DAM-QA 在六个 VQA 基准测试上持续优于基线 DAM 模型，在 DocVQA 上取得了 7 个百分点的提升。此外，DAM-QA 在参数量较少的情况下，在区域感知模型中取得了最佳的整体性能，显著缩小了与强大的通用 VLM 的差距。

Conclusion: DAM-QA 框架在文本丰富的 VQA 任务上展现了潜力，与高效的集成策略相结合，可以应用于更广泛的 VQA 任务。

Abstract: Recent progress has been made in region-aware vision-language modeling,
particularly with the emergence of the Describe Anything Model (DAM). DAM is
capable of generating detailed descriptions of any specific image areas or
objects without the need for additional localized image-text alignment
supervision. We hypothesize that such region-level descriptive capability is
beneficial for the task of Visual Question Answering (VQA), especially in
challenging scenarios involving images with dense text. In such settings, the
fine-grained extraction of textual information is crucial to producing correct
answers. Motivated by this, we introduce DAM-QA, a framework with a tailored
evaluation protocol, developed to investigate and harness the region-aware
capabilities from DAM for the text-rich VQA problem that requires reasoning
over text-based information within images. DAM-QA incorporates a mechanism that
aggregates answers from multiple regional views of image content, enabling more
effective identification of evidence that may be tied to text-related elements.
Experiments on six VQA benchmarks show that our approach consistently
outperforms the baseline DAM, with a notable 7+ point gain on DocVQA. DAM-QA
also achieves the best overall performance among region-aware models with fewer
parameters, significantly narrowing the gap with strong generalist VLMs. These
results highlight the potential of DAM-like models for text-rich and broader
VQA tasks when paired with efficient usage and integration strategies. Our code
is publicly available at https://github.com/Linvyl/DAM-QA.git.

</details>


### [80] [Vision-based Perception for Autonomous Vehicles in Obstacle Avoidance Scenarios](https://arxiv.org/abs/2507.12449)
*Van-Hoang-Anh Phan,Chi-Tam Nguyen,Doan-Trung Au,Thanh-Danh Phan,Minh-Thien Duong,My-Ha Le*

Main category: cs.CV

TL;DR: 一个仅使用摄像头就能有效避障的系统，基于YOLOv11和Depth Anything V2的系统，在大学校园的测试中表现良好。


<details>
  <summary>Details</summary>
Motivation: 为确保自动驾驶汽车的安全，避障至关重要。

Method: 提出了一种利用仅摄像头感知模块和基于Frenet-Pure Pursuit的规划策略的高效避障流程。该系统集成了计算机视觉领域的进步，利用YOLOv11进行目标检测，并利用Depth Anything V2等先进的单目深度估算模型来估算物体距离。

Result: 对这些模型进行了比较分析，以深入了解它们在实际条件下的准确性、效率和鲁棒性。

Conclusion: 该系统在大学校园的各种场景中进行了评估，证明了其在处理各种障碍物和增强自主导航方面的有效性。

Abstract: Obstacle avoidance is essential for ensuring the safety of autonomous
vehicles. Accurate perception and motion planning are crucial to enabling
vehicles to navigate complex environments while avoiding collisions. In this
paper, we propose an efficient obstacle avoidance pipeline that leverages a
camera-only perception module and a Frenet-Pure Pursuit-based planning
strategy. By integrating advancements in computer vision, the system utilizes
YOLOv11 for object detection and state-of-the-art monocular depth estimation
models, such as Depth Anything V2, to estimate object distances. A comparative
analysis of these models provides valuable insights into their accuracy,
efficiency, and robustness in real-world conditions. The system is evaluated in
diverse scenarios on a university campus, demonstrating its effectiveness in
handling various obstacles and enhancing autonomous navigation. The video
presenting the results of the obstacle avoidance experiments is available at:
https://www.youtube.com/watch?v=FoXiO5S_tA8

</details>


### [81] [Mitigating Object Hallucinations via Sentence-Level Early Intervention](https://arxiv.org/abs/2507.12455)
*Shangpin Peng,Senqiao Yang,Li Jiang,Zhuotao Tian*

Main category: cs.CV

TL;DR: SENTINEL是一个创新的框架，通过在句子生成早期进行干预来解决多模态大语言模型的幻觉问题。该方法不依赖人类标注，通过生成和验证偏好数据，并使用上下文感知偏好损失进行训练，有效减少了幻觉，并提升了模型的整体性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在跨模态理解方面取得了革命性进展，但在处理与视觉输入相矛盾的虚构内容（幻觉）方面仍存在挑战。现有的缓解幻觉的方法要么计算成本高昂，要么在训练数据和模型输出之间引入分布不匹配。本文旨在解决MLLMs中的幻觉问题，并提出一种不依赖人类标注的高效方法。

Method: SENTINEL框架，包括引导高质量的领域内偏好对（通过迭代采样模型输出来验证对象存在，并交叉检查两个开放词汇检测器，将句子分类为幻觉/非幻觉），然后构建上下文感知偏好数据（使用上下文连贯的正样本和幻觉负样本），最后使用上下文感知偏好损失（C-DPO）进行训练，该损失在幻觉最初出现的句子级别上强调判别性学习。

Result: SENTINEL可以将幻觉减少90%以上，并且在幻觉基准和通用能力基准上都优于先前最先进的方法。

Conclusion: SENTINEL通过句子级别的早期干预，可以在不依赖人类标注的情况下，将幻觉减少90%以上，并在幻觉和通用能力基准测试中均优于现有最先进方法，展示了其优越性和泛化能力。

Abstract: Multimodal large language models (MLLMs) have revolutionized cross-modal
understanding but continue to struggle with hallucinations - fabricated content
contradicting visual inputs. Existing hallucination mitigation methods either
incur prohibitive computational costs or introduce distribution mismatches
between training data and model outputs. We identify a critical insight:
hallucinations predominantly emerge at the early stages of text generation and
propagate through subsequent outputs. To address this, we propose **SENTINEL**
(**S**entence-level **E**arly i**N**tervention **T**hrough **IN**-domain
pr**E**ference **L**earning), a framework that eliminates dependency on human
annotations. Specifically, we first bootstrap high-quality in-domain preference
pairs by iteratively sampling model outputs, validating object existence
through cross-checking with two open-vocabulary detectors, and classifying
sentences into hallucinated/non-hallucinated categories. Subsequently, we use
context-coherent positive samples and hallucinated negative samples to build
context-aware preference data iteratively. Finally, we train models using a
context-aware preference loss (C-DPO) that emphasizes discriminative learning
at the sentence level where hallucinations initially manifest. Experimental
results show that SENTINEL can reduce hallucinations by over 90\% compared to
the original model and outperforms the previous state-of-the-art method on both
hallucination benchmarks and general capabilities benchmarks, demonstrating its
superiority and generalization ability. The models, datasets, and code are
available at https://github.com/pspdada/SENTINEL.

</details>


### [82] [Interpreting Radiologist's Intention from Eye Movements in Chest X-ray Diagnosis](https://arxiv.org/abs/2507.12461)
*Trong-Thang Pham,Anh Nguyen,Zhigang Deng,Carol C. Wu,Hien Van Nguyen,Ngan Le*

Main category: cs.CV

TL;DR: 提出 RadGazeIntent，一种新的深度学习模型，用于解释放射科医生在医学图像中的注视意图。与基线方法相比，RadGazeIntent 在意图识别方面表现更好。


<details>
  <summary>Details</summary>
Motivation: 现有的模型未能捕捉每次注视背后的潜在意图，而训练有素的放射科医生在搜索时会遵循一个心理清单来定位病变。

Method: 提出了一种名为 RadGazeIntent 的深度学习方法，该方法采用基于 Transformer 的架构，处理眼动追踪数据的时域和空域，将细粒度的注视特征转化为粗粒度的、有意义的诊断意图表示，以解释放射科医生的目标。

Result: RadGazeIntent 能够预测放射科医生在特定时刻正在检查的发现，并且在所有意图标记的数据集上均优于基线方法。

Conclusion: RadGazeIntent 能够预测放射科医生在特定时刻正在检查的发现，并且在所有意图标记的数据集上均优于基线方法。

Abstract: Radiologists rely on eye movements to navigate and interpret medical images.
A trained radiologist possesses knowledge about the potential diseases that may
be present in the images and, when searching, follows a mental checklist to
locate them using their gaze. This is a key observation, yet existing models
fail to capture the underlying intent behind each fixation. In this paper, we
introduce a deep learning-based approach, RadGazeIntent, designed to model this
behavior: having an intention to find something and actively searching for it.
Our transformer-based architecture processes both the temporal and spatial
dimensions of gaze data, transforming fine-grained fixation features into
coarse, meaningful representations of diagnostic intent to interpret
radiologists' goals. To capture the nuances of radiologists' varied
intention-driven behaviors, we process existing medical eye-tracking datasets
to create three intention-labeled subsets: RadSeq (Systematic Sequential
Search), RadExplore (Uncertainty-driven Exploration), and RadHybrid (Hybrid
Pattern). Experimental results demonstrate RadGazeIntent's ability to predict
which findings radiologists are examining at specific moments, outperforming
baseline methods across all intention-labeled datasets.

</details>


### [83] [SpatialTrackerV2: 3D Point Tracking Made Easy](https://arxiv.org/abs/2507.12462)
*Yuxi Xiao,Jianyuan Wang,Nan Xue,Nikita Karaev,Yuri Makarov,Bingyi Kang,Xing Zhu,Hujun Bao,Yujun Shen,Xiaowei Zhou*

Main category: cs.CV

TL;DR: SpatialTrackerV2 is a fast and accurate monocular 3D point tracking method that unifies geometry and motion estimation in an end-to-end architecture.


<details>
  <summary>Details</summary>
Motivation: To develop a high-performing and feedforward 3D point tracker that unifies intrinsic connections between point tracking, monocular depth, and camera pose estimation, moving beyond modular pipelines.

Method: SpatialTrackerV2 is a feed-forward 3D point tracking method for monocular videos that unifies point tracking, monocular depth, and camera pose estimation into a single, fully differentiable, end-to-end architecture. It decomposes world-space 3D motion into scene geometry, camera ego-motion, and pixel-wise object motion, enabling scalable training across diverse datasets.

Result: The method achieves a 30% improvement over existing 3D tracking methods and matches the accuracy of leading dynamic 3D reconstruction approaches while operating 50 times faster.

Conclusion: SpatialTrackerV2 outperforms existing 3D tracking methods by 30%, and matches the accuracy of leading dynamic 3D reconstruction approaches while running 50x faster.

Abstract: We present SpatialTrackerV2, a feed-forward 3D point tracking method for
monocular videos. Going beyond modular pipelines built on off-the-shelf
components for 3D tracking, our approach unifies the intrinsic connections
between point tracking, monocular depth, and camera pose estimation into a
high-performing and feedforward 3D point tracker. It decomposes world-space 3D
motion into scene geometry, camera ego-motion, and pixel-wise object motion,
with a fully differentiable and end-to-end architecture, allowing scalable
training across a wide range of datasets, including synthetic sequences, posed
RGB-D videos, and unlabeled in-the-wild footage. By learning geometry and
motion jointly from such heterogeneous data, SpatialTrackerV2 outperforms
existing 3D tracking methods by 30%, and matches the accuracy of leading
dynamic 3D reconstruction approaches while running 50$\times$ faster.

</details>


### [84] [MMHU: A Massive-Scale Multimodal Benchmark for Human Behavior Understanding](https://arxiv.org/abs/2507.12463)
*Renjie Li,Ruijie Ye,Mingyang Wu,Hao Frank Yang,Zhiwen Fan,Hezhen Hu,Zhengzhong Tu*

Main category: cs.CV

TL;DR: MMHU是一个大规模数据集，用于自动驾驶中的人类行为理解，包含丰富的注释和多样的评估任务。


<details>
  <summary>Details</summary>
Motivation: 为了促进安全驾驶系统的发展，理解人类在交通生态系统中的行为至关重要，但目前缺乏一个全面的基准来评估自动驾驶中的人类行为理解。

Method: MMHU包含57k个人类运动片段和1.73M帧，数据来源多样，包括Waymo、YouTube和自行收集的数据。通过人机协作标注流程生成详细的行为描述。

Result: MMHU提供了广泛的评估套件，能够对运动预测、运动生成和人类行为问答等多个任务进行基准测试。

Conclusion: MMHU是一个大规模的基准，用于评估自动驾驶中的人类行为理解。它提供了丰富的人类运动、轨迹、意图和驾驶安全相关的关键行为标签。

Abstract: Humans are integral components of the transportation ecosystem, and
understanding their behaviors is crucial to facilitating the development of
safe driving systems. Although recent progress has explored various aspects of
human behavior$\unicode{x2014}$such as motion, trajectories, and
intention$\unicode{x2014}$a comprehensive benchmark for evaluating human
behavior understanding in autonomous driving remains unavailable. In this work,
we propose $\textbf{MMHU}$, a large-scale benchmark for human behavior analysis
featuring rich annotations, such as human motion and trajectories, text
description for human motions, human intention, and critical behavior labels
relevant to driving safety. Our dataset encompasses 57k human motion clips and
1.73M frames gathered from diverse sources, including established driving
datasets such as Waymo, in-the-wild videos from YouTube, and self-collected
data. A human-in-the-loop annotation pipeline is developed to generate rich
behavior captions. We provide a thorough dataset analysis and benchmark
multiple tasks$\unicode{x2014}$ranging from motion prediction to motion
generation and human behavior question answering$\unicode{x2014}$thereby
offering a broad evaluation suite. Project page :
https://MMHU-Benchmark.github.io.

</details>


### [85] [CytoSAE: Interpretable Cell Embeddings for Hematology](https://arxiv.org/abs/2507.12464)
*Muhammed Furkan Dasdelen,Hyesu Lim,Michele Buck,Katharina S. Götze,Carsten Marr,Steffen Schneider*

Main category: cs.CV

TL;DR: CytoSAE是一种用于血液学图像分析的稀疏自编码器，它能识别和生成与疾病相关的细胞概念，提供亚细胞层面的可解释性，并在AML分类任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决医学成像领域缺乏可解释性工具的问题，特别是针对日益增多的医学基础模型，本文旨在探索稀疏自编码器（SAEs）在血液学领域的可行性。

Method: 提出了一种名为CytoSAE的稀疏自编码器，并使用超过40,000张外周血单细胞图像进行训练，同时验证了其在骨髓细胞学等域外数据集上的泛化能力和识别概念的能力。

Result: CytoSAE能够识别形态学相关的细胞概念，并能生成患者和疾病特异性的概念，用于识别病灶细胞和细胞异常。在AML子类型分类任务中，CytoSAE概念的性能与最先进方法相当，并提供了亚细胞层面的可解释性。

Conclusion: CytoSAE在细胞学图像分析中展现了其适用性，能够识别、生成与疾病相关的细胞概念，并提供亚细胞层面的可解释性，在AML子类型分类任务上达到与最先进方法相当的性能。

Abstract: Sparse autoencoders (SAEs) emerged as a promising tool for mechanistic
interpretability of transformer-based foundation models. Very recently, SAEs
were also adopted for the visual domain, enabling the discovery of visual
concepts and their patch-wise attribution to tokens in the transformer model.
While a growing number of foundation models emerged for medical imaging, tools
for explaining their inferences are still lacking. In this work, we show the
applicability of SAEs for hematology. We propose CytoSAE, a sparse autoencoder
which is trained on over 40,000 peripheral blood single-cell images. CytoSAE
generalizes to diverse and out-of-domain datasets, including bone marrow
cytology, where it identifies morphologically relevant concepts which we
validated with medical experts. Furthermore, we demonstrate scenarios in which
CytoSAE can generate patient-specific and disease-specific concepts, enabling
the detection of pathognomonic cells and localized cellular abnormalities at
the patch level. We quantified the effect of concepts on a patient-level AML
subtype classification task and show that CytoSAE concepts reach performance
comparable to the state-of-the-art, while offering explainability on the
sub-cellular level. Source code and model weights are available at
https://github.com/dynamical-inference/cytosae.

</details>


### [86] [PhysX: Physical-Grounded 3D Asset Generation](https://arxiv.org/abs/2507.12465)
*Ziang Cao,Zhaoxi Chen,Linag Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: 提出PhysX框架，包含PhysXNet数据集和PhysXGen模型，用于生成包含物理属性的3D资源，解决了现有3D生成模型忽视物理属性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的3D生成模型主要关注几何和纹理，忽视了物理属性，导致生成的3D资源在模拟和具身智能等物理领域应用受限。

Method: 提出了一种名为PhysX的端到端物理属性3D资源生成范式，包括：1）PhysXNet，一个包含绝对尺度、材质、可及性、运动学和功能描述五个基础维度的物理属性3D数据集，并设计了基于视觉-语言模型的、可扩展的人工辅助标注流程；2）PhysXGen，一个前馈的、用于物理属性图像到3D资源生成的框架，通过双分支结构明确建模3D结构和物理属性之间的潜在相关性，将物理知识注入预训练的3D结构空间。

Result: 实验验证了PhysXGen框架的优越性能和良好的泛化能力。

Conclusion: PhysXGen在保留原生几何质量的同时，能够生成具有可信物理预测的3D资源。

Abstract: 3D modeling is moving from virtual to physical. Existing 3D generation
primarily emphasizes geometries and textures while neglecting physical-grounded
modeling. Consequently, despite the rapid development of 3D generative models,
the synthesized 3D assets often overlook rich and important physical
properties, hampering their real-world application in physical domains like
simulation and embodied AI. As an initial attempt to address this challenge, we
propose \textbf{PhysX}, an end-to-end paradigm for physical-grounded 3D asset
generation. 1) To bridge the critical gap in physics-annotated 3D datasets, we
present PhysXNet - the first physics-grounded 3D dataset systematically
annotated across five foundational dimensions: absolute scale, material,
affordance, kinematics, and function description. In particular, we devise a
scalable human-in-the-loop annotation pipeline based on vision-language models,
which enables efficient creation of physics-first assets from raw 3D assets.2)
Furthermore, we propose \textbf{PhysXGen}, a feed-forward framework for
physics-grounded image-to-3D asset generation, injecting physical knowledge
into the pre-trained 3D structural space. Specifically, PhysXGen employs a
dual-branch architecture to explicitly model the latent correlations between 3D
structures and physical properties, thereby producing 3D assets with plausible
physical predictions while preserving the native geometry quality. Extensive
experiments validate the superior performance and promising generalization
capability of our framework. All the code, data, and models will be released to
facilitate future research in generative physical AI.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [87] [Subjective Evaluation Profile Analysis of Science Fiction Short Stories and its Critical-Theoretical Significance](https://arxiv.org/abs/2507.11582)
*Kazuyoshi Otsuka*

Main category: cs.CL

TL;DR: LLMs show unique literary evaluation patterns and biases, similar to human critics, rather than being neutral evaluators.


<details>
  <summary>Details</summary>
Motivation: To explore aesthetic preferences and evaluation patterns in literary assessment by positioning LLMs as subjective literary critics.

Method: Ten Japanese science fiction short stories were translated into English and evaluated by six state-of-the-art LLMs across seven independent sessions. Principal component analysis and clustering techniques were used for analysis.

Result: Significant variations in evaluation consistency (alpha ranging from 1.00 to 0.35) and five distinct evaluation patterns were revealed. Evaluation variance across stories differed by up to 4.5-fold, with distinctive evaluation vocabularies for each model confirmed by TF-IDF analysis.

Conclusion: LLMs may possess individual evaluation characteristics similar to human critical schools, rather than functioning as neutral benchmarkers.

Abstract: This study positions large language models (LLMs) as "subjective literary
critics" to explore aesthetic preferences and evaluation patterns in literary
assessment. Ten Japanese science fiction short stories were translated into
English and evaluated by six state-of-the-art LLMs across seven independent
sessions. Principal component analysis and clustering techniques revealed
significant variations in evaluation consistency ({\alpha} ranging from 1.00 to
0.35) and five distinct evaluation patterns. Additionally, evaluation variance
across stories differed by up to 4.5-fold, with TF-IDF analysis confirming
distinctive evaluation vocabularies for each model. Our seven-session
within-day protocol using an original Science Fiction corpus strategically
minimizes external biases, allowing us to observe implicit value systems shaped
by RLHF and their influence on literary judgment. These findings suggest that
LLMs may possess individual evaluation characteristics similar to human
critical schools, rather than functioning as neutral benchmarkers.

</details>


### [88] [MapIQ: Benchmarking Multimodal Large Language Models for Map Question Answering](https://arxiv.org/abs/2507.11625)
*Varun Srivastava,Fan Lei,Srija Mukhopadhyay,Vivek Gupta,Ross Maciejewski*

Main category: cs.CL

TL;DR: 本文提出了MapIQ数据集，用于评估多模态大语言模型在不同类型地图上的视觉问答能力，并分析了模型对地图设计的敏感性。


<details>
  <summary>Details</summary>
Motivation: 现有地图视觉问答（Map-VQA）研究主要集中在分级统计地图，限制了研究范围和对地图类型的覆盖。本文旨在通过引入包含多种地图类型和主题的数据集，并评估多模态大语言模型在这些地图上的表现，来推动Map-VQA领域的发展，并探究模型对地图设计的鲁棒性和敏感性。

Method: 创建了一个包含14,706个问题-答案对的MapIQ数据集，涵盖了分级统计地图、地图填充图和比例符号地图三种地图类型，以及住房、犯罪等六个不同主题。评估了多个多模态大语言模型在六种视觉分析任务上的表现，并与人类基线进行了比较。通过额外的实验研究了地图设计变化（如颜色方案、图例设计、地图元素移除）对模型性能的影响。

Result: 在MapIQ数据集上，多模态大语言模型在不同地图类型和视觉分析任务上的表现各异。实验结果揭示了模型在处理特定地图类型（如比例符号地图）和执行某些分析任务（如空间关系推理）时面临的挑战，并指出了地图设计变化对模型性能的显著影响，提示了未来改进的方向。

Conclusion: MapIQ基准数据集的评估表明，多模态大语言模型在地图视觉问答任务上仍有提升空间，尤其是在处理不同地图类型和应对地图设计变化方面。

Abstract: Recent advancements in multimodal large language models (MLLMs) have driven
researchers to explore how well these models read data visualizations, e.g.,
bar charts, scatter plots. More recently, attention has shifted to visual
question answering with maps (Map-VQA). However, Map-VQA research has primarily
focused on choropleth maps, which cover only a limited range of thematic
categories and visual analytical tasks. To address these gaps, we introduce
MapIQ, a benchmark dataset comprising 14,706 question-answer pairs across three
map types: choropleth maps, cartograms, and proportional symbol maps spanning
topics from six distinct themes (e.g., housing, crime). We evaluate multiple
MLLMs using six visual analytical tasks, comparing their performance against
one another and a human baseline. An additional experiment examining the impact
of map design changes (e.g., altered color schemes, modified legend designs,
and removal of map elements) provides insights into the robustness and
sensitivity of MLLMs, their reliance on internal geographic knowledge, and
potential avenues for improving Map-VQA performance.

</details>


### [89] [Cross-lingual Few-shot Learning for Persian Sentiment Analysis with Incremental Adaptation](https://arxiv.org/abs/2507.11634)
*Farideh Majidi,Ziaeddin Beheshtifard*

Main category: cs.CL

TL;DR: 本研究通过结合少样本学习、增量学习和多语言预训练模型（如mDeBERTa和XLM-RoBERTa），成功实现了波斯语跨语言情感分析，准确率高达96%.


<details>
  <summary>Details</summary>
Motivation: 为了解决波斯语等低资源语言在情感分析任务中数据不足的问题，本研究旨在开发一种能够利用有限数据并从高资源语言获取先验知识的模型。

Method: 本研究采用了少样本学习和增量学习方法，并使用了XLM-RoBERTa、mDeBERTa和DistilBERT三个预训练的多语言模型，在来自X、Instagram、Digikala、Snappfood和Taaghche等多种来源的波斯语小样本数据上进行了微调。

Result: 实验结果表明，mDeBERTa和XLM-RoBERTa在波斯语情感分析任务上取得了高绩效，准确率达到了96%。

Conclusion: 本研究成功开发了一种在波斯语中使用少样本和增量学习方法进行跨语言情感分析的模型，mDeBERTa和XLM-RoBERTa模型达到了96%的准确率，证明了结合少样本学习、增量学习和多语言预训练模型的有效性。

Abstract: This research examines cross-lingual sentiment analysis using few-shot
learning and incremental learning methods in Persian. The main objective is to
develop a model capable of performing sentiment analysis in Persian using
limited data, while getting prior knowledge from high-resource languages. To
achieve this, three pre-trained multilingual models (XLM-RoBERTa, mDeBERTa, and
DistilBERT) were employed, which were fine-tuned using few-shot and incremental
learning approaches on small samples of Persian data from diverse sources,
including X, Instagram, Digikala, Snappfood, and Taaghche. This variety enabled
the models to learn from a broad range of contexts. Experimental results show
that the mDeBERTa and XLM-RoBERTa achieved high performances, reaching 96%
accuracy on Persian sentiment analysis. These findings highlight the
effectiveness of combining few-shot learning and incremental learning with
multilingual pre-trained models.

</details>


### [90] [Partitioner Guided Modal Learning Framework](https://arxiv.org/abs/2507.11661)
*Guimin Hu,Yi Xin,Lijie Hu,Zhihong Zhu,Hasti Seifi*

Main category: cs.CL

TL;DR: PgM框架通过模态划分器将多模态表示划分为单模态和配对模态特征，分别进行学习和重建，以提高多模态学习的效果和灵活性。


<details>
  <summary>Details</summary>
Motivation: 为了充分利用多模态学习中的信息，同时能够灵活调整不同模态和分区的表示以适应不同的下游任务。

Method: PgM框架由模态划分器、单模态学习器、配对模态学习器和单配对模态解码器组成，其中模态划分器将学习到的模态表示分割成单模态和配对模态特征，模态学习器包含用于单模态和配对模态学习的专用组件，而单配对模态解码器则基于单模态和配对模态特征重建模态表示。

Result: PgM框架能够彻底学习单模态和配对模态特征，并具有灵活调整表示分布的能力，同时允许跨模态和分区的不同学习速率，并在四个多模态任务和现有模型上均取得了显著效果。

Conclusion: PgM框架在四个多模态任务中被证明是有效的，并且可以迁移到现有模型，同时可以调整模态和分区的分布以及学习速率。

Abstract: Multimodal learning benefits from multiple modal information, and each
learned modal representations can be divided into uni-modal that can be learned
from uni-modal training and paired-modal features that can be learned from
cross-modal interaction. Building on this perspective, we propose a
partitioner-guided modal learning framework, PgM, which consists of the modal
partitioner, uni-modal learner, paired-modal learner, and uni-paired modal
decoder. Modal partitioner segments the learned modal representation into
uni-modal and paired-modal features. Modal learner incorporates two dedicated
components for uni-modal and paired-modal learning. Uni-paired modal decoder
reconstructs modal representation based on uni-modal and paired-modal features.
PgM offers three key benefits: 1) thorough learning of uni-modal and
paired-modal features, 2) flexible distribution adjustment for uni-modal and
paired-modal representations to suit diverse downstream tasks, and 3) different
learning rates across modalities and partitions. Extensive experiments
demonstrate the effectiveness of PgM across four multimodal tasks and further
highlight its transferability to existing models. Additionally, we visualize
the distribution of uni-modal and paired-modal features across modalities and
tasks, offering insights into their respective contributions.

</details>


### [91] [Chain-of-Descriptions: Improving Code LLMs for VHDL Code Generation and Summarization](https://arxiv.org/abs/2507.12308)
*Prashanth Vijayaraghavan,Apoorva Nitsure,Charles Mackin,Luyao Shi,Stefano Ambrogio,Arvind Haran,Viresh Paruthi,Ali Elzein,Dan Coops,David Beymer,Tyler Baldwin,Ehsan Degan*

Main category: cs.CL

TL;DR: 本研究发现现有的大型语言模型（LLMs）在处理VHDL代码（一种硬件描述语言）时表现不佳。为了解决这个问题，研究者们提出了一种名为Chain-of-Descriptions (CoDes)的新方法。该方法通过让LLMs先生成一系列中间描述步骤，然后再生成最终的VHDL代码或摘要，来显著提高模型的性能。实验结果表明，CoDes方法比传统的直接提示方法效果更好，为改进LLMs在VHDL领域的应用提供了新的途径。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在通用代码任务中广泛应用，但针对硬件描述语言（HDL），特别是VHDL的研究和优化仍然不足。现有代码LLMs在VHDL代码生成和摘要任务上表现不佳，存在显著的性能差距。

Method: 提出了Chain-of-Descriptions (CoDes)新方法，通过生成一系列中间描述步骤来增强LLMs处理VHDL代码的能力，并将其与原始输入结合。在VHDL-Eval和VHDL-Xform两个数据集上进行了评估。

Result: 现有代码LLMs在VHDL代码生成和摘要任务上表现不佳。CoDes方法相比标准提示策略在多个指标上均有显著提升，证明了其有效性。

Conclusion: 本研究提出的Chain-of-Descriptions (CoDes)方法显著提高了LLMs在VHDL代码生成和摘要任务上的表现，并为未来相关研究提供了框架。

Abstract: Large Language Models (LLMs) have become widely used across diverse NLP tasks
and domains, demonstrating their adaptability and effectiveness. In the realm
of Electronic Design Automation (EDA), LLMs show promise for tasks like
Register-Transfer Level (RTL) code generation and summarization. However,
despite the proliferation of LLMs for general code-related tasks, there's a
dearth of research focused on evaluating and refining these models for hardware
description languages (HDLs), notably VHDL. In this study, we evaluate the
performance of existing code LLMs for VHDL code generation and summarization
using various metrics and two datasets -- VHDL-Eval and VHDL-Xform. The latter,
an in-house dataset, aims to gauge LLMs' understanding of functionally
equivalent code. Our findings reveal consistent underperformance of these
models across different metrics, underscoring a significant gap in their
suitability for this domain. To address this challenge, we propose
Chain-of-Descriptions (CoDes), a novel approach to enhance the performance of
LLMs for VHDL code generation and summarization tasks. CoDes involves
generating a series of intermediate descriptive steps based on: (i) the problem
statement for code generation, and (ii) the VHDL code for summarization. These
steps are then integrated with the original input prompt (problem statement or
code) and provided as input to the LLMs to generate the final output. Our
experiments demonstrate that the CoDes approach significantly surpasses the
standard prompting strategy across various metrics on both datasets. This
method not only improves the quality of VHDL code generation and summarization
but also serves as a framework for future research aimed at enhancing code LLMs
for VHDL.

</details>


### [92] [ExpliCIT-QA: Explainable Code-Based Image Table Question Answering](https://arxiv.org/abs/2507.11694)
*Maximiliano Hormazábal Lagos,Álvaro Bueno Sáez,Pedro Alonso Doval,Jorge Alcalde Vesteiro,Héctor Cerezo-Costas*

Main category: cs.CL

TL;DR: ExpliCIT-QA是一个多模态表格问答系统，通过链式思考、逐步推理、代码生成和执行来提供可解释的答案，并在TableVQA-Bench上展示了其在透明度和可审计性方面的优势。


<details>
  <summary>Details</summary>
Motivation: 该系统旨在弥合端到端表格视觉问答（TableVQA）系统的可解释性差距，提供透明度和可审计性，允许检查所有中间输出，包括解析的表格、推理步骤、生成的代码和最终答案。

Method: ExpliCIT-QA是一个多模态问答系统，采用模块化设计，包括多模态表格理解（使用链式思考提取表格图像内容）、基于语言的推理（生成逐步解释）、自动代码生成（创建Python/Pandas脚本并进行错误处理）、代码执行（计算最终答案）以及自然语言解释（描述答案计算过程）。

Result: ExpliCIT-QA在TableVQA-Bench基准上进行了评估，与现有基线进行了比较，在可解释性和透明度方面取得了改进。

Conclusion: ExpliCIT-QA在TableVQA-Bench基准上进行了评估，与现有基线进行了比较，在可解释性和透明度方面取得了改进，为金融和医疗保健等需要审计结果的敏感领域提供了应用前景。

Abstract: We present ExpliCIT-QA, a system that extends our previous MRT approach for
tabular question answering into a multimodal pipeline capable of handling
complex table images and providing explainable answers. ExpliCIT-QA follows a
modular design, consisting of: (1) Multimodal Table Understanding, which uses a
Chain-of-Thought approach to extract and transform content from table images;
(2) Language-based Reasoning, where a step-by-step explanation in natural
language is generated to solve the problem; (3) Automatic Code Generation,
where Python/Pandas scripts are created based on the reasoning steps, with
feedback for handling errors; (4) Code Execution to compute the final answer;
and (5) Natural Language Explanation that describes how the answer was
computed. The system is built for transparency and auditability: all
intermediate outputs, parsed tables, reasoning steps, generated code, and final
answers are available for inspection. This strategy works towards closing the
explainability gap in end-to-end TableVQA systems. We evaluated ExpliCIT-QA on
the TableVQA-Bench benchmark, comparing it with existing baselines. We
demonstrated improvements in interpretability and transparency, which open the
door for applications in sensitive domains like finance and healthcare where
auditing results are critical.

</details>


### [93] [CRABS: A syntactic-semantic pincer strategy for bounding LLM interpretation of Python notebooks](https://arxiv.org/abs/2507.11742)
*Meng Li,Timothy M. McPhillips,Dingmin Wang,Shin-Rong Tsai,Bertram Ludäscher*

Main category: cs.CL

TL;DR: CRABS是一种结合语法分析和LLM的新方法，能准确理解Python笔记本的数据流和执行依赖，解决了现有LLM的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在理解包含复杂数据和软件依赖的Python笔记本时存在局限性，常出现幻觉和长上下文问题，导致评估、复用和改编笔记本变得困难。需要一种更有效的方法来理解笔记本的结构和数据流。

Method: CRABS策略：结合浅层语法分析（AST）和LLM的零样本学习，通过识别单元格的输入输出集来解决歧义，从而构建信息流图和单元格执行依赖图。

Result: CRABS在包含3454个单元格输入输出的50个Kaggle笔记本的数据集上进行了评估，LLM在解决语法分析遗留的歧义方面达到了98%的准确率。CRABS在识别单元格间信息流方面取得了98%的平均F1分数，在识别传递性单元格执行依赖方面取得了99%的平均F1分数。

Conclusion: CRABS通过结合浅层语法分析和LLM的零样本学习能力，在识别笔记本中的信息流和单元格执行依赖性方面表现出色，准确率分别达到98%和99%，有效解决了现有LLM在理解复杂笔记本时遇到的挑战。

Abstract: Recognizing the information flows and operations comprising data science and
machine learning Python notebooks is critical for evaluating, reusing, and
adapting notebooks for new tasks. Investigating a notebook via re-execution
often is impractical due to the challenges of resolving data and software
dependencies. While Large Language Models (LLMs) pre-trained on large codebases
have demonstrated effectiveness in understanding code without running it, we
observe that they fail to understand some realistic notebooks due to
hallucinations and long-context challenges. To address these issues, we propose
a notebook understanding task yielding an information flow graph and
corresponding cell execution dependency graph for a notebook, and demonstrate
the effectiveness of a pincer strategy that uses limited syntactic analysis to
assist full comprehension of the notebook using an LLM. Our Capture and Resolve
Assisted Bounding Strategy (CRABS) employs shallow syntactic parsing and
analysis of the abstract syntax tree (AST) to capture the correct
interpretation of a notebook between lower and upper estimates of the
inter-cell I/O sets, then uses an LLM to resolve remaining ambiguities via
cell-by-cell zero-shot learning, thereby identifying the true data inputs and
outputs of each cell. We evaluate and demonstrate the effectiveness of our
approach using an annotated dataset of 50 representative, highly up-voted
Kaggle notebooks that together represent 3454 actual cell inputs and outputs.
The LLM correctly resolves 1397 of 1425 (98%) ambiguities left by analyzing the
syntactic structure of these notebooks. Across 50 notebooks, CRABS achieves
average F1 scores of 98% identifying cell-to-cell information flows and 99%
identifying transitive cell execution dependencies.

</details>


### [94] [Value-Based Large Language Model Agent Simulation for Mutual Evaluation of Trust and Interpersonal Closeness](https://arxiv.org/abs/2507.11979)
*Yuki Sakamoto,Takahisa Uchida,Hiroshi Ishiguro*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large language models (LLMs) have emerged as powerful tools for simulating
complex social phenomena using human-like agents with specific traits. In human
societies, value similarity is important for building trust and close
relationships; however, it remains unexplored whether this principle holds true
in artificial societies comprising LLM agents. Therefore, this study
investigates the influence of value similarity on relationship-building among
LLM agents through two experiments. First, in a preliminary experiment, we
evaluated the controllability of values in LLMs to identify the most effective
model and prompt design for controlling the values. Subsequently, in the main
experiment, we generated pairs of LLM agents imbued with specific values and
analyzed their mutual evaluations of trust and interpersonal closeness
following a dialogue. The experiments were conducted in English and Japanese to
investigate language dependence. The results confirmed that pairs of agents
with higher value similarity exhibited greater mutual trust and interpersonal
closeness. Our findings demonstrate that the LLM agent simulation serves as a
valid testbed for social science theories, contributes to elucidating the
mechanisms by which values influence relationship building, and provides a
foundation for inspiring new theories and insights into the social sciences.

</details>


### [95] [AI Wizards at CheckThat! 2025: Enhancing Transformer-Based Embeddings with Sentiment for Subjectivity Detection in News Articles](https://arxiv.org/abs/2507.11764)
*Matteo Fasulo,Luca Babboni,Luca Tedeschini*

Main category: cs.CL

TL;DR: AI Wizards improved news subjectivity detection by adding sentiment scores to transformer models, achieving top rankings, including 1st in Greek.


<details>
  <summary>Details</summary>
Motivation: To improve subjectivity detection in news articles by exploring the integration of sentiment scores into transformer-based models and assessing generalization capabilities across various languages, including unseen ones.

Method: The study enhanced transformer-based classifiers (mDeBERTaV3-base, ModernBERT-base, Llama3.2-1B) by integrating sentiment scores from an auxiliary model with sentence representations. Decision threshold calibration was used to handle class imbalance.

Result: Sentiment feature integration significantly boosted performance, especially the subjective F1 score. The framework achieved high rankings, including 1st place for Greek with a Macro F1 score of 0.51.

Conclusion: AI Wizards' sentiment-augmented transformer models achieved strong performance in the CLEF 2025 CheckThat! Task 1, demonstrating significant improvements, particularly in subjective F1 score, and ranking first for Greek.

Abstract: This paper presents AI Wizards' participation in the CLEF 2025 CheckThat! Lab
Task 1: Subjectivity Detection in News Articles, classifying sentences as
subjective/objective in monolingual, multilingual, and zero-shot settings.
Training/development datasets were provided for Arabic, German, English,
Italian, and Bulgarian; final evaluation included additional unseen languages
(e.g., Greek, Romanian, Polish, Ukrainian) to assess generalization. Our
primary strategy enhanced transformer-based classifiers by integrating
sentiment scores, derived from an auxiliary model, with sentence
representations, aiming to improve upon standard fine-tuning. We explored this
sentiment-augmented architecture with mDeBERTaV3-base, ModernBERT-base
(English), and Llama3.2-1B. To address class imbalance, prevalent across
languages, we employed decision threshold calibration optimized on the
development set. Our experiments show sentiment feature integration
significantly boosts performance, especially subjective F1 score. This
framework led to high rankings, notably 1st for Greek (Macro F1 = 0.51).

</details>


### [96] [Tracing Facts or just Copies? A critical investigation of the Competitions of Mechanisms in Large Language Models](https://arxiv.org/abs/2507.11809)
*Dante Campregher,Yanxu Chen,Sander Hoffman,Maria Heuss*

Main category: cs.CL

TL;DR: 本研究通过可复现性研究，利用机械可解释性工具，分析了大型语言模型（LLMs）如何处理包含事实与反事实信息。研究发现，注意力头通过通用复制抑制而非选择性反事实抑制来促进事实输出，且这种行为具有领域依赖性，更大模型的模式更专业化和类别敏感。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨大型语言模型（LLMs）在面对相互竞争的事实信息和反事实信息时如何进行处理，并着重研究注意力头在此过程中扮演的角色。研究试图重现并解释三项近期研究（Ortu et al., Yu, Merullo, and Pavlick以及McDougall et al.）关于模型学习的事实与矛盾上下文信息之间竞争的研究结果，这些研究利用了机械可解释性工具。

Method: 本研究采用可复现性研究方法，利用机械可解释性工具，通过分析注意力头的行为来研究大型语言模型（LLMs）处理竞争性事实信息和反事实信息的能力。研究重点关注注意力头在这一过程中的作用，并试图重现和调和三项近期研究的发现。具体而言，本研究检查了注意力头强度与事实输出比例之间的关系，评估了关于注意力头抑制机制的竞争性假设，并调查了这些注意力模式的领域特异性。

Result: 研究发现，促进事实输出的注意力头通过通用的复制抑制机制（而非选择性的反事实抑制）来实现这一点，因为增强这些注意力头也会抑制正确事实的输出。此外，研究表明注意力头的行为是领域依赖的，更大模型表现出更专业化和更具类别敏感性的模式。

Conclusion: 研究结果表明，在处理竞争性事实和反事实信息时，语言模型（LLMs）通过通用的复制抑制机制而非选择性的反事实抑制来促进事实的输出。此外，注意力头行为具有领域依赖性，更大模型的模式更加专业化和类别敏感。

Abstract: This paper presents a reproducibility study examining how Large Language
Models (LLMs) manage competing factual and counterfactual information, focusing
on the role of attention heads in this process. We attempt to reproduce and
reconcile findings from three recent studies by Ortu et al., Yu, Merullo, and
Pavlick and McDougall et al. that investigate the competition between
model-learned facts and contradictory context information through Mechanistic
Interpretability tools. Our study specifically examines the relationship
between attention head strength and factual output ratios, evaluates competing
hypotheses about attention heads' suppression mechanisms, and investigates the
domain specificity of these attention patterns. Our findings suggest that
attention heads promoting factual output do so via general copy suppression
rather than selective counterfactual suppression, as strengthening them can
also inhibit correct facts. Additionally, we show that attention head behavior
is domain-dependent, with larger models exhibiting more specialized and
category-sensitive patterns.

</details>


### [97] [ILID: Native Script Language Identification for Indian Languages](https://arxiv.org/abs/2507.11832)
*Yash Ingle,Pruthwik Mishra*

Main category: cs.CL

TL;DR: 该研究发布了一个包含230K个句子（包括英语和所有22种官方印度语言）的数据集，并开发了强大的基线模型，以应对印度语言识别的挑战。


<details>
  <summary>Details</summary>
Motivation: 语言识别在NLP中至关重要，尤其是在处理嘈杂、短小和混合语言的环境时，而印度语言之间由于词汇和语音相似性以及共享相同脚本而具有挑战性。

Method: 使用最新的机器学习和深度学习方法开发和发布了强大的基线模型。

Result: 发布了一个包含230K个句子（包括英语和所有22种官方印度语言）的数据集，其中大部分数据是新创建的，并开发了可与最先进模型相媲美的基线模型。

Conclusion: 发布了一个包含230K个句子（包括英语和所有22种官方印度语言）的数据集，并开发了强大的基线模型，这些模型在语言识别任务上可与最先进的模型相媲美。

Abstract: The language identification task is a crucial fundamental step in NLP. Often
it serves as a pre-processing step for widely used NLP applications such as
multilingual machine translation, information retrieval, question and
answering, and text summarization. The core challenge of language
identification lies in distinguishing languages in noisy, short, and code-mixed
environments. This becomes even harder in case of diverse Indian languages that
exhibit lexical and phonetic similarities, but have distinct differences. Many
Indian languages share the same script making the task even more challenging.
In this paper, we release a dataset of 230K sentences consisting of English and
all 22 official Indian languages labeled with their language identifiers where
data in most languages are newly created. We also develop and release robust
baseline models using state-of-the-art approaches in machine learning and deep
learning that can aid the research in this field. Our baseline models are
comparable to the state-of-the-art models for the language identification task.

</details>


### [98] [Your LLM Knows the Future: Uncovering Its Multi-Token Prediction Potential](https://arxiv.org/abs/2507.11851)
*Mohammad Samragh,Arnav Kundu,David Harrison,Kumari Nishu,Devang Naik,Minsik Cho,Mehrdad Farajtabar*

Main category: cs.CL

TL;DR: 通过利用未来标记的知识并引入屏蔽输入、门控 LoRA、采样器模块、辅助损失和投机生成等创新，该方法在不损失质量的情况下，将语言模型的推理速度提高了多达5倍。


<details>
  <summary>Details</summary>
Motivation: 为了克服自回归语言模型固有的顺序生成模式的限制，该模型利用了标准自回归语言模型关于未来标记的内在知识，并结合了多种技术以实现这一潜力，从而能够同步预测多个后续标记。

Method: 该框架通过以下关键创新实现多于一个的标记的同步预测：(1) 屏蔽输入形式，其中多个未来标记从共同前缀联合预测；(2) 门控 LoRA 形式，保留了原始 LLM 的功能，同时支持多标记预测；(3) 轻量级、可学习的采样器模块，从预测的未来标记生成连贯序列；(4) 一组辅助训练损失，包括一致性损失，以增强联合预测标记的一致性和准确性；(5) 投机生成策略，在未来二次方扩展标记，同时保持高保真度。

Result: 该方法实现了显著的加速，在生成代码和数学方面速度提高了近5倍，在通用聊天和知识任务方面速度提高了近2.5倍，同时没有损失任何质量。

Conclusion: 该方法通过监督微调预训练模型实现了显著的加速，在生成代码和数学方面速度提高了近5倍，在通用聊天和知识任务方面速度提高了近2.5倍，并且没有损失任何质量。

Abstract: Autoregressive language models are constrained by their inherently sequential
nature, generating one token at a time. This paradigm limits inference speed
and parallelism, especially during later stages of generation when the
direction and semantics of text are relatively certain. In this work, we
propose a novel framework that leverages the inherent knowledge of vanilla
autoregressive language models about future tokens, combining techniques to
realize this potential and enable simultaneous prediction of multiple
subsequent tokens. Our approach introduces several key innovations: (1) a
masked-input formulation where multiple future tokens are jointly predicted
from a common prefix; (2) a gated LoRA formulation that preserves the original
LLM's functionality, while equipping it for multi-token prediction; (3) a
lightweight, learnable sampler module that generates coherent sequences from
the predicted future tokens; (4) a set of auxiliary training losses, including
a consistency loss, to enhance the coherence and accuracy of jointly generated
tokens; and (5) a speculative generation strategy that expands tokens
quadratically in the future while maintaining high fidelity. Our method
achieves significant speedups through supervised fine-tuning on pretrained
models. For example, it generates code and math nearly 5x faster, and improves
general chat and knowledge tasks by almost 2.5x. These gains come without any
loss in quality.

</details>


### [99] [Cross-Domain Transfer and Few-Shot Learning for Personal Identifiable Information Recognition](https://arxiv.org/abs/2507.11862)
*Junhong Ye,Xu Yuan,Xinying Qiu*

Main category: cs.CL

TL;DR: 本文研究了跨领域迁移、数据融合和少样本学习在PII识别中的应用，发现法律-传记迁移效果好，医疗迁移效果差，融合收益因领域而异，低专业化领域少样本也能实现高识别率。


<details>
  <summary>Details</summary>
Motivation: 准确识别个人身份信息（PII）是自动化文本匿名化的核心。本文研究跨领域模型迁移、多领域数据融合和样本高效学习在PII识别中的有效性。

Method: 使用来自医疗（I2B2）、法律（TAB）和传记（Wikipedia）的标注语料库，评估模型在四个维度上的表现：领域内性能、跨领域迁移性、融合和少样本学习。

Result: 法律领域数据能很好地迁移到传记文本，而医疗领域数据则难以接受外部迁移。融合的收益因领域而异，在低专业化领域，仅需10%的训练数据即可实现高识别率。

Conclusion: 跨领域模型迁移、多领域数据融合和样本高效学习可用于PII识别，其中法律领域数据对传记文本的迁移效果良好，而医疗领域数据的迁移效果不佳。数据融合的收益具有领域特异性，并且在低专业化领域，仅使用10%的训练数据即可实现高质量的识别。

Abstract: Accurate recognition of personally identifiable information (PII) is central
to automated text anonymization. This paper investigates the effectiveness of
cross-domain model transfer, multi-domain data fusion, and sample-efficient
learning for PII recognition. Using annotated corpora from healthcare (I2B2),
legal (TAB), and biography (Wikipedia), we evaluate models across four
dimensions: in-domain performance, cross-domain transferability, fusion, and
few-shot learning. Results show legal-domain data transfers well to
biographical texts, while medical domains resist incoming transfer. Fusion
benefits are domain-specific, and high-quality recognition is achievable with
only 10% of training data in low-specialization domains.

</details>


### [100] [COLA-GEC: A Bidirectional Framework for Enhancing Grammatical Acceptability and Error Correction](https://arxiv.org/abs/2507.11867)
*Xiangyu Yang,Xinying Qiu*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Grammatical Error Correction (GEC) and grammatical acceptability judgment
(COLA) are core tasks in natural language processing, sharing foundational
grammatical knowledge yet typically evolving independently. This paper
introduces COLA-GEC, a novel bidirectional framework that enhances both tasks
through mutual knowledge transfer. First, we augment grammatical acceptability
models using GEC datasets, significantly improving their performance across
multiple languages. Second, we integrate grammatical acceptability signals into
GEC model training via a dynamic loss function, effectively guiding corrections
toward grammatically acceptable outputs. Our approach achieves state-of-the-art
results on several multilingual benchmarks. Comprehensive error analysis
highlights remaining challenges, particularly in punctuation error correction,
providing insights for future improvements in grammatical modeling.

</details>


### [101] [DualReward: A Dynamic Reinforcement Learning Framework for Cloze Tests Distractor Generation](https://arxiv.org/abs/2507.11875)
*Tianyou Huang,Xinglu Chen,Jingshen Zhang,Xinying Qiu,Ruiying Niu*

Main category: cs.CL

TL;DR: DualReward是一个基于强化学习的框架，通过双奖励机制和自适应缩放来生成填空测试干扰项，相比现有方法在多样化数据上表现更优。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统依赖监督学习或静态生成模型的填空测试干扰项自动生成方法的局限性，本文提出了一种新颖的强化学习框架。

Method: 本文提出了一种新颖的强化学习框架DualReward，其核心在于使用一种包含自适应缩放的双奖励结构，以区分人类创建的优质干扰项和模型生成的候选干扰项，并根据模型的性能和置信度动态调整奖励信号的强度。

Result: 在CLOTH-F（段落级）和MCQ（句子级）两个填空测试数据集上的评估结果显示，DualReward相比现有最先进的方法在CLOTH-F数据集上实现了稳步提升，在MCQ数据集上则带来了更显著的性能提升（P@1提升3.48-3.86%），证明了其在处理多样化问题类型和领域方面的有效性。

Conclusion: DualReward框架通过引入包含自适应缩放的双奖励结构，在自动生成填空测试干扰项方面取得了显著成效，尤其在处理多样化跨领域数据时表现突出。

Abstract: This paper introduces DualReward, a novel reinforcement learning framework
for automatic distractor generation in cloze tests. Unlike conventional
approaches that rely primarily on supervised learning or static generative
models, our method employs a dual reward structure with adaptive scaling that
differentiates between human-created gold standard distractors and
model-generated candidates. The framework dynamically adjusts reward signal
intensity based on model performance and confidence. We evaluate our approach
on both passage-level (CLOTH-F) and sentence-level (MCQ) cloze test datasets,
demonstrating consistent improvements over state-of-the-art baselines.
Experimental results show that our adaptive reward scaling mechanism provides
modest but consistent benefits on homogeneous datasets (CLOTH-F) and more
substantial improvements (3.48-3.86% in P@1) on diverse, cross-domain data
(MCQ), suggesting its particular effectiveness for handling varied question
types and domains. Our work offers a flexible framework that effectively
balances learning from reliable human examples while exploring novel,
high-quality distractors for automated test generation.

</details>


### [102] [LLMs Encode Harmfulness and Refusal Separately](https://arxiv.org/abs/2507.11878)
*Jiachen Zhao,Jing Huang,Zhengxuan Wu,David Bau,Weiyan Shi*

Main category: cs.CL

TL;DR: LLM的安全机制比其拒绝行为更能反映其对有害性的理解。我们发现了一个独立的“有害性方向”，可用于检测不安全输入，并提出了一种名为Latent Guard的内置安全机制，其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 探究LLMs在拒绝有害指令时，是否真正理解了“有害性”本身，而不仅仅是表现出拒绝行为。研究现有工作揭示的“拒绝方向”可能不足以全面解释LLMs的安全机制，因此提出识别并分析独立的“有害性方向”。

Method: 通过识别并操纵LLM内部编码的“有害性方向”来分析其安全机制。实验表明，沿着有害性方向进行干预会改变模型对指令有害性的判断，而沿着拒绝方向则直接引发拒绝行为。此外，还研究了某些越狱方法的工作原理以及对抗性微调对模型内部有害性理解的影响。

Result: 发现了与拒绝方向不同的“有害性方向”。沿有害性方向操纵可使LLM将无害指令误判为有害；而沿拒绝方向操纵则直接导致拒绝，但不会改变模型对有害性的判断。部分越狱方法通过降低拒绝信号而非改变内部有害性判断来奏效。对抗性微调对有害性理解影响甚微。提出的Latent Guard作为一种内置安全机制，在检测不安全输入和减少过度拒绝方面表现出色，性能媲美甚至优于Llama Guard 3 8B。

Conclusion: LLMs对有害指令的拒绝行为可能与其对有害性的内部理解是分离的。研究发现存在一个“有害性方向”，独立于“拒绝方向”，可以操纵模型将无害指令误判为有害。这种有害性表示可以作为一种内置的安全机制（Latent Guard），有效检测不安全输入并减少过度拒绝，并且能抵抗微调攻击，其性能可与专用安全模型媲美。

Abstract: LLMs are trained to refuse harmful instructions, but do they truly understand
harmfulness beyond just refusing? Prior work has shown that LLMs' refusal
behaviors can be mediated by a one-dimensional subspace, i.e., a refusal
direction. In this work, we identify a new dimension to analyze safety
mechanisms in LLMs, i.e., harmfulness, which is encoded internally as a
separate concept from refusal. There exists a harmfulness direction that is
distinct from the refusal direction. As causal evidence, steering along the
harmfulness direction can lead LLMs to interpret harmless instructions as
harmful, but steering along the refusal direction tends to elicit refusal
responses directly without reversing the model's judgment on harmfulness.
Furthermore, using our identified harmfulness concept, we find that certain
jailbreak methods work by reducing the refusal signals without reversing the
model's internal belief of harmfulness. We also find that adversarially
finetuning models to accept harmful instructions has minimal impact on the
model's internal belief of harmfulness. These insights lead to a practical
safety application: The model's latent harmfulness representation can serve as
an intrinsic safeguard (Latent Guard) for detecting unsafe inputs and reducing
over-refusals that is robust to finetuning attacks. For instance, our Latent
Guard achieves performance comparable to or better than Llama Guard 3 8B, a
dedicated finetuned safeguard model, across different jailbreak methods. Our
findings suggest that LLMs' internal understanding of harmfulness is more
robust than their refusal decision to diverse input instructions, offering a
new perspective to study AI safety

</details>


### [103] [BlockBPE: Parallel BPE Tokenization](https://arxiv.org/abs/2507.11941)
*Amos You*

Main category: cs.CL

TL;DR: BlockBPE 是一个在 GPU 上并行化 BPE 的新方法，速度更快，吞吐量更高。


<details>
  <summary>Details</summary>
Motivation: 现有的分词器（如 HuggingFace Tokenizers 和 OpenAI 的 tiktoken）在 GPU 批量推理工作流中是 CPU 密集型的，并且效率低下。

Method: BlockBPE 通过并行化 BPE 算法，在 GPU 上实现了高效的分词，将时间复杂度从 $O(n 	ext{ log } n) $ 降低到 $O(nd)$，其中 $d 	ext{ « } n$。它通过消除正则表达式预分词并优化线程块内的分词合并来实现这一点。

Result: 与 HuggingFace Tokenizers 和 tiktoken 相比，BlockBPE 在高批量推理工作负载下实现了高达 2 倍的吞吐量提升（相比 tiktoken）和 2.5 倍的吞吐量提升（相比 HuggingFace Tokenizers）。

Conclusion: BlockBPE 是一种创新的并行 GPU 实现，用于字节对编码 (BPE)，它通过消除正则表达式预分词并利用线程块内的并行分词合并，实现了接近线性的时间复杂度，显著提高了 GPU 上的批量推理吞吐量。

Abstract: Tokenization is a critical preprocessing step in large language model
pipelines, yet widely-used implementations remain CPU-bound and suboptimal for
batch inference workflows on GPU. We present BlockBPE, a parallel GPU
implementation of byte-pair encoding (BPE) that achieves near linear-time
complexity under realistic assumptions and is optimized for high-throughput,
batch inference. Unlike existing Rust-based tokenizers such as HuggingFace
Tokenizers or OpenAI's tiktoken-whose runtimes are dominated by Regex
pre-tokenization and exhibit $O(n \log n)$ runtime-BlockBPE eliminates the
Regex pre-tokenization which leads to small loss in generation quality, but
enables highly parallelized token merges within thread blocks, reducing overall
complexity to $O(nd)$ where $d \ll n$. On high-batch inference workloads,
BlockBPE achieves up to 2x higher throughput than tiktoken and 2.5x over
HuggingFace Tokenizers.

</details>


### [104] [Marco-Bench-MIF: On Multilingual Instruction-Following Capability of Large Language Models](https://arxiv.org/abs/2507.11882)
*Bo Zeng,Chenyang Lyu,Sinuo Liu,Mingyan Zeng,Minghao Wu,Xuanfan Ni,Tianqi Shi,Yu Zhao,Yefeng Liu,Chenyu Zhu,Ruizhe Li,Jiahui Geng,Qing Li,Yu Tong,Longyue Wang,Weihua Luo,Kaifu Zhang*

Main category: cs.CL

TL;DR: 为解决现有LLM评估数据集缺乏多语言和本地化的问题，我们创建了一个包含30种语言的Marco-Bench-MIF基准。评估结果显示，语言资源、模型规模和数据本地化对模型性能有显著影响，并指出了跨语言指令遵循的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）评估数据集在多语言和本地化方面存在不足，主要集中在英语或使用机器翻译，限制了其在多语言环境中的应用。

Method: 通过结合翻译和验证的混合流程，创建了一个包含30种语言的本地化多语言指令遵循评估数据集Marco-Bench-MIF，该数据集考虑了语言约束和文化参考。

Result: 在Marco-Bench-MIF上的评估显示：1. 高资源语言和低资源语言之间存在25-35%的准确性差距；2. 模型规模对性能有45-60%的影响，但仍然存在特定脚本的挑战；3. 机器翻译数据相比本地化数据低估了7-22%的准确性。

Conclusion: 该研究提出了一个名为Marco-Bench-MIF的多语言指令遵循基准，并对20多个大型语言模型进行了评估，发现了高低资源语言之间的准确性差距、模型规模的影响以及机器翻译数据低估准确性等问题。研究还指出了跨语言关键词一致性和组合约束遵守方面的挑战。

Abstract: Instruction-following capability has become a major ability to be evaluated
for Large Language Models (LLMs). However, existing datasets, such as IFEval,
are either predominantly monolingual and centered on English or simply machine
translated to other languages, limiting their applicability in multilingual
contexts. In this paper, we present an carefully-curated extension of IFEval to
a localized multilingual version named Marco-Bench-MIF, covering 30 languages
with varying levels of localization. Our benchmark addresses linguistic
constraints (e.g., modifying capitalization requirements for Chinese) and
cultural references (e.g., substituting region-specific company names in
prompts) via a hybrid pipeline combining translation with verification. Through
comprehensive evaluation of 20+ LLMs on our Marco-Bench-MIF, we found that: (1)
25-35% accuracy gap between high/low-resource languages, (2) model scales
largely impact performance by 45-60% yet persists script-specific challenges,
and (3) machine-translated data underestimates accuracy by7-22% versus
localized data. Our analysis identifies challenges in multilingual instruction
following, including keyword consistency preservation and compositional
constraint adherence across languages. Our Marco-Bench-MIF is available at
https://github.com/AIDC-AI/Marco-Bench-MIF.

</details>


### [105] [A Survey of Deep Learning for Geometry Problem Solving](https://arxiv.org/abs/2507.11936)
*Jianzhe Ma,Wenxuan Wang,Qin Jin*

Main category: cs.CL

TL;DR: 本论文对深度学习在几何问题解决领域的应用进行了全面的调研，总结了相关任务、方法、评估指标，并探讨了挑战与未来方向，旨在为该领域提供参考。


<details>
  <summary>Details</summary>
Motivation: 几何问题解决是数学推理的关键领域，广泛应用于教育、人工智能的数学能力评估以及多模态能力评估等重要领域。近年来，深度学习技术的快速发展，特别是多模态大语言模型的兴起，引发了广泛的研究热潮。

Method: 通过（i）全面总结几何问题解决的相关任务；（ii）深入回顾相关的深度学习方法；（iii）详细分析评估指标和方法；（iv）批判性地讨论当前的挑战和未来可探索的方向，对深度学习在几何问题解决中的应用进行了调研。

Result: 对深度学习在几何问题解决中的应用进行了全面的总结、回顾和分析，并讨论了当前的挑战和未来方向。

Conclusion: 本篇论文旨在为深度学习在几何问题解决中的应用提供一个全面且实用的参考，以促进该领域的进一步发展。

Abstract: Geometry problem solving is a key area of mathematical reasoning, which is
widely involved in many important fields such as education, mathematical
ability assessment of artificial intelligence, and multimodal ability
assessment. In recent years, the rapid development of deep learning technology,
especially the rise of multimodal large language models, has triggered a
widespread research boom. This paper provides a survey of the applications of
deep learning in geometry problem solving, including (i) a comprehensive
summary of the relevant tasks in geometry problem solving; (ii) a thorough
review of related deep learning methods; (iii) a detailed analysis of
evaluation metrics and methods; and (iv) a critical discussion of the current
challenges and future directions that can be explored. Our goal is to provide a
comprehensive and practical reference of deep learning for geometry problem
solving to promote further developments in this field. We create a continuously
updated list of papers on GitHub: https://github.com/majianz/dl4gps.

</details>


### [106] [POLYCHARTQA: Benchmarking Large Vision-Language Models with Multilingual Chart Question Answering](https://arxiv.org/abs/2507.11939)
*Yichen Xu,Liangyu Chen,Liang Zhang,Wenxuan Wang,Qin Jin*

Main category: cs.CL

TL;DR: PolyChartQA是首个大规模多语言图表问答基准，包含10种语言，旨在解决现有英语中心化基准的局限性。它通过解耦数据和代码来生成多语言图表，并揭示了英语与其他语言在图表理解方面存在显著的性能差距，为全球包容性视觉语言模型的研究奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 现有图表理解基准以英语为中心，限制了其对全球受众的可及性和适用性。因此，需要一个多语言的基准来促进对全球受众的普适性。

Method: PolyChartQA的构建采用了解耦管线，将图表数据与渲染代码分离，通过翻译数据和重用代码来灵活生成多语言图表。该方法利用了最先进的基于LLM的翻译，并实施了严格的质量控制，以确保生成的多语言图表的语言和语义一致性。

Result: PolyChartQA包含22,606张图表和26,151个问答对，涵盖10种不同的语言。在开源和闭源的大型视觉语言模型上的实验揭示了英语与其他语言（尤其是具有非拉丁字符的低资源语言）之间显著的性能差距。

Conclusion: PolyChartQA的发布为推动全球包容性的视觉语言模型奠定了基础，并促进了多语言图表理解的系统评估。

Abstract: Charts are a universally adopted medium for interpreting and communicating
data. However, existing chart understanding benchmarks are predominantly
English-centric, limiting their accessibility and applicability to global
audiences. In this paper, we present PolyChartQA, the first large-scale
multilingual chart question answering benchmark covering 22,606 charts and
26,151 question-answering pairs across 10 diverse languages. PolyChartQA is
built using a decoupled pipeline that separates chart data from rendering code,
allowing multilingual charts to be flexibly generated by simply translating the
data and reusing the code. We leverage state-of-the-art LLM-based translation
and enforce rigorous quality control in the pipeline to ensure the linguistic
and semantic consistency of the generated multilingual charts. PolyChartQA
facilitates systematic evaluation of multilingual chart understanding.
Experiments on both open- and closed-source large vision-language models reveal
a significant performance gap between English and other languages, especially
low-resource ones with non-Latin scripts. This benchmark lays a foundation for
advancing globally inclusive vision-language models.

</details>


### [107] [DAC: A Dynamic Attention-aware Approach for Task-Agnostic Prompt Compression](https://arxiv.org/abs/2507.11942)
*Yi Zhao,Zuchao Li,Hai Zhao,Baoyuan Qi,Guoming Liu*

Main category: cs.CL

TL;DR: DAC是一种新的提示压缩方法，它结合了熵和注意力信息，以提高效率和信息密度，并在各种基准测试中显示出优越的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于信息熵的提示压缩方法忽略了算法层面的注意力关键标记的重要性以及压缩过程中信息熵的变化，而DAC旨在解决这些问题。

Method: 提出了一种动态的、考虑注意力的任务无关提示压缩方法（DAC），该方法结合了熵和注意力信息，在压缩过程中动态感知熵变化，以实现细粒度提示压缩。

Result: DAC在各种任务和大型语言模型上实现了稳健且显著的改进。

Conclusion: DAC在LongBench、GSM8K和BBH等多个领域的广泛实验表明，该方法在各种任务和大型语言模型上始终能带来稳健且显著的改进，有效证明了其功效。

Abstract: Task-agnostic prompt compression leverages the redundancy in natural language
to reduce computational overhead and enhance information density within
prompts, especially in long-context scenarios. Existing methods predominantly
rely on information entropy as the metric to compress lexical units, aiming to
achieve minimal information loss. However, these approaches overlook two
critical aspects: (i) the importance of attention-critical tokens at the
algorithmic level, and (ii) shifts in information entropy during the
compression process. Motivated by these challenges, we propose a dynamic
attention-aware approach for task-agnostic prompt compression (DAC). This
approach effectively integrates entropy and attention information, dynamically
sensing entropy shifts during compression to achieve fine-grained prompt
compression. Extensive experiments across various domains, including LongBench,
GSM8K, and BBH, show that DAC consistently yields robust and substantial
improvements across a diverse range of tasks and LLMs, offering compelling
evidence of its efficacy.

</details>


### [108] [IAM: Efficient Inference through Attention Mapping between Different-scale LLMs](https://arxiv.org/abs/2507.11953)
*Yi Zhao,Zuchao Li,Hai Zhao*

Main category: cs.CL

TL;DR: IAM框架通过利用不同大小语言模型间的注意力相似性，实现对Transformer的优化，从而在加速计算和减少显存占用的同时，保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型（LLMs）在处理长上下文时资源消耗过大的问题，并利用模型间的相似性进行优化，而非仅仅依赖模型内部的稀疏性。

Method: IAM框架通过分析不同尺度语言模型之间注意力矩阵的相似性，选择映射层并进行注意力映射，以加速注意力计算并减少KV缓存使用。

Result: IAM框架能够加速预填充（prefill）15%，并减少22.1%的KV缓存使用量，同时对模型性能影响不明显。该框架在不同系列模型上都表现出良好的泛化能力，并且可以与其他KV缓存优化方法兼容。

Conclusion: IAM框架通过在小模型和大模型之间进行注意力映射，实现了加速注意力计算和减少KV缓存使用的双重效益，并且在不明显牺牲性能的情况下，能够加速预填充并减少KV缓存使用量。实验结果表明IAM具有良好的泛化性，并且可以与其他KV缓存优化方法协同工作。

Abstract: LLMs encounter significant challenges in resource consumption nowadays,
especially with long contexts. Despite extensive efforts dedicate to enhancing
inference efficiency, these methods primarily exploit internal sparsity within
the models, without leveraging external information for optimization. We
identify the high similarity of attention matrices across different-scale LLMs,
which offers a novel perspective for optimization. We first conduct a
comprehensive analysis of how to measure similarity, how to select mapping
Layers and whether mapping is consistency. Based on these insights, we
introduce the IAM framework, which achieves dual benefits of accelerated
attention computation and reduced KV cache usage by performing attention
mapping between small and large LLMs. Our experimental results demonstrate that
IAM can accelerate prefill by 15% and reduce KV cache usage by 22.1% without
appreciably sacrificing performance. Experiments on different series of models
show the generalizability of IAM. Importantly, it is also orthogonal to many
existing KV cache optimization methods, making it a versatile addition to the
current toolkit for enhancing LLM efficiency.

</details>


### [109] [The benefits of query-based KGQA systems for complex and temporal questions in LLM era](https://arxiv.org/abs/2507.11954)
*Artem Alekseev,Mikhail Chaichuk,Miron Butko,Alexander Panchenko,Elena Tutubalina,Oleg Somov*

Main category: cs.CL

TL;DR: A new multi-stage query-based framework for knowledge graph QA improves performance on complex reasoning and temporal questions, especially with smaller language models.


<details>
  <summary>Details</summary>
Motivation: Large language models struggle with multi-hop reasoning and temporal questions in QA. Query-based KGQA offers a modular alternative by generating executable queries instead of direct answers.

Method: We propose a multi-stage query-based framework for Wikidata QA, incorporating a novel entity linking and predicate matching method using CoT reasoning. We evaluate its robustness across multi-hop and temporal QA datasets through generalization and rejection studies.

Result: Our proposed framework enhances performance on challenging multi-hop and temporal benchmarks, demonstrating the potential of query-based multi-stage KGQA for improving QA capabilities.

Conclusion: We demonstrate that a query-based multi-stage KGQA framework can improve multi-hop and temporal QA performance, even with small language models.

Abstract: Large language models excel in question-answering (QA) yet still struggle
with multi-hop reasoning and temporal questions. Query-based knowledge graph QA
(KGQA) offers a modular alternative by generating executable queries instead of
direct answers. We explore multi-stage query-based framework for WikiData QA,
proposing multi-stage approach that enhances performance on challenging
multi-hop and temporal benchmarks. Through generalization and rejection
studies, we evaluate robustness across multi-hop and temporal QA datasets.
Additionally, we introduce a novel entity linking and predicate matching method
using CoT reasoning. Our results demonstrate the potential of query-based
multi-stage KGQA framework for improving multi-hop and temporal QA with small
language models. Code and data: https://github.com/ar2max/NLDB-KGQA-System

</details>


### [110] [PoTPTQ: A Two-step Power-of-Two Post-training for LLMs](https://arxiv.org/abs/2507.11959)
*Xinyu Wang,Vahid Partovi Nia,Peng Lu,Jerry Huang,Xiao-Wen Chang,Boxing Chen,Yufei Cui*

Main category: cs.CL

TL;DR: LLM难以部署，因为需要大量计算资源。POT量化可以解决这个问题，但现有方法在GPU上效果不佳。本研究提出了一种新的POT量化框架，提高了精度并加快了推理速度，在低精度下效果尤为显著。


<details>
  <summary>Details</summary>
Motivation: 现有的POT量化方法在CPU上高效，但在GPU上效果不佳，原因是符号位纠缠和反量化所需的顺序位操作。

Method: 提出了一种两步的训练后算法：首先，使用鲁棒的起点初始化量化尺度；其次，使用最小的校准集来优化这些尺度。

Result: 在2位和3位格式等低精度下，POT量化算法的性能优于现有的整数量化方法。在NVIDIA V100上推理速度提高了3.67倍，在NVIDIA RTX 4090上提高了1.63倍。

Conclusion: 该研究提出了一种新颖的POT量化框架，用于LLM权重，在极低精度格式下实现了最先进的准确性，并通过更有效的反量化实现了更快的推理。

Abstract: Large Language Models (LLMs) have demonstrated remarkable performance across
various natural language processing (NLP) tasks. However, their deployment is
challenging due to the substantial computational resources required.
Power-of-two (PoT) quantization is a general tool to counteract this
difficulty. Albeit previous works on PoT quantization can be efficiently
dequantized on CPUs using fixed-point addition, it showed less effectiveness on
GPUs. The reason is entanglement of the sign bit and sequential bit
manipulations needed for dequantization. We propose a novel POT quantization
framework for LLM weights that (i) outperforms state-of-the-art accuracy in
extremely low-precision number formats, and (ii) enables faster inference
through more efficient dequantization. To maintain the accuracy of the
quantized model, we introduce a two-step post-training algorithm: (i)
initialize the quantization scales with a robust starting point, and (ii)
refine these scales using a minimal calibration set. The performance of our PoT
post-training algorithm surpasses the current state-of-the-art in integer
quantization, particularly at low precisions such as 2- and 3-bit formats. Our
PoT quantization accelerates the dequantization step required for the floating
point inference and leads to $3.67\times$ speed up on a NVIDIA V100, and
$1.63\times$ on a NVIDIA RTX 4090, compared to uniform integer dequantization.

</details>


### [111] [Toxicity-Aware Few-Shot Prompting for Low-Resource Singlish Translation](https://arxiv.org/abs/2507.11966)
*Ziyu Ge,Gabriel Chua,Leanne Tan,Roy Ka-Wei Lee*

Main category: cs.CL

TL;DR: 为了解决低资源语言翻译中的毒性内容挑战，我们提出了一个两阶段框架，结合了少样本提示工程和基于语义相似性的模型优化，以在新加坡式英语翻译中保留毒性和细微差别。


<details>
  <summary>Details</summary>
Motivation: 随着在线交流越来越多地包含代表性不足的语言和本地方言，标准的翻译系统往往无法保留本地俚语、混合语和包含有害言论的文化标记。由于缺乏平行数据和用于净化冒犯性表达的安全过滤器，在低资源语言对之间翻译有毒内容带来了额外的挑战。

Method: 我们提出了一个可复现的、两阶段的毒性保留翻译框架。首先，我们进行人工验证的少样本提示工程，迭代地整理和排序标注者选择的新加坡式英语-目标语言示例，以捕捉细微的俚语、语气和毒性。其次，我们通过使用直接翻译和回译的语义相似性来对几个大语言模型进行基准测试，以优化模型-提示对。

Result: 定量的人工评估证实了我们流程的有效性和效率。

Conclusion: 该框架通过支持文化敏感的审核和低资源背景下的基准测试，为多文化大语言模型的安全做出了贡献。通过将新加坡式英语定位为包容性自然语言处理的试验场，我们强调了在内容审核和区域平台治理等实际应用中保留社会语言细微差别的重要性。

Abstract: As online communication increasingly incorporates under-represented languages
and colloquial dialects, standard translation systems often fail to preserve
local slang, code-mixing, and culturally embedded markers of harmful speech.
Translating toxic content between low-resource language pairs poses additional
challenges due to scarce parallel data and safety filters that sanitize
offensive expressions. In this work, we propose a reproducible, two-stage
framework for toxicity-preserving translation, demonstrated on a code-mixed
Singlish safety corpus. First, we perform human-verified few-shot prompt
engineering: we iteratively curate and rank annotator-selected Singlish-target
examples to capture nuanced slang, tone, and toxicity. Second, we optimize
model-prompt pairs by benchmarking several large language models using semantic
similarity via direct and back-translation. Quantitative human evaluation
confirms the effectiveness and efficiency of our pipeline. Beyond improving
translation quality, our framework contributes to the safety of multicultural
LLMs by supporting culturally sensitive moderation and benchmarking in
low-resource contexts. By positioning Singlish as a testbed for inclusive NLP,
we underscore the importance of preserving sociolinguistic nuance in real-world
applications such as content moderation and regional platform governance.

</details>


### [112] [Graph Representations for Reading Comprehension Analysis using Large Language Model and Eye-Tracking Biomarker](https://arxiv.org/abs/2507.11972)
*Yuhong Zhang,Jialu Li,Shilai Yang,Yuchen Xu,Gert Cauwenberghs,Tzyy-Ping Jung*

Main category: cs.CL

TL;DR: 本研究通过构建图表文本表示，发现LLM在语言理解的拓扑结构层面高度一致，为理解人机协同学习提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）的进步，需要比较人类和LLM在不同情境下理解语言的差异，并将其应用于推理、情感解释和信息检索等功能性任务。先前的研究使用LLM和人类生物标记研究阅读理解过程，发现与推理目标相关性高低词语的生物标记表现出不同的模式，但仅关注单个单词限制了理解的深度。

Method: 本研究使用基于LLM的AI代理将阅读材料中的单词分组为节点和边，形成基于语义和问题导向提示的图表文本表示。然后比较了重要节点和边上的眼动分布。

Result: 研究结果表明，LLM在语言理解方面，尤其是在图的拓扑结构层面，表现出高度的一致性。这些结果建立在先前的发现之上，并为有效的人机协同学习策略提供了见解。

Conclusion: LLM在语言理解方面，尤其是在图的拓扑结构层面，表现出高度的一致性。

Abstract: Reading comprehension is a fundamental skill in human cognitive development.
With the advancement of Large Language Models (LLMs), there is a growing need
to compare how humans and LLMs understand language across different contexts
and apply this understanding to functional tasks such as inference, emotion
interpretation, and information retrieval. Our previous work used LLMs and
human biomarkers to study the reading comprehension process. The results showed
that the biomarkers corresponding to words with high and low relevance to the
inference target, as labeled by the LLMs, exhibited distinct patterns,
particularly when validated using eye-tracking data. However, focusing solely
on individual words limited the depth of understanding, which made the
conclusions somewhat simplistic despite their potential significance. This
study used an LLM-based AI agent to group words from a reading passage into
nodes and edges, forming a graph-based text representation based on semantic
meaning and question-oriented prompts. We then compare the distribution of eye
fixations on important nodes and edges. Our findings indicate that LLMs exhibit
high consistency in language understanding at the level of graph topological
structure. These results build on our previous findings and offer insights into
effective human-AI co-learning strategies.

</details>


### [113] [Simplifications are Absolutists: How Simplified Language Reduces Word Sense Awareness in LLM-Generated Definitions](https://arxiv.org/abs/2507.11981)
*Lukas Ellinger,Miriam Anschütz,Georg Groh*

Main category: cs.CL

TL;DR: LLM 对多义词的简化定义会丢失信息并产生误导。研究表明，简化会降低定义的完整性，而通过直接偏好优化对 Llama 3.1 8B 进行微调可提高其同义词响应质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）可以提供准确的单词定义和解释，但对于儿童或语言学习者等不同目标群体，定义的范围也会发生变化。这对于同义词尤其重要，因为过度简化可能会通过省略关键词义来丢失信息，从而可能误导用户。

Method: 使用两个涵盖多种语言的新型评估数据集，通过 LLM-as-Judge 和人工标注测试了 DeepSeek v3、Llama 4 Maverick、Qwen3-30B A3B、GPT-4o mini 和 Llama 3.1 8B。

Result: 简化会严重降低定义的完整性，忽略词语的多义性，增加误解的风险。通过直接偏好优化对 Llama 3.1 8B 进行微调，可以显著提高所有提示类型的同义词响应质量。

Conclusion: 简化会严重影响同义词定义的完整性，忽略多义性，增加误解的风险。通过直接偏好优化微调 Llama 3.1 8B 可显著提高所有类型提示下的同义词响应质量。这表明在教育型自然语言处理中需要平衡简洁性和完整性，以确保为所有学习者提供可靠、上下文感知的定义。

Abstract: Large Language Models (LLMs) can provide accurate word definitions and
explanations for any context. However, the scope of the definition changes for
different target groups, like children or language learners. This is especially
relevant for homonyms, words with multiple meanings, where oversimplification
might risk information loss by omitting key senses, potentially misleading
users who trust LLM outputs. We investigate how simplification impacts homonym
definition quality across three target groups: Normal, Simple, and ELI5. Using
two novel evaluation datasets spanning multiple languages, we test DeepSeek v3,
Llama 4 Maverick, Qwen3-30B A3B, GPT-4o mini, and Llama 3.1 8B via LLM-as-Judge
and human annotations. Our results show that simplification drastically
degrades definition completeness by neglecting polysemy, increasing the risk of
misunderstanding. Fine-tuning Llama 3.1 8B with Direct Preference Optimization
substantially improves homonym response quality across all prompt types. These
findings highlight the need to balance simplicity and completeness in
educational NLP to ensure reliable, context-aware definitions for all learners.

</details>


### [114] [Improving Data and Parameter Efficiency of Neural Language Models Using Representation Analysis](https://arxiv.org/abs/2507.12004)
*Josip Jukić*

Main category: cs.CL

TL;DR: 本论文提出结合表示平滑度、主动学习、参数高效微调和上下文学习弱监督技术，以提高神经语言模型的数据和参数效率、鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 本论文旨在解决神经语言模型在数据和参数效率方面面临的挑战，通过表示分析和优化技术来提高模型的鲁棒性和泛化能力，减少对大量标记数据的依赖。

Method: 本论文提出的方法包括：1. 基于表示平滑度的正则化策略，利用雅可比矩阵和海森矩阵稳定训练过程，减少对输入扰动的敏感性。2. 结合主动学习和参数高效微调，利用表示平滑度指导早期停止，无需标记验证集，从而降低标记工作量和计算资源。3. 利用上下文学习增强弱监督技术，更有效地利用未标记数据进行训练，提高模型在低资源和动态数据环境下的准确性、适应性和鲁棒性。

Result: 实验评估表明，本论文提出的方法在性能、稳定性和效率方面均显著优于传统方法，尤其在低资源设置和动态数据环境中，模型准确性、适应性和鲁棒性得到显著提升。

Conclusion: 本论文提出的基于表示平滑度的方法，结合主动学习和参数高效微调技术，以及利用上下文学习进行弱监督，能够显著提高数据和参数效率，同时增强模型的鲁棒性和泛化能力，尤其在低资源和动态数据环境中表现优异。

Abstract: This thesis addresses challenges related to data and parameter efficiency in
neural language models, with a focus on representation analysis and the
introduction of new optimization techniques. The first part examines the
properties and dynamics of language representations within neural models,
emphasizing their significance in enhancing robustness and generalization. It
proposes innovative approaches based on representation smoothness, including
regularization strategies that utilize Jacobian and Hessian matrices to
stabilize training and mitigate sensitivity to input perturbations. The second
part focuses on methods to significantly enhance data and parameter efficiency
by integrating active learning strategies with parameter-efficient fine-tuning,
guided by insights from representation smoothness analysis. It presents
smoothness-informed early-stopping techniques designed to eliminate the need
for labeled validation sets and proposes innovative combinations of active
learning and parameter-efficient fine-tuning to reduce labeling efforts and
computational resources. Extensive experimental evaluations across various NLP
tasks demonstrate that these combined approaches substantially outperform
traditional methods in terms of performance, stability, and efficiency. The
third part explores weak supervision techniques enhanced by in-context learning
to effectively utilize unlabeled data, further reducing dependence on extensive
labeling. It shows that using in-context learning as a mechanism for weak
supervision enables models to better generalize from limited labeled data by
leveraging unlabeled examples more effectively during training. Comprehensive
empirical evaluations confirm significant gains in model accuracy,
adaptability, and robustness, especially in low-resource settings and dynamic
data environments.

</details>


### [115] [A Comparative Approach to Assessing Linguistic Creativity of Large Language Models and Humans](https://arxiv.org/abs/2507.12039)
*Anca Dinu,Andra-Maria Florescu,Alina Resceanu*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在语言创造力测试中超越了人类，但人类更倾向于扩展性创造力，而LLMs更倾向于固定性创造力。


<details>
  <summary>Details</summary>
Motivation: 开发一种用于评估人类和大型语言模型（LLMs）语言创造力的方法。

Method: 提出并实施了一项包含词语构成（派生和复合）及隐喻语言使用的任务的语言创造力测试，对24名人类和等量LLM进行测试，并使用OCSAI工具从原创性、阐述性和灵活性三个维度进行评估。

Result: LLMs在所有评估标准上均优于人类，并在八项测试任务中的六项表现更好。LLMs和人类在个体答案的独特性上存在细微差异。

Conclusion: LLMs在语言创造力测试中表现优于人类，尤其在原创性、阐述性和灵活性方面。人类倾向于扩展性创造力（E-creativity），而LLMs倾向于固定性创造力（F-creativity）。

Abstract: The following paper introduces a general linguistic creativity test for
humans and Large Language Models (LLMs). The test consists of various tasks
aimed at assessing their ability to generate new original words and phrases
based on word formation processes (derivation and compounding) and on
metaphorical language use. We administered the test to 24 humans and to an
equal number of LLMs, and we automatically evaluated their answers using OCSAI
tool for three criteria: Originality, Elaboration, and Flexibility. The results
show that LLMs not only outperformed humans in all the assessed criteria, but
did better in six out of the eight test tasks. We then computed the uniqueness
of the individual answers, which showed some minor differences between humans
and LLMs. Finally, we performed a short manual analysis of the dataset, which
revealed that humans are more inclined towards E(extending)-creativity, while
LLMs favor F(ixed)-creativity.

</details>


### [116] [Evaluating the Ability of Large Language Models to Reason about Cardinal Directions, Revisited](https://arxiv.org/abs/2507.12059)
*Anthony G Cohn,Robert E Blackwell*

Main category: cs.CL

TL;DR: LLM在推断基数方向方面能力不足。


<details>
  <summary>Details</summary>
Motivation: 为了研究LLM在推断基数方向方面的能力。

Method: 使用由模板集生成的基准来测试28个LLM推断基数方向的能力，该基准允许在移动工具、第一人称、第二人称或第三人称等方面进行变化。

Result: 即使是较新的LLM也无法可靠地确定所有问题的正确基数方向。

Conclusion: LLM在推断基数方向方面能力不足，即使是较新的LLM也无法可靠地确定所有问题的正确基数方向。

Abstract: We investigate the abilities of 28 Large language Models (LLMs) to reason
about cardinal directions (CDs) using a benchmark generated from a set of
templates, extensively testing an LLM's ability to determine the correct CD
given a particular scenario. The templates allow for a number of degrees of
variation such as means of locomotion of the agent involved, and whether set in
the first, second or third person. Even the newer Large Reasoning Models are
unable to reliably determine the correct CD for all questions. This paper
summarises and extends earlier work presented at COSIT-24.

</details>


### [117] [StylOch at PAN: Gradient-Boosted Trees with Frequency-Based Stylometric Features](https://arxiv.org/abs/2507.12064)
*Jeremi K. Ochab,Mateusz Matias,Tymoteusz Boba,Tomasz Walkowiak*

Main category: cs.CL

TL;DR: This paper presents a non-neural AI detection method using spaCy for feature extraction and light-gradient boosting for classification, trained on a large dataset of AI-generated texts.


<details>
  <summary>Details</summary>
Motivation: To detect binary AI in text using a robust and explainable method.

Method: A modular stylometric pipeline using public spaCy models for text preprocessing and feature extraction, with light-gradient boosting machines as the classifier.

Result: The pipeline extracts thousands of features from linguistic annotations and is trained on a large corpus of over 500,000 machine-generated texts. Parameter options were explored to enhance classifier capacity.

Conclusion: The approach follows a non-neural, computationally inexpensive, and explainable method, proving effective.

Abstract: This submission to the binary AI detection task is based on a modular
stylometric pipeline, where: public spaCy models are used for text
preprocessing (including tokenisation, named entity recognition, dependency
parsing, part-of-speech tagging, and morphology annotation) and extracting
several thousand features (frequencies of n-grams of the above linguistic
annotations); light-gradient boosting machines are used as the classifier. We
collect a large corpus of more than 500 000 machine-generated texts for the
classifier's training. We explore several parameter options to increase the
classifier's capacity and take advantage of that training set. Our approach
follows the non-neural, computationally inexpensive but explainable approach
found effective previously.

</details>


### [118] [BOOKCOREF: Coreference Resolution at Book Scale](https://arxiv.org/abs/2507.12075)
*Giuliano Martinelli,Tommaso Bonomo,Pere-Lluís Huguet Cabot,Roberto Navigli*

Main category: cs.CL

TL;DR: 本研究提出了 BOOKCOREF，一个包含全篇叙事文本（平均长度超过 200,000 词元）的开创性基准，用于评估指代消解系统。研究发现，现有模型在处理书本规模的文本时性能会下降，并为未来的研究提供了新的挑战和机会。


<details>
  <summary>Details</summary>
Motivation: 现有基准（如 LitBank）在评估长文本（尤其是书本规模）方面的能力有限，无法充分评估指代消解系统在处理包含数十万个词元的超长文本时的能力。

Method: 提出了一种新的自动流水线，用于在全篇叙事文本中生成高质量的指代消解注释，并利用该流水线创建了第一个书本规模的指代消解基准 BOOKCOREF，平均文档长度超过 200,000 个词元。

Result: BOOKCOREF 是第一个书本规模的指代消解基准，平均文档长度超过 200,000 个词元。实验表明，在 BOOKCOREF 上评估时，当前的指代消解系统可以提高高达 +20 CoNLL-F1 分数。该基准揭示了书本规模的指代消解所带来的新挑战，并表明现有模型在这一规模下性能会下降。

Conclusion: 现有针对长文档的指代消解系统在全书规模的评估中表现不佳，表明需要新的模型和评估方法。

Abstract: Coreference Resolution systems are typically evaluated on benchmarks
containing small- to medium-scale documents. When it comes to evaluating long
texts, however, existing benchmarks, such as LitBank, remain limited in length
and do not adequately assess system capabilities at the book scale, i.e., when
co-referring mentions span hundreds of thousands of tokens. To fill this gap,
we first put forward a novel automatic pipeline that produces high-quality
Coreference Resolution annotations on full narrative texts. Then, we adopt this
pipeline to create the first book-scale coreference benchmark, BOOKCOREF, with
an average document length of more than 200,000 tokens. We carry out a series
of experiments showing the robustness of our automatic procedure and
demonstrating the value of our resource, which enables current long-document
coreference systems to gain up to +20 CoNLL-F1 points when evaluated on full
books. Moreover, we report on the new challenges introduced by this
unprecedented book-scale setting, highlighting that current models fail to
deliver the same performance they achieve on smaller documents. We release our
data and code to encourage research and development of new book-scale
Coreference Resolution systems at https://github.com/sapienzanlp/bookcoref.

</details>


### [119] [Findings of MEGA: Maths Explanation with LLMs using the Socratic Method for Active Learning](https://arxiv.org/abs/2507.12079)
*Tosin Adewumi,Foteini Simistira Liwicki,Marcus Liwicki,Viktor Gardelli,Lama Alkhaled,Hamam Mokayed*

Main category: cs.CL

TL;DR: 本研究提出了一种名为MEGA的新型数学教学方法，结合了多种教学策略，并通过实验证明其在提升学生数学学习体验和解释困难数学问题方面优于传统的逐步教学法。


<details>
  <summary>Details</summary>
Motivation: 部分学生在数学学习上存在困难，导致他们回避数学相关学科，尽管数学在包括信号处理在内的许多领域都至关重要。学生数学困难的根源往往在于次优的教学法。

Method: 本研究提出了一种结合了苏格拉底方法、思维链（CoT）推理、简化游戏化和形成性反馈的干预研究，称为MEGA（Mathematics Explanations through Games by AI LLMs）。研究通过组内设计，在GSM8K和MATH两个数据集上，比较了MEGA方法与传统的逐步（CoT）方法在大学生的数学学习效果。

Result: 研究结果表明，在两个数据集上，学生们普遍认为MEGA方法在学习体验上优于CoT方法。在更困难的MATH数据集上，MEGA方法的学生认同度（47.5%）远高于CoT方法（26.67%），表明MEGA方法在解释困难数学问题方面效果更佳。

Conclusion: MEGA方法在解释困难数学问题方面优于传统的逐步（CoT）方法，在更难的MATH数据集上，MEGA方法的学生认同度为47.5%，而CoT方法为26.67%。

Abstract: This paper presents an intervention study on the effects of the combined
methods of (1) the Socratic method, (2) Chain of Thought (CoT) reasoning, (3)
simplified gamification and (4) formative feedback on university students'
Maths learning driven by large language models (LLMs). We call our approach
Mathematics Explanations through Games by AI LLMs (MEGA). Some students
struggle with Maths and as a result avoid Math-related discipline or subjects
despite the importance of Maths across many fields, including signal
processing. Oftentimes, students' Maths difficulties stem from suboptimal
pedagogy. We compared the MEGA method to the traditional step-by-step (CoT)
method to ascertain which is better by using a within-group design after
randomly assigning questions for the participants, who are university students.
Samples (n=60) were randomly drawn from each of the two test sets of the Grade
School Math 8K (GSM8K) and Mathematics Aptitude Test of Heuristics (MATH)
datasets, based on the error margin of 11%, the confidence level of 90%, and a
manageable number of samples for the student evaluators. These samples were
used to evaluate two capable LLMs at length (Generative Pretrained Transformer
4o (GPT4o) and Claude 3.5 Sonnet) out of the initial six that were tested for
capability. The results showed that students agree in more instances that the
MEGA method is experienced as better for learning for both datasets. It is even
much better than the CoT (47.5% compared to 26.67%) in the more difficult MATH
dataset, indicating that MEGA is better at explaining difficult Maths problems.

</details>


### [120] [Iterative Augmentation with Summarization Refinement (IASR) Evaluation for Unstructured Survey data Modeling and Analysis](https://arxiv.org/abs/2507.12126)
*Payal Bhattad,Sai Manoj Pudukotai Dinakarrao,Anju Gupta*

Main category: cs.CL

TL;DR: 提出了一种新的LLM文本增强评估框架，证明了其在提高NLP任务性能方面的有效性，并指出了GPT-3.5 Turbo的优势。


<details>
  <summary>Details</summary>
Motivation: 现有文本数据增强技术在语义保持方面存在不足，尤其是在低资源和迭代生成场景下，可能导致冗余和不稳定性。

Method: 提出了一种包含“可扩展性分析”和“带摘要精炼的迭代增强（IASR）”的评估框架，用于评估LLM文本增强的语义保持能力和稳定性。

Result: 在主题建模任务中，使用GPT增强的少样本标注，实现了400%的主题粒度增长，并消除了主题重叠。GPT-3.5 Turbo在语义保真度、多样性和生成效率方面表现最佳。

Conclusion: 该框架为评估基于LLM的文本增强提供了结构化方法，并在实际的NLP应用中展示了其有效性。

Abstract: Text data augmentation is a widely used strategy for mitigating data sparsity
in natural language processing (NLP), particularly in low-resource settings
where limited samples hinder effective semantic modeling. While augmentation
can improve input diversity and downstream interpretability, existing
techniques often lack mechanisms to ensure semantic preservation during
large-scale or iterative generation, leading to redundancy and instability.
This work introduces a principled evaluation framework for large language model
(LLM) based text augmentation, comprising two components: (1) Scalability
Analysis, which measures semantic consistency as augmentation volume increases,
and (2) Iterative Augmentation with Summarization Refinement (IASR), which
evaluates semantic drift across recursive paraphrasing cycles. Empirical
evaluations across state-of-the-art LLMs show that GPT-3.5 Turbo achieved the
best balance of semantic fidelity, diversity, and generation efficiency.
Applied to a real-world topic modeling task using BERTopic with GPT-enhanced
few-shot labeling, the proposed approach results in a 400% increase in topic
granularity and complete elimination of topic overlaps. These findings
validated the utility of the proposed frameworks for structured evaluation of
LLM-based augmentation in practical NLP pipelines.

</details>


### [121] [Overview of the Sensemaking Task at the ELOQUENT 2025 Lab: LLMs as Teachers, Students and Evaluators](https://arxiv.org/abs/2507.12143)
*Pavel Šindelář,Ondřej Bojar*

Main category: cs.CL

TL;DR: ELOQUENT的Sensemaking任务评估语言模型理解文本和问答能力。2025年研究发现，模型在生成问题、严格依据文本回答以及LLM作为裁判评分方面仍有待提高。


<details>
  <summary>Details</summary>
Motivation: ELOQUENT旨在创建易于测试的高层标准来评估生成语言模型，Sensemaking是其中的一项任务，旨在评估生成模型“理解给定文本”的能力，并模仿课堂考试的三个步骤：出题、答题和评分。

Method: 本研究介绍了ELOQUENT的Sensemaking共享任务，该任务旨在评估生成语言模型理解文本并据此进行问答的能力。任务分为三个步骤：由教师系统生成问题，由学生系统回答问题，由评估系统评分，所有环节均严格依据提供的输入材料。研究报告了2025年的Sensemaking任务，使用了7种不同类型的测试材料（包括事实核查分析、教科书、讲座录音和教育视频），涵盖英、德、乌、捷四种语言。共有4个团队参与，提交了2个教师系统、2个学生系统和2个评估系统。研究还为教师和学生系统增加了基于商用大型语言模型的基线，并设计了一种全自动评估程序，同时与极简人工评估进行了比较。

Result: 在2025年的Sensemaking任务中，研究发现教师系统在生成问题方面，评估策略仍需改进，难以区分问题集质量。学生系统在回答问题方面整体表现尚可，但在严格限制于给定文本方面存在问题。评估系统在LLM作为裁判的范式下，会出现将混乱的问答对和答非所问的答案误判为可接受的情况。

Conclusion: 该研究发现，在ELOQUENT的Sensemaking任务中，教师系统（生成问题）的评估策略仍需改进，因为很难区分不同问题集的质量。学生系统（回答问题）在LLM的加持下表现尚可，但在严格依据给定文本回答方面仍存在困难。评估系统（评分）在LLM作为裁判的范式下存在缺陷，会将混乱的问答对和答非所问的答案误判为可接受。

Abstract: ELOQUENT is a set of shared tasks that aims to create easily testable
high-level criteria for evaluating generative language models. Sensemaking is
one such shared task.
  In Sensemaking, we try to assess how well generative models ``make sense out
of a given text'' in three steps inspired by exams in a classroom setting: (1)
Teacher systems should prepare a set of questions, (2) Student systems should
answer these questions, and (3) Evaluator systems should score these answers,
all adhering rather strictly to a given set of input materials.
  We report on the 2025 edition of Sensemaking, where we had 7 sources of test
materials (fact-checking analyses of statements, textbooks, transcribed
recordings of a lecture, and educational videos) spanning English, German,
Ukrainian, and Czech languages.
  This year, 4 teams participated, providing us with 2 Teacher submissions, 2
Student submissions, and 2 Evaluator submissions. We added baselines for
Teacher and Student using commercial large language model systems. We devised a
fully automatic evaluation procedure, which we compare to a minimalistic manual
evaluation.
  We were able to make some interesting observations. For the first task, the
creation of questions, better evaluation strategies will still have to be
devised because it is difficult to discern the quality of the various candidate
question sets. In the second task, question answering, the LLMs examined
overall perform acceptably, but restricting their answers to the given input
texts remains problematic. In the third task, evaluation of question answers,
our adversarial tests reveal that systems using the LLM-as-a-Judge paradigm
erroneously rate both garbled question-answer pairs and answers to mixed-up
questions as acceptable.

</details>


### [122] [Toward a Behavioural Translation Style Space: Simulating the Temporal Dynamics of Affect, Behaviour, and Cognition in Human Translation Production](https://arxiv.org/abs/2507.12208)
*Michael Carl,Takanori Mizowaki,Aishvarya Ray,Masaru Yamada,Devi Sri Bandaru,Xinyue Ren*

Main category: cs.CL

TL;DR: 该研究提出了行为翻译风格空间（BTSS），这是一个分层结构，通过分析眼动和键盘记录数据来模拟翻译过程中的认知、情感和行为。


<details>
  <summary>Details</summary>
Motivation: 提出可观察的翻译行为（眼动和指尖移动）是执行翻译的物理行为的基础，但它是由更高层次的认知过程和情感翻译状态引起和塑造的。

Method: 通过分析键盘记录和眼动数据作为隐藏心理处理结构的指标，将行为模式组织成多层嵌入式BTSS。

Result: 该BTSS为计算翻译代理提供了基础，该代理可以模拟人类翻译生产过程中情感、自动化行为和认知的 temporal dynamics。

Conclusion: 该研究提出了一个行为翻译风格空间（BTSS），该空间是一个分层结构，包含各种嵌入式处理层，用于描述可能的行为翻译模式。

Abstract: The paper introduces a Behavioural Translation Style Space (BTSS) that
describes possible behavioural translation patterns. The suggested BTSS is
organized as a hierarchical structure that entails various embedded processing
layers. We posit that observable translation behaviour - i.e., eye and finger
movements - is fundamental when executing the physical act of translation but
it is caused and shaped by higher-order cognitive processes and affective
translation states. We analyse records of keystrokes and gaze data as
indicators of the hidden mental processing structure and organize the
behavioural patterns as a multi-layered embedded BTSS. The BTSS serves as the
basis for a computational translation agent to simulate the temporal dynamics
of affect, automatized behaviour and cognition during human translation
production.

</details>


### [123] [Towards few-shot isolated word reading assessment](https://arxiv.org/abs/2507.12217)
*Reuben Smit,Retief Louw,Herman Kamper*

Main category: cs.CL

TL;DR: An ASR-free, few-shot method using SSL for child speech reading assessment showed promise but highlighted limitations of SSL for child data in such systems.


<details>
  <summary>Details</summary>
Motivation: To explore an ASR-free method for isolated word reading assessment in low-resource settings.

Method: A few-shot, ASR-free method comparing child speech input to adult-provided reference templates using intermediate layers from large self-supervised learned (SSL) models. Design options such as discretising SSL features and barycentre averaging of templates were investigated.

Result: Idealised experiments showed reasonable performance for adults but a substantial drop for child speech input, even with child templates.

Conclusion: SSL representations have limitations for processing child data in few-shot classification systems, despite their success in low-resource speech tasks.

Abstract: We explore an ASR-free method for isolated word reading assessment in
low-resource settings. Our few-shot approach compares input child speech to a
small set of adult-provided reference templates. Inputs and templates are
encoded using intermediate layers from large self-supervised learned (SSL)
models. Using an Afrikaans child speech benchmark, we investigate design
options such as discretising SSL features and barycentre averaging of the
templates. Idealised experiments show reasonable performance for adults, but a
substantial drop for child speech input, even with child templates. Despite the
success of employing SSL representations in low-resource speech tasks, our work
highlights the limitations of SSL representations for processing child data
when used in a few-shot classification system.

</details>


### [124] [Improving Contextual ASR via Multi-grained Fusion with Large Language Models](https://arxiv.org/abs/2507.12252)
*Shilin Zhou,Zhenghua Li*

Main category: cs.CL

TL;DR: 提出了一种新的多粒度融合方法，结合了token级和短语级融合，以提高ASR对关键词的识别能力，并在中文和英文数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 虽然端到端自动语音识别（ASR）模型在转录一般语音方面表现出色，但在准确识别专有名词或用户特定实体等上下文相关关键词方面却常常遇到困难。以往的方法通过在文本模式中利用关键词词典来提高关键词识别，但这些方法在不同的粒度上操作并各有局限性。

Method: 提出了一种新颖的多粒度融合方法，结合了语言模型（LLMs）的token级和短语级融合的优点，并通过晚期融合策略结合了ASR的声学信息和LLM的丰富上下文知识。

Result: 实验表明，所提出的方法在关键词相关指标上取得了最先进的性能，同时保持了对非关键词文本的高准确率。消融研究也证实了token级和短语级组件在此联合多粒度框架中对性能提升做出了显著贡献，并能相互补充。

Conclusion: 该方法在中文和英文数据集上都取得了最先进的性能，同时保持了对非关键词文本的高准确率。

Abstract: While end-to-end Automatic Speech Recognition (ASR) models have shown
impressive performance in transcribing general speech, they often struggle to
accurately recognize contextually relevant keywords, such as proper nouns or
user-specific entities.
  Previous approaches have explored leveraging keyword dictionaries in the
textual modality to improve keyword recognition, either through token-level
fusion that guides token-by-token generation or phrase-level fusion that
enables direct copying of keyword phrases.
  However, these methods operate at different granularities and have their own
limitations.
  In this paper, we propose a novel multi-grained fusion approach that jointly
leverages the strengths of both token-level and phrase-level fusion with Large
Language Models (LLMs).
  Our approach incorporates a late-fusion strategy that elegantly combines
ASR's acoustic information with LLM's rich contextual knowledge, balancing
fine-grained token precision with holistic phrase-level understanding.
  Experiments on Chinese and English datasets demonstrate that our approach
achieves state-of-the-art performance on keyword-related metrics while
preserving high accuracy on non-keyword text.
  Ablation studies further confirm that the token-level and phrase-level
components both contribute significantly to the performance gains,
complementing each other in our joint multi-grained framework.
  The code and models will be publicly available at https://github.com/.

</details>


### [125] [Translationese-index: Using Likelihood Ratios for Graded and Generalizable Measurement of Translationese](https://arxiv.org/abs/2507.12260)
*Yikang Liu,Wanyang Zhang,Yiming Wang,Jialong Tang,Pei Zhang,Baosong Yang,Fei Huang,Rui Wang,Hai Hu*

Main category: cs.CL

TL;DR: 本研究提出了 T-index，一种量化翻译痕迹的新指标，该指标基于语言模型似然比计算，已被证明在跨领域评估中具有鲁棒性和效率，并且可以作为现有机器翻译质量评估指标的补充。


<details>
  <summary>Details</summary>
Motivation: 为了开发一种量化翻译痕迹（translationese）的方法，并作为机器翻译质量评估的补充指标。

Method: 提出了一种名为“翻译痕迹指数”（T-index）的量化指标，该指标通过对比微调的语言模型（LMs）的似然比计算得出。使用合成数据集和真实翻译数据集对 T-index 的跨领域泛化能力和有效性进行了评估。

Result: T-index 能够有效且高效地捕捉翻译中的翻译痕迹。使用少量合成数据微调的语言模型即可获得良好的 T-index 评分。T-index 的相对差异可以预测人类对翻译痕迹的标注，其绝对值与人类评分具有良好的相关性（Pearson

Conclusion: T-index 是一种新颖的、可量化的翻译指标，可以有效衡量翻译中“翻译痕迹”的程度，并且与现有的机器翻译质量评估指标（如 BLEU 和 COMET）的相关性较低，可以作为补充指标。

Abstract: In this paper, we propose the first quantitative measure for translationese
-- the translationese-index (T-index) for graded and generalizable measurement
of translationese, computed from the likelihood ratios of two contrastively
fine-tuned language models (LMs). We use a synthesized dataset and a dataset
with translations in the wild to evaluate T-index's generalizability in
cross-domain settings and its validity against human judgments. Our results
show that T-index is both robust and efficient. T-index scored by two 0.5B LMs
fine-tuned on only 1-5k pairs of synthetic data can well capture translationese
in the wild. We find that the relative differences in T-indices between
translations can well predict pairwise translationese annotations obtained from
human annotators; and the absolute values of T-indices correlate well with
human ratings of degrees of translationese (Pearson's $r = 0.568$).
Additionally, the correlation between T-index and existing machine translation
(MT) quality estimation (QE) metrics such as BLEU and COMET is low, suggesting
that T-index is not covered by these metrics and can serve as a complementary
metric in MT QE.

</details>


### [126] [Infherno: End-to-end Agent-based FHIR Resource Synthesis from Free-form Clinical Notes](https://arxiv.org/abs/2507.12261)
*Johann Frei,Nils Feldhus,Lisa Raithel,Roland Roller,Alexander Meyer,Frank Kramer*

Main category: cs.CL

TL;DR: Infherno 是一个利用 LLM 代理、代码执行和医疗术语数据库工具的端到端框架，用于将自由格式临床笔记自动转换为结构化 FHIR 资源，解决了现有方法的局限性，并达到了与人类相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的从自由格式临床笔记到结构化 FHIR 资源翻译的自动化方法，例如基于模块化、基于规则的系统或经过指令调优和约束解码的 LLM，通常存在泛化能力有限和结构不一致的问题。

Method: 提出一个由 LLM 代理、代码执行和医疗术语数据库工具提供支持的端到端框架，称为 Infherno，以解决现有从自由格式临床笔记到结构化 FHIR 资源翻译的自动化方法的局限性。

Result: Infherno 框架在预测 FHIR 资源方面与人类基线具有竞争力。

Conclusion: Infherno 框架能够生成符合 FHIR 模式的 FHIR 资源，并且在从非结构化文本预测 FHIR 资源方面与人类基线具有竞争力。

Abstract: For clinical data integration and healthcare services, the HL7 FHIR standard
has established itself as a desirable format for interoperability between
complex health data. Previous attempts at automating the translation from
free-form clinical notes into structured FHIR resources rely on modular,
rule-based systems or LLMs with instruction tuning and constrained decoding.
Since they frequently suffer from limited generalizability and structural
inconformity, we propose an end-to-end framework powered by LLM agents, code
execution, and healthcare terminology database tools to address these issues.
Our solution, called Infherno, is designed to adhere to the FHIR document
schema and competes well with a human baseline in predicting FHIR resources
from unstructured text. The implementation features a front end for custom and
synthetic data and both local and proprietary models, supporting clinical data
integration processes and interoperability across institutions.

</details>


### [127] [Text-ADBench: Text Anomaly Detection Benchmark based on LLMs Embedding](https://arxiv.org/abs/2507.12295)
*Feng Xiao,Jicong Fan*

Main category: cs.CL

TL;DR: 本研究通过实证研究和引入文本异常检测基准，评估了不同语言模型的嵌入在多种文本数据集上的异常检测性能。结果显示，嵌入质量是关键，LLM嵌入并未使深度学习方法优于传统浅层算法。研究还提出了利用跨模型性能矩阵低秩特性进行快速模型评估的策略，并开源了相关工具包。


<details>
  <summary>Details</summary>
Motivation: 尽管在大型语言模型（LLM）和异常检测算法方面取得了显著进展，但缺乏用于评估现有文本数据异常检测方法的标准化和全面的基准，限制了严格的比较和创新方法的开发。

Method: 该研究进行了一项全面的实证研究，并引入了一个文本异常检测基准。该基准利用了来自各种预训练语言模型的嵌入，涵盖了广泛的文本数据集。研究系统地评估了基于嵌入的文本异常检测的有效性，纳入了早期语言模型（GloVe, BERT）、多个LLM（LLaMa-2, Llama-3, Mistral, OpenAI）、多领域文本数据集（新闻、社交媒体、科学出版物）以及全面的评估指标（AUROC, AUPRC）。

Result: 研究发现，嵌入质量对异常检测的有效性起着关键作用，并且在使用LLM嵌入时，深度学习方法并未优于传统的浅层算法。跨模型性能矩阵的低秩特性为快速模型评估和选择提供了有效策略。通过开源基准工具包，为未来在鲁棒和可扩展的文本异常检测系统方面的研究奠定了基础。

Conclusion: 研究结果表明，嵌入质量显著影响文本异常检测的有效性，并且在使用大型语言模型（LLM）的嵌入时，深度学习方法并不比传统的浅层算法（如KNN、Isolation Forest）表现出性能优势。此外，跨模型性能矩阵表现出显著的低秩特性，这为在实际应用中快速评估和选择模型（或嵌入）提供了一种有效的策略。

Abstract: Text anomaly detection is a critical task in natural language processing
(NLP), with applications spanning fraud detection, misinformation
identification, spam detection and content moderation, etc. Despite significant
advances in large language models (LLMs) and anomaly detection algorithms, the
absence of standardized and comprehensive benchmarks for evaluating the
existing anomaly detection methods on text data limits rigorous comparison and
development of innovative approaches. This work performs a comprehensive
empirical study and introduces a benchmark for text anomaly detection,
leveraging embeddings from diverse pre-trained language models across a wide
array of text datasets. Our work systematically evaluates the effectiveness of
embedding-based text anomaly detection by incorporating (1) early language
models (GloVe, BERT); (2) multiple LLMs (LLaMa-2, LLama-3, Mistral, OpenAI
(small, ada, large)); (3) multi-domain text datasets (news, social media,
scientific publications); (4) comprehensive evaluation metrics (AUROC, AUPRC).
Our experiments reveal a critical empirical insight: embedding quality
significantly governs anomaly detection efficacy, and deep learning-based
approaches demonstrate no performance advantage over conventional shallow
algorithms (e.g., KNN, Isolation Forest) when leveraging LLM-derived
embeddings.In addition, we observe strongly low-rank characteristics in
cross-model performance matrices, which enables an efficient strategy for rapid
model evaluation (or embedding evaluation) and selection in practical
applications. Furthermore, by open-sourcing our benchmark toolkit that includes
all embeddings from different models and code at
https://github.com/jicongfan/Text-Anomaly-Detection-Benchmark, this work
provides a foundation for future research in robust and scalable text anomaly
detection systems.

</details>


### [128] [Exploring Gender Bias in Alzheimer's Disease Detection: Insights from Mandarin and Greek Speech Perception](https://arxiv.org/abs/2507.12356)
*Liu He,Yuanchao Li,Rui Feng,XinRan Han,Yin-Long Liu,Yuwei Yang,Zude Zhu,Jiahong Yuan*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Gender bias has been widely observed in speech perception tasks, influenced
by the fundamental voicing differences between genders. This study reveals a
gender bias in the perception of Alzheimer's Disease (AD) speech. In a
perception experiment involving 16 Chinese listeners evaluating both Chinese
and Greek speech, we identified that male speech was more frequently identified
as AD, with this bias being particularly pronounced in Chinese speech. Acoustic
analysis showed that shimmer values in male speech were significantly
associated with AD perception, while speech portion exhibited a significant
negative correlation with AD identification. Although language did not have a
significant impact on AD perception, our findings underscore the critical role
of gender bias in AD speech perception. This work highlights the necessity of
addressing gender bias when developing AD detection models and calls for
further research to validate model performance across different linguistic
contexts.

</details>


### [129] [Beyond Single Models: Enhancing LLM Detection of Ambiguity in Requests through Debate](https://arxiv.org/abs/2507.12370)
*Ana Davila,Jacinto Colan,Yasuhisa Hasegawa*

Main category: cs.CL

TL;DR: 本研究提出了一种多代理辩论框架，通过让多个LLM（包括Llama3-8B和Mistral-7B）进行辩论来提高处理歧义的能力。结果显示，该框架显著提升了模型的性能，特别是Mistral-7B，成功率达到76.7%，证明了结构化辩论在增强LLM清晰度和鲁棒性方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型（LLM）在处理用户请求时面临的歧义挑战。

Method: 本研究引入并评估了一个多代理辩论框架，该框架由三种LLM架构（Llama3-8B、Gemma2-9B和Mistral-7B变体）和一个包含各种歧义的数据集组成。

Result: 辩论框架显著提高了Llama3-8B和Mistral-7B变体的性能，其中Mistral-7B主导的辩论成功率达到76.7%，尤其在处理复杂的歧义和实现有效的共识方面表现出色。

Conclusion: 该辩论框架作为一种有针对性的方法，可以增强大型语言模型（LLM）的能力，并为开发更强大、更自适应的语言理解系统提供了重要的见解，证明了结构化辩论可以提高交互系统的清晰度。

Abstract: Large Language Models (LLMs) have demonstrated significant capabilities in
understanding and generating human language, contributing to more natural
interactions with complex systems. However, they face challenges such as
ambiguity in user requests processed by LLMs. To address these challenges, this
paper introduces and evaluates a multi-agent debate framework designed to
enhance detection and resolution capabilities beyond single models. The
framework consists of three LLM architectures (Llama3-8B, Gemma2-9B, and
Mistral-7B variants) and a dataset with diverse ambiguities. The debate
framework markedly enhanced the performance of Llama3-8B and Mistral-7B
variants over their individual baselines, with Mistral-7B-led debates achieving
a notable 76.7% success rate and proving particularly effective for complex
ambiguities and efficient consensus. While acknowledging varying model
responses to collaborative strategies, these findings underscore the debate
framework's value as a targeted method for augmenting LLM capabilities. This
work offers important insights for developing more robust and adaptive language
understanding systems by showing how structured debates can lead to improved
clarity in interactive systems.

</details>


### [130] [Web-Browsing LLMs Can Access Social Media Profiles and Infer User Demographics](https://arxiv.org/abs/2507.12372)
*Meysam Alizadeh,Fabrizio Gilardi,Zeynab Samei,Mohsen Mosleh*

Main category: cs.CL

TL;DR: 具备网络浏览能力的LLM可以从社交媒体推断用户人口属性，但存在偏见风险，应限制其在公开应用中的使用。


<details>
  <summary>Details</summary>
Motivation: 评估具备网络浏览能力的LLM在直接检索和分析社交媒体数据以推断用户人口属性方面的能力，这是一个先前未被探索的领域。

Method: 使用合成数据集（48个X（Twitter）账户）和调查数据集（1,384名国际参与者）来评估LLM通过用户名推断用户人口属性的能力。分析了LLM如何解析和解释社交媒体资料，以了解潜在的偏见。

Result: LLM能够访问社交媒体内容并以合理的准确性预测用户人口属性。分析显示，LLM对社交媒体资料的解析可能导致对活动量少的账户产生性别和政治偏见。

Conclusion: LLM在访问和分析社交媒体数据以推断用户人口属性方面表现出潜力，但也带来了性别和政治偏见以及被滥用的风险。建议限制其在公开应用中的能力，并为验证过的研究目的保留受控访问。

Abstract: Large language models (LLMs) have traditionally relied on static training
data, limiting their knowledge to fixed snapshots. Recent advancements,
however, have equipped LLMs with web browsing capabilities, enabling real time
information retrieval and multi step reasoning over live web content. While
prior studies have demonstrated LLMs ability to access and analyze websites,
their capacity to directly retrieve and analyze social media data remains
unexplored. Here, we evaluate whether web browsing LLMs can infer demographic
attributes of social media users given only their usernames. Using a synthetic
dataset of 48 X (Twitter) accounts and a survey dataset of 1,384 international
participants, we show that these models can access social media content and
predict user demographics with reasonable accuracy. Analysis of the synthetic
dataset further reveals how LLMs parse and interpret social media profiles,
which may introduce gender and political biases against accounts with minimal
activity. While this capability holds promise for computational social science
in the post API era, it also raises risks of misuse particularly in information
operations and targeted advertising underscoring the need for safeguards. We
recommend that LLM providers restrict this capability in public facing
applications, while preserving controlled access for verified research
purposes.

</details>


### [131] [Probing for Arithmetic Errors in Language Models](https://arxiv.org/abs/2507.12379)
*Yucheng Sun,Alessandro Stolfo,Mrinmaya Sachan*

Main category: cs.CL

TL;DR: 内部激活可用于检测和纠正语言模型的算术错误。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型内部激活是否能用于检测算术错误。

Method: 通过分析模型内部激活来检测算术错误，并训练了轻量级的错误检测器来预测模型正确性，将分析扩展到链式思考轨迹，并演示了探针如何指导选择性重提示。

Result: 探针可以准确地从隐藏状态解码模型预测的输出和正确答案，错误检测器可以以超过90%的准确率预测模型正确性，探针可以很好地泛化到更复杂的链式思考设置，并能指导选择性重提示以提高任务准确性。

Conclusion: 内部激活可以用来预测算术错误，并且可以使用简单的探针来指导模型的选择性重提示，从而提高任务准确性。

Abstract: We investigate whether internal activations in language models can be used to
detect arithmetic errors. Starting with a controlled setting of 3-digit
addition, we show that simple probes can accurately decode both the model's
predicted output and the correct answer from hidden states, regardless of
whether the model's output is correct. Building on this, we train lightweight
error detectors that predict model correctness with over 90% accuracy. We then
extend our analysis to structured chain-of-thought traces on addition-only
GSM8K problems and find that probes trained on simple arithmetic generalize
well to this more complex setting, revealing consistent internal
representations. Finally, we demonstrate that these probes can guide selective
re-prompting of erroneous reasoning steps, improving task accuracy with minimal
disruption to correct outputs. Our findings suggest that arithmetic errors can
be anticipated from internal activations alone, and that simple probes offer a
viable path toward lightweight model self-correction.

</details>


### [132] [Advancing Retrieval-Augmented Generation for Structured Enterprise and Internal Data](https://arxiv.org/abs/2507.12425)
*Chandana Cheerla*

Main category: cs.CL

TL;DR: 一个改进的RAG框架，通过混合检索、元数据过滤、语义分块和保留表格结构来增强，以更有效地处理企业数据。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）虽然具有强大的生成能力，但受到静态预训练、短上下文窗口以及处理异构数据格式的挑战的限制。传统的检索增强生成（RAG）框架虽然解决了一些这些问题，但通常在处理结构化和半结构化数据时存在困难。

Method: 提出了一种先进的RAG框架，结合了使用密集嵌入（all-mpnet-base-v2）和BM25的混合检索策略，并通过SpaCy NER的元数据感知过滤和交叉编码器重排序进行了增强。该框架应用语义分块以保持文本连贯性，并保留表格数据结构以保持行-列完整性。量化索引优化了检索效率，而人在回路反馈和对话记忆提高了适应性。

Result: 实验表明，该框架在企业数据集上的Precision@5提高了15%（90对75），Recall@5提高了13%（87对74），平均倒数排名提高了16%（0.85对0.69）。定性评估显示，在5点李克特量表上，忠实度（4.6对3.0）、完整性（4.2对2.5）和相关性（4.5对3.2）得分更高。

Conclusion: 该框架在企业任务中有效，能够提供准确、全面且与上下文相关的响应。未来的工作将包括扩展到多模态数据和整合基于代理的检索。

Abstract: Organizations increasingly rely on proprietary enterprise data, including HR
records, structured reports, and tabular documents, for critical
decision-making. While Large Language Models (LLMs) have strong generative
capabilities, they are limited by static pretraining, short context windows,
and challenges in processing heterogeneous data formats. Conventional
Retrieval-Augmented Generation (RAG) frameworks address some of these gaps but
often struggle with structured and semi-structured data.
  This work proposes an advanced RAG framework that combines hybrid retrieval
strategies using dense embeddings (all-mpnet-base-v2) and BM25, enhanced by
metadata-aware filtering with SpaCy NER and cross-encoder reranking. The
framework applies semantic chunking to maintain textual coherence and retains
tabular data structures to preserve row-column integrity. Quantized indexing
optimizes retrieval efficiency, while human-in-the-loop feedback and
conversation memory improve adaptability.
  Experiments on enterprise datasets show notable improvements: Precision@5
increased by 15 percent (90 versus 75), Recall@5 by 13 percent (87 versus 74),
and Mean Reciprocal Rank by 16 percent (0.85 versus 0.69). Qualitative
evaluations show higher scores in Faithfulness (4.6 versus 3.0), Completeness
(4.2 versus 2.5), and Relevance (4.5 versus 3.2) on a 5-point Likert scale.
These results demonstrate the framework's effectiveness in delivering accurate,
comprehensive, and contextually relevant responses for enterprise tasks. Future
work includes extending to multimodal data and integrating agent-based
retrieval. The source code will be released at
https://github.com/CheerlaChandana/Enterprise-Chatbot

</details>


### [133] [Can We Predict Alignment Before Models Finish Thinking? Towards Monitoring Misaligned Reasoning Models](https://arxiv.org/abs/2507.12428)
*Yik Siu Chan,Zheng-Xin Yong,Stephen H. Bach*

Main category: cs.CL

TL;DR: 通过分析CoT的激活，可以提前预测语言模型的最终响应是否安全。


<details>
  <summary>Details</summary>
Motivation: 开放权重推理语言模型会生成长CoT，这会带来额外的安全风险，因为有害内容经常出现在CoT和最终输出中。因此，需要研究如何利用CoT来预测最终响应的错误。

Method: 研究了人类、大型语言模型和文本分类器等多种监控方法，并使用了CoT文本和激活。

Result: 与基于文本的方法相比，基于CoT激活的简单线性探针在预测最终响应是否安全方面表现更好。该探针在推理早期就能做出准确预测，并且在不同模型大小、系列和安全基准上都具有普遍性。

Conclusion: CoT的激活可以用来预测最终响应的安全性，并且在推理完成之前就能做出准确的预测。

Abstract: Open-weights reasoning language models generate long chains-of-thought (CoTs)
before producing a final response, which improves performance but introduces
additional alignment risks, with harmful content often appearing in both the
CoTs and the final outputs. In this work, we investigate if we can use CoTs to
predict final response misalignment. We evaluate a range of monitoring
approaches, including humans, highly-capable large language models, and text
classifiers, using either CoT text or activations. First, we find that a simple
linear probe trained on CoT activations can significantly outperform all
text-based methods in predicting whether a final response will be safe or
unsafe. CoT texts are often unfaithful and can mislead humans and classifiers,
while model latents (i.e., CoT activations) offer a more reliable predictive
signal. Second, the probe makes accurate predictions before reasoning
completes, achieving strong performance even when applied to early CoT
segments. These findings generalize across model sizes, families, and safety
benchmarks, suggesting that lightweight probes could enable real-time safety
monitoring and early intervention during generation.

</details>


### [134] [S2WTM: Spherical Sliced-Wasserstein Autoencoder for Topic Modeling](https://arxiv.org/abs/2507.12451)
*Suman Adhya,Debarshi Kumar Sanyal*

Main category: cs.CL

TL;DR: S2WTM是一种新的神经主题模型，通过使用球面切片瓦瑟斯坦距离来解决后验坍塌问题，并在主题连贯性、多样性和下游任务性能方面优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 为了在潜在空间中建模超球结构，同时缓解VAE-NTMs常出现的后验坍塌问题（这会导致KL散度项在目标函数中急剧减小，产生无效的潜在表示）。

Method: S2WTM采用支持单位超球面的先验分布，并利用球面切片瓦瑟斯坦距离使聚合后验分布与先验对齐。

Result: 实验结果表明，S2WTM在主题模型方面优于最先进的模型，能生成更连贯、更多样的主题，并提高了下游任务的性能。

Conclusion: S2WTM在主题模型方面优于最先进的模型，能生成更连贯、更多样的主题，并提高了下游任务的性能。

Abstract: Modeling latent representations in a hyperspherical space has proven
effective for capturing directional similarities in high-dimensional text data,
benefiting topic modeling. Variational autoencoder-based neural topic models
(VAE-NTMs) commonly adopt the von Mises-Fisher prior to encode hyperspherical
structure. However, VAE-NTMs often suffer from posterior collapse, where the KL
divergence term in the objective function highly diminishes, leading to
ineffective latent representations. To mitigate this issue while modeling
hyperspherical structure in the latent space, we propose the Spherical Sliced
Wasserstein Autoencoder for Topic Modeling (S2WTM). S2WTM employs a prior
distribution supported on the unit hypersphere and leverages the Spherical
Sliced-Wasserstein distance to align the aggregated posterior distribution with
the prior. Experimental results demonstrate that S2WTM outperforms
state-of-the-art topic models, generating more coherent and diverse topics
while improving performance on downstream tasks.

</details>


### [135] [Language Models Improve When Pretraining Data Matches Target Tasks](https://arxiv.org/abs/2507.12466)
*David Mizrahi,Anders Boesen Lindbo Larsen,Jesse Allardice,Suzie Petryk,Yuri Gorokhov,Jeffrey Li,Alex Fang,Josh Gardner,Tom Gunter,Afshin Dehghan*

Main category: cs.CL

TL;DR: BETR是一种新的数据选择方法，通过将预训练数据与评估基准对齐，可以显著提高模型性能并优化计算资源的使用。


<details>
  <summary>Details</summary>
Motivation: 探索当数据选择的优化显式化时会发生什么。

Method: 提出了一种名为Benchmark-Targeted Ranking (BETR)的简单方法，该方法根据与基准训练样本的相似性来选择预训练文档。BETR将基准样本和预训练文档的样本嵌入共享空间，通过与基准的相似性对该样本进行评分，然后训练一个轻量级分类器来预测整个语料库的这些分数。

Result: BETR在所有尺度上实现了2.1倍的计算乘数（相对于DCLM-Baseline，相对于未过滤数据为4.7倍），并在10个任务中的9个任务上提高了性能。BETR的泛化能力也很好，当针对与评估套件不重叠的多样化基准时，它仍然能匹配或优于基线。此外，更大的模型需要不太激进的过滤。

Conclusion: 直接将预训练数据与目标任务匹配可以精确地塑造模型能力，并且最优的选择策略必须适应模型规模。

Abstract: Every data selection method inherently has a target. In practice, these
targets often emerge implicitly through benchmark-driven iteration: researchers
develop selection strategies, train models, measure benchmark performance, then
refine accordingly. This raises a natural question: what happens when we make
this optimization explicit? To explore this, we propose benchmark-targeted
ranking (BETR), a simple method that selects pretraining documents based on
similarity to benchmark training examples. BETR embeds benchmark examples and a
sample of pretraining documents in a shared space, scores this sample by
similarity to benchmarks, then trains a lightweight classifier to predict these
scores for the full corpus. We compare data selection methods by training over
500 models spanning $10^{19}$ to $10^{22}$ FLOPs and fitting scaling laws to
them. From this, we find that simply aligning pretraining data to evaluation
benchmarks using BETR achieves a 2.1x compute multiplier over DCLM-Baseline
(4.7x over unfiltered data) and improves performance on 9 out of 10 tasks
across all scales. BETR also generalizes well: when targeting a diverse set of
benchmarks disjoint from our evaluation suite, it still matches or outperforms
baselines. Our scaling analysis further reveals a clear trend: larger models
require less aggressive filtering. Overall, our findings show that directly
matching pretraining data to target tasks precisely shapes model capabilities
and highlight that optimal selection strategies must adapt to model scale.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [136] [A Cellular Automata Approach to Donation Game](https://arxiv.org/abs/2507.11744)
*Marcin Kowalik,Przemysław Stokłosa,Mateusz Grabowski,Janusz Starzyk,Paweł Raif*

Main category: cs.MA

TL;DR: 本文研究了细胞自动机中合作的演变，发现代理的移动性和空间局部性对合作有显著影响。


<details>
  <summary>Details</summary>
Motivation: 探索在部分可观察环境和影响合作的多种因素（如声誉、慷慨和宽恕）下，合作的涌现和演变。

Method: 研究合作动力学，利用细胞自动机，定义符合捐赠游戏机制的细胞自动机规则，并引入感知和行动噪声模型以及控制代理策略概率演变的突变矩阵。

Result: 合作受到代理的移动性及其在游戏棋盘上的空间局部性的显著影响，强调了区分完全随机的多代理系统和更可能与最近邻居交互的系统的关键作用。

Conclusion: 合作行为受到环境噪声、部分可观察性以及可能包含声誉、慷慨和宽恕等特质的决策策略的影响。与传统的随机交互模拟不同，本文采用细胞自动机来研究当交互仅限于相邻代理时合作的演变。

Abstract: The donation game is a well-established framework for studying the emergence
and evolution of cooperation in multi-agent systems. The cooperative behavior
can be influenced by the environmental noise in partially observable settings
and by the decision-making strategies of agents, which may incorporate not only
reputation but also traits such as generosity and forgiveness. Traditional
simulations often assume fully random interactions, where cooperation is tested
between randomly selected agent pairs. In this paper, we investigate
cooperation dynamics using the concept of Stephen Wolfram's one-dimensional
binary cellular automata. This approach allows us to explore how cooperation
evolves when interactions are limited to neighboring agents. We define binary
cellular automata rules that conform to the donation game mechanics.
Additionally, we introduce models of perceptual and action noise, along with a
mutation matrix governing the probabilistic evolution of agent strategies. Our
empirical results demonstrate that cooperation is significantly affected by
agents' mobility and their spatial locality on the game board. These findings
highlight the importance of distinguishing between entirely random multi-agent
systems and those in which agents are more likely to interact with their
nearest neighbors.

</details>


### [137] [CoCre-Sam (Kokkuri-san): Modeling Ouija Board as Collective Langevin Dynamics Sampling from Fused Language Models](https://arxiv.org/abs/2507.11906)
*Tadahiro Taniguchi,Masatoshi Nagano,Haruumi Omoto,Yoshiki Hayashi*

Main category: cs.MA

TL;DR: CoCre-Sam 框架将集体人类语言现象（如使用通灵板）建模为集体 Langevin 动力学采样，有效地融合了语言模型，并从概率采样原理中产生了有意义的输出。


<details>
  <summary>Details</summary>
Motivation: 虽然存在心理学解释（如意念运动效应），但去中心化、隐式语言知识如何通过共享物理交互融合的计算理解仍然难以捉摸。

Method:  CoCre-Sam（集体生物采样）框架将此现象建模为从隐式融合的语言模型进行集体 Langevin 动力学采样。每个参与者都表示为与能量景观相关的代理，该景观源自反映语言先验的内部语言模型，并且代理根据局部能量梯度施加随机力。

Result: 模拟验证了 CoCre-Sam 动力学能够有效地融合不同的模型并生成有意义的字符序列，而部分移除研究则证实了集体互动和随机性的基本作用。

Conclusion: CoCre-Sam 提供了一种新颖的计算机制，将个体隐性知识、具身集体行为和涌现的语言现象联系起来，并将这些复杂的相互作用与概率采样原理相结合。

Abstract: Collective human activities like using an Ouija board (or Kokkuri-san) often
produce emergent, coherent linguistic outputs unintended by any single
participant. While psychological explanations such as the ideomotor effect
exist, a computational understanding of how decentralized, implicit linguistic
knowledge fuses through shared physical interaction remains elusive. We
introduce CoCre-Sam (Collective-Creature Sampling), a framework modeling this
phenomenon as collective Langevin dynamics sampling from implicitly fused
language models. Each participant is represented as an agent associated with an
energy landscape derived from an internal language model reflecting linguistic
priors, and agents exert stochastic forces based on local energy gradients. We
theoretically prove that the collective motion of the shared pointer
(planchette) corresponds to Langevin MCMC sampling from the sum of individual
energy landscapes, representing fused collective knowledge. Simulations
validate that CoCre-Sam dynamics effectively fuse different models and generate
meaningful character sequences, while ablation studies confirm the essential
roles of collective interaction and stochasticity. Altogether, CoCre-Sam
provides a novel computational mechanism linking individual implicit knowledge,
embodied collective action, and emergent linguistic phenomena, grounding these
complex interactions in the principles of probabilistic sampling.

</details>


### [138] [Modeling Feasible Locomotion of Nanobots for Cancer Detection and Treatment](https://arxiv.org/abs/2507.12400)
*Noble Harasha,Cristina Gava,Nancy Lynch,Claudia Contini,Frederik Mallmann-Trenn*

Main category: cs.MA

TL;DR: 本文提出了一个用于癌症治疗的纳米机器人模型，该模型具有两种变体：一种使用固定的化学梯度，另一种使用由纳米机器人自身产生的动态化学梯度。模拟结果表明，第二种模型变体由于其化学信号放大机制，在定位癌变组织方面表现更好。


<details>
  <summary>Details</summary>
Motivation: 将运动纳米颗粒（“纳米机器人”）引入人体，有潜力提高药物递送的选择性并减少副作用。本文考虑了一个纳米机器人蜂群，用于定位单一癌变区域，并通过在癌变部位释放携带的药物来治疗。然而，在纳米尺度上，单个智能体的计算、通信、传感和运动能力都极其有限、不稳定且/或不存在。

Method: 本文提出了一个通用的模型来正式描述纳米机器人（在血液等胶体环境中）的个体和集体行为，用于癌症的检测和治疗。该模型包括一个受实际纳米颗粒启发的、可行的、精确的智能体运动模型，这些颗粒在外部化学梯度存在的情况下，通过自推作用移向浓度较高区域。文章提出了该通用模型的两种变体：第一种假设存在一个随时间固定的、以癌变部位为中心的内源性化学梯度；第二种是一种更具推测性和动态性的变体，其中智能体自身产生并放大一个以癌变部位为中心的化学梯度。

Result: 对于第一种模型变体，文章展示了智能体在所提出的运动模型下的行为的模拟结果，以及分析结果，用于限制智能体到达癌变部位所需的时间。对于第二种模型变体，模拟结果突显了智能体发出自身化学信号的集体效益，并展示了其运行时性能的显著提高。

Conclusion: 尽管第二种模型在智能体能力假设方面更具推测性，但它通过化学信号放大机制在运行时性能上有了显著的改进，这表明其集体效益。

Abstract: Deploying motile nanosized particles, also known as ``nanobots'', in the
human body promises to improve selectivity in drug delivery and reduce side
effects. We consider a swarm of nanobots locating a single cancerous region and
treating it by releasing an onboard payload of drugs at the site. At nanoscale,
the computation, communication, sensing, and locomotion capabilities of
individual agents are extremely limited, noisy, and/or nonexistent.
  We present a general model to formally describe the individual and collective
behavior of agents in a colloidal environment, such as the bloodstream, for
cancer detection and treatment by nanobots. This includes a feasible and
precise model of agent locomotion, inspired by actual nanoparticles that, in
the presence of an external chemical gradient, move towards areas of higher
concentration by means of self-propulsion. We present two variants of our
general model: The first assumes an endogenous chemical gradient that is fixed
over time and centered at the targeted cancer site; the second is a more
speculative and dynamic variant in which agents themselves create and amplify a
chemical gradient centered at the cancer site. In both settings, agents can
sense the gradient and ascend it noisily, locating the cancer site more quickly
than via simple Brownian motion.
  For the first variant of the model, we present simulation results to show the
behavior of agents under our locomotion model, as well as {analytical results}
to bound the time it takes for the agents to reach the cancer site. For the
second variant, simulation results highlight the collective benefit in having
agents issue their own chemical signal. While arguably more speculative in its
agent capability assumptions, this variant shows a significant improvement in
runtime performance over the first variant, resulting from its chemical signal
amplification mechanism.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [139] [A Framework to Pinpoint Bottlenecks in Emerging Solar Cells and Disordered Devices via Differential Machine Learning](https://arxiv.org/abs/2507.11740)
*Cai Williams,Chen Wang,Alexander Ehm,Dietrich R. T. Zahn,Maria Saladina,Carsten Deibel,Roderick C. I. Mackenzie*

Main category: physics.app-ph

TL;DR: 开发了基于神经网络的方法，仅用光电流-电压曲线即可评估太阳能电池材料参数，并提供置信度评估。


<details>
  <summary>Details</summary>
Motivation: 目前的材料开发进展迅速，但与表征能力脱节，导致材料开发如同“随机游走”，新材料的提出速度超过了我们对其的理解。然而，将宏观器件性能与微观性质联系起来是开发下一代太阳能电池、传感器和晶体管材料的关键挑战。

Method: 提出两种基于神经网络的方法，仅需测量光电流-电压曲线和适度的计算资源即可提取关键材料参数，如载流子迁移率和陷阱态密度。

Result: 演示了该技术在PM6:Y12和PM6:BTP-eC9有机太阳能电池上的应用，这些电池或是新制的，或是经过性能衰减的。

Conclusion: 该方法利用光电流-电压曲线来评估有机太阳能电池的材料参数，并将预测参数置于非高斯似然分布中，从而对每个预测参数进行置信度评估。

Abstract: A key challenge in the development of materials for the next generation of
solar cells, sensors and transistors is linking macroscopic device performance
to underlying microscopic properties. For years, fabrication of devices has
been faster than our ability to characterize them. This has led to a random
walk of material development, with new materials being proposed faster than our
understanding. We present two neural network-based methods for extracting key
material parameters, including charge carrier mobility and trap state density,
in optoelectronic devices such as solar cells. Our methods require solely
measured light current--voltage curve and modest computational resources,
making our approach applicable in even minimally equipped laboratories. Unlike
traditional machine learning models, our methods place the final material
values in a non-Gaussian likelihood distribution, allowing confidence
assessment of each predicted parameter. We demonstrate these techniques using
fresh PM6:Y12 and degraded PM6:BTP-eC9 organic solar cells.

</details>


### [140] [Magneto-photoelectrochemical 2D heterojunction platform for biosensing detection](https://arxiv.org/abs/2507.11843)
*Tao Wang,Nan Zhang,Hongjie Huang,Yunhe An,Yunyun Dai,Yongrui Li,Nan Yang,Chaojie Yang,Xinran Zhou,Yucheng Zhu,Yingshan Ma,Lingling Huang,Yongtian Wang,Yang Liu,Zhiyong Yan*

Main category: physics.app-ph

TL;DR: 本研究通过磁场调制策略，利用MXenes/Co-TiO2异质结构显著提高了PEC生物传感器的灵敏度，实现了对PKA的超灵敏检测，为生物传感和疾病诊断提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 光电化学（PEC）生物传感器虽然具有高灵敏度和低背景噪声的优点，但其性能受到光生载流子复合的严重限制。

Method: 本研究提出了一种非接触式磁场调制策略，通过操纵载流子自旋态来抑制电子-空穴复合，并在此机制上开发了基于MXenes/钴掺杂二氧化钛（Co-TiO2）异质结构的新型磁场调制光电化学（PEC）生物传感平台，实现了对蛋白激酶A（PKA）活性的超灵敏检测。

Result: 与未施加磁场的探针修饰生物传感器相比，所开发的平台检测灵敏度提高了68.75%，PKA的超低检测限为0.00016 U/mL，线性范围为0.005至80 U/mL。

Conclusion: 本研究提出了一种新颖的磁场调制策略，通过操纵载流子自旋态来抑制电子-空穴复合，从而显著提高光电转换效率。该策略在MXenes/钴掺杂二氧化钛（Co-TiO2）异质结构的基础上，开发了一个基于磁场调制的蛋白激酶A（PKA）活性检测平台，实现了对PKA的超灵敏检测，检测灵敏度提高了68.75%，PKA的超低检测限为0.00016 U/mL，线性范围宽，为激酶活性分析提供了新方法，并为高性能生物传感平台的开发开辟了新途径，有望用于早期疾病诊断和药物筛选。

Abstract: Photoelectrochemical (PEC) biosensors exhibit significant potential for
biomolecule detection due to their high sensitivity and low background noise.
However, their performance is severely constrained by the rapid recombination
of photogenerated charge carriers. This study innovatively introduces a
non-contact magnetic modulation strategy to suppress electron-hole
recombination by manipulating carrier spin states, thereby significantly
enhancing photoelectric conversion efficiency. Building on this mechanism, we
developed a novel magnetically modulated PEC biosensing platform based on the
MXenes/cobalt-doped titanium dioxide (Co-TiO2) heterostructure. This platform
achieved ultrasensitive detection of protein kinase A (PKA) activity. Compared
to an identical probe-modified biosensor without magnetic field application,
the developed platform demonstrated a 68.75% enhancement in detection
sensitivity and achieved an ultralow detection limit for PKA of 0.00016 U/mL.
It also exhibited a wide linear range from 0.005 to 80 U/mL. This research not
only provides a novel methodology for kinase activity analysis but also
pioneers the innovative strategy of magnetic modulation for enhanced PEC
sensing. It opens new avenues for developing high-performance biosensing
platforms, holding significant promise for early disease diagnosis and drug
screening applications.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [141] [Predictable Drifts in Collective Cultural Attention: Evidence from Nation-Level Library Takeout Data](https://arxiv.org/abs/2507.12007)
*Anders Weile Larsen,Vedran Sekara*

Main category: cs.SI

TL;DR: 文化产品（如图书）的消费者关注度难以预测，且集体关注度存在预测限制。研究发现，文化会随时间持续漂移，且不同书籍类型和人群的影响不同，这对于市场预测和推荐系统具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 预测图书、电影、歌曲等文化产品的消费者关注度变化，以及预测跨文化产品的集体关注度限制。

Method: 通过分析四年间近200万人的全国图书馆借阅数据（包括超过1亿次的借阅和超过66万本不同的书籍），并结合注册数据来研究年龄、性别、教育程度和地理区域对文化漂移的影响。

Result: 文化会以接近恒定的速率持续漂移，导致随时间的差异不断扩大，并且这种漂移在不同书籍类型之间存在差异。不同的人口群体对文化漂移的影响程度不同。

Conclusion: 文化，以所借书籍的流行度分布来衡量，随着时间的推移，其组合关注度会以接近恒定的速率持续漂移，并且这种漂移在不同的书籍类型之间存在差异。)

Abstract: Predicting changes in consumer attention for cultural products, such as
books, movies, and songs, is notoriously difficult. Past research on predicting
the popularity of individual products suggests the existence of intrinsic
prediction limits. However, little is known about the limits for predicting
collective attention across cultural products. Here, we analyze four years of
nationwide library loan data for approximately 2 million individuals,
comprising over 100 million loans of more than 660,000 unique books. We find
that culture, as measured by popularity distributions of loaned books, drifts
continually from month to month at a near-constant rate, leading to a growing
divergence over time, and that drifts vary between different book genres. By
linking book loans to registry data, we investigate the influence of age, sex,
educational level, and geographical area on cultural drift, finding
heterogeneous effects from the different demographic groups. Our findings have
important implications for market forecasting and developing robust recommender
systems, highlighting the need to account for specific drift dynamics for
different types of items and demographic groups.

</details>


### [142] [Contrastive Cascade Graph Learning for Classifying Real and Synthetic Information Diffusion Patterns](https://arxiv.org/abs/2507.12063)
*Naoki Shibao,Sho Tsugawa*

Main category: cs.SI

TL;DR: CCGL是一种用于级联图分类的对比学习方法，在捕捉结构模式方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了遏制有害内容的传播和促进可靠信息的传播，对级联图挖掘的研究吸引了越来越多的关注。其中，对比级联图学习（CCGL）是一种有前景的方法。级联图挖掘中的一个重要任务是级联分类，即根据级联图的结构特征对其进行分类。尽管CCGL有望在此任务中发挥作用，但其性能尚未得到充分评估。

Method: 对比级联图学习（CCGL）

Result: 研究结果表明，CCGL在捕捉平台和模型特定的级联图结构模式方面表现出色。

Conclusion: CCGL在捕捉平台和模型特定的级联图结构模式方面表现出强大的性能，有潜力应用于各种下游信息传播分析任务。

Abstract: A wide variety of information is disseminated through social media, and
content that spreads at scale can have tangible effects on the real world. To
curb the spread of harmful content and promote the dissemination of reliable
information, research on cascade graph mining has attracted increasing
attention. A promising approach in this area is Contrastive Cascade Graph
Learning (CCGL). One important task in cascade graph mining is cascade
classification, which involves categorizing cascade graphs based on their
structural characteristics. Although CCGL is expected to be effective for this
task, its performance has not yet been thoroughly evaluated. This study aims to
investigate the effectiveness of CCGL for cascade classification. Our findings
demonstrate the strong performance of CCGL in capturing platform- and
model-specific structural patterns in cascade graphs, highlighting its
potential for a range of downstream information diffusion analysis tasks.

</details>


### [143] [Multimodal Coordinated Online Behavior: Trade-offs and Strategies](https://arxiv.org/abs/2507.12108)
*Lorenzo Mannocci,Stefano Cresci,Matteo Magnani,Anna Monreale,Maurizio Tesconi*

Main category: cs.SI

TL;DR: This paper explores multimodal approaches for detecting coordinated online behavior, finding that combining different data types offers a richer understanding than single-data methods, despite variations in individual data source utility.


<details>
  <summary>Details</summary>
Motivation: Traditional methods focusing on single interaction types or independently analyzing multiple modalities may miss complex dynamics in multimodal coordinated behavior. This research aims to improve the detection and analysis of such behavior.

Method: The study compares different operationalizations for detecting multimodal coordinated behavior, evaluating weakly and strongly integrated multimodal models against monomodal approaches. It assesses the impact of various implementations of multimodality on detection outcomes.

Result: Multimodal approaches provide a more comprehensive understanding of coordination dynamics compared to monomodal ones, even though some modalities do not contribute distinct information. The findings help in understanding the trade-offs in integrating different data modalities.

Conclusion: Coordinated online behavior analysis benefits from multimodal approaches, although not all modalities offer unique insights. The study highlights the trade-offs between weakly and strongly integrated multimodal models for capturing different types of coordination.

Abstract: Coordinated online behavior, which spans from beneficial collective actions
to harmful manipulation such as disinformation campaigns, has become a key
focus in digital ecosystem analysis. Traditional methods often rely on
monomodal approaches, focusing on single types of interactions like co-retweets
or co-hashtags, or consider multiple modalities independently of each other.
However, these approaches may overlook the complex dynamics inherent in
multimodal coordination. This study compares different ways of operationalizing
the detection of multimodal coordinated behavior. It examines the trade-off
between weakly and strongly integrated multimodal models, highlighting the
balance between capturing broader coordination patterns and identifying tightly
coordinated behavior. By comparing monomodal and multimodal approaches, we
assess the unique contributions of different data modalities and explore how
varying implementations of multimodality impact detection outcomes. Our
findings reveal that not all the modalities provide distinct insights, but that
with a multimodal approach we can get a more comprehensive understanding of
coordination dynamics. This work enhances the ability to detect and analyze
coordinated online behavior, offering new perspectives for safeguarding the
integrity of digital platforms.

</details>


<div id='cond-mat.soft'></div>

# cond-mat.soft [[Back]](#toc)

### [144] [Dual Effect of L-Cysteine on the Reorientation and Relaxation of Fe3O4-Decorated Graphene Oxide Liquid Crystals](https://arxiv.org/abs/2507.12018)
*M. Zhezhu,Y. Melikyan,V. Hayrapetyan,A. Vasilev,H. Gharagulyan*

Main category: cond-mat.soft

TL;DR: 本研究通过磁场控制Fe3O4修饰的L-半胱氨酸功能化GOLC的取向和弛豫时间，并实现了微图案的创建，为高级应用提供了可调谐GOLC组件的制造方法。


<details>
  <summary>Details</summary>
Motivation: 研究Fe3O4修饰的L-半胱氨酸功能化GOLC在外部磁场下的动力学行为，分析L-半胱氨酸对GOLC取向和弛豫时间的影响，并探索其在微图案创建和控制方面的应用，旨在实现可调谐GOLC组件的制造。

Method: 通过溶液燃烧法合成Fe3O4纳米颗粒，并用L-半胱氨酸对电化学合成的GO进行功能化，然后研究Fe3O4修饰的L-半胱氨酸功能化GOLC在外部磁场下的动力学行为，并与GOLC进行比较，同时研究L-半胱氨酸对GOLC系统磁场诱导的取向和弛豫时间的影响。

Result: Fe3O4修饰的L-半胱氨酸功能化GOLC在磁场作用下表现出可调谐的取向行为。L-半胱氨酸能够缩短GOLC的取向时间并延长其弛豫时间。此外，通过磁场可以控制GOLC干燥液滴的微图案创建，形成网状、针织状、花状、辐射状和平行条状等图案。

Conclusion: 本研究表明，L-半胱氨酸对Fe3O4修饰的L-半胱氨酸功能化GOLC的磁场诱导取向和弛豫时间具有双重影响，可缩短取向时间并延长弛豫时间，这为可调谐GOLC组件的制造提供了可能。

Abstract: Here, we study the dynamics of Fe3O4-decorated L-Cysteine-functionalized GOLC
director under an external magnetic field and analyze L-Cysteine's influence on
the reorientation and relaxation time of the director. In particular, Fe3O4
nanoparticles were synthesized by solution-combustion method and added for
altering orientational properties of GO which we synthesized electrochemically
and functionalized by L-Cysteine. In addition, a comprehensive comparison of
the director behaviour of GOLC and Fe3O4-decorated L-Cysteine-GOLC was
undertaken to verify the tunability of the aforementioned systems. Furthermore,
we demonstrate dual-effect of L-Cysteine on the magnetic field-induced
alignment and relaxation time of GOLC systems, namely decrease in reorientation
time and at the same time increase in relaxation time. Besides, micropattern
creation and controlling in the drying drops of GOLC (net- and knit-like,
flower-like, radial- and parallel-strip etc.) using a magnetic field were
shown. The results of our studies could facilitate the fabrication of ordered
and patterned tunable GOLC assemblies for a range of advanced applications.
GOLC was undertaken to verify the tunability of the aforementioned systems.
Furthermore, we demonstrate dual-effect of L-Cysteine on the magnetic
field-induced alignment and relaxation time of GOLC systems, namely decrease in
reorientation time and at the same time increase in relaxation time. Besides,
micropattern creation and controlling in the drying drops of GOLC (net- and
knit-like, flower-like, radial- and parallel-strip etc.) using a magnetic field
were shown. The results of our studies could facilitate the fabrication of
ordered and patterned tunable GOLC assemblies for a range of advanced
applications.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [145] [HCOMC: A Hierarchical Cooperative On-Ramp Merging Control Framework in Mixed Traffic Environment on Two-Lane Highways](https://arxiv.org/abs/2507.11621)
*Tianyi Wang,Yangyang Wang,Jie Pan,Junfeng Jiao,Christian Claudel*

Main category: cs.RO

TL;DR: 提出了一种用于异构交通流的分层协同匝道汇入控制（HCOMC）框架，该框架通过结合纵向协调规划、自主变道和多目标优化，提高了安全性、效率和燃油经济性。


<details>
  <summary>Details</summary>
Motivation: 为了解决异构交通流中CAVs尚未普及的问题，需要为两车道高速公路提出一个分层协同的匝道汇入控制（HCOMC）框架。

Method: 提出了一种HCOMC框架，包括基于改进虚拟车辆模型的纵向协调规划模型、基于博弈论的自主变道模型以及使用精英非支配排序遗传算法的多目标优化模型。

Result: 通过仿真分析了HCOMC在不同交通密度和CAV渗透率下的性能，结果表明HCOMC具有显著的综合优势。

Conclusion: HCOMC在提高车辆安全、稳定和快速并入、优化交通效率和节省燃油消耗方面表现出显著的综合优势。

Abstract: Highway on-ramp merging areas are common bottlenecks to traffic congestion
and accidents. Currently, a cooperative control strategy based on connected and
automated vehicles (CAVs) is a fundamental solution to this problem. While CAVs
are not fully widespread, it is necessary to propose a hierarchical cooperative
on-ramp merging control (HCOMC) framework for heterogeneous traffic flow on
two-lane highways to address this gap. This paper extends longitudinal
car-following models based on the intelligent driver model and lateral
lane-changing models using the quintic polynomial curve to account for
human-driven vehicles (HDVs) and CAVs, comprehensively considering human
factors and cooperative adaptive cruise control. Besides, this paper proposes a
HCOMC framework, consisting of a hierarchical cooperative planning model based
on the modified virtual vehicle model, a discretionary lane-changing model
based on game theory, and a multi-objective optimization model using the
elitist non-dominated sorting genetic algorithm to ensure the safe, smooth, and
efficient merging process. Then, the performance of our HCOMC is analyzed under
different traffic densities and CAV penetration rates through simulation. The
findings underscore our HCOMC's pronounced comprehensive advantages in
enhancing the safety of group vehicles, stabilizing and expediting merging
process, optimizing traffic efficiency, and economizing fuel consumption
compared with benchmarks.

</details>


### [146] [A Roadmap for Climate-Relevant Robotics Research](https://arxiv.org/abs/2507.11623)
*Alan Papalia,Charles Dawson,Laurentiu L. Anton,Norhan Magdy Bayomi,Bianca Champenois,Jung-Hoon Cho,Levi Cai,Joseph DelPreto,Kristen Edwards,Bilha-Catherine Githinji,Cameron Hickert,Vindula Jayawardana,Matthew Kramer,Shreyaa Raghavan,David Russell,Shide Salimi,Jingnan Shi,Soumya Sudhakar,Yanwei Wang,Shouyi Wang,Luca Carlone,Vijay Kumar,Daniela Rus,John E. Fernandez,Cathy Wu,George Kantor,Derek Young,Hanumant Singh*

Main category: cs.RO

TL;DR: 机器人学可以为应对气候变化做出贡献。本文提出了一个路线图，列出了机器人技术在能源、建筑、交通、工业、土地利用和地球科学等领域应对气候变化的应用和合作机会。


<details>
  <summary>Details</summary>
Motivation: 气候变化是21世纪面临的重大挑战，机器人领域的研究人员正在寻求为其做出贡献。

Method: 通过识别高影响力领域和具体可操作的问题，来激发机器人学和气候科学交叉领域的新研究方向和合作。

Result: 本文提出了一个包含能源系统优化、建筑、精准农业、建筑围护结构改造、自动驾驶卡车和大规模环境监测等应用的路线图。它强调不仅要应用实体机器人，还要应用机器人学的规划、感知、控制和估计算法等工具。

Conclusion: 本文旨在为气候相关的机器人研究提出一个路线图，明确了在能源、建筑环境、交通、工业、土地利用和地球科学等领域，机器人专家与气候专家的合作机会。

Abstract: Climate change is one of the defining challenges of the 21st century, and
many in the robotics community are looking for ways to contribute. This paper
presents a roadmap for climate-relevant robotics research, identifying
high-impact opportunities for collaboration between roboticists and experts
across climate domains such as energy, the built environment, transportation,
industry, land use, and Earth sciences. These applications include problems
such as energy systems optimization, construction, precision agriculture,
building envelope retrofits, autonomous trucking, and large-scale environmental
monitoring. Critically, we include opportunities to apply not only physical
robots but also the broader robotics toolkit - including planning, perception,
control, and estimation algorithms - to climate-relevant problems. A central
goal of this roadmap is to inspire new research directions and collaboration by
highlighting specific, actionable problems at the intersection of robotics and
climate. This work represents a collaboration between robotics researchers and
domain experts in various climate disciplines, and it serves as an invitation
to the robotics community to bring their expertise to bear on urgent climate
priorities.

</details>


### [147] [CoNav Chair: Development and Evaluation of a Shared Control based Wheelchair for the Built Environment](https://arxiv.org/abs/2507.11716)
*Yifan Xu,Qianwei Wang,Jordan Lillie,Vineet Kamat,Carol Menassa,Clive D'Souza*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: As the global population of people with disabilities (PWD) continues to grow,
so will the need for mobility solutions that promote independent living and
social integration. Wheelchairs are vital for the mobility of PWD in both
indoor and outdoor environments. The current SOTA in powered wheelchairs is
based on either manually controlled or fully autonomous modes of operation,
offering limited flexibility and often proving difficult to navigate in
spatially constrained environments. Moreover, research on robotic wheelchairs
has focused predominantly on complete autonomy or improved manual control;
approaches that can compromise efficiency and user trust. To overcome these
challenges, this paper introduces the CoNav Chair, a smart wheelchair based on
the Robot Operating System (ROS) and featuring shared control navigation and
obstacle avoidance capabilities that are intended to enhance navigational
efficiency, safety, and ease of use for the user. The paper outlines the CoNav
Chair's design and presents a preliminary usability evaluation comparing three
distinct navigation modes, namely, manual, shared, and fully autonomous,
conducted with 21 healthy, unimpaired participants traversing an indoor
building environment. Study findings indicated that the shared control
navigation framework had significantly fewer collisions and performed
comparably, if not superior to the autonomous and manual modes, on task
completion time, trajectory length, and smoothness; and was perceived as being
safer and more efficient based on user reported subjective assessments of
usability. Overall, the CoNav system demonstrated acceptable safety and
performance, laying the foundation for subsequent usability testing with end
users, namely, PWDs who rely on a powered wheelchair for mobility.

</details>


### [148] [Generating Actionable Robot Knowledge Bases by Combining 3D Scene Graphs with Robot Ontologies](https://arxiv.org/abs/2507.11770)
*Giang Nguyen,Mihai Pomarlan,Sascha Jongebloed,Nils Leusmann,Minh Nhat Vu,Michael Beetz*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In robotics, the effective integration of environmental data into actionable
knowledge remains a significant challenge due to the variety and
incompatibility of data formats commonly used in scene descriptions, such as
MJCF, URDF, and SDF. This paper presents a novel approach that addresses these
challenges by developing a unified scene graph model that standardizes these
varied formats into the Universal Scene Description (USD) format. This
standardization facilitates the integration of these scene graphs with robot
ontologies through semantic reporting, enabling the translation of complex
environmental data into actionable knowledge essential for cognitive robotic
control. We evaluated our approach by converting procedural 3D environments
into USD format, which is then annotated semantically and translated into a
knowledge graph to effectively answer competency questions, demonstrating its
utility for real-time robotic decision-making. Additionally, we developed a
web-based visualization tool to support the semantic mapping process, providing
users with an intuitive interface to manage the 3D environment.

</details>


### [149] [The Developments and Challenges towards Dexterous and Embodied Robotic Manipulation: A Survey](https://arxiv.org/abs/2507.11840)
*Gaofeng Li,Ruize Wang,Peisen Xu,Qi Ye,Jiming Chen*

Main category: cs.RO

TL;DR: This survey covers the progress of robotic manipulation, from mechanical programming to embodied intelligence and from simple grippers to dexterous hands. It focuses on current advances in data collection and skill learning, and identifies key challenges in the field.


<details>
  <summary>Details</summary>
Motivation: Achieving human-like dexterous robotic manipulation is a central goal and a pivotal challenge in robotics, with AI enabling rapid progress.

Method: This survey summarizes the evolution of robotic manipulation from mechanical programming to embodied intelligence, focusing on the transition from simple grippers to multi-fingered dexterous hands. It highlights recent advances in dexterous manipulation data collection (simulation, human demonstrations, teleoperation) and skill-learning frameworks (imitation, reinforcement learning), and discusses three key challenges.

Result: The survey outlines key characteristics and main challenges in robotic manipulation, highlights recent advances in data collection and skill-learning frameworks, and summarizes and discusses three key challenges restricting the development of dexterous robotic manipulation.

Conclusion: The survey summarizes the evolution of robotic manipulation, focusing on current advances in data collection and skill-learning frameworks for dexterous manipulation, while also outlining key challenges.

Abstract: Achieving human-like dexterous robotic manipulation remains a central goal
and a pivotal challenge in robotics. The development of Artificial Intelligence
(AI) has allowed rapid progress in robotic manipulation. This survey summarizes
the evolution of robotic manipulation from mechanical programming to embodied
intelligence, alongside the transition from simple grippers to multi-fingered
dexterous hands, outlining key characteristics and main challenges. Focusing on
the current stage of embodied dexterous manipulation, we highlight recent
advances in two critical areas: dexterous manipulation data collection (via
simulation, human demonstrations, and teleoperation) and skill-learning
frameworks (imitation and reinforcement learning). Then, based on the overview
of the existing data collection paradigm and learning framework, three key
challenges restricting the development of dexterous robotic manipulation are
summarized and discussed.

</details>


### [150] [Towards Autonomous Riding: A Review of Perception, Planning, and Control in Intelligent Two-Wheelers](https://arxiv.org/abs/2507.11852)
*Mohammed Hassanin,Mohammad Abu Alsheikh,Carlos C. N. Kuhn,Damith Herath,Dinh Thai Hoang,Ibrahim Radwan*

Main category: cs.RO

TL;DR: 对自动骑行 (AR) 技术进行了综述，重点介绍了其在城市交通中的应用。审查强调了 AR 相对于自动驾驶 (AD) 的独特挑战，并确定了研究中的差距，同时提出了多模态传感和边缘深度学习等未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 由于电动踏板车和电动自行车等两轮车辆的快速普及，对可靠的自动骑行 (AR) 技术产生了迫切需求。然而，与成熟的自动驾驶 (AD) 系统相比，AR 由于两轮平台的固有不稳定性、尺寸和功率限制以及不可预测的环境，带来了独特的挑战，并对道路使用者的安全构成了严重威胁。

Method: 本文系统地审查了自动骑行 (AR) 系统的核心组成部分，包括感知、规划和控制，并借鉴了自动驾驶 (AD) 技术。

Result: 审查确定了当前 AR 研究中的关键差距，包括缺乏全面的 AR 感知系统、行业和政府支持有限，以及研究界关注不足。此外，它还从 AD 的角度分析了 AR 的差距，强调了多模态传感器技术和边缘深度学习架构等有前景的研究方向。

Conclusion: 该综述旨在通过整合自动驾驶研究的见解和自动骑行 (AR) 的具体要求，加速未来城市交通中安全、高效和可扩展的自动骑行系统的发展。

Abstract: The rapid adoption of micromobility solutions, particularly two-wheeled
vehicles like e-scooters and e-bikes, has created an urgent need for reliable
autonomous riding (AR) technologies. While autonomous driving (AD) systems have
matured significantly, AR presents unique challenges due to the inherent
instability of two-wheeled platforms, limited size, limited power, and
unpredictable environments, which pose very serious concerns about road users'
safety. This review provides a comprehensive analysis of AR systems by
systematically examining their core components, perception, planning, and
control, through the lens of AD technologies. We identify critical gaps in
current AR research, including a lack of comprehensive perception systems for
various AR tasks, limited industry and government support for such
developments, and insufficient attention from the research community. The
review analyses the gaps of AR from the perspective of AD to highlight
promising research directions, such as multimodal sensor techniques for
lightweight platforms and edge deep learning architectures. By synthesising
insights from AD research with the specific requirements of AR, this review
aims to accelerate the development of safe, efficient, and scalable autonomous
riding systems for future urban mobility.

</details>


### [151] [A Fast Method for Planning All Optimal Homotopic Configurations for Tethered Robots and Its Extended Applications](https://arxiv.org/abs/2507.11880)
*Jinyuan Liu,Minglei Fu,Ling Shi,Chenguang Yang,Wenan Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种名为CDT-TCS的新型算法，用于解决有绳机器人在运动规划中面临的线束长度限制和缠绕问题。该算法结合了代数拓扑和几何优化，能够高效地计算出机器人的最优可行配置。在此基础上，还开发了三个具体的应用算法，并在仿真和实际实验中证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 有绳机器人在灾难响应和地下探索等环境中具有优势，但其运动规划受到线束长度限制和缠绕风险的严重制约。

Method:  CDT-TCS算法利用CDT编码作为同伦不变量来表示路径的拓扑状态，结合代数拓扑和几何优化，能够一次性计算出二维环境中所有位置的有绳机器人的最优可行配置集。在此基础上，提出了CDT-TPP（最优有绳路径规划）、CDT-TMV（考虑线束约束的多目标访问）和CDT-UTPP（无绳机器人最优距离路径规划）三个特定应用算法。

Result: 所提出的算法在各自的问题领域显著优于现有技术，并在机器人平台上进行了实际验证。

Conclusion:  CDT-TCS算法及其衍生算法在有绳机器人路径规划、多目标访问和无绳机器人路径规划方面取得了显著的成果，并在仿真和实际实验中证明了其优越性。

Abstract: Tethered robots play a pivotal role in specialized environments such as
disaster response and underground exploration, where their stable power supply
and reliable communication offer unparalleled advantages. However, their motion
planning is severely constrained by tether length limitations and entanglement
risks, posing significant challenges to achieving optimal path planning. To
address these challenges, this study introduces CDT-TCS (Convex Dissection
Topology-based Tethered Configuration Search), a novel algorithm that leverages
CDT Encoding as a homotopy invariant to represent topological states of paths.
By integrating algebraic topology with geometric optimization, CDT-TCS
efficiently computes the complete set of optimal feasible configurations for
tethered robots at all positions in 2D environments through a single
computation. Building on this foundation, we further propose three
application-specific algorithms: i) CDT-TPP for optimal tethered path planning,
ii) CDT-TMV for multi-goal visiting with tether constraints, iii) CDT-UTPP for
distance-optimal path planning of untethered robots. All theoretical results
and propositions underlying these algorithms are rigorously proven and
thoroughly discussed in this paper. Extensive simulations demonstrate that the
proposed algorithms significantly outperform state-of-the-art methods in their
respective problem domains. Furthermore, real-world experiments on robotic
platforms validate the practicality and engineering value of the proposed
framework.

</details>


### [152] [Fast and Scalable Game-Theoretic Trajectory Planning with Intentional Uncertainties](https://arxiv.org/abs/2507.12174)
*Zhenmin Huang,Yusen Xie,Benshan Ma,Shaojie Shen,Jun Ma*

Main category: cs.RO

TL;DR: 提出了一种新颖的博弈论交互式轨迹规划方法，通过将智能体交互建模为贝叶斯博弈并利用ADMM算法，有效解决了意图不确定性问题，提高了效率和可扩展性，实现了实时规划。


<details>
  <summary>Details</summary>
Motivation: 现有的博弈论方法在处理智能体意图不确定性方面存在计算负担重、效率低和可扩展性差的问题，而多智能体交互轨迹规划是机器人领域的一个长期挑战。

Method: 提出了一种新颖的博弈论交互式轨迹规划方法，将具有意图不确定性的智能体交互建模为一般贝叶斯博弈，并证明其在特定假设下的等价形式为势博弈。通过优化统一的优化问题来获得最优交互轨迹的贝叶斯纳什均衡。此外，提出了一种基于对偶共识交替方向乘子法（ADMM）的分布式算法，用于并行求解问题，以提高可扩展性。

Result: 仿真和实验结果表明，所提出的方法在多种具有一般形式意图不确定性的场景下均有效，并且其可扩展性优于现有的集中式和分布式基线方法。

Conclusion: 该方法能够有效处理具有一般形式意图不确定性的多智能体交互轨迹规划问题，并且具有良好的可扩展性，能够实现不确定博弈场景下的实时交互式轨迹规划。

Abstract: Trajectory planning involving multi-agent interactions has been a
long-standing challenge in the field of robotics, primarily burdened by the
inherent yet intricate interactions among agents. While game-theoretic methods
are widely acknowledged for their effectiveness in managing multi-agent
interactions, significant impediments persist when it comes to accommodating
the intentional uncertainties of agents. In the context of intentional
uncertainties, the heavy computational burdens associated with existing
game-theoretic methods are induced, leading to inefficiencies and poor
scalability. In this paper, we propose a novel game-theoretic interactive
trajectory planning method to effectively address the intentional uncertainties
of agents, and it demonstrates both high efficiency and enhanced scalability.
As the underpinning basis, we model the interactions between agents under
intentional uncertainties as a general Bayesian game, and we show that its
agent-form equivalence can be represented as a potential game under certain
minor assumptions. The existence and attainability of the optimal interactive
trajectories are illustrated, as the corresponding Bayesian Nash equilibrium
can be attained by optimizing a unified optimization problem. Additionally, we
present a distributed algorithm based on the dual consensus alternating
direction method of multipliers (ADMM) tailored to the parallel solving of the
problem, thereby significantly improving the scalability. The attendant
outcomes from simulations and experiments demonstrate that the proposed method
is effective across a range of scenarios characterized by general forms of
intentional uncertainties. Its scalability surpasses that of existing
centralized and decentralized baselines, allowing for real-time interactive
trajectory planning in uncertain game settings.

</details>


### [153] [NemeSys: An Online Underwater Explorer with Goal-Driven Adaptive Autonomy](https://arxiv.org/abs/2507.11889)
*Adnan Abdullah,Alankrit Gupta,Vaishnav Ramesh,Shivali Patel,Md Jahidul Islam*

Main category: cs.RO

TL;DR: NemeSys AUV系统通过浮标利用光学和磁电信号实现低带宽通信，可在水下实时重构任务，提高适应性和响应能力。


<details>
  <summary>Details</summary>
Motivation: 当前AUV平台在GPS拒止、通信受限的海 marine环境中，大多执行静态、预编程任务，或依赖系绳连接和高延迟声学信道进行中途任务更新，这严重限制了它们的适应性和响应能力。

Method: 提出了一种名为NemeSys的新型AUV系统，该系统利用浮标进行紧凑的光学和磁电（OME）信号传输，实现了实时任务重构。该系统包括完整的系统设计、控制架构和语义任务编码框架，支持通过低带宽通信进行交互式探索和任务适应。

Result: 通过分析模型、受控实验评估和开阔水域试验验证了NemeSys系统的可行性，结果证实了在线任务适应和语义任务更新的可能性。

Conclusion: NemeSys是一个支持通过浮标进行实时任务重构的AUV系统，通过紧凑的光学和磁电（OME）信号传输，实现了低带宽通信下的交互式探索和任务适应性，验证了在线AUV平台在动态和不确定水下环境中实现目标驱动的自适应自主性的可行性。

Abstract: Adaptive mission control and dynamic parameter reconfiguration are essential
for autonomous underwater vehicles (AUVs) operating in GPS-denied,
communication-limited marine environments. However, most current AUV platforms
execute static, pre-programmed missions or rely on tethered connections and
high-latency acoustic channels for mid-mission updates, significantly limiting
their adaptability and responsiveness. In this paper, we introduce NemeSys, a
novel AUV system designed to support real-time mission reconfiguration through
compact optical and magnetoelectric (OME) signaling facilitated by floating
buoys. We present the full system design, control architecture, and a semantic
mission encoding framework that enables interactive exploration and task
adaptation via low-bandwidth communication. The proposed system is validated
through analytical modeling, controlled experimental evaluations, and
open-water trials. Results confirm the feasibility of online mission adaptation
and semantic task updates, highlighting NemeSys as an online AUV platform for
goal-driven adaptive autonomy in dynamic and uncertain underwater environments.

</details>


### [154] [Hybrid Conformal Prediction-based Risk-Aware Model Predictive Planning in Dense, Uncertain Environments](https://arxiv.org/abs/2507.11920)
*Jeongyong Yang,KwangBin Lee,SooJean Han*

Main category: cs.RO

TL;DR: HyPRAP 是一种新的路径规划框架，它结合了多种预测模型和风险评估方法，以在复杂的动态环境中实现高效和安全的导航。


<details>
  <summary>Details</summary>
Motivation: 实时路径规划在密集且充满不确定性的环境中是一个挑战，因为预测大量动态障碍物的未来运动在计算上既繁重又不切实际。

Method: 提出了一种名为 HyPRAP 的混合预测风险感知路径规划框架，结合了多种预测模型来预测局部障碍物的运动，并引入了基于预测的碰撞风险指数（P-CRI）来评估风险，实现了对高风险障碍物的重点关注和对低风险障碍物的简化处理。同时，通过混合共形预测实现了不确定性量化。

Result: HyPRAP 框架能够有效平衡安全性和计算效率，并且在模拟中表现优于单一预测器方法，P-CRI 指数也优于传统的基于邻近度的风险评估方法。

Conclusion: HyPRAP框架通过混合预测模型和 P-CRI 指数，在保持安全性的同时有效平衡了计算效率，特别适用于障碍物密集的动态环境。

Abstract: Real-time path planning in dense, uncertain environments remains a
challenging problem, as predicting the future motions of numerous dynamic
obstacles is computationally burdensome and unrealistic. To address this, we
introduce Hybrid Prediction-based Risk-Aware Planning (HyPRAP), a
prediction-based risk-aware path-planning framework which uses a hybrid
combination of models to predict local obstacle movement. HyPRAP uses a novel
Prediction-based Collision Risk Index (P-CRI) to evaluate the risk posed by
each obstacle, enabling the selective use of predictors based on whether the
agent prioritizes high predictive accuracy or low computational prediction
overhead. This selective routing enables the agent to focus on high-risk
obstacles while ignoring or simplifying low-risk ones, making it suitable for
environments with a large number of obstacles. Moreover, HyPRAP incorporates
uncertainty quantification through hybrid conformal prediction by deriving
confidence bounds simultaneously achieved by multiple predictions across
different models. Theoretical analysis demonstrates that HyPRAP effectively
balances safety and computational efficiency by leveraging the diversity of
prediction models. Extensive simulations validate these insights for more
general settings, confirming that HyPRAP performs better compared to single
predictor methods, and P-CRI performs better over naive proximity-based risk
assessment.

</details>


### [155] [A Multi-Level Similarity Approach for Single-View Object Grasping: Matching, Planning, and Fine-Tuning](https://arxiv.org/abs/2507.11938)
*Hao Chen,Takuya Kiyokawa,Zhengtao Hu,Weiwei Wan,Kensuke Harada*

Main category: cs.RO

TL;DR: Grasping unknown objects from a single view is hard due to partial observations. Existing methods are sensitive to noise. This paper proposes a new method using similarity matching: find similar known objects in a database, imitate their grasps, and fine-tune. It uses multiple features (semantic, geometric, dimensional) and a new descriptor (C-FPFH) for better matching, especially with noisy, partial data. Large language models and a new registration method also help.


<details>
  <summary>Details</summary>
Motivation: Traditional learning-based grasping approaches face limitations in performance robustness due to sensitivity to sensing noise and environmental changes. This paper aims to address this bottleneck by introducing a new perspective of similarity matching to achieve highly generalized grasping of unknown objects from a single view, overcoming the uncertainty caused by partial observations.

Method: The paper proposes a novel method for grasping unknown objects from a single view based on similarity matching. It involves three steps: 1) identifying candidate objects with high similarity using visual features and a database; 2) planning grasps for the unknown object based on the candidate models' pre-existing grasping knowledge; 3) optimizing grasp quality via local fine-tuning. A multi-level similarity matching framework integrating semantic, geometric, and dimensional features is introduced to handle uncertainty. A new point cloud geometric descriptor, C-FPFH, is proposed for accurate similarity assessment between partial and complete point clouds. Large language models, semi-oriented bounding boxes, and a novel plane detection-based point cloud registration approach are also incorporated to enhance matching accuracy.

Result: The method robustly achieves unknown-object grasping from a single viewpoint. It utilizes visual features for similarity matching with a database, plans imitative grasps using candidate models, and optimizes grasp quality through local fine-tuning. The multi-level similarity matching framework and the novel C-FPFH descriptor improve accuracy under single-view conditions, enhanced further by LLMs and a new registration approach.

Conclusion: The proposed similarity matching method robustly achieves unknown-object grasping from a single viewpoint by leveraging visual features for similarity matching with a database, planning imitative grasps using candidate models, and optimizing grasp quality through local fine-tuning. The multi-level similarity matching framework integrates semantic, geometric, and dimensional features, and a novel C-FPFH descriptor enhances assessment between partial and complete point clouds. LLMs, semi-oriented bounding boxes, and a novel point cloud registration approach further improve matching accuracy.

Abstract: Grasping unknown objects from a single view has remained a challenging topic
in robotics due to the uncertainty of partial observation. Recent advances in
large-scale models have led to benchmark solutions such as GraspNet-1Billion.
However, such learning-based approaches still face a critical limitation in
performance robustness for their sensitivity to sensing noise and environmental
changes. To address this bottleneck in achieving highly generalized grasping,
we abandon the traditional learning framework and introduce a new perspective:
similarity matching, where similar known objects are utilized to guide the
grasping of unknown target objects. We newly propose a method that robustly
achieves unknown-object grasping from a single viewpoint through three key
steps: 1) Leverage the visual features of the observed object to perform
similarity matching with an existing database containing various object models,
identifying potential candidates with high similarity; 2) Use the candidate
models with pre-existing grasping knowledge to plan imitative grasps for the
unknown target object; 3) Optimize the grasp quality through a local
fine-tuning process. To address the uncertainty caused by partial and noisy
observation, we propose a multi-level similarity matching framework that
integrates semantic, geometric, and dimensional features for comprehensive
evaluation. Especially, we introduce a novel point cloud geometric descriptor,
the C-FPFH descriptor, which facilitates accurate similarity assessment between
partial point clouds of observed objects and complete point clouds of database
models. In addition, we incorporate the use of large language models, introduce
the semi-oriented bounding box, and develop a novel point cloud registration
approach based on plane detection to enhance matching accuracy under
single-view conditions. Videos are available at https://youtu.be/qQDIELMhQmk.

</details>


### [156] [IANN-MPPI: Interaction-Aware Neural Network-Enhanced Model Predictive Path Integral Approach for Autonomous Driving](https://arxiv.org/abs/2507.11940)
*Kanghyun Ryu,Minjun Sung,Piyush Gupta,Jovin D'sa,Faizan M. Tariq,David Isele,Sangjae Bae*

Main category: cs.RO

TL;DR: A new control method, IANN-MPPI, allows autonomous vehicles to plan trajectories interactively by predicting how other vehicles react to the AV's potential actions, leading to more efficient maneuvers in dense traffic.


<details>
  <summary>Details</summary>
Motivation: Autonomous vehicles (AVs) in dense traffic exhibit overly conservative behavior due to limited ability to anticipate and respond to interactive behavior of surrounding agents. Traditional methods overlook agents adapting their behavior in response to AV actions.

Method: The proposed method is Interaction-Aware Neural Network-Enhanced Model Predictive Path Integral (IANN-MPPI) control, which incorporates a spline-based prior for the MPPI sampling distribution to enhance lane-changing behavior. It addresses limitations of traditional methods by predicting interactive behavior, unlike non-interactive predictions.

Result: IANN-MPPI was evaluated in a dense traffic merging scenario, demonstrating its ability to perform efficient merging maneuvers.

Conclusion: IANN-MPPI enables interactive trajectory planning by predicting surrounding agents' reactions to control sequences, improving performance in dense traffic merging scenarios and allowing efficient merging maneuvers.

Abstract: Motion planning for autonomous vehicles (AVs) in dense traffic is
challenging, often leading to overly conservative behavior and unmet planning
objectives. This challenge stems from the AVs' limited ability to anticipate
and respond to the interactive behavior of surrounding agents. Traditional
decoupled prediction and planning pipelines rely on non-interactive predictions
that overlook the fact that agents often adapt their behavior in response to
the AV's actions. To address this, we propose Interaction-Aware Neural
Network-Enhanced Model Predictive Path Integral (IANN-MPPI) control, which
enables interactive trajectory planning by predicting how surrounding agents
may react to each control sequence sampled by MPPI. To improve performance in
structured lane environments, we introduce a spline-based prior for the MPPI
sampling distribution, enabling efficient lane-changing behavior. We evaluate
IANN-MPPI in a dense traffic merging scenario, demonstrating its ability to
perform efficient merging maneuvers. Our project website is available at
https://sites.google.com/berkeley.edu/iann-mppi

</details>


### [157] [A Review of Generative AI in Aquaculture: Foundations, Applications, and Future Directions for Smart and Sustainable Farming](https://arxiv.org/abs/2507.11974)
*Waseem Akram,Muhayy Ud Din,Lyes Saad Soud,Irfan Hussain*

Main category: cs.RO

TL;DR: GAI正成为水产养殖业发展的关键驱动力，能够通过整合多模态数据来优化决策和运营，尽管仍存在数据可用性、实时性能、可解释性和监管不确定性等挑战。


<details>
  <summary>Details</summary>
Motivation: 随着水产养殖业向数据驱动、自动化和数字化集成运营（水产养殖4.0）的范式转变，GAI模型为行业发展提供了新的机遇。

Method: 本综述全面综合了GAI在水产养殖领域的应用，涵盖了基础架构、实验系统、试点部署和实际用例，并提出了一个跨越感知、控制、优化、通信和监管合规的应用分类。

Result: GAI在实现水下感知、数字孪生建模和自主规划（如ROV任务）方面发挥着日益重要的作用。

Conclusion: GAI是水产养殖业向智能化、适应性决策发展的关键推动者，它能够整合多模态数据，并在环境监测、机器人技术、疾病诊断、基础设施规划、报告和市场分析等领域提供新的机遇。

Abstract: Generative Artificial Intelligence (GAI) has rapidly emerged as a
transformative force in aquaculture, enabling intelligent synthesis of
multimodal data, including text, images, audio, and simulation outputs for
smarter, more adaptive decision-making. As the aquaculture industry shifts
toward data-driven, automation and digital integration operations under the
Aquaculture 4.0 paradigm, GAI models offer novel opportunities across
environmental monitoring, robotics, disease diagnostics, infrastructure
planning, reporting, and market analysis. This review presents the first
comprehensive synthesis of GAI applications in aquaculture, encompassing
foundational architectures (e.g., diffusion models, transformers, and retrieval
augmented generation), experimental systems, pilot deployments, and real-world
use cases. We highlight GAI's growing role in enabling underwater perception,
digital twin modeling, and autonomous planning for remotely operated vehicle
(ROV) missions. We also provide an updated application taxonomy that spans
sensing, control, optimization, communication, and regulatory compliance.
Beyond technical capabilities, we analyze key limitations, including limited
data availability, real-time performance constraints, trust and explainability,
environmental costs, and regulatory uncertainty. This review positions GAI not
merely as a tool but as a critical enabler of smart, resilient, and
environmentally aligned aquaculture systems.

</details>


### [158] [Robust Planning for Autonomous Vehicles with Diffusion-Based Failure Samplers](https://arxiv.org/abs/2507.11991)
*Juanran Wang,Marc R. Schlichting,Mykel J. Kochenderfer*

Main category: cs.RO

TL;DR: 本研究利用深度生成模型（去噪扩散概率模型和生成对抗网络）来提高自动驾驶汽车在十字路口的安全性，通过生成和利用碰撞诱因的传感器噪声序列来构建更优的规划器，并在模拟中取得了更好的效果。


<details>
  <summary>Details</summary>
Motivation: 高风险交通区域（如十字路口）是造成碰撞的主要原因，本研究旨在利用深度生成模型提高自动驾驶汽车在十字路口环境下的安全性。

Method: 本研究利用深度生成模型，具体为1000步去噪扩散概率模型，以生成自动驾驶汽车在四向十字路口导航时，基于入侵者相对位置和速度的碰撞诱因传感器噪声序列。之后，利用生成对抗网络架构将1000步模型提炼为单步去噪扩散模型，以实现快速推理并保持采样质量。

Result: 与基线智能驾驶模型控制器相比，本研究提出的稳健规划器通过模拟实验证明了其显著更低的失败率和延迟率。

Conclusion: 深度生成模型可以提高自动驾驶汽车在十字路口等高风险交通区域的安全性，通过生成碰撞诱因的传感器噪声序列，并可以将其提炼为单步模型以实现快速推理，从而为自动驾驶汽车构建稳健的规划器。

Abstract: High-risk traffic zones such as intersections are a major cause of
collisions. This study leverages deep generative models to enhance the safety
of autonomous vehicles in an intersection context. We train a 1000-step
denoising diffusion probabilistic model to generate collision-causing sensor
noise sequences for an autonomous vehicle navigating a four-way intersection
based on the current relative position and velocity of an intruder. Using the
generative adversarial architecture, the 1000-step model is distilled into a
single-step denoising diffusion model which demonstrates fast inference speed
while maintaining similar sampling quality. We demonstrate one possible
application of the single-step model in building a robust planner for the
autonomous vehicle. The planner uses the single-step model to efficiently
sample potential failure cases based on the currently measured traffic state to
inform its decision-making. Through simulation experiments, the robust planner
demonstrates significantly lower failure rate and delay rate compared with the
baseline Intelligent Driver Model controller.

</details>


### [159] [Robust Route Planning for Sidewalk Delivery Robots](https://arxiv.org/abs/2507.12067)
*Xing Tong,Michele D. Simoni*

Main category: cs.RO

TL;DR: 人行道配送机器人的出行时间因行人、障碍物和路况而异。本研究通过优化和模拟，提出并评估了预算、椭圆和支持向量聚类（SVC）等鲁棒路径规划方法。结果表明，椭圆和DRSP方法在各种条件下均优于传统方法，尤其是在机器人较宽、较慢或在恶劣天气和高拥挤环境下运行时。


<details>
  <summary>Details</summary>
Motivation: 人行道配送机器人是城市货运分销的有前途的解决方案，与卡车相比可减少拥堵，并为无人机提供更安全、更高的容量替代方案。然而，由于行人密度、障碍物和基础设施条件变化而导致的人行道出行时间不可靠，可能会严重影响其效率。本研究解决了人行道机器人鲁棒路径规划问题，明确考虑了由于人行道条件变化而导致的时间不确定性。

Method: 本研究整合了优化和模拟，以重现障碍物和行人流量的影响并生成真实的出行时间。研究了三种不同的方法来推导不确定性集，包括预算、椭圆和支持向量聚类（SVC）方法，以及一种分布鲁棒方法来解决最短路径（SP）问题。

Result: 研究结果表明，与传统的单路径（SP）相比，鲁棒路径规划在不同的路况下显著提高了运营可靠性。椭圆和分布鲁棒路径（DRSP）方法表现最佳，在平均和最差情况延迟方面产生了最高效的路径。敏感性分析表明，与传统SP相比，鲁棒方法始终表现更好，特别是对于更宽、更慢、导航行为更保守的路边配送机器人。在恶劣天气和高行人拥挤情况下，这些优势更为明显。

Conclusion: 在各种机器人设计和环境条件下，与传统的单路径（SP）相比，鲁棒路径规划在不同的路况下显著提高了运营可靠性。在考虑的各种方法中，椭圆和分布鲁棒路径（DRSP）方法表现最佳，在平均和最差情况延迟方面产生了最高效的路径。敏感性分析表明，与传统SP相比，鲁棒方法始终表现更好，特别是对于更宽、更慢、导航行为更保守的路边配送机器人。在恶劣天气和高行人拥挤情况下，这些优势更为明显。

Abstract: Sidewalk delivery robots are a promising solution for urban freight
distribution, reducing congestion compared to trucks and providing a safer,
higher-capacity alternative to drones. However, unreliable travel times on
sidewalks due to pedestrian density, obstacles, and varying infrastructure
conditions can significantly affect their efficiency. This study addresses the
robust route planning problem for sidewalk robots, explicitly accounting for
travel time uncertainty due to varying sidewalk conditions. Optimization is
integrated with simulation to reproduce the effect of obstacles and pedestrian
flows and generate realistic travel times. The study investigates three
different approaches to derive uncertainty sets, including budgeted,
ellipsoidal, and support vector clustering (SVC)-based methods, along with a
distributionally robust method to solve the shortest path (SP) problem. A
realistic case study reproducing pedestrian patterns in Stockholm's city center
is used to evaluate the efficiency of robust routing across various robot
designs and environmental conditions. The results show that, when compared to a
conventional SP, robust routing significantly enhances operational reliability
under variable sidewalk conditions. The Ellipsoidal and DRSP approaches
outperform the other methods, yielding the most efficient paths in terms of
average and worst-case delay. Sensitivity analyses reveal that robust
approaches consistently outperform the conventional SP, particularly for
sidewalk delivery robots that are wider, slower, and have more conservative
navigation behaviors. These benefits are even more pronounced in adverse
weather conditions and high pedestrian congestion scenarios.

</details>


### [160] [Tree-SLAM: semantic object SLAM for efficient mapping of individual trees in orchards](https://arxiv.org/abs/2507.12093)
*David Rapado-Rincon,Gert Kootstra*

Main category: cs.RO

TL;DR: Tree-SLAM是一种用于果园的语义SLAM方法，通过检测和重识别树干作为路标，解决了GPS信号差和环境重复性问题，实现了高精度的树木地图绘制。


<details>
  <summary>Details</summary>
Motivation: 在果园等密集树冠下，GPS信号常常不可靠，给精确绘制单棵树木带来挑战。同时，标准的SLAM方法会因为树木外观的重复性而产生混淆，导致建图错误。因此，需要一种专门针对果园环境的SLAM方法来解决这些问题。

Method: Tree-SLAM是一种语义SLAM方法，利用RGB-D图像进行树木映射。它首先使用实例分割模型检测树干，然后通过级联图的数据关联算法估计树干位置并进行重识别。重识别的树干被用作因子图框架中的路标，该框架整合了GPS信号、里程计和树干观测数据。

Result: Tree-SLAM生成的单棵树木地图具有高达18厘米的地理定位误差，这一误差小于种植距离的20%。该方法在不同季节的苹果和梨园的多种数据集上都得到了验证，证明了其在高精度建图和在GPS信号不可靠情况下的鲁棒性。

Conclusion: Tree-SLAM利用RGB-D图像，通过实例分割模型检测树干，并使用基于级联图的数据关联算法进行定位和重新识别。该方法将重新识别的树干作为路标，结合了有噪声的GPS信号、里程计和树干观测信息，在一个因子图框架内进行SLAM，实现了低至18厘米的树木地图地理定位误差，优于20%的种植距离。该方法在不同季节的苹果和梨园的多种数据集上进行了验证，证明了其在高精度建图和在GPS信号不可靠情况下的鲁棒性。

Abstract: Accurate mapping of individual trees is an important component for precision
agriculture in orchards, as it allows autonomous robots to perform tasks like
targeted operations or individual tree monitoring. However, creating these maps
is challenging because GPS signals are often unreliable under dense tree
canopies. Furthermore, standard Simultaneous Localization and Mapping (SLAM)
approaches struggle in orchards because the repetitive appearance of trees can
confuse the system, leading to mapping errors. To address this, we introduce
Tree-SLAM, a semantic SLAM approach tailored for creating maps of individual
trees in orchards. Utilizing RGB-D images, our method detects tree trunks with
an instance segmentation model, estimates their location and re-identifies them
using a cascade-graph-based data association algorithm. These re-identified
trunks serve as landmarks in a factor graph framework that integrates noisy GPS
signals, odometry, and trunk observations. The system produces maps of
individual trees with a geo-localization error as low as 18 cm, which is less
than 20\% of the planting distance. The proposed method was validated on
diverse datasets from apple and pear orchards across different seasons,
demonstrating high mapping accuracy and robustness in scenarios with unreliable
GPS signals.

</details>


### [161] [Leveraging Sidewalk Robots for Walkability-Related Analyses](https://arxiv.org/abs/2507.12148)
*Xing Tong,Michele D. Simoni,Kaj Munhoz Arfvidsson,Jonas Mårtensson*

Main category: cs.RO

TL;DR: 本研究提出一种利用街道配送机器人作为移动数据收集平台来评估步行的方法，以克服传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的步行数据收集方法成本高昂且难以扩展，而街道配送机器人可以作为移动数据收集平台，以可扩展、自动化和实时的方式捕获步行相关特征。

Method: 利用配备传感器的机器人在斯德哥尔摩KTH的街道网络上进行部署，完成了101次行程，覆盖了900个路段，收集了街道级别的步行相关特征数据。

Result: 机器人速度与行人行为密切相关，可以作为评估行人动态的代理。行人的移动模式受到街道特征的显著影响，高密度、较窄和不平整的街道会导致行人移动轨迹变慢和变异。

Conclusion: 该框架能够持续监测街道状况和行人行为，有助于创建更宜行、包容和响应迅速的城市环境。

Abstract: Walkability is a key component of sustainable urban development, while
collecting detailed data on its related features remains challenging due to the
high costs and limited scalability of traditional methods. Sidewalk delivery
robots, increasingly deployed in urban environments, offer a promising solution
to these limitations. This paper explores how these robots can serve as mobile
data collection platforms, capturing sidewalk-level features related to
walkability in a scalable, automated, and real-time manner. A sensor-equipped
robot was deployed on a sidewalk network at KTH in Stockholm, completing 101
trips covering 900 segments. From the collected data, different typologies of
features are derived, including robot trip characteristics (e.g., speed,
duration), sidewalk conditions (e.g., width, surface unevenness), and sidewalk
utilization (e.g., pedestrian density). Their walkability-related implications
were investigated with a series of analyses. The results demonstrate that
pedestrian movement patterns are strongly influenced by sidewalk
characteristics, with higher density, reduced width, and surface irregularity
associated with slower and more variable trajectories. Notably, robot speed
closely mirrors pedestrian behavior, highlighting its potential as a proxy for
assessing pedestrian dynamics. The proposed framework enables continuous
monitoring of sidewalk conditions and pedestrian behavior, contributing to the
development of more walkable, inclusive, and responsive urban environments.

</details>


### [162] [Probabilistic Safety Verification for an Autonomous Ground Vehicle: A Situation Coverage Grid Approach](https://arxiv.org/abs/2507.12158)
*Nawshin Mannan Proma,Gricel Vázquez,Sepeedeh Shahbeigi,Arjun Badyal,Victoria Hodge*

Main category: cs.RO

TL;DR: 本研究提出了一种新的自动驾驶汽车安全验证方法，通过情况覆盖网格、概率建模和模型检查来识别高风险情况并提供安全保证。


<details>
  <summary>Details</summary>
Motivation: 随着工业自主地面车辆日益部署在安全关键环境中，确保其在各种条件下的安全运行至关重要。

Method: 本研究提出了一种基于系统性情况提取、概率建模和验证的新型安全验证方法。研究基于情况覆盖网格的概念，详尽枚举了与车辆运行相关的环境配置。该网格通过基于情况的系统测试收集的定量概率数据进行增强，捕获了情况之间的概率转换。研究然后生成了一个概率模型，该模型编码了正常和不安全系统行为的动态。通过针对该模型的概率模型检查来验证从危险分析中提取并以时序逻辑形式化的安全属性。

Result: 结果表明，该方法能够有效识别高风险情况，提供定量的安全保证，并支持满足监管标准的要求，从而为自动驾驶系统的可靠部署做出贡献。

Conclusion: 该方法可有效识别高风险情况，提供定量安全保证，并支持符合监管标准，从而促进自动驾驶系统的稳健部署。

Abstract: As industrial autonomous ground vehicles are increasingly deployed in
safety-critical environments, ensuring their safe operation under diverse
conditions is paramount. This paper presents a novel approach for their safety
verification based on systematic situation extraction, probabilistic modelling
and verification. We build upon the concept of a situation coverage grid, which
exhaustively enumerates environmental configurations relevant to the vehicle's
operation. This grid is augmented with quantitative probabilistic data
collected from situation-based system testing, capturing probabilistic
transitions between situations. We then generate a probabilistic model that
encodes the dynamics of both normal and unsafe system behaviour. Safety
properties extracted from hazard analysis and formalised in temporal logic are
verified through probabilistic model checking against this model. The results
demonstrate that our approach effectively identifies high-risk situations,
provides quantitative safety guarantees, and supports compliance with
regulatory standards, thereby contributing to the robust deployment of
autonomous systems.

</details>


### [163] [UniLGL: Learning Uniform Place Recognition for FOV-limited/Panoramic LiDAR Global Localization](https://arxiv.org/abs/2507.12194)
*Hongming Shen,Xun Chen,Yulin Hui,Zhenyu Wu,Wei Wang,Qiyang Lyu,Tianchen Deng,Danwei Wang*

Main category: cs.RO

TL;DR: 提出了一种名为UniLGL的统一大地激光雷达（LGL）方法，该方法通过编码几何和材质信息、融合多BEV图像以及引入视点不变性假设，实现了空间、材质和传感器类型的均匀性，并在各种真实场景和平台中得到了验证，验证了其鲁棒性和广泛适用性。


<details>
  <summary>Details</summary>
Motivation: 现有的大地激光雷达（LGL）方法通常只考虑激光雷达观测的部分信息（例如几何特征），或者仅适用于同类激光雷达传感器，忽略了LGL的统一性问题。本研究旨在提出一种统一的LGL方法，同时实现空间、材质和传感器类型的均匀性。

Method: UniLGL方法通过将包含几何和材质信息的点云编码为一对BEV图像（空间BEV图像和强度BEV图像），并设计了一个端到端的融合网络来提取均匀特征，从而实现空间和材质的均匀性。为了实现传感器类型均匀性，该方法引入了视点不变性假设，取代了传统的平移等变性假设，并在全局描述符和局部特征表示上监督UniLGL。最后，通过2D BEV图像上的局部特征与点云之间的映射关系，推导出一个鲁棒的全局姿态估计器，用于在SE(3)上确定全局姿态的全局最小值，无需额外的配准。

Result: 实验结果表明，UniLGL在真实世界环境中表现优于其他最先进的LGL方法，并成功应用于卡车和微型飞行器等不同平台，实现了高精度定位建图和多MAV协同探索，证明了其在工业和现场场景中的应用潜力。

Conclusion: 该研究提出的UniLGL方法在真实世界环境中通过广泛的基准测试，在空间和材质均匀性以及传感器类型均匀性方面表现出色，与现有的最先进的LGL方法相比具有竞争力。此外，UniLGL已成功部署在不同平台（如卡车和微型飞行器），实现了高精度定位建图和多MAV协同探索，证明了其在工业和现场场景中的广泛适用性。

Abstract: Existing LGL methods typically consider only partial information (e.g.,
geometric features) from LiDAR observations or are designed for homogeneous
LiDAR sensors, overlooking the uniformity in LGL. In this work, a uniform LGL
method is proposed, termed UniLGL, which simultaneously achieves spatial and
material uniformity, as well as sensor-type uniformity. The key idea of the
proposed method is to encode the complete point cloud, which contains both
geometric and material information, into a pair of BEV images (i.e., a spatial
BEV image and an intensity BEV image). An end-to-end multi-BEV fusion network
is designed to extract uniform features, equipping UniLGL with spatial and
material uniformity. To ensure robust LGL across heterogeneous LiDAR sensors, a
viewpoint invariance hypothesis is introduced, which replaces the conventional
translation equivariance assumption commonly used in existing LPR networks and
supervises UniLGL to achieve sensor-type uniformity in both global descriptors
and local feature representations. Finally, based on the mapping between local
features on the 2D BEV image and the point cloud, a robust global pose
estimator is derived that determines the global minimum of the global pose on
SE(3) without requiring additional registration. To validate the effectiveness
of the proposed uniform LGL, extensive benchmarks are conducted in real-world
environments, and the results show that the proposed UniLGL is demonstratively
competitive compared to other State-of-the-Art LGL methods. Furthermore, UniLGL
has been deployed on diverse platforms, including full-size trucks and agile
Micro Aerial Vehicles (MAVs), to enable high-precision localization and mapping
as well as multi-MAV collaborative exploration in port and forest environments,
demonstrating the applicability of UniLGL in industrial and field scenarios.

</details>


### [164] [Next-Gen Museum Guides: Autonomous Navigation and Visitor Interaction with an Agentic Robot](https://arxiv.org/abs/2507.12273)
*Luca Garello,Francesca Cocchella,Alessandra Sciutti,Manuel Catalano,Francesco Rea*

Main category: cs.RO

TL;DR: Alter-Ego 机器人通过 LLM 和 SLAM 技术为博物馆访客提供互动导览，在真实环境中受到好评，但理解和响应能力有待改进。


<details>
  <summary>Details</summary>
Motivation: 为了探索和提升公共场所（特别是文化和教育场所）的用户体验，特别是利用自主机器人。

Method: 设计、实现并评估了 Alter-Ego 机器人，它结合了大型语言模型（LLMs）以实现实时、情境感知的问答交互，并利用同步定位与地图构建（SLAM）技术进行无缝导航和路线自适应。在真实博物馆环境中对 34 名参与者进行了测试，结合了访客-机器人对话的定性分析和交互前后问卷的定量分析。

Result: 机器人总体上受到好评，并为博物馆体验增添了趣味性，但其在理解和响应方面存在局限性。该研究揭示了文化场所人机交互（HRI）的现状，强调了人工智能驱动的机器人在支持可达性和知识获取方面的潜力，以及在复杂现实环境中部署此类技术的局限性和挑战。

Conclusion: 本研究阐述了在文化和教育场所部署人工智能驱动的自主机器人（如 Alter-Ego 博物馆导览机器人）的潜力与挑战。结果表明，该机器人能提供引人入胜的博物馆体验，但其理解和响应能力仍有待提高。

Abstract: Autonomous robots are increasingly being tested into public spaces to enhance
user experiences, particularly in cultural and educational settings. This paper
presents the design, implementation, and evaluation of the autonomous museum
guide robot Alter-Ego equipped with advanced navigation and interactive
capabilities. The robot leverages state-of-the-art Large Language Models (LLMs)
to provide real-time, context aware question-and-answer (Q&A) interactions,
allowing visitors to engage in conversations about exhibits. It also employs
robust simultaneous localization and mapping (SLAM) techniques, enabling
seamless navigation through museum spaces and route adaptation based on user
requests. The system was tested in a real museum environment with 34
participants, combining qualitative analysis of visitor-robot conversations and
quantitative analysis of pre and post interaction surveys. Results showed that
the robot was generally well-received and contributed to an engaging museum
experience, despite some limitations in comprehension and responsiveness. This
study sheds light on HRI in cultural spaces, highlighting not only the
potential of AI-driven robotics to support accessibility and knowledge
acquisition, but also the current limitations and challenges of deploying such
technologies in complex, real-world environments.

</details>


### [165] [Assessing the Value of Visual Input: A Benchmark of Multimodal Large Language Models for Robotic Path Planning](https://arxiv.org/abs/2507.12391)
*Jacinto Colan,Ana Davila,Yasuhisa Hasegawa*

Main category: cs.RO

TL;DR: LLMs可用于机器人路径规划，但当前模型在处理复杂环境时能力有限。视觉输入有一定帮助，但并非总是比文本提示更优。


<details>
  <summary>Details</summary>
Motivation: 评估视觉输入对多模态LLM在机器人路径规划任务中的效用。

Method: 通过评估15种多模态LLMs在2D网格环境中生成路径的能力，比较了仅文本输入与文本加视觉输入在不同模型大小和网格复杂度下的表现。

Result: 在简单的、小规模的网格环境中，视觉输入或少样本文本提示能带来一定好处，成功率中等。然而，在较大的网格环境中，模型性能显著下降，表明存在可扩展性问题。总体而言，更大的模型通常能获得更高的平均成功率，但视觉模态并未比结构良好的文本提示显示出普遍优势。在简单网格上找到的成功路径质量普遍较高。

Conclusion: LLMs在机器人路径规划中具有潜力，但目前在处理复杂环境和大规模任务时存在可扩展性挑战。视觉输入对提升模型性能有一定帮助，但并非总是优于精心设计的文本提示。未来的研究应关注LLMs的空间推理、约束满足和多模态集成能力。

Abstract: Large Language Models (LLMs) show potential for enhancing robotic path
planning. This paper assesses visual input's utility for multimodal LLMs in
such tasks via a comprehensive benchmark. We evaluated 15 multimodal LLMs on
generating valid and optimal paths in 2D grid environments, simulating
simplified robotic planning, comparing text-only versus text-plus-visual inputs
across varying model sizes and grid complexities. Our results indicate moderate
success rates on simpler small grids, where visual input or few-shot text
prompting offered some benefits. However, performance significantly degraded on
larger grids, highlighting a scalability challenge. While larger models
generally achieved higher average success, the visual modality was not
universally dominant over well-structured text for these multimodal systems,
and successful paths on simpler grids were generally of high quality. These
results indicate current limitations in robust spatial reasoning, constraint
adherence, and scalable multimodal integration, identifying areas for future
LLM development in robotic path planning.

</details>


### [166] [Regrasp Maps for Sequential Manipulation Planning](https://arxiv.org/abs/2507.12407)
*Svetlana Levit,Marc Toussaint*

Main category: cs.RO

TL;DR: This paper presents a method to speed up TAMP solvers for regrasp manipulation by using a regrasp map to guide the search and handle mode switches and object placements.


<details>
  <summary>Details</summary>
Motivation: We consider manipulation problems in constrained and cluttered settings, which require several regrasps at unknown locations.

Method: We propose to inform an optimization-based task and motion planning (TAMP) solver with possible regrasp areas and grasp sequences to speed up the search. Our main idea is to use a state space abstraction, a regrasp map, capturing the combinations of available grasps in different parts of the configuration space, and allowing us to provide the solver with guesses for the mode switches and additional constraints for the object placements.

Result: Our method is able to provide a robust search method for challenging regrasp manipulation problems.

Conclusion: We propose a robust search method for challenging regrasp manipulation problems by interleaving the creation of regrasp maps, their adaptation based on failed refinements, and solving TAMP (sub)problems.

Abstract: We consider manipulation problems in constrained and cluttered settings,
which require several regrasps at unknown locations. We propose to inform an
optimization-based task and motion planning (TAMP) solver with possible regrasp
areas and grasp sequences to speed up the search. Our main idea is to use a
state space abstraction, a regrasp map, capturing the combinations of available
grasps in different parts of the configuration space, and allowing us to
provide the solver with guesses for the mode switches and additional
constraints for the object placements. By interleaving the creation of regrasp
maps, their adaptation based on failed refinements, and solving TAMP
(sub)problems, we are able to provide a robust search method for challenging
regrasp manipulation problems.

</details>


### [167] [Design and Development of an Automated Contact Angle Tester (ACAT) for Surface Wettability Measurement](https://arxiv.org/abs/2507.12431)
*Connor Burgess,Kyle Douin,Amir Kordijazi*

Main category: cs.RO

TL;DR: ACAT是一种全集成的机器人工作单元，用于自动化3D打印材料的表面润湿性测量。


<details>
  <summary>Details</summary>
Motivation: ACAT是为了解决手动接触角测试的局限性而设计的，旨在实现3D打印材料表面润湿性测量的自动化，提高测试的精度、可重复性和安全性。

Method: ACAT系统结合了可编程机器人技术、精确的液体分配以及模块化的软件-硬件架构，包括电气系统、基于Raspberry Pi和Python的软件控制系统以及包含3轴笛卡尔机器人、气动驱动和精密液体分配器的机械系统。

Result: ACAT能够实现高通量的自动化表面表征，并为未来集成到智能制造和材料发现工作流程中提供了稳健的平台。

Conclusion: ACAT是一个高通量、自动化的表面表征系统，为未来集成到智能制造和材料发现工作流程中提供了稳健的平台。

Abstract: The Automated Contact Angle Tester (ACAT) is a fully integrated robotic work
cell developed to automate the measurement of surface wettability on 3D-printed
materials. Designed for precision, repeatability, and safety, ACAT addresses
the limitations of manual contact angle testing by combining programmable
robotics, precise liquid dispensing, and a modular software-hardware
architecture. The system is composed of three core subsystems: (1) an
electrical system including power, control, and safety circuits compliant with
industrial standards such as NEC 70, NFPA 79, and UL 508A; (2) a software
control system based on a Raspberry Pi and Python, featuring fault detection,
GPIO logic, and operator interfaces; and (3) a mechanical system that includes
a 3-axis Cartesian robot, pneumatic actuation, and a precision liquid dispenser
enclosed within a safety-certified frame. The ACAT enables high-throughput,
automated surface characterization and provides a robust platform for future
integration into smart manufacturing and materials discovery workflows. This
paper details the design methodology, implementation strategies, and system
integration required to develop the ACAT platform.

</details>


### [168] [EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos](https://arxiv.org/abs/2507.12440)
*Ruihan Yang,Qinxi Yu,Yecheng Wu,Rui Yan,Borui Li,An-Chieh Cheng,Xueyan Zou,Yunhao Fang,Hongxu Yin,Sifei Liu,Song Han,Yao Lu,Xiaolong Wang*

Main category: cs.RO

TL;DR: EgoVLA利用大规模人类视频数据训练机器人进行操作，并通过逆运动学和重定向技术转换动作，在仿真环境中取得了优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决真实机器人数据收集的规模限制问题，本研究探索使用大规模、丰富场景和任务的人类视频来训练视觉-语言-动作（VLA）模型，以改进机器人操作能力。

Method: EgoVLA模型通过预测人类手腕和手部动作，并利用逆运动学和重定向技术将人类动作转换为机器人动作。该模型在 Isaac Humanoid Manipulation Benchmark 上进行了微调和评估，并在各种双臂操作任务中展现了优越性能。

Result: EgoVLA在Isaac Humanoid Manipulation Benchmark基准测试中，相比现有方法取得了显著的性能提升，并验证了使用人类视频数据进行训练的有效性。

Conclusion: 通过使用人类视频进行训练，EgoVLA在机器人操作任务中取得了显著的改进，并证明了人类数据在机器人学习中的重要性。

Abstract: Real robot data collection for imitation learning has led to significant
advancements in robotic manipulation. However, the requirement for robot
hardware in the process fundamentally constrains the scale of the data. In this
paper, we explore training Vision-Language-Action (VLA) models using egocentric
human videos. The benefit of using human videos is not only for their scale but
more importantly for the richness of scenes and tasks. With a VLA trained on
human video that predicts human wrist and hand actions, we can perform Inverse
Kinematics and retargeting to convert the human actions to robot actions. We
fine-tune the model using a few robot manipulation demonstrations to obtain the
robot policy, namely EgoVLA. We propose a simulation benchmark called Isaac
Humanoid Manipulation Benchmark, where we design diverse bimanual manipulation
tasks with demonstrations. We fine-tune and evaluate EgoVLA with Isaac Humanoid
Manipulation Benchmark and show significant improvements over baselines and
ablate the importance of human data. Videos can be found on our website:
https://rchalyang.github.io/EgoVLA

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [169] [A Study on the Application of Artificial Intelligence in Ecological Design](https://arxiv.org/abs/2507.11595)
*Hengyue Zhao*

Main category: cs.AI

TL;DR: 本篇论文研究了AI在生态设计中的应用，探讨了AI如何帮助建立人与自然的相互依存关系，并通过案例研究展示了AI在数据分析、生态恢复等方面的潜力，并提出了结合AI和植物修复的设计思路。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索AI是否能够促进人与自然关系的转变，从人类主导转向相互依存，并考察AI在其中扮演的媒介角色。

Method: 通过案例研究，分析了艺术家和设计师如何运用AI进行数据分析、图像识别和生态恢复，并提出了将强化学习与植物修复相结合的设计路径。

Result: 研究表明，AI不仅扩展了创意方法，还重塑了生态设计的理论与实践，能够链接科学见解、艺术实践和环境管理，为未来可持续的、技术支持的生态系统研究提供了方向。

Conclusion: 该研究探讨了人工智能（AI）在促进人类与自然关系的转变中，从人类主导转向相互依存的可能性，并展示了AI在生态设计领域的应用潜力。

Abstract: This paper asks whether our relationship with nature can move from human
dominance to genuine interdependence, and whether artificial intelligence (AI)
can mediate that shift. We examine a new ecological-design paradigm in which AI
interacts with non-human life forms. Through case studies we show how artists
and designers apply AI for data analysis, image recognition, and ecological
restoration, producing results that differ from conventional media. We argue
that AI not only expands creative methods but also reframes the theory and
practice of ecological design. Building on the author's prototype for
AI-assisted water remediation, the study proposes design pathways that couple
reinforcement learning with plant-based phytoremediation. The findings
highlight AI's potential to link scientific insight, artistic practice, and
environmental stewardship, offering a roadmap for future research on
sustainable, technology-enabled ecosystems.

</details>


### [170] [General Modular Harness for LLM Agents in Multi-Turn Gaming Environments](https://arxiv.org/abs/2507.11633)
*Yuxuan Zhang,Haoyang Yu,Lanxiang Hu,Haojian Jin,Hao Zhang*

Main category: cs.AI

TL;DR: A modular harness for LLM agents (perception, memory, reasoning) improves performance in diverse games without special engineering. It helps analyze module impact, showing memory is key for long puzzles and perception for noisy games.


<details>
  <summary>Details</summary>
Motivation: To create a unified workflow for analyzing how different modules (perception, memory, reasoning) affect the performance of LLM/VLM agents across diverse, dynamic, interactive settings, particularly in multi-turn gaming environments, without requiring domain-specific engineering.

Method: A modular harness design for LLM agents is introduced, composed of perception, memory, and reasoning components. This harness allows a single LLM or VLM backbone to address various multi-turn gaming environments. The framework facilitates analysis of module performance using classic and modern game suites as testbeds.

Result: Extensive experiments show the harness consistently improves gameplay performance over unharnessed baselines. Specific findings include memory's dominance in long-horizon puzzles and perception's criticality in vision-noisy arcades, highlighting the distinct contribution patterns of each module.

Conclusion: The modular harness design effectively advances general-purpose agents by enabling a single LLM or VLM backbone to handle diverse gaming environments without domain-specific engineering. The framework allows for analysis of individual module contributions, showing that memory is crucial for long-horizon tasks and perception for visually noisy ones.

Abstract: We introduce a modular harness design for LLM agents that composes of
perception, memory, and reasoning components, enabling a single LLM or VLM
backbone to tackle a wide spectrum of multi turn gaming environments without
domain-specific engineering. Using classic and modern game suites as
low-barrier, high-diversity testbeds, our framework provides a unified workflow
for analyzing how each module affects performance across dynamic interactive
settings. Extensive experiments demonstrate that the harness lifts gameplay
performance consistently over un-harnessed baselines and reveals distinct
contribution patterns, for example, memory dominates in long-horizon puzzles
while perception is critical in vision noisy arcades. These findings highlight
the effectiveness of our modular harness design in advancing general-purpose
agent, given the familiarity and ubiquity of games in everyday human
experience.

</details>


### [171] [Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification](https://arxiv.org/abs/2507.11662)
*Moises Andrade,Joonhyuk Cha,Brandon Ho,Vriksha Srihari,Karmesh Yadav,Zsolt Kira*

Main category: cs.AI

TL;DR: MLLM 验证器存在“一致性偏差”问题，即倾向于偏爱上下文中的信息，即使这些信息不准确。本文提出了一种名为 SGV 的新方法，通过让 MLLM 先生成通用的先验知识，再基于这些先验知识来评估具体轨迹，成功解决了这个问题，显著提高了验证的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统的奖励函数在数学和棋盘游戏等领域取得了成功，但在没有明确成功标准（如计算机使用）的领域，将其扩展存在挑战。MLLM 因其世界知识、人类偏好对齐和推理能力而成为有希望的解决方案，但存在一致性偏差问题。

Method: 提出了一种名为“自我接地验证”（Self-Grounded Verification, SGV）的新方法。SGV 通过两个步骤来利用 MLLM 的知识和推理能力：1. 检索与评估数据无关的、关于任务完成的广泛先验知识。2. 在自我生成的先验知识的条件下，对候选轨迹进行推理和评估。

Result: SGV 方法提高了 MLLM 验证器的准确性和故障检测率，最高可提高 20 个百分点。该方法能够对异构代理进行实时监督，提高了 GUI 专家在 OSWorld 中的任务完成率、扩散策略在 robomimic 中的表现，以及 ReAct 代理在 VisualWebArena 中的表现，并在该基准测试中创下新的最先进记录，超越了之前的最佳记录 48%。

Conclusion: MLLM 验证器存在一致性偏差，会偏爱上下文窗口中的信息，即使这些信息并不理想。SGV 方法通过利用 MLLM 的采样机制来解决此问题，提高了准确性和故障检测率，并在各项任务中取得了新的进展。

Abstract: Verifiers -- functions assigning rewards to agent behavior -- have been key
for AI progress in domains like math and board games. However, extending these
gains to domains without clear-cut success criteria (e.g.,computer use) remains
a challenge: while humans can recognize suitable outcomes, translating this
intuition into scalable rules is non-trivial. Multimodal Large Language
Models(MLLMs) emerge as a promising solution, given their world knowledge,
human-preference alignment, and reasoning skills. We evaluate MLLMs as
verifiers of agent trajectories across web navigation, computer use, and
robotic manipulation, and identify a critical limitation: agreement bias, a
strong tendency for MLLMs to favor information in their context window, often
generating chains of thought to rationalize flawed behavior. This bias is
pervasive across models, resilient to test-time scaling, and can impact several
methods using MLLMs as evaluators (e.g.,data filtering). Notably, it occurs
despite MLLMs showing strong, human-aligned priors on desired behavior. To
address this, we propose Self-Grounded Verification (SGV), a lightweight method
that enables more effective use of MLLMs' knowledge and reasoning by harnessing
their own sampling mechanisms via unconditional and conditional generation. SGV
operates in two steps: first, the MLLM is elicited to retrieve broad priors
about task completion, independent of the data under evaluation. Then,
conditioned on self-generated priors, it reasons over and evaluates a candidate
trajectory. Enhanced with SGV, MLLM verifiers show gains of up to 20 points in
accuracy and failure detection rates, and can perform real-time supervision of
heterogeneous agents, boosting task completion of a GUI specialist in OSWorld,
a diffusion policy in robomimic, and a ReAct agent in VisualWebArena -- setting
a new state of the art on the benchmark, surpassing the previous best by 48%.

</details>


### [172] [ClarifAI: Enhancing AI Interpretability and Transparency through Case-Based Reasoning and Ontology-Driven Approach for Improved Decision-Making](https://arxiv.org/abs/2507.11733)
*Srikanth Vemula*

Main category: cs.AI

TL;DR: ClarifAI通过结合案例推理和本体来提高AI的可解释性和透明度，以满足利益相关者的需求，并可用于高风险环境。


<details>
  <summary>Details</summary>
Motivation: 为了提高AI在改进决策制定方面的透明度和可解释性，本研究引入了ClarifAI。

Method: 利用案例推理（CBR）方法并整合面向本体的方法，ClarifAI旨在满足AI驱动的应用程序中各种利益相关者的复杂解释需求。

Result: ClarifAI结合了CBR和本体，提供了详尽的解释机制，增强了跨不同部门和高风险环境的AI可解释性。

Conclusion: 该研究展示了ClarifAI在提高AI系统可解释性方面的潜力，为在关键决策过程中部署AI铺平了道路。

Abstract: This Study introduces Clarity and Reasoning Interface for Artificial
Intelligence(ClarifAI), a novel approach designed to augment the transparency
and interpretability of artificial intelligence (AI) in the realm of improved
decision making. Leveraging the Case-Based Reasoning (CBR) methodology and
integrating an ontology-driven approach, ClarifAI aims to meet the intricate
explanatory demands of various stakeholders involved in AI-powered
applications. The paper elaborates on ClarifAI's theoretical foundations,
combining CBR and ontologies to furnish exhaustive explanation mechanisms. It
further elaborates on the design principles and architectural blueprint,
highlighting ClarifAI's potential to enhance AI interpretability across
different sectors and its applicability in high-stake environments. This
research delineates the significant role of ClariAI in advancing the
interpretability of AI systems, paving the way for its deployment in critical
decision-making processes.

</details>


### [173] [Auto-Formulating Dynamic Programming Problems with Large Language Models](https://arxiv.org/abs/2507.11737)
*Chenyu Zhou,Jingyuan Yang,Linwei Xin,Yitian Chen,Ziyan He,Dongdong Ge*

Main category: cs.AI

TL;DR: LLM在自动构建动态规划（DP）模型方面潜力巨大，但DP问题的特性带来了挑战。本文提出了DP-Bench基准和DPLM模型，并通过DualReflect数据生成管道解决了这些问题，实现了与SOTA LLM相当甚至更优的性能，并揭示了数据生成策略的权衡。


<details>
  <summary>Details</summary>
Motivation: 传统的DP模型构建需要专家知识，LLM有潜力自动化此过程，但DP问题的随机转移和有限的训练数据给直接应用LLM带来了挑战。因此，需要专门的基准和方法来评估和改进LLM在DP问题上的表现。

Method: DP-Bench作为第一个涵盖教科书级别DP问题的基准，用于系统评估。DPLM是一个7B参数的专用模型，其核心是DualReflect合成数据生成管道，该管道结合了前向生成（增加多样性）和后向生成（保证可靠性）来扩展训练数据。

Result: DP-Bench的评估结果表明，DPLM的性能可与OpenAI的o1和DeepSeek-R1等SOTA LLM相媲美，并在难题上超越它们。研究发现，向后生成在低数据量时因其强正确性保证而更受青睐，而向前生成在大规模时通过引入多样化表述变得更有价值，两者结合使用至关重要。

Conclusion: DP-Bench和DPLM的引入为DP模型自动构建提供了基准和方法。DPLM通过DualReflect合成数据生成管道，在低数据量情况下优先考虑向后生成以保证正确性，在大数据量情况下则结合向前生成以增加多样性，从而在DP问题上达到与SOTA LLM相当甚至更优的性能。

Abstract: Dynamic programming (DP) is a fundamental method in operations research, but
formulating DP models has traditionally required expert knowledge of both the
problem context and DP techniques. Large Language Models (LLMs) offer the
potential to automate this process. However, DP problems pose unique challenges
due to their inherently stochastic transitions and the limited availability of
training data. These factors make it difficult to directly apply existing
LLM-based models or frameworks developed for other optimization problems, such
as linear or integer programming. We introduce DP-Bench, the first benchmark
covering a wide range of textbook-level DP problems to enable systematic
evaluation. We present Dynamic Programming Language Model (DPLM), a
7B-parameter specialized model that achieves performance comparable to
state-of-the-art LLMs like OpenAI's o1 and DeepSeek-R1, and surpasses them on
hard problems. Central to DPLM's effectiveness is DualReflect, our novel
synthetic data generation pipeline, designed to scale up training data from a
limited set of initial examples. DualReflect combines forward generation for
diversity and backward generation for reliability. Our results reveal a key
insight: backward generation is favored in low-data regimes for its strong
correctness guarantees, while forward generation, though lacking such
guarantees, becomes increasingly valuable at scale for introducing diverse
formulations. This trade-off highlights the complementary strengths of both
approaches and the importance of combining them.

</details>


### [174] [BuildEvo: Designing Building Energy Consumption Forecasting Heuristics via LLM-driven Evolution](https://arxiv.org/abs/2507.12207)
*Subin Lin,Chuanbo Hua*

Main category: cs.AI

TL;DR: BuildEvo是一个利用大型语言模型和进化过程来自动化设计建筑能源预测启发式方法的新框架，它整合了物理原理，提高了预测的准确性、泛化能力和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统的启发式方法精度不足，而先进的模型可能不透明且难以推广，忽略了物理原理。因此，需要一种能够设计出既有效又可解释，并考虑物理原理的预测模型。

Method: BuildEvo框架利用大型语言模型（LLMs）在一个进化过程中自动设计和优化建筑能源预测的启发式方法，该过程系统地融入了建筑特征和运行数据的物理见解。

Result: BuildEvo在基准测试中取得了最先进的性能，提高了模型的泛化能力，并提供了透明的预测逻辑。

Conclusion: BuildEvo通过结合LLM和进化过程，实现了自动化设计有效的、可解释的、并融入了物理洞察的建筑能源预测启发式方法，在基准测试中达到了最先进的性能，并提高了泛化能力和预测逻辑的透明度。

Abstract: Accurate building energy forecasting is essential, yet traditional heuristics
often lack precision, while advanced models can be opaque and struggle with
generalization by neglecting physical principles. This paper introduces
BuildEvo, a novel framework that uses Large Language Models (LLMs) to
automatically design effective and interpretable energy prediction heuristics.
Within an evolutionary process, BuildEvo guides LLMs to construct and enhance
heuristics by systematically incorporating physical insights from building
characteristics and operational data (e.g., from the Building Data Genome
Project 2). Evaluations show BuildEvo achieves state-of-the-art performance on
benchmarks, offering improved generalization and transparent prediction logic.
This work advances the automated design of robust, physically grounded
heuristics, promoting trustworthy models for complex energy systems.

</details>


### [175] [Survey of Swarm Intelligence Approaches to Search Documents Based On Semantic Similarity](https://arxiv.org/abs/2507.11787)
*Chandrashekar Muniyappa,Eunjin Kim*

Main category: cs.AI

TL;DR: 本文调查了 Swarm Intelligence 算法在语义相似性文档搜索中的最新进展，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: Swarm Intelligence (SI) 作为一种模拟自然界生物群体行为的人工智能方法，在解决现实世界问题方面显示出强大的能力，尤其在计算机优化问题中得到了广泛应用。本文旨在深入探讨 SI 算法在文档搜索领域的最新发展，并为该领域的研究提供指导。

Method: 本文通过调研和分析最新的 Swarm Intelligence 算法在基于语义相似性的文档搜索中的应用，总结了当前的研究进展，并对未来的研究方向进行了展望。

Result: 本次调查回顾了 Swarm Intelligence 算法在基于语义相似性的文档搜索中的最新发展，并提出了未来的研究方向。

Conclusion: Swarm Intelligence (SI) 算法在基于语义相似性的文档搜索领域展现出巨大潜力，未来的研究应着重于算法的效率、可扩展性以及在具体应用场景中的表现。

Abstract: Swarm Intelligence (SI) is gaining a lot of popularity in artificial
intelligence, where the natural behavior of animals and insects is observed and
translated into computer algorithms called swarm computing to solve real-world
problems. Due to their effectiveness, they are applied in solving various
computer optimization problems. This survey will review all the latest
developments in Searching for documents based on semantic similarity using
Swarm Intelligence algorithms and recommend future research directions.

</details>


### [176] [A Parallel CPU-GPU Framework for Cost-Bounded DFS with Applications to IDA* and BTS](https://arxiv.org/abs/2507.11916)
*Ehsan Futuhi,Nathan R. Sturtevant*

Main category: cs.AI

TL;DR: 提出了一种利用CPU和GPU并行性的成本受限深度优先搜索（CB-DFS）方法，并提出了Batch IDA*和Batch BTS等算法，在魔方和滑动拼图上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了利用GPU的并行处理能力来增强经典的搜索算法，特别是深度优先搜索。

Method: 提出了一种用于深度优先搜索（DFS）的批量GPU计算方法，称为成本受限深度优先搜索（CB-DFS），并提出了利用此方法的算法，如Batch IDA*和Batch BTS。

Result: GPU操作可以有效地批量处理DFS，并且在3x3魔方和4x4滑动拼图（STP）上进行了评估，还分析了超参数、神经网络启发式大小和硬件资源对性能的影响。

Conclusion: GPU操作可以有效地批量处理DFS，并且我们在3x3魔方和4x4滑动拼图（STP）上评估了CB-DFS方法，证明了其有效性。

Abstract: The rapid advancement of GPU technology has unlocked powerful parallel
processing capabilities, creating new opportunities to enhance classic search
algorithms. A recent successful application of GPUs is in compressing large
pattern database (PDB) heuristics using neural networks while preserving
heuristic admissibility. However, very few algorithms have been designed to
exploit GPUs during search. Several variants of A* exist that batch GPU
computations. In this paper we introduce a method for batching GPU computations
in depth first search. In particular, we describe a new cost-bounded
depth-first search (CB-DFS) method that leverages the combined parallelism of
modern CPUs and GPUs. This is used to create algorithms like \emph{Batch IDA*},
an extension of the Iterative Deepening A* (IDA*) algorithm, or Batch BTS, an
extensions of Budgeted Tree Search. Our approach builds on the general approach
used by Asynchronous Parallel IDA* (AIDA*), while maintaining optimality
guarantees. We evaluate the approach on the 3x3 Rubik's Cube and 4x4 sliding
tile puzzle (STP), showing that GPU operations can be efficiently batched in
DFS. Additionally, we conduct extensive experiments to analyze the effects of
hyperparameters, neural network heuristic size, and hardware resources on
performance.

</details>


### [177] [Aime: Towards Fully-Autonomous Multi-Agent Framework](https://arxiv.org/abs/2507.11988)
*Yexuan Shi,Mingyu Wang,Yunxiang Cao,Hongjie Lai,Junjian Lan,Xin Han,Yu Wang,Jie Geng,Zhenan Li,Zihao Xia,Xiang Chen,Chen Li,Jian Xu,Wenbo Duan,Yuanshuo Zhu*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Multi-Agent Systems (MAS) powered by Large Language Models (LLMs) are
emerging as a powerful paradigm for solving complex, multifaceted problems.
However, the potential of these systems is often constrained by the prevalent
plan-and-execute framework, which suffers from critical limitations: rigid plan
execution, static agent capabilities, and inefficient communication. These
weaknesses hinder their adaptability and robustness in dynamic environments.
This paper introduces Aime, a novel multi-agent framework designed to overcome
these challenges through dynamic, reactive planning and execution. Aime
replaces the conventional static workflow with a fluid and adaptive
architecture. Its core innovations include: (1) a Dynamic Planner that
continuously refines the overall strategy based on real-time execution
feedback; (2) an Actor Factory that implements Dynamic Actor instantiation,
assembling specialized agents on-demand with tailored tools and knowledge; and
(3) a centralized Progress Management Module that serves as a single source of
truth for coherent, system-wide state awareness. We empirically evaluated Aime
on a diverse suite of benchmarks spanning general reasoning (GAIA), software
engineering (SWE-bench Verified), and live web navigation (WebVoyager). The
results demonstrate that Aime consistently outperforms even highly specialized
state-of-the-art agents in their respective domains. Its superior adaptability
and task success rate establish Aime as a more resilient and effective
foundation for multi-agent collaboration.

</details>


### [178] [Understanding visual attention beehind bee-inspired UAV navigation](https://arxiv.org/abs/2507.11992)
*Pranav Rajbhandari,Abhi Veda,Matthew Garratt,Mandayam Srinivasan,Sridhar Ravi*

Main category: cs.AI

TL;DR: 本研究利用强化学习和视流信息，成功训练无人机在复杂环境中进行导航，其方法和结果类似于飞行昆虫的行为，并为无人机控制律的开发提供了新的思路。


<details>
  <summary>Details</summary>
Motivation: 由于生物系统在飞行和避障方面具有出色的能力，尽管其感知和计算能力有限，因此在自主无人机导航领域广泛应用了受生物启发的 设计。特别是，蜜蜂主要利用其视觉场中物体的视流（视运动）来导航拥挤的环境。

Method: 本研究采用强化学习方法，仅使用视流作为传感输入，训练无人机在充满障碍物的隧道中进行导航，并通过分析训练所得智能体的注意力模式，探究其对视流的哪些区域进行重点关注以做出运动决策。

Result: 研究发现，智能体主要关注视流不连续和视流大的区域。这些训练好的智能体通过避开产生大视流的障碍物并在环境中保持居中位置来导航，这与飞行昆虫的行为相似。这种模式在独立训练的智能体中普遍存在，表明这可能是一种开发物理无人机的简单显式控制律的有效策略。

Conclusion: 该研究表明，基于视流的强化学习方法可以有效地训练无人机在复杂环境中导航，并且所提出的方法具有良好的泛化性和鲁棒性，可为开发简单的显式控制律提供参考。

Abstract: Bio-inspired design is often used in autonomous UAV navigation due to the
capacity of biological systems for flight and obstacle avoidance despite
limited sensory and computational capabilities. In particular, honeybees mainly
use the sensory input of optic flow, the apparent motion of objects in their
visual field, to navigate cluttered environments. In our work, we train a
Reinforcement Learning agent to navigate a tunnel with obstacles using only
optic flow as sensory input. We inspect the attention patterns of trained
agents to determine the regions of optic flow on which they primarily base
their motor decisions. We find that agents trained in this way pay most
attention to regions of discontinuity in optic flow, as well as regions with
large optic flow magnitude. The trained agents appear to navigate a cluttered
tunnel by avoiding the obstacles that produce large optic flow, while
maintaining a centered position in their environment, which resembles the
behavior seen in flying insects. This pattern persists across independently
trained agents, which suggests that this could be a good strategy for
developing a simple explicit control law for physical UAVs.

</details>


### [179] [Topology Enhanced MARL for Multi-Vehicle Cooperative Decision-Making of CAVs](https://arxiv.org/abs/2507.12110)
*Ye Han,Lijun Zhang,Dejian Meng,Zhuang Zhang*

Main category: cs.AI

TL;DR: TPE-MARL 通过构建博弈拓扑张量和融合访问计数与互信息，有效解决了多智能体强化学习中的探索-开发难题，提升了自动驾驶汽车在混合交通中的决策性能。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体强化学习（MARL）中固有的探索-开发权衡问题，特别是在交通流等复杂场景下，智能体数量的增加导致联合状态-动作空间呈指数级增长，使得优化更加困难。

Method: 提出了一种拓扑增强的多智能体强化学习（TPE-MARL）方法，该方法构建了一个动态交通流博弈拓扑张量，用于压缩高维交通状态信息并缩小搜索空间。在此基础上，利用 QMIX 作为基础强化学习算法，并结合访问计数和智能体互信息，构建了拓扑增强的多智能体强化学习框架。

Result: TPE-MARL 在不同交通密度和自动驾驶汽车渗透率下进行了广泛的模拟评估，结果表明该方法在训练动态、探索模式、宏观交通性能指标和微观车辆行为方面均表现出色，成功实现了探索与开发的平衡，并在交通效率、安全、决策平滑度和任务完成度方面取得了优越性能。

Conclusion: TPE-MARL 算法成功平衡了探索与开发，在交通效率、安全、决策平滑度和任务完成度方面表现出卓越的性能，其决策的合理性可与人类驾驶员媲美，甚至超越。

Abstract: The exploration-exploitation trade-off constitutes one of the fundamental
challenges in reinforcement learning (RL), which is exacerbated in multi-agent
reinforcement learning (MARL) due to the exponential growth of joint
state-action spaces. This paper proposes a topology-enhanced MARL (TPE-MARL)
method for optimizing cooperative decision-making of connected and autonomous
vehicles (CAVs) in mixed traffic. This work presents two primary contributions:
First, we construct a game topology tensor for dynamic traffic flow,
effectively compressing high-dimensional traffic state information and decrease
the search space for MARL algorithms. Second, building upon the designed game
topology tensor and using QMIX as the backbone RL algorithm, we establish a
topology-enhanced MARL framework incorporating visit counts and agent mutual
information. Extensive simulations across varying traffic densities and CAV
penetration rates demonstrate the effectiveness of TPE-MARL. Evaluations
encompassing training dynamics, exploration patterns, macroscopic traffic
performance metrics, and microscopic vehicle behaviors reveal that TPE-MARL
successfully balances exploration and exploitation. Consequently, it exhibits
superior performance in terms of traffic efficiency, safety, decision
smoothness, and task completion. Furthermore, the algorithm demonstrates
decision-making rationality comparable to or exceeding that of human drivers in
both mixed-autonomy and fully autonomous traffic scenarios. Code of our work is
available at
\href{https://github.com/leoPub/tpemarl}{https://github.com/leoPub/tpemarl}.

</details>


### [180] [Partially Observable Reference Policy Programming: Solving POMDPs Sans Numerical Optimisation](https://arxiv.org/abs/2507.12186)
*Edward Kim,Hanna Kurniawati*

Main category: cs.AI

TL;DR: PORP 是一种创新的在线 POMDP 求解器，通过深度采样和渐进式策略更新，在动态环境中提供了理论保证和优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决在线规划中的采样稀疏性问题，同时提供理论保证，将性能损失界定为采样近似误差的平均值，而不是通常的最大值。

Method: 提出了一种新颖的任意在线近似 POMDP 求解器——部分可观察参考策略编程 (PORP)，该求解器能够深入采样有意义的未来历史，同时强制执行渐进式策略更新。

Result: 经验评估证实了该算法的理论结果，并表明该求解器在动态演化环境中表现明显优于当前在线基准。

Conclusion: 该求解器在 Corsica 地区的直升机紧急情况等大规模动态演化环境问题上表现优于当前在线基准。

Abstract: This paper proposes Partially Observable Reference Policy Programming, a
novel anytime online approximate POMDP solver which samples meaningful future
histories very deeply while simultaneously forcing a gradual policy update. We
provide theoretical guarantees for the algorithm's underlying scheme which say
that the performance loss is bounded by the average of the sampling
approximation errors rather than the usual maximum, a crucial requirement given
the sampling sparsity of online planning. Empirical evaluations on two
large-scale problems with dynamically evolving environments -- including a
helicopter emergency scenario in the Corsica region requiring approximately 150
planning steps -- corroborate the theoretical results and indicate that our
solver considerably outperforms current online benchmarks.

</details>


### [181] [Xiangqi-R1: Enhancing Spatial Strategic Reasoning in LLMs for Chinese Chess via Reinforcement Learning](https://arxiv.org/abs/2507.12215)
*Yuhao Chen,Shuochen Liu,Yuanjie Lyu,Chao Zhang,Jiayao Shi,Tong Xu*

Main category: cs.AI

TL;DR: 本研究针对中国象棋这一复杂棋盘游戏，提出了一种名为Xiangqi-R1的LLM训练框架和模型，旨在提升LLM的空间策略推理能力。实验结果表明，Xiangqi-R1相比通用LLM在走法合法性和分析准确率上均有显著提升，为发展通用策略智能提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在空间策略推理方面的能力，而这对于复杂且完全可观察的棋盘游戏至关重要，尽管LLM在一般推理方面表现出色。

Method: 提出了一种针对中国象棋的训练框架，使用包含专家注释和引擎评估的五百万个棋盘-走法对的大型数据集。引入了一个7B参数模型Xiangqi-R1，该模型经过多阶段训练：(1)针对合法走法预测进行微调，(2)结合策略注释以改进决策，(3)通过具有多维度奖励信号的群体相对策略优化（GRPO）进行强化学习以增强推理稳定性。

Result: 与通用LLM相比，Xiangqi-R1在走法合法性方面提高了18%，分析准确率提高了22%。

Conclusion:  Xiangqi-R1在提高中国象棋等空间复杂领域通用策略智能方面展示了潜力，表明通用LLM在此类任务中表现不佳。

Abstract: Game playing has long served as a fundamental benchmark for evaluating
Artificial General Intelligence (AGI). While Large Language Models (LLMs) have
demonstrated impressive capabilities in general reasoning, their effectiveness
in spatial strategic reasoning, which is critical for complex and fully
observable board games, remains insufficiently explored. In this work, we adopt
Chinese Chess (Xiangqi) as a challenging and rich testbed due to its intricate
rules and spatial complexity. To advance LLMs' strategic competence in such
environments, we propose a training framework tailored to Xiangqi, built upon a
large-scale dataset of five million board-move pairs enhanced with expert
annotations and engine evaluations. Building on this foundation, we introduce
Xiangqi-R1, a 7B-parameter model trained in multi-stage manner: (1) fine-tuning
for legal move prediction to capture basic spatial rules, (2) incorporating
strategic annotations to improve decision-making, and (3) applying
reinforcement learning via Group Relative Policy Optimization (GRPO) with
multi-dimensional reward signals to enhance reasoning stability. Our
Experimental results indicate that, despite their size and power,
general-purpose LLMs struggle to achieve satisfactory performance in these
tasks. Compared to general-purpose LLMs, Xiangqi-R1 greatly advances with an
18% rise in move legality and a 22% boost in analysis accuracy. Our results
point to a promising path for creating general strategic intelligence in
spatially complex areas.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [182] [The AI Shadow War: SaaS vs. Edge Computing Architectures](https://arxiv.org/abs/2507.11545)
*Rhea Pritham Marpu,Kevin J McNamara,Preeti Gupta*

Main category: cs.DC

TL;DR: 边缘AI凭借更高的能效、更好的数据隐私和更低的延迟，正在挑战传统的云AI模型，并有望在不久的将来占据主导地位。


<details>
  <summary>Details</summary>
Motivation: AI架构在中心化云模型和去中心化边缘AI之间存在冲突

Method: 本文分析了AI架构在计算能力、能效和数据隐私方面的竞争

Result: 边缘AI在能效、数据隐私和低延迟方面优于云AI，预计市场将大幅增长，并形成混合边缘-云生态系统

Conclusion: 边缘AI通过利用测试时训练和混合专家架构等创新，在性能上挑战云系统，并拥有10,000倍的能效优势，同时通过本地处理确保数据主权，从而实现更广泛的应用和增长。

Abstract: The very DNA of AI architecture presents conflicting paths: centralized
cloud-based models (Software-as-a-Service) versus decentralized edge AI (local
processing on consumer devices). This paper analyzes the competitive
battleground across computational capability, energy efficiency, and data
privacy. Recent breakthroughs show edge AI challenging cloud systems on
performance, leveraging innovations like test-time training and
mixture-of-experts architectures. Crucially, edge AI boasts a 10,000x
efficiency advantage: modern ARM processors consume merely 100 microwatts
forinference versus 1 watt for equivalent cloud processing. Beyond efficiency,
edge AI secures data sovereignty by keeping processing local, dismantling
single points of failure in centralized architectures. This democratizes access
throughaffordable hardware, enables offline functionality, and reduces
environmental impact by eliminating data transmission costs. The edge AI market
projects explosive growth from $9 billion in 2025 to $49.6 billion by 2030
(38.5% CAGR), fueled by privacy demands and real-time analytics. Critical
applications including personalized education, healthcare monitoring,
autonomous transport, and smart infrastructure rely on edge AI's ultra-low
latency (5-10ms versus 100-500ms for cloud). The convergence of architectural
innovation with fundamental physics confirms edge AI's distributed approach
aligns with efficient information processing, signaling the inevitable
emergence of hybrid edge-cloud ecosystems.

</details>


### [183] [A Model Aware AIGC Task Offloading Algorithm in IIoT Edge Computing](https://arxiv.org/abs/2507.11560)
*Xin Wang,Xiao Huan Li,Xun Wang*

Main category: cs.DC

TL;DR: 本研究提出了一个针对IIoT边缘计算环境的AIGC任务卸载框架和MADDPG-MATO算法，以最小化延迟和能耗，实验证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 为了解决工业物联网（IIoT）环境下的AIGC任务面临的计算密集型和低延迟需求挑战，以及传统云平台难以满足实时性要求的问题，利用边缘计算分载任务以降低延迟，同时考虑AIGC模型切换带来的延迟和资源消耗。

Method: 提出了一种AIGC任务卸载框架，并设计了基于多智能体深度确定性策略梯度（MADDPG-MATO）的感知模型卸载算法，以最小化延迟和能耗。

Result: 实验结果表明，MADDPG-MATO算法的延迟平均降低6.98%，能耗平均降低7.12%，任务完成率平均提高3.72%，证明了该算法在动态、高负载的IIoT环境中的鲁棒性和效率。

Conclusion: 所提出的MADDPG-MATO算法在延迟、能耗和任务完成率方面均优于基线算法，在动态、高负载的IIoT环境中表现出稳健性和高效性。

Abstract: The integration of the Industrial Internet of Things (IIoT) with Artificial
Intelligence-Generated Content (AIGC) offers new opportunities for smart
manufacturing, but it also introduces challenges related to
computation-intensive tasks and low-latency demands. Traditional generative
models based on cloud computing are difficult to meet the real-time
requirements of AIGC tasks in IIoT environments, and edge computing can
effectively reduce latency through task offloading. However, the dynamic nature
of AIGC tasks, model switching delays, and resource constraints impose higher
demands on edge computing environments. To address these challenges, this paper
proposes an AIGC task offloading framework tailored for IIoT edge computing
environments, considering the latency and energy consumption caused by AIGC
model switching for the first time. IIoT devices acted as multi-agent
collaboratively offload their dynamic AIGC tasks to the most appropriate edge
servers deployed with different generative models. A model aware AIGC task
offloading algorithm based on Multi-Agent Deep Deterministic Policy Gradient
(MADDPG-MATO) is devised to minimize the latency and energy. Experimental
results show that MADDPG-MATO outperforms baseline algorithms, achieving an
average reduction of 6.98% in latency, 7.12% in energy consumption, and a 3.72%
increase in task completion rate across four sets of experiments with model
numbers ranging from 3 to 6, it is demonstrated that the proposed algorithm is
robust and efficient in dynamic, high-load IIoT environments.

</details>


### [184] [Environmentally-Conscious Cloud Orchestration Considering Geo-Distributed Data Centers](https://arxiv.org/abs/2507.11563)
*Giulio Attenni,Novella Bartolini*

Main category: cs.DC

TL;DR: 本研究提出了一种优化模型，用于在云环境中进行环境意识的作业部署和迁移，通过平衡多个环境因素来最小化环境影响。模拟结果表明该方法优于仅考虑单一环境因素的传统方法。


<details>
  <summary>Details</summary>
Motivation: 随着对可持续云服务的需求增长，云客户需要根据可持续性指标选择数据中心运营商，并准确报告其服务的生态足迹。本研究旨在解决云环境中作业部署和迁移的环境影响问题。

Method: 本研究提出了一种优化模型，用于平衡多个环境因素，同时尊重用户偏好，以实现环境意识的作业部署和迁移。通过分析可持续性报告，定义了包含关键可持续性指标的数据中心环境影响档案。

Result: 模拟案例研究表明，与仅优化单一可持续性因素的基线策略相比，本研究提出的方法具有潜力。

Conclusion: 本研究提出了一个理论框架，用于在云环境中进行满足环境意识的作业部署和迁移，旨在最小化资源配置对环境的影响，同时纳入可持续性要求。随着对可持续云服务的需求增长，云客户根据可持续性指标选择数据中心运营商以及准确报告其服务的生态足迹至关重要。为此，我们分析了可持续性报告，并定义了全面的数据中心环境影响档案，纳入了关键的可持续性指标。我们将此问题形式化为一个优化模型，在尊重用户偏好的同时平衡多个环境因素。模拟案例研究证明了我们方法与仅针对单一可持续性因素进行优化的基线策略相比的潜力。

Abstract: This paper presents a theoretical discussion for environmentally-conscious
job deployment and migration in cloud environments, aiming to minimize the
environmental impact of resource provisioning while incorporating
sustainability requirements. As the demand for sustainable cloud services
grows, it is crucial for cloud customers to select data center operators based
on sustainability metrics and to accurately report the ecological footprint of
their services. To this end, we analyze sustainability reports and define
comprehensive environmental impact profiles for data centers, incorporating key
sustainability indicators. We formalize the problem as an optimization model,
balancing multiple environmental factors while respecting user preferences. A
simulative case study demonstrates the {potential} of our approach compared to
baseline strategies that optimize for single sustainability factors.

</details>


### [185] [PGT-I: Scaling Spatiotemporal GNNs with Memory-Efficient Distributed Training](https://arxiv.org/abs/2507.11683)
*Seth Ockerman,Amal Gueroudji,Tanwi Mallick,Yixuan He,Line Pouchard,Robert Ross,Shivaram Venkataraman*

Main category: cs.DC

TL;DR: ST-GNNs 存在内存限制，本文提出的 PGT-I 通过分布式训练和创新的索引技术，显著降低了内存开销并提高了训练速度，首次实现了在大规模数据集上的完整训练。


<details>
  <summary>Details</summary>
Motivation: ST-GNNs 在建模时空依赖方面功能强大，但主要受限于内存，导致其应用规模受限。现有的分布式训练框架缺乏对 ST-GNNs 的支持，并且忽略了时空数据的特性。

Method: 本文提出了一种名为 PGT-I 的方法，它扩展了 PyTorch Geometric Temporal，通过集成分布式数据并行训练、索引批处理和分布式索引批处理策略。索引技术利用时空结构动态构建快照，减少内存开销，而分布式索引批处理则支持跨多个 GPU 的可扩展处理。

Result: PGT-I 实现了在不进行图划分的情况下，在整个 PeMS 数据集上训练 ST-GNNs，峰值内存使用量最多可减少 89%，并在 128 个 GPU 上实现了高达 13.1 倍的标准 DDP 加速。

Conclusion: PyTorch Geometric Temporal Index (PGT-I) 扩展了 PyTorch Geometric Temporal，通过集成分布式数据并行训练、索引批处理和分布式索引批处理，解决了 ST-GNNs 的内存限制问题。

Abstract: Spatiotemporal graph neural networks (ST-GNNs) are powerful tools for
modeling spatial and temporal data dependencies. However, their applications
have been limited primarily to small-scale datasets because of memory
constraints. While distributed training offers a solution, current frameworks
lack support for spatiotemporal models and overlook the properties of
spatiotemporal data. Informed by a scaling study on a large-scale workload, we
present PyTorch Geometric Temporal Index (PGT-I), an extension to PyTorch
Geometric Temporal that integrates distributed data parallel training and two
novel strategies: index-batching and distributed-index-batching. Our index
techniques exploit spatiotemporal structure to construct snapshots dynamically
at runtime, significantly reducing memory overhead, while
distributed-index-batching extends this approach by enabling scalable
processing across multiple GPUs. Our techniques enable the first-ever training
of an ST-GNN on the entire PeMS dataset without graph partitioning, reducing
peak memory usage by up to 89\% and achieving up to a 13.1x speedup over
standard DDP with 128 GPUs.

</details>


### [186] [Arctic Inference with Shift Parallelism: Fast and Efficient Open Source Inference System for Enterprise AI](https://arxiv.org/abs/2507.11830)
*Samyam Rajbhandari,Mert Hidayetoglu,Aurick Qiao,Ye Wang,Juncheng Yang,Jeff Rasley,Michael Wyatt,Yuxiong He*

Main category: cs.DC

TL;DR: Arctic Inference 是一个开源 vLLM 插件，通过 Shift Parallelism 等技术提高了 AI 推理的速度和效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有系统在延迟、吞吐量和成本之间进行权衡的问题。

Method: Arctic Inference 引入了Shift Parallelism，一种动态并行策略，结合了推测解码、SwiftKV 计算减少和优化的嵌入推理。

Result: 实现了高达 3.4 倍的请求完成速度，1.75 倍的生成速度，以及每 GPU 160 万个 token/秒的嵌入吞吐量，在延迟和吞吐量优化部署方面均表现出色。

Conclusion: Arctic Inference 现已开源，为企业 AI 提供最先进、最具成本效益的推理，并已集成到 Snowflake Cortex AI 中。

Abstract: Inference is now the dominant AI workload, yet existing systems force
trade-offs between latency, throughput, and cost. Arctic Inference, an
open-source vLLM plugin from Snowflake AI Research, introduces Shift
Parallelism, a dynamic parallelism strategy that adapts to real-world traffic
while integrating speculative decoding, SwiftKV compute reduction, and
optimized embedding inference. It achieves up to 3.4 times faster request
completion, 1.75 times faster generation, and 1.6M tokens/sec per GPU for
embeddings, outperforming both latency- and throughput-optimized deployments.
Already powering Snowflake Cortex AI, Arctic Inference delivers
state-of-the-art, cost-effective inference for enterprise AI and is now
available to the community.

</details>


### [187] [Performance Assessment of Load Balancing Methods in Cloud Computing: Analysis of Round Robin, Equally Spread, and Throttled Strategies Using Cloud Analyst](https://arxiv.org/abs/2507.11899)
*Saeid Aghasoleymani Najafabadi*

Main category: cs.DC

TL;DR: 在云环境中，动态负载均衡至关重要。虽然循环算法在单数据中心内略有优势，但在分布式设置中，均衡和限流算法能更好地减少响应时间并降低成本。


<details>
  <summary>Details</summary>
Motivation: 随着云环境中工作负载变得越来越动态和不可预测，需要从传统的静态方法演变到更具适应性和智能化的负载均衡策略，以优化资源分配、保持高质量服务和运营效率。

Method: 使用Cloud Analyst模拟工具评估了在中心化和分布式资源设置下不同负载均衡算法在各种场景下的性能。

Result: 在单数据中心内，循环算法的处理时间略好；但考虑到网络延迟，均衡和限流技术表现具有竞争力。在分布式环境（跨多个数据中心）中，响应时间显著减少，均衡和限流算法在保持快速响应时间和降低运营成本方面表现突出。

Conclusion: 本研究强调了在分布式云环境中采用智能、动态负载均衡和资源管理实践的必要性，以满足不断变化的云需求、优化成本并保持竞争优势。持续评估和整合新兴技术对于维持有效和可扩展的云运营至关重要。

Abstract: Load balancing plays a pivotal role in cloud computing, ensuring that
resources are optimally allocated to maintain high service quality and
operational efficiency. As workloads in cloud environments become increasingly
dynamic and unpredictable, load balancing strategies are evolving from
traditional static methods to more adaptive and intelligent approaches. In this
study, the Cloud Analyst simulation tool was used to evaluate the performance
of different load balancing algorithms under various scenarios, including both
centralized and distributed resource setups. The results highlight that while
the Round Robin algorithm yields slightly better processing times within a
single data center, Equally Spread and Throttled techniques perform
competitively, especially when network latency is considered. More importantly,
when resources are distributed across multiple data centers, response times are
significantly reduced, emphasizing the value of proximity and efficient load
distribution. In these distributed environments, Equally Spread and Throttled
algorithms not only maintain quick response times but also contribute to lower
operational costs. These findings demonstrate the necessity of strategic
resource placement and proactive infrastructure planning to balance performance
and cost. Adopting intelligent, dynamic load balancing and resource management
practices can help organizations meet evolving cloud demands, optimize costs,
and maintain a competitive advantage. Continuous evaluation and integration of
emerging technologies are crucial for sustaining effective and scalable cloud
operations.

</details>


### [188] [Making Serverless Computing Extensible: A Case Study of Serverless Data Analytics](https://arxiv.org/abs/2507.11929)
*Minchen Yu,Yinghao Ren,Jiamu Zhao,Jiaqi Li*

Main category: cs.DC

TL;DR: Serverless computing often forces a choice between performance and simplicity. This paper proposes an extensible design principle for serverless platforms, realized in Proteus. Proteus uses decision workflows to let developers optimize for specific needs (like data analytics) while keeping the platform simple and shareable, showing improved performance and resource sharing.


<details>
  <summary>Details</summary>
Motivation: Serverless applications face a dilemma between using general-purpose platforms that may lack performance for complex workloads and building application-specific systems that sacrifice simplicity and generality. The paper aims to address this by enabling domain-specialized optimizations within a shared, easy-to-use serverless environment.

Method: The paper proposes an extensible design principle for serverless computing and demonstrates its application through a system called Proteus. Proteus introduces a novel abstraction of decision workflows to allow developers to customize control-plane behaviors for performance improvements, using data analytics as a representative use case.

Result: Preliminary results show that Proteus

Conclusion: The proposed extensible design principle and Proteus platform enable developers to customize serverless platform behaviors for domain-specific optimizations, retaining a shared and easy-to-use environment. Proteus, with its decision workflows abstraction, effectively optimizes analytical query execution and supports fine-grained resource sharing.

Abstract: Serverless computing has attracted a broad range of applications due to its
ease of use and resource elasticity. However, developing serverless
applications often poses a dilemma -- relying on general-purpose serverless
platforms can fall short of delivering satisfactory performance for complex
workloads, whereas building application-specific serverless systems undermines
the simplicity and generality. In this paper, we propose an extensible design
principle for serverless computing. We argue that a platform should enable
developers to extend system behaviors for domain-specialized optimizations
while retaining a shared, easy-to-use serverless environment. We take data
analytics as a representative serverless use case and realize this design
principle in Proteus. Proteus introduces a novel abstraction of decision
workflows, allowing developers to customize control-plane behaviors for
improved application performance. Preliminary results show that Proteus's
prototype effectively optimizes analytical query execution and supports
fine-grained resource sharing across diverse applications.

</details>


### [189] [NineToothed: A Triton-Based High-Level Domain-Specific Language for Machine Learning](https://arxiv.org/abs/2507.11978)
*Jiacheng Huang,Zimin Li,Yinghui Li,Haojie Wang*

Main category: cs.DC

TL;DR: NineToothed是一个新的深度学习领域特定语言（DSL），它允许开发者使用串行编程模型，通过自动将串行代码转换为并行代码，简化了开发过程，同时保持了与Triton相当的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的深度学习领域特定语言（DSL），如Triton，要求开发者具备并行编程专业知识并暴露许多底层细节，这增加了开发和维护的复杂性。因此，有必要开发一种支持深度学习工作负载串行编程的新编程模型。

Method: NineToothed通过（1）一种具有张量导向元编程（TOM）的语言，采用排列和应用范式，支持表达平铺计算而无需管理低级细节，以及（2）一个生成高性能并行代码的代码生成器，实现了序列代码到并行代码的自动转换。

Result: 评估结果表明，NineToothed能够极大地简化计算内核的开发，同时保持与Triton相当的性能。

Conclusion: NineToothed通过其特定领域语言（DSL）和代码生成器，能够显著简化深度学习计算内核的开发，同时保持与Triton相当的性能。

Abstract: The emergence of deep learning domain-specific languages (DSLs) has
substantially reduced the obstacles in developing high-performance,
cross-platform compute kernels. However, current DSLs, such as Triton, still
demand that developers possess expertise in parallel programming and expose
them to many low-level details. This requirement complicates the development
process and adds to the difficulty of maintaining compute kernels.
Consequently, developing a new programming model that supports serial
programming for deep learning workloads is crucial.
  This paper introduces NineToothed, a domain-specific language that offers
serial semantics for machine learning programming. Through the automatic
transformation of serial code into parallel code, NineToothed significantly
streamlines the development process while causing minimal performance
degradation. NineToothed encompasses (1) a language with tensor-oriented
metaprogramming (TOM) that adopts the arrange-and-apply paradigm, enabling the
expression of tiled computations without the need to manage low-level details
and (2) a code generator for generating high-performance parallel code. Our
evaluation results indicate that NineToothed can greatly simplify compute
kernel development while maintaining performance comparable to that of Triton.

</details>


### [190] [ARRC: Explainable, Workflow-Integrated Recommender for Sustainable Resource Optimization Across the Edge-Cloud Continuum](https://arxiv.org/abs/2507.12032)
*Brian-Frederik Jahnke,René Brinkhege,Jan Peter Meyer,Daniel Tebernum,Falk Howar*

Main category: cs.DC

TL;DR: ARRC通过将可解释的、基于工作流的推荐系统集成到资源管理中，以软件工程原则实现了边缘-云系统中可持续、透明且低成本的资源优化，显著提高了效率和可维护性。


<details>
  <summary>Details</summary>
Motivation: 为了解决边缘-云连续体中实现可持续、可解释和可维护的资源优化自动化的核心挑战，应对由异构平台和分层抽象引起的持续过度配置和操作复杂性，以及缺乏可解释性和可维护性的系统带来的脆弱性、恢复困难和技术债务累积问题。

Method: ARRC是一个基于软件工程设计原则的推荐系统，通过封装优化逻辑到专门的、可审计的代理中，并通过共享接口进行协调，将可解释的、跨层级的资源建议直接注入到操作员的工作流中（例如，工单和GitOps拉取请求）。

Result: ARRC在多区域工业部署中的经验评估显示，运营商工作量减少超过50%，计算利用率提高高达7.7倍，错误率保持在5%以下，且大部分收益来自于操作员批准的增量更改。

Conclusion: ARRC是一个经验证的框架，用于将可解释的、工作流驱动的自动化集成到资源管理中，旨在推进健壮、可维护和透明的边缘-云连续体平台的最佳实践。

Abstract: Achieving sustainable, explainable, and maintainable automation for resource
optimization is a core challenge across the edge-cloud continuum. Persistent
overprovisioning and operational complexity often stem from heterogeneous
platforms and layered abstractions, while systems lacking explainability and
maintainability become fragile, impede safe recovery, and accumulate technical
debt. Existing solutions are frequently reactive, limited to single abstraction
layers, or require intrusive platform changes, leaving efficiency and
maintainability gains unrealized.
  This paper addresses safe, transparent, and low-effort resource optimization
in dynamic, multi-tenant edge-cloud systems, without disrupting operator
workflows or increasing technical debt. We introduce ARRC, a recommender system
rooted in software engineering design principles, which delivers explainable,
cross-layer resource recommendations directly into operator workflows (such as
tickets and GitOps pull requests). ARRC encapsulates optimization logic in
specialized, auditable agents coordinated via a shared interface, supporting
maintainability and extensibility through transparency and the ability to
inspect both recommendations and their rationale.
  Empirical evaluation in a multi-region industrial deployment shows that ARRC
reduces operator workload by over 50%, improves compute utilization by up to
7.7x, and maintains error rates below 5%, with most benefits achieved through
incremental, operator-approved changes. This demonstrates that explainable,
recommendation-based architectures can achieve sustainable efficiency and
maintainability improvements at production scale.
  ARRC provides an empirically evaluated framework for integrating explainable,
workflow-driven automation into resource management, intended to advance best
practices for robust, maintainable, and transparent edge-cloud continuum
platforms.

</details>


### [191] [Distributed Algorithms for Potential Problems](https://arxiv.org/abs/2507.12038)
*Alkida Balliu,Thomas Boudier,Francesco d'Amore,Dennis Olivetti,Gustav Schmid,Jukka Suomela*

Main category: cs.DC

TL;DR: 提出了一种新的分布式算法，可将局部最优问题（如局部最优割）在有界度图中的轮数复杂度从 $O(n)$ 降低到 $\log^{O(1)} n$，并将确定性轮数复杂度精确到 $\Theta(\log n)$。


<details>
  <summary>Details</summary>
Motivation: 解决局部最优问题（如局部最优割）在分布式计算中是一个重要的挑战，特别是对于局部最优割问题，其确定性和随机化模型中的轮数复杂度存在较大差距。

Method: 提出了一种用于解决局部最优问题的快速分布式算法，该算法适用于有界度图。

Result: 在有界度图中，所有局部最优问题（包括局部最优割）都可以在确定性和随机化局部模型中以 $\log^{O(1)} n$ 轮数解决。特别是，局部最优割问题的确定性轮数复杂度被确定为 $\Theta(\log n)$。

Conclusion: 该论文提出了一种解决局部最优问题（包括局部最优割）的分布式算法，该算法在确定性和随机化局部模型中都只需要 $\log^{O(1)} n$ 的轮数，从而缩小了局部最优割问题的已知上界和下界之间的差距，并将该问题的确定性轮数复杂度确定为 $\Theta(\log n)$。

Abstract: In this work we present a fast distributed algorithm for local potential
problems: these are graph problems where the task is to find a locally optimal
solution where no node can unilaterally improve the utility in its local
neighborhood by changing its own label. A simple example of such a problem is
the task of finding a locally optimal cut, i.e., a cut where for each node at
least half of its incident edges are cut edges. The distributed round
complexity of locally optimal cut has been wide open; the problem is known to
require $\Omega(\log n)$ rounds in the deterministic LOCAL model and
$\Omega(\log \log n)$ rounds in the randomized LOCAL model, but the only known
upper bound is the trivial brute-force solution of $O(n)$ rounds. Locally
optimal cut in bounded-degree graphs is perhaps the simplest example of a
locally checkable labeling problem for which there is still such a large gap
between current upper and lower bounds. We show that in bounded-degree graphs,
all local potential problems, including locally optimal cut, can be solved in
$\log^{O(1)} n$ rounds, both in the deterministic and randomized LOCAL models.
In particular, the deterministic round complexity of the locally optimal cut
problem is now settled to $\log^{\Theta(1)} n$.

</details>


### [192] [Urban Green Governance: IoT-Driven Management and Enhancement of Urban Green Spaces in Campobasso](https://arxiv.org/abs/2507.12106)
*Antonio Salis,Gabriele Troina,Gianluca Boanelli,Marco Ottaviano,Paola Fortini,Soraya Versace*

Main category: cs.DC

TL;DR: 该项目通过集成物联网和数据驱动平台，利用传感器和机器学习优化城市绿地管理，提高可持续性。


<details>
  <summary>Details</summary>
Motivation: 城市公共绿地的有效设计和管理对促进城市人口的健康和福祉至关重要，这些区域是城市生态系统的“绿色肺”，通过提供生态系统服务来提高生活质量。

Method: 通过集成物联网系统和数据驱动的治理平台，利用树语者传感器、土壤湿度和水分潜力监测系统，并结合机器学习算法的预测模型和物联网传感器的实时数据，对城市绿地进行实时监控和智能管理，优化灌溉，并提供自定义警报。

Result: 部署了一个基于云的平台，支持城市绿地管理者、技术专家和运营人员进行整体的实时决策，实现了对树木和绿地健康状况的实时监控，并优化了公园灌溉。

Conclusion: 该项目展示了数字化、物联网传感器融合和技术创新如何支持可持续城市治理，增强环境韧性并提高市民生活质量。

Abstract: The efficient design and management of public green spaces is a key factor in
promoting the health and well-being of urban population, as emphasized by the
WHO, UNEP, and EEA. These areas serve as the "green lungs" of the urban
ecosystem, playing a vital role in enhancing quality of life thanks to the
provision of ecosystem services. In this context, the Smart Green City use case
in Campobasso municipality, funded by the Italian Ministry of Enterprises
(MIMIT), emerges as an innovative model for the sustainable management of green
urban areas through the adoption of an advanced system of emerging technologies
integrated and interoperable. The project integrates IoT systems and
data-driven governance platforms, enabling real-time monitoring of the health
status of trees and green areas via a Decision Support System (DSS). It also
facilitates the collection and analysis of data from diverse sources, including
weather conditions, air quality, soil moisture, pollution levels. The resulting
cloud-based platform supports a holistic real time decision making for green
urban managers, technical experts and operational staff. It enables intelligent
control and management of urban green spaces using Tree Talker sensors,
integrated with soil moisture and water potential monitoring systems. Thanks to
predictive models based on machine learning algorithms and real time data
provided by IoT sensors, irrigation of public parks can be optimized by
providing suggestions on when and how much water to apply. Customized alerts
layers are also activated warning users when monitored parameters, such as soil
temperature, humidity, or water potential, exceed predefined thresholds. This
Use Case demonstrates how digitalization, IoT sensors fusion and technological
innovation can support sustainable urban governance, fostering environmental
resilience and improving citizens quality of life.

</details>


### [193] [Toward Efficient SpMV in Sparse LLMs via Block Extraction and Compressed Storage](https://arxiv.org/abs/2507.12205)
*Junqing Lin,Jingwei Sun,Mingge Lu,Guangzhong Sun*

Main category: cs.DC

TL;DR: EC-SpMV通过分层块提取和EC-CSR格式，加速了稀疏LLM推理，性能提升高达6.44倍，存储开销减少高达55.4%。


<details>
  <summary>Details</summary>
Motivation: 现有的SpMV内核和稀疏矩阵格式（源于科学计算）未能充分利用稀疏LLM（尤其是在批处理大小为1的解码器阶段）的独特结构模式，导致性能不佳和存储开销过大。

Method: EC-SpMV提出了一种新的GPU优化稀疏矩阵-向量乘（SpMV）方法，包括（1）捕捉稀疏LLM中多粒度块结构的分层块提取算法，以及（2）使用增量索引的EC-CSR新压缩稀疏格式，以降低存储开销和提高内存访问效率。

Result: EC-SpMV在LLaMA和OPT模型的稀疏权重矩阵上进行了评估，与最先进的SpMV库相比，速度最高提高了6.44倍，存储开销比CSR格式减少了高达55.4%。

Conclusion: EC-SpMV通过其分层块提取算法和EC-CSR压缩格式，在稀疏LLM推理中实现了显著的加速和存储优化。

Abstract: Sparse Matrix-Vector Multiplication (SpMV) has become a critical performance
bottleneck in the local deployment of sparse Large Language Models (LLMs),
where inference predominantly operates on workloads during the decoder phase
with a batch size of one. Existing SpMV kernels and sparse matrix formats,
originally designed for scientific computing, fail to exploit the unique
structure patterns inherent in sparse LLMs, resulting in suboptimal performance
and excessive storage overhead. This paper presents EC-SpMV, a GPU-optimized
SpMV approach for accelerating sparse LLM inference. EC-SpMV introduces (1) a
hierarchical block extraction algorithm that captures multiple granularities of
block structures within sparse LLMs, and (2) a novel compressed sparse format
(EC-CSR) that employs delta indexing to reduce storage overhead and enhance
memory access efficiency. Evaluated on real sparse weight matrices from LLaMA
and OPT models, EC-SpMV achieves up to 6.44x speedup over state-of-the-art SpMV
libraries and reduces storage overhead by up to 55.4% compared to CSR.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [194] [Emerging Paradigms in the Energy Sector: Forecasting and System Control Optimisation](https://arxiv.org/abs/2507.12373)
*Dariush Pourkeramati,Gareth Wadge,Rachel Hassall,Charlotte Mitchell,Anish Khadka,Shiwang Jaiswal,Andrew Duncan,Rossella Arcucci*

Main category: cs.ET

TL;DR: 该研究重点介绍了通过利用机器学习和模型预测控制来改进能源需求预测、建筑能源优化、热力管网优化以及在系统之系统（SoS）框架内进行能源管理系统（EMS）优化的方法。通过实际案例研究，展示了人工智能在提高能源系统的效率、韧性和可持续性方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 由于可再生能源整合、电力系统分散化以及对效率和可持续性的关注日益增加，能源行业正在经历快速转型。对更准确的预测和优化策略的需求推动了这项研究。

Method: 本研究利用机器学习技术和模型预测控制（MPC）来优化能源管理。

Result: 研究表明，在从单个建筑到复杂的互联能源网络的各个层面上，能源效率都得到了显著提高。天气信息驱动的需求预测提高了电网的韧性和资源分配策略。智能建筑优化通过集成预测分析，在不影响居住者舒适度的情况下，显著降低了能耗。优化热电联产热力管网可在遵守运营和资产限制的同时，节省成本和减少碳排放。在系统层面，先进的能源管理系统（EMS）优化确保了分布式资源、存储解决方案和需求侧灵活性的协调控制。

Conclusion: 该研究展示了人工智能驱动的自动化和集成控制解决方案在促进有弹性的、高效的和可持续的能源未来方面的潜力。

Abstract: The energy sector is experiencing rapid transformation due to increasing
renewable energy integration, decentralisation of power systems, and a
heightened focus on efficiency and sustainability. With energy demand becoming
increasingly dynamic and generation sources more variable, advanced forecasting
and optimisation strategies are crucial for maintaining grid stability,
cost-effectiveness, and environmental sustainability. This paper explores
emerging paradigms in energy forecasting and management, emphasizing four
critical domains: Energy Demand Forecasting integrated with Weather Data,
Building Energy Optimisation, Heat Network Optimisation, and Energy Management
System (EMS) Optimisation within a System of Systems (SoS) framework.
Leveraging machine learning techniques and Model Predictive Control (MPC), the
study demonstrates substantial enhancements in energy efficiency across scales
-- from individual buildings to complex interconnected energy networks.
Weather-informed demand forecasting significantly improves grid resilience and
resource allocation strategies. Smart building optimisation integrates
predictive analytics to substantially reduce energy consumption without
compromising occupant comfort. Optimising CHP-based heat networks achieves cost
and carbon savings while adhering to operational and asset constraints. At the
systems level, sophisticated EMS optimisation ensures coordinated control of
distributed resources, storage solutions, and demand-side flexibility. Through
real-world case studies we highlight the potential of AI-driven automation and
integrated control solutions in facilitating a resilient, efficient, and
sustainable energy future.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [195] [Double Duty: FPGA Architecture to Enable Concurrent LUT and Adder Chain Usage](https://arxiv.org/abs/2507.11709)
*Junius Pun,Xilai Dai,Grace Zgheib,Mahesh A. Iyer,Andrew Boutros,Vaughn Betz,Mohamed S. Abdelfattah*

Main category: cs.AR

TL;DR: 本研究提出了一种新的FPGA逻辑块架构（双重职责），通过允许加法器和查找表（LUT）同时运行，显著提高了FPGA的面积效率（平均降低9.7%的面积延迟积），特别是在处理加法器密集型和混合精度等现代计算任务时。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络（DNN）中普遍存在的稀疏性和混合精度问题，促使研究者探索如何优化FPGA的逻辑块架构以提高其算术密度。现有的FPGA逻辑块架构限制了加法器链的独立使用，仅允许其输入源自查找表（LUT）的输出，从而阻碍了加法器和查找表（LUT）的并行使用，不利于面积优化。

Method: 本研究提出的双重职责逻辑块架构，通过改进FPGA逻辑块的布线方式，允许加法器链和查找表（LUT）同时使用。具体而言，在不增加额外输入引脚的情况下，利用现有的4个输入引脚，实现了对查找表（LUT）的绕过，使信号能够直接输入到加法器链。研究在电路和计算机辅助设计（CAD）层面进行了精确建模，并使用开源FPGA开发工具进行了实验评估。

Result: 在类似Stratix-10的架构上进行的实验评估显示，该双重职责逻辑块架构在Kratos基准测试中的加法器密集型电路上实现了21.6%的面积缩减，在更通用的Koios和VTR基准测试中分别实现了9.3%和8.2%的面积缩减。这些面积改进并未对关键路径延迟产生负面影响，证明了通过增加加法器链使用灵活性可以在现代FPGA架构上实现更高的密度。在所有评估的三个基准测试集的所有电路上平均来看，双重职责FPGA架构将面积延迟积提高了9.7%。

Conclusion: 所提出的双重职责逻辑块架构能够在不增加昂贵逻辑集群输入的情况下，通过使用现有的4个输入来绕过查找表（LUT），直接连接到加法器链输入，从而实现查找表（LUT）和加法器链的同时使用。实验结果表明，与现有架构相比，该架构在加法器密集型电路和更通用的基准测试中，面积分别减少了21.6%、9.3%和8.2%，同时关键路径延迟没有受到影响，平均面积延迟积提高了9.7%。

Abstract: Flexibility and customization are key strengths of Field-Programmable Gate
Arrays (FPGAs) when compared to other computing devices. For instance, FPGAs
can efficiently implement arbitrary-precision arithmetic operations, and can
perform aggressive synthesis optimizations to eliminate ineffectual operations.
Motivated by sparsity and mixed-precision in deep neural networks (DNNs), we
investigate how to optimize the current logic block architecture to increase
its arithmetic density. We find that modern FPGA logic block architectures
prevent the independent use of adder chains, and instead only allow adder chain
inputs to be fed by look-up table (LUT) outputs. This only allows one of the
two primitives -- either adders or LUTs -- to be used independently in one
logic element and prevents their concurrent use, hampering area optimizations.
In this work, we propose the Double Duty logic block architecture to enable the
concurrent use of the adders and LUTs within a logic element. Without adding
expensive logic cluster inputs, we use 4 of the existing inputs to bypass the
LUTs and connect directly to the adder chain inputs. We accurately model our
changes at both the circuit and CAD levels using open-source FPGA development
tools. Our experimental evaluation on a Stratix-10-like architecture
demonstrates area reductions of 21.6% on adder-intensive circuits from the
Kratos benchmarks, and 9.3% and 8.2% on the more general Koios and VTR
benchmarks respectively. These area improvements come without an impact to
critical path delay, demonstrating that higher density is feasible on modern
FPGA architectures by adding more flexibility in how the adder chain is used.
Averaged across all circuits from our three evaluated benchmark set, our Double
Duty FPGA architecture improves area-delay product by 9.7%.

</details>


### [196] [MOFCO: Mobility- and Migration-Aware Task Offloading in Three-Layer Fog Computing Environments](https://arxiv.org/abs/2507.12028)
*Soheil Mahdizadeh,Elyas Oustad,Mohsen Ansari*

Main category: cs.AR

TL;DR: MOFCO 是一种新的雾计算任务卸载算法，可感知移动性和迁移，通过进化博弈论解决 MINLP 问题，在降低延迟和能耗方面比现有方法效果好 19%。


<details>
  <summary>Details</summary>
Motivation: 移动性给三层雾计算环境中的任务卸载带来了挑战，会导致服务迁移成本高昂并降低整体系统性能。

Method: MOFCO 算法将任务卸载和资源分配制定为混合整数非线性规划（MINLP）问题，并采用受启发于进化博弈论的启发式方法进行有效求解。

Result: 实验结果表明，MOFCO 将系统成本（延迟和能耗）平均降低了 19%，在某些情况下最高可达 43%。

Conclusion: MOFCO 通过结合迁移感知和移动性，在三层雾计算环境中有效地解决了任务卸载和资源分配问题，与其他方法相比，可将系统成本（延迟和能耗）平均降低 19%，在某些情况下甚至高达 43%。

Abstract: Task offloading in three-layer fog computing environments presents a critical
challenge due to user equipment (UE) mobility, which frequently triggers costly
service migrations and degrades overall system performance. This paper
addresses this problem by proposing MOFCO, a novel Mobility- and
Migration-aware Task Offloading algorithm for Fog Computing environments. The
proposed method formulates task offloading and resource allocation as a
Mixed-Integer Nonlinear Programming (MINLP) problem and employs a
heuristic-aided evolutionary game theory approach to solve it efficiently. To
evaluate MOFCO, we simulate mobile users using SUMO, providing realistic
mobility patterns. Experimental results show that MOFCO reduces system cost,
defined as a combination of latency and energy consumption, by an average of
19% and up to 43% in certain scenarios compared to state-of-the-art methods.

</details>


### [197] [High-Performance Pipelined NTT Accelerators with Homogeneous Digit-Serial Modulo Arithmetic](https://arxiv.org/abs/2507.12418)
*George Alexakis,Dimitrios Schoinianakis,Giorgos Dimitrakopoulos*

Main category: cs.AR

TL;DR: 通过数字串行算术和冗余数据表示，设计了一种高效的NTT硬件加速器，提高了性能并降低了硬件成本。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有NTT硬件加速器在大数模数运算中遇到的硬件面积和时钟频率限制问题，本研究旨在设计一种更高效的NTT硬件加速器。

Method: 本文利用数字串行模运算结合冗余数据表示，设计了模块化流水线NTT加速器，使其能够在任意小的数字上统一运行，无需中间的（反）序列化。

Result: 实验结果表明，该方法在同等性能和输入输出带宽约束下，相比现有最先进的实现，能够实现更高的时钟频率并降低硬件复杂度。

Conclusion: 所提出的基于数字串行算术和冗余数据表示的模块化流水线NTT加速器架构，在保持并行性的同时，通过规整的流水线实现了高时钟频率，并且在同等性能和输入输出带宽限制下，相比现有最先进的实现具有更低的硬件复杂度。

Abstract: The Number Theoretic Transform (NTT) is a fundamental operation in
privacy-preserving technologies, particularly within fully homomorphic
encryption (FHE). The efficiency of NTT computation directly impacts the
overall performance of FHE, making hardware acceleration a critical technology
that will enable realistic FHE applications. Custom accelerators, in FPGAs or
ASICs, offer significant performance advantages due to their ability to exploit
massive parallelism and specialized optimizations. However, the operation of
NTT over large moduli requires large word-length modulo arithmetic that limits
achievable clock frequencies in hardware and increases hardware area costs. To
overcome such deficits, digit-serial arithmetic has been explored for modular
multiplication and addition independently. The goal of this work is to leverage
digit-serial modulo arithmetic combined with appropriate redundant data
representation to design modular pipelined NTT accelerators that operate
uniformly on arbitrary small digits, without the need for intermediate
(de)serialization. The proposed architecture enables high clock frequencies
through regular pipelining while maintaining parallelism. Experimental results
demonstrate that the proposed approach outperforms state-of-the-art
implementations and reduces hardware complexity under equal performance and
input-output bandwidth constraints.

</details>


### [198] [Characterizing State Space Model (SSM) and SSM-Transformer Hybrid Language Model Performance with Long Context Length](https://arxiv.org/abs/2507.12442)
*Saptarshi Mitra,Rachid Karami,Haocheng Xu,Sitao Huang,Hyoukjun Kwon*

Main category: cs.AR

TL;DR: SSMs在消费级GPU上比Transformers更适合长上下文推理，处理的序列更长，速度更快。SSM的内核是性能瓶颈，值得关注。


<details>
  <summary>Details</summary>
Motivation: 随着对能在本地设备上处理连续、长上下文输入的机器智能的需求不断增长，但传统的Transformer架构因其二次复杂性和内存需求而在效率和可用性方面存在不足。因此，需要对SSM和混合模型等新架构在实际消费级硬件上的性能进行系统化表征，以指导系统级优化和推动新应用。

Method: 通过对Transformer、SSM和混合模型进行比较基准测试，在消费级和嵌入式GPU上对长上下文推理进行系统化性能表征。分析了SSM的硬件感知内核对推理延迟的影响，并在边缘平台上进行了详细的设备特定表征。

Result: SSMs不仅可行，而且在该领域表现更优越，能够在24GB消费级GPU上处理长达220K个token的序列，这大约是同类Transformer的4倍。虽然Transformers在短序列上可能快1.8倍，但SSMs在极长上下文（约57K token）时速度可提升4倍。SSM的硬件感知内核占用了超过55%的边缘平台推理延迟，是未来硬件加速的关键。

Conclusion: SSMs在长上下文推理方面表现优于Transformer，在消费级GPU上能处理更长的序列（高达220K tokens），并且在长上下文时速度更快（高达4倍）。SSM的硬件感知内核是影响推理性能的关键因素，是未来硬件加速的主要目标。

Abstract: The demand for machine intelligence capable of processing continuous,
long-context inputs on local devices is growing rapidly. However, the quadratic
complexity and memory requirements of traditional Transformer architectures
make them inefficient and often unusable for these tasks. This has spurred a
paradigm shift towards new architectures like State Space Models (SSMs) and
hybrids, which promise near-linear scaling. While most current research focuses
on the accuracy and theoretical throughput of these models, a systematic
performance characterization on practical consumer hardware is critically
needed to guide system-level optimization and unlock new applications.
  To address this gap, we present a comprehensive, comparative benchmarking of
carefully selected Transformer, SSM, and hybrid models specifically for
long-context inference on consumer and embedded GPUs. Our analysis reveals that
SSMs are not only viable but superior for this domain, capable of processing
sequences up to 220K tokens on a 24GB consumer GPU-approximately 4x longer than
comparable Transformers. While Transformers may be up to 1.8x faster at short
sequences, SSMs demonstrate a dramatic performance inversion, becoming up to 4x
faster at very long contexts (~57K tokens). Our operator-level analysis reveals
that custom, hardware-aware SSM kernels dominate the inference runtime,
accounting for over 55% of latency on edge platforms, identifying them as a
primary target for future hardware acceleration. We also provide detailed,
device-specific characterization results to guide system co-design for the
edge. To foster further research, we will open-source our characterization
framework.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [199] [Lecture Notes on Quantum Algorithms](https://arxiv.org/abs/2507.11565)
*Muhammad Faryad*

Main category: quant-ph

TL;DR: This paper is a textbook-style guide to quantum computing, covering fundamental concepts, key algorithms (like Shor's and Grover's), and advanced topics such as Hamiltonian simulation and quantum chemistry simulations, complete with circuit details and complexity analysis.


<details>
  <summary>Details</summary>
Motivation: To provide a structured and in-depth understanding of quantum algorithms, from basic principles to advanced applications, and to offer practical insights into their implementation.

Method: The paper reviews linear algebra, quantum mechanics postulates, and systematically introduces quantum gates, algorithms (including those based on quantum Fourier transform and Grover's algorithm), Hamiltonian simulation techniques, and applications to specific problems like fermionic systems. It also discusses complexity analysis and provides detailed quantum circuits.

Result: The paper details various quantum algorithms and techniques, including their theoretical underpinnings, circuit implementations, and applications in areas like factoring, search, and simulating quantum systems.

Conclusion: The paper provides a comprehensive overview of quantum algorithms and their implementation, covering foundational concepts, various algorithms like Deutsch-Jozsa and Grover's, and advanced topics such as Hamiltonian simulation and variational algorithms.

Abstract: These notes begin in Chapter 1 with a review of linear algebra and the
postulates of quantum mechanics, leading to an explanation of single- and
multi-qubit gates. Chapter 2 explores the challenge of constructing arbitrary
quantum states from given initial states, and introduces circuits for building
oracles. Chapter 3 presents foundational algorithms such as entanglement
creation, quantum teleportation, Deutsch-Jozsa, Bernstein-Vazirani, and Simon's
algorithm.
  Chapters 4 and 5 cover algorithms based on the quantum Fourier transform,
including phase estimation, period finding, factoring, and logarithm
computation. These chapters also include complexity analysis and detailed
quantum circuits suitable for implementation in code. Chapter 6 introduces
Grover's algorithm for quantum search and amplitude amplification, including
its realization via Hamiltonian simulation and a method for derandomization.
  Chapter 7 discusses basic techniques for Hamiltonian simulation, such as
Lie-Trotter decomposition, sparse Hamiltonians, and the linear combination of
unitaries. It also provides example circuits for simulating Hamiltonians
expressed as linear combinations of Pauli operators. Chapter 8 introduces
variational quantum algorithms, and Chapter 9 presents an algorithm for
simulating fermionic many-particle systems, with an emphasis on molecular
Hamiltonians. It also outlines the key transformations needed to map a
molecular Hamiltonian to a form suitable for simulation on a quantum computer.

</details>


### [200] [Visualising Quantum Product Codes](https://arxiv.org/abs/2507.11577)
*Tom Scruby*

Main category: quant-ph

TL;DR: 本文将超图乘积（HGP）的可视化方法推广到the lifted和the balanced乘积，提供了一种统一的图形化描述，并阐释了它们的各种属性。


<details>
  <summary>Details</summary>
Motivation: 现有两种强大的超图乘积（HGP）的泛化——the lifted和the balanced乘积，虽然取得了巨大成功，但缺乏统一的图形化描述方法。

Method: 本文回顾了可视化HGP码的经典方法，并通过增加第三维度将其推广到the lifted和the balanced乘积。

Result: 提供了一种统一的图形化方法来描述the lifted和the balanced乘积，并揭示了它们的各种属性，例如界定$k$和$d$的难度、寻找经典逻辑基的挑战，以及这两种乘积之间的联系和差异。

Conclusion: 该论文通过添加第三维度，将超图乘积（HGP）的经典可视化方法推广到 the lifted 和 the balanced 乘积，提供了一种统一的图形化方法来描述这些代码。这有助于理解它们的属性，例如 i) 为什么难以界定 $k$ 和 $d$；ii) 在一般情况下寻找经典逻辑基的困难；以及 iii) 这两种乘积的关系和区别。

Abstract: The hypergraph product (HGP) is a famous code construction technique with an
equally famous canonical visualisation. This visual perspective provides much
more than simply a way to build intuition: HGP codes can be defined
graphically, properties can be demonstrated graphically, and approaches to
fault-tolerant logic have been developed graphically. In recent years two
powerful generalisations of this product -- the lifted and balanced products --
have been proposed and employed to great success, but a unified graphical
approach to describing these codes has been absent. In these notes I review the
canonical approach to visualising HGP codes and then show how, via the addition
of a third dimension, it can be generalised to apply to both the lifted and the
balanced product. In the process we obtain clear intuition into various
properties of these codes such as i) why it is hard to bound $k$ and $d$ ii)
the issues with finding a canonical logical basis in the general case and iii)
how the two products are related, and how they differ. I have attempted to
structure these notes plainly and directly, so that the visual intuition can be
easily obtained by those who want it while the rigorous justification is still
available to those who demand it.

</details>


### [201] [k-Contextuality as a Heuristic for Memory Separations in Learning](https://arxiv.org/abs/2507.11604)
*Mariesa H. Teo,Willers Yang,James Sud,Teague Tomesh,Frederic T. Chong,Eric R. Anschuetz*

Main category: quant-ph

TL;DR: 提出强k-情境性来识别经典计算机难以处理但量子计算机可能擅长的问题，并开发了估计该度量和预测经典与量子模型性能差异的算法。


<details>
  <summary>Details</summary>
Motivation: 在经典机器学习模型难以处理具有长程相关性的数据集的背景下，提出了一种新的量化方法来衡量情境性，并以此作为开发高效算法的动机，以估计序列数据中的情境性。

Method: 提出了一种名为强k-情境性的新情境性量化方法，并证明了具有强k-情境性的翻译任务无法被具有少于k个潜在状态的经典流模型以有限的相对熵表示。该相关性度量不会对量子生成模型产生类似的资源下界。

Result: 经验表明，强k-情境性的估计值可以预测资源受限的经典和量子贝叶斯网络在建模数据时的性能差异。

Conclusion: 强k-情境性可以作为衡量问题的难度的指标，这对于经典计算机来说可能很困难，但对于量子计算机来说则不然。

Abstract: Classical machine learning models struggle with learning and prediction tasks
on data sets exhibiting long-range correlations. Previously, the existence of a
long-range correlational structure known as contextuality was shown to inhibit
efficient classical machine learning representations of certain
quantum-inspired sequential distributions. Here, we define a new quantifier of
contextuality we call strong k-contextuality, and prove that any translation
task exhibiting strong k-contextuality is unable to be represented to finite
relative entropy by a classical streaming model with fewer than k latent
states. Importantly, this correlation measure does not induce a similar
resource lower bound for quantum generative models. Using this theory as
motivation, we develop efficient algorithms which estimate our new measure of
contextuality in sequential data, and empirically show that this estimate is a
good predictor for the difference in performance of resource-constrained
classical and quantum Bayesian networks in modeling the data. Strong
k-contextuality thus emerges as a measure to help identify problems that are
difficult for classical computers, but may not be for quantum computers.

</details>


### [202] [Rise and fall of nonstabilizerness via random measurements](https://arxiv.org/abs/2507.11619)
*Annarita Scocco,Wai-Keong Mok,Leandro Aolita,Mario Collura,Tobias Haug*

Main category: quant-ph

TL;DR: 研究了监测量子电路中非稳定性的动力学。计算基测量会通过克利福德打乱来保护非稳定性，而非克利福德基测量会同时产生和破坏非稳定性，导致稳定的非稳定性状态。


<details>
  <summary>Details</summary>
Motivation: 为了研究监测量子电路中非稳定（魔法）的动力学。

Method: 研究了由随机克利福德酉变换和局部幺正测量的监测量子电路中非稳定（也称为“魔法”）的动力学。对于计算基中的测量，推导了稳定器零度动力学的解析模型；对于在旋转的非克利福德基中进行的测量，研究了非稳定性的动力学。

Result: 对于计算基测量，稳定器零度以量子化的步长衰减，需要指数测量才能消失。对于旋转非克利福德基测量，测量会同时产生和破坏非稳定性，导致非平凡稳态。Haar随机状态在恒定时间内达到平衡，而稳定器状态表现出与大小成正比的弛豫时间。稳定器零度对旋转角不敏感，而稳定器Rényi熵揭示了更丰富的动力学结构。

Conclusion: 测量可以同时抑制和维持量子计算资源，揭示了粗粒度和细粒度非稳定诊断之间的显著区别。

Abstract: We investigate the dynamics of nonstabilizerness - also known as `magic' - in
monitored quantum circuits composed of random Clifford unitaries and local
projective measurements. For measurements in the computational basis, we derive
an analytical model for dynamics of the stabilizer nullity, showing that it
decays in quantized steps and requires exponentially many measurements to
vanish, which reveals the strong protection through Clifford scrambling. On the
other hand, for measurements performed in rotated non-Clifford bases,
measurements can both create and destroy nonstabilizerness. Here, the dynamics
leads to a steady-state with non-trivial nonstabilizerness, independent of the
initial state. We find that Haar-random states equilibrate in constant time,
whereas stabilizer states exhibit linear-in-size relaxation time. While the
stabilizer nullity is insensitive to the rotation angle, Stabilizer R\'enyi
Entropies expose a richer structure in their dynamics. Our results uncover
sharp distinctions between coarse and fine-grained nonstabilizerness
diagnostics and demonstrate how measurements can both suppress and sustain
quantum computational resources.

</details>


### [203] [Dynamics Simulation of Arbitrary Non-Hermitian Systems Based on Quantum Monte Carlo](https://arxiv.org/abs/2507.11675)
*Xiaogang Li,Qiming Ding,Kecheng Liu,Xiao Yuan*

Main category: quant-ph

TL;DR: 提出了一种混合经典-量子算法（基于QMC），用于模拟非厄米系统的动力学，解决了模拟挑战，并成功应用于开放量子系统。


<details>
  <summary>Details</summary>
Motivation: 非厄米量子系统虽然具有独特性且应用前景广阔，但其开放性和非幺正演化给动力学模拟带来了挑战。

Method: 提出了一种基于量子蒙特卡洛（QMC）的混合经典-量子算法，用于模拟任意时间依赖的非厄米系统的动力学，该算法是量子虚时演化（QITE）算法的自然扩展。

Result: 该混合算法结合了经典和量子计算的优点，具有良好的适用性和适应性，成功应用于开放量子系统的动态模拟，达到了预期效果。

Conclusion: 该算法为模拟任意时间依赖的非厄米系统提供了一种新颖的混合经典-量子方法，并已成功应用于开放量子系统。

Abstract: Non-Hermitian quantum systems exhibit unique properties and hold significant
promise for diverse applications, yet their dynamical simulation poses a
particular challenge due to intrinsic openness and non-unitary evolution. Here,
we introduce a hybrid classical-quantum algorithm based on Quantum Monte Carlo
(QMC) for simulating the dynamics of arbitrary time-dependent non-Hermitian
systems. Notably, this approach constitutes a natural extension of the quantum
imaginary-time evolution (QITE) algorithm. This algorithm combines the
advantages of both classical and quantum computation and exhibits good
applicability and adaptability, making it promising for simulating arbitrary
non-Hermitian systems such as PT-symmetric systems, non-physical processes, and
open quantum systems. To validate the algorithm, we applied it to the dynamic
simulation of open quantum systems and achieved the desired results.

</details>


### [204] [Notions of Adiabatic Drift in the Quantized Harper model](https://arxiv.org/abs/2507.11696)
*Alice C. Quillen,Nathan Skerrett,Damian R. Sowinski,Abobakar Sediq Miakhel*

Main category: quant-ph

TL;DR: 研究了哈珀哈密顿量的量化、离散和漂移版本（有限几乎马修算子），该算子类似于钟摆哈密顿量，但受限于环面。该算子具有跨越多个数量级的能级间距，并与循环轨道相关。系统参数缓慢变化时，会发生绝热和非绝热跃迁。只有在漂移速率极小的情况下，才能抑制所有向叠加态的跃迁。该模型表明，具有非局域势且与共振经典动力系统相关的量子系统可能具有广泛的能级间距。讨论了与具有分裂相空间的经典系统相关联的量子系统的绝热漂移概念。


<details>
  <summary>Details</summary>
Motivation: 研究量化、离散和漂移的哈珀哈密顿量，这种哈密顿量在相空间中限制在环面上，类似于钟摆哈密顿量。

Method: 研究了哈珀哈密顿量的量化、离散和漂移版本，也称为有限几乎马修算子。

Result: 观察到能级间距跨越多个数量级，并且具有接近简并的能级对，这些能级对与相关的经典系统中的循环轨道相关。当系统参数缓慢变化时，绝热和非绝热跃迁可能发生在跨越多个数量级的漂移速率下。只有在漂移速率可以忽略不计的情况下，才能抑制所有向叠加态的跃迁。

Conclusion: 该模型表明，具有非局域势且与共振经典动力系统相关的量子系统可能具有广泛的能级间距。

Abstract: We study a quantized, discrete and drifting version of the Harper
Hamiltonian, also called the finite almost Mathieu operator, which resembles
the pendulum Hamiltonian but in phase space is confined to a torus. Spacing
between pairs of eigenvalues of the operator spans many orders of magnitude,
with nearly degenerate pairs of states at energies that are associated with
circulating orbits in the associated classical system. When parameters of the
system slowly vary, both adiabatic and diabatic transitions can take place at
drift rates that span many orders of magnitude. Only under an extremely
negligible drift rate would all transitions into superposition states be
suppressed. The wide range of energy level spacings could be a common property
of quantum systems with non-local potentials that are related to resonant
classical dynamical systems. Notions for adiabatic drift are discussed for
quantum systems that are associated with classical ones with divided phase
space.

</details>


### [205] [Time-Aware Qubit Assignment and Circuit Optimization for Distributed Quantum Computing](https://arxiv.org/abs/2507.11707)
*Leo Sünkel,Jonas Stein,Maximilian Zorn,Thomas Gabor,Claudia Linnhoff-Popien*

Main category: quant-ph

TL;DR: 为减少分布式量子计算中的通信成本，本文提出并评估了两种方法：1. 采用时间感知算法优化量子比特分配；2. 采用进化算法优化量子电路本身。两种方法均优于基线方法，尤其是在减少通信开销方面。


<details>
  <summary>Details</summary>
Motivation: 分布式量子计算通过将大型量子电路分解为可在多个量子处理单元（QPU）上并行执行的子电路，为扩展量子计算能力提供了一种有前景的途径。然而，这种方法需要新的编译器来处理网络约束和量子通信的独特性质，特别是量子通信（如量子隐形传态）的成本高昂，因此需要有效的方法来最小化其使用。

Method: 该研究通过模拟退火和进化算法来解决量子比特分配问题，以最小化通信成本，并将其与图划分和顺序量子比特分配基线进行比较。此外，还提出了一种基于进化的量子电路优化算法，通过调整电路本身来降低通信成本。

Result: 研究结果表明，所提出的两种方法（时间感知算法和进化算法）在减少通信成本方面优于传统的图划分和顺序量子比特分配方法。进化算法在降低通信成本方面表现尤为突出。

Conclusion: 该研究提出了两种优化技术以减少分布式量子计算中的通信成本：一种是基于时间感知的算法，另一种是基于进化的量子电路优化算法。这两种方法都通过优化子电路的分配和调整电路本身来最小化量子通信的开销。

Abstract: The emerging paradigm of distributed quantum computing promises a potential
solution to scaling quantum computing to currently unfeasible dimensions. While
this approach itself is still in its infancy, and many obstacles must still be
overcome before its physical implementation, challenges from the software and
algorithmic side must also be identified and addressed. For instance, this
paradigm shift requires a new form of compiler that considers the network
constraints in general as well as phenomena arising due to the nature of
quantum communication. In distributed quantum computing, large circuits are
divided into smaller subcircuits such that they can be executed individually
and simultaneously on multiple QPUs that are connected through quantum
channels. As quantum communication, for example, in the form of teleportation,
is expensive, it must be used sparingly. We address the problem of assigning
qubits to QPUs to minimize communication costs in two different ways. First by
applying time-aware algorithms that take into account the changing connectivity
of a given circuit as well as the underlying network topology. We define the
optimization problem, use simulated annealing and an evolutionary algorithm and
compare the results to graph partitioning and sequential qubit assignment
baselines. In another approach, we propose an evolutionary-based quantum
circuit optimization algorithm that adjusts the circuit itself rather than the
schedule to reduce the overall communication cost. We evaluate the techniques
against random circuits and different network topologies. Both evolutionary
algorithms outperform the baseline in terms of communication cost reduction. We
give an outlook on how the approaches can be integrated into a compilation
framework for distributed quantum computing.

</details>


### [206] [Separation of relaxation timescales via strong system-bath coupling: Dissipative three-level system as a case study](https://arxiv.org/abs/2507.11712)
*Brett Min,Matthew Gerry,Dvira Segal*

Main category: quant-ph

TL;DR: 强系统-浴耦合对量子系统的弛豫动力学产生影响，导致短期动力学加速，而长期动力学则延长。


<details>
  <summary>Details</summary>
Motivation: 强系统-浴耦合将耗散量子系统的弛豫动力学分为两个不同的状态：短期动力学，如预期的那样，随着与环境的耦合增加而加速；以及缓慢动力学，与直觉相反，在足够强的耦合下会越来越延长。

Method: 使用反应坐标极化子变换映射，揭示了该效应的普遍机制，并推导了两种弛豫时间尺度的精确表达式。数值模拟证实了我们的分析预测。

Result: 分析表明，强系统-浴耦合将耗散量子系统的弛豫动力学分为两个不同的状态：短期动力学，如预期的那样，随着与环境的耦合增加而加速；以及缓慢动力学，与直觉相反，在足够强的耦合下会越来越延长。

Conclusion: 强耦合到耗散浴可以自发地产生和维持长寿命的量子相干性，为通过浴工程制备量子态提供了一种有前景的策略。

Abstract: We analytically demonstrate that strong system-bath coupling separates the
relaxation dynamics of a dissipative quantum system into two distinct regimes:
a short-time dynamics that, as expected, accelerates with increasing coupling
to the environment, and a slow dynamics that, counterintuitively, becomes
increasingly prolonged at sufficiently strong coupling. Using the
reaction-coordinate polaron-transform mapping, we uncover the general mechanism
behind this effect and derive accurate expressions for both relaxation
timescales. Numerical simulations confirm our analytical predictions. From a
practical perspective, our results suggest that strong coupling to a
dissipative bath can autonomously generate and sustain long-lived quantum
coherences, offering a promising strategy for bath-engineered quantum state
preparation.

</details>


### [207] [Can entanglement be mediated by a Koopmanian system?](https://arxiv.org/abs/2507.11713)
*Chiara Marletto,Vlatko Vedral*

Main category: quant-ph

TL;DR: 该研究提出了一种将经典系统与量子比特耦合的方法，并证明了该系统不会产生量子纠缠，尽管它违反了守恒定律，这可能对量子引力有影响。


<details>
  <summary>Details</summary>
Motivation: 讨论了其对量子引力半经典处理的启示。

Method: 提出一种将库普曼经典系统与两个量子比特耦合以介导它们之间相互作用的方法。

Result: 证明了由此产生的动力学永远不会导致两个量子比特之间的纠缠。

Conclusion: 该复合系统违反了与预期混合量子-经典系统相符的精确守恒定律。

Abstract: We present a method for coupling a Koopmanian classical system to two quantum
bits to mediate an interaction between them. We then prove that the resulting
dynamics can never lead to entanglement between the two qubits. Even though the
total system of two qubits and the Koopmanian classical system are described
with the full quantum formalism, we show that their composite system violates
exact conservation laws as expected for a hybrid quantum-classical system. We
finally discuss the implications for semi-classical treatments of quantum
gravity.

</details>


### [208] [Non-additive measures for quantum probability?](https://arxiv.org/abs/2507.11735)
*Gabriele Carcassi,Christine A. Aidala*

Main category: quant-ph

TL;DR: Quantum probability is not classical. This paper explores using non-additive measures, a concept from classical physics, to quantify quantum states. It introduces a "quantum measure" and discusses its properties and potential for a new probability calculus, aiming to bridge classical and quantum physics.


<details>
  <summary>Details</summary>
Motivation: The motivation stems from the fundamental difference between quantum and classical probability, where quantum probability does not follow the classical Kolmogorov calculus. While signed measures have been successful, this paper explores the less-trodden path of non-additive measures to quantify the count of quantum states, motivated by the non-additive nature of measures in quantum mechanics, unlike their additive counterparts in classical mechanics.

Method: The paper proposes exploring non-additive measures in quantum mechanics, drawing parallels with classical mechanics where measures define geometric structure. It links the concept to the entropy of uniform distributions and the logarithm of the measure of their support. The study will investigate the properties of this "quantum measure" and explore generalizations of the Radon-Nikodym derivative to develop an extended probability calculus.

Result: The paper aims to present the general idea and open problems related to non-additive measures in quantum mechanics. It will explore the properties of the proposed "quantum measure", discuss its physical reasonableness and mathematical peculiarities, and investigate the need for characterizing properties and a generalization of the Radon-Nikodym derivative for an extended probability calculus.

Conclusion: This paper explores the potential of non-additive measures in quantum mechanics, proposing a generalization of probability calculus that reduces to the standard additive form for distinguishable cases. It aims to bridge the gap between classical and quantum probability by investigating the properties of a "quantum measure" and its mathematical and physical implications.

Abstract: It is well-established that quantum probability does not follow classical
Kolmogorov probability calculus. Various approaches have been developed to
loosen the axioms, of which the use of signed measures is the most successful
(e.g. the Wigner quasiprobability distribution). As part of our larger effort
Assumptions of Physics, we have been considering the various roles of measures,
which are used in physics not only for probability, but also to quantify the
count of possible states and configurations. These measures play a crucial role
in classical mechanics, as they effectively define its geometric structure. If
one tries to construct a parallel in quantum mechanics, the measure to quantify
the count of states turns out to be non-additive. The proper extension of
probability calculus may require the use of non-additive measures, which is
something that, to our knowledge, has not yet been explored. The purpose of
this paper is to present the general idea and the open problems to an audience
that is knowledgeable of the subject of non-additive set functions, though not
necessarily in quantum physics, in the hope that it will spark helpful
discussions. We go through the motivation in simple terms, which stems from the
link between the entropy of a uniform distribution and the logarithm of the
measure associated to its support. If one extends this notion to quantum
mechanics, the associated measure is non-additive. We will explore some
properties of this "quantum measure", its reasonableness in terms of the
physics, but its peculiarity on the math side. We will explore the need for a
set of properties that can properly characterize the measure and a
generalization of the Radon-Nikodym derivative to define a properly extended
probability calculus that reduces to the standard additive one on sets of
physically distinguishable cases (i.e. orthogonal measurement outcomes).

</details>


### [209] [Simultaneous High-Fidelity Single-Qubit Gates in a Spin Qubit Array](https://arxiv.org/abs/2507.11918)
*Yi-Hsien Wu,Leon C. Camenzind,Patrick Bütler,Ik Kyeong Jin,Akito Noiri,Kenta Takeda,Takashi Nakajima,Takashi Kobayashi,Giordano Scappucci,Hsi-Sheng Goan,Seigo Tarucha*

Main category: quant-ph

TL;DR: 通过单个微波线实现了五个硅量子比特的高保真度并行控制，克服了扩展瓶颈。


<details>
  <summary>Details</summary>
Motivation: 为了解决在可扩展量子计算中，硅自旋量子比特在扩展到多量子比特器件时，实现同时多量子比特操作的高保真度控制这一主要挑战。

Method: 利用单个共享微波线和定制控制脉冲，结合仅包含成对校准的校准方案，以补偿驱动引起的相位偏移，实现了对五个硅自旋量子比特的全部并行高保真度控制。

Result: 在对五个硅自旋量子比特的全部并行控制中，实现了高于99.99%的原始π/2门保真度，部分量子比特接近99.999%。即使在同时操作多达三个量子比特时，这些保真度也基本得以保持，并且在全部并行操作五个量子比特时，保真度仍保持在99.9%的实用容错阈值之上。

Conclusion: 该研究通过使用单个共享微波线和定制控制脉冲，成功实现了对五个硅自旋量子比特的全部并行高保真度控制。该方法在减少硬件复杂性的同时，显著提高了量子比特的控制保真度，并为大规模量子计算阵列提供了可扩展的控制策略。

Abstract: Silicon spin qubits are a promising platform for scalable quantum computing
due to their compatibility with industrial semiconductor fabrication and the
recent scaling to multi-qubit devices. Control fidelities above the 99%
fault-tolerant threshold are routinely achieved, but extending high-fidelity
control to simultaneous multi-qubit operation remains a major challenge. We
demonstrate high-fidelity, fully parallel control of five silicon spin qubits
using a single shared microwave line. Using tailored control pulses, all qubits
achieve primitive $\pi/2$ gate fidelities well above 99.99%, with some
approaching 99.999%, exceeding previously reported fidelities in silicon spin
qubits. These fidelities are mostly preserved during simultaneous operation of
up to three qubits, and remain at the practical fault-tolerant threshold of
99.9% even during fully parallel five-qubit operation. This performance is
enabled by a calibration scheme that compensates drive-induced phase shifts
using only pairwise calibrations, scaling quadratically with qubit number and
avoiding exponential overhead. By reducing the number of impedance-controlled
microwave lines, our approach addresses a key architectural bottleneck and
offers a scalable control strategy for high-fidelity operation in large spin
qubit arrays.

</details>


### [210] [The Gorini-Kossakowski-Sudarshan-Lindblad generation theorem](https://arxiv.org/abs/2507.11766)
*Paul E. Lammert*

Main category: quant-ph

TL;DR: The paper explains the GKSL theorem for quantum systems, showing how to generate certain types of evolution (semigroups) using specific mathematical tools, including an extension for systems that change over time.


<details>
  <summary>Details</summary>
Motivation: The paper aims to explain the fundamental paradigm of the Lindblad equation in quantum theory, specifically focusing on the GKSL generation theorem which defines the generators of completely positive trace-preserving semigroups.

Method: The finite-dimensional case is addressed using a Jamio
l{}kowski transform, while the infinite-dimensional case is handled through finite-dimensional approximations. An extension to time-dependent generators is also included.

Result: The paper successfully demonstrates the GKSL generation theorem for both finite and infinite-dimensional cases, deriving the Choi-Kraus presentation and extending the results to time-dependent generators.

Conclusion: This paper provides a comprehensive exposition of the GKSL generation theorem, detailing the conditions under which superoperators can generate completely positive trace-preserving semigroups for open quantum systems.

Abstract: The Lindblad equation embodies a fundamental paradigm of the quantum theory
of open systems, and the Gorini-Kossakowski-Sudarshan-Lindblad (GKSL)
generation theorem says precisely which superoperators can appear on its
right-hand side. These are the generators of completely positive
trace-preserving (or nonincreasing) semigroups. A complete exposition of this
theorem is given. The finite-dimensional case is handled using a form of
Jamio\l{}kowski transform. The treatment requires no previous knowledge of
complete positivity and obtains the Choi-Kraus presentation along the way. The
(separable) infinite-dimensional case is handled by means of a sequence of
finite-dimensional approximations, using the finite-dimensional case as a
crucial tool. An extension to time-dependent generator is also given.

</details>


### [211] [Optomagnonic continuous-variable quantum teleportation enhanced by non-Gaussian distillation](https://arxiv.org/abs/2507.12065)
*Zi-Xu Lu,Xuan Zuo,Zhi-Yuan Fan,Jie Li*

Main category: quant-ph

TL;DR: 利用光镁复合量子传送协议，通过非高斯操作克服弱耦合，实现光态到镁复合态的传送。


<details>
  <summary>Details</summary>
Motivation: 为了在远距离量子节点之间利用光而非微波场传输量子信息，构建混合镁复合量子网络需要光镁复合。

Method: 通过引入非高斯操作（例如，使用辅助微波腔实现对镁复合的新高斯和位移操作）来增强光镁复合纠缠，进而提高传送保真度。

Result: 成功将相干态、单光子态、压缩态和猫态等一系列光态传送到镁复合模式。

Conclusion: 该工作为镁复合量子中继和量子网络提供了实验实现指南，并开辟了一条利用光子到镁复合新路，以实现对镁复合量子态的制备。

Abstract: The capability of magnons to coherently couple with various quantum systems
makes them an ideal candidate to build hybrid quantum systems. The optomagnonic
coupling is essential for constructing a hybrid magnonic quantum network, as
the transmission of quantum information among remote quantum nodes must be
accomplished using light rather than microwave field. Here we provide an
optomagnonic continuous-variable quantum teleportation protocol, which enables
the transfer of an input optical state to a remote magnon mode. To overcome the
currently relatively weak coupling in the experiment, we introduce non-Gaussian
distillation operations to enhance the optomagnonic entanglement and thus the
fidelity of the teleportation. An auxiliary microwave cavity is adopted to
realize the non-Gaussian and displacement operations on magnons. We show that a
series of optical states, such as coherent, single-photon, squeezed and cat
states, can be teleported to the magnon mode. The work provides guidance for
the experimental realization of magnonic quantum repeaters and quantum networks
and a new route to prepare diverse magnonic quantum states exploiting the
photon-to-magnon quantum teleportation.

</details>


### [212] [Analyzing the free states of one quantum resource theory as resource states of another](https://arxiv.org/abs/2507.11793)
*Andrew E. Deneris,Paolo Braccia,Pablo Bermejo,N. L. Diaz,Antonio A. Mele,M. Cerezo*

Main category: quant-ph

TL;DR: 本研究分析了量子资源理论中自由态在多方纠缠、费米子非高斯性等多个理论中的资源性，揭示了跨理论分析的复杂性。


<details>
  <summary>Details</summary>
Motivation: 随着量子资源理论（QRTs）的发展，人们开始关注将一个QRT中的自由态置于另一个QRT的框架下进行评估，这可能揭示其潜在的资源属性。这种跨理论的视角促使了对不同QRTs之间状态进行表征的研究。本工作旨在为这一领域贡献力量，通过分析自由态在多个特定QRTs中的资源性。

Method: 本研究通过分析自由态在多个量子资源理论中的表现，跨越了多方纠缠、费米子非高斯性、虚数性、实数性、自旋相干性、Clifford非稳定太性、$S_n$-等变性以及非均匀纠缠等理论。研究结合了严格的理论推导和数值模拟，以揭示跨理论分析的现象。

Result: 研究结果表明，在跨理论分析中，自由态的行为表现出丰富且复杂的特性。理论研究和数值模拟均证实了这一点，为理解不同量子资源理论之间的相互作用提供了见解。

Conclusion: 本研究对量子资源理论（QRTs）中的自由态在多个量子资源理论（包括多方纠缠、费米子非高斯性、虚数性、实数性、自旋相干性、Clifford非稳定太性、$S_n$-等变性以及非均匀纠缠）的见证之间进行分析，提供了严格的理论结果和数值研究，揭示了跨理论分析的丰富复杂行为。

Abstract: In the context of quantum resource theories (QRTs), free states are defined
as those which can be obtained at no cost under a certain restricted set of
conditions. However, when taking a free state from one QRT and evaluating it
through the optics of another QRT, it might well turn out that the state is now
extremely resourceful. Such realization has recently prompted numerous works
characterizing states across several QRTs. In this work we contribute to this
body of knowledge by analyzing the resourcefulness in free states for--and
across witnesses of--the QRTs of multipartite entanglement, fermionic
non-Gaussianity, imaginarity, realness, spin coherence, Clifford
non-stabilizerness, $S_n$-equivariance and non-uniform entanglement. We provide
rigorous theoretical results as well as present numerical studies that showcase
the rich and complex behavior that arises in this type of cross-examination.

</details>


### [213] [Mobility rings in a non-Hermitian non-Abelian quasiperiodic lattice](https://arxiv.org/abs/2507.12176)
*Rui-Jie Chen,Guo-Qing Zhang,Zhi Li,Dan-Wei Zhang*

Main category: quant-ph

TL;DR: 研究了自旋1/2非互易Aubry-Andr'e链中的非厄米拓扑相变和迁移率环。


<details>
  <summary>Details</summary>
Motivation: 研究自旋1/2非互易Aubry-Andr'e链在SU(2)非阿贝尔人工规范场下的局域化和拓扑性质。

Method: 基于拓扑性质，我们得到了迁移率环的精确表达式。此外，我们还数值研究了相应的指标，如反向参与率、归一化参与率、缠绕数、非厄米谱结构和波函数。

Result: 数值结果与解析表达式吻合良好，证实了迁移率环的出现。

Conclusion: 研究揭示了在SU(2)非阿贝尔人工规范场下的自旋1/2非互易Aubry-Andr'e链中，与阿贝尔情况不同，非阿贝尔情况会出现迁移率环，并伴随着非厄米拓扑相变。这些迁移率环是迁移率边的非厄米推广，在周期性边界条件下，它们将安德森局域化态与扩展态在复能量平面上分离开来。

Abstract: We study localization and topological properties in spin-1/2 non-reciprocal
Aubry-Andr\'{e} chain with SU(2) non-Abelian artificial gauge fields. The
results reveal that, different from the Abelian case, mobility rings, will
emerge in the non-Abelian case accompanied by the non-Hermitian topological
phase transition. As the non-Hermitian extension of mobility edges, such
mobility rings separate Anderson localized eigenstates from extended
eigenstates in the complex energy plane under the periodic boundary condition.
Based on the topological properties, we obtain the exact expression of the
mobility rings. Furthermore, the corresponding indicators such as inverse
participation rate, normalized participation ratio, winding number,
non-Hermitian spectral structures and wave functions are numerically studied.
The numerical results are in good agreement with the analytical expression,
which confirms the emergence of mobility rings.

</details>


### [214] [Tripartite Entanglement in Multimode Cavity Quantum Electrodynamics](https://arxiv.org/abs/2507.11885)
*Nishan Amgain,Mahir Rahman,Umar Arshad,Fernando Romero Consuegra,Emil Sayahi,Imran M. Mirza*

Main category: quant-ph

TL;DR: 通过数值模拟，研究了多模腔量子电动力学中三方纠缠的生成、动力学及其影响因素（模式数量、比特位置、损耗），并发现了可控的纠缠动力学和优于单/双激发的纠缠性能，为量子网络和量子存储提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 为了在多模腔量子电动力学（cQED）架构中，研究三方纠缠的生成和动力学，特别是纠缠与腔模式数量、比特位置以及损耗（自发辐射和光子泄漏）等因素之间的关系。

Method: 采用数值模拟方法，研究了多模腔量子电动力学（cQED）中比特（量子发射体或原子）三方纠缠的生成和动力学。利用三方负熵和与真实三方纠缠态（绿berger-Horne-Zeilinger态）的保真度来分析模式数量、比特位置和损耗（自发辐射和光子泄漏）的影响。

Result: 数值结果揭示了两种延迟效应：光子在比特间传播的时间和光子在腔内完成一个来回的时间。这些效应仅在多模腔中观察到，并且可以通过改变腔内比特的位置来控制三方纠缠的塌缩和复兴模式。此外，损耗对生成纠缠的影响以及最大纠缠与总模式数量的依赖性，其结果优于单激发和双激发的情况。

Conclusion: 该研究为基于纠缠的量子网络协议和量子存储器的发展提供了希望，特别是在腔量子电动力学（cQED）领域，展示了通过操纵腔模式、比特位置和损耗来控制三方纠缠动力学的潜力。

Abstract: We numerically investigate the generation and dynamics of tripartite
entanglement among qubits (quantum emitters or atoms) in multimode cavity
quantum electrodynamics (cQED). Our cQED architecture features three initially
unentangled excited two-level quantum emitters confined within a
triangle-shaped multimode optical cavity, which later become entangled due to a
Jaynes-Cummings-like interaction. Using the tripartite negativity measure of
entanglement and fidelity with respect to the genuine tripartite entangled
state (Greenberger-Horne-Zeilinger (or GHZ) state, to be precise), we analyze
the impact of the number of cavity modes, qubit locations, and losses
(spontaneous emission from qubits and photon leakage from the cavity mirrors)
on the generated entanglement. Our key results include the presence of two
kinds of retardation effects: one resulting from the time it takes for photons
to propagate from one qubit to another, and the other to complete one round
trip in the cavity. We observed these retardation effects only in multimode
cavities, with the exciting possibility of controlling the collapse and revival
patterns of tripartite entanglement by altering the qubit locations in the
cavity. Furthermore, the impact of losses on the generated entanglement and the
dependence of maximum entanglement on the total number of modes yield results
that surpass those reported for single and two excitations. With recent
advances in circuit quantum electrodynamics, these findings hold promise for
the development of entanglement-based quantum networking protocols and quantum
memories.

</details>


### [215] [Observation of quantum noise reduction in a Raman amplifier via quantum correlation between atom and light](https://arxiv.org/abs/2507.11890)
*Jianmin Wang,Rong Zhu,Yue Li,Z. Y. Ou*

Main category: quant-ph

TL;DR: 实验通过制备原子与光场的关联态，实现了拉曼放大器超过3.5dB的量子噪声抑制，并展示了其在量子传感和测量方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 放大器在放大能量的同时会引入量子噪声，但若能操控放大器的内部自由度，则可以管理甚至降低输出端的量子噪声。

Method: 通过制备原子介质与斯托克斯光场的关联态，实验演示了降低拉曼放大器的量子噪声。

Result: 实验实现了超过3.5dB的量子噪声抑制，并将拉曼放大器作为测量原子与光量子关联的工具，同时该方案构成了一个量子纠缠原子-光混合干涉仪。

Conclusion: 该方案为量子增强型传感器提供了基础，可实现超过3.5dB的量子噪声抑制。

Abstract: Any amplifier requires coupling to its internal degrees of freedom for energy
gain. This coupling introduces extra quantum noise to the output. On the other
hand, if the internal degree of the amplifier can be accessed and manipulated,
we can manage and even reduce the quantum noise of the amplifier's output. In
this paper, we present an experiment to reduce the quantum noise of a Raman
amplifier by preparing the atomic medium in a correlated state with the Stokes
light field. We report an observation of quantum noise reduction of more than
3.5 dB in the atomic Raman amplification process. From another perspective, the
Raman amplifier at high gain in turn serves as a measurement tool for the
quantum correlation between the atom and light. Furthermore, such a scheme,
when viewed as a whole, also forms a quantum-entangled atom-light hybrid
interferometer that can lead to quantum-enhanced sensors.

</details>


### [216] [Hybrid quantum lattice model: Polaritons, photons, and spin waves propagation](https://arxiv.org/abs/2507.12319)
*Maritza Ahumada,Natalia Valderrama-Quinteros,Diego Tancara,Guillermo Romero*

Main category: quant-ph

TL;DR: 通过调整参数控制量子链中激发的传播和交换。


<details>
  <summary>Details</summary>
Motivation: 控制低维量子系统中的量子激发传播对于推进量子通信网络和量子模拟器等量子技术至关重要。

Method: 利用时间演化块 जेव्हा (TEBD) 算法模拟混合量子链动力学，并通过局部可观测量分析激发传输特性。

Result: 通过 TEBD 模拟，研究发现通过匹配阻抗和共振条件可以控制极化激元、自旋波和光子等不同类型激发的传播，或沿着混合链交换激发性质。

Conclusion: 该研究揭示了通过调整系统参数（如阻抗匹配和共振条件）来控制不同类型激发在混合量子链中的传播，或实现激发性质交换的重要性，为设计可控的量子链路和单激发交换提供了思路。

Abstract: Controlling the propagation of quantum excitations in low-dimensional quantum
systems is pivotal for advancing quantum technologies, including communication
networks and quantum simulators. We propose a one-dimensional hybrid quantum
lattice model comprising coupled cavity quantum electrodynamics (QED) units.
Each unit integrates a single-mode cavity that interacts with a two-level
system (TLS), featuring direct coupling between adjacent TLLs. This
configuration enables the coherent propagation of polaritons, spin waves, and
photons, depending on the interplay between light-matter coupling and spin-spin
interactions. Employing the time-evolving block decimation (TEBD) algorithm, we
simulate the dynamics of various excitation configurations and analyze their
transport characteristics using local observables. Our analysis reveals the
importance of matching impedance and resonance conditions via system parameters
for the propagation of different types of excitations or swapping the nature of
excitations along the hybrid lattice. These findings offer insight into
designing controllable quantum links and single-excitation swaps in
low-dimensional quantum systems.

</details>


### [217] [Noise-induced Quantum Mpemba effect](https://arxiv.org/abs/2507.11915)
*Mingrui Zhao,Zhonghuai Hou*

Main category: quant-ph

TL;DR: 噪声会影响量子马姆巴效应，可以诱发或消除它，并可能减慢退相干速率。


<details>
  <summary>Details</summary>
Motivation: 解决各种噪声如何影响量子马姆巴效应这一未知问题。

Method: 通过构建一个适用于随机电报噪声下d层开放量子系统的通用动力学框架，并研究扩展系统的动力学然后进行投影。

Result: 噪声可以诱导额外的模式并强烈影响原始系统的弛豫动力学，在某些初始状态下会导致异常减慢，从而诱发或消除量子马姆巴效应。在噪声相关时间长的极限下，会产生反直觉的效应：噪声可能减慢退相干速率。

Conclusion: 噪声可以诱导额外的模式并强烈影响原始系统的弛豫动力学，在某些初始状态下会导致异常减慢，从而诱发或消除量子马姆巴效应。特别地，在噪声相关时间长的极限下，会产生反直觉的效应：噪声可能减慢退相干速率。

Abstract: The quantum Mpemba effect (QMPE), an intriguing anomalous relaxation
phenomenon, has recently attracted significant attention. However, how various
types of noise, which are ubiquitous in real systems, may affect the QMPE
remains unknown. Here, we address this gap by constructing a general dynamical
framework for d level open quantum systems under random telegraph noise. By
investigating the dynamics of an extended system and then projecting back, we
find that noise can induce additional modes and strongly influence the
relaxation dynamics of the original system. Specially, in the limit of long
correlation time of noise, these modes cause anomalous slowdown for certain
initial states, thereby inducing or eliminating QMPE, illustrated by a
three-level example system. Interestingly, this mechanism leads to a counter
intuitive effect:the decoherence rate may be slowed down by noise.

</details>


### [218] [Jenga-Krotov algorithm: Efficient compilation of multi-qubit gates for exchange-only qubits](https://arxiv.org/abs/2507.12448)
*Jiahao Wu,Guanjie He,Wenyuan Zhuo,Quan Fu,Xin Wang*

Main category: quant-ph

TL;DR: 使用 Jenga-Krotov (JK) 优化算法，将实现 Toffoli 门所需的交换操作数量减少了一半以上，并大大缩短了操作时间，同时保持了高保真度，为在半导体平台上实现多量子比特算法铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 传统的 Toffoli 门等高效多量子比特门操作的综合仍然是一个关键瓶颈，因为其脉冲序列冗长且易出错。

Method: 提出了一种名为 Jenga-Krotov (JK) 的梯度优化算法，用于发现紧凑、高保真的 EO 量子比特门序列。

Result: 将 Toffoli 门的必需交换幺正操作从 216 个减少到 92 个，并将所需时间步从 162 个压缩到 50 个，同时保持目标保真度。在实际噪声下，优化序列的累积门误差比传统方法低一个数量级。

Conclusion: 该研究证明了 Jenga-Krotov (JK) 算法是一种用于 EO 体系结构中多量子比特门综合的通用且可扩展的策略，有望在半导体平台上实现多量子比特算法。

Abstract: Exchange-only (EO) qubits, implemented in triple-quantum-dot systems, offer a
compelling platform for scalable semiconductor-based quantum computing by
enabling universal control through purely exchange interactions. While
high-fidelity single- and two-qubit gates have been demonstrated, the synthesis
of efficient multi-qubit operations -- such as the Toffoli gate -- remains a
key bottleneck. Conventional gate decompositions into elementary operations
lead to prohibitively long and error-prone pulse sequences, limiting practical
deployment. In this work, we introduce a gradient-based optimization algorithm,
Jenga-Krotov (JK), tailored to discover compact, high-fidelity EO gate
sequences. Applying JK to the Toffoli gate, we reduce the number of required
exchange unitaries from 216 (in standard decomposition) to 92, and compress the
time steps required from 162 to 50, all while maintaining target fidelity.
Under realistic noise, the accumulated gate error from our optimized sequence
is an order of magnitude lower than that of conventional approaches. These
results demonstrate that the JK algorithm is a general and scalable strategy
for multi-qubit gate synthesis in EO architectures, potentially facilitating
realization of multi-qubit algorithms on semiconductor platforms.

</details>


### [219] [Measurement-Induced Phase Transition in a Disordered XX Spin Chain: A Real-Space Renormalization Group Study](https://arxiv.org/abs/2507.11957)
*Siddharth Tiwary,Joel E. Moore*

Main category: quant-ph

TL;DR: 研究了带随机测量的XX自旋链，并提出了一种新的RSRG-X方法，发现了由非幺正性引起的新型强无序不动点。


<details>
  <summary>Details</summary>
Motivation: 研究在随机测量（非厄米退相干）存在的情况下，淬灭无序自旋链的物理性质，探索测量与幺正动力学之间的相互作用如何产生新的相和相变。

Method: 通过将受监测链映射到具有复杂耦合的非厄米自旋梯，提出了一种适用于开放系统的RSRG-X方法。

Result: 分析显示，在随机测量下，XX自旋链会出现一类新的强无序不动点。

Conclusion: 该研究揭示了由于非幺正性出现的一类新的强无序不动点，拓宽了RSRG可及的临界现象范围。

Abstract: Spin chains with quenched disorder exhibit rich critical behavior, often
captured by real-space renormalization group (RSRG) techniques. However, the
physics of such systems in the presence of random measurements (i.e.,
non-Hermitian dephasing) remains largely unexplored. The interplay between
measurements and unitary dynamics gives rise to novel phases and phase
transitions in monitored quantum systems. In this work, we investigate the
disordered XX spin chain subject to stochastic local measurements in the $X$
and $Y$ bases. By mapping the monitored chain to a non-Hermitian spin ladder
with complex couplings, we propose an RSRG-for-excited-states (RSRG-X) approach
for this open-system setting. Our analysis reveals a new class of strongly
disordered fixed points that emerge due to non-unitarity, broadening the
landscape of critical phenomena accessible via RSRG.

</details>


### [220] [Obfuscation of Unitary Quantum Programs](https://arxiv.org/abs/2507.11970)
*Mi-Ying Huang,Er-Cheng Tang*

Main category: quant-ph

TL;DR: 本研究提出了一种新的量子态混淆方法，首次实现了对量子输入和输出的量子程序的混淆。


<details>
  <summary>Details</summary>
Motivation: 在量子计算领域，程序混淆旨在隐藏程序的内部工作原理同时保持其功能。虽然现有研究已在特定类别的量子电路上实现了混淆，但本研究旨在改进现有结果，提出首个支持量子输入和输出的量子态混淆方案。

Method: 通过设计一个功能性量子认证方案和一个编译器来实现混淆。该认证方案允许密钥持有者在模拟安全下学习认证量子态的特定函数。该编译器将任意量子电路表示为一种量子程序，该程序由非自适应克利福德门和自适应且兼容的测量序列组成。

Result: 成功构建了首个支持量子输入和输出的量子态混淆方案，并提出了一种功能性量子认证方案和一个将任意量子电路表示为特定量子程序的编译器。

Conclusion: 本研究提出了首个支持量子输入和输出的量子态混淆方案，改进了现有针对伪确定性量子程序在经典预言机模型下的混淆方案。

Abstract: Program obfuscation aims to hide the inner workings of a program while
preserving its functionality. In the quantum setting, recent works have
obtained obfuscation schemes for specialized classes of quantum circuits. For
instance, Bartusek, Brakerski, and Vaikuntanathan (STOC 2024) constructed a
quantum state obfuscation scheme, which supports the obfuscation of quantum
programs represented as quantum states for pseudo-deterministic quantum
programs with classical inputs and outputs in the classical oracle model.
  In this work, we improve upon existing results by constructing the first
quantum state obfuscation scheme for unitary (or approximately unitary) quantum
programs supporting quantum inputs and outputs in the classical oracle model.
At the core of our obfuscation scheme are two novel ingredients: a functional
quantum authentication scheme that allows key holders to learn specific
functions of the authenticated quantum state with simulation-based security,
and a compiler that represents an arbitrary quantum circuit as a projective
linear-plus-measurement quantum program described by a sequence of non-adaptive
Clifford gates interleaved with adaptive and compatible measurements.

</details>


### [221] [QAS-QTNs: Curriculum Reinforcement Learning-Driven Quantum Architecture Search for Quantum Tensor Networks](https://arxiv.org/abs/2507.12013)
*Siddhant Dutta,Nouhaila Innan,Sadok Ben Yahia,Muhammad Shafique*

Main category: quant-ph

TL;DR: 本研究提出了一种结合量子强化学习和量子课程学习的量子架构搜索（QAS）框架，并通过实验证明了其在优化量子电路方面相对于经典方法的优越性，尤其是在处理更复杂的量子系统时。


<details>
  <summary>Details</summary>
Motivation: 量子架构搜索（QAS）是一个旨在自动化量子电路设计以获得最佳性能的新兴领域。本研究旨在开发一种更有效的QAS框架，以应对日益复杂的量子电路设计任务。

Method: 本研究提出了一种新的量子架构搜索（QAS）框架，该框架结合了混合量子强化学习和量子课程学习策略。具体来说，研究基准测试了四种先进的经典强化学习算法（A2C, PPO, DDQN, TD3）及其量子增强版本（QA2C, QPPO, QDDQN, QTD3），以优化变分量子电路（VQC）。该方法通过逐步增加电路深度和门复杂度来训练学习代理，并使用参数化量子电路作为函数逼近器。为了提高学习效率和稳定性，所有算法（包括经典和量子）都采用了优先经验回放（PER）。

Result: 实验结果表明，量子增强强化学习在优化变分量子电路方面显著优于经典方法。在2量子比特环境中，PERQDDQN的成功概率为0.46，最优成功次数约3000次，优于经典PERDDQN（0.42，约2400次）。在更复杂的3量子比特环境中，PERQDDQN和PERQTD3的成功概率均达到约0.47，最优成功次数分别约为3800和3600次，表现优于其经典对应算法。此外，将QAS-QTN方法应用于分类问题时，优化后的量子电路准确率达到90.33%，优于随机酉量子模型。

Conclusion: 本研究提出的混合量子强化学习与量子课程学习相结合的量子架构搜索（QAS）框架，在优化变分量子电路（VQC）方面显著优于纯经典强化学习方法，能够更高效、更稳定地设计出性能更优的量子电路。

Abstract: Quantum Architecture Search (QAS) is an emerging field aimed at automating
the design of quantum circuits for optimal performance. This paper introduces a
novel QAS framework employing hybrid quantum reinforcement learning with
quantum curriculum learning strategies, enabling learning agents to tackle
increasingly complex quantum circuit design tasks. We benchmark four
state-of-the-art classical reinforcement learning algorithms (A2C, PPO, DDQN,
TD3) against their quantum-enhanced counterparts (QA2C, QPPO, QDDQN, QTD3) for
optimizing variational quantum circuits (VQCs). Our approach progressively
increases circuit depth and gate complexity during training, leveraging
parameterized quantum circuits as function approximations. To improve learning
efficiency and stability, all algorithms, both classical and quantum, are
augmented with Prioritized Experience Replay (PER). Experimental results show
that quantum-enhanced RL significantly outperforms classical methods. In a
2-qubit environment, PERQDDQN achieves a success probability of 0.46 with
~3,000 optimal successes, surpassing classical PERDDQN (0.42, ~2,400). In the
more complex 3-qubit setting, PERQDDQN and PERQTD3 reach success probabilities
of ~0.47, with optimal success counts of ~3,800 and ~3,600, respectively,
outperforming their classical counterparts. Additionally, we apply our QAS-QTN
approach to a classification problem, where the optimized quantum circuit
achieves an accuracy of 90.33\%, outperforming quantum models consisting of
random ansatz. This hybrid classical-quantum approach leads to faster
convergence and more efficient quantum circuit designs, demonstrating its
potential for advancing automated quantum architecture search.

</details>


### [222] [Extending the Limited Performance of the Quantum Refrigerator with Catalysts](https://arxiv.org/abs/2507.12016)
*Cong Fu,Ousi Pan,Zhiqiang Fan,Yushun Tang,Shanhe Su,Youhui Lin,Jincan Chen*

Main category: quant-ph

TL;DR: 通过利用催化剂，研究人员演示了一种量子冰箱，其性能超越了传统限制，并且可以在更广泛的条件下运行。


<details>
  <summary>Details</summary>
Motivation: 量子热力学机器在探索微观尺度上热力学的基本极限方面提供了有希望的平台。

Method: 研究了一个由两个双态系统（TLS）和两个不同温度的热库组成的工作介质，并借助充当催化剂的辅助系统来操作的二冲程量子冰箱。

Result: 催化剂的存在使性能系数（COP）超越了奥托界限，并允许制冷器在没有催化剂的情况下无法进入的频率和温度状态下运行。

Conclusion: 催化剂能够超越奥托界限，并在没有催化剂的情况下无法进入的频率和温度状态下运行制冷器。这些结果突显了催化机制在拓宽量子热设备的运行能力和超越传统热力学性能极限方面的潜力。

Abstract: Quantum thermal machines offer promising platforms for exploring the
fundamental limits of thermodynamics at the microscopic scale. Here, we study a
two-stroke quantum refrigerator that extracts heat from a cold reservoir via
discrete strokes powered by external work. The working medium consists of two
two-level systems (TLSs) and two heat reservoirs at different temperatures and
is assisted by an auxiliary system acting as a catalyst. Remarkably, the
catalyst remains unchanged after each cycle, ensuring that heat extraction is
driven entirely by the work input. We show that the presence of the catalyst
leads to two significant enhancements: it enables the coefficient of
performance (COP) to exceed the Otto bound and allows the refrigerator to
operate in frequency and temperature regimes that are inaccessible without a
catalyst. These results highlight the potential of catalytic mechanisms to
broaden the operational capabilities of quantum thermal devices and to surpass
conventional thermodynamic performance limits.

</details>


### [223] [Channel capacity of small modular quantum networks in the ultrastrongly coupled regime](https://arxiv.org/abs/2507.12020)
*Salvatore Alex Cordovana,Luigi Giannelli,Nicola Macrì,Giuliano Benenti,Elisabetta Paladino,Giuseppe A. Falci*

Main category: quant-ph

TL;DR: Modular quantum computers can achieve high capacity and robustness using ultrastrong coupling and adiabatic transport, mitigating leakage from the dynamical Casimir effect.


<details>
  <summary>Details</summary>
Motivation: To investigate state-transfer in modular quantum computer architectures exploiting the ultrastrong coupling regime.

Method: Investigate state-transfer in modular quantum computer architectures exploiting the ultrastrong coupling regime of interaction between quantum processing units and ICs.

Result: Protocols based on adiabatic coherent transport may achieve near-ideal single-letter quantum capacity and robustness against parametric fluctuations suppressing leakage induced by the dynamical Casimir effect.

Conclusion:  Adiabatic coherent transport protocols achieve near-ideal single-letter quantum capacity and robustness against parametric fluctuations by suppressing leakage induced by the dynamical Casimir effect.

Abstract: We investigate state-transfer in modular quantum computer architectures
exploiting the ultrastrong coupling regime of interaction between quantum
processing units and ICs. We show that protocols based on adiabatic coherent
transport may achieve near-ideal single-letter quantum capacity and robustness
against parametric fluctuations suppressing leakage induced by the dynamical
Casimir effect.

</details>


### [224] [Benchmarking fault-tolerant quantum computing hardware via QLOPS](https://arxiv.org/abs/2507.12024)
*Linghang Kong,Fang Zhang,Jianxin Chen*

Main category: quant-ph

TL;DR: 提出QLOPS作为评估FTQC方案性能的度量标准，该框架整合了码率、解码器准确性、吞吐量和延迟等因素，并考虑了实际应用需求。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏一个用于分析和评估不同FTQC方案的全面框架。

Method: 提出了一种名为“量子逻辑操作每秒”（QLOPS）的度量标准，用于评估量子硬件平台上的FTQC方案性能。该基准测试框架整合了关键的相关因素，例如量子纠错码的码率、解码器的准确性、吞吐量和延迟，并反映了量子算法执行的实际需求。

Result: QLOPS度量标准能够评估FTQC方案在量子硬件平台上的性能，并考虑了实际应用需求。

Conclusion: 该框架能够识别量子硬件中的瓶颈，为硬件开发提供潜在方向，并为评估FTQC设计建立比较框架。该基准测试方法考虑了实际应用，有助于估算实施量子算法所需的硬件资源，并为潜在的时间线提供初步见解。

Abstract: It is widely recognized that quantum computing has profound impacts on
multiple fields, including but not limited to cryptography, machine learning,
materials science, etc. To run quantum algorithms, it is essential to develop
scalable quantum hardware with low noise levels and to design efficient
fault-tolerant quantum computing (FTQC) schemes. Currently, various FTQC
schemes have been developed for different hardware platforms. However, a
comprehensive framework for the analysis and evaluation of these schemes is
still lacking. In this work, we propose Quantum Logical Operations Per Second
(QLOPS) as a metric for assessing the performance of FTQC schemes on quantum
hardware platforms. This benchmarking framework will integrate essential
relevant factors, e.g., the code rates of quantum error-correcting codes, the
accuracy, throughput, and latency of the decoder, and reflect the practical
requirements of quantum algorithm execution. This framework will enable the
identification of bottlenecks in quantum hardware, providing potential
directions for their development. Moreover, our results will help establish a
comparative framework for evaluating FTQC designs. As this benchmarking
approach considers practical applications, it may assist in estimating the
hardware resources needed to implement quantum algorithms and offers
preliminary insights into potential timelines.

</details>


### [225] [A resource-centric, task-based approach to quantum network control](https://arxiv.org/abs/2507.12030)
*Alexander Pirker,Belen Munoz,Wolfgang Dür*

Main category: quant-ph

TL;DR: 量子网络需要新的管理方式。该论文提出了一种资源中心化的任务驱动方案，将目标分解为分布式工作流（saga），而不是使用传统的层次化分层方案。


<details>
  <summary>Details</summary>
Motivation: 量子网络与经典网络存在根本性差异，需要新的组织、管理和操作原则。

Method: 提出了一种资源中心化的任务驱动方案，将量子应用的目标分解为分布式工作流（saga），其中包含在量子网络资源（如经典消息、量子信道和纠缠）上运行的任务。

Result: 该方案将量子应用的目标分解为分布式工作流（saga），每个工作流包含在量子网络资源上运行的任务，这些任务可以包括操作、测量，甚至其他协议。

Conclusion: 该论文提出了一种资源中心化的任务驱动方案，用于组织和管理量子网络设备的操作，这与传统的层次化分层方案不同。

Abstract: Quantum networks exhibit fundamental differences from their classical
counterparts. These differences necessitate novel principles when organizing,
managing, and operating them. Here we propose an unconventional approach to
organize and manage the operations of quantum network devices. Instead of a
hierarchical scheme using layers, like in classical networks and present
quantum network stack models, we propose a resource-centric task-based scheme.
In this scheme, quantum applications pose objectives, initiated by a node, to a
quantum network, such as sharing an entangled state or sending a qubit along a
path. The quantum network node initiating the objective consequently derives a
distributed workflow, referred to as saga, comprising numerous tasks operating
on resources, which completes the objective. We identify three different kinds
of resources with their own and independent topology, namely classical
messaging, quantum channels and entanglement. Sagas can either be centrally
orchestrated or performed in choreography by the network nodes. The tasks of a
saga originate from and operate on resources of the network, such as quantum
channels or entanglement, and they not only comprise operations and
measurements, but potentially also include other tasks or even entire
protocols, such as sending a qubit, distributing entanglement or performing
entanglement purification steps.

</details>


### [226] [Selective decoupling in multi-level quantum systems by the SU(2) sign anomaly](https://arxiv.org/abs/2507.12056)
*Giorgio Anfuso,Giulia Piccitto,Vittorio Romano,Elisabetta Paladino,Giuseppe Falci*

Main category: quant-ph

TL;DR: Selective decoupling in quantum networks is achieved using $2	ext{	extpi}$-pulses, enabling control over interactions and decoherence when direct control is limited.


<details>
  <summary>Details</summary>
Motivation: The motivation is to provide a flexible strategy for decoupling transitions in a quantum network, especially when direct control over these transitions is not available.

Method: The study investigates dynamical decoupling using $2	ext{	extpi}$-pulses within a two-level subspace of a multilevel system.

Result: The research shows that selective decoupling can be achieved through this method, which can be used to control internode interactions or actively suppress decoherence.

Conclusion: The paper concludes that dynamical decoupling operated by $2	ext{	extpi}$-pulses in a two-level subspace of a multilevel system can lead to selective decoupling, offering a flexible strategy for controlling internode interactions or suppressing decoherence in quantum networks when direct control is unavailable.

Abstract: We investigate dynamical decoupling operated by $2\pi$-pulses in a two-level
subspaces of a multilevel system showing that it may leads to selective
decoupling. This provides a flexible strategy for decoupling transitions in a
quantum network, when control to directly address them is not available which
can be use to control internode interaction or actively suppress decoherence

</details>


### [227] [Generation of Near-ideal Indistinguishable Two-Photon State by Incoherent Light](https://arxiv.org/abs/2507.12066)
*Yue-Wei Song,Ming-Yuan Gao,Zhi-Cheng Guo,Zheng-He Zhou,Yin-Hai Li,Guang-Can Guo,Zhi-Yuan Zhou,Bao-Sen Shi*

Main category: quant-ph

TL;DR: 本研究证明了使用不相干光源（通过放大自发辐射光的频率倍增）可以制备出高度不可区分的光子量子态，其Hong-Ou-Mandel干涉可见度高达99.1%，这挑战了传统上认为相干泵浦是必需的观点，并为利用易于获得的不相干光源工程化高质量量子源提供了一种可行方法。


<details>
  <summary>Details</summary>
Motivation: 光子不可区分性是实现从光子量子计算到精密计量等先进量子信息处理应用的关键。Hong-Ou-Mandel（HOM）干涉效应是量化光子不可区分性的有力方法，其可见度是评价光源质量的终极标准。然而，目前量子技术普遍认为相干泵浦是制备量子光源的必要条件，这限制了不相干光源的应用。因此，本研究旨在探索利用不相干光源制备高质量量子态的可能性。

Method: 通过对放大自发辐射光进行频率倍增来产生不相干光，并利用其制备了可区分的二光子量子态。对理论进行了分析，发现在二光子强度干涉中，泵浦相位随机化不影响符合可见度，而时间相干性则增强了二次谐波产生中光谱的对称性。实验中，测量了由不相干光源产生的二光子态的涌现效率（约60%）和符合-意外比（超过15000），并观察到Hong-Ou-Mandel（HOM）干涉条纹，可见度高达99.1%，无需进行光谱滤波。

Result: 实验结果显示，该不相干泵浦光子源具有约60%的涌现效率和超过15000的符合-意外比。在没有进行光谱滤波的情况下，观察到的HOM干涉条纹可见度达到了99.1%，证明了光子接近理想的不可区分性。

Conclusion: 该研究揭示了相干泵浦对于制备高质量量子源并非必需，并展示了如何利用易于获取的不相干光源来制备高质量量子态，为量子信息处理开辟了新的途径。

Abstract: High-quality quantum states lie at the heart of advanced quantum information
processing. The degree of photon indistinguishability is critical for
applications from photonic quantum computation to precision metrology. The
two-photon Hong-Ou-Mandel (HOM) interference effect provides a rigorous
quantification method, with its visibility serving as the ultimate benchmark
for source quality. Generally, the coherent pumping is widely regarded as
indispensable for the preparation of quantum sources. As a result, incoherent
light sources have seen limited applications in the current quantum
technologies. In this work, we generate an indistinguishable two-photon state
by incoherent light generated by frequency doubling of Amplified Spontaneous
Emission light. The theoretical analysis indicates that phase randomization of
the pumping does not affect the coincidence visibility in two-photon intensity
interference. Moreover, temporal incoherence further enhances the symmetry of
the generated spectrum in second-harmonic generation. In the experiment, the
incoherently pumped photon sources exhibit a heralding efficiency of
approximately 60\% and a coincidence-to-accidental ratio exceeding 15000. The
observed HOM interference fringes show the visibility of 99.1\% without any
spectrum filtering, confirming the near-ideal indistinguishability of the
photons. Our study reveals the role of temporal coherence in second-order
nonlinear interactions, it provide a potential approach to use an easily
accessible incoherent light for engineering high-quality quantum sources.

</details>


### [228] [A thermofield-double model of Uhlmann anholonomy](https://arxiv.org/abs/2507.12071)
*Péter Lévay,Csaba Velich*

Main category: quant-ph

TL;DR: 本文研究了量子系统的几何演化，利用 Uhlmann 条件和热场双重形式主义，分析了不同观测者视角下的演化行为，并将几何演化与量子计算（如全息量子计算和 iSWAP 门）联系起来。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨量子系统的几何演化及其与不同观测者的关系。

Method: 本文考虑了一个由两个纠缠的子系统（称为左和右子系统）组成的简单参数化量子系统，每个子系统都具有 N 个量子比特，并置于热场双重形式主义中。我们假设系统是根据 Uhlmann 的平行传输条件以纯粹的几何方式演化的。我们探讨了相对于耦合到左子系统或右子系统的观测者而言，该演化的不同解释。Uhlmann 条件通过将两个可能的局部酉操作集视为规范自由度来打破左右子系统之间的对称性。

Result: 通过规范右侧，我们表明左侧的几何演化通过类似于非酉滤波测量的局部操作显现出来。另一方面，在右侧，基本的演化步骤被组织成一系列全息量子计算的酉操作。我们计算了控制我们模型传输的 Uhlmann 连接，事实证明它与高维瞬子有关。然后，我们评估了对于以 Bures 度量定义的测地线段的测地线三角形的连接的单节性。通过分析左侧出现的局部滤波测量的显式形式，我们意识到它们在统计意义上也是区分两个给定混合态的最佳测量。我们还指出，通过在右侧进行干涉实验，可以观察到单节性量子计算的物理效应。我们通过计算相移和由此产生的干涉实验中的可见度模式的显式示例来证明这一点。

Conclusion: 最后，我们提出了一个由测地线三角形组成的序列，通过单节性（anholonomy）产生 iSWAP 门，这是计算通用性所必需的。

Abstract: A simple parametrized family of quantum systems consisting of two entangled
subsystems, dubbed left and right ones, both of them featuring N qubits is
considered in the thermofield double formalism. We assume that the system
evolves in a purely geometric manner based on the parallel transport condition
due to Uhlmann. We explore the different interpretations of this evolution
relative to observers either coupled to the left or to the right subsystems.
The Uhlmann condition breaks the symmetry between left and right by regarding
one of the two possible sets of local unitary operations as gauge degrees of
freedom. Then gauging the right side we show that the geometric evolution on
the left manifests itself via certain local operations reminiscent of
non-unitary filtering measurements. On the other hand on the right the basic
evolutionary steps are organized into a sequence of unitary operations of a
holonomic quantum computation. We calculate the Uhlmann connection governing
the transport for our model which turns out to be related to higher dimensional
instantons. Then we evaluate the anholonomy of the connection for geodesic
triangles with geodesic segments defined with respect to the Bures metric. By
analysing the explicit form of the local filtering measurements showing up on
the left side we realize that they are also optimal measurements for
distinguishing two given mixed states in the statistical sense. We also point
out that by conducting an interference experiment on the right side one can
observe the physical effects of the anholonomic quantum computation. We
demonstrate this by calculating explicit examples for phase shifts and
visibility patterns arising in such interference experiments. Finally a
sequence of geodesic triangles producing the iSWAP gate via anholonomy needed
for computational universality is presented.

</details>


### [229] [Quantum Machine Learning in Multi-Qubit Phase-Space Part I: Foundations](https://arxiv.org/abs/2507.12117)
*Timothy Heightman,Edward Jiang,Ruth Mora-Soto,Maciej Lewenstein,Marcin Płodzień*

Main category: quant-ph

TL;DR: 提出了一种用于量子机器学习的相位空间量子态动力学形式，克服了经典模拟的限制。


<details>
  <summary>Details</summary>
Motivation: 为了克服量子机器学习（QML）在经典模拟中由于希尔伯特空间指数增长而面临的实际限制，本研究探索了利用量子态的相位空间表示作为一种替代方法。

Method: 本研究构建了一个闭合的、可组合的动力学形式，用于处理单量子比特和多量子比特系统中的量子态。该方法将 Pauli 群的算子代数替换为辛流形上的函数动力学，并用与量子比特数量成线性关系的域上的谐波支撑来重构维度灾难。

Result: 该方法将维度灾难的复杂性转化为与量子比特数量成线性关系的谐波支撑，为基于相位空间的变分建模提供了新的QML路径。

Conclusion: 本研究提出了一种基于量子态相位空间的动力学形式，为量子机器学习（QML）开辟了新的途径，其特点是变分建模。

Abstract: Quantum machine learning (QML) seeks to exploit the intrinsic properties of
quantum mechanical systems, including superposition, coherence, and quantum
entanglement for classical data processing. However, due to the exponential
growth of the Hilbert space, QML faces practical limits in classical
simulations with the state-vector representation of quantum system. On the
other hand, phase-space methods offer an alternative by encoding quantum states
as quasi-probability functions. Building on prior work in qubit phase-space and
the Stratonovich-Weyl (SW) correspondence, we construct a closed, composable
dynamical formalism for one- and many-qubit systems in phase-space. This
formalism replaces the operator algebra of the Pauli group with function
dynamics on symplectic manifolds, and recasts the curse of dimensionality in
terms of harmonic support on a domain that scales linearly with the number of
qubits. It opens a new route for QML based on variational modelling over
phase-space.

</details>


### [230] [Cutting Slack: Quantum Optimization with Slack-Free Methods for Combinatorial Benchmarks](https://arxiv.org/abs/2507.12159)
*Monit Sharma,Hoong Chuin Lau*

Main category: quant-ph

TL;DR: 本研究探索了基于拉格朗日的优化技术，如对偶上升、捆绑方法、割平面方法和增广拉格朗日公式，以在量子计算机上解决约束组合优化问题。研究人员发现，对于 TSP 和 MDKP 等问题，可以减少量子比特的使用，而 MIS 问题可以从这些方法中受益，以提高可行性和结果质量。总体而言，拉格朗日方法为约束处理提供了一种可扩展的替代方案，与传统的 QUBO 惩罚方法相比，能够节省量子比特，并为各种实际应用提供了见解。


<details>
  <summary>Details</summary>
Motivation: 为了解决量子组合优化中约束处理的瓶颈，特别是与松弛变量编码相关的挑战，该研究旨在探索基于拉格朗日的优化技术，以提高量子求解器的可扩展性。

Method: 本研究调查了包括对偶上升、捆绑方法、割平面方法和增广拉格朗日公式在内的一系列基于拉格朗日的优化技术，用于在量子模拟器和硬件上求解约束组合问题。

Result: 该研究表明，对于具有不等式约束或度约束结构的多维背包问题（MDKP）和旅行商问题（TSP），可以实现无松弛的重新表述，从而在不影响性能的情况下显著节省量子比特。然而，最大独立集（MIS）虽然不能直接从消除松弛中受益，但通过基于拉格朗日的更新可以提高可行性和目标质量。在经典困难的实例上对这些方法进行了基准测试，分析了量子比特使用、可行性和最优性差距方面的权衡。

Conclusion: 拉格朗日方法为量子组合优化提供了一种可扩展的约束处理替代方案，在某些情况下可以节省量子比特，并为实际应用提供了实际见解。

Abstract: Constraint handling remains a key bottleneck in quantum combinatorial
optimization. While slack-variable-based encodings are straightforward, they
significantly increase qubit counts and circuit depth, challenging the
scalability of quantum solvers. In this work, we investigate a suite of
Lagrangian-based optimization techniques including dual ascent, bundle methods,
cutting plane approaches, and augmented Lagrangian formulations for solving
constrained combinatorial problems on quantum simulators and hardware. Our
framework is applied to three representative NP-hard problems: the Travelling
Salesman Problem (TSP), the Multi-Dimensional Knapsack Problem (MDKP), and the
Maximum Independent Set (MIS).
  We demonstrate that MDKP and TSP, with their inequality-based or
degree-constrained structures, allow for slack-free reformulations, leading to
significant qubit savings without compromising performance. In contrast, MIS
does not inherently benefit from slack elimination but still gains in
feasibility and objective quality from principled Lagrangian updates. We
benchmark these methods across classically hard instances, analyzing trade-offs
in qubit usage, feasibility, and optimality gaps. Our results highlight the
flexibility of Lagrangian formulations as a scalable alternative to naive QUBO
penalization, even when qubit savings are not always achievable. This work
provides practical insights for deploying constraint-aware quantum optimization
pipelines, with applications in logistics, network design, and resource
allocation.

</details>


### [231] [BenchRL-QAS: Benchmarking reinforcement learning algorithms for quantum architecture search](https://arxiv.org/abs/2507.12189)
*Azhar Ikhtiarudin,Aditi Das,Param Thakkar,Akash Kundu*

Main category: quant-ph

TL;DR: BenchRL-QAS is a new framework to benchmark RL algorithms for quantum architecture search (QAS). It tested 9 RL agents on 4 quantum tasks and found that RL classifiers work well, but no single RL algorithm is best for all QAS tasks. Performance depends on the specific task, qubit count, and noise, so choosing the right RL algorithm is important.


<details>
  <summary>Details</summary>
Motivation: To systematically evaluate reinforcement learning (RL) algorithms in quantum architecture search (QAS) across diverse tasks and system sizes, addressing the need for fair and comprehensive comparison.

Method: Introduced BenchRL-QAS, a unified benchmarking framework for evaluating RL algorithms in QAS across diverse tasks and system sizes (2- to 8-qubit). Benchmarked nine RL agents (value-based and policy-gradient) on tasks like VQE, VQD, quantum classification, and state preparation, in both noiseless and noisy regimes. Proposed a weighted ranking metric balancing accuracy, circuit depth, gate count, and computational efficiency.

Result: RL-based quantum classifiers outperformed baseline variational classifiers. Algorithmic performance in QAS is highly context-dependent, varying with task structure, qubit count, and noise, supporting the "no free lunch" principle in RL-based quantum circuit design.

Conclusion: RL-based quantum classifier outperforms baseline variational classifiers. No single RL algorithm is universally optimal for QAS tasks; performance is context-dependent, highlighting the need for tailored algorithm selection and systematic benchmarking.

Abstract: We introduce BenchRL-QAS, a unified benchmarking framework for systematically
evaluating reinforcement learning (RL) algorithms in quantum architecture
search (QAS) across diverse variational quantum algorithm tasks and system
sizes ranging from 2- to 8-qubit. Our study benchmarks nine RL agents including
both value-based and policy-gradient methods on representative quantum problems
such as variational quantum eigensolver, variational quantum state
diagonalization, quantum classification, and state preparation, spanning both
noiseless and realistic noisy regimes. We propose a weighted ranking metric
that balances accuracy, circuit depth, gate count, and computational
efficiency, enabling fair and comprehensive comparison. Our results first
reveal that RL-based quantum classifier outperforms baseline variational
classifiers. Then we conclude that no single RL algorithm is universally
optimal when considering a set of QAS tasks; algorithmic performance is highly
context-dependent, varying with task structure, qubit count, and noise. This
empirical finding provides strong evidence for the "no free lunch" principle in
RL-based quantum circuit design and highlights the necessity of tailored
algorithm selection and systematic benchmarking for advancing quantum circuit
synthesis. This work represents the most comprehensive RL-QAS benchmarking
effort to date, and BenchRL-QAS along with all experimental data are made
publicly available to support reproducibility and future research
https://github.com/azhar-ikhtiarudin/bench-rlqas.

</details>


### [232] [A solid-state temporally multiplexed quantum memory array at the single-photon level](https://arxiv.org/abs/2507.12200)
*Markus Teller,Susana Plascencia,Cristina Sastre Jachimska,Samuele Grandi,Hugues de Riedmatten*

Main category: quant-ph

TL;DR: 该研究利用固态量子内存阵列，结合空间和时间复用技术，实现了单光子级别的弱相干脉冲存储，并验证了低串扰和按需读出的能力，为提高量子网络中的纠缠分发速率提供了潜力。


<details>
  <summary>Details</summary>
Motivation: 利用不同自由度下的多模态是提高远程量子节点之间已宣告的纠缠速率的最有希望的方法之一。

Method: 通过结合空间和时间复用，在多达 250 个时空模式中存储了单光子级别的弱相干脉冲，平均信噪比为 10^2，并对整个系统进行了全面的特性分析，包括其复用和解复用阶段。

Result: 实现了具有 10 个单独可控制的、具有按需读出和时间复用的自旋波内存单元的、空间复用的固态量子内存阵列。

Conclusion: 该内存阵列具有低串扰，即使在单光子级别也能为存储非经典状态做好准备，并有望提高纠缠分发速率。

Abstract: The exploitation of multimodality in different degrees of freedom is one of
the most promising ways to increase the rate of heralded entanglement between
distant quantum nodes. In this paper, we realize a spatially-multiplexed
solid-state quantum memory array with ten individually controllable spin-wave
memory cells featuring on-demand read-out and temporal multiplexing. By
combining spatial and temporal multiplexing, we store weak coherent pulses at
the single-photon level in up to 250 spatio-temporal modes, with an average
signal-to-noise ratio of 10(2). We perform a thorough characterization of the
whole system, including its multiplexing and demultiplexing stage. We verify
that the memory array exhibits low cross-talk even at the single-photon level.
The measured performance indicates readiness for storing non-classical states
and promises a speed-up in entanglement distribution rates.

</details>


### [233] [What are we talking about when we discuss the Born-Oppenheimer approximation?](https://arxiv.org/abs/2507.12223)
*Olimpia Lombardi,Sebastian Fortin,Juan Camilo Martinez Gonzalez,Hernan Lucas Accorinti*

Main category: quant-ph

TL;DR: 该论文批判了HLT关于分子哈密顿量的观点，认为他们的论点是不可信的。


<details>
  <summary>Details</summary>
Motivation: 反驳HLT关于分子哈密顿量的观点，即他们认为分子哈密顿量可以完全在量子力学框架内进行描述。

Method: 对HLT的文章进行批判性分析

Result: HLT的文章和他们的论点被认为是不可信的。

Conclusion: 该论文旨在批判性地分析HLT的文章，并阐述为什么认为他们的论点不具说服力。

Abstract: Nick Huggett, James Ladyman, and Karim Thebault (HLT) have presented a
comprehensive article examining the Born-Oppenheimer Approximation (BOA). Their
central objective is to challenge our position on the matter-namely, that the
BOA incorporates a classical assumption incompatible with the Heisenberg
Uncertainty Principle. In contrast, HLT contend that the BOA involves no such
classical assumption and, as a result, supports the view that chemistry can be
reduced to physics. The purpose of this paper is to offer a critical analysis
of the HLT article and to clarify why we consider their arguments unpersuasive.

</details>


### [234] [Relations between parameters of the Hamiltonian and Neel-type states in the anisotropic Heisenberg model](https://arxiv.org/abs/2507.12225)
*Pavel Babaian,Gennady Koval*

Main category: quant-ph

TL;DR: The paper analyzes Neel-type states in the anisotropic Heisenberg model with an external field, providing formulas for spin directions based on model parameters for any spin and dimension.


<details>
  <summary>Details</summary>
Motivation: Investigate Neel-type states in the anisotropic Heisenberg model with an external field.

Method: Investigation of Neel-type states in the anisotropic Heisenberg model with an external field.

Result: Expressions relating the angles which define the directions of spin polarisation to the parameters of the Hamiltonian.

Conclusion: We find expressions relating the angles which define the directions of spin polarisation to the parameters of the Hamiltonian for arbitrary spin s and arbitrary dimension of the space d.

Abstract: This article investigates Neel-type states in the anisotropic Heisenberg
model with an external field. For arbitrary spin $s$ and arbitrary dimension of
the space $d$ we find the expressions relating the angles which define the
directions of spin polarisation to the parameters of the Hamiltonian.

</details>


### [235] [Comment on "Properties and dynamics of generalized squeezed states"](https://arxiv.org/abs/2507.12250)
*Rubén Gordillo,Ricardo Puebla*

Main category: quant-ph

TL;DR: 一篇声称观察到广义压缩态振荡动力学的文章的作者错误地将数值制品归因于物理现象。本研究通过数值和理论分析证明了这些振荡是由于截断引起的，并表明平均光子数是非递减的，从而反驳了这些现象。


<details>
  <summary>Details</summary>
Motivation: 反驳一篇声称在广义压缩态（二阶以上）的压缩参数增加时出现意外振荡动力学的文章。

Method: 通过对平均光子数的泰勒级数进行数值分析，并给出解析证明，证明了所观察到的振荡行为是数值截断引起的数值制品，而非真实的物理效应。

Result: 所观察到的振荡行为是数值制品，而非真实的物理效应，因为振荡对福克基的截断非常敏感，并且广义压缩态在有限压缩参数后包含无限能量。

Conclusion: 广义压缩态的平均光子数是关于压缩参数的非递减函数，排除了其内禀的振荡动力学可能性。本研究旨在澄清所报告振荡的来源，并强调处理高阶压缩态时需要特别注意。

Abstract: A recent article [S. Ashhab and M. Ayyash, New J. Phys. 27, 054104 (2025)]
has reported unexpected oscillatory dynamics in generalized squeezed states of
order higher than two as their squeezing parameter increases. This behaviour,
observed through numerical simulations using truncated bosonic annihilation and
creation operators, appeared in several properties of these states, including
their average photon number. The authors argued that these oscillations reflect
a genuine physical effect. Here, however, we demonstrate that the observed
oscillatory behaviour is a consequence of numerical artefacts. A numerical
analysis reveals that the oscillations are highly sensitive to the truncation
of the Fock basis, indicating a lack of convergence. This is further supported
by a theoretical analysis of the Taylor series of the average photon number,
suggesting that these generalized squeezed states contain infinite energy after
a finite value of the squeezing parameter. Finally, we provide an analytical
proof that the average photon number of any generalized squeezed state is a
non-decreasing function, thereby ruling out the possibility of intrinsic
oscillatory dynamics. We hope these results help clarify the origin of the
reported oscillations and highlight the special care required when dealing with
high-order squeezing states.

</details>


### [236] [Design Automation in Quantum Error Correction](https://arxiv.org/abs/2507.12253)
*Archisman Ghosh,Avimita Chatterjee,Swaroop Ghosh*

Main category: quant-ph

TL;DR: 本章全面介绍了量子纠错（QEC）中的设计自动化，解决了量子比特开销和硬件效率问题，涵盖了理论、流程、技术进展（如T门优化、改进表面码、ML解码器）和近地平架构，旨在为容错量子计算提供可扩展的QEC系统设计理解。


<details>
  <summary>Details</summary>
Motivation: 随着量子设备的规模化，集成强大的QEC协议以将逻辑错误率抑制在阈值以下并确保可靠运行至关重要。然而，当前的QEC框架存在显著的量子比特开销和硬件效率低下问题，因此，QEC流程中的设计自动化对于实现可扩展、低开销的容错量子计算至关重要。

Method: 本章内容结构分为四个部分：首先，阐述QEC的理论基础，包括逻辑与物理量子比特表示、稳定器码构造及错误 الصي收提取；其次，概述QEC设计流程，强调设计自动化的必要性；再次，调研QEC设计自动化的最新进展，涵盖算法T门优化、减少量子比特开销的改进型表面码架构以及基于机器学习的解码器自动化；最后，探讨近地平容错量子计算架构，将自动化QEC流程整合到可扩展硬件平台，并讨论端到端验证方法。

Result: 本章全面介绍了QEC的设计自动化，涵盖了理论基础、设计流程、最新技术进展（如T门优化、改进型表面码、机器学习解码器）以及近地平架构的整合与验证，并通过案例研究展示了实际应用和性能权衡。

Conclusion: 本章旨在全面介绍量子纠错（QEC）中的设计自动化，为读者提供在容错量子计算领域中QEC系统设计的整体理解。

Abstract: Quantum error correction (QEC) underpins practical fault-tolerant quantum
computing (FTQC) by addressing the fragility of quantum states and mitigating
decoherence-induced errors. As quantum devices scale, integrating robust QEC
protocols is imperative to suppress logical error rates below threshold and
ensure reliable operation, though current frameworks suffer from substantial
qubit overheads and hardware inefficiencies. Design automation in the QEC flow
is thus critical, enabling automated synthesis, transpilation, layout, and
verification of error-corrected circuits to reduce qubit footprints and push
fault-tolerance margins. This chapter presents a comprehensive treatment of
design automation in QEC, structured into four main sections. The first section
delves into the theoretical aspects of QEC, covering logical versus physical
qubit representations, stabilizer code construction, and error syndrome
extraction mechanisms. In the second section, we outline the QEC design flow,
detailing the areas highlighting the need for design automation. The third
section surveys recent advancements in design automation techniques, including
algorithmic $T$-gate optimization, modified surface code architecture to
incorporate lesser qubit overhead, and machine-learning-based decoder
automation. The final section examines near-term FTQC architectures,
integrating automated QEC pipelines into scalable hardware platforms and
discussing end-to-end verification methodologies. Each section is complemented
by case studies of recent research works, illustrating practical
implementations and performance trade-offs. Collectively, this chapter aims to
equip readers with a holistic understanding of design automation in QEC system
design in the fault-tolerant landscape of quantum computing.

</details>


### [237] [Surrogate Quantum Circuit Design for the Lattice Boltzmann Collision Operator](https://arxiv.org/abs/2507.12256)
*Monica Lăcătuş,Matthias Möller*

Main category: quant-ph

TL;DR: 该研究提出了一种新的量子计算方法（SQC），用于模拟高雷诺数湍流，克服了传统方法的局限性，并在模拟结果中表现出准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统计算流体动力学（CFD）工具难以在高雷诺数下进行直接数值模拟，这激发了对量子算法在量子计算机上进行CFD模拟的兴趣，因为量子计算机有望在某些问题上提供潜在的加速。

Method: 提出了一种学习替代量子电路（SQC）的框架，该框架可以近似D2Q9格的BGK碰撞算子，并对四个量子比特的电路进行训练，以满足质量守恒、动量守恒、D8等距和尺度等距等物理性质。

Result: 所提出的SQC框架在IBM Heron处理器上编译时，只需要2,430个本地门，并且不需要额外的辅助量子比特、概率性后选或重复执行。此外，其深度与网格分辨率无关。在泰勒-格林涡旋衰减和盖驱动腔的基准测试中，SQC能够准确捕捉涡旋耗散和流动再循环。

Conclusion: 该研究提出了一种学习替代量子电路（SQC）的框架，该框架可以近似D2Q9格的Bhatnagar Gross Krook（BGK）碰撞算子，以解决量子计算中碰撞步骤的挑战。

Abstract: Direct numerical simulation of turbulent flows at high Reynolds numbers
remains a major challenge for traditional computational fluid dynamics (CFD)
tools running on classical computer hardware. This has motivated growing
interest in quantum algorithms for CFD to enable flow simulations on quantum
computers. The reason being that these computers are expected to deliver
potential speed-ups for certain problems. One promising quantum CFD approach is
a fully quantum implementation of the lattice Boltzmann method called QLBM.
Although efficient quantum routines are now available for the streaming step,
implementing the nonlinear, irreversible collision step with a low depth
circuit that avoids additional ancilla qubits, probabilistic post-selection and
repeated executions remains a significant challenge. In this study, we address
this challenge by introducing a framework for learning a surrogate quantum
circuit (SQC) that approximates the full Bhatnagar Gross Krook (BGK) collision
operator for the D2Q9 lattice. The four qubit circuit is trained to respect the
physical properties of the BGK collision operator, including mass and momentum
conservation, D8 equivariance and scale equivariance. When compiled to the gate
set used by IBM Heron processor under the assumption of full qubit
connectivity, the 15 block SQC requires only 2,430 native gates and uses
neither ancilla qubits nor post-selection or repeated executions. Moreover, its
depth is independent of the grid resolution, as collision is a local operation
that can exploit quantum parallelism to its full extent. We validate the SQC on
two benchmark flows, the Taylor Green vortex decay and the lid driven cavity,
demonstrating that it accurately captures vortex dissipation and flow
recirculation.

</details>


### [238] [Approximating fixed size quantum correlations in polynomial time](https://arxiv.org/abs/2507.12302)
*Julius A. Zeiss,Gereon Koßmann,Omar Fawzi,Mario Berta*

Main category: quant-ph

TL;DR: 通过新的量子de Finetti定理和SDP技术，实现了对两人自由博弈最优值的多项式级ε-加性近似计算，比先前方法更高效。


<details>
  <summary>Details</summary>
Motivation: 先前分析方法在计算固定规模两人自由博弈（具有固定维度纠缠辅助）的最优值时，虽然关注于与问题规模（问答数量）的依赖性，但只能提供exp(1/ε)的保证。本研究旨在克服这一局限，开发出一种计算效率更高的近似方法，将计算复杂度从指数级降低到关于ε的多项式级。

Method: 本研究的核心方法是利用新颖的Bose对称量子de Finetti定理，该定理针对约束量子可分性问题进行了定制。基于这些定理，研究构建了用于近似此类博弈纠缠值的SDP（半定规划）外层层级。通过运用表示论中的对称约简技术，研究成功地将这些SDP的计算复杂性降低至poly(1/ε)，从而实现了高效的ε-加性近似。

Result: 本研究的核心成果是提出了一种能够以poly(1/ε)的计算复杂度实现对固定规模两人自由博弈（具有固定维度纠缠辅助）最优值进行ε-加性近似的方法。此外，研究还引入了一种测量基约整方案，能够将SDP计算得到的外层界转化为一系列可认证的、性能优越的纠缠策略内层序列，这些策略可作为某些优化方法的初始值。

Conclusion: 本研究提出的基于Bose对称量子de Finetti定理和表示论对称约简技术的SDP外层层级方法，能够实现对固定规模两人自由博弈在固定维度纠缠辅助下的最优值进行ε-加性近似计算，其计算复杂度为poly(1/ε)，显著优于先前仅提供exp(1/ε)保证的解析方法。此外，研究还提出了一种测量基约整方案，可将SDP外层界转化为可认证的良好纠缠策略内层序列，为量子信息理论中更广泛的约束可分性问题提供了新的技术思路。

Abstract: We show that $\varepsilon$-additive approximations of the optimal value of
fixed-size two-player free games with fixed-dimensional entanglement assistance
can be computed in time $\mathrm{poly}(1/\varepsilon)$. This stands in contrast
to previous analytic approaches, which focused on scaling with the number of
questions and answers, but yielded only strict $\mathrm{exp}(1/\varepsilon)$
guarantees. Our main result is based on novel Bose-symmetric quantum de Finetti
theorems tailored for constrained quantum separability problems. These results
give rise to semidefinite programming (SDP) outer hierarchies for approximating
the entangled value of such games. By employing representation-theoretic
symmetry reduction techniques, we demonstrate that these SDPs can be formulated
and solved with computational complexity $\mathrm{poly}(1/\varepsilon)$,
thereby enabling efficient $\varepsilon$-additive approximations. In addition,
we introduce a measurement-based rounding scheme that translates the resulting
outer bounds into certifiably good inner sequences of entangled strategies.
These strategies can, for instance, serve as warm starts for see-saw
optimization methods. We believe that our techniques are of independent
interest for broader classes of constrained separability problems in quantum
information theory.

</details>


### [239] [Uncertainty and entropies of classical channels](https://arxiv.org/abs/2507.12310)
*Takla Nateeboon*

Main category: quant-ph

TL;DR: 本论文研究了经典信道不确定性的量化，提出了新的方法和熵的定义。


<details>
  <summary>Details</summary>
Motivation: 研究目的是定义和量化经典信道中固有的不确定性。

Method: 本论文回顾了概率向量的 શ્રેણી化及其变体，并引入了三种不同的方法来形式化经典信道中固有的不确定性概念。

Result: 论文中的三种方法定义了相同的预序关系，并且成功地将经典状态熵扩展到信道领域，为经典信道的不确定性提供了量化。

Conclusion: 本论文提出了三种方法来形式化经典信道中固有的不确定性概念，并定义了经典信道熵，将其作为不确定性的量化。

Abstract: In this thesis, I studied a mathematical development to define and quantify
the uncertainty inherent in classical channels. This thesis starts with the
introduction and background on how to formally think about uncertainty in the
domain of classical states. The concept of probability vector majorization and
its variants, relative majorization and conditional majorization, are reviewed.
This thesis introduces three conceptually distinct approaches to formalize the
notion of uncertainty inherent in classical channels. These three approaches
define the same preordering on the domain of classical channels, leading to
characterizations from many perspectives. With the solid foundation of
uncertainty comparison, classical channel entropy is then defined to be an
additive monotone with respect to the majorization relation. The well-known
entropies in the domain of classical states are uniquely extended to the domain
of channels via the optimal extensions, providing not only a solid foundation
but also the quantifiers of uncertainty inherent in classical channels.

</details>


### [240] [Tailored Quantum Device Calibration with Statistical Model Checking](https://arxiv.org/abs/2507.12323)
*Filip Mazurek,Marissa D'Onofrio,Andrew Van Horn,Jiyong Yu,Kavyashree Ranawat,Jungsang Kim,Kenneth R. Brown*

Main category: quant-ph

TL;DR: 本研究提出SPAQ框架，利用统计模型检验简化量子系统校准的调优和分析，并通过实例证明其能提高系统可用性。


<details>
  <summary>Details</summary>
Motivation: 量子设备需要精确校准的模拟信号，这一过程复杂且耗时。为了对量子校准程序进行严格的统计评估，本研究利用了统计模型检验（SMC）技术。

Method: 本研究将统计模型检验（SMC）扩展到SPA（用于处理器分析）框架，创建了SPAQ（用于量子校准）。SPAQ允许对量子系统校准的属性进行概率评估，并应用于基于有向无环图的校准优化方案，以查找失效时间的下界、隐藏节点依赖关系和参数阈值。

Result: 研究表明，SPAQ能够找到失效时间的下界、隐藏节点依赖关系和参数阈值，并通过调整校准方案，提高了模拟量子系统的可用性。

Conclusion: 该研究提出了SPAQ框架，将统计模型检验（SMC）应用于量子系统校准，以简化调优和分析过程。通过SPAQ，可以评估校准程序的属性，例如参数的失效时间，从而找到失效时间的下界、隐藏节点依赖关系和参数阈值，并利用这些信息改进模拟量子系统的可用性。

Abstract: Quantum devices require precisely calibrated analog signals, a process that
is complex and time-consuming. Many calibration strategies exist, and all
require careful analysis and tuning to optimize system availability. To enable
rigorous statistical evaluation of quantum calibration procedures, we leverage
statistical model checking (SMC), a technique used in fields that require
statistical guarantees. SMC allows for probabilistic evaluation of properties
of interest, such as a certain parameter's time to failure. We extend the SMC
for Processor Analysis (SPA) framework, which uses SMC for evaluation of
classical systems, to create SPA for Quantum calibration (SPAQ) enabling
simplified tuning and analysis of quantum system calibration. We focus on a
directed acyclic graph-based calibration optimization scheme and demonstrate
how to craft properties of interest for its analysis. We show how to use SPAQ
to find lower bounds of time to failure information, hidden node dependencies,
and parameter threshold values and use that information to improve simulated
quantum system availability through calibration scheme adjustments.

</details>


### [241] [On approximate quantum error correction for symmetric noise](https://arxiv.org/abs/2507.12326)
*Gereon Koßmann,Julius A. Zeiss,Omar Fawzi,Mario Berta*

Main category: quant-ph

TL;DR: 本研究提出了一种新的量子纠错分析方法，通过测量舍入和对称性降维来提高效率和实用性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决现有基于可扩展性的半定规划层级在评估固定层级时面临的计算复杂性问题，并为近似量子纠错提供一种更实用的分析方法，以缩小理论与实践之间的差距。

Method: 本研究首先介绍了Berta et al.提出的基于可扩展性的半定规划层级，并引入了一个测量基础的舍入方案来提取内部序列。接着，为了应对层级评估的计算复杂性，研究者们探索了基于对称性的降维技术，结合了噪声对称性（如量子比特衰减信道的多重副本）和优化变量可扩展性产生的排列对称性。

Result: 研究引入了一种测量基础的舍入方案，用于从半定规划层级中提取可认证的编码器-解码器对。通过结合噪声对称性和排列对称性，实现了基于对称性的降维，并展示了该框架在处理具有挑战性的数值示例中的有效性。

Conclusion: 该研究通过引入基于测量的舍入方案，从半定规划层级中提取出可认证的编码器-解码器对，并利用基于对称性的降维技术来处理计算复杂度，为近似量子纠错提供了一种有效的分析方法，有助于缩小量子信息理论的理论发展与其在小型量子纠错码分析中的实际应用之间的差距。

Abstract: We revisit the extendability-based semi-definite programming hierarchy
introduced by Berta et al. [Mathematical Programming, 1 - 49 (2021)], which
provides converging outer bounds on the optimal fidelity of approximate quantum
error correction (AQEC). As our first contribution, we introduce a
measurement-based rounding scheme that extracts inner sequences of certifiably
good encoder-decoder pairs from this outer hierarchy. To address the
computational complexity of evaluating fixed levels of the hierarchy, we
investigate the use of symmetry-based dimension reduction. In particular, we
combine noise symmetries - such as those present in multiple copies of the
qubit depolarizing channel - with the permutational symmetry arising from the
extendability of the optimization variable. This framework is illustrated
through basic, but already challenging numerical examples that showcase its
practical effectiveness. Our results contribute to narrowing the gap between
theoretical developments in quantum information theory and their practical
applications in the analysis of small-scale quantum error-correcting codes.

</details>


### [242] [Quantum Phase Transition in the Dicke Model](https://arxiv.org/abs/2507.12332)
*Moorad Alexanian*

Main category: quant-ph

TL;DR: 研究了Dicke模型中的量子相变。


<details>
  <summary>Details</summary>
Motivation: 为了研究量子光学和量子相变，特别是研究Dicke模型中原子与光场相互作用时发生的相变。

Method: 提出了一种新的模型，在考虑了自旋和相互作用项之后，我们能够从数学上推导出态的演化。

Result: 我们推导出了一个关于正常/超辐射量子相变的结果，该结果基于对Dicke模型的分析，该模型包含N个任意自旋的原子以及独立的同旋转和反旋转耦合项。

Conclusion: 未提供

Abstract: We consider a previously modified Jaynes-Cummings model with single-photon
cavity radiation field and atomic system exchanging a squeezed photon and
deduce a normal/superradiance quantum phase transition in the Dicke model of N
atoms of arbitrary spin with independent co- and counter-rotating coupling
terms.

</details>


### [243] [Modulator-free, self-testing quantum random number generator](https://arxiv.org/abs/2507.12346)
*Ana Blázquez-Coído,Fadri Grünenfelder,Anthony Martin,Raphael Houlmann,Hugo Zbinden,Davide Rusca*

Main category: quant-ph

TL;DR: 一个能在不可信设备上实时验证随机数产生的量子随机数生成器，速率为450kbps。


<details>
  <summary>Details</summary>
Motivation: 为了确保量子随机数生成器（QRNG）产生的随机数的真实性，需要进行鲁棒的验证。自测试QRNG通过允许基于实验观测数据来验证生成的随机数，同时仅需很少的假设来满足这一需求。

Method: 提出了一种可自测试的QRNG，该设备能够使用不可信的测量设备和部分表征的信源，并允许用户实时验证其功能。

Result: 实验实现了每秒450kb的认证随机比特生成速率。

Conclusion: 该研究提出了一个实用的、可自测试的量子随机数生成器（QRNG），可在不可信的测量设备和部分表征的信源下运行，并允许用户实时检查设备的运行情况。

Abstract: Quantum random number generators (QRNGs) use the inherent unpredictability of
quantum mechanics to generate true randomness, as opposed to classical random
number generators. However, ensuring the authenticity of this randomness still
requires robust verification. Self-testing QRNGs address this need by enabling
the validation of the randomness produced based on the observed data from the
experiment while requiring few assumptions. In this work, we present a
practical, self-testing QRNG designed to operate with an untrusted measurement
device and a partially characterized source, allowing the user to check the
adequate functioning of the setup in real time. Our experiment yields a rate of
certified random bits of 450kbps

</details>


### [244] [Entanglement-efficiency trade-offs in the fusion-based generation of photonic GHZ-like states](https://arxiv.org/abs/2507.12389)
*A. A. Melkozerov,M. Yu. Saygin,S. S. Straupe*

Main category: quant-ph

TL;DR: 开发了一种新的线性光学方法来生成具有可变纠缠度的类 GHZ 状态。


<details>
  <summary>Details</summary>
Motivation: 先前的研究主要集中在特定的纠缠态，如图态和 GHZ 态，而具有可变纠缠度的更广泛状态类别仍未得到充分研究。

Method: 提出基于改进的融合门的线性光学方法，以生成和融合类 GHZ 状态。

Result: 实现了对生成效率和输出状态纠缠度的灵活控制。

Conclusion: 通过改进的融合门，我们提出了两种生成和融合类 GHZ 状态的线性光学方法，这些状态具有可变的纠缠度，可用于可扩展的量子计算和通信。

Abstract: Probabilistic entangling measurements are key operations in linear-optical
quantum technologies, enabling the generation and manipulation of
high-dimensional quantum states. While prior research has focused predominantly
on specific entangled states, notably graph states and
Greenberger-Horne-Zeilinger (GHZ) states, broader classes of states with
variable entanglement remain underexplored. In this work, we present a
linear-optical approach for generating and fusing GHZ-like states, which
generalize standard GHZ states to include variable entanglement degrees. We
introduce two schemes based on modified fusion gates that allow flexible
control over generation efficiency and the entanglement of the output states.
These results offer a promising pathway toward resource-efficient
entangled-state generation for scalable quantum computing and communication.

</details>


### [245] [Beyond Ground States: Physics-Inspired Optimization of Excited States of Classical Hamiltonians](https://arxiv.org/abs/2507.12394)
*Erik Altelarrea-Ferré,Júlia Barberà-Rodríguez,David Jansen,Antonio Acín*

Main category: quant-ph

TL;DR: ExcLQA 是一种新的经典算法，可以识别经典伊辛哈密顿量的激发态，并能有效解决最短向量问题，性能优于 Metropolis-Hastings 算法。


<details>
  <summary>Details</summary>
Motivation: 本文旨在扩展局部量子退火（LQA）以识别经典伊辛哈密顿量的激发态，并利用此能力解决潜在的后量子密码学方案的安全性的最短向量问题（SVP）。

Method: ExcLQA 算法通过在成本函数中添加一个惩罚项来扩展 LQA，以目标激发态，并使用单个超参数通过二分查找来设置所需的惩罚级别。

Result: ExcLQA 能够解决高达 46 阶的 SVP 实例，并且在解决比例、计算次数和近似因子方面优于 Metropolis-Hastings 算法。

Conclusion: ExcLQA 算法在解决最短向量问题（SVP）方面表现出色，能够处理高达 46 阶的实例，并在已测试的实例中在解决比例、计算次数和近似因子方面优于 Metropolis-Hastings 算法。

Abstract: We introduce excited local quantum annealing (ExcLQA), a classical,
physics-inspired algorithm that extends local quantum annealing (LQA) to
identify excited states of classical Ising Hamiltonians. LQA simulates quantum
annealing while constraining the quantum state to remain in a product state and
uses a gradient-based approach to find approximate solutions to large-scale
quadratic unconstrained binary optimization problems. ExcLQA extends this
framework by adding a penalty term in the cost function to target excited
states, with a single hyperparameter that can be tuned via binary search to set
the desired penalization level. We benchmark ExcLQA on the shortest vector
problem (SVP), a fundamental lattice problem underlying the security of many
postquantum cryptographic schemes. Solving an SVP instance can be mapped to
identifying the first excited state of a Hamiltonian, with approximate
solutions located among nearby excited states. Our results show that ExcLQA
manages to solve SVP instances up to rank 46, and outperforms the
Metropolis-Hastings algorithm in solved ratio, number of shots, and
approximation factor in the tested instances.

</details>


### [246] [Bounding the asymptotic quantum value of all multipartite compiled non-local games](https://arxiv.org/abs/2507.12408)
*Matilde Baroni,Dominik Leichtle,Siniša Janković,Ivan Šupić*

Main category: quant-ph

TL;DR: 本文扩展了 Kalai 等人的编译器，以实现所有多方非局部博弈的量子健全性，使用了算子代数方法。


<details>
  <summary>Details</summary>
Motivation: 区分经典世界和量子世界中可能存在的相关性，并解决了 Kalai 等人提出的编译器在多方博弈的量子健全性方面的已知局限性。

Method: 通过算子代数理论技术，将顺序操作无信号策略刻画为多方情况下的量子交换算子策略，从而推广了先前的一些结果。在此过程中，我们还构建了顺序 PVM 的通用 C*-代数，并证明了适用于 C*-代数上的完全正映射的 Radon-Nikodym 导数的链式法则。

Result: 证明了 Kalai 等人的编译器实现了所有多方编译的非局部博弈的量子健全性。

Conclusion: 本论文证明了 Kalai 等人的编译器确实为所有多方编译的非局部博弈实现了量子健全性，方法是将渐进情况下的任何可生成的相关性归结为量子交换策略。

Abstract: Non-local games are a powerful tool to distinguish between correlations
possible in classical and quantum worlds. Kalai et al. (STOC'23) proposed a
compiler that converts multipartite non-local games into interactive protocols
with a single prover, relying on cryptographic tools to remove the assumption
of physical separation of the players. While quantum completeness and classical
soundness of the construction have been established for all multipartite games,
quantum soundness is known only in the special case of bipartite games.
  In this paper, we prove that the Kalai et al.'s compiler indeed achieves
quantum soundness for all multipartite compiled non-local games, by showing
that any correlations that can be generated in the asymptotic case correspond
to quantum commuting strategies.
  Our proof uses techniques from the theory of operator algebras, and relies on
a characterisation of sequential operationally no-signalling strategies as
quantum commuting operator strategies in the multipartite case, thereby
generalising several previous results. On the way, we construct universal
C*-algebras of sequential PVMs and prove a new chain rule for Radon-Nikodym
derivatives of completely positive maps on C*-algebras which may be of
independent interest.

</details>


### [247] [Adiabatic Cooling of Planar Motion in a Penning Trap Ion Crystal to Sub-Millikelvin Temperatures](https://arxiv.org/abs/2507.12429)
*Wes Johnson,Bryce Bullock,Athreya Shankar,John Zaris,John J. Bollinger,Scott E. Parker*

Main category: quant-ph

TL;DR: 通过改变离子晶体旋转频率来冷却低频模式以提高量子信息处理效率。


<details>
  <summary>Details</summary>
Motivation: 二维平面离子晶体在 Penning 陷阱中是量子信息科学实验的平台，但低频平面模式的冷却效率低下，限制了其在量子信息处理中的应用。

Method: 通过数值模拟演示了绝热地改变离子晶体的旋转频率来动态调整非线性模式耦合，并展示了该技术可以产生更低的亚毫开尔文温度。

Result: 数值模拟表明，该技术可以将低频平面模式冷却至亚毫开尔文温度，提高了鼓膜模式在实验相关旋转频率下的光谱分辨率。

Conclusion: 通过绝热地改变离子晶体的旋转频率，可以动态调整非线性模式耦合，从而增强低频平面模式的冷却效果，并产生更低的亚毫开尔文温度，提高了鼓膜模式在量子信息处理应用中的光谱分辨率。

Abstract: Two-dimensional planar ion crystals in a Penning trap are a platform for
quantum information science experiments. However, the low-frequency planar
modes of these crystals are not efficiently cooled by laser cooling, which can
limit the utility of the drumhead modes for quantum information processing.
Recently, it has been shown that nonlinear mode coupling can enhance the
cooling of the low-frequency planar modes. Here, we demonstrate in numerical
simulations that this coupling can be dynamically tuned by adiabatically
changing the rotation frequency of the ion crystal during experiments.
Furthermore, we show that this technique can, in addition, produce lower
temperatures for the low-frequency planar modes via an adiabatic cooling
process. This result allows cooling of the planar modes to sub-millikelvin
temperatures, resulting in improved spectral resolution of the drumhead modes
at experimentally relevant rotation frequencies, which is crucial for quantum
information processing applications.

</details>


### [248] [Heisenberg limited multiple eigenvalue estimation via off-the-grid compressed sensing](https://arxiv.org/abs/2507.12438)
*Davide Castaldo,Stefano Corni*

Main category: quant-ph

TL;DR: 一种结合了非网格压缩感知和信号分类的量子算法，能够高效地同时估计酉矩阵的多个特征值，并可能提供量子优势。


<details>
  <summary>Details</summary>
Motivation: 量子相位估算是有差错容忍量子计算机的旗舰算法，本文旨在探索一种更高效的相位估计算法。

Method: 结合了非网格压缩感知协议和先进的信号分类方法，利用哈达玛测试同时估计酉矩阵的多个特征值，并且仅对自相关函数进行少量采样。

Result: 实现了同时估计多个特征值，并在强相关和弱相关情况下达到了海森堡极限，同时还开发了一种利用先验知识进行更快更精确恢复的改进型非网格协议。 论证了该算法可能通过分析其对初始输入状态质量的鲁棒性来提供潜在的量子优势。

Conclusion: 该算法在强相关和弱相关情况下均能达到海森堡极限，并且只需很短的演化时间即可获得多个特征值的ε精度估计。该算法还通过分析其对初始输入状态质量的鲁棒性，展示了潜在的量子优势。

Abstract: Quantum phase estimation is the flagship algorithm for quantum simulation on
fault-tolerant quantum computers. We demonstrate that an \emph{off-grid}
compressed sensing protocol, combined with a state-of-the-art signal
classification method, enables the simultaneous estimation of multiple
eigenvalues of a unitary matrix using the Hadamard test while sampling only a
few percent of the full autocorrelation function. Our numerical evidence
indicates that the proposed algorithm achieves the Heisenberg limit in both
strongly and weakly correlated regimes and requires very short evolution times
to obtain an $\epsilon$-accurate estimate of multiple eigenvalues at once.
  Additionally -- and of independent interest -- we develop a modified off-grid
protocol that leverages prior knowledge of the underlying signal for faster and
more accurate recovery. Finally, we argue that this algorithm may offer a
potential quantum advantage by analyzing its resilience with respect to the
quality of the initial input state.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [249] [Trustworthy Tree-based Machine Learning by $MoS_2$ Flash-based Analog CAM with Inherent Soft Boundaries](https://arxiv.org/abs/2507.12384)
*Bo Wen,Guoyun Gao,Zhicheng Xu,Ruibin Mao,Xiaojuan Qi,X. Sharon Hu,Xunzhao Yin,Can Li*

Main category: cs.LG

TL;DR: 本研究提出了一种利用 MoS2 闪存模拟 CAM 的软树模型推理方法，该方法具有软边界，能有效解决 AI 可信度问题，并能在设备变化和对抗性攻击下保持高准确率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 为了解决人工智能（尤其是树模型）在可解释性和鲁棒性方面的可信度问题，以及传统加速方法在处理设备变化和对抗性攻击方面的局限性。

Method: 提出了一种使用 MoS2 闪存基模拟 CAM 的硬件-软件协同设计方法，该 CAM 具有固有的软边界，可实现软树模型的有效推理。

Result: 在 WDBC 数据集上实现了 96% 的准确率，在 MNIST 数据集上，在 10% 的器件阈值变化下，准确率仅下降 0.6%，而传统决策树下降了 45.3%。

Conclusion: 这项工作提出了一种新颖的硬件-软件协同设计方法，使用具有固有软边界的 MoS2 闪存模拟 CAM，实现了软树模型的有效推理。该方法在面对设备变化和对抗性攻击时表现出卓越的鲁棒性，同时实现了最先进的准确性，为增强人工智能的可信度和效率的专用硬件铺平了道路。

Abstract: The rapid advancement of artificial intelligence has raised concerns
regarding its trustworthiness, especially in terms of interpretability and
robustness. Tree-based models like Random Forest and XGBoost excel in
interpretability and accuracy for tabular data, but scaling them remains
computationally expensive due to poor data locality and high data dependence.
Previous efforts to accelerate these models with analog content addressable
memory (CAM) have struggled, due to the fact that the difficult-to-implement
sharp decision boundaries are highly susceptible to device variations, which
leads to poor hardware performance and vulnerability to adversarial attacks.
This work presents a novel hardware-software co-design approach using $MoS_2$
Flash-based analog CAM with inherent soft boundaries, enabling efficient
inference with soft tree-based models. Our soft tree model inference
experiments on $MoS_2$ analog CAM arrays show this method achieves exceptional
robustness against device variation and adversarial attacks while achieving
state-of-the-art accuracy. Specifically, our fabricated analog CAM arrays
achieve $96\%$ accuracy on Wisconsin Diagnostic Breast Cancer (WDBC) database,
while maintaining decision explainability. Our experimentally calibrated model
validated only a $0.6\%$ accuracy drop on the MNIST dataset under $10\%$ device
threshold variation, compared to a $45.3\%$ drop for traditional decision
trees. This work paves the way for specialized hardware that enhances AI's
trustworthiness and efficiency.

</details>


### [250] [Recurrent U-Net-Based Graph Neural Network (RUGNN) for Accurate Deformation Predictions in Sheet Material Forming](https://arxiv.org/abs/2507.11547)
*Yingxue Zhao,Qianyi Chen,Haoran Li,Haosu Zhou,Hamid Reza Attar,Tobias Pfaff,Tailin Wu,Nan Li*

Main category: cs.LG

TL;DR: 提出了一种名为RUGNN的新型图神经网络代理模型，用于精确预测材料成型过程中的变形，克服了传统AI模型的局限性，并在实际案例中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的基于AI的代理模型（通常使用基于标量或图像的神经网络构建）在捕获复杂的3D空间关系和以排列不变的方式运行时能力有限。

Method: 提出了一种名为RUGNN的新型图神经网络代理模型，该模型结合了门控循环单元（GRUs）来模拟时间动态，并采用受U-Net启发的基于图的下采样/上采样机制来处理空间长程依赖关系。还提出了一种新颖的“节点到表面”接触表示方法，以提高大规模接触相互作用的计算效率。

Result: RUGNN模型在铝合金冷成型和热成型案例研究中得到了验证，结果表明该模型能够准确预测变形，与地面真实有限元模拟结果非常吻合，并且优于几种基线GNN架构。

Conclusion: RUGNN模型是支持片材成型设计的可靠方法，能够实现准确的可制造性预测。

Abstract: In recent years, various artificial intelligence-based surrogate models have
been proposed to provide rapid manufacturability predictions of material
forming processes. However, traditional AI-based surrogate models, typically
built with scalar or image-based neural networks, are limited in their ability
to capture complex 3D spatial relationships and to operate in a
permutation-invariant manner. To overcome these issues, emerging graph-based
surrogate models are developed using graph neural networks. This study
developed a new graph neural network surrogate model named Recurrent U
Net-based Graph Neural Network (RUGNN). The RUGNN model can achieve accurate
predictions of sheet material deformation fields across multiple forming
timesteps. The RUGNN model incorporates Gated Recurrent Units (GRUs) to model
temporal dynamics and a U-Net inspired graph-based downsample/upsample
mechanism to handle spatial long-range dependencies. A novel 'node-to-surface'
contact representation method was proposed, offering significant improvements
in computational efficiency for large-scale contact interactions. The RUGNN
model was validated using a cold forming case study and a more complex hot
forming case study using aluminium alloys. Results demonstrate that the RUGNN
model provides accurate deformation predictions closely matching ground truth
FE simulations and outperforming several baseline GNN architectures. Model
tuning was also performed to identify suitable hyperparameters, training
strategies, and input feature representations. These results demonstrate that
RUGNN is a reliable approach to support sheet material forming design by
enabling accurate manufacturability predictions.

</details>


### [251] [RiemannLoRA: A Unified Riemannian Framework for Ambiguity-Free LoRA Optimization](https://arxiv.org/abs/2507.12142)
*Vladimir Bogachev,Vladimir Aletov,Alexander Molozhavenko,Denis Bobkov,Vera Soboleva,Aibek Alanov,Maxim Rakhuba*

Main category: cs.LG

TL;DR: RiemannLoRA通过将LoRA适配器视为流形并利用黎曼优化来改进初始化和处理过参数化，从而在LLM和扩散模型上实现了更好的性能和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 解决LoRA在初始化和过参数化方面的挑战。

Method: 将LoRA矩阵视为流形，并通过黎曼优化进行初始化和更新。

Result: RiemannLoRA在LLM和扩散模型上均提高了收敛速度和最终性能。

Conclusion: RiemannLoRA在LLM和扩散模型上均优于LoRA及其变体。

Abstract: Low-Rank Adaptation (LoRA) has become a widely adopted standard for
parameter-efficient fine-tuning of large language models (LLMs), significantly
reducing memory and computational demands. However, challenges remain,
including finding optimal initialization strategies or mitigating
overparametrization in low-rank matrix factorization. In this work, we propose
a novel approach that addresses both of the challenges simultaneously within a
unified framework. Our method treats a set of fixed-rank LoRA matrices as a
smooth manifold. Considering adapters as elements on this manifold removes
overparametrization, while determining the direction of the fastest loss
decrease along the manifold provides initialization. Special care is taken to
obtain numerically stable and computationally efficient implementation of our
method, using best practices from numerical linear algebra and Riemannian
optimization. Experimental results on LLM and diffusion model architectures
demonstrate that RiemannLoRA consistently improves both convergence speed and
final performance over standard LoRA and its state-of-the-art modifications.

</details>


### [252] [SurgeryLSTM: A Time-Aware Neural Model for Accurate and Explainable Length of Stay Prediction After Spine Surgery](https://arxiv.org/abs/2507.11570)
*Ha Na Cho,Sairam Sutari,Alexander Lopez,Hansen Bow,Kai Zheng*

Main category: cs.LG

TL;DR: SurgeryLSTM 通过结合时间建模和注意力机制，在预测择期脊柱手术患者的停留时间方面，展现了比传统模型更高的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 为了开发和评估预测择期脊柱手术患者停留时间（LOS）的机器学习（ML）模型，并着重于时间建模和模型可解释性。

Method: 研究人员将传统的机器学习模型（如线性回归、随机森林、支持向量机和 XGBoost）与他们开发的模型 SurgeryLSTM 进行了比较。SurgeryLSTM 是一个带有注意力机制的掩码双向长短期记忆（BiLSTM）模型。实验使用了结构化的围手术期电子健康记录（EHR）数据。通过决定系数（R2）评估模型性能，并利用可解释人工智能识别关键预测因子。

Result: SurgeryLSTM 模型达到了最高的预测准确性（R2=0.86），优于 XGBoost（R2=0.85）和基线模型。注意力机制通过动态识别术前临床序列中有影响力的时间段，提高了模型的可解释性，使临床医生能够追踪哪些事件或特征对每个 LOS 预测的贡献最大。骨骼疾病、慢性肾病和腰椎融合术被确定为影响 LOS 的最重要预测因子。

Conclusion: SurgeryLSTM 模型为择期脊柱手术的预测提供了有效且可解释的 AI 解决方案。将基于时间的、可解释的机器学习方法整合到临床决策支持系统中，可以提高出院准备度和个体化患者护理。

Abstract: Objective: To develop and evaluate machine learning (ML) models for
predicting length of stay (LOS) in elective spine surgery, with a focus on the
benefits of temporal modeling and model interpretability. Materials and
Methods: We compared traditional ML models (e.g., linear regression, random
forest, support vector machine (SVM), and XGBoost) with our developed model,
SurgeryLSTM, a masked bidirectional long short-term memory (BiLSTM) with an
attention, using structured perioperative electronic health records (EHR) data.
Performance was evaluated using the coefficient of determination (R2), and key
predictors were identified using explainable AI. Results: SurgeryLSTM achieved
the highest predictive accuracy (R2=0.86), outperforming XGBoost (R2 = 0.85)
and baseline models. The attention mechanism improved interpretability by
dynamically identifying influential temporal segments within preoperative
clinical sequences, allowing clinicians to trace which events or features most
contributed to each LOS prediction. Key predictors of LOS included bone
disorder, chronic kidney disease, and lumbar fusion identified as the most
impactful predictors of LOS. Discussion: Temporal modeling with attention
mechanisms significantly improves LOS prediction by capturing the sequential
nature of patient data. Unlike static models, SurgeryLSTM provides both higher
accuracy and greater interpretability, which are critical for clinical
adoption. These results highlight the potential of integrating attention-based
temporal models into hospital planning workflows. Conclusion: SurgeryLSTM
presents an effective and interpretable AI solution for LOS prediction in
elective spine surgery. Our findings support the integration of temporal,
explainable ML approaches into clinical decision support systems to enhance
discharge readiness and individualized patient care.

</details>


### [253] [Distribution-Free Uncertainty-Aware Virtual Sensing via Conformalized Neural Operators](https://arxiv.org/abs/2507.11574)
*Kazuma Kobayashi,Shailesh Garg,Farid Ahmed,Souvik Chakraborty,Syed Bahauddin Alam*

Main category: cs.LG

TL;DR: "CMCO 是一种新的框架，为深度学习中的虚拟传感提供可靠的不确定性量化，它将蒙特卡洛 dropout 和分裂保形预测结合在一个模型中，无需重新训练或复杂的损失函数设计。在各种应用中都显示出良好的效果。"


<details>
  <summary>Details</summary>
Motivation: "为了解决深度学习在实时虚拟传感中的安全部署挑战，特别是在传感器数据稀疏、嘈杂或非共置的领域，CMCO 旨在提供稳健的不确定性量化。"

Method: "CMCO 框架通过将蒙特卡洛 dropout 与分裂保形预测相结合，在一个 DeepONet 架构中，实现了具有经过校准的、无分布预测区间的神经算子虚拟传感。"

Result: "CMCO 在湍流、弹塑性变形和全球宇宙辐射剂量估算三个不同的应用中，即使在具有强空间梯度和代理传感的设置中，也始终如一地实现了接近标称的经验覆盖率。"

Conclusion: "CMCO 提供了一个通用、即插即用的不确定性量化解决方案，用于神经算子，在数字孪生、传感器融合和安全关键监控中实现实时、可信的推理。通过以最小的计算开销连接理论和部署，CMCO 为可扩展、可泛化且能感知不确定性的科学机器学习奠定了新基础。"

Abstract: Robust uncertainty quantification (UQ) remains a critical barrier to the safe
deployment of deep learning in real-time virtual sensing, particularly in
high-stakes domains where sparse, noisy, or non-collocated sensor data are the
norm. We introduce the Conformalized Monte Carlo Operator (CMCO), a framework
that transforms neural operator-based virtual sensing with calibrated,
distribution-free prediction intervals. By unifying Monte Carlo dropout with
split conformal prediction in a single DeepONet architecture, CMCO achieves
spatially resolved uncertainty estimates without retraining, ensembling, or
custom loss design. Our method addresses a longstanding challenge: how to endow
operator learning with efficient and reliable UQ across heterogeneous domains.
Through rigorous evaluation on three distinct applications: turbulent flow,
elastoplastic deformation, and global cosmic radiation dose estimation-CMCO
consistently attains near-nominal empirical coverage, even in settings with
strong spatial gradients and proxy-based sensing. This breakthrough offers a
general-purpose, plug-and-play UQ solution for neural operators, unlocking
real-time, trustworthy inference in digital twins, sensor fusion, and
safety-critical monitoring. By bridging theory and deployment with minimal
computational overhead, CMCO establishes a new foundation for scalable,
generalizable, and uncertainty-aware scientific machine learning.

</details>


### [254] [STAGED: A Multi-Agent Neural Network for Learning Cellular Interaction Dynamics](https://arxiv.org/abs/2507.11660)
*Joao F. Rocha,Ke Xu,Xingzhi Sun,Ananya Krishna,Dhananjay Bhaskar,Blanche Mongeon,Morgan Craig,Mark Gerstein,Smita Krishnaswamy*

Main category: cs.LG

TL;DR: STAGED通过结合ABM和深度学习，使用图ODE网络学习细胞间通讯和细胞内基因调控网络，以更准确地模拟细胞动态。


<details>
  <summary>Details</summary>
Motivation: 现有的单细胞技术和计算方法在分析细胞动态时存在局限性，例如将细胞视为独立数据点，以及基于规则的ABM缺乏数据驱动性。需要新的计算方法来学习复杂的细胞相互作用动态。

Method: STAGED模型，使用图ODE网络（GDEs）表示基因和相互作用，通过注意力机制学习相互作用强度，并进行训练以匹配模拟和来自空间转录组学数据的推断轨迹。

Result: 该模型能够捕捉细胞间和细胞内的相互作用，从而实现对细胞动态更自适应和更准确的表示。

Conclusion: STAGED整合了ABM和深度学习，通过图ODE网络（GDEs）和注意力机制，能够动态学习细胞间通讯及其对细胞内基因调控网络的影响，从而更自适应、更准确地表示细胞动态。

Abstract: The advent of single-cell technology has significantly improved our
understanding of cellular states and subpopulations in various tissues under
normal and diseased conditions by employing data-driven approaches such as
clustering and trajectory inference. However, these methods consider cells as
independent data points of population distributions. With spatial
transcriptomics, we can represent cellular organization, along with dynamic
cell-cell interactions that lead to changes in cell state. Still, key
computational advances are necessary to enable the data-driven learning of such
complex interactive cellular dynamics. While agent-based modeling (ABM)
provides a powerful framework, traditional approaches rely on handcrafted rules
derived from domain knowledge rather than data-driven approaches. To address
this, we introduce Spatio Temporal Agent-Based Graph Evolution Dynamics(STAGED)
integrating ABM with deep learning to model intercellular communication, and
its effect on the intracellular gene regulatory network. Using graph ODE
networks (GDEs) with shared weights per cell type, our approach represents
genes as vertices and interactions as directed edges, dynamically learning
their strengths through a designed attention mechanism. Trained to match
continuous trajectories of simulated as well as inferred trajectories from
spatial transcriptomics data, the model captures both intercellular and
intracellular interactions, enabling a more adaptive and accurate
representation of cellular dynamics.

</details>


### [255] [Einstein Fields: A Neural Perspective To Computational General Relativity](https://arxiv.org/abs/2507.11589)
*Sandeep Suresh Cranganore,Andrei Bodnar,Arturs Berzins,Johannes Brandstetter*

Main category: cs.LG

TL;DR: Einstein Fields 是一种神经张量场，能压缩四维数值相对论模拟，通过自动微分导出物理量，并在时空几何编码中自然产生动力学。


<details>
  <summary>Details</summary>
Motivation: 为了压缩计算密集型的四维数值相对论模拟，并为数值相对论提供更具可扩展性和表达性的方法，提出了一种名为 Einstein Fields 的神经表征。

Method: Einstein Fields 通过将广义相对论的核心张量场“度规”建模为隐式神经网络权重，实现了对四维数值相对论模拟的压缩。这种神经张量场表示使得能够利用自动微分来推导物理量，并且在编码时空几何的同时，动力学作为副产品自然涌现。

Result: Einstein Fields 在多个广义相对论的典型测试用例中展现了其在连续时空建模、网格无关性、存储效率、导数精度和易用性方面的潜力。

Conclusion: Einstein Fields 作为一种新的神经表征，能够将计算密集型的四维数值相对论模拟压缩到紧凑的隐式神经网络权重中，并能通过自动微分导出物理量。与传统的神经场不同，Einstein Fields 是神经张量场，其优势在于能够在时空几何编码的同时自然地产生动力学。该方法在连续时空建模、网格无关性、存储效率、导数精度和易用性方面展现出巨大潜力，并在广义相对论的典型测试用例中得到了验证。研究团队还发布了基于 JAX 的开源库，为数值相对论的可扩展和表达性方法铺平了道路。

Abstract: We introduce Einstein Fields, a neural representation that is designed to
compress computationally intensive four-dimensional numerical relativity
simulations into compact implicit neural network weights. By modeling the
\emph{metric}, which is the core tensor field of general relativity, Einstein
Fields enable the derivation of physical quantities via automatic
differentiation. However, unlike conventional neural fields (e.g., signed
distance, occupancy, or radiance fields), Einstein Fields are \emph{Neural
Tensor Fields} with the key difference that when encoding the spacetime
geometry of general relativity into neural field representations, dynamics
emerge naturally as a byproduct. Einstein Fields show remarkable potential,
including continuum modeling of 4D spacetime, mesh-agnosticity, storage
efficiency, derivative accuracy, and ease of use. We address these challenges
across several canonical test beds of general relativity and release an open
source JAX-based library, paving the way for more scalable and expressive
approaches to numerical relativity. Code is made available at
https://github.com/AndreiB137/EinFields

</details>


### [256] [Measuring Informativeness Gap of (Mis)Calibrated Predictors](https://arxiv.org/abs/2507.12094)
*Yiding Feng,Wei Tang*

Main category: cs.LG

TL;DR: 衡量预测模型在下游任务中的有用性，提出信息差的概念及一种新的度量方法。


<details>
  <summary>Details</summary>
Motivation: 在决策者需要在多个可能校准错误的预测模型中进行选择时，确定哪个模型更有用。

Method: 本文提出信息差的概念，并给出了其对偶刻画，这是一种可以视为EMD松弛变体的信息度量。

Result: 研究提出了信息差的概念，并将其与现有概念（如U-校准和校准决策损失）联系起来，同时还提出了一种新的信息度量，该度量满足完备性和可靠性，并且可以样本高效地估计。

Conclusion: 该研究提出了信息差的概念，用于量化两个预测模型在下游决策任务中的效用差异，并提供了一种新的信息度量方法，该方法是EMD的松弛变体，具有完备性和可靠性，并且可以在仅能访问预测值的情况下进行样本高效估计。

Abstract: In many applications, decision-makers must choose between multiple predictive
models that may all be miscalibrated. Which model (i.e., predictor) is more
"useful" in downstream decision tasks? To answer this, our first contribution
introduces the notion of the informativeness gap between any two predictors,
defined as the maximum normalized payoff advantage one predictor offers over
the other across all decision-making tasks. Our framework strictly generalizes
several existing notions: it subsumes U-Calibration [KLST-23] and Calibration
Decision Loss [HW-24], which compare a miscalibrated predictor to its
calibrated counterpart, and it recovers Blackwell informativeness [Bla-51,
Bla-53] as a special case when both predictors are perfectly calibrated. Our
second contribution is a dual characterization of the informativeness gap,
which gives rise to a natural informativeness measure that can be viewed as a
relaxed variant of the earth mover's distance (EMD) between two prediction
distributions. We show that this measure satisfies natural desiderata: it is
complete and sound, and it can be estimated sample-efficiently in the
prediction-only access setting. Along the way, we also obtain novel
combinatorial structural results when applying this measure to perfectly
calibrated predictors.

</details>


### [257] [Synthetic Tabular Data Generation: A Comparative Survey for Modern Techniques](https://arxiv.org/abs/2507.11590)
*Raju Challagundla,Mohsen Dorodchi,Pu Wang,Minwoo Lee*

Main category: cs.LG

TL;DR: 此项工作对合成表格数据生成领域的最新进展进行了全面回顾，重点介绍了保持数据复杂性、统计准确性和隐私性的方法。它引入了一个新的分类系统，并提出了一个基准框架，以指导未来的研究和实际应用。


<details>
  <summary>Details</summary>
Motivation: 随着隐私法规的收紧和现实世界数据访问的限制，合成数据（尤其是表格数据）已成为金融、医疗和社会科学等领域的关键解决方案。

Method: 对保留复杂特征关系、统计保真度和隐私要求的新兴合成表格数据生成方法进行了全面的回顾和分类。

Result: 提出了一种基于实际生成目标（包括预期下游应用、隐私保证和数据效用）的新型分类法，并提出了一个基准框架，以指导方法设计、评估和技术创新。

Conclusion: 该综述通过引入新的分类法和基准框架，为合成表格数据生成的研究和实践提供了方向，特别关注隐私和数据效用。

Abstract: As privacy regulations become more stringent and access to real-world data
becomes increasingly constrained, synthetic data generation has emerged as a
vital solution, especially for tabular datasets, which are central to domains
like finance, healthcare and the social sciences. This survey presents a
comprehensive and focused review of recent advances in synthetic tabular data
generation, emphasizing methods that preserve complex feature relationships,
maintain statistical fidelity, and satisfy privacy requirements. A key
contribution of this work is the introduction of a novel taxonomy based on
practical generation objectives, including intended downstream applications,
privacy guarantees, and data utility, directly informing methodological design
and evaluation strategies. Therefore, this review prioritizes the actionable
goals that drive synthetic data creation, including conditional generation and
risk-sensitive modeling. Additionally, the survey proposes a benchmark
framework to align technical innovation with real-world demands. By bridging
theoretical foundations with practical deployment, this work serves as both a
roadmap for future research and a guide for implementing synthetic tabular data
in privacy-critical environments.

</details>


### [258] [Learning Representations of Event Time Series with Sparse Autoencoders for Anomaly Detection, Similarity Search, and Unsupervised Classification](https://arxiv.org/abs/2507.11620)
*Steven Dillmann,Juan Rafael Martínez-Galarza*

Main category: cs.LG

TL;DR: 提出了一种用于事件时间序列的新型张量表示和稀疏自动编码器方法，可用于各种下游任务，并在X射线天文学中进行了验证。


<details>
  <summary>Details</summary>
Motivation: 事件时间序列因其非结构化和不规则的结构，在提取有意义的模式和识别显著现象方面带来了重大挑战。

Method: 提出了一种新颖的二维和三维张量表示法，并结合了稀疏自动编码器，以学习具有物理意义的潜在表示。

Result: 这些嵌入支持多种下游任务，包括异常检测、基于相似性的检索、语义聚类和无监督分类。在X射线天文学的真实数据集上进行了演示，表明这些表示成功地捕获了时间和光谱特征，并分离了不同类别的X射线瞬变。

Conclusion: 该框架为分析跨科学和工业领域的复杂、不规则事件时间序列提供了一个灵活、可扩展且可推广的解决方案。

Abstract: Event time series are sequences of discrete events occurring at irregular
time intervals, each associated with a domain-specific observational modality.
They are common in domains such as high-energy astrophysics, computational
social science, cybersecurity, finance, healthcare, neuroscience, and
seismology. Their unstructured and irregular structure poses significant
challenges for extracting meaningful patterns and identifying salient phenomena
using conventional techniques. We propose novel two- and three-dimensional
tensor representations for event time series, coupled with sparse autoencoders
that learn physically meaningful latent representations. These embeddings
support a variety of downstream tasks, including anomaly detection,
similarity-based retrieval, semantic clustering, and unsupervised
classification. We demonstrate our approach on a real-world dataset from X-ray
astronomy, showing that these representations successfully capture temporal and
spectral signatures and isolate diverse classes of X-ray transients. Our
framework offers a flexible, scalable, and generalizable solution for analyzing
complex, irregular event time series across scientific and industrial domains.

</details>


### [259] [A Bayesian Incentive Mechanism for Poison-Resilient Federated Learning](https://arxiv.org/abs/2507.12439)
*Daniel Commey,Rebecca A. Sarpong,Griffith S. Klogo,Winful Bagyl-Bac,Garth V. Crosby*

Main category: cs.LG

TL;DR: 提出了一种主动的、经济上的防御方法，通过贝叶斯激励机制使恶意行为在经济上不合理，以应对联邦学习中的数据投毒攻击。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习防御机制通常是反应性的，并且依赖于计算成本高昂的统计聚合规则，同时通常假设有诚实多数。本研究提出了一种主动的、经济上的防御方法，以应对开放参与的联邦学习所面临的数据投毒攻击。

Method: 通过一个轻量级的贝叶斯激励机制，将每次训练轮次建模为不完全信息的贝叶斯博弈，服务器利用一小部分私有的验证数据集在支付前验证更新质量。

Result: 实验结果表明，该机制具有鲁棒性。在MNIST数据集上，面对50%的标签翻转攻击者，该机制仍能保持96.7%的准确率，仅比面对30%标签翻转攻击者的场景低0.3个百分点。这比标准的FedAvg（在相同50%攻击下准确率会崩溃）高出51.7个百分点。

Conclusion: 该机制计算量轻、预算有限，并易于集成到现有的联邦学习框架中，为经济上稳健和可持续的联邦学习生态系统提供了实用的途径。

Abstract: Federated learning (FL) enables collaborative model training across
decentralized clients while preserving data privacy. However, its
open-participation nature exposes it to data-poisoning attacks, in which
malicious actors submit corrupted model updates to degrade the global model.
Existing defenses are often reactive, relying on statistical aggregation rules
that can be computationally expensive and that typically assume an honest
majority. This paper introduces a proactive, economic defense: a lightweight
Bayesian incentive mechanism that makes malicious behavior economically
irrational. Each training round is modeled as a Bayesian game of incomplete
information in which the server, acting as the principal, uses a small, private
validation dataset to verify update quality before issuing payments. The design
satisfies Individual Rationality (IR) for benevolent clients, ensuring their
participation is profitable, and Incentive Compatibility (IC), making poisoning
an economically dominated strategy. Extensive experiments on non-IID partitions
of MNIST and FashionMNIST demonstrate robustness: with 50% label-flipping
adversaries on MNIST, the mechanism maintains 96.7% accuracy, only 0.3
percentage points lower than in a scenario with 30% label-flipping adversaries.
This outcome is 51.7 percentage points better than standard FedAvg, which
collapses under the same 50% attack. The mechanism is computationally light,
budget-bounded, and readily integrates into existing FL frameworks, offering a
practical route to economically robust and sustainable FL ecosystems.

</details>


### [260] [Deep Generative Methods and Tire Architecture Design](https://arxiv.org/abs/2507.11639)
*Fouad Oubari,Raphael Meunier,Rodrigue Décatoire,Mathilde Mougeot*

Main category: cs.LG

TL;DR: 本研究全面评估了五种深度生成模型在工业轮胎结构生成任务中的表现，发现扩散模型整体性能最优，MDM和DDPM各有优势。同时，提出的“分类填充”方法能够有效处理条件生成场景。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决工业界在选择最适合复杂制造设计任务的深度生成模型时面临的关键问题，为工业实践者提供指导。

Method: 本研究提出了一种名为“分类填充”的新方法，这是一种掩码感知逆扩散过程，可在无需额外训练的情况下保留已知标签，从而使离散扩散模型能够处理条件场景。我们采用了专门针对工业要求校准的、几何感知的指标来评估模型性能，这些指标量化了空间连贯性、组件交互、结构连通性和感知保真度。

Result: 研究结果显示，扩散模型在工业轮胎结构生成任务中表现出最强的整体性能。其中，MDM在分布内生成方面表现最佳，而DDPM在处理分布外维度约束方面泛化能力更强。此外，掩码训练的VAE在条件生成任务上的表现优于MMVAE	extsuperscript{+}。

Conclusion: 在本研究中，我们对五种代表性的深度生成模型（变分自编码器、生成对抗网络、多模态变分自编码器、去噪扩散概率模型和多项式扩散模型）在工业轮胎结构生成任务中的表现进行了全面研究。研究结果表明，扩散模型在整体性能上表现最佳。具体而言，MDM在分布内生成方面表现突出，而DDPM在处理分布外维度约束方面具有更好的泛化能力。此外，经过掩码训练的VAE在几乎所有条件生成指标上均优于多模态变分自编码器MMVAE	extsuperscript{+}。

Abstract: As deep generative models proliferate across the AI landscape, industrial
practitioners still face critical yet unanswered questions about which deep
generative models best suit complex manufacturing design tasks. This work
addresses this question through a complete study of five representative models
(Variational Autoencoder, Generative Adversarial Network, multimodal
Variational Autoencoder, Denoising Diffusion Probabilistic Model, and
Multinomial Diffusion Model) on industrial tire architecture generation. Our
evaluation spans three key industrial scenarios: (i) unconditional generation
of complete multi-component designs, (ii) component-conditioned generation
(reconstructing architectures from partial observations), and (iii)
dimension-constrained generation (creating designs that satisfy specific
dimensional requirements). To enable discrete diffusion models to handle
conditional scenarios, we introduce categorical inpainting, a mask-aware
reverse diffusion process that preserves known labels without requiring
additional training. Our evaluation employs geometry-aware metrics specifically
calibrated for industrial requirements, quantifying spatial coherence,
component interaction, structural connectivity, and perceptual fidelity. Our
findings reveal that diffusion models achieve the strongest overall
performance; a masking-trained VAE nonetheless outperforms the multimodal
variant MMVAE\textsuperscript{+} on nearly all component-conditioned metrics,
and within the diffusion family MDM leads in-distribution whereas DDPM
generalises better to out-of-distribution dimensional constraints.

</details>


### [261] [Tracing the Path to Grokking: Embeddings, Dropout, and Network Activation](https://arxiv.org/abs/2507.11645)
*Ahmed Salah,David Yevick*

Main category: cs.LG

TL;DR: 本研究提出了一系列可预测神经网络 grokking 现象（延迟泛化）的指标，包括 dropout 鲁棒性曲线、dropout 下的准确性方差、不活跃神经元的百分比以及嵌入的分布和相似性。这些指标有助于理解 grokking 的起源和行为。


<details>
  <summary>Details</summary>
Motivation: Grokking 是一种延迟泛化现象，其中神经网络的测试准确性在训练准确性提高后才明显提高。本研究旨在寻找可预测 grokking 行为的实用指标。

Method: 通过 Dropout 鲁棒性曲线 (DRC) 估计神经网络在推理过程中对噪声的韧性，该曲线是通过在模型从记忆化到泛化的过程中，准确性随 dropout 率变化的得到的。此外，在训练检查点中，测试准确性在随机 dropout 下的方差在 grokking 期间表现出局部最大值。研究还发现，不活跃神经元的百分比在泛化期间会减少，而嵌入则趋向于双峰分布，且与观察到的余弦相似性模式和数据集对称性相关。

Result: 研究提出的指标（dropout 下的方差、鲁棒性、嵌入相似性和稀疏性度量）能够预测 grokking 行为。具体来说，DRC 曲线、测试准确性在随机 dropout 下的方差、不活跃神经元的百分比以及嵌入的双峰分布和余弦相似性模式都与 grokking 现象相关。

Conclusion: 该研究提出了一系列实用的指标，如 dropout 下的方差、鲁棒性、嵌入相似性和稀疏性度量，可以预测 grokking 行为。这些指标为理解 grokking 的起源和行为提供了有价值的见解。

Abstract: Grokking refers to delayed generalization in which the increase in test
accuracy of a neural network occurs appreciably after the improvement in
training accuracy This paper introduces several practical metrics including
variance under dropout, robustness, embedding similarity, and sparsity
measures, that can forecast grokking behavior. Specifically, the resilience of
neural networks to noise during inference is estimated from a Dropout
Robustness Curve (DRC) obtained from the variation of the accuracy with the
dropout rate as the model transitions from memorization to generalization. The
variance of the test accuracy under stochastic dropout across training
checkpoints further exhibits a local maximum during the grokking. Additionally,
the percentage of inactive neurons decreases during generalization, while the
embeddings tend to a bimodal distribution independent of initialization that
correlates with the observed cosine similarity patterns and dataset symmetries.
These metrics additionally provide valuable insight into the origin and
behaviour of grokking.

</details>


### [262] [ZKP-FedEval: Verifiable and Privacy-Preserving Federated Evaluation using Zero-Knowledge Proofs](https://arxiv.org/abs/2507.11649)
*Daniel Commey,Benjamin Appiah,Griffith S. Klogo,Garth V. Crosby*

Main category: cs.LG

TL;DR: 该研究提出了一种在联邦学习中使用零知识证明来保护评估阶段隐私的方法，通过证明本地损失低于阈值来替代直接暴露损失值，并在MNIST和HAR数据集上进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）允许在不暴露原始数据的情况下，在分散的数据上进行协作模型训练。然而，FL中的评估阶段可能通过共享的性能指标泄露敏感信息。

Method: 本研究提出了一种结合零知识证明（ZKP）的新型协议，用于在联邦学习（FL）中实现隐私保护和可验证的评估。客户端生成简洁的证明，断言其本地损失低于预定阈值，而不是暴露原始损失值。该方法不依赖外部API，并包含用于联邦学习模拟、ZKP电路设计和在MNIST及人类活动识别（HAR）数据集上进行实验评估的自包含模块。

Result: 研究在MNIST和人类活动识别（HAR）数据集上，针对卷积神经网络（CNN）模型和多层感知机（MLP）模型，实现了基于阈值的证明。评估了该方法在计算开销、通信成本和可验证性方面的性能。

Conclusion: 本文提出了一种结合零知识证明（ZKP）的新型协议，用于在联邦学习（FL）中实现隐私保护和可验证的评估，以解决评估阶段可能泄露敏感信息的问题。

Abstract: Federated Learning (FL) enables collaborative model training on decentralized
data without exposing raw data. However, the evaluation phase in FL may leak
sensitive information through shared performance metrics. In this paper, we
propose a novel protocol that incorporates Zero-Knowledge Proofs (ZKPs) to
enable privacy-preserving and verifiable evaluation for FL. Instead of
revealing raw loss values, clients generate a succinct proof asserting that
their local loss is below a predefined threshold. Our approach is implemented
without reliance on external APIs, using self-contained modules for federated
learning simulation, ZKP circuit design, and experimental evaluation on both
the MNIST and Human Activity Recognition (HAR) datasets. We focus on a
threshold-based proof for a simple Convolutional Neural Network (CNN) model
(for MNIST) and a multi-layer perceptron (MLP) model (for HAR), and evaluate
the approach in terms of computational overhead, communication cost, and
verifiability.

</details>


### [263] [Composing Linear Layers from Irreducibles](https://arxiv.org/abs/2507.11688)
*Travis Pence,Daisuke Yamada,Vikas Singh*

Main category: cs.LG

TL;DR: 该研究使用 Clifford 代数，提出了一种使用 O(log^2 d) 参数分解线性层的方法，与 O(d^2) 的密集矩阵相比，该方法在大型语言模型中表现良好。


<details>
  <summary>Details</summary>
Motivation: 虽然大型模型表现出似乎是由低级原语组成的模块化行为，但这些基本构建块的理解程度很差。该研究旨在通过识别/合成由一组最小的几何原语组成的线性变换来探索线性层中的组合结构。

Method: 使用 Clifford 代数，研究表明线性层可以表示为双向量（编码定向平面的几何对象）的组合，并引入了一种可微分算法，将其分解为旋转向量的乘积。

Result: 与块哈达玛和低秩近似等强基线相比，基于旋转向量的层在大型语言模型注意力层的键、查询和值投影中匹配了性能。

Conclusion: 该研究为深度模型中的几何原语如何组合成更高级别的函数提供了一个代数视角。

Abstract: Contemporary large models often exhibit behaviors suggesting the presence of
low-level primitives that compose into modules with richer functionality, but
these fundamental building blocks remain poorly understood. We investigate this
compositional structure in linear layers by asking: can we identify/synthesize
linear transformations from a minimal set of geometric primitives? Using
Clifford algebra, we show that linear layers can be expressed as compositions
of bivectors -- geometric objects encoding oriented planes -- and introduce a
differentiable algorithm that decomposes them into products of rotors. This
construction uses only O(log^2 d) parameters, versus O(d^2) required by dense
matrices. Applied to the key, query, and value projections in LLM attention
layers, our rotor-based layers match the performance of strong baselines such
as block-Hadamard and low-rank approximations. Our findings provide an
algebraic perspective on how these geometric primitives can compose into
higher-level functions within deep models.

</details>


### [264] [The Impact of Coreset Selection on Spurious Correlations and Group Robustness](https://arxiv.org/abs/2507.11690)
*Amaya Dharmasiri,William Yang,Polina Kirichenko,Lydia Liu,Olga Russakovsky*

Main category: cs.LG

TL;DR: 研究了 coreset 选择对数据集偏差的影响，发现基于嵌入的方法比基于学习动态的方法更不容易加剧偏差，并且降低偏差并不直接等同于提高模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究数据约简方法（如 coreset 选择）对数据集偏差的影响，特别是它们是否会延续、放大或减轻这些偏差。

Method: 在十个不同的虚假相关性基准、五个样本重要性/难易度评分指标和五个数据选择策略的广泛实验中，分析了 coreset 选择对虚假偏差水平和下游模型鲁棒性的影响。

Result: 基于嵌入的样本表征选择 coreset 比基于学习动态的表征选择，意外加剧偏差的风险相对较低。此外，研究发现，优先选择难样本可以降低偏差水平，但不能保证下游模型的鲁棒性。

Conclusion: 某些以难样本为导向的 coreset 选择方法虽然可以降低偏差水平，但并不能保证下游模型的鲁棒性。

Abstract: Coreset selection methods have shown promise in reducing the training data
size while maintaining model performance for data-efficient machine learning.
However, as many datasets suffer from biases that cause models to learn
spurious correlations instead of causal features, it is important to understand
whether and how dataset reduction methods may perpetuate, amplify, or mitigate
these biases. In this work, we conduct the first comprehensive analysis of the
implications of data selection on the spurious bias levels of the selected
coresets and the robustness of downstream models trained on them. We use an
extensive experimental setting spanning ten different spurious correlations
benchmarks, five score metrics to characterize sample importance/ difficulty,
and five data selection policies across a broad range of coreset sizes.
Thereby, we unravel a series of nontrivial nuances in interactions between
sample difficulty and bias alignment, as well as dataset bias and resultant
model robustness. For example, we find that selecting coresets using
embedding-based sample characterization scores runs a comparatively lower risk
of inadvertently exacerbating bias than selecting using characterizations based
on learning dynamics. Most importantly, our analysis reveals that although some
coreset selection methods could achieve lower bias levels by prioritizing
difficult samples, they do not reliably guarantee downstream robustness.

</details>


### [265] [Time series classification of satellite data using LSTM networks: an approach for predicting leaf-fall to minimize railroad traffic disruption](https://arxiv.org/abs/2507.11702)
*Hein de Wilde,Ali Mohammed Mansoor Alsahag,Pierre Blanchet*

Main category: cs.LG

TL;DR: 本研究利用LSTM和卫星数据预测铁路叶落时间，以减少交通中断损失。


<details>
  <summary>Details</summary>
Motivation: 每年由于落叶造成的铁路交通中断给英国铁路行业带来超过3亿英镑的损失，因此预测落叶时间对于高效安排缓解措施至关重要。然而，当前预测方法在可扩展性和可靠性方面存在局限。

Method: 本研究采用一种结合了地面真实叶落数据、多光谱卫星数据和气象卫星数据的LSTM（长短期记忆）网络模型，来预测叶落的时间。

Result: LSTM模型在预测叶落开始时间方面达到了6.32天的均方根误差，在预测叶落结束时间方面达到了9.31天的均方根误差。

Conclusion: 本研究提出的基于LSTM和多光谱卫星数据的叶落预测模型，在预测叶落开始和结束时间方面表现出优于先前方法的性能，为铁路行业的叶落防护措施优化和生态系统理解提供了新的机会。

Abstract: Railroad traffic disruption as a result of leaf-fall cost the UK rail
industry over 300 million per year and measures to mitigate such disruptions
are employed on a large scale, with 1.67 million kilometers of track being
treated in the UK in 2021 alone. Therefore, the ability to anticipate the
timing of leaf-fall would offer substantial benefits for rail network
operators, enabling the efficient scheduling of such mitigation measures.
However, current methodologies for predicting leaf-fall exhibit considerable
limitations in terms of scalability and reliability. This study endeavors to
devise a prediction system that leverages specialized prediction methods and
the latest satellite data sources to generate both scalable and reliable
insights into leaf-fall timings. An LSTM network trained on ground-truth
leaf-falling data combined with multispectral and meteorological satellite data
demonstrated a root-mean-square error of 6.32 days for predicting the start of
leaf-fall and 9.31 days for predicting the end of leaf-fall. The model, which
improves upon previous work on the topic, offers promising opportunities for
the optimization of leaf mitigation measures in the railway industry and the
improvement of our understanding of complex ecological systems.

</details>


### [266] [Reinforcement Learning from Adversarial Preferences in Tabular MDPs](https://arxiv.org/abs/2507.11706)
*Taira Tsuchiya,Shinji Ito,Haipeng Luo*

Main category: cs.LG

TL;DR: 本研究提出了偏好导向的马尔可夫决策过程（PbMDPs），并为基于Borda得分的PbMDPs建立了遗憾下界。研究提出的策略优化算法在已知和未知转移的情况下均能达到接近理论下界的遗憾界限。


<details>
  <summary>Details</summary>
Motivation: 在标准片段式马尔可夫决策过程中，智能体直接观测到损失的数值。然而，在许多实际场景中，智能体只能获得关于两个选项之间偏好的信息。本研究旨在填补这一空白，提出并分析了偏好导向的马尔可夫决策过程（PbMDPs），其中智能体通过比较两个候选动作的偏好来学习。

Method: 本文首先为具有对抗性损失的片段式MDPs建立了一个$
 Omega(\sqrt{HSAT})$的遗憾下界，然后利用该构造推导出了基于Borda得分的PbMDPs的遗憾下界为 $
 Omega( (H^2 S K)^{1/3} T^{2/3} )$。接着，提出了一种基于在线线性优化的全局优化方法，在已知转移的情况下，遗憾界限为$
 	ilde{O}((H^2 S^2 K)^{1/3} T^{2/3} )$。为了克服全局优化方法的局限性，提出了一种策略优化算法，其遗憾界限在已知转移的情况下约为$
 	ilde{O}( (H^6 S K^5)^{1/3} T^{2/3} )$，并进一步将结果扩展到未知转移的情况。

Result: 本研究为基于Borda得分的PbMDPs建立了遗憾下界，并提出了两种算法，其中策略优化算法在已知转移的情况下，遗憾界限约为$
 	ilde{O}( (H^6 S K^5)^{1/3} T^{2/3} )$，并成功扩展到了未知转移的情况。

Conclusion: 本研究提出了偏好导向的马尔可夫决策过程（PbMDPs），其中智能体通过比较两个候选动作的偏好来学习，而不是直接观测损失值。研究了基于Borda得分的PbMDPs，并建立了相应的遗憾界限。

Abstract: We introduce a new framework of episodic tabular Markov decision processes
(MDPs) with adversarial preferences, which we refer to as preference-based MDPs
(PbMDPs). Unlike standard episodic MDPs with adversarial losses, where the
numerical value of the loss is directly observed, in PbMDPs the learner instead
observes preferences between two candidate arms, which represent the choices
being compared. In this work, we focus specifically on the setting where the
reward functions are determined by Borda scores. We begin by establishing a
regret lower bound for PbMDPs with Borda scores. As a preliminary step, we
present a simple instance to prove a lower bound of $\Omega(\sqrt{HSAT})$ for
episodic MDPs with adversarial losses, where $H$ is the number of steps per
episode, $S$ is the number of states, $A$ is the number of actions, and $T$ is
the number of episodes. Leveraging this construction, we then derive a regret
lower bound of $\Omega( (H^2 S K)^{1/3} T^{2/3} )$ for PbMDPs with Borda
scores, where $K$ is the number of arms. Next, we develop algorithms that
achieve a regret bound of order $T^{2/3}$. We first propose a global
optimization approach based on online linear optimization over the set of all
occupancy measures, achieving a regret bound of $\tilde{O}((H^2 S^2 K)^{1/3}
T^{2/3} )$ under known transitions. However, this approach suffers from
suboptimal dependence on the potentially large number of states $S$ and
computational inefficiency. To address this, we propose a policy optimization
algorithm whose regret is roughly bounded by $\tilde{O}( (H^6 S K^5)^{1/3}
T^{2/3} )$ under known transitions, and further extend the result to the
unknown-transition setting.

</details>


### [267] [Subgraph Generation for Generalizing on Out-of-Distribution Links](https://arxiv.org/abs/2507.11710)
*Jay Revolinsky,Harry Shomer,Jiliang Tang*

Main category: cs.LG

TL;DR: FLEX是一个图生成模型框架，通过结构条件图生成和对抗性协同训练，解决了图神经网络在分布外场景下的链接预测性能问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有图神经网络（GNNs）在处理分布内样本时表现良好，但在分布外（OOD）场景下性能下降的问题，以及图生成模型（GGMs）的应用局限于特定领域的问题，提出FLEX框架以桥接这一差距。

Method: FLEX框架结合了结构条件图生成和自编码器与GNN之间的对抗性协同训练两种机制。

Result: 大量实验证明FLEX在合成和真实世界的OOD环境中能够提升链接预测性能，并且有助于理解图数据增强对链接结构的影响。

Conclusion: FLEX框架通过结构条件图生成和自编码器与GNN之间的对抗性协同训练，实现了样本分布的结构对齐，从而在分布外（OOD）场景下提升了链接预测性能。该框架无需专家知识即可适应不同的OOD场景。

Abstract: Graphs Neural Networks (GNNs) demonstrate high-performance on the link
prediction (LP) task. However, these models often rely on all dataset samples
being drawn from the same distribution. In addition, graph generative models
(GGMs) show a pronounced ability to generate novel output graphs. Despite this,
GGM applications remain largely limited to domain-specific tasks. To bridge
this gap, we propose FLEX as a GGM framework which leverages two mechanism: (1)
structurally-conditioned graph generation, and (2) adversarial co-training
between an auto-encoder and GNN. As such, FLEX ensures structural-alignment
between sample distributions to enhance link-prediction performance in
out-of-distribution (OOD) scenarios. Notably, FLEX does not require expert
knowledge to function in different OOD scenarios. Numerous experiments are
conducted in synthetic and real-world OOD settings to demonstrate FLEX's
performance-enhancing ability, with further analysis for understanding the
effects of graph data augmentation on link structures. The source code is
available here: https://github.com/revolins/FlexOOD.

</details>


### [268] [Globalization for Scalable Short-term Load Forecasting](https://arxiv.org/abs/2507.11729)
*Amirhossein Ahmadi,Hamidreza Zareipour,Henry Leung*

Main category: cs.LG

TL;DR: 该研究比较了全局和局部电力负荷预测模型，发现全局目标转换模型在有全局特征和聚类的情况下效果更好。全局特征转换模型则在平衡局部和全局动态方面遇到挑战，需要聚类来处理数据异质性。


<details>
  <summary>Details</summary>
Motivation: 传统局部预测模型（LFMs）在泛化性、过拟合、数据漂移和冷启动问题方面存在显著局限性，并且在扩展性方面存在计算成本高和效率低的问题。全局预测模型（GFMs）通过全局化和交叉学习提供了新的解决方案，能够提高预测的泛化性、可扩展性、准确性和鲁棒性。

Method: 本文研究了在数据漂移情况下的全局负荷预测，重点分析了不同建模技术和数据异质性的影响。文章探讨了特征转换和目标转换模型，并研究了全局化、数据异质性和数据漂移的不同影响。此外，研究还考察了全局化在峰值负荷预测和层级预测中的作用。为了处理数据异质性和全局与局部之间的平衡，本文提出了单独的时间序列聚类（TSC）方法，包括用于特征转换模型的基于模型的TSC以及新的用于目标转换模型的加权实例TSC。

Result: 在对阿尔伯塔电力负荷的真实数据集进行的广泛实验中，结果表明全局目标转换模型（GTFM）在预测精度上持续优于其局部对应模型，尤其是在整合了全局特征和聚类技术之后。相比之下，全局特征转换模型（GFM）在协调局部与全局动态方面遇到困难，通常需要聚类技术（TSC）来有效地管理数据异质性。

Conclusion: 全局目标转换模型（GTFM）在电力负荷预测方面优于局部模型，尤其是在结合全局特征和聚类技术时。全局特征转换模型（GFM）在平衡局部和全局动态方面存在挑战，需要聚类技术来有效处理数据异质性。

Abstract: Forecasting load in power transmission networks is essential across various
hierarchical levels, from the system level down to individual points of
delivery (PoD). While intuitive and locally accurate, traditional local
forecasting models (LFMs) face significant limitations, particularly in
handling generalizability, overfitting, data drift, and the cold start problem.
These methods also struggle with scalability, becoming computationally
expensive and less efficient as the network's size and data volume grow. In
contrast, global forecasting models (GFMs) offer a new approach to enhance
prediction generalizability, scalability, accuracy, and robustness through
globalization and cross-learning. This paper investigates global load
forecasting in the presence of data drifts, highlighting the impact of
different modeling techniques and data heterogeneity. We explore
feature-transforming and target-transforming models, demonstrating how
globalization, data heterogeneity, and data drift affect each differently. In
addition, we examine the role of globalization in peak load forecasting and its
potential for hierarchical forecasting. To address data heterogeneity and the
balance between globality and locality, we propose separate time series
clustering (TSC) methods, introducing model-based TSC for feature-transforming
models and new weighted instance-based TSC for target-transforming models.
Through extensive experiments on a real-world dataset of Alberta's electricity
load, we demonstrate that global target-transforming models consistently
outperform their local counterparts, especially when enriched with global
features and clustering techniques. In contrast, global feature-transforming
models face challenges in balancing local and global dynamics, often requiring
TSC to manage data heterogeneity effectively.

</details>


### [269] [HyDRA: A Hybrid Dual-Mode Network for Closed- and Open-Set RFFI with Optimized VMD](https://arxiv.org/abs/2507.12133)
*Hanwen Liu,Yuhe Huang,Yifeng Gong,Yanjie Zhai,Jiaxuan Lu*

Main category: cs.LG

TL;DR: HyDRA是一种混合双模射频架构，结合了优化的VMD、CNN、Transformer和Mamba，用于设备识别。它在闭集和开集场景下均表现出色，并能在嵌入式设备上实现快速、低功耗的推理，适用于实时无线身份验证。


<details>
  <summary>Details</summary>
Motivation: 设备识别对于无线通信系统的安全至关重要，特别是在接入控制等应用中。射频指纹识别(RFFI)通过利用硬件引起的信号失真，提供了一种非加密的解决方案。

Method: HyDRA是一种混合双模射频架构，它将优化的变分模态分解(VMD)与基于卷积神经网络(CNN)、Transformer和Mamba组件融合的新型架构相结合，支持闭集和开集分类任务。优化的VMD通过固定中心频率和使用闭式解来提高预处理效率和分类准确性。HyDRA采用Transformer动态序列编码器(TDSE)进行全局依赖建模，并采用Mamba线性流编码器(MLFE)进行线性复杂度处理，以适应不同条件。

Result: 在公共数据集上的评估表明，HyDRA在闭集场景下达到了最先进(SOTA)的准确率，并在我们提出的开集分类方法中表现出鲁棒的性能，能够有效识别未经授权的设备。部署在NVIDIA Jetson Xavier NX上，HyDRA实现了毫秒级的推理速度和低功耗。

Conclusion: HyDRA在闭集场景下达到了最先进(SOTA)的准确率，并在我们提出的开集分类方法中表现出鲁棒的性能，能够有效识别未经授权的设备。此外，HyDRA部署在NVIDIA Jetson Xavier NX上，实现了毫秒级的推理速度和低功耗，为现实世界中实时无线身份验证提供了一个实用的解决方案。

Abstract: Device recognition is vital for security in wireless communication systems,
particularly for applications like access control. Radio Frequency Fingerprint
Identification (RFFI) offers a non-cryptographic solution by exploiting
hardware-induced signal distortions. This paper proposes HyDRA, a Hybrid
Dual-mode RF Architecture that integrates an optimized Variational Mode
Decomposition (VMD) with a novel architecture based on the fusion of
Convolutional Neural Networks (CNNs), Transformers, and Mamba components,
designed to support both closed-set and open-set classification tasks. The
optimized VMD enhances preprocessing efficiency and classification accuracy by
fixing center frequencies and using closed-form solutions. HyDRA employs the
Transformer Dynamic Sequence Encoder (TDSE) for global dependency modeling and
the Mamba Linear Flow Encoder (MLFE) for linear-complexity processing, adapting
to varying conditions. Evaluation on public datasets demonstrates
state-of-the-art (SOTA) accuracy in closed-set scenarios and robust performance
in our proposed open-set classification method, effectively identifying
unauthorized devices. Deployed on NVIDIA Jetson Xavier NX, HyDRA achieves
millisecond-level inference speed with low power consumption, providing a
practical solution for real-time wireless authentication in real-world
environments.

</details>


### [270] [Graph Neural Networks Powered by Encoder Embedding for Improved Node Learning](https://arxiv.org/abs/2507.11732)
*Shiyu Chen,Cencheng Shen,Youngser Park,Carey E. Priebe*

Main category: cs.LG

TL;DR: GG是一种新的GNN框架，通过GEE生成高质量的初始节点特征，在节点聚类和分类任务上均表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: GNN的性能受限于依赖随机或信息量少的初始特征表示，这可能导致收敛慢和次优解。而GG利用GEE生成高质量的初始节点特征，以增强GNN的端到端训练。

Method: 提出了一种名为GEE（one-hot graph encoder embedding）的统计学方法来生成高质量的初始节点特征，并将其与GNN相结合，形成GEE驱动的GNN（GG），并通过GG-C（GG和GEE的输出连接）来改进节点分类任务。

Result: GG在节点聚类任务上始终达到最先进的性能，在所有评估的真实世界数据集上均排名第一，并且比标准GNN收敛更快。GG-C在节点分类任务上也优于现有的基线模型。

Conclusion: GG-C通过连接GG和GEE的输出来改进GNN在节点分类任务上的表现，GG在节点聚类任务上表现优于标准GNN，并且收敛速度更快，这表明在实现GNN的全部潜力时，基于原则的、感知结构的特征初始化很重要。

Abstract: Graph neural networks (GNNs) have emerged as a powerful framework for a wide
range of node-level graph learning tasks. However, their performance is often
constrained by reliance on random or minimally informed initial feature
representations, which can lead to slow convergence and suboptimal solutions.
In this paper, we leverage a statistically grounded method, one-hot graph
encoder embedding (GEE), to generate high-quality initial node features that
enhance the end-to-end training of GNNs. We refer to this integrated framework
as the GEE-powered GNN (GG), and demonstrate its effectiveness through
extensive simulations and real-world experiments across both unsupervised and
supervised settings. In node clustering, GG consistently achieves
state-of-the-art performance, ranking first across all evaluated real-world
datasets, while exhibiting faster convergence compared to the standard GNN. For
node classification, we further propose an enhanced variant, GG-C, which
concatenates the outputs of GG and GEE and outperforms competing baselines.
These results confirm the importance of principled, structure-aware feature
initialization in realizing the full potential of GNNs.

</details>


### [271] [Sparse Identification of Nonlinear Dynamics with Conformal Prediction](https://arxiv.org/abs/2507.11739)
*Urban Fasel*

Main category: cs.LG

TL;DR: 本研究将保形预测与集成SINDy（E-SINDy）相结合，提出了一种新的不确定性量化方法，该方法在预测、模型选择和系数不确定性量化方面均表现出色，可用于安全关键应用。


<details>
  <summary>Details</summary>
Motivation: 为了评估SINDy模型的可靠性，尤其是在安全关键应用中，量化其不确定性至关重要。尽管已存在多种不确定性量化方法，但本研究旨在探索保形预测框架与SINDy的结合，以提供具有覆盖保证的预测区间。

Method: 本研究将保形预测框架与集成SINDy（E-SINDy）相结合，提出三种不确定性量化应用：1.量化时间序列预测的不确定性；2.基于库特征重要性进行模型选择；3.通过特征保形预测量化已识别模型系数的不确定性。

Result: 研究结果表明，将保形预测方法与E-SINDy集成，在时间序列预测方面能够可靠地实现目标覆盖率，在量化特征重要性方面表现有效，并且能够为模型系数生成更稳健的不确定性区间，即使在非高斯噪声下，其表现也优于标准的E-SINDy系数估计。

Conclusion: 本研究将保形预测与集成SINDy（E-SINDy）相结合，为SINDy模型提供了新的不确定性量化方法。研究表明，该方法在时间序列预测、模型选择和系数不确定性量化方面均表现出色，能够满足期望的覆盖率，有效量化特征重要性，并生成更稳健的不确定性区间，即使在非高斯噪声下也优于标准的E-SINDy估计。

Abstract: The Sparse Identification of Nonlinear Dynamics (SINDy) is a method for
discovering nonlinear dynamical system models from data. Quantifying
uncertainty in SINDy models is essential for assessing their reliability,
particularly in safety-critical applications. While various uncertainty
quantification methods exist for SINDy, including Bayesian and ensemble
approaches, this work explores the integration of Conformal Prediction, a
framework that can provide valid prediction intervals with coverage guarantees
based on minimal assumptions like data exchangeability. We introduce three
applications of conformal prediction with Ensemble-SINDy (E-SINDy): (1)
quantifying uncertainty in time series prediction, (2) model selection based on
library feature importance, and (3) quantifying the uncertainty of identified
model coefficients using feature conformal prediction. We demonstrate the three
applications on stochastic predator-prey dynamics and several chaotic dynamical
systems. We show that conformal prediction methods integrated with E-SINDy can
reliably achieve desired target coverage for time series forecasting,
effectively quantify feature importance, and produce more robust uncertainty
intervals for model coefficients, even under non-Gaussian noise, compared to
standard E-SINDy coefficient estimates.

</details>


### [272] [A Graph-in-Graph Learning Framework for Drug-Target Interaction Prediction](https://arxiv.org/abs/2507.11757)
*Yuehua Song,Yong Gao*

Main category: cs.LG

TL;DR: A new Graph-in-Graph (GiG) model using both transductive and inductive learning improves drug-target interaction prediction by integrating molecular and network-level features, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Accurately predicting drug-target interactions (DTIs) is crucial for advancing drug discovery and target validation. Existing machine learning approaches, including GNN-based methods, face difficulties in effectively integrating diverse features of drugs, targets, and their interactions. The proposed framework aims to address this limitation.

Method: The study introduces a novel framework that leverages both transductive and inductive learning. This framework utilizes a GNN-based model called Graph-in-Graph (GiG), which represents drug and target molecular structures as meta-nodes in a drug-target interaction graph to explore intricate relationships. A special benchmark comprising drug SMILES, protein sequences, and their interaction data was compiled for evaluation.

Result: The GiG model demonstrates significantly improved performance compared to existing approaches across all evaluation metrics on a specially compiled benchmark.

Conclusion: The proposed GiG model significantly outperforms existing approaches across all evaluation metrics, highlighting the benefits of integrating different learning paradigms and interaction data.

Abstract: Accurately predicting drug-target interactions (DTIs) is pivotal for
advancing drug discovery and target validation techniques. While machine
learning approaches including those that are based on Graph Neural Networks
(GNN) have achieved notable success in DTI prediction, many of them have
difficulties in effectively integrating the diverse features of drugs, targets
and their interactions. To address this limitation, we introduce a novel
framework to take advantage of the power of both transductive learning and
inductive learning so that features at molecular level and drug-target
interaction network level can be exploited. Within this framework is a
GNN-based model called Graph-in-Graph (GiG) that represents graphs of drug and
target molecular structures as meta-nodes in a drug-target interaction graph,
enabling a detailed exploration of their intricate relationships. To evaluate
the proposed model, we have compiled a special benchmark comprising drug
SMILES, protein sequences, and their interaction data, which is interesting in
its own right. Our experimental results demonstrate that the GiG model
significantly outperforms existing approaches across all evaluation metrics,
highlighting the benefits of integrating different learning paradigms and
interaction data.

</details>


### [273] [RadioDiff-3D: A 3D$\times$3D Radio Map Dataset and Generative Diffusion Based Benchmark for 6G Environment-Aware Communication](https://arxiv.org/abs/2507.12166)
*Xiucheng Wang,Qiming Zhang,Nan Cheng,Junting Chen,Zezhong Zhang,Zan Li,Shuguang Cui,Xuemin Shen*

Main category: cs.LG

TL;DR: 该研究提出了 UrbanRadio3D 数据集和 RadioDiff-3D 模型，用于解决现有 3D 无线电图构建方法的局限性，并在性能上取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有无线电图（RM）构建方法主要集中在二维平面上的路径损耗预测，忽略了到达角（DoA）、到达时间（ToA）和垂直空间变化等关键参数。这是由于依赖静态学习范式，限制了其在训练数据分布之外的泛化能力。

Method: 提出了一种名为 UrbanRadio3D 的大规模、高分辨率 3D 无线电图数据集，该数据集通过在真实城市环境中进行射线追踪来构建。此外，还提出了一种基于 3D 卷积 UNet 的基准模型，以及一个名为 RadioDiff-3D 的基于扩散模型的生成框架，用于 3D 无线电图的构建。

Result: UrbanRadio3D 数据集比之前的 3D RM 数据集大 37 倍以上，包含路径损耗、DoA 和 ToA 三个指标，以及比现有数据集多 7 倍的高度层。RadioDiff-3D 在各种环境动态下，在构建高维无线电图方面表现出优越的性能。

Conclusion: 该工作提供了基础数据集和基准，为未来 3D 环境感知通信的研究奠定了基础。所提出的 RadioDiff-3D 在构建高维无线电图方面表现优于现有方法。

Abstract: Radio maps (RMs) serve as a critical foundation for enabling
environment-aware wireless communication, as they provide the spatial
distribution of wireless channel characteristics. Despite recent progress in RM
construction using data-driven approaches, most existing methods focus solely
on pathloss prediction in a fixed 2D plane, neglecting key parameters such as
direction of arrival (DoA), time of arrival (ToA), and vertical spatial
variations. Such a limitation is primarily due to the reliance on static
learning paradigms, which hinder generalization beyond the training data
distribution. To address these challenges, we propose UrbanRadio3D, a
large-scale, high-resolution 3D RM dataset constructed via ray tracing in
realistic urban environments. UrbanRadio3D is over 37$\times$3 larger than
previous datasets across a 3D space with 3 metrics as pathloss, DoA, and ToA,
forming a novel 3D$\times$33D dataset with 7$\times$3 more height layers than
prior state-of-the-art (SOTA) dataset. To benchmark 3D RM construction, a UNet
with 3D convolutional operators is proposed. Moreover, we further introduce
RadioDiff-3D, a diffusion-model-based generative framework utilizing the 3D
convolutional architecture. RadioDiff-3D supports both radiation-aware
scenarios with known transmitter locations and radiation-unaware settings based
on sparse spatial observations. Extensive evaluations on UrbanRadio3D validate
that RadioDiff-3D achieves superior performance in constructing rich,
high-dimensional radio maps under diverse environmental dynamics. This work
provides a foundational dataset and benchmark for future research in 3D
environment-aware communication. The dataset is available at
https://github.com/UNIC-Lab/UrbanRadio3D.

</details>


### [274] [Torsional-GFN: a conditional conformation generator for small molecules](https://arxiv.org/abs/2507.11759)
*Alexandra Volokhova,Léna Néhale Ezzine,Piotr Gaiński,Luca Scimeca,Emmanuel Bengio,Prudencio Tossou,Yoshua Bengio,Alex Hernandez-Garcia*

Main category: cs.LG

TL;DR: Torsional-GFN 是一种 GFlowNet 模型，可以高效生成分子构象，其采样比例近似符合玻尔兹曼分布，并具有零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了在药物发现等应用中生成稳定的分子构象，以更有效的方法替代分子动力学来从玻尔兹曼分布中采样构象。

Method: Torsional-GFN 是一种条件生成流网络（GFlowNet），专门设计用于仅使用奖励函数作为训练信号，通过采样其扭转角来生成与玻尔兹曼分布成比例的分子构象。它以分子图和局部结构（键长、键角）作为条件。

Result: Torsional-GFN 能够使用单一模型对多种分子的构象进行采样，采样比例近似符合玻尔兹曼分布，并能对分子动力学模拟中出现的未见键长和键角实现零样本泛化。

Conclusion: Torsional-GFN 能够以零样本泛化能力，使用单一模型对多种分子的构象进行采样，且采样比例近似符合玻尔兹曼分布。该方法为扩展到更大的分子系统、实现对未见分子的零样本泛化以及将局部结构生成纳入 GFlowNet 模型提供了有前景的方向。

Abstract: Generating stable molecular conformations is crucial in several drug
discovery applications, such as estimating the binding affinity of a molecule
to a target. Recently, generative machine learning methods have emerged as a
promising, more efficient method than molecular dynamics for sampling of
conformations from the Boltzmann distribution. In this paper, we introduce
Torsional-GFN, a conditional GFlowNet specifically designed to sample
conformations of molecules proportionally to their Boltzmann distribution,
using only a reward function as training signal. Conditioned on a molecular
graph and its local structure (bond lengths and angles), Torsional-GFN samples
rotations of its torsion angles. Our results demonstrate that Torsional-GFN is
able to sample conformations approximately proportional to the Boltzmann
distribution for multiple molecules with a single model, and allows for
zero-shot generalization to unseen bond lengths and angles coming from the MD
simulations for such molecules. Our work presents a promising avenue for
scaling the proposed approach to larger molecular systems, achieving zero-shot
generalization to unseen molecules, and including the generation of the local
structure into the GFlowNet model.

</details>


### [275] [Selective Quantization Tuning for ONNX Models](https://arxiv.org/abs/2507.12196)
*Nikolaos Louloudakis,Ajitha Rajan*

Main category: cs.LG

TL;DR: TuneQn 是一个用于 ONNX 模型的选择性量化、部署和优化套件，可在保持准确性的同时减小模型尺寸。


<details>
  <summary>Details</summary>
Motivation: 量化会降低模型大小和计算需求，但可能以牺牲准确性为代价，并且完全量化模型在低端硬件上可能表现不佳。因此，需要一种选择性量化方法来确定哪些层可以被排除在量化之外。

Method: TuneQn 是一个支持 ONNX 模型选择性量化、跨多种 CPU 和 GPU 设备部署及执行的套件，并结合了性能分析和多目标优化。TuneQn 能生成选择性量化的 ONNX 模型，在不同硬件上部署它们，测量准确性和大小等指标，执行帕累托前沿最小化以识别最佳模型候选者，并可视化结果。

Result: TuneQn 在四个 ONNX 模型和两个量化设置上，跨 CPU 和 GPU 设备进行了评估，证明了其有效性。

Conclusion: TuneQn 能够有效地执行选择性量化和调整，选择的 ONNX 模型候选者与完全量化模型相比，准确性损失最多可减少 54.14%，与原始模型相比，模型尺寸最多可减少 72.9%。

Abstract: Quantization is a process that reduces the precision of deep neural network
models to lower model size and computational demands, often at the cost of
accuracy. However, fully quantized models may exhibit sub-optimal performance
below acceptable levels and face deployment challenges on low-end hardware
accelerators due to practical constraints. To address these issues,
quantization can be selectively applied to only a subset of layers, but
selecting which layers to exclude is non-trivial. To this direction, we propose
TuneQn, a suite enabling selective quantization, deployment and execution of
ONNX models across various CPU and GPU devices, combined with profiling and
multi-objective optimization. TuneQn generates selectively quantized ONNX
models, deploys them on different hardware, measures performance on metrics
like accuracy and size, performs Pareto Front minimization to identify the best
model candidate and visualizes the results. To demonstrate the effectiveness of
TuneQn, we evaluated TuneQn on four ONNX models with two quantization settings
across CPU and GPU devices. As a result, we demonstrated that our utility
effectively performs selective quantization and tuning, selecting ONNX model
candidates with up to a $54.14$% reduction in accuracy loss compared to the
fully quantized model, and up to a $72.9$% model size reduction compared to the
original model.

</details>


### [276] [Scaling laws for activation steering with Llama 2 models and refusal mechanisms](https://arxiv.org/abs/2507.11771)
*Sheikh Abdur Raheem Ali,Justin Xu,Ivory Yang,Jasmine Xinze Li,Ayse Arslan,Clark Benham*

Main category: cs.LG

TL;DR: 对比激活增加（CAA）技术在Llama 2模型上的效果随层级和模型规模变化，负面引导效果更强。


<details>
  <summary>Details</summary>
Motivation: 评估对比激活增加（CAA）技术在不同规模模型上的有效性，以了解其在复杂和强大语言模型上的应用潜力。

Method: 通过寻找模型残差流向量空间中的“方向”并将其添加到前向传播过程中，来探索对比激活增加（CAA）技术在Llama 2模型（7B、13B和70B）上的有效性。使用以拒绝行为为中心的答案匹配问题进行评估。

Result: 1) CAA在模型早期到中期层级最为有效。 2) CAA的效果随着模型规模的增大而减弱。 3) 负面引导比正面引导在所有模型规模上都产生更明显的效果。

Conclusion: 对比激活增加（CAA）技术在不同规模的Llama 2模型上进行了探索，发现其在模型早期到中期层级效果最佳，但随着模型规模增大，效果会减弱。此外，负面引导比正面引导具有更显著的影响。

Abstract: As large language models (LLMs) evolve in complexity and capability, the
efficacy of less widely deployed alignment techniques are uncertain. Building
on previous work on activation steering and contrastive activation addition
(CAA), this paper explores the effectiveness of CAA with model scale using the
family of Llama 2 models (7B, 13B, and 70B). CAA works by finding desirable
'directions' in the model's residual stream vector space using contrastive
pairs (for example, hate to love) and adding this direction to the residual
stream during the forward pass. It directly manipulates the residual stream and
aims to extract features from language models to better control their outputs.
Using answer matching questions centered around the refusal behavior, we found
that 1) CAA is most effective when applied at early-mid layers. 2) The
effectiveness of CAA diminishes with model size. 3) Negative steering has more
pronounced effects than positive steering across all model sizes.

</details>


### [277] [Predicting Delayed Trajectories Using Network Features: A Study on the Dutch Railway Network](https://arxiv.org/abs/2507.11776)
*Merel Kampere,Ali Mohammed Mansoor Alsahag*

Main category: cs.LG

TL;DR: 该研究使用XGBoost和节点中心性来预测荷兰铁路延误，但性能有限，尤其是在非同步测试中，需要更多特定情境的调整。


<details>
  <summary>Details</summary>
Motivation: 为了解决荷兰铁路网络延误预测研究的不足，特别是现有研究侧重于短期预测而忽视了对网络大范围模式的考量，本研究旨在预测延误轨迹，以缓解连锁效应。

Method: 采用XGBoost分类器，并结合节点中心性度量，对荷兰铁路网络中的延误轨迹进行预测。同时，还对比了包括随机森林、决策树、梯度提升、AdaBoost和逻辑回归在内的多种分类器。

Result: XGBoost分类器在预测荷兰铁路延误方面表现出有限的性能，尤其是在非同步测试场景下。研究结果表明，需要针对具体情境进行更多的调整。

Conclusion: 该研究揭示了在非同步测试场景下预测荷兰铁路延误的性能有限，强调了需要进行更符合特定情境的调整。

Abstract: The Dutch railway network is one of the busiest in the world, with delays
being a prominent concern for the principal passenger railway operator NS. This
research addresses a gap in delay prediction studies within the Dutch railway
network by employing an XGBoost Classifier with a focus on topological
features. Current research predominantly emphasizes short-term predictions and
neglects the broader network-wide patterns essential for mitigating ripple
effects. This research implements and improves an existing methodology,
originally designed to forecast the evolution of the fast-changing US air
network, to predict delays in the Dutch Railways. By integrating Node
Centrality Measures and comparing multiple classifiers like RandomForest,
DecisionTree, GradientBoosting, AdaBoost, and LogisticRegression, the goal is
to predict delayed trajectories. However, the results reveal limited
performance, especially in non-simultaneous testing scenarios, suggesting the
necessity for more context-specific adaptations. Regardless, this research
contributes to the understanding of transportation network evaluation and
proposes future directions for developing more robust predictive models for
delays.

</details>


### [278] [Enforcing Latent Euclidean Geometry in Single-Cell VAEs for Manifold Interpolation](https://arxiv.org/abs/2507.11789)
*Alessandro Palma,Sergei Rybakov,Leon Hetzel,Stephan Günnemann,Fabian J. Theis*

Main category: cs.LG

TL;DR: FlatVI 是一种新的训练框架，通过将潜在流形正则化为欧几里得几何，改进了单细胞 RNA 测序数据的轨迹重建和流形插值。


<details>
  <summary>Details</summary>
Motivation: 现有的单细胞 RNA 测序方法在模拟细胞状态转换时，通常假设潜在空间中的线性平移和欧几里得几何，但这可能与数据流形上的测地线路径不匹配，限制了下游方法。

Method: 提出了一种名为 FlatVI 的新颖训练框架，该框架将离散似然变分自编码器的潜在流形正则化为欧几里得几何。

Result: 在合成数据上的实验支持了该方法的理论健全性，同时在时间解析单细胞 RNA 测序数据上的应用证明了其在轨迹重建和流形插值方面的改进。

Conclusion: FlatVI 框架通过正则化潜在流形以实现欧几里得几何，从而提高在单细胞 RNA 测序数据的时间解析轨迹重建和流形插值方面的性能。

Abstract: Latent space interpolations are a powerful tool for navigating deep
generative models in applied settings. An example is single-cell RNA
sequencing, where existing methods model cellular state transitions as latent
space interpolations with variational autoencoders, often assuming linear
shifts and Euclidean geometry. However, unless explicitly enforced, linear
interpolations in the latent space may not correspond to geodesic paths on the
data manifold, limiting methods that assume Euclidean geometry in the data
representations. We introduce FlatVI, a novel training framework that
regularises the latent manifold of discrete-likelihood variational autoencoders
towards Euclidean geometry, specifically tailored for modelling single-cell
count data. By encouraging straight lines in the latent space to approximate
geodesic interpolations on the decoded single-cell manifold, FlatVI enhances
compatibility with downstream approaches that assume Euclidean latent geometry.
Experiments on synthetic data support the theoretical soundness of our
approach, while applications to time-resolved single-cell RNA sequencing data
demonstrate improved trajectory reconstruction and manifold interpolation.

</details>


### [279] [CLID-MU: Cross-Layer Information Divergence Based Meta Update Strategy for Learning with Noisy Labels](https://arxiv.org/abs/2507.11807)
*Ruofan Hu,Dongyu Zhang,Huayi Zhang,Elke Rundensteiner*

Main category: cs.LG

TL;DR: 提出一种无需干净标签数据集的元学习方法CLID-MU，通过跨层信息一致性指导训练，在带噪声标签的数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的元学习方法在处理带噪声标签的数据时需要干净的标签元数据集，但在实际应用中难以获得。本研究旨在解决这一挑战，提出一种无需干净标签数据集的元学习方法。

Method: CLID-MU方法利用了数据本身的结构信息，通过衡量模型最后隐藏层与最终层之间数据结构的一致性来评估模型性能并指导训练，以此解决了传统元学习方法对干净标签数据集的依赖。

Result: CLID-MU在合成和真实世界噪声数据集上的实验结果表明，该方法在不同噪声比例下均优于最先进的方法。

Conclusion: 该研究提出了一种无需干净标签数据集的元学习方法CLID-MU，并通过实验证明其在处理带噪声标签的数据时优于现有技术。

Abstract: Learning with noisy labels (LNL) is essential for training deep neural
networks with imperfect data. Meta-learning approaches have achieved success by
using a clean unbiased labeled set to train a robust model. However, this
approach heavily depends on the availability of a clean labeled meta-dataset,
which is difficult to obtain in practice. In this work, we thus tackle the
challenge of meta-learning for noisy label scenarios without relying on a clean
labeled dataset. Our approach leverages the data itself while bypassing the
need for labels. Building on the insight that clean samples effectively
preserve the consistency of related data structures across the last hidden and
the final layer, whereas noisy samples disrupt this consistency, we design the
Cross-layer Information Divergence-based Meta Update Strategy (CLID-MU).
CLID-MU leverages the alignment of data structures across these diverse feature
spaces to evaluate model performance and use this alignment to guide training.
Experiments on benchmark datasets with varying amounts of labels under both
synthetic and real-world noise demonstrate that CLID-MU outperforms
state-of-the-art methods. The code is released at
https://github.com/ruofanhu/CLID-MU.

</details>


### [280] [SynCoGen: Synthesizable 3D Molecule Generation via Joint Reaction and Coordinate Modeling](https://arxiv.org/abs/2507.11818)
*Andrei Rekesh,Miruna Cretu,Dmytro Shevchuk,Vignesh Ram Somnath,Pietro Liò,Robert A. Batey,Mike Tyers,Michał Koziarski,Cheng-Hao Liu*

Main category: cs.LG

TL;DR: SynCoGen 是一个用于可合成 3D 分子生成的框架，它结合了扩散模型和流匹配，并使用包含 600K 砌块图和 3.3M 构象的 SynSpace 数据集进行训练。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有生成模型在 2D 分子图表示上的局限性，该工作提出了 SynCoGen，一个能够进行几何条件生成的框架。

Method: SynCoGen 框架结合了同时掩码图扩散和流匹配，用于可合成的 3D 分子生成，并从分子砌块、化学反应和原子坐标的联合分布中进行采样。SynSpace 数据集包含超过 600K 个合成感知砌块图和 3.3M 个构象。

Result: SynCoGen 在无条件小分子图和构象生成方面实现了最先进的性能，并在零样本分子连接器设计方面表现出有竞争力。

Conclusion: SynCoGen 框架通过结合同时掩码图扩散和流匹配，实现了可合成的 3D 分子生成，并在无条件小分子图和构象生成方面取得了最先进的性能，同时在药物发现的蛋白质配体生成方面，在零样本分子连接器设计方面也表现出有竞争力。

Abstract: Ensuring synthesizability in generative small molecule design remains a major
challenge. While recent developments in synthesizable molecule generation have
demonstrated promising results, these efforts have been largely confined to 2D
molecular graph representations, limiting the ability to perform geometry-based
conditional generation. In this work, we present SynCoGen (Synthesizable
Co-Generation), a single framework that combines simultaneous masked graph
diffusion and flow matching for synthesizable 3D molecule generation. SynCoGen
samples from the joint distribution of molecular building blocks, chemical
reactions, and atomic coordinates. To train the model, we curated SynSpace, a
dataset containing over 600K synthesis-aware building block graphs and 3.3M
conformers. SynCoGen achieves state-of-the-art performance in unconditional
small molecule graph and conformer generation, and the model delivers
competitive performance in zero-shot molecular linker design for protein ligand
generation in drug discovery. Overall, this multimodal formulation represents a
foundation for future applications enabled by non-autoregressive molecular
generation, including analog expansion, lead optimization, and direct structure
conditioning.

</details>


### [281] [MNIST-Gen: A Modular MNIST-Style Dataset Generation Using Hierarchical Semantics, Reinforcement Learning, and Category Theory](https://arxiv.org/abs/2507.11821)
*Pouya Shaeri,Arash Karimi,Ariane Middel*

Main category: cs.LG

TL;DR: MNIST-Gen：自动生成特定任务的MNIST风格数据集，利用CLIP和强化学习，提高效率和准确性，已成功应用于树木和食物分类。


<details>
  <summary>Details</summary>
Motivation: 标准MNIST数据集在领域特定任务（如树木、食物分类）中存在局限性和不足。手动创建和发布自定义数据集耗时且受限，因此需要一个自动化、适应性强的数据集生成框架。

Method: MNIST-Gen框架结合了基于CLIP的语义理解、强化学习和人类反馈，采用分层语义分类方法，支持复杂的类别结构和多种处理模式（单独审查、智能批量处理、快速批量处理）。借鉴范畴论的思想，将数据转换阶段建模为可组合的态射。

Result: 成功生成了“Tree-MNIST”和“Food-MNIST”两个新的特定任务数据集。MNIST-Gen实现了85%的自动分类准确率，并与手动方法相比节省了80%的时间，证明了其在生成特定任务评估数据方面的有效性。

Conclusion: 该研究提出了MNIST-Gen框架，一个能够自动生成特定类别MNIST风格图像数据集的系统。该系统利用CLIP和强化学习，结合人类反馈，实现了高效且智能的数据集创建。实验证明，MNIST-Gen在生成“Tree-MNIST”和“Food-MNIST”数据集方面表现出色，自动分类准确率达到85%，并节省了80%的时间。

Abstract: Neural networks are often benchmarked using standard datasets such as MNIST,
FashionMNIST, or other variants of MNIST, which, while accessible, are limited
to generic classes such as digits or clothing items. For researchers working on
domain-specific tasks, such as classifying trees, food items, or other
real-world objects, these data sets are insufficient and irrelevant.
Additionally, creating and publishing a custom dataset can be time consuming,
legally constrained, or beyond the scope of individual projects. We present
MNIST-Gen, an automated, modular, and adaptive framework for generating
MNIST-style image datasets tailored to user-specified categories using
hierarchical semantic categorization. The system combines CLIP-based semantic
understanding with reinforcement learning and human feedback to achieve
intelligent categorization with minimal manual intervention. Our hierarchical
approach supports complex category structures with semantic characteristics,
enabling fine-grained subcategorization and multiple processing modes:
individual review for maximum control, smart batch processing for large
datasets, and fast batch processing for rapid creation. Inspired by category
theory, MNIST-Gen models each data transformation stage as a composable
morphism, enhancing clarity, modularity, and extensibility. As proof of
concept, we generate and benchmark two novel datasets-\textit{Tree-MNIST} and
\textit{Food-MNIST}-demonstrating MNIST-Gen's utility for producing
task-specific evaluation data while achieving 85\% automatic categorization
accuracy and 80\% time savings compared to manual approaches.

</details>


### [282] [HyperEvent:Learning Cohesive Events for Large-scale Dynamic Link Prediction](https://arxiv.org/abs/2507.11836)
*Jian Gao,Jianshe Wu,JingYi Ding*

Main category: cs.LG

TL;DR: HyperEvent 通过将动态链接预测视为超事件识别，并使用事件相关性向量构建关联序列，有效捕捉了事件间的结构联系。该方法在多个数据集上超越了现有技术，并在大规模数据集上实现了更高的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理动态链接预测时，侧重于单个交互或原子状态，未能捕捉复合超事件（即因果相关事件组）的结构内聚性。

Method: 提出了一种名为 HyperEvent 的框架，将动态链接预测任务重构为超事件识别问题。该框架通过动态构建关联序列来量化查询事件与历史事件之间的成对依赖关系，以捕捉超事件的结构内聚性。此外，还提出了一种高效的并行训练算法，通过分割事件流来实现大规模图的并发训练。

Result: HyperEvent 在 5 个数据集中的 4 个上优于最先进的方法。在 Flight 数据集上，平均倒数排名（MRR）相较于基线方法提高了 6.95%，同时训练时间仅占基线的 10.17%。

Conclusion: HyperEvent 通过将动态链接预测重新构建为超事件识别，并引入动态构建的关联序列，成功捕捉了复合超事件的结构内聚性。该框架在 5 个数据集中的 4 个上超越了现有方法，并在大规模图上展示了出色的准确性和效率，例如在 Flight 数据集上实现了 6.95% 的平均倒数排名提升，同时训练时间仅为现有方法的 10.17%。

Abstract: Dynamic link prediction in continuous-time dynamic graphs is a fundamental
task for modeling evolving complex systems. Existing node-centric and
event-centric methods focus on individual interactions or atomic states,
failing to capture the structural cohesion of composite hyper-events, groups of
causally related events. To address this, we propose HyperEvent, a framework
reframing dynamic link prediction as hyper-event recognition. Central to
HyperEvent is the dynamic construction of an association sequence using event
correlation vectors. These vectors quantify pairwise dependencies between the
query event and relevant historical events, thereby characterizing the
structural cohesion of a potential hyper-event. The framework predicts the
occurrence of the query event by evaluating whether it collectively forms a
valid hyper-event with these historical events. Notably, HyperEvent outperforms
state-of-the-art methods on 4 out of 5 datasets in the official leaderboard.
For scalability, we further introduce an efficient parallel training algorithm
that segments large event streams to enable concurrent training. Experiments
validate HyperEvent's superior accuracy and efficiency on large-scale graphs.
Among which HyperEvent achieves a 6.95% improvement in Mean Reciprocal Rank
over state-of-the-art baseline on the large-scale Flight dataset while
utilizing only 10.17% of the training time.

</details>


### [283] [Protenix-Mini: Efficient Structure Predictor via Compact Architecture, Few-Step Diffusion and Switchable pLM](https://arxiv.org/abs/2507.11839)
*Chengyue Gong,Xinshi Chen,Yuxuan Zhang,Yuxuan Song,Hao Zhou,Wenzhi Xiao*

Main category: cs.LG

TL;DR: Protenix-Mini optimizes protein structure prediction by using a faster ODE sampler, pruning network components, and replacing the MSA module, resulting in a more efficient model with minimal accuracy loss.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the challenge of balancing model efficiency and prediction accuracy in biomolecular structure prediction for efficient real-world deployment and inference-time scaling, especially for large-scale applications with limited computational resources.

Method: The study introduces Protenix-Mini, a lightweight protein structure prediction model, by replacing the multi-step AF3 sampler with a few-step ODE sampler, pruning redundant blocks in the Protenix framework, and substituting the MSA module with an ESM module. It utilizes a two-step ODE sampling strategy and a streamlined architecture.

Result: Protenix-Mini achieves high-fidelity predictions with only a negligible 1 to 5 percent decrease in performance compared to its full-scale counterpart on benchmark datasets, demonstrating significant reduction in model complexity and computational overhead.

Conclusion: Protenix-Mini is an efficient protein structure prediction model that significantly reduces computational overhead with a slight decrease in accuracy, making it suitable for resource-limited applications.

Abstract: Lightweight inference is critical for biomolecular structure prediction and
other downstream tasks, enabling efficient real-world deployment and
inference-time scaling for large-scale applications. In this work, we address
the challenge of balancing model efficiency and prediction accuracy by making
several key modifications, 1) Multi-step AF3 sampler is replaced by a few-step
ODE sampler, significantly reducing computational overhead for the diffusion
module part during inference; 2) In the open-source Protenix framework, a
subset of pairformer or diffusion transformer blocks doesn't make contributions
to the final structure prediction, presenting opportunities for architectural
pruning and lightweight redesign; 3) A model incorporating an ESM module is
trained to substitute the conventional MSA module, reducing MSA preprocessing
time. Building on these key insights, we present Protenix-Mini, a compact and
optimized model designed for efficient protein structure prediction. This
streamlined version incorporates a more efficient architectural design with a
two-step Ordinary Differential Equation (ODE) sampling strategy. By eliminating
redundant Transformer components and refining the sampling process,
Protenix-Mini significantly reduces model complexity with slight accuracy drop.
Evaluations on benchmark datasets demonstrate that it achieves high-fidelity
predictions, with only a negligible 1 to 5 percent decrease in performance on
benchmark datasets compared to its full-scale counterpart. This makes
Protenix-Mini an ideal choice for applications where computational resources
are limited but accurate structure prediction remains crucial.

</details>


### [284] [Online Training and Pruning of Deep Reinforcement Learning Networks](https://arxiv.org/abs/2507.11975)
*Valentin Frank Ingmar Guenter,Athanasios Sideris*

Main category: cs.LG

TL;DR: 在强化学习中，通过一种新的训练和剪枝结合的方法（XiNet），可以有效压缩大型神经网络，提升效率和性能，同时保持原有表现。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络（NN）强化学习（RL）算法在利用特征提取网络时性能有所提升，但计算和内存复杂性也显著增加。神经网络剪枝方法在监督学习中有效解决了这个问题，但在RL中的应用仍有待探索。因此，需要一种在RL中有效应用剪枝技术的方法。

Method: 本研究提出了一种将训练和剪枝相结合的方法，用于优化强化学习（RL）算法，特别是那些使用在线特征提取网络（OFENet）的算法。该方法通过训练网络来解决随机优化问题，以确定网络权重和用于缩放每个单元的0/1随机变量（ξ）的变分伯努利分布的参数。当某个单元对性能贡献很小时，其对应的变分参数会趋向于0，从而将该单元永久性地剪枝。研究中还提出了一种成本感知、促进稀疏性的正则化方案，该方案针对OFENet的DenseNet架构，并自动选择相关超参数，将RL目标与网络压缩相结合。

Result: 通过在连续控制基准（MuJoCo）和Soft Actor-Critic RL代理上评估，证明了OFENet可以被大幅度剪枝，同时性能损失极小。实验结果还表明，在训练过程中剪枝大型网络比从头开始训练小型网络能产生更有效、性能更高的RL代理。

Conclusion: 该方法可以大幅度修剪大型神经网络，同时保持性能。此外，在训练过程中修剪大型网络可以产生比从头开始训练的小型网络更有效、性能更高的强化学习代理。

Abstract: Scaling deep neural networks (NN) of reinforcement learning (RL) algorithms
has been shown to enhance performance when feature extraction networks are used
but the gained performance comes at the significant expense of increased
computational and memory complexity. Neural network pruning methods have
successfully addressed this challenge in supervised learning. However, their
application to RL is underexplored. We propose an approach to integrate
simultaneous training and pruning within advanced RL methods, in particular to
RL algorithms enhanced by the Online Feature Extractor Network (OFENet). Our
networks (XiNet) are trained to solve stochastic optimization problems over the
RL networks' weights and the parameters of variational Bernoulli distributions
for 0/1 Random Variables $\xi$ scaling each unit in the networks. The
stochastic problem formulation induces regularization terms that promote
convergence of the variational parameters to 0 when a unit contributes little
to the performance. In this case, the corresponding structure is rendered
permanently inactive and pruned from its network. We propose a cost-aware,
sparsity-promoting regularization scheme, tailored to the DenseNet architecture
of OFENets expressing the parameter complexity of involved networks in terms of
the parameters of the RVs in these networks. Then, when matching this cost with
the regularization terms, the many hyperparameters associated with them are
automatically selected, effectively combining the RL objectives and network
compression. We evaluate our method on continuous control benchmarks (MuJoCo)
and the Soft Actor-Critic RL agent, demonstrating that OFENets can be pruned
considerably with minimal loss in performance. Furthermore, our results confirm
that pruning large networks during training produces more efficient and higher
performing RL agents rather than training smaller networks from scratch.

</details>


### [285] [Generalized Linear Bandits: Almost Optimal Regret with One-Pass Update](https://arxiv.org/abs/2507.11847)
*Yu-Jie Zhang,Sheng-An Xu,Peng Zhao,Masashi Sugiyama*

Main category: cs.LG

TL;DR: 文章提出了一个联合高效的算法，用于解决广义线性老虎机（GLB）问题，实现了接近最优的后悔界限和恒定的时间和空间复杂度。


<details>
  <summary>Details</summary>
Motivation: 为了解决广义线性老虎机（GLB）问题中存在的计算和统计效率的权衡问题。

Method: 该算法的核心是为在线镜像下降（OMD）估计器提供一个精确的置信集，该置信集是通过利用在线预测中的混合损失概念进行的新颖分析得出的。

Result: 该方法实现了接近最优的后悔界限，并且每轮具有恒定的时间和空间复杂度，其统计效率与最大似然估计相当。

Conclusion: 文章提出了一个联合高效的算法，实现了接近最优的后悔界限，并且每轮具有恒定的时间和空间复杂度。

Abstract: We study the generalized linear bandit (GLB) problem, a contextual
multi-armed bandit framework that extends the classical linear model by
incorporating a non-linear link function, thereby modeling a broad class of
reward distributions such as Bernoulli and Poisson. While GLBs are widely
applicable to real-world scenarios, their non-linear nature introduces
significant challenges in achieving both computational and statistical
efficiency. Existing methods typically trade off between two objectives, either
incurring high per-round costs for optimal regret guarantees or compromising
statistical efficiency to enable constant-time updates. In this paper, we
propose a jointly efficient algorithm that attains a nearly optimal regret
bound with $\mathcal{O}(1)$ time and space complexities per round. The core of
our method is a tight confidence set for the online mirror descent (OMD)
estimator, which is derived through a novel analysis that leverages the notion
of mix loss from online prediction. The analysis shows that our OMD estimator,
even with its one-pass updates, achieves statistical efficiency comparable to
maximum likelihood estimation, thereby leading to a jointly efficient
optimistic method.

</details>


### [286] [OrdShap: Feature Position Importance for Sequential Black-Box Models](https://arxiv.org/abs/2507.11855)
*Davin Hill,Brian L. Hill,Aria Masoomi,Vijay S. Nori,Robert E. Tillman,Jennifer Dy*

Main category: cs.LG

TL;DR: OrdShap 是一种新的归因方法，可以区分序列深度学习模型中特征值和特征位置的影响，并提供对其行为的更深入的见解。


<details>
  <summary>Details</summary>
Motivation: 现有的归因技术量化特征重要性，但它们固有地假设特征排序固定，混淆了（1）特征值和（2）它们在输入序列中的位置的影响。为了解决这个差距，我们引入了 OrdShap。

Method: OrdShap 通过置换特征位置来量化模型预测的变化，从而区分特征值和特征位置的影响。OrdShap 与 Sanchez-Berganti

os 值之间存在博弈论联系，为位置敏感归因提供了一种理论上合理的方法。

Result: OrdShap 在健康、自然语言和合成数据集的经验结果突显了 OrdShap 在捕捉特征值和特征位置归因方面的有效性，并提供了对模型行为的更深入的见解。

Conclusion: OrdShap 是一种新颖的归因方法，它通过量化模型预测对置换特征位置的响应来区分这些效应，在健康、自然语言和合成数据集的经验结果突显了 OrdShap 在捕捉特征值和特征位置归因方面的有效性，并提供了对模型行为的更深入的见解。

Abstract: Sequential deep learning models excel in domains with temporal or sequential
dependencies, but their complexity necessitates post-hoc feature attribution
methods for understanding their predictions. While existing techniques quantify
feature importance, they inherently assume fixed feature ordering - conflating
the effects of (1) feature values and (2) their positions within input
sequences. To address this gap, we introduce OrdShap, a novel attribution
method that disentangles these effects by quantifying how a model's predictions
change in response to permuting feature position. We establish a game-theoretic
connection between OrdShap and Sanchez-Berganti\~nos values, providing a
theoretically grounded approach to position-sensitive attribution. Empirical
results from health, natural language, and synthetic datasets highlight
OrdShap's effectiveness in capturing feature value and feature position
attributions, and provide deeper insight into model behavior.

</details>


### [287] [A Policy-Improved Deep Deterministic Policy Gradient Framework for the Discount Order Acceptance Strategy of Ride-hailing Drivers](https://arxiv.org/abs/2507.11865)
*Hanwen Dai,Chang Gao,Fang He,Congyuan Ji,Yanni Yang*

Main category: cs.LG

TL;DR: 为了优化网约车平台上的折扣快车服务，我们提出了一种名为pi-DDPG的强化学习框架。该框架通过改进的策略学习和时空模式捕捉，能有效管理司机接受服务的决策，尤其是在数据有限的早期阶段，能够显著降低训练成本并提高学习效率。


<details>
  <summary>Details</summary>
Motivation: 为了应对网约车平台整合带来的市场碎片化问题，需要管理司机接受折扣快车服务的行为。然而，新业务模式下缺乏历史数据，需要在线学习。但早期探索成本高昂，因此需要可靠的早期性能。该研究旨在解决这些挑战，动态管理司机接受折扣快车服务的比例。

Method: 提出了一种名为pi-DDPG的框架，该框架结合了：1. 策略改进模块：用于在早期训练阶段提升策略性能。2. 卷积长短期记忆网络（CLSTM）：用于捕捉复杂时空模式。3. 优先经验回放机制：用于提高学习效率。该框架将司机接受折扣快车服务的比例决策制定为一个连续控制任务，并使用基于真实数据集的模拟器进行验证。

Result: 数值实验结果表明，pi-DDPG框架实现了更优越的学习效率，并显著降低了早期训练的损失。

Conclusion: 该研究提出了一个名为pi-DDPG的框架，通过结合策略改进模块、卷积长短期记忆网络和优先经验回放机制，来动态管理网约车平台司机的折扣快车服务接受行为，以应对数据稀疏、高随机性和不透明的匹配机制等挑战。实验结果表明，pi-DDPG在学习效率和早期训练损失方面表现优于现有方法。

Abstract: The rapid expansion of platform integration has emerged as an effective
solution to mitigate market fragmentation by consolidating multiple
ride-hailing platforms into a single application. To address heterogeneous
passenger preferences, third-party integrators provide Discount Express service
delivered by express drivers at lower trip fares. For the individual platform,
encouraging broader participation of drivers in Discount Express services has
the potential to expand the accessible demand pool and improve matching
efficiency, but often at the cost of reduced profit margins. This study aims to
dynamically manage drivers' acceptance of Discount Express from the perspective
of individual platforms. The lack of historical data under the new business
model necessitates online learning. However, early-stage exploration through
trial and error can be costly in practice, highlighting the need for reliable
early-stage performance in real-world deployment. To address these challenges,
this study formulates the decision regarding the proportion of drivers'
acceptance behavior as a continuous control task. In response to the high
stochasticity, the opaque matching mechanisms employed by third-party
integrator, and the limited availability of historical data, we propose a
policy-improved deep deterministic policy gradient (pi-DDPG) framework. The
proposed framework incorporates a refiner module to boost policy performance
during the early training phase, leverages a convolutional long short-term
memory network to effectively capture complex spatiotemporal patterns, and
adopts a prioritized experience replay mechanism to enhance learning
efficiency. A simulator based on a real-world dataset is developed to validate
the effectiveness of the proposed pi-DDPG. Numerical experiments demonstrate
that pi-DDPG achieves superior learning efficiency and significantly reduces
early-stage training losses.

</details>


### [288] [Imbalanced Regression Pipeline Recommendation](https://arxiv.org/abs/2507.11901)
*Juscimara G. Avelino,George D. C. Cavalcanti,Rafael M. O. Cruz*

Main category: cs.LG

TL;DR: 该研究提出了一种名为 Meta-IR 的新框架，用于解决不平衡回归问题。该框架使用元学习来自动选择最佳的重采样和学习模型组合，并在实验中优于现有方法和 AutoML 框架。


<details>
  <summary>Details</summary>
Motivation: 不平衡问题广泛存在于现实世界的各种场景中，并且在分类任务中得到了广泛研究。然而，由于某些目标值的稀有性，它们也给回归任务带来了挑战。常见的替代方法是采用预处理中的平衡算法来解决数据集不平衡问题。但由于重采样方法和学习模型的各种组合，确定最优解决方案需要测试大量的组合。此外，学习模型、数据集和评估指标都会影响最佳策略。因此，需要一种更有效的方法来自动选择最佳的解决方案。

Method: 提出了一种名为“Meta-learning for Imbalanced Regression (Meta-IR)”的框架，该框架不依赖于现有的文献，而是通过训练元分类器来为每个任务在零样本的情况下推荐最佳的重采样策略和学习模型组合。元分类器利用一组元特征来学习如何将这些元特征映射到指示最佳管道的类别。文章提出了两种方法：“Independent” 方法分别训练元分类器来指示最佳学习算法和重采样策略；“Chained” 方法则通过一个包含多个步骤的过程，将一个元分类器的输出作为另一个的输入，以模拟内在的关系因素。

Result: 与 AutoML 框架相比，“Meta-IR” 取得了更好的结果。此外，与包括六种学习算法和六种重采样算法（加上无重采样，总共 42 种配置）的基线方法相比，“Meta-IR” 表现更优。特别是，“Chained” 方法显示出优越的性能，表明学习算法和重采样策略之间存在任务特定的内在关系。

Conclusion: "Meta-IR" 框架在处理不平衡回归问题时，通过训练元分类器来推荐最佳的重采样策略和学习模型组合，并在零样本设置下实现了优于 AutoML 框架和现有基线方法的性能。其中，“Chained” 方法通过模拟学习算法和重采样策略之间的内在关系，展现出更优越的性能。

Abstract: Imbalanced problems are prevalent in various real-world scenarios and are
extensively explored in classification tasks. However, they also present
challenges for regression tasks due to the rarity of certain target values. A
common alternative is to employ balancing algorithms in preprocessing to
address dataset imbalance. However, due to the variety of resampling methods
and learning models, determining the optimal solution requires testing many
combinations. Furthermore, the learning model, dataset, and evaluation metric
affect the best strategies. This work proposes the Meta-learning for Imbalanced
Regression (Meta-IR) framework, which diverges from existing literature by
training meta-classifiers to recommend the best pipeline composed of the
resampling strategy and learning model per task in a zero-shot fashion. The
meta-classifiers are trained using a set of meta-features to learn how to map
the meta-features to the classes indicating the best pipeline. We propose two
formulations: Independent and Chained. Independent trains the meta-classifiers
to separately indicate the best learning algorithm and resampling strategy.
Chained involves a sequential procedure where the output of one meta-classifier
is used as input for another to model intrinsic relationship factors. The
Chained scenario showed superior performance, suggesting a relationship between
the learning algorithm and the resampling strategy per task. Compared with
AutoML frameworks, Meta-IR obtained better results. Moreover, compared with
baselines of six learning algorithms and six resampling algorithms plus no
resampling, totaling 42 (6 X 7) configurations, Meta-IR outperformed all of
them. The code, data, and further information of the experiments can be found
on GitHub: https://github.com/JusciAvelino/Meta-IR.

</details>


### [289] [Resampling strategies for imbalanced regression: a survey and empirical analysis](https://arxiv.org/abs/2507.11902)
*Juscimara G. Avelino,George D. C. Cavalcanti,Rafael M. O. Cruz*

Main category: cs.LG

TL;DR: 本研究针对回归任务中的不平衡问题，提出了分类法，进行了广泛的实验研究，并提供了新的见解和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 现实世界中存在不平衡问题，虽然在分类领域已有研究，但目标值为连续的回归任务也存在同样的问题，需要解决。

Method: 提出了一种基于三个关键标准（回归模型、学习过程和评估指标）的不平衡回归方法分类法，并进行了广泛的实验研究，包括各种平衡和预测模型。

Result: 通过实验研究了不平衡回归的各种平衡和预测模型，并使用指标捕捉了用户的重要因素，以评估预测模型在不平衡回归数据上下文中的表现。

Conclusion: 该研究为不平衡回归方法提供了新的见解，强调了它们对各种模型学习过程的优势，并指明了进一步研究的方向。

Abstract: Imbalanced problems can arise in different real-world situations, and to
address this, certain strategies in the form of resampling or balancing
algorithms are proposed. This issue has largely been studied in the context of
classification, and yet, the same problem features in regression tasks, where
target values are continuous. This work presents an extensive experimental
study comprising various balancing and predictive models, and wich uses metrics
to capture important elements for the user and to evaluate the predictive model
in an imbalanced regression data context. It also proposes a taxonomy for
imbalanced regression approaches based on three crucial criteria: regression
model, learning process, and evaluation metrics. The study offers new insights
into the use of such strategies, highlighting the advantages they bring to each
model's learning process, and indicating directions for further studies. The
code, data and further information related to the experiments performed herein
can be found on GitHub: https://github.com/JusciAvelino/imbalancedRegression.

</details>


### [290] [From Generative to Episodic: Sample-Efficient Replicable Reinforcement Learning](https://arxiv.org/abs/2507.11926)
*Max Hopkins,Sihan Liu,Christopher Ye,Yuichi Yoshida*

Main category: cs.LG

TL;DR: 本文提出了一种高效的可复现强化学习算法，将样本复杂度从 O(S^7 A^7) 降低到 O(S^2A)，解决了可复现探索比批量学习更昂贵的问题。


<details>
  <summary>Details</summary>
Motivation: 由于经验科学和机器学习中普遍存在的复现性失败问题，对可复现学习算法的研究日益受到关注。在强化学习（RL）领域，尤其是在与环境互动的控制设置中，存在着数据效率和复现性的巨大知识空白，这促使研究者探索可复现探索的成本以及样本效率可复现 RL 的可能性。

Method: 本文提出了一种新的可复现强化学习算法，其样本复杂度显著低于现有最优上界 O(S^7 A^7)，并证明了 O(S^2A) 的下界，表明该算法在样本效率方面接近最优。

Result: 本文的主要成果是一种新的可复现强化学习算法，其样本复杂度为 O(S^2A)（在低时限表格型 MDPs 上），接近了生成模型设置下的 O(S^2A^2) 和非生成模型设置下的 O(S^7 A^7）的差距。此外，研究还提供了 O(S^2A) 的下界（在生成模型设置下，具有并行采样假设）和 O(S^2) 的无条件下界（在片段式设置下），证明了算法在状态空间 S 方面的近乎最优性。

Conclusion: 本研究展示了一种用于低时限表格型马尔可夫决策过程（MDP）的可复现强化学习算法，其样本复杂度为 O(S^2A)，这显著缩小了生成模型和非生成模型环境之间的差距，并接近于无生成模型情况下的下界 O(S^2)。

Abstract: The epidemic failure of replicability across empirical science and machine
learning has recently motivated the formal study of replicable learning
algorithms [Impagliazzo et al. (2022)]. In batch settings where data comes from
a fixed i.i.d. source (e.g., hypothesis testing, supervised learning), the
design of data-efficient replicable algorithms is now more or less understood.
In contrast, there remain significant gaps in our knowledge for control
settings like reinforcement learning where an agent must interact directly with
a shifting environment. Karbasi et. al show that with access to a generative
model of an environment with $S$ states and $A$ actions (the RL 'batch
setting'), replicably learning a near-optimal policy costs only
$\tilde{O}(S^2A^2)$ samples. On the other hand, the best upper bound without a
generative model jumps to $\tilde{O}(S^7 A^7)$ [Eaton et al. (2024)] due to the
substantial difficulty of environment exploration. This gap raises a key
question in the broader theory of replicability: Is replicable exploration
inherently more expensive than batch learning? Is sample-efficient replicable
RL even possible?
  In this work, we (nearly) resolve this problem (for low-horizon tabular
MDPs): exploration is not a significant barrier to replicable learning! Our
main result is a replicable RL algorithm on $\tilde{O}(S^2A)$ samples, bridging
the gap between the generative and episodic settings. We complement this with a
matching $\tilde{\Omega}(S^2A)$ lower bound in the generative setting (under
the common parallel sampling assumption) and an unconditional lower bound in
the episodic setting of $\tilde{\Omega}(S^2)$ showcasing the near-optimality of
our algorithm with respect to the state space $S$.

</details>


### [291] [Accelerating RF Power Amplifier Design via Intelligent Sampling and ML-Based Parameter Tuning](https://arxiv.org/abs/2507.11928)
*Abhishek Sriram,Neal Tuffy*

Main category: cs.LG

TL;DR: 通过使用MaxMin Latin Hypercube Sampling和CatBoost梯度提升，该研究提出了一种机器学习加速的优化框架，用于射频功率放大器设计，将仿真需求减少65%，同时保持±0.3至±0.4 dBm的精度。


<details>
  <summary>Details</summary>
Motivation: 本文提出了一个机器学习加速的优化框架，用于射频功率放大器设计，可将仿真需求减少65%，同时保持±0.3至±0.4 dBm的精度。

Method: 本研究提出的方法结合了MaxMin Latin Hypercube Sampling和CatBoost梯度提升，以智能地探索多维参数空间。该方法不是通过穷举模拟所有参数组合来达到目标P2dB压缩规格，而是有选择性地选取约35%的关键仿真点。该框架处理ADS网表，在简化的数据集上执行谐波平衡仿真，并训练CatBoost模型来预测整个设计空间中的P2dB性能。

Result: 所提出的框架在15个PA工作模式下的验证产生了0.901的平均R²，并通过系统对参数组合按其满足目标规格的可能性进行排名。

Conclusion: 该框架通过自动化基于GUI的工作流程，将仿真时间缩短了58.24%至77.78%，从而在不影响生产射频电路所需的精度标准的情况下，实现了快速设计迭代。

Abstract: This paper presents a machine learning-accelerated optimization framework for
RF power amplifier design that reduces simulation requirements by 65% while
maintaining $\pm0.3$ to $\pm0.4$ dBm accuracy. The proposed method combines
MaxMin Latin Hypercube Sampling with CatBoost gradient boosting to
intelligently explore multidimensional parameter spaces. Instead of
exhaustively simulating all parameter combinations to achieve target P2dB
compression specifications, our approach strategically selects approximately
35% of critical simulation points. The framework processes ADS netlists,
executes harmonic balance simulations on the reduced dataset, and trains a
CatBoost model to predict P2dB performance across the entire design space.
Validation across 15 PA operating modes yields an average $R^2$ of 0.901, with
the system ranking parameter combinations by their likelihood of meeting target
specifications. The integrated solution delivers 58.24% to 77.78% reduction in
simulation time through automated GUI-based workflows, enabling rapid design
iterations without compromising accuracy standards required for production RF
circuits.

</details>


### [292] [Kevin: Multi-Turn RL for Generating CUDA Kernels](https://arxiv.org/abs/2507.11948)
*Carlo Baronio,Pietro Marsella,Ben Pan,Simon Guo,Silas Alberti*

Main category: cs.LG

TL;DR: 通过多轮强化学习， Kevin模型在AI性能优化中实现了显著的正确率和速度提升。


<details>
  <summary>Details</summary>
Motivation: GPU核函数编写对于AI系统的效率至关重要，但该过程充满挑战且需要反复试验。强化学习（RL）非常适合此场景，因为它具有可验证的奖励（如正确性和加速），并且该过程本身具有迭代性。

Method: 本研究提出了一种灵活的多轮强化学习方法，用于解决长轨迹学习和跨轮次奖励归因等现实挑战，并开发了首个使用该方法进行CUDA核生成和优化的模型Kevin。

Result: Kevin模型将纯CUDA代码的正确率从56%提升至82%，平均加速比从基线（PyTorch Eager）的0.53倍提升至1.10倍，并且超越了o4-mini模型（0.78倍）。

Conclusion: Kevin在多轮强化学习的加持下，在CUDA核生成和优化方面取得了显著的成果。在测试时扩展性方面，通过增加串行优化轮数能比并行采样带来更高的性能提升率。

Abstract: Writing GPU kernels is a challenging task and critical for AI systems'
efficiency. It is also highly iterative: domain experts write code and improve
performance through execution feedback. Moreover, it presents verifiable
rewards like correctness and speedup, making it a natural environment to apply
Reinforcement Learning (RL). To explicitly incorporate the iterative nature of
this process into training, we develop a flexible multi-turn RL recipe that
addresses unique challenges encountered in real-world settings, such as
learning from long trajectories and effective reward attribution across turns.
We present Kevin - K(ernel D)evin, the first model trained with multi-turn RL
for CUDA kernel generation and optimization. In our evaluation setup, Kevin
shows significant gains over its base model (QwQ-32B), improving correctness of
generated kernels (in pure CUDA) from 56% to 82% and mean speedup from 0.53x to
1.10x of baseline (PyTorch Eager), and surpassing frontier models like o4-mini
(0.78x). Finally, we study its behavior across test-time scaling axes: we found
scaling serial refinement more beneficial than parallel sampling. In
particular, when given more refinement turns, Kevin shows a higher rate of
improvement.

</details>


### [293] [Can LLMs Find Fraudsters? Multi-level LLM Enhanced Graph Fraud Detection](https://arxiv.org/abs/2507.11997)
*Tairan Huang,Yili Wang*

Main category: cs.LG

TL;DR: MLED框架利用LLM增强图欺诈检测，通过多级增强器融合文本和图结构信息，在真实数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有图欺诈检测方法忽略了原始文本信息中丰富的语义线索，并且在多模态数据中融合文本和图结构信息方面存在挑战。

Method: MLED框架利用LLM从文本信息中提取外部知识来增强图欺诈检测方法。该框架包括一个类型级增强器和一个关系级增强器，分别用于增强欺诈者与良性实体之间的差异以及欺诈者在不同关系中的重要性。

Result: 实验结果表明，MLED在四个真实数据集上取得了最先进的性能。

Conclusion: MLED是一个通用的框架，可以应用于现有方法，在图欺诈检测方面取得了最先进的性能。

Abstract: Graph fraud detection has garnered significant attention as Graph Neural
Networks (GNNs) have proven effective in modeling complex relationships within
multimodal data. However, existing graph fraud detection methods typically use
preprocessed node embeddings and predefined graph structures to reveal
fraudsters, which ignore the rich semantic cues contained in raw textual
information. Although Large Language Models (LLMs) exhibit powerful
capabilities in processing textual information, it remains a significant
challenge to perform multimodal fusion of processed textual embeddings with
graph structures. In this paper, we propose a \textbf{M}ulti-level \textbf{L}LM
\textbf{E}nhanced Graph Fraud \textbf{D}etection framework called MLED. In
MLED, we utilize LLMs to extract external knowledge from textual information to
enhance graph fraud detection methods. To integrate LLMs with graph structure
information and enhance the ability to distinguish fraudsters, we design a
multi-level LLM enhanced framework including type-level enhancer and
relation-level enhancer. One is to enhance the difference between the
fraudsters and the benign entities, the other is to enhance the importance of
the fraudsters in different relations. The experiments on four real-world
datasets show that MLED achieves state-of-the-art performance in graph fraud
detection as a generalized framework that can be applied to existing methods.

</details>


### [294] [Detecting In-Person Conversations in Noisy Real-World Environments with Smartwatch Audio and Motion Sensing](https://arxiv.org/abs/2507.12002)
*Alice Zhang,Callihan Bertley,Dawei Liang,Edison Thomaz*

Main category: cs.LG

TL;DR: 一项研究利用智能手表捕获的音频和惯性数据，在具有挑战性的声学环境中，通过融合口头和非口头线索来检测面对面的口头交谈，并在实验室和半自然环境中分别取得了82.0%和77.2%的宏观F1分数。


<details>
  <summary>Details</summary>
Motivation: 为了在具有挑战性的声学环境中，仅利用商品智能手表捕获的音频和惯性数据，来检测人类社交互动中的基础方面——面对面的口头交谈。

Method: 利用商品智能手表捕获的音频和惯性数据，在声学挑战场景中开发了一种新颖的计算方法来检测面对面的口头交谈。对机器学习和深度学习模型进行了分析，并采用了3种不同的融合方法，证明了融合音频和惯性数据来考虑对话中的口头和非口头线索的优势。

Result: 机器学习和深度学习模型结合3种不同的融合方法，证明了融合音频和惯性数据能够利用口头线索和非口头姿态。在实验室研究和半自然研究中，该框架在对话检测上的宏观F1分数分别为82.0±3.0%和77.2±1.8%。

Conclusion: 该框架在实验室环境中的对话检测上达到了82.0±3.0%的宏观F1分数，在半自然环境中的对话检测上达到了77.2±1.8%的宏观F1分数。

Abstract: Social interactions play a crucial role in shaping human behavior,
relationships, and societies. It encompasses various forms of communication,
such as verbal conversation, non-verbal gestures, facial expressions, and body
language. In this work, we develop a novel computational approach to detect a
foundational aspect of human social interactions, in-person verbal
conversations, by leveraging audio and inertial data captured with a commodity
smartwatch in acoustically-challenging scenarios. To evaluate our approach, we
conducted a lab study with 11 participants and a semi-naturalistic study with
24 participants. We analyzed machine learning and deep learning models with 3
different fusion methods, showing the advantages of fusing audio and inertial
data to consider not only verbal cues but also non-verbal gestures in
conversations. Furthermore, we perform a comprehensive set of evaluations
across activities and sampling rates to demonstrate the benefits of multimodal
sensing in specific contexts. Overall, our framework achieved 82.0$\pm$3.0%
macro F1-score when detecting conversations in the lab and 77.2$\pm$1.8% in the
semi-naturalistic setting.

</details>


### [295] [DUSE: A Data Expansion Framework for Low-resource Automatic Modulation Recognition based on Active Learning](https://arxiv.org/abs/2507.12011)
*Yao Lu,Hongyu Gao,Zhuangzhi Chen,Dongwei Xu,Yun Lin,Qi Xuan,Guan Gui*

Main category: cs.LG

TL;DR: A new framework called DUSE expands data for automatic modulation recognition by using uncertainty scoring and active learning to select useful samples, addressing data scarcity issues and outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Deep neural networks for AMR require a large amount of labeled data, but target domain data is often scarce in practical scenarios, making manual annotation costly and data augmentation insufficient.

Method: DUSE uses an uncertainty scoring function to filter out useful samples from relevant AMR datasets and employs an active learning strategy to continuously refine the scorer.

Result: DUSE outperforms 8 coreset selection baselines and shows strong cross-architecture generalization.

Conclusion: DUSE consistently outperforms 8 coreset selection baselines in both class-balance and class-imbalance settings, and exhibits strong cross-architecture generalization for unseen models.

Abstract: Although deep neural networks have made remarkable achievements in the field
of automatic modulation recognition (AMR), these models often require a large
amount of labeled data for training. However, in many practical scenarios, the
available target domain data is scarce and difficult to meet the needs of model
training. The most direct way is to collect data manually and perform expert
annotation, but the high time and labor costs are unbearable. Another common
method is data augmentation. Although it can enrich training samples to a
certain extent, it does not introduce new data and therefore cannot
fundamentally solve the problem of data scarcity. To address these challenges,
we introduce a data expansion framework called Dynamic Uncertainty-driven
Sample Expansion (DUSE). Specifically, DUSE uses an uncertainty scoring
function to filter out useful samples from relevant AMR datasets and employs an
active learning strategy to continuously refine the scorer. Extensive
experiments demonstrate that DUSE consistently outperforms 8 coreset selection
baselines in both class-balance and class-imbalance settings. Besides, DUSE
exhibits strong cross-architecture generalization for unseen models.

</details>


### [296] [Granular feedback merits sophisticated aggregation](https://arxiv.org/abs/2507.12041)
*Anmol Kagrecha,Henrik Marklund,Potsawee Manakul,Richard Zeckhauser,Benjamin Van Roy*

Main category: cs.LG

TL;DR: 本文研究了如何利用有限的个体反馈来预测人群的反馈分布。结果表明，更复杂的反馈组合方法比正则化平均更能有效利用反馈信息，尤其是在反馈粒度较高时，可以显著减少所需个体数量以达到相同的预测精度。


<details>
  <summary>Details</summary>
Motivation: 在利用有限个体反馈预测人群反馈分布的研究中，探索比正则化平均更优越的方法，尤其是在反馈粒度不同的情况下。

Method: 本文提出了一种结合个体反馈的复杂方法，以优于正则化平均的方法来预测人群的反馈分布。

Result: 研究结果证实，随着反馈粒度的增加，复杂方法能够显著优于正则化平均。具体来说，在二元反馈的情况下，复杂方法在提高性能方面所需个体数量的减少效果不明显；而在五点反馈的情况下，复杂方法所需的个体数量大约只有正则化平均的一半。

Conclusion: 随着反馈粒度的增加，可以通过比正则化平均更复杂的方法组合个体反馈，从而在预测人群反馈分布方面获得显著改进。

Abstract: Human feedback is increasingly used across diverse applications like training
AI models, developing recommender systems, and measuring public opinion -- with
granular feedback often being preferred over binary feedback for its greater
informativeness. While it is easy to accurately estimate a population's
distribution of feedback given feedback from a large number of individuals,
cost constraints typically necessitate using smaller groups. A simple method to
approximate the population distribution is regularized averaging: compute the
empirical distribution and regularize it toward a prior. Can we do better? As
we will discuss, the answer to this question depends on feedback granularity.
  Suppose one wants to predict a population's distribution of feedback using
feedback from a limited number of individuals. We show that, as feedback
granularity increases, one can substantially improve upon predictions of
regularized averaging by combining individuals' feedback in ways more
sophisticated than regularized averaging.
  Our empirical analysis using questions on social attitudes confirms this
pattern. In particular, with binary feedback, sophistication barely reduces the
number of individuals required to attain a fixed level of performance. By
contrast, with five-point feedback, sophisticated methods match the performance
of regularized averaging with about half as many individuals.

</details>


### [297] [Information-Theoretic Generalization Bounds of Replay-based Continual Learning](https://arxiv.org/abs/2507.12043)
*Wen Wen,Tieliang Gong,Yunjiao Zhang,Zeyu Gao,Weizhan Zhang,Yong-Jin Liu*

Main category: cs.LG

TL;DR: 本研究为基于重放的持续学习提供了理论基础，通过信息论界限揭示了内存缓冲区如何影响泛化能力。研究表明，有限的重放优于详尽重放，并提出了更易于计算的泛化差距界限。


<details>
  <summary>Details</summary>
Motivation: 尽管持续学习（CL）在从顺序任务中获取知识方面取得了显著的经验性能，但对其泛化行为的理论理解仍然有限，特别是对于基于重放的方法。本研究旨在解决这一理论空白。

Method: 本文建立了一个统一的理论框架，推导了信息论界限，并使用低维变量来获得更紧密且易于计算的泛化差距上限。以随机梯度 Langevin 动力学（SGLD）作为代表性方法进行了举例说明。

Result: 研究结果表明，利用先前任务的有限示例以及当前任务数据，而不是详尽的重放，有助于提高泛化能力，同时有效缓解灾难性遗忘。此外，基于预测的界限通过使用低维变量，为泛化差距提供了更紧密且易于计算的上限。

Conclusion: 该研究为基于重放的持续学习建立了统一的理论框架，并推导出了一系列信息论界限，明确了内存缓冲区如何与当前任务交互以影响泛化能力。实验结果验证了该理论框架的有效性。

Abstract: Continual learning (CL) has emerged as a dominant paradigm for acquiring
knowledge from sequential tasks while avoiding catastrophic forgetting.
Although many CL methods have been proposed to show impressive empirical
performance, the theoretical understanding of their generalization behavior
remains limited, particularly for replay-based approaches. In this paper, we
establish a unified theoretical framework for replay-based CL, deriving a
series of information-theoretic bounds that explicitly characterize how the
memory buffer interacts with the current task to affect generalization.
Specifically, our hypothesis-based bounds reveal that utilizing the limited
exemplars of previous tasks alongside the current task data, rather than
exhaustive replay, facilitates improved generalization while effectively
mitigating catastrophic forgetting. Furthermore, our prediction-based bounds
yield tighter and computationally tractable upper bounds of the generalization
gap through the use of low-dimensional variables. Our analysis is general and
broadly applicable to a wide range of learning algorithms, exemplified by
stochastic gradient Langevin dynamics (SGLD) as a representative method.
Comprehensive experimental evaluations demonstrate the effectiveness of our
derived bounds in capturing the generalization dynamics in replay-based CL
settings.

</details>


### [298] [FloGAN: Scenario-Based Urban Mobility Flow Generation via Conditional GANs and Dynamic Region Decoupling](https://arxiv.org/abs/2507.12053)
*Seanglidet Yean,Jiazu Zhou,Bu-Sung Lee,Markus Schläpfer*

Main category: cs.LG

TL;DR: 本研究提出了一种基于cGAN的新方法，用于生成考虑动态城市因素（如土地利用）的出行流，该方法在新加坡的手机数据上得到了验证，并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 城市居民的出行模式随土地利用和人口的变化而演变，这使得城市规划者必须模拟和分析人类出行模式，以优化交通和实现可持续城市发展。现有的生成模型依赖于历史轨迹，并忽略了人口密度和土地利用等不断变化的因素；而机械方法则假设场景静态不变，限制了其在缺乏历史数据进行校准的未来预测中的应用。

Method: 本研究提出了一种利用条件生成对抗网络（cGAN）的新方法，该方法结合了历史轨迹、人口密度、土地利用、动态区域大小和土地利用类型等自适应因素，以生成出发地-目的地迁移流。

Result: 该方法能够根据新加坡的手机数据，并与其他现有方法进行比较，快速生成具有可调空间粒度的迁移流，且无需复杂的校准数据或行为建模。

Conclusion: 该研究引入了一种新颖的、数据驱动的方法，用于为模拟的城市情景生成出发地-目的地迁移流，该方法利用了动态区域大小和土地利用类型等自适应因素，并利用条件生成对抗网络（cGAN）将历史数据与这些自适应参数相结合。

Abstract: The mobility patterns of people in cities evolve alongside changes in land
use and population. This makes it crucial for urban planners to simulate and
analyze human mobility patterns for purposes such as transportation
optimization and sustainable urban development. Existing generative models
borrowed from machine learning rely heavily on historical trajectories and
often overlook evolving factors like changes in population density and land
use. Mechanistic approaches incorporate population density and facility
distribution but assume static scenarios, limiting their utility for future
projections where historical data for calibration is unavailable. This study
introduces a novel, data-driven approach for generating origin-destination
mobility flows tailored to simulated urban scenarios. Our method leverages
adaptive factors such as dynamic region sizes and land use archetypes, and it
utilizes conditional generative adversarial networks (cGANs) to blend
historical data with these adaptive parameters. The approach facilitates rapid
mobility flow generation with adjustable spatial granularity based on regions
of interest, without requiring extensive calibration data or complex behavior
modeling. The promising performance of our approach is demonstrated by its
application to mobile phone data from Singapore, and by its comparison with
existing methods.

</details>


### [299] [Emergence of Quantised Representations Isolated to Anisotropic Functions](https://arxiv.org/abs/2507.12070)
*George Bird*

Main category: cs.LG

TL;DR: 本文提出了一种新的表征对齐方法，发现代数对称性是任务无关结构的关键。激活函数的选择会影响表征是离散化还是连续化，离散对称性导致离散化，连续对称性则保持连续。这种量化效应可能是不利于重建的。


<details>
  <summary>Details</summary>
Motivation: 为了探究代数对称性如何预测任务无关结构在表征中的作用，以及在自编码器模型中离散表征是如何形成和排列的，特别是激活函数如何影响这一过程。

Method: 提出了一种新的表征对齐确定方法，并借鉴了现有的Spotlight Resonance方法。通过对自编码器模型进行消融研究（仅改变激活函数），来研究离散表征的形成和排列。

Result: 研究发现，当激活函数通过离散的代数置换等变对称性定义时，表征倾向于离散化；而在连续的代数正交等变定义下，表征保持连续。这表明功能形式的选择会带来非预期的归纳偏差，导致表征结构的人工离散化（量化效应）。量化效应与重建误差的增加相关。

Conclusion: 该研究提出了一个用于确定表征对齐的新方法，并发现代数对称性是任务无关结构在表征中的有力预测因子。研究结果表明，在自编码器模型中，激活函数的选择会影响表征的离散化或连续性，离散的代数置换等变对称性倾向于使表征离散化，而连续的代数正交等变定义则保持表征连续。这些发现支持了功能形式的选择可能带有非预期的归纳偏差，从而在表征中产生与任务无关的人工结构，特别是当前形式会使原本连续的结构离散化（量化效应）。此外，该研究支持了一个关于离散表征如何形成的通用因果模型，并可能为下游的可解释性现象（如祖母神经元、离散编码方案、通用线性特征和叠加）提供先决条件。最后，初步结果表明表征的量化与重建误差的增加相关，这进一步证实了这种崩溃可能是有害的。

Abstract: This paper describes a novel methodology for determining representational
alignment, developed upon the existing Spotlight Resonance method. Using this,
it is found that algebraic symmetries of network primitives are a strong
predictor for task-agnostic structure in representations. Particularly, this
new tool is used to gain insight into how discrete representations can form and
arrange in autoencoder models, through an ablation study where only the
activation function is altered. Representations are found to tend to discretise
when the activation functions are defined through a discrete algebraic
permutation-equivariant symmetry. In contrast, they remain continuous under a
continuous algebraic orthogonal-equivariant definition. These findings
corroborate the hypothesis that functional form choices can carry unintended
inductive biases which produce task-independent artefactual structures in
representations, particularly that contemporary forms induce discretisation of
otherwise continuous structure -- a quantisation effect. Moreover, this
supports a general causal model for one mode in which discrete representations
may form, and could constitute a prerequisite for downstream interpretability
phenomena, including grandmother neurons, discrete coding schemes, general
linear features and possibly Superposition. Hence, this tool and proposed
mechanism for the influence of functional form on representations may provide
several insights into emergent interpretability research. Finally, preliminary
results indicate that quantisation of representations appears to correlate with
a measurable increase in reconstruction error, reinforcing previous conjectures
that this collapse can be detrimental.

</details>


### [300] [Self-Adaptive and Robust Federated Spectrum Sensing without Benign Majority for Cellular Networks](https://arxiv.org/abs/2507.12127)
*Ngoc Duy Pham,Thusitha Dayaratne,Viet Vo,Shangqi Lai,Sharif Abuadbba,Hajime Suzuki,Xingliang Yuan,Carsten Rudolph*

Main category: cs.LG

TL;DR: 联邦学习在无线通信频谱感知中大有可为，通过半监督学习解决了数据不足的问题，并用“疫苗”抵御了恶意攻击，效果显著。


<details>
  <summary>Details</summary>
Motivation: 为了解决5G和6G发展带来的频谱稀缺问题，以及中心化机器学习在动态频谱分配（DSA）中的隐私、带宽和监管限制，探索联邦学习（FL）在频谱感知中的应用。

Method: 提出了一种结合能量检测的半监督联邦学习方法来解决标签数据稀缺问题，并提出了一种基于疫苗接种思想的防御机制来应对数据投毒攻击。

Result: 在合成和真实世界的数据集上，FLSS在无标签数据集上实现了近乎完美的准确率，并能抵御大量恶意参与者的数据投毒攻击。

Conclusion: 该研究提出了一种基于联邦学习的频谱感知（FLSS）方法，通过半监督学习解决了标签数据稀缺问题，并提出了一种基于疫苗接种的防御机制来应对数据投毒攻击，在合成和真实世界的数据集上都取得了近乎完美的准确率和拜占庭鲁棒性。

Abstract: Advancements in wireless and mobile technologies, including 5G advanced and
the envisioned 6G, are driving exponential growth in wireless devices. However,
this rapid expansion exacerbates spectrum scarcity, posing a critical
challenge. Dynamic spectrum allocation (DSA)--which relies on sensing and
dynamically sharing spectrum--has emerged as an essential solution to address
this issue. While machine learning (ML) models hold significant potential for
improving spectrum sensing, their adoption in centralized ML-based DSA systems
is limited by privacy concerns, bandwidth constraints, and regulatory
challenges. To overcome these limitations, distributed ML-based approaches such
as Federated Learning (FL) offer promising alternatives. This work addresses
two key challenges in FL-based spectrum sensing (FLSS). First, the scarcity of
labeled data for training FL models in practical spectrum sensing scenarios is
tackled with a semi-supervised FL approach, combined with energy detection,
enabling model training on unlabeled datasets. Second, we examine the security
vulnerabilities of FLSS, focusing on the impact of data poisoning attacks. Our
analysis highlights the shortcomings of existing majority-based defenses in
countering such attacks. To address these vulnerabilities, we propose a novel
defense mechanism inspired by vaccination, which effectively mitigates data
poisoning attacks without relying on majority-based assumptions. Extensive
experiments on both synthetic and real-world datasets validate our solutions,
demonstrating that FLSS can achieve near-perfect accuracy on unlabeled datasets
and maintain Byzantine robustness against both targeted and untargeted data
poisoning attacks, even when a significant proportion of participants are
malicious.

</details>


### [301] [FourCastNet 3: A geometric approach to probabilistic machine-learning weather forecasting at scale](https://arxiv.org/abs/2507.12144)
*Boris Bonev,Thorsten Kurth,Ankur Mahesh,Mauro Bisson,Jean Kossaifi,Karthik Kashinath,Anima Anandkumar,William D. Collins,Michael S. Pritchard,Alexander Keller*

Main category: cs.LG

TL;DR: FourCastNet 3 使用几何机器学习在天气预报方面取得了突破，其速度比现有模型快 8-60 倍，准确性相当，并能进行长达 60 天的预报。


<details>
  <summary>Details</summary>
Motivation: FourCastNet 3 旨在通过可扩展的几何机器学习方法改进全球天气预报，解决传统模型和现有机器学习方法的局限性，提高预测精度、效率和稳定性。

Method: FourCastNet 3 采用可扩展的几何机器学习方法，结合球形几何和卷积神经网络架构，实现了概率集成预报。它使用结合模型和数据并行的新型训练范式，并在大规模 GPU 上进行训练。

Result: FourCastNet 3 在预测精度上超越了传统的集成模型，媲美先进的扩散模型，并且速度快 8 到 60 倍。它还表现出优异的概率校准和光谱保真度，即使在长达 60 天的预报期内也能保持。

Conclusion: FourCastNet 3 是一种强大的天气预报模型，通过其几何机器学习方法、高精度、高效率和稳定性，有望改进气象预报和预警系统。

Abstract: FourCastNet 3 advances global weather modeling by implementing a scalable,
geometric machine learning (ML) approach to probabilistic ensemble forecasting.
The approach is designed to respect spherical geometry and to accurately model
the spatially correlated probabilistic nature of the problem, resulting in
stable spectra and realistic dynamics across multiple scales. FourCastNet 3
delivers forecasting accuracy that surpasses leading conventional ensemble
models and rivals the best diffusion-based methods, while producing forecasts 8
to 60 times faster than these approaches. In contrast to other ML approaches,
FourCastNet 3 demonstrates excellent probabilistic calibration and retains
realistic spectra, even at extended lead times of up to 60 days. All of these
advances are realized using a purely convolutional neural network architecture
tailored for spherical geometry. Scalable and efficient large-scale training on
1024 GPUs and more is enabled by a novel training paradigm for combined model-
and data-parallelism, inspired by domain decomposition methods in classical
numerical models. Additionally, FourCastNet 3 enables rapid inference on a
single GPU, producing a 90-day global forecast at 0.25{\deg}, 6-hourly
resolution in under 20 seconds. Its computational efficiency, medium-range
probabilistic skill, spectral fidelity, and rollout stability at subseasonal
timescales make it a strong candidate for improving meteorological forecasting
and early warning systems through large ensemble predictions.

</details>


### [302] [PRISM: Distributed Inference for Foundation Models at Edge](https://arxiv.org/abs/2507.12145)
*Muhammad Azlan Qazi,Alexandros Iosifidis,Qi Zhang*

Main category: cs.LG

TL;DR: PRISM 是一种用于边缘设备上的分布式 Transformer 推理的通信高效且计算感知型策略，它通过减少通信和计算来大幅提升效率，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 基础模型在各种应用中取得了显著成功，但在边缘部署方面带来了严峻的挑战，因此需要开发实用且高效的策略。

Method: PRISM 是一种通信高效且计算感知型策略，用于在边缘设备上进行分布式 Transformer 推理。它利用 Segment Means 表示来近似中间输出特征，以减少设备间通信，并重构自注意力机制以消除冗余计算，同时设计了一种针对自回归模型的感知分区因果掩码方案。

Result: PRISM 在 ViT、BERT 和 GPT-2 上进行了评估，结果显示通信开销（BERT 在 CR=128 时减少高达 99.2%）和每设备计算量（BERT 在相同设置下减少 51.24%）均有大幅减少，同时准确率仅有轻微下降。

Conclusion: PRISM 提供了一种可扩展且实用的解决方案，用于在资源受限的分布式环境中部署基础模型。

Abstract: Foundation models (FMs) have achieved remarkable success across a wide range
of applications, from image classification to natural langurage processing, but
pose significant challenges for deployment at edge. This has sparked growing
interest in developing practical and efficient strategies for bringing
foundation models to edge environments. In this work, we propose PRISM, a
communication-efficient and compute-aware strategy for distributed Transformer
inference on edge devices. Our method leverages a Segment Means representation
to approximate intermediate output features, drastically reducing inter-device
communication. Additionally, we restructure the self-attention mechanism to
eliminate redundant computations caused by per-device Key/Value calculation in
position-wise partitioning and design a partition-aware causal masking scheme
tailored for autoregressive models. We evaluate PRISM on ViT, BERT, and GPT-2
across diverse datasets, namely CIFAR-10, CIFAR-100, ImageNet-1k, GLUE, and
CBT. Our results demonstrate substantial reductions in communication overhead
(up to 99.2% for BERT at compression rate CR = 128) and per-device computation
(51.24% for BERT at the same setting), with only minor accuracy degradation.
This method offers a scalable and practical solution for deploying foundation
models in distributed resource-constrained environments.

</details>


### [303] [Multi-Component VAE with Gaussian Markov Random Field](https://arxiv.org/abs/2507.12165)
*Fouad Oubari,Mohamed El-Baha,Raphael Meunier,Rodrigue Décatoire,Mathilde Mougeot*

Main category: cs.LG

TL;DR: GMRF MCVAE 通过将高斯马尔可夫随机场嵌入先验和后验分布来解决多组件生成中的结构一致性问题，并在各种数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多组件变分自编码器（MCVAE）通常依赖简化的聚合策略，忽略了关键的细微差别，从而损害了生成组件之间的结构一致性。本研究旨在解决这一差距。

Method: 提出了一种新的生成框架——高斯马尔可夫随机场多组件变分自编码器（GMRF MCVAE），该框架将高斯马尔可夫随机场嵌入先验和后验分布中，以显式地对跨组件关系进行建模。

Result: GMRF MCVAE 在用于评估复杂组件关系的合成 Copula 数据集上实现了最先进的性能，在 PolyMNIST 基准测试中表现出有竞争力 results，并在真实世界的 BIKED 数据集上显著提高了结构一致性。

Conclusion: GMRF MCVAE 框架在 BIKED 数据集上显著提高了结构一致性，在 Copula 和 PolyMNIST 基准测试中也取得了最先进或具有竞争力的结果，表明其在需要稳健且逼真的多组件相干性建模的实际应用中特别适用。

Abstract: Multi-component datasets with intricate dependencies, like industrial
assemblies or multi-modal imaging, challenge current generative modeling
techniques. Existing Multi-component Variational AutoEncoders typically rely on
simplified aggregation strategies, neglecting critical nuances and consequently
compromising structural coherence across generated components. To explicitly
address this gap, we introduce the Gaussian Markov Random Field Multi-Component
Variational AutoEncoder , a novel generative framework embedding Gaussian
Markov Random Fields into both prior and posterior distributions. This design
choice explicitly models cross-component relationships, enabling richer
representation and faithful reproduction of complex interactions. Empirically,
our GMRF MCVAE achieves state-of-the-art performance on a synthetic Copula
dataset specifically constructed to evaluate intricate component relationships,
demonstrates competitive results on the PolyMNIST benchmark, and significantly
enhances structural coherence on the real-world BIKED dataset. Our results
indicate that the GMRF MCVAE is especially suited for practical applications
demanding robust and realistic modeling of multi-component coherence

</details>


### [304] [Nonlinear Concept Erasure: a Density Matching Approach](https://arxiv.org/abs/2507.12341)
*Antoine Saillenfest,Pirmin Lemberger*

Main category: cs.LG

TL;DR: LEOPARD是一种新的概念擦除方法，用于从文本表示中去除敏感信息，以提高公平性。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，需要确保神经模型不会从文本表示中推断出敏感信息，以解决公平性问题。

Method: 通过学习投影矩阵，使敏感概念的类条件特征分布在投影后无法区分，并通过调整投影矩阵的秩来控制信息去除程度，同时保持局部结构。

Result: LEOPARD在经典自然语言处理基准测试中实现了最先进的非线性属性擦除性能，并能有效减轻深度非线性分类器的偏差。

Conclusion: LEOPARD方法在去除文本表示中的敏感信息（如性别、种族）方面表现出色，有效消除了偏差，促进了公平性。

Abstract: Ensuring that neural models used in real-world applications cannot infer
sensitive information, such as demographic attributes like gender or race, from
text representations is a critical challenge when fairness is a concern. We
address this issue through concept erasure, a process that removes information
related to a specific concept from distributed representations while preserving
as much of the remaining semantic information as possible. Our approach
involves learning an orthogonal projection in the embedding space, designed to
make the class-conditional feature distributions of the discrete concept to
erase indistinguishable after projection. By adjusting the rank of the
projector, we control the extent of information removal, while its
orthogonality ensures strict preservation of the local structure of the
embeddings. Our method, termed $\overline{\mathrm{L}}$EOPARD, achieves
state-of-the-art performance in nonlinear erasure of a discrete attribute on
classic natural language processing benchmarks. Furthermore, we demonstrate
that $\overline{\mathrm{L}}$EOPARD effectively mitigates bias in deep nonlinear
classifiers, thereby promoting fairness.

</details>


### [305] [Explainable Evidential Clustering](https://arxiv.org/abs/2507.12192)
*Victor F. Lopes de Souza,Karima Bakhti,Sofiane Ramdani,Denis Mottet,Abdelhak Imoussaten*

Main category: cs.LG

TL;DR: 本研究解决了证据聚类结果的解释性问题，提出了IEMM算法，能够为不完美数据提供可解释的聚类结果，并获得了高度满意的解释效果。


<details>
  <summary>Details</summary>
Motivation: 传统的无监督分类方法在处理包含不确定性和不精确性的不完美数据时存在不足。证据聚类（基于Dempster-Shafer理论）虽然能应对这些挑战，但对其结果的解释性研究不足，而这在高风险领域（如医疗保健）至关重要。

Method: 本研究首先分析了表示性在一般情况下是决策树作为溯因解释器的充要条件，然后将此概念推广以适应部分标记，通过效用函数来表示“可容忍”的错误，并将证据错误定义为解释成本，最终构建了适用于证据分类器的解释器，并提出了IEMM算法。

Result: 研究表明，表示性是决策树作为溯因解释器的充要条件。通过效用函数可以处理部分标记和“可容忍”错误。IEMM算法能够提供可解释且谨慎的证据聚类解释，并且在考虑决策者偏好时，解释令人满意的比例高达93%。

Conclusion: 本研究提出了迭代证据错误最小化（IEMM）算法，该算法为证据聚类函数提供可解释且谨慎的决策树解释，并在合成和真实世界数据上进行了验证，在考虑决策者偏好时，解释令人满意的比例高达93%。

Abstract: Unsupervised classification is a fundamental machine learning problem.
Real-world data often contain imperfections, characterized by uncertainty and
imprecision, which are not well handled by traditional methods. Evidential
clustering, based on Dempster-Shafer theory, addresses these challenges. This
paper explores the underexplored problem of explaining evidential clustering
results, which is crucial for high-stakes domains such as healthcare. Our
analysis shows that, in the general case, representativity is a necessary and
sufficient condition for decision trees to serve as abductive explainers.
Building on the concept of representativity, we generalize this idea to
accommodate partial labeling through utility functions. These functions enable
the representation of "tolerable" mistakes, leading to the definition of
evidential mistakeness as explanation cost and the construction of explainers
tailored to evidential classifiers. Finally, we propose the Iterative
Evidential Mistake Minimization (IEMM) algorithm, which provides interpretable
and cautious decision tree explanations for evidential clustering functions. We
validate the proposed algorithm on synthetic and real-world data. Taking into
account the decision-maker's preferences, we were able to provide an
explanation that was satisfactory up to 93% of the time.

</details>


### [306] [Physics-Informed Linear Model (PILM): Analytical Representations and Application to Crustal Strain Rate Estimation](https://arxiv.org/abs/2507.12218)
*Tomohisa Okazaki*

Main category: cs.LG

TL;DR: 本文提出了一种物理信息线性模型（PILM），它使用基函数的线性组合来表示 PDE 解，从而能够获得最优解的解析表示。该模型适用于线性正向和反向问题，并已成功应用于地壳应变率的估算，其中比较了物理正则化和数学正则化，发现后者在贝叶斯视角下表现更优。


<details>
  <summary>Details</summary>
Motivation: 许多物理系统由偏微分方程（PDE）描述，求解这些方程以及从观测数据中估计其系数或边界条件（BC）在理解相关现象中起着至关重要的作用。最近，一种称为物理信息神经网络（PINN）的机器学习方法，通过最小化来自PDE、BC和数据的残差总和来使用神经网络求解PDE，在科学界获得了广泛关注。

Method: 本文提出并验证了一种物理信息线性模型（PILM），该模型使用基函数的线性组合来表示解，从而能够对最优解进行解析表示。PILM被制定并验证了用于说明性的正向和反向问题，包括具有不确定边界条件的案例。此外，PILM还应用于使用大地测量数据估算地壳应变率。特别地，将强制弹性平衡于速度场的物理正则化与施加平滑约束的数学正则化进行了比较。

Result: 在贝叶斯视角下，数学正则化表现出优越的性能。

Conclusion: PILM提供了一个分析可解的框架，适用于线性正向和反向问题、不定定系统和物理正则化。

Abstract: Many physical systems are described by partial differential equations (PDEs),
and solving these equations and estimating their coefficients or boundary
conditions (BCs) from observational data play a crucial role in understanding
the associated phenomena. Recently, a machine learning approach known as
physics-informed neural network, which solves PDEs using neural networks by
minimizing the sum of residuals from the PDEs, BCs, and data, has gained
significant attention in the scientific community. In this study, we
investigate a physics-informed linear model (PILM) that uses linear
combinations of basis functions to represent solutions, thereby enabling an
analytical representation of optimal solutions. The PILM was formulated and
verified for illustrative forward and inverse problems including cases with
uncertain BCs. Furthermore, the PILM was applied to estimate crustal strain
rates using geodetic data. Specifically, physical regularization that enforces
elastic equilibrium on the velocity fields was compared with mathematical
regularization that imposes smoothness constraints. From a Bayesian
perspective, mathematical regularization exhibited superior performance. The
PILM provides an analytically solvable framework applicable to linear forward
and inverse problems, underdetermined systems, and physical regularization.

</details>


### [307] [Optimizers Qualitatively Alter Solutions And We Should Leverage This](https://arxiv.org/abs/2507.12224)
*Razvan Pascanu,Clare Lyle,Ionut-Vlad Modoranu,Naima Elosegui Borras,Dan Alistarh,Petar Velickovic,Sarath Chandar,Soham De,James Martens*

Main category: cs.LG

TL;DR: 优化器不仅关乎速度，还影响模型学到什么的本质。


<details>
  <summary>Details</summary>
Motivation: 本文旨在改变深度学习社区对优化器研究的关注点，从仅仅关注训练效率（如迭代次数、FLOPs或时间）转向理解和设计能够影响模型学习解决方案性质的优化器。

Method: 本文通过论证优化器不仅影响收敛速度，还影响学习解决方案的性质来提出新观点。作者认为优化器可以被用来编码归纳偏倚和改变模型有效表达能力，并应作为一种在学习过程中引入特定属性的手段。

Result: 本文的论点揭示了优化器在深度学习中的双重作用：不仅影响收敛速度，还塑造了学习解决方案的内在属性（如归纳偏倚和表达能力）。作者希望此论点能激发研究，促进对优化器如何影响学习过程的理解，并提升优化器设计在模型训练中的地位。

Conclusion: 社区应该通过理解现有方法的偏差并着重于创建能够引入特定解属性的新优化器，来超越仅仅基于收敛速率的评估方式。优化器的设计应被视为影响模型结果的关键因素，与架构和数据同等重要。

Abstract: Due to the nonlinear nature of Deep Neural Networks (DNNs), one can not
guarantee convergence to a unique global minimum of the loss when using
optimizers relying only on local information, such as SGD. Indeed, this was a
primary source of skepticism regarding the feasibility of DNNs in the early
days of the field. The past decades of progress in deep learning have revealed
this skepticism to be misplaced, and a large body of empirical evidence shows
that sufficiently large DNNs following standard training protocols exhibit
well-behaved optimization dynamics that converge to performant solutions. This
success has biased the community to use convex optimization as a mental model
for learning, leading to a focus on training efficiency, either in terms of
required iteration, FLOPs or wall-clock time, when improving optimizers. We
argue that, while this perspective has proven extremely fruitful, another
perspective specific to DNNs has received considerably less attention: the
optimizer not only influences the rate of convergence, but also the qualitative
properties of the learned solutions. Restated, the optimizer can and will
encode inductive biases and change the effective expressivity of a given class
of models. Furthermore, we believe the optimizer can be an effective way of
encoding desiderata in the learning process. We contend that the community
should aim at understanding the biases of already existing methods, as well as
aim to build new optimizers with the explicit intent of inducing certain
properties of the solution, rather than solely judging them based on their
convergence rates. We hope our arguments will inspire research to improve our
understanding of how the learning process can impact the type of solution we
converge to, and lead to a greater recognition of optimizers design as a
critical lever that complements the roles of architecture and data in shaping
model outcomes.

</details>


### [308] [Robust Causal Discovery in Real-World Time Series with Power-Laws](https://arxiv.org/abs/2507.12257)
*Matteo Tusoni,Giuseppe Masi,Andrea Coletta,Aldo Glielmo,Viviana Arrigoni,Novella Bartolini*

Main category: cs.LG

TL;DR: 许多因果发现方法对噪声敏感，但本研究提出了一种利用时间序列的幂律谱特征来提高鲁棒性的新方法，并在各种基准测试和真实世界数据集上取得了更好的结果。


<details>
  <summary>Details</summary>
Motivation: 探索随机时间序列中的因果关系是一项艰巨但至关重要的任务，在金融、经济、神经科学和气候科学等广泛的应用领域中都至关重要。然而，许多因果发现（CD）算法通常对噪声高度敏感，在应用于实际数据时会导致误导性的因果推断。

Method: 本研究提出了一种基于提取功率谱特征的稳健因果发现方法，该特征能够放大真实的因果信号。

Result: 在合成基准和真实世界数据集上，本研究提出的方法在因果发现方面优于现有最先进的方法。

Conclusion: 该方法在合成基准和具有已知因果结构 的真实世界数据集上始终优于最先进的替代方法，证明了其鲁棒性和实际相关性。

Abstract: Exploring causal relationships in stochastic time series is a challenging yet
crucial task with a vast range of applications, including finance, economics,
neuroscience, and climate science. Many algorithms for Causal Discovery (CD)
have been proposed, but they often exhibit a high sensitivity to noise,
resulting in misleading causal inferences when applied to real data. In this
paper, we observe that the frequency spectra of typical real-world time series
follow a power-law distribution, notably due to an inherent self-organizing
behavior. Leveraging this insight, we build a robust CD method based on the
extraction of power -law spectral features that amplify genuine causal signals.
Our method consistently outperforms state-of-the-art alternatives on both
synthetic benchmarks and real-world datasets with known causal structures,
demonstrating its robustness and practical relevance.

</details>


### [309] [A Framework for Nonstationary Gaussian Processes with Neural Network Parameters](https://arxiv.org/abs/2507.12262)
*Zachary James,Joseph Guinness*

Main category: cs.LG

TL;DR: 我们提出了一种使用神经网络学习非平稳核参数的高斯过程框架，并在各种机器学习任务中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了克服平稳核的局限性，并提高高斯过程对非平稳数据的表达能力。

Method: 将参数视为神经网络的输出，并将神经网络与高斯过程联合训练，以使用链式法则计算导数。

Result: 该方法在准确性和对数得分方面优于平稳模型和分层模型，并且能够恢复非平稳参数。

Conclusion: 与平稳模型和分层模型相比，该方法在准确性和对数得分方面均优于它们，并且与用于大规模数据集的近似方法兼容。该方法还展示了其恢复空间数据集的非平稳参数的能力。

Abstract: Gaussian processes have become a popular tool for nonparametric regression
because of their flexibility and uncertainty quantification. However, they
often use stationary kernels, which limit the expressiveness of the model and
may be unsuitable for many datasets. We propose a framework that uses
nonstationary kernels whose parameters vary across the feature space, modeling
these parameters as the output of a neural network that takes the features as
input. The neural network and Gaussian process are trained jointly using the
chain rule to calculate derivatives. Our method clearly describes the behavior
of the nonstationary parameters and is compatible with approximation methods
for scaling to large datasets. It is flexible and easily adapts to different
nonstationary kernels without needing to redesign the optimization procedure.
Our methods are implemented with the GPyTorch library and can be readily
modified. We test a nonstationary variance and noise variant of our method on
several machine learning datasets and find that it achieves better accuracy and
log-score than both a stationary model and a hierarchical model approximated
with variational inference. Similar results are observed for a model with only
nonstationary variance. We also demonstrate our approach's ability to recover
the nonstationary parameters of a spatial dataset.

</details>


### [310] [RegCL: Continual Adaptation of Segment Anything Model via Model Merging](https://arxiv.org/abs/2507.12297)
*Yuan-Chen Shu,Zhiwei Lin,Yongtao Wang*

Main category: cs.LG

TL;DR: RegCL通过合并LoRA模块参数来解决SAM在多领域适应中的灾难性遗忘问题，实现了参数高效且无需重放的持续学习。


<details>
  <summary>Details</summary>
Motivation: 现有的针对特定领域（如SAM）的适配方法存在灾难性遗忘的问题，限制了模型的扩展性。当这些方法用于其他领域时，可能会导致性能下降。为了解决这个问题，需要一个能够高效整合多领域知识的框架。

Method: RegCL是一个新颖的非重放持续学习（CL）框架，通过模型合并实现高效的多领域知识整合。该框架将模型合并算法融入持续学习范式，合并了在不同领域训练的SAM适配模块（如LoRA模块）的参数，并通过权重优化来指导合并过程，以最小化合并模型与各领域特定模型之间的预测差异。

Result: 实验结果表明，RegCL在多个下游数据集上实现了良好的持续学习性能，有效巩固了多领域知识，同时保持了参数效率（模型大小不随任务数量增加而改变），并且不需要历史数据存储。

Conclusion: RegCL框架通过模型合并有效整合了多领域知识，同时保持了参数效率，并且在多个下游数据集上实现了良好的持续学习性能，证明了其在动态场景下的有效性。

Abstract: To address the performance limitations of the Segment Anything Model (SAM) in
specific domains, existing works primarily adopt adapter-based one-step
adaptation paradigms. However, some of these methods are specific developed for
specific domains. If used on other domains may lead to performance degradation.
This issue of catastrophic forgetting severely limits the model's scalability.
To address this issue, this paper proposes RegCL, a novel non-replay continual
learning (CL) framework designed for efficient multi-domain knowledge
integration through model merging. Specifically, RegCL incorporates the model
merging algorithm into the continual learning paradigm by merging the
parameters of SAM's adaptation modules (e.g., LoRA modules) trained on
different domains. The merging process is guided by weight optimization, which
minimizes prediction discrepancies between the merged model and each of the
domain-specific models. RegCL effectively consolidates multi-domain knowledge
while maintaining parameter efficiency, i.e., the model size remains constant
regardless of the number of tasks, and no historical data storage is required.
Experimental results demonstrate that RegCL achieves favorable continual
learning performance across multiple downstream datasets, validating its
effectiveness in dynamic scenarios.

</details>


### [311] [PROL : Rehearsal Free Continual Learning in Streaming Data via Prompt Online Learning](https://arxiv.org/abs/2507.12305)
*M. Anwar Ma'sum,Mahardhika Pratama,Savitha Ramasamy,Lin Liu,Habibullah Habibullah,Ryszard Kowalczyk*

Main category: cs.LG

TL;DR: 本研究提出了一种新颖的、参数量少且性能优越的在线持续学习方法，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 在线持续学习 (OCL) 中的数据隐私约束使得灾难性遗忘问题复杂化。现有的方法要么使用内存保存示例，要么使用基于提示的方法，但后者存在参数数量不断增长的问题，而前者可能因数据开放策略而不适用于实际情况。

Method: 提出了一种包含四个主要组成部分的新颖基于提示的方法：(1) 作为通用知识的单一轻量级提示生成器，(2) 作为特定知识的可训练缩放器和移位器，(3) 预训练模型 (PTM) 泛化保持，以及 (4) 硬软更新机制。

Result: 该方法在 CIFAR100、ImageNet-R、ImageNet-A 和 CUB 数据集上取得了显著更高的性能，并且在参数数量、训练时间和推理时间方面都具有优势。

Conclusion: 该研究提出了一种新颖的基于提示的方法，用于在线持续学习，并在 CIFAR100、ImageNet-R、ImageNet-A 和 CUB 数据集上显著优于当前最先进的方法。

Abstract: The data privacy constraint in online continual learning (OCL), where the
data can be seen only once, complicates the catastrophic forgetting problem in
streaming data. A common approach applied by the current SOTAs in OCL is with
the use of memory saving exemplars or features from previous classes to be
replayed in the current task. On the other hand, the prompt-based approach
performs excellently in continual learning but with the cost of a growing
number of trainable parameters. The first approach may not be applicable in
practice due to data openness policy, while the second approach has the issue
of throughput associated with the streaming data. In this study, we propose a
novel prompt-based method for online continual learning that includes 4 main
components: (1) single light-weight prompt generator as a general knowledge,
(2) trainable scaler-and-shifter as specific knowledge, (3) pre-trained model
(PTM) generalization preserving, and (4) hard-soft updates mechanism. Our
proposed method achieves significantly higher performance than the current
SOTAs in CIFAR100, ImageNet-R, ImageNet-A, and CUB dataset. Our complexity
analysis shows that our method requires a relatively smaller number of
parameters and achieves moderate training time, inference time, and throughput.
For further study, the source code of our method is available at
https://github.com/anwarmaxsum/PROL.

</details>


### [312] [Thought Purity: Defense Paradigm For Chain-of-Thought Attack](https://arxiv.org/abs/2507.12314)
*Zihao Xue,Zhen Bi,Long Ma,Zhenlin Hu,Yan Wang,Zhenfang Liu,Qing Sheng,Jie Xiao,Jungang Lou*

Main category: cs.LG

TL;DR: 本研究提出了Thought Purity (TP) 防御范式，以应对大语言模型（LLM）推理中的安全漏洞，特别是Chain-of-Thought（CoT）生成过程中的后门提示攻击（CoTA）。TP通过优化数据处理、强化学习规则约束和自适应监控，增强了模型对恶意内容的抵抗力，同时保持了其任务性能，旨在提升AI的安全与功能平衡。


<details>
  <summary>Details</summary>
Motivation: 尽管经过强化学习训练的大语言模型（LRM）在推理能力上表现出色，但它们仍然容易受到安全威胁，尤其是在Chain-of-Thought（CoT）生成过程中，后门提示攻击（如CoTA）可以系统性地破坏模型的推理机制，降低其安全性和任务性能。因此，有必要开发一种能够同时解决这种安全-性能复合漏洞的防御机制。

Method: 本研究提出的Thought Purity (TP) 防御范式包含三个协同部分：1. 一个安全优化的数据处理流程；2. 强化学习增强的规则约束；3. 自适应监控指标。该范式旨在系统性地提高模型抵抗恶意内容的能力，同时保持其操作效率，以应对CoTA攻击。

Result: Thought Purity (TP) 防御范式通过其三个协同组件，成功建立了首个针对强化学习对齐推理系统中的CoTA漏洞的综合防御机制，显著提高了AI架构在安全性和功能性之间的平衡。

Conclusion: 本研究提出了Thought Purity (TP) 防御范式，通过三项协同组件（安全优化数据处理流程、强化学习增强规则约束、自适应监控指标）来应对大语言模型（LLM）推理能力中的安全漏洞，特别是针对Chain-of-Thought (CoT)生成过程中的后门提示攻击（Chain-of-Thought Attack, CoTA）。TP旨在增强模型对恶意内容的抵抗力，同时保持其任务性能，为下一代AI架构的安全与功能平衡树立了新的里程碑。

Abstract: While reinforcement learning-trained Large Reasoning Models (LRMs, e.g.,
Deepseek-R1) demonstrate advanced reasoning capabilities in the evolving Large
Language Models (LLMs) domain, their susceptibility to security threats remains
a critical vulnerability. This weakness is particularly evident in
Chain-of-Thought (CoT) generation processes, where adversarial methods like
backdoor prompt attacks can systematically subvert the model's core reasoning
mechanisms. The emerging Chain-of-Thought Attack (CoTA) reveals this
vulnerability through exploiting prompt controllability, simultaneously
degrading both CoT safety and task performance with low-cost interventions. To
address this compounded security-performance vulnerability, we propose Thought
Purity (TP): a defense paradigm that systematically strengthens resistance to
malicious content while preserving operational efficacy. Our solution achieves
this through three synergistic components: (1) a safety-optimized data
processing pipeline (2) reinforcement learning-enhanced rule constraints (3)
adaptive monitoring metrics. Our approach establishes the first comprehensive
defense mechanism against CoTA vulnerabilities in reinforcement
learning-aligned reasoning systems, significantly advancing the
security-functionality equilibrium for next-generation AI architectures.

</details>


### [313] [Heat Kernel Goes Topological](https://arxiv.org/abs/2507.12380)
*Maximilian Krahn,Vikas Garg*

Main category: cs.LG

TL;DR: 该研究提出了一种新颖的拓扑框架，通过组合复形上的拉普拉斯算子高效计算热核，解决了现有拓扑神经网络计算开销大的问题。该方法在理论上具有最大表达能力，在实践中计算效率高且性能优越，为分子分析任务提供了新的解决方案。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有拓扑神经网络涉及较高阶消息传递带来的显著计算开销问题。

Method: 提出了一种新颖的拓扑框架，引入了组合复形上的拉普拉斯算子，用于高效计算热核作为节点描述符。该方法能够捕获多尺度信息并生成排列等变表示，易于集成到现代基于 Transformer 的架构中。

Result: 在理论上，该方法被证明具有最大表达能力，可以区分任意非同构的组合复形。在实践中，该方法在计算效率方面显著优于现有的拓扑方法，并且在标准分子数据集上取得了与最先进描述符相当的性能，同时在区分复杂的拓扑结构和避免拓扑基准测试的盲点方面表现出优越的能力。

Conclusion: 该研究通过引入组合复形上的拉普拉斯算子，提出了一种新颖的拓扑框架，能够高效计算热核作为节点描述符。该方法能够捕获多尺度信息并生成排列等变表示，易于集成到基于 Transformer 的架构中。在理论上，该方法具有最大表达能力，能够区分任意非同构的组合复形。在实践中，该方法在计算效率上显著优于现有的拓扑方法，并在分子数据集上展现出与最先进描述符相当的性能，同时在区分复杂的拓扑结构和避免拓扑基准测试的盲点方面表现出卓越的能力。总体而言，这项工作通过提供具有表达能力且可扩展的表示，推动了拓扑深度学习的发展，为分子分类和性质预测任务开辟了令人兴奋的新途径。

Abstract: Topological neural networks have emerged as powerful successors of graph
neural networks. However, they typically involve higher-order message passing,
which incurs significant computational expense. We circumvent this issue with a
novel topological framework that introduces a Laplacian operator on
combinatorial complexes (CCs), enabling efficient computation of heat kernels
that serve as node descriptors. Our approach captures multiscale information
and enables permutation-equivariant representations, allowing easy integration
into modern transformer-based architectures.
  Theoretically, the proposed method is maximally expressive because it can
distinguish arbitrary non-isomorphic CCs. Empirically, it significantly
outperforms existing topological methods in terms of computational efficiency.
Besides demonstrating competitive performance with the state-of-the-art
descriptors on standard molecular datasets, it exhibits superior capability in
distinguishing complex topological structures and avoiding blind spots on
topological benchmarks. Overall, this work advances topological deep learning
by providing expressive yet scalable representations, thereby opening up
exciting avenues for molecular classification and property prediction tasks.

</details>


### [314] [Improving Reinforcement Learning Sample-Efficiency using Local Approximation](https://arxiv.org/abs/2507.12383)
*Mohit Prashant,Arvind Easwaran*

Main category: cs.LG

TL;DR: 本研究通过逼近原始MDP来降低RL的样本复杂度，并将样本复杂度提高到O(SA log A)时间步长。


<details>
  <summary>Details</summary>
Motivation: 现有文献中的样本复杂度界限有待提高，并且研究了状态之间的转移关系对样本复杂度的影响。

Method: 通过使用状态空间的子集来逼近原始MDP，并在此基础上构建了一个PAC-MDP算法，将样本复杂度降低到O(SA log A)时间步长。

Result: 推导出了比现有文献更优的、关于无限时间范围的马尔可夫决策过程（MDP）设置下强化学习（RL）的渐近样本复杂度界限，并将结果扩展到无模型的设置。

Conclusion: 通过实验展示了所提出算法的显著改进。

Abstract: In this study, we derive Probably Approximately Correct (PAC) bounds on the
asymptotic sample-complexity for RL within the infinite-horizon Markov Decision
Process (MDP) setting that are sharper than those in existing literature. The
premise of our study is twofold: firstly, the further two states are from each
other, transition-wise, the less relevant the value of the first state is when
learning the $\epsilon$-optimal value of the second; secondly, the amount of
'effort', sample-complexity-wise, expended in learning the $\epsilon$-optimal
value of a state is independent of the number of samples required to learn the
$\epsilon$-optimal value of a second state that is a sufficient number of
transitions away from the first. Inversely, states within each other's vicinity
have values that are dependent on each other and will require a similar number
of samples to learn. By approximating the original MDP using smaller MDPs
constructed using subsets of the original's state-space, we are able to reduce
the sample-complexity by a logarithmic factor to $O(SA \log A)$ timesteps,
where $S$ and $A$ are the state and action space sizes. We are able to extend
these results to an infinite-horizon, model-free setting by constructing a
PAC-MDP algorithm with the aforementioned sample-complexity. We conclude with
showing how significant the improvement is by comparing our algorithm against
prior work in an experimental setting.

</details>


### [315] [ROC-n-reroll: How verifier imperfection affects test-time scaling](https://arxiv.org/abs/2507.12399)
*Florian E. Dorner,Yatong Chen,André F. Cruz,Fanny Yang*

Main category: cs.LG

TL;DR: Test-time scaling methods leverage extra compute for better language models, but verifier imperfections were poorly understood theoretically. We proved scaling depends on ROC curve geometry: rejection sampling on local, Best-of-N on global. Rejection sampling can't be predicted from low compute if ROC is unknown. Both methods hit same accuracy with infinite compute, based on ROC slope near origin. Experiments confirm this.


<details>
  <summary>Details</summary>
Motivation: While test-time scaling techniques like Best-of-N and rejection sampling empirically improve language model performance by using additional compute during inference, there's a lack of theoretical understanding regarding the impact of verifier imperfection on their performance. This work aims to fill this gap by providing a theoretical framework to analyze these methods.

Method: We theoretically analyze the instance-level accuracy of test-time scaling methods, specifically Best-of-N and rejection sampling, by characterizing their performance based on the geometry of the verifier's Receiver Operating Characteristic (ROC) curve. We mathematically derive the relationships between ROC curve properties (local vs. global geometry, slope near the origin) and the scaling behavior of these methods. We then experimentally validate our theoretical results using different versions of Llama and Qwen on the GSM8K dataset.

Result: We proved that rejection sampling's scaling is determined by the local geometry of the ROC curve, whereas Best-of-N's scaling depends on global properties. Consequently, performance extrapolation for rejection sampling from low-compute regimes is not feasible without knowing the ROC curve. We also found that while rejection sampling outperforms Best-of-N for fixed compute, both methods achieve the same accuracy in the infinite-compute limit, which is dictated by the ROC curve's slope near the origin. Our experiments confirmed these theoretical predictions.

Conclusion: We theoretically prove how instance-level accuracy of test-time scaling methods (Best-of-N and rejection sampling) is characterized by the geometry of the verifier's ROC curve. Rejection sampling's scaling depends on local ROC geometry, while Best-of-N depends on global properties. Extrapolating rejection sampling performance from low-compute regimes is impossible when the ROC curve is unknown. Both methods converge to the same accuracy in the infinite-compute limit, determined by the ROC curve's slope near the origin. Experiments on GSM8K confirm these findings.

Abstract: Test-time scaling aims to improve language model performance by leveraging
additional compute during inference. While many works have empirically studied
techniques like Best-of-N (BoN) and rejection sampling that make use of a
verifier to enable test-time scaling, there is little theoretical understanding
of how verifier imperfection affects performance. In this work, we address this
gap. Specifically, we prove how instance-level accuracy of these methods is
precisely characterized by the geometry of the verifier's ROC curve.
Interestingly, while scaling is determined by the local geometry of the ROC
curve for rejection sampling, it depends on global properties of the ROC curve
for BoN. As a consequence when the ROC curve is unknown, it is impossible to
extrapolate the performance of rejection sampling based on the low-compute
regime. Furthermore, while rejection sampling outperforms BoN for fixed
compute, in the infinite-compute limit both methods converge to the same level
of accuracy, determined by the slope of the ROC curve near the origin. Our
theoretical results are confirmed by experiments on GSM8K using different
versions of Llama and Qwen to generate and verify solutions.

</details>


### [316] [NOCTA: Non-Greedy Objective Cost-Tradeoff Acquisition for Longitudinal Data](https://arxiv.org/abs/2507.12412)
*Dzung Dinh,Boqi Chen,Marc Niethammer,Junier Oliva*

Main category: cs.LG

TL;DR: NOCTA is a new method for acquiring informative features sequentially, considering cost and temporal dynamics, outperforming existing methods in medical datasets.


<details>
  <summary>Details</summary>
Motivation: Resource constraints in critical applications (e.g., healthcare) limit information gathering for predictions. Temporal prediction tasks add complexity in deciding when/what information is important, considering feature costs (time, money, risk) and evolving data.

Method: NOCTA is a Non-Greedy Objective Cost-Tradeoff Acquisition method that sequentially acquires the most informative features at inference time. It utilizes a non-parametric method based on nearest neighbors (NOCTA-NP) and a parametric method that predicts the utility of potential acquisitions (NOCTA-P).

Result: Both NOCTA variants, NOCTA-NP and NOCTA-P, demonstrate superior performance compared to existing methods.

Conclusion: NOCTA-NP and NOCTA-P outperform existing baselines on both synthetic and real-world medical datasets.

Abstract: In many critical applications, resource constraints limit the amount of
information that can be gathered to make predictions. For example, in
healthcare, patient data often spans diverse features ranging from lab tests to
imaging studies. Each feature may carry different information and must be
acquired at a respective cost of time, money, or risk to the patient. Moreover,
temporal prediction tasks, where both instance features and labels evolve over
time, introduce additional complexity in deciding when or what information is
important. In this work, we propose NOCTA, a Non-Greedy Objective Cost-Tradeoff
Acquisition method that sequentially acquires the most informative features at
inference time while accounting for both temporal dynamics and acquisition
cost. We first introduce a cohesive estimation target for our NOCTA setting,
and then develop two complementary estimators: 1) a non-parametric method based
on nearest neighbors to guide the acquisition (NOCTA-NP), and 2) a parametric
method that directly predicts the utility of potential acquisitions (NOCTA-P).
Experiments on synthetic and real-world medical datasets demonstrate that both
NOCTA variants outperform existing baselines.

</details>


### [317] [Mixture of Raytraced Experts](https://arxiv.org/abs/2507.12419)
*Andrea Perin,Giacomo Lagomarsini,Claudio Gallicchio,Giuseppe Nuti*

Main category: cs.LG

TL;DR: 提出了一种名为“光线追踪专家混合体”的新型 MoE 架构，该架构可以动态选择专家序列，从而实现可变计算量和可变深度，并能在训练中减少 epoch 数量和提高准确性。


<details>
  <summary>Details</summary>
Motivation: 现有 MoE 架构通常需要为给定样本执行固定量的计算。本研究旨在克服这一限制，探索能够随着计算通过专家序列而提高准确性的模型。

Method: 提出了一种堆叠式 MoE 架构，称为“光线追踪专家混合体”（Mixture of Raytraced Experts），能够动态选择专家序列，从而产生可变宽度和深度的计算图。训练方法类似于循环神经网络，通过迭代地从候选专家集中采样来展开序列。

Result: 与现有方法相比，该模型在训练的 epoch 数量上减少了 10% 到 40%，同时保持了相当或更高的准确性。该方法不需要负载均衡机制。

Conclusion: 所提出的方法为 MoE 领域开辟了新的研究方向，有潜力设计出更快、更具表现力的模型。

Abstract: We introduce a Mixture of Raytraced Experts, a stacked Mixture of Experts
(MoE) architecture which can dynamically select sequences of experts, producing
computational graphs of variable width and depth. Existing MoE architectures
generally require a fixed amount of computation for a given sample. Our
approach, in contrast, yields predictions with increasing accuracy as the
computation cycles through the experts' sequence. We train our model by
iteratively sampling from a set of candidate experts, unfolding the sequence
akin to how Recurrent Neural Networks are trained. Our method does not require
load-balancing mechanisms, and preliminary experiments show a reduction in
training epochs of 10\% to 40\% with a comparable/higher accuracy. These
results point to new research directions in the field of MoEs, allowing the
design of potentially faster and more expressive models. The code is available
at https://github.com/nutig/RayTracing

</details>


### [318] [Targeted Deep Architectures: A TMLE-Based Framework for Robust Causal Inference in Neural Networks](https://arxiv.org/abs/2507.12435)
*Yi Li,David Mccoy,Nolan Gunter,Kaitlyn Lee,Alejandro Schuler,Mark van der Laan*

Main category: cs.LG

TL;DR: TDA是一种新的框架，它将TMLE直接嵌入到神经网络的参数空间中，无需对骨干网络架构进行限制，从而实现对因果参数（如处理效应或整个生存曲线）的无偏估计和有效的置信区间。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在因果参数推断方面存在不足，而现有的基于双重机器学习和目标最大似然估计的神经网络实现要么依赖于不能保证解决有效影响函数方程的目标损失，要么在多参数设置中计算成本高昂。

Method: TDA框架将TMLE嵌入到网络的参数空间中，通过冻结除一小部分“目标”子集外的所有参数，并沿着从影响函数到损失关于权重的梯度投影导出的目标梯度进行迭代更新，从而实现无偏估计和有效的置信区间。

Result: TDA在IHDP数据集（平均处理效应）和具有信息性审查的模拟生存数据上，相比于标准的神经网络估计器和先前的事后方法，能够减少偏差并提高覆盖率。

Conclusion: TDA框架提供了一种可扩展的途径，用于在现代深度架构中对复杂的多参数目标进行严格的因果推断。

Abstract: Modern deep neural networks are powerful predictive tools yet often lack
valid inference for causal parameters, such as treatment effects or entire
survival curves. While frameworks like Double Machine Learning (DML) and
Targeted Maximum Likelihood Estimation (TMLE) can debias machine-learning fits,
existing neural implementations either rely on "targeted losses" that do not
guarantee solving the efficient influence function equation or computationally
expensive post-hoc "fluctuations" for multi-parameter settings. We propose
Targeted Deep Architectures (TDA), a new framework that embeds TMLE directly
into the network's parameter space with no restrictions on the backbone
architecture. Specifically, TDA partitions model parameters - freezing all but
a small "targeting" subset - and iteratively updates them along a targeting
gradient, derived from projecting the influence functions onto the span of the
gradients of the loss with respect to weights. This procedure yields plug-in
estimates that remove first-order bias and produce asymptotically valid
confidence intervals. Crucially, TDA easily extends to multi-dimensional causal
estimands (e.g., entire survival curves) by merging separate targeting
gradients into a single universal targeting update. Theoretically, TDA inherits
classical TMLE properties, including double robustness and semiparametric
efficiency. Empirically, on the benchmark IHDP dataset (average treatment
effects) and simulated survival data with informative censoring, TDA reduces
bias and improves coverage relative to both standard neural-network estimators
and prior post-hoc approaches. In doing so, TDA establishes a direct, scalable
pathway toward rigorous causal inference within modern deep architectures for
complex multi-parameter targets.

</details>


### [319] [Cost-aware Stopping for Bayesian Optimization](https://arxiv.org/abs/2507.12453)
*Qian Xie,Linda Cai,Alexander Terenin,Peter I. Frazier,Ziv Scully*

Main category: cs.LG

TL;DR: 提出了一种新的贝叶斯优化成本感知停止规则，与 PBGI 结合使用可提高效率和性能。


<details>
  <summary>Details</summary>
Motivation: 在自动化机器学习、科学发现和贝叶斯优化等应用的昂贵的黑盒函数评估中，决定何时停止评估是一个重要的实际考虑因素。然而，现有的成本感知型停止规则缺乏保证它们在产生过多的函数评估成本之前停止。

Method: 提出了一种成本感知型停止规则，该规则能够适应变化的评估成本且无需进行启发式调整。该规则在理论上与最先进的成本感知型采集函数（即 Pandora's Box Gittins Index (PBGI) 和每次日志期望改进成本）相关联。证明了理论保证，限制了与这两种采集函数配对的停止规则所产生的预期累积评估成本。

Result: 在合成和经验任务（包括超参数优化和神经网络结构大小搜索）的实验中，证明了该方法在成本感知方面的有效性。

Conclusion: 该成本感知型停止规则在与 PBGI 采集函数配对时，在成本调整的简单遗憾方面，持续匹配或优于其他采集函数-停止规则对，该度量捕捉了解觉质量和累积评估成本之间的权衡。

Abstract: In automated machine learning, scientific discovery, and other applications
of Bayesian optimization, deciding when to stop evaluating expensive black-box
functions is an important practical consideration. While several adaptive
stopping rules have been proposed, in the cost-aware setting they lack
guarantees ensuring they stop before incurring excessive function evaluation
costs. We propose a cost-aware stopping rule for Bayesian optimization that
adapts to varying evaluation costs and is free of heuristic tuning. Our rule is
grounded in a theoretical connection to state-of-the-art cost-aware acquisition
functions, namely the Pandora's Box Gittins Index (PBGI) and log expected
improvement per cost. We prove a theoretical guarantee bounding the expected
cumulative evaluation cost incurred by our stopping rule when paired with these
two acquisition functions. In experiments on synthetic and empirical tasks,
including hyperparameter optimization and neural architecture size search, we
show that combining our stopping rule with the PBGI acquisition function
consistently matches or outperforms other acquisition-function--stopping-rule
pairs in terms of cost-adjusted simple regret, a metric capturing trade-offs
between solution quality and cumulative evaluation cost.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [320] [New allocation rule based on graph structures and their application to economic phenomena](https://arxiv.org/abs/2507.11808)
*Taiki Yamada,Taisuke Matsubae,Tomoya Akamatsu*

Main category: cs.GT

TL;DR: 本研究提出了边缘化夏普利值，一种新的分配规则，用于评估网络化系统中由交互（边缘）驱动的价值，解决了传统基于节点的分配方法的局限性，并在内容平台和供应链的案例中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统分配规则（如夏普利和梅尔森值）通常基于节点级别或连接组件的特征来评估玩家的贡献，未能充分捕捉边缘（交互）的关键作用，而边缘是供应链和数字平台等系统中价值生成的主要驱动力。

Method: 本研究提出了一种新的基于边缘的夏普利值，将特征函数从节点集转移到边集，以更精细、更具上下文敏感性地评估网络化系统中的贡献。

Result: 该研究建立了边缘化夏普利值的理论基础，并表明它保留了公平和对称等关键属性。在内容平台网络和供应链物流（SCL）的两个用例中，该方法产生了直观且结构一致的分配，尤其是在存在重叠路线、独家合同或成本敏感路径的情况下。

Conclusion: 该研究提出了边缘化夏普利值，一种新的合作博弈论分配规则，专门针对网络化系统。该方法将特征函数从节点集转移到边集，从而能够更精细、更具上下文敏感性地评估贡献。研究建立了其理论基础，证明了其与经典分配规则的关系，并表明它保留了公平和对称等关键属性。该方法在内容平台网络和供应链物流（SCL）等用例中产生了直观且结构一致的分配，特别是在存在重叠路线、独家合同或成本敏感路径的情况下。

Abstract: This study introduces the \emph{edge-based Shapley value}, a novel allocation
rule within cooperative game theory, specifically tailored for networked
systems, where value is generated through interactions represented by edges.
Traditional allocation rules, such as the Shapley and Myerson values, evaluate
player contributions based on node-level characteristics, or connected
components. However, these approaches often fail to adequately capture the
functional role of edges, which are crucial in systems such as supply chains
and digital platforms, where interactions, rather than individual agents, are
the primary drivers of value. Our edge-based Shapley value shifts the
characteristic function from node sets to edge sets, thereby enabling a more
granular and context-sensitive evaluation of the contributions. We establish
its theoretical foundations, demonstrate its relationship to classical
allocation rules, and show that it retains key properties such as fairness and
symmetry. To illustrate its applicability, we present two use cases: content
platform networks and supply chain logistics (SCL). In both cases, our method
produces intuitive and structurally consistent allocations, particularly in
scenarios with overlapping routes, exclusive contracts or cost-sensitive paths.
This framework offers a new perspective on value attribution in cooperative
settings with complex interaction structures and provides practical tools for
analyzing real-world economic and logistical networks.

</details>


### [321] [Coalitions on the Fly in Cooperative Games](https://arxiv.org/abs/2507.11883)
*Yao Zhang,Indrajit Saha,Zhaohong Sun,Makoto Yokoo*

Main category: cs.GT

TL;DR: 本研究提出了一种用于动态合作博弈的在线价值分配策略，旨在最大化社会福利，并为不同类型的策略提供了竞争比率分析。


<details>
  <summary>Details</summary>
Motivation: 在玩家动态到达和形成联盟以完成任务的合作博弈顺序设定中，设计一种能激励玩家形成最大化社会福利的联盟结构的在线价值分配策略。

Method: 研究了合作博弈中的顺序设定，玩家动态地形成联盟以完成任务。设计了一种在线价值分配策略，该策略旨在激励玩家形成最大化社会福利的联盟结构。重点研究了单调和有界合作博弈。

Result: 在单调和有界合作博弈中，任何不可撤销策略的竞争比率上限为 $\frac{3\mathsf{min}}{\mathsf{max}}$。所提出的策略竞争比率接近最优，为 $\min\left\{\frac{1}{2}, \frac{3\mathsf{min}}{\mathsf{max}}\right\}$。

Conclusion: 本研究设计了一种在线价值分配策略，该策略实现了接近最优的竞争比率，并在有限玩家数量的情况下考虑了非可撤销策略。

Abstract: In this work, we examine a sequential setting of a cooperative game in which
players arrive dynamically to form coalitions and complete tasks either
together or individually, depending on the value created. Upon arrival, a new
player as a decision maker faces two options: forming a new coalition or
joining an existing one. We assume that players are greedy, i.e., they aim to
maximize their rewards based on the information available at their arrival. The
objective is to design an online value distribution policy that incentivizes
players to form a coalition structure that maximizes social welfare. We focus
on monotone and bounded cooperative games. Our main result establishes an upper
bound of $\frac{3\mathsf{min}}{\mathsf{max}}$ on the competitive ratio for any
irrevocable policy (i.e., one without redistribution), and proposes a policy
that achieves a near-optimal competitive ratio of $\min\left\{\frac{1}{2},
\frac{3\mathsf{min}}{\mathsf{max}}\right\}$, where $\mathsf{min}$ and
$\mathsf{max}$ denote the smallest and largest marginal contribution of any
sub-coalition of players respectively. Finally, we also consider
non-irrevocable policies, with alternative bounds only when the number of
players is limited.

</details>


### [322] [Contracting with a Mechanism Designer](https://arxiv.org/abs/2507.12054)
*Tian Bai,Yiding Feng,Yaohao Liu,Mengfan Ma,Mingyu Xiao*

Main category: cs.GT

TL;DR: 本文提出一个三方模型来分析众包市场的经济互动，使用斯塔克尔伯格博弈和虚拟价值定价来优化委托方与平台之间的合同设计，并量化了信息不对称和市场不确定性带来的效率损失。


<details>
  <summary>Details</summary>
Motivation: 现代众包市场中，雇主、平台和工人之间的经济互动日益复杂。现有模型难以充分解释这种多方关系中的激励机制和效率损失，因此需要一个更全面的分析框架来理解和优化这些市场。

Method: 本文将众包市场中的经济互动建模为一个三方博弈，即委托方（雇主）、中间方（平台）和代理方（工人）。该模型被分析为一个扩展型斯塔克尔伯格博弈。研究中引入了虚拟价值定价的概念，并将委托方的效用损失量化为双重边际化价格（PoDM）和无政府价格（PoA）。

Result: 研究成功地对子博弈完美均衡进行了完全刻画，揭示了在特定条件下线性合同是最优的。研究还量化了委托方因委托和信息不对称造成的效用损失（PoDM和PoA），并为这些比率在不同分布假设和匿名定价机制下的表现提供了界限。最后，研究将这些结果扩展到一个考虑市场规模不确定性的稳健框架。

Conclusion: 该研究为理解众包市场的经济动态提供了新的视角，并提出了在信息不对称和代理成本存在的情况下，如何设计最优委托合同。

Abstract: This paper explores the economic interactions within modern crowdsourcing
markets. In these markets, employers issue requests for tasks, platforms
facilitate the recruitment of crowd workers, and workers complete tasks for
monetary rewards. Recognizing that these roles serve distinct functions within
the ecosystem, we introduce a three-party model that distinguishes among the
principal (the requester), the intermediary (the platform), and the pool of
agents (the workers). The principal, unable to directly engage with agents,
relies on the intermediary to recruit and incentivize them. This interaction
unfolds in two stages: first, the principal designs a profit-sharing contract
with the intermediary; second, the intermediary implements a mechanism to
select an agent to complete the delegated task.
  We analyze the proposed model as an extensive-form Stackelberg game. Our
contributions are fourfold: (1) We fully characterize the subgame perfect
equilibrium. In particular, we reduce the principal's contract design problem
to a novel auction-theoretic formulation we term virtual value pricing, and
reveals that linear contracts are optimal even when the task have multiple
outcomes and agents' cost distributions are asymmetric. (2) To quantify the
principal's utility loss from delegation and information asymmetry, we
introduce the price of double marginalization (PoDM) and the classical price of
anarchy (PoA), and derive tight or nearly tight bounds on both ratios under
regular and monotone hazard rate (MHR) distributions. (3) We further examine
these two ratios in a natural setting where the intermediary is restricted to
anonymous pricing mechanisms, and show that similar qualitative insights
continue to hold. (4) Finally, we extend our results on both ratios to a robust
framework that accommodates scenarios in which the principal lacks precise
information about the market size.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [323] [Real-Time Cloth Simulation Using WebGPU: Evaluating Limits of High-Resolution](https://arxiv.org/abs/2507.11794)
*Nak-Jun Sung,Jun Ma,TaeHeon Kim,Yoo-joo Choi,Min-Hyung Choi,Min Hong*

Main category: cs.GR

TL;DR: WebGPU在实时布料模拟方面比WebGL有显著的性能提升，能处理高分辨率和复杂的碰撞，但仍需平衡性能与真实感。


<details>
  <summary>Details</summary>
Motivation: 传统基于WebGL的方法在处理复杂的物理模拟（如布料模拟）时存在性能瓶颈，因为WebGL更侧重于图形渲染而非通用GPU（GPGPU）计算。WebGPU作为一种新的图形和计算范式，有望通过其并行处理和计算着色器能力来改善这些情况。

Method: 使用基于WebGPU的框架，通过实现质量-弹簧方法（Mass-Spring Method）来进行布料模拟，并集成了碰撞检测与响应处理。

Result: 与WebGL相比，WebGPU在布料模拟性能上表现出显著优越性，特别是在高分辨率模拟下，即使节点数达到640K，也能维持60fps。WebGPU能够实时处理4K到100K节点布料模型与100K三角形表面模型之间的碰撞。

Conclusion: WebGPU在实时布料模拟方面表现出显著的优势，能够实现高分辨率下的高性能，并能处理复杂的碰撞交互，尤其是在与WebGL的比较中。然而，在追求实时性能与真实感渲染之间取得平衡仍然是一个关键的考虑因素。

Abstract: This study explores the capabilities of WebGPU, an emerging web graphics
paradigm, for real-time cloth simulation. Traditional WebGL-based methods have
been in handling complex physical simulations due to their emphasis on graphics
rendering rather than general-purpose GPU (GPGPU) operations. WebGPU, designed
to provide modern 3D graphics and computational capabilities, offers
significant improvements through parallel processing and support for
computational shaders. In this work, we implemented a cloth simulation system
using the Mass-Spring Method within the WebGPU framework, integrating collision
detection and response handling with the 3D surface model. First, comparative
performance evaluations demonstrate that WebGPU substantially outperforms
WebGL, particularly in high-resolution simulations, maintaining 60 frames per
second (fps) even with up to 640K nodes. The second experiment aimed to
determine the real-time limitations of WebGPU and confirmed that WebGPU can
handle real-time collisions between 4K and 100k cloth node models and a 100K
triangle surface model in real-time. These experiments also highlight the
importance of balancing real-time performance with realistic rendering when
handling collisions between cloth models and complex 3D objects. Our source
code is available at https://github.com/nakjun/Cloth-Simulation-WebGPU

</details>


### [324] [Measuring and predicting visual fidelity](https://arxiv.org/abs/2507.11857)
*Benjamin Watson,Alinda Friedman,Aaron McGaffey*

Main category: cs.GR

TL;DR: 本研究评估了测量和预测视觉保真度的实验和自动技术。发现实验技术对简化敏感但对物体类型反应不同。自动技术擅长预测评分，但在预测偏好和命名时间方面效果不佳。建议改进现有技术。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在研究和评估测量和预测视觉保真度的不同技术，并了解这些技术对不同物体类型和简化级别的响应。

Method: 本研究采用多边形模型作为视觉刺激，通过两种不同的模型简化算法（未具体说明）改变其保真度。研究将刺激分为动物和人造物品两类。实验技术包括命名时间、评分和偏好。自动预测技术包括基于图像和模型本身的技术。

Result: 所有测量方法（命名时间、评分、偏好）都对简化类型和简化级别敏感。然而，这些测量方法在对动物和人造物品这两种物体类型的响应上有所不同。自动测量技术在预测实验评分方面表现良好，在预测偏好方面效果一般，在预测命名时间方面效果不佳。

Conclusion: 本研究对用于测量和预测视觉保真度的技术进行了研究。研究使用了多边形模型作为视觉刺激，并通过两种不同的模型简化算法来改变其保真度。研究还将刺激分为两类：动物和人造物品。研究了三种不同的实验技术来测量这些保真度变化：命名时间、评分和偏好。所有测量方法都对简化类型和简化级别敏感。然而，这些测量方法在对物体类型的响应上有所不同。研究还检查了几种自动技术来预测这些实验测量，包括基于图像和模型本身的技术。自动保真度测量在预测实验评分方面取得了成功，在预测偏好方面不太成功，在预测命名时间方面基本失败。最后，我们对实验和自动视觉保真度测量的使用和改进提出了建议。

Abstract: This paper is a study of techniques for measuring and predicting visual
fidelity. As visual stimuli we use polygonal models, and vary their fidelity
with two different model simplification algorithms. We also group the stimuli
into two object types: animals and man made artifacts. We examine three
different experimental techniques for measuring these fidelity changes: naming
times, ratings, and preferences. All the measures were sensitive to the type of
simplification and level of simplification. However, the measures differed from
one another in their response to object type. We also examine several automatic
techniques for predicting these experimental measures, including techniques
based on images and on the models themselves. Automatic measures of fidelity
were successful at predicting experimental ratings, less successful at
predicting preferences, and largely failures at predicting naming times. We
conclude with suggestions for use and improvement of the experimental and
automatic measures of visual fidelity.

</details>


### [325] [MOSPA: Human Motion Generation Driven by Spatial Audio](https://arxiv.org/abs/2507.11949)
*Shuyang Xu,Zhiyang Dou,Mingyi Shi,Liang Pan,Leo Ho,Jingbo Wang,Yuan Liu,Cheng Lin,Yuexin Ma,Wenping Wang,Taku Komura*

Main category: cs.GR

TL;DR: This paper introduces the first Spatial Audio-Driven Human Motion (SAM) dataset and a diffusion-based framework (MOSPA) to generate human motion realistically responding to spatial audio, achieving state-of-the-art results.


<details>
  <summary>Details</summary>
Motivation: Existing models overlook the impact of spatial features in spatial audio signals on human motion. This work aims to bridge this gap by enabling high-quality modeling of human movements in response to spatial audio.

Method: A diffusion-based generative framework called MOSPA is developed to generate human motion from spatial audio. It utilizes an effective fusion mechanism to capture the relationship between body motion and spatial audio.

Result: MOSPA can generate diverse and realistic human motions conditioned on varying spatial audio inputs. The SAM dataset provides diverse and high-quality spatial audio and motion data for benchmarking.

Conclusion: The proposed MOSPA framework and SAM dataset achieve state-of-the-art performance in generating human motion driven by spatial audio, establishing a new benchmark for this task.

Abstract: Enabling virtual humans to dynamically and realistically respond to diverse
auditory stimuli remains a key challenge in character animation, demanding the
integration of perceptual modeling and motion synthesis. Despite its
significance, this task remains largely unexplored. Most previous works have
primarily focused on mapping modalities like speech, audio, and music to
generate human motion. As of yet, these models typically overlook the impact of
spatial features encoded in spatial audio signals on human motion. To bridge
this gap and enable high-quality modeling of human movements in response to
spatial audio, we introduce the first comprehensive Spatial Audio-Driven Human
Motion (SAM) dataset, which contains diverse and high-quality spatial audio and
motion data. For benchmarking, we develop a simple yet effective
diffusion-based generative framework for human MOtion generation driven by
SPatial Audio, termed MOSPA, which faithfully captures the relationship between
body motion and spatial audio through an effective fusion mechanism. Once
trained, MOSPA could generate diverse realistic human motions conditioned on
varying spatial audio inputs. We perform a thorough investigation of the
proposed dataset and conduct extensive experiments for benchmarking, where our
method achieves state-of-the-art performance on this task. Our model and
dataset will be open-sourced upon acceptance. Please refer to our supplementary
video for more details.

</details>


### [326] [HPR3D: Hierarchical Proxy Representation for High-Fidelity 3D Reconstruction and Controllable Editing](https://arxiv.org/abs/2507.11971)
*Tielong Wang,Yuxuan Xiong,Jinfan Liu,Zhifan Zhang,Ye Chen,Yue Shi,Bingbing Ni*

Main category: cs.GR

TL;DR: 提出了一种新的 3D 层次代理节点表示方法，解决了现有 3D 表示的局限性，实现了高效、高质量和易于编辑的 3D 模型。


<details>
  <summary>Details</summary>
Motivation: 现有的 3D 表示（如网格、体素、点云和 NeRF）存在局限性，例如任务特定性、编辑复杂性、结构模糊性以及数据复杂性与保真度之间的权衡。

Method: 提出了一种新颖的 3D 层次代理节点表示方法，通过在对象的表面和内部分布稀疏的代理节点，并通过层次结构（树状结构）组织它们。每个节点都存储其邻域内的局部形状和纹理信息（由小型 MLP 隐式编码）。查询任何 3D 坐标的属性涉及从附近和父节点进行高效的神经插值和轻量级解码。

Result: 该方法在 3D 重建和编辑方面表现出色，具有高度的表达效率、高保真渲染质量和卓越的可编辑性。

Conclusion: 该框架生成了紧凑的表示，其中节点与局部语义对齐，能够直接进行拖放编辑，并提供可扩展的质量-复杂性控制。实验证明了该方法的表达效率、高保真渲染质量和卓越的可编辑性。

Abstract: Current 3D representations like meshes, voxels, point clouds, and NeRF-based
neural implicit fields exhibit significant limitations: they are often
task-specific, lacking universal applicability across reconstruction,
generation, editing, and driving. While meshes offer high precision, their
dense vertex data complicates editing; NeRFs deliver excellent rendering but
suffer from structural ambiguity, hindering animation and manipulation; all
representations inherently struggle with the trade-off between data complexity
and fidelity. To overcome these issues, we introduce a novel 3D Hierarchical
Proxy Node representation. Its core innovation lies in representing an object's
shape and texture via a sparse set of hierarchically organized
(tree-structured) proxy nodes distributed on its surface and interior. Each
node stores local shape and texture information (implicitly encoded by a small
MLP) within its neighborhood. Querying any 3D coordinate's properties involves
efficient neural interpolation and lightweight decoding from relevant nearby
and parent nodes. This framework yields a highly compact representation where
nodes align with local semantics, enabling direct drag-and-edit manipulation,
and offers scalable quality-complexity control. Extensive experiments across 3D
reconstruction and editing demonstrate our method's expressive efficiency,
high-fidelity rendering quality, and superior editability.

</details>


### [327] [SmokeSVD: Smoke Reconstruction from A Single View via Progressive Novel View Synthesis and Refinement with Diffusion Models](https://arxiv.org/abs/2507.12156)
*Chen Li,Shanshan Dong,Sheng Qiu,Jianmin Han,Zan Gao,Kemeng Huang,Taku Komura*

Main category: cs.GR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Reconstructing dynamic fluids from sparse views is a long-standing and
challenging problem, due to the severe lack of 3D information from insufficient
view coverage. While several pioneering approaches have attempted to address
this issue using differentiable rendering or novel view synthesis, they are
often limited by time-consuming optimization and refinement processes under
ill-posed conditions. To tackle above challenges, we propose SmokeSVD, an
efficient and effective framework to progressively generate and reconstruct
dynamic smoke from a single video by integrating both the powerful generative
capabilities from diffusion models and physically guided consistency
optimization towards realistic appearance and dynamic evolution. Specifically,
we first propose a physically guided side-view synthesizer based on diffusion
models, which explicitly incorporates divergence and gradient guidance of
velocity fields to generate visually realistic and spatio-temporally consistent
side-view images frame by frame, significantly alleviating the ill-posedness of
single-view reconstruction without imposing additional constraints.
Subsequently, we determine a rough estimation of density field from the pair of
front-view input and side-view synthetic image, and further refine 2D blurry
novel-view images and 3D coarse-grained density field through an iterative
process that progressively renders and enhances the images from increasing
novel viewing angles, generating high-quality multi-view image sequences.
Finally, we reconstruct and estimate the fine-grained density field, velocity
field, and smoke source via differentiable advection by leveraging the
Navier-Stokes equations. Extensive quantitative and qualitative experiments
show that our approach achieves high-quality reconstruction and outperforms
previous state-of-the-art techniques.

</details>


### [328] [Shape Adaptation for 3D Hairstyle Retargeting](https://arxiv.org/abs/2507.12168)
*Lu Yu,Zhong Ren,Youyi Zheng,Xiang Chen,Kun Zhou*

Main category: cs.GR

TL;DR: An automatic method for adapting 3D hairstyles to new characters in games/VR, using multi-scale optimization and a new hairline editing tool, making it easier for artists.


<details>
  <summary>Details</summary>
Motivation: Retargeting existing 3D hairstyles for new characters in games and VR is challenging for artists due to complex hair geometries and spatial interactions that need to be preserved.

Method: The method formulates hair retargeting as a constrained optimization problem, using a multi-scale strategy for efficient computation. It addresses global coupling at a coarse level and local details in parallel. A novel hairline edit tool is introduced, utilizing physics-based membrane deformation to redistribute hair roots with minimal distortion.

Result: The method effectively retargets 3D hairstyles, demonstrated through quantitative and qualitative experiments on various hairstyles and characters, preserving shape properties and spatial relationships.

Conclusion: This paper presents an automatic shape adaptation method to retarget 3D hairstyles, achieving efficient and high-quality results through a multi-scale optimization strategy and offering user customization with a novel hairline edit tool.

Abstract: It is demanding to author an existing hairstyle for novel characters in games
and VR applications. However, it is a non-trivial task for artists due to the
complicated hair geometries and spatial interactions to preserve. In this
paper, we present an automatic shape adaptation method to retarget 3D
hairstyles. We formulate the adaptation process as a constrained optimization
problem, where all the shape properties and spatial relationships are converted
into individual objectives and constraints. To make such an optimization on
high-resolution hairstyles tractable, we adopt a multi-scale strategy to
compute the target positions of the hair strands in a coarse-to-fine manner.
The global solving for the inter-strands coupling is restricted to the coarse
level, and the solving for fine details is made local and parallel. In
addition, we present a novel hairline edit tool to allow for user customization
during retargeting. We achieve it by solving physics-based deformations of an
embedded membrane to redistribute the hair roots with minimal distortion. We
demonstrate the efficacy of our method through quantitative and qualitative
experiments on various hairstyles and characters.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [329] [Finite Pinwheel Scheduling: the k-Visits Problem](https://arxiv.org/abs/2507.11681)
*Sotiris Kanellopoulos,Christos Pergaminelis,Maria Kokkou,Euripides Markou,Aris Pagourtzis*

Main category: cs.DS

TL;DR: Pinwheel Scheduling 是一个基本调度问题，作者将其推广到 k-Visits，并证明 k=2 的情况是 NP-complete 的，但如果截止日期不同则可以解决。


<details>
  <summary>Details</summary>
Motivation: Pinwheel Scheduling 是一个基本的调度问题，其中每个任务 i 都与一个正整数 d_i 相关联，目标是每 1 个时间槽安排一个任务，确保每个任务在每 d_i 个时间槽中至少出现一次。虽然推测它是 PSPACE-complete，但 Pinwheel Scheduling 是否是 NP-hard（除非使用紧凑输入编码）甚至是否包含在 NP 中仍然是公开的。引入 k-Visits，Pinwheel Scheduling 的有限版本，其中给定 n 个截止日期，目标是准确地调度每个任务 k 次。

Method: 通过从数值三维匹配 (N3DM) 进行的惊人归约，证明了 2-Visits 是强 NP-complete。我们还通过将 2-Visits 归约到位置匹配（N3DM 的一种变体）来展示一种针对 2-Visits 的 FPT 算法，该算法由与输入截止日期彼此接近的程度相关的值参数化，以及一种针对具有最多两个不同截止日期的实例的线性时间算法。

Result: 2-Visits 是强 NP-complete，并且可以推广到 k-Visits (k>=2) 的变体，其中每个任务的截止日期在调度中可能不同，以及 Pinwheel Scheduling 的类似变体。

Conclusion: 2-Visits 问题当所有截止日期都不同时可以在线性时间内解决，这使得它成为少数几个具有有趣二分法的自然问题之一：当输入是集合时属于 P，当输入是多重集时是 NP-complete。通过将 2-Visits 归约到我们称为位置匹配的 N3DM 的变体，我们实现了这一点。基于此归约，我们还展示了一种针对 2-Visits 的 FPT 算法，该算法由与输入截止日期彼此接近的程度相关的值参数化，以及一种针对具有最多两个不同截止日期的实例的线性时间算法。

Abstract: Pinwheel Scheduling is a fundamental scheduling problem, in which each task
$i$ is associated with a positive integer $d_i$, and the objective is to
schedule one task per time slot, ensuring each task perpetually appears at
least once in every $d_i$ time slots. Although conjectured to be
PSPACE-complete, it remains open whether Pinwheel Scheduling is NP-hard (unless
a compact input encoding is used) or even contained in NP.
  We introduce k-Visits, a finite version of Pinwheel Scheduling, where given n
deadlines, the goal is to schedule each task exactly k times. While we observe
that the 1-Visit problem is trivial, we prove that 2-Visits is strongly
NP-complete through a surprising reduction from Numerical 3-Dimensional
Matching (N3DM). As intermediate steps in the reduction, we define NP-complete
variants of N3DM which may be of independent interest. We further extend our
strong NP-hardness result to a generalization of k-Visits $k\geq 2$ in which
the deadline of each task may vary throughout the schedule, as well as to a
similar generalization of Pinwheel Scheduling, thus making progress towards
settling the complexity of Pinwheel Scheduling.
  Additionally, we prove that 2-Visits can be solved in linear time if all
deadlines are distinct, rendering it one of the rare natural problems which
exhibit the interesting dichotomy of being in P if their input is a set and
NP-complete if the input is a multiset. We achieve this through a Turing
reduction from 2-Visits to a variation of N3DM, which we call Position
Matching. Based on this reduction, we also show an FPT algorithm for 2-Visits
parameterized by a value related to how close the input deadlines are to each
other, as well as a linear-time algorithm for instances with up to two distinct
deadlines.

</details>


### [330] [Approaching Optimality for Solving Dense Linear Systems with Low-Rank Structure](https://arxiv.org/abs/2507.11724)
*Michał Dereziński,Aaron Sidford*

Main category: cs.DS

TL;DR: 研究提出了新的随机算法，可以高效地求解条件适中的线性系统和回归问题，并首次实现了计算稠密矩阵核范数的近线性时间算法。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在提供高精度的随机算法来解决线性系统和回归问题，特别是针对那些除了 k 个大奇异值之外条件适中的情况。目的是在接近理论复杂度的同时，改进现有算法在处理这类问题时的性能和权衡。

Method: 该研究提出的算法基于三个通用的递归预处理框架，并仔细设计了矩阵绘制（sketching）和低秩更新公式以适应问题的结构。

Result: 该研究提出了新的高精度随机算法，在处理具有k个大奇异值的线性系统和回归问题时，运行时间接近理论最优。具体而言，对于d x d正定系统，运行时间为 O(d^2 + k^ω)；对于n x d矩阵的回归问题，运行时间为 O(nnz(A) + d^2 + k^ω)。研究还实现了计算任意稠密矩阵核范数的近线性时间算法。

Conclusion: 该研究提出了用于求解线性系统和回归问题的高精度随机算法。这些算法在处理具有k个大奇异值的适度条件问题时表现出色。对于 d x d 的正定系统，算法的成功率为 whp，运行时间为 O(d^2 + k^ω)。对于 A ∈ R^(nxd) 矩阵的回归问题，算法的成功率为 whp，运行时间为 O(nnz(A) + d^2 + k^ω)，其中 ω 是矩阵乘法指数，nnz(A) 是 A 中非零元素的数量。这些方法接近这些问题的稠密输入的自然复杂度限制，并改进了先前方法的权衡，先前方法在 d x d 系统上运行时间为 O(d^2.065} + k^ω) 或 O(d^2 + dk^{ω-1})。此外，研究表明，即使在所有奇异值（除了 k 个）具有适当界定的广义均值这一较弱假设下，也可以实现这些运行时间。因此，研究首次提出了计算任意稠密矩阵乘法近似核范数（nuclear norm）的近线性时间算法。这些算法基于三个通用的递归预处理框架，其中矩阵绘制（sketching）和低秩更新公式经过精心设计以适应问题的结构。

Abstract: We provide new high-accuracy randomized algorithms for solving linear systems
and regression problems that are well-conditioned except for $k$ large singular
values. For solving such $d \times d$ positive definite system our algorithms
succeed whp. and run in time $\tilde O(d^2 + k^\omega)$. For solving such
regression problems in a matrix $\mathbf{A} \in \mathbb{R}^{n \times d}$ our
methods succeed whp. and run in time $\tilde O(\mathrm{nnz}(\mathbf{A}) + d^2 +
k^\omega)$ where $\omega$ is the matrix multiplication exponent and
$\mathrm{nnz}(\mathbf{A})$ is the number of non-zeros in $\mathbf{A}$. Our
methods nearly-match a natural complexity limit under dense inputs for these
problems and improve upon a trade-off in prior approaches that obtain running
times of either $\tilde O(d^{2.065}+k^\omega)$ or $\tilde O(d^2 +
dk^{\omega-1})$ for $d\times d$ systems. Moreover, we show how to obtain these
running times even under the weaker assumption that all but $k$ of the singular
values have a suitably bounded generalized mean. Consequently, we give the
first nearly-linear time algorithm for computing a multiplicative approximation
to the nuclear norm of an arbitrary dense matrix. Our algorithms are built on
three general recursive preconditioning frameworks, where matrix sketching and
low-rank update formulas are carefully tailored to the problems' structure.

</details>


### [331] [Pathfinding in Self-Deleting Graphs](https://arxiv.org/abs/2507.12047)
*Michal Dvořák,Dušan Knop,Michal Opler,Jan Pokorný,Ondřej Suchý,Krisztina Szilágyi*

Main category: cs.DS

TL;DR: 在遍历依赖图（特别是自删除图）上寻找路径的问题是NP难的，并且在某些参数化下是W[1]-完全的。但当参数为f(v)的最大尺寸和某些结构参数时，问题是FPT的。该问题也不存在多项式核。  


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于解决一种新型的图搜索问题，即在“遍历依赖图”上进行路径寻找。这类图的特点是边的存在与否会随着访问过的顶点的变化而变化，这与传统图搜索问题有显著区别。具体而言，研究关注的是“自删除图”，其中每个顶点都关联一个函数，该函数指定了访问该顶点后将被删除的边集。这种遍历依赖性使得路径寻找变得更加复杂。研究旨在深入理解这类问题的计算复杂性，并探索在不同参数化下的可处理性，为解决现实世界中涉及动态或状态依赖性搜索问题的算法设计提供理论基础。

Method: 本研究首先定义了“自删除图”的概念，即图中边的删除与否取决于之前访问过的顶点。然后，针对“自删除s-t路径”问题，研究证明了即使在图是外平面、二分图、最大度为3、带宽为2且每个顶点的f(v)大小不超过1的特定条件下，该问题也是NP难的。对于“最短自删除s-t路径”问题，研究证明了当以路径长度为参数时，该问题是W[1]-完全的。对于“自删除s-t路径”问题，研究证明了当以顶点覆盖数、反馈顶点集数和树深度为参数时，该问题也是W[1]-完全的。此外，研究还表明，当以f(v)的最大尺寸以及几个结构参数为参数时，该问题是可处理的（FPT）。最后，研究通过证明即使在2-外平面图上，结合顶点覆盖数和f(v)的最大尺寸作为参数时，该问题也不存在多项式核，从而对问题的计算复杂性进行了更深入的探讨。

Result: 本研究证明了“自删除s-t路径”问题在多种限制条件下（包括图为外平面、二分图、最大度为3、带宽为2且|f(v)|≤1）仍然是NP难的。进一步地，“最短自删除s-t路径”问题在以路径长度为参数时是W[1]-完全的，而“自删除s-t路径”问题在以顶点覆盖数、反馈顶点集数和树深度为参数时也是W[1]-完全的。研究还发现，该问题在以f(v)的最大尺寸和几个结构参数为参数时是FPT的。最后，研究表明，即使仅考虑2-外平面图，并且参数为顶点覆盖数和f(v)的最大尺寸的组合，该问题也不存在多项式核。

Conclusion: 该研究证明了在自删除图上寻找s-t路径的问题是NP难的，即使在特定限制条件下也是如此。同时，它还表明该问题在以路径长度、顶点覆盖数、反馈顶点集数和树深度为参数时是W[1]-完全的。研究还发现，当以f(v)的最大尺寸和几个结构参数为参数时，该问题是FPT（固定参数可处理的）。最后，研究指出，即使结合了顶点覆盖数和f(v)的最大尺寸作为参数，该问题在2-外平面图上也不存在多项式核。

Abstract: In this paper, we study the problem of pathfinding on traversal-dependent
graphs, i.e., graphs whose edges change depending on the previously visited
vertices. In particular, we study \emph{self-deleting graphs}, introduced by
Carmesin et al. (Sarah Carmesin, David Woller, David Parker, Miroslav Kulich,
and Masoumeh Mansouri. The Hamiltonian cycle and travelling salesperson
problems with traversal-dependent edge deletion. J. Comput. Sci.), which
consist of a graph $G=(V, E)$ and a function $f\colon V\rightarrow 2^E$, where
$f(v)$ is the set of edges that will be deleted after visiting the vertex $v$.
In the \textsc{(Shortest) Self-Deleting $s$-$t$-path} problem we are given a
self-deleting graph and its vertices $s$ and $t$, and we are asked to find a
(shortest) path from $s$ to $t$, such that it does not traverse an edge in
$f(v)$ after visiting $v$ for any vertex $v$.
  We prove that \textsc{Self-Deleting $s$-$t$-path} is NP-hard even if the
given graph is outerplanar, bipartite, has maximum degree $3$, bandwidth $2$
and $|f(v)|\leq 1$ for each vertex $v$. We show that \textsc{Shortest
Self-Deleting $s$-$t$-path} is W[1]-complete parameterized by the length of the
sought path and that \textsc{Self-Deleting $s$-$t$-path} is \W{1}-complete
parameterized by the vertex cover number, feedback vertex set number and
treedepth. We also show that the problem becomes FPT when we parameterize by
the maximum size of $f(v)$ and several structural parameters. Lastly, we show
that the problem does not admit a polynomial kernel even for parameterization
by the vertex cover number and the maximum size of $f(v)$ combined already on
2-outerplanar graphs.

</details>


### [332] [Weighted $k$-Server Admits an Exponentially Competitive Algorithm](https://arxiv.org/abs/2507.12130)
*Adithya Bijoy,Ankit Mondal,Ashish Chiplunkar*

Main category: cs.DS

TL;DR: 本文为加权 k-服务器问题设计了一个竞争比为 exp(O(k^2)) 的随机在线算法，打破了之前的指数级壁垒。


<details>
  <summary>Details</summary>
Motivation: 加权 k-服务器问题以其复杂的性质和逃避标准在线算法技术而闻名，其确定性竞争比随 k 指数级增长，而随机竞争比的行为尚未完全理解，本文旨在缩小随机和确定性竞争比之间的指数级差距。

Method: 通过递归定义“阶段”的概念，对任何离线解施加成本下界，同时允许具有有界期望成本的随机在线算法。该算法本身也是递归的，涉及虚拟并行运行多个算法，并以随机顺序遵循其中一个算法的决策。

Result: 提出了一种竞争比为 exp(O(k^2)) 的加权 k-服务器随机在线算法，该算法打破了确定性算法的指数级壁垒。该技术还可以推广到加权统一度量上的广义 k-服务器问题。

Conclusion: 本文为加权 k-服务器问题设计了一个具有 exp(O(k^2)) 竞争比的随机在线算法，打破了确定性算法的指数级壁垒，并将其技术推广到加权统一度量上的广义 k-服务器问题。

Abstract: The weighted $k$-server is a variant of the $k$-server problem, where the
cost of moving a server is the server's weight times the distance through which
it moves. The problem is famous for its intriguing properties and for evading
standard techniques for designing and analyzing online algorithms. Even on
uniform metric spaces with sufficiently many points, the deterministic
competitive ratio of weighted $k$-server is known to increase doubly
exponentially with respect to $k$, while the behavior of its randomized
competitive ratio is not fully understood. Specifically, no upper bound better
than doubly exponential is known, while the best known lower bound is singly
exponential in $k$. In this paper, we close the exponential gap between these
bounds by giving an $\exp(O(k^2))$-competitive randomized online algorithm for
the weighted $k$-server problem on uniform metrics, thus breaking the doubly
exponential barrier for deterministic algorithms for the first time. This is
achieved by a recursively defined notion of a phase which, on the one hand,
forces a lower bound on the cost of any offline solution, while, on the other
hand, also admits a randomized online algorithm with bounded expected cost. The
algorithm is also recursive; it involves running several algorithms virtually
and in parallel and following the decisions of one of them in a random order.
We also show that our techniques can be lifted to construct an
$\exp(O(k^2))$-competitive randomized online algorithm for the generalized
$k$-server problem on weighted uniform metrics.

</details>


### [333] [A near-complete resolution of the exponential-time complexity of k-opt for the traveling salesman problem](https://arxiv.org/abs/2507.12304)
*Sophia Heimann,Hung P. Hoang,Stefan Hougardy*

Main category: cs.DS

TL;DR: $k$-opt 算法在 $k=3,4$ 时可能需要指数级迭代，2.5-opt 也有类似下界。


<details>
  <summary>Details</summary>
Motivation: 解决 $k$-opt 算法在 $k=3$ 和 $k=4$ 的情况下，即使使用最优枢轴选择规则，迭代次数的上界问题。

Method: 通过证明在 $k=3$ 和 $k=4$ 的情况下，即使使用最优枢轴选择规则，k-opt 算法也可能需要指数级迭代次数，来解决 $k$-opt 算法迭代次数的开放性问题。

Result: 证明了 $k$-opt 算法在 $k=3$ 和 $k=4$ 的情况下，可能需要指数级迭代次数，即使使用最优枢轴选择规则。同时，也为 2.5-opt 算法建立了类似的指数级下界。

Conclusion: 该研究解决了 $k$-opt 算法在 $k=3$ 和 $k=4$ 的情况下，即使使用最优枢轴选择规则，也可能需要指数级迭代次数的问题。研究还为 2.5-opt 算法建立了类似的指数级下界。所有结果均适用于一般和度量旅行商问题。

Abstract: The $k$-opt algorithm is one of the simplest and most widely used heuristics
for solving the traveling salesman problem. Starting from an arbitrary tour,
the $k$-opt algorithm improves the current tour in each iteration by exchanging
up to $k$ edges. The algorithm continues until no further improvement of this
kind is possible. For a long time, it remained an open question how many
iterations the $k$-opt algorithm might require for small values of $k$,
assuming the use of an optimal pivot rule. In this paper, we resolve this
question for the cases $k = 3$ and $k = 4$ by proving that in both these cases
an exponential number of iterations may be needed even if an optimal pivot rule
is used. Combined with a recent result from Heimann, Hoang, and Hougardy (ICALP
2024), this provides a complete answer for all $k \geq 3$ regarding the number
of iterations the $k$-opt algorithm may require under an optimal pivot rule. In
addition we establish an analogous exponential lower bound for the 2.5-opt
algorithm, a variant that generalizes 2-opt and is a restricted version of
3-opt. All our results hold for both the general and the metric traveling
salesman problem.

</details>


### [334] [Online Block Packing](https://arxiv.org/abs/2507.12357)
*Ariel Ben Eliezer,Noam Nisan*

Main category: cs.DS

TL;DR: 为具有多维块约束和近似耐心竞标者的区块链提供在线近似算法，以解决 Babaioff 和 Nisan（2025 年 EC）提出的公开问题。


<details>
  <summary>Details</summary>
Motivation: 解决 Babaioff 和 Nisan（2025 年 EC）留下的公开问题，这些问题涉及具有多维块约束和近似耐心竞标者的区块链的算法挑战。

Method: 在线近似算法

Result: 提供在线近似算法，以解决具有多维块约束和近似耐心竞标者的区块链的算法挑战。

Conclusion: 该研究为具有多维块约束且服务于近似耐心竞标者的区块链算法挑战提供了在线近似算法。

Abstract: We consider the algorithmic challenge that is faced by blockchains that have
multidimensional block constraints and serve quasi-patient bidders. We provide
online approximation algorithms for this problem, thus solving open problems
left by [Babaioff and Nisan, EC 2025].

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [335] [CompressedVQA-HDR: Generalized Full-reference and No-reference Quality Assessment Models for Compressed High Dynamic Range Videos](https://arxiv.org/abs/2507.11900)
*Wei Sun,Linhan Cao,Kang Fu,Dandan Zhu,Jun Jia,Menghan Hu,Xiongkuo Min,Guangtao Zhai*

Main category: eess.IV

TL;DR: 提出 CompressedVQA-HDR 框架，利用 Swin Transformer (FR) 和 SigLip 2 (NR) 评估 HDR 视频质量，通过在 SDR 数据集上预训练和混合数据集训练等策略解决了数据不足问题，取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视频压缩质量评估（VQA）方法在处理日益多样化的视频内容，特别是高动态范围（HDR）内容时，往往缺乏泛化能力，因此需要开发能够有效评估 HDR 视频质量的方法。

Method: 提出了一种名为 CompressedVQA-HDR 的视频质量评估（VQA）框架，包含全参考（FR）和无参考（NR）两种模型。FR 模型采用 Swin Transformer 提取参考帧和失真帧的深度结构和纹理相似性特征。NR 模型利用 SigLip 2 提取最终层特征图的全局均值作为质量感知表示。为了解决 HDR 训练数据有限的问题，FR 模型在大量 SDR VQA 数据集上预训练后，在 HDRSDR-VQA 数据集上进行微调；NR 模型则采用跨多个压缩 VQA 数据集的迭代混合数据集训练策略，随后在 HDRSDR-VQA 数据集上进行微调。

Result: 实验结果表明，所提出的 FR 和 NR 模型相比现有的 VQA 模型取得了最先进的性能。CompressedVQA-HDR-FR 模型在 IEEE ICME 2025 的 Generalizable HDR & SDR Video Quality Measurement Grand Challenge 的 FR 赛道中获得第一名。

Conclusion: 所提出的 CompressedVQA-HDR 框架在评估 HDR 视频质量方面表现出色，其 FR 和 NR 模型均达到了最先进的性能，并且 FR 模型在 IEEE ICME 2025 的比赛中获得第一名。

Abstract: Video compression is a standard procedure applied to all videos to minimize
storage and transmission demands while preserving visual quality as much as
possible. Therefore, evaluating the visual quality of compressed videos is
crucial for guiding the practical usage and further development of video
compression algorithms. Although numerous compressed video quality assessment
(VQA) methods have been proposed, they often lack the generalization capability
needed to handle the increasing diversity of video types, particularly high
dynamic range (HDR) content. In this paper, we introduce CompressedVQA-HDR, an
effective VQA framework designed to address the challenges of HDR video quality
assessment. Specifically, we adopt the Swin Transformer and SigLip 2 as the
backbone networks for the proposed full-reference (FR) and no-reference (NR)
VQA models, respectively. For the FR model, we compute deep structural and
textural similarities between reference and distorted frames using
intermediate-layer features extracted from the Swin Transformer as its
quality-aware feature representation. For the NR model, we extract the global
mean of the final-layer feature maps from SigLip 2 as its quality-aware
representation. To mitigate the issue of limited HDR training data, we
pre-train the FR model on a large-scale standard dynamic range (SDR) VQA
dataset and fine-tune it on the HDRSDR-VQA dataset. For the NR model, we employ
an iterative mixed-dataset training strategy across multiple compressed VQA
datasets, followed by fine-tuning on the HDRSDR-VQA dataset. Experimental
results show that our models achieve state-of-the-art performance compared to
existing FR and NR VQA models. Moreover, CompressedVQA-HDR-FR won first place
in the FR track of the Generalizable HDR & SDR Video Quality Measurement Grand
Challenge at IEEE ICME 2025. The code is available at
https://github.com/sunwei925/CompressedVQA-HDR.

</details>


### [336] [Identifying Signatures of Image Phenotypes to Track Treatment Response in Liver Disease](https://arxiv.org/abs/2507.12012)
*Matthias Perkonigg,Nina Bastati,Ahmed Ba-Ssalamah,Peter Mesenbrink,Alexander Goehler,Miljen Martic,Xiaofei Zhou,Michael Trauner,Georg Langs*

Main category: eess.IV

TL;DR: 本研究利用无监督机器学习和深度聚类网络，从肝脏磁共振图像中识别出可量化治疗反应的组织模式词汇，并在非酒精性脂肪性肝炎患者的临床试验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 量化的与疾病进展和治疗反应相关的图像模式对于指导个体治疗和开发新疗法至关重要。

Method: 本研究提出了一种使用深度聚类网络同时编码和聚类医学图像斑块到低维潜在空间的方法，以建立组织模式词汇。

Result: 该词汇能够捕捉与治疗反应相关的差异性组织变化及其在肝脏中的位置。在非酒精性脂肪性肝炎患者的随机对照试验队列中，该方法能够识别与治疗相关的特定肝脏组织变化通路，并且比已有的非影像学测量方法能更好地区分治疗组。此外，该词汇还可以根据非侵入性影像数据预测活检衍生的特征。

Conclusion: 该方法在独立的验证队列上进行了验证，证明了所提出方法的可行性。

Abstract: Quantifiable image patterns associated with disease progression and treatment
response are critical tools for guiding individual treatment, and for
developing novel therapies. Here, we show that unsupervised machine learning
can identify a pattern vocabulary of liver tissue in magnetic resonance images
that quantifies treatment response in diffuse liver disease. Deep clustering
networks simultaneously encode and cluster patches of medical images into a
low-dimensional latent space to establish a tissue vocabulary. The resulting
tissue types capture differential tissue change and its location in the liver
associated with treatment response. We demonstrate the utility of the
vocabulary on a randomized controlled trial cohort of non-alcoholic
steatohepatitis patients. First, we use the vocabulary to compare longitudinal
liver change in a placebo and a treatment cohort. Results show that the method
identifies specific liver tissue change pathways associated with treatment, and
enables a better separation between treatment groups than established
non-imaging measures. Moreover, we show that the vocabulary can predict biopsy
derived features from non-invasive imaging data. We validate the method on a
separate replication cohort to demonstrate the applicability of the proposed
method.

</details>


### [337] [Benchmarking and Explaining Deep Learning Cortical Lesion MRI Segmentation in Multiple Sclerosis](https://arxiv.org/abs/2507.12092)
*Nataliia Molchanova,Alessandro Cagol,Mario Ocampo-Pineda,Po-Jui Lu,Matthias Weigel,Xinjie Chen,Erin Beck,Charidimos Tsagkas,Daniel Reich,Colin Vanden Bulcke,Anna Stolting,Serena Borrelli,Pietro Maggi,Adrien Depeursinge,Cristina Granziera,Henning Mueller,Pedro M. Gordaliza,Meritxell Bach Cuadra*

Main category: eess.IV

TL;DR: 这项研究开发并评估了一个自动化的 MRI 皮层病变检测和分割系统，在多中心数据集上取得了良好的结果，并为提高其临床应用提供了见解和建议。


<details>
  <summary>Details</summary>
Motivation: 由于 CL 在 MRI 上的成像特点、专家标注的挑战以及缺乏标准化的自动化方法，其在临床上的应用受到限制，因此需要一个全面的基准测试来改进 CL 的检测和分割。

Method: 本研究使用 nnU-Net 框架，并进行了针对性的改进，对来自四个机构的 656 个 MRI 扫描进行了 CL 检测和分割的基准测试，并进行了分布外测试。

Result: 在多中心基准测试中，模型在同域测试中表现出 0.64 的 F1 分数，在分布外测试中为 0.5，表明了其强大的病变检测能力。研究还分析了模型内部特征和错误，以更好地理解 AI 的决策过程，并探讨了数据变异性、病变模糊性和方案差异对模型性能的影响。

Conclusion: 本研究提出了一种用于检测和分割多发性硬化症（MS）皮层病变（CL）的综合性多中心基准测试，并对模型进行了评估和分析，为克服临床应用障碍提供了建议。

Abstract: Cortical lesions (CLs) have emerged as valuable biomarkers in multiple
sclerosis (MS), offering high diagnostic specificity and prognostic relevance.
However, their routine clinical integration remains limited due to subtle
magnetic resonance imaging (MRI) appearance, challenges in expert annotation,
and a lack of standardized automated methods. We propose a comprehensive
multi-centric benchmark of CL detection and segmentation in MRI. A total of 656
MRI scans, including clinical trial and research data from four institutions,
were acquired at 3T and 7T using MP2RAGE and MPRAGE sequences with
expert-consensus annotations. We rely on the self-configuring nnU-Net
framework, designed for medical imaging segmentation, and propose adaptations
tailored to the improved CL detection. We evaluated model generalization
through out-of-distribution testing, demonstrating strong lesion detection
capabilities with an F1-score of 0.64 and 0.5 in and out of the domain,
respectively. We also analyze internal model features and model errors for a
better understanding of AI decision-making. Our study examines how data
variability, lesion ambiguity, and protocol differences impact model
performance, offering future recommendations to address these barriers to
clinical adoption. To reinforce the reproducibility, the implementation and
models will be publicly accessible and ready to use at
https://github.com/Medical-Image-Analysis-Laboratory/ and
https://doi.org/10.5281/zenodo.15911797.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [338] [Generative Intelligence Systems in the Flow of Group Emotions](https://arxiv.org/abs/2507.11831)
*Fernando Koch,Jessica Nahulan,Jeremy Fox,Martin Keen*

Main category: cs.HC

TL;DR: 该研究提出了一种用于编排情绪传染的模型，使人工智能代理能够检测、推断和响应群体情绪，以调节协作、教育和社会环境中的群体情绪。


<details>
  <summary>Details</summary>
Motivation: 为了在包含人类和人工智能代理的交互式设置中，利用情感线索来塑造群体动态，并使人工智能代理能够模拟情感行为。

Method: 提出了一种能够检测情绪信号、推断群体情绪模式并生成目标情绪反应的情绪传染编排模型。该系统能够捕捉人类的情绪交流，并利用这些见解来生成适应性、生成性响应，从而实时影响群体情绪。

Result: 实验结果证明了该系统在感知和引导群体情绪动态方面的有效性。

Conclusion: 该模型能够实现情绪传染的编排，用于在协作、教育和社会环境等应用中，通过实时生成适应性响应来调节群体情绪，将情感计算从个体层面反应提升到群体层面。

Abstract: Emotional cues frequently arise and shape group dynamics in interactive
settings where multiple humans and artificial agents communicate through shared
digital channels. While artificial agents lack intrinsic emotional states, they
can simulate affective behavior using synthetic modalities such as text or
speech. This work introduces a model for orchestrating emotion contagion,
enabling agents to detect emotional signals, infer group mood patterns, and
generate targeted emotional responses. The system captures human emotional
exchanges and uses this insight to produce adaptive, generative responses that
influence group affect in real time. The model supports applications in
collaborative, educational, and social environments by shifting affective
computing from individual-level reactions to coordinated, group-level emotion
modulation. We present the system architecture and provide experimental results
that illustrate its effectiveness in sensing and steering group mood dynamics.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [339] [Foundation Models for Brain Signals: A Critical Review of Current Progress and Future Directions](https://arxiv.org/abs/2507.11783)
*Gayal Kuruppu,Neeraj Wagh,Yogatheesan Varatharajah*

Main category: eess.SP

TL;DR: 早期EEG-FMs在利用Transformer进行自监督学习方面取得了进展，但评估方法不统一且有限。未来的研究需要标准化评估、展示规模效应，并与领域专家合作以推动其实际应用。


<details>
  <summary>Details</summary>
Motivation: 由于有监督EEG编码器在学习鲁棒EEG模式方面存在不足，且过度依赖昂贵的信号注释，因此研究重点转向通用的自监督EEG编码器（即EEG基础模型，EEG-FMs），以实现鲁棒和可扩展的EEG特征提取。然而，早期EEG-FMs的实际准备情况和长期研究进展的评价标准尚不明确，因此有必要对第一代EEG-FMs进行系统性、全面的回顾。

Method: 本研究对10个早期的EEG-FMs进行了回顾，并对其方法、实证结果和现有研究差距进行了批判性综合。大多数EEG-FMs采用基于序列的建模方案，依赖于基于Transformer的骨干网络，并通过重构掩码序列来进行自监督学习。

Result: 大多数EEG-FMs采用了基于序列的建模方案，利用Transformer骨干网络，并通过重构掩码序列来进行自监督学习。然而，模型评估方法不统一且评估范围有限，难以评估其在实际应用中的效用。未来的工作需要在标准化和现实的评估方面取得进展，并展示出更显著的规模效应，同时在EEG表示学习流程中做出合乎原则且值得信赖的选择。

Conclusion: 未来的EEG-FMs研究应采用标准化的、现实的评估方法，并展示更显著的规模效应。同时，应在EEG表示学习流程中做出原则性和可信赖的选择，通过与领域专家合作开发基准、软件工具、技术方法和应用程序，以进一步提高EEG-FMs的转化效用和实际应用。

Abstract: Patterns of electrical brain activity recorded via electroencephalography
(EEG) offer immense value for scientific and clinical investigations. The
inability of supervised EEG encoders to learn robust EEG patterns and their
over-reliance on expensive signal annotations have sparked a transition towards
general-purpose self-supervised EEG encoders, i.e., EEG foundation models
(EEG-FMs), for robust and scalable EEG feature extraction. However, the
real-world readiness of early EEG-FMs and the rubric for long-term research
progress remain unclear. A systematic and comprehensive review of
first-generation EEG-FMs is therefore necessary to understand the current
state-of-the-art and identify key directions for future EEG-FMs. To that end,
this study reviews 10 early EEG-FMs and presents a critical synthesis of their
methodology, empirical findings, and outstanding research gaps. We find that
most EEG-FMs adopt a sequence-based modeling scheme that relies on
transformer-based backbones and the reconstruction of masked sequences for
self-supervision. However, model evaluations remain heterogeneous and largely
limited, making it challenging to assess their practical off-the-shelf utility.
In addition to adopting standardized and realistic evaluations, future work
should demonstrate more substantial scaling effects and make principled and
trustworthy choices throughout the EEG representation learning pipeline. We
believe that developing benchmarks, software tools, technical methodologies,
and applications in collaboration with domain experts may further advance the
translational utility and real-world adoption of EEG-FMs.

</details>


### [340] [Directional Measurements and Analysis for FR3 Low-Altitude Channels in a Campus Environment](https://arxiv.org/abs/2507.11846)
*Yulu Guo,Tongjia Zhang,Xiangwen Gu,Shu Sun,Meixia Tao,Ruifeng Gao*

Main category: eess.SP

TL;DR: 本研究通过在室外校园环境中进行低高度信道测量，展示了路径损耗和功率角谱的测量结果，并分析了这些结果在不同场景下的表现，旨在为中频段通信系统提供渠道模型的基本见解。


<details>
  <summary>Details</summary>
Motivation: 本论文旨在提供一个关于FR3频段在室外校园环境中低高度信道测量的详细信息。

Method: 本研究使用时域信道探测系统，进行了两种类型的测量：通过沿26个点的屋顶路径以1米间隔移动发射器（Tx）进行的路径损耗测量，以及通过在半功率波束宽度间隔内进行天线扫描而进行的定向功率角谱测量。

Result: 路径损耗分析表明，近点模型优于传统的3GPP模型及其高度校正的变体，路径损耗指数接近自由空间值，表明视距传播占主导地位。功率角谱测量表明，传播行为随环境条件变化显著，靠近接收器的接收器对地面反射更敏感，而遮挡链路由于主要的散射效应而表现出均匀的角度特性，走廊环境则产生不对称的功率分布。

Conclusion: 本研究结果表明，低高度传播的特点是发射器高度与地面散射机制之间存在复杂的相互作用，为了新兴的中频段通信系统提供了渠道模型的基本见解。

Abstract: In this paper, we present detailed low-altitude channel measurements at the
FR3 band in an outdoor campus environment. Using a time-domain channel sounder
system, we conduct two types of measurements: path loss measurements by moving
the transmitter (Tx) at one-meter intervals along a 26-point rooftop path, and
directional power angular spectrum measurements through antenna scanning at
half-power beam width intervals. The path loss analysis across different Rx
shows that the close-in model outperforms conventional 3GPP models and
height-corrected variants, with path loss exponents close to free space values
indicating line-of-sight dominance. The power angular spectrum measurements
show that propagation behavior varies significantly with environmental
conditions. Closer Rx exhibit stronger sensitivity to ground reflections during
downward Tx tilting, while obstructed links display uniform angular
characteristics due to dominant scattering effects, and corridor environments
produce asymmetric power distributions. These results indicate that
low-altitude propagation is characterized by complex interactions between Tx
height and ground scattering mechanisms, providing fundamental insights for
channel modeling in emerging mid-band communication systems.

</details>


### [341] [Joint UAV Placement and Transceiver Design in Multi-User Wireless Relay Networks](https://arxiv.org/abs/2507.11912)
*Tzu-Hsuan Chou,Nicolo Michelusi,David J. Love,James V. Krogmeier*

Main category: eess.SP

TL;DR: 该论文提出了一种优化无人机中继位置和收发器设计的方法，以提高非正交多用户无线中继网络中用户的最小 SINR。所提出的方法在 SINR 方面比现有方案有显著提高。


<details>
  <summary>Details</summary>
Motivation: 为了提高非正交多用户无线中继网络中用户的最小信噪比（SINR），通过优化无人机（UAV）中继的位置、中继波束形成和接收组合。

Method: 该方法将设计分为两个问题：波束形成感知无人机位置优化和用于最小化信噪比最大化的收发器设计。利用大规模 MIMO 基站的窄波束特性，推导了期望波束形成信噪比的近似值，并提出了一种无人机位置算法，以使用差值凸框架来提供改进最小期望波束形成信噪比的用户位置。随后，在将无人机中继部署到优化位置并提供估计的 CSI 后，提出了一种联合中继波束形成和接收组合（JRBC）算法，以使用块坐标下降方法优化收发器以改进最小波束形成信噪比。

Result: 数值结果表明，所提出的无人机位置算法结合 JRBC 算法，与最先进的方案相比，SINR 提高了 4.6 dB。

Conclusion: 所提出的无人机位置算法结合联合中继波束形成和接收组合（JRBC）算法，与最先进的方案相比，SINR 提高了 4.6 dB。

Abstract: In this paper, a novel approach is proposed to improve the minimum
signal-to-interference-plus-noise-ratio (SINR) among users in non-orthogonal
multi-user wireless relay networks, by optimizing the placement of unmanned
aerial vehicle (UAV) relays, relay beamforming, and receive combining. The
design is separated into two problems: beamforming-aware UAV placement
optimization and transceiver design for minimum SINR maximization. A
significant challenge in beamforming-aware UAV placement optimization is the
lack of instantaneous channel state information (CSI) prior to deploying UAV
relays, making it difficult to derive the beamforming SINR in non-orthogonal
multi-user transmission. To address this issue, an approximation of the
expected beamforming SINR is derived using the narrow beam property of a
massive MIMO base station. Based on this, a UAV placement algorithm is proposed
to provide UAV positions that improve the minimum expected beamforming SINR
among users, using a difference-of-convex framework. Subsequently, after
deploying the UAV relays to the optimized positions, and with estimated CSI
available, a joint relay beamforming and receive combining (JRBC) algorithm is
proposed to optimize the transceiver to improve the minimum beamforming SINR
among users, using a block-coordinate descent approach. Numerical results show
that the UAV placement algorithm combined with the JRBC algorithm provides a
4.6 dB SINR improvement over state-of-the-art schemes.

</details>


### [342] [Scene Graph-Aided Probabilistic Semantic Communication for Image Transmission](https://arxiv.org/abs/2507.11913)
*Chen Zhu,Siyun Liang,Zhouxiang Zhao,Jianrong Bao,Zhaohui Yang,Zhaoyang Zhang,Dusit Niyato*

Main category: eess.SP

TL;DR: 提出了一种基于概率图的语义通信框架，用于无线图像传输，通过两阶段压缩和多轮语义压缩算法提高传输效率和语义对齐。


<details>
  <summary>Details</summary>
Motivation: 语义通信旨在传输意义而非原始符号，为缓解网络拥塞和提高传输效率提供了有前景的解决方案。

Method: 提出了一种无线图像通信框架，使用概率图作为分布式用户的共享语义知识库。通过场景图表示高层图像语义，并设计了一种两阶段压缩算法，利用学习到的条件和共现概率去除可预测的成分。在发射端，该算法过滤冗余的关系和实体对；在接收端，语义恢复利用相同的概率图重建被省略的信息。此外，还提出了一种具有理论性能分析的多轮语义压缩算法。

Result: 仿真结果表明，所提出的语义感知方案实现了优越的传输吞吐量和可观的语义对齐，验证了利用高层语义进行图像通信的有效性。

Conclusion: 所提出的语义感知方案通过利用高层语义实现了优越的传输吞吐量和可观的语义对齐，验证了其有效性。

Abstract: Semantic communication emphasizes the transmission of meaning rather than raw
symbols. It offers a promising solution to alleviate network congestion and
improve transmission efficiency. In this paper, we propose a wireless image
communication framework that employs probability graphs as shared semantic
knowledge base among distributed users. High-level image semantics are
represented via scene graphs, and a two-stage compression algorithm is devised
to remove predictable components based on learned conditional and co-occurrence
probabilities. At the transmitter, the algorithm filters redundant relations
and entity pairs, while at the receiver, semantic recovery leverages the same
probability graphs to reconstruct omitted information. For further research, we
also put forward a multi-round semantic compression algorithm with its
theoretical performance analysis. Simulation results demonstrate that our
semantic-aware scheme achieves superior transmission throughput and satiable
semantic alignment, validating the efficacy of leveraging high-level semantics
for image communication.

</details>


### [343] [STFT-based Time-Frequency Mode Decomposition: A Fast and Robust Method for Multicomponent Signal Analysis](https://arxiv.org/abs/2507.11919)
*Wei Zhou,Wei-Jian Li,Wei-Xin Ren*

Main category: eess.SP

TL;DR: TFMD是一种新颖的信号分解框架，通过将信号分解视为时频域的图像分割任务，实现了快速、鲁棒和自适应的分解，并在准确性、计算效率和对不同信号类型的适应性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有信号分解方法在准确性、计算成本和先验信息（如模式数量）需求之间存在权衡，而TFMD旨在提供一种快速、鲁棒且自适应的分解方法。

Method: TFMD将信号分解重构为时频域中的图像分割任务。首先将信号转换为频谱图，然后通过平滑处理来增强高能区域的连续性。接着采用一系列自适应阈值处理和基于连通组件标记的尺寸过滤来自动分割频谱图并为每个模式生成掩码。最后通过短时傅里叶逆变换来重构模式。

Result: TFMD能够准确确定模式数量并以高保真度重构模式，在强噪声条件下表现尤为出色。与现有方法相比，TFMD在更广泛的信号类型上表现出鲁棒且有竞争力的性能，并且由于其非迭代设计，具有更高的计算效率。该方法还成功应用于真实世界的桥梁振动信号分析。

Conclusion: TFMD提供了一个计算高效且强大的多组分信号分析范式，在准确性、多功能性和效率方面取得了令人信服的平衡，适用于大规模或时间敏感的应用。

Abstract: The decomposition of complex, multicomponent, and non-stationary signals into
their constituent modes is a fundamental yet significant challenge in science
and engineering. Existing methods often struggle with a trade-off among
accuracy, computational cost, and the need for prior information such as the
number of modes. This paper introduces time-frequency mode decomposition
(TFMD), a novel framework for the fast, robust, and adaptive decomposition of
such signals. TFMD operates on the principle that modes form contiguous
high-energy regions in the time-frequency domain. Its non-iterative pipeline
reframes signal decomposition as an image segmentation task: a signal is
transformed into a spectrogram, which is then smoothed to enhance the
continuity of these high-energy regions. A sequence of adaptive thresholding
and connected-component labeling with size-based filtering is then employed to
automatically segment the spectrogram and generate a mask for each mode. The
modes are finally reconstructed via the inverse short-time Fourier transform.
Validation on diverse synthetic signals demonstrates that TFMD accurately
determines the number of modes and reconstructs them with high fidelity. Its
performance is particularly strong in high-noise conditions. A comparative
analysis confirms that TFMD provides robust, competitive performance across a
wider variety of signal types, while a theoretical complexity analysis reveals
its superior computational efficiency stemming from its non-iterative design.
The method's practical utility is further demonstrated by successfully
extracting modal responses from a real-world footbridge vibration signal. TFMD
provides a computationally efficient and powerful paradigm for multicomponent
signal analysis, offering a compelling balance of accuracy, versatility, and
efficiency for large-scale or time-sensitive applications.

</details>


### [344] [DSSD: Efficient Edge-Device Deployment and Collaborative Inference via Distributed Split Speculative Decoding](https://arxiv.org/abs/2507.12000)
*Jiahong Ning,Ce Zheng,Tingting Yang*

Main category: eess.SP

TL;DR: DSSD是一种在设备边缘系统部署LLM的新方法，通过在设备和边缘之间分配验证任务来提高效率，降低通信成本，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型（LLMs）在设备边缘系统部署的资源限制和通信开销问题，同时克服现有解决方案在推理准确性和延迟或候选词元验证的上行传输成本之间进行权衡的缺点。

Method: 提出了一种名为分布式分裂推测解码（DSSD）的新型架构，该架构保持了SLM-LLM的划分，并将验证阶段在设备和边缘之间进行了划分。

Result: 实验表明，DSSD相比现有方法表现更优。

Conclusion: DSSD通过在设备和边缘之间划分验证阶段，用单一下行传输替换了多个词汇分布的上行传输，显著降低了通信延迟，同时保持了推理质量，优于现有方法。

Abstract: Large language models (LLMs) have transformed natural language processing but
face critical deployment challenges in device-edge systems due to resource
limitations and communication overhead. To address these issues, collaborative
frameworks have emerged that combine small language models (SLMs) on devices
with LLMs at the edge, using speculative decoding (SD) to improve efficiency.
However, existing solutions often trade inference accuracy for latency or
suffer from high uplink transmission costs when verifying candidate tokens. In
this paper, we propose Distributed Split Speculative Decoding (DSSD), a novel
architecture that not only preserves the SLM-LLM split but also partitions the
verification phase between the device and edge. In this way, DSSD replaces the
uplink transmission of multiple vocabulary distributions with a single downlink
transmission, significantly reducing communication latency while maintaining
inference quality. Experiments show that our solution outperforms current
methods, and codes are at:
https://github.com/JasonNing96/DSSD-Efficient-Edge-Computing

</details>


### [345] [Enhancing Situational Awareness in ISAC Networks via Drone Swarms: A Real-World Channel Sounding Data Set](https://arxiv.org/abs/2507.12010)
*Julia Beuster,Carsten Andrich,Sebastian Giehl,Marc Miranda,Lorenz Mohr,Dieter Novotny,Tom Kaufmann,Christian Schneider,Reiner Thomä*

Main category: eess.SP

TL;DR: 该论文介绍了用于6G ISAC网络的无人机群多静态雷达数据集，用于物体感知和跟踪，支持真实世界环境下的算法开发。


<details>
  <summary>Details</summary>
Motivation: 随着6G移动网络中集成传感与通信（ISAC）和无人机（UAV）等用户设备（UE）能力的提升，通过多静态雷达传感在网状ISAC网络中增强态势感知具有重大意义。

Method: 通过包含多达四架无人机的测试平台，利用同步的分布式地面传感器节点和飞行传感器节点，采集了真实世界的信道探测数据，以感知多径环境中的各种物体（如停放的汽车、垂直起降飞行器和小型无人机）的双静态反射率。

Result: 展示了利用协同无人机群在空对空（A2A）和空对地（A2G）场景中进行多静态雷达跟踪和定位的潜力，并提供了公开的数据集以支持未来ISAC算法在真实环境中的开发和验证。

Conclusion: 该论文提出了一个包含无人机群的多静态雷达传感数据集，旨在推动6G网6G网络中集成传感与通信（ISAC）技术的发展，并通过多静态雷达感知提升态势感知能力。

Abstract: With the upcoming capabilities of integrated sensing and communication (ISAC)
and the incorporation of user equipment (UE) like unmanned aerial vehicles
(UAVs) in 6G mobile networks, there is a significant opportunity to enhance
situational awareness through multi-static radar sensing in meshed ISAC
networks. This paper presents a real-world channel sounding data set acquired
using a testbed with synchronized, distributed ground-based sensor nodes and
flying sensor nodes within a swarm of up to four drones. The conducted
measurement campaign is designed to sense the bi-static reflectivity of objects
such as parking cars, vertical take-off and landing (VTOL) aircraft, and small
drones in multi-path environments. We detail the rationale behind the selection
of the included scenarios and the configuration of the participating nodesand
present exemplary results to demonstrate the potential of using collaborating
drone swarms for multi-static radar tracking and localization in air-to-air
(A2A) and air-to-ground (A2G) scenarios. The data sets are publicly available
to support the development and validation of future ISAC algorithms in
real-world environments rather than relying solely on simulation.

</details>


### [346] [DoRF: Doppler Radiance Fields for Robust Human Activity Recognition Using Wi-Fi](https://arxiv.org/abs/2507.12132)
*Navid Hasanzadeh,Shahrokh Valaee*

Main category: eess.SP

TL;DR: 提出了一种基于 NeRF 的新方法，利用 Wi-Fi CSI 来创建多普勒辐射场（DoRF），以提高人类活动识别的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管现有的基于 Wi-Fi CSI 的人类活动识别（HAR）方法取得了进展，但在实际部署中的泛化能力仍然不足。

Method: 提出了一种新方法，从一维多普勒速度投影中重建三维运动的潜在表示，并构建了一个统一的多普勒辐射场（DoRF），以提供活动的全貌并提高对环境变化的鲁棒性。

Result: 所提出的方法显著提高了 Wi-Fi HAR 的泛化准确性。

Conclusion: Wi-Fi CSI 的新方法 DoRFs 显著提高了基于 Wi-Fi 的人类活动识别（HAR）的泛化能力，为实际传感应用展示了巨大潜力。

Abstract: Wi-Fi Channel State Information (CSI) has gained increasing interest for
remote sensing applications. Recent studies show that Doppler velocity
projections extracted from CSI can enable human activity recognition (HAR) that
is robust to environmental changes and generalizes to new users. However,
despite these advances, generalizability still remains insufficient for
practical deployment. Inspired by neural radiance fields (NeRF), which learn a
volumetric representation of a 3D scene from 2D images, this work proposes a
novel approach to reconstruct an informative 3D latent motion representation
from one-dimensional Doppler velocity projections extracted from Wi-Fi CSI. The
resulting latent representation is then used to construct a uniform Doppler
radiance field (DoRF) of the motion, providing a comprehensive view of the
performed activity and improving the robustness to environmental variability.
The results show that the proposed approach noticeably enhances the
generalization accuracy of Wi-Fi-based HAR, highlighting the strong potential
of DoRFs for practical sensing applications.

</details>


### [347] [A Practical Analysis: Understanding Phase Noise Modelling in Time and Frequency Domain for Phase-Locked Loops](https://arxiv.org/abs/2507.12146)
*Carl Collmann,Bitan Banerjee,Ahmad Nimr,Gerhard Fettweis*

Main category: eess.SP

TL;DR: 本研究提出了一种针对SDR设备的相位噪声建模方法，并以USRPX310为例进行了验证。该方法通过测量数据提取关键的锁相环性能参数，并建立了一个可用于分析相位噪声对MIMO系统影响的参数化模型。


<details>
  <summary>Details</summary>
Motivation: MIMO系统中的相位噪声会严重影响性能，尤其是在需要相位同步的应用中。对于使用SDR设备构建的MIMO测试平台，相位噪声的影响不容忽视，特别是在采用数字波束形成的MIMO系统中，精确的相位对齐至关重要。因此，对SDR设备的相位噪声进行精确建模至关重要，但现有SDR设备的数据手册信息不足以进行全面的相位噪声性能表征。

Method: 提出了一种实用的相位噪声建模方法，该方法基于测量数据，推导了关键的锁相环（PLL）性能指标（如周期抖动、振荡器常数和PLL带宽）的估计值，并提出了一个PLL电路相位噪声功率谱密度的参数化模型，同时提供了参数估计。

Result: 基于测量数据，推导了关键的锁相环（PLL）性能指标，如周期抖动、振荡器常数和PLL带宽的估计值。提出了一个PLL电路相位噪声功率谱密度的参数化模型，并提供了相应的参数估计。该模型可用于进一步研究相位噪声对使用类似SDR设备实现的MIMO系统性能的影响。

Conclusion: 该研究提出了一个应用于USRPX310系列SDR的实用相位噪声建模方法。基于测量数据，研究推导了诸如周期抖动、振荡器常数和锁相环带宽等关键锁相环性能指标的估计值。此外，研究提出了一个锁相环电路相位噪声功率谱密度的参数化模型，并提供了相应的参数估计。

Abstract: In MIMO systems, the presence of phase noise is a significant factor that can
degrade performance. For MIMO testbeds build from SDR devices, phase noise
cannot be ignored, particular in applications that require phase
synchronization. This is especially relevant in MIMO systems that employ
digital beamforming, where precise phase alignment is crucial. Accordingly,
accurate phase noise modelling of SDR devices is essential. However, the
information provided in data sheets for different SDR models varies widely and
is often insufficient for comprehensive characterization of their phase noise
performance. While numerical simulations of PLL phase noise behavior are
documented in the literature, there is a lack of extensive measurements
supported by appropriate system modelling. In this work, we present a practical
phase noise modeling methodology applied to an SDR from the USRP X310 series.
Based on measurement data, we derive estimates of key PLL performance
indicators such as cycle-to-cycle jitter, oscillator constants, and PLL
bandwidth. Furthermore, we propose a parametric model for the phase noise PSD
of the PLL circuit and provide corresponding parameter estimates. This model
can be used for further investigation into the impact of phase noise on MIMO
system performance implemented by similar SDR devices.

</details>


### [348] [PAPR of DFT-s-OTFS with Pulse Shaping](https://arxiv.org/abs/2507.12210)
*Jialiang Zhu,Sanoopkumar P. S.,Arman Farhang*

Main category: eess.SP

TL;DR: DFT-s-OTFS通过DFT扩展缓解了OTFS在高 dolayı情况下的PAPR问题。交织分配比块分配效果更好，RRC脉冲比矩形脉冲PAPR更高。DFT-s-OTFS的BER性能与OTFS相当。


<details>
  <summary>Details</summary>
Motivation: 解决OTFS在大多普勒单元数下PAPR过高的问题。

Method: 通过推导DFT-s-OTFS在不同脉冲整形滤波器和资源分配策略下的PAPR上限，并进行仿真验证。

Result: 推导了交织和块两种都卜勒资源分配方案下的DFT-s-OTFS的PAPR上限。交织分配方案比块分配方案具有更低的PAPR。

Conclusion: DFT-s-OTFS在交织分配方案下可以获得比块分配方案更低的PAPR，并且可以产生周期性的时域信号，从而简化发射机设计。与矩形脉冲相比，RRC脉冲通常会导致更高的最大PAPR。DFT-s-OTFS在BER性能上与未进行DFT扩展的OTFS相当。

Abstract: Orthogonal Time Frequency Space (OTFS) suffers from high peak-to-average
power ratio (PAPR) when the number of Doppler bins is large. To address this
issue, a discrete Fourier transform spread OTFS (DFT-s-OTFS) scheme is employed
by applying DFT spreading across the Doppler dimension. This paper presents a
thorough PAPR analysis of DFT-s-OTFS in the uplink scenario using different
pulse shaping filters and resource allocation strategies. Specifically, we
derive a PAPR upper bound of DFT-s-OTFS with interleaved and block Doppler
resource allocation schemes. Our analysis reveals that DFT-s-OTFS with
interleaved allocation yields a lower PAPR than that of block allocation.
Furthermore, we show that interleaved allocation produces a periodic
time-domain signal composed of repeated quadrature amplitude modulated (QAM)
symbols which simplifies the transmitter design. Based on our analytical
results, the root raised cosine (RRC) pulse generally results in a higher
maximum PAPR compared to the rectangular pulse. Simulation results confirm the
validity of the derived PAPR upper bounds. Furthermore, we also demonstrate
through BER simulation analysis that the DFT-s-OTFS gives the same performance
as OTFS without DFT spreading.

</details>


### [349] [Cell Sensing: Traffic detection](https://arxiv.org/abs/2507.12211)
*Saúl Fenollosa*

Main category: eess.SP

TL;DR: 本研究提出了一种利用LTE信号进行交通监控的被动传感系统，证明了其可行性，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 提出一种使用环境LTE信号的被动传感系统，作为传统监控方法的一种非侵入式且可扩展的替代方案。

Method: 提出一种利用环境LTE信号的被动传感系统，采用双接收器架构分析CSI以隔离由移动目标引起的差分多普勒频移，从而克服硬件相位损伤。

Result: 在室内测试中，该系统在6000毫米/分钟以上的速度下实现了超过90%的检测准确率，并在室外评估中可靠地估计了行人和车辆的速度。

Conclusion: LTE信号可作为一种可行的交通监控方法，未来研究方向包括AoA集成、机器学习和实时嵌入式系统开发。

Abstract: This work presents a passive sensing system for traffic monitoring using
ambient Long Term Evolution (LTE) signals as a non-intrusive and scalable
alternative to traditional surveillance methods. The approach employs a
dual-receiver architecture analyzing Channel State Information (CSI) to isolate
differential Doppler shifts induced by moving targets, effectively mitigating
hardware-induced phase impairments. Implemented with a Software Defined Radio
(SDR) platform and srsRAN software, the system demonstrated over 90% detection
accuracy for speeds above 6000 mm/min in controlled indoor tests, and provided
reliable speed estimations for pedestrians and vehicles in outdoor evaluations.
Despite challenges at low speeds, directional ambiguity, and multipath fading
in urban settings, the results validate LTE-based passive sensing as a feasible
traffic monitoring method, identifying critical areas for future research such
as angle-of-arrival (AoA) integration, machine learning, and real-time embedded
system development.

</details>


### [350] [Novel Approach to Dual-Channel Estimation in Integrated Sensing and Communications for 6G](https://arxiv.org/abs/2507.12221)
*Alejandro Castilla,Saúl Fenollosa,Monika Drozdowska,Alejandro Lopez-Escudero,Sergio Micò-Rosa,Narcis Cardona*

Main category: eess.SP

TL;DR: 本研究提出了一种用于毫米波雷达ISAC的双通道模型，通过干扰提取、信道分析等方法提取感知和通信信道，并在实验中得到验证，为6G ISAC系统设计提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 为了满足6G对环境数据感知与通信融合的需求，理解和建模ISAC系统至关重要，特别是双通道模型在毫米波雷达ISAC中的应用。

Method: 本研究提出了一系列用于ISAC双通道模型的方法，包括干扰提取、模块和相位相关性分析、chirp聚类以及自杂波缩减，以从单站测量中提取双站感知信道并进行通信信道估计。

Result: 实验结果表明，所提出的技术能够成功提取和验证感知和通信信道，通过均方根延迟扩展（RMS DS）、功率延迟剖面（PDP）和到达角（AoA）分析得到验证，并且与RT模拟结果一致。

Conclusion: 该研究通过在消声室中进行实验，并与射线追踪（RT）模拟进行比较，成功地提取和验证了双通道模型，证明了其在毫米波雷达ISAC中的有效性，为未来网络的完全集成感知和通信提供了创新途径。

Abstract: Integrated Sensing and Communication (ISAC) design is crucial for 6G and
harmonizes environmental data sensing with communication, emphasizing the need
to understand and model these elements. This paper delves into dual-channel
models for ISAC, employing channel extraction techniques to validate and
enhance accuracy. Focusing on millimeter wave (mmWave) radars, it explores the
extraction of the bistatic sensing channel from monostatic measurements and
subsequent communication channel estimation. The proposed methods involve
interference extraction, module and phase correlation analyses, chirp
clustering, and auto-clutter reduction. A comprehensive set-up in an anechoic
chamber with controlled scenarios evaluates the proposed techniques,
demonstrating successful channel extraction and validation through Root Mean
Square Delay Spread (RMS DS), Power Delay Profile (PDP), and Angle of Arrival
(AoA) analysis. Comparison with Ray-Tracing (RT) simulations confirms the
effectiveness of the proposed approach, presenting an innovative stride towards
fully integrated sensing and communication in future networks.

</details>


### [351] [Frequency-responsive RCS characteristics and scaling implications for ISAC development](https://arxiv.org/abs/2507.12235)
*Saúl Fenollosa,Monika Drozdowska,Wenfei Yang,Sergio Micó-Rosa,Alejandro Castilla,Alejandro Lopez-Escudero,Jian Li,Narcis Cardona*

Main category: eess.SP

TL;DR: This paper analyzes how Radar Cross-Section (RCS) changes with frequency for different targets (AGV, pedestrian, car) in FR2/FR3 bands. It uses background subtraction and time-domain gating for measurement. Findings show RCS varies with frequency, shape, material, and geometry, which is important for 6G sensing and communication systems.


<details>
  <summary>Details</summary>
Motivation: The objective was to analyze how Radar Cross-Section (RCS) properties vary with frequency for targets such as an AGV, a pedestrian, and a car, providing insights for advancing sensing systems and 3GPP channel models, particularly for Integrated Sensing and Communications (ISAC) techniques proposed for 6G standards.

Method: The methodology involved background subtraction and time-domain gating to extract RCS, measuring targets like an AGV, pedestrian, and car in FR2 and FR3 frequency bands across indoor and outdoor environments. The analysis compared RCS values and the distribution of greatest contribution points based on range response across different bands.

Result: Measurements were taken in FR2 and FR3 bands for various targets in diverse environments. The analysis compared RCS values and their distribution across different bands based on range response. Results showed how RCS values change with frequency and target shape, indicating that scaling RCS values based on frequency and geometry is complex and varies among different materials and shapes.

Conclusion: The paper demonstrates that RCS values change with frequency and target shape, highlighting the complexity of scaling RCS values based on frequency and geometry across different materials and shapes. These findings are crucial for improving sensing systems and 3GPP channel models for ISAC in 6G.

Abstract: This paper presents an investigation on the Radar Cross-Section (RCS) of
various targets, with the objective of analysing how RCS properties vary with
frequency. Targets such as an Automated Guided Vehicle (AGV), a pedestrian, and
a full-scale car were measured in the frequency bands referred to in industry
standards as FR2 and FR3. Measurements were taken in diverse environments,
indoors and outdoors, to ensure comprehensive scenario coverage. The
methodology employed in RCS extraction performs background subtraction,
followed by time-domain gating to isolate the influence of the target. This
analysis compares the RCS values and how the points of greatest contribution
are distributed across different bands based on the range response of the RCS.
Analysis of the results demonstrated how RCS values change with frequency and
target shape, providing insights into the electromagnetic behaviour of these
targets. Key findings highlight how much scaling RCS values based on frequency
and geometry is complex and varies among different types of materials and
shapes. These insights are instrumental for advancing sensing systems and
enhancing 3GPP channel models, particularly for Integrated Sensing and
Communications (ISAC) techniques proposed for 6G standards.

</details>


### [352] [Leveraging Bi-Directional Channel Reciprocity for Robust Ultra-Low-Rate Implicit CSI Feedback with Deep Learning](https://arxiv.org/abs/2507.12301)
*Zhenyu Liu,Yi Ma,Rahim Tafazolli,Zhi Ding*

Main category: eess.SP

TL;DR: 通过引入双向相关性增强和输入格式对齐模块，Dual-ImRUNet框架实现了超低比特率的隐式CSI反馈，并提高了环境鲁棒性，显著减少了反馈开销。


<details>
  <summary>Details</summary>
Motivation: 现有的基于深度学习的隐式CSI反馈方法在超低比特率场景下性能会下降，并且在不同环境之间适应性较差。

Method: 提出了一种名为Dual-ImRUNet的双向隐式信道状态信息（CSI）反馈框架。该框架包含两个新的即插即用预处理模块：1.双向相关性增强模块，用于增强上下行链路CSI特征向量矩阵之间的相关性，通过将高度相关的上下行链路信道矩阵投影到各自的特征空间来减少冗余，以实现超低比特率反馈。2.输入格式对齐模块，用于在不增加额外传输开销的情况下，保持编解码器两侧数据分布的一致性，增强对环境变化的鲁棒性。最后，开发了一个基于Transformer的隐式CSI反馈网络，利用角度-延迟域稀疏性和双向相关性进行超低比特率CSI压缩。

Result: 仿真结果表明，与现有最先进的方法相比，反馈开销减少了85%，并且在未知的环境中也具有鲁棒性。

Conclusion: 该研究提出的Dual-ImRUNet框架在超低比特率和环境鲁棒性方面表现出色，能够将反馈开销减少85%，并能适应未知的环境。

Abstract: Deep learning-based implicit channel state information (CSI) feedback has
been introduced to enhance spectral efficiency in massive MIMO systems.
Existing methods often show performance degradation in ultra-low-rate scenarios
and inadaptability across diverse environments. In this paper, we propose
Dual-ImRUNet, an efficient uplink-assisted deep implicit CSI feedback framework
incorporating two novel plug-in preprocessing modules to achieve ultra-low
feedback rates while maintaining high environmental robustness. First, a novel
bi-directional correlation enhancement module is proposed to strengthen the
correlation between uplink and downlink CSI eigenvector matrices. This module
projects highly correlated uplink and downlink channel matrices into their
respective eigenspaces, effectively reducing redundancy for ultra-low-rate
feedback. Second, an innovative input format alignment module is designed to
maintain consistent data distributions at both encoder and decoder sides
without extra transmission overhead, thereby enhancing robustness against
environmental variations. Finally, we develop an efficient transformer-based
implicit CSI feedback network to exploit angular-delay domain sparsity and
bi-directional correlation for ultra-low-rate CSI compression. Simulation
results demonstrate successful reduction of the feedback overhead by 85%
compared with the state-of-the-art method and robustness against unseen
environments.

</details>


### [353] [Road Roughness Estimation via Fusion of Standard Onboard Automotive Sensors](https://arxiv.org/abs/2507.12317)
*Martin Agebjär,Gustav Zetterqvist,Fredrik Gustafsson,Johan Wahlström,Gustaf Hendeby*

Main category: eess.SP

TL;DR: A KF-based method estimates road roughness (IRI) using inertial and speed data. It’s cost-effective but less accurate with only lateral vibrations.


<details>
  <summary>Details</summary>
Motivation: To provide a cost-effective solution for pavement monitoring by estimating road roughness using vehicle vibrations and speed measurements.

Method: A Kalman filter (KF)-based method is introduced to estimate road roughness (IRI) by fusing inertial and speed measurements. The method involves system identification on a physical vehicle to estimate model parameters, followed by KF-based reconstruction of the longitudinal road profile to compute IRI values.

Result: Validation on 230 km of real-world data shows IRI estimation errors between 1% and 10% of reference values. Accuracy significantly decreases when using only lateral vibrations.

Conclusion: KF-based estimation shows potential for efficient road roughness monitoring, but accuracy is limited when using only lateral vibrations.

Abstract: Road roughness significantly affects vehicle vibrations and ride quality. We
introduce a Kalman filter (KF)-based method for estimating road roughness in
terms of the international roughness index (IRI) by fusing inertial and speed
measurements, offering a cost-effective solution for pavement monitoring. The
method involves system identification on a physical vehicle to estimate
realistic model parameters, followed by KF-based reconstruction of the
longitudinal road profile to compute IRI values. It explores IRI estimation
using vertical and lateral vibrations, the latter more common in modern
vehicles. Validation on 230 km of real-world data shows promising results, with
IRI estimation errors ranging from 1% to 10% of the reference values. However,
accuracy deteriorates significantly when using only lateral vibrations,
highlighting their limitations. These findings demonstrate the potential of
KF-based estimation for efficient road roughness monitoring.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [354] [A Deep Reinforcement Learning Method for Multi-objective Transmission Switching](https://arxiv.org/abs/2507.11726)
*Ding Lin,Jianhui Wang,Tianqiao Zhao,Meng Yue*

Main category: eess.SY

TL;DR: 使用DRL方法进行多目标输电潮流开关，以平衡成本和可靠性。


<details>
  <summary>Details</summary>
Motivation: 为了平衡成本节约和可靠性提高，但随着系统规模的增长，由于固有的非线性和高计算需求，获得可行的解决方案变得极其困难。

Method: 提出了一种深度强化学习（DRL）方法，采用基于对决的Actor-Critic框架来评估动作空间中每个线路切换决策的相对影响。

Result: 所提出的DRL方法能够提高决策质量，从而提高系统可靠性和成本效益。

Conclusion: DRL方法在多目标输电潮流开关问题上有效且高效，相比于基准DRL算法。

Abstract: Transmission switching is a well-established approach primarily applied to
minimize operational costs through strategic network reconfiguration. However,
exclusive focus on cost reduction can compromise system reliability. While
multi-objective transmission switching can balance cost savings with
reliability improvements, feasible solutions become exceedingly difficult to
obtain as system scale grows, due to the inherent nonlinearity and high
computational demands involved. This paper proposes a deep reinforcement
learning (DRL) method for multi-objective transmission switching. The method
incorporates a dueling-based actor-critic framework to evaluate the relative
impact of each line switching decision within the action space, which improves
decision quality and enhances both system reliability and cost efficiency.
Numerical studies on the IEEE 118-bus system verify the effectiveness and
efficiency of the proposed approach compared to two benchmark DRL algorithms.

</details>


### [355] [Reconfigurable Battery Systems for Enhanced Fast Charging in Electric Vehicles](https://arxiv.org/abs/2507.11749)
*Jonathan Olivares,Tyler Depe,Rakeshkumar Mahto*

Main category: eess.SY

TL;DR: This paper investigates reconfigurable battery systems to reduce EV charging times, proposing new configurations and using simulations to show that increased series connections can speed up charging safely, improving EV accessibility and sustainability.


<details>
  <summary>Details</summary>
Motivation: Prolonged charging times for electric vehicles (EVs) are a significant barrier to widespread adoption, particularly for those without access to fast charging infrastructure.

Method: The paper proposes innovative battery pack configurations that dynamically adjust the arrangement of cells to optimize charging performance. Simulations were conducted using MATLAB and Simulink to compare the efficiency of various battery configurations, focusing on charging times, state of charge (SOC), voltage, and current under different conditions.

Result: Connecting more batteries in series through reconfigurability in battery packs can significantly reduce charging times while maintaining operational safety.

Conclusion: The study shows that reconfigurable battery designs can offer a practical solution for faster, more efficient home-based EV charging, making EV ownership more accessible and sustainable.

Abstract: The adoption of electric vehicles (EVs) is rapidly growing as a key solution
to reducing greenhouse gas emissions. However, prolonged charging times remain
a significant barrier to widespread EV usage, especially for individuals
without access to fast charging infrastructure. This paper explores the
potential of reconfigurable battery systems to reduce EV charging times without
compromising battery life. We propose innovative battery pack configurations
that dynamically adjust the arrangement of cells to optimize charging
performance. Simulations were conducted using MATLAB and Simulink to compare
the efficiency of various battery configurations, focusing on charging times,
state of charge (SOC), voltage, and current under different conditions. The
results demonstrate that connecting more batteries in series through
reconfigurability in battery packs can significantly reduce charging times
while maintaining operational safety. This study offers insights into how
reconfigurable battery designs can provide a practical solution for faster,
more efficient home-based EV charging, making EV ownership more accessible and
sustainable.

</details>


### [356] [Mobility Extraction and Analysis of GaN HEMTs for RF Applications Using TCAD and Experimental Data](https://arxiv.org/abs/2507.11849)
*Tanjim Rahman*

Main category: eess.SY

TL;DR: 本研究通过TCAD仿真和实验分析了GaN HEMT器件，展示了其良好的电学性能和高迁移率，为器件设计提供了参考。


<details>
  <summary>Details</summary>
Motivation: 为了深入理解GaN HEMT器件的结构-性能关系，为先进的晶体管设计提供关键依据。

Method: 本研究采用Nextnano仿真软件进行TCAD模拟，以研究2DEG形成和载流子约束，并通过实验表征分析了制造出的GaN HEMT器件的I-V和C-V数据，提取了关键电学参数，如ON/OFF电流比、亚阈值摆幅、DIBL、导通电阻、饱和电压、跨导和场效应迁移率。

Result: 仿真和实验结果显示，器件具有优异的性能，包括高ON/OFF电流比、良好的栅极控制、短沟道抑制以及高达1200 cm2/V.s的峰值场效应迁移率。

Conclusion: 该研究结合了TCAD仿真和实验表征，对GaN HEMT器件进行了全面的分析，揭示了其能带结构、载流子行为以及关键的电学参数，为先进GaN器件的设计提供了深入的见解。

Abstract: This paper presents an analysis of GaN high-electron-mobility transistors
(HEMTs) using both TCAD simulation and experimental characterization. The
energy band structure was studied using Nextnano simulation software to observe
two-dimensional electron gas (2DEG) formation and carrier confinement under
equilibrium conditions. Additionally, I-V and C-V data from fabricated
research-grade GaN HEMTs were analyzed to extract key electrical parameters.
The device demonstrated an ON current of 1.9 mA and an OFF current of 0.01 mA,
indicating a strong ON/OFF current ratio. A subthreshold swing of 80 mV/decade
and a DIBL of 5 mV/V were observed, confirming good gate control and
short-channel suppression. The ON-resistance was 22.72 ohm per micron, with a
saturation voltage of 1 V . The peak transconductance was extracted as 0.18 mS
in the linear region and 0.5 mS in saturation. Field-effect mobility was
calculated using the transconductance method, with a maximum value of
approximately 1200 cm2/V.s at low drain bias. The combined simulation and
experimental approach provided comprehensive insight into GaN HEMT behavior,
enabling a deeper understanding of structure-performance relationships critical
to advanced transistor design.

</details>


### [357] [Algorithm Design and Comparative Test of Natural Gradient Gaussian Approximation Filter](https://arxiv.org/abs/2507.11872)
*Wenhan Cao,Tianyi Zhang,Shengbo Eben Li*

Main category: eess.SY

TL;DR: NANO滤波器通过优化方法避免线性化误差，在非线性系统上优于EKF、UKF等滤波器。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统贝叶斯滤波器中线性化技术（如泰勒展开和随机线性回归）在非线性与非高斯系统上引入的估计误差。

Method: NANO滤波器将贝叶斯滤波解释为两个优化问题的解决方案，定义了最优高斯近似及其极值条件。在预测步，它计算先验分布的前两个矩，等同于矩匹配滤波器；在更新步，采用自然梯度下降法直接最小化更新目标，避免了模型线性化误差。

Result: 通过在阻尼线性振荡器、序列预测、修正增长模型和机器人定位等四个经典系统上进行对比测试，并使用高斯、拉普拉斯和Beta噪声，验证了NANO滤波器处理非线性的能力。此外，通过卫星姿态估计的例子，验证了NANO滤波器对数据异常值的鲁棒性。

Conclusion: NANO滤波器在处理非线性系统时，相比于EKF、UKF、IEKF和PLF等滤波器，在性能上表现更优，同时计算负担相似。

Abstract: Popular Bayes filters typically rely on linearization techniques such as
Taylor series expansion and stochastic linear regression to use the structure
of standard Kalman filter. These techniques may introduce large estimation
errors in nonlinear and non-Gaussian systems. This paper overviews a recent
breakthrough in filtering algorithm design called \textit{N}atural
Gr\textit{a}dient Gaussia\textit{n} Appr\textit{o}ximation (NANO) filter and
compare its performance over a large class of nonlinear filters. The NANO
filter interprets Bayesian filtering as solutions to two distinct optimization
problems, which allows to define optimal Gaussian approximation and derive its
corresponding extremum conditions. The algorithm design still follows the
two-step structure of Bayes filters. In the prediction step, NANO filter
calculates the first two moments of the prior distribution, and this process is
equivalent to a moment-matching filter. In the update step, natural gradient
descent is employed to directly minimize the objective of the update step,
thereby avoiding errors caused by model linearization. Comparative tests are
conducted on four classic systems, including the damped linear oscillator,
sequence forecasting, modified growth model, and robot localization, under
Gaussian, Laplace, and Beta noise to evaluate the NANO filter's capability in
handling nonlinearity. Additionally, we validate the NANO filter's robustness
to data outliers using a satellite attitude estimation example. It is observed
that the NANO filter outperforms popular Kalman filters family such as extended
Kalman filter (EKF), unscented Kalman filter (UKF), iterated extended Kalman
filter (IEKF) and posterior linearization filter (PLF), while having similar
computational burden.

</details>


### [358] [Advantages of Feedback in Distributed Data-Gathering for Accurate and Power-Efficient State-Estimation](https://arxiv.org/abs/2507.11924)
*Hyeongmin Choe,Soojean Han*

Main category: eess.SY

TL;DR: 提出了一种新的分布式数据收集方法FB，并证明其在传感器网络中比NF方法更优越。


<details>
  <summary>Details</summary>
Motivation: 为了在分布式目标跟踪传感器网络中节省通信资源和保证信息准确性，需要有效的数据收集方法。

Method: 提出了一种名为反馈（FB）的分布式数据收集方法，并将其与传统的非反馈（NF）架构进行了比较，评估了在不同架构规范下的可行性和优势。

Result: 通过理论分析和广泛的数值模拟，证明了FB方法的有效性，并得出了FB可行性和优势的条件。

Conclusion: FB方法在通信能力和数据准确性方面都优于NF方法，并且FB可行性取决于通信成本，而FB优势取决于通信延迟。

Abstract: In distributed target-tracking sensor networks, efficient data gathering
methods are necessary to save communication resources and assure information
accuracy. This paper proposes a Feedback (FB) distributed data-gathering method
which lets the central unit feed information back to the mobile sensors; each
sensor then uses it to cancel redundant transmissions and reduce communication
congestion. We rigorously compare its performance, in terms of mean-squared
error (MSE) and cost of power per sensor, against more conventional
Non-Feedback (NF) architectures by evaluating conditions of feasibility and
advantage under different architecture specifications (e.g., communication
delay rate, power cost rate, maximum back-off time, sampling period,
observation noise). Here, we defined the advantage as the performance gain
achieved by FB over NF, while FB is said to be feasible if the advantage region
is nonempty. Our theoretical analyses show that the feasibility of FB depends
more on the communication power cost, while the advantage depends on the
sensors' propagation delay per transmission interval; we derive concrete
conditions under which these outcomes hold. Using extensive numerical
simulations under a variety of settings, we confirm the accuracy of the derived
conditions, and show that our theoretical results hold even for more complex
scenarios where the simplifying assumptions no longer hold.

</details>


### [359] [Towards Ultra-Reliable 6G in-X Subnetworks: Dynamic Link Adaptation by Deep Reinforcement Learning](https://arxiv.org/abs/2507.12031)
*Fateme Salehi,Aamir Mahmood,Sarder Fakhrul Abedin,Kyi Thar,Mikael Gidlund*

Main category: eess.SY

TL;DR: 该研究提出了一种基于DRL的链路自适应框架，通过优化传输功率和块长来减少6G网络中的连续丢包，从而提高URLLC应用的可靠性和能效。


<details>
  <summary>Details</summary>
Motivation: 解决6G网络中URLLC（超可靠低延迟通信）面临的连续丢包问题，该问题可能破坏工业控制和自动化等关键任务的安全。

Method: 采用基于软Actor-Critic（SAC）的深度强化学习（DRL）算法，针对动态信道和干扰条件，联合优化能源效率（EE）和可靠性，以减少连续丢包。

Result: 仿真结果表明，该方法显著优于基线算法，减少了丢包突发，并且在评估场景中仅消耗了全资源分配策略18%的传输成本。

Conclusion: 所提出的基于SAC的DRL方法通过调整传输功率和块长，显著减少了连续丢包事件，同时仅消耗了最大资源分配策略18%的传输成本，并在可靠性和能源效率之间实现了灵活的权衡。

Abstract: 6G networks are composed of subnetworks expected to meet ultra-reliable
low-latency communication (URLLC) requirements for mission-critical
applications such as industrial control and automation. An often-ignored aspect
in URLLC is consecutive packet outages, which can destabilize control loops and
compromise safety in in-factory environments. Hence, the current work proposes
a link adaptation framework to support extreme reliability requirements using
the soft actor-critic (SAC)-based deep reinforcement learning (DRL) algorithm
that jointly optimizes energy efficiency (EE) and reliability under dynamic
channel and interference conditions. Unlike prior work focusing on average
reliability, our method explicitly targets reducing burst/consecutive outages
through adaptive control of transmit power and blocklength based solely on the
observed signal-to-interference-plus-noise ratio (SINR). The joint optimization
problem is formulated under finite blocklength and quality of service
constraints, balancing reliability and EE. Simulation results show that the
proposed method significantly outperforms the baseline algorithms, reducing
outage bursts while consuming only 18\% of the transmission cost required by a
full/maximum resource allocation policy in the evaluated scenario. The
framework also supports flexible trade-off tuning between EE and reliability by
adjusting reward weights, making it adaptable to diverse industrial
requirements.

</details>


### [360] [Distributed Resilient State Estimation and Control with Strategically Implemented Security Measures](https://arxiv.org/abs/2507.12052)
*Takumi Shinohara,Karl H. Johansson,Henrik Sandberg*

Main category: eess.SY

TL;DR: 该研究提出了一种在面对恶意攻击和噪声时，能够平衡成本和弹性的分布式状态估计与控制方法，并通过车辆编队模拟验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在存在恶意虚假数据注入传感器攻击和有界噪声的情况下，研究分布式弹性状态估计与控制问题，并考虑了系统运营商（防御者）为抵御传感器攻击而部署网络安全措施的成本效益问题。

Method: 提出了一种算法来识别最优安全措施，并在某些条件下推导出可高效计算的充分条件，最终开发了一个考虑最优安全措施的分布式弹性状态估计和控制方案。

Result: 证明了通过适当实施安全措施可以最大化系统的弹性，从而使得攻击者无法执行不可检测的传感器攻击，并给出了保证估计和控制误差的有界条件。

Conclusion: 本研究通过数值模拟验证了所提出的分布式弹性状态估计与控制方案的有效性，该方案能够平衡弹性收益与成本效益，并在车辆编队场景下进行了验证。

Abstract: This paper addresses the problem of distributed resilient state estimation
and control for linear time-invariant systems in the presence of malicious
false data injection sensor attacks and bounded noise. We consider a system
operator (defender) capable of deploying cybersecurity measures to counteract
the sensor compromises. Although such measures enhance resilience against
adversarial attacks, they may incur substantial costs; hence, it is crucial to
select countermeasures to balance resilience gains and cost efficiency
strategically. We first demonstrate that the system's resilience against
attacks is maximized through the appropriate implementation of security
measures, implying that no attacker can execute undetectable sensor attacks.
Building on this analysis, we propose an algorithm that identifies the optimal
security measure. While determining this measure is NP-hard in general, we also
derive sufficient conditions under which efficient computation is feasible.
Furthermore, we develop a distributed resilient state estimation and control
scheme informed by the optimal security measure and establish conditions that
guarantee bounded estimation and control errors. Finally, we validate the
efficacy of our approach via numerical simulations of a vehicle platooning
scenario.

</details>


### [361] [Inductance Estimation for High-Power Multilayer Rectangle Planar Windings](https://arxiv.org/abs/2507.12082)
*Theofilos Papadopoulos,Antonios Antonopoulos*

Main category: eess.SY

TL;DR: A new equation estimates inductance for planar windings with high accuracy, validated by simulations and experiments.


<details>
  <summary>Details</summary>
Motivation: To develop a simple and accurate equation for estimating the inductance of Multilayer Rectangle-shaped Planar Windings (MLRPWs) for high-frequency, high-power applications.

Method: Multiple Linear Regression (MLR) was used to generate coefficients for a monomial-like equation based on approximately 6,000 simulated windings, using an 80/20 training/evaluation split.

Result: The equation achieved a mean error of 0% and a standard deviation below 1.8%, with accuracy confirmed on experimental samples both within and outside the initial training dataset.

Conclusion: The proposed monomial-like equation provides a simple and accurate method for estimating the inductance of MLRPWs for high-frequency, high-power applications, with low mean error and standard deviation, confirmed by experimental validation.

Abstract: This paper proposes a simple and accurate monomial-like equation for
estimating the inductance of Multilayer Rectangle-shaped Planar Windings
(MLRPWs) for high-frequency, high-power applications. The equation consists of
the power product of the geometrical dimensions, raised at individual power
coefficients. The coefficients are generated via Multiple Linear Regression
(MLR), based on a large set of approximately 6,000 simulated windings, with an
80/20 training/evaluation sample ratio. The resulting mean error value is 0%,
with a standard deviation below 1.8%. The accuracy of the inductance estimation
is confirmed on several experimental samples, with dimensions both within and
outside the initial training dataset.

</details>


### [362] [Integrated Switched Capacitor Array and Synchronous Charge Extraction with Adaptive Hybrid MPPT for Piezoelectric Harvesters](https://arxiv.org/abs/2507.12163)
*Pramit Karmakar,Siddharth B,Chinmay Murlidhar Kadnur Rao*

Main category: eess.SY

TL;DR: 本研究提出了一个集成了非线性压电模型、同步电荷提取（SECE）、混合最大功率点跟踪（MPPT）和开关电容阵列（SCA）的压电能量收集（PEH）框架，以解决现有PEH技术的挑战。该框架在处理非线性、提高功率输出和适应可变频率输入方面均表现出优越性。


<details>
  <summary>Details</summary>
Motivation: 压电能量收集（PEH）作为一种利用环境振动来收集能量的有前景的技术，在自供电技术和可持续基础设施发展中扮演着重要角色。然而，PEH技术面临着诸如带宽窄、非线性强和阻抗失配等实际挑战。本研究旨在通过提出一个新颖的模拟PEH框架来解决这些问题。

Method: 该研究提出了一种模拟的压电能量收集（PEH）框架，该框架集成了非线性压电模型、同步电荷提取（SECE）、混合最大功率点跟踪（MPPT）和开关电容阵列（SCA）。其中，Bouc-Wen模型用于建立系统的非线性，SECE用于在压电达到机械极值时提取最大电荷，混合MPPT用于改进性能，SCA用于提高系统对可变频率输入的弹性。

Result: 研究表明，所提出的混合MPPT相较于传统的P&O（Perturb and Observe）算法有了显著的改进。此外，经过SCA调整的系统证明了其在面对可变频率输入时具有良好的弹性。

Conclusion: 该研究提出了一个新颖的、模拟的压电能量收集（PEH）框架，该框架旨在解决压电能量收集（PEH）中的非线性、窄带宽和阻抗不匹配等挑战。通过采用非线性压电模型、同步电荷提取（SECE）、混合最大功率点跟踪（MPPT）和开关电容阵列（SCA），该模型能够适应PEH的非线性特性，并在可变频率输入下表现出弹性。

Abstract: Energy Harvesting technologies will play a fundamental role in the
development of the next generation of electronic systems as well as in
advancing the development of sustainable infrastructure. One of the critical
challenges in EH is utilizing ambient vibrations to harvest energy. Piezo
Energy Harvesting, which uses ambient vibrations, is a promising technology in
energy harvesting and a self-powered technology. However, it suffers from
several practical challenges. Some of these challenges include narrow
bandwidth, non-linearity, and impedance mismatch, among others. This paper
presents a novel, simulated Piezo Energy Harvesting (PEH) framework that
addresses some of these challenges. The proposed model is designed to be
adaptive and effective against the inherent non-linearity of PEH. This detailed
model covers a non-linear piezo, Synchronous Electric Charge Extraction (SECE),
Hybrid Maximum Power Point Tracking (MPPT) and a Switched Capacitor Array
(SCA). The SECE extracts the maximum charge accumulated on the piezo every time
the piezo reaches the mechanical extremum. The Bouc-Wen model has been used to
establish nonlinearity in the system. The hybrid MPPT exhibits significant
improvement over conventional P&O, while the SCA-tuned system demonstrates
resilience against variable frequency input.

</details>


### [363] [Learning, fast and slow: a two-fold algorithm for data-based model adaptation](https://arxiv.org/abs/2507.12187)
*Laura Boca de Giuli,Alessio La Bella,Riccardo Scattolini*

Main category: eess.SY

TL;DR: 提出了一种新颖的两级建模架构，结合了慢速（基于集合的模型，具有监测和在线集成）和快速（在线训练的高斯过程）学习组件，以应对数据驱动模型随时间推移和不同不确定性来源的自适应挑战，并在基准能源系统上证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 解决数据驱动模型随时间自适应的挑战，处理由超出范围和范围内的不确定性引起Plant-model mismatch。

Method: 提出了一种新颖的两级建模架构：1. 慢速学习组件：当监测策略认为有必要时，会学习系统在未探索的操作条件下的动态。它包括一个模型集合，其中组合规则根据其训练数据与当前操作条件之间的统计接近度来为单个模型设置权重，以及一个基于统计控制图的监测算法来监督集合的可靠性并在检测到新操作条件时触发新模型的离线训练和集成。2. 快速学习组件：作为一个高斯过程（GP）模型，它在每次迭代时使用最近的数据进行在线训练，同时丢弃旧样本，从而实时补偿慢速学习模型的失配。

Result: 在文献中引用的基准能源系统上测试了所提出的方法，结果表明，与标准的自适应方法相比，慢速和快速学习组件的组合使用提高了模型准确性。

Conclusion: 所提出的方法通过结合慢速和快速学习组件，在处理超出范围和范围内的不确定性方面，比标准的自适应方法提高了模型准确性。

Abstract: This article addresses the challenge of adapting data-based models over time.
We propose a novel two-fold modelling architecture designed to correct
plant-model mismatch caused by two types of uncertainty. Out-of-domain
uncertainty arises when the system operates under conditions not represented in
the initial training dataset, while in-domain uncertainty results from
real-world variability and flaws in the model structure or training process. To
handle out-of-domain uncertainty, a slow learning component, inspired by the
human brain's slow thinking process, learns system dynamics under unexplored
operating conditions, and it is activated only when a monitoring strategy deems
it necessary. This component consists of an ensemble of models, featuring (i) a
combination rule that weights individual models based on the statistical
proximity between their training data and the current operating condition, and
(ii) a monitoring algorithm based on statistical control charts that supervises
the ensemble's reliability and triggers the offline training and integration of
a new model when a new operating condition is detected. To address in-domain
uncertainty, a fast learning component, inspired by the human brain's fast
thinking process, continuously compensates in real time for the mismatch of the
slow learning model. This component is implemented as a Gaussian process (GP)
model, trained online at each iteration using recent data while discarding
older samples. The proposed methodology is tested on a benchmark energy system
referenced in the literature, demonstrating that the combined use of slow and
fast learning components improves model accuracy compared to standard
adaptation approaches.

</details>


### [364] [Neural Co-state Regulator: A Data-Driven Paradigm for Real-time Optimal Control with Input Constraints](https://arxiv.org/abs/2507.12259)
*Lihan Lian,Yuxin Tong,Uduak Inyang-Udoh*

Main category: eess.SY

TL;DR: 提出了一种名为神经协同状态调节器（NCR）的无监督学习框架，用于实时解决非线性最优控制问题。该框架利用神经网络预测最优协同状态轨迹，并通过二次规划处理输入约束。实验证明，NCR在性能和计算效率上均优于传统的非线性MPC。


<details>
  <summary>Details</summary>
Motivation: 为了在实时情况下解决具有输入约束的非线性最优控制问题（OCPs）。

Method: 提出了一种新颖的无监督学习框架，使用神经网络（NN）来预测最优协同状态轨迹，以最小化控制哈密顿量，并结合二次规划（QP）求解器来满足输入约束和最优性条件。

Result: NCR在收敛误差和输入轨迹平滑度方面优于非线性MPC求解器，并且计算时间比非线性MPC快两个数量级。

Conclusion: 所提出的神经协同状态调节器（NCR）能够有效地解决非线性最优控制问题，并且在收敛误差和输入轨迹平滑度方面优于非线性模型预测控制（MPC）求解器，同时计算时间也大大减少。

Abstract: We propose a novel unsupervised learning framework for solving nonlinear
optimal control problems (OCPs) with input constraints in real-time. In this
framework, a neural network (NN) learns to predict the optimal co-state
trajectory that minimizes the control Hamiltonian for a given system, at any
system's state, based on the Pontryagin's Minimum Principle (PMP).
Specifically, the NN is trained to find the norm-optimal co-state solution that
simultaneously satisfies the nonlinear system dynamics and minimizes a
quadratic regulation cost. The control input is then extracted from the
predicted optimal co-state trajectory by solving a quadratic program (QP) to
satisfy input constraints and optimality conditions. We coin the term neural
co-state regulator (NCR) to describe the combination of the co-state NN and
control input QP solver. To demonstrate the effectiveness of the NCR, we
compare its feedback control performance with that of an expert nonlinear model
predictive control (MPC) solver on a unicycle model. Because the NCR's training
does not rely on expert nonlinear control solvers which are often suboptimal,
the NCR is able to produce solutions that outperform the nonlinear MPC solver
in terms of convergence error and input trajectory smoothness even for system
conditions that are outside its original training domain. At the same time, the
NCR offers two orders of magnitude less computational time than the nonlinear
MPC.

</details>


### [365] [Mixed-integer Second-Order Cone Programming for Multi-period Scheduling of Flexible AC Transmission System Devices](https://arxiv.org/abs/2507.12327)
*Mohamad Charara,Martin De Montigny,Nivine Abou Daher,Hanane Dagdougui,Antoine Lesage-Landry*

Main category: eess.SY

TL;DR: 该研究提出了一种MISOCP模型，用于优化FACTS设备（OLTC、STATCOM、并联电抗器、TCSC）的多周期调度，以最小化电力损耗。模型通过二阶锥松弛和线性化处理设备约束，并在标准测试系统中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着能源需求的增长和可再生能源整合的增加，电力系统面临着运行挑战，如过载、损耗和稳定性问题。FACTS设备对于确保电网可靠运行和高效整合可再生能源至关重要。

Method: 提出了一种混合整数二阶锥规划（MISOCP）模型，用于电网输电系统中关键柔性交流输电系统（FACTS）设备的制定。该模型整合了四种关键控制机制：利用离散抽头的在线负荷分接头改变器（OLTC）、静止同步补偿器（STATCOM）、并联电抗器和晶闸管控制串联电容器（TCSC）。为了保证可处理性，模型采用了二阶锥松弛方法，并通过二进制扩展和线性化处理了设备特定的约束。

Result: 通过在IEEE 9节点、30节点和RTS96测试系统上的评估，证明了所提出的MISOCP模型能够有效减少有功功率损耗。

Conclusion: 该模型在IEEE 9节点、30节点和RTS96测试系统上进行了评估，证明了其减少损耗的能力，并有可能应用于更大规模的电网。

Abstract: With the increasing energy demand and the growing integration of renewable
sources of energy, power systems face operational challenges such as overloads,
losses, and stability concerns, particularly as networks operate near their
capacity limits. Flexible alternating current transmission system (FACTS)
devices are essential to ensure reliable grid operations and enable the
efficient integration of renewable energy. This work introduces a mixed-integer
second-order cone programming (MISOCP) model for the multi-period scheduling of
key FACTS devices in electric transmission systems. The proposed model
integrates four key control mechanisms: (i) on-load tap changers (OLTCs) for
voltage regulation via discrete taps; (ii) static synchronous compensators
(STATCOMs) and (iii) shunt reactors for reactive power compensation; and (iv)
thyristor-controlled series capacitors (TCSCs) for adjustable impedance and
flow control. The objective is to minimize active power losses using a limited
number of control actions while meeting physical and operational constraints at
all times throughout the defined time horizon. To ensure tractability, the
model employs a second-order cone relaxation of the power flow. Device-specific
constraints are handled via binary expansion and linearization: OLTCs and shunt
reactors are modelled with discrete variables, STATCOMs through reactive power
bounds, and TCSCs using a reformulation-linearization technique (RLT). A
multi-period formulation captures the sequential nature of decision making,
ensuring consistency across time steps. The model is evaluated on the IEEE
9-bus, 30-bus, and RTS96 test systems, demonstrating its ability to reduce
losses, with potential applicability to larger-scale grids.

</details>


### [366] [Symbolic Control: Unveiling Free Robustness Margins](https://arxiv.org/abs/2507.12339)
*Youssef Ait Si,Antoine Girard,Adnane Saoud*

Main category: eess.SY

TL;DR: 本研究提出了计算符号控制鲁棒性裕值的方法，并将其应用于控制器设计。


<details>
  <summary>Details</summary>
Motivation: 解决符号控制技术在系统扰动下的鲁棒性保证问题。

Method: 提出了一种计算最大鲁棒性裕值的方法，包括均匀裕值和非均匀裕值（状态和输入相关），并证明了鲁棒性裕值的紧密度依赖于用于计算符号模型的可达性技术的紧密度。

Result: 证明了符号模型具有固有的鲁棒性裕值，并提出了计算这些裕值的方法，同时展示了其在控制器综合中的应用。

Conclusion: 该研究提供了计算最大鲁棒性裕值的方法，并展示了其在控制器综合中的应用。

Abstract: This paper addresses the challenge of ensuring robustness in the presence of
system perturbations for symbolic control techniques. Given a discrete-time
control system that is related to its symbolic model by an alternating
simulation relation. In this paper, we focus on computing the maximum
robustness margin under which the symbolic model remains valid for a
perturbed-version of the discrete-time control system. We first show that
symbolic models are inherently equipped with a certain free robustness margins.
We then provide constructive procedures to compute uniform and non-uniform
(state and input dependent) robustness margins. We also show that the tightness
of the robustness margin depends on the tightness of the reachability technique
used to compute the symbolic model. We then explain how the computed robustness
margin can be used for the sake of controller synthesis. Finally, we present
two illustrative examples to demonstrate the effectiveness of our approach.

</details>


### [367] [BitWave: Exploiting Column-Based Bit-Level Sparsity for Deep Learning Acceleration](https://arxiv.org/abs/2507.12444)
*Man Shi,Vikram Jain,Antony Joseph,Maurice Meijer,Marian Verhelst*

Main category: eess.SY

TL;DR: BitWave是一种新的计算方法和架构，通过位列串行和动态数据流技术，解决了现有位串行加速器内存访问效率低的问题，在提升速度和效率方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有位串行加速器在利用位级稀疏性时，由于非零位的索引不规则，导致内存访问效率低下，而内存访问通常是DNN加速器性能的主要瓶颈。

Method: 提出了一种名为“位列串行”的新型计算方法和兼容的“BitWave”架构设计，利用结构化位级稀疏性，结合动态数据流技术，通过跳过冗余计算和权重压缩来减少计算量和内存占用。

Result: BitWave在16nm FinFet工艺节点下，实现了1.138 mm2的面积和17.56 mW的功耗。与最先进的稀疏感知加速器相比，最高可实现13.25倍的速度提升和7.71倍的效率提升。

Conclusion: BitWave通过位列串行方法和BitWave架构，结合结构化位级稀疏性和动态数据流技术，实现了计算和内存占用的减少，并通过训练后优化缓解了稀疏性带来的性能下降，在四个深度学习基准测试中展现了卓越的性能。

Abstract: Bit-serial computation facilitates bit-wise sequential data processing,
offering numerous benefits, such as a reduced area footprint and
dynamically-adaptive computational precision. It has emerged as a prominent
approach, particularly in leveraging bit-level sparsity in Deep Neural Networks
(DNNs). However, existing bit-serial accelerators exploit bit-level sparsity to
reduce computations by skipping zero bits, but they suffer from inefficient
memory accesses due to the irregular indices of the non-zero bits.
  As memory accesses typically are the dominant contributor to DNN accelerator
performance, this paper introduces a novel computing approach called
"bit-column-serial" and a compatible architecture design named "BitWave."
BitWave harnesses the advantages of the "bit-column-serial" approach,
leveraging structured bit-level sparsity in combination with dynamic dataflow
techniques. This achieves a reduction in computations and memory footprints
through redundant computation skipping and weight compression. BitWave is able
to mitigate the performance drop or the need for retraining that is typically
associated with sparsity-enhancing techniques using a post-training
optimization involving selected weight bit-flips. Empirical studies conducted
on four deep-learning benchmarks demonstrate the achievements of BitWave: (1)
Maximally realize 13.25x higher speedup, 7.71x efficiency compared to
state-of-the-art sparsity-aware accelerators. (2) Occupying 1.138 mm2 area and
consuming 17.56 mW power in 16nm FinFet process node.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [368] [Comment on Decidability of Quasi-Dense Modal Logics by Lyon and Ostropolski-Nalewaja](https://arxiv.org/abs/2507.11644)
*Olivier Gasquet*

Main category: cs.LO

TL;DR: A previous proof about the decidability of quasi-dense modal logics was found to be flawed, leaving the question open.


<details>
  <summary>Details</summary>
Motivation: To address the flaw in a previous proof concerning the decidability of quasi-dense modal logics.

Method: The paper identifies a flaw in a previous proof regarding the union of consistent sets, which invalidates the original conclusion.

Result: The previous proof's conclusion that an upper bound in EXPSPACE exists for the decidability of quasi-dense modal logics is invalidated.

Conclusion: The decidability of quasi-dense modal logics remains an open question.

Abstract: In \cite{Lyon24} the question of the decidability of quasi-dense modal logics
is answered, and an upper bound in EXPSPACE is given. Unfortunately, authors'
intricate proof contains a major flaw that cannot be fixed, leaving the
question wide open. Once identified, this error roughly amounts to assuming
that the union of two consistent sets is consistent, which is of course wrong.

</details>


### [369] [Counting Answer Sets of Disjunctive Answer Set Programs](https://arxiv.org/abs/2507.11655)
*Mohimenul Kabir,Supratik Chakraborty,Kuldeep S Meel*

Main category: cs.LO

TL;DR: SharpASP-SR是一个新的框架，通过将析取逻辑程序中的答案集计数问题约简为投影命题模型计数问题来解决，并在实验中表现优于现有计数器。


<details>
  <summary>Details</summary>
Motivation: 尽管在正规逻辑程序方面取得了显著进展，但对于析取逻辑程序，设计高效的ASP计数器仍然是一个挑战。然而，答案集计数已成为一个重要的计算问题，在概率推理、网络可靠性分析等领域有应用。

Method: 提出了一种名为SharpASP-SR的新型框架，该框架基于减法约简到投影命题模型计数，用于对析取逻辑程序进行答案集计数。该方法引入了答案集的替代表征，实现了有效的约简，并确保中间表示的大小为多项式。

Result: 实验评估表明，SharpASP-SR在具有大量答案集的实例上显著优于现有的计数器，并且结合枚举技术的混合方法实现了最先进的性能。

Conclusion: SharpASP-SR通过将析取逻辑程序中的答案集计数问题通过减法约简为投影命题模型计数问题，并保证中间表示的多项式大小，从而能够有效利用投影模型计数技术的最新进展，并在具有大量答案集的实例上显著优于现有计数器。此外，结合枚举技术和SharpASP-SR的混合计数方法在全谱的析取程序上实现了最先进的性能。

Abstract: Answer Set Programming (ASP) provides a powerful declarative paradigm for
knowledge representation and reasoning. Recently, counting answer sets has
emerged as an important computational problem with applications in
probabilistic reasoning, network reliability analysis, and other domains. This
has motivated significant research into designing efficient ASP counters. While
substantial progress has been made for normal logic programs, the development
of practical counters for disjunctive logic programs remains challenging.
  We present SharpASP-SR, a novel framework for counting answer sets of
disjunctive logic programs based on subtractive reduction to projected
propositional model counting. Our approach introduces an alternative
characterization of answer sets that enables efficient reduction while ensuring
that intermediate representations remain of polynomial size. This allows
SharpASP-SR to leverage recent advances in projected model counting technology.
Through extensive experimental evaluation on diverse benchmarks, we demonstrate
that SharpASP-SR significantly outperforms existing counters on instances with
large answer set counts. Building on these results, we develop a hybrid
counting approach that combines enumeration techniques with SharpASP-SR to
achieve state-of-the-art performance across the full spectrum of disjunctive
programs.

</details>


### [370] [Anthem 2.0: Automated Reasoning for Answer Set Programming](https://arxiv.org/abs/2507.11704)
*Jorge Fandinno,Christoph Glinzer,Zachary Hansen,Jan Heuer,Yuliya Lierler,Vladimir Lifschitz,Torsten Schaub,Tobias Stolzmann*

Main category: cs.LO

TL;DR: Anthem 2.0 是一个用于验证 mini-gringo 逻辑程序的工具，可以翻译程序、分析属性并使用一阶定理证明器进行验证。


<details>
  <summary>Details</summary>
Motivation: Anthem 2.0 的目的是为了帮助验证使用 mini-gringo 语言编写的逻辑程序，该语言包含算术运算和选择规则。

Method: Anthem 2.0 将逻辑程序翻译成“here-and-there”逻辑中的公式表示，并分析如紧性等逻辑程序的属性。最后，通过调用一阶定理证明器来验证程序的属性。

Result: Anthem 2.0 能够支持程序验证，并能演示如何有效地使用该工具并解释其结果。

Conclusion: Anthem 2.0 是一个强大的工具，用于验证 mini-gringo 语言编写的逻辑程序，它可以通过调用一阶定理证明器来支持程序验证，例如确认程序是否符合一阶规范，或建立程序的强等价和外部等价。

Abstract: Anthem 2.0 is a tool to aid in the verification of logic programs written in
an expressive fragment of Clingo's input language named mini-gringo, which
includes arithmetic operations and simple choice rules but not aggregates. It
can translate logic programs into formula representations in the logic of
here-and-there, and analyze properties of logic programs such as tightness.
Most importantly, Anthem 2.0 can support program verification by invoking
first-order theorem provers to confirm that a program adheres to a first-order
specification, or to establish strong and external equivalence of programs.
This paper serves as an overview of the system's capabilities. We demonstrate
how to use Anthem 2.0 effectively and interpret its results.

</details>


### [371] [Approximation Fixpoint Theory as a Unifying Framework for Fuzzy Logic Programming Semantics (Extended Version)](https://arxiv.org/abs/2507.11961)
*Pascal Kettmann,Jesse Heyninck,Hannes Strass*

Main category: cs.LO

TL;DR: 本文利用近似不动点理论（AFT）统一了模糊逻辑编程中的稳定模型和有根据模型语义，并扩展了AFT的应用范围。


<details>
  <summary>Details</summary>
Motivation: 为了将近似不动点理论（AFT）的范围从二值逻辑扩展到多值逻辑，并使现有的AFT结果能够广泛应用于模糊逻辑编程。

Method: 本文展示了如何将经典逻辑编程中的稳定模型和有根据模型语义重构到近似不动点理论（AFT）的通用框架中。

Result: 本文澄清了现有语义之间的形式关系，将分层结构的概念从经典模糊逻辑程序推广到模糊逻辑程序，并设计了这些语义的“更精确”变体。

Conclusion: 本文将两个最著名的经典语义，即稳定模型和有根据模型，在近似不动点理论（AFT）的通用框架内进行重建。这不仅将AFT的范围从二值逻辑扩展到多值逻辑，而且允许将现有的AFT结果广泛应用于模糊逻辑编程。

Abstract: Fuzzy logic programming is an established approach for reasoning under
uncertainty. Several semantics from classical, two-valued logic programming
have been generalized to the case of fuzzy logic programs. In this paper, we
show that two of the most prominent classical semantics, namely the stable
model and the well-founded semantics, can be reconstructed within the general
framework of approximation fixpoint theory (AFT). This not only widens the
scope of AFT from two- to many-valued logics, but allows a wide range of
existing AFT results to be applied to fuzzy logic programming. As first
examples of such applications, we clarify the formal relationship between
existing semantics, generalize the notion of stratification from classical to
fuzzy logic programs, and devise "more precise" variants of the semantics.

</details>


### [372] [SHACL Validation in the Presence of Ontologies: Semantics and Rewriting Techniques](https://arxiv.org/abs/2507.12286)
*Anouk Oudshoorn,Magdalena Ortiz,Mantas Simkus*

Main category: cs.LO

TL;DR: 该论文提出了一种在存在本体的情况下验证 SHACL 的方法，该方法通过将 SHACL 验证还原为标准验证来解决 SHACL 和 OWL 之间的语义鸿沟问题。研究表明，即使有简单的本体，验证的复杂度也很高。


<details>
  <summary>Details</summary>
Motivation: SHACL 和 OWL 是两个重要的 W3C 标准，在管理 RDF 数据方面有许多共同点，但存在一个根本性的差异：OWL 基于开放世界假设，而 SHACL 基于封闭世界假设。将两者结合起来很有吸引力，但它们之间的语义鸿沟在语义和计算上都是一个主要挑战。

Method: 提出了一种基于核心通用模型的 SHACL 验证语义，并提供了一种为 Horn-ALCHIQ 中的本体构造这些模型的技术。然后，使用该模型的有限表示来开发一种将 SHACL 验证（在存在本体的情况下）还原为标准验证的重写技术。

Result: 研究了 SHACL 验证在存在本体时的情况下的复杂度，并表明即使是很简单的本体也会使问题达到 EXPTIME 完全，而在数据复杂度下达到 PTIME 完全。

Conclusion: SHACL 验证在存在本体的情况下可以被还原为标准验证，并且即使是很简单的本体，其复杂度也是 EXPTIME 完全的，而在数据复杂度下是 PTIME 完全的。

Abstract: SHACL and OWL are two prominent W3C standards for managing RDF data. These
languages share many features, but they have one fundamental difference: OWL,
designed for inferring facts from incomplete data, makes the open-world
assumption, whereas SHACL is a constraint language that treats the data as
complete and must be validated under the closed-world assumption. The
combination of both formalisms is very appealing and has been called for, but
their semantic gap is a major challenge, semantically and computationally. In
this paper, we advocate a semantics for SHACL validation in the presence of
ontologies based on core universal models. We provide a technique for
constructing these models for ontologies in the rich data-tractable description
logic Horn-ALCHIQ. Furthermore, we use a finite representation of this model to
develop a rewriting technique that reduces SHACL validation in the presence of
ontologies to standard validation. Finally, we study the complexity of SHACL
validation in the presence of ontologies, and show that even very simple
ontologies make the problem EXPTIME-complete, and PTIME-complete in data
complexity.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [373] [Designing lattice spin models and magnon gaps with supercurrents](https://arxiv.org/abs/2507.11606)
*Johanne Bratland Tjernshaugen,Martin Tang Bruland,Jacob Linder*

Main category: cond-mat.mes-hall

TL;DR: 通过超电流实现对自旋相互作用和磁咙的电控制，无需耗散电流。


<details>
  <summary>Details</summary>
Motivation: 为了在量子应用（如量子比特、存储和传感器功能）中实现对单个自旋磁相互作用的电控制，并最小化能量耗散。

Method: 通过理论计算和模拟，研究了自旋极化超电流对表面磁性吸附原子相互作用的影响，以及超电流对反铁磁和交变磁绝缘体中磁咙的控制作用。

Result: 发现了自旋极化超电流可使磁相互作用不仅依赖于磁原子的相对距离，还依赖于其空间绝对位置。这使得对整个自旋晶格的电控制成为可能，并实现了非共线基态。此外，超电流还能控制反铁磁和交变磁绝缘体中的磁咙。

Conclusion: 本研究表明，超电流可以控制自旋晶格和磁咙，并实现对磁相互作用的电控制，而无需耗散电流。

Abstract: Controlling magnetic interactions at the level of individual spins is
relevant for a variety of quantum applications, such as qubits, memory and
sensor functionality. Finding ways to exert electrical control over spin
interactions, with minimal energy dissipation, is a key objective in this
endeavour. We show here that spin lattices and magnon gaps can be controlled
with a supercurrent. Remarkably, a spin-polarized supercurrent makes the
interaction between magnetic adatoms placed on the surface of a superconductor
depend not only on their relative distance, but also on their absolute position
in space. This property permits electric control over the interaction not only
between two individual spins, but in fact over an entire spin lattice, allowing
for non-collinear ground states and a practical arena to study the properties
of different spin Hamiltonians. Moreover, we show that a supercurrent controls
the magnon gap in antiferromagnetic and altermagnetic insulators. These results
provide an accessible way to realize electrically controlled spin switching and
magnon gaps without dissipative currents.

</details>


### [374] [Nesting-driven ferromagnetism of itinerant electrons](https://arxiv.org/abs/2507.11614)
*Ya. I. Rodionov,A. V. Rozhkov,M. E. S. Beck,A. O. Sboychakov,K. I. Kugel,A. L. Rakhmanov*

Main category: cond-mat.mes-hall

TL;DR: 理论研究了具有完美费米面嵌套的相互作用费米子模型，发现其基态为绝缘体（SDW或CDW），掺杂后出现非Stoner型的铁磁性。


<details>
  <summary>Details</summary>
Motivation: 理论研究费米面完美嵌套的相互作用费米子模型，以理解其在不同掺杂下的基态和铁磁化机制。

Method: 使用平均场近似来理论研究一个包含相互作用的电子和空穴的模型，其费米面是完美嵌套的。为了抑制不均匀状态，模型中包含足够强的长程库仑排斥力。

Result: 构建了该模型的相图，并研究了各种有序相的性质。模型表明，掺杂会导致有限的铁磁极化。

Conclusion: 该模型的研究表明，在没有掺杂的情况下，费米面完美嵌套的相互作用费米子的基态是绝缘的，并具有密度波序（SDW或CDW）。在掺杂后，会出现有限的铁磁极化，并且驱动铁磁化的机制并非 Stoner 型。

Abstract: We theoretically investigate a model with electrons and holes whose Fermi
surfaces are perfectly nested. The fermions are assumed to be interacting, both
with each other and with the lattice. To suppress inhomogeneous states, a
sufficiently strong long-range Coulomb repulsion is included into the model.
Using the mean field approximation, one can demonstrate that in the absence of
doping, the ground state of such a model is insulating and possesses a
density-wave order, either SDW, or CDW. Upon doping, a finite ferromagnetic
polarization emerges. It is argued that the mechanism driving the
ferromagnetism is not of the Stoner type. A phase diagram of the model is
constructed, and various properties of the ordered phases are studied.

</details>


### [375] [Beyond ensemble averaging: Parallelized single-shot readout of hole capture in diamond](https://arxiv.org/abs/2507.11722)
*Richard Monge,Yuki Nakamura,Olaf Bach,Jason Shao,Artur Lozovoi,Alexander A. Wood,Kento Sasaki,Kensuke Kobayashi,Tom Delord,Carlos A. Meriles*

Main category: cond-mat.mes-hall

TL;DR: 这项研究利用先进的光学技术，在纳米尺度上揭示了半导体中的电荷载流子行为，为量子设备等领域提供了新的见解。


<details>
  <summary>Details</summary>
Motivation: 理解半导体中电荷载流子的产生、传输和捕获具有根本的技术重要性。然而，电子学中普遍存在的系综测量技术对现代量子电子设备运行至关重要的纳米级环境的洞察力有限。

Method: 结合宽场光学显微镜和精密光谱学，研究光生空穴被金刚石中带负电的氮空位（NV-）中心捕获的情况。

Result: 同时对数百个独立的NV进行单次电荷读数，可以解析电离杂质的作用，揭示空间电荷场的形成，并监测扩散过程中热载流子的热化。测量到的NV-空穴捕获半径超过0.2微米，接近Onsager极限，这得益于共存电荷陷阱的近乎完全中和。

Conclusion: 这些结果建立了一个新的平台，用于解决超越整体平均值的电荷动力学问题，并与纳米电子学和量子设备直接相关。

Abstract: Understanding the generation, transport and capture of charge carriers in
semiconductors is of fundamental technological importance. However, the
ensemble measurement techniques ubiquitous in electronics offer limited insight
into the nanoscale environment that is crucial to the operation of modern
quantum-electronic devices. Here, we combine widefield optical microscopy with
precision spectroscopy to examine the capture of photogenerated holes by
negatively charged nitrogen vacancy (NV-) centers in diamond. Simultaneous
single-shot charge readout over hundreds of individual NVs allows us to resolve
the roles of ionized impurities, reveal the formation of space charges fields,
and monitor the thermalization of hot photo-carriers during diffusion. We
measure effective NV- hole capture radii in excess of 0.2 um, a value
approaching the Onsager limit and made possible here thanks to the
near-complete neutralization of coexisting charge traps. These results
establish a new platform for resolving charge dynamics beyond ensemble
averages, with direct relevance to nanoscale electronics and quantum devices.

</details>


### [376] [Anisotropic-scaling localization in higher-dimensional non-Hermitian systems](https://arxiv.org/abs/2507.11933)
*Zuxuan Ou,Hui-Qiang Liang,Guo-Fu Xu,Linhu Li*

Main category: cond-mat.mes-hall

TL;DR: 本研究揭示了更高维度非厄米系统中的一种新局域化现象——各向异性定标局域化（ASL），它具有尺寸依赖的各向异性局域化长度。ASL的产生机制与非倒易性的引入方式有关，并且可以通过特征值的实部或虚部来区分ASL态与非厄米皮肤态。该研究解决了现有文献中关于环状谱和边界态皮肤状局域化共存的难题，并为理解和分类复杂的更高维度非厄米局域化现象提供了新框架。


<details>
  <summary>Details</summary>
Motivation: 空间量子态局域化是凝聚态物理和量子模拟的焦点之一，因为它标志着非平凡的能带拓扑和非倒易性非厄米性等深刻的物理现象。然而，在更高维度中，由于不同局域化机制和空间几何之间复杂的相互作用，态局域化的表征变得难以捉摸。

Method: 通过解析解和数值模拟相结合的方法。

Result: 揭示了各向异性定标局域化（ASL）现象，其中局域化长度遵循不同的尺寸依赖定标规则。ASL可以源于两种不同的机制：有效的体耦合或不同一维边缘之间的结。通过复和实特征值分别识别了ASL态和边缘非厄米皮肤态的竞争，解决了环状谱和边界态皮肤状局域化共存的问题，并提供了一个分类框架。

Conclusion: 本工作揭示了一种在更高维度非厄米系统中外来的局域化现象，称为各向异性定标局域化（ASL），其中局域化长度遵循不同的尺寸依赖定标规则，表现出各向异性。ASL可以源于两种不同的机制：有效的体耦合或不同一维边缘之间的结，具体取决于非倒易性引入系统的方式。通过复和实特征值分别识别了ASL态和边缘非厄米皮肤态的竞争。我们的结果解决了当代文献中环状谱和边界态皮肤状局域化这种微妙的共存问题，并提供了一个框架来对具有复杂更高阶非厄米局域化的局域化轮廓进行分类。

Abstract: Spatial localization of quantum states is one of the focal points in
condensed matter physics and quantum simulations, as it signatures profound
physics such as nontrivial band topology and non-reciprocal non-Hermiticity.
Yet, in higher dimensions, characterizing state localization becomes elusive
due to the sophisticated interplay between different localization mechanisms
and spacial geometries. In this work, we unveil an exotic type of localization
phenomenon in higher-dimensional non-Hermitian systems, termed
anisotropic-scaling localization (ASL), where localization lengths follow
distinct size-dependent scaling rules in an anisotropic manner. Assisted with
both analytical solution and numerical simulation, we find that ASL can emerge
from two different mechanisms of effective bulk couplings or one-dimensional
junction between different 1D edges, depending on how non-reciprocity is
introduced to the system. The competition between ASL states and edge
non-Hermitian skin states are further identified by their complex and real
eigenenergies, respectively. Our results resolve the subtle co-existence of
loop-like spectrum and skin-like localization of boundary states in
contemporary literature, and provide a framework to classify the intricate
higher-order non- Hermitian localization regarding their localization profiles.

</details>


### [377] [Quantum oscillations of valley current driven by microwave irradiation in transition-metal dichalcogenide/ferromagnet hybrids](https://arxiv.org/abs/2507.11934)
*Xin Hu,Yuya Ominato,Mamoru Matsuo*

Main category: cond-mat.mes-hall

TL;DR: Spin pumping in TMDC/ferromagnet heterostructures creates a valley current with quantum oscillations, linking spintronics and valleytronics.


<details>
  <summary>Details</summary>
Motivation: To theoretically study spin and valley transport in a TMDC/ferromagnet heterostructure and to explore phenomena arising from the interplay between spintronics and valleytronics.

Method: Theoretical study of spin and valley transport in a TMDC/ferromagnet heterostructure under a perpendicular magnetic field, focusing on microwave-driven spin pumping and its effect on valley-selective spin excitation.

Result: Microwave-driven spin pumping induces a valley-selective spin excitation due to valley-asymmetric Landau levels, generating a pure valley current. This valley current exhibits pronounced quantum oscillations as a function of chemical potential, serving as an experimental signature of quantized valley states.

Conclusion: The study establishes a new pathway to interface spintronics and valleytronics by demonstrating microwave-driven spin pumping in a TMDC/ferromagnet heterostructure, which induces a valley-selective spin excitation and generates a pure valley current exhibiting quantum oscillations.

Abstract: We theoretically study spin and valley transport in a TMDC/ferromagnet
heterostructure under a perpendicular magnetic field. We find that
microwave-driven spin pumping induces a valley-selective spin excitation, a
direct consequence of the valley-asymmetric Landau levels in the TMDC
conduction band. This process generates a pure valley current which, as our
central finding, exhibits pronounced quantum oscillations as a function of
chemical potential. These oscillations provide a definitive experimental
signature of the quantized valley states and establish a new pathway to
interface spintronics and valleytronics.

</details>


### [378] [Shock absorption by multilayer carbon nanotube packings](https://arxiv.org/abs/2507.12034)
*Alexander V. Savin*

Main category: cond-mat.mes-hall

TL;DR: 碳纳米管阵列是有效的减震器。


<details>
  <summary>Details</summary>
Motivation: 研究碳纳米管阵列作为减震器的有效性。

Method: 通过模拟研究了横向冲击能量在平行单壁碳纳米管的多层堆积（阵列）中的传播。

Result: 直径为 2.7-3.9 nm 的碳纳米管阵列最能吸收冲击能量，部分碳纳米管在吸收能量后处于崩溃状态。较小直径碳纳米管的压缩是弹性的，而较大直径碳纳米管的压缩会释放能量。

Conclusion: 碳纳米管阵列可作为有效的减震器，特别是直径为 2.7-3.9 nm 的碳纳米管阵列效果最显著。冲击能量的一部分被吸收到打包的能量转移到一个更高的固定状态，其中一部分碳纳米管处于崩溃状态。

Abstract: The propagation of transverse impact energy in a multilayer packing (in an
array) of parallel single-walled carbon nanotubes has been simulated. It has
been shown that such nanotube arrays are effective shock absorbers. The
depreciation effect is most pronounced for packings of nanotubes with a
diameter of 2.7-3.9 nm. Here, part of the impact energy is absorbed due to the
transfer of the packing to a higher energy stationary state, in which part of
the nanotubes is in a collapsed state. The impact impulse reaches the other
edge of the packing most weakened and distributed over time. For nanotubes with
a smaller diameter, the compression of the array occurs elastically without
energy accumulation, and for nanotubes with a larger diameter - with energy
release.

</details>


### [379] [Controlling the magneto-transport properties of magnetic topological insulator thin films from Cr$_x$(Bi$_y\,$Sb$_{1-y}$)$_{2-x}$Te$_3$ via molecular beam epitaxy](https://arxiv.org/abs/2507.12115)
*Jan Karthein,Jonas Buchhorn,Kaycee Underwood,Abdur Rehman Jalil,Max Vaßen-Carl,Peter Schüffelgen,Detlev Grützmacher,Thomas Schäpers*

Main category: cond-mat.mes-hall

TL;DR: 通过调整分子束外延的衬底温度和铬浓度，可以优化磁性拓扑绝缘体薄膜的质量，调控其载流子浓度，并有望实现超导电性。


<details>
  <summary>Details</summary>
Motivation: 探究通过调整分子束外延参数来调控磁性拓扑绝缘体薄膜磁输运性质的方法，旨在实现载流子浓度的调控和潜在的超导电性。

Method: 研究了分子束外延过程中衬底温度和铬浓度对磁性拓扑绝缘体薄膜的表面形貌、晶体质量、粗糙度和磁输运性质的影响。

Result: 衬底温度和铬浓度的精确控制可以优化薄膜的质量，并调控费米能级，使其接近本征电荷中性。较低的铬浓度有助于将材料推向可能出现强超导关联的区域。

Conclusion: 通过调整分子束外延的参数，可以优化磁性拓扑绝缘体薄膜的载流子浓度，并可能实现超导电性。

Abstract: In this work we present a systematic in-depth study of how we can alter the
magneto-transport properties of magnetic topological insulator thin films by
tuning the parameters of the molecular beam epitaxy. First, we show how a
varying substrate temperature changes the surface morphology and when chosen
properly leads to a high crystal quality. Next, the effect of the chromium
concentration on the film roughness and crystal quality is investigated.
Finally, both the substrate temperature and the chromium concentration are
investigated with respect to their effect on the magneto-transport properties
of the magnetic topological insulator thin films. It becomes apparent that the
substrate temperature and the chromium concentration can be used to tune the
Fermi level of the film which allows to make the material intrinsically charge
neutral. A very low chromium concentration furthermore allows to tune the
magnetic topological insulator into a regime where strong superconducting
correlations can be expected when combining the material with a superconductor.

</details>


### [380] [Local control of parity and charge in nanoscale superconducting lead islands](https://arxiv.org/abs/2507.12150)
*Stefano Trivini,Jon Ortuzar,Katerina Vaxevani,Beatriz Viña-Bausá,F. Sebastian Bergeret,Jose Ignacio Pascual*

Main category: cond-mat.mes-hall

TL;DR: 研究了小超导岛中的电荷量子化现象，发现通过电压脉冲可以调谐其超导基态，有望用于量子比特设计。


<details>
  <summary>Details</summary>
Motivation: 探索小超导岛中电荷量子化与库仑相互作用和库珀对之间的相互作用。

Method: 使用扫描隧道光谱技术，测量了单个纳米岛的充电能量（EC）和配对能量（Δ），并通过施加可控电压脉冲来调节岛的静电势，绘制了完整的电荷-奇偶校验图谱。

Result: 在临界岛尺寸以下（EC > Δ），观察到了基态在偶数和奇数奇偶校验之间的交叉。通过电压脉冲可以连续调谐岛的静电势，并绘制出完整的电荷-奇偶校验图谱。

Conclusion: 该研究展示了可调的超导基态，为量子比特的设计和控制提供了潜在的平台。

Abstract: Small superconducting islands can exhibit charge quantization, where Coulomb
interactions compete with Cooper pairing. Using scanning tunneling
spectroscopy, we probe this interplay by measuring the charging energy ($E_C$)
and the pairing energy ($\Delta$) of individual nano-islands. Below a critical
island size, where $E_C > \Delta$, we observe a crossover between even and odd
parity ground states. By applying controlled voltage pulses, we continuously
tune the island's electrostatic potential and map the full charge-parity
landscape. These results demonstrate tunable superconducting ground states,
offering a potential platform for qubit design and control.

</details>


### [381] [Light-hole states and hyperfine interaction in electrically-defined Ge/GeSn quantum dots](https://arxiv.org/abs/2507.12249)
*Agnieszka Miętkiewicz,Jakub Ziembicki,Krzysztof Gawarecki*

Main category: cond-mat.mes-hall

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We theoretically investigate hole spins confined in a gate-defined quantum
dot (QD) embedded in GeSn/Ge/GeSn quantum well (QW) structure. Owing to the
tensile strain in the Ge layer, the system effectively realizes a light-hole
qubit. We systematically study how various morphological parameters influence
the energy spectrum, g-factors, and the hyperfine coupling to the nuclear spin
bath. The simulations are carried out using a realistic, fully atomic
sp$^3$d$^5$s$^*$ tight-binding model. We also perform complementary DFT
calculations of wave functions near the atomic cores and use them to
parameterize the hyperfine-interaction Hamiltonian. We evaluate the Overhauser
field fluctuations and demonstrate that the strength of the hyperfine coupling
for the lowest hole doublet crucially depends on the Sn content in the barrier.
We highlight the conduction-valence band mixing, which leads to considerable
$s$-type admixtures to the hole states, providing the dominant channel of
hyperfine coupling due to the Fermi contact interaction.

</details>


### [382] [Electrically tunable heavy fermion and quantum criticality in magic-angle twisted trilayer graphene](https://arxiv.org/abs/2507.12254)
*Le Zhang,Wenqiang Zhou,Xinjie Fang,Zhen Zhan,Kenji Watanabe,Takashi Taniguchi,Yi-feng Yang,Shuigang Xu*

Main category: cond-mat.mes-hall

TL;DR: 在魔角扭曲三层石墨烯中，通过调控Kondo杂化，实现了电可调的重费米子态，并观察到量子相变。


<details>
  <summary>Details</summary>
Motivation: 探索在非稀土体系中工程化重费米子态，以及在扭曲石墨烯体系中寻找局域电子与巡游电子强耦合的直接证据。

Method: 利用魔角扭曲三层石墨烯，通过位移场调控局域平带电子与巡游狄拉克电子之间的Kondo杂化作用，实现了重费米子态。

Result: 观察到从反铁磁半金属到顺磁重费米子金属的连续量子相变，表现为电阻率从对数温度依赖到二次方温度依赖的交叉，以及在量子临界点附近准粒子有效质量的显著增加和费米面重构。

Conclusion: 该研究通过魔角扭曲三层石墨烯中的Kondo杂化，成功实现了可电调谐的重费米子态，揭示了从反铁磁半金属到顺磁重费米子金属的连续量子相变，为重费米子物理和非常规超导等相关量子现象的研究提供了新的平台。

Abstract: The interplay between localized magnetic moments and itinerant electrons
gives rise to exotic quantum states in condensed matter systems.
Two-dimensional moire superlattices offer a powerful platform for engineering
heavy fermion states beyond conventional rare-earth intermetallic compounds.
While localized and itinerant carriers have been observed in twisted graphene
moire systems, direct evidence of their strong coupling--leading to artificial
heavy fermion states--has remained elusive. Here, we demonstrate electrically
tunable heavy fermion in magic-angle twisted trilayer graphene, achieved by
controlling the Kondo hybridization between localized flatband electrons and
itinerant Dirac electrons via a displacement field. Our results reveal a
continuous quantum phase transition from an antiferromagnetic semimetal to a
paramagnetic heavy fermion metal, evidenced by a crossover from logarithmic to
quadratic temperature-dependent resistivity, a dramatic enhancement of
quasiparticle effective mass, and Fermi surface reconstruction near quantum
critical point. This highly tunable platform offers unprecedented control over
heavy fermion physics, establishing moire heterostructures as a versatile arena
for exploring correlated quantum phases--including potential unconventional
superconductivity--in two-dimensional materials.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [383] [Electron and phonon topology in transition metal material TaSi](https://arxiv.org/abs/2507.11705)
*Saurabh Kumar Sen,Shivendra Kumar Gupta,Nagarjuna Patra,Ajit Singh Jhala,Poorva Singh*

Main category: cond-mat.mtrl-sci

TL;DR: TaSi是一种具有多重费米子和手性玻色子激发的拓扑材料，在量子材料、拓扑电子学和自旋电子学中有潜在应用。


<details>
  <summary>Details</summary>
Motivation: 寻找同时具有电子和玻色子多重激发（准粒子）的材料，以期在凝聚态物理和量子材料等领域取得进展。

Method: 使用第一性原理计算研究了TaSi的电子和声子性质。

Result: 在SOC存在的情况下，TaSi的电子能带表现出四重简并的3/2自旋Rarita-Schwinger（RSW）费米子、具有大陈数C=+4的六重激发（双重1自旋）以及具有-1陈数的1/2自旋外尔费米子。此外，声子能带结构也表现出手性陈数为C=±2的玻色子激发。

Conclusion: TaSi是一种非对称手性拓扑材料，具有受空间群P 2 1 3保护的四重简并外尔费米子。该材料同时具有受SOC保护的六重激发和手性 the bosonic excitations，具有大陈数。电子和玻色子激发的共存赋予了TaSi奇特的输运现象，使其成为量子材料、拓扑电子学和自旋电子学等未来应用的有希望的候选者。

Abstract: The plethora of multifold quasiparticles in topological materials has led to
significant advancements in condensed matter physics, inspiring the
investigation for materials that host both electronic and bosonic multifold
excitations. In this work, we explore the electronic and phononic properties of
TaSi, a non symmorphic chiral topological material crystallizing in space group
P 2 1 3 (No. 198). This system exhibits multifold fermions, which are higher
spin generalizations of Weyl fermions, protected by the unique crystalline
symmetries of the structure. Using first principles calculations, we predict
that electronic band possesses fourfold spin 3/2 Rarita Schwinger (RSW)
fermions, sixfold excitations (double spin 1), all possessing large Chern
numbers C = +4 and Weyl fermions of spin 1/2 with Chern no. -1 in the presence
of spin orbit coupling (SOC). Additionally, the phononic band structure hosts
chiral bosonic excitations characterized by Chern numbers C = +-2. The
coexistence of chiral electronic and bosonic quasiparticles give rise to exotic
transport phenomena, rendering the material as promising candidate for future
applications in quantum materials, topological electronics, and spintronics.

</details>


### [384] [High-throughput computational framework for lattice dynamics and thermal transport including high-order anharmonicity: an application to cubic and tetragonal inorganic compounds](https://arxiv.org/abs/2507.11750)
*Zhi Li,Huiju Lee,Chris Wolverton,Yi Xia*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究开发了一个高通量框架，用于准确预测材料的晶格热导率 (kL)，方法是将更高级别的不谐波效应（如四声子散射）纳入计算中。该方法揭示了这些效应如何显著影响 kL，并为发现具有极端热学特性的新材料提供了途径。


<details>
  <summary>Details</summary>
Motivation: 准确地从第一性原理预测 kL 对于识别具有极端热学行为的材料仍然是一个挑战，因为可靠的结果，特别是对于低 kL 化合物，需要更高级别的不谐波效应。

Method: 该工作开发了一个高通量工作流程，该工作流程将自洽声子重构、四声子散射和离面热流等更高级别的不谐波效应集成到一个统一的框架中，用于计算 kL。

Result: 该工作计算了 773 种立方和四方无机化合物的 kL。在 562 种动态稳定的化合物中，约 60% 的材料的 HA+3ph 预测与 SCPH+3,4ph+OD 预测非常匹配。然而，SCPH 校正通常会增加 kL，有时会增加 8 倍以上，而四声子散射普遍降低了 kL，有时会降低到 HA+3ph 值的 15%。离面贡献在高 kL 系统中很小，但在高度不谐波、低 kL 的化合物中可能超过总 kL 的 50%。

Conclusion: 该工作提供了一个高通量的 दुसरी工作流程，用于集成更高级别的不谐波效应，以进行精确的晶格热导率（kL）预测。它量化了这些效应的影响，并为识别具有极端热学行为的新型材料提供了一个可扩展且可解释的途径。

Abstract: Accurately predicting lattice thermal conductivity (kL) from first principles
remains a challenge in identifying materials with extreme thermal behavior.
While modern lattice dynamics methods enable routine predictions of kL within
the harmonic approximation and three-phonon scattering framework (HA+3ph),
reliable results, especially for low-kL compounds, require higher-order
anharmonic effects, including self-consistent phonon renormalization,
four-phonon scattering, and off-diagonal heat flux (SCPH+3,4ph+OD). We present
a high-throughput workflow integrating these effects into a unified framework.
Using this, we compute kL for 773 cubic and tetragonal inorganic compounds
across diverse chemistries and structures. From 562 dynamically stable
compounds, we assess the hierarchical effects of higher-order anharmonicity.
For about 60% of materials, HA+3ph predictions closely match those from
SCPH+3,4ph+OD. However, SCPH corrections often increase kL, sometimes by over 8
times, while four-phonon scattering universally reduces it, occasionally to 15%
of the HA+3ph value. Off-diagonal contributions are minor in high-kL systems
but can exceed 50% of total kL in highly anharmonic, low-kL compounds. We
highlight four cases-Rb2TlAlH6, Cu3VS4, CuBr, and Cl2O-exhibiting distinct
anharmonic behaviors. This work delivers not only a robust workflow for
high-fidelity kL dataset but also a quantitative framework to determine when
higher-order effects are essential. The hierarchy of kL results, from the
HA+3ph to SCPH+3,4ph+OD level, offers a scalable, interpretable route to
discovering next-generation extreme thermal materials.

</details>


### [385] [MOFSimBench: Evaluating Universal Machine Learning Interatomic Potentials In Metal--Organic Framework Molecular Modeling](https://arxiv.org/abs/2507.11806)
*Hendrik Kraß,Ju Huang,Seyed Mohamad Moosavi*

Main category: cond-mat.mtrl-sci

TL;DR: uMLIPs在多孔材料建模方面已准备好部署，并且在各种任务中持续优于经典力场和微调的机器学习势。模型架构不如训练数据的质量和多样性重要，尤其是包含非平衡构象的数据。


<details>
  <summary>Details</summary>
Motivation: 金属有机框架（MOFs）和相关纳米多孔材料在碳捕获、储能和催化应用中具有关键意义。然而，由于其化学性质多样、结构复杂（包括孔隙率和配位键）以及现有训练数据集中缺乏这些材料，uMLIPs在实际应用中对这类材料的建模仍存在可靠性和有效性问题。

Method: 本研究介绍了一个名为MOFSimBench的基准，用于评估uMLIPs在多孔材料建模的关键任务中的性能，包括结构优化、分子动力学稳定性、体材料性质（如体积模量和热容）的预测以及客主相互作用。

Result: 在化学和结构上多样化的材料集上对20多个不同架构的模型进行评估后，发现性能最佳的uMLIPs在所有任务中持续优于经典力场和微调的机器学习势。数据质量，特别是训练集的多样性和包含非平衡构象，对决定uMLIPs的性能起着比模型架构更重要的作用。

Conclusion: uMLIPs在多孔材料建模方面已准备好部署，并且在各种任务中持续优于经典力场和微调的机器学习势。模型架构不如训练数据的质量和多样性重要，尤其是包含非平衡构象的数据。

Abstract: Universal machine learning interatomic potentials (uMLIPs) have emerged as
powerful tools for accelerating atomistic simulations, offering scalable and
efficient modeling with accuracy close to quantum calculations. However, their
reliability and effectiveness in practical, real-world applications remain an
open question. Metal-organic frameworks (MOFs) and related nanoporous materials
are highly porous crystals with critical relevance in carbon capture, energy
storage, and catalysis applications. Modeling nanoporous materials presents
distinct challenges for uMLIPs due to their diverse chemistry, structural
complexity, including porosity and coordination bonds, and the absence from
existing training datasets. Here, we introduce MOFSimBench, a benchmark to
evaluate uMLIPs on key materials modeling tasks for nanoporous materials,
including structural optimization, molecular dynamics (MD) stability, the
prediction of bulk properties, such as bulk modulus and heat capacity, and
guest-host interactions. Evaluating over 20 models from various architectures
on a chemically and structurally diverse materials set, we find that
top-performing uMLIPs consistently outperform classical force fields and
fine-tuned machine learning potentials across all tasks, demonstrating their
readiness for deployment in nanoporous materials modeling. Our analysis
highlights that data quality, particularly the diversity of training sets and
inclusion of out-of-equilibrium conformations, plays a more critical role than
model architecture in determining performance across all evaluated uMLIPs. We
release our modular and extendable benchmarking framework at
https://github.com/AI4ChemS/mofsim-bench, providing an open resource to guide
the adoption for nanoporous materials modeling and further development of
uMLIPs.

</details>


### [386] [Thermodynamic stabilization and electronic effects of oxygen vacancies at BiFeO$_3$ neutral ferroelectric domain walls](https://arxiv.org/abs/2507.11863)
*Guo-Dong Zhao,Ismaila Dabo,Long-Qing Chen*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究利用第一性原理模拟，解释了BiFeO3铁电畴壁中氧空位导致的导电性增强机制，为铁电材料设计提供了理论指导。


<details>
  <summary>Details</summary>
Motivation: BiFeO3铁电材料中的畴壁导电性增强机制尚不完全清楚，特别是畴壁缺陷的电子贡献，因此需要原子尺度的理解。

Method: 利用第一性原理模拟计算了氧空位在BiFeO3铁电畴壁中的热力学稳定性和电子影响，并分析了其在低电流和高电流下的导电机制。

Result: 氧空位在畴壁中的能量比在体相中高0.3 eV，这使得空位在畴壁中的浓度增加了几个数量级。氧空位引起的电子带隙态会促进n型导电，并且空位的聚集会促进高电流下的肖特基势垒发射。

Conclusion: 首先，氧空位在铁电畴壁中的能量稳定性高于体相，与局部键的减弱有关。其次，氧空位会在畴壁中诱导局域的极化子电子带隙态，这会在低电流下促进n型导电，并且空位的聚集会促进高电流下的肖特基势垒发射。最后，该研究为理解畴壁导电性提供了定量基础，并为铁电材料中的缺陷工程提供了指导。

Abstract: Enhanced conductivity at ferroelectric domain walls in BiFeO$_3$ has been
widely observed, yet the microscopic origins of this effect, including
electronic contributions from domain-wall defects, are incompletely understood
at the atomistic level. Here, we carry out first-principles simulations to
quantify the thermodynamic stability and electronic impact of oxygen vacancies
at charge-neutral 71$^\circ$, 109$^\circ$, and 180$^\circ$ domain walls of
BiFeO$_3$. We find that vacancies are energetically favored at domain walls by
up to 0.3 eV compared to the bulk, leading to orders-of-magnitude increase in
vacancy equilibrium concentration. The corresponding formation energy
landscapes are discontinued and explained by local bond weakening. The
vacancies induce localized electronic intragap states corresponding to small
polarons, which promote thermally activated n-type conduction in the
low-current regime, and their tendency to aggregate facilitate Schottky
emission in the high-current regime. Our results provide a quantitative
foundation for interpreting domain-wall conduction, offer guidance for defect
engineering in ferroelectrics, and provide important information to phase-field
simulations of defect-domain wall interactions in a ferroelectric domain
structure.

</details>


### [387] [Ultrasensitive Room-Temperature NO2 Gas Sensor Based on In2O3-NbS2 Heterojunction](https://arxiv.org/abs/2507.11864)
*P K Shihabudeen,Alex Sam,Shih-Wen Chiu,Ta-Jen Yen,Kea-Tiong Tang*

Main category: cond-mat.mtrl-sci

TL;DR: A new NO2 gas sensor was created using NbS2 and In2O3 films, showing high performance.


<details>
  <summary>Details</summary>
Motivation: Investigating the potential of NbS2, a 2D transition metal dichalcogenide with semi-metallic conductivity and high surface activity, for electronic and sensing applications.

Method: Fabrication of a heterostructure comprising a spin-coated In2O3 film on a semi-metallic NbS2 film.

Result: A high-performance NO2 gas sensor was developed.

Conclusion: The study reports a high-performance NO2 gas sensor based on a heterostructure comprising a spin-coated In2O3 film on a semi-metallic NbS2 film.

Abstract: Niobium disulfide (NbS2), a two-dimensional transition metal dichalcogenide
with semi metallic conductivity and high surface activity, offers promising
properties for electronic and sensing applications. In this study, we report a
high-performance NO2 gas sensor based on a heterostructure comprising a
spin-coated In2O3 film on a semi-metallic NbS2 film.

</details>


### [388] [Single domain spectroscopic signatures of a magnetic Kagome metal](https://arxiv.org/abs/2507.12085)
*L. Plucinski,G. Bihlmayer,Y. Mokrousov,Yishui Zhou,Yixi Su,A. Bostwick,C. Jozwiak,E. Rotenberg,D. Usachov,C. M. Schneider*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究利用μ-CD-ARPES技术成功获取了Kagome磁性金属DyMn6Sn6的单磁畴电子结构和磁性信息，揭示了Dy和Mn的磁矩排列方式，并首次实现了对其轨道磁化的光谱学研究，为进一步研究新型磁性材料的磁相提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 为了获得量子材料（如量子几何张量）的关键性质，需要能够分辨自旋和轨道的电子能带。尽管近期对磁性Kagome化合物的研究有所复苏，但由于畴尺寸小和缺乏合适的技术，一直无法对其磁性进行光谱学测量。此外，其真实空间的磁构型复杂且依赖于温度。本研究旨在解决这些问题。

Method: 研究使用高分辨率微聚焦圆二向色性角分辨光电子能谱（μ-CD-ARPES）技术。

Result: 研究成功分辨了DyMn6Sn6的磁畴，并获得了Dy 4f和Mn 3p能级的磁性信息。实验结果与基于Hartree-Fock方法的模型计算结果吻合，揭示了Dy和Mn局域磁矩的 the ferrimagnetic alignment。此外，通过与ab initio电子结构计算的比较，研究将Mn 3d主导的价带的特征与轨道磁化联系起来。

Conclusion: 本研究通过μ-CD-ARPES技术实现了对Kagome磁性金属DyMn6Sn6的单磁畴（包括Dy 4f和Mn 3p能级）的光谱学研究，并首次获得了其电子带的自旋和轨道分辨信息。

Abstract: Spin- and orbital-resolved access to the electronic bands is necessary to
establish key properties of quantum materials such as the quantum-geometric
tensor. Despite recent revival on magnetic Kagome compounds, no spectroscopic
access to their magnetic properties has been available so far due to small
domain sizes and lack of appropriate techniques. Furthermore, their real space
magnetic texture is often complex and temperature-dependent. We investigate the
magnetic Kagome metal DyMn$_6$Sn$_6$ using high-resolution micro-focused
circular-dichroic angle-resolved photoemission ($\mu$-CD-ARPES) to probe its
magnetic and electronic properties. By tuning the kinetic energy to various
features of the Dy $4f$ multiplet, we resolve magnetic domains in samples
cryo-cooled down to 20 K. Smaller, but clear signatures are detected in the Mn
$3p$ levels. The behavior of both Dy $4f$ and Mn $3p$ features are in
remarkable agreement with our modeling based on the Hartree-Fock method,
revealing ferrimagnetic alignment of Dy and Mn local moments, and further
strengthening our interpretation. Adjusting the energy to the Mn $3d$-dominated
valence bands reveals signatures which we relate to the orbital magnetization
through a comparison to {\it ab initio} electronic structure calculations. Our
study establishes the spectroscopic access to a single magnetic domain in a
Kagome metal, paving the way for further research into imaging magnetic phases
of novel magnetic materials using $\mu$-CD-ARPES.

</details>


### [389] [Circular dichroism in the photoelectron angular distribution of achiral molecules](https://arxiv.org/abs/2507.12113)
*Christian S. Kern,Xiaosheng Yang,Giovanni Zamborlini,Simone Mearini,Matteo Jugovac,Vitaliy Feyer,Umberto De Giovannini,Angel Rubio,Serguei Soubatch,Michael G. Ramsey,F. Stefan Tautz,Peter Puschnig*

Main category: cond-mat.mtrl-sci

TL;DR: CDAD在非手性体系中源于光电子终态，可通过散射模型分析。


<details>
  <summary>Details</summary>
Motivation: 研究非手性有机分子在金属衬底界面处CDAD的产生机制。

Method: 通过实验CDAD动量图与依赖时空调密度泛函理论的模拟进行对比，并采用简单的散射模型来分析终态。

Result: 展示了非手性体系光电子的终态是CDAD的来源，并能分解CDAD信号为部分波的贡献。

Conclusion: CDAD信号源于非手性体系光电子的终态，其CDAD信号可分解为部分波的贡献。

Abstract: Circular dichroism in the angular distribution (CDAD) is the effect that the
angular intensity distribution of photoemitted electrons depends on the
handedness of the incident circularly polarized light. A CDAD may arise from
intrinsic material properties like chirality, spin-orbit interaction, or
quantum-geometrical effects on the electronic structure. In addition, CDAD has
also been reported for achiral organic molecules at the interface to metallic
substrates. For this latter case, we investigate two prototypical
$\pi$-conjugated molecules, namely tetracene and pentacene, whose frontier
orbitals have a similar shape but exhibit distinctly different symmetries. By
comparing experimental CDAD momentum maps with simulations within
time-dependent density functional theory, we show how the final state of the
photoelectron must be regarded as the source of the CDAD in such otherwise
achiral systems. We gain additional insight into the mechanism by employing a
simple scattering model for the final state, which allows us to decompose the
CDAD signal into partial wave contributions.

</details>


### [390] [Cryogenic spin 3/2 nuclear quadrupole resonance: Spin relaxation and electric field gradient via Rabi frequency goniometry](https://arxiv.org/abs/2507.12279)
*Ritik R. Modi,Karen L. Sauer*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究提出了一种利用NQR光谱确定单晶样品上自旋为3/2的核的电场梯度主轴坐标系的方法，并成功应用于35Cl的氯化钾单晶样品。研究还进行了低温下的弛豫时间测量，并展示了在无低温恒温器中进行NQR实验的可行性。


<details>
  <summary>Details</summary>
Motivation: 为了找到一种简单的方法来确定单晶样品上自旋为3/2的核的电场梯度主轴坐标系，并探索在无低温恒温器中进行NQR实验的可行性。

Method: 利用核四极共振(NQR)光谱学，通过比较粉末和单晶样品在不同激发方向下的NQR信号，来确定35Cl的拉比频率，并据此确定EFG-PAF。

Result: 成功确定了35Cl在KClO3单晶样品上的EFG-PAF，并测量了在17K至200K温度范围内以及在无低温恒温器中进行的T1和T2*弛豫时间。

Conclusion: 本研究提出了一种确定自旋为3/2的核在单晶样品上电场梯度主轴坐标系(EFG-PAF)的简单方法，并成功应用于35Cl的氯化钾(KClO3)单晶样品。研究还测量了在17K至200K温度范围内，以及在无低温恒温器中进行实验时，T1和T2*弛豫时间。

Abstract: A straightforward way to determine the electric field gradient $-$ principal
axes frame (EFG-PAF) on single crystal samples with spin 3/2 nuclei is
demonstrated. Nuclear quadrupole resonance (NQR) spectroscopy is used to
determine the Rabi frequency for $^{35}$Cl in a single crystal of potassium
chlorate (KClO$_3$) by comparing the NQR signal for powder and single crystal
samples. By exploiting the geometrical dependence of the Rabi frequency with
respect to the excitation direction, EFG-PAF is readily determined.
Furthermore, relaxation times $T_1$ and $T_2^*$ were measured at multiple
temperatures ranging from $17~\textrm{K}$ to $200 ~$K, extending the results of
previous works to colder temperatures where new relaxation mechanisms become
dominant. The experiments were performed in a cryogen-free cryostat, which
posed distinct challenges compared to a conventional cryogenic cooling setup.
The successful operation of the NQR probe within a cryogen-free cryostat has
the potential to make the technique more accessible and widen applications.

</details>


### [391] [Ab initio study of flexoelectricity in MXene monolayers](https://arxiv.org/abs/2507.12293)
*Shashikant Kumar,Zixi Zhang,Phanish Suryanarayana*

Main category: cond-mat.mtrl-sci

TL;DR: MXene单层材料具有显著的压电效应，氮化物基MXene表现尤为突出。


<details>
  <summary>Details</summary>
Motivation: 研究MXene单层材料的压电效应。

Method: 使用Kohn-Sham密度泛函理论计算了126种MXene单层材料沿两个主方向的横向压电系数。

Result: 计算得到的压电系数范围为0.19e至1.3e，并且在两个主方向上几乎各向同性。研究发现，过渡金属对压电响应有显著影响，氮化物基MXene的压电系数普遍高于碳化物基MXene。此外，压电系数随结构厚度的增加而增加，但经过弯曲模量归一化后，趋势则相反。

Conclusion: MXene单层材料的压电效应具有很大的潜力，特别是在氮化物基MXene中，其系数与结构厚度成正比，但与弯曲模量成反比。

Abstract: We investigate flexoelectricity in MXene monolayers from first principles.
Specifically, we compute the transverse flexoelectric coefficients of 126 MXene
monolayers along their two principal directions using Kohn-Sham density
functional theory. The values span a wide range from 0.19$e$ to 1.3$e$ and are
nearly isotropic with respect to bending direction. The transition metal is
found to play a significant role in the flexoelectric response, with
nitride-based MXenes consistently displaying larger coefficients than their
carbide counterparts. Moreover, the coefficients increase with structural
thickness, but when normalized by the bending modulus, which is also computed
for all 126 monolayers, they exhibit the opposite trend.

</details>


### [392] [Magnetic and ferroelectric phase diagram of twisted CrI$_3$ layers](https://arxiv.org/abs/2507.12324)
*Haoshen Ye,Shuai Dong*

Main category: cond-mat.mtrl-sci

TL;DR: CrI3 的扭转超晶格中的结构弛豫会影响磁性，但对铁电性具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管电子结构方面的扭转子学已有大量发现，但铁性莫尔纹理较为平淡，因此受到的关注较少。

Method: 通过 CrI3 模型系统，证明层间堆叠势能自发导致结构弛豫，这对于理解扭转超晶格中的铁性至关重要。

Result: 层间堆叠势能自发导致结构弛豫，影响扭转超晶格中的磁基态。 扭转双层 CrI3 中的磁泡被消除，而铁电涡旋则因拓扑保护而更加鲁棒。

Conclusion: 忽略扭转双层 CrI3 中磁泡的预期行为，但由于拓扑保护，铁电涡旋对结构弛豫、扭转角和厚度具有鲁棒性。

Abstract: Twisting layers provide a rich ore for exotic physics in low dimensions.
Despite the abundant discoveries of twistronics from the aspect of electronic
structures, ferroic moir\'e textures are more plain and thus less concerned.
Rigid lattice models are straightforward which can give a rough but intuitional
description in most cases. However, taking CrI$_3$ as a model system, here we
will demonstrate that the interlayer stacking potential can spontaneously lead
to structural relaxation, which plays a vital role to understand the ferroicity
in the twisted superlattices. The magnetic ground state is sensitive to the
stacking mode and twisting angles, which can be seriously affected by the
structural relaxation. In particular, the expected magnetic bubbles are
annihilated in its bilayer. In contrast, due to topological protection, the
ferroelectric vortices are more robust to structural relaxation, as well as
twisting angle and thickness.Due to the universal existence of spontaneous
structural relaxation in twisted superlattices, our work may lead to a general
revisitation of emerging physics of twistronics.

</details>


### [393] [Material-Limited Switching in Nanoscale Ferroelectrics](https://arxiv.org/abs/2507.12353)
*Tony Chiang,John J. Plombon,Megan K. Lenox,Ian Mercer,Punyashloka Debashis,Mahendra DC,Susan Trolier-McKinstry,Jon-Paul Maria,Jon F. Ihlefeld,Ian A. Young,John T. Heron*

Main category: cond-mat.mtrl-sci

TL;DR: Ferroelectric switching speed is no longer obfuscated by measurement circuits, achieving speeds as fast as ~150 ps in La$_{0.15}$Bi$_{0.85}$FeO$_{3}$ capacitors. This advancement allows for the observation of intrinsic material properties and favorable scaling trends for high-performance computing.


<details>
  <summary>Details</summary>
Motivation: The motivation is to overcome the limitations imposed by the interaction between measurement circuits and ferroelectric switching, which has historically obscured the real material responses at nanosecond timescales and lower.

Method: The paper reports fundamental polarization switching speeds in ferroelectric materials by experimentally distinguishing between circuit-limited and material-limited switching regimes through lateral scaling of island capacitors from micron to nanoscales.

Result: The study reports switching speeds as fast as ~150 ps in La$_{0.15}$Bi$_{0.85}$FeO$_{3}$ capacitors, a fundamental switching limit of ~210 ps in polycrystalline Hf$_{0.5}$Zr$_{0.5}$O$_{2}$ capacitors, and switching times near 20 ns for Al$_{0.92}$B$_{0.08}$N, limited by coercive and breakdown electric fields. It also reports the activation field, instantaneous pseudo-resistivity, and energy-delay in the material-limited regime.

Conclusion: The study establishes a criterion for achieving the material-limited regime in ferroelectric switching, enabling the observation of intrinsic material properties and favorable scaling trends for high-performance computing.

Abstract: The ferroelectric switching speed has been experimentally obfuscated by the
interaction between the measurement circuit and the ferroelectric switching
itself. This has prohibited the observation of real material responses at
nanosecond timescales and lower. Here, fundamental polarization switching
speeds in ferroelectric materials with the perovskite, fluorite, and wurtzite
structures are reported. Upon lateral scaling of island capacitors from micron
to nanoscales, a clear transition from circuit-limited switching to a
material-limited switching regime is observed. In
La$_{0.15}$Bi$_{0.85}$FeO$_{3}$ capacitors, switching is as fast as ~150 ps,
the fastest switching time reported. For polycrystalline
Hf$_{0.5}$Zr$_{0.5}$O$_{2}$ capacitors, a fundamental switching limit of ~210
ps is observed. Switching times for Al$_{0.92}$B$_{0.08}$N are near 20 ns,
limited by the coercive and breakdown electric fields. The activation field,
instantaneous pseudo-resistivity, and energy-delay are reported in this
material-limited regime. Lastly, a criterion for reaching the material-limited
regime is provided. This regime enables observation of intrinsic material
properties and favorable scaling trends for high-performance computing.

</details>


### [394] [Towards dislocation-driven quantum interconnects](https://arxiv.org/abs/2507.12387)
*Cunzhi Zhang,Victor Wen-zhe Yu,Yu Jin,Jonah Nagura,Sevim Polat Genlik,Maryam Ghazisaeidi,Giulia Galli*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究提出在半导体和绝缘体的位错处刻蚀自旋量子比特，以实现量子互连。研究发现，这种方法可以工程化具有良好光学和电荷特性的自旋缺陷，并改善NV中心的相干性。最后，预测的光谱有助于识别缺陷。


<details>
  <summary>Details</summary>
Motivation: 为了实现量子互连的鲁棒架构，即量子技术部署中的核心问题，本研究提出了一种在半导体和绝缘体中通过在位错处刻蚀自旋量子比特来构建互连的方法，从而形成准一维纠缠点缺陷线。

Method: 利用第一性原理计算，结合了先进的计算方法，研究了金刚石中氮-空位（NV）中心在位错附近的光学周期和相干特性。

Result: 研究表明，可以工程化具有类似于其块状对应物的特性的自旋缺陷，包括电荷稳定性和有利的光学周期。此外，靠近位错的NV中心的相干特性得到了显著改善。最后，研究预测了可能有助于实验识别特定缺陷构型的光学探测磁共振光谱。

Conclusion: 该研究为固态中一维自旋缺陷阵列的工程化提供了理论基础。

Abstract: A central problem in the deployment of quantum technologies is the
realization of robust architectures for quantum interconnects. We propose to
engineer interconnects in semiconductors and insulators by patterning spin
qubits at dislocations, thus forming quasi one-dimensional lines of entangled
point defects. To gain insight into the feasibility and control of
dislocation-driven interconnects, we investigate the optical cycle and
coherence properties of nitrogen-vacancy (NV) centers in diamond, in proximity
of dislocations, using a combination of advanced first-principles calculations.
We show that one can engineer spin defects with properties similar to those of
their bulk counterparts, including charge stability and a favorable optical
cycle, and that NV centers close to dislocations have much improved coherence
properties. Finally, we predict optically detected magnetic resonance spectra
that may facilitate the experimental identification of specific defect
configurations. Our results provide a theoretical foundation for the
engineering of one-dimensional arrays of spin defects in the solid state.

</details>


### [395] [Revealing the impact of chemical short-range order on radiation damage in MoNbTaVW high-entropy alloys using a machine-learning potential](https://arxiv.org/abs/2507.12388)
*Jiahui Liu,Shuo Cao,Yanzhou Wang,Zheyong Fan,Guocai Lv,Ping Qian,Yanjing Su*

Main category: cond-mat.mtrl-sci

TL;DR: CSRO在MoNbTaVW合金中能提升抗辐照能力，但其稳定性不足，在辐照下会退化，影响长期效果。


<details>
  <summary>Details</summary>
Motivation: 研究化学短程有序（CSRO）对MoNbTaVW高熵合金中主要辐射损伤的影响，并探讨其在辐射下的稳定性和对辐射抗性的长期影响。

Method: 使用混合蒙特卡洛/分子动力学模拟和机器学习势能，研究了化学短程有序（CSRO）对MoNbTaVW高熵合金中主要辐照损伤的影响。

Result: CSRO通过促进间隙扩散和抑制空位迁移来增强抗辐照能力，从而在恢复阶段提高缺陷复合效率。然而，CSRO在累积辐照下会迅速退化，在0.03 dpa的剂量下，Warren-Cowley参数会降至0.3以下。这种有序性的丧失降低了CSRO对辐射抗性的长期增强作用。

Conclusion: CSRO可以有效提高MoNbTaVW的抗辐照能力，但其在辐照下的稳定性对于实现和维持这种益处至关重要。

Abstract: The effect of chemical short-range order (CSRO) on primary radiation damage
in MoNbTaVW high-entropy alloys is investigated using hybrid Monte
Carlo/molecular dynamics simulations with a machine-learned potential. We show
that CSRO enhances radiation tolerance by promoting interstitial diffusion
while suppressing vacancy migration, thereby increasing defect recombination
efficiency during recovery stage. However, CSRO is rapidly degraded under
cumulative irradiation, with Warren-Cowley parameters dropping below 0.3 at a
dose of only 0.03~dpa. This loss of ordering reduces the long-term enhancement
of CSRO on radiation resistance. Our results highlight that while CSRO can
effectively improve the radiation tolerance of MoNbTaVW, its stability under
irradiation is critical to realizing and sustaining this benefit.

</details>


### [396] [Topological quantum materials: kagome, chiral, and square-net frameworks](https://arxiv.org/abs/2507.12410)
*Avdhesh K. Sharma,Snehashish Chatterjee,Premakumar Yanda,Claudia Felser,Chandra Shekhar*

Main category: cond-mat.mtrl-sci

TL;DR: 本文综述了kagome、手征和方网状结构拓扑量子材料的几何、对称性、自旋-轨道耦合和电子关联等因素如何影响其独特的电子能带结构和物理性质，并讨论了其最新的实验发现、合成路线以及面临的挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 文章旨在探讨拓扑量子材料，特别是具有狄拉克和外尔费米子、节点线半金属、平坦能带、范霍夫奇点、电荷密度波、超导电性、非平凡贝里相位以及非线性电和热输运等特性的kagome、手征和方网状结构材料。

Method: 本文通过综述，探讨了几何、对称性、自旋-轨道耦合和电子关联在这些材料中的作用，并介绍了它们的晶体结构如何产生独特的电子能带结构、受拓扑保护的态以及不同的物理性质，同时强调了高质量单晶的制备是研究这些性质的关键。

Result: 文章回顾了这三类材料的最新实验发现和关键材料的合成路线，并指出了当前在设计和探索拓扑量子材料方面面临的挑战和未来的发展方向。

Conclusion: 文章总结了拓扑量子材料在凝聚态物理和材料科学中的前沿地位，重点介绍了kagome、手征和方网状结构这三类材料的独特之处。

Abstract: Topological quantum materials have emerged as a frontier in condensed matter
physics as well as in materials science, with intriguing electronic states that
are robust to perturbations. Among the diverse structural motifs, kagome,
chiral, and square-net structures offer a wide range of topological phases and
physical phenomena. These include Dirac and Weyl fermions, nodal-line
semimetals, flat bands, van Hove singularities, charge density waves,
superconductivity, nontrivial Berry phase, nonlinear electrical and thermal
transports. This review explores the distinct roles of geometry, symmetry,
spin-orbit coupling, and electron correlations in these three classes of
materials. It also highlights how their crystallographic features give rise to
unique electronic band structures, topologically protected states and different
physical properties, which require high-quality-single crystals. The present
discussion comprises recent experimental discoveries and identification of the
synthesis routes of key materials within each framework. Finally, the review
outlines the current challenges and future directions in the design and
exploration of topological quantum materials.

</details>


### [397] [Alkali doping of Zn$_{\rm x}$Mg$_{\rm 1-x}$O alloys for $p$-type conductivity](https://arxiv.org/abs/2507.12446)
*John L. Lyons*

Main category: cond-mat.mtrl-sci

TL;DR: Zn$_{x}$Mg$_{1-x}$O合金是实现p型超宽带隙氧化物的有希望的系统。


<details>
  <summary>Details</summary>
Motivation: 克服超宽带隙氧化物中普遍存在的空穴局域化问题，以实现p型导电性

Method: 通过研究氧化锌和氧化镁的合金在岩盐结构中的性质

Result: Zn$_{x}$Mg$_{1-x}$O合金在稳定的岩盐晶体结构中可以实现p型掺杂，并且带隙超过4 eV，这与之前的研究一致，即岩盐结构氧化锌对空穴极化子不敏感。

Conclusion: 碱金属掺杂的Zn$_{x}$Mg$_{1-x}$O合金有望实现p型掺杂的超宽带隙氧化物

Abstract: Nearly all ultrawide-bandgap oxides are affected by hole localization that
limits $p$-type conductivity and thus potential applications for these
materials. Highly localized holes, also known as hole polarons, trap in the
vicinity of acceptor dopants, giving rise to large ionization energies and
severely constraining free hole concentrations. Though this hole-trapping
behavior affects wurtzite zinc oxide, rocksalt zinc oxide was recently found to
be resistant to the formation of hole polarons. Moreover, $p$-type doping using
lithium acceptors was predicted to be achievable. While rocksalt zinc oxide is
metastable and has a band gap near $\sim$3 eV, here it is found that zinc
magnesium oxide (Zn$_{\rm x}$Mg$_{\rm 1-x}$O) alloys remain $p$-type dopable
within the stable rocksalt crystal structure, in addition to exhibiting band
gaps in excess of 4 eV. As in rocksalt zinc oxide, alkali acceptors are shallow
in zinc magnesium oxide and do not appear to be affected by donor compensation.
These results indicate that alkali-doped Zn$_{\rm x}$Mg$_{\rm 1-x}$O alloys are
a promising system for achieving a $p$-type dopable ultrawide-bandgap oxide.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [398] [Emergent Heterogeneous Swarm Control Through Hebbian Learning](https://arxiv.org/abs/2507.11566)
*Fuda van Diggelen,Tugay Alperen Karagüzel,Andres Garcia Rincon,A. E. Eiben,Dario Floreano,Eliseo Ferrante*

Main category: cs.NE

TL;DR: Hebbian learning allows robot swarms to automatically develop diverse behaviors (heterogeneity) using only local information, simplifying learning and improving performance, and can replace traditional methods like MARL.


<details>
  <summary>Details</summary>
Motivation: To address challenges in learning heterogeneous control for swarm robotics, including the micro-macro problem, curse of dimensionality, and the need for extensive prior knowledge.

Method: Introducing Hebbian learning, a biologically inspired neural adaptation relying solely on local information, as a novel method for swarm robotics.

Result: Demonstrated the natural emergence of heterogeneity, resulting in swarm-level behavioural switching and significantly improved swarm capabilities. Also showed Hebbian learning rules as a valid alternative to MARL in standard benchmarking tasks.

Conclusion: Hebbian learning enables the automatic emergence of heterogeneity in swarm robotics, leading to behavioural switching and improved swarm capabilities. It offers a viable alternative to Multi Agent Reinforcement Learning for benchmarking tasks.

Abstract: In this paper, we introduce Hebbian learning as a novel method for swarm
robotics, enabling the automatic emergence of heterogeneity. Hebbian learning
presents a biologically inspired form of neural adaptation that solely relies
on local information. By doing so, we resolve several major challenges for
learning heterogeneous control: 1) Hebbian learning removes the complexity of
attributing emergent phenomena to single agents through local learning rules,
thus circumventing the micro-macro problem; 2) uniform Hebbian learning rules
across all swarm members limit the number of parameters needed, mitigating the
curse of dimensionality with scaling swarm sizes; and 3) evolving Hebbian
learning rules based on swarm-level behaviour minimises the need for extensive
prior knowledge typically required for optimising heterogeneous swarms. This
work demonstrates that with Hebbian learning heterogeneity naturally emerges,
resulting in swarm-level behavioural switching and in significantly improved
swarm capabilities. It also demonstrates how the evolution of Hebbian learning
rules can be a valid alternative to Multi Agent Reinforcement Learning in
standard benchmarking tasks.

</details>


### [399] [Survey of Genetic and Differential Evolutionary Algorithm Approaches to Search Documents Based On Semantic Similarity](https://arxiv.org/abs/2507.11751)
*Chandrashekar Muniyappa,Eunjin Kim*

Main category: cs.NE

TL;DR: 本文主要探讨了在文档检索领域，利用遗传算法和差分进化算法进行语义文本相似性搜索的最新进展，旨在解决大规模数据中文档识别的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决在大规模数据中识别相似文档的挑战。

Method: 对文档的语义文本相似性搜索的研究，侧重于遗传算法和差分进化算法。

Result: 深入探讨了深度神经网络和进化计算算法（如遗传算法和差分进化算法）在文档相似性搜索方面的最新进展。

Conclusion: 对基于遗传和差分进化计算算法的文档语义文本相似性搜索的最新进展进行了探讨。

Abstract: Identifying similar documents within extensive volumes of data poses a
significant challenge. To tackle this issue, researchers have developed a
variety of effective distributed computing techniques. With the advancement of
computing power and the rise of big data, deep neural networks and evolutionary
computing algorithms such as genetic algorithms and differential evolution
algorithms have achieved greater success. This survey will explore the most
recent advancements in the search for documents based on their semantic text
similarity, focusing on genetic and differential evolutionary computing
algorithms.

</details>


### [400] [Simulated Language Acquisition in a Biologically Realistic Model of the Brain](https://arxiv.org/abs/2507.11788)
*Daniel Mitropolsky,Christos Papadimitriou*

Main category: cs.NE

TL;DR: 提出了一种简单的数学模型和模拟系统，能够学习语言，并能生成新的句子。


<details>
  <summary>Details</summary>
Motivation: 尽管神经科学取得了巨大进步，但我们仍然缺乏关于大脑神经元放电如何产生高级认知现象（如规划和语言）的令人信服的叙述。

Method: 提出了一种基于六个基本神经科学原理（兴奋性神经元、大脑区域、随机突触、赫布可塑性、局部抑制和区域间抑制）的数学形式化，并实现了一个模拟神经形态系统。

Result: 模拟神经形态系统能够从零开始，通过接触适量的基础句子，学习任何语言的语义、词性（动词或名词）以及词序，并能生成新的句子。

Conclusion: 该模型能够学习任何语言的语义、词性（动词或名词）以及词序，并能生成新的句子。

Abstract: Despite tremendous progress in neuroscience, we do not have a compelling
narrative for the precise way whereby the spiking of neurons in our brain
results in high-level cognitive phenomena such as planning and language. We
introduce a simple mathematical formulation of six basic and broadly accepted
principles of neuroscience: excitatory neurons, brain areas, random synapses,
Hebbian plasticity, local inhibition, and inter-area inhibition. We implement a
simulated neuromorphic system based on this formalism, which is capable of
basic language acquisition: Starting from a tabula rasa, the system learns, in
any language, the semantics of words, their syntactic role (verb versus noun),
and the word order of the language, including the ability to generate novel
sentences, through the exposure to a modest number of grounded sentences in the
same language. We discuss several possible extensions and implications of this
result.

</details>
