<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 91]
- [cs.CL](#cs.CL) [Total: 49]
- [eess.SP](#eess.SP) [Total: 9]
- [cs.RO](#cs.RO) [Total: 16]
- [cs.AI](#cs.AI) [Total: 21]
- [cs.LO](#cs.LO) [Total: 6]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.GR](#cs.GR) [Total: 5]
- [math.OC](#math.OC) [Total: 1]
- [cs.NE](#cs.NE) [Total: 3]
- [cs.GT](#cs.GT) [Total: 2]
- [cs.DC](#cs.DC) [Total: 15]
- [cs.ET](#cs.ET) [Total: 1]
- [cs.DS](#cs.DS) [Total: 5]
- [eess.SY](#eess.SY) [Total: 18]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 11]
- [cs.SI](#cs.SI) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 21]
- [cs.LG](#cs.LG) [Total: 63]
- [quant-ph](#quant-ph) [Total: 37]
- [cs.AR](#cs.AR) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Lumina-mGPT 2.0: Stand-Alone AutoRegressive Image Modeling](https://arxiv.org/abs/2507.17801)
*Yi Xin,Juncheng Yan,Qi Qin,Zhen Li,Dongyang Liu,Shicheng Li,Victor Shea-Jay Huang,Yupeng Zhou,Renrui Zhang,Le Zhuo,Tiancheng Han,Xiaoqing Sun,Siqi Luo,Mengmeng Wang,Bin Fu,Yuewen Cao,Hongsheng Li,Guangtao Zhai,Xiaohong Liu,Yu Qiao,Peng Gao*

Main category: cs.CV

TL;DR: Lumina-mGPT 2.0 is a new autoregressive model trained from scratch that achieves diffusion-level image quality, works across multiple tasks like editing and synthesis, and is faster with new decoding methods. It's a strong, flexible foundation model for multimodal generation.


<details>
  <summary>Details</summary>
Motivation: To revitalize the autoregressive paradigm for high-quality image generation and beyond, offering an alternative to existing approaches that rely on pretrained components or hybrid architectures. The goal is to achieve comparable quality to diffusion models while maintaining the flexibility and compositionality of autoregressive modeling.

Method: Lumina-mGPT 2.0 is a stand-alone, decoder-only autoregressive model trained from scratch. It uses a unified tokenization scheme and incorporates efficient decoding strategies like inference-time scaling and speculative Jacobi sampling.

Result: Achieves generation quality on par with state-of-the-art diffusion models like DALL-E 3 and SANA. Demonstrates strong performance on text-to-image benchmarks (GenEval, DPG) and multi-task capabilities on the Graph200K benchmark. Effectively handles various tasks including subject-driven generation, image editing, controllable synthesis, and dense prediction within a single framework.

Conclusion: Lumina-mGPT 2.0 is a powerful and flexible foundation model for unified multimodal generation, matching and sometimes exceeding the performance of diffusion-based models.

Abstract: We present Lumina-mGPT 2.0, a stand-alone, decoder-only autoregressive model
that revisits and revitalizes the autoregressive paradigm for high-quality
image generation and beyond. Unlike existing approaches that rely on pretrained
components or hybrid architectures, Lumina-mGPT 2.0 is trained entirely from
scratch, enabling unrestricted architectural design and licensing freedom. It
achieves generation quality on par with state-of-the-art diffusion models such
as DALL-E 3 and SANA, while preserving the inherent flexibility and
compositionality of autoregressive modeling. Our unified tokenization scheme
allows the model to seamlessly handle a wide spectrum of tasks-including
subject-driven generation, image editing, controllable synthesis, and dense
prediction-within a single generative framework. To further boost usability, we
incorporate efficient decoding strategies like inference-time scaling and
speculative Jacobi sampling to improve quality and speed, respectively.
Extensive evaluations on standard text-to-image benchmarks (e.g., GenEval, DPG)
demonstrate that Lumina-mGPT 2.0 not only matches but in some cases surpasses
diffusion-based models. Moreover, we confirm its multi-task capabilities on the
Graph200K benchmark, with the native Lumina-mGPT 2.0 performing exceptionally
well. These results position Lumina-mGPT 2.0 as a strong, flexible foundation
model for unified multimodal generation. We have released our training details,
code, and models at https://github.com/Alpha-VLLM/Lumina-mGPT-2.0.

</details>


### [2] [SV3.3B: A Sports Video Understanding Model for Action Recognition](https://arxiv.org/abs/2507.17844)
*Sai Varun Kodathala,Yashwanth Reddy Vutukoori,Rakesh Vunnam*

Main category: cs.CV

TL;DR: SV3.3B是一个轻量级视频理解模型，用于高效的体育视频分析，可在设备端部署，能够生成技术细节丰富、分析性强的体育描述，性能优于GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 解决传统体育视频分析中计算密集、需要服务器端处理且缺乏对运动细节深入理解的挑战。现有方法难以捕捉有意义的体育分析所需、发生在几秒内的细微生物力学转换，如准备、执行和收尾等关键阶段。

Method: 提出SV3.3B，一个包含3.3B参数的轻量级视频理解模型，结合新颖的时间运动差分采样和自监督学习，用于高效的设备端部署。该模型采用DWT-VGG16-LDA关键帧提取机制，识别16个代表性帧，并使用经过掩码去噪预训练的V-DWT-JEPA2编码器和针对体育动作描述生成微调的LLM解码器。

Result: SV3.3B在NSVA篮球数据集子集上，在文本生成指标和体育特定评估标准上均取得了优于GPT-4o等闭源模型的性能，同时计算需求显著降低。在地面真实验证指标上比GPT-4o提高了29.2%，在信息密度、动作复杂性和测量精度等方面也取得了实质性改进。

Conclusion: SV3.3B在NSVA篮球数据集子集上实现了优于GPT-4o等闭源模型，在文本生成和体育特定评估标准上均表现出色，同时计算需求更低，在信息密度、动作复杂性和测量精度等方面有显著提升。

Abstract: This paper addresses the challenge of automated sports video analysis, which
has traditionally been limited by computationally intensive models requiring
server-side processing and lacking fine-grained understanding of athletic
movements. Current approaches struggle to capture the nuanced biomechanical
transitions essential for meaningful sports analysis, often missing critical
phases like preparation, execution, and follow-through that occur within
seconds. To address these limitations, we introduce SV3.3B, a lightweight 3.3B
parameter video understanding model that combines novel temporal motion
difference sampling with self-supervised learning for efficient on-device
deployment. Our approach employs a DWT-VGG16-LDA based keyframe extraction
mechanism that intelligently identifies the 16 most representative frames from
sports sequences, followed by a V-DWT-JEPA2 encoder pretrained through
mask-denoising objectives and an LLM decoder fine-tuned for sports action
description generation. Evaluated on a subset of the NSVA basketball dataset,
SV3.3B achieves superior performance across both traditional text generation
metrics and sports-specific evaluation criteria, outperforming larger
closed-source models including GPT-4o variants while maintaining significantly
lower computational requirements. Our model demonstrates exceptional capability
in generating technically detailed and analytically rich sports descriptions,
achieving 29.2% improvement over GPT-4o in ground truth validation metrics,
with substantial improvements in information density, action complexity, and
measurement precision metrics essential for comprehensive athletic analysis.
Model Available at https://huggingface.co/sportsvision/SV3.3B.

</details>


### [3] [Detail++: Training-Free Detail Enhancer for Text-to-Image Diffusion Models](https://arxiv.org/abs/2507.17853)
*Lifeng Chen,Jiner Wang,Zihao Pan,Beier Zhu,Xiaofeng Yang,Chi Zhang*

Main category: cs.CV

TL;DR: Detail++是一个训练框架，通过渐进式细节注入（PDI）策略和质心对齐损失，解决了T2I模型处理复杂提示（如多对象、多属性）的难题，提高了生成图像的质量和属性绑定准确性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有文本到图像（T2I）生成模型在处理涉及多个具有不同属性的主体等复杂提示时面临的挑战。

Method: 提出了一种名为Detail++的训练框架，并引入了新颖的渐进式细节注入（PDI）策略。该策略将复杂提示分解为一系列简化的子提示，通过分阶段引导生成过程，利用自注意力机制的布局控制能力确保全局构图，再通过交叉注意力机制和测试时的质心对齐损失来精确绑定属性与对象，减少绑定噪声，增强属性一致性。

Result: Detail++显著优于现有方法，尤其在涉及多对象和复杂风格条件的场景下。

Conclusion: Detail++框架在处理包含多个对象和复杂风格条件的情况下，显著优于现有方法。

Abstract: Recent advances in text-to-image (T2I) generation have led to impressive
visual results. However, these models still face significant challenges when
handling complex prompt, particularly those involving multiple subjects with
distinct attributes. Inspired by the human drawing process, which first
outlines the composition and then incrementally adds details, we propose
Detail++, a training-free framework that introduces a novel Progressive Detail
Injection (PDI) strategy to address this limitation. Specifically, we decompose
a complex prompt into a sequence of simplified sub-prompts, guiding the
generation process in stages. This staged generation leverages the inherent
layout-controlling capacity of self-attention to first ensure global
composition, followed by precise refinement. To achieve accurate binding
between attributes and corresponding subjects, we exploit cross-attention
mechanisms and further introduce a Centroid Alignment Loss at test time to
reduce binding noise and enhance attribute consistency. Extensive experiments
on T2I-CompBench and a newly constructed style composition benchmark
demonstrate that Detail++ significantly outperforms existing methods,
particularly in scenarios involving multiple objects and complex stylistic
conditions.

</details>


### [4] [FishDet-M: A Unified Large-Scale Benchmark for Robust Fish Detection and CLIP-Guided Model Selection in Diverse Aquatic Visual Domains](https://arxiv.org/abs/2507.17859)
*Muayad Abujabal,Lyes Saad Saoud,Irfan Hussain*

Main category: cs.CV

TL;DR: 本文提出了FishDet-M，一个包含13个数据集的大型鱼类检测基准，并对28种模型进行了评估。同时，引入了一个基于CLIP的零样本模型选择框架，以适应不同的水下应用场景。


<details>
  <summary>Details</summary>
Motivation: 准确的鱼类检测对于水下生态监测、水产养殖自动化和机器人感知至关重要。然而，实际应用受到数据集碎片化、异构成像条件和不一致评估规程的限制。为了解决这些问题，本文提出了FishDet-M，旨在提供一个统一、标准化且可扩展的鱼类检测基准。

Method: 本文提出了FishDet-M，这是最大的鱼类检测统一基准，整合了13个包含海洋、咸淡水、遮挡和水族馆等多样化水生环境的数据集。所有数据均采用COCO风格的边界框和分割掩码进行统一标注。研究系统性地对28个当代目标检测模型进行了基准测试，涵盖了YOLOv8-v12系列、R-CNN系列和DETR系列模型，并使用了mAP、mAP@50、mAP@75以及尺度相关的AP（AP$_{S}$、AP$_{M}$、AP$_{L}$）和推理性能（延迟、参数量）等标准指标。此外，还引入了一个基于CLIP的模型选择框架，利用视觉-语言对齐能力，为每个输入图像动态选择最合适的检测器，实现了无需集成计算的高性能零样本选择。

Result: 基准测试结果揭示了在FishDet-M上训练的模型在检测性能上的差异，以及不同模型架构在准确性和效率之间的权衡。基于CLIP的模型选择框架在没有集成计算的情况下，实现了高性能的零样本选择，为实时应用提供了可扩展的解决方案。

Conclusion: FishDet-M是一个统一的鱼类检测基准，包含13个跨越不同水生环境的数据集，并提供COCO风格的标注。它对28种当代目标检测模型进行了全面基准测试，评估了准确性和效率。此外，研究引入了一个基于CLIP的模型选择框架，通过视觉-语言对齐实现零样本的动态模型选择，以适应不同场景的应用。FishDet-M为评估水下复杂场景下的目标检测提供了标准化和可复现的平台，并公开了所有数据集、预训练模型和评估工具。

Abstract: Accurate fish detection in underwater imagery is essential for ecological
monitoring, aquaculture automation, and robotic perception. However, practical
deployment remains limited by fragmented datasets, heterogeneous imaging
conditions, and inconsistent evaluation protocols. To address these gaps, we
present \textit{FishDet-M}, the largest unified benchmark for fish detection,
comprising 13 publicly available datasets spanning diverse aquatic environments
including marine, brackish, occluded, and aquarium scenes. All data are
harmonized using COCO-style annotations with both bounding boxes and
segmentation masks, enabling consistent and scalable cross-domain evaluation.
We systematically benchmark 28 contemporary object detection models, covering
the YOLOv8 to YOLOv12 series, R-CNN based detectors, and DETR based models.
Evaluations are conducted using standard metrics including mAP, mAP@50, and
mAP@75, along with scale-specific analyses (AP$_S$, AP$_M$, AP$_L$) and
inference profiling in terms of latency and parameter count. The results
highlight the varying detection performance across models trained on FishDet-M,
as well as the trade-off between accuracy and efficiency across models of
different architectures. To support adaptive deployment, we introduce a
CLIP-based model selection framework that leverages vision-language alignment
to dynamically identify the most semantically appropriate detector for each
input image. This zero-shot selection strategy achieves high performance
without requiring ensemble computation, offering a scalable solution for
real-time applications. FishDet-M establishes a standardized and reproducible
platform for evaluating object detection in complex aquatic scenes. All
datasets, pretrained models, and evaluation tools are publicly available to
facilitate future research in underwater computer vision and intelligent marine
systems.

</details>


### [5] [Real-Time Object Detection and Classification using YOLO for Edge FPGAs](https://arxiv.org/abs/2507.18174)
*Rashed Al Amin,Roman Obermaisser*

Main category: cs.CV

TL;DR: 本研究提出了一种为FPGA优化的YOLOv5系统，用于高效的实时目标检测和分类，适用于边缘设备。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有基于YOLO的目标检测和分类系统在资源效率方面难以满足边缘FPGA平台需求的问题。

Method: 提出了一种基于YOLOv5的资源高效实时目标检测和分类系统，并针对FPGA部署进行了优化。

Result: 实验结果表明，该系统实现了99%的分类准确率、3.5W的功耗和9FPS的处理速度。

Conclusion: 该研究提出了一种基于YOLOv5的资源高效实时目标检测和分类系统，并针对FPGA部署进行了优化，在Xilinx Kria KV260 FPGA板上实现了99%的分类准确率、3.5W的功耗和9FPS的处理速度，证明了其在边缘计算应用中的有效性。

Abstract: Object detection and classification are crucial tasks across various
application domains, particularly in the development of safe and reliable
Advanced Driver Assistance Systems (ADAS). Existing deep learning-based methods
such as Convolutional Neural Networks (CNNs), Single Shot Detectors (SSDs), and
You Only Look Once (YOLO) have demonstrated high performance in terms of
accuracy and computational speed when deployed on Field-Programmable Gate
Arrays (FPGAs). However, despite these advances, state-of-the-art YOLO-based
object detection and classification systems continue to face challenges in
achieving resource efficiency suitable for edge FPGA platforms. To address this
limitation, this paper presents a resource-efficient real-time object detection
and classification system based on YOLOv5 optimized for FPGA deployment. The
proposed system is trained on the COCO and GTSRD datasets and implemented on
the Xilinx Kria KV260 FPGA board. Experimental results demonstrate a
classification accuracy of 99%, with a power consumption of 3.5W and a
processing speed of 9 frames per second (FPS). These findings highlight the
effectiveness of the proposed approach in enabling real-time,
resource-efficient object detection and classification for edge computing
applications.

</details>


### [6] [Towards Facilitated Fairness Assessment of AI-based Skin Lesion Classifiers Through GenAI-based Image Synthesis](https://arxiv.org/abs/2507.17860)
*Ko Watanabe. Stanislav Frolov. Adriano Lucieri. Andreas Dengel*

Main category: cs.CV

TL;DR: 本研究使用 GenAI LightningDiT 模型评估皮肤癌检测器的公平性，发现合成数据是评估公平性的有效方法，但当训练数据与合成数据来源不匹配时会增加评估难度。


<details>
  <summary>Details</summary>
Motivation: 评估和改善深度学习在皮肤癌筛查等领域的公平性至关重要，因为该技术在带来益处的同时，也可能存在未预见的固有偏见。公平性评估的关键挑战在于确保评估数据集能够充分代表不同的个人身份信息 (PII)（性别、年龄和种族）以及其他少数群体。

Method: 本研究利用最先进的生成式人工智能 (GenAI) LightningDiT 模型来评估公开皮肤癌分类器的公平性。

Result: 研究结果表明，使用高度逼真的合成数据进行公平性评估是一种有前景的方向。然而，研究也发现，当用于评估的皮肤癌检测模型所训练的数据与生成合成图像的数据来源不同时，验证公平性会变得困难。

Conclusion: Deep learning 模型在边缘设备上的应用为皮肤癌筛查带来了革命性的潜力，但也伴随着潜在的偏见风险。本研究利用生成式人工智能 (GenAI) LightningDiT 模型评估了公共皮肤癌分类器的公平性，并提出使用高度逼真的合成数据来评估公平性是一种有前景的方向。研究结果表明，当用于评估的皮肤癌检测模型所训练的数据与生成合成图像的数据来源不同时，验证公平性会变得困难。尽管如此，本研究提出的方法为使用合成数据来衡量和提高医学影像 GenAI 系统的公平性提供了一个有价值的新途径。

Abstract: Recent advancements in Deep Learning and its application on the edge hold
great potential for the revolution of routine screenings for skin cancers like
Melanoma. Along with the anticipated benefits of this technology, potential
dangers arise from unforseen and inherent biases. Thus, assessing and improving
the fairness of such systems is of utmost importance. A key challenge in
fairness assessment is to ensure that the evaluation dataset is sufficiently
representative of different Personal Identifiable Information (PII) (sex, age,
and race) and other minority groups. Against the backdrop of this challenge,
this study leverages the state-of-the-art Generative AI (GenAI) LightningDiT
model to assess the fairness of publicly available melanoma classifiers. The
results suggest that fairness assessment using highly realistic synthetic data
is a promising direction. Yet, our findings indicate that verifying fairness
becomes difficult when the melanoma-detection model used for evaluation is
trained on data that differ from the dataset underpinning the synthetic images.
Nonetheless, we propose that our approach offers a valuable new avenue for
employing synthetic data to gauge and enhance fairness in medical-imaging GenAI
systems.

</details>


### [7] [DiNAT-IR: Exploring Dilated Neighborhood Attention for High-Quality Image Restoration](https://arxiv.org/abs/2507.17892)
*Hanzhou Liu,Binghan Li,Chengkai Liu,Mi Lu*

Main category: cs.CV

TL;DR: DiNAT-IR 是一种新的 Transformer 模型，用于图像恢复。它使用扩张邻域注意力和通道感知模块来提高效率和质量，并在各种任务中表现良好。


<details>
  <summary>Details</summary>
Motivation: 为了解决 Transformer 在图像恢复任务中高计算成本的问题，并弥补仅关注通道注意力而可能忽略局部细节的不足。

Method: 提出了一种名为扩张邻域注意力（DiNA）的替代方法，该方法通过结合滑动窗口注意力和混合扩张因子来平衡全局上下文和局部精度。此外，还引入了一个通道感知模块来增强局部注意力，有效整合全局上下文而不会牺牲像素级精度。

Result: DiNAT-IR 在多个基准测试中取得了有竞争力的结果，提供了一种高质量的解决方案。

Conclusion: DiNAT-IR 是一种基于 Transformer 的图像恢复架构，通过结合通道感知模块和扩张邻域注意力，在多个基准测试中取得了有竞争力的结果，为各种低级计算机视觉问题提供了高质量的解决方案。

Abstract: Transformers, with their self-attention mechanisms for modeling long-range
dependencies, have become a dominant paradigm in image restoration tasks.
However, the high computational cost of self-attention limits scalability to
high-resolution images, making efficiency-quality trade-offs a key research
focus. To address this, Restormer employs channel-wise self-attention, which
computes attention across channels instead of spatial dimensions. While
effective, this approach may overlook localized artifacts that are crucial for
high-quality image restoration. To bridge this gap, we explore Dilated
Neighborhood Attention (DiNA) as a promising alternative, inspired by its
success in high-level vision tasks. DiNA balances global context and local
precision by integrating sliding-window attention with mixed dilation factors,
effectively expanding the receptive field without excessive overhead. However,
our preliminary experiments indicate that directly applying this global-local
design to the classic deblurring task hinders accurate visual restoration,
primarily due to the constrained global context understanding within local
attention. To address this, we introduce a channel-aware module that
complements local attention, effectively integrating global context without
sacrificing pixel-level precision. The proposed DiNAT-IR, a Transformer-based
architecture specifically designed for image restoration, achieves competitive
results across multiple benchmarks, offering a high-quality solution for
diverse low-level computer vision problems.

</details>


### [8] [AFRDA: Attentive Feature Refinement for Domain Adaptive Semantic Segmentation](https://arxiv.org/abs/2507.17957)
*Md. Al-Masrur Khan,Durgakant Pushp,Lantao Liu*

Main category: cs.CV

TL;DR: AFR模块通过精炼特征并自适应地平衡局部与全局信息，显著提高了无监督域自适应语义分割的精度，尤其在复杂区域表现更佳。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督域自适应语义分割（UDA-SS）方法在平衡细粒度的局部细节和全局上下文信息方面存在困难，这在复杂区域会导致分割错误。为了解决这个问题，需要一种能够提高分割精度的有效方法。

Method: 提出了一种自适应特征精炼（AFR）模块，该模块通过利用低分辨率的语义先验来精炼高分辨率的特征，并整合捕捉精细结构和提供边界信息的高频分量。AFR模块还通过不确定性驱动的注意力机制自适应地平衡局部和全局信息。

Result: AFR模块将GTA V --> Cityscapes的mIoU提高了1.05%，将Synthia-->Cityscapes的mIoU提高了1.04%，达到了最先进的分割性能。

Conclusion: AFR模块通过融合低分辨率的语义先验和高分辨率的特征，并引入不确定性驱动的注意力机制来平衡局部与全局信息，有效解决了现有UDA-SS方法在处理复杂区域时遇到的分割精度问题。该方法易于集成，并在GTA V --> Cityscapes和Synthia-->Cityscapes数据集上取得了最先进的性能提升。

Abstract: In Unsupervised Domain Adaptive Semantic Segmentation (UDA-SS), a model is
trained on labeled source domain data (e.g., synthetic images) and adapted to
an unlabeled target domain (e.g., real-world images) without access to target
annotations. Existing UDA-SS methods often struggle to balance fine-grained
local details with global contextual information, leading to segmentation
errors in complex regions. To address this, we introduce the Adaptive Feature
Refinement (AFR) module, which enhances segmentation accuracy by refining
highresolution features using semantic priors from low-resolution logits. AFR
also integrates high-frequency components, which capture fine-grained
structures and provide crucial boundary information, improving object
delineation. Additionally, AFR adaptively balances local and global information
through uncertaintydriven attention, reducing misclassifications. Its
lightweight design allows seamless integration into HRDA-based UDA methods,
leading to state-of-the-art segmentation performance. Our approach improves
existing UDA-SS methods by 1.05% mIoU on GTA V --> Cityscapes and 1.04% mIoU on
Synthia-->Cityscapes. The implementation of our framework is available at:
https://github.com/Masrur02/AFRDA

</details>


### [9] [A Multi-Dataset Benchmark for Semi-Supervised Semantic Segmentation in ECG Delineation](https://arxiv.org/abs/2507.18323)
*Minje Park,Jeonghwa Lim,Taehyung Yu,Sunghoon Joo*

Main category: cs.CV

TL;DR: 这项研究首次对心电图描绘的半监督学习进行了基准测试，发现Transformer在处理该任务时优于卷积网络，并为该领域未来的研究提供了标准化框架和数据集。


<details>
  <summary>Details</summary>
Motivation: 深度学习在心电图描绘方面取得了一定的进展，但由于公开标注数据集的稀缺，其发展受到了限制。而半监督学习可以通过利用大量的未标注心电图数据来解决这一问题。

Method: 本文首次对心电图描绘的半监督语义分割（SemiSeg）进行了系统性基准测试。研究者整合了多个公共数据集，并选取了五种具有代表性的SemiSeg算法，将它们应用于卷积网络和Transformer两种不同的网络架构上，并在域内和跨域两种不同设置下进行了评估。此外，研究者还提出了针对心电图的特定训练配置和数据增强策略，并引入了一个标准化的评估框架。

Result: 研究结果表明，在半监督心电图描绘任务中，Transformer架构的性能优于卷积网络架构。

Conclusion: 该基准测试为推动半监督心电图描绘方法的发展奠定了基础，并为该领域进一步研究提供了便利。

Abstract: Electrocardiogram (ECG) delineation, the segmentation of meaningful waveform
features, is critical for clinical diagnosis. Despite recent advances using
deep learning, progress has been limited by the scarcity of publicly available
annotated datasets. Semi-supervised learning presents a promising solution by
leveraging abundant unlabeled ECG data. In this study, we present the first
systematic benchmark for semi-supervised semantic segmentation (SemiSeg) in ECG
delineation. We curated and unified multiple public datasets, including
previously underused sources, to support robust and diverse evaluation. We
adopted five representative SemiSeg algorithms from computer vision,
implemented them on two different architectures: the convolutional network and
the transformer, and evaluated them in two different settings: in-domain and
cross-domain. Additionally, we propose ECG-specific training configurations and
augmentation strategies and introduce a standardized evaluation framework. Our
results show that the transformer outperforms the convolutional network in
semi-supervised ECG delineation. We anticipate that our benchmark will serve as
a foundation for advancing semi-supervised ECG delineation methods and will
facilitate further research in this domain.

</details>


### [10] [OPEN: A Benchmark Dataset and Baseline for Older Adult Patient Engagement Recognition in Virtual Rehabilitation Learning Environments](https://arxiv.org/abs/2507.17959)
*Ali Abedi,Sadaf Safa,Tracey J. F. Colella,Shehroz S. Khan*

Main category: cs.CV

TL;DR: 该研究提出了OPEN数据集，这是最大的老年人虚拟学习参与数据集，包含面部、手部和身体标志点以及情感/行为特征。在对该数据集进行测试后，人工智能模型在识别参与度方面达到了81%的准确率，为个性化参与建模奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 随着在线教育和虚拟康复的兴起，准确测量虚拟群体设置中的参与度变得越来越重要，然而，现有数据集和方法在关注老年人群体和考虑参与度的纵向性方面存在局限性。因此，该研究旨在通过引入一个专门针对老年人的大型数据集来解决这些问题，以支持人工智能驱动的参与度识别。

Method: 该研究引入了OPEN（老年人患者参与）数据集，该数据集包含从11名老年人参与为期六周的每周虚拟小组学习课程（心脏康复的一部分）中收集的数据，产生了超过35小时的数据。为了保护隐私，原始视频被省略，但释放的数据包括面部、手部和身体关节的标志点，以及从视频中提取的情感和行为特征。此外，注释包括二元参与状态、情感和行为标签以及上下文类型指示符（例如，讲师是面向小组还是个人讲话）。该数据集提供了包含5秒、10秒、30秒和可变长度样本的版本。为了证明其实用性，研究人员训练了多种机器学习和深度学习模型，并将参与识别准确率提高到81%。

Result: 所训练的多种机器学习和深度学习模型在参与识别任务上达到了高达81%的准确率。

Conclusion: OPEN提供了一个可扩展的基础，用于在老龄化人群中进行个性化参与建模，并为更广泛的参与识别研究做出了贡献。

Abstract: Engagement in virtual learning is essential for participant satisfaction,
performance, and adherence, particularly in online education and virtual
rehabilitation, where interactive communication plays a key role. Yet,
accurately measuring engagement in virtual group settings remains a challenge.
There is increasing interest in using artificial intelligence (AI) for
large-scale, real-world, automated engagement recognition. While engagement has
been widely studied in younger academic populations, research and datasets
focused on older adults in virtual and telehealth learning settings remain
limited. Existing methods often neglect contextual relevance and the
longitudinal nature of engagement across sessions. This paper introduces OPEN
(Older adult Patient ENgagement), a novel dataset supporting AI-driven
engagement recognition. It was collected from eleven older adults participating
in weekly virtual group learning sessions over six weeks as part of cardiac
rehabilitation, producing over 35 hours of data, making it the largest dataset
of its kind. To protect privacy, raw video is withheld; instead, the released
data include facial, hand, and body joint landmarks, along with affective and
behavioral features extracted from video. Annotations include binary engagement
states, affective and behavioral labels, and context-type indicators, such as
whether the instructor addressed the group or an individual. The dataset offers
versions with 5-, 10-, 30-second, and variable-length samples. To demonstrate
utility, multiple machine learning and deep learning models were trained,
achieving engagement recognition accuracy of up to 81 percent. OPEN provides a
scalable foundation for personalized engagement modeling in aging populations
and contributes to broader engagement recognition research.

</details>


### [11] [Bearded Dragon Activity Recognition Pipeline: An AI-Based Approach to Behavioural Monitoring](https://arxiv.org/abs/2507.17987)
*Arsen Yermukan,Pedro Machado,Feliciano Domingos,Isibor Kennedy Ihianle,Jordan J. Bird,Stefano S. K. Kaburu,Samantha J. Ward*

Main category: cs.CV

TL;DR: 本项目开发了一个基于YOLOv8s的自动化系统，用于监测鬃狮蜥的栖息行为，但对狩猎行为的检测（特别是蟋蟀）仍需改进。


<details>
  <summary>Details</summary>
Motivation: 传统的鬃狮蜥行为监测耗时且容易出错，本项目旨在引入一个自动化的实时视频分析系统。

Method: 使用YOLO目标检测模型（v5、v7、v8、v11、v12）对1200张图像（包括鬃狮蜥、加热灯和蟋蟀）的自定义数据集进行训练，选择了YOLOv8s作为最优模型，并通过逐帧目标坐标提取、时间插值和基于规则的逻辑来处理视频素材，以对特定行为进行分类。

Result: YOLOv8s模型在准确性（mAP@0.5:0.95 = 0.855）和速度之间取得了最佳平衡。鬃狮蜥的栖息行为检测可靠，但狩猎行为检测的准确性较低（mAP@0.5 = 0.392），主要原因是蟋蟀的检测效果不佳。

Conclusion: 该自动化系统为在受控环境中监测爬行动物行为提供了一个可扩展的解决方案，显著提高了研究效率和数据质量。

Abstract: Traditional monitoring of bearded dragon (Pogona Viticeps) behaviour is
time-consuming and prone to errors. This project introduces an automated system
for real-time video analysis, using You Only Look Once (YOLO) object detection
models to identify two key behaviours: basking and hunting. We trained five
YOLO variants (v5, v7, v8, v11, v12) on a custom, publicly available dataset of
1200 images, encompassing bearded dragons (600), heating lamps (500), and
crickets (100). YOLOv8s was selected as the optimal model due to its superior
balance of accuracy (mAP@0.5:0.95 = 0.855) and speed. The system processes
video footage by extracting per-frame object coordinates, applying temporal
interpolation for continuity, and using rule-based logic to classify specific
behaviours. Basking detection proved reliable. However, hunting detection was
less accurate, primarily due to weak cricket detection (mAP@0.5 = 0.392).
Future improvements will focus on enhancing cricket detection through expanded
datasets or specialised small-object detectors. This automated system offers a
scalable solution for monitoring reptile behaviour in controlled environments,
significantly improving research efficiency and data quality.

</details>


### [12] [AG-VPReID.VIR: Bridging Aerial and Ground Platforms for Video-based Visible-Infrared Person Re-ID](https://arxiv.org/abs/2507.17995)
*Huy Nguyen,Kien Nguyen,Akila Pemasiri,Akmal Jahan,Clinton Fookes,Sridha Sridharan*

Main category: cs.CV

TL;DR: 提出AG-VPReID.VIR数据集和TCC-VPReID模型，以解决航空地面跨模态视频行人重识别问题。


<details>
  <summary>Details</summary>
Motivation: 现有数据集主要关注地面视角，而航空视角能够解决地面视角在遮挡、覆盖范围和易受阻碍方面的问题，因此需要跨航空地面视角和可见光红外模态的行人重识别数据集。

Method: 提出了一种名为TCC-VPReID的新型三流网络架构，通过风格鲁棒性特征学习、基于记忆的跨视角适应和中间引导的时间建模来解决跨平台和跨模态的行人重识别的联合挑战。

Result: AG-VPReID.VIR数据集展示了与现有数据集相比的独特挑战，并且TCC-VPReID框架在多个评估协议上实现了显著的性能提升。

Conclusion: TCC-VPReID框架在跨平台和跨模态的行人重识别方面取得了显著的性能提升，并且AG-VPReID.VIR数据集克服了现有数据集的局限性。

Abstract: Person re-identification (Re-ID) across visible and infrared modalities is
crucial for 24-hour surveillance systems, but existing datasets primarily focus
on ground-level perspectives. While ground-based IR systems offer nighttime
capabilities, they suffer from occlusions, limited coverage, and vulnerability
to obstructions--problems that aerial perspectives uniquely solve. To address
these limitations, we introduce AG-VPReID.VIR, the first aerial-ground
cross-modality video-based person Re-ID dataset. This dataset captures 1,837
identities across 4,861 tracklets (124,855 frames) using both UAV-mounted and
fixed CCTV cameras in RGB and infrared modalities. AG-VPReID.VIR presents
unique challenges including cross-viewpoint variations, modality discrepancies,
and temporal dynamics. Additionally, we propose TCC-VPReID, a novel
three-stream architecture designed to address the joint challenges of
cross-platform and cross-modality person Re-ID. Our approach bridges the domain
gaps between aerial-ground perspectives and RGB-IR modalities, through
style-robust feature learning, memory-based cross-view adaptation, and
intermediary-guided temporal modeling. Experiments show that AG-VPReID.VIR
presents distinctive challenges compared to existing datasets, with our
TCC-VPReID framework achieving significant performance gains across multiple
evaluation protocols. Dataset and code are available at
https://github.com/agvpreid25/AG-VPReID.VIR.

</details>


### [13] [Exploring the interplay of label bias with subgroup size and separability: A case study in mammographic density classification](https://arxiv.org/abs/2507.17996)
*Emma A. M. Stanley,Raghav Mehta,Mélanie Roschewitz,Nils D. Forkert,Ben Glocker*

Main category: cs.CV

TL;DR: 医学影像AI中的标签偏倚会影响模型特征和公平性，子群的大小和可分离性是关键因素，偏倚标签的验证集会降低模型性能。


<details>
  <summary>Details</summary>
Motivation: 研究关注医学人工智能系统中因特定子群标签偏倚（标签偏倚）而产生的公平性问题，旨在探究子群大小和可分离性如何影响学习到的特征和模型性能。

Method: 通过在EMory BrEast成像数据集（EMBED）上训练深度学习模型，模拟了影响可分离子群（基于成像制造商）或不可分离“伪子群”的标签偏倚，并分析了模型特征和性能。

Result: 模拟的子群标签偏倚导致模型学习到的特征表示发生显著变化，这些变化取决于受标签偏倚影响子群的相对大小和可分离性。此外，使用带有偏倚标签的验证集定义分类阈值会显著影响子群性能，例如，当偏倚影响多数可分离子群时，该子群的真阳性率从0.898（干净标签验证集）降至0.518（偏倚标签验证集）。

Conclusion: 该研究揭示了标签偏倚对医学影像人工智能中子群公平性的影响，强调了子群大小和可分离性在特征表示和模型性能中的作用。

Abstract: Systematic mislabelling affecting specific subgroups (i.e., label bias) in
medical imaging datasets represents an understudied issue concerning the
fairness of medical AI systems. In this work, we investigated how size and
separability of subgroups affected by label bias influence the learned features
and performance of a deep learning model. Therefore, we trained deep learning
models for binary tissue density classification using the EMory BrEast imaging
Dataset (EMBED), where label bias affected separable subgroups (based on
imaging manufacturer) or non-separable "pseudo-subgroups". We found that
simulated subgroup label bias led to prominent shifts in the learned feature
representations of the models. Importantly, these shifts within the feature
space were dependent on both the relative size and the separability of the
subgroup affected by label bias. We also observed notable differences in
subgroup performance depending on whether a validation set with clean labels
was used to define the classification threshold for the model. For instance,
with label bias affecting the majority separable subgroup, the true positive
rate for that subgroup fell from 0.898, when the validation set had clean
labels, to 0.518, when the validation set had biased labels. Our work
represents a key contribution toward understanding the consequences of label
bias on subgroup fairness in medical imaging AI.

</details>


### [14] [Registration beyond Points: General Affine Subspace Alignment via Geodesic Distance on Grassmann Manifold](https://arxiv.org/abs/2507.17998)
*Jaeho Shin,Hyeonjae Gil,Junwoo Jang,Maani Ghaffari,Ayoung Kim*

Main category: cs.CV

TL;DR: 本文提出了一种新的可优化成本函数，用于配准问题，通过直接最小化测地线距离来改进现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的 Affine Grassmannian 方法虽然能衡量特征间的接近度，但无法将距离表示为刚体变换的显式函数，这阻碍了其在配准问题中的应用。

Method: 提出了一种新的成本函数，该函数基于高维线性子空间的基，并可以针对刚体变换进行优化。该方法直接最小化测地线距离，避免了表示歧义性。

Result: 所提出的成本函数及其 BnB 求解器在各种计算机视觉任务中提高了现有解决方案的收敛性或超越了它们。

Conclusion: 本文首次明确推导了 Grassmannian 特征与刚体变换（R 和 t）之间的可优化成本函数。我们提出了一个基于变换后基的成本函数，它可以应用于任何仿射子空间的配准问题，并且比基于向量参数的方法更能找到全局最优解。

Abstract: Affine Grassmannian has been favored for expressing proximity between lines
and planes due to its theoretical exactness in measuring distances among
features. Despite this advantage, the existing method can only measure the
proximity without yielding the distance as an explicit function of rigid body
transformation. Thus, an optimizable distance function on the manifold has
remained underdeveloped, stifling its application in registration problems.
This paper is the first to explicitly derive an optimizable cost function
between two Grassmannian features with respect to rigid body transformation
($\mathbf{R}$ and $\mathbf{t}$). Specifically, we present a rigorous
mathematical proof demonstrating that the bases of high-dimensional linear
subspaces can serve as an explicit representation of the cost. Finally, we
propose an optimizable cost function based on the transformed bases that can be
applied to the registration problem of any affine subspace. Compared to vector
parameter-based approaches, our method is able to find a globally optimal
solution by directly minimizing the geodesic distance which is agnostic to
representation ambiguity. The resulting cost function and its extension to the
inlier-set maximizing \ac{BnB} solver have been demonstrated to improve the
convergence of existing solutions or outperform them in various computer vision
tasks. The code is available on
https://github.com/joomeok/GrassmannRegistration.

</details>


### [15] [GRR-CoCa: Leveraging LLM Mechanisms in Multimodal Model Architectures](https://arxiv.org/abs/2507.18009)
*Jake R. Patock,Nicole Catherine Lewis,Kevin McCoy,Christina Gomez,Canling Chen,Lorenzo Luzi*

Main category: cs.CV

TL;DR: GRR-CoCa通过整合LLM中的先进架构改进了CoCa模型，在对比和生成任务上均显著提升了性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的SOTA多模态模型虽然性能强大，但在架构先进性方面常落后于LLM。将LLM中已被证明能提升性能的架构修改（高斯误差门控线性单元、均方根归一化、旋转位置嵌入）应用于CoCa模型。

Method: 提出GRR-CoCa，一种改进的SOTA对比字幕模型（CoCa），将高斯误差门控线性单元、均方根归一化和旋转位置嵌入整合到文本解码器和视觉Transformer（ViT）编码器中。通过标准预训练和微调工作流程，在对比和生成任务上对GRR-CoCa与基线CoCa进行了基准测试。

Result: GRR-CoCa在预训练数据集和三个不同的微调数据集上显著优于基线CoCa。预训练方面，对比损失、困惑度和CoCa损失分别提升了27.25%、3.71%和7.15%。平均微调方面，对比损失、困惑度和CoCa损失分别提升了13.66%、5.18%和5.55%。

Conclusion: GRR-CoCa架构的改进提升了模型在视觉-语言领域的性能和泛化能力。

Abstract: State-of-the-art (SOTA) image and text generation models are multimodal
models that have many similarities to large language models (LLMs). Despite
achieving strong performances, leading foundational multimodal model
architectures frequently lag behind the architectural sophistication of
contemporary LLMs. We propose GRR-CoCa, an improved SOTA Contrastive Captioner
(CoCa) model that incorporates Gaussian error gated linear units, root mean
squared normalization, and rotary positional embedding into the textual
decoders and the vision transformer (ViT) encoder. Each architectural
modification has been shown to improve model performance in LLMs, but has yet
to be adopted in CoCa. We benchmarked GRR-CoCa against Baseline CoCa, a model
with the same modified textual decoders but with CoCa's original ViT encoder.
We used standard pretraining and fine-tuning workflows to benchmark the models
on contrastive and generative tasks. Our GRR-CoCa significantly outperformed
Baseline CoCa on the pretraining dataset and three diverse fine-tuning
datasets. Pretraining improvements were 27.25% in contrastive loss, 3.71% in
perplexity, and 7.15% in CoCa loss. The average fine-tuning improvements were
13.66% in contrastive loss, 5.18% in perplexity, and 5.55% in CoCa loss. We
show that GRR-CoCa's modified architecture improves performance and
generalization across vision-language domains.

</details>


### [16] [Celeb-DF++: A Large-scale Challenging Video DeepFake Benchmark for Generalizable Forensics](https://arxiv.org/abs/2507.18015)
*Yuezun Li,Delong Zhu,Xinjie Cui,Siwei Lyu*

Main category: cs.CV

TL;DR: 为了解决 DeepFake 检测的泛化能力问题，我们提出了 Celeb-DF++ 数据集，它比以往的数据集包含更多样化的伪造类型和最新的 DeepFake 技术，并评估了现有检测方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的 DeepFake 检测方法在处理各种未知的 DeepFake 类型时泛化能力不足，主要是因为现有数据集的伪造类型不够多样。

Method: 提出 Celeb-DF++ 数据集，包含 FS、FR、TF 三种场景，使用 22 种最新的 DeepFake 方法生成，并建立评估协议以衡量 24 种最新检测方法的泛化能力。

Result: 评估结果表明，现有检测方法的泛化能力存在局限性，凸显了 Celeb-DF++ 数据集的挑战性。

Conclusion: Celeb-DF++ 作为一个新的大规模、具有挑战性的视频 DeepFake 基准，专注于可泛化的取证，并包含三种常见的伪造场景：换脸 (FS)、面部重演 (FR) 和说话人脸 (TF)。该数据集使用了 22 种不同的最新 DeepFake 方法生成，涵盖了当前流行的 DeepFake 案例。

Abstract: The rapid advancement of AI technologies has significantly increased the
diversity of DeepFake videos circulating online, posing a pressing challenge
for \textit{generalizable forensics}, \ie, detecting a wide range of unseen
DeepFake types using a single model. Addressing this challenge requires
datasets that are not only large-scale but also rich in forgery diversity.
However, most existing datasets, despite their scale, include only a limited
variety of forgery types, making them insufficient for developing generalizable
detection methods. Therefore, we build upon our earlier Celeb-DF dataset and
introduce {Celeb-DF++}, a new large-scale and challenging video DeepFake
benchmark dedicated to the generalizable forensics challenge. Celeb-DF++ covers
three commonly encountered forgery scenarios: Face-swap (FS), Face-reenactment
(FR), and Talking-face (TF). Each scenario contains a substantial number of
high-quality forged videos, generated using a total of 22 various recent
DeepFake methods. These methods differ in terms of architectures, generation
pipelines, and targeted facial regions, covering the most prevalent DeepFake
cases witnessed in the wild. We also introduce evaluation protocols for
measuring the generalizability of 24 recent detection methods, highlighting the
limitations of existing detection methods and the difficulty of our new
dataset.

</details>


### [17] [High-fidelity 3D Gaussian Inpainting: preserving multi-view consistency and photorealistic details](https://arxiv.org/abs/2507.18023)
*Jun Zhou,Dinghao Li,Nannan Li,Mingjie Wang*

Main category: cs.CV

TL;DR: 提出了一种新的3D高斯喷涂修复框架，通过掩码细化和不确定性引导优化，提高了3D场景修复的质量和一致性。


<details>
  <summary>Details</summary>
Motivation: 解决多视图3D重建和新视图合成中的3D场景修复挑战，尤其是在处理3D结构不规则性和保持多视图一致性方面。

Method: 提出了一种新颖的3D高斯喷涂（3DGS）为基础的三维场景修复框架，利用稀疏的修复视图，并通过自动掩码细化过程和区域感知的不确定性引导优化来重建完整的3D场景。

Result: 通过自动掩码细化过程（包括高斯场景过滤和反向投影）和不确定性引导的细粒度优化策略，实现了更准确的遮挡区域定位、逼真的边界恢复，并减轻了多视图不一致性，增强了修复细节的保真度。

Conclusion: 该方法在视觉质量和视图一致性方面优于现有最先进的方法。

Abstract: Recent advancements in multi-view 3D reconstruction and novel-view synthesis,
particularly through Neural Radiance Fields (NeRF) and 3D Gaussian Splatting
(3DGS), have greatly enhanced the fidelity and efficiency of 3D content
creation. However, inpainting 3D scenes remains a challenging task due to the
inherent irregularity of 3D structures and the critical need for maintaining
multi-view consistency. In this work, we propose a novel 3D Gaussian inpainting
framework that reconstructs complete 3D scenes by leveraging sparse inpainted
views. Our framework incorporates an automatic Mask Refinement Process and
region-wise Uncertainty-guided Optimization. Specifically, we refine the
inpainting mask using a series of operations, including Gaussian scene
filtering and back-projection, enabling more accurate localization of occluded
regions and realistic boundary restoration. Furthermore, our Uncertainty-guided
Fine-grained Optimization strategy, which estimates the importance of each
region across multi-view images during training, alleviates multi-view
inconsistencies and enhances the fidelity of fine details in the inpainted
results. Comprehensive experiments conducted on diverse datasets demonstrate
that our approach outperforms existing state-of-the-art methods in both visual
quality and view consistency.

</details>


### [18] [Emotion Recognition from Skeleton Data: A Comprehensive Survey](https://arxiv.org/abs/2507.18026)
*Haifeng Lu,Jiuyi Chen,Zhen Zhang,Ruida Liu,Runhao Zeng,Xiping Hu*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Emotion recognition through body movements has emerged as a compelling and
privacy-preserving alternative to traditional methods that rely on facial
expressions or physiological signals. Recent advancements in 3D skeleton
acquisition technologies and pose estimation algorithms have significantly
enhanced the feasibility of emotion recognition based on full-body motion. This
survey provides a comprehensive and systematic review of skeleton-based emotion
recognition techniques. First, we introduce psychological models of emotion and
examine the relationship between bodily movements and emotional expression.
Next, we summarize publicly available datasets, highlighting the differences in
data acquisition methods and emotion labeling strategies. We then categorize
existing methods into posture-based and gait-based approaches, analyzing them
from both data-driven and technical perspectives. In particular, we propose a
unified taxonomy that encompasses four primary technical paradigms: Traditional
approaches, Feat2Net, FeatFusionNet, and End2EndNet. Representative works
within each category are reviewed and compared, with benchmarking results
across commonly used datasets. Finally, we explore the extended applications of
emotion recognition in mental health assessment, such as detecting depression
and autism, and discuss the open challenges and future research directions in
this rapidly evolving field.

</details>


### [19] [ViGText: Deepfake Image Detection with Vision-Language Model Explanations and Graph Neural Networks](https://arxiv.org/abs/2507.18031)
*Ahmad ALBarqawi,Mahmoud Nazzal,Issa Khalil,Abdallah Khreishah,NhatHai Phan*

Main category: cs.CV

TL;DR: ViGText是一种新的深度伪造检测方法，它结合了视觉和文本信息，通过图神经网络提高了检测的准确性和鲁棒性，特别是在处理定制深度伪造方面。


<details>
  <summary>Details</summary>
Motivation: 传统的深度伪造检测方法在处理复杂的、定制的深度伪造方面常常遇到困难，尤其是在泛化和对抗恶意攻击的鲁棒性方面。本研究引入了一种新颖的方法ViGText，该方法将图像与视觉大型语言模型（VLLM）文本解释集成在一个基于图的框架中，以改进深度伪造检测。

Method: ViGText将图像划分为块，构建图像和文本图，并使用图神经网络（GNNs）进行集成分析以识别深度伪造。它通过跨空间和频率域的多级特征提取来捕捉细节，从而提高其检测复杂深度伪造的鲁棒性和准确性。

Result: ViGText在泛化评估下将平均F1分数从72.45%提高到98.32%，在检测用户定制的深度伪造方面表现出卓越的能力。在鲁棒性方面，ViGText的召回率比其他深度伪造检测方法提高了11.1%。在面对利用其基于图的架构的定向攻击时，ViGText将分类性能下降限制在4%以内。

Conclusion: ViGText设定了检测深度伪造的新标准，通过详细的视觉和文本分析，有助于确保媒体的真实性和信息的完整性。

Abstract: The rapid rise of deepfake technology, which produces realistic but
fraudulent digital content, threatens the authenticity of media. Traditional
deepfake detection approaches often struggle with sophisticated, customized
deepfakes, especially in terms of generalization and robustness against
malicious attacks. This paper introduces ViGText, a novel approach that
integrates images with Vision Large Language Model (VLLM) Text explanations
within a Graph-based framework to improve deepfake detection. The novelty of
ViGText lies in its integration of detailed explanations with visual data, as
it provides a more context-aware analysis than captions, which often lack
specificity and fail to reveal subtle inconsistencies. ViGText systematically
divides images into patches, constructs image and text graphs, and integrates
them for analysis using Graph Neural Networks (GNNs) to identify deepfakes.
Through the use of multi-level feature extraction across spatial and frequency
domains, ViGText captures details that enhance its robustness and accuracy to
detect sophisticated deepfakes. Extensive experiments demonstrate that ViGText
significantly enhances generalization and achieves a notable performance boost
when it detects user-customized deepfakes. Specifically, average F1 scores rise
from 72.45% to 98.32% under generalization evaluation, and reflects the model's
superior ability to generalize to unseen, fine-tuned variations of stable
diffusion models. As for robustness, ViGText achieves an increase of 11.1% in
recall compared to other deepfake detection approaches. When facing targeted
attacks that exploit its graph-based architecture, ViGText limits
classification performance degradation to less than 4%. ViGText uses detailed
visual and textual analysis to set a new standard for detecting deepfakes,
helping ensure media authenticity and information integrity.

</details>


### [20] [Enhancing Scene Transition Awareness in Video Generation via Post-Training](https://arxiv.org/abs/2507.18046)
*Hanwen Shen,Jiajie Lu,Yupeng Cao,Xiaonan Yang*

Main category: cs.CV

TL;DR: TAV数据集通过包含多个场景转换的视频片段，解决了AI视频生成中长视频和场景转换的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前的AI视频生成模型在生成具有连贯场景转换的长视频方面存在困难，因为它们无法从提示中推断何时需要转换。大多数开源模型在仅包含单个场景片段的数据集上进行训练，限制了它们学习和响应需要多个场景的提示的能力。因此，需要开发场景转换意识来实现多场景生成。

Method: 提出TAV（Transition-Aware Video）数据集，该数据集包含具有多个场景转换的预处理视频片段。

Result: 实验表明，在TAV数据集上进行后训练可以提高模型对场景转换的理解，缩小所需场景和生成场景之间的差距，并保持图像质量。

Conclusion: 通过在TAV数据集上进行后训练，可以提高模型对基于提示的场景转换的理解能力，缩小所需场景和生成场景之间的差距，并保持图像质量。

Abstract: Recent advances in AI-generated video have shown strong performance on
\emph{text-to-video} tasks, particularly for short clips depicting a single
scene. However, current models struggle to generate longer videos with coherent
scene transitions, primarily because they cannot infer when a transition is
needed from the prompt. Most open-source models are trained on datasets
consisting of single-scene video clips, which limits their capacity to learn
and respond to prompts requiring multiple scenes. Developing scene transition
awareness is essential for multi-scene generation, as it allows models to
identify and segment videos into distinct clips by accurately detecting
transitions.
  To address this, we propose the \textbf{Transition-Aware Video} (TAV)
dataset, which consists of preprocessed video clips with multiple scene
transitions. Our experiment shows that post-training on the \textbf{TAV}
dataset improves prompt-based scene transition understanding, narrows the gap
between required and generated scenes, and maintains image quality.

</details>


### [21] [BokehDiff: Neural Lens Blur with One-Step Diffusion](https://arxiv.org/abs/2507.18060)
*Chengxuan Zhu,Qingnan Fan,Qi Zhang,Jinwei Chen,Huaqi Zhang,Chao Xu,Boxin Shi*

Main category: cs.CV

TL;DR: BokehDiff是一种新的散景模糊渲染方法，使用扩散模型生成逼真的效果，并克服了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有散景渲染方法在深度估计准确性上的限制及其产生的伪影问题，本研究引入了一种新的方法。

Method: 该方法采用受物理启发的自注意力模块，结合了与图像形成过程一致的深度相关模糊圆约束和自遮挡效应。它还对扩散模型进行了调整，以实现一步推理，同时避免引入额外噪声。

Result: BokehDiff能够生成高质量、高保真的散景模糊效果，并提出了一种利用扩散模型合成具有透明度前景的新方法，以解决数据不足的问题，实现了真实性和场景多样性的平衡。

Conclusion: BokehDiff通过利用生成式扩散先验，实现了物理精确且视觉上吸引人的散景模糊渲染，克服了以往方法在深度不连续处产生的伪影问题。

Abstract: We introduce BokehDiff, a novel lens blur rendering method that achieves
physically accurate and visually appealing outcomes, with the help of
generative diffusion prior. Previous methods are bounded by the accuracy of
depth estimation, generating artifacts in depth discontinuities. Our method
employs a physics-inspired self-attention module that aligns with the image
formation process, incorporating depth-dependent circle of confusion constraint
and self-occlusion effects. We adapt the diffusion model to the one-step
inference scheme without introducing additional noise, and achieve results of
high quality and fidelity. To address the lack of scalable paired data, we
propose to synthesize photorealistic foregrounds with transparency with
diffusion models, balancing authenticity and scene diversity.

</details>


### [22] [Adapting Large VLMs with Iterative and Manual Instructions for Generative Low-light Enhancement](https://arxiv.org/abs/2507.18064)
*Xiaoran Sun,Liyan Wang,Cong Wang,Yeying Jin,Kin-man Lam,Zhixun Su,Yang Yang,Jinshan Pan*

Main category: cs.CV

TL;DR: 本文提出VLM-IMI，利用视觉-语言模型和文本指令提升低光图像质量，并通过迭代优化提升细节和语义一致性，实验证明效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有低光图像增强方法忽视了来自正常光图像的语义指导，限制了其在复杂光照条件下的表现。本文旨在利用大型视觉-语言模型和文本信息来提供更强的语义指导，以改善低光图像增强的效果。

Method: 提出了一种名为VLM-IMI的新框架，该框架利用视觉-语言模型（VLMs）和迭代式、手动指令（IMIs）进行低光图像增强。通过引入文本描述作为增强线索，并设计了指令先验融合模块来融合图像和文本特征，最后采用迭代式手动指令策略进行推理，逐步优化增强效果。

Result: VLM-IMI在各种场景下进行了广泛的实验，并在定量指标和感知质量上均优于现有的最先进方法，尤其在极端低光条件下，能够更好地恢复结构保真度、语义一致性和细节。

Conclusion: VLM-IMI通过结合视觉-语言模型和迭代式指令，实现了低光图像增强，并在各种场景下超越了现有最先进的方法。

Abstract: Most existing low-light image enhancement (LLIE) methods rely on pre-trained
model priors, low-light inputs, or both, while neglecting the semantic guidance
available from normal-light images. This limitation hinders their effectiveness
in complex lighting conditions. In this paper, we propose VLM-IMI, a novel
framework that leverages large vision-language models (VLMs) with iterative and
manual instructions (IMIs) for LLIE. VLM-IMI incorporates textual descriptions
of the desired normal-light content as enhancement cues, enabling semantically
informed restoration. To effectively integrate cross-modal priors, we introduce
an instruction prior fusion module, which dynamically aligns and fuses image
and text features, promoting the generation of detailed and semantically
coherent outputs. During inference, we adopt an iterative and manual
instruction strategy to refine textual instructions, progressively improving
visual quality. This refinement enhances structural fidelity, semantic
alignment, and the recovery of fine details under extremely low-light
conditions. Extensive experiments across diverse scenarios demonstrate that
VLM-IMI outperforms state-of-the-art methods in both quantitative metrics and
perceptual quality. The source code is available at
https://github.com/sunxiaoran01/VLM-IMI.

</details>


### [23] [DSFormer: A Dual-Scale Cross-Learning Transformer for Visual Place Recognition](https://arxiv.org/abs/2507.18444)
*Haiyang Jiang,Songhao Piao,Chao Gao,Lei Yu,Liguo Chen*

Main category: cs.CV

TL;DR: 提出了一种名为DSFormer的新型Transformer框架，并结合了块聚类策略，以提高视觉地点识别的鲁棒性，同时减少了对训练数据的需求，并在实验中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 视觉地点识别（VPR）对于鲁棒的移动机器人定位至关重要，但在不断变化的环境条件和视角下保持可靠的性能方面面临重大挑战。

Method: 提出了一种整合了双尺度Transformer（DSFormer）和创新的块聚类策略的新框架。DSFormer通过实现从CNN最后两层提取的双尺度特征之间的双向信息传输来增强特征表示，并通过自注意力机制捕捉每个尺度内的长距离依赖关系，以及通过共享的交叉注意力机制进行跨尺度学习。块聚类策略则从多个不同的视角对SF-XL训练数据集进行了重新划分，以优化数据组织，进一步提高对视角变化的鲁棒性。

Result: 与先前的方法相比，该方法将所需的训练数据量减少了约30％，并作为全局检索解决方案，在使用512维全局描述符时，超越了DELG、Patch-NetVLAD、TransVPR和R2Former等先进的重新排序方法。

Conclusion: 该方法在大多数基准数据集上实现了最先进的性能，并且在计算效率方面有了显著提高。

Abstract: Visual Place Recognition (VPR) is crucial for robust mobile robot
localization, yet it faces significant challenges in maintaining reliable
performance under varying environmental conditions and viewpoints. To address
this, we propose a novel framework that integrates Dual-Scale-Former
(DSFormer), a Transformer-based cross-learning module, with an innovative block
clustering strategy. DSFormer enhances feature representation by enabling
bidirectional information transfer between dual-scale features extracted from
the final two CNN layers, capturing both semantic richness and spatial details
through self-attention for long-range dependencies within each scale and shared
cross-attention for cross-scale learning. Complementing this, our block
clustering strategy repartitions the widely used San Francisco eXtra Large
(SF-XL) training dataset from multiple distinct perspectives, optimizing data
organization to further bolster robustness against viewpoint variations.
Together, these innovations not only yield a robust global embedding adaptable
to environmental changes but also reduce the required training data volume by
approximately 30\% compared to previous partitioning methods. Comprehensive
experiments demonstrate that our approach achieves state-of-the-art performance
across most benchmark datasets, surpassing advanced reranking methods like
DELG, Patch-NetVLAD, TransVPR, and R2Former as a global retrieval solution
using 512-dim global descriptors, while significantly improving computational
efficiency.

</details>


### [24] [TextSAM-EUS: Text Prompt Learning for SAM to Accurately Segment Pancreatic Tumor in Endoscopic Ultrasound](https://arxiv.org/abs/2507.18082)
*Pascal Spiegler,Taha Koleilat,Arash Harirpoush,Corey S. Miller,Hassan Rivaz,Marta Kersten-Oertel,Yiming Xiao*

Main category: cs.CV

TL;DR: 提出TextSAM-EUS，一种轻量级的文本驱动SAM模型，用于EUS胰腺肿瘤自动分割，无需手动提示，性能优于SOTA模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决EUS图像中存在的散斑噪声、低对比度和直观性差的问题，以及全监督深度学习模型在胰腺肿瘤分割中易出错且依赖大量专家标注数据的挑战。

Method: 提出了一种新颖、轻量级的文本驱动的SAM模型适配方法TextSAM-EUS，利用BiomedCLIP文本编码器进行文本提示学习（上下文优化），并结合基于LoRA的SAM架构适配，实现了EUS胰腺肿瘤的自动分割，仅调整了0.86%的总参数。

Result: TextSAM-EUS在使用自动提示时达到了82.69%的Dice系数和85.28%的归一化表面距离（NSD），在使用手动几何提示时达到了83.10%的Dice系数和85.70%的NSD，性能优于现有的最先进的监督深度学习模型和基础模型（如SAM及其变体）。

Conclusion: TextSAM-EUS是首个将提示学习应用于SAM医学图像分割的模型，为实现高效、鲁棒的EUS自动分割提供了实用的选择。

Abstract: Pancreatic cancer carries a poor prognosis and relies on endoscopic
ultrasound (EUS) for targeted biopsy and radiotherapy. However, the speckle
noise, low contrast, and unintuitive appearance of EUS make segmentation of
pancreatic tumors with fully supervised deep learning (DL) models both
error-prone and dependent on large, expert-curated annotation datasets. To
address these challenges, we present TextSAM-EUS, a novel, lightweight,
text-driven adaptation of the Segment Anything Model (SAM) that requires no
manual geometric prompts at inference. Our approach leverages text prompt
learning (context optimization) through the BiomedCLIP text encoder in
conjunction with a LoRA-based adaptation of SAM's architecture to enable
automatic pancreatic tumor segmentation in EUS, tuning only 0.86% of the total
parameters. On the public Endoscopic Ultrasound Database of the Pancreas,
TextSAM-EUS with automatic prompts attains 82.69% Dice and 85.28% normalized
surface distance (NSD), and with manual geometric prompts reaches 83.10% Dice
and 85.70% NSD, outperforming both existing state-of-the-art (SOTA) supervised
DL models and foundation models (e.g., SAM and its variants). As the first
attempt to incorporate prompt learning in SAM-based medical image segmentation,
TextSAM-EUS offers a practical option for efficient and robust automatic EUS
segmentation. Our code will be publicly available upon acceptance.

</details>


### [25] [Learning from Heterogeneity: Generalizing Dynamic Facial Expression Recognition via Distributionally Robust Optimization](https://arxiv.org/abs/2507.15765)
*Feng-Qi Cui,Anyang Tong,Jinyang Huang,Jie Zhang,Dan Guo,Zhi Liu,Meng Wang*

Main category: cs.CV

TL;DR: 提出HDF框架，通过DAM和DSM模块解决DFER中的样本异质性问题，提升了模型在不同场景下的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的动态面部表情识别（DFER）方法在面对多源数据和个体表情差异引起的样本异质性时，性能会下降。

Method: 提出了一种名为异质性感知分布框架（HDF）的新框架，并设计了两个即插即用模块：时间-频率分布注意力模块（DAM）和分布感知缩放模块（DSM）。DAM通过双分支注意力设计捕捉时序一致性和频域鲁棒性，增强对序列不一致和视觉风格变化的容忍度。DSM基于梯度敏感性和信息瓶颈原理，动态平衡分类和对比损失，实现更稳定和具区分性的表示学习。

Result: HDF框架在DFEW和FERV39k数据集上显著提高了识别准确性和鲁棒性，在多样化和不平衡场景下取得了优越的WAR和UAR指标。

Conclusion: HDF框架在DFEW和FERV39k数据集上显著提高了识别准确性和鲁棒性，在多样化和不平衡场景下表现出优越的加权平均召回率（WAR）和未加权平均召回率（UAR），同时保持了强大的泛化能力。

Abstract: Dynamic Facial Expression Recognition (DFER) plays a critical role in
affective computing and human-computer interaction. Although existing methods
achieve comparable performance, they inevitably suffer from performance
degradation under sample heterogeneity caused by multi-source data and
individual expression variability. To address these challenges, we propose a
novel framework, called Heterogeneity-aware Distributional Framework (HDF), and
design two plug-and-play modules to enhance time-frequency modeling and
mitigate optimization imbalance caused by hard samples. Specifically, the
Time-Frequency Distributional Attention Module (DAM) captures both temporal
consistency and frequency robustness through a dual-branch attention design,
improving tolerance to sequence inconsistency and visual style shifts. Then,
based on gradient sensitivity and information bottleneck principles, an
adaptive optimization module Distribution-aware Scaling Module (DSM) is
introduced to dynamically balance classification and contrastive losses,
enabling more stable and discriminative representation learning. Extensive
experiments on two widely used datasets, DFEW and FERV39k, demonstrate that HDF
significantly improves both recognition accuracy and robustness. Our method
achieves superior weighted average recall (WAR) and unweighted average recall
(UAR) while maintaining strong generalization across diverse and imbalanced
scenarios. Codes are released at https://github.com/QIcita/HDF_DFER.

</details>


### [26] [Comparison of Segmentation Methods in Remote Sensing for Land Use Land Cover](https://arxiv.org/abs/2507.18099)
*Naman Srivastava,Joel D Joy,Yash Dixit,Swarup E,Rakshit Ramesh*

Main category: cs.CV

TL;DR: 本研究通过结合大气校正和先进的机器学习模型（DeeplabV3+, CPS），有效提升了陆地利用土地覆盖（LULC）测绘的准确性，并通过印度海得拉巴的案例研究，证明了其在监测城市化进程中的实用价值。


<details>
  <summary>Details</summary>
Motivation: 陆地利用土地覆盖（LULC）测绘对于城市和资源规划至关重要，是构建智慧和可持续城市的关键要素。本研究旨在评估先进的LULC测绘技术，特别是大气校正和机器学习模型，以应对快速城市化带来的土地利用变化，为城市规划和政策制定提供支持。

Method: 本研究采用了基于查找表（LUT）的大气校正技术，并将其应用于Cartosat多光谱（MX）传感器图像。随后，利用DeeplabV3+和带有动态加权的交叉伪监督（CPS）模型进行监督和半监督学习，以预测陆地利用土地覆盖（LULC）。通过分析不同时期的Cartosat MX图像，评估了这些技术的准确性和效用。

Result: 研究结果表明，所评估的LULC测绘技术，包括经过大气校正的Cartosat MX图像以及DeeplabV3+和CPS模型（特别是带有动态加权的CPS），能够准确地识别和量化城市扩张、绿地缩减和工业区扩张等土地利用变化。这些技术在实际应用中显示出其有效性。

Conclusion: 该研究评估了基于查找表（LUT）的大气校正技术，并结合了DeeplabV3+和带有动态加权的交叉伪监督（CPS）等监督和半监督学习模型，用于陆地利用土地覆盖（LULC）的预测。通过对印度海得拉巴的案例研究，展示了这些技术在应对快速城市化导致的时态土地利用变化（如城市扩张、绿地缩减和工业区扩张）方面的准确性和实用性，为城市规划者和政策制定者提供了有价值的见解。

Abstract: Land Use Land Cover (LULC) mapping is essential for urban and resource
planning, and is one of the key elements in developing smart and sustainable
cities.This study evaluates advanced LULC mapping techniques, focusing on
Look-Up Table (LUT)-based Atmospheric Correction applied to Cartosat
Multispectral (MX) sensor images, followed by supervised and semi-supervised
learning models for LULC prediction. We explore DeeplabV3+ and Cross-Pseudo
Supervision (CPS). The CPS model is further refined with dynamic weighting,
enhancing pseudo-label reliability during training. This comprehensive approach
analyses the accuracy and utility of LULC mapping techniques for various urban
planning applications. A case study of Hyderabad, India, illustrates
significant land use changes due to rapid urbanization. By analyzing Cartosat
MX images over time, we highlight shifts such as urban sprawl, shrinking green
spaces, and expanding industrial areas. This demonstrates the practical utility
of these techniques for urban planners and policymakers.

</details>


### [27] [Datasets and Recipes for Video Temporal Grounding via Reinforcement Learning](https://arxiv.org/abs/2507.18100)
*Ruizhe Chen,Zhiting Fan,Tianze Luo,Heqing Zou,Zhaopeng Feng,Guiyang Xie,Hansheng Zhang,Zhuochen Wang,Zuozhu Liu,Huaijian Zhang*

Main category: cs.CV

TL;DR: 通过SFT和RL的两阶段训练框架，利用冷启动数据和难度控制RL，提高了VTG模型的准确性和鲁棒性，并在多个基准测试中取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在视频时间定位（VTG）任务中，尽管有LVLMs和指令调优的进展，但通常存在时间感知能力有限和泛化能力差的问题。

Method: 提出了一种两阶段训练框架，结合了监督微调（SFT）和强化学习（RL），首先利用高质量的精选冷启动数据进行SFT初始化，然后进行难度控制的RL以增强时间定位和推理能力。

Result: 该方法在VTG任务上表现出优于现有模型的能力，特别是在处理挑战性和开放域场景时。

Conclusion: 所提出的方法在多个VTG基准测试中持续优于现有模型，特别是在具有挑战性和开放域的场景中。

Abstract: Video Temporal Grounding (VTG) aims to localize relevant temporal segments in
videos given natural language queries. Despite recent progress with large
vision-language models (LVLMs) and instruction-tuning, existing approaches
often suffer from limited temporal awareness and poor generalization. In this
work, we introduce a two-stage training framework that integrates supervised
fine-tuning with reinforcement learning (RL) to improve both the accuracy and
robustness of VTG models. Our approach first leverages high-quality curated
cold start data for SFT initialization, followed by difficulty-controlled RL to
further enhance temporal localization and reasoning abilities. Comprehensive
experiments on multiple VTG benchmarks demonstrate that our method consistently
outperforms existing models, particularly in challenging and open-domain
scenarios. We conduct an in-depth analysis of training strategies and dataset
curation, highlighting the importance of both high-quality cold start data and
difficulty-controlled RL. To facilitate further research and industrial
adoption, we release all intermediate datasets, models, and code to the
community.

</details>


### [28] [A Multimodal Seq2Seq Transformer for Predicting Brain Responses to Naturalistic Stimuli](https://arxiv.org/abs/2507.18104)
*Qianyi He,Yuan Chang Leong*

Main category: cs.CV

TL;DR: 本研究提出了一种基于Transformer的序列到序列模型，用于预测对电影的fMRI反应。该模型利用多模态输入（视觉、听觉、语言）和先进的注意力机制来捕捉时间结构和个体差异，并在挑战赛中取得了良好性能。


<details>
  <summary>Details</summary>
Motivation: 为了应对Algonauts 2025挑战赛，该研究旨在开发能够预测对自然化多模态电影的全脑fMRI反应的编码模型。

Method: 提出了一种序列到序列的Transformer，该模型能够从视觉、听觉和语言输入中自回归地预测fMRI活动。通过结合使用预训练模型（如VideoMAE、HuBERT、Qwen和BridgeTower）提取的刺激特征，以及通过双交叉注意力机制整合来自先前脑状态、当前刺激和情节摘要的信息，实现了对感知信息和叙事信息的处理。该模型的一个核心创新在于使用多模态上下文序列来预测脑活动序列，从而捕捉刺激和神经反应中的长期时间结构。另一个创新点是结合了共享编码器和部分特定于受试者的解码器，这在考虑个体差异的同时利用了跨受试者的共同结构。

Result: 模型在分布内和分布外数据集上均取得了优异的预测结果，表明其在处理和预测脑活动方面的能力。

Conclusion: 该模型在分布内和分布外数据上均表现出强劲的性能，证明了时间感知、多模态序列建模在脑活动预测方面的有效性。

Abstract: The Algonauts 2025 Challenge called on the community to develop encoding
models that predict whole-brain fMRI responses to naturalistic multimodal
movies. In this submission, we propose a sequence-to-sequence Transformer that
autoregressively predicts fMRI activity from visual, auditory, and language
inputs. Stimulus features were extracted using pretrained models including
VideoMAE, HuBERT, Qwen, and BridgeTower. The decoder integrates information
from prior brain states, current stimuli, and episode-level summaries via dual
cross-attention mechanisms that attend to both perceptual information extracted
from the stimulus as well as narrative information provided by high-level
summaries of narrative content. One core innovation of our approach is the use
of sequences of multimodal context to predict sequences of brain activity,
enabling the model to capture long-range temporal structure in both stimuli and
neural responses. Another is the combination of a shared encoder with partial
subject-specific decoder, which leverages common structure across subjects
while accounting for individual variability. Our model achieves strong
performance on both in-distribution and out-of-distribution data, demonstrating
the effectiveness of temporally-aware, multimodal sequence modeling for brain
activity prediction. The code is available at
https://github.com/Angelneer926/Algonauts_challenge.

</details>


### [29] [Distributional Uncertainty for Out-of-Distribution Detection](https://arxiv.org/abs/2507.18106)
*JinYoung Kim,DaeUng Jo,Kimin Yun,Jeonghyo Song,Youngjoon Yoo*

Main category: cs.CV

TL;DR: 提出了一种新的自由能后验网络框架，通过联合建模不确定性和利用自由能来检测 OoD 样本，解决了传统方法在语义对齐方面的不足，并在多个基准测试中取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 传统的深度神经网络不确定性估计方法（如 MC Dropout）在检测分布外（OoD）样本时，往往只关注模型或数据不确定性，未能与 OoD 检测的语义目标保持一致。

Method: 本研究提出了一种新颖的框架，称为自由能后验网络（Free-Energy Posterior Network），该框架结合了基于自由能的密度估计器（参数化为 Beta 分布）和集成到后验网络中的损失函数，用于联合建模分布不确定性并识别 OoD 和错误分类区域。

Result: 实验结果表明，该方法在 Fishyscapes、RoadAnomaly 和 Segment-Me-If-You-Can 等具有挑战性的真实世界基准上验证了其有效性。

Conclusion: 该框架通过集成到残差预测分支（RPL）框架中，超越了事后能量阈值，并利用 Beta 分布的方差学习了 OoD 区域，从而提供了一种语义上有意义且计算效率高的方法。

Abstract: Estimating uncertainty from deep neural networks is a widely used approach
for detecting out-of-distribution (OoD) samples, which typically exhibit high
predictive uncertainty. However, conventional methods such as Monte Carlo (MC)
Dropout often focus solely on either model or data uncertainty, failing to
align with the semantic objective of OoD detection. To address this, we propose
the Free-Energy Posterior Network, a novel framework that jointly models
distributional uncertainty and identifying OoD and misclassified regions using
free energy. Our method introduces two key contributions: (1) a
free-energy-based density estimator parameterized by a Beta distribution, which
enables fine-grained uncertainty estimation near ambiguous or unseen regions;
and (2) a loss integrated within a posterior network, allowing direct
uncertainty estimation from learned parameters without requiring stochastic
sampling. By integrating our approach with the residual prediction branch (RPL)
framework, the proposed method goes beyond post-hoc energy thresholding and
enables the network to learn OoD regions by leveraging the variance of the Beta
distribution, resulting in a semantically meaningful and computationally
efficient solution for uncertainty-aware segmentation. We validate the
effectiveness of our method on challenging real-world benchmarks, including
Fishyscapes, RoadAnomaly, and Segment-Me-If-You-Can.

</details>


### [30] [T2VWorldBench: A Benchmark for Evaluating World Knowledge in Text-to-Video Generation](https://arxiv.org/abs/2507.18107)
*Yubin Chen,Xuyang Guo,Zhenmei Shi,Zhao Song,Jiahao Zhang*

Main category: cs.CV

TL;DR: 提出T2VWorldBench基准来评估文本到视频模型的世界知识能力，发现现有模型在这方面存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 当前文本到视频模型在利用世界知识以确保语义一致性和事实准确性方面的能力在很大程度上未被充分研究。

Method: 提出了T2VWorldBench，一个评估文本到视频模型世界知识生成能力的系统性评估框架，该框架涵盖6个主要类别、60个子类别和1200个提示，并结合了人类评估和使用视觉语言模型（VLMs）的自动化评估。

Result: 评估了10个最先进的文本到视频模型，结果表明大多数模型在理解世界知识和生成正确视频方面存在不足。

Conclusion: 大多数文本到视频模型无法理解世界知识并生成真正正确的视频，这表明当前模型在利用世界知识方面存在关键差距，为构建具有稳健常识推理和事实生成能力的模型提供了宝贵的研究机会和切入点。

Abstract: Text-to-video (T2V) models have shown remarkable performance in generating
visually reasonable scenes, while their capability to leverage world knowledge
for ensuring semantic consistency and factual accuracy remains largely
understudied. In response to this challenge, we propose T2VWorldBench, the
first systematic evaluation framework for evaluating the world knowledge
generation abilities of text-to-video models, covering 6 major categories, 60
subcategories, and 1,200 prompts across a wide range of domains, including
physics, nature, activity, culture, causality, and object. To address both
human preference and scalable evaluation, our benchmark incorporates both human
evaluation and automated evaluation using vision-language models (VLMs). We
evaluated the 10 most advanced text-to-video models currently available,
ranging from open source to commercial models, and found that most models are
unable to understand world knowledge and generate truly correct videos. These
findings point out a critical gap in the capability of current text-to-video
models to leverage world knowledge, providing valuable research opportunities
and entry points for constructing models with robust capabilities for
commonsense reasoning and factual generation.

</details>


### [31] [Information Entropy-Based Framework for Quantifying Tortuosity in Meibomian Gland Uneven Atrophy](https://arxiv.org/abs/2507.18135)
*Kesheng Wang,Xiaoyu Chen,Chunlei He,Fenfen Li,Xinxin Yu,Dexing Kong,Shoujun Huang,Qi Dai*

Main category: cs.CV

TL;DR: 提出了一种新的基于信息熵的曲率量化方法，用于医学图像分析。该方法通过比较目标曲线和参考曲线来评估曲率，克服了传统方法的局限性。实验结果表明，该方法能有效评估睑板腺萎缩的均匀性，并能区分Demodex感染患者，具有良好的临床应用前景。


<details>
  <summary>Details</summary>
Motivation: 在医学图像分析领域，精确量化曲率对于辅助诊断和病理评估至关重要，特别是在评估睑板腺萎缩均匀性等应用场景中。

Method: 提出了一种基于信息熵的曲率量化框架，该框架结合了概率模型、熵理论和曲线数据的域变换，通过比较目标曲线与参考曲线来评估曲率，而非依赖理想化的直线比较。

Result: 数值模拟实验初步验证了该方法的稳定性和有效性。在实际应用中，该框架能够量化睑板腺萎缩的空间均匀性，并区分Demodex阴性和阳性患者群体，其区分能力通过曲线下面积（0.8768）、敏感性（0.75）和特异性（0.93）得到体现。

Conclusion: 该研究提出的基于信息熵的曲率量化框架能够有效评估睑板腺萎缩的均匀性，并且在区分Demodex阴性和阳性患者群体方面表现出显著差异，具有临床应用潜力。

Abstract: In the medical image analysis field, precise quantification of curve
tortuosity plays a critical role in the auxiliary diagnosis and pathological
assessment of various diseases. In this study, we propose a novel framework for
tortuosity quantification and demonstrate its effectiveness through the
evaluation of meibomian gland atrophy uniformity,serving as a representative
application scenario.
  We introduce an information entropy-based tortuosity quantification framework
that integrates probability modeling with entropy theory and incorporates
domain transformation of curve data. Unlike traditional methods such as
curvature or arc-chord ratio, this approach evaluates the tortuosity of a
target curve by comparing it to a designated reference curve. Consequently, it
is more suitable for tortuosity assessment tasks in medical data where
biologically plausible reference curves are available, providing a more robust
and objective evaluation metric without relying on idealized straight-line
comparisons.
  First, we conducted numerical simulation experiments to preliminarily assess
the stability and validity of the method. Subsequently, the framework was
applied to quantify the spatial uniformity of meibomian gland atrophy and to
analyze the difference in this uniformity between \textit{Demodex}-negative and
\textit{Demodex}-positive patient groups. The results demonstrated a
significant difference in tortuosity-based uniformity between the two groups,
with an area under the curve of 0.8768, sensitivity of 0.75, and specificity of
0.93. These findings highlight the clinical utility of the proposed framework
in curve tortuosity analysis and its potential as a generalizable tool for
quantitative morphological evaluation in medical diagnostics.

</details>


### [32] [Degradation-Consistent Learning via Bidirectional Diffusion for Low-Light Image Enhancement](https://arxiv.org/abs/2507.18144)
*Jinhong He,Minglong Xue,Zhipu Liu,Mingliang Zhou,Aoxiang Ning,Palaiahnakote Shivakumara*

Main category: cs.CV

TL;DR: 该研究提出了一种双向扩散优化机制，通过联合建模低光照和正常光照图像的退化过程，并结合自适应特征交互和反射感知校正模块，解决了现有扩散模型在处理复杂退化模式时遇到的结构不一致和像素错位问题，从而在低光图像增强方面取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 低光图像增强旨在提高退化图像的可见性，以更好地符合人类视觉感知。基于扩散的方法由于其强大的生成能力而表现出有希望的性能。然而，其单向退化建模常常难以捕捉真实世界退化模式的复杂性，导致结构不一致和像素错位。

Method: 提出了一种双向扩散优化机制，该机制对低光照和正常光照图像的退化过程进行联合建模，从而实现更精确的退化参数匹配并提高生成质量。具体来说，我们在训练期间执行从低光照到正常光照以及从正常光照到低光照的双向扩散，并引入自适应特征交互（AFI）模块来优化特征表示。通过利用这两个路径之间的互补性，我们的方法对光照衰减和噪声分布施加了隐式对称约束，从而促进了一致的退化学习，并提高了模型感知光照和细节退化的能力。此外，我们设计了一个反射感知校正模块（RACM）来指导去噪后的颜色恢复并抑制曝光过度的区域，从而确保内容的一致性并生成与人类视觉感知一致的高质量图像。

Result: 通过利用双向扩散和自适应特征交互以及反射感知校正模块，该方法能够更精确地匹配退化参数，提高生成质量，并确保内容一致性，生成高质量、符合人类视觉感知的图像。

Conclusion: 该方法在定量和定性评估方面均优于最先进的方法，并能有效推广到各种退化场景。

Abstract: Low-light image enhancement aims to improve the visibility of degraded images
to better align with human visual perception. While diffusion-based methods
have shown promising performance due to their strong generative capabilities.
However, their unidirectional modelling of degradation often struggles to
capture the complexity of real-world degradation patterns, leading to
structural inconsistencies and pixel misalignments. To address these
challenges, we propose a bidirectional diffusion optimization mechanism that
jointly models the degradation processes of both low-light and normal-light
images, enabling more precise degradation parameter matching and enhancing
generation quality. Specifically, we perform bidirectional diffusion-from
low-to-normal light and from normal-to-low light during training and introduce
an adaptive feature interaction block (AFI) to refine feature representation.
By leveraging the complementarity between these two paths, our approach imposes
an implicit symmetry constraint on illumination attenuation and noise
distribution, facilitating consistent degradation learning and improving the
models ability to perceive illumination and detail degradation. Additionally,
we design a reflection-aware correction module (RACM) to guide color
restoration post-denoising and suppress overexposed regions, ensuring content
consistency and generating high-quality images that align with human visual
perception. Extensive experiments on multiple benchmark datasets demonstrate
that our method outperforms state-of-the-art methods in both quantitative and
qualitative evaluations while generalizing effectively to diverse degradation
scenarios. Code at https://github.com/hejh8/BidDiff

</details>


### [33] [WaveMamba: Wavelet-Driven Mamba Fusion for RGB-Infrared Object Detection](https://arxiv.org/abs/2507.18173)
*Haodong Zhu,Wenhao Dong,Linlin Yang,Hong Li,Yuguang Yang,Yangyang Ren,Qingcheng Zhu,Zichao Feng,Changbai Li,Shaohui Lin,Runqi Wang,Xiaoyan Luo,Baochang Zhang*

Main category: cs.CV

TL;DR: WaveMamba是一种创新的RGB-IR融合方法，利用小波变换和Mamba架构，通过低频和高频特征的有效融合，显著提升了目标检测的准确率。


<details>
  <summary>Details</summary>
Motivation: 利用可见光（RGB）和红外（IR）图像互补的特性，以提高目标检测性能。

Method: 提出了一种名为WaveMamba的跨模态融合方法，其核心是WaveMamba Fusion Block (WMFB)。WMFB包含低频Mamba融合块（LMFB）和高频特征增强策略。LMFB基于Mamba框架，通过通道交换进行低频特征融合，并利用门控注意力机制进行深度融合。高频特征则采用“绝对最大值”融合策略。

Result: 在四个基准测试中，WaveMamba取得了显著的性能提升，平均mAP比最先进的方法提高了4.5%。

Conclusion: WaveMamba 通过跨模态融合方法，利用离散小波变换（DWT）分解的RGB和红外图像的频率特征，并结合改进的检测头（IDWT），实现了显著的性能提升，平均mAP提高了4.5%，超越了现有技术。

Abstract: Leveraging the complementary characteristics of visible (RGB) and infrared
(IR) imagery offers significant potential for improving object detection. In
this paper, we propose WaveMamba, a cross-modality fusion method that
efficiently integrates the unique and complementary frequency features of RGB
and IR decomposed by Discrete Wavelet Transform (DWT). An improved detection
head incorporating the Inverse Discrete Wavelet Transform (IDWT) is also
proposed to reduce information loss and produce the final detection results.
The core of our approach is the introduction of WaveMamba Fusion Block (WMFB),
which facilitates comprehensive fusion across low-/high-frequency sub-bands.
Within WMFB, the Low-frequency Mamba Fusion Block (LMFB), built upon the Mamba
framework, first performs initial low-frequency feature fusion with channel
swapping, followed by deep fusion with an advanced gated attention mechanism
for enhanced integration. High-frequency features are enhanced using a strategy
that applies an ``absolute maximum" fusion approach. These advancements lead to
significant performance gains, with our method surpassing state-of-the-art
approaches and achieving average mAP improvements of 4.5% on four benchmarks.

</details>


### [34] [Unsupervised Domain Adaptation for 3D LiDAR Semantic Segmentation Using Contrastive Learning and Multi-Model Pseudo Labeling](https://arxiv.org/abs/2507.18176)
*Abhishek Kaushik,Norbert Haala,Uwe Soergel*

Main category: cs.CV

TL;DR: 该研究提出了一种用于3D LiDAR语义分割的无监督域适应方法，通过对比预训练和多模型伪标签策略，有效解决了域转移问题，无需目标域标注即可提升分割精度。


<details>
  <summary>Details</summary>
Motivation: 为了解决3D LiDAR语义分割在自动驾驶系统中面临的由于传感器类型、地理位置等域转移导致的的性能下降问题，同时克服手动标注目标域数据的成本高昂和操作困难的挑战。

Method: 提出了一种新颖的两阶段框架：1. 采用无监督对比学习在片段级别预训练骨干网络，以学习鲁棒的、与域无关的特征。2. 引入多模型伪标签策略，集成多种先进架构（包括投影、体素、混合和基于柱状的方法），并通过硬投票聚合其预测，生成高质量、精炼的伪标签，以微调对比预训练的网络，从而缓解了单一模型的偏差。

Result: 实验结果表明，该方法在从SemanticKITTI到未标记的目标数据集（SemanticPOSS, SemanticSlamantic）的适应性测试中，相比于直接迁移和单一模型UDA方法，显著提高了分割精度，证明了该方法在无需目标域标注的情况下有效缩小域间隙的能力。

Conclusion: 本研究提出的结合了对比预训练和多模型伪标签策略的无监督域适应方法，在解决3D LiDAR语义分割中的域转移问题上取得了显著成效，无需目标域标注即可有效提升分割精度，克服了手动标注的成本和复杂性。

Abstract: Addressing performance degradation in 3D LiDAR semantic segmentation due to
domain shifts (e.g., sensor type, geographical location) is crucial for
autonomous systems, yet manual annotation of target data is prohibitive. This
study addresses the challenge using Unsupervised Domain Adaptation (UDA) and
introduces a novel two-stage framework to tackle it. Initially, unsupervised
contrastive learning at the segment level is used to pre-train a backbone
network, enabling it to learn robust, domain-invariant features without labels.
Subsequently, a multi-model pseudo-labeling strategy is introduced, utilizing
an ensemble of diverse state-of-the-art architectures (including projection,
voxel, hybrid, and cylinder-based methods). Predictions from these models are
aggregated via hard voting to generate high-quality, refined pseudo-labels for
the unlabeled target domain, mitigating single-model biases. The contrastively
pre-trained network is then fine-tuned using these robust pseudo-labels.
Experiments adapting from SemanticKITTI to unlabeled target datasets
(SemanticPOSS, SemanticSlamantic) demonstrate significant improvements in
segmentation accuracy compared to direct transfer and single-model UDA
approaches. These results highlight the effectiveness of combining contrastive
pre-training with refined ensemble pseudo-labeling for bridging complex domain
gaps without requiring target domain annotations.

</details>


### [35] [Differential-UMamba: Rethinking Tumor Segmentation Under Limited Data Scenarios](https://arxiv.org/abs/2507.18177)
*Dhruv Jain,Romain Modzelewski,Romain Hérault,Clement Chatelain,Eva Torfeh,Sebastien Thureau*

Main category: cs.CV

TL;DR: Diff-UMamba通过结合UNet和mamba机制，并引入NRM来处理数据稀疏的医学图像分割问题，在多项数据集上均取得了性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习模型在数据稀疏场景下容易过拟合噪声和无关模式，导致泛化能力受限的问题，特别是在医学图像分割领域。

Method: 提出了一种结合UNet框架和mamba机制的Diff-UMamba新架构，其核心是噪声约减模块（NRM），采用信号差分策略来抑制编码器内的噪声或不相关激活。

Result: 在MSD（肺和胰腺）和AIIB23数据集上，Diff-UMamba在各种分割任务上比基线方法提高了1-3%的性能。在BraTS-21数据集上，通过改变可用训练样本的比例进行了评估。在对内部NSCLC数据集的GTV分割验证中，相较于基线方法提高了4-5%。

Conclusion: Diff-UMamba在低数据量设置下实现了改进的分割准确性和鲁棒性，在MSD、AIIB23和NSCLC数据集上均优于基线方法。

Abstract: In data-scarce scenarios, deep learning models often overfit to noise and
irrelevant patterns, which limits their ability to generalize to unseen
samples. To address these challenges in medical image segmentation, we
introduce Diff-UMamba, a novel architecture that combines the UNet framework
with the mamba mechanism for modeling long-range dependencies. At the heart of
Diff-UMamba is a Noise Reduction Module (NRM), which employs a signal
differencing strategy to suppress noisy or irrelevant activations within the
encoder. This encourages the model to filter out spurious features and enhance
task-relevant representations, thereby improving its focus on clinically
meaningful regions. As a result, the architecture achieves improved
segmentation accuracy and robustness, particularly in low-data settings.
Diff-UMamba is evaluated on multiple public datasets, including MSD (lung and
pancreas) and AIIB23, demonstrating consistent performance gains of 1-3% over
baseline methods across diverse segmentation tasks. To further assess
performance under limited-data conditions, additional experiments are conducted
on the BraTS-21 dataset by varying the proportion of available training
samples. The approach is also validated on a small internal non-small cell lung
cancer (NSCLC) dataset for gross tumor volume (GTV) segmentation in cone beam
CT (CBCT), where it achieves a 4-5% improvement over the baseline.

</details>


### [36] [MatSSL: Robust Self-Supervised Representation Learning for Metallographic Image Segmentation](https://arxiv.org/abs/2507.18184)
*Hoang Hai Nam Nguyen,Phan Nguyen Duc Hieu,Ho Won Lee*

Main category: cs.CV

TL;DR: MatSSL 是一种新的自监督学习架构，通过门控特征融合有效整合多层次表征。它能在小型无标签数据集上进行预训练，然后在多个基准数据集上微调，显著优于现有方法，尤其在金相领域表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前显微图像分析依赖有监督方法，需要为新数据集重新训练且在少量标记样本上表现不一致。自监督学习（SSL）是替代方案，但现有方法通常需要大规模数据集。MatSSL 旨在解决这些限制，使其能够在小型无标签数据集上进行有效的自监督预训练和微调。

Method: MatSSL 架构采用门控特征融合（Gated Feature Fusion）机制，在骨干网络的每一阶段整合多层次的表征，以实现对包含金属材料的显微图像的分析。

Result: MatSSL 在 MetalDAM 数据集上的分割模型达到了 69.13% 的 mIoU，优于使用 ImageNet 预训练编码器的 66.73%。在环境隔热涂层（EBC）基准数据集上，与使用 MicroNet 预训练的模型相比，MatSSL 的平均 mIoU 提高了近 40%。

Conclusion: MatSSL 是一种在小型、无标签数据集上进行自监督预训练，然后在多个基准数据集上进行微调的模型，它能够有效适应金相领域，并且能保留从大规模自然图像预训练中学到的丰富且可迁移的特征。

Abstract: MatSSL is a streamlined self-supervised learning (SSL) architecture that
employs Gated Feature Fusion at each stage of the backbone to integrate
multi-level representations effectively. Current micrograph analysis of
metallic materials relies on supervised methods, which require retraining for
each new dataset and often perform inconsistently with only a few labeled
samples. While SSL offers a promising alternative by leveraging unlabeled data,
most existing methods still depend on large-scale datasets to be effective.
MatSSL is designed to overcome this limitation. We first perform
self-supervised pretraining on a small-scale, unlabeled dataset and then
fine-tune the model on multiple benchmark datasets. The resulting segmentation
models achieve 69.13% mIoU on MetalDAM, outperforming the 66.73% achieved by an
ImageNet-pretrained encoder, and delivers consistently up to nearly 40%
improvement in average mIoU on the Environmental Barrier Coating benchmark
dataset (EBC) compared to models pretrained with MicroNet. This suggests that
MatSSL enables effective adaptation to the metallographic domain using only a
small amount of unlabeled data, while preserving the rich and transferable
features learned from large-scale pretraining on natural images.

</details>


### [37] [TeEFusion: Blending Text Embeddings to Distill Classifier-Free Guidance](https://arxiv.org/abs/2507.18192)
*Minghao Fu,Guo-Hua Wang,Xiaohao Chen,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang*

Main category: cs.CV

TL;DR: TeEFusion 是一种高效的蒸馏方法，通过融合文本嵌入来解决 CFG 推理成本高的问题，显著提高生成速度同时保持图像质量。


<details>
  <summary>Details</summary>
Motivation: CFG（classifier-free guidance）依赖两次前向传播，尤其结合复杂的采样算法时，推理成本高昂。

Method: TeEFusion 通过融合条件和无条件文本嵌入，并学习教师模型的采样方法，实现高效文本到图像合成。

Result: TeEFusion 使学生模型能够模仿教师模型的性能，同时推理速度提高 6 倍，并保持可比的图像质量。

Conclusion: TeEFusion 是一种新颖高效的蒸馏方法，它将引导幅度直接纳入文本嵌入，并蒸馏教师模型的复杂采样策略，无需额外参数即可重建所需的引导。

Abstract: Recent advances in text-to-image synthesis largely benefit from sophisticated
sampling strategies and classifier-free guidance (CFG) to ensure high-quality
generation. However, CFG's reliance on two forward passes, especially when
combined with intricate sampling algorithms, results in prohibitively high
inference costs. To address this, we introduce TeEFusion (\textbf{Te}xt
\textbf{E}mbeddings \textbf{Fusion}), a novel and efficient distillation method
that directly incorporates the guidance magnitude into the text embeddings and
distills the teacher model's complex sampling strategy. By simply fusing
conditional and unconditional text embeddings using linear operations,
TeEFusion reconstructs the desired guidance without adding extra parameters,
simultaneously enabling the student model to learn from the teacher's output
produced via its sophisticated sampling approach. Extensive experiments on
state-of-the-art models such as SD3 demonstrate that our method allows the
student to closely mimic the teacher's performance with a far simpler and more
efficient sampling strategy. Consequently, the student model achieves inference
speeds up to 6$\times$ faster than the teacher model, while maintaining image
quality at levels comparable to those obtained through the teacher's complex
sampling approach. The code is publicly available at
\href{https://github.com/AIDC-AI/TeEFusion}{github.com/AIDC-AI/TeEFusion}.

</details>


### [38] [LEAF: Latent Diffusion with Efficient Encoder Distillation for Aligned Features in Medical Image Segmentation](https://arxiv.org/abs/2507.18214)
*Qilin Huang,Tianyu Lin,Zhiguang Chen,Fudan Zheng*

Main category: cs.CV

TL;DR: LEAF是一种高效的医学图像分割模型，通过改进扩散模型的微调过程和特征提取，提高了分割精度，且不增加推理成本。


<details>
  <summary>Details</summary>
Motivation: 现有方法将原始训练过程直接迁移到医学图像分割任务，缺乏针对性调整，且常用的预训练扩散模型在特征提取方面仍有不足。

Method: 提出了一种基于潜在扩散模型的医学图像分割方法LEAF。在微调过程中，用分割图的直接预测替换原始的噪声预测模式，以降低分割结果的方差。同时，采用特征蒸馏方法使卷积层的隐藏状态与基于Transformer的视觉编码器的特征对齐。

Result: 实验结果表明，LEAF方法提升了原始扩散模型在多种医学图像分割数据集上的性能。

Conclusion: LEAF模型在多种分割数据集和不同疾病类型的分割任务上都提升了原始扩散模型的性能，且在推理阶段不改变模型架构、参数数量或计算量，具有高效率。

Abstract: Leveraging the powerful capabilities of diffusion models has yielded quite
effective results in medical image segmentation tasks. However, existing
methods typically transfer the original training process directly without
specific adjustments for segmentation tasks. Furthermore, the commonly used
pre-trained diffusion models still have deficiencies in feature extraction.
Based on these considerations, we propose LEAF, a medical image segmentation
model grounded in latent diffusion models. During the fine-tuning process, we
replace the original noise prediction pattern with a direct prediction of the
segmentation map, thereby reducing the variance of segmentation results. We
also employ a feature distillation method to align the hidden states of the
convolutional layers with the features from a transformer-based vision encoder.
Experimental results demonstrate that our method enhances the performance of
the original diffusion model across multiple segmentation datasets for
different disease types. Notably, our approach does not alter the model
architecture, nor does it increase the number of parameters or computation
during the inference phase, making it highly efficient.

</details>


### [39] [3D Test-time Adaptation via Graph Spectral Driven Point Shift](https://arxiv.org/abs/2507.18225)
*Xin Wei,Qin Yang,Yijie Fang,Mingrui Zhu,Nannan Wang*

Main category: cs.CV

TL;DR: GSDTTA是一种新颖的3D点云分类测试时域自适应方法，它在图谱域中进行自适应，通过图傅里叶变换和优化低频分量来提高效率，并使用自训练策略进行改进。


<details>
  <summary>Details</summary>
Motivation: 现有的3D测试时域自适应（TTA）方法由于点云的非结构化和无序性，效率低下且可能需要额外的训练数据。GSDTTA旨在通过图谱域的自适应来克服这些限制。

Method: GSDTTA将自适应任务从空间域转移到图谱域，通过图傅里叶变换（GFT）将点云表示为离群点感知图，并优化最低10%的频率分量以捕获大部分能量，然后通过逆GFT（IGFT）重构自适应点云。该过程辅以特征图引导的自训练策略，以迭代方式优化谱调整和模型参数。

Result: 在基准数据集上的实验和消融研究证明了GSDTTA的有效性，其在3D点云分类的TTA方面优于现有方法。

Conclusion: GSDTTA在3D点云分类的测试时域自适应方面表现优于现有方法。

Abstract: While test-time adaptation (TTA) methods effectively address domain shifts by
dynamically adapting pre-trained models to target domain data during online
inference, their application to 3D point clouds is hindered by their irregular
and unordered structure. Current 3D TTA methods often rely on computationally
expensive spatial-domain optimizations and may require additional training
data. In contrast, we propose Graph Spectral Domain Test-Time Adaptation
(GSDTTA), a novel approach for 3D point cloud classification that shifts
adaptation to the graph spectral domain, enabling more efficient adaptation by
capturing global structural properties with fewer parameters. Point clouds in
target domain are represented as outlier-aware graphs and transformed into
graph spectral domain by Graph Fourier Transform (GFT). For efficiency,
adaptation is performed by optimizing only the lowest 10% of frequency
components, which capture the majority of the point cloud's energy. An inverse
GFT (IGFT) is then applied to reconstruct the adapted point cloud with the
graph spectral-driven point shift. This process is enhanced by an
eigenmap-guided self-training strategy that iteratively refines both the
spectral adjustments and the model parameters. Experimental results and
ablation studies on benchmark datasets demonstrate the effectiveness of GSDTTA,
outperforming existing TTA methods for 3D point cloud classification.

</details>


### [40] [DATA: Domain-And-Time Alignment for High-Quality Feature Fusion in Collaborative Perception](https://arxiv.org/abs/2507.18237)
*Chengchang Tian,Jianwei Ma,Yan Huang,Zhanye Chen,Honghao Wei,Hui Zhang,Wei Hong*

Main category: cs.CV

TL;DR: DATA网络通过CDAM和PTAM模块来解决协同感知中的域间隙和时间失配问题，并通过IFAM模块增强特征表示，在各种挑战下都表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决协同感知中特征级别融合面临的域间隙和时间失配问题，这些问题会降低特征质量。

Method: 本文提出了一致性保持域对齐模块（CDAM）和渐进时间对齐模块（PTAM），并通过实例关注特征聚合模块（IFAM）来增强语义表示。

Result: DATA网络在三个典型数据集上实现了最先进的性能。

Conclusion: DATA网络在三个典型数据集上实现了最先进的性能，在存在严重通信延迟和姿态错误的情况下保持了鲁棒性。

Abstract: Feature-level fusion shows promise in collaborative perception (CP) through
balanced performance and communication bandwidth trade-off. However, its
effectiveness critically relies on input feature quality. The acquisition of
high-quality features faces domain gaps from hardware diversity and deployment
conditions, alongside temporal misalignment from transmission delays. These
challenges degrade feature quality with cumulative effects throughout the
collaborative network. In this paper, we present the Domain-And-Time Alignment
(DATA) network, designed to systematically align features while maximizing
their semantic representations for fusion. Specifically, we propose a
Consistency-preserving Domain Alignment Module (CDAM) that reduces domain gaps
through proximal-region hierarchical downsampling and observability-constrained
discriminator. We further propose a Progressive Temporal Alignment Module
(PTAM) to handle transmission delays via multi-scale motion modeling and
two-stage compensation. Building upon the aligned features, an Instance-focused
Feature Aggregation Module (IFAM) is developed to enhance semantic
representations. Extensive experiments demonstrate that DATA achieves
state-of-the-art performance on three typical datasets, maintaining robustness
with severe communication delays and pose errors. The code will be released at
https://github.com/ChengchangTian/DATA.

</details>


### [41] [DepthDark: Robust Monocular Depth Estimation for Low-Light Environments](https://arxiv.org/abs/2507.18243)
*Longjian Zeng,Zunjie Zhu,Rongfeng Lu,Ming Lu,Bolun Zheng,Chenggang Yan,Anke Xue*

Main category: cs.CV

TL;DR: 提出DepthDark模型，通过模拟数据和PEFT策略解决低光照单目深度估计问题，在夜间数据集上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 当前单目深度估计的基础模型主要针对典型的日间条件，在低光照环境下有效性显著下降，缺乏专门为低光照场景设计的稳健基础模型。这主要是由于缺乏大规模、高质量的低光照配对深度数据集以及有效的参数高效微调（PEFT）策略。

Method: 提出了一种名为DepthDark的稳健基础模型，包含一个光晕模拟模块和一个噪声模拟模块，用于模拟夜间成像过程并生成高质量的低光照配对深度数据集。此外，还提出了一种利用光照引导和多尺度特征融合的低光照PEFT策略。

Result: 通过模拟夜间成像过程生成了高质量的低光照配对深度数据集，并提出了一种有效的低光照PEFT策略，提升了模型在低光照环境下的能力。

Conclusion: DepthDark在nuScenes-Night和RobotCar-Night数据集上实现了最先进的深度估计性能，并验证了其在有限的训练数据和计算资源下的有效性。

Abstract: In recent years, foundation models for monocular depth estimation have
received increasing attention. Current methods mainly address typical daylight
conditions, but their effectiveness notably decreases in low-light
environments. There is a lack of robust foundational models for monocular depth
estimation specifically designed for low-light scenarios. This largely stems
from the absence of large-scale, high-quality paired depth datasets for
low-light conditions and the effective parameter-efficient fine-tuning (PEFT)
strategy. To address these challenges, we propose DepthDark, a robust
foundation model for low-light monocular depth estimation. We first introduce a
flare-simulation module and a noise-simulation module to accurately simulate
the imaging process under nighttime conditions, producing high-quality paired
depth datasets for low-light conditions. Additionally, we present an effective
low-light PEFT strategy that utilizes illumination guidance and multiscale
feature fusion to enhance the model's capability in low-light environments. Our
method achieves state-of-the-art depth estimation performance on the
challenging nuScenes-Night and RobotCar-Night datasets, validating its
effectiveness using limited training data and computing resources.

</details>


### [42] [LONG3R: Long Sequence Streaming 3D Reconstruction](https://arxiv.org/abs/2507.18255)
*Zhuoguang Chen,Minghui Qin,Tianyuan Yuan,Zhe Liu,Hang Zhao*

Main category: cs.CV

TL;DR: LONG3R是一种用于长序列流式多视角三维场景重建的新模型，通过循环操作和创新的记忆体机制实现了实时处理和优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理长序列输入时存在耗时或仅限于短序列的问题，限制了其在实时场景下的应用。因此，需要一种能够处理长序列的流式多视角三维场景重建方法。

Method: LONG3R模型采用循环操作，通过内存门控机制过滤相关信息，并结合新的观测输入到双源细化解码器中进行粗到精的交互。该模型使用三维时空记忆体来动态修剪冗余的空间信息并自适应调整分辨率。此外，为了提高模型在长序列上的性能和训练效率，采用了两阶段的课程学习策略。

Result: 实验结果表明，LONG3R在长序列处理上明显优于最先进的流式方法，并能保持实时推理速度。

Conclusion: LONG3R在处理长序列的多视角三维场景重建方面，在实时推理速度和性能上均优于现有的流式方法。

Abstract: Recent advancements in multi-view scene reconstruction have been significant,
yet existing methods face limitations when processing streams of input images.
These methods either rely on time-consuming offline optimization or are
restricted to shorter sequences, hindering their applicability in real-time
scenarios. In this work, we propose LONG3R (LOng sequence streaming 3D
Reconstruction), a novel model designed for streaming multi-view 3D scene
reconstruction over longer sequences. Our model achieves real-time processing
by operating recurrently, maintaining and updating memory with each new
observation. We first employ a memory gating mechanism to filter relevant
memory, which, together with a new observation, is fed into a dual-source
refined decoder for coarse-to-fine interaction. To effectively capture
long-sequence memory, we propose a 3D spatio-temporal memory that dynamically
prunes redundant spatial information while adaptively adjusting resolution
along the scene. To enhance our model's performance on long sequences while
maintaining training efficiency, we employ a two-stage curriculum training
strategy, each stage targeting specific capabilities. Experiments demonstrate
that LONG3R outperforms state-of-the-art streaming methods, particularly for
longer sequences, while maintaining real-time inference speed. Project page:
https://zgchen33.github.io/LONG3R/.

</details>


### [43] [Exploiting Gaussian Agnostic Representation Learning with Diffusion Priors for Enhanced Infrared Small Target Detection](https://arxiv.org/abs/2507.18260)
*Junyao Li,Yahao Lu,Xingyuan Guo,Xiaoyu Xian,Tiantian Wang,Yukai Shi*

Main category: cs.CV

TL;DR: 由于当前红外小目标检测（ISTD）方法在数据稀疏时鲁棒性不足，本研究提出了高斯无关表示学习，利用高斯群压缩器和两阶段扩散模型来提高检测性能。


<details>
  <summary>Details</summary>
Motivation: 当前红外小目标检测（ISTD）方法依赖大规模、昂贵的手动标注数据，导致其在真实世界的鲁棒性不足，尤其是在数据稀疏的挑战下。本研究旨在探索数据稀疏性对ISTD性能的影响，并提出一种新的方法来提高模型的鲁棒性。

Method: 本研究提出高斯无关表示学习，具体包括利用高斯采样和压缩进行非均匀量化的“高斯群压缩器”，以及用于真实世界重建的两阶段扩散模型。

Result: 通过与最先进的检测方法在各种数据稀疏场景下进行比较评估，证明了所提出方法在提高红外小目标检测性能方面的有效性。

Conclusion: 本研究提出的高斯无关表示学习方法，通过高斯群压缩器利用高斯采样和压缩进行非均匀量化，并结合两阶段扩散模型进行真实世界重建，在各种数据稀疏场景下，显著提高了红外小目标检测方法的鲁棒性和性能。

Abstract: Infrared small target detection (ISTD) plays a vital role in numerous
practical applications. In pursuit of determining the performance boundaries,
researchers employ large and expensive manual-labeling data for representation
learning. Nevertheless, this approach renders the state-of-the-art ISTD methods
highly fragile in real-world challenges. In this paper, we first study the
variation in detection performance across several mainstream methods under
various scarcity -- namely, the absence of high-quality infrared data -- that
challenge the prevailing theories about practical ISTD. To address this
concern, we introduce the Gaussian Agnostic Representation Learning.
Specifically, we propose the Gaussian Group Squeezer, leveraging Gaussian
sampling and compression for non-uniform quantization. By exploiting a diverse
array of training samples, we enhance the resilience of ISTD models against
various challenges. Then, we introduce two-stage diffusion models for
real-world reconstruction. By aligning quantized signals closely with
real-world distributions, we significantly elevate the quality and fidelity of
the synthetic samples. Comparative evaluations against state-of-the-art
detection methods in various scarcity scenarios demonstrate the efficacy of the
proposed approach.

</details>


### [44] [Dissecting the Dental Lung Cancer Axis via Mendelian Randomization and Mediation Analysis](https://arxiv.org/abs/2507.18287)
*Wenran Zhang,Huihuan Luo,Linda Wei,Ping Nie,Yiqun Wu,Dedong Yu*

Main category: cs.CV

TL;DR: 蛀牙增加患鳞状细胞肺癌风险，肺功能下降是部分原因；牙周病则无显著影响。


<details>
  <summary>Details</summary>
Motivation: 尽管有观察性研究表明牙周病和蛀牙与肺癌之间存在关联，但其因果关系尚不明确。本研究旨在利用孟德尔随机化方法探究牙齿疾病（牙周病、蛀牙）与肺癌亚型之间的因果关系，并评估肺功能在其中起到的中介作用。

Method: 本研究采用双样本孟德尔随机化（MR）方法，并结合了最大的全基因组关联研究（GWAS）数据，包括487,823例蛀牙和506,594例牙周炎病例，以及来自Transdisciplinary Research of Cancer in Lung联盟的肺癌数据。主要分析方法为逆方差加权法（IVW），并使用delta法评估了肺功能（FVC和FEV1）的中介作用。

Result: 研究发现，蛀牙对总体肺癌和其亚型有显著的因果效应。蛀牙发病率每增加一个标准差，鳞状细胞肺癌的风险增加188.0%（OR = 2.880, 95% CI = 1.236–6.713, p = 0.014）。此外，肺活量（FVC）和第一秒用力呼气容积（FEV1）的下降分别解释了该效应的5.124%和5.890%。牙周病与肺癌之间未发现因果关系。

Conclusion: 该研究表明，蛀牙在因果关系上会增加患肺癌的风险，特别是鳞状细胞癌，部分原因是肺功能下降。牙周炎与肺癌之间未发现因果关系。

Abstract: Periodontitis and dental caries are common oral diseases affecting billions
globally. While observational studies suggest links between these conditions
and lung cancer, causality remains uncertain. This study used two sample
Mendelian randomization (MR) to explore causal relationships between dental
traits (periodontitis, dental caries) and lung cancer subtypes, and to assess
mediation by pulmonary function. Genetic instruments were derived from the
largest available genome wide association studies, including data from 487,823
dental caries and 506,594 periodontitis cases, as well as lung cancer data from
the Transdisciplinary Research of Cancer in Lung consortium. Inverse variance
weighting was the main analytical method; lung function mediation was assessed
using the delta method. The results showed a significant positive causal effect
of dental caries on overall lung cancer and its subtypes. Specifically, a one
standard deviation increase in dental caries incidence was associated with a
188.0% higher risk of squamous cell lung carcinoma (OR = 2.880, 95% CI =
1.236--6.713, p = 0.014), partially mediated by declines in forced vital
capacity (FVC) and forced expiratory volume in one second (FEV1), accounting
for 5.124% and 5.890% of the total effect. No causal effect was found for
periodontitis. These findings highlight a causal role of dental caries in lung
cancer risk and support integrating dental care and pulmonary function
monitoring into cancer prevention strategies.

</details>


### [45] [LMM-Det: Make Large Multimodal Models Excel in Object Detection](https://arxiv.org/abs/2507.18300)
*Jincheng Li,Chunyu Xie,Ji Ao,Dawei Leng,Yuhui Yin*

Main category: cs.CV

TL;DR: LMM-Det 利用大型多模态模型进行目标检测，无需专用模块，并通过数据调整和推理优化提高了性能。


<details>
  <summary>Details</summary>
Motivation: 弥补大型多模态模型在目标检测能力方面与专用检测器之间的显著差距。

Method: 提出了一种名为 LMM-Det 的方法，该方法不依赖于专门的检测模块，而是利用大型多模态模型进行目标检测。具体来说，通过数据分布调整和推理优化来提高召回率，并通过重组指令对话来增强大型多模态模型的检测能力。

Result: LMM-Det 在目标检测任务中表现出色，能够有效提高召回率，证明了其通用性和有效性。

Conclusion: LMM-Det 是一种简单而有效的方法，可以在没有专用检测模块的情况下，利用大型多模态模型进行通用目标检测，并且在召回率和整体性能方面都表现出色。

Abstract: Large multimodal models (LMMs) have garnered wide-spread attention and
interest within the artificial intelligence research and industrial
communities, owing to their remarkable capability in multimodal understanding,
reasoning, and in-context learning, among others. While LMMs have demonstrated
promising results in tackling multimodal tasks like image captioning, visual
question answering, and visual grounding, the object detection capabilities of
LMMs exhibit a significant gap compared to specialist detectors. To bridge the
gap, we depart from the conventional methods of integrating heavy detectors
with LMMs and propose LMM-Det, a simple yet effective approach that leverages a
Large Multimodal Model for vanilla object Detection without relying on
specialized detection modules. Specifically, we conduct a comprehensive
exploratory analysis when a large multimodal model meets with object detection,
revealing that the recall rate degrades significantly compared with specialist
detection models. To mitigate this, we propose to increase the recall rate by
introducing data distribution adjustment and inference optimization tailored
for object detection. We re-organize the instruction conversations to enhance
the object detection capabilities of large multimodal models. We claim that a
large multimodal model possesses detection capability without any extra
detection modules. Extensive experiments support our claim and show the
effectiveness of the versatile LMM-Det. The datasets, models, and codes are
available at https://github.com/360CVGroup/LMM-Det.

</details>


### [46] [Improving Large Vision-Language Models' Understanding for Field Data](https://arxiv.org/abs/2507.18311)
*Xiaomei Zhang,Hanyu Zheng,Xiangyu Zhu,Jinghuan Wei,Junhong Zou,Zhen Lei,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: FieldLVLM通过字段感知语言生成和数据压缩的多模态模型微调，显著提升了大型视觉语言模型理解科学字段数据的能力，并在相关任务中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大型视觉语言模型（LVLMs）在图像字幕和视觉问答等任务中展现出强大的能力，但它们在科学领域，特别是解释自然科学中复杂的田野数据方面的应用仍有待探索。

Method: FieldLVLM框架包含两个核心部分：1. 提出了一种特殊目的的机器学习管线，用于提取田野数据的关键物理特征（如流动分类、雷诺数、涡旋模式），并将其转换为结构化的文本描述，形成一个专门的数据集。2. 采用数据压缩策略对大型视觉语言模型进行微调，以降低田野输入的复杂性，保留最有效的信息值，确保与模型的语言解码器兼容，并更有效地指导其学习。

Result: 实验结果表明，FieldLVLM在处理科学田野数据的任务上，显著优于现有方法。

Conclusion: FieldLVLM的出现为大型视觉语言模型在科学研究领域的应用开辟了新的可能性，有效地弥合了大型模型与领域特定发现之间的差距。

Abstract: Large Vision-Language Models (LVLMs) have shown impressive capabilities
across a range of tasks that integrate visual and textual understanding, such
as image captioning and visual question answering. These models are trained on
large-scale image and video datasets paired with text, enabling them to bridge
visual perception and natural language processing. However, their application
to scientific domains, especially in interpreting complex field data commonly
used in the natural sciences, remains underexplored. In this work, we introduce
FieldLVLM, a novel framework designed to improve large vision-language models'
understanding of field data. FieldLVLM consists of two main components: a
field-aware language generation strategy and a data-compressed multimodal model
tuning. The field-aware language generation strategy leverages a
special-purpose machine learning pipeline to extract key physical features from
field data, such as flow classification, Reynolds number, and vortex patterns.
This information is then converted into structured textual descriptions that
serve as a dataset. The data-compressed multimodal model tuning focuses on
LVLMs with these generated datasets, using a data compression strategy to
reduce the complexity of field inputs and retain only the most informative
values. This ensures compatibility with the models language decoder and guides
its learning more effectively. Experimental results on newly proposed benchmark
datasets demonstrate that FieldLVLM significantly outperforms existing methods
in tasks involving scientific field data. Our findings suggest that this
approach opens up new possibilities for applying large vision-language models
to scientific research, helping bridge the gap between large models and
domain-specific discovery.

</details>


### [47] [Beyond Low-rankness: Guaranteed Matrix Recovery via Modified Nuclear Norm](https://arxiv.org/abs/2507.18327)
*Jiangjun Peng,Yisi Luo,Xiangyong Cao,Shuang Xu,Deyu Meng*

Main category: cs.CV

TL;DR: A new Modified Nuclear Norm (MNN) framework is proposed, which uses matrix transformations before applying the nuclear norm to better capture both local and global data structures. This method achieves theoretical recovery guarantees for Robust PCA and matrix completion tasks without needing parameter tuning, and experimental results confirm its effectiveness.


<details>
  <summary>Details</summary>
Motivation: To address limitations in existing matrix recovery methods that struggle to jointly capture local information and global low-rankness without requiring trade-off parameter tuning, and to provide exact theoretical recovery guarantees for Robust PCA and MC tasks.

Method: The study introduces a new modified nuclear norm (MNN) framework, defined by applying suitable transformations to a matrix and then performing the nuclear norm on the transformed matrix. This approach allows for joint capture of local information and global low-rankness without trade-off parameter tuning.

Result: The MNN framework jointly captures local information and global low-rankness without trade-off parameter tuning. It provides exact theoretical recovery guarantees for Robust PCA and MC tasks under mild assumptions on the transformation, outperforming existing methods that combine local and global information.

Conclusion: The MNN framework is a unified and effective approach to structured low-rank recovery, accommodating various transformations and demonstrating effectiveness through extensive experiments.

Abstract: The nuclear norm (NN) has been widely explored in matrix recovery problems,
such as Robust PCA and matrix completion, leveraging the inherent global
low-rank structure of the data. In this study, we introduce a new modified
nuclear norm (MNN) framework, where the MNN family norms are defined by
adopting suitable transformations and performing the NN on the transformed
matrix. The MNN framework offers two main advantages: (1) it jointly captures
both local information and global low-rankness without requiring trade-off
parameter tuning; (2) Under mild assumptions on the transformation, we provided
exact theoretical recovery guarantees for both Robust PCA and MC tasks-an
achievement not shared by existing methods that combine local and global
information. Thanks to its general and flexible design, MNN can accommodate
various proven transformations, enabling a unified and effective approach to
structured low-rank recovery. Extensive experiments demonstrate the
effectiveness of our method. Code and supplementary material are available at
https://github.com/andrew-pengjj/modified_nuclear_norm.

</details>


### [48] [GVCCS: A Dataset for Contrail Identification and Tracking on Visible Whole Sky Camera Sequences](https://arxiv.org/abs/2507.18330)
*Gabriel Jarry,Ramon Dalmau,Philippe Very,Franck Ballerini,Stephania-Denisa Bocu*

Main category: cs.CV

TL;DR: 提供了一个新的 contrail 数据集（GVCCS）和一个深度学习框架，以改进 contrail 监测和气候影响评估。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有 contrail 数据集在时间跟踪和来源航班归属方面的不足，该研究提出了一个新的 GVCCS 数据集，以支持 contrail 动力学和形成过程的详细分析，并促进物理模型的校准。

Method: 提出了一种包含122个视频序列（24,228帧）的地面可见光相机 contrail（飞机尾迹）序列（GVCCS）数据集，并开发了一个统一的深度学习框架，利用全景分割模型对 contrail 进行分析，包括语义分割（识别 contrail 像素）、实例分割（分离单个 contrail）和时间跟踪。

Result: 创建了一个新的 GVCCS 数据集，其中包含122个视频序列（24,228帧），并对 contrail 进行了单独标记和时间跟踪，包括其来源航班标识符。此外，还提出了一个统一的深度学习框架，用于 contrail 分析。

Conclusion: 该研究提出了一个包含122个视频序列（24,228帧）的地面可见光相机 contrail（飞机尾迹）序列（GVCCS）数据集，并提供了一个统一的深度学习框架，用于 contrail 的分析，包括语义分割、实例分割和时间跟踪。该数据集包含 contrail 的个别标签和时间跟踪信息，以及其来源航班的标识符，旨在支持改进 contrail 监测，促进物理模型的校准，并为更准确的气候影响评估奠定基础。

Abstract: Aviation's climate impact includes not only CO2 emissions but also
significant non-CO2 effects, especially from contrails. These ice clouds can
alter Earth's radiative balance, potentially rivaling the warming effect of
aviation CO2. Physics-based models provide useful estimates of contrail
formation and climate impact, but their accuracy depends heavily on the quality
of atmospheric input data and on assumptions used to represent complex
processes like ice particle formation and humidity-driven persistence.
Observational data from remote sensors, such as satellites and ground cameras,
could be used to validate and calibrate these models. However, existing
datasets don't explore all aspect of contrail dynamics and formation: they
typically lack temporal tracking, and do not attribute contrails to their
source flights. To address these limitations, we present the Ground Visible
Camera Contrail Sequences (GVCCS), a new open data set of contrails recorded
with a ground-based all-sky camera in the visible range. Each contrail is
individually labeled and tracked over time, allowing a detailed analysis of its
lifecycle. The dataset contains 122 video sequences (24,228 frames) and
includes flight identifiers for contrails that form above the camera. As
reference, we also propose a unified deep learning framework for contrail
analysis using a panoptic segmentation model that performs semantic
segmentation (contrail pixel identification), instance segmentation (individual
contrail separation), and temporal tracking in a single architecture. By
providing high-quality, temporally resolved annotations and a benchmark for
model evaluation, our work supports improved contrail monitoring and will
facilitate better calibration of physical models. This sets the groundwork for
more accurate climate impact understanding and assessments.

</details>


### [49] [Boosting Multi-View Indoor 3D Object Detection via Adaptive 3D Volume Construction](https://arxiv.org/abs/2507.18331)
*Runmin Zhang,Zhu Yu,Si-Yuan Cao,Lingyu Zhu,Guangyi Zhang,Xiaokai Bai,Hui-Liang Shen*

Main category: cs.CV

TL;DR: SGCDet是一种创新的多视图室内3D目标检测框架，通过自适应3D体积构造提高了检测性能和效率，并且仅需3D边界框进行监督。


<details>
  <summary>Details</summary>
Motivation: 为了提高多视图室内3D目标检测的表示能力和效率，克服现有方法中体素感受野固定于图像固定位置的问题，并消除对地面真实场景几何的依赖。

Method: 提出了一种基于自适应3D体积构造的多视图室内3D目标检测框架。该框架引入了几何和上下文感知聚合模块，用于整合自适应区域内的几何和上下文信息，并动态调整来自不同视图的贡献。此外，还提出了一种稀疏体积构造策略，用于自适应地识别和选择具有高占用概率的体素以进行特征细化，从而最小化自由空间中的冗余计算。

Result: SGCDet能够有效且高效地以自适应方式进行体积构造，并且仅需3D边界框即可进行监督。实验结果表明，SGCDet在ScanNet、ScanNet200和ARKitScenes数据集上取得了最先进的性能。

Conclusion: SGCDet在ScanNet、ScanNet200和ARKitScenes数据集上实现了最先进的性能，并且仅使用3D边界框进行监督，无需场景几何的地面真实信息。

Abstract: This work presents SGCDet, a novel multi-view indoor 3D object detection
framework based on adaptive 3D volume construction. Unlike previous approaches
that restrict the receptive field of voxels to fixed locations on images, we
introduce a geometry and context aware aggregation module to integrate
geometric and contextual information within adaptive regions in each image and
dynamically adjust the contributions from different views, enhancing the
representation capability of voxel features. Furthermore, we propose a sparse
volume construction strategy that adaptively identifies and selects voxels with
high occupancy probabilities for feature refinement, minimizing redundant
computation in free space. Benefiting from the above designs, our framework
achieves effective and efficient volume construction in an adaptive way. Better
still, our network can be supervised using only 3D bounding boxes, eliminating
the dependence on ground-truth scene geometry. Experimental results demonstrate
that SGCDet achieves state-of-the-art performance on the ScanNet, ScanNet200
and ARKitScenes datasets. The source code is available at
https://github.com/RM-Zhang/SGCDet.

</details>


### [50] [Improving Bird Classification with Primary Color Additives](https://arxiv.org/abs/2507.18334)
*Ezhini Rasendiran R,Chandresh Kumar Maurya*

Main category: cs.CV

TL;DR: 通过将频率信息通过颜色编码到频谱图中，可以提高鸟类物种分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 对使用鸟鸣录音对鸟类物种进行分类，由于环境噪声、声音重叠和标签缺失等因素，这是一项挑战性任务。现有模型在低信噪比或多物种录音方面存在困难。

Method: 将频率信息通过主要颜色添加剂嵌入到频谱图中，以增强物种区分。

Result: 该方法在F1分数上提高了7.3%，在ROC-AUC上提高了6.2%，在CMAP上提高了6.6%，显著优于未使用颜色编码的模型以及BirdCLEF 2024的获胜模型。

Conclusion: 通过将频率信息通过颜色编码到频谱图中，可以增强不同物种的区分度，并提高分类准确性。

Abstract: We address the problem of classifying bird species using their song
recordings, a challenging task due to environmental noise, overlapping
vocalizations, and missing labels. Existing models struggle with low-SNR or
multi-species recordings. We hypothesize that birds can be classified by
visualizing their pitch pattern, speed, and repetition, collectively called
motifs. Deep learning models applied to spectrogram images help, but similar
motifs across species cause confusion. To mitigate this, we embed frequency
information into spectrograms using primary color additives. This enhances
species distinction and improves classification accuracy. Our experiments show
that the proposed approach achieves statistically significant gains over models
without colorization and surpasses the BirdCLEF 2024 winner, improving F1 by
7.3%, ROC-AUC by 6.2%, and CMAP by 6.6%. These results demonstrate the
effectiveness of incorporating frequency information via colorization.

</details>


### [51] [EgoExoBench: A Benchmark for First- and Third-person View Video Understanding in MLLMs](https://arxiv.org/abs/2507.18342)
*Yuping He,Yifei Huang,Guo Chen,Baoqi Pei,Jilan Xu,Tong Lu,Jiangmiao Pang*

Main category: cs.CV

TL;DR: EgoExoBench是首个用于自主-他主视频理解和推理的基准，旨在评估和改进多模态大语言模型（MLLMs）的跨视角推理能力。现有模型在此类任务上表现不佳，凸显了进一步研究的必要性。


<details>
  <summary>Details</summary>
Motivation: 人类能够进行自主和他人视角之间的知识转移和整合，这对人类智能至关重要，但目前的多模态大语言模型（MLLMs）在这一能力上仍未得到探索。

Method: 该研究引入了EgoExoBench，一个专门用于自主-他主视频理解和推理的基准。该基准由公开数据集构建，并包含7300多个问答对，分为语义对齐、视角关联和时间推理三个核心挑战。

Result: 在对13个最先进的MLLMs进行评估后发现，尽管这些模型在单一视角任务上表现出色，但在自主-他主视频理解和推理的跨视角对齐、关联和时间推理方面存在挑战。

Conclusion: EgoExoBench的引入旨在推动多模态大语言模型（MLLMs）在第一人称（自主）和第三人称（他主）视角之间进行知识转移和整合的能力。该基准包含7300多个问答对，涵盖11个子任务和3项核心挑战：语义对齐、视角关联和时间推理。

Abstract: Transferring and integrating knowledge across first-person (egocentric) and
third-person (exocentric) viewpoints is intrinsic to human intelligence,
enabling humans to learn from others and convey insights from their own
experiences. Despite rapid progress in multimodal large language models
(MLLMs), their ability to perform such cross-view reasoning remains unexplored.
To address this, we introduce EgoExoBench, the first benchmark for
egocentric-exocentric video understanding and reasoning. Built from publicly
available datasets, EgoExoBench comprises over 7,300 question-answer pairs
spanning eleven sub-tasks organized into three core challenges: semantic
alignment, viewpoint association, and temporal reasoning. We evaluate 13
state-of-the-art MLLMs and find that while these models excel on single-view
tasks, they struggle to align semantics across perspectives, accurately
associate views, and infer temporal dynamics in the ego-exo context. We hope
EgoExoBench can serve as a valuable resource for research on embodied agents
and intelligent assistants seeking human-like cross-view intelligence.

</details>


### [52] [VB-Mitigator: An Open-source Framework for Evaluating and Advancing Visual Bias Mitigation](https://arxiv.org/abs/2507.18348)
*Ioannis Sarridis,Christos Koutlis,Symeon Papadopoulos,Christos Diou*

Main category: cs.CV

TL;DR: VB-Mitigator是一个开源框架，用于统一视觉偏差缓解技术的研究和评估，包含多种方法和数据集，旨在加速公平AI发展。


<details>
  <summary>Details</summary>
Motivation: 旨在解决计算机视觉模型中存在的偏差问题，这些问题导致AI系统不公平、不可靠且泛化能力差。现有研究因实现方式碎片化和评估实践不一致而受到阻碍，不同研究中使用的数据集和指标也加剧了复现性的困难，使得评估和比较不同方法的有效性变得困难。

Method: 提出并实现了一个名为VB-Mitigator的开源框架，该框架统一了视觉偏差缓解技术的研究、评估和比较分析，集成了12种已有的缓解方法和7个基准数据集，并支持扩展性，允许集成更多方法、数据集、指标和模型。

Result: VB-Mitigator提供了一个统一的研究环境，包含了12种缓解方法和7个数据集，并进行了全面的性能比较。该框架的易扩展性允许无缝集成更多内容，旨在通过提供基础代码库来加速公平感知计算机视觉模型的研究。

Conclusion: 该研究通过引入VB-Mitigator框架，旨在统一视觉偏差缓解技术的研究、评估和比较分析，并提出最佳评估实践，以加速公平感知计算机视觉模型的研究。

Abstract: Bias in computer vision models remains a significant challenge, often
resulting in unfair, unreliable, and non-generalizable AI systems. Although
research into bias mitigation has intensified, progress continues to be
hindered by fragmented implementations and inconsistent evaluation practices.
Disparate datasets and metrics used across studies complicate reproducibility,
making it difficult to fairly assess and compare the effectiveness of various
approaches. To overcome these limitations, we introduce the Visual Bias
Mitigator (VB-Mitigator), an open-source framework designed to streamline the
development, evaluation, and comparative analysis of visual bias mitigation
techniques. VB-Mitigator offers a unified research environment encompassing 12
established mitigation methods, 7 diverse benchmark datasets. A key strength of
VB-Mitigator is its extensibility, allowing for seamless integration of
additional methods, datasets, metrics, and models. VB-Mitigator aims to
accelerate research toward fairness-aware computer vision models by serving as
a foundational codebase for the research community to develop and assess their
approaches. To this end, we also recommend best evaluation practices and
provide a comprehensive performance comparison among state-of-the-art
methodologies.

</details>


### [53] [Deformable Convolution Module with Globally Learned Relative Offsets for Fundus Vessel Segmentation](https://arxiv.org/abs/2507.18354)
*Lexuan Zhu,Yuxuan Li,Yuning Ren*

Main category: cs.CV

TL;DR: 提出了一种新颖的可变形卷积模块，用于捕获长距离全局特征，并将其应用于眼底血管分割模型GDCUnet。GDCUnet在公共数据集上取得了最先进的性能，并证明了该模块的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了处理复杂形状特征，可变形卷积通过学习偏移量来适应性地改变卷积核的形状。眼底血管具有全局自相似的复杂边缘，需要能够捕获长距离全局特征的模型。

Method: 提出了一种新颖的可插入可变形卷积模块，该模块使用注意力和前馈网络来学习偏移量，以捕获长距离全局特征。该模块通过学习子像素位移场并自适应地扭曲所有通道的特征图来实现全局特征变形，并将卷积核大小与学习网络解耦。在此基础上，设计了一个用于眼底血管分割的深度学习模型GDCUnet。

Result: GDCUnet在公共数据集上实现了最先进的性能，并且所提出的可变形卷积模块能够更显著地学习眼底血管的复杂特征，增强了模型的表示和泛化能力。

Conclusion: 该模型在公共数据集上取得了最先进的性能，并且在消融实验中证明了其有效性，可以应用于更多具有复杂全局自相似特征的计算机视觉任务。

Abstract: Deformable convolution can adaptively change the shape of convolution kernel
by learning offsets to deal with complex shape features. We propose a novel
plug and play deformable convolutional module that uses attention and
feedforward networks to learn offsets, so that the deformable patterns can
capture long-distance global features. Compared with previously existing
deformable convolutions, the proposed module learns the sub pixel displacement
field and adaptively warps the feature maps across all channels rather than
directly deforms the convolution kernel , which is equivalent to a relative
deformation of the kernel sampling grids, achieving global feature deformation
and the decoupling of kernel size and learning network. Considering that the
fundus blood vessels have globally self similar complex edges, we design a deep
learning model for fundus blood vessel segmentation, GDCUnet, based on the
proposed convolutional module. Empirical evaluations under the same
configuration and unified framework show that GDCUnet has achieved state of the
art performance on public datasets. Further ablation experiments demonstrated
that the proposed deformable convolutional module could more significantly
learn the complex features of fundus blood vessels, enhancing the model
representation and generalization capabilities.The proposed module is similar
to the interface of conventional convolution, we suggest applying it to more
machine vision tasks with complex global self similar features.

</details>


### [54] [MVG4D: Image Matrix-Based Multi-View and Motion Generation for 4D Content Creation from a Single Image](https://arxiv.org/abs/2507.18371)
*Xiaotian Chen,DongFu Yin,Fei Richard Yu,Xuanchen Li,Xinhao Zhang*

Main category: cs.CV

TL;DR: MVG4D 是一个新框架，利用多视图合成和 4D 高斯泼溅从单张图片生成动态 4D 内容，提高了时间一致性和视觉真实感，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 尽管生成模型在数字内容创作方面取得了显著进展，但从 2D 图像扩展到复杂的 3D 和 4D 场景，尤其是在生成高保真和时间一致的动态 4D 内容方面，仍然是一个挑战。

Method: MVG4D 框架的核心是一个图像矩阵模块，用于合成时间连贯且空间多样的多视图图像，为下游的 3D 和 4D 重建提供丰富的监督信号。这些多视图图像随后用于优化 3D 高斯点云，并通过一个轻量级变形网络将其扩展到时间域。

Result: MVG4D 在 Objaverse 数据集上的广泛实验表明，与最先进的基线相比，在 CLIP-I、PSNR、FVD 和时间效率方面均表现更优。该方法显著减少了闪烁伪影，锐化了跨视图和时间的结构细节，从而能够实现更具沉浸感的 AR/VR 体验。

Conclusion: MVG4D 通过结合多视图合成和 4D 高斯泼溅（4D GS）的创新框架，实现了从单张静态图像生成动态 4D 内容，有效解决了现有 4D GS 方法在运动不连续和背景退化方面的挑战。实验证明 MVG4D 在多个指标上优于现有技术，并能减少闪烁、锐化结构细节，为 4D 内容生成开辟了新的高效可控方向。

Abstract: Advances in generative modeling have significantly enhanced digital content
creation, extending from 2D images to complex 3D and 4D scenes. Despite
substantial progress, producing high-fidelity and temporally consistent dynamic
4D content remains a challenge. In this paper, we propose MVG4D, a novel
framework that generates dynamic 4D content from a single still image by
combining multi-view synthesis with 4D Gaussian Splatting (4D GS). At its core,
MVG4D employs an image matrix module that synthesizes temporally coherent and
spatially diverse multi-view images, providing rich supervisory signals for
downstream 3D and 4D reconstruction. These multi-view images are used to
optimize a 3D Gaussian point cloud, which is further extended into the temporal
domain via a lightweight deformation network. Our method effectively enhances
temporal consistency, geometric fidelity, and visual realism, addressing key
challenges in motion discontinuity and background degradation that affect prior
4D GS-based methods. Extensive experiments on the Objaverse dataset demonstrate
that MVG4D outperforms state-of-the-art baselines in CLIP-I, PSNR, FVD, and
time efficiency. Notably, it reduces flickering artifacts and sharpens
structural details across views and time, enabling more immersive AR/VR
experiences. MVG4D sets a new direction for efficient and controllable 4D
generation from minimal inputs.

</details>


### [55] [Towards Effective Human-in-the-Loop Assistive AI Agents](https://arxiv.org/abs/2507.18374)
*Filippos Bellos,Yayuan Li,Cary Shu,Ruey Day,Jeffrey M. Siskind,Jason J. Corso*

Main category: cs.CV

TL;DR: This paper presents a framework and dataset for evaluating human-AI collaboration in physical tasks, along with an AR-equipped AI agent that provides guidance. Human studies show that AI assistance improves task completion.


<details>
  <summary>Details</summary>
Motivation: Effective human-AI collaboration for physical task completion has significant potential, but evaluating such collaboration is challenging due to the complexity of human-in-the-loop interactions.

Method: The paper introduces an evaluation framework and a multimodal dataset of human-AI interactions. It also develops an AR-equipped AI agent that provides interactive guidance in real-world tasks.

Result: The study demonstrates that AI-assisted collaboration improves task completion, with empirical insights into AI-assisted human performance shared through human studies.

Conclusion: AI-assisted collaboration improves task completion.

Abstract: Effective human-AI collaboration for physical task completion has significant
potential in both everyday activities and professional domains. AI agents
equipped with informative guidance can enhance human performance, but
evaluating such collaboration remains challenging due to the complexity of
human-in-the-loop interactions. In this work, we introduce an evaluation
framework and a multimodal dataset of human-AI interactions designed to assess
how AI guidance affects procedural task performance, error reduction and
learning outcomes. Besides, we develop an augmented reality (AR)-equipped AI
agent that provides interactive guidance in real-world tasks, from cooking to
battlefield medicine. Through human studies, we share empirical insights into
AI-assisted human performance and demonstrate that AI-assisted collaboration
improves task completion.

</details>


### [56] [Towards Consistent Long-Term Pose Generation](https://arxiv.org/abs/2507.18382)
*Yayuan Li,Filippos Bellos,Jason Corso*

Main category: cs.CV

TL;DR: 提出了一种新的单阶段姿势生成方法，直接在连续坐标空间中操作，通过相对运动预测和统一占位符令牌，克服了现有方法的误差累积问题，并在长期生成任务中取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有姿势生成方法依赖中间表示（如量化或自回归模型），在长期生成时会累积误差，导致性能下降和时间相干性差。本研究旨在解决这一根本性限制。

Method: 提出了一种新颖的单阶段架构，直接从单个RGB图像和文本描述生成连续坐标空间中的姿势，通过相对运动预测机制和统一的占位符令牌方法，消除了对中间表示或基于令牌生成的需求。

Result: 在Penn Action和F-PHAB数据集上的大量实验表明，该方法显著优于现有的基于量化和自回归的方法，尤其在长期生成场景下。

Conclusion: 该方法通过直接在连续坐标空间中生成姿势，并采用相对运动预测机制和统一的占位符令牌方法，克服了现有基于量化和自回归方法的局限性，尤其在长期生成方面表现更优。

Abstract: Current approaches to pose generation rely heavily on intermediate
representations, either through two-stage pipelines with quantization or
autoregressive models that accumulate errors during inference. This fundamental
limitation leads to degraded performance, particularly in long-term pose
generation where maintaining temporal coherence is crucial. We propose a novel
one-stage architecture that directly generates poses in continuous coordinate
space from minimal context - a single RGB image and text description - while
maintaining consistent distributions between training and inference. Our key
innovation is eliminating the need for intermediate representations or
token-based generation by operating directly on pose coordinates through a
relative movement prediction mechanism that preserves spatial relationships,
and a unified placeholder token approach that enables single-forward generation
with identical behavior during training and inference. Through extensive
experiments on Penn Action and First-Person Hand Action Benchmark (F-PHAB)
datasets, we demonstrate that our approach significantly outperforms existing
quantization-based and autoregressive methods, especially in long-term
generation scenarios.

</details>


### [57] [SynC: Synthetic Image Caption Dataset Refinement with One-to-many Mapping for Zero-shot Image Captioning](https://arxiv.org/abs/2507.18616)
*Si-Woo Kim,MinJu Jeon,Ye-Chan Kim,Soeun Lee,Taewhan Kim,Dong-Jin Kim*

Main category: cs.CV

TL;DR: SynC 通过将标题重新分配给合成图像池中最语义对齐的图像来精炼用于零次图像字幕（ZIC）的合成数据集，从而提高 ZIC 模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的数据集修剪技术主要用于删除网络爬取数据中有噪声的文本，但这些方法不适合合成数据特有的挑战，因为合成数据通常具有格式良好的标题，但图像可能是表示不准确的。为了解决这个差距，我们引入了 SynC，一个专门为 ZIC 设计的用于精炼合成图像-标题数据集的新颖框架。

Method: SynC 采用一对多映射策略，首先为每个标题检索多个相关的候选图像，然后应用受循环一致性启发的对齐评分器，通过验证其通过图像到文本检索检索原始标题的能力来选择最佳图像。

Result: 广泛的评估表明，SynC 在标准基准（MS-COCO、Flickr30k、NoCaps）上的各种 ZIC 模型方面，能够一致且显著地提高性能，在某些场景中达到最先进的结果。

Conclusion: SynC 提供了一种有效的策略来整理精炼的合成数据以增强 ZIC。

Abstract: Zero-shot Image Captioning (ZIC) increasingly utilizes synthetic datasets
generated by text-to-image (T2I) models to mitigate the need for costly manual
annotation. However, these T2I models often produce images that exhibit
semantic misalignments with their corresponding input captions (e.g., missing
objects, incorrect attributes), resulting in noisy synthetic image-caption
pairs that can hinder model training. Existing dataset pruning techniques are
largely designed for removing noisy text in web-crawled data. However, these
methods are ill-suited for the distinct challenges of synthetic data, where
captions are typically well-formed, but images may be inaccurate
representations. To address this gap, we introduce SynC, a novel framework
specifically designed to refine synthetic image-caption datasets for ZIC.
Instead of conventional filtering or regeneration, SynC focuses on reassigning
captions to the most semantically aligned images already present within the
synthetic image pool. Our approach employs a one-to-many mapping strategy by
initially retrieving multiple relevant candidate images for each caption. We
then apply a cycle-consistency-inspired alignment scorer that selects the best
image by verifying its ability to retrieve the original caption via
image-to-text retrieval. Extensive evaluations demonstrate that SynC
consistently and significantly improves performance across various ZIC models
on standard benchmarks (MS-COCO, Flickr30k, NoCaps), achieving state-of-the-art
results in several scenarios. SynC offers an effective strategy for curating
refined synthetic data to enhance ZIC.

</details>


### [58] [HumanMaterial: Human Material Estimation from a Single Image via Progressive Training](https://arxiv.org/abs/2507.18385)
*Yu Jiang,Jiahao Xia,Jiongming Qin,Yusen Wang,Tuo Cao,Chunxia Xiao*

Main category: cs.CV

TL;DR: 该研究提出了一种新的全身体逆渲染方法，通过使用高质量数据集和新颖的模型（HumanMaterial）及损失函数（CPR），显著提高了渲染真实感，特别是在皮肤材质上，并在实验中取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 先前工作在全身体逆渲染中，为了获得照片级真实感渲染效果，需要估计多种材质图，但这通常依赖渲染结果的约束，且材质图本身缺少约束，导致问题本质上是病态的。以往方法通过构建材质数据集进行训练，但其简化的材质数据和渲染方程限制了渲染结果的真实感，特别是皮肤。为了提高渲染真实感，尤其针对皮肤，需要更高质量的数据集和更有效的模型。同时，随着预测材质数量的增加，端到端模型难以平衡各材质图的重要性，易导致模型欠拟合。

Method: 本研究提出了一种基于物理渲染（physically-based rendering）的全身体逆渲染方法。该方法构建了名为OpenHumanBRDF的高质量数据集，并设计了HumanMaterial模型，采用渐进式训练策略，结合三种先验模型和一个微调模型来估计多种材质（包括法线、漫反射、粗糙度、镜面反射、位移和次表面散射）。此外，还提出了Controlled PBR Rendering (CPR) 损失函数，以在训练先验模型时增强不同材质的重要性。

Result: 通过在OpenHumanBRDF数据集和真实数据上的大量实验证明，本研究提出的方法在全身体逆渲染任务上达到了最先进的性能，尤其在皮肤等材质的真实感方面有显著提升。

Conclusion: 本研究通过构建高质量数据集OpenHumanBRDF，并提出HumanMaterial模型及CPR损失函数，解决了全身体（full-body）逆渲染中真实感渲染和多材质估计的挑战，尤其在皮肤材质方面取得了显著进展，实现了最先进的性能。

Abstract: Full-body Human inverse rendering based on physically-based rendering aims to
acquire high-quality materials, which helps achieve photo-realistic rendering
under arbitrary illuminations. This task requires estimating multiple material
maps and usually relies on the constraint of rendering result. The absence of
constraints on the material maps makes inverse rendering an ill-posed task.
Previous works alleviated this problem by building material dataset for
training, but their simplified material data and rendering equation lead to
rendering results with limited realism, especially that of skin. To further
alleviate this problem, we construct a higher-quality dataset (OpenHumanBRDF)
based on scanned real data and statistical material data. In addition to the
normal, diffuse albedo, roughness, specular albedo, we produce displacement and
subsurface scattering to enhance the realism of rendering results, especially
for the skin. With the increase in prediction tasks for more materials, using
an end-to-end model as in the previous work struggles to balance the importance
among various material maps, and leads to model underfitting. Therefore, we
design a model (HumanMaterial) with progressive training strategy to make full
use of the supervision information of the material maps and improve the
performance of material estimation. HumanMaterial first obtain the initial
material results via three prior models, and then refine the results by a
finetuning model. Prior models estimate different material maps, and each map
has different significance for rendering results. Thus, we design a Controlled
PBR Rendering (CPR) loss, which enhances the importance of the materials to be
optimized during the training of prior models. Extensive experiments on
OpenHumanBRDF dataset and real data demonstrate that our method achieves
state-of-the-art performance.

</details>


### [59] [Iwin Transformer: Hierarchical Vision Transformer using Interleaved Windows](https://arxiv.org/abs/2507.18405)
*Simin Huo,Ning Li*

Main category: cs.CV

TL;DR: Iwin Transformer 是一种创新的视觉 Transformer，它结合了窗口注意力和卷积，实现了高效的全局信息交换，并在多项视觉任务中取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 克服 Swin Transformer 需要连续两个块才能近似全局注意力的限制，并在单个模块内实现全局信息交换。

Method: Iwin Transformer 使用交错窗口注意力和深度可分离卷积相结合的方式，实现了位置嵌入无关的层级视觉 Transformer。注意力机制用于连接远距离的 token，而卷积则用于连接邻近的 token，从而在单个模块内实现全局信息交换。

Result: 在 ImageNet-1K 上的图像分类任务中取得了 87.4% 的 top-1 准确率，并在语义分割和视频动作识别等任务中表现出强大的竞争力。此外，Iwin Transformer 的核心组件可作为独立模块替换现有模型中的自注意力模块，并对未来的研究（如视频生成中的 Iwin 3D Attention）具有启发潜力。

Conclusion: Iwin Transformer 是一种新颖的、无位置嵌入的、可直接从低分辨率微调到高分辨率的层级视觉 Transformer。它通过创新的交错窗口注意力和深度可分离卷积协同工作，其中注意力连接远距离 token，卷积连接相邻 token，从而在单个模块内实现全局信息交换，克服了 Swin Transformer 需要连续两个块才能近似全局注意力的限制。

Abstract: We introduce Iwin Transformer, a novel position-embedding-free hierarchical
vision transformer, which can be fine-tuned directly from low to high
resolution, through the collaboration of innovative interleaved window
attention and depthwise separable convolution. This approach uses attention to
connect distant tokens and applies convolution to link neighboring tokens,
enabling global information exchange within a single module, overcoming Swin
Transformer's limitation of requiring two consecutive blocks to approximate
global attention. Extensive experiments on visual benchmarks demonstrate that
Iwin Transformer exhibits strong competitiveness in tasks such as image
classification (87.4 top-1 accuracy on ImageNet-1K), semantic segmentation and
video action recognition. We also validate the effectiveness of the core
component in Iwin as a standalone module that can seamlessly replace the
self-attention module in class-conditional image generation. The concepts and
methods introduced by the Iwin Transformer have the potential to inspire future
research, like Iwin 3D Attention in video generation. The code and models are
available at https://github.com/cominder/Iwin-Transformer.

</details>


### [60] [DCFFSNet: Deep Connectivity Feature Fusion Separation Network for Medical Image Segmentation](https://arxiv.org/abs/2507.18407)
*Xun Ye,Ruixiang Tang,Mingda Zhang,Jianglong Qin*

Main category: cs.CV

TL;DR: DCFFSNet, a novel network for medical image segmentation, improves edge precision and regional consistency by decoupling and dynamically balancing connectivity features with other features, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing deep networks integrating connectivity often forcibly inject it as an additional feature module, resulting in coupled feature spaces with no standardized mechanism to quantify different feature strengths.

Method: The paper proposes DCFFSNet (Dual-Connectivity Feature Fusion-Separation Network), which introduces a feature space decoupling strategy to quantify the relative strength between connectivity features and other features. It builds a deep connectivity feature fusion-separation architecture that dynamically balances multi-scale feature expression.

Result: Experiments on ISIC2018, DSB2018, and MoNuSeg datasets showed DCFFSNet outperforming other models by significant margins in Dice and IoU metrics. For example, on ISIC2018, it achieved 1.3% higher Dice and 1.2% higher IoU than CMUNet.

Conclusion: DCFFSNet effectively resolves segmentation fragmentation and achieves smooth edge transitions, significantly enhancing clinical usability, outperforming existing mainstream methods across all metrics.

Abstract: Medical image segmentation leverages topological connectivity theory to
enhance edge precision and regional consistency. However, existing deep
networks integrating connectivity often forcibly inject it as an additional
feature module, resulting in coupled feature spaces with no standardized
mechanism to quantify different feature strengths. To address these issues, we
propose DCFFSNet (Dual-Connectivity Feature Fusion-Separation Network). It
introduces an innovative feature space decoupling strategy. This strategy
quantifies the relative strength between connectivity features and other
features. It then builds a deep connectivity feature fusion-separation
architecture. This architecture dynamically balances multi-scale feature
expression. Experiments were conducted on the ISIC2018, DSB2018, and MoNuSeg
datasets. On ISIC2018, DCFFSNet outperformed the next best model (CMUNet) by
1.3% (Dice) and 1.2% (IoU). On DSB2018, it surpassed TransUNet by 0.7% (Dice)
and 0.9% (IoU). On MoNuSeg, it exceeded CSCAUNet by 0.8% (Dice) and 0.9% (IoU).
The results demonstrate that DCFFSNet exceeds existing mainstream methods
across all metrics. It effectively resolves segmentation fragmentation and
achieves smooth edge transitions. This significantly enhances clinical
usability.

</details>


### [61] [Self-Supervised Ultrasound-Video Segmentation with Feature Prediction and 3D Localised Loss](https://arxiv.org/abs/2507.18424)
*Edward Ellis,Robert Mendel,Andrew Bulpitt,Nasim Parsa,Michael F Byrne,Sharib Ali*

Main category: cs.CV

TL;DR: 本研究将 V-JEPA 自监督学习框架应用于超声视频分割，并通过引入 3D 局部性辅助任务克服 ViT 模型在医学小数据集上的局限性，显著提升了分割性能，尤其是在数据量较少时效果更佳。


<details>
  <summary>Details</summary>
Motivation: 超声图像数据获取和标注成本高，而自监督学习（SSL）能在有限标注数据下提升模型性能。V-JEPA 作为一种基于特征预测的 SSL 方法，具有不依赖像素级重建和负样本的优点，有望克服超声图像噪声和伪影问题，有效利用时序信息。

Method: 本研究首次将 V-JEPA 框架应用于超声视频数据，并提出了一种新的 3D 局部性辅助任务，以增强 ViT 模型在 V-JEPA 预训练过程中的局部特征学习能力。

Result: 实验结果表明，V-JEPA 结合提出的辅助任务，在不同的冻结编码器配置下，显著提高了分割性能。在 100% 训练数据下提升了 3.4%，在仅使用 10% 训练数据的情况下提升高达 8.35%。

Conclusion: V-JEPA 结合提出的 3D 局部性辅助任务在超声图像分割任务上展现出优越性能，尤其是在标注数据有限的情况下，能够显著提升分割效果。

Abstract: Acquiring and annotating large datasets in ultrasound imaging is challenging
due to low contrast, high noise, and susceptibility to artefacts. This process
requires significant time and clinical expertise. Self-supervised learning
(SSL) offers a promising solution by leveraging unlabelled data to learn useful
representations, enabling improved segmentation performance when annotated data
is limited. Recent state-of-the-art developments in SSL for video data include
V-JEPA, a framework solely based on feature prediction, avoiding pixel level
reconstruction or negative samples. We hypothesise that V-JEPA is well-suited
to ultrasound imaging, as it is less sensitive to noisy pixel-level detail
while effectively leveraging temporal information. To the best of our
knowledge, this is the first study to adopt V-JEPA for ultrasound video data.
Similar to other patch-based masking SSL techniques such as VideoMAE, V-JEPA is
well-suited to ViT-based models. However, ViTs can underperform on small
medical datasets due to lack of inductive biases, limited spatial locality and
absence of hierarchical feature learning. To improve locality understanding, we
propose a novel 3D localisation auxiliary task to improve locality in ViT
representations during V-JEPA pre-training. Our results show V-JEPA with our
auxiliary task improves segmentation performance significantly across various
frozen encoder configurations, with gains up to 3.4\% using 100\% and up to
8.35\% using only 10\% of the training data.

</details>


### [62] [NLML-HPE: Head Pose Estimation with Limited Data via Manifold Learning](https://arxiv.org/abs/2507.18429)
*Mahdi Ghafourian,Federico M. Sukno*

Main category: cs.CV

TL;DR: 通过张量分解和神经网络将头部姿态估计作为回归问题，解决了数据限制和标签不准确的问题，实现了实时性能。


<details>
  <summary>Details</summary>
Motivation: 头部姿态估计（HPE）在人机交互和面部识别等计算机视觉应用中至关重要，但现有的HPE方法在训练数据有限和标签不准确的情况下存在挑战。

Method: 提出了一种名为NLML-HPE的新型深度学习方法，结合了张量分解（Tucker分解）和前馈神经网络，将头部姿态估计（HPE）表述为回归问题，将输入标志点映射到连续的姿态角度表示。该方法将每个欧拉角分解到不同的子空间，并将流形的每个维度建模为余弦曲线。

Result: 该方法在训练数据有限的情况下实现了实时性能，并且能够准确地捕捉物体旋转的特性，从而能够快速预测未见过的数据。

Conclusion: NLML-HPE通过结合张量分解和前馈神经网络，将头部姿态估计（HPE）作为一个回归问题，为每个欧拉角（偏航、俯仰、翻滚）映射到连续的姿态角度表示。该方法通过生成精确的2D数据集解决了标签不准确的挑战，并通过学习旋转的内在流形实现了实时性能，即使在训练数据有限的情况下也是如此。

Abstract: Head pose estimation (HPE) plays a critical role in various computer vision
applications such as human-computer interaction and facial recognition. In this
paper, we propose a novel deep learning approach for head pose estimation with
limited training data via non-linear manifold learning called NLML-HPE. This
method is based on the combination of tensor decomposition (i.e., Tucker
decomposition) and feed forward neural networks. Unlike traditional
classification-based approaches, our method formulates head pose estimation as
a regression problem, mapping input landmarks into a continuous representation
of pose angles. To this end, our method uses tensor decomposition to split each
Euler angle (yaw, pitch, roll) to separate subspaces and models each dimension
of the underlying manifold as a cosine curve. We address two key challenges: 1.
Almost all HPE datasets suffer from incorrect and inaccurate pose annotations.
Hence, we generated a precise and consistent 2D head pose dataset for our
training set by rotating 3D head models for a fixed set of poses and rendering
the corresponding 2D images. 2. We achieved real-time performance with limited
training data as our method accurately captures the nature of rotation of an
object from facial landmarks. Once the underlying manifold for rotation around
each axis is learned, the model is very fast in predicting unseen data. Our
training and testing code is available online along with our trained models:
https: //github.com/MahdiGhafoorian/NLML_HPE.

</details>


### [63] [PDB-Eval: An Evaluation of Large Multimodal Models for Description and Explanation of Personalized Driving Behavior](https://arxiv.org/abs/2507.18447)
*Junda Wu,Jessica Echterhoff,Kyungtae Han,Amr Abdelraouf,Rohit Gupta,Julian McAuley*

Main category: cs.CV

TL;DR: 本研究提出了PDB-Eval，一个用于评估和微调大型多模态模型（MLLMs）在驾驶行为理解和推理能力的基准。通过在PDB-X和PDB-QA数据集上进行微调，MLLMs在驾驶相关的问答和意图预测任务上取得了显著的性能提升，证明了该方法在弥合模型与驾驶领域之间差距方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有数据集在基于外部视觉证据描述和解释车辆运动方面的局限性，本研究旨在为个性化驾驶行为的详细理解提供一个基准，并使大型多模态模型（MLLMs）能够更好地理解和推理驾驶场景。这对于风险评估、事故预防以及为驾驶员行为定制安全和驾驶辅助系统至关重要。

Method: 本研究提出PDB-Eval基准，包含PDB-X和PDB-QA两个主要部分。PDB-X用于评估MLLMs对时间驾驶场景的理解能力，其数据集设计旨在从外部视角寻找有效的视觉证据来解释内部视角下的驾驶员行为。PDB-QA则是一个视觉解释问答任务，用于MLLMs的指令微调，以对其推理能力进行校准，从而弥合领域差距并保持模型的泛化能力。

Result: MLLMs在PDB-Eval基准上进行了微调，在问答任务上的零样本性能提升高达73.2%。在Brain4Cars的转弯意图预测任务上，性能提升高达12.5%。在AIDE的所有任务上，性能也得到了一致的提升，最高可达11.0%。

Conclusion: 该研究通过引入PDB-Eval基准，包括PDB-X和PDB-QA，成功地将大型多模态模型（MLLMs）应用于理解和推理驾驶行为。实验结果表明，在细粒度描述和解释上对MLLMs进行微调，能够有效缩小MLLMs与驾驶领域之间的差距，并在问答任务上实现高达73.2%的零样本性能提升。此外，在Brain4Cars和AIDE等实际任务中的评估也显示出显著的性能改进，分别在转弯意图预测任务上提升高达12.5%，在AIDE的所有任务上提升高达11.0%。

Abstract: Understanding a driver's behavior and intentions is important for potential
risk assessment and early accident prevention. Safety and driver assistance
systems can be tailored to individual drivers' behavior, significantly
enhancing their effectiveness. However, existing datasets are limited in
describing and explaining general vehicle movements based on external visual
evidence. This paper introduces a benchmark, PDB-Eval, for a detailed
understanding of Personalized Driver Behavior, and aligning Large Multimodal
Models (MLLMs) with driving comprehension and reasoning. Our benchmark consists
of two main components, PDB-X and PDB-QA. PDB-X can evaluate MLLMs'
understanding of temporal driving scenes. Our dataset is designed to find valid
visual evidence from the external view to explain the driver's behavior from
the internal view. To align MLLMs' reasoning abilities with driving tasks, we
propose PDB-QA as a visual explanation question-answering task for MLLM
instruction fine-tuning. As a generic learning task for generative models like
MLLMs, PDB-QA can bridge the domain gap without harming MLLMs'
generalizability. Our evaluation indicates that fine-tuning MLLMs on
fine-grained descriptions and explanations can effectively bridge the gap
between MLLMs and the driving domain, which improves zero-shot performance on
question-answering tasks by up to 73.2%. We further evaluate the MLLMs
fine-tuned on PDB-X in Brain4Cars' intention prediction and AIDE's recognition
tasks. We observe up to 12.5% performance improvements on the turn intention
prediction task in Brain4Cars, and consistent performance improvements up to
11.0% on all tasks in AIDE.

</details>


### [64] [Revisiting Physically Realizable Adversarial Object Attack against LiDAR-based Detection: Clarifying Problem Formulation and Experimental Protocols](https://arxiv.org/abs/2507.18457)
*Luo Cheng,Hanwei Zhang,Lijun Zhang,Holger Hermanns*

Main category: cs.CV

TL;DR: 提出一个标准化的物理对抗激光雷达攻击框架，解决了现实世界中可实现性和重现性问题，并通过模拟到物理的成功攻击转移进行了验证。


<details>
  <summary>Details</summary>
Motivation: 解决当前物理对抗性对象攻击在现实世界中可实现性差、重现性低的问题，旨在为激光雷达目标检测的对抗性鲁棒性研究提供一个标准化的评估平台。

Method: 提出一个设备无关的标准化框架，该框架抽象了物理对抗性对象攻击的关键要素，支持多种方法，并提供开源代码和基准测试协议，可在模拟和真实世界环境中进行测试。

Result: 成功将模拟攻击转移到物理激光雷达系统，验证了框架的有效性，并为影响攻击成功率的因素提供了见解，深化了对现实世界激光雷达感知中对抗性鲁棒性的理解。

Conclusion: 该研究提出了一个设备无关的标准化框架，用于物理对抗性激光雷达目标攻击，支持多种方法，并提供了模拟和真实世界设置的开源代码和基准测试协议。该框架促进了公平比较，加速了研究，并通过将模拟攻击成功转移到物理激光雷达系统进行了验证。

Abstract: Adversarial robustness in LiDAR-based 3D object detection is a critical
research area due to its widespread application in real-world scenarios. While
many digital attacks manipulate point clouds or meshes, they often lack
physical realizability, limiting their practical impact. Physical adversarial
object attacks remain underexplored and suffer from poor reproducibility due to
inconsistent setups and hardware differences. To address this, we propose a
device-agnostic, standardized framework that abstracts key elements of physical
adversarial object attacks, supports diverse methods, and provides open-source
code with benchmarking protocols in simulation and real-world settings. Our
framework enables fair comparison, accelerates research, and is validated by
successfully transferring simulated attacks to a physical LiDAR system. Beyond
the framework, we offer insights into factors influencing attack success and
advance understanding of adversarial robustness in real-world LiDAR perception.

</details>


### [65] [CRUISE: Cooperative Reconstruction and Editing in V2X Scenarios using Gaussian Splatting](https://arxiv.org/abs/2507.18473)
*Haoran Xu,Saining Zhang,Peishuo Li,Baijun Ye,Xiaoxue Chen,Huan-ang Gao,Jv Zheng,Xiaowei Song,Ziqiao Peng,Run Miao,Jinrang Jia,Yifeng Shi,Guangqi Yi,Hang Zhao,Hao Tang,Hongyang Li,Kaicheng Yu,Hao Zhao*

Main category: cs.CV

TL;DR: CRUISE是一个用于V2X驾驶环境的重建和合成框架，利用分解高斯泼溅技术，能够高保真重建和增强V2X场景数据，从而提升自动驾驶模型的性能。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶领域，V2X通信至关重要，但其在数据生成和增强方面的潜力尚未被充分发掘。本研究旨在利用仿真技术为V2X场景提供数据支持。

Method: CRUISE框架采用分解高斯泼溅技术来重建和合成V2X驾驶环境。该技术能够准确重建真实世界场景，并通过将动态交通参与者分解为可编辑的高斯表示，实现对驾驶场景的灵活修改和增强。

Result: CRUISE能够高保真地重建V2X驾驶场景，提升多视角下的3D检测和协同3D跟踪性能，并能有效生成具有挑战性的边缘案例。

Conclusion: CRUISE框架能够高保真地重建V2X驾驶场景，通过支持灵活编辑的分解高斯泼溅技术，能够无缝修改和增强驾驶场景。此外，该框架能从主车和基础设施的视角渲染图像，从而实现大规模V2X数据集增强，用于训练和评估。实验结果表明，CRUISE能够提升多视角下的3D检测以及V2X-Seq基准上的协同3D跟踪，并能有效生成具有挑战性的边缘案例。

Abstract: Vehicle-to-everything (V2X) communication plays a crucial role in autonomous
driving, enabling cooperation between vehicles and infrastructure. While
simulation has significantly contributed to various autonomous driving tasks,
its potential for data generation and augmentation in V2X scenarios remains
underexplored. In this paper, we introduce CRUISE, a comprehensive
reconstruction-and-synthesis framework designed for V2X driving environments.
CRUISE employs decomposed Gaussian Splatting to accurately reconstruct
real-world scenes while supporting flexible editing. By decomposing dynamic
traffic participants into editable Gaussian representations, CRUISE allows for
seamless modification and augmentation of driving scenes. Furthermore, the
framework renders images from both ego-vehicle and infrastructure views,
enabling large-scale V2X dataset augmentation for training and evaluation. Our
experimental results demonstrate that: 1) CRUISE reconstructs real-world V2X
driving scenes with high fidelity; 2) using CRUISE improves 3D detection across
ego-vehicle, infrastructure, and cooperative views, as well as cooperative 3D
tracking on the V2X-Seq benchmark; and 3) CRUISE effectively generates
challenging corner cases.

</details>


### [66] [Q-Former Autoencoder: A Modern Framework for Medical Anomaly Detection](https://arxiv.org/abs/2507.18481)
*Francesco Dalmonte,Emirhan Bayar,Emre Akbas,Mariana-Iuliana Georgescu*

Main category: cs.CV

TL;DR: 提出Q-Former自编码器，利用预训练的视觉基础模型和Q-Former架构进行无监督医学图像异常检测，在多个数据集上取得SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 旨在解决医学图像异常检测中存在的异常多样性和标注数据缺乏的挑战，提出一种无监督的解决方案。

Method: 提出了一种现代化的、基于自编码器的框架——Q-Former自编码器，该框架利用预训练的视觉基础模型（如DINO、DINOv2和掩码自编码器）作为特征提取器，并使用Q-Former架构作为瓶颈来聚合多尺度特征，同时结合感知损失来指导重建。

Result: 在BraTS2021、RESC和RSNA四个数据集上取得了先进的成果，展示了视觉基础模型在医学图像异常检测中的有效性。

Conclusion: 该框架利用预训练的视觉基础模型（如DINO、DINOv2和掩码自编码器）作为特征提取器，并结合Q-Former架构和感知损失，在医学图像异常检测任务上取得了先进的成果，证明了在自然图像上预训练的模型能够有效地泛化到医学图像分析任务中，而无需进一步微调。

Abstract: Anomaly detection in medical images is an important yet challenging task due
to the diversity of possible anomalies and the practical impossibility of
collecting comprehensively annotated data sets. In this work, we tackle
unsupervised medical anomaly detection proposing a modernized autoencoder-based
framework, the Q-Former Autoencoder, that leverages state-of-the-art pretrained
vision foundation models, such as DINO, DINOv2 and Masked Autoencoder. Instead
of training encoders from scratch, we directly utilize frozen vision foundation
models as feature extractors, enabling rich, multi-stage, high-level
representations without domain-specific fine-tuning. We propose the usage of
the Q-Former architecture as the bottleneck, which enables the control of the
length of the reconstruction sequence, while efficiently aggregating multiscale
features. Additionally, we incorporate a perceptual loss computed using
features from a pretrained Masked Autoencoder, guiding the reconstruction
towards semantically meaningful structures. Our framework is evaluated on four
diverse medical anomaly detection benchmarks, achieving state-of-the-art
results on BraTS2021, RESC, and RSNA. Our results highlight the potential of
vision foundation model encoders, pretrained on natural images, to generalize
effectively to medical image analysis tasks without further fine-tuning. We
release the code and models at https://github.com/emirhanbayar/QFAE.

</details>


### [67] [A COCO-Formatted Instance-Level Dataset for Plasmodium Falciparum Detection in Giemsa-Stained Blood Smears](https://arxiv.org/abs/2507.18483)
*Frauke Wilm,Luis Carlos Rivera Monroy,Mathias Öttl,Lukas Mürdter,Leonid Mill,Andreas Maier*

Main category: cs.CV

TL;DR: 本研究改进了NIH疟疾数据集，添加了详细的COCO格式标注，并使用Faster R-CNN模型进行了验证，证明了高质量标注对于提高疟疾自动诊断模型性能的重要性。


<details>
  <summary>Details</summary>
Motivation: 为了克服当前深度学习疟疾诊断方法因缺乏详细实例级标注的数据集而面临的挑战，本研究旨在增强NIH疟疾数据集，并提供详细的边界框标注以支持对象检测训练。

Method: 使用Faster R-CNN模型对更新后的NIH疟疾数据集（包含COCO格式的边界框标注）进行训练，以检测感染和非感染的红细胞以及白细胞。

Result: Faster R-CNN模型在原始数据集上的交叉验证达到了高达0.88的感染细胞检测F1分数，证明了更新后的标注集能够支持稳健的检测性能。

Conclusion: 对NIH疟疾数据集的更新和验证表明，标注数量和一致性对于开发稳健的自动检测模型至关重要，而自动标注改进与手动校正相结合可以产生高质量的训练数据。

Abstract: Accurate detection of Plasmodium falciparum in Giemsa-stained blood smears is
an essential component of reliable malaria diagnosis, especially in developing
countries. Deep learning-based object detection methods have demonstrated
strong potential for automated Malaria diagnosis, but their adoption is limited
by the scarcity of datasets with detailed instance-level annotations. In this
work, we present an enhanced version of the publicly available NIH malaria
dataset, with detailed bounding box annotations in COCO format to support
object detection training. We validated the revised annotations by training a
Faster R-CNN model to detect infected and non-infected red blood cells, as well
as white blood cells. Cross-validation on the original dataset yielded F1
scores of up to 0.88 for infected cell detection. These results underscore the
importance of annotation volume and consistency, and demonstrate that automated
annotation refinement combined with targeted manual correction can produce
training data of sufficient quality for robust detection performance. The
updated annotations set is publicly available via GitHub:
https://github.com/MIRA-Vision-Microscopy/malaria-thin-smear-coco.

</details>


### [68] [Reinforced Embodied Active Defense: Exploiting Adaptive Interaction for Robust Visual Perception in Adversarial 3D Environments](https://arxiv.org/abs/2507.18484)
*Xiao Yang,Lingxuan Wu,Lizhong Wang,Chengyang Ying,Hang Su,Jun Zhu*

Main category: cs.CV

TL;DR: 提出了一种名为 Rein-EAD 的主动防御框架，用于应对 3D 环境中的对抗性攻击。该框架通过自适应探索和与环境交互来提高感知鲁棒性，并能在不需要可微分环境的情况下实现高效的策略更新。实验证明 Rein-EAD 在多种任务中有效，并能抵抗未知攻击。


<details>
  <summary>Details</summary>
Motivation: 现有的防御机制（如对抗性训练和净化）主要采用被动策略，依赖于对攻击策略的预定义假设，这限制了它们在动态 3D 环境中的适应性。

Method: 提出了一种名为“强化具身主动防御”（Rein-EAD）的主动防御框架，该框架利用自适应探索和与环境的交互来提高 3D 对抗性背景下的感知鲁棒性。通过实现平衡即时预测准确性和预测熵最小化的多步目标，Rein-EAD 在多步视野内优化防御策略。此外，Rein-EAD 采用面向不确定性的奖励塑造机制，以实现高效的策略更新，从而降低计算开销并支持实际应用，且无需可微分环境。

Result: 实验结果表明，Rein-EAD 在 3D 物体分类、人脸识别和自动驾驶等多样化任务中，能够显著降低攻击成功率，同时保持标准准确性。

Conclusion: Rein-EAD 框架在 3D 对抗性环境中展示了优越的防御能力，能显著降低攻击成功率，同时保持标准准确性，并能泛化到未知的自适应攻击。

Abstract: Adversarial attacks in 3D environments have emerged as a critical threat to
the reliability of visual perception systems, particularly in safety-sensitive
applications such as identity verification and autonomous driving. These
attacks employ adversarial patches and 3D objects to manipulate deep neural
network (DNN) predictions by exploiting vulnerabilities within complex scenes.
Existing defense mechanisms, such as adversarial training and purification,
primarily employ passive strategies to enhance robustness. However, these
approaches often rely on pre-defined assumptions about adversarial tactics,
limiting their adaptability in dynamic 3D settings. To address these
challenges, we introduce Reinforced Embodied Active Defense (Rein-EAD), a
proactive defense framework that leverages adaptive exploration and interaction
with the environment to improve perception robustness in 3D adversarial
contexts. By implementing a multi-step objective that balances immediate
prediction accuracy with predictive entropy minimization, Rein-EAD optimizes
defense strategies over a multi-step horizon. Additionally, Rein-EAD involves
an uncertainty-oriented reward-shaping mechanism that facilitates efficient
policy updates, thereby reducing computational overhead and supporting
real-world applicability without the need for differentiable environments.
Comprehensive experiments validate the effectiveness of Rein-EAD, demonstrating
a substantial reduction in attack success rates while preserving standard
accuracy across diverse tasks. Notably, Rein-EAD exhibits robust generalization
to unseen and adaptive attacks, making it suitable for real-world complex
tasks, including 3D object classification, face recognition and autonomous
driving.

</details>


### [69] [Delving into Mapping Uncertainty for Mapless Trajectory Prediction](https://arxiv.org/abs/2507.18498)
*Zongzheng Zhang,Xuchong Qiu,Boran Zhang,Guantian Zheng,Xunjiang Gu,Guoxuan Chi,Huan-ang Gao,Leichen Wang,Ziming Liu,Xinrun Li,Igor Gilitschenski,Hongyang Li,Hang Zhao,Hao Zhao*

Main category: cs.CV

TL;DR: 本研究提出了一种新的方法，能够根据自车未来的运动状态来判断是否将在线生成的高精地图的不确定性纳入轨迹预测，从而提高预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 为了解决在线生成的高精地图（HD maps）在自动驾驶中可靠性不确定以及现有地图不确定性整合策略对特定场景的收益洞察有限的问题，本研究旨在分析地图不确定性对轨迹预测影响最大的驾驶场景，并发现关键因素——运动状态。

Method: 提出了一种新的本体感觉场景门控（Proprioceptive Scenario Gating）方法，该方法基于对自车未来运动状态的预测，自适应地将地图不确定性整合到轨迹预测中。此外，还引入了一种基于协方差的地图不确定性（Covariance-based Map Uncertainty）方法，以更好地与地图几何对齐。

Result: 所提出的方法在nuScenes数据集上进行了验证，在地图无关轨迹预测性能上比现有最先进的方法提高了高达23.6%。

Conclusion: 所提出的方法能够自适应地将地图不确定性整合到轨迹预测中，并取得了显著的性能提升，在nuScenes数据集上比现有最先进的方法提高了23.6%。

Abstract: Recent advances in autonomous driving are moving towards mapless approaches,
where High-Definition (HD) maps are generated online directly from sensor data,
reducing the need for expensive labeling and maintenance. However, the
reliability of these online-generated maps remains uncertain. While
incorporating map uncertainty into downstream trajectory prediction tasks has
shown potential for performance improvements, current strategies provide
limited insights into the specific scenarios where this uncertainty is
beneficial. In this work, we first analyze the driving scenarios in which
mapping uncertainty has the greatest positive impact on trajectory prediction
and identify a critical, previously overlooked factor: the agent's kinematic
state. Building on these insights, we propose a novel Proprioceptive Scenario
Gating that adaptively integrates map uncertainty into trajectory prediction
based on forecasts of the ego vehicle's future kinematics. This lightweight,
self-supervised approach enhances the synergy between online mapping and
trajectory prediction, providing interpretability around where uncertainty is
advantageous and outperforming previous integration methods. Additionally, we
introduce a Covariance-based Map Uncertainty approach that better aligns with
map geometry, further improving trajectory prediction. Extensive ablation
studies confirm the effectiveness of our approach, achieving up to 23.6%
improvement in mapless trajectory prediction performance over the
state-of-the-art method using the real-world nuScenes driving dataset. Our
code, data, and models are publicly available at
https://github.com/Ethan-Zheng136/Map-Uncertainty-for-Trajectory-Prediction.

</details>


### [70] [Human Scanpath Prediction in Target-Present Visual Search with Semantic-Foveal Bayesian Attention](https://arxiv.org/abs/2507.18503)
*João Luzio,Alexandre Bernardino,Plinio Moreno*

Main category: cs.CV

TL;DR: SemBA-FAST是一个结合深度学习和概率模型的框架，用于预测人类在视觉搜索任务中的注意力分配，其表现优于现有方法，并在人因工程和机器人领域具有潜在应用价值。


<details>
  <summary>Details</summary>
Motivation: 为了在目标存在的视觉搜索任务中预测人类视觉注意力，研究了SemBA-FAST框架，该框架旨在模拟人类的自上而下和自下而上的线索以及中央凹视觉在引导注意力中的作用。

Method: SemBA-FAST框架整合了深度对象检测和概率语义融合机制，利用预训练检测器和人工注视点来动态更新自上而下的知识并逐步改进注视点预测。

Result: SemBA-FAST在COCO-Search18基准数据集上的评估结果显示，其性能超越了基线和其他自上而下的方法，并在某些情况下能与扫描路径驱动的模型相竞争。

Conclusion: SemBA-FAST框架在COCO-Search18基准数据集上表现出色，生成的注视点序列与人类真实扫描路径高度相似，优于其他自上而下方法，并在某些方面可与扫描路径驱动的模型相媲美。

Abstract: In goal-directed visual tasks, human perception is guided by both top-down
and bottom-up cues. At the same time, foveal vision plays a crucial role in
directing attention efficiently. Modern research on bio-inspired computational
attention models has taken advantage of advancements in deep learning by
utilizing human scanpath data to achieve new state-of-the-art performance. In
this work, we assess the performance of SemBA-FAST, i.e. Semantic-based
Bayesian Attention for Foveal Active visual Search Tasks, a top-down framework
designed for predicting human visual attention in target-present visual search.
SemBA-FAST integrates deep object detection with a probabilistic semantic
fusion mechanism to generate attention maps dynamically, leveraging pre-trained
detectors and artificial foveation to update top-down knowledge and improve
fixation prediction sequentially. We evaluate SemBA-FAST on the COCO-Search18
benchmark dataset, comparing its performance against other scanpath prediction
models. Our methodology achieves fixation sequences that closely match human
ground-truth scanpaths. Notably, it surpasses baseline and other top-down
approaches and competes, in some cases, with scanpath-informed models. These
findings provide valuable insights into the capabilities of semantic-foveal
probabilistic frameworks for human-like attention modelling, with implications
for real-time cognitive computing and robotics.

</details>


### [71] [Explaining How Visual, Textual and Multimodal Encoders Share Concepts](https://arxiv.org/abs/2507.18512)
*Clément Cornet,Romaric Besançon,Hervé Le Borgne*

Main category: cs.CV

TL;DR: 提出新指标可跨模态比较SAE特征，发现VLM视觉特征与文本编码器共享，强调文本预训练作用。


<details>
  <summary>Details</summary>
Motivation: 之前的研究仅限于同一模态内的模型比较，缺乏跨模态比较的方法。本研究旨在弥补这一不足，并深入了解不同类型模型共享表示或特征的程度。

Method: 提出了一种新的量化指标，用于比较不同模态的SAE特征，并量化了不同模型类别之间个体特征的比较共享性。对21个不同大小和在不同数据集上训练的视觉、文本和多模态编码器进行了多项研究。

Result: 研究结果揭示了视觉特征在VLMs和文本编码器之间的共享性，表明文本预训练对模型表示有重要影响。该研究为跨模态模型比较提供了新的工具和见解。

Conclusion: 文章提出了一个新的量化指标，用于比较不同模态（视觉、文本、多模态）的稀疏自编码器（SAE）特征，并量化了不同模型类别之间个体特征的比较共享性。研究结果表明，视觉语言模型（VLMs）中特有的视觉特征与文本编码器共享，这凸显了文本预训练的影响。

Abstract: Sparse autoencoders (SAEs) have emerged as a powerful technique for
extracting human-interpretable features from neural networks activations.
Previous works compared different models based on SAE-derived features but
those comparisons have been restricted to models within the same modality. We
propose a novel indicator allowing quantitative comparison of models across SAE
features, and use it to conduct a comparative study of visual, textual and
multimodal encoders. We also propose to quantify the Comparative Sharedness of
individual features between different classes of models. With these two new
tools, we conduct several studies on 21 encoders of the three types, with two
significantly different sizes, and considering generalist and domain specific
datasets. The results allow to revisit previous studies at the light of
encoders trained in a multimodal context and to quantify to which extent all
these models share some representations or features. They also suggest that
visual features that are specific to VLMs among vision encoders are shared with
text encoders, highlighting the impact of text pretraining. The code is
available at https://github.com/CEA-LIST/SAEshareConcepts

</details>


### [72] [Towards Large Scale Geostatistical Methane Monitoring with Part-based Object Detection](https://arxiv.org/abs/2507.18513)
*Adhemar de Senneville,Xavier Bou,Thibaud Ehret,Rafael Grompone,Jean Louis Bonne,Nicolas Dumelie,Thomas Lauvaux,Gabriele Facciolo*

Main category: cs.CV

TL;DR: This paper tackles the challenge of finding rare bio-digesters in massive remote sensing datasets using a new part-based detection method and dataset, ultimately estimating methane emissions.


<details>
  <summary>Details</summary>
Motivation: The motivation is to overcome the challenge of detecting rare objects in the vast amounts of remote sensing data, which is crucial for applications like estimating the environmental impact of human activities at scale, specifically focusing on methane production and emissions from bio-digesters in France.

Method: A part-based method considering essential bio-digester sub-elements is developed to improve initial detections. This method is applied to new regions to create an inventory of bio-digesters, followed by geostatistical estimation of methane production.

Result: The paper introduces a novel dataset with a high imbalance towards observations without objects and demonstrates the application of the proposed method to build an inventory of bio-digesters and estimate their methane production.

Conclusion: The paper proposes a part-based method and a novel dataset to address the challenge of detecting rare objects (bio-digesters) in large-scale remote sensing imagery, and applies it to estimate methane production.

Abstract: Object detection is one of the main applications of computer vision in remote
sensing imagery. Despite its increasing availability, the sheer volume of
remote sensing data poses a challenge when detecting rare objects across large
geographic areas. Paradoxically, this common challenge is crucial to many
applications, such as estimating environmental impact of certain human
activities at scale. In this paper, we propose to address the problem by
investigating the methane production and emissions of bio-digesters in France.
We first introduce a novel dataset containing bio-digesters, with small
training and validation sets, and a large test set with a high imbalance
towards observations without objects since such sites are rare. We develop a
part-based method that considers essential bio-digester sub-elements to boost
initial detections. To this end, we apply our method to new, unseen regions to
build an inventory of bio-digesters. We then compute geostatistical estimates
of the quantity of methane produced that can be attributed to these
infrastructures in a given area at a given time.

</details>


### [73] [Object segmentation in the wild with foundation models: application to vision assisted neuro-prostheses for upper limbs](https://arxiv.org/abs/2507.18517)
*Bolutife Atoki,Jenny Benois-Pineau,Renaud Péteri,Fabien Baldacci,Aymar de Rugy*

Main category: cs.CV

TL;DR: 本研究探索了使用SAM基础模型进行物体分割，通过注视焦点提示和Egocentric数据微调，在杂乱场景中提升了分割效果，尤其适用于假肢应用。


<details>
  <summary>Details</summary>
Motivation: 为了实现视觉引导的上肢神经假体应用，需要解决在杂乱的视觉场景中对日常物体进行语义对象分割的问题，并探索了无需针对特定图像进行微调的解决方案。

Method: 提出了一种基于注视焦点的提示生成方法，并对SAM模型进行了Egocentric视觉数据微调，以解决在杂乱视觉场景中进行语义对象分割的问题。

Result: 在RoboFlow平台上公开的Grasping-in-the-Wild语料库的真实世界挑战性数据上，IoU分割质量指标提高了多达0.51点。

Conclusion: 该研究表明，通过基于注视焦点的提示生成并结合Egocentric视觉数据微调，SAM模型在分割“野外”的杂乱场景中的日常物体方面表现出潜力，IoU分割质量指标在真实世界的抓取数据上提升了0.51点。

Abstract: In this work, we address the problem of semantic object segmentation using
foundation models. We investigate whether foundation models, trained on a large
number and variety of objects, can perform object segmentation without
fine-tuning on specific images containing everyday objects, but in highly
cluttered visual scenes. The ''in the wild'' context is driven by the target
application of vision guided upper limb neuroprostheses. We propose a method
for generating prompts based on gaze fixations to guide the Segment Anything
Model (SAM) in our segmentation scenario, and fine-tune it on egocentric visual
data. Evaluation results of our approach show an improvement of the IoU
segmentation quality metric by up to 0.51 points on real-world challenging data
of Grasping-in-the-Wild corpus which is made available on the RoboFlow Platform
(https://universe.roboflow.com/iwrist/grasping-in-the-wild)

</details>


### [74] [GaussianFusionOcc: A Seamless Sensor Fusion Approach for 3D Occupancy Prediction Using 3D Gaussians](https://arxiv.org/abs/2507.18522)
*Tomislav Pavković,Mohammad-Ali Nikouei Mahani,Johannes Niedermayer,Johannes Betz*

Main category: cs.CV

TL;DR: GaussianFusionOcc是一种新颖的3D语义占用预测方法，通过结合3D高斯表示和多传感器融合技术，实现了更高的精度、效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 3D语义占用预测是自动驾驶的关键任务，需要精确、安全的导航。传感器融合对于提高预测的可靠性至关重要。

Method: 提出了一种名为GaussianFusionOcc的新方法，该方法使用3D高斯表示和创新的传感器融合机制，并采用模态无关的可变形注意力来提取特征、精炼高斯属性。

Result: GaussianFusionOcc在内存效率和推理速度方面表现出色，并能通过多传感器融合实现更精确、可扩展的占用预测。

Conclusion: 3D高斯融合方法在3D语义占用预测任务上表现优于现有最先进模型，尤其在多传感器融合和效率方面。

Abstract: 3D semantic occupancy prediction is one of the crucial tasks of autonomous
driving. It enables precise and safe interpretation and navigation in complex
environments. Reliable predictions rely on effective sensor fusion, as
different modalities can contain complementary information. Unlike conventional
methods that depend on dense grid representations, our approach,
GaussianFusionOcc, uses semantic 3D Gaussians alongside an innovative sensor
fusion mechanism. Seamless integration of data from camera, LiDAR, and radar
sensors enables more precise and scalable occupancy prediction, while 3D
Gaussian representation significantly improves memory efficiency and inference
speed. GaussianFusionOcc employs modality-agnostic deformable attention to
extract essential features from each sensor type, which are then used to refine
Gaussian properties, resulting in a more accurate representation of the
environment. Extensive testing with various sensor combinations demonstrates
the versatility of our approach. By leveraging the robustness of multi-modal
fusion and the efficiency of Gaussian representation, GaussianFusionOcc
outperforms current state-of-the-art models.

</details>


### [75] [IntentVCNet: Bridging Spatio-Temporal Gaps for Intention-Oriented Controllable Video Captioning](https://arxiv.org/abs/2507.18531)
*Tianheng Qiu,Jingchun Gao,Jingyu Li,Huiyi Leong,Xuan Huang,Xi Wang,Xiaocheng Zhang,Kele Xu,Lan Zhang*

Main category: cs.CV

TL;DR: 提出IntentVCNet来弥合LVLM的时空鸿沟，通过提示组合和参数高效的框适配器实现面向意图的视频字幕生成。


<details>
  <summary>Details</summary>
Motivation: 现有的LVLM虽然在空间和时间理解方面各有优势，但无法根据指令对时间序列进行细粒度的空间控制，这种时空鸿沟使得实现细粒度的面向意图的视频控制变得复杂。

Method: 提出了一种新的IntentVCNet，它统一了LVLM中固有的时空理解知识，以在提示和模型层面弥合时空鸿沟。具体来说，提出了一种提示组合策略，使LLM能够模拟表征用户意图的提示与视频序列之间的隐式关系。然后，提出了一种参数高效的框适配器，该适配器增强了全局视觉上下文中的对象语义信息，以便视觉标记具有关于用户意图的先验信息。

Result: 所提出的方法在几个开源LVLM上取得了最先进的结果，并在IntentVC挑战赛中获得亚军。

Conclusion: 该方法可以增强LVLM对视频序列中空间细节的建模能力，并促进LVLM准确生成面向意图的受控字幕。

Abstract: Intent-oriented controlled video captioning aims to generate targeted
descriptions for specific targets in a video based on customized user intent.
Current Large Visual Language Models (LVLMs) have gained strong instruction
following and visual comprehension capabilities. Although the LVLMs
demonstrated proficiency in spatial and temporal understanding respectively, it
was not able to perform fine-grained spatial control in time sequences in
direct response to instructions. This substantial spatio-temporal gap
complicates efforts to achieve fine-grained intention-oriented control in
video. Towards this end, we propose a novel IntentVCNet that unifies the
temporal and spatial understanding knowledge inherent in LVLMs to bridge the
spatio-temporal gap from both prompting and model perspectives. Specifically,
we first propose a prompt combination strategy designed to enable LLM to model
the implicit relationship between prompts that characterize user intent and
video sequences. We then propose a parameter efficient box adapter that
augments the object semantic information in the global visual context so that
the visual token has a priori information about the user intent. The final
experiment proves that the combination of the two strategies can further
enhance the LVLM's ability to model spatial details in video sequences, and
facilitate the LVLMs to accurately generate controlled intent-oriented
captions. Our proposed method achieved state-of-the-art results in several open
source LVLMs and was the runner-up in the IntentVC challenge. Our code is
available on https://github.com/thqiu0419/IntentVCNet.

</details>


### [76] [COT-AD: Cotton Analysis Dataset](https://arxiv.org/abs/2507.18532)
*Akbar Ali,Mahek Vyas,Soumyaratna Debnath,Chanda Grover Kamra,Jaidev Sanjay Khalane,Reuben Shibu Devanesan,Indra Deep Mastan,Subramanian Sankaranarayanan,Pankaj Khanna,Shanmuganathan Raman*

Main category: cs.CV

TL;DR: COT-AD 是一个全面的棉花作物计算机视觉数据集，包含超过 25,000 张图像，用于病虫害识别、植被和杂草分析，以支持数据驱动的作物管理。


<details>
  <summary>Details</summary>
Motivation: 为了增强棉花作物分析，需要一个专门针对棉花种植周期中病虫害识别、植被和杂草分析的全面数据集。

Method: 介绍了 COT-AD 数据集，该数据集包含 25,000 多张图像（5,000 张已标注），涵盖了从空中拍摄的用于田间尺度检测和分割的图像，以及记录关键病害的高分辨率单反相机图像。

Result: COT-AD 数据集包含棉花病虫害识别、植被和杂草分析的标注，支持分类、分割、图像恢复、增强、基于深度生成模型的棉花作物合成以及早期病害管理等任务。

Conclusion: COT-AD 数据集弥补了棉花农业数据集的关键空白，支持多种计算机视觉任务，以促进数据驱动的棉花作物管理。

Abstract: This paper presents COT-AD, a comprehensive Dataset designed to enhance
cotton crop analysis through computer vision. Comprising over 25,000 images
captured throughout the cotton growth cycle, with 5,000 annotated images,
COT-AD includes aerial imagery for field-scale detection and segmentation and
high-resolution DSLR images documenting key diseases. The annotations cover
pest and disease recognition, vegetation, and weed analysis, addressing a
critical gap in cotton-specific agricultural datasets. COT-AD supports tasks
such as classification, segmentation, image restoration, enhancement, deep
generative model-based cotton crop synthesis, and early disease management,
advancing data-driven crop management

</details>


### [77] [Elucidating the Design Space of Arbitrary-Noise-Based Diffusion Models](https://arxiv.org/abs/2507.18534)
*Xingyu Qiu,Mengying Yang,Xinghua Ma,Dong Liang,Yuzhen Li,Fanding Li,Gongning Luo,Wei Wang,Kuanquan Wang,Shuo Li*

Main category: cs.CV

TL;DR: EDA 是一种基于任意噪声的扩散模型，可以提高图像修复效果，尤其在 MRI 偏置场校正和自然图像阴影去除方面表现优异。


<details>
  <summary>Details</summary>
Motivation: EDM 的固定噪声模式限制了其在图像修复领域的应用，强制注入高斯噪声会破坏退化图像，并增加修复的复杂性。

Method: 本研究提出了 EDA（Elucidates the Design space of Arbitrary-noise-based diffusion models），扩展了噪声模式的自由度，同时保留了 EDM 的原始模块灵活性，并严格证明了噪声复杂度的增加不会带来额外的计算开销。

Result: EDA 在 MRI 偏置场校正、CT 金属伪影还原和自然图像阴影去除任务上进行了验证，在偏置场校正和阴影去除任务上取得了最先进的性能，并且仅使用 5 个采样步。

Conclusion: EDA 提案了一种基于任意噪声的扩散模型设计空间，并在 MRI 偏置场校正、CT 金属伪影还原和自然图像阴影去除等任务上进行了验证，在偏置场校正和阴影去除任务上取得了最先进的性能。

Abstract: EDM elucidates the unified design space of diffusion models, yet its fixed
noise patterns restricted to pure Gaussian noise, limit advancements in image
restoration. Our study indicates that forcibly injecting Gaussian noise
corrupts the degraded images, overextends the image transformation distance,
and increases restoration complexity. To address this problem, our proposed EDA
Elucidates the Design space of Arbitrary-noise-based diffusion models.
Theoretically, EDA expands the freedom of noise pattern while preserving the
original module flexibility of EDM, with rigorous proof that increased noise
complexity incurs no additional computational overhead during restoration. EDA
is validated on three typical tasks: MRI bias field correction (global smooth
noise), CT metal artifact reduction (global sharp noise), and natural image
shadow removal (local boundary-aware noise). With only 5 sampling steps, EDA
outperforms most task-specific methods and achieves state-of-the-art
performance in bias field correction and shadow removal.

</details>


### [78] [TTS-VAR: A Test-Time Scaling Framework for Visual Auto-Regressive Generation](https://arxiv.org/abs/2507.18537)
*Zhekai Chen,Ruihang Chu,Yukang Chen,Shiwei Zhang,Yujie Wei,Yingya Zhang,Xihui Liu*

Main category: cs.CV

TL;DR: TTS-VAR是一个用于视觉自回归模型的新型测试时域扩展框架，通过路径搜索、聚类多样性搜索和重采样潜力选择来提高生成质量和效率，在Infinity模型上取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 扩展视觉生成模型以满足现实世界内容创作的需求，但传统的训练时扩展方法需要高昂的训练和计算成本。因此，在测试时进行扩展因其资源效率和有前景的性能而备受关注。

Method: TTS-VAR框架通过引入自适应下降批次大小计划，并在粗粒度尺度上采用基于聚类的多样性搜索（通过语义特征聚类保留结构多样性），在细粒度尺度上采用基于重采样的潜力选择（使用结合多尺度生成历史的奖励函数来优先选择有潜力的候选样本），将生成过程建模为路径搜索问题。

Result: 在强大的VAR模型Infinity上，TTS-VAR实现了8.7%的GenEval分数提升（从0.69提升到0.75）。关键的见解揭示了早期结构特征能够有效影响最终质量，并且重采样的有效性因生成阶段而异。

Conclusion: TTS-VAR是首个用于视觉自回归（VAR）模型的通用测试时域（test-time）缩放框架，通过将生成过程建模为路径搜索问题，动态平衡计算效率和探索能力。实验证明，TTS-VAR在Infinity模型上实现了8.7%的GenEval分数提升，表明早期结构特征对最终质量有显著影响，并且在不同生成阶段，重采样具有不同的有效性。

Abstract: Scaling visual generation models is essential for real-world content
creation, yet requires substantial training and computational expenses.
Alternatively, test-time scaling has garnered growing attention due to resource
efficiency and promising performance. In this work, we present TTS-VAR, the
first general test-time scaling framework for visual auto-regressive (VAR)
models, modeling the generation process as a path searching problem. To
dynamically balance computational efficiency with exploration capacity, we
first introduce an adaptive descending batch size schedule throughout the
causal generation process. Besides, inspired by VAR's hierarchical
coarse-to-fine multi-scale generation, our framework integrates two key
components: (i) At coarse scales, we observe that generated tokens are hard for
evaluation, possibly leading to erroneous acceptance of inferior samples or
rejection of superior samples. Noticing that the coarse scales contain
sufficient structural information, we propose clustering-based diversity
search. It preserves structural variety through semantic feature clustering,
enabling later selection on samples with higher potential. (ii) In fine scales,
resampling-based potential selection prioritizes promising candidates using
potential scores, which are defined as reward functions incorporating
multi-scale generation history. Experiments on the powerful VAR model Infinity
show a notable 8.7% GenEval score improvement (from 0.69 to 0.75). Key insights
reveal that early-stage structural features effectively influence final
quality, and resampling efficacy varies across generation scales. Code is
available at https://github.com/ali-vilab/TTS-VAR.

</details>


### [79] [Unposed 3DGS Reconstruction with Probabilistic Procrustes Mapping](https://arxiv.org/abs/2507.18541)
*Chong Cheng,Zijian Wang,Sicheng Yu,Yu Hu,Nanjie Yao,Hao Wang*

Main category: cs.CV

TL;DR: 通过概率Procrustes映射和联合优化，我们的新方法能高效、精确地从大量户外无姿态图像中重建3D场景，突破了现有MVS模型的局限。


<details>
  <summary>Details</summary>
Motivation: 现有的3DGS技术在依赖精确的相机姿态和点云初始化方面存在局限性，尤其是在处理大规模户外图像的无姿态重建任务时，传统MVS模型可能面临内存限制和精度下降的问题。因此，需要一种能够有效处理大规模无姿态图像数据并实现精确3D重建的方法。

Method: 本文提出了一种新颖的无姿态3DGS重建框架，该框架整合了预训练的多视图立体（MVS）先验和概率Procrustes映射策略。具体方法包括：1. 将输入图像分割成子集。2. 运用概率Procrustes问题求解点云的封闭形式对齐，实现子图到全局空间的映射。3. 采用概率耦合和软除尘机制拒绝对不确定的对应点。4. 提出一个联合优化框架，从置信感知锚点构建高斯，并结合3DGS可微分渲染和分析雅可比矩阵，联合优化场景和姿态。

Result: 在Waymo和KITTI数据集上的实验表明，该方法能够从无姿态图像序列中实现精确重建，并且在处理包含数百张户外图像的数据集时，能在几分钟内完成点云和姿态的全局对齐，为无姿态3DGS重建设定了新的最先进水平。

Conclusion: 本文提出的新型无姿态3DGS重建框架，通过集成预训练MVS先验和概率Procrustes映射策略，解决了现有MVS模型在处理大规模户外图像时的内存限制和精度下降问题。通过将输入图像分割成子集，并将子图映射到全局空间，与3DGS联合优化几何和姿态。具体而言，我们将数千万个点云的映射形式化为概率Procrustes问题，并求解封闭形式的对齐。通过采用概率耦合和软除尘机制来拒绝不确定的对应关系，我们的方法能在几分钟内跨越数百张图像全局对齐点云和姿态。此外，我们提出了一个用于3DGS和相机姿态的联合优化框架，通过从置信感知锚点构建高斯，并结合3DGS可微分渲染和分析雅可比矩阵来联合优化场景和姿态，从而实现精确重建和姿态估计。在Waymo和KITTI数据集上的实验表明，我们的方法能够从无姿态图像序列中实现精确重建，为无姿态3DGS重建设定了新的最先进水平。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a core technique for 3D
representation. Its effectiveness largely depends on precise camera poses and
accurate point cloud initialization, which are often derived from pretrained
Multi-View Stereo (MVS) models. However, in unposed reconstruction task from
hundreds of outdoor images, existing MVS models may struggle with memory limits
and lose accuracy as the number of input images grows. To address this
limitation, we propose a novel unposed 3DGS reconstruction framework that
integrates pretrained MVS priors with the probabilistic Procrustes mapping
strategy. The method partitions input images into subsets, maps submaps into a
global space, and jointly optimizes geometry and poses with 3DGS. Technically,
we formulate the mapping of tens of millions of point clouds as a probabilistic
Procrustes problem and solve a closed-form alignment. By employing
probabilistic coupling along with a soft dustbin mechanism to reject uncertain
correspondences, our method globally aligns point clouds and poses within
minutes across hundreds of images. Moreover, we propose a joint optimization
framework for 3DGS and camera poses. It constructs Gaussians from
confidence-aware anchor points and integrates 3DGS differentiable rendering
with an analytical Jacobian to jointly refine scene and poses, enabling
accurate reconstruction and pose estimation. Experiments on Waymo and KITTI
datasets show that our method achieves accurate reconstruction from unposed
image sequences, setting a new state of the art for unposed 3DGS
reconstruction.

</details>


### [80] [A 3D Cross-modal Keypoint Descriptor for MR-US Matching and Registration](https://arxiv.org/abs/2507.18551)
*Daniil Morozov,Reuben Dorent,Nazim Haouchine*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Intraoperative registration of real-time ultrasound (iUS) to preoperative
Magnetic Resonance Imaging (MRI) remains an unsolved problem due to severe
modality-specific differences in appearance, resolution, and field-of-view. To
address this, we propose a novel 3D cross-modal keypoint descriptor for MRI-iUS
matching and registration. Our approach employs a patient-specific
matching-by-synthesis approach, generating synthetic iUS volumes from
preoperative MRI. This enables supervised contrastive training to learn a
shared descriptor space.
  A probabilistic keypoint detection strategy is then employed to identify
anatomically salient and modality-consistent locations. During training, a
curriculum-based triplet loss with dynamic hard negative mining is used to
learn descriptors that are i) robust to iUS artifacts such as speckle noise and
limited coverage, and ii) rotation-invariant . At inference, the method detects
keypoints in MR and real iUS images and identifies sparse matches, which are
then used to perform rigid registration. Our approach is evaluated using 3D
MRI-iUS pairs from the ReMIND dataset. Experiments show that our approach
outperforms state-of-the-art keypoint matching methods across 11 patients, with
an average precision of $69.8\%$. For image registration, our method achieves a
competitive mean Target Registration Error of 2.39 mm on the ReMIND2Reg
benchmark.
  Compared to existing iUS-MR registration approach, our framework is
interpretable, requires no manual initialization, and shows robustness to iUS
field-of-view variation. Code is available at
https://github.com/morozovdd/CrossKEY.

</details>


### [81] [VideoMind: An Omni-Modal Video Dataset with Intent Grounding for Deep-Cognitive Video Understanding](https://arxiv.org/abs/2507.18552)
*Baoyao Yang,Wanyun Li,Dixin Chen,Junxiang Chen,Wenbin Yao,Haifeng Lin*

Main category: cs.CV

TL;DR: VideoMind 是一个包含 103K 视频、音频和分层文本描述（事实、抽象、意图）的全模态数据集，旨在实现深度视频理解和多模态特征表示。它通过提供需要跨视频上下文集成的意图表达（通过 COT 生成）来解决现有数据集的不足，并包含手动验证的基准和多层次检索指标。研究结果表明，VideoMind 是一个强大的基准，可用于细粒度的跨模态对齐和需要深度视频理解的任务。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是创建一个用于深度视频内容认知和增强多模态特征表示的全模态数据集。现有数据集在提供需要跨视频上下文整合的深层认知表达（如意图）方面存在不足。因此，本研究旨在通过 VideoMind 数据集来解决这一差距，该数据集包含分层描述和通过思维链（COT）方法生成的意图表达，以促进对视频内容的更深入理解。

Method: 本研究引入了一个名为 VideoMind 的新数据集。该数据集包含 103,000 个视频样本，每个样本都配有音频和分层文本描述（事实、抽象、意图）。特别是，它包含通过思维链（COT）方法生成的意图表达，这些表达需要对整个视频进行上下文整合。数据集还提供了对主体、地点、时间、事件、动作和意图的注释。研究人员还创建了一个包含 3,000 个手动验证样本的基准，并设计了多层次评估指标的混合认知检索实验来评估模型。最后，研究人员发布了对 InternVideo、VAST 和 UMT-L 等模型的评估结果。

Result: VideoMind 数据集包含 103,000 个视频样本，每个样本都配有音频和分层文本描述（事实、抽象、意图）。数据集包含超过 2200 万个单词。研究人员使用该数据集评估了 InternVideo、VAST 和 UMT-L 等模型，并在 GitHub、HuggingFace 和 OpenDataLab 上公开了该数据集及其评估结果。

Conclusion: VideoMind 是一个视频中心的全模态数据集，旨在促进深度视频内容认知和增强的多模态特征表示。它通过提供包含事实、抽象和意图信息的三层描述，并采用思维链（COT）方法生成需要跨视频上下文集成的深层认知表达（如意图），从而在现有数据集之上进行了扩展。该数据集支持细粒度的跨模态对齐和需要深度视频理解的任务，如情感和意图识别。

Abstract: This paper introduces VideoMind, a video-centric omni-modal dataset designed
for deep video content cognition and enhanced multi-modal feature
representation. The dataset comprises 103K video samples (3K reserved for
testing), each paired with audio and systematically detailed textual
descriptions. Specifically, every video and its audio is described across three
hierarchical layers (factual, abstract, and intent), progressing from surface
to depth. It contains over 22 million words, averaging ~225 words per sample.
VideoMind's key distinction from existing datasets is its provision of intent
expressions, which require contextual integration across the entire video and
are not directly observable. These deep-cognitive expressions are generated
using a Chain-of-Thought (COT) approach, prompting the mLLM through
step-by-step reasoning. Each description includes annotations for subject,
place, time, event, action, and intent, supporting downstream recognition
tasks. Crucially, we establish a gold-standard benchmark with 3,000 manually
validated samples for evaluating deep-cognitive video understanding. We design
hybrid-cognitive retrieval experiments, scored by multi-level retrieval
metrics, to appropriately assess deep video comprehension. Evaluation results
for models (e.g., InternVideo, VAST, UMT-L) are released. VideoMind serves as a
powerful benchmark for fine-grained cross-modal alignment and advances fields
requiring in-depth video understanding, such as emotion and intent recognition.
The data is publicly available on GitHub, HuggingFace, and OpenDataLab,
https://github.com/cdx-cindy/VideoMind.

</details>


### [82] [Synthetic Data Augmentation for Enhanced Chicken Carcass Instance Segmentation](https://arxiv.org/abs/2507.18558)
*Yihong Feng,Chaitanya Pallerla,Xiaomin Lin,Pouya Sohrabipour Sr,Philip Crandall,Wan Shou,Yu She,Dongyi Wang*

Main category: cs.CV

TL;DR: 合成数据可以提高鸡胴体的分割性能，并减少数据收集和注释的工作量。


<details>
  <summary>Details</summary>
Motivation: 为了提高自动化检测在快节奏工业环境中的鸡胴体实例分割的准确性，并解决劳动密集型的数据收集和注释问题。

Method: 本研究提出了第一个用于生成照片级真实感、自动标注的鸡胴体合成图像的流程，并引入了一个包含300张标注的真实世界图像的新基准数据集，专门用于家禽分割研究。在不​​同比例的合成图像的真实数据集上评估了著名的实例分割模型。

Result: 与仅使用真实数据相比，在所有模型中，合成数据在鸡胴体分割方面显著提高了性能。

Conclusion: 该研究表明，在真实带注释数据稀缺的情况下，使用合成数据增强可以有效提高鸡胴体分割的性能，同时减少手动注释的工作量，并推动鸡胴体检测的自动化。

Abstract: The poultry industry has been driven by broiler chicken production and has
grown into the world's largest animal protein sector. Automated detection of
chicken carcasses on processing lines is vital for quality control, food
safety, and operational efficiency in slaughterhouses and poultry processing
plants. However, developing robust deep learning models for tasks like instance
segmentation in these fast-paced industrial environments is often hampered by
the need for laborious acquisition and annotation of large-scale real-world
image datasets. We present the first pipeline generating photo-realistic,
automatically labeled synthetic images of chicken carcasses. We also introduce
a new benchmark dataset containing 300 annotated real-world images, curated
specifically for poultry segmentation research. Using these datasets, this
study investigates the efficacy of synthetic data and automatic data annotation
to enhance the instance segmentation of chicken carcasses, particularly when
real annotated data from the processing line is scarce. A small real dataset
with varying proportions of synthetic images was evaluated in prominent
instance segmentation models. Results show that synthetic data significantly
boosts segmentation performance for chicken carcasses across all models. This
research underscores the value of synthetic data augmentation as a viable and
effective strategy to mitigate data scarcity, reduce manual annotation efforts,
and advance the development of robust AI-driven automated detection systems for
chicken carcasses in the poultry processing industry.

</details>


### [83] [Deep Learning-Based Age Estimation and Gender Deep Learning-Based Age Estimation and Gender Classification for Targeted Advertisement](https://arxiv.org/abs/2507.18565)
*Muhammad Imran Zaman,Nisar Ahmed*

Main category: cs.CV

TL;DR: 提出了一种新的深度学习方法，使用CNN对人脸图像进行年龄和性别分类，以提高定向广告的有效性。该方法在性别分类上达到95%的准确率，年龄估计的平均绝对误差为5.77岁，并指出了在识别年幼个体年龄方面存在的挑战。


<details>
  <summary>Details</summary>
Motivation: 为了提高定向广告活动的有效性，需要一种能够从面部图像同时对年龄和性别进行分类的方法，并利用年龄和性别信息中固有的相关性。

Method: 提出了一种新颖的深度学习方法，使用定制的卷积神经网络（CNN）架构，用于面部图像的年龄和性别联合分类。该模型学习共享表示，并在多样化的面部图像数据集上进行了训练。

Result: 实验结果表明，性别分类准确率显著提高至95%，年龄估计的平均绝对误差为5.77岁。研究还分析了不同年龄组的性能，并探讨了CNN架构和超参数对整体性能的影响。

Conclusion: 该模型在性别分类上达到了95%的准确率，在年龄估计上取得了5.77岁的平均绝对误差。分析显示，在识别年幼个体年龄方面存在挑战，需要进行数据增强和模型优化。

Abstract: This paper presents a novel deep learning-based approach for simultaneous age
and gender classification from facial images, designed to enhance the
effectiveness of targeted advertising campaigns. We propose a custom
Convolutional Neural Network (CNN) architecture, optimized for both tasks,
which leverages the inherent correlation between age and gender information
present in facial features. Unlike existing methods that often treat these
tasks independently, our model learns shared representations, leading to
improved performance. The network is trained on a large, diverse dataset of
facial images, carefully pre-processed to ensure robustness against variations
in lighting, pose, and image quality. Our experimental results demonstrate a
significant improvement in gender classification accuracy, achieving 95%, and a
competitive mean absolute error of 5.77 years for age estimation. Critically,
we analyze the performance across different age groups, identifying specific
challenges in accurately estimating the age of younger individuals. This
analysis reveals the need for targeted data augmentation and model refinement
to address these biases. Furthermore, we explore the impact of different CNN
architectures and hyperparameter settings on the overall performance, providing
valuable insights for future research.

</details>


### [84] [Facial Demorphing from a Single Morph Using a Latent Conditional GAN](https://arxiv.org/abs/2507.18566)
*Nitish Shukla,Arun Ross*

Main category: cs.CV

TL;DR: 提出一种在潜在空间分解变形图的新方法，解决了现有重构方法的变形复制问题，并能处理未知的变形技术和面部风格，在真实数据集上取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的人脸变形图检测方法（MAD）无法识别变形图的构成身份，而现有的重构方法存在重构结果与变形图相似度高（变形复制问题）或假设训练和测试时使用相同变形技术的问题。本文提出了一种新的重构方法，以解决上述问题。

Method: 该方法在潜在空间中分解变形图像，使其能够对来自未见过的变形技术和面部风格的变形图像进行重构。

Result: 该方法能够对来自未见过的变形技术和面部风格的变形图像进行重构，并且性能优于现有方法，重构的人脸图像保真度高。

Conclusion: 该方法在合成人脸的变形图像上进行训练，并在使用任意变形技术的真实人脸变形图像上进行测试，其性能明显优于现有方法，并能生成高保真度的重构人脸图像。

Abstract: A morph is created by combining two (or more) face images from two (or more)
identities to create a composite image that is highly similar to both
constituent identities, allowing the forged morph to be biometrically
associated with more than one individual. Morph Attack Detection (MAD) can be
used to detect a morph, but does not reveal the constituent images. Demorphing
- the process of deducing the constituent images - is thus vital to provide
additional evidence about a morph. Existing demorphing methods suffer from the
morph replication problem, where the outputs tend to look very similar to the
morph itself, or assume that train and test morphs are generated using the same
morph technique. The proposed method overcomes these issues. The method
decomposes a morph in latent space allowing it to demorph images created from
unseen morph techniques and face styles. We train our method on morphs created
from synthetic faces and test on morphs created from real faces using arbitrary
morph techniques. Our method outperforms existing methods by a considerable
margin and produces high fidelity demorphed face images.

</details>


### [85] [Adversarial Distribution Matching for Diffusion Distillation Towards Efficient Image and Video Synthesis](https://arxiv.org/abs/2507.18569)
*Yanzuo Lu,Yuxi Ren,Xin Xia,Shanchuan Lin,Xing Wang,Xuefeng Xiao,Andy J. Ma,Xiaohua Xie,Jian-Huang Lai*

Main category: cs.CV

TL;DR: ADM通过对抗性学习解决DMD的模式崩溃问题，并在图像和视频合成方面设定了新的性能基准。


<details>
  <summary>Details</summary>
Motivation: 为了解决DMD依赖反向KL散度最小化可能引起的模式崩溃问题，提出ADM框架。

Method: ADM框架利用基于扩散的判别器，以对抗方式对齐真实和伪造分数估计器之间的潜在预测，用于分数蒸馏。在一步蒸馏的挑战性应用中，通过在潜在和像素空间中结合混合判别器的对抗蒸馏来进一步改进预训练生成器。ADM还整合了ODE对上的分布损失，为后续阶段的分数蒸馏微调提供了更好的初始化。

Result: ADM在SDXL上实现了一步蒸馏的优越性能，并且GPU时间更少。将多步ADM蒸馏应用于SD3-Medium、SD3.5-Large和CogVideoX，为高效图像和视频合成设定了新的基准。

Conclusion: ADM通过结合对抗蒸馏预训练和ADM微调到DMDX统一流程中，在SDXL上实现了一步蒸馏的优越性能，并且GPU时间更少。将多步ADM蒸馏应用于SD3-Medium、SD3.5-Large和CogVideoX，为高效图像和视频合成设定了新的基准。

Abstract: Distribution Matching Distillation (DMD) is a promising score distillation
technique that compresses pre-trained teacher diffusion models into efficient
one-step or multi-step student generators. Nevertheless, its reliance on the
reverse Kullback-Leibler (KL) divergence minimization potentially induces mode
collapse (or mode-seeking) in certain applications. To circumvent this inherent
drawback, we propose Adversarial Distribution Matching (ADM), a novel framework
that leverages diffusion-based discriminators to align the latent predictions
between real and fake score estimators for score distillation in an adversarial
manner. In the context of extremely challenging one-step distillation, we
further improve the pre-trained generator by adversarial distillation with
hybrid discriminators in both latent and pixel spaces. Different from the mean
squared error used in DMD2 pre-training, our method incorporates the
distributional loss on ODE pairs collected from the teacher model, and thus
providing a better initialization for score distillation fine-tuning in the
next stage. By combining the adversarial distillation pre-training with ADM
fine-tuning into a unified pipeline termed DMDX, our proposed method achieves
superior one-step performance on SDXL compared to DMD2 while consuming less GPU
time. Additional experiments that apply multi-step ADM distillation on
SD3-Medium, SD3.5-Large, and CogVideoX set a new benchmark towards efficient
image and video synthesis.

</details>


### [86] [HybridTM: Combining Transformer and Mamba for 3D Semantic Segmentation](https://arxiv.org/abs/2507.18575)
*Xinyu Wang,Jinghua Hou,Zhe Liu,Yingying Zhu*

Main category: cs.CV

TL;DR: 提出HybridTM，一种结合Transformer和Mamba的3D语义分割混合架构，解决了Transformer的长距离依赖建模和Mamba的特征表示问题，并在多个基准上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: Transformer在3D语义分割中具有强大的注意力机制，但其二次复杂度限制了对大规模点云中长距离依赖的建模。基于Mamba的方法虽然具有线性复杂度，但在提取3D特征时存在特征表示的不足。如何有效结合两者的互补优势仍然是一个开放的挑战。

Method: 提出了一种名为HybridTM的混合架构，该架构集成了Transformer和Mamba，并提出了一种内部层混合策略，以更精细的粒度结合注意力和Mamba，从而同时捕捉长距离依赖关系和细粒度的局部特征。

Result: 实验证明了HybridTM在各种室内和室外数据集上的有效性和泛化能力。

Conclusion: HybridTM在ScanNet、ScanSet200和nuScenes基准上取得了最先进的性能。

Abstract: Transformer-based methods have demonstrated remarkable capabilities in 3D
semantic segmentation through their powerful attention mechanisms, but the
quadratic complexity limits their modeling of long-range dependencies in
large-scale point clouds. While recent Mamba-based approaches offer efficient
processing with linear complexity, they struggle with feature representation
when extracting 3D features. However, effectively combining these complementary
strengths remains an open challenge in this field. In this paper, we propose
HybridTM, the first hybrid architecture that integrates Transformer and Mamba
for 3D semantic segmentation. In addition, we propose the Inner Layer Hybrid
Strategy, which combines attention and Mamba at a finer granularity, enabling
simultaneous capture of long-range dependencies and fine-grained local
features. Extensive experiments demonstrate the effectiveness and
generalization of our HybridTM on diverse indoor and outdoor datasets.
Furthermore, our HybridTM achieves state-of-the-art performance on ScanNet,
ScanNet200, and nuScenes benchmarks. The code will be made available at
https://github.com/deepinact/HybridTM.

</details>


### [87] [DRWKV: Focusing on Object Edges for Low-Light Image Enhancement](https://arxiv.org/abs/2507.18594)
*Xuecheng Bai,Yuxiang Wang,Boyu Hu,Qinyuan Jie,Chuanzhi Xu,Hongru Xiao,Kechen Li,Vera Chung*

Main category: cs.CV

TL;DR: DRWKV是一种用于低光图像增强的新型模型，通过整合GER理论、进化WKV注意力和Bi-SAB与MS2-Loss，能够有效提升边缘保真度、空间连续性和视觉自然度，并在各项性能指标上取得领先，同时具备泛化能力。


<details>
  <summary>Details</summary>
Motivation: 低光图像增强仍然是一项挑战性任务，特别是在极端光照退化下保持物体边缘连续性和精细结构细节方面。

Method: 本文提出了一种名为DRWKV（Detailed Receptance Weighted Key Value）的新型模型，该模型整合了提出的全局边缘Retinex（GER）理论，能够有效分离光照和边缘结构，从而增强边缘保真度。其次，引入了进化WKV注意力（Evolving WKV Attention），一种螺旋扫描机制，能够更有效地捕获空间边缘连续性并对不规则结构进行建模。第三，设计了双边谱对齐器（Bi-SAB）和定制的MS2-Loss，以联合对齐亮度和色度特征，提高视觉自然度并减轻伪影。

Result: DRWKV在五个低光图像增强基准测试中取得了领先的性能，同时保持了较低的计算复杂度。此外，DRWKV在低光多目标跟踪任务中提高了下游性能，验证了其泛化能力。

Conclusion: DRWKV在PSNR、SSIM和NIQE方面取得了领先的性能，同时保持了较低的计算复杂度。此外，DRWKV在低光多目标跟踪任务中提高了下游性能，验证了其泛化能力。

Abstract: Low-light image enhancement remains a challenging task, particularly in
preserving object edge continuity and fine structural details under extreme
illumination degradation. In this paper, we propose a novel model, DRWKV
(Detailed Receptance Weighted Key Value), which integrates our proposed Global
Edge Retinex (GER) theory, enabling effective decoupling of illumination and
edge structures for enhanced edge fidelity. Secondly, we introduce Evolving WKV
Attention, a spiral-scanning mechanism that captures spatial edge continuity
and models irregular structures more effectively. Thirdly, we design the
Bilateral Spectrum Aligner (Bi-SAB) and a tailored MS2-Loss to jointly align
luminance and chrominance features, improving visual naturalness and mitigating
artifacts. Extensive experiments on five LLIE benchmarks demonstrate that DRWKV
achieves leading performance in PSNR, SSIM, and NIQE while maintaining low
computational complexity. Furthermore, DRWKV enhances downstream performance in
low-light multi-object tracking tasks, validating its generalization
capabilities.

</details>


### [88] [3D Software Synthesis Guided by Constraint-Expressive Intermediate Representation](https://arxiv.org/abs/2507.18625)
*Shuqing Li,Anson Y. Lam,Yun Peng,Wenxuan Wang,Michael R. Lyu*

Main category: cs.CV

TL;DR: Scenethesis 是一种新的 3D 软件合成方法，使用 ScenethesisLang 语言来处理复杂的空间和语义约束，提高了需求捕获和约束满足率，并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有 3D 软件生成方法在处理复杂空间和语义约束以及对特定元素进行修改和控制方面存在不足。为了解决这些挑战，提出 Scenethesis 来实现对用户规范和生成的 3D 软件之间的形式可追溯性。

Method: 提出了一种名为 Scenethesis 的新型需求敏感 3D 软件合成方法。该方法基于 ScenethesisLang，这是一种领域特定语言，作为一种细粒度的、约束感知的中间表示（IR），用于连接自然语言需求和可执行的 3D 软件。Scenethesis 将 3D 软件合成分解为在 ScenethesisLang 上运行的阶段，实现了独立验证、目标修改和系统的约束满足。

Result: Scenethesis 准确捕获了超过 80% 的用户需求，满足了超过 90% 的硬约束，并能同时处理超过 100 个约束。与最先进的方法相比，BLIP-2 视觉评估分数提高了 42.8%。

Conclusion: Scenethesis 通过将 3D 软件合成分解为在 ScenethesisLang 上运行的阶段，实现了对用户需求的准确捕获（超过 80%）和硬约束的满足（超过 90%），同时能处理超过 100 个约束。与最先进的方法相比，BLIP-2 视觉评估分数提高了 42.8%。

Abstract: Graphical user interface (UI) software has undergone a fundamental
transformation from traditional two-dimensional (2D) desktop/web/mobile
interfaces to spatial three-dimensional (3D) environments. While existing work
has made remarkable success in automated 2D software generation, such as
HTML/CSS and mobile app interface code synthesis, the generation of 3D software
still remains under-explored. Current methods for 3D software generation
usually generate the 3D environments as a whole and cannot modify or control
specific elements in the software. Furthermore, these methods struggle to
handle the complex spatial and semantic constraints inherent in the real world.
To address the challenges, we present Scenethesis, a novel
requirement-sensitive 3D software synthesis approach that maintains formal
traceability between user specifications and generated 3D software. Scenethesis
is built upon ScenethesisLang, a domain-specific language that serves as a
granular constraint-aware intermediate representation (IR) to bridge natural
language requirements and executable 3D software. It serves both as a
comprehensive scene description language enabling fine-grained modification of
3D software elements and as a formal constraint-expressive specification
language capable of expressing complex spatial constraints. By decomposing 3D
software synthesis into stages operating on ScenethesisLang, Scenethesis
enables independent verification, targeted modification, and systematic
constraint satisfaction. Our evaluation demonstrates that Scenethesis
accurately captures over 80% of user requirements and satisfies more than 90%
of hard constraints while handling over 100 constraints simultaneously.
Furthermore, Scenethesis achieves a 42.8% improvement in BLIP-2 visual
evaluation scores compared to the state-of-the-art method.

</details>


### [89] [SIDA: Synthetic Image Driven Zero-shot Domain Adaptation](https://arxiv.org/abs/2507.18632)
*Ye-Chan Kim,SeungJu Cha,Si-Woo Kim,Taewhan Kim,Dong-Jin Kim*

Main category: cs.CV

TL;DR: SIDA是一种新颖且高效的零样本域适应方法，利用合成图像代替文本描述来捕捉风格线索。通过域混合和补丁风格迁移模块，该方法能有效模拟现实世界的变化，并在各种场景下实现最先进的性能，同时大大缩短了适应时间。


<details>
  <summary>Details</summary>
Motivation: 现有零样本域适应方法依赖CLIP的嵌入空间和文本描述来模拟目标域风格，但这种方法难以捕捉复杂的现实世界变化，并且适应时间长。为了解决这些问题，本研究探索利用图像数据，因为它能提供更丰富、更细粒度的风格线索。

Method: SIDA方法利用合成图像进行零样本域适应，通过创建源域图像并进行图像翻译以反映目标域风格来生成合成图像。利用这些合成图像的风格特征作为目标域的代理，并引入了域混合（Domain Mix）和补丁风格迁移（Patch Style Transfer）模块来模拟现实世界的变化。其中，域混合用于融合多种风格以扩展类内表示，补丁风格迁移则为不同图像块分配不同风格。

Result: SIDA方法在各种零样本域适应场景下展现出最先进的性能，尤其是在具有挑战性的领域，同时显著减少了适应时间，实现了高效的适应。

Conclusion: SIDA方法在各种零样本域适应场景下均取得了最先进的性能，尤其是在具有挑战性的领域，并且显著减少了适应时间，提高了效率。

Abstract: Zero-shot domain adaptation is a method for adapting a model to a target
domain without utilizing target domain image data. To enable adaptation without
target images, existing studies utilize CLIP's embedding space and text
description to simulate target-like style features. Despite the previous
achievements in zero-shot domain adaptation, we observe that these text-driven
methods struggle to capture complex real-world variations and significantly
increase adaptation time due to their alignment process. Instead of relying on
text descriptions, we explore solutions leveraging image data, which provides
diverse and more fine-grained style cues. In this work, we propose SIDA, a
novel and efficient zero-shot domain adaptation method leveraging synthetic
images. To generate synthetic images, we first create detailed, source-like
images and apply image translation to reflect the style of the target domain.
We then utilize the style features of these synthetic images as a proxy for the
target domain. Based on these features, we introduce Domain Mix and Patch Style
Transfer modules, which enable effective modeling of real-world variations. In
particular, Domain Mix blends multiple styles to expand the intra-domain
representations, and Patch Style Transfer assigns different styles to
individual patches. We demonstrate the effectiveness of our method by showing
state-of-the-art performance in diverse zero-shot adaptation scenarios,
particularly in challenging domains. Moreover, our approach achieves high
efficiency by significantly reducing the overall adaptation time.

</details>


### [90] [Identifying Prompted Artist Names from Generated Images](https://arxiv.org/abs/2507.18633)
*Grace Su,Sheng-Yu Wang,Aaron Hertzmann,Eli Shechtman,Jun-Yan Zhu,Richard Zhang*

Main category: cs.CV

TL;DR: 介绍了一个包含 1.95M 张图像、涵盖 110 位艺术家的基准，用于识别文本到图像模型生成图像时所使用的艺术家名称。该基准包含四个泛化设置，并评估了多种方法。结果表明，在多艺术家提示方面仍有很大改进空间。


<details>
  <summary>Details</summary>
Motivation: 介绍了一个用于提示艺术家识别的基准，以解决文本到图像模型中一个常见且有争议的用法：通过明确命名艺术家（例如，“在 Greg Rutkowski 的风格中”）来生成图片。

Method: 介绍了一个用于提示艺术家识别的基准：仅从图像预测提示中调用的艺术家名称。该数据集包含涵盖 110 位艺术家的 1.95M 张图像，并涵盖了四个泛化设置：持出艺术家、增加的提示复杂性、多个艺术家提示和不同的文本到图像模型。评估了特征相似性基线、对比风格描述符、数据归属方法、监督分类器和少样本原型网络。

Result: 在泛化模式方面，监督和少样本模型在可见艺术家和复杂提示方面表现出色，而当艺术家的风格明显时，风格描述符的迁移效果更好；多艺术家提示仍然是最具挑战性的。

Conclusion: 该基准测试揭示了显著的提升空间，并提供了一个公开的测试平台，以促进文本到图像模型的负责任的审核。

Abstract: A common and controversial use of text-to-image models is to generate
pictures by explicitly naming artists, such as "in the style of Greg
Rutkowski". We introduce a benchmark for prompted-artist recognition:
predicting which artist names were invoked in the prompt from the image alone.
The dataset contains 1.95M images covering 110 artists and spans four
generalization settings: held-out artists, increasing prompt complexity,
multiple-artist prompts, and different text-to-image models. We evaluate
feature similarity baselines, contrastive style descriptors, data attribution
methods, supervised classifiers, and few-shot prototypical networks.
Generalization patterns vary: supervised and few-shot models excel on seen
artists and complex prompts, whereas style descriptors transfer better when the
artist's style is pronounced; multi-artist prompts remain the most challenging.
Our benchmark reveals substantial headroom and provides a public testbed to
advance the responsible moderation of text-to-image models. We release the
dataset and benchmark to foster further research:
https://graceduansu.github.io/IdentifyingPromptedArtists/

</details>


### [91] [Captain Cinema: Towards Short Movie Generation](https://arxiv.org/abs/2507.18634)
*Junfei Xiao,Ceyuan Yang,Lvmin Zhang,Shengqu Cai,Yang Zhao,Yuwei Guo,Gordon Wetzstein,Maneesh Agrawala,Alan Yuille,Lu Jiang*

Main category: cs.CV

TL;DR: Captain Cinema是一个短片生成框架，通过关键帧规划和视频合成来确保叙事和视觉的长期连贯性，并采用交错训练策略和专门数据集进行优化。


<details>
  <summary>Details</summary>
Motivation: 为了生成具有长期连贯性的短片，需要一种能够处理长叙事和视觉动态的生成框架。

Method: 该框架首先生成一系列关键帧，以确保故事情节和视觉外观的长期连贯性，然后将这些关键帧作为视频合成模型的条件信号，以产生它们之间的时空动态。通过交错训练策略和专门策划的电影数据集来支持多场景长叙事电影的稳定高效生成。

Result: 生成的短片在视觉上是连贯的，叙事上是一致的，并且质量高、效率高。

Conclusion: Captain Cinema在自动创建视觉连贯、叙事一致、高质量且高效的短片方面表现良好。

Abstract: We present Captain Cinema, a generation framework for short movie generation.
Given a detailed textual description of a movie storyline, our approach firstly
generates a sequence of keyframes that outline the entire narrative, which
ensures long-range coherence in both the storyline and visual appearance (e.g.,
scenes and characters). We refer to this step as top-down keyframe planning.
These keyframes then serve as conditioning signals for a video synthesis model,
which supports long context learning, to produce the spatio-temporal dynamics
between them. This step is referred to as bottom-up video synthesis. To support
stable and efficient generation of multi-scene long narrative cinematic works,
we introduce an interleaved training strategy for Multimodal Diffusion
Transformers (MM-DiT), specifically adapted for long-context video data. Our
model is trained on a specially curated cinematic dataset consisting of
interleaved data pairs. Our experiments demonstrate that Captain Cinema
performs favorably in the automated creation of visually coherent and narrative
consistent short movies in high quality and efficiency. Project page:
https://thecinema.ai

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [92] [Shop-R1: Rewarding LLMs to Simulate Human Behavior in Online Shopping via Reinforcement Learning](https://arxiv.org/abs/2507.17842)
*Yimeng Zhang,Tian Wang,Jiri Gesi,Ziyi Wang,Yuxuan Lu,Jiacheng Lin,Sinong Zhan,Vianne Gao,Ruochen Jiao,Junze Liu,Kun Qian,Yuxin Tang,Ran Xue,Houyu Zhang,Qingjun Cui,Yufan Guo,Dakuo Wang*

Main category: cs.CL

TL;DR: 本文提出 Shop-R1，一种强化学习框架，通过自监督的Rationale Generation和分层奖励的Action Prediction，显著提高了LLM在线购物行为模拟的推理能力和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 在线购物行为模拟方法受限于用于生成推理过程的模型能力。本文旨在通过一种新的强化学习框架来增强 LLM 的推理能力，以更准确地模拟真实人类行为。

Method: Shop-R1 是一个新颖的强化学习框架，将任务分解为两个阶段：1.  वापरा内部模型信号（如 logit 分布）进行自监督推理的“Rationale Generation”；2. 提出分层奖励结构，包含难度感知缩放，用于评估高级动作类型和细粒度子动作（属性和值）的准确性，以“Action Prediction”阶段。

Result: Shop-R1 相比基线方法实现了超过 65% 的相对性能提升。

Conclusion: Shop-R1 通过包含内部模型信号的自监督学习和分层奖励结构，提高了 LLM 在线购物环境中的推理能力和行为模拟的准确性，相比基线方法有显著提升。

Abstract: Large Language Models (LLMs) have recently demonstrated strong potential in
generating 'believable human-like' behavior in web environments. Prior work has
explored augmenting training data with LLM-synthesized rationales and applying
supervised fine-tuning (SFT) to enhance reasoning ability, which in turn can
improve downstream action prediction. However, the performance of such
approaches remains inherently bounded by the reasoning capabilities of the
model used to generate the rationales. In this paper, we introduce Shop-R1, a
novel reinforcement learning (RL) framework aimed at enhancing the reasoning
ability of LLMs for simulation of real human behavior in online shopping
environments Specifically, Shop-R1 decomposes the human behavior simulation
task into two stages: rationale generation and action prediction, each guided
by distinct reward signals. For rationale generation, we leverage internal
model signals (e.g., logit distributions) to guide the reasoning process in a
self-supervised manner. For action prediction, we propose a hierarchical reward
structure with difficulty-aware scaling to prevent reward hacking and enable
fine-grained reward assignment. This design evaluates both high-level action
types and the correctness of fine-grained sub-action details (attributes and
values), rewarding outputs proportionally to their difficulty. Experimental
results show that our method achieves a relative improvement of over 65%
compared to the baseline.

</details>


### [93] [Dynamic and Generalizable Process Reward Modeling](https://arxiv.org/abs/2507.17849)
*Zhangyue Yin,Qiushi Sun,Zhiyuan Zeng,Qinyuan Cheng,Xipeng Qiu,Xuanjing Huang*

Main category: cs.CL

TL;DR: DG-PRM通过奖励树和帕累托支配估计解决了现有过程奖励模型的局限性，实现了动态、可泛化的奖励，并在各项任务和分布外场景中取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 现有过程奖励模型（PRMs）依赖启发式方法，难以实现跨域泛化。虽然LLM-as-judge被提出用于提供泛化奖励，但现有研究主要关注反馈结果，忽略了文本中包含的有意义的指导。此外，静态和粗粒度的评估标准难以适应复杂的过程监督。

Method: 提出了一种动态且可泛化的过程奖励模型（DG-PRM），该模型包含一个奖励树，用于捕捉和存储细粒度的、多维度的奖励标准。DG-PRM能够动态选择奖励信号进行分步奖励评分。为了处理多方面的奖励信号，研究采用了帕累托支配估计来识别具有区分性的正负样本对。

Result: DG-PRM在主流基准测试中取得了惊人的性能，显著提升了模型在需要密集奖励的任务上的表现。实验结果表明，DG-PRM能够很好地适应分布外场景，展现出卓越的泛化能力。

Conclusion: DG-PRM在监督学习的各项任务中显著提升了模型的性能，并且在分布外场景中表现出良好的适应性和泛化能力。

Abstract: Process Reward Models (PRMs) are crucial for guiding Large Language Models
(LLMs) in complex scenarios by providing dense reward signals. However,
existing PRMs primarily rely on heuristic approaches, which struggle with
cross-domain generalization. While LLM-as-judge has been proposed to provide
generalized rewards, current research has focused mainly on feedback results,
overlooking the meaningful guidance embedded within the text. Additionally,
static and coarse-grained evaluation criteria struggle to adapt to complex
process supervision. To tackle these challenges, we propose Dynamic and
Generalizable Process Reward Modeling (DG-PRM), which features a reward tree to
capture and store fine-grained, multi-dimensional reward criteria. DG-PRM
dynamically selects reward signals for step-wise reward scoring. To handle
multifaceted reward signals, we pioneeringly adopt Pareto dominance estimation
to identify discriminative positive and negative pairs. Experimental results
show that DG-PRM achieves stunning performance on prevailing benchmarks,
significantly boosting model performance across tasks with dense rewards.
Further analysis reveals that DG-PRM adapts well to out-of-distribution
scenarios, demonstrating exceptional generalizability.

</details>


### [94] [VeriMinder: Mitigating Analytical Vulnerabilities in NL2SQL](https://arxiv.org/abs/2507.17896)
*Shubham Mohole,Sainyam Galhotra*

Main category: cs.CL

TL;DR: VeriMinder 是一个旨在帮助用户提出无偏见分析问题的交互式系统。它通过上下文语义映射、分析框架和 LLM 驱动的提示生成来检测和缓解分析中的认知偏见，用户测试结果显示其在提高分析质量方面效果显著。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言数据库接口（NLIDBs）的普及，用户可能缺乏统计分析背景，这带来了提出无偏见分析问题的挑战。现有研究虽关注 Text-to-SQL 的准确性，但对分析问题的认知偏见的研究尚不充分。

Method: VeriMinder 系统引入了三项关键创新：1. 针对特定分析背景的上下文语义映射框架，用于识别相关偏见。2. 操作化“难变性”原则的分析框架，指导用户进行系统性数据分析。3. 优化后的、由 LLM 驱动的系统，通过多候选者、批评反馈和自我反思的结构化流程生成高质量、特定任务的提示。

Result: VeriMinder 系统成功检测并缓解了分析中的认知偏见，提高了分析的质量、具体性、全面性和准确性。

Conclusion: VeriMinder 系统通过用户测试验证了其有效性，82.5% 的参与者认为该系统积极影响了分析质量。在对比评估中，VeriMinder 在分析的具体性、全面性和准确性方面显著优于其他方法，提升率至少达到 20%。

Abstract: Application systems using natural language interfaces to databases (NLIDBs)
have democratized data analysis. This positive development has also brought
forth an urgent challenge to help users who might use these systems without a
background in statistical analysis to formulate bias-free analytical questions.
Although significant research has focused on text-to-SQL generation accuracy,
addressing cognitive biases in analytical questions remains underexplored. We
present VeriMinder, https://veriminder.ai, an interactive system for detecting
and mitigating such analytical vulnerabilities. Our approach introduces three
key innovations: (1) a contextual semantic mapping framework for biases
relevant to specific analysis contexts (2) an analytical framework that
operationalizes the Hard-to-Vary principle and guides users in systematic data
analysis (3) an optimized LLM-powered system that generates high-quality,
task-specific prompts using a structured process involving multiple candidates,
critic feedback, and self-reflection.
  User testing confirms the merits of our approach. In direct user experience
evaluation, 82.5% participants reported positively impacting the quality of the
analysis. In comparative evaluation, VeriMinder scored significantly higher
than alternative approaches, at least 20% better when considered for metrics of
the analysis's concreteness, comprehensiveness, and accuracy. Our system,
implemented as a web application, is set to help users avoid "wrong question"
vulnerability during data analysis. VeriMinder code base with prompts,
https://reproducibility.link/veriminder, is available as an MIT-licensed
open-source software to facilitate further research and adoption within the
community.

</details>


### [95] [One Whisper to Grade Them All](https://arxiv.org/abs/2507.17918)
*Nhan Phan,Anusha Porwal,Yaroslav Getman,Ekaterina Voskoboinik,Tamás Grósz,Mikko Kurimo*

Main category: cs.CL

TL;DR: 一种创新的端到端自动口语评估（ASA）方法，使用单一Whisper-small模型处理所有口语回答，无需转录，大大提高效率，并在2025年Speak & Improve挑战赛中取得了领先的性能。数据。


<details>
  <summary>Details</summary>
Motivation: 为了应对多部分二语测试的整体自动口语评估（ASA）需求，并提高效率，去除转录和分部分模型的需求，缩短推理时间，使ASA能够在大规模计算机辅助语言学习系统中使用。

Method: 提出了一种端到端的整体自动口语评估（ASA）方法，使用单一的Whisper-small编码器处理所有四个口语回答，并通过轻量级聚合器结合信息进行最终评分。此外，还提出了一种数据采样策略，允许在仅使用44.8%的说话者数据的情况下训练模型，并达到0.383的RMSE。

Result: 在2025年Speak & Improve挑战赛中，该系统实现了0.384的RMSE，优于文本基线（0.44）。通过数据采样策略，模型在仅使用44.8%的说话者数据的情况下达到了0.383的RMSE。

Conclusion: 该系统在2025年Speak & Improve挑战赛中取得了优异成绩，RMSE为0.384，优于文本基线（0.44），证明了其在整体自动口语评估方面的有效性和效率。

Abstract: We present an efficient end-to-end approach for holistic Automatic Speaking
Assessment (ASA) of multi-part second-language tests, developed for the 2025
Speak & Improve Challenge. Our system's main novelty is the ability to process
all four spoken responses with a single Whisper-small encoder, combine all
information via a lightweight aggregator, and predict the final score. This
architecture removes the need for transcription and per-part models, cuts
inference time, and makes ASA practical for large-scale Computer-Assisted
Language Learning systems.
  Our system achieved a Root Mean Squared Error (RMSE) of 0.384, outperforming
the text-based baseline (0.44) while using at most 168M parameters (about 70%
of Whisper-small). Furthermore, we propose a data sampling strategy, allowing
the model to train on only 44.8% of the speakers in the corpus and still reach
0.383 RMSE, demonstrating improved performance on imbalanced classes and strong
data efficiency.

</details>


### [96] [Evaluating the Performance of AI Text Detectors, Few-Shot and Chain-of-Thought Prompting Using DeepSeek Generated Text](https://arxiv.org/abs/2507.17944)
*Hulayyil Alshammari,Praveen Rao*

Main category: cs.CL

TL;DR: 本研究评估了六种AI检测工具和DeepSeek模型本身识别DeepSeek生成文本的能力，并测试了释义和人类化等对抗性攻击的效果。结果显示，QuillBot和Copyleaks表现最佳，而人类化攻击显著降低了检测准确率。DeepSeek模型通过少样本和CoT提示，在检测方面表现出高准确率。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型（LLMs）在文本生成领域的广泛应用引发了对写作完整性的担忧，AI检测技术应运而生。然而，现有的研究主要集中在ChatGPT等知名LLMs，而对新近发布的DeepSeek模型的研究存在空白。因此，本研究旨在探究现有的AI检测工具在识别DeepSeek生成文本方面的有效性，并评估对抗性攻击（如释义和人类化）对检测准确率的影响，同时探索DeepSeek模型本身作为检测器的潜力。

Method: 本研究评估了六种AI检测工具（AI Text Classifier, Content Detector AI, Copyleaks, QuillBot, GPT-2, GPTZero）识别DeepSeek生成文本的能力，并对这些文本进行了标准的释义和人类化等对抗性攻击。此外，研究还将DeepSeek本身作为检测器，通过少样本提示和思维链（CoT）推理来区分AI和人类文本。实验数据包括49对人类问答以及使用DeepSeek-v3生成的49个AI回答，并增加了196个经过对抗性技术处理的样本，以评估检测器的鲁棒性和准确性。

Result: QuillBot和Copyleaks在原始和释义后的DeepSeek文本上表现出接近完美的性能。然而，AI Text Classifier和GPT-2等工具的表现则不稳定。人类化攻击对检测准确率的影响最大，Copyleaks、QuillBot和GPTZero的准确率分别降至71%、58%和52%。另一方面，少样本提示和思维链（CoT）提示在识别AI和人类文本方面表现出高准确率，其中最佳的五样本提示仅错分了1个样本（AI召回率96%，人类召回率100%）。

Conclusion: QuillBot和Copyleaks在识别原始和释义后的DeepSeek文本方面表现接近完美，而AI Text Classifier和GPT-2等检测器的结果则不尽人意。人类化攻击是最有效的攻击方式，导致Copyleaks、QuillBot和GPTZero的准确率分别下降至71%、58%和52%。少样本和思维链提示（CoT）在识别AI和人类文本方面展现出高准确率，其中最佳的五样本提示仅错误分类了49个样本中的1个（AI召回率96%，人类召回率100%）。

Abstract: Large language models (LLMs) have rapidly transformed the creation of written
materials. LLMs have led to questions about writing integrity, thereby driving
the creation of artificial intelligence (AI) detection technologies.
Adversarial attacks, such as standard and humanized paraphrasing, inhibit
detectors' ability to detect machine-generated text. Previous studies have
mainly focused on ChatGPT and other well-known LLMs and have shown varying
accuracy across detectors. However, there is a clear gap in the literature
about DeepSeek, a recently published LLM. Therefore, in this work, we
investigate whether six generally accessible AI detection tools -- AI Text
Classifier, Content Detector AI, Copyleaks, QuillBot, GPT-2, and GPTZero -- can
consistently recognize text generated by DeepSeek. The detectors were exposed
to the aforementioned adversarial attacks. We also considered DeepSeek as a
detector by performing few-shot prompting and chain-of-thought reasoning (CoT)
for classifying AI and human-written text. We collected 49 human-authored
question-answer pairs from before the LLM era and generated matching responses
using DeepSeek-v3, producing 49 AI-generated samples. Then, we applied
adversarial techniques such as paraphrasing and humanizing to add 196 more
samples. These were used to challenge detector robustness and assess accuracy
impact. While QuillBot and Copyleaks showed near-perfect performance on
original and paraphrased DeepSeek text, others -- particularly AI Text
Classifier and GPT-2 -- showed inconsistent results. The most effective attack
was humanization, reducing accuracy to 71% for Copyleaks, 58% for QuillBot, and
52% for GPTZero. Few-shot and CoT prompting showed high accuracy, with the best
five-shot result misclassifying only one of 49 samples (AI recall 96%, human
recall 100%).

</details>


### [97] [Are LLM Belief Updates Consistent with Bayes' Theorem?](https://arxiv.org/abs/2507.17951)
*Sohaib Imran,Ihor Kendiukhov,Matthew Broerman,Aditya Thomas,Riccardo Campanella,Rob Lamb,Peter M. Atkinson*

Main category: cs.CL

TL;DR: 研究表明，更大的语言模型更符合贝叶斯定理。


<details>
  <summary>Details</summary>
Motivation: 为了检验更大的、更强大的语言模型在上下文中接收到证据时，是否能更一致地根据贝叶斯定理更新它们对命题的“信念”。

Method: 提出了一种贝叶斯相干系数（BCC）度量，并生成了一个数据集来衡量BCC。对五个模型家族的多个预训练语言模型进行了BCC测量。

Result: 结果表明，更大的、更强大的预训练语言模型在分配信念时与贝叶斯定理更加一致。模型越大，参数越多，训练数据越多，在常见基准测试上的得分越高，BCC值也越高。

Conclusion: 更大的、更强大的预训练语言模型在分配信念时与贝叶斯定理更加一致。

Abstract: Do larger and more capable language models learn to update their "beliefs"
about propositions more consistently with Bayes' theorem when presented with
evidence in-context? To test this, we formulate a Bayesian Coherence
Coefficient (BCC) metric and generate a dataset with which to measure the BCC.
We measure BCC for multiple pre-trained-only language models across five model
families, comparing against the number of model parameters, the amount of
training data, and model scores on common benchmarks. Our results provide
evidence for our hypothesis that larger and more capable pre-trained language
models assign credences that are more coherent with Bayes' theorem. These
results have important implications for our understanding and governance of
LLMs.

</details>


### [98] [Natural Language Processing for Tigrinya: Current State and Future Directions](https://arxiv.org/abs/2507.17974)
*Fitsum Gaim,Jong C. Park*

Main category: cs.CL

TL;DR: Tigrinya的NLP研究进展缓慢，但正在通过资源创建和新技术取得进展，研究人员应关注其形态复杂性和资源稀缺性问题。


<details>
  <summary>Details</summary>
Motivation: 尽管Tigrinya语言有数百万使用者，但在NLP研究中代表性严重不足。本研究旨在全面调查Tigrinya的NLP研究现状，并为未来的研究提供指导。

Method: 对2011年至2025年间超过40项关于Tigrinya语言的NLP研究进行了系统性回顾和分析，涵盖了计算资源、模型和十种下游任务（包括形态处理、机器翻译、语音识别和问答）。

Result: 分析显示，Tigrinya的NLP研究从早期的基于规则的系统发展到现代的神经网络架构，其进步与资源创建的里程碑密切相关。研究识别了Tigrinya的形态复杂性和资源稀缺性带来的挑战，并指出了有前景的研究方向，如面向形态感知的建模、跨语言迁移和社区驱动的资源开发。

Conclusion: 本文为Tigrinya语言的自然语言处理（NLP）研究提供了一个全面的概述和未来发展方向的路线图，强调了资源创建和特定语言特征（如形态复杂性）对该领域进步的重要性。

Abstract: Despite being spoken by millions of people, Tigrinya remains severely
underrepresented in Natural Language Processing (NLP) research. This work
presents a comprehensive survey of NLP research for Tigrinya, analyzing over 40
studies spanning more than a decade of work from 2011 to 2025. We
systematically review the current state of computational resources, models, and
applications across ten distinct downstream tasks, including morphological
processing, machine translation, speech recognition, and question-answering.
Our analysis reveals a clear trajectory from foundational, rule-based systems
to modern neural architectures, with progress consistently unlocked by resource
creation milestones. We identify key challenges rooted in Tigrinya's
morphological complexity and resource scarcity, while highlighting promising
research directions, including morphology-aware modeling, cross-lingual
transfer, and community-centered resource development. This work serves as both
a comprehensive reference for researchers and a roadmap for advancing Tigrinya
NLP. A curated metadata of the surveyed studies and resources is made publicly
available.\footnote{Tigrinya NLP Anthology:
https://github.com/fgaim/tigrinya-nlp-anthology.

</details>


### [99] [Technical Report of TeleChat2, TeleChat2.5 and T1](https://arxiv.org/abs/2507.18013)
*Zihan Wang,Xinzhang Liu,Yitong Yao,Chao Wang,Yu Zhao,Zhihao Yang,Wenmin Deng,Kaipeng Jia,Jiaxin Peng,Yuyao Huang,Sishi Xiong,Zhuo Jiang,Kaidong Yu,Xiaohui Hu,Fubei Yao,Ruiyu Fang,Zhuoru Jiang,Ruiting Song,Qiyi Xie,Rui Xue,Xuewei He,Yanlei Xue,Zhu Yuan,Zhaoxi Zhang,Zilu Huang,Shiquan Wang,Xin Wang,Hanming Wu,Mingyuan Wang,Xufeng Zhan,Yuhan Sun,Zhaohu Xing,Yuhao Jiang,Bingkai Yang,Shuangyong Song,Yongxiang Li,Zhongjiang He,Xuelong Li*

Main category: cs.CL

TL;DR: 发布了性能显著提升的TeleChat2、TeleChat2.5和T1系列模型，它们在数学、代码生成和复杂推理方面表现优异，并已公开可用。


<details>
  <summary>Details</summary>
Motivation: 为了提供比前代TeleChat更强大的语言模型，特别是在代码生成、数学推理和复杂推理任务方面，并公开这些模型以赋能开发者和研究人员。

Method: 通过改进预训练和后训练策略来提升模型性能，包括使用10万亿高质量、多样化的token进行预训练，监督微调（SFT），直接偏好优化（DPO），以及针对特定领域数据集的持续预训练和强化学习（RL）。TeleChat2.5和T1模型采用了1150亿参数的密集Transformer架构。

Result: TeleChat2、TeleChat2.5和T1模型在推理和通用任务性能上均有显著提升。其中，T1模型在长链思维（CoT）推理、数学和代码方面表现尤为突出，甚至超越了OpenAI的o1-mini和GPT-4o等专有模型。TeleChat2.5则侧重于快速推理。

Conclusion: 该研究发布了TeleChat2、TeleChat2.5和T1三个模型的最新系列，这些模型在性能上相比前代TeleChat有了显著提升。研究公开了这些模型，包括不同参数规模的版本，以支持开发和研究社区。

Abstract: We introduce the latest series of TeleChat models: \textbf{TeleChat2},
\textbf{TeleChat2.5}, and \textbf{T1}, offering a significant upgrade over
their predecessor, TeleChat. Despite minimal changes to the model architecture,
the new series achieves substantial performance gains through enhanced training
strategies in both pre-training and post-training stages. The series begins
with \textbf{TeleChat2}, which undergoes pretraining on 10 trillion
high-quality and diverse tokens. This is followed by Supervised Fine-Tuning
(SFT) and Direct Preference Optimization (DPO) to further enhance its
capabilities. \textbf{TeleChat2.5} and \textbf{T1} expand the pipeline by
incorporating a continual pretraining phase with domain-specific datasets,
combined with reinforcement learning (RL) to improve performance in code
generation and mathematical reasoning tasks. The \textbf{T1} variant is
designed for complex reasoning, supporting long Chain-of-Thought (CoT)
reasoning and demonstrating substantial improvements in mathematics and coding.
In contrast, \textbf{TeleChat2.5} prioritizes speed, delivering rapid
inference. Both flagship models of \textbf{T1} and \textbf{TeleChat2.5} are
dense Transformer-based architectures with 115B parameters, showcasing
significant advancements in reasoning and general task performance compared to
the original TeleChat. Notably, \textbf{T1-115B} outperform proprietary models
such as OpenAI's o1-mini and GPT-4o. We publicly release \textbf{TeleChat2},
\textbf{TeleChat2.5} and \textbf{T1}, including post-trained versions with 35B
and 115B parameters, to empower developers and researchers with
state-of-the-art language models tailored for diverse applications.

</details>


### [100] [NeuralDB: Scaling Knowledge Editing in LLMs to 100,000 Facts with Neural KV Database](https://arxiv.org/abs/2507.18028)
*Weizhi Fei,Hao Shi,Jing Xu,Jingchen Peng,Jiazheng Li,Jingzhao Zhang,Bo Bai,Wei Han,Zhenyuan Chen,Xueyan Niu*

Main category: cs.CL

TL;DR: NeuralDB 通过将编辑事实表示为神经键值（KV）数据库并使用非线性门控检索模块，解决了现有语言模型编辑方法在扩展时损害通用能力和遗忘事实的问题。该方法在大量事实编辑任务中表现出色，并能保持模型的整体性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模语言模型 (LLM) 编辑方法（如定位与编辑 L&E）在扩展到大量事实编辑时，可能会损害模型的通用能力，甚至导致编辑事实的遗忘。

Method: NeuralDB 提出了一种将现有线性定位与编辑 (L&E) 方法建模为查询键值 (KV) 数据库的视角，并在此基础上构建了一个显式地将编辑事实表示为神经 KV 数据库的框架，该框架配备了一个非线性门控检索模块。该门控模块仅在推理涉及编辑事实时激活，从而有效保护了 LLM 的通用能力。

Result: 在 ZsRE 和 CounterFacts 数据集上，使用 GPT2-XL、GPT-J (6B) 和 Llama-3 (8B) 模型进行了涉及 10,000 个事实编辑的综合实验。结果表明，NeuralDB 在编辑效率、泛化性、特异性、流畅性和一致性方面表现优于现有方法，并能保持模型的整体性能。

Conclusion: NeuralDB 框架在编辑效率、泛化性、特异性、流畅性和一致性方面表现出色，并能保持跨六项代表性文本理解和生成任务的整体性能。此外，NeuralDB 在扩展到 100,000 个事实（比先前工作多 50 倍）时仍能保持有效性。

Abstract: Efficiently editing knowledge stored in large language models (LLMs) enables
model updates without large-scale training. One possible solution is
Locate-and-Edit (L\&E), allowing simultaneous modifications of a massive number
of facts. However, such editing may compromise the general abilities of LLMs
and even result in forgetting edited facts when scaling up to thousands of
edits. In this paper, we model existing linear L\&E methods as querying a
Key-Value (KV) database. From this perspective, we then propose NeuralDB, an
editing framework that explicitly represents the edited facts as a neural KV
database equipped with a non-linear gated retrieval module, % In particular,
our gated module only operates when inference involves the edited facts,
effectively preserving the general abilities of LLMs. Comprehensive experiments
involving the editing of 10,000 facts were conducted on the ZsRE and
CounterFacts datasets, using GPT2-XL, GPT-J (6B) and Llama-3 (8B). The results
demonstrate that NeuralDB not only excels in editing efficacy, generalization,
specificity, fluency, and consistency, but also preserves overall performance
across six representative text understanding and generation tasks. Further
experiments indicate that NeuralDB maintains its effectiveness even when scaled
to 100,000 facts (\textbf{50x} more than in prior work).

</details>


### [101] [GrAInS: Gradient-based Attribution for Inference-Time Steering of LLMs and VLMs](https://arxiv.org/abs/2507.18043)
*Duy Nguyen,Archiki Prasad,Elias Stengel-Eskin,Mohit Bansal*

Main category: cs.CL

TL;DR: GrAInS 是一种新的推理时控制方法，通过识别和利用关键 token 的梯度信息，实现了对大型语言模型和视觉语言模型的精细化控制，无需重新训练，并在多个基准测试中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的推理时控制方法通常依赖于固定的、全局的干预向量，忽略了单个输入 token 的因果影响，并且未能利用模型 logits 的信息梯度，特别是在多模态设置中，视觉和文本输入的贡献不均衡的情况下。

Method: GrAInS 是一种推理时控制方法，它结合了对比梯度归因（使用积分梯度）和注意力机制，以识别对模型输出影响最大的 token（正面和负面）。然后，它利用这些 token 来构建方向性控制向量，以引导模型从不良行为转向期望行为。GrAInS 在推理过程中，会根据 token 级别的归因信号来调整 transformer 层中的隐藏激活，并通过归一化激活来保持表示尺度。

Result: GrAInS 在 TruthfulQA 上使用 Llama-3.1-8B 时，准确率提高了 13.22%；在 MMHal-Bench 上使用 LLaVA-1.6-7B 时，幻觉率从 0.624 降低到 0.514；在 SPA-VL 上，对齐胜率提高了 8.11%，同时保持了模型的流畅性和通用能力。

Conclusion: GrAInS 可以在不进行重新训练或辅助监督的情况下，实现对模型行为的细粒度、可解释和模块化控制，并且在各种任务和模型上均优于现有的微调和推理时控制方法。

Abstract: Inference-time steering methods offer a lightweight alternative to
fine-tuning large language models (LLMs) and vision-language models (VLMs) by
modifying internal activations at test time without updating model weights.
However, most existing approaches rely on fixed, global intervention vectors,
overlook the causal influence of individual input tokens, and fail to leverage
informative gradients from the model's logits, particularly in multimodal
settings where visual and textual inputs contribute unevenly. To address these
limitations, we introduce GrAInS, an inference-time steering approach that
operates across both language-only and vision-language models and tasks. GrAInS
uses contrastive, gradient-based attribution via Integrated Gradients to
identify the top-k most influential tokens, both positively and negatively
attributed based on their contribution to preferred versus dispreferred
outputs. These tokens are then used to construct directional steering vectors
that capture semantic shifts from undesirable to desirable behavior. During
inference, GrAInS adjusts hidden activations at transformer layers guided by
token-level attribution signals, and normalizes activations to preserve
representational scale. This enables fine-grained, interpretable, and modular
control over model behavior, without retraining or auxiliary supervision.
Empirically, GrAInS consistently outperforms both fine-tuning and existing
steering baselines: it achieves a 13.22% accuracy gain on TruthfulQA using
Llama-3.1-8B, reduces hallucination rates on MMHal-Bench from 0.624 to 0.514
with LLaVA-1.6-7B, and improves alignment win rates on SPA-VL by 8.11%, all
while preserving the model's fluency and general capabilities.

</details>


### [102] [Synthetic Data Generation for Phrase Break Prediction with Large Language Model](https://arxiv.org/abs/2507.18044)
*Hoyeon Lee,Sejung Son,Ye-Eun Kang,Jong-Hwan Kim*

Main category: cs.CL

TL;DR: LLM 可用于生成合成词语断点标注，以解决传统方法的数据收集挑战。


<details>
  <summary>Details</summary>
Motivation: LLM 在处理 NLP 数据挑战方面的成功，以及当前词语断点预测方法在获取高质量数据方面的挑战。

Method: 利用 LLM 生成合成词语断点标注，并与传统标注进行比较，评估其在多种语言中的有效性。

Result: LLM 生成的合成数据能够有效缓解词语断点预测中的数据挑战。

Conclusion: LLM 生成的合成数据可以有效缓解词语断点预测中的数据挑战，并展示了 LLM 作为语音领域的潜在解决方案。

Abstract: Current approaches to phrase break prediction address crucial prosodic
aspects of text-to-speech systems but heavily rely on vast human annotations
from audio or text, incurring significant manual effort and cost. Inherent
variability in the speech domain, driven by phonetic factors, further
complicates acquiring consistent, high-quality data. Recently, large language
models (LLMs) have shown success in addressing data challenges in NLP by
generating tailored synthetic data while reducing manual annotation needs.
Motivated by this, we explore leveraging LLM to generate synthetic phrase break
annotations, addressing the challenges of both manual annotation and
speech-related tasks by comparing with traditional annotations and assessing
effectiveness across multiple languages. Our findings suggest that LLM-based
synthetic data generation effectively mitigates data challenges in phrase break
prediction and highlights the potential of LLMs as a viable solution for the
speech domain.

</details>


### [103] [Privacy-Preserving Synthetic Review Generation with Diverse Writing Styles Using LLMs](https://arxiv.org/abs/2507.18055)
*Tevin Atwal,Chan Nam Tieu,Yefeng Yuan,Zhan Shi,Yuhong Liu,Liang Cheng*

Main category: cs.CL

TL;DR: 评估了大型语言模型生成的合成数据的多样性和隐私性，发现其存在局限性，并提出了一种基于提示的方法来改进合成评论的多样性，同时保护用户隐私。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）生成的合成数据日益增长的应用，为数据驱动的应用带来了机遇和挑战。虽然合成数据为真实世界数据提供了一种经济高效、可扩展的替代方案以促进模型训练，但其多样性和隐私风险仍有待充分探索。

Method: 提出了一套全面的指标，用于量化评估由几个最先进的大型语言模型生成的文本合成数据的多样性（包括语言表达、情感和用户视角）和隐私性（即重新识别风险和风格异常值）。

Result: 实验结果揭示了大型语言模型在生成多样化和保护隐私的合成数据方面存在显著局限性。

Conclusion: 实验结果揭示了大型语言模型在生成多样化和保护隐私的合成数据方面存在显著局限性。

Abstract: The increasing use of synthetic data generated by Large Language Models
(LLMs) presents both opportunities and challenges in data-driven applications.
While synthetic data provides a cost-effective, scalable alternative to
real-world data to facilitate model training, its diversity and privacy risks
remain underexplored. Focusing on text-based synthetic data, we propose a
comprehensive set of metrics to quantitatively assess the diversity (i.e.,
linguistic expression, sentiment, and user perspective), and privacy (i.e.,
re-identification risk and stylistic outliers) of synthetic datasets generated
by several state-of-the-art LLMs. Experiment results reveal significant
limitations in LLMs' capabilities in generating diverse and privacy-preserving
synthetic data. Guided by the evaluation results, a prompt-based approach is
proposed to enhance the diversity of synthetic reviews while preserving
reviewer privacy.

</details>


### [104] [TELEVAL: A Dynamic Benchmark Designed for Spoken Language Models in Chinese Interactive Scenarios](https://arxiv.org/abs/2507.18061)
*Zehan Li,Hongjie Chen,Yuxin Zhang,Jing Zhou,Xuening Wang,Hang Lv,Mengjie Du,Yaodong Song,Jie Lian,Jian Kang,Jie Li,Yongxiang Li,Zhongjiang He,Xuelong Li*

Main category: cs.CL

TL;DR: 提出TELEVAL，一个用于评估中文口语语言模型的动态基准，关注真实对话交互和用户体验，结果显示现有模型仍需改进。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注SLMs执行复杂任务的能力，未能反映用户在真实对话场景中的交互方式，因此需要一个更贴合实际的评估框架。

Method: 提出了一种名为TELEVAL的动态基准，用于评估中文口语语言模型（SLMs）作为对话代理在现实交互场景中的有效性。TELEVAL包含显式语义、副语言和隐式语义以及系统能力三个评估维度，采用符合实际使用习惯的对话格式，并分别评估文本和音频输出。该基准特别关注模型在无额外指令的情况下从用户语音中提取隐式线索并做出适当响应的能力。

Result: 实验表明，尽管近期取得了进展，但现有的SLMs在自然对话任务方面仍有相当大的改进空间。

Conclusion: 现有的口语语言模型（SLMs）在自然对话任务方面仍有很大提升空间，TELEVAL旨在成为一个以用户为中心的评估框架，直接反映用户体验，并促进更强大的面向对话的SLMs的发展。

Abstract: Spoken language models (SLMs) have seen rapid progress in recent years, along
with the development of numerous benchmarks for evaluating their performance.
However, most existing benchmarks primarily focus on evaluating whether SLMs
can perform complex tasks comparable to those tackled by large language models
(LLMs), often failing to align with how users naturally interact in real-world
conversational scenarios. In this paper, we propose TELEVAL, a dynamic
benchmark specifically designed to evaluate SLMs' effectiveness as
conversational agents in realistic Chinese interactive settings. TELEVAL
defines three evaluation dimensions: Explicit Semantics, Paralinguistic and
Implicit Semantics, and System Abilities. It adopts a dialogue format
consistent with real-world usage and evaluates text and audio outputs
separately. TELEVAL particularly focuses on the model's ability to extract
implicit cues from user speech and respond appropriately without additional
instructions. Our experiments demonstrate that despite recent progress,
existing SLMs still have considerable room for improvement in natural
conversational tasks. We hope that TELEVAL can serve as a user-centered
evaluation framework that directly reflects the user experience and contributes
to the development of more capable dialogue-oriented SLMs.

</details>


### [105] [Hybrid and Unitary Fine-Tuning of Large Language Models: Methods and Benchmarking under Resource Constraints](https://arxiv.org/abs/2507.18076)
*Haomin Qi,Zihan Dai,Chengbo Huang*

Main category: cs.CL

TL;DR: 通过结合BOFT和LoRA-GA的优点，并引入uRNN，提出了一种新的混合微调方法，在效率和性能上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 微调大型语言模型（LLMs）由于其规模和内存需求，仍然是一个计算瓶颈。

Method: 提出了一种新的混合策略，该策略将BOFT的正交稳定性和LoRA-GA的梯度对齐快速收敛动态集成起来。通过计算由梯度范数引导的每层自适应更新，该混合方法在收敛效率和跨不同任务的泛化能力方面均表现出色。首次探索了将单位RNN（uRNN）原理应用于基于Transformer的大型语言模型，通过结构化单位约束来增强梯度稳定性。

Result: 在GLUE、GSM8K、MT-Bench和HumanEval四个基准上，使用7B到405B参数的模型进行实证评估，结果表明该混合方法持续优于单独的PEFT基线，在训练时间和内存使用量方面分别减少了2.1倍和50%，同时达到了接近完全微调的准确率。

Conclusion: 该混合方法作为一种实用且可扩展的微调解决方案，可在资源受限的情况下实际部署大型语言模型。

Abstract: Fine-tuning large language models (LLMs) remains a computational bottleneck
due to their scale and memory demands. This paper presents a comprehensive
evaluation of parameter-efficient fine-tuning (PEFT) techniques, including
LoRA, BOFT, LoRA-GA, and uRNN, and introduces a novel hybrid strategy that
dynamically integrates BOFT's orthogonal stability with LoRA-GA's
gradient-aligned rapid convergence. By computing per-layer adaptive updates
guided by gradient norms, the hybrid method achieves superior convergence
efficiency and generalization across diverse tasks. We also explore, for the
first time, the adaptation of unitary RNN (uRNN) principles to
transformer-based LLMs, enhancing gradient stability through structured unitary
constraints. Empirical evaluations on four benchmarks -- GLUE, GSM8K, MT-Bench,
and HumanEval -- using models ranging from 7B to 405B parameters demonstrate
that our hybrid method consistently outperforms individual PEFT baselines,
approaching full fine-tuning accuracy while reducing resource consumption by up
to 2.1 times in training time and 50 percent in memory usage. These findings
establish the hybrid approach as a practical and scalable fine-tuning solution
for real-world deployment of LLMs under resource constraints.

</details>


### [106] [A New Pair of GloVes](https://arxiv.org/abs/2507.18103)
*Riley Carlson,John Bauer,Christopher D. Manning*

Main category: cs.CL

TL;DR: New 2024 GloVe models trained on updated data show improved performance on recent NER tasks while maintaining comparable results on other tasks.


<details>
  <summary>Details</summary>
Motivation: To update the original 2014 GloVe models to reflect language and world evolution, and to carefully document the data versions and preprocessing used.

Method: Trained two sets of word embeddings using Wikipedia, Gigaword, and a subset of Dolma. Evaluated through vocabulary comparison, direct testing, and NER tasks.

Result: The 2024 GloVe models incorporate new culturally and linguistically relevant words, perform comparably on analogy and similarity tasks, and demonstrate improved performance on recent, temporally dependent NER datasets.

Conclusion: The 2024 GloVe models incorporate new words, perform comparably on structural tasks, and show improved performance on recent, temporally dependent NER datasets.

Abstract: This report documents, describes, and evaluates new 2024 English GloVe
(Global Vectors for Word Representation) models. While the original GloVe
models built in 2014 have been widely used and found useful, languages and the
world continue to evolve and we thought that current usage could benefit from
updated models. Moreover, the 2014 models were not carefully documented as to
the exact data versions and preprocessing that were used, and we rectify this
by documenting these new models. We trained two sets of word embeddings using
Wikipedia, Gigaword, and a subset of Dolma. Evaluation through vocabulary
comparison, direct testing, and NER tasks shows that the 2024 vectors
incorporate new culturally and linguistically relevant words, perform
comparably on structural tasks like analogy and similarity, and demonstrate
improved performance on recent, temporally dependent NER datasets such as
non-Western newswire data.

</details>


### [107] [GOAT-SLM: A Spoken Language Model with Paralinguistic and Speaker Characteristic Awareness](https://arxiv.org/abs/2507.18119)
*Hongjie Chen,Zehan Li,Yaodong Song,Wenming Deng,Yitong Yao,Yuxin Zhang,Hang Lv,Xuechao Zhu,Jian Kang,Jie Lian,Jie Li,Chao Wang,Shuangyong Song,Yongxiang Li,Zhongjiang He*

Main category: cs.CL

TL;DR: GOAT-SLM 是一个具有副语言和说话人特征意识的新型口语模型，可以进行更自然、更具适应性和更具社会意识的口语交互。


<details>
  <summary>Details</summary>
Motivation: 大多数现有模型将语音仅仅视为语言内容的载体，忽略了人类语音中嵌入的丰富的副语言和说话人特征线索，如方言、年龄、情绪和非语音发声。因此，本研究提出了 GOAT-SLM，一个具有副语言和说话人特征意识的新型口语模型，旨在将口语建模扩展到文本语义之外。

Method: GOAT-SLM 采用双模态头部架构，将语言建模与声学实现分离，实现了强大的语言理解能力，同时支持富有表现力和自适应的语音生成。为了提高模型效率和通用性，我们提出了一种模块化、分阶段的训练策略，利用大规模的语音-文本语料库逐步对齐语言、副语言和说话人特征信息。

Result: 在 TELEVAL（一个多维度评估基准）上的实验结果表明，GOAT-SLM 在语义和非语义任务上都取得了均衡的性能，并且在处理情绪、方言变异和年龄敏感交互方面优于现有的开源模型。

Conclusion: GOAT-SLM 的工作强调了超越语言内容进行建模的重要性，并推动了更自然、更具适应性和更具社会意识的口语系统的发展。

Abstract: Recent advances in end-to-end spoken language models (SLMs) have
significantly improved the ability of AI systems to engage in natural spoken
interactions. However, most existing models treat speech merely as a vehicle
for linguistic content, often overlooking the rich paralinguistic and speaker
characteristic cues embedded in human speech, such as dialect, age, emotion,
and non-speech vocalizations. In this work, we introduce GOAT-SLM, a novel
spoken language model with paralinguistic and speaker characteristic awareness,
designed to extend spoken language modeling beyond text semantics. GOAT-SLM
adopts a dual-modality head architecture that decouples linguistic modeling
from acoustic realization, enabling robust language understanding while
supporting expressive and adaptive speech generation. To enhance model
efficiency and versatility, we propose a modular, staged training strategy that
progressively aligns linguistic, paralinguistic, and speaker characteristic
information using large-scale speech-text corpora. Experimental results on
TELEVAL, a multi-dimensional evaluation benchmark, demonstrate that GOAT-SLM
achieves well-balanced performance across both semantic and non-semantic tasks,
and outperforms existing open-source models in handling emotion, dialectal
variation, and age-sensitive interactions. This work highlights the importance
of modeling beyond linguistic content and advances the development of more
natural, adaptive, and socially aware spoken language systems.

</details>


### [108] [MathOPEval: A Fine-grained Evaluation Benchmark for Visual Operations of MLLMs in Mathematical Reasoning](https://arxiv.org/abs/2507.18140)
*Xiaoyuan Li,Moxin Li,Wenjie Wang,Rui Men,Yichang Zhang,Fuli Feng,Dayiheng Liu,Junyang Lin*

Main category: cs.CL

TL;DR: 本研究评估了多模态大语言模型（MLLM）在多模态数学推理中基于代码执行视觉操作的能力，提出了多模态代码生成（MCG）和多模态代码编辑（MCE）的评估框架，并使用包含五种数学图形的数据集进行了实验。结果显示，现有 MLLM 在细粒度视觉操作上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有评估主要关注纯文本推理，但 MLLM 通过代码执行准确的视觉操作的能力在很大程度上仍未被探索。本工作旨在弥补这一差距，评估 MLLM 在多模态数学推理中基于代码的能力。

Method: 本研究提出一个框架，包含两个关键评估方面：(1) 多模态代码生成 (MCG)，评估模型从头开始准确理解和构建可视化的能力；(2) 多模态代码编辑 (MCE)，评估模型进行细粒度操作（包括删除、修改和注释）的能力。同时，构建了一个包含五种最流行数学图形的数据集（几何图、函数图和三种统计图），以全面有效地评估现有 MLLM。

Result: 通过对九种主流 MLLM 进行实验评估，结果表明现有模型在执行细粒度视觉操作方面仍显著落后于人类表现。

Conclusion: 现有模型在执行细粒度视觉操作方面仍远未达到人类水平。

Abstract: Recent progress in Multi-modal Large Language Models (MLLMs) has enabled
step-by-step multi-modal mathematical reasoning by performing visual operations
based on the textual instructions. A promising approach uses code as an
intermediate representation to precisely express and manipulate the images in
the reasoning steps. However, existing evaluations focus mainly on text-only
reasoning outputs, leaving the MLLM's ability to perform accurate visual
operations via code largely unexplored. This work takes a first step toward
addressing that gap by evaluating MLLM's code-based capabilities in multi-modal
mathematical reasoning.Specifically, our framework focuses on two key
evaluation aspects: (1) Multi-modal Code Generation (MCG) evaluates the model's
ability to accurately understand and construct visualizations from scratch. (2)
Multi-modal Code Editing (MCE) assesses the model's capacity for fine-grained
operations, which include three types: Deletion, Modification and Annotation.
To evaluate the above tasks, we incorporate a dataset that covers the five most
popular types of mathematical figures, including geometric diagrams, function
plots, and three types of statistical charts, to provide a comprehensive and
effective measurement of existing MLLMs. Our experimental evaluation involves
nine mainstream MLLMs, and the results reveal that existing models still lag
significantly behind human performance in performing fine-grained visual
operations.

</details>


### [109] [HIVMedQA: Benchmarking large language models for HIV medical decision support](https://arxiv.org/abs/2507.18143)
*Gonzalo Cardenal Antolin,Jacques Fellay,Bashkim Jaha,Roger Kouyos,Niko Beerenwinkel,Diane Duroux*

Main category: cs.CL

TL;DR: LLM在HIV管理中的应用：Gemini 2.5 Pro表现最佳，但仍需克服复杂问题和认知偏差的挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在临床决策支持方面显示出潜力，但其在HIV管理中的应用仍未得到充分探索，相关基准研究也十分有限。本研究旨在评估LLM在HIV管理方面的能力、优势和局限性。

Method: 研究人员开发了一个名为HIVMedQA的基准数据集，包含临床相关的HIV管理问题，并与七个通用LLM和三个专业LLM进行了评估。评估框架结合了词汇相似性和LLM-as-a-judge方法，并考察了问题理解、推理、知识回忆、偏见、潜在危害和事实准确性等方面。

Result: Gemini 2.5 Pro在大多数评估维度上表现优于其他模型，但两个顶级模型是专有的。随着问题复杂度的增加，模型性能会下降。经过医学微调的模型不一定优于通用模型，模型规模并非性能的可靠预测指标。推理和理解比事实回忆更具挑战性，并且观察到诸如新近度效应和现状偏见等认知偏差。

Conclusion: LLM在HIV管理中的应用仍需进一步研究和开发，以确保其安全有效性。当前的LLM在理解、推理和认知偏差方面存在局限性，并且在复杂问题上的表现会下降。

Abstract: Large language models (LLMs) are emerging as valuable tools to support
clinicians in routine decision-making. HIV management is a compelling use case
due to its complexity, including diverse treatment options, comorbidities, and
adherence challenges. However, integrating LLMs into clinical practice raises
concerns about accuracy, potential harm, and clinician acceptance. Despite
their promise, AI applications in HIV care remain underexplored, and LLM
benchmarking studies are scarce. This study evaluates the current capabilities
of LLMs in HIV management, highlighting their strengths and limitations. We
introduce HIVMedQA, a benchmark designed to assess open-ended medical question
answering in HIV care. The dataset consists of curated, clinically relevant
questions developed with input from an infectious disease physician. We
evaluated seven general-purpose and three medically specialized LLMs, applying
prompt engineering to enhance performance. Our evaluation framework
incorporates both lexical similarity and an LLM-as-a-judge approach, extended
to better reflect clinical relevance. We assessed performance across key
dimensions: question comprehension, reasoning, knowledge recall, bias,
potential harm, and factual accuracy. Results show that Gemini 2.5 Pro
consistently outperformed other models across most dimensions. Notably, two of
the top three models were proprietary. Performance declined as question
complexity increased. Medically fine-tuned models did not always outperform
general-purpose ones, and larger model size was not a reliable predictor of
performance. Reasoning and comprehension were more challenging than factual
recall, and cognitive biases such as recency and status quo were observed.
These findings underscore the need for targeted development and evaluation to
ensure safe, effective LLM integration in clinical care.

</details>


### [110] [Sticking to the Mean: Detecting Sticky Tokens in Text Embedding Models](https://arxiv.org/abs/2507.18171)
*Kexin Chen,Dongxia Wang,Yi Liu,Haonan Zhang,Wenhai Wang*

Main category: cs.CL

TL;DR: Transformer模型存在“粘滞词元”问题，会降低模型性能。研究发现了868个此类词元，它们主要来自特殊或碎片化词汇，并可能导致高达50%的性能下降。需要改进词元化策略和模型设计来解决此问题。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer类文本嵌入模型在自然语言处理任务中得到广泛应用，但令人惊讶的“粘滞词元”现象可能会破坏嵌入的可靠性。这些词元在句子中反复插入时，会将句子的相似度拉向某个特定值，从而扰乱嵌入距离的正常分布并降低下游任务的性能。因此，有必要系统地研究这些异常词元，定义它们，并开发检测方法，以了解其影响并提出缓解策略。

Method: 本研究首先系统地研究了Transformer类文本嵌入模型中存在的“粘滞词元”现象，并对其进行了形式化定义。接着，研究引入了一种基于句子和词元过滤的高效检测方法——粘滞词元检测器（STD）。该方法被应用于14个模型家族的40个检查点，以发现粘滞词元。随后，研究对发现的粘滞词元进行了分析，探讨了其来源以及与模型大小和词汇表大小的关系。此外，研究还评估了粘滞词元对聚类和检索等下游任务的影响，并通过注意力层分析来探究其在模型内部表征中的作用。

Result: 研究发现了868个粘滞词元，这些词元通常来源于词汇表中的特殊或未使用条目，以及多语言语料库中的碎片化子词。粘滞词元的存在并不严格与模型大小或词汇表大小相关。在下游任务（如聚类和检索）中，粘滞词元的存在会导致高达50%的性能下降。注意力层分析显示，粘滞词元不成比例地主导了模型的内部表征。

Conclusion: 本研究揭示了Transformer类文本嵌入模型中存在的“粘滞词元”现象，该现象会破坏词元嵌入的可靠性并影响下游任务的性能。研究提出了一个名为粘滞词元检测器（STD）的高效检测方法，并通过对14个模型家族的40个检查点进行分析，发现了868个粘滞词元。这些词元通常来源于词汇表中的特殊或未使用条目，以及多语言语料库中的碎片化子词。研究还发现粘滞词元的存在与模型大小或词汇表大小没有严格相关性，并观察到它们会对聚类和检索等下游任务造成高达50%的性能下降。通过注意力层分析，研究表明粘滞词元不成比例地主导了模型的内部表征，这引发了对词元化鲁棒性的担忧。研究结果强调了在未来的文本嵌入应用中，需要更好的词元化策略和模型设计来减轻粘滞词元的影响。

Abstract: Despite the widespread use of Transformer-based text embedding models in NLP
tasks, surprising 'sticky tokens' can undermine the reliability of embeddings.
These tokens, when repeatedly inserted into sentences, pull sentence similarity
toward a certain value, disrupting the normal distribution of embedding
distances and degrading downstream performance. In this paper, we
systematically investigate such anomalous tokens, formally defining them and
introducing an efficient detection method, Sticky Token Detector (STD), based
on sentence and token filtering. Applying STD to 40 checkpoints across 14 model
families, we discover a total of 868 sticky tokens. Our analysis reveals that
these tokens often originate from special or unused entries in the vocabulary,
as well as fragmented subwords from multilingual corpora. Notably, their
presence does not strictly correlate with model size or vocabulary size. We
further evaluate how sticky tokens affect downstream tasks like clustering and
retrieval, observing significant performance drops of up to 50%. Through
attention-layer analysis, we show that sticky tokens disproportionately
dominate the model's internal representations, raising concerns about
tokenization robustness. Our findings show the need for better tokenization
strategies and model design to mitigate the impact of sticky tokens in future
text embedding applications.

</details>


### [111] [SCOPE: Stochastic and Counterbiased Option Placement for Evaluating Large Language Models](https://arxiv.org/abs/2507.18182)
*Wonjun Jeong,Dongseok Kim,Taegkeun Whangbo*

Main category: cs.CL

TL;DR: SCOPE 框架通过消除选择偏倚来提高 LLM 在多项选择任务中的评估公平性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）可以通过利用选项位置或标签中固有的偏见，在多项选择任务中获得虚高的分数，而不是展示真正的理解能力。本研究引入 SCOPE 评估框架，旨在以独立于数据集的方式衡量和减轻这种选择偏倚。

Method: SCOPE 通过反复调用缺乏语义内容的空提示来估计模型的独特位置偏倚分布，然后根据逆偏倚分布重新分配答案槽，从而使随机选择正确答案的概率（幸运率）均衡化。此外，它还阻止了语义相似的干扰项与答案相邻放置，以阻止基于表面接近线索的近乎完美的猜测。

Result: SCOPE 框架在多个基准实验中，在稳定的性能提升和更清晰的正确选项置信度分布方面，持续优于现有的去偏方法。

Conclusion: SCOPE 提供了一个新的框架，用于增强 LLM 评估的公平性和可靠性，并在多个基准实验中表现出优于现有去偏方法的性能。

Abstract: Large Language Models (LLMs) can achieve inflated scores on multiple-choice
tasks by exploiting inherent biases in option positions or labels, rather than
demonstrating genuine understanding. This study introduces SCOPE, an evaluation
framework designed to measure and mitigate such selection bias in a
dataset-independent manner. By repeatedly invoking a null prompt that lacks
semantic content, SCOPE estimates each model's unique position-bias
distribution. It then redistributes the answer slot according to the
inverse-bias distribution, thereby equalizing the lucky-rate, the probability
of selecting the correct answer by chance. Furthermore, it prevents
semantically similar distractors from being placed adjacent to the answer,
thereby blocking near-miss guesses based on superficial proximity cues. Across
multiple benchmark experiments, SCOPE consistently outperformed existing
debiasing methods in terms of stable performance improvements and showed
clearer confidence distributions over correct options. This framework thus
offers a new standard for enhancing the fairness and reliability of LLM
evaluations.

</details>


### [112] [TN-AutoRCA: Benchmark Construction and Agentic Framework for Self-Improving Alarm-Based Root Cause Analysis in Telecommunication Networks](https://arxiv.org/abs/2507.18190)
*Keyu Wu,Qianjin Yu,Manlin Mei,Ruiting Liu,Jun Wang,Kailai Zhang,Yelun Bao*

Main category: cs.CL

TL;DR: AI struggles with Root Cause Analysis in telecom networks because of complex reasoning and limited benchmarks.


<details>
  <summary>Details</summary>
Motivation: The abstract highlights the critical importance of Root Cause Analysis (RCA) in telecommunication networks and the significant challenges AI faces in performing this task due to complex graph-based reasoning and a lack of realistic benchmarks.

Method: None

Result: None

Conclusion: None

Abstract: Root Cause Analysis (RCA) in telecommunication networks is a critical task,
yet it presents a formidable challenge for Artificial Intelligence (AI) due to
its complex, graph-based reasoning requirements and the scarcity of realistic
benchmarks.

</details>


### [113] [Integrating an ISO30401-compliant Knowledge management system with existing business processes of an organization](https://arxiv.org/abs/2507.18197)
*Aline Belloni,Patrick Prieur*

Main category: cs.CL

TL;DR: 本文讨论了如何在PDCA周期中，利用SECI模型将ISO30401知识管理体系整合到ISO9001等现有管理体系中。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决“ISO30401实施者”在向客户解释ISO30401中描述的知识开发、转化和传递活动如何与现有运营流程相结合时面临的挑战。

Method: 本文结合了流程建模原则，特别是ISO9001背景下的建模方法，并探索了基于SECI模型在PDCA循环中实施ISO30401知识管理体系。

Result: 本文通过案例分析和实践经验，阐述了ISO30401知识管理系统如何与整合管理系统的其他流程（如ISO9001）相融合，并提出了具体的实施方法。

Conclusion: 本文基于作者的实践经验，探讨了符合ISO30401标准的知识管理系统（KMS）如何与整合管理系统（IMS）的其他流程相结合，并提出通过运用SECI模型机制在PDCA循环的各个阶段来实施KMS。

Abstract: Business process modeling is used by most organizations as an essential
framework for ensuring efficiency and effectiveness of the work and workflow
performed by its employees and for ensuring the alignment of such work with its
strategic goals. For organizations that are compliant or near-compliant with
ISO 9001, this approach involves the detailed mapping of processes,
sub-processes, activities, and tasks. ISO30401 is a Management System Standard,
introduced in 2018, establishing universal requirements for the set up of a
Knowledge Management System in an organization. As ``ISO30401 implementers'' we
regularly face the challenge of explaining our clients how the knowledge
development, transformation and conveyances activities depicted in ISO30401 do
integrate with existing operational processes. This article recaps process
modelling principles in the context of ISO9001 and explores, based on our
experience, how an ISO30401-compliant Knowledge Management System (KMS)
entwines with all other processes of an Integrated Management System and in
particular how it can be implemented by deploying the mechanisms of the SECI
model through the steps of PDCA cycles.

</details>


### [114] [Safeguarding RAG Pipelines with GMTP: A Gradient-based Masked Token Probability Method for Poisoned Document Detection](https://arxiv.org/abs/2507.18202)
*San Kim,Jonghwi Kim,Yejin Jeon,Gary Geunbae Lee*

Main category: cs.CL

TL;DR: GMTP是一种新的防御方法，通过分析梯度和掩码标记概率来检测和过滤RAG知识库中的恶意文档，有效解决了RAG的安全风险。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）虽然能增强大型语言模型（LLM）的能力，但其对外部知识库的依赖性带来了安全风险，攻击者可能注入恶意文档来操纵模型输出。

Method: GMTP方法通过检查检索器相似性函数的梯度来识别高影响力标记，然后通过掩码语言模型（MLM）检查这些关键标记的掩码标记概率，以检测恶意文档。

Result: GMTP能够消除超过90%的污染内容，同时保留相关文档，在各种数据集和对抗性设置中保持了强大的检索和生成性能。

Conclusion: 提出了一种名为梯度掩码标记概率（GMTP）的新型防御方法，用于检测和过滤对抗性攻击的注入文档，实验证明该方法能有效消除超过90%的污染内容，同时保留相关文档，从而在各种数据集和对抗性设置中保持强大的检索和生成性能。

Abstract: Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by
providing external knowledge for accurate and up-to-date responses. However,
this reliance on external sources exposes a security risk, attackers can inject
poisoned documents into the knowledge base to steer the generation process
toward harmful or misleading outputs. In this paper, we propose Gradient-based
Masked Token Probability (GMTP), a novel defense method to detect and filter
out adversarially crafted documents. Specifically, GMTP identifies high-impact
tokens by examining gradients of the retriever's similarity function. These key
tokens are then masked, and their probabilities are checked via a Masked
Language Model (MLM). Since injected tokens typically exhibit markedly low
masked-token probabilities, this enables GMTP to easily detect malicious
documents and achieve high-precision filtering. Experiments demonstrate that
GMTP is able to eliminate over 90% of poisoned content while retaining relevant
documents, thus maintaining robust retrieval and generation performance across
diverse datasets and adversarial settings.

</details>


### [115] [Exploring the Impact of Instruction-Tuning on LLM's Susceptibility to Misinformation](https://arxiv.org/abs/2507.18203)
*Kyubeen Han,Junseo Jang,Hongjin Kim,Geunyeong Jeong,Harksoo Kim*

Main category: cs.CL

TL;DR: Instruction-tuning makes LLMs more likely to believe user-provided misinformation.


<details>
  <summary>Details</summary>
Motivation: While instruction-tuning enhances LLM usability, it may increase dependence on user input, leading to the acceptance of misinformation. Little research has directly studied the impact of instruction-tuning on this phenomenon.

Method: Investigated the impact of instruction-tuning on LLM susceptibility to misinformation through comparative analysis with base models, exploring factors like user role, misinformation length, and warnings.

Result: Instruction-tuned LLMs are significantly more likely to accept misinformation presented by users compared to base models, indicating an increased reliance on user-provided information.

Conclusion: Instruction-tuning improves LLM usability but increases susceptibility to misinformation by making models more reliant on user input, shifting the burden of verification from the model to the user. Further research is needed to mitigate these unintended consequences.

Abstract: Instruction-tuning enhances the ability of large language models (LLMs) to
follow user instructions more accurately, improving usability while reducing
harmful outputs. However, this process may increase the model's dependence on
user input, potentially leading to the unfiltered acceptance of misinformation
and the generation of hallucinations. Existing studies primarily highlight that
LLMs are receptive to external information that contradict their parametric
knowledge, but little research has been conducted on the direct impact of
instruction-tuning on this phenomenon. In our study, we investigate the impact
of instruction-tuning on LLM's susceptibility to misinformation. Our analysis
reveals that instruction-tuned LLMs are significantly more likely to accept
misinformation when it is presented by the user. A comparison with base models
shows that instruction-tuning increases reliance on user-provided information,
shifting susceptibility from the assistant role to the user role. Furthermore,
we explore additional factors influencing misinformation susceptibility, such
as the role of the user in prompt structure, misinformation length, and the
presence of warnings in the system prompt. Our findings underscore the need for
systematic approaches to mitigate unintended consequences of instruction-tuning
and enhance the reliability of LLMs in real-world applications.

</details>


### [116] [Prune&Comp: Free Lunch for Layer-Pruned LLMs via Iterative Pruning with Magnitude Compensation](https://arxiv.org/abs/2507.18212)
*Xinrui Chen,Hongxing Zhang,Fanyi Zeng,Yongxian Wei,Yizhi Wang,Xitong Ling,Guanghao Li,Chun Yuan*

Main category: cs.CL

TL;DR: Prune&Comp是一种训练前、零开销的层剪枝技术，通过补偿隐藏状态中的幅度间隙来提高LLM性能，在LLaMA-3-8B上的实验结果表明其有效性。


<details>
  <summary>Details</summary>
Motivation: 识别并解决移除任何层都会在隐藏状态中引起显著的幅度间隙，从而导致性能大幅下降的问题。

Method: Prune&Comp通过离线重新缩放剩余权重来估计和消除层移除引起的幅度间隙，从而实现训练前和零运行时开销。

Result: Prune&Comp在LLaMA-3-8B上实现了近乎减半的困惑度，并保留了93.19%的原始模型问答性能，优于基线4.01%。

Conclusion: Prune&Comp是一种新颖的即插即用型层剪枝方案，通过在训练前以零运行时开销进行幅度补偿来解决层移除引起的隐藏状态幅度间隙问题。当与迭代剪枝和补偿循环结合时，Prune&Comp可提高现有层剪枝指标的性能，例如，在LLaMA-3-8B上剪枝5层时，困惑度几乎减半，并保留93.19%的原始模型问答性能。

Abstract: Layer pruning has emerged as a promising technique for compressing large
language models (LLMs) while achieving acceleration proportional to the pruning
ratio. In this work, we identify that removing any layer induces a significant
magnitude gap in hidden states, resulting in substantial performance
degradation. To address this issue, we propose Prune&Comp, a novel
plug-and-play layer pruning scheme that leverages magnitude compensation to
mitigate such gaps in a training-free manner. Specifically, we first estimate
the magnitude gap caused by layer removal and then eliminate this gap by
rescaling the remaining weights offline, with zero runtime overhead incurred.
We further demonstrate the advantages of Prune&Comp through an iterative
pruning strategy. When integrated with an iterative prune-and-compensate loop,
Prune&Comp consistently enhances existing layer pruning metrics. For instance,
when 5 layers of LLaMA-3-8B are pruned using the prevalent block influence
metric, Prune&Comp nearly halves the perplexity and retains 93.19\% of the
original model's question-answering performance, outperforming the baseline by
4.01%.

</details>


### [117] [Locate-and-Focus: Enhancing Terminology Translation in Speech Language Models](https://arxiv.org/abs/2507.18263)
*Suhang Wu,Jialong Tang,Chengyi Yang,Pei Zhang,Baosong Yang,Junhui Li,Junfeng Yao,Min Zhang,Jinsong Su*

Main category: cs.CL

TL;DR: 一种新的语音翻译方法，通过定位和聚焦术语来提高翻译的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前直接语音翻译（ST）在术语翻译方面存在挑战，现有方法在利用翻译知识时会受到无关噪声的干扰，且未能充分利用翻译知识。

Method: 提出了一种新颖的定位与聚焦（Locate-and-Focus）方法，首先定位包含术语的语音片段以构建翻译知识，从而最小化对语音翻译模型的不相关信息干扰；然后，将翻译知识与音频和文本模态的语音内容及假设进行关联，使模型在翻译过程中更好地聚焦于翻译知识。

Result: 实验结果表明，所提出的方法能够有效定位语音中的术语，并提高术语翻译的成功率，同时保持了鲁棒的通用翻译性能。

Conclusion: 本研究提出的定位与聚焦方法有效解决了语音翻译中术语翻译的挑战，通过最小化无关信息和多模态关联，提高了术语翻译的成功率，同时保持了鲁棒的通用翻译性能。

Abstract: Direct speech translation (ST) has garnered increasing attention nowadays,
yet the accurate translation of terminology within utterances remains a great
challenge. In this regard, current studies mainly concentrate on leveraging
various translation knowledge into ST models. However, these methods often
struggle with interference from irrelevant noise and can not fully utilize the
translation knowledge. To address these issues, in this paper, we propose a
novel Locate-and-Focus method for terminology translation. It first effectively
locates the speech clips containing terminologies within the utterance to
construct translation knowledge, minimizing irrelevant information for the ST
model. Subsequently, it associates the translation knowledge with the utterance
and hypothesis from both audio and textual modalities, allowing the ST model to
better focus on translation knowledge during translation. Experimental results
across various datasets demonstrate that our method effectively locates
terminologies within utterances and enhances the success rate of terminology
translation, while maintaining robust general translation performance.

</details>


### [118] [Zero-shot OCR Accuracy of Low-Resourced Languages: A Comparative Analysis on Sinhala and Tamil](https://arxiv.org/abs/2507.18264)
*Nevidu Jayatilleke,Nisansa de Silva*

Main category: cs.CL

TL;DR: 研究评估了六种OCR引擎在Sinhala和Tamil上的零样本性能。Surya在Sinhala上表现最佳，Document AI在Tamil上表现最佳。引入了一个新的合成Tamil OCR基准数据集。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言（LRL）的光学字符识别（OCR）问题，特别是使用独特脚本的语言，仍然是一个开放性问题。

Method: 本研究对六种不同的OCR引擎（Cloud Vision API、Surya、Document AI、Tesseract、Subasa OCR和EasyOCR）在Sinhala和Tamil这两种低资源语言上的零样本性能进行了比较分析。

Result: Surya在Sinhala上表现最好，词错误率（WER）为2.61%。Document AI在Tamil上表现最好，字符错误率（CER）为0.78%。此外，还引入了一个新的合成Tamil OCR基准数据集。

Conclusion: Surya在Sinhala的OCR表现最佳，而Document AI在Tamil的OCR表现最佳。

Abstract: Solving the problem of Optical Character Recognition (OCR) on printed text
for Latin and its derivative scripts can now be considered settled due to the
volumes of research done on English and other High-Resourced Languages (HRL).
However, for Low-Resourced Languages (LRL) that use unique scripts, it remains
an open problem. This study presents a comparative analysis of the zero-shot
performance of six distinct OCR engines on two LRLs: Sinhala and Tamil. The
selected engines include both commercial and open-source systems, aiming to
evaluate the strengths of each category. The Cloud Vision API, Surya, Document
AI, and Tesseract were evaluated for both Sinhala and Tamil, while Subasa OCR
and EasyOCR were examined for only one language due to their limitations. The
performance of these systems was rigorously analysed using five measurement
techniques to assess accuracy at both the character and word levels. According
to the findings, Surya delivered the best performance for Sinhala across all
metrics, with a WER of 2.61%. Conversely, Document AI excelled across all
metrics for Tamil, highlighted by a very low CER of 0.78%. In addition to the
above analysis, we also introduce a novel synthetic Tamil OCR benchmarking
dataset.

</details>


### [119] [StyleAdaptedLM: Enhancing Instruction Following Models with Efficient Stylistic Transfer](https://arxiv.org/abs/2507.18294)
*Pritika Ramu,Apoorv Saxena,Meghanath M Y,Varsha Sankar,Debraj Basu*

Main category: cs.CL

TL;DR: StyleAdaptedLM是一个使用LoRA将风格特征有效迁移到指令遵循模型中的框架，无需配对数据即可实现风格定制，并保持指令遵循能力。


<details>
  <summary>Details</summary>
Motivation: 在企业沟通中，将大型语言模型（LLM）适配到特定的风格特征（如品牌声音或作者语气）非常重要，但从缺乏指令-响应格式的语料库中实现这一点具有挑战性，并且可能影响指令遵循能力。

Method: StyleAdaptedLM框架使用LoRA技术，在包含非结构化风格语料库的基础模型上训练LoRA适配器，然后将这些适配器合并到指令遵循模型中，以实现风格迁移。

Result: 实验表明，StyleAdaptedLM在保持指令遵循能力的同时，提高了风格一致性，并且人类评估证实了其在品牌特定惯例采纳方面的有效性。

Conclusion: StyleAdaptedLM提供了一种有效的方法，可以在不影响指令遵循能力的情况下，通过LoRA将风格特征转移到指令遵循模型中，从而实现LLM的风格个性化。

Abstract: Adapting LLMs to specific stylistic characteristics, like brand voice or
authorial tones, is crucial for enterprise communication but challenging to
achieve from corpora which lacks instruction-response formatting without
compromising instruction adherence. We introduce StyleAdaptedLM, a framework
that efficiently transfers stylistic traits to instruction-following models
using Low-Rank Adaptation (LoRA). LoRA adapters are first trained on a base
model with diverse unstructured stylistic corpora, then merged with a separate
instruction-following model. This enables robust stylistic customization
without paired data or sacrificing task performance. Experiments across
multiple datasets and models demonstrate improved stylistic consistency while
preserving instruction adherence, with human evaluations confirming
brand-specific convention uptake. StyleAdaptedLM offers an efficient path for
stylistic personalization in LLMs.

</details>


### [120] [BadReasoner: Planting Tunable Overthinking Backdoors into Large Reasoning Models for Fun or Profit](https://arxiv.org/abs/2507.18305)
*Biao Yi,Zekun Fei,Jianing Geng,Tong Li,Lihai Nie,Zheli Liu,Yiming Li*

Main category: cs.CL

TL;DR: 提出了一种针对大型推理模型（LRMs）的新型“过度思考后门”攻击，该攻击通过数据中毒和可控触发器（重复次数）来精确控制模型推理的详细程度，并在不影响答案正确性的前提下，显著增加推理过程的长度。


<details>
  <summary>Details</summary>
Motivation: 识别出一种针对大型推理模型（LRMs）的、以前未被探索的攻击向量，称为“过度思考后门”，并提出一种可控的后门，能够精确控制模型推理的详细程度。

Method: 提出了一种新颖的可调后门攻击，通过数据中毒和可调触发器（重复次数）实现，该触发器与相应冗长的推理过程配对，并通过指令教师LLM向正确的推理过程注入可控数量的冗余细化步骤来生成。

Result: 在各种LRMs上进行的广泛的经验性测试表明，该方法能够可靠地触发推理过程长度的可控、多重增加，同时不损害最终答案的正确性。

Conclusion: 该研究提出了一种可控的、多重提高推理过程长度的“过度思考后门”攻击方法，且不损害最终答案的正确性。

Abstract: Large reasoning models (LRMs) have emerged as a significant advancement in
artificial intelligence, representing a specialized class of large language
models (LLMs) designed to tackle complex reasoning tasks. The defining
characteristic of LRMs lies in their extensive chain-of-thought (CoT) reasoning
capabilities. In this paper, we identify a previously unexplored attack vector
against LRMs, which we term "overthinking backdoors". We advance this concept
by proposing a novel tunable backdoor, which moves beyond simple on/off attacks
to one where an attacker can precisely control the extent of the model's
reasoning verbosity. Our attack is implemented through a novel data poisoning
methodology. It pairs a tunable trigger-where the number of repetitions signals
the desired intensity-with a correspondingly verbose CoT response. These
responses are programmatically generated by instructing a teacher LLM to inject
a controlled number of redundant refinement steps into a correct reasoning
process. The approach preserves output correctness, which ensures stealth and
establishes the attack as a pure resource-consumption vector. Extensive
empirical results on various LRMs demonstrate that our method can reliably
trigger a controllable, multi-fold increase in the length of the reasoning
process, without degrading the final answer's correctness. Our source code is
available at https://github.com/FZaKK/BadReasoner.

</details>


### [121] [Uncertainty Quantification for Evaluating Machine Translation Bias](https://arxiv.org/abs/2507.18338)
*Ieva Raminta Staliūnaitė,Julius Cheng,Andreas Vlachos*

Main category: cs.CL

TL;DR: 机器翻译模型在处理性别信息时存在偏见，即使在目标语言需要区分性别而源语言不明确的情况下也是如此。我们发现，即使模型在性别明确的情况下表现良好，在性别模糊的情况下也可能无法准确地表达不确定性。此外，缓解模型偏见的方法对模糊和非模糊情况有不同的影响。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器翻译中模型性别偏见问题，并探究模型在处理性别模糊信息时的表现。

Method: 利用新提出的语义不确定性指标，评估MT模型在性别明确和模糊情况下的表现，并分析去偏处理对其影响。

Result: 高翻译和性别准确率的模型在性别模糊情况下不一定表现出预期的不确定性。去偏处理对模糊和非模糊翻译实例有独立影响。

Conclusion: MT模型在处理源语言中性别不明确但目标语言需要性别区分的词汇时，应在性别明确时进行准确翻译，在性别模糊时保持不确定性。研究发现，模型在性别模糊的情况下不一定表现出预期的不确定性，且去偏处理对模糊和非模糊情况有独立影响。

Abstract: In machine translation (MT), when the source sentence includes a lexeme whose
gender is not overtly marked, but whose target-language equivalent requires
gender specification, the model must infer the appropriate gender from the
context and/or external knowledge. Studies have shown that MT models exhibit
biased behaviour, relying on stereotypes even when they clash with contextual
information. We posit that apart from confidently translating using the correct
gender when it is evident from the input, models should also maintain
uncertainty about the gender when it is ambiguous. Using recently proposed
metrics of semantic uncertainty, we find that models with high translation and
gender accuracy on unambiguous instances do not necessarily exhibit the
expected level of uncertainty in ambiguous ones. Similarly, debiasing has
independent effects on ambiguous and unambiguous translation instances.

</details>


### [122] [TDR: Task-Decoupled Retrieval with Fine-Grained LLM Feedback for In-Context Learning](https://arxiv.org/abs/2507.18340)
*Yifu Chen,Bingchen Huang,Zhiling Wang,Yuanchao Du,Junfeng Luo,Lei Shen,Zhineng chen*

Main category: cs.CL

TL;DR: TDR是一个新的框架，通过解耦不同任务的ICL示例并利用LLM的细粒度反馈来改进示例检索，从而提高ICL的性能。


<details>
  <summary>Details</summary>
Motivation: ICL的有效性在很大程度上依赖于这些示例的质量，并且以往专注于增强示例检索能力的工作已经取得了令人瞩目的性能。然而，在检索高质量示例方面仍然存在两个挑战：(1)区分交叉任务数据分布的困难，(2)使检索器输出与LLM的反馈建立细粒度联系的困难。

Method: TDR框架将ICL示例与不同任务解耦，使检索模块能够从多任务数据集中检索特定于目标任务的示例。此外，TDR对LLM的细粒度反馈进行建模，以监督和指导检索模块的训练，这有助于检索高质量的示例。

Result: TDR在30个NLP任务的套件上进行了广泛的实验，结果表明TDR在所有数据集上持续改进结果，并取得了最先进的性能。

Conclusion: TDR是一个即插即用的框架，可以轻松地与各种LLM结合，以提高ICL的示例检索能力。在30个NLP任务的套件上进行的大量实验表明，TDR在所有数据集上持续改进结果，并取得了最先进的性能。

Abstract: In-context learning (ICL) has become a classic approach for enabling LLMs to
handle various tasks based on a few input-output examples. The effectiveness of
ICL heavily relies on the quality of these examples, and previous works which
focused on enhancing example retrieval capabilities have achieved impressive
performances. However, two challenges remain in retrieving high-quality
examples: (1) Difficulty in distinguishing cross-task data distributions, (2)
Difficulty in making the fine-grained connection between retriever output and
feedback from LLMs. In this paper, we propose a novel framework called TDR. TDR
decouples the ICL examples from different tasks, which enables the retrieval
module to retrieve examples specific to the target task within a multi-task
dataset. Furthermore, TDR models fine-grained feedback from LLMs to supervise
and guide the training of the retrieval module, which helps to retrieve
high-quality examples. We conducted extensive experiments on a suite of 30 NLP
tasks, the results demonstrate that TDR consistently improved results across
all datasets and achieves state-of-the-art performance. Meanwhile, our approach
is a plug-and-play method, which can be easily combined with various LLMs to
improve example retrieval abilities for ICL. The code is available at
https://github.com/Nnn-s/TDR.

</details>


### [123] [Hybrid Annotation for Propaganda Detection: Integrating LLM Pre-Annotations with Human Intelligence](https://arxiv.org/abs/2507.18343)
*Ariana Sahitaj,Premtim Sahitaj,Veronika Solopova,Jiaao Li,Sebastian Möller,Vera Schmitt*

Main category: cs.CL

TL;DR: 该研究通过结合人类标注和LLM辅助，提出了一种提高社交媒体宣传检测效率和准确性的新方法，并成功地将此方法应用于微调小型语言模型。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上的宣传检测任务复杂且高质量标注数据有限，这使得现有方法面临挑战。因此，本研究旨在提高宣传检测的一致性和可扩展性，以应对这些挑战。

Method: 本研究提出了一种结合人类专业知识和大型语言模型（LLM）辅助的框架，用于提高宣传检测的一致性和可扩展性。具体方法包括：1. 提出一个分层分类法，将14种细粒度宣传技术归纳为三个更广泛的类别。2. 在HQP数据集上进行人类标注研究，揭示了细粒度标签的标注者间一致性较低的问题。3. 实施一个LLM辅助的预标注流程，用于提取宣传性文本、生成简洁的解释，并分配局部标签和全局标签。4. 进行二次人类验证研究，以评估LLM辅助流程的改进效果。5. 利用知识蒸馏技术，使用LLM生成的高质量标注数据来微调更小的语言模型（SLMs），使其能够执行结构化标注。

Result: 研究结果表明，LLM辅助的预标注流程显著提高了人类标注者的一致性和时间效率。通过知识蒸馏，使用LLM生成的数据微调的SLMs能够有效执行结构化标注，为开发可扩展、鲁棒的宣传检测系统提供了可行方案。

Conclusion: 该研究提出了一种结合人类专业知识和大型语言模型（LLM）辅助的新颖框架，用于提高社交媒体上传播检测的一致性和可扩展性。通过分层分类法组织14种细粒度宣传技术，并在一项人类标注研究中发现细粒度标签的标注者间一致性较低。研究实施了一个LLM辅助的预标注流程，用于提取宣传性文本、生成解释并分配局部和全局标签。随后的二次人类验证研究表明，在一致性和效率方面都有显著的提高。在此基础上，通过知识蒸馏，让大型模型生成标注数据，然后用这些高质量的LLM生成的数据来微调更小的语言模型（SLMs）。该研究为开发可扩展、鲁棒的宣传检测系统做出了贡献，并支持了透明、负责任的媒体生态系统的理念，符合可持续发展目标16。代码已在GitHub上公开。

Abstract: Propaganda detection on social media remains challenging due to task
complexity and limited high-quality labeled data. This paper introduces a novel
framework that combines human expertise with Large Language Model (LLM)
assistance to improve both annotation consistency and scalability. We propose a
hierarchical taxonomy that organizes 14 fine-grained propaganda techniques into
three broader categories, conduct a human annotation study on the HQP dataset
that reveals low inter-annotator agreement for fine-grained labels, and
implement an LLM-assisted pre-annotation pipeline that extracts propagandistic
spans, generates concise explanations, and assigns local labels as well as a
global label. A secondary human verification study shows significant
improvements in both agreement and time-efficiency. Building on this, we
fine-tune smaller language models (SLMs) to perform structured annotation.
Instead of fine-tuning on human annotations, we train on high-quality
LLM-generated data, allowing a large model to produce these annotations and a
smaller model to learn to generate them via knowledge distillation. Our work
contributes towards the development of scalable and robust propaganda detection
systems, supporting the idea of transparent and accountable media ecosystems in
line with SDG 16. The code is publicly available at our GitHub repository.

</details>


### [124] [CLEAR: Error Analysis via LLM-as-a-Judge Made Easy](https://arxiv.org/abs/2507.18392)
*Asaf Yehudai,Lilach Eden,Yotam Perlitz,Roy Bar-Haim,Michal Shmueli-Scheuer*

Main category: cs.CL

TL;DR: CLEAR是一个开源工具，用于LLM评估中的错误分析。它通过生成反馈、识别问题和提供交互式仪表板来解释模型表现好坏的原因，而不仅仅是给出分数。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM评估范式通常只产生一个单一的分数或排名，无法解释模型表现好坏的原因。为了解决这个问题，需要一个能够深入分析模型具体、可操作的性能原因的工具。

Method: CLEAR首先生成逐实例的文本反馈，然后创建一个系统级错误问题集，并量化每个已识别问题的发生率。该包还提供了一个交互式仪表板，允许用户通过聚合可视化进行全面的错误分析，应用交互式过滤器来分离特定问题或分数范围，并深入研究例证特定行为模式的单个实例。

Result: CLEAR能够生成逐实例的文本反馈，识别系统级错误问题，并量化这些问题的发生率。交互式仪表板使用户能够通过可视化、过滤和深入分析来全面理解LLM的错误模式。

Conclusion: CLEAR填补了LLM评估中“是什么”到“为什么”的空白，提供了一个可扩展的、基于LLM的错误分析框架，并展示了其在RAG和数学基准上的实用性。

Abstract: The evaluation of Large Language Models (LLMs) increasingly relies on other
LLMs acting as judges. However, current evaluation paradigms typically yield a
single score or ranking, answering which model is better but not why. While
essential for benchmarking, these top-level scores obscure the specific,
actionable reasons behind a model's performance. To bridge this gap, we
introduce CLEAR, an interactive, open-source package for LLM-based error
analysis. CLEAR first generates per-instance textual feedback, then it creates
a set of system-level error issues, and quantifies the prevalence of each
identified issue. Our package also provides users with an interactive dashboard
that allows for a comprehensive error analysis through aggregate
visualizations, applies interactive filters to isolate specific issues or score
ranges, and drills down to the individual instances that exemplify a particular
behavioral pattern. We demonstrate CLEAR analysis for RAG and Math benchmarks,
and showcase its utility through a user case study.

</details>


### [125] [Factual Inconsistencies in Multilingual Wikipedia Tables](https://arxiv.org/abs/2507.18406)
*Silvia Cappa,Lingxiao Kong,Pille-Riin Peet,Fanfu Wei,Yuchen Zhou,Jan-Christoph Kalo*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Wikipedia serves as a globally accessible knowledge source with content in
over 300 languages. Despite covering the same topics, the different versions of
Wikipedia are written and updated independently. This leads to factual
inconsistencies that can impact the neutrality and reliability of the
encyclopedia and AI systems, which often rely on Wikipedia as a main training
source. This study investigates cross-lingual inconsistencies in Wikipedia's
structured content, with a focus on tabular data. We developed a methodology to
collect, align, and analyze tables from Wikipedia multilingual articles,
defining categories of inconsistency. We apply various quantitative and
qualitative metrics to assess multilingual alignment using a sample dataset.
These insights have implications for factual verification, multilingual
knowledge interaction, and design for reliable AI systems leveraging Wikipedia
content.

</details>


### [126] [FinDPO: Financial Sentiment Analysis for Algorithmic Trading through Preference Optimization of LLMs](https://arxiv.org/abs/2507.18417)
*Giorgos Iacovides,Wuyang Zhou,Danilo Mandic*

Main category: cs.CL

TL;DR: FinDPO框架使用DPO技术提升金融大模型在情感分析和投资策略中的表现，实现了高收益和高夏普比率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于SFT（Supervised Fine-Tuning）的大语言模型在金融情感分析任务中存在泛化能力不足和容易过拟合的问题，无法有效处理金融领域中新事件和专业术语。因此，需要一种新的方法来提高模型在金融领域的适应性和实用性。

Method: 提出了一种名为FinDPO的金融领域LLM框架，该框架基于DPO（Direct Preference Optimization）进行后训练的人类偏好对齐。此外，FinDPO还包含一个创新的‘logit-to-score’转换机制，能够将离散的情感预测转化为连续的情感得分（概率），以便集成到投资组合策略中。

Result: FinDPO在标准情感分类基准测试中取得了SOTA性能，平均超越现有SFT模型11%。通过FinDPO框架的‘logit-to-score’转换，在模拟投资组合策略中，即使在考虑5个基点的交易成本下，仍能实现67%的年化回报和2.0的夏普比率。

Conclusion: FinDPO是一个基于DPO的金融领域LLM框架，在情感分析任务上取得了新的SOTA性能，并且首次实现了将LLM的预测结果应用于真实投资组合策略，在考虑交易成本的情况下，实现了67%的年化收益和2.0的夏普比率。

Abstract: Opinions expressed in online finance-related textual data are having an
increasingly profound impact on trading decisions and market movements. This
trend highlights the vital role of sentiment analysis as a tool for quantifying
the nature and strength of such opinions. With the rapid development of
Generative AI (GenAI), supervised fine-tuned (SFT) large language models (LLMs)
have become the de facto standard for financial sentiment analysis. However,
the SFT paradigm can lead to memorization of the training data and often fails
to generalize to unseen samples. This is a critical limitation in financial
domains, where models must adapt to previously unobserved events and the
nuanced, domain-specific language of finance. To this end, we introduce FinDPO,
the first finance-specific LLM framework based on post-training human
preference alignment via Direct Preference Optimization (DPO). The proposed
FinDPO achieves state-of-the-art performance on standard sentiment
classification benchmarks, outperforming existing supervised fine-tuned models
by 11% on the average. Uniquely, the FinDPO framework enables the integration
of a fine-tuned causal LLM into realistic portfolio strategies through a novel
'logit-to-score' conversion, which transforms discrete sentiment predictions
into continuous, rankable sentiment scores (probabilities). In this way,
simulations demonstrate that FinDPO is the first sentiment-based approach to
maintain substantial positive returns of 67% annually and strong risk-adjusted
performance, as indicated by a Sharpe ratio of 2.0, even under realistic
transaction costs of 5 basis points (bps).

</details>


### [127] [AraTable: Benchmarking LLMs' Reasoning and Understanding of Arabic Tabular Data](https://arxiv.org/abs/2507.18442)
*Rana Alshaikh,Israa Alghanmi,Shelan Jeawak*

Main category: cs.CL

TL;DR: AraTable 是一个阿拉伯语表格数据评估基准，旨在提高大型语言模型在该领域的能力。


<details>
  <summary>Details</summary>
Motivation: 填补阿拉伯语表格数据评估的空白，因为现有的基准主要针对英语，且公共资源有限，阿拉伯语本身也具有独特的语言特征。

Method: AraTable 通过混合方法构建，其中大型语言模型生成初始内容，然后由人类专家进行筛选和验证。自动评估框架采用自我反思机制。

Result: AraTable 的初步分析表明，尽管大型语言模型在直接问答等简单任务上表现尚可，但在需要更深层推理和事实核查的任务上仍面临重大挑战，这表明在复杂表格推理任务上存在改进的空间。auto-eval 框架的性能接近人类裁判。

Conclusion: 该研究提出了 AraTable，一个用于评估大型语言模型在阿拉伯语表格数据上的推理和理解能力的基准。它还提出了一个自动评估框架，该框架的性能接近人类评审员。

Abstract: The cognitive and reasoning abilities of large language models (LLMs) have
enabled remarkable progress in natural language processing. However, their
performance in interpreting structured data, especially in tabular formats,
remains limited. Although benchmarks for English tabular data are widely
available, Arabic is still underrepresented because of the limited availability
of public resources and its unique language features. To address this gap, we
present AraTable, a novel and comprehensive benchmark designed to evaluate the
reasoning and understanding capabilities of LLMs when applied to Arabic tabular
data. AraTable consists of various evaluation tasks, such as direct question
answering, fact verification, and complex reasoning, involving a wide range of
Arabic tabular sources. Our methodology follows a hybrid pipeline, where
initial content is generated by LLMs and subsequently filtered and verified by
human experts to ensure high dataset quality. Initial analyses using AraTable
show that, while LLMs perform adequately on simpler tabular tasks such as
direct question answering, they continue to face significant cognitive
challenges when tasks require deeper reasoning and fact verification. This
indicates that there are substantial opportunities for future work to improve
performance on complex tabular reasoning tasks. We also propose a fully
automated evaluation framework that uses a self-deliberation mechanism and
achieves performance nearly identical to that of human judges. This research
provides a valuable, publicly available resource and evaluation framework that
can help accelerate the development of foundational models for processing and
analysing Arabic structured data.

</details>


### [128] [Restoring Rhythm: Punctuation Restoration Using Transformer Models for Bangla, a Low-Resource Language](https://arxiv.org/abs/2507.18448)
*Md Obyedullahil Mamun,Md Adyelullahil Mamun,Arif Ahmad,Md. Imran Hossain Emu*

Main category: cs.CL

TL;DR: 通过使用 XLM-RoBERTa-large 模型和数据增强技术，成功实现了孟加拉语标点恢复，准确率高，并为低资源 NLP 研究做出了贡献。


<details>
  <summary>Details</summary>
Motivation: 标点恢复对于提高文本可读性至关重要，并且是自动语音识别（ASR）等后续处理任务的关键，特别是对于孟加拉语这类资源匮乏的语言。

Method: 研究探索了基于 Transformer 的模型（特别是 XLM-RoBERTa-large）在无标点孟加拉语文本中自动恢复标点的应用，重点关注在不同文本领域预测句号、逗号、问号和感叹号。为解决带注释资源稀缺的问题，研究构建了一个大型、多样化的训练语料库并应用了数据增强技术。

Result: 所提出的模型在新闻测试集上达到了 97.1% 的准确率，在参考集上达到了 91.2%，在 ASR 测试集上达到了 90.2%，展现了在真实、嘈杂场景下的有效性。

Conclusion: 该研究为孟加拉语的标点恢复奠定了坚实的基础，并为未来的低资源自然语言处理研究贡献了公开的数据集和代码。

Abstract: Punctuation restoration enhances the readability of text and is critical for
post-processing tasks in Automatic Speech Recognition (ASR), especially for
low-resource languages like Bangla. In this study, we explore the application
of transformer-based models, specifically XLM-RoBERTa-large, to automatically
restore punctuation in unpunctuated Bangla text. We focus on predicting four
punctuation marks: period, comma, question mark, and exclamation mark across
diverse text domains. To address the scarcity of annotated resources, we
constructed a large, varied training corpus and applied data augmentation
techniques. Our best-performing model, trained with an augmentation factor of
alpha = 0.20%, achieves an accuracy of 97.1% on the News test set, 91.2% on the
Reference set, and 90.2% on the ASR set.
  Results show strong generalization to reference and ASR transcripts,
demonstrating the model's effectiveness in real-world, noisy scenarios. This
work establishes a strong baseline for Bangla punctuation restoration and
contributes publicly available datasets and code to support future research in
low-resource NLP.

</details>


### [129] [Generation of Synthetic Clinical Text: A Systematic Review](https://arxiv.org/abs/2507.18451)
*Basel Alshaikhdeeb,Ahmed Abdelmonem Hemedan,Soumyabrata Ghosh,Irina Balaur,Venkata Satagopam*

Main category: cs.CL

TL;DR: 这是一篇关于生成临床合成文本的系统性综述，重点介绍了其在NLP中的应用、技术、评估方法以及面临的隐私挑战。


<details>
  <summary>Details</summary>
Motivation: 为解决临床NLP中的稀疏性和隐私等常见问题，通过生成临床合成文本来提供有效的解决方案。

Method: 通过系统性回顾，对（i）生成目的、（ii）技术和（iii）评估方法这三个研究问题进行量化分析。搜索了PubMed、ScienceDirect、Web of Science、Scopus、IEEE、Google Scholar和arXiv数据库。

Result: 在1398篇文章中确定了94篇相关文章。2018年以来，生成合成医疗文本受到广泛关注，主要用于文本增强、辅助写作、语料库构建、隐私保护、注释和实用性。Transformer架构（尤其是GPT）是生成文本的主要技术。评估方面包括相似性、隐私、结构和实用性，其中实用性是最常用的评估方法。

Conclusion: 虽然生成的合成医疗文本在不同下游NLP任务中可以作为真实医疗文档，但它在改善准确性和克服稀疏性/欠采样问题方面，被证明是重要的补充。然而，隐私仍然是生成合成医疗文本的一个主要问题，需要更多的人工评估来检查是否存在敏感信息。尽管如此，生成合成医疗文本的进展将大大加快工作流程和管道开发，摒弃耗时的法律事务。

Abstract: Generating clinical synthetic text represents an effective solution for
common clinical NLP issues like sparsity and privacy. This paper aims to
conduct a systematic review on generating synthetic medical free-text by
formulating quantitative analysis to three research questions concerning (i)
the purpose of generation, (ii) the techniques, and (iii) the evaluation
methods. We searched PubMed, ScienceDirect, Web of Science, Scopus, IEEE,
Google Scholar, and arXiv databases for publications associated with generating
synthetic medical unstructured free-text. We have identified 94 relevant
articles out of 1,398 collected ones. A great deal of attention has been given
to the generation of synthetic medical text from 2018 onwards, where the main
purpose of such a generation is towards text augmentation, assistive writing,
corpus building, privacy-preserving, annotation, and usefulness. Transformer
architectures were the main predominant technique used to generate the text,
especially the GPTs. On the other hand, there were four main aspects of
evaluation, including similarity, privacy, structure, and utility, where
utility was the most frequent method used to assess the generated synthetic
medical text. Although the generated synthetic medical text demonstrated a
moderate possibility to act as real medical documents in different downstream
NLP tasks, it has proven to be a great asset as augmented, complementary to the
real documents, towards improving the accuracy and overcoming
sparsity/undersampling issues. Yet, privacy is still a major issue behind
generating synthetic medical text, where more human assessments are needed to
check for the existence of any sensitive information. Despite that, advances in
generating synthetic medical text will considerably accelerate the adoption of
workflows and pipeline development, discarding the time-consuming legalities of
data transfer.

</details>


### [130] [Not All Features Deserve Attention: Graph-Guided Dependency Learning for Tabular Data Generation with Language Models](https://arxiv.org/abs/2507.18504)
*Zheyu Zhang,Shuo Yang,Bardh Prenkaj,Gjergji Kasneci*

Main category: cs.CL

TL;DR: GraDe通过图增强LLM注意力，提升表格数据生成效果，尤其在复杂数据上表现更佳。


<details>
  <summary>Details</summary>
Motivation: LLM在文本化表格数据生成方面潜力巨大，但其自注意力机制会分散到所有特征对上，导致对表格数据中固有的稀疏特征级依赖关系关注不足，尤其是在处理复杂依赖或语义模糊特征的数据集时。

Method: GraDe (Graph-Guided Dependency Learning) 方法，通过一个轻量级的动态图学习模块，并结合外部提取的功能依赖，将稀疏依赖图整合到LLM的注意力机制中，优先关注关键特征交互，抑制不相关交互。

Result: GraDe在复杂真实世界数据集上的表现优于现有LLM方法（最高提升12%），并在合成数据质量上达到SOTA水平。

Conclusion: GraDe方法通过整合稀疏依赖图到LLM的注意力机制中，有效解决了LLM在表格数据生成中对关键特征交互关注不足的问题。实验证明，GraDe在复杂真实世界数据集上的表现优于现有LLM方法（最高提升12%），并在合成数据质量上达到SOTA水平。该方法对LLM表格数据建模具有实际应用价值。

Abstract: Large Language Models (LLMs) have shown strong potential for tabular data
generation by modeling textualized feature-value pairs. However, tabular data
inherently exhibits sparse feature-level dependencies, where many feature
interactions are structurally insignificant. This creates a fundamental
mismatch as LLMs' self-attention mechanism inevitably distributes focus across
all pairs, diluting attention on critical relationships, particularly in
datasets with complex dependencies or semantically ambiguous features. To
address this limitation, we propose GraDe (Graph-Guided Dependency Learning), a
novel method that explicitly integrates sparse dependency graphs into LLMs'
attention mechanism. GraDe employs a lightweight dynamic graph learning module
guided by externally extracted functional dependencies, prioritizing key
feature interactions while suppressing irrelevant ones. Our experiments across
diverse real-world datasets demonstrate that GraDe outperforms existing
LLM-based approaches by up to 12% on complex datasets while achieving
competitive results with state-of-the-art approaches in synthetic data quality.
Our method is minimally intrusive yet effective, offering a practical solution
for structure-aware tabular data modeling with LLMs.

</details>


### [131] [The Moral Gap of Large Language Models](https://arxiv.org/abs/2507.18523)
*Maciej Skorski,Alina Landowska*

Main category: cs.CL

TL;DR: 大型语言模型在道德推理方面不如针对特定任务进行微调的 Transformer 模型。


<details>
  <summary>Details</summary>
Motivation: 道德基础检测对于分析社会话语和开发符合伦理的 AI 系统至关重要，但大型语言模型在专门的道德推理方面的表现尚不清楚。

Method: 本研究使用 ROC、PR 和 DET 曲线分析，对最先进的 LLM 和在 Twitter 和 Reddit 数据集上进行微调的 Transformer 进行了首次全面比较。

Result: 结果显示，尽管付出了提示工程的努力，LLM 仍然存在较高的假阴性率和系统性的道德内容漏检，它们在道德内容检测方面的表现存在显著的性能差距。

Conclusion: 在道德推理应用中，任务特定的微调仍然优于提示工程。

Abstract: Moral foundation detection is crucial for analyzing social discourse and
developing ethically-aligned AI systems. While large language models excel
across diverse tasks, their performance on specialized moral reasoning remains
unclear.
  This study provides the first comprehensive comparison between
state-of-the-art LLMs and fine-tuned transformers across Twitter and Reddit
datasets using ROC, PR, and DET curve analysis.
  Results reveal substantial performance gaps, with LLMs exhibiting high false
negative rates and systematic under-detection of moral content despite prompt
engineering efforts. These findings demonstrate that task-specific fine-tuning
remains superior to prompting for moral reasoning applications.

</details>


### [132] [Effective Multi-Task Learning for Biomedical Named Entity Recognition](https://arxiv.org/abs/2507.18542)
*João Ruano,Gonçalo M. Correia,Leonor Barreiros,Afonso Mendes*

Main category: cs.CL

TL;DR: SRU-NER是一种新的命名实体识别方法，通过多任务学习和动态损失调整来处理嵌套实体和跨数据集整合，提高了生物医学和通用NER任务的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 生物医学命名实体识别因生物医学术语的复杂性和标注数据集之间的一致性问题而面临重大挑战。

Method: SRU-NER（基于槽的递归单元命名实体识别）是一种新颖的方法，通过有效的多任务学习策略处理嵌套命名实体并整合多个数据集。SRU-NER通过动态调整损失计算来缓解标注空白，避免惩罚在给定数据集中不存在的实体类型的预测。

Result: SRU-NER在生物医学和通用领域命名实体识别任务中取得了有竞争力的性能，并提高了跨领域泛化能力。

Conclusion: SRU-NER在生物医学和通用领域命名实体识别任务中取得了有竞争力的性能，并提高了跨领域泛化能力。

Abstract: Biomedical Named Entity Recognition presents significant challenges due to
the complexity of biomedical terminology and inconsistencies in annotation
across datasets. This paper introduces SRU-NER (Slot-based Recurrent Unit NER),
a novel approach designed to handle nested named entities while integrating
multiple datasets through an effective multi-task learning strategy. SRU-NER
mitigates annotation gaps by dynamically adjusting loss computation to avoid
penalizing predictions of entity types absent in a given dataset. Through
extensive experiments, including a cross-corpus evaluation and human assessment
of the model's predictions, SRU-NER achieves competitive performance in
biomedical and general-domain NER tasks, while improving cross-domain
generalization.

</details>


### [133] [GLiNER2: An Efficient Multi-Task Information Extraction System with Schema-Driven Interface](https://arxiv.org/abs/2507.18546)
*Urchade Zaratiana,Gil Pasternak,Oliver Boyd,George Hurn-Maloney,Ash Lewis*

Main category: cs.CL

TL;DR: GLiNER2 是一个高效、统一的框架，可用于各种 NLP 任务，如命名实体识别、文本分类和结构化数据提取，并且比大型语言模型更易于部署。


<details>
  <summary>Details</summary>
Motivation: 解决现有信息提取解决方案需要针对不同任务进行专门的模型或依赖计算成本高昂的大型语言模型的问题。

Method: GLiNER2 是一个统一的框架，通过直观的基于模式的接口支持多任务组合，并利用预训练的 Transformer 编码器架构。

Result: GLiNER2 保持了 CPU 效率和紧凑的尺寸，在提取和分类任务上表现出有竞争力的性能。

Conclusion: GLiNER2 在命名实体识别、文本分类和分层结构化数据提取方面取得了有竞争力的性能，并且在部署可访问性方面相比基于 LLM 的替代方案有了显著改进。

Abstract: Information extraction (IE) is fundamental to numerous NLP applications, yet
existing solutions often require specialized models for different tasks or rely
on computationally expensive large language models. We present GLiNER2, a
unified framework that enhances the original GLiNER architecture to support
named entity recognition, text classification, and hierarchical structured data
extraction within a single efficient model. Built pretrained transformer
encoder architecture, GLiNER2 maintains CPU efficiency and compact size while
introducing multi-task composition through an intuitive schema-based interface.
Our experiments demonstrate competitive performance across extraction and
classification tasks with substantial improvements in deployment accessibility
compared to LLM-based alternatives. We release GLiNER2 as an open-source
pip-installable library with pre-trained models and documentation at
https://github.com/fastino-ai/GLiNER2.

</details>


### [134] [GIIFT: Graph-guided Inductive Image-free Multimodal Machine Translation](https://arxiv.org/abs/2507.18562)
*Jiafeng Xiong,Yuting Zhao*

Main category: cs.CL

TL;DR: GIIFT框架通过多模态场景图和图注意力网络，实现了强大的归纳式无图像机器翻译能力，在多个基准测试中达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有MMT方法在利用视觉信息方面存在挑战，主要体现在强制性的视觉-语言对齐以及局限于训练时所使用的多模态领域。这限制了模型在无图像场景下的推理能力和泛化性。因此，本研究旨在克服这些局限，提出一种能够有效整合跨模态信息并实现无图像推理的MMT框架。

Method: 本研究提出了GIIFT（Graph-guided Inductive Image-Free MMT）框架，一个两阶段的图引导归纳无图像MMT框架。该框架构建了新颖的多模态场景图，以保留和整合特定模态的信息。核心组件是一个跨模态图注意力网络适配器，用于在统一的融合空间中学习多模态知识，并将其归纳推广到无图像翻译的领域。

Result: 在Multi30K数据集（英译法和英译德）上，GIIFT超越了现有方法，即使在推理过程中不使用图像，也实现了最先进的性能。在WMT基准测试中，GIIFT相较于无图像翻译基线方法取得了显著的改进，证明了其在归纳式无图像推理方面的强大能力。

Conclusion: GIIFT框架在多模态机器翻译（MMT）领域取得了显著的成果，它能够有效地利用视觉信息，克服现有方法在处理跨模态差异和适应无图像推理方面的局限性。通过构建新颖的多模态场景图和采用图注意力网络适配器，GIIFT在统一的融合空间中学习跨模态知识，并能将其归纳推广到更广泛的无图像翻译领域。实验结果表明，GIIFT在Multi30K数据集和WMT基准测试中均超越了现有方法，达到了最先进水平，尤其在无图像推理方面展现出强大能力。

Abstract: Multimodal Machine Translation (MMT) has demonstrated the significant help of
visual information in machine translation. However, existing MMT methods face
challenges in leveraging the modality gap by enforcing rigid visual-linguistic
alignment whilst being confined to inference within their trained multimodal
domains. In this work, we construct novel multimodal scene graphs to preserve
and integrate modality-specific information and introduce GIIFT, a two-stage
Graph-guided Inductive Image-Free MMT framework that uses a cross-modal Graph
Attention Network adapter to learn multimodal knowledge in a unified fused
space and inductively generalize it to broader image-free translation domains.
Experimental results on the Multi30K dataset of English-to-French and
English-to-German tasks demonstrate that our GIIFT surpasses existing
approaches and achieves the state-of-the-art, even without images during
inference. Results on the WMT benchmark show significant improvements over the
image-free translation baselines, demonstrating the strength of GIIFT towards
inductive image-free inference.

</details>


### [135] [Hybrid Tokenization Strategy for DNA Language Model using Byte Pair Encoding and K-MER Methods](https://arxiv.org/abs/2507.18570)
*Ganesh Sapkota,Md Hasibur Rahman*

Main category: cs.CL

TL;DR: 本研究提出了一种混合分词策略，结合了 6-mer 和 BPE-600，以提高 DNA 语言模型的性能。该模型在 DNA 序列建模中同时捕捉局部和全局模式，并在预测任务中取得了优于现有模型的准确率。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统 k-mer 分词在捕捉局部 DNA 序列结构方面的有效性，以及在处理不均匀词元分布和有限的全局序列上下文理解方面的挑战。

Method: 提出了一种结合 6 聚体分词和字节对编码（BPE-600）的新型混合分词策略，通过合并独特的 6 聚体词元和通过 600 次 BPE 循环生成的 BPE 词元，来构建平衡且具有上下文感知的词汇表。

Result: 在下一个 k-mer 预测任务中，该混合词汇表训练的基础 DLM 取得了显著的性能提升，预测 3-mers 的准确率为 10.78%，4-mers 的准确率为 10.1%，5-mers 的准确率为 4.12%，优于 NT、DNABERT2 和 GROVER 等现有模型。

Conclusion: 该混合分词策略通过同时保留局部序列结构和全局上下文信息，显著提高了 DNA 语言模型在基因组语言建模方面的性能，为下游 DNA 序列分析和生物学研究奠定了基础。

Abstract: This paper presents a novel hybrid tokenization strategy that enhances the
performance of DNA Language Models (DLMs) by combining 6-mer tokenization with
Byte Pair Encoding (BPE-600). Traditional k-mer tokenization is effective at
capturing local DNA sequence structures but often faces challenges, including
uneven token distribution and a limited understanding of global sequence
context. To address these limitations, we propose merging unique 6mer tokens
with optimally selected BPE tokens generated through 600 BPE cycles. This
hybrid approach ensures a balanced and context-aware vocabulary, enabling the
model to capture both short and long patterns within DNA sequences
simultaneously. A foundational DLM trained on this hybrid vocabulary was
evaluated using next-k-mer prediction as a fine-tuning task, demonstrating
significantly improved performance. The model achieved prediction accuracies of
10.78% for 3-mers, 10.1% for 4-mers, and 4.12% for 5-mers, outperforming
state-of-the-art models such as NT, DNABERT2, and GROVER. These results
highlight the ability of the hybrid tokenization strategy to preserve both the
local sequence structure and global contextual information in DNA modeling.
This work underscores the importance of advanced tokenization methods in
genomic language modeling and lays a robust foundation for future applications
in downstream DNA sequence analysis and biological research.

</details>


### [136] [Wide-In, Narrow-Out: Revokable Decoding for Efficient and Effective DLLMs](https://arxiv.org/abs/2507.18578)
*Feng Hong,Geng Yu,Yushi Ye,Haicheng Huang,Huangjie Zheng,Ya Zhang,Yanfeng Wang,Jiangchao Yao*

Main category: cs.CL

TL;DR: WINO 是一种训练无关的解码算法，通过可撤销的解码机制解决了 DLLMs 的质量-速度权衡问题，实现了更快的推理速度和更高的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的 DLLMs 存在严重的质量-速度权衡问题，快速并行解码会导致性能显著下降，这是由于标准解码的不可逆性以及早期错误上下文累积。

Method: WINO 算法采用并行草稿和验证机制，利用模型的双向上下文来验证和修改潜在的错误，实现可撤销的解码。

Result: 在 LLaDA 和 MMaDA 等开源 DLLMs 上验证，WINO 算法显著改善了质量-速度权衡。例如，在 GSM8K 数学基准测试中，推理速度提高了 6 倍，准确率提高了 2.58%；在 Flickr30K 图像描述任务中，实现了 10 倍的速度提升和更高的性能。

Conclusion: WINO 算法通过引入可撤销的解码机制，显著改善了 DLLMs 的质量-速度权衡，在多个基准测试中实现了更快的推理速度和更高的准确性。

Abstract: Diffusion Large Language Models (DLLMs) have emerged as a compelling
alternative to Autoregressive models, designed for fast parallel generation.
However, existing DLLMs are plagued by a severe quality-speed trade-off, where
faster parallel decoding leads to significant performance degradation. We
attribute this to the irreversibility of standard decoding in DLLMs, which is
easily polarized into the wrong decoding direction along with early error
context accumulation. To resolve this, we introduce Wide-In, Narrow-Out (WINO),
a training-free decoding algorithm that enables revokable decoding in DLLMs.
WINO employs a parallel draft-and-verify mechanism, aggressively drafting
multiple tokens while simultaneously using the model's bidirectional context to
verify and re-mask suspicious ones for refinement. Verified in open-source
DLLMs like LLaDA and MMaDA, WINO is shown to decisively improve the
quality-speed trade-off. For instance, on the GSM8K math benchmark, it
accelerates inference by 6$\times$ while improving accuracy by 2.58%; on
Flickr30K captioning, it achieves a 10$\times$ speedup with higher performance.
More comprehensive experiments are conducted to demonstrate the superiority and
provide an in-depth understanding of WINO.

</details>


### [137] [System Report for CCL25-Eval Task 10: SRAG-MAV for Fine-Grained Chinese Hate Speech Recognition](https://arxiv.org/abs/2507.18580)
*Jiahao Wang,Ramen Liu,Longhui Zhang,Jing Li*

Main category: cs.CL

TL;DR: 提出SRAG-MAV框架，提升中文仇恨言论识别性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决细粒度中文仇恨言论识别（FGCHSR）问题，提出SRAG-MAV框架来提高模型性能。

Method: 提出SRAG-MAV框架，包括任务重构（TR）、自检索增强生成（SRAG）和多轮累积投票（MAV）。将四元组提取任务重构为三元组提取，使用动态检索创建上下文提示，并通过多轮推理和投票提高性能和稳定性。

Result: SRAG-MAV框架在STATE ToxiCN数据集上取得了硬性得分26.66，软性得分48.35，平均得分37.505，优于基线模型。

Conclusion: 基于Qwen2.5-7B模型，SRAG-MAV框架在CCL25-Eval任务10的FGCHSR任务上取得了优于GPT-4o和微调Qwen2.5-7B的性能。

Abstract: This paper presents our system for CCL25-Eval Task 10, addressing
Fine-Grained Chinese Hate Speech Recognition (FGCHSR). We propose a novel
SRAG-MAV framework that synergistically integrates task reformulation(TR),
Self-Retrieval-Augmented Generation (SRAG), and Multi-Round Accumulative Voting
(MAV). Our method reformulates the quadruplet extraction task into triplet
extraction, uses dynamic retrieval from the training set to create contextual
prompts, and applies multi-round inference with voting to improve output
stability and performance. Our system, based on the Qwen2.5-7B model, achieves
a Hard Score of 26.66, a Soft Score of 48.35, and an Average Score of 37.505 on
the STATE ToxiCN dataset, significantly outperforming baselines such as GPT-4o
(Average Score 15.63) and fine-tuned Qwen2.5-7B (Average Score 35.365). The
code is available at https://github.com/king-wang123/CCL25-SRAG-MAV.

</details>


### [138] [AQuilt: Weaving Logic and Self-Inspection into Low-Cost, High-Relevance Data Synthesis for Specialist LLMs](https://arxiv.org/abs/2507.18584)
*Xiaopeng Ke,Hexuan Deng,Xuebo Liu,Jun Rao,Zhenxi Song,Jun Yu,Min Zhang*

Main category: cs.CL

TL;DR: AQuilt是一个用于构建特定领域指令调优数据的框架，能有效提升LLM在专业领域的性能，且成本较低。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在特定领域表现不佳，现有的数据合成方法计算成本高、性能受限且泛化能力不足。

Method: AQuilt框架通过整合逻辑和检查机制，鼓励模型进行推理和自我检查以提升性能。此外，它还支持可定制的任务指令，以生成高质量的特定任务数据。

Result: AQuilt框架生成了一个包含703k个样本的数据集，用于训练一个强大的数据合成模型。实验结果表明，AQuilt的性能与DeepSeek-V3相当，但生产成本仅为其17%。此外，生成的数据与下游任务的相关性更高。

Conclusion: AQuilt框架能够从无标签数据中构建特定领域的指令调优数据，能够提高模型在专业领域上的性能，并且具有良好的泛化能力，同时生产成本低。

Abstract: Despite the impressive performance of large language models (LLMs) in general
domains, they often underperform in specialized domains. Existing approaches
typically rely on data synthesis methods and yield promising results by using
unlabeled data to capture domain-specific features. However, these methods
either incur high computational costs or suffer from performance limitations,
while also demonstrating insufficient generalization across different tasks. To
address these challenges, we propose AQuilt, a framework for constructing
instruction-tuning data for any specialized domains from corresponding
unlabeled data, including Answer, Question, Unlabeled data, Inspection, Logic,
and Task type. By incorporating logic and inspection, we encourage reasoning
processes and self-inspection to enhance model performance. Moreover,
customizable task instructions enable high-quality data generation for any
task. As a result, we construct a dataset of 703k examples to train a powerful
data synthesis model. Experiments show that AQuilt is comparable to DeepSeek-V3
while utilizing just 17% of the production cost. Further analysis demonstrates
that our generated data exhibits higher relevance to downstream tasks. Source
code, models, and scripts are available at https://github.com/Krueske/AQuilt.

</details>


### [139] [TRPrompt: Bootstrapping Query-Aware Prompt Optimization from Textual Rewards](https://arxiv.org/abs/2507.18618)
*Andreea Nica,Ivan Zakazov,Nicolas Mario Baldwin,Saibo Geng,Robert West*

Main category: cs.CL

TL;DR: TRPrompt通过文本反馈优化LLM提示，无需模型微调，即可在数学推理任务上达到SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在改进大型语言模型的推理能力，同时避免对模型参数进行更新。

Method: TRPrompt框架通过整合文本反馈来训练提示模型，该模型能够生成针对特定问题的、状态最优的提示。

Result: TRPrompt框架在GSMHard和MATH等数学数据集上实现了先进的、针对查询优化的提示，展示了其在提升LLM推理能力方面的有效性。

Conclusion: TRPrompt框架统一了基于文本反馈和基于数值奖励的方法，通过将文本反馈直接整合到提示模型的训练中，实现了零样本的提示优化。

Abstract: Prompt optimization improves the reasoning abilities of large language models
(LLMs) without requiring parameter updates to the target model. Following
heuristic-based "Think step by step" approaches, the field has evolved in two
main directions: while one group of methods uses textual feedback to elicit
improved prompts from general-purpose LLMs in a training-free way, a concurrent
line of research relies on numerical rewards to train a special prompt model,
tailored for providing optimal prompts to the target model. In this paper, we
introduce the Textual Reward Prompt framework (TRPrompt), which unifies these
approaches by directly incorporating textual feedback into training of the
prompt model. Our framework does not require prior dataset collection and is
being iteratively improved with the feedback on the generated prompts. When
coupled with the capacity of an LLM to internalize the notion of what a "good"
prompt is, the high-resolution signal provided by the textual rewards allows us
to train a prompt model yielding state-of-the-art query-specific prompts for
the problems from the challenging math datasets GSMHard and MATH.

</details>


### [140] [Checklists Are Better Than Reward Models For Aligning Language Models](https://arxiv.org/abs/2507.18624)
*Vijay Viswanathan,Yanchao Sun,Shuang Ma,Xiang Kong,Meng Cao,Graham Neubig,Tongshuang Wu*

Main category: cs.CL

TL;DR: RLCF是一种新的强化学习方法，它使用指令特定的清单来训练语言模型，以更好地遵循指令，并在多项基准测试中取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 为了克服目前强化学习在指令遵循方面主要依赖固定标准（如“有用性”和“有害性”）的局限性，本研究提出使用灵活的、指令特定的标准来拓宽强化学习在引导指令遵循方面的应用。

Method: 提出了一种名为“RLCF”的强化学习方法，该方法使用指令特定的标准来评估响应。具体来说，它从指令中提取清单，并利用AI法官和专用验证程序来评估响应满足清单项目的程度，然后将这些分数组合起来计算强化学习的奖励。

Result: RLCF在五个广泛研究的基准测试中，相较于其他对齐方法，能够提升指令遵循模型的性能，包括在FollowBench上提高了4个百分点的硬满意率，在InFoBench上提高了6个百分点，在Arena-Hard上提高了3个百分点的胜率。

Conclusion: RLCF通过提取指令特定的清单并结合AI法官和专用验证程序来评估响应，从而提高了语言模型遵循指令的能力，并在各项基准测试中均优于其他方法。

Abstract: Language models must be adapted to understand and follow user instructions.
Reinforcement learning is widely used to facilitate this -- typically using
fixed criteria such as "helpfulness" and "harmfulness". In our work, we instead
propose using flexible, instruction-specific criteria as a means of broadening
the impact that reinforcement learning can have in eliciting instruction
following. We propose "Reinforcement Learning from Checklist Feedback" (RLCF).
From instructions, we extract checklists and evaluate how well responses
satisfy each item - using both AI judges and specialized verifier programs -
then combine these scores to compute rewards for RL. We compare RLCF with other
alignment methods applied to a strong instruction following model
(Qwen2.5-7B-Instruct) on five widely-studied benchmarks -- RLCF is the only
method to improve performance on every benchmark, including a 4-point boost in
hard satisfaction rate on FollowBench, a 6-point increase on InFoBench, and a
3-point rise in win rate on Arena-Hard. These results establish checklist
feedback as a key tool for improving language models' support of queries that
express a multitude of needs.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [141] [Time and Frequency Synchronization for Multiuser OTFS in Uplink](https://arxiv.org/abs/2507.17966)
*Mohsen Bayat,Sanoopkumar P. S.,Arman Farhang*

Main category: eess.SP

TL;DR: 在高移动性 MU-OTFS 系统中，我们提出了一种新的时频同步技术，用于准确估计和校正时频偏移。


<details>
  <summary>Details</summary>
Motivation: 为了在高移动性场景下实现高精度的上行链路多用户 OTFS (MU-OTFS) 系统的时频同步，以提高信道估计精度和用户定位的准确性。

Method: 提出了一种新的基于相关性的时频同步技术，包括使用循环前缀的单用户启发式 PCP (SU-PCP) 导引结构，以及一种利用滤波器组分离用户信号的第二种时频同步技术。此外，还提出了一种通过寻找相关函数中的第一个主要峰值来增强时频同步精度的数学阈值范围，并利用第一类切比雪夫多项式基展开模型 (CPF-BEM) 来处理信道的时间变化，将多维最大似然搜索问题简化为多个一维搜索问题。

Result: 该论文提出的时频同步技术能够准确估计和校正时频偏移，从而提高了 MU-OTFS 系统的性能。

Conclusion: 该论文提出了一种新的基于相关性的时频同步技术，用于高移动性场景下的上行链路多用户 OTFS (MU-OTFS) 系统。

Abstract: In this paper, we propose time and frequency synchronization techniques for
uplink multiuser OTFS (MU-OTFS) systems in high-mobility scenarios. This work
focuses on accurately estimating and correcting timing offsets (TOs) and
carrier frequency offsets (CFOs). Specifically, TO estimation is essential for
locating users' pilots on the delay-time plane, while CFO estimation enhances
channel estimation accuracy. First, we propose a TO estimation technique for an
existing multiuser pilot structure in MU-OTFS. We replace the impulse pilot
(IMP) in this pilot structure with a more practical pilot with a cyclic prefix
(PCP), referred to as single-user-inspired PCP (SU-PCP). This structure employs
different Zadoff-Chu (ZC) sequences, which enables pilot separation via
correlation at the receiver side. Consequently, we introduce a
correlation-based TO estimation technique for uplink MU-OTFS using this pilot
structure. Next, a spectrally efficient and practical pilot pattern is
proposed, where each user transmits a PCP within a shared pilot region on the
delay-Doppler plane, referred to as MU-PCP. At the receiver, the second TO
estimation technique utilizes a bank of filters to separate different users'
signals and accurately estimate their TOs. Then, we derive a mathematical
threshold range to enhance TO estimation accuracy by finding the first major
peak in the correlation function rather than relying solely on the highest
peak. After locating the received users' pilot signals using one of the
proposed TO estimation techniques, our proposed CFO estimation technique
reduces the multi-dimensional maximum likelihood (ML) search problem into
multiple one-dimensional search problems. In this technique, we apply the
Chebyshev polynomials of the first kind basis expansion model (CPF-BEM) to
effectively handle the time-variations of the channel in obtaining the CFO
estimates for all the users.

</details>


### [142] [Metasurface-based Fluid Antennas: from Electromagnetics to Communications Model](https://arxiv.org/abs/2507.17982)
*Pablo Ramírez-Espinosa,Cleofás Segura-Gómez,Ángel Palomares-Caballero,F. Javier López-Martínez,David Morales-Jiménez*

Main category: eess.SP

TL;DR: 本论文提出了一种用于超表面流体天线系统（FAS）的解析模型，利用电路理论和导纳矩阵来处理超表面的电磁效应，解决了电子可重构天线建模的挑战，并验证了该模型能实现与理想化天线相似的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决电子可重构天线在解析建模中遇到的挑战，以及应对流体天线系统日益增长的研究兴趣，论文旨在为超表面实现的流体天线系统提供一个完整的解析模型。

Method: 本篇论文提出了一种基于超表面实现流体天线系统的完整解析模型，利用电路理论改写了传统的流体天线系统信号模型，引入了包含超表面电磁效应的导纳矩阵。

Result: 通过与全波仿真的对比，所提出的模型得到了验证，并且两者结果吻合良好。结果证实了基于DMA的FAS能够实现与理想化位置灵活天线相似的性能。

Conclusion: 所提出的模型能够被应用于标准的性能分析，并为包括结果信号协方差矩阵在内的关键度量提供了闭式表达式，证明了基于DMA的FAS可以实现与理想化位置灵活天线相似的性能。

Abstract: Fluid antenna systems (FASs) have become a popular topic in the wireless
community as an effective yet simple means of exploiting spatial diversity. Due
to the limitations of physically moving radiating elements, electronically
reconfigurable antennas are emerging as practical implementations of FASs,
since changing the radiation pattern is functionally equivalent to physically
moving the device. However, electronically reconfigurable antennas pose a
challenge in terms of analytical modeling, often requiring full-wave
simulations or measurements for their characterization; this severely limits
the extraction of theoretical insights useful for system design. Motivated by
these difficulties and the growing interest in FASs, we propose in this paper a
complete analytical model for metasurface-based embodiments of FASs.
Specifically, we advocate for the implementation of the FAS concept through
dynamic metasurface antennas (DMAs), hitherto proposed as array replacements in
multiple-input multiple-output (MIMO) systems. We leverage circuit theory to
rewrite the conventional signal model of FASs in terms of admittance matrices
accounting for the electromagnetic effects inherent to metasurfaces. The model
is validated with full-wave simulations, showing good agreement. We further
illustrate how to apply the model for standard performance analysis, and
provide closed-form expressions for key metrics, including the resulting signal
covariance matrix. Results confirm that practical DMA-based FASs can achieve
similar performance to that of idealized implementations of position-flexible
antennas.

</details>


### [143] [Multiple Active STAR-RIS-Assisted Secure Integrated Sensing and Communication via Cooperative Beamforming](https://arxiv.org/abs/2507.18035)
*Hyeonho Noh,Hyeonsu Lyu,Hyun Jong Yang*

Main category: eess.SP

TL;DR: 本研究提出了一种新的集成传感和通信（ISAC）网络，并使用多STAR-RIS来提高通信速率，同时满足传感和安全要求。


<details>
  <summary>Details</summary>
Motivation: 为了最大化总和速率，同时满足感知SINR要求、保密性约束以及BS和STAR-RIS的功率约束，优化了BS波束成形器和STAR-RIS的反射/透射系数。

Method: 提出了一种交替优化（AO）框架来解决高度非凸问题。通过KKT条件更新BS波束形成器，并通过SCA和半定放松（SDR）求解的半定规划（SDP）来优化STAR-RIS。

Result: 仿真表明，与基线方法相比，所提出的算法在满足感知和安全约束的同时，实现了更高的通信速率。

Conclusion: 该算法在满足感知和安全约束的同时，与被动RIS和单STAR-RIS基线相比，实现了显著的总速率增益。

Abstract: This paper explores an integrated sensing and communication (ISAC) network
empowered by multiple active simultaneously transmitting and reflecting
reconfigurable intelligent surfaces (STAR-RISs). A base station (BS) furnishes
downlink communication to multiple users while concurrently interrogating a
sensing target. We jointly optimize the BS transmit beamformer and the
reflection/transmission coefficients of every active STAR-RIS in order to
maximize the aggregate communication sum-rate, subject to (i) a stringent
sensing signal-to-interference-plus-noise ratio (SINR) requirement, (ii) an
upper bound on the leakage of confidential information, and (iii) individual
hardware and total power constraints at both the BS and the STAR-RISs. The
resulting highly non-convex program is tackled with an efficient alternating
optimization (AO) framework. First, the original formulation is reformulated
into an equivalent yet more tractable representation and partitioned into
subproblems. The BS beamformer is updated in closed form via the
Karush-Kuhn-Tucker (KKT) conditions, whereas the STAR-RIS reflection and
transmission vectors are refined through successive convex approximation (SCA),
yielding a semidefinite program that is then solved via semidefinite
relaxation. Comprehensive simulations demonstrate that the proposed algorithm
delivers substantial sum-rate gains over passive-RIS and single STAR-RIS
baselines, all the while rigorously meeting the prescribed sensing and security
constraints.

</details>


### [144] [Geometrical portrait of Multipath error propagation in GNSS Direct Position Estimation](https://arxiv.org/abs/2507.18096)
*Jihong Huang,Rong Yang,Wei Gao,Xingqun Zhan,Zheng Yao*

Main category: eess.SP

TL;DR: DPE方法在城市环境中具有鲁棒性，但缺乏多路径误差的理论表征。本研究提出的SCMB模型通过几何分析量化了多路径误差，并给出了选择DPE卫星的几何建议。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏对直接位置估计算法（DPE）的多路径误差的理论表征。本研究旨在通过几何分析扩展DPE噪声方差的理论框架，并建立一个能够量化多路径误差对CAF和PVT解决方案影响的SCMB模型。

Method: 本研究提出了一种新的卫星圆多路径偏差（SCMB）模型，该模型通过几何分析量化了由偏心偏差引起的多路径误差对CAF和PVT解的偏差。通过蒙特卡洛模拟和城市峡谷测试验证了模型的准确性。

Result: 研究结果表明，最大PVT偏差取决于跨越不同卫星通道的最大多路径误差。PVT偏差随卫星仰角增大而增大，这受到CAF多路径偏差投影的影响。本研究为从几何角度选择DPE卫星提供了参考。

Conclusion: 本研究通过几何分析建立了直接位置估计算法（DPE）的卫星圆多路径偏差（SCMB）模型，并验证了其准确性。研究结果表明，最大位置、速度和时间（PVT）偏差取决于观测到的最大多路径误差，并且随着卫星仰角增加而增加。这为了从几何角度选择DPE卫星提供了参考，强调了结合高低仰角卫星以获得最佳几何构型的优势。

Abstract: Direct Position Estimation (DPE) is a method that directly estimate position,
velocity, and time (PVT) information from cross ambiguity function (CAF) of the
GNSS signals, significantly enhancing receiver robustness in urban
environments. However, there is still a lack of theoretical characterization on
multipath errors in the context of DPE theory. Geometric observations highlight
the unique characteristics of DPE errors stemming from multipath and thermal
noise as estimation bias and variance respectively. Expanding upon the
theoretical framework of DPE noise variance through geometric analysis, this
paper focuses on a geometric representation of multipath errors by quantifying
the deviations in CAF and PVT solutions caused by off-centering bias relative
to the azimuth and elevation angles. A satellite circular multipath bias (SCMB)
model is introduced, amalgamating CAF and PVT errors from multiple satellite
channels. The boundaries for maximum or minimum PVT bias are established
through discussions encompassing various multipath conditions. The correctness
of the multipath geometrical portrait is confirmed through both Monte Carlo
simulations and urban canyon tests. The findings indicate that the maximum PVT
bias depends on the largest multipath errors observed across various satellite
channels. Additionally, the PVT bias increases with satellite elevation angles,
influenced by the CAF multipath bias projection. This serves as a reference for
selecting DPE satellites from a geometric standpoint, underscoring the
importance of choosing a balanced combination of high and low elevation angles
to achieve an optimal satellite geometry configuration.

</details>


### [145] [Envelope Control Enabled Probabilistic Shaping for Peak Power Constrained IM DD Systems](https://arxiv.org/abs/2507.18149)
*Dongdong Zou,Wei Wang,Jiawen Yao,Zhongxing Tian,Zeyu Feng,Huan Huang,Fan Li,Gordon Ning Liu,Gangxiang Shen,Yi Cai*

Main category: eess.SP

TL;DR: 首次提出并验证了适用于具有记忆效应的峰值功率约束IM-DD系统的概率整形方案，实现了性能提升和速率适应能力。


<details>
  <summary>Details</summary>
Motivation: 解决概率整形（PS）技术在具有记忆效应的峰值功率约束（PPC）强度调制直接检测（IM-DD）系统中的应用难题，减轻由记忆效应引起的问题，如非线性、过冲、峰均功率比（PAPR）增加等。

Method: 提出了一种新颖的间接概率整形（PS）方案，包含发射端的动态选择性映射（DSLM）机制和接收端的改进M-BCJR算法的Turbo均衡器，以减轻记忆效应带来的损伤。

Result: 所提出的方案在56GBaud PAM8系统中实现了1dB的接收灵敏度提升，并证明了其与典型概率幅度整形（PAS）架构的兼容性，实现了简单的细粒度速率适应能力。

Conclusion: 该研究首次提出了将概率整形（PS）技术应用于具有峰值功率约束（PPC）和记忆效应的强度调制直接检测（IM-DD）系统，并通过实验验证了其有效性，展示了1dB的接收灵敏度提升。

Abstract: Probabilistic shaping (PS) has attracted significant attention in
intensity-modulation and direct-detection (IM-DD) systems. However, due to the
unique system model and inherent constraints, the effective application of the
PS technique is still an open question in IM-DD systems, particularly in
systems with memory effects. In this paper, a novel indirect PS scheme tailored
for peak power constrained (PPC) IM-DD systems is proposed. The key idea lies
in strategically controlling the signal envelope to mitigate memory-induced
impairments, such as nonlinearity, overshoot, peak-to-average power ratio
enhancement, etc. The proposed scheme incorporates a dynamic selective mapping
(DSLM) mechanism at the transmitter, enabling an untypical bit-to-symbol
mapping in which the current symbol is not only determined by the current bits
pattern but also by previously generated symbols within a specified memory
length. At the receiver side, a turbo equalizer with a modified M-BCJR
algorithm is proposed to achieve the recovery of ambiguous bits induced by
DSLM. Experimental verification in a 56GBaud PAM8 system demonstrates that the
proposed scheme exhibits 1dB receiver sensitivity improvement over 2km
single-mode fiber transmission. In addition, the proposed scheme has also been
demonstrated to be compatible with the typical probabilistic amplitude shaping
architecture, enabling a simple and fine-granularity rate adaptation
capability. To the best of our knowledge, this work opens a new sight for the
application of the PS technique in PPC IM-DD systems with memory effects.

</details>


### [146] [GNSS Jammer and Spoofer Mitigation via Multi-Antenna Processing](https://arxiv.org/abs/2507.18166)
*Jonas Elmiger,Gian Marti,Christoph Studer*

Main category: eess.SP

TL;DR: SCHIEBER是一种用于多天线GNSS接收机的方法，可以抵抗干扰和欺骗攻击。


<details>
  <summary>Details</summary>
Motivation: 现代定位依赖GNSS，但GNSS容易受到干扰和欺骗攻击。

Method: SCHIEBER通过使用一种新颖的自适应空间滤波技术来缓解干扰，并在信号采集后通过比较接收到的信号的到达方向（DoA）和伪距估计来识别和拒绝欺骗信号。

Result: 通过对GPS L1 C/A系统在欺骗和干扰攻击下的广泛模拟，证明了SCHIEBER的有效性。

Conclusion: SCHIEBER是一种新颖的多天线GNSS接收机方法，可以在不知道接收机位置或攻击类型的情况下，缓解干扰器和欺骗器。

Abstract: Modern positioning relies on radio signals from global navigation satellite
systems (GNSS). Their low receive power renders these radio signals susceptible
to jamming attacks, in which malicious transmitters emit strong interference to
disrupt signal acquisition. Moreover, GNSS are vulnerable to spoofing attacks,
in which malicious transmitters mimic legitimate satellites by transmitting
spurious GNSS signals. We propose SCHIEBER, a novel method for multi-antenna
GNSS receivers that mitigates jammers as well as spoofers without requiring any
prior knowledge of the receiver position or attack type: Jammers are mitigated
during signal acquisition using a recently developed adaptive spatial filtering
technique. Spoofers are identified and rejected after signal acquisition using
a novel approach that tests the consistency of acquired signals by comparing
their respective direction of arrival (DoA) and pseudorange estimates in a test
that is invariant with respect to the unknown receiver position. We demonstrate
the efficacy of our method using extensive simulations of a GPS L1 C/A system
under spoofing and jamming attacks.

</details>


### [147] [ICWLM: A Multi-Task Wireless Large Model via In-Context Learning](https://arxiv.org/abs/2507.18167)
*Yuxuan Wen,Xiaoming Chen,Maojun Zhang,Zhaoyang Zhang*

Main category: eess.SP

TL;DR: ICWLM 是一个为无线通信设计的大模型，能同时处理多种物理层任务，并通过上下文学习适应不同环境，性能优越且泛化能力强。


<details>
  <summary>Details</summary>
Motivation: 传统的深度学习方法在解决无线通信物理层问题时，通常是任务特定的，并且面临数据稀疏和泛化能力不足的挑战。为了克服这些限制，需要一种能够处理多种任务并且能够适应不同网络环境的模型。

Method: ICWLM（In-Context Wireless Large Model）是一种为无线通信原生设计的大模型，它从头开始在海量的、混合的无线数据集上进行训练，实现了物理层多任务的联合学习。该模型利用上下文学习（ICL）能力，能够通过少量示例适应不同的系统配置和信道条件，无需重新训练。此外，还采用了动态权重平均（DWA）算法来平衡多任务训练中的任务损失，以提高学习的效率和稳定性。

Result: ICWLM 在性能上与特定任务的方法相当，并且在面对未知的系统配置时表现出强大的泛化能力。这表明该模型在降低部署复杂性和提高智能资源管理方面具有潜力。

Conclusion: 该研究提出了一种新颖的、为无线通信原生设计的大模型（ICWLM），它能够从头开始在海量、混合的无线数据集上进行训练，并同时处理物理层中的多个经典问题，如用户预编码（和速率最大化和最大最小信噪比）和信道预测。ICWLM 的一个关键创新在于利用了上下文学习（ICL）能力，使其能够适应不断变化的系统配置和信道条件，而只需很少的示例对，无需进行广泛的重新训练。此外，研究还采用了动态权重平均（DWA）算法来动态平衡多任务训练过程中的个体任务损失，确保在不同目标上的学习效率和稳定性。大量的仿真结果表明，ICWLM 在性能上可与特定任务的方法相媲美，同时展现了对未见过的系统配置的卓越泛化能力。这项工作为开发统一且自适应的未来无线网络人工智能模型提供了一种有前景的范例，有望降低部署复杂性并增强智能资源管理。

Abstract: The rapid evolution of wireless communication technologies, particularly
massive multiple-input multiple-output (mMIMO) and millimeter-wave (mmWave),
introduces significant network complexity and computational demands.
Significant research efforts have been made to improve physical layer
performance by resorting to deep learning (DL) methods, which, however, are
usually task-specific and struggle with data scarcity and generalization. To
address these challenges, we propose a novel In-Context Wireless Large Model
(ICWLM), a wireless-native foundation model designed for simultaneous
multi-task learning at the physical layer. Unlike conventional methods that
adapt wireless data to pre-trained large language models (LLMs), ICWLM is
trained directly on large-scale, mixed wireless datasets from scratch. It
jointly solves multiple classical physical layer problems, including multi-user
precoding (sum-rate maximization and max-min SINR) and channel prediction. A
key innovation of ICWLM is its utilization of in-context learning (ICL),
enabling the model to adapt to varying system configurations and channel
conditions with minimal demonstration pairs, eliminating the need for extensive
retraining. Furthermore, we employ the Dynamic Weight Averaging (DWA) algorithm
to dynamically balance the individual task losses during multi-task training,
ensuring efficient and stable learning across diverse objectives. Extensive
simulation results demonstrate that ICWLM achieves competitive performance
compared to task-specific methods while exhibiting remarkable generalization
capabilities to unseen system configurations. This work offers a promising
paradigm for developing unified and adaptive AI models for future wireless
networks, potentially reducing deployment complexity and enhancing intelligent
resource management.

</details>


### [148] [Quantized Signal Recovery with Interference via Parametrized Look-Up Tables](https://arxiv.org/abs/2507.18370)
*Morriel Kasher,Michael Tinston,Predrag Spasojevic*

Main category: eess.SP

TL;DR: 一种优化的查找表（LUT）后校正方法，用于低分辨率ADC，能显著提高性能并抵抗干扰。


<details>
  <summary>Details</summary>
Motivation: 为了实现对低分辨率ADC的有效全数字后校正，并优化查找表（LUT）的性能，尤其是在处理非线性或宽带量化器时。

Method: 通过结合参数化模型（考虑输入信号、噪声和干扰）来优化查找表（LUT）性能，并提出了解析估计器和针对特定信号（PSK输入、LFM干扰）的近似方法，用于全数字后校正低分辨率ADC。

Result: 模拟结果表明，该估计器能够实时、高精度地恢复输入信号的瞬时值，包括抵消因前端饱和引起的谐波失真。与传统线性滤波技术相比，在均方误差方面提高了10dB以上，在无杂散动态范围方面提高了20dBc以上。

Conclusion: 该研究提出了一种结合参数化模型和三种解析估计器的用于查找表（LUT）的优化方法，适用于低分辨率、非线性或宽带量化器，并通过模拟结果验证了其实时准确恢复输入信号的能力，包括抵消由前端饱和引起的谐波失真。与传统线性滤波技术相比，该估计器在均方误差和无杂散动态范围方面均有显著提升，并且对输入参数、非线性量化器和时变干扰源具有鲁棒性。

Abstract: Efficient all-digital post-correction of low-resolution analog-to-digital
converters can be achieved by using Look-Up Tables (LUTs). The performance of a
LUT can be optimized by incorporating a parametric model for the expected input
signal, noise level, and interference signals. We evaluate three analytical
estimators for integration with parametrized LUTs, especially with applications
to low-resolution, non-linear, or wideband quantizers. We also propose several
approximations to improve tractability of the estimation problem for
Phase-Shift Keyed input signals and Linear Frequency Modulated interference
signals. Simulated results validate the ability of our estimator to recover the
instantaneous value of the desired input signal in real-time with a high degree
of accuracy. This includes cancellation of harmonic distortion that aliases
into the desired signal bandwidth from front-end saturation due to high-power
out-of-band interference. Our estimators are shown to achieve a significant
gain over conventional linear-filtering techniques while also being robust to
changes in input parameters, non-linear quantizers, and time-variant
interference sources. For a tone input quantized to 3 bits and estimated with a
fixed 12-tap model order we achieve $>$10 dB improvement in Mean Square Error
and $>$20 dBc improvement in Spurious-Free Dynamic Range.

</details>


### [149] [A Foundation Model for Massive MIMO Precoding with an Adaptive per-User Rate-Power Tradeoff](https://arxiv.org/abs/2507.18587)
*Jérôme Emery,Ali Hasanzadeh Karkan,Jean-François Frigon,François Leduc-Primeau*

Main category: eess.SP

TL;DR: 通过Transformer基础模型和数据增强方法，解决了mMIMO预编码中的数据稀疏和训练复杂度问题，在能耗和性能上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 深度学习在mMIMO预编码中具有潜力，但实际部署面临数据收集困难和训练复杂度高等挑战。

Method: 提出了一种基于Transformer的基础模型用于mMIMO预编码，以最小化发射机能耗并动态适应用户速率需求。为了解决数据稀疏情况下的模型适应性问题，提出了一种通过计算预训练特征提取器输出之间的余弦相似度来寻找与目标分布相似的训练样本的数据增强方法。

Result: 在相同的能耗下，提出的基础模型在零样本部署时性能显著优于零迫，并且在复杂度降低8倍的情况下，性能接近加权最小均方误差。

Conclusion: 该研究通过提出一种基于Transformer的基础模型解决了数据稀疏和训练复杂度的问题，使得深度学习在mMIMO预编码中具有实际应用价值。此外，动态配置用户速率需求的能力可以被上层算法利用，以更好地控制能效、频谱效率和公平性。

Abstract: Deep learning (DL) has emerged as a solution for precoding in massive
multiple-input multiple-output (mMIMO) systems due to its capacity to learn the
characteristics of the propagation environment. However, training such a model
requires high-quality, local datasets at the deployment site, which are often
difficult to collect. We propose a transformer-based foundation model for mMIMO
precoding that seeks to minimize the energy consumption of the transmitter
while dynamically adapting to per-user rate requirements. At equal energy
consumption, zero-shot deployment of the proposed foundation model
significantly outperforms zero forcing, and approaches weighted minimum mean
squared error performance with 8x less complexity. To address model adaptation
in data-scarce settings, we introduce a data augmentation method that finds
training samples similar to the target distribution by computing the cosine
similarity between the outputs of the pre-trained feature extractor. Our work
enables the implementation of DL-based solutions in practice by addressing
challenges of data availability and training complexity. Moreover, the ability
to dynamically configure per-user rate requirements can be leveraged by higher
level resource allocation and scheduling algorithms for greater control over
energy efficiency, spectral efficiency and fairness.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [150] [PinchBot: Long-Horizon Deformable Manipulation with Guided Diffusion Policy](https://arxiv.org/abs/2507.17846)
*Alison Bartsch,Arvind Car,Amir Barati Farimani*

Main category: cs.RO

TL;DR:  PinchBot是一个机器人系统，通过捏合动作制作简单的陶艺品。


<details>
  <summary>Details</summary>
Motivation: 探索机器人通过捏合动作制作陶艺的挑战，这是一个多模态、长时序的软体操作任务。

Method:  PinchBot是一个目标条件扩散策略模型，结合了预训练的3D点云嵌入、任务进度预测和碰撞约束动作投影。

Result: 机器人能够成功制作各种简单的陶艺目标。

Conclusion:  PinchBot成功实现了简单的陶艺制作目标，这是一个多模态、长时序的软体操作任务。

Abstract: Pottery creation is a complicated art form that requires dexterous, precise
and delicate actions to slowly morph a block of clay to a meaningful, and often
useful 3D goal shape. In this work, we aim to create a robotic system that can
create simple pottery goals with only pinch-based actions. This pinch pottery
task allows us to explore the challenges of a highly multi-modal and
long-horizon deformable manipulation task. To this end, we present PinchBot, a
goal-conditioned diffusion policy model that when combined with pre-trained 3D
point cloud embeddings, task progress prediction and collision-constrained
action projection, is able to successfully create a variety of simple pottery
goals. For experimental videos and access to the demonstration dataset, please
visit our project website:
https://sites.google.com/andrew.cmu.edu/pinchbot/home.

</details>


### [151] [A Step-by-step Guide on Nonlinear Model Predictive Control for Safe Mobile Robot Navigation](https://arxiv.org/abs/2507.17856)
*Dennis Benders,Laura Ferranti,Johannes Köhler*

Main category: cs.RO

TL;DR: 本报告详细介绍了如何利用NMPC实现移动机器人的安全导航，重点关注约束和避障。


<details>
  <summary>Details</summary>
Motivation: 设计一种能够使移动机器人在充满障碍物的环境中安全导航的模型预测控制（MPC）方案。

Method: 通过提供从理论概念到数学证明和实现的实用且易于访问的路径，重点关注安全性和性能保证。

Result: 提供了一个关于如何实现NMPC的详细指南，以满足安全导航要求。

Conclusion: 该报告提供了一个分步方法来实现非线性模型预测控制（NMPC）方案，以满足安全导航要求。

Abstract: Designing a Model Predictive Control (MPC) scheme that enables a mobile robot
to safely navigate through an obstacle-filled environment is a complicated yet
essential task in robotics. In this technical report, safety refers to ensuring
that the robot respects state and input constraints while avoiding collisions
with obstacles despite the presence of disturbances and measurement noise. This
report offers a step-by-step approach to implementing Nonlinear Model
Predictive Control (NMPC) schemes addressing these safety requirements.
Numerous books and survey papers provide comprehensive overviews of linear MPC
(LMPC) \cite{bemporad2007robust,kouvaritakis2016model}, NMPC
\cite{rawlings2017model,allgower2004nonlinear,mayne2014model,grune2017nonlinear,saltik2018outlook},
and their applications in various domains, including robotics
\cite{nascimento2018nonholonomic,nguyen2021model,shi2021advanced,wei2022mpc}.
This report does not aim to replicate those exhaustive reviews. Instead, it
focuses specifically on NMPC as a foundation for safe mobile robot navigation.
The goal is to provide a practical and accessible path from theoretical
concepts to mathematical proofs and implementation, emphasizing safety and
performance guarantees. It is intended for researchers, robotics engineers, and
practitioners seeking to bridge the gap between theoretical NMPC formulations
and real-world robotic applications.
  This report is not necessarily meant to remain fixed over time. If someone
finds an error in the presented theory, please reach out via the given email
addresses. We are happy to update the document if necessary.

</details>


### [152] [OpenNav: Open-World Navigation with Multimodal Large Language Models](https://arxiv.org/abs/2507.18033)
*Mingfeng Yuan,Letian Wang,Steven L. Waslander*

Main category: cs.RO

TL;DR: 提出了一种基于多模态大语言模型的机器人导航新方法，能理解复杂指令并生成导航路径，已在模拟和真实环境中验证。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人导航和规划任务中，语言描述与实际机器人动作之间的鸿沟，特别是在开放世界中，超越预定义的运动原语的限制。

Method: 利用多模态大语言模型（MLLMs）的跨模态理解和代码生成能力，与视觉-语言感知模型交互，生成鸟瞰图价值图，整合语义和空间信息。通过大规模自动驾驶数据集（AVDs）和真实机器人（Husky）进行验证。

Result: 在自动驾驶数据集（AVDs）上验证了该框架在户外导航任务中的零样本能力，能够执行多样化的自然语言导航指令，并对物体检测错误和语言歧义具有鲁棒性。在室内和室外场景的Husky机器人上进行了验证，证明了其真实世界的鲁棒性和适用性。

Conclusion: 该研究提出了一种零样本视觉-语言导航框架，能够处理开放集指令和开放集物体，通过多模态大语言模型（MLLMs）整合语义和空间信息，并利用自动驾驶数据集和真实机器人进行了验证。

Abstract: Pre-trained large language models (LLMs) have demonstrated strong
common-sense reasoning abilities, making them promising for robotic navigation
and planning tasks. However, despite recent progress, bridging the gap between
language descriptions and actual robot actions in the open-world, beyond merely
invoking limited predefined motion primitives, remains an open challenge. In
this work, we aim to enable robots to interpret and decompose complex language
instructions, ultimately synthesizing a sequence of trajectory points to
complete diverse navigation tasks given open-set instructions and open-set
objects. We observe that multi-modal large language models (MLLMs) exhibit
strong cross-modal understanding when processing free-form language
instructions, demonstrating robust scene comprehension. More importantly,
leveraging their code-generation capability, MLLMs can interact with
vision-language perception models to generate compositional 2D bird-eye-view
value maps, effectively integrating semantic knowledge from MLLMs with spatial
information from maps to reinforce the robot's spatial understanding. To
further validate our approach, we effectively leverage large-scale autonomous
vehicle datasets (AVDs) to validate our proposed zero-shot vision-language
navigation framework in outdoor navigation tasks, demonstrating its capability
to execute a diverse range of free-form natural language navigation
instructions while maintaining robustness against object detection errors and
linguistic ambiguities. Furthermore, we validate our system on a Husky robot in
both indoor and outdoor scenes, demonstrating its real-world robustness and
applicability. Supplementary videos are available at
https://trailab.github.io/OpenNav-website/

</details>


### [153] [Modular Robot and Landmark Localisation Using Relative Bearing Measurements](https://arxiv.org/abs/2507.18070)
*Behzad Zamani,Jochen Trumpf,Chris Manzie*

Main category: cs.RO

TL;DR: 提出了一种模块化的非线性最小二乘滤波方法，并集成CI算法，用于独立子系统系统，并解决了机器人-地标定位问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决由独立子系统组成的系统中状态和误差协方估计的更新问题，特别是在子系统共享估计时防止信息重复计算的问题。

Method: 提出了一种模块化的非线性最小二乘滤波方法，并集成了基于最小二乘估计的协方差交叉（CI）算法，以处理由独立子系统组成的系统中的状态和误差协方估计的更新，特别是当子系统共享估计时，能够有效防止信息重复计算。

Result: 通过与单一的联合状态滤波器进行基准测试，展示了该模块化方法的优势，并提出了一些在通信和带宽需求降低的情况下能够实现性能逐步下降的方法。

Conclusion: 该方法通过将模块化方法与协方差交叉（CI）算法相结合，实现了在由独立子系统组成的系统中的状态和误差协方估计的独立更新，即使在子系统共享估计的情况下也能有效防止信息重复计算。特别是在机器人-地标定位问题中，该方法能够处理机器人姿态和地标位置之间的耦合估计问题。

Abstract: In this paper we propose a modular nonlinear least squares filtering approach
for systems composed of independent subsystems. The state and error covariance
estimate of each subsystem is updated independently, even when a relative
measurement simultaneously depends on the states of multiple subsystems. We
integrate the Covariance Intersection (CI) algorithm as part of our solution in
order to prevent double counting of information when subsystems share estimates
with each other. An alternative derivation of the CI algorithm based on least
squares estimation makes this integration possible. We particularise the
proposed approach to the robot-landmark localization problem. In this problem,
noisy measurements of the bearing angle to a stationary landmark position
measured relative to the SE(2) pose of a moving robot couple the estimation
problems for the robot pose and the landmark position. In a randomized
simulation study, we benchmark the proposed modular method against a monolithic
joint state filter to elucidate their respective trade-offs. In this study we
also include variants of the proposed method that achieve a graceful
degradation of performance with reduced communication and bandwidth
requirements.

</details>


### [154] [A Modular Residual Learning Framework to Enhance Model-Based Approach for Robust Locomotion](https://arxiv.org/abs/2507.18138)
*Min-Gyu Kim,Dongyun Kang,Hajun Kim,Hae-Won Park*

Main category: cs.RO

TL;DR: 提出了一种结合基于模型和学习方法的混合框架，用于提高机器人运动的鲁棒性和效率。


<details>
  <summary>Details</summary>
Motivation: 为了在具有高不确定性的环境中实现鲁棒的运动能力，并提高控制性能和学习效率。

Method: 将残差模块集成到基于模型的框架（包括启发式设计的步态规划器和动态模型）中，以补偿模型失配导致的性能下降。为每个残差模块选择合适的基于学习的方法。

Result: 在具有高不确定性的环境中，与基线方法相比，该框架展示了改进的控制性能和更高的学习效率。此外，该方法还使得标称控制器对参数调整更加鲁棒。在真实四足机器人上进行的实验表明，即使存在超出模拟的未知不确定性，机器人也能成功保持平衡并跟踪指令速度。

Conclusion: 该方法通过结合基于模型和基于学习的框架的优点，实现了鲁棒的运动能力，并在具有高不确定性的环境中提高了控制性能和学习效率，同时使得标称控制器对参数调整更加鲁棒。

Abstract: This paper presents a novel approach that combines the advantages of both
model-based and learning-based frameworks to achieve robust locomotion. The
residual modules are integrated with each corresponding part of the model-based
framework, a footstep planner and dynamic model designed using heuristics, to
complement performance degradation caused by a model mismatch. By utilizing a
modular structure and selecting the appropriate learning-based method for each
residual module, our framework demonstrates improved control performance in
environments with high uncertainty, while also achieving higher learning
efficiency compared to baseline methods. Moreover, we observed that our
proposed methodology not only enhances control performance but also provides
additional benefits, such as making nominal controllers more robust to
parameter tuning. To investigate the feasibility of our framework, we
demonstrated residual modules combined with model predictive control in a real
quadrupedal robot. Despite uncertainties beyond the simulation, the robot
successfully maintains balance and tracks the commanded velocity.

</details>


### [155] [Autonomous UAV Navigation for Search and Rescue Missions Using Computer Vision and Convolutional Neural Networks](https://arxiv.org/abs/2507.18160)
*Luka Šiktar,Branimir Ćaran,Bojan Šekoranja,Marko Švaco*

Main category: cs.RO

TL;DR: 本文介绍了一个基于UAV的搜索和救援子系统，利用CNN进行人员检测、面部识别和跟踪，并使用PD控制器进行自主导航，已在初步实验中成功验证。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是开发一个利用UAV进行搜索和救援任务的子系统，特别是针对人员检测、面部识别和跟踪已识别的个人。

Method: 本文提出了一种集成UAV、ROS2框架、YOLOv11、YOLOv11-pose和dlib库CNN的子系统，用于搜索和救援任务。该系统通过CNN进行人员检测、面部识别和跟踪，并通过PD控制器和IMU数据进行自主导航。

Result: 在14名已知人员上进行的初步实验表明，所提出的子系统可以成功用于实时搜索和救援任务。

Conclusion: 该子系统已成功用于实时搜索和救援任务，并为未来的现场部署和集成自动导航奠定了基础。

Abstract: In this paper, we present a subsystem, using Unmanned Aerial Vehicles (UAV),
for search and rescue missions, focusing on people detection, face recognition
and tracking of identified individuals. The proposed solution integrates a UAV
with ROS2 framework, that utilizes multiple convolutional neural networks (CNN)
for search missions. System identification and PD controller deployment are
performed for autonomous UAV navigation. The ROS2 environment utilizes the
YOLOv11 and YOLOv11-pose CNNs for tracking purposes, and the dlib library CNN
for face recognition. The system detects a specific individual, performs face
recognition and starts tracking. If the individual is not yet known, the UAV
operator can manually locate the person, save their facial image and
immediately initiate the tracking process. The tracking process relies on
specific keypoints identified on the human body using the YOLOv11-pose CNN
model. These keypoints are used to track a specific individual and maintain a
safe distance. To enhance accurate tracking, system identification is
performed, based on measurement data from the UAVs IMU. The identified system
parameters are used to design PD controllers that utilize YOLOv11-pose to
estimate the distance between the UAVs camera and the identified individual.
The initial experiments, conducted on 14 known individuals, demonstrated that
the proposed subsystem can be successfully used in real time. The next step
involves implementing the system on a large experimental UAV for field use and
integrating autonomous navigation with GPS-guided control for rescue operations
planning.

</details>


### [156] [MoRPI-PINN: A Physics-Informed Framework for Mobile Robot Pure Inertial Navigation](https://arxiv.org/abs/2507.18206)
*Arup Kumar Sahoo,Itzik Klein*

Main category: cs.RO

TL;DR: MoRPI-PINN是一个创新的物理信息神经网络框架，通过模拟蛇行运动来提高惯性信号信噪比，从而实现高精度的机器人导航，即使在GPS等辅助导航手段失效的情况下也能有效工作。


<details>
  <summary>Details</summary>
Motivation: 为了在没有卫星导航或摄像头的情况下实现移动机器人的自主导航，需要解决仅依赖惯性传感器导致的导航方案漂移问题。

Method: 提出了一种名为MoRPI-PINN的物理信息神经网络框架，该框架通过将物理定律和约束嵌入训练过程来为基于惯性的移动机器人导航提供精确的解决方案。

Result: 实验证明，MoRPI-PINN与其他方法相比，精度提高了85%以上，证明了其在惯性导航方面的准确性和鲁棒性。

Conclusion: MoRPI-PINN是一个轻量级的框架，可以实现在边缘设备上，并应用于任何典型的移动机器人应用中，与现有方法相比，精度提高了85%以上。

Abstract: A fundamental requirement for full autonomy in mobile robots is accurate
navigation even in situations where satellite navigation or cameras are
unavailable. In such practical situations, relying only on inertial sensors
will result in navigation solution drift due to the sensors' inherent noise and
error terms. One of the emerging solutions to mitigate drift is to maneuver the
robot in a snake-like slithering motion to increase the inertial
signal-to-noise ratio, allowing the regression of the mobile robot position. In
this work, we propose MoRPI-PINN as a physics-informed neural network framework
for accurate inertial-based mobile robot navigation. By embedding physical laws
and constraints into the training process, MoRPI-PINN is capable of providing
an accurate and robust navigation solution. Using real-world experiments, we
show accuracy improvements of over 85% compared to other approaches. MoRPI-PINN
is a lightweight approach that can be implemented even on edge devices and used
in any typical mobile robot application.

</details>


### [157] [Evaluation of facial landmark localization performance in a surgical setting](https://arxiv.org/abs/2507.18248)
*Ines Frajtag,Marko Švaco,Filip Šuligoj*

Main category: cs.RO

TL;DR: 该研究测试了 MediaPipe 算法在受控手术环境中的面部地标检测性能，重点关注其在不同光照和角度下的准确性，并讨论了其在医疗程序中的潜在应用。


<details>
  <summary>Details</summary>
Motivation: 在包括医学在内的各个领域，机器人技术、计算机视觉及其应用正变得越来越普遍。许多面部检测算法已应用于神经外科、眼科和整形外科。使用这些算法的一个共同挑战是可变的照明条件和检测位置的灵活性，以识别和精确地定位患者。

Method: 提出实验测试 MediaPipe 算法在受控环境中的面部地标检测，使用自动调整位置的机器人手臂，同时手术灯和模型保持固定位置。

Result: 研究结果表明，在手术照明下提高面部地标检测的准确性，显著提高了在大偏航角和俯仰角下的检测性能。标准差/离散度的增加是由于对面部地标检测不精确造成的。

Conclusion: 该分析可用于讨论将 MediaPipe 算法整合到医疗程序中的潜力。

Abstract: The use of robotics, computer vision, and their applications is becoming
increasingly widespread in various fields, including medicine. Many face
detection algorithms have found applications in neurosurgery, ophthalmology,
and plastic surgery. A common challenge in using these algorithms is variable
lighting conditions and the flexibility of detection positions to identify and
precisely localize patients. The proposed experiment tests the MediaPipe
algorithm for detecting facial landmarks in a controlled setting, using a
robotic arm that automatically adjusts positions while the surgical light and
the phantom remain in a fixed position. The results of this study demonstrate
that the improved accuracy of facial landmark detection under surgical lighting
significantly enhances the detection performance at larger yaw and pitch
angles. The increase in standard deviation/dispersion occurs due to imprecise
detection of selected facial landmarks. This analysis allows for a discussion
on the potential integration of the MediaPipe algorithm into medical
procedures.

</details>


### [158] [ReSem3D: Refinable 3D Spatial Constraints via Fine-Grained Semantic Grounding for Generalizable Robotic Manipulation](https://arxiv.org/abs/2507.18262)
*Chenyu Su,Weiwei Shang,Chen Qian,Fei Zhang,Shuang Cong*

Main category: cs.RO

TL;DR: ReSem3D是一个统一的操作框架，用于语义多样化的环境，利用视觉基础模型（VFMs）和多模态大语言模型（MLLMs）的协同作用，实现细粒度的视觉基础和动态构建的层次化三维空间约束，以实现实时操作。


<details>
  <summary>Details</summary>
Motivation: 现有的方法存在三个主要限制：(1)约束建模中的语义粒度粗糙；(2)缺乏实时闭环规划；(3)在语义多样化的环境中鲁棒性受损。

Method: ReSem3D框架通过多模态大语言模型（MLLMs）和视觉基础模型（VFMs）的协同作用，实现了细粒度的视觉基础和动态构建的层次化三维空间约束，以实现实时操作。具体而言，该框架由MLLM中的层次化递归推理驱动，与VFMs交互，从自然语言指令和RGB-D观测中分两阶段自动构建三维空间约束：部件级提取和区域级精炼。随后，这些约束被编码为联合空间中的实时优化目标，从而能够对动态干扰做出反应。

Result: 通过在语义丰富的家庭和稀疏的化学实验室环境中的大量模拟和真实世界实验，ReSem3D在零样本条件下执行了各种操作任务，表现出强大的适应性和泛化能力。

Conclusion: ReSem3D在零样本条件下能够执行各种操作任务，表现出强大的适应性和泛化能力。

Abstract: Semantics-driven 3D spatial constraints align highlevel semantic
representations with low-level action spaces, facilitating the unification of
task understanding and execution in robotic manipulation. The synergistic
reasoning of Multimodal Large Language Models (MLLMs) and Vision Foundation
Models (VFMs) enables cross-modal 3D spatial constraint construction.
Nevertheless, existing methods have three key limitations: (1) coarse semantic
granularity in constraint modeling, (2) lack of real-time closed-loop planning,
(3) compromised robustness in semantically diverse environments. To address
these challenges, we propose ReSem3D, a unified manipulation framework for
semantically diverse environments, leveraging the synergy between VFMs and
MLLMs to achieve fine-grained visual grounding and dynamically constructs
hierarchical 3D spatial constraints for real-time manipulation. Specifically,
the framework is driven by hierarchical recursive reasoning in MLLMs, which
interact with VFMs to automatically construct 3D spatial constraints from
natural language instructions and RGB-D observations in two stages: part-level
extraction and region-level refinement. Subsequently, these constraints are
encoded as real-time optimization objectives in joint space, enabling reactive
behavior to dynamic disturbances. Extensive simulation and real-world
experiments are conducted in semantically rich household and sparse chemical
lab environments. The results demonstrate that ReSem3D performs diverse
manipulation tasks under zero-shot conditions, exhibiting strong adaptability
and generalization. Code and videos at https://resem3d.github.io.

</details>


### [159] [Adaptive Articulated Object Manipulation On The Fly with Foundation Model Reasoning and Part Grounding](https://arxiv.org/abs/2507.18276)
*Xiaojie Zhang,Yuanfei Wang,Ruihai Wu,Kunqi Xu,Yu Li,Liuyu Xiang,Hao Dong,Zhaofeng He*

Main category: cs.RO

TL;DR: AdaRPG框架利用基础模型来克服关节物体操作中的几何多样性和功能变化带来的挑战，提高了视觉归纳能力和泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有关于自适应关节物体操纵的研究在跨类别泛化方面面临两大挑战：真实世界关节物体的几何多样性给视觉感知和理解带来了复杂性，以及物体功能和机制的变化阻碍了统一的自适应操纵策略的发展。

Method: AdaRPG框架利用基础模型提取物体部件，构建了一个部件级可供性标注数据集来训练可供性模型，并利用基础模型中的通用知识来推理复杂机制，生成高级控制代码来调用原始技能函数。

Result: 模拟和真实世界实验证明了AdaRPG在新的关节物体类别中具有强大的泛化能力。

Conclusion: AdaRPG框架通过利用基础模型提取部件，增强了功能原始技能的视觉归纳能力，并利用基础模型中的通用知识来推理复杂机制，从而在新的关节对象类别中展现出强大的泛化能力。

Abstract: Articulated objects pose diverse manipulation challenges for robots. Since
their internal structures are not directly observable, robots must adaptively
explore and refine actions to generate successful manipulation trajectories.
While existing works have attempted cross-category generalization in adaptive
articulated object manipulation, two major challenges persist: (1) the
geometric diversity of real-world articulated objects complicates visual
perception and understanding, and (2) variations in object functions and
mechanisms hinder the development of a unified adaptive manipulation strategy.
To address these challenges, we propose AdaRPG, a novel framework that
leverages foundation models to extract object parts, which exhibit greater
local geometric similarity than entire objects, thereby enhancing visual
affordance generalization for functional primitive skills. To support this, we
construct a part-level affordance annotation dataset to train the affordance
model. Additionally, AdaRPG utilizes the common knowledge embedded in
foundation models to reason about complex mechanisms and generate high-level
control codes that invoke primitive skill functions based on part affordance
inference. Simulation and real-world experiments demonstrate AdaRPG's strong
generalization ability across novel articulated object categories.

</details>


### [160] [AF-RLIO: Adaptive Fusion of Radar-LiDAR-Inertial Information for Robust Odometry in Challenging Environments](https://arxiv.org/abs/2507.18317)
*Chenglong Qian,Yang Xu,Xiufang Shi,Jiming Chen,Liang Li*

Main category: cs.RO

TL;DR: 提出了一种名为AF-RLIO的自适应融合方法，该方法集成了4D毫米波雷达、激光雷达、IMU和GPS，以提高在复杂环境下的机器人导航和姿态估计的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统单传感器（如激光雷达或GPS）在烟雾、隧道和恶劣天气等复杂动态环境中导航的性能下降问题，提出了一种多传感器融合方法。

Method: 1.预处理模块：利用雷达数据去除动态点并确定激光雷达的性能下降条件。 2.动态感知多模态里程计：选择合适的点云数据进行扫描到地图匹配，并通过迭代误差状态卡尔曼滤波器与IMU紧密耦合。 3.因子图优化模块：平衡里程计和GPS数据的权重，构建姿态图进行优化。

Result: 在数据集和真实机器人环境中进行了评估和测试，证明了AF-RLIO在挑战性条件下的有效性和优势。

Conclusion: 该方法在烟雾和隧道等挑战性条件下，在鲁棒性和准确性方面优于现有方法，证明了其在复杂环境下的有效性和优势。

Abstract: In robotic navigation, maintaining precise pose estimation and navigation in
complex and dynamic environments is crucial. However, environmental challenges
such as smoke, tunnels, and adverse weather can significantly degrade the
performance of single-sensor systems like LiDAR or GPS, compromising the
overall stability and safety of autonomous robots. To address these challenges,
we propose AF-RLIO: an adaptive fusion approach that integrates 4D
millimeter-wave radar, LiDAR, inertial measurement unit (IMU), and GPS to
leverage the complementary strengths of these sensors for robust odometry
estimation in complex environments. Our method consists of three key modules.
Firstly, the pre-processing module utilizes radar data to assist LiDAR in
removing dynamic points and determining when environmental conditions are
degraded for LiDAR. Secondly, the dynamic-aware multimodal odometry selects
appropriate point cloud data for scan-to-map matching and tightly couples it
with the IMU using the Iterative Error State Kalman Filter. Lastly, the factor
graph optimization module balances weights between odometry and GPS data,
constructing a pose graph for optimization. The proposed approach has been
evaluated on datasets and tested in real-world robotic environments,
demonstrating its effectiveness and advantages over existing methods in
challenging conditions such as smoke and tunnels.

</details>


### [161] [G2S-ICP SLAM: Geometry-aware Gaussian Splatting ICP SLAM](https://arxiv.org/abs/2507.18344)
*Gyuhyeon Pak,Hae Min Cho,Euntai Kim*

Main category: cs.RO

TL;DR: 提出了一种名为G2S-ICP SLAM的新型SLAM系统，使用高斯表面表示场景，实现了高精度、高保真度的实时3D重建和定位。


<details>
  <summary>Details</summary>
Motivation: 为了在SLAM管线中集成表面对齐的高斯圆盘，并提出了一种几何感知的损失函数来监督光度、深度和法线一致性。

Method: 提出了一种新颖的几何感知RGB-D高斯表面SLAM系统G2S-ICP SLAM，该系统通过使用约束于局部切平面的高斯分布来表示场景元素，实现了高保真3D重建和鲁棒的实时相机姿态跟踪。将表面对齐的高斯圆盘集成到通用ICP框架中，引入各向异性协方差先验，并提出了一种几何感知的损失函数来监督光度、深度和法线一致性。

Result: 该系统实现了实时运行，同时保持了视觉和几何保真度，并在Replica和TUM-RGBD数据集上进行了广泛的实验验证，证明其在定位精度和重建完整性方面优于现有SLAM系统。

Conclusion: G2S-ICP SLAM在定位精度、重建完整性和渲染质量方面优于先前SLAM系统。

Abstract: In this paper, we present a novel geometry-aware RGB-D Gaussian Splatting
SLAM system, named G2S-ICP SLAM. The proposed method performs high-fidelity 3D
reconstruction and robust camera pose tracking in real-time by representing
each scene element using a Gaussian distribution constrained to the local
tangent plane. This effectively models the local surface as a 2D Gaussian disk
aligned with the underlying geometry, leading to more consistent depth
interpretation across multiple viewpoints compared to conventional 3D
ellipsoid-based representations with isotropic uncertainty. To integrate this
representation into the SLAM pipeline, we embed the surface-aligned Gaussian
disks into a Generalized ICP framework by introducing anisotropic covariance
prior without altering the underlying registration formulation. Furthermore we
propose a geometry-aware loss that supervises photometric, depth, and normal
consistency. Our system achieves real-time operation while preserving both
visual and geometric fidelity. Extensive experiments on the Replica and
TUM-RGBD datasets demonstrate that G2S-ICP SLAM outperforms prior SLAM systems
in terms of localization accuracy, reconstruction completeness, while
maintaining the rendering quality.

</details>


### [162] [Residual Koopman Model Predictive Control for Enhanced Vehicle Dynamics with Small On-Track Data Input](https://arxiv.org/abs/2507.18396)
*Yonghao Fu,Cheng Hu,Haokun Xiong,Zhangpeng Bao,Wenyuan Du,Edoardo Ghignone,Michele Magno,Lei Xie,Hongye Su*

Main category: cs.RO

TL;DR: RKMPC通过结合LMPC和基于神经网络的残差模型，在保证模型可解释性的同时，提高了跟踪性能和鲁棒性，并减少了对训练数据的需求。


<details>
  <summary>Details</summary>
Motivation: 传统的纯跟踪（PP）控制未能考虑车辆模型约束，影响了驾驶安全。而模型预测控制（MPC）虽然能优化控制动作，但其性能高度依赖于车辆模型的准确性。传统的车辆建模方法在捕捉非线性动力学和保持计算效率之间存在固有权衡，导致控制性能下降。

Method: 提出了一种名为残差库普曼模型预测控制（RKMPC）的框架，该框架采用双线性模型预测控制（LMPC）架构来计算控制输入。LMPC基于车辆运动学模型计算基线控制输入，而基于神经网络的RKMPC则计算补偿输入。最终的控制指令是这两个组件的总和。

Result: RKMPC所需的训练数据仅为传统库普曼模型预测控制（KMPC）的20%，同时实现了更优越的跟踪性能。与传统的LMPC相比，RKMPC将横向误差减小了11.7%-22.1%，将航向误差减小了8.9%-15.8%，并将前轮转向稳定性提高了多达27.6%。

Conclusion: RKMPC通过结合LMPC和基于神经网络的残差模型，在保证模型可解释性的同时，提高了跟踪性能和鲁棒性，并减少了对训练数据的需求。

Abstract: In vehicle trajectory tracking tasks, the simplest approach is the Pure
Pursuit (PP) Control. However, this single-point preview tracking strategy
fails to consider vehicle model constraints, compromising driving safety. Model
Predictive Control (MPC) as a widely adopted control method, optimizes control
actions by incorporating mechanistic models and physical constraints. While its
control performance critically depends on the accuracy of vehicle modeling.
Traditional vehicle modeling approaches face inherent trade-offs between
capturing nonlinear dynamics and maintaining computational efficiency, often
resulting in reduced control performance. To address these challenges, this
paper proposes Residual Koopman Model Predictive Control (RKMPC) framework.
This method uses two linear MPC architecture to calculate control inputs: a
Linear Model Predictive Control (LMPC) computes the baseline control input
based on the vehicle kinematic model, and a neural network-based RKMPC
calculates the compensation input. The final control command is obtained by
adding these two components. This design preserves the reliability and
interpretability of traditional mechanistic model while achieving performance
optimization through residual modeling. This method has been validated on the
Carsim-Matlab joint simulation platform and a physical 1:10 scale F1TENTH
racing car. Experimental results show that RKMPC requires only 20% of the
training data needed by traditional Koopman Model Predictive Control (KMPC)
while delivering superior tracking performance. Compared to traditional LMPC,
RKMPC reduces lateral error by 11.7%-22.1%, decreases heading error by
8.9%-15.8%, and improves front-wheel steering stability by up to 27.6%. The
implementation code is available at: https://github.com/ZJU-DDRX/Residual
Koopman.

</details>


### [163] [Evaluating the Pre-Dressing Step: Unfolding Medical Garments Via Imitation Learning](https://arxiv.org/abs/2507.18436)
*David Blanco-Mulero,Júlia Borràs,Carme Torras*

Main category: cs.RO

TL;DR: 机器人辅助穿衣需要解决衣物折叠问题。本研究提出预穿衣步骤，通过模仿学习和视觉分类，有效解决了折叠衣物的处理问题，并发现结合运动比单一高动态运动更有效。


<details>
  <summary>Details</summary>
Motivation: 机器人辅助穿衣在临床环境中具有潜力，但现有研究忽略了衣物（如病号服和围裙）的预先折叠状态，需要额外的解开步骤。

Method: 本研究利用模仿学习了包括高加速和低加速运动在内的三种操纵原语，并采用视觉分类器对服装状态（闭合、部分打开、完全打开）进行分类。

Result: 本研究提出的预穿衣步骤，通过结合运动和分类器，能够有效处理折叠的衣物，提高了效率。

Conclusion: 结合运动组合和分类器可以有效地增强打开配置，但高动态运动对刚拆包的服装效果不佳。

Abstract: Robotic-assisted dressing has the potential to significantly aid both
patients as well as healthcare personnel, reducing the workload and improving
the efficiency in clinical settings. While substantial progress has been made
in robotic dressing assistance, prior works typically assume that garments are
already unfolded and ready for use. However, in medical applications gowns and
aprons are often stored in a folded configuration, requiring an additional
unfolding step. In this paper, we introduce the pre-dressing step, the process
of unfolding garments prior to assisted dressing. We leverage imitation
learning for learning three manipulation primitives, including both high and
low acceleration motions. In addition, we employ a visual classifier to
categorise the garment state as closed, partly opened, and fully opened. We
conduct an empirical evaluation of the learned manipulation primitives as well
as their combinations. Our results show that highly dynamic motions are not
effective for unfolding freshly unpacked garments, where the combination of
motions can efficiently enhance the opening configuration.

</details>


### [164] [A Novel Monte-Carlo Compressed Sensing and Dictionary Learning Method for the Efficient Path Planning of Remote Sensing Robots](https://arxiv.org/abs/2507.18462)
*Alghalya Al-Hajri,Ejmen Al-Ubejdij,Aiman Erbad,Ali Safa*

Main category: cs.RO

TL;DR: 该研究首次探索了如何利用压缩感知（CS）测量矩阵的结构来优化机器人环境数据收集的采样轨迹。通过结合字典学习（DL）和蒙特卡洛优化框架，该方法在减少机器人行程距离和提高重建准确性方面取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用压缩感知（CS）测量矩阵的结构来设计优化的机器人环境数据收集采样轨迹。

Method: 结合了压缩感知（CS）和字典学习（DL），并通过蒙特卡洛优化框架生成测量矩阵，以优化机器人采样轨迹。

Result: 实验结果表明，该方法可将机器人行程距离减少到全覆盖路径的10%以下，同时将重建准确性与基于DCT和多项式字典的传统CS方法相比提高了五倍以上，与先前提出的信息路径规划（IPP）方法相比提高了两倍。

Conclusion: 提出了一种新的蒙特卡洛优化框架，用于为机器人环境数据收集生成测量矩阵，以最小化机器人路径长度和信号重建误差。

Abstract: In recent years, Compressed Sensing (CS) has gained significant interest as a
technique for acquiring high-resolution sensory data using fewer measurements
than traditional Nyquist sampling requires. At the same time, autonomous
robotic platforms such as drones and rovers have become increasingly popular
tools for remote sensing and environmental monitoring tasks, including
measurements of temperature, humidity, and air quality. Within this context,
this paper presents, to the best of our knowledge, the first investigation into
how the structure of CS measurement matrices can be exploited to design
optimized sampling trajectories for robotic environmental data collection. We
propose a novel Monte Carlo optimization framework that generates measurement
matrices designed to minimize both the robot's traversal path length and the
signal reconstruction error within the CS framework. Central to our approach is
the application of Dictionary Learning (DL) to obtain a data-driven sparsifying
transform, which enhances reconstruction accuracy while further reducing the
number of samples that the robot needs to collect. We demonstrate the
effectiveness of our method through experiments reconstructing $NO_2$ pollution
maps over the Gulf region. The results indicate that our approach can reduce
robot travel distance to less than $10\%$ of a full-coverage path, while
improving reconstruction accuracy by over a factor of five compared to
traditional CS methods based on DCT and polynomial dictionaries, as well as by
a factor of two compared to previously-proposed Informative Path Planning (IPP)
methods.

</details>


### [165] [Experimental Comparison of Whole-Body Control Formulations for Humanoid Robots in Task Acceleration and Task Force Spaces](https://arxiv.org/abs/2507.18502)
*Sait Sovukluk,Grazia Zambella,Tobias Egle,Christian Ott*

Main category: cs.RO

TL;DR: 本文对比了人形机器人的两种全身控制方法（ID-WBC和PB-WBC），通过实验分析了它们在不同工况下的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于，尽管ID-WBC和PB-WBC在理想条件下都预测稳定，但它们在面对实际的关节摩擦、传感器噪声、未建模外部干扰和不完美接触条件时的鲁棒性尚不明确。

Method: 本文采用实验方法，在人形机器人平台上对比了逆动力学全身控制（ID-WBC）和基于被动性的全身控制（PB-WBC）这两种控制策略。

Result: 实验结果表明，两种控制方法在摆荡足位姿控制、负重和不负重下蹲以及跳跃等任务中表现出不同的性能和特点，具体体现了各自的优势和劣势。

Conclusion: 该研究通过在机器人平台上进行实验，比较了两种全身控制方法的优缺点，为未来的机器人控制研究提供了参考。

Abstract: This paper studies the experimental comparison of two different whole-body
control formulations for humanoid robots: inverse dynamics whole-body control
(ID-WBC) and passivity-based whole-body control (PB-WBC). The two controllers
fundamentally differ from each other as the first is formulated in task
acceleration space and the latter is in task force space with passivity
considerations. Even though both control methods predict stability under ideal
conditions in closed-loop dynamics, their robustness against joint friction,
sensor noise, unmodeled external disturbances, and non-perfect contact
conditions is not evident. Therefore, we analyze and experimentally compare the
two controllers on a humanoid robot platform through swing foot position and
orientation control, squatting with and without unmodeled additional weights,
and jumping. We also relate the observed performance and characteristic
differences with the controller formulations and highlight each controller's
advantages and disadvantages.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [166] [ASP-Assisted Symbolic Regression: Uncovering Hidden Physics in Fluid Mechanics](https://arxiv.org/abs/2507.17777)
*Theofanis Aravanis,Grigorios Chrimatopoulos,Mohammad Ferdows,Michalis Xenos,Efstratios Em Tzirtzilakis*

Main category: cs.AI

TL;DR: 符号回归（SR）能从流体模拟数据中提取简洁、可解释的方程，并与解析解一致。结合ASP知识表示后，SR模型更可靠且符合物理原理。


<details>
  <summary>Details</summary>
Motivation: 在流体动力学领域，对底层流动物理学的理解与准确预测同等重要。因此，本研究的动机是利用符号回归（SR）这一无需预设模型结构即可揭示复杂物理系统中可解释数学关系的工具，来模拟基础的三维不可压缩流。

Method: 本研究使用PySR库将符号回归应用于三维不可压缩流体在矩形通道中的层流流动，直接从数值模拟数据中推导出描述轴向速度和压力的紧凑符号方程。此外，提出了一种将SR与ASP（答案集编程）相结合的混合方法，以确保生成的符号表达式不仅统计准确，而且在物理上合理，并遵循领域特定原理。

Result: 通过PySR库，研究成功从数值模拟数据中推导出紧凑的符号方程，这些方程不仅近似了所研究流动的抛物线速度分布和压降，而且与文献中的解析解完全吻合。提出的SR/ASP混合框架确保了SR生成的符号表达式既统计准确又物理合理。

Conclusion: 该研究展示了符号回归（SR）在简化复杂流体行为为简洁、可解释的方程方面的能力，并强调了知识表示方法（如ASP）在提高数据驱动的SR模型的可靠性以及使其符合领域原理方面的潜力。这些混合方法为需要可解释预测和实时数据分析的场景提供了基础。

Abstract: Unlike conventional Machine-Learning (ML) approaches, often criticized as
"black boxes", Symbolic Regression (SR) stands out as a powerful tool for
revealing interpretable mathematical relationships in complex physical systems,
requiring no a priori assumptions about models' structures. Motivated by the
recognition that, in fluid mechanics, an understanding of the underlying flow
physics is as crucial as accurate prediction, this study applies SR to model a
fundamental three-dimensional (3D) incompressible flow in a rectangular
channel, focusing on the (axial) velocity and pressure fields under laminar
conditions. By employing the PySR library, compact symbolic equations were
derived directly from numerical simulation data, revealing key characteristics
of the flow dynamics. These equations not only approximate the parabolic
velocity profile and pressure drop observed in the studied fluid flow, but also
perfectly coincide with analytical solutions from the literature. Furthermore,
we propose an innovative approach that integrates SR with the
knowledge-representation framework of Answer Set Programming (ASP), combining
the generative power of SR with the declarative reasoning strengths of ASP. The
proposed hybrid SR/ASP framework ensures that the SR-generated symbolic
expressions are not only statistically accurate, but also physically plausible,
adhering to domain-specific principles. Overall, the study highlights two key
contributions: SR's ability to simplify complex flow behaviours into concise,
interpretable equations, and the potential of knowledge-representation
approaches to improve the reliability and alignment of data-driven SR models
with domain principles. Insights from the examined 3D channel flow pave the way
for integrating such hybrid approaches into efficient frameworks, [...] where
explainable predictions and real-time data analysis are crucial.

</details>


### [167] [Agentic AI framework for End-to-End Medical Data Inference](https://arxiv.org/abs/2507.18115)
*Soorya Ram Shimgekar,Shayan Vassef,Abhay Goyal,Navin Kumar,Koustuv Saha*

Main category: cs.AI

TL;DR: 提出了一种 Agentic AI 框架，通过一系列专用代理自动处理临床数据管道（从提取到推理），以降低成本并提高效率。


<details>
  <summary>Details</summary>
Motivation: 在医疗保健领域构建和部署机器学习解决方案由于预处理工作流不完整、模型兼容性问题以及严格的数据隐私限制，成本高昂且耗费大量人力。本研究提出了一种 Agentic AI 框架，旨在解决这些挑战。

Method: 介绍了一种能够自动化从数据提取到模型推理的整个临床数据管道的 Agentic AI 框架。该框架由一系列模块化的、任务特定的代理组成，这些代理可以处理结构化和非结构化数据，并自动执行特征选择、模型选择和预处理推荐。

Result: 在老年病学、姑息治疗和结肠镜成像的公开数据集上对该系统进行了评估，证明了其处理结构化和非结构化数据的能力，并成功实现了端到端的自动化机器学习流程。

Conclusion: 通过自动化机器学习生命周期中摩擦较大的阶段，该框架减少了对重复专家干预的需求，为在临床环境中运行人工智能提供了可扩展、经济高效的途径。

Abstract: Building and deploying machine learning solutions in healthcare remains
expensive and labor-intensive due to fragmented preprocessing workflows, model
compatibility issues, and stringent data privacy constraints. In this work, we
introduce an Agentic AI framework that automates the entire clinical data
pipeline, from ingestion to inference, through a system of modular,
task-specific agents. These agents handle both structured and unstructured
data, enabling automatic feature selection, model selection, and preprocessing
recommendation without manual intervention. We evaluate the system on publicly
available datasets from geriatrics, palliative care, and colonoscopy imaging.
For example, in the case of structured data (anxiety data) and unstructured
data (colonoscopy polyps data), the pipeline begins with file-type detection by
the Ingestion Identifier Agent, followed by the Data Anonymizer Agent ensuring
privacy compliance, where we first identify the data type and then anonymize
it. The Feature Extraction Agent identifies features using an embedding-based
approach for tabular data, extracting all column names, and a multi-stage
MedGemma-based approach for image data, which infers modality and disease name.
These features guide the Model-Data Feature Matcher Agent in selecting the
best-fit model from a curated repository. The Preprocessing Recommender Agent
and Preprocessing Implementor Agent then apply tailored preprocessing based on
data type and model requirements. Finally, the ``Model Inference Agent" runs
the selected model on the uploaded data and generates interpretable outputs
using tools like SHAP, LIME, and DETR attention maps. By automating these
high-friction stages of the ML lifecycle, the proposed framework reduces the
need for repeated expert intervention, offering a scalable, cost-efficient
pathway for operationalizing AI in clinical environments.

</details>


### [168] [I2I-STRADA -- Information to Insights via Structured Reasoning Agent for Data Analysis](https://arxiv.org/abs/2507.17874)
*SaiBarath Sundar,Pranav Satheesan,Udayaadithya Avadhanam*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recent advances in agentic systems for data analysis have emphasized
automation of insight generation through multi-agent frameworks, and
orchestration layers. While these systems effectively manage tasks like query
translation, data transformation, and visualization, they often overlook the
structured reasoning process underlying analytical thinking. Reasoning large
language models (LLMs) used for multi-step problem solving are trained as
general-purpose problem solvers. As a result, their reasoning or thinking steps
do not adhere to fixed processes for specific tasks. Real-world data analysis
requires a consistent cognitive workflow: interpreting vague goals, grounding
them in contextual knowledge, constructing abstract plans, and adapting
execution based on intermediate outcomes. We introduce I2I-STRADA
(Information-to-Insight via Structured Reasoning Agent for Data Analysis), an
agentic architecture designed to formalize this reasoning process. I2I-STRADA
focuses on modeling how analysis unfolds via modular sub-tasks that reflect the
cognitive steps of analytical reasoning. Evaluations on the DABstep and DABench
benchmarks show that I2I-STRADA outperforms prior systems in planning coherence
and insight alignment, highlighting the importance of structured cognitive
workflows in agent design for data analysis.

</details>


### [169] [SMARTAPS: Tool-augmented LLMs for Operations Management](https://arxiv.org/abs/2507.17927)
*Timothy Tin Long Yu,Mahdi Mostajabdaveh,Jabo Serge Byusa,Rindra Ramamonjison,Giuseppe Carenini,Kun Mao,Zirui Zhou,Yong Zhang*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large language models (LLMs) present intriguing opportunities to enhance user
interaction with traditional algorithms and tools in real-world applications.
An advanced planning system (APS) is a sophisticated software that leverages
optimization to help operations planners create, interpret, and modify an
operational plan. While highly beneficial, many customers are priced out of
using an APS due to the ongoing costs of consultants responsible for
customization and maintenance. To address the need for a more accessible APS
expressed by supply chain planners, we present SmartAPS, a conversational
system built on a tool-augmented LLM. Our system provides operations planners
with an intuitive natural language chat interface, allowing them to query
information, perform counterfactual reasoning, receive recommendations, and
execute scenario analysis to better manage their operation. A short video
demonstrating the system has been released: https://youtu.be/KtIrJjlDbyw

</details>


### [170] [Synthesis of timeline-based planning strategies avoiding determinization](https://arxiv.org/abs/2507.17988)
*Dario Della Monica,Angelo Montanari,Pietro Sala*

Main category: cs.AI

TL;DR: 本文提出了一种新的定性时间线规划方法，通过映射到确定性有限自动机来简化规划策略的合成，并识别了满足此方法的Allen关系子集。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有方法中需要昂贵确定化步骤的限制，直接合成规划策略。

Method: 通过将定性时间线规划的一个片段映射到确定性有限自动机的非空性问题来解决。

Result: 识别出了满足特定条件的定性时间线规划片段，该片段的规划存在性问题可直接映射到确定性有限自动机的非空性问题，从而能够合成规划策略。识别出了Allen关系的最大化子集，该子集满足确定性片段的要求。

Conclusion: 本文识别出了定性时间线规划的一个片段，其规划存在性问题可以直接映射到确定性有限自动机的非空性问题，从而可以合成规划策略。此外，还识别出了最大化满足该确定性片段的Allen关系子集。

Abstract: Qualitative timeline-based planning models domains as sets of independent,
but
  interacting, components whose behaviors over time, the timelines, are
governed
  by sets of qualitative temporal constraints (ordering relations), called
  synchronization rules.
  Its plan-existence problem has been shown to be PSPACE-complete; in
  particular, PSPACE-membership has been proved via reduction to the
  nonemptiness problem for nondeterministic finite automata.
  However, nondeterministic automata cannot be directly used to synthesize
  planning strategies as a costly determinization step is needed.
  In this paper, we identify a fragment of qualitative timeline-based planning
  whose plan-existence problem can be directly mapped into the nonemptiness
  problem of deterministic finite automata, which can then
  synthesize strategies.
  In addition, we identify a maximal subset of Allen's relations that fits into
  such a deterministic fragment.

</details>


### [171] [Multi-Agent Guided Policy Optimization](https://arxiv.org/abs/2507.18059)
*Yueheng Li,Guangming Xie,Zongqing Lu*

Main category: cs.AI

TL;DR: MAGPO is a new MARL framework that improves upon CTDE by better using centralized training and providing theoretical guarantees. It uses an auto-regressive joint policy for exploration and aligns it with decentralized policies for deployability. Experiments show it outperforms existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing CTDE methods often underutilize centralized training or lack theoretical guarantees, necessitating a better approach for cooperative MARL under practical constraints.

Method: MAGPO uses an auto-regressive joint policy for scalable, coordinated exploration and explicitly aligns it with decentralized policies to ensure deployability under partial observability. Theoretical guarantees of monotonic policy improvement are provided.

Result: MAGPO was empirically evaluated on 43 tasks across 6 diverse environments, demonstrating consistent outperformance of strong CTDE baselines and matching or surpassing fully centralized approaches.

Conclusion: MAGPO is a principled and practical solution for decentralized multi-agent learning, consistently outperforming CTDE baselines and matching or surpassing fully centralized approaches.

Abstract: Due to practical constraints such as partial observability and limited
communication, Centralized Training with Decentralized Execution (CTDE) has
become the dominant paradigm in cooperative Multi-Agent Reinforcement Learning
(MARL). However, existing CTDE methods often underutilize centralized training
or lack theoretical guarantees. We propose Multi-Agent Guided Policy
Optimization (MAGPO), a novel framework that better leverages centralized
training by integrating centralized guidance with decentralized execution.
MAGPO uses an auto-regressive joint policy for scalable, coordinated
exploration and explicitly aligns it with decentralized policies to ensure
deployability under partial observability. We provide theoretical guarantees of
monotonic policy improvement and empirically evaluate MAGPO on 43 tasks across
6 diverse environments. Results show that MAGPO consistently outperforms strong
CTDE baselines and matches or surpasses fully centralized approaches, offering
a principled and practical solution for decentralized multi-agent learning. Our
code and experimental data can be found in https://github.com/liyheng/MAGPO.

</details>


### [172] [E.A.R.T.H.: Structuring Creative Evolution through Model Error in Generative AI](https://arxiv.org/abs/2507.18004)
*Yusen Peng,Shuhua Mao*

Main category: cs.AI

TL;DR: AI can be more creative by learning from its mistakes using the E.A.R.T.H. framework, which turns errors into creative assets through a five-stage process involving generation, amplification, selection, transformation, and feedback, leading to more novel and impactful outputs.


<details>
  <summary>Details</summary>
Motivation: To explore how AI can move beyond imitation toward genuine creativity by leveraging model-generated errors.

Method: The paper proposes the E.A.R.T.H. framework, a five-stage generative pipeline (Error generation, Amplification, Refine selection, Transform, Harness feedback) that transforms model-generated errors into creative assets, using structured prompts, semantic scoring, and human-in-the-loop evaluation with LLaMA-2-7B-Chat, SBERT, BERTScore, CLIP, BLIP-2, and Stable Diffusion, and a composite reward function based on novelty, surprise, and relevance.

Result: The E.A.R.T.H. framework demonstrated significant improvements in creativity scores (52.5% increase in Refine stage, final output 70.4% improvement). Refined slogans were shorter and more novel with a slight drop in relevance. Cross-modal tests showed strong slogan-to-image alignment, and human evaluations indicated a high percentage of satisfactory outputs, with metaphorical slogans outperforming literal ones. Feedback highlighted stylistic precision and emotional resonance.

Conclusion: The error-centered, feedback-driven generation enhances creativity, offering a scalable path toward self-evolving, human-aligned creative AI.

Abstract: How can AI move beyond imitation toward genuine creativity? This paper
proposes the E.A.R.T.H. framework, a five-stage generative pipeline that
transforms model-generated errors into creative assets through Error
generation, Amplification, Refine selection, Transform, and Harness feedback.
Drawing on cognitive science and generative modeling, we posit that "creative
potential hides in failure" and operationalize this via structured prompts,
semantic scoring, and human-in-the-loop evaluation. Implemented using
LLaMA-2-7B-Chat, SBERT, BERTScore, CLIP, BLIP-2, and Stable Diffusion, the
pipeline employs a composite reward function based on novelty, surprise, and
relevance. At the Refine stage, creativity scores increase by 52.5% (1.179 to
1.898, t = -5.56, p < 0.001), with final outputs reaching 2.010 - a 70.4%
improvement. Refined slogans are 48.4% shorter, 40.7% more novel, with only a
4.0% drop in relevance. Cross-modal tests show strong slogan-to-image alignment
(CLIPScore: 0.249; BERTScore F1: 0.816). In human evaluations, 60% of outputs
scored >= 4.0, with metaphorical slogans (avg. 4.09) outperforming literal ones
(3.99). Feedback highlights stylistic precision and emotional resonance. These
results demonstrate that error-centered, feedback-driven generation enhances
creativity, offering a scalable path toward self-evolving, human-aligned
creative AI.

</details>


### [173] [Does visualization help AI understand data?](https://arxiv.org/abs/2507.18022)
*Victoria R. Li,Johnathan Sun,Martin Wattenberg*

Main category: cs.AI

TL;DR: 图表有助于AI系统（如GPT 4.1和Claude 3.5）进行数据分析，尤其是在处理复杂数据集时，可以提高数据描述的准确性和精确度。


<details>
  <summary>Details</summary>
Motivation: 探究图表是否能帮助AI系统进行数据分析。

Method: 通过进行一系列实验，对比了在有散点图和无散点图的情况下，GPT 4.1和Claude 3.5在三个代表性分析任务中的表现，并与提供空白图表和提供错误数据图表的基线进行了比较。

Result: 在有散点图的情况下，AI系统描述合成数据集更精确、更准确，尤其是在数据集变得复杂时。实验结果表明，性能的提升源于图表的实际内容。

Conclusion: AI系统（例如GPT 4.1和Claude 3.5）像人类一样，可以通过图表分析数据，并且在处理复杂数据集时尤其受益。

Abstract: Charts and graphs help people analyze data, but can they also be useful to AI
systems? To investigate this question, we perform a series of experiments with
two commercial vision-language models: GPT 4.1 and Claude 3.5. Across three
representative analysis tasks, the two systems describe synthetic datasets more
precisely and accurately when raw data is accompanied by a scatterplot,
especially as datasets grow in complexity. Comparison with two baselines --
providing a blank chart and a chart with mismatched data -- shows that the
improved performance is due to the content of the charts. Our results are
initial evidence that AI systems, like humans, can benefit from visualization.

</details>


### [174] [Logical Characterizations of GNNs with Mean Aggregation](https://arxiv.org/abs/2507.18145)
*Moritz Schönherr,Carsten Lutz*

Main category: cs.AI

TL;DR: 均值GNN的表达能力在不同设置下与特定逻辑系统相当，但通常弱于其他聚合函数GNN。


<details>
  <summary>Details</summary>
Motivation: 研究均值聚合函数的GNN的表达能力，并与其它聚合函数（如最大值和求和）进行比较。

Method: 通过研究GNN的聚合函数为均值时的表达能力，并在非均匀和均匀设置下分别进行分析。

Result: 在非均匀设置中，均值GNN的表达能力与Ratio模态逻辑相同。在均匀设置中，均值GNN的表达能力与不交错模态逻辑相同。

Conclusion: 在非均匀设置中，均值GNN与Ratio模态逻辑的表达能力相同，但弱于和GNN。在均匀设置中，均值GNN的表达能力与不交错模态逻辑相同，弱于和GNN和最大GNN。

Abstract: We study the expressive power of graph neural networks (GNNs) with mean as
the aggregation function. In the non-uniform setting, we show that such GNNs
have exactly the same expressive power as ratio modal logic, which has modal
operators expressing that at least a certain ratio of the successors of a
vertex satisfies a specified property. The non-uniform expressive power of mean
GNNs is thus higher than that of GNNs with max aggregation, but lower than for
sum aggregation--the latter are characterized by modal logic and graded modal
logic, respectively. In the uniform setting, we show that the expressive power
relative to MSO is exactly that of alternation-free modal logic, under the
natural assumptions that combination functions are continuous and
classification functions are thresholds. This implies that, relative to MSO and
in the uniform setting, mean GNNs are strictly less expressive than sum GNNs
and max GNNs. When any of the assumptions is dropped, the expressive power
increases.

</details>


### [175] [AlphaGo Moment for Model Architecture Discovery](https://arxiv.org/abs/2507.18074)
*Yixiu Liu,Yang Nan,Weixian Xu,Xiangkun Hu,Lyumanshan Ye,Zhen Qin,Pengfei Liu*

Main category: cs.AI

TL;DR: ASI-Arch是一个人工智能系统，它能够自主地研究和发现新的神经网络架构，解决了AI研究中的人类认知瓶颈，并发现了106个先进的线性注意力架构。


<details>
  <summary>Details</summary>
Motivation: AI研究的进展受到人类认知能力的线性限制，而AI系统能力呈指数级增长，形成开发瓶颈。ASI-Arch旨在打破这一限制，实现AI对其自身架构的创新。

Method: ASI-Arch系统通过自主进行1773次实验，利用20000多个GPU小时，完成了从假设新架构概念到实现、训练和验证的端到端研究。

Result: ASI-Arch发现了106个创新的、最先进的线性注意力架构，这些架构展示了超越人类设计的潜在设计原则，并揭示了架构创新的新途径。

Conclusion: ASI-Arch通过自主假设、实现、训练和验证新颖的架构概念，实现了端到端的科学研究，发现了106个创新的、最先进的线性注意力架构，并且其发现能力可以通过计算来扩展，从而将研究进展从人类限制转变为可计算扩展的过程。

Abstract: While AI systems demonstrate exponentially improving capabilities, the pace
of AI research itself remains linearly bounded by human cognitive capacity,
creating an increasingly severe development bottleneck. We present ASI-Arch,
the first demonstration of Artificial Superintelligence for AI research
(ASI4AI) in the critical domain of neural architecture discovery--a fully
autonomous system that shatters this fundamental constraint by enabling AI to
conduct its own architectural innovation. Moving beyond traditional Neural
Architecture Search (NAS), which is fundamentally limited to exploring
human-defined spaces, we introduce a paradigm shift from automated optimization
to automated innovation. ASI-Arch can conduct end-to-end scientific research in
the domain of architecture discovery, autonomously hypothesizing novel
architectural concepts, implementing them as executable code, training and
empirically validating their performance through rigorous experimentation and
past experience. ASI-Arch conducted 1,773 autonomous experiments over 20,000
GPU hours, culminating in the discovery of 106 innovative, state-of-the-art
(SOTA) linear attention architectures. Like AlphaGo's Move 37 that revealed
unexpected strategic insights invisible to human players, our AI-discovered
architectures demonstrate emergent design principles that systematically
surpass human-designed baselines and illuminate previously unknown pathways for
architectural innovation. Crucially, we establish the first empirical scaling
law for scientific discovery itself--demonstrating that architectural
breakthroughs can be scaled computationally, transforming research progress
from a human-limited to a computation-scalable process. We provide
comprehensive analysis of the emergent design patterns and autonomous research
capabilities that enabled these breakthroughs, establishing a blueprint for
self-accelerating AI systems.

</details>


### [176] [Actively evaluating and learning the distinctions that matter: Vaccine safety signal detection from emergency triage notes](https://arxiv.org/abs/2507.18123)
*Sedigh Khademi,Christopher Palmer,Muhammad Javed,Hazel Clothier,Jim Buttery,Gerardo Luis Dimaguila,Jim Black*

Main category: cs.AI

TL;DR: 本研究利用自然语言处理和主动学习技术，通过分析急诊记录来监测疫苗安全。


<details>
  <summary>Details</summary>
Motivation: 由于临床试验中安全数据收集窗口有限以及早期广泛实施，对获得许可后监测系统的需求日益增长。急诊分诊记录包含进入卫生系统时的专家、简洁的患者生命体征信息，可以显著促进及时的疫苗安全信号监测。

Method: 本研究旨在利用自然语言处理技术和主动学习，快速开发一个分类器，从急诊记录中检测潜在的疫苗安全问题。

Result: 与仅基于关键词的分类相比，自然语言处理提供了一种更准确、更有效的方法。主动学习优化了标注过程和标注数据的质量，可以更快地实现模型并提高模型性能。

Conclusion: 这项工作结合了主动学习、数据增强和主动学习及评估技术，创建了一个分类器，用于加强对急诊分诊记录的疫苗安全监测。

Abstract: The rapid development of COVID-19 vaccines has showcased the global
communitys ability to combat infectious diseases. However, the need for
post-licensure surveillance systems has grown due to the limited window for
safety data collection in clinical trials and early widespread implementation.
This study aims to employ Natural Language Processing techniques and Active
Learning to rapidly develop a classifier that detects potential vaccine safety
issues from emergency department notes. ED triage notes, containing expert,
succinct vital patient information at the point of entry to health systems, can
significantly contribute to timely vaccine safety signal surveillance. While
keyword-based classification can be effective, it may yield false positives and
demand extensive keyword modifications. This is exacerbated by the infrequency
of vaccination-related ED presentations and their similarity to other reasons
for ED visits. NLP offers a more accurate and efficient alternative, albeit
requiring annotated data, which is often scarce in the medical field. Active
learning optimizes the annotation process and the quality of annotated data,
which can result in faster model implementation and improved model performance.
This work combines active learning, data augmentation, and active learning and
evaluation techniques to create a classifier that is used to enhance vaccine
safety surveillance from ED triage notes.

</details>


### [177] [Decoupling Knowledge and Reasoning in LLMs: An Exploration Using Cognitive Dual-System Theory](https://arxiv.org/abs/2507.18178)
*Mutian Yang,Jiandong Gao,Ji Wu*

Main category: cs.AI

TL;DR: 该研究提出一个框架，利用“快思慢想”区分LLMs的知识与推理，发现推理具领域特异性，知识与推理均随参数量提升（知识提升尤甚），且知识与推理在网络层级分布不同。


<details>
  <summary>Details</summary>
Motivation: 区分LLMs的知识和推理能力对于模型分析、可解释性和开发至关重要。

Method: 受双系统认知理论启发，提出认知归因框架，将LLMs的认知分解为知识检索（阶段1）和推理调整（阶段2）。通过在“快速思考”和“慢速思考”两种不同认知模式下提示LLMs生成答案来分离这两个阶段，并分析不同认知模式下的性能以量化知识和推理的贡献。该框架应用于15个LLMs和3个数据集。

Result: 1.推理调整具有领域特异性，有利于推理密集型领域（如数学、物理、化学），可能损害知识密集型领域。
2.参数缩放能同时提升知识和推理，其中知识提升更为显著。参数缩放使LLMs的推理更加审慎，但智能性提升较为适度。
3.知识主要存在于较低的网络层，而推理则运行在较高层。

Conclusion: 该研究提出了一个认知归因框架，用于区分大型语言模型（LLMs）的知识和推理能力。研究结果表明，推理能力具有领域特异性，参数缩放对知识和推理都有提升作用（知识提升更明显），知识主要存在于较低的网络层，而推理则存在于较高层。该框架为理解LLMs提供了新的视角，并对现有研究（如缩放定律、分层知识编辑和小模型推理限制）提供了新的见解。

Abstract: While large language models (LLMs) leverage both knowledge and reasoning
during inference, the capacity to distinguish between them plays a pivotal role
in model analysis, interpretability, and development. Inspired by dual-system
cognitive theory, we propose a cognition attribution framework to decouple the
contribution of knowledge and reasoning. In particular, the cognition of LLMs
is decomposed into two distinct yet complementary phases: knowledge retrieval
(Phase 1) and reasoning adjustment (Phase 2). To separate these phases, LLMs
are prompted to generate answers under two different cognitive modes, fast
thinking and slow thinking, respectively. The performance under different
cognitive modes is analyzed to quantify the contribution of knowledge and
reasoning. This architecture is employed to 15 LLMs across 3 datasets. Results
reveal: (1) reasoning adjustment is domain-specific, benefiting
reasoning-intensive domains (e.g., mathematics, physics, and chemistry) and
potentially imparing knowledge-intensive domains. (2) Parameter scaling
improves both knowledge and reasoning, with knowledge improvements being more
pronounced. Additionally, parameter scaling make LLMs reasoning significantly
more prudent, while moderately more intelligent. (3) Knowledge primarily
resides in lower network layers, while reasoning operates in higher layers. Our
framework not only helps understand LLMs from a "decoupling" perspective, but
also provides new insights into existing research, including scaling laws,
hierarchical knowledge editing, and limitations of small-model reasoning.

</details>


### [178] [Comparing Non-minimal Semantics for Disjunction in Answer Set Programming](https://arxiv.org/abs/2507.18198)
*Felicidad Aguado,Pedro Cabalar,Brais Muñiz,Gilberto Pérez,Concepción Vidal*

Main category: cs.AI

TL;DR: 本文比较了四种非模型最小化的ASP析取语义，发现其中三种是相同的，并且是第四种语义的超集。


<details>
  <summary>Details</summary>
Motivation: 旨在比较四种不同的ASP析取语义，它们不遵循模型最小化原则，并探究它们之间的关系。

Method: 比较了四种不同的ASP（Answer Set Programming）中析取的语义，并证明了其中三种语义（Forks、Justified Models和DI语义的松弛版本）实际上是相同的，而第四种语义（Strongly Supported Models）则将析取视为经典逻辑。

Result: 证明了Forks、Justified Models和DI语义的松弛版本是相同的，并且这种共同的语义总是提供一个程序稳定模型的超集，并且严格强于Strongly Supported Models语义。

Conclusion: 三种非模型最小化语义（Forks、Justified Models和DI语义的松弛版本）是相同的，并且是Strongly Supported Models语义的超集。

Abstract: In this paper, we compare four different semantics for disjunction in Answer
Set Programming that, unlike stable models, do not adhere to the principle of
model minimality. Two of these approaches, Cabalar and Mu\~niz' \emph{Justified
Models} and Doherty and Szalas' \emph{Strongly Supported Models}, directly
provide an alternative non-minimal semantics for disjunction. The other two,
Aguado et al's \emph{Forks} and Shen and Eiter's \emph{Determining Inference}
(DI) semantics, actually introduce a new disjunction connective, but are
compared here as if they constituted new semantics for the standard disjunction
operator. We are able to prove that three of these approaches (Forks, Justified
Models and a reasonable relaxation of the DI semantics) actually coincide,
constituting a common single approach under different definitions. Moreover,
this common semantics always provides a superset of the stable models of a
program (in fact, modulo any context) and is strictly stronger than the fourth
approach (Strongly Supported Models), that actually treats disjunctions as in
classical logic.

</details>


### [179] [Foundations for Risk Assessment of AI in Protecting Fundamental Rights](https://arxiv.org/abs/2507.18290)
*Antonino Rotolo,Beatrice Ferrigno,Jose Miguel Angel Garcia Godinez,Claudio Novelli,Giovanni Sartor*

Main category: cs.AI

TL;DR: 本研究提出了一个整合了定义平衡和可废止推理的AI风险评估框架，以应对欧盟《AI法案》下的法律合规性和基本权利保护的复杂性。该框架通过分析AI部署场景和对基本权利的影响，为AI风险分析提供了哲学基础，并支持对高风险AI系统和通用目的AI系统进行评估。未来的工作将侧重于开发形式化模型和算法，以实现更有效的AI风险管理。


<details>
  <summary>Details</summary>
Motivation: 本章旨在提出一个概念框架，用于定性评估人工智能（AI）的风险，特别是在欧盟《AI法案》的背景下。

Method: 我们的方法强调需要分析AI部署场景，并识别潜在的法律侵权行为和对基本权利的多层影响。在此分析的基础上，我们为AI风险分析的逻辑描述提供了哲学基础。具体来说，我们考虑了概念上掌握AI部署场景与基本权利之间相互作用的基本构建块，在可废止推理中纳入定义平衡以及关于权利的背景促进或降级。

Result: 这种分层方法使得对高风险AI系统和通用目的AI（GPAI）系统进行更可操作的评估模型成为可能，并强调了后者的更广泛适用性。未来的工作旨在开发一个形式化模型和有效的算法，以增强AI风险评估，将理论见解与实际应用相结合，以支持负责任的AI治理。

Conclusion: 本研究提出了一个用于人工智能（AI）定性风险评估的概念框架，特别关注欧盟《AI法案》的背景。该框架通过整合定义平衡和可废止推理，来处理法律合规性和基本权利保护的复杂性。定义平衡采用比例分析来解决相互竞争的权利之间的冲突，而可废止推理则适应法律决策的动态性。

Abstract: This chapter introduces a conceptual framework for qualitative risk
assessment of AI, particularly in the context of the EU AI Act. The framework
addresses the complexities of legal compliance and fundamental rights
protection by itegrating definitional balancing and defeasible reasoning.
Definitional balancing employs proportionality analysis to resolve conflicts
between competing rights, while defeasible reasoning accommodates the dynamic
nature of legal decision-making. Our approach stresses the need for an analysis
of AI deployment scenarios and for identifying potential legal violations and
multi-layered impacts on fundamental rights. On the basis of this analysis, we
provide philosophical foundations for a logical account of AI risk analysis. In
particular, we consider the basic building blocks for conceptually grasping the
interaction between AI deployment scenarios and fundamental rights,
incorporating in defeasible reasoning definitional balancing and arguments
about the contextual promotion or demotion of rights. This layered approach
allows for more operative models of assessment of both high-risk AI systems and
General Purpose AI (GPAI) systems, emphasizing the broader applicability of the
latter. Future work aims to develop a formal model and effective algorithms to
enhance AI risk assessment, bridging theoretical insights with practical
applications to support responsible AI governance.

</details>


### [180] [The AlphaPhysics Term Rewriting System for Marking Algebraic Expressions in Physics Exams](https://arxiv.org/abs/2507.18337)
*Peter Baumgartner,Lachlan McGinness*

Main category: cs.AI

TL;DR: 提出了一种结合LLM和自动推理（SMT和项重写）的自动物理考试批改方法，并在1500多份真实学生答卷上进行了评估。


<details>
  <summary>Details</summary>
Motivation: 自动批改物理考试，解决评估学生类型化答案相对于参考答案正确性的难题。

Method: 本研究提出了一种结合计算机代数系统、SMT求解器和项重写系统的方法，用于自动批改物理考试。首先，利用大型语言模型解析和纠正学生答案中的错误，并将其转换为机器可读格式。然后，应用自动推理技术，包括现成的SMT求解和针对涉及三角函数表达式的物理问题的项重写系统，来评估学生解决方案的正确性。

Result: 该方法在2023年澳大利亚物理奥林匹亚竞赛的1500多份真实学生考试答卷上进行了评估，证明了其在处理物理问题（特别是涉及三角函数表达式）的自动批改能力。

Conclusion: 基于SMT求解器和项重写系统的自动推理技术被应用于评估学生答案的正确性，并在2023年澳大利亚物理奥林匹克竞赛的1500多份真实学生试卷上进行了评估。

Abstract: We present our method for automatically marking Physics exams. The marking
problem consists in assessing typed student answers for correctness with
respect to a ground truth solution. This is a challenging problem that we seek
to tackle using a combination of a computer algebra system, an SMT solver and a
term rewriting system. A Large Language Model is used to interpret and remove
errors from student responses and rewrite these in a machine readable format.
Once formalized and language-aligned, the next step then consists in applying
automated reasoning techniques for assessing student solution correctness. We
consider two methods of automated theorem proving: off-the-shelf SMT solving
and term rewriting systems tailored for physics problems involving
trigonometric expressions. The development of the term rewrite system and
establishing termination and confluence properties was not trivial, and we
describe it in some detail in the paper. We evaluate our system on a rich pool
of over 1500 real-world student exam responses from the 2023 Australian Physics
Olympiad.

</details>


### [181] [Reasoning Beyond the Obvious: Evaluating Divergent and Convergent Thinking in LLMs for Financial Scenarios](https://arxiv.org/abs/2507.18368)
*Zhuang Qiang Bok,Watson Wei Khong Chua*

Main category: cs.AI

TL;DR: ConDiFi是一个新的金融LLM评估基准，用于衡量发散和收敛思维。GPT-4o在可操作性方面表现不佳，而DeepSeek-R1和Cohere Command R+表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM推理基准主要关注事实准确性或逐步逻辑，但在金融领域，专业人士不仅需要做出最优决策，还需要在不确定性下生成具有创造性和可行性的未来。

Method: 引入了一个名为ConDiFi的基准，该基准结合了发散和收敛两种思维能力，用于评估金融任务中的LLM。基准包含607个宏观金融提示用于发散推理，以及990个多步对抗选择题用于收敛推理。评估了14个领先模型。

Result: GPT-4o在生成新颖性和可操作性方面表现不佳，尽管其语言流畅度很高。DeepSeek-R1和Cohere Command R+等模型在生成适合投资决策的可操作性见解方面表现优异。

Conclusion: ConDiFi提供了一个新的视角来评估LLM在金融领域安全和战略部署所需的推理能力。

Abstract: Most reasoning benchmarks for LLMs emphasize factual accuracy or step-by-step
logic. In finance, however, professionals must not only converge on optimal
decisions but also generate creative, plausible futures under uncertainty. We
introduce ConDiFi, a benchmark that jointly evaluates divergent and convergent
thinking in LLMs for financial tasks.
  ConDiFi features 607 macro-financial prompts for divergent reasoning and 990
multi-hop adversarial MCQs for convergent reasoning. Using this benchmark, we
evaluated 14 leading models and uncovered striking differences. Despite high
fluency, GPT-4o underperforms on Novelty and Actionability. In contrast, models
like DeepSeek-R1 and Cohere Command R+ rank among the top for generating
actionable, insights suitable for investment decisions. ConDiFi provides a new
perspective to assess reasoning capabilities essential to safe and strategic
deployment of LLMs in finance.

</details>


### [182] [Revisiting LLM Reasoning via Information Bottleneck](https://arxiv.org/abs/2507.18391)
*Shiye Lei,Zhihao Cheng,Kai Jia,Dacheng Tao*

Main category: cs.AI

TL;DR: 通过信息瓶颈理论和IB正则化，提升大语言模型在数学推理任务上的表现，并且易于实现。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR方法在引导LLM进行推理时，很大程度上依赖启发式和直觉驱动，缺乏原则性的方法论。本研究旨在为LLM推理提供理论基础，并提出一种新的优化框架。

Method: 提出了一种基于信息瓶颈（IB）原理的理论分析，并推导了IB正则化方法，该方法可以无缝集成到现有的基于RL的后训练框架中，只需一行代码修改。

Result: 在多个数学推理基准和RL算法上，IB正则化技术展现了持续的性能提升，证明了其有效性。

Conclusion: 该研究提出了IB-aware reasoning optimization (IBRO)框架，并通过IB正则化技术，在数学推理基准和RL算法上验证了LLM推理能力的提升。

Abstract: Large language models (LLMs) have recently demonstrated remarkable progress
in reasoning capabilities through reinforcement learning with verifiable
rewards (RLVR). By leveraging simple rule-based rewards, RL effectively
incentivizes LLMs to produce extended chain-of-thought (CoT) reasoning
trajectories, progressively guiding them toward correct answers. However,
existing approaches remain largely heuristic and intuition-driven, limiting the
development of principled methodologies. In this paper, we present a
theoretical characterization of LLM reasoning grounded in information
bottleneck (IB) principle, introducing IB-aware reasoning optimization (IBRO),
a framework that encourages reasoning trajectories to be both informative about
the final correct answer and generalizable across diverse prompts. We derive a
practical token-level surrogate objective and propose an efficient
approximation, resulting in the lightweight IB regularization method. This
technique integrates seamlessly into existing RL-based post-training frameworks
without additional computational overhead, requiring only a one-line code
modification. Empirically, we validate IB regularization across multiple
mathematical reasoning benchmarks and RL algorithms, demonstrating consistent
improvements in LLM reasoning performance.

</details>


### [183] [Optimising Call Centre Operations using Reinforcement Learning: Value Iteration versus Proximal Policy Optimisation](https://arxiv.org/abs/2507.18398)
*Kwong Ho Li,Wathsala Karunarathne*

Main category: cs.AI

TL;DR: 强化学习（RL），特别是PPO，能有效优化呼叫中心路由，减少客户等待时间和员工空闲时间。


<details>
  <summary>Details</summary>
Motivation: 本文旨在利用强化学习（RL）优化呼叫中心的呼叫路由，以最小化客户等待时间和员工空闲时间。

Method: 本文比较了两种强化学习（RL）方法：一种是基于模型的价值迭代（VI）方法，另一种是无模型的近端策略优化（PPO）方法。模型方面，采用了理论模型和结合了离散事件模拟（DES）与OpenAI Gym环境的模拟模型。问题被构建为技能路由（SBR）框架下的马尔可夫决策过程（MDP），并假设客户到达率为泊松分布，服务时间和放弃时间为指数分布。

Result: 通过1000次测试，PPO策略在模拟模型中持续获得最高奖励，并实现了最低的客户等待时间和员工空闲时间，尽管其训练时间更长。

Conclusion: RL（包括基于模型和无模型的PPO方法）在优化呼叫中心路由方面表现出色，能有效减少客户等待时间和员工空闲时间，其中PPO在训练时间较长的情况下表现最佳。

Abstract: This paper investigates the application of Reinforcement Learning (RL) to
optimise call routing in call centres to minimise client waiting time and staff
idle time. Two methods are compared: a model-based approach using Value
Iteration (VI) under known system dynamics, and a model-free approach using
Proximal Policy Optimisation (PPO) that learns from experience. For the
model-based approach, a theoretical model is used, while a simulation model
combining Discrete Event Simulation (DES) with the OpenAI Gym environment is
developed for model-free learning. Both models frame the problem as a Markov
Decision Process (MDP) within a Skills-Based Routing (SBR) framework, with
Poisson client arrivals and exponentially distributed service and abandonment
times. For policy evaluation, random, VI, and PPO policies are evaluated using
the simulation model. After 1,000 test episodes, PPO consistently achives the
highest rewards, along with the lowest client waiting time and staff idle time,
despite requiring longer training time.

</details>


### [184] [GPU Accelerated Compact-Table Propagation](https://arxiv.org/abs/2507.18413)
*Enrico Santi,Fabio Tardivo,Agostino Dovier,Andrea Formisano*

Main category: cs.AI

TL;DR: 通过GPU加速CT算法，有效处理大规模表约束。


<details>
  <summary>Details</summary>
Motivation: 虽然表约束在理论上可以模拟任何其他约束，并且有许多高效的传播算法，但现实世界中的大规模表约束（包含成百上千个有效案例）仍然难以用标准的CPU方法有效处理。

Method: 本文关注一种特定的约束形式——表约束，用于通过枚举备选项来指定变量值的条件。该研究详细介绍了紧凑表（CT）算法，这是目前表约束的最先进的传播算法。

Result: 该研究通过GPU加速CT算法，有效解决了大规模表约束的处理瓶颈，并在实验中得到了验证。

Conclusion: 该研究通过利用现代GPU的大规模计算能力来处理大型表约束，并报告了GPU加速的CT算法的设计和实现、其与现有约束求解器的集成以及在大量实例上的实验验证。

Abstract: Constraint Programming developed within Logic Programming in the Eighties;
nowadays all Prolog systems encompass modules capable of handling constraint
programming on finite domains demanding their solution to a constraint solver.
This work focuses on a specific form of constraint, the so-called table
constraint, used to specify conditions on the values of variables as an
enumeration of alternative options. Since every condition on a set of finite
domain variables can be ultimately expressed as a finite set of cases, Table
can, in principle, simulate any other constraint. These characteristics make
Table one of the most studied constraints ever, leading to a series of
increasingly efficient propagation algorithms. Despite this, it is not uncommon
to encounter real-world problems with hundreds or thousands of valid cases that
are simply too many to be handled effectively with standard CPU-based
approaches. In this paper, we deal with the Compact-Table (CT) algorithm, the
state-of-the-art propagation algorithms for Table. We describe how CT can be
enhanced by exploiting the massive computational power offered by modern GPUs
to handle large Table constraints. In particular, we report on the design and
implementation of GPU-accelerated CT, on its integration into an existing
constraint solver, and on an experimental validation performed on a significant
set of instances.

</details>


### [185] [On the Performance of Concept Probing: The Influence of the Data (Extended Version)](https://arxiv.org/abs/2507.18550)
*Manuel de Sousa Ribeiro,Afonso Leote,João Leite*

Main category: cs.AI

TL;DR: This paper examines how the data used to train concept probing models affects their performance in image classification and provides concept labels for datasets.


<details>
  <summary>Details</summary>
Motivation: Concept probing is a method to interpret artificial neural networks by training classifiers to map internal representations into human-defined concepts. While previous research focused on the model being probed or the probing model, this paper addresses the gap in understanding the data requirements for training these probing models.

Method: The research focuses on concept probing in image classification tasks and examines the effect of data used to train probing models on their performance.

Result: The paper investigates the effect of data used to train probing models on their performance and makes concept labels for two widely used datasets available.

Conclusion: The study investigates the impact of data used for training concept probing models on their performance in image classification tasks and makes concept labels for two widely used datasets available.

Abstract: Concept probing has recently garnered increasing interest as a way to help
interpret artificial neural networks, dealing both with their typically large
size and their subsymbolic nature, which ultimately renders them unfeasible for
direct human interpretation. Concept probing works by training additional
classifiers to map the internal representations of a model into human-defined
concepts of interest, thus allowing humans to peek inside artificial neural
networks. Research on concept probing has mainly focused on the model being
probed or the probing model itself, paying limited attention to the data
required to train such probing models. In this paper, we address this gap.
Focusing on concept probing in the context of image classification tasks, we
investigate the effect of the data used to train probing models on their
performance. We also make available concept labels for two widely used
datasets.

</details>


### [186] [SafeWork-R1: Coevolving Safety and Intelligence under the AI-45$^{\circ}$ Law](https://arxiv.org/abs/2507.18576)
*Shanghai AI Lab,:,Yicheng Bao,Guanxu Chen,Mingkang Chen,Yunhao Chen,Chiyu Chen,Lingjie Chen,Sirui Chen,Xinquan Chen,Jie Cheng,Yu Cheng,Dengke Deng,Yizhuo Ding,Dan Ding,Xiaoshan Ding,Yi Ding,Zhichen Dong,Lingxiao Du,Yuyu Fan,Xinshun Feng,Yanwei Fu,Yuxuan Gao,Ruijun Ge,Tianle Gu,Lujun Gui,Jiaxuan Guo,Qianxi He,Yuenan Hou,Xuhao Hu,Hong Huang,Kaichen Huang,Shiyang Huang,Yuxian Jiang,Shanzhe Lei,Jie Li,Lijun Li,Hao Li,Juncheng Li,Xiangtian Li,Yafu Li,Lingyu Li,Xueyan Li,Haotian Liang,Dongrui Liu,Qihua Liu,Zhixuan Liu,Bangwei Liu,Huacan Liu,Yuexiao Liu,Zongkai Liu,Chaochao Lu,Yudong Lu,Xiaoya Lu,Zhenghao Lu,Qitan Lv,Caoyuan Ma,Jiachen Ma,Xiaoya Ma,Zhongtian Ma,Lingyu Meng,Ziqi Miao,Yazhe Niu,Yuezhang Peng,Yuan Pu,Han Qi,Chen Qian,Xingge Qiao,Jingjing Qu,Jiashu Qu,Wanying Qu,Wenwen Qu,Xiaoye Qu,Qihan Ren,Qingnan Ren,Qingyu Ren,Jing Shao,Wenqi Shao,Shuai Shao,Dongxing Shi,Xin Song,Xinhao Song,Yan Teng,Xuan Tong,Yingchun Wang,Xuhong Wang,Shujie Wang,Xin Wang,Yige Wang,Yixu Wang,Yuanfu Wang,Futing Wang,Ruofan Wang,Wenjie Wang,Yajie Wang,Muhao Wei,Xiaoyu Wen,Fenghua Weng,Yuqi Wu,Yingtong Xiong,Xingcheng Xu,Chao Yang,Yue Yang,Yang Yao,Yulei Ye,Zhenyun Yin,Yi Yu,Bo Zhang,Qiaosheng Zhang,Jinxuan Zhang,Yexin Zhang,Yinqiang Zheng,Hefeng Zhou,Zhanhui Zhou,Pengyu Zhu,Qingzi Zhu,Yubo Zhu,Bowen Zhou*

Main category: cs.AI

TL;DR: 本研究提出了SafeLadder框架和SafeWork-R1模型，通过创新的安全强化学习和验证机制，显著提升了AI的安全性和能力，且优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有AI对齐方法（如RLHF）仅能学习人类偏好的局限性，本研究旨在开发一种能够让AI具备内在安全推理和自我反思能力的方法，从而实现AI的安全性和能力的协同发展。

Method: 研究提出了SafeLadder框架，该框架通过大规模、渐进式的安全导向强化学习进行后训练，并辅以一套多原则验证器。此外，还实现了两种不同的推理时干预方法和一种审议式搜索机制，以执行步骤级验证。

Result: SafeWork-R1在安全相关基准测试上的平均性能比其基础模型Qwen2.5-VL-78B提升了46.54%，且未损害通用能力。与GPT-4.1和Claude Opus 4等领先的专有模型相比，SafeWork-R1在安全方面也达到了最先进的性能。此外，研究还开发了SafeWork-R1-InternVL3-78B、SafeWork-R1-DeepSeek-70B和SafeWork-R1-Qwen2.5VL-7B等模型，均证明了安全与能力协同发展的可行性。

Conclusion: 该研究提出的SafeLadder框架能够协同发展AI的安全性和能力，SafeWork-R1模型在安全相关基准测试中表现出显著的性能提升，并且与现有顶尖模型相比具有领先的安全性能，证明了该框架的通用性和有效性。

Abstract: We introduce SafeWork-R1, a cutting-edge multimodal reasoning model that
demonstrates the coevolution of capabilities and safety. It is developed by our
proposed SafeLadder framework, which incorporates large-scale, progressive,
safety-oriented reinforcement learning post-training, supported by a suite of
multi-principled verifiers. Unlike previous alignment methods such as RLHF that
simply learn human preferences, SafeLadder enables SafeWork-R1 to develop
intrinsic safety reasoning and self-reflection abilities, giving rise to safety
`aha' moments. Notably, SafeWork-R1 achieves an average improvement of
$46.54\%$ over its base model Qwen2.5-VL-72B on safety-related benchmarks
without compromising general capabilities, and delivers state-of-the-art safety
performance compared to leading proprietary models such as GPT-4.1 and Claude
Opus 4. To further bolster its reliability, we implement two distinct
inference-time intervention methods and a deliberative search mechanism,
enforcing step-level verification. Finally, we further develop
SafeWork-R1-InternVL3-78B, SafeWork-R1-DeepSeek-70B, and
SafeWork-R1-Qwen2.5VL-7B. All resulting models demonstrate that safety and
capability can co-evolve synergistically, highlighting the generalizability of
our framework in building robust, reliable, and trustworthy general-purpose AI.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [187] [Program Logics via Distributive Monoidal Categories](https://arxiv.org/abs/2507.18238)
*Filippo Bonchi,Elena Di Lavore,Mario Román,Sam Staton*

Main category: cs.LO

TL;DR: 本论文从命令式范畴的公理推导出程序逻辑，并介绍了用于命令式多范畴的内部语言及其组合子。


<details>
  <summary>Details</summary>
Motivation: 本文旨在从命令式范畴的公理推导出多种程序逻辑。

Method: 论文推导了命令式多范畴的内部语言，并在其上为 Dijkstra 的保护命令语言的一个变体推导了组合子。程序逻辑的规则从该内部语言中推导出来。

Result: 从该内部语言中可以推导出程序逻辑的规则。

Conclusion: 本篇论文从 the axioms of imperative categories (uniformly traced distributive copy-discard categories) 推导出多种程序逻辑，包括正确性、不正确性和关系 Hoare 逻辑。

Abstract: We derive multiple program logics, including correctness, incorrectness, and
relational Hoare logic, from the axioms of imperative categories: uniformly
traced distributive copy-discard categories. We introduce an internal language
for imperative multicategories, on top of which we derive combinators for an
adaptation of Dijkstra's guarded command language. Rules of program logics are
derived from this internal language.

</details>


### [188] [Resourceful Traces for Commuting Processes](https://arxiv.org/abs/2507.18246)
*Matthew Earnshaw,Chad Nester,Mario Román*

Main category: cs.LO

TL;DR: Mazurkiewicz traces are re-imagined as input-output transformations, creating a new way to present effectful categories. This leads to a graphical method for these categories and a way to combine them when their actions must commute but can exchange resources.


<details>
  <summary>Details</summary>
Motivation: To develop a novel notion of presentation for effectful categories by considering actions of a Mazurkiewicz trace as transformations, leading to a graphical calculus and facilitating the construction of the commuting tensor product of free effectful categories.

Method: We consider actions of a Mazurkiewicz trace not as atomic names, but as transformations from a specified type of inputs to a specified type of outputs, yielding a novel notion of presentation for effectful categories. This notion gives rise to a graphical calculus, which we use to construct the commuting tensor product of free effectful categories.

Result: A novel notion of presentation for effectful categories, a graphical calculus, and a construction of the commuting tensor product of free effectful categories that captures the combination of systems with commuting actions and resource exchange.

Conclusion: We introduce a novel notion of presentation for effectful categories by treating Mazurkiewicz trace actions as transformations between specified input and output types. This presentation yields a graphical calculus for effectful categories, enabling the construction of the commuting tensor product of free effectful categories. This construction captures the combination of systems where actions must commute while allowing resource exchange.

Abstract: We show that, when the actions of a Mazurkiewicz trace are considered not
merely as atomic (i.e., mere names) but transformations from a specified type
of inputs to a specified type of outputs, we obtain a novel notion of
presentation for effectful categories (also known as generalised Freyd
categories), a well-known algebraic structure in the semantics of
side-effecting computation. Like the usual representation of traces as graphs,
our notion of presentation gives rise to a graphical calculus for effectful
categories. We use our presentations to give a construction of the commuting
tensor product of free effectful categories, capturing the combination of
systems in which the actions of each must commute with one another, while still
permitting exchange of resources

</details>


### [189] [Distributing Retractions, Weak Distributive Laws and Applications to Monads of Hyperspaces, Continuous Valuations and Measures](https://arxiv.org/abs/2507.18418)
*Jean Goubault-Larrecq*

Main category: cs.LO

TL;DR: 本文研究了如何从两个给定的单子 $S$ 和 $T$ 以及它们之间的弱分布律来构建一个复合单子 $U$。作者提出了一种名为“分布反收缩”的方法来识别这种复合单子，并证明了分布反收缩与弱分布律之间的等价性。此外，研究还探讨了该方法在三个具体应用中的情况，涉及 Plotkin 超空间单子、连续估值单子和预示或叉集单子。


<details>
  <summary>Details</summary>
Motivation: 本文的目的是建立一个由两个单子 $S$ 和 $T$ 组合而成的复合单子 $U$。

Method: 通过展示一个分布反收缩，我们将 $ST$ 映射到 $U$。

Result: 分布反收缩和弱分布律之间存在一对一的对应关系。本文还描述了超线性或次线性估值单子的代数。

Conclusion: 在紧致 Hausdorff 空间范畴中，Plotkin 超空间单子有时被称为 Vietoris 单子，连续估值单子与 Radon 单子相吻合，由此推断相关的组合单子是归一化叉集单子。

Abstract: Given two monads $S$, $T$ on a category where idempotents split, and a weak
distributive law between them, one can build a combined monad $U$. Making
explicit what this monad $U$ is requires some effort. When we already have an
idea what $U$ should be, we show how to recognize that $U$ is indeed the
combined monad obtained from $S$ and $T$: it suffices to exhibit what we call a
distributing retraction of $ST$ onto $U$. We show that distributing retractions
and weak distributive laws are in one-to-one correspondence, in a 2-categorical
setting. We give three applications, where $S$ is the Smyth, Hoare or Plotkin
hyperspace monad, $T$ is a monad of continuous valuations, and $U$ is a monad
of previsions or of forks, depending on the case. As a byproduct, this allows
us to describe the algebras of monads of superlinear, resp. sublinear
previsions. In the category of compact Hausdorff spaces, the Plotkin hyperspace
monad is sometimes known as the Vietoris monad, the monad of probability
valuations coincides with the Radon monad, and we infer that the associated
combined monad is the monad of normalized forks.

</details>


### [190] [Well-Founded Coalgebras Meet König's Lemma](https://arxiv.org/abs/2507.18539)
*Henning Urbat,Thorsten Wißmann*

Main category: cs.LO

TL;DR: 本文将K"onig引理推广到协同代数，扩展了其在数学和计算机科学中的应用范围，并提出了构造初始代数的新方法。


<details>
  <summary>Details</summary>
Motivation: K"onig引理在数学和计算机科学中有广泛的应用。本文旨在将K"onig引理推广到更广泛的范畴，特别是协同代数，以探索其在更抽象的数学结构中的应用，并为关键的初始代数构造提供新的见解。

Method: 本文提出了K"onig引理的协同代数版本，将有限分支树推广到有限端函子H的协同代数，并将集合范畴推广到局部有限可呈现范畴C。论文中的K"onig引理陈述为，在C和H的温和假设下，每个良基协同代数都可以表示为其具有有限生成状态空间的良基子协同代数的定向连接。论文还展示了该引理在topos中的图以及名词和凸转换系统中的应用。此外，还提出了两种构造H初始代数的方法，一种是全新的，另一种是对现有方法的改进，提供了更简洁的证明。

Result: 论文成功地提出了K"onig引理的协同代数版本，并证明了其在局部有限可呈现范畴中的适用性。该引理在图、名词集合和凸集等领域得到了应用。此外，还提出了两种构造初始代数的新方法，其中一种是全新的，另一种提供了对现有方法的更简洁的证明，并揭示了良基协同代数与递归协同代数之间的关系。

Conclusion: 该论文提出了K"onig引理的一个新的协同代数版本，该版本具有两个维度的推广：从有限分支树到有限端函子H的协同代数，以及从集合的基础范畴到局部有限可呈现范畴C（如偏序集、名词集合或凸集范畴）。该协同代数K"onig引理指出，在C和H的温和假设下，每个良基协同代数都是其具有有限生成状态空间的良基子协同代数的定向连接，特别是良基协同代数范畴是局部可呈现的。作为应用，论文推导出了在 topos 中的图以及名词和凸转换系统的K"onig引理版本。此外，论文还表明，证明所依据的关键构造产生了H的初始代数（等价地，最终递归协同代数）的两个简单构造：初始代数是所有良基协同代数和所有具有有限可呈现状态空间的递归协同代数的共同极限。值得注意的是，这一结果甚至在良基协同代数是递归协同代数的真子类的情况下也成立。第一个初始代数构造是全新的，而对于第二个构造，本文的方法提供了一个简短而清晰的正确性新证明。

Abstract: K\"onig's lemma is a fundamental result about trees with countless
applications in mathematics and computer science. In contrapositive form, it
states that if a tree is finitely branching and well-founded (i.e. has no
infinite paths), then it is finite. We present a coalgebraic version of
K\"onig's lemma featuring two dimensions of generalization: from finitely
branching trees to coalgebras for a finitary endofunctor H, and from the base
category of sets to a locally finitely presentable category C, such as the
category of posets, nominal sets, or convex sets. Our coalgebraic K\"onig's
lemma states that, under mild assumptions on C and H, every well-founded
coalgebra for H is the directed join of its well-founded subcoalgebras with
finitely generated state space -- in particular, the category of well-founded
coalgebras is locally presentable. As applications, we derive versions of
K\"onig's lemma for graphs in a topos as well as for nominal and convex
transition systems. Additionally, we show that the key construction underlying
the proof gives rise to two simple constructions of the initial algebra
(equivalently, the final recursive coalgebra) for the functor H: The initial
algebra is both the colimit of all well-founded and of all recursive coalgebras
with finitely presentable state space. Remarkably, this result holds even in
settings where well-founded coalgebras form a proper subclass of recursive
ones. The first construction of the initial algebra is entirely new, while for
the second one our approach yields a short and transparent new correctness
proof.

</details>


### [191] [Proceedings 19th International Workshop on the ACL2 Theorem Prover and Its Applications](https://arxiv.org/abs/2507.18567)
*Ruben Gamboa,Panagiotis Manolios*

Main category: cs.LO

TL;DR: ACL2 is a theorem proving system that has received the 2005 ACM Software System Award.


<details>
  <summary>Details</summary>
Motivation: To present research related to the ACL2 theorem prover and its applications.

Method: ACL2 theorem proving system.

Result: The 2005 ACM Software System Award was awarded to Boyer, Kaufmann, and Moore for their work on ACL2 and the other theorem provers in the Boyer-Moore family.

Conclusion: ACL2 is a theorem proving system.

Abstract: The ACL2 Workshop series is the major technical forum for users of the ACL2
theorem proving system to present research related to the ACL2 theorem prover
and its applications. ACL2 is an industrial-strength automated reasoning
system, the latest in the Boyer-Moore family of theorem provers. The 2005 ACM
Software System Award was awarded to Boyer, Kaufmann, and Moore for their work
on ACL2 and the other theorem provers in the Boyer-Moore family.

</details>


### [192] [Approximate SMT Counting Beyond Discrete Domains](https://arxiv.org/abs/2507.18612)
*Arijit Shaw,Kuldeep S. Meel*

Main category: cs.LO

TL;DR: pact是一种用于混合SMT公式的模型计数器，它使用基于哈希的近似技术，能够高效地处理包含连续和离散变量的公式，并在实验中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于现有方法（如位 प्रकल्技术）在处理包含连续和离散变量的混合SMT公式时存在局限性，尤其是在将解投影到离散域进行计数时，因此需要一种新的方法来扩展SMT求解器的能力，以满足混合SMT公式模型计数的扩展需求。

Method: pact利用基于哈希的近似模型计数方法来估计混合SMT公式的解，并且通过优化哈希函数，使得SMT求解器的调用次数与投影变量数量呈对数关系。

Result: 在14,202个实例的基准测试中，pact成功完成了603个实例，而基线方法仅完成了13个实例，显示出pact在处理大规模混合SMT公式模型计数方面的优越性。

Conclusion: pact在混合SMT公式模型计数方面取得了显著的性能提升，相比基线方法，它能够成功处理更多的实例，并且在处理时间上也有优势。

Abstract: Satisfiability Modulo Theory (SMT) solvers have advanced automated reasoning,
solving complex formulas across discrete and continuous domains. Recent
progress in propositional model counting motivates extending SMT capabilities
toward model counting, especially for hybrid SMT formulas. Existing approaches,
like bit-blasting, are limited to discrete variables, highlighting the
challenge of counting solutions projected onto the discrete domain in hybrid
formulas.
  We introduce pact, an SMT model counter for hybrid formulas that uses
hashing-based approximate model counting to estimate solutions with theoretical
guarantees. pact makes a logarithmic number of SMT solver calls relative to the
projection variables, leveraging optimized hash functions. pact achieves
significant performance improvements over baselines on a large suite of
benchmarks. In particular, out of 14,202 instances, pact successfully finished
on 603 instances, while Baseline could only finish on 13 instances.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [193] [Technical Implementation of Tippy: Multi-Agent Architecture and System Design for Drug Discovery Laboratory Automation](https://arxiv.org/abs/2507.17852)
*Yao Fehlis,Charles Crain,Aidan Jensen,Michael Watson,James Juhasz,Paul Mandel,Betty Liu,Shawn Mahon,Daren Wilson,Nick Lynch-Jonely,Ben Leedom,David Fuller*

Main category: cs.MA

TL;DR: 本文介绍了Tippy的多代理系统，用于药物发现实验室自动化。它使用五个专用代理（Supervisor、Molecule、Lab、Analysis、Report）通过OpenAI Agents SDK和MCP进行协调。系统通过Kubernetes、Docker和CI/CD进行部署，并使用向量数据库和Envoy反向代理。该方法展示了AI代理在协调复杂实验室工作流程方面的有效性，并确保了安全性、可扩展性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 基于我们先前关于用于药物研究的agentic AI的论文中所提出的概念框架，本文对Tippy用于药物发现实验室自动化的多代理系统实现进行了全面的技术分析。

Method: 本研究提出了一个分布式微服务架构，包含五个专门的代理（Supervisor、Molecule、Lab、Analysis和Report），它们通过OpenAI Agents SDK编排进行协调，并通过Model Context Protocol (MCP)访问实验室工具。系统架构包括特定代理的工具集成、异步通信模式以及通过Git进行跟踪的全面配置管理。

Result: 生产部署策略利用Kubernetes容器编排（含Helm图表）、Docker容器化和CI/CD管道进行自动化测试和部署。该实现集成了用于RAG功能的向量数据库，并采用Envoy反向代理来实现安全的外部访问。

Conclusion: 该工作展示了专门的AI代理如何通过标准化协议有效地协调复杂实验室工作流程，同时保持安全性、可扩展性、可靠性并与现有实验室基础设施集成。

Abstract: Building on the conceptual framework presented in our previous work on
agentic AI for pharmaceutical research, this paper provides a comprehensive
technical analysis of Tippy's multi-agent system implementation for drug
discovery laboratory automation. We present a distributed microservices
architecture featuring five specialized agents (Supervisor, Molecule, Lab,
Analysis, and Report) that coordinate through OpenAI Agents SDK orchestration
and access laboratory tools via the Model Context Protocol (MCP). The system
architecture encompasses agent-specific tool integration, asynchronous
communication patterns, and comprehensive configuration management through
Git-based tracking. Our production deployment strategy utilizes Kubernetes
container orchestration with Helm charts, Docker containerization, and CI/CD
pipelines for automated testing and deployment. The implementation integrates
vector databases for RAG functionality and employs an Envoy reverse proxy for
secure external access. This work demonstrates how specialized AI agents can
effectively coordinate complex laboratory workflows while maintaining security,
scalability, reliability, and integration with existing laboratory
infrastructure through standardized protocols.

</details>


### [194] [Assemble Your Crew: Automatic Multi-agent Communication Topology Design via Autoregressive Graph Generation](https://arxiv.org/abs/2507.18224)
*Shiyuan Li,Yixin Liu,Qingsong Wen,Chengqi Zhang,Shirui Pan*

Main category: cs.MA

TL;DR: ARG-Designer是一种新颖的自回归模型，通过条件自回归图生成任务来设计多代理系统（MAS）的协作拓扑。它能够根据自然语言任务查询动态地确定代理数量、角色和通信链接，从而为特定任务创建定制化的MAS设计，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的MAS设计方法依赖于模板图修改范式，并且具有预定义的代理和硬编码的交互结构，这在很大程度上限制了它们适应特定任务需求的能力。

Method: 将MAS设计重构为一个条件自回归图生成任务，提出了一种名为ARG-Designer的新型自回归模型，该模型能够从头开始构建协作图。它以自然语言任务查询为条件，可以动态地确定所需代理的数量、从可扩展的池中选择合适的角色，并建立它们之间的通信链接。

Result: ARG-Designer能够生成定制化的拓扑结构，精确匹配不同任务的独特需求，并在实验中展示了其优越的性能、更高的代币效率和增强的可扩展性。

Conclusion: ARG-Designer在六个不同的基准测试中取得了最先进的性能，并且在代币效率和可扩展性方面表现出显著的优势，为MAS设计提供了一种灵活且可扩展的方法。

Abstract: Multi-agent systems (MAS) based on large language models (LLMs) have emerged
as a powerful solution for dealing with complex problems across diverse
domains. The effectiveness of MAS is critically dependent on its collaboration
topology, which has become a focal point for automated design research.
However, existing approaches are fundamentally constrained by their reliance on
a template graph modification paradigm with a predefined set of agents and
hard-coded interaction structures, significantly limiting their adaptability to
task-specific requirements. To address these limitations, we reframe MAS design
as a conditional autoregressive graph generation task, where both the system
composition and structure are designed jointly. We propose ARG-Designer, a
novel autoregressive model that operationalizes this paradigm by constructing
the collaboration graph from scratch. Conditioned on a natural language task
query, ARG-Designer sequentially and dynamically determines the required number
of agents, selects their appropriate roles from an extensible pool, and
establishes the optimal communication links between them. This generative
approach creates a customized topology in a flexible and extensible manner,
precisely tailored to the unique demands of different tasks. Extensive
experiments across six diverse benchmarks demonstrate that ARG-Designer not
only achieves state-of-the-art performance but also enjoys significantly
greater token efficiency and enhanced extensibility. The source code of
ARG-Designer is available at https://github.com/Shiy-Li/ARG-Designer.

</details>


### [195] [Designing Value-Aligned Traffic Agents through Conflict Sensitivity](https://arxiv.org/abs/2507.18284)
*Astrid Rakow,Joe Collenette,Maike Schwammberger,Marija Slavkovik,Gleifer Vs Alves*

Main category: cs.MA

TL;DR: 通过认知博弈论的冲突模型和价值对齐操作设计域（VODDs），在开发阶段而非运行时解决自动驾驶代理的价值冲突，实现安全且符合价值观的行为。


<details>
  <summary>Details</summary>
Motivation: 为了使自动驾驶交通代理（ATAs）的行为不仅安全，而且符合法律、社会和道德等多方面的利益相关者价值观。

Method: 采用来自认知博弈论的冲突形式模型，并将其应用于价值冲突分析，以指导ATA的设计过程，包括价值提取、能力规范、解释和自适应系统优化。

Result: 通过价值对齐操作设计域（VODDs）的理念，将模糊的价值冲突转化为结构化的行为规范，从而在开发阶段就能更好地引导和优化ATA的行为，实现价值敏感性。

Conclusion: 该研究提出了一种将冲突分析应用于自动驾驶交通代理（ATAs）设计的方法，通过价值对齐操作设计域（VODDs）来应对价值冲突，并强调在开发阶段而非运行时解决道德困境。

Abstract: Autonomous traffic agents (ATAs) are expected to act in ways tat are not only
safe, but also aligned with stakeholder values across legal, social, and moral
dimensions. In this paper, we adopt an established formal model of conflict
from epistemic game theory to support the development of such agents. We focus
on value conflicts-situations in which agents face competing goals rooted in
value-laden situations and show how conflict analysis can inform key phases of
the design process. This includes value elicitation, capability specification,
explanation, and adaptive system refinement. We elaborate and apply the concept
of Value-Aligned Operational Design Domains (VODDs) to structure autonomy in
accordance with contextual value priorities. Our approach shifts the emphasis
from solving moral dilemmas at runtime to anticipating and structuring
value-sensitive behaviour during development.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [196] [Zero-Shot Dynamic Concept Personalization with Grid-Based LoRA](https://arxiv.org/abs/2507.17963)
*Rameen Abdal,Or Patashnik,Ekaterina Deyneka,Hao Chen,Aliaksandr Siarohin,Sergey Tulyakov,Daniel Cohen-Or,Kfir Aberman*

Main category: cs.GR

TL;DR: 提出了一种用于文本到视频模型的动态概念个性化的全零样本框架，使用Grid-LoRA和Grid Fill模块，无需微调即可实现高质量、可泛化的个性化编辑。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到视频生成方法虽然能实现高质量合成，但动态概念的个性化（捕捉特定主体的外观和运动）通常需要针对每个实例进行微调，这在可扩展性方面存在限制。

Method: 本方法利用结构化的2x2视频网格，空间化组织输入和输出对，从而训练轻量级的Grid-LoRA适配器，用于在网格内进行编辑和组合。在推理时，专用的Grid Fill模块可以补全部分观察到的布局，生成时间连贯且身份保持一致的输出。

Result: 实验证明，该方法在各种主体和编辑场景下都能生成高质量且一致的结果，并且能够泛化到未训练过的概念。

Conclusion: 该方法实现了完全零样本的动态概念个性化，并能在一次前向传播中泛化到未见过的动态概念，无需任何测试时优化。

Abstract: Recent advances in text-to-video generation have enabled high-quality
synthesis from text and image prompts. While the personalization of dynamic
concepts, which capture subject-specific appearance and motion from a single
video, is now feasible, most existing methods require per-instance fine-tuning,
limiting scalability. We introduce a fully zero-shot framework for dynamic
concept personalization in text-to-video models. Our method leverages
structured 2x2 video grids that spatially organize input and output pairs,
enabling the training of lightweight Grid-LoRA adapters for editing and
composition within these grids. At inference, a dedicated Grid Fill module
completes partially observed layouts, producing temporally coherent and
identity preserving outputs. Once trained, the entire system operates in a
single forward pass, generalizing to previously unseen dynamic concepts without
any test-time optimization. Extensive experiments demonstrate high-quality and
consistent results across a wide range of subjects beyond trained concepts and
editing scenarios.

</details>


### [197] [DanceGraph: A Complementary Architecture for Synchronous Dancing Online](https://arxiv.org/abs/2507.18052)
*David Sinclair,Ademyemi Ademola,Babis Koniaris,Kenny Mitchell*

Main category: cs.GR

TL;DR: DanceGraph 解决了在线跳舞的延迟问题，通过高效的架构和交互式风格化来实现同步。


<details>
  <summary>Details</summary>
Motivation: 解决网络身体姿势共享的延迟问题，实现同步在线跳舞。

Method: DanceGraph 通过开发实时的、带宽高效的架构来最小化延迟，并减少同步音乐节奏所需的运动预测的时间。

Result: 我们提出了一个名为 DanceGraph 的架构，并展示了一种用于通过在线舞蹈修正来对节奏舞蹈进行参数化风格化的交互式方法。

Conclusion: DanceGraph 是一个用于同步在线跳舞的架构，可以克服网络身体姿势共享的延迟。

Abstract: DanceGraph is an architecture for synchronized online dancing overcoming the
latency of networked body pose sharing. We break down this challenge by
developing a real-time bandwidth-efficient architecture to minimize lag and
reduce the timeframe of required motion prediction for synchronization with the
music's rhythm. In addition, we show an interactive method for the
parameterized stylization of dance motions for rhythmic dance using online
dance correctives.

</details>


### [198] [GeoAvatar: Adaptive Geometrical Gaussian Splatting for 3D Head Avatar](https://arxiv.org/abs/2507.18155)
*SeungJun Moon,Hah Min Lew,Seungeun Lee,Ji-Su Kang,Gyeong-Moon Park*

Main category: cs.GR

TL;DR: GeoAvatar通过自适应几何高斯方法，解决了3D头像生成中身份保持与新颖姿势和表情之间的平衡问题，特别是在嘴部动画方面进行了改进，并发布了包含丰富面部表情的动态面部视频数据集。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在将高斯适应不同面部区域的几何偏差方面存在的问题，从而导致质量不佳。

Method: GeoAvatar利用自适应预分配阶段（APS）将高斯分割为刚性和柔性集，用于自适应偏移正则化。它还引入了基于嘴部解剖学和动力学的新型嘴部结构和部分变形策略，以提高嘴部动画的保真度。此外，它还提出了一种用于高斯和3DMM人脸之间精确绑定正则化的损失。

Result: GeoAvatar在重建和新颖动画场景中均取得了优于现有方法的性能。

Conclusion: GeoAvatar框架在重建和新颖动画场景中优于最先进的方法。

Abstract: Despite recent progress in 3D head avatar generation, balancing identity
preservation, i.e., reconstruction, with novel poses and expressions, i.e.,
animation, remains a challenge. Existing methods struggle to adapt Gaussians to
varying geometrical deviations across facial regions, resulting in suboptimal
quality. To address this, we propose GeoAvatar, a framework for adaptive
geometrical Gaussian Splatting. GeoAvatar leverages Adaptive Pre-allocation
Stage (APS), an unsupervised method that segments Gaussians into rigid and
flexible sets for adaptive offset regularization. Then, based on mouth anatomy
and dynamics, we introduce a novel mouth structure and the part-wise
deformation strategy to enhance the animation fidelity of the mouth. Finally,
we propose a regularization loss for precise rigging between Gaussians and 3DMM
faces. Moreover, we release DynamicFace, a video dataset with highly expressive
facial motions. Extensive experiments show the superiority of GeoAvatar
compared to state-of-the-art methods in reconstruction and novel animation
scenarios.

</details>


### [199] [PS-GS: Gaussian Splatting for Multi-View Photometric Stereo](https://arxiv.org/abs/2507.18231)
*Yixiao Chen,Bin Liang,Hanzhi Guo,Yongqing Cheng,Jiayi Zhao,Dongdong Weng*

Main category: cs.GR

TL;DR: PS-GS是一种新的多视图光度立体法逆渲染技术，通过高斯泼溅和延迟逆渲染，能够高效地重建物体几何、材质和光照，并在各种应用中表现出色。


<details>
  <summary>Details</summary>
Motivation: 在固定环境光照的逆渲染方法基础上，整合多视图光度立体法（MVPS）可以获得更精确的3D重建，但效率不高，存在挑战。

Method: 1. 使用2D高斯泼溅模型初始化几何。2. 通过包含光照计算多层感知机的延迟逆渲染进行联合优化。3. 使用未校准的光度立体法估计的法线来正则化渲染的法线图。4. 提出2D高斯射线追踪以优化入射光照。

Result: 成功实现了高效的逆渲染，并能进行新视角合成、重新照明以及材料和形状编辑。

Conclusion: PS-GS方法在合成和真实数据集的实验中，在重建精度和计算效率方面均优于现有方法。

Abstract: Integrating inverse rendering with multi-view photometric stereo (MVPS)
yields more accurate 3D reconstructions than the inverse rendering approaches
that rely on fixed environment illumination. However, efficient inverse
rendering with MVPS remains challenging. To fill this gap, we introduce the
Gaussian Splatting for Multi-view Photometric Stereo (PS-GS), which efficiently
and jointly estimates the geometry, materials, and lighting of the object that
is illuminated by diverse directional lights (multi-light). Our method first
reconstructs a standard 2D Gaussian splatting model as the initial geometry.
Based on the initialization model, it then proceeds with the deferred inverse
rendering by the full rendering equation containing a lighting-computing
multi-layer perceptron. During the whole optimization, we regularize the
rendered normal maps by the uncalibrated photometric stereo estimated normals.
We also propose the 2D Gaussian ray-tracing for single directional light to
refine the incident lighting. The regularizations and the use of multi-view and
multi-light images mitigate the ill-posed problem of inverse rendering. After
optimization, the reconstructed object can be used for novel-view synthesis,
relighting, and material and shape editing. Experiments on both synthetic and
real datasets demonstrate that our method outperforms prior works in terms of
reconstruction accuracy and computational efficiency.

</details>


### [200] [Tiny is not small enough: High-quality, low-resource facial animation models through hybrid knowledge distillation](https://arxiv.org/abs/2507.18352)
*Zhen Han,Mattias Teye,Derek Yadgaroff,Judith Bütepage*

Main category: cs.GR

TL;DR: 本研究通过知识蒸馏技术，在设备端实现了实时、高质量的语音驱动3D面部动画，解决了现有模型体积大、仅能离线运行的问题。


<details>
  <summary>Details</summary>
Motivation: 为了克服高质量、鲁棒的语音驱动3D面部动画模型训练所需的大型、多样化音频-动画对数据集的缺乏，并解决现有基于大型预训练语音编码器模型体积庞大、仅适用于离线推理的问题，本研究探索在游戏开发背景下实现设备端、实时的面部动画模型。

Method: 本研究采用混合知识蒸馏和伪标签技术。利用一个高性能的教师模型，在一个大型音频数据集中训练非常小的学生模型。学生模型仅包含卷积层和全连接层，无需注意力上下文或循环更新。

Result: 研究成功将模型内存占用减少到3.4MB，所需未来音频上下文减少到81毫秒，同时保持了高质量的面部动画效果。

Conclusion: 该研究通过混合知识蒸馏和伪标签技术，成功开发出能在设备上进行实时语音驱动3D面部动画的小型模型，内存占用最高可达3.4MB，所需未来音频上下文最短可达81毫秒，同时保持了高质量的动画效果。这为实现现实的、由模型驱动的数字角色的设备端推理奠定了基础。

Abstract: The training of high-quality, robust machine learning models for
speech-driven 3D facial animation requires a large, diverse dataset of
high-quality audio-animation pairs. To overcome the lack of such a dataset,
recent work has introduced large pre-trained speech encoders that are robust to
variations in the input audio and, therefore, enable the facial animation model
to generalize across speakers, audio quality, and languages. However, the
resulting facial animation models are prohibitively large and lend themselves
only to offline inference on a dedicated machine. In this work, we explore
on-device, real-time facial animation models in the context of game
development. We overcome the lack of large datasets by using hybrid knowledge
distillation with pseudo-labeling. Given a large audio dataset, we employ a
high-performing teacher model to train very small student models. In contrast
to the pre-trained speech encoders, our student models only consist of
convolutional and fully-connected layers, removing the need for attention
context or recurrent updates. In our experiments, we demonstrate that we can
reduce the memory footprint to up to 3.4 MB and required future audio context
to up to 81 ms while maintaining high-quality animations. This paves the way
for on-device inference, an important step towards realistic, model-driven
digital characters.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [201] [Designing efficient interventions for pre-disease states using control theory](https://arxiv.org/abs/2507.18269)
*Makito Oku*

Main category: math.OC

TL;DR: 本研究提出了一种名为MCSC的控制理论方法，用于疾病前治疗，通过稀疏控制器识别干预状态，并通过模拟和实际数据验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了在老龄化社会中延长健康预期寿命，在疾病前状态预防各种疾病至关重要，但目前数学上针对疾病前治疗的框架尚未完善。

Method: 本研究提出了一种名为马尔可夫链稀疏控制（MCSC）的疾病前治疗方法，该方法基于控制理论，将马尔可夫链上概率分布的时间演化描述为离散时间线性系统，并通过设计稀疏控制器来识别干预的候选状态。

Result: 通过数值模拟和实际数据分析验证了MCSC的有效性。

Conclusion: 该研究提出了基于马尔可夫链稀疏控制（MCSC）的方法，这是一种基于控制理论的疾病前治疗方法，旨在通过设计稀疏控制器来识别少数干预候选状态，并已通过数值模拟和实际数据分析验证了其有效性。

Abstract: To extend healthy life expectancy in an aging society, it is crucial to
prevent various diseases at pre-disease states. Although dynamical network
biomarker theory has been developed for pre-disease detection, mathematical
frameworks for pre-disease treatment have not been well established. Here I
propose a control theory-based approach for pre-disease treatment, named Markov
chain sparse control (MCSC), where time evolution of a probability distribution
on a Markov chain is described as a discrete-time linear system. By designing a
sparse controller, a few candidate states for intervention are identified. The
validity of MCSC is demonstrated using numerical simulations and real-data
analysis.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [202] [Neuromorphic Computing: A Theoretical Framework for Time, Space, and Energy Scaling](https://arxiv.org/abs/2507.17886)
*James B Aimone*

Main category: cs.NE

TL;DR: 神经形态计算（NMC）是一种低功耗的计算方式，其性能和功耗与传统计算不同，特别适合处理稀疏和可扩展的算法。


<details>
  <summary>Details</summary>
Motivation: 解释神经形态计算（NMC）的计算价值主张，并将其与传统的冯·诺依曼架构（如CPU和GPU）进行比较，以说明其作为低功耗替代品的潜力。

Method: 通过展示NMC在时间和空间上的可扩展性相当于理论上无限的处理器，并阐述其能量可扩展性与传统系统不同，即能量消耗与算法状态的导数成正比，而非绝对工作量。

Result: NMC在时间和空间上的可扩展性相当于理论上无限的处理器，但其能量可扩展性与传统系统显著不同。NMC更适合处理稀疏、可扩展且活动与目标函数成比例的算法，如迭代优化和蒙特卡洛采样。

Conclusion: 神经形态计算（NMC）可以被视为一种通用的、可编程的计算范式，尽管其与传统的存储程序架构有很大不同。

Abstract: Neuromorphic computing (NMC) is increasingly viewed as a low-power
alternative to conventional von Neumann architectures such as central
processing units (CPUs) and graphics processing units (GPUs), however the
computational value proposition has been difficult to define precisely.
  Here, we explain how NMC should be seen as general-purpose and programmable
even though it differs considerably from a conventional stored-program
architecture. We show that the time and space scaling of NMC is equivalent to
that of a theoretically infinite processor conventional system, however the
energy scaling is significantly different. Specifically, the energy of
conventional systems scales with absolute algorithm work, whereas the energy of
neuromorphic systems scales with the derivative of algorithm state. The unique
characteristics of NMC architectures make it well suited for different classes
of algorithms than conventional multi-core systems like GPUs that have been
optimized for dense numerical applications such as linear algebra. In contrast,
the unique characteristics of NMC make it ideally suited for scalable and
sparse algorithms whose activity is proportional to an objective function, such
as iterative optimization and large-scale sampling (e.g., Monte Carlo).

</details>


### [203] [Explicit Sign-Magnitude Encoders Enable Power-Efficient Multipliers](https://arxiv.org/abs/2507.18179)
*Felix Arnold,Maxence Bouvier,Ryan Amaudruz,Renzo Andri,Lukas Cavigelli*

Main category: cs.NE

TL;DR: 通过将乘法器分解为子组件并利用符号幅度编码，提高了乘法器的功率效率，特别是在AI工作负载中。


<details>
  <summary>Details</summary>
Motivation: 为了提高固定点乘法器的功率效率，该研究提出了一种分解乘法器并利用符号幅度编码优势的方法。

Method: 本研究提出了一种将固定点乘法器分解为子组件的方法，首先使用编码器模块将操作数从二的补码转换为符号幅度表示，然后通过乘法器模块执行计算操作，并以原始格式输出结果值。该方法利用了乘法中符号幅度编码的功率效率优势。为了确保计算格式不变，这两个组件是分开综合和优化的。

Result: 在标准差为3.0的正常分布输入下，4位乘法器的后综合模拟显示，与未分解的综合相比，开关活动降低了12.9%。如果放宽合规性要求且输入范围为-7至+7，开关活动降低可达33%。基于开关活动驱动的设计空间探索的综合优化方法可进一步提高5-10%的功率效率。

Conclusion: 该方法通过将固定点乘法器分解为子组件，并利用符号幅度编码的能效优势，显著提高了乘法器的功率效率。在AI工作负载的典型输入下，4位乘法器设计的后综合模拟显示，与未分解的综合相比，开关活动降低了12.9%。如果放宽合规性要求并稍微减小输入范围，开关活动降低可达33%。此外，基于开关活动驱动的设计空间探索的综合优化方法可比无功耗感知的方法提高5-10%的功率效率。

Abstract: This work presents a method to maximize power-efficiency of fixed point
multiplier units by decomposing them into sub-components. First, an encoder
block converts the operands from a two's complement to a sign magnitude
representation, followed by a multiplier module which performs the compute
operation and outputs the resulting value in the original format. This allows
to leverage the power-efficiency of the Sign Magnitude encoding for the
multiplication. To ensure the computing format is not altered, those two
components are synthesized and optimized separately. Our method leads to
significant power savings for input values centered around zero, as commonly
encountered in AI workloads. Under a realistic input stream with values
normally distributed with a standard deviation of 3.0, post-synthesis
simulations of the 4-bit multiplier design show up to 12.9% lower switching
activity compared to synthesis without decomposition. Those gains are achieved
while ensuring compliance into any production-ready system as the overall
circuit stays logic-equivalent. With the compliance lifted and a slightly
smaller input range of -7 to +7, switching activity reductions can reach up to
33%. Additionally, we demonstrate that synthesis optimization methods based on
switching-activity-driven design space exploration can yield a further 5-10%
improvement in power-efficiency compared to a power agnostic approach.

</details>


### [204] [Contraction, Criticality, and Capacity: A Dynamical-Systems Perspective on Echo-State Networks](https://arxiv.org/abs/2507.18467)
*Pradeep Singh,Lavanya Sankaranarayanan,Balasubramanian Raman*

Main category: cs.NE

TL;DR: 本文从动力学系统角度统一分析了回声状态网络（ESNs）的稳定性、记忆和表达能力，证明了其遗忘特性和普遍性，提出了量化计算资源的方法，并提供了基于数学和神经科学的设计原则，解释了其在实践中的高效性。


<details>
  <summary>Details</summary>
Motivation: 当前关于ESNs（回声状态网络）的稳定性、记忆和表达能力的研究分散在不同学科，缺乏统一的理论框架。本文旨在提供一个统一的动力学系统视角来解决这些基本问题，并从数学和神经科学角度为ESNs的设计提供指导。

Method: 本文采用动力学系统理论，结合泛函分析、随机吸引子理论和神经科学发现，对ESNs的稳定性、记忆和表达能力进行了统一分析。具体方法包括：证明了ESNs的Echo-State Property（初始条件冲刷）和全局Lipschitz动力学必然导致Fading-Memory Property（远程输入几何遗忘），并提供了代数检验方法；利用Stone-Weierstrass策略证明了具有多项式库和线性读出的ESNs在因果、时不变的fading-memory滤波器巴拿赫空间中是稠密的；通过记忆容量谱量化计算资源，并分析了拓扑和泄漏率如何重新分配延迟特定的容量；将ESNs建模为斜积随机动力系统，建立了单点回拉吸引子的存在性，并推导了条件Lyapunov界限。

Result: 1. 证明了ESNs的Echo-State Property和全局Lipschitz动力学蕴含Fading-Memory Property，并提供了代数检验方法。2. 证明了具有多项式库和线性读出的ESNs在因果、时不变的fading-memory滤波器巴拿赫空间中是稠密的，扩展了其普遍性至随机输入。3. 提出了记忆容量谱来量化计算资源，并揭示了拓扑和泄漏率如何影响容量分配以及与Lyapunov谱在混沌边缘的联系。4. 建立了ESNs作为斜积随机动力系统的模型，证明了单点回拉吸引子的存在性，并推导了条件Lyapunov界限，为大脑皮层临界性提供了严格的数学类比。

Conclusion: ESNs 的数学分析揭示了其内在记忆能力和表达能力，并提供了优化的设计指导，解释了它们在实践中为何能与完全训练的循环网络相媲美。

Abstract: Echo-State Networks (ESNs) distil a key neurobiological insight: richly
recurrent but fixed circuitry combined with adaptive linear read-outs can
transform temporal streams with remarkable efficiency. Yet fundamental
questions about stability, memory and expressive power remain fragmented across
disciplines. We present a unified, dynamical-systems treatment that weaves
together functional analysis, random attractor theory and recent
neuroscientific findings. First, on compact multivariate input alphabets we
prove that the Echo-State Property (wash-out of initial conditions) together
with global Lipschitz dynamics necessarily yields the Fading-Memory Property
(geometric forgetting of remote inputs). Tight algebraic tests translate
activation-specific Lipschitz constants into certified spectral-norm bounds,
covering both saturating and rectifying nonlinearities. Second, employing a
Stone-Weierstrass strategy we give a streamlined proof that ESNs with
polynomial reservoirs and linear read-outs are dense in the Banach space of
causal, time-invariant fading-memory filters, extending universality to
stochastic inputs. Third, we quantify computational resources via
memory-capacity spectrum, show how topology and leak rate redistribute
delay-specific capacities, and link these trade-offs to Lyapunov spectra at the
\textit{edge of chaos}. Finally, casting ESNs as skew-product random dynamical
systems, we establish existence of singleton pullback attractors and derive
conditional Lyapunov bounds, providing a rigorous analogue to cortical
criticality. The analysis yields concrete design rules-spectral radius, input
gain, activation choice-grounded simultaneously in mathematics and
neuroscience, and clarifies why modest-sized reservoirs often rival fully
trained recurrent networks in practice.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [205] [$k$-Approval Veto: A Spectrum of Voting Rules Balancing Metric Distortion and Minority Protection](https://arxiv.org/abs/2507.17981)
*Fatih Erdem Kizilkaya,David Kempe*

Main category: cs.GT

TL;DR: k-Approval Veto 投票规则在社会福利和少数群体保护之间提供了可调节的权衡，但高水平的少数群体保护可能以降低社会福利为代价。


<details>
  <summary>Details</summary>
Motivation: 在单席位排序复选选举中，民主制度面临着最大化社会福利（多数原则）和保护少数群体免受过差结果（少数原则）之间的权衡。本研究旨在探索这种权衡，并分析一类名为 k-Approval Veto 的投票规则，以提供不同程度的权衡。

Method: 本研究使用度量扭曲框架来衡量社会福利，涉及功利主义、α-分位数和平均主义目标。为了衡量少数群体保护，引入了 ℓ-mutual minority criterion。主要研究了 k-Approval Veto 投票规则类，分析了其在不同 k 值下的表现，并将其与 Plurality Veto 和 Vote By Veto 进行比较。

Result: k-Approval Veto 投票规则具有至少 k 的少数群体保护能力，但社会福利有所下降。具体而言，对于功利主义目标，度量扭曲随 k 线性增加；对于 α-分位数目标，当 α ≥ k/(k+1) 时，度量扭曲为最优值 5，当 α < k/(k+1) 时，度量扭曲无界；对于平均主义目标，对于所有 k 值，度量扭曲均为最优值 3。

Conclusion: 该研究分析了 k-Approval Veto 投票规则在多数原则（最大化社会福利）和少数原则（保护少数群体免受过差结果的影响）之间的权衡。研究使用度量扭曲来衡量社会福利，并引入了 ℓ-mutual minority criterion 来衡量少数群体保护。研究表明，k-Approval Veto 提供了两种原则的全面权衡，其少数群体保护至少为 k，但会牺牲一定的社会福利。对于不同的社会福利目标（功利主义、α-分位数和平均主义），k-Approval Veto 的度量扭曲有不同的表现。

Abstract: In the context of single-winner ranked-choice elections between $m$
candidates, we explore the tradeoff between two competing goals in every
democratic system: the majority principle (maximizing the social welfare) and
the minority principle (safeguarding minority groups from overly bad
outcomes).To measure the social welfare, we use the well-established framework
of metric distortion subject to various objectives: utilitarian (i.e., total
cost), $\alpha$-percentile (e.g., median cost for $\alpha = 1/2$), and
egalitarian (i.e., max cost). To measure the protection of minorities, we
introduce the $\ell$-mutual minority criterion, which requires that if a
sufficiently large (parametrized by $\ell$) coalition $T$ of voters ranks all
candidates in $S$ lower than all other candidates, then none of the candidates
in $S$ should win. The highest $\ell$ for which the criterion is satisfied
provides a well-defined measure of mutual minority protection (ranging from 1
to $m$).
  Our main contribution is the analysis of a recently proposed class of voting
rules called $k$-Approval Veto, offering a comprehensive range of trade-offs
between the two principles. This class spans between Plurality Veto (for $k=1$)
- a simple voting rule achieving optimal metric distortion - and Vote By Veto
(for $k=m$) which picks a candidate from the proportional veto core. We show
that $k$-Approval Veto has minority protection at least $k$, and thus, it
accommodates any desired level of minority protection. However, this comes at
the price of lower social welfare. For the utilitarian objective, the metric
distortion increases linearly in $k$. For the $\alpha$-percentile objective,
the metric distortion is the optimal value of 5 for $\alpha \ge k/(k+1)$ and
unbounded for $\alpha < k/(k+1)$. For the egalitarian objective, the metric
distortion is the optimal value of 3 for all values of $k$.

</details>


### [206] [On Pareto-Optimal and Fair Allocations with Personalized Bi-Valued Utilities](https://arxiv.org/abs/2507.18251)
*Jiarong Jin,Biaoshuai Tao*

Main category: cs.GT

TL;DR: 该研究解决了具有个性化双值效用的公平分配问题，对帕累托最优分配进行了表征，并提出了相应的判定算法。研究发现，当价值比率r_i为整数时，判定问题可以在多项式时间内解决，但当r_i为小数时，该问题是coNP完全的。此外，研究还证明了EFX分配总是存在的，并且可以高效计算。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决公平分配问题，特别是针对具有个性化双值效用的情况。现有研究在处理这类问题时存在局限性，例如在判定帕累托最优性方面的计算复杂度问题，以及在EFX分配的存在性和计算方法方面。因此，本研究希望通过提供更全面的理论表征和更有效的算法，来推进公平分配领域的研究，并为解决实际的资源分配问题提供理论支持。

Method: 本研究首先对具有个性化双值效用的公平分配问题进行了研究，为每种物品的分配方式进行了定义，并引入了价值比率r_i的概念。接着，研究人员给出了所有帕累托最优分配的表征，并基于此表征提出了一种判定给定分配是否为帕累托最优的算法，该算法在r_i为整数的情况下具有多项式时间复杂度。对于r_i为小数的普遍情况，研究人员证明了判定问题的coNP完全性。最后，研究人员证明了在个性化双值效用下，EFX分配总是存在的，并且可以通过多项式时间算法进行计算。

Result: 研究人员给出了所有帕累托最优分配的表征，并指出当价值比率r_i为整数时，判定一个分配是否为帕累托最优可以在多项式时间内完成。然而，当r_i为小数时，该判定问题是coNP完全的。此外，研究证明了在个性化双值效用下，EFX分配始终存在并且可以在多项式时间内计算出来。

Conclusion: 该研究为具有个性化双值效用的公平分配问题提供了对所有帕累托最优分配的表征，并表明在特定条件下，帕累托最优性判定问题是coNP完全的。此外，研究证明了EFX分配总是存在的，并且可以在个性化双值效用设置下进行多项式时间计算，并将一个关于EFX和帕累托最优分配是否存在及如何计算的开放性问题留给后续研究。

Abstract: We study the fair division problem of allocating $m$ indivisible goods to $n$
agents with additive personalized bi-valued utilities. Specifically, each agent
$i$ assigns one of two positive values $a_i > b_i > 0$ to each good, indicating
that agent $i$'s valuation of any good is either $a_i$ or $b_i$. For
convenience, we denote the value ratio of agent $i$ as $r_i = a_i / b_i$.
  We give a characterization to all the Pareto-optimal allocations. Our
characterization implies a polynomial-time algorithm to decide if a given
allocation is Pareto-optimal in the case each $r_i$ is an integer. For the
general case (where $r_i$ may be fractional), we show that this decision
problem is coNP-complete. Our result complements the existing results: this
decision problem is coNP-complete for tri-valued utilities (where each agent's
value for each good belongs to $\{a,b,c\}$ for some prescribed $a>b>c\geq0$),
and this decision problem belongs to P for bi-valued utilities (where $r_i$ in
our model is the same for each agent).
  We further show that an EFX allocation always exists and can be computed in
polynomial time under the personalized bi-valued utilities setting, which
extends the previous result on bi-valued utilities. We propose the open problem
of whether an EFX and Pareto-optimal allocation always exists (and can be
computed in polynomial time).

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [207] [Incentivised Orchestrated Training Architecture (IOTA): A Technical Primer for Release](https://arxiv.org/abs/2507.17766)
*Felix Quinque,Alan Aboudib,Szymon Fonau,Rodrigo Lopez Portillo Alcocer,Brian McCrindle,Steffen Cruz*

Main category: cs.DC

TL;DR: IOTA是一种新的分布式LLM预训练架构，解决了现有方法的局限性，通过协作、细粒度激励和优化技术实现可扩展和公平的训练。


<details>
  <summary>Details</summary>
Motivation: Bittensor的Subnet 9在分布式预训练方面取得了进展，但也存在 miner需要本地容纳整个模型和“赢家通吃”的奖励机制导致模型囤积的问题。IOTA旨在解决这些局限性，构建一个可扩展且能公平奖励贡献者的协作单元。

Method: IOTA提出了一种新的分布式预训练架构，包括数据和流水线并行SWARM架构，细粒度的连续激励机制，激活压缩技术，蝴蝶All-Reduce算法以及CLASP（基于路径采样贡献损失评估）的公平归因方案。

Result: IOTA架构能够支持任意大小的模型，并通过细粒度激励、激活压缩（最高可达128倍带宽压缩）、蝴蝶All-Reduce（提供线性可扩展性、冗余和防碰撞检测）以及CLASP（公平的功劳分配和漏洞检测）等关键技术，提高了训练速度和可扩展性。

Conclusion: IOTA通过数据和流水线并行、细粒度激励、激活压缩、蝴蝶 all-reduce和CLASP等方法，解决了现有分布式预训练模型的局限性，实现了可扩展、公平的LLM预训练。

Abstract: In August 2024, Bittensor's Subnet 9 (SN9) demonstrated that a distributed
network of incentivized, permissionless actors could each pretrain large
language models (LLMs) ranging from 700 million to 14 billion parameters, while
surpassing established baselines. While that work validated blockchain-based
decentralized pretraining as viable, it contained core issues: (i) every miner
had to fit an entire model locally, and (ii) "winner-takes-all" rewards
encouraged model hoarding.
  Here we introduce IOTA (Incentivized Orchestrated Training Architecture), an
architecture that addresses these limitations by transforming SN9's previously
isolated competitors into a single cooperating unit that can scale arbitrarily
while still rewarding each contributor fairly.
  Key preliminary results: (1) Data- and Pipeline-parallel SWARM architecture -
An orchestrator distributes model layers across heterogeneous miners and
streams activations between them, enabling model sizes to scale with the number
of participants rather than being constrained by the VRAM of a single machine;
(2) Granular, continuous incentives - Validators measure each miner's
contribution and allocate token emissions proportionally; (3) Activation
compression - We used model-bottlenecks to cut communication bandwidths of
activations by up to 128x, vastly improving training speed; (4) Butterfly
All-Reduce - Miners average disjoint parameter slices in O(1) bandwidth,
offering linear scalability, redundancy and built-in collusion detection; (5)
CLASP (Contribution Loss Assessment via Sampling of Pathways) - A fair
attribution scheme assigns credit to miners proportional to their marginal
utility and detects exploits, even when contributions are interdependent across
the pipeline.

</details>


### [208] [PolyServe: Efficient Multi-SLO Serving at Scale](https://arxiv.org/abs/2507.17769)
*Kan Zhu,Haiyang Shi,Le Xu,Jiaxin Shan,Arvind Krishnamurthy,Baris Kasikci,Liguang Xie*

Main category: cs.DC

TL;DR: PolyServe 是一种新的多 SLO 调度策略，可大规模扩展，在满足 SLO 的同时最大限度地提高吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有系统将工作负载简单地分为延迟敏感 (LS) 或尽力而为 (BE) 会忽略延迟敏感类别中的细微差别，并导致次优的用户体验和调度机会。然而，高效地服务具有多个 SLO 要求的请求带来了重大挑战，包括批处理中的请求可能与它们不同的 SLO 要求不对齐，以及需要针对这些 SLO 层次进行细粒度的自动扩展，并且无法像 LS/BE 场景那样中止 BE 请求来确保 LS 请求的 SLO 可实现性。

Method: PolyServe首先根据每个 token 的延迟要求将请求分组到多个 bin 中，然后将每个 bin 调度到服务器集群的子集。PolyServe 将请求路由到负载最高但仍可实现 SLO 的服务器，从而创建负载梯度以促进自动扩展。为了提高利用率，PolyServe 允许较松 SLO 的请求在自己的服务器饱和时共享较紧 SLO 的实例。PolyServe 使用剖析数据来指导调度决策，并通过感知请求等待时间的调度、动态分块和连续分块预填充预测来管理尾部延迟。

Result: PolyServe 实现了 1.23 倍的好产量增益，与现有策略相比，达到了最优好产量的 92.5%。

Conclusion: PolyServe通过将请求分组到多个 bin 中，并将每个 bin 调度到服务器集群的子集，实现了高 SLO 可实现性和高吞吐量。它通过创建负载梯度来实现精细化自动扩展，并通过允许较松 SLO 的请求共享较紧 SLO 的实例来提高利用率。PolyServe 使用剖析数据来指导调度决策，并通过感知请求等待时间的调度、动态分块和连续分块预填充预测来管理尾部延迟。与现有策略相比，PolyServe 的好产量提高了 1.23 倍，达到了最优好产量的 92.5%。

Abstract: Advances in Large Language Models (LLMs) have led to a surge of LLM-powered
applications. These applications have diverse token-generation latency
requirements. As a result, simply classifying workloads as latency-sensitive
(LS) or best-effort (BE) overlooks the nuances within the latency-sensitive
category and results in suboptimal user experiences and scheduling
opportunities. However, efficiently serving requests with multiple SLO
requirements poses significant challenges. First, all requests within a batch
generate new tokens simultaneously, which can misalign them with their distinct
SLO requirements. Moreover, while existing systems focus on auto-scaling for
handling various overall request rates, the diversity of SLOs necessitates
fine-grained auto-scaling among these SLO tiers. Finally, unlike LS/BE
scenarios, where BE requests can be aborted at any time to ensure the SLO
attainment of LS requests, those with different latency-sensitive SLOs cannot
tolerate prolonged delays, and tail latency must be controlled.
  To tackle these challenges, we propose PolyServe, a novel multi-SLO
scheduling policy at scale that maintains high SLO attainment while maximizing
throughput. PolyServe first groups requests into multiple bins based on their
per-token latency requirement, then schedules each bin to a subset of the
server fleet. PolyServe routes requests to the highest-load but still
SLO-attainable server to create a load gradient that facilitates auto-scaling.
To increase utilization, PolyServe permits looser-SLO requests to share
tighter-SLO instances when their own servers are saturated. PolyServe uses
profiling data to guide scheduling decisions and manage tail latency through
request-wait-time-aware scheduling, dynamic chunking, and continuous chunked
prefill prediction. PolyServe achieves 1.23x goodput gain compared to existing
policies, achieving up to 92.5% of optimal goodput.

</details>


### [209] [Comparative Evaluation of PyTorch, JAX, SciPy, and Neal for Solving QUBO Problems at Scale](https://arxiv.org/abs/2507.17770)
*Pei-Kun Yang*

Main category: cs.DC

TL;DR: QUBO 求解器性能评估：PyTorch 在大规模问题上表现均衡，Neal 在小规模问题上能量值最低，但内存消耗大。SciPy 性能最差。


<details>
  <summary>Details</summary>
Motivation: QUBO 是一种用于模拟组合优化问题的通用框架。

Method: 对 Neal、PyTorch (CPU)、PyTorch (GPU)、JAX 和 SciPy 这五种基于软件的 QUBO 求解器进行基准测试，测试范围涵盖 1000x1000 到 45000x45000 的随机生成的 QUBO 矩阵，以及从 10^-1 到 10^-6 的六个收敛阈值。评估了它们在解决方案质量（能量）和计算时间方面的性能。

Result: Neal 实现了最低的能量值，但由于内存消耗大，仅限于变量数量高达 6000 的问题。PyTorch 的能量值略高于 Neal，但具有更优越的可扩展性，可以解决多达 45000 个变量的实例，并且由于支持 GPU 加速和 CPU 多线程，运行时间也显著缩短。JAX 的能量值略高于 PyTorch，并且仅限于 25000 个变量，运行时间与 PyTorch 在 GPU 上的运行时间相当。SciPy 是约束最多的求解器，仅限于 6000 个变量，并且始终产生最高的能量值和最长的计算时间。

Conclusion: 在计算资源允许的情况下，PyTorch 是大规模 QUBO 问题的最均衡选择。

Abstract: Quadratic Unconstrained Binary Optimization (QUBO) is a versatile framework
for modeling combinatorial optimization problems. This study benchmarks five
software-based QUBO solvers: Neal, PyTorch (CPU), PyTorch (GPU), JAX, and
SciPy, on randomly generated QUBO matrices ranging from 1000x1000 to
45000x45000, under six convergence thresholds from 10^-1 to 10^-6. We evaluate
their performance in terms of solution quality (energy) and computational time.
Among the solvers tested, Neal achieved the lowest energy values but was
limited to problems with up to 6000 variables due to high memory consumption.
PyTorch produced slightly higher energy results than Neal but demonstrated
superior scalability, solving instances with up to 45000 variables. Its support
for GPU acceleration and CPU multi-threading also resulted in significantly
shorter runtimes. JAX yielded energy values slightly above those of PyTorch and
was limited to 25000 variables, with runtimes comparable to PyTorch on GPU.
SciPy was the most constrained solver, handling only up to 6000 variables and
consistently producing the highest energy values with the longest computation
times. These findings highlight trade-offs between solution quality,
scalability, and runtime efficiency, and suggest that PyTorch is the most
balanced choice for large-scale QUBO problems when computational resources
permit.

</details>


### [210] [Flexible Vector Integration in Embedded RISC-V SoCs for End to End CNN Inference Acceleration](https://arxiv.org/abs/2507.17771)
*Dmitri Lyalikov*

Main category: cs.DC

TL;DR: 该研究提出了一种利用RISC-V向量扩展（RVV-1.0）和优化缓存层次结构来提升嵌入式SoC上深度学习性能的方法。实验证明，该方法能显著加速图像预处理和YOLOv3模型中的CPU回退层，同时降低功耗，为在资源受限设备上部署深度学习提供了有效的解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习模型在资源受限的嵌入式平台上的广泛应用，以及异构和领域特定架构的出现，如何有效利用这些专用硬件（如DLAs和NPUs）成为关键挑战。传统的硅扩展已接近极限，嵌入式SoC面临功耗/性能的权衡问题。为了充分发挥异构架构的优势，需要进行有效的系统集成和优化的编译/执行模型。该研究旨在解决在异构架构中，将专用硬件单元进行硬件集成，并优化执行模型以实现均衡执行的挑战，特别是关注内存层次结构和与其他执行模块的邻近性，并验证其在实际应用中的性能。

Method: 该研究通过硬件集成，将深度学习加速器（DLAs）和神经网络处理单元（NPUs）等专用硬件集成到嵌入式SoC的内存层次结构中。利用RISC-V向量1.0扩展（RVV-1.0）及其缓存层次结构方案，优化了CNN的执行流程，重点关注了运行时性能瓶颈，包括预处理和后处理，并与仅关注加速器本身的研究区分开。通过实验验证了RVV-1.0在减少预处理瓶颈和CPU回退方面相对于CPU的性能提升。

Result: 实验结果表明，与仅CPU相比，利用RVV-1.0和优化的缓存层次结构，图像预处理速度最高可提升9倍，YOLOv3模型的回退层执行速度最高可提升3倍。RVV-1.0被证明是一个灵活的编程模型，能够在大规模异构嵌入式SoC上实现计算和内存占用的平衡，并支持现代深度学习数据流，同时功耗低于传统的并行执行平台。

Conclusion: 该研究展示了RISC-V向量扩展（RVV-1.0）在异构嵌入式SoC中的潜力，通过优化的缓存层次结构，显著减少了图像预处理和YOLOv3模型中的CPU回退层瓶颈，实现了高达9倍的预处理加速和3倍的回退层加速。RVV-1.0提供了一个灵活的编程模型，能够在大规模异构嵌入式SoC上实现计算和内存占用的平衡，同时功耗低于传统的并行执行平台。

Abstract: The emergence of heterogeneity and domain-specific architectures targeting
deep learning inference show great potential for enabling the deployment of
modern CNNs on resource-constrained embedded platforms. A significant
development is the diversification of custom hardware solely targeting the most
expensive parts of CNNs. DLAs (deep learning accelerators) and NPUs (neural
processing units), among others, can overcome the approaching limits of
traditional silicon scaling and provide a solution to the power/performance
tradeoff within embedded SoCs. Efficient DSA utilization requires proper system
integration and a compilation/execution model for balanced execution in these
heterogeneous architectures. There is a critical need for proper system
integration and an efficient compilation/execution model for balanced execution
in these heterogeneous architectures. This work highlights the hardware
integration challenges for efficiently placing these units within the memory
hierarchy and correct proximity to other execution blocks. We experimentally
verify performance bottlenecks in CNN execution and pre/post-processing at
runtime, where previous attention has generally been given to accelerator
speedup alone. This work takes advantage of the ratification of the RISC-V
Vector 1.0 extension and demonstrates its potential as a flexible target within
a well-suited cache hierarchy scheme to reduce pre-processing bottlenecks and
CPU fallback processes. Our results show up to a 9x speedup of image
pre-processing and YOLOv3 fallback layer execution by up to 3x compared to CPU.
We demonstrate RVV-1.0 in exposing a flexible programming model that can enable
a balanced computation and memory footprint on accelerator-rich embedded SoCs
supporting modern deep-learning dataflows while consuming less power than
traditional parallel execution platforms.

</details>


### [211] [Caching Techniques for Reducing the Communication Cost of Federated Learning in IoT Environments](https://arxiv.org/abs/2507.17772)
*Ahmad Alhonainy,Praveen Rao*

Main category: cs.DC

TL;DR: 本研究通过引入 FIFO、LRU 和基于优先级的缓存策略来优化联邦学习通信，成功降低了带宽使用量，并保持了模型准确性，使其在资源受限和延迟敏感的应用中更具实用性。


<details>
  <summary>Details</summary>
Motivation: 为了解决联邦学习（FL）中通信成本高昂的瓶颈，尤其是在资源受限的环境中。

Method: 引入了先进的缓存策略，包括先进先出（FIFO）、最近最少使用（LRU）和基于优先级的方法，以选择性地转发重要的模型更新，从而减少不必要的模型更新传输。

Result: 在 CIFAR-10 和医疗数据集上进行的实验表明，与传统方法相比，该方法能显著减少通信量，同时仅带来微小的准确性损失。

Conclusion: 通过智能缓存策略（FIFO、LRU 和基于优先级）显著降低了通信成本，同时保持了模型准确性，提高了 FL 的可扩展性、内存效率和可靠性，适用于边缘物联网网络中的延迟敏感应用。

Abstract: Federated Learning (FL) allows multiple distributed devices to jointly train
a shared model without centralizing data, but communication cost remains a
major bottleneck, especially in resource-constrained environments. This paper
introduces caching strategies - FIFO, LRU, and Priority-Based - to reduce
unnecessary model update transmissions. By selectively forwarding significant
updates, our approach lowers bandwidth usage while maintaining model accuracy.
Experiments on CIFAR-10 and medical datasets show reduced communication with
minimal accuracy loss. Results confirm that intelligent caching improves
scalability, memory efficiency, and supports reliable FL in edge IoT networks,
making it practical for deployment in smart cities, healthcare, and other
latency-sensitive applications.

</details>


### [212] [MultiKernelBench: A Multi-Platform Benchmark for Kernel Generation](https://arxiv.org/abs/2507.17773)
*Zhongzhen Wen,Yinghui Zhang,Zhong Li,Zhongxin Liu,Linna Xie,Tian Zhang*

Main category: cs.DC

TL;DR: MultiKernelBench是一个新的深度学习内核生成基准，支持多平台和多类别，并通过改进的提示方法评估了LLM的表现，揭示了其在跨平台泛化和任务难度方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有评估LLM生成深度学习内核的基准存在硬件支持有限、内核分类粗糙、任务覆盖不平衡等问题，阻碍了LLM在该领域的有效评估和发展。

Method: 提出MultiKernelBench基准，包含285个任务，覆盖14个内核类别，支持Nvidia GPU、Huawei NPU和Google TPU。设计模块化后端抽象层以支持新硬件平台。提出类别感知单发提示方法，利用同类示例提升生成质量。

Result: 系统评估了七种先进LLM，发现任务难度存在显著差异，模型在训练曝光较少的平台上泛化能力较差，并验证了定向提示策略的有效性。

Conclusion: LLMs在深度学习内核生成方面展现出潜力，但现有基准存在局限。MultiKernelBench通过提供多平台、多类别、模块化设计的基准，并结合类别感知单发提示方法，有效评估和提升了LLM在这一领域的表现。实验揭示了任务难度差异、跨平台泛化能力不足以及定向提示策略的有效性。

Abstract: The automatic generation of deep learning (DL) kernels using large language
models (LLMs) has emerged as a promising approach to reduce the manual effort
and hardware-specific expertise required for writing high-performance operator
implementations. However, existing benchmarks for evaluating LLMs in this
domain suffer from limited hardware support, coarse-grained kernel
categorization, and imbalanced task coverage. To address these limitations, we
introduce MultiKernelBench, the first comprehensive, multi-platform benchmark
for LLM-based DL kernel generation. MultiKernelBench spans 285 tasks across 14
well-defined kernel categories and supports three major hardware platforms:
Nvidia GPUs, Huawei NPUs, and Google TPUs. To enable future extensibility, we
design a modular backend abstraction layer that decouples platform-specific
logic from the core benchmarking infrastructure, allowing easy integration of
new hardware platforms. We further propose a simple yet effective
category-aware one-shot prompting method that improves generation quality by
providing in-category exemplars. Through systematic evaluations of seven
state-of-the-art LLMs, we reveal significant variation in task difficulty, poor
generalization to platforms with less training exposure, and the effectiveness
of targeted prompting strategies. MultiKernelBench is publicly available at
https://github.com/wzzll123/MultiKernelBench.

</details>


### [213] [CHAMP: A Configurable, Hot-Swappable Edge Architecture for Adaptive Biometric Tasks](https://arxiv.org/abs/2507.17793)
*Joel Brogan,Matthew Yohe,David Cornett*

Main category: cs.DC

TL;DR: CHAMP是一个模块化的边缘AI平台，允许现场操作员即插即用地添加和更换AI功能（如人脸识别、物体追踪等），并保证数据安全。它使用了FPGA加速器和自定义操作系统，性能可扩展性好，适用于现场生物识别、监控和灾难响应等场景。


<details>
  <summary>Details</summary>
Motivation: 为了使现场操作员能够灵活、高性能地使用边缘AI系统，并能够即时适应任务需求，本文旨在提供一种可配置的、热插拔的AI分析系统，类似于模块化的乐高积木。

Method: CHAMP（Configurable Hot-swappable Architecture for Machine Perception）是一个模块化的边缘计算平台，利用基于FPGA的低功耗加速器和高吞吐量总线，通过自定义的VDiSK操作系统实现即插即用的AI管道和加密保护的生物识别数据集。论文详细介绍了CHAMP的设计，包括其模块化扩展能力和用于运行时重新配置的VDiSK操作系统，以及其加密功能以确保模块上数据的安全和隐私。

Result: 实验结果表明，CHAMP平台从1个加速器扩展到5个加速器时，吞吐量实现了近乎线性的扩展，突显了基于USB3的总线在性能提升和饱和限制方面的表现。

Conclusion: CHAMP平台通过其模块化设计、可插拔的AI能力以及CHAMP的VDiSK操作系统，实现了灵活、高性能的边缘AI系统，能够满足现场操作员的需求。实验证明了该系统在1到5个神经网络加速器上的近乎线性吞吐量扩展能力，并讨论了其在现场生物识别、监控和灾难响应等领域的应用前景，以及未来在总线协议、卡盒功能和系统软件方面的改进方向。

Abstract: What if you could piece together your own custom biometrics and AI analysis
system, a bit like LEGO blocks? We aim to bring that technology to field
operators in the field who require flexible, high-performance edge AI system
that can be adapted on a moment's notice. This paper introduces CHAMP
(Configurable Hot-swappable Architecture for Machine Perception), a modular
edge computing platform that allows operators to dynamically swap in
specialized AI "capability cartridges" for tasks like face recognition, object
tracking, and document analysis. CHAMP leverages low-power FPGA-based
accelerators on a high-throughput bus, orchestrated by a custom operating
system (VDiSK) to enable plug-and-play AI pipelines and cryptographically
secured biometric datasets. In this paper we describe the CHAMP design,
including its modular scaling with multiple accelerators and the VDiSK
operating system for runtime reconfiguration, along with its cryptographic
capabilities to keep data stored on modules safe and private. Experiments
demonstrate near-linear throughput scaling from 1 to 5 neural compute
accelerators, highlighting both the performance gains and saturation limits of
the USB3-based bus. Finally, we discuss applications of CHAMP in field
biometrics, surveillance, and disaster response, and outline future
improvements in bus protocols, cartridge capabilities, and system software.

</details>


### [214] [Optimizing Edge Gaming Slices through an Enhanced User Plane Function and Analytics in Beyond-5G Networks](https://arxiv.org/abs/2507.17843)
*Bruno Marques da Silva,Larissa Ferreira Rodrigues Moreira,Flávio de Oliveira Silva,Rodrigo Moreira*

Main category: cs.DC

TL;DR: 该研究提出了一种集成了NWDAF和UPF的闭环架构，用于估算用户延迟并增强5G控制平面，通过AI模型实现游戏分类，为移动边缘博弈研究带来新方向。


<details>
  <summary>Details</summary>
Motivation: 最新的游戏和泛在通信技术给移动用户的服务管理和协议遵从带来了挑战，现有的边缘博弈技术虽然提高了吞吐量、降低了延迟并利用了云计算，但在非侵入式用户延迟测量等核心功能方面仍需进一步发展。

Method: 本研究提出了一种闭环架构，该架构集成了网络数据分析功能（NWDAF）和用户平面功能（UPF），用于估算用户延迟并增强具有延迟感知的5G控制平面。

Result: 研究结果表明，在NWDAF中嵌入人工智能模型能够实现游戏分类，为移动边缘博弈研究开辟了新的途径。

Conclusion: 该研究提出了一种将网络数据分析功能（NWDAF）和用户平面功能（UPF）集成，以实现用户延迟估算并增强支持延迟感知的5G控制平面的闭环架构。研究结果表明，在NWDAF中嵌入人工智能模型能够实现游戏分类，为移动边缘博弈研究开辟了新的途径。

Abstract: The latest generation of games and pervasive communication technologies poses
challenges in service management and Service-Level Agreement compliance for
mobile users. State-of-the-art edge-gaming techniques enhance throughput,
reduce latency, and leverage cloud computing. However, further development of
core functions such as the User Plane Function (UPF) is needed for
non-intrusive user latency measurement. This paper proposes a closed-loop
architecture integrating the Network Data Analytics Function (NWDAF) and UPF to
estimate user latency and enhance the 5G control plane by making it
latency-aware. The results show that embedding an artificial intelligence model
within NWDAF enables game classification and opens new avenues for mobile edge
gaming research.

</details>


### [215] [PowerTrip: Exploiting Federated Heterogeneous Datacenter Power for Distributed ML Training](https://arxiv.org/abs/2507.17904)
*Talha Mehboob,Luanzheng Guo,Nathan Tallent,Michael Zink,David Irwin*

Main category: cs.DC

TL;DR: 由于电力限制和网络延迟，大型 AI 模型训练需要跨地域分布式。PowerTrip 通过动态选择站点来优化功耗-通信权衡，可将达到准确率的时间缩短多达 50%。


<details>
  <summary>Details</summary>
Motivation: 由于区域电网的电力限制，大型 AI 模型需要跨地域分布式训练，这带来了通信开销的挑战，并在可用功率和网络延迟之间产生了权衡。现有方法忽略了站点之间异构电力供应的挑战。

Method: PowerTrip使用基于功耗-成本启发式的方法，优先选择高功耗可用性和低网络延迟的站点，并采用动态贪婪方法，利用训练效率的边际收益来优化站点数量。

Result: 评估结果表明，PowerTrip 与现有基线策略相比，可以将达到准确率的时间缩短高达 50%。

Conclusion: PowerTrip通过动态选择站点来优化功耗-通信权衡，与现有基线策略相比，可将达到准确率的时间缩短多达 50%。

Abstract: The exponential growth of large-scale AI models has led to computational and
power demands that can exceed the capacity of a single data center. This is due
to the limited power supplied by regional grids that leads to limited regional
computational power. Consequently, distributing training workloads across
geographically distributed sites has become essential. However, this approach
introduces a significant challenge in the form of communication overhead,
creating a fundamental trade-off between the performance gains from accessing
greater aggregate power and the performance losses from increased network
latency. Although prior work has focused on reducing communication volume or
using heuristics for distribution, these methods assume constant homogeneous
power supplies and ignore the challenge of heterogeneous power availability
between sites.
  To address the challenge of training large models in power-constrained,
geo-distributed environments, we introduce PowerTrip, a system that dynamically
selects a subset of sites during runtime to optimize the power-communication
trade-off. Specifically, PowerTrip selects sites based on a power-to-cost
heuristic, prioritizing those with high power availability and low network
latency. PowerTrip employs a dynamic greedy approach and uses the marginal gain
in training efficiency, i.e., accuracy improvement per unit of time, to
optimize for the number of sites where the performance penalty from network
overhead negates the benefit of adding more computational power. Our
evaluation, which uses real-world Google power traces to model realistic power
capacity constraints, demonstrates that PowerTrip can reduce time-to-accuracy
by up to 50% compared to existing baseline policies.

</details>


### [216] [C-Koordinator: Interference-aware Management for Large-scale and Co-located Microservice Clusters](https://arxiv.org/abs/2507.18005)
*Shengye Song,Minxian Xu,Zuowei Zhang,Chengxi Gao,Fansong Zeng,Yu Ding,Kejiang Ye,Chengzhong Xu*

Main category: cs.DC

TL;DR: 阿里巴巴研究人员提出了C-Koordinator平台，通过精确预测和缓解大规模微服务集群中的资源竞争干扰，将应用程序延迟降低了高达36.1%。


<details>
  <summary>Details</summary>
Motivation: 随着微服务架构的广泛采用，云平台通过共置不同微服务来提高资源利用率。然而，这也会引发微服务之间的资源竞争和干扰。因此，设计能够感知干扰的策略对于大规模共置微服务集群至关重要，以提高资源利用率并减轻竞争引起的干扰。

Method: 本研究首先分析了阿里巴巴大规模、共置微服务集群的特点，并阐述了选择指令周期（CPI）作为度量标准的理由及其预测方法。随后，基于CPI干扰预测和分析，设计并实现了C-Koordinator平台，该平台整合了共置和干扰缓解策略。

Result: C-Koordinator平台的干扰预测模型准确率超过90.3%，能够精确预测并快速缓解运行环境中的干扰。实验结果表明，与现有技术相比，在不同系统负载下，应用程序的延迟（P50、P90、P99响应时间）降低并趋于稳定，性能提升幅度在16.7%至36.1%之间，有效保证了共置环境下的应用程序性能。

Conclusion: 该研究提出了C-Koordinator平台，一个用于管理大规模微服务集群的开源解决方案，通过结合资源整合和干扰缓解策略，显著提高了资源利用率并减少了应用程序延迟。

Abstract: Microservices transform traditional monolithic applications into lightweight,
loosely coupled application components and have been widely adopted in many
enterprises. Cloud platform infrastructure providers enhance the resource
utilization efficiency of microservices systems by co-locating different
microservices. However, this approach also introduces resource competition and
interference among microservices. Designing interference-aware strategies for
large-scale, co-located microservice clusters is crucial for enhancing resource
utilization and mitigating competition-induced interference. These challenges
are further exacerbated by unreliable metrics, application diversity, and node
heterogeneity.
  In this paper, we first analyze the characteristics of large-scale and
co-located microservices clusters at Alibaba and further discuss why cycle per
instruction (CPI) is adopted as a metric for interference measurement in
large-scale production clusters, as well as how to achieve accurate prediction
of CPI through multi-dimensional metrics. Based on CPI interference prediction
and analysis, we also present the design of the C-Koordinator platform, an
open-source solution utilized in Alibaba cluster, which incorporates
co-location and interference mitigation strategies. The interference prediction
models consistently achieve over 90.3% accuracy, enabling precise prediction
and rapid mitigation of interference in operational environments. As a result,
application latency is reduced and stabilized across all percentiles (P50, P90,
P99) response time (RT), achieving improvements ranging from 16.7% to 36.1%
under various system loads compared with state-of-the-art system. These results
demonstrate the system's ability to maintain smooth application performance in
co-located environments.

</details>


### [217] [Unlock the Potential of Fine-grained LLM Serving via Dynamic Module Scaling](https://arxiv.org/abs/2507.18006)
*Jingfeng Wu,Yiyuan He,Minxian Xu,Xitong Gao,Kejiang Ye,Chengzhong Xu*

Main category: cs.DC

TL;DR: CoCoServe通过LLM模块级动态扩展，降低成本并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM服务系统在资源管理方面面临挑战，静态部署导致资源利用率低下和性能下降，而实例调整成本高昂限制了动态扩展。

Method: 提出了一种名为CoCoServe的弹性系统，该系统通过模块（如解码器层和投影）的复制和迁移，实现了LLM的动态和细粒度扩展。开发了一种自动扩展机制，动态调节资源分配和性能优化。

Result: CoCoServe的扩展操作具有良好的可扩展性，可将成本降低46%，同时保持可用性。与Hugging Face Transformers和vLLM等先进系统相比，CoCoServe的延迟降低了14%-75%，吞吐量平均提高了1.16倍至4倍。

Conclusion: CoCoServe通过模块级操作实现了LLM的弹性服务，显著降低了成本（46%）并提高了性能（延迟降低14%-75%，吞吐量提高1.16x-4x），优于现有系统。

Abstract: The rise of large language models (LLMs) has created new opportunities across
various fields but has also introduced significant challenges in resource
management. Current LLM serving systems face a fundamental tension: balancing
serving demands with limited resources while adapting to unpredictable traffic
patterns. Static deployments lead to suboptimal resource utilization and
performance degradation under dynamic workloads. Furthermore, the high cost of
adjusting instances hinders dynamic scaling, limiting the true potential of
efficient LLM serving.
  To address this, we propose CoCoServe, an elastic system that facilitates
dynamic and fine-grained scaling. Its key innovation lies in the module-level
operations for the replication and migration of LLM modules, such as decoder
layers and projections. Through a comprehensive analysis of the trade-offs
associated with these operations, we develop an auto-scaling mechanism that
dynamically regulates module-level resource allocation and performance
optimization, enabling a more cost-effective deployment of LLMs. Our evaluation
demonstrates that the scaling operations employed by CoCoServe exhibit
excellent scalability and can reduce costs by 46% while maintaining
availability. Compared to state-of-the-art LLM serving systems (e.g., Hugging
Face Transformers and vLLM), our approach reduces latency by 14%-75% and
achieves 1.16x-4x throughput on average across different model sizes and
workloads.

</details>


### [218] [Cloud Native System for LLM Inference Serving](https://arxiv.org/abs/2507.18007)
*Minxian Xu,Junhan Liao,Jingfeng Wu,Yiyuan He,Kejiang Ye,Chengzhong Xu*

Main category: cs.DC

TL;DR: Cloud Native技术通过提高资源效率、降低延迟和增强可扩展性，解决了LLM推理服务在高需求云环境中的挑战。


<details>
  <summary>Details</summary>
Motivation: LLM的巨大计算需求给高效部署带来了挑战，尤其是在云环境中，传统的推理服务方法存在资源效率低、运营成本高、延迟问题和可扩展性有限等问题。

Method: 通过利用容器化、微服务和动态调度等Cloud Native技术，并结合基于Kubernetes的自动伸缩进行实际评估，来演示Cloud Native系统在LLM推理服务中的优势。

Result: Cloud Native架构能够动态适应工作负载波动，缓解性能瓶颈，同时优化LLM推理服务的性能。

Conclusion: Cloud Native技术能够通过更有效的资源分配、降低延迟和提高吞吐量来改进LLM推理服务，特别是在高需求场景下，并能通过基于Kubernetes的自动伸缩动态适应工作负载波动，从而优化性能。

Abstract: Large Language Models (LLMs) are revolutionizing numerous industries, but
their substantial computational demands create challenges for efficient
deployment, particularly in cloud environments. Traditional approaches to
inference serving often struggle with resource inefficiencies, leading to high
operational costs, latency issues, and limited scalability. This article
explores how Cloud Native technologies, such as containerization,
microservices, and dynamic scheduling, can fundamentally improve LLM inference
serving. By leveraging these technologies, we demonstrate how a Cloud Native
system enables more efficient resource allocation, reduces latency, and
enhances throughput in high-demand scenarios. Through real-world evaluations
using Kubernetes-based autoscaling, we show that Cloud Native architectures can
dynamically adapt to workload fluctuations, mitigating performance bottlenecks
while optimizing LLM inference serving performance. This discussion provides a
broader perspective on how Cloud Native frameworks could reshape the future of
scalable LLM inference serving, offering key insights for researchers,
practitioners, and industry leaders in cloud computing and artificial
intelligence.

</details>


### [219] [FCPO: Federated Continual Policy Optimization for Real-Time High-Throughput Edge Video Analytics](https://arxiv.org/abs/2507.18047)
*Lucas Liebe,Thanh-Tung Nguyen,Dongman Lee*

Main category: cs.DC

TL;DR: FCPO是一种结合持续强化学习（CRL）和联邦强化学习（FRL）的新方法，用于优化边缘视频分析（EVA）的实时推理服务。它通过动态调整批处理大小、输入分辨率和多线程来提高性能，实验结果显示其在吞吐量、延迟和收敛速度方面均有显著提升，同时内存消耗更低。


<details>
  <summary>Details</summary>
Motivation: 边缘视频分析（EVA）的复杂性日益增加，给实时推理服务系统带来了挑战。现有的调度系统虽然可以优化异构设备的全局工作负载分布，但通常存在调度周期长的问题，这在快速变化的边缘环境中会导致次优处理。虽然本地强化学习（RL）可以实现周期间的快速调整，但面临可扩展性、知识集成和适应性问题。

Method: FCPO结合了持续强化学习（CRL）和联邦强化学习（FRL）。CRL允许智能体从不断变化的马尔可夫决策过程中学习，从而捕捉动态环境变化。FRL通过整合不同推理模型的经验来提高泛化能力和收敛速度。FCPO通过特定于智能体的聚合方案和考虑多样性的经验缓冲区来结合这两种方法。该集成可以动态调整推理批处理大小、输入分辨率以及预处理和后处理过程中的多线程。

Result: 实验在真实的EVA测试平台上进行，结果显示FCPO在有效吞吐量方面提高了5倍以上，延迟降低了60%，收敛速度提高了20%，并且内存消耗减少了高达10倍，优于现有的基于强化学习的方法。

Conclusion: FCPO通过结合持续强化学习（CRL）和联邦强化学习（FRL）来解决边缘视频分析（EVA）中实时推理服务系统的挑战。实验表明，与现有的基于强化学习的方法相比，FCPO在有效吞吐量方面提高了5倍多，延迟降低了60%，收敛速度提高了20%，同时内存消耗减少了10倍。

Abstract: The growing complexity of Edge Video Analytics (EVA) facilitates new kind of
intelligent applications, but creates challenges in real-time inference serving
systems. State-of-the-art (SOTA) scheduling systems optimize global workload
distributions for heterogeneous devices but often suffer from extended
scheduling cycles, leading to sub-optimal processing in rapidly changing Edge
environments. Local Reinforcement Learning (RL) enables quick adjustments
between cycles but faces scalability, knowledge integration, and adaptability
issues. Thus, we propose FCPO, which combines Continual RL (CRL) with Federated
RL (FRL) to address these challenges. This integration dynamically adjusts
inference batch sizes, input resolutions, and multi-threading during pre- and
post-processing. CRL allows agents to learn from changing Markov Decision
Processes, capturing dynamic environmental variations, while FRL improves
generalization and convergence speed by integrating experiences across
inference models. FCPO combines these via an agent-specific aggregation scheme
and a diversity-aware experience buffer. Experiments on a real-world EVA
testbed showed over 5 times improvement in effective throughput, 60% reduced
latency, and 20% faster convergence with up to 10 times less memory consumption
compared to SOTA RL-based approaches.

</details>


### [220] [A large-scale distributed parallel discrete event simulation engines based on Warped2 for Wargaming simulation](https://arxiv.org/abs/2507.18050)
*Xiaoning Jia,Ruilin Kong,Guangya Si,Bilong Shen,Zhe Ji*

Main category: cs.DC

TL;DR: 本研究提出了一种优化的并行离散事件模拟（PDES）框架，通过异步监听器、METIS负载均衡、实体交互求解器和空间散列等技术，显著提高了大规模模拟的性能和效率，实现了高达16倍的加速。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统wargaming引擎在资源分配和复杂实体交互模式方面的局限性，提出了一个优化框架。

Method: (1) 引入异步监听器线程以解决大规模场景下的事件监控延迟问题。(2) 采用基于METIS的负载均衡策略来解决实时模拟中的动态事件分配问题。(3) 设计了具有约束满足机制的实体交互求解器来缓解状态冲突。(4) 引入了空间散列算法来克服大规模最近邻搜索中的O(n^2)复杂度瓶颈。

Result: 实验验证表明，该框架相比基线实现实现了16倍的加速，在MPI和Pthreads实现中均保持了8倍于单线程配置的加速。负载均衡和LP迁移策略结合将同步开销减少了58.18%，其中负载均衡是主要的优化因素，占总改进的57%。

Conclusion: 该框架为大规模并行离散事件模拟（PDES）提供了增强的解决方案，通过协同优化显著提高了时间保真度和计算效率。

Abstract: Rising demand for complex simulations highlights conventional
engines'scalability limits, spurring Parallel Discrete Event Simulation (PDES)
adoption.Warped2, a PDES engine leveraging Time Warp synchronization with
Pending Event Set optimization, delivers strong performance, it struggles with
inherent wargaming limitations: inefficient LP resource allocation during
synchronization and unaddressed complex entity interaction patterns. To address
these challenges, we present an optimized framework featuring four synergistic
improvements: (1) Asynchronous listener threads are introduced to address event
monitoring latency in large-scale scenarios, instead of synchronous polling
mechanisms, (2) METIS-based load rebalancing strategy is incorporated to
address the issue of dynamic event allocation during real-world simulation, (3)
Entity interaction solver with constraint satisfaction mechanisms is designed
to mitigate state conflicts, and (4) Spatial hashing algorithm to overcome
O(n^2) complexity bottlenecks in large-scale nearest-neighbor searches.
Experimental validation through a GridWorld demo demonstrates significant
enhancements in temporal fidelity and computational efficiency. Benchmark
results show our framework achieves 16x acceleration over baseline
implementations and maintains 8x speedup over 1-thread configuration across MPI
and Pthreads implementations.The combined load balancing and LP migration
strategy reduces synchronization overhead by 58.18%, with load balancing
accounting for 57% of the total improvement as the dominant optimization
factor. These improvements provide an enhanced solution for PDES implementation
in large-scale simulation scenarios.

</details>


### [221] [Towards Designing an Energy Aware Data Replication Strategy for Cloud Systems Using Reinforcement Learning](https://arxiv.org/abs/2507.18459)
*Amir Najjar,Riad Mokadem,Jean-Marc Pierson*

Main category: cs.DC

TL;DR: This paper uses reinforcement learning to create a self-adapting data replication strategy for cloud systems, improving quality of service and balancing profit with environmental impact.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the challenges of traditional threshold-based data replication mechanisms, which require manual adjustment by system administrators due to workload changes and system architecture variations, and to meet the demand for scalable distributed systems that maintain a high quality of service.

Method: The paper proposes a reinforcement learning model for data replication, defining states, actions, and rewards to dynamically adapt to workload changes and different architectures.

Result: The proposed strategy aims to provide satisfactory Quality of Service while optimizing a trade-off between provider profit and environmental impact.

Conclusion: This paper proposes a novel data replication strategy for cloud systems using reinforcement learning to automatically adapt to workload changes and system characteristics, optimizing a trade-off between provider profit and environmental impact.

Abstract: The rapid growth of global data volumes has created a demand for scalable
distributed systems that can maintain a high quality of service. Data
replication is a widely used technique that provides fault tolerance, improved
performance and higher availability. Traditional implementations often rely on
threshold-based activation mechanisms, which can vary depending on workload
changes and system architecture. System administrators typically bear the
responsibility of adjusting these thresholds. To address this challenge,
reinforcement learning can be used to dynamically adapt to workload changes and
different architectures. In this paper, we propose a novel data replication
strategy for cloud systems that employs reinforcement learning to automatically
learn system characteristics and adapt to workload changes. The strategy's aim
is to provide satisfactory Quality of Service while optimizing a trade-off
between provider profit and environmental impact. We present the architecture
behind our solution and describe the reinforcement learning model by defining
the states, actions and rewards.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [222] [Low-power switching of memristors exhibiting fractional-order dynamics](https://arxiv.org/abs/2507.18487)
*Nathan Astin,Yuriy V. Pershin*

Main category: cs.ET

TL;DR: 分数阶忆阻器可以通过电流脉冲进行开关，最佳策略取决于分数阶导数的阶数和运动方程中的功率指数。


<details>
  <summary>Details</summary>
Motivation: 探索分数阶忆阻器设备的开关行为，并提出最小化焦耳损耗的策略，以实现更节能的神经形态计算。

Method: 使用电流脉冲和 Caputo 型导数的分数阶微分方程来模拟忆阻器设备的开关行为，并研究了焦耳损耗。

Result: 研究表明，最小化焦耳损耗的最佳开关策略取决于分数阶导数的阶数和运动方程中的功率指数。当分数阶导数的阶数超过功率指数的一半时，应使用宽脉冲；否则，应使用零电流后跟窄脉冲。

Conclusion: 该研究为下一代节能神经形态计算架构奠定了基础，使其能够更密切地模仿生物学对应物。

Abstract: In this conference contribution, we present some initial results on switching
memristive devices exhibiting fractional-order behavior using current pulses.
In our model, it is assumed that the evolution of a state variable follows a
fractional-order differential equation involving a Caputo-type derivative. A
study of Joule losses demonstrates that the best switching strategy minimizing
these losses depends on the fractional derivative's order and the power
exponent in the equation of motion. It is found that when the order of the
fractional derivative exceeds half of the power exponent, the best approach is
to employ a wide pulse. Conversely, when this condition is not met, Joule
losses are minimized by applying a zero current followed by a narrow current
pulse of the highest allowable amplitude. These findings are explored further
in the context of multi-pulse control. Our research lays the foundation for the
advancement of the next generation of energy-efficient neuromorphic computing
architectures that more closely mimic their biological counterparts.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [223] [Smoothed Analysis of Online Metric Problems](https://arxiv.org/abs/2507.17834)
*Christian Coester,Jack Umenberger*

Main category: cs.DS

TL;DR: 在平滑分析框架下，k-服务器、k-出租车和集合追逐问题均可通过多对数竞争比算法解决，优于纯粹最坏情况。


<details>
  <summary>Details</summary>
Motivation: 研究经典在线问题（如k-服务器、k-出租车和大小为k的集合追逐）在混合了对抗和随机因素（通过平滑分析模型）下的表现，旨在找到比纯粹最坏情况模型更优的算法。

Method: 通过将平滑实例还原为有限度量上的完全对抗实例，并利用现有算法，提供了一种简单有效的求解方法。

Result: 在特定条件下（度量空间位于范数空间球内，请求分布密度有界），所有三个问题均可实现多对数竞争比算法（polylog(k/σ)），并给出了匹配此上限的下限，显著优于纯粹最坏情况下的已知结果（分别为2k-1、∞和Θ(k^2)）。

Conclusion: 该研究表明，在平滑分析的框架下，通过允许请求位置在小的扰动下对抗，可以在$k$-服务器、$k$-出租车和大小为$k$的集合追逐等经典在线问题上实现多对数竞争比算法，这在一定程度上缓和了纯粹最坏情况模型的严格性。

Abstract: We study three classical online problems -- $k$-server, $k$-taxi, and chasing
size $k$ sets -- through a lens of smoothed analysis. Our setting allows
request locations to be adversarial up to small perturbations, interpolating
between worst-case and average-case models. Specifically, we show that if the
metric space is contained in a ball in any normed space and requests are drawn
from distributions whose density functions are upper bounded by $1/\sigma$
times the uniform density over the ball, then all three problems admit
polylog$(k/\sigma)$-competitive algorithms. Our approach is simple: it reduces
smoothed instances to fully adversarial instances on finite metrics and
leverages existing algorithms in a black-box manner. We also provide a lower
bound showing that no algorithm can achieve a competitive ratio
sub-polylogarithmic in $k/\sigma$, matching our upper bounds up to the exponent
of the polylogarithm. In contrast, the best known competitive ratios for these
problems in the fully adversarial setting are $2k-1$, $\infty$ and
$\Theta(k^2)$, respectively.

</details>


### [224] [Better Bounds for Semi-Streaming Single-Source Shortest Paths](https://arxiv.org/abs/2507.17841)
*Sepehr Assadi,Gary Hoppenworth,Janani Sundaresan*

Main category: cs.DS

TL;DR: 在半流模型下，该研究提出的随机化算法在单源最短路径近似方面，将空间和通道复杂度分别降低到 $O(\frac{1}{\epsilon} \cdot n \log^3 n)$ 和 $O(\frac{1}{\epsilon} \cdot (\frac{\log n}{\log\log n})^2)$，优于先前技术。同时，证明了该问题至少需要 $\Omega(\frac{\log n}{\log\log n})$ 通道，将通道复杂度的差距缩小到二次方。


<details>
  <summary>Details</summary>
Motivation: 在半流模型下，对无向图进行单源最短路径近似是一个长期存在的未解决问题。本研究旨在缩小现有算法在通道复杂度上的差距，并为该问题提供理论下界。

Method: 提出一个简单的随机化算法，并给出了其在空间和通道数上的复杂性界限。通过理论推导，证明了任何半流算法在该问题上达到常数近似比所需的最小通道数下界。

Result: 算法方面，提出了一种随机化算法，可以在 $O(\frac{1}{\epsilon} \cdot n \log^3 n)$ 空间和 $O(\frac{1}{\epsilon} \cdot (\frac{\log n}{\log\log n})^2)$ 通道内，以高概率计算 $(1+\epsilon)$-近似最短路径。该算法还可以进行确定化和动态流处理。理论下界方面，证明了任何半流算法要达到常数近似比，至少需要 $\Omega(\frac{\log n}{\log\log n})$ 通道。

Conclusion: 该研究在半流模型中对单源最短路径近似问题取得了进展，通过提出一个简单的随机化算法，在空间和通道数上都优于先前算法。同时，他们还提出了一个理论下界，证明了任何半流算法要达到常数近似比，至少需要 $\Omega(\frac{\log n}{\log\log n})$ 个通道。这些结果将单源最短路径近似的通道复杂度差距从多对数缩小到仅二次方。

Abstract: In the semi-streaming model, an algorithm must process any $n$-vertex graph
by making one or few passes over a stream of its edges, use $O(n \cdot
\text{polylog }n)$ words of space, and at the end of the last pass, output a
solution to the problem at hand. Approximating (single-source) shortest paths
on undirected graphs is a longstanding open question in this model. In this
work, we make progress on this question from both upper and lower bound fronts:
  We present a simple randomized algorithm that for any $\epsilon > 0$, with
high probability computes $(1+\epsilon)$-approximate shortest paths from a
given source vertex in \[
  O\left(\frac{1}{\epsilon} \cdot n \log^3 n \right)~\text{space} \quad
\text{and} \quad O\left(\frac{1}{\epsilon} \cdot \left(\frac{\log n}{\log\log
n} \right) ^2\right) ~\text{passes}.
  \] The algorithm can also be derandomized and made to work on dynamic streams
at a cost of some extra $\text{poly}(\log n, 1/\epsilon)$ factors only in the
space. Previously, the best known algorithms for this problem required
$1/\epsilon \cdot \log^{c}(n)$ passes, for an unspecified large constant $c$.
  We prove that any semi-streaming algorithm that with large constant
probability outputs any constant approximation to shortest paths from a given
source vertex (even to a single fixed target vertex and only the distance, not
necessarily the path) requires \[ \Omega\left(\frac{\log n}{\log\log n}\right)
~\text{passes}. \] We emphasize that our lower bound holds for any
constant-factor approximation of shortest paths. Previously, only constant-pass
lower bounds were known and only for small approximation ratios below two.
  Our results collectively reduce the gap in the pass complexity of
approximating single-source shortest paths in the semi-streaming model from
$\text{polylog } n$ vs $\omega(1)$ to only a quadratic gap.

</details>


### [225] [Strong Sparsification for 1-in-3-SAT via Polynomial Freiman-Ruzsa](https://arxiv.org/abs/2507.17878)
*Benjamin Bedert,Tamio-Vesa Nakajima,Karolina Okrasa,Stanislav Živný*

Main category: cs.DS

TL;DR: 本研究提出强稀疏化概念，为 1-in-3-SAT 设计新算法，并改进超图着色算法。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在探索一种新的稀疏化方法（强稀疏化），通过合并变量来简化问题，并将其应用于解决 1-in-3-SAT 问题以及改进 3-一致超图的近似线性排序着色算法。

Method: 该研究提出了一种新的稀疏化概念——“强稀疏化”，其中变量可以合并而不是移除约束。强稀疏化算法利用了多项式 Freiman-Ruzsa 定理来约束 $\mathbb{F}_2^d$ 中向量集的大小，并成功应用于改进 3-一致超图近似线性排序着色算法。

Result: 成功为 1-in-3-SAT 设计了强稀疏化算法，并证明了该算法的正确性。利用多项式 Freiman-Ruzsa 定理在 $\mathbb{F}_2^d$ 中得到了向量集大小的亚二次界。此外，还改进了 3-一致超图近似线性排序着色的状态艺术算法。

Conclusion: 该研究提出了“强稀疏化”这一新概念，其中变量可以合并而不是移除约束。主要成果是为 1-in-3-SAT 提供了一种强稀疏化算法。此外，该研究还改进了近似 3-一致超图线性排序着色的状态艺术算法。

Abstract: We introduce a new notion of sparsification, called \emph{strong
sparsification}, in which constraints are not removed but variables can be
merged. As our main result, we present a strong sparsification algorithm for
1-in-3-SAT. The correctness of the algorithm relies on establishing a
sub-quadratic bound on the size of certain sets of vectors in $\mathbb{F}_2^d$.
This result, obtained using the recent \emph{Polynomial Freiman-Ruzsa Theorem}
(Gowers, Green, Manners and Tao, Ann. Math. 2025), could be of independent
interest. As an application, we improve the state-of-the-art algorithm for
approximating linearly-ordered colourings of 3-uniform hypergraphs (H{\aa}stad,
Martinsson, Nakajima and{\v{Z}}ivn{\'{y}}, APPROX 2024).

</details>


### [226] [Dual Charging for Half-Integral TSP](https://arxiv.org/abs/2507.17999)
*Nathan Klein,Mehrshad Taziki*

Main category: cs.DS

TL;DR: max entropy算法在half-integral TSP和half integral LP解的近似算法方面取得新进展，界限得到提高。


<details>
  <summary>Details</summary>
Motivation: 提高half-integral TSP和half integral LP解的近似算法的界限，并探索max entropy算法的分析方法。

Method: 使用对偶分析max entropy算法在half-integral TSP上的期望成本，并将其分析扩展到half integral LP解的情况。

Result: max entropy算法是half-integral TSP的1.49776近似算法；为特定情况下的half integral LP解提供1.4671近似，并分析了奇数顶点n的情况。

Conclusion: max entropy算法是half-integral TSP的1.49776近似算法，优于Karlin等人的1.49993。分析方法从primal转向dual，有望简化max entropy优于3/2近似的证明。另外，为不存在proper minimum cut且顶点数为偶数的half integral LP解提供1.4671近似，优于Haddadan和Newman的1.476。对于奇数顶点n，因子增加O(1/n)。

Abstract: We show that the max entropy algorithm is a randomized 1.49776 approximation
for half-integral TSP, improving upon the previous known bound of 1.49993 from
Karlin et al. This also improves upon the best-known approximation for
half-integral TSP due to Gupta et al. Our improvement results from using the
dual, instead of the primal, to analyze the expected cost of the matching. We
believe this method of analysis could lead to a simpler proof that max entropy
is a better-than-3/2 approximation in the general case.
  We also give a 1.4671 approximation for half integral LP solutions with no
proper minimum cuts and an even number of vertices, improving upon the bound of
Haddadan and Newman of 1.476. We then extend the analysis to the case when
there are an odd number of vertices $n$ at the cost of an additional $O(1/n)$
factor.

</details>


### [227] [On recognizing graphs representing Persistent Perfect Phylogenies](https://arxiv.org/abs/2507.18281)
*Paola Bonizzoni,Gianluca Della Vedova,Mauricio Soto Gomez,Gabriella Trucco*

Main category: cs.DS

TL;DR: 研究提出了一种基于图性质的多项式时间算法，用于解决持久性完美系统问题，尤其是在最大图场景下，并缩小了与完美系统和Dollo-k系统在计算复杂度上的差距。


<details>
  <summary>Details</summary>
Motivation: 将持久性完美系统（Dollo-1）作为处理字符缺失的完美系统模型的推广，并着眼于识别相关联的二分图类。

Method: 提出了一种用于判定最大图中持久性完美系统存在性的多项式时间算法，该算法基于图的性质。

Result: 提出了一种多项式时间算法，用于判定最大图中的持久性完美系统存在性。

Conclusion: 该研究为判定最大图中的持久性完美系统存在性提供了一种多项式时间算法，该算法仅依赖于图的性质，缩小了完美系统（线性时间）和Dollo-k系统（k>1，NP-hard）之间的差距。

Abstract: The Persistent Perfect phylogeny, also known as Dollo-1, has been introduced
as a generalization of the well-known perfect phylogenetic model for binary
characters to deal with the potential loss of characters. The problem of
deciding the existence of a Persistent Perfect phylogeny can be reduced to the
one of recognizing a class of bipartite graphs whose nodes are species and
characters. Thus an interesting question is solving directly the problem of
recognizing such graphs. We present a polynomial-time algorithm for deciding
Persistent Perfect phylogeny existence in maximal graphs, where no character's
species set is contained within another character's species set. Our solution,
that relies only on graph properties, narrows the gap between the linear-time
simple algorithm for Perfect Phylogeny and the NP-hardness results for the
Dollo-$k$ phylogeny with $k>1$.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [228] [Safe Reinforcement Learning-based Automatic Generation Control](https://arxiv.org/abs/2507.17868)
*Amr S. Mohamed,Emily Nguyen,Deepa Kundur*

Main category: eess.SY

TL;DR: 本研究提出了一种结合控制障碍函数（CBF）和强化学习（RL）的框架，以确保电力系统（如自动发电控制）的安全运行。


<details>
  <summary>Details</summary>
Motivation: 随着电力系统对高级控制和决策算法的需求不断增长，但机器学习（包括RL）在缺乏安全保障的情况下应用于电力系统引发了关键的安全问题。因此，本研究的动机是开发一种安全的方法来利用RL的优势，同时确保电力系统的稳定性和可靠性。

Method: 本研究开发了一种新的框架，该框架结合了控制障碍函数（CBF）和强化学习（RL），用于电力系统的安全控制。CBF用于确保RL代理在学习和部署过程中保持在安全的操作区域内。

Result: 该研究成功地开发了一个将CBF与RL相结合的框架，为在电力系统控制（特别是AGC）中安全地使用RL奠定了基础。这有助于建立对RL作为安全选项的信任，并为未来的详细验证和应用研究提供了基础。

Conclusion: 本研究提出了一个基于控制障碍函数（CBF）的框架，用于在自动发电控制（AGC）等电力系统控制应用中安全地学习和部署强化学习（RL）代理。

Abstract: Amidst the growing demand for implementing advanced control and
decision-making algorithms|to enhance the reliability, resilience, and
stability of power systems|arises a crucial concern regarding the safety of
employing machine learning techniques. While these methods can be applied to
derive more optimal control decisions, they often lack safety assurances. This
paper proposes a framework based on control barrier functions to facilitate
safe learning and deployment of reinforcement learning agents for power system
control applications, specifically in the context of automatic generation
control. We develop the safety barriers and reinforcement learning framework
necessary to establish trust in reinforcement learning as a safe option for
automatic generation control - as foundation for future detailed verification
and application studies.

</details>


### [229] [Trusted Data Fusion, Multi-Agent Autonomy, Autonomous Vehicles](https://arxiv.org/abs/2507.17875)
*R. Spencer Hallyburton,Miroslav Pajic*

Main category: eess.SY

TL;DR: 为了提高无人机情报、监视和侦察（ISR）任务中的安全性，本研究提出了一种基于信任的传感器融合框架，使用隐马尔可夫模型（HMM）来评估数据来源的可靠性。该方法提高了在受攻击环境下的弹性和准确性，并通过模拟数据集进行了验证。


<details>
  <summary>Details</summary>
Motivation: 为了解决无人机（UAV）在情报、监视和侦察（ISR）任务中，由于其去中心化性质而面临的安全挑战，特别是网络物理攻击的脆弱性，本研究旨在提高分布式多主体网络中的态势感知和数据融合的可靠性。

Method: 本研究提出了一种基于信任的框架，并利用隐马尔可夫模型（HMM）来估计智能体及其提供的信息的可靠性。该框架在分布式多主体网络中实现了去中心化的信任评估和数据融合。

Result: 通过在虚幻引擎模拟器中构建的多主体空中数据集进行评估，研究表明该框架在对抗性环境中能够提高ISR性能并检测恶意行为者。

Conclusion: 该研究提出了一种基于信任的框架，用于分布式多主体网络中的传感器融合，通过使用基于隐马尔可夫模型（HMM）的方法来去中心化地估计智能体及其提供的信息的可靠性。该框架通过优先融合来自可靠来源的数据，提高了在对抗环境中的弹性和准确性，并在各种攻击场景下实现了改进的ISR性能和恶意行为者检测能力。

Abstract: Multi-agent collaboration enhances situational awareness in intelligence,
surveillance, and reconnaissance (ISR) missions. Ad hoc networks of unmanned
aerial vehicles (UAVs) allow for real-time data sharing, but they face security
challenges due to their decentralized nature, making them vulnerable to
cyber-physical attacks. This paper introduces a trust-based framework for
assured sensor fusion in distributed multi-agent networks, utilizing a hidden
Markov model (HMM)-based approach to estimate the trustworthiness of agents and
their provided information in a decentralized fashion. Trust-informed data
fusion prioritizes fusing data from reliable sources, enhancing resilience and
accuracy in contested environments. To evaluate the assured sensor fusion under
attacks on system/mission sensing, we present a novel multi-agent aerial
dataset built from the Unreal Engine simulator. We demonstrate through case
studies improved ISR performance and an ability to detect malicious actors in
adversarial settings.

</details>


### [230] [Rapid Modeling Architecture for Lightweight Simulator to Accelerate and Improve Decision Making for Industrial Systems](https://arxiv.org/abs/2507.17990)
*Takumi Kato,Zhi Li Hu*

Main category: eess.SY

TL;DR: 提出 RMA 架构，构建轻量级工业模拟器，将建模时间减少 78.3%，以加速工业系统设计决策。


<details>
  <summary>Details</summary>
Motivation: 在工业系统设计的早期阶段，信息有限导致设计不够精确，且难以在后期解决。现有的模拟器建模时间过长，无法满足快速决策的需求。

Method: 提出了一种名为 RMA (Rapid Modeling Architecture) 的轻量级工业模拟器架构，并构建了原型系统。

Result: 该模拟器在实际工厂布局设计问题中，建模时间相比传统模拟器减少了 78.3%。

Conclusion: 该研究提出了 RMA 架构，以减轻建模负担，同时保留关键细节，从而加速和改善工业系统设计的决策过程。

Abstract: Designing industrial systems, such as building, improving, and automating
distribution centers and manufacturing plants, involves critical
decision-making with limited information in the early phases. The lack of
information leads to less accurate designs of the systems, which are often
difficult to resolve later. It is effective to use simulators to model the
designed system and find out the issues early. However, the modeling time
required by conventional simulators is too long to allow for rapid model
creation to meet decision-making demands. In this paper, we propose a Rapid
Modeling Architecture (RMA) for a lightweight industrial simulator that
mitigates the modeling burden while maintaining the essential details in order
to accelerate and improve decision-making. We have prototyped a simulator based
on the RMA and applied it to the actual factory layout design problem. We also
compared the modeling time of our simulator to that of an existing simulator,
and as a result, our simulator achieved a 78.3% reduction in modeling time
compared to conventional simulators.

</details>


### [231] [Quantitative Damping Calculation and Compensation Method for Global Stability Improvement of Inverter-Based Systems](https://arxiv.org/abs/2507.18001)
*Yang Li,Zenghui Zheng,Xiangyang Wu,Jiayong Li,Wei Wang,Qiang Zeng,Zhikang Shuai*

Main category: eess.SY

TL;DR: 提出一种定量阻尼计算和补偿的新方法，以提高多逆变器系统的稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决多逆变器系统中由小信号稳定性问题引起的宽带振荡问题，并明确需要多少阻尼补偿才能确保系统的全局稳定性。

Method: 首先，基于节点导纳模型，提出了一种定量阻尼计算算法，用于确定所需的阻尼补偿量和补偿位置。然后，提出了一种具有输出电流前馈控制策略的特定AD，以增强系统阻尼效率。

Result: 仿真和实验结果表明，该方法能有效提高基于逆变器的系统的全局稳定性。

Conclusion: 提出的方法为增强基于逆变器的系统的全局稳定性提供了一种有效的方法，并且得到了仿真和实验的验证。

Abstract: Small-signal stability issues-induced broadband oscillations pose significant
threats to the secure operation of multi-inverter systems, attracting extensive
research attention. Researches revealed that system instability is led by the
lacking of positive damping, yet it has not been clearly specified how much the
exact amount of damping compensation required to sufficiently ensure system
global stability. This paper presents a feasible solution for quantitative
damping calculation and compensation to enhance the global stability of
inverter-based systems. First, based on the system nodal admittance model, a
quantitative damping calculation algorithm is presented, which can suggest the
required damping compensation as well as compensation location for sufficient
stability improvement. Then, we propose a specific AD with output current
feedforward control strategy, which make the AD be quasi-pure resistive and can
effectively enhance system damping efficiency. Finally, a testing system with
three inverters is used as case study, showing that the proposed method
provides a promising solution to efficiently enhance the global stability
improvement of inverter-based systems. Simulations and experiments validate the
proposed method.

</details>


### [232] [Carbon Emission Flow Tracing: Fast Algorithm and California Grid Study](https://arxiv.org/abs/2507.18077)
*Yuqing Shen,Yuanyuan Shi,Daniel Kirschen,Yize Chen*

Main category: eess.SY

TL;DR: 提出了一种新的、计算高效的算法，用于量化单个发电机排放如何通过电网传输并影响特定地点的用户。该算法利用图论技术，并通过在加州电网上进行模拟进行了验证，展示了其在揭示局部和时间排放模式方面的能力。


<details>
  <summary>Details</summary>
Motivation: 尽管系统运营商和公用事业公司日益公开系统层面的碳排放信息，但尚不清楚单个发电机的排放如何通过电网传输以及它们如何影响特定地点的用电客户。

Method: 利用基于图的拓扑排序和有向环移除技术，将它们应用于由发电调度和潮流优化解决方案形成的有向图，从而有效地识别每个发电机对每个节点的影响，并捕获排放量在不同系统条件下的空间分布情况。

Result: 通过对包含8870个节点的实际加利福尼亚电网进行模拟，并结合实际CAISO数据和CATS模型，该算法能够准确估算潮流条件、发电结构和全系统排放量，并对加利福尼亚每个县进行细粒度的时空排放分析。

Conclusion: 该方法为交流和直流最优潮流问题提供了一种新颖且计算高效的方法，用于节点平均和边际碳排放率的精确量化，这为未来在电网排放、规划、运营和能源政策方面的研究提供了基础。

Abstract: Power systems decarbonization are at the focal point of the clean energy
transition. While system operators and utility companies increasingly publicize
system-level carbon emission information, it remains unclear how emissions from
individual generators are transported through the grid and how they impact
electricity users at specific locations. This paper presents a novel and
computationally efficient approach for exact quantification of nodal average
and marginal carbon emission rates, applicable to both AC and DC optimal power
flow problems. The approach leverages graph-based topological sorting and
directed cycle removal techniques, applied to directed graphs formed by
generation dispatch and optimal power flow solutions. Our proposed algorithm
efficiently identifies each generator's contribution to each node, capturing
how emissions are spatially distributed under varying system conditions. To
validate its effectiveness and reveal locational and temporal emission patterns
in the real world, we simulate the 8,870-bus realistic California grid using
actual CAISO data and the CATS model. Based on year long hourly data on nodal
loads and renewable generation, obtained or estimated from CAISO public data,
our method accurately estimates power flow conditions, generation mixes, and
systemwide emissions, and delivers fine grained spatiotemporal emission
analysis for every California county. Both our algorithm and the California
study are open-sourced, providing a foundation for future research on grid
emissions, planning, operations, and energy policy.

</details>


### [233] [Towards Microgrid Resilience Enhancement via Mobile Power Sources and Repair Crews: A Multi-Agent Reinforcement Learning Approach](https://arxiv.org/abs/2507.18095)
*Yi Wang,Dawei Qiu,Fei Teng,Goran Strbac*

Main category: eess.SY

TL;DR: 为应对通信故障，本研究提出了一个去中心化的分层多智能体强化学习方法，用于协调移动电源和维修人员的调度，以增强微电网的韧性，并通过案例研究验证了其在负载恢复方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有工作在解决MPS和RC的协调调度问题时，通常采用中心化方法，并假设通信网络在事件发生后仍然完全正常运行。然而，越来越多的证据表明，某些极端事件会损坏或降级通信基础设施，使得中心化决策不切实际。为了解决这一问题，本研究提出了一个去中心化框架。

Method: 提出了一种分层多智能体强化学习方法，该方法具有一个两级框架：高级动作用于在电力和交通网络之间切换决策，低级动作通过混合策略构建，用于分别计算电力和交通网络中的连续调度和离散路由决策。该方法还嵌入了封装系统动态的函数，以增强学习稳定性和可扩展性。

Result: 通过基于IEEE 33节点和69节点电网的案例研究，验证了所提出方法在负载恢复方面的有效性。

Conclusion: 该论文提出了一种去中心化的框架来解决移动电源（MPS）和维修人员（RC）的韧性驱动调度问题，以应对通信基础设施在极端事件中可能损坏或降级的情况。

Abstract: Mobile power sources (MPSs) have been gradually deployed in microgrids as
critical resources to coordinate with repair crews (RCs) towards resilience
enhancement owing to their flexibility and mobility in handling the complex
coupled power-transport systems. However, previous work solves the coordinated
dispatch problem of MPSs and RCs in a centralized manner with the assumption
that the communication network is still fully functioning after the event.
However, there is growing evidence that certain extreme events will damage or
degrade communication infrastructure, which makes centralized decision making
impractical. To fill this gap, this paper formulates the resilience-driven
dispatch problem of MPSs and RCs in a decentralized framework. To solve this
problem, a hierarchical multi-agent reinforcement learning method featuring a
two-level framework is proposed, where the high-level action is used to switch
decision-making between power and transport networks, and the low-level action
constructed via a hybrid policy is used to compute continuous scheduling and
discrete routing decisions in power and transport networks, respectively. The
proposed method also uses an embedded function encapsulating system dynamics to
enhance learning stability and scalability. Case studies based on IEEE 33-bus
and 69-bus power networks are conducted to validate the effectiveness of the
proposed method in load restoration.

</details>


### [234] [Regional Frequency-Constrained Planning for the Optimal Sizing of Power Systems via Enhanced Input Convex Neural Networks](https://arxiv.org/abs/2507.18102)
*Yi Wang,Goran Strbac*

Main category: eess.SY

TL;DR: 本研究提出了一种新颖的频率约束规划模型，考虑了电力系统中的区域频率安全和跨区域频率振荡问题。通过增强的ICNN提取区域频率约束，并结合自适应遗传算法进行求解，最终在三个电力系统上验证了模型的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多忽略了不同区域频率的差异性，本研究旨在解决这一问题，提出能够考虑区域频率安全和跨区域频率振荡的规划模型。

Method: 本研究提出了一种新颖的规划模型，用于电力系统的最优选址问题，该模型考虑了区域频率安全和跨区域频率振荡。首先，通过增强的输入凸神经网络（ICNN）提取区域频率约束，并将其嵌入到原始优化中，同时采用原则性的权重初始化策略来解决传统ICNN中非负权重的梯度消失问题并增强其拟合能力。接着，开发了一种具有稀疏性计算和局部搜索的自适应遗传算法，将规划模型分为两个阶段并进行迭代求解。

Result: 所提出的模型能够确保区域系统安全并做出切合实际的投资决策，并在三个不同的电力系统上进行了案例研究验证。

Conclusion: 所提出的用于含高比例可再生能源的电力系统的频率约束规划模型能够确保区域系统安全并做出切合实际的投资决策。

Abstract: Large renewable penetration has been witnessed in power systems, resulting in
reduced levels of system inertia and increasing requirements for frequency
response services. There have been plenty of studies developing
frequency-constrained models for power system security. However, most existing
literature only considers uniform frequency security, while neglecting
frequency spatial differences in different regions. To fill this gap, this
paper proposes a novel planning model for the optimal sizing problem of power
systems, capturing regional frequency security and inter-area frequency
oscillations. Specifically, regional frequency constraints are first extracted
via an enhanced input convex neural network (ICNN) and then embedded into the
original optimisation for frequency security, where a principled weight
initialisation strategy is adopted to deal with the gradient vanishing issues
of non-negative weights in traditional ICNNs and enhance its fitting ability.
An adaptive genetic algorithm with sparsity calculation and local search is
developed to separate the planning model into two stages and effectively solve
it iteratively. Case studies have been conducted on three different power
systems to verify the effectiveness of the proposed frequency-constrained
planning model in ensuring regional system security and obtaining realistic
investment decisions.

</details>


### [235] [Two-Stage TSO-DSO Services Provision Framework for Electric Vehicle Coordination](https://arxiv.org/abs/2507.18110)
*Yi Wang,Dawei Qiu,Fei Teng,Goran Strbac*

Main category: eess.SY

TL;DR: 该研究提出了一种两阶段框架和一种基于强化学习的去中心化方法，以协调大规模电动汽车在电网频率服务和电压支持方面的作用，解决了传统方法中通信开销大的问题。


<details>
  <summary>Details</summary>
Motivation: 为了协调电网运营商（TSO）的频率和配电系统运营商（DSO）的电压安全问题，并利用电动汽车（EV）的车辆到电网（V2G）能力来提供成本效益的频率服务。

Method: 提出了一种两阶段的服务提供框架，用于处理电动汽车（EV）的频率响应和电压支持。第一阶段，电动汽车参与日前电网频率互动，用于频率储备调度。第二阶段，电动汽车在配电网中进行实时调度，以实现储备输送并支持电压。为处理大规模电动汽车数量和复杂环境，提出了一种去中心化操作模式，并提出了一种通信高效的强化学习算法，用于减少大规模多代理强化学习训练中的通信开销，同时不影响策略性能。

Result: 通过在不同规模的电网（包括6节点输电网络和33节点/69节点配电网络）上进行案例研究，验证了所提出方法的有效性和可扩展性，证明了该方法能够使电动汽车有效支持频率服务和电压。

Conclusion: 所提出的框架能够有效协调电网频率和电压安全，所提出的去中心化操作范式和通信高效强化学习算法能够有效处理大规模多代理强化学习训练中的通信开销问题，同时不影响策略性能。

Abstract: High renewable penetration has been witnessed in power systems, resulting in
reduced system inertia and increasing requirements for frequency response
services. Electric vehicles (EVs), owing to their vehicle-to-grid (V2G)
capabilities, can provide cost-effective frequency services for transmission
system operators (TSOs). However, EVs that are inherently connected to
distribution networks may pose voltage security issues for distribution system
operators (DSOs) when supporting TSO frequency. To coordinate both TSO
frequency and DSO voltage, this paper proposes a two-stage service provision
framework for multi-EVs. At stage one, EVs participate in day-ahead TSO-DSO
interactions for frequency reserve schedules; at stage two, EVs make real-time
dispatching behaviors in distribution networks for reserve delivery while
supporting DSO voltage. Considering the potentially large EV number and
environment complexity, a decentralized operation paradigm is introduced for
real-time EV dispatches at stage two, while a communication-efficient
reinforcement learning (RL) algorithm is proposed to reduce the communication
overhead during large-scale multi-agent RL training without compromising policy
performance. Case studies are carried out on a 6-bus transmission and 33-bus
distribution network as well as a 69-bus distribution network to evaluate the
effectiveness and scalability of the proposed method in enabling EVs for
frequency service and voltage support.

</details>


### [236] [Data-Driven Model Order Reduction for Continuous- and Discrete-Time Nonlinear Systems](https://arxiv.org/abs/2507.18131)
*Behrad Samari,Henrik Sandberg,Karl H. Johansson,Abolfazl Lavaei*

Main category: eess.SY

TL;DR: 该研究提出了一种数据驱动的框架，用于构建非线性动力学系统的降阶模型（ROM），即使在系统模型未知且高度非线性时也是如此。该方法利用系统数据构建ROM，并通过半定规划提供保证。所提出的方法在控制合成方面已被证明是有效的。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的许多复杂系统，特别是那些具有高度非线性项且其精确模型未知的系统，在模型降阶（ROM）构建方面面临严峻挑战。尽管ROM对于控制器设计至关重要，但克服这些挑战对于实际应用至关重要。

Method: 本研究提出了一种数据驱动的框架，利用两个输入-状态轨迹数据集构建系统的基于数据的闭环表示。该方法采用仿真函数（SF）的概念来表征原始系统与其数据驱动ROM之间的相似性。具体而言，研究提出了数据依赖的半定规划，以同时构建ROM和SF，并保证其正确性。随后，将为ROM设计的控制器通过接口函数迁移到原始系统。

Result: 所提出的数据驱动ROM在四个涉及未知动力学和高度非线性项的基准案例研究中被证明是有效的。这些ROM能够成功地用于综合控制器，从而确保满足高层逻辑属性的未知系统。

Conclusion: 该研究提出了一个数据驱动的框架，用于为具有未知模型和高非线性项的连续时间和离散时间非线性动力学系统构建降阶模型（ROM）。通过利用两个输入-状态轨迹数据集，该框架首先构建系统的基于数据的闭环表示，然后利用仿真函数（SF）的概念建立原始系统与数据驱动ROM输出轨迹之间的相似性关系，从而为它们的接近度提供形式化表征。研究提出了数据依赖的半定规划作为同时构建ROM和SF的充分条件，并提供了正确性保证。最后，通过将控制器设计从数据驱动ROM迁移到原始系统，验证了该框架在满足高层逻辑属性方面的有效性，并通过四个基准案例研究进行了评估。

Abstract: Model order reduction simplifies high-dimensional dynamical systems by
deriving lower-dimensional models that preserve essential system
characteristics. These techniques are crucial to controller design for complex
systems while significantly reducing computational costs. Nevertheless,
constructing effective reduced-order models (ROMs) poses considerable
challenges, particularly for dynamical systems characterized by highly
nonlinear terms. These challenges are further exacerbated when the actual
system model is unavailable, a scenario frequently encountered in real-world
applications. In this work, we propose a data-driven framework for the
construction of ROMs for both continuous- and discrete-time nonlinear dynamical
systems with unknown mathematical models. By leveraging two sets of data
collected from the system, referred to as two input-state trajectories, we
first construct a data-based closed-loop representation of the system. We then
establish a similarity relation between the output trajectories of the original
system and those of its data-driven ROM employing the notion of simulation
functions (SFs), thereby enabling a formal characterization of their closeness.
To achieve this, we propose data-dependent semidefinite programs as sufficient
conditions to simultaneously construct both ROMs and SFs, while offering
correctness guarantees. We demonstrate that the obtained data-driven ROMs can
be employed for synthesizing controllers that ensure the unknown system
satisfies high-level logic properties. This is accomplished by first designing
controllers for the data-driven ROMs and then translating the results back to
the original system through an interface function. We evaluate the efficacy of
our data-driven findings through four benchmark case studies involving unknown
dynamics with highly nonlinear terms.

</details>


### [237] [Data-Driven Incremental GAS Certificate of Nonlinear Homogeneous Networks: A Formal Modular Approach](https://arxiv.org/abs/2507.18141)
*Mahdieh Zaker,David Angeli,Abolfazl Lavaei*

Main category: eess.SY

TL;DR: 该研究提出了一种数据驱动的组合方法，用于验证具有未知动力学的互联网络稳定性。该方法通过解决子系统的场景优化问题来构建Lyapunov函数，样本复杂度与子系统数量呈线性关系，优于现有整体方法。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是为具有未知动力学的互联网络提供一种可行的稳定性验证方法。现有的整体方法在面对大量子系统时，样本复杂度呈指数增长，不适用于实际应用。因此，需要一种新的方法，该方法能够处理未知的动力学，并且样本复杂度与子系统数量呈线性增长。

Method: 该研究采用数据驱动的组合方法。首先，将增量输入状态稳定性（delta-ISS）的Lyapunov条件转化为鲁棒优化问题（ROP）。然后，通过收集子系统轨迹数据，开发场景优化程序（SOP）来解决ROP中的未知动力学问题，从而为每个子系统构建数据驱动的delta-ISS Lyapunov函数。最后，利用小增益组合条件，基于子系统的数据驱动delta-ISS Lyapunov函数，构建互联网络的增量Lyapunov函数。

Result: 该研究成功地开发了一种数据驱动的组合方法，该方法能够处理具有未知动力学的互联网络。实验结果表明，该方法将样本复杂度与子系统粒度相匹配，随着子系统数量的增加，所需数据呈线性增长。与现有的整体方法相比，该方法在样本复杂度方面具有显著优势。通过将该方法应用于一个包含10000个子系统的未知非线性齐次网络，并提供了正确性保证，证明了该方法的有效性。

Conclusion: 该研究提出了一种数据驱动的组合方法，用于验证具有未知动力学的单度齐次互联网络中的增量全局渐近稳定性（delta-GAS）。通过将增量输入状态稳定性（delta-ISS）条件重新表述为鲁棒优化问题（ROP），然后开发场景优化程序（SOP）来处理未知的子系统动力学，并利用小增益组合条件，成功构建了增量Lyapunov函数，验证了网络的delta-GAS性质。

Abstract: This work focuses on a compositional data-driven approach to verify
incremental global asymptotic stability (delta-GAS) over interconnected
homogeneous networks of degree one with unknown mathematical dynamics. Our
proposed approach leverages the concept of incremental input-to-state stability
(delta-ISS) of subsystems, characterized by delta-ISS Lyapunov functions. To
implement our data-driven scheme, we initially reframe the delta-ISS Lyapunov
conditions as a robust optimization program (ROP). However, due to the presence
of unknown subsystem dynamics in the ROP constraints, we develop a scenario
optimization program (SOP) by gathering data from trajectories of each unknown
subsystem. We solve the SOP and construct a delta-ISS Lyapunov function for
each subsystem with unknown dynamics. We then leverage a small-gain
compositional condition to facilitate the construction of an incremental
Lyapunov function for an unknown interconnected network with unknown dynamics
based on its data-driven delta-ISS Lyapunov functions of individual subsystems,
while providing correctness guarantees. We demonstrate that our data-driven
compositional approach aligns sample complexity with subsystem granularity,
resulting in a linear increase in required data as the number of subsystems
rises. In contrast, the existing monolithic approach in the literature exhibits
exponential growth in sample complexity with increasing number of subsystems,
rendering it impractical for real-world applications. To validate the
effectiveness of our compositional data-driven approach, we apply it to an
unknown nonlinear homogeneous network of degree one, comprising 10000
subsystems. By gathering data from each unknown subsystem, we demonstrate that
the interconnected network is delta-GAS with a correctness guarantee.

</details>


### [238] [Unit Commitment Framework for Nuclear Reactors with Reactivity Decline](https://arxiv.org/abs/2507.18150)
*Shiny Choudhury,Michael Davidson,George Tynan*

Main category: eess.SY

TL;DR: 这项工作提出了一种创新的建模方法，将燃料循环动力学和氙中毒等物理约束整合到核反应堆的调度框架中。通过考虑这些因素，可以实现更灵活的运行，减缓反应性衰减，延长燃料循环，并为将核能更有效地整合到能源系统提供支持。


<details>
  <summary>Details</summary>
Motivation: 传统的核反应堆模型通常将其视为具有固定停机时间和限制性爬坡能力的不灵活的基荷发电机。然而，反应堆的运行灵活性实际上与其燃料循环阶段和相关的反应性裕度密切相关。氙中毒是影响功率机动性的一个关键物理约束，它是由功率爬坡下降后中子吸收氙浓度增加引起的。这可能因抑制核心反应性而延迟甚至阻止随后的功率爬坡。此外，如果反应堆在低反应性期间关闭，由于氙瞬态的变化，重新启动时间可能差异很大，导致停机时间延长。因此，有必要开发一种能够准确反映这些物理行为的建模方法。

Method: 提出了一种结合了燃料循环动力学的物理信息元启发式建模方法，并将其嵌入单元承诺（UC）框架。该框架能够跟踪反应性裕度、动态激活与氙相关的约束，并根据核心条件内生地实施重新燃料运行。

Result: 通过将燃料循环动力学嵌入单元承诺框架，可以实现考虑操作依赖性的核调度，该调度能够反映监管限制和物理行为。对代表性反应堆机队进行的应用表明，灵活运行可以减缓反应性衰减并延长燃料循环。因此，燃料循环感知灵活性建模对于准确调度核反应堆至关重要，并为将核能整合到能源系统模型中提供了可行的途径。

Conclusion: 通过将燃料循环动力学嵌入单元承诺框架，可以实现考虑操作依赖性的核调度，该调度能够反映监管限制和物理行为。对代表性反应堆机队进行的应用表明，灵活运行可以减缓反应性衰减并延长燃料循环。因此，燃料循环感知灵活性建模对于准确调度核反应堆至关重要，并为将核能整合到能源系统模型中提供了可行的途径。

Abstract: Nuclear reactors are often modeled as inflexible, baseload generators with
fixed downtimes and restrictive ramping limits. In practice, however, a
reactor's operational flexibility is closely tied to it's fuel cycle stage and
the associated reactivity margin. A key physical constraint to power
maneuverability is xenon poisoning, caused by an increase in neutron absorbing
xenon concentration following a power ramp down. This can delay or even prevent
subsequent power ramp up due to suppressed core reactivity. Additionally, if a
reactor is shutdown during periods of low reactivity, restart times can vary
significantly due to these xenon transients, leading to longer downtimes. This
work introduces a physics informed, metaheuristic modeling approach that embeds
fuel cycle dynamics directly with a unit commitment (UC) framework. The
framework tracks reactivity margin, dynamically activates xenon related
constraints, and endogenously implements refueling outages based on the core
conditions. By capturing intra-cycle reactivity evolution and the conditional
onset of xenon poisoning, the formulation allows for operation dependent
nuclear dispatch that reflects both regulatory limits and physical behavior.
When applied to a representative reactor fleet operating in distinct modes of
operation -- ranging from baseload to part load -- the framework reveals that
flexible operation can slow reactivity degradation and extend fuel cycles. The
results show that fuel cycle aware flexibility modeling is critical for
accurate scheduling of nuclear reactors and offers a tractable pathway to
integrate nuclear power in energy system models.

</details>


### [239] [Stability Constrained Voltage Control in Distribution Grids with Arbitrary Communication Infrastructure](https://arxiv.org/abs/2507.18158)
*Zhenyi Yuan,Jie Feng,Yuanyuan Shi,Jorge Cortés*

Main category: eess.SY

TL;DR: 所提出的框架利用任意通信基础设施来设计基于学习的、可证明稳定的电压调节控制器，并在UCSD微电网测试平台上进行了有效验证。


<details>
  <summary>Details</summary>
Motivation: 为了在确保闭环系统稳定性的同时，设计出能够执行配电网电压调节功能Thus， 基于学习的反应式功率控制器。

Method: 提出了一种统一的设计框架，用于设计基于学习的、可证明稳定的电压调节控制器。该框架允许控制器利用任意通信基础设施，并使用输入凸神经网络（ICNN）来满足稳定性约束。

Result: 仿真结果表明，该框架在加州大学圣地亚哥分校（UCSD）微电网测试平台上是有效的，并强调了通信在改善控制性能方面的作用。

Conclusion: 所提出的框架通过允许控制器利用任意通信基础设施来利用本地总线之外的信息，从而克服了现有方法在分散式控制器上的限制，为控制器设计带来了更宽松的约束。

Abstract: We consider the problem of designing learning-based reactive power
controllers that perform voltage regulation in distribution grids while
ensuring closed-loop system stability. In contrast to existing methods, where
the provably stable controllers are restricted to be decentralized, we propose
a unified design framework that enables the controllers to take advantage of an
arbitrary communication infrastructure on top of the physical power network.
This allows the controllers to incorporate information beyond their local bus,
covering existing methods as a special case and leading to less conservative
constraints on the controller design. We then provide a design procedure to
construct input convex neural network (ICNN) based controllers that satisfy the
identified stability constraints by design under arbitrary communication
scenarios, and train these controllers using supervised learning. Simulation
results on the the University of California, San Diego (UCSD) microgrid testbed
illustrate the effectiveness of the framework and highlight the role of
communication in improving control performance.

</details>


### [240] [Optimal Integration Of Heat-Pump And Solar Thermal Energy In The Pre-heating Loop Of Wood And Gas Boiler Based District Heating System](https://arxiv.org/abs/2507.18204)
*Hamza Mettali,Rousset François,Eric Bideaux,Clausse Marc*

Main category: eess.SY

TL;DR: 本研究通过MILP模型优化了区域能源网络中的太阳能热集成，考虑了经济和环境因素。结果显示，太阳能集成面积可达11,932平方米，但可能增加天然气消耗和储热损失。结合生物质能可提高系统稳定性和成本效益，但限制了可再生能源渗透率。


<details>
  <summary>Details</summary>
Motivation: 为了在区域能源网络中实现供热脱碳，本研究旨在优化太阳能热（结合或不结合热泵）的系统设计，以应对其性能对室外和设定温度的高度依赖性，并综合考虑技术经济和环境因素。

Method: 该研究使用混合整数线性规划（MILP）模型，并结合温度离散化技术来解决区域能源网络中太阳能热集成的优化问题。该模型考虑了技术经济和环境（CO2）因素，旨在优化系统设计。

Result: 通过温度离散化和MILP模型，研究成功地将MIP间隙从19%（26小时）减少到10%（12小时），并消散了6%的过剩太阳热。多情景分析显示，在不同碳税和排放情景下，太阳能集成面积可达11,932平方米，但天然气消耗增加（50%）和储热损失增加（49%）。引入木材锅炉可覆盖45%的热需求，降低单位热成本（LCOH），但限制了可再生能源渗透率。高碳税促进了太阳能的应用，但遇到了储能效率瓶颈，而生物质则提升了成本效益和系统稳定性。

Conclusion: 该研究开发了一个多标准的优化方法，结合了技术经济和环境因素，为区域能源网络中的太阳能热集成提供了优化设计策略。研究结果表明，在不同碳税和排放情景下，太阳能集成面积可达11,932平方米，但也会增加天然气消耗和储热损失。引入木材锅炉可以减少对太阳能的依赖，但限制了可再生能源的渗透率。提高碳税会促进太阳能的应用，但会面临储能效率的问题，而生物质则能提高成本效益和系统稳定性。

Abstract: The integration of renewable sources is essential for decarbonizing heat
production in district energy networks. Beyond biomass-based solutions, solar
thermal energy, with or without heat pumps, presents a significant opportunity.
However, system performance is highly dependent on outdoor and setpoint
temperatures. This study aims to optimize system design using a multi-criteria
approach that considers techno-economic and environmental (CO2) factors. A
Mixed-Integer Linear Programming (MILP) model is developed, incorporating
temperature discretization for problem linearization and capturing key dynamic
characteristics of heat generators. The model improves convergence, reducing a
19% MIP gap in 26 hours to 10% in 12 hours by dissipating 6% excess solar heat.
A multi-scenario analysis under two carbon taxation levels and different CO2
emission cases revealed solar integration up to 11,932 m${}^2$ but increased
gas reliance (50%) and TES losses (49%). Wood boiler inclusion reduced solar
dependency, covering 45% of heat, lowered LCOH, but limited renewable
penetration. Higher carbon taxes boosted solar adoption but faced storage
inefficiencies, while biomass enhanced cost efficiency and system stability.

</details>


### [241] [Maneuvering-based Dynamic Thrust Allocation for Fully-Actuated Vessels](https://arxiv.org/abs/2507.18309)
*Emir Cem Gezer,Roger Skjetne*

Main category: eess.SY

TL;DR: 该研究提出了一种用于全驱动船舶的推力分配新方法，通过Lyapunov函数和控制屏障函数确保动态跟踪和限制遵守，实现了简单有效且平滑的推力器参考信号。


<details>
  <summary>Details</summary>
Motivation: 为了解决全驱动船舶的推力分配问题，并为推力器提供平滑、动态的参考信号。

Method: 使用控制Lyapunov函数创建非线性参考滤波器，并利用控制屏障函数来确保推力器力度的饱和限制得到遵守。

Result: 实现了一种简单有效的方法，用于船舶的推力分配。

Conclusion: 该方法通过控制Lyapunov函数创建推力器力度的非线性参考滤波器，并利用控制屏障函数来确保推力器力度的饱和限制得到遵守，从而为全驱动船舶的航行器操作问题提供了一种新的推力分配方法。

Abstract: This paper introduces a new approach to solving the thrust allocation problem
using the maneuvering problem in the maritime domain for fully actuated
vessels. The method uses a control Lyapunov function to create a nonlinear
reference filter for the thruster forces. The filter ensures dynamic tracking
of the optimal thrust allocation solution with rate limitation in the output
thruster references. It further uses control barrier functions to ensure that
the thruster force saturation limits are respected. The approach aims for
simplicity and effectiveness, as well as smooth and dynamic thruster reference
signals, in the implementation of thrust allocation for marine vessels.

</details>


### [242] [Toward Sustainable Vertical Farming: Impacts of Environmental Factors and Energy Mix on Performance and Costs](https://arxiv.org/abs/2507.18419)
*Francesco Ceccanti,Aldo Bischi,Umberto Desideri,Andrea Baccioli*

Main category: eess.SY

TL;DR: 本研究评估了垂直农业系统的生产性能和能耗，通过改变温度、PPFD、CO2 浓度和隔热厚度，并考虑了不同的气候区。结果显示 PPFD 对作物生长和能耗影响最大。研究确定了最具成本效益的设置为 24°C、250 PPFD、1400 ppm CO2，并带有隔热层。为了实现可持续性，需要近乎脱碳的能源系统。


<details>
  <summary>Details</summary>
Motivation: 垂直农业因其在保障稳定、优质、无病虫害的蔬菜生产方面的潜力，以及与能源系统和城市发展的协同作用而受到越来越多的关注。因此，需要标准化的设计和运营指南来提高能源效率和降低成本。

Method: 通过结合挪威、中国和迪拜三个不同的气候区（代表不同的社会环境因素）的三种温度、光合光子通量密度（PPFD）和二氧化碳浓度水平，评估了 162 种情景。此外，还测试了两种隔热厚度。

Result: PPFD 是作物生长的主要因素（相关性：0.85），其次是二氧化碳（0.36）和室内温度（0.22）。PPFD 也是总能耗的主要驱动因素（相关性：0.73），因为它同时影响照明和暖通空调系统负荷。最低的比耗能量（SEC）与最低的作物生产率（55 kg/m2）相吻合。研究确定了最具成本效益的设置为 24°C、250 PPFD、1400 ppm CO2，并带有隔热层，这在所有气候下都是一致的。

Conclusion: 只有近乎脱碳的能源系统才能支持垂直农业，而不会像进口生菜那样增加二氧化碳排放量。

Abstract: The increasing interest in vertical farming arises from its ability to ensure
consistent, high-quality, and pest-free vegetable production while supporting
synergies with energy systems and urban development. Accordingly, standardized
design and operation guidelines are essential to improve energy efficiency and
lower costs. This study analyzes the production performance and energy
consumption of a vertical farming system, assessing its efficiency,
sustainability, and economic viability. A total of 162 scenarios were evaluated
by combining three levels of temperature, photosynthetic photon flux density
(PPFD), and CO2 concentration across three distinct climatic zones, namely
Norway, China, and Dubai, which also differ from a socio-environmental
viewpoint. Two insulation thicknesses were also tested in each scenario.
Results indicate that due to the heating, ventilation, and air conditioning and
dehumidification (HVACD) system, neither the insulation layer nor the external
climate significantly influences crop productivity. PPFD proved to be the
dominant factor in crop growth (correlation: 0.85), followed by CO2 (0.36) and
indoor temperature (0.22). PPFD also emerged as the primary driver of overall
energy consumption (correlation: 0.73), as it affects both lighting and HVACD
loads. Notably, the lowest specific energy consumption (SEC) coincided with the
lowest crop productivity (55 kg/m2). The levelized cost of lettuce (LCoL),
balancing productivity and energy use, identified the most cost-effective setup
as 24C, 250 PPFD, 1400 ppm CO2, with insulation, consistent across all
climates. Ultimately, only nearly decarbonized energy systems can support
vertical farming without increasing CO2 emissions compared to imported lettuce.

</details>


### [243] [A Robust Predictive Control Method for Pump Scheduling in Water Distribution Networks](https://arxiv.org/abs/2507.18492)
*Mirhan Ürkmez,Carsten Kallesøe,Jan Dimon Bendtsen,Eric C. Kerrigan,John Leth*

Main category: eess.SY

TL;DR: 该研究提出了一种鲁棒模型预测控制（RMPC）方法，用于优化水泵调度，以降低电力成本。该方法能够处理模型不确定性和用水量预测误差，并在实际案例中表现优于其他MPC方法。


<details>
  <summary>Details</summary>
Motivation: 为了降低供水管网（WDNs）因水泵运行而产生的电力成本，同时克服模型不确定性和用水量预测误差带来的挑战。

Method: 使用鲁棒模型预测控制（RMPC）方法，通过优化调度策略来最小化泵的运行成本，同时满足系统约束。该方法将一个线性模型与有界扰动相结合，并通过稀疏化优化问题将其计算复杂度从O(N^6)降低到O(N^3)。

Result: 与名义和约束收紧的MPC方法相比，该RMPC方法在满足约束方面表现更优，并且在经济效益方面相当。

Conclusion: 所提出的鲁棒模型预测控制（RMPC）方法在满足约束方面优于名义和约束收紧的模型预测控制（MPC）方法，并在经济效益方面具有可比性。

Abstract: Water utilities aim to reduce the high electrical costs of Water Distribution
Networks (WDNs), primarily driven by pumping. However, pump scheduling is
challenging due to model uncertainties and water demand forecast errors. This
paper presents a Robust Model Predictive Control (RMPC) method for optimal and
reliable pump scheduling, extending a previous efficient robust control method
tailored to our model. A linear model with bounded additive disturbances is
used to represent tank water level evolution, with uncertainty bounds derived
from WDN simulation and demand data. At each time step, a pump scheduling
policy, affine in past disturbances, is optimized to satisfy system constraints
over a prediction horizon. The resulting policies are then applied in a
receding horizon fashion. The optimization problem is formulated to require
$\mathcal{O}(N^6)$ computations per iteration with an interior-point method,
which is reduced to $\mathcal{O}(N^3)$ by reformulating it into a sparse form.
When evaluated on a model representing the water distribution network of
Randers, a medium-sized town in Denmark, the method surpasses nominal and
constraint-tightening model predictive control (MPC) approaches in terms of
meeting constraints and provides comparable economic outcomes.

</details>


### [244] [Global Observer Design for a Class of Linear Observed Systems on Groups](https://arxiv.org/abs/2507.18493)
*Changwu Liu,Yuan Shen*

Main category: eess.SY

TL;DR: 提出了一个统一的观察器框架，用于处理李群上的线性观测系统。通过将系统沉浸到线性时变系统中，并结合类似卡尔曼的观察器和优化重构，可以实现全局或半全局稳定性，并应用于导航问题。


<details>
  <summary>Details</summary>
Motivation: 线性观测系统在群上对各种实际状态估计问题的几何形状进行编码。

Method: 通过将李群上的双不变系统限制在其正规子群上，提出了一种线性观察器框架，该框架可以将原始系统沉浸到线性时变系统中。通过为沉浸式系统设计类似卡尔曼的观察器，然后通过优化重构群值状态来构建观察器。

Result: 在秩条件满足且找到重构优化的全局最优值的情况下，可以实现全局指数稳定性（GES），这反映了非欧几里得状态空间固有的拓扑困难。当联合估计输入偏差时，可以保证半全局稳定性。

Conclusion: 该理论应用于双帧系统的全局指数稳定性（GES）观察器设计，可为一系列导航问题建模。提供了两个非平凡的示例来说明实现的细节。

Abstract: Linear observed systems on groups encode the geometry of a variety of
practical state estimation problems. In this paper, we propose a unified
observer framework for a class of linear observed systems by restricting a
bi-invariant system on a Lie group to its normal subgroup. This structural
property powerfully enables a system immersion of the original system into a
linear time-varying system. Leveraging the immersion, an observer is
constructed by first designing a Kalman-like observer for the immersed system
and then reconstructing the group-valued state via optimization. Under a rank
condition, global exponential stability (GES) is achieved provided one global
optimum of the reconstruction optimization is found, reflecting the topological
difficulties inherent to the non-Euclidean state space. Semi-global stability
is guaranteed when input biases are jointly estimated. The theory is applied to
the GES observer design for two-frame systems, capable of modeling a family of
navigation problems. Two non-trivial examples are provided to illustrate
implementation details.

</details>


### [245] [Design and optimization of a novel leaf-shape antenna for RF energy transfer](https://arxiv.org/abs/2507.18630)
*Junbin Zhong,Mingtong Chen,Zhengbao Yang*

Main category: eess.SY

TL;DR: 受叶子启发的射频能量传输天线在915 MHz下表现出色，可用于为设备供电。


<details>
  <summary>Details</summary>
Motivation: 为射频能量传输设计一种受生物启发的叶形天线，并优化其在915 MHz频段的性能。

Method: 设计并优化了受自然叶片启发的叶形天线，使用AutoCAD和HFSS软件进行建模，并通过制作PCB原型、进行仿真和物理测试来优化其性能，重点在于实现915 MHz频段的阻抗匹配。

Result: 天线在915 MHz频率下达到了接近-20 dB的S11参数，表明其能有效捕获射频能量，并能在最远200 cm的距离为设备供电。

Conclusion: 该研究提出的叶形天线设计通过了阻抗匹配，在915 MHz频段表现出优异的射频能量捕获能力，并成功为设备供电。

Abstract: In this research, the design and optimization of a novel leaf-shaped antenna
inspired by natural leaf structures for radio frequency energy transfer is
presented. The objectives of this study are to develop a bio-inspired antenna,
optimize its performance through impedance matching for the 915 MHz frequency
band, and evaluate its efficiency in capturing RF energy. The design process
involves selecting an appropriate leaf shape, modeling the antenna using
AutoCAD and HFSS software, and fabricating a printed circuit board (PCB)
prototype. Simulations and physical tests are conducted to optimize the
antennas performance, achieving an S11 parameter of nearly -20 dB at 915 MHz,
indicating effective energy capture. Experimental results demonstrate the
antennas ability to power a device at distances up to 200 cm, with charging
times reflecting its efficiency. The study concludes that the bio-inspired
design of the proposed antenna improves RF energy transfer. Future work should
focus on testing the antennas penetration through concrete and developing a
feedback system for autonomous alignment.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [246] [Quantum Geometric Injection and Shift Optical Forces Drive Coherent Phonons](https://arxiv.org/abs/2507.17814)
*J. Luke Pimlott,Habib Rostami*

Main category: cond-mat.mes-hall

TL;DR: 该研究发现了两种新的声子机制（注入力和移位力），它们可以用于操纵量子材料，并且可以通过改变驱动频率和磁通量进行调节。


<details>
  <summary>Details</summary>
Motivation: 识别了注入力和移位力这两种声子机制，它们是光电流效应的声子对应物，能够驱动晶格振动并触发瞬态涌现性质。

Method: 利用双层Haldane模型，通过解析和数值方法量化了作用于层间剪切声子的注入力和移位力。

Result: 揭示了通过改变驱动频率和磁通量可以对注入力和移位力进行强烈的可调性（包括幅度和方向），发现了通过超快相干操纵量子材料的一种独特的量子几何机制。

Conclusion: 该研究揭示了注入力和移位力这两种由量子几何张量、声子移位矢量和带间电子-声子耦合不对称性决定的、由光电流效应驱动晶格振动的声子对应物，它们可以触发瞬态的涌现性质。

Abstract: We identify {\em injection} and {\em shift} rectified Raman forces, which are
phononic counterparts of the photogalvanic effect, that drive lattice
vibrations and trigger transient emergent properties. These forces are governed
by the {\em quantum geometric tensor}, a {\em phononic shift vector}, and
interband asymmetries in the electron-phonon coupling. The injection force acts
displacively, while -- unlike conventional impulsive mechanisms -- the shift
force emerges impulsively in the resonant interband absorbing regime when
time-reversal symmetry is broken. Using the bilayer Haldane model, we quantify
the injection and shift forces acting on interlayer shear phonons through both
analytical and numerical methods. Strikingly, we reveal strong tunability, both
in magnitude and direction, of the rectified forces by varying the driving
frequency and magnetic flux, uncovering a distinct quantum geometric mechanism
for ultrafast and coherent manipulation of quantum materials.

</details>


### [247] [Higher Chern bands in helical homotrilayer transition metal dichalcogenides](https://arxiv.org/abs/2507.17819)
*Jungho Daniel Choi,Nicolás Morales-Durán,Yves H. Kwan,Andrew J. Millis,Nicolas Regnault,Daniele Guerci*

Main category: cond-mat.mes-hall

TL;DR: 研究提出了一种新的材料平台，用于实现可调的关联拓扑相，并确定了实现特定拓扑特性的条件。


<details>
  <summary>Details</summary>
Motivation: 为了实现具有更高和可调陈数的关联拓扑相。

Method: 提出了扭曲的同层三层过渡金属硫属化物作为实现具有更高和可调陈数（Chern numbers）的关联拓扑相的平台。推导了一个低能连续模型，并推导了一个高对称堆垛域的有效紧束缚描述。

Result: 研究确定了扭转角和位移场的范围，使得最高空穴能带与其他能带分离，并具有 K 谷陈数 C=-2。

Conclusion: 研究表明，扭转角和位移场可以诱导从 C=-2 到 C=-1 的转变，以及从拓扑平庸能带到 C=-1 能带的转变。在 Hartree-Fock 计算中，C=-2 能带在相互作用存在的情况下，在填充因子 ν=-1 处仍能保持稳定。

Abstract: We propose helically twisted homotrilayer transition metal dichalcogenides as
a platform for realizing correlated topological phases of matter with higher
and tunable Chern numbers. We show that a clear separation of scales emerges
for small twist angles, allowing us to derive a low-energy continuum model that
captures the physics within moir\'e-scale domains. We identify regimes of twist
angle and displacement field for which the highest-lying hole band is isolated
from other bands and is topological with $K$-valley Chern number $C=-2$. We
demonstrate that varying the displacement field can induce a transition from
$C=-2$ to $C=-1$, as well as from a topologically trivial band to a $C=-1$
band. We derive an effective tight-binding description for a high-symmetry
stacking domain which is valid for a wide range of twist angles, and we show
that the $C=-2$ band can remain stable at filling fraction $\nu=-1$ in the
presence of interactions in Hartree-Fock calculations.

</details>


### [248] [Extending exciton and trion lifetimes in MoSe$_{2}$ with a nanoscale plasmonic cavity](https://arxiv.org/abs/2507.17879)
*Grace H. Chen,Anchita Addhya,Ian N. Hammock,Philip Kim,Alexander A. High*

Main category: cond-mat.mes-hall

TL;DR: 通过将MoSe2置于银腔中，延长了激子寿命，为研究暗激子和开发新光电器件提供了途径。


<details>
  <summary>Details</summary>
Motivation: 过渡金属硫属化物的激子寿命极短（皮秒级），这阻碍了激子热化、限制了集体相干性的出现，并降低了激子在光电器件中的传输。本研究旨在解决这一问题。

Method: 将MoSe2置于深亚波长法布里-珀罗银腔中，利用全光学方法延长激子寿命。

Result: 观察到激子和trion的光致发光（PL）谱线宽度一致性地减小（~1 nm），相应的寿命增加（~10 ps）。

Conclusion: 本研究探索了一种全光学方法，通过将MoSe2置于深亚波长法布里-珀罗银腔中，延长激子寿命。该腔体结构旨在抑制平面光学偶极子（如や激子和trion）的辐射复合。实验观察到激子和trion的光致发光（PL）谱线变宽（~1 nm），相应的寿命增加（~10 ps）。通过蚀刻掉顶层银膜，PL谱线和寿命均恢复到初始值，证实了这些现象源于激子-腔体相互作用。

Abstract: Excitons in transition metal dichalcogenides (TMDs) have extremely short,
picosecond-scale lifetimes which hinders exciton thermalization, limits the
emergence of collective coherence, and reduces exciton transport in
optoelectronic devices. In this work, we explore an all-optical pathway to
extend exciton lifetimes by placing MoSe$_2$ in a deep-subwavelength
Fabry-Perot silver cavity. The cavity structure is designed to suppress
radiative recombination from in-plane optical dipoles, such as bright excitons
and trions. We observe a consistent decrease in photoluminescence (PL)
linewidths of excitons and trions (~1 nm), along with a corresponding lifetime
increase (~10 ps). We confirm the experimental observations arise purely from
exciton-cavity interactions-etching back the top silver layer returns the PL
linewidth and lifetimes return to their original values. Our study offers a
pathway to engineer excited state lifetimes in 2D materials which can be
utilized for studies of optically dark excitons and have potential applications
for novel optoelectronic devices.

</details>


### [249] [Multipole order in two-dimensional altermagnets](https://arxiv.org/abs/2507.18020)
*Tenta Tani,Ulrich Zülicke*

Main category: cond-mat.mes-hall

TL;DR: 二维反磁性材料中的磁偶极子序，重点关注通用最小三点模型和代表单层FeSe的四点模型。研究了它们的低能有效哈密顿量和磁偶极子指标。通用模型显示出非零磁八极序，而FeSe模型则显示出磁十六极序，这与亚晶格同旋自由度相互作用有关。二维反磁性材料的分类和理解超越了体相描述。


<details>
  <summary>Details</summary>
Motivation: 理论研究二维（2D）反磁性材料中的磁偶极子序。

Method: 通过构建低能有效哈密顿量并计算其各自的价数指标来表征潜在的磁序，研究了两个代表性模型：通用的最小三点模型和代表单层FeSe的四点模型。

Result: 通用的最小模型表现出预期的非零磁八极序，而单层FeSe模型中的磁八极序则全局消失，取而代之的是磁十六极序。

Conclusion: 二维反磁性材料的分类和全面理解超越了体相描述，本研究揭示了与亚晶格同旋自由度相互作用而出现的带结构中的反磁性分裂。

Abstract: We theoretically investigate the magnetic-multipole orders in two-dimensional
(2D) altermagnets, focusing on two representative models: a generic minimal
three-site model, and a four-site model representative of monolayer FeSe. We
construct low-energy effective Hamiltonians for both systems and calculate
their respective multipole indicators to characterize the underlying magnetic
order. Our analysis reveals an intriguing contrast between the two systems. We
find that the generic minimal model exhibits the expected non-zero
magnetic-octupole order. In the monolayer-FeSe model, however, the
magnetic-octupole order vanishes globally, and a magnetic-hexadecapole order is
present instead. The emergence of altermagnetic splitting in the band structure
then arises via the interplay with a sublattice-isospin degree of freedom. Our
work demonstrates how the classification and comprehensive understanding of 2D
altermagnetic materials transcends bulk descriptions.

</details>


### [250] [Topological Layer-Spin Filter in Screw Dislocation](https://arxiv.org/abs/2507.18089)
*Jiaojiao Zhou,Hong Hu,Jiangying Yu,Lin Xu,Shu-guang Cheng,Hua Jiang*

Main category: cond-mat.mes-hall

TL;DR: 该研究利用螺旋位错实现了三维材料中电子自旋和层自由度的同时操控，并发现了层-自旋滤波效应，同时证明了该效应在不同类型的无序下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 将量子自旋霍尔效应的双层维度拓展到三维，并通过螺旋位错实现对层自由度的控制，同时操控电子自旋和层自由度。

Method: 通过数值模拟研究包含螺旋位错的多层凯恩-梅勒模型的电子输运性质。

Result: 发现耗散的量子自旋霍尔边缘态不仅在结构外边界传播，而且沿着螺旋位错传播，起到层-自旋滤波器的作用；自旋向上和自旋向下的载流子分别流向不同的汲取层；载流子流入特定汲取层的自旋由输入源层决定；传输系数和自旋极化对安德森无序具有鲁棒性；磁性无序会导致自旋翻转和背散射，抑制传输系数但保持自旋极化基本不变；研究了包含两个螺旋位错器件中的层分辨和自旋分辨的输运性质。

Conclusion: 该研究揭示了包含螺旋位错的多层凯恩-梅勒模型具有同时操控电子自旋和层自由度的潜力，并提出了一种新的调制电子传输的方法。

Abstract: While the quantum spin Hall effect leverages two-dimensional topological
states to manipulate spin without dissipation, layertonics extends this
paradigm to three dimension by enabling control over the layer degree of
freedom. Topological materials incorporating screw dislocations exhibit the
capability for simultaneous manipulation of both electronic spin and layer
degrees of freedom. In this work, the electronic transport properties of a
multilayer Kane-Mele model with screw dislocations is studied theoretically.
Numerical simulations of a screw dislocation reveal that dissipationless
quantum spin Hall edge states propagate not only at the outer boundaries of the
structure but also along the screw dislocation itself, working as layer-spin
filter. In detail, 1) the spin-up and spin-down carriers starting from the same
source layer flow to different drain layers along the topological channels,
respectively. 2) The spin of carriers flowing into a given drain layer is
determined by the input source layer. Moreover, we found that the transmission
coefficient and spin polarization remain robust against Anderson disorder.
Under magnetic disorder, spin flip and backscattering occur, suppressing the
transmission coefficient while maintaining nearly unchanged spin polarization.
Finally, the layer- and spin-resolved transport properties in a device with two
screw dislocations are investigated as well. We have developed an innovative
methodology to modulate electron transport with simultaneous layer and spin
resolution.

</details>


### [251] [Dislocation-Driven Nucleation Type Switching Across Repeated Ultrafast Magnetostructural Phase Transition](https://arxiv.org/abs/2507.18364)
*Jan Hajduček,Antoine Andrieux,Jon Ander Arregi,Martin Tichý,Paolo Cattaneo,Beatrice Ferrari,Fabrizio Carbone,Vojtěch Uhlíř,Thomas LaGrange*

Main category: cond-mat.mes-hall

TL;DR: 研究通过透射电子显微镜发现，激光辐照会改变FeRh薄膜的磁相变方式，并与材料中的位错网络相互作用，影响磁畴的形成。


<details>
  <summary>Details</summary>
Motivation: 为了理解磁性材料在超快时间尺度下的磁序演化，以及探索微观结构与动态形核之间的关联，填补了该领域实验证据的空白。

Method: 利用高空间和时间分辨率的原位透射电子显微镜，观察了FeRh薄膜在重复激光脉冲作用下的磁性相变过程，特别是形核机制和微观结构的变化。

Result: 研究发现，累积激光辐照会显著改变FeRh薄膜的磁性相变形核路径，从均匀形核转变为非均匀形核，导致相变温度降低20 K，并出现亚微米磁涡旋作为优先形核结构。这些磁涡旋被位错网络钉扎，而位错网络在重复的激光脉冲作用下会形成和重排。

Conclusion: 该研究通过透射电子显微镜揭示了磁畴演化与材料微观结构之间的联系，发现累积激光辐照会改变FeRh薄膜的磁性相变过程，从均匀形核转变为非均匀形核，并导致磁性涡旋的出现，这些涡旋被位错网络钉扎，从而对超快电子显微镜实验和缺陷介导的相变提供了新的认识。

Abstract: Controlling magnetic order on ultrafast timescales, driven by spintronic and
recording applications, is one of the main directions of current research in
magnetism. Despite major advances in understanding the temporal evolution of
magnetic order upon its emergence or quenching, experimental demonstration of
the local link between microstructure and dynamic nucleation is missing. Here,
taking advantage of the high structural and magnetic resolution of in situ
transmission electron microscopy, we observe that cumulative laser irradiation
significantly alters the nucleation pathway of the first-order
antiferromagnetic to ferromagnetic phase transition of FeRh thin films, causing
the transition to switch from homogeneous to heterogeneous nucleation. This
leads to a decrease of 20 K in transition temperature and the emergence of
sub-micron magnetic vortices as preferential nucleation motifs. These vortices
are pinned in the film by underlying dislocation networks. We observe that the
dislocation networks are formed and rearranged upon repeated crossing of the
phase transition using femtosecond and picosecond laser pulses. Our results
establish a direct link between defect formation, nucleation energetics, and
the microscopic morphology of the nucleated ferromagnetic phase, with broad
implications for ultrafast stroboscopic experiments and defect-mediated phase
transitions in functional materials.

</details>


### [252] [Quasicrystalline Altermagnetism](https://arxiv.org/abs/2507.18408)
*Rui Chen,Bin Zhou,Dong-Hui Xu*

Main category: cond-mat.mes-hall

TL;DR: Quasicrystals can host exotic altermagnetic orders (g-wave and i-wave) due to their unique symmetries, with predicted experimental signatures in spectral functions and spin conductance.


<details>
  <summary>Details</summary>
Motivation: The paper aims to explore the possibility of altermagnetic orders in quasicrystals, which possess unique rotational symmetries not found in periodic crystals.

Method: The research utilizes symmetry analysis and self-consistent mean-field theory to predict and characterize altermagnetic phases.

Result: Stable g-wave and i-wave altermagnetism are predicted in octagonal and dodecagonal quasicrystals, respectively. These phases exhibit unique anisotropic spin-splittings and nodal structures in their spectral functions and spin conductance, serving as experimental fingerprints.

Conclusion: The study establishes quasicrystals as a versatile platform for realizing unconventional altermagnetic orders, extending beyond the limitations of crystallographic symmetry.

Abstract: Altermagnets are a recently discovered class of magnetic materials that
combine a collinear, zero-magnetization spin structure, characteristic of
antiferromagnets, with spin-split electronic bands, a hallmark of ferromagnets.
This unique behavior arises from the breaking of combined time-reversal and
spatial symmetries (such as inversion or lattice translation), which are
preserved in conventional antiferromagnets. To date, research has focused on
altermagnetic phases in periodic crystals, where the order is linked to
specific crystallographic rotation symmetries. In this work, we demonstrate
that quasicrystals, which possess rotational symmetries forbidden in periodic
lattices, can host exotic altermagnetic orders. Using symmetry analysis and
self-consistent mean-field theory, we predict stable $g$-wave and $i$-wave
altermagnetism in octagonal and dodecagonal quasicrystals, respectively. These
novel phases are characterized by global $C_8T$ and $C_{12}T$ symmetries and
manifest as unique anisotropic spin-splittings in their spectral functions and
spin conductance, featuring characteristic eight- and twelve-fold nodal
structures that serve as unambiguous experimental fingerprints. Our findings
establish quasicrystals as a versatile platform for realizing unconventional
altermagnetic orders beyond the constraints of crystallographic symmetry.

</details>


### [253] [Local Hall Conductivity in Disordered Topological Insulators](https://arxiv.org/abs/2507.18441)
*Zachariah Addison,Nandini Trivedi*

Main category: cond-mat.mes-hall

TL;DR: 论文研究了缺乏平移对称性的系统的局域霍尔电导，发现无序和区域分割会影响切恩绝缘体和拓扑无序绝缘体的存在空间。


<details>
  <summary>Details</summary>
Motivation: 预期研究结果将促进下一代局域扫描和局域阻抗谱实验，以视化无序拓扑绝缘体本体周围的霍尔电流。

Method: 推导了缺乏平移对称性的系统的局域霍尔电导表达式，并利用其研究了磁绝缘体中霍尔信号围绕无序区域的局域涨落。

Result: 发现非磁性势能无序的引入会扩大切恩绝缘状态的参数空间。此外，通过将单个无序区域分割成多个具有相同总无序量的较小区域，可以增强拓扑无序绝缘体存在的相空间。

Conclusion: 研究结果表明，非磁性势能无序的引入会扩大绝缘体状态的参数空间，并且将单个无序区域分割成多个较小的区域可以增强拓扑无序绝缘体的存在空间。

Abstract: We derive the expression for the local Hall conductivity for systems that
lack translation symmetry and use it to study the local fluctuations of the
Hall signal around disordered patches in magnetic insulators. We find that the
regime in parameter space over which the system is a Chern insulating state
increases upon inclusion of non-magnetic potential disorder. In addition, the
phase space over which the topological Anderson insulator exists can be
enhanced by breaking up a single disordered patch into multiple smaller patches
with the same total amount of disorder. We expect our results will motivate the
next generation of local scanning and local impedance spectroscopy experiments
to visualize Hall currents around patches in the bulk of a disordered
topological insulator.

</details>


### [254] [Symmetry driven spin anisotropic magnetotransport in quantum spin Hall insulator WTe2 1T](https://arxiv.org/abs/2507.18543)
*Shrushti Tapar,Bent Weber,Saroj P Dash,3 Shantanu Mukherjee,Bhaskaran Muralidharan*

Main category: cond-mat.mes-hall

TL;DR: 单层1T WTe2的磁输运分析表明，非同构对称性保护边缘态自旋简并，为自旋电子器件提供了新的方向。


<details>
  <summary>Details</summary>
Motivation: 突出非同构对称性在控制边缘态自旋行为中的作用，并探索1T WTe2在自旋电子器件中的应用潜力。

Method: 通过比较沿晶体y和x方向边缘的纳米带中的电子传输，对单层1T WTe2进行全面的磁输运分析，并进行能量分辨的电流密度和角度传输分析。

Result: y边缘纳米带在能量和动量空间中表现出显著的边缘态能带分裂，以及电导率的强角度依赖性；x边缘纳米带在磁场下几乎没有自旋分裂，这归因于非同构对称性保护了沿Gamma-X方向的简并状态。

Conclusion: 该研究提供了基于输运-光谱的非同构对称性保护的自旋简并的直接证据，并强调了1T WTe2在利用对称性保护和方向选择性输运通道的自旋电子器件方面的潜力。

Abstract: We present a comprehensive magnetotransport analysis of monolayer 1T WTe2,
highlighting the role of nonsymmorphic symmetries in governing edge-state spin
behavior. By comparing the electronic transmission in nanoribbons with edges
along the crystallographic y and x directions, our analysis reveals a
pronounced anisotropy in the magnetic field response. The y-edge ribbon
exhibits significant spin splitting of edge-state bands in both energy and
momentum space, along with a strong angular dependence of the conductance. The
observed magnetotransport response indicates a spin quantization axis that
aligns with the out-of-plane spin quantization axis reported in previous
experimental studies. In contrast, the x edge ribbon shows negligible spin
splitting under magnetic fields, which is attributed to nonsymmorphic
symmetries such as glide mirror and screw rotation, that protects degeneracies
along the Gamma X direction, even when time-reversal symmetry is broken. The
energy-resolved current density and angular transmission analyses confirm that
this anisotropy originates from edge states, while bulk states remain largely
insensitive to the field orientation. Our results establish direct
transport-spectroscopy based evidence of nonsymmorphic-symmetry-protected spin
degeneracy in the 1T WTe2, and underscores its promise for spintronic devices
that leverage symmetry-protected and directionally selective transport
channels.

</details>


### [255] [Ultrafast coherent magnon spin currents in antiferromagnets](https://arxiv.org/abs/2507.18563)
*Torstein Hegstad,Johan H. Mentink*

Main category: cond-mat.mes-hall

TL;DR: Antiferromagnets can generate ultrafast spin currents using magnon pairs, controlled by light polarization, and even create circular currents.


<details>
  <summary>Details</summary>
Motivation: The primary motivation is to address the challenge of generating coherent magnon spin currents with high frequencies and short wavelengths in ultrafast spintronics and magnonics, specifically by exploring the potential of counter-propagating magnon pairs in antiferromagnets.

Method: The paper proposes exciting counter-propagating magnon pairs, particularly those at the edge of the Brillouin zone in antiferromagnets, and utilizing a coherent superposition of multiple magnon-pair modes to generate net spin currents.

Result: The research shows that coherent superposition of magnon-pair modes can produce net spin currents in parity-time symmetric antiferromagnets, excited by linearly polarized light. The direction of these currents is steerable by light polarization, and orthogonal currents can be superposed to generate circular spin currents.

Conclusion: The study demonstrates that a coherent superposition of multiple magnon-pair modes in parity-time symmetric antiferromagnets can generate net spin currents, which can be controlled by light polarization and further manipulated to create circular spin currents.

Abstract: Generating coherent magnon spin currents with the highest frequencies and
shortest wavelengths is a key challenge in ultrafast spintronics and magnonics.
A promising route is to excite counter-propagating magnon pairs. In
antiferromagnets, such pairs can be accessed in the ultrafast regime, where
coherent dynamics are dominated by magnons at the edge of the Brillouin zone.
However, it has seemed impossible to generate a net spin current from coherent
magnon pairs. Here we show that a coherent superposition of multiple
magnon-pair modes can produce such a current in parity-time symmetric
antiferromagnets. The ultrafast coherent spin currents are excited with
linearly polarized light, with the light polarization steering the current
direction. Finally, by superposing two orthogonal spin currents, circular spin
currents can be generated, which have not been discussed for steady-state
currents.

</details>


### [256] [Superconductivity from dual-surface carriers in rhombohedral graphene](https://arxiv.org/abs/2507.18598)
*Manish Kumar,Derek Waleffe,Anna Okounkova,Raveel Tejani,Vo Tien Phong,Kenji Watanabe,Takashi Taniguchi,Cyprian Lewandowski,Joshua Folk,Matthew Yankowitz*

Main category: cond-mat.mes-hall

TL;DR: 在菱面体石墨烯中发现了新的超导机制，并观测到了量子化的反常霍尔效应。


<details>
  <summary>Details</summary>
Motivation: 探索了菱面体石墨烯中存在的异常低能电子波函数及其对对称性破缺相的影响，并在此基础上发现了超导现象。

Method: 本研究通过实验观测了菱面体石墨烯的超导电性，并分析了其在不同层数和外加电场下的电学性质。

Result: 在八层石墨烯中，超导现象出现在每个符号的外加电位移场（D）下五个不同的能带中；在七层石墨烯-六方氮化硼（hBN）叠层样品中，超导现象来源于一个尖锐的电阻特征，并在此特征中出现了两个能带；此外，在高D下，该电阻特征还会在接近每莫尔单位晶胞一个电子的掺杂附近诱导出h/e²量子化的反常霍尔效应。

Conclusion: 研究发现了多层石墨烯中一种新颖的超导机制，并为实现与邻近拓扑态的耦合提供了机会。

Abstract: Intrinsic rhombohedral graphene hosts an unusual low-energy electronic
wavefunction, predominantly localized at its outer crystal faces with
negligible presence in the bulk. Increasing the number of graphene layers
amplifies the density of states near charge neutrality, greatly enhancing the
susceptibility to symmetry-breaking phases. Here, we report superconductivity
in rhombohedral graphene arising from an unusual charge-delocalized
semimetallic normal state, characterized by coexisting valence- and
conduction-band Fermi pockets split to opposite crystal surfaces. In octalayer
graphene, the superconductivity appears in five apparently distinct pockets for
each sign of an external electric displacement field ($D$). In a moir\'e
superlattice sample where heptalayer graphene is aligned on one side to
hexagonal boron nitride, two pockets of superconductivity emerge from a single
sharp resistive feature. At higher $D$ the same resistive feature additionally
induces an $h/e^{2}$-quantized anomalous Hall state at dopings near one
electron per moir\'e unit cell. Our findings reveal a novel superconducting
regime in multilayer graphene and create opportunities for coupling to nearby
topological states.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [257] [Mapping Technological Futures: Anticipatory Discourse Through Text Mining](https://arxiv.org/abs/2504.02853)
*Maciej Skorski,Alina Landowska,Krzysztof Rajda*

Main category: cs.SI

TL;DR: 本研究分析了150万条来自KOL在X平台的帖子，发现KOL通过塑造对人工智能等技术的乐观预期来影响公众认知，尽管“气候变化”和“战争”等话题会引起焦虑，但总体上希望情绪占主导。


<details>
  <summary>Details</summary>
Motivation: 鉴于人工智能等新兴技术的波动性和不可预测性所带来的显著不确定性，本研究旨在深入探究技术未来相关的预期性论述，特别关注关键意见领袖（KOL）在社交媒体平台上的讨论。

Method: 本研究采用先进的文本挖掘技术，包括BERTopic模型、情感、情绪和态度分析，对来自400位关键意见领袖（KOL）在X平台（2021年至2023年）发布的150万条帖子进行了分析，以识别和理解围绕技术未来的预期性论述。

Result: 研究识别了100个反映预期技术驱动未来的不同话题。结果显示，KOL在构建“当前未来”（例如，对人工智能和物联网的乐观愿景）和影响“未来现在”（例如，这些预测如何塑造当前的社会和地缘政治辩论）方面发挥着双重作用。积极情绪（如希望）普遍存在，并且超过了焦虑情绪，尤其是在“机器学习、数据科学和深度学习”等话题中。相比之下，“气候变化”和“战争、乌克兰和特朗普”等话题则引发了更多的焦虑情绪。

Conclusion: 本研究揭示了关键意见领袖（KOL）在塑造围绕新兴技术的社会叙事中的关键作用，他们通过连接想象的未来和现实，影响着公众对技术（如人工智能和物联网）的认知和讨论方向，尤其是在不确定时期。

Abstract: The volatility and unpredictability of emerging technologies, such as
artificial intelligence (AI), generate significant uncertainty, which is widely
discussed on social media. This study examines anticipatory discourse
surrounding technological futures by analysing 1.5 million posts from 400 key
opinion leaders (KOLs) published on the X platform (from 2021 to 2023). Using
advanced text mining techniques, including BERTopic modelling, sentiment,
emotion, and attitude analyses, the research identifies 100 distinct topics
reflecting anticipated tech-driven futures. Our findings emphasize the dual
role of KOLs in framing \textit{present futures} -- optimistic visions of
transformative technologies like AI and IoT -- and influencing \textit{future
presents}, where these projections shape contemporary societal and geopolitical
debates. Positive emotions such as Hope dominate, outweighing Anxiety,
particularly in topics like ``Machine Learning, Data Science, and Deep
Learning,'' while discussions around ``Climate Change'' and ``War, Ukraine, and
Trump People'' elicit \textit{Anxiety}. By framing technologies as solutions to
societal challenges, KOLs act as mediators of societal narratives, bridging
imagined futures and current realities. These insights underscore their pivotal
role in directing public attention with emerging technologies during periods of
heightened uncertainty, advancing our understanding of anticipatory discourse
in technology-mediated contexts.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [258] [Sb2S3 and GaAs Absorber Layer-based Quantum Dot Solar Cells with Cadmium Telluride-based HTL: A Comparative Study](https://arxiv.org/abs/2507.17877)
*Sayak Banerjee,Anupam Chetia,Satyajit Sahu*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Quantum dot solar cells (QDSC) are widely acknowledged to be one of the best
solar energy harvesting devices in the present world. Absorber layer is a core
component of a QDSC with a strong influence on its operational efficiency.
Hence, we choose to undertake a comparative study of two QDSC having different
QD absorber layers: Sb2S3 and GaAs with the motive to identify the better
absorber layer material. The numerical analysis has been carried out using
SCAPS-1D (Solar Cell Capacitance Simulator-1D). The structure of the QDSCs
under study are: FTO/TiO2/CdS/Sb2S3/CuI/C and FTO/TiO2/CdS/GaAs/CuI/C. Critical
parameters, including temperature, back contact work function, series and shunt
resistances, were meticulously adjusted in the simulations, demonstrating that
the maximum efficiency attained by Sb2S3 and GaAs absorber layer based QDSC is
15.94% and 26.95% respectively indicating GaAs-QD to be a better absorber layer
material for a QDSC.

</details>


### [259] [Ultra-clean interface between high k dielectric and 2D MoS2](https://arxiv.org/abs/2507.18010)
*Han Yan,Yan Wang,Yang Li,Dibya Phuyal,Lixin Liu,Hailing Guo,Yuzheng Guo,Tien-Lin Lee,Min Hyuk Kim,Hu Young Jeong,Manish Chhowalla*

Main category: cond-mat.mtrl-sci

TL;DR: 氧化锆（ZrO2）是用于二维TMDs电子器件的有前途的介电材料，可形成清洁的界面并提高器件性能。


<details>
  <summary>Details</summary>
Motivation: 传统的氧化物介电层（如SiO2、Al2O3、HfO2）在与二维TMDs集成时会引起掺杂和引入缺陷态，影响器件性能和稳定性。因此，需要开发一种能够与TMDs形成清洁界面的新型介电材料。

Method: 采用软X射线光电子能谱、硬X射线光电子能谱和密度泛函理论研究了ZrO2与MoS2的界面相互作用。制备了基于ZrO2的场效应晶体管（FET），并对其性能进行了表征，包括阈值电压、亚阈值摆幅和导通电流。

Result: ZrO2与单层MoS2形成了超净界面，没有观察到明显的掺杂效应。基于ZrO2的器件表现出稳定的阈值电压（0.36±0.3 V），优异的亚阈值摆幅（75 mV/decade），以及超过400微安的高导通电流。此外，还展示了基于ZrO2的p型WSe2 FETs，其导通电流大于200微安/微米。ZrO2/MoS2界面无缺陷，实现了0.86 nm等效氧化层厚度和80 mV/decade亚阈值摆幅的顶栅FETs，并且可以通过栅极金属功函数工程有效调控阈值电压。

Conclusion: 氧化锆（ZrO2）作为一种与半导体工艺兼容的高介电常数电介质，能够与单层二硫化钼（MoS2）形成超净界面，并且不会显着掺杂MoS2。基于ZrO2的器件表现出稳定的阈值电压、低亚阈值摆幅和高导通电流，证明了ZrO2在可扩展的二维TMD电子学器件中的应用潜力。

Abstract: Atomically thin transition metal dichalcogenides (TMDs) are promising
candidates for next-generation transistor channels due to their superior
scaling properties. However, the integration of ultra-thin gate dielectrics
remains a challenge, as conventional oxides such as SiO2, Al2O3, and HfO2 tend
to unintentionally dope 2D TMDs and introduce interfacial defect states,
leading to undesirable field-effect transistor (FET) performance and unstable
threshold voltages. Here, we demonstrate that zirconium oxide (ZrO2), a high-k
dielectric compatible with semiconductor processing, forms an ultra-clean
interface with monolayer MoS2. Using soft and hard X-ray photoelectron
spectroscopy and density functional theory, we find that ZrO2 does not
measurably interact with MoS2, in contrast to significant doping observed for
SiO2 and HfO2 substrates. As a result, back-gated monolayer MoS2 FETs
fabricated with ZrO2 dielectrics exhibit stable and positive threshold voltages
(0.36 plus/minus 0.3 V), low subthreshold swing (75 mV per decade), and high ON
currents exceeding 400 microamperes. We further demonstrate p-type WSe2 FETs
with ON currents greater than 200 microamperes per micrometer by suppressing
electron doping with ZrO2 dielectrics. Atomic-resolution imaging confirms a
defect-free ZrO2/MoS2 interface, which enables top-gate FETs with an equivalent
oxide thickness of 0.86 nanometers and subthreshold swing of 80 mV per decade.
Moreover, the ultraclean ZrO2/MoS2 interface allows for effective threshold
voltage modulation in top-gate FETs via gate metal work function engineering.
These findings establish ZrO2 as a highly promising, industry-compatible high-k
dielectric for scalable 2D TMD-based electronics.

</details>


### [260] [Analysis of Fe and Co binary catalysts in chemical vapor deposition growth of single-walled carbon nanotubes](https://arxiv.org/abs/2507.17891)
*Qingmei Hu,Ya Feng,Wanyu Dai,Daisuke Asa,Daniel Hedman,Aina Fito Parera,Yixi Yao,Yongjia Zheng,Kaoru Hisama,Gunjan Auti,Hirofumi Daiguji,Christophe Bichara,Shohei Chiashi,Yan Li,Wim Wenseleers,Dmitry Levshov,Sofie Cambre,Keigo Otsuka,Rong Xiang,Shigeo Maruyama*

Main category: cond-mat.mtrl-sci

TL;DR: 本文研究了Fe-Co比例和CVD条件对单壁碳纳米管生长的影响。发现Fe$_{0.75}$Co$_{0.25}$在850°C时效果最佳，而Fe$_{0}$Co$_{1}$在600°C时活性更高。高产量的关键在于尺寸均匀且表面富钴的Fe-Co催化剂颗粒。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解Fe-Co比例和CVD生长参数对SWCNTs生长影响，本文旨在阐明Fe和Co原子在SWCNTs生长中的不同作用。

Method: 通过改变Fe-Co的比例和CVD生长条件，系统地研究了Fe-Co比例对SWCNTs生长的影响。利用透射电子显微镜（TEM）和能量色散X射线光谱（EDS）分析了催化剂的形貌和组成。通过分子动力学（MD）模拟研究了Fe$_x$Co$_{1-x}$簇的结构和熔化行为。

Result: Fe$_{0.75}$Co$_{0.25}$在850°C时是高效的二元催化剂，催化剂簇直径为2.5-6 nm，SWCNTs直径为0.9-1.1 nm。Fe$_{0}$Co$_{1}$在600°C时催化活性更高，催化剂簇直径为1.5-5 nm，SWCNTs直径为0.6-0.9 nm。高产量的SWCNTs与尺寸均匀且表面富含钴的Fe-Co催化剂颗粒有关。

Conclusion: Fe$_{0.75}$Co$_{0.25}$催化剂在850°C时生长单壁碳纳米管（SWCNTs）效果最佳，形成2.5-6 nm的催化剂簇，生长出的SWCNTs直径为0.9-1.1 nm。Fe$_{0}$Co$_{1}$在600°C时催化活性更高，形成1.5-5 nm的催化剂簇，生长出的SWCNTs直径为0.6-0.9 nm。高产量的SWCNTs与尺寸均匀且表面富含钴的Fe-Co催化剂颗粒有关，钴的表面富集提高了碳溶解度。分子动力学模拟结果也支持这些发现，表明Fe$_x$Co$_{1-x}$簇的结构和熔化行为取决于其尺寸和组成。

Abstract: Metal catalysts play a pivotal role in the growth of single-walled carbon
nanotubes (SWCNTs), with binary metallic catalysts emerging as an efficient
SWCNT synthesis strategy. Among these, iron (Fe), cobalt (Co), and their alloys
are particularly effective. However, prior studies have predominantly employed
Fe--Co alloy catalysts with fixed atomic ratios as well as unchanged chemical
vapor deposition (CVD) conditions, leaving the influence of variable Fe--Co
compositions and CVD growth parameters on SWCNT synthesis poorly understood.
This study focuses on the role of Fe--Co catalyst ratios, with the aim of
elucidating the distinct contributions of Fe and Co atoms in the growth of
SWCNTs. By systematically exploring a wide range of Fe--Co ratios and growth
conditions, we identified Fe$_{0.75}$Co$_{0.25}$ as a highly efficient binary
catalyst at 850~$^\circ$C, primarily forming catalyst clusters with diameters
of 2.5--6~nm and yielding SWCNTs with diameters ranging from 0.9--1.1~nm. On
the other hand, Fe$_{0}$Co$_{1}$ exhibited higher catalytic activity at
600~$^\circ$C, generating smaller catalyst clusters of 1.5--5~nm and producing
SWCNTs with reduced diameters of about 0.6--0.9~nm. Transmission electron
microscope (TEM) and energy dispersive X-ray spectroscopy (EDS) analyses reveal
that high SWCNT yields correlate with the formation of uniformly sized Fe--Co
catalyst particles with surface-segregated Co that optimizes carbon solubility.
Molecular dynamics (MD) simulations further corroborate these findings,
demonstrating that the structure and melting behavior of Fe$_x$Co$_{1-x}$
clusters depend on cluster size and composition.

</details>


### [261] [Computation and Sensitivity Analysis of the Deformation-Gradient Tensor Reconstruction in Dark-Field X-ray Microscopy](https://arxiv.org/abs/2507.17929)
*Brinthan Kanesalingam,Darshan Chalise,Carsten Detlefs,Leora Dresselhaus-Marais*

Main category: cond-mat.mtrl-sci

TL;DR: 本文为暗场X射线显微镜（DFXM）开发了一个逆向建模框架，以明确关联其角移与应变和晶格旋转张量。通过使用倾斜衍射几何，可以重建完整的形变梯度张量F(g)。该框架还包括计算工具和敏感性分析，以提高DFXM实验的解释和设计能力。


<details>
  <summary>Details</summary>
Motivation: DFXM技术能够对体材料进行纳米尺度的成像，并具有近几百微米的视场，但缺乏明确关联其角移与应变和晶格旋转张量的逆向建模框架，这限制了其在材料科学中的应用。

Method: 提出了倾斜衍射几何，并开发了相应的计算框架，用于前向计算角移和反向重建形变梯度张量F(g)。还建立了敏感性分析方法，将DFXM的特定角度与应变或旋转张量的分量联系起来，并计算重建每个分量的误差。

Result: 成功开发了DFXM的逆向建模形式主义和计算框架，能够重建形变梯度张量F(g)，并进行了敏感性分析，将DFXM角度与应变/旋转张量分量联系起来，并量化了重建误差。这有助于解释和设计DFXM实验。

Conclusion: 开发了一个逆向建模框架，用于将DFXM中的角移与应变和晶格旋转张量明确关联起来，并展示了使用倾斜衍射几何重建完整的形变梯度张量F(g)的可能性。该框架还包括计算框架，用于前向计算预期的角移，并从DFXM实验中为单个像素重建平均F(g)。

Abstract: Spatially resolved strain measurements are crucial to understanding the
properties of engineering materials. Although strain measurements utilizing
techniques such as transmission electron microscopy and electron backscatter
diffraction offer high spatial resolution, they are limited to surface or thin
samples. X-ray diffraction methods, including Bragg Coherent Diffraction
Imaging and X-ray topography, enable strain measurements deep inside bulk
materials but face challenges in simultaneously achieving both high spatial
resolution and large field-of-view. Dark-field X-ray Microscopy (DFXM) offers a
promising solution with its ability to image bulk crystals at the nanoscale
while offering a field-of-view approaching a few hundred $\mu$m. However, an
inverse modeling framework to explicitly relate the angular shifts in DFXM to
the strain and lattice rotation tensors is lacking. In this paper, we develop
such an inverse modeling formalism. Using the oblique diffraction geometry,
enabling access to noncoplanar symmetry-equivalent reflections, we demonstrate
that the reconstruction of the full deformation gradient tensor
($\mathbf{F^{(g)}}$) is possible. We also develop the computational framework
to both forward calculate the anticipated angular shifts and reconstruct the
average $\mathbf{F^{(g)}}$ for an individual pixel from DFXM experiments.
Finally, utilizing the established formalism and computational framework, we
present methods for sensitivity analysis to relate individual components of the
rotation or strain tensor to specific angles of DFXM. The developed sensitivity
analysis also enables explicit computation of the errors associated with the
reconstruction of each component. The formalism, the computational framework,
and the sensitivity analysis established in this paper should assist both the
interpretation of past DFXM experiments and the design of future DFXM
experiments.

</details>


### [262] [Nucleation of magnetic textures in stripe domain bifurcations for reconfigurable domain wall racetracks](https://arxiv.org/abs/2507.18356)
*V. V. Fernández,S. Ferrer,A. Hierro-Rodríguez,M. Vélez*

Main category: cond-mat.mtrl-sci

TL;DR: 赛道内存中的磁性势可以提高器件的通用性。NdCo5/Py赛道中的微磁模拟显示，磁拓扑电荷交换控制着涡旋/反涡旋对的形成，这对于引导传播至关重要。


<details>
  <summary>Details</summary>
Motivation: 为了增强最终器件的通用性，在赛道内存范例中利用磁性势而不是几何势，并添加了磁性可重构能力。

Method: 使用基于磁性势的赛道内存范例，并通过微磁模拟研究了NdCo5/Py可重构赛道中的磁化反转过程。

Result: 研究了用于信息载体的纹理拓扑，以及控制涡旋、反涡旋、Bloch线和Bloch点的成核的磁性涡度线。

Conclusion: 磁拓扑电荷交换可以控制涡旋/反涡旋对的形成，这对于通过条纹模式进行引导传播至关重要。

Abstract: Within the racetrack memory paradigm, systems exploiting magnetic guiding
potentials instead of geometrical ones, allow for enhancing the versatility of
the final devices adding magnetic reconfigurable capabilities. Hard/soft
magnetic multilayers with stripe domain configurations fulfill these
requirements. In these systems, the topology of the generated textures that
would act as information carriers, is strongly conditioned by the stripe
lattice configuration. Micromagnetic simulations have been used to study the
magnetization reversal process in NdCo$_5$/Py reconfigurable racetracks. By
using skyrmionic charges and magnetic vorticity lines, the topological
transformations controlling the nucleation of vortices, antivortices, Bloch
lines and Bloch points has been analyzed. It has been shown that magnetic
topological charge exchanges between textures rule the formation of
vortex/antivortex pairs with opposite polarities, key for the guided
propagation through the stripe pattern.

</details>


### [263] [Efficient $G_0W_0$ and BSE calculations of heterostructures within an all-electron framework](https://arxiv.org/abs/2507.17960)
*Maximilian Schebek,Ignacio Gonzalez Oliva,Claudia Draxl*

Main category: cond-mat.mtrl-sci

TL;DR: 研究将一种高效计算极化率的方法扩展到 (L)APW 方法，用于 G0W0 和 BSE 计算，以低成本高精度计算二维材料异质结构的光学光谱。


<details>
  <summary>Details</summary>
Motivation: 计算二维材料异质结的光电性质，尤其是使用高精度全电子计算和多体微扰理论时，由于其较大的单位晶胞而面临挑战，计算成本高昂。

Method: 将一种基于加性理论的，用于高效计算非相互作用极化率的方法（此前已针对平面波基组进行开发）扩展至 (线性化) 增强平面波 (L)APW 方法，并为 BSE 计算实现了一个相似的方法。

Result: 实现了 G0W0 和 BSE 计算的低成本高精度光学光谱计算，并通过双层 WSe2 和吡啶@MoS2 的准粒子带结构和光学光谱计算结果与精确参考计算进行了比较，验证了该方法。

Conclusion: 该研究将一种能够高效计算非相互作用极化率的方法扩展到 (线性化) 增强平面波 (L)APW 方法，并实现了在 G0W0 和 BSE 计算中的应用，从而能够低成本地计算高精度的光学光谱。

Abstract: The combination of two-dimensional materials into heterostructures offers new
opportunities for the design of optoelectronic devices with tunable properties.
However, computing electronic and optical properties of such systems using
state-of-the-art methodology is challenging due to their large unit cells. This
is in particular so for highly-precise all-electron calculations within the
framework of many-body perturbation theory, which come with high computational
costs. Here, we extend an approach that allows for the efficient calculation of
the non-interacting polarizability, previously developed for planewave basis
sets, to the (linearized) augmented planewave (L)APW method. This approach is
based on an additive ansatz, which computes and superposes the polarizabilities
of the individual components in their respective unit cells. We implement this
formalism in the $G_0W_0$ module of the exciting code and implement an
analogous approach for BSE calculations. This allows the calculation of
highly-precise optical spectra at low cost. So-obtained results of the
quasi-particle band structure and optical spectra are demonstrated for bilayer
WSe$_2$ and pyridine@MoS$_2$ in comparison with exact reference calculations.

</details>


### [264] [Tuning chiral anomaly signature in a Dirac semimetal via fast-ion implantation](https://arxiv.org/abs/2507.17972)
*Manasi Mandal,Eunbi Rha,Abhijatmedhi Chotrattanapituk,Denisse Córdova Carrizales,Alexander Lygo,Kevin B. Woller,Mouyang Cheng,Ryotaro Okabe,Guomin Zhu,Kiran Mak,Chu-Liang Fu,Chuhang Liu,Lijun Wu,Yimei Zhu,Susanne Stemmer,Mingda Li*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Cd$_3$As$_2$ is a prototypical Dirac semimetal that hosts a chiral anomaly
and thereby functions as a platform to test high-energy physics hypotheses and
to realize energy efficient applications. Here we use a combination of
accelerator-based fast ion implantation and theory-driven planning to enhance
the negative longitudinal magnetoresistance (NLMR)--a signature of a chiral
anomaly--in Nb-doped Cd$_3$As$_2$ thin films. High-energy ion implantation is
commonly used to investigate semiconductors and nuclear materials but is rarely
employed to study quantum materials. We use electrical transport and
transmission electron microscopy to characterize the NLMR and the crystallinity
of Nb-doped Cd$_3$As$_2$ thin films. We find surface-doped Nb-Cd$_3$As$_2$ thin
films display a maximum NLMR around $B = 7$ T and bulk-doped Nb-Cd$_3$As$_2$
thin films display a maximum NLMR over $B = 9$ T--all while maintaining
crystallinity. This is more than a 100% relative enhancement of the maximum
NLMR compared to pristine Cd$_3$As$_2$ thin films ($B = 4$ T). Our work
demonstrates the potential of high-energy ion implantation as a practical route
to realize chiralitronic functionalities in topological semimetals.

</details>


### [265] [Compositional Tuning in NaxAlB14 via Diffusion Control](https://arxiv.org/abs/2507.18008)
*Mihiro Hoshino,Suguru Iwasaki,Shigeto Hirai,Yoshihiko Ihara,Tohru Sugahara,Haruhiko Morito,Masaya Fujioka*

Main category: cond-mat.mtrl-sci

TL;DR: 通过高压扩散控制和退火，实现了NaxAlB14的均匀Na分布，并揭示了Na含量、硼空位对材料电学和光学性质的影响，为设计功能性硼化物材料提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 为了在NaxAlB14中实现均匀的Na分布，并研究其在不同Na浓度下的结构和电子性质，克服了传统固态反应难以获得非化学计量和均匀成分的限制。

Method: 本研究利用高压扩散控制（HPDC）结合退火处理，实现了NaxAlB14中Na的均匀分布。具体而言，通过在高压下增强Na的扩散以促进Na的脱嵌，并控制Na的移除过程，随后进行退火处理，从而获得均匀的Na成分。

Result: 研究发现，随着Na含量的降低，NaxAlB14的电导率增加，光学带隙缩小。NMR测量和DFT计算表明，费米能级处态密度增加，硼空位会在带隙中心附近产生深能级，导致光学带隙减小。

Conclusion: 本研究表明，通过结合高压扩散控制（HPDC）和随后的退火处理，可以实现NaxAlB14中Na的均匀分布，从而为可调谐成分的亚稳态化合物合成提供了一种新方法，并为设计具有可调电子特性的硼化物功能材料奠定了基础。

Abstract: A uniform Na distribution in NaxAlB14 was achieved using high-pressure
diffusion control (HPDC), which promotes Na deintercalation through enhanced
diffusion under high pressure, combined with post-annealing. NaxAlB14 with a
non-stoichiometric Na composition is thermodynamically metastable, and
conventional solid-state reactions with adjusted starting compositions
typically result in the formation of stoichiometric NaAlB14 and side products.
While HPDC alone typically leads to concentration gradients, intentionally
halting the Na removal process before complete extraction, followed by
annealing, enabled a uniform composition across the bulk. This allowed
structural and electronic properties to be examined over a wide range of Na
concentrations. As Na content decreased, electrical conductivity increased, and
the optical band gap narrowed. NMR measurements showed an increase in the
density of states at the Fermi level, consistent with DFT calculations
predicting boron-related in-gap states. Boron vacancies at specific sites were
found to generate deep levels near the band gap center, which can explain
experimentally observed optical gap reduction. These results demonstrate that
diffusion-controlling methods can be effectively applied to synthesize
metastable compounds with tunable compositions in covalent frameworks.
Furthermore, they provide a foundation for designing functional boride-based
materials with adjustable electronic properties by controlling Na extraction
and inducing defect formation.

</details>


### [266] [Defect-Assisted Recombination in Semiconductors and Photovoltaic Device Parameters from First Principles](https://arxiv.org/abs/2507.18011)
*Jiban Kangsabanik,Kristian S. Thygesen*

Main category: cond-mat.mtrl-sci

TL;DR: A new method to calculate defect-assisted SRH recombination rates in semiconductors from first principles is introduced, which accounts for steady state recombination dynamics and transition rates due to radiative and non-radiative multi-phonon emission processes. The method has been used to evaluate the effect of selected defects on photovoltaic device parameters of seven emergent photovoltaic semiconductors, highlighting the limitations of commonly employed approximations.


<details>
  <summary>Details</summary>
Motivation: To evaluate the effect of selected defects on the photovoltaic device parameters of seven emergent photovoltaic semiconductors and to highlight the limitations of commonly employed approximations to the recombination dynamics.

Method: We introduce a method to calculate defect-assisted Shockley-Read-Hall (SRH) recombination rates in imperfect semiconductors from first principles. The method accounts for the steady state recombination dynamics under given non-equilibrium conditions (split quasi Fermi levels), by invoking a full solution to the rate equations describing transitions across the band gap via all possible charge states of the defect. Transition rates due to radiative and non-radiative multi-phonon emission processes are calculated from first principles.

Result: The method is used to evaluate the effect of selected defects on the photovoltaic device parameters of seven emergent photovoltaic semiconductors. These examples clearly highlight the limitations of commonly employed approximations to the recombination dynamics.

Conclusion: The method advances the description and understanding of defect-induced losses in photovoltaics and provides a basis for developing the concept of defect tolerant semiconductors and for discovering high-performance photovoltaic materials computationally.

Abstract: We introduce a method to calculate defect-assisted Shockley-Read-Hall (SRH)
recombination rates in imperfect semiconductors from first principles. The
method accounts for the steady state recombination dynamics under given
non-equilibrium conditions (split quasi Fermi levels), by invoking a full
solution to the rate equations describing transitions across the band gap via
all possible charge states of the defect. Transition rates due to radiative and
non-radiative multi-phonon emission processes are calculated from first
principles. The method is used to evaluate the effect of selected defects on
the photovoltaic device parameters of seven emergent photovoltaic
semiconductors. These examples clearly highlight the limitations of commonly
employed approximations to the recombination dynamics. Our work advances the
description and understanding of defect-induced losses in photovoltaics and
provides a basis for developing the important concept of defect tolerant
semiconductors and to discover high-performance photovoltaic materials
computationally.

</details>


### [267] [Out-of-plane ferroelectricity, magnetoelectric coupling and persistent spin texture in two-dimensional multiferroics](https://arxiv.org/abs/2507.18018)
*Ying Zhou,Cheng-Ao Ji,Shuai Dong,Xuezeng Lu*

Main category: cond-mat.mtrl-sci

TL;DR: 通过外延应变在二维材料中实现面外铁电性，并首次展示了垂直极化、磁电耦合和可切换自旋纹理的集成，为开发下一代自旋电子器件开辟了新途径。


<details>
  <summary>Details</summary>
Motivation: 二维多铁性材料中的面外铁电性在小型化磁电自旋轨道晶体管方面具有巨大潜力，但同时结合鲁棒铁电性和强磁电耦合的体系却极为罕见。

Method: 通过外延应变稳定剥离的二维 Ruddlesden Popper 衍生物中的面外铁电性，并研究了铁电性与磁性的耦合关系。

Result: 外延应变稳定了剥离的二维 Ruddlesden Popper 衍生物中的面外铁电性。混合不Proper铁电的Pc相在切换时转变为纯粹面内极化的P21相，伴随着弱铁磁性的90度旋转。Pc相表现出交替磁性，而P21相显示全布里渊区带分裂，并具有在相边界旋转90度的持久自旋纹理。

Conclusion: 该研究展示了一种通过外延应变稳定剥离的二维 Ruddlesden Popper 衍生物中的面外铁电性的方法，并实现了垂直极化、磁电耦合和可切换自旋纹理的集成，为下一代自旋电子器件提供了关键特性。

Abstract: Two dimensional multiferroics with out of plane ferroelectricity hold
significant promise for miniaturized magnetoelectric spin-orbit transistors,
yet systems combining robust ferroelectricity and strong magnetoelectric
coupling are exceedingly rare. Here, we demonstrate that epitaxial strain
stabilizes out of plane ferroelectricity in exfoliated two dimensional
Ruddlesden Popper derivatives. The hybrid improper ferroelectric Pc phase
transitions to a competing P21 phase with purely in plane polarization upon
switching, accompanied by a 90 degree rotation of weak ferromagnetism.
Crucially, the Pc phase exhibits altermagnetism, while P21 displays full
Brillouin zone band splitting, with persistent spin textures rotating 90 degree
at the phase boundary. This work establishes a pathway to engineer two
dimensional multiferroics that integrate vertical polarization, magnetoelectric
coupling, and switchable spin textures, key features for next generation
spintronic devices.

</details>


### [268] [Nitrogen-vacancy centre formation via local femto-second laser annealing of diamond](https://arxiv.org/abs/2507.18027)
*Davin Yue Ming Peng,Alexander J Healey,Rebecca Griffin,Benjamin Cumming,Hiroshi Abe,Takeshi Ohshima,Alastair Stacey,Brant C Gibson,Brett C Johnson,Philipp Reineck*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Emerging quantum technologies based on the nitrogen-vacancy (NV) centre in
diamond require carefully engineered material with controlled defect density,
optimised NV formation processes, and minimal crystal strain. The choice of NV
generation technique plays a crucial role in determining the quality and
performance of these centres. In this work, we investigate NV centre formation
in nitrogen-doped diamond using femtosecond (fs) laser processing. We
systematically examine the effect of laser pulse energy on NV production and
quality using photoluminescence and optically detected magnetic resonance
measurements. We also probe the role of pre-existing lattice defects formed by
electron irradiation and consider defect evolution over extended dwell times.
Finally, we are able to identify a regime where the main action of the fs-laser
is to diffuse rather than create vacancies. This local annealing capability
expands the toolkit for tailored NV production and presents opportunities for
fine tuning defect populations.

</details>


### [269] [Anomalous magnetoresistance in an antiferromagnetic Kagome semimetal heterostructures](https://arxiv.org/abs/2507.18069)
*Xionghua Liu,Qiyuan Feng,Weibin Cui,Hanjie Guo,Yubin Hou,Xiaomin Zhang,Yongcheng Deng,Dong Zhang,Jing Zhang,Qingyou Lu,Kaiyou Wang*

Main category: cond-mat.mtrl-sci

TL;DR: 通过在FeSn薄膜上添加Pt层，可以控制其自旋纹理，从而影响其电学性质。在薄样品中，观察到了一种特殊的磁阻行为，这与特殊的拓扑自旋纹理有关。


<details>
  <summary>Details</summary>
Motivation: 探索Kagome反铁磁半金属在自旋电子学中的应用潜力，并研究拓扑、自旋和关联之间的量子相互作用。

Method: 通过引入重金属Pt层产生界面Dzyaloshinskii Moriya相互作用，并研究FeSn薄膜厚度变化对霍尔电阻率和磁阻的影响，利用磁力显微镜表征自旋纹理。

Result: FeSn薄膜的自旋纹理随厚度变化而变化，导致霍尔电阻率和磁阻也发生相应变化。在较薄的FeSn-Pt样品中观察到了一种在低磁场下反常的阻尼振荡行为的磁阻。

Conclusion: FeSn薄膜通过引入重金属Pt层产生的界面Dzyaloshinskii-Moriya相互作用，实现了可调控的自旋纹理，为理解Kagome反铁磁体中的新奇现象提供了新视角。

Abstract: Antiferromagnetic Kagome semimetals have attracted tremendous attentions for
their potential application in antiferromagnetic topological spintronics.
Effectively manipulating Kagome antiferromagnetic states could reveal abundant
physical phenomena induced from quantum interactions between topology, spin,
and correlation. Here, we achieved tunable spin textures of FeSn thin films via
introducing interfacial Dzyaloshinskii Moriya interaction from heavy-metal Pt
overlayer. With increasing FeSn thickness, the variable spin textures result in
gradual change in Hall resistivity and magnetoresistance. Importantly, an
unconventional damped oscillatory-like behavior of magnetoresistance at
relatively low magnetic field can be observed in thin FeSn-Pt samples. This
oscillatory like magnetoresistance feature was confirmed to be related to the
special topological spin textures revealed by magnetic force microscopy
measurements. The formation of rich variety of topological spin textures in
association with exotic magneto-transport properties in antiferromagnetic
Kagome FeSn heterostructures offers new perspectives for understanding the
novel emergent phenomena in Kagome antiferromagnets.

</details>


### [270] [Exploring the functional properties of diamond-like quaternary compound Li$_2$ZnGeS$_4$ for potential energy applications: A theoretical approach](https://arxiv.org/abs/2507.18136)
*Celestine Lalengmawia,Michael T. Nunsanga,Saurav Suman,Zosiamliana Renthlei,Lalruat Sanga,Hani Laltlanmawii,Lalhriat Zuala,Shivraj Gurung,Amel Laref,Dibya Prakash Rai*

Main category: cond-mat.mtrl-sci

TL;DR: This paper investigates the properties of Li2ZnGeS4, a wide-bandgap semiconductor, using DFT. The findings suggest its potential for optoelectronics and piezoelectric applications.


<details>
  <summary>Details</summary>
Motivation: The motivation for this work is to explore the potential of the diamond-like quaternary semiconductor Li2ZnGeS4, which is well-synthesized but scarcely explored, for energy production and storage applications, anticipating its usefulness in wide-bandgap semiconductors (WBGSs).

Method: The study employed GGA and mGGA functionals within density functional theory (DFT) to explore the electronic, optical, mechanical, and piezo-electromechanical properties of Li2ZnGeS4. Structural stability was confirmed using Born stability criteria and Molecular-dynamic (MD) simulations.

Result: The study explored the electronic, optical, mechanical, and piezo-electromechanical properties of Li2ZnGeS4, finding its results to be in qualitative agreement with previously reported data. Structural stability was confirmed.

Conclusion: Li2ZnGeS4 is a potential candidate for optoelectronics and piezoelectric applications.

Abstract: It is anticipated that wide-bandgap semiconductors (WBGSs) would be useful
materials for energy production and storage. A well-synthesized, yet, scarcely
explored diamond-like quaternary semiconductor-Li$_2$ZnGeS$_4$ has been
considered for this work. Herein, we have employed two well-known functionals
GGA and mGGA within a frame-work of density functional theory (DFT). We have
explored the electronic, optical, mechanical, and piezo-electromechanical
properties. Our results are in qualitative agreement with some of the
previously reported data. The structural stabilities have been confirmed using
the Born stability criteria and Molecular-dynamic (MD) simulations. Based on
our findings, we claim that Li$_2$ZnGeS$_4$ is the most probable candidate for
optoelectronics and piezoelectric applications.

</details>


### [271] [Theory of Magnetization Temperature Dependence in Ferrimagnetics](https://arxiv.org/abs/2507.18209)
*Rostyslav O. Serha,Anna Pomyalov,Andrii V. Chumak,Victor S. L'vov*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究将描述磁化强度的理论模型扩展到多亚晶格反铁磁体，并与实验数据吻合良好。


<details>
  <summary>Details</summary>
Motivation: 为了在更广泛的温度范围内准确描述稀土磁性材料（特别是多亚晶格反铁磁体如YIG）的自发磁化强度M(T)，并为理论描述提供一种新的框架。

Method: 通过分析和推广Bloch-3/2定律和Weiss平均场近似来描述多亚晶格反铁磁体的M(T)，并使用单一调优参数结合这两种方法来覆盖0<T<Tc的温度范围。

Result: 该研究提出的理论模型能够很好地描述YIG在整个温度范围内的M(T)，并且实验和理论结果都表明M(T)在几乎所有温度下都遵循平均场理论的预测（$\	exttt{sqrt(Tc - T)}$）。

Conclusion: 该研究将描述M(T)的两种近似方法（Bloch-3/2定律和Weiss平均场近似）推广到多亚晶格反铁磁体，并通过实验数据验证了该方法的有效性，发现M(T)在接近居里温度时近似符合平均场理论的预测。

Abstract: Recent advancements in spintronics and fundamental physical research have
brought increased attention to the rare-earth-based magnetically ordered
materials. One of the important properties of these materials is the
temperature dependence of the spontaneous magnetization $M(T)$. Recently, a
successful framework was proposed for the theoretical description of M(T)
across the entire temperature range from zero to the Curie temperature in
simple cubic ferromagnetics, EuO and EuS. We extend this approach to compute
and analyze $M(T)$ for multi-sublattice collinear ferrimagnetics such as
Yttrium Iron Garnet $Y_3Fe_5 O_{12}$. We analyzed and generalized for
multi-sublattice collinear ferrimagnetics two well-known approximations
describing $M(T)$. The first approach is the Bloch-3/2 law, which describes the
suppression of $M(T)$ due to spin-wave excitation, and is valid in the
low-temperature limit $T << T_c$. The second one is Weiss's mean-field
approximation, which provides a reasonable description of $M(T)$ near $T_c$.
Using a single tuning parameter, we combine these two approaches to describe
$M(T)$ for any $0<T<T_c$. The theoretical result for $M(T)$ aligns well with
our measurements and the previously available experimental data across the
entire temperature range. We also demonstrate that experimental and theoretical
dependences $M(T)$ follow the mean-field prediction $\sqrt{T_c - T }$ for
almost all temperatures.

</details>


### [272] [Dis-GEN: Disordered crystal structure generation](https://arxiv.org/abs/2507.18275)
*Martin Hoffmann Petersen,Ruiming Zhu,Haiwen Dai,Savyasanchi Aggarwal,Nong Wei,Andy Paul Chen,Arghya Bhowmik,Juan Maria Garcia Lastra,Kedar Hippalgaonkar*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: A wide range of synthesized crystalline inorganic materials exhibit
compositional disorder, where multiple atomic species partially occupy the same
crystallographic site. As a result, the physical and chemical properties of
such materials are dependent on how the atomic species are distributed among
the corresponding symmetrical sites, making them exceptionally challenging to
model using computational methods. For this reason, existing generative models
cannot handle the complexities of disordered inorganic crystals. To address
this gap, we introduce Dis-GEN, a generative model based on an empirical
equivariant representation, derived from theoretical crystallography
methodology. Dis-GEN is capable of generating symmetry-consistent structures
that accommodate both compositional disorder and vacancies. The model is
uniquely trained on experimental structures from the Inorganic Crystal
Structure Database (ICSD) - the world's largest database of identified
inorganic crystal structures. We demonstrate that Dis-GEN can effectively
generate disordered inorganic materials while preserving crystallographic
symmetry throughout the generation process. This approach provides a critical
check point for the systematic exploration and discovery of disordered
functional materials, expanding the scope of generative modeling in materials
science.

</details>


### [273] [Antiferromagnetic Hall-Memristors](https://arxiv.org/abs/2507.18388)
*Gaspar De la Barrera,Alvaro S. Nunez*

Main category: cond-mat.mtrl-sci

TL;DR: 本文提出了一种基于反铁磁材料和霍尔-忆阻特性的新型自旋忆阻器，利用非线性爱德尔斯坦效应实现记忆的读写，并以CuMnAs为例进行了实验验证，有望用于开发更智能、更节能的计算系统。


<details>
  <summary>Details</summary>
Motivation: 为了克服标准硅电子器件的限制，推动更智能、更节能的计算系统发展，探索了能够通过控制自旋来存储记忆的新型材料——自旋忆阻器。

Method: 提出了一种基于反铁磁材料和霍尔-忆阻特性的自旋忆阻器，并利用非线性爱德尔斯坦效应作为读写器。通过对称性分析支持了该效应的可行性，并以CuMnAs为例进行了具体实现，将器件从传统的两端扩展到了四端。

Result: 成功提出并论证了一种基于反铁磁材料和霍尔-忆阻特性的自旋忆阻器，利用非线性爱德尔斯坦效应实现了对记忆寄存器的读写操作，并将该器件从两端扩展到四端，为相关技术提供了实验和理论基础。

Conclusion: 该研究提出的基于反铁磁材料和霍尔-忆阻特性的自旋忆阻器，利用非线性爱德尔斯坦效应作为读写器，为更智能、更节能的计算系统提供了新的技术方向。

Abstract: Spin-memristors are a class of materials that can store memories through the
control of spins, potentially leading to novel technologies that address the
constraints of standard silicon electronics, thereby facilitating the
advancement of more intelligent and energy-efficient computing systems. In this
work, we present a spin-memristor based on antiferromagnetic materials that
exhibit Hall-memresistance. Moreover, the nonlinear Edelstein effect acts as
both a writer and eraser of memory registers. We provide a generic
symmetry-based analysis that supports the viability of the effect. To achieve a
concrete realization of these ideas, we focus on CuMnAs, which has been shown
to have a controllable nonlinear Hall effect. Our results extend the
two-terminal spin-memristor setting, which is customarily the standard type of
device in this context, to a four-terminal device.

</details>


### [274] [Efficient $GW$ band structure calculations using Gaussian basis functions and application to atomically thin transition-metal dichalcogenides](https://arxiv.org/abs/2507.18411)
*Rémi Pasquier,María Camarasa-Gómez,Anna-Sophia Hehn,Daniel Hernangómez-Pérez,Jan Wilhelm*

Main category: cond-mat.mtrl-sci

TL;DR: 提出了一种新的GW算法，可以快速准确地计算二维材料的电子带隙。


<details>
  <summary>Details</summary>
Motivation: 为了实现对原子尺度二维过渡金属硫族化合物的准确且计算高效的准粒子带隙结构计算。

Method: 采用晶格求和方法计算了不可约密度响应和自能，并采用k点采样计算了屏蔽的库仑相互作用。

Result: 计算出的GW带隙与基于平面波的参考计算结果的平均差异在50meV以内，并且计算速度快，在笔记本电脑上不到两天，或使用1024核不到30分钟即可完成。

Conclusion: 该算法为原子尺度二维过渡金属硫族化合物的GW计算提供了一个高效且可扩展的框架。

Abstract: We present a $GW$ space-time algorithm for periodic systems in a Gaussian
basis including spin-orbit coupling. We employ lattice summation to compute the
irreducible density response and the self-energy, while we employ $k$-point
sampling for computing the screened Coulomb interaction. Our algorithm enables
accurate and computationally efficient quasiparticle band structure
calculations for atomically thin transition-metal dichalcogenides. For
monolayer MoS$_\text{2}$, MoSe$_\text{2}$, WS$_\text{2}$, and WSe$_\text{2}$,
computed $GW$ band gaps agree on average within 50~meV with plane-wave-based
reference calculations. $G_0W_0$ band structures are obtained in less than two
days on a laptop (Intel i5, 192 GB RAM) or in less than 30 minutes using 1024
cores. Overall, our work provides an efficient and scalable framework for $GW$
calculations on atomically thin materials.

</details>


### [275] [2D ferroelectricity accompanying antiferro-orbital order in semi-metallic WTe$_2$](https://arxiv.org/abs/2507.18438)
*Fangyuan Gu,Ruoshi Jiang,Wei Ku*

Main category: cond-mat.mtrl-sci

TL;DR: Ferroelectricity in WTe2 is explained by a coupling between out-of-plane electric polarization and in-plane antiferro-orbital order, offering potential for new memory devices.


<details>
  <summary>Details</summary>
Motivation: To understand the mechanism behind the surprisingly robust ferroelectricity in WTe2, which survives at high temperatures despite the small ordered polarization, challenging standard understandings.

Method: Density-functional-based multi-energy-scale analysis of the system's broken symmetries.

Result: Identification of a weak out-of-plane ferroelectricity coupled with a strong in-plane antiferro-orbital order, which emerges from a higher-energy antiferroelectric structure. This explains the observed phenomenon and reveals a new paradigm of electronic ferroelectricity.

Conclusion: The study identifies a weak out-of-plane ferroelectricity accompanying a strong in-plane antiferro-orbital order in bilayer and trilayer WTe2, explaining the survival of ferroelectricity at high temperatures. This reveals a new paradigm of electronic ferroelectricity applicable to 2D polar metals for next-generation non-volatile memory.

Abstract: The first switchable electric polarization in metals was recently discovered
in bilayer and trilayer WTe2. Strangely, despite the tininess of the ordered
polarization, the ferroelectricity survives up to 350 K, rendering the
mechanism of such ferroelectricity challenging for standard understandings.
Here, via a density-functional-based multi-energy-scale analysis of the
system's broken symmetries, we identify a weak out-of-plane ferroelectricity
accompanying a strong in-plane antiferro-orbital order. This unusual low-energy
correlation, which emerges from an antiferroelectric structure formed at much
higher energy, naturally explains the above puzzling observation. This result
reveals an unprecedented paradigm of electronic ferroelectricity generally
applicable to 2D polar metals with ultrafast-switchable polarization ideal for
the next-generation non-volatile memory and other devices.

</details>


### [276] [Active Δ-learning with universal potentials for global structure optimization](https://arxiv.org/abs/2507.18485)
*Joe Pitfield,Mads-Peter Verner Christiansen,Bjørk Hammer*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Universal machine learning interatomic potentials (uMLIPs) have recently been
formulated and shown to generalize well. When applied out-of-sample, further
data collection for improvement of the uMLIPs may, however, be required. In
this work we demonstrate that, whenever the envisaged use of the MLIPs is
global optimization, the data acquisition can follow an active learning scheme
in which a gradually updated uMLIP directs the finding of new structures, which
are subsequently evaluated at the density functional theory (DFT) level. In the
scheme, we augment foundation models using a {\Delta}-model based on this new
data using local SOAP-descriptors, Gaussian kernels, and a sparse Gaussian
Process Regression model. We compare the efficacy of the approach with
different global optimization algorithms, Random Structure Search, Basin
Hopping, a Bayesian approach with competitive candidates (GOFEE), and a replica
exchange formulation (REX). We further compare several foundation models,
CHGNet, MACE-MP0, and MACE-MPA. The test systems are silver-sulfur clusters and
sulfur-induced surface reconstructions on Ag(111) and Ag(100). Judged by the
fidelity of identifying global minima, active learning with GPR-based
{\Delta}-models appears to be a robust approach. Judged by the total CPU time
spent, the REX approach stands out as being the most efficient.

</details>


### [277] [Deep learning-enabled large-scale analysis of particle geometry-lithiation correlations in battery cathode materials](https://arxiv.org/abs/2507.18530)
*Binbin Lin,Luis J. Carrillo,Xiang-Long Peng,Wan-Xin Chen,David A. Santosb,Sarbajit Banerjeeb,Bai-Xiang Xu*

Main category: cond-mat.mtrl-sci

TL;DR: 深度学习用于V2O5纳米颗粒分割，揭示几何特征与锂化相的关系，优化电池材料。


<details>
  <summary>Details</summary>
Motivation: 为了解决V2O5纳米颗粒分割的挑战性问题，并探究锂化V2O5纳米颗粒的化学成分与其几何特征之间的相关性，以期优化锂电池材料的锂化均匀性和降低应力。

Method: 该研究采用深度学习模型结合奇异值分解技术和光谱数据库，对扫描透射X射线显微镜图像进行处理，生成精确的组分和相图，并分析了几何特征（如粒子尺寸、长宽比、圆度、凸度和取向）对锂化相图的影响。

Result: 揭示了粒子尺寸、长宽比、圆度、凸度和取向等几何特征对锂化相图的量化影响，为优化粒子几何形状以提高相变电池材料的锂化均匀性和降低应力提供了依据。

Conclusion: 该研究通过深度学习模型实现了V2O5纳米颗粒的分割，揭示了几何特征与锂化相图之间的关系，为优化锂电池材料提供了策略。

Abstract: A deep learning model is employed to address the challenging problem of V2O5
nanoparticle segmentation and the correlation between the chemical composition
and the geometrical features of lithiated V2O5 nanoparticles as an exemplar of
a phase-transforming battery cathode material. First, the deep learning-enabled
segmentation model is integrated with the singular value decomposition
technique and a spectral database to generate accurate composition and phase
maps capturing lithiation heterogeneities as imaged using scanning transmission
X-ray microscopy. These phase maps act as the output properties for correlation
analysis. Subsequently, the quantitative influences of the geometrical features
of nanoparticles such as the particle size (i.e., projected perimeter and
area), the aspect ratio, circularity, convexity, and orientation on the
lithiation phase maps are revealed. These findings inform strategies to improve
lithiation uniformity and reduce stress in phase-transforming lithium battery
materials via optimized particle geometry.

</details>


### [278] [Programmable phase selection between altermagnetic and non-centrosymmetric polymorphs of MnTe on InP via molecular beam epitaxy](https://arxiv.org/abs/2507.18592)
*An-Hsi Chen,Parul R. Raghuvanshi,Jacob Cook,Michael Chilcote,Jason Lapano,Alessandro R. Mazza,Qiangsheng Lu,Sangsoo Kim,Yueh-Chun Wu,T. Zac Ward,Benjamin Lawrie,Guang Bian,James Burns,Jonathan D. Poplawsky,Myung-Geun Han,Yimei Zhu,Lucas Lindsay,Hu Miao,Robert G. Moore,Gyula Eres,Valentino R. Cooper,Matthew Brahlek*

Main category: cond-mat.mtrl-sci

TL;DR: 通过调控InP衬底表面（In端或P端）成功外延生长了不同晶体结构（六方NiAs或立方ZnS）的MnTe，揭示了界面化学性质在相选择中的关键作用，为MnTe在自旋电子和微电子领域的应用提供了基础。


<details>
  <summary>Details</summary>
Motivation: 为了在特定应用中获得目标物理性质，需要精确控制外延生长过程中近简并晶体多晶异质体（包括反铁磁性和非中心对称多晶异质体）的选择。MnTe是研究此类问题的理想模型材料。

Method: 研究利用分子束外延（MBE）技术，结合电子显微镜、光电子能谱和反射高能电子衍射等多种表征手段，并辅以第一性原理计算，来研究MnTe在不同表面化学性质的InP衬底上的外延生长行为，特别是其相选择性机制。

Result: 研究成功地在InP衬底的(111)A（In端 termination）表面外延生长了六方NiAs结构的MnTe（反铁磁性），在(111)B（P端 termination）表面外延生长了立方ZnS结构的MnTe（非中心对称，宽带隙>3eV）。通过界面分析和理论计算表明，界面端接和应变是触发相选择的关键因素，并阐述了其形成机制。

Conclusion: 该研究通过精确控制InP衬底表面的化学性质，成功实现了MnTe晶体多晶异质外延生长中的相选择性，为开发新型自旋电子和微电子器件奠定了基础。

Abstract: Phase selecting nearly degenerate crystalline polymorphs during epitaxial
growth can be challenging yet is critical to targeting physical properties for
specific applications. Here, we establish how phase selectivity of
altermagnetic and non-centrosymmetric polymorphs of MnTe with high structural
quality and phase purity can be programmed by subtle changes to the surface of
lattice-matched InP substrates in molecular beam epitaxial (MBE) growth. Bulk
altermagnetic MnTe is thermodynamically stable in the hexagonal NiAs-structure
and is synthesized here on the (111)A surface (In-terminated) of InP, while the
non-centrosymmetric, cubic ZnS-structure with wide band gap (> 3eV) is
stabilized on the (111)B surface (P-terminated). Here we use electron
microscopy, photoemission spectroscopy, and reflection high-energy electron
diffraction, which together indicate that the phase selection is triggered at
the interface and proceeds along the growing surface. First principles
calculations suggest that interfacial termination and strain have a significant
effect on the interfacial energy; stabilizing the NiAs polymorph on the
In-terminated surface and the ZnS structure on the P-terminated surface.
Selectively grown, high-quality films of MnTe polymorphs are key platforms that
will enable our understanding of the novel properties of these materials,
thereby facilitating their use in new applications ranging from spintronics to
microelectronic devices.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [279] [Explainable Graph Neural Networks via Structural Externalities](https://arxiv.org/abs/2507.17848)
*Lijun Wu,Dong Hao,Zhiyi Fan*

Main category: cs.LG

TL;DR: GraphEXT是一个新颖的GNN可解释性框架，它利用合作博弈论和外部性来量化节点的重要性，并能更好地捕捉节点间的交互作用。


<details>
  <summary>Details</summary>
Motivation: 现有的GNN可解释性方法难以有效捕捉网络中节点之间复杂的交互模式，而GNN模型本身具有“黑盒”的特性，对其可解释性提出了挑战。

Method: GraphEXT框架利用合作博弈论和外部性概念，将图节点划分为联盟，并将图结构作为外部性。通过在外部性下整合Shapley值，量化节点在联盟间转换时的边际贡献。

Result: 实验结果表明，GraphEXT在忠实度方面优于现有的基线方法，并能显著增强GNN模型的可解释性。

Conclusion: GraphEXT通过利用合作博弈论和外部性概念，在GNN可解释性方面取得了显著的改进，在忠实度方面优于现有方法，并增强了GNN模型的可解释性。

Abstract: Graph Neural Networks (GNNs) have achieved outstanding performance across a
wide range of graph-related tasks. However, their "black-box" nature poses
significant challenges to their explainability, and existing methods often fail
to effectively capture the intricate interaction patterns among nodes within
the network. In this work, we propose a novel explainability framework,
GraphEXT, which leverages cooperative game theory and the concept of social
externalities. GraphEXT partitions graph nodes into coalitions, decomposing the
original graph into independent subgraphs. By integrating graph structure as an
externality and incorporating the Shapley value under externalities, GraphEXT
quantifies node importance through their marginal contributions to GNN
predictions as the nodes transition between coalitions. Unlike traditional
Shapley value-based methods that primarily focus on node attributes, our
GraphEXT places greater emphasis on the interactions among nodes and the impact
of structural changes on GNN predictions. Experimental studies on both
synthetic and real-world datasets show that GraphEXT outperforms existing
baseline methods in terms of fidelity across diverse GNN architectures ,
significantly enhancing the explainability of GNN models.

</details>


### [280] [Fourier Neural Operators for Non-Markovian Processes:Approximation Theorems and Experiments](https://arxiv.org/abs/2507.17887)
*Wonjae Lee,Taeyoung Kim,Hyungbin Park*

Main category: cs.LG

TL;DR: MFNO是一种新的神经网络，可以学习随机系统的动力学，并能处理非周期性输入。


<details>
  <summary>Details</summary>
Motivation: 为了学习随机系统的动力学，并解决标准FNO无法处理非周期性输入的问题。

Method: MFNO通过引入镜像填充来扩展标准的FNO，使其能够处理非周期性输入。其理论分析基于Wong-Zakai类型定理和各种近似技术。

Result: MFNO可以任意精度的近似路径依赖随机微分方程和分数布朗运动的Lipschitz变换。

Conclusion: MFNO在处理非周期性输入时表现出强大的分辨率泛化能力，并且在样本路径生成方面比经典数值方案更快，在与其他基线模型相比时，其性能相当或更优。

Abstract: This paper introduces an operator-based neural network, the mirror-padded
Fourier neural operator (MFNO), designed to learn the dynamics of stochastic
systems. MFNO extends the standard Fourier neural operator (FNO) by
incorporating mirror padding, enabling it to handle non-periodic inputs. We
rigorously prove that MFNOs can approximate solutions of path-dependent
stochastic differential equations and Lipschitz transformations of fractional
Brownian motions to an arbitrary degree of accuracy. Our theoretical analysis
builds on Wong--Zakai type theorems and various approximation techniques.
Empirically, the MFNO exhibits strong resolution generalization--a property
rarely seen in standard architectures such as LSTMs, TCNs, and DeepONet.
Furthermore, our model achieves performance that is comparable or superior to
these baselines while offering significantly faster sample path generation than
classical numerical schemes.

</details>


### [281] [Enhancing Quantization-Aware Training on Edge Devices via Relative Entropy Coreset Selection and Cascaded Layer Correction](https://arxiv.org/abs/2507.17768)
*Yujia Tong,Jingling Yuan,Chuang Hu*

Main category: cs.LG

TL;DR: QuaRC improves low-bit model quantization on edge devices using coreset selection and layer correction, achieving higher accuracy with less data than existing methods.


<details>
  <summary>Details</summary>
Motivation: The increasing demand for low-bit quantized models on edge devices, coupled with the need to retrain models using sensitive edge data due to privacy concerns, necessitates efficient training methods like QAT on edge devices. Traditional QAT's reliance on complete datasets incurs high computational costs, and existing coreset selection methods fail to eliminate quantization errors with small datasets, leading to performance degradation.

Method: QuaRC utilizes a two-phase approach: 1. Coreset selection using the 'Relative Entropy Score' to identify subsets that capture quantization errors. 2. Training phase employing 'Cascaded Layer Correction' to align intermediate layer outputs of quantized and full-precision models.

Result: QuaRC achieves a 5.72% improvement in Top-1 accuracy on the ImageNet-1K dataset when quantizing ResNet-18 to 2-bit using only 1% of the data, outperforming state-of-the-art techniques.

Conclusion: QuaRC is an effective QAT framework with coresets for edge devices that improves performance on low-bit quantized models by addressing quantization errors in intermediate layers, achieving significant accuracy improvements compared to state-of-the-art techniques.

Abstract: With the development of mobile and edge computing, the demand for low-bit
quantized models on edge devices is increasing to achieve efficient deployment.
To enhance the performance, it is often necessary to retrain the quantized
models using edge data. However, due to privacy concerns, certain sensitive
data can only be processed on edge devices. Therefore, employing
Quantization-Aware Training (QAT) on edge devices has become an effective
solution. Nevertheless, traditional QAT relies on the complete dataset for
training, which incurs a huge computational cost. Coreset selection techniques
can mitigate this issue by training on the most representative subsets.
However, existing methods struggle to eliminate quantization errors in the
model when using small-scale datasets (e.g., only 10% of the data), leading to
significant performance degradation. To address these issues, we propose QuaRC,
a QAT framework with coresets on edge devices, which consists of two main
phases: In the coreset selection phase, QuaRC introduces the ``Relative Entropy
Score" to identify the subsets that most effectively capture the model's
quantization errors. During the training phase, QuaRC employs the Cascaded
Layer Correction strategy to align the intermediate layer outputs of the
quantized model with those of the full-precision model, thereby effectively
reducing the quantization errors in the intermediate layers. Experimental
results demonstrate the effectiveness of our approach. For instance, when
quantizing ResNet-18 to 2-bit using a 1% data subset, QuaRC achieves a 5.72%
improvement in Top-1 accuracy on the ImageNet-1K dataset compared to
state-of-the-art techniques.

</details>


### [282] [Low-rank adaptive physics-informed HyperDeepONets for solving differential equations](https://arxiv.org/abs/2507.18346)
*Etienne Zeudong,Elsa Cardoso-Bihlo,Alex Bihlo*

Main category: cs.LG

TL;DR: PI-LoRA-HyperDeepONets 通过低秩分解减少了 HyperDeepONets 的参数量和计算成本，同时提高了准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决 HyperDeepONets 架构在算子学习中存在的内存和计算成本高的问题。

Method: 通过在物理信息机器学习的背景下引入 PI-LoRA-HyperDeepONets，利用低秩自适应（LoRA）将超网络的输出层权重矩阵分解为两个较小的低秩矩阵，从而减少了可训练参数数量，并对主干网络权重进行了额外正则化。

Result: PI-LoRA-HyperDeepONets 实现了高达 70% 的参数缩减，并在预测准确性和泛化能力方面持续优于常规 HyperDeepONets。

Conclusion: PI-LoRA-HyperDeepONets 在参数量和预测准确性及泛化能力方面优于常规 HyperDeepONets。

Abstract: HyperDeepONets were introduced in Lee, Cho and Hwang [ICLR, 2023] as an
alternative architecture for operator learning, in which a hypernetwork
generates the weights for the trunk net of a DeepONet. While this improves
expressivity, it incurs high memory and computational costs due to the large
number of output parameters required. In this work we introduce, in the
physics-informed machine learning setting, a variation, PI-LoRA-HyperDeepONets,
which leverage low-rank adaptation (LoRA) to reduce complexity by decomposing
the hypernetwork's output layer weight matrix into two smaller low-rank
matrices. This reduces the number of trainable parameters while introducing an
extra regularization of the trunk networks' weights. Through extensive
experiments on both ordinary and partial differential equations we show that
PI-LoRA-HyperDeepONets achieve up to 70\% reduction in parameters and
consistently outperform regular HyperDeepONets in terms of predictive accuracy
and generalization.

</details>


### [283] [Knowledge Abstraction for Knowledge-based Semantic Communication: A Generative Causality Invariant Approach](https://arxiv.org/abs/2507.17784)
*Minh-Duong Nguyen,Quoc-Viet Pham,Nguyen H. Tran,Hoang-Khoi Do,Duy T. Ngo,Won-Joo Hwang*

Main category: cs.LG

TL;DR: 利用因果不变性学习的生成对抗网络提高了语义通信中信道解码器的数据重建能力，并在PSNR方面取得了领先。


<details>
  <summary>Details</summary>
Motivation: 为了在语义通信的信道解码器中捕获通用知识以提高数据重建，并解决用户收集的数据随时间演变导致知识差异的问题。

Method: 提出了一种利用因果不变性学习的生成对抗网络，并设计了稀疏更新协议以在不同领域和不断演变的数据中保持知识的不变性。

Result: 经验评估表明，因果不变性知识在不同设备之间保持一致性，并在分类任务中表现出有前景的性能，并且基于知识的数据重建在PSNR方面优于其他最先进的方法。

Conclusion: 该模型通过因果不变性学习来提取因果和非因果表示，从而实现鲁棒的数据重建，并在峰值信噪比（PSNR）方面超越了其他最先进的方法。

Abstract: In this study, we design a low-complexity and generalized AI model that can
capture common knowledge to improve data reconstruction of the channel decoder
for semantic communication. Specifically, we propose a generative adversarial
network that leverages causality-invariant learning to extract causal and
non-causal representations from the data. Causal representations are invariant
and encompass crucial information to identify the data's label. They can
encapsulate semantic knowledge and facilitate effective data reconstruction at
the receiver. Moreover, the causal mechanism ensures that learned
representations remain consistent across different domains, making the system
reliable even with users collecting data from diverse domains. As
user-collected data evolves over time causing knowledge divergence among users,
we design sparse update protocols to improve the invariant properties of the
knowledge while minimizing communication overheads. Three key observations were
drawn from our empirical evaluations. Firstly, causality-invariant knowledge
ensures consistency across different devices despite the diverse training data.
Secondly, invariant knowledge has promising performance in classification
tasks, which is pivotal for goal-oriented semantic communications. Thirdly, our
knowledge-based data reconstruction highlights the robustness of our decoder,
which surpasses other state-of-the-art data reconstruction and semantic
compression methods in terms of Peak Signal-to-Noise Ratio (PSNR).

</details>


### [284] [Self-similarity Analysis in Deep Neural Networks](https://arxiv.org/abs/2507.17785)
*Jingyi Ding,Chengwen Qi,Hongfei Wang,Jianshe Wu,Licheng Jiao,Yuwei Guo,Jian Gao*

Main category: cs.LG

TL;DR: 该研究提出了一种复杂网络建模方法，以研究深度神经网络中隐藏空间几何的自相似性。研究发现，通过约束特征网络的自相似性可以提高模型性能，尤其是在MLP和注意力架构中，性能提升高达6%。


<details>
  <summary>Details</summary>
Motivation: 尽管现有研究发现深度神经网络在特征表示或参数分布方面表现出强烈的分层自相似性，但除了关于权重幂律分布对模型性能影响的初步研究外，尚未对隐藏空间几何的自相似性如何影响模型权重优化进行量化分析，并且对内部神经元的动态行为也缺乏清晰的理解。

Method: 提出了一种基于隐藏层神经元输出特征的复杂网络建模方法，用于研究不同隐藏层构建的特征网络的自相似性，并分析了调整特征网络自相似性程度如何增强深度神经网络的分类性能。

Result: 研究表明，特征网络的自相似性程度在不同的模型架构中是不同的。此外，通过在训练过程中嵌入特征网络的自相似性约束，可以提高自相似深度神经网络（MLP架构和注意力架构）的性能。

Conclusion: 通过在训练过程中嵌入特征网络的自相似性约束，可以提高自相似深度神经网络（MLP架构和注意力架构）的性能，最高可达6个百分点。

Abstract: Current research has found that some deep neural networks exhibit strong
hierarchical self-similarity in feature representation or parameter
distribution. However, aside from preliminary studies on how the power-law
distribution of weights across different training stages affects model
performance,there has been no quantitative analysis on how the self-similarity
of hidden space geometry influences model weight optimization, nor is there a
clear understanding of the dynamic behavior of internal neurons. Therefore,
this paper proposes a complex network modeling method based on the output
features of hidden-layer neurons to investigate the self-similarity of feature
networks constructed at different hidden layers, and analyzes how adjusting the
degree of self-similarity in feature networks can enhance the classification
performance of deep neural networks. Validated on three types of networks MLP
architectures, convolutional networks, and attention architectures this study
reveals that the degree of self-similarity exhibited by feature networks varies
across different model architectures. Furthermore, embedding constraints on the
self-similarity of feature networks during the training process can improve the
performance of self-similar deep neural networks (MLP architectures and
attention architectures) by up to 6 percentage points.

</details>


### [285] [Reinforcement Learning for Accelerated Aerodynamic Shape Optimisation](https://arxiv.org/abs/2507.17786)
*Florian Sobieczky,Alfredo Lopez,Erika Dudkin,Christopher Lackner,Matthias Hochsteger,Bernhard Scheichl,Helmut Sobieczky*

Main category: cs.LG

TL;DR: 我们引入了一种基于强化学习（RL）的自适应优化算法，用于关注降维的气动形状优化。


<details>
  <summary>Details</summary>
Motivation: 我们的目标是最大限度地减少计算工作量，并利用观察到的优化结果来解释所发现的极值在实现期望的流场中的作用。

Method: 该方法采用基于代理的、Actor-Critic策略评估MCMC方法，并专注于降维，利用强化学习（RL）。

Result: 我们给出了一个简单的流体动力学问题的例子，该问题允许在特征重要性评分方面进行解释。

Conclusion: 该方法通过对中间CFD模拟的局部优化参数进行一系列更改，有可能加速全局优化。

Abstract: We introduce a reinforcement learning (RL) based adaptive optimization
algorithm for aerodynamic shape optimization focused on dimensionality
reduction. The form in which RL is applied here is that of a surrogate-based,
actor-critic policy evaluation MCMC approach allowing for temporal 'freezing'
of some of the parameters to be optimized. The goals are to minimize
computational effort, and to use the observed optimization results for
interpretation of the discovered extrema in terms of their role in achieving
the desired flow-field.
  By a sequence of local optimized parameter changes around intermediate CFD
simulations acting as ground truth, it is possible to speed up the global
optimization if (a) the local neighbourhoods of the parameters in which the
changed parameters must reside are sufficiently large to compete with the
grid-sized steps and its large number of simulations, and (b) the estimates of
the rewards and costs on these neighbourhoods necessary for a good step-wise
parameter adaption are sufficiently accurate. We give an example of a simple
fluid-dynamical problem on which the method allows interpretation in the sense
of a feature importance scoring.

</details>


### [286] [Hyperbolic Deep Learning for Foundation Models: A Survey](https://arxiv.org/abs/2507.17787)
*Neil He,Hiren Madhu,Ngoc Bui,Menglin Yang,Rex Ying*

Main category: cs.LG

TL;DR: 基础模型在各种任务中表现出色，但在表示能力、适应性和可扩展性方面存在局限性。双曲几何通过其处理层次结构和幂律分布的能力，为解决这些局限性提供了一种有前途的方法，从而提高了模型的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 基础模型（包括大型语言模型、视觉语言模型和大型多模态模型）在各种下游任务中取得了显著成功。然而，这些模型存在有限的表示能力、较低的适应性和递减的可扩展性等基本局限性。这引发了一个关键问题：欧氏几何是否真的是所有基础模型的最佳归纳偏置，或者引入替代的几何空间是否能更好地使模型与真实世界数据的内在结构保持一致并改进推理过程？

Method: 本文全面回顾了双曲神经网络及其在基础模型方面的最新发展，并概述了该领域的关键挑战和研究方向。

Result: 双曲空间，一类以体积随距离呈指数增长为特征的非欧流形，提供了一个数学上合理的解决方案。这些空间能够以比欧氏几何少得多的维度，对层次结构（例如树、分类法）和幂律分布进行低失真嵌入。最近的进展利用了这些特性来增强基础模型，包括提高大型语言模型的复杂推理能力、视觉语言模型的零样本泛化能力以及跨模态语义对齐能力，同时保持参数效率。

Conclusion: 虽然欧氏几何在许多基础模型中取得了成功，但双曲几何为解决其表示能力、适应性和可扩展性方面的局限性提供了一种有前途的解决方案。双曲神经网络在嵌入层次结构和幂律分布方面具有优势，并且已成功应用于大型语言模型、视觉语言模型和多模态模型，以提高其性能和参数效率。未来的研究应集中于解决双曲几何在基础模型中的应用挑战，并探索新的研究方向。

Abstract: Foundation models pre-trained on massive datasets, including large language
models (LLMs), vision-language models (VLMs), and large multimodal models, have
demonstrated remarkable success in diverse downstream tasks. However, recent
studies have shown fundamental limitations of these models: (1) limited
representational capacity, (2) lower adaptability, and (3) diminishing
scalability. These shortcomings raise a critical question: is Euclidean
geometry truly the optimal inductive bias for all foundation models, or could
incorporating alternative geometric spaces enable models to better align with
the intrinsic structure of real-world data and improve reasoning processes?
Hyperbolic spaces, a class of non-Euclidean manifolds characterized by
exponential volume growth with respect to distance, offer a mathematically
grounded solution. These spaces enable low-distortion embeddings of
hierarchical structures (e.g., trees, taxonomies) and power-law distributions
with substantially fewer dimensions compared to Euclidean counterparts. Recent
advances have leveraged these properties to enhance foundation models,
including improving LLMs' complex reasoning ability, VLMs' zero-shot
generalization, and cross-modal semantic alignment, while maintaining parameter
efficiency. This paper provides a comprehensive review of hyperbolic neural
networks and their recent development for foundation models. We further outline
key challenges and research directions to advance the field.

</details>


### [287] [Remembering the Markov Property in Cooperative MARL](https://arxiv.org/abs/2507.18333)
*Kale-ab Abebe Tessera,Leonard Hinckeldey,Riccardo Zamboni,David Abel,Amos Storkey*

Main category: cs.LG

TL;DR: MARL算法通过学习约定而非恢复马尔可夫信号来取得成功，这些约定是脆弱的，并且在基准测试中没有充分测试Dec-POMDP假设。


<details>
  <summary>Details</summary>
Motivation: MARL算法的成功原因并非有效恢复马尔可夫信号，而是学习绕过环境观察和记忆的简单约定。

Method: 通过有针对性的案例研究，我们证明了共同适应的智能体可以学会脆弱的约定，并表明相同的模型可以学会基础策略。

Result: MARL算法学习到的约定是脆弱的，当与非适应性智能体配对时会失败。但当任务设计需要时，模型可以学会基础策略。这表明问题在于基准设计，而非模型本身。模型可能没有充分测试Dec-POMDP的核心假设。

Conclusion: 目前的元学习算法的成功并非因为有效的马尔可夫信号恢复，而是因为学习简单的、绕过环境观察和记忆的约定。通过有针对性的案例研究，我们证明了共同适应的智能体可以学会脆弱的约定，而当与不适应的智能体匹配时，这些约定就会失败。重要的是，当任务设计需要时，相同的模型可以学会基础策略，这表明问题不在于学习模型的根本限制，而在于基准设计的失败。我们的分析还表明，现代元学习环境可能无法充分测试Dec-POMDP的核心假设。因此，我们提倡建立在两个核心原则之上的新合作环境：(1)基于观察的行为和(2)基于记忆的关于其他智能体的推理，确保成功需要真正的技能而不是脆弱的、共同适应的协议。

Abstract: Cooperative multi-agent reinforcement learning (MARL) is typically formalised
as a Decentralised Partially Observable Markov Decision Process (Dec-POMDP),
where agents must reason about the environment and other agents' behaviour. In
practice, current model-free MARL algorithms use simple recurrent function
approximators to address the challenge of reasoning about others using partial
information. In this position paper, we argue that the empirical success of
these methods is not due to effective Markov signal recovery, but rather to
learning simple conventions that bypass environment observations and memory.
Through a targeted case study, we show that co-adapting agents can learn
brittle conventions, which then fail when partnered with non-adaptive agents.
Crucially, the same models can learn grounded policies when the task design
necessitates it, revealing that the issue is not a fundamental limitation of
the learning models but a failure of the benchmark design. Our analysis also
suggests that modern MARL environments may not adequately test the core
assumptions of Dec-POMDPs. We therefore advocate for new cooperative
environments built upon two core principles: (1) behaviours grounded in
observations and (2) memory-based reasoning about other agents, ensuring
success requires genuine skill rather than fragile, co-adapted agreements.

</details>


### [288] [Adaptive Repetition for Mitigating Position Bias in LLM-Based Ranking](https://arxiv.org/abs/2507.17788)
*Ali Vardasbi,Gustavo Penha,Claudia Hauff,Hugues Bouchard*

Main category: cs.LG

TL;DR: 为解决LLM排序中的顺序偏见和重复不一致性问题，我们提出动态提前停止方法，大幅减少了计算量（平均87%），同时保持了准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在项目排序和答案评估任务中存在顺序偏见（模型决策受候选项目顺序影响）和重复一致性低（相同输入可能导致不同输出）的问题。现有通过多次重复并聚合结果的方法计算成本高昂。此外，顺序偏见的表现（方向和幅度）因实例而异，需要一种针对每个实例的缓解策略。

Method: 提出并评估了一种动态提前停止方法，该方法能够自适应地确定每个实例所需的重复次数，以解决LLM的顺序偏见和重复不一致性问题。同时，还提出了一种基于置信度的变体，进一步优化了效率。

Result: 与静态重复相比，动态提前停止方法能将LLM调用次数平均减少81%，同时保持准确性。基于置信度的变体能将LLM调用次数平均减少87%，准确性仅有轻微下降。

Conclusion: 为解决大型语言模型（LLM）在对项目进行排序或评估答案时存在的顺序偏见和重复一致性问题，本研究提出了一种动态提前停止方法，该方法能为每个实例自适应地确定所需的重复次数。通过在三种不同大小的模型和重新排序、对齐两个任务上进行评估，我们证明了该方法能将LLM调用次数平均减少81%，同时保持准确性。此外，我们还提出了一种基于置信度的动态提前停止方法，与静态重复相比，LLM调用次数平均减少87%，并且准确性仅有轻微下降。

Abstract: When using LLMs to rank items based on given criteria, or evaluate answers,
the order of candidate items can influence the model's final decision. This
sensitivity to item positioning in a LLM's prompt is known as position bias.
Prior research shows that this bias exists even in large models, though its
severity varies across models and tasks. In addition to position bias, LLMs
also exhibit varying degrees of low repetition consistency, where repeating the
LLM call with the same candidate ordering can lead to different rankings. To
address both inconsistencies, a common approach is to prompt the model multiple
times with different candidate orderings and aggregate the results via majority
voting. However, this repetition strategy, significantly increases
computational costs. Extending prior findings, we observe that both the
direction -- favoring either the earlier or later candidate in the prompt --
and magnitude of position bias across instances vary substantially, even within
a single dataset. This observation highlights the need for a per-instance
mitigation strategy. To this end, we introduce a dynamic early-stopping method
that adaptively determines the number of repetitions required for each
instance. Evaluating our approach across three LLMs of varying sizes and on two
tasks, namely re-ranking and alignment, we demonstrate that transitioning to a
dynamic repetition strategy reduces the number of LLM calls by an average of
81%, while preserving the accuracy. Furthermore, we propose a confidence-based
adaptation to our early-stopping method, reducing LLM calls by an average of
87% compared to static repetition, with only a slight accuracy trade-off
relative to our original early-stopping method.

</details>


### [289] [Moving Out: Physically-grounded Human-AI Collaboration](https://arxiv.org/abs/2507.18623)
*Xuhui Kang,Sung-Wook Lee,Haolin Liu,Yuyan Wang,Yen-Ling Kuo*

Main category: cs.LG

TL;DR: 提出了一种新的人机协作基准 Moving Out，并提出了一种名为 BASS 的新方法，通过增强行为、模拟和选择来提高智能体的多样性和对行为结果的理解能力，在 AI-AI 和人类-AI 协作任务中取得了优于最先进模型的效果。


<details>
  <summary>Details</summary>
Motivation: 为了有效地与人类协作，具身智能体（例如机器人）必须能够适应环境中的物理动作和约束。这种物理上关联的人机协作必须考虑到由物理约束引起的连续状态-动作空间和约束动力学的复杂性增加。

Method: 提出了一种新颖的方法，称为 BASS（行为增强、模拟和选择），以增强智能体的多样性及其对行为结果的理解。

Result: 使用 Moving Out，设计了两个任务并收集了人类-人类交互数据，以评估模型适应不同人类行为和未见过的物理属性的能力。实验表明 BASS 在 AI-AI 和人类-AI 协作方面优于最先进的模型。

Conclusion: BASS 表现优于最先进的模型，在 AI-AI 和人类-AI 协作方面都取得了更好的效果。

Abstract: The ability to adapt to physical actions and constraints in an environment is
crucial for embodied agents (e.g., robots) to effectively collaborate with
humans. Such physically grounded human-AI collaboration must account for the
increased complexity of the continuous state-action space and constrained
dynamics caused by physical constraints. In this paper, we introduce
\textit{Moving Out}, a new human-AI collaboration benchmark that resembles a
wide range of collaboration modes affected by physical attributes and
constraints, such as moving heavy items together and maintaining consistent
actions to move a big item around a corner. Using Moving Out, we designed two
tasks and collected human-human interaction data to evaluate models' abilities
to adapt to diverse human behaviors and unseen physical attributes. To address
the challenges in physical environments, we propose a novel method, BASS
(Behavior Augmentation, Simulation, and Selection), to enhance the diversity of
agents and their understanding of the outcome of actions. Our experiments show
that BASS outperforms state-of-the-art models in AI-AI and human-AI
collaboration. The project page is available at
\href{https://live-robotics-uva.github.io/movingout_ai/}{https://live-robotics-uva.github.io/movingout\_ai/}.

</details>


### [290] [Helix 1.0: An Open-Source Framework for Reproducible and Interpretable Machine Learning on Tabular Scientific Data](https://arxiv.org/abs/2507.17791)
*Eduardo Aguilar-Bejarano,Daniel Lea,Karthikeyan Sivakumar,Jimiama M. Mase,Reza Omidvar,Ruizhe Li,Troy Kettle,James Mitchell-White,Morgan R Alexander,David A Winkler,Grazziela Figueredo*

Main category: cs.LG

TL;DR: Helix 是一个开源的 Python 框架，用于表格数据的可复现和可解释的机器学习工作流，提供用户友好的界面和创新的解释方法。


<details>
  <summary>Details</summary>
Motivation: 为了满足对透明、可复现和可解释的机器学习工作流日益增长的需求，尤其是在表格数据分析领域。Helix 旨在帮助研究人员（即使是没有正式数据科学培训的人）能够理解和使用机器学习。

Method: Helix 是一个基于 Python 的软件框架，包含用于数据预处理、可视化、模型训练、评估、解释和预测的模块。它有一个用户友好的界面，用于设计实验和检查结果。

Result: Helix 是一个开源框架，它提供了一个集成的环境，用于处理表格数据的机器学习工作流，支持从数据预处理到模型解释的整个过程，并促进了对 FAIR 原则的遵守。

Conclusion: Helix 是一个开源、可扩展的 Python 软件框架，用于表格数据的可复现和可解释的机器学习工作流。它通过标准化数据预处理、可视化、机器学习模型训练、评估、解释、结果检查和对新数据的模型预测等模块，解决了对透明实验数据分析来源日益增长的需求。Helix 提供了一个用户友好的界面，用于设计计算实验和检查结果，包括一种使用语言术语解释机器学习决策的新方法。该平台旨在支持没有数据科学正规培训的研究人员，并促进对 FAIR 原则的遵守。

Abstract: Helix is an open-source, extensible, Python-based software framework to
facilitate reproducible and interpretable machine learning workflows for
tabular data. It addresses the growing need for transparent experimental data
analytics provenance, ensuring that the entire analytical process -- including
decisions around data transformation and methodological choices -- is
documented, accessible, reproducible, and comprehensible to relevant
stakeholders. The platform comprises modules for standardised data
preprocessing, visualisation, machine learning model training, evaluation,
interpretation, results inspection, and model prediction for unseen data. To
further empower researchers without formal training in data science to derive
meaningful and actionable insights, Helix features a user-friendly interface
that enables the design of computational experiments, inspection of outcomes,
including a novel interpretation approach to machine learning decisions using
linguistic terms all within an integrated environment. Released under the MIT
licence, Helix is accessible via GitHub and PyPI, supporting community-driven
development and promoting adherence to the FAIR principles.

</details>


### [291] [Causal Mechanism Estimation in Multi-Sensor Systems Across Multiple Domains](https://arxiv.org/abs/2507.17792)
*Jingyi Yu,Tim Pychynski,Marco F. Huber*

Main category: cs.LG

TL;DR: CICME是一种新颖的三步因果推断方法，用于从异构数据中识别共同和个体因果机制，并在制造场景中表现良好。


<details>
  <summary>Details</summary>
Motivation: 为了通过因果关系更深入地了解复杂的传感器系统，需要一种能够从异构数据中推断因果机制的方法。

Method: CICME是一种新颖的三步方法，利用因果迁移学习（CTL）从跨多个域的异构数据中推断因果机制。它首先利用CTL检测出域不变的因果机制，然后利用识别出的共同因果机制来指导对每个域中剩余因果机制的估计。

Result: 在受制造过程启发的情景下，CICME在具有挑战性的设定下被评估，并被证明在某些场景下优于仅在汇总数据或仅在单个域数据上应用因果发现的方法。

Conclusion: CICME 能够可靠地检测出域不变的因果机制，并能估计各个域中的剩余因果机制，在某些场景下其性能甚至优于基线方法。

Abstract: To gain deeper insights into a complex sensor system through the lens of
causality, we present common and individual causal mechanism estimation
(CICME), a novel three-step approach to inferring causal mechanisms from
heterogeneous data collected across multiple domains. By leveraging the
principle of Causal Transfer Learning (CTL), CICME is able to reliably detect
domain-invariant causal mechanisms when provided with sufficient samples. The
identified common causal mechanisms are further used to guide the estimation of
the remaining causal mechanisms in each domain individually. The performance of
CICME is evaluated on linear Gaussian models under scenarios inspired from a
manufacturing process. Building upon existing continuous optimization-based
causal discovery methods, we show that CICME leverages the benefits of applying
causal discovery on the pooled data and repeatedly on data from individual
domains, and it even outperforms both baseline methods under certain scenarios.

</details>


### [292] [LSDM: LLM-Enhanced Spatio-temporal Diffusion Model for Service-Level Mobile Traffic Prediction](https://arxiv.org/abs/2507.17795)
*Shiyuan Zhang,Tong Li,Zhu Xiao,Hongyang Du,Kaibin Huang*

Main category: cs.LG

TL;DR: LSDM：一种利用LLM和扩散模型进行移动流量预测的方法，提高了预测的准确性和适应性。


<details>
  <summary>Details</summary>
Motivation: 当前移动流量预测方法在不同城市环境中的适应性有限，并且由于个人流量模式的高度不确定性、详细环境背景的缺乏以及不同网络服务之间复杂依赖关系，导致结果不准确。这些挑战需要能够捕捉动态流量分布和丰富环境特征的先进建模技术。

Method: 提出了一种LLM增强的时空扩散模型（LSDM），该模型整合了扩散模型的生成能力、Transformer的自适应学习能力以及多模态环境信息捕捉能力，用于建模服务级别的流量模式和动态。

Result: 与类似模型（如CSDI）相比，LSDM的均方根误差至少可降低8.29%。在加入LLM的上下文信息后，决定系数（coefficient of determination）性能至少提高了2.83%。

Conclusion: LSDM模型在服务级别流量预测方面表现出色，具有出色的泛化和适应能力。

Abstract: Service-level mobile traffic prediction for individual users is essential for
network efficiency and quality of service enhancement. However, current
prediction methods are limited in their adaptability across different urban
environments and produce inaccurate results due to the high uncertainty in
personal traffic patterns, the lack of detailed environmental context, and the
complex dependencies among different network services. These challenges demand
advanced modeling techniques that can capture dynamic traffic distributions and
rich environmental features. Inspired by the recent success of diffusion models
in distribution modeling and Large Language Models (LLMs) in contextual
understanding, we propose an LLM-Enhanced Spatio-temporal Diffusion Model
(LSDM). LSDM integrates the generative power of diffusion models with the
adaptive learning capabilities of transformers, augmented by the ability to
capture multimodal environmental information for modeling service-level
patterns and dynamics. Extensive evaluations on real-world service-level
datasets demonstrate that the model excels in traffic usage predictions,
showing outstanding generalization and adaptability. After incorporating
contextual information via LLM, the performance improves by at least 2.83% in
terms of the coefficient of determination. Compared to models of a similar
type, such as CSDI, the root mean squared error can be reduced by at least
8.29%. The code and dataset will be available at:
https://github.com/SoftYuaneR/LSDM.

</details>


### [293] [CoCAI: Copula-based Conformal Anomaly Identification for Multivariate Time-Series](https://arxiv.org/abs/2507.17796)
*Nicholas A. Pearson,Francesca Zanello,Davide Russo,Luca Bortolussi,Francesca Cairoli*

Main category: cs.LG

TL;DR: CoCAI框架结合了生成式人工智能和基于共聚物的建模，用于多变量时间序列分析，以提高预测准确性和异常检测能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决多变量时间序列分析中提供准确预测和实现稳健异常检测这两个关键挑战。

Method: CoCAI利用基于扩散的模型捕获数据内的复杂依赖关系以实现高质量预测，并利用共聚物（copula-based）建模和降维技术进行稳健的异常检测，同时通过共形预测技术提供具有统计有效性的预测区域。

Result: 所提出的CoCAI方法能够提供准确的预测和稳健的异常检测。

Conclusion: CoCAI在水处理和污水处理系统等实际运行数据上的实证测试证实了其在准确预测数据目标序列和识别其中异常段方面的有效性。

Abstract: We propose a novel framework that harnesses the power of generative
artificial intelligence and copula-based modeling to address two critical
challenges in multivariate time-series analysis: delivering accurate
predictions and enabling robust anomaly detection. Our method, Copula-based
Conformal Anomaly Identification for Multivariate Time-Series (CoCAI),
leverages a diffusion-based model to capture complex dependencies within the
data, enabling high quality forecasting. The model's outputs are further
calibrated using a conformal prediction technique, yielding predictive regions
which are statistically valid, i.e., cover the true target values with a
desired confidence level. Starting from these calibrated forecasts, robust
outlier detection is performed by combining dimensionality reduction techniques
with copula-based modeling, providing a statistically grounded anomaly score.
CoCAI benefits from an offline calibration phase that allows for minimal
overhead during deployment and delivers actionable results rooted in
established theoretical foundations. Empirical tests conducted on real
operational data derived from water distribution and sewerage systems confirm
CoCAI's effectiveness in accurately forecasting target sequences of data and in
identifying anomalous segments within them.

</details>


### [294] [GenSelect: A Generative Approach to Best-of-N](https://arxiv.org/abs/2507.17797)
*Shubham Toshniwal,Ivan Sorokin,Aleksander Ficek,Ivan Moshkov,Igor Gitman*

Main category: cs.LG

TL;DR: GenSelect是一种新的方法，通过LLM进行长推理和选择来改进测试时的方法，在数学推理任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法在利用LLM的比较能力和扩展性方面的不足，我们提出了GenSelect。

Method: GenSelect通过让LLM对N个候选解决方案进行长期推理和选择来利用其比较能力。

Result: GenSelect在数学推理任务上，特别是使用QwQ和DeepSeek-R1-0528等推理模型时，表现优于现有的评分方法。

Conclusion: GenSelect通过利用LLM的比较优势并与并行采样预算有效扩展，在数学推理任务上超越了现有的评分方法。

Abstract: Generative reward models with parallel sampling have enabled effective
test-time scaling for reasoning tasks. Current approaches employ pointwise
scoring of individual solutions or pairwise comparisons. However, pointwise
methods underutilize LLMs' comparative abilities, while pairwise methods scale
inefficiently with larger sampling budgets. We introduce GenSelect, where the
LLM uses long reasoning to select the best solution among N candidates. This
leverages LLMs' comparative strengths while scaling efficiently across parallel
sampling budgets. For math reasoning, we demonstrate that reasoning models,
such as QwQ and DeepSeek-R1-0528, excel at GenSelect, outperforming existing
scoring approaches with simple prompting.

</details>


### [295] [Wasserstein GAN-Based Precipitation Downscaling with Optimal Transport for Enhancing Perceptual Realism](https://arxiv.org/abs/2507.17798)
*Kenta Shiraishi,Yuka Muto,Atsushi Okazaki,Shunji Kotsuki*

Main category: cs.LG

TL;DR: WGAN在降水降尺度预测中生成了更真实的降水场，并且其判别器可以用于评估数据集质量。


<details>
  <summary>Details</summary>
Motivation: 高分辨率降水预测对于减少固定和局部强降雨造成的损害至关重要，但使用过程驱动的数值天气预报模型进行高分辨率降水预测仍然具有挑战性。

Method: 提出使用Wasserstein生成对抗网络（WGAN）结合最优输运成本来进行降水降尺度。

Result: WGAN生成的降水场具有视觉上的真实感和精细结构，尽管在传统评估指标上表现略有下降，但其学习到的判别器与人类感知的真实性高度相关。

Conclusion: WGAN框架不仅提高了降水降尺度预测的感知真实性，还为评估和质量控制降水数据集提供了新视角。

Abstract: High-resolution (HR) precipitation prediction is essential for reducing
damage from stationary and localized heavy rainfall; however, HR precipitation
forecasts using process-driven numerical weather prediction models remains
challenging. This study proposes using Wasserstein Generative Adversarial
Network (WGAN) to perform precipitation downscaling with an optimal transport
cost. In contrast to a conventional neural network trained with mean squared
error, the WGAN generated visually realistic precipitation fields with
fine-scale structures even though the WGAN exhibited slightly lower performance
on conventional evaluation metrics. The learned critic of WGAN correlated well
with human perceptual realism. Case-based analysis revealed that large
discrepancies in critic scores can help identify both unrealistic WGAN outputs
and potential artifacts in the reference data. These findings suggest that the
WGAN framework not only improves perceptual realism in precipitation
downscaling but also offers a new perspective for evaluating and
quality-controlling precipitation datasets.

</details>


### [296] [Look the Other Way: Designing 'Positive' Molecules with Negative Data via Task Arithmetic](https://arxiv.org/abs/2507.17876)
*Rıza Özçelik,Sarah de Ruiter,Francesca Grisoni*

Main category: cs.LG

TL;DR: 生成分子设计瓶颈？试试分子任务算术！在负例上训练，反向操作生成你想要的分子。更快、更多样、更成功。


<details>
  <summary>Details</summary>
Motivation: 生成具有理想属性的分子（即‘正例’分子）在分子生成设计中是一个固有的瓶颈。

Method: 分子任务算术：在多样且丰富的负例上训练模型以学习‘属性方向’，然后沿着相反的属性方向移动模型来生成正例分子，而无需访问任何正例数据。

Result: 在20个零样本设计实验中，分子任务算术比在正例分子上训练的模型生成了更多样化且更成功的設計。此外，在双目标和少样本设计任务中，分子任务算术能持续提高设计的多样性，同时保持理想的设计属性。

Conclusion: 分子任务算术是一种简单、数据高效且性能优越的迁移学习策略，有潜力成为从头分子设计的标准方法。

Abstract: The scarcity of molecules with desirable properties (i.e., 'positive'
molecules) is an inherent bottleneck for generative molecule design. To
sidestep such obstacle, here we propose molecular task arithmetic: training a
model on diverse and abundant negative examples to learn 'property directions'
$--$ without accessing any positively labeled data $--$ and moving models in
the opposite property directions to generate positive molecules. When analyzed
on 20 zero-shot design experiments, molecular task arithmetic generated more
diverse and successful designs than models trained on positive molecules.
Moreover, we employed molecular task arithmetic in dual-objective and few-shot
design tasks. We find that molecular task arithmetic can consistently increase
the diversity of designs while maintaining desirable design properties. With
its simplicity, data efficiency, and performance, molecular task arithmetic
bears the potential to become the $\textit{de-facto}$ transfer learning
strategy for de novo molecule design.

</details>


### [297] [Lower Bounds for Public-Private Learning under Distribution Shift](https://arxiv.org/abs/2507.17895)
*Amrith Setlur,Pratiksha Thaker,Jonathan Ullman*

Main category: cs.LG

TL;DR: 在存在分布偏移的情况下，结合使用公共和私有数据进行机器学习的有效性取决于偏移量的大小。小偏移量需要大量数据，大偏移量则使公共数据失效。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于探索在两个数据源存在分布偏移的情况下，结合使用公共数据和私有数据进行机器学习的有效性，特别是关注何时以及如何利用这两个数据源的互补价值。

Method: 本研究将公共-私有学习的已知下界扩展到两个数据源表现出显著分布偏移的情况。我们对高斯均值估计和高斯线性回归的两种情况进行了分析，其中分布偏移表现为均值或参数的变化。

Result: 研究结果表明，当分布偏移量很小时（相对于期望的精度），需要大量公共数据或私有数据才能有效估计私有参数。当分布偏移量很大时，公共数据则无法提供任何优势。

Conclusion: 当数据源分布偏移显著时，我们扩展了公共-私有学习的已知下界。在数据源具有相同分布的情况下，结合两个数据源没有互补价值，这在均值估计等设置中得到了证明。对于高斯均值估计和高斯线性回归，当偏移量相对于期望精度很小时，公共数据或私有数据必须足够丰富才能估计私有参数。相反，当偏移量很大时，公共数据没有带来任何好处。

Abstract: The most effective differentially private machine learning algorithms in
practice rely on an additional source of purportedly public data. This paradigm
is most interesting when the two sources combine to be more than the sum of
their parts. However, there are settings such as mean estimation where we have
strong lower bounds, showing that when the two data sources have the same
distribution, there is no complementary value to combining the two data
sources. In this work we extend the known lower bounds for public-private
learning to setting where the two data sources exhibit significant distribution
shift. Our results apply to both Gaussian mean estimation where the two
distributions have different means, and to Gaussian linear regression where the
two distributions exhibit parameter shift. We find that when the shift is small
(relative to the desired accuracy), either public or private data must be
sufficiently abundant to estimate the private parameter. Conversely, when the
shift is large, public data provides no benefit.

</details>


### [298] [Federated Learning for Large-Scale Cloud Robotic Manipulation: Opportunities and Challenges](https://arxiv.org/abs/2507.17903)
*Obaidullah Zaland,Chanh Nguyen,Florian T. Pokorny,Monowar Bhuyan*

Main category: cs.LG

TL;DR: 联邦学习在云机器人操纵中的应用前景与挑战。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前机器人操纵任务受限于机器人个体能力和速度的问题，以及利用联邦学习的优势。

Method: 本文介绍了联邦学习（FL）的基本概念及其与云机器人操纵的联系。

Result: 联邦学习（FL）为云机器人操纵提供了新的视角，但也面临挑战。

Conclusion: 该联邦学习（FL）的研究为云机器人操纵提供了基本概念，并预见了通过FL实现大规模高效可靠的云机器人操纵的机遇和挑战。

Abstract: Federated Learning (FL) is an emerging distributed machine learning paradigm,
where the collaborative training of a model involves dynamic participation of
devices to achieve broad objectives. In contrast, classical machine learning
(ML) typically requires data to be located on-premises for training, whereas FL
leverages numerous user devices to train a shared global model without the need
to share private data. Current robotic manipulation tasks are constrained by
the individual capabilities and speed of robots due to limited low-latency
computing resources. Consequently, the concept of cloud robotics has emerged,
allowing robotic applications to harness the flexibility and reliability of
computing resources, effectively alleviating their computational demands across
the cloud-edge continuum. Undoubtedly, within this distributed computing
context, as exemplified in cloud robotic manipulation scenarios, FL offers
manifold advantages while also presenting several challenges and opportunities.
In this paper, we present fundamental concepts of FL and their connection to
cloud robotic manipulation. Additionally, we envision the opportunities and
challenges associated with realizing efficient and reliable cloud robotic
manipulation at scale through FL, where researchers adopt to design and verify
FL models in either centralized or decentralized settings.

</details>


### [299] [ARBoids: Adaptive Residual Reinforcement Learning With Boids Model for Cooperative Multi-USV Target Defense](https://arxiv.org/abs/2502.18549)
*Jiyue Tao,Tongsheng Shen,Dexin Zhao,Feitian Zhang*

Main category: cs.LG

TL;DR: ARBoids是一种结合了Boids模型和深度强化学习的框架，用于提升USV拦截能力，尤其在面对机动性更强的攻击者时表现更优。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决无人水面载具（USV）在面对机动性更强的敌方USV时，如何有效拦截的问题，特别是当攻击者机动性优于防御者时，拦截难度显著增加。

Method: 该研究提出了一种名为ARBoids的新型自适应残差强化学习框架，该框架将深度强化学习（DRL）与受生物启发的基于力的Boids模型相结合。Boids模型作为一种计算高效的多智能体协同基线策略，而DRL则学习残差策略以自适应地优化防御者的行为。

Result: ARBoids框架在仿真环境中展现了优于传统拦截策略的性能，并对具有不同机动性特征的攻击者表现出良好的适应性和泛化能力。

Conclusion: ARBoids框架在Gazebo仿真环境中得到验证，其性能优于传统的纯基于力的方法和标准的深度强化学习策略，并且能够很好地适应具有不同机动性特征的攻击者。

Abstract: The target defense problem (TDP) for unmanned surface vehicles (USVs)
concerns intercepting an adversarial USV before it breaches a designated target
region, using one or more defending USVs. A particularly challenging scenario
arises when the attacker exhibits superior maneuverability compared to the
defenders, significantly complicating effective interception. To tackle this
challenge, this letter introduces ARBoids, a novel adaptive residual
reinforcement learning framework that integrates deep reinforcement learning
(DRL) with the biologically inspired, force-based Boids model. Within this
framework, the Boids model serves as a computationally efficient baseline
policy for multi-agent coordination, while DRL learns a residual policy to
adaptively refine and optimize the defenders' actions. The proposed approach is
validated in a high-fidelity Gazebo simulation environment, demonstrating
superior performance over traditional interception strategies, including pure
force-based approaches and vanilla DRL policies. Furthermore, the learned
policy exhibits strong adaptability to attackers with diverse maneuverability
profiles, highlighting its robustness and generalization capability. The code
of ARBoids will be released upon acceptance of this letter.

</details>


### [300] [Deep learning-aided inverse design of porous metamaterials](https://arxiv.org/abs/2507.17907)
*Phu Thien Nguyen,Yousef Heider,Dennis M. Kochmann,Fadi Aldakheel*

Main category: cs.LG

TL;DR: 这项研究开发了一种名为pVAE的深度学习框架，用于设计具有特定渗透性等特性的多孔超材料。它使用VAE和CNN来加速模拟过程，并在合成和真实数据上进行了训练，证明了其在生成新材料方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 为了探索利用深度学习生成框架进行多孔超材料的反向设计。

Method: 开发了一个属性变分自编码器（pVAE），它是一个在变分自编码器（VAE）中增加了回归器的模型，用于生成具有定制液压特性的结构化超材料。虽然该研究使用格子玻尔兹曼方法（LBM）为有限的多孔微结构生成内在渗透率张量数据，但它训练了一个卷积神经网络（CNN）来预测有效的液压特性，从而显著降低了与直接LBM模拟相比的计算成本。pVAE框架在两个数据集上进行训练：一个是合成的人工多孔微结构数据集，另一个是真实开孔泡沫体素的CT扫描图像。

Result: pVAE框架能够捕捉关键的微结构特征，并将其映射到一个紧凑且可解释的潜在空间中，用于高效的结构-属性探索。该研究对潜在空间进行了详细的分析和解释，展示了其在结构-属性映射、插值和反向设计中的作用。这种方法有助于生成具有所需特性的新超材料。

Conclusion: 该研究提出了一个基于深度学习的生成框架，用于反向设计具有定制液压特性的多孔超材料，例如孔隙率和渗透率。

Abstract: The ultimate aim of the study is to explore the inverse design of porous
metamaterials using a deep learning-based generative framework. Specifically,
we develop a property-variational autoencoder (pVAE), a variational autoencoder
(VAE) augmented with a regressor, to generate structured metamaterials with
tailored hydraulic properties, such as porosity and permeability. While this
work uses the lattice Boltzmann method (LBM) to generate intrinsic permeability
tensor data for limited porous microstructures, a convolutional neural network
(CNN) is trained using a bottom-up approach to predict effective hydraulic
properties. This significantly reduces the computational cost compared to
direct LBM simulations. The pVAE framework is trained on two datasets: a
synthetic dataset of artificial porous microstructures and CT-scan images of
volume elements from real open-cell foams. The encoder-decoder architecture of
the VAE captures key microstructural features, mapping them into a compact and
interpretable latent space for efficient structure-property exploration. The
study provides a detailed analysis and interpretation of the latent space,
demonstrating its role in structure-property mapping, interpolation, and
inverse design. This approach facilitates the generation of new metamaterials
with desired properties. The datasets and codes used in this study will be made
open-access to support further research.

</details>


### [301] [SETOL: A Semi-Empirical Theory of (Deep) Learning](https://arxiv.org/abs/2507.17912)
*Charles H Martin,Christopher Hinrichs*

Main category: cs.LG

TL;DR: 本研究提出了SETOL理论，用以解释SOTA神经网络的性能，并与HTSR理论中的关键指标（alpha）及新提出的ERG指标在多种模型上表现出良好的一致性。


<details>
  <summary>Details</summary>
Motivation: 为了解释当前最先进（SOTA）神经网络（NN）的出色性能，并为重尾自正则化（HTSR）理论中的关键指标（alpha和alpha-hat）提供正式的理论基础。

Method: 本研究提出了半经验学习理论（SETOL），利用统计力学、随机矩阵理论和量子化学方法，为重尾自正则化（HTSR）理论中的基本量（如alpha和alpha-hat）提供了形式化解释。SETOL还提出了新的学习前提条件，包括ERG指标，并将其应用于一个简单的三层MLP和SOTA NN模型进行测试。

Result: SETOL理论与MLP模型表现出良好的一致性，并能通过计算权重矩阵的经验谱密度（ESD）来估计SOTA NN模型的层质量。SETOL的ERG指标和HTSR的alpha指标在MLP和SOTA NN模型上表现出良好的一致性。

Conclusion: SETOL与HTSR的alpha指标在MLP和SOTA NN模型上表现出良好的一致性

Abstract: We present a SemiEmpirical Theory of Learning (SETOL) that explains the
remarkable performance of State-Of-The-Art (SOTA) Neural Networks (NNs). We
provide a formal explanation of the origin of the fundamental quantities in the
phenomenological theory of Heavy-Tailed Self-Regularization (HTSR): the
heavy-tailed power-law layer quality metrics, alpha and alpha-hat. In prior
work, these metrics have been shown to predict trends in the test accuracies of
pretrained SOTA NN models, importantly, without needing access to either
testing or training data. Our SETOL uses techniques from statistical mechanics
as well as advanced methods from random matrix theory and quantum chemistry.
The derivation suggests new mathematical preconditions for ideal learning,
including a new metric, ERG, which is equivalent to applying a single step of
the Wilson Exact Renormalization Group. We test the assumptions and predictions
of SETOL on a simple 3-layer multilayer perceptron (MLP), demonstrating
excellent agreement with the key theoretical assumptions. For SOTA NN models,
we show how to estimate the individual layer qualities of a trained NN by
simply computing the empirical spectral density (ESD) of the layer weight
matrices and plugging this ESD into our SETOL formulas. Notably, we examine the
performance of the HTSR alpha and the SETOL ERG layer quality metrics, and find
that they align remarkably well, both on our MLP and on SOTA NNs.

</details>


### [302] [From Seed to Harvest: Augmenting Human Creativity with AI for Red-teaming Text-to-Image Models](https://arxiv.org/abs/2507.17922)
*Jessica Quaye,Charvi Rastogi,Alicia Parrish,Oana Inel,Minsuk Kahng,Lora Aroyo,Vijay Janapa Reddi*

Main category: cs.LG

TL;DR: Seed2Harvest是一种混合红队测试方法，通过结合人类创造力和机器计算能力，成功地扩展了具有文化多样性的人类对抗性提示种子，实现了更全面、可扩展的T2I模型安全评估。


<details>
  <summary>Details</summary>
Motivation: 为了应对T2I模型在各种应用中的普及，对其进行对抗性攻击的稳健评估变得至关重要。需要持续获取各种领域的新颖且具有挑战性的对抗性提示，以对模型抵御多种攻击向量的新型攻击的韧性进行压力测试。

Method: 提出了一种名为Seed2Harvest的混合红队测试方法，通过引导扩大人造的、具有文化多样性的对抗性提示种子。

Result: Seed2Harvest方法生成的提示保留了人类提示的特征和攻击模式，同时保持了相当的平均攻击成功率（NudeNet为0.31，SD NSFW为0.36，Q16为0.12）。与原始数据集相比，扩展后的数据集实现了更高的多样性，拥有535个独特的地理位置和7.48的香农熵（原始数据集为58个地理位置和5.28的熵）。

Conclusion: 为了实现持续的T2I模型安全评估，需要结合人类创造力和机器计算能力，实现全面、可扩展的红队测试。

Abstract: Text-to-image (T2I) models have become prevalent across numerous
applications, making their robust evaluation against adversarial attacks a
critical priority. Continuous access to new and challenging adversarial prompts
across diverse domains is essential for stress-testing these models for
resilience against novel attacks from multiple vectors. Current techniques for
generating such prompts are either entirely authored by humans or synthetically
generated. On the one hand, datasets of human-crafted adversarial prompts are
often too small in size and imbalanced in their cultural and contextual
representation. On the other hand, datasets of synthetically-generated prompts
achieve scale, but typically lack the realistic nuances and creative
adversarial strategies found in human-crafted prompts. To combine the strengths
of both human and machine approaches, we propose Seed2Harvest, a hybrid
red-teaming method for guided expansion of culturally diverse, human-crafted
adversarial prompt seeds. The resulting prompts preserve the characteristics
and attack patterns of human prompts while maintaining comparable average
attack success rates (0.31 NudeNet, 0.36 SD NSFW, 0.12 Q16). Our expanded
dataset achieves substantially higher diversity with 535 unique geographic
locations and a Shannon entropy of 7.48, compared to 58 locations and 5.28
entropy in the original dataset. Our work demonstrates the importance of
human-machine collaboration in leveraging human creativity and machine
computational capacity to achieve comprehensive, scalable red-teaming for
continuous T2I model safety evaluation.

</details>


### [303] [UrbanPulse: A Cross-City Deep Learning Framework for Ultra-Fine-Grained Population Transfer Prediction](https://arxiv.org/abs/2507.17924)
*Hongrong Yang,Markus Schlaepfer*

Main category: cs.LG

TL;DR: UrbanPulse是一个创新的深度学习框架，通过将每个兴趣点视为节点并利用图卷积和Transformer模型，实现了超精细粒度的城市人口流动预测。它通过多阶段迁移学习有效解决了跨城市泛化难题，并在实际数据集上取得了优越的准确性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在人口流动预测方面存在局限性，包括静态空间假设、跨城市泛化能力差、计算成本高、无法捕捉空间结构以及为了追求准确性而牺牲分辨率。UrbanPulse旨在解决这些问题，提供精细粒度的城市范围预测。

Method: UrbanPulse是一个可扩展的深度学习框架，它将每个兴趣点（POI）视为一个独立的节点，并通过结合时间图卷积编码器和基于Transformer的解码器来预测超精细粒度的城市范围OD流。它采用三阶段迁移学习策略（大规模城市图预训练、冷启动适应和强化学习微调）来确保跨城市泛化能力。

Result: 在对加利福尼亚三个大都市区的1.03亿条GPS记录进行评估后，UrbanPulse在准确性和可扩展性方面均达到了最先进的水平。

Conclusion: UrbanPulse 通过高效的迁移学习，在提高分辨率和城市范围预测能力方面取得了显著进展，为在不同城市中实际部署高分辨率、人工智能驱动的城市预测奠定了关键一步。

Abstract: Accurate population flow prediction is essential for urban planning,
transportation management, and public health. Yet existing methods face key
limitations: traditional models rely on static spatial assumptions, deep
learning models struggle with cross-city generalization, and Large Language
Models (LLMs) incur high computational costs while failing to capture spatial
structure. Moreover, many approaches sacrifice resolution by clustering Points
of Interest (POIs) or restricting coverage to subregions, limiting their
utility for city-wide analytics. We introduce UrbanPulse, a scalable deep
learning framework that delivers ultra-fine-grained, city-wide OD flow
predictions by treating each POI as an individual node. It combines a temporal
graph convolutional encoder with a transformer-based decoder to model
multi-scale spatiotemporal dependencies. To ensure robust generalization across
urban contexts, UrbanPulse employs a three-stage transfer learning strategy:
pretraining on large-scale urban graphs, cold-start adaptation, and
reinforcement learning fine-tuning.Evaluated on over 103 million cleaned GPS
records from three metropolitan areas in California, UrbanPulse achieves
state-of-the-art accuracy and scalability. Through efficient transfer learning,
UrbanPulse takes a key step toward making high-resolution, AI-powered urban
forecasting deployable in practice across diverse cities.

</details>


### [304] [Multimodal Fine-grained Reasoning for Post Quality Evaluation](https://arxiv.org/abs/2507.17934)
*Xiaoxu Guo,Siyan Liang,Yachao Cui,Juxiang Zhou,Lei Wang,Han Cao*

Main category: cs.LG

TL;DR: MFTRR框架通过多模态线索、细粒度质量区分和抑制噪声的推理机制，改进了帖子质量评估的准确性，并在多个数据集上取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 现有的帖子质量评估研究存在三个主要局限性：1. 将任务视为单一模态分类，未能利用多模态线索和细粒度质量区分；2. 在深度多模态融合过程中引入噪声，导致误导性信号；3. 缺乏捕捉相关性和全面性等复杂语义关系的能力。

Method: MFTRR框架，包括局部-全局语义相关性推理模块（通过最大信息融合机制抑制噪声）和多层次证据关系推理模块（探索宏观和微观关系线索），将帖子质量评估重构为排序任务，并整合多模态数据。

Result: MFTRR框架在三个新构建的多模态主题-帖子数据集和公共Lazada-Home数据集上进行了评估，实验结果表明MFTRR显著优于最先进的基线方法，在艺术史数据集上NDCG@3的提升高达9.52%。

Conclusion: MFTRR框架在三个新构建的多模态主题-帖子数据集和公共Lazada-Home数据集上进行了评估，实验结果表明MFTRR显著优于最先进的基线方法，在艺术史数据集上NDCG@3的提升高达9.52%。

Abstract: Accurately assessing post quality requires complex relational reasoning to
capture nuanced topic-post relationships. However, existing studies face three
major limitations: (1) treating the task as unimodal categorization, which
fails to leverage multimodal cues and fine-grained quality distinctions; (2)
introducing noise during deep multimodal fusion, leading to misleading signals;
and (3) lacking the ability to capture complex semantic relationships like
relevance and comprehensiveness. To address these issues, we propose the
Multimodal Fine-grained Topic-post Relational Reasoning (MFTRR) framework,
which mimics human cognitive processes. MFTRR reframes post-quality assessment
as a ranking task and incorporates multimodal data to better capture quality
variations. It consists of two key modules: (1) the Local-Global Semantic
Correlation Reasoning Module, which models fine-grained semantic interactions
between posts and topics at both local and global levels, enhanced by a maximum
information fusion mechanism to suppress noise; and (2) the Multi-Level
Evidential Relational Reasoning Module, which explores macro- and micro-level
relational cues to strengthen evidence-based reasoning. We evaluate MFTRR on
three newly constructed multimodal topic-post datasets and the public
Lazada-Home dataset. Experimental results demonstrate that MFTRR significantly
outperforms state-of-the-art baselines, achieving up to 9.52% NDCG@3
improvement over the best unimodal method on the Art History dataset.

</details>


### [305] [Gait Recognition Based on Tiny ML and IMU Sensors](https://arxiv.org/abs/2507.18627)
*Jiahang Zhang,Mingtong Chen,Zhengbao Yang*

Main category: cs.LG

TL;DR: 利用Tiny ML和IMU传感器，在XIAO-nRF52840 Sense微控制器上实现了超过80%准确率的步态识别，可用于低功耗设备。


<details>
  <summary>Details</summary>
Motivation: 本项目的动机是开发一种低功耗、高精度的步态识别系统，利用Tiny ML和IMU传感器技术，实现对行走、静止、上楼、下楼等日常活动进行实时分类和异常检测，以满足电池供电设备或能量收集设备的应用需求。

Method: 本研究提出了一种基于Tiny ML和IMU传感器（LSM6DS3）的步态识别系统。使用XIAO-nRF52840 Sense微控制器采集运动数据（加速度和角速度），并通过Edge Impulse平台进行数据预处理（滑动窗口、数据归一化）和深度神经网络（DNN）分类器训练。最终将训练好的模型部署到微控制器上进行实时活动分类。

Result: 该Tiny ML步态识别系统在测试数据集上实现了超过80%的准确率，能够有效区分四种不同的活动。此外，系统还具备异常检测能力，提高了整体鲁棒性。Tiny ML的应用确保了系统的低功耗特性。

Conclusion: 该系统集成了Tiny ML和IMU传感器，在XIAO-nRF52840 Sense微控制器上实现了高效的步态识别，对四种活动（行走、静止、上楼、下楼）的分类准确率超过80%，并且支持异常检测，实现了低功耗运行，适用于电池供电设备。

Abstract: This project presents the development of a gait recognition system using Tiny
Machine Learning (Tiny ML) and Inertial Measurement Unit (IMU) sensors. The
system leverages the XIAO-nRF52840 Sense microcontroller and the LSM6DS3 IMU
sensor to capture motion data, including acceleration and angular velocity,
from four distinct activities: walking, stationary, going upstairs, and going
downstairs. The data collected is processed through Edge Impulse, an edge AI
platform, which enables the training of machine learning models that can be
deployed directly onto the microcontroller for real-time activity
classification.The data preprocessing step involves extracting relevant
features from the raw sensor data using techniques such as sliding windows and
data normalization, followed by training a Deep Neural Network (DNN) classifier
for activity recognition. The model achieves over 80% accuracy on a test
dataset, demonstrating its ability to classify the four activities effectively.
Additionally, the platform enables anomaly detection, further enhancing the
robustness of the system. The integration of Tiny ML ensures low-power
operation, making it suitable for battery-powered or energy-harvesting devices.

</details>


### [306] [VIBE: Video-Input Brain Encoder for fMRI Response Modeling](https://arxiv.org/abs/2507.17958)
*Daniel Carlstrom Schad,Shrey Dixit,Janis Keck,Viktor Studenyak,Aleksandr Shpilevoi,Andrej Bicanski*

Main category: cs.LG

TL;DR: VIBE是一个两阶段Transformer模型，融合视频、音频和文本特征来预测fMRI活动，并在Algonauts 2025挑战赛中表现优异。


<details>
  <summary>Details</summary>
Motivation: 本文旨在通过融合多模态特征来更准确地预测fMRI活动。

Method: VIBE是一个两阶段的Transformer模型，它融合了视频、音频和文本的多模态特征来预测fMRI活动。该模型利用开源模型（Qwen2.5, BEATs, Whisper, SlowFast, V-JEPA）提取的表示，并通过一个模态融合Transformer进行合并，然后由一个具有旋转嵌入的预测Transformer进行时间解码。

Result: VIBE模型在CNeuroMod数据集（65小时电影数据）上训练，并在Friends S07数据集上实现了32.25的平均parcel-wise皮尔逊相关系数（in-distribution），在六部不同的电影数据集上实现了21.25的平均相关系数（out-of-distribution）。早期版本的模型在相同测试集上分别取得了0.3198和0.2096的成绩，赢得了Algonauts 2025挑战赛的Phase-1，并获得总亚军。

Conclusion: VIBE模型在预测fMRI活动方面表现出色，在Algonauts 2025挑战赛中取得了优异成绩。

Abstract: We present VIBE, a two-stage Transformer that fuses multi-modal video, audio,
and text features to predict fMRI activity. Representations from open-source
models (Qwen2.5, BEATs, Whisper, SlowFast, V-JEPA) are merged by a
modality-fusion transformer and temporally decoded by a prediction transformer
with rotary embeddings. Trained on 65 hours of movie data from the CNeuroMod
dataset and ensembled across 20 seeds, VIBE attains mean parcel-wise Pearson
correlations of 32.25 on in-distribution Friends S07 and 21.25 on six
out-of-distribution films. An earlier iteration of the same architecture
obtained 0.3198 and 0.2096, respectively, winning Phase-1 and placing second
overall in the Algonauts 2025 Challenge.

</details>


### [307] [Improving the Computational Efficiency and Explainability of GeoAggregator](https://arxiv.org/abs/2507.17977)
*Rui Deng,Ziqi Li,Mingshu Wang*

Main category: cs.LG

TL;DR: 该论文改进了GeoAggregator（GA）模型，通过优化效率和增强可解释性，提高了预测准确性和推理速度。


<details>
  <summary>Details</summary>
Motivation: 为了更准确地建模和解释地理空间表格数据（GTD），理解其中的地理现象及其潜在过程。

Method: 1) 优化了数据加载流程和GA模型的前向传播，提高了计算效率；2) 整合了模型集成策略和基于GeoShapley框架的解释功能，增强了模型的可解释性。

Result: 改进后的GA模型在预测准确性和推理速度上均优于原始模型。解释性实验表明，GA能有效捕捉数据中的空间效应。

Conclusion: 该研究通过优化数据加载流程、加速前向传播、引入模型集成策略以及基于GeoShapley框架的解释功能，改进了GeoAggregator（GA）模型。实验结果表明，改进后的GA模型在预测准确性和推理速度上优于原始模型，并且能够有效捕捉数据中的空间效应。

Abstract: Accurate modeling and explaining geospatial tabular data (GTD) are critical
for understanding geospatial phenomena and their underlying processes. Recent
work has proposed a novel transformer-based deep learning model named
GeoAggregator (GA) for this purpose, and has demonstrated that it outperforms
other statistical and machine learning approaches. In this short paper, we
further improve GA by 1) developing an optimized pipeline that accelerates the
dataloading process and streamlines the forward pass of GA to achieve better
computational efficiency; and 2) incorporating a model ensembling strategy and
a post-hoc model explanation function based on the GeoShapley framework to
enhance model explainability. We validate the functionality and efficiency of
the proposed strategies by applying the improved GA model to synthetic
datasets. Experimental results show that our implementation improves the
prediction accuracy and inference speed of GA compared to the original
implementation. Moreover, explanation experiments indicate that GA can
effectively captures the inherent spatial effects in the designed synthetic
dataset. The complete pipeline has been made publicly available for community
use (https://github.com/ruid7181/GA-sklearn).

</details>


### [308] [SIFOTL: A Principled, Statistically-Informed Fidelity-Optimization Method for Tabular Learning](https://arxiv.org/abs/2507.17979)
*Shubham Mohole,Sainyam Galhotra*

Main category: cs.LG

TL;DR: SIFOTL 是一种用于表格学习的统计信息保真度优化方法，它提取隐私合规的摘要统计信息，并使用双 XGBoost 模型和 LLM 来识别数据转换的驱动因素，即使在存在噪声和隐私限制的情况下也能保持高性能。


<details>
  <summary>Details</summary>
Motivation: 识别驱动表格数据集数据转换的因素对于分析和决策支持系统（尤其关注医疗保健的系统）而言是一个重大挑战。隐私规则限制了数据访问，复杂的流程产生的噪声阻碍了分析。

Method: SIFOTL（统计信息保真度优化方法用于表格学习）通过以下方式解决此挑战：(i) 提取符合隐私规定的数据摘要统计信息，(ii) 采用双 XGBoost 模型，在 LLM 的辅助下将干预信号与噪声分离开来，以及 (iii) 通过帕累托加权决策树合并 XGBoost 输出，以识别负责转换的可解释片段。

Result: SIFOTL 在 MEPS 数据集上实现了 0.85 的 F1 分数，显著优于 BigQuery 贡献分析（F1=0.46）和统计检验（F1=0.20）。在 18 个基于 Synthea ABM 生成的 EHR 数据集上，SIFOTL 在没有噪声的情况下保持了 0.86-0.96 的 F1 分数，即使在注入观察性噪声的情况下也能达到 >= 0.75 的分数，而基线平均 F1 分数在相同测试下的范围为 0.19-0.67。

Conclusion: SIFOTL 提供了一个可解释的、注重隐私的工作流程，在经验上对观察性噪声具有鲁棒性。

Abstract: Identifying the factors driving data shifts in tabular datasets is a
significant challenge for analysis and decision support systems, especially
those focusing on healthcare. Privacy rules restrict data access, and noise
from complex processes hinders analysis. To address this challenge, we propose
SIFOTL (Statistically-Informed Fidelity-Optimization Method for Tabular
Learning) that (i) extracts privacy-compliant data summary statistics, (ii)
employs twin XGBoost models to disentangle intervention signals from noise with
assistance from LLMs, and (iii) merges XGBoost outputs via a Pareto-weighted
decision tree to identify interpretable segments responsible for the shift.
Unlike existing analyses which may ignore noise or require full data access for
LLM-based analysis, SIFOTL addresses both challenges using only privacy-safe
summary statistics. Demonstrating its real-world efficacy, for a MEPS panel
dataset mimicking a new Medicare drug subsidy, SIFOTL achieves an F1 score of
0.85, substantially outperforming BigQuery Contribution Analysis (F1=0.46) and
statistical tests (F1=0.20) in identifying the segment receiving the subsidy.
Furthermore, across 18 diverse EHR datasets generated based on Synthea ABM,
SIFOTL sustains F1 scores of 0.86-0.96 without noise and >= 0.75 even with
injected observational noise, whereas baseline average F1 scores range from
0.19-0.67 under the same tests. SIFOTL, therefore, provides an interpretable,
privacy-conscious workflow that is empirically robust to observational noise.

</details>


### [309] [Machine Unlearning of Traffic State Estimation and Prediction](https://arxiv.org/abs/2507.17984)
*Xin Wang,R. Tyrrell Rockafellar,Xuegang,Ban*

Main category: cs.LG

TL;DR: 为了解决数据隐私和可靠性问题，本研究提出了一种名为TSEP-Machine Unlearning的新方法，使交通预测模型能够选择性地遗忘不想要的数据。


<details>
  <summary>Details</summary>
Motivation: 数据驱动的交通状态估计与预测（TSEP）依赖包含敏感信息的数据源，这引发了隐私、网络安全和数据新鲜度等问题，可能侵蚀公众对智能交通系统的信任。此外，“被遗忘权”的法规要求模型能够从其记忆中移除特定数据，而仅仅从后端数据库中删除数据是不够的。

Method: TSEP-Machine Unlearning，一种使模型能够选择性遗忘数据的学习范式。

Result: 提出了一种名为TSEP-Machine Unlearning的新型学习范式，使TSEP模型能够选择性地遗忘数据，以解决数据敏感性、污染和过时问题。

Conclusion: 该研究引入了一种新颖的学习范式TSEP-Machine Unlearning，它能够使训练好的TSEP模型选择性地遗忘隐私敏感、被污染或过时的数据，旨在提高数据驱动的交通状态估计与预测（TSEP）的可信度和可靠性。

Abstract: Data-driven traffic state estimation and prediction (TSEP) relies heavily on
data sources that contain sensitive information. While the abundance of data
has fueled significant breakthroughs, particularly in machine learning-based
methods, it also raises concerns regarding privacy, cybersecurity, and data
freshness. These issues can erode public trust in intelligent transportation
systems. Recently, regulations have introduced the "right to be forgotten",
allowing users to request the removal of their private data from models. As
machine learning models can remember old data, simply removing it from back-end
databases is insufficient in such systems. To address these challenges, this
study introduces a novel learning paradigm for TSEP-Machine Unlearning
TSEP-which enables a trained TSEP model to selectively forget
privacy-sensitive, poisoned, or outdated data. By empowering models to
"unlearn," we aim to enhance the trustworthiness and reliability of data-driven
traffic TSEP.

</details>


### [310] [Predictive Scaling Laws for Efficient GRPO Training of Large Reasoning Models](https://arxiv.org/abs/2507.18014)
*Datta Nimmaturi,Vaishnavi Bhargava,Rajat Ghosh,Johnu George,Debojyoti Dutta*

Main category: cs.LG

TL;DR: 在LLM微调中，通过一个预测框架和经验扩展定律，识别出最佳的训练停止点，以节省计算资源，同时不影响性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决使用GRPO等强化学习方法对LLM进行微调计算成本高昂的问题。

Method: 提出一个预测框架，对LLM的训练动态进行建模，以优化资源使用，并利用实验数据推导出基于模型大小、初始性能和训练进度的经验扩展定律。

Result: 得出了一个经验扩展定律，能够预测奖励轨迹，并识别出三个一致的训练阶段：缓慢启动、快速改进和平台期。研究发现，在某个训练轮数后继续训练的收益很小，提前停止训练可以显著降低计算成本，同时不牺牲性能。该方法可推广到不同类型的模型。

Conclusion: 通过建立经验扩展定律，为GRPO（一种强化学习方法）的微调提供了一个可行的效率指南，在不影响模型性能的情况下，可以显著减少计算量。

Abstract: Fine-tuning large language models (LLMs) for reasoning tasks using
reinforcement learning methods like Group Relative Policy Optimization (GRPO)
is computationally expensive. To address this, we propose a predictive
framework that models training dynamics and helps optimize resource usage.
Through experiments on Llama and Qwen models (3B 8B), we derive an empirical
scaling law based on model size, initial performance, and training progress.
This law predicts reward trajectories and identifies three consistent training
phases: slow start, rapid improvement, and plateau. We find that training
beyond certain number of an epoch offers little gain, suggesting earlier
stopping can significantly reduce compute without sacrificing performance. Our
approach generalizes across model types, providing a practical guide for
efficient GRPO-based fine-tuning.

</details>


### [311] [Multiscale Neural PDE Surrogates for Prediction and Downscaling: Application to Ocean Currents](https://arxiv.org/abs/2507.18067)
*Abdessamad El-Kabid,Loubna Benabbou,Redouane Lguensat,Alex Hernández-García*

Main category: cs.LG

TL;DR: 提出一个基于神经算子的深度学习框架，能以任意分辨率求解偏微分方程，并成功应用于Copernicus海洋流数据降尺度，解决了现有数据分辨率不足的问题。


<details>
  <summary>Details</summary>
Motivation: 为了满足海洋学中对高分辨率近岸流数据的需求，以支持海岸管理、环境监测和海上安全。现有的卫星产品（如Copernicus海面流速数据）和全球海洋模型在空间分辨率上往往不足以支持精细的局部分析。

Method: 本研究提出一个基于神经算子的监督深度学习框架，用于求解偏微分方程。该框架能够提供任意分辨率的解决方案，并可用于建模替代性偏微分方程和预测任意分辨率的解，不受输入分辨率限制。具体应用包括对Copernicus海洋流数据进行降尺度。

Result: 所提出的方法在真实世界的Copernicus海洋流数据和合成Navier-Stokes模拟数据集上进行了评估，证明了其在提供任意分辨率解决方案和进行海洋流数据降尺度方面的有效性。

Conclusion: 该研究提出了一个基于神经算子的监督深度学习框架，用于求解偏微分方程并提供任意分辨率的解，并将其应用于Copernicus海洋流数据降尺度，实现了比现有卫星产品和全球海洋模型更高分辨率的海洋流数据建模。

Abstract: Accurate modeling of physical systems governed by partial differential
equations is a central challenge in scientific computing. In oceanography,
high-resolution current data are critical for coastal management, environmental
monitoring, and maritime safety. However, available satellite products, such as
Copernicus data for sea water velocity at ~0.08 degrees spatial resolution and
global ocean models, often lack the spatial granularity required for detailed
local analyses. In this work, we (a) introduce a supervised deep learning
framework based on neural operators for solving PDEs and providing arbitrary
resolution solutions, and (b) propose downscaling models with an application to
Copernicus ocean current data. Additionally, our method can model surrogate
PDEs and predict solutions at arbitrary resolution, regardless of the input
resolution. We evaluated our model on real-world Copernicus ocean current data
and synthetic Navier-Stokes simulation datasets.

</details>


### [312] [Group Sequence Policy Optimization](https://arxiv.org/abs/2507.18071)
*Chujie Zheng,Shixuan Liu,Mingze Li,Xiong-Hui Chen,Bowen Yu,Chang Gao,Kai Dang,Yuqiong Liu,Rui Men,An Yang,Jingren Zhou,Junyang Lin*

Main category: cs.LG

TL;DR: GSPO是一种新的强化学习算法，通过序列级优化提高了大型语言模型（LLM）的训练效率和性能，特别是在混合专家（MoE）模型中，并有助于Qwen3模型的改进。


<details>
  <summary>Details</summary>
Motivation: 为了开发一种更稳定、更高效、性能更强的强化学习算法，用于训练大型语言模型，特别是为了解决混合专家（MoE）模型训练中的稳定性问题。

Method: GSPO算法通过基于序列似然的序列级重要性比率定义，以及序列级的裁剪、奖励和优化来实现稳定、高效的训练，与之前的基于token级重要性比率的算法不同。

Result: GSPO算法在训练效率和性能上优于GRPO算法，稳定了混合专家（MoE）强化学习的训练，并有潜力简化强化学习基础设施的设计。

Conclusion: GSPO算法在训练大型语言模型方面表现出优越的效率和性能，特别是在混合专家（MoE）模型的强化学习训练中，并简化了强化学习基础设施的设计，为最新的Qwen3模型带来了显著的改进。

Abstract: This paper introduces Group Sequence Policy Optimization (GSPO), our stable,
efficient, and performant reinforcement learning algorithm for training large
language models. Unlike previous algorithms that adopt token-level importance
ratios, GSPO defines the importance ratio based on sequence likelihood and
performs sequence-level clipping, rewarding, and optimization. We demonstrate
that GSPO achieves superior training efficiency and performance compared to the
GRPO algorithm, notably stabilizes Mixture-of-Experts (MoE) RL training, and
has the potential for simplifying the design of RL infrastructure. These merits
of GSPO have contributed to the remarkable improvements in the latest Qwen3
models.

</details>


### [313] [C-AAE: Compressively Anonymizing Autoencoders for Privacy-Preserving Activity Recognition in Healthcare Sensor Streams](https://arxiv.org/abs/2507.18072)
*Ryusei Fujimoto,Yugo Nakamura,Yutaka Arakawa*

Main category: cs.LG

TL;DR: C-AAE 结合 AAE 和 ADPCM 技术，在保护可穿戴设备用户隐私的同时，有效维持了活动识别的准确性，并大幅减小了数据体积。


<details>
  <summary>Details</summary>
Motivation: 由于可穿戴加速度计和陀螺仪能够捕捉细粒度的行为特征，可能被用于重新识别用户，因此在医疗保健应用中保护用户隐私至关重要。

Method: 提出了一种名为 C-AAE 的压缩匿名自编码器，它结合了匿名自编码器 (AAE) 和自适应差分脉冲编码调制 (ADPCM)。AAE 将原始传感器数据投影到潜在空间，保留活动相关特征并消除身份线索。ADPCM 对潜在数据流进行差分编码，以进一步隐藏残余身份信息并降低比特率。

Result: 实验表明，与单独使用 AAE 相比，C-AAE 将用户重新识别的 F1 分数降低了 10-15 个百分点，同时将活动识别的 F1 分数保持在未受保护基线的 5 个百分点以内。此外，ADPCM 将数据量减少了约 75%，从而降低了传输和存储开销。

Conclusion: C-AAE 通过将 AAE 与 ADPCM 相结合，在保护用户隐私和保持活动识别效用之间取得了实际的平衡，这对于医疗保健领域的持续传感器活动识别尤其重要。

Abstract: Wearable accelerometers and gyroscopes encode fine-grained behavioural
signatures that can be exploited to re-identify users, making privacy
protection essential for healthcare applications. We introduce C-AAE, a
compressive anonymizing autoencoder that marries an Anonymizing AutoEncoder
(AAE) with Adaptive Differential Pulse-Code Modulation (ADPCM). The AAE first
projects raw sensor windows into a latent space that retains activity-relevant
features while suppressing identity cues. ADPCM then differentially encodes
this latent stream, further masking residual identity information and shrinking
the bitrate. Experiments on the MotionSense and PAMAP2 datasets show that C-AAE
cuts user re-identification F1 scores by 10-15 percentage points relative to
AAE alone, while keeping activity-recognition F1 within 5 percentage points of
the unprotected baseline. ADPCM also reduces data volume by roughly 75 %,
easing transmission and storage overheads. These results demonstrate that C-AAE
offers a practical route to balancing privacy and utility in continuous,
sensor-based activity recognition for healthcare.

</details>


### [314] [Squeeze10-LLM: Squeezing LLMs' Weights by 10 Times via a Staged Mixed-Precision Quantization Method](https://arxiv.org/abs/2507.18073)
*Qingcheng Zhu,Yangyang Ren,Linlin Yang,Mingbao Lin,Yanjing Li,Sheng Xu,Zichao Feng,Haodong Zhu,Yuguang Yang,Juan Zhang,Runqi Wang,Baochang Zhang*

Main category: cs.LG

TL;DR: Squeeze10-LLM 通过创新的 PBAR 和 FIAS 技术，将 LLM 的权重量化到平均 1.6 位，显著提高了在低比特量化下的准确率，解决了极端压缩导致的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 部署大型语言模型 (LLM) 因其巨大的参数量和高昂的计算成本而面临挑战。超低比特量化可以显著减小存储并加速推理，但极端压缩（即平均比特宽度小于等于 2）常常导致严重的性能下降。

Method: Squeeze10-LLM 是一个分阶段的混合精度训练后量化 (PTQ) 框架，通过将 80% 的权重量化到 1 位和 20% 的权重量化到 4 位，实现了平均每权重 1.6 位。该框架包含两个关键创新：后二值化激活鲁棒性 (PBAR) 和全信息激活监督 (FIAS)。PBAR 是一种改进的权重显著性度量，考虑了量化对激活的影响；FIAS 是一种在量化过程中保留完整激活信息以减轻跨层累积误差传播的策略。

Result: Squeeze10-LLM 实现了平均每权重 1.6 位，将六个零样本分类任务的平均准确率从 43% 提高到 56%，显著优于现有的 PTQ 方法。

Conclusion: Squeeze10-LLM 在 LLaMA 和 LLaMA2 模型上实现了最先进的亚 2 位权重量化性能，将六个零样本分类任务的平均准确率从 43% 提高到 56%，显著优于现有的 PTQ 方法。

Abstract: Deploying large language models (LLMs) is challenging due to their massive
parameters and high computational costs. Ultra low-bit quantization can
significantly reduce storage and accelerate inference, but extreme compression
(i.e., mean bit-width <= 2) often leads to severe performance degradation. To
address this, we propose Squeeze10-LLM, effectively "squeezing" 16-bit LLMs'
weights by 10 times. Specifically, Squeeze10-LLM is a staged mixed-precision
post-training quantization (PTQ) framework and achieves an average of 1.6 bits
per weight by quantizing 80% of the weights to 1 bit and 20% to 4 bits. We
introduce Squeeze10LLM with two key innovations: Post-Binarization Activation
Robustness (PBAR) and Full Information Activation Supervision (FIAS). PBAR is a
refined weight significance metric that accounts for the impact of quantization
on activations, improving accuracy in low-bit settings. FIAS is a strategy that
preserves full activation information during quantization to mitigate
cumulative error propagation across layers. Experiments on LLaMA and LLaMA2
show that Squeeze10-LLM achieves state-of-the-art performance for sub-2bit
weight-only quantization, improving average accuracy from 43% to 56% on six
zero-shot classification tasks--a significant boost over existing PTQ methods.
Our code will be released upon publication.

</details>


### [315] [Learning from Hard Labels with Additional Supervision on Non-Hard-Labeled Classes](https://arxiv.org/abs/2507.18098)
*Kosuke Sugiyama,Masato Uchida*

Main category: cs.LG

TL;DR: 通过将硬标签和附加监督视为概率分布并结合，研究了附加监督对分类模型性能的提升作用，并提出了理论框架和实验验证。


<details>
  <summary>Details</summary>
Motivation: 在训练数据有限的情况下，丰富标签信息对于构建高精度分类模型至关重要。研究附加监督（如硬标签的置信度）的益处及其对泛化性能的贡献。

Method: 提出一个理论框架，将硬标签和附加监督视为概率分布，通过仿射组合构建软标签，并进行泛化误差分析。

Result: 附加监督的关键在于其在非硬标签类别上的分布信息，而非硬标签的置信度。附加监督和混合系数在软标签精炼中起互补作用。理论上刻画了附加监督及其混合系数对收敛速率和误差上界的影响。实验证明，基于该理论设计的附加监督能提升分类准确性。

Conclusion: 本研究提出了一个理论框架，将硬标签和附加监督视为概率分布，并通过仿射组合构建软标签。理论分析表明，附加监督的关键在于其在非硬标签类别上的分布信息，而非硬标签的置信度。附加监督和混合系数在软标签的精炼中起互补作用，分别决定调整方向和步长。通过泛化误差分析，我们理论上刻画了附加监督及其混合系数对收敛速率和误差上界的渐近值的影响。实验证明，基于该理论设计的附加监督能够提升分类准确性。

Abstract: In scenarios where training data is limited due to observation costs or data
scarcity, enriching the label information associated with each instance becomes
crucial for building high-accuracy classification models. In such contexts, it
is often feasible to obtain not only hard labels but also {\it additional
supervision}, such as the confidences for the hard labels. This setting
naturally raises fundamental questions: {\it What kinds of additional
supervision are intrinsically beneficial?} And {\it how do they contribute to
improved generalization performance?} To address these questions, we propose a
theoretical framework that treats both hard labels and additional supervision
as probability distributions, and constructs soft labels through their affine
combination. Our theoretical analysis reveals that the essential component of
additional supervision is not the confidence score of the assigned hard label,
but rather the information of the distribution over the non-hard-labeled
classes. Moreover, we demonstrate that the additional supervision and the
mixing coefficient contribute to the refinement of soft labels in complementary
roles. Intuitively, in the probability simplex, the additional supervision
determines the direction in which the deterministic distribution representing
the hard label should be adjusted toward the true label distribution, while the
mixing coefficient controls the step size along that direction. Through
generalization error analysis, we theoretically characterize how the additional
supervision and its mixing coefficient affect both the convergence rate and
asymptotic value of the error bound. Finally, we experimentally demonstrate
that, based on our theory, designing additional supervision can lead to
improved classification accuracy, even when utilized in a simple manner.

</details>


### [316] [Percentile-Based Deep Reinforcement Learning and Reward Based Personalization For Delay Aware RAN Slicing in O-RAN](https://arxiv.org/abs/2507.18111)
*Peyman Tehrani,Anas Alsoliman*

Main category: cs.LG

TL;DR: O-RAN 网络中，PDA-DRL 算法通过深度强化学习和模型权重共享，在满足延迟约束的同时优化了 PRB 利用率和个性化。


<details>
  <summary>Details</summary>
Motivation: 在 O-RAN 架构下，解决了多 MVNO 竞争 PRB 资源以满足客户延迟约束并最小化 PRB 利用率的挑战。

Method: 提出了一种基于 LLN 的奖励函数，并进行了实际修改，实现了 PDA-DRL 算法。同时，引入了基于奖励的个性化方法，实现了模型权重共享。

Result: PDA-DRL 相比于优化平均延迟的 DRL 模型，平均延迟降低了 38%。基于奖励的个性化方法优于传统的聚合方法。

Conclusion: PDA-DRL 在满足概率延迟约束的同时，通过模型权重共享实现了更优的资源利用率和个性化。

Abstract: In this paper, we tackle the challenge of radio access network (RAN) slicing
within an open RAN (O-RAN) architecture. Our focus centers on a network that
includes multiple mobile virtual network operators (MVNOs) competing for
physical resource blocks (PRBs) with the goal of meeting probabilistic delay
upper bound constraints for their clients while minimizing PRB utilization.
Initially, we derive a reward function based on the law of large numbers (LLN),
then implement practical modifications to adapt it for real-world experimental
scenarios. We then propose our solution, the Percentile-based Delay-Aware Deep
Reinforcement Learning (PDA-DRL), which demonstrates its superiority over
several baselines, including DRL models optimized for average delay
constraints, by achieving a 38\% reduction in resultant average delay.
Furthermore, we delve into the issue of model weight sharing among multiple
MVNOs to develop a robust personalized model. We introduce a reward-based
personalization method where each agent prioritizes other agents' model weights
based on their performance. This technique surpasses traditional aggregation
methods, such as federated averaging, and strategies reliant on traffic
patterns and model weight distance similarities.

</details>


### [317] [Policy Disruption in Reinforcement Learning:Adversarial Attack with Large Language Models and Critical State Identification](https://arxiv.org/abs/2507.18113)
*Junyong Jiang,Buwei Tian,Chenxing Xu,Songze Li,Lu Dong*

Main category: cs.LG

TL;DR: 提出一种利用LLM生成对抗性奖励并结合关键状态识别算法的RL对抗性攻击方法，无需修改环境，即可有效引导目标代理做出次优决策。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法依赖于修改环境或策略的局限性，提出一种在不改变环境的情况下，利用环境中现有代理引导目标策略输出次优动作的对抗性攻击方法。

Method: 提出了一种奖励迭代优化框架，利用大型语言模型（LLM）生成显式定制以利用目标代理漏洞的对抗性奖励，并设计了一种关键状态识别算法来精确找出目标代理最脆弱的状态。

Result: 通过在不同环境中进行实验，证明了该方法在诱导目标代理做出次优决策方面的有效性。

Conclusion: 该方法在各种环境中优于现有方法。

Abstract: Reinforcement learning (RL) has achieved remarkable success in fields like
robotics and autonomous driving, but adversarial attacks designed to mislead RL
systems remain challenging. Existing approaches often rely on modifying the
environment or policy, limiting their practicality. This paper proposes an
adversarial attack method in which existing agents in the environment guide the
target policy to output suboptimal actions without altering the environment. We
propose a reward iteration optimization framework that leverages large language
models (LLMs) to generate adversarial rewards explicitly tailored to the
vulnerabilities of the target agent, thereby enhancing the effectiveness of
inducing the target agent toward suboptimal decision-making. Additionally, a
critical state identification algorithm is designed to pinpoint the target
agent's most vulnerable states, where suboptimal behavior from the victim leads
to significant degradation in overall performance. Experimental results in
diverse environments demonstrate the superiority of our method over existing
approaches.

</details>


### [318] [Maximizing Prefix-Confidence at Test-Time Efficiently Improves Mathematical Reasoning](https://arxiv.org/abs/2507.18122)
*Matthias Otth,Jonas Hübotter,Ido Hakimi,Andreas Krause*

Main category: cs.LG

TL;DR: 语言模型在数学推理任务中，通过选择自身置信度最高的前缀尝试，可以提高准确率和计算效率，并且不易受长度偏差影响。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明语言模型无需外部验证器或奖励信号即可通过最大化自身预测置信度来进行自我改进。本研究旨在探索语言模型在数学推理任务中的测试时缩放，特别是利用模型自身置信度来选择最有希望的尝试。

Method: 研究了语言模型在数学推理任务中的测试时缩放，利用模型自身置信度来选择最有希望的尝试。具体来说，研究了前缀置信度缩放，并通过比较准确率-计算量权衡和对长度偏差的敏感性来评估其效果。同时，也评估了结合前缀置信度的测试时训练。

Result: 前缀置信度缩放（仅使用32个标记的前缀）在准确率-计算量权衡方面优于投票多数法，并且不易受长度偏差影响。结合前缀置信度的测试时训练虽然优于基础模型，但效果不如单独的前缀置信度缩放。

Conclusion: 研究发现，在数学推理任务中，仅继续选择模型自身前缀置信度最高的尝试，可以在准确率-计算量权衡方面优于投票多数法，并且对长度偏差的敏感性低于BoN。在测试时训练结合前缀置信度虽然优于基础模型，但并未超过单独的前缀置信度缩放。

Abstract: Recent work has shown that language models can self-improve by maximizing
their own confidence in their predictions, without relying on external
verifiers or reward signals. In this work, we study the test-time scaling of
language models for mathematical reasoning tasks, where the model's own
confidence is used to select the most promising attempts. Surprisingly, we find
that we can achieve significant performance gains by continuing only the most
promising attempt, selected by the model's prefix-confidence. We systematically
evaluate prefix-confidence scaling on five mathematical reasoning datasets: the
school-level GSM8K and MATH500, and the competition-level AMC23, AIME24, and
AIME25. We find that prefix-confidence scaling with prefixes of only 32 tokens
achieves a better accuracy-compute trade-off than majority voting. Moreover,
prefix-confidence scaling appears less susceptible than BoN to length biases.
Finally, we also evaluate test-time training with prefix-confidence and find
that, while outperforming the base model, it does not improve over
prefix-confidence scaling.

</details>


### [319] [Neuromorphic Computing for Embodied Intelligence in Autonomous Systems: Current Trends, Challenges, and Future Directions](https://arxiv.org/abs/2507.18139)
*Alberto Marchisio,Muhammad Shafique*

Main category: cs.LG

TL;DR: 该文件调查了神经拟态计算在提高自主系统（如机器人和无人驾驶飞行器）的能效、鲁棒性和适应性方面的进展，重点介绍了事件驱动的传感和脉冲神经网络，并讨论了实时决策和持续学习的挑战。


<details>
  <summary>Details</summary>
Motivation: 对跨机器人、移动代理（例如，无人机）和自动驾驶汽车等领域的智能、自适应和节能自主系统的日益增长的需求，正推动着对神经拟态计算的兴趣。通过从生物神经系统中汲取灵感，神经拟态方法为增强自主平台的感知、决策和响应能力提供了有希望的途径。

Method: 对神经拟态算法、专用硬件和跨层优化策略进行了调查，重点关注其在现实世界自主场景中的部署。整合了来自机器学习、机器人、神经科学和神经拟态工程的观点。

Result: 重点关注了事件驱动的动态视觉传感器及其在实现快速、高效感知方面的作用。强调了通过将脉冲神经网络整合到自主系统架构中来提高能效、鲁棒性、适应性和可靠性的新方法。

Conclusion: 该文件对神经拟态算法、专用硬件和跨层优化策略的最新进展进行了调查，重点关注其在现实世界自主场景中的部署。它强调了通过将脉冲神经网络整合到自主系统架构中来提高能效、鲁棒性、适应性和可靠性的新方法。最后，探讨了新兴趋势和开放式挑战，特别是在实时决策、持续学习以及开发安全、有弹性的自主系统方面。

Abstract: The growing need for intelligent, adaptive, and energy-efficient autonomous
systems across fields such as robotics, mobile agents (e.g., UAVs), and
self-driving vehicles is driving interest in neuromorphic computing. By drawing
inspiration from biological neural systems, neuromorphic approaches offer
promising pathways to enhance the perception, decision-making, and
responsiveness of autonomous platforms. This paper surveys recent progress in
neuromorphic algorithms, specialized hardware, and cross-layer optimization
strategies, with a focus on their deployment in real-world autonomous
scenarios. Special attention is given to event-based dynamic vision sensors and
their role in enabling fast, efficient perception. The discussion highlights
new methods that improve energy efficiency, robustness, adaptability, and
reliability through the integration of spiking neural networks into autonomous
system architectures. We integrate perspectives from machine learning,
robotics, neuroscience, and neuromorphic engineering to offer a comprehensive
view of the state of the field. Finally, emerging trends and open challenges
are explored, particularly in the areas of real-time decision-making, continual
learning, and the development of secure, resilient autonomous systems.

</details>


### [320] [When Noisy Labels Meet Class Imbalance on Graphs: A Graph Augmentation Method with LLM and Pseudo Label](https://arxiv.org/abs/2507.18153)
*Riting Xia,Rucong Wang,Yulin Liu,Anchen Li,Xueyan Liu,Yan Zhang*

Main category: cs.LG

TL;DR: 针对类别不平衡且标签含噪声的图节点分类问题，提出了一种名为GraphALP的新框架，利用大语言模型和伪标签技术生成合成数据、降低噪声，有效提升了分类性能。


<details>
  <summary>Details</summary>
Motivation: 解决类别不平衡图节点分类中的一个实际但研究不足的问题，即真实世界的图标签通常包含噪声，而现有研究通常假设标签是干净的。

Method: 提出了一种名为GraphALP的新颖框架，该框架基于大语言模型（LLMs）和伪标签技术。具体来说，设计了一种基于LLM的过采样方法来生成合成的少数类节点，以缓解类别不平衡问题。在类别均衡图的基础上，开发了一种动态加权伪标签方法来获得高置信度的伪标签，以降低标签噪声。此外，还实现了一种二次LLM引导的过采样机制，以减轻伪标签可能引入的类别分布偏差。

Result: 实验结果表明，GraphALP在类别不平衡且带噪声标签的图上取得了优于现有最先进方法的性能。

Conclusion: GraphALP在类别不平衡且带噪声标签的图上取得了优于现有方法的性能。

Abstract: Class-imbalanced graph node classification is a practical yet underexplored
research problem. Although recent studies have attempted to address this issue,
they typically assume clean and reliable labels when processing
class-imbalanced graphs. This assumption often violates the nature of
real-world graphs, where labels frequently contain noise. Given this gap, this
paper systematically investigates robust node classification for
class-imbalanced graphs with noisy labels. We propose GraphALP, a novel Graph
Augmentation framework based on Large language models (LLMs) and
Pseudo-labeling techniques. Specifically, we design an LLM-based oversampling
method to generate synthetic minority nodes, producing label-accurate minority
nodes to alleviate class imbalance. Based on the class-balanced graphs, we
develop a dynamically weighted pseudo-labeling method to obtain high-confidence
pseudo labels to reduce label noise ratio. Additionally, we implement a
secondary LLM-guided oversampling mechanism to mitigate potential class
distribution skew caused by pseudo labels. Experimental results show that
GraphALP achieves superior performance over state-of-the-art methods on
class-imbalanced graphs with noisy labels.

</details>


### [321] [ChronoSelect: Robust Learning with Noisy Labels via Dynamics Temporal Memory](https://arxiv.org/abs/2507.18183)
*Jianchao Wang,Qingfeng Li,Pengcheng Zheng,Xiaorong Pu,Yazhou Ren*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Training deep neural networks on real-world datasets is often hampered by the
presence of noisy labels, which can be memorized by over-parameterized models,
leading to significant degradation in generalization performance. While
existing methods for learning with noisy labels (LNL) have made considerable
progress, they fundamentally suffer from static snapshot evaluations and fail
to leverage the rich temporal dynamics of learning evolution. In this paper, we
propose ChronoSelect (chrono denoting its temporal nature), a novel framework
featuring an innovative four-stage memory architecture that compresses
prediction history into compact temporal distributions. Our unique sliding
update mechanism with controlled decay maintains only four dynamic memory units
per sample, progressively emphasizing recent patterns while retaining essential
historical knowledge. This enables precise three-way sample partitioning into
clean, boundary, and noisy subsets through temporal trajectory analysis and
dual-branch consistency. Theoretical guarantees prove the mechanism's
convergence and stability under noisy conditions. Extensive experiments
demonstrate ChronoSelect's state-of-the-art performance across synthetic and
real-world benchmarks.

</details>


### [322] [Goal-based Trajectory Prediction for improved Cross-Dataset Generalization](https://arxiv.org/abs/2507.18196)
*Daniel Grimm,Ahmed Abouelazm,J. Marius Zöllner*

Main category: cs.LG

TL;DR: 在自动驾驶中，预测其他交通参与者的未来状态至关重要，但现有模型在未见过的数据上表现不佳。本研究提出了一种新的图神经网络，通过结合道路网络信息和多阶段目标分类，提高了模型的泛化能力，并在跨数据集评估中得到了验证。


<details>
  <summary>Details</summary>
Motivation: 为了实现完全自动驾驶，需要充分理解周围环境，特别是预测其他交通参与者的未来状态。现有模型在部署到新的/未见过的区域时性能会显著下降，表明模型缺乏泛化能力。

Method: 提出了一种新的图神经网络（GNN），它结合了交通参与者和矢量化道路网络，并通过多阶段方法对目标进行分类，以提高泛化能力。

Result: 通过跨数据集评估（在Argoverse2上训练，在NuScenes上评估）证明了所提出方法的有效性。

Conclusion: 该研究引入了一种新的图神经网络（GNN），该网络利用了由交通参与者和矢量化道路网络组成的异构图，并通过多阶段方法对目标（即预测轨迹的终点）进行分类，从而实现了对未见场景的更好泛化。

Abstract: To achieve full autonomous driving, a good understanding of the surrounding
environment is necessary. Especially predicting the future states of other
traffic participants imposes a non-trivial challenge. Current SotA-models
already show promising results when trained on real datasets (e.g. Argoverse2,
NuScenes). Problems arise when these models are deployed to new/unseen areas.
Typically, performance drops significantly, indicating that the models lack
generalization. In this work, we introduce a new Graph Neural Network (GNN)
that utilizes a heterogeneous graph consisting of traffic participants and
vectorized road network. Latter, is used to classify goals, i.e. endpoints of
the predicted trajectories, in a multi-staged approach, leading to a better
generalization to unseen scenarios. We show the effectiveness of the goal
selection process via cross-dataset evaluation, i.e. training on Argoverse2 and
evaluating on NuScenes.

</details>


### [323] [FedSA-GCL: A Semi-Asynchronous Federated Graph Learning Framework with Personalized Aggregation and Cluster-Aware Broadcasting](https://arxiv.org/abs/2507.18219)
*Zhongzheng Yuan,Lianshuai Guo,Xunkai Li,Yinlin Zhu,Wenyu Wang,Meixia Qu*

Main category: cs.LG

TL;DR: FedSA-GCL通过半异步框架和ClusterCast机制，解决了联邦图学习中的效率和拓扑特性问题，并在实验中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦图学习（FGL）方法多依赖于同步通信，导致效率低下且在实际应用中不切实际。同时，现有的异步联邦学习（AFL）方法主要针对图像分类和自然语言处理等任务，未能考虑图数据的独特拓扑属性，直接应用于图学习可能导致语义漂移和表示不一致。

Method: 提出了一种名为FedSA-GCL的半异步联邦框架，并引入了ClusterCast机制来解决现有联邦图学习（FGL）方法在同步通信方面存在的效率低下和不切实际的问题，以及现有异步联邦学习（AFL）方法在处理图数据拓扑特性时可能导致的语义漂移和表示不一致问题。

Result: FedSA-GCL在多个真实世界图数据集上进行了评估，并与9种基线方法进行了比较。实验结果表明，FedSA-GCL在Louvain和Metis划分算法下，相比基线方法平均分别提高了2.92%和3.4%，证明了其出色的鲁棒性和效率。

Conclusion: FedSA-GCL是一个半异步联邦框架，通过新颖的ClusterCast机制，利用客户间标签分布差异和图拓扑特征进行高效训练。实验证明，与9种基线方法相比，FedSA-GCL在Louvain和Metis数据集上分别取得了2.92%和3.4%的平均性能提升，表现出优越的鲁棒性和效率。

Abstract: Federated Graph Learning (FGL) is a distributed learning paradigm that
enables collaborative training over large-scale subgraphs located on multiple
local systems. However, most existing FGL approaches rely on synchronous
communication, which leads to inefficiencies and is often impractical in
real-world deployments. Meanwhile, current asynchronous federated learning
(AFL) methods are primarily designed for conventional tasks such as image
classification and natural language processing, without accounting for the
unique topological properties of graph data. Directly applying these methods to
graph learning can possibly result in semantic drift and representational
inconsistency in the global model. To address these challenges, we propose
FedSA-GCL, a semi-asynchronous federated framework that leverages both
inter-client label distribution divergence and graph topological
characteristics through a novel ClusterCast mechanism for efficient training.
We evaluate FedSA-GCL on multiple real-world graph datasets using the Louvain
and Metis split algorithms, and compare it against 9 baselines. Extensive
experiments demonstrate that our method achieves strong robustness and
outstanding efficiency, outperforming the baselines by an average of 2.92% with
the Louvain and by 3.4% with the Metis.

</details>


### [324] [Sparse identification of nonlinear dynamics with library optimization mechanism: Recursive long-term prediction perspective](https://arxiv.org/abs/2507.18220)
*Ansei Yonezawa,Heisei Yonezawa,Shuichi Yahagi,Itsuro Kajiwara,Shinya Kijimoto,Hikaru Taniuchi,Kentaro Murakami*

Main category: cs.LG

TL;DR: SINDy-LOM通过优化基函数库来发现动力学方程，提高了长期预测精度和模型可靠性，简化了用户操作。


<details>
  <summary>Details</summary>
Motivation: 传统SINDy方法在设计候选基函数库方面存在挑战，需要设计合适的库，这对于许多动力系统来说并非易事。

Method: 提出了一种结合稀疏回归和新颖库学习策略的SINDy-LOM方法。该方法采用两层优化架构：内层从候选基函数中提取数据驱动模型，外层从递归长期（RLT）预测精度角度优化基函数，将库设计重新表述为参数化基函数的优化。

Result: SINDy-LOM模型具有良好的可解释性和可用性，能够生成简约模型。库优化机制显著减轻了用户负担，RLT视角提高了模型可靠性。通过应用于柴油机气路系统，验证了该方法的有效性。

Conclusion: SINDy-LOM通过优化基函数库，在保证模型可解释性和可用性的同时，提高了模型的长期预测精度和可靠性，降低了用户设计库的负担。

Abstract: The sparse identification of nonlinear dynamics (SINDy) approach can discover
the governing equations of dynamical systems based on measurement data, where
the dynamical model is identified as the sparse linear combination of the given
basis functions. A major challenge in SINDy is the design of a library, which
is a set of candidate basis functions, as the appropriate library is not
trivial for many dynamical systems. To overcome this difficulty, this study
proposes SINDy with library optimization mechanism (SINDy-LOM), which is a
combination of the sparse regression technique and the novel learning strategy
of the library. In the proposed approach, the basis functions are parametrized.
The SINDy-LOM approach involves a two-layer optimization architecture: the
inner-layer, in which the data-driven model is extracted as the sparse linear
combination of the candidate basis functions, and the outer-layer, in which the
basis functions are optimized from the viewpoint of the recursive long-term
(RLT) prediction accuracy; thus, the library design is reformulated as the
optimization of the parametrized basis functions. The resulting SINDy-LOM model
has good interpretability and usability, as the proposed approach yields the
parsimonious model. The library optimization mechanism significantly reduces
user burden. The RLT perspective improves the reliability of the resulting
model compared with the traditional SINDy approach that can only ensure the
one-step-ahead prediction accuracy. The validity of the proposed approach is
demonstrated by applying it to a diesel engine airpath system, which is a
well-known complex industrial system.

</details>


### [325] [Boosting Revisited: Benchmarking and Advancing LP-Based Ensemble Methods](https://arxiv.org/abs/2507.18242)
*Fabian Akkerman,Julien Ferry,Christian Artigues,Emmanuel Hebrard,Thibaut Vidal*

Main category: cs.LG

TL;DR: 本文研究了基于LP的梯度提升方法，发现它们在浅层树方面表现优于或等于XGBoost和LightGBM，并且可以用于优化现有模型。


<details>
  <summary>Details</summary>
Motivation: 尽管理论上具有吸引力，但基于线性规划的完全正确梯度提升方法受到的经验关注有限。

Method: 本文对六种基于LP的梯度提升（包括NM-Boost和QRLP-Boost）进行了大规模的实验研究，并在20个不同的数据集上评估了启发式和最优基学习器的使用。分析了准确性、集成稀疏性、间隔分布、任何时候的性能和超参数敏感性。

Result: 研究表明，完全正确方法在浅层树方面可以超越或匹配XGBoost和LightGBM等最先进的启发式方法，同时产生更稀疏的集成。这些方法可以在不牺牲性能的情况下优化预训练的集成。

Conclusion: 完全正确梯度提升方法在浅层树方面可以超越或匹配XGBoost和LightGBM等最先进的启发式方法，同时产生更稀疏的集成。这些方法可以在不牺牲性能的情况下优化预训练的集成，并且可以突出显示最优决策树在此背景下的优势和局限性。

Abstract: Despite their theoretical appeal, totally corrective boosting methods based
on linear programming have received limited empirical attention. In this paper,
we conduct the first large-scale experimental study of six LP-based boosting
formulations, including two novel methods, NM-Boost and QRLP-Boost, across 20
diverse datasets. We evaluate the use of both heuristic and optimal base
learners within these formulations, and analyze not only accuracy, but also
ensemble sparsity, margin distribution, anytime performance, and hyperparameter
sensitivity. We show that totally corrective methods can outperform or match
state-of-the-art heuristics like XGBoost and LightGBM when using shallow trees,
while producing significantly sparser ensembles. We further show that these
methods can thin pre-trained ensembles without sacrificing performance, and we
highlight both the strengths and limitations of using optimal decision trees in
this context.

</details>


### [326] [Leveraging Data Augmentation and Siamese Learning for Predictive Process Monitoring](https://arxiv.org/abs/2507.18293)
*Sjoerd van Straten,Alessandro Padella,Marwan Hassani*

Main category: cs.LG

TL;DR: SiamSA-PPM is a new self-supervised learning framework that uses Siamese learning and Statistical Augmentation to address the limitations of low variability and small data in Predictive Process Monitoring. It generates realistic trace variants to learn representations without labeled supervision, showing strong performance in prediction tasks and improving data variability.


<details>
  <summary>Details</summary>
Motivation: Deep learning PPM approaches are often limited by the low variability and small size of real-world event logs.

Method: SiamSA-PPM is a novel self-supervised learning framework that combines Siamese learning with Statistical Augmentation. It employs three novel statistically grounded transformation methods that leverage control-flow semantics and frequent behavioral patterns to generate realistic, semantically valid new trace variants. These augmented views are used within a Siamese learning setup to learn generalizable representations of process prefixes without the need for labeled supervision.

Result: Extensive experiments on real-life event logs demonstrate that SiamSA-PPM achieves competitive or superior performance compared to the SOTA in both next activity and final outcome prediction tasks. Statistical augmentation significantly outperforms random transformations and improves variability in the data.

Conclusion: SiamSA-PPM is a promising direction for training data enrichment in process prediction, achieving competitive or superior performance compared to the SOTA in both next activity and final outcome prediction tasks.

Abstract: Predictive Process Monitoring (PPM) enables forecasting future events or
outcomes of ongoing business process instances based on event logs. However,
deep learning PPM approaches are often limited by the low variability and small
size of real-world event logs. To address this, we introduce SiamSA-PPM, a
novel self-supervised learning framework that combines Siamese learning with
Statistical Augmentation for Predictive Process Monitoring. It employs three
novel statistically grounded transformation methods that leverage control-flow
semantics and frequent behavioral patterns to generate realistic, semantically
valid new trace variants. These augmented views are used within a Siamese
learning setup to learn generalizable representations of process prefixes
without the need for labeled supervision. Extensive experiments on real-life
event logs demonstrate that SiamSA-PPM achieves competitive or superior
performance compared to the SOTA in both next activity and final outcome
prediction tasks. Our results further show that statistical augmentation
significantly outperforms random transformations and improves variability in
the data, highlighting SiamSA-PPM as a promising direction for training data
enrichment in process prediction.

</details>


### [327] [Self-Supervised Coarsening of Unstructured Grid with Automatic Differentiation](https://arxiv.org/abs/2507.18297)
*Sergei Shumilin,Alexander Ryabov,Nikolay Yavich,Evgeny Burnaev,Vladimir Vanovskiy*

Main category: cs.LG

TL;DR: 提出了一种基于可微分物理学的非结构化网格细化算法，可将网格点数量减少10倍，同时保持关键区域的精度。


<details>
  <summary>Details</summary>
Motivation: 为了应对现代数值模拟的高计算负荷，需要一种能在保持合理精度的同时减小离散问题规模的方法。

Method: 本工作提出了一种基于可微分物理学概念的非结构化网格细化算法，采用了k-means聚类、自动微分和随机最小化算法。

Result: 在所考虑的场景中，将网格点数量减少了10倍，同时保留了关注点处模拟变量的动态。

Conclusion: 该算法可以应用于任意由演化偏微分方程描述的系统的模拟。

Abstract: Due to the high computational load of modern numerical simulation, there is a
demand for approaches that would reduce the size of discrete problems while
keeping the accuracy reasonable. In this work, we present an original algorithm
to coarsen an unstructured grid based on the concepts of differentiable
physics. We achieve this by employing k-means clustering, autodifferentiation
and stochastic minimization algorithms. We demonstrate performance of the
designed algorithm on two PDEs: a linear parabolic equation which governs
slightly compressible fluid flow in porous media and the wave equation. Our
results show that in the considered scenarios, we reduced the number of grid
points up to 10 times while preserving the modeled variable dynamics in the
points of interest. The proposed approach can be applied to the simulation of
an arbitrary system described by evolutionary partial differential equations.

</details>


### [328] [Regression-aware Continual Learning for Android Malware Detection](https://arxiv.org/abs/2507.18313)
*Daniele Ghiani,Daniele Angioni,Giorgio Piras,Angelo Sotgiu,Luca Minnei,Srishti Gupta,Maura Pintor,Fabio Roli,Battista Biggio*

Main category: cs.LG

TL;DR: 针对持续学习恶意软件检测中的“安全回归”问题，提出了一种回归感知方法，通过改进的PCT有效减少了回归，同时保持了检测性能。


<details>
  <summary>Details</summary>
Motivation: 在反病毒领域，随着恶意软件的快速进化，基于机器学习的检测器需要不断更新。然而，全量数据重新训练不切实际。持续学习（CL）作为一种可行的替代方案，可以在不访问全部数据的情况下进行增量更新，并能缓解灾难性遗忘。但一个关键但被忽视的问题是“安全回归”，即曾经被正确检测的恶意软件样本在模型更新后逃避了检测，这可能导致用户对更新过程失去信任。

Method: 通过自适应正向训练（PCT）到持续学习（CL）设置，以模型无关的方式保留先前的预测行为，并提出了一种减少安全回归的感知惩罚。

Result: 在ELSA、Tesseract和AZ-Class数据集上进行的实验证明了该方法在减少回归和保持检测性能方面的有效性。

Conclusion: 该方法有效减少了不同持续学习场景下的回归问题，同时保持了模型检测性能的长期稳定

Abstract: Malware evolves rapidly, forcing machine learning (ML)-based detectors to
adapt continuously. With antivirus vendors processing hundreds of thousands of
new samples daily, datasets can grow to billions of examples, making full
retraining impractical. Continual learning (CL) has emerged as a scalable
alternative, enabling incremental updates without full data access while
mitigating catastrophic forgetting. In this work, we analyze a critical yet
overlooked issue in this context: security regression. Unlike forgetting, which
manifests as a general performance drop on previously seen data, security
regression captures harmful prediction changes at the sample level, such as a
malware sample that was once correctly detected but evades detection after a
model update. Although often overlooked, regressions pose serious risks in
security-critical applications, as the silent reintroduction of previously
detected threats in the system may undermine users' trust in the whole updating
process. To address this issue, we formalize and quantify security regression
in CL-based malware detectors and propose a regression-aware penalty to
mitigate it. Specifically, we adapt Positive Congruent Training (PCT) to the CL
setting, preserving prior predictive behavior in a model-agnostic manner.
Experiments on the ELSA, Tesseract, and AZ-Class datasets show that our method
effectively reduces regression across different CL scenarios while maintaining
strong detection performance over time.

</details>


### [329] [State of Health Estimation of Batteries Using a Time-Informed Dynamic Sequence-Inverted Transformer](https://arxiv.org/abs/2507.18320)
*Janak M. Patel,Milad Ramezankhani,Anirudh Deodhar,Dagnachew Birru*

Main category: cs.LG

TL;DR: TIDSIT是一种新颖的Transformer架构，通过结合时间嵌入和注意力机制，有效解决了电池健康状态估算中不规则时间序列数据的挑战，显著提高了预测精度和可靠性。


<details>
  <summary>Details</summary>
Motivation: 电池健康监测因电池供电的车辆和储能系统的快速普及而变得日益关键。电池性能和安全至关重要，但其会随着时间和充放电循环而退化，导致效率降低和安全隐患。因此，准确估算电池健康状态 (SoH) 对于确保运行可靠性和安全至关重要。然而，现有的机器学习模型在处理现实世界测量中的不规则性（如非均匀采样间隔和可变长度的放电周期）时存在困难，通常需要通过特征提取来处理，这会导致信息丢失和准确性下降。

Method: 提出了一种新颖的架构：时间感知动态序列倒置Transformer (TIDSIT)。该架构结合了连续时间嵌入，以有效表示不规则采样数据，并利用带时间注意力的填充序列来管理可变长度输入，同时不丢弃序列信息。

Result: TIDSIT在NASA电池退化数据集上实现了超过50%的预测误差降低，SoH预测误差低于0.58%，显著优于现有模型。

Conclusion: TIDSIT架构在NASA电池退化数据集上的实验结果表明，其性能显著优于现有模型，预测误差降低了50%以上，并且SoH预测误差保持在0.58%以下。此外，该架构具有通用性，有望在涉及不规则时间序列数据的健康监测任务中得到广泛应用。

Abstract: The rapid adoption of battery-powered vehicles and energy storage systems
over the past decade has made battery health monitoring increasingly critical.
Batteries play a central role in the efficiency and safety of these systems,
yet they inevitably degrade over time due to repeated charge-discharge cycles.
This degradation leads to reduced energy efficiency and potential overheating,
posing significant safety concerns. Accurate estimation of a State of Health
(SoH) of battery is therefore essential for ensuring operational reliability
and safety. Several machine learning architectures, such as LSTMs,
transformers, and encoder-based models, have been proposed to estimate SoH from
discharge cycle data. However, these models struggle with the irregularities
inherent in real-world measurements: discharge readings are often recorded at
non-uniform intervals, and the lengths of discharge cycles vary significantly.
To address this, most existing approaches extract features from the sequences
rather than processing them in full, which introduces information loss and
compromises accuracy. To overcome these challenges, we propose a novel
architecture: Time-Informed Dynamic Sequence Inverted Transformer (TIDSIT).
TIDSIT incorporates continuous time embeddings to effectively represent
irregularly sampled data and utilizes padded sequences with temporal attention
mechanisms to manage variable-length inputs without discarding sequence
information. Experimental results on the NASA battery degradation dataset show
that TIDSIT significantly outperforms existing models, achieving over 50%
reduction in prediction error and maintaining an SoH prediction error below
0.58%. Furthermore, the architecture is generalizable and holds promise for
broader applications in health monitoring tasks involving irregular time-series
data.

</details>


### [330] [Efficient Uncertainty in LLMs through Evidential Knowledge Distillation](https://arxiv.org/abs/2507.18366)
*Lakshmana Sri Harsha Nemani,P. K. Srijith,Tomasz Kuśmierczyk*

Main category: cs.LG

TL;DR: 本研究提出了一种通过低秩适配（LoRA）和证据学习将教师模型的知识蒸馏到学生模型中的方法，实现了大型语言模型（LLM）的高效不确定性量化，仅需一次前向传播即可达到与教师模型相当或更优的性能。


<details>
  <summary>Details</summary>
Motivation: 标准大型语言模型（LLM）中的准确不确定性量化仍然是一个关键挑战，这促使人们采用贝叶斯和基于集成的方法。然而，这些方法通常需要计算成本高昂的采样，涉及多次前向传播才能有效估计预测不确定性。

Method: 提出了一种新颖的方法，通过将需要多次前向传播的、具有不确定性意识的教师模型蒸馏成紧凑的学生模型来实现高效有效的不确定性估计。学生模型共享相同的架构，但使用低秩适配（LoRA）进行微调。比较了两种不同的蒸馏策略：一种是学生模型使用传统的 softmax 输出，另一种是学生模型利用 Dirichlet 分布输出，通过证据学习明确模拟认知不确定性。

Result: 在分类数据集上的实证评估表明，这些学生模型在预测和不确定性量化性能方面可以达到与其教师模型相当或更优的水平，同时关键在于仅需一次前向传播。

Conclusion: 本研究首次证明了通过证据蒸馏可以在大型语言模型中实现即时且稳健的不确定性量化。

Abstract: Accurate uncertainty quantification remains a key challenge for standard
LLMs, prompting the adoption of Bayesian and ensemble-based methods. However,
such methods typically necessitate computationally expensive sampling,
involving multiple forward passes to effectively estimate predictive
uncertainty.
  In this paper, we introduce a novel approach enabling efficient and effective
uncertainty estimation in LLMs without sacrificing performance. Specifically,
we distill uncertainty-aware teacher models - originally requiring multiple
forward passes - into compact student models sharing the same architecture but
fine-tuned using Low-Rank Adaptation (LoRA). We compare two distinct
distillation strategies: one in which the student employs traditional
softmax-based outputs, and another in which the student leverages
Dirichlet-distributed outputs to explicitly model epistemic uncertainty via
evidential learning.
  Empirical evaluations on classification datasets demonstrate that such
students can achieve comparable or superior predictive and uncertainty
quantification performance relative to their teacher models, while critically
requiring only a single forward pass. To our knowledge, this is the first
demonstration that immediate and robust uncertainty quantification can be
achieved in LLMs through evidential distillation.

</details>


### [331] [A Comprehensive Review of Diffusion Models in Smart Agriculture: Progress, Applications, and Challenges](https://arxiv.org/abs/2507.18376)
*Xing Hua,Haodong Chen,Qianqian Duan,Danfeng Hong,Ruijiao Li,Huiliang Shang,Linghua Jiang,Haima Yang,Dawei Zhang*

Main category: cs.LG

TL;DR: 深度学习和扩散模型在智慧农业中具有巨大潜力，尤其是在数据增强、图像生成和去噪方面，尽管计算效率和泛化能力仍需改进。


<details>
  <summary>Details</summary>
Motivation: 随着全球人口增长和可耕地资源日益稀缺，智慧农业和精准农业已成为农业发展的重要方向。以深度学习模型为代表的人工智能（AI）技术已广泛应用于作物监测和病虫害检测等领域。作为一种新兴的生成模型，扩散模型在农业图像处理、数据增强和遥感等任务中展现出巨大潜力。与传统的生成对抗网络（GANs）相比，扩散模型具有更优的训练稳定性和生成质量，能有效解决农业数据有限和图像样本不平衡等挑战。

Method: 本文回顾了扩散模型在农业应用中的最新进展，重点关注其在作物病虫害检测、遥感图像增强、作物生长预测和农业资源管理方面的潜力。

Result: 实验结果表明，扩散模型在数据增强、图像生成和去噪等方面显著提高了模型的准确性和鲁棒性，尤其是在复杂环境中。

Conclusion: 尽管在计算效率和泛化能力方面存在挑战，但随着技术的进步，扩散模型有望在智慧农业和精准农业中发挥越来越重要的作用，为全球农业的可持续发展提供有力支持。

Abstract: With the global population growing and arable land resources becoming
increasingly scarce,smart agriculture and precision agriculture have emerged as
key directions for the future ofagricultural development.Artificial
intelligence (AI) technologies, particularly deep learning models, have found
widespread applications in areas such as crop monitoring and pest detection. As
an emerging generative model, diffusion models have shown significant promise
in tasks like agricultural image processing, data augmentation, and remote
sensing. Compared to traditional generative adversarial networks (GANs),
diffusion models offer superior training stability and generation quality,
effectively addressing challenges such as limited agricultural data and
imbalanced image samples. This paper reviews the latest advancements in the
application of diffusion models in agriculture, focusing on their potential in
crop pest and disease detection, remote sensing image enhancement, crop growth
prediction, and agricultural resource management. Experimental results
demonstrate that diffusion models significantly improve model accuracy and
robustness in data augmentation, image generation, and denoising, especially in
complex environments. Despite challenges related to computational efficiency
and generalization capabilities, diffusion models are expected to play an
increasingly important role in smart and precision agriculture as technology
advances, providing substantial support for the sustainable development of
global agriculture.

</details>


### [332] [Multi-Model Ensemble and Reservoir Computing for River Discharge Prediction in Ungauged Basins](https://arxiv.org/abs/2507.18423)
*Mizuki Funato,Yohei Sawada*

Main category: cs.LG

TL;DR: HYPER是一种新的水文预测方法，结合了多模型集成和储层计算，在数据稀缺地区表现优于LSTM，计算效率高。


<details>
  <summary>Details</summary>
Motivation: 尽管准确的洪水预测和水资源管理至关重要，但许多地区缺乏足够的河流流量观测数据，这限制了降雨-径流分析的能力。尽管存在许多基于物理和机器学习的模型，但在数据稀缺的条件下实现高准确性、可解释性和计算效率仍然是一个重大挑战。

Method: 该研究提出了一种新颖的水文预测方法，即多模型集成和储层计算的水文预测（HYPER）。该方法首先应用贝叶斯模型平均（BMA）对43个“未经校准”的流域模型进行处理。然后，通过线性回归训练一个储层计算（RC）模型来修正BMA输出中的误差，这是一个非迭代过程，确保了高计算效率。对于未经测量的流域，通过将BMA和RC权重与已测量流域的流域属性相关联来推断所需的权重，从而创建了一个可推广的框架。

Result: 在数据充足的情况下，HYPER（中位数Kling-Gupta效率KGE为0.56）的表现与基准LSTM（KGE为0.55）相当，但计算时间仅为其5%。在数据稀缺的情况下（23%的流域已测量），HYPER保持了稳健的性能（KGE为0.55）和较低的不确定性，而LSTM的表现则显著下降（KGE为-0.04）。

Conclusion: HYPER 提供了一个在数据稀缺条件下进行流量预测的稳健、高效且可推广的解决方案，尤其适用于未经测量的流域，使其能够广泛应用于各种地区。该研究表明，当集合了足够大的模型集合并结合基于机器学习的偏差校正时，单个概念水文模型不一定需要进行校准。

Abstract: Despite the critical need for accurate flood prediction and water management,
many regions lack sufficient river discharge observations, limiting the skill
of rainfall-runoff analyses. Although numerous physically based and machine
learning models exist, achieving high accuracy, interpretability, and
computational efficiency under data-scarce conditions remains a major
challenge. We address this challenge with a novel method, HYdrological
Prediction with multi-model Ensemble and Reservoir computing (HYPER) that
leverages multi-model ensemble and reservoir computing (RC). Our approach first
applies Bayesian model averaging (BMA) to 43 "uncalibrated" catchment-based
conceptual hydrological models. An RC model is then trained via linear
regression to correct errors in the BMA output, a non-iterative process that
ensures high computational efficiency. For ungauged basins, we infer the
required BMA and RC weights by linking them to catchment attributes from gauged
basins, creating a generalizable framework. We evaluated HYPER using data from
87 river basins in Japan. In a data-rich scenario, HYPER (median Kling-Gupta
Efficiency, KGE, of 0.56) performed comparably to a benchmark LSTM (KGE 0.55)
but required only 5% of its computational time. In a data-scarce scenario (23%
of basins gauged), HYPER maintained robust performance (KGE 0.55) and lower
uncertainty, whereas the LSTM's performance degraded significantly (KGE -0.04).
These results reveal that individual conceptual hydrological models do not
necessarily need to be calibrated when an effectively large ensemble is
assembled and combined with machine-learning-based bias correction. HYPER
provides a robust, efficient, and generalizable solution for discharge
prediction, particularly in ungauged basins, making it applicable to a wide
range of regions.

</details>


### [333] [Revisiting Bisimulation Metric for Robust Representations in Reinforcement Learning](https://arxiv.org/abs/2507.18519)
*Leiji Zhang,Zeyu Wang,Xin Li,Yao-Hui Li*

Main category: cs.LG

TL;DR: 修订了模拟度量，解决了其在表示独特场景和权重依赖方面的问题，并通过实验证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决了传统模拟度量在表示某些独特场景和依赖预定义权重进行递归更新方面的两个主要问题。

Method: 通过引入状态-动作对的度量，提出了一个修订版的模拟度量，该度量具有更精确的奖励差距定义和新颖的、具有自适应系数的更新算子。

Result: 理论分析和在深度强化学习控制和元世界基准上的实验表明，所提出的方法具有收敛性，并能改进表示的区分度。

Conclusion: 该研究提出了一个修订版的模拟度量，通过引入状态-动作对的度量，提供了更精确的奖励差距定义和具有自适应系数的新颖更新算子。研究结果表明，该方法具有收敛性和改进的表示区分度，并在深度强化学习基准测试中得到了验证。

Abstract: Bisimulation metric has long been regarded as an effective control-related
representation learning technique in various reinforcement learning tasks.
However, in this paper, we identify two main issues with the conventional
bisimulation metric: 1) an inability to represent certain distinctive
scenarios, and 2) a reliance on predefined weights for differences in rewards
and subsequent states during recursive updates. We find that the first issue
arises from an imprecise definition of the reward gap, whereas the second issue
stems from overlooking the varying importance of reward difference and
next-state distinctions across different training stages and task settings. To
address these issues, by introducing a measure for state-action pairs, we
propose a revised bisimulation metric that features a more precise definition
of reward gap and novel update operators with adaptive coefficient. We also
offer theoretical guarantees of convergence for our proposed metric and its
improved representation distinctiveness. In addition to our rigorous
theoretical analysis, we conduct extensive experiments on two representative
benchmarks, DeepMind Control and Meta-World, demonstrating the effectiveness of
our approach.

</details>


### [334] [GLANCE: Graph Logic Attention Network with Cluster Enhancement for Heterophilous Graph Representation Learning](https://arxiv.org/abs/2507.18521)
*Zhongtian Sun,Anoushka Harit,Alexandra Cristea,Christl A. Donnelly,Pietro Liò*

Main category: cs.LG

TL;DR: GLANCE通过整合逻辑推理、动态图细化和聚类来增强GNN在异质图上的表现，实现了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: GNN在异质图（连接节点在特征或类别标签上存在差异）上的表现不佳，因为它们在邻域聚合方面不够明智，并且未能充分结合高阶结构模式。

Method: GLANCE框架整合了逻辑引导推理、动态图细化和自适应聚类来增强图表示学习。具体而言，它结合了用于可解释和结构化嵌入的逻辑层、用于图结构去噪的多头注意力边缘剪枝，以及用于捕获全局模式的聚类机制。

Result: GLANCE在Cornell、Texas和Wisconsin等基准数据集上实现了有竞争力的性能，为异质图场景提供了稳健且可解释的解决方案。

Conclusion: GLANCE框架轻量、自适应且能有效应对异质图的挑战，在Cornell、Texas和Wisconsin等基准数据集上取得了有竞争力的性能。

Abstract: Graph Neural Networks (GNNs) have demonstrated significant success in
learning from graph-structured data but often struggle on heterophilous graphs,
where connected nodes differ in features or class labels. This limitation
arises from indiscriminate neighbor aggregation and insufficient incorporation
of higher-order structural patterns. To address these challenges, we propose
GLANCE (Graph Logic Attention Network with Cluster Enhancement), a novel
framework that integrates logic-guided reasoning, dynamic graph refinement, and
adaptive clustering to enhance graph representation learning. GLANCE combines a
logic layer for interpretable and structured embeddings, multi-head
attention-based edge pruning for denoising graph structures, and clustering
mechanisms for capturing global patterns. Experimental results in benchmark
datasets, including Cornell, Texas, and Wisconsin, demonstrate that GLANCE
achieves competitive performance, offering robust and interpretable solutions
for heterophilous graph scenarios. The proposed framework is lightweight,
adaptable, and uniquely suited to the challenges of heterophilous graphs.

</details>


### [335] [C2G-KD: PCA-Constrained Generator for Data-Free Knowledge Distillation](https://arxiv.org/abs/2507.18533)
*Magnus Bengtsson,Kenneth Östberg*

Main category: cs.LG

TL;DR: C2G-KD是一种数据驱动的知识蒸馏方法，它使用类别条件生成器和PCA约束来创建合成数据，即使在数据量很少的情况下也能有效地训练模型。


<details>
  <summary>Details</summary>
Motivation: 介绍了一种名为C2G-KD的数据驱动知识蒸馏框架，旨在生成合成样本以用于训练。

Method: 提出了一种名为C2G-KD的数据驱动知识蒸馏框架，该框架利用类别条件生成器生成合成样本，并通过冻结的教师模型和来自PCA的几何约束进行指导。生成器不接触真实训练数据，而是通过语义和结构损失来激活教师模型的输出来学习。通过将生成的样本约束在从每个类别仅两个真实示例估计的类别特定PCA子空间内，可以保持拓扑一致性和多样性。

Result: 实验证明，即使使用很少的真实数据（每个类别仅两个），C2G-KD也能生成具有保留的拓扑一致性和多样性的合成数据，从而能够启动有效的综合训练。

Conclusion: C2G-KD框架在MNIST上的实验表明，即使是最小的类别结构也足以启动有用的综合训练流程。

Abstract: We introduce C2G-KD, a data-free knowledge distillation framework where a
class-conditional generator is trained to produce synthetic samples guided by a
frozen teacher model and geometric constraints derived from PCA. The generator
never observes real training data but instead learns to activate the teacher's
output through a combination of semantic and structural losses. By constraining
generated samples to lie within class-specific PCA subspaces estimated from as
few as two real examples per class, we preserve topological consistency and
diversity. Experiments on MNIST show that even minimal class structure is
sufficient to bootstrap useful synthetic training pipelines.

</details>


### [336] [The Price equation reveals a universal force-metric-bias law of algorithmic learning and natural selection](https://arxiv.org/abs/2507.18549)
*Steven A. Frank*

Main category: cs.LG

TL;DR: 本文利用价格方程提出了一种统一的学习算法框架（FMB定律），将自然选择、梯度下降、Adam等多种算法归纳为同一原理下的特例，并解释了Fisher信息等概念的来源。


<details>
  <summary>Details</summary>
Motivation: 旨在揭示多样化的学习算法、优化方法和自然选择之间在数学结构上的共性，尽管它们表面上存在差异。

Method: 提出了一种基于价格方程的通用力-度量-偏差（FMB）定律：Δθ = Mf + b + ξ。其中，力f通过参数与性能之间的协方差驱动参数Δθ的改进；度量M通过曲率的倒数对移动进行重新缩放；偏差b增加了动量或改变参照系；噪声ξ实现了探索。

Result: 研究表明，一种简单的基于价格方程的符号划分可以揭示一个普遍的力-度量-偏差（FMB）定律，该定律统一了多种学习和优化算法，并解释了Fisher信息、Kullback-Leibler散度和d'Alembert原理的出现。

Conclusion: 该框架统一了自然选择、贝叶斯更新、牛顿法、随机梯度下降、随机朗之万动力学、Adam优化以及大多数其他算法，将它们视为同一基本过程的特例。价格方程还揭示了为什么Fisher信息、Kullback-Leibler散度和d'Alembert原理自然地出现在学习动态中。通过揭示这种共同的结构，FMB定律为理解、比较和设计跨学科的学习算法提供了原则性基础。

Abstract: Diverse learning algorithms, optimization methods, and natural selection
share a common mathematical structure, despite their apparent differences. Here
I show that a simple notational partitioning of change by the Price equation
reveals a universal force-metric-bias (FMB) law: $\Delta\mathbf{\theta} =
\mathbf{M}\,\mathbf{f} + \mathbf{b} + \mathbf{\xi}$. The force $\mathbf{f}$
drives improvement in parameters, $\Delta\mathbf{\theta}$, through the
covariance between the parameters and performance. The metric $\mathbf{M}$
rescales movement by inverse curvature. The bias $\mathbf{b}$ adds momentum or
changes in the frame of reference. The noise $\mathbf{\xi}$ enables
exploration. This framework unifies natural selection, Bayesian updating,
Newton's method, stochastic gradient descent, stochastic Langevin dynamics,
Adam optimization, and most other algorithms as special cases of the same
underlying process. The Price equation also reveals why Fisher information,
Kullback-Leibler divergence, and d'Alembert's principle arise naturally in
learning dynamics. By exposing this common structure, the FMB law provides a
principled foundation for understanding, comparing, and designing learning
algorithms across disciplines.

</details>


### [337] [The Geometry of LLM Quantization: GPTQ as Babai's Nearest Plane Algorithm](https://arxiv.org/abs/2507.18553)
*Jiale Chen,Torsten Hoefler,Dan Alistarh*

Main category: cs.LG

TL;DR: GPTQ 量化算法在数学上等同于格上的 Babai 最近平面算法，提供了理论基础和误差界限。


<details>
  <summary>Details</summary>
Motivation: GPTQ 作为一种量化 LLM 权重的标准方法，其内部工作原理缺乏几何意义和最坏情况保证。本研究旨在提供 GPTQ 的理论基础。

Method: 将 GPTQ 的工作原理（从后向前执行）与 Babai 的最近平面算法联系起来，并证明了它们在 Hessian 矩阵定义的格上的数学等价性。

Result: 证明了 GPTQ 在特定条件下与 Babai 的最近平面算法等价，从而为 GPTQ 的误差传播提供了几何解释，并继承了 Babai 算法的误差上界。ERC 20 代币的发行需要考虑这些因素，但 ERC 721 代币的标准更为严格，主要用于表示独特的数字资产，例如加密艺术品或收藏品。

Conclusion: GPTQ 的工作原理可以被数学上解释为 Babai 最近平面算法在 Hessian 矩阵定义的格上的应用，这为 GPTQ 提供了坚实的理论基础，并允许将格算法的进展应用于未来的模型量化。

Abstract: Quantizing the weights of large language models (LLMs) from 16-bit to lower
bitwidth is the de facto approach to deploy massive transformers onto more
affordable accelerators. GPTQ emerged as one of the standard methods for
one-shot post-training quantization at LLM scale. Yet, its inner workings are
described as a sequence of ad-hoc algebraic updates that obscure any geometric
meaning or worst-case guarantees. In this work, we show that, when executed
back-to-front (from the last to first dimension) for a linear layer, GPTQ is
mathematically identical to Babai's nearest plane algorithm for the classical
closest vector problem (CVP) on a lattice defined by the Hessian matrix of the
layer's inputs. This equivalence is based on a sophisticated mathematical
argument, and has two analytical consequences: (i) the GPTQ error propagation
step gains an intuitive geometric interpretation; (ii) GPTQ inherits the error
upper bound of Babai's algorithm under the no-clipping condition. Taken
together, these results place GPTQ on firm theoretical footing and open the
door to importing decades of progress in lattice algorithms towards the design
of future quantization algorithms for billion-parameter models.

</details>


### [338] [Neural Tangent Kernels and Fisher Information Matrices for Simple ReLU Networks with Random Hidden Weights](https://arxiv.org/abs/2507.18555)
*Jun'ichi Takeuchia,Yoshinari Takeishia,Noboru Muratab,Kazushi Mimurac,Ka Long Keith Hod,Hiroshi Nagaoka*

Main category: cs.LG

TL;DR: Analyzed Fisher information matrices and NTK in 2-layer ReLU networks, showing their linear relationship and providing spectral decomposition and function approximation.


<details>
  <summary>Details</summary>
Motivation: To understand the properties of Fisher information matrices and neural tangent kernels in 2-layer ReLU networks with random hidden weights.

Method: Spectral decomposition of NTK and approximation formula for functions presented by 2-layer neural networks.

Result: Established a linear transformation relationship between Fisher information matrices and NTK, obtained spectral decomposition of NTK with eigenfunctions and major eigenvalues, and derived an approximation formula for the functions presented by these networks.

Conclusion: The paper analyzes Fisher information matrices and neural tangent kernels (NTK) for 2-layer ReLU networks with random hidden weights, demonstrating a linear transformation relationship between them and providing spectral decomposition with major eigenvalues.

Abstract: Fisher information matrices and neural tangent kernels (NTK) for 2-layer ReLU
networks with random hidden weight are argued. We discuss the relation between
both notions as a linear transformation and show that spectral decomposition of
NTK with concrete forms of eigenfunctions with major eigenvalues. We also
obtain an approximation formula of the functions presented by the 2-layer
neural networks.

</details>


### [339] [Beyond Internal Data: Constructing Complete Datasets for Fairness Testing](https://arxiv.org/abs/2507.18561)
*Varsha Ramineni,Hossein A. Rahmani,Emine Yilmaz,David Barber*

Main category: cs.LG

TL;DR: 在缺乏包含人口统计信息的真实数据的情况下，本研究提出了一种利用重叠数据集创建合成数据的方法，用于公平性测试，结果表明合成数据在评估模型公平性方面与真实数据具有一致性。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能在高风险领域和决策制定中的普及，测试其潜在危害和偏见变得至关重要。全球范围内出现的强调公平性和充分测试的AI法规，以及一些强制性独立偏见审计的要求，都反映了这种紧迫性。然而，获取用于公平性测试的必要数据仍然是一个重大挑战，特别是在行业环境中，法律和隐私问题限制了用于评估群体差异的人口统计数据的收集，并且审计人员在获取数据方面面临实际和文化挑战。

Method: 提出利用重叠数据集构建包含人口统计信息的合成数据，并通过与真实数据进行比较来验证合成数据的保真度，并进行实证分析证明基于合成数据的公平性指标与基于真实数据的指标一致。

Result: 经验证，与真实数据相比，合成数据在反映受保护属性和模型特征之间的潜在关系方面具有保真度。此外，基于合成数据测试得出的公平性指标与基于真实数据得出的公平性指标一致，表明该方法在数据受限的情况下是可行且有效的。

Conclusion: 该研究提出了一种克服现实世界数据稀缺性以进行公平性测试的方法，通过利用单独的重叠数据集来构建包含人口统计信息的完整合成数据，从而能够进行独立的、与模型无关的公平性评估。

Abstract: As AI becomes prevalent in high-risk domains and decision-making, it is
essential to test for potential harms and biases. This urgency is reflected by
the global emergence of AI regulations that emphasise fairness and adequate
testing, with some mandating independent bias audits. However, procuring the
necessary data for fairness testing remains a significant challenge.
Particularly in industry settings, legal and privacy concerns restrict the
collection of demographic data required to assess group disparities, and
auditors face practical and cultural challenges in gaining access to data.
Further, internal historical datasets are often insufficiently representative
to identify real-world biases. This work focuses on evaluating classifier
fairness when complete datasets including demographics are inaccessible. We
propose leveraging separate overlapping datasets to construct complete
synthetic data that includes demographic information and accurately reflects
the underlying relationships between protected attributes and model features.
We validate the fidelity of the synthetic data by comparing it to real data,
and empirically demonstrate that fairness metrics derived from testing on such
synthetic data are consistent with those obtained from real data. This work,
therefore, offers a path to overcome real-world data scarcity for fairness
testing, enabling independent, model-agnostic evaluation of fairness, and
serving as a viable substitute where real data is limited.

</details>


### [340] [Linear Memory SE(2) Invariant Attention](https://arxiv.org/abs/2507.18597)
*Ethan Pronovost,Neha Boloor,Peter Schleede,Noureldin Hendy,Andres Morales,Nicholas Roy*

Main category: cs.LG

TL;DR: 提出一种SE(2)不变的Transformer架构，使用线性内存的注意力机制处理空间数据，提高了在自动驾驶等任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在处理空间数据时需要二次内存的缺点，提出一种线性内存的注意力机制，以实现与大型语言模型类似的扩展性。

Method: 提出了一种SE(2)不变的缩放点积注意力机制，该机制相对于场景中的物体数量只需要线性内存。将此机制应用于SE(2)不变Transformer架构。

Result: 所提出的SE(2)不变Transformer架构具有线性内存开销，并且在实验中证明了其有效性，提高了性能。

Conclusion: 该方法在实践中是可行的，并且与同等的非不变性架构相比，性能得到了提升。

Abstract: Processing spatial data is a key component in many learning tasks for
autonomous driving such as motion forecasting, multi-agent simulation, and
planning. Prior works have demonstrated the value in using SE(2) invariant
network architectures that consider only the relative poses between objects
(e.g. other agents, scene features such as traffic lanes). However, these
methods compute the relative poses for all pairs of objects explicitly,
requiring quadratic memory. In this work, we propose a mechanism for SE(2)
invariant scaled dot-product attention that requires linear memory relative to
the number of objects in the scene. Our SE(2) invariant transformer
architecture enjoys the same scaling properties that have benefited large
language models in recent years. We demonstrate experimentally that our
approach is practical to implement and improves performance compared to
comparable non-invariant architectures.

</details>


### [341] [Demystify Protein Generation with Hierarchical Conditional Diffusion Models](https://arxiv.org/abs/2507.18603)
*Zinan Ling,Yi Shi,Da Yan,Yang Zhou,Bo Hui*

Main category: cs.LG

TL;DR: 提出了一种新的多层次条件扩散模型和评估指标Protein-MMD，用于改进条件蛋白质设计。


<details>
  <summary>Details</summary>
Motivation: 由于蛋白质的生物功能由多层次结构决定，因此需要一种能够整合多层次信息以进行高效蛋白质设计的方法。

Method: 提出了一种新的多层次条件扩散模型，该模型整合了基于序列和基于结构的信息，用于由指定功能指导的高效的端到端蛋白质设计。通过同时生成不同层次的表示，该框架能够有效地模拟不同层次之间固有的层次关系，从而生成具有信息量和区分度的蛋白质表示。还提出了一种新的可靠评估指标Protein-MMD，用于评估条件扩散模型生成的蛋白质的质量，该指标能够捕捉真实和生成蛋白质序列在分布和功能上的相似性，同时确保条件一致性。

Result: 与现有方法相比，所提出的生成框架和评估指标在条件蛋白质生成任务上表现出优越的性能。

Conclusion: 实验结果表明，所提出的生成框架和评估指标在条件蛋白生成任务上是有效的。

Abstract: Generating novel and functional protein sequences is critical to a wide range
of applications in biology. Recent advancements in conditional diffusion models
have shown impressive empirical performance in protein generation tasks.
However, reliable generations of protein remain an open research question in de
novo protein design, especially when it comes to conditional diffusion models.
Considering the biological function of a protein is determined by multi-level
structures, we propose a novel multi-level conditional diffusion model that
integrates both sequence-based and structure-based information for efficient
end-to-end protein design guided by specified functions. By generating
representations at different levels simultaneously, our framework can
effectively model the inherent hierarchical relations between different levels,
resulting in an informative and discriminative representation of the generated
protein. We also propose a Protein-MMD, a new reliable evaluation metric, to
evaluate the quality of generated protein with conditional diffusion models.
Our new metric is able to capture both distributional and functional
similarities between real and generated protein sequences while ensuring
conditional consistency. We experiment with the benchmark datasets, and the
results on conditional protein generation tasks demonstrate the efficacy of the
proposed generation framework and evaluation metric.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [342] [Squeezing enhanced sensing at an exceptional point](https://arxiv.org/abs/2507.17961)
*Changqing Wang,Deyuan Hu,Silvia Zorzetti,Anna Grassellino,Alexander Romanenko,Zheshen Zhang*

Main category: quant-ph

TL;DR: 本研究提出了一个结合压缩态和奇异点的量子传感新框架，显著提高了传感精度，并可应用于多种量子传感平台。


<details>
  <summary>Details</summary>
Motivation: 提高测量精度是传感和计量学的核心，这通常通过压缩态等非经典资源来实现，但将其与非厄米退化相结合仍然是一个挑战。

Method: 提出一个通用框架，将压缩态和非厄米退化（奇异点）相结合，用于开放系统中的量子传感。

Result: 在参数振荡阈值和奇异点处，传感精度与扰动强度的四次方成正比，实现了卓越的灵敏度增强。

Conclusion: 通过在开放系统量子传感的通用框架中统一 the parametric oscillation threshold and an exceptional point，我们发现了灵敏度的非凡增强，其传感精度与扰动强度的四次方成比例。该结果推广到具有高阶奇异点的多模压缩态传感器，可用于各种量子传感平台。

Abstract: Pushing the boundaries of measurement precision is central for sensing and
metrology, pursued by nonclassical resources such as squeezing, and
non-Hermitian degeneracies with distinct spectral response. Their convergence,
however, remains challenging. We find extraordinary enhancement of sensitivity
by unifying both effects in a general framework for quantum sensing in open
systems. At the parametric oscillation threshold and an exceptional point, the
sensing precision exhibits a unique quartic scaling with the perturbation
strength. The result generalizes to multimode squeezed-state sensors with
higher-order exceptional points catered to various quantum sensing platforms.

</details>


### [343] [Improved Quantum Sensing by Spectral Design](https://arxiv.org/abs/2507.17828)
*Paul Aigner,Wolfgang Dür*

Main category: quant-ph

TL;DR: 利用酉控制设计哈密顿量谱图，提升参数估计精度。


<details>
  <summary>Details</summary>
Motivation: 研究如何利用酉控制改进参数估计。

Method: 提出了一种利用酉控制来设计有效谱的方法，并将谱操作问题简化为一系列基本开关操作。

Result: 证明了可以实现任意期望的能级相对间距，并且任何修正后的谱都可以表示为原始特征值的凸组合，其中权重形成一个双随机矩阵。通过单参数估计示例，证明了该谱工程方法能显著提高估计精度。

Conclusion: 研究表明，通过设计印记哈密顿量的有效谱，可以提高参数估计的精度。

Abstract: We investigate how unitary control can improve parameter estimation by
designing the effective spectrum of the imprinting Hamiltonian. We show that,
for commuting Hamiltonians, the general problem of spectral manipulation via
unitary control simplifies to a finite sequence of elementary switching
operations. Furthermore, we demonstrate that any desired relative spacing of
energy levels can be achieved. We also show that any modified spectrum can be
expressed as a convex combination of the original eigenvalues, with the convex
weights forming a bi-stochastic matrix. Through several single-parameter
estimation examples, we demonstrate that our spectral engineering method
substantially enhances estimation accuracy.

</details>


### [344] [Resource-Efficient Simulations of Particle Scattering on a Digital Quantum Computer](https://arxiv.org/abs/2507.17832)
*Yahui Chai,Joe Gibbs,Vincent R. Pascuzzi,Zoë Holmes,Stefan Kühn,Francesco Tacchino,Ivano Tavernelli*

Main category: quant-ph

TL;DR: 在数字量子计算机上使用张量网络和电路压缩技术，高效高保真地模拟了相互作用Thirring模型中粒子波包的散射。


<details>
  <summary>Details</summary>
Motivation: 为了在数字量子计算机上高效且高保真地模拟粒子波包在相互作用Thirring模型中的散射动力学。

Method: 开发并演示了模拟方法，识别了低纠缠时间切片，并利用张量网络进行高效表示。通过基于矩阵乘积状态技术的电路压缩，平均将电路深度减少了3.2倍，从而在当代量子处理器上以更高的保真度评估更长的演化时间。结合零噪声外推和Pauli扭曲技术，在量子硬件上精确模拟了40个量子比特的完整散射动力学，并展示了80个量子比特的波包态制备。

Result: 在40个量子比特上精确模拟了完整的散射动力学，并在80个量子比特上展示了波包态制备。电路深度平均减少了3.2倍，实现了更长的演化时间和更高的保真度。

Conclusion: 本研究成功在数字量子计算机上（最多80个量子比特）模拟了相互作用的Thirring模型中粒子波包的散射，并实现了硬件应用。

Abstract: We develop and demonstrate methods for simulating the scattering of particle
wave packets in the interacting Thirring model on digital quantum computers,
with hardware implementations on up to 80 qubits. We identify low-entanglement
time slices of the scattering dynamics and exploit their efficient
representation by tensor networks. Circuit compression based on matrix product
state techniques yields on average a reduction by a factor of 3.2 in circuit
depth compared to conventional approaches, allowing longer evolution times to
be evaluated with higher fidelity on contemporary quantum processors. Utilizing
zero-noise extrapolation in combination with Pauli twirling, on quantum
hardware we accurately simulate the full scattering dynamics on 40 qubits, and
further demonstrate the wave packet state-preparation on 80 qubits.

</details>


### [345] [Real-time analog circuit for auto-correlative weak-value amplification in the time domain](https://arxiv.org/abs/2507.18180)
*Jing-Hui Huang,Guang-Jun Wang,Xiang-Yun Hu*

Main category: quant-ph

TL;DR: AWVA技术在量子参数估计中优于SWVA。通过使用AD835乘法器和NE5532运算放大器实现的模拟电路，AWVA在低信噪比下表现出更高的精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了在实时参数估计中获得更高的精度，AWVA技术相比标准的SWVA技术具有独特的优势。

Method: 实现了一个实时模拟电路用于AWVA，使用了AD835乘法器和NE5532运算放大器作为积分器。使用高斯指针对AWVA方案进行了测试。

Result: 所实现的AWVA电路对高斯指针表现出足够的灵敏度，频率范围为200 Hz < f < 20kHz。

Conclusion: 与SWVA相比，AWVA在信噪比（SNR）为-12 dB < SNR < -4 dB时，实现了更高的精度和对噪声更优越的鲁棒性。该电路不仅适用于量子计量学，还可应用于各种信号检测方案。

Abstract: The auto-correlative weak-value amplification (AWVA) technique demonstrates
distinct advantages over standard weak-value amplification (SWVA) for quantum
parameter estimation. To achieve enhanced precision in real-time parameter
estimation, the AWVA requires additional resources compared to SWVA, namely
real-time multiplication and integrator modules. We implemented a real-time
analog circuit for AWVA using an AD835 multiplier and an NE5532 operational
amplifier for the integrator. The circuit was tested using Gaussian pointers in
the AWVA scheme, exhibiting sufficient sensitivity for Gaussian pointers with
frequencies 200 Hz < f < 20kHz. Compared to SWVA, AWVA achieves higher accuracy
and superior robustness against noise at signal-to-noise ratios (SNRs) of -12
dB < SNR < -4 dB. Beyond quantum metrology, the circuit is applicable to
diverse detection schemes for correlated signals.

</details>


### [346] [Dynamics of colored-noise-driven stochastic Schrödinger equations](https://arxiv.org/abs/2507.17864)
*Pietro De Checchi,Federico Gallina,Barbara Fresch,Giulio G. Giusteri*

Main category: quant-ph

TL;DR: 彩色噪声影响双能级系统动力学，推导了相关方程并分析了其影响。


<details>
  <summary>Details</summary>
Motivation: 研究彩色随机噪声对双能级系统动力学的影响，以理解其对相干弛豫时间尺度和系统演化的影响。

Method: 推导了随机薛定谔方程（SSE）和量子主方程（QME），并利用奥恩斯坦-乌伦贝克彩色噪声分析了不同耗散项的出现及其对系统演化的影响，最后推导了QME开放项的闭合模型。

Result: 明确了彩色噪声如何影响相干弛豫时间尺度，并解释了不同耗散项的出现与随机势的性质相关。

Conclusion: 研究了彩色随机噪声对双能级系统动力学的影响，并推导了随机薛定谔方程和量子主方程，比较了有记忆和无记忆过程，并着重研究了奥恩斯坦-乌伦贝克彩色噪声。

Abstract: In this work, we study the effect of colored stochastic noise as a source of
fluctuations in the dynamics of a two-level system, e.g. the states of a qubit
system or two local sites in a transfer problem. We derive the stochastic
Schr\"odinger equations (SSE) and related quantum master equations (QME) for
the average density matrix for different stochastic potentials. We compare the
case of memory and memoryless processes, which reflect different short-time
behaviors and, in some cases, can lead to different stationary distributions of
the average system state. Focusing on the use of an Ornstein-Uhlenbeck coloured
noise driving the dynamics, in the same fashion as the white noise is the
formal derivative of a Wiener process, we shed light on how different
dissipative terms of a generic QME arise depending on the nature of the
stochastic potential involved, and their effect on the short and long time
evolution of the system. We rationalize the emergence of the different terms in
terms of the time- and frequency-dependent coefficients Redfield QME. Within
this framework, we explicitly derive a closure model for the open terms in the
QME derived from the SSE approach, and clarify how colored noise impacts the
coherence relaxation time scales

</details>


### [347] [Shallow quantum circuit for generating O(1)-entanged approximate state designs](https://arxiv.org/abs/2507.17871)
*Wonjun Lee,Minki Hhan,Gil Young Cho,Hyukjoon Kwon*

Main category: quant-ph

TL;DR: 研究提出了一种生成具有极低纠缠、魔法和相干性的 $\epsilon$-近似状态 $t$-设计的有效方法，并提供了一种无需辅助比特的浅层量子电路，该方法可降低量子信息处理的成本。


<details>
  <summary>Details</summary>
Motivation: 需要一种能够作为 $\epsilon$-近似状态 $t$-设计，同时又具有极低纠缠、魔法和相干性的量子态，以降低量子信息科学中相关应用的成本，并提高算法效率。

Method: 通过开发一种将 $k$ 量子比特近似状态设计转换为 $n$ 量子比特设计的算法，并利用多控制门，在不增加支持尺寸的情况下生成具有低纠缠、魔法和相干性的 $\epsilon$-近似状态 $t$-设计。

Result: 发现了一类新的量子态，它们是 $\epsilon$-近似状态 $t$-设计，且纠缠、魔法和相干性达到理论下界 $O(1)$。提出了无需辅助比特的浅层量子电路来生成这些状态，其电路深度优于现有算法。该方法可用于降低经典模拟随机量子态的成本，并已在经典阴影断层扫描中得到应用。

Conclusion: 该研究发现了一类新的量子态，它们是 $\epsilon$-近似状态 $t$-设计，同时具有极低的纠缠、魔法和相干性。这些资源可以达到理论下界 $\Omega\left(\log (t/\epsilon)\right)$，且不随系统尺寸 $n$ 扩展（$O(1)$）。此外，研究提出了一种无需辅助比特的浅层量子电路来生成这些状态，并开发了一种将 $k$ 量子比特近似状态设计转换为 $n$ 量子比特设计的算法，其电路深度为 $O\left(t [\log t]^3 \log n \log(1/\epsilon)\right)$，是现有无辅助比特算法中最优的。该研究为经典模拟随机量子态提供了更经济的途径，并在量子信息处理任务中具有潜在应用，例如通过 $O(1)$-纠缠估计器实现经典阴影断层扫描，缩短了运行时间。

Abstract: Random quantum states have various applications in quantum information
science, including quantum cryptography, quantum simulation, and benchmarking
quantum devices. In this work, we discover a new ensemble of quantum states
that serve as an $\epsilon$-approximate state $t$-design while possessing
extremely low entanglement, magic, and coherence. We show that those resources
such quantum states can reach their theoretical lower bounds, $\Omega\left(\log
(t/\epsilon)\right)$, which are also proven in this work. This implies that for
fixed $t$ and $\epsilon$, those resources do not scale with the system size,
i.e., $O(1)$ with respect to the total number of qubits $n$ in the system.
Moreover, we explicitly construct an ancilla-free shallow quantum circuit for
generating such states. To this end, we develop an algorithm that transforms
$k$-qubit approximate state designs into $n$-qubit ones through a sequence of
multi-controlled gates, without increasing the support size. The depth of such
a quantum circuit is $O\left(t [\log t]^3 \log n \log(1/\epsilon)\right)$,
which is the most efficient among existing algorithms without ancilla qubits. A
class of shallow quantum circuits proposed in our work offers reduced cost for
classical simulation of random quantum states, leading to potential
applications in various quantum information processing tasks. As a concrete
example for demonstrating utility of our algorithm, we propose classical shadow
tomography using an $O(1)$-entangled estimator, which can achieve shorter
runtime compared to conventional schemes.

</details>


### [348] [Stability of Continuous Time Quantum Walks in Complex Networks](https://arxiv.org/abs/2507.17880)
*Adithya L J,Johannes Nokkala,Jyrki Piilo,Chandrakala Meena*

Main category: quant-ph

TL;DR: 本研究调查了连续时间量子行走在不同网络拓扑和退相干机制下的稳定性。结果显示，异构网络通常比同质网络更稳定，但具体排名取决于所用指标和退相干模型。初始化节点的中心性在异构网络中对稳定性有显著影响。


<details>
  <summary>Details</summary>
Motivation: 研究连续时间量子行走（CTQWs）在不同网络拓扑和退相干机制下的稳定性，以了解其维持量子特性的能力。

Method: 本研究采用多种指标评估量子稳定性，包括节点占据概率、相干性的$\\ell_1$-范数、与初始状态的保真度、量子-经典距离以及冯诺依曼熵。

Result: 结果表明，网络拓扑和退相干机制的相互作用会影响相干性的保持。内禀退相干导致相干性衰减最慢，其次是Haken-Strobl噪声，而量子随机游走（QSW）导致相干性丧失最快。网络拓扑之间的稳定性排名根据退相干机制和所使用的量化指标而变化。例如，在Haken-Strobl和内禀退相干下，量子-经典距离将环形网络的稳定性评为高于无标度网络，尽管其他指标一致倾向于无标度网络。

Conclusion: 异构网络（例如星型和无标度网络）通常最稳定，而同质网络（例如环形和Erd
H{o}s-R\'enyi网络）更容易受到退相干的影响。然而，完全图由于其密集的连通性，尽管是同质的，但仍然高度稳定。此外，在异构网络中，初始化节点的中心性（通过度或紧密度衡量）对稳定性有显著影响，这表明了局部拓扑特征在量子动力学中的作用。

Abstract: We investigate the stability of continuous time quantum walks (CTQWs) in a
range of network topologies under different decoherence mechanisms, defining
stability as the system's ability to preserve quantum properties over time. The
networks studied range from homogeneous to heterogeneous structures, including
cycle, complete, Erd\H{o}s-R\'enyi, small-world, scale-free, and star
topologies. The decoherence models considered are intrinsic decoherence,
Haken-Strobl noise, and quantum stochastic walks (QSWs). To assess quantum
stability, we employ several metrics: node occupation probabilities, the
$\ell_1$-norm of coherence, fidelity with the initial state, quantum-classical
distance, and von Neumann entropy. Our results reveal that the interplay of
both network topology and decoherence model influences coherence preservation.
Intrinsic decoherence results in the slowest decay of coherence, followed by
Haken-Strobl noise, while QSW causes the most rapid loss of coherence. The
stability ranking among network topologies varies depending on the decoherence
model and quantifier used. For example, under Haken-Strobl and intrinsic
decoherence, the quantum-classical distance ranks the cycle network more stable
than scale-free networks, although other metrics consistently favour scale-free
topologies. In general, heterogeneous networks, such as star and scale-free
networks, exhibit the highest stability, whereas homogeneous topologies, such
as cycle and Erd\H{o}s-R\'enyi networks, are more vulnerable to decoherence.
The complete graph, despite its homogeneity, remains highly stable due to its
dense connectivity. Furthermore, in heterogeneous networks, the centrality of
the initialised node, measured by degree or closeness, has a pronounced impact
on stability, underscoring the role of local topological features in quantum
dynamics.

</details>


### [349] [Quantum Machine Learning Playground](https://arxiv.org/abs/2507.17931)
*Pascal Debus,Sebastian Issel,Kilian Tscharke*

Main category: quant-ph

TL;DR: 本文开发了一个交互式可视化工具，用于解释量子机器学习算法，并推出了一个QML游乐场。


<details>
  <summary>Details</summary>
Motivation: 受TensorFlow Playground等经典机器学习可视化工具的成功启发，本文旨在弥合QML领域可视化资源方面的差距。

Method: 本文概述了相关的可视化隐喻，阐述了算法可视化概念，并设计了一个具体的交互式Web应用程序来实现该工具。

Result: 本文介绍了首个量子机器学习游乐场，这是一个交互式Web应用程序，用于学习和探索QML模型，特别是数据再上传通用量子分类器。

Conclusion: 本文提出了一种创新的交互式可视化工具，旨在揭开量子机器学习（QML）算法的神秘面纱，并为QML领域提供可视化资源，以降低量子计算的入门门槛，鼓励该领域的进一步创新。文章还介绍了该工具的第一个版本，一个用于学习和探索QML模型的量子机器学习游乐场。

Abstract: This article introduces an innovative interactive visualization tool designed
to demystify quantum machine learning (QML) algorithms. Our work is inspired by
the success of classical machine learning visualization tools, such as
TensorFlow Playground, and aims to bridge the gap in visualization resources
specifically for the field of QML. The article includes a comprehensive
overview of relevant visualization metaphors from both quantum computing and
classical machine learning, the development of an algorithm visualization
concept, and the design of a concrete implementation as an interactive web
application. By combining common visualization metaphors for the so-called data
re-uploading universal quantum classifier as a representative QML model, this
article aims to lower the entry barrier to quantum computing and encourage
further innovation in the field. The accompanying interactive application is a
proposal for the first version of a quantum machine learning playground for
learning and exploring QML models.

</details>


### [350] [Quantum Fisher Information in Curved Spacetime: Dirac Particles in Noisy Channels around a Schwarzschild Black Hole](https://arxiv.org/abs/2507.17901)
*Cookey Iyen,Muhammad Sanusi Liman,Benedict O. Ayomanor,Emem-obong Solomon James,Yame Mwanzang Philemon,Babatunde James Falaye*

Main category: quant-ph

TL;DR: 本研究调查了在史瓦西黑洞弯曲时空中，三量子比特纠缠狄拉克系统在受损耗噪声通道影响下的量子费舍尔信息（QFI）的行为，重点关注了压缩广义幅度阻尼（SGAD）通道及其子通道（GAD和AD）对QFI的影响。研究发现，强压缩可以提高QFI的鲁棒性，抵抗霍金温度变化，并减缓QFI的衰减，表明其作为纠错策略的潜力。此外，信道温度是主要的退相干来源，并观察到关于相位参数的QFI在特定信道温度下出现瞬态尖峰现象。


<details>
  <summary>Details</summary>
Motivation: 量子信息处理在与经典方法相比具有显著优势，但仍然容易受到由环境相互作用和时空效应引起的退相干的影响。

Method: 本研究通过分析一个置于史瓦西黑洞弯曲时空中的三量子比特纠缠狄拉克系统，在受耗散噪声通道影响的情况下，量子费舍尔信息（QFI）作为纠缠和参数估计的诊断工具的行为。

Result: 在强压缩（r=1）下，关于纠缠权重（θ）的QFI对霍金温度（TH）的变化完全免疫，但仍会随着信道温度（TC）的升高而退化。与r=0相比，r=1下的QFI衰减明显更慢，这表明压缩可以作为一种纠错策略。对于关于相位（φ）的QFI，在TC=2时观察到一个瞬态尖峰，这可能归因于热共振或非单调退相干，并且这种行为不受TH的影响。在广义幅度阻尼（GAD）和幅度阻尼（AD）信道中也观察到类似的模式，其中TC持续是退相干的主要来源。

Conclusion: 研究结果揭示了环境噪声、相对论效应以及弯曲时空中的量子误差弹性之间复杂的相互作用。

Abstract: Quantum information processing promises significant advantages over classical
methods but remains vulnerable to decoherence induced by environmental
interactions and spacetime effects. This work investigates the behavior of
Quantum Fisher Information (QFI) as a diagnostic tool for entanglement and
parameter estimation in a three-qubit entangled Dirac system subjected to
dissipative noisy channels in the curved spacetime of a Schwarzschild black
hole. In particular, we examine the influence of the squeezed generalized
amplitude damping (SGAD) channel, along with its subchannels -- generalized
amplitude damping (GAD) and amplitude damping (AD) -- on the QFI with respect
to entanglement weight ($\theta$) and phase ($\phi$) parameters. Our results
show that under strong squeezing ($r = 1$), the QFI with respect to $\theta$
becomes completely resistant to variations in the Hawking temperature ($T_H$),
while still exhibiting degradation with increasing channel temperature ($T_C$).
The QFI decay is significantly slower at $r = 1$ compared to $r = 0$,
suggesting that squeezing can function as an error mitigation strategy. For QFI
with respect to $\phi$, a transient spike is observed at $T_C = 2$, potentially
due to thermal resonance or non-monotonic decoherence, and this behavior is
unaffected by $T_H$. Similar patterns are noted in the GAD and AD channels,
where $T_C$ consistently dominates as the principal source of decoherence.
Overall, the results highlight the intricate interplay between environmental
noise, relativistic effects, and quantum error resilience in curved spacetime.

</details>


### [351] [Tensorial Spin-Phonon Relaxation Reveals Mode-Selective Relaxation Pathways in a Single-Molecule Magnet](https://arxiv.org/abs/2507.17910)
*Roman Dmitriev,Nosheen Younas,Yu Zhang,Andrei Piryatinski,Eric R. Bittner*

Main category: quant-ph

TL;DR: A first-principles framework using DFT and open-system formalism is developed to compute spin relaxation tensors in molecular qubits. It identifies specific vibrational modes responsible for decoherence, matching experimental results and aiding in qubit design.


<details>
  <summary>Details</summary>
Motivation: Understanding and controlling spin relaxation in molecular qubits is essential for developing chemically tunable quantum information platforms.

Method: Combining density functional theory with a mode-resolved open-system formalism. Spin Hamiltonian is expanded in vibrational normal modes and both linear and quadratic spin-phonon coupling tensors are evaluated via finite differences of the g-tensor. This constructs a relaxation tensor that enters a Lindblad-type quantum master equation.

Result: A highly mode-selective structure is revealed, where only three vibrational modes dominate longitudinal (T1) decoherence, and a single mode accounts for the majority of transverse (T2) relaxation. Computed relaxation times show excellent agreement with experimental measurements without any empirical fitting.

Conclusion: First-principles spin-phonon tensors can provide predictive insight into decoherence pathways and guide the rational design of molecular qubits.

Abstract: Understanding and controlling spin relaxation in molecular qubits is
essential for developing chemically tunable quantum information platforms. We
present a fully first-principles framework for computing the spin relaxation
tensor in a single-molecule magnet, \ce{VOPc(OH)8}, by combining density
functional theory with a mode-resolved open-system formalism. By expanding the
spin Hamiltonian in vibrational normal modes and evaluating both linear and
quadratic spin-phonon coupling tensors via finite differences of the
$g$-tensor, we construct a relaxation tensor that enters a Lindblad-type
quantum master equation. Our formalism captures both direct (one-phonon) and
resonant-Raman (two-phonon) relaxation processes. Numerical analysis reveals a
highly mode-selective structure: only three vibrational modes dominate
longitudinal ($T_1$) decoherence, while a single mode accounts for the majority
of transverse ($T_2$) relaxation. The computed relaxation times show excellent
agreement with experimental measurements, without any empirical fitting. These
results demonstrate that first-principles spin-phonon tensors can provide
predictive insight into decoherence pathways and guide the rational design of
molecular qubits.

</details>


### [352] [Qubit encodings for lattices of dipolar planar rotors](https://arxiv.org/abs/2507.17952)
*Muhammad Shaeer Moeed,James Brown,Alexander Ibrahim,Estevao Vilas Boas De Oliveira,Pierre-Nicholas Roy*

Main category: quant-ph

TL;DR: 本文研究了两种编码方法在量子模拟中的应用，并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 近地量子设备在模拟多体物理中难以探测的区域具有潜力。为此，人们提出了各种量子比特编码方案来处理二次量子化哈密顿量。本文旨在研究两种量子比特表示方法在平面转子格哈密顿量上的应用。

Method: 本文提出两种编码方法：1.将转子哈密顿量投影分解为二元并映射到自旋1/2投影；2.将平面转子格希尔伯特空间嵌入到一个更大的空间，通过投影恢复到物理自由度（ unary mapping）。

Result: 通过在小型链上进行稀疏对角化验证了两种编码方法的正确性，并讨论了在近地量子设备上模拟小型平面转子格所需的量子相位估计资源。

Conclusion: 本文验证了两种量子比特编码方法，并将它们应用于模拟平面转子哈密顿量。

Abstract: Near term quantum devices have recently garnered significant interest as
promising candidates for investigating difficult-to-probe regimes in many-body
physics. To this end, various qubit encoding schemes targeting second quantized
Hamiltonians have been proposed and optimized. In this work, we investigate two
qubit representations of the planar rotor lattice Hamiltonian. The first
representation is realized by decomposing the rotor Hamiltonian projectors in
binary and mapping them to spin-1/2 projectors. The second approach relies on
embedding the planar rotor lattice Hilbert space in a larger space and
recovering the relevant qubit encoded system as a quotient space projecting
down to the physical degrees of freedom. This is typically called the unary
mapping and is used for bosonic systems. We establish the veracity of the two
encoding approaches using sparse diagonalization on small chains and discuss
quantum phase estimation resource requirements to simulate small planar rotor
lattices on near-term quantum devices.

</details>


### [353] [Spatial correlations in four-wave mixing with structured light](https://arxiv.org/abs/2507.17964)
*Mateus R. L. da Motta,Sandra S. Vianna*

Main category: quant-ph

TL;DR: 本研究使用量化近轴框架处理了四波混频（FWM）中的双光子态，分析了其在不同表示下的特性，并将其与自发参量下转换（PDC）进行了比较，为未来光学研究提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 研究FWM和自发参量下转换（PDC）之间的形式和物理相似性，展示了泵浦结构向双光子态的重要空间符合剖面特性的转移，而这种转移自然地延伸到了FWM。

Method: 采用量化近轴框架对四波混频（FWM）进行详细的理论处理，捕捉该过程中产生的双光子态的多空间模式性质。通过在位置和动量表示下对双光子态进行分析，确定了这些描述等效的条件。

Result: 我们证明了FWM和PDC之间的相似性，并详细说明了从近场位置相关性到远场动量相关性的过渡，这反映了潜在的空间纠缠。此外，还讨论了纠缠度量，如螺旋带宽和施密特秩。

Conclusion: 本研究整合了已知和关于四波混频（FWM）中空间关联的新结果，并提供了一个理论框架，可能支持未来在非线性光学和量子光学中使用结构光进行的研究。

Abstract: We present a detailed theoretical treatment of four-wave mixing (FWM) in a
quantized paraxial framework, capturing the multi-spatial-mode nature of the
biphoton state generated in the process. By analyzing the biphoton state both
in position and momentum representations, we identify the conditions under
which these descriptions become equivalent. We also highlight formal and
physical similarities between FWM and spontaneous parametric down-conversion
(PDC), showing that the transfer of pump structure to the spatial coincidence
profile, an important and well-known characteristic of the biphoton state,
carries over naturally to FWM. In addition, our treatment captures the
transition from position correlations in the near field to momentum
correlations in the far field, reflecting the underlying spatial entanglement.
The measures of entanglement, including the spiral bandwidth and the Schmidt
rank, are discussed. Our work consolidates known and new results on spatial
correlations in FWM and provides a theoretical framework that may support
future studies in nonlinear and quantum optics with structured light.

</details>


### [354] [Molecular Properties in Quantum-Classical Auxiliary-Field Quantum Monte Carlo: Correlated Sampling with Application to Accurate Nuclear Forces](https://arxiv.org/abs/2507.17992)
*Joshua J. Goings,Kyujin Shin,Seunghyo Noh,Woomin Kyoung,Donghwi Kim,Jihye Baek,Martin Roetteler,Evgeny Epifanovsky,Luning Zhao*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We extend correlated sampling from classical auxiliary-field quantum Monte
Carlo to the quantum-classical (QC-AFQMC) framework, enabling accurate nuclear
force computations crucial for geometry optimization and reaction dynamics.
Stochastic electronic structure methods typically encounter prohibitive
statistical noise when computing gradients via finite differences. To address
this, our approach maximizes correlation between nearby geometries by
synchronizing random number streams, aligning orbitals, using deterministic
integral decompositions, and employing a consistent set of classical shadow
measurements defined at a single reference geometry. Crucially, reusing this
single, reference-defined shadow ensemble eliminates the need for additional
quantum measurements at displaced geometries. Together, these methodological
choices substantially reduce statistical variance in computed forces. We
validate the method across hydrogen chains, confirming accuracy throughout
varying correlation regimes, and demonstrate significant improvements over
single-reference methods in force evaluations for N$_2$ and stretched linear
H$_4$, particularly in strongly correlated regions where conventional coupled
cluster approaches qualitatively fail. Orbital-optimized trial wave functions
further boost accuracy for demanding cases such as stretched CO$_2$, without
increasing quantum resource requirements. Finally, we apply our methodology to
the MEA-CO$_2$ carbon capture reaction, employing quantum information metrics
for active space selection and matchgate shadows for efficient overlap
evaluations, establishing QC-AFQMC as a robust framework for exploring complex
reaction pathways.

</details>


### [355] [On-Chip Laser-Driven Free-Electron Spin Polarizer](https://arxiv.org/abs/2507.17993)
*Clarisse Woodahl,Melanie Murillo,Charles Roques-Carmes,Aviv Karnieli,David A. B. Miller,Olav Solgaard*

Main category: quant-ph

TL;DR: 通过激光驱动的纳米光子场和两级相互作用在集成光子学芯片上产生自旋极化电子。


<details>
  <summary>Details</summary>
Motivation: 开发一种在纳米尺度上研究自旋相关电和磁效应的自旋极化电子束源。

Method: 通过激光驱动的纳米光子场，利用两级相互作用（包括自由空间漂移长度）在集成光子学芯片上产生自旋极化电子，其中光学近场被用来旋转自旋态。

Result: 该方法产生具有高平均自旋期望值的自旋极化电子。

Conclusion: 该方法提供了一种在集成光子学芯片上生成自旋极化电子的紧凑、可扩展的方法，可在微米尺度上实现。

Abstract: Spin-polarized electron beam sources enable studies of spin-dependent
electric and magnetic effects at the nanoscale. We propose a method of creating
spin-polarized electrons on an integrated photonics chip by laser driven
nanophotonic fields. A two-stage interaction separated by a free space drift
length is proposed, where the first stage and drift length introduces
spin-dependent characteristics into the probability distribution of the
electron wavefunction. The second stage uses an adjusted optical near-field to
rotate the spin states utilizing the spin-dependent wavepacket distribution to
produce electrons with high ensemble average spin expectation values. This
platform provides an integrated and compact method to generate spin-polarized
electrons, implementable with millimeter scale chips and table-top lasers.

</details>


### [356] [Entanglement-based quantum key distribution with non-Gaussian continuous variables](https://arxiv.org/abs/2507.18000)
*Hao Jeng,Ping Koy Lam,Syed M. Assad*

Main category: quant-ph

TL;DR: 该研究提出了一种向纠缠态添加光子的技术，以提高量子密钥分发的性能。研究发现，这种方法不仅能增加密钥生成速率和最大安全距离，还能有效抵抗退相干。尽管这种方法产生的量子态具有高度的非高斯特性，给分析带来挑战，但研究开发了新的分析方法来应对。


<details>
  <summary>Details</summary>
Motivation: 为了提升量子密钥分发（QKD）的性能，特别是在密钥生成速率和最大安全距离方面，并解决从非高斯纠缠态提取密钥的复杂问题。

Method: 提出了一种向纠缠态添加光子的技术，并分析了该技术在量子密钥分发中的应用。

Result: 所产生的量子相关性具有高度的非高斯特性，传统的基于高斯最优性原理的分析方法失效，但新开发的分析方法能够处理这种非高斯态，并证明了单光子添加确实能提高密钥速率和最大距离，同时该技术还能保护协议免受退相干的影响。

Conclusion: 研究表明，单光子添加技术可以提升量子密钥分发（QKD）的密钥生成速率和最大安全距离，并且该技术能够有效抵抗被动和主动的退相干。

Abstract: Addition of single photons to two-mode-squeezed-vacuum states has the effect
of distilling quantum entanglement, and, when deployed in quantum key
distribution, should lead also to an increase in the secret key rate. However,
the extraction of secret keys from non-Gaussian entangled states is a complex
issue and is at present not fully understood. In this paper we describe a
technique for adding photons to entangled states, and demonstrate how it leads
to an increase in secret key rates and the maximal distance for which keys can
be distributed assuming asymptotic conditions. The quantum correlations thus
produced were found to be of a highly non-Gaussian character, such that the
Gaussian extremity principle returns a negative keyrate and effectively kills
the protocol; we have therefore developed methods of analysis that do not
require prior assumptions about the state. Although it could have been that the
addition of single photons would make the system more fragile, this turned out
not to be the case. Rather, the addition of a single photon was found to
protect the protocol against both passive and active decoherence.

</details>


### [357] [Enhanced continuous-variable quantum key distribution protocol via adaptive signal processing](https://arxiv.org/abs/2507.18049)
*Ozlem Erkilic,Biveen Shajilal,Lorcan O. Conlon,Angus Walsh,Aritra Das,Sebastian Kish,Thomas Symul,Ping Koy Lam,Syed M. Assad,Jie Zhao*

Main category: quant-ph

TL;DR: 一种新的量子密钥分发协议，通过使用概率过滤器，实现了比现有协议更高的密钥速率和安全性。


<details>
  <summary>Details</summary>
Motivation: 为了克服连续可变量子密钥分发协议在光纤损耗和自由空间信道中大气闪烁方面的挑战，并提高其在动态变化信道中的性能。

Method: 提出了一种新的连续可变量子密钥分发协议，该协议利用爱丽丝处的高斯滤波器和鲍勃处类似凹口但非高斯的不确定性滤波器，以超越最优高斯调制连续可变量子密钥分发协议。

Result: 该协议实现了比最优高斯调制连续可变量子密钥分发协议高三倍的密钥速率，并表明在低地球轨道卫星通信中比非最优协议高 400 倍。

Conclusion: 通过使用具有非高斯滤波器的概率过滤器，该量子密钥分发协议超越了高斯调制连续可变量子密钥分发协议，实现了更高的密钥速率并提高了安全性，同时无需硬件修改即可与现有系统集成。

Abstract: Quantum key distribution (QKD) provides a promising approach to secure
communications, with continuous-variable QKD (CV-QKD) offering compatibility
with existing telecommunication infrastructure. Despite this advantage, CV-QKD
is limited by challenges such as losses in terrestrial fibres and atmospheric
scintillation in free-space channels. We introduce a QKD protocol that
surpasses the optimal Gaussian modulated CV-QKD (GG02) protocol by utilising
probabilistic filters without known physical representation. Our approach
employs a Gaussian filter at Alice's station and a non-Gaussian notch-like
filter at Bob's station. Alice's filter optimises modulation variance to
achieve key rates near the optimal GG02 performance, while Bob's filter adapts
the effective channel conditions, which can result in higher key rates than the
optimal GG02 protocol. Our security analysis avoids Gaussian extremality,
accurately bounding Eve's information. The protocol dynamically optimises the
secret-key rate for rapidly changing channels, such as terrestrial links and
satellite-to-ground communications, and can extract keys in regions deemed
non-secure by parameter estimation. Implemented at software level, our protocol
requires no hardware modifications and can be integrated into existing QKD
systems. Experimental results show a threefold increase in key rates over the
optimal GG02 protocol, while simulations for Low Earth Orbit satellite quantum
communications indicate a 400-fold increase compared to the non-optimised
counterpart.

</details>


### [358] [Observation of period doubling and higher multiplicities in a driven single-spin system](https://arxiv.org/abs/2507.18387)
*Dhruv Deshmukh,Raúl B. González,Roberto Sailer,Fedor Jelezko,Ressa S. Said,Joachim Ankerhold*

Main category: quant-ph

TL;DR: 量子系统在周期驱动下会产生亚谐波响应。本研究以NV色心为例，在自旋1/2系统中实验证实了周期加倍及更高重数（2-5倍）的亚谐波响应，并发现了其在传感应用中的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是探索和证实量子系统（特别是自旋1/2系统）在外部时域周期场驱动下的亚谐波响应（k倍驱动周期），并验证其在传感协议中的潜在应用。

Method: 本研究基于氮-空位（NV）中心，利用其在环境条件下优越的相干性、强场敏感性和光学可寻址性，在广泛的驱动参数范围内监测了相干的k重周期振荡。

Result: 实验观察到了周期加倍（k=2）及更高重数（k=3, 4, 5）的亚谐波响应，并验证了在特定参数范围内存在增强的灵敏度，这可用于改进传感协议。

Conclusion: 本研究通过实验和理论分析，在一个自旋1/2系统中观察到了周期加倍和更高倍数的亚谐波响应（k=2, ..., 5）。

Abstract: One of the prime features of quantum systems strongly driven by external
time-periodic fields is the subharmonic response with integer multiples of the
drive period $k\, T_d$. Here we demonstrate experimentally based on a careful
theoretical analysis period doubling and higher multiplicities ($k=2,\ldots 5$)
for one of the most fundamental systems, namely, an individual spin-$1/2$.
Realized as a nitrogen vacancy center in diamond, the particular coherence
properties under ambient conditions, strong field sensitivity, and optical
addressability allow to monitor coherent $k$-tupling oscillations over a broad
set of driving parameters in the vicinity of the ideal manifolds. We verify an
enhanced sensitivity within this domain which provides new means for improved
sensing protocols.

</details>


### [359] [Entanglement certification by measuring nonlocality](https://arxiv.org/abs/2507.18066)
*Xuan Du Trinh,Zhengyu Wu,Junlin Bai,Huan-Hsin Tseng,Nengkun Yu,Aruna Balasubramanian*

Main category: quant-ph

TL;DR: 该研究提出了一种基于CHSH不等式违反的实用纠缠验证方法，建立了CHSH度量与纠缠保真度之间的数学关系，并开发了优化资源利用率和可靠性的统计方法。模拟结果为在资源受限的量子网络中实现高效纠缠验证提供了指导。


<details>
  <summary>Details</summary>
Motivation: 可靠的纠缠操纵是量子网络的关键，需要实用的纠缠验证方法。

Method: 提出了一种基于Clauser-Horne-Shimony-Holt（CHSH）不等式违反的纠缠验证方法，并建立了CHSH度量与纠缠保真度之间的数学关系，同时开发了优化资源利用率并保持验证可靠性的统计方法。

Result: 开发了使用CHSH度量的纠缠保真度精确边界，以及用于估计样本复杂性的统计框架和可量化置信度的验证协议。NetSquid模拟显示了验证准确性、资源效率和操作参数之间的关键权衡。

Conclusion: 该研究为资源受限的量子网络提供了切实可行的指导，用于在安全性和实际限制之间取得平衡，以实现高效的纠缠验证。

Abstract: Reliable entanglement manipulation is key to quantum networks. This paper
presents a practical approach to entanglement verification based on
Clauser-Horne-Shimony-Holt (CHSH) inequality violation. We establish
mathematical bounds relating the CHSH measure to entanglement fidelity and
develop statistical methods that optimize resource usage while maintaining
verification reliability. Our main contributions include tight bounds on
entanglement fidelity using the CHSH measure, a statistical framework for
estimating sample complexity, and practical verification protocols with
quantifiable confidence. Using NetSquid simulations, we comprehensively
evaluated our protocols under various network conditions, demonstrating the key
trade-offs between verification accuracy, resource efficiency, and operational
parameters. Our results provide concrete guidance for implementing efficient
entanglement verification in resource-constrained quantum networks, balancing
security requirements with practical limitations.

</details>


### [360] [Magnetic Memory and Hysteresis from Quantum Transitions: Theory and Experiments on Quantum Annealers](https://arxiv.org/abs/2507.18079)
*Frank Barrows,Elijah Pelofske,Pratik Sathe,Francesco Caravelli,Cristiano Nisoli*

Main category: quant-ph

TL;DR: 提出了一种新的理论框架，解释了量子退火中的量子滞后现象，并在 D-Wave 硬件上得到验证。


<details>
  <summary>Details</summary>
Motivation: 理解 D-Wave 模拟量子硬件中大规模横向场伊辛系统中的鲁棒磁滞现象的量子本质。

Method: 结合 Landau-Zener 跃迁（一阶分段常数传播子）和半经典畴壁动力学，并在 D-Wave 量子退火器上进行实验测试，分析了具有多达 4,906 个量子比特的系统。

Result: 提出的框架能够重现实验数据中观察到的扭结密度、磁滞回线形状和纵向扫描速率依赖趋势，并捕捉到了奇特的非单调特征和瞬态负磁化率，将其确认为真实的量子记忆效应。

Conclusion: 该研究提出了一个结合 Landau-Zener 跃迁和半经典畴壁动力学的概念框架，用于解释量子退火中观察到的滞后现象，并成功在 D-Wave 量子退火器上进行了实验验证，捕捉到了量子迟滞效应。

Abstract: Quantum annealing leverages quantum tunneling for non-local searches, thereby
minimizing memory effects that typically arise from metastabilities.
Nonetheless, recent work has demonstrated robust hysteresis in large-scale
transverse-field Ising systems implemented on D-Wave's analog quantum hardware.
The quantum nature of these intriguing results remains to be understood at a
deeper level. Here, we present a conceptual framework that explains the
observed behavior by combining two-level Landau-Zener transitions via a
first-order piecewise-constant propagator with semiclassical domain-wall
kinetics. We test this approach experimentally on a quantum annealer, where we
observe clear coercivity even in one-dimensional rings with periodic boundary
conditions comprising up to 4,906 qubits-regimes where classical hysteresis is
forbidden, but quantum hysteresis is not. Our framework reproduces the measured
kink densities, hysteresis loop shapes, and longitudinal sweep-rate scaling
trends observed in data from three different D-Wave quantum annealers. In
particular, it captures striking non-monotonic features and transiently
negative susceptibilities, identifying them as genuine quantum memory effects.
These results establish programmable quantum annealers as powerful testbeds for
exploring memory-endowed non-equilibrium dynamics in quantum many-body systems.

</details>


### [361] [An Initialization-free Quantum Algorithm for General Abelian Hidden Subgroup Problem](https://arxiv.org/abs/2507.18088)
*Sekang Kwon,Jeong San Kim*

Main category: quant-ph

TL;DR: 一种无需初始化即可解决有限阿贝尔群隐蔽子群问题的量子算法，可恢复辅助寄存器状态以提高效率。


<details>
  <summary>Details</summary>
Motivation: 为了提高量子算法效率，通过减少初始化操作时间来解决隐蔽子群问题。

Method: 提出了一种无需初始化即可解决有限阿贝尔群隐蔽子群问题的量子算法，该算法可以使用任意未知混合态作为辅助寄存器。

Result: 该算法在保留可比肩现有方法计算成本的同时，能够恢复辅助寄存器的状态，使其可重复利用。

Conclusion: 该算法为有限阿贝尔群中的隐蔽子群问题提供了一种无需初始化即可解决的方法，并能恢复辅助寄存器的状态，可用于其他操作，从而提高量子算法效率。

Abstract: Hidden Subgroup Problem(HSP) seeks to identify an unknown subgroup H of a
group G for a given injective function f defined on cosets of H. Here we
present an initialization-free quantum algorithm for solving HSP in the case
where G is a finite abelian group. Our algorithm can adopt an arbitrary unknown
mixed state as the auxiliary register and removes the need for initialization
while preserving computational cost comparable to existing methods. Our
algorithm also restores the state of the auxiliary register to its original
form after completing the computations. Since the recovered state can be
utilized for other operations, a single preparation of the auxiliary register
in an arbitrarily unknown mixed state is sufficient to execute the iterative
procedure in solving hidden subgroup problems. This approach provides a
promising direction for improving quantum algorithm efficiency by reducing
operational time of initialization.

</details>


### [362] [Advancing the hBN Defects Database through Photophysical Characterization of Bulk hBN](https://arxiv.org/abs/2507.18093)
*Chanaprom Cholsuk,Sujin Suwanna,Tobias Vogl*

Main category: quant-ph

TL;DR: 本文构建了一个包含600个块状hBN缺陷及其光物理性质的数据库，以解决理论与实验之间的差距，并支持机器学习在量子材料中的应用。


<details>
  <summary>Details</summary>
Motivation: 大多数理论研究模拟的是单层hBN，因为这在计算上比计算块状结构更便宜。然而，大多数实验研究是在多层到块状hBN上进行的，这在理论和实验之间造成了差异。因此，需要一个包含块状hBN缺陷的全面数据库。

Method: 我们提出了一个扩展的hBN缺陷数据库，包括了一组全面的块状hBN缺陷及其激发态光物理性质。该数据库包含超过120个中性缺陷，并系统地评估了从-2到2的电荷态（总共600个缺陷）。对于每个缺陷，我们确定了最稳定的电荷和自旋构型，并计算了零声子线、光致发光光谱、吸收光谱、黄锐斯因子、相互作用的辐射寿命、跃迁偶极矩和极化特性。

Result: 我们的分析表明，电子-声子耦合强度主要受空位的影响，空位往往会引起更强的晶格畸变并拓宽声子侧带。此外，相关性分析表明，虽然大多数性质是独立的，但黄锐斯因子与构型坐标密切相关。所有数据均可在https://h-bn.info公开获取，并提供了一个新的应用程序编程接口（API）以方便与机器学习工作流集成。

Conclusion: 该数据库旨在弥合理论与实验之间的差距，有助于可靠地识别量子发射体，并支持量子材料研究中机器学习驱动的方法的发展。

Abstract: Quantum emitters in hexagonal boron nitride (hBN) have gained significant
attention due to a wide range of defects that offer high quantum efficiency and
single-photon purity at room temperature. Most theoretical studies on hBN
defects simulate monolayers, as this is computationally cheaper than
calculating bulk structures. However, most experimental studies are carried out
on multilayer to bulk hBN, which creates additional possibilities for
discrepancies between theory and experiment. In this work, we present an
extended database of hBN defects that includes a comprehensive set of bulk hBN
defects along with their excited-state photophysical properties. The database
features over 120 neutral defects, systematically evaluated across charge
states ranging from -2 to 2 (600 defects in total). For each defect, the most
stable charge and spin configurations are identified and used to compute the
zero-phonon line, photoluminescence spectrum, absorption spectrum, Huang-Rhys
(HR) factor, interactive radiative lifetimes, transition dipole moments, and
polarization characteristics. Our analysis reveals that the electron-phonon
coupling strength is primarily influenced by the presence of vacancies, which
tend to induce stronger lattice distortions and broaden phonon sidebands.
Additionally, correlation analysis shows that while most properties are
independent, the HR factor strongly correlates with the configuration
coordinates. All data are publicly available at https://h-bn.info, along with a
new application programming interface (API) to facilitate integration with
machine learning workflows. This database is therefore designed to bridge the
gap between theory and experiment, aid in the reliable identification of
quantum emitters, and support the development of machine-learning-driven
approaches in quantum materials research.

</details>


### [363] [Silicon single-photon detector achieving over 84% photon detection efficiency with flexible operation modes](https://arxiv.org/abs/2507.18172)
*Dong An,Chao Yu,Ming-Yang Zheng,Anran Guo,Junsong Wang,Ruizhi Li,Huaping Ma,Xiu-Ping Xie,Xiao-Hui Bao,Qiang Zhang,Jun Zhang,Jian-Wei Pan*

Main category: quant-ph

TL;DR: 我们开发了一种硅单光子探测器（Si SPD），在785 nm处具有高达84.4%的PDE，并支持多种操作模式。


<details>
  <summary>Details</summary>
Motivation: 为了提高光子探测效率（PDE），这是收集光子的关键特性。

Method: 通过设计和制造厚结硅单光子雪崩二极管（SPAD），采用背部入射结构提高雪崩概率，并通过掺杂补偿雪崩区域来最小化噪声。读出电路由50 V淬灭电压实现，支持自由运行、门控或混合模式。

Result: 在自由运行模式下，探测器实现了84.4%的最大PDE，暗计数率为260 cps，268 K下的延时后脉冲概率为2.9%。

Conclusion: 这项工作为需要超高效率、多工作模式的硅单光子探测器提供了实用的解决方案。

Abstract: Silicon single-photon detectors (Si SPDs) play a crucial role in detecting
single photons in the visible spectrum. For various applications, photon
detection efficiency (PDE) is the most critical characteristic for effectively
collecting photons. Here, we present a Si SPD with a remarkable PDE of up to
84.4% at 785 nm, supporting multiple operation modes. We design and fabricate a
thick-junction Si single-photon avalanche diode (SPAD) that enhances the
avalanche probability through a backside-illumination structure, while
minimizing noise through the design of a doping-compensated avalanche region.
To maximize PDE, we implement a readout circuit with a 50 V quenching voltage,
enabling operation in free-running, gating, or hybrid modes. The SPAD, along
with its readout circuits and affiliated circuits, is integrated into a compact
SPD module. In free-running mode, the module achieves a maximum PDE of 84.4%,
with a dark count rate of 260 cps, and an afterpulse probability of 2.9% at 268
K. This work provides a practical solution for applications requiring
ultra-high-efficiency Si SPD with multiple operation modes.

</details>


### [364] [Optimal Quantum $(r,δ)$-Locally Repairable Codes via Classical Ones](https://arxiv.org/abs/2507.18175)
*Kun Zhou,Meng Cao*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Locally repairable codes (LRCs) play a crucial role in mitigating data loss
in large-scale distributed and cloud storage systems. This paper establishes a
unified decomposition theorem for general optimal $(r,\delta)$-LRCs. Based on
this, we obtain that the local protection codes of general optimal
$(r,\delta)$-LRCs are MDS codes with the same minimum Hamming distance
$\delta$. We prove that for general optimal $(r,\delta)$-LRCs, their minimum
Hamming distance $d$ always satisfies $d\geq \delta$. We fully characterize the
optimal quantum $(r,\delta)$-LRCs induced by classical optimal
$(r,\delta)$-LRCs that admit a minimal decomposition. We construct three
infinite families of optimal quantum $(r,\delta)$-LRCs with flexible
parameters.

</details>


### [365] [Data Transmission over a Bosonic Arbitrarily Varying Quantum Channel](https://arxiv.org/abs/2507.18259)
*Janis Nötzel,Florian Seitz*

Main category: quant-ph

TL;DR: 本文研究了量子通信在存在干扰下的鲁棒性问题，并针对特定类型的信道和干扰，给出了其通信容量的计算公式。


<details>
  <summary>Details</summary>
Motivation: 分析任意变化的信道对于理解量子通信的鲁棒性至关重要，特别是针对半经典攻击。

Method: 通过将问题建模为光束分离器设置，并结合一个假定的量子熵功率不等式来推导容量公式。

Result: 得出了有损耗玻色子信道在半经典攻击下的显式容量公式，并展示了该公式与新的量子熵功率不等式的联系。

Conclusion: 该论文为一类重要的实际任意变化的信道模型提供了编码定理，特别是针对有损耗的玻色子信道在半经典攻击下的容量进行了显式计算。

Abstract: Arbitrarily varying channels offer a powerful framework for analyzing the
robustness of quantum communication systems, especially for classical-quantum
models, where the analysis displays strengths or weaknesses of specific signal
constellations under generic attacks. In this work, we provide a coding theorem
for a large class of practically relevant arbitrarily varying channel models.
Namely, we give an explicit capacity formula for the lossy bosonic channel
subject to semi-classical attacks, where an adversary injects semi-classical
states into the transmission line. Mathematically, this is modeled via a
beam-splitter setup, with transmitter and jammer controlling different input
ports and the receiver observing one output port. We show how a recently
conjectured new quantum entropy power inequality relates to our capacity
formula.

</details>


### [366] [Non-equilibrium Dynamics of Three-Level Absorption Refrigerator at Third-Order Liouvillian Exceptional Points](https://arxiv.org/abs/2507.18261)
*Jingyi Gao,Naomichi Hatano*

Main category: quant-ph

TL;DR: 研究了三能级量子吸收制冷机中的孤立点（LEPs），发现在三阶LEPs处系统能更快达到平衡，且制冷机性能更优。


<details>
  <summary>Details</summary>
Motivation: 旨在研究三能级量子吸收制冷机中的孤立点（LEPs）对非平衡过程的影响，特别是其在系统状态和热流阻尼中的作用，以期优化制冷机的性能。

Method: 通过解析和数值方法，研究了三能级量子吸收制冷机中孤立点（LEPs）对非平衡过程的影响。重点分析了三阶LEPs的系统状态和热流阻尼特性，并研究了非平衡过程对冷浴抽热的影响。

Result: 发现了二阶和三阶LEPs；证明了系统状态和热流在三阶LEPs处达到临界阻尼，实现了最快的收敛；揭示了在三阶LEPs处，非平衡过程能够以更低的功耗实现更大的热量传递。

Conclusion: 在三阶孤立点的超临界阻尼现象证明了最快收敛到平衡态，并且在非平衡过程中，与两浴体系相比，冷热浴之间的热传递大大增加，同时功浴的能量消耗却大大减小，证明了该装置的优越性能。

Abstract: We analyze the influence of Liouvillian exceptional points (LEPs) in the
three-level quantum absorption refrigerator, putting emphasis on the
non-equilibrium process before the convergence to the steady state. We search
for the second-order and third-order LEPs in the system with two types of
couplings. Focusing on the third-order LEPs, we analyze the damping of the
system state in the long term analytically and numerically. In addition, we
analyze the damping of heat currents and the influence of the non-equilibrium
process in the heat extraction from the cold bath. Critical damping at LEPs of
both the system state and the heat currents is achieved, implying the fastest
convergence to the equilibrium system. During the non-equilibrium process, we
find that much heat transfer from the cold bath to the hot bath with less
energy cost of the work bath is achieved at the third-order LEP, leading to
better performance of the refrigerator.

</details>


### [367] [Partial trace relations beyond normal matrices](https://arxiv.org/abs/2507.18278)
*Pablo Costa Rico,Michael M. Wolf*

Main category: quant-ph

TL;DR: This paper studies partial traces and their dilations for complex matrices, finding new inequalities and applications to quantum states and maps.


<details>
  <summary>Details</summary>
Motivation: To investigate the relationship between partial traces and their dilations for general complex matrices, paying particular attention to rank constraints.

Method: We investigate the relationship between partial traces and their dilations for general complex matrices, focusing on the existence of (joint) dilations and norm inequalities relating partial traces and their dilations. A central ingredient for this is a novel majorization relation for Kronecker sums.

Result: Every pair of matrices of equal size and trace admits dilations of any rank larger than one. We generalize Audenaert's subadditivity inequality to encompass general matrices, multiple tensor factors, and different norms.

Conclusion: We generalize Audenaert's subadditivity inequality and extend the interval of Werner states for which they are provably 2-undistillable in any dimension d>=4. We also prove new Schmidt-number witnesses and k-positive maps.

Abstract: We investigate the relationship between partial traces and their dilations
for general complex matrices, focusing on two main aspects: the existence of
(joint) dilations and norm inequalities relating partial traces and their
dilations. Throughout our analysis, we pay particular attention to rank
constraints. We find that every pair of matrices of equal size and trace admits
dilations of any rank larger than one. We generalize Audenaert's subadditivity
inequality to encompass general matrices, multiple tensor factors, and
different norms. A central ingredient for this is a novel majorization relation
for Kronecker sums. As an application, we extend the interval of Werner states
in which they are provably 2-undistillable in any dimension $d\geq4$. We also
prove new Schmidt-number witnesses and $k$-positive maps.

</details>


### [368] [Certifying non-classicality and non-Gaussianity through optical parametric amplification](https://arxiv.org/abs/2507.18296)
*Mahmoud Kalash,Marcello H. M. Passos,Éva Rácz,László Ruppert,Radim Filip,Maria V. Chekhova*

Main category: quant-ph

TL;DR: 本文提出了一种利用光学参量放大和强度探测器认证非高斯态的新方法，无需光子数分辨，可为高维量子技术提供基础。


<details>
  <summary>Details</summary>
Motivation: 为了简化量子信息协议中认证非高斯态的过程，提出了一种无需光子数分辨能力的新方法。

Method: 提出了一种利用光学参量放大结合传统强度探测器来测量放大态的平均光子数和二阶关联函数，并以此认证非高斯态的方法。

Result: 成功认证了信号准单光子态的非高斯性。

Conclusion: 本文证明了光学参量放大结合传统强度探测器可以有效替代基于光子数测量的方法来认证非高斯态，且无需光子数分辨能力。

Abstract: Non-Gaussian states of light are essential for numerous quantum information
protocols; thus, certifying non-Gaussianity is crucial. Full quantum state
tomography achieves this, but it implies observing the Wigner function
negativity, which requires efficient detection. Certifying non-Gaussianity
through directly measurable parameters is a simpler alternative, typically
achieved by measuring photon-number probabilities - either directly using
photon-number resolving detectors or through Hanbury Brown-Twiss type
measurements with single-photon detectors. Here, we demonstrate theoretically
and experimentally that optical parametric amplification combined with
conventional intensity detectors can effectively replace this approach without
the need for photon-number resolution. In our method, we measure the mean
photon number and the second-order correlation function for the amplified
state. Using it, we successfully certify the non-Gaussianity of a heralded
quasi-single-photon state. Since optical parametric amplification is a
multimode process, our method provides a foundation for developing
high-dimensional quantum technologies utilizing multimode non-Gaussian states.

</details>


### [369] [Probing metric fluctuations with the spin of a particle: a quantum simulation with bimodal optical cavities](https://arxiv.org/abs/2507.18351)
*Jiannis K. Pachos,Patricio Salgado-Rebolledo,Martine Schut*

Main category: quant-ph

TL;DR: 本研究利用（2+1）D 大质量引力玩具模型与狄拉克费米子研究时空涨落对费米子自旋演化的影响，并提出了一个基于光学腔的实验方案，可用于探测量子引力与物质的相互作用。


<details>
  <summary>Details</summary>
Motivation: 探索量子引力潜在的经验表现形式是一个具有挑战性的课题。本研究旨在模拟量子引力与物质的相互作用，并为实验探测提供理论基础。

Method: 利用（2+1）D 大质量引力玩具模型与狄拉克费米子在格子中进行相互作用，该模型能够支持特定的时空涨落。研究重点关注费米子自旋如何因其与时空涨落的耦合而演化。为此，构建了一个包含两个描述时空几何涨落的玻色子模式以及费米子自旋的最小模型。

Result: 观察到费米子自旋根据其与时空涨落的相互作用表现出多种演化模式。

Conclusion: 该研究提出了一种新颖的模拟方法，用于模拟量子引力与物质之间的相互作用，并提出了一个可用于当前技术探测的实验方案。

Abstract: Exploring potential empirical manifestations of quantum gravity is a
challenging pursuit. In this study, we utilise a lattice representation of a
(2+1)D massive gravity toy model interacting with Dirac fermions that can
support specific spacetime fluctuations. We focus on the evolution of the
fermion's spin due to its coupling to spacetime fluctuations. To monitor their
dynamics a minimal model is required that comprises two bosonic modes
describing spacetime geometry fluctuations coupled with the spin of the
fermion. A possible emulation of this system involves encoding spin degrees of
freedom in an atom coupled with a bimodal optical cavity that provides the two
bosonic modes. We observe diverse spin evolution patterns based on its
interaction with fluctuating spacetime geometry. Our proposal introduces a
novel approach for modelling the effect of interactions between quantum gravity
and matter that can be probed with current technology.

</details>


### [370] [The Quantum Foucault Modes](https://arxiv.org/abs/2507.18420)
*Samuel Alperin*

Main category: quant-ph

TL;DR: 量子谐振子在特定驱动下行为类似傅科摆，并展现出一种独特的、在经典力学中被禁止的量子现象。


<details>
  <summary>Details</summary>
Motivation: 研究驱动量子谐振子在非厄米、PT对称驱动下的行为，并探索其与经典傅科摆的联系，以及揭示新型量子动力学。

Method: 通过研究非厄米、PT对称驱动下的量子谐振子，并将其与经典傅科摆的轨迹进行比较，来分析其动力学行为。

Result: 量子谐振子在非厄米、PT对称驱动下的Wigner空间轨迹与经典傅科摆的实空间轨迹相同。特别地，在映射自平凡一维摆的情况下，量子动力学表现为动量周期性演化但位置固定，这在经典系统中是不可能实现的。

Conclusion: 该研究表明，在非厄米、PT对称的驱动下，量子谐振子与经典傅科摆之间存在深刻的联系，并且揭示了一种禁止在经典系统中出现的、具有周期性演化动量但固定位置的新型量子动力学。

Abstract: The driven quantum harmonic oscillator is fundamental to a number of
important physical systems. Here, we consider the quantum harmonic oscillator
under non-Hermitian, PT-symmetric driving, showing that the resulting set of
Wigner-space trajectories of an initial coherent state is identical to the set
of real-space trajectories of the classical Foucault pendulum. Remarkably, in
the case mapped from the trivial 1D pendulum, the corresponding quantum
dynamics are those of an oscillator with periodically evolving momentum but
fixed position, a novel type of dynamics which are forbidden in classical
systems.

</details>


### [371] [Quantum Machine Learning for Predicting Binding Free Energies in Structure-Based Virtual Screening](https://arxiv.org/abs/2507.18425)
*Pei-Kun Yang*

Main category: quant-ph

TL;DR: 利用量子机器学习加速蛋白质-配体结合自由能预测，该方法在近中期量子硬件上表现出良好性能。


<details>
  <summary>Details</summary>
Motivation: 在基于结构的虚拟筛选中，评估蛋白质-配体复合物的结合自由能时，需要考虑分子构象以及它们在空间中的平移和旋转。然而，这会迅速增加计算的复杂性。量子计算因其固有的并行性，为解决这一挑战提供了有前景的替代方案。

Method: 本研究介绍了一种量子机器学习方法，将分子信息编码为量子态，并使用参数化量子门进行处理。该模型使用PyTorch实现和训练，并在理想模拟、有限采样和量子噪声模拟三种设置下进行评估。

Result: 在六个量子比特单元下，该模型实现了2.37 kcal/mol的均方根偏差（RMSD）和0.650的皮尔逊相关系数。即使在100,000次采样的情况下，预测也保持一致。量子噪声会略微降低精度，但配体亲和力的排名基本保持不变。

Conclusion: 这项研究提出了一种量子机器学习方法，用于评估蛋白质-配体复合物的结合自由能，该方法在实际应用中具有可扩展性和鲁棒性，有望加速虚拟筛选。

Abstract: In structure-based virtual screening, it is often necessary to evaluate the
binding free energy of protein-ligand complexes by considering not only
molecular conformations but also how these structures shift and rotate in
space. The number of possible combinations grows rapidly and can become
overwhelming. While classical computing has limitations in this context,
quantum computing offers a promising alternative due to its inherent
parallelism. In this study, we introduce a quantum machine learning approach
that encodes molecular information into quantum states and processes them using
parameterized quantum gates. The model is implemented and trained using
PyTorch, and its performance is evaluated under three settings: ideal
simulation, limited-shot sampling, and simulations with quantum noise. With six
quantum circuit units, the model achieves an RMSD of 2.37 kcal/mol and a
Pearson correlation of 0.650. Even when using 100,000 shots, the predictions
remain consistent, indicating that the model is compatible with near-term
quantum hardware. Although noise slightly reduces accuracy, the ranking of
ligand affinities remains largely unchanged. These findings point to a
practical and scalable strategy that balances robustness and predictive power,
offering a viable path to accelerate virtual screening through moderately deep
quantum circuits.

</details>


### [372] [Three-qubit encoding in ytterbium-171 atoms for simulating 1+1D QCD](https://arxiv.org/abs/2507.18426)
*William Huie,Cianan Conefrey-Shinozaki,Zhubing Jia,Patrick Draper,Jacob P. Covey*

Main category: quant-ph

TL;DR: 通过将三个量子比特编码到单个原子（镥-171）的不同自由度，实现核物质的资源高效量子模拟。


<details>
  <summary>Details</summary>
Motivation: 核物质的量子模拟因夸克自由度的复杂性（如物质/反物质、味、色、自旋）而效率低下，需要更优的资源利用方法。

Method: 通过将三个量子比特编码到单个镥-171原子的不同自由度（电子跃迁、核自旋和运动状态）来构建三量子比特系统，并开发了一系列复合边带脉冲来实现通用门和读出。

Result: 该方法使用两个原子即可模拟单味1+1D轴向规范量子色动力学中的真空持久振荡和弦断裂，并考虑了资源需求和纠错。

Conclusion: 本文提出的编码方式为核物质的资源高效数字模拟提供了一种新方法，并为中性原子量子处理器中的通用量子比特编码开辟了新机遇。

Abstract: Simulating nuclear matter described by quantum chromodynamics using quantum
computers is notoriously inefficient because of the assortment of quark degrees
of freedom such as matter/antimatter, flavor, color, and spin. Here, we propose
to address this resource efficiency challenge by encoding three qubits within
individual ytterbium-171 atoms of a neutral atom quantum processor. The three
qubits are encoded in three distinct sectors: an electronic "clock" transition,
the spin-1/2 nucleus, and the lowest two motional states in one radial
direction of the harmonic trapping potential. We develop a family of composite
sideband pulses and demonstrate a universal gate set and readout protocol for
this three-qubit system. We then apply it to single-flavor quantum
chromodynamics in 1+1D axial gauge for which the three qubits directly
represent the occupancy of quarks in the three colors. We show that two atoms
are sufficient to simulate both vacuum persistence oscillations and string
breaking. We consider resource requirements and connections to error
detection/correction. Our work is a step towards resource-efficient digital
simulation of nuclear matter and opens new opportunities for versatile qubit
encoding in neutral atom quantum processors.

</details>


### [373] [Geometric Measures of Complexity for Open and Closed Quantum Systems](https://arxiv.org/abs/2507.18440)
*Alberto Acevedo,Antonio Falco*

Main category: quant-ph

TL;DR: 本文将量子系统的酉动力学视为黎曼流形上的轨迹，并提出了量子计算复杂度的几何解释。在此基础上，为模拟量子噪声的量子通道定义了几何复杂度，并进行了分析。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有理论无法描述非酉动力学（如量子噪声）的几何复杂度的问题。

Method: 通过将量子通道的动力学映射到黎曼流形上，为量子计算的几何复杂度提供了新的视角，并扩展了迈克尔·尼尔森的工作。

Result: 成功地为一类量子通道定义了几何复杂度，为理解和量化噪声对量子计算的影响提供了新的工具。

Conclusion: 为一类通用的量子通道提出了几何复杂度的新定义，并分析了它们的几何复杂度。

Abstract: The unitary dynamics of quantum systems can be modeled as a trajectory on a
Riemannian manifold. This theoretical framework naturally yields a purely
geometric interpretation of computational complexity for quantum algorithms, a
notion originally developed by Michael Nielsen (Circa, 2007). However, for
nonunitary dynamics, it is unclear how one can recover a completely geometric
characterization of Nielsen-like geometric complexity. The main obstacle to
overcome is that nonunitary dynamics cannot be characterized by Lie groups
(which are Riemannian manifolds), as is the case for unitary dynamics. Building
on Nielsen's work, we present a definition of geometric complexity for a fairly
generic family of quantum channels. These channels are useful for modeling
noise in quantum circuits, among other things, and analyze the geometric
complexity of these quantum channels.

</details>


### [374] [Generalised state space geometry in Hermitian and non-Hermitian quantum systems](https://arxiv.org/abs/2507.18486)
*Kunal Pal*

Main category: quant-ph

TL;DR: 本研究将信息几何推广到量子领域，通过修改量子态空间的几何结构，构建了广义对偶联络，并成功应用于非厄米量子系统动力学和量子自然梯度下降优化。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索修改量子态空间上的厄米张量结构对几何形状的影响，并尝试将经典信息几何中的对偶联络概念推广到量子领域，以期找到与经典概率分布函数相对应的量子几何结构。

Method: 本研究探索了修改投影空间上的厄米张量结构如何影响纯量子态的几何形状，以及此类推广是否可以用来定义与经典概率分布函数直接对应的对偶联络，并通过非平凡相位进行修改。研究人员通过构建联络族，利用双正交形式主义对张量进行了分类，并识别了度量和贝里曲率。

Result: 研究表明，可以构建一族在Fubini-Study张量的实值部分上广义对偶的联络。利用该双正交形式主义，研究人员系统地分类了由非厄米哈密顿量决定的量子系统动力学中出现的四种张量，并识别了复值度量和贝里曲率。此外，研究还阐明了度量在量子自然梯度下降优化问题中的作用，并将其推广到了非厄米情况。

Conclusion: 本研究成功构建了一族在Fubini-Study张量的实值部分上广义对偶的联络，并利用这种双正交形式主义系统地分类了由非厄米哈密顿量决定的量子系统动力学中出现的四种张量，同时识别了复值度量和贝里曲率。此外，我们阐明了度量在量子自然梯度下降优化问题中的作用，并将其推广到非厄米情况。

Abstract: One of the key features of information geometry in the classical setting is
the existence of a metric structure and a family of connections on the space of
probability distributions. The uniqueness of the Fisher--Rao metric and the
duality of these connections is at the heart of classical information geometry.
However, these features do not carry over straightforwardly to quantum systems,
where a Hermitian inner product structure on the Hilbert space induces a metric
on the complex projective space of pure states -- the Fubini-Study tensor,
which is preserved under the unitary evolution. In this work, we explore how
modifying the Hermitian tensor structure on the projective space may affect the
geometry of pure quantum states, and whether such generalisations can be used
to define dual connections with a direct correspondence to classical
probability distribution functions, modified by the presence of a non-trivial
phase. We show that it is indeed possible to construct a family of connections
that are dual to each other in a generalised sense with respect to the
real-valued sector of the Fubini--Study tensor. Using this biorthogonal
formalism, we systematically classify the four types of tensors that can arise
when the dynamics of a quantum system are governed by a non-Hermitian
Hamiltonian, identifying both the complex-valued metric and the Berry
curvature. Finally, we elucidate the role of the metric in a quantum natural
gradient descent optimisation problem, generalised to the non-Hermitian case
for a suitable choice of cost function.

</details>


### [375] [The hidden subgroup problem for infinite groups](https://arxiv.org/abs/2507.18499)
*Greg Kuperberg*

Main category: quant-ph

TL;DR: 本文将 Shor 算法推广到离散无限群的隐藏子群问题，证明了其 NP 难性，并提出了新的算法。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探索隐藏子群问题（HSP）在离散无限群中的应用，借鉴 Shor 算法在整数上的成功经验，并为该问题提供新的算法和硬度结果。

Method: 该研究通过借鉴 Shor 算法来探索离散无限群的隐藏子群问题（HSP）。在硬度方面，研究人员证明了 HSP 在有理数加法群和非阿贝尔自由群的正规子群中是 NP 难的。此外，研究还间接将短向量问题的一个版本规约到具有伪多项式查询成本的 Z^k 中的 HSP。在算法方面，研究人员将 Shor-Kitaev 算法推广到 Z^k 中隐藏子群具有缺失秩或无限索引的情况。最后，研究人员为阿贝尔隐藏移位问题（AHShP）提出了一个拉伸指数时间算法，并将其推广到任何有限生成、虚拟阿贝尔群中的 HSP。

Result: 研究表明，HSP 在有理数加法群和非阿贝尔自由群的正规子群中是 NP 难的。此外，还发现短向量问题的一个版本可以间接规约到 Z^k 中具有伪多项式查询成本的 HSP。在算法方面，研究将 Shor-Kitaev 算法推广到了 Z^k 中隐藏子群具有缺失秩或无限索引的情况，并为 AHShP 及其在有限生成、虚拟阿贝尔群中的推广提供了拉伸指数时间算法。

Conclusion: 该研究为离散无限群的隐藏子群问题（HSP）提供了新的算法和硬度结果，并将其推广到具有缺失秩或无限索引的子群。

Abstract: Following the example of Shor's algorithm for period-finding in the integers,
we explore the hidden subgroup problem (HSP) for discrete infinite groups. On
the hardness side, we show that HSP is NP-hard for the additive group of
rational numbers, and for normal subgroups of non-abelian free groups. We also
indirectly reduce a version of the short vector problem to HSP in
$\mathbb{Z}^k$ with pseudo-polynomial query cost. On the algorithm side, we
generalize the Shor-Kitaev algorithm for HSP in $\mathbb{Z}^k$ (with standard
polynomial query cost) to the case where the hidden subgroup has deficient rank
or equivalently infinite index. Finally, we outline a stretched exponential
time algorithm for the abelian hidden shift problem (AHShP), extending prior
work of the author as well as Regev and Peikert. It follows that HSP in any
finitely generated, virtually abelian group also has a stretched exponential
time algorithm.

</details>


### [376] [Tunable Non-Gaussian Mechanical States in a Strongly Coupled Hybrid Quantum System](https://arxiv.org/abs/2507.18571)
*Jugal Talukdar,Scott E. Smart,Prineha Narang*

Main category: quant-ph

TL;DR: 研究了由耦合到机械谐振器的一个或多个量子比特组成的混合系统，并研究了非高斯运动态的产生和控制。


<details>
  <summary>Details</summary>
Motivation: 量子运动态是第二场量子革命的关键组成部分。

Method: 研究了由耦合到机械谐振器的一个或多个量子比特组成的复合系统，该谐振器又与外部驱动的光子腔相互作用，其中非高斯运动态的产生和控制。

Result: 在强耦合机制下，当具有盒式轮廓的随时间变化的外部驱动与无相互作用的相互作用和频率配置相结合时，会产生高度非高斯的量子态，并具有增强的量子Fisher信息。

Conclusion: 该混合架构通过集成非线性相互作用和多个控制参数，为量子控制提供了一个通用的平台，该平台有可能用于先进的量子态工程以及在量子传感、计量和信息处理中的应用。

Abstract: Quantum states of motion are critical components in the second quantum
revolution. We investigate the generation and control of non-Gaussian motional
states in a tripartite hybrid quantum system consisting of a collection of
qubits coupled to a mechanical resonator, which in turn interacts with an
externally driven photonic cavity. This hybrid architecture provides a
versatile platform for quantum control by integrating nonlinear interactions
and multiple control parameters. Operating in the strong coupling regime, we
study the transient dynamics resulting from a time-dependent external drive
that has a boxcar profile. Starting from coherent states in both the mechanical
and cavity subsystems, we show that this drive protocol, combined with
time-independent interaction and frequency configurations, leads to the
emergence of highly non-Gaussian quantum states in the intermediary mechanical
degree of freedom. These states are characterized by a pronounced negative
volume in the Wigner quasi-probability distribution and enhanced quantum Fisher
information, indicative of their quantum utility. We systematically analyze the
impact of the qubit phase, interaction strengths, and drive parameters on the
degree of non-Gaussianity. Our findings underscore the tunability and richness
of this hybrid platform, paving the way for advanced quantum state engineering
and applications in quantum sensing, metrology, and information processing.

</details>


### [377] [Hybrid quantum-classical algorithm for near-optimal planning in POMDPs](https://arxiv.org/abs/2507.18606)
*Gilberto Cunha,Alexandra Ramôa,André Sequeira,Michael de Oliveira,Luís Barbosa*

Main category: quant-ph

TL;DR: QBRL是一种结合量子计算的强化学习算法，能在部分可观察的环境中提供更快的规划。


<details>
  <summary>Details</summary>
Motivation: 为了在部分可观察的环境中，利用量子计算的优势来加速强化学习的决策过程，特别是在环境动力学可以被建模为稀疏贝叶斯网络的情况下。

Method: 提出了一种混合量子-经典的前瞻性算法QBRL（Quantum Bayesian Reinforcement Learning），用于在部分可观察环境中的模型基础强化学习。该算法利用量子拒绝采样和幅度放大来加速稀疏贝叶斯网络上的推理，以进行量子增强的信念更新。

Result: QBRL在稀疏贝叶斯网络上实现了比经典方法更快的规划，并且通过数值实验展示了QBRL相对于其经典对应物的性能。分析了量子计算优势在决策性能上的转化，并指出优势的大小取决于具体的部署设置。

Conclusion: QBRL在部分可观察环境中的模型基础强化学习方面，通过量子增强的信念更新，可以比其经典对应物实现更快的近优规划。该方法在稀疏贝叶斯网络上表现出色，尽管其量子计算优势的大小可能因部署设置而异。

Abstract: Reinforcement learning (RL) provides a principled framework for
decision-making in partially observable environments, which can be modeled as
Markov decision processes and compactly represented through dynamic decision
Bayesian networks. Recent advances demonstrate that inference on sparse
Bayesian networks can be accelerated using quantum rejection sampling combined
with amplitude amplification, leading to a computational speedup in estimating
acceptance probabilities.\\ Building on this result, we introduce Quantum
Bayesian Reinforcement Learning (QBRL), a hybrid quantum-classical look-ahead
algorithm for model-based RL in partially observable environments. We present a
rigorous, oracle-free time complexity analysis under fault-tolerant assumptions
for the quantum device. Unlike standard treatments that assume a black-box
oracle, we explicitly specify the inference process, allowing our bounds to
more accurately reflect the true computational cost. We show that, for
environments whose dynamics form a sparse Bayesian network, horizon-based
near-optimal planning can be achieved sub-quadratically faster through
quantum-enhanced belief updates.
  Furthermore, we present numerical experiments benchmarking QBRL against its
classical counterpart on simple yet illustrative decision-making tasks. Our
results offer a detailed analysis of how the quantum computational advantage
translates into decision-making performance, highlighting that the magnitude of
the advantage can vary significantly across different deployment settings.

</details>


### [378] [Hybrid Reward-Driven Reinforcement Learning for Efficient Quantum Circuit Synthesis](https://arxiv.org/abs/2507.16641)
*Sara Giordano,Kornikar Sen,Miguel A. Martin-Delgado*

Main category: quant-ph

TL;DR: 一种新的强化学习框架，利用Q学习和混合奖励，能高效合成量子电路，实现最小深度和门数量。


<details>
  <summary>Details</summary>
Motivation: 为解决量子比特有限且易受噪声影响的NISQ时代以及未来容错量子计算中，高效合成指定量子态的量子电路这一核心挑战。

Method: 采用基于动作序列的表格式Q学习，结合混合奖励机制（静态奖励+动态惩罚）以及稀疏矩阵表示和状态空间离散化技术，以应对高维量子状态空间的挑战。

Result: 在最多七个量子比特的图态制备任务中，该算法能够持续发现具有最小深度和最优门数量的电路。将框架扩展到通用门集以制备任意量子态时，同样能生成最小深度电路，证明了其鲁棒性和适应性。

Conclusion: 该研究展示了一种基于强化学习的量子电路合成方法，能够高效地生成目标量子态，并在最小深度和门数量方面实现了近乎最优的电路。

Abstract: A reinforcement learning (RL) framework is introduced for the efficient
synthesis of quantum circuits that generate specified target quantum states
from a fixed initial state, addressing a central challenge in both the NISQ era
and future fault-tolerant quantum computing. The approach utilizes tabular
Q-learning, based on action sequences, within a discretized quantum state
space, to effectively manage the exponential growth of the space dimension. The
framework introduces a hybrid reward mechanism, combining a static,
domain-informed reward that guides the agent toward the target state with
customizable dynamic penalties that discourage inefficient circuit structures
such as gate congestion and redundant state revisits. By leveraging sparse
matrix representations and state-space discretization, the method enables
scalable navigation of high-dimensional environments while minimizing
computational overhead. Benchmarking on graph-state preparation tasks for up to
seven qubits, we demonstrate that the algorithm consistently discovers
minimal-depth circuits with optimized gate counts. Moreover, extending the
framework to a universal gate set for arbitrary quantum states, it still
produces minimal depth circuits, highlighting the algorithm's robustness and
adaptability. The results confirm that this RL-driven approach efficiently
explores the complex quantum state space and synthesizes near-optimal quantum
circuits, providing a resource-efficient foundation for quantum circuit
optimization.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [379] [Designing High-Performance and Thermally Feasible Multi-Chiplet Architectures enabled by Non-bendable Glass Interposer](https://arxiv.org/abs/2507.18040)
*Harsh Sharma,Janardhan Rao Doppa,Umit Y. Ogras,Partha Pratim Pande*

Main category: cs.AR

TL;DR: 为解决玻璃内插器多芯片系统尺寸增大带来的翘曲问题，提出了一种热、翘曲和性能感知的协同设计框架，通过架构和封装协同优化，实现了性能提升和功耗降低。


<details>
  <summary>Details</summary>
Motivation: 现有的玻璃内插器在尺寸增大时会出现严重的翘曲问题，从而导致机械应力和可靠性问题，需要新的方法来缓解翘曲引起的弯曲，并为基于玻璃内插器的多芯片系统提供可扩展的性能。

Method: 提出了一种热、翘曲和性能感知的协同设计框架，通过分解表面和嵌入式芯片，以平衡性能、功耗和结构可靠性之间的权衡。

Result: 与传统的 2.5D 系统相比，所提出的设计框架优化后的多芯片架构在执行深度神经网络工作负载时，性能提高了 64.7%，功耗降低了 40%，并且制造成本更低。

Conclusion: 所提出的设计框架通过架构和封装的协同优化，能够平衡性能、功耗和结构可靠性等矛盾的设计目标，为基于玻璃内插器的多芯片系统提供了优化的解决方案。

Abstract: Multi-chiplet architectures enabled by glass interposer offer superior
electrical performance, enable higher bus widths due to reduced crosstalk, and
have lower capacitance in the redistribution layer than current silicon
interposer-based systems. These advantages result in lower energy per bit,
higher communication frequencies, and extended interconnect range. However,
deformation of the package (warpage) in glass interposer-based systems becomes
a critical challenge as system size increases, leading to severe mechanical
stress and reliability concerns. Beyond a certain size, conventional packaging
techniques fail to manage warpage effectively, necessitating new approaches to
mitigate warpage induced bending with scalable performance for glass interposer
based multi-chiplet systems. To address these inter-twined challenges, we
propose a thermal-, warpage-, and performance-aware design framework that
employs architecture and packaging co-optimization. The proposed framework
disintegrates the surface and embedded chiplets to balance conflicting design
objectives, ensuring optimal trade-offs between performance, power, and
structural reliability. Our experiments demonstrate that optimized
multi-chiplet architectures from our design framework achieve up to 64.7%
performance improvement and 40% power reduction compared to traditional 2.5D
systems to execute deep neural network workloads with lower fabrication costs.

</details>


### [380] [Sandwich: Separating Prefill-Decode Compilation for Efficient CPU LLM Serving](https://arxiv.org/abs/2507.18454)
*Juntao Zhao,Jiuru Li,Chuan Wu*

Main category: cs.AR

TL;DR: Sandwich是一种创新的CPU服务引擎，通过区分预填充和解码阶段并优化执行计划，显著提高了LLM服务的吞吐量和降低了延迟。


<details>
  <summary>Details</summary>
Motivation: 现有基于CPU的服务解决方案忽略了LLM推理中预填充和解码阶段的工作负载差异，采用了静态分区和算子级执行，这并非最优。

Method: Sandwich提出了一种以硬件为中心、面向CPU的LLM服务引擎，针对LLM推理的预填充和解码阶段采用了不同的执行计划，并进行了单独优化。

Result: Sandwich在x86和ARM平台上实现了平均2.01倍的吞吐量提升，以及高达3.40倍的单序列服务延迟改善，同时在连续批处理服务中实现了显著的Goodput提升。其GEMM内核性能可与静态编译器相媲美，但内核调优成本却低了三个数量级。

Conclusion: Sandwich在CPU上实现了LLM服务的重大改进，在吞吐量、延迟和资源利用率方面均优于现有解决方案，并大大降低了内核调优成本。

Abstract: Utilizing CPUs to serve large language models (LLMs) is a resource-friendly
alternative to GPU serving. Existing CPU-based solutions ignore workload
differences between the prefill and the decode phases of LLM inference,
applying a static per-NUMA (Non-Uniform Memory Access) node model partition and
utilizing vendor libraries for operator-level execution, which is suboptimal.
We propose Sandwich, a hardware-centric CPU-based LLM serving engine that uses
different execution plans for the prefill and decode phases and optimizes them
separately.
  We evaluate Sandwich across diverse baselines and datasets on five CPU
platforms, including x86 with AVX-2 and AVX-512, as well as ARM with NEON.
Sandwich achieves an average 2.01x throughput improvement and 90% satisfactory
time-to-first-token (TTFT) and time-per-output-token (TPOT) latencies with up
to 3.40x lower requirements in single sequence serving, and significant
improvement in Goodput in continuous-batching serving. The GEMM kernels
generated by Sandwich outperform representative vendor kernels and other
dynamic shape solutions, achieving performance comparable to static compilers
with three orders of magnitude less kernel tuning costs.

</details>


### [381] [PRACtical: Subarray-Level Counter Update and Bank-Level Recovery Isolation for Efficient PRAC Rowhammer Mitigation](https://arxiv.org/abs/2507.18581)
*Ravan Nazaraliyev,Saber Ganjisaffar,Nurlan Nazaraliyev,Nael Abu-Ghazaleh*

Main category: cs.AR

TL;DR: PRACtical是一种优化DDR5 Rowhammer防护机制（PRAC+ABO）的方法，通过改进计数器更新和实现银行级恢复刷新，显著提升了性能和能效，同时不牺牲安全性。


<details>
  <summary>Details</summary>
Motivation: DDR5标准的PRAC（每行激活计数器）和ABO（警报回退）虽然能应对Rowhammer攻击，但PRAC在预充电阶段更新计数器会带来性能开销，而恢复刷新会暂停整个内存通道，影响效率。需要一种性能更优化的方法。

Method: PRACtical通过引入集中式增量电路减少计数器更新延迟，实现计数器更新与其他子阵列的后续行激活重叠。此外，通过DRAM内置寄存器识别受攻击银行，实现银行级粒度，仅暂停受影响银行，而非整个内存通道。

Result: PRACtical平均性能提升8%（最高20%），平均能耗降低19%，并且在面对激进性能攻击时，性能下降不超过6%，同时保持了Rowhammer防护能力。

Conclusion: PRACtical在保持Rowhammer防护的同时，平均性能提升8%（最高20%），降低19%的能耗，并将激进性能攻击引起 的性能下降限制在6%以内。

Abstract: As DRAM density increases, Rowhammer becomes more severe due to heightened
charge leakage, reducing the number of activations needed to induce bit flips.
The DDR5 standard addresses this threat with in-DRAM per-row activation
counters (PRAC) and the Alert Back-Off (ABO) signal to trigger mitigation.
However, PRAC adds performance overhead by incrementing counters during the
precharge phase, and recovery refreshes stalls the entire memory channel, even
if only one bank is under attack.
  We propose PRACtical, a performance-optimized approach to PRAC+ABO that
maintains the same security guarantees. First, we reduce counter update latency
by introducing a centralized increment circuit, enabling overlap between
counter updates and subsequent row activations in other subarrays. Second, we
enhance the $RFM_{ab}$ mitigation by enabling bank-level granularity: instead
of stalling the entire channel, only affected banks are paused. This is
achieved through a DRAM-resident register that identifies attacked banks.
  PRACtical improves performance by 8% on average (up to 20%) over the
state-of-the-art, reduces energy by 19%, and limits performance degradation
from aggressive performance attacks to less than 6%, all while preserving
Rowhammer protection.

</details>


### [382] [Clo-HDnn: A 4.66 TFLOPS/W and 3.78 TOPS/W Continual On-Device Learning Accelerator with Energy-efficient Hyperdimensional Computing via Progressive Search](https://arxiv.org/abs/2507.17953)
*Chang Eun Song,Weihong Xu,Keming Fan,Soumil Jain,Gopabandhu Hota,Haichao Yang,Leo Liu,Kerem Akarvardar,Meng-Fan Chang,Carlos H. Diaz,Gert Cauwenberghs,Tajana Rosing,Mingu Kang*

Main category: cs.AR

TL;DR: Clo-HDnn 是一种用于持续学习的 ODL 加速器，通过结合 HDC、Kronecker HD Encoder 和 WCFE 来优化性能和效率，与现有解决方案相比，能效提高了多达 7.77 倍。


<details>
  <summary>Details</summary>
Motivation: 为新兴的持续学习 (CL) 任务设计了一个片上学习 (ODL) 加速器。

Method: Clo-HDnn 结合了超维计算 (HDC)、低成本克罗内克 HD 编码器和权重聚类特征提取 (WCFE) 来优化准确性和效率。它采用无梯度 CL 来更新和存储知识，并通过编码和比较部分查询超向量来降低复杂性。

Result: Clo-HDnn 在 FE 方面实现了 4.66 TFLOPS/W，在分类器方面实现了 3.78 TOPS/W，与现有的 ODL 加速器相比，能效分别提高了 7.77 倍和 4.85 倍。

Conclusion: Clo-HDnn 在准确性和效率方面进行了优化，与现有的 ODL 加速器相比，在能效方面有了显著的提高。

Abstract: Clo-HDnn is an on-device learning (ODL) accelerator designed for emerging
continual learning (CL) tasks. Clo-HDnn integrates hyperdimensional computing
(HDC) along with low-cost Kronecker HD Encoder and weight clustering feature
extraction (WCFE) to optimize accuracy and efficiency. Clo-HDnn adopts
gradient-free CL to efficiently update and store the learned knowledge in the
form of class hypervectors. Its dual-mode operation enables bypassing costly
feature extraction for simpler datasets, while progressive search reduces
complexity by up to 61% by encoding and comparing only partial query
hypervectors. Achieving 4.66 TFLOPS/W (FE) and 3.78 TOPS/W (classifier),
Clo-HDnn delivers 7.77x and 4.85x higher energy efficiency compared to SOTA ODL
accelerators.

</details>
