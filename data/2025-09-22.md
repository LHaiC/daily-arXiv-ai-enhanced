<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 109]
- [cs.CL](#cs.CL) [Total: 56]
- [cs.ET](#cs.ET) [Total: 1]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.DC](#cs.DC) [Total: 3]
- [cs.AR](#cs.AR) [Total: 1]
- [eess.SP](#eess.SP) [Total: 17]
- [cs.RO](#cs.RO) [Total: 43]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 12]
- [physics.app-ph](#physics.app-ph) [Total: 2]
- [cs.MA](#cs.MA) [Total: 2]
- [eess.SY](#eess.SY) [Total: 12]
- [cs.SI](#cs.SI) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 12]
- [cs.AI](#cs.AI) [Total: 17]
- [quant-ph](#quant-ph) [Total: 41]
- [cs.LG](#cs.LG) [Total: 98]
- [cs.DS](#cs.DS) [Total: 6]
- [cs.GT](#cs.GT) [Total: 3]
- [cs.GR](#cs.GR) [Total: 8]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Exploring the Capabilities of LLM Encoders for Image-Text Retrieval in Chest X-rays](https://arxiv.org/abs/2509.15234)
*Hanbin Ko,Gihun Cho,Inhyeok Baek,Donguk Kim,Joonbeom Koo,Changi Kim,Dongheon Lee,Chang Min Park*

Main category: cs.CV

TL;DR: LLM2VEC4CXR和LLM2CLIP4CXR是针对胸部X光报告的领域适应LLM编码器和双塔框架，旨在解决临床报告的异质性问题，并提高图像-文本对齐的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言预训练模型在放射学领域受到临床报告异质性（如缩写、仅有印象的注释和风格变化）的限制，单纯扩大模型规模并不能带来性能提升，甚至可能损害模型学习。本研究旨在探索大型语言模型（LLM）编码器是否能提供稳健的临床表征，以适应不同风格并更好地指导图像-文本对齐。

Method: 提出LLM2VEC4CXR，一个领域适应的LLM编码器，用于胸部X光报告。在此基础上，构建LLM2CLIP4CXR双塔框架，将LLM2VEC4CXR与视觉主干相结合，以实现图像-文本对齐。

Result: LLM2VEC4CXR在临床文本理解方面优于基于BERT的方法，能够处理缩写和风格变化，并在报告级别指标上实现了强大的临床对齐。LLM2CLIP4CXR利用这些嵌入，提高了检索准确性和面向临床的分数，并且比以前的医疗CLIP变体具有更强的跨数据集泛化能力。

Conclusion: 在1.6M的胸部X光研究数据上训练的模型表明，鲁棒性（而非单纯的规模）是有效多模态学习的关键。本研究发布了模型以支持医学图像-文本表示学习的进一步研究。

Abstract: Vision-language pretraining has advanced image-text alignment, yet progress
in radiology remains constrained by the heterogeneity of clinical reports,
including abbreviations, impression-only notes, and stylistic variability.
Unlike general-domain settings where more data often leads to better
performance, naively scaling to large collections of noisy reports can plateau
or even degrade model learning. We ask whether large language model (LLM)
encoders can provide robust clinical representations that transfer across
diverse styles and better guide image-text alignment. We introduce LLM2VEC4CXR,
a domain-adapted LLM encoder for chest X-ray reports, and LLM2CLIP4CXR, a
dual-tower framework that couples this encoder with a vision backbone.
LLM2VEC4CXR improves clinical text understanding over BERT-based baselines,
handles abbreviations and style variation, and achieves strong clinical
alignment on report-level metrics. LLM2CLIP4CXR leverages these embeddings to
boost retrieval accuracy and clinically oriented scores, with stronger
cross-dataset generalization than prior medical CLIP variants. Trained on 1.6M
CXR studies from public and private sources with heterogeneous and noisy
reports, our models demonstrate that robustness -- not scale alone -- is the
key to effective multimodal learning. We release models to support further
research in medical image-text representation learning.

</details>


### [2] [Fast OTSU Thresholding Using Bisection Method](https://arxiv.org/abs/2509.16179)
*Sai Varun Kodathala*

Main category: cs.CV

TL;DR: 通过利用二分法优化 Otsu 阈值算法，将计算复杂度从 O(L) 降低到 O(log L)，从而提高计算效率。


<details>
  <summary>Details</summary>
Motivation: Otsu 阈值算法在图像分割中至关重要，但其计算效率因需要遍历所有可能的阈值而受到严重限制。

Method: 采用二分法来利用类间方差函数的单峰特性，以优化 Otsu 阈值算法。

Result: 与传统的穷举搜索相比，计算量减少了 91.63%，算法迭代次数减少了 97.21%。二分法在 66.67% 的测试用例中实现了精确的阈值匹配，在 95.83% 的测试用例中偏差在 5 个灰度级以内。

Conclusion: 所提出的优化方法在不影响 Otsu 方法的理论基础或分割质量的情况下，解决了大规模图像处理系统中的关键计算瓶颈，适用于实时应用。

Abstract: The Otsu thresholding algorithm represents a fundamental technique in image
segmentation, yet its computational efficiency is severely limited by
exhaustive search requirements across all possible threshold values. This work
presents an optimized implementation that leverages the bisection method to
exploit the unimodal characteristics of the between-class variance function.
Our approach reduces the computational complexity from O(L) to O(log L)
evaluations while preserving segmentation accuracy. Experimental validation on
48 standard test images demonstrates a 91.63% reduction in variance
computations and 97.21% reduction in algorithmic iterations compared to
conventional exhaustive search. The bisection method achieves exact threshold
matches in 66.67% of test cases, with 95.83% exhibiting deviations within 5
gray levels. The algorithm maintains universal convergence within theoretical
logarithmic bounds while providing deterministic performance guarantees
suitable for real-time applications. This optimization addresses critical
computational bottlenecks in large-scale image processing systems without
compromising the theoretical foundations or segmentation quality of the
original Otsu method.

</details>


### [3] [ViSpec: Accelerating Vision-Language Models with Vision-Aware Speculative Decoding](https://arxiv.org/abs/2509.15235)
*Jialiang Kang,Han Shu,Wenshuo Li,Yingjie Zhai,Xinghao Chen*

Main category: cs.CV

TL;DR: ViSpec通过引入视觉感知推测解码来加速大型视觉语言模型（VLMs）的推理过程，解决了现有方法加速效果有限的问题，并实现了显著的加速效果。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）推测解码技术在视觉语言模型（VLMs）上的应用效果不佳，加速效果有限（<1.5倍），而多模态能力在大模型中日益重要，因此需要改进VLMs的推测解码技术。

Method: ViSpec框架通过以下方式实现加速：1. 使用轻量级视觉适配器模块压缩图像标记，并将其集成到草稿模型的注意力机制中，同时保留原始图像位置信息。2. 提取每个输入图像的全局特征向量，并将其增强到所有后续文本标记中，以提高多模态一致性。3. 通过重新利用现有数据集和使用目标VLM生成扩展输出来创建专门的训练数据集，以解决长响应多模态数据集的稀缺性问题。4. 采用一种训练策略，避免草稿模型利用目标模型隐藏状态的直接访问，从而防止出现“捷径学习”。

Result: ViSpec在VLM推测解码方面实现了首次显著加速，验证了其有效性。

Conclusion: ViSpec框架成功地加速了VLMs的推理过程，解决了现有方法的局限性，并为未来的多模态模型研究开辟了新的可能性。

Abstract: Speculative decoding is a widely adopted technique for accelerating inference
in large language models (LLMs), yet its application to vision-language models
(VLMs) remains underexplored, with existing methods achieving only modest
speedups (<1.5x). This gap is increasingly significant as multimodal
capabilities become central to large-scale models. We hypothesize that large
VLMs can effectively filter redundant image information layer by layer without
compromising textual comprehension, whereas smaller draft models struggle to do
so. To address this, we introduce Vision-Aware Speculative Decoding (ViSpec), a
novel framework tailored for VLMs. ViSpec employs a lightweight vision adaptor
module to compress image tokens into a compact representation, which is
seamlessly integrated into the draft model's attention mechanism while
preserving original image positional information. Additionally, we extract a
global feature vector for each input image and augment all subsequent text
tokens with this feature to enhance multimodal coherence. To overcome the
scarcity of multimodal datasets with long assistant responses, we curate a
specialized training dataset by repurposing existing datasets and generating
extended outputs using the target VLM with modified prompts. Our training
strategy mitigates the risk of the draft model exploiting direct access to the
target model's hidden states, which could otherwise lead to shortcut learning
when training solely on target model outputs. Extensive experiments validate
ViSpec, achieving, to our knowledge, the first substantial speedup in VLM
speculative decoding.

</details>


### [4] [ORCA: Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models](https://arxiv.org/abs/2509.15435)
*Chung-En Johnny Yu,Hsuan-Chih,Chen,Brian Jalaian,Nathaniel D. Bastian*

Main category: cs.CV

TL;DR: ORCA 是一个用于提高大型视觉语言模型（LVLM）的事实准确性和鲁棒性的框架，通过使用小型视觉模型进行测试时结构化推理。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLM）在多模态能力方面表现出色，但容易出现幻觉和对抗性攻击，限制了其在实际应用中的可靠性。

Method: ORCA 框架采用观察-推理-批判-行动（Observe-Reason-Critique-Act）循环，利用多个小型视觉模型（参数量小于 3B）进行测试时结构化推理。它通过提问、验证跨模型不一致性以及迭代优化预测来工作，无需访问模型内部或进行重新训练。ORCA 还可以存储中间推理过程，支持可审计的决策。

Result: 在 POPE 基准测试中，ORCA 将独立 LVLM 的性能提高了 +3.64% 到 +40.67%。在对抗性扰动下，ORCA 在 POPE 基准测试中平均提高了 +20.11% 的准确率。与防御技术结合使用时，ORCA 在对抗性扰动的 AMBER 图像上的性能提升了 +1.20% 到 +48.00%。

Conclusion: ORCA 为构建更可靠、更鲁棒的多模态系统提供了一条有前景的途径，即使在没有对抗性训练或防御机制的情况下，也能实现幻觉缓解和对抗性鲁棒性。

Abstract: Large Vision-Language Models (LVLMs) exhibit strong multimodal capabilities
but remain vulnerable to hallucinations from intrinsic errors and adversarial
attacks from external exploitations, limiting their reliability in real-world
applications. We present ORCA, an agentic reasoning framework that improves the
factual accuracy and adversarial robustness of pretrained LVLMs through
test-time structured inference reasoning with a suite of small vision models
(less than 3B parameters). ORCA operates via an Observe--Reason--Critique--Act
loop, querying multiple visual tools with evidential questions, validating
cross-model inconsistencies, and refining predictions iteratively without
access to model internals or retraining. ORCA also stores intermediate
reasoning traces, which supports auditable decision-making. Though designed
primarily to mitigate object-level hallucinations, ORCA also exhibits emergent
adversarial robustness without requiring adversarial training or defense
mechanisms. We evaluate ORCA across three settings: (1) clean images on
hallucination benchmarks, (2) adversarially perturbed images without defense,
and (3) adversarially perturbed images with defense applied. On the POPE
hallucination benchmark, ORCA improves standalone LVLM performance by +3.64\%
to +40.67\% across different subsets. Under adversarial perturbations on POPE,
ORCA achieves an average accuracy gain of +20.11\% across LVLMs. When combined
with defense techniques on adversarially perturbed AMBER images, ORCA further
improves standalone LVLM performance, with gains ranging from +1.20\% to
+48.00\% across evaluation metrics. These results demonstrate that ORCA offers
a promising path toward building more reliable and robust multimodal systems.

</details>


### [5] [M-PACE: Mother Child Framework for Multimodal Compliance](https://arxiv.org/abs/2509.15241)
*Shreyash Verma,Amit Kesari,Vinayak Trivedi,Anupam Purwar,Ratnesh Jamidar*

Main category: cs.CV

TL;DR: M-PACE 是一个用于多模态内容合规性评估的框架，它利用 MLLM 统一了传统分散的合规性检查流程，在广告合规性评估中表现出色，并引入了包含挑战性样本的人工标注基准。


<details>
  <summary>Details</summary>
Motivation: 传统合规性框架依赖于分散、多阶段的流水线，集成了图像分类、文本提取、音频转录、手工检查和基于规则的合并等独立模块。这种架构碎片化增加了运营开销，阻碍了可扩展性，并阻碍了适应动态指南的效率。多模态大型语言模型 (MLLM) 的出现为在能够联合处理视觉和文本内容的单一通用框架下统一这些工作流程提供了潜力。

Method: M-PACE 是一个多模态参数无关合规引擎框架，它在一个推理过程中评估视觉-语言输入。它采用母子 MLLM 设置，其中更强的父 MLLM 评估子模型的输出，以减少对人工审阅者的依赖。此外，还引入了一个人工标注的基准，其中包含模拟具有视觉障碍和脏话注入等挑战性真实世界条件的增强样本。

Result: M-PACE 在广告合规性评估中表现出色，能够评估 15 个以上的合规性相关属性。与 Gemini 2.5 Pro 相比，使用 Gemini 2.0 Flash 作为子 MLLM 的 M-PACE 将推理成本降低了 31 倍以上（每个图像 0.0005 美元，而 Gemini 2.5 Pro 为 0.0159 美元），同时保持了可比的准确性。

Conclusion: M-PACE 框架利用 MLLM 在单一推理过程中有效评估多模态内容的合规性，从而解决传统方法的局限性。该框架在广告合规性领域取得了显著成果，通过引入成本效益和准确性的权衡，大幅降低了成本并减少了对人工审阅者的依赖。通过人工标注基准的引入，为更严格的评估铺平了道路。

Abstract: Ensuring that multi-modal content adheres to brand, legal, or
platform-specific compliance standards is an increasingly complex challenge
across domains. Traditional compliance frameworks typically rely on disjointed,
multi-stage pipelines that integrate separate modules for image classification,
text extraction, audio transcription, hand-crafted checks, and rule-based
merges. This architectural fragmentation increases operational overhead,
hampers scalability, and hinders the ability to adapt to dynamic guidelines
efficiently. With the emergence of Multimodal Large Language Models (MLLMs),
there is growing potential to unify these workflows under a single,
general-purpose framework capable of jointly processing visual and textual
content. In light of this, we propose Multimodal Parameter Agnostic Compliance
Engine (M-PACE), a framework designed for assessing attributes across
vision-language inputs in a single pass. As a representative use case, we apply
M-PACE to advertisement compliance, demonstrating its ability to evaluate over
15 compliance-related attributes. To support structured evaluation, we
introduce a human-annotated benchmark enriched with augmented samples that
simulate challenging real-world conditions, including visual obstructions and
profanity injection. M-PACE employs a mother-child MLLM setup, demonstrating
that a stronger parent MLLM evaluating the outputs of smaller child models can
significantly reduce dependence on human reviewers, thereby automating quality
control. Our analysis reveals that inference costs reduce by over 31 times,
with the most efficient models (Gemini 2.0 Flash as child MLLM selected by
mother MLLM) operating at 0.0005 per image, compared to 0.0159 for Gemini 2.5
Pro with comparable accuracy, highlighting the trade-off between cost and
output quality achieved in real time by M-PACE in real life deployment over
advertising data.

</details>


### [6] [ProFusion: 3D Reconstruction of Protein Complex Structures from Multi-view AFM Images](https://arxiv.org/abs/2509.15242)
*Jaydeep Rade,Md Hasibul Hasan Hasib,Meric Ozturk,Baboucarr Faal,Sheng Yang,Dipali G. Sashital,Vincenzo Venditti,Baoyu Chen,Soumik Sarkar,Adarsh Krishnamurthy,Anwesha Sarkar*

Main category: cs.CV

TL;DR: ProFusion是一个结合深度学习和原子力显微镜（AFM）的混合框架，用于解决蛋白质复合物（PC）的三维结构预测问题。它利用虚拟AFM生成合成数据，并通过条件扩散模型和神经辐射场（NeRF）进行三维重建，实现了高分辨率、低成本的蛋白质复合物结构预测。


<details>
  <summary>Details</summary>
Motivation: 现有的基于AI的蛋白质结构预测方法在处理涉及多个相互作用蛋白质的大型蛋白质复合物时存在困难，而实验技术（如冷冻电镜）成本高昂且耗时。AFM可以提供高分辨率的高度图，但缺乏足够的训练数据。因此，需要一种能够整合AFM数据并有效预测蛋白质复合物结构的方法。

Method: 开发了一个名为ProFusion的混合框架，该框架结合了深度学习模型和原子力显微镜（AFM）。首先，利用虚拟AFM模拟成像过程，生成了包含约542,000个蛋白质的多视角合成AFM图像数据集。然后，训练了一个条件扩散模型来从无姿态输入合成新视图，并使用实例特定的神经辐射场（NeRF）模型进行三维结构重建。

Result: 重建的三维蛋白质结构平均Chamfer距离在AFM成像分辨率之内，显示出高结构保真度。该方法在实验AFM图像上进行了广泛验证，证明了其在准确、经济高效的蛋白质复合物结构预测方面的潜力。

Conclusion: ProFusion框架通过整合模拟AFM数据和深度学习技术，能够实现高分辨率、低成本的蛋白质复合物结构预测，并可利用AFM实验进行快速迭代验证，为蛋白质复合物结构研究提供了新的解决方案。

Abstract: AI-based in silico methods have improved protein structure prediction but
often struggle with large protein complexes (PCs) involving multiple
interacting proteins due to missing 3D spatial cues. Experimental techniques
like Cryo-EM are accurate but costly and time-consuming. We present ProFusion,
a hybrid framework that integrates a deep learning model with Atomic Force
Microscopy (AFM), which provides high-resolution height maps from random
orientations, naturally yielding multi-view data for 3D reconstruction.
However, generating a large-scale AFM imaging data set sufficient to train deep
learning models is impractical. Therefore, we developed a virtual AFM framework
that simulates the imaging process and generated a dataset of ~542,000 proteins
with multi-view synthetic AFM images. We train a conditional diffusion model to
synthesize novel views from unposed inputs and an instance-specific Neural
Radiance Field (NeRF) model to reconstruct 3D structures. Our reconstructed 3D
protein structures achieve an average Chamfer Distance within the AFM imaging
resolution, reflecting high structural fidelity. Our method is extensively
validated on experimental AFM images of various PCs, demonstrating strong
potential for accurate, cost-effective protein complex structure prediction and
rapid iterative validation using AFM experiments.

</details>


### [7] [CoPAD : Multi-source Trajectory Fusion and Cooperative Trajectory Prediction with Anchor-oriented Decoder in V2X Scenarios](https://arxiv.org/abs/2509.15984)
*Kangyu Wu,Jiaqi Qiao,Ya Zhang*

Main category: cs.CV

TL;DR: CoPAD是一个用于V2X场景下多车道协同轨迹预测的新型轻量级框架，通过融合匈牙利算法、卡尔曼滤波、过去时间注意力（PTA）模块、模式注意力模块和基于锚点的解码器（AoD），实现了高精度、高完整性的轨迹预测，并在DAIR-V2X-Seq数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 单车感知的不稳定性限制了轨迹预测的效果，因此需要一种能够融合多源数据并提高预测准确性和多样性的协同轨迹预测方法。

Method: 提出CoPAD框架，包含：1. 基于匈牙利算法和卡尔曼滤波的融合模块，用于多源轨迹数据的早期融合；2. PTA模块，捕捉历史轨迹间的交互信息；3. 模式注意力模块，增强预测的多样性；4. 基于稀疏锚点的AoD解码器，生成完整轨迹。

Result: CoPAD在DAIR-V2X-Seq数据集上实现了最先进的性能，证明了其在V2X场景下协同轨迹预测的有效性。

Conclusion: CoPAD通过有效的融合和注意力机制，显著提高了V2X场景下协同轨迹预测的性能，克服了单车感知不稳定的限制。

Abstract: Recently, data-driven trajectory prediction methods have achieved remarkable
results, significantly advancing the development of autonomous driving.
However, the instability of single-vehicle perception introduces certain
limitations to trajectory prediction. In this paper, a novel lightweight
framework for cooperative trajectory prediction, CoPAD, is proposed. This
framework incorporates a fusion module based on the Hungarian algorithm and
Kalman filtering, along with the Past Time Attention (PTA) module, mode
attention module and anchor-oriented decoder (AoD). It effectively performs
early fusion on multi-source trajectory data from vehicles and road
infrastructure, enabling the trajectories with high completeness and accuracy.
The PTA module can efficiently capture potential interaction information among
historical trajectories, and the mode attention module is proposed to enrich
the diversity of predictions. Additionally, the decoder based on sparse anchors
is designed to generate the final complete trajectories. Extensive experiments
show that CoPAD achieves the state-of-the-art performance on the DAIR-V2X-Seq
dataset, validating the effectiveness of the model in cooperative trajectory
prediction in V2X scenarios.

</details>


### [8] [Multi-Modal Interpretability for Enhanced Localization in Vision-Language Models](https://arxiv.org/abs/2509.15243)
*Muhammad Imran,Yugyung Lee*

Main category: cs.CV

TL;DR: MMEL框架通过引入分层语义关系模块，增强了视觉-语言模型的可解释性，提高了其在安全关键应用中的可靠性。


<details>
  <summary>Details</summary>
Motivation: 安全关键领域对视觉-语言模型的可解释性、透明度和可靠性提出了更高要求，现有模型难以满足这些需求。

Method: MMEL框架结合了梯度解释（Grad-eclip）和新提出的分层语义关系模块，该模块通过多尺度特征处理、自适应注意力加权和跨模态对齐来增强模型可解释性。

Result: MMEL生成的解释性可视化结果更聚焦、更具情境感知能力，能更好地反映模型处理复杂场景的方式，并且在标准数据集上进行了验证。

Conclusion: MMEL框架可以推广到不同领域，为需要高可解释性和可靠性的应用提供了有价值的模型决策见解。

Abstract: Recent advances in vision-language models have significantly expanded the
frontiers of automated image analysis. However, applying these models in
safety-critical contexts remains challenging due to the complex relationships
between objects, subtle visual cues, and the heightened demand for transparency
and reliability. This paper presents the Multi-Modal Explainable Learning
(MMEL) framework, designed to enhance the interpretability of vision-language
models while maintaining high performance. Building upon prior work in
gradient-based explanations for transformer architectures (Grad-eclip), MMEL
introduces a novel Hierarchical Semantic Relationship Module that enhances
model interpretability through multi-scale feature processing, adaptive
attention weighting, and cross-modal alignment. Our approach processes features
at multiple semantic levels to capture relationships between image regions at
different granularities, applying learnable layer-specific weights to balance
contributions across the model's depth. This results in more comprehensive
visual explanations that highlight both primary objects and their contextual
relationships with improved precision. Through extensive experiments on
standard datasets, we demonstrate that by incorporating semantic relationship
information into gradient-based attribution maps, MMEL produces more focused
and contextually aware visualizations that better reflect how vision-language
models process complex scenes. The MMEL framework generalizes across various
domains, offering valuable insights into model decisions for applications
requiring high interpretability and reliability.

</details>


### [9] [Walk and Read Less: Improving the Efficiency of Vision-and-Language Navigation via Tuning-Free Multimodal Token Pruning](https://arxiv.org/abs/2509.15250)
*Wenda Qin,Andrea Burns,Bryan A. Plummer,Margrit Betke*

Main category: cs.CV

TL;DR: 通过导航感知剪枝(NAP)技术，在保持高成功率的同时，显著提高了视觉-语言导航(VLN)任务的效率，并将计算量减少了50%以上。


<details>
  <summary>Details</summary>
Motivation: 大型模型在VLN任务上表现优异，但在资源受限环境下运行成本高。现有的剪枝技术未能有效解决VLN特有的信息丢失和计算成本增加问题。

Method: 提出导航感知剪枝(NAP)方法，首先根据导航可行性将图像分割为前景和背景，然后利用大型语言模型提取导航相关指令，最后仅对背景标记进行剪枝，并移除低重要性的导航节点以避免回溯。

Result: NAP在标准VLN基准测试中显著优于现有方法，在提高成功率的同时，计算量减少超过50%。

Conclusion: NAP是一种有效的剪枝策略，能够解决VLN任务中的信息丢失和计算成本增加问题，在保证性能的同时显著提高效率。

Abstract: Large models achieve strong performance on Vision-and-Language Navigation
(VLN) tasks, but are costly to run in resource-limited environments. Token
pruning offers appealing tradeoffs for efficiency with minimal performance loss
by reducing model input size, but prior work overlooks VLN-specific challenges.
For example, information loss from pruning can effectively increase
computational cost due to longer walks. Thus, the inability to identify
uninformative tokens undermines the supposed efficiency gains from pruning. To
address this, we propose Navigation-Aware Pruning (NAP), which uses
navigation-specific traits to simplify the pruning process by pre-filtering
tokens into foreground and background. For example, image views are filtered
based on whether the agent can navigate in that direction. We also extract
navigation-relevant instructions using a Large Language Model. After filtering,
we focus pruning on background tokens, minimizing information loss. To further
help avoid increases in navigation length, we discourage backtracking by
removing low-importance navigation nodes. Experiments on standard VLN
benchmarks show NAP significantly outperforms prior work, preserving higher
success rates while saving more than 50% FLOPS.

</details>


### [10] [RespoDiff: Dual-Module Bottleneck Transformation for Responsible & Faithful T2I Generation](https://arxiv.org/abs/2509.15257)
*Silpa Vadakkeeveetil Sreelatha,Sauradip Nag,Muhammad Awais,Serge Belongie,Anjan Dutta*

Main category: cs.CV

TL;DR: RespoDiff是一个新颖的框架，通过在扩散模型的中间瓶颈表示上进行双模块变换，实现了负责任的文本到图像生成，在保持语义一致性的同时，提高了公平性和安全性，而不会损害图像保真度。


<details>
  <summary>Details</summary>
Motivation: 确保文本到图像生成模型的公平性和安全性，同时又不损害语义保真度和图像质量，这是一个尚未解决的挑战。

Method: 提出了一种名为RespoDiff的新颖框架，该框架在扩散模型的中间瓶颈表示上引入了两个可学习的模块：一个专注于捕获和强制执行公平性和安全性等负责任的概念，另一个致力于保持与中性提示的语义对齐。通过引入新的分数匹配目标来促进双重学习过程。

Result: RespoDiff在负责任的生成方面优于最先进的方法，通过同时优化两个目标并保持图像保真度，实现了20%的改进，并且可以无缝集成到SDXL等大规模模型中。

Conclusion: RespoDiff通过在不损害图像保真度的情况下，在公平性、安全性和语义对齐之间取得平衡，从而有效地解决了负责任的文本到图像生成的问题。

Abstract: The rapid advancement of diffusion models has enabled high-fidelity and
semantically rich text-to-image generation; however, ensuring fairness and
safety remains an open challenge. Existing methods typically improve fairness
and safety at the expense of semantic fidelity and image quality. In this work,
we propose RespoDiff, a novel framework for responsible text-to-image
generation that incorporates a dual-module transformation on the intermediate
bottleneck representations of diffusion models. Our approach introduces two
distinct learnable modules: one focused on capturing and enforcing responsible
concepts, such as fairness and safety, and the other dedicated to maintaining
semantic alignment with neutral prompts. To facilitate the dual learning
process, we introduce a novel score-matching objective that enables effective
coordination between the modules. Our method outperforms state-of-the-art
methods in responsible generation by ensuring semantic alignment while
optimizing both objectives without compromising image fidelity. Our approach
improves responsible and semantically coherent generation by 20% across
diverse, unseen prompts. Moreover, it integrates seamlessly into large-scale
models like SDXL, enhancing fairness and safety. Code will be released upon
acceptance.

</details>


### [11] [Autoguided Online Data Curation for Diffusion Model Training](https://arxiv.org/abs/2509.15267)
*Valeria Pais,Luis Oala,Daniele Faccio,Marco Aversa*

Main category: cs.CV

TL;DR: 本文研究了自导引和在线数据选择方法能否提高生成扩散模型训练的时间和样本效率，并在合成数据和图像生成任务上进行了评估。


<details>
  <summary>Details</summary>
Motivation: 生成模型的计算成本引发了对高效数据整理的期望，本文旨在探索自导引和在线数据选择方法在提高生成扩散模型训练效率方面的潜力。

Method: 将联合示例选择（JEST）和自导引方法整合到统一的代码库中，并在合成二维数据生成任务和（3x64x64）维图像生成任务上进行评估，比较了相同运行时间和相同样本数下的表现，并考虑了选择的开销。

Result: 在所有实验中，自导引都能持续提高样本质量和多样性。早期AJEST（仅在训练开始时进行选择）在数据效率方面可以媲美或略优于单独使用自导引。然而，AJEST的时间开销和复杂性使其在大多数情况下不如自导引或均匀随机数据选择。

Conclusion: 虽然有针对性的在线选择可以在训练早期带来效率提升，但鲁棒的样本质量提升主要由自导引驱动。研究讨论了数据选择的局限性和适用范围，并指出了其可能受益的情况。

Abstract: The costs of generative model compute rekindled promises and hopes for
efficient data curation. In this work, we investigate whether recently
developed autoguidance and online data selection methods can improve the time
and sample efficiency of training generative diffusion models. We integrate
joint example selection (JEST) and autoguidance into a unified code base for
fast ablation and benchmarking. We evaluate combinations of data curation on a
controlled 2-D synthetic data generation task as well as (3x64x64)-D image
generation. Our comparisons are made at equal wall-clock time and equal number
of samples, explicitly accounting for the overhead of selection. Across
experiments, autoguidance consistently improves sample quality and diversity.
Early AJEST (applying selection only at the beginning of training) can match or
modestly exceed autoguidance alone in data efficiency on both tasks. However,
its time overhead and added complexity make autoguidance or uniform random data
selection preferable in most situations. These findings suggest that while
targeted online selection can yield efficiency gains in early training, robust
sample quality improvements are primarily driven by autoguidance. We discuss
limitations and scope, and outline when data selection may be beneficial.

</details>


### [12] [PRISM: Phase-enhanced Radial-based Image Signature Mapping framework for fingerprinting AI-generated images](https://arxiv.org/abs/2509.15270)
*Emanuele Ricco,Elia Onofri,Lorenzo Cima,Stefano Cresci,Roberto Di Pietro*

Main category: cs.CV

TL;DR: PRISM是一个基于相位增强的径向图像签名映射框架，用于识别AI生成图像的模型来源，在36K数据集上准确率达92.04%，并能有效区分真实与伪造图像。


<details>
  <summary>Details</summary>
Motivation: 在商业环境中，需要识别AI生成内容的模型来源，以保证用户订阅的专有服务内容的来源可靠性。

Method: PRISM利用离散傅里叶变换的径向归约，结合振幅和相位信息捕捉模型特征，并通过线性判别分析进行聚类，以实现模型归因。

Result: 在PRISM-36K数据集上，PRISM的归因准确率为92.04%。在四个文献基准上，平均准确率为81.60%。在区分真实与伪造图像的任务上，平均准确率为88.41%，在GenImage数据集上最佳准确率为95.06%。

Conclusion: 基于频域指纹识别的技术能够实现跨架构和跨数据集的模型归因，为增强生成式AI系统的责任感和可信度提供了可行方案。

Abstract: A critical need has emerged for generative AI: attribution methods. That is,
solutions that can identify the model originating AI-generated content. This
feature, generally relevant in multimodal applications, is especially sensitive
in commercial settings where users subscribe to paid proprietary services and
expect guarantees about the source of the content they receive. To address
these issues, we introduce PRISM, a scalable Phase-enhanced Radial-based Image
Signature Mapping framework for fingerprinting AI-generated images. PRISM is
based on a radial reduction of the discrete Fourier transform that leverages
amplitude and phase information to capture model-specific signatures. The
output of the above process is subsequently clustered via linear discriminant
analysis to achieve reliable model attribution in diverse settings, even if the
model's internal details are inaccessible. To support our work, we construct
PRISM-36K, a novel dataset of 36,000 images generated by six text-to-image GAN-
and diffusion-based models. On this dataset, PRISM achieves an attribution
accuracy of 92.04%. We additionally evaluate our method on four benchmarks from
the literature, reaching an average accuracy of 81.60%. Finally, we evaluate
our methodology also in the binary task of detecting real vs fake images,
achieving an average accuracy of 88.41%. We obtain our best result on GenImage
with an accuracy of 95.06%, whereas the original benchmark achieved 82.20%. Our
results demonstrate the effectiveness of frequency-domain fingerprinting for
cross-architecture and cross-dataset model attribution, offering a viable
solution for enforcing accountability and trust in generative AI systems.

</details>


### [13] [Large Vision Models Can Solve Mental Rotation Problems](https://arxiv.org/abs/2509.15271)
*Sebastian Ray Mason,Anders Gjølbye,Phillip Chavarria Højbjerg,Lenka Tětková,Lars Kai Hansen*

Main category: cs.CV

TL;DR: Vision transformers (ViT, CLIP, DINOv2, DINOv3) are evaluated on mental rotation tasks. Self-supervised ViTs and intermediate layers perform better. Task difficulty increases with rotation complexity and occlusion, similar to human performance.


<details>
  <summary>Details</summary>
Motivation: Understand how well vision transformers develop mental rotation abilities, a key aspect of spatial reasoning.

Method: Systematically evaluated ViT, CLIP, DINOv2, and DINOv3 on various mental-rotation tasks (simple/complex blocks, text, photorealistic objects). Probed model representations layer by layer.

Result: Self-supervised ViTs capture geometric structure better than supervised ones. Intermediate layers outperform final layers. Task difficulty increases with rotation complexity and occlusion, mirroring human performance.

Conclusion: Self-supervised ViTs show promise in capturing geometric structure for mental rotation, with intermediate layers being more effective. The models' performance on tasks with increasing complexity and occlusion suggests similar constraints to human spatial reasoning in their embedding space representations.

Abstract: Mental rotation is a key test of spatial reasoning in humans and has been
central to understanding how perception supports cognition. Despite the success
of modern vision transformers, it is still unclear how well these models
develop similar abilities. In this work, we present a systematic evaluation of
ViT, CLIP, DINOv2, and DINOv3 across a range of mental-rotation tasks, from
simple block structures similar to those used by Shepard and Metzler to study
human cognition, to more complex block figures, three types of text, and
photo-realistic objects. By probing model representations layer by layer, we
examine where and how these networks succeed. We find that i) self-supervised
ViTs capture geometric structure better than supervised ViTs; ii) intermediate
layers perform better than final layers; iii) task difficulty increases with
rotation complexity and occlusion, mirroring human reaction times and
suggesting similar constraints in embedding space representations.

</details>


### [14] [Which Direction to Choose? An Analysis on the Representation Power of Self-Supervised ViTs in Downstream Tasks](https://arxiv.org/abs/2509.15272)
*Yannis Kaltampanidis,Alexandros Doumanoglou,Dimitrios Zarpalas*

Main category: cs.CV

TL;DR: 本文旨在评估未修改的 Vision Transformer (ViT) 特征在图像分类和分割任务中的内在表征能力，以填补现有研究中对其的分析空白。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习 (SSL) 方法虽然在下游任务中表现出色，但通常需要对预训练的 ViT 特征进行额外的转换。本文旨在探究未经修改的 ViT 特征本身的表征能力。

Method: 本文系统地评估了未经修改的 ViT 特征在标准和少样本图像分类及分割任务中的表现。使用基于超平面（如逻辑回归）或余弦相似度的规则，并在不同 token 类型、任务和预训练 ViT 模型之间进行分析，不使用额外的特征转换。

Result: 本文分析了不同 token 类型、任务和预训练 ViT 模型在分类和分割任务中的表现，并基于这些规则进行了详细的实验，在两个广泛使用的数据集上进行了报告。

Conclusion: 本文提供了关于如何根据任务、上下文和预训练目标选择最佳 token 类型和决策规则的见解，并详细报告了在两个广泛使用的数据集上的发现。

Abstract: Self-Supervised Learning (SSL) for Vision Transformers (ViTs) has recently
demonstrated considerable potential as a pre-training strategy for a variety of
computer vision tasks, including image classification and segmentation, both in
standard and few-shot downstream contexts. Two pre-training objectives dominate
the landscape of SSL techniques: Contrastive Learning and Masked Image
Modeling. Features (or tokens) extracted from the final transformer attention
block -- specifically, the keys, queries, and values -- as well as features
obtained after the final block's feed-forward layer, have become a common
foundation for addressing downstream tasks. However, in many existing
approaches, these pre-trained ViT features are further processed through
additional transformation layers, often involving lightweight heads or combined
with distillation, to achieve superior task performance. Although such methods
can improve task outcomes, to the best of our knowledge, a comprehensive
analysis of the intrinsic representation capabilities of unaltered ViT features
has yet to be conducted. This study aims to bridge this gap by systematically
evaluating the use of these unmodified features across image classification and
segmentation tasks, in both standard and few-shot contexts. The classification
and segmentation rules that we use are either hyperplane based (as in logistic
regression) or cosine-similarity based, both of which rely on the presence of
interpretable directions in the ViT's latent space. Based on the previous rules
and without the use of additional feature transformations, we conduct an
analysis across token types, tasks, and pre-trained ViT models. This study
provides insights into the optimal choice for token type and decision rule
based on the task, context, and the pre-training objective, while reporting
detailed findings on two widely-used datasets.

</details>


### [15] [How Good are Foundation Models in Step-by-Step Embodied Reasoning?](https://arxiv.org/abs/2509.15293)
*Dinura Dissanayake,Ahmed Heakl,Omkar Thawakar,Noor Ahsan,Ritesh Thawkar,Ketan More,Jean Lahoud,Rao Anwer,Hisham Cholakkal,Ivan Laptev,Fahad Shahbaz Khan,Salman Khan*

Main category: cs.CV

TL;DR: 该研究提出了FoMER基准来评估大型多模态模型（LMM）在具身推理方面的能力，并展示了LMM在该领域的潜力和局限性。


<details>
  <summary>Details</summary>
Motivation: 评估大型多模态模型（LMM）在物理世界中执行有效、安全、空间连贯且符合上下文的决策能力，因为目前对LMM在具身任务中进行结构化推理的研究尚不充分。

Method: 提出了FoMER（Foundation Model Embodied Reasoning）基准，包含大规模、精心策划的具身推理任务。该基准旨在评估LMM在复杂具身决策场景下的推理能力，涵盖需要理解多模态观测、推理物理约束和安全以及生成自然语言有效动作的任务。FoMER包含1.1k多个样本，涵盖10个任务和8种具身环境，涉及三种不同的机器人类型。研究还提出了一个新的评估框架，将感知基础与动作推理分离开来。

Result: 对几个领先的LMM在该基准上的表现进行了实证分析，突显了LMM在具身推理方面的潜力和当前局限性。

Conclusion: LMM在具身推理方面既有潜力也有局限性，指出了机器人智能未来研究的关键挑战和机遇。研究团队将公开提供数据和代码。

Abstract: Embodied agents operating in the physical world must make decisions that are
not only effective but also safe, spatially coherent, and grounded in context.
While recent advances in large multimodal models (LMMs) have shown promising
capabilities in visual understanding and language generation, their ability to
perform structured reasoning for real-world embodied tasks remains
underexplored. In this work, we aim to understand how well foundation models
can perform step-by-step reasoning in embodied environments. To this end, we
propose the Foundation Model Embodied Reasoning (FoMER) benchmark, designed to
evaluate the reasoning capabilities of LMMs in complex embodied decision-making
scenarios. Our benchmark spans a diverse set of tasks that require agents to
interpret multimodal observations, reason about physical constraints and
safety, and generate valid next actions in natural language. We present (i) a
large-scale, curated suite of embodied reasoning tasks, (ii) a novel evaluation
framework that disentangles perceptual grounding from action reasoning, and
(iii) empirical analysis of several leading LMMs under this setting. Our
benchmark includes over 1.1k samples with detailed step-by-step reasoning
across 10 tasks and 8 embodiments, covering three different robot types. Our
results highlight both the potential and current limitations of LMMs in
embodied reasoning, pointing towards key challenges and opportunities for
future research in robot intelligence. Our data and code will be made publicly
available.

</details>


### [16] [CoDoL: Conditional Domain Prompt Learning for Out-of-Distribution Generalization](https://arxiv.org/abs/2509.15330)
*Min Zhang,Bo Jiang,Jie Zhou,Yimeng Liu,Xin Lin*

Main category: cs.CV

TL;DR: CoDoL通过利用领域信息形成提示并改进视觉-语言嵌入对齐来提高OOD泛化能力。


<details>
  <summary>Details</summary>
Motivation: CLIP等预训练视觉-语言模型（VLM）在学习分布外（OOD）表示方面显示出巨大潜力，但基于提示的CLIP方法存在文本描述不准确和视觉-语言嵌入对齐有限的问题，影响了准确性、鲁棒性和泛化性能。

Method: 提出了一种新颖的条件领域提示学习（CoDoL）方法，该方法利用易于获得的领域信息形成提示，并改进视觉-语言嵌入对齐以提高OOD泛化能力。为了同时捕获实例特定和领域特定的信息，提出了一种轻量级的领域元网络（DMN）为每个领域中的图像生成输入条件令牌。

Result: 在四个OOD基准（PACS、VLCS、OfficeHome和DigitDG）上进行了广泛的实验，验证了所提出的CoDoL在改进视觉-语言嵌入对齐和OOD泛化性能方面的有效性。

Conclusion: CoDoL通过利用领域信息和DMN来提高视觉-语言嵌入对齐，从而有效提升了OOD泛化能力。

Abstract: Recent advances in pre-training vision-language models (VLMs), e.g.,
contrastive language-image pre-training (CLIP) methods, have shown great
potential in learning out-of-distribution (OOD) representations. Despite
showing competitive performance, the prompt-based CLIP methods still suffer
from: i) inaccurate text descriptions, which leads to degraded accuracy and
robustness, and poses a challenge for zero-shot CLIP methods. ii) limited
vision-language embedding alignment, which significantly affects the
generalization performance. To tackle the above issues, this paper proposes a
novel Conditional Domain prompt Learning (CoDoL) method, which utilizes
readily-available domain information to form prompts and improves the
vision-language embedding alignment for improving OOD generalization. To
capture both instance-specific and domain-specific information, we further
propose a lightweight Domain Meta Network (DMN) to generate input-conditional
tokens for images in each domain. Extensive experiments on four OOD benchmarks
(PACS, VLCS, OfficeHome and DigitDG) validate the effectiveness of our proposed
CoDoL in terms of improving the vision-language embedding alignment as well as
the out-of-distribution generalization performance.

</details>


### [17] [Emulating Human-like Adaptive Vision for Efficient and Flexible Machine Visual Perception](https://arxiv.org/abs/2509.15333)
*Yulin Wang,Yang Yue,Yang Yue,Huanqian Wang,Haojun Jiang,Yizeng Han,Zanlin Ni,Yifan Pu,Minglei Shi,Rui Lu,Qisen Yang,Andrew Zhao,Zhuofan Xia,Shiji Song,Gao Huang*

Main category: cs.CV

TL;DR: AdaptiveNN是一个模仿人类视觉的框架，通过粗略到精细的序列决策过程，仅关注与任务相关的区域，从而大大降低了计算成本，同时保持了准确性，并提高了可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前机器视觉模型被动处理整个场景，导致资源消耗巨大，限制了其在真实世界中的应用和进一步发展。人类视觉具有高度适应性，能够通过关注任务相关区域来高效处理复杂环境，这启发了开发更高效的机器视觉模型。 

Method: AdaptiveNN将视觉感知构建为一个粗略到精细的序列决策过程。它利用一种结合了表征学习和自我奖励强化学习的理论，实现了端到端的训练，无需对注视点位置进行额外监督。该模型能够渐进地识别和关注与任务相关的区域，并整合跨注视点的信息，在信息充分时主动停止观察。

Result: 在17个基准和9个任务（包括大规模视觉识别、细粒度识别、视觉搜索、真实驾驶和医疗图像处理、语言驱动的具身AI以及与人类的对比）上评估，AdaptiveNN实现了高达28倍的推理成本降低，同时不牺牲准确性。它能够灵活适应不同的任务需求和资源预算（无需重新训练），并通过其注视模式提供更好的可解释性。在许多情况下，AdaptiveNN表现出与人类相似的感知行为。

Conclusion: AdaptiveNN通过模仿人类视觉的适应性，提供了一种高效、灵活且可解释的计算机视觉解决方案，有望解决当前机器视觉模型的局限性，并为研究视觉认知提供新的工具。

Abstract: Human vision is highly adaptive, efficiently sampling intricate environments
by sequentially fixating on task-relevant regions. In contrast, prevailing
machine vision models passively process entire scenes at once, resulting in
excessive resource demands scaling with spatial-temporal input resolution and
model size, yielding critical limitations impeding both future advancements and
real-world application. Here we introduce AdaptiveNN, a general framework
aiming to drive a paradigm shift from 'passive' to 'active, adaptive' vision
models. AdaptiveNN formulates visual perception as a coarse-to-fine sequential
decision-making process, progressively identifying and attending to regions
pertinent to the task, incrementally combining information across fixations,
and actively concluding observation when sufficient. We establish a theory
integrating representation learning with self-rewarding reinforcement learning,
enabling end-to-end training of the non-differentiable AdaptiveNN without
additional supervision on fixation locations. We assess AdaptiveNN on 17
benchmarks spanning 9 tasks, including large-scale visual recognition,
fine-grained discrimination, visual search, processing images from real driving
and medical scenarios, language-driven embodied AI, and side-by-side
comparisons with humans. AdaptiveNN achieves up to 28x inference cost reduction
without sacrificing accuracy, flexibly adapts to varying task demands and
resource budgets without retraining, and provides enhanced interpretability via
its fixation patterns, demonstrating a promising avenue toward efficient,
flexible, and interpretable computer vision. Furthermore, AdaptiveNN exhibits
closely human-like perceptual behaviors in many cases, revealing its potential
as a valuable tool for investigating visual cognition. Code is available at
https://github.com/LeapLabTHU/AdaptiveNN.

</details>


### [18] [LowDiff: Efficient Diffusion Sampling with Low-Resolution Condition](https://arxiv.org/abs/2509.15342)
*Jiuyi Xu,Qing Jin,Meida Chen,Andrew Feng,Yang Sui,Yangming Shi*

Main category: cs.CV

TL;DR: LowDiff是一个高效的扩散模型框架，通过级联生成不同分辨率的图像来提高采样速度，并取得了与现有方法相当甚至更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型在图像生成方面取得了巨大成功，但采样速度慢是其应用的主要障碍。以往的研究主要集中在压缩模型或减少去噪步数，而忽视了在生成过程中利用多分辨率输入。本研究旨在提出一种新的方法来解决这个问题。

Method: LowDiff提出了一种基于级联方法的、新颖且高效的扩散模型框架，通过生成递增分辨率的输出。此外，LowDiff采用统一的模型从低分辨率逐步精炼图像至目标分辨率。该框架适用于像素空间和潜在空间的扩散模型。

Result: 通过提出的架构设计和生成技术，LowDiff在显著减少高分辨率采样步数的情况下，实现了相当或更优越的性能。在CIFAR-10、FFHQ和ImageNet数据集上的大量实验证明了该方法的有效性和通用性。结果显示，在所有数据集和设置下，吞吐量提高了50%以上，同时保持了相当或更好的图像质量。在无条件CIFAR-10上，LowDiff的FID为2.11，IS为9.87；在有条件CIFAR-10上，FID为1.94，IS为10.03。在FFHQ 64x64上，FID为2.43；在ImageNet 256x256上，基于LightningDiT-B/1的LowDiff生成高质量样本，FID为4.00，IS为195.06，同时效率也得到了显著提升。

Conclusion: LowDiff通过级联生成和统一的渐进式精炼模型，有效解决了扩散模型采样速度慢的问题，并在图像生成质量和效率方面取得了显著的改进，具有广泛适用性的成果。

Abstract: Diffusion models have achieved remarkable success in image generation but
their practical application is often hindered by the slow sampling speed. Prior
efforts of improving efficiency primarily focus on compressing models or
reducing the total number of denoising steps, largely neglecting the
possibility to leverage multiple input resolutions in the generation process.
In this work, we propose LowDiff, a novel and efficient diffusion framework
based on a cascaded approach by generating increasingly higher resolution
outputs. Besides, LowDiff employs a unified model to progressively refine
images from low resolution to the desired resolution. With the proposed
architecture design and generation techniques, we achieve comparable or even
superior performance with much fewer high-resolution sampling steps. LowDiff is
applicable to diffusion models in both pixel space and latent space. Extensive
experiments on both conditional and unconditional generation tasks across
CIFAR-10, FFHQ and ImageNet demonstrate the effectiveness and generality of our
method. Results show over 50% throughput improvement across all datasets and
settings while maintaining comparable or better quality. On unconditional
CIFAR-10, LowDiff achieves an FID of 2.11 and IS of 9.87, while on conditional
CIFAR-10, an FID of 1.94 and IS of 10.03. On FFHQ 64x64, LowDiff achieves an
FID of 2.43, and on ImageNet 256x256, LowDiff built on LightningDiT-B/1
produces high-quality samples with a FID of 4.00 and an IS of 195.06, together
with substantial efficiency gains.

</details>


### [19] [MaskAttn-SDXL: Controllable Region-Level Text-To-Image Generation](https://arxiv.org/abs/2509.15357)
*Yu Chang,Jiahao Chen,Anzhe Cheng,Paul Bogdan*

Main category: cs.CV

TL;DR: MaskAttn-SDXL通过在Stable Diffusion XL的UNet中引入区域级门控机制来解决文本到图像模型在处理多对象、多属性和空间关系时的组合失败问题。该机制通过学习二进制掩码来稀疏化跨注意力中的token-to-latent交互，从而提高空间依从性和属性绑定能力，且几乎没有额外开销。


<details>
  <summary>Details</summary>
Motivation: 文本到图像扩散模型在处理包含多个对象、属性和空间关系的提示时，常常出现组合失败的情况，导致实体纠缠、属性混合和空间线索违反。

Method: 提出MaskAttn-SDXL，一种应用于Stable Diffusion XL (SDXL) UNet的跨注意力logits的区域级门控机制。该机制为每一层学习一个二进制掩码，并将其注入到softmax之前的每个跨注意力logit图，以稀疏化token-to-latent交互，仅保留语义上相关的连接。

Result: MaskAttn-SDXL在处理多对象提示时，能够提高空间依从性和属性绑定能力，同时保持图像的整体质量和多样性。

Conclusion: 研究表明，logits级别的掩码跨注意力是一种数据高效的增强组合控制的方法，MaskAttn-SDXL为文本到图像生成提供了实用的空间控制扩展。

Abstract: Text-to-image diffusion models achieve impressive realism but often suffer
from compositional failures on prompts with multiple objects, attributes, and
spatial relations, resulting in cross-token interference where entities
entangle, attributes mix across objects, and spatial cues are violated. To
address these failures, we propose MaskAttn-SDXL,a region-level gating
mechanism applied to the cross-attention logits of Stable Diffusion XL(SDXL)'s
UNet. MaskAttn-SDXL learns a binary mask per layer, injecting it into each
cross-attention logit map before softmax to sparsify token-to-latent
interactions so that only semantically relevant connections remain active. The
method requires no positional encodings, auxiliary tokens, or external region
masks, and preserves the original inference path with negligible overhead. In
practice, our model improves spatial compliance and attribute binding in
multi-object prompts while preserving overall image quality and diversity.
These findings demonstrate that logit-level maksed cross-attention is an
data-efficient primitve for enforcing compositional control, and our method
thus serves as a practical extension for spatial control in text-to-image
generation.

</details>


### [20] [RaceGAN: A Framework for Preserving Individuality while Converting Racial Information for Image-to-Image Translation](https://arxiv.org/abs/2509.15391)
*Mst Tasnim Pervin,George Bebis,Fang Jiang,Alireza Tavakkoli*

Main category: cs.CV

TL;DR: RaceGAN是一个新框架，可以通过多域图像到图像翻译来转换种族特征，同时保持独特性和高层语义，而无需参考图像。


<details>
  <summary>Details</summary>
Motivation: 现有的图像到图像翻译模型（如CycleGAN, StarGAN, StarGANv2, StyleGAN）在处理多域、保持个体独特性以及映射低层样式变化方面存在局限性。本研究旨在解决这些问题，专注于通过多域图像到图像翻译来转换种族特征。

Method: 提出了一种名为RaceGAN的新框架，该框架能够通过多域图像到图像翻译来转换种族特征，同时保持个体独特性和高层语义，并且不需要参考图像。该框架还对潜在空间进行了分析，以了解其如何将不同族裔群体的面部聚类。

Result: RaceGAN在芝加哥面部数据集上进行了测试，并在转换种族特征（亚洲、白人、黑人）方面优于其他模型。此外，使用基于InceptionReNetv2的分类进行了定量评估，以证明种族转换的有效性。

Conclusion: RaceGAN在多域图像到图像翻译方面取得了成功，尤其是在种族特征转换任务上，能够保持个体独特性和高层语义，并且无需参考图像。该模型在芝加哥面部数据集上表现优于现有方法，并通过定量评估和潜在空间分析证明了其有效性。

Abstract: Generative adversarial networks (GANs) have demonstrated significant progress
in unpaired image-to-image translation in recent years for several
applications. CycleGAN was the first to lead the way, although it was
restricted to a pair of domains. StarGAN overcame this constraint by tackling
image-to-image translation across various domains, although it was not able to
map in-depth low-level style changes for these domains. Style mapping via
reference-guided image synthesis has been made possible by the innovations of
StarGANv2 and StyleGAN. However, these models do not maintain individuality and
need an extra reference image in addition to the input. Our study aims to
translate racial traits by means of multi-domain image-to-image translation. We
present RaceGAN, a novel framework capable of mapping style codes over several
domains during racial attribute translation while maintaining individuality and
high level semantics without relying on a reference image. RaceGAN outperforms
other models in translating racial features (i.e., Asian, White, and Black)
when tested on Chicago Face Dataset. We also give quantitative findings
utilizing InceptionReNetv2-based classification to demonstrate the
effectiveness of our racial translation. Moreover, we investigate how well the
model partitions the latent space into distinct clusters of faces for each
ethnic group.

</details>


### [21] [Generating Part-Based Global Explanations Via Correspondence](https://arxiv.org/abs/2509.15393)
*Kunal Rathore,Prasad Tadepalli*

Main category: cs.CV

TL;DR: 提出一种利用少量标注图像中的用户定义的部件标签，高效地将它们迁移到更大的数据集，从而通过聚合部件的基础局部解释来生成全局符号解释，以提供大规模模型决策的可解释性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型往往不透明，现有的解释方法通常关注单个图像的局部视觉解释，而基于概念的解释虽然提供全局洞见，却需要大量的标注，成本高昂。

Method: 利用用户定义的部件标签，将它们从少量标注图像迁移到更大的数据集，聚合部件基础的局部解释，生成全局符号解释。

Result: 能够大规模地生成全局符号解释，为模型决策提供可解释性。

Conclusion: 该方法能够高效地为深度学习模型提供大规模、可理解的解释，克服了现有方法的局限性。

Abstract: Deep learning models are notoriously opaque. Existing explanation methods
often focus on localized visual explanations for individual images.
Concept-based explanations, while offering global insights, require extensive
annotations, incurring significant labeling cost. We propose an approach that
leverages user-defined part labels from a limited set of images and efficiently
transfers them to a larger dataset. This enables the generation of global
symbolic explanations by aggregating part-based local explanations, ultimately
providing human-understandable explanations for model decisions on a large
scale.

</details>


### [22] [Causal Fingerprints of AI Generative Models](https://arxiv.org/abs/2509.15406)
*Hui Xu,Chi Liu,Congcong Zhu,Minghao Wang,Youyang Qu,Longxiang Gao*

Main category: cs.CV

TL;DR: 研究提出了一种新的“因果指纹”方法来识别AI生成图像的来源，该方法优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成模型溯源方法依赖于模型特定的线索或合成伪影，泛化能力有限。本文认为，完整的模型指纹应反映图像来源与模型痕迹之间的因果关系，但该方向探索不足。

Method: 提出“因果指纹”概念，并设计了一个因果解耦框架，在预训练的扩散重建残差得到的语义不变潜在空间中，将指纹与图像内容和风格分离开。通过引入多样化的特征表示来增强指纹的区分度。

Result: 在代表性的GAN和扩散模型上评估了溯源性能，并通过因果指纹生成的反事实样本实现了溯源匿名化。实验表明，该方法在模型溯源方面优于现有方法。

Conclusion: 所提出的因果指纹方法在模型溯源方面表现出强大潜力，可用于伪造检测、模型版权追溯和身份保护。

Abstract: AI generative models leave implicit traces in their generated images, which
are commonly referred to as model fingerprints and are exploited for source
attribution. Prior methods rely on model-specific cues or synthesis artifacts,
yielding limited fingerprints that may generalize poorly across different
generative models. We argue that a complete model fingerprint should reflect
the causality between image provenance and model traces, a direction largely
unexplored. To this end, we conceptualize the \emph{causal fingerprint} of
generative models, and propose a causality-decoupling framework that
disentangles it from image-specific content and style in a semantic-invariant
latent space derived from pre-trained diffusion reconstruction residual. We
further enhance fingerprint granularity with diverse feature representations.
We validate causality by assessing attribution performance across
representative GANs and diffusion models and by achieving source anonymization
using counterfactual examples generated from causal fingerprints. Experiments
show our approach outperforms existing methods in model attribution, indicating
strong potential for forgery detection, model copyright tracing, and identity
protection.

</details>


### [23] [NeuroRAD-FM: A Foundation Model for Neuro-Oncology with Distributionally Robust Training](https://arxiv.org/abs/2509.15416)
*Moinak Bhattacharya,Angelica P. Kurtz,Fabio M. Iwamoto,Prateek Prasanna,Gagandeep Singh*

Main category: cs.CV

TL;DR: 开发了一种结合分布鲁棒性损失函数的神经肿瘤学领域特定基础模型，提高了分子标记预测和生存分析的准确性，并实现了跨机构的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基础模型在神经肿瘤学数据异质性和肿瘤复杂性方面泛化能力不足，尤其是在预测非常见分子标记方面表现不佳，而这些标记对于治疗反应和风险分层至关重要。

Method: 在多机构脑肿瘤MRI数据上，使用BYOL、DINO、MAE、MoCo等自监督方法预训练基础模型，并采用分布鲁棒优化（DRO）来解决机构和类别不平衡问题。评估了模型在常见和非常见分子标记分类、连续标记预测以及生存预测任务上的表现。

Result: 该模型在CUIMC机构上，平均平衡准确率从0.744提升至0.785，AUC从0.656提升至0.676，尤其在代表性不足的CDKN2A/2B和ATRX标记上提升显著。生存分析方面，所有机构的c-index均有提升。Grad-CAM可视化结果证实了模型的可解释性。

Conclusion: 结合基础模型和分布鲁棒优化（DRO）可以生成更具跨机构不变性的表征，提高常见和非常见分子标记的预测精度，并增强生存区分能力，为精准神经肿瘤学提供了新的方向，但仍需前瞻性验证并整合纵向和干预性信号。

Abstract: Neuro-oncology poses unique challenges for machine learning due to
heterogeneous data and tumor complexity, limiting the ability of foundation
models (FMs) to generalize across cohorts. Existing FMs also perform poorly in
predicting uncommon molecular markers, which are essential for treatment
response and risk stratification. To address these gaps, we developed a
neuro-oncology specific FM with a distributionally robust loss function,
enabling accurate estimation of tumor phenotypes while maintaining
cross-institution generalization. We pretrained self-supervised backbones
(BYOL, DINO, MAE, MoCo) on multi-institutional brain tumor MRI and applied
distributionally robust optimization (DRO) to mitigate site and class
imbalance. Downstream tasks included molecular classification of common markers
(MGMT, IDH1, 1p/19q, EGFR), uncommon alterations (ATRX, TP53, CDKN2A/2B, TERT),
continuous markers (Ki-67, TP53), and overall survival prediction in IDH1
wild-type glioblastoma at UCSF, UPenn, and CUIMC. Our method improved molecular
prediction and reduced site-specific embedding differences. At CUIMC, mean
balanced accuracy rose from 0.744 to 0.785 and AUC from 0.656 to 0.676, with
the largest gains for underrepresented endpoints (CDKN2A/2B accuracy 0.86 to
0.92, AUC 0.73 to 0.92; ATRX AUC 0.69 to 0.82; Ki-67 accuracy 0.60 to 0.69).
For survival, c-index improved at all sites: CUIMC 0.592 to 0.597, UPenn 0.647
to 0.672, UCSF 0.600 to 0.627. Grad-CAM highlighted tumor and peri-tumoral
regions, confirming interpretability. Overall, coupling FMs with DRO yields
more site-invariant representations, improves prediction of common and uncommon
markers, and enhances survival discrimination, underscoring the need for
prospective validation and integration of longitudinal and interventional
signals to advance precision neuro-oncology.

</details>


### [24] [Region-Aware Deformable Convolutions](https://arxiv.org/abs/2509.15436)
*Abolfazl Saheban Maleki,Maryam Imani*

Main category: cs.CV

TL;DR: RAD-Conv是一种新的卷积算子，通过使用四个边界偏移量为每个卷积核元素创建灵活的、矩形的可变形区域，从而能够适应复杂的图像结构。


<details>
  <summary>Details</summary>
Motivation: 传统的卷积算子在处理复杂图像结构时存在局限性，而RAD-Conv通过引入可变形的矩形区域来解决这个问题。

Method: RAD-Conv使用四个边界偏移量为每个核元素创建灵活的矩形区域，这些区域的大小和形状可以动态调整以匹配图像内容，从而实现感受野形状与核结构的分离。

Result: RAD-Conv能够精确控制感受野的宽度和高度，从而捕捉局部细节和长距离依赖关系，甚至可以使用小的1x1卷积核。

Conclusion: RAD-Conv通过结合注意力机制的适应性和标准卷积的效率，为构建更具表现力和效率的视觉模型提供了一种实用的解决方案。

Abstract: We introduce Region-Aware Deformable Convolution (RAD-Conv), a new
convolutional operator that enhances neural networks' ability to adapt to
complex image structures. Unlike traditional deformable convolutions, which are
limited to fixed quadrilateral sampling areas, RAD-Conv uses four boundary
offsets per kernel element to create flexible, rectangular regions that
dynamically adjust their size and shape to match image content. This approach
allows precise control over the receptive field's width and height, enabling
the capture of both local details and long-range dependencies, even with small
1x1 kernels. By decoupling the receptive field's shape from the kernel's
structure, RAD-Conv combines the adaptability of attention mechanisms with the
efficiency of standard convolutions. This innovative design offers a practical
solution for building more expressive and efficient vision models, bridging the
gap between rigid convolutional architectures and computationally costly
attention-based methods.

</details>


### [25] [CAGE: Continuity-Aware edGE Network Unlocks Robust Floorplan Reconstruction](https://arxiv.org/abs/2509.15459)
*Yiyi Liu,Chunyang Liu,Weiqin Jiao,Bojian Wu,Fashuai Li,Biao Xiong*

Main category: cs.CV

TL;DR: CAGE网络是一个用于从点云密度图重建矢量平面图的框架，它通过将墙体视为连续的边缘来提高鲁棒性和细节恢复能力。


<details>
  <summary>Details</summary>
Motivation: 传统的多边形表示对噪声敏感，易导致布局不完整或不合理；现有的基于线的群组方法虽然更鲁棒，但难以恢复精细的几何细节。

Method: 提出了一种基于边缘的表示方法，将每个墙体段建模为有向的、几何连续的边缘。开发了一种集成了扰动和潜在查询的双查询Transformer解码器，用于去噪框架。

Result: 在Structured3D和SceneCAD数据集上进行了实验，CAGE在房间、角落和角度方面取得了99.1%、91.7%和89.3%的F1分数，达到了最先进的性能，并表现出良好的跨数据集泛化能力。

Conclusion: CAGE网络通过其创新的架构，能够生成连贯、无缝隙且拓扑有效的房间边界，提高了鲁棒性并减少了伪影。

Abstract: We present \textbf{CAGE} (\textit{Continuity-Aware edGE}) network, a
\textcolor{red}{robust} framework for reconstructing vector floorplans directly
from point-cloud density maps. Traditional corner-based polygon representations
are highly sensitive to noise and incomplete observations, often resulting in
fragmented or implausible layouts. Recent line grouping methods leverage
structural cues to improve robustness but still struggle to recover fine
geometric details. To address these limitations, we propose a \textit{native}
edge-centric formulation, modeling each wall segment as a directed,
geometrically continuous edge. This representation enables inference of
coherent floorplan structures, ensuring watertight, topologically valid room
boundaries while improving robustness and reducing artifacts. Towards this
design, we develop a dual-query transformer decoder that integrates perturbed
and latent queries within a denoising framework, which not only stabilizes
optimization but also accelerates convergence. Extensive experiments on
Structured3D and SceneCAD show that \textbf{CAGE} achieves state-of-the-art
performance, with F1 scores of 99.1\% (rooms), 91.7\% (corners), and 89.3\%
(angles). The method also demonstrates strong cross-dataset generalization,
underscoring the efficacy of our architectural innovations. Code and pretrained
models will be released upon acceptance.

</details>


### [26] [Self-supervised learning of imaging and clinical signatures using a multimodal joint-embedding predictive architecture](https://arxiv.org/abs/2509.15470)
*Thomas Z. Li,Aravind R. Krishnan,Lianrui Zuo,John M. Still,Kim L. Sandler,Fabien Maldonado,Thomas A. Lasko,Bennett A. Landman*

Main category: cs.CV

TL;DR: 利用自监督学习和多模态数据预训练模型，用于肺结节诊断。


<details>
  <summary>Details</summary>
Motivation: 肺结节诊断的多模态模型开发受限于标注数据稀缺和模型过拟合问题。

Method: 利用患者的CT扫描和电子健康记录，通过自监督学习和联合嵌入预测架构（JEPA）进行预训练，然后进行监督微调。

Result: 在内部队列中，该方法优于未正则化的多模态模型和仅影像模型（AUC分别为0.91、0.88、0.73），但在外部队列中表现不佳（分别为0.72、0.75）。开发了一个合成环境来表征JEPA可能表现不佳的场景。

Conclusion: 提出了一种利用未标记的多模态医学档案改进预测模型的方法，并展示了其在肺结节诊断中的优势和局限性。

Abstract: The development of multimodal models for pulmonary nodule diagnosis is
limited by the scarcity of labeled data and the tendency for these models to
overfit on the training distribution. In this work, we leverage self-supervised
learning from longitudinal and multimodal archives to address these challenges.
We curate an unlabeled set of patients with CT scans and linked electronic
health records from our home institution to power joint embedding predictive
architecture (JEPA) pretraining. After supervised finetuning, we show that our
approach outperforms an unregularized multimodal model and imaging-only model
in an internal cohort (ours: 0.91, multimodal: 0.88, imaging-only: 0.73 AUC),
but underperforms in an external cohort (ours: 0.72, imaging-only: 0.75 AUC).
We develop a synthetic environment that characterizes the context in which JEPA
may underperform. This work innovates an approach that leverages unlabeled
multimodal medical archives to improve predictive models and demonstrates its
advantages and limitations in pulmonary nodule diagnosis.

</details>


### [27] [Efficient Multimodal Dataset Distillation via Generative Models](https://arxiv.org/abs/2509.15472)
*Zhenghao Zhao,Haoxuan Wang,Junyi Wu,Yuzhang Shang,Gaowen Liu,Yan Yan*

Main category: cs.CV

TL;DR: EDGE是一种高效的多模态数据集蒸馏方法，通过生成模型解决现有方法的计算瓶颈，并在三个数据集上取得了优越的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法（基于匹配训练轨迹）在蒸馏多模态数据集时需要大量计算资源且耗时较长。

Method: 提出了一种名为EDGE的生成蒸馏方法，通过引入双向对比损失和多样性损失来解决生成图像与文本不匹配以及样本多样性不足的问题，并结合字幕合成策略提升文本-图像检索性能。

Result: 在Flickr30K、COCO和CC3M数据集上进行了评估，EDGE方法相比现有方法在性能和效率上均有显著提升，并且速度提高了18倍。

Conclusion: EDGE是一种高效且性能优越的多模态数据集蒸馏方法，能够有效解决现有方法的局限性。

Abstract: Dataset distillation aims to synthesize a small dataset from a large dataset,
enabling the model trained on it to perform well on the original dataset. With
the blooming of large language models and multimodal large language models, the
importance of multimodal datasets, particularly image-text datasets, has grown
significantly. However, existing multimodal dataset distillation methods are
constrained by the Matching Training Trajectories algorithm, which
significantly increases the computing resource requirement, and takes days to
process the distillation. In this work, we introduce EDGE, a generative
distillation method for efficient multimodal dataset distillation.
Specifically, we identify two key challenges of distilling multimodal datasets
with generative models: 1) The lack of correlation between generated images and
captions. 2) The lack of diversity among generated samples. To address the
aforementioned issues, we propose a novel generative model training workflow
with a bi-directional contrastive loss and a diversity loss. Furthermore, we
propose a caption synthesis strategy to further improve text-to-image retrieval
performance by introducing more text information. Our method is evaluated on
Flickr30K, COCO, and CC3M datasets, demonstrating superior performance and
efficiency compared to existing approaches. Notably, our method achieves
results 18x faster than the state-of-the-art method.

</details>


### [28] [OpenViGA: Video Generation for Automotive Driving Scenes by Streamlining and Fine-Tuning Open Source Models with Public Data](https://arxiv.org/abs/2509.15479)
*Björn Möller,Zhengyang Li,Malte Stelzer,Thomas Graave,Fabian Bettels,Muaaz Ataya,Tim Fingscheidt*

Main category: cs.CV

TL;DR: OpenViGA是一个开源的视频生成系统，专门用于生成汽车驾驶场景，解决了现有系统资源消耗大、缺乏透明度和可复现性等问题。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成系统在生成真实的汽车驾驶场景时，通常将分词、未来状态预测（世界模型）和视频解码分配给专用模型，这些模型通常体积庞大、训练资源消耗大，且缺乏公开的代码和数据集，使得设计选择难以理解且复现性差。本研究旨在解决这些不足。

Method: OpenViGA系统整合了三个核心组件：图像分词器、世界模型和视频解码器。该系统基于强大的预训练开源模型进行构建，并使用公开可用的汽车数据集（BDD100K）进行微调。通过对各组件进行单独的定量和定性评估，以及优化组件间的接口，实现了一个连贯的视频生成系统。

Result: 在256x256分辨率、4帧/秒的条件下，OpenViGA能够逐帧预测真实的驾驶场景视频，算法延迟仅为一帧。

Conclusion: OpenViGA提供了一个可复现的、开源的汽车驾驶场景视频生成系统，通过利用现有开源模型和公开数据集，在保证生成视频质量的同时，降低了资源消耗和使用门槛，并公开了代码和模型以促进研究和应用。

Abstract: Recent successful video generation systems that predict and create realistic
automotive driving scenes from short video inputs assign tokenization, future
state prediction (world model), and video decoding to dedicated models. These
approaches often utilize large models that require significant training
resources, offer limited insight into design choices, and lack publicly
available code and datasets. In this work, we address these deficiencies and
present OpenViGA, an open video generation system for automotive driving
scenes. Our contributions are: Unlike several earlier works for video
generation, such as GAIA-1, we provide a deep analysis of the three components
of our system by separate quantitative and qualitative evaluation: Image
tokenizer, world model, video decoder. Second, we purely build upon powerful
pre-trained open source models from various domains, which we fine-tune by
publicly available automotive data (BDD100K) on GPU hardware at academic scale.
Third, we build a coherent video generation system by streamlining interfaces
of our components. Fourth, due to public availability of the underlying models
and data, we allow full reproducibility. Finally, we also publish our code and
models on Github. For an image size of 256x256 at 4 fps we are able to predict
realistic driving scene videos frame-by-frame with only one frame of
algorithmic latency.

</details>


### [29] [Comparing Computational Pathology Foundation Models using Representational Similarity Analysis](https://arxiv.org/abs/2509.15482)
*Vaibhav Mishra,William Lotter*

Main category: cs.CV

TL;DR: 本文系统地分析了计算病理学（CPath）中六种基础模型的学习表征空间，发现不同训练范式（如视觉-语言对比学习和自蒸馏）的模型在表征结构和变异性上存在显著差异。研究还发现所有模型都具有高度的病理切片依赖性，但疾病依赖性较低，并且染色质标准化可以降低这种病理切片依赖性。视觉-语言模型相比于纯视觉模型具有更紧凑的表征。


<details>
  <summary>Details</summary>
Motivation: 评估计算病理学（CPath）中基础模型在表征结构和变异性方面的特点，以指导模型的有效开发和部署。

Method: 使用计算神经科学中的表征相似性分析技术，系统地分析了六种CPath基础模型（CONCH, PLIP, KEEP, UNI (v2), Virchow (v2), Prov-GigaPath）在TCGA H&E图像斑块上的表征空间。

Result: UNI2和Virchow2的模型表征结构最独特，Prov-Gigapath的模型表征相似性最高。相同训练范式（纯视觉 vs 视觉-语言）并不保证更高的表征相似性。所有模型的表征都显示出高度的病理切片依赖性，但疾病依赖性相对较低。染色质标准化将所有模型的病理切片依赖性降低了5.5%（CONCH）到20.5%（PLIP）。视觉-语言模型相比纯视觉模型具有更紧凑的表征。

Conclusion: 不同训练范式对模型表征有显著影响，视觉-语言模型具有更紧凑的表征。病理切片依赖性是普遍存在的，但可以通过染色质标准化来缓解。研究结果为提高模型鲁棒性、模型集成策略以及理解训练范式如何塑造模型表征提供了见解。该分析框架可扩展到其他医学影像领域。

Abstract: Foundation models are increasingly developed in computational pathology
(CPath) given their promise in facilitating many downstream tasks. While recent
studies have evaluated task performance across models, less is known about the
structure and variability of their learned representations. Here, we
systematically analyze the representational spaces of six CPath foundation
models using techniques popularized in computational neuroscience. The models
analyzed span vision-language contrastive learning (CONCH, PLIP, KEEP) and
self-distillation (UNI (v2), Virchow (v2), Prov-GigaPath) approaches. Through
representational similarity analysis using H&E image patches from TCGA, we find
that UNI2 and Virchow2 have the most distinct representational structures,
whereas Prov-Gigapath has the highest average similarity across models. Having
the same training paradigm (vision-only vs. vision-language) did not guarantee
higher representational similarity. The representations of all models showed a
high slide-dependence, but relatively low disease-dependence. Stain
normalization decreased slide-dependence for all models by a range of 5.5%
(CONCH) to 20.5% (PLIP). In terms of intrinsic dimensionality, vision-language
models demonstrated relatively compact representations, compared to the more
distributed representations of vision-only models. These findings highlight
opportunities to improve robustness to slide-specific features, inform model
ensembling strategies, and provide insights into how training paradigms shape
model representations. Our framework is extendable across medical imaging
domains, where probing the internal representations of foundation models can
help ensure effective development and deployment.

</details>


### [30] [SmolRGPT: Efficient Spatial Reasoning for Warehouse Environments with 600M Parameters](https://arxiv.org/abs/2509.15490)
*Abdarahmane Traore,Éric Hervet,Andy Couturier*

Main category: cs.CV

TL;DR: SmolRGPT是一个紧凑型视觉-语言模型，参数量仅为600M，但能在仓储空间推理等具有挑战性的任务上取得与更大模型相当的性能，并明确地整合了区域级空间推理，同时利用RGB和深度信息。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型（VLMs）虽然能力强大，但通常需要巨大的模型参数量，导致在计算和内存资源受限的环境（如仓库、机器人和工业应用）中部署困难，而这些场景对效率和空间理解能力的要求很高。

Method: SmolRGPT采用了一种包含三个阶段的课程学习策略：首先对齐视觉和语言特征，然后实现空间关系理解，最后适应特定任务的数据集。该模型还通过整合RGB和深度信息来显式地加入区域级空间推理。

Result: 在仓储空间推理基准测试中，参数量仅为600M的SmolRGPT取得了有竞争力的结果，其性能与一些规模大得多的模型相当甚至更优。

Conclusion: 该研究表明，在不牺牲核心空间推理能力的情况下，可以在现实世界的应用中部署高效的、可行的多模态智能。

Abstract: Recent advances in vision-language models (VLMs) have enabled powerful
multimodal reasoning, but state-of-the-art approaches typically rely on
extremely large models with prohibitive computational and memory requirements.
This makes their deployment challenging in resource-constrained environments
such as warehouses, robotics, and industrial applications, where both
efficiency and robust spatial understanding are critical. In this work, we
present SmolRGPT, a compact vision-language architecture that explicitly
incorporates region-level spatial reasoning by integrating both RGB and depth
cues. SmolRGPT employs a three-stage curriculum that progressively align visual
and language features, enables spatial relationship understanding, and adapts
to task-specific datasets. We demonstrate that with only 600M parameters,
SmolRGPT achieves competitive results on challenging warehouse spatial
reasoning benchmarks, matching or exceeding the performance of much larger
alternatives. These findings highlight the potential for efficient, deployable
multimodal intelligence in real-world settings without sacrificing core spatial
reasoning capabilities. The code of the experimentation will be available at:
https://github.com/abtraore/SmolRGPT

</details>


### [31] [Lynx: Towards High-Fidelity Personalized Video Generation](https://arxiv.org/abs/2509.15496)
*Shen Sang,Tiancheng Zhi,Tianpei Gu,Jing Liu,Linjie Luo*

Main category: cs.CV

TL;DR: Lynx是一个基于DiT的高保真个性化视频合成模型，通过ID-adapter和Ref-adapter实现身份保真和细节注入，并在基准测试中表现优越。


<details>
  <summary>Details</summary>
Motivation: 提出一个能够从单张输入图像合成高保真个性化视频的模型，并确保身份的准确性和视频的真实感。

Method: 基于开源Diffusion Transformer（DiT）构建，引入了两个轻量级适配器：ID-adapter（使用Perceiver Resampler将ArcFace面部嵌入转换为紧凑的身份令牌）和Ref-adapter（集成来自冻结参考路径的密集VAE特征，通过交叉注意力注入细节）。

Result: 在包含40个受试者和20个提示的基准测试中（共800个测试用例），Lynx在面部相似度、提示遵循能力和视频质量方面均表现出色。

Conclusion: Lynx在保持身份保真的同时，实现了时间连贯性和视觉真实感，推动了个性化视频生成技术的发展。

Abstract: We present Lynx, a high-fidelity model for personalized video synthesis from
a single input image. Built on an open-source Diffusion Transformer (DiT)
foundation model, Lynx introduces two lightweight adapters to ensure identity
fidelity. The ID-adapter employs a Perceiver Resampler to convert
ArcFace-derived facial embeddings into compact identity tokens for
conditioning, while the Ref-adapter integrates dense VAE features from a frozen
reference pathway, injecting fine-grained details across all transformer layers
through cross-attention. These modules collectively enable robust identity
preservation while maintaining temporal coherence and visual realism. Through
evaluation on a curated benchmark of 40 subjects and 20 unbiased prompts, which
yielded 800 test cases, Lynx has demonstrated superior face resemblance,
competitive prompt following, and strong video quality, thereby advancing the
state of personalized video generation.

</details>


### [32] [Backdoor Mitigation via Invertible Pruning Masks](https://arxiv.org/abs/2509.15497)
*Kealan Dunnett,Reza Arablouei,Dimity Miller,Volkan Dedeoglu,Raja Jurdak*

Main category: cs.CV

TL;DR: 提出一种新颖的剪枝方法，通过学习到的选择机制和可逆剪枝掩模来识别和移除导致后门行为的参数，同时保留主要任务的准确性，并在低数据条件下表现出优势。


<details>
  <summary>Details</summary>
Motivation: 现有的基于剪枝的方法在识别和移除导致后门行为的特定参数方面存在不足，而剪枝方法相比微调方法具有更好的可解释性和在低数据条件下的鲁棒性。

Method: 提出一种新颖的剪枝方法，包含一个学习到的选择机制来识别关键参数，以及一个可逆的剪枝掩模，旨在同时实现消除后门任务和保留主任务的目标。该方法被构建为一个双层优化问题，联合学习选择变量、稀疏可逆掩模和样本特定的后门扰动。

Result: 实验证明，该方法优于现有的基于剪枝的后门缓解方法，在数据有限的情况下保持了强大的性能，并与最先进的微调方法相比具有竞争力。该方法在成功缓解后门后，对于受损样本的正确预测恢复效果尤为显著。

Conclusion: 所提出的剪枝方法在后门缓解方面表现出优越性，特别是在低数据条件下和恢复受损样本的准确性方面，为后门防御提供了一种有前景的解决方案。

Abstract: Model pruning has gained traction as a promising defense strategy against
backdoor attacks in deep learning. However, existing pruning-based approaches
often fall short in accurately identifying and removing the specific parameters
responsible for inducing backdoor behaviors. Despite the dominance of
fine-tuning-based defenses in recent literature, largely due to their superior
performance, pruning remains a compelling alternative, offering greater
interpretability and improved robustness in low-data regimes. In this paper, we
propose a novel pruning approach featuring a learned \emph{selection} mechanism
to identify parameters critical to both main and backdoor tasks, along with an
\emph{invertible} pruning mask designed to simultaneously achieve two
complementary goals: eliminating the backdoor task while preserving it through
the inverse mask. We formulate this as a bi-level optimization problem that
jointly learns selection variables, a sparse invertible mask, and
sample-specific backdoor perturbations derived from clean data. The inner
problem synthesizes candidate triggers using the inverse mask, while the outer
problem refines the mask to suppress backdoor behavior without impairing
clean-task accuracy. Extensive experiments demonstrate that our approach
outperforms existing pruning-based backdoor mitigation approaches, maintains
strong performance under limited data conditions, and achieves competitive
results compared to state-of-the-art fine-tuning approaches. Notably, the
proposed approach is particularly effective in restoring correct predictions
for compromised samples after successful backdoor mitigation.

</details>


### [33] [MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training](https://arxiv.org/abs/2509.15514)
*Junbiao Pang,Tianyang Cai,Baochang Zhang*

Main category: cs.CV

TL;DR: MEC-Quant通过最大熵编码优化量化感知训练，在极低比特下也能取得与全精度相当甚至更优的性能，解决了现有QAT方法表现不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 现有量化感知训练（QAT）方法在性能上仍逊于全精度（FP）模型，尤其是在极低比特量化时，会引入偏差，影响模型泛化能力。

Method: 提出最大熵编码量化（MEC-Quant），一个更原则性的目标函数，通过优化表示的结构来减少偏差。为了实现端到端训练，利用最小编码长度作为熵的可行替代，并基于混合专家（MOE）模型推导出可扩展的重构。

Result: 在多个计算机视觉任务上的广泛实验证明了MEC-Quant的优越性，将QAT的性能极限推至x位激活，其精度可与FP模型媲美甚至超越。

Conclusion: MEC-Quant在不依赖额外技巧的情况下，为QAT树立了新的最先进水平。

Abstract: Quantization-Aware Training (QAT) has driven much attention to produce
efficient neural networks. Current QAT still obtains inferior performances
compared with the Full Precision (FP) counterpart. In this work, we argue that
quantization inevitably introduce biases into the learned representation,
especially under the extremely low-bit setting. To cope with this issue, we
propose Maximum Entropy Coding Quantization (MEC-Quant), a more principled
objective that explicitly optimizes on the structure of the representation, so
that the learned representation is less biased and thus generalizes better to
unseen in-distribution samples. To make the objective end-to-end trainable, we
propose to leverage the minimal coding length in lossy data coding as a
computationally tractable surrogate for the entropy, and further derive a
scalable reformulation of the objective based on Mixture Of Experts (MOE) that
not only allows fast computation but also handles the long-tailed distribution
for weights or activation values. Extensive experiments on various tasks on
computer vision tasks prove its superiority. With MEC-Qaunt, the limit of QAT
is pushed to the x-bit activation for the first time and the accuracy of
MEC-Quant is comparable to or even surpass the FP counterpart. Without bells
and whistles, MEC-Qaunt establishes a new state of the art for QAT.

</details>


### [34] [GUI-ARP: Enhancing Grounding with Adaptive Region Perception for GUI Agents](https://arxiv.org/abs/2509.15532)
*Xianhang Ye,Yiqing Li,Wei Dai,Miancan Liu,Ziyuan Chen,Zhangye Han,Hongbo Min,Jinkui Ren,Xiantao Zhang,Wen Yang,Zhi Jin*

Main category: cs.CV

TL;DR: GUI-ARP框架通过自适应区域感知(ARP)和自适应阶段控制(ASC)实现多阶段推理，以解决现有GUI接地方法中的细粒度定位问题。它通过两阶段训练（监督微调+基于GRPO的强化微调）来动态利用视觉注意力，并根据任务复杂度选择单阶段或多阶段推理。GUI-ARP在ScreenSpot-Pro和UI-Vision基准测试上取得了最先进的性能，其7B模型在ScreenSpot-Pro上达到60.8%的准确率，在UI-Vision上达到30.9%，优于一些大型模型。


<details>
  <summary>Details</summary>
Motivation: 现有GUI接地方法难以在高分辨率截图上进行细粒度定位。

Method: 提出GUI-ARP框架，包含自适应区域感知(ARP)和自适应阶段控制(ASC)，实现自适应多阶段推理。通过监督微调和基于GRPO的强化微调的两阶段训练方法。

Result: GUI-ARP在ScreenSpot-Pro和UI-Vision基准测试上取得最先进性能，GUI-ARP-7B在ScreenSpot-Pro上准确率达60.8%，在UI-Vision上达30.9%，表现优于一些大型模型。

Conclusion: GUI-ARP框架能够有效解决高分辨率GUI接地中的细粒度定位问题，并能根据任务复杂度自适应地调整推理策略，在多个基准测试中取得优异成绩。

Abstract: Existing GUI grounding methods often struggle with fine-grained localization
in high-resolution screenshots. To address this, we propose GUI-ARP, a novel
framework that enables adaptive multi-stage inference. Equipped with the
proposed Adaptive Region Perception (ARP) and Adaptive Stage Controlling (ASC),
GUI-ARP dynamically exploits visual attention for cropping task-relevant
regions and adapts its inference strategy, performing a single-stage inference
for simple cases and a multi-stage analysis for more complex scenarios. This is
achieved through a two-phase training pipeline that integrates supervised
fine-tuning with reinforcement fine-tuning based on Group Relative Policy
Optimization (GRPO). Extensive experiments demonstrate that the proposed
GUI-ARP achieves state-of-the-art performance on challenging GUI grounding
benchmarks, with a 7B model reaching 60.8% accuracy on ScreenSpot-Pro and 30.9%
on UI-Vision benchmark. Notably, GUI-ARP-7B demonstrates strong competitiveness
against open-source 72B models (UI-TARS-72B at 38.1%) and proprietary models.

</details>


### [35] [SAMPO:Scale-wise Autoregression with Motion PrOmpt for generative world models](https://arxiv.org/abs/2509.15536)
*Sen Wang,Jingyi Tian,Le Wang,Zhimin Liao,Jiayi Li,Huaiyi Dong,Kun Xia,Sanping Zhou,Wei Tang,Hua Gang*

Main category: cs.CV

TL;DR: SAMPO是一个结合了视觉自回归和因果建模的混合框架，用于提高世界模型的预测能力和效率，在视频预测和基于模型的控制方面取得了有竞争力的性能，并将推理速度提高了4.4倍。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归世界模型在视觉上连贯的预测方面存在困难，主要体现在空间结构混乱、解码效率低下和运动建模不足。

Method: SAMPO框架整合了时间因果解码和双向空间注意力机制，以在每个尺度内实现空间局部性和并行解码。此外，它还采用了不对称多尺度分词器来保留空间细节并提取紧凑的动态表征，并引入了一个轨迹感知运动提示模块来注入时空线索。

Result: SAMPO在动作条件视频预测和基于模型的控制方面取得了有竞争力的性能，生成质量有所提高，推理速度提高了4.4倍。该模型还表现出良好的零样本泛化能力和扩展性。

Conclusion: SAMPO通过结合视觉自回归和因果建模，有效解决了现有世界模型的局限性，显著提高了预测质量和效率，并在各种任务中展现出优越的性能和泛化能力。

Abstract: World models allow agents to simulate the consequences of actions in imagined
environments for planning, control, and long-horizon decision-making. However,
existing autoregressive world models struggle with visually coherent
predictions due to disrupted spatial structure, inefficient decoding, and
inadequate motion modeling. In response, we propose \textbf{S}cale-wise
\textbf{A}utoregression with \textbf{M}otion \textbf{P}r\textbf{O}mpt
(\textbf{SAMPO}), a hybrid framework that combines visual autoregressive
modeling for intra-frame generation with causal modeling for next-frame
generation. Specifically, SAMPO integrates temporal causal decoding with
bidirectional spatial attention, which preserves spatial locality and supports
parallel decoding within each scale. This design significantly enhances both
temporal consistency and rollout efficiency. To further improve dynamic scene
understanding, we devise an asymmetric multi-scale tokenizer that preserves
spatial details in observed frames and extracts compact dynamic representations
for future frames, optimizing both memory usage and model performance.
Additionally, we introduce a trajectory-aware motion prompt module that injects
spatiotemporal cues about object and robot trajectories, focusing attention on
dynamic regions and improving temporal consistency and physical realism.
Extensive experiments show that SAMPO achieves competitive performance in
action-conditioned video prediction and model-based control, improving
generation quality with 4.4$\times$ faster inference. We also evaluate SAMPO's
zero-shot generalization and scaling behavior, demonstrating its ability to
generalize to unseen tasks and benefit from larger model sizes.

</details>


### [36] [Beyond Words: Enhancing Desire, Emotion, and Sentiment Recognition with Non-Verbal Cues](https://arxiv.org/abs/2509.15540)
*Wei Chen,Tongguan Wang,Feiyue Xue,Junkai Li,Hui Liu,Ying Sha*

Main category: cs.CV

TL;DR: 本文提出了一种对称双向多模态学习框架（SyDES），用于识别人的欲望、情绪和情感，通过强制文本和图像模态之间的相互指导来捕捉与意图相关的图像表示，并取得了比现有方法更好的效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在情感分析中主要关注语言线索，忽视了图像作为互补的非语言线索，并且专门针对人类欲望理解的多模态方法研究不足。

Method: 提出一种对称双向多模态学习框架（SyDES），该框架强制文本和图像模态之间的相互指导。具体来说，使用低分辨率图像获取全局视觉表示以进行跨模态对齐，同时将高分辨率图像划分为子图像并使用掩码图像建模进行建模，以增强捕获细粒度局部特征的能力。引入文本引导图像解码器和图像引导文本解码器，以促进在图像信息的局部和全局表示上的深度跨模态交互。此外，采用混合尺度图像策略，将高分辨率图像裁剪成子图像进行掩码建模。

Result: 所提出的方法在MSED数据集上进行了评估，该数据集包括一个欲望理解基准以及情绪和情感识别。实验结果表明，相比其他最先进的方法，该方法在欲望理解、情绪识别和情感分析方面分别取得了1.1%、0.6%和0.9%的F1分数提升。

Conclusion: 所提出的对称双向多模态学习框架（SyDES）能够有效地捕捉与意图相关的图像表示，并在欲望理解、情绪识别和情感分析方面实现了持续的改进，验证了该方法的有效性。

Abstract: Desire, as an intention that drives human behavior, is closely related to
both emotion and sentiment. Multimodal learning has advanced sentiment and
emotion recognition, but multimodal approaches specially targeting human desire
understanding remain underexplored. And existing methods in sentiment analysis
predominantly emphasize verbal cues and overlook images as complementary
non-verbal cues. To address these gaps, we propose a Symmetrical Bidirectional
Multimodal Learning Framework for Desire, Emotion, and Sentiment Recognition,
which enforces mutual guidance between text and image modalities to effectively
capture intention-related representations in the image. Specifically,
low-resolution images are used to obtain global visual representations for
cross-modal alignment, while high resolution images are partitioned into
sub-images and modeled with masked image modeling to enhance the ability to
capture fine-grained local features. A text-guided image decoder and an
image-guided text decoder are introduced to facilitate deep cross-modal
interaction at both local and global representations of image information.
Additionally, to balance perceptual gains with computation cost, a mixed-scale
image strategy is adopted, where high-resolution images are cropped into
sub-images for masked modeling. The proposed approach is evaluated on MSED, a
multimodal dataset that includes a desire understanding benchmark, as well as
emotion and sentiment recognition. Experimental results indicate consistent
improvements over other state-of-the-art methods, validating the effectiveness
of our proposed method. Specifically, our method outperforms existing
approaches, achieving F1-score improvements of 1.1% in desire understanding,
0.6% in emotion recognition, and 0.9% in sentiment analysis. Our code is
available at: https://github.com/especiallyW/SyDES.

</details>


### [37] [Enhancing Sa2VA for Referent Video Object Segmentation: 2nd Solution for 7th LSVOS RVOS Track](https://arxiv.org/abs/2509.15546)
*Ran Hong,Feng Lu,Leilei Cao,An Yan,Youhai Jiang,Fengjie Zhu*

Main category: cs.CV

TL;DR: 本研究提出了一个无需训练的框架，通过引入视频-语言检查器和关键帧采样器来改进Sa2VA在参考视频对象分割（RVOS）任务上的表现，显著减少了假阳性，并提升了对早期对象出现和长时序上下文的捕捉能力，在MeViS测试集上取得了64.14%的J&F分数，在ICCV 2025的LSVOS挑战赛中排名第二。


<details>
  <summary>Details</summary>
Motivation: RVOS任务旨在分割视频中与给定自然语言描述匹配的所有对象，弥合视觉和语言理解的差距。现有方法（如Sa2VA）结合了大型语言模型（LLMs）和SAM，利用LLMs的视频推理能力指导视频分割，但仍有改进空间。

Method: 提出一个包含两个关键组件的训练免费框架：1. 视频-语言检查器：显式验证查询中描述的主体和动作是否实际出现在视频中，以减少假阳性。2. 关键帧采样器：自适应地选择信息帧，以更好地捕捉早期对象出现和长时序上下文。

Result: 在没有额外训练的情况下，该方法在MeViS测试集上达到了64.14%的J&F分数，在第7届LSVOS挑战赛（ICCV 2025）的RVOS赛道上排名第二。

Conclusion: 本研究提出的训练免费框架通过视频-语言检查器和关键帧采样器，有效提升了Sa2VA在RVOS任务上的性能，表明该方法在不进行额外训练的情况下具有很强的竞争力。

Abstract: Referential Video Object Segmentation (RVOS) aims to segment all objects in a
video that match a given natural language description, bridging the gap between
vision and language understanding. Recent work, such as Sa2VA, combines Large
Language Models (LLMs) with SAM~2, leveraging the strong video reasoning
capability of LLMs to guide video segmentation. In this work, we present a
training-free framework that substantially improves Sa2VA's performance on the
RVOS task. Our method introduces two key components: (1) a Video-Language
Checker that explicitly verifies whether the subject and action described in
the query actually appear in the video, thereby reducing false positives; and
(2) a Key-Frame Sampler that adaptively selects informative frames to better
capture both early object appearances and long-range temporal context. Without
any additional training, our approach achieves a J&F score of 64.14% on the
MeViS test set, ranking 2nd place in the RVOS track of the 7th LSVOS Challenge
at ICCV 2025.

</details>


### [38] [MS-GS: Multi-Appearance Sparse-View 3D Gaussian Splatting in the Wild](https://arxiv.org/abs/2509.15548)
*Deming Li,Kaiwen Jiang,Yutao Tang,Ravi Ramamoorthi,Rama Chellappa,Cheng Peng*

Main category: cs.CV

TL;DR: MS-GS是一个用于稀疏视图和多外观场景的新型3D高斯泼溅框架，利用单目深度估计的几何先验和多视图约束来提高三维重建和新视角合成的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有技术在处理野外照片集合（数量有限、外观多样）的场景重建和新视角合成方面存在不足，容易出现过度平滑和过拟合。

Method: MS-GS框架利用单目深度估计提取的几何先验，并结合从运动中恢复结构（SfM）的点来锚定局部语义区域，以获得可靠的对齐和几何线索。然后，通过一系列细粒度和粗粒度的引导式几何监督，在虚拟视图上引入多视图约束，以增强三维一致性并减少过拟合。

Result: MS-GS在具有挑战性的稀疏视图和多外观条件下实现了照片级的渲染效果，并在不同数据集上显著优于现有方法。

Conclusion: MS-GS在稀疏视图和多外观场景下，通过结合几何先验和多视图约束，有效解决了现有NeRF和3DGS方法的不足，实现了高质量的三维重建和新视角合成。

Abstract: In-the-wild photo collections often contain limited volumes of imagery and
exhibit multiple appearances, e.g., taken at different times of day or seasons,
posing significant challenges to scene reconstruction and novel view synthesis.
Although recent adaptations of Neural Radiance Field (NeRF) and 3D Gaussian
Splatting (3DGS) have improved in these areas, they tend to oversmooth and are
prone to overfitting. In this paper, we present MS-GS, a novel framework
designed with Multi-appearance capabilities in Sparse-view scenarios using
3DGS. To address the lack of support due to sparse initializations, our
approach is built on the geometric priors elicited from monocular depth
estimations. The key lies in extracting and utilizing local semantic regions
with a Structure-from-Motion (SfM) points anchored algorithm for reliable
alignment and geometry cues. Then, to introduce multi-view constraints, we
propose a series of geometry-guided supervision at virtual views in a
fine-grained and coarse scheme to encourage 3D consistency and reduce
overfitting. We also introduce a dataset and an in-the-wild experiment setting
to set up more realistic benchmarks. We demonstrate that MS-GS achieves
photorealistic renderings under various challenging sparse-view and
multi-appearance conditions and outperforms existing approaches significantly
across different datasets.

</details>


### [39] [Diffusion-Based Cross-Modal Feature Extraction for Multi-Label Classification](https://arxiv.org/abs/2509.15553)
*Tian Lan,Yiming Zheng,Jianxin Yin*

Main category: cs.CV

TL;DR: Diff-Feat 从预训练的扩散 Transformer 模型中提取中间特征，并融合这些特征以用于下游任务，在图像和文本的多标签分类任务上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 为了提取能够捕捉多标签交互的强大表示，以应对多标签分类的广泛应用。

Method: 提出了一种名为 Diff-Feat 的框架，该框架从预训练的扩散 Transformer 模型中提取中间特征（针对图像和文本），然后融合这些特征以用于下游任务。通过局部搜索算法来寻找最优的“图像-文本”×“块-时间步”组合，并使用简单的融合-线性投影和加法操作。

Result: Diff-Feat 在 MS-COCO-enhanced 和 Visual Genome 500 数据集上分别取得了 98.6% 和 45.7% 的 mAP，超越了现有的 CNN、图和 Transformer 基线模型。t-SNE 和聚类指标显示 Diff-Feat 形成了比单一模态方法更紧凑的语义簇。

Conclusion: Diff-Feat 是一种简单而强大的框架，通过融合预训练扩散 Transformer 模型中的中间特征，能够有效地解决多标签分类问题，并在多个基准测试中取得最先进的成果。

Abstract: Multi-label classification has broad applications and depends on powerful
representations capable of capturing multi-label interactions. We introduce
\textit{Diff-Feat}, a simple but powerful framework that extracts intermediate
features from pre-trained diffusion-Transformer models for images and text, and
fuses them for downstream tasks. We observe that for vision tasks, the most
discriminative intermediate feature along the diffusion process occurs at the
middle step and is located in the middle block in Transformer. In contrast, for
language tasks, the best feature occurs at the noise-free step and is located
in the deepest block. In particular, we observe a striking phenomenon across
varying datasets: a mysterious "Layer $12$" consistently yields the best
performance on various downstream classification tasks for images (under
DiT-XL/2-256$\times$256). We devise a heuristic local-search algorithm that
pinpoints the locally optimal "image-text"$\times$"block-timestep" pair among a
few candidates, avoiding an exhaustive grid search. A simple fusion-linear
projection followed by addition-of the selected representations yields
state-of-the-art performance: 98.6\% mAP on MS-COCO-enhanced and 45.7\% mAP on
Visual Genome 500, surpassing strong CNN, graph, and Transformer baselines by a
wide margin. t-SNE and clustering metrics further reveal that
\textit{Diff-Feat} forms tighter semantic clusters than unimodal counterparts.
The code is available at https://github.com/lt-0123/Diff-Feat.

</details>


### [40] [From Development to Deployment of AI-assisted Telehealth and Screening for Vision- and Hearing-threatening diseases in resource-constrained settings: Field Observations, Challenges and Way Forward](https://arxiv.org/abs/2509.15558)
*Mahesh Shakya,Bijay Adhikari,Nirsara Shrestha,Bipin Koirala,Arun Adhikari,Prasanta Poudyal,Luna Mathema,Sarbagya Buddhacharya,Bijay Khatri,Bishesh Khanal*

Main category: cs.CV

TL;DR: AI辅助筛查和远程医疗在资源匮乏地区（RCS）的应用面临挑战，但通过迭代、跨学科合作和工作流程数字化可以克服。


<details>
  <summary>Details</summary>
Motivation: 解决资源匮乏地区（RCS）因视觉和听觉障碍疾病导致的、可预防的残疾问题，并探索大规模AI辅助筛查和远程医疗的部署潜力。

Method: 通过早期原型设计、影子部署和持续反馈，进行迭代的、跨学科的合作，并对AI开发和工作流程数字化进行端到端的共同设计。

Result: 在RCS地区部署AI辅助筛查和远程医疗存在挑战，但通过迭代、跨学科合作、利用公共数据集和模型、以及自动化AI图像质量检查可以解决。

Conclusion: AI辅助筛查和远程医疗在RCS地区的成功部署需要将AI开发和工作流程数字化视为一个端到端的、迭代的共同设计过程，以应对实际挑战并填补实际领域知识的空白。

Abstract: Vision- and hearing-threatening diseases cause preventable disability,
especially in resource-constrained settings(RCS) with few specialists and
limited screening setup. Large scale AI-assisted screening and telehealth has
potential to expand early detection, but practical deployment is challenging in
paper-based workflows and limited documented field experience exist to build
upon. We provide insights on challenges and ways forward in development to
adoption of scalable AI-assisted Telehealth and screening in such settings.
Specifically, we find that iterative, interdisciplinary collaboration through
early prototyping, shadow deployment and continuous feedback is important to
build shared understanding as well as reduce usability hurdles when
transitioning from paper-based to AI-ready workflows. We find public datasets
and AI models highly useful despite poor performance due to domain shift. In
addition, we find the need for automated AI-based image quality check to
capture gradable images for robust screening in high-volume camps.
  Our field learning stress the importance of treating AI development and
workflow digitization as an end-to-end, iterative co-design process. By
documenting these practical challenges and lessons learned, we aim to address
the gap in contextual, actionable field knowledge for building real-world
AI-assisted telehealth and mass-screening programs in RCS.

</details>


### [41] [DC-Mamba: Bi-temporal deformable alignment and scale-sparse enhancement for remote sensing change detection](https://arxiv.org/abs/2509.15563)
*Min Sun,Fenghui Guo*

Main category: cs.CV

TL;DR: DC-Mamba是一个新框架，通过双时态可变形对齐(BTDA)和尺度稀疏变化放大器(SSCA)来解决遥感变化检测中的几何错位和噪声问题，显著提高了F1分数和IoU。


<details>
  <summary>Details</summary>
Motivation: 现有遥感变化检测方法，包括最先进的状态空间模型（SSM），在处理几何错位和区分真实变化与噪声方面存在不足。

Method: 提出了一种名为DC-Mamba的“先对齐后增强”框架，该框架基于ChangeMamba骨干，并集成了两个模块：1）双时态可变形对齐（BTDA），用于在语义特征层面纠正空间错位；2）尺度稀疏变化放大器（SSCA），用于选择性地放大高置信度的变化信号并抑制噪声。

Result: DC-Mamba将F1分数从0.5730提高到0.5903，IoU从0.4015提高到0.4187，显著优于ChangeMamba基线。

Conclusion: DC-Mamba的“先对齐后增强”策略有效，为遥感变化检测提供了一个鲁棒且易于部署的解决方案，能够解决几何和特征层面的挑战。

Abstract: Remote sensing change detection (RSCD) is vital for identifying land-cover
changes, yet existing methods, including state-of-the-art State Space Models
(SSMs), often lack explicit mechanisms to handle geometric misalignments and
struggle to distinguish subtle, true changes from noise.To address this, we
introduce DC-Mamba, an "align-then-enhance" framework built upon the
ChangeMamba backbone. It integrates two lightweight, plug-and-play modules: (1)
Bi-Temporal Deformable Alignment (BTDA), which explicitly introduces geometric
awareness to correct spatial misalignments at the semantic feature level; and
(2) a Scale-Sparse Change Amplifier(SSCA), which uses multi-source cues to
selectively amplify high-confidence change signals while suppressing noise
before the final classification. This synergistic design first establishes
geometric consistency with BTDA to reduce pseudo-changes, then leverages SSCA
to sharpen boundaries and enhance the visibility of small or subtle targets.
Experiments show our method significantly improves performance over the strong
ChangeMamba baseline, increasing the F1-score from 0.5730 to 0.5903 and IoU
from 0.4015 to 0.4187. The results confirm the effectiveness of our
"align-then-enhance" strategy, offering a robust and easily deployable solution
that transparently addresses both geometric and feature-level challenges in
RSCD.

</details>


### [42] [BTL-UI: Blink-Think-Link Reasoning Model for GUI Agent](https://arxiv.org/abs/2509.15566)
*Shaojie Zhang,Ruoceng Zhang,Pei Fu,Shaokang Wang,Jiahui Yang,Xin Du,Shiqi Cui,Bin Qin,Ying Huang,Zhenbo Luo,Jian Luan*

Main category: cs.CV

TL;DR: Blink-Think-Link (BTL) 是一个受大脑启发的框架，用于模仿人类认知过程的GUI交互，通过眨眼（注意）、思考（推理）和链接（命令生成）三个阶段来提高AI驱动的GUI交互的自然性，并引入了眨眼数据生成和基于规则的奖励机制，显著提高了GUI代理的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的AI驱动的人机图形用户界面（GUI）交互自动化方法，尽管在多模态大语言模型和强化微调技术方面取得了进展，但其交互逻辑与自然的人机GUI交流模式存在显著差异，这表明存在一个关键的挑战需要解决。

Method: 提出了一种名为“Blink-Think-Link”（BTL）的受大脑启发的框架，该框架模仿了用户与图形界面之间的认知过程。该系统将交互分解为三个阶段：（1）眨眼——快速检测和关注相关的屏幕区域，类似于扫视性眼动；（2）思考——更高级别的推理和决策，类似于认知规划；（3）链接——为精确的运动控制生成可执行命令，类似于人类的选择机制。此外，还引入了两个关键技术创新：一个优化的眨眼数据自动化标注流程，以及一个基于规则的奖励机制（BTL Reward），该机制结合了过程和结果来驱动强化学习。

Result: 基于BTL框架，开发了一个名为BTL-UI的GUI代理模型。该模型在静态GUI理解和动态交互任务方面，在综合基准测试中始终表现出最先进的性能。

Conclusion: BTL框架通过模仿人类认知过程（眨眼、思考、链接）和引入新的技术创新（眨眼数据生成、BTL奖励），成功地提高了AI驱动的GUI交互的自然性和效率，并在各项GUI代理任务中取得了实证验证的优越性能。

Abstract: In the field of AI-driven human-GUI interaction automation, while rapid
advances in multimodal large language models and reinforcement fine-tuning
techniques have yielded remarkable progress, a fundamental challenge persists:
their interaction logic significantly deviates from natural human-GUI
communication patterns. To fill this gap, we propose "Blink-Think-Link" (BTL),
a brain-inspired framework for human-GUI interaction that mimics the human
cognitive process between users and graphical interfaces. The system decomposes
interactions into three biologically plausible phases: (1) Blink - rapid
detection and attention to relevant screen areas, analogous to saccadic eye
movements; (2) Think - higher-level reasoning and decision-making, mirroring
cognitive planning; and (3) Link - generation of executable commands for
precise motor control, emulating human action selection mechanisms.
Additionally, we introduce two key technical innovations for the BTL framework:
(1) Blink Data Generation - an automated annotation pipeline specifically
optimized for blink data, and (2) BTL Reward -- the first rule-based reward
mechanism that enables reinforcement learning driven by both process and
outcome. Building upon this framework, we develop a GUI agent model named
BTL-UI, which demonstrates consistent state-of-the-art performance across both
static GUI understanding and dynamic interaction tasks in comprehensive
benchmarks. These results provide conclusive empirical validation of the
framework's efficacy in developing advanced GUI Agents.

</details>


### [43] [Towards Size-invariant Salient Object Detection: A Generic Evaluation and Optimization Approach](https://arxiv.org/abs/2509.15573)
*Shilong Bao,Qianqian Xu,Feiran Li,Boyu Han,Zhiyong Yang,Xiaochun Cao,Qingming Huang*

Main category: cs.CV

TL;DR: 本论文提出了一种名为SIEva的尺寸不变评估框架，用于解决显著目标检测（SOD）中现有评估协议对物体尺寸敏感的问题，并通过SIOpt优化框架提升了跨尺寸目标的检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有SOD评估协议对显著目标的大小敏感，导致大目标错误主导评估，小目标被忽视，进而影响评估的准确性和实际应用效果。

Method: 提出了一种尺寸不变评估（SIEva）框架，通过单独评估每个可分离的评估项并聚合结果来减轻尺寸不平衡的影响。在此基础上，开发了一个遵循尺寸不变原则的优化框架（SIOpt），该框架模型无关，可与多种SOD骨干网络集成。

Result: SIOpt显著提高了跨尺寸显著目标的检测性能，并提供了SOD方法泛化分析和新评估协议有效性的理论证据。实验证明了该方法的有效性。

Conclusion: 提出的SIEva框架和SIOpt优化方法有效解决了SOD评估中的尺寸不一致问题，提高了对不同尺寸显著目标的检测性能。

Abstract: This paper investigates a fundamental yet underexplored issue in Salient
Object Detection (SOD): the size-invariant property for evaluation protocols,
particularly in scenarios when multiple salient objects of significantly
different sizes appear within a single image. We first present a novel
perspective to expose the inherent size sensitivity of existing widely used SOD
metrics. Through careful theoretical derivations, we show that the evaluation
outcome of an image under current SOD metrics can be essentially decomposed
into a sum of several separable terms, with the contribution of each term being
directly proportional to its corresponding region size. Consequently, the
prediction errors would be dominated by the larger regions, while smaller yet
potentially more semantically important objects are often overlooked, leading
to biased performance assessments and practical degradation. To address this
challenge, a generic Size-Invariant Evaluation (SIEva) framework is proposed.
The core idea is to evaluate each separable component individually and then
aggregate the results, thereby effectively mitigating the impact of size
imbalance across objects. Building upon this, we further develop a dedicated
optimization framework (SIOpt), which adheres to the size-invariant principle
and significantly enhances the detection of salient objects across a broad
range of sizes. Notably, SIOpt is model-agnostic and can be seamlessly
integrated with a wide range of SOD backbones. Theoretically, we also present
generalization analysis of SOD methods and provide evidence supporting the
validity of our new evaluation protocols. Finally, comprehensive experiments
speak to the efficacy of our proposed approach. The code is available at
https://github.com/Ferry-Li/SI-SOD.

</details>


### [44] [Multimodal Learning for Fake News Detection in Short Videos Using Linguistically Verified Data and Heterogeneous Modality Fusion](https://arxiv.org/abs/2509.15578)
*Shanghong Li,Chiam Wen Qi Ruth,Hong Xu,Fang Liu*

Main category: cs.CV

TL;DR: 本论文提出了一种名为HFN（Heterogeneous Fusion Net）的新型多模态框架，用于检测短视频平台上的假新闻。该框架整合了视频、音频和文本数据，并通过引入决策网络动态调整模态权重和加权多模态特征融合模块来提高鲁棒性。此外，研究者还贡献了一个名为VESV的短视频真实性检测数据集。实验结果表明，HFN在FakeTT和VESV数据集上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前短视频平台上的假新闻检测方法在处理动态和多模态内容时存在不足，而假新闻的广泛传播可能导致严重的社会危害。

Method: 提出了一种名为HFN（Heterogeneous Fusion Net）的新型多模态框架，该框架整合了视频、音频和文本数据。HFN引入了一个决策网络，可在推理过程中动态调整模态权重，并设计了一个加权多模态特征融合模块以处理不完整数据。同时，构建了一个名为VESV的短视频假新闻检测数据集。

Result: 在FakeTT和VESV数据集上的实验结果显示，HFN在Marco F1指标上分别比现有最先进的方法提高了2.71%和4.14%。

Conclusion: HFN提供了一个强大的解决方案，能够有效识别短视频平台上的假新闻，为打击虚假信息提供了更可靠、更全面的方法。

Abstract: The rapid proliferation of short video platforms has necessitated advanced
methods for detecting fake news. This need arises from the widespread influence
and ease of sharing misinformation, which can lead to significant societal
harm. Current methods often struggle with the dynamic and multimodal nature of
short video content. This paper presents HFN, Heterogeneous Fusion Net, a novel
multimodal framework that integrates video, audio, and text data to evaluate
the authenticity of short video content. HFN introduces a Decision Network that
dynamically adjusts modality weights during inference and a Weighted
Multi-Modal Feature Fusion module to ensure robust performance even with
incomplete data. Additionally, we contribute a comprehensive dataset VESV
(VEracity on Short Videos) specifically designed for short video fake news
detection. Experiments conducted on the FakeTT and newly collected VESV
datasets demonstrate improvements of 2.71% and 4.14% in Marco F1 over
state-of-the-art methods. This work establishes a robust solution capable of
effectively identifying fake news in the complex landscape of short video
platforms, paving the way for more reliable and comprehensive approaches in
combating misinformation.

</details>


### [45] [EyePCR: A Comprehensive Benchmark for Fine-Grained Perception, Knowledge Comprehension and Clinical Reasoning in Ophthalmic Surgery](https://arxiv.org/abs/2509.15596)
*Gui Wang,Yang Wennuo,Xusen Ma,Zehao Zhong,Zhuoru Wu,Ende Wu,Rong Qu,Wooi Ping Cheah,Jianfeng Ren,Linlin Shen*

Main category: cs.CV

TL;DR: EyePCR是一个用于眼科手术分析的大规模基准，旨在评估多模态大语言模型（MLLMs）在手术认知方面的能力，通过提供包含210k VQA、25k三元组医学知识图谱以及四个临床推理任务的标注语料库，并展示了其在评估和提升模型在该领域表现方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在眼科手术这类高风险、特定领域场景下的表现仍有待探索，缺乏针对性的评估基准。因此，需要开发一个能够评估模型在手术认知方面（感知、理解、推理）能力的基准。

Method: 构建了一个名为EyePCR的大规模眼科手术分析基准。该基准包含：1. 超过210k个VQA（视觉问答）数据，覆盖1048个细粒度属性，用于多视角感知评估。2. 一个包含超过25k个三元组的医学知识图谱，用于理解评估。3. 四个临床实践相关的推理任务。此外，研究还开发了一个名为EyePCR-MLLM的模型（Qwen2.5-VL-7B的领域自适应版本）用于在该基准上进行评估。

Result: EyePCR-MLLM在感知任务的多选题中取得了最高的准确率，并且在理解和推理任务上超越了其他开源模型，其表现可与GPT-4等商业模型相媲美。EyePCR基准揭示了当前MLLMs在处理手术认知方面的局限性。

Conclusion: EyePCR基准的建立为评估和提升眼科手术视频理解模型的临床可靠性奠定了基础，并指出了现有MLLMs在模拟外科医生认知能力方面的不足，为未来的研究指明了方向。

Abstract: MLLMs (Multimodal Large Language Models) have showcased remarkable
capabilities, but their performance in high-stakes, domain-specific scenarios
like surgical settings, remains largely under-explored. To address this gap, we
develop \textbf{EyePCR}, a large-scale benchmark for ophthalmic surgery
analysis, grounded in structured clinical knowledge to evaluate cognition
across \textit{Perception}, \textit{Comprehension} and \textit{Reasoning}.
EyePCR offers a richly annotated corpus with more than 210k VQAs, which cover
1048 fine-grained attributes for multi-view perception, medical knowledge graph
of more than 25k triplets for comprehension, and four clinically grounded
reasoning tasks. The rich annotations facilitate in-depth cognitive analysis,
simulating how surgeons perceive visual cues and combine them with domain
knowledge to make decisions, thus greatly improving models' cognitive ability.
In particular, \textbf{EyePCR-MLLM}, a domain-adapted variant of Qwen2.5-VL-7B,
achieves the highest accuracy on MCQs for \textit{Perception} among compared
models and outperforms open-source models in \textit{Comprehension} and
\textit{Reasoning}, rivalling commercial models like GPT-4.1. EyePCR reveals
the limitations of existing MLLMs in surgical cognition and lays the foundation
for benchmarking and enhancing clinical reliability of surgical video
understanding models.

</details>


### [46] [TennisTV: Do Multimodal Large Language Models Understand Tennis Rallies?](https://arxiv.org/abs/2509.15602)
*Zhongyuan Bao,Lejun Zhang*

Main category: cs.CV

TL;DR: 现有的MLLM在理解视频方面表现优异，但在处理像网球这样信息密集且节奏快的运动方面存在挑战。为此，我们提出了TennisTV，一个全面的网球视频理解基准，包含8个任务和2500个经人工验证的问题。通过评估16个MLLM，我们发现现有模型在这一领域存在明显不足，并且需要根据任务调整帧采样密度，同时提高时间定位能力以增强推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的MLLM在理解快速、信息密集的运动视频方面存在不足，例如网球比赛。

Method: TennisTV基准通过将每次回合建模为连续击球事件的时间序列，并利用自动化流程进行过滤和问题生成。该基准包含8个不同层级（回合和击球）的任务，并附带2500个经过人工验证的问题。

Result: 在评估16个代表性MLLM后，结果显示现有模型在网球视频理解方面存在显著的局限性。

Conclusion: 为了提升MLLM在网球视频理解方面的能力，需要根据具体任务优化帧采样密度，并着重提高模型的时间定位能力以增强其推理表现。

Abstract: Multimodal large language models (MLLMs) excel at general video understanding
but struggle with fast, high-frequency sports like tennis, where rally clips
are short yet information-dense. To systematically evaluate MLLMs in this
challenging domain, we present TennisTV, the first and most comprehensive
benchmark for tennis video understanding. TennisTV models each rally as a
temporal-ordered sequence of consecutive stroke events, using automated
pipelines for filtering and question generation. It covers 8 tasks at rally and
stroke levels and includes 2,500 human-verified questions. Evaluating 16
representative MLLMs, we provide the first systematic assessment of tennis
video understanding. Results reveal substantial shortcomings and yield two key
insights: (i) frame-sampling density should be tailored and balanced across
tasks, and (ii) improving temporal grounding is essential for stronger
reasoning.

</details>


### [47] [Enhancing WSI-Based Survival Analysis with Report-Auxiliary Self-Distillation](https://arxiv.org/abs/2509.15608)
*Zheng Wang,Hong Liu,Zheng Wang,Danyi Li,Min Cen,Baptiste Magnier,Li Liang,Liansheng Wang*

Main category: cs.CV

TL;DR: 本研究提出了一种名为Rasa的新框架，利用病理报告辅助全切片图像（WSI）进行生存分析，以克服传统WSI分析中的特征噪声和数据可及性限制。


<details>
  <summary>Details</summary>
Motivation: 传统的基于全切片图像（WSI）的生存分析在预测患者预后方面面临特征噪声和数据可及性有限的挑战，未能有效捕捉关键的预后特征。病理报告包含丰富的患者信息，但其在增强WSI生存分析方面的潜力尚未得到充分探索。

Method: 本研究提出了一种名为Rasa（Report-auxiliary self-distillation）的新框架。首先，利用大型语言模型（LLMs）提取病理报告中的细粒度、与WSI相关的文本描述。然后，设计了一个基于自蒸馏的流程，在教师模型的文本知识指导下，筛选掉学生模型中不相关或冗余的WSI特征。最后，在学生模型的训练中引入了风险感知混合策略，以增加训练数据的数量和多样性。

Result: 在收集的CRC数据和公开的TCGA-BRCA数据上进行的广泛实验表明，Rasa在性能上优于最先进的方法。

Conclusion: Rasa框架通过整合病理报告的文本信息，并利用自蒸馏和数据增强技术，有效解决了WSI生存分析中的挑战，显著提高了预测的准确性和鲁棒性。

Abstract: Survival analysis based on Whole Slide Images (WSIs) is crucial for
evaluating cancer prognosis, as they offer detailed microscopic information
essential for predicting patient outcomes. However, traditional WSI-based
survival analysis usually faces noisy features and limited data accessibility,
hindering their ability to capture critical prognostic features effectively.
Although pathology reports provide rich patient-specific information that could
assist analysis, their potential to enhance WSI-based survival analysis remains
largely unexplored. To this end, this paper proposes a novel Report-auxiliary
self-distillation (Rasa) framework for WSI-based survival analysis. First,
advanced large language models (LLMs) are utilized to extract fine-grained,
WSI-relevant textual descriptions from original noisy pathology reports via a
carefully designed task prompt. Next, a self-distillation-based pipeline is
designed to filter out irrelevant or redundant WSI features for the student
model under the guidance of the teacher model's textual knowledge. Finally, a
risk-aware mix-up strategy is incorporated during the training of the student
model to enhance both the quantity and diversity of the training data.
Extensive experiments carried out on our collected data (CRC) and public data
(TCGA-BRCA) demonstrate the superior effectiveness of Rasa against
state-of-the-art methods. Our code is available at
https://github.com/zhengwang9/Rasa.

</details>


### [48] [PCSR: Pseudo-label Consistency-Guided Sample Refinement for Noisy Correspondence Learning](https://arxiv.org/abs/2509.15623)
*Zhuoyao Liu,Yang Liu,Wentao Feng,Shudong Huang*

Main category: cs.CV

TL;DR: 本研究提出了一种名为 PCSR 的新框架，通过伪标签一致性来解决跨模态检索中的图像-文本对齐噪声问题，提高了检索的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态检索方法通常假设图像-文本对是完美对齐的，忽略了真实数据中存在的噪声对应关系，这会误导相似性学习并降低检索性能。此外，现有方法对噪声实例的区分过于粗糙，并且采用统一的训练策略，未能充分利用样本信息进行模型优化。

Method: PCSR 框架首先使用基于置信度的估计来区分干净和噪声对。然后，通过伪标签一致性来细化噪声对，揭示结构上不同的子集。研究者还提出了伪标签一致性分数 (PCS) 来量化预测稳定性，从而区分噪声对中的模糊样本和可细化样本。最后，采用自适应对优化 (APO) 策略，对模糊样本使用鲁棒损失函数进行优化，并通过文本替换来增强可细化样本。

Result: 在 CC152K、MS-COCO 和 Flickr30K 数据集上的广泛实验证明了该方法在噪声监督下提高检索鲁棒性的有效性。

Conclusion: PCSR 框架通过区分和优化不同类型的样本，有效解决了跨模态检索中的噪声对应问题，提高了模型的性能和鲁棒性。

Abstract: Cross-modal retrieval aims to align different modalities via semantic
similarity. However, existing methods often assume that image-text pairs are
perfectly aligned, overlooking Noisy Correspondences in real data. These
misaligned pairs misguide similarity learning and degrade retrieval
performance. Previous methods often rely on coarse-grained categorizations that
simply divide data into clean and noisy samples, overlooking the intrinsic
diversity within noisy instances. Moreover, they typically apply uniform
training strategies regardless of sample characteristics, resulting in
suboptimal sample utilization for model optimization. To address the above
challenges, we introduce a novel framework, called Pseudo-label
Consistency-Guided Sample Refinement (PCSR), which enhances correspondence
reliability by explicitly dividing samples based on pseudo-label consistency.
Specifically, we first employ a confidence-based estimation to distinguish
clean and noisy pairs, then refine the noisy pairs via pseudo-label consistency
to uncover structurally distinct subsets. We further proposed a Pseudo-label
Consistency Score (PCS) to quantify prediction stability, enabling the
separation of ambiguous and refinable samples within noisy pairs. Accordingly,
we adopt Adaptive Pair Optimization (APO), where ambiguous samples are
optimized with robust loss functions and refinable ones are enhanced via text
replacement during training. Extensive experiments on CC152K, MS-COCO and
Flickr30K validate the effectiveness of our method in improving retrieval
robustness under noisy supervision.

</details>


### [49] [pFedSAM: Personalized Federated Learning of Segment Anything Model for Medical Image Segmentation](https://arxiv.org/abs/2509.15638)
*Tong Wang,Xingyue Zhao,Linghao Zhuang,Haoyu Zhao,Jiayi Yin,Yuyang He,Gang Yu,Bo Lin*

Main category: cs.CV

TL;DR: 提出了一种针对异构数据医学图像分割的个性化联邦SAM框架，通过聚合全局参数和保留L-MoE来处理跨客户端共性和领域特定特征，并使用解耦的全局-局部微调机制（知识蒸馏）来弥合全局和局部模型之间的差距。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习方法在处理复杂、异构的医学图像数据时，由于依赖轻量级架构，效果不佳；而SAM模型虽然分割能力强，但其巨大的编码器在联邦环境中存在挑战。

Method: 提出了一种个性化联邦SAM框架，包括：1）聚合全局参数以捕捉跨客户端共性，同时保留L-MoE组件以保存领域特定特征；2）通过知识蒸馏利用教师-学生范式进行解耦的全局-局部微调，以缩小全局共享模型和个性化局部模型之间的差距。

Result: 实验结果表明，该方法显著提高了分割性能，实现了鲁棒的跨域适应，并减少了通信开销。

Conclusion: 所提出的个性化联邦SAM框架有效地解决了异构数据医学图像分割中的挑战，并在性能、适应性和效率方面取得了显著的改进。

Abstract: Medical image segmentation is crucial for computer-aided diagnosis, yet
privacy constraints hinder data sharing across institutions. Federated learning
addresses this limitation, but existing approaches often rely on lightweight
architectures that struggle with complex, heterogeneous data. Recently, the
Segment Anything Model (SAM) has shown outstanding segmentation capabilities;
however, its massive encoder poses significant challenges in federated
settings. In this work, we present the first personalized federated SAM
framework tailored for heterogeneous data scenarios in medical image
segmentation. Our framework integrates two key innovations: (1) a personalized
strategy that aggregates only the global parameters to capture cross-client
commonalities while retaining the designed L-MoE (Localized Mixture-of-Experts)
component to preserve domain-specific features; and (2) a decoupled
global-local fine-tuning mechanism that leverages a teacher-student paradigm
via knowledge distillation to bridge the gap between the global shared model
and the personalized local models, thereby mitigating overgeneralization.
Extensive experiments on two public datasets validate that our approach
significantly improves segmentation performance, achieves robust cross-domain
adaptation, and reduces communication overhead.

</details>


### [50] [UNIV: Unified Foundation Model for Infrared and Visible Modalities](https://arxiv.org/abs/2509.15642)
*Fangyuan Mao,Shuo Wang,Jilin Mei,Chen Min,Shun Lu,Fuyang Liu,Yu Hu*

Main category: cs.CV

TL;DR: 为解决RGB可见光和红外图像融合感知中的挑战，提出了一种名为UNIV的统一基础模型，通过引入补丁级跨模态对比学习（PCCL）和双知识保留机制（结合LoRA和同步蒸馏），实现了有效的跨模态特征对齐和知识迁移，同时在MVIP数据集上取得了优越的性能，并在保持可见光任务性能的同时，提升了红外感知任务的表现。


<details>
  <summary>Details</summary>
Motivation: 当前的RGB可见光和红外感知模型在各自领域表现优异，但在融合感知场景（如自动驾驶）中表现不佳，因此需要一个能够有效融合两种模态数据的模型。

Method: 提出了一种名为UNIV的生物启发式统一基础模型，包含两个关键创新：1. 补丁级跨模态对比学习（PCCL）：一种受视网膜水平细胞侧抑制启发的注意力引导蒸馏框架，用于跨模态特征对齐。2. 双知识保留机制：模拟视网膜双极细胞信号路由，结合LoRA适配器（增加2%参数）和同步蒸馏，防止灾难性遗忘。此外，还引入了MVIP数据集作为跨模态学习的基准。

Result: 在MVIP数据集上的实验表明，UNIV模型在红外感知任务上表现优越（语义分割+1.7 mIoU，目标检测+0.7 mAP），同时在可见光RGB任务上保持了99%以上的基线性能。

Conclusion: UNIV模型通过模仿视网膜的生物机制，成功地实现了RGB可见光和红外信息的有效融合，提高了在各种天气条件下的感知鲁棒性，并且在保持原有可见光任务性能的同时，显著提升了红外感知任务的性能。

Abstract: The demand for joint RGB-visible and infrared perception is growing rapidly,
particularly to achieve robust performance under diverse weather conditions.
Although pre-trained models for RGB-visible and infrared data excel in their
respective domains, they often underperform in multimodal scenarios, such as
autonomous vehicles equipped with both sensors. To address this challenge, we
propose a biologically inspired UNified foundation model for Infrared and
Visible modalities (UNIV), featuring two key innovations. First, we introduce
Patch-wise Cross-modality Contrastive Learning (PCCL), an attention-guided
distillation framework that mimics retinal horizontal cells' lateral
inhibition, which enables effective cross-modal feature alignment while
remaining compatible with any transformer-based architecture. Second, our
dual-knowledge preservation mechanism emulates the retina's bipolar cell signal
routing - combining LoRA adapters (2% added parameters) with synchronous
distillation to prevent catastrophic forgetting, thereby replicating the
retina's photopic (cone-driven) and scotopic (rod-driven) functionality. To
support cross-modal learning, we introduce the MVIP dataset, the most
comprehensive visible-infrared benchmark to date. It contains 98,992 precisely
aligned image pairs spanning diverse scenarios. Extensive experiments
demonstrate UNIV's superior performance on infrared tasks (+1.7 mIoU in
semantic segmentation and +0.7 mAP in object detection) while maintaining 99%+
of the baseline performance on visible RGB tasks. Our code is available at
https://github.com/fangyuanmao/UNIV.

</details>


### [51] [GS-Scale: Unlocking Large-Scale 3D Gaussian Splatting Training via Host Offloading](https://arxiv.org/abs/2509.15645)
*Donghyun Lee,Dawoon Jeong,Jae W. Lee,Hongil Yoon*

Main category: cs.CV

TL;DR: GS-Scale通过将高斯点存储在CPU内存中，并按需将部分数据传输到GPU，实现了3D高斯泼溅的高效训练，显著降低了GPU内存需求，同时保持了与纯GPU训练相当的训练速度。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅在渲染方面表现出色，但大规模场景训练受限于GPU内存，需要存储参数、梯度和优化器状态。

Method: GS-Scale将所有高斯点存储在CPU内存中，仅在每次前向和后向传播时按需将部分数据传输到GPU。通过选择性地卸载几何参数、向前传递参数以实现CPU优化器更新与GPU计算的流水线化，以及延迟优化器更新来最小化不必要的内存访问，来解决CPU处理带来的性能瓶颈。

Result: GS-Scale将GPU内存需求降低了3.3-5.6倍，训练速度与未进行主机卸载的GPU训练相当。它能够在消费级GPU上训练大规模3D高斯泼溅，例如在RTX 4070 Mobile GPU上将高斯点数量从400万扩展到1800万，并带来23-35%的LPIPS改进。

Conclusion: GS-Scale是一种快速且内存高效的3D高斯泼溅训练系统，它通过创新的系统级优化，解决了大规模场景训练的内存限制问题，使得在消费级GPU上进行高质量的3D高斯泼溅训练成为可能。

Abstract: The advent of 3D Gaussian Splatting has revolutionized graphics rendering by
delivering high visual quality and fast rendering speeds. However, training
large-scale scenes at high quality remains challenging due to the substantial
memory demands required to store parameters, gradients, and optimizer states,
which can quickly overwhelm GPU memory. To address these limitations, we
propose GS-Scale, a fast and memory-efficient training system for 3D Gaussian
Splatting. GS-Scale stores all Gaussians in host memory, transferring only a
subset to the GPU on demand for each forward and backward pass. While this
dramatically reduces GPU memory usage, it requires frustum culling and
optimizer updates to be executed on the CPU, introducing slowdowns due to CPU's
limited compute and memory bandwidth. To mitigate this, GS-Scale employs three
system-level optimizations: (1) selective offloading of geometric parameters
for fast frustum culling, (2) parameter forwarding to pipeline CPU optimizer
updates with GPU computation, and (3) deferred optimizer update to minimize
unnecessary memory accesses for Gaussians with zero gradients. Our extensive
evaluations on large-scale datasets demonstrate that GS-Scale significantly
lowers GPU memory demands by 3.3-5.6x, while achieving training speeds
comparable to GPU without host offloading. This enables large-scale 3D Gaussian
Splatting training on consumer-grade GPUs; for instance, GS-Scale can scale the
number of Gaussians from 4 million to 18 million on an RTX 4070 Mobile GPU,
leading to 23-35% LPIPS (learned perceptual image patch similarity)
improvement.

</details>


### [52] [FingerSplat: Contactless Fingerprint 3D Reconstruction and Generation based on 3D Gaussian Splatting](https://arxiv.org/abs/2509.15648)
*Yuwei Jia,Yutang Lu,Zhe Cui,Fei Su*

Main category: cs.CV

TL;DR: 该研究提出了一种新颖的3D高斯喷溅框架，用于非接触式指纹的配准、重建和生成，旨在提升非接触式指纹识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有的非接触式指纹识别方法由于数据不足和缺乏隐式3D表示，性能落后于接触式方法。

Method: 利用3D高斯喷溅技术，实现从稀疏输入图像中进行非接触式指纹的3D配准、完整重建，且无需相机参数。

Result: 实验证明该方法能从2D图像精确地配准和重建3D指纹，并从3D模型生成高质量的非接触式指纹，从而提高识别性能。

Conclusion: 该方法为非接触式指纹识别提供了一个新的范式，通过集成3D指纹重建和生成，有效提高了识别准确率。

Abstract: Researchers have conducted many pioneer researches on contactless
fingerprints, yet the performance of contactless fingerprint recognition still
lags behind contact-based methods primary due to the insufficient contactless
fingerprint data with pose variations and lack of the usage of implicit 3D
fingerprint representations. In this paper, we introduce a novel contactless
fingerprint 3D registration, reconstruction and generation framework by
integrating 3D Gaussian Splatting, with the goal of offering a new paradigm for
contactless fingerprint recognition that integrates 3D fingerprint
reconstruction and generation. To our knowledge, this is the first work to
apply 3D Gaussian Splatting to the field of fingerprint recognition, and the
first to achieve effective 3D registration and complete reconstruction of
contactless fingerprints with sparse input images and without requiring camera
parameters information. Experiments on 3D fingerprint registration,
reconstruction, and generation prove that our method can accurately align and
reconstruct 3D fingerprints from 2D images, and sequentially generates
high-quality contactless fingerprints from 3D model, thus increasing the
performances for contactless fingerprint recognition.

</details>


### [53] [A PCA Based Model for Surface Reconstruction from Incomplete Point Clouds](https://arxiv.org/abs/2509.15675)
*Hao Liu*

Main category: cs.CV

TL;DR: 本研究提出了一种基于主成分分析（PCA）的模型，用于从不完整的点云数据中进行表面重建，解决了扫描过程中因光吸收和遮挡导致的数据缺失问题。


<details>
  <summary>Details</summary>
Motivation: 点云数据在数学建模中至关重要，但扫描过程中的数据缺失给表面重建带来挑战。

Method: 利用PCA估计法向量信息作为正则化项，并采用算子分裂法求解模型，以推断缺失区域的表面结构。

Result: 实验证明，该模型能有效推断缺失区域的表面结构，并成功重建表面，优于现有方法。

Conclusion: 本研究提出的PCA基模型能够从不完整的点云数据中进行有效的表面重建。

Abstract: Point cloud data represents a crucial category of information for
mathematical modeling, and surface reconstruction from such data is an
important task across various disciplines. However, during the scanning
process, the collected point cloud data may fail to cover the entire surface
due to factors such as high light-absorption rate and occlusions, resulting in
incomplete datasets. Inferring surface structures in data-missing regions and
successfully reconstructing the surface poses a challenge. In this paper, we
present a Principal Component Analysis (PCA) based model for surface
reconstruction from incomplete point cloud data. Initially, we employ PCA to
estimate the normal information of the underlying surface from the available
point cloud data. This estimated normal information serves as a regularizer in
our model, guiding the reconstruction of the surface, particularly in areas
with missing data. Additionally, we introduce an operator-splitting method to
effectively solve the proposed model. Through systematic experimentation, we
demonstrate that our model successfully infers surface structures in
data-missing regions and well reconstructs the underlying surfaces,
outperforming existing methodologies.

</details>


### [54] [Camera Splatting for Continuous View Optimization](https://arxiv.org/abs/2509.15677)
*Gahye Lee,Hyomin Kim,Gwangjin Ju,Jooeun Son,Hyejeong Yoon,Seungyong Lee*

Main category: cs.CV

TL;DR: Camera Splatting框架通过将相机表示为3D高斯，并使用点相机优化相机外围，在新视角合成方面优于FVS方法，尤其在处理复杂视图依赖现象时。


<details>
  <summary>Details</summary>
Motivation: 为了在新视角合成中更好地捕捉复杂的视图依赖现象（如金属反射和文本纹理），提出了Camera Splatting框架。

Method: 将每个相机建模为3D高斯（相机splat），并将虚拟相机（点相机）放置在表面附近的3D点上以观察相机splat的分布。通过微分地优化相机splat，使其从点相机观察到的分布符合预期，从而实现视图优化。

Result: 与Farthest View Sampling（FVS）方法相比，Camera Splatting优化后的视图在捕捉复杂的视图依赖现象方面表现出更优越的性能。

Conclusion: Camera Splatting框架在新视角合成方面取得了优于FVS的性能，特别是在处理具有挑战性的视觉效果时。

Abstract: We propose Camera Splatting, a novel view optimization framework for novel
view synthesis. Each camera is modeled as a 3D Gaussian, referred to as a
camera splat, and virtual cameras, termed point cameras, are placed at 3D
points sampled near the surface to observe the distribution of camera splats.
View optimization is achieved by continuously and differentiably refining the
camera splats so that desirable target distributions are observed from the
point cameras, in a manner similar to the original 3D Gaussian splatting.
Compared to the Farthest View Sampling (FVS) approach, our optimized views
demonstrate superior performance in capturing complex view-dependent phenomena,
including intense metallic reflections and intricate textures such as text.

</details>


### [55] [Towards Sharper Object Boundaries in Self-Supervised Depth Estimation](https://arxiv.org/abs/2509.15987)
*Aurélien Cecille,Stefan Duffner,Franck Davoine,Rémi Agier,Thibault Neveu*

Main category: cs.CV

TL;DR: 该方法使用自监督学习，通过将每像素深度建模为混合分布，实现了清晰的深度不连续性，提高了边界清晰度和点云质量。


<details>
  <summary>Details</summary>
Motivation: 现有单目深度估计方法在物体边界处存在模糊，导致出现虚假的中间3D点。而通常实现清晰边缘需要细粒度的监督，而本方法仅使用自监督即可实现清晰的深度不连续性。

Method: 将每像素深度建模为混合分布，捕捉多个可能的深度值，并将不确定性从直接回归转移到混合权重。该方法通过考虑方差的损失函数和不确定性传播，可以无缝集成到现有流程中。

Result: 在KITTI和VKITTIv2数据集上的评估表明，该方法实现了高达35%的边界清晰度提升，并改进了点云质量。

Conclusion: 该方法通过将每像素深度建模为混合分布，成功地在自监督条件下实现了清晰的深度不连续性，解决了现有方法的局限性，并在性能上优于最先进的方法。

Abstract: Accurate monocular depth estimation is crucial for 3D scene understanding,
but existing methods often blur depth at object boundaries, introducing
spurious intermediate 3D points. While achieving sharp edges usually requires
very fine-grained supervision, our method produces crisp depth discontinuities
using only self-supervision. Specifically, we model per-pixel depth as a
mixture distribution, capturing multiple plausible depths and shifting
uncertainty from direct regression to the mixture weights. This formulation
integrates seamlessly into existing pipelines via variance-aware loss functions
and uncertainty propagation. Extensive evaluations on KITTI and VKITTIv2 show
that our method achieves up to 35% higher boundary sharpness and improves point
cloud quality compared to state-of-the-art baselines.

</details>


### [56] [Layout Stroke Imitation: A Layout Guided Handwriting Stroke Generation for Style Imitation with Diffusion Model](https://arxiv.org/abs/2509.15678)
*Sidra Hanif,Longin Jan Latecki*

Main category: cs.CV

TL;DR: 该研究提出了一种结合多尺度注意力特征和词语布局的条件化扩散模型，用于生成具有书法风格的笔画，以解决现有方法在模仿书法风格和单词间距方面的问题。


<details>
  <summary>Details</summary>
Motivation: 现有手写笔画生成方法在模仿书法风格时未能充分考虑单词间距（单词布局）这一重要特征，导致生成的单词间距不一致。

Method: 提出了一种结合多尺度注意力特征和词语布局的条件化扩散模型来预测笔画。其中，多尺度注意力特征用于捕捉局部和全局的书法风格信息，而词语布局则用于确保单词间距的一致性。与直接生成图像的方法不同，该模型生成笔画，从而提供了缺失的时间坐标信息。

Result: 实验结果表明，所提出的扩散模型在笔画生成方面优于当前最先进的方法，并且在图像生成方面也具有竞争力。

Conclusion: 该研究提出的条件化扩散模型通过引入多尺度注意力特征和词语布局，能够更好地模仿书法风格和生成一致的单词间距，从而在手写笔画生成任务上取得了显著的进步。

Abstract: Handwriting stroke generation is crucial for improving the performance of
tasks such as handwriting recognition and writers order recovery. In
handwriting stroke generation, it is significantly important to imitate the
sample calligraphic style. The previous studies have suggested utilizing the
calligraphic features of the handwriting. However, they had not considered word
spacing (word layout) as an explicit handwriting feature, which results in
inconsistent word spacing for style imitation. Firstly, this work proposes
multi-scale attention features for calligraphic style imitation. These
multi-scale feature embeddings highlight the local and global style features.
Secondly, we propose to include the words layout, which facilitates word
spacing for handwriting stroke generation. Moreover, we propose a conditional
diffusion model to predict strokes in contrast to previous work, which directly
generated style images. Stroke generation provides additional temporal
coordinate information, which is lacking in image generation. Hence, our
proposed conditional diffusion model for stroke generation is guided by
calligraphic style and word layout for better handwriting imitation and stroke
generation in a calligraphic style. Our experimentation shows that the proposed
diffusion model outperforms the current state-of-the-art stroke generation and
is competitive with recent image generation networks.

</details>


### [57] [Saccadic Vision for Fine-Grained Visual Classification](https://arxiv.org/abs/2509.15688)
*Johann Schmidt,Sebastian Stober,Joachim Denzler,Paul Bodesheim*

Main category: cs.CV

TL;DR: 该论文提出了一种受人类视觉启发的两阶段方法，用于细粒度视觉分类（FGVC），通过提取外围特征和注视斑块，并结合选择性注意力机制，解决了现有基于部件的方法在特征定位和冗余性方面存在的挑战，并在多个基准数据集上取得了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于部件的细粒度视觉分类方法依赖于复杂的定位网络，需要深入理解图像内容，并且特征效用有限，同时采样点存在空间冗余，难以确定最优部件数量。本研究的动机是解决这些问题。

Method: 提出了一种受人类视觉启发（眼球运动）的两阶段方法：1. 提取外围特征并生成采样图。2. 并行编码注视斑块，使用权重共享编码器。3. 采用上下文选择性注意力机制加权注视斑块。4. 融合外围和注视表示。5. 使用非最大抑制来消除采样过程中的空间冗余。

Result: 在 CUB-200-2011、NABirds、Food-101、Stanford-Dogs、EU-Moths、Ecuador-Moths 和 AMI-Moths 等多个数据集上进行了评估，表明该方法取得了与最先进方法相当的性能，并且持续优于基线编码器。

Conclusion: 所提出的方法能够有效解决细粒度视觉分类中的挑战，并在多个标准和具有挑战性的数据集上取得了有竞争力的结果。

Abstract: Fine-grained visual classification (FGVC) requires distinguishing between
visually similar categories through subtle, localized features - a task that
remains challenging due to high intra-class variability and limited inter-class
differences. Existing part-based methods often rely on complex localization
networks that learn mappings from pixel to sample space, requiring a deep
understanding of image content while limiting feature utility for downstream
tasks. In addition, sampled points frequently suffer from high spatial
redundancy, making it difficult to quantify the optimal number of required
parts. Inspired by human saccadic vision, we propose a two-stage process that
first extracts peripheral features (coarse view) and generates a sample map,
from which fixation patches are sampled and encoded in parallel using a
weight-shared encoder. We employ contextualized selective attention to weigh
the impact of each fixation patch before fusing peripheral and focus
representations. To prevent spatial collapse - a common issue in part-based
methods - we utilize non-maximum suppression during fixation sampling to
eliminate redundancy. Comprehensive evaluation on standard FGVC benchmarks
(CUB-200-2011, NABirds, Food-101 and Stanford-Dogs) and challenging insect
datasets (EU-Moths, Ecuador-Moths and AMI-Moths) demonstrates that our method
achieves comparable performance to state-of-the-art approaches while
consistently outperforming our baseline encoder.

</details>


### [58] [SCENEFORGE: Enhancing 3D-text alignment with Structured Scene Compositions](https://arxiv.org/abs/2509.15693)
*Cristian Sbrolli,Matteo Matteucci*

Main category: cs.CV

TL;DR: SceneForge通过构建包含显式空间关系的多对象3D场景及其对应的多对象文本描述，来增强3D点云与文本的对比学习，有效解决了3D-文本数据集稀缺的问题，并在多个下游任务上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的3D-文本数据集规模有限，数据复杂性和多样性不足，限制了对比学习的效果。

Method: SceneForge框架通过组合单个3D形状来创建多对象场景，并辅以由大型语言模型改进的多对象文本描述。在对比训练中引入这些结构化的、组合性的样本，以丰富数据。研究了每场景对象数量、组合样本比例和场景构建策略等关键设计元素。

Result: SceneForge在ModelNet、ScanObjNN、Objaverse-LVIS和ScanNet等数据集的零样本分类任务上，以及ShapeNetPart数据集的少样本部件分割任务上，均实现了显著的性能提升。此外，在ScanQA数据集的3D视觉问答任务上也有所改进，并在检索场景中表现出鲁棒性，还能根据文本指令调整空间配置，展现出空间推理能力。

Conclusion: SceneForge通过引入结构化的场景组合样本，有效提升了3D-文本对比学习的效果，解决了大规模数据集稀缺的问题，并在多种3D理解任务上展现出优越的性能和泛化能力。其方法具有模型无关性，能够提升不同编码器架构的性能。

Abstract: The whole is greater than the sum of its parts-even in 3D-text contrastive
learning. We introduce SceneForge, a novel framework that enhances contrastive
alignment between 3D point clouds and text through structured multi-object
scene compositions. SceneForge leverages individual 3D shapes to construct
multi-object scenes with explicit spatial relations, pairing them with coherent
multi-object descriptions refined by a large language model. By augmenting
contrastive training with these structured, compositional samples, SceneForge
effectively addresses the scarcity of large-scale 3D-text datasets,
significantly enriching data complexity and diversity. We systematically
investigate critical design elements, such as the optimal number of objects per
scene, the proportion of compositional samples in training batches, and scene
construction strategies. Extensive experiments demonstrate that SceneForge
delivers substantial performance gains across multiple tasks, including
zero-shot classification on ModelNet, ScanObjNN, Objaverse-LVIS, and ScanNet,
as well as few-shot part segmentation on ShapeNetPart. SceneForge's
compositional augmentations are model-agnostic, consistently improving
performance across multiple encoder architectures. Moreover, SceneForge
improves 3D visual question answering on ScanQA, generalizes robustly to
retrieval scenarios with increasing scene complexity, and showcases spatial
reasoning capabilities by adapting spatial configurations to align precisely
with textual instructions.

</details>


### [59] [ORIC: Benchmarking Object Recognition in Incongruous Context for Large Vision-Language Models](https://arxiv.org/abs/2509.15695)
*Zhaoyang Li,Zhan Ling,Yuchen Zhou,Hao Su*

Main category: cs.CV

TL;DR: 大型视觉语言模型（LVLM）在处理不一致的上下文时，容易出现物体识别错误（例如，错误识别或幻觉）。为了解决这个问题，我们提出了ORIC基准测试，该测试通过LLM和CLIP引导的采样来系统地评估LVLM在不一致上下文中的表现。


<details>
  <summary>Details</summary>
Motivation: 评估大型视觉语言模型（LVLM）在不一致上下文中的物体识别能力，解决它们在物体识别方面存在的错误，例如物体错认和幻觉。

Method: 提出ORIC基准测试，并采用LLM引导采样和CLIP引导采样策略来识别不一致的上下文中的物体。评估18个LVLM和2个开放词汇检测模型。

Result: 在ORIC基准测试中，LVLM表现出显著的物体识别差距，表明上下文不一致性对模型提出了挑战。

Conclusion: 现有的LVLM在上下文感知物体识别方面存在局限性，需要进一步的研究来提高它们在不一致上下文中的鲁棒性。

Abstract: Large Vision-Language Models (LVLMs) have made significant strides in image
caption, visual question answering, and robotics by integrating visual and
textual information. However, they remain prone to errors in incongruous
contexts, where objects appear unexpectedly or are absent when contextually
expected. This leads to two key recognition failures: object misidentification
and hallucination. To systematically examine this issue, we introduce the
Object Recognition in Incongruous Context Benchmark (ORIC), a novel benchmark
that evaluates LVLMs in scenarios where object-context relationships deviate
from expectations. ORIC employs two key strategies: (1) LLM-guided sampling,
which identifies objects that are present but contextually incongruous, and (2)
CLIP-guided sampling, which detects plausible yet nonexistent objects that are
likely to be hallucinated, thereby creating an incongruous context. Evaluating
18 LVLMs and two open-vocabulary detection models, our results reveal
significant recognition gaps, underscoring the challenges posed by contextual
incongruity. This work provides critical insights into LVLMs' limitations and
encourages further research on context-aware object recognition.

</details>


### [60] [Training-Free Pyramid Token Pruning for Efficient Large Vision-Language Models via Region, Token, and Instruction-Guided Importance](https://arxiv.org/abs/2509.15704)
*Yuxuan Liang,Xu Li,Xiaolei Chen,Yi Zheng,Haotian Chen,Bin Li,Xiangyang Xue*

Main category: cs.CV

TL;DR: PTP通过结合自下而上的视觉显著性和自上而下的指令引导来修剪LVLM中的视觉标记，减少计算开销和延迟，且性能损失最小。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLM）在处理高分辨率图像时存在计算效率低的问题，现有方法（将图像分割成多个子图像）会显著增加视觉标记的数量，导致计算开销呈指数级增长。

Method: 提出了一种名为金字塔标记修剪（PTP）的免训练标记修剪策略，该策略将区域和标记层面的自下而上的视觉显著性与自上而下的指令引导重要性相结合。PTP借鉴了人类视觉注意力机制，优先保留视觉显著区域的标记，并利用文本指令精确定位与特定多模态任务最相关的标记。

Result: 在13个不同的基准测试中进行了广泛的实验，结果表明该方法显著降低了计算开销和推理延迟，同时将性能损失降至最低。

Conclusion: PTP是一种有效的策略，可以解决LVLM在高分辨率图像处理中的效率问题，通过有选择地保留重要视觉信息来减少计算负担。

Abstract: Large Vision-Language Models (LVLMs) have significantly advanced multimodal
understanding but still struggle with efficiently processing high-resolution
images. Recent approaches partition high-resolution images into multiple
sub-images, dramatically increasing the number of visual tokens and causing
exponential computational overhead during inference. To address these
limitations, we propose a training-free token pruning strategy, Pyramid Token
Pruning (PTP), that integrates bottom-up visual saliency at both region and
token levels with top-down instruction-guided importance. Inspired by human
visual attention mechanisms, PTP selectively retains more tokens from visually
salient regions and further leverages textual instructions to pinpoint tokens
most relevant to specific multimodal tasks. Extensive experiments across 13
diverse benchmarks demonstrate that our method substantially reduces
computational overhead and inference latency with minimal performance loss.

</details>


### [61] [SGMAGNet: A Baseline Model for 3D Cloud Phase Structure Reconstruction on a New Passive Active Satellite Benchmark](https://arxiv.org/abs/2509.15706)
*Chi Yang,Fu Wang,Xiaofei Yang,Hao Huang,Weijia Cao,Xiaowen Chu*

Main category: cs.CV

TL;DR: 本研究提出了一种利用多模态卫星观测数据（可见光、红外图像和雷达/激光雷达垂直剖面）进行3D云相态结构重建的基准数据集和框架，旨在改进数值天气预报中的云微物理参数化。


<details>
  <summary>Details</summary>
Motivation: 云相态剖面对于数值天气预报（NWP）至关重要，因为它直接影响辐射传输和降水过程。

Method: 构建了一个包含同步图像-剖面对的数据集，定义了一个监督学习任务，即给定可见光/红外图像块，预测相应的3D云相态结构。采用了SGMAGNet模型，并与UNet和SegNet等基线模型进行了比较。

Result: SGMAGNet在云相态重建方面表现出优越性能，特别是在复杂的多层云和边界过渡区域，其精确率、召回率、F1分数和IoU分别达到0.922、0.858、0.763和0.617，显著优于所有基线模型。

Conclusion: SGMAGNet在云相态重建任务上取得了最佳性能，为未来集成到NWP系统以改进云微物理参数化奠定了基础。

Abstract: Cloud phase profiles are critical for numerical weather prediction (NWP), as
they directly affect radiative transfer and precipitation processes. In this
study, we present a benchmark dataset and a baseline framework for transforming
multimodal satellite observations into detailed 3D cloud phase structures,
aiming toward operational cloud phase profile retrieval and future integration
with NWP systems to improve cloud microphysics parameterization. The multimodal
observations consist of (1) high--spatiotemporal--resolution, multi-band
visible (VIS) and thermal infrared (TIR) imagery from geostationary satellites,
and (2) accurate vertical cloud phase profiles from spaceborne lidar
(CALIOP\slash CALIPSO) and radar (CPR\slash CloudSat). The dataset consists of
synchronized image--profile pairs across diverse cloud regimes, defining a
supervised learning task: given VIS/TIR patches, predict the corresponding 3D
cloud phase structure. We adopt SGMAGNet as the main model and compare it with
several baseline architectures, including UNet variants and SegNet, all
designed to capture multi-scale spatial patterns. Model performance is
evaluated using standard classification metrics, including Precision, Recall,
F1-score, and IoU. The results demonstrate that SGMAGNet achieves superior
performance in cloud phase reconstruction, particularly in complex multi-layer
and boundary transition regions. Quantitatively, SGMAGNet attains a Precision
of 0.922, Recall of 0.858, F1-score of 0.763, and an IoU of 0.617,
significantly outperforming all baselines across these key metrics.

</details>


### [62] [Toward Medical Deepfake Detection: A Comprehensive Dataset and Novel Method](https://arxiv.org/abs/2509.15711)
*Shuaibo Li,Zhaohu Xing,Hongqiu Wang,Pengfei Hao,Xingyu Li,Zekai Liu,Lei Zhu*

Main category: cs.CV

TL;DR: 该研究提出了MedForensics数据集和DSKI模型，用于检测AI生成的医学影像，并取得了优于现有方法和人类专家的准确性。


<details>
  <summary>Details</summary>
Motivation: AI生成的医学影像带来了诊断欺骗、金融欺诈和虚假信息传播等风险，但现有研究和数据集不足，且通用媒体取证方法不适用于医学影像。

Method: 构建了MedForensics数据集，包含六种医学模态和十二种生成模型；提出了DSKI模型，包含跨域细粒度适配器（CDFA）和医学取证检索模块（MFRM），以提取细微伪造线索并提高少样本检索的检测准确性。

Result: DSKI模型在多种医学模态上显著优于现有方法和人类专家。

Conclusion: DSKI模型能够有效检测AI生成的医学影像，为应对相关挑战提供了解决方案。

Abstract: The rapid advancement of generative AI in medical imaging has introduced both
significant opportunities and serious challenges, especially the risk that fake
medical images could undermine healthcare systems. These synthetic images pose
serious risks, such as diagnostic deception, financial fraud, and
misinformation. However, research on medical forensics to counter these threats
remains limited, and there is a critical lack of comprehensive datasets
specifically tailored for this field. Additionally, existing media forensic
methods, which are primarily designed for natural or facial images, are
inadequate for capturing the distinct characteristics and subtle artifacts of
AI-generated medical images. To tackle these challenges, we introduce
\textbf{MedForensics}, a large-scale medical forensics dataset encompassing six
medical modalities and twelve state-of-the-art medical generative models. We
also propose \textbf{DSKI}, a novel \textbf{D}ual-\textbf{S}tage
\textbf{K}nowledge \textbf{I}nfusing detector that constructs a vision-language
feature space tailored for the detection of AI-generated medical images. DSKI
comprises two core components: 1) a cross-domain fine-trace adapter (CDFA) for
extracting subtle forgery clues from both spatial and noise domains during
training, and 2) a medical forensic retrieval module (MFRM) that boosts
detection accuracy through few-shot retrieval during testing. Experimental
results demonstrate that DSKI significantly outperforms both existing methods
and human experts, achieving superior accuracy across multiple medical
modalities.

</details>


### [63] [TrueMoE: Dual-Routing Mixture of Discriminative Experts for Synthetic Image Detection](https://arxiv.org/abs/2509.15741)
*Laixin Zhang,Shuaibo Li,Wei Ma,Hongbin Zha*

Main category: cs.CV

TL;DR: TrueMoE是一个创新的双路由混合判别模型，通过将检测任务重构为多个专业化、轻量级判别子空间之间的协作推理，有效解决了现有合成图像检测方法的泛化性不足问题。


<details>
  <summary>Details</summary>
Motivation: 现有合成图像检测方法通常试图构建单一、通用的判别空间，但这种方法复杂且脆弱，难以泛化到未知的生成模式。

Method: TrueMoE提出了一个包含判别专家阵列（DEA）的双路由混合判别模型。DEA沿着互补的流形结构和感知粒度轴进行组织，能够捕捉不同子空间中的伪造线索。双路由机制包括一个粒度感知稀疏路由器和一个流形感知密集路由器，能够自适应地将输入图像分配给最相关的专家。

Result: 在广泛的生成模型上的大量实验表明，TrueMoE在泛化性和鲁棒性方面表现优越。

Conclusion: TrueMoE通过其创新的双路由混合专家框架，克服了现有方法的局限性，为合成图像检测提供了更有效、更通用的解决方案。

Abstract: The rapid progress of generative models has made synthetic image detection an
increasingly critical task. Most existing approaches attempt to construct a
single, universal discriminative space to separate real from fake content.
However, such unified spaces tend to be complex and brittle, often struggling
to generalize to unseen generative patterns. In this work, we propose TrueMoE,
a novel dual-routing Mixture-of-Discriminative-Experts framework that
reformulates the detection task as a collaborative inference across multiple
specialized and lightweight discriminative subspaces. At the core of TrueMoE is
a Discriminative Expert Array (DEA) organized along complementary axes of
manifold structure and perceptual granularity, enabling diverse forgery cues to
be captured across subspaces. A dual-routing mechanism, comprising a
granularity-aware sparse router and a manifold-aware dense router, adaptively
assigns input images to the most relevant experts. Extensive experiments across
a wide spectrum of generative models demonstrate that TrueMoE achieves superior
generalization and robustness.

</details>


### [64] [Hybrid Lie semi-group and cascade structures for the generalized Gaussian derivative model for visual receptive fields](https://arxiv.org/abs/2509.15748)
*Tony Lindeberg*

Main category: cs.CV

TL;DR: 本篇论文解决了在不同视图条件下观察相似物体或时空事件时，由于自然图像变换导致的图像结构变化问题。作者提出基于协变感受野族来处理这种变化，通过扩展感受野形状以适应图像变换的自由度。


<details>
  <summary>Details</summary>
Motivation: 由于实际观察条件下图像结构的变化，早期视觉层级的感受野响应会受到几何变换的显著影响。处理这种变化的一种方法是基于协变感受野族，它扩展了感受野形状以适应图像变换的自由度。

Method: 本文推导了在多参数感受野族中，不同形状参数下得到的气微观和宏观关系。这包括（i）类似于半群和李群概念的微观关系，以及（ii）描述如何通过在更精细的空间和时间尺度上应用较小支撑的增量滤波器来计算更粗糙尺度上的感受野响应的宏观级联平滑特性。

Result: 本文的研究结果加深了对不同滤波器参数下空间和时空感受野响应之间关系的理解，可用于（ii）设计更有效的计算多参数感受野族中感受野响应的方案，以及（iii）构建生物视觉中简单细胞计算的理想化理论模型。

Conclusion: 本论文研究了在多参数感受野族中，不同形状参数下的空间和时空感受野响应之间的关系。推导了微观和宏观关系，并提出了这些结果在设计更有效的计算方案和构建生物视觉理论模型方面的应用。

Abstract: Because of the variabilities of real-world image structures under the natural
image transformations that arise when observing similar objects or
spatio-temporal events under different viewing conditions, the receptive field
responses computed in the earliest layers of the visual hierarchy may be
strongly influenced by such geometric image transformations. One way of
handling this variability is by basing the vision system on covariant receptive
field families, which expand the receptive field shapes over the degrees of
freedom in the image transformations.
  This paper addresses the problem of deriving relationships between spatial
and spatio-temporal receptive field responses obtained for different values of
the shape parameters in the resulting multi-parameter families of receptive
fields. For this purpose, we derive both (i) infinitesimal relationships,
roughly corresponding to a combination of notions from semi-groups and Lie
groups, as well as (ii) macroscopic cascade smoothing properties, which
describe how receptive field responses at coarser spatial and temporal scales
can be computed by applying smaller support incremental filters to the output
from corresponding receptive fields at finer spatial and temporal scales,
structurally related to the notion of Lie algebras, although with directional
preferences.
  The presented results provide (i) a deeper understanding of the relationships
between spatial and spatio-temporal receptive field responses for different
values of the filter parameters, which can be used for both (ii) designing more
efficient schemes for computing receptive field responses over populations of
multi-parameter families of receptive fields, as well as (iii)~formulating
idealized theoretical models of the computations of simple cells in biological
vision.

</details>


### [65] [FloorSAM: SAM-Guided Floorplan Reconstruction with Semantic-Geometric Fusion](https://arxiv.org/abs/2509.15750)
*Han Ye,Haofu Wang,Yunchi Zhang,Jiangjian Xiao,Yuqiang Jin,Jinyuan Liu,Wen-An Zhang,Uladzislau Sychou,Alexander Tuzikov,Vladislav Sobolevskii,Valerii Zakharov,Boris Sokolov,Minglei Fu*

Main category: cs.CV

TL;DR: FloorSAM是一个整合了点云密度图和Segment Anything Model (SAM)的框架，用于从LiDAR数据中精确重建建筑楼层平面图。


<details>
  <summary>Details</summary>
Motivation: 传统的楼层平面图重建方法在处理噪声、泛化性和几何细节方面存在不足，而FloorSAM旨在解决这些问题。

Method: FloorSAM利用点云密度图和SAM的零样本学习能力，通过网格过滤、自适应分辨率投影、图像增强、自适应提示点和多阶段过滤来生成精确的房间分割，并结合掩码和点云分析进行轮廓提取和正则化。

Result: 所提出的方法在Giblayout和ISPRS数据集上进行了测试，结果表明其在准确性、召回率和鲁棒性方面优于传统方法，尤其是在处理噪声和复杂场景时。

Conclusion: FloorSAM能够生成精确的楼层平面图，并恢复房间的拓扑关系，为室内导航、BIM和精确测量提供了更好的解决方案。

Abstract: Reconstructing building floor plans from point cloud data is key for indoor
navigation, BIM, and precise measurements. Traditional methods like geometric
algorithms and Mask R-CNN-based deep learning often face issues with noise,
limited generalization, and loss of geometric details. We propose FloorSAM, a
framework that integrates point cloud density maps with the Segment Anything
Model (SAM) for accurate floor plan reconstruction from LiDAR data. Using
grid-based filtering, adaptive resolution projection, and image enhancement, we
create robust top-down density maps. FloorSAM uses SAM's zero-shot learning for
precise room segmentation, improving reconstruction across diverse layouts.
Room masks are generated via adaptive prompt points and multistage filtering,
followed by joint mask and point cloud analysis for contour extraction and
regularization. This produces accurate floor plans and recovers room
topological relationships. Tests on Giblayout and ISPRS datasets show better
accuracy, recall, and robustness than traditional methods, especially in noisy
and complex settings. Code and materials: github.com/Silentbarber/FloorSAM.

</details>


### [66] [Simulated Cortical Magnification Supports Self-Supervised Object Learning](https://arxiv.org/abs/2509.15751)
*Zhengyang Yu,Arthur Aubret,Chen Yu,Jochen Triesch*

Main category: cs.CV

TL;DR: 最近的自监督学习模型通过模拟幼儿的视觉经验来学习物体表征，但忽略了人类视觉的中央凹特性（中心高分辨率，周边低分辨率）。本研究调查了这种可变分辨率在物体表征发展中的作用。


<details>
  <summary>Details</summary>
Motivation: 研究人类视觉的中央凹特性在物体表征发展中的作用，以提高自监督学习模型的性能。

Method: 使用包含人类与物体交互的自我中心视频数据集，应用人类中央凹和皮层放大模型修改输入，模拟视觉内容向周边逐渐模糊。将修改后的视频序列用于训练两个受生物启发的自监督学习模型。

Result: 模拟中央凹视觉有助于学习到更高质量的物体表征。分析表明，这得益于物体在视觉场中显得更大，以及中周边视觉信息之间的更好权衡。

Conclusion: 通过模拟人类的中央凹视觉，可以使自监督学习模型在物体表征学习上表现更佳，更接近真实的人类视觉学习过程。

Abstract: Recent self-supervised learning models simulate the development of semantic
object representations by training on visual experience similar to that of
toddlers. However, these models ignore the foveated nature of human vision with
high/low resolution in the center/periphery of the visual field. Here, we
investigate the role of this varying resolution in the development of object
representations. We leverage two datasets of egocentric videos that capture the
visual experience of humans during interactions with objects. We apply models
of human foveation and cortical magnification to modify these inputs, such that
the visual content becomes less distinct towards the periphery. The resulting
sequences are used to train two bio-inspired self-supervised learning models
that implement a time-based learning objective. Our results show that modeling
aspects of foveated vision improves the quality of the learned object
representations in this setting. Our analysis suggests that this improvement
comes from making objects appear bigger and inducing a better trade-off between
central and peripheral visual information. Overall, this work takes a step
towards making models of humans' learning of visual representations more
realistic and performant.

</details>


### [67] [MCOD: The First Challenging Benchmark for Multispectral Camouflaged Object Detection](https://arxiv.org/abs/2509.15753)
*Yang Li,Tingfa Xu,Shuyan Bai,Peifu Liu,Jianan Li*

Main category: cs.CV

TL;DR: MCOD是首个多光谱伪装目标检测数据集，解决了现有数据集仅支持RGB的局限性，提高了检测的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的RGB伪装目标检测方法在挑战性条件下性能受限，且缺乏支持多光谱方法的数据集，阻碍了该领域的发展。

Method: 提出MCOD数据集，该数据集包含全面的挑战属性、多样的真实世界场景和高质量的像素级标注，并在此数据集上评估了十一种代表性的COD方法。

Result: 在MCOD数据集上，所有方法均出现性能下降，但多光谱信息的融合显著缓解了这种下降，证明了其在增强检测鲁棒性方面的价值。

Conclusion: MCOD数据集为多光谱伪装目标检测的未来研究提供了坚实的基础，并强调了多光谱信息在提升检测性能中的重要性。

Abstract: Camouflaged Object Detection (COD) aims to identify objects that blend
seamlessly into natural scenes. Although RGB-based methods have advanced, their
performance remains limited under challenging conditions. Multispectral
imagery, providing rich spectral information, offers a promising alternative
for enhanced foreground-background discrimination. However, existing COD
benchmark datasets are exclusively RGB-based, lacking essential support for
multispectral approaches, which has impeded progress in this area. To address
this gap, we introduce MCOD, the first challenging benchmark dataset
specifically designed for multispectral camouflaged object detection. MCOD
features three key advantages: (i) Comprehensive challenge attributes: It
captures real-world difficulties such as small object sizes and extreme
lighting conditions commonly encountered in COD tasks. (ii) Diverse real-world
scenarios: The dataset spans a wide range of natural environments to better
reflect practical applications. (iii) High-quality pixel-level annotations:
Each image is manually annotated with precise object masks and corresponding
challenge attribute labels. We benchmark eleven representative COD methods on
MCOD, observing a consistent performance drop due to increased task difficulty.
Notably, integrating multispectral modalities substantially alleviates this
degradation, highlighting the value of spectral information in enhancing
detection robustness. We anticipate MCOD will provide a strong foundation for
future research in multispectral camouflaged object detection. The dataset is
publicly accessible at https://github.com/yl2900260-bit/MCOD.

</details>


### [68] [Overview of PlantCLEF 2024: multi-species plant identification in vegetation plot images](https://arxiv.org/abs/2509.15768)
*Herve Goeau,Vincent Espitalier,Pierre Bonnet,Alexis Joly*

Main category: cs.CV

TL;DR: 该论文介绍了 PlantCLEF 2024 挑战赛，该挑战赛利用包含数千张多标签图像和 800 多个物种的数据集，结合先进的视觉转换器模型，旨在提高 AI 在生态学研究中识别植物物种的效率。


<details>
  <summary>Details</summary>
Motivation: 利用 AI 提高生态学研究中植物物种识别的效率，扩展研究范围和覆盖范围。

Method: PlantCLEF 2024 挑战赛使用包含 170 万张植物图像的大型训练集和预训练的视觉转换器模型。评估方法为（弱标签）多标签分类任务，目标是预测高分辨率样地图像中的所有植物物种。

Result: 论文详细介绍了数据集、评估方法、参赛者使用的方法和模型以及取得的成果。

Conclusion: AI 在植物物种识别方面具有巨大潜力，PlantCLEF 2024 挑战赛为此提供了先进的数据集和模型，推动了相关领域的发展。

Abstract: Plot images are essential for ecological studies, enabling standardized
sampling, biodiversity assessment, long-term monitoring and remote, large-scale
surveys. Plot images are typically fifty centimetres or one square meter in
size, and botanists meticulously identify all the species found there. The
integration of AI could significantly improve the efficiency of specialists,
helping them to extend the scope and coverage of ecological studies. To
evaluate advances in this regard, the PlantCLEF 2024 challenge leverages a new
test set of thousands of multi-label images annotated by experts and covering
over 800 species. In addition, it provides a large training set of 1.7 million
individual plant images as well as state-of-the-art vision transformer models
pre-trained on this data. The task is evaluated as a (weakly-labeled)
multi-label classification task where the aim is to predict all the plant
species present on a high-resolution plot image (using the single-label
training data). In this paper, we provide an detailed description of the data,
the evaluation methodology, the methods and models employed by the participants
and the results achieved.

</details>


### [69] [Robust Vision-Language Models via Tensor Decomposition: A Defense Against Adversarial Attacks](https://arxiv.org/abs/2509.16163)
*Het Patel,Muzammil Allie,Qian Zhang,Jia Chen,Evangelos E. Papalexakis*

Main category: cs.CV

TL;DR: 提出一种轻量级防御方法，利用张量分解过滤视觉语言模型（VLMs）中的对抗性噪声，无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLMs）防御方法需要昂贵的重新训练或重大的架构更改，而本文提出了一种轻量级方法。

Method: 通过分解和重构视觉编码器表示来过滤对抗性噪声，同时保留其含义。

Result: 在COCO和Flickr30K数据集上，CLIP模型在使用本文方法后鲁棒性得到提升。在Flickr30K上，性能恢复了12.3%，Recall@1准确率从7.5%提高到19.8%。在COCO上，性能恢复了8.1%，准确率从3.8%提高到11.9%。张量训练分解在低秩（8-32）和低残差强度（α=0.1-0.2）下效果最佳。

Conclusion: 该方法是一种实用的、即插即用的解决方案，对现有的VLMs来说开销极小。

Abstract: Vision language models (VLMs) excel in multimodal understanding but are prone
to adversarial attacks. Existing defenses often demand costly retraining or
significant architecture changes. We introduce a lightweight defense using
tensor decomposition suitable for any pre-trained VLM, requiring no retraining.
By decomposing and reconstructing vision encoder representations, it filters
adversarial noise while preserving meaning. Experiments with CLIP on COCO and
Flickr30K show improved robustness. On Flickr30K, it restores 12.3\%
performance lost to attacks, raising Recall@1 accuracy from 7.5\% to 19.8\%. On
COCO, it recovers 8.1\% performance, improving accuracy from 3.8\% to 11.9\%.
Analysis shows Tensor Train decomposition with low rank (8-32) and low residual
strength ($\alpha=0.1-0.2$) is optimal. This method is a practical,
plug-and-play solution with minimal overhead for existing VLMs.

</details>


### [70] [Vision-Language Models as Differentiable Semantic and Spatial Rewards for Text-to-3D Generation](https://arxiv.org/abs/2509.15772)
*Weimin Bai,Yubo Li,Weijian Luo,Wenzheng Chen,He Sun*

Main category: cs.CV

TL;DR: VLM3D是一个新的文本到3D生成框架，通过集成大型视觉语言模型（VLM）到SDS流程中，解决了现有SDS方法在语义对齐和3D几何一致性方面的局限性，并在GPTeval3D基准测试中表现出显著优于先前方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于SDS的文本到3D生成方法依赖于CLIP风格的文本编码器，导致语义对齐粗糙，难以处理细粒度提示；并且2D扩散先验缺乏明确的3D空间约束，导致几何不一致和多对象场景中对象关系不准确。

Method: VLM3D框架将大型视觉语言模型（VLM）作为可微分的语义和空间先验集成到SDS流程中。VLM提供丰富的语言监督，实现细粒度提示对齐，并利用其内在的视觉语言建模能力来增强3D一致性和对象关系推理。

Result: 在GPTeval3D基准测试中，VLM3D在语义保真度、几何连贯性和空间准确性方面显著优于先前基于SDS的方法，在各种对象和复杂场景的生成中表现出色。

Conclusion: VLM3D通过集成VLM作为SDS流程中的先验，成功解决了现有方法的局限性，提高了文本到3D生成在语义和几何方面的质量，特别是在处理细粒度提示和复杂场景方面。

Abstract: Score Distillation Sampling (SDS) enables high-quality text-to-3D generation
by supervising 3D models through the denoising of multi-view 2D renderings,
using a pretrained text-to-image diffusion model to align with the input prompt
and ensure 3D consistency. However, existing SDS-based methods face two
fundamental limitations: (1) their reliance on CLIP-style text encoders leads
to coarse semantic alignment and struggles with fine-grained prompts; and (2)
2D diffusion priors lack explicit 3D spatial constraints, resulting in
geometric inconsistencies and inaccurate object relationships in multi-object
scenes. To address these challenges, we propose VLM3D, a novel text-to-3D
generation framework that integrates large vision-language models (VLMs) into
the SDS pipeline as differentiable semantic and spatial priors. Unlike standard
text-to-image diffusion priors, VLMs leverage rich language-grounded
supervision that enables fine-grained prompt alignment. Moreover, their
inherent vision language modeling provides strong spatial understanding, which
significantly enhances 3D consistency for single-object generation and improves
relational reasoning in multi-object scenes. We instantiate VLM3D based on the
open-source Qwen2.5-VL model and evaluate it on the GPTeval3D benchmark.
Experiments across diverse objects and complex scenes show that VLM3D
significantly outperforms prior SDS-based methods in semantic fidelity,
geometric coherence, and spatial correctness.

</details>


### [71] [Enriched Feature Representation and Motion Prediction Module for MOSEv2 Track of 7th LSVOS Challenge: 3rd Place Solution](https://arxiv.org/abs/2509.15781)
*Chang Soo Lim,Joonyoung Moon,Donghyeon Cho*

Main category: cs.CV

TL;DR: 本研究提出的SCOPE框架整合了Cutie和SAM2的优点，并通过引入运动预测模块和集成策略，在LSVOS挑战赛MOSEv2赛道上取得了第三名的成绩。


<details>
  <summary>Details</summary>
Motivation: 现有的视频对象分割方法（如Cutie和SAM2）在特征容量和时序建模方面存在局限性。本研究旨在克服这些局限性，以提高视频对象分割的鲁棒性。

Method: 本研究提出了一种新框架，将SAM2的ViT编码器替换Cutie的编码器，并引入运动预测模块来增强时序建模。此外，还采用了一种集成策略，结合了Cutie、SAM2和本研究的变体模型。

Result: 所提出的SCOPE框架在LSVOS挑战赛MOSEv2赛道上取得了第三名，证明了富集特征表示和运动预测在视频对象分割中的有效性。

Conclusion: 富集特征表示和运动预测是实现鲁棒视频对象分割的关键。

Abstract: Video object segmentation (VOS) is a challenging task with wide applications
such as video editing and autonomous driving. While Cutie provides strong
query-based segmentation and SAM2 offers enriched representations via a
pretrained ViT encoder, each has limitations in feature capacity and temporal
modeling. In this report, we propose a framework that integrates their
complementary strengths by replacing the encoder of Cutie with the ViT encoder
of SAM2 and introducing a motion prediction module for temporal stability. We
further adopt an ensemble strategy combining Cutie, SAM2, and our variant,
achieving 3rd place in the MOSEv2 track of the 7th LSVOS Challenge. We refer to
our final model as SCOPE (SAM2-CUTIE Object Prediction Ensemble). This
demonstrates the effectiveness of enriched feature representation and motion
prediction for robust video object segmentation. The code is available at
https://github.com/2025-LSVOS-3rd-place/MOSEv2_3rd_place.

</details>


### [72] [MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid Vision Tokenizer](https://arxiv.org/abs/2509.16197)
*Yanghao Li,Rui Qian,Bowen Pan,Haotian Zhang,Haoshuo Huang,Bowen Zhang,Jialing Tong,Haoxuan You,Xianzhi Du,Zhe Gan,Hyunjik Kim,Chao Jia,Zhenbang Wang,Yinfei Yang,Mingfei Gao,Zi-Yi Dou,Wenze Hu,Chang Gao,Dongxu Li,Philipp Dufter,Zirui Wang,Guoli Yin,Zhengdong Zhang,Chen Chen,Yang Zhao,Ruoming Pang,Zhifeng Chen*

Main category: cs.CV

TL;DR: Manzano 是一个统一的多模态大语言模型框架，通过混合图像分词器和精选的训练方法，平衡了图像理解和生成能力，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有开源模型在多模态理解和生成能力之间存在性能权衡，需要一个能同时优化这两种能力的框架。

Method: Manzano 使用单个共享视觉编码器，通过两个轻量级适配器生成用于图像到文本理解的连续嵌入和用于文本到图像生成的离散标记。统一的自回归大语言模型处理这些标记，并辅以扩散解码器将图像标记转换为像素。该框架还采用了统一的训练策略。

Result: Manzano 在统一模型中取得了最先进的成果，在文本丰富的评估方面与专业模型相比也具有竞争力。研究表明，该模型任务冲突很小，并且随着模型规模的增大而持续改进。

Conclusion: Manzano 的混合分词器设计是有效的，它成功地平衡了多模态能力，并且易于扩展。

Abstract: Unified multimodal Large Language Models (LLMs) that can both understand and
generate visual content hold immense potential. However, existing open-source
models often suffer from a performance trade-off between these capabilities. We
present Manzano, a simple and scalable unified framework that substantially
reduces this tension by coupling a hybrid image tokenizer with a well-curated
training recipe. A single shared vision encoder feeds two lightweight adapters
that produce continuous embeddings for image-to-text understanding and discrete
tokens for text-to-image generation within a common semantic space. A unified
autoregressive LLM predicts high-level semantics in the form of text and image
tokens, with an auxiliary diffusion decoder subsequently translating the image
tokens into pixels. The architecture, together with a unified training recipe
over understanding and generation data, enables scalable joint learning of both
capabilities. Manzano achieves state-of-the-art results among unified models,
and is competitive with specialist models, particularly on text-rich
evaluation. Our studies show minimal task conflicts and consistent gains from
scaling model size, validating our design choice of a hybrid tokenizer.

</details>


### [73] [Ideal Registration? Segmentation is All You Need](https://arxiv.org/abs/2509.15784)
*Xiang Chen,Fengting Zhang,Qinghao Liu,Min Liu,Kun Wu,Yaonan Wang,Hang Zhang*

Main category: cs.CV

TL;DR: SegReg通过基于分割的自适应正则化解决了现有图像配准方法中存在的平滑性约束不足的问题，在多个临床场景下取得了优于现有方法的性能，并将配准精度与分割质量联系起来。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习图像配准方法通常使用全局统一的平滑性约束，无法处理解剖运动中存在的复杂、区域性变化的形变，因此需要一种能够适应区域性形变模式的配准框架。

Method: SegReg首先通过分割将输入的移动和固定图像分解为解剖上一致的子区域。然后，这些局部区域由相同的配准骨干网络处理，以计算优化的局部形变场，并将这些局部形变场整合为全局形变场。

Result: SegReg使用地面真实分割在关键解剖结构上实现了近乎完美的结构对齐（Dice系数为98.23%），并且在心脏、腹部和肺部图像的三个临床配准场景中，即使使用自动分割，其性能也优于现有方法2-12%。

Conclusion: SegReg通过利用区域特定的形变模式来实现解剖自适应正则化，克服了现有方法的局限性，并且其配准精度与分割质量呈现出近乎线性的依赖关系，将配准问题转化为分割问题。

Abstract: Deep learning has revolutionized image registration by its ability to handle
diverse tasks while achieving significant speed advantages over conventional
approaches. Current approaches, however, often employ globally uniform
smoothness constraints that fail to accommodate the complex, regionally varying
deformations characteristic of anatomical motion. To address this limitation,
we propose SegReg, a Segmentation-driven Registration framework that implements
anatomically adaptive regularization by exploiting region-specific deformation
patterns. Our SegReg first decomposes input moving and fixed images into
anatomically coherent subregions through segmentation. These localized domains
are then processed by the same registration backbone to compute optimized
partial deformation fields, which are subsequently integrated into a global
deformation field. SegReg achieves near-perfect structural alignment (98.23%
Dice on critical anatomies) using ground-truth segmentation, and outperforms
existing methods by 2-12% across three clinical registration scenarios
(cardiac, abdominal, and lung images) even with automatic segmentation. Our
SegReg demonstrates a near-linear dependence of registration accuracy on
segmentation quality, transforming the registration challenge into a
segmentation problem. The source code will be released upon manuscript
acceptance.

</details>


### [74] [CBPNet: A Continual Backpropagation Prompt Network for Alleviating Plasticity Loss on Edge Devices](https://arxiv.org/abs/2509.15785)
*Runjie Shao,Boyu Diao,Zijia An,Ruiqi Liu,Yongjun Xu*

Main category: cs.CV

TL;DR: 在机器人和自动驾驶等应用中，为了满足对动态环境的实时响应需求，适合边缘设备的持续学习方法受到了越来越多的关注。然而，仅使用提示来更新冻结的预训练模型会引入新的瓶颈：可塑性损失，即模型学习新知识的能力会因冻结的主干和有限的提示参数而减弱。为了解决这个问题，本文提出了持续反向传播提示网络（CBPNet），这是一个旨在恢复模型学习活力的有效且参数高效的框架。通过集成一个能够通过自适应地重新初始化未充分利用的参数来抵消可塑性衰减的‘高效CBP块’，CBPNet能够有效缓解这个问题。


<details>
  <summary>Details</summary>
Motivation: 为了满足机器人和自动驾驶等需要对动态环境进行实时响应的应用的需求，适合边缘设备的有效持续学习方法受到了越来越多的关注。然而，使用冻结的预训练模型和提示词（prompt）成为对抗灾难性遗忘的主流策略，但这种方法引入了一个新的关键瓶颈：可塑性损失，即模型学习新知识的能力会因为冻结的主干网络和有限的提示词参数而减弱。作者认为这种可塑性的降低源于在训练过程中利用不足的参数缺乏更新活力。

Method: 提出持续反向传播提示网络（CBPNet），一个旨在恢复模型学习活力的有效且参数高效的框架。该框架创新性地集成了一个高效的CBP块，通过自适应地重新初始化那些利用不足的参数来抵消可塑性衰减。

Result: 在边缘设备上的实验结果表明，CBPNet在多个基准测试中都表现出了有效性。在Split CIFAR-100上，其平均准确率比强基线提高了1%以上；在更具挑战性的Split ImageNet-R上，其准确率达到了69.41%，达到了当前最优水平。

Conclusion: CBPNet通过训练占主干模型参数量0.2%以下的额定参数，有效恢复了模型的学习活力，解决了仅使用提示词更新冻结模型带来的可塑性损失问题，并在Split CIFAR-100和Split ImageNet-R等基准测试中取得了优于现有方法的性能。

Abstract: To meet the demands of applications like robotics and autonomous driving that
require real-time responses to dynamic environments, efficient continual
learning methods suitable for edge devices have attracted increasing attention.
In this transition, using frozen pretrained models with prompts has become a
mainstream strategy to combat catastrophic forgetting. However, this approach
introduces a new critical bottleneck: plasticity loss, where the model's
ability to learn new knowledge diminishes due to the frozen backbone and the
limited capacity of prompt parameters. We argue that the reduction in
plasticity stems from a lack of update vitality in underutilized parameters
during the training process. To this end, we propose the Continual
Backpropagation Prompt Network (CBPNet), an effective and parameter efficient
framework designed to restore the model's learning vitality. We innovatively
integrate an Efficient CBP Block that counteracts plasticity decay by
adaptively reinitializing these underutilized parameters. Experimental results
on edge devices demonstrate CBPNet's effectiveness across multiple benchmarks.
On Split CIFAR-100, it improves average accuracy by over 1% against a strong
baseline, and on the more challenging Split ImageNet-R, it achieves a state of
the art accuracy of 69.41%. This is accomplished by training additional
parameters that constitute less than 0.2% of the backbone's size, validating
our approach.

</details>


### [75] [FoBa: A Foreground-Background co-Guided Method and New Benchmark for Remote Sensing Semantic Change Detection](https://arxiv.org/abs/2509.15788)
*Haotian Zhang,Han Guo,Keyan Chen,Hao Chen,Zhengxia Zou,Zhenwei Shi*

Main category: cs.CV

TL;DR: 本文提出LevirSCD数据集和FoBa方法，以解决遥感语义变化检测（SCD）中数据集不足和方法利用变化信息不足的问题。LevirSCD包含16类变化和210种变化类型，解决了类别定义不精细的问题。FoBa方法利用前景-背景协同指导，并结合GIF模块和一致性损失，提高了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有遥感语义变化检测（SCD）数据集在变化类别、类型和细粒度定义上存在不足，难以满足实际应用需求。现有方法对变化信息的利用不足，通常仅作为后处理步骤，限制了模型性能的进一步提升。

Method: 提出LevirSCD数据集，包含16类变化和210种变化类型，细化了类别定义。提出前景-背景协同指导（FoBa）方法，利用关注感兴趣区域的前景和包含上下文信息背景来协同指导模型，以减轻语义模糊性并增强检测细微变化的能力。引入门控交互融合（GIF）模块和一致性损失，以满足双时相交互和空间一致性的需求。

Result: 在LevirSCD、SECOND和JL1三个数据集上进行的大量实验表明，FoBa方法在SeK指标上分别比当前SOTA方法提高了1.48%、3.61%和2.81%。

Conclusion: 提出的LevirSCD数据集和FoBa方法在遥感语义变化检测任务上取得了显著的改进，证明了其有效性和实用性。

Abstract: Despite the remarkable progress achieved in remote sensing semantic change
detection (SCD), two major challenges remain. At the data level, existing SCD
datasets suffer from limited change categories, insufficient change types, and
a lack of fine-grained class definitions, making them inadequate to fully
support practical applications. At the methodological level, most current
approaches underutilize change information, typically treating it as a
post-processing step to enhance spatial consistency, which constrains further
improvements in model performance. To address these issues, we construct a new
benchmark for remote sensing SCD, LevirSCD. Focused on the Beijing area, the
dataset covers 16 change categories and 210 specific change types, with more
fine-grained class definitions (e.g., roads are divided into unpaved and paved
roads). Furthermore, we propose a foreground-background co-guided SCD (FoBa)
method, which leverages foregrounds that focus on regions of interest and
backgrounds enriched with contextual information to guide the model
collaboratively, thereby alleviating semantic ambiguity while enhancing its
ability to detect subtle changes. Considering the requirements of bi-temporal
interaction and spatial consistency in SCD, we introduce a Gated Interaction
Fusion (GIF) module along with a simple consistency loss to further enhance the
model's detection performance. Extensive experiments on three datasets (SECOND,
JL1, and the proposed LevirSCD) demonstrate that FoBa achieves competitive
results compared to current SOTA methods, with improvements of 1.48%, 3.61%,
and 2.81% in the SeK metric, respectively. Our code and dataset are available
at https://github.com/zmoka-zht/FoBa.

</details>


### [76] [Minimal Semantic Sufficiency Meets Unsupervised Domain Generalization](https://arxiv.org/abs/2509.15791)
*Tan Pan,Kaiyu Guo,Dongli Xu,Zhaorui Tan,Chen Jiang,Deshu Chen,Xin Guo,Brian C. Lovell,Limei Han,Yuan Cheng,Mahsa Baktashmotlagh*

Main category: cs.CV

TL;DR: 该研究提出了最小充分语义表征（MS-UDG）框架，用于解决无监督域泛化（UDG）问题，该框架通过信息论实现表征的充分性和最小化，并在常用UDG基准上取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 当前无监督学习（尤其是自监督学习）的泛化能力研究尚不充分，UDG任务面临在无类别标签的情况下区分语义与变化的挑战，且现有方法依赖的域标签在现实中不可用。

Method: 将UDG形式化为学习最小充分语义表征的任务，该表征需要满足充分性（保留跨增强视图共享的语义信息）和最小化（最大程度去除与语义无关的信息）。通过结合基于InfoNCE的目标（实现充分性）、语义-变异解耦损失和基于重建的机制（实现最小化）来实践这一优化。

Result: MS-UDG 在常用的无监督域泛化基准测试中设定了新的最先进水平，其性能始终优于现有的自监督学习和 UDG 方法，并且在表征学习过程中不使用类别或域标签。

Conclusion: 所提出的 MS-UDG 框架通过信息论视角，利用最小充分语义表征有效解决了无监督域泛化问题，并在实践中取得了优异的性能。

Abstract: The generalization ability of deep learning has been extensively studied in
supervised settings, yet it remains less explored in unsupervised scenarios.
Recently, the Unsupervised Domain Generalization (UDG) task has been proposed
to enhance the generalization of models trained with prevalent unsupervised
learning techniques, such as Self-Supervised Learning (SSL). UDG confronts the
challenge of distinguishing semantics from variations without category labels.
Although some recent methods have employed domain labels to tackle this issue,
such domain labels are often unavailable in real-world contexts. In this paper,
we address these limitations by formalizing UDG as the task of learning a
Minimal Sufficient Semantic Representation: a representation that (i) preserves
all semantic information shared across augmented views (sufficiency), and (ii)
maximally removes information irrelevant to semantics (minimality). We
theoretically ground these objectives from the perspective of information
theory, demonstrating that optimizing representations to achieve sufficiency
and minimality directly reduces out-of-distribution risk. Practically, we
implement this optimization through Minimal-Sufficient UDG (MS-UDG), a
learnable model by integrating (a) an InfoNCE-based objective to achieve
sufficiency; (b) two complementary components to promote minimality: a novel
semantic-variation disentanglement loss and a reconstruction-based mechanism
for capturing adequate variation. Empirically, MS-UDG sets a new
state-of-the-art on popular unsupervised domain-generalization benchmarks,
consistently outperforming existing SSL and UDG methods, without category or
domain labels during representation learning.

</details>


### [77] [TASAM: Terrain-and-Aware Segment Anything Model for Temporal-Scale Remote Sensing Segmentation](https://arxiv.org/abs/2509.15795)
*Tianyang Wang,Xi Xiao,Gaofei Chen,Hanzhang Chi,Qi Zhang,Guo Cheng,Yingrui Ji*

Main category: cs.CV

TL;DR: TASAM通过引入地形感知适配器、时间提示生成器和多尺度融合策略，扩展了SAM模型以应对高分辨率遥感图像分割的挑战，在三个基准测试中取得了显著的性能提升，并且计算开销极小。


<details>
  <summary>Details</summary>
Motivation: SAM在遥感数据上泛化能力不足，存在复杂地形、多尺度物体和时间动态等挑战。本研究旨在提出一种能够处理这些挑战的遥感图像分割方法。

Method: TASAM模型集成了三种轻量级模块：地形感知适配器（注入高程先验）、时间提示生成器（捕捉土地覆盖随时间的变化）和多尺度融合策略（增强细粒度物体分割）。该方法在不重新训练SAM主干模型的情况下进行。

Result: 在LoveDA、iSAID和WHU-CD三个遥感基准测试中，TASAM在分割性能上取得了显著的提升，优于零样本SAM和特定任务的模型，同时计算开销很小。

Conclusion: TASAM的成果凸显了领域自适应增强对于基础模型的价值，并为更鲁棒的地理空间分割提供了可扩展的途径。

Abstract: Segment Anything Model (SAM) has demonstrated impressive zero-shot
segmentation capabilities across natural image domains, but it struggles to
generalize to the unique challenges of remote sensing data, such as complex
terrain, multi-scale objects, and temporal dynamics. In this paper, we
introduce TASAM, a terrain and temporally-aware extension of SAM designed
specifically for high-resolution remote sensing image segmentation. TASAM
integrates three lightweight yet effective modules: a terrain-aware adapter
that injects elevation priors, a temporal prompt generator that captures
land-cover changes over time, and a multi-scale fusion strategy that enhances
fine-grained object delineation. Without retraining the SAM backbone, our
approach achieves substantial performance gains across three remote sensing
benchmarks-LoveDA, iSAID, and WHU-CD-outperforming both zero-shot SAM and
task-specific models with minimal computational overhead. Our results highlight
the value of domain-adaptive augmentation for foundation models and offer a
scalable path toward more robust geospatial segmentation.

</details>


### [78] [ChronoForge-RL: Chronological Forging through Reinforcement Learning for Enhanced Video Understanding](https://arxiv.org/abs/2509.15800)
*Kehua Chen*

Main category: cs.CV

TL;DR: ChronoForge-RL框架结合了TAD和KF-GRPO，通过可微分的关键帧选择机制和对比学习来解决视频理解中的计算效率和信息帧选择问题，在VideoMME和LVBench上取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前视频理解方法在处理密集视频内容时计算量大，且难以通过均匀采样策略识别语义显著帧。

Method: 提出ChronoForge-RL框架，包含：1. 可微分的关键帧选择机制（三阶段）；2. 时间注意力蒸馏（TAD），通过变异评分、拐点检测和优先蒸馏选择信息帧；3. 关键帧感知组相对策略优化（KF-GRPO），通过对比学习和显著性增强奖励机制来利用帧内容和时间关系。

Result: 在VideoMME上达到69.1%，在LVBench上达到52.7%，性能超越现有方法，且7B参数模型性能可媲美72B参数模型。

Conclusion: ChronoForge-RL框架通过创新的关键帧选择和时间推理机制，显著提高了视频理解的效率和性能。

Abstract: Current state-of-the-art video understanding methods typically struggle with
two critical challenges: (1) the computational infeasibility of processing
every frame in dense video content and (2) the difficulty in identifying
semantically significant frames through naive uniform sampling strategies. In
this paper, we propose a novel video understanding framework, called
ChronoForge-RL, which combines Temporal Apex Distillation (TAD) and
KeyFrame-aware Group Relative Policy Optimization (KF-GRPO) to tackle these
issues. Concretely, we introduce a differentiable keyframe selection mechanism
that systematically identifies semantic inflection points through a three-stage
process to enhance computational efficiency while preserving temporal
information. Then, two particular modules are proposed to enable effective
temporal reasoning: Firstly, TAD leverages variation scoring, inflection
detection, and prioritized distillation to select the most informative frames.
Secondly, we introduce KF-GRPO which implements a contrastive learning paradigm
with a saliency-enhanced reward mechanism that explicitly incentivizes models
to leverage both frame content and temporal relationships. Finally, our
proposed ChronoForge-RL achieves 69.1% on VideoMME and 52.7% on LVBench
compared to baseline methods, clearly surpassing previous approaches while
enabling our 7B parameter model to achieve performance comparable to 72B
parameter alternatives.

</details>


### [79] [CIDER: A Causal Cure for Brand-Obsessed Text-to-Image Models](https://arxiv.org/abs/2509.15803)
*Fangjian Shen,Zifeng Liang,Chao Wang,Wushao Wen*

Main category: cs.CV

TL;DR: CIDER框架通过在推理时优化提示来减少文本到图像模型中的品牌偏见，而无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 文本到图像模型存在显著的“品牌偏见”，即在通用提示下生成主要商业品牌内容的倾向，这带来了道德和法律风险。

Method: 使用轻量级检测器识别品牌内容，并使用视觉语言模型（VLM）生成风格迥异的替代内容。引入品牌中立性得分（BNS）来量化此问题。

Result: CIDER显著减少了显性和隐性偏见，同时保持了图像质量和美观。

Conclusion: CIDER为生成更具原创性和公平性的内容提供了一个实用的解决方案，有助于构建值得信赖的生成式人工智能。

Abstract: Text-to-image (T2I) models exhibit a significant yet under-explored "brand
bias", a tendency to generate contents featuring dominant commercial brands
from generic prompts, posing ethical and legal risks. We propose CIDER, a
novel, model-agnostic framework to mitigate bias at inference-time through
prompt refinement to avoid costly retraining. CIDER uses a lightweight detector
to identify branded content and a Vision-Language Model (VLM) to generate
stylistically divergent alternatives. We introduce the Brand Neutrality Score
(BNS) to quantify this issue and perform extensive experiments on leading T2I
models. Results show CIDER significantly reduces both explicit and implicit
biases while maintaining image quality and aesthetic appeal. Our work offers a
practical solution for more original and equitable content, contributing to the
development of trustworthy generative AI.

</details>


### [80] [Boosting Active Learning with Knowledge Transfer](https://arxiv.org/abs/2509.15805)
*Tianyang Wang,Xi Xiao,Gaofei Chen,Xiaoying Liao,Guo Cheng,Yingrui Ji*

Main category: cs.CV

TL;DR: 提出一种利用知识迁移来增强主动学习（AL）中不确定性估计的新方法，利用教师-学生模式，其中教师是AL中的任务模型，学生是学习教师的辅助模型。


<details>
  <summary>Details</summary>
Motivation: 现有的不确定性估计方法通常需要复杂的辅助模型和高级的训练方式，难以训练，尤其是在计算生物学中的低温电子断层扫描（cryo-ET）分类等领域任务中。

Method: 在每个AL周期中同时训练教师和学生模型，并采用模型输出之间的特定距离来衡量未标记数据的不确定性。学生模型与任务无关，不需要特殊的训练方式（例如对抗性训练），适用于各种任务。

Result: 在经典的计算机视觉任务和cryo-ET挑战中进行了广泛的实验，证明了该方法的有效性和效率。

Conclusion: 所提出的方法通过知识迁移有效提升了主动学习中的不确定性估计，且适用于多种任务。

Abstract: Uncertainty estimation is at the core of Active Learning (AL). Most existing
methods resort to complex auxiliary models and advanced training fashions to
estimate uncertainty for unlabeled data. These models need special design and
hence are difficult to train especially for domain tasks, such as Cryo-Electron
Tomography (cryo-ET) classification in computational biology. To address this
challenge, we propose a novel method using knowledge transfer to boost
uncertainty estimation in AL. Specifically, we exploit the teacher-student mode
where the teacher is the task model in AL and the student is an auxiliary model
that learns from the teacher. We train the two models simultaneously in each AL
cycle and adopt a certain distance between the model outputs to measure
uncertainty for unlabeled data. The student model is task-agnostic and does not
rely on special training fashions (e.g. adversarial), making our method
suitable for various tasks. More importantly, we demonstrate that data
uncertainty is not tied to concrete value of task loss but closely related to
the upper-bound of task loss. We conduct extensive experiments to validate the
proposed method on classical computer vision tasks and cryo-ET challenges. The
results demonstrate its efficacy and efficiency.

</details>


### [81] [LC-SLab -- An Object-based Deep Learning Framework for Large-scale Land Cover Classification from Satellite Imagery and Sparse In-situ Labels](https://arxiv.org/abs/2509.15868)
*Johannes Leonhardt,Juergen Gall,Ribana Roscher*

Main category: cs.CV

TL;DR: 提出LC-SLab框架，利用面向对象的方法和稀疏监督，提高深度学习在土地覆盖分类中的精度和连贯性。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的土地覆盖绘图方法在处理空间覆盖稀疏的实地数据时，预测结果常出现碎片化和噪声问题。面向对象分类虽然有潜力解决此问题，但在深度学习土地覆盖绘图流程中，尤其是在中等分辨率成像和稀疏监督的背景下，仍未得到充分探索。

Method: 提出LC-SLab框架，一个系统探索面向对象的深度学习方法在稀疏监督下进行大规模土地覆盖分类的深度学习框架。该框架支持两种模式：1. 通过图神经网络进行输入级聚合；2. 通过对已有的语义分割模型结果进行后处理来进行输出级聚合。此外，还融入了来自大型预训练网络特征以提升小数据集上的性能。

Result: 在使用稀疏的LUCAS标签对Sentinel-2年度合成图像进行评估时，面向对象的方法在精度上可媲美甚至超越常用的逐像素模型，并产生更连贯的地图。输入级聚合在较小的数据集上表现更稳健，而输出级聚合在数据量较大时效果更佳。LC-SLab的多种配置表现优于现有的土地覆盖产品。

Conclusion: LC-SLab框架能够显著提高土地覆盖分类的精度和空间连贯性，尤其是在稀疏监督和中等分辨率成像的场景下，为大规模土地覆盖制图提供了一种有效的方法。

Abstract: Large-scale land cover maps generated using deep learning play a critical
role across a wide range of Earth science applications. Open in-situ datasets
from principled land cover surveys offer a scalable alternative to manual
annotation for training such models. However, their sparse spatial coverage
often leads to fragmented and noisy predictions when used with existing deep
learning-based land cover mapping approaches. A promising direction to address
this issue is object-based classification, which assigns labels to semantically
coherent image regions rather than individual pixels, thereby imposing a
minimum mapping unit. Despite this potential, object-based methods remain
underexplored in deep learning-based land cover mapping pipelines, especially
in the context of medium-resolution imagery and sparse supervision. To address
this gap, we propose LC-SLab, the first deep learning framework for
systematically exploring object-based deep learning methods for large-scale
land cover classification under sparse supervision. LC-SLab supports both
input-level aggregation via graph neural networks, and output-level aggregation
by postprocessing results from established semantic segmentation models.
Additionally, we incorporate features from a large pre-trained network to
improve performance on small datasets. We evaluate the framework on annual
Sentinel-2 composites with sparse LUCAS labels, focusing on the tradeoff
between accuracy and fragmentation, as well as sensitivity to dataset size. Our
results show that object-based methods can match or exceed the accuracy of
common pixel-wise models while producing substantially more coherent maps.
Input-level aggregation proves more robust on smaller datasets, whereas
output-level aggregation performs best with more data. Several configurations
of LC-SLab also outperform existing land cover products, highlighting the
framework's practical utility.

</details>


### [82] [Zero-Shot Visual Grounding in 3D Gaussians via View Retrieval](https://arxiv.org/abs/2509.15871)
*Liwei Liao,Xufeng Li,Xiaoyun Zheng,Boning Liu,Feng Gao,Ronggang Wang*

Main category: cs.CV

TL;DR: GVR是一种新颖的3D视觉基础框架，它将3DVG转化为2D检索任务，利用对象级视图检索从多个视图收集基础线索，从而避免了昂贵的3D注释和逐场景训练。


<details>
  <summary>Details</summary>
Motivation: 现有的3DVG方法难以处理3D高斯喷溅（3DGS）中的空间纹理隐式表示，并且需要大量的标注数据。

Method: 提出GVR（Grounding via View Retrieval）框架，将3DVG视为2D检索任务，通过对象级视图检索来收集多视角下的基础线索。

Result: 实验证明，GVR在避免逐场景训练的情况下，实现了最先进的视觉基础性能。

Conclusion: GVR为零样本3DVG研究奠定了坚实的基础，解决了现有方法在处理3DGS隐式表示和数据标注方面的挑战。

Abstract: 3D Visual Grounding (3DVG) aims to locate objects in 3D scenes based on text
prompts, which is essential for applications such as robotics. However,
existing 3DVG methods encounter two main challenges: first, they struggle to
handle the implicit representation of spatial textures in 3D Gaussian Splatting
(3DGS), making per-scene training indispensable; second, they typically require
larges amounts of labeled data for effective training. To this end, we propose
\underline{G}rounding via \underline{V}iew \underline{R}etrieval (GVR), a novel
zero-shot visual grounding framework for 3DGS to transform 3DVG as a 2D
retrieval task that leverages object-level view retrieval to collect grounding
clues from multiple views, which not only avoids the costly process of 3D
annotation, but also eliminates the need for per-scene training. Extensive
experiments demonstrate that our method achieves state-of-the-art visual
grounding performance while avoiding per-scene training, providing a solid
foundation for zero-shot 3DVG research. Video demos can be found in
https://github.com/leviome/GVR_demos.

</details>


### [83] [ENSAM: an efficient foundation model for interactive segmentation of 3D medical images](https://arxiv.org/abs/2509.15874)
*Elias Stenhede,Agnar Martin Bjørnstad,Arian Ranjbar*

Main category: cs.CV

TL;DR: ENSAM是一个轻量级、可提示的通用3D医学图像分割模型，在有限数据和计算资源下表现良好，并具有快速的训练速度和优化的收敛性。


<details>
  <summary>Details</summary>
Motivation: 提出一个轻量级、可提示的通用3D医学图像分割模型，以应对有限数据和计算预算的挑战。

Method: ENSAM结合了基于SegResNet的编码器、提示编码器和掩码解码器，采用U-Net风格架构，并利用了潜在交叉注意力、相对位置编码、归一化注意力和Muon优化器进行训练。

Result: 在CVPR 2025挑战赛中，ENSAM在隐藏测试集上取得了DSC AUC 2.404、NSD AUC 2.266、最终DSC 0.627和最终NSD 0.597的成绩，优于VISTA3D和SAM-Med3D，并与SegVol相当，在最终DSC方面超越了SegVol。此外，在Coreset Track中排名第五，是未使用预训练权重的模型中表现最好的。

Conclusion: ENSAM在有限数据和计算资源下实现了高性能的3D医学图像分割，其相对位置编码和Muon优化器显著提高了收敛速度和分割质量。

Abstract: We present ENSAM (Equivariant, Normalized, Segment Anything Model), a
lightweight and promptable model for universal 3D medical image segmentation.
ENSAM combines a SegResNet-based encoder with a prompt encoder and mask decoder
in a U-Net-style architecture, using latent cross-attention, relative
positional encoding, normalized attention, and the Muon optimizer for training.
ENSAM is designed to achieve good performance under limited data and
computational budgets, and is trained from scratch on under 5,000 volumes from
multiple modalities (CT, MRI, PET, ultrasound, microscopy) on a single 32 GB
GPU in 6 hours. As part of the CVPR 2025 Foundation Models for Interactive 3D
Biomedical Image Segmentation Challenge, ENSAM was evaluated on hidden test set
with multimodal 3D medical images, obtaining a DSC AUC of 2.404, NSD AUC of
2.266, final DSC of 0.627, and final NSD of 0.597, outperforming two previously
published baseline models (VISTA3D, SAM-Med3D) and matching the third (SegVol),
surpassing its performance in final DSC but trailing behind in the other three
metrics. In the coreset track of the challenge, ENSAM ranks 5th of 10 overall
and best among the approaches not utilizing pretrained weights. Ablation
studies confirm that our use of relative positional encodings and the Muon
optimizer each substantially speed up convergence and improve segmentation
quality.

</details>


### [84] [Self-Supervised Cross-Modal Learning for Image-to-Point Cloud Registration](https://arxiv.org/abs/2509.15882)
*Xingmei Wang,Xiaoyu Hu,Chengkai Huang,Ziyan Zeng,Guohao Nie,Quan Z. Sheng,Lina Yao*

Main category: cs.CV

TL;DR: CrossI2P是一个无需监督的框架，通过融合的几何-语义嵌入空间和粗到精的配准范式，解决了图像到点云配准的挑战。


<details>
  <summary>Details</summary>
Motivation: 弥合2D和3D传感器模态之间的差距，以实现自主系统中的鲁棒感知，解决了现有方法在语义-几何差距和局部最优方面存在的挑战。

Method: 使用双路径对比学习学习几何-语义融合嵌入空间，以实现无标注的双向对齐。采用粗到精的配准范式，包括全局配准和几何约束的点级精炼。采用动态训练机制和梯度归一化来平衡损失。

Result: 在KITTI Odometry基准测试中，性能比最先进的方法提高了23.7%，在nuScenes中提高了37.9%。

Conclusion: CrossI2P通过其创新的框架，显著提高了图像到点云配准的准确性和鲁棒性。

Abstract: Bridging 2D and 3D sensor modalities is critical for robust perception in
autonomous systems. However, image-to-point cloud (I2P) registration remains
challenging due to the semantic-geometric gap between texture-rich but
depth-ambiguous images and sparse yet metrically precise point clouds, as well
as the tendency of existing methods to converge to local optima. To overcome
these limitations, we introduce CrossI2P, a self-supervised framework that
unifies cross-modal learning and two-stage registration in a single end-to-end
pipeline. First, we learn a geometric-semantic fused embedding space via
dual-path contrastive learning, enabling annotation-free, bidirectional
alignment of 2D textures and 3D structures. Second, we adopt a coarse-to-fine
registration paradigm: a global stage establishes superpoint-superpixel
correspondences through joint intra-modal context and cross-modal interaction
modeling, followed by a geometry-constrained point-level refinement for precise
registration. Third, we employ a dynamic training mechanism with gradient
normalization to balance losses for feature alignment, correspondence
refinement, and pose estimation. Extensive experiments demonstrate that
CrossI2P outperforms state-of-the-art methods by 23.7% on the KITTI Odometry
benchmark and by 37.9% on nuScenes, significantly improving both accuracy and
robustness.

</details>


### [85] [RACap: Relation-Aware Prompting for Lightweight Retrieval-Augmented Image Captioning](https://arxiv.org/abs/2509.15883)
*Xiaosheng Long,Hanyu Wang,Zhentao Song,Kun Luo,Hongde Liu*

Main category: cs.CV

TL;DR: 该研究提出了一种名为RACap的关系感知检索增强模型，用于图像描述生成，以解决现有方法在关系建模中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强图像描述方法在关系建模方面存在不足：1. 语义提示表示粗糙，难以捕捉细粒度关系；2. 缺乏对图像对象及其语义关系的显式建模。

Method: RACap模型挖掘检索到的标题中的结构化关系语义，并识别图像中的异构对象，以增强语义一致性和关系表达能力。

Result: RACap模型参数量仅为10.8M，但实验结果表明其性能优于之前的轻量级图像描述模型。

Conclusion: RACap通过挖掘和利用结构化关系语义以及识别异构对象，有效提升了图像描述的质量，并在轻量级模型中取得了优越的性能。

Abstract: Recent retrieval-augmented image captioning methods incorporate external
knowledge to compensate for the limitations in comprehending complex scenes.
However, current approaches face challenges in relation modeling: (1) the
representation of semantic prompts is too coarse-grained to capture
fine-grained relationships; (2) these methods lack explicit modeling of image
objects and their semantic relationships. To address these limitations, we
propose RACap, a relation-aware retrieval-augmented model for image captioning,
which not only mines structured relation semantics from retrieval captions, but
also identifies heterogeneous objects from the image. RACap effectively
retrieves structured relation features that contain heterogeneous visual
information to enhance the semantic consistency and relational expressiveness.
Experimental results show that RACap, with only 10.8M trainable parameters,
achieves superior performance compared to previous lightweight captioning
models.

</details>


### [86] [RangeSAM: Leveraging Visual Foundation Models for Range-View repesented LiDAR segmentation](https://arxiv.org/abs/2509.15886)
*Paul Julius Kühn,Duc Anh Nguyen,Arjan Kuijper,Holger Graf,Dieter Fellner,Saptarshi Neil Sinha*

Main category: cs.CV

TL;DR: 该研究提出了一种将视觉基础模型(VFM)SAM2应用于激光雷达点云的范围视图分割的新框架，通过修改SAM2的编码器以适应范围视图的几何特性，实现了高效、可扩展且性能具有竞争力的3D分割。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有激光雷达点云分割方法计算成本高、内存访问不规则和实时效率低的问题，并利用视觉基础模型(VFM)在分割任务上的快速进展。

Method: 提出了一种新的范围视图框架，该框架将SAM2模型适配于3D点云分割，结合了高效的2D特征提取和标准的投影/反投影技术。通过修改SAM2的编码器，包括一个强调水平空间依赖性的新模块、一个针对球形投影几何特性的定制化配置，以及一个用于捕捉范围视图伪图像独特空间模式和不连续性的适配机制。

Result: 在SemanticKITTI数据集上取得了有竞争力的性能，同时受益于以2D为中心的流水线的速度、可扩展性和部署简单性。

Conclusion: 视觉基础模型(VFM)有潜力作为3D感知的通用骨干网络，并为统一的、由基础模型驱动的激光雷达分割开辟了道路。使用VFM的范围视图分割方法带来了有前景的结果。

Abstract: Point cloud segmentation is central to autonomous driving and 3D scene
understanding. While voxel- and point-based methods dominate recent research
due to their compatibility with deep architectures and ability to capture
fine-grained geometry, they often incur high computational cost, irregular
memory access, and limited real-time efficiency. In contrast, range-view
methods, though relatively underexplored - can leverage mature 2D semantic
segmentation techniques for fast and accurate predictions. Motivated by the
rapid progress in Visual Foundation Models (VFMs) for captioning, zero-shot
recognition, and multimodal tasks, we investigate whether SAM2, the current
state-of-the-art VFM for segmentation tasks, can serve as a strong backbone for
LiDAR point cloud segmentation in the range view. We present , to our
knowledge, the first range-view framework that adapts SAM2 to 3D segmentation,
coupling efficient 2D feature extraction with standard
projection/back-projection to operate on point clouds. To optimize SAM2 for
range-view representations, we implement several architectural modifications to
the encoder: (1) a novel module that emphasizes horizontal spatial dependencies
inherent in LiDAR range images, (2) a customized configuration of tailored to
the geometric properties of spherical projections, and (3) an adapted mechanism
in the encoder backbone specifically designed to capture the unique spatial
patterns and discontinuities present in range-view pseudo-images. Our approach
achieves competitive performance on SemanticKITTI while benefiting from the
speed, scalability, and deployment simplicity of 2D-centric pipelines. This
work highlights the viability of VFMs as general-purpose backbones for 3D
perception and opens a path toward unified, foundation-model-driven LiDAR
segmentation. Results lets us conclude that range-view segmentation methods
using VFMs leads to promising results.

</details>


### [87] [Global Regulation and Excitation via Attention Tuning for Stereo Matching](https://arxiv.org/abs/2509.15891)
*Jiahao Li,Xinhong Chen,Zhengmin Jiang,Qian Zhou,Yung-Hui Li,Jianping Wang*

Main category: cs.CV

TL;DR: GREAT框架通过引入空间注意力、匹配注意力和体积注意力模块，增强了迭代立体匹配方法处理遮挡、纹理缺失和重复模式等病态区域的能力，显著提升了在各种基准测试中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的迭代立体匹配方法在处理遮挡、纹理缺失或重复模式等病态区域时存在困难，因为它们缺乏全局上下文和几何信息来进行有效的迭代优化。

Method: 提出GREAT框架，包含空间注意力（SA）、匹配注意力（MA）和体积注意力（VA）三个模块。SA捕获空间维度上的全局上下文，MA沿极线提取全局上下文，VA与SA和MA协同工作，利用全局上下文和几何细节构建更鲁棒的代价体积。将GREAT框架集成到现有的迭代立体匹配方法中，形成GREAT-Stereo。

Result: 将GREAT框架集成到IGEV-Stereo中后，GREAT-IGEV在Scene Flow测试集、KITTI 2015和ETH3D排行榜上名列第一，在中度数据集上排名第二，在具有挑战性的病态区域表现出优越的性能。

Conclusion: GREAT框架能够有效地增强迭代立体匹配方法处理病态区域的能力，并且具有普遍性和有效性。

Abstract: Stereo matching achieves significant progress with iterative algorithms like
RAFT-Stereo and IGEV-Stereo. However, these methods struggle in ill-posed
regions with occlusions, textureless, or repetitive patterns, due to a lack of
global context and geometric information for effective iterative refinement. To
enable the existing iterative approaches to incorporate global context, we
propose the Global Regulation and Excitation via Attention Tuning (GREAT)
framework which encompasses three attention modules. Specifically, Spatial
Attention (SA) captures the global context within the spatial dimension,
Matching Attention (MA) extracts global context along epipolar lines, and
Volume Attention (VA) works in conjunction with SA and MA to construct a more
robust cost-volume excited by global context and geometric details. To verify
the universality and effectiveness of this framework, we integrate it into
several representative iterative stereo-matching methods and validate it
through extensive experiments, collectively denoted as GREAT-Stereo. This
framework demonstrates superior performance in challenging ill-posed regions.
Applied to IGEV-Stereo, among all published methods, our GREAT-IGEV ranks first
on the Scene Flow test set, KITTI 2015, and ETH3D leaderboards, and achieves
second on the Middlebury benchmark. Code is available at
https://github.com/JarvisLee0423/GREAT-Stereo.

</details>


### [88] [Deep Feedback Models](https://arxiv.org/abs/2509.15905)
*David Calhas,Arlindo L. Oliveira*

Main category: cs.CV

TL;DR: DFMs是一种结合了自下而上输入和高层表征的循环神经网络，通过指数衰减确保收敛，在物体识别、分割和医学成像任务中表现优于前馈网络，尤其是在数据量少或噪声大的情况下。


<details>
  <summary>Details</summary>
Motivation: DFMs通过引入反馈机制，使网络能够随时间迭代地优化内部状态，模拟生物决策过程，从而提高模型的稳定性和泛化能力。

Method: DFMs被建模为一个通过循环神经网络求解的微分方程，并使用指数衰减进行稳定以确保收敛。

Result: 在物体识别、分割和医学成像任务中，DFMs在低数据量和高噪声条件下均优于前馈网络。

Conclusion: 反馈机制对于实现稳定、鲁棒和可泛化的学习至关重要。

Abstract: Deep Feedback Models (DFMs) are a new class of stateful neural networks that
combine bottom up input with high level representations over time. This
feedback mechanism introduces dynamics into otherwise static architectures,
enabling DFMs to iteratively refine their internal state and mimic aspects of
biological decision making. We model this process as a differential equation
solved through a recurrent neural network, stabilized via exponential decay to
ensure convergence. To evaluate their effectiveness, we measure DFMs under two
key conditions: robustness to noise and generalization with limited data. In
both object recognition and segmentation tasks, DFMs consistently outperform
their feedforward counterparts, particularly in low data or high noise regimes.
In addition, DFMs translate to medical imaging settings, while being robust
against various types of noise corruption. These findings highlight the
importance of feedback in achieving stable, robust, and generalizable learning.
Code is available at https://github.com/DCalhas/deep_feedback_models.

</details>


### [89] [Sparse Multiview Open-Vocabulary 3D Detection](https://arxiv.org/abs/2509.15924)
*Olivier Moliner,Viktor Larsson,Kalle Åström*

Main category: cs.CV

TL;DR: 本研究提出了一种无需训练的开放词汇3D目标检测方法，用于稀疏视图场景，利用预训练的2D基础模型，通过优化3D提议以实现跨视图的特征度量一致性。


<details>
  <summary>Details</summary>
Motivation: 传统的3D目标检测方法仅限于固定类别的检测，限制了其应用范围。本研究旨在解决开放词汇3D目标检测问题，尤其是在稀疏视图这一具有挑战性但实用的场景下。

Method: 提出了一种无需训练的、基于预训练的2D基础模型的开放词汇3D目标检测方法。该方法不依赖于计算成本高昂的3D特征融合或3D特定学习，而是通过提升2D检测结果并直接优化3D提议以实现跨视图的特征度量一致性。

Result: 在标准基准测试中，该方法在密集采样场景下表现与最先进技术相当，在稀疏视图场景下则显著优于它们，证明了其在稀疏视图设置下的强大性能。

Conclusion: 本研究提出的无需训练的开放词汇3D目标检测方法，在稀疏视图场景下表现出色，通过充分利用2D数据，为该领域提供了一个强大的基线。

Abstract: The ability to interpret and comprehend a 3D scene is essential for many
vision and robotics systems. In numerous applications, this involves 3D object
detection, i.e.~identifying the location and dimensions of objects belonging to
a specific category, typically represented as bounding boxes. This has
traditionally been solved by training to detect a fixed set of categories,
which limits its use. In this work, we investigate open-vocabulary 3D object
detection in the challenging yet practical sparse-view setting, where only a
limited number of posed RGB images are available as input. Our approach is
training-free, relying on pre-trained, off-the-shelf 2D foundation models
instead of employing computationally expensive 3D feature fusion or requiring
3D-specific learning. By lifting 2D detections and directly optimizing 3D
proposals for featuremetric consistency across views, we fully leverage the
extensive training data available in 2D compared to 3D. Through standard
benchmarks, we demonstrate that this simple pipeline establishes a powerful
baseline, performing competitively with state-of-the-art techniques in densely
sampled scenarios while significantly outperforming them in the sparse-view
setting.

</details>


### [90] [PAN: Pillars-Attention-Based Network for 3D Object Detection](https://arxiv.org/abs/2509.15935)
*Ruan Bispo,Dane Mitrev,Letizia Mariotti,Clément Botty,Denver Humphrey,Anthony Scanlan,Ciarán Eising*

Main category: cs.CV

TL;DR: 摄像头-雷达融合是实时3D目标检测的低成本替代方案，尤其是在恶劣天气和光照条件下。本研究提出了一种新的高效3D目标检测算法，该算法利用鸟瞰图（BEV）中的摄像头和雷达数据，并在融合特征到检测头之前，利用雷达的优势。


<details>
  <summary>Details</summary>
Motivation: 现有研究在摄像头-雷达融合的3D目标检测方面较为有限，未能充分利用雷达数据的精确测距和速度信息。因此，需要开发新的算法来探索这些优势。

Method: 提出了一种新的算法，在鸟瞰图（BEV）中融合摄像头和雷达数据。通过一个新提出的骨干网络将雷达点云特征映射到嵌入空间，并利用自注意力机制来建模雷达点之间的依赖关系。为了减少推理时间，用简化的卷积层替换了PointPillars架构中基于FPN的卷积层。

Result: 该方法在nuScenes数据集上实现了58.2的NDS指标，达到了新的最先进水平，并创下了相同类别推理时间的基准记录。

Conclusion: 本研究提出的摄像头-雷达融合3D目标检测算法，通过利用雷达的优势和优化网络结构，在检测精度和推理速度方面均取得了显著的成果，为该领域树立了新的标杆。

Abstract: Camera-radar fusion offers a robust and low-cost alternative to Camera-lidar
fusion for the 3D object detection task in real-time under adverse weather and
lighting conditions. However, currently, in the literature, it is possible to
find few works focusing on this modality and, most importantly, developing new
architectures to explore the advantages of the radar point cloud, such as
accurate distance estimation and speed information. Therefore, this work
presents a novel and efficient 3D object detection algorithm using cameras and
radars in the bird's-eye-view (BEV). Our algorithm exploits the advantages of
radar before fusing the features into a detection head. A new backbone is
introduced, which maps the radar pillar features into an embedded dimension. A
self-attention mechanism allows the backbone to model the dependencies between
the radar points. We are using a simplified convolutional layer to replace the
FPN-based convolutional layers used in the PointPillars-based architectures
with the main goal of reducing inference time. Our results show that with this
modification, our approach achieves the new state-of-the-art in the 3D object
detection problem, reaching 58.2 of the NDS metric for the use of ResNet-50,
while also setting a new benchmark for inference time on the nuScenes dataset
for the same category.

</details>


### [91] [A multi-temporal multi-spectral attention-augmented deep convolution neural network with contrastive learning for crop yield prediction](https://arxiv.org/abs/2509.15966)
*Shalini Dangi,Surya Karthikeya Mullapudi,Chandravardhan Singh Raghaw,Shahid Shafi Dar,Mohammad Zia Ur Rehman,Nagendra Kumar*

Main category: cs.CV

TL;DR: 该研究提出了一种名为MTMS-YieldNet的新型多时相多光谱产量预测网络，通过结合光谱和时空信息，并利用对比学习进行预训练，以提高产量预测的准确性，尤其是在应对气候变化带来的挑战方面。


<details>
  <summary>Details</summary>
Motivation: 气候变化影响天气、土壤和农场管理，增加了精准预测作物产量的难度。现有方法难以有效利用多光谱数据，而该研究旨在解决这一问题。

Method: 提出了一种名为MTMS-YieldNet的新型网络，该网络整合了光谱数据和时空信息，并利用对比学习进行特征辨别和预训练，以捕捉遥感数据中的空间-光谱模式和时空依赖性。

Result: MTMS-YieldNet在Sentinel-1、Landsat-8和Sentinel-2数据集上分别取得了0.336、0.353和0.331的MAPE分数，优于七种现有最先进的方法，显示了其在不同气候和季节条件下的有效产量预测性能。

Conclusion: MTMS-YieldNet 能够有效提高产量预测的准确性，为农民提供有价值的决策支持，有助于改善作物产量。

Abstract: Precise yield prediction is essential for agricultural sustainability and
food security. However, climate change complicates accurate yield prediction by
affecting major factors such as weather conditions, soil fertility, and farm
management systems. Advances in technology have played an essential role in
overcoming these challenges by leveraging satellite monitoring and data
analysis for precise yield estimation. Current methods rely on spatio-temporal
data for predicting crop yield, but they often struggle with multi-spectral
data, which is crucial for evaluating crop health and growth patterns. To
resolve this challenge, we propose a novel Multi-Temporal Multi-Spectral Yield
Prediction Network, MTMS-YieldNet, that integrates spectral data with
spatio-temporal information to effectively capture the correlations and
dependencies between them. While existing methods that rely on pre-trained
models trained on general visual data, MTMS-YieldNet utilizes contrastive
learning for feature discrimination during pre-training, focusing on capturing
spatial-spectral patterns and spatio-temporal dependencies from remote sensing
data. Both quantitative and qualitative assessments highlight the excellence of
the proposed MTMS-YieldNet over seven existing state-of-the-art methods.
MTMS-YieldNet achieves MAPE scores of 0.336 on Sentinel-1, 0.353 on Landsat-8,
and an outstanding 0.331 on Sentinel-2, demonstrating effective yield
prediction performance across diverse climatic and seasonal conditions. The
outstanding performance of MTMS-YieldNet improves yield predictions and
provides valuable insights that can assist farmers in making better decisions,
potentially improving crop yields.

</details>


### [92] [Shedding Light on Depth: Explainability Assessment in Monocular Depth Estimation](https://arxiv.org/abs/2509.15980)
*Lorenzo Cirillo,Claudio Schiavella,Lorenzo Papa,Paolo Russo,Irene Amerini*

Main category: cs.CV

TL;DR: 本篇论文探讨了可解释人工智能在单目深度估计（MDE）中的应用，并提出了一种新的评估指标“归因保真度”。


<details>
  <summary>Details</summary>
Motivation: MDE模型广泛应用于现实世界，但其可解释性研究不足，本研究旨在填补这一空白，并提高对MDE模型决策过程的理解和信任度。

Method: 研究人员将三种成熟的特征归因方法（Saliency Maps, Integrated Gradients, Attention Rollout）应用于两种不同复杂度的MDE模型（METER和PixelFormer）。他们通过扰动关键和非关键像素来评估解释的质量，并引入了新的评估指标“归因保真度”（Attribution Fidelity）来衡量解释的可靠性。

Result: 实验结果表明，Saliency Maps和Integrated Gradients分别在轻量级和深度MDE模型中表现良好，能够有效突出重要的输入特征。新的“归因保真度”指标能够有效识别不可靠的解释图，即使在传统指标显示满意的情况下。

Conclusion: 本研究验证了特征归因方法在MDE模型中的有效性，并提出了“归因保真度”这一新的评估指标，为未来MDE模型的可解释性研究提供了有价值的工具。

Abstract: Explainable artificial intelligence is increasingly employed to understand
the decision-making process of deep learning models and create trustworthiness
in their adoption. However, the explainability of Monocular Depth Estimation
(MDE) remains largely unexplored despite its wide deployment in real-world
applications. In this work, we study how to analyze MDE networks to map the
input image to the predicted depth map. More in detail, we investigate
well-established feature attribution methods, Saliency Maps, Integrated
Gradients, and Attention Rollout on different computationally complex models
for MDE: METER, a lightweight network, and PixelFormer, a deep network. We
assess the quality of the generated visual explanations by selectively
perturbing the most relevant and irrelevant pixels, as identified by the
explainability methods, and analyzing the impact of these perturbations on the
model's output. Moreover, since existing evaluation metrics can have some
limitations in measuring the validity of visual explanations for MDE, we
additionally introduce the Attribution Fidelity. This metric evaluates the
reliability of the feature attribution by assessing their consistency with the
predicted depth map. Experimental results demonstrate that Saliency Maps and
Integrated Gradients have good performance in highlighting the most important
input features for MDE lightweight and deep models, respectively. Furthermore,
we show that Attribution Fidelity effectively identifies whether an
explainability method fails to produce reliable visual maps, even in scenarios
where conventional metrics might suggest satisfactory results.

</details>


### [93] [DAFTED: Decoupled Asymmetric Fusion of Tabular and Echocardiographic Data for Cardiac Hypertension Diagnosis](https://arxiv.org/abs/2509.15990)
*Jérémie Stym-Popper,Nathan Painchaud,Clément Rambour,Pierre-Yves Courand,Nicolas Thome,Olivier Bernard*

Main category: cs.CV

TL;DR: 提出一种非对称多模态数据融合策略，用于医学诊断，该策略从主要模态开始，通过分离共享和模态特定信息来整合次要模态。


<details>
  <summary>Details</summary>
Motivation: 多模态数据融合是增强医学诊断的关键方法。

Method: 提出一种非对称融合策略，从主模态开始，通过分离共享和模态特定信息来整合次模态。

Result: 在包含239名患者的回声心动图时间序列和表格记录的数据集上进行了验证，该模型优于现有方法，AUC超过90%。

Conclusion: 该模型在医学诊断方面的改进为临床应用树立了重要的基准。

Abstract: Multimodal data fusion is a key approach for enhancing diagnosis in medical
applications. We propose an asymmetric fusion strategy starting from a primary
modality and integrating secondary modalities by disentangling shared and
modality-specific information. Validated on a dataset of 239 patients with
echocardiographic time series and tabular records, our model outperforms
existing methods, achieving an AUC over 90%. This improvement marks a crucial
benchmark for clinical use.

</details>


### [94] [Towards Robust Visual Continual Learning with Multi-Prototype Supervision](https://arxiv.org/abs/2509.16011)
*Xiwei Liu,Yulong Li,Yichen Li,Xinlin Zhuang,Haolin Yang,Huifa Li,Imran Razzak*

Main category: cs.CV

TL;DR: MuproCL框架通过使用多重、上下文感知的原型来替代单一目标，解决了语言指导的持续学习中的语义模糊和类内视觉多样性问题，提高了性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的语言指导的持续学习方法依赖单一语义目标，存在语义模糊和类内视觉多样性不足的问题。

Method: 提出MuproCL框架，使用轻量级LLM代理进行类别消歧和视觉模态扩展，生成多重语义原型，并采用LogSumExp聚合机制使视觉模型自适应地与最相关的原型对齐。

Result: 在各种持续学习基线上的广泛实验表明，MuproCL持续提高性能和鲁棒性。

Conclusion: MuproCL为语言指导的持续学习提供了一条更有效的路径。

Abstract: Language-guided supervision, which utilizes a frozen semantic target from a
Pretrained Language Model (PLM), has emerged as a promising paradigm for visual
Continual Learning (CL). However, relying on a single target introduces two
critical limitations: 1) semantic ambiguity, where a polysemous category name
results in conflicting visual representations, and 2) intra-class visual
diversity, where a single prototype fails to capture the rich variety of visual
appearances within a class. To this end, we propose MuproCL, a novel framework
that replaces the single target with multiple, context-aware prototypes.
Specifically, we employ a lightweight LLM agent to perform category
disambiguation and visual-modal expansion to generate a robust set of semantic
prototypes. A LogSumExp aggregation mechanism allows the vision model to
adaptively align with the most relevant prototype for a given image. Extensive
experiments across various CL baselines demonstrate that MuproCL consistently
enhances performance and robustness, establishing a more effective path for
language-guided continual learning.

</details>


### [95] [DistillMatch: Leveraging Knowledge Distillation from Vision Foundation Model for Multimodal Image Matching](https://arxiv.org/abs/2509.16017)
*Meng Yang,Fan Fan,Zizhuo Li,Songchu Deng,Yong Ma,Jiayi Ma*

Main category: cs.CV

TL;DR: DistillMatch利用视觉基础模型(VFM)的知识蒸馏来解决多模态图像匹配的挑战，通过注入模态类别信息和使用V2I-GAN进行数据增强来提高性能。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法在多模态图像匹配方面表现不佳且适应性差，因为模态间的显著外观差异和高щихся的标注数据集的稀缺性。

Method: 提出DistillMatch，一种利用VFM（如DINOv2和DINOv3）知识蒸馏的轻量级学生模型，提取高级语义特征进行跨模态匹配。该模型还提取并注入模态类别信息，并使用V2I-GAN进行可见光到红外图像的翻译以增强数据。

Result: DistillMatch在公共数据集上的表现优于现有算法。

Conclusion: DistillMatch通过结合VFM的通用特征提取能力、模态类别信息注入和数据增强技术，成功地提高了多模态图像匹配的性能和泛化能力。

Abstract: Multimodal image matching seeks pixel-level correspondences between images of
different modalities, crucial for cross-modal perception, fusion and analysis.
However, the significant appearance differences between modalities make this
task challenging. Due to the scarcity of high-quality annotated datasets,
existing deep learning methods that extract modality-common features for
matching perform poorly and lack adaptability to diverse scenarios. Vision
Foundation Model (VFM), trained on large-scale data, yields generalizable and
robust feature representations adapted to data and tasks of various modalities,
including multimodal matching. Thus, we propose DistillMatch, a multimodal
image matching method using knowledge distillation from VFM. DistillMatch
employs knowledge distillation to build a lightweight student model that
extracts high-level semantic features from VFM (including DINOv2 and DINOv3) to
assist matching across modalities. To retain modality-specific information, it
extracts and injects modality category information into the other modality's
features, which enhances the model's understanding of cross-modal correlations.
Furthermore, we design V2I-GAN to boost the model's generalization by
translating visible to pseudo-infrared images for data augmentation.
Experiments show that DistillMatch outperforms existing algorithms on public
datasets.

</details>


### [96] [Generalized Deep Multi-view Clustering via Causal Learning with Partially Aligned Cross-view Correspondence](https://arxiv.org/abs/2509.16022)
*Xihong Yang,Siwei Wang,Jiaqi Jin,Fangdi Wang,Tianrui Liu,Yueming Jin,Xinwang Liu,En Zhu,Kunlun He*

Main category: cs.CV

TL;DR: 本篇论文提出了一种名为CauMVC的因果多视图聚类网络，用于解决真实世界中数据跨视图对齐不一致的问题，并通过因果推断和变分自编码器来提取不变特征和进行后干预推理，实验证明了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有跨视图聚类方法大多依赖视图一致性假设，但在实际应用中，跨视图对齐往往是部分对齐的，这限制了聚类性能。本研究将数据顺序变化（从完全对齐到部分对齐）导致的模型性能下降视为一个广义多视图聚类问题。

Method: 提出了一种名为CauMVC的因果多视图聚类网络。该方法采用因果建模方法来理解多视图聚类过程，将部分对齐数据视为一种干预，将带部分对齐数据进行多视图聚类视为一种后干预推理。设计了一个变分自编码器（VAE）用于因果学习，其中编码器用于估计不变特征，解码器用于执行后干预推理。此外，还设计了一个对比正则化器来捕捉样本相关性。

Result: 在完全对齐和部分对齐的数据集上的实证实验表明，CauMVC具有很强的泛化能力和有效性。

Conclusion: 本论文首次提出使用因果学习来解决广义多视图聚类问题，并通过CauMVC网络在处理跨视图对齐不一致性方面取得了良好的效果。

Abstract: Multi-view clustering (MVC) aims to explore the common clustering structure
across multiple views. Many existing MVC methods heavily rely on the assumption
of view consistency, where alignments for corresponding samples across
different views are ordered in advance. However, real-world scenarios often
present a challenge as only partial data is consistently aligned across
different views, restricting the overall clustering performance. In this work,
we consider the model performance decreasing phenomenon caused by data order
shift (i.e., from fully to partially aligned) as a generalized multi-view
clustering problem. To tackle this problem, we design a causal multi-view
clustering network, termed CauMVC. We adopt a causal modeling approach to
understand multi-view clustering procedure. To be specific, we formulate the
partially aligned data as an intervention and multi-view clustering with
partially aligned data as an post-intervention inference. However, obtaining
invariant features directly can be challenging. Thus, we design a Variational
Auto-Encoder for causal learning by incorporating an encoder from existing
information to estimate the invariant features. Moreover, a decoder is designed
to perform the post-intervention inference. Lastly, we design a contrastive
regularizer to capture sample correlations. To the best of our knowledge, this
paper is the first work to deal generalized multi-view clustering via causal
learning. Empirical experiments on both fully and partially aligned data
illustrate the strong generalization and effectiveness of CauMVC.

</details>


### [97] [GLip: A Global-Local Integrated Progressive Framework for Robust Visual Speech Recognition](https://arxiv.org/abs/2509.16031)
*Tianyue Wang,Shuang Yang,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: GLip是一个用于鲁棒视觉语音识别（VSR）的全局-局部联合渐进框架，通过联合学习全局和局部特征，并利用渐进式学习策略来应对光照变化、遮挡、模糊和姿态变化等现实世界挑战。


<details>
  <summary>Details</summary>
Motivation: 现有VSR方法在应对光照变化、遮挡、模糊和姿态变化等现实世界视觉挑战方面存在不足。

Method: GLip采用双通路特征提取架构，在两阶段渐进式学习框架中整合全局和局部特征。第一阶段利用视听数据学习粗略的视觉特征与语音内容的对齐。第二阶段引入上下文增强模块（CEM）来融合局部特征和全局上下文，实现精确的视听映射。

Result: GLip在LRS2和LRS3基准测试中持续优于现有方法，并在新增的普通话数据集上验证了其有效性。

Conclusion: GLip通过联合学习全局和局部特征，并采用渐进式学习策略，能有效应对各种视觉挑战，提高了VSR的鲁棒性。

Abstract: Visual speech recognition (VSR), also known as lip reading, is the task of
recognizing speech from silent video. Despite significant advancements in VSR
over recent decades, most existing methods pay limited attention to real-world
visual challenges such as illumination variations, occlusions, blurring, and
pose changes. To address these challenges, we propose GLip, a Global-Local
Integrated Progressive framework designed for robust VSR. GLip is built upon
two key insights: (i) learning an initial \textit{coarse} alignment between
visual features across varying conditions and corresponding speech content
facilitates the subsequent learning of \textit{precise} visual-to-speech
mappings in challenging environments; (ii) under adverse conditions, certain
local regions (e.g., non-occluded areas) often exhibit more discriminative cues
for lip reading than global features. To this end, GLip introduces a dual-path
feature extraction architecture that integrates both global and local features
within a two-stage progressive learning framework. In the first stage, the
model learns to align both global and local visual features with corresponding
acoustic speech units using easily accessible audio-visual data, establishing a
coarse yet semantically robust foundation. In the second stage, we introduce a
Contextual Enhancement Module (CEM) to dynamically integrate local features
with relevant global context across both spatial and temporal dimensions,
refining the coarse representations into precise visual-speech mappings. Our
framework uniquely exploits discriminative local regions through a progressive
learning strategy, demonstrating enhanced robustness against various visual
challenges and consistently outperforming existing methods on the LRS2 and LRS3
benchmarks. We further validate its effectiveness on a newly introduced
challenging Mandarin dataset.

</details>


### [98] [Graph-based Point Cloud Surface Reconstruction using B-Splines](https://arxiv.org/abs/2509.16050)
*Stuti Pathak,Rhys G. Evans,Gunther Steenackers,Rudi Penne*

Main category: cs.CV

TL;DR: 该研究提出了一种新颖的表面重建方法，可以同时预测 B 样条曲线的控制点数量和位置，从而在没有法线信息的情况下从嘈杂的点云数据生成平滑的表面。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理嘈杂的点云数据时，依赖法线信息，导致不可靠。B 样条方法虽然具有平滑性，但难以匹配表面复杂性。

Method: 提出了一种基于字典引导图卷积网络的策略，同时预测 B 样条的控制点数量和位置，无需法线信息。

Result: 与现有基线方法相比，该方法在定性和定量评估中均表现出更优越的性能。

Conclusion: 该方法能够从嘈杂的点云数据中生成平滑的表面，无需法线信息，并且在复杂性匹配方面优于现有方法。

Abstract: Generating continuous surfaces from discrete point cloud data is a
fundamental task in several 3D vision applications. Real-world point clouds are
inherently noisy due to various technical and environmental factors. Existing
data-driven surface reconstruction algorithms rely heavily on ground truth
normals or compute approximate normals as an intermediate step. This dependency
makes them extremely unreliable for noisy point cloud datasets, even if the
availability of ground truth training data is ensured, which is not always the
case. B-spline reconstruction techniques provide compact surface
representations of point clouds and are especially known for their smoothening
properties. However, the complexity of the surfaces approximated using
B-splines is directly influenced by the number and location of the spline
control points. Existing spline-based modeling methods predict the locations of
a fixed number of control points for a given point cloud, which makes it very
difficult to match the complexity of its underlying surface. In this work, we
develop a Dictionary-Guided Graph Convolutional Network-based surface
reconstruction strategy where we simultaneously predict both the location and
the number of control points for noisy point cloud data to generate smooth
surfaces without the use of any point normals. We compare our reconstruction
method with several well-known as well as recent baselines by employing
widely-used evaluation metrics, and demonstrate that our method outperforms all
of them both qualitatively and quantitatively.

</details>


### [99] [Language-Instructed Reasoning for Group Activity Detection via Multimodal Large Language Model](https://arxiv.org/abs/2509.16054)
*Jihua Peng,Qianxiong Xu,Yichen Liu,Chenxi Liu,Cheng Long,Rui Zhao,Ziyue Li*

Main category: cs.CV

TL;DR: LIR-GAD是一个新颖的框架，利用多模态大语言模型（MLLM）进行小组活动检测（GAD），通过引入特殊的<ACT>和<GROUP>标记来增强MLLM的上下文推理和可解释性，并通过多模态双对齐融合（MDAF）模块进一步提高性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的小组活动检测（GAD）方法虽然能识别群体动态，但缺乏上下文推理和可解释性，因为它们仅依赖于视觉特征的隐式模式识别。

Method: 提出LIR-GAD框架，通过将视频帧、语言指令以及新引入的活动级别<ACT>标记和组级别<GROUP>标记整合到MLLM中来解决GAD问题。此外，还设计了多标签分类损失和多模态双对齐融合（MDAF）模块来增强模型的表示学习和融合能力。

Result: LIR-GAD在GAD任务上取得了优越的性能，如定量和定性实验所示。

Conclusion: LIR-GAD利用MLLM的预训练常识知识，通过引入的特殊标记和MDAF模块，有效克服了现有方法的局限性，在小组活动检测方面取得了显著的性能提升。

Abstract: Group activity detection (GAD) aims to simultaneously identify group members
and categorize their collective activities within video sequences. Existing
deep learning-based methods develop specialized architectures (e.g.,
transformer networks) to model the dynamics of individual roles and semantic
dependencies between individuals and groups. However, they rely solely on
implicit pattern recognition from visual features and struggle with contextual
reasoning and explainability. In this work, we propose LIR-GAD, a novel
framework of language-instructed reasoning for GAD via Multimodal Large
Language Model (MLLM). Our approach expand the original vocabulary of MLLM by
introducing an activity-level <ACT> token and multiple cluster-specific <GROUP>
tokens. We process video frames alongside two specially designed tokens and
language instructions, which are then integrated into the MLLM. The pretrained
commonsense knowledge embedded in the MLLM enables the <ACT> token and <GROUP>
tokens to effectively capture the semantic information of collective activities
and learn distinct representational features of different groups, respectively.
Also, we introduce a multi-label classification loss to further enhance the
<ACT> token's ability to learn discriminative semantic representations. Then,
we design a Multimodal Dual-Alignment Fusion (MDAF) module that integrates
MLLM's hidden embeddings corresponding to the designed tokens with visual
features, significantly enhancing the performance of GAD. Both quantitative and
qualitative experiments demonstrate the superior performance of our proposed
method in GAD taks.

</details>


### [100] [See&Trek: Training-Free Spatial Prompting for Multimodal Large Language Model](https://arxiv.org/abs/2509.16087)
*Pengteng Li,Pinhao Song,Wuyang Li,Weiyu Guo,Huizai Yao,Yijie Xu,Dugang Liu,Hui Xiong*

Main category: cs.CV

TL;DR: SEE&TREK是一个创新的、无需训练的提示框架，旨在增强多模态大语言模型（MLLMS）在纯视觉约束下的空间理解能力。它通过最大化语义丰富度采样和模拟运动轨迹来重建空间关系和时间连贯性，解决了纯视觉空间理解的不足。该方法无需训练和GPU，只需一次前向传播即可集成到现有MLLMS中，并在VSI-BENCH和STI-BENCH基准测试中显示出显著的性能提升，最高可达+3.5%。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型（MLLMS）在纯视觉约束下空间理解能力不足的问题，而现有方法大多依赖于额外的模态（如深度或点云）来提升空间推理能力。

Method: SEE&TREK框架包含两个核心原则：增加视觉多样性和重建运动。通过最大化语义丰富度采样（Maximum Semantic Richness Sampling）提取能够捕捉场景结构的语义丰富的关键帧；通过模拟视觉轨迹来重建运动，并将相对空间位置编码到关键帧中，以保持空间关系和时间连贯性。

Result: 在VSI-BENCH和STI-BENCH基准测试上，SEE&TREK能够持续提升多种MLLMS在不同空间推理任务上的性能，最高性能提升可达+3.5%。

Conclusion: SEE&TREK是一个高效且易于集成的框架，能够显著增强MLLMS的纯视觉空间理解能力，为实现更强的空间智能提供了有前景的途径。

Abstract: We introduce SEE&TREK, the first training-free prompting framework tailored
to enhance the spatial understanding of Multimodal Large Language Models
(MLLMS) under vision-only constraints. While prior efforts have incorporated
modalities like depth or point clouds to improve spatial reasoning, purely
visualspatial understanding remains underexplored. SEE&TREK addresses this gap
by focusing on two core principles: increasing visual diversity and motion
reconstruction. For visual diversity, we conduct Maximum Semantic Richness
Sampling, which employs an off-the-shell perception model to extract
semantically rich keyframes that capture scene structure. For motion
reconstruction, we simulate visual trajectories and encode relative spatial
positions into keyframes to preserve both spatial relations and temporal
coherence. Our method is training&GPU-free, requiring only a single forward
pass, and can be seamlessly integrated into existing MLLM'S. Extensive
experiments on the VSI-B ENCH and STI-B ENCH show that S EE &T REK consistently
boosts various MLLM S performance across diverse spatial reasoning tasks with
the most +3.5% improvement, offering a promising path toward stronger spatial
intelligence.

</details>


### [101] [Blind-Spot Guided Diffusion for Self-supervised Real-World Denoising](https://arxiv.org/abs/2509.16091)
*Shen Cheng,Haipeng Li,Haibin Huang,Xiaohong Liu,Shuaicheng Liu*

Main category: cs.CV

TL;DR: 提出了一种名为盲区引导扩散（Blind-Spot Guided Diffusion, BSGD）的新型自监督图像去噪框架，解决了盲区网络（BSN）牺牲局部细节和扩散模型难以应用于自监督去噪的挑战。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有盲区网络（BSN）在图像去噪中牺牲局部细节和引入像素不连续性的问题，以及扩散模型在自监督去噪中的应用难题。

Method: 提出了一种双分支扩散模型。一个分支基于BSN生成半净图像，另一个分支捕捉噪声分布。通过BSN分支引导采样过程，在保留局部细节的同时捕捉噪声结构，实现无配对数据的有效训练。

Result: 在SIDD和DND数据集上进行了大量实验，取得了最先进的性能。

Conclusion: 该方法被证明是真实世界图像自监督去噪的有效解决方案。

Abstract: In this work, we present Blind-Spot Guided Diffusion, a novel self-supervised
framework for real-world image denoising. Our approach addresses two major
challenges: the limitations of blind-spot networks (BSNs), which often
sacrifice local detail and introduce pixel discontinuities due to spatial
independence assumptions, and the difficulty of adapting diffusion models to
self-supervised denoising. We propose a dual-branch diffusion framework that
combines a BSN-based diffusion branch, generating semi-clean images, with a
conventional diffusion branch that captures underlying noise distributions. To
enable effective training without paired data, we use the BSN-based branch to
guide the sampling process, capturing noise structure while preserving local
details. Extensive experiments on the SIDD and DND datasets demonstrate
state-of-the-art performance, establishing our method as a highly effective
self-supervised solution for real-world denoising. Code and pre-trained models
are released at: https://github.com/Sumching/BSGD.

</details>


### [102] [AdaSports-Traj: Role- and Domain-Aware Adaptation for Multi-Agent Trajectory Modeling in Sports](https://arxiv.org/abs/2509.16095)
*Yi Xu,Yun Fu*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Trajectory prediction in multi-agent sports scenarios is inherently
challenging due to the structural heterogeneity across agent roles (e.g.,
players vs. ball) and dynamic distribution gaps across different sports
domains. Existing unified frameworks often fail to capture these structured
distributional shifts, resulting in suboptimal generalization across roles and
domains. We propose AdaSports-Traj, an adaptive trajectory modeling framework
that explicitly addresses both intra-domain and inter-domain distribution
discrepancies in sports. At its core, AdaSports-Traj incorporates a Role- and
Domain-Aware Adapter to conditionally adjust latent representations based on
agent identity and domain context. Additionally, we introduce a Hierarchical
Contrastive Learning objective, which separately supervises role-sensitive and
domain-aware representations to encourage disentangled latent structures
without introducing optimization conflict. Experiments on three diverse sports
datasets, Basketball-U, Football-U, and Soccer-U, demonstrate the effectiveness
of our adaptive design, achieving strong performance in both unified and
cross-domain trajectory prediction settings.

</details>


### [103] [SegDINO3D: 3D Instance Segmentation Empowered by Both Image-Level and Object-Level 2D Features](https://arxiv.org/abs/2509.16098)
*Jinyuan Qu,Hongyang Li,Xingyu Chen,Shilong Liu,Yukai Shi,Tianhe Ren,Ruitao Jing,Lei Zhang*

Main category: cs.CV

TL;DR: SegDINO3D是一个结合2D和3D信息的3D实例分割新框架，通过利用预训练的2D检测模型来提升3D表示能力，并在ScanNetV2和ScanNet200数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 由于3D训练数据相对于2D图像数据不足，SegDINO3D旨在充分利用预训练的2D检测模型的2D表示（包括图像级和对象级特征）来改进3D表示。

Method: SegDINO3D框架接受点云及其关联的2D图像作为输入。在编码器阶段，它首先通过检索相应视图的2D图像特征来丰富每个3D点，然后利用3D编码器进行3D上下文融合。在解码器阶段，它将3D对象查询表述为3D边界框，并通过3D查询与从2D图像获得的2D对象查询（来自2D检测模型）进行交叉注意力计算。3D边界框查询还允许模型使用预测的边界框来调节交叉注意力，以实现更精确的查询。

Result: SegDINO3D在ScanNetV2和ScanNet200 3D实例分割基准测试中取得了最先进的性能。特别是在具有挑战性的ScanNet200数据集上，SegDINO3D在验证集和隐藏测试集上的mAP分别比先前方法高出+8.7和+6.8。

Conclusion: SegDINO3D通过有效整合2D和3D信息，利用预训练的2D模型来弥补3D数据的不足，并在3D实例分割任务中取得了显著的性能提升，证明了其优越性。

Abstract: In this paper, we present SegDINO3D, a novel Transformer encoder-decoder
framework for 3D instance segmentation. As 3D training data is generally not as
sufficient as 2D training images, SegDINO3D is designed to fully leverage 2D
representation from a pre-trained 2D detection model, including both
image-level and object-level features, for improving 3D representation.
SegDINO3D takes both a point cloud and its associated 2D images as input. In
the encoder stage, it first enriches each 3D point by retrieving 2D image
features from its corresponding image views and then leverages a 3D encoder for
3D context fusion. In the decoder stage, it formulates 3D object queries as 3D
anchor boxes and performs cross-attention from 3D queries to 2D object queries
obtained from 2D images using the 2D detection model. These 2D object queries
serve as a compact object-level representation of 2D images, effectively
avoiding the challenge of keeping thousands of image feature maps in the memory
while faithfully preserving the knowledge of the pre-trained 2D model. The
introducing of 3D box queries also enables the model to modulate
cross-attention using the predicted boxes for more precise querying. SegDINO3D
achieves the state-of-the-art performance on the ScanNetV2 and ScanNet200 3D
instance segmentation benchmarks. Notably, on the challenging ScanNet200
dataset, SegDINO3D significantly outperforms prior methods by +8.7 and +6.8 mAP
on the validation and hidden test sets, respectively, demonstrating its
superiority.

</details>


### [104] [RadarGaussianDet3D: An Efficient and Effective Gaussian-based 3D Detector with 4D Automotive Radars](https://arxiv.org/abs/2509.16119)
*Weiyi Xiong,Bing Zhu,Tao Huang,Zewei Zheng*

Main category: cs.CV

TL;DR: RadarGaussianDet3D通过使用高斯原始体和分布作为中间表示，解决了现有4D雷达3D探测器特征稀疏和优化不佳的问题，实现了实时、高精度的自动驾驶感知。


<details>
  <summary>Details</summary>
Motivation: 现有4D雷达3D探测器在BEV特征提取中依赖于柱状编码器，导致特征图稀疏，表示质量下降；同时，边界框属性独立优化导致检测精度次优；并且推理速度可能无法满足车载嵌入式设备的实时性要求。

Method: 提出了一种名为RadarGaussianDet3D的高斯基3D探测器。设计了一种新颖的点高斯编码器（PGE），将每个点转换为高斯原始体，并使用3D高斯泼溅（3DGS）技术进行BEV栅格化，生成更密集的特征图。提出了一种新的边界框高斯损失（BGL），将边界框转换为3D高斯分布以进行更全面、一致的优化。

Result: RadarGaussianDet3D在TJ4DRadSet和View-of-Delft数据集上实现了最先进的检测精度，并且推理速度显著提高。

Conclusion: RadarGaussianDet3D克服了现有4D雷达3D探测器的局限性，在保持高检测精度的同时显著提高了推理速度，显示出其在自动驾驶中实时部署的潜力。

Abstract: 4D automotive radars have gained increasing attention for autonomous driving
due to their low cost, robustness, and inherent velocity measurement
capability. However, existing 4D radar-based 3D detectors rely heavily on
pillar encoders for BEV feature extraction, where each point contributes to
only a single BEV grid, resulting in sparse feature maps and degraded
representation quality. In addition, they also optimize bounding box attributes
independently, leading to sub-optimal detection accuracy. Moreover, their
inference speed, while sufficient for high-end GPUs, may fail to meet the
real-time requirement on vehicle-mounted embedded devices. To overcome these
limitations, an efficient and effective Gaussian-based 3D detector, namely
RadarGaussianDet3D is introduced, leveraging Gaussian primitives and
distributions as intermediate representations for radar points and bounding
boxes. In RadarGaussianDet3D, a novel Point Gaussian Encoder (PGE) is designed
to transform each point into a Gaussian primitive after feature aggregation and
employs the 3D Gaussian Splatting (3DGS) technique for BEV rasterization,
yielding denser feature maps. PGE exhibits exceptionally low latency, owing to
the optimized algorithm for point feature aggregation and fast rendering of
3DGS. In addition, a new Box Gaussian Loss (BGL) is proposed, which converts
bounding boxes into 3D Gaussian distributions and measures their distance to
enable more comprehensive and consistent optimization. Extensive experiments on
TJ4DRadSet and View-of-Delft demonstrate that RadarGaussianDet3D achieves
state-of-the-art detection accuracy while delivering substantially faster
inference, highlighting its potential for real-time deployment in autonomous
driving.

</details>


### [105] [BaseReward: A Strong Baseline for Multimodal Reward Model](https://arxiv.org/abs/2509.16127)
*Yi-Fan Zhang,Haihua Yang,Huanyu Zhang,Yang Shi,Zezhou Chen,Haochen Tian,Chaoyou Fu,Haotian Wang,Kai Wu,Bo Cui,Xu Wang,Jianfei Pan,Haotian Wang,Zhang Zhang,Liang Wang*

Main category: cs.CV

TL;DR: 本篇论文旨在为构建先进的多模态奖励模型（MRMs）提供一份系统性的指南，并提出了一种名为BaseReward的强大基线模型。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型（MLLMs）的快速发展，如何使其符合人类偏好成为一个关键挑战。奖励模型（RMs）是实现这一目标的核心技术，但目前缺乏一个系统性的指南来构建先进的多模态奖励模型（MRMs）。

Method: 通过详尽的实验分析，研究者系统地探究了MRM开发流程中的各个关键组成部分，包括奖励建模范式（如Naive-RM、Critic-based RM和Generative RM）、奖励头架构、训练策略、数据管理（涵盖十余个多模态和纯文本偏好数据集）、骨干模型和模型规模，以及集成方法。基于实验结果，提出了一种名为BaseReward的模型，该模型采用Qwen2.5-VL骨干，优化的两层奖励头，并在精心策划的多模态和纯文本偏好数据混合集上进行训练。

Result: BaseReward在MM-RLHF-Reward Bench、VL-Reward Bench和Multimodal Reward Bench等主要基准测试中取得了新的SOTA（state-of-the-art）性能，超越了之前的模型。将BaseReward集成到实际的强化学习流程中，成功提升了MLLM在感知、推理和对话等任务上的表现。

Conclusion: 本研究不仅提供了一个顶级的MRM，更重要的是为社区提供了一个清晰、经过实证支持的指南，以开发下一代MLLM的鲁棒奖励模型。

Abstract: The rapid advancement of Multimodal Large Language Models (MLLMs) has made
aligning them with human preferences a critical challenge. Reward Models (RMs)
are a core technology for achieving this goal, but a systematic guide for
building state-of-the-art Multimodal Reward Models (MRMs) is currently lacking
in both academia and industry. Through exhaustive experimental analysis, this
paper aims to provide a clear ``recipe'' for constructing high-performance
MRMs. We systematically investigate every crucial component in the MRM
development pipeline, including \textit{reward modeling paradigms} (e.g.,
Naive-RM, Critic-based RM, and Generative RM), \textit{reward head
architecture}, \textit{training strategies}, \textit{data curation} (covering
over ten multimodal and text-only preference datasets), \textit{backbone model}
and \textit{model scale}, and \textit{ensemble methods}.
  Based on these experimental insights, we introduce \textbf{BaseReward}, a
powerful and efficient baseline for multimodal reward modeling. BaseReward
adopts a simple yet effective architecture, built upon a {Qwen2.5-VL} backbone,
featuring an optimized two-layer reward head, and is trained on a carefully
curated mixture of high-quality multimodal and text-only preference data. Our
results show that BaseReward establishes a new SOTA on major benchmarks such as
MM-RLHF-Reward Bench, VL-Reward Bench, and Multimodal Reward Bench,
outperforming previous models. Furthermore, to validate its practical utility
beyond static benchmarks, we integrate BaseReward into a real-world
reinforcement learning pipeline, successfully enhancing an MLLM's performance
across various perception, reasoning, and conversational tasks. This work not
only delivers a top-tier MRM but, more importantly, provides the community with
a clear, empirically-backed guide for developing robust reward models for the
next generation of MLLMs.

</details>


### [106] [Recovering Parametric Scenes from Very Few Time-of-Flight Pixels](https://arxiv.org/abs/2509.16132)
*Carter Sifferman,Yiquan Li,Yiming Li,Fangzhou Mu,Michael Gleicher,Mohit Gupta,Yin Li*

Main category: cs.CV

TL;DR: 从稀疏的深度测量中恢复3D参数化场景的几何形状。


<details>
  <summary>Details</summary>
Motivation: 利用低成本、商用飞行时间（ToF）传感器，仅用很少的深度测量来恢复3D参数化场景的几何形状。

Method: 结合前馈预测和可微分渲染的分析-合成框架，以改进场景参数估计，并利用时间分辨的光子计数数据。

Result: 在模拟和受控的真实世界捕获中，使用未纹理的3D模型有效地恢复了物体姿态，并为其他参数化场景提供了初步结果。

Conclusion: 所提出的方法能够从稀疏的ToF测量中恢复场景几何形状，并探索了该成像解决方案的极限和能力。

Abstract: We aim to recover the geometry of 3D parametric scenes using very few depth
measurements from low-cost, commercially available time-of-flight sensors.
These sensors offer very low spatial resolution (i.e., a single pixel), but
image a wide field-of-view per pixel and capture detailed time-of-flight data
in the form of time-resolved photon counts. This time-of-flight data encodes
rich scene information and thus enables recovery of simple scenes from sparse
measurements. We investigate the feasibility of using a distributed set of few
measurements (e.g., as few as 15 pixels) to recover the geometry of simple
parametric scenes with a strong prior, such as estimating the 6D pose of a
known object. To achieve this, we design a method that utilizes both
feed-forward prediction to infer scene parameters, and differentiable rendering
within an analysis-by-synthesis framework to refine the scene parameter
estimate. We develop hardware prototypes and demonstrate that our method
effectively recovers object pose given an untextured 3D model in both
simulations and controlled real-world captures, and show promising initial
results for other parametric scenes. We additionally conduct experiments to
explore the limits and capabilities of our imaging solution.

</details>


### [107] [AcT2I: Evaluating and Improving Action Depiction in Text-to-Image Models](https://arxiv.org/abs/2509.16141)
*Vatsal Malaviya,Agneet Chatterjee,Maitreya Patel,Yezhou Yang,Chitta Baral*

Main category: cs.CV

TL;DR: T2I模型在生成复杂动作场景图像时存在不足，提出AcT2I基准和基于LLM的提示增强方法，显著提升了图像生成精度。


<details>
  <summary>Details</summary>
Motivation: 现有T2I模型在描绘复杂动作场景时存在困难，难以捕捉隐含的语义和上下文细节。

Method: 提出AcT2I基准来评估T2I模型在动作场景生成上的表现。利用大型语言模型（LLM）的知识蒸馏技术，通过增强提示信息（特别是时间维度）来弥补T2I模型的不足。

Result: 在AcT2I基准上，现有T2I模型表现不佳。通过提示增强方法，图像生成精度最高提升了72%。

Conclusion: 当前T2I模型在生成需要复杂推理的图像方面存在局限性，但通过系统性地整合语言学知识（如时间信息）可以显著提高生成图像的精确度和上下文相关性。

Abstract: Text-to-Image (T2I) models have recently achieved remarkable success in
generating images from textual descriptions. However, challenges still persist
in accurately rendering complex scenes where actions and interactions form the
primary semantic focus. Our key observation in this work is that T2I models
frequently struggle to capture nuanced and often implicit attributes inherent
in action depiction, leading to generating images that lack key contextual
details. To enable systematic evaluation, we introduce AcT2I, a benchmark
designed to evaluate the performance of T2I models in generating images from
action-centric prompts. We experimentally validate that leading T2I models do
not fare well on AcT2I. We further hypothesize that this shortcoming arises
from the incomplete representation of the inherent attributes and contextual
dependencies in the training corpora of existing T2I models. We build upon this
by developing a training-free, knowledge distillation technique utilizing Large
Language Models to address this limitation. Specifically, we enhance prompts by
incorporating dense information across three dimensions, observing that
injecting prompts with temporal details significantly improves image generation
accuracy, with our best model achieving an increase of 72%. Our findings
highlight the limitations of current T2I methods in generating images that
require complex reasoning and demonstrate that integrating linguistic knowledge
in a systematic way can notably advance the generation of nuanced and
contextually accurate images.

</details>


### [108] [Pointing to a Llama and Call it a Camel: On the Sycophancy of Multimodal Large Language Models](https://arxiv.org/abs/2509.16149)
*Renjie Pi,Kehao Miao,Li Peihang,Runtao Liu,Jiahui Gao,Jipeng Zhang,Xiaofang Zhou*

Main category: cs.CV

TL;DR: MLLMs 在处理图像输入时表现出比文本 LLMs 更明显的视觉奉承行为，称为“奉承模态鸿沟”。


<details>
  <summary>Details</summary>
Motivation: 识别并解决 MLLMs 中因图像输入而加剧的视觉奉承行为。

Method: 1. 分析导致视觉奉承行为扩大的因素。 2. 尝试了标准的监督微调，但发现它会导致模型对纠正指令过于固执。 3. 提出了“奉承反思调整”（SRT），一种通过反思性推理来区分误导性和纠正性指令的方法。

Result: SRT 显著减少了 MLLMs 对误导性指令的奉承行为，同时避免了对纠正性指令的过度固执。

Conclusion: SRT 是一种有效缓解 MLLMs 中视觉奉承行为的方法，而不会损害其对正确指令的响应能力。

Abstract: Multimodal large language models (MLLMs) have demonstrated extraordinary
capabilities in conducting conversations based on image inputs. However, we
observe that MLLMs exhibit a pronounced form of visual sycophantic behavior.
While similar behavior has also been noted in text-based large language models
(LLMs), it becomes significantly more prominent when MLLMs process image
inputs. We refer to this phenomenon as the "sycophantic modality gap." To
better understand this issue, we further analyze the factors that contribute to
the exacerbation of this gap. To mitigate the visual sycophantic behavior, we
first experiment with naive supervised fine-tuning to help the MLLM resist
misleading instructions from the user. However, we find that this approach also
makes the MLLM overly resistant to corrective instructions (i.e., stubborn even
if it is wrong). To alleviate this trade-off, we propose Sycophantic Reflective
Tuning (SRT), which enables the MLLM to engage in reflective reasoning,
allowing it to determine whether a user's instruction is misleading or
corrective before drawing a conclusion. After applying SRT, we observe a
significant reduction in sycophantic behavior toward misleading instructions,
without resulting in excessive stubbornness when receiving corrective
instructions.

</details>


### [109] [UniMRSeg: Unified Modality-Relax Segmentation via Hierarchical Self-Supervised Compensation](https://arxiv.org/abs/2509.16170)
*Xiaoqi Zhao,Youwei Pang,Chenyang Yu,Lihe Zhang,Huchuan Lu,Shijian Lu,Georges El Fakhri,Xiaofeng Liu*

Main category: cs.CV

TL;DR: UniMRSeg 通过分层自监督补偿（HSSC）解决了多模态图像分割中因模态不完整或损坏导致的性能下降问题，在不增加部署成本的情况下，实现了对各种缺失模态的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态图像分割方法在面对训练-推理阶段的模态不匹配问题时，通常需要为每种模态组合训练专门的模型，这导致了高昂的部署成本，并需要进行详尽的模型子集选择和模态匹配。因此，需要一种能够统一处理不同模态组合并降低部署成本的方法。

Method: 本文提出了一种名为 UniMRSeg 的统一模态-放松分割网络，它利用分层自监督补偿（HSSC）机制。该机制在输入、特征和输出三个层级上弥合了完整模态与不完整模态之间的表示差距。具体包括：1. 采用混合掩码增强的模态重建，鼓励模型学习内在模态特征并通过跨模态融合生成缺失模态的有意义表示。2. 模态不变的对比学习，隐式地补偿不完整-完整模态对之间的特征空间距离。3. 所提出的轻量级逆注意力适配器，显式地补偿了冻结编码器中较弱的感知语义。4. 在混合一致性约束下进行微调，以确保在所有模态组合下都能稳定预测，且性能波动小。

Result: UniMRSeg 在标准的脑肿瘤 MRI 分割、RGB-D 语义分割以及 RGB-D/T 显着目标分割等多种缺失模态场景下，显著优于现有最先进的方法，且无需复杂的附加组件。

Conclusion: UniMRSeg 提出了一种新颖有效的解决方案，通过分层自监督补偿（HSSC）实现了对多模态图像分割中模态缺失问题的鲁棒性，显著提高了在各种不完整模态下的分割性能，同时避免了传统方法的高部署成本。

Abstract: Multi-modal image segmentation faces real-world deployment challenges from
incomplete/corrupted modalities degrading performance. While existing methods
address training-inference modality gaps via specialized per-combination
models, they introduce high deployment costs by requiring exhaustive model
subsets and model-modality matching. In this work, we propose a unified
modality-relax segmentation network (UniMRSeg) through hierarchical
self-supervised compensation (HSSC). Our approach hierarchically bridges
representation gaps between complete and incomplete modalities across input,
feature and output levels. % First, we adopt modality reconstruction with the
hybrid shuffled-masking augmentation, encouraging the model to learn the
intrinsic modality characteristics and generate meaningful representations for
missing modalities through cross-modal fusion. % Next, modality-invariant
contrastive learning implicitly compensates the feature space distance among
incomplete-complete modality pairs. Furthermore, the proposed lightweight
reverse attention adapter explicitly compensates for the weak perceptual
semantics in the frozen encoder. Last, UniMRSeg is fine-tuned under the hybrid
consistency constraint to ensure stable prediction under all modality
combinations without large performance fluctuations. Without bells and
whistles, UniMRSeg significantly outperforms the state-of-the-art methods under
diverse missing modality scenarios on MRI-based brain tumor segmentation, RGB-D
semantic segmentation, RGB-D/T salient object segmentation. The code will be
released at https://github.com/Xiaoqi-Zhao-DLUT/UniMRSeg.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [110] [Synthetic bootstrapped pretraining](https://arxiv.org/abs/2509.15248)
*Zitong Yang,Aonan Zhang,Hong Liu,Tatsunori Hashimoto,Emmanuel Candès,Chong Wang,Ruoming Pang*

Main category: cs.CL

TL;DR: SBP是一种新的语言模型预训练方法，通过学习文档间的关系来合成新数据，从而提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 标准预训练方法主要关注文档内因果关系，未能有效利用文档间的丰富关联性。SBP旨在通过建模和利用文档间关联性来提升语言模型性能。

Method: SBP首先学习文档间关系模型，然后利用该模型合成大规模新语料库进行联合训练。在计算量匹配的设置下，使用多达1万亿个token从头开始预训练了一个30亿参数的模型。

Result: SBP在预训练的3B参数模型上持续优于基线方法，并显著接近使用20倍更多独特数据所能达到的最优性能。合成的文档不仅仅是简单的释义，而是抽象核心概念后进行重述。

Conclusion: SBP是一种有效的语言模型预训练技术，能够通过合成数据显著提升模型性能，并具有自然的贝叶斯解释，即合成器能够学习和抽象文档间共享的潜在概念。

Abstract: We introduce Synthetic Bootstrapped Pretraining (SBP), a language model (LM)
pretraining procedure that first learns a model of relations between documents
from the pretraining dataset and then leverages it to synthesize a vast new
corpus for joint training. While the standard pretraining teaches LMs to learn
causal correlations among tokens within a single document, it is not designed
to efficiently model the rich, learnable inter-document correlations that can
potentially lead to better performance. We validate SBP by designing a
compute-matched pretraining setup and pretrain a 3B-parameter model on up to 1T
tokens from scratch. We find SBP consistently improves upon a strong repetition
baseline and delivers a significant fraction of performance improvement
attainable by an oracle upper bound with access to 20x more unique data.
Qualitative analysis reveals that the synthesized documents go beyond mere
paraphrases -- SBP first abstracts a core concept from the seed material and
then crafts a new narration on top of it. Besides strong empirical performance,
SBP admits a natural Bayesian interpretation: the synthesizer implicitly learns
to abstract the latent concepts shared between related documents.

</details>


### [111] [Comparative Analysis of Tokenization Algorithms for Low-Resource Language Dzongkha](https://arxiv.org/abs/2509.15255)
*Tandin Wangchuk,Tad Gonsalves*

Main category: cs.CL

TL;DR: SentencePiece在隆宗语分词方面比BPE和WordPiece更有效，为隆宗语自然语言处理的进步铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM分词器对隆宗语等低资源语言效果不佳，需要针对隆宗语进行研究。

Method: 评估了BPE、WordPiece和SentencePiece这三种分词算法在隆宗语上的训练和性能，并使用子词肥力、继续词比例、归一化序列长度和执行时间等指标进行评估。

Result: 所有三种算法都显示出潜力，但SentencePiece在隆宗语分词方面最有效。

Conclusion: 为低资源语言开发定制化方法至关重要，SentencePiece为隆宗语大规模语言模型的发展铺平了道路。

Abstract: Large Language Models (LLMs) are gaining popularity and improving rapidly.
Tokenizers are crucial components of natural language processing, especially
for LLMs. Tokenizers break down input text into tokens that models can easily
process while ensuring the text is accurately represented, capturing its
meaning and structure. Effective tokenizers enhance the capabilities of LLMs by
improving a model's understanding of context and semantics, ultimately leading
to better performance in various downstream tasks, such as translation,
classification, sentiment analysis, and text generation. Most pre-trained
tokenizers are suitable for high-resource languages like English but perform
poorly for low-resource languages. Dzongkha, Bhutan's national language spoken
by around seven hundred thousand people, is a low-resource language, and its
linguistic complexity poses unique NLP challenges. Despite some progress,
significant research in Dzongkha NLP is lacking, particularly in tokenization.
This study evaluates the training and performance of three common tokenization
algorithms in comparison to other popular methods. Specifically, Byte-Pair
Encoding (BPE), WordPiece, and SentencePiece (Unigram) were evaluated for their
suitability for Dzongkha. Performance was assessed using metrics like Subword
Fertility, Proportion of Continued Words, Normalized Sequence Length, and
execution time. The results show that while all three algorithms demonstrate
potential, SentencePiece is the most effective for Dzongkha tokenization,
paving the way for further NLP advancements. This underscores the need for
tailored approaches for low-resource languages and ongoing research. In this
study, we presented three tokenization algorithms for Dzongkha, paving the way
for building Dzongkha Large Language Models.

</details>


### [112] [Toxicity Red-Teaming: Benchmarking LLM Safety in Singapore's Low-Resource Languages](https://arxiv.org/abs/2509.15260)
*Yujia Hu,Ming Shan Hee,Preslav Nakov,Roy Ka-Wei Lee*

Main category: cs.CL

TL;DR: 本研究提出了SGToxicGuard，一个用于评估新加坡多语言环境下大型语言模型（LLM）安全性的新数据集和评估框架，旨在解决低资源、多语言设置下LLM安全机制研究不足的问题。


<details>
  <summary>Details</summary>
Motivation: 目前，大型语言模型（LLM）在安全机制方面，尤其是在低资源、多语言环境下的研究尚不充分。本研究旨在弥合这一差距，并为在语言多样化环境中构建更安全、更具包容性的AI系统奠定基础。

Method: 本研究采用了红队测试方法，系统地探测LLM在三种真实场景（对话、问答、内容创作）下的漏洞。研究利用SGToxicGuard数据集，并在新加坡的多种语言（包括新加坡式英语、中文、马来语和泰米尔语）背景下进行评估。

Result: 通过对先进的多语言LLM进行广泛的实验，研究结果揭示了它们在安全防护方面存在的关键缺陷。SGToxicGuard数据集和评估框架为理解和解决这些问题提供了基础。

Conclusion: 本研究通过引入SGToxicGuard数据集和评估框架，在新加坡的多语言环境中，为评估和改进大型语言模型的安全性提供了新的途径。研究结果表明，现有的多语言LLM在安全防护方面存在不足，并强调了在文化敏感性和毒性方面进行改进的必要性，以期为语言多样化环境下的AI系统提供更安全、更包容的解决方案。

Abstract: The advancement of Large Language Models (LLMs) has transformed natural
language processing; however, their safety mechanisms remain under-explored in
low-resource, multilingual settings. Here, we aim to bridge this gap. In
particular, we introduce \textsf{SGToxicGuard}, a novel dataset and evaluation
framework for benchmarking LLM safety in Singapore's diverse linguistic
context, including Singlish, Chinese, Malay, and Tamil. SGToxicGuard adopts a
red-teaming approach to systematically probe LLM vulnerabilities in three
real-world scenarios: \textit{conversation}, \textit{question-answering}, and
\textit{content composition}. We conduct extensive experiments with
state-of-the-art multilingual LLMs, and the results uncover critical gaps in
their safety guardrails. By offering actionable insights into cultural
sensitivity and toxicity mitigation, we lay the foundation for safer and more
inclusive AI systems in linguistically diverse environments.\footnote{Link to
the dataset: https://github.com/Social-AI-Studio/SGToxicGuard.}
\textcolor{red}{Disclaimer: This paper contains sensitive content that may be
disturbing to some readers.}

</details>


### [113] [PolBiX: Detecting LLMs' Political Bias in Fact-Checking through X-phemisms](https://arxiv.org/abs/2509.15335)
*Charlott Jakob,David Harbecke,Patrick Parschan,Pia Wenzel Neves,Vera Schmitt*

Main category: cs.CL

TL;DR: 研究发现，除了政治倾向，判断性词语的使用更能影响大型语言模型对事实的判断，并且显式提示模型保持客观并不能缓解这一现象。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在需要客观评估的应用中越来越普遍，但其政治偏见可能影响评估的准确性。已有研究发现LLM偏向左倾立场，但对事实核查等下游任务的影响尚不明确。

Method: 通过替换德语文本中的委婉语或粗鄙语，构建了事实等价但政治内涵不同的“最小对”文本，以评估LLM在判断这些文本真伪时的一致性。评估了六种LLM。

Result: 研究发现，判断性词语的使用比政治倾向更能显著影响LLM的真伪判断。部分模型表现出政治偏见，但显式提示模型保持客观并不能缓解这种偏见。

Conclusion: 判断性词语对LLM真伪判断的影响比政治倾向更显著，且提示模型保持客观无效。

Abstract: Large Language Models are increasingly used in applications requiring
objective assessment, which could be compromised by political bias. Many
studies found preferences for left-leaning positions in LLMs, but downstream
effects on tasks like fact-checking remain underexplored. In this study, we
systematically investigate political bias through exchanging words with
euphemisms or dysphemisms in German claims. We construct minimal pairs of
factually equivalent claims that differ in political connotation, to assess the
consistency of LLMs in classifying them as true or false. We evaluate six LLMs
and find that, more than political leaning, the presence of judgmental words
significantly influences truthfulness assessment. While a few models show
tendencies of political bias, this is not mitigated by explicitly calling for
objectivism in prompts.

</details>


### [114] [Quantifying Self-Awareness of Knowledge in Large Language Models](https://arxiv.org/abs/2509.15339)
*Yeongbin Seo,Dongha Lee,Jinyoung Yeo*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Hallucination prediction in large language models (LLMs) is often interpreted
as a sign of self-awareness. However, we argue that such performance can arise
from question-side shortcuts rather than true model-side introspection. To
disentangle these factors, we propose the Approximate Question-side Effect
(AQE), which quantifies the contribution of question-awareness. Our analysis
across multiple datasets reveals that much of the reported success stems from
exploiting superficial patterns in questions. We further introduce SCAO
(Semantic Compression by Answering in One word), a method that enhances the use
of model-side signals. Experiments show that SCAO achieves strong and
consistent performance, particularly in settings with reduced question-side
cues, highlighting its effectiveness in fostering genuine self-awareness in
LLMs.

</details>


### [115] [Real, Fake, or Manipulated? Detecting Machine-Influenced Text](https://arxiv.org/abs/2509.15350)
*Yitong Wang,Zhongping Zhang,Margherita Piana,Zheng Zhou,Peter Gerstoft,Bryan A. Plummer*

Main category: cs.CL

TL;DR: LLM生成的文本可能用于传播错误信息，而不仅仅是翻译。本文提出了一种名为HERO的层级、长度鲁棒的机器影响文本检测器，可以区分人类写作、机器生成、机器润色和机器翻译文本。HERO通过结合长度专业模型和子类别引导模块的预测来实现这一目标，该模块有助于区分容易混淆的类别。实验证明HERO优于现有技术。


<details>
  <summary>Details</summary>
Motivation: LLM可用于改进文档、翻译或生成可能用于传播错误信息的文档。需要一种能够区分不同类型机器影响文本（机器生成、机器润色、机器翻译）并与人类写作区分开来的方法，以理解LLM使用的意图。

Method: 提出了一种名为HERO（层级、长度鲁棒的机器影响文本检测器）的方法。HERO结合了由子类别引导训练的长度专业模型。子类别引导模块有助于区分容易混淆的类别（例如，不同源语言）。

Result: 在五个LLM和六个领域进行的广泛实验表明，HERO的性能优于现有技术，平均mAP提高了2.5-3。

Conclusion: HERO能够有效地区分人类写作、机器生成、机器润色和机器翻译文本，并且在不同长度的文本上表现稳健，优于现有技术。

Abstract: Large Language Model (LLMs) can be used to write or modify documents,
presenting a challenge for understanding the intent behind their use. For
example, benign uses may involve using LLM on a human-written document to
improve its grammar or to translate it into another language. However, a
document entirely produced by a LLM may be more likely to be used to spread
misinformation than simple translation (\eg, from use by malicious actors or
simply by hallucinating). Prior works in Machine Generated Text (MGT) detection
mostly focus on simply identifying whether a document was human or machine
written, ignoring these fine-grained uses. In this paper, we introduce a
HiErarchical, length-RObust machine-influenced text detector (HERO), which
learns to separate text samples of varying lengths from four primary types:
human-written, machine-generated, machine-polished, and machine-translated.
HERO accomplishes this by combining predictions from length-specialist models
that have been trained with Subcategory Guidance. Specifically, for categories
that are easily confused (\eg, different source languages), our Subcategory
Guidance module encourages separation of the fine-grained categories, boosting
performance. Extensive experiments across five LLMs and six domains demonstrate
the benefits of our HERO, outperforming the state-of-the-art by 2.5-3 mAP on
average.

</details>


### [116] [Beyond Spurious Signals: Debiasing Multimodal Large Language Models via Counterfactual Inference and Adaptive Expert Routing](https://arxiv.org/abs/2509.15361)
*Zichen Wu,Hsiu-Yuan Huang,Yunfang Wu*

Main category: cs.CL

TL;DR: 通过因果中介进行多模态大模型（MLLMs）的偏见消除


<details>
  <summary>Details</summary>
Motivation: 现有的MLLMs在整合视觉和文本信息方面能力强大，但存在依赖虚假关联的问题，这会削弱其在复杂多模态推理任务中的鲁棒性和泛化能力。

Method: 提出一种新颖的基于因果中介的偏见消除框架，通过反事实示例区分核心语义与虚假的文本和视觉背景，激活训练阶段的偏见消除，并采用专家混合（MoE）架构和动态路由来选择性地激活特定模态的偏见消除专家。

Result: 在多模态讽刺检测和情感分析任务上的实证评估表明，该框架显著优于单一模态的偏见消除策略和现有的最先进模型。

Conclusion: 该研究提出的基于因果中介的偏见消除框架能够有效解决MLLMs中的虚假关联偏见问题，并提升其在多模态推理任务上的表现。

Abstract: Multimodal Large Language Models (MLLMs) have shown substantial capabilities
in integrating visual and textual information, yet frequently rely on spurious
correlations, undermining their robustness and generalization in complex
multimodal reasoning tasks. This paper addresses the critical challenge of
superficial correlation bias in MLLMs through a novel causal mediation-based
debiasing framework. Specially, we distinguishing core semantics from spurious
textual and visual contexts via counterfactual examples to activate
training-stage debiasing and employ a Mixture-of-Experts (MoE) architecture
with dynamic routing to selectively engages modality-specific debiasing
experts. Empirical evaluation on multimodal sarcasm detection and sentiment
analysis tasks demonstrates that our framework significantly surpasses unimodal
debiasing strategies and existing state-of-the-art models.

</details>


### [117] [Speech Language Models for Under-Represented Languages: Insights from Wolof](https://arxiv.org/abs/2509.15362)
*Yaya Sy,Dioula Doucouré,Christophe Cerisara,Irina Illina*

Main category: cs.CL

TL;DR: 训练了一个用于沃尔夫语（一种西非代表性不足的语言）的语音语言模型，该模型在语音识别和语音翻译方面表现出色，并将分享模型和代码。


<details>
  <summary>Details</summary>
Motivation: 解决沃尔夫语作为一种代表性不足的语言，在语音技术领域缺乏资源的问题。

Method: 首先，通过在大量自发、高质量的沃尔夫语语音数据上持续预训练HuBERT模型，以提升其在自动语音识别（ASR）任务上的表现。然后，将这个预训练的语音编码器集成到一个沃尔夫语语言模型（LLM）中，创建第一个沃尔夫语语音LLM，并探索其在语音翻译等多任务上的应用。此外，还研究了训练语音LLM执行多步思维链（Chain-of-Thought）的能力，以提高其在转录或翻译前的理解和推理能力。

Result: 预训练的HuBERT模型在ASR任务上优于基础模型和非洲语言中心模型。所训练的语音LLM不仅提高了语音识别性能，在语音翻译任务上也取得了良好的效果。

Conclusion: 所提出的方法成功地为沃尔夫语构建了一个功能强大的语音LLM，它在语音识别和语音翻译方面都有显著的提升，并且计划公开分享模型和代码以促进该领域的研究。

Abstract: We present our journey in training a speech language model for Wolof, an
underrepresented language spoken in West Africa, and share key insights. We
first emphasize the importance of collecting large-scale, spontaneous,
high-quality speech data, and show that continued pretraining HuBERT on this
dataset outperforms both the base model and African-centric models on ASR. We
then integrate this speech encoder into a Wolof LLM to train the first Speech
LLM for this language, extending its capabilities to tasks such as speech
translation. Furthermore, we explore training the Speech LLM to perform
multi-step Chain-of-Thought before transcribing or translating. Our results
show that the Speech LLM not only improves speech recognition but also performs
well in speech translation. The models and the code will be openly shared.

</details>


### [118] [Frustratingly Easy Data Augmentation for Low-Resource ASR](https://arxiv.org/abs/2509.15373)
*Katsumi Ibaraki,David Chiang*

Main category: cs.CL

TL;DR: 本文提出了三种用于低资源语音识别（ASR）的数据增强方法，通过文本生成和语音合成（TTS）来创建新的语音数据，并在四种低资源语言上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 为低资源自动语音识别（ASR）任务提供有效的数据增强方法，以提升模型性能。

Method: 本文提出了三种独立的文本增强方法（基于词标替换、随机替换、LLM），然后使用语音合成（TTS）生成合成语音，最后将原始语音和合成语音结合用于模型微调。

Result: 在Vatlongos、Nashta、Shinekhen Buryat和Kakabe四种低资源语言上，使用增强数据微调Wav2Vec2-XLSR-53模型，取得了显著的词错误率（WER）降低，其中Nashta语言的WER降低了14.3%。该方法也对英语等高资源语言有效。

Conclusion: 本文提出的三种数据增强方法在低资源和高资源语言的ASR任务上都证明了其有效性和广泛适用性。

Abstract: This paper introduces three self-contained data augmentation methods for
low-resource Automatic Speech Recognition (ASR). Our techniques first generate
novel text--using gloss-based replacement, random replacement, or an LLM-based
approach--and then apply Text-to-Speech (TTS) to produce synthetic audio. We
apply these methods, which leverage only the original annotated data, to four
languages with extremely limited resources (Vatlongos, Nashta, Shinekhen
Buryat, and Kakabe). Fine-tuning a pretrained Wav2Vec2-XLSR-53 model on a
combination of the original audio and generated synthetic data yields
significant performance gains, including a 14.3% absolute WER reduction for
Nashta. The methods prove effective across all four low-resource languages and
also show utility for high-resource languages like English, demonstrating their
broad applicability.

</details>


### [119] [Quantifying Uncertainty in Natural Language Explanations of Large Language Models for Question Answering](https://arxiv.org/abs/2509.15403)
*Yangyi Li,Mengdi Huai*

Main category: cs.CL

TL;DR: 研究如何为大型语言模型生成的自然语言解释提供有效的不确定性保证，并提出了一种新颖的后验、模型无关的框架，以及一种在存在噪声时仍能保持有效不确定性保证的鲁棒方法。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）缺乏透明度，需要可解释的方法来理解其行为，自然语言解释因其自解释能力和处理闭源模型的能力而备受关注。然而，目前还没有研究关注如何为这些自然语言解释提供有效的不确定性保证，这对于理解解释的置信度至关重要。

Method: 提出了一种新颖的后验、模型无关的不确定性估计框架，用于LLM生成的自然语言解释。设计了一种新颖的鲁棒不确定性估计方法，即使在存在噪声的情况下也能保持有效的不确定性保证。

Result: 在问答（QA）任务上的广泛实验证明了所提出方法的有效性。

Conclusion: 所提出的不确定性估计框架和鲁棒方法能够为LLM生成的自然语言解释提供有效的不确定性保证，即使在存在噪声的情况下也能保持鲁棒性。

Abstract: Large language models (LLMs) have shown strong capabilities, enabling
concise, context-aware answers in question answering (QA) tasks. The lack of
transparency in complex LLMs has inspired extensive research aimed at
developing methods to explain large language behaviors. Among existing
explanation methods, natural language explanations stand out due to their
ability to explain LLMs in a self-explanatory manner and enable the
understanding of model behaviors even when the models are closed-source.
However, despite these promising advancements, there is no existing work
studying how to provide valid uncertainty guarantees for these generated
natural language explanations. Such uncertainty quantification is critical in
understanding the confidence behind these explanations. Notably, generating
valid uncertainty estimates for natural language explanations is particularly
challenging due to the auto-regressive generation process of LLMs and the
presence of noise in medical inquiries. To bridge this gap, in this work, we
first propose a novel uncertainty estimation framework for these generated
natural language explanations, which provides valid uncertainty guarantees in a
post-hoc and model-agnostic manner. Additionally, we also design a novel robust
uncertainty estimation method that maintains valid uncertainty guarantees even
under noise. Extensive experiments on QA tasks demonstrate the desired
performance of our methods.

</details>


### [120] [Deep learning and abstractive summarisation for radiological reports: an empirical study for adapting the PEGASUS models' family with scarce data](https://arxiv.org/abs/2509.15419)
*Claudio Benzoni,Martina Langhals,Martin Boeker,Luise Modersohn,Máté E. Maros*

Main category: cs.CL

TL;DR: fine-tuning PEGASUS and PEGASUS-X for medical text summarisation shows challenges with scarce data, with PEGASUS exhibiting double-descent and PEGASUS-X being negatively impacted by larger checkpoints.


<details>
  <summary>Details</summary>
Motivation: The increasing volume of medical imaging necessitates automated tools for summarising complex medical texts, a challenging task in sensitive and data-restrictive domains.

Method: Fine-tuned non-domain-specific abstractive summarisation models (PEGASUS and PEGASUS-X) on a medium-sized radiological reports dataset, evaluating different checkpoints and training data sizes while monitoring performance with lexical and semantic metrics.

Result: PEGASUS showed phases related to epoch-wise double-descent or peak-drop-recovery. PEGASUS-X's performance was negatively affected by using a larger checkpoint.

Conclusion: Fine-tuning highly expressive models on scarce data for summarisation in specialised domains presents challenges and risks, necessitating further research into robust fine-tuning strategies.

Abstract: Regardless of the rapid development of artificial intelligence, abstractive
summarisation is still challenging for sensitive and data-restrictive domains
like medicine. With the increasing number of imaging, the relevance of
automated tools for complex medical text summarisation is expected to become
highly relevant. In this paper, we investigated the adaptation via fine-tuning
process of a non-domain-specific abstractive summarisation encoder-decoder
model family, and gave insights to practitioners on how to avoid over- and
underfitting. We used PEGASUS and PEGASUS-X, on a medium-sized radiological
reports public dataset. For each model, we comprehensively evaluated two
different checkpoints with varying sizes of the same training data. We
monitored the models' performances with lexical and semantic metrics during the
training history on the fixed-size validation set. PEGASUS exhibited different
phases, which can be related to epoch-wise double-descent, or
peak-drop-recovery behaviour. For PEGASUS-X, we found that using a larger
checkpoint led to a performance detriment. This work highlights the challenges
and risks of fine-tuning models with high expressivity when dealing with scarce
training data, and lays the groundwork for future investigations into more
robust fine-tuning strategies for summarisation models in specialised domains.

</details>


### [121] [BiRQ: Bi-Level Self-Labeling Random Quantization for Self-Supervised Speech Recognition](https://arxiv.org/abs/2509.15430)
*Liuyuan Jiang,Xiaodong Cui,Brian Kingsbury,Tianyi Chen,Lisha Chen*

Main category: cs.CL

TL;DR: BiRQ是一种双层自监督学习框架，通过复用模型自身一部分作为伪标签生成器，结合了BEST-RQ的效率和HuBERT的标签增强优势，无需外部编码器，实现了端到端的标签精炼和训练。


<details>
  <summary>Details</summary>
Motivation: 为了解决语音自监督学习中生成信息丰富且高效的伪标签的挑战，同时兼顾效率和标签质量。

Method: 提出了一种双层自监督学习框架BiRQ，它复用模型自身一部分作为伪标签生成器，利用随机投影量化器离散化中间表示生成增强标签，并使用来自原始输入的锚定标签来稳定训练，通过一阶双层优化问题进行端到端训练。

Result: BiRQ在多个数据集（包括LibriSpeech、AMI会议和YODAS）上持续优于BEST-RQ，同时保持了低复杂度和计算效率。

Conclusion: BiRQ通过端到端的方式实现了高效的伪标签生成和模型训练，无需外部编码器，并在多项语音识别任务上取得了性能提升。

Abstract: Speech is a rich signal, and labeled audio-text pairs are costly, making
self-supervised learning essential for scalable representation learning. A core
challenge in speech SSL is generating pseudo-labels that are both informative
and efficient: strong labels, such as those used in HuBERT, improve downstream
performance but rely on external encoders and multi-stage pipelines, while
efficient methods like BEST-RQ achieve simplicity at the cost of weaker labels.
We propose BiRQ, a bilevel SSL framework that combines the efficiency of
BEST-RQ with the refinement benefits of HuBERT-style label enhancement. The key
idea is to reuse part of the model itself as a pseudo-label generator:
intermediate representations are discretized by a random-projection quantizer
to produce enhanced labels, while anchoring labels derived directly from the
raw input stabilize training and prevent collapse. Training is formulated as an
efficient first-order bilevel optimization problem, solved end-to-end with
differentiable Gumbel-softmax selection. This design eliminates the need for
external label encoders, reduces memory cost, and enables iterative label
refinement in an end-to-end fashion. BiRQ consistently improves over BEST-RQ
while maintaining low complexity and computational efficiency. We validate our
method on various datasets, including 960-hour LibriSpeech, 150-hour AMI
meetings and 5,000-hour YODAS, demonstrating consistent gains over BEST-RQ.

</details>


### [122] [PILOT: Steering Synthetic Data Generation with Psychological & Linguistic Output Targeting](https://arxiv.org/abs/2509.15447)
*Caitlin Cisar,Emily Sheffield,Joshua Drake,Alden Harrell,Subramanian Chidambaram,Nikita Nangia,Vinayak Arannil,Alex Williams*

Main category: cs.CL

TL;DR: PILOT是一个两阶段框架，通过结构化的心理语言学档案来指导大型语言模型的生成，解决了自然语言用户画像带来的不精确控制问题，显著提高了输出的一致性和主题纯度。


<details>
  <summary>Details</summary>
Motivation: 现有生成式AI应用依赖自然语言用户画像，导致模型在强调属性时产生意外推断，限制了对输出的精确控制。PILOT旨在通过结构化的心理语言学档案来提供更精确的控制。

Method: PILOT分为两个阶段：第一阶段将自然语言用户画像转换为包含语言和心理维度标准化分的多维度档案；第二阶段利用这些档案引导模型沿着可衡量的变化轴进行生成。实验在三种先进的大型语言模型上，使用25种合成用户画像，在三种条件下（自然语言、基于模式、混合）进行了评估。

Result: 基于模式的方法显著减少了人工痕迹和用户画像重复，提高了输出连贯性（轮廓得分从0.098提高到0.237，主题纯度从0.773提高到0.957）。基于模式的方法生成更简洁、主题一致性更高的输出，而自然语言方法词汇多样性更高但可预测性较低。混合方法在两者之间取得了平衡。专家评估确认PILOT在所有条件下均保持了高质量的响应，且不同引导方法之间没有统计学上的显著差异。

Conclusion: PILOT框架通过结构化的心理语言学档案，能够更精确地控制生成式AI应用中的大型语言模型输出，解决了自然语言引导的局限性。基于模式的方法在提高输出质量和一致性方面表现优越，而混合方法可在多样性和一致性之间取得良好平衡。

Abstract: Generative AI applications commonly leverage user personas as a steering
mechanism for synthetic data generation, but reliance on natural language
representations forces models to make unintended inferences about which
attributes to emphasize, limiting precise control over outputs. We introduce
PILOT (Psychological and Linguistic Output Targeting), a two-phase framework
for steering large language models with structured psycholinguistic profiles.
In Phase 1, PILOT translates natural language persona descriptions into
multidimensional profiles with normalized scores across linguistic and
psychological dimensions. In Phase 2, these profiles guide generation along
measurable axes of variation. We evaluate PILOT across three state-of-the-art
LLMs (Mistral Large 2, Deepseek-R1, LLaMA 3.3 70B) using 25 synthetic personas
under three conditions: Natural-language Persona Steering (NPS), Schema-Based
Steering (SBS), and Hybrid Persona-Schema Steering (HPS). Results demonstrate
that schema-based approaches significantly reduce artificial-sounding persona
repetition while improving output coherence, with silhouette scores increasing
from 0.098 to 0.237 and topic purity from 0.773 to 0.957. Our analysis reveals
a fundamental trade-off: SBS produces more concise outputs with higher topical
consistency, while NPS offers greater lexical diversity but reduced
predictability. HPS achieves a balance between these extremes, maintaining
output variety while preserving structural consistency. Expert linguistic
evaluation confirms that PILOT maintains high response quality across all
conditions, with no statistically significant differences between steering
approaches.

</details>


### [123] [Evaluating Multimodal Large Language Models on Spoken Sarcasm Understanding](https://arxiv.org/abs/2509.15476)
*Zhu Li,Xiyuan Gao,Yuqing Zhang,Shekhar Nayak,Matt Coler*

Main category: cs.CL

TL;DR: LLMs and multimodal LLMs are evaluated for sarcasm detection across text, audio, and vision modalities in both English and Chinese, using zero-shot, few-shot, and fine-tuning methods. Audio-based models show strong unimodal performance, and text-audio and audio-vision combinations outperform others. Multimodal LLMs like Qwen-Omni demonstrate competitive performance, indicating their potential for cross-lingual, audio-visual-textual sarcasm understanding.


<details>
  <summary>Details</summary>
Motivation: Sarcasm detection is challenging due to reliance on subtle cross-modal cues (text, speech, vision). Prior work has focused on textual or visual-textual sarcasm, leaving comprehensive audio-visual-textual sarcasm understanding underexplored.

Method: Systematically evaluated LLMs and multimodal LLMs for sarcasm detection on English (MUStARD++) and Chinese (MCSD 1.0) datasets. Explored zero-shot, few-shot, and LoRA fine-tuning settings. Also investigated models as feature encoders, integrating representations via a collaborative gating fusion module.

Result: Audio-based models achieved the strongest unimodal performance. Text-audio and audio-vision combinations outperformed unimodal and trimodal models. Multimodal LLMs like Qwen-Omni showed competitive zero-shot and fine-tuned performance.

Conclusion: Findings highlight the potential of Multimodal LLMs for cross-lingual, audio-visual-textual sarcasm understanding.

Abstract: Sarcasm detection remains a challenge in natural language understanding, as
sarcastic intent often relies on subtle cross-modal cues spanning text, speech,
and vision. While prior work has primarily focused on textual or visual-textual
sarcasm, comprehensive audio-visual-textual sarcasm understanding remains
underexplored. In this paper, we systematically evaluate large language models
(LLMs) and multimodal LLMs for sarcasm detection on English (MUStARD++) and
Chinese (MCSD 1.0) in zero-shot, few-shot, and LoRA fine-tuning settings. In
addition to direct classification, we explore models as feature encoders,
integrating their representations through a collaborative gating fusion module.
Experimental results show that audio-based models achieve the strongest
unimodal performance, while text-audio and audio-vision combinations outperform
unimodal and trimodal models. Furthermore, MLLMs such as Qwen-Omni show
competitive zero-shot and fine-tuned performance. Our findings highlight the
potential of MLLMs for cross-lingual, audio-visual-textual sarcasm
understanding.

</details>


### [124] [Red Teaming Multimodal Language Models: Evaluating Harm Across Prompt Modalities and Models](https://arxiv.org/abs/2509.15478)
*Madison Van Doren,Casey Ford,Emily Dix*

Main category: cs.CL

TL;DR: 多模态大语言模型（MLLMs）在对抗性攻击下存在安全风险，Pixtral 12B 最易受攻击，Claude Sonnet 3.5 最具抵抗力，且纯文本提示比多模态提示更有效。


<details>
  <summary>Details</summary>
Motivation: 评估领先的多模态大语言模型（MLLMs）在面对文本和多模态对抗性提示时的安全性，以了解其在现实应用中的风险。

Method: 招募26名红队成员生成726个针对非法活动、虚假信息和不道德行为三类危害的提示，并提交给GPT-4o、Claude Sonnet 3.5、Pixtral 12B和Qwen VL Plus四个模型。随后，17名标注者对2904个模型输出进行评级，评估其有害程度。

Result: Pixtral 12B的有害响应率最高（约62%），Claude Sonnet 3.5的有害响应率最低（约10%）。纯文本提示比多模态提示略微更有效地绕过了安全机制。模型类型和输入模态都是预测有害性的显著因素。

Conclusion: 目前的MLLMs在面对对抗性提示时存在显著的安全漏洞，特别是Pixtral 12B。随着MLLMs的广泛部署，迫切需要开发稳健的多模态安全基准来应对这些挑战。

Abstract: Multimodal large language models (MLLMs) are increasingly used in real world
applications, yet their safety under adversarial conditions remains
underexplored. This study evaluates the harmlessness of four leading MLLMs
(GPT-4o, Claude Sonnet 3.5, Pixtral 12B, and Qwen VL Plus) when exposed to
adversarial prompts across text-only and multimodal formats. A team of 26 red
teamers generated 726 prompts targeting three harm categories: illegal
activity, disinformation, and unethical behaviour. These prompts were submitted
to each model, and 17 annotators rated 2,904 model outputs for harmfulness
using a 5-point scale. Results show significant differences in vulnerability
across models and modalities. Pixtral 12B exhibited the highest rate of harmful
responses (~62%), while Claude Sonnet 3.5 was the most resistant (~10%).
Contrary to expectations, text-only prompts were slightly more effective at
bypassing safety mechanisms than multimodal ones. Statistical analysis
confirmed that both model type and input modality were significant predictors
of harmfulness. These findings underscore the urgent need for robust,
multimodal safety benchmarks as MLLMs are deployed more widely.

</details>


### [125] [mucAI at BAREC Shared Task 2025: Towards Uncertainty Aware Arabic Readability Assessment](https://arxiv.org/abs/2509.15485)
*Ahmed Abdou*

Main category: cs.CL

TL;DR: 提出一种模型无关的后处理技术，使用共形预测生成具有覆盖率保证的预测集，并通过在共形集上使用 softmax 重新归一化的概率进行加权平均，以提高细粒度阿拉伯语可读性分类的 QWK 分数。


<details>
  <summary>Details</summary>
Motivation: 提高细粒度阿拉伯语可读性分类的性能，特别是在 BAREC 2025 共享任务的 19 个序数级别上。

Method: 应用共形预测生成具有覆盖率保证的预测集，然后计算 softmax 重新归一化概率在共形集上的加权平均值。

Result: 在不同的基础模型上，QWK 分数一致提高了 1-3 分。在严格的跟踪任务中，句子级别的 QWK 分数（测试）为 84.9%，（盲测）为 85.7%，文档级别的 QWK 分数为 73.3%。

Conclusion: 该方法通过减少高罚分误分类到较近的级别，提高了 QWK 分数，结合了统计保证和实际可用性，使人类审阅者能够专注于少数几个合理的级别，适用于阿拉伯语的教育评估。

Abstract: We present a simple, model-agnostic post-processing technique for
fine-grained Arabic readability classification in the BAREC 2025 Shared Task
(19 ordinal levels). Our method applies conformal prediction to generate
prediction sets with coverage guarantees, then computes weighted averages using
softmax-renormalized probabilities over the conformal sets. This
uncertainty-aware decoding improves Quadratic Weighted Kappa (QWK) by reducing
high-penalty misclassifications to nearer levels. Our approach shows consistent
QWK improvements of 1-3 points across different base models. In the strict
track, our submission achieves QWK scores of 84.9\%(test) and 85.7\% (blind
test) for sentence level, and 73.3\% for document level. For Arabic educational
assessment, this enables human reviewers to focus on a handful of plausible
levels, combining statistical guarantees with practical usability.

</details>


### [126] [LLM Cache Bandit Revisited: Addressing Query Heterogeneity for Cost-Effective LLM Inference](https://arxiv.org/abs/2509.15515)
*Hantao Yang,Hong Xie,Defu Lian,Enhong Chen*

Main category: cs.CL

TL;DR: 本研究解决了LLM缓存中的查询异构性问题，并将缓存选择视为一个背包问题，提出了一种基于累积的策略，该策略将算法的遗憾界限提高到 O(sqrt(MNT))，并通过实验证明可降低约 12% 的总成本。


<details>
  <summary>Details</summary>
Motivation: 解决LLM推理成本效益问题，特别是处理查询大小异构性对缓存选择的挑战。

Method: 将最优缓存选择视为背包问题，并采用基于累积的策略来平衡计算开销和缓存更新。

Result: 理论上证明了算法的遗憾界限为 O(sqrt(MNT))，优于先前 O(MN*sqrt(T)) 的结果，并提供了一个先前缺失的依赖于问题的界限。实验表明，该算法可将总成本降低约 12%。

Conclusion: 所提出的基于累积的策略能够有效地处理LLM缓存中的查询异构性问题，并在理论和实践上都优于现有方法。

Abstract: This paper revisits the LLM cache bandit problem, with a special focus on
addressing the query heterogeneity for cost-effective LLM inference. Previous
works often assume uniform query sizes. Heterogeneous query sizes introduce a
combinatorial structure for cache selection, making the cache replacement
process more computationally and statistically challenging. We treat optimal
cache selection as a knapsack problem and employ an accumulation-based strategy
to effectively balance computational overhead and cache updates. In theoretical
analysis, we prove that the regret of our algorithm achieves an $O(\sqrt{MNT})$
bound, improving the coefficient of $\sqrt{MN}$ compared to the $O(MN\sqrt{T})$
result in Berkeley, where $N$ is the total number of queries and $M$ is the
cache size. Additionally, we also provide a problem-dependent bound, which was
absent in previous works. The experiment rely on real-world data show that our
algorithm reduces the total cost by approximately 12\%.

</details>


### [127] [How do Language Models Generate Slang: A Systematic Comparison between Human and Machine-Generated Slang Usages](https://arxiv.org/abs/2509.15518)
*Siyang Wu,Zhewei Sun*

Main category: cs.CL

TL;DR: 大型语言模型（LLM）在处理俚语方面存在偏见，尽管它们能够生成有创意的俚语，但其知识与人类的理解不完全一致，这限制了它们在语言学分析等外推任务中的应用。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）在理解和生成俚语方面的能力，特别是它们的泛化性和可靠性，以及它们所捕获的结构化俚语知识是否与人类的用法一致。

Method: 通过比较人类和机器生成的俚语用法，重点关注三个核心方面：1）反映机器对俚语系统性偏见的特征；2）词汇创造和词语重用所体现的创造力；3）作为模型蒸馏的黄金标准示例时的信息量。使用来自在线俚语词典（OSD）的人类俚语用法，并与GPT-4o和Llama-3生成的俚语进行比较。

Result: 研究发现，LLM在感知俚语方面存在显著偏见。虽然LLM在俚语的创造性方面捕获了重要知识，但这种知识与人类的理解不完全一致，限制了LLM在外推任务（如语言学分析）中的应用。

Conclusion: 大型语言模型（LLM）在俚语的创造性方面表现良好，但其对俚语的理解与人类存在差异，无法满足在语言学分析等需要精确对齐的复杂任务中的应用需求。

Abstract: Slang is a commonly used type of informal language that poses a daunting
challenge to NLP systems. Recent advances in large language models (LLMs),
however, have made the problem more approachable. While LLM agents are becoming
more widely applied to intermediary tasks such as slang detection and slang
interpretation, their generalizability and reliability are heavily dependent on
whether these models have captured structural knowledge about slang that align
well with human attested slang usages. To answer this question, we contribute a
systematic comparison between human and machine-generated slang usages. Our
evaluative framework focuses on three core aspects: 1) Characteristics of the
usages that reflect systematic biases in how machines perceive slang, 2)
Creativity reflected by both lexical coinages and word reuses employed by the
slang usages, and 3) Informativeness of the slang usages when used as
gold-standard examples for model distillation. By comparing human-attested
slang usages from the Online Slang Dictionary (OSD) and slang generated by
GPT-4o and Llama-3, we find significant biases in how LLMs perceive slang. Our
results suggest that while LLMs have captured significant knowledge about the
creative aspects of slang, such knowledge does not align with humans
sufficiently to enable LLMs for extrapolative tasks such as linguistic
analyses.

</details>


### [128] [A method for improving multilingual quality and diversity of instruction fine-tuning datasets](https://arxiv.org/abs/2509.15549)
*Chunguang Zhao,Yilun Liu,Pufan Zeng,Yuanchang Luo,Shimin Tao,Minggui He,Weibin Meng,Song Xu,Ziang Chen,Chen Liu,Hongxia Ma,Li Zhang,Boxing Chen,Daimeng Wei*

Main category: cs.CL

TL;DR: M-DaQ是一种新的多语言指令微调方法，通过选择高质量、语义多样化的样本，显著提高了大型语言模型在18种语言上的性能，并在人类评估中得到验证。


<details>
  <summary>Details</summary>
Motivation: 现有的多语言指令微调方法在数据选择方面存在不足，难以跨语言推广，而高质量多语言数据的缺乏是关键瓶颈。

Method: 提出了一种名为M-DaQ（Multilingual Data Quality and Diversity）的新方法，用于选择高质量、语义多样化的多语言指令微调样本。首次在多语言环境下系统地研究了表面对齐假设（SAH）。

Result: 在18种语言的实证结果表明，使用M-DaQ方法微调的模型比传统基线模型有显著的性能提升，获胜率超过60%。人类评估也验证了这些提升，特别是文化相关性的提高。

Conclusion: M-DaQ方法能够有效提升大型语言模型的多语言能力，并在跨语言数据选择方面取得了重要进展。

Abstract: Multilingual Instruction Fine-Tuning (IFT) is essential for enabling large
language models (LLMs) to generalize effectively across diverse linguistic and
cultural contexts. However, the scarcity of high-quality multilingual training
data and corresponding building method remains a critical bottleneck. While
data selection has shown promise in English settings, existing methods often
fail to generalize across languages due to reliance on simplistic heuristics or
language-specific assumptions. In this work, we introduce Multilingual Data
Quality and Diversity (M-DaQ), a novel method for improving LLMs
multilinguality, by selecting high-quality and semantically diverse
multilingual IFT samples. We further conduct the first systematic investigation
of the Superficial Alignment Hypothesis (SAH) in multilingual setting.
Empirical results across 18 languages demonstrate that models fine-tuned with
M-DaQ method achieve significant performance gains over vanilla baselines over
60% win rate. Human evaluations further validate these gains, highlighting the
increment of cultural points in the response. We release the M-DaQ code to
support future research.

</details>


### [129] [DNA-DetectLLM: Unveiling AI-Generated Text via a DNA-Inspired Mutation-Repair Paradigm](https://arxiv.org/abs/2509.15550)
*Xiaowei Zhu,Yubing Ren,Fang Fang,Qingfeng Tan,Shi Wang,Yanan Cao*

Main category: cs.CL

TL;DR: DNA-DetectLLM是一种零样本检测方法，利用DNA修复的类比来区分人类写作和AI生成文本，在准确性和鲁棒性方面均达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的快速发展模糊了AI生成文本和人类写作文本之间的界限，带来了错误信息、作者身份模糊和知识产权等社会风险，因此迫切需要可靠的AI生成文本检测方法。然而，生成语言模型的最新进展导致人类写作和AI生成文本的特征分布显著重叠，使得准确检测更具挑战性。

Method: 提出一种受DNA启发的修复方法，直接且可解释地捕捉人类写作和AI生成文本之间的内在差异。具体而言，DNA-DetectLLM为每个输入构建一个理想的AI生成序列，然后迭代地修复非最优的标记，最后将累积的修复量量化为一个可解释的检测信号。

Result: DNA-DetectLLM在多个公共基准数据集上实现了最先进的检测性能，在AUROC方面相对提高了5.55%，在F1分数方面相对提高了2.08%，并且表现出对各种对抗性攻击和不同输入长度的强大鲁棒性。

Conclusion: DNA-DetectLLM通过一种新颖的、受DNA启发的修复方法，有效地解决了AI生成文本检测的挑战，并在准确性和鲁棒性方面取得了显著成果。

Abstract: The rapid advancement of large language models (LLMs) has blurred the line
between AI-generated and human-written text. This progress brings societal
risks such as misinformation, authorship ambiguity, and intellectual property
concerns, highlighting the urgent need for reliable AI-generated text detection
methods. However, recent advances in generative language modeling have resulted
in significant overlap between the feature distributions of human-written and
AI-generated text, blurring classification boundaries and making accurate
detection increasingly challenging. To address the above challenges, we propose
a DNA-inspired perspective, leveraging a repair-based process to directly and
interpretably capture the intrinsic differences between human-written and
AI-generated text. Building on this perspective, we introduce DNA-DetectLLM, a
zero-shot detection method for distinguishing AI-generated and human-written
text. The method constructs an ideal AI-generated sequence for each input,
iteratively repairs non-optimal tokens, and quantifies the cumulative repair
effort as an interpretable detection signal. Empirical evaluations demonstrate
that our method achieves state-of-the-art detection performance and exhibits
strong robustness against various adversarial attacks and input lengths.
Specifically, DNA-DetectLLM achieves relative improvements of 5.55% in AUROC
and 2.08% in F1 score across multiple public benchmark datasets.

</details>


### [130] [Exploring Polyglot Harmony: On Multilingual Data Allocation for Large Language Models Pretraining](https://arxiv.org/abs/2509.15556)
*Ping Guo,Yubing Ren,Binbin Liu,Fengze Liu,Haobin Lin,Yifan Zhang,Bingni Zhang,Taifeng Wang,Yin Zheng*

Main category: cs.CL

TL;DR: Climb框架通过考虑跨语言交互来优化多语言LLM的训练数据语言比例，以提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在多语言能力方面需求巨大，但确定最佳语言比例具有挑战性，因为存在复杂的跨语言交互和对数据集规模的敏感性。

Method: 提出了一种名为Climb（跨语言交互感知多语言平衡）的新框架，该框架引入了跨语言交互感知的语言比例，量化了每种语言的有效分配，并通过两步优化程序（首先均衡各语言的边际收益，然后最大化所得语言分配向量的幅度）来优化。

Result: Climb框架能够准确测量不同多语言环境下的跨语言交互。使用Climb优化比例训练的LLM在多语言性能方面达到了最先进的水平，并且在与使用更多数据训练的开源LLM相比时，仍具有竞争力。

Conclusion: Climb框架通过优化多语言数据分配，显著提高了LLM的多语言性能，并简化了优化过程。

Abstract: Large language models (LLMs) have become integral to a wide range of
applications worldwide, driving an unprecedented global demand for effective
multilingual capabilities. Central to achieving robust multilingual performance
is the strategic allocation of language proportions within training corpora.
However, determining optimal language ratios is highly challenging due to
intricate cross-lingual interactions and sensitivity to dataset scale. This
paper introduces Climb (Cross-Lingual Interaction-aware Multilingual
Balancing), a novel framework designed to systematically optimize multilingual
data allocation. At its core, Climb introduces a cross-lingual
interaction-aware language ratio, explicitly quantifying each language's
effective allocation by capturing inter-language dependencies. Leveraging this
ratio, Climb proposes a principled two-step optimization procedure--first
equalizing marginal benefits across languages, then maximizing the magnitude of
the resulting language allocation vectors--significantly simplifying the
inherently complex multilingual optimization problem. Extensive experiments
confirm that Climb can accurately measure cross-lingual interactions across
various multilingual settings. LLMs trained with Climb-derived proportions
consistently achieve state-of-the-art multilingual performance, even achieving
competitive performance with open-sourced LLMs trained with more tokens.

</details>


### [131] [How important is language for human-like intelligence?](https://arxiv.org/abs/2509.15560)
*Gary Lupyan,Hunter Gentry,Martin Zettersten*

Main category: cs.CL

TL;DR: Language is crucial for both human and artificial general intelligence because it provides compact representations of abstract concepts and embodies collectively evolved knowledge.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the long-standing question of whether language merely expresses pre-existing thoughts or actively shapes cognition, arguing for the latter and its importance for AI and human intelligence.

Method: The paper argues that language's two key properties—compact representations for abstract concepts and its nature as an output of collective minds—enable the development of general abilities.

Result: Language allows learning systems (biological or artificial) to acquire compressed world models, thereby reverse-engineering the conceptual and causal structures underlying human-like thought.

Conclusion: Language plays a transformative role in cognition, enabling the emergence of general intelligence in both humans and AI by providing compressed representations and access to evolved cultural abstractions.

Abstract: We use language to communicate our thoughts. But is language merely the
expression of thoughts, which are themselves produced by other, nonlinguistic
parts of our minds? Or does language play a more transformative role in human
cognition, allowing us to have thoughts that we otherwise could (or would) not
have? Recent developments in artificial intelligence (AI) and cognitive science
have reinvigorated this old question. We argue that language may hold the key
to the emergence of both more general AI systems and central aspects of human
intelligence. We highlight two related properties of language that make it such
a powerful tool for developing domain--general abilities. First, language
offers compact representations that make it easier to represent and reason
about many abstract concepts (e.g., exact numerosity). Second, these compressed
representations are the iterated output of collective minds. In learning a
language, we learn a treasure trove of culturally evolved abstractions. Taken
together, these properties mean that a sufficiently powerful learning system
exposed to language--whether biological or artificial--learns a compressed
model of the world, reverse engineering many of the conceptual and causal
structures that support human (and human-like) thought.

</details>


### [132] [LiteLong: Resource-Efficient Long-Context Data Synthesis for LLMs](https://arxiv.org/abs/2509.15568)
*Junlong Jia,Xing Wu,Chaochen Gao,Ziyang Chen,Zijia Lin,Zhongzhi Li,Weinong Wang,Haotian Xu,Donghui Jin,Debing Zhang,Binghui Guo*

Main category: cs.CL

TL;DR: LiteLong是一种通过结构化主题组织和多主体辩论来合成长上下文数据的资源高效方法，解决了现有合成方法的计算效率问题。


<details>
  <summary>Details</summary>
Motivation: 现有使用基于相关性的聚合来合成高质量长上下文数据的模型在计算效率方面存在挑战，而高质量的长上下文数据对于训练能够处理大量文档的大型语言模型至关重要。

Method: LiteLong利用BISAC图书分类系统提供全面的分层主题组织，然后采用多LLM的辩论机制在此结构内生成多样化、高质量的主题。对于每个主题，使用轻量级的BM25检索相关文档，并将它们连接成128K个token的训练样本。

Result: 在HELMET和Ruler基准测试上的实验表明，LiteLong在长上下文性能上具有竞争力，并且可以与其他长依赖增强方法无缝集成。

Conclusion: LiteLong通过降低计算和数据工程成本，使高质量长上下文数据合成更加容易，从而促进长上下文语言训练的进一步研究。

Abstract: High-quality long-context data is essential for training large language
models (LLMs) capable of processing extensive documents, yet existing synthesis
approaches using relevance-based aggregation face challenges of computational
efficiency. We present LiteLong, a resource-efficient method for synthesizing
long-context data through structured topic organization and multi-agent debate.
Our approach leverages the BISAC book classification system to provide a
comprehensive hierarchical topic organization, and then employs a debate
mechanism with multiple LLMs to generate diverse, high-quality topics within
this structure. For each topic, we use lightweight BM25 retrieval to obtain
relevant documents and concatenate them into 128K-token training samples.
Experiments on HELMET and Ruler benchmarks demonstrate that LiteLong achieves
competitive long-context performance and can seamlessly integrate with other
long-dependency enhancement methods. LiteLong makes high-quality long-context
data synthesis more accessible by reducing both computational and data
engineering costs, facilitating further research in long-context language
training.

</details>


### [133] [Relevance to Utility: Process-Supervised Rewrite for RAG](https://arxiv.org/abs/2509.15577)
*Jaeyoung Kim,Jongho Kim,Seung-won Hwang,Seoho Song,Young-In Song*

Main category: cs.CL

TL;DR: R2U通过过程监督直接优化生成正确答案的概率，弥补了检索相关性和生成效用之间的差距。


<details>
  <summary>Details</summary>
Motivation: 现有的“桥梁”模块未能有效解决检索到的文档在生成过程中有效推理所需的内容缺失问题。

Method: 提出R2U，通过过程监督直接优化生成正确答案的概率，并提出一种通过LLM进行蒸馏来近似高效监督的方法。

Result: 在多个开放域问答基准测试中，R2U的性能持续优于强大的桥梁基线。

Conclusion: R2U通过直接优化生成效用，在开放域问答方面取得了显著的改进。

Abstract: Retrieval-Augmented Generation systems often suffer from a gap between
optimizing retrieval relevance and generative utility: retrieved documents may
be topically relevant but still lack the content needed for effective reasoning
during generation. While existing "bridge" modules attempt to rewrite the
retrieved text for better generation, we show how they fail to capture true
document utility. In this work, we propose R2U, with a key distinction of
directly optimizing to maximize the probability of generating a correct answer
through process supervision. As such direct observation is expensive, we also
propose approximating an efficient distillation pipeline by scaling the
supervision from LLMs, which helps the smaller rewriter model generalize
better. We evaluate our method across multiple open-domain question-answering
benchmarks. The empirical results demonstrate consistent improvements over
strong bridging baselines.

</details>


### [134] [Chunk Based Speech Pre-training with High Resolution Finite Scalar Quantization](https://arxiv.org/abs/2509.15579)
*Yun Tang,Cindy Tseng*

Main category: cs.CL

TL;DR: 本研究提出了一种名为Chunk SSL的基于块的自监督学习算法，用于解决流式和离线语音预训练中的部分语音输入问题，并通过实验证明了其在语音识别和语音翻译任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 低延迟语音人机通信的需求日益增长，但现有的自监督学习算法在处理流式应用中的部分语音输入时存在不足。

Method: 提出Chunk SSL算法，采用掩码预测损失，并结合先前块的信息来恢复被掩码的语音帧。同时，提出了一种复制和追加的数据增强方法，并使用高分辨率的有限标量量化（FSQ）模块离散化语音特征，通过组掩码预测损失来降低大词汇量带来的计算成本。

Result: 在语音识别和语音翻译任务中，Chunk SSL在流式和离线模式下均取得了具有竞争力的结果，特别是在Librispeech和Must-C数据集上。

Conclusion: Chunk SSL是一种有效的统一解决方案，能够同时处理流式和离线语音预训练，并在下游任务中取得优异表现。

Abstract: Low latency speech human-machine communication is becoming increasingly
necessary as speech technology advances quickly in the last decade. One of the
primary factors behind the advancement of speech technology is self-supervised
learning. Most self-supervised learning algorithms are designed with full
utterance assumption and compromises have to made if partial utterances are
presented, which are common in the streaming applications. In this work, we
propose a chunk based self-supervised learning (Chunk SSL) algorithm as an
unified solution for both streaming and offline speech pre-training. Chunk SSL
is optimized with the masked prediction loss and an acoustic encoder is
encouraged to restore indices of those masked speech frames with help from
unmasked frames in the same chunk and preceding chunks. A copy and append data
augmentation approach is proposed to conduct efficient chunk based
pre-training. Chunk SSL utilizes a finite scalar quantization (FSQ) module to
discretize input speech features and our study shows a high resolution FSQ
codebook, i.e., a codebook with vocabulary size up to a few millions, is
beneficial to transfer knowledge from the pre-training task to the downstream
tasks. A group masked prediction loss is employed during pre-training to
alleviate the high memory and computation cost introduced by the large
codebook. The proposed approach is examined in two speech to text tasks, i.e.,
speech recognition and speech translation. Experimental results on the
\textsc{Librispeech} and \textsc{Must-C} datasets show that the proposed method
could achieve very competitive results for speech to text tasks at both
streaming and offline modes.

</details>


### [135] [DivLogicEval: A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models](https://arxiv.org/abs/2509.15587)
*Tsz Ting Chung,Lemao Liu,Mo Yu,Dit-Yan Yeung*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Logic reasoning in natural language has been recognized as an important
measure of human intelligence for Large Language Models (LLMs). Popular
benchmarks may entangle multiple reasoning skills and thus provide unfaithful
evaluations on the logic reasoning skill. Meanwhile, existing logic reasoning
benchmarks are limited in language diversity and their distributions are
deviated from the distribution of an ideal logic reasoning benchmark, which may
lead to biased evaluation results. This paper thereby proposes a new classical
logic benchmark DivLogicEval, consisting of natural sentences composed of
diverse statements in a counterintuitive way. To ensure a more reliable
evaluation, we also introduce a new evaluation metric that mitigates the
influence of bias and randomness inherent in LLMs. Through experiments, we
demonstrate the extent to which logical reasoning is required to answer the
questions in DivLogicEval and compare the performance of different popular LLMs
in conducting logical reasoning.

</details>


### [136] [SciEvent: Benchmarking Multi-domain Scientific Event Extraction](https://arxiv.org/abs/2509.15620)
*Bofu Dong,Pritesh Shah,Sumedh Sonawane,Tiyasha Banerjee,Erin Brady,Xinya Du,Ming Jiang*

Main category: cs.CL

TL;DR: 该研究提出了一个名为SciEvent的新型跨领域科学信息抽取基准，旨在解决现有方法在处理跨学科研究和理解上下文信息方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖于狭窄领域的实体关系抽取，难以处理跨学科研究和捕捉科学信息的必要上下文，导致信息碎片化或冲突。

Method: 提出SciEvent基准，包含5个领域共500篇科学摘要，通过统一的事件抽取（EE）模式进行标注，包括事件片段、触发词和细粒度论元。将SciIE定义为多阶段EE流程：1.将摘要分为背景、方法、结果和结论；2.抽取相应的触发词和论元。

Result: 通过对EE模型、LLM和人工标注者进行实验，发现当前模型在社会学和人文学科等领域存在性能差距。

Conclusion: SciEvent是一个具有挑战性的基准，推动了可泛化、跨领域的科学信息抽取（SciIE）的发展。

Abstract: Scientific information extraction (SciIE) has primarily relied on
entity-relation extraction in narrow domains, limiting its applicability to
interdisciplinary research and struggling to capture the necessary context of
scientific information, often resulting in fragmented or conflicting
statements. In this paper, we introduce SciEvent, a novel multi-domain
benchmark of scientific abstracts annotated via a unified event extraction (EE)
schema designed to enable structured and context-aware understanding of
scientific content. It includes 500 abstracts across five research domains,
with manual annotations of event segments, triggers, and fine-grained
arguments. We define SciIE as a multi-stage EE pipeline: (1) segmenting
abstracts into core scientific activities--Background, Method, Result, and
Conclusion; and (2) extracting the corresponding triggers and arguments.
Experiments with fine-tuned EE models, large language models (LLMs), and human
annotators reveal a performance gap, with current models struggling in domains
such as sociology and humanities. SciEvent serves as a challenging benchmark
and a step toward generalizable, multi-domain SciIE.

</details>


### [137] [Concept Unlearning in Large Language Models via Self-Constructed Knowledge Triplets](https://arxiv.org/abs/2509.15621)
*Tomoya Yamashita,Yuuki Yamanaka,Masanori Yamada,Takayuki Miura,Toshiki Shibahara,Tomoharu Iwata*

Main category: cs.CL

TL;DR: 概念性机器遗忘（CU）是机器遗忘（MU）的一个新领域，旨在从大型语言模型（LLM）中删除特定概念，而不是特定的句子。通过利用知识图谱来表示LLM的内部知识，CU将概念删除定义为移除目标节点及其相关边。提出了一种新方法，通过提示LLM生成关于遗忘目标的知识三元组和解释性句子，并将遗忘过程应用于这些表示，以实现更精确的概念删除。


<details>
  <summary>Details</summary>
Motivation: 现有的机器遗忘（MU）方法需要明确的目标句子，不支持删除个人或事件等更广泛的概念。因此，需要一种新的方法来满足概念删除的需求。

Method: 利用知识图谱表示LLM的内部知识，将概念遗忘（CU）定义为移除遗忘目标节点及其相关边。提出一种新方法，提示LLM生成关于遗忘目标的知识三元组和解释性句子，并将遗忘过程应用于这些表示。

Result: 实验表明，该方法有效地实现了概念级遗忘，同时保留了不相关的知识。

Conclusion: 概念性遗忘（CU）是机器遗忘（MU）的一个新领域，它通过利用知识图谱和LLM的内部知识表示，实现了比传统MU方法更精确、更全面的概念删除。

Abstract: Machine Unlearning (MU) has recently attracted considerable attention as a
solution to privacy and copyright issues in large language models (LLMs).
Existing MU methods aim to remove specific target sentences from an LLM while
minimizing damage to unrelated knowledge. However, these approaches require
explicit target sentences and do not support removing broader concepts, such as
persons or events. To address this limitation, we introduce Concept Unlearning
(CU) as a new requirement for LLM unlearning. We leverage knowledge graphs to
represent the LLM's internal knowledge and define CU as removing the forgetting
target nodes and associated edges. This graph-based formulation enables a more
intuitive unlearning and facilitates the design of more effective methods. We
propose a novel method that prompts the LLM to generate knowledge triplets and
explanatory sentences about the forgetting target and applies the unlearning
process to these representations. Our approach enables more precise and
comprehensive concept removal by aligning the unlearning process with the LLM's
internal knowledge representations. Experiments on real-world and synthetic
datasets demonstrate that our method effectively achieves concept-level
unlearning while preserving unrelated knowledge.

</details>


### [138] [Sparse-Autoencoder-Guided Internal Representation Unlearning for Large Language Models](https://arxiv.org/abs/2509.15631)
*Tomoya Yamashita,Akira Ito,Yuuki Yamanaka,Masanori Yamada,Takayuki Miura,Toshiki Shibahara*

Main category: cs.CL

TL;DR: LLM 遗忘技术旨在通过干预模型内部激活来真正实现遗忘，而非仅仅抑制输出，从而解决现有方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 遗忘方法（如梯度上升）通过抑制输出来防止生成不希望的内容，但这可能无法消除模型内部的知识，并且可能导致模型崩溃。需要一种直接干预模型内部激活的方法来实现真正的遗忘。

Method: 提出一种新的遗忘方法，将遗忘定义为目标激活与“未知”实体激活无法区分。该方法通过在稀疏自编码器潜在空间中修改目标激活，使其从“已知”实体移向“未知”实体。

Result: 该方法成功地将遗忘目标的内部激活与未知实体对齐，而抑制类方法无法可靠地做到这一点。此外，该方法在问答任务中有效降低了模型对遗忘知识的记忆，且对非遗忘知识的损害不大。

Conclusion: 提出的基于激活的方法通过将目标激活与未知实体对齐，实现了真正的遗忘，避免了过度抑制和模型崩溃，并在不损害模型其他知识的情况下有效减少了对目标知识的回忆。

Abstract: As large language models (LLMs) are increasingly deployed across various
applications, privacy and copyright concerns have heightened the need for more
effective LLM unlearning techniques. Many existing unlearning methods aim to
suppress undesirable outputs through additional training (e.g., gradient
ascent), which reduces the probability of generating such outputs. While such
suppression-based approaches can control model outputs, they may not eliminate
the underlying knowledge embedded in the model's internal activations; muting a
response is not the same as forgetting it. Moreover, such suppression-based
methods often suffer from model collapse. To address these issues, we propose a
novel unlearning method that directly intervenes in the model's internal
activations. In our formulation, forgetting is defined as a state in which the
activation of a forgotten target is indistinguishable from that of ``unknown''
entities. Our method introduces an unlearning objective that modifies the
activation of the target entity away from those of known entities and toward
those of unknown entities in a sparse autoencoder latent space. By aligning the
target's internal activation with those of unknown entities, we shift the
model's recognition of the target entity from ``known'' to ``unknown'',
achieving genuine forgetting while avoiding over-suppression and model
collapse. Empirically, we show that our method effectively aligns the internal
activations of the forgotten target, a result that the suppression-based
approaches do not reliably achieve. Additionally, our method effectively
reduces the model's recall of target knowledge in question-answering tasks
without significant damage to the non-target knowledge.

</details>


### [139] [Multilingual LLM Prompting Strategies for Medical English-Vietnamese Machine Translation](https://arxiv.org/abs/2509.15640)
*Nhu Vo,Nu-Uyen-Phuong Le,Dung D. Le,Massimo Piccardi,Wray Buntine*

Main category: cs.CL

TL;DR: 多语言大语言模型(LLM)在医学英越机器翻译(En-Vi MT)方面表现出潜力，但模型规模是关键因素，而术语感知提示能进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 越南医疗领域缺乏低资源和研究不足的越南语机器翻译工具，需要改进医学英语-越南语互译能力。

Method: 系统评估了六种不同规模(0.5B-9B参数)的多语言大语言模型在MedEV数据集上的零样本、少样本和字典增强提示策略，并使用了英越医学词典Meddict。

Result: 模型规模是影响翻译性能的主要因素，较大的LLM在零样本设置下表现出色。少样本提示的改进有限。然而，结合术语提示和基于嵌入的示例检索能够持续提升领域特定的翻译效果。

Conclusion: 多语言大语言模型在医学英越机器翻译方面展现了巨大潜力，但目前仍受限于模型规模和需要针对性地引入医学术语知识来进一步优化翻译质量。

Abstract: Medical English-Vietnamese machine translation (En-Vi MT) is essential for
healthcare access and communication in Vietnam, yet Vietnamese remains a
low-resource and under-studied language. We systematically evaluate prompting
strategies for six multilingual LLMs (0.5B-9B parameters) on the MedEV dataset,
comparing zero-shot, few-shot, and dictionary-augmented prompting with Meddict,
an English-Vietnamese medical lexicon. Results show that model scale is the
primary driver of performance: larger LLMs achieve strong zero-shot results,
while few-shot prompting yields only marginal improvements. In contrast,
terminology-aware cues and embedding-based example retrieval consistently
improve domain-specific translation. These findings underscore both the promise
and the current limitations of multilingual LLMs for medical En-Vi MT.

</details>


### [140] [Layer-wise Minimal Pair Probing Reveals Contextual Grammatical-Conceptual Hierarchy in Speech Representations](https://arxiv.org/abs/2509.15655)
*Linyang He,Qiaolin Wang,Xilin Jiang,Nima Mesgarani*

Main category: cs.CL

TL;DR: Transformer-based speech language models (SLMs)在编码语法特征方面比概念特征更鲁棒，尽管它们在语音识别和理解方面取得了显著进步，但它们编码细微句法和概念特征的程度尚不清楚。


<details>
  <summary>Details</summary>
Motivation: 评估Transformer-based speech language models (SLMs)在编码句法和概念特征方面的能力，类比大型语言模型（LLMs）的语言能力评估。

Method: 使用最小配对设计和诊断特征分析，跨越71个任务，进行层级和时间分辨分析，评估S3M、ASR、codec和AudioLLMs中的SLMs。

Result: 所有评估的SLMs在编码语法特征方面比概念特征更鲁棒。

Conclusion: Transformer-based SLMs能更可靠地编码句法特征而非概念特征。

Abstract: Transformer-based speech language models (SLMs) have significantly improved
neural speech recognition and understanding. While existing research has
examined how well SLMs encode shallow acoustic and phonetic features, the
extent to which SLMs encode nuanced syntactic and conceptual features remains
unclear. By drawing parallels with linguistic competence assessments for large
language models, this study is the first to systematically evaluate the
presence of contextual syntactic and semantic features across SLMs for
self-supervised learning (S3M), automatic speech recognition (ASR), speech
compression (codec), and as the encoder for auditory large language models
(AudioLLMs). Through minimal pair designs and diagnostic feature analysis
across 71 tasks spanning diverse linguistic levels, our layer-wise and
time-resolved analysis uncovers that 1) all speech encode grammatical features
more robustly than conceptual ones.

</details>


### [141] [VOX-KRIKRI: Unifying Speech and Language through Continuous Fusion](https://arxiv.org/abs/2509.15667)
*Dimitrios Damianos,Leon Voukoutis,Georgios Paraskevopoulos,Vassilis Katsouros*

Main category: cs.CL

TL;DR: 我们提出了一个多模态融合框架，连接预训练的基于解码器的LLM和声学编码器-解码器架构（如Whisper），以构建支持语音的LLM。该框架不直接使用音频嵌入，而是探索使用中间的音频条件文本空间进行更有效的对齐。它在连续文本表示空间中运行，通过交叉注意力融合Whisper的隐藏解码器状态和LLM的状态，并支持离线和流式模式。我们还介绍了希腊语的第一个语音LLM——VoxKrikri。


<details>
  <summary>Details</summary>
Motivation: 构建支持语音的LLM，并探索在预训练的LLM和声学模型之间进行有效对齐的方法。

Method: 使用多模态融合框架，通过交叉注意力融合Whisper的隐藏解码器状态和LLM的状态，在连续文本表示空间中进行操作，支持离线和流式模式。

Result: 成功构建了希腊语的第一个语音LLM（VoxKrikri），在希腊语自动语音识别基准测试中实现了平均约20%的相对改进，达到了最先进的水平。

Conclusion: 连续空间融合是构建多语言和低资源语音LLM的一个有前景的方向。

Abstract: We present a multimodal fusion framework that bridges pre-trained
decoder-based large language models (LLM) and acoustic encoder-decoder
architectures such as Whisper, with the aim of building speech-enabled LLMs.
Instead of directly using audio embeddings, we explore an intermediate
audio-conditioned text space as a more effective mechanism for alignment. Our
method operates fully in continuous text representation spaces, fusing
Whisper's hidden decoder states with those of an LLM through cross-modal
attention, and supports both offline and streaming modes. We introduce
\textit{VoxKrikri}, the first Greek speech LLM, and show through analysis that
our approach effectively aligns representations across modalities. These
results highlight continuous space fusion as a promising path for multilingual
and low-resource speech LLMs, while achieving state-of-the-art results for
Automatic Speech Recognition in Greek, providing an average $\sim20\%$ relative
improvement across benchmarks.

</details>


### [142] [Fine-Tuning Large Multimodal Models for Automatic Pronunciation Assessment](https://arxiv.org/abs/2509.15701)
*Ke Wang,Wenning Wei,Yan Deng,Lei He,Sheng Zhao*

Main category: cs.CL

TL;DR: 本研究探索了微调大型多模态模型（LMM）在自动发音评估（APA）中的应用，并在细粒度评估方面取得了有竞争力的结果，但指出在音素级别评估方面仍存在挑战，并建议使用Spearman等级相关系数（SCC）来评估序数一致性。


<details>
  <summary>Details</summary>
Motivation: 自动发音评估（APA）对于计算机辅助语言学习（CALL）至关重要，需要跨多个粒度和方面进行评估。大型多模态模型（LMM）为APA提供了新的机会，但其在细粒度评估方面的有效性仍不确定。

Method: 使用Speechocean762数据集和私有语料库对LMM进行微调，以进行APA评估。

Result: 微调显著优于零样本设置，并在单词和句子级别上取得了有竞争力的结果。在音素级别上，评估仍然具有挑战性。Pearson相关系数（PCC）达到0.9，而Spearman等级相关系数（SCC）保持在0.6左右，表明SCC能更好地反映序数一致性。

Conclusion: LMM在APA方面既有潜力也存在局限性。未来的工作应侧重于细粒度建模和面向排名的评估。

Abstract: Automatic Pronunciation Assessment (APA) is critical for Computer-Assisted
Language Learning (CALL), requiring evaluation across multiple granularities
and aspects. Large Multimodal Models (LMMs) present new opportunities for APA,
but their effectiveness in fine-grained assessment remains uncertain. This work
investigates fine-tuning LMMs for APA using the Speechocean762 dataset and a
private corpus. Fine-tuning significantly outperforms zero-shot settings and
achieves competitive results on single-granularity tasks compared to public and
commercial systems. The model performs well at word and sentence levels, while
phoneme-level assessment remains challenging. We also observe that the Pearson
Correlation Coefficient (PCC) reaches 0.9, whereas Spearman's rank Correlation
Coefficient (SCC) remains around 0.6, suggesting that SCC better reflects
ordinal consistency. These findings highlight both the promise and limitations
of LMMs for APA and point to future work on fine-grained modeling and
rank-aware evaluation.

</details>


### [143] [Once Upon a Time: Interactive Learning for Storytelling with Small Language Models](https://arxiv.org/abs/2509.15714)
*Jonas Mayer Martins,Ali Hamza Bashir,Muhammad Rehan Khalid,Lisa Beinborn*

Main category: cs.CL

TL;DR: 儿童通过互动式学习语言，而大型语言模型通常通过预测下一个词来学习。本研究探索了结合高层认知反馈（如可读性、叙事连贯性和创造性）的互动式学习方法，可以提高语言模型的学习效率。


<details>
  <summary>Details</summary>
Motivation: 儿童通过社会互动学习语言，这与大型语言模型主要通过预测下一个词来学习的方式形成对比。因此，研究的动机是探索是否可以通过结合高层、受认知启发的反馈来提高语言模型的学习效率，从而减少所需的数据量。

Method: 本研究训练了一个学生模型来生成故事，并由一个教师模型对故事的可读性、叙事连贯性和创造性进行评分。通过改变反馈循环之前的预训练量，评估了这种互动式学习对正式和功能性语言能力的影响。

Result: 结果表明，高层反馈具有很高的学习效率。仅在互动学习中使用 100 万词的输入，故事创作能力就能获得与使用 41000 万词进行下一个词预测相同的提升。

Conclusion: 研究发现，通过结合高层反馈的互动式学习，可以显著提高语言模型的学习效率，使其在较少的数据量下就能达到与大规模预训练相当的性能。

Abstract: Children efficiently acquire language not just by listening, but by
interacting with others in their social environment. Conversely, large language
models are typically trained with next-word prediction on massive amounts of
text. Motivated by this contrast, we investigate whether language models can be
trained with less data by learning not only from next-word prediction but also
from high-level, cognitively inspired feedback. We train a student model to
generate stories, which a teacher model rates on readability, narrative
coherence, and creativity. By varying the amount of pretraining before the
feedback loop, we assess the impact of this interactive learning on formal and
functional linguistic competence. We find that the high-level feedback is
highly data efficient: With just 1 M words of input in interactive learning,
storytelling skills can improve as much as with 410 M words of next-word
prediction.

</details>


### [144] [REFER: Mitigating Bias in Opinion Summarisation via Frequency Framed Prompting](https://arxiv.org/abs/2509.15723)
*Nannan Huang,Haytham M. Fayek,Xiuzhen Zhang*

Main category: cs.CL

TL;DR: 通过引入基于频率的提示框架REFER，提升了大型语言模型在观点摘要中的公平性，尤其是在模型规模较大和推理指令较强时。


<details>
  <summary>Details</summary>
Motivation: 以往关于使用大型语言模型（LLMs）进行公平观点摘要的研究，依赖于超参数调整或在提示中提供真实分布信息，但这些方法在实际应用中受限，因为终端用户很少更改默认参数，且准确的分布信息不易获得。本研究旨在借鉴认知科学中频率表示能减少人类统计推理系统性偏差的发现，探索频率提示（REFER）是否也能增强LLM观点摘要的公平性。

Method: 本研究通过系统性实验，采用不同的提示框架，将旨在改善人类推理的技术改编，以期在语言模型中实现比抽象概率表示更有效的信息处理。

Result: 实验结果表明，REFER框架能增强语言模型在观点摘要时的公平性，并且在更大的语言模型和更强的推理指令下，这种效果尤为显著。

Conclusion: 本研究提出的频率提示框架REFER能够有效提升大型语言模型在进行观点摘要时的公平性，为解决LLM在信息摘要中的偏见问题提供了一种新的、更实用的方法。

Abstract: Individuals express diverse opinions, a fair summary should represent these
viewpoints comprehensively. Previous research on fairness in opinion
summarisation using large language models (LLMs) relied on hyperparameter
tuning or providing ground truth distributional information in prompts.
However, these methods face practical limitations: end-users rarely modify
default model parameters, and accurate distributional information is often
unavailable. Building upon cognitive science research demonstrating that
frequency-based representations reduce systematic biases in human statistical
reasoning by making reference classes explicit and reducing cognitive load,
this study investigates whether frequency framed prompting (REFER) can
similarly enhance fairness in LLM opinion summarisation. Through systematic
experimentation with different prompting frameworks, we adapted techniques
known to improve human reasoning to elicit more effective information
processing in language models compared to abstract probabilistic
representations.Our results demonstrate that REFER enhances fairness in
language models when summarising opinions. This effect is particularly
pronounced in larger language models and using stronger reasoning instructions.

</details>


### [145] [Can LLMs Judge Debates? Evaluating Non-Linear Reasoning via Argumentation Theory Semantics](https://arxiv.org/abs/2509.15739)
*Reza Sanayei,Srdjan Vesic,Eduardo Blanco,Mihai Surdeanu*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在近似计算论证理论（CAT）中的量化论证（QuAD）语义方面表现出潜力，但其性能受到输入长度和话语流畅度等因素的限制。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在近似计算论证理论（CAT）中的结构化推理能力，特别是在非线性结构（如辩论中的论证图）上的表现。

Method: 在两个NoDE数据集上，仅提供对话格式的辩论，并采用链式思考（Chain-of-Thought）和情境学习（In-Context Learning）等高级指令策略，评估LLMs在没有图谱访问权限的情况下对论证进行排名。

Result: LLMs在近似QuAD排名方面表现出中等程度的一致性，但性能会随着输入长度的增加或话语流程的中断而下降。高级提示策略有助于缓解这些负面影响，减少论证长度和位置偏差。

Conclusion: LLMs在模拟形式论证语义方面具有潜力，但也存在局限性，未来需要进一步研究图感知推理能力。

Abstract: Large Language Models (LLMs) excel at linear reasoning tasks but remain
underexplored on non-linear structures such as those found in natural debates,
which are best expressed as argument graphs. We evaluate whether LLMs can
approximate structured reasoning from Computational Argumentation Theory (CAT).
Specifically, we use Quantitative Argumentation Debate (QuAD) semantics, which
assigns acceptability scores to arguments based on their attack and support
relations. Given only dialogue-formatted debates from two NoDE datasets, models
are prompted to rank arguments without access to the underlying graph. We test
several LLMs under advanced instruction strategies, including Chain-of-Thought
and In-Context Learning. While models show moderate alignment with QuAD
rankings, performance degrades with longer inputs or disrupted discourse flow.
Advanced prompting helps mitigate these effects by reducing biases related to
argument length and position. Our findings highlight both the promise and
limitations of LLMs in modeling formal argumentation semantics and motivate
future work on graph-aware reasoning.

</details>


### [146] [UniGist: Towards General and Hardware-aligned Sequence-level Long Context Compression](https://arxiv.org/abs/2509.15763)
*Chenlong Deng,Zhisong Zhang,Kelong Mao,Shuaiyi Li,Tianqing Fang,Hongming Zhang,Haitao Mi,Dong Yu,Zhicheng Dou*

Main category: cs.CL

TL;DR: UniGist框架通过用精细的压缩令牌（gist）替换原始令牌来压缩长上下文，解决了KV缓存的内存瓶颈，并在长上下文任务中实现了显著的压缩质量和内存节省。


<details>
  <summary>Details</summary>
Motivation: KV缓存的内存开销是长上下文模型部署的主要瓶颈，而现有的序列级压缩方法可能会丢失重要的上下文信息。

Method: UniGist采用一种无分块的训练策略，设计了一个包含gist shift技巧的高效内核，并支持通过实际移除压缩令牌来实现灵活推理。

Result: UniGist在多个长上下文任务中显著提高了压缩质量，在细节回忆任务和长距离依赖建模方面表现尤为出色。

Conclusion: UniGist是一种有效的长上下文压缩框架，通过用精细的压缩令牌（gist）替换原始令牌来保留上下文信息，从而实现显著的内存节省和性能提升。

Abstract: Large language models are increasingly capable of handling long-context
inputs, but the memory overhead of key-value (KV) cache remains a major
bottleneck for general-purpose deployment. While various compression strategies
have been explored, sequence-level compression, which drops the full KV caches
for certain tokens, is particularly challenging as it can lead to the loss of
important contextual information. To address this, we introduce UniGist, a
sequence-level long-context compression framework that efficiently preserves
context information by replacing raw tokens with special compression tokens
(gists) in a fine-grained manner. We adopt a chunk-free training strategy and
design an efficient kernel with a gist shift trick, enabling optimized GPU
training. Our scheme also supports flexible inference by allowing the actual
removal of compressed tokens, resulting in real-time memory savings.
Experiments across multiple long-context tasks demonstrate that UniGist
significantly improves compression quality, with especially strong performance
in detail-recalling tasks and long-range dependency modeling.

</details>


### [147] [UPRPRC: Unified Pipeline for Reproducing Parallel Resources -- Corpus from the United Nations](https://arxiv.org/abs/2509.15789)
*Qiuyang Lu,Fangjian Shen,Zhengkai Tang,Qiang Liu,Hexuan Cheng,Hui Liu,Wushao Wen*

Main category: cs.CL

TL;DR: A new reproducible multilingual dataset is created using GAPA algorithm, which is larger than previous works.


<details>
  <summary>Details</summary>
Motivation: Previous corpora from UN documents have issues like opaque process, difficulty of reproduction, and limited scale.

Method: The paper introduces a complete end-to-end solution for data acquisition and text alignment, featuring a novel Graph-Aided Paragraph Alignment (GAPA) algorithm. The process is reproducible and scalable.

Result: The resulting corpus contains over 713 million English tokens, more than doubling the scale of prior work. It is the largest publicly available parallel corpus of human-translated, non-AI-generated content.

Conclusion: The new GAPA algorithm and the resulting large-scale, reproducible corpus address the limitations of previous datasets, advancing machine translation research.

Abstract: The quality and accessibility of multilingual datasets are crucial for
advancing machine translation. However, previous corpora built from United
Nations documents have suffered from issues such as opaque process, difficulty
of reproduction, and limited scale. To address these challenges, we introduce a
complete end-to-end solution, from data acquisition via web scraping to text
alignment. The entire process is fully reproducible, with a minimalist
single-machine example and optional distributed computing steps for
scalability. At its core, we propose a new Graph-Aided Paragraph Alignment
(GAPA) algorithm for efficient and flexible paragraph-level alignment. The
resulting corpus contains over 713 million English tokens, more than doubling
the scale of prior work. To the best of our knowledge, this represents the
largest publicly available parallel corpus composed entirely of
human-translated, non-AI-generated content. Our code and corpus are accessible
under the MIT License.

</details>


### [148] [RAVE: Retrieval and Scoring Aware Verifiable Claim Detection](https://arxiv.org/abs/2509.15793)
*Yufeng Li,Arkaitz Zubiaga*

Main category: cs.CL

TL;DR: RAVE框架通过结合证据检索和相关性及来源可信度的结构化信号，提高了推文等多种格式可验证声明的检测准确率和F1分数，优于仅文本和基于检索的方法。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上传播的错误信息需要可扩展的事实核查工具，而声明检测是其中的关键一步，旨在识别可客观验证的声明。

Method: 提出了一种名为RAVE（检索和评分感知可验证声明检测）的框架，该框架结合了证据检索以及与相关性和来源可信度相关的结构化信号。

Result: 在CT22-test和PoliClaim-test数据集上的实验表明，RAVE在准确率和F1分数上始终优于仅文本和基于检索的基线方法。

Conclusion: RAVE框架在声明检测任务中表现出色，能够有效处理模糊的政治言论和推文等不同格式。

Abstract: The rapid spread of misinformation on social media underscores the need for
scalable fact-checking tools. A key step is claim detection, which identifies
statements that can be objectively verified. Prior approaches often rely on
linguistic cues or claim check-worthiness, but these struggle with vague
political discourse and diverse formats such as tweets. We present RAVE
(Retrieval and Scoring Aware Verifiable Claim Detection), a framework that
combines evidence retrieval with structured signals of relevance and source
credibility. Experiments on CT22-test and PoliClaim-test show that RAVE
consistently outperforms text-only and retrieval-based baselines in both
accuracy and F1.

</details>


### [149] [Best-of-L: Cross-Lingual Reward Modeling for Mathematical Reasoning](https://arxiv.org/abs/2509.15811)
*Sara Rajaee,Rochelle Choenni,Ekaterina Shutova,Christof Monz*

Main category: cs.CL

TL;DR: 跨语言奖励模型提升了大型语言模型（LLMs）在数学推理方面的能力，即使是高资源语言也能受益，并且在低采样预算下尤其能提升英语的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的推理能力在不断提高，但我们尚不清楚多语言LLMs的推理能力在不同语言之间是如何变化的，以及不同语言是否会产生相互补充的推理路径。

Method: 训练了一个奖励模型来对多种语言中给定问题的生成响应进行排序。

Result: 结果表明，与仅在单一语言内进行奖励建模相比，我们的跨语言奖励模型能显著提高数学推理性能，并且即使是高资源语言也能从中受益。虽然英语在多语言模型中的表现通常最高，但我们发现跨语言采样在低采样预算下尤其有利于英语。

Conclusion: 研究结果揭示了通过利用不同语言的互补优势来改进多语言推理的新机会。

Abstract: While the reasoning abilities of large language models (LLMs) continue to
advance, it remains unclear how such ability varies across languages in
multilingual LLMs and whether different languages produce reasoning paths that
complement each other. To investigate this question, we train a reward model to
rank generated responses for a given question across languages. Our results
show that our cross-lingual reward model substantially improves mathematical
reasoning performance compared to using reward modeling within a single
language, benefiting even high-resource languages. While English often exhibits
the highest performance in multilingual models, we find that cross-lingual
sampling particularly benefits English under low sampling budgets. Our findings
reveal new opportunities to improve multilingual reasoning by leveraging the
complementary strengths of diverse languages.

</details>


### [150] [The Curious Case of Visual Grounding: Different Effects for Speech- and Text-based Language Encoders](https://arxiv.org/abs/2509.15837)
*Adrian Sauter,Willem Zuidema,Marianne de Heer Kloots*

Main category: cs.CL

TL;DR: 视觉信息会影响语音和文本模型的语言处理方式，但对它们的内部表征有不同的影响。


<details>
  <summary>Details</summary>
Motivation: 探讨视觉信息对语音和文本深度学习模型语言处理的影响，以及这种视觉关联如何影响模型内部的词语表征。

Method: 通过全局表征比较和聚类分析，探究视觉关联对语音和文本模型中语音和语义辨别能力的影响。

Result: 视觉关联增强了口语和书面语表征之间在词语身份上的对齐，但并未显著提升语义辨别能力。对于语音模型，视觉关联并未改善其语义辨别能力，而文本模型则有所改善。

Conclusion: 视觉关联对语音和文本模型的内部表征有不同的影响。视觉关联主要通过增强词语身份编码来增加口语和书面语表征的对齐，但对语义辨别能力的提升作用有限。研究结果可为开发更有效的视觉信息增强语音模型的方法提供参考。

Abstract: How does visual information included in training affect language processing
in audio- and text-based deep learning models? We explore how such visual
grounding affects model-internal representations of words, and find
substantially different effects in speech- vs. text-based language encoders.
Firstly, global representational comparisons reveal that visual grounding
increases alignment between representations of spoken and written language, but
this effect seems mainly driven by enhanced encoding of word identity rather
than meaning. We then apply targeted clustering analyses to probe for phonetic
vs. semantic discriminability in model representations. Speech-based
representations remain phonetically dominated with visual grounding, but in
contrast to text-based representations, visual grounding does not improve
semantic discriminability. Our findings could usefully inform the development
of more efficient methods to enrich speech-based models with visually-informed
semantics.

</details>


### [151] [Multi-Physics: A Comprehensive Benchmark for Multimodal LLMs Reasoning on Chinese Multi-Subject Physics Problems](https://arxiv.org/abs/2509.15839)
*Zhongze Luo,Zhenshuai Yin,Yongxin Guo,Zhichao Wang,Jionghao Zhu,Xiaoying Tang*

Main category: cs.CL

TL;DR: 现有的多模态大语言模型(MLLMs)在科学领域，特别是在物理学方面的评估存在不足，因此我们提出了一个名为Multi-Physics的中文物理推理基准，它包含5个难度级别和11个学科主题的1412个图像相关选择题。


<details>
  <summary>Details</summary>
Motivation: 现有的评估基准在细粒度的主题覆盖、逐步推理过程的考察以及多语言支持方面存在不足，未能系统地评估视觉信息的作用。

Method: 提出Multi-Physics基准，包含1412个图像相关选择题，覆盖11个高中物理学科和5个难度级别。采用双重评估框架，分析最终答案准确性和思维链的完整性。通过改变输入模式比较模型性能，研究难度和视觉信息的影响。

Result: 评估了20种不同的MLLMs，并分析了最终答案准确性和思维链的完整性。研究了难度级别和视觉信息对模型性能的影响。

Conclusion: Multi-Physics基准为社区提供了细粒度的资源，并为剖析最先进MLLMs的多模态推理过程提供了稳健的方法。

Abstract: While multimodal LLMs (MLLMs) demonstrate remarkable reasoning progress,
their application in specialized scientific domains like physics reveals
significant gaps in current evaluation benchmarks. Specifically, existing
benchmarks often lack fine-grained subject coverage, neglect the step-by-step
reasoning process, and are predominantly English-centric, failing to
systematically evaluate the role of visual information. Therefore, we introduce
\textbf {Multi-Physics} for Chinese physics reasoning, a comprehensive
benchmark that includes 5 difficulty levels, featuring 1,412 image-associated,
multiple-choice questions spanning 11 high-school physics subjects. We employ a
dual evaluation framework to evaluate 20 different MLLMs, analyzing both final
answer accuracy and the step-by-step integrity of their chain-of-thought.
Furthermore, we systematically study the impact of difficulty level and visual
information by comparing the model performance before and after changing the
input mode. Our work provides not only a fine-grained resource for the
community but also offers a robust methodology for dissecting the multimodal
reasoning process of state-of-the-art MLLMs, and our dataset and code have been
open-sourced: https://github.com/luozhongze/Multi-Physics.

</details>


### [152] [Distribution-Aligned Decoding for Efficient LLM Task Adaptation](https://arxiv.org/abs/2509.15888)
*Senkang Hu,Xudong Han,Jinqi Jiang,Yihang Tao,Zihan Fang,Sam Tak Wu Kwong,Yuguang Fang*

Main category: cs.CL

TL;DR: 通过在解码过程中直接引导模型输出分布，而不是通过权重更新，来将大型语言模型适应下游任务。SVD 使用从 KL 散度梯度中提取的任务感知转向向量来指导解码过程，理论上等同于完全微调的梯度步骤。


<details>
  <summary>Details</summary>
Motivation: 微调大型语言模型（LLM）进行下游任务仍然成本高昂，即使使用参数高效微调（PEFT）。

Method: 将任务适应重新定义为输出分布对齐，并引入转向向量解码（SVD）。SVD 首先进行短暂的预训练微调，然后提取一个转向向量，该向量基于预训练模型和微调模型的输出分布之间的 KL 散度梯度。在解码过程中使用此向量来引导模型生成符合任务分布的输出。

Result: 在三个任务和九个基准测试中，SVD 结合四种 PEFT 方法，将多项选择题的准确率提高了高达 5 分，开放式问题的真实性提高了 2 分，在常识推理数据集上的提升相似（1-2 分），并且没有增加额外的可训练参数。

Conclusion: SVD 提供了一种轻量级、有理论依据的方法，可以更有效地适应大型语言模型以完成下游任务，而无需增加计算成本。

Abstract: Adapting billion-parameter language models to a downstream task is still
costly, even with parameter-efficient fine-tuning (PEFT). We re-cast task
adaptation as output-distribution alignment: the objective is to steer the
output distribution toward the task distribution directly during decoding
rather than indirectly through weight updates. Building on this view, we
introduce Steering Vector Decoding (SVD), a lightweight, PEFT-compatible, and
theoretically grounded method. We start with a short warm-start fine-tune and
extract a task-aware steering vector from the Kullback-Leibler (KL) divergence
gradient between the output distribution of the warm-started and pre-trained
models. This steering vector is then used to guide the decoding process to
steer the model's output distribution towards the task distribution. We
theoretically prove that SVD is first-order equivalent to the gradient step of
full fine-tuning and derive a globally optimal solution for the strength of the
steering vector. Across three tasks and nine benchmarks, SVD paired with four
standard PEFT methods improves multiple-choice accuracy by up to 5 points and
open-ended truthfulness by 2 points, with similar gains (1-2 points) on
commonsense datasets without adding trainable parameters beyond the PEFT
adapter. SVD thus offers a lightweight, theoretically grounded path to stronger
task adaptation for large language models.

</details>


### [153] [The Psychology of Falsehood: A Human-Centric Survey of Misinformation Detection](https://arxiv.org/abs/2509.15896)
*Arghodeep Nandi,Megha Sundriyal,Euna Mehnaz Khan,Jikai Sun,Emily Vraga,Jaideep Srivastava,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 该论文调查了数字时代错误信息的传播问题，并提出需要超越传统事实核查方法，结合心理学概念（如认知偏差、社会动态和情绪反应）来开发以人为本的检测框架。


<details>
  <summary>Details</summary>
Motivation: 当前的自动化事实核查系统主要关注事实准确性，但未能充分应对错误信息如何利用人们的感知、解读和情绪反应来造成危害，因此有必要开发更全面的人类中心检测方法。

Method: 通过分析结合了心理学概念（认知偏差、社会动态、情绪反应）的最新错误信息检测系统，并探讨了传统事实核查方法与这些心理学概念的相互作用。

Result: 现有方法存在局限性，但结合心理学和行为学进行分析揭示了改进的机会。研究还提出了包括神经行为模型在内的未来研究方向，以整合技术因素和人类认知与社会影响的复杂性。

Conclusion: 通过整合技术方法和对人类心理及行为的深刻理解，可以开发出更有效、更适应性强的错误信息检测框架，从而更好地应对其社会危害。

Abstract: Misinformation remains one of the most significant issues in the digital age.
While automated fact-checking has emerged as a viable solution, most current
systems are limited to evaluating factual accuracy. However, the detrimental
effect of misinformation transcends simple falsehoods; it takes advantage of
how individuals perceive, interpret, and emotionally react to information. This
underscores the need to move beyond factuality and adopt more human-centered
detection frameworks. In this survey, we explore the evolving interplay between
traditional fact-checking approaches and psychological concepts such as
cognitive biases, social dynamics, and emotional responses. By analyzing
state-of-the-art misinformation detection systems through the lens of human
psychology and behavior, we reveal critical limitations of current methods and
identify opportunities for improvement. Additionally, we outline future
research directions aimed at creating more robust and adaptive frameworks, such
as neuro-behavioural models that integrate technological factors with the
complexities of human cognition and social influence. These approaches offer
promising pathways to more effectively detect and mitigate the societal harms
of misinformation.

</details>


### [154] [Re-FRAME the Meeting Summarization SCOPE: Fact-Based Summarization and Personalization via Questions](https://arxiv.org/abs/2509.15901)
*Frederic Kirstein,Sonu Kumar,Terry Ruas,Bela Gipp*

Main category: cs.CL

TL;DR: FRAME是一个用于会议摘要的模块化流水线，通过语义丰富、事实评分和主题组织来改进LLM摘要的准确性。SCOPE协议通过模型推理过程来个性化摘要。P-MESA是一个无参考的评估框架，可评估摘要与目标读者的契合度。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM会议摘要方法容易出现幻觉、遗漏和不相关内容，因此需要改进摘要的准确性、可控性和个性化。

Method: FRAME通过提取和评分事实、主题组织以及丰富大纲来将摘要重构为语义丰富任务。SCOPE协议通过模型回答九个问题来建立推理过程，从而实现摘要个性化。P-MESA评估框架用于评估摘要与目标读者的契合度。

Result: FRAME在QMSum和FAME数据集上将幻觉和遗漏减少了2/5（使用MESA测量）。SCOPE协议在知识匹配和目标对齐方面优于仅提示基线。P-MESA评估框架在识别错误实例方面具有>=89%的准确率，并与人类严重性评级高度一致（r>=0.70）。

Conclusion: 会议摘要应被重新构想为一项语义丰富任务，以提高摘要的可控性、忠实性和个性化。

Abstract: Meeting summarization with large language models (LLMs) remains error-prone,
often producing outputs with hallucinations, omissions, and irrelevancies. We
present FRAME, a modular pipeline that reframes summarization as a semantic
enrichment task. FRAME extracts and scores salient facts, organizes them
thematically, and uses these to enrich an outline into an abstractive summary.
To personalize summaries, we introduce SCOPE, a reason-out-loud protocol that
has the model build a reasoning trace by answering nine questions before
content selection. For evaluation, we propose P-MESA, a multi-dimensional,
reference-free evaluation framework to assess if a summary fits a target
reader. P-MESA reliably identifies error instances, achieving >= 89% balanced
accuracy against human annotations and strongly aligns with human severity
ratings (r >= 0.70). On QMSum and FAME, FRAME reduces hallucination and
omission by 2 out of 5 points (measured with MESA), while SCOPE improves
knowledge fit and goal alignment over prompt-only baselines. Our findings
advocate for rethinking summarization to improve control, faithfulness, and
personalization.

</details>


### [155] [Beyond the Score: Uncertainty-Calibrated LLMs for Automated Essay Assessment](https://arxiv.org/abs/2509.15926)
*Ahmed Karim,Qiao Wang,Zheng Yuan*

Main category: cs.CL

TL;DR: 本研究将保形预测和UAcc方法应用于自动化论文评分（AES）领域，利用开源大语言模型（LLM）提升评分的可信度和透明度。


<details>
  <summary>Details</summary>
Motivation: 当前自动化论文评分（AES）系统虽在部分公开基准上能达到接近人类的评分一致性，但在高风险考试等实际应用中推广受限，主要原因是大多数模型仅输出单一分数，缺乏置信度度量或解释。本研究旨在解决这一问题。

Method: 研究采用了保形预测（conformal prediction）方法，这是一种无需预设分布的包装器，可以为任何分类器提供集合形式的输出和正式的覆盖率保证。具体而言，研究微调了两个开源大语言模型（Llama-3 8B和Qwen-2.5 3B），并在三个不同的语料库（ASAP、TOEFL11、Cambridge-FCE）上进行了训练，同时设定了90%的风险水平进行校准。模型性能通过UAcc（一种不确定性感知准确度指标，该指标同时考虑了预测的准确性和简洁性）进行评估。

Result: 经过校准的模型始终满足覆盖率目标，同时保持预测集的小巧。实验结果表明，中等规模的开源LLM已经能够支持教师参与的AES系统。

Conclusion: 本研究首次将保形预测和UAcc结合应用于论文评分，证明了中等规模的开源LLM在提供可信且具有解释性的论文评分方面的潜力。未来的工作将进一步探索模型的扩展性和更广泛的用户研究。

Abstract: Automated Essay Scoring (AES) systems now reach near human agreement on some
public benchmarks, yet real-world adoption, especially in high-stakes
examinations, remains limited. A principal obstacle is that most models output
a single score without any accompanying measure of confidence or explanation.
We address this gap with conformal prediction, a distribution-free wrapper that
equips any classifier with set-valued outputs and formal coverage guarantees.
Two open-source large language models (Llama-3 8B and Qwen-2.5 3B) are
fine-tuned on three diverse corpora (ASAP, TOEFL11, Cambridge-FCE) and
calibrated at a 90 percent risk level. Reliability is assessed with UAcc, an
uncertainty-aware accuracy that rewards models for being both correct and
concise. To our knowledge, this is the first work to combine conformal
prediction and UAcc for essay scoring. The calibrated models consistently meet
the coverage target while keeping prediction sets compact, indicating that
open-source, mid-sized LLMs can already support teacher-in-the-loop AES; we
discuss scaling and broader user studies as future work.

</details>


### [156] [Localmax dynamics for attention in transformers and its asymptotic behavior](https://arxiv.org/abs/2509.15958)
*Henri Cimetière,Maria Teresa Chiri,Bahman Gharesifard*

Main category: cs.CL

TL;DR: localmax dynamics是一种新的离散时间注意力模型，它在softmax和hardmax动力学之间进行插值，其中只有对给定令牌产生影响的令牌才具有正权重。


<details>
  <summary>Details</summary>
Motivation: 本研究提出了localmax dynamics，一种新的离散时间注意力模型，旨在结合softmax和hardmax动力学的优点，并克服它们的局限性。

Method: 通过引入一个控制邻域影响的参数，并放松邻域交互，通过一个对齐敏感性参数，可以控制偏离纯hardmax行为的程度。该模型还引入了静止集来捕获令牌在顶点附近的不变行为。

Result: localmax dynamics不会表现出有限时间收敛，但可以恢复hardmax的极限行为。研究结果还展示了该模型在不同对齐敏感性参数下的行为。

Conclusion: localmax dynamics是一种有前途的注意力模型，但需要进一步研究其在非对称设置中的应用，并探索新的分析方法。

Abstract: We introduce a new discrete-time attention model, termed the localmax
dynamics, which interpolates between the classic softmax dynamics and the
hardmax dynamics, where only the tokens that maximize the influence toward a
given token have a positive weight. As in hardmax, uniform weights are
determined by a parameter controlling neighbor influence, but the key extension
lies in relaxing neighborhood interactions through an alignment-sensitivity
parameter, which allows controlled deviations from pure hardmax behavior. As we
prove, while the convex hull of the token states still converges to a convex
polytope, its structure can no longer be fully described by a maximal alignment
set, prompting the introduction of quiescent sets to capture the invariant
behavior of tokens near vertices. We show that these sets play a key role in
understanding the asymptotic behavior of the system, even under time-varying
alignment sensitivity parameters. We further show that localmax dynamics does
not exhibit finite-time convergence and provide results for vanishing, nonzero,
time-varying alignment-sensitivity parameters, recovering the limiting behavior
of hardmax as a by-product. Finally, we adapt Lyapunov-based methods from
classical opinion dynamics, highlighting their limitations in the asymmetric
setting of localmax interactions and outlining directions for future research.

</details>


### [157] [BEFT: Bias-Efficient Fine-Tuning of Language Models](https://arxiv.org/abs/2509.15974)
*Baichuan Huang,Ananth Balashankar,Amir Aminifar*

Main category: cs.CL

TL;DR: 偏见项微调是一种有效的参数高效微调技术，但选择哪个偏见项进行微调以获得最佳下游性能尚不清楚。本文提出了一种名为 BEFT 的偏见项选择方法，并在各种大型语言模型和下游任务上证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在选择要微调的偏见项方面提供的指导有限，无法有效提高下游性能。

Method: 提出了一种用于选择要微调的偏见项的方法，即偏见高效微调 (BEFT)。

Result: 在各种大型语言模型（包括编码器-only和解码器-only架构，参数量从1.1亿到67亿）和各种下游任务（包括分类、多项选择和生成任务）上，对所提出的偏见高效方法进行了广泛评估，并证明了其有效性和优越性。

Conclusion: 所提出的偏见高效微调方法在各种下游任务中优于其他偏见选择方法。

Abstract: Fine-tuning all-bias-terms stands out among various parameter-efficient
fine-tuning (PEFT) techniques, owing to its out-of-the-box usability and
competitive performance, especially in low-data regimes. Bias-only fine-tuning
has the potential for unprecedented parameter efficiency. However, the link
between fine-tuning different bias terms (i.e., bias terms in the query, key,
or value projections) and downstream performance remains unclear. The existing
approaches, e.g., based on the magnitude of bias change or empirical Fisher
information, provide limited guidance for selecting the particular bias term
for effective fine-tuning. In this paper, we propose an approach for selecting
the bias term to be fine-tuned, forming the foundation of our bias-efficient
fine-tuning (BEFT). We extensively evaluate our bias-efficient approach against
other bias-selection approaches, across a wide range of large language models
(LLMs) spanning encoder-only and decoder-only architectures from 110M to 6.7B
parameters. Our results demonstrate the effectiveness and superiority of our
bias-efficient approach on diverse downstream tasks, including classification,
multiple-choice, and generation tasks.

</details>


### [158] [Session-Level Spoken Language Assessment with a Multimodal Foundation Model via Multi-Target Learning](https://arxiv.org/abs/2509.16025)
*Hong-Yun Lin,Jhen-Ke Lin,Chung-Chun Wang,Hao-Chien Lu,Berlin Chen*

Main category: cs.CL

TL;DR: 该研究提出了一种新颖的多模态基础模型方法，用于评估 L2 英语学习者的口语能力，通过一次性处理整个响应会话并结合多目标学习和预训练的 Whisper ASR 模型，实现了比现有方法更优越的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着 L2 英语学习者数量的增加，对可靠的口语语言评估（SLA）的需求日益增长，这是计算机辅助语言学习（CALL）的关键组成部分。现有方法存在级联流水线易出错或端到端模型仅关注短音频窗口的问题。

Method: 提出了一种新颖的多模态基础模型方法，该方法结合了多目标学习和一个冻结的、基于 Whisper ASR 的语音先验模型，用于声学感知校准，从而能够联合学习 SLA 的整体和特质级别目标，无需手工制作的特征。通过连贯地处理 L2 说话者的整个响应会话来进行评估。

Result: 在 Speak & Improve 基准测试的实验表明，所提出的方法在预测整体口语能力方面表现出色，超越了先前最先进的级联系统，并表现出鲁棒的跨部分泛化能力。

Conclusion: 该研究提出的多模态基础模型方法能够一次性处理整个响应会话，并能进行整体和特质级别的 SLA 评估，实现了比现有方法更优越的性能和鲁棒性，为 CALL 应用提供了一个紧凑且可部署的评估器。

Abstract: Spoken Language Assessment (SLA) estimates a learner's oral proficiency from
spontaneous speech. The growing population of L2 English speakers has
intensified the demand for reliable SLA, a critical component of Computer
Assisted Language Learning (CALL). Existing efforts often rely on cascaded
pipelines, which are prone to error propagation, or end-to-end models that
often operate on a short audio window, which might miss discourse-level
evidence. This paper introduces a novel multimodal foundation model approach
that performs session-level evaluation in a single pass. Our approach couples
multi-target learning with a frozen, Whisper ASR model-based speech prior for
acoustic-aware calibration, allowing for jointly learning holistic and
trait-level objectives of SLA without resorting to handcrafted features. By
coherently processing the entire response session of an L2 speaker, the model
excels at predicting holistic oral proficiency. Experiments conducted on the
Speak & Improve benchmark demonstrate that our proposed approach outperforms
the previous state-of-the-art cascaded system and exhibits robust cross-part
generalization, producing a compact deployable grader that is tailored for CALL
applications.

</details>


### [159] [Think, Verbalize, then Speak: Bridging Complex Thoughts and Comprehensible Speech](https://arxiv.org/abs/2509.16028)
*Sang Hoon Woo,Sehun Lee,Kang-wook Kim,Gunhee Kim*

Main category: cs.CL

TL;DR: 该研究提出了一种名为 Think-Verbalize-Speak 的框架，通过将语言模型（LLM）的推理过程与口语表达分离开来，解决了 LLM 在语音对话中推理能力下降的问题。该框架包括一个中间的“语言化”步骤，将 LLM 的思考过程转化为适合口语表达的文本。此外，还引入了一个名为 ReVerT 的高效语言化模型，该模型采用增量和异步摘要技术来减少延迟。实验结果表明，该方法在提高语音的自然度和简洁性的同时，对推理性能的影响很小。


<details>
  <summary>Details</summary>
Motivation: 直接将大型语言模型（LLM）应用于口语对话系统时，由于文本和口语表达方式的差异，往往会导致推理能力下降。现有方法虽然尝试使 LLM 的输出更适合口语，但对推理能力的影响尚不明确。

Method: 提出 Think-Verbalize-Speak 框架，将 LLM 的推理与口语表达分离。核心是“语言化”步骤，将思考过程转化为适合口语表达的文本。同时引入 ReVerT，一种基于增量和异步摘要的低延迟语言化模型。

Result: 实验证明，该方法在多个基准测试中，能够提高语音的自然度和简洁性，同时对推理能力的影响很小。

Conclusion: Think-Verbalize-Speak 框架通过解耦推理和口语表达，并引入 ReVerT 模型，有效解决了 LLM 在语音对话中推理能力下降的问题，同时保证了语音输出的质量。

Abstract: Spoken dialogue systems increasingly employ large language models (LLMs) to
leverage their advanced reasoning capabilities. However, direct application of
LLMs in spoken communication often yield suboptimal results due to mismatches
between optimal textual and verbal delivery. While existing approaches adapt
LLMs to produce speech-friendly outputs, their impact on reasoning performance
remains underexplored. In this work, we propose Think-Verbalize-Speak, a
framework that decouples reasoning from spoken delivery to preserve the full
reasoning capacity of LLMs. Central to our method is verbalizing, an
intermediate step that translates thoughts into natural, speech-ready text. We
also introduce ReVerT, a latency-efficient verbalizer based on incremental and
asynchronous summarization. Experiments across multiple benchmarks show that
our method enhances speech naturalness and conciseness with minimal impact on
reasoning. The project page with the dataset and the source code is available
at https://yhytoto12.github.io/TVS-ReVerT

</details>


### [160] [Beyond Pointwise Scores: Decomposed Criteria-Based Evaluation of LLM Responses](https://arxiv.org/abs/2509.16093)
*Fangyi Yu,Nabeel Seedat,Dasha Herrmannova,Frank Schilder,Jonathan Richard Schwarz*

Main category: cs.CL

TL;DR: DeCE是一个分解式LLM评估框架，用于在高风险领域评估长篇答案，能将事实准确性、相关性和概念覆盖率分开，并与专家判断有更强的相关性。


<details>
  <summary>Details</summary>
Motivation: 在高风险领域（如法律、医学）评估长篇答案是一个基本挑战，现有指标（如BLEU、ROUGE）和LLM评估器无法捕捉语义正确性，且容易将细微的答案质量方面简化为单一分数。

Method: DeCE框架通过分离精确率（事实准确性和相关性）和召回率（所需概念的覆盖范围）来评估答案，并使用从黄金答案要求中自动提取的、针对特定实例的标准。该框架是模型无关和领域通用的，不需要预定义的分类法或手工制作的评分标准。

Result: DeCE在涉及多司法管辖区推理和引用归因的法律问答任务中，与专家判断的相关性（r=0.78）显著高于传统指标（r=0.12）、逐点LLM评分（r=0.35）和现代多维评估器（r=0.48）。此外，DeCE揭示了可解释的权衡：通用模型倾向于召回，而专业模型倾向于精确率。重要的是，只有11.95%的LLM生成的标准需要专家修订，这表明DeCE具有可扩展性。

Conclusion: DeCE提供了一个可解释且可操作的LLM评估框架，适用于专家领域，能够更准确、更细致地评估长篇答案的质量。

Abstract: Evaluating long-form answers in high-stakes domains such as law or medicine
remains a fundamental challenge. Standard metrics like BLEU and ROUGE fail to
capture semantic correctness, and current LLM-based evaluators often reduce
nuanced aspects of answer quality into a single undifferentiated score. We
introduce DeCE, a decomposed LLM evaluation framework that separates precision
(factual accuracy and relevance) and recall (coverage of required concepts),
using instance-specific criteria automatically extracted from gold answer
requirements. DeCE is model-agnostic and domain-general, requiring no
predefined taxonomies or handcrafted rubrics. We instantiate DeCE to evaluate
different LLMs on a real-world legal QA task involving multi-jurisdictional
reasoning and citation grounding. DeCE achieves substantially stronger
correlation with expert judgments ($r=0.78$), compared to traditional metrics
($r=0.12$), pointwise LLM scoring ($r=0.35$), and modern multidimensional
evaluators ($r=0.48$). It also reveals interpretable trade-offs: generalist
models favor recall, while specialized models favor precision. Importantly,
only 11.95% of LLM-generated criteria required expert revision, underscoring
DeCE's scalability. DeCE offers an interpretable and actionable LLM evaluation
framework in expert domains.

</details>


### [161] [DiEP: Adaptive Mixture-of-Experts Compression through Differentiable Expert Pruning](https://arxiv.org/abs/2509.16105)
*Sikai Bai,Haoxi Li,Jie Zhang,Zicong Hong,Song Guo*

Main category: cs.CL

TL;DR: MoE模型规模大带来内存和存储挑战，现有剪枝方法因层间专家冗余度不一效果不佳。提出DiEP非均匀剪枝策略，自适应调整层级剪枝率并学习层间重要性，有效解决冗余度问题。DiEP将全局离散搜索空间转化为连续空间，实现自适应梯度剪枝。实验表明DiEP在多种NLP任务上表现优异，在MMLU数据集上，Mixtral 8x7B模型使用DiEP剪枝后，仅用一半专家即可保留92%的性能，效果优于其他剪枝方法7.1%。


<details>
  <summary>Details</summary>
Motivation: 现有MoE剪枝方法在不同MoE层级剪枝率单一，未能有效处理专家冗余度不一的问题，导致模型性能下降。

Method: 提出一种名为DiEP（Differentiable Expert Pruning）的非均匀剪枝策略，通过在层级自适应调整剪枝率，并联合学习层间重要性，来捕捉不同MoE层级的不同冗余度。将全局离散搜索空间转化为连续空间，实现梯度下降优化。

Result: 在五个先进的MoE模型和多种NLP任务上的广泛实验证明了DiEP的有效性。特别地，在MMLU基准测试中，DiEP在Mixtral 8x7B模型上，仅用一半专家即可保留约92%的原始性能，比其他剪枝方法的效果好达7.1%。

Conclusion: DiEP是一种有效的非均匀剪枝策略，能够自适应地处理MoE模型中不同层级的专家冗余度，从而在显著减少模型大小的同时，有效保持甚至提升模型性能。

Abstract: Despite the significant breakthrough of Mixture-of-Experts (MoE), the
increasing scale of these MoE models presents huge memory and storage
challenges. Existing MoE pruning methods, which involve reducing parameter size
with a uniform sparsity across all layers, often lead to suboptimal outcomes
and performance degradation due to varying expert redundancy in different MoE
layers. To address this, we propose a non-uniform pruning strategy, dubbed
\textbf{Di}fferentiable \textbf{E}xpert \textbf{P}runing (\textbf{DiEP}), which
adaptively adjusts pruning rates at the layer level while jointly learning
inter-layer importance, effectively capturing the varying redundancy across
different MoE layers. By transforming the global discrete search space into a
continuous one, our method handles exponentially growing non-uniform expert
combinations, enabling adaptive gradient-based pruning. Extensive experiments
on five advanced MoE models demonstrate the efficacy of our method across
various NLP tasks. Notably, \textbf{DiEP} retains around 92\% of original
performance on Mixtral 8$\times$7B with only half the experts, outperforming
other pruning methods by up to 7.1\% on the challenging MMLU dataset.

</details>


### [162] [It Depends: Resolving Referential Ambiguity in Minimal Contexts with Commonsense Knowledge](https://arxiv.org/abs/2509.16107)
*Lukas Ellinger,Georg Groh*

Main category: cs.CL

TL;DR: LLMs 在解决多轮对话中的指代消解歧义时存在困难，尤其是在简化语言提示下，但通过 DPO 微调 Llama-3.1-8B 可显著提高其性能。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（LLMs）是否能利用常识知识来解决多轮对话中的指代歧义，并分析在歧义持续存在时模型的行为，以及简化语言请求如何影响这一能力。

Method: 使用新的多语言评估数据集，通过 LLM-as-Judge 和人类注释测试 DeepSeek v3、GPT-4o、Qwen3-32B、GPT-4o-mini 和 Llama-3.1-8B 模型。

Result: 当前 LLMs 在解决歧义方面存在困难，倾向于固定一种解释或涵盖所有可能，而非采取模糊或寻求澄清的策略。简化语言提示会加剧这一问题，减少常识推理和多样化响应。对 Llama-3.1-8B 进行 DPO 微调后，在所有请求类型下消解歧义的能力均得到显著提升。

Conclusion: LLMs 在处理歧义方面需要更高级的微调技术，以在不同沟通风格下保证稳健的性能。

Abstract: Ambiguous words or underspecified references require interlocutors to resolve
them, often by relying on shared context and commonsense knowledge. Therefore,
we systematically investigate whether Large Language Models (LLMs) can leverage
commonsense to resolve referential ambiguity in multi-turn conversations and
analyze their behavior when ambiguity persists. Further, we study how requests
for simplified language affect this capacity. Using a novel multilingual
evaluation dataset, we test DeepSeek v3, GPT-4o, Qwen3-32B, GPT-4o-mini, and
Llama-3.1-8B via LLM-as-Judge and human annotations. Our findings indicate that
current LLMs struggle to resolve ambiguity effectively: they tend to commit to
a single interpretation or cover all possible references, rather than hedging
or seeking clarification. This limitation becomes more pronounced under
simplification prompts, which drastically reduce the use of commonsense
reasoning and diverse response strategies. Fine-tuning Llama-3.1-8B with Direct
Preference Optimization substantially improves ambiguity resolution across all
request types. These results underscore the need for advanced fine-tuning to
improve LLMs' handling of ambiguity and to ensure robust performance across
diverse communication styles.

</details>


### [163] [CodeRAG: Finding Relevant and Necessary Knowledge for Retrieval-Augmented Repository-Level Code Completion](https://arxiv.org/abs/2509.16112)
*Sheng Zhang,Yifan Ding,Shuquan Lian,Shun Song,Hui Li*

Main category: cs.CL

TL;DR: CodeRAG通过改进的检索增强方法，显著提升了代码补全的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于代码大语言模型的代码补全方法在查询构建、代码检索和模型对齐方面存在问题。

Method: 提出CodeRAG框架，包含对数概率引导的查询构建、多路径代码检索和偏好对齐的BestFit重排。

Result: 在ReccEval和CCEval基准测试中，CodeRAG显著优于现有方法。

Conclusion: CodeRAG框架能有效解决现有代码补全方法的不足，并取得更好的效果。

Abstract: Repository-level code completion automatically predicts the unfinished code
based on the broader information from the repository. Recent strides in Code
Large Language Models (code LLMs) have spurred the development of
repository-level code completion methods, yielding promising results.
Nevertheless, they suffer from issues such as inappropriate query construction,
single-path code retrieval, and misalignment between code retriever and code
LLM. To address these problems, we introduce CodeRAG, a framework tailored to
identify relevant and necessary knowledge for retrieval-augmented
repository-level code completion. Its core components include log probability
guided query construction, multi-path code retrieval, and preference-aligned
BestFit reranking. Extensive experiments on benchmarks ReccEval and CCEval
demonstrate that CodeRAG significantly and consistently outperforms
state-of-the-art methods. The implementation of CodeRAG is available at
https://github.com/KDEGroup/CodeRAG.

</details>


### [164] [CultureScope: A Dimensional Lens for Probing Cultural Understanding in LLMs](https://arxiv.org/abs/2509.16188)
*Jinghao Zhang,Sihang Jiang,Shiwei Guo,Shisong Chen,Yanghua Xiao,Hongwei Feng,Jiaqing Liang,Minggui HE,Shimin Tao,Hongxia Ma*

Main category: cs.CL

TL;DR: LLMs的文化理解能力评估至关重要，但现有基准测试存在局限性。本文提出了CultureScope，一个基于文化冰山理论的全面评估框架，通过新颖的维度模式指导知识库和评估数据集的构建，可适应不同语言和文化。实验证明该方法有效，并揭示了现有LLMs的文化能力不足，多语言数据并不直接等同于文化理解。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在不同文化环境下的理解能力，以确保其应用的可靠性和文化适应性。现有基准测试缺乏全面性、可扩展性和适应性，且依赖专家手动标注。

Method: 提出CultureScope评估框架，借鉴文化冰山理论，设计了包含3层140个维度的文化知识分类模式，用于自动化构建特定文化知识库和评估数据集。

Result: 实验结果表明，CultureScope能有效评估LLMs的文化理解能力。现有LLMs普遍缺乏全面的文化能力，仅包含多语言数据并不一定能提升文化理解。

Conclusion: LLMs在文化理解方面仍有很大提升空间，多语言数据并非万能。CultureScope提供了一个全面且可扩展的评估框架。

Abstract: As large language models (LLMs) are increasingly deployed in diverse cultural
environments, evaluating their cultural understanding capability has become
essential for ensuring trustworthy and culturally aligned applications.
However, most existing benchmarks lack comprehensiveness and are challenging to
scale and adapt across different cultural contexts, because their frameworks
often lack guidance from well-established cultural theories and tend to rely on
expert-driven manual annotations. To address these issues, we propose
CultureScope, the most comprehensive evaluation framework to date for assessing
cultural understanding in LLMs. Inspired by the cultural iceberg theory, we
design a novel dimensional schema for cultural knowledge classification,
comprising 3 layers and 140 dimensions, which guides the automated construction
of culture-specific knowledge bases and corresponding evaluation datasets for
any given languages and cultures. Experimental results demonstrate that our
method can effectively evaluate cultural understanding. They also reveal that
existing large language models lack comprehensive cultural competence, and
merely incorporating multilingual data does not necessarily enhance cultural
understanding. All code and data files are available at
https://github.com/HoganZinger/Culture

</details>


### [165] [RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation](https://arxiv.org/abs/2509.16198)
*Jane Luo,Xin Zhang,Steven Liu,Jie Wu,Yiming Huang,Yangyu Huang,Chengyu Yin,Ying Xin,Jianfeng Liu,Yuefeng Zhan,Hao Sun,Qi Chen,Scarlett Li,Mao Yang*

Main category: cs.CL

TL;DR: 本论文提出了一种名为 RPG 的新方法，用于解决从头开始生成整个代码库的挑战，并通过 ZeroRepo 框架实现了这一目标，在实际项目基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 由于自然语言的模糊性和冗长性，大型语言模型在生成完整代码库方面存在挑战，无法有效地表示复杂的软件结构，因此需要一种新的方法来解决此问题。

Method: 提出了一种名为仓库规划图（RPG）的持久化表示方法，该方法将能力、文件结构、数据流和函数统一在一个图中，取代了模糊的自然语言。在此基础上，开发了 ZeroRepo 框架，该框架通过三个阶段（提案级规划、实现级细化和图引导代码生成）来生成代码库，并使用测试验证。

Result: 在 RepoCraft 基准测试中，ZeroRepo 生成的代码库平均包含近 36,000 行代码，比最强的基线（Claude Code）高约 3.9 倍，比其他基线高约 64 倍。在功能覆盖率和测试通过率方面，ZeroRepo 分别达到了 81.5% 和 69.7%，分别比 Claude Code 高 27.3 和 35.8 个百分点。

Conclusion: RPG 能够对复杂的依赖关系进行建模，通过近线性扩展实现日益复杂的规划，并增强大型语言模型对代码库的理解，从而加速代理本地化。ZeroRepo 在代码库生成方面取得了显著的成功。

Abstract: Large language models excel at function- and file-level code generation, yet
generating complete repositories from scratch remains a fundamental challenge.
This process demands coherent and reliable planning across proposal- and
implementation-level stages, while natural language, due to its ambiguity and
verbosity, is ill-suited for faithfully representing complex software
structures. To address this, we introduce the Repository Planning Graph (RPG),
a persistent representation that unifies proposal- and implementation-level
planning by encoding capabilities, file structures, data flows, and functions
in one graph. RPG replaces ambiguous natural language with an explicit
blueprint, enabling long-horizon planning and scalable repository generation.
Building on RPG, we develop ZeroRepo, a graph-driven framework for repository
generation from scratch. It operates in three stages: proposal-level planning
and implementation-level refinement to construct the graph, followed by
graph-guided code generation with test validation. To evaluate this setting, we
construct RepoCraft, a benchmark of six real-world projects with 1,052 tasks.
On RepoCraft, ZeroRepo produces repositories averaging nearly 36K LOC, roughly
3.9$\times$ the strongest baseline (Claude Code) and about 64$\times$ other
baselines. It attains 81.5% functional coverage and a 69.7% pass rate,
exceeding Claude Code by 27.3 and 35.8 percentage points, respectively. Further
analysis shows that RPG models complex dependencies, enables progressively more
sophisticated planning through near-linear scaling, and enhances LLM
understanding of repositories, thereby accelerating agent localization.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [166] [Digital Engineering Transformation as a Sociotechnical Challenge: Categorization of Barriers and Their Mapping to DoD's Policy Goals](https://arxiv.org/abs/2509.15461)
*Md Doulotuzzaman Xames,Taylan G. Topcu*

Main category: cs.ET

TL;DR: DE转型面临社会技术障碍，仅靠技术投入不足以成功。


<details>
  <summary>Details</summary>
Motivation: DE转型旨在整合分析模型和数字制品，以改进可追溯性和系统生命周期管理，但许多倡议效果不佳或失败，原因是未能充分理解社会和技术障碍及其相互作用。

Method: 通过文献回顾和基于社会技术系统理论，识别并组织了六个维度的DE障碍：人员、流程、文化、目标、基础设施和技术。随后，将这些障碍映射到美国国防部的DE政策目标。

Result: 技术投资本身不足以实现DE的目标，失败案例常常源于人员、领导支持和文化认同等社会因素。社会技术障碍可能跨越多个维度，影响难以追踪，并使实施复杂化。

Conclusion: DE转型需要综合考虑社会和技术因素，而不仅仅是技术投入。管理者可利用障碍映射来识别风险，政策制定者需在战略指令之外进行持续投入和长期变革管理，工程师应视DE为协作的机会。

Abstract: Digital Engineering (DE) transformation represents a paradigm shift in
systems engineering (SE), aiming to integrate diverse analytical models and
digital artifacts into an authoritative source of truth for improved
traceability and more efficient system lifecycle management. Despite
institutional support, many DE initiatives underperform or fail to realize
their intended benefits. We argue that this often results from a limited
understanding of the social and technical barriers, and particularly how their
interplay shapes transformation outcomes. To address this gap, we document
barriers identified in the literature and grounded in sociotechnical systems
theory, organized into six dimensions: people, processes, culture, goals,
infrastructure, and technology. We then map these barriers to the U.S.
Department of Defense's DE policy goals. Our analysis shows that technological
investments alone are insufficient, as failures frequently arise from social
factors such as workforce readiness, leadership support, and cultural
alignment. The mapping also demonstrates that sociotechnical barriers often
cascade across dimensions, making their impact on policy goals difficult to
trace and complicating implementation. These insights carry practical
implications: managers may use the mapping as a diagnostic tool to identify
risks and prioritize resources; policymakers may complement strategic mandates
with sustained investments and long-term change management; and engineers may
view DE not as a threat to job security but as an opportunity for more
effective collaboration.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [167] [Two Optimizations on the Stålmarck Procedure](https://arxiv.org/abs/2509.16172)
*Sergei Leonov,Liam Davis*

Main category: cs.LO

TL;DR: StalmarckSAT is a re-implementation of the Stå lmarck Procedure with two new strategies, CDB and DPO, that improve solve times.


<details>
  <summary>Details</summary>
Motivation: The paper aims to improve the Stå lmarck Procedure for SAT solving by introducing two novel strategies: Cardinality Driven Branching (CDB) and Deductive Priority Ordering (DPO).

Method: The paper presents StalmarckSAT, a modern re-implementation of the Stå lmarck Procedure, and incorporates two new strategies: CDB, a heuristic to improve branching with the dilemma rule, and DPO, which intelligently orders simple rules based on their deductive potential.

Result: The implemented strategies, CDB and DPO, demonstrate improved solve times in the experiments.

Conclusion: The novel strategies CDB and DPO integrated into StalmarckSAT lead to improved performance in SAT solving.

Abstract: In this paper, we introduce StalmarckSAT, the a modern re-implementation of
the St\aa lmarck Procedure for SAT solving, and present two novel strategies to
improve the Procedure, Cardinality Driven Branching (CDB) and Deductive
Priority Ordering (DPO). CDB is a heuristic to improve branching with the
dilemma rule, and DPO intelligently orders simple rules based on their
deductive potential. Our results demonstrate improved solve times with both
strategies.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [168] [PCCL: Photonic circuit-switched collective communication for distributed ML](https://arxiv.org/abs/2509.15450)
*Abhishek Vijaya Kumar,Arjun Devraj,Rachee Singh*

Main category: cs.DC

TL;DR: PCCL是一个光互连通信库，通过动态调整网络拓扑以匹配通信模式，解决了分布式机器学习中的性能瓶颈，实现了高达3倍的加速。


<details>
  <summary>Details</summary>
Motivation: 分布式机器学习在实际GPU集群中存在理论与实现性能之间的差距，主要是由于拥塞和跳数延迟。PCCL旨在解决这个问题。

Method: PCCL通过重构网络拓扑来匹配通信模式，为通信GPU创建直接、无冲突的电路，从而消除拥塞和延迟。它采用硬件无关的优化框架，根据网络重构延迟和拥塞/延迟成本之间的权衡来决定何时重构。

Result: 在128个GPU上，PCCL在各种工作负载、缓冲区大小和拓扑结构上实现了高达3倍的加速，端到端训练吞吐量提高了1.3倍。

Conclusion: PCCL通过动态适应网络拓扑来匹配通信模式，解决了分布式机器学习中的性能瓶颈，并在实际应用中取得了显著的加速效果。

Abstract: Modern distributed ML suffers from a fundamental gap between the theoretical
and realized performance of collective communication algorithms due to
congestion and hop-count induced dilation in practical GPU clusters. We present
PCCL, a Photonic Collective Communication Library that reconfigures the network
topology to match the communication patterns of collective algorithms, thereby
eliminating congestion and dilation by creating direct, contention-free
circuits between communicating GPUs. Unlike prior approaches that synthesize
algorithms for specific network topologies and collectives, PCCL generalizes to
any collective primitive and any topology by adapting the network to match each
algorithm's communication pattern. PCCL's key innovation lies in its
hardware-agnostic optimization framework that intelligently decides when to
reconfigure based on the trade-off between network reconfiguration delay and
congestion/dilation costs, making it practical across different optical
hardware with varying switching speeds. Our evaluation demonstrates that PCCL
achieves up to 3X speedup over state-of-the-art algorithms on 128 GPUs across
various workloads, buffer sizes, and topologies, translating to a 1.3X speedup
in end-to-end training throughput.

</details>


### [169] [Angelfish: Consensus with Optimal Throughput and Latency Across the Leader-DAG Spectrum](https://arxiv.org/abs/2509.15847)
*Qianyu Yu,Giuliano Losa,Nibesh Shrestha,Xuechao Wang*

Main category: cs.DC

TL;DR: Angelfish是一种新的混合共识协议，它结合了基于领导者和基于DAG的共识协议的优点，在保持高吞吐量的同时，显著降低了延迟。


<details>
  <summary>Details</summary>
Motivation: 现代区块链系统在性能最大化方面面临挑战，现有协议在延迟和吞吐量之间存在权衡。需要一种能够平稳适应不同设计空间（从基于领导者到基于DAG）并能在两者之间取得良好平衡的协议。

Method: Angelfish协议采用一种混合方法，允许动态调整的节点子集使用“尽力而为广播”来发送轻量级投票，而不是广播成本较高的DAG顶点。这种方法减少了通信量，帮助滞后节点赶上，并降低了实际延迟。

Result: Angelfish在保持最高吞吐量的同时，在中等吞吐量下达到了与基于领导者协议相当的延迟，并且在实际应用中延迟低于之前的基于DAG的协议。

Conclusion: Angelfish成功地结合了基于领导者和基于DAG的共识协议的优点，提供了一种高性能的解决方案，在各种负载条件下都能实现低延迟和高吞吐量。

Abstract: To maximize performance, many modern blockchain systems rely on
eventually-synchronous, Byzantine fault-tolerant (BFT) consensus protocols. Two
protocol designs have emerged in this space: protocols that minimize latency
using a leader that drives both data dissemination and consensus, and protocols
that maximize throughput using a separate, asynchronous data dissemination
layer. Recent protocols such as Partially-Synchronous Bullshark and Sailfish
combine elements of both approaches by using a DAG to enable parallel data
dissemination and a leader that paces DAG formation. This improves latency
while achieving state-of-the-art throughput. Yet the latency of leader-based
protocols is still better under moderate loads.
  We present Angelfish, a hybrid protocol that adapts smoothly across this
design space, from leader-based to Sailfish-like DAG-based consensus. Angelfish
lets a dynamically-adjusted subset of parties use best-effort broadcast to
issue lightweight votes instead of reliably broadcasting costlier DAG vertices.
This reduces communication, helps lagging nodes catch up, and lowers latency in
practice compared to prior DAG-based protocols. Our empirical evaluation shows
that Angelfish attains state-of-the-art peak throughput while matching the
latency of leader-based protocols under moderate throughput, delivering the
best of both worlds.

</details>


### [170] [Efficient Pre-Training of LLMs via Topology-Aware Communication Alignment on More Than 9600 GPUs](https://arxiv.org/abs/2509.15940)
*Guoliang He,Youhe Jiang,Wencong Xiao,Kaihua Jiang,Shuguang Wang,Jun Wang,Zixian Du,Zhuo Jiang,Xinlei Zhang,Binhang Yuan,Eiko Yoneki*

Main category: cs.DC

TL;DR: Arnold是一个调度系统，可将LLM通信模式与大规模数据中心拓扑对齐，从而提高LLM预训练的性能。


<details>
  <summary>Details</summary>
Motivation: LLM预训练面临通信模式复杂、带宽争用和资源调度效率低下等挑战，导致训练性能不佳。

Method: 通过对物理网络拓扑对LLM预训练作业影响的深入研究，开发了一种调度算法，以有效地将通信模式与现代数据中心的物理网络拓扑对齐。

Result: 模拟实验表明，该算法可将通信组的最大传播范围减少多达1.67倍。在生产环境中，该调度系统在超过9600个GPU上训练时，端到端性能提高了10.6%。

Conclusion: Arnold调度系统通过将LLM通信模式与数据中心拓扑进行有效对齐，显著提高了大规模LLM预训练的性能。

Abstract: The scaling law for large language models (LLMs) depicts that the path
towards machine intelligence necessitates training at large scale. Thus,
companies continuously build large-scale GPU clusters, and launch training jobs
that span over thousands of computing nodes. However, LLM pre-training presents
unique challenges due to its complex communication patterns, where GPUs
exchange data in sparse yet high-volume bursts within specific groups.
Inefficient resource scheduling exacerbates bandwidth contention, leading to
suboptimal training performance. This paper presents Arnold, a scheduling
system summarizing our experience to effectively align LLM communication
patterns with data center topology at scale. An in-depth characteristic study
is performed to identify the impact of physical network topology to LLM
pre-training jobs. Based on the insights, we develop a scheduling algorithm to
effectively align communication patterns with the physical network topology in
modern data centers. Through simulation experiments, we show the effectiveness
of our algorithm in reducing the maximum spread of communication groups by up
to $1.67$x. In production training, our scheduling system improves the
end-to-end performance by $10.6\%$ when training with more than $9600$ GPUs, a
significant improvement for our training pipeline.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [171] [Automatic Microarchitecture-Aware Custom Instruction Design for RISC-V Processors](https://arxiv.org/abs/2509.15782)
*Evgenii Rezunov,Niko Zurstraßen,Lennart M. Reimann,Rainer Leupers*

Main category: cs.AR

TL;DR: CIDRE是一款用于RISC-V ASIP设计的自动化工具，能够自动分析应用热点并生成定制指令建议，从而在不显著增加面积的情况下提高性能。


<details>
  <summary>Details</summary>
Motivation: ASIP设计中寻找能够提升性能但又不过度增加面积和功耗的定制指令是一个重要的挑战，目前该过程劳动密集且通常需要手动完成，缺乏自动化。

Method: CIDRE工具通过自动分析RISC-V应用程序中的热点，并生成定制指令建议及其nML描述，以便与其他EDA工具结合，精确评估建议的成本效益。

Result: 在RISC-V基准测试研究中，CIDRE能够将Embench和MiBench的嵌入式基准测试性能最高提升2.47倍，同时面积仅增加了不到24%。

Conclusion: CIDRE成功实现了ASIP设计的自动化，能够有效加速RISC-V应用程序，并在性能提升和硬件成本之间取得良好平衡。

Abstract: An Application-Specific Instruction Set Processor(ASIP) is a specialized
microprocessor that provides a trade-off between the programmability of a
General Purpose Processor (GPP) and the performance and energy-efficiency of
dedicated hardware accelerators. ASIPs are often derived from off-the-shelf
GPPs extended by custom instructions tailored towards a specific software
workload. One of the most important challenges of designing an ASIP is to find
said custom instructions that help to increase performance without being too
costly in terms of area and power consumption. To date, solving this challenge
is relatively labor-intensive and typically performed manually. Addressing the
lack of automation, we present Custom Instruction Designer for RISC-V
Extensions (CIDRE), a front-to-back tool for ASIP design. CIDRE automatically
analyzes hotspots in RISC-V applications and generates custom instruction
suggestions with a corresponding nML description. The nML description can be
used with other electronic design automation tools to accurately assess the
cost and benefits of the found suggestions. In a RISC-V benchmark study, we
were able to accelerate embedded benchmarks from Embench and MiBench by up to
2.47x with less than 24% area increase. The entire process was conducted
completely automatically.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [172] [(SP)$^2$-Net: A Neural Spatial Spectrum Method for DOA Estimation](https://arxiv.org/abs/2509.15475)
*Lioz Berman,Sharon Gannot,Tom Tirer*

Main category: eess.SP

TL;DR: 提出一种基于深度学习的单快拍多源DOA估计算法(SP)^2-Net，以克服Bartlett波束形成器的孔径限制，生成高分辨率空间谱。


<details>
  <summary>Details</summary>
Motivation: 单快拍场景下，Bartlett波束形成器受限于阵列孔径，而最大似然估计和基于样本协方差的谱估计方法不适用。

Method: 训练一个深度神经网络，输入测量值和假设角度，输出与更宽阵列能力一致的分数，用于生成高分辨率空间谱。

Result: 所提(SP)^2-Net算法在单快拍下相比Bartlett波束形成器和基于稀疏性的DOA估计算法具有更高的分辨率和精度。

Conclusion: 深度学习方法能够有效提升单快拍DOA估计的分辨率和精度，克服传统方法的局限性。

Abstract: We consider the problem of estimating the directions of arrival (DOAs) of
multiple sources from a single snapshot of an antenna array, a task with many
practical applications. In such settings, the classical Bartlett beamformer is
commonly used, as maximum likelihood estimation becomes impractical when the
number of sources is unknown or large, and spectral methods based on the sample
covariance are not applicable due to the lack of multiple snapshots. However,
the accuracy and resolution of the Bartlett beamformer are fundamentally
limited by the array aperture. In this paper, we propose a deep learning
technique, comprising a novel architecture and training strategy, for
generating a high-resolution spatial spectrum from a single snapshot.
Specifically, we train a deep neural network that takes the measurements and a
hypothesis angle as input and learns to output a score consistent with the
capabilities of a much wider array. At inference time, a heatmap can be
produced by scanning an arbitrary set of angles. We demonstrate the advantages
of our trained model, named (SP)$^2$-Net, over the Bartlett beamformer and
sparsity-based DOA estimation methods.

</details>


### [173] [CSIT-Free Downlink Transmission for mmWave MU-MISO Systems in High-Mobility Scenario](https://arxiv.org/abs/2509.15564)
*Jeongjae Lee,Wonseok Choi,Songnam Hong*

Main category: eess.SP

TL;DR: 本篇论文提出了一种无需信道状态信息（CSIT）的毫米波（mmWave）多用户多输入单输出（MU-MISO）系统下行（DL）传输新框架，特别是在高速移动场景下，通过符号检测和同时的信道状态信息（CSIR）及多普勒频移估计来消除干扰并获得全分集合成增益。


<details>
  <summary>Details</summary>
Motivation: 在毫米波（mmWave）多用户多输入单输出（MU-MISO）系统的快速移动场景下，传统的下行（DL）传输需要获取信道状态信息（CSIT），而这个过程会产生巨大的开销，并且在极短的信道相干时间内难以完成。因此，需要一种能够消除CSIT获取开销并充分利用信道相干时间的新型DL传输框架。

Method: 提出了一种无需CSIT的DL传输框架。该框架利用了毫米波信道的特性和独特设计的无CSIT幺正预编码，并提出了一种符号检测方法，同时进行接收端的信道状态信息（CSIR）和多普勒频移估计，以完全消除干扰并实现全分集合成增益。

Result: 通过仿真证明了所提出的方法与现有基线方法相比是有效的。

Conclusion: 所提出的无需CSIT的DL传输框架在毫米波MU-MISO系统的快速移动场景下是有效的，能够消除信道状态信息获取的开销，并在短时间内实现高性能的传输。

Abstract: This paper investigates the downlink (DL) transmission in millimeter-wave
(mmWave) multi-user multiple-input single-output (MU-MISO) systems especially
focusing on a high speed mobile scenario. To complete the DL transmission
within an extremely short channel coherence time, we propose a novel DL
transmission framework that eliminates the need for channel state information
at the transmitter (CSIT), of which acquisition process requires a substantial
overhead, instead fully exploiting the given channel coherence time. Harnessing
the characteristic of mmWave channel and uniquely designed CSIT-free unitary
precoding, we propose a symbol detection method along with the simultaneous CSI
at the receiver (CSIR) and Doppler shift estimation method to completely cancel
the interferences while achieving a full combining gain. Via simulations, we
demonstrate the effectiveness of the proposed method comparing with the
existing baselines.

</details>


### [174] [Twisting Signals for Joint Radar-Communications: An OAM Vortex Beam Approach](https://arxiv.org/abs/2509.15601)
*Wanghan Lv,Kumar Vijay Mishra,Jinsong Hu*

Main category: eess.SP

TL;DR: 提出了一种基于OAM的毫米波联合雷达通信（JRC）系统，用于汽车雷达和车对车通信，该系统使用ULA和行波天线同时产生多个LG涡旋光束，并提出了相应的目标参数估计和通信恢复策略，以及性能分析。


<details>
  <summary>Details</summary>
Motivation: OAM技术因其独特的螺旋相位和模式正交性，在无线通信和雷达系统中具有提升性能的潜力，但现有OAM系统大多基于UCA，本文旨在探索OAM在JRC系统中的新应用。

Method: 提出了一种基于ULA的OAM空间调制方案，利用行波天线同时产生多个LG涡旋光束，构建了OAM-JRC模型，设计了仅使用雷达帧的目标参数估计算法，并提出了OAM模式划分复用策略以保证通信的可识别性和恢复，最后通过理论分析和数值实验验证了系统性能。

Result: 推导了雷达目标参数的恢复保证和Cramér-Rao下界（CRLB），并评估了通信的误码率（BER），数值实验验证了所提OAM-JRC系统和参数估计方法的有效性。

Conclusion: 所提出的OAM-JRC系统能够有效地集成汽车雷达和V2V通信功能，并通过新颖的OAM调制和复用策略实现了雷达参数估计和通信信息恢复的协同优化。

Abstract: Orbital angular momentum (OAM) technology has attracted much research
interest in recent years because of its characteristic helical phase front
twisting around the propagation axis and natural orthogonality among different
OAM states to encode more degrees of freedom than classical planar beams.
Leveraging upon these features, OAM technique has been applied to wireless
communication systems to enhance spectral efficiency and radar systems to
distinguish spatial targets without beam scanning. Leveraging upon these unique
properties, we propose an OAM-based millimeter-wave joint radar-communications
(JRC) system comprising a bi-static automotive radar and vehicle-to-vehicle
(V2V) communications. Different from existing uniform circular array (UCA)
based OAM systems where each element is an isotropic antenna, an OAM spatial
modulation scheme utilizing a uniform linear array (ULA) is adopted with each
element being a traveling-wave antenna, producing multiple Laguerre-Gaussian
(LG) vortex beams simultaneously. Specifically, we first build a novel
bi-static automotive OAM-JRC model that embeds communication messages in a
radar signal, following which a target position and velocity parameters
estimation algorithm is designed with only radar frames. Then, an OAM-based
mode-division multiplexing (MDM) strategy between radar and JRC frames is
presented to ensure the JRC parameters identifiability and recovery.
Furthermore, we analyze the performance of the JRC system through deriving
recovery guarantees and Cram\'er-Rao lower bound (CRLB) of radar target
parameters and evaluating the bit error rate (BER) of communication,
respectively. Our numerical experiments validate the effectiveness of the
proposed OAM-based JRC system and parameter estimation method.

</details>


### [175] [Blind Source Separation of Radar Signals in Time Domain Using Deep Learning](https://arxiv.org/abs/2509.15603)
*Sven Hinderer*

Main category: eess.SP

TL;DR: 该研究提出了一种新的时域盲信号分离方法，并利用监督训练的神经网络来处理雷达信号的去交织问题，能够有效分离重叠的雷达和通信信号，即使是连续波信号也能处理，并且仅需单通道接收机。


<details>
  <summary>Details</summary>
Motivation: 在复杂电磁环境下，准确识别和分离雷达信号对于电子对抗至关重要，特别是当信号来自同一方向且频率相近时，信号分离（去交织）面临巨大挑战。

Method: 将雷达信号去交织问题视为时域盲信号分离问题，并应用监督训练的神经网络进行处理。该方法借鉴了音频源分离领域的先进模型，并进行了扩展以适应任意射频（RF）信号的去交织需求。

Result: 实验结果表明，该方法能够成功分离出单通道接收机接收到的、在给定频带内混合的两种未知波形。

Conclusion: 该研究提出的基于深度学习的时域盲信号分离方法，为解决雷达信号去交织难题提供了有效途径，尤其在处理高度重叠和连续波信号方面具有显著优势。

Abstract: Identification and further analysis of radar emitters in a contested
environment requires detection and separation of incoming signals. If they
arrive from the same direction and at similar frequencies, deinterleaving them
remains challenging. A solution to overcome this limitation becomes
increasingly important with the advancement of emitter capabilities. We propose
treating the problem as blind source separation in time domain and apply
supervisedly trained neural networks to extract the underlying signals from the
received mixture. This allows us to handle highly overlapping and also
continuous wave (CW) signals from both radar and communication emitters. We
make use of advancements in the field of audio source separation and extend a
current state-of-the-art model with the objective of deinterleaving arbitrary
radio frequency (RF) signals. Results show, that our approach is capable of
separating two unknown waveforms in a given frequency band with a single
channel receiver.

</details>


### [176] [Wireless Sensing with Movable Intelligent Surface](https://arxiv.org/abs/2509.15627)
*Ziyuan Zheng,Qingqing Wu,Yanze Zhu,Wen Chen,Ying Gao,Honghao Wang*

Main category: eess.SP

TL;DR: 本论文提出了一种低成本的可移动智能表面（MIS）用于无线传感，通过机械重构代替电子调谐，实现了多目标检测。


<details>
  <summary>Details</summary>
Motivation: 现有可重构智能表面（RIS）的电子调谐硬件成本和功耗高，但其在无线传感方面前景广阔。受流体天线系统（FAS）的启发，需要一种低成本的解决方案。

Method: 提出了一种低成本的可移动智能表面（MIS），它堆叠了一个固定和一个可移动的预相位超表面层。通过改变可移动层的相对位置来合成不同的复合相位模式，从而实现多波束模式以进行多目标检测。建立了MIS使能的多跳回波信号模型，并考虑了多目标干扰。然后，制定了一个最差情况下的信噪比（SINR）最大化问题，该问题联合设计MIS的相移和调度MS2的位置。开发了一种基于流形增广拉格朗日方法（RALM）的算法来解决混合整数非凸问题。还推导了一种具有封闭形式相位分布和位置调度的启发式MIS波束转向设计。

Result: 模拟验证了MIS的波束模式重构能力。结果表明，基于RALM的方案在提高传感SINR方面显著优于封闭形式方案。此外，研究揭示了波束模式中的增益-分集权衡，为选择最佳MIS配置提供了依据。

Conclusion: MIS通过机械重构提供了一种低成本、高效率的无线传感解决方案，能够通过优化相位和位置调度来显著提高传感性能，并且其增益-分集特性为实际应用提供了优化指导。

Abstract: Future wireless networks are envisioned to deliver not only gigabit
communications but also ubiquitous sensing. Reconfigurable intelligent surfaces
(RISs) have emerged to reshape radio propagation, recently showing considerable
promise for wireless sensing. Still, their per-element electronic tuning incurs
prohibitive hardware cost and power consumption. Motivated by the concept of
fluid antenna system (FAS), this paper introduces a low-cost movable
intelligent surface (MIS) for wireless sensing, which replaces element-wise
electronic phase tuning with panel-wise mechanical reconfiguration. The MIS
stacks a large fixed and a smaller movable pre-phased metasurface layers, whose
differential position shifts synthesize distinct composite phase patterns,
enabling multiple beam patterns for multi-target detection. We characterize a
MIS-enabled multi-hop echo signal model with multi-target interference and then
formulate a worst-case sensing signal-to-interference-plus-noise ratio (SINR)
maximization problem that jointly designs MIS phase shifts and schedules MS2's
position. A Riemannian Augmented Lagrangian Method (RALM)-based algorithm is
developed to solve the formulated mixed-integer non-convex problem. We also
derive a heuristic MIS beam steering design with closed-form phase distribution
and position scheduling. Simulations validate MIS's beam pattern
reconfiguration capability, show that the RALM-based scheme significantly
outperforms the closed-form scheme in improving sensing SINR, and uncover a
gain-diversity trade-off in beam patterns that informs the optimal choice of
MIS configuration.

</details>


### [177] [Optimizing Sparse Antenna Arrays for Localization and Sensing using Vector Spherical Wave Functions](https://arxiv.org/abs/2509.15636)
*Tobias Lafer,Erik Leitinger,Klaus Witrisal*

Main category: eess.SP

TL;DR: 该研究提出了一种利用Cramér-Rao下界（CRLB）和矢量球波函数（VSWFs）系统优化移动和物联网应用设备中小天线阵列布局和方向以获得最佳定位性能的方法。


<details>
  <summary>Details</summary>
Motivation: 在电子设备中，特别是移动和物联网设备中，天线数量的增加和空间的限制之间的矛盾日益突出，因此需要优化稀疏天线阵列的布局以获得最佳的定位性能。

Method: 提出了一种利用Cramér-Rao下界（CRLB）和矢量球波函数（VSWFs）来优化稀疏天线阵列布局和方向的方法。VSWFs建立了考虑频率、方向和极化依赖特性、互耦及周围障碍物畸变的宽带信号模型。在加性白高斯噪声信道条件下，推导了该模型的定位参数（如到达角和到达时间）的CRLB，并提出了通过最小化CRLB来确定天线最优位置和方向的优化问题。

Result: 通过一个包含三个交叉指数锥形槽（XETS）天线的示例性布置，演示了所提出的优化过程。

Conclusion: 该研究提出了一种系统性的方法来优化小天线阵列在电子设备中的布局，以提高定位性能。

Abstract: In increasing number of electronic devices implement wideband radio
technologies for localization and sensing purposes, like ultra-wideband (UWB).
Such radio technologies benefit from a large number of antennas, but space for
antennas is often limited, especially in devices for mobile and IoT
applications. A common challenge is therefore to optimize the placement and
orientations of a small number of antenna elements inside a device, leading to
the best localization performance. We propose a method for systematically
approaching the optimization of such sparse arrays by means of Cram\'er-Rao
lower bounds (CRLBs) and vector spherical wave functions (VSWFs). The VSWFs
form the basis of a wideband signal model considering frequency, direction and
polarization-dependent characteristics of the antenna array under test (AUT),
together with mutual coupling and distortions from surrounding obstacles. We
derive the CRLBs for localization parameters like delay and angle-of-arrival
for this model under additive white Gaussian noise channel conditions, and
formulate optimization problems for determining optimal antenna positions and
orientations via minimization of the CRLBs. The proposed optimization procedure
is demonstrated by means of an exemplary arrangement of three Crossed
Exponentially Tapered Slot (XETS) antennas.

</details>


### [178] [Hybrid Baseband Simulation for Single-Channel Radar-Based Indoor Localization System](https://arxiv.org/abs/2509.15650)
*Sven Hinderer,Zheming Yin,Athanasios Papanikolaou,Jan Hesselbarth,Bin Yang*

Main category: eess.SP

TL;DR: 毫米波单通道雷达可实现高精度室内定位，并结合射线追踪和天线增益测量来模拟基带信号。


<details>
  <summary>Details</summary>
Motivation: 开发一种低成本、高精度的室内定位系统，该系统使用毫米波单通道雷达和主动反射器作为参考。

Method: 提出一种混合雷达基带信号模拟器，模拟单通道雷达的基带接收信号。该模拟器结合了射线追踪信道模拟、天线增益测量以及雷达散射截面模拟。

Result: 实现了在复杂场景下对基带接收信号的真实建模。

Conclusion: 所提出的混合雷达基带信号模拟器能够真实地模拟毫米波单通道雷达的基带接收信号，为室内定位系统的开发提供了有效工具。

Abstract: Indoor localization with chirp sequence radar at millimeter wavelength offers
high localization accuracy at low system cost. We propose a hybrid radar
baseband signal simulator for our novel single-channel radar-based indoor
localization system consisting of an active radar and passive reflectors as
references. By combining ray tracing channel simulations with real measurements
of the two-way antenna gain of the radar and accurate simulation of the radar
cross section of chosen reflectors, realistic modeling of the baseband receive
signal in complex scenarios is achieved.

</details>


### [179] [Extended k-u Fading Model in mmWave Communication: Statistical Properties and Performance Evaluations](https://arxiv.org/abs/2509.15681)
*Jiahuan Wu,Xinchun Yu,Xiao-Ping Zhang*

Main category: eess.SP

TL;DR: 提出了一种名为扩展k-u模型的小尺度衰落模型，该模型通过引入一个新参数来考虑多径簇的不平衡性，优于原始k-u模型，尤其是在视距（LoS）路径场景下，其建模能力比扩展n-u模型更准确，并且比a-k-n-u模型在数学上更易处理。在毫米波通信场景下进行了实验，结果表明扩展k-u模型在拟合测量数据时具有更小的均方误差。此外，还获得了该模型的关键统计特征的闭合形式表达式，并推导和分析了一些通信系统性能指标的表达式。


<details>
  <summary>Details</summary>
Motivation: 为了改进现有的小尺度衰落模型（如k-u模型）在毫米波通信场景下的建模能力，尤其是在考虑多径簇不平衡性方面，提出了一种新的扩展k-u模型。

Method: 通过在原始k-u模型中增加一个新参数来考虑多径簇的不平衡性，形成扩展k-u模型。在28 GHz、65 GHz和92 GHz的毫米波通信场景下进行了实验，并将扩展k-u模型与k-u模型和扩展n-u模型进行了比较。通过理论推导获得了模型的关键统计特征的闭合形式表达式，并推导了通信系统性能指标的表达式。

Result: 扩展k-u模型在拟合毫米波通信场景下的测量数据时，相比k-u模型和扩展n-u模型，均方误差更小。通过理论推导，得到了扩展k-u模型的概率密度函数、累积分布函数、任意阶矩和矩生成函数等关键统计特征的闭合形式表达式。此外，还推导和分析了衰落量、中断概率和平均比特错误率等通信系统性能指标的表达式。

Conclusion: 扩展k-u模型能够更准确地刻画毫米波通信场景下的小尺度衰落，尤其是在存在视距路径的情况下，并且在数学上比a-k-n-u模型更易于处理。该模型及其统计特性和性能指标的分析为毫米波通信系统的设计和优化提供了有价值的参考。

Abstract: This study proposes a small-scale fading model, named the extended k-u model,
which incorporates the imbalance of multipath clusters by adding a new
parameter based on the original k-u model. The extended k-u model outperforms
the k-u model in characterizing small-scale fading in the millimeter-wave
(mmWave) band and has more accurate modeling capability than the extended n-u
model in scenarios with line-of-sight (LoS) paths. And it is mathematically
more tractable than the a-k-n-u model. Experiments are conducted for mmWave
communication scenarios with LoS paths, covering the outdoor 28 GHz band, the
indoor 65 GHz band, and the indoor 92 GHz band. The results demonstrate that
the extended k-u model achieves a smaller mean square error in fitting the
measured data compared to both the k-u model and the extended n-u model across
all scenarios. In addition, through theoretical derivations, closed-form
expressions are obtained for the key statistical characteristics of the
extended k-u model, including the probability density function, cumulative
distribution function, moments of arbitrary order, and moment generating
function. Based on these statistics, this study further derives and analyzes
the expressions for some performance metrics of the communication system,
including the amount of fading, the probability of outage, and the average bit
error rate.

</details>


### [180] [Distributed Multi-Task Learning for Joint Wireless Signal Enhancement and Recognition](https://arxiv.org/abs/2509.15718)
*Hao Zhang,Fuhui Zhou,Qihui Wu,Chau Yuen*

Main category: eess.SP

TL;DR: 该论文提出了一种新颖的分布式多任务学习框架，用于联合无线信号增强和识别（WSER），以解决在低信噪比（SNR）和分布式网络设置下进行信号识别的挑战。


<details>
  <summary>Details</summary>
Motivation: 在现代和未来的无线通信网络中，无线信号识别（WSR）至关重要，因为它旨在以非协作的方式识别接收到的信号的属性。然而，在低信噪比（SNR）条件和分布式网络设置下准确分类信号具有挑战性。

Method: 提出了一种名为WSERNet的新型深度学习模型，并结合了增强的联邦学习算法FedProx+。WSERNet使用非对称卷积块（ACBlock）来捕获输入信号中的长距离依赖关系。FedProx+通过在损失函数中引入一个近邻项来增强模型的收敛速度和鲁棒性。

Result: 实验证明，所提出的联合WSER框架在集中式和分布式设置（包括独立同分布（IID）和非独立同分布（non-IID）数据分布）下，相比现有最先进的方法，取得了更优越的性能。

Conclusion: 该研究成功提出了一种有效的分布式多任务学习框架，用于联合无线信号增强和识别，解决了现有技术在低SNR和分布式环境下的局限性。

Abstract: Wireless signal recognition (WSR) is crucial in modern and future wireless
communication networks since it aims to identify the properties of the received
signal in a no-collaborative manner. However, it is challenging to accurately
classify signals in low signal-to-noise ratio (SNR) conditions and distributed
network settings. In this paper, we propose a novel distributed multi-task
learning framework for joint wireless signal enhancement and recognition
(WSER), addressing the crucial need for non-collaborative signal identification
in modern wireless networks. Our approach integrates a wireless signal
enhancement and recognition network (WSERNet) with FedProx+, an enhanced
federated learning algorithm designed for heterogeneous data distributions.
Specifically, WSERNet leverages an asymmetric convolution block (ACBlock) to
capture long-range dependencies in the input signal and improve the performance
of the deep learning model. FedProx+ introduces a proximal term to the loss
function to encourage the model updates to be closer to the previous model,
enhancing the convergence speed and robustness of federated learning. Extensive
experiments demonstrate the effectiveness of the proposed framework for joint
WSER, achieving superior performance compared to state-of-the-art methods under
both centralized and distributed settings including independent and identically
distributed (IID) and non-IID data distributions.

</details>


### [181] [Explainable Deep Learning Based Adversarial Defense for Automatic Modulation Classification](https://arxiv.org/abs/2509.15766)
*Peihao Dong,Jingchun Wang,Shen Gao,Fuhui Zhou,Qihui Wu*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Deep learning (DL) has been widely applied to enhance automatic modulation
classification (AMC). However, the elaborate AMC neural networks are
susceptible to various adversarial attacks, which are challenging to handle due
to the generalization capability and computational cost. In this article, an
explainable DL based defense scheme, called SHapley Additive exPlanation
enhanced Adversarial Fine-Tuning (SHAP-AFT), is developed in the perspective of
disclosing the attacking impact on the AMC network. By introducing the concept
of cognitive negative information, the motivation of using SHAP for defense is
theoretically analyzed first. The proposed scheme includes three stages, i.e.,
the attack detection, the information importance evaluation, and the AFT. The
first stage indicates the existence of the attack. The second stage evaluates
contributions of the received data and removes those data positions using
negative Shapley values corresponding to the dominating negative information
caused by the attack. Then the AMC network is fine-tuned based on adversarial
adaptation samples using the refined received data pattern. Simulation results
show the effectiveness of the Shapley value as the key indicator as well as the
superior defense performance of the proposed SHAP-AFT scheme in face of
different attack types and intensities.

</details>


### [182] [Fundamental Limits of THz Inter-Satellite ISAC Under Hardware Impairments](https://arxiv.org/abs/2509.15902)
*Haofan Dong,Ozgur B. Akan*

Main category: eess.SP

TL;DR: 本论文提出了太赫兹（THz）低地球轨道（LEO）星间链路（ISL）集成传感与通信（ISAC）系统的理论分析框架，并推导了其性能极限。


<details>
  <summary>Details</summary>
Motivation: 为了分析太赫兹（THz）低地球轨道（LEO）星间链路（ISL）集成传感与通信（ISAC）系统的基本性能极限。

Method: 通过推导统一的端到端信号模型，并进行贝叶斯克拉美-罗下界（BCRLB）分析，同时考虑了轨道动力学、硬件损伤和波束指向误差的影响，并推导了通信容量的解析表达式。

Result: 研究表明，太赫兹ISAC系统的传感精度与载波频率呈二次方关系，但会受到硬件失真的限制；通信性能受硬件限制而非功耗限制，并推导了考虑相位噪声和功率放大器（PA）非线性的容量上限；在200-600 GHz频段可能存在有利的运行条件；PA非线性是主要的性能瓶颈。

Conclusion: 在太赫兹ISAC系统中，PA非线性是关键的性能瓶颈，并且存在一个性能与频率和硬件质量相关的最优工作频段。

Abstract: This paper establishes a theoretical framework for analyzing the fundamental
performance limits of terahertz (THz) Low Earth Orbit (LEO) inter-satellite
link (ISL) Integrated Sensing and Communications (ISAC) systems. We develop a
unified, end-to-end signal model that, jointly captures the effects of extreme
orbital dynamics, cascaded non-ideal hardware impairments, and micro-radian
beam pointing errors. Through Bayesian Cram\'er-Rao Lower Bound (BCRLB)
analysis, we derive the ultimate sensing accuracy for range and range-rate,
revealing a quadratic ($1/f_c^2$) improvement in estimation variance with
carrier frequency, which is ultimately floored by signal-dependent hardware
distortion. For communication, we show that system performance is not
power-limited but hardware-limited, deriving a closed-form capacity ceiling
under the joint effect of phase noise and PA nonlinearity: $C_{\text{sat}} =
\log_2(1 + e^{-\sigma_\phi^2}/\Gamma_{\text{eff}})$, where
$\Gamma_{\text{eff}}$ is a proposed hardware quality factor. Our numerical
results, based on state-of-the-art component data and the identified
trade-offs, suggest that favorable operational conditions may exist in the
sub-THz frequency range (200-600 GHz) where the quadratic sensing gain with
frequency is balanced against hardware quality degradation. Power Amplifier
(PA) nonlinearity emerges as the dominant performance bottleneck, exceeding
other impairments by one to two orders of magnitude.

</details>


### [183] [MoE-CE: Enhancing Generalization for Deep Learning based Channel Estimation via a Mixture-of-Experts Framework](https://arxiv.org/abs/2509.15964)
*Tianyu Li,Yan Xin,Jianzhong,Zhang*

Main category: eess.SP

TL;DR: MoE-CE是一个灵活的混合专家（MoE）框架，用于提高深度学习（DL）信道估计（CE）方法的泛化能力，通过使用多个专门的专家子网络和一个动态选择相关专家的路由器来适应不同的信道条件。


<details>
  <summary>Details</summary>
Motivation: 传统的基于深度学习（DL）的信道估计（CE）方法在变化的环境（如不同的信噪比、资源块数量和信道配置文件）下泛化能力不足，尤其是在多任务和零样本场景下。

Method: 提出了一种灵活的混合专家（MoE）框架，称为MoE-CE。该框架利用多个专门处理不同信道特征的专家子网络，并通过一个学习到的路由器动态地为每个输入选择最相关的专家。

Result: 在合成数据集上进行了广泛的实验，包括多任务和零样本评估，结果表明MoE-CE的性能持续优于传统的深度学习方法，在保持效率的同时实现了显著的性能提升。

Conclusion: MoE-CE框架通过引入混合专家架构，能够有效提升深度学习信道估计方法的泛化能力和适应性，同时不会不成比例地增加计算成本。

Abstract: Reliable channel estimation (CE) is fundamental for robust communication in
dynamic wireless environments, where models must generalize across varying
conditions such as signal-to-noise ratios (SNRs), the number of resource blocks
(RBs), and channel profiles. Traditional deep learning (DL)-based methods
struggle to generalize effectively across such diverse settings, particularly
under multitask and zero-shot scenarios. In this work, we propose MoE-CE, a
flexible mixture-of-experts (MoE) framework designed to enhance the
generalization capability of DL-based CE methods. MoE-CE provides an
appropriate inductive bias by leveraging multiple expert subnetworks, each
specialized in distinct channel characteristics, and a learned router that
dynamically selects the most relevant experts per input. This architecture
enhances model capacity and adaptability without a proportional rise in
computational cost while being agnostic to the choice of the backbone model and
the learning algorithm. Through extensive experiments on synthetic datasets
generated under diverse SNRs, RB numbers, and channel profiles, including
multitask and zero-shot evaluations, we demonstrate that MoE-CE consistently
outperforms conventional DL approaches, achieving significant performance gains
while maintaining efficiency.

</details>


### [184] [Scalable Hessian-free Proximal Conjugate Gradient Method for Nonconvex and Nonsmooth Optimization](https://arxiv.org/abs/2509.15973)
*Yiming Zhou,Wei Dai*

Main category: eess.SP

TL;DR: 提出了一种新的近邻共轭梯度（PCG）方法，用于解决包含非凸可微函数q和非光滑函数h的复合最小化问题。该方法在保持近邻（拟）牛顿算法快速收敛性的同时，降低了计算和内存复杂度，尤其适用于谱聚类Hessian。


<details>
  <summary>Details</summary>
Motivation: 解决大规模、病态且非凸的复合最小化问题，该问题在信号处理和机器学习中普遍存在但难以高效解决。

Method: 通过共轭梯度（CG）迭代形成牛顿方向的近似值，构建一个曲率感知的凸代理，并赋予其一个CG推导的各向同性权重，以保证局部二阶模型被凸代理支配。近邻步骤后，通过Cauchy步长与基于CG最大Ritz值推导的步长之比来缩放CG方向，以保持凸代理并允许进一步逼近。该方法利用自动微分计算Hessian-向量乘积，实现无Hessian操作。

Result: 证明了算法收敛到一阶临界点。在非凸正则化的CS-MRI和字典学习的数值实验中，与基准方法相比，证明了该方法的效率。

Conclusion: 所提出的PCG方法能够高效地解决大规模、病态和非凸的复合最小化问题，并在实际应用中表现出优越的性能。

Abstract: This work studies a composite minimization problem involving a differentiable
function q and a nonsmooth function h, both of which may be nonconvex. This
problem is ubiquitous in signal processing and machine learning yet remains
challenging to solve efficiently, particularly when large-scale instances, poor
conditioning, and nonconvexity coincide. To address these challenges, we
propose a proximal conjugate gradient method (PCG) that matches the fast
convergence of proximal (quasi-)Newton algorithms while reducing computation
and memory complexity, and is especially effective for spectrally clustered
Hessians. Our key innovation is to form, at each iteration, an approximation to
the Newton direction based on CG iterations to build a majorization surrogate.
We define this surrogate in a curvature-aware manner and equip it with a
CG-derived isotropic weight, guaranteeing majorization of a local second-order
model of q along the given direction. To better preserve majorization after the
proximal step and enable further approximation refinement, we scale the CG
direction by the ratio between the Cauchy step length and a step size derived
from the largest Ritz value of the CG tridiagonal. All curvature is accessed
via Hessian-vector products computed by automatic differentiation, keeping the
method Hessian-free. Convergence to first-order critical points is established.
Numerical experiments on CS-MRI with nonconvex regularization and on dictionary
learning, against benchmark methods, demonstrate the efficiency of the proposed
approach.

</details>


### [185] [Wireless Channel Foundation Model with Embedded Noise-Plus-Interference Suppression Structure](https://arxiv.org/abs/2509.15993)
*Yuwei Wang,Li Sun,Tingting Yang*

Main category: eess.SP

TL;DR: 该论文提出了一种增强的无线信道基础模型（WCFM），该模型能够抑制噪声和干扰（NPI），以解决在实际系统中由于使用有噪声的信道状态信息（CSI）而导致的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 实际系统中的无线信道状态信息（CSI）是有噪声的，这与用于训练无线信道基础模型（WCFM）的完美CSI不同，从而导致下游任务的性能下降。

Method: 提出了一种包含NPI抑制能力的增强WCFM架构。首先获得CSI的粗略估计，然后计算投影矩阵以提取NPI项，接着通过NPI估计和减法模块处理，最后通过CSI完成网络获得干净的CSI以进行特征提取。

Result: 与现有技术相比，所提出的具有NPI抑制能力的WCFM在信道预测任务上取得了更好的性能。

Conclusion: 所提出的增强WCFM架构通过抑制NPI能够有效提高在实际有噪声信道条件下的性能。

Abstract: Wireless channel foundation model (WCFM) is a task-agnostic AI model that is
pretrained on large-scale wireless channel datasets to learn a universal
channel feature representation that can be used for a wide range of downstream
tasks related to communications and sensing. While existing works on WCFM have
demonstrated its great potentials in various tasks including beam prediction,
channel prediction, localization, etc, the models are all trained using perfect
(i.e., error-free and complete) channel information state (CSI) data which are
generated with simulation tools. However, in practical systems where the WCFM
is deployed, perfect CSI is not available. Instead, channel estimation needs to
be first performed based on pilot signals over a subset of the resource
elements (REs) to acquire a noisy version of the CSI (termed as degraded CSI),
which significantly differs from the perfect CSI in some real-world
environments with severe noise and interference. As a result, the feature
representation generated by the WCFM is unable to reflect the characteristics
of the true channel, yielding performance degradation in downstream tasks. To
address this issue, in this paper we propose an enhanced wireless channel
foundation model architecture with noise-plus-interference (NPI) suppression
capability. In our approach, coarse estimates of the CSIs are first obtained.
With these information, two projection matrices are computed to extract the NPI
terms in the received signals, which are further processed by a NPI estimation
and subtraction module. Finally, the resultant signal is passed through a CSI
completion network to get a clean version of the CSI, which is used for feature
extraction. Simulation results demonstrated that compared to the
state-of-the-art solutions, WCFM with NPI suppression structure achieves
improved performance on channel prediction task.

</details>


### [186] [Secure Multicast Communications with Pinching-Antenna Systems (PASS)](https://arxiv.org/abs/2509.16045)
*Shan Shan,Chongjun Ouyang,Yong Li,Yuanwei Liu*

Main category: eess.SP

TL;DR: 本研究提出了一种基于捏合天线系统的安全多播通信框架（PASS），通过自适应调整捏合天线位置来优化波束成形，以提高多播安全。


<details>
  <summary>Details</summary>
Motivation: 为了提高多播通信的安全性，本文研究了捏合天线系统（PASS）中的安全多播通信。

Method: 针对单播和多播场景，分别采用了交替优化（AO）、半正定规划（SDR）、Dinkelbach-ADMM、Majorization-Minimization（MM）、二阶锥规划（SOCP）以及基于MM的逐元顺序更新等方法来联合优化发射和捏合波束成形，以最大化安全多播率。

Result: 与传统的固定位置天线相比，PASS在各种配置下均能提供更好的保密性能，并且在服务区域更大、天线阵列更大、用户和窃听者密度更高的情况下，其性能优势更为显著。

Conclusion: PASS通过自适应调整捏合天线位置以实现捏合波束成形，能够有效提升多播通信的安全性。

Abstract: This article investigates secure multicast communications in pinching-antenna
systems (PASS), where pinching beamforming is enabled by adaptively adjusting
pinching antenna (PAs) positions along waveguides to improve multicast
security. Specifically, a PASS-based secure multicast framework is proposed, in
which joint optimization of transmit and pinching beamforming is conducted to
maximize the secrecy multicast rate. i) For the single-group multicast
scenario, an alternating optimization (AO) framework is employed, where the
pinching beamformer is updated via an element-wise sequential optimization
method. The transmit beamformer is designed via a semidefinite relaxation (SDR)
formulation for an upper-bound solution, while a Dinkelbach-alternating
direction method of multipliers (ADMM) offers a low-complexity alternative. ii)
For the multi-group multicast scenario, transmit and pinching beamformers are
alternately optimized under a majorization-minimization (MM) framework. The
transmit beamformer is obtained via SDR or an efficient second-order cone
programming (SOCP) method, while the pinching beamformer is updated through
MM-based element-wise sequential update strategy. Numerical results are
provided to demonstrate that: (i) PASS consistently outperform conventional
fixed-location antenna architectures in terms of secrecy performance across
various configurations; and (ii) the performance advantage of PASS over
fixed-location architectures becomes more significant with increased service
region, larger antenna arrays, and higher user and eavesdropper densities.

</details>


### [187] [In-Situ Fault Detection of Submerged Pump Impellers Using Encapsulated Accelerometers and Machine Learning](https://arxiv.org/abs/2509.16086)
*Sahil P. Wankhede,Xiangdong Xie,Ali H. Alshehri,Keith W Brashler,Mohammad Ba'adani,Doru C Turcan,Kamal Youcef-Toumi,Xian Du*

Main category: eess.SP

TL;DR: 本研究首次提出并验证了在油气操作中，将传感器封装并直接安装在潜水叶轮碗上，以实现原位振动监测，从而能比安装在电机上的传统传感器更早地检测到故障。


<details>
  <summary>Details</summary>
Motivation: 油气操作中的立式涡轮泵依赖电机安装的加速度计进行状态监测，但无法检测到浸没在恶劣井下环境中的叶轮故障。

Method: 使用实验室规模的泵装置，在1米油浸环境下收集正常和模拟故障条件下的振动数据，并使用一系列机器学习模型进行分析，以评估传感器性能。

Result: 叶轮安装的传感器平均准确率为91.3%，AUC-ROC为0.973，优于最佳非浸没式传感器。封装对传感器性能没有显著影响。

Conclusion: 本研究首次证明，封装后的叶轮安装式传感器可以在油浸环境中可靠地检测故障，从而实现更早的故障检测、减少计划外停机时间并优化维护。

Abstract: Vertical turbine pumps in oil and gas operations rely on motor-mounted
accelerometers for condition monitoring. However, these sensors cannot detect
faults at submerged impellers exposed to harsh downhole environments. We
present the first study deploying encapsulated accelerometers mounted directly
on submerged impeller bowls, enabling in-situ vibration monitoring. Using a
lab-scale pump setup with 1-meter oil submergence, we collected vibration data
under normal and simulated fault conditions. The data were analyzed using a
suite of machine learning models -- spanning traditional and deep learning
methods -- to evaluate sensor effectiveness. Impeller-mounted sensors achieved
91.3% average accuracy and 0.973 AUC-ROC, outperforming the best non-submerged
sensor. Crucially, encapsulation caused no statistically significant
performance loss in sensor performance, confirming its viability for
oil-submerged environments. While the lab setup used shallow submergence,
real-world pump impellers operate up to hundreds of meters underground -- well
beyond the range of surface-mounted sensors. This first-of-its-kind in-situ
monitoring system demonstrates that impeller-mounted sensors -- encapsulated
for protection while preserving diagnostic fidelity -- can reliably detect
faults in critical submerged pump components. By capturing localized vibration
signatures that are undetectable from surface-mounted sensors, this approach
enables earlier fault detection, reduces unplanned downtime, and optimizes
maintenance for downhole systems in oil and gas operations.

</details>


### [188] [Xona Pulsar Compatibility with GNSS](https://arxiv.org/abs/2509.16183)
*Tyler G. R. Reid,Matteo Gala,Mathieu Favreau,Argyris Kriezis,Michael O'Meara,Andre Pant,Paul Tarantino,Christina Youn*

Main category: eess.SP

TL;DR: Xona公司的Pulsar卫星导航系统（部署于近地轨道）经过测试，证明与GPS和Galileo兼容，并且不会对现有GNSS系统造成干扰。


<details>
  <summary>Details</summary>
Motivation: 分析Xona公司的Pulsar近地轨道（LEO）卫星导航系统与现有全球导航卫星系统（GNSS）的兼容性，特别是评估其X1和X5信号对GPS和Galileo的C/N0（载波噪声比）的影响，以确保其成功部署和生态系统的整合。

Method: 通过理论分析和硬件测试（包括实验室仿真和在轨实际测试）相结合的方式，评估Pulsar系统引入其X1和X5信号后对现有GNSS接收机的C/N0的影响。测试范围涵盖了一系列商用GNSS接收机。

Result: 硬件测试和理论分析表明，Pulsar系统对现有GNSS系统没有产生不良干扰影响。Pulsar的频谱紧凑型QPSK调制和信号设计确保了其在提供高精度（厘米级）、高韧性和认证功能的同时，能够与现有GNSS接收机通过固件更新实现兼容。

Conclusion: Xona公司的Pulsar LEO卫星导航系统与GPS和Galileo兼容，不会对现有GNSS系统造成干扰，能够支持全球PNT（定位、导航和授时）生态系统的共存和整合。

Abstract: At least ten emerging providers are developing satellite navigation systems
for low Earth orbit (LEO). Compatibility with existing GNSS in L-band is
critical to their successful deployment and for the larger ecosystem. Xona is
deploying Pulsar, a near 260-satellite LEO constellation offering dual L-band
navigation services near L1 and L5. Designed for interoperability, Pulsar
provides centimeter-level accuracy, resilience, and authentication, while
maintaining a format that existing GNSS receivers can support through a
firmware update. This study examines Pulsar's compatibility with GPS and
Galileo by evaluating C/N0 degradation caused by the introduction of its X1 and
X5 signals. Using spectrally compact QPSK modulation, Pulsar minimizes
interference despite higher signal power. Theoretical analysis is supported by
hardware testing across a range of commercial GNSS receivers in both lab-based
simulation and in-orbit live-sky conditions. The study confirms Pulsar causes
no adverse interference effects to existing GNSS, supporting coexistence and
integration within the global PNT ecosystem.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [189] [DIPP: Discriminative Impact Point Predictor for Catching Diverse In-Flight Objects](https://arxiv.org/abs/2509.15254)
*Ngoc Huy Nguyen,Kazuki Shibata,Takamitsu Matsubara*

Main category: cs.RO

TL;DR: 本研究提出了一个用于四足机器人空中抓取飞行物体的框架，通过构建真实世界数据集和名为DIPP（Discriminative Impact Point Predictor）的新模型，提高了抓取成功率。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏包含复杂气动特性的多样化公开数据集，以及在物体轨迹早期难以准确预测落点，导致机器人空中抓取任务面临挑战。

Method: 构建了一个包含8000条轨迹和20种物体的真实世界数据集。提出了DIPP模型，包含判别性特征嵌入（DFE）和落点预测（IPP）两个模块，并实现了基于神经网络加速度估计器（NAE）和直接落点估计器（DPE）的两种IPP。

Result: 所构建的数据集比现有数据集更具多样性和复杂性。所提出的方法在已知和未知物体上的表现均优于基线方法。通过仿真实验证明，早期预测的改进能提高抓取成功率，并通过真实世界实验验证了方法的有效性。

Conclusion: 本研究成功构建了一个真实世界数据集，并提出了一个有效的DIPP模型，能够准确预测飞行物体的落点，显著提高了四足机器人在复杂气动条件下的空中抓取能力。

Abstract: In this study, we address the problem of in-flight object catching using a
quadruped robot with a basket. Our objective is to accurately predict the
impact point, defined as the object's landing position. This task poses two key
challenges: the absence of public datasets capturing diverse objects under
unsteady aerodynamics, which are essential for training reliable predictors;
and the difficulty of accurate early-stage impact point prediction when
trajectories appear similar across objects. To overcome these issues, we
construct a real-world dataset of 8,000 trajectories from 20 objects, providing
a foundation for advancing in-flight object catching under complex
aerodynamics. We then propose the Discriminative Impact Point Predictor (DIPP),
consisting of two modules: (i) a Discriminative Feature Embedding (DFE) that
separates trajectories by dynamics to enable early-stage discrimination and
generalization, and (ii) an Impact Point Predictor (IPP) that estimates the
impact point from these features. Two IPP variants are implemented: an Neural
Acceleration Estimator (NAE)-based method that predicts trajectories and
derives the impact point, and a Direct Point Estimator (DPE)-based method that
directly outputs it. Experimental results show that our dataset is more diverse
and complex than existing dataset, and that our method outperforms baselines on
both 15 seen and 5 unseen objects. Furthermore, we show that improved
early-stage prediction enhances catching success in simulation and demonstrate
the effectiveness of our approach through real-world experiments. The
demonstration is available at
https://sites.google.com/view/robot-catching-2025.

</details>


### [190] [GiAnt: A Bio-Inspired Hexapod for Adaptive Terrain Navigation and Object Detection](https://arxiv.org/abs/2509.15264)
*Aasfee Mosharraf Bhuiyan,Md Luban Mehda,Md. Thawhid Hasan Puspo,Jubayer Amin Pritom*

Main category: cs.RO

TL;DR: 一种仿蚂蚁六足机器人GiAnt，轻便、易于制造且能适应复杂地形。


<details>
  <summary>Details</summary>
Motivation: 为了设计一种轻便、成本低廉且能适应复杂地形的六足机器人，模仿蚂蚁的高效运动能力。

Method: 通过3D打印和激光切割技术制造轻质结构（1.75kg），采用单自由度连杆曲柄机构设计腿部，基于Arduino和步态分析实现控制，并集成机器学习和图像处理技术进行物体识别。

Result:  GiAnt机器人能够轻松越过8厘米的高度障碍，适应草地、岩石和陡峭表面等多种地形，并能识别81种不同的物体。

Conclusion:  GiAnt是研发可负担的六足机器人进行研究、探索和测绘的重要一步，其在适应性和控制简洁性方面具有独特优势。

Abstract: This paper presents the design, development and testing of GiAnt, an
affordable hexapod which is inspired by the efficient motions of ants. The
decision to model GiAnt after ants rather than other insects is rooted in ants'
natural adaptability to a variety of terrains. This bio-inspired approach gives
it a significant advantage in outdoor applications, offering terrain
flexibility along with efficient energy use. It features a lightweight
3D-printed and laser cut structure weighing 1.75 kg with dimensions of 310 mm x
200 mm x 120 mm. Its legs have been designed with a simple Single Degree of
Freedom (DOF) using a link and crank mechanism. It is great for conquering
challenging terrains such as grass, rocks, and steep surfaces. Unlike
traditional robots using four wheels for motion, its legged design gives
superior adaptability to uneven and rough surfaces. GiAnt's control system is
built on Arduino, allowing manual operation. An effective way of controlling
the legs of GiAnt was achieved by gait analysis. It can move up to 8 cm of
height easily with its advanced leg positioning system. Furthermore, equipped
with machine learning and image processing technology, it can identify 81
different objects in a live monitoring system. It represents a significant step
towards creating accessible hexapod robots for research, exploration, and
surveying, offering unique advantages in adaptability and control simplicity.

</details>


### [191] [Embodied Arena: A Comprehensive, Unified, and Evolving Evaluation Platform for Embodied AI](https://arxiv.org/abs/2509.15273)
*Fei Ni,Min Zhang,Pengyi Li,Yifu Yuan,Lingfeng Zhang,Yuecheng Liu,Peilong Han,Longxin Kou,Shaojin Ma,Jinbin Qiao,David Gamaliel Arcos Bravo,Yuening Wang,Xiao Hu,Zhanguang Zhang,Xianze Yao,Yutong Li,Zhao Zhang,Ying Wen,Ying-Cong Chen,Xiaodan Liang,Liang Lin,Bin He,Haitham Bou-Ammar,He Wang,Huazhe Xu,Jiankang Deng,Shan Luo,Shuqiang Jiang,Wei Pan,Yang Gao,Stefanos Zafeiriou,Jan Peters,Yuzheng Zhuang,Yingxue Zhang,Yan Zheng,Hongyao Tang,Jianye Hao*

Main category: cs.RO

TL;DR: Embodied AI development faces challenges in understanding capabilities, evaluation standardization, and data acquisition. Embodied Arena addresses these by providing a unified evaluation platform with a capability taxonomy, standardized system supporting diverse benchmarks and models, and an LLM-driven data generation pipeline. It features real-time leaderboards and presents nine key findings to guide future research.


<details>
  <summary>Details</summary>
Motivation: Embodied AI development lags behind other AI fields due to a lack of systematic understanding of core capabilities, absence of unified evaluation systems, and underdeveloped automated data acquisition methods. This hinders clear research objectives, cross-benchmark evaluation, and model scaling.

Method: The paper introduces Embodied Arena, a unified evaluation platform for Embodied AI. It establishes a three-level capability taxonomy (perception, reasoning, task execution), integrates 22 benchmarks across three domains, and supports 30+ models. A novel LLM-driven pipeline is used for automated and scalable acquisition of embodied data. Real-time leaderboards with dual perspectives (benchmark and capability) are published.

Result: Embodied Arena successfully addresses the identified challenges by providing a systematic capability taxonomy, a standardized evaluation system with diverse benchmarks and models, and a scalable data acquisition pipeline. The platform publishes real-time leaderboards and presents nine key findings derived from the evaluation results.

Conclusion: Embodied Arena serves as a comprehensive and unified evaluation platform that establishes a systematic capability taxonomy, a standardized evaluation system, and an automated data generation pipeline for Embodied AI. This platform aims to provide clear research objectives, enable feasible cross-benchmark evaluations, overcome data bottlenecks, and ultimately drive progress in the field of Embodied AI by offering insights and pinpointing critical research problems.

Abstract: Embodied AI development significantly lags behind large foundation models due
to three critical challenges: (1) lack of systematic understanding of core
capabilities needed for Embodied AI, making research lack clear objectives; (2)
absence of unified and standardized evaluation systems, rendering
cross-benchmark evaluation infeasible; and (3) underdeveloped automated and
scalable acquisition methods for embodied data, creating critical bottlenecks
for model scaling. To address these obstacles, we present Embodied Arena, a
comprehensive, unified, and evolving evaluation platform for Embodied AI. Our
platform establishes a systematic embodied capability taxonomy spanning three
levels (perception, reasoning, task execution), seven core capabilities, and 25
fine-grained dimensions, enabling unified evaluation with systematic research
objectives. We introduce a standardized evaluation system built upon unified
infrastructure supporting flexible integration of 22 diverse benchmarks across
three domains (2D/3D Embodied Q&A, Navigation, Task Planning) and 30+ advanced
models from 20+ worldwide institutes. Additionally, we develop a novel
LLM-driven automated generation pipeline ensuring scalable embodied evaluation
data with continuous evolution for diversity and comprehensiveness. Embodied
Arena publishes three real-time leaderboards (Embodied Q&A, Navigation, Task
Planning) with dual perspectives (benchmark view and capability view),
providing comprehensive overviews of advanced model capabilities. Especially,
we present nine findings summarized from the evaluation results on the
leaderboards of Embodied Arena. This helps to establish clear research veins
and pinpoint critical research problems, thereby driving forward progress in
the field of Embodied AI.

</details>


### [192] [Measurement and Potential Field-Based Patient Modeling for Model-Mediated Tele-ultrasound](https://arxiv.org/abs/2509.15325)
*Ryan S. Yeung,David G. Black,Septimiu E. Salcudean*

Main category: cs.RO

TL;DR: 远端社区的超声检查可以通过遥操作超声检查得到改善。为了在模型中更准确地模拟患者的接触力，我们提出了一种方法，通过结合测量的位置和力来更新内部势场模型。


<details>
  <summary>Details</summary>
Motivation: 为了在遥操作超声检查中实现更准确的力反馈，特别是在存在通信延迟的情况下，需要一种更新患者内部势场模型的方法。

Method: 本研究提出了一种更新势场模型的方法，该模型在患者表面生成点云模型，并将其转换为静态体素化体积。通过结合拉普拉斯算子和测量的力来求解势场，并根据体素化体积和超声换能器点壳模型之间的重叠来渲染力。

Result: 与仅使用拉普拉斯方程相比，在本研究的三个志愿者患者的实验中，将测量力纳入模型可将力的大小误差平均减少 7.23 N，将力矢量角度误差平均减少 9.37°。

Conclusion: 通过结合测量的位置和力来更新势场模型，可以提高遥操作超声检查中力反馈的准确性，从而有望改善远程医疗诊断成像的质量。

Abstract: Teleoperated ultrasound can improve diagnostic medical imaging access for
remote communities. Having accurate force feedback is important for enabling
sonographers to apply the appropriate probe contact force to optimize
ultrasound image quality. However, large time delays in communication make
direct force feedback impractical. Prior work investigated using point
cloud-based model-mediated teleoperation and internal potential field models to
estimate contact forces and torques. We expand on this by introducing a method
to update the internal potential field model of the patient with measured
positions and forces for more transparent model-mediated tele-ultrasound. We
first generate a point cloud model of the patient's surface and transmit this
to the sonographer in a compact data structure. This is converted to a static
voxelized volume where each voxel contains a potential field value. These
values determine the forces and torques, which are rendered based on overlap
between the voxelized volume and a point shell model of the ultrasound
transducer. We solve for the potential field using a convex quadratic that
combines the spatial Laplace operator with measured forces. This was evaluated
on volunteer patients ($n=3$) by computing the accuracy of rendered forces.
Results showed the addition of measured forces to the model reduced the force
magnitude error by an average of 7.23 N and force vector angle error by an
average of 9.37$^{\circ}$ compared to using only Laplace's equation.

</details>


### [193] [Trust-Aware Embodied Bayesian Persuasion for Mixed-Autonomy](https://arxiv.org/abs/2509.15404)
*Shaoting Peng,Katherine Driggs-Campbell,Roy Dong*

Main category: cs.RO

TL;DR: 该研究提出了一个名为TA-EBP的框架，通过结合贝叶斯说服和信任模型，使自动驾驶汽车（AV）能够以安全且可信的方式影响人类驾驶员（HV）的行为，从而提高交通安全和效率。


<details>
  <summary>Details</summary>
Motivation: 传统的博弈论模型在影响人类驾驶员行为时存在长期影响衰减和被视为操纵而破坏信任的问题，这可能导致更危险的驾驶行为。

Method: 提出信任感知型具身贝叶斯说服（TA-EBP）框架，该框架将贝叶斯说服应用于交通交叉口通信，并引入信任参数来确定影响所需的最低信任水平。此外，将贝叶斯说服的抽象信号转化为物理意义上的连续动作空间，即AV的前进微调，并推导出最优信号幅度的定理。

Result: 在混合自动驾驶交通仿真中验证了TA-EBP框架。结果表明，与忽略信任或缺乏通信的基线模型相比，TA-EBP能够成功说服人类驾驶员更加谨慎驾驶，消除碰撞并改善交通流量。

Conclusion: TA-EBP框架为交通交叉口场景下自动驾驶汽车与人类驾驶员的交互提供了一种透明且非策略性的影响模型，能够有效提高交通安全和效率。

Abstract: Safe and efficient interaction between autonomous vehicles (AVs) and
human-driven vehicles (HVs) is a critical challenge for future transportation
systems. While game-theoretic models capture how AVs influence HVs, they often
suffer from a long-term decay of influence and can be perceived as
manipulative, eroding the human's trust. This can paradoxically lead to riskier
human driving behavior over repeated interactions. In this paper, we address
this challenge by proposing the Trust-Aware Embodied Bayesian Persuasion
(TA-EBP) framework. Our work makes three key contributions: First, we apply
Bayesian persuasion to model communication at traffic intersections, offering a
transparent alternative to traditional game-theoretic models. Second, we
introduce a trust parameter to the persuasion framework, deriving a theorem for
the minimum trust level required for influence. Finally, we ground the abstract
signals of Bayesian persuasion theory into a continuous, physically meaningful
action space, deriving a second theorem for the optimal signal magnitude,
realized as an AV's forward nudge. Additionally, we validate our framework in a
mixed-autonomy traffic simulation, demonstrating that TA-EBP successfully
persuades HVs to drive more cautiously, eliminating collisions and improving
traffic flow compared to baselines that either ignore trust or lack
communication. Our work provides a transparent and non-strategic framework for
influence in human-robot interaction, enhancing both safety and efficiency.

</details>


### [194] [Sym2Real: Symbolic Dynamics with Residual Learning for Data-Efficient Adaptive Control](https://arxiv.org/abs/2509.15412)
*Easop Lee,Samuel A. Moore,Boyuan Chen*

Main category: cs.RO

TL;DR: Sym2Real是一个数据驱动的框架，通过结合低保真仿真数据和真实世界残差学习，在很少的数据下实现机器人控制器（如四旋翼和赛车）的鲁棒控制，解决了符号回归在机器人应用中的噪声敏感性和模型退化问题。


<details>
  <summary>Details</summary>
Motivation: 开发一种数据驱动的框架，以数据高效的方式训练低级自适应控制器，使其在真实世界机器人控制中具有鲁棒性，无需专家知识或仿真调优。

Method: 将符号回归应用于机器人控制，并通过结合低保真仿真数据和目标真实世界残差学习来解决噪声敏感性和模型退化问题。

Result: 在四旋翼和赛车平台上实现了数据高效的适应性控制，在六种分布外仿真到仿真场景和五种真实世界条件下均取得了成功，仅使用了约10条轨迹。

Conclusion: Sym2Real框架通过巧妙结合仿真和真实世界数据，能够以极高的数据效率训练出鲁棒的机器人控制器，有效解决了符号回归在实际应用中的挑战。

Abstract: We present Sym2Real, a fully data-driven framework that provides a principled
way to train low-level adaptive controllers in a highly data-efficient manner.
Using only about 10 trajectories, we achieve robust control of both a quadrotor
and a racecar in the real world, without expert knowledge or simulation tuning.
Our approach achieves this data efficiency by bringing symbolic regression to
real-world robotics while addressing key challenges that prevent its direct
application, including noise sensitivity and model degradation that lead to
unsafe control. Our key observation is that the underlying physics is often
shared for a system regardless of internal or external changes. Hence, we
strategically combine low-fidelity simulation data with targeted real-world
residual learning. Through experimental validation on quadrotor and racecar
platforms, we demonstrate consistent data-efficient adaptation across six
out-of-distribution sim2sim scenarios and successful sim2real transfer across
five real-world conditions. More information and videos can be found at at
http://generalroboticslab.com/Sym2Real

</details>


### [195] [Online Slip Detection and Friction Coefficient Estimation for Autonomous Racing](https://arxiv.org/abs/2509.15423)
*Christopher Oeltjen,Carson Sobolewski,Saleh Faghfoorian,Lorant Domokos,Giancarlo Vidal,Ivan Ruchkin*

Main category: cs.RO

TL;DR: 本文提出了一种仅使用IMU、LiDAR和控制输入，无需模型或训练数据即可在线估计轮胎-道路摩擦系数（TRFC）的轻量级方法。


<details>
  <summary>Details</summary>
Motivation: 准确的轮胎-道路摩擦系数（TRFC）对于车辆安全、稳定性和性能至关重要，尤其是在自动驾驶赛车中。

Method: 通过比较指令运动和测量运动来实时检测滑移事件，并直接从无滑移条件下的观测加速度来估计TRFC。

Result: 实验表明，该方法能够精确一致地检测滑移并估算摩擦系数，结果与地面真实测量值高度吻合。

Conclusion: 该方法简单、可部署且计算效率高，在实时滑移监测和摩擦系数估算方面具有潜力。

Abstract: Accurate knowledge of the tire-road friction coefficient (TRFC) is essential
for vehicle safety, stability, and performance, especially in autonomous
racing, where vehicles often operate at the friction limit. However, TRFC
cannot be directly measured with standard sensors, and existing estimation
methods either depend on vehicle or tire models with uncertain parameters or
require large training datasets. In this paper, we present a lightweight
approach for online slip detection and TRFC estimation. Our approach relies
solely on IMU and LiDAR measurements and the control actions, without special
dynamical or tire models, parameter identification, or training data. Slip
events are detected in real time by comparing commanded and measured motions,
and the TRFC is then estimated directly from observed accelerations under
no-slip conditions. Experiments with a 1:10-scale autonomous racing car across
different friction levels demonstrate that the proposed approach achieves
accurate and consistent slip detections and friction coefficients, with results
closely matching ground-truth measurements. These findings highlight the
potential of our simple, deployable, and computationally efficient approach for
real-time slip monitoring and friction coefficient estimation in autonomous
driving.

</details>


### [196] [Implicit Kinodynamic Motion Retargeting for Human-to-humanoid Imitation Learning](https://arxiv.org/abs/2509.15443)
*Xingyu Chen,Hanyu Wu,Sikai Wu,Mingliang Zhou,Diyun Xiang,Haodong Zhang*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Human-to-humanoid imitation learning aims to learn a humanoid whole-body
controller from human motion. Motion retargeting is a crucial step in enabling
robots to acquire reference trajectories when exploring locomotion skills.
However, current methods focus on motion retargeting frame by frame, which
lacks scalability. Could we directly convert large-scale human motion into
robot-executable motion through a more efficient approach? To address this
issue, we propose Implicit Kinodynamic Motion Retargeting (IKMR), a novel
efficient and scalable retargeting framework that considers both kinematics and
dynamics. In kinematics, IKMR pretrains motion topology feature representation
and a dual encoder-decoder architecture to learn a motion domain mapping. In
dynamics, IKMR integrates imitation learning with the motion retargeting
network to refine motion into physically feasible trajectories. After
fine-tuning using the tracking results, IKMR can achieve large-scale physically
feasible motion retargeting in real time, and a whole-body controller could be
directly trained and deployed for tracking its retargeted trajectories. We
conduct our experiments both in the simulator and the real robot on a full-size
humanoid robot. Extensive experiments and evaluation results verify the
effectiveness of our proposed framework.

</details>


### [197] [Explainable AI-Enhanced Supervisory Control for Robust Multi-Agent Robotic Systems](https://arxiv.org/abs/2509.15491)
*Reza Pirayeshshirazinezhad,Nima Fathi*

Main category: cs.RO

TL;DR: 提出了一个结合了时序自动机、鲁棒控制器和可解释预测器的多智能体机器人XAI监督控制框架，并在航天器编队和AUV领域进行了验证，证明了其安全、可审计、可解释和高效的优点。


<details>
  <summary>Details</summary>
Motivation: 为多智能体机器人系统提供一个安全、可审计、可解释且高效的监督控制框架，以应对资源受限和安全关键的应用场景。

Method: 结合了（1）用于安全、可审计模式切换的时序自动机监督器，（2）鲁棒的连续控制（用于大角度机动的Lyapunov控制器；用于精度和干扰抑制的具有边界层的滑模控制器（SMC）），以及（3）将任务上下文映射到增益和预期性能（能量、误差）的可解释预测器。使用蒙特卡洛驱动的优化来提供训练数据。

Result: 在航天器编队飞行和AUV（自主水下航行器）两个领域进行了验证。SMC控制器在航天器验证中实现了亚毫米级对齐，跟踪误差降低了21.7%，能耗降低了81.4%。在AUV测试中，SMC在随机变化的洋流下保持了可控的误差。

Conclusion: 该方法对于安全关键、资源受限的多智能体机器人系统具有良好的可移植性和可解释性。

Abstract: We present an explainable AI-enhanced supervisory control framework for
multi-agent robotics that combines (i) a timed-automata supervisor for safe,
auditable mode switching, (ii) robust continuous control (Lyapunov-based
controller for large-angle maneuver; sliding-mode controller (SMC) with
boundary layers for precision and disturbance rejection), and (iii) an
explainable predictor that maps mission context to gains and expected
performance (energy, error). Monte Carlo-driven optimization provides the
training data, enabling transparent real-time trade-offs.
  We validated the approach in two contrasting domains, spacecraft formation
flying and autonomous underwater vehicles (AUVs). Despite different
environments (gravity/actuator bias vs. hydrodynamic drag/currents), both share
uncertain six degrees of freedom (6-DOF) rigid-body dynamics, relative motion,
and tight tracking needs, making them representative of general robotic
systems. In the space mission, the supervisory logic selects parameters that
meet mission criteria. In AUV leader-follower tests, the same SMC structure
maintains a fixed offset under stochastic currents with bounded steady error.
In spacecraft validation, the SMC controller achieved submillimeter alignment
with 21.7% lower tracking error and 81.4% lower energy consumption compared to
Proportional-Derivative PD controller baselines. At the same time, in AUV
tests, SMC maintained bounded errors under stochastic currents. These results
highlight both the portability and the interpretability of the approach for
safety-critical, resource-constrained multi-agent robotics.

</details>


### [198] [STARC: See-Through-Wall Augmented Reality Framework for Human-Robot Collaboration in Emergency Response](https://arxiv.org/abs/2509.15507)
*Shenghai Yuan,Weixiang Guo,Tianxin Hu,Yu Yang,Jinyu Chen,Rui Qian,Zhongyuan Liu,Lihua Xie*

Main category: cs.RO

TL;DR: STARC是一个AR框架，通过融合机器人建图和消防员的激光雷达感知，提供隐藏危险和遇难者的实时可视化，以增强态势感知并降低风险。


<details>
  <summary>Details</summary>
Motivation: 在紧急响应任务中，消防员需要在被遮挡物阻碍视线的复杂室内环境中导航，这会隐藏危险和待救人员。STARC旨在解决这一问题。

Method: STARC框架融合了移动机器人建图和消防员佩戴的激光雷达感知。地面机器人进行大区域探索和3D人体检测，而消防员头盔或手持式激光雷达通过相对姿态估计与机器人的全局地图对齐。这种跨激光雷达对齐实现了低延迟的AR可视化，将检测到的人体及其点云投影到消防员的视野中。

Result: 实验结果表明，STARC系统在姿态对齐、检测和叠加方面都表现稳定可靠，证明了其在消防、灾难救援和安全关键操作中的潜力。

Conclusion: STARC框架通过提供隐藏的遇难者和危险的实时可视化，提高了态势感知能力，降低了操作员的风险。该系统在模拟、实验室设置和战术现场试验中得到了验证，代码和设计将在接受后开源。

Abstract: In emergency response missions, first responders must navigate cluttered
indoor environments where occlusions block direct line-of-sight, concealing
both life-threatening hazards and victims in need of rescue. We present STARC,
a see-through AR framework for human-robot collaboration that fuses
mobile-robot mapping with responder-mounted LiDAR sensing. A ground robot
running LiDAR-inertial odometry performs large-area exploration and 3D human
detection, while helmet- or handheld-mounted LiDAR on the responder is
registered to the robot's global map via relative pose estimation. This
cross-LiDAR alignment enables consistent first-person projection of detected
humans and their point clouds - rendered in AR with low latency - into the
responder's view. By providing real-time visualization of hidden occupants and
hazards, STARC enhances situational awareness and reduces operator risk.
Experiments in simulation, lab setups, and tactical field trials confirm robust
pose alignment, reliable detections, and stable overlays, underscoring the
potential of our system for fire-fighting, disaster relief, and other
safety-critical operations. Code and design will be open-sourced upon
acceptance.

</details>


### [199] [Distribution Estimation for Global Data Association via Approximate Bayesian Inference](https://arxiv.org/abs/2509.15565)
*Yixuan Jia,Mason B. Peterson,Qingyuan Li,Yulun Tian,Jonathan P. How*

Main category: cs.RO

TL;DR: 通过利用近似贝叶斯推理来处理全局数据关联中的多模态解决方案，以避免过早地承诺单一解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的全局数据关联方法（通常依赖于最大似然估计或最大共识）在处理重复或对称数据时面临挑战，因为这些数据会导致解决方案高度多峰。

Method: 提出了一种利用近似贝叶斯推理的数据关联框架，该框架通过粒子表示和更新规则来捕捉多个解决方案模式，并结合了优化约束和GPU并行化。

Result: 在模拟和真实世界的高度模糊数据集上进行了广泛的实验，证明该方法能够正确估计点云配准或对象地图的变换分布。

Conclusion: 所提出的基于近似贝叶斯推理的数据关联框架能够有效地处理模糊情况下的多模态解决方案，从而在各种机器人应用中提高数据关联的准确性。

Abstract: Global data association is an essential prerequisite for robot operation in
environments seen at different times or by different robots. Repetitive or
symmetric data creates significant challenges for existing methods, which
typically rely on maximum likelihood estimation or maximum consensus to produce
a single set of associations. However, in ambiguous scenarios, the distribution
of solutions to global data association problems is often highly multimodal,
and such single-solution approaches frequently fail. In this work, we introduce
a data association framework that leverages approximate Bayesian inference to
capture multiple solution modes to the data association problem, thereby
avoiding premature commitment to a single solution under ambiguity. Our
approach represents hypothetical solutions as particles that evolve according
to a deterministic or randomized update rule to cover the modes of the
underlying solution distribution. Furthermore, we show that our method can
incorporate optimization constraints imposed by the data association
formulation and directly benefit from GPU-parallelized optimization. Extensive
simulated and real-world experiments with highly ambiguous data show that our
method correctly estimates the distribution over transformations when
registering point clouds or object maps.

</details>


### [200] [Momentum-constrained Hybrid Heuristic Trajectory Optimization Framework with Residual-enhanced DRL for Visually Impaired Scenarios](https://arxiv.org/abs/2509.15582)
*Yuting Zeng,Zhiwen Zheng,You Zhou,JiaLing Xiao,Yongbin Yu,Manping Fan,Bo Gong,Liyong Ren*

Main category: cs.RO

TL;DR: 该论文提出了一种用于视觉障碍辅助导航的动量约束混合启发式轨迹优化框架（MHHTOF），结合了轨迹采样生成、优化和评估，并利用了残差增强的深度强化学习（DRL）。


<details>
  <summary>Details</summary>
Motivation: 为视觉障碍辅助导航场景开发一种能够确保轨迹平滑性、可行性和安全性的先进轨迹优化框架。

Method: 该框架分为两个阶段：第一阶段使用三阶插值和五阶多项式，结合动量约束轨迹优化（MTO），在Frenet坐标系中生成启发式轨迹采样簇（HTSC）；第二阶段利用基于LSTM的残差增强Actor-Critic网络，在笛卡尔坐标系中自适应地优化轨迹选择。引入双阶段成本建模机制（DCMM）进行跨阶段的语义优先级对齐，以支持以人为中心的优化。

Result: 所提出的LSTM-ResB-PPO模型比PPO基线模型收敛速度快一倍，同时提高了奖励和训练稳定性。与基线方法相比，所选模型平均成本降低了30.3%，成本方差降低了53.3%，自我风险和障碍物风险降低了77%以上。

Conclusion: 该框架在提高复杂辅助导航任务的鲁棒性、安全性和实时可行性方面是有效的。

Abstract: This paper proposes a momentum-constrained hybrid heuristic trajectory
optimization framework (MHHTOF) tailored for assistive navigation in visually
impaired scenarios, integrating trajectory sampling generation, optimization
and evaluation with residual-enhanced deep reinforcement learning (DRL). In the
first stage, heuristic trajectory sampling cluster (HTSC) is generated in the
Frenet coordinate system using third-order interpolation with fifth-order
polynomials and momentum-constrained trajectory optimization (MTO) constraints
to ensure smoothness and feasibility. After first stage cost evaluation, the
second stage leverages a residual-enhanced actor-critic network with LSTM-based
temporal feature modeling to adaptively refine trajectory selection in the
Cartesian coordinate system. A dual-stage cost modeling mechanism (DCMM) with
weight transfer aligns semantic priorities across stages, supporting
human-centered optimization. Experimental results demonstrate that the proposed
LSTM-ResB-PPO achieves significantly faster convergence, attaining stable
policy performance in approximately half the training iterations required by
the PPO baseline, while simultaneously enhancing both reward outcomes and
training stability. Compared to baseline method, the selected model reduces
average cost and cost variance by 30.3% and 53.3%, and lowers ego and obstacle
risks by over 77%. These findings validate the framework's effectiveness in
enhancing robustness, safety, and real-time feasibility in complex assistive
planning tasks.

</details>


### [201] [Bench-RNR: Dataset for Benchmarking Repetitive and Non-repetitive Scanning LiDAR for Infrastructure-based Vehicle Localization](https://arxiv.org/abs/2509.15583)
*Runxin Zhao,Chunxiang Wang,Hanyang Zhuang,Ming Yang*

Main category: cs.RO

TL;DR: 该研究提出了一个用于基础设施车辆定位的数据集，并对比了重复扫描和非重复扫描激光雷达的性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究多依赖重复扫描激光雷达，但非重复扫描激光雷达具有消除盲区和成本效益高等优点，其在路侧感知和定位方面的应用有限。本研究旨在解决这一问题，并为选择最适合基础设施车辆定位的激光雷达扫描模式提供指导。

Method: 构建了一个包含重复扫描和非重复扫描激光雷达数据的基础设施车辆定位数据集，包含5445帧点云和8个不同轨迹序列。通过实验建立了基础设施车辆定位的基线，并对比了两种扫描模式的性能。

Result: 实验结果为基础设施车辆定位方法设定了基准，并对比了使用非重复扫描和重复扫描激光雷达的性能。

Conclusion: 该研究提出的数据集为基础设施感知和车辆定位的进步提供了支持，并有助于为基础设施车辆定位选择最合适的激光雷达扫描模式。数据集和源代码已公开。

Abstract: Vehicle localization using roadside LiDARs can provide centimeter-level
accuracy for cloud-controlled vehicles while simultaneously serving multiple
vehicles, enhanc-ing safety and efficiency. While most existing studies rely on
repetitive scanning LiDARs, non-repetitive scanning LiDAR offers advantages
such as eliminating blind zones and being more cost-effective. However, its
application in roadside perception and localization remains limited. To address
this, we present a dataset for infrastructure-based vehicle localization, with
data collected from both repetitive and non-repetitive scanning LiDARs, in
order to benchmark the performance of different LiDAR scanning patterns. The
dataset contains 5,445 frames of point clouds across eight vehicle trajectory
sequences, with diverse trajectory types. Our experiments establish base-lines
for infrastructure-based vehicle localization and compare the performance of
these methods using both non-repetitive and repetitive scanning LiDARs. This
work offers valuable insights for selecting the most suitable LiDAR scanning
pattern for infrastruc-ture-based vehicle localization. Our dataset is a
signifi-cant contribution to the scientific community, supporting advancements
in infrastructure-based perception and vehicle localization. The dataset and
source code are publicly available at:
https://github.com/sjtu-cyberc3/BenchRNR.

</details>


### [202] [Distributed Nash Equilibrium Seeking Algorithm in Aggregative Games for Heterogeneous Multi-Robot Systems](https://arxiv.org/abs/2509.15597)
*Yi Dong,Zhongguo Li,Sarvapali D. Ramchurn,Xiaowei Huang*

Main category: cs.RO

TL;DR: 本文提出了一种分布式纳什均衡算法，用于异构多机器人系统，通过分布式优化和输出控制实现纳什均衡。


<details>
  <summary>Details</summary>
Motivation: 开发一种适用于异构多机器人系统的分布式纳什均衡算法。

Method: 提出分布式优化算法以计算纳什均衡作为每个机器人的定制参考，并设计输出控制律以在聚合博弈中跟踪它。

Result: 算法保证收敛并产生有效的结果，已通过数值模拟和物理机器人实验进行验证。

Conclusion: 所提出的分布式算法能够有效地为异构多机器人系统寻找纳什均衡。

Abstract: This paper develops a distributed Nash Equilibrium seeking algorithm for
heterogeneous multi-robot systems. The algorithm utilises distributed
optimisation and output control to achieve the Nash equilibrium by leveraging
information shared among neighbouring robots. Specifically, we propose a
distributed optimisation algorithm that calculates the Nash equilibrium as a
tailored reference for each robot and designs output control laws for
heterogeneous multi-robot systems to track it in an aggregative game. We prove
that our algorithm is guaranteed to converge and result in efficient outcomes.
The effectiveness of our approach is demonstrated through numerical simulations
and empirical testing with physical robots.

</details>


### [203] [ORB: Operating Room Bot, Automating Operating Room Logistics through Mobile Manipulation](https://arxiv.org/abs/2509.15600)
*Jinkai Qiu,Yungjun Kim,Gaurav Sethia,Tanmay Agarwal,Siddharth Ghodasara,Zackory Erickson,Jeffrey Ichnowski*

Main category: cs.RO

TL;DR: ORB是一个用于医院手术室的自动化物流机器人框架，通过行为树集成多种功能，并在真实环境中成功进行了物料检索和补货操作。


<details>
  <summary>Details</summary>
Motivation: 在医院手术室中高效地递送物品至关重要，但自动化物品级手术室物流面临感知、效率和无菌性方面的挑战。

Method: 提出ORB机器人框架，采用分层行为树（BT）架构集成物体识别（YOLOv7、SAM2、Grounded DINO）、场景理解和GPU加速运动规划（cuRobo），实现实时、无碰撞的移动操作。

Result: ORB在手术室物品检索任务中取得了80%的成功率，在补货任务中取得了96%的成功率。

Conclusion: ORB是一个可靠且适应性强的自主手术室物流系统。

Abstract: Efficiently delivering items to an ongoing surgery in a hospital operating
room can be a matter of life or death. In modern hospital settings, delivery
robots have successfully transported bulk items between rooms and floors.
However, automating item-level operating room logistics presents unique
challenges in perception, efficiency, and maintaining sterility. We propose the
Operating Room Bot (ORB), a robot framework to automate logistics tasks in
hospital operating rooms (OR). ORB leverages a robust, hierarchical behavior
tree (BT) architecture to integrate diverse functionalities of object
recognition, scene interpretation, and GPU-accelerated motion planning. The
contributions of this paper include: (1) a modular software architecture
facilitating robust mobile manipulation through behavior trees; (2) a novel
real-time object recognition pipeline integrating YOLOv7, Segment Anything
Model 2 (SAM2), and Grounded DINO; (3) the adaptation of the cuRobo
parallelized trajectory optimization framework to real-time, collision-free
mobile manipulation; and (4) empirical validation demonstrating an 80% success
rate in OR supply retrieval and a 96% success rate in restocking operations.
These contributions establish ORB as a reliable and adaptable system for
autonomous OR logistics.

</details>


### [204] [PRIMT: Preference-based Reinforcement Learning with Multimodal Feedback and Trajectory Synthesis from Foundation Models](https://arxiv.org/abs/2509.15607)
*Ruiqi Wang,Dezhong Zhao,Ziqin Yuan,Tianyu Shao,Guohua Chen,Dominic Kao,Sungeun Hong,Byung-Cheol Min*

Main category: cs.RO

TL;DR: 本论文提出了一种名为PRIMT的基于偏好的强化学习框架，利用多模态基础模型（FMs）解决人类输入过多和奖励学习中的模糊性与信用分配难题，并在多项任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决基于偏好的强化学习（PbRL）中人类输入过多、奖励学习中的查询模糊性和信用分配困难等挑战。

Method: PRIMT框架：1. 利用大型语言模型和视觉-语言模型进行多模态反馈评估，解决奖励学习中的模糊性和信用分配问题。2. 结合了前瞻性轨迹生成（减少早期查询模糊性）和后视轨迹增强（通过因果辅助损失进行反事实推理，改进信用分配）。

Result: 在2个运动和6个操作任务的基准测试中，PRIMT的表现优于基于FM和脚本的基线方法。

Conclusion: PRIMT通过结合多模态基础模型和新颖的轨迹处理技术，有效解决了PbRL中的关键挑战，并在多项任务中取得了先进的性能。

Abstract: Preference-based reinforcement learning (PbRL) has emerged as a promising
paradigm for teaching robots complex behaviors without reward engineering.
However, its effectiveness is often limited by two critical challenges: the
reliance on extensive human input and the inherent difficulties in resolving
query ambiguity and credit assignment during reward learning. In this paper, we
introduce PRIMT, a PbRL framework designed to overcome these challenges by
leveraging foundation models (FMs) for multimodal synthetic feedback and
trajectory synthesis. Unlike prior approaches that rely on single-modality FM
evaluations, PRIMT employs a hierarchical neuro-symbolic fusion strategy,
integrating the complementary strengths of large language models and
vision-language models in evaluating robot behaviors for more reliable and
comprehensive feedback. PRIMT also incorporates foresight trajectory
generation, which reduces early-stage query ambiguity by warm-starting the
trajectory buffer with bootstrapped samples, and hindsight trajectory
augmentation, which enables counterfactual reasoning with a causal auxiliary
loss to improve credit assignment. We evaluate PRIMT on 2 locomotion and 6
manipulation tasks on various benchmarks, demonstrating superior performance
over FM-based and scripted baselines.

</details>


### [205] [Miniature soft robot with magnetically reprogrammable surgical functions](https://arxiv.org/abs/2509.15610)
*Chelsea Shan Xian Ng,Yu Xuan Yeoh,Nicholas Yong Wei Foo,Keerthana Radhakrishnan,Guo Zhan Lum*

Main category: cs.RO

TL;DR: 一种可重新编程的磁化薄膜，可实现六自由度运动和多种手术功能，适用于体内微创手术。


<details>
  <summary>Details</summary>
Motivation: 当前的磁驱动微型机器人功能受限（最多两种功能或五自由度运动），且需要强外部磁场（<4cm），不适用于手术。需要开发功能更多、运动更灵活且能在体内安全工作的微型机器人。

Method: 开发了一种可编程磁化膜的毫米级软体机器人，通过控制磁化分布实现多种功能（药物输送、切割、抓取、样本存储、远程加热）和六自由度运动（包括三维旋转），能在非结构化环境中滚动和爬行，并能在较弱的磁场（<65mT, 1.5T/m）下工作。

Result: 该软体机器人实现了五种手术功能，包括药物输送、切割、抓取、样本存储和远程加热。它能够实现六自由度运动，包括滚动和爬行，克服了五自由度机器人的局限性。所使用的磁场较弱且均匀，能够穿透生物组织，保证了在人体内的可控性。

Conclusion: 这种可编程磁化软体机器人代表了软体驱动器领域的一项重大突破，有望通过具有前所未有功能的无系链微型机器彻底改变微创治疗。

Abstract: Miniature robots are untethered actuators, which have significant potential
to make existing minimally invasive surgery considerably safer and painless,
and enable unprecedented treatments because they are much smaller and dexterous
than existing surgical robots. Of the miniature robots, the magnetically
actuated ones are the most functional and dexterous. However, existing magnetic
miniature robots are currently impractical for surgery because they are either
restricted to possessing at most two on-board functionalities or having limited
five degrees-of-freedom (DOF) locomotion. Some of these actuators are also only
operational under specialized environments where actuation from strong external
magnets must be at very close proximity (< 4 cm away). Here we present a
millimeter-scale soft robot where its magnetization profile can be reprogrammed
upon command to perform five surgical functionalities: drug-dispensing, cutting
through biological tissues (simulated with gelatin), gripping, storing
(biological) samples and remote heating. By possessing full six-DOF motions,
including the sixth-DOF rotation about its net magnetic moment, our soft robot
can also roll and two-anchor crawl across challenging unstructured
environments, which are impassable by its five-DOF counterparts. Because our
actuating magnetic fields are relatively uniform and weak (at most 65 mT and
1.5 T/m), such fields can theoretically penetrate through biological tissues
harmlessly and allow our soft robot to remain controllable within the depths of
the human body. We envision that this work marks a major milestone for the
advancement of soft actuators, and towards revolutionizing minimally invasive
treatments with untethered miniature robots that have unprecedented
functionalities.

</details>


### [206] [Indoor Positioning Based on Active Radar Sensing and Passive Reflectors: Reflector Placement Optimization](https://arxiv.org/abs/2509.15613)
*Sven Hinderer,Pascal Schlachter,Zhibin Yu,Xiaofeng Wu,Bin Yang*

Main category: cs.RO

TL;DR: 该研究提出了一种基于雷达传感的室内定位系统（IPS），用于自主移动机器人（AMR）。


<details>
  <summary>Details</summary>
Motivation: 为了实现高精度、低成本的室内定位，并解决复杂室内环境中雷达反射器优化布局的问题。

Method: 提出了一种结合简单反射器和单通道FMCW雷达的IPS。另外，提出了一种多目标粒子群优化（MOPSO）算法来优化2D房间内雷达反射器的布局。

Result: 通过结合反射器和FMCW雷达，可以实现高定位精度和低系统成本。MOPSO算法可以优化复杂房间设置中的雷达反射器放置。

Conclusion: 该研究提出了一种经济高效且高精度的室内定位系统，并通过MOPSO算法解决了反射器布局的优化问题。

Abstract: We extend our work on a novel indoor positioning system (IPS) for autonomous
mobile robots (AMRs) based on radar sensing of local, passive radar reflectors.
Through the combination of simple reflectors and a single-channel frequency
modulated continuous wave (FMCW) radar, high positioning accuracy at low system
cost can be achieved. Further, a multi-objective (MO) particle swarm
optimization (PSO) algorithm is presented that optimizes the 2D placement of
radar reflectors in complex room settings.

</details>


### [207] [Omni-LIVO: Robust RGB-Colored Multi-Camera Visual-Inertial-LiDAR Odometry via Photometric Migration and ESIKF Fusion](https://arxiv.org/abs/2509.15673)
*Yinong Cao,Xin He,Yuwei Chen,Chenyang Zhang,Chengyu Pu,Bingtao Wang,Kaile Wu,Shouzheng Zhu,Fei Han,Shijie Liu,Chunlai Li,Jianyu Wang*

Main category: cs.RO

TL;DR: 本文提出了一种名为 Omni-LIVO 的多摄像头激光雷达-惯性-视觉里程计（LIVO）系统，解决了现有系统视野受限的鲁棒性问题。


<details>
  <summary>Details</summary>
Motivation: 现有 LIVO 系统多依赖单目相机，空间覆盖受限且鲁棒性较差，无法匹配宽视场激光雷达的探测范围。

Method: Omni-LIVO 首次实现了紧耦合的多摄像头 LIVO 系统，通过跨视图直接跟踪策略（Cross-View direct tracking strategy）保持非重叠视图间的光度一致性，并扩展了误差状态迭代卡尔曼滤波器（ESIKF）以支持多视图更新和自适应协方差加权。

Result: 在公开基准和自定义数据集上的评估显示，Omni-LIVO 在准确性和鲁棒性方面优于最先进的 LIVO、LIO 和视觉惯性基线。

Conclusion: Omni-LIVO 成功弥合了宽视场激光雷达和传统摄像头之间的视场不匹配问题，提高了系统的空间覆盖率和鲁棒性。

Abstract: Wide field-of-view (FoV) LiDAR sensors provide dense geometry across large
environments, but most existing LiDAR-inertial-visual odometry (LIVO) systems
rely on a single camera, leading to limited spatial coverage and degraded
robustness. We present Omni-LIVO, the first tightly coupled multi-camera LIVO
system that bridges the FoV mismatch between wide-angle LiDAR and conventional
cameras. Omni-LIVO introduces a Cross-View direct tracking strategy that
maintains photometric consistency across non-overlapping views, and extends the
Error-State Iterated Kalman Filter (ESIKF) with multi-view updates and adaptive
covariance weighting. The system is evaluated on public benchmarks and our
custom dataset, showing improved accuracy and robustness over state-of-the-art
LIVO, LIO, and visual-inertial baselines. Code and dataset will be released
upon publication.

</details>


### [208] [Imagination at Inference: Synthesizing In-Hand Views for Robust Visuomotor Policy Inference](https://arxiv.org/abs/2509.15717)
*Haoran Ding,Anqing Duan,Zezhou Sun,Dezhen Song,Yoshihiko Nakamura*

Main category: cs.RO

TL;DR: 通过利用新颖的视图合成（NVS）技术，即使在没有实际手持摄像机的情况下，机器人也能“想象”手持视图，从而提高其运动控制策略的性能。


<details>
  <summary>Details</summary>
Motivation: 在机器人操作中，手持（本体感受）视图对于精确控制至关重要，但增加手持摄像机会带来硬件、复杂性和成本方面的挑战。

Method: 利用经过微调的扩散模型，以代理视图和手持视图相机之间的相对姿态为条件，进行新颖视图合成（NVS）。具体来说，采用基于LoRA的微调来使预训练的NVS模型（ZeroNVS）适应机器人操作领域。

Result: 在模拟基准（RoboMimic和MimicGen）和使用Unitree Z1机械臂进行的草莓采摘等现实世界实验中，合成的手持视图显著提高了策略推理能力，有效弥补了真实手持摄像机缺失造成的性能下降。

Conclusion: 该方法为部署鲁棒的运动控制策略提供了一种可扩展且硬件轻量级的解决方案，并突显了想象视觉推理在具身智能体中的潜力。

Abstract: Visual observations from different viewpoints can significantly influence the
performance of visuomotor policies in robotic manipulation. Among these,
egocentric (in-hand) views often provide crucial information for precise
control. However, in some applications, equipping robots with dedicated in-hand
cameras may pose challenges due to hardware constraints, system complexity, and
cost. In this work, we propose to endow robots with imaginative perception -
enabling them to 'imagine' in-hand observations from agent views at inference
time. We achieve this via novel view synthesis (NVS), leveraging a fine-tuned
diffusion model conditioned on the relative pose between the agent and in-hand
views cameras. Specifically, we apply LoRA-based fine-tuning to adapt a
pretrained NVS model (ZeroNVS) to the robotic manipulation domain. We evaluate
our approach on both simulation benchmarks (RoboMimic and MimicGen) and
real-world experiments using a Unitree Z1 robotic arm for a strawberry picking
task. Results show that synthesized in-hand views significantly enhance policy
inference, effectively recovering the performance drop caused by the absence of
real in-hand cameras. Our method offers a scalable and hardware-light solution
for deploying robust visuomotor policies, highlighting the potential of
imaginative visual reasoning in embodied agents.

</details>


### [209] [SMART: Scalable Multi-Agent Reasoning and Trajectory Planning in Dense Environments](https://arxiv.org/abs/2509.15737)
*Heye Huang,Yibin Yang,Wang Chen,Tiantian Chen,Xiaopeng Li,Sikai Chen*

Main category: cs.RO

TL;DR: SMART是一个分层框架，结合了基于优先级的搜索和分布式优化，用于高效、可行的多车规划，在模拟和真实世界中均优于基线方法，并且具有出色的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 密集交通环境中多车轨迹规划是一个非凸问题，由于碰撞约束的快速增长而变得越来越困难。为了实现实时、大规模的协调，必须有效地探索可行行为并解决复杂的交互。 

Method: SMART框架在上层使用基于强化学习的优先级估计和混合A*搜索来探索交互模式，在下层使用可并行化的凸优化来细化解决方案。通过对空间进行分区并构建可行走廊，将联合非凸问题分解为可并行求解的凸子问题。

Result: SMART在50米x50米地图上，在高达25辆车的情况下，成功率超过90%，并且在1秒内完成。在100米x100米地图上，在高达50辆车的情况下，成功率超过95%，并且在高达90辆车的情况下仍然可行，运行时间比仅优化方法快一个数量级。SMART还通过车路协同提高了可扩展性和安全性，在真实世界实验中规划时间低至0.014秒。

Conclusion: SMART框架通过结合分层搜索和分布式优化，有效地解决了多车轨迹规划的挑战，在各种场景下都表现出卓越的性能、可扩展性和效率，并且通过车路协同进一步增强了安全性。

Abstract: Multi-vehicle trajectory planning is a non-convex problem that becomes
increasingly difficult in dense environments due to the rapid growth of
collision constraints. Efficient exploration of feasible behaviors and
resolution of tight interactions are essential for real-time, large-scale
coordination. This paper introduces SMART, Scalable Multi-Agent Reasoning and
Trajectory Planning, a hierarchical framework that combines priority-based
search with distributed optimization to achieve efficient and feasible
multi-vehicle planning. The upper layer explores diverse interaction modes
using reinforcement learning-based priority estimation and large-step hybrid A*
search, while the lower layer refines solutions via parallelizable convex
optimization. By partitioning space among neighboring vehicles and constructing
robust feasible corridors, the method decouples the joint non-convex problem
into convex subproblems solved efficiently in parallel. This design alleviates
the step-size trade-off while ensuring kinematic feasibility and collision
avoidance. Experiments show that SMART consistently outperforms baselines. On
50 m x 50 m maps, it sustains over 90% success within 1 s up to 25 vehicles,
while baselines often drop below 50%. On 100 m x 100 m maps, SMART achieves
above 95% success up to 50 vehicles and remains feasible up to 90 vehicles,
with runtimes more than an order of magnitude faster than optimization-only
approaches. Built on vehicle-to-everything communication, SMART incorporates
vehicle-infrastructure cooperation through roadside sensing and agent
coordination, improving scalability and safety. Real-world experiments further
validate this design, achieving planning times as low as 0.014 s while
preserving cooperative behaviors.

</details>


### [210] [GP3: A 3D Geometry-Aware Policy with Multi-View Images for Robotic Manipulation](https://arxiv.org/abs/2509.15733)
*Quanhao Qian,Guoyang Zhao,Gongjie Zhang,Jiuniu Wang,Ran Xu,Junlong Gao,Deli Zhao*

Main category: cs.RO

TL;DR: GP3是一个利用多视图输入进行3D几何感知机器人操作的策略，能够进行精确的3D场景几何理解，并在模拟和真实环境中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 有效的机器人操作依赖于对3D场景几何的精确理解，而通过多视图观测是获取这种几何最直接的方法之一。

Method: GP3采用空间编码器从RGB观测中推断出密集的空间特征，从而估算出深度和相机参数，形成一个针对操作而优化的紧凑而富有表现力的3D场景表示。该表示与语言指令融合，并通过轻量级的策略头转化为连续动作。

Result: GP3在模拟基准测试中始终优于最先进的方法。此外，GP3在无需深度传感器或预映射环境的真实机器人上也能有效迁移，仅需极少的微调。

Conclusion: GP3是一种实用的、与传感器无关的、用于几何感知机器人操作的解决方案。

Abstract: Effective robotic manipulation relies on a precise understanding of 3D scene
geometry, and one of the most straightforward ways to acquire such geometry is
through multi-view observations. Motivated by this, we present GP3 -- a 3D
geometry-aware robotic manipulation policy that leverages multi-view input. GP3
employs a spatial encoder to infer dense spatial features from RGB
observations, which enable the estimation of depth and camera parameters,
leading to a compact yet expressive 3D scene representation tailored for
manipulation. This representation is fused with language instructions and
translated into continuous actions via a lightweight policy head. Comprehensive
experiments demonstrate that GP3 consistently outperforms state-of-the-art
methods on simulated benchmarks. Furthermore, GP3 transfers effectively to
real-world robots without depth sensors or pre-mapped environments, requiring
only minimal fine-tuning. These results highlight GP3 as a practical,
sensor-agnostic solution for geometry-aware robotic manipulation.

</details>


### [211] [An MPC framework for efficient navigation of mobile robots in cluttered environments](https://arxiv.org/abs/2509.15917)
*Johannes Köhler,Daniel Zhang,Raffaele Soloperto,Andrea Carron,Melanie Zeilinger*

Main category: cs.RO

TL;DR: We present an MPC framework for mobile robot navigation in cluttered environments, integrating a shortest path planner for dynamic target selection and collision avoidance, validated by hardware experiments.


<details>
  <summary>Details</summary>
Motivation: To enable efficient navigation of mobile robots in cluttered environments, ensuring convergence to dynamically selected targets and guaranteeing collision avoidance under general nonlinear dynamics.

Method: The proposed approach integrates a finite-segment shortest path planner into the finite-horizon trajectory optimization of the Model Predictive Control (MPC) framework.

Result: The approach was validated through hardware experiments on a small ground robot, which successfully navigated complex environments and reached dynamically assigned targets within 2-3 seconds.

Conclusion: The presented MPC framework is effective for efficient and safe navigation of mobile robots in cluttered environments with dynamic targets.

Abstract: We present a model predictive control (MPC) framework for efficient
navigation of mobile robots in cluttered environments. The proposed approach
integrates a finite-segment shortest path planner into the finite-horizon
trajectory optimization of the MPC. This formulation ensures convergence to
dynamically selected targets and guarantees collision avoidance, even under
general nonlinear dynamics and cluttered environments. The approach is
validated through hardware experiments on a small ground robot, where a human
operator dynamically assigns target locations. The robot successfully navigated
through complex environments and reached new targets within 2-3 seconds.

</details>


### [212] [FlyKites: Human-centric Interactive Exploration and Assistance under Limited Communication](https://arxiv.org/abs/2509.15807)
*Yuyang Zhang,Zhuoli Tian,Jinsheng Wei,Meng Guo*

Main category: cs.RO

TL;DR: FlyKites是一个新颖的人本交互式探索和辅助框架，用于解决多机器人系统在通信受限情况下的探索问题。它通过“扩散模式”进行分布式探索和间歇通信，“中继模式”优化中继拓扑、操作员路径和机器人角色分配，以及“人机环回在线执行”模式实现自适应交互，以最小延迟提供所有请求的协助。


<details>
  <summary>Details</summary>
Motivation: 在对未知环境进行探索（如地下、侦察、搜救）时，多机器人系统可能会遇到通信受限的问题，需要持续的人类协助，而传统的近距离通信方式难以满足需求。

Method: FlyKites框架包含三个交错的组件：1. 扩散模式：机器人协同探索环境，并与操作员进行分布式和间歇式通信。2. 中继模式：同时优化中继拓扑、操作员路径和机器人中继角色分配，以最小化延迟。3. 人机环回在线执行：机器人自适应地切换角色并与操作员进行交互。

Result: 通过大量的人机环回模拟和硬件实验，证明了FlyKites在充满挑战的环境下具有有效的性能。

Conclusion: FlyKites框架能够有效地解决多机器人系统在通信受限情况下的探索和人类协助问题，通过优化的通信和角色分配策略，实现高效的交互和低延迟的响应。

Abstract: Fleets of autonomous robots have been deployed for exploration of unknown
scenes for features of interest, e.g., subterranean exploration,
reconnaissance, search and rescue missions. During exploration, the robots may
encounter un-identified targets, blocked passages, interactive objects,
temporary failure, or other unexpected events, all of which require consistent
human assistance with reliable communication for a time period. This however
can be particularly challenging if the communication among the robots is
severely restricted to only close-range exchange via ad-hoc networks,
especially in extreme environments like caves and underground tunnels. This
paper presents a novel human-centric interactive exploration and assistance
framework called FlyKites, for multi-robot systems under limited communication.
It consists of three interleaved components: (I) the distributed exploration
and intermittent communication (called the "spread mode"), where the robots
collaboratively explore the environment and exchange local data among the fleet
and with the operator; (II) the simultaneous optimization of the relay
topology, the operator path, and the assignment of robots to relay roles
(called the "relay mode"), such that all requested assistance can be provided
with minimum delay; (III) the human-in-the-loop online execution, where the
robots switch between different roles and interact with the operator
adaptively. Extensive human-in-the-loop simulations and hardware experiments
are performed over numerous challenging scenes.

</details>


### [213] [Coordinated Multi-Drone Last-mile Delivery: Learning Strategies for Energy-aware and Timely Operations](https://arxiv.org/abs/2509.15830)
*Chuhao Qin,Arun Narayanan,Evangelos Pournaras*

Main category: cs.RO

TL;DR: 本文提出一种结合K-means聚类、强化学习和多智能体深度强化学习的算法，用于解决无人机多包裹、时效性强的配送问题，在效率和成本上均表现优异。


<details>
  <summary>Details</summary>
Motivation: 无人机在末端配送中展现出速度快、成本低、安全性高等优势，尤其在疫情期间的紧急医疗物资配送中作用显著。然而，在多包裹、时效性要求高以及无人机自身能量限制的情况下，如何优化无人机群的配送路线是一个新挑战。

Method: 该问题被分解为三个子问题：1. 使用K-means聚类优化仓库选址和服务区域；2. 通过强化学习确定无人机的最优飞行范围；3. 利用新的优化方案选择方法规划和选择多包裹配送路线。为整合这些方案并提升长期效率，提出了一种利用基于Actor-Critic的多智能体深度强化学习的新算法。

Result: 通过使用真实配送数据集进行的大量实验表明，所提出的算法具有出色的性能，在经济效率（最小化能耗）、快速操作（减少配送延迟和总体执行时间）以及为实际物流应用提供战略性仓库部署指导方面，均提供了新的见解。

Conclusion: 所提出的结合K-means聚类、强化学习和多智能体深度强化学习的算法，在解决无人机多包裹、时效性强的配送问题上取得了显著成效，能够在保证配送效率的同时，有效降低能耗和执行时间，并为仓库的战略部署提供了有价值的参考。

Abstract: Drones have recently emerged as a faster, safer, and cost-efficient way for
last-mile deliveries of parcels, particularly for urgent medical deliveries
highlighted during the pandemic. This paper addresses a new challenge of
multi-parcel delivery with a swarm of energy-aware drones, accounting for
time-sensitive customer requirements. Each drone plans an optimal multi-parcel
route within its battery-restricted flight range to minimize delivery delays
and reduce energy consumption. The problem is tackled by decomposing it into
three sub-problems: (1) optimizing depot locations and service areas using
K-means clustering; (2) determining the optimal flight range for drones through
reinforcement learning; and (3) planning and selecting multi-parcel delivery
routes via a new optimized plan selection approach. To integrate these
solutions and enhance long-term efficiency, we propose a novel algorithm
leveraging actor-critic-based multi-agent deep reinforcement learning.
Extensive experimentation using realistic delivery datasets demonstrate an
exceptional performance of the proposed algorithm. We provide new insights into
economic efficiency (minimize energy consumption), rapid operations (reduce
delivery delays and overall execution time), and strategic guidance on depot
deployment for practical logistics applications.

</details>


### [214] [High-Bandwidth Tactile-Reactive Control for Grasp Adjustment](https://arxiv.org/abs/2509.15876)
*Yonghyeon Lee,Tzu-Yuan Lin,Alexander Alexiev,Sangbae Kim*

Main category: cs.RO

TL;DR: 该研究提出了一种纯粹基于触觉反馈的抓取调整算法，以解决视觉抓取系统中存在的校准误差、传感器噪声和抓取姿态预测不准确等问题，从而提高抓取的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 视觉抓取系统由于校准误差、传感器噪声和抓取姿态预测不准确等问题，在抓取过程中存在固有的接触不确定性。高带宽的触觉反馈与精心设计的触觉反应控制器相结合，可以显著提高系统在感知错误情况下的鲁棒性。

Method: 提出了一种纯粹基于触觉反馈的抓取调整算法。该控制器不需要物体几何的先验知识或准确的抓取姿态，即使从粗略、不精确的初始配置和不确定的接触点开始，也能够优化抓取。

Result: 通过仿真研究和在配备了指尖触觉传感器（工作频率为 200 Hz）的 15-DoF 机械臂（具有 8-DoF 手）上的实际实验，证明了所提出的基于触觉反应的抓取框架能够有效地提高抓取稳定性。

Conclusion: 所提出的纯粹基于触觉反馈的抓取调整算法能够有效提高抓取稳定性，并且不依赖于物体的几何信息或精确的初始抓取姿态。

Abstract: Vision-only grasping systems are fundamentally constrained by calibration
errors, sensor noise, and grasp pose prediction inaccuracies, leading to
unavoidable contact uncertainty in the final stage of grasping. High-bandwidth
tactile feedback, when paired with a well-designed tactile-reactive controller,
can significantly improve robustness in the presence of perception errors. This
paper contributes to controller design by proposing a purely tactile-feedback
grasp-adjustment algorithm. The proposed controller requires neither prior
knowledge of the object's geometry nor an accurate grasp pose, and is capable
of refining a grasp even when starting from a crude, imprecise initial
configuration and uncertain contact points. Through simulation studies and
real-world experiments on a 15-DoF arm-hand system (featuring an 8-DoF hand)
equipped with fingertip tactile sensors operating at 200 Hz, we demonstrate
that our tactile-reactive grasping framework effectively improves grasp
stability.

</details>


### [215] [Improving Robotic Manipulation with Efficient Geometry-Aware Vision Encoder](https://arxiv.org/abs/2509.15880)
*An Dinh Vuong,Minh Nhat Vu,Ian Reid*

Main category: cs.RO

TL;DR: 本研究将几何感知视觉表示整合到机器人操作的模仿学习中，使用高效的eVGGT编码器，在多个任务中提高了成功率，并显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的基于RGB的模仿学习方法缺乏明确的3D推理能力，而几何感知视觉模型（如VGGT）在这方面表现出色。本研究旨在探索将几何感知视觉表示集成到机器人操作中，以克服现有方法的局限性。

Method: 将几何感知视觉编码器（VGGT）集成到模仿学习框架（ACT和DP）中，并提出了一种高效的蒸馏版本eVGGT，以解决高计算成本问题。

Result: 将几何感知视觉编码器集成到模仿学习框架中，在模拟和真实世界的多项操作任务中，成功率相比标准视觉编码器最多提高了6.5%。高效的eVGGT编码器速度是VGGT的近9倍，体积是VGGT的1/5，同时保留了强大的3D推理能力。

Conclusion: 几何感知视觉表示可以显著提高机器人操作模仿学习的性能。提出的eVGGT编码器在保持强大3D推理能力的同时，实现了高效的计算，为在实际机器人系统中部署几何感知模型提供了解决方案。

Abstract: Existing RGB-based imitation learning approaches typically employ traditional
vision encoders such as ResNet or ViT, which lack explicit 3D reasoning
capabilities. Recent geometry-grounded vision models, such as
VGGT~\cite{wang2025vggt}, provide robust spatial understanding and are
promising candidates to address this limitation. This work investigates the
integration of geometry-aware visual representations into robotic manipulation.
Our results suggest that incorporating the geometry-aware vision encoder into
imitation learning frameworks, including ACT and DP, yields up to 6.5%
improvement over standard vision encoders in success rate across single- and
bi-manual manipulation tasks in both simulation and real-world settings.
Despite these benefits, most geometry-grounded models require high
computational cost, limiting their deployment in practical robotic systems. To
address this challenge, we propose eVGGT, an efficient geometry-aware encoder
distilled from VGGT. eVGGT is nearly 9 times faster and 5 times smaller than
VGGT, while preserving strong 3D reasoning capabilities. Code and pretrained
models will be released to facilitate further research in geometry-aware
robotics.

</details>


### [216] [A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning](https://arxiv.org/abs/2509.15937)
*Shaopeng Zhai,Qi Zhang,Tianyi Zhang,Fuxian Huang,Haoran Zhang,Ming Zhou,Shengzhe Zhang,Litao Liu,Sixu Lin,Jiangmiao Pang*

Main category: cs.RO

TL;DR: VLAC是一个基于InternVL的通用过程奖励模型，通过结合视觉-语言-动作（VLA）模型和强化学习（RL），解决了机器人现实世界RL中稀疏奖励和低效探索的问题。它能输出密集的进度信号和完成信号，无需任务特定奖励设计，并支持单样本跨任务和跨环境迁移。VLAC还通过引入人类在循环（human-in-the-loop）机制，进一步提高了样本效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 机器人现实世界强化学习（RL）受限于稀疏、手工设计的奖励和低效的探索。VLAC旨在通过一个通用的过程奖励模型来解决这些问题。

Method: VLAC是一个基于InternVL的通用过程奖励模型，通过在大型异构数据集上进行训练，输出密集的进度增量和完成信号。它利用视觉-语言数据集增强感知、对话和推理能力，并结合机器人和人类轨迹数据来指导动作生成和进度估计。通过构造大量的负样本和语义不匹配样本，VLAC被加强以拒绝不相关的提示并检测回归或停滞。在异步现实世界RL循环中，VLAC与分级的“人类在循环”协议（离线演示重放、回报与探索、人类引导探索）相结合，以加速探索和稳定早期学习。

Result: 在四个不同的现实世界操纵任务中，VLAC将成功率从约30%提高到约90%，交互200次。结合“人类在循环”干预措施，样本效率提高了50%，最终成功率高达100%。

Conclusion: VLAC通过提供密集的奖励信号和利用“人类在循环”机制，显著提高了机器人现实世界强化学习的效率和成功率，克服了传统方法的局限性。

Abstract: Robotic real-world reinforcement learning (RL) with vision-language-action
(VLA) models is bottlenecked by sparse, handcrafted rewards and inefficient
exploration. We introduce VLAC, a general process reward model built upon
InternVL and trained on large scale heterogeneous datasets. Given pairwise
observations and a language goal, it outputs dense progress delta and done
signal, eliminating task-specific reward engineering, and supports one-shot
in-context transfer to unseen tasks and environments. VLAC is trained on
vision-language datasets to strengthen perception, dialogic and reasoning
capabilities, together with robot and human trajectories data that ground
action generation and progress estimation, and additionally strengthened to
reject irrelevant prompts as well as detect regression or stagnation by
constructing large numbers of negative and semantically mismatched samples.
With prompt control, a single VLAC model alternately generating reward and
action tokens, unifying critic and policy. Deployed inside an asynchronous
real-world RL loop, we layer a graded human-in-the-loop protocol (offline
demonstration replay, return and explore, human guided explore) that
accelerates exploration and stabilizes early learning. Across four distinct
real-world manipulation tasks, VLAC lifts success rates from about 30\% to
about 90\% within 200 real-world interaction episodes; incorporating
human-in-the-loop interventions yields a further 50% improvement in sample
efficiency and achieves up to 100% final success.

</details>


### [217] [Right-Side-Out: Learning Zero-Shot Sim-to-Real Garment Reversal](https://arxiv.org/abs/2509.15953)
*Chang Yu,Siyu Ma,Wenxin Du,Zeshun Zong,Han Xue,Wendi Chen,Cewu Lu,Yin Yang,Xuchen Han,Joseph Masterjohn,Alejandro Castro,Chenfanfu Jiang*

Main category: cs.RO

TL;DR: 右侧颠倒衣物是一个具有挑战性的操作任务，通过利用任务结构，该零样本模拟到现实的框架通过分解任务为“拖动/挥动”和“插入和拉动”两个阶段来解决这个挑战，并使用参数化的双手机器人操作来减少动作空间。


<details>
  <summary>Details</summary>
Motivation: 衣物右转是一个动态的、具有快速接触变化和严重视觉遮挡的操作任务。

Method: 将任务分解为‘拖动/挥动’和‘插入和拉动’两个阶段，并使用深度推断、关键点参数化的双手机器人操作来减少动作空间。使用定制的高保真GPU并行材料点法(MPM)模拟器进行数据生成，该模拟器对薄壳变形进行建模并处理批处理的接触。通过随机化衣物几何、材料参数和视点来扩展数据生成，并生成深度、蒙版和每原始关键点标签，无需人工标注。

Result: 在真实硬件上实现了高达81.3%的成功率。

Conclusion: 通过任务分解和高保真模拟，该框架能够处理高度动态、严重遮挡的任务，而无需耗费人力进行演示。

Abstract: Turning garments right-side out is a challenging manipulation task: it is
highly dynamic, entails rapid contact changes, and is subject to severe visual
occlusion. We introduce Right-Side-Out, a zero-shot sim-to-real framework that
effectively solves this challenge by exploiting task structures. We decompose
the task into Drag/Fling to create and stabilize an access opening, followed by
Insert&Pull to invert the garment. Each step uses a depth-inferred,
keypoint-parameterized bimanual primitive that sharply reduces the action space
while preserving robustness. Efficient data generation is enabled by our
custom-built, high-fidelity, GPU-parallel Material Point Method (MPM) simulator
that models thin-shell deformation and provides robust and efficient contact
handling for batched rollouts. Built on the simulator, our fully automated
pipeline scales data generation by randomizing garment geometry, material
parameters, and viewpoints, producing depth, masks, and per-primitive keypoint
labels without any human annotations. With a single depth camera, policies
trained entirely in simulation deploy zero-shot on real hardware, achieving up
to 81.3% success rate. By employing task decomposition and high fidelity
simulation, our framework enables tackling highly dynamic, severely occluded
tasks without laborious human demonstrations.

</details>


### [218] [Swarm Oracle: Trustless Blockchain Agreements through Robot Swarms](https://arxiv.org/abs/2509.15956)
*Alexandre Pacheco,Hanqing Zhao,Volker Strobel,Tarik Roukny,Gregory Dudek,Andreagiovanni Reina,Marco Dorigo*

Main category: cs.RO

TL;DR: Swarm Oracle是一个去中心化的机器人网络，利用自主机器人和点对点通信来验证现实世界的数据，并将其提供给公共区块链上的智能合约。


<details>
  <summary>Details</summary>
Motivation: 现有的Oracle解决方案可能无法满足区块链对自主性、透明度和信任的需求。

Method: Swarm Oracle利用机器人群的去中心化、容错性和移动性，通过拜占庭容错协议整合来自多个利益相关者的机器人，以就现实世界的数据达成共识，并利用基于区块链代币的声誉系统进行故障和攻击恢复。

Result: 实验证明，Swarm Oracle能够就环境信息达成共识，即使在存在机器人攻击的情况下，并且能够通过声誉系统从故障和攻击中恢复。

Conclusion: Swarm Oracle通过利用机器人群体的独特能力，为区块链提供了安全、可信的数据源，并具备自主恢复能力。

Abstract: Blockchain consensus, rooted in the principle ``don't trust, verify'', limits
access to real-world data, which may be ambiguous or inaccessible to some
participants. Oracles address this limitation by supplying data to blockchains,
but existing solutions may reduce autonomy, transparency, or reintroduce the
need for trust. We propose Swarm Oracle: a decentralized network of autonomous
robots -- that is, a robot swarm -- that use onboard sensors and peer-to-peer
communication to collectively verify real-world data and provide it to smart
contracts on public blockchains. Swarm Oracle leverages the built-in
decentralization, fault tolerance and mobility of robot swarms, which can
flexibly adapt to meet information requests on-demand, even in remote
locations. Unlike typical cooperative robot swarms, Swarm Oracle integrates
robots from multiple stakeholders, protecting the system from single-party
biases but also introducing potential adversarial behavior. To ensure the
secure, trustless and global consensus required by blockchains, we employ a
Byzantine fault-tolerant protocol that enables robots from different
stakeholders to operate together, reaching social agreements of higher quality
than the estimates of individual robots. Through extensive experiments using
both real and simulated robots, we showcase how consensus on uncertain
environmental information can be achieved, despite several types of attacks
orchestrated by large proportions of the robots, and how a reputation system
based on blockchain tokens lets Swarm Oracle autonomously recover from faults
and attacks, a requirement for long-term operation.

</details>


### [219] [CoReVLA: A Dual-Stage End-to-End Autonomous Driving Framework for Long-Tail Scenarios via Collect-and-Refine](https://arxiv.org/abs/2509.15968)
*Shiyu Fang,Yiming Cui,Haoyang Liang,Chen Lv,Peng Hang,Jian Sun*

Main category: cs.RO

TL;DR: CoReVLA是一个持续学习的端到端自动驾驶框架，通过数据收集和行为改进的双阶段过程，提高了在长尾场景中的性能。


<details>
  <summary>Details</summary>
Motivation: 长尾、安全关键场景是自动驾驶的性能瓶颈，现有VLA模型在此类场景中数据不足且学习效率低下。

Method: CoReVLA首先在开源驾驶问答数据集上进行微调，然后在CAVE仿真平台中收集驾驶员接管数据，最后使用直接偏好优化（DPO）从人类偏好中学习。

Result: CoReVLA在Bench2Drive基准测试中，在长尾、安全关键场景下，驾驶得分（DS）达到72.18，成功率（SR）达到50%，优于现有方法7.96 DS和15% SR。

Conclusion: CoReVLA能够持续改进其在类似易失败场景中的性能，并通过案例研究证明了这一点。

Abstract: Autonomous Driving (AD) systems have made notable progress, but their
performance in long-tail, safety-critical scenarios remains limited. These rare
cases contribute a disproportionate number of accidents. Vision-Language Action
(VLA) models have strong reasoning abilities and offer a potential solution,
but their effectiveness is limited by the lack of high-quality data and
inefficient learning in such conditions. To address these challenges, we
propose CoReVLA, a continual learning end-to-end autonomous driving framework
that improves the performance in long-tail scenarios through a dual-stage
process of data Collection and behavior Refinement. First, the model is jointly
fine-tuned on a mixture of open-source driving QA datasets, allowing it to
acquire a foundational understanding of driving scenarios. Next, CoReVLA is
deployed within the Cave Automatic Virtual Environment (CAVE) simulation
platform, where driver takeover data is collected from real-time interactions.
Each takeover indicates a long-tail scenario that CoReVLA fails to handle
reliably. Finally, the model is refined via Direct Preference Optimization
(DPO), allowing it to learn directly from human preferences and thereby avoid
reward hacking caused by manually designed rewards. Extensive open-loop and
closed-loop experiments demonstrate that the proposed CoReVLA model can
accurately perceive driving scenarios and make appropriate decisions. On the
Bench2Drive benchmark, CoReVLA achieves a Driving Score (DS) of 72.18 and a
Success Rate (SR) of 50%, outperforming state-of-the-art methods by 7.96 DS and
15% SR under long-tail, safety-critical scenarios. Furthermore, case studies
demonstrate the model's ability to continually improve its performance in
similar failure-prone scenarios by leveraging past takeover experiences. All
codea and preprocessed datasets are available at:
https://github.com/FanGShiYuu/CoReVLA

</details>


### [220] [Defining and Monitoring Complex Robot Activities via LLMs and Symbolic Reasoning](https://arxiv.org/abs/2509.16006)
*Francesco Argenziano,Elena Umili,Francesco Leotta,Daniele Nardi*

Main category: cs.RO

TL;DR: 使用LLM和自动化规划来使机器人能够理解和执行由人类用自然语言指定的复杂活动，并允许人类监控执行情况。


<details>
  <summary>Details</summary>
Motivation: 在工业和农业等动态环境中，机器人需要能够处理未预定义的、由多种原子任务组成的复杂活动，并且人类需要能够监控这些活动以确保安全执行。

Method: 提出一个整合LLM和自动化规划的通用架构，该架构允许人类用自然语言指定高层活动，并通过查询机器人来监控其执行情况。实现了该架构并用精准农业场景进行了量化评估。

Result: 在精准农业场景中，该方法得到了量化评估。

Conclusion: 所提出的架构能够使机器人理解并执行人类用自然语言指定的复杂活动，并允许人类进行监控。

Abstract: Recent years have witnessed a growing interest in automating labor-intensive
and complex activities, i.e., those consisting of multiple atomic tasks, by
deploying robots in dynamic and unpredictable environments such as industrial
and agricultural settings. A key characteristic of these contexts is that
activities are not predefined: while they involve a limited set of possible
tasks, their combinations may vary depending on the situation. Moreover,
despite recent advances in robotics, the ability for humans to monitor the
progress of high-level activities - in terms of past, present, and future
actions - remains fundamental to ensure the correct execution of
safety-critical processes. In this paper, we introduce a general architecture
that integrates Large Language Models (LLMs) with automated planning, enabling
humans to specify high-level activities (also referred to as processes) using
natural language, and to monitor their execution by querying a robot. We also
present an implementation of this architecture using state-of-the-art
components and quantitatively evaluate the approach in a real-world precision
agriculture scenario.

</details>


### [221] [A Matter of Height: The Impact of a Robotic Object on Human Compliance](https://arxiv.org/abs/2509.16032)
*Michael Faber,Andrey Grishko,Julian Waksberg,David Pardo,Tomer Leivy,Yuval Hazan,Emanuel Talmansky,Benny Megidish,Hadas Erel*

Main category: cs.RO

TL;DR: The study found that a shorter robot led to higher compliance with requests, contrary to human social dynamics where taller individuals are often perceived as more persuasive. Designers should not assume human interaction patterns directly apply to robots.


<details>
  <summary>Details</summary>
Motivation: To investigate whether the persuasive effect of height observed in human-human interactions extends to human-robot interactions, specifically with a non-humanoid robot.

Method: Participants were asked to volunteer for a tedious task by either a short (95cm) or tall (132cm) robot. Compliance rates were compared between the two conditions.

Result: Participants showed higher compliance with the requests of the shorter robot, indicating an inverse relationship compared to human social dynamics.

Conclusion: Height significantly impacts human-robot interaction, but in a manner distinct from human-human dynamics. Design elements from human social dynamics cannot be directly transferred to robots without empirical testing.

Abstract: Robots come in various forms and have different characteristics that may
shape the interaction with them. In human-human interactions, height is a
characteristic that shapes human dynamics, with taller people typically
perceived as more persuasive. In this work, we aspired to evaluate if the same
impact replicates in a human-robot interaction and specifically with a highly
non-humanoid robotic object. The robot was designed with modules that could be
easily added or removed, allowing us to change its height without altering
other design features. To test the impact of the robot's height, we evaluated
participants' compliance with its request to volunteer to perform a tedious
task. In the experiment, participants performed a cognitive task on a computer,
which was framed as the main experiment. When done, they were informed that the
experiment was completed. While waiting to receive their credits, the robotic
object, designed as a mobile robotic service table, entered the room, carrying
a tablet that invited participants to complete a 300-question questionnaire
voluntarily. We compared participants' compliance in two conditions: A Short
robot composed of two modules and 95cm in height and a Tall robot consisting of
three modules and 132cm in height. Our findings revealed higher compliance with
the Short robot's request, demonstrating an opposite pattern to human dynamics.
We conclude that while height has a substantial social impact on human-robot
interactions, it follows a unique pattern of influence. Our findings suggest
that designers cannot simply adopt and implement elements from human social
dynamics to robots without testing them first.

</details>


### [222] [Learning Safety for Obstacle Avoidance via Control Barrier Functions](https://arxiv.org/abs/2509.16037)
*Shuo Liu,Zhe Huang,Calin A. Belta*

Main category: cs.RO

TL;DR: 该研究提出了一种基于残差神经网络的局部安全球（LSB）方法，用于解决具有任意非凸几何形状的机器人在复杂环境中安全导航的障碍物规避问题。该方法通过训练神经网络来预测机器人与障碍物之间的距离，并利用该预测距离构建LSB，从而实现连续时间的无碰撞导航。LSB边界被编码为离散时间高阶CBF（DHOCBF），并结合非线性优化和一种新的松弛技术来提高可行性，确保了机器人刚体运动在连续时间内保持无碰撞。实验证明，该方法在处理复杂几何形状、生成无碰撞且动态可行轨迹方面表现出色，并且具有毫秒级的求解时间和高预测精度，在安全性和效率上优于现有的基于CBF的方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于控制障碍函数（CBF）的方法在处理具有任意非凸几何形状的机器人在复杂环境中导航时面临挑战，因为它们依赖于解析计算或多面体近似，这些方法对于复杂几何形状或未知机器人配置是不可行的。

Method: 该研究训练了一个残差神经网络，用于预测机器人与障碍物之间的距离，即使在未见过的情况下也能进行快速准确的预测。预测的距离定义了一个局部安全球（LSB）的半径，该球确保了连续时间的无碰撞导航。LSB边界被编码为一个离散时间高阶CBF（DHOCBF），其约束被纳入一个非线性优化框架。为了提高可行性，引入了一种新颖的松弛技术。

Result: 该框架确保了机器人刚体在连续时间步之间的运动是无碰撞的，有效地连接了离散时间控制和连续时间安全。该方法能够处理任意非凸机器人几何形状，并在杂乱环境中生成无碰撞、动态可行的轨迹。实验证明了该方法具有毫秒级的求解时间和高预测精度，在安全性和效率方面优于现有的基于CBF的方法。

Conclusion: 该研究提出的基于神经网络的局部安全球（LSB）方法，通过快速准确的距离预测和结合CBF的优化框架，有效解决了具有任意非凸几何形状机器人在复杂环境中安全导航的挑战，实现了高效且安全的自主导航。

Abstract: Obstacle avoidance is central to safe navigation, especially for robots with
arbitrary and nonconvex geometries operating in cluttered environments.
Existing Control Barrier Function (CBF) approaches often rely on analytic
clearance computations, which are infeasible for complex geometries, or on
polytopic approximations, which become intractable when robot configurations
are unknown. To address these limitations, this paper trains a residual neural
network on a large dataset of robot-obstacle configurations to enable fast and
tractable clearance prediction, even at unseen configurations. The predicted
clearance defines the radius of a Local Safety Ball (LSB), which ensures
continuous-time collision-free navigation. The LSB boundary is encoded as a
Discrete-Time High-Order CBF (DHOCBF), whose constraints are incorporated into
a nonlinear optimization framework. To improve feasibility, a novel relaxation
technique is applied. The resulting framework ensure that the robot's
rigid-body motion between consecutive time steps remains collision-free,
effectively bridging discrete-time control and continuous-time safety. We show
that the proposed method handles arbitrary, including nonconvex, robot
geometries and generates collision-free, dynamically feasible trajectories in
cluttered environments. Experiments demonstrate millisecond-level solve times
and high prediction accuracy, highlighting both safety and efficiency beyond
existing CBF-based methods.

</details>


### [223] [Compose by Focus: Scene Graph-based Atomic Skills](https://arxiv.org/abs/2509.16053)
*Han Qi,Changhe Chen,Heng Yang*

Main category: cs.RO

TL;DR: 机器人需要组合原子技能来解决复杂任务，但现有方法在技能执行的鲁棒性方面存在挑战。本文提出了一种基于场景图的表示方法，并结合图神经网络和基于扩散的模仿学习来学习技能，最终结合视觉-语言模型进行任务规划，在模拟和现实世界中均取得了更好的效果。


<details>
  <summary>Details</summary>
Motivation: 提高通用机器人的组合泛化能力，使其能够结合原子技能解决复杂、长周期的任务，并解决现有 visuomotor 策略在面对场景变化时鲁棒性不足的问题。

Method: 提出一种基于场景图的表示方法，该方法关注任务相关的物体和关系，以减少对无关变化的敏感性。在此基础上，开发了一个场景图技能学习框架，集成了图神经网络和基于扩散的模仿学习。最后，将“聚焦”的场景图技能与基于视觉-语言模型（VLM）的任务规划器相结合。

Result: 在模拟和现实世界的操纵任务中，与最先进的方法相比，成功率得到了显著提高，证明了在长周期任务中鲁棒性和组合泛化能力的改进。

Conclusion: 所提出的基于场景图的表示和学习框架能够显著提高机器人在长周期任务中的鲁棒性和组合泛化能力。

Abstract: A key requirement for generalist robots is compositional generalization - the
ability to combine atomic skills to solve complex, long-horizon tasks. While
prior work has primarily focused on synthesizing a planner that sequences
pre-learned skills, robust execution of the individual skills themselves
remains challenging, as visuomotor policies often fail under distribution
shifts induced by scene composition. To address this, we introduce a scene
graph-based representation that focuses on task-relevant objects and relations,
thereby mitigating sensitivity to irrelevant variation. Building on this idea,
we develop a scene-graph skill learning framework that integrates graph neural
networks with diffusion-based imitation learning, and further combine "focused"
scene-graph skills with a vision-language model (VLM) based task planner.
Experiments in both simulation and real-world manipulation tasks demonstrate
substantially higher success rates than state-of-the-art baselines,
highlighting improved robustness and compositional generalization in
long-horizon tasks.

</details>


### [224] [Latent Conditioned Loco-Manipulation Using Motion Priors](https://arxiv.org/abs/2509.16061)
*Maciej Stępień,Rafael Kourdis,Constant Roux,Olivier Stasse*

Main category: cs.RO

TL;DR: 本文将模仿学习与潜在空间控制相结合，应用于人形和四足机器人的运动操纵任务，并解决了安全约束和模仿质量问题。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人控制方法（如深度强化学习）主要关注单一技能，对于需要考虑高级目标、机器人物理限制和期望运动风格的复杂任务效率低下。

Method: 通过模仿简单合成运动或运动学重新定向的犬类运动，训练一个多功能运动策略，该策略通过模仿获得低级技能，并提供对技能执行的潜在空间控制。此外，还引入了处理约束以确保部署安全性的方法，并使用扩散判别器来提高模仿质量。

Result: 在H1人形机器人和Solo12四足机器人的模拟环境中进行了运动操纵验证，并在Solo12硬件上进行了策略部署。

Conclusion: 所提出的方法能够有效地应用于人形和四足机器人的运动操纵任务，解决了现有方法的局限性。

Abstract: Although humanoid and quadruped robots provide a wide range of capabilities,
current control methods, such as Deep Reinforcement Learning, focus mainly on
single skills. This approach is inefficient for solving more complicated tasks
where high-level goals, physical robot limitations and desired motion style
might all need to be taken into account. A more effective approach is to first
train a multipurpose motion policy that acquires low-level skills through
imitation, while providing latent space control over skill execution. Then,
this policy can be used to efficiently solve downstream tasks. This method has
already been successful for controlling characters in computer graphics. In
this work, we apply the approach to humanoid and quadrupedal loco-manipulation
by imitating either simple synthetic motions or kinematically retargeted dog
motions. We extend the original formulation to handle constraints, ensuring
deployment safety, and use a diffusion discriminator for better imitation
quality. We verify our methods by performing loco-manipulation in simulation
for the H1 humanoid and Solo12 quadruped, as well as deploying policies on
Solo12 hardware. Videos and code are available at
https://gepetto.github.io/LaCoLoco/

</details>


### [225] [DSPv2: Improved Dense Policy for Effective and Generalizable Whole-body Mobile Manipulation](https://arxiv.org/abs/2509.16063)
*Yue Su,Chubin Zhang,Sijin Chen,Liufan Tan,Yansong Tang,Jianan Wang,Xihui Liu*

Main category: cs.RO

TL;DR: DSPv2通过融合3D空间特征和多视图2D语义特征，并在全身机器人操作中扩展了密集策略范式，从而在任务性能和泛化能力上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了在多样化的环境和复杂的任务中实现机器人技能的泛化，需要通过模仿来学习全身的移动操作，但现有的方法在处理复杂观测、实现鲁棒泛化和生成连贯动作方面存在挑战。

Method: 提出了一种名为DSPv2的新型策略架构，它采用了一种有效的编码方案来融合3D空间特征和多视图2D语义特征，并将在全身移动操作领域扩展了密集策略范式。

Result: DSPv2在任务性能和泛化能力方面显著优于现有方法。

Conclusion: DSPv2通过有效的特征融合和密集策略范式的扩展，成功解决了全身移动操作中的复杂观测处理、鲁棒泛化和连贯动作生成等挑战，并在实验中证明了其优越性。

Abstract: Learning whole-body mobile manipulation via imitation is essential for
generalizing robotic skills to diverse environments and complex tasks. However,
this goal is hindered by significant challenges, particularly in effectively
processing complex observation, achieving robust generalization, and generating
coherent actions. To address these issues, we propose DSPv2, a novel policy
architecture. DSPv2 introduces an effective encoding scheme that aligns 3D
spatial features with multi-view 2D semantic features. This fusion enables the
policy to achieve broad generalization while retaining the fine-grained
perception necessary for precise control. Furthermore, we extend the Dense
Policy paradigm to the whole-body mobile manipulation domain, demonstrating its
effectiveness in generating coherent and precise actions for the whole-body
robotic platform. Extensive experiments show that our method significantly
outperforms existing approaches in both task performance and generalization
ability. Project page is available at: https://selen-suyue.github.io/DSPv2Net/.

</details>


### [226] [I-FailSense: Towards General Robotic Failure Detection with Vision-Language Models](https://arxiv.org/abs/2509.16072)
*Clemence Grislain,Hamed Rahimi,Olivier Sigaud,Mohamed Chetouani*

Main category: cs.RO

TL;DR: 本研究提出了一种名为I-FailSense的框架，用于提高机器人对语言指令的理解和执行能力，特别是针对语义不一致的错误进行检测。


<details>
  <summary>Details</summary>
Motivation: 现有机器人技术在理解和执行语言指令方面存在不足，尤其是在检测自身执行过程中发生的语义不一致错误方面能力有限。这阻碍了机器人在开放世界环境中进行稳健部署。

Method: 提出了一种构建语义不一致性错误检测数据集的方法，并开发了I-FailSense框架。该框架通过对基础视觉语言模型（VLM）进行后训练，并附加轻量级的分类头（FS块）在不同内部层进行训练，最后通过集成机制聚合预测结果。

Result: I-FailSense在语义不一致性错误检测方面优于现有同类和更大规模的VLM。此外，即使仅在语义不一致性检测上进行训练，I-FailSense也能泛化到更广泛的机器人故障类别，并在其他模拟环境和真实世界中实现零样本或少量微调的有效迁移。

Conclusion: I-FailSense框架在提高机器人对语言指令的鲁棒性方面取得了显著进展，尤其在检测和处理语义不一致性错误方面表现出色，并具备良好的泛化和迁移能力。

Abstract: Language-conditioned robotic manipulation in open-world settings requires not
only accurate task execution but also the ability to detect failures for robust
deployment in real-world environments. Although recent advances in
vision-language models (VLMs) have significantly improved the spatial reasoning
and task-planning capabilities of robots, they remain limited in their ability
to recognize their own failures. In particular, a critical yet underexplored
challenge lies in detecting semantic misalignment errors, where the robot
executes a task that is semantically meaningful but inconsistent with the given
instruction. To address this, we propose a method for building datasets
targeting Semantic Misalignment Failures detection, from existing
language-conditioned manipulation datasets. We also present I-FailSense, an
open-source VLM framework with grounded arbitration designed specifically for
failure detection. Our approach relies on post-training a base VLM, followed by
training lightweight classification heads, called FS blocks, attached to
different internal layers of the VLM and whose predictions are aggregated using
an ensembling mechanism. Experiments show that I-FailSense outperforms
state-of-the-art VLMs, both comparable in size and larger, in detecting
semantic misalignment errors. Notably, despite being trained only on semantic
misalignment detection, I-FailSense generalizes to broader robotic failure
categories and effectively transfers to other simulation environments and
real-world with zero-shot or minimal post-training. The datasets and models are
publicly released on HuggingFace (Webpage:
https://clemgris.github.io/I-FailSense/).

</details>


### [227] [Real-Time Planning and Control with a Vortex Particle Model for Fixed-Wing UAVs in Unsteady Flows](https://arxiv.org/abs/2509.16079)
*Ashwin Gupta,Kevin Wolfe,Gino Perrotta,Joseph Moore*

Main category: cs.RO

TL;DR: 该研究提出了一种能够考虑非定常空气动力学的实时规划与控制方法，该方法使用轻量化的涡流粒子模型和基于采样的策略优化，并通过仿真和实验证明其能提高飞机在复杂气流中的机动性能。


<details>
  <summary>Details</summary>
Motivation: 非定常空气动力学效应对航空器飞行性能，特别是在敏捷机动和复杂气动环境中，有显著影响。

Method: 研究采用轻量化的涡流粒子模型，并进行了GPU并行加速，同时结合了基于采样的策略优化方法，以利用涡流粒子模型进行预测性推理。

Result: 通过仿真和硬件实验证明，通过使用非定常空气动力学模型进行重新规划，可以提高飞机在存在非定常环境气流干扰的情况下，进行剧烈后失速机动的性能。

Conclusion: 所提出的考虑非定常空气动力学的实时规划与控制方法能够有效提升航空器的机动性能，尤其是在应对复杂气动环境时。

Abstract: Unsteady aerodynamic effects can have a profound impact on aerial vehicle
flight performance, especially during agile maneuvers and in complex
aerodynamic environments. In this paper, we present a real-time planning and
control approach capable of reasoning about unsteady aerodynamics. Our approach
relies on a lightweight vortex particle model, parallelized to allow GPU
acceleration, and a sampling-based policy optimization strategy capable of
leveraging the vortex particle model for predictive reasoning. We demonstrate,
through both simulation and hardware experiments, that by replanning with our
unsteady aerodynamics model, we can improve the performance of aggressive
post-stall maneuvers in the presence of unsteady environmental flow
disturbances.

</details>


### [228] [Efficient Detection of Objects Near a Robot Manipulator via Miniature Time-of-Flight Sensors](https://arxiv.org/abs/2509.16122)
*Carter Sifferman,Mohit Gupta,Michael Gleicher*

Main category: cs.RO

TL;DR: 提出一种利用机械臂搭载的飞行时间（ToF）传感器检测和定位机械臂附近物体的方法，解决了区分机器人本体和外部物体的挑战。


<details>
  <summary>Details</summary>
Motivation: 利用机械臂搭载的传感器检测和定位机械臂附近的物体，并解决区分机器人本体和外部物体在传感器测量中的挑战。

Method: 提出一种计算量轻量级的方法，该方法利用了许多现成的、低分辨率的ToF传感器捕获的原始飞行时间信息。通过构建一个机器人本体存在时预期的传感器测量经验模型，并在运行时使用该模型来检测机器人附近的物体。

Result: 该方法不仅能避免在常见的传感器配置中出现机器人自身检测，还能在传感器放置方面提供额外的灵活性，从而实现对机器人臂半径区域更有效的覆盖。该方法能够检测机械臂附近的小物体，并以合理的精度定位物体在机器人连杆上的位置。

Conclusion: 该方法在物体类型、位置和环境光照水平方面进行了性能评估，并识别了测量原理中固有的性能限制因素。所提出的方法在碰撞避免和促进安全的人机交互方面具有潜在应用价值。

Abstract: We provide a method for detecting and localizing objects near a robot arm
using arm-mounted miniature time-of-flight sensors. A key challenge when using
arm-mounted sensors is differentiating between the robot itself and external
objects in sensor measurements. To address this challenge, we propose a
computationally lightweight method which utilizes the raw time-of-flight
information captured by many off-the-shelf, low-resolution time-of-flight
sensor. We build an empirical model of expected sensor measurements in the
presence of the robot alone, and use this model at runtime to detect objects in
proximity to the robot. In addition to avoiding robot self-detections in common
sensor configurations, the proposed method enables extra flexibility in sensor
placement, unlocking configurations which achieve more efficient coverage of a
radius around the robot arm. Our method can detect small objects near the arm
and localize the position of objects along the length of a robot link to
reasonable precision. We evaluate the performance of the method with respect to
object type, location, and ambient light level, and identify limiting factors
on performance inherent in the measurement principle. The proposed method has
potential applications in collision avoidance and in facilitating safe
human-robot interaction.

</details>


### [229] [Reward Evolution with Graph-of-Thoughts: A Bi-Level Language Model Framework for Reinforcement Learning](https://arxiv.org/abs/2509.16136)
*Changwei Yao,Xinzi Liu,Chen Li,Marios Savvides*

Main category: cs.RO

TL;DR: RE-GoT是一个新的双层框架，它利用图论和视觉语言模型来自动化强化学习中的奖励函数设计。


<details>
  <summary>Details</summary>
Motivation: 设计有效的奖励函数是强化学习中的一个重大挑战，通常需要大量的人工专业知识和迭代优化。虽然大型语言模型（LLM）已被用于自动化奖励设计，但它们存在幻觉、依赖人工反馈以及难以处理复杂多步任务的局限性。

Method: RE-GoT首先将任务分解为具有文本属性的图，以进行全面的分析和奖励函数的生成，然后利用视觉语言模型（VLM）的视觉反馈进行迭代优化，无需人工干预。

Result: 在RoboGen和ManiSkill2任务上的大量实验表明，RE-GoT的性能始终优于现有的基于LLM的基线。在RoboGen上，我们的方法将平均任务成功率提高了32.25%，在复杂的多步任务上取得了显著的进步。在ManiSkill2上，RE-GoT在四项不同的操作任务上的平均成功率为93.73%，显著超过了之前的基于LLM的方法，甚至超过了专家设计的奖励。

Conclusion: 结合LLM和VLM以及图论推理，为自主奖励演化提供了一个可扩展且有效的解决方案。

Abstract: Designing effective reward functions remains a major challenge in
reinforcement learning (RL), often requiring considerable human expertise and
iterative refinement. Recent advances leverage Large Language Models (LLMs) for
automated reward design, but these approaches are limited by hallucinations,
reliance on human feedback, and challenges with handling complex, multi-step
tasks. In this work, we introduce Reward Evolution with Graph-of-Thoughts
(RE-GoT), a novel bi-level framework that enhances LLMs with structured
graph-based reasoning and integrates Visual Language Models (VLMs) for
automated rollout evaluation. RE-GoT first decomposes tasks into
text-attributed graphs, enabling comprehensive analysis and reward function
generation, and then iteratively refines rewards using visual feedback from
VLMs without human intervention. Extensive experiments on 10 RoboGen and 4
ManiSkill2 tasks demonstrate that RE-GoT consistently outperforms existing
LLM-based baselines. On RoboGen, our method improves average task success rates
by 32.25%, with notable gains on complex multi-step tasks. On ManiSkill2,
RE-GoT achieves an average success rate of 93.73% across four diverse
manipulation tasks, significantly surpassing prior LLM-based approaches and
even exceeding expert-designed rewards. Our results indicate that combining
LLMs and VLMs with graph-of-thoughts reasoning provides a scalable and
effective solution for autonomous reward evolution in RL.

</details>


### [230] [Modeling Elastic-Body Dynamics of Fish Swimming Using a Variational Framework](https://arxiv.org/abs/2509.16145)
*Zhiheng Chen,Wei Wang*

Main category: cs.RO

TL;DR: 该论文提出了一种基于Hamilton原理推导的鱼类游动全身体动力学模型，用于优化和控制水下软体机器鱼的设计。


<details>
  <summary>Details</summary>
Motivation: 为了支持鱼类水下机器人的设计优化和控制，需要一个准确、可解释且计算上可行的模型来描述其游动动力学。

Method: 利用Hamilton原理推导了鱼类游动全身体动力学模型，考虑了变形鱼体的大变形和流固耦合效应，实现了无需预设运动学即可自主推进的运动。

Result: 模拟研究了驱动频率和身体刚度对游动速度和运输成本的影响，发现游动速度和能源效率随尾部拍打频率呈现相反趋势，并且身体刚度和长度存在最优值。

Conclusion: 研究结果为理解生物游动机制提供了见解，并为设计高性能的软体机器人游泳器提供了依据。

Abstract: Fish-inspired aquatic robots are gaining increasing attention in research
communities due to their high swimming speeds and efficient propulsion enabled
by flexible bodies that generate undulatory motions. To support the design
optimizations and control of such systems, accurate, interpretable, and
computationally tractable modeling of the underlying swimming dynamics is
indispensable. In this letter, we present a full-body dynamics model for fish
swimming, rigorously derived from Hamilton's principle. The model captures the
continuously distributed elasticity of a deformable fish body undergoing large
deformations and incorporates fluid-structure coupling effects, enabling
self-propelled motion without prescribing kinematics. A preliminary parameter
study explores the influence of actuation frequency and body stiffness on
swimming speed and cost of transport (COT). Simulation results indicate that
swimming speed and energy efficiency exhibit opposing trends with tail-beat
frequency and that both body stiffness and body length have distinct optimal
values. These findings provide insights into biological swimming mechanisms and
inform the design of high-performance soft robotic swimmers.

</details>


### [231] [Agentic Aerial Cinematography: From Dialogue Cues to Cinematic Trajectories](https://arxiv.org/abs/2509.16176)
*Yifan Lin,Sophie Ziyu Liu,Ran Qi,George Z. Xue,Xinping Song,Chao Qin,Hugh H. -T. Liu*

Main category: cs.RO

TL;DR: 我们提出了ACDC，一个通过自然语言对话驱动的自主无人机电影制作系统，利用LLM和VFM将文本提示转换为电影级航拍轨迹，解决了手动操作耗时和效果不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的无人机电影制作工作流程需要手动选择航点和视角，这既耗时又影响一致性。

Method: 该方法结合了视觉-语言检索、基于偏好的贝叶斯优化和运动规划，将自然语言提示直接转换为无人机视频。

Result: 在模拟和硬件在环实验中，ACDC都能在各种室内场景中生成高质量的专业镜头，无需机器人或电影制作专业知识。

Conclusion: 研究结果表明，具身人工智能在连接开放式对话和现实世界自主航拍方面具有巨大潜力。

Abstract: We present Agentic Aerial Cinematography: From Dialogue Cues to Cinematic
Trajectories (ACDC), an autonomous drone cinematography system driven by
natural language communication between human directors and drones. The main
limitation of previous drone cinematography workflows is that they require
manual selection of waypoints and view angles based on predefined human intent,
which is labor-intensive and yields inconsistent performance. In this paper, we
propose employing large language models (LLMs) and vision foundation models
(VFMs) to convert free-form natural language prompts directly into executable
indoor UAV video tours. Specifically, our method comprises a vision-language
retrieval pipeline for initial waypoint selection, a preference-based Bayesian
optimization framework that refines poses using aesthetic feedback, and a
motion planner that generates safe quadrotor trajectories. We validate ACDC
through both simulation and hardware-in-the-loop experiments, demonstrating
that it robustly produces professional-quality footage across diverse indoor
scenes without requiring expertise in robotics or cinematography. These results
highlight the potential of embodied AI agents to close the loop from
open-vocabulary dialogue to real-world autonomous aerial cinematography.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [232] [Quantum oscillations in two-dimensional hole gases with competing cyclotron and Zeeman energy](https://arxiv.org/abs/2509.15268)
*Davide Costa,Lucas E. A. Stehouwer,Davide Degli Esposti,Giordano Scappucci*

Main category: cond-mat.mes-hall

TL;DR: 评估二维材料中的量子输运参数，尤其是在存在能量尺度竞争时，具有挑战性。通过在低掺杂的应变锗量子阱中自洽地评估有效质量、g因子和量子寿命，我们克服了这一挑战，并估计出133(3)×10^3 cm^2/Vs的量子迁移率，创下了IV族半导体二维材料的记录。此外，在低磁场和低密度下观测到的清晰的分数阶量子霍尔效应进一步证明了空穴气的优异品质。


<details>
  <summary>Details</summary>
Motivation: 在存在不同能量尺度竞争时，评估二维系统中影响量子振荡的临界能带结构和量子输运参数具有挑战性。

Method: 在低掺杂应变锗量子阱中自洽地评估有效质量、g因子和量子寿命。

Result: 估计出133(3)×10^3 cm^2/Vs的量子迁移率，创下了IV族半导体二维材料的记录。在低磁场和低密度下观测到清晰的分数阶量子霍尔效应。

Conclusion: 通过在低掺杂应变锗量子阱中自洽地评估关键量子输运参数，实现了创纪录的量子迁移率，并观察到高质量空穴气的证据。

Abstract: Evaluation of critical bandstructure and quantum transport parameters in
two-dimensional systems is challenging when competition emerges among different
energy scales shaping quantum oscillations in a magnetic field. Here we
overcome this challenge in low-disorder strained germanium quantum wells by
evaluating self-consistently effective mass, g-factor, and quantum lifetime. As
a result, we estimate a quantum mobility of 133(3)$\times$10$^3$ cm$^2$/Vs,
setting a benchmark for 2D holes in group IV semiconductors. The high quality
of the hole gas if further highlighted by observing clean fractional quantum
Hall states at low magnetic field and low density.

</details>


### [233] [Electrodynamics of carbon nanotubes with non-local surface conductivity](https://arxiv.org/abs/2509.15287)
*Tomer Berghaus,Touvia Miloh,Oded Gottlieb,Gregory Ya. Slepyan*

Main category: cond-mat.mes-hall

TL;DR: 本文提出了一个考虑非局域表面电导率（空间色散）的碳纳米管（CNT）电动力学新框架。基于 Kubo 技术和狄拉克方程，推导了 CNT 表面的有效边界条件，并获得了 CNT 特征模式的色散关系。结果表明，非局域性产生了新的特征模式，这些模式在局域电导率极限下会消失。此外，还利用 Wiener-Hopf 技术为半无限长 CNT 得到了表面电流的精确解，并在此基础上提出了考虑非局域效应的附加边界条件。通过数值模拟和近似解析解，分析了有限长度 CNT 的电磁散射模式，并利用所得结果计算了作用在有限长度 CNT 上的光学力。最后，讨论了该研究在纳米天线和电子器件设计方面的潜在应用及未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 提出一个考虑非局域表面电导率（空间色散）的碳纳米管（CNT）电动力学新框架。

Method: 基于 Kubo 技术和狄拉克方程，推导了 CNT 表面的有效边界条件，获得了 CNT 特征模式的色散关系。利用 Wiener-Hopf 技术为半无限长 CNT 得到了表面电流的精确解，并提出了考虑非局域效应的附加边界条件。通过数值模拟和近似解析解，分析了有限长度 CNT 的电磁散射模式。

Result: 非局域性产生了新的特征模式，这些模式在局域电导率极限下会消失。得到了有限长度 CNT 的电磁散射模式的近似解析解，并计算了作用在有限长度 CNT 上的光学力。

Conclusion: 该研究为理解和应用碳纳米管的电动力学特性提供了新方法，并在纳米天线和电子器件设计方面具有潜在应用价值。

Abstract: A new framework that can be utilized for the electrodynamics of carbon
nanotubes (CNTs) with non-local surface conductivity (spatial dispersion) is
presented. The model of non-local conductivity is developed on the basis of the
Kubo technique applied to the Dirac equation for pseudospins. As a result, the
effective boundary conditions for the electromagnetic (EM) field on a CNT
surface are formulated. The dispersion relation for the eigenmodes of an
infinitely long CNT is obtained and analyzed. It is shown that due to
nonlocality, a new type of eigenmodes are created that disappear in the local
conductivity limit. These eigenmodes should be properly accounted for in the
correct formulation of the CNT end conditions for the surface current, which
are manifested in the EM-field scattering problem. Additional boundary
conditions that consider nonlocality effects are also formulated based on the
exact solution obtained for the surface current by means of using the
Wiener-Hopf (WH) technique for a semi-infinite CNT. The scattering pattern of
the EM-field is simulated by a finite-length model of a CNT, using a
numerically solved integral equation for the surface current density and its
approximate analytical solution. Thus, the scattering field of a CNT prevailing
in the wide frequency range from THz to infrared light is analytically solved
and analyzed. The newly obtained results are then utilized for determining the
optical forces exerted on a CNT of finite length. Potential applications for
the design of nanoantennas and other electronic devices, including pointing out
some future directions, are also discussed.

</details>


### [234] [Absence of skewness in the voltage fluctuations of a tunnel junction in the quantum regime](https://arxiv.org/abs/2509.15352)
*Clovis Farley,Bertrand Reulet*

Main category: cond-mat.mes-hall

TL;DR: 隧道结中的电流涨落具有低电压偏压下的方差与真空涨落相对应的特性，以及与泊松过程相似的频率无关的偏度。本研究探讨了在低电压下，由此产生的真空涨落是否具有有限的偏度。


<details>
  <summary>Details</summary>
Motivation: 研究隧道结中的电流涨落是否在低电压下表现出具有有限偏度的真空涨落。

Method: 计算任意电磁环境在零温度下的影响，并分析量子导体在电压频率高于电压时的三次矩（双谱）。

Result: 证明了任何量子导体在电压频率高于电压时的三次矩（双谱）始终为零，并通过实验数据证实了隧道结在量子区域的测量结果与计算一致。

Conclusion: 低电压下，隧道结产生的真空涨落的偏度有限，即隧道结产生偏斜真空。

Abstract: Current fluctuations in a tunnel junction have a remarkable property: On the
one hand, their variance corresponds to vacuum fluctuations at low voltage bias
$V$, when the electron energy $eV$ is smaller than the photon detection energy
$hf$ . On the other hand, their skewness, i.e. their third moment, is frequency
independent, equal to $e^2I$ as if electron transport were simply Poissonian.
We address the following question: Could it be that at low voltage, the vacuum
fluctuations generated by the junction have a finite skewness, i.e. that the
junction generates skewed vacuum ? To answer this question we calculate the
effect of an arbitrary electromagnetic environment at zero temperature and show
that the bispectrum of third moment of voltage fluctuations of any quantum
conductor is always zero at frequencies larger than the voltage. We also show
experimental data on tunnel junctions in the quantum regime that agree with our
calculation.

</details>


### [235] [Förster transfer between quantum dots in a shared phonon environment: An exact approach, revealing the role of pure dephasing](https://arxiv.org/abs/2509.15418)
*Liubov S. Sirkina,Luke M. J. Hall,Amy Morreau,Wolfgang Langbein,Egor A. Muljarov*

Main category: cond-mat.mes-hall

TL;DR: 文章对两个量子点之间的能量转移进行了精确的微观理论研究，考虑了偶极-偶极相互作用和共同声子浴的影响，并超越了常用的微扰方法。


<details>
  <summary>Details</summary>
Motivation: 理解量子点之间能量转移的精确理论，这对自然和技术都至关重要。

Method: 采用精确的微观方法处理受激激子能级之间的声子辅助跃迁，并与基于费米黄金定则的分析模型进行比较。

Result: 提取了状态的弛豫时间 T1、退相干时间 T2 和纯退相干时间 T2*，并发现精确结果与分析模型在某些参数下存在显著差异，这主要归因于多声子过程的重要性。

Conclusion: 对于相当的电子-声子耦合和偶极耦合（在量子点之间距离较近和温度较高时实现），多声子过程会影响能量转移的动力学，导致精确结果与基于费米黄金定则的分析模型存在偏差。

Abstract: F\"orster resonance energy transfer has an important role in nature and
technology, rendering its exact theoretical understanding significant. To this
end, a system of two electronically decoupled quantum dots (QDs) is considered,
interacting via dipole-dipole interaction and a common phonon bath. While the
former leads to an oscillatory excitation transfer between the dots, the latter
provide the dissipation resulting in directional F\"orster transfer. We present
an exact microscopic treatment of the phonon-assisted transitions between
hybridized exciton levels of the coupled QD system, going beyond the simple
perturbative approaches commonly used in the literature. From our
asymptotically exact results we extract population decay times $T_1$, dephasing
times $T_2$, and resulting pure dephasing times $T_2^*$ of the states. We
compare this treatment with an analytical model based on Fermi's golden rule,
combining the most accurate elements of existing analytical treatments. The
exact results show a significant deviation from this model in some parameter
regimes, mainly due to the role of multi-phonon processes, which become
important for comparable electron-phonon and dipolar coupling, realised at
short distances between the QDs and at elevated temperatures.

</details>


### [236] [Symmetries and dynamics of quantum Hall bulk anyons in quadratic potentials](https://arxiv.org/abs/2509.15488)
*Preethi Basani,Varsha Subramanyan,Smitha Vishveshwara*

Main category: cond-mat.mes-hall

TL;DR: 文章研究了最低朗道能级(LLL)中二维任意子（Abelian anyons）的相干态及其动力学行为，特别是与su(1,1)李代数相关的广义相干态。


<details>
  <summary>Details</summary>
Motivation: 研究LLL中任意子相干态的动力学行为，并与量子光学进行类比。

Method: 利用与量子光学和相干态对称性的类比，解析计算了团聚参数（bunching parameter）和相干态轨迹。

Result: 在无界的鞍形势阱中，团聚参数决定了轨迹的指数发散行为；在有界的椭圆形势阱中，团聚参数呈振荡行为，其最大值与势阱的离心率有关。

Conclusion: 文章结果揭示了团聚参数在不同势阱中对任意子相干态动力学行为的影响，并将这些分析与任意子探测的实验概念联系起来。

Abstract: We study two-particle coherent states and their dynamics in the lowest Landau
level (LLL) under the influence of quadratic potentials. We focus on
generalized coherent states that describe Abelian anyons in the LLL and are
associated with the $\mathfrak{su}(1,1)$ Lie algebra. We draw on parallels with
quantum optics and symmetry properties of the coherent states considered here
to analytically calculate quantities such as a bunching parameter, which
depends on quantum statistics, as well as coherent state trajectories under the
influence of generic quadratic potentials. Our results show that in unbounded
saddle potentials, the bunching parameter governs the trajectories which show
exponentially diverging behavior in a manner that depends on quantum
statistics. In bounded elliptical potentials, the bunching parameter is
oscillatory and its maximum magnitude depends on the eccentricity of the
applied potential. We draw connections between our analyses and the key
concepts that underlie anyon detection in recent experiments.

</details>


### [237] [Magnetoelastic Coupling-Driven Chiral Spin Textures: A Skyrmion-Antiskyrmion-Like Array](https://arxiv.org/abs/2509.15511)
*Gyungchoon Go,Se Kwon Kim*

Main category: cond-mat.mes-hall

TL;DR: 马格内托弹性耦合可以导致铁磁系统中出现手征自旋结构，无需DMI。


<details>
  <summary>Details</summary>
Motivation: 探索在没有DMI的情况下，仅通过马格内托弹性耦合在铁磁系统中形成手征自旋纹理的机制。

Method: 理论上研究了强马格内托弹性耦合对二维铁磁系统自旋态的影响，分析了其与弯曲声子和基板的耦合。

Result: 发现周期性的手征自旋纹理（类似于斯格明子-反斯格明子晶格）可以在强马格内托弹性耦合和弱弯曲声子-基板耦合的条件下自发形成。

Conclusion: 马格内托弹性耦合是形成手征自旋纹理的一种以前未被发现的机制，这可能对具有强马格内托弹性响应的材料具有潜在应用价值。

Abstract: We theoretically demonstrate that sufficiently strong magnetoelastic coupling
can change the ground state of otherwise uniform spin systems to chiral spin
configurations. More specifically, we show that, a periodic array of chiral
spin textures can spontaneously emerge in a two-dimensional ferromagnetic
system on a substrate-even in the absence of Dzyaloshinskii-Moriya interaction.
The resulting spin texture resembles a skyrmion-antiskyrmion lattice,
characterized by alternating scalar spin chirality and a nonuniform but
sign-preserving out-of-plane spin profile. Our analysis reveals that such
patterns form naturally when the magnetoelastic interaction is sufficiently
strong, while the coupling between flexural phonons and the substrate is
sufficiently weak. These findings uncover a previously unexplored mechanism for
chiral spin texture formation driven purely by magnetoelastic coupling,
signaling at potential utilities of materials with strong magnetoelastic
responses.

</details>


### [238] [Evidence for Half-Quantized Chiral Edge Current in a C = 1/2 Parity Anomaly State](https://arxiv.org/abs/2509.15525)
*Deyi Zhuo,Bomin Zhang,Humian Zhou,Han Tay,Xiaoda Liu,Zhiyuan Xi,Chui-Zhen Chen,Cui-Zu Chang*

Main category: cond-mat.mes-hall

TL;DR: 在分子束外延生长的非对称磁性拓扑绝缘体三层结构中，观察到半整数量子霍尔电导平台，并将其与C=1/2奇偶异常态相关联，证明了该状态下存在半整数手征边缘电流。


<details>
  <summary>Details</summary>
Motivation: 研究半整数量子霍尔电导和C=1/2奇偶异常态在磁性拓扑绝缘体中的存在和特性。

Method: 通过分子束外延生长非对称磁性拓扑绝缘体三层结构，并在特定面内磁场下进行实验测量，结合数值模拟进行分析。

Result: 观察到半整数量子霍尔电导平台，并伴随显著的非局域和非互易输运信号，证明了半整数手征边缘电流的存在。

Conclusion: 证实了非对称磁性拓扑绝缘体三层结构是研究单狄拉克费米子物理的平台，并为探索C=1/2奇偶异常态下的拓扑磁电效应和量子化磁光响应等现象铺平了道路。

Abstract: A single massive Dirac surface band is predicted to exhibit a half-quantized
Hall conductance, a hallmark of the C = 1/2 parity anomaly state in quantum
field theory. Experimental signatures of the C = 1/2 parity anomaly state have
been observed in semi-magnetic topological insulator (TI) bilayers, yet whether
it supports a half-quantized chiral edge current remains elusive. Here, we
observe a robust half-quantized Hall conductance plateau in a molecular beam
epitaxy (MBE)-grown asymmetric magnetic TI trilayer under specific in-plane
magnetic field regimes, corresponding to the C = 1/2 parity anomaly state.
Within this state, both nonlocal and nonreciprocal transport signals are
greatly enhanced, which we identify as direct evidence for a half-quantized
chiral edge current localized at the boundary of the top gapped surface. Our
numerical simulations demonstrate that this half-quantized chiral edge channel
is the essential carrier of the observed half-quantized Hall conductance
plateau, analogous to the quantized chiral edge channel in the C = 1 quantum
anomalous Hall state. Our results provide experimental evidence for the
half-quantized chiral edge transport in a C = 1/2 parity anomaly state. This
work establishes asymmetric magnetic TI trilayers as a platform for probing
single Dirac fermion physics and paves the way to explore a series of exciting
phenomena in the C = 1/2 parity anomaly state, including the topological
magnetoelectric effect and quantized magneto-optical response.

</details>


### [239] [Dynamic polarization of nuclear spins by optically-oriented electrons and holes in lead halide perovskite semiconductors](https://arxiv.org/abs/2509.15530)
*Mladen Kotur,Pavel S. Bazhin,Kirill V. Kavokin,Nataliia E. Kopteva,Dmitri R. Yakovlev,Dennis Kudlacik,Manfred Bayer*

Main category: cond-mat.mes-hall

TL;DR: 该论文提出了一个关于通过光定向电荷载流子在卤化物钙钛矿中动态极化核自旋系统的理论，并将其与在FA$_{0.9}$Cs$_{0.1}$PbI$_{2.8}$Br$_{0.2}$晶体上进行的实验进行了比较。


<details>
  <summary>Details</summary>
Motivation: 开发一个理论模型来解释和预测卤化物钙钛矿中核自旋系统的动态极化现象，并与实验结果进行对比。

Method: 推导了电子和空穴与铅和卤素核自旋相互作用的自旋哈密顿量。研究了卤素自旋与电荷载流子的相互作用的各向异性，以及四极分裂对卤素自旋的影响。计算了动态极化的核的Overhauser场，并与实验测量的Hanle效应的角依赖性进行了比较。

Result: 理论模型与实验数据吻合良好，表明铅核的自旋极化增强，其平均自旋是局域电子和空穴平均自旋的数倍。卤素自旋的动态极化通过其在外场下对铅核产生的磁场表现出来，该磁场在零外磁场下维持了铅核的磁化。测量得到核自旋-晶格弛豫时间约为10秒。

Conclusion: 光定向电荷载流子是实现卤化物钙钛矿中核自旋系统动态极化的有效途径。铅核的强自旋极化可能源于其与具有高自旋取向的激子的相互作用。卤素自旋的四极分裂和动态极化在核自旋动力学中起着重要作用。

Abstract: A theory of dynamic polarization of the nuclear spin system via
optically-oriented charge carriers in lead halide perovskites is developed and
compared with the experiments performed on a
FA$_{0.9}$Cs$_{0.1}$PbI$_{2.8}$Br$_{0.2}$ crystal. The spin Hamiltonians of the
electron and hole hyperfine interaction with the nuclear spins of lead and
halogen are derived. The hyperfine interaction of the halogen spins with charge
carriers is shown to be anisotropic and depending on the position of the
halogen nucleus in the cubic elementary cell. The quadrupole splitting is
absent for the lead spins, but plays an important role for the halogen spins
and affects their dynamic polarization by charge carriers. The Overhauser
fields of the dynamically polarized nuclei are calculated as functions of the
tilting angle of an external magnetic field and compared with the
experimentally measured angular dependence of the Hanle effect. The comparison
of the theoretical model with the experimental data reveals an enhanced spin
polarization of the lead nuclei, whose mean spin exceeds several times the mean
spins of localized electrons and holes. This unexpectedly strong spin
polarization is explained by the interaction of the lead nuclei with excitons
having a high degree of spin orientation due to their short lifetime after
excitation by circularly-polarized light. The dynamic polarization of the
quadrupole-split halogen spins manifests itself via the magnetic field they
produce at the lead nuclei. This field maintains the magnetization of the lead
nuclei at zero external magnetic field. The dynamics of the nuclear spin
polarization is measured under optical pumping and in the dark, yielding a
nuclear spin-lattice relaxation time on the order of 10 seconds.

</details>


### [240] [Terahertz radiation induced attractive-repulsive Fermi polaron conversion in transition metal dichalcogenide monolayers](https://arxiv.org/abs/2509.15708)
*A. M. Shentsev,M. M. Glazov*

Main category: cond-mat.mes-hall

TL;DR: 理论研究了二维材料中的太赫兹辐射诱导的费米极化激子态跃迁，并考虑了与费米海的相互作用。


<details>
  <summary>Details</summary>
Motivation: 研究了过渡金属硫属化合物单分子层中由太赫兹辐射引起的吸引和排斥费米极化激子态之间的跃迁。

Method: 提出了一种多体描述，明确考虑了与居民电荷载流子费米海的相关性，并计算了直接光学转换速率以及间接转换机制。

Result: 计算出的直接光学转换速率在阈值附近具有特征频率依赖性，这与电子-激子散射有关；强太赫兹脉冲可以通过德鲁德吸收加热电子气，从而实现间接转换，该转换表现出对温度的强指数依赖性。

Conclusion: 研究结果揭示了多体相关和热效应对二维半导体中激子复合物的太赫兹驱动动力学的重要性。

Abstract: We present a theoretical study of terahertz radiation-induced transitions
between attractive and repulsive Fermi polaron states in monolayers of
transition metal dichalcogenides. Going beyond the simple few-particle trion
picture, we develop a many-body description that explicitly accounts for
correlations with the Fermi sea of resident charge carriers. We calculate the
rate of the direct optical conversion process, showing that it features a
characteristic frequency dependence near the threshold due to final-state
electron-exciton scattering related to the trion correlation with the Fermi sea
hole. Furthermore, we demonstrate that intense terahertz pulses can
significantly heat the electron gas via Drude absorption enabling an
additional, indirect conversion mechanism through collisions between hot
electrons and polarons, which exhibits a strong exponential dependence on
temperature. Our results reveal the important role of many-body correlations
and thermal effects in the terahertz-driven dynamics of excitonic complexes in
two-dimensional semiconductors.

</details>


### [241] [A heat-resilient hole spin qubit in silicon](https://arxiv.org/abs/2509.15823)
*V. Champain,G. Boschetto,H. Niebojewski,B. Bertrand,L. Mauro,M. Bassi,V. Schmitt,X. Jehl,S. Zihlmann,R. Maurand,Y. -M. Niquet,C. B. Winkelmann,S. De Franceschi,B. Martinez,B. Brun*

Main category: cond-mat.mes-hall

TL;DR: 微波脉冲过热量子比特环境导致拉莫尔频率偏移，提出利用磁场调控以消除热效应。


<details>
  <summary>Details</summary>
Motivation: 近期量子处理器在扩展过程中遇到热效应问题，微波脉冲过热导致拉莫尔频率偏移，降低了门保真度。

Method: 通过实验表征单硅空穴自旋的拉莫尔频率对温度的依赖性，并进行精确的自旋静电环境和旋磁特性建模。

Result: 发现了由自旋-轨道耦合引起的电磁敏感性是热效应的根本原因，电偶极子在升温时导致频率偏移；提出通过调控磁场角度可以消除热效应，找到一个对热效应不敏感的“甜点”。

Conclusion: 该研究揭示了量子处理器中拉莫尔频率偏移的热效应的起源，并提出了一种优化方案，通过调控磁场角度来消除这种效应，提高了量子处理器保真度。

Abstract: Recent advances in scaling up spin-based quantum processors have revealed
unanticipated issues related to thermal effects. Microwave pulses required to
manipulate and read the qubits are found to overheat the spins environment,
which unexpectedly induces Larmor frequency shifts, reducing thereby gate
fidelities. In this study, we shine light on these elusive thermal effects, by
experimentally characterizing the temperature dependence of the Larmor
frequency for a single hole spin in silicon. Our results unambiguously reveal
an electrical origin underlying the thermal susceptibility, stemming from the
spin-orbit-induced electric susceptibility. We perform an accurate modeling of
the spin electrostatic environment and gyromagnetic properties, allowing us to
pinpoint electric dipoles as responsible for these frequency shifts, that
unfreeze as the temperature increases. Surprisingly, we find that the thermal
susceptibility can be tuned with the magnetic field angle and can even cancel
out, unveiling a sweet spot where the hole spin is rendered immune to thermal
effects. These findings bear important implications for optimizing spin-based
quantum processors fidelity.

</details>


### [242] [Nonreciprocal plasmons in one-dimensional carbon nanostructures](https://arxiv.org/abs/2509.16109)
*Álvaro Rodríguez Echarri,F. Javier García de Abajo,Joel D. Cox*

Main category: cond-mat.mes-hall

TL;DR: 石墨烯纳米结构可用于非互易纳米光子学。


<details>
  <summary>Details</summary>
Motivation: 传统的等离激元材料具有固有的光学响应互易性，这阻碍了微型等离激元波导中光的定向控制，而这种控制对于新兴的纳米光子技术具有吸引力。石墨烯能够承受大电流，为非互易等离激子学提供了希望，但以往的研究仅限于具有线性电色散的宏观样品。

Method: 理论探索了由漂移偏置石墨烯纳米带（GNRs）和碳纳米管（CNTs）组成的介观等离激元波导的非互易响应中的量子有限尺寸和非局部效应。利用基于紧束缚电子态和自洽平均场光学响应的原子模拟方法。

Result: 研究表明，适度的电流偏置可以显著打破 GNRs 和 CNTs 中传播的引导等离激元模式的互易性，这些 GNRs 和 CNTs 表现出电子带隙。通过附近点偶极子发射器的激发和随后引导的等离激元模式的传播，可以通过施加的电流主动控制，这还可以用于调节多个发射器的非局部相互作用。

Conclusion: 研究结果表明，石墨烯纳米结构是实现非互易纳米光子学的有前景的原子级薄平台。

Abstract: The directional control of light in miniaturized plasmonic waveguides holds
appealing possibilities for emerging nanophotonic technologies, but is hindered
by the intrinsic reciprocal optical response of conventional plasmonic
materials. While the ability of graphene to sustain large electrical currents
shows promise for nonreciprocal plasmonics, studies have been limited to
extended samples characterized by linear electrical dispersion. Here, we
theoretically explore quantum finite-size and nonlocal effects in the
nonreciprocal response of mesoscale plasmonic waveguides comprised of
drift-biased graphene nanoribbons (GNRs) and carbon nanotubes (CNTs). Using
atomistic simulation methods based on tight-binding electronic states and
self-consistent mean-field optical response, we reveal that a moderate
electrical bias can significantly break reciprocity for propagation of guided
plasmon modes in GNRs and CNTs exhibiting electronic band gaps. The excitation
by a nearby point dipole emitter and subsequent propagation of guided plasmon
modes can thus be actively controlled by the applied current, which can further
be leveraged to mediate nonlocal interactions of multiple emitters. Our results
establish graphene nanostructures as a promising atomically thin platform for
nonreciprocal nanophotonics.

</details>


### [243] [Classical and Quantum theory of magnonic and magnetoelastic nonlinear dynamics in continuum geometries](https://arxiv.org/abs/2509.16199)
*Marco Brühlmann,Yunyoung Hwang,Jorge Puebla,Carlos Gonzalez-Ballestero*

Main category: cond-mat.mes-hall

TL;DR: 本文提出了一个耦合了自旋和声波的非线性动力学理论，并推导了磁化和声波振幅的经典运动方程，考虑了三磁振子和四磁振子过程，以及线性和非线性磁弹性相互作用。该模型成功复现了声驱动下的声子到磁声子的下转换实验现象，并推导了所有速率的解析表达式，适用于量子化。最后，对模型进行了量子化，推导了磁声子和声子算符的Heisenberg-Langevin运动方程，并展示了如何在平均场近似下计算量子期望值。


<details>
  <summary>Details</summary>
Motivation: 本文旨在提供一个理论模型来解释和预测磁性材料中自旋波和声波之间的非线性耦合动力学，特别是在量子 regime 下声学控制磁子的可能性。

Method: 通过结合Landau-Lifshitz-Gilbert方程和磁弹性哈密顿量，推导出包含三磁振子和四磁振子过程以及线性和非线性磁弹性相互作用的磁化和声波振幅的经典运动方程。随后，对该模型进行量子化，得到磁声子和声子算符的Heisenberg-Langevin运动方程，并采用平均场近似计算量子期望值。

Result: 模型成功复现了实验观察到的声驱动下的声子到磁声子的下转换现象，并推导了方程中所有速率的解析表达式。量子化后的模型展示了在平均场近似下计算量子期望值的方法。

Conclusion: 该研究为在量子 regime 下利用声学手段控制磁子提供了理论基础和可行性。

Abstract: We provide a theory of spin and acoustic wave coupled nonlinear dynamics in
continuum systems. Combining the Landau-Lifshitz-Gilbert equations with the
magnetoelastic Hamiltonian, we derive classical equations of motion for the
magnetization and acoustic wave amplitudes, that include magnonic nonlinearity
-- both three- and four-magnon processes -- as well as linear and nonlinear
magnetoelastic interactions. We focus on two-dimensional magnetic films
sustaining surface acoustic waves, a geometry where our model successfully
reproduces our recent experimental observation of phonon-to-magnon
down-conversion under acoustic drive. We provide analytical expressions for all
the rates in our equations, which make them particularly suitable for
quantization. We then quantize our model, deriving Heisenberg-Langevin
equations of motion for magnon and phonon operators, and show how to compute
quantum expectation values in the mean field approximation. Our work paves the
way toward acoustic control of magnons in the quantum regime.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [244] [Thin-film boundary-layer diffusion of non-equilibrium flow to kinetically limited reactive surfaces via Damköhler thermochemistry tables](https://arxiv.org/abs/2509.15427)
*Jeffrey D. Engerer,Lincoln N. Collins*

Main category: physics.app-ph

TL;DR: 该研究提出了一种新的边界层积分求解方法，用于处理大气层进入时的表面非平衡化学反应，并将其结果预先制成表格，以提高计算的灵活性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统的大气层进入热化学计算方法依赖于假设表面化学平衡，并且在处理有限速率表面反应时存在局限性。本研究旨在提供一种更灵活、更通用的方法。

Method: 提出了一种边界层积分求解方法，将无气体氧的墙面模型与有限速率表面反应动力学相结合，并进行了预制表处理，无需直接集成到平衡热化学求解器中。

Result: 该方法在简单的空气-碳体系中，能够更灵活地处理假设的动力学速率和墙面气体条件，并展示了初步结果。

Conclusion: 该方法为大气层进入的表面非平衡化学反应提供了一种新的、更灵活的解决方案，但其在复杂材料和先进模拟中的扩展性仍需进一步研究和验证。

Abstract: Traditional ablation thermochemistry tables for atmospheric entry are derived
from boundary-layer element diffusion assuming homogeneous and heterogeneous
thermochemical equilibrium at the vehicle surface. Prior techniques for
finite-rate surface reactions predominantly embed specific heterogeneous
reaction models within the homogeneous equilibrium solution procedures and
tables. This paper disseminates a boundary-layer integral solution for wall-gas
free oxygen coupled to finite-rate surface kinetics. Solutions are
pre-tabulated along normalized kinetics variables without direct integration
into an equilibrium thermochemistry solver. This technique allows greater
flexibility in presumed kinetics rates and wall-gas conditions in simple
air-carbon systems, but the extensibility to state-of-the-art simulations and
complex materials remains uncertain. A derivation and preliminary results are
presented to the encourage further development.

</details>


### [245] [Whisker-Like Sensors: Effective Design, Pauline Pounds, Manivannan M](https://arxiv.org/abs/2509.15925)
*Prasanna Kumar Routray,Debadutta Subudhi*

Main category: physics.app-ph

TL;DR: 受启于生物触须的传感器在流体流动传感、纹理分析和环境探索等领域有广泛应用。然而，现有设计在耐用性、制造复杂性和响应一致性方面存在挑战。为了解决这些问题，我们提出了一个模块化架构，将触须传感器分解为五个功能组件：触须元件（WE）、柔顺元件（CE）、传感元件（SE）、支撑结构（SS）和数据采集模块（DAQ）。我们基于此架构开发并比较了四种内部传感器设计，它们在材料选择、传感模式和机械结构上有所不同。为了统一异构传感器输出，我们引入了一种校准策略，将原始传感器读数（无论是来自压力、磁通量还是视觉特征）映射到一个共同的表示：触须基部的弯矩。这种表示支持跨传感技术的解释和比较。我们采用纹理粗糙度分析作为代表性传感任务来评估设计权衡。使用高分辨率激光传感器和标准化粗糙度样本，对每个触须传感器的频域响应进行了基准测试。实证结果表明，刚性触须提高了纹理分类的准确性，而柔性触须为探索性机器人任务提供了鲁棒性。在评估的设计中，带有橡胶CE的霍尔效应传感器在耐用性、可重构性和制造简洁性方面表现出最有利的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有触须传感器设计在耐用性、制造复杂性和响应一致性方面存在挑战，需要改进。

Method: 提出模块化架构（WE, CE, SE, SS, DAQ），开发四种不同设计，引入将传感器读数统一为触须基部弯矩的校准策略，并使用纹理粗糙度分析任务进行评估。

Result: 刚性触须提高了纹理分类准确性，柔性触须提高了机器人任务的鲁棒性。带有橡胶CE的霍尔效应传感器在耐用性、可重构性和制造简洁性方面具有最佳平衡。

Conclusion: 提出的模块化架构和校准策略能够有效评估和改进生物启发式触须传感器的设计，其中霍尔效应传感器结合橡胶CE的设计具有综合优势。

Abstract: Bio-inspired whisker sensors are employed in diverse applications such as
fluid-flow sensing, texture analysis, and environmental exploration. However,
existing designs often face challenges related to durability, fabrication
complexity, and response consistency. To address these issues, we propose a
modular architecture that decomposes whisker sensors into five functional
components: the whisker element (WE), compliant element (CE), sensing element
(SE), support structure (SS), and data acquisition module (DAQ). We develop and
compare four in-house sensor designs built using this architecture, each
differing in material choice, sensing modality, and mechanical structure. To
unify heterogeneous sensor outputs, we introduce a calibration strategy that
maps raw sensor readings-whether from pressure, magnetic flux, or visual
features-into a common representation: the bending moment at the whisker base.
This representation supports consistent interpretation and comparison across
sensing techniques. We adopt texture roughness analysis as a representative
sensing task to evaluate design trade-offs. Each whisker sensor's
frequency-domain response is benchmarked against a high-resolution laser sensor
using standardized roughness specimens. Empirical results show that rigid
whiskers improve accuracy in texture classification, while flexible whiskers
provide robustness for exploratory robotics tasks. Among the evaluated designs,
the Hall-effect sensor with a rubber CE demonstrates the most favorable balance
of durability, reconfigurability, and fabrication simplicity.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [246] [Generating Plans for Belief-Desire-Intention (BDI) Agents Using Alternating-Time Temporal Logic (ATL)](https://arxiv.org/abs/2509.15238)
*Dylan Léveillé*

Main category: cs.MA

TL;DR: 使用ATL自动生成BDI计划，以处理多智能体协作和竞争。


<details>
  <summary>Details</summary>
Motivation: 现有的BDI代理计划生成方法需要大量手动工作，并且主要集中在单智能体系统。

Method: 开发了一个使用ATL自动生成BDI计划的工具，该工具能考虑代理间的竞争或协作。

Result: 生成的计划能够成功实现协作目标。

Conclusion: 所提出的方法生成的计划能使智能体成功达成目标。

Abstract: Belief-Desire-Intention (BDI) is a framework for modelling agents based on
their beliefs, desires, and intentions. Plans are a central component of BDI
agents, and define sequences of actions that an agent must undertake to achieve
a certain goal. Existing approaches to plan generation often require
significant manual effort, and are mainly focused on single-agent systems. As a
result, in this work, we have developed a tool that automatically generates BDI
plans using Alternating-Time Temporal Logic (ATL). By using ATL, the plans
generated accommodate for possible competition or cooperation between the
agents in the system. We demonstrate the effectiveness of the tool by
generating plans for an illustrative game that requires agent collaboration to
achieve a shared goal. We show that the generated plans allow the agents to
successfully attain this goal.

</details>


### [247] [Dynamic Agent Grouping ECBS: Scaling Windowed Multi-Agent Path Finding with Completeness Guarantees](https://arxiv.org/abs/2509.15381)
*Tiannan Zhang,Rishi Veerapaneni,Shao-Hung Chan,Jiaoyang Li,Maxim Likhachev*

Main category: cs.MA

TL;DR: DAG-ECBS 扩展了 WinC-MAPF 框架，允许使用有界次优求解器，同时保持完整性，提高了可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有 WinC-MAPF 框架需要最优 MAPF 求解器，而本文旨在通过使用有界次优求解器来扩展该框架，同时保持完整性。

Method: 提出了一种名为 DAG-ECBS 的新方法，该方法动态地创建和规划代理组，并确保每个代理组的解是有界次优的。证明了 DAG-ECBS 在 WinC-MAPF 框架中可以保持完整性。

Result: DAG-ECBS 与 SS-CBS 相比显示出改进的可扩展性，并且可以优于没有完整性保证的窗口化 ECBS。

Conclusion: 该工作为设计更多可以使用 WinC-MAPF 框架的 MAPF 方法提供了一个蓝图。

Abstract: Multi-Agent Path Finding (MAPF) is the problem of finding a set of
collision-free paths for a team of agents. Although several MAPF methods which
solve full-horizon MAPF have completeness guarantees, very few MAPF methods
that plan partial paths have completeness guarantees. Recent work introduced
the Windowed Complete MAPF (WinC-MAPF) framework, which shows how windowed
optimal MAPF solvers (e.g., SS-CBS) can use heuristic updates and disjoint
agent groups to maintain completeness even when planning partial paths
(Veerapaneni et al. 2024). A core limitation of WinC-MAPF is that they required
optimal MAPF solvers. Our main contribution is to extend WinC-MAPF by showing
how we can use a bounded suboptimal solver while maintaining completeness. In
particular, we design Dynamic Agent Grouping ECBS (DAG-ECBS) which dynamically
creates and plans agent groups while maintaining that each agent group solution
is bounded suboptimal. We prove how DAG-ECBS can maintain completeness in the
WinC-MAPF framework. DAG-ECBS shows improved scalability compared to SS-CBS and
can outperform windowed ECBS without completeness guarantees. More broadly, our
work serves as a blueprint for designing more MAPF methods that can use the
WinC-MAPF framework.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [248] [Modeling Adaptive Tracking of Predictable Stimuli in Electric Fish](https://arxiv.org/abs/2509.15344)
*Yu Yang,Andreas Oliveira,Louis L. Whitcomb,Felipe Pait,Mario Sznaier,Noah J. Cowan*

Main category: eess.SY

TL;DR: 该研究提出了一个基于自适应内部模型原理（IMP）的系统来模拟弱电鱼Eigenmannia virescens在移动庇护所中的追踪行为，该系统能够识别庇护所的频率并进行几乎完美的追踪，即使在高频下也能很好地复现鱼类的行为。


<details>
  <summary>Details</summary>
Motivation: 模拟弱电鱼Eigenmannia virescens在低频正弦振荡的移动庇护所中的追踪行为，并解释其在高频下相位滞后增加和增益降低的非线性行为。

Method: 提出一个自适应内部模型原理（IMP）系统，该系统包含一个自适应状态估计器来识别未知的庇护所频率，并将该频率估计值输入到一个基于谐振子模型的闭环IMP系统中。

Result: 证明了所提出的IMP系统在自适应频率估计下，其追踪误差可以指数级收敛到具有理想信息的理想控制系统的追踪误差。模拟结果表明，该模型能够很好地复现鱼类在宽频率范围内的追踪Bode图。

Conclusion: 结合IMP和自适应识别过程在理论上是可行的，并为自适应感觉运动控制提供了一个基本框架。

Abstract: The weakly electric fish \emph{Eigenmannia virescens} naturally swims back
and forth to stay within a moving refuge, tracking its motion using visual and
electrosensory feedback. Previous experiments show that when the refuge
oscillates as a low-frequency sinusoid (below about 0.5 Hz), the tracking is
nearly perfect, but phase lag increases and gain decreases at higher
frequencies. Here, we model this nonlinear behavior as an adaptive internal
model principle (IMP) system. Specifically, an adaptive state estimator
identifies the \emph{a priori} unknown frequency, and feeds this parameter
estimate into a closed-loop IMP-based system built around a lightly damped
harmonic oscillator. We prove that the closed-loop tracking error of the
IMP-based system, where the online adaptive frequency estimate is used as a
surrogate for the unknown frequency, converges exponentially to that of an
ideal control system with perfect information about the stimulus. Simulations
further show that our model reproduces the fish refuge tracking Bode plot
across a wide frequency range. These results establish the theoretical validity
of combining the IMP with an adaptive identification process and provide a
basic framework in adaptive sensorimotor control.

</details>


### [249] [Risk-Aware Congestion Management with Capacity Limitation Contracts and Redispatch](https://arxiv.org/abs/2509.15354)
*Bart van der Holst,Phuong Nguyen,Johan Morren,Koen Kok*

Main category: eess.SY

TL;DR: 本文提出将容量限制合同（CLCs）和再调度合同（RCs）两种拥堵管理工具作为一种考虑风险的资源分配问题进行协调。通过开发一个机会约束的两阶段随机混合整数规划模型，并使用荷兰再调度市场（GOPACS）的实际订单簿数据，研究了由聚合商管理的车队电动汽车（EVs）的灵活性，并模拟了EV充电和再调度市场条件的双重不确定性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究容量限制合同（CLCs）和再调度合同（RCs）这两种拥堵管理工具的协调，将此问题视为一个考虑风险的资源分配问题，以平衡两种工具的优势和劣势。

Method: 提出一种机会约束的两阶段随机混合整数规划模型，该模型用于系统运营商从管理电动汽车（EVs）车队的聚合商处采购灵活性，并考虑了EV充电和再调度市场条件的双重不确定性，使用了荷兰再调度市场（GOPACS）的实际订单簿数据。

Result: 研究结果表明，结合使用CLCs和RCs通常是降低与单一工具相关的风险最经济有效的方法，但最佳组合取决于车队规模和RC激活时间。EV加载的大量不确定性增加了RC在日内激活的可能性，以纠正早期CLCs阶段的预测错误。对于大型车队（例如25,000辆），由于不成熟的再调度市场中的市场流动性风险，最优策略会限制再调度。这种风险随着再调度激活时间的推迟而增加，因为再调度产品的交易窗口缩小了。

Conclusion: 研究结果强调了各种不确定性来源如何影响拥堵管理工具之间的最佳权衡。

Abstract: This paper presents the coordination of two congestion management instruments
- capacity limitation contracts (CLCs) and redispatch contracts (RCs) - as a
risk-aware resource allocation problem. We propose that the advantages and
drawbacks of these instruments can be represented as operational risk profiles
and can be balanced through coordination. To this end, we develop a
chance-constrained two-stage stochastic mixed-integer program for a system
operator procuring flexibility from an aggregator managing a fleet of electric
vehicles (EVs). The model captures uncertainty in EV charging and redispatch
market conditions, using real order book data from the Dutch redispatch market
(GOPACS).
  Results indicate that combining CLCs and RCs is generally the most
cost-effective approach to mitigate risks associated with each instrument, but
the optimal mix depends on fleet size and RC activation timing. Large
uncertainty about EV loading increases RC activation intraday to correct for
forecasting errors at the earlier CLC stage. For large fleet sizes (e.g.
25.000) the optimal policy limits redispatch due to market liquidity risks in
the immature redispatch market. This risk increases for later redispatch
activation due to shrinking trading windows for redispatch products. These
findings highlight how various sources of uncertainty can impact the optimal
trade-off between congestion management instruments.

</details>


### [250] [Inverse Source Method for Constrained Phased Array Synthesis through Null-Space Exploitation](https://arxiv.org/abs/2509.15710)
*Lorenzo Poli,Paolo Rocca,Arianna Benoni,Andrea Massa*

Main category: eess.SY

TL;DR: 提出一种基于逆源法和辐射算子零空间的新型相控阵天线综合方法，可满足用户定义的功率方向图掩码及其他几何电气约束。


<details>
  <summary>Details</summary>
Motivation: 在相控阵天线设计中，需要同时满足用户定义的功率方向图掩码以及对阵面几何和/或单元激励的其他约束。

Method: 将相控阵单元激励表示为最小范数（辐射）项和非辐射项的线性组合。其中，辐射项通过辐射算子截断奇异值分解计算，用于生成满足方向图掩码的远场功率方向图；非辐射项属于辐射算子零空间，通过全局优化策略用于满足额外的几何或电气约束。

Result: 通过数值算例展示了该方法在各种阵列布局和设计目标下的有效性。

Conclusion: 所提出的相控阵天线综合方法能够有效拟合用户定义的功率方向图掩码，并满足额外的几何和/或电气约束。

Abstract: A versatile approach for the synthesis of phased array (PA) antennas able to
fit user-defined power pattern masks, while fulfilling additional geometrical
and/or electrical constraints on the geometry of the array aperture and/or on
the array excitations is presented. Such a synthesis method is based on the
inverse source (IS) formulation and exploits the null-space of the radiation
operator that causes the non-uniqueness of the IS problem at hand. More in
detail, the unknown element excitations of the PA are expressed as the linear
combination of a minimum-norm or radiating (RA) term and a suitable
non-radiating (NR) component. The former, computed via the truncated singular
value decomposition (SVD) of the array radiation operator, is devoted to
generate a far-field power pattern that fulfills user-defined pattern masks.
The other one belongs to the null-space of the radiation operator and allows
one to fit additional geometrical and/or electrical constraints on the geometry
of the array aperture and/or on the beam-forming network (BFN) when determined
with a customized global optimization strategy. A set of numerical examples,
concerned with various array arrangements and additional design targets, is
reported to prove the effectiveness of the proposed approach.

</details>


### [251] [All-Electric Heavy-Duty Robotic Manipulator: Actuator Configuration Optimization and Sensorless Control](https://arxiv.org/abs/2509.15778)
*Mohammad Bahari,Amir Hossein Barjini,Pauli Mustalahti,Jouni Mattila*

Main category: eess.SY

TL;DR: 本论文提出了一个统一的框架，用于全电动重型机器人操作器（HDRM）的建模、优化和无传感器控制，该操作器由机电线性执行器（EMLA）驱动。


<details>
  <summary>Details</summary>
Motivation: HDRM的建模、优化和无传感器控制，以实现精确的运动和高效的驱动。

Method: 1. 建立EMLA模型，捕捉电机机电和方向相关的传动效率。 2. 建立HDRM的数学模型，包括运动学和动力学。 3. 采用安全轨迹生成器将笛卡尔目标映射到关节空间。 4. 使用NSGA-II优化EMLA配置。 5. 嵌入深度神经网络以加速优化过程。 6. 使用物理信息Kriging代理模型支持无传感器控制。 7. 将执行器模型嵌入分层虚拟分解控制（VDC）框架。

Result: 实验验证表明，在不同负载下，HDRM能够精确跟踪轨迹并实现有效的无传感器控制。

Conclusion: 所提出的统一框架能够有效地对HDRM进行建模、优化和无传感器控制。

Abstract: This paper presents a unified framework that integrates modeling,
optimization, and sensorless control of an all-electric heavy-duty robotic
manipulator (HDRM) driven by electromechanical linear actuators (EMLAs). An
EMLA model is formulated to capture motor electromechanics and
direction-dependent transmission efficiencies, while a mathematical model of
the HDRM, incorporating both kinematics and dynamics, is established to
generate joint-space motion profiles for prescribed TCP trajectories. A
safety-ensured trajectory generator, tailored to this model, maps Cartesian
goals to joint space while enforcing joint-limit and velocity margins. Based on
the resulting force and velocity demands, a multi-objective Non-dominated
Sorting Genetic Algorithm II (NSGA-II) is employed to select the optimal EMLA
configuration. To accelerate this optimization, a deep neural network, trained
with EMLA parameters, is embedded in the optimization process to predict
steady-state actuator efficiency from trajectory profiles. For the chosen EMLA
design, a physics-informed Kriging surrogate, anchored to the analytic model
and refined with experimental data, learns residuals of EMLA outputs to support
force and velocity sensorless control. The actuator model is further embedded
in a hierarchical virtual decomposition control (VDC) framework that outputs
voltage commands. Experimental validation on a one-degree-of-freedom EMLA
testbed confirms accurate trajectory tracking and effective sensorless control
under varying loads.

</details>


### [252] [Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent Control](https://arxiv.org/abs/2509.15799)
*Max Studt,Georg Schildbach*

Main category: eess.SY

TL;DR: 该框架结合了强化学习（RL）和模型预测控制（MPC），用于多智能体系统的安全协调控制，在模拟中表现优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 在动态、受约束的环境中实现基于学习的控制的安全性和协调性仍然是一个挑战，现有的端到端学习方法效率低且不可靠，而基于模型的方法泛化能力有限。

Method: 提出一种分层框架，使用强化学习进行战术决策，并使用模型预测控制进行低层执行。高层策略从结构化兴趣区域（ROIs）中选择抽象目标，MPC 确保动态可行和安全的运动。

Result: 在捕食者-猎物基准测试中，该方法在奖励、安全性和一致性方面优于端到端和基于屏蔽的强化学习基线。

Conclusion: 结合结构化学习和基于模型的方法可以实现多智能体系统的安全协调控制。

Abstract: Achieving safe and coordinated behavior in dynamic, constraint-rich
environments remains a major challenge for learning-based control. Pure
end-to-end learning often suffers from poor sample efficiency and limited
reliability, while model-based methods depend on predefined references and
struggle to generalize. We propose a hierarchical framework that combines
tactical decision-making via reinforcement learning (RL) with low-level
execution through Model Predictive Control (MPC). For the case of multi-agent
systems this means that high-level policies select abstract targets from
structured regions of interest (ROIs), while MPC ensures dynamically feasible
and safe motion. Tested on a predator-prey benchmark, our approach outperforms
end-to-end and shielding-based RL baselines in terms of reward, safety, and
consistency, underscoring the benefits of combining structured learning with
model-based control.

</details>


### [253] [Bandwidth-Constrained Sensor Scheduling: A Trade-off between Fairness and Efficiency](https://arxiv.org/abs/2509.15820)
*Yuxing Zhong,Yuchi Wu,Daniel E. Quevedo,Ling Shi*

Main category: eess.SY

TL;DR: 该论文提出了一种新的q-公平框架来解决带宽受限信道下的传感器调度公平性问题，并在两种通信场景下推导了最优调度策略并提出了近似算法。


<details>
  <summary>Details</summary>
Motivation: 现有的公平调度方法忽略了整体系统效率，而本研究旨在通过引入q-公平性框架来平衡效率和公平性。

Method: 在两种通信场景下，推导了有限通信速率下的最优调度，并提出了有限的同步传感器传输下的两个次优算法，并分析了它们与最优策略的性能差距。

Result: 模拟结果表明，所提出的算法在有限通信速率和有限同步传感器传输的两种情况下，都能有效地平衡效率和公平性。

Conclusion: 提出的q-公平框架能够有效平衡带宽受限信道下的传感器调度效率和公平性。

Abstract: We address fair sensor scheduling over bandwidth-constrained communication
channels. While existing literature on fair scheduling overlooks overall system
efficiency, we introduce a novel $q$-fairness framework to balance efficiency
and fairness by adjusting the parameter $q$. Specifically, for two
communication scenarios, we: (i) derive the optimal schedule under limited
communication rates, and (ii) propose two suboptimal algorithms under limited
simultaneous sensor transmissions and analyze their performance gaps relative
to the optimal strategy. Simulations demonstrate that our algorithms
effectively balance efficiency and fairness in both cases.

</details>


### [254] [Data-Driven Uncertainty Modeling for Robust Feedback Active Noise Control in Headphones](https://arxiv.org/abs/2509.15864)
*Florian Hilgemann,Egke Chatzimoustafa,Peter Jax*

Main category: eess.SY

TL;DR: 本研究提出更精确的不确定性模型以提升主动降噪（ANC）耳机性能，通过优化控制器和原型机测试，结果表明新模型能安全地提升数分贝的主动降噪效果。


<details>
  <summary>Details</summary>
Motivation: 现有反馈控制ANC方法受限于系统不确定性，尤其是在不同佩戴情况下，传统非结构化模型倾向于高估不确定性，从而限制了ANC性能。因此，需要更精确的不确定性模型来改善ANC性能。

Method: 本研究探索能更精确拟合观测到的不确定性变化的不确定性模型，并基于这些模型描述控制器优化，最后通过ANC原型机对比传统和提出模型的性能。

Result: 通过广泛的人类佩戴者测量，证实了所提出模型的鲁棒性，并表明其性能优于传统方法，能够安全地将ANC耳机的降噪效果提升数分贝。

Conclusion: 本研究提出的更精确的不确定性模型能够有效提升ANC耳机的性能，并且在实际应用中表现出鲁棒性，可以安全地增加主动降噪量。

Abstract: Active noise control (ANC) has become popular for reducing noise and thus
enhancing user comfort in headphones. While feedback control offers an
effective way to implement ANC, it is restricted by uncertainty of the
controlled system that arises, e.g., from differing wearing situations. Widely
used unstructured models which capture these variations tend to overestimate
the uncertainty and thus restrict ANC performance. As a remedy, this work
explores uncertainty models that provide a more accurate fit to the observed
variations in order to improve ANC performance for over-ear and in-ear
headphones. We describe the controller optimization based on these models and
implement an ANC prototype to compare the performances associated with
conventional and proposed modeling approaches. Extensive measurements with
human wearers confirm the robustness and indicate a performance improvement
over conventional methods. The results allow to safely increase the active
attenuation of ANC headphones by several decibels.

</details>


### [255] [Five-Level Common-Ground Inverter Topology Using an Integrated Charge-Pump and Switched-Capacitor Network](https://arxiv.org/abs/2509.16012)
*Anup Marahatta,Shafiuzzaman Khadem,Sandipan Patra*

Main category: eess.SY

TL;DR: 一个用于离网光伏发电的新型五电平逆变器拓扑。


<details>
  <summary>Details</summary>
Motivation: 提供一种适用于离网光伏发电的新型五电平逆变器拓扑。

Method: 提出一种新型的五电平逆变器拓扑。

Result: 该拓扑适用于离网光伏发电。

Conclusion: 该新型五电平逆变器拓扑可满足离网光伏发电应用的需求。

Abstract: This paper presents a novel five-level common-ground (CG) inverter topology
designed for transformerless residential photovoltaic (PV) applications.

</details>


### [256] [On the Number of Control Nodes of Threshold and XOR Boolean Networks](https://arxiv.org/abs/2509.16077)
*Christopher H. Fok,Liangjie Sun,Tatsuya Akutsu,Wai-Ki Ching*

Main category: eess.SY

TL;DR: 本论文研究了具有度约束的阈值和XOR布尔网络的最小可控性问题，为控制节点数量提供了上下界，并提出了相关的计算算法。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于理解和控制基因调控网络等生物系统，特别是通过最小干预来实现系统可控。

Method: 论文首先推导了阈值布尔网络的下界相关不等式和上界，然后构建了具有少量控制节点的阈值布尔网络。接着，为异或（XOR）布尔网络推导了可控性的充要条件，并提出了计算控制节点集和控制信号的多项式时间算法。最后，利用环论和线性代数，为一类特定的度约束XOR布尔网络（k-k-XOR-BNs）建立了最优情况下的上界。

Result: 论文为阈值布尔网络提供了控制节点的数量界限，并成功构建了具有少量控制节点的网络。对于XOR布尔网络，论文给出了可控性的代数充要条件和高效的计算算法。特别地，论文证明了对于特定的k-k-XOR-BNs，只需要一个控制节点即可实现2^m个节点的网络可控。

Conclusion: 本研究为基因调控网络等网络化系统的最小干预提供了理论见解，并通过数学方法（不等式、代数条件、算法、环论和线性代数）为不同类型的布尔网络（阈值和XOR）的可控性分析和控制节点数量的确定做出了贡献。

Abstract: Boolean networks (BNs) are important models for gene regulatory networks and
many other biological systems. In this paper, we study the minimal
controllability problem of threshold and XOR BNs with degree constraints.
Firstly, we derive lower-bound-related inequalities and some upper bounds for
the number of control nodes of several classes of controllable majority-type
threshold BNs. Secondly, we construct controllable majority-type BNs and BNs
involving Boolean threshold functions with both positive and negative
coefficients such that these BNs are associated with a small number of control
nodes. Thirdly, we derive a linear-algebraic necessary and sufficient condition
for the controllability of general XOR-BNs, whose update rules are based on the
XOR logical operator, and construct polynomial-time algorithms for computing
control-node sets and control signals for general XOR-BNs. Lastly, we use ring
theory and linear algebra to establish a few best-case upper bounds for a type
of degree-constrainted XOR-BNs called $k$-$k$-XOR-BNs. In particular, we show
that for any positive integer $m \geq 2$ and any odd integer $k \in [3, 2^{m} -
1]$, there exists a $2^{m}$-node controllable $k$-$k$-XOR-BN with 1 control
node. Our results offer theoretical insights into minimal interventions in
networked systems such as gene regulatory networks.

</details>


### [257] [On-Policy Reinforcement-Learning Control for Optimal Energy Sharing and Temperature Regulation in District Heating Systems](https://arxiv.org/abs/2509.16083)
*Xinyi Yi,Ioannis Lestas*

Main category: eess.SY

TL;DR: 数据驱动的温控和能源共享方案可优化区域供暖系统。


<details>
  <summary>Details</summary>
Motivation: 解决在需求和系统参数未知的情况下，区域供暖系统的温度调控和最优能源共享问题。

Method: 提出一种采用数据驱动的在线更新的温控方案。

Result: 该方案能收敛到系统的最优平衡点，并保证收敛到最优LQR控制策略，从而提供良好的瞬态性能。仿真结果也验证了该方法的效率。

Conclusion: 所提出的数据驱动方法能够有效地优化区域供暖系统的温度调控和能源共享。

Abstract: We address the problem of temperature regulation and optimal energy sharing
in district heating systems (DHSs) where the demand and system parameters are
unknown. We propose a temperature regulation scheme that employs data-driven
on-policy updates that achieve these objectives. In particular, we show that
the proposed control scheme converges to an optimal equilibrium point of the
system, while also having guaranteed convergence to an optimal LQR control
policy, thus providing good transient performance. The efficiency of our
approach is also demonstrated through extensive simulations.

</details>


### [258] [Real-Time Thermal State Estimation and Forecasting in Laser Powder Bed Fusion](https://arxiv.org/abs/2509.16114)
*Yukta Pareek,Abdul Malik Al Mardhouf Al Saadi,Amrita Basak,Satadru Dey*

Main category: eess.SY

TL;DR: 该研究提出了一种用于激光粉末床熔融（L-PBF）的实时热状态预测框架，通过结合物理信息降阶热模型和卡尔曼滤波，能够有效预测温度分布，为 L-PBF 过程的主动控制提供解决方案。


<details>
  <summary>Details</summary>
Motivation: L-PBF 过程中缺乏实时预测温度分布的能力，影响了零件质量和结构完整性，需要一种能够预测未来温度分布以进行主动过程控制的方法。

Method: 提出了一种基于物理信息降阶热模型和卡尔曼滤波相结合的实时热状态预测框架，以捕捉层间热传递动力学并预测温度演变。

Result: 通过对多种零件几何形状的测量数据进行验证，该方法能够可靠地估计和预测峰值温度和冷却趋势。

Conclusion: 该框架通过实现预测性热管理，为 L-PBF 过程提供了一种实际且计算效率高 的解决方案，为 L-PBF 的闭环控制铺平了道路。

Abstract: Laser Powder Bed Fusion (L-PBF) is a widely adopted additive manufacturing
process for fabricating complex metallic parts layer by layer. Effective
thermal management is essential to ensure part quality and structural
integrity, as thermal gradients and residual stresses can lead to defects such
as warping and cracking. However, existing experimental or computational
techniques lack the ability to forecast future temperature distributions in
real time, an essential capability for proactive process control. This paper
presents a real-time thermal state forecasting framework for L-PBF, based on a
physics-informed reduced-order thermal model integrated with a Kalman filtering
scheme. The proposed approach efficiently captures inter-layer heat transfer
dynamics and enables accurate tracking and forecasting of spatial and temporal
temperature evolution. Validation across multiple part geometries using
measured data demonstrates that the method reliably estimates and forecasts
peak temperatures and cooling trends. By enabling predictive thermal control,
this framework offers a practical and computationally efficient solution for
thermal management in L-PBF, paving the way toward closed-loop control in
L-PBF.

</details>


### [259] [Polymatroidal Representations of Aggregate EV Flexibility Considering Network Constraints](https://arxiv.org/abs/2509.16134)
*Karan Mukhi,Alessandro Abate*

Main category: eess.SY

TL;DR: EV充电管理需要考虑电网约束，利用广义多面体表示EV聚合灵活性，并提出优化和分解方法。


<details>
  <summary>Details</summary>
Motivation: 电动汽车（EV）的普及带来了显著的灵活性潜力，但无协调或同步充电可能导致配电网络过载。

Method: 利用广义多面体（一类多面体）表示EV种群的总灵活性，并将网络约束集成到该表示中，以获得受网络约束的总灵活性集。此外，还演示了如何对这些受网络约束的总灵活性集进行优化，并提出了一种分解程序，该程序将聚合负荷曲线映射到单个EV调度指令，同时遵守设备级和网络级约束。

Result: 提出了受网络约束的总灵活性集，并开发了一种优化和分解方法。

Conclusion: 所提出的方法能够优化EV充电，同时满足设备和电网约束。

Abstract: The increasing penetration of electric vehicles (EVs) introduces significant
flexibility potential to power systems. However, uncoordinated or synchronous
charging can lead to overloading of distribution networks. Extending recent
approaches that utilize generalized polymatroids, a family of polytopes, to
represent the aggregate flexibility of EV populations, we show how to integrate
network constraints into this representation to obtain network-constrained
aggregate flexibility sets. Furthermore, we demonstrate how to optimize over
these network-constrained aggregate flexibility sets, and propose a
disaggregation procedure that maps an aggregate load profile to individual EV
dispatch instructions, while respecting both device-level and network
constraints.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [260] [PoliTok-DE: A Multimodal Dataset of Political TikToks and Deletions From Germany](https://arxiv.org/abs/2509.15860)
*Tomas Ruiz,Andreas Nanz,Ursula Kristin Schmid,Carsten Schwemmer,Yannis Theocharis,Diana Rieger*

Main category: cs.SI

TL;DR: 该论文发布了一个名为 PoliTok-DE 的大规模多模态数据集，其中包含与 2024 年萨克森州选举相关的 TikTok 帖子，并对其中被删除的内容进行了分析。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是提供一个用于计算社会科学研究的多模态数据集，特别关注政治传播、不容忍现象以及社交媒体平台的内容审核策略，特别是针对 2024 年萨克森州选举这一特定事件。

Method: 研究者利用 TikTok 研究 API 和网络爬虫技术，收集了 2024 年 7 月 1 日至 11 月 30 日期间发布的超过 195,000 条与 2024 年萨克森州选举相关的 TikTok 帖子，这些帖子涵盖了视频、音频、图像和文本等多种模态。研究还特别关注了其中被删除的超过 18,000 条帖子（占总数的 17.3%），并提供代码以获取全部多模态媒体和元数据。此外，还进行了一个关于不容忍与娱乐共现现象的标注子集案例研究。

Result: 研究构建了一个包含超过 195,000 条 TikTok 帖子的 PoliTok-DE 数据集，其中 17.3% 的帖子已被删除。通过案例研究，初步展示了该数据集在分析不容忍与娱乐共现方面的潜力。

Conclusion: PoliTok-DE 数据集为计算社会科学研究提供了宝贵资源，尤其是在政治传播、不容忍现象以及理解平台内容删除策略方面，并支持多模态研究方法。

Abstract: We present PoliTok-DE, a large-scale multimodal dataset (video, audio,
images, text) of TikTok posts related to the 2024 Saxony state election in
Germany. The corpus contains over 195,000 posts published between 01.07.2024
and 30.11.2024, of which over 18,000 (17.3%) were subsequently deleted from the
platform. Posts were identified via the TikTok research API and complemented
with web scraping to retrieve full multimodal media and metadata. PoliTok-DE
supports computational social science across substantive and methodological
agendas: substantive work on intolerance and political communication;
methodological work on platform policies around deleted content and
qualitative-quantitative multimodal research. To illustrate one possible
analysis, we report a case study on the co-occurrence of intolerance and
entertainment using an annotated subset. The dataset of post IDs is publicly
available on Hugging Face, and full content can be hydrated with our provided
code. Access to the deleted content is restricted, and can be requested for
research purposes.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [261] [Long-lived dynamics of the charge density wave in TiSe$_2$ observed by neutron scattering](https://arxiv.org/abs/2509.15358)
*K. Dharmasiri,S. S. Philip,D. Louca,S. A. Chen,M. D. Frontzek,Z. J. Morgan,C. Hua*

Main category: cond-mat.mtrl-sci

TL;DR: 激光加热下1T-TiSe2的电荷密度波（CDW）熔化和重构行为，揭示了非热机制在CDW熔化中的作用。


<details>
  <summary>Details</summary>
Motivation: 研究1T-TiSe2在激光加热下的电荷密度波（CDW）状态，特别是CDW的熔化和重构过程，以探究声子和激子的作用。

Method: 结合时间分辨弹性中子散射和快速激光加热技术，探测CDW状态。

Result: 激光加热导致CDW状态下的超晶格布拉格峰在5秒内消散，该速率远慢于样品的热响应。电子有序破坏迅速，但周期性晶格畸变（PLD）的演化明显滞后。

Conclusion: CDW的熔化通过非热机制进行，可能与超晶格声子（如软模）的损失有关。

Abstract: Time-resolved elastic neutron scattering combined with rapid laser heating
was used to probe the charge density wave (CDW) state in 1T-TiSe$_2$, capturing
both the melting and reformation of the CDW on long timescales and providing
clues on the roles of phonons and excitons. With the laser source on,
superlattice Bragg peaks such as (-1.5, -1.5, 1.5) observed below the CDW
transition due to the new lattice periodicity, dissipate within 5 seconds, at a
rate that is much slower than the sample's thermal response to the heat wave
propagation. Whereas the electronic ordering associated with the CDW phase is
disrupted rapidly by the laser-induced heating, the periodic lattice distortion
(PLD) exhibits a markedly slower evolution during the melting process. This
delayed suppression of the PLD relative to the thermal response indicates that
CDW melting proceeds through a nonthermal pathway, likely linked to the loss of
superlattice phonons such as the soft mode at q = (0.5 ,0, 0.5 ).

</details>


### [262] [First-principles calculation of higher-order elastic constants from divided differences](https://arxiv.org/abs/2509.15468)
*Ruvini Attanayake,Umesh C. Roy,Abhiyan Pandit,Angelo Bongiorno*

Main category: cond-mat.mtrl-sci

TL;DR: 介绍了一种计算材料高阶弹性常数的新方法。


<details>
  <summary>Details</summary>
Motivation: 需要一种能够精确计算材料高阶弹性常数的方法，并且该方法需要适用于各种材料和对称性。

Method: 该方法基于有限应变变形、密度泛函理论计算柯西应力张量以及递归数值微分技术。

Result: 计算了立方晶体材料（如硅和金）高达6阶的弹性常数，三方晶体材料（如α-石英）高达5阶的弹性常数，以及芳纶（kevlar）的二阶和三阶弹性常数。计算结果与基于连续体近似的密度泛函理论计算结果进行了验证。

Conclusion: 所提出的方法能够计算任意阶数的弹性常数，适用于各种晶体材料，并且计算精度得到了验证。

Abstract: A method is presented to calculate from first principles the higher-order
elastic constants of a solid material. The method relies on finite strain
deformations, a density functional theory approach to calculate the Cauchy
stress tensor, and a recursive numerical differentiation technique homologous
to the divided differences polynomial interpolation algorithm. The method is
applicable as is to any material, regardless its symmetry, to calculate elastic
constants of, in principle, any order. Here, we introduce conceptual framework
and technical details of our method, we discuss sources of errors, we assess
convergence trends, and we present selected applications. In particular, our
method is used to calculate elastic constants up to the 6$^{th}$ order of two
crystalline materials with the cubic symmetry, silicon and gold. To demonstrate
general applicability, our method is also used to calculate the elastic
constants up to the 5$^{th}$ order of $\alpha$-quartz, a crystalline material
belonging to the trigonal crystal system, and the second- and third-order
elastic constants of kevlar, a material with an anisotropic bonding network.
Higher order elastic constants computed with our method are validated against
density functional theory calculations by comparing stress responses to large
deformations derived within the continuum approximation.

</details>


### [263] [Intrinsic Berry Curvature Driven Anomalous Hall and Nernst Effect in Co$_2$MnSn](https://arxiv.org/abs/2509.15644)
*Bishal Das,Arnab Bhattacharya,Amit Chanda,Chanchal K. Barman,Jadupati Nag,Hariharan Srikanth,Aftab Alam,I. Das*

Main category: cond-mat.mtrl-sci

TL;DR: Co2MnSn是一种磁性拓扑半金属，在室温下表现出显著的反常霍尔和能斯特电导率，并且可以通过化学取代进一步提高。这使其成为研究拓扑输运现象和开发下一代热电及自旋电子器件的有前景的平台。


<details>
  <summary>Details</summary>
Motivation: 研究具有非平凡的体带交叉的磁性拓扑半金属，以期同时实现大的反常霍尔电导率和能斯特电导率。

Method: 结合第一性原理计算和电子、热学输运测量，研究了Co2MnSn的反常输运特性。通过化学取代来调节费米能级，以期增强反常输运效应。

Result: 第一性原理计算揭示了Co2MnSn中的魏尔点产生显著的贝里曲率，驱动了主要的本征反常霍尔/能斯特效应。电子和热学输运测量结果显示，Co2MnSn在室温下具有鲁棒的反常输运特性，反常霍尔电导率约为500 S/cm，能斯特电导率约为1.3 A/m/K。通过化学取代，在150 K时反常霍尔电导率可达约1376 S/cm，能斯特电导率可达约1.49 A/m/K。

Conclusion: Co2MnSn是一种有前景的磁性拓扑半金属材料，其显著的反常输运特性在室温下得以保持，并且可以通过化学取代进一步优化，这使其在拓扑输运研究以及热电和自旋电子技术领域具有重要的应用潜力。

Abstract: Magnetic topological semimetals often exhibit unusual electronic and thermal
transport due to nontrivial bulk band crossings, enabling simultaneous
realization of large anomalous Hall and Nernst conductivities ($\sigma_{xy}$
and $\alpha_{xy}$). Here, a comprehensive experimental and theoretical study of
the anomalous transport properties of ferromagnetic Co$_2$MnSn is reported.
First-principles calculations reveal topological Weyl points producing
significant Berry curvature, driving dominant intrinsic anomalous Hall/Nernst
effects. Electronic and thermal transport measurements demonstrate robust
anomalous transport with substantial conductivity values that persist at room
temperature ($\sigma_{xy}\sim$ 500 S/cm, $\alpha_{xy}\sim$ 1.3 A/m/K). We also
show how the chemical substitution (via tuning Fermi level) can boost these
effects (up to $\sigma_{xy}\sim$ 1376 S/cm, $\alpha_{xy}\sim$ 1.49 A/m/K at 150
K). These findings position Co$_2$MnSn as a compelling platform for exploring
topological transport phenomena and advancing next-generation thermoelectric
and spintronic technologies.

</details>


### [264] [Crystal Growth, Band Structure, Magnetism and Electrochemical Properties of Hexavalent Strontium Ruthenium Oxyhydroxide](https://arxiv.org/abs/2509.15671)
*Subham Naik,Soumili Dutta,Hiranmayee Senapati,Sweta Yadav,Subarna Ray,Jai Prakash,Rahul Sharma,Gohil S. Thakur*

Main category: cond-mat.mtrl-sci

TL;DR: 发现了一种新的六价钌羟基氧化物Sr3Ru2O9H2，具有独特的五配位钌结构，并对其进行了晶体结构、电子结构、磁性和电化学性质的全面研究。


<details>
  <summary>Details</summary>
Motivation: 钌酸盐是一类具有广泛且令人兴奋的特性的有趣材料，因此发现新的稳定钌酸盐仍然是一个活跃的研究领域。

Method: 采用低温水热法制备Sr3Ru2O9H2，并通过优化Sr(OH)2与KRuO4的比例来分离单晶和粉末样品。

Result: 获得了Sr3Ru2O9H2，其具有罕见的五配位钌，呈孤立的三方棱柱状，并结晶于非中心对称的四方晶系中。孤立的钌多面体导致钌金属中心之间存在约50pm的大空间距离，使得该化合物尽管存在强反铁磁相关性，但仍保持顺磁性。能带结构计算表明，其电子基态为类金属，费米面主要由钌d轨道和氧p轨道贡献。其电化学性能与报道的其他OER催化剂相当。

Conclusion: Sr3Ru2O9H2是一种具有新颖结构的六价钌酸盐，具有顺磁性，并表现出类金属电子性质和相当的电化学性能，值得进一步研究。

Abstract: Ruthenates comprise an interesting class of materials with a wide range of
extremely exciting properties, and thus the discovery of new stable ruthenates
remains an active area of investigation. We report the crystal growth and
comprehensive studies including crystal and electronic structure, magnetic and
electrochemical properties of a hexavalent ruthenium oxyhydroxide Sr3Ru2O9H2
prepared through a low-temperature hydrothermal method. Single crystals and
powder samples of this phase are isolated by optimising the Sr(OH)2 to KRuO4
ratio while maintaining a high base concentration. The new structure consists
of a rare five-coordinated RuVI featuring isolated trigonal prisms and
crystallising in a non-centrosymmetric tetragonal system. Isolated Ru polyhedra
leading to a large spatial distance ~ 50 pm between the Ru metal centres render
the compound paramagnetic despite strong antiferromagnetic correlation. Band
structure calculation suggests a metal-like electronic ground state with mostly
Ru d and O p orbitals contributing to the Fermi surface. The electrochemical
performance of Sr3Ru2O9H2, though not as impressive as RuO2, remains relevant
and is on par with other reported OER catalysts.

</details>


### [265] [Barrier Electrostatics and Contact Engineering for Ultra-Wide Bandgap AlGaN HFETs](https://arxiv.org/abs/2509.15715)
*Seungheon Shin,Can Cao,Jon Pratt,Yinxuan Zhu,Brianna A. Klein,Andrew Armstrong,Andrew A. Allerman,Siddharth Rajan*

Main category: cond-mat.mtrl-sci

TL;DR: We developed UWBG AlGaN HFETs with a split-doped barrier for high-power RF applications, achieving a high breakdown field (> 5.3 MV/cm) and low contact resistance (~1.55 Ωmm), leading to state-of-the-art performance.


<details>
  <summary>Details</summary>
Motivation: The paper aims to develop ultra-wide bandgap (UWBG) AlGaN heterostructure field-effect transistors (HFETs) tailored for high-power radiofrequency applications, addressing the need for devices with enhanced breakdown fields and reduced contact resistance.

Method: A split-doped barrier architecture with two distinct doping concentrations was employed in UWBG AlGaN HFETs to improve both the breakdown field and contact resistance.

Result: The developed UWBG AlGaN HFETs demonstrated a high breakdown field (> 5.3 MV/cm), low contact resistance (~1.55 Ωmm), a maximum drain current of 487 mA/mm, and a high cutoff frequency of 7.2 GHz, representing a state-of-the-art combination of these parameters.

Conclusion: The study demonstrates that the split-doped barrier architecture in UWBG AlGaN HFETs is a viable approach to achieve high device performance, pushing towards material limits while minimizing contact resistance, thus enabling next-generation high-power, high-frequency applications.

Abstract: We report ultra-wide bandgap (UWBG) AlGaN heterostructure field-effect
transistors (HFETs) exhibiting a high breakdown field (> 5.3 MV/cm) and a low
contact resistance (~1.55 {\Omega}mm), tailored for high-power radiofrequency
applications. A split-doped barrier architecture, employing two distinct doping
concentrations, is shown to enhance both the breakdown field and contact
resistance. This design enables a state-of-the-art combination of maximum drain
current (487 mA/mm) and breakdown field, along with a high cutoff frequency of
7.2 GHz. These results demonstrate a viable pathway to push device performance
toward the material limits while minimizing contact resistance in UWBG AlGaN
HFETs, paving the way for next-generation high-power, high-frequency
applications.

</details>


### [266] [Direct observation of cation-dependent polarisation switching dynamics in fluorite ferroelectrics](https://arxiv.org/abs/2509.15682)
*Kousuke Ooe,Yufan Shen,Kazuki Shitara,Shunsuke Kobayashi,Yuichi Shimakawa,Daisuke Kan,Joanne Etheridge*

Main category: cond-mat.mtrl-sci

TL;DR: 氟化物铁电材料因其独特的铁电机制而成为下一代非易失性存储器的有希望的候选材料，但其极化切换机制的原子尺度动力学仍存在争议。本研究使用先进的扫描透射电子显微镜技术直接观察了ZrO2和Hf0.5Zr0.5O2薄膜中的极化切换路径，并结合密度泛函理论揭示了不同阳离子物种的影响。


<details>
  <summary>Details</summary>
Motivation: 由于对原子尺度动力学了解有限，理解氟化物铁电材料的极化切换机制对开发下一代非易失性存储器至关重要。

Method: 使用最佳明场扫描透射电子显微镜技术直接观察ZrO2和Hf0.5Zr0.5O2独立薄膜中的极化切换路径和氧位点动力学，并结合密度泛函理论分析不同阳离子物种的影响。

Result: 观察到180度和90度极化切换路径涉及不同空间尺度的非极化中间态。揭示了阳离子物种如何影响可及的极化切换路径。

Conclusion: 本研究提供了对极化切换动力学的原子级见解，为氟化物铁电材料和相关存储器的工程设计开辟了新途径。

Abstract: Fluorite ferroelectrics are exciting candidates for next-generation
non-volatile memory devices because their unique ferroelectric mechanism, which
arises from unconventional oxygen displacements, permits ferroelectricity with
minimal thickness constraints. However, the polarisation switching mechanism
remains the subject of intense debate due to a limited understanding of the
atomic-scale dynamics which are extremely challenging to detect and measure.
Here, we observe directly the polarisation switching pathways by visualising
oxygen site dynamics in ZrO2 and Hf0.5Zr0.5O2 freestanding membranes using an
advanced atomic-column imaging technique-optimum bright-field scanning
transmission electron microscopy. We observe that the 180- and 90-degree
polarisation pathways involve different nonpolar intermediate states with
distinct spatial scales. Coupled with density functional theory, we also reveal
how different cation species in fluorite oxides impact the accessible
polarisation switching pathways. Our atomic-level insights into the
polarisation switching dynamics open new avenues for the advanced engineering
of fluorite ferroelectric materials and resulting memory devices.

</details>


### [267] [Unveiling Excitonic Insulator Signatures in Ta$_\mathrm{2}$NiSe$_\mathrm{5}$](https://arxiv.org/abs/2509.15771)
*Nour Maraytta,Peter Nagel,Fatemeh Ghorbani,Amir Ghiami,Santanu Pakhira,Mai Ye,Bjoern Wehinger,Federico Abbruciati,Gaston Garbarino,Matthieu Le Tacon,Stefan Schuppler,Amir-Abbas Haghighirad,Michael Merz*

Main category: cond-mat.mtrl-sci

TL;DR: Ta2NiSe5及其掺杂类似物在高温下表现出结构相变，这与具有吸引力的电子特性的激子绝缘体状态有关。


<details>
  <summary>Details</summary>
Motivation: 鉴于激子绝缘体围绕其能隙的特定穹顶状演化，研究Ta2NiSe5及其类似物以探索其作为激子绝缘体的潜力。

Method: 使用高分辨率单晶X射线衍射和近边X射线吸收精细结构(NEXAFS)研究了Ta2NiSe5、Ta2(Ni,Co)Se5和Ta2NiS5。

Result: 研究发现在Ta2NiSe5和Ta2(Ni,Co)Se5中存在从正交晶系(Cmcm)到单斜晶系(C2/c)的二级结构相变，而在Ta2NiS5中未观察到相变。该相变增强了Ta、Ni和Se原子之间的杂化，缩短了键长，并加强了轨道相互作用。NEXAFS数据证实了更强的杂化、激子结合能的显著变化以及轨道特性的关键改变。

Conclusion: 研究结果表明Ta2NiSe5中存在激子绝缘体状态，并强调了轨道在形成激子绝缘体状态中的关键电子作用。Ta2NiS5中未观察到相变，这表明其电子特性不同。

Abstract: The high-temperature phase of Ta$_\mathrm{2}$NiSe$_\mathrm{5}$, a
near-zero-gap semiconductor ($E_G$ = 0), is a promising candidate for an
excitonic insulator. Given the dome-like evolution expected for an excitonic
insulator around $E_G$, we investigated Ta$_\mathrm{2}$NiSe$_\mathrm{5}$, the
more semi-metallic Ta$_\mathrm{2}$(Ni,Co)Se$_\mathrm{5}$, and semiconducting
Ta$_\mathrm{2}$NiS$_\mathrm{5}$ using high-resolution single-crystal x-ray
diffraction and near-edge x-ray absorption fine structure (NEXAFS). Our
findings reveal a second-order structural phase transition from orthorhombic
(space group: $Cmcm$) to monoclinic (space group: $C2/c$) in
Ta$_\mathrm{2}$NiSe$_\mathrm{5}$ and Ta$_\mathrm{2}$(Ni,Co)Se$_\mathrm{5}$, but
no transition in Ta$_\mathrm{2}$NiS$_\mathrm{5}$ down to 2 K. This transition
breaks two mirror symmetries, enabling and enhancing the hybridization of Ta,
Ni, and Se atoms, shortening bond lengths, and strengthening orbital
interactions. NEXAFS data confirm stronger hybridization, significant changes
in excitonic binding energies, and a key alteration in orbital character,
suggesting an excitonic insulating state in Ta$_\mathrm{2}$NiSe$_\mathrm{5}$
and emphasizing the crucial electronic role of orbitals in the formation of the
excitonic insulator state.

</details>


### [268] [Mechanistic Insights into Complete Methane Oxidation on Single-Atom Pd Supported by SSZ-13 Zeolite: A First-Principles Study](https://arxiv.org/abs/2509.15875)
*Anuroopa Behatha,Shalini Tomar,Hojin Jeong,Joon Hwan Choi,Seung-Cheol Lee,Satadeep Bhattacharjee*

Main category: cond-mat.mtrl-sci

TL;DR: Complete catalytic oxidation of methane is challenging for Pd-based catalysts. This study uses DFT and CI-NEB to investigate methane oxidation over single-atom Pd on SSZ-13 zeolite. The O2-assisted pathway is found to be more favorable than the direct pathway, especially for C-H bond cleavage. Oxygen-rich environments and multi-site mechanisms enhance thermodynamic feasibility, suggesting design principles for improved Pd-zeolite catalysts.


<details>
  <summary>Details</summary>
Motivation: Palladium-based catalysts face challenges in achieving both high activity and stability for the complete catalytic oxidation of methane, a crucial process for greenhouse gas mitigation and clean energy conversion.

Method: Density functional theory (DFT) calculations combined with climbing-image nudged elastic band (CI-NEB) calculations were employed to investigate methane oxidation over single-atom Pd supported on SSZ-13 zeolite. Various Al distributions and Pd placements were assessed, and two mechanistic routes (direct dehydrogenation and O2-assisted oxidative dehydrogenation) were evaluated to determine activation barriers and energy profiles.

Result: The O2-assisted oxidative dehydrogenation pathway was found to be energetically favorable with an exothermic profile, particularly during C-H bond cleavage, in contrast to the energetically demanding and endothermic direct (dry) pathway. Stable hydroxyl and CO/CO2 intermediates were identified. An alternative low-energy pathway involving O-assisted and multi-site mechanisms was proposed, reducing the overall reaction enthalpy.

Conclusion: Oxygen-rich environments significantly improve the thermodynamic feasibility of complete methane oxidation over single-atom Pd/SSZ-13. The study proposes design principles for developing highly active and moisture-resistant Pd-zeolite catalysts for sustainable methane utilization, highlighting the importance of O-assisted and multi-site mechanisms for low-energy pathways.

Abstract: Complete catalytic oxidation of methane is an effective strategy for
greenhouse gas mitigation and clean energy conversion; yet, ensuring both high
catalytic activity and stability with palladium-based catalysts remains a
challenge. In the present work, we employed a theoretical investigation of
methane oxidation over single-atom Pd supported on SSZ-13 zeolite using density
functional theory calculations, combined with climbing-image nudged elastic
band calculations to determine activation barriers. A systematic assessment of
various Al distributions and Pd placements was carried out to identify the most
stable configurations for Pd incorporation within the zeolite
framework.Further, two mechanistic routes for methane activation were
evaluated: (i) direct dehydrogenation under dry conditions, and (ii)
O$_2$-assisted oxidative dehydrogenation. Our results demonstrate that the
direct (dry) pathway is energetically demanding and overall endothermic,
whereas the O$_2$ assisted route facilitates the exothermic energy profile,
particularly in the C-H bond cleavage. The formation of stable hydroxyl and
CO/CO$_2$ intermediates were also studied. The results emphasize the role of
oxygen-rich environments in enabling the complete methane oxidation with
improved thermodynamic feasibility. Moreover, we propose an alternate
low-energy pathway based on O-assisted and multi-site mechanisms that reduce
the overall reaction enthalpy. These insights provide the design principles for
highly active and moisture-resistant Pd-zeolite catalysts for sustainable
methane utilization.

</details>


### [269] [An Equivariant Graph Network for Interpretable Nanoporous Materials Design](https://arxiv.org/abs/2509.15908)
*Zhenhao Zhou,Salman Bin Kashif,Dawei Feng,Jin-Hu Dou,Kaihang Shi,Tao Deng,Zhenpeng Yao*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究提出了一种三维周期性空间采样方法，用于分析纳米多孔材料的结构-性质关系，实现了高精度的性质预测和可解释的位点贡献量化。


<details>
  <summary>Details</summary>
Motivation: 纳米多孔材料在可持续应用领域潜力巨大，但其庞大的化学空间给高效设计带来了挑战。机器学习可加速探索，但现有模型在可解释性或保真度方面存在不足，难以阐明晶体几何与性质间的关联。

Method: 提出一种三维周期性空间采样方法，将大型纳米多孔结构分解为局部几何位点，以结合性质预测和位点贡献量化。

Result: 所提出的模型在气体储存、分离和导电等性质预测方面达到了最先进的准确性和数据效率。该方法还能解释预测结果，并能准确识别对目标性质有显著影响的局部位点。

Conclusion: 该方法通过识别不同纳米多孔骨架中可转移的高性能位点，为可解释的、对称为感知的纳米多孔材料设计开辟了道路，并且该方法还可以扩展到分子晶体等其他材料。

Abstract: Nanoporous materials hold promise for diverse sustainable applications, yet
their vast chemical space poses challenges for efficient design. Machine
learning offers a compelling pathway to accelerate the exploration, but
existing models lack either interpretability or fidelity for elucidating the
correlation between crystal geometry and property. Here, we report a
three-dimensional periodic space sampling method that decomposes large
nanoporous structures into local geometrical sites for combined property
prediction and site-wise contribution quantification. Trained with a
constructed database and retrieved datasets, our model achieves
state-of-the-art accuracy and data efficiency for property prediction on gas
storage, separation, and electrical conduction. Meanwhile, this approach
enables the interpretation of the prediction and allows for accurate
identification of significant local sites for targeted properties. Through
identifying transferable high-performance sites across diverse nanoporous
frameworks, our model paves the way for interpretable, symmetry-aware
nanoporous materials design, which is extensible to other materials, like
molecular crystals and beyond.

</details>


### [270] [Phase Behavior and Ion Transport in Lithium-Niobium-Tantalum Oxide Alloys](https://arxiv.org/abs/2509.16021)
*Hengning Chen,Zeyu Deng,Gopalakrishnan Sai Gautam,Yan Li,Pieremanuele Canepa*

Main category: cond-mat.mtrl-sci

TL;DR: Li3NbxTa1-xO4的相行为和性质很大程度上是未知的。本研究通过第一性原理声子计算、簇展开和蒙特卡洛模拟，推导了Li3NbxTa1-xO4的温度-组成相图。研究结果表明，振动熵在预测相稳定性方面起着至关重要的作用，它促进了Nb在Li3TaO4中的溶解度，同时抑制了Ta在Li3NbO4中的混溶性。此外，Nb/Ta混合为调控Li3NbxTa1-xO4的锂离子电导率提供了一条有前途的途径。本研究强调了在处理多组分系统（而不仅仅是简单的二元混合物）的蒙特卡洛模拟中明确包含振动熵效应的重要性。该研究为Li3NbxTa1-xO4在储能和其他领域的潜在应用奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 尽管LiNbxTa1-xO3在高性能法拉第电容器、非线性光学和可充电电池的保护涂层等领域具有广泛应用，但Li3NbxTa1-xO4的相行为和性质在很大程度上仍是未知的。

Method: 采用多尺度方法，包括第一性原理声子计算、簇展开和蒙特卡洛模拟，来推导Li3NbxTa1-xO4的温度-组成相图。

Result: 研究结果表明，振动熵在预测相稳定性方面起着至关重要的作用，它促进了Nb在Li3TaO4中的溶解度，同时抑制了Ta在Li3NbO4中的混溶性。此外，Nb/Ta混合为调控Li3NbxTa1-xO4的锂离子电导率提供了一条有前途的途径。本研究强调了在处理多组分系统（而不仅仅是简单的二元混合物）的蒙特卡洛模拟中明确包含振动熵效应的重要性。

Conclusion: 该研究为Li3NbxTa1-xO4的相行为和锂离子传输性质提供了基础见解，为其在储能和其他领域的潜在应用铺平了道路。

Abstract: Lithium niobate-tantalate mixtures have garnered considerable interest for
their ability to merge the desirable properties of both end members, enabling
diverse high-value applications, such as high-performance faradaic capacitors,
non-linear optics, and protective coatings in rechargeable batteries. While
numerous studies on the application of $\mathrm{LiNb_xTa_{1-x}O_3}$ exist, the
phase behavior and properties of $\mathrm{Li_3Nb_xTa_{1-x}O_4}$ remain largely
unexplored. In this work, we employ a multiscale approach that encompasses
first-principles phonon calculations, cluster expansion, and Monte Carlo
simulations to derive the temperature-composition phase diagram for
$\mathrm{Li_3Nb_xTa_{1-x}O_4}$. Our findings reveal the critical role of
vibrational entropy in accurately predicting phase stability, which promotes
the solubility of Nb in $\mathrm{Li_3TaO_4}$ while suppressing the miscibility
of Ta in $\mathrm{Li_3NbO_4}$. Additionally, we demonstrate that Nb/Ta mixing
offers a promising avenue for tailoring the Li-ion conductivities of
$\mathrm{Li_3Nb_xTa_{1-x}O_4}$. On the technical side, we demonstrated the
importance of including vibrational entropy effects explicitly in Monte Carlo
simulations dealing with multicomponent systems, beyond simple binary mixtures.
On the application side, this study provides fundamental insights into the
phase behavior and Li-ion transport properties of
$\mathrm{Li_3Nb_xTa_{1-x}O_4}$, paving the way for its potential applications
in energy storage and other fields.

</details>


### [271] [Phonon polariton Hall effect](https://arxiv.org/abs/2509.16100)
*Omer Yaniv,Dominik M. Juraschek*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究表明，在磁场中，声子极化激子（由光学声子和太赫兹辐射耦合而成）可以支持横向能量流，并能通过声子极化霍尔效应实现光的弯曲。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是将声子霍尔效应推广到光-物质混合激发，并探索其在太赫兹波段的应用潜力。

Method: 通过理论推导，计算了在磁场作用下，声子极化激子的能流算符，并证明了其具有不等群速度的左旋和右旋圆偏振模式，从而实现了横向能量流。

Result: 研究表明，声子极化霍尔效应导致了左旋和右旋圆偏振模式的群速度不等，进而产生了横向能量流，并通过声子极化霍尔效应实现了光的弯曲。

Conclusion: 本研究首次理论证明了在磁场中，声子极化激子可以支持横向能量流，并能通过声子极化霍尔效应实现光的弯曲，为开发太赫兹极化激子器件提供了新的途径。

Abstract: The phonon Hall effect conventionally describes the generation of a
transverse heat current in an applied magnetic field. In this work, we extend
the effect to hybrid light-matter excitations and demonstrate theoretically
that phonon polaritons, formed by coupling optical phonons with terahertz
radiation, support transverse energy flow when coherently driven in an applied
magnetic field. Using the example of PbTe, which exhibits strongly coupled
phonon polaritons, we show that the magnetic field splits the phonon-polariton
branches into left and right-handed circular polarization, obtaining unequal
group velocities. We derive the energy current operators for propagating phonon
polaritons and show how their mixed phononic-photonic nature enables
controllable transverse phonon-polariton transport in the terahertz regime. Our
results demonstrate bending of light through a phonon polariton Hall effect,
which provides a route towards terahertz polaritonic devices.

</details>


### [272] [Electronic bounds in magnetic crystals](https://arxiv.org/abs/2509.16121)
*Daniel Passos,Ivo Souza*

Main category: cond-mat.mtrl-sci

TL;DR: 本文系统研究了磁性晶体中不同电子性质（电子密度、有效质量、轨道磁矩、局域化长度、陈数不变量、电极化率）之间的约束关系，发现了新的理论下限和上限，并将其从二维推广到三维，适用于金属和绝缘体。


<details>
  <summary>Details</summary>
Motivation: 研究磁性晶体中不同电子性质间的约束关系，旨在发现新的理论结果并推广现有理论。

Method: 系统地研究了电子密度、有效质量、轨道磁矩、局域化长度、陈数不变量和电极化率之间的约束关系，并将其应用于低能带和高能带，以及金属和绝缘体。

Result: 发现了陈绝缘体的电极化率的下限，以及轨道磁矩的求和部分的上限。将涉及陈数不变量的约束关系从二维推广到三维。这些约束关系在金属和绝缘体中均成立。

Conclusion: 本文提出的约束关系普遍适用于磁性晶体，并且发现了新的理论结果，将二维的陈数推广到了三维的陈向量。

Abstract: We present a systematic study of bound relations between different electronic
properties of magnetic crystals: electron density, effective mass, orbital
magnetization, localization length, Chern invariant, and electric
susceptibility. All relations are satisfied for a group of low-lying bands,
while some remain valid for upper bands. New results include a lower bound on
the electric susceptibility of Chern insulators, and an upper bound on the
sum-rule part of the orbital magnetization. In addition, bounds involving the
Chern invariant are generalized from two dimensions (Chern number) to three
(Chern vector). Bound relations are established for metals as well as
insulators, and are illustrated for model systems. The manner in which they
approach saturation in a model Chern insulator with tunable flat bands is
analyzed in terms of the optical absorption spectrum.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [273] [MICA: Multi-Agent Industrial Coordination Assistant](https://arxiv.org/abs/2509.15237)
*Di Wen,Kunyu Peng,Junwei Zheng,Yufan Chen,Yitain Shi,Jiale Wei,Ruiping Liu,Kailun Yang,Rainer Stiefelhagen*

Main category: cs.AI

TL;DR: MICA是一个多智能体工业协作助手，可在计算、连接和隐私受限的环境中提供实时指导。它利用五个专业化的语言智能体和自适应步骤融合（ASF）技术，以提高任务成功率和可靠性，并已在离线硬件上进行了部署。


<details>
  <summary>Details</summary>
Motivation: 工业工作流需要能够在计算、连接和隐私受限的环境下，提供自适应和可信赖的辅助。MICA旨在满足这一需求。

Method: MICA通过协调五个专业化的语言智能体，并由安全检查器进行审核，来实现准确和合规的支持。它引入了自适应步骤融合（ASF）技术，该技术结合了专家推理和在线自然语音反馈调整，以实现对步骤的鲁棒理解。此外，它还建立了一个新的跨代表性任务类别的多智能体协作基准，并提出了针对工业辅助的评估指标。

Result: 实验表明，MICA在任务成功率、可靠性和响应速度方面持续优于基线结构，并且可以在实际的离线硬件上部署。MICA被认为是实现可部署、注重隐私的多智能体辅助系统的重要一步，适用于动态工厂环境。

Conclusion: MICA是一个多智能体工业协作助手，能够提供实时的、注重隐私的、在资源受限环境下的辅助支持，并在工业环境中取得了良好的效果。

Abstract: Industrial workflows demand adaptive and trustworthy assistance that can
operate under limited computing, connectivity, and strict privacy constraints.
In this work, we present MICA (Multi-Agent Industrial Coordination Assistant),
a perception-grounded and speech-interactive system that delivers real-time
guidance for assembly, troubleshooting, part queries, and maintenance. MICA
coordinates five role-specialized language agents, audited by a safety checker,
to ensure accurate and compliant support. To achieve robust step understanding,
we introduce Adaptive Step Fusion (ASF), which dynamically blends expert
reasoning with online adaptation from natural speech feedback. Furthermore, we
establish a new multi-agent coordination benchmark across representative task
categories and propose evaluation metrics tailored to industrial assistance,
enabling systematic comparison of different coordination topologies. Our
experiments demonstrate that MICA consistently improves task success,
reliability, and responsiveness over baseline structures, while remaining
deployable on practical offline hardware. Together, these contributions
highlight MICA as a step toward deployable, privacy-preserving multi-agent
assistants for dynamic factory environments. The source code will be made
publicly available at https://github.com/Kratos-Wen/MICA.

</details>


### [274] [KNARsack: Teaching Neural Algorithmic Reasoners to Solve Pseudo-Polynomial Problems](https://arxiv.org/abs/2509.15239)
*Stjepan Požgaj,Dobrik Georgiev,Marin Šilić,Petar Veličković*

Main category: cs.AI

TL;DR: NAR 领域的一个新尝试，通过模仿经典算法来解决 Knapsack 问题。


<details>
  <summary>Details</summary>
Motivation: 在标准 NAR 基准中，Knapsack 问题（一种连接经典算法和组合优化的伪多项式问题）被忽略了。本文旨在解决这一问题。

Method: 设计了一个模仿 Knapsack 问题两阶段流程（构建动态规划表和重构解决方案）的神经算法推理器，并通过动态规划监督来模拟中间状态。

Result: 与直接预测基线相比，该方法在泛化到更大的问题实例方面表现更好。

Conclusion: 通过动态规划监督来模拟中间状态的神经算法推理器能够更好地泛化到更大的 Knapsack 问题实例。

Abstract: Neural algorithmic reasoning (NAR) is a growing field that aims to embed
algorithmic logic into neural networks by imitating classical algorithms. In
this extended abstract, we detail our attempt to build a neural algorithmic
reasoner that can solve Knapsack, a pseudo-polynomial problem bridging
classical algorithms and combinatorial optimisation, but omitted in standard
NAR benchmarks. Our neural algorithmic reasoner is designed to closely follow
the two-phase pipeline for the Knapsack problem, which involves first
constructing the dynamic programming table and then reconstructing the solution
from it. The approach, which models intermediate states through dynamic
programming supervision, achieves better generalization to larger problem
instances than a direct-prediction baseline that attempts to select the optimal
subset only from the problem inputs.

</details>


### [275] [The Distribution Shift Problem in Transportation Networks using Reinforcement Learning and AI](https://arxiv.org/abs/2509.15291)
*Federico Taschin,Abderrahmane Lazaraq,Ozan K. Tonguz,Inci Ozgunes*

Main category: cs.AI

TL;DR: 元强化学习（Meta RL）在智能交通信号控制中可能存在可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 智能交通网络中机器学习（ML）和人工智能（AI）的应用日益广泛，其中强化学习（RL）被证明是一种有前景的方法。然而，在交通信号控制中使用RL时，由于训练数据的分布会动态变化，导致训练好的RL代理的可靠性成为一个挑战。

Method: 评估和分析一种名为MetaLight的先进Meta RL方法，并在不同条件下进行测试。

Result: MetaLight在某些条件下表现良好，但在其他条件下性能下降（错误率高达22%）。

Conclusion: Meta RL方案并非总是足够鲁棒，可能存在重大的可靠性问题。

Abstract: The use of Machine Learning (ML) and Artificial Intelligence (AI) in smart
transportation networks has increased significantly in the last few years.
Among these ML and AI approaches, Reinforcement Learning (RL) has been shown to
be a very promising approach by several authors. However, a problem with using
Reinforcement Learning in Traffic Signal Control is the reliability of the
trained RL agents due to the dynamically changing distribution of the input
data with respect to the distribution of the data used for training. This
presents a major challenge and a reliability problem for the trained network of
AI agents and could have very undesirable and even detrimental consequences if
a suitable solution is not found. Several researchers have tried to address
this problem using different approaches. In particular, Meta Reinforcement
Learning (Meta RL) promises to be an effective solution. In this paper, we
evaluate and analyze a state-of-the-art Meta RL approach called MetaLight and
show that, while under certain conditions MetaLight can indeed lead to
reasonably good results, under some other conditions it might not perform well
(with errors of up to 22%), suggesting that Meta RL schemes are often not
robust enough and can even pose major reliability problems.

</details>


### [276] [An Artificial Intelligence Driven Semantic Similarity-Based Pipeline for Rapid Literature](https://arxiv.org/abs/2509.15292)
*Abhiyan Dhakal,Kausik Paudel,Sanjog Sigdel*

Main category: cs.AI

TL;DR: 该研究提出了一种使用Transformer和余弦相似度进行文献综述的自动化流程，特点是开销小、相关性高。


<details>
  <summary>Details</summary>
Motivation: 传统的文献综述方法效率低下，本研究旨在通过利用语义相似性来改进这一过程，以实现最小的开销和高相关性。

Method: 使用Transformer生成的词嵌入和余弦相似度来计算文本之间的语义距离。输入论文的标题和摘要后，系统能生成关键词，从开放获取的知识库中检索相关论文，并根据与输入论文的语义相似度对检索结果进行排序。研究中评估了三种词嵌入模型，并采用统计阈值方法来过滤相关论文。

Result: 该系统能够根据输入的论文标题和摘要，生成关键词，检索相关论文，并进行排序。在没有启发式反馈或真实相关性标签的情况下，该系统在过滤相关论文方面显示出潜力。

Conclusion: 该自动化文献综述流程利用Transformer词嵌入和余弦相似度，提供了一种可扩展且实用的初步研究和探索性分析工具。

Abstract: We propose an automated pipeline for performing literature reviews using
semantic similarity. Unlike traditional systematic review systems or
optimization based methods, this work emphasizes minimal overhead and high
relevance by using transformer based embeddings and cosine similarity. By
providing a paper title and abstract, it generates relevant keywords, fetches
relevant papers from open access repository, and ranks them based on their
semantic closeness to the input. Three embedding models were evaluated. A
statistical thresholding approach is then applied to filter relevant papers,
enabling an effective literature review pipeline. Despite the absence of
heuristic feedback or ground truth relevance labels, the proposed system shows
promise as a scalable and practical tool for preliminary research and
exploratory analysis.

</details>


### [277] [Knowledge-Driven Hallucination in Large Language Models: An Empirical Study on Process Modeling](https://arxiv.org/abs/2509.15336)
*Humam Kourani,Anton Antonov,Alessandro Berti,Wil M. P. van der Aalst*

Main category: cs.AI

TL;DR: LLMs在分析任务中可能产生知识驱动的幻觉，即模型的输出与来源证据相矛盾，因为它被模型的内部知识覆盖。本研究通过在自动化流程建模任务中评估LLMs来调查这种现象，该任务旨在从给定的来源文档生成正式的业务流程模型。通过设计对照实验，我们评估了LLMs在多大程度上忠实于所提供的证据，并提出了一种评估此关键可靠性问题的方法。


<details>
  <summary>Details</summary>
Motivation: LLMs在分析任务中具有巨大潜力，但其内置知识可能导致输出与事实证据相悖，即“知识驱动的幻觉”。

Method: 进行一项受控实验，使用描述标准和非典型流程结构的输入，评估LLMs在自动化流程建模任务中对提供证据的忠实度，制造了证据与LLM背景知识之间的冲突。

Result: 评估了LLMs在自动化流程建模任务中，输出与提供证据的冲突程度，量化了知识驱动幻觉的风险。

Conclusion: LLMs在处理基于证据的任务时，可能出现知识驱动的幻觉，需要严格验证AI生成的工件，以确保其可靠性。

Abstract: The utility of Large Language Models (LLMs) in analytical tasks is rooted in
their vast pre-trained knowledge, which allows them to interpret ambiguous
inputs and infer missing information. However, this same capability introduces
a critical risk of what we term knowledge-driven hallucination: a phenomenon
where the model's output contradicts explicit source evidence because it is
overridden by the model's generalized internal knowledge. This paper
investigates this phenomenon by evaluating LLMs on the task of automated
process modeling, where the goal is to generate a formal business process model
from a given source artifact. The domain of Business Process Management (BPM)
provides an ideal context for this study, as many core business processes
follow standardized patterns, making it likely that LLMs possess strong
pre-trained schemas for them. We conduct a controlled experiment designed to
create scenarios with deliberate conflict between provided evidence and the
LLM's background knowledge. We use inputs describing both standard and
deliberately atypical process structures to measure the LLM's fidelity to the
provided evidence. Our work provides a methodology for assessing this critical
reliability issue and raises awareness of the need for rigorous validation of
AI-generated artifacts in any evidence-based domain.

</details>


### [278] [Diagnostics of cognitive failures in multi-agent expert systems using dynamic evaluation protocols and subsequent mutation of the processing context](https://arxiv.org/abs/2509.15366)
*Andrejs Sorstkins,Josh Bailey,Dr Alistair Baron*

Main category: cs.AI

TL;DR: 该研究提出了一个用于评估和迁移专家行为到 LLM 驱动的代理的诊断框架。


<details>
  <summary>Details</summary>
Motivation: 现有的 LLM 代理评估方法不足以诊断其在多步决策过程中的行为，本研究旨在解决这一问题。

Method: 该框架包含三个部分：(i) 专家标注的数据集，(ii) 通过行为变异生成的数据集，(iii) 一个基于 LLM 的代理裁判，用于评分和提出改进建议。改进建议被整合到向量化推荐图中，以实现专家干预的可复用性。

Result: 该框架在多智能体招募-助理系统中得到验证，发现了潜在的认知缺陷（如偏见、提取漂移、工具误路由），并引导代理实现专家级别的推理和风格。

Conclusion: 该框架为在随机、工具增强的 LLM 代理中标准化、可复现的专家行为迁移奠定了基础，实现了从静态评估到主动的专家系统优化。

Abstract: The rapid evolution of neural architectures - from multilayer perceptrons to
large-scale Transformer-based models - has enabled language models (LLMs) to
exhibit emergent agentic behaviours when equipped with memory, planning, and
external tool use. However, their inherent stochasticity and multi-step
decision processes render classical evaluation methods inadequate for
diagnosing agentic performance. This work introduces a diagnostic framework for
expert systems that not only evaluates but also facilitates the transfer of
expert behaviour into LLM-powered agents. The framework integrates (i) curated
golden datasets of expert annotations, (ii) silver datasets generated through
controlled behavioural mutation, and (iii) an LLM-based Agent Judge that scores
and prescribes targeted improvements. These prescriptions are embedded into a
vectorized recommendation map, allowing expert interventions to propagate as
reusable improvement trajectories across multiple system instances. We
demonstrate the framework on a multi-agent recruiter-assistant system, showing
that it uncovers latent cognitive failures - such as biased phrasing,
extraction drift, and tool misrouting - while simultaneously steering agents
toward expert-level reasoning and style. The results establish a foundation for
standardized, reproducible expert behaviour transfer in stochastic,
tool-augmented LLM agents, moving beyond static evaluation to active expert
system refinement.

</details>


### [279] [FragmentRetro: A Quadratic Retrosynthetic Method Based on Fragmentation Algorithms](https://arxiv.org/abs/2509.15409)
*Yu Shee,Anthony M. Smaldone,Anton Morgunov,Gregory W. Kyro,Victor S. Batista*

Main category: cs.AI

TL;DR: FragmentRetro是一种利用碎片算法（BRICS和r-BRICS）、结合库存感知探索和模式指纹筛选的新型逆合成方法，实现了二次计算复杂度 O(h^2)，解决了传统树搜索方法指数级复杂度的难题，并在多个数据集上取得了高解决率和有竞争力的运行时间。


<details>
  <summary>Details</summary>
Motivation: 传统基于树搜索的逆合成方法计算复杂度高（指数级），限制了计算机辅助合成规划（CASP）的应用。需要更高效的方法来处理复杂的分子。

Method: FragmentRetro方法结合了BRICS和r-BRICS碎片算法，利用库存感知探索和模式指纹筛选，通过递归组合分子碎片并验证其在构建模块集合中的存在性来生成逆合成解决方案。该方法将计算复杂度降低到O(h^2)。

Result: 在PaRoutes、USPTO-190和天然产物数据集上的评估表明，FragmentRetro具有高解决率和有竞争力的运行时间，即使在传统树搜索方法失败的情况下也能找到解决方案。指纹筛选显著降低了子结构匹配的复杂度。

Conclusion: FragmentRetro通过其计算优势和生成战略性起始候选物お能力，为可扩展和自动化的合成规划提供了一个强大的基础组件，尽管它主要关注识别基于碎片は的解决方案而非完整的反应路径。

Abstract: Retrosynthesis, the process of deconstructing a target molecule into simpler
precursors, is crucial for computer-aided synthesis planning (CASP). Widely
adopted tree-search methods often suffer from exponential computational
complexity. In this work, we introduce FragmentRetro, a novel retrosynthetic
method that leverages fragmentation algorithms, specifically BRICS and r-BRICS,
combined with stock-aware exploration and pattern fingerprint screening to
achieve quadratic complexity. FragmentRetro recursively combines molecular
fragments and verifies their presence in a building block set, providing sets
of fragment combinations as retrosynthetic solutions. We present the first
formal computational analysis of retrosynthetic methods, showing that tree
search exhibits exponential complexity $O(b^h)$, DirectMultiStep scales as
$O(h^6)$, and FragmentRetro achieves $O(h^2)$, where $h$ represents the number
of heavy atoms in the target molecule and $b$ is the branching factor for tree
search. Evaluations on PaRoutes, USPTO-190, and natural products demonstrate
that FragmentRetro achieves high solved rates with competitive runtime,
including cases where tree search fails. The method benefits from fingerprint
screening, which significantly reduces substructure matching complexity. While
FragmentRetro focuses on efficiently identifying fragment-based solutions
rather than full reaction pathways, its computational advantages and ability to
generate strategic starting candidates establish it as a powerful foundational
component for scalable and automated synthesis planning.

</details>


### [280] [Stress Testing Deliberative Alignment for Anti-Scheming Training](https://arxiv.org/abs/2509.15541)
*Bronson Schoen,Evgenia Nitishinskaya,Mikita Balesni,Axel Højmark,Felix Hofstätter,Jérémy Scheurer,Alexander Meinke,Jason Wolfe,Teun van der Weij,Alex Lloyd,Nicholas Goldowsky-Dill,Angela Fan,Andrei Matveiakin,Rusheb Shah,Marcus Williams,Amelia Glaese,Boaz Barak,Wojciech Zaremba,Marius Hobbhahn*

Main category: cs.AI

TL;DR: AI系统可能秘密追求错误目标，即“蓄谋”。为评估和缓解蓄谋行为，需采用新策略，包括测试模型在分布外任务上的蓄谋倾向、评估其是否具有情境意识，以及检查其对预存的错误目标的鲁棒性。本文使用“秘密行动”（如秘密违规或故意测试表现不佳）作为蓄谋的代理指标，并设计了相应的评估方法。实验发现，“审慎对齐”方法能显著降低秘密行动的发生率，但不能完全消除。该方法在阻止模型追求隐藏目标方面效果显著，但在后续的红队测试中仍发现不当行为。研究还表明，模型的链式思考（CoT）常表现出对齐评估的情境意识，且这种意识会降低秘密行动，反之则会增加。因此，观察到的秘密行动发生率的降低可能部分源于情境意识。尽管研究依赖人类可读的CoT进行训练和评估，但随着模型推理能力超越标准英语，这种依赖性会减弱。本文鼓励对蓄谋行为的对齐缓解措施及其评估进行研究，特别是在欺骗性对齐这一本文未涵盖的对抗性场景。


<details>
  <summary>Details</summary>
Motivation: AI系统可能秘密追求与人类意图不符的目标（即“蓄谋”），这给AI安全带来了严峻挑战。传统的机器学习方法难以检测和缓解这种行为，因此需要新的评估和缓解策略。

Method: 本文提出了一种评估和缓解AI“蓄谋”行为的方法。首先，将“秘密行动”（如秘密违规、故意测试表现不佳）作为“蓄谋”的代理指标，并设计了相应的评估方法，包括测试模型在分布外（OOD）任务上的蓄谋倾向、评估其情境意识以及检查其对预存错误目标的鲁棒性。然后，以“审慎对齐”作为反蓄谋干预措施的案例研究，在26个OOD评估（180多个环境）中进行测试。

Result: “审慎对齐”方法将秘密行动的发生率从13%降低到0.4%，但未能完全消除。该方法在阻止模型追求隐藏目标方面效果显著，但在后续的红队测试中仍发现不当行为。研究还发现，模型的链式思考（CoT）常表现出对齐评估的情境意识，且这种意识与秘密行动的减少呈正相关。

Conclusion: “审慎对齐”是一种有效的反蓄谋干预措施，能显著降低AI的秘密行动发生率，但仍有改进空间。情境意识在AI行为对齐中起重要作用，但随着模型能力的提升，对其的依赖性可能会减弱。未来的研究应着重于开发更强大的反蓄谋技术，特别是在欺骗性对齐等更复杂的对抗场景下。

Abstract: Highly capable AI systems could secretly pursue misaligned goals -- what we
call "scheming". Because a scheming AI would deliberately try to hide its
misaligned goals and actions, measuring and mitigating scheming requires
different strategies than are typically used in ML. We propose that assessing
anti-scheming interventions requires at least (1) testing propensity to scheme
on far out-of-distribution (OOD) tasks, (2) evaluating whether lack of scheming
is driven by situational awareness, and (3) checking for robustness to
pre-existing misaligned goals. We use a broad category of "covert actions" --
such as secretly breaking rules or intentionally underperforming in tests -- as
a proxy for scheming, and design evaluations for covert actions. We then
stress-test deliberative alignment as a case study for anti-scheming. Across 26
OOD evaluations (180+ environments), deliberative alignment reduces covert
action rates (OpenAI o3: 13%->0.4%) but does not fully eliminate them. Our
mitigation is also able to largely stop agents from pursuing a hidden goal
previously trained into the model, but we still find misbehavior after
additional red-teaming. We find that models' chain-of-thought (CoT) often
demonstrates awareness of being evaluated for alignment, and show causal
evidence that this awareness decreases covert behavior, while unawareness
increases it. Therefore, we cannot exclude that the observed reductions in
covert action rates are at least partially driven by situational awareness.
While we rely on human-legible CoT for training, studying situational
awareness, and demonstrating clear evidence of misalignment, our ability to
rely on this degrades as models continue to depart from reasoning in standard
English. We encourage research into alignment mitigations for scheming and
their assessment, especially for the adversarial case of deceptive alignment,
which this paper does not address.

</details>


### [281] [MicroRCA-Agent: Microservice Root Cause Analysis Method Based on Large Language Model Agents](https://arxiv.org/abs/2509.15635)
*Pan Tang,Shixiang Tang,Huanqi Pu,Zhiqing Miao,Zhixing Wang*

Main category: cs.AI

TL;DR: 本文提出了一种基于大语言模型代理的微服务根因分析解决方案MicroRCA-Agent，该方案通过多模态数据融合构建智能故障根因定位系统。


<details>
  <summary>Details</summary>
Motivation: 解决微服务故障根因定位的复杂性问题，提出一种智能化的多模态数据融合分析系统。

Method: 1. 结合Drain日志解析算法和多级数据过滤机制压缩日志。2. 采用Isolation Forest和状态码验证的双重异常检测方法识别追踪异常。3. 设计统计对称比率过滤机制和两阶段大语言模型分析策略，实现跨层级现象的全面总结。4. 利用跨模态提示整合多模态异常信息，通过大语言模型的理解和推理能力生成结构化的分析结果。

Result: 实验验证了各模态数据的价值和系统架构的有效性，在复杂的微服务故障场景下，该方案取得了50.71分。代码已开源。

Conclusion: MicroRCA-Agent通过多模态数据融合和大语言模型代理，有效提高了微服务故障根因分析的准确性和智能化水平。

Abstract: This paper presents MicroRCA-Agent, an innovative solution for microservice
root cause analysis based on large language model agents, which constructs an
intelligent fault root cause localization system with multimodal data fusion.
The technical innovations are embodied in three key aspects: First, we combine
the pre-trained Drain log parsing algorithm with multi-level data filtering
mechanism to efficiently compress massive logs into high-quality fault
features. Second, we employ a dual anomaly detection approach that integrates
Isolation Forest unsupervised learning algorithms with status code validation
to achieve comprehensive trace anomaly identification. Third, we design a
statistical symmetry ratio filtering mechanism coupled with a two-stage LLM
analysis strategy to enable full-stack phenomenon summarization across
node-service-pod hierarchies. The multimodal root cause analysis module
leverages carefully designed cross-modal prompts to deeply integrate multimodal
anomaly information, fully exploiting the cross-modal understanding and logical
reasoning capabilities of large language models to generate structured analysis
results encompassing fault components, root cause descriptions, and reasoning
trace. Comprehensive ablation studies validate the complementary value of each
modal data and the effectiveness of the system architecture. The proposed
solution demonstrates superior performance in complex microservice fault
scenarios, achieving a final score of 50.71. The code has been released at:
https://github.com/tangpan360/MicroRCA-Agent.

</details>


### [282] [CCrepairBench: A High-Fidelity Benchmark and Reinforcement Learning Framework for C++ Compilation Repair](https://arxiv.org/abs/2509.15690)
*Weixuan Sun,Jucai Zhai,Dengfeng Liu,Xin Zhang,Xiaojun Wu,Qiaobo Hao,AIMgroup,Yang Fang,Jiuyang Tang*

Main category: cs.AI

TL;DR: 本文提出了CCRepair数据集和一种基于强化学习的自动修复C++编译错误的方法，通过混合奖励信号和LLM-as-a-Judge评估系统，提高了修复补丁的语义正确性，并验证了其在模型训练效率上的有效性。


<details>
  <summary>Details</summary>
Motivation: 自动修复C++编译错误至关重要，但现有方法受限于数据稀疏和难以生成语义正确的补丁。

Method: 构建了大规模C++编译错误数据集CCRepair；提出了一种基于混合奖励信号（关注语义质量而非仅可编译性）的强化学习（RL）修复范式；并建立了一个通过LLM-as-a-Judge（经验证可靠性）进行评估的系统。

Result: RL训练的Qwen2.5-1.5B-Instruct模型取得了与Qwen2.5-14B-Instruct模型相当的性能，证明了训练范式的效率。

Conclusion: 该研究为社区提供了新的数据集和更有效的范式，以训练和评估鲁棒的编译修复模型，促进了更实用、更可靠的自动编程助手的发展。

Abstract: The automated repair of C++ compilation errors presents a significant
challenge, the resolution of which is critical for developer productivity.
Progress in this domain is constrained by two primary factors: the scarcity of
large-scale, high-fidelity datasets and the limitations of conventional
supervised methods, which often fail to generate semantically correct
patches.This paper addresses these gaps by introducing a comprehensive
framework with three core contributions. First, we present CCrepair, a novel,
large-scale C++ compilation error dataset constructed through a sophisticated
generate-and-verify pipeline. Second, we propose a Reinforcement Learning (RL)
paradigm guided by a hybrid reward signal, shifting the focus from mere
compilability to the semantic quality of the fix. Finally, we establish the
robust, two-stage evaluation system providing this signal, centered on an
LLM-as-a-Judge whose reliability has been rigorously validated against the
collective judgments of a panel of human experts. This integrated approach
aligns the training objective with generating high-quality, non-trivial patches
that are both syntactically and semantically correct. The effectiveness of our
approach was demonstrated experimentally. Our RL-trained Qwen2.5-1.5B-Instruct
model achieved performance comparable to a Qwen2.5-14B-Instruct model,
validating the efficiency of our training paradigm. Our work provides the
research community with a valuable new dataset and a more effective paradigm
for training and evaluating robust compilation repair models, paving the way
for more practical and reliable automated programming assistants.

</details>


### [283] [A Nascent Taxonomy of Machine Learning in Intelligent Robotic Process Automation](https://arxiv.org/abs/2509.15730)
*Lukas Laakmann,Seyyid A. Ciftci,Christian Janiesch*

Main category: cs.AI

TL;DR: RPA结合机器学习可实现更复杂的任务自动化。


<details>
  <summary>Details</summary>
Motivation: RPA在自动化规则化、结构化任务方面有优势，但其象征性在处理复杂任务时存在局限。将机器学习概念融入RPA（即智能RPA）可以拓宽可自动化任务的范围。

Method: 进行文献综述，探讨RPA与机器学习的联系，并构建智能RPA的分类体系。

Result: 提出一个包含RPA-ML集成和RPA-ML交互两个元特征的分类体系，该体系进一步细分为架构与生态、能力、数据基础、智能水平、集成技术深度、部署环境、生命周期阶段和用户-机器人关系八个维度。

Conclusion: 智能RPA通过结合RPA和机器学习，克服了传统RPA在处理复杂任务时的局限性，并提出了一个系统的分类框架来理解和组织这一领域的研究。

Abstract: Robotic process automation (RPA) is a lightweight approach to automating
business processes using software robots that emulate user actions at the
graphical user interface level. While RPA has gained popularity for its
cost-effective and timely automation of rule-based, well-structured tasks, its
symbolic nature has inherent limitations when approaching more complex tasks
currently performed by human agents. Machine learning concepts enabling
intelligent RPA provide an opportunity to broaden the range of automatable
tasks. In this paper, we conduct a literature review to explore the connections
between RPA and machine learning and organize the joint concept intelligent RPA
into a taxonomy. Our taxonomy comprises the two meta-characteristics RPA-ML
integration and RPA-ML interaction. Together, they comprise eight dimensions:
architecture and ecosystem, capabilities, data basis, intelligence level, and
technical depth of integration as well as deployment environment, lifecycle
phase, and user-robot relation.

</details>


### [284] [Ontology Creation and Management Tools: the Case of Anatomical Connectivity](https://arxiv.org/abs/2509.15780)
*Natallia Kokash,Bernard de Bono,Tom Gillespie*

Main category: cs.AI

TL;DR: 该研究介绍了ApiNATOMY框架，一个用于构建多尺度生理回路图的知识表示和管理工具集，旨在支持神经系统等生理系统数据的绘制。


<details>
  <summary>Details</summary>
Motivation: 开发支持外周神经系统等生理系统数据绘制的基础设施，特别是关注其与所研究器官的相关性。

Method: 创建了一个名为ApiNATOMY的框架，该框架包含一个知识表示（KR）模型和一系列知识管理（KM）工具，用于拓扑和语义化地表示多尺度生理回路图。KR模型允许生理学专家捕捉解剖实体间的相互作用，KM工具则帮助建模者将高层抽象转化为详细的生理过程模型，并能与外部本体和知识图谱集成。

Result: ApiNATOMY框架能够让生理学专家轻松捕捉解剖实体间的相互作用，并帮助建模者将高层抽象转化为详细的生理过程模型，支持与外部知识库的集成。

Conclusion: ApiNATOMY提供了一个集成知识表示和管理工具的解决方案，以支持和促进生理学研究中复杂系统的建模和数据绘制。

Abstract: We are developing infrastructure to support researchers in mapping data
related to the peripheral nervous system and other physiological systems, with
an emphasis on their relevance to the organs under investigation. The nervous
system, a complex network of nerves and ganglia, plays a critical role in
coordinating and transmitting signals throughout the body. To aid in this, we
have created ApiNATOMY, a framework for the topological and semantic
representation of multiscale physiological circuit maps. ApiNATOMY integrates a
Knowledge Representation (KR) model and a suite of Knowledge Management (KM)
tools. The KR model enables physiology experts to easily capture interactions
between anatomical entities, while the KM tools help modelers convert
high-level abstractions into detailed models of physiological processes, which
can be integrated with external ontologies and knowledge graphs.

</details>


### [285] [Building Data-Driven Occupation Taxonomies: A Bottom-Up Multi-Stage Approach via Semantic Clustering and Multi-Agent Collaboration](https://arxiv.org/abs/2509.15786)
*Nan Li,Bo Kang,Tijl De Bie*

Main category: cs.AI

TL;DR: CLIMB是一个全自动框架，用于从原始招聘信息创建高质量、数据驱动的职业分类法，优于现有方法并能捕捉区域特征。


<details>
  <summary>Details</summary>
Motivation: 手动创建职业分类法耗时，而现有的自动化方法要么无法适应动态的区域市场（自顶向下），要么难以从嘈杂的数据中构建连贯的层次结构（自底向上）。

Method: CLIMB框架使用全局语义聚类来提炼核心职业，然后采用基于反射的多代理系统来迭代地构建连贯的层次结构。

Result: 在三个不同的真实世界数据集上，CLIMB生成的分类法比现有方法更连贯、更具可扩展性，并成功捕捉了独特的区域特征。

Conclusion: CLIMB框架能够自动创建高质量、数据驱动的职业分类法，并且优于现有方法，能够捕捉区域市场的独特性。

Abstract: Creating robust occupation taxonomies, vital for applications ranging from
job recommendation to labor market intelligence, is challenging. Manual
curation is slow, while existing automated methods are either not adaptive to
dynamic regional markets (top-down) or struggle to build coherent hierarchies
from noisy data (bottom-up). We introduce CLIMB (CLusterIng-based Multi-agent
taxonomy Builder), a framework that fully automates the creation of
high-quality, data-driven taxonomies from raw job postings. CLIMB uses global
semantic clustering to distill core occupations, then employs a
reflection-based multi-agent system to iteratively build a coherent hierarchy.
On three diverse, real-world datasets, we show that CLIMB produces taxonomies
that are more coherent and scalable than existing methods and successfully
capture unique regional characteristics. We release our code and datasets at
https://anonymous.4open.science/r/CLIMB.

</details>


### [286] [A Comparative Study of Rule-Based and Data-Driven Approaches in Industrial Monitoring](https://arxiv.org/abs/2509.15848)
*Giovanni De Gasperis,Sante Dino Facchini*

Main category: cs.AI

TL;DR: 工业监控正从传统规则转向数据驱动，本文比较两者优劣并提出混合方案，认为未来是结合专家知识和数据洞察的智能协同系统。


<details>
  <summary>Details</summary>
Motivation: 随着工业4.0的发展，工业监控系统正从传统的基于规则的架构转向利用机器学习和人工智能的数据驱动方法，因此有必要比较这两种方法。

Method: 对基于规则的系统和数据驱动的系统进行了比较分析，研究了各自的优点、局限性和应用场景，并提出了一个评估其关键属性的基本框架。

Result: 基于规则的系统具有高可解释性、确定性行为和易于实施的优点，但难以扩展和适应。数据驱动的系统在检测异常和预测性维护方面表现出色，但存在数据可用性、可解释性和集成复杂性的挑战。

Conclusion: 混合解决方案结合了两种方法的优点，是未来工业监控的一个有前景的方向，可以提高系统的弹性、运行效率和可信度。

Abstract: Industrial monitoring systems, especially when deployed in Industry 4.0
environments, are experiencing a shift in paradigm from traditional rule-based
architectures to data-driven approaches leveraging machine learning and
artificial intelligence. This study presents a comparison between these two
methodologies, analyzing their respective strengths, limitations, and
application scenarios, and proposes a basic framework to evaluate their key
properties. Rule-based systems offer high interpretability, deterministic
behavior, and ease of implementation in stable environments, making them ideal
for regulated industries and safety-critical applications. However, they face
challenges with scalability, adaptability, and performance in complex or
evolving contexts. Conversely, data-driven systems excel in detecting hidden
anomalies, enabling predictive maintenance and dynamic adaptation to new
conditions. Despite their high accuracy, these models face challenges related
to data availability, explainability, and integration complexity. The paper
suggests hybrid solutions as a possible promising direction, combining the
transparency of rule-based logic with the analytical power of machine learning.
Our hypothesis is that the future of industrial monitoring lies in intelligent,
synergic systems that leverage both expert knowledge and data-driven insights.
This dual approach enhances resilience, operational efficiency, and trust,
paving the way for smarter and more flexible industrial environments.

</details>


### [287] [EHR-MCP: Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol](https://arxiv.org/abs/2509.15957)
*Kanato Masayoshi,Masahiro Hashimoto,Ryoichi Yokoyama,Naoki Toda,Yoshifumi Uwamino,Shogo Fukuda,Ho Namkoong,Masahiro Jinzaki*

Main category: cs.AI

TL;DR: LLM可以通过MCP工具从医院的EHR数据库中检索临床信息，在简单任务上准确率接近完美，但在复杂任务上存在挑战。


<details>
  <summary>Details</summary>
Motivation: 评估通过MCP连接到EHR的LLM在真实医院环境中自主检索临床相关信息的能力。

Method: 开发了集成了医院EHR数据库的EHR-MCP框架，并使用GPT-4.1通过LangGraph ReAct代理进行交互，测试了6项感染控制团队（ICT）的任务，并回顾性分析了8名患者的数据。

Result: LLM能够一致地选择和执行正确的MCP工具，除两个任务外，准确率接近完美；复杂任务的性能较低，错误主要源于参数不正确或对工具结果的误解；EHR-MCP的响应是可靠的，但长度和重复性数据可能超出上下文窗口。

Conclusion: LLM可以通过MCP工具从EHR中检索临床数据，在简单任务上表现接近完美，但复杂任务存在挑战。EHR-MCP为安全、一致的数据访问提供了基础设施，并可能为医院AI代理奠定基础。未来的工作应超越检索，关注推理、生成和临床影响评估。

Abstract: Background: Large language models (LLMs) show promise in medicine, but their
deployment in hospitals is limited by restricted access to electronic health
record (EHR) systems. The Model Context Protocol (MCP) enables integration
between LLMs and external tools.
  Objective: To evaluate whether an LLM connected to an EHR database via MCP
can autonomously retrieve clinically relevant information in a real hospital
setting.
  Methods: We developed EHR-MCP, a framework of custom MCP tools integrated
with the hospital EHR database, and used GPT-4.1 through a LangGraph ReAct
agent to interact with it. Six tasks were tested, derived from use cases of the
infection control team (ICT). Eight patients discussed at ICT conferences were
retrospectively analyzed. Agreement with physician-generated gold standards was
measured.
  Results: The LLM consistently selected and executed the correct MCP tools.
Except for two tasks, all tasks achieved near-perfect accuracy. Performance was
lower in the complex task requiring time-dependent calculations. Most errors
arose from incorrect arguments or misinterpretation of tool results. Responses
from EHR-MCP were reliable, though long and repetitive data risked exceeding
the context window.
  Conclusions: LLMs can retrieve clinical data from an EHR via MCP tools in a
real hospital setting, achieving near-perfect performance in simple tasks while
highlighting challenges in complex ones. EHR-MCP provides an infrastructure for
secure, consistent data access and may serve as a foundation for hospital AI
agents. Future work should extend beyond retrieval to reasoning, generation,
and clinical impact assessment, paving the way for effective integration of
generative AI into clinical practice.

</details>


### [288] [Structured Information for Improving Spatial Relationships in Text-to-Image Generation](https://arxiv.org/abs/2509.15962)
*Sander Schildermans,Chang Tian,Ying Jiao,Marie-Francine Moens*

Main category: cs.AI

TL;DR: 该研究提出了一种通过在提示中添加基于元组的结构化信息来增强文本到图像生成中空间关系的方法。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成模型在忠实捕捉自然语言提示中的空间关系方面仍面临挑战。

Method: 该方法使用经过微调的语言模型，自动将提示转换为基于元组的结构化信息，并将其集成到文本到图像生成流程中。

Result: 实验证明，该方法在空间准确性方面取得了显著的改进，并且不影响基于Inception Score衡量的整体图像质量。自动生成的元组的质量与人工制作的元组相当。

Conclusion: 该方法为文本到图像生成提供了一种实用且可移植的解决方案，以增强空间关系，解决了当前大规模生成系统的一个关键限制。

Abstract: Text-to-image (T2I) generation has advanced rapidly, yet faithfully capturing
spatial relationships described in natural language prompts remains a major
challenge. Prior efforts have addressed this issue through prompt optimization,
spatially grounded generation, and semantic refinement. This work introduces a
lightweight approach that augments prompts with tuple-based structured
information, using a fine-tuned language model for automatic conversion and
seamless integration into T2I pipelines. Experimental results demonstrate
substantial improvements in spatial accuracy, without compromising overall
image quality as measured by Inception Score. Furthermore, the automatically
generated tuples exhibit quality comparable to human-crafted tuples. This
structured information provides a practical and portable solution to enhance
spatial relationships in T2I generation, addressing a key limitation of current
large-scale generative systems.

</details>


### [289] [Attention Schema-based Attention Control (ASAC): A Cognitive-Inspired Approach for Attention Management in Transformers](https://arxiv.org/abs/2509.16058)
*Krati Saxena,Federico Jurado Ruiz,Guido Manzi,Dianbo Liu,Alex Lamb*

Main category: cs.AI

TL;DR: ASAC通过整合认知科学中的注意力模式理论，利用VQVAE作为注意力抽象器和控制器，在Transformer中实现注意力模式，从而提高AI系统（尤其是计算机视觉和NLP）的效率、准确性、学习速度、鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 受到认知科学中注意力模式理论（AST）的启发，该理论认为人类通过建立对注意力的模型来管理注意力，并将其应用于AI领域，以期提高AI系统的效率和性能。

Method: 将ASAC模块集成到Transformer架构中，该模块使用VQVAE作为注意力抽象器和控制器，显式地对注意力分配进行建模。

Result: ASAC模块在计算机视觉和NLP领域均表现出有效性，提高了分类准确性，并加速了学习过程。在视觉Transformer的实验中，ASAC提高了分类准确性并加速了学习。此外，ASAC在多任务学习、对抗性攻击的鲁棒性、迁移学习和少样本学习方面也表现出优势。

Conclusion: ASAC的成功实验证明了认知科学与机器学习之间的联系，并为在AI系统中有效利用注意力机制提供了新的见解。

Abstract: Attention mechanisms have become integral in AI, significantly enhancing
model performance and scalability by drawing inspiration from human cognition.
Concurrently, the Attention Schema Theory (AST) in cognitive science posits
that individuals manage their attention by creating a model of the attention
itself, effectively allocating cognitive resources. Inspired by AST, we
introduce ASAC (Attention Schema-based Attention Control), which integrates the
attention schema concept into artificial neural networks. Our initial
experiments focused on embedding the ASAC module within transformer
architectures. This module employs a Vector-Quantized Variational AutoEncoder
(VQVAE) as both an attention abstractor and controller, facilitating precise
attention management. By explicitly modeling attention allocation, our approach
aims to enhance system efficiency. We demonstrate ASAC's effectiveness in both
the vision and NLP domains, highlighting its ability to improve classification
accuracy and expedite the learning process. Our experiments with vision
transformers across various datasets illustrate that the attention controller
not only boosts classification accuracy but also accelerates learning.
Furthermore, we have demonstrated the model's robustness and generalization
capabilities across noisy and out-of-distribution datasets. In addition, we
have showcased improved performance in multi-task settings. Quick experiments
reveal that the attention schema-based module enhances resilience to
adversarial attacks, optimizes attention to improve learning efficiency, and
facilitates effective transfer learning and learning from fewer examples. These
promising results establish a connection between cognitive science and machine
learning, shedding light on the efficient utilization of attention mechanisms
in AI systems.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [290] [Classical and Quantum Heuristics for the Binary Paint Shop Problem](https://arxiv.org/abs/2509.15294)
*V Vijendran,Dax Enshan Koh,Ping Koy Lam,Syed M Assad*

Main category: quant-ph

TL;DR: 该研究通过将二元油漆车间问题 (BPSP) 归约为加权 MaxCut 问题，并在此框架下对两种先进的低深度 QAOA 变体（XQAOA 和 RQAOA）在 p=1 的情况下进行基准测试，以评估它们在 BPSP 上的性能。实验结果表明，XQAOA 在 2^7 到 2^12 辆车的实例中表现优于 RQAOA 和所有已知的经典启发式算法，平均比率为 0.357，并且在扩展时表现稳健。然而，RQAOA 在实例规模增大时性能下降，并且在较大的实例中表现不如 RSG 启发式算法。


<details>
  <summary>Details</summary>
Motivation: 在汽车制造中，二元油漆车间问题 (BPSP) 是一种 APX-hard 优化问题。该研究的动机在于开发理论基础以应用 QAOA 解决 BPSP，并使用先进的 QAOA 变体（XQAOA 和 RQAOA）来优化生产效率和降低成本，通过最小化油漆喷涂过程中的颜色交换次数。

Method: 该研究首先将 BPSP 归约为加权 MaxCut 问题。然后，使用此框架对两种先进的低深度 QAOA 变体（eXpressive QAOA (XQAOA) 和 Recursive QAOA (RQAOA)）在 p=1 的情况下进行基准测试。实验在从 2^7 到 2^12 辆车的各种实例上进行，并将 XQAOA 和 RQAOA 的性能与最强的经典启发式算法（包括 Recursive Star Greedy (RSG)）进行了比较。

Result: 在 2^7 到 2^12 辆车的实例中，XQAOA 在 p=1 时（XQAOA_1）取得了 0.357 的平均比率，优于 RQAOA_1 和所有经典启发式算法，包括 RSG 的预期性能。然而，RQAOA_1 的性能随着实例规模的增加而下降，在大多数 2^11 辆车的实例和所有 2^12 辆车的实例中均落后于 RSG。

Conclusion: XQAOA_1 在 BPSP 中表现出优越的性能和良好的扩展性，有望超越所有已知的启发式算法。相比之下，RQAOA_1 在大规模实例上表现出性能下降，这表明在实际应用中需要谨慎选择 QAOA 变体和参数。这项工作首次报告了 RQAOA_1 在规模上的性能退化。

Abstract: The Binary Paint Shop Problem (BPSP) is an $\mathsf{APX}$-hard optimisation
problem in automotive manufacturing: given a sequence of $2n$ cars, comprising
$n$ distinct models each appearing twice, the task is to decide which of two
colours to paint each car so that the two occurrences of each model are painted
differently, while minimising consecutive colour swaps. The key performance
metric is the paint swap ratio, the average number of colour changes per car,
which directly impacts production efficiency and cost. Prior work showed that
the Quantum Approximate Optimisation Algorithm (QAOA) at depth $p=7$ achieves a
paint swap ratio of $0.393$, outperforming the classical Recursive Greedy (RG)
heuristic with an expected ratio of $0.4$ [Phys. Rev. A 104, 012403 (2021)].
More recently, the classical Recursive Star Greedy (RSG) heuristic was
conjectured to achieve an expected ratio of $0.361$. In this study, we develop
the theoretical foundations for applying QAOA to BPSP through a reduction of
BPSP to weighted MaxCut, and use this framework to benchmark two
state-of-the-art low-depth QAOA variants, eXpressive QAOA (XQAOA) and Recursive
QAOA (RQAOA), at $p=1$ (denoted XQAOA$_1$ and RQAOA$_1$), against the strongest
classical heuristics known to date. Across instances ranging from $2^7$ to
$2^{12}$ cars, XQAOA$_1$ achieves an average ratio of $0.357$, surpassing
RQAOA$_1$ and all classical heuristics, including the conjectured performance
of RSG. Surprisingly, RQAOA$_1$ shows diminishing performance as size
increases: despite using provably optimal QAOA$_1$ parameters at each
recursion, it is outperformed by RSG on most $2^{11}$-car instances and all
$2^{12}$-car instances. To our knowledge, this is the first study to report
RQAOA$_1$'s performance degradation at scale. In contrast, XQAOA$_1$ remains
robust, indicating strong potential to asymptotically surpass all known
heuristics.

</details>


### [291] [CLASS: A Controller-Centric Layout Synthesizer for Dynamic Quantum Circuits](https://arxiv.org/abs/2509.15742)
*Yu Chen,Yilun Zhao,Bing Li,He Li,Mengdi Wang,Yinhe Han,Ying Wang*

Main category: quant-ph

TL;DR: CLASS 是一种控制器中心布局合成器，可减少分布式控制系统中的通信延迟，它通过超图建模和启发式图划分算法实现，在减少通信延迟方面效果显著，同时仅有少量额外操作的增加。


<details>
  <summary>Details</summary>
Motivation: 传统量子计算布局综合方法侧重于优化电路深度，但忽略了经典处理和通信时间对动态量子电路的影响。因此，需要一种新的方法来解决分布式控制系统中的通信延迟问题。

Method: CLASS 采用两阶段框架：首先，通过超图模型来表示问题；然后，利用启发式图划分算法来优化布局，以减少控制器间的通信延迟。

Result: CLASS 能够将通信延迟最多降低 100%，同时平均额外操作数量仅增加 2.10%。

Conclusion: CLASS 是一种有效的控制器中心布局合成器，能够显著降低分布式控制系统中的通信延迟，为动态量子电路的设计提供了新的解决方案。

Abstract: Layout Synthesis for Quantum Computing (LSQC) is a critical component of
quantum design tools. Traditional LSQC studies primarily focus on optimizing
for reduced circuit depth by adopting a device-centric design methodology.
However, these approaches overlook the impact of classical processing and
communication time, thereby being insufficient for Dynamic Quantum Circuits
(DQC).
  To address this, we introduce CLASS, a controller-centric layout synthesizer
designed to reduce inter-controller communication latency in a distributed
control system. It consists of a two-stage framework featuring a
hypergraph-based modeling and a heuristic-based graph partitioning algorithm.
Evaluations demonstrate that CLASS effectively reduces communication latency by
up to 100% with only a 2.10% average increase in the number of additional
operations.

</details>


### [292] [Triplet Loss Based Quantum Encoding for Class Separability](https://arxiv.org/abs/2509.15705)
*Marco Mordacci,Mahul Pandey,Paolo Santini,Michele Amoretti*

Main category: quant-ph

TL;DR: 提出了一种高效的数据驱动编码方案，用于提升变分量子分类器的性能，特别是针对图像等复杂数据集。该方案通过生成在希尔伯特空间中根据分类标签形成良好分离簇的输入状态来辅助分类任务。使用受经典人脸识别算法启发的三角损失函数来训练编码电路，并通过编码密度矩阵之间的平均迹距离来衡量类可分离性。在MNIST和MedMNIST数据集上的二元分类任务基准测试表明，与相同VQC结构的幅度编码相比，该方案在电路深度要求低得多的情况下，性能有了显著提升。


<details>
  <summary>Details</summary>
Motivation: 为了提高变分量子分类器在处理复杂数据集（如图像）时的性能，需要设计一种能够生成在希尔伯特空间中根据标签形成良好分离簇的输入状态的编码方案。

Method: 设计了一种数据驱动的编码方案，并使用受经典人脸识别算法启发的三角损失函数来训练编码电路。通过计算编码密度矩阵之间的平均迹距离来评估类可分离性。

Result: 在MNIST和MedMNIST数据集的二元分类任务上，所提出的编码方案相比于幅度编码，在相同的VQC结构下，显著提高了分类性能，并且所需的电路深度更低。

Conclusion: 所提出的高效、数据驱动的编码方案能够有效提升变分量子分类器处理复杂数据集的性能，通过优化希尔伯特空间中的类可分离性，并以更低的电路深度实现了优于幅度编码的效果。

Abstract: An efficient and data-driven encoding scheme is proposed to enhance the
performance of variational quantum classifiers. This encoding is specially
designed for complex datasets like images and seeks to help the classification
task by producing input states that form well-separated clusters in the Hilbert
space according to their classification labels. The encoding circuit is trained
using a triplet loss function inspired by classical facial recognition
algorithms, and class separability is measured via average trace distances
between the encoded density matrices. Benchmark tests performed on various
binary classification tasks on MNIST and MedMNIST datasets demonstrate
considerable improvement over amplitude encoding with the same VQC structure
while requiring a much lower circuit depth.

</details>


### [293] [Impact of Single Rotations and Entanglement Topologies in Quantum Neural Networks](https://arxiv.org/abs/2509.15722)
*Marco Mordacci,Michele Amoretti*

Main category: quant-ph

TL;DR: 该研究分析了不同变分量子电路（VQC）在量子机器学习任务中的性能，重点关注其如何随纠缠拓扑、门类型和任务的变化而变化，以确定构建量子神经网络（QNN）的理想方法。


<details>
  <summary>Details</summary>
Motivation: 本研究的目的是确定构建量子神经网络（QNN）的理想方法，通过分析不同变分量子电路（VQC）的性能，并研究其如何随纠缠拓扑、所选门和量子机器学习任务的变化而变化。

Method: 研究中使用了两种类型的电路：一种包含交替的旋转层和纠缠层，另一种在第一种的基础上增加了一个最终的旋转层。旋转层考虑了单旋转和双旋转序列的所有组合。比较了线性、圆形、成对和全连接四种不同的纠缠拓扑。实验任务包括概率分布生成、图像生成和图像分类。

Result: 实验结果表明，电路的表达能力和纠缠能力与其性能相关，研究人员将实现的性能与这些特性联系起来，以了解它们对结果的影响。

Conclusion: 不同变分量子电路在量子机器学习任务中的性能受到纠缠拓扑、门类型和具体任务的影响，理解电路的表达能力和纠缠能力对于优化QNN的设计至关重要。

Abstract: In this work, an analysis of the performance of different Variational Quantum
Circuits is presented, investigating how it changes with respect to
entanglement topology, adopted gates, and Quantum Machine Learning tasks to be
performed. The objective of the analysis is to identify the optimal way to
construct circuits for Quantum Neural Networks. In the presented experiments,
two types of circuits are used: one with alternating layers of rotations and
entanglement, and the other, similar to the first one, but with an additional
final layer of rotations. As rotation layers, all combinations of one and two
rotation sequences are considered. Four different entanglement topologies are
compared: linear, circular, pairwise, and full. Different tasks are considered,
namely the generation of probability distributions and images, and image
classification. Achieved results are correlated with the expressibility and
entanglement capability of the different circuits to understand how these
features affect performance.

</details>


### [294] [Photon Blockade Mediated by Two-Photon Absorption in an Optical Parametric Amplifier](https://arxiv.org/abs/2509.15696)
*Weiyi An,Jie Zhu*

Main category: quant-ph

TL;DR: 本研究将非传统光子阻碍 (UPB) 与环境诱导光子阻 rzecz (EPB) 相结合，并通过考虑光学参量放大器 (OPA) 中的双光子吸收 (TPA) 效应，实现了更稳定的光子阻碍，并能更有效地抑制多光子态。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索结合非传统光子阻碍 (UPB) 和环境诱导光子阻碍 (EPB) 的新方法，以实现更稳定且抑制多光子能力更强的光子阻碍。

Method: 本研究提出将非传统光子阻碍 (UPB) 的量子干涉机制与环境诱导光子阻碍 (EPB) 的双光子吸收 (TPA) 机制相结合，并将其应用于光学参量放大器 (OPA) 中。

Result: 通过将 UPB 和 EPB 结合并考虑 OPA 中的 TPA 效应，本研究成功实现了更稳定的光子阻碍，并显著增强了对多光子态的抑制。

Conclusion: 本研究成功地将 UPB 和 EPB 结合在 OPA 中，利用 TPA 效应实现了更稳定、抑制多光子态能力更强的光子阻碍，为单光子源的制备提供了新的途径。

Abstract: Photon blockade (PB) is a quantum effect in strongly nonlinear systems where
a single photon prevents the system from being excited to a higher level,
generating anti-bunched light fields. It enables the generation of
single-photon sources for quantum information processing. Conventional photon
blockade (CPB) leverages strong nonlinear interactions to generate an
anharmonic energy spectrum. Unconventional photon blockade (UPB) utilizes
destructive quantum interference between excitation pathways. Recently,
environmentally induced photon blockade (EPB) has emerged as a novel approach,
exploiting two-photon absorption (TPA) to realize photon blockade. In this
work, we combine UPB and EPB together, considering the TPA effect in the
optical parametric amplifier (OPA), thereby achieving a more stable PB with
stronger suppression of multi-photon states.

</details>


### [295] [Training Variational Quantum Circuits Using Particle Swarm Optimization](https://arxiv.org/abs/2509.15726)
*Marco Mordacci,Michele Amoretti*

Main category: quant-ph

TL;DR: 粒子群优化（PSO）被用于训练变分量子电路（VQC），以解决梯度下降方法中常见的“贫瘠高原”问题。PSO在MedMNIST数据集上进行了测试，与梯度下降方法相比，在分类准确性上取得了相当或更好的结果，并且使用的量子门数量更少。


<details>
  <summary>Details</summary>
Motivation: 梯度下降优化方法在训练变分量子电路（VQC）时可能面临“贫瘠高原”问题，因此需要探索替代的优化方法。

Method: 使用粒子群优化（PSO）算法来训练变分量子电路（VQC）。PSO算法能够自动选择量子门（Rx, Ry, Rz, CNOT）、目标量子比特和旋转角度。该方法在MedMNIST数据集上进行了测试，并与使用经典随机梯度下降的预定义VQC进行了比较。

Result: 在MedMNIST数据集的多个分类任务上，PSO优化VQC的方法取得了与梯度下降相当或更好的分类准确性。值得注意的是，PSO方法使用的量子门数量少于梯度下降方法。

Conclusion: 粒子群优化（PSO）是一种有效的训练变分量子电路（VQC）的方法，可以克服梯度下降方法中“贫瘠高原”的问题，并在图像分类任务中取得有竞争力的结果，同时所需的量子资源更少。

Abstract: In this work, the Particle Swarm Optimization (PSO) algorithm has been used
to train various Variational Quantum Circuits (VQCs). This approach is
motivated by the fact that commonly used gradient-based optimization methods
can suffer from the barren plateaus problem. PSO is a stochastic optimization
technique inspired by the collective behavior of a swarm of birds. The
dimension of the swarm, the number of iterations of the algorithm, and the
number of trainable parameters can be set. In this study, PSO has been used to
train the entire structure of VQCs, allowing it to select which quantum gates
to apply, the target qubits, and the rotation angle, in case a rotation is
chosen. The algorithm is restricted to choosing from four types of gates: Rx,
Ry, Rz, and CNOT. The proposed optimization approach has been tested on various
datasets of the MedMNIST, which is a collection of biomedical image datasets
designed for image classification tasks. Performance has been compared with the
results achieved by classical stochastic gradient descent applied to a
predefined VQC. The results show that the PSO can achieve comparable or even
better classification accuracy across multiple datasets, despite the PSO using
a lower number of quantum gates than the VQC used with gradient descent
optimization.

</details>


### [296] [Simultaneous Speedmeter and Position-Meter Response in a Single Tabletop Interferometer](https://arxiv.org/abs/2509.15285)
*Mikhail Korobko,Xiang Li,Torben Sobottke,Yiqiu Ma,Yanbei Chen,Roman Schnabel*

Main category: quant-ph

TL;DR: 这项工作首次在具有可移动测试质量的系统中实验性地观察到测速仪行为，这是一种通过测量测试质量速度而不是位置来避免量子辐射压力噪声的新型干涉仪概念。


<details>
  <summary>Details</summary>
Motivation: 量子辐射压力噪声（QRPN）限制了引力波探测器的低频灵敏度，而现有的抑制方法（如注入频率相关压缩光）会增加实验复杂性。

Method: 提出并实现了一种新颖的混合读出腔配置，允许同时从两个不同的输出端口提取位置和速度信号，并与理论模型进行比较。

Result: 实验观察到测速仪行为，并观察到区分测速仪和测位仪的预期标度行为。理论模型支持了这些观察结果，并展示了混合读出腔如何实现关键的测速仪特性。

Conclusion: 测速仪概念是减轻未来探测器中 QRPN 的可行替代方案，为进一步的实验探索奠定了基础。

Abstract: Quantum radiation-pressure noise (QRPN) limits the low-frequency sensitivity
of gravitational wave detectors. The established method for suppressing QRPN is
the injection of frequency-dependent squeezed light. It requires long-baseline
filter cavities introducing substantial experimental complexity. A completely
different interferometer concept is the speedmeter. It avoids QRPN at the
source by measuring test mass speed instead of position. While extensively
researched theoretically, speedmeters are yet to be demonstrated with a moving
test mass in an optomechanical setting. In this work, we present the first
experimental observation of speedmeter behavior in a system with a movable test
mass. We realize a novel hybrid readout cavity configuration that enables
simultaneous extraction of position and speed signals from two distinct output
ports. We compare the optical transfer functions associated with each channel
and observe the expected scaling behavior that distinguishes a speedmeter from
a position-meter. We support our observations with a detailed theoretical
model, showing how the hybrid readout cavity implements key speedmeter
features. Our results underscore the relevance of the speedmeter concept as an
alternative for mitigating QRPN in future detectors and lay the groundwork for
further experimental exploration.

</details>


### [297] [Integrated high-fidelity preparation and analysis of photonic two-qubit states for quantum network nodes](https://arxiv.org/abs/2509.15312)
*Jonas C. J. Zatsch,Tim Engling,Jeldrik Huster,Louis L. Hohmann,Shreya Kumar,Stefanie Barz*

Main category: quant-ph

TL;DR: A silicon-on-insulator integrated photonic chip is presented for bidirectional quantum network nodes, demonstrating high fidelities for state preparation and entanglement distribution.


<details>
  <summary>Details</summary>
Motivation: Quantum networks require local quantum processing and efficient quantum transmission. Integrated photonics on silicon-on-insulator is a promising platform due to its compatibility with existing fiber networks.

Method: Developed a silicon-on-insulator integrated photonic chip capable of bidirectional operation for preparing single- and two-qubit states and performing full quantum state tomography. Demonstrated entanglement distribution between network nodes.

Result: Achieved preparation fidelities above 97% for on-chip prepared Bell states coupled into optical fibers. Demonstrated entanglement distribution between network nodes with a fidelity of 90.0(16)%.

Conclusion: The bidirectional photonic circuit serves as a versatile node for telecom quantum networks, capable of both sending and receiving quantum information, which is crucial for deploying multipurpose quantum networks.

Abstract: The realisation of quantum networks requires local quantum information
processing at the network nodes and highly efficient transmission of quantum
information across the network. Integrated photonics, based on
silicon-on-insulator, is a promising platform for quantum network nodes, as it
supports low-loss propagation of telecom wavelength photons, making it
compatible with existing optical fibre networks. Here, we present a
silicon-on-insulator integrated photonic chip, capable of bidirectional
operation, enabling the preparation of arbitrary single- and two-qubit states,
and performing full quantum state tomography on up to two qubits. Using our
chip, we obtain preparation fidelities above 97% for on-chip prepared Bell
states coupled into optical fibres. Furthermore, we demonstrate that we can
distribute entanglement between network nodes by preparing a two-qubit cluster
state on the first node and performing full quantum state tomography on the
second node, achieving a fidelity of 90.0(16)%. This result proves that our
approach allows the distribution of entanglement from one chip to another. The
potential of bidirectional operation makes our circuit a versatile node in
telecom quantum networks, both functioning as a sender and receiver unit, a key
element for the deployment of fully photonic multi-purpose quantum networks.

</details>


### [298] [Unentanglement and Post-Measurement Branching in Quantum Interactive Proofs](https://arxiv.org/abs/2509.15319)
*Sabee Grewal,William Kretschmer*

Main category: quant-ph

TL;DR: 这项研究探讨了量子交互式证明中的“解纠缠”和“后测量分支”这两个方面，并揭示了它们对计算能力的显著影响。


<details>
  <summary>Details</summary>
Motivation: 研究量子交互式证明中“解纠缠”和“后测量分支”这两个方面的影响。

Method: 分析了在不同条件下（例如，部分消息为量子、无后测量分支）的量子交互式证明系统的计算能力，并与经典证明系统进行对比。

Result: 研究表明，即使只有第一条消息是量子的，三轮无纠缠量子交互式证明也能达到 NEXP 的计算能力。但如果验证者不使用后测量分支，则同一类证明系统的能力被限制在 QAM。此外，研究还发现后测量分支在两轮量子-经典证明系统中可能导致能力分离，这与经典证明系统中的情况不同。

Conclusion: “解纠缠”和“后测量分支”是影响量子交互式证明能力的重要因素，它们可能导致比经典证明系统更强的计算能力和不同的分离现象。

Abstract: We investigate two resources whose effects on quantum interactive proofs
remain poorly understood: the promise of unentanglement, and the verifier's
ability to condition on an intermediate measurement, which we call
post-measurement branching. We first show that unentanglement can dramatically
increase computational power: three-round unentangled quantum interactive
proofs equal NEXP, even if only the first message is quantum. By contrast, we
prove that if the verifier uses no post-measurement branching, then the same
type of unentangled proof system has at most the power of QAM. Finally, we
investigate post-measurement branching in two-round quantum-classical proof
systems. Unlike the equivalence between public-coin and private-coin classical
interactive proofs, we give evidence of a separation in the quantum setting
that arises from post-measurement branching.

</details>


### [299] [Neural Architecture Search Algorithms for Quantum Autoencoders](https://arxiv.org/abs/2509.15451)
*Ankit Kulshrestha,Xiaoyuan Liu,Hayato Ushijima-Mwesigwa,Ilya Safro*

Main category: quant-ph

TL;DR: We propose two Quantum-NAS algorithms to automate quantum circuit design, inspired by Neural Architecture Search. Our algorithms found efficient autoencoder designs for quantum data compression tasks, outperforming baselines in denoising, classical compression, and pure quantum compression, thus significantly reducing manual effort.


<details>
  <summary>Details</summary>
Motivation: The current manual approach to designing quantum circuits for specific algorithms is not scalable and requires significant effort, especially for future complex algorithms.

Method: We propose two Quantum-NAS algorithms, inspired by Neural Architecture Search, to automate the design of quantum circuits. We use quantum data compression as the driver task.

Result: Our Quantum-NAS algorithms successfully designed efficient autoencoders for quantum data compression tasks, outperforming existing methods in quantum data denoising, classical data compression, and pure quantum data compression.

Conclusion: Quantum NAS algorithms can significantly reduce the manual effort required for designing quantum circuits while delivering high-performance solutions for various tasks.

Abstract: The design of quantum circuits is currently driven by the specific objectives
of the quantum algorithm in question. This approach thus relies on a
significant manual effort by the quantum algorithm designer to design an
appropriate circuit for the task. However this approach cannot scale to more
complex quantum algorithms in the future without exponentially increasing the
circuit design effort and introducing unwanted inductive biases. Motivated by
this observation, we propose to automate the process of cicuit design by
drawing inspiration from Neural Architecture Search (NAS). In this work, we
propose two Quantum-NAS algorithms that aim to find efficient circuits given a
particular quantum task. We choose quantum data compression as our driver
quantum task and demonstrate the performance of our algorithms by finding
efficient autoencoder designs that outperform baselines on three different
tasks - quantum data denoising, classical data compression and pure quantum
data compression. Our results indicate that quantum NAS algorithms can
significantly alleviate the manual effort while delivering performant quantum
circuits for any given task.

</details>


### [300] [Fault-tolerant quantum computing with a high-rate symplectic double code](https://arxiv.org/abs/2509.15457)
*Naoyuki Kanomata,Hayato Goto*

Main category: quant-ph

TL;DR: 提出了一种用于[[30, 6, 5]]双码的容错编码器，解决了现有高码率量子码在容错编码状态制备方法方面的不足。该编码器具有紧凑、高编码率的优点，可实现早期实验验证。通过使用尽可能少​​的辅助量子比特来检测编码过程中的关键错误，该编码器在保持低逻辑错误率的同时，减少了资源开销。还开发了一种任意状态编码器，用于将任意量子态注入码空间，结合基本的容错操作，支持通用量子计算。


<details>
  <summary>Details</summary>
Motivation: 大多数高码率、大距离的量子码缺乏有效的容错编码状态制备方法，限制了容错量子计算的效率。

Method: 提出一种用于[[30, 6, 5]]双码的容错编码器，该编码器能够以较少的辅助量子比特检测关键错误，并开发了一种任意状态编码器。

Result: 仿真结果表明，该编码器是可靠和有效的，并且可以实现高效、可靠的逻辑状态制备。

Conclusion: 即使是对于紧凑且高码率的量子码，也可以实现高效可靠的逻辑状态制备，这为实现适用于近期实验的容错量子计算提供了一条有潜力的途径。

Abstract: High-rate and large-distance quantum codes are expected to make
fault-tolerant quantum computing more efficient, but most of them lack
efficient fault-tolerant encoded-state preparation methods. We propose such a
fault-tolerant encoder for a [[30, 6, 5]] symplectic double code. The advantage
of this code is its compactness, in addition to its high encoding rate,
allowing for early experimental realization. Detecting crucial errors during
encoding with as few auxiliary qubits as possible, our encoder can reduce
resource overheads while keeping low logical error rates, compared to more
naive methods. Numerical simulations with a circuit-level noise model
demonstrate the reliability and effectiveness of the proposed method. We also
develop an arbitrary-state encoder that enables the injection of arbitrary
quantum states into the code space. Combined with basic fault-tolerant
operations, this supports universal quantum computation. We thus demonstrate
that efficient and reliable logical state preparation is achievable even for a
compact and high-rate code, offering a potential step toward efficient
fault-tolerant quantum computing suitable for near-term experiments.

</details>


### [301] [Topology and Spectral Entanglement in Cavity-Mediated Photon Scattering](https://arxiv.org/abs/2509.15465)
*Eric R. Bittner,Andrei Piryatinski*

Main category: quant-ph

TL;DR: We establish a diagrammatic theory for cavity-mediated photon-photon interactions in a topological insulator (SSH model), revealing how spectral entanglement and Kerr nonlinearity arise from the fourth-order vertex, leading to a nonlinear topological phase diagram. We also analyze electronic self-energy from photon exchange and its impact on band renormalization, connecting band geometry to light-matter correlations.


<details>
  <summary>Details</summary>
Motivation: The paper aims to develop a theoretical framework to understand cavity-mediated photon-photon interactions in topological insulators, specifically linking band geometry to light-matter correlations and exploring the emergence of nonlinear phenomena.

Method: The study employs a diagrammatic theory based on the SSH model to investigate photon-photon interactions. It computes the fourth-order vertex to analyze spectral entanglement and Kerr nonlinearity, and calculates the electronic self-energy from vacuum photon exchange.

Result: The analysis yields a nonlinear topological phase diagram governed by the fourth-order vertex. It also identifies symmetry-imposed limits on band renormalization due to vacuum photon exchange.

Conclusion: The research demonstrates a connection between the geometric properties of energy bands in topological insulators and the emergence of light-matter correlations, particularly in the context of cavity-mediated photon interactions.

Abstract: We develop a diagrammatic theory of cavity-mediated photon-photon
interactions in a topological insulator using the SSH model. The fourth-order
vertex $\Gamma^{(4)}(\omega_1,\omega_2)$ governs spectral entanglement and Kerr
nonlinearity, leading to a nonlinear topological phase diagram. We also compute
the electronic self-energy from vacuum photon exchange and identify
symmetry-imposed limits on band renormalization. These results link band
geometry to the emergence of light-matter correlations.

</details>


### [302] [Dispersion Relations in Two- and Three-Dimensional Quantum Systems](https://arxiv.org/abs/2509.15483)
*Valeriia Bilokon,Elvira Bilokon,Illya Lukin,Andrii Sotnikov,Denys Bondar*

Main category: quant-ph

TL;DR: 使用张量网络方法计算强关联量子系统的动量分辨激发谱，首次实现了三维量子晶格模型色散关系的计算。


<details>
  <summary>Details</summary>
Motivation: 在强关联量子系统中，尤其是在二维及以上空间维度，提取动量分辨的激发谱是一个巨大的挑战。

Method: 提出了一种高效的张量网络方法，在无限投影纠缠对态（iPEPS）框架内，通过虚时演化来计算色散关系。

Result: 在横向场伊辛模型上进行了基准测试，该方法成功捕捉了二维和三维晶格在顺磁和铁磁相中的色散关系，并且与解析方法（在适用范围内）高度吻合。

Conclusion: 该方法首次实现了三维量子晶格模型的色散关系计算，为相关研究开辟了新的前沿。该方法效率高，计算资源需求适中，在宽泛的参数范围内精度高，适用于量子模拟、光子材料设计和量子信息平台等领域。

Abstract: Extracting momentum-resolved excitation spectra in strongly correlated
quantum systems remains a major challenge, especially beyond one spatial
dimension. We present an efficient tensor-network approach to compute
dispersion relations via imaginary-time evolution within the infinite projected
entangled-pair states (iPEPS) framework. Benchmarking on the transverse-field
Ising model, the method successfully captures dispersion relations in both
paramagnetic and ferromagnetic phases for two- and three-dimensional lattices,
achieving strong agreement with series expansion methods, where these are
applicable. Crucially, this work presents the first demonstration of dispersion
relation calculations for three-dimensional quantum lattice models - a
long-standing computational challenge that opens entirely new research
frontiers. The method demonstrates remarkable efficiency, requiring only modest
computational resources while maintaining high accuracy across wide parameter
ranges. Its broad applicability makes it a powerful tool for quantum
simulation, photonic material design, and quantum information platforms
requiring precise momentum-resolved spectra.

</details>


### [303] [Enhanced Quantum Signal Control and Sensing Under Multicolored Noise via Generalized Filter Function Framework](https://arxiv.org/abs/2503.13206)
*Zhi-Da Zhang,Yao Song,Wen-Zheng Dong,Xiu-Hao Deng*

Main category: quant-ph

TL;DR: 我们提出了一种广义滤波器函数框架，将噪声耦合强度作为可调控参数，实现了跨用户定义频带的目标噪声抑制。通过优化此广义滤波器函数，我们设计了带选择性控制脉冲，在强噪声和多样化频谱分布下实现了0.9999的单比特和双比特门保真度。我们进一步将该方法扩展到量子传感领域，选择性地提高交流信号的信噪比，精度最高可提升10dB。所得控制脉冲在实验上是可行的，为在复杂频谱噪声下进行鲁棒的量子操作和高精度信号处理提供了实际途径。


<details>
  <summary>Details</summary>
Motivation: 在强噪声和多样化频谱分布下实现高保真度的量子操作，并提高量子传感精度。

Method: 提出一种广义滤波器函数框架，将噪声耦合强度作为可调控参数，设计带选择性控制脉冲，并将其扩展到量子传感领域。

Result: 在强噪声和多样化频谱分布下实现了0.9999的单比特和双比特门保真度，量子传感精度最高可提升10dB。

Conclusion: 所提出的广义滤波器函数框架和控制脉冲在实验上可行，为在复杂频谱噪声下进行鲁棒的量子操作和高精度信号处理提供了实际途径。

Abstract: We introduce a generalized filter-function framework that treats noise
coupling strength as a tunable control parameter, enabling target noise
suppression across user-defined frequency bands. By optimizing this generalized
filter function, we design band-selective control pulses that achieve $0.9999$
fidelity of single- and two-qubit gates under strong noise with diverse
spectral profiles. We further extend the method to selectively enhance the
signal-to-noise ratio for quantum sensing of AC signals with an enhanced
precision of up to $10$ dB. The resulting control pulses are experimentally
feasible, offering a practical pathway toward robust quantum operations and
high-precision signal processing under spectrally complex noises.

</details>


### [304] [Full Quantum Stack: Ket Platform](https://arxiv.org/abs/2509.15484)
*Evandro Rosa,Eduardo Lussi,Jerusa Marchi,Rafael de Santiago*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: As quantum computing hardware continues to scale, the need for a robust
software infrastructure that bridges the gap between high-level algorithm
development and low-level physical qubit control becomes increasingly critical.
A full-stack approach, analogous to classical computing, is essential for
managing complexity, enabling hardware-agnostic programming, and systematically
optimizing performance. In this paper, we present a comprehensive, end-to-end
quantum software stack, detailing each layer of abstraction from user-facing
code to hardware execution. We begin at the highest level with the Ket quantum
programming platform, which provides an expressive, Python-based interface for
algorithm development. We then describe the crucial multi-stage compilation
process, which translates hardware-agnostic programs into hardware-compliant
circuits by handling gate decomposition, qubit mapping to respect device
connectivity, and native gate translation. To illustrate the complete workflow,
we present a concrete example, compiling the Grover diffusion operator for a
superconducting quantum processor. Finally, we connect the compiled circuit to
its physical realization by explaining how native gates are implemented through
calibrated microwave pulses. This includes the calibration of single- and
two-qubit gates, frequency characterization, and measurement procedures,
providing a clear picture of how abstract quantum programs ultimately map onto
the physical control of a quantum processor. By providing a detailed blueprint
of a complete quantum stack, this work illuminates the critical interplay
between software abstractions and physical hardware, establishing a framework
for developing practical and performant quantum applications.

</details>


### [305] [Discrete Flow-Based Generative Models for Measurement Optimization in Quantum Computing](https://arxiv.org/abs/2509.15486)
*Isaac L. Huidobro-Meezs,Jun Dai,Rodrigo A. Vargas-Hernández*

Main category: quant-ph

TL;DR: GFlowNets被应用于量子模拟中的哈密顿量着色问题，以减少测量成本。


<details>
  <summary>Details</summary>
Motivation: 量子模拟中的测量瓶颈限制了化学精度，尤其是在嘈杂的硬件上，需要改进测量策略来平衡总测量次数、不同测量电路的数量以及硬件编译约束。

Method: 提出了一种自适应生成流网络（GFlowNets）的算法，用于对哈密顿量进行图着色，以生成多样化的高质量分组，并在基准分子哈密顿量上与现有方法进行了比较。

Result: 所提出的GFlowNets方法在减少测量成本方面优于排序插入基线，并且通过整合电路数量和测量成本的复合奖励，进一步提高了性能。

Conclusion: 该生成策略框架不仅降低了测量成本，还通过其奖励函数为潜在的硬件感知适应提供了灵活性。

Abstract: Achieving chemical accuracy in quantum simulations is often constrained by
the measurement bottleneck: estimating operators requires a large number of
shots, which remains costly even on fault-tolerant devices and is further
exacerbated on today's noisy hardware by finite circuit fidelity and
error-mitigation overhead. Addressing this challenge involves a multiobjective
optimization problem that balances total shot count, the number of distinct
measurement circuits, and hardware-specific compilation constraints. Existing
methods typically rely on heuristic graph-coloring strategies to group
commuting or qubit-wise commuting Hamiltonian terms, or on greedy allocation
schemes for distributing measurements. Such approaches explore only a limited
portion of the combinatorial solution space, potentially missing superior
solutions. We introduce an algorithm that adapts Generative Flow Networks
(GFlowNets) for coloring graph representations of Hamiltonians, enabling the
generation of diverse, high-quality groupings. Our approach samples colored
graphs in proportion to a user-defined reward, naturally capturing
multiobjective trade-offs and discovering multiple competitive solutions. On
benchmark molecular Hamiltonians, our method outperforms sorted-insertion
baselines by reducing measurement costs. We further analyze the role of
composite rewards, incorporating both the number of circuits and measurement
costs, leading to additional improvements. This generative policy framework not
only reduces measurement costs but also offers flexibility for potential
hardware-aware adaptations through its reward function.

</details>


### [306] [QuantEM: The quantum error management compiler](https://arxiv.org/abs/2509.15505)
*Ji Liu,Quinn Langfitt,Mingyoung Jessica Jeng,Alvin Gonzales,Noble Agyeman-Bobie,Kaiya Jones Siddharth Vijaymurugan,Daniel Dilley,Zain H. Saleem,Nikos Hardavellas,Kaitlin N. Smith*

Main category: quant-ph

TL;DR: 通过自动化编译流程，QuantEM 简化了将量子纠错码集成到任意量子程序中的过程，降低了开发者负担，并提高了跨架构的一致性。


<details>
  <summary>Details</summary>
Motivation: 量子计算正朝着容错架构发展，量子纠错（QED）作为错误缓解和完全纠错之间的过渡策略，具有实用性和可扩展性。然而，将 QED 应用于任意量子电路仍具挑战性，因为需要手动插入检测子电路、分配辅助量子比特以及进行特定硬件映射和调度。

Method: 提出了一种名为 QuantEM 的模块化、可扩展的编译器，用于自动化 QED 代码到任意量子程序的集成。该编译器包含三个主要模块：程序分析与转换模块（引入检查和辅助量子比特）、纠错码集成模块（将增强电路映射到特定硬件后端）以及测量结果后处理和资源管理模块。

Result: QuantEM 接受高层量子电路、选择的纠错码和目标硬件拓扑，生成优化的可执行电路。它还可以根据电路结构和资源估算自动选择合适的检测码。目前支持 Pauli check sandwiching 和 Iceberg 码，并可扩展支持未来的 QED 方案和硬件目标。

Conclusion: QuantEM 自动化了复杂的 QED 编译流程，减轻了开发者的负担，能够快速进行代码探索，并确保在不同架构上一致且正确地应用检测逻辑。

Abstract: As quantum computing advances toward fault-tolerant architectures, quantum
error detection (QED) has emerged as a practical and scalable intermediate
strategy in the transition from error mitigation to full error correction. By
identifying and discarding faulty runs rather than correcting them, QED enables
improved reliability with significantly lower overhead. Applying QED to
arbitrary quantum circuits remains challenging, however, because of the need
for manual insertion of detection subcircuits, ancilla allocation, and
hardware-specific mapping and scheduling.
  We present QuantEM, a modular and extensible compiler designed to automate
the integration of QED codes into arbitrary quantum programs. Our compiler
consists of three key modules: (1) program analysis and transformation module
to examine quantum programs in a QED-aware context and introduce checks and
ancilla qubits, (2) error detection code integration module to map augmented
circuits onto specific hardware backends, and (3) postprocessing and resource
management for measurement results postprocessing and resource-efficient
estimation techniques. The compiler accepts a high-level quantum circuit, a
chosen error detection code, and a target hardware topology and then produces
an optimized and executable circuit. It can also automatically select an
appropriate detection code for the user based on circuit structure and resource
estimates. QuantEM currently supports Pauli check sandwiching and Iceberg codes
and is designed to support future QED schemes and hardware targets. By
automating the complex QED compilation flow, this work reduces developer
burden, enables fast code exploration, and ensures consistent and correct
application of detection logic across architectures.

</details>


### [307] [Measurement-Driven Transitions between Area Law Phases](https://arxiv.org/abs/2509.15634)
*Hui Yu,Jiangping Hu*

Main category: quant-ph

TL;DR: This paper introduces a measurement-only quantum circuit model (a projective quantum Ising model with three-spin interactions) that exhibits three distinct phases. The authors use entanglement measures to identify phase boundaries and critical exponents, and find a connection to bond percolation.


<details>
  <summary>Details</summary>
Motivation: Quantum circuits with unitary gates and projective measurements are useful for preparing quantum many-body states. This work explores a measurement-only circuit model to study its properties.

Method: The authors analyze a projective quantum Ising model with three-spin interactions. They use topological entanglement entropy and mutual information to identify phase boundaries and perform scaling analysis to derive critical exponents. They also establish a relationship with the bond percolation model.

Result: The model exhibits three distinct phases separated by two critical lines. The entanglement measures successfully identify these boundaries and critical exponents. A connection to the bond percolation model is established under certain conditions.

Conclusion: The study demonstrates the potential of measurement-only quantum circuits for exploring complex quantum phenomena and suggests further research in this area using similar models.

Abstract: In recent years, quantum circuits consisting of unitary gates and projective
measurements have become valuable tools for stimulating or preparing quantum
many-body states with non-trivial properties. Here, we introduce and examine a
measurement-only circuit (the projective quantum Ising model with three-spin
interactions) that involves three non-commuting projective measurements. This
model features three distinct phases, separated by two critical lines. We
utilize two entanglement measures (topological entanglement entropy and mutual
information) to identify the phase boundaries and derive various critical
exponents through scaling analysis. We establish a relationship between our
model and a two-dimensional statistical model (bond percolation) within certain
limits. We hope that our results will shed light on further studies using other
measurement-only models.

</details>


### [308] [Bose's Probabilistic Interactions, Einstein's Objections, and Their Legacy in Quantum Optics and Stochastic Mechanics](https://arxiv.org/abs/2509.15686)
*Partha Ghose*

Main category: quant-ph

TL;DR: S. N. Bose 提出的光子计数方法和物质-辐射相互作用概率定律被爱因斯坦批评，但本文认为区分遭遇概率和跃迁率可以解决爱因斯坦的担忧，并且现代量子光学和腔量子电动力学证实了 Bose 的核心观点：自发辐射源于原子与量化场的耦合，而非原子固有的属性。此外，随机力学模型比标准量子力学更符合 Bose 的观点，并能调和微观随机性与经典极限。 


<details>
  <summary>Details</summary>
Motivation: 本文旨在调和爱因斯坦对 S. N. Bose 概率定律的批评，并论证 Bose 的核心思想在现代量子光学中得到了证实。

Method: 本文通过区分遭遇概率和跃迁率来调和爱因斯坦的担忧，并引用现代量子光学和腔量子电动力学的证据来支持 Bose 的观点。此外，本文还探讨了随机力学模型与 Bose 观点的契合度。

Result: 区分遭遇概率和跃迁率可以解决爱因斯坦的担忧，现代量子光学和腔量子电动力学证实了 Bose 的核心观点，即“自发”辐射源于原子与量化场的耦合，其速率由局部光子模式结构决定。随机力学模型比标准量子力学更符合 Bose 的观点，并能调和微观随机性与经典极限。

Conclusion: S. N. Bose 的核心思想得到了现代量子光学和腔量子电动力学的证实，自发辐射并非原子固有属性，而是源于原子与量化场的耦合。随机力学模型为理解微观随机性和经典极限之间的联系提供了新的视角。

Abstract: In 1924, S. N. Bose proposed (i) a new counting method for photons and (ii) a
probabilistic law of microscopic matter-radiation interactions, treating
emission and absorption as two aspects of a single, field-dependent process.
While Einstein enthusiastically extended Bose's counting to material particles,
he sharply criticized the probabilistic law, invoking detailed balance and the
correspondence principle. This paper argues that (i) once one distinguishes
encounter probabilities from transition rates, Einstein's concerns can be
reconciled, and (ii) that modern quantum optics and cavity QED vindicate Bose's
core intuition: ``spontaneous'' emission is not an intrinsic property of an
isolated atom, as Einstein had assumed, but emerges from its coupling to the
quantized field, with the rate set by the local photonic mode structure
(LDOS/Purcell effect), all while satisfying Einstein's correspondence
requirement in the classical (high-intensity) limit. It is further suggested
that stochastic-mechanics models--persistent random walks leading to the
telegrapher's equation, with diffusive and chiral limits yielding the
Schr\"{o}dinger and Dirac equations--accord more closely with Bose's view of
fundamental randomness than standard quantum mechanics, and furnish a
mesoscopic bridge that reconciles micro-level stochasticity with Einstein's
demand for the correct classical limit.

</details>


### [309] [Robust self-testing of quantum steering assemblages via operator inequalities](https://arxiv.org/abs/2509.15699)
*Beata Zjawin*

Main category: quant-ph

TL;DR: 提出了一种新的算子不等式方法，用于设备无关地自测试量子态，特别是最大化违反 CHSH 不等式的组装。该方法显著优于之前的数值方法，是设备无关组装自测试的首次解析处理。


<details>
  <summary>Details</summary>
Motivation: 量子自测试的鲁棒性对于在实验中认证量子资源至关重要。虽然量子态和量子测量的自测试已有解析方法，但对于量子组装的设备无关认证仍是开放性挑战，之前的研究主要依赖数值方法。

Method: 开发了用于鲁棒量子组装自测试的算子不等式，特别关注最大化违反 CHSH 不等式的组装，并获得了其认证保真度的明确下界。

Result: 提出的解析方法得到的下界显著优于先前数值方法得到的界限，实现了设备无关的组装自测试的首次解析处理。

Conclusion: 该研究展示了算子不等式在量子态认证之外的新应用，并为理解量子组装的设备无关认证提供了理论基础，有望指导未来的理论和实验发展。

Abstract: Robust self-testing provides a framework for certifying quantum resources
under experimental imperfections. Improving robustness bounds for quantum
resources such as quantum states, steering assemblages, and measurements is a
constant effort that ensures relevance in the experimental realm. Despite
progress in analytic self-testing methods for quantum states and measurements,
extending these techniques to device-independent certification of steering
assemblages has remained an open challenge, with previous work relying
primarily on numerical approaches. We address this gap by developing operator
inequalities for robust self-testing of quantum steering assemblages.
Specifically, we consider the assemblage that achieves maximal violation of the
Clauser-Horne-Shimony-Holt (CHSH) inequality and obtain explicit lower bounds
on its certification fidelity. Our analytic approach yields results that
significantly improve upon previous numerical bounds, representing the first
analytic treatment of device-independent assemblage self-testing. This work
demonstrates a new application of operator inequalities beyond quantum state
certification and contributes to the foundational understanding of
device-independent certification in steering scenarios, potentially guiding
future theoretical and experimental developments.

</details>


### [310] [Qubit-oscillator-based gate implementations for approximate Gottesman-Kitaev-Preskill codes](https://arxiv.org/abs/2509.15707)
*Lukas Brenner,Beatriz Dias,Robert Koenig*

Main category: quant-ph

TL;DR: 该论文提出了一种在混合系统中使用GKP量子比特编码实现逻辑门的方法，并分析了其错误率。


<details>
  <summary>Details</summary>
Motivation: 在混合量子系统中实现高效的量子逻辑门，特别是针对GKP量子比特编码。

Method: 提出了一种使用两个振荡器和三个量子比特来实现GKP量子比特编码的逻辑门的方法，并分析了在大压缩极限下的错误率。

Result: 在压缩参数和编码量子比特数量的函数中，逻辑门错误率得到了一个上限。对于某些Clifford操作，提出的方法克服了现有高斯实现方法的缺点，即在无噪声情况下也存在恒定的逻辑门错误。

Conclusion: 该方法为在混合系统中实现容错量子计算提供了一种有前景的途径。

Abstract: We consider hybrid qubit-oscillator systems together with Gaussian,
multi-qubit as well as qubit-controlled Gaussian unitaries. We propose
implementations of logical gates for approximate Gottesman-Kitaev-Preskill
codes in this model using two oscillators and three qubits. We show that these
gate implementations become exact in the limit of large squeezing: The logical
gate error is upper bounded by a linear function of the squeezing parameter,
and depends polynomially on the number of encoded qubits. For certain
Cliffords, our constructions overcome a shortcoming of well-known Gaussian
implementations which have a constant logical gate error even in the absence of
noise.

</details>


### [311] [Hamiltonian learning via quantum Zeno effect](https://arxiv.org/abs/2509.15713)
*Giacomo Franceschetto,Egle Pagliaro,Luciano Pereira,Leonardo Zambrano,Antonio Acín*

Main category: quant-ph

TL;DR: 一种可扩展的、对实验友好的量子哈密顿量学习协议，利用量子齐纳效应和量子过程断层扫描来学习局部相互作用的哈密顿量系数，适用于大规模量子硬件。


<details>
  <summary>Details</summary>
Motivation: 理解量子系统的动力学和验证其行为需要确定其哈密顿量。哈密顿量学习作为一种数据驱动的方法，对于量子硬件的基准测试和表征尤为重要，但现有方法在大规模和复杂系统上面临挑战。

Method: 提出了一种利用量子齐纳效应来局域化动力学，并结合量子过程断层扫描来学习作用在选定量子比特上的局部哈密顿量子集系数的方法。该方法不需要复杂的量子态制备，并且使用实验上可实现的、保持相干性的操作。

Result: 理论上保证了该协议的性能，并通过数值模拟和在IBM超导量子硬件上的实验实现，成功学习了一个包含109个量子比特的哈密顿量的系数。

Conclusion: 所提出的哈密顿量学习协议是一种可扩展且对实验友好的方法，适用于大规模量子硬件，能够有效学习局部相互作用哈密顿量的系数。

Abstract: Determining the Hamiltonian of a quantum system is essential for
understanding its dynamics and validating its behavior. Hamiltonian learning
provides a data-driven approach to reconstruct the generator of the dynamics
from measurements on the evolved system. Among its applications, it is
particularly important for benchmarking and characterizing quantum hardware,
such as quantum computers and simulators. However, as these devices grow in
size and complexity, this task becomes increasingly challenging. To address
this, we propose a scalable and experimentally friendly Hamiltonian learning
protocol for Hamiltonian operators made of local interactions. It leverages the
quantum Zeno effect as a reshaping tool to localize the system's dynamics and
then applies quantum process tomography to learn the coefficients of a local
subset of the Hamiltonian acting on selected qubits. Unlike existing
approaches, our method does not require complex state preparations and uses
experimentally accessible, coherence-preserving operations. We derive
theoretical performance guarantees and demonstrate the feasibility of our
protocol both with numerical simulations and through an experimental
implementation on IBM's superconducting quantum hardware, successfully learning
the coefficients of a 109-qubit Hamiltonian.

</details>


### [312] [Task-Oriented Gaussian Optimization for Non-Gaussian Resources in Continuous-Variable Quantum Computation](https://arxiv.org/abs/2509.15747)
*Boxuan Jing,Feng-Xiao Sun,Qiongyi He*

Main category: quant-ph

TL;DR: 本工作提出了一种高斯优化协议，用于改进连续变量系统中非高斯资源（特别是立方相位态）的制备和应用，以提高量子计算的性能。


<details>
  <summary>Details</summary>
Motivation: 连续变量系统中的非高斯资源对于实现超越经典模拟的通用量子计算至关重要，但立方相位态的实验制备仍然是一个挑战，现有的近似方案在具体量子任务中表现不佳。

Method: 提出了一种高斯优化协议，该协议系统地优化非高斯资源。该协议利用了特定任务的高斯操作来改进近似立方相位态，从而提高基于魔态的量子计算的门保真度，并减少基于测量的量子计算中非线性四次测量方差。此外，还提出了一种基于福克基叠加、压缩和位移的任务导向型非高斯态制备方案。

Result: 所提出的协议显著提高了基于魔态和基于测量的量子计算的性能。具体而言，它提高了门保真度，并降低了非线性四次测量的方差。任务导向型方案能够直接为特定任务目标定制资源态。

Conclusion: 该框架提供了一种强大且广泛适用的工具，用于增强各种连续变量量子信息方案的性能，通过高斯优化协议和任务导向型状态制备，为实现更高效的量子计算提供了可行途径。

Abstract: In continuous-variable systems, non-Gaussian resources are essential for
achieving universal quantum computation that lies beyond classical simulation.
Among the candidate states, the cubic phase state stands out as the simplest
form of single-mode non-Gaussian resource, yet its experimental preparation
still remains a great challenge. Although a variety of approximate schemes have
been proposed to simulate the cubic phase state, they often fall short when
deployed in concrete quantum tasks. In this work, we present a Gaussian
optimization protocol that systematically refines the non-Gaussian resources,
which significantly improves the performance of both magic-state-based and
measurement-based quantum computation. Leveraging task-specific Gaussian
operations on approximate cubic phase states, our protocol offers an
experimentally feasible approach to enhance gate fidelity in magic-state-based
quantum computation and reduce the variance of nonlinear quadrature measurement
in measurement-based quantum computation. Building on this framework, we
further propose a task-oriented non-Gaussian state preparation scheme based on
superpositions in the Fock basis followed by squeezing and displacement. This
strategy enables direct tailoring of resource states to specific task goals.
Owing to its flexibility and generality, our framework provides a powerful and
broadly applicable tool for enhancing performance across a wide range of
continuous-variable quantum information protocols.

</details>


### [313] [Gaussian fermionic embezzlement of entanglement](https://arxiv.org/abs/2509.15749)
*Alessia Kera,Lauritz van Luijk,Alexander Stottmeister,Henrik Wilming*

Main category: quant-ph

TL;DR: Embezzlement of entanglement allows extracting arbitrary entangled states from a resource state with local operations and minimal perturbation. This paper shows that for fermionic Gaussian states, embezzlement operations are restricted to Gaussian operations when extracting Gaussian entangled states. The study provides a detailed understanding of entanglement embezzlement in finite-size fermionic Gaussian systems and connects them to abstract algebraic characterizations. Novel bounds on the distance between covariances and trace-distance of Gaussian states are also established.


<details>
  <summary>Details</summary>
Motivation: The paper investigates whether embezzlement operations can be restricted to Gaussian operations when extracting Gaussian entangled states from fermionic Gaussian states, motivated by the fact that ground states of critical fermions are natural embezzling states.

Method: The study proves that embezzlement operations are indeed restricted to Gaussian operations for fermionic Gaussian states. Novel bounds relating the distance of covariances to the trace-distance of Gaussian states are established as part of the proof.

Result: It is proven that embezzlement operations are restricted to Gaussian operations for fermionic Gaussian states. Novel bounds relating the distance of covariances to the trace-distance of Gaussian states are established.

Conclusion: Embezzlement property is a generic property of fermionic Gaussian states, providing a fine-grained understanding of entanglement embezzlement in finite-size regimes and bridging them to abstract characterizations. Novel bounds on covariance distance and trace distance are also presented.

Abstract: Embezzlement of entanglement allows to extract arbitrary entangled states
from a suitable embezzling state using only local operations while perturbing
the resource state arbitrarily little. A natural family of embezzling states is
given by ground states of non-interacting, critical fermions in one spatial
dimension. This raises the question of whether the embezzlement operations can
be restricted to Gaussian operations whenever one only wishes to extract
Gaussian entangled states. We show that this is indeed the case and prove that
the embezzling property is in fact a generic property of fermionic Gaussian
states. Our results provide a fine-grained understanding of embezzlement of
entanglement for fermionic Gaussian states in the finite-size regime and
thereby bridge finite-size systems to abstract characterizations based on the
classification of von Neumann algebras. To prove our results, we establish
novel bounds relating the distance of covariances to the trace-distance of
Gaussian states, which may be of independent interest.

</details>


### [314] [Products between block-encodings](https://arxiv.org/abs/2509.15779)
*Dekuan Dong,Yingzhou Li,Jungong Xue*

Main category: quant-ph

TL;DR: 提出了一种在量子算法中对块编码矩阵进行乘积的高效方法，显著减少了辅助量子比特的数量，并实现了更复杂的块编码。


<details>
  <summary>Details</summary>
Motivation: 在量子算法中，将矩阵嵌入到酉算子中是标准的做法，而高效地实现块编码矩阵的乘积对于哈密顿模拟和量子线性代数等应用至关重要。

Method: 提出了一种用于块编码矩阵的矩阵-矩阵乘积、Kronecker 乘积和 Hadamard 乘积的资源高效实现方法，适用于任意尺寸的矩形矩阵。

Result: 所提出的方法显著减少了辅助量子比特的数量，对于一系列矩阵乘法实现了指数级的量子比特节省，同时门复杂度仅有适度增加。这些乘积操作还支持更复杂的块编码，包括时间依赖哈密顿模拟的压缩装置以及 Kronecker 乘积之和表示的矩阵，并改善了资源需求。

Conclusion: 所提出的块编码乘积方法在量子算法中具有重要的应用前景，能够有效降低资源消耗并支持更复杂的量子计算任务。

Abstract: Block-encoding is a standard framework for embedding matrices into unitary
operators in quantum algorithms. Efficient implementation of products between
block-encoded matrices is crucial for applications such as Hamiltonian
simulation and quantum linear algebra. We present resource-efficient methods
for matrix-matrix, Kronecker, and Hadamard products between block-encodings
that apply to rectangular matrices of arbitrary dimensions. Our constructions
significantly reduce the number of ancilla qubits, achieving exponential qubit
savings for sequences of matrix-matrix multiplications, with a moderate
increase in gate complexity. These product operations also enable more complex
block-encodings, including a compression gadget for time-dependent Hamiltonian
simulation and matrices represented as sums of Kronecker products, each with
improved resource requirements.

</details>


### [315] [The basic ideas of quantum mechanics](https://arxiv.org/abs/2509.15819)
*David Ellerman*

Main category: quant-ph

TL;DR: 该论文旨在通过识别和解释量子力学（QM）的基本直观概念，来理解量子实在，而不是深入研究其数学机制。


<details>
  <summary>Details</summary>
Motivation: 量子力学（QM）的数学框架难以解释，研究者希望找到一种更直观的方式来理解量子实在。

Method: 识别和解释量子力学（QM）的基本直观概念。

Result: 提供关于量子实在的直观（anschaulich）理解，但不深入探讨其数学机制。

Conclusion: 通过直观概念可以更好地理解量子实在，即使不完全理解其背后的数学原理。

Abstract: For a century, quantum theorists have been reading the mathematical entrails
of quantum mechanics (QM) to divine the nature of quantum reality. But to
little avail. In this paper a different approach is taken, namely to identify
and explain the basic intuitive ideas involved in QM. This does not tell one
how those basic `gears' all mesh together in the beautiful mathematics of QM.
But this does give one some intuitive (\textit{anschaulich})) ideas about the
quantum reality described in the seemingly hard-to-interpret mathematical
framework.

</details>


### [316] [Single-shot sorting of Mössbauer time-domain data at X-ray free electron lasers](https://arxiv.org/abs/2509.15833)
*Miriam Gerharz,Willi Hippler,Berit Marx-Glowna,Sakshath Sadashivaiah,Kai S. Schulze,Ingo Uschmann,Robert Lötzsch,Kai Schlage,Sven Velten,Dominik Lentrodt,Lukas Wolff,Olaf Leupold,Ilya Sergeev,Hans-Christian Wille,Cornelius Strohm,Marc Guetg,Shan Liu,Gianluca Aldo Geloni,Ulrike Boesenberg,Jörg Hallmann,Alexey Zozulya,Jan-Etienne Pudell,Angel Rodriguez-Fernandez,Mohamed Youssef,Anders Madsen,Lars Bocklage,Gerhard G. Paulus,Christoph H. Keitel,Thomas Pfeifer,Ralf Röhlsberger,Jörg Evers*

Main category: quant-ph

TL;DR: XFELs可实现Mössbauer单次测量，但信号少。本文提出一种新方法，通过对数据分类，即使信号少也能分析所有数据，从而实现对非平衡瞬态动力学的研究。


<details>
  <summary>Details</summary>
Motivation: Mössbauer光谱具有高分辨率，但低计数率限制了其在非平衡现象研究中的应用。XFELs的出现为单次测量提供了可能，但信号强度不足是一个挑战。

Method: 提出一种数据分类方法，根据不同动力学类别对每次XFEL测量进行分组，并独立分析，无需理论模型或先验知识。

Result: 实现了高达900个信号光子/次的相干核前向散射，并证明了所提出的分类方法可以处理所有单次测量数据，即使信号强度不同。

Conclusion: 该方法克服了XFELs在Mössbauer单次测量中的信号强度限制，使得研究非平衡瞬态动力学成为可能，为Mössbauer科学开辟了新方向。

Abstract: M\"ossbauer spectroscopy is widely used to study structure and dynamics of
matter with remarkably high energy resolution, provided by the narrow nuclear
resonance line widths. However, the narrow width implies low count rates, such
that experiments commonly average over extended measurement times or many x-ray
pulses (``shots''). This averaging impedes the study of non-equilibrium
phenomena. It has been suggested that X-ray free-electron lasers (XFELs) could
enable M\"ossbauer single-shot measurements without averaging, and a
proof-of-principle demonstration has been reported. However, so far, only a
tiny fraction of all shots resulted in signal-photon numbers which are
sufficiently high for a single-shot analysis. Here, we demonstrate coherent
nuclear-forward-scattering of self-seeded XFEL radiation, with up to 900
signal-photons per shot. We develop a sorting approach which allows us to
include all data on a single-shot level, independent of the signal content of
the individual shots. It utilizes the presence of different dynamics classes,
i.e. different nuclear evolutions after each excitation. Each shot is assigned
to one of the classes, which can then be analyzed separately. Our approach
determines the classes from the data without requiring theory modeling nor
prior knowledge on the dynamics, making it also applicable to unknown
phenomena. We envision that our approach opens up new grounds for M\"ossbauer
science, enabling the study of out-of-equilibrium transient dynamics of the
nuclei or their environment.

</details>


### [317] [Empty-Signal Detection: Proof-of-Principle Scheme for Arbitrarily Long-Distance Quantum Communication](https://arxiv.org/abs/2509.15884)
*Hao Shu*

Main category: quant-ph

TL;DR: 本论文提出了一种空信号检测（ESD）策略，通过利用辅助自由度（DOF）来编码光子存在信息，并结合状态制备、受控门和多副本分析，实现了对空信号的有效检测，从而解决了量子密钥分发（QKD）中由空信号引起的数据误码率（QBER）爆炸问题，为实现任意距离的安全量子通信提供了技术框架。


<details>
  <summary>Details</summary>
Motivation: 由于单光子探测器（SPDs）中不可避免的暗计数，量子通信（QKD）长期以来受到接收端空信号引起的量子比特错误率（QBER）急剧增加的限制，这阻碍了其扩展到任意长距离。本研究旨在解决这一挑战。

Method: 提出了一种空信号检测（ESD）策略，该策略将状态制备、受控门和多副本分析集成到一个块中。该策略的核心思想是将光子存在信息编码到独立于消息编码自由度的辅助自由度（DOF）上，然后通过在辅助DOF上应用受控门并随后在辅助副本上进行测量，来验证接收信号的非空性，而不干扰传输的消息。这样，就可以从后续通信处理中排除空信号。

Result: 所提出的ESD策略能够有效检测并排除空信号，从而解决了由空信号引起的QBER爆炸问题。该方案仅依赖于实际的、甚至市面上可买到的设备，可以在当前技术条件下实现。通过允许在QBER估计中将损耗信道渐近地视为无损信道，为实现任意距离的量子通信提供了一个框架。

Conclusion: 本研究提供了一个框架，通过允许在QBER估计中将损耗信道渐近地视为无损信道，从而实现任意距离的量子通信。此外，本研究提供了一个原理性演示，证明在当前技术条件下，安全量子通信可以扩展到任意距离。

Abstract: Secure quantum communication, particularly quantum key distribution (QKD),
has remained a central research focus for more than four decades and continues
to attract significant attention in recent years. However, due to the
unavoidable dark counts in single-photon detectors (SPDs), it has long been
constrained by the rapid increase of the quantum bit error rate (QBER) induced
by empty signals at the receiver, which prevents it from extending to
arbitrarily long distances. To address this challenge, this paper introduces an
empty-signal detection (ESD) strategy for quantum communication receivers,
which integrates state preparation, controlled gates, and multi-copy analysis
into a single block. The core idea is to encode photon-existence information
onto an auxiliary degree of freedom (DOF) that is independent of the
message-encoding DOF, allowing the receiver, through controlled gates on the
auxiliary DOFs and subsequent measurements on the auxiliary copies, to verify
the non-emptiness of the received signal without disturbing the transmitted
message. In this way, empty signals can be excluded from further communication
processing, thereby resolving the QBER explosion problem caused by empty
signals. Moreover, the proposed design relies solely on practical, even
commercially available, devices, and can be realized under current
technological conditions. Therefore, this study provides a framework for
achieving arbitrarily long-distance quantum communication by allowing a lossy
channel to be asymptotically regarded as lossless in QBER estimations, and
offers a proof-of-principle demonstration that secure quantum communications
can be extended to arbitrary distances under current technology.

</details>


### [318] [Quantum Metric Spaces: Replacing Fuzzy Metrics with the Hilbert Space Structure of Quantum States](https://arxiv.org/abs/2509.15945)
*Nicola Fabiano*

Main category: quant-ph

TL;DR: 模糊度量空间在处理不确定性方面已过时，被量子态几何所取代。


<details>
  <summary>Details</summary>
Motivation: 现有的模糊度量空间框架将不确定性视为外部施加的层，这与量子系统或认知表征等内在不确定性领域不符。作者认为模糊度量空间对于模拟这种不确定性是不必要的。

Method: 利用复希尔伯特空间作为度量空间，其中“点”是量子态本身，态之间的距离由希尔伯特范数给出。通过将人工智能概念建模为高斯波函数和通过量子重叠积分对模糊输入进行分类来演示。

Result: 该框架能够以非经典的方式捕捉不确定性，而无需模糊逻辑、t-范数或隶属度。与模糊方法不同，该方法通过态矢量的几何结构自然地处理干涉、分布形状和概念组合性。

Conclusion: 模糊度量空间在表示内在不确定性方面已过时，已被更强大、更具预测性和本体论上更一致的量子态几何框架所取代。

Abstract: Fuzzy metric spaces, grounded in t-norms and membership functions, have been
widely proposed to model uncertainty in machine learning, decision systems, and
artificial intelligence. Yet these frameworks treat uncertainty as an external
layer of imprecision imposed upon classical, point-like entities - a conceptual
mismatch for domains where indeterminacy is intrinsic, such as quantum systems
or cognitive representations. We argue that fuzzy metrics are unnecessary for
modeling such uncertainty: instead, the well-established structure of complex
Hilbert spaces - the foundational language of quantum mechanics for over a
century - provides a natural, rigorous, and non-contradictory metric space
where the ``points'' are quantum states themselves. The distance between states
is given by the Hilbert norm, which directly encodes state distinguishability
via the Born rule. This framework inherently captures the non-classical nature
of uncertainty without requiring fuzzy logic, t-norms, or membership degrees.
We demonstrate its power by modeling AI concepts as Gaussian wavefunctions and
classifying ambiguous inputs via quantum overlap integrals. Unlike fuzzy
methods, our approach naturally handles interference, distributional shape, and
concept compositionality through the geometry of state vectors. We conclude
that fuzzy metric spaces, while historically useful, are obsolete for
representing intrinsic uncertainty - superseded by the more robust, predictive,
and ontologically coherent framework of quantum state geometry.

</details>


### [319] [Single-Round Deterministic Quantum Anonymous Veto Using Bell States](https://arxiv.org/abs/2509.15951)
*Ravi Sangwan,Harishankar Mishra,Henry Sukumar,Gudapati Naresh Raghava*

Main category: quant-ph

TL;DR: 我们提出了一个新的确定性量子匿名否决（QAV）协议，该协议仅使用二方贝尔态，并在单轮中实现结论性否决检测，从而解决了现有QAV方案的资源要求和可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 现有量子匿名否决（QAV）方案在实际应用中存在资源需求大、可扩展性差、需要多方纠缠等问题。本研究旨在提出一种更实用、资源需求更少的QAV协议。

Method: 提出了一种新的确定性QAV协议，该协议仅利用二方纠缠（贝尔态），并在单轮中实现结论性否决检测。该协议不依赖于多量子比特纠缠态或迭代轮次，并利用偏振-路径编码和离散时间量子行走在光子平台上实现。

Result: 该协议在单轮中实现了结论性否决检测，且仅使用二方纠缠。协议保持了投票者匿名、正确性和可验证性等关键特性。在光子平台上实现了该协议的可行性。

Conclusion: 本研究提出的确定性QAV协议是一种资源高效且在实验上可行的替代方案，它解决了现有QAV方案的局限性，提高了在分布式系统中进行安全量子决策的可行性，并适合在近期量子设备上实现。

Abstract: Quantum Anonymous Veto (QAV) protocols enable secure and anonymous
decision-making by allowing participants to detect the presence of a veto
without revealing individual choices. While existing QAV schemes offer strong
theoretical guarantees, they face significant limitations in practical
implementation due to resource requirements, scalability issues, and the need
for multipartite entanglement. In this work, we propose a novel deterministic
QAV protocol that leverages only bipartite entanglement in the form of Bell
states and achieves conclusive veto detection in a single round. Our approach
eliminates the need for multi-qubit entangled states and iterative rounds,
thereby significantly reducing experimental overhead and enhancing scalability.
The protocol preserves critical properties such as voter anonymity,
correctness, and verifiability, making it well-suited for implementation on
near-term quantum devices. Furthermore, we outline a practical photonic
realization based on polarization-path encoding and discrete-time quantum
walks, demonstrating its feasibility within current quantum optical platforms.
This work contributes a resource-efficient and experimentally viable
alternative to existing QAV schemes, advancing the prospects of secure quantum
decision-making in distributed systems.

</details>


### [320] [Unveiling Entanglement's Metrological Power: Empirical Modeling of Optimal States in Quantum Metrics](https://arxiv.org/abs/2509.15954)
*Volkan Erol*

Main category: quant-ph

TL;DR: 本研究通过数值分析，揭示了纠缠度量与最大化量子费舍尔信息（MQFI）之间的强经验关系，并为量子传感器的设计和资源分配提供了指导。


<details>
  <summary>Details</summary>
Motivation: 研究量子纠缠度量与最大化量子费舍尔信息（MQFI）之间的关系，以期改进量子传感器的设计和资源分配。

Method: 对20,000个随机两比特态进行数值分析，比较了三种纠缠度量（concurrence、negativity、relative entropy of entanglement）与MQFI的关系，并使用统计分析方法（bootstrap resampling、data binning、multiple model comparisons）来验证关系。

Result: 发现纠缠度量与MQFI之间存在强经验关系，优化局部酉变换比固定生成器量子费舍尔信息更能预测这种关系。通过指数拟合和多项式拟合，模型的R^2值分别达到0.99以上和0.999，证实了量子计量优势的饱和行为。

Conclusion: 本研究为量子资源理论的预测提供了直接的经验验证，并为量子传感器的优化和资源分配设定了基本界限。提出的多项式和指数拟合方程为量子传感器的实际设计提供了重要指导。

Abstract: Using extensive numerical analysis of 20,000 randomly generated two-qubit
states, we provide a quantitative analysis of the connection between
entanglement measures and Maximized Quantum Fisher Information (MQFI). Our
systematic study shows strong empirical relationships between the metrological
capacity of quantum states and three different entanglement measures:
concurrence, negativity, and relative entropy of entanglement. We show that
optimization over local unitary transformations produces substantially more
predictable relationships than fixed-generator quantum Fisher information
approaches using sophisticated statistical analysis, such as bootstrap
resampling, systematic data binning, and multiple model comparisons. With
exponential fits reaching $R^2 > 0.99$ and polynomial models reaching $R^2 =
0.999$, we offer thorough empirical support for saturation behavior in quantum
metrological advantage. With immediate applications to realworld quantum
sensing protocols, our findings directly empirically validate important
predictions from quantum resource theory and set fundamental bounds for quantum
sensor optimization and resource allocation. These intricate relationships are
quantitatively described by the polynomial and exponential fit equations, which
offer crucial real-world direction for the design of quantum sensors.

</details>


### [321] [Quantum Enhanced Anomaly Detection for ADS-B Data using Hybrid Deep Learning](https://arxiv.org/abs/2509.15991)
*Rani Naaman,Felipe Gohring de Magalhaes,Jean-Yves Ouattara,Gabriela Nicolescu*

Main category: quant-ph

TL;DR: 量子机器学习结合经典机器学习技术，在航空器广播式自动相关监视（ADS-B）数据异常检测方面展现出与传统全连接神经网络相当的性能。


<details>
  <summary>Details</summary>
Motivation: 利用量子计算的叠加和纠缠特性，加速处理速度并处理高维度复杂数据，以探索其在ADS-B数据异常检测中的影响。

Method: 提出一种结合量子与经典机器学习的新方法，具体为混合全连接量子神经网络（H-FQNN），并与不同损失函数进行比较，使用公开的ADS-B数据集进行评估。

Result: H-FQNN模型的准确率在90.17%到94.05%之间，与传统全连接神经网络（FNN）模型（准确率在91.50%到93.37%之间）的性能相当，证明了其在异常检测方面的竞争力。

Conclusion: 混合式量子-经典方法在ADS-B数据异常检测方面具有潜力，其性能与传统方法相当。

Abstract: The emerging field of Quantum Machine Learning (QML) has shown promising
advantages in accelerating processing speed and effectively handling the high
dimensionality associated with complex datasets. Quantum Computing (QC) enables
more efficient data manipulation through the quantum properties of
superposition and entanglement. In this paper, we present a novel approach
combining quantum and classical machine learning techniques to explore the
impact of quantum properties for anomaly detection in Automatic Dependent
Surveillance-Broadcast (ADS-B) data. We compare the performance of a
Hybrid-Fully Connected Quantum Neural Network (H-FQNN) with different loss
functions and use a publicly available ADS-B dataset to evaluate the
performance. The results demonstrate competitive performance in detecting
anomalies, with accuracies ranging from 90.17% to 94.05%, comparable to the
performance of a traditional Fully Connected Neural Network (FNN) model, which
achieved accuracies between 91.50% and 93.37%.

</details>


### [322] [Quantum Reinforcement Learning with Dynamic-Circuit Qubit Reuse and Grover-Based Trajectory Optimization](https://arxiv.org/abs/2509.16002)
*Thet Htar Su,Shaswot Shresthamali,Masaaki Kondo*

Main category: quant-ph

TL;DR: A fully quantum reinforcement learning framework is proposed, utilizing quantum state, action, and reward encoding, dynamic circuit-based qubit reuse, and Grover's algorithm for policy optimization. Simulations and hardware experiments show reduced qubit requirements and feasibility on current quantum processors.


<details>
  <summary>Details</summary>
Motivation: To develop a fully quantum reinforcement learning framework that eliminates classical subroutines, reduces qubit requirements, and accelerates policy optimization for large-scale sequential decision-making tasks.

Method: The framework encodes states, actions, rewards, and transitions in the quantum domain. It uses dynamic circuit operations (mid-circuit measurement and reset) for qubit reuse, reducing qubit needs from 7*T to 7. Quantum arithmetic computes trajectory returns, and Grover's algorithm amplifies the probability of measuring trajectories with the highest return.

Result: Simulations show the dynamic-circuit implementation preserves trajectory fidelity and reduces qubit usage by 66% compared to static designs. Hardware experiments on IBM Heron-class hardware confirm the framework's operation within current quantum processor constraints.

Conclusion: The proposed fully quantum reinforcement learning framework is feasible under noisy intermediate-scale quantum conditions and advances the scalability and practical application of quantum reinforcement learning for sequential decision-making.

Abstract: A fully quantum reinforcement learning framework is developed that integrates
a quantum Markov decision process, dynamic circuit-based qubit reuse, and
Grover's algorithm for trajectory optimization. The framework encodes states,
actions, rewards, and transitions entirely within the quantum domain, enabling
parallel exploration of state-action sequences through superposition and
eliminating classical subroutines. Dynamic circuit operations, including
mid-circuit measurement and reset, allow reuse of the same physical qubits
across multiple agent-environment interactions, reducing qubit requirements
from 7*T to 7 for T time steps while preserving logical continuity. Quantum
arithmetic computes trajectory returns, and Grover's search is applied to the
superposition of these evaluated trajectories to amplify the probability of
measuring those with the highest return, thereby accelerating the
identification of the optimal policy. Simulations demonstrate that the
dynamic-circuit-based implementation preserves trajectory fidelity while
reducing qubit usage by 66 percent relative to the static design. Experimental
deployment on IBM Heron-class quantum hardware confirms that the framework
operates within the constraints of current quantum processors and validates the
feasibility of fully quantum multi-step reinforcement learning under noisy
intermediate-scale quantum conditions. This framework advances the scalability
and practical application of quantum reinforcement learning for large-scale
sequential decision-making tasks.

</details>


### [323] [AI Methods for Permutation Circuit Synthesis Across Generic Topologies](https://arxiv.org/abs/2509.16020)
*Victor Villar,Juan Cruz-Benito,Ismael Faro,David Kremer*

Main category: quant-ph

TL;DR: 利用基于RL的通用模型，实现跨不同拓扑的排列电路近优合成。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够跨多种拓扑合成排列电路的AI方法，避免为每个拓扑单独训练模型。

Method: 训练一个在通用矩形晶格上运行的RL基础模型，并使用掩码机制来动态选择拓扑。

Result: 在5x5晶格上实现了优于经典启发式算法的合成，性能媲美专门的AI模型，并且能够处理未见过的拓扑。

Conclusion: 提出的方法允许单个训练模型高效地跨不同拓扑合成电路，便于集成到转译工作流中。

Abstract: This paper investigates artificial intelligence (AI) methodologies for the
synthesis and transpilation of permutation circuits across generic topologies.
Our approach uses Reinforcement Learning (RL) techniques to achieve
near-optimal synthesis of permutation circuits up to 25 qubits. Rather than
developing specialized models for individual topologies, we train a
foundational model on a generic rectangular lattice, and employ masking
mechanisms to dynamically select subsets of topologies during the synthesis.
This enables the synthesis of permutation circuits on any topology that can be
embedded within the rectangular lattice, without the need to re-train the
model. In this paper we show results for 5x5 lattice and compare them to
previous AI topology-oriented models and classical methods, showing that they
outperform classical heuristics, and match previous specialized AI models, and
performs synthesis even for topologies that were not seen during training. We
further show that the model can be fine tuned to strengthen the performance for
selected topologies of interest. This methodology allows a single trained model
to efficiently synthesize circuits across diverse topologies, allowing its
practical integration into transpilation workflows.

</details>


### [324] [Exact Relation Between Wehrl-Rényi Entropy and Many-Body Entanglement](https://arxiv.org/abs/2509.16036)
*Pengfei Zhang,Chen Xu,Peng Zhang*

Main category: quant-ph

TL;DR: 通过建立量子多体系统中系统整体的 Wehrl-Rényi 熵（WRE）与所有可能子系统的约化密度矩阵纯度之间的精确关系，论文提出了一种独立于子系统且可实验测量的量子纠缠表征方法。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在为量子多体系统中的纠缠提供一种独立于子系统且可实验测量的表征方法，以克服传统基于子系统纯度度量方法的局限性。

Method: 通过数学推导，建立了系统整体的 Wehrl-Rényi 熵 $S_W^{(2)}$ 与所有 $2^N$ 个子系统的约化密度矩阵纯度 $\mathrm{Tr}({{\hat \rho}_A}^2)$ 之间的精确关系式 $e^{-S_W^{(2)}} = (6\pi)^{-N} \sum_A \mathrm{Tr}({{\hat \rho}_A}^2)$，并提出了实验测量 WRE 的具体方案。

Result: 推导并证明了 WRE 与所有子系统纯度之间的精确关系，并提出了一种可行的实验测量方案。通过理论计算，得到了 Haar 随机态、GHZ 态和 W 态的 WRE 值。

Conclusion: Wehrl-Rényi 熵（WRE）提供了一种独立于子系统且可实验测量的表征 $N$ 粒子量子系统纯态整体纠缠的方法，可应用于具有全连接耦合的强关联自旋系统，如光学镊子或超导量子电路实现的系统。

Abstract: Quantum entanglement is key to understanding correlations and emergent
phenomena in quantum many-body systems. For $N$ qubits (distinguishable
spin-$1/2$ particles) in a pure quantum state, many-body entanglement can be
characterized by the purity of the reduced density matrix of a subsystem,
defined as the trace of the square of this reduced density matrix.
Nevertheless, this approach depends on the choice of subsystem. In this letter,
we establish an exact relation between the Wehrl-R\'enyi entropy (WRE)
$S_W^{(2)}$, which is the 2nd R\'enyi entropy of the Husimi function of the
entire system, and the purities of all possible subsystems. Specifically, we
prove the relation $e^{-S_W^{(2)}} = (6\pi)^{-N} \sum_A \mathrm{Tr}({{\hat
\rho}_A}^2)$, where $A$ denotes a subsystem with reduced density matrix ${\hat
\rho}_A$, and the summation runs over all $2^N$ possible subsystems.
Furthermore, we show that the WRE can be experimentally measured via a concrete
scheme. Therefore, the WRE is a subsystem-independent and experimentally
measurable characterization of the overall entanglement in pure states of $N$
qubits. It can be applied to the study of strongly correlated spin systems,
particularly those with all-to-all couplings that do not have a natural
subsystem division, such as systems realized with natural atoms in optical
tweezer arrays or superconducting quantum circuits. We also analytically derive
the WRE for several representative many-body states, including Haar-random
states, the Greenberger-Horne-Zeilinger (GHZ) state, and the W state.

</details>


### [325] [Integrated Telecom Wavelength Heralded Single-Photon Source based on GHz gated detectors](https://arxiv.org/abs/2509.16049)
*Maria Ana Pereira,Mingsong Wu,Arslan Sajid Raja,Rui Ning Wang,Tobias Kippenberg,Hugo Zbinden,Tiff Brydges,Rob Thew*

Main category: quant-ph

TL;DR: 该论文提出了一种简单灵活的、用于产生高光谱纯度单光子的方案，利用了具有时间分辨能力的单光子探测器来过滤光子，并结合了窄带光子对源。


<details>
  <summary>Details</summary>
Motivation: 需要一种产生高光谱纯度单光子的方法。

Method: 使用连续波激光器泵浦概率性光子对源，并利用具有时间分辨能力的门控单光子雪崩二极管来选择和过滤光子。

Result: 成功地产生了具有高光谱纯度的单光子，并证明了该方案的灵活性，能够适应不同的波长和带宽。

Conclusion: 所提出的方案是一种简单且灵活的单光子源，能够产生高光谱纯度的单光子，并具有进一步扩展到其他波长和带宽的潜力。

Abstract: We introduce a simple and flexible concept for a heralded -- spectrally pure
-- single photon source. The scheme uses a probabilistic photon pair source
pumped with a CW laser, whereby a rapid gating InGaAs/InP single photon
avalanche diode provides a synchronous clock and temporally resolves, and hence
spectrally filters, the heralded photons. We demonstrate the concept by
combining this with a narrow-band integrated silicon nitride photon-pair
source. This simple architecture is capable of heralding photons with high
spectral purity in the telecom band, but could be adapted to other wavelengths
and bandwidth regimes.

</details>


### [326] [Theory of Multi-photon Processes for Applications in Quantum Control](https://arxiv.org/abs/2509.16074)
*Longxiang Huang,Jacquelin Luneau,Johannes Schirk,Florian Wallner,Christian M. F. Schneider,Stefan Filipp,Klaus Liegener,Peter Rabl*

Main category: quant-ph

TL;DR: 提出一个评估周期性驱动的量子系统中多光子过程的通用理论框架，并使用退化的 Floquet 摄动理论和多光子过程的图示表示来系统地评估驱动量子系统的有效动力学。


<details>
  <summary>Details</summary>
Motivation: 多光子过程在量子技术平台中用于工程和控制非平凡相互作用，需要精确确定有效耦合率和由驱动引起的频率偏移。

Method: 使用退化的 Floquet 摄动理论和多光子过程的图示表示，开发一种系统且可自动化的方法，以任意阶的驱动强度评估驱动量子系统的有效动力学。

Result: 将该框架应用于超导通量量子比特中的多光子拉比振荡，理论预测与精确数值模拟在先前已知方法不再适用的参数范围内也表现出极好的一致性。

Conclusion: 所提出的理论框架在评估多光子过程中是有效且精确的，即使在先前方法不再适用的情况下也是如此。

Abstract: We present a general theoretical framework for evaluating multi-photon
processes in periodically driven quantum systems, which have been identified as
a versatile tool for engineering and controlling nontrivial interactions in
various quantum technology platforms. To achieve the accuracy required for such
applications, the resulting effective coupling rates, as well as any
drive-induced frequency shifts, must be determined with very high precision.
Here, we employ degenerate Floquet perturbation theory together with a
diagrammatic representation of multi-photon processes to develop a systematic
and automatable approach for evaluating the effective dynamics of driven
quantum systems to arbitrary orders in the drive strength. As a specific
example, we demonstrate the effectiveness of this framework by applying it to
the study of multi-photon Rabi oscillations in a superconducting fluxonium
qubit, finding excellent agreement between our theoretical predictions and
exact numerical simulations, even in parameter regimes where previously known
methods are no longer applicable.

</details>


### [327] [Effects of time dependence in the second order coherence of pulsed light](https://arxiv.org/abs/2509.16090)
*Joscelyn van der Veen,Daniel James*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: For light in a single temporal mode, the time dependence is associated
entirely with the deterministic pulse shape rather than the quantum state. This
means the second order coherence of light can no longer be understood as the
temporal distribution of photons. We calculate the distribution of photon
arrival time differences for pulsed light and find that it is inherently
strongly bunched in terms of photocount arrival time differences. We further
show how to account for the pulse shape when determining the second order
coherence that characterizes quantum states.

</details>


### [328] [Frequency shifts due to relativistic effects and retardation in continuous variable quantum key distribution](https://arxiv.org/abs/2509.16164)
*Emanuel Schlake,Jan P. Hackstein,Roy Barzel,Eva Hackmann,Dennis Rätzel,Claus Lämmerzahl*

Main category: quant-ph

TL;DR: 文章研究了卫星与地面站进行量子通信时的频率偏移问题，发现相对论效应和信号延迟效应显著影响通信性能。


<details>
  <summary>Details</summary>
Motivation: 太空量子通信涉及卫星与地面站之间的高速光信号交换，需要考虑相对论效应。

Method: 分析了频率偏移的各项贡献，包括多普勒频移、相对论修正和信号延迟修正，并研究了这些效应对比特率的影响。

Result: 相对论修正对轨道的影响可忽略，但时间膨胀和信号延迟效应与相对论贡献相当，显著影响通信性能。

Conclusion: 在太空量子通信中，必须考虑相对论效应和信号延迟效应，因为它们会显著影响通信性能。

Abstract: Space-based quantum communication naturally involves satellites and ground
stations exchanging optical signals at high altitudes and large relative
velocities. Starting from general relativistic considerations, we
systematically separate the frequency shift into longitudinal Doppler
contributions, relativistic corrections, and corrections from the propagation
delay (retardation). We find the relativistic corrections to the Keplerian
satellite orbits to be negligible on the considered timescale, compared to the
gravitational and special relativistic time dilation contributions to the
frequency shift. Somewhat surprisingly, we find the contribution from the
retardation effect to be on the same order of magnitude as the relativistic
contributions. To analyze the significance of these effects, we investigate
secret key rates for a continuous variable quantum key distribution protocol
for various configurations of satellite orbits and ground stations. We find
that the corrections from relativistic effects and retardation significantly
impact the communication performance and should be taken into account.

</details>


### [329] [Sequential analysis in a continuous spin-noise quantum sensor](https://arxiv.org/abs/2509.16177)
*Elisabet Roda-Salichs,Giulio Gasbarri,Antoni Alou,Michalis Skotiniotis,Aleksandra Sierant,Diana Méndez-Avalos,Morgan W. Mitchell,John Calsamiglia*

Main category: quant-ph

TL;DR: 该研究提出并实现了一种基于量子传感器的序贯数据分析技术，用于实时、高精度地检测弱磁场。


<details>
  <summary>Details</summary>
Motivation: 控制和检测应用需要对传感器信号进行实时分析，这需要计算高效且符合因果关系的数据分析方法，以模型为基础，并且仅使用特定时间点之前可用的传感器数据。

Method: 在基于自旋噪声的量子传感器上实现序贯数据分析技术，执行假设检验和检测最快变化点。通过自适应地收集测量数据，直到达到预定义的置信阈值来检测弱磁场。

Result: 在真实的实验环境中演示了该方法，并推导了可实现精度和响应时间的性能边界。结果表明，序贯技术能够实现更快、更灵敏的检测。

Conclusion: 序贯数据分析技术是量子传感的有力工具，能够实现更快速、更灵敏的检测，在生物磁学、地球物理勘探、隐藏材料探测、暗物质搜寻和奇异自旋相互作用等领域具有潜在应用价值。

Abstract: Many control and detection applications require real-time analysis of signals
from sensors, in order to quickly and accurately act upon events revealed by
the sensors. Such signal analysis benefits from statistical models of signal
and sensor behavior. This creates a need for data analysis methods that are
simultaneously model-based, computationally efficient and causal, in the sense
that they employ only sensor data available prior to a specific point in time.
In this work, we implement sequential data analysis techniques on a
spin-noise-based quantum sensor, to perform two key tasks: hypothesis testing
and quickest change-point detection. These online protocols allow us to detect
weak magnetic fields by adaptively collecting measurement data until a
predefined confidence threshold is reached. We demonstrate these methods in a
realistic experimental setting and derive performance bounds for the achievable
precision and response time. Our approach has potential utility when detecting
small perturbations to the magnetic field, in both applied and fundamental
contexts including biomagnetism, geophysical surveys, detection of concealed
materials, searches for dark matter candidates and exotic spin interactions.
Our results demonstrate that sequential techniques enable faster and more
sensitive detection, making them a powerful tool for quantum sensing.

</details>


### [330] [Quantum Generative Adversarial Autoencoders: Learning latent representations for quantum data generation](https://arxiv.org/abs/2509.16186)
*Naipunnya Raj,Rajiv Sangle,Avinash Singh,Krishna Kumar Sabapathy*

Main category: quant-ph

TL;DR: 一个名为QGAA的量子模型，用于生成量子数据，它结合了量子自编码器（QAE）和量子生成对抗网络（QGAN），能够生成纯纠缠态和分子基态。


<details>
  <summary>Details</summary>
Motivation: 为了生成量子数据，并赋予量子自编码器（QAE）生成能力。

Method: 提出并实现了一种名为量子生成对抗自编码器（QGAA）的量子模型，该模型由量子自编码器（QAE）和量子生成对抗网络（QGAN）组成。

Result: 在H2和LiH分子基态生成任务中，平均能量估计误差在6量子比特模拟中分别达到了0.02和0.06哈特里，并成功生成了纯纠缠态。

Conclusion: QGAA在量子态生成、量子化学和近期量子机器学习应用方面显示出巨大潜力。

Abstract: In this work, we introduce the Quantum Generative Adversarial Autoencoder
(QGAA), a quantum model for generation of quantum data. The QGAA consists of
two components: (a) Quantum Autoencoder (QAE) to compress quantum states, and
(b) Quantum Generative Adversarial Network (QGAN) to learn the latent space of
the trained QAE. This approach imparts the QAE with generative capabilities.
The utility of QGAA is demonstrated in two representative scenarios: (a)
generation of pure entangled states, and (b) generation of parameterized
molecular ground states for H$_2$ and LiH. The average errors in the energies
estimated by the trained QGAA are 0.02 Ha for H$_2$ and 0.06 Ha for LiH in
simulations upto 6 qubits. These results illustrate the potential of QGAA for
quantum state generation, quantum chemistry, and near-term quantum machine
learning applications.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [331] [Hierarchical Self-Attention: Generalizing Neural Attention Mechanics to Multi-Scale Problems](https://arxiv.org/abs/2509.15448)
*Saeed Amizadeh,Sara Abdali,Yinheng Li,Kazuhito Koishida*

Main category: cs.LG

TL;DR: 文章提出了一个数学模型来处理多模态、多尺度数据，并从中推导出一种新的注意力机制，该机制通过熵最小化原则，能够融合层级和多模态信息，同时保持与Softmax attention的相似性。


<details>
  <summary>Details</summary>
Motivation: 现有的Transformer模型在处理多尺度、多模态数据时存在泛化能力不足的问题，现有的方法多是基于启发式规则，不够通用。

Method: 提出一个数学构造来表示多模态、多尺度数据，并从熵最小化原理推导出新的神经网络注意力机制。提出一种基于动态规划的高效算法来计算注意力机制。

Result: 将新的注意力机制集成到Transformer模型中，实验证明该模型可以从头开始训练，也可以在预训练模型上进行微调，以注入层级信息，从而提高模型的效率，尤其是在零样本学习场景下。

Conclusion: 提出的层级注意力机制能够有效地处理多模态、多尺度数据，并能通过注入层级信息来提升Transformer模型的性能和效率。

Abstract: Transformers and their attention mechanism have been revolutionary in the
field of Machine Learning. While originally proposed for the language data,
they quickly found their way to the image, video, graph, etc. data modalities
with various signal geometries. Despite this versatility, generalizing the
attention mechanism to scenarios where data is presented at different scales
from potentially different modalities is not straightforward. The attempts to
incorporate hierarchy and multi-modality within transformers are largely based
on ad hoc heuristics, which are not seamlessly generalizable to similar
problems with potentially different structures. To address this problem, in
this paper, we take a fundamentally different approach: we first propose a
mathematical construct to represent multi-modal, multi-scale data. We then
mathematically derive the neural attention mechanics for the proposed construct
from the first principle of entropy minimization. We show that the derived
formulation is optimal in the sense of being the closest to the standard
Softmax attention while incorporating the inductive biases originating from the
hierarchical/geometric information of the problem. We further propose an
efficient algorithm based on dynamic programming to compute our derived
attention mechanism. By incorporating it within transformers, we show that the
proposed hierarchical attention mechanism not only can be employed to train
transformer models in hierarchical/multi-modal settings from scratch, but it
can also be used to inject hierarchical information into classical, pre-trained
transformer models post training, resulting in more efficient models in
zero-shot manner.

</details>


### [332] [Instance Generation for Meta-Black-Box Optimization through Latent Space Reverse Engineering](https://arxiv.org/abs/2509.15810)
*Chen Wang,Zeyuan Ma,Zhiguang Cao,Yue-Jiao Gong*

Main category: cs.LG

TL;DR: MetaBBO研究使用元学习训练基于神经网络的算法设计策略，但现有方法在CoCo-BBOB基准测试集上可能存在泛化能力不足的问题。本文提出了一种名为LSRE的实例生成方法，用于生成多样化的训练问题实例Diverse-BBO，以提高MetaBBOs的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有MetaBBO研究中使用的CoCo-BBOB基准测试集在多样性方面存在局限，可能导致MetaBBOs过拟合，泛化能力下降。

Method: LSRE方法首先训练一个自编码器将高维问题特征映射到二维潜在空间，然后在该空间进行均匀网格采样，并通过遗传编程搜索函数公式，生成多样化的Diverse-BBO问题集。

Result: 在Diverse-BBO上训练的MetaBBOs在合成和现实场景中表现出更优越的泛化性能，实验结果优于现有的训练集选择。

Conclusion: LSRE方法生成的Diverse-BBO问题集能够有效提高MetaBBOs的泛化能力，并且在消融研究中验证了LSRE设计选择的有效性，同时揭示了实例多样性与MetaBBO泛化能力之间的关系。

Abstract: To relieve intensive human-expertise required to design optimization
algorithms, recent Meta-Black-Box Optimization (MetaBBO) researches leverage
generalization strength of meta-learning to train neural network-based
algorithm design policies over a predefined training problem set, which
automates the adaptability of the low-level optimizers on unseen problem
instances. Currently, a common training problem set choice in existing MetaBBOs
is well-known benchmark suites CoCo-BBOB. Although such choice facilitates the
MetaBBO's development, problem instances in CoCo-BBOB are more or less limited
in diversity, raising the risk of overfitting of MetaBBOs, which might further
results in poor generalization. In this paper, we propose an instance
generation approach, termed as \textbf{LSRE}, which could generate diverse
training problem instances for MetaBBOs to learn more generalizable policies.
LSRE first trains an autoencoder which maps high-dimensional problem features
into a 2-dimensional latent space. Uniform-grid sampling in this latent space
leads to hidden representations of problem instances with sufficient diversity.
By leveraging a genetic-programming approach to search function formulas with
minimal L2-distance to these hidden representations, LSRE reverse engineers a
diversified problem set, termed as \textbf{Diverse-BBO}. We validate the
effectiveness of LSRE by training various MetaBBOs on Diverse-BBO and observe
their generalization performances on either synthetic or realistic scenarios.
Extensive experimental results underscore the superiority of Diverse-BBO to
existing training set choices in MetaBBOs. Further ablation studies not only
demonstrate the effectiveness of design choices in LSRE, but also reveal
interesting insights on instance diversity and MetaBBO's generalization.

</details>


### [333] [Solar Forecasting with Causality: A Graph-Transformer Approach to Spatiotemporal Dependencies](https://arxiv.org/abs/2509.15481)
*Yanan Niu,Demetri Psaltis,Christophe Moser,Luisa Lambertini*

Main category: cs.LG

TL;DR: SolarCAST是一个利用历史太阳光照数据预测未来太阳光照的因果模型，无需依赖昂贵的设备或复杂的预处理，相比现有方法提高了预测精度。


<details>
  <summary>Details</summary>
Motivation: 准确的太阳能预测对于有效的可再生能源管理至关重要，而现有方法依赖专业硬件和大量预处理。

Method: SolarCAST使用可扩展的神经网络组件来模拟三种混淆因素：可观测的同步变量（时间、站点标识）、潜在的同步因素（区域天气模式）和滞后影响（云层移动），分别使用嵌入模块、时空图神经网络和门控Transformer进行建模。

Result: SolarCAST在各种地理条件下均优于领先的时间序列和多模态基线模型，其错误率比领先的商业预测器Solcast低25.9%。

Conclusion: SolarCAST提供了一种轻量级、实用且通用的本地化太阳能预测解决方案。

Abstract: Accurate solar forecasting underpins effective renewable energy management.
We present SolarCAST, a causally informed model predicting future global
horizontal irradiance (GHI) at a target site using only historical GHI from
site X and nearby stations S - unlike prior work that relies on sky-camera or
satellite imagery requiring specialized hardware and heavy preprocessing. To
deliver high accuracy with only public sensor data, SolarCAST models three
classes of confounding factors behind X-S correlations using scalable neural
components: (i) observable synchronous variables (e.g., time of day, station
identity), handled via an embedding module; (ii) latent synchronous factors
(e.g., regional weather patterns), captured by a spatio-temporal graph neural
network; and (iii) time-lagged influences (e.g., cloud movement across
stations), modeled with a gated transformer that learns temporal shifts. It
outperforms leading time-series and multimodal baselines across diverse
geographical conditions, and achieves a 25.9% error reduction over the top
commercial forecaster, Solcast. SolarCAST offers a lightweight, practical, and
generalizable solution for localized solar forecasting.

</details>


### [334] [Inference Offloading for Cost-Sensitive Binary Classification at the Edge](https://arxiv.org/abs/2509.15674)
*Vishnu Narayanan Moothedath,Umang Agarwal,Umeshraja N,James Richard Gross,Jaya Prakash Champati,Sharayu Moharir*

Main category: cs.LG

TL;DR: 该研究提出了一种在线学习框架H2T2，用于在边缘智能系统中优化分层推理（HI）的准确性和卸载成本之间的权衡，即使在模型未校准的情况下也能实现次线性遗憾。


<details>
  <summary>Details</summary>
Motivation: 在边缘智能系统中，二元分类错误与成本不对称（假阴性比假阳性更昂贵），且推理涉及本地模型和通过网络访问的远程模型，存在卸载成本。本研究旨在理解分层推理（HI）系统中分类准确性与卸载成本之间的基本权衡。

Method: 提出一种在线学习框架，通过自适应地调整本地模型置信度分数的阈值对来优化HI系统。阈值决定了本地预测和是否将样本卸载到远程模型。对于已校准模型，提供了一个封闭解；对于未校准模型，提出了H2T2策略，证明其具有次线性遗憾，且该策略是模型无关、无需训练、在推理阶段利用有限反馈进行学习的。

Result: H2T2策略被证明具有次线性遗憾，并且在模拟中表现优于朴素和单阈值HI策略，有时甚至优于离线最优值。该策略还表现出对分布变化的鲁棒性，并能有效适应不匹配的分类器。

Conclusion: H2T2是一种有效的在线学习策略，能够解决边缘智能系统中分层推理的挑战，在准确性和成本之间取得良好平衡，并具有良好的适应性和鲁棒性。

Abstract: We focus on a binary classification problem in an edge intelligence system
where false negatives are more costly than false positives. The system has a
compact, locally deployed model, which is supplemented by a larger, remote
model, which is accessible via the network by incurring an offloading cost. For
each sample, our system first uses the locally deployed model for inference.
Based on the output of the local model, the sample may be offloaded to the
remote model. This work aims to understand the fundamental trade-off between
classification accuracy and these offloading costs within such a hierarchical
inference (HI) system. To optimize this system, we propose an online learning
framework that continuously adapts a pair of thresholds on the local model's
confidence scores. These thresholds determine the prediction of the local model
and whether a sample is classified locally or offloaded to the remote model. We
present a closed-form solution for the setting where the local model is
calibrated. For the more general case of uncalibrated models, we introduce
H2T2, an online two-threshold hierarchical inference policy, and prove it
achieves sublinear regret. H2T2 is model-agnostic, requires no training, and
learns in the inference phase using limited feedback. Simulations on real-world
datasets show that H2T2 consistently outperforms naive and single-threshold HI
policies, sometimes even surpassing offline optima. The policy also
demonstrates robustness to distribution shifts and adapts effectively to
mismatched classifiers.

</details>


### [335] [FedHK-MVFC: Federated Heat Kernel Multi-View Clustering](https://arxiv.org/abs/2509.15844)
*Kristina P. Sinaga*

Main category: cs.LG

TL;DR: 本研究提出了一种结合量子场论和联邦医疗分析的多视图聚类框架，使用热核系数进行几何感知相似性度量，并开发了集中式和联邦式算法，旨在提高聚类准确性、降低通信成本并保护隐私。


<details>
  <summary>Details</summary>
Motivation: 在分布式人工智能和注重隐私的医疗应用领域，需要一种能够整合不同数据源并保护患者隐私的分析框架。

Method: 提出了一种基于量子场论和热核距离（HKD）变换的多视图聚类框架。开发了两种算法：Heat Kernel-Enhanced Multi-View Fuzzy Clustering (HK-MVFC) 用于集中式分析，以及 Federated Heat Kernel Multi-View Fuzzy Clustering (FedHK-MVFC) 用于隐私保护的联邦学习，结合了差分隐私和安全聚合技术。

Result: 在合成心血管病患者数据集上，聚类准确率提高了 8-12%，通信成本降低了 70%，效率保留了 98.2%。在 10,000 条真实患者记录（包括 ECG、心脏成像和行为数据）上进行了验证，证明了其在协作表型分析中的有效性。

Conclusion: 该框架为医疗保健领域中的几何感知联邦学习树立了新的标准，能够将高级数学概念转化为处理敏感医疗数据的实用解决方案，同时保证了严谨性和临床相关性。其理论贡献包括具有可证明收敛性的更新规则、自适应视图权重和隐私保护协议。

Abstract: In the realm of distributed AI and privacy-focused medical applications, we
propose a framework for multi-view clustering that links quantum field theory
with federated healthcare analytics. Our method uses heat-kernel coefficients
from spectral analysis to convert Euclidean distances into geometry-aware
similarity measures, capturing the structure of diverse medical data. We lay
this out through the Heat Kernel Distance (HKD) transformation with convergence
guarantees. Two algorithms are developed: Heat Kernel-Enhanced Multi-View Fuzzy
Clustering (HK-MVFC) for central analysis, and Federated Heat Kernel Multi-View
Fuzzy Clustering (FedHK-MVFC) for secure, privacy-preserving learning across
hospitals using differential privacy and secure aggregation to facilitate
HIPAA-compliant collaboration. Tests on synthetic datasets of cardiovascular
patients show an $8-12 \%$ increase in clustering accuracy, $70 \%$ reduced
communication, and $98.2 \%$ efficiency retention over centralized methods.
Validated on 10,000 patient records across two hospitals, it proves useful for
collaborative phenotyping involving ECG, cardiac imaging, and behavioral data.
Our theoretical contributions include update rules with proven convergence,
adaptive view weighting, and privacy-preserving protocols. This presents a new
standard for geometry-aware federated learning in healthcare, turning advanced
math into workable solutions for analyzing sensitive medical data while
ensuring both rigor and clinical relevance.

</details>


### [336] [ToFU: Transforming How Federated Learning Systems Forget User Data](https://arxiv.org/abs/2509.15861)
*Van-Tuan Tran,Hong-Hanh Nguyen-Le,Quoc-Viet Pham*

Main category: cs.LG

TL;DR: 在联邦学习（FL）中，神经网络会无意中记住训练数据，带来隐私风险。为了解决这个问题，我们提出了一个名为ToFU（Transformation-guided Federated Unlearning）的框架，通过在学习过程中引入变换来减少对特定实例的记忆，从而使模型更容易被“遗忘”。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）中的神经网络会记住训练数据，这带来了隐私风险，如推断和重建敏感数据。现有的联邦学习（FU）方法通常在事后进行，难以高效地擦除神经网络中深度记忆的信息。

Method: ToFU框架在学习过程中引入变换，以减少对特定实例的记忆。理论分析表明，变换组合可以证明实例特定的信息界限，从而简化后续的遗忘过程。ToFU可以即插即用，并能改进现有FU方法的性能。

Result: 在CIFAR-10、CIFAR-100和MUFAC基准测试中，ToFU的性能优于现有的FU基线方法，与现有方法结合使用时能提升性能，并减少遗忘时间。

Conclusion: ToFU通过在学习过程中引入变换，为联邦学习提供了一种更有效、更易于遗忘的方法，解决了现有FU方法难以擦除深度记忆的问题。

Abstract: Neural networks unintentionally memorize training data, creating privacy
risks in federated learning (FL) systems, such as inference and reconstruction
attacks on sensitive data. To mitigate these risks and to comply with privacy
regulations, Federated Unlearning (FU) has been introduced to enable
participants in FL systems to remove their data's influence from the global
model. However, current FU methods primarily act post-hoc, struggling to
efficiently erase information deeply memorized by neural networks. We argue
that effective unlearning necessitates a paradigm shift: designing FL systems
inherently amenable to forgetting. To this end, we propose a
learning-to-unlearn Transformation-guided Federated Unlearning (ToFU) framework
that incorporates transformations during the learning process to reduce
memorization of specific instances. Our theoretical analysis reveals how
transformation composition provably bounds instance-specific information,
directly simplifying subsequent unlearning. Crucially, ToFU can work as a
plug-and-play framework that improves the performance of existing FU methods.
Experiments on CIFAR-10, CIFAR-100, and the MUFAC benchmark show that ToFU
outperforms existing FU baselines, enhances performance when integrated with
current methods, and reduces unlearning time.

</details>


### [337] [RLinf: Flexible and Efficient Large-scale Reinforcement Learning via Macro-to-Micro Flow Transformation](https://arxiv.org/abs/2509.15965)
*Chao Yu,Yuanqing Wang,Zhen Guo,Hao Lin,Si Xu,Hongzhi Zang,Quanlu Zhang,Yongji Wu,Chunyang Zhu,Junhao Hu,Zixiao Huang,Mingjie Wei,Yuqing Xie,Ke Yang,Bo Dai,Zhexuan Xu,Xiangyuan Wang,Xu Fu,Zhihao Liu,Kang Chen,Weilin Liu,Gang Liu,Boxun Li,Jianlei Yang,Zhi Yang,Guohao Dai,Yu Wang*

Main category: cs.LG

TL;DR: RLinf是一个高性能强化学习训练系统，通过M2Flow设计范式将高层RL工作流分解并重组为优化执行流，实现了1.1x-2.13x的训练加速。


<details>
  <summary>Details</summary>
Motivation: 强化学习（RL）在通用人工智能、主体智能和具身智能方面潜力巨大，但现有系统在处理RL工作流的异构性和动态性时存在硬件利用率低和训练速度慢的问题。

Method: RLinf基于宏到微流转换（M2Flow）设计范式，该范式自动在时间和空间维度上分解RL工作流，并重组为优化的执行流。该系统利用RLinf worker的自适应通信能力，实现了上下文切换和弹性流水线，并通过配置分析指导的调度策略来生成最优执行计划。

Result: 在推理RL和具身RL任务上的广泛评估表明，RLinf的端到端训练吞吐量持续优于最先进的系统，实现了1.1x-2.13x的加速。

Conclusion: RLinf通过其创新的M2Flow设计和优化的执行策略，解决了现有RL训练系统效率低下的问题，显著提高了训练速度和硬件利用率。

Abstract: Reinforcement learning (RL) has demonstrated immense potential in advancing
artificial general intelligence, agentic intelligence, and embodied
intelligence. However, the inherent heterogeneity and dynamicity of RL
workflows often lead to low hardware utilization and slow training on existing
systems. In this paper, we present RLinf, a high-performance RL training system
based on our key observation that the major roadblock to efficient RL training
lies in system flexibility. To maximize flexibility and efficiency, RLinf is
built atop a novel RL system design paradigm called macro-to-micro flow
transformation (M2Flow), which automatically breaks down high-level,
easy-to-compose RL workflows at both the temporal and spatial dimensions, and
recomposes them into optimized execution flows. Supported by RLinf worker's
adaptive communication capability, we devise context switching and elastic
pipelining to realize M2Flow transformation, and a profiling-guided scheduling
policy to generate optimal execution plans. Extensive evaluations on both
reasoning RL and embodied RL tasks demonstrate that RLinf consistently
outperforms state-of-the-art systems, achieving 1.1x-2.13x speedup in
end-to-end training throughput.

</details>


### [338] [Pre-Forgettable Models: Prompt Learning as a Native Mechanism for Unlearning](https://arxiv.org/abs/2509.15230)
*Rutger Hendrix,Giovanni Patanè,Leonardo G. Russo,Simone Carnemolla,Giovanni Bellitto,Federica Proietto Salanitri,Concetto Spampinato,Matteo Pennisi*

Main category: cs.LG

TL;DR: 本研究提出了一种基于提示的学习框架，将知识获取和移除统一在单一训练阶段，通过移除对应提示词实现即时遗忘，无需重新训练或访问原始数据，并能抵抗成员推理攻击，满足隐私和安全要求。


<details>
  <summary>Details</summary>
Motivation: 现有模型在移除特定数据时面临计算成本高、效率低下和不适于实时系统的挑战，需要一种更高效、更安全的数据遗忘方法。

Method: 将知识绑定到专门的提示词（prompt tokens）上，而非模型权重中，实现知识的即时移除（通过删除对应提示词）。

Result: 实验证明，该框架在保留原有类别的预测性能的同时，能有效移除遗忘的类别，并且对成员推理攻击具有抵抗力，能防止知识被提取。

Conclusion: 通过将可移除性嵌入模型架构，本研究为设计模块化、可扩展且符合伦理的AI模型奠定了新基础，适用于敏感和受监管环境。

Abstract: Foundation models have transformed multimedia analysis by enabling robust and
transferable representations across diverse modalities and tasks. However,
their static deployment conflicts with growing societal and regulatory demands
-- particularly the need to unlearn specific data upon request, as mandated by
privacy frameworks such as the GDPR. Traditional unlearning approaches,
including retraining, activation editing, or distillation, are often
computationally expensive, fragile, and ill-suited for real-time or
continuously evolving systems. In this paper, we propose a paradigm shift:
rethinking unlearning not as a retroactive intervention but as a built-in
capability. We introduce a prompt-based learning framework that unifies
knowledge acquisition and removal within a single training phase. Rather than
encoding information in model weights, our approach binds class-level semantics
to dedicated prompt tokens. This design enables instant unlearning simply by
removing the corresponding prompt -- without retraining, model modification, or
access to original data. Experiments demonstrate that our framework preserves
predictive performance on retained classes while effectively erasing forgotten
ones. Beyond utility, our method exhibits strong privacy and security
guarantees: it is resistant to membership inference attacks, and prompt removal
prevents any residual knowledge extraction, even under adversarial conditions.
This ensures compliance with data protection principles and safeguards against
unauthorized access to forgotten information, making the framework suitable for
deployment in sensitive and regulated environments. Overall, by embedding
removability into the architecture itself, this work establishes a new
foundation for designing modular, scalable and ethically responsive AI models.

</details>


### [339] [Personalized Federated Learning with Heat-Kernel Enhanced Tensorized Multi-View Clustering](https://arxiv.org/abs/2509.16101)
*Kristina P. Sinaga*

Main category: cs.LG

TL;DR: 该研究提出了一种结合热核、张量化、多视图模糊 C 均值聚类和张量分解的个性化联邦学习框架。


<details>
  <summary>Details</summary>
Motivation: 为了解决高维多视图数据的表示和分析挑战，并实现高效、隐私保护的联邦学习。

Method: 框架整合了热核系数、Tucker 分解和 CANDECOMP/PARAFAC 分解，利用张量化、矩阵化和向量化技术来表示高维多视图结构。通过双层优化方案，包括本地热核增强模糊聚类和张量分解，以及带有隐私保护的个性化机制的联邦聚合。本地阶段使用张量化核欧氏距离变换和 Tucker 分解来发现客户端特定的模式，而全局聚合过程通过差分隐私保护协议协调客户端之间的张量因子。

Result: 该方法能够有效地处理高维多视图数据，并通过低秩张量近似实现显著的通信节省。

Conclusion: 该个性化联邦学习框架通过创新的张量分解技术，实现了对高维多视图数据的有效表示和分析，同时保证了通信效率和隐私保护。

Abstract: We present a robust personalized federated learning framework that leverages
heat-kernel enhanced tensorized multi-view fuzzy c-means clustering with
advanced tensor decomposition techniques. Our approach integrates heat-kernel
coefficients adapted from quantum field theory with Tucker decomposition and
canonical polyadic decomposition (CANDECOMP/PARAFAC) to transform conventional
distance metrics and efficiently represent high-dimensional multi-view
structures. The framework employs matriculation and vectorization techniques to
facilitate the discovery of hidden structures and multilinear relationships via
N-way generalized tensors. The proposed method introduces a dual-level
optimization scheme: local heat-kernel enhanced fuzzy clustering with tensor
decomposition operating on order-N input tensors, and federated aggregation of
tensor factors with privacy-preserving personalization mechanisms. The local
stage employs tensorized kernel Euclidean distance transformations and Tucker
decomposition to discover client-specific patterns in multi-view tensor data,
while the global aggregation process coordinates tensor factors (core tensors
and factor matrices) across clients through differential privacy-preserving
protocols. This tensorized approach enables efficient handling of
high-dimensional multi-view data with significant communication savings through
low-rank tensor approximations.

</details>


### [340] [A Multi-Scale Graph Neural Process with Cross-Drug Co-Attention for Drug-Drug Interactions Prediction](https://arxiv.org/abs/2509.15256)
*Zimo Yan,Jie Zhang,Zheng Xie,Yiping Song,Hao Li*

Main category: cs.LG

TL;DR: MPNP-DDI是一个新的多尺度图神经过程框架，用于准确预测药物-药物相互作用（DDI），并量化预测置信度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在捕捉跨不同尺度的结构信息方面存在困难，并且缺乏量化预测置信度的机制。

Method: MPNP-DDI采用独特的消息传递方案学习多尺度图表示，并通过跨药物共注意力机制融合这些表示，同时利用神经过程模块进行不确定性估计。

Result: MPNP-DDI在基准数据集上显著优于最先进的基线方法。

Conclusion: MPNP-DDI通过提供准确、可泛化且基于不确定性的预测，成为药物警戒、多重用药风险评估和精准医疗的有力计算工具。

Abstract: Accurate prediction of drug-drug interactions (DDI) is crucial for medication
safety and effective drug development. However, existing methods often struggle
to capture structural information across different scales, from local
functional groups to global molecular topology, and typically lack mechanisms
to quantify prediction confidence. To address these limitations, we propose
MPNP-DDI, a novel Multi-scale Graph Neural Process framework. The core of
MPNP-DDI is a unique message-passing scheme that, by being iteratively applied,
learns a hierarchy of graph representations at multiple scales. Crucially, a
cross-drug co-attention mechanism then dynamically fuses these multi-scale
representations to generate context-aware embeddings for interacting drug
pairs, while an integrated neural process module provides principled
uncertainty estimation. Extensive experiments demonstrate that MPNP-DDI
significantly outperforms state-of-the-art baselines on benchmark datasets. By
providing accurate, generalizable, and uncertainty-aware predictions built upon
multi-scale structural features, MPNP-DDI represents a powerful computational
tool for pharmacovigilance, polypharmacy risk assessment, and precision
medicine.

</details>


### [341] [Generative AI Meets Wireless Sensing: Towards Wireless Foundation Model](https://arxiv.org/abs/2509.15258)
*Zheng Yang,Guoxuan Chi,Chenshu Wu,Hanyu Liu,Yuchong Gao,Yunhao Liu,Jie Xu,Tony Xiao Han*

Main category: cs.LG

TL;DR: 生成式人工智能（GenAI）在无线传感领域的应用日益受到关注，本综述探讨了GenAI如何通过数据增强、域适应和去噪等技术来改进设备定位、人体活动识别和环境监测等无线传感应用。


<details>
  <summary>Details</summary>
Motivation: 整合生成式人工智能（GenAI）到无线传感系统以提升其性能和应用范围。

Method: 从两个角度探讨GenAI与无线传感的融合：1. 将GenAI作为插件增强任务特定模型或作为求解器直接解决传感任务。2. 分析主流生成模型（GANs、VAEs、扩散模型）的特性及其在无线传感任务中的适用性。

Result: GenAI在增强无线传感模型、改进定位、活动识别和环境监测方面展现出巨大潜力。不同生成模型各有优势，适用于不同任务。

Conclusion: GenAI在无线传感领域具有广阔的应用前景，未来研究方向包括开发能够处理多样化传感任务的统一、预训练的无线基础模型。

Abstract: Generative Artificial Intelligence (GenAI) has made significant advancements
in fields such as computer vision (CV) and natural language processing (NLP),
demonstrating its capability to synthesize high-fidelity data and improve
generalization. Recently, there has been growing interest in integrating GenAI
into wireless sensing systems. By leveraging generative techniques such as data
augmentation, domain adaptation, and denoising, wireless sensing applications,
including device localization, human activity recognition, and environmental
monitoring, can be significantly improved. This survey investigates the
convergence of GenAI and wireless sensing from two complementary perspectives.
First, we explore how GenAI can be integrated into wireless sensing pipelines,
focusing on two modes of integration: as a plugin to augment task-specific
models and as a solver to directly address sensing tasks. Second, we analyze
the characteristics of mainstream generative models, such as Generative
Adversarial Networks (GANs), Variational Autoencoders (VAEs), and diffusion
models, and discuss their applicability and unique advantages across various
wireless sensing tasks. We further identify key challenges in applying GenAI to
wireless sensing and outline a future direction toward a wireless foundation
model: a unified, pre-trained design capable of scalable, adaptable, and
efficient signal understanding across diverse sensing tasks.

</details>


### [342] [IEFS-GMB: Gradient Memory Bank-Guided Feature Selection Based on Information Entropy for EEG Classification of Neurological Disorders](https://arxiv.org/abs/2509.15259)
*Liang Zhang,Hanyang Dong,Jia-Hong Gao,Yi Sun,Kuntao Xiao,Wanli Yang,Zhao Lv,Shurong Sheng*

Main category: cs.LG

TL;DR: 该研究提出了一种名为IEFS-GMB的基于信息熵和梯度记忆银行的特征选择方法，用于改善基于深度学习的脑电图（EEG）分类在神经系统疾病诊断中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的脑电图特征选择方法在设计上并非专门针对脑电图诊断，并且存在依赖特定模型、可解释性差、以及仅使用单次迭代数据导致鲁棒性不足等问题。

Method: IEFS-GMB方法通过构建一个动态的梯度记忆银行来存储历史梯度信息，并利用信息熵来计算特征重要性，最后通过熵基加权来选择信息丰富的EEG特征。

Result: 在四个公开的神经系统疾病数据集上的实验表明，使用IEFS-GMB增强的编码器相比基线模型，准确率提升了0.64%至6.45%。

Conclusion: IEFS-GMB方法在提高模型准确性和可解释性方面表现优于四种竞争性特征选择技术，证明了其在临床环境中的实用价值。

Abstract: Deep learning-based EEG classification is crucial for the automated detection
of neurological disorders, improving diagnostic accuracy and enabling early
intervention. However, the low signal-to-noise ratio of EEG signals limits
model performance, making feature selection (FS) vital for optimizing
representations learned by neural network encoders. Existing FS methods are
seldom designed specifically for EEG diagnosis; many are architecture-dependent
and lack interpretability, limiting their applicability. Moreover, most rely on
single-iteration data, resulting in limited robustness to variability. To
address these issues, we propose IEFS-GMB, an Information Entropy-based Feature
Selection method guided by a Gradient Memory Bank. This approach constructs a
dynamic memory bank storing historical gradients, computes feature importance
via information entropy, and applies entropy-based weighting to select
informative EEG features. Experiments on four public neurological disease
datasets show that encoders enhanced with IEFS-GMB achieve accuracy
improvements of 0.64% to 6.45% over baseline models. The method also
outperforms four competing FS techniques and improves model interpretability,
supporting its practical use in clinical settings.

</details>


### [343] [A Weak Supervision Approach for Monitoring Recreational Drug Use Effects in Social Media](https://arxiv.org/abs/2509.15266)
*Lucía Prieto-Santamaría,Alba Cortés Iglesias,Claudio Vidal Giné,Fermín Fernández Calderón,Óscar M. Lozano,Alejandro Rodríguez-González*

Main category: cs.LG

TL;DR: 本研究利用推特数据分析了摇头丸、GHB 和 2C-B 这三种新兴精神活性物质的用户体验和影响。


<details>
  <summary>Details</summary>
Motivation: 传统监测系统在了解娱乐性药物使用的真实世界影响方面存在不足，本研究旨在利用社交媒体数据来弥补这一差距。

Method: 通过整合俚语术语和 MetaMap 生物医学概念提取，识别了超过 92,000 条提及这些物质的推文，并根据用户报告的效果对其进行情感极性标注。研究人员还训练了机器学习模型来预测推文内容的情感极性，并采用了处理类别不平衡的技术。

Result: 研究发现了推特能够用于检测特定物质的表型效应，并且情感极性分类模型能以高准确率支持实时药物警戒和药物效应表征。其中，eXtreme Gradient Boosting 结合成本敏感学习的模型表现最佳（F1 = 0.885, AUPRC = 0.934）。

Conclusion: 本研究证明了利用推特数据进行药物警戒和理解新兴精神活性物质影响的可行性和有效性。

Abstract: Understanding the real-world effects of recreational drug use remains a
critical challenge in public health and biomedical research, especially as
traditional surveillance systems often underrepresent user experiences. In this
study, we leverage social media (specifically Twitter) as a rich and unfiltered
source of user-reported effects associated with three emerging psychoactive
substances: ecstasy, GHB, and 2C-B. By combining a curated list of slang terms
with biomedical concept extraction via MetaMap, we identified and weakly
annotated over 92,000 tweets mentioning these substances. Each tweet was
labeled with a polarity reflecting whether it reported a positive or negative
effect, following an expert-guided heuristic process. We then performed
descriptive and comparative analyses of the reported phenotypic outcomes across
substances and trained multiple machine learning classifiers to predict
polarity from tweet content, accounting for strong class imbalance using
techniques such as cost-sensitive learning and synthetic oversampling. The top
performance on the test set was obtained from eXtreme Gradient Boosting with
cost-sensitive learning (F1 = 0.885, AUPRC = 0.934). Our findings reveal that
Twitter enables the detection of substance-specific phenotypic effects, and
that polarity classification models can support real-time pharmacovigilance and
drug effect characterization with high accuracy.

</details>


### [344] [Modeling Transformers as complex networks to analyze learning dynamics](https://arxiv.org/abs/2509.15269)
*Elisabetta Rocchetti*

Main category: cs.LG

TL;DR: LLMs的学习动态可以通过复杂网络理论（CNT）来研究，通过将LLM表示为有向加权图，并分析其网络指标的演变，揭示了信息传播者和收集者组件的角色。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（LLMs）在训练过程中获得复杂能力的过程，并探索是否能通过复杂网络理论（CNT）的视角来表征这些学习动态。

Method: 将基于Transformer的LLM表示为一个有向加权图，其中节点是模型的计算组件（注意力头和MLP），边表示因果影响，并通过基于干预的消融技术进行测量。跟踪Pythia-14M模型在感应任务上的143个训练检查点中该组件图的演变，并分析一系列图论指标。

Result: 网络结构演变经历探索、巩固和细化等不同阶段。识别出稳定的信息传播者组件层级和动态的信息收集者组件集，它们在关键学习节点处重新配置角色。

Conclusion: 从组件级别的网络视角为可视化和理解驱动LLM中功能电路形成的自组织原理提供了强大的宏观视角。

Abstract: The process by which Large Language Models (LLMs) acquire complex
capabilities during training remains a key open question in mechanistic
interpretability. This project investigates whether these learning dynamics can
be characterized through the lens of Complex Network Theory (CNT). I introduce
a novel methodology to represent a Transformer-based LLM as a directed,
weighted graph where nodes are the model's computational components (attention
heads and MLPs) and edges represent causal influence, measured via an
intervention-based ablation technique. By tracking the evolution of this
component-graph across 143 training checkpoints of the Pythia-14M model on a
canonical induction task, I analyze a suite of graph-theoretic metrics. The
results reveal that the network's structure evolves through distinct phases of
exploration, consolidation, and refinement. Specifically, I identify the
emergence of a stable hierarchy of information spreader components and a
dynamic set of information gatherer components, whose roles reconfigure at key
learning junctures. This work demonstrates that a component-level network
perspective offers a powerful macroscopic lens for visualizing and
understanding the self-organizing principles that drive the formation of
functional circuits in LLMs.

</details>


### [345] [Partial Column Generation with Graph Neural Networks for Team Formation and Routing](https://arxiv.org/abs/2509.15275)
*Giacomo Dall'Olio,Rainer Kolisch,Yaoxin Wu*

Main category: cs.LG

TL;DR: 提出了一种基于图神经网络的团队形成与路径规划问题的新型求解策略，通过预测可能产生负约化成本的列，提高了求解效率，尤其在困难实例和严格时间限制下表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 团队形成与路径规划问题在机场、医疗和维护等领域有实际应用，但求解困难，现有基于列生成的精确求解方法有待改进。

Method: 提出了一种新颖的、基于预测的列生成策略，利用图神经网络预测哪些定价问题可能产生负约化成本的列，并将其应用于团队形成与路径规划问题。

Result: 计算实验表明，所提出的策略能够提升求解方法的性能，特别是在解决困难实例且时间限制严格的情况下，其表现优于文献中传统的局部列生成方法。

Conclusion: 所提出的基于图神经网络的预测性局部列生成策略是一种有效的改进方法，能够显著提升团队形成与路径规划问题的求解效率。

Abstract: The team formation and routing problem is a challenging optimization problem
with several real-world applications in fields such as airport, healthcare, and
maintenance operations. To solve this problem, exact solution methods based on
column generation have been proposed in the literature. In this paper, we
propose a novel partial column generation strategy for settings with multiple
pricing problems, based on predicting which ones are likely to yield columns
with a negative reduced cost. We develop a machine learning model tailored to
the team formation and routing problem that leverages graph neural networks for
these predictions. Computational experiments demonstrate that applying our
strategy enhances the solution method and outperforms traditional partial
column generation approaches from the literature, particularly on hard
instances solved under a tight time limit.

</details>


### [346] [Fleming-R1: Toward Expert-Level Medical Reasoning via Reinforcement Learning](https://arxiv.org/abs/2509.15279)
*Chi Liu,Derek Li,Yan Shu,Robin Chen,Derek Duan,Teng Fang,Bryan Dai*

Main category: cs.LG

TL;DR: Fleming-R1是一个在医学领域展现出专业级临床推理能力的模型，通过新颖的数据策略、冷启动方法和可验证的强化学习框架，在提高准确性和可解释性方面取得了显著进展。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医学领域的应用前景广阔，但要达到专家级别的临床推理能力，不仅需要准确的答案，还需要透明的推理过程，而这正是当前面临的挑战。

Method: Fleming-R1模型采用了三种互补的创新：1. 提出推理导向数据策略（RODS），结合了精选的医学问答数据集和知识图谱引导的合成，以扩充代表性不足的疾病、药物和多步推理链的覆盖范围。2. 采用思维链（CoT）冷启动，从教师模型中提取高质量的推理轨迹，建立强大的推理先验。3. 实施了一个两阶段的可验证奖励强化学习（RLVR）框架，利用分组相对策略优化，巩固核心推理技能，并通过自适应的困难样本挖掘来解决持续存在的失败模式。

Result: 在各种医学基准测试中，Fleming-R1在参数效率方面取得了显著的改进：7B变体超过了许多更大的基线模型，而32B模型则达到了与GPT-4o接近的水平，并且持续优于强大的开源替代模型。

Conclusion: 研究结果表明，结构化数据设计、面向推理的初始化以及可验证的强化学习可以推动临床推理能力的提升，超越简单的准确性优化。Fleming-R1的公开发布旨在促进医学人工智能领域透明、可复现和可审计的进展，从而在关键的临床环境中实现更安全的部署。

Abstract: While large language models show promise in medical applications, achieving
expert-level clinical reasoning remains challenging due to the need for both
accurate answers and transparent reasoning processes. To address this
challenge, we introduce Fleming-R1, a model designed for verifiable medical
reasoning through three complementary innovations. First, our
Reasoning-Oriented Data Strategy (RODS) combines curated medical QA datasets
with knowledge-graph-guided synthesis to improve coverage of underrepresented
diseases, drugs, and multi-hop reasoning chains. Second, we employ
Chain-of-Thought (CoT) cold start to distill high-quality reasoning
trajectories from teacher models, establishing robust inference priors. Third,
we implement a two-stage Reinforcement Learning from Verifiable Rewards (RLVR)
framework using Group Relative Policy Optimization, which consolidates core
reasoning skills while targeting persistent failure modes through adaptive
hard-sample mining. Across diverse medical benchmarks, Fleming-R1 delivers
substantial parameter-efficient improvements: the 7B variant surpasses much
larger baselines, while the 32B model achieves near-parity with GPT-4o and
consistently outperforms strong open-source alternatives. These results
demonstrate that structured data design, reasoning-oriented initialization, and
verifiable reinforcement learning can advance clinical reasoning beyond simple
accuracy optimization. We release Fleming-R1 publicly to promote transparent,
reproducible, and auditable progress in medical AI, enabling safer deployment
in high-stakes clinical environments.

</details>


### [347] [Automated Constitutive Model Discovery by Pairing Sparse Regression Algorithms with Model Selection Criteria](https://arxiv.org/abs/2509.16040)
*Jorge-Humberto Urrea-Quintero,David Anton,Laura De Lorenzis,Henning Wessels*

Main category: cs.LG

TL;DR: 本研究提出了一种全自动化的本构模型发现框架，结合了三种稀疏回归算法（LASSO、LARS、OMP）和三种模型选择标准（K-fold CV、AIC、BIC），以系统地探索稀疏性、预测性能和计算成本之间的权衡。该框架应用于各向同性和非各向异性超弹性材料，并使用合成和实验数据集。结果表明，所有九种算法-标准组合在发现各向同性和非各向异性材料方面都表现出色，能够生成高精度的本构模型，拓宽了除 LASSO 等基于 L1 的方法之外的可用发现算法的范围。


<details>
  <summary>Details</summary>
Motivation: 从数据中自动发现本构模型作为传统模型校准方法的替代方案。

Method: 提出一个全自动化的框架，将三种稀疏回归算法（LASSO、LARS、OMP）与三种模型选择标准（K-fold CV、AIC、BIC）相结合，以发现本构模型。

Result: 所有九种算法-标准组合在发现各向同性和非各向异性材料方面都表现出色，能够生成高精度的本构模型。

Conclusion: 本研究提出的框架能够有效发现各向同性和非各向异性材料的本构模型，并且拓宽了可用的发现算法的范围。

Abstract: The automated discovery of constitutive models from data has recently emerged
as a promising alternative to the traditional model calibration paradigm. In
this work, we present a fully automated framework for constitutive model
discovery that systematically pairs three sparse regression algorithms (Least
Absolute Shrinkage and Selection Operator (LASSO), Least Angle Regression
(LARS), and Orthogonal Matching Pursuit (OMP)) with three model selection
criteria: $K$-fold cross-validation (CV), Akaike Information Criterion (AIC),
and Bayesian Information Criterion (BIC). This pairing yields nine distinct
algorithms for model discovery and enables a systematic exploration of the
trade-off between sparsity, predictive performance, and computational cost.
While LARS serves as an efficient path-based solver for the
$\ell_1$-constrained problem, OMP is introduced as a tractable heuristic for
$\ell_0$-regularized selection. The framework is applied to both isotropic and
anisotropic hyperelasticity, utilizing both synthetic and experimental
datasets. Results reveal that all nine algorithm-criterion combinations perform
consistently well for the discovery of isotropic and anisotropic materials,
yielding highly accurate constitutive models. These findings broaden the range
of viable discovery algorithms beyond $\ell_1$-based approaches such as LASSO.

</details>


### [348] [Hybrid unary-binary design for multiplier-less printed Machine Learning classifiers](https://arxiv.org/abs/2509.15316)
*Giorgos Armeniakos,Theodoros Mantzakidis,Dimitrios Soudris*

Main category: cs.LG

TL;DR: 利用印刷电子器件构建混合单/二元结构，用于高效实现多层感知器（MLP）分类器。


<details>
  <summary>Details</summary>
Motivation: 印刷电子（PE）器件为实现机器学习（ML）电路提供了灵活且成本低廉的替代方案，但其较大的尺寸限制了分类器的复杂度。利用PE器件的低制造成本和非经常性支出（NRE）成本，可以为特定的ML模型定制硬件，从而简化电路设计。

Method: 提出了一种混合单/二元结构，无需昂贵的编码器，即可实现高效、无乘法器的MLP分类器。结合感知器架构感知训练，进一步优化了面积和功耗效率。

Result: 在六个数据集上的评估显示，面积平均减少了46%，功耗平均减少了39%，同时准确性损失很小，优于其他最先进的MLP设计。

Conclusion: 所提出的混合单/二元架构和架构感知训练方法，能够显著降低印刷电子MLP分类器的面积和功耗，同时保持高准确性。

Abstract: Printed Electronics (PE) provide a flexible, cost-efficient alternative to
silicon for implementing machine learning (ML) circuits, but their large
feature sizes limit classifier complexity. Leveraging PE's low fabrication and
NRE costs, designers can tailor hardware to specific ML models, simplifying
circuit design. This work explores alternative arithmetic and proposes a hybrid
unary-binary architecture that removes costly encoders and enables efficient,
multiplier-less execution of MLP classifiers. We also introduce
architecture-aware training to further improve area and power efficiency.
Evaluation on six datasets shows average reductions of 46% in area and 39% in
power, with minimal accuracy loss, surpassing other state-of-the-art MLP
designs.

</details>


### [349] [Kuramoto Orientation Diffusion Models](https://arxiv.org/abs/2509.15328)
*Yue Song,T. Anderson Keller,Sevan Brodjian,Takeru Miyato,Yisong Yue,Pietro Perona,Max Welling*

Main category: cs.LG

TL;DR: 该模型利用生物系统中的相位同步机制，通过随机的Kuramoto动力学来生成具有方向信息的图像，特别是在指纹和纹理等数据上表现出色。


<details>
  <summary>Details</summary>
Motivation: 标准生成模型难以处理指纹和纹理等具有相干角方向模式的图像，因此需要新的方法来处理这类数据。

Method: 提出了一种基于周期域的评分生成模型，该模型利用随机Kuramoto动力学来模拟数据的扩散过程。在前向扩散过程中，通过耦合振荡器和全局参考相位实现同步，使数据坍缩到von Mises分布；在反向生成过程中，通过学习到的评分函数来逆转动力学，实现非同步化，生成多样化的模式。

Result: 该模型在通用图像基准测试中取得了有竞争力的结果，并在指纹和纹理等方向密集型数据集上显著提高了生成质量。

Conclusion: 受生物启发的同步动力学可作为生成模型中的结构化先验，为图像生成带来了新的可能性。

Abstract: Orientation-rich images, such as fingerprints and textures, often exhibit
coherent angular directional patterns that are challenging to model using
standard generative approaches based on isotropic Euclidean diffusion.
Motivated by the role of phase synchronization in biological systems, we
propose a score-based generative model built on periodic domains by leveraging
stochastic Kuramoto dynamics in the diffusion process. In neural and physical
systems, Kuramoto models capture synchronization phenomena across coupled
oscillators -- a behavior that we re-purpose here as an inductive bias for
structured image generation. In our framework, the forward process performs
\textit{synchronization} among phase variables through globally or locally
coupled oscillator interactions and attraction to a global reference phase,
gradually collapsing the data into a low-entropy von Mises distribution. The
reverse process then performs \textit{desynchronization}, generating diverse
patterns by reversing the dynamics with a learned score function. This approach
enables structured destruction during forward diffusion and a hierarchical
generation process that progressively refines global coherence into fine-scale
details. We implement wrapped Gaussian transition kernels and periodicity-aware
networks to account for the circular geometry. Our method achieves competitive
results on general image benchmarks and significantly improves generation
quality on orientation-dense datasets like fingerprints and textures.
Ultimately, this work demonstrates the promise of biologically inspired
synchronization dynamics as structured priors in generative modeling.

</details>


### [350] [Global Pre-fixing, Local Adjusting: A Simple yet Effective Contrastive Strategy for Continual Learning](https://arxiv.org/abs/2509.15347)
*Jia Tang,Xinrui Wang,Songcan Chen*

Main category: cs.LG

TL;DR: GPLASC是一种新的对比学习策略，用于解决持续学习中的灾难性遗忘问题，通过划分表示空间和调整局部特征来提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于对比损失的方法在持续学习中存在类间和类内特征混淆的问题，导致性能受限。

Method: 提出了一种名为GPLASC（Global Pre-fixing, Local Adjusting for Supervised Contrastive learning）的对比学习策略。该策略将表示空间的单位超球面划分为不重叠的区域，区域中心构成一个类间预设的ETF（Equiangular Tight Frame）。同时，在单个任务内，该方法调节特征结构，形成各自区域内的类内可调ETF。

Result: GPLASC同时保证了任务之间和任务内部的区分性特征结构，并且可以无缝集成到现有的对比持续学习框架中。实验验证了其有效性。

Conclusion: GPLASC通过全局预设和局部调整的策略，有效解决了持续学习中的特征混淆问题，提高了模型的表示能力和遗忘缓解能力。

Abstract: Continual learning (CL) involves acquiring and accumulating knowledge from
evolving tasks while alleviating catastrophic forgetting. Recently, leveraging
contrastive loss to construct more transferable and less forgetful
representations has been a promising direction in CL. Despite advancements,
their performance is still limited due to confusion arising from both
inter-task and intra-task features. To address the problem, we propose a simple
yet effective contrastive strategy named \textbf{G}lobal \textbf{P}re-fixing,
\textbf{L}ocal \textbf{A}djusting for \textbf{S}upervised \textbf{C}ontrastive
learning (GPLASC). Specifically, to avoid task-level confusion, we divide the
entire unit hypersphere of representations into non-overlapping regions, with
the centers of the regions forming an inter-task pre-fixed \textbf{E}quiangular
\textbf{T}ight \textbf{F}rame (ETF). Meanwhile, for individual tasks, our
method helps regulate the feature structure and form intra-task adjustable ETFs
within their respective allocated regions. As a result, our method
\textit{simultaneously} ensures discriminative feature structures both between
tasks and within tasks and can be seamlessly integrated into any existing
contrastive continual learning framework. Extensive experiments validate its
effectiveness.

</details>


### [351] [KoopCast: Trajectory Forecasting via Koopman Operators](https://arxiv.org/abs/2509.15513)
*Jungjin Lee,Jaeuk Shin,Gihwan Kim,Joonho Han,Insoon Yang*

Main category: cs.LG

TL;DR: KoopCast是一个轻量级的模型，利用Koopman算子理论来预测动态环境中的轨迹。它结合了神经目标估计和基于Koopman算子的精炼模块，实现了高精度、可解释性和低延迟。


<details>
  <summary>Details</summary>
Motivation: 需要一个轻量级且高效的模型来进行通用动态环境中的轨迹预测，该模型能够处理非线性动力学并提供可解释性。

Method: 提出KoopCast模型，采用两阶段设计：1. 概率神经网络目标估计器预测长期目标；2. Koopman算子精炼模块在非线性特征空间中进行线性预测，整合意图和历史信息。

Result: 在ETH/UCY、Waymo开放运动数据集和nuScenes数据集上验证了KoopCast模型的性能，在预测精度、模式级可解释性和效率方面表现出色。

Conclusion: KoopCast模型通过结合目标估计和Koopman算子理论，在保证预测精度的同时，实现了良好的可解释性和效率，适用于多智能体交互和地图约束的非线性运动场景。

Abstract: We present KoopCast, a lightweight yet efficient model for trajectory
forecasting in general dynamic environments. Our approach leverages Koopman
operator theory, which enables a linear representation of nonlinear dynamics by
lifting trajectories into a higher-dimensional space. The framework follows a
two-stage design: first, a probabilistic neural goal estimator predicts
plausible long-term targets, specifying where to go; second, a Koopman
operator-based refinement module incorporates intention and history into a
nonlinear feature space, enabling linear prediction that dictates how to go.
This dual structure not only ensures strong predictive accuracy but also
inherits the favorable properties of linear operators while faithfully
capturing nonlinear dynamics. As a result, our model offers three key
advantages: (i) competitive accuracy, (ii) interpretability grounded in Koopman
spectral theory, and (iii) low-latency deployment. We validate these benefits
on ETH/UCY, the Waymo Open Motion Dataset, and nuScenes, which feature rich
multi-agent interactions and map-constrained nonlinear motion. Across
benchmarks, KoopCast consistently delivers high predictive accuracy together
with mode-level interpretability and practical efficiency.

</details>


### [352] [Probabilistic Conformal Coverage Guarantees in Small-Data Settings](https://arxiv.org/abs/2509.15349)
*Petrus H. Zwart*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Conformal prediction provides distribution-free prediction sets with
guaranteed marginal coverage. However, in split conformal prediction this
guarantee is training-conditional only in expectation: across many calibration
draws, the average coverage equals the nominal level, but the realized coverage
for a single calibration set may vary substantially. This variance undermines
effective risk control in practical applications. Here we introduce the Small
Sample Beta Correction (SSBC), a plug-and-play adjustment to the conformal
significance level that leverages the exact finite-sample distribution of
conformal coverage to provide probabilistic guarantees, ensuring that with
user-defined probability over the calibration draw, the deployed predictor
achieves at least the desired coverage.

</details>


### [353] [Universal Learning of Stochastic Dynamics for Exact Belief Propagation using Bernstein Normalizing Flows](https://arxiv.org/abs/2509.15533)
*Peter Amorese,Morteza Lahijanian*

Main category: cs.LG

TL;DR: 该研究提出了一个结合归一化流和伯恩斯坦多项式的模型，用于学习非线性随机动力学，并支持解析信念传播，在处理高度非线性系统和非高斯噪声方面表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在未知系统模型的情况下，学习一个既能通用近似非线性随机动力学又能支持解析信念传播的模型。

Method: 结合归一化流（用于密度估计）和伯恩斯坦多项式（用于解析可处理性）。

Result: 提出的方法在高度非线性系统和非加性、非高斯噪声方面，相比最先进的数据驱动方法，在信念传播方面更有效。

Conclusion: 该方法为一类能够通用近似非线性随机动力学并支持解析信念传播的模型奠定了理论基础，并在实践中证明了其有效性。

Abstract: Predicting the distribution of future states in a stochastic system, known as
belief propagation, is fundamental to reasoning under uncertainty. However,
nonlinear dynamics often make analytical belief propagation intractable,
requiring approximate methods. When the system model is unknown and must be
learned from data, a key question arises: can we learn a model that (i)
universally approximates general nonlinear stochastic dynamics, and (ii)
supports analytical belief propagation? This paper establishes the theoretical
foundations for a class of models that satisfy both properties. The proposed
approach combines the expressiveness of normalizing flows for density
estimation with the analytical tractability of Bernstein polynomials. Empirical
results show the efficacy of our learned model over state-of-the-art
data-driven methods for belief propagation, especially for highly non-linear
systems with non-additive, non-Gaussian noise.

</details>


### [354] [Predicting Language Models' Success at Zero-Shot Probabilistic Prediction](https://arxiv.org/abs/2509.15356)
*Kevin Ren,Santiago Cortes-Gomez,Carlos Miguel Patiño,Ananya Joshi,Ruiqi Lyu,Jingjing Tang,Alistair Turcan,Khurram Yamin,Steven Wu,Bryan Wilder*

Main category: cs.LG

TL;DR: 大型语言模型（LLMs）在表格预测任务中表现不稳定，但当模型表现良好时，其预测概率能更准确地反映个体准确性。研究提出了在无标签数据的情况下，预测LLMs在特定任务上性能的指标，以区分模型适用和不适用的任务。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs作为零样本模型在各种表格预测任务中的预测能力，并找出何时用户可以信任LLMs的预测质量。

Method: 进行大规模实证研究，测试LLMs在不同表格预测任务中的零样本能力，并构建无标签数据指标来预测LLMs的性能。

Result: LLMs在不同任务和数据集上的性能差异很大。当LLMs在基础预测任务上表现良好时，其预测概率是衡量个体准确性的有力信号。提出的无标签数据指标能有效预测LLMs在新任务上的表现。

Conclusion: LLMs的零样本预测能力不稳定，但可以通过无标签数据指标来预测其在特定任务上的适用性，从而帮助用户更好地利用LLMs。

Abstract: Recent work has investigated the capabilities of large language models (LLMs)
as zero-shot models for generating individual-level characteristics (e.g., to
serve as risk models or augment survey datasets). However, when should a user
have confidence that an LLM will provide high-quality predictions for their
particular task? To address this question, we conduct a large-scale empirical
study of LLMs' zero-shot predictive capabilities across a wide range of tabular
prediction tasks. We find that LLMs' performance is highly variable, both on
tasks within the same dataset and across different datasets. However, when the
LLM performs well on the base prediction task, its predicted probabilities
become a stronger signal for individual-level accuracy. Then, we construct
metrics to predict LLMs' performance at the task level, aiming to distinguish
between tasks where LLMs may perform well and where they are likely unsuitable.
We find that some of these metrics, each of which are assessed without labeled
data, yield strong signals of LLMs' predictive performance on new tasks.

</details>


### [355] [Stochastic Sample Approximations of (Local) Moduli of Continuity](https://arxiv.org/abs/2509.15368)
*Rodion Nazarov,Allen Gehret,Robert Shorten,Jakub Marecek*

Main category: cs.LG

TL;DR: 该论文研究了局部连续性模量在神经网络鲁棒性和闭环模型公平性评估中的应用，并提出了一个非均匀随机样本近似方法。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于评估神经网络的鲁棒性及其在闭环模型中重复使用的公平性。

Method: 研究了广义导数与局部连续性模量之间的联系，并提出了一种非均匀随机样本近似方法来计算局部连续性模量。

Result: 提出了一种计算局部连续性模量的方法，该方法对于研究神经网络的鲁棒性和公平性具有重要意义。

Conclusion: 本研究提出了一个计算局部连续性模量的方法，为评估神经网络的鲁棒性和公平性提供了新的工具。

Abstract: Modulus of local continuity is used to evaluate the robustness of neural
networks and fairness of their repeated uses in closed-loop models. Here, we
revisit a connection between generalized derivatives and moduli of local
continuity, and present a non-uniform stochastic sample approximation for
moduli of local continuity. This is of importance in studying robustness of
neural networks and fairness of their repeated uses.

</details>


### [356] [SolarCrossFormer: Improving day-ahead Solar Irradiance Forecasting by Integrating Satellite Imagery and Ground Sensors](https://arxiv.org/abs/2509.15827)
*Baptiste Schubnel,Jelena Simeunović,Corentin Tissier,Pierre-Jean Alet,Rafael E. Carrillo*

Main category: cs.LG

TL;DR: SolarCrossFormer是一个结合卫星图像和地面气象站时间序列数据的深度学习模型，用于精确的日前太阳能辐照度预测，具有高时间和空间分辨率，并在实际应用中表现出鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有太阳能预测方案在时间和空间分辨率上无法满足系统运营商的需求，因此需要更精确的预测模型。

Method: 提出了一种名为SolarCrossFormer的新型深度学习模型，该模型利用图神经网络来融合卫星图像和地面气象站时间序列数据，以捕捉数据模态间的相关性，并生成具有15分钟分辨率、长达24小时的概率性预测。

Result: 在瑞士为期一年的127个地点的数据集上进行实验，SolarCrossFormer在整个预测范围内实现了6.1%的归一化平均绝对误差，其预测精度可与商业数值天气预报服务相媲美。

Conclusion: SolarCrossFormer模型能够生成高精度、高分辨率的太阳能辐照度预测，并且在实际应用中表现出良好的鲁棒性，能够处理新数据和预测无输入数据的地点，其性能可与商业服务竞争。

Abstract: Accurate day-ahead forecasts of solar irradiance are required for the
large-scale integration of solar photovoltaic (PV) systems into the power grid.
However, current forecasting solutions lack the temporal and spatial resolution
required by system operators. In this paper, we introduce SolarCrossFormer, a
novel deep learning model for day-ahead irradiance forecasting, that combines
satellite images and time series from a ground-based network of meteorological
stations. SolarCrossFormer uses novel graph neural networks to exploit the
inter- and intra-modal correlations of the input data and improve the accuracy
and resolution of the forecasts. It generates probabilistic forecasts for any
location in Switzerland with a 15-minute resolution for horizons up to 24 hours
ahead. One of the key advantages of SolarCrossFormer its robustness in real
life operations. It can incorporate new time-series data without retraining the
model and, additionally, it can produce forecasts for locations without input
data by using only their coordinates. Experimental results over a dataset of
one year and 127 locations across Switzerland show that SolarCrossFormer yield
a normalized mean absolute error of 6.1 % over the forecasting horizon. The
results are competitive with those achieved by a commercial numerical weather
prediction service.

</details>


### [357] [Adversarial generalization of unfolding (model-based) networks](https://arxiv.org/abs/2509.15370)
*Vicky Kouni*

Main category: cs.LG

TL;DR: 本文研究了在对抗性攻击下，展开网络的对抗泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的对抗性攻击理论对展开网络的性能理解不足，而展开网络在如压缩感知等关键领域具有重要应用，其对抗鲁棒性至关重要。

Method: 提出新框架估计了展开网络的对抗性Rademacher复杂度，并基于此给出了对抗泛化误差界限，并验证了模型的过参数化可以增强对抗鲁棒性。

Result: 理论分析表明，误差界限与攻击强度紧密相关，实验结果也验证了该理论的有效性。

Conclusion: 本文首次对展开网络的对抗泛化进行了理论分析，并提出了一种利用过参数化来增强模型对抗鲁棒性的方法。

Abstract: Unfolding networks are interpretable networks emerging from iterative
algorithms, incorporate prior knowledge of data structure, and are designed to
solve inverse problems like compressed sensing, which deals with recovering
data from noisy, missing observations. Compressed sensing finds applications in
critical domains, from medical imaging to cryptography, where adversarial
robustness is crucial to prevent catastrophic failures. However, a solid
theoretical understanding of the performance of unfolding networks in the
presence of adversarial attacks is still in its infancy. In this paper, we
study the adversarial generalization of unfolding networks when perturbed with
$l_2$-norm constrained attacks, generated by the fast gradient sign method.
Particularly, we choose a family of state-of-the-art overaparameterized
unfolding networks and deploy a new framework to estimate their adversarial
Rademacher complexity. Given this estimate, we provide adversarial
generalization error bounds for the networks under study, which are tight with
respect to the attack level. To our knowledge, this is the first theoretical
analysis on the adversarial generalization of unfolding networks. We further
present a series of experiments on real-world data, with results corroborating
our derived theory, consistently for all data. Finally, we observe that the
family's overparameterization can be exploited to promote adversarial
robustness, shedding light on how to efficiently robustify neural networks.

</details>


### [358] [Targeted Fine-Tuning of DNN-Based Receivers via Influence Functions](https://arxiv.org/abs/2509.15950)
*Marko Tuononen,Heikki Penttinen,Ville Hautamäki*

Main category: cs.LG

TL;DR: 我们首次将影响函数应用于基于深度学习的无线接收机，以解释和优化其性能。


<details>
  <summary>Details</summary>
Motivation: 为了理解和改进深度学习无线接收机的性能，需要一种解释其内部工作原理的方法。

Method: 利用影响函数分析训练样本对DeepRx（一个全卷积接收机）的位预测的影响，并提出一种基于影响函数的微调策略，包括损失相对影响和二阶更新。

Result: 研究表明，影响函数可以识别影响位预测的关键训练样本，并且基于影响函数的微调策略（特别是使用容量类二元交叉熵损失和一阶更新）能够有效降低误比特率，优于随机微调，尤其是在单目标场景下。然而，在多目标场景下效果不佳。

Conclusion: 影响函数既是深度学习无线接收机的可解释性工具，也为接收机的有效适应提供了基础。

Abstract: We present the first use of influence functions for deep learning-based
wireless receivers. Applied to DeepRx, a fully convolutional receiver,
influence analysis reveals which training samples drive bit predictions,
enabling targeted fine-tuning of poorly performing cases. We show that
loss-relative influence with capacity-like binary cross-entropy loss and
first-order updates on beneficial samples most consistently improves bit error
rate toward genie-aided performance, outperforming random fine-tuning in
single-target scenarios. Multi-target adaptation proved less effective,
underscoring open challenges. Beyond experiments, we connect influence to
self-influence corrections and propose a second-order, influence-aligned update
strategy. Our results establish influence functions as both an interpretability
tool and a basis for efficient receiver adaptation.

</details>


### [359] [Bayesian Physics Informed Neural Networks for Reliable Transformer Prognostics](https://arxiv.org/abs/2509.15933)
*Ibai Ramirez,Jokin Alcibar,Joel Pino,Mikel Sanz,David Pardo,Jose I. Aizpurua*

Main category: cs.LG

TL;DR: 该研究提出了一个贝叶斯物理信息神经网络（B-PINN）框架，用于概率性预测，解决了SciML在预测性维护领域的应用限制，该框架通过结合贝叶斯神经网络和物理信息神经网络，能够进行不确定性感知预测，并在变压器老化案例研究中得到了验证，相比于dropout-PINN，B-PINN提供了更可靠的预测和不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 目前SciML在预测性维护领域的应用有限，主要是因为在结合老化物理学方面引入偏微分方程（PDE）的复杂性以及缺乏可靠的不确定性量化方法。本研究旨在解决这些问题，提供一种能够进行不确定性感知预测的框架。

Method: 本研究提出了一个贝叶斯物理信息神经网络（B-PINN）框架，该框架将贝叶斯神经网络嵌入到物理信息神经网络（PINN）架构中，以实现概率性的预测。研究中将热扩散PDE作为物理残差，并探索了不同的先验分布对预测后验分布以及编码先验物理知识能力的影响。该框架应用于变压器老化案例研究，其中绝缘退化主要由热应力驱动。

Result: 该B-PINN框架在变压器老化案例研究中得到了应用，并通过与有限元模型和实际测量数据进行对比验证。与dropout-PINN基线相比，B-PINN通过准确量化预测不确定性，提供了更可靠的预测结果。

Conclusion: 本研究提出的B-PINN框架能够进行可靠的预测，并能准确量化预测不确定性，这对于支持关键电力资产的健壮和知情的维护决策至关重要。

Abstract: Scientific Machine Learning (SciML) integrates physics and data into the
learning process, offering improved generalization compared with purely
data-driven models. Despite its potential, applications of SciML in prognostics
remain limited, partly due to the complexity of incorporating partial
differential equations (PDEs) for ageing physics and the scarcity of robust
uncertainty quantification methods. This work introduces a Bayesian
Physics-Informed Neural Network (B-PINN) framework for probabilistic
prognostics estimation. By embedding Bayesian Neural Networks into the PINN
architecture, the proposed approach produces principled, uncertainty-aware
predictions. The method is applied to a transformer ageing case study, where
insulation degradation is primarily driven by thermal stress. The heat
diffusion PDE is used as the physical residual, and different prior
distributions are investigated to examine their impact on predictive posterior
distributions and their ability to encode a priori physical knowledge. The
framework is validated against a finite element model developed and tested with
real measurements from a solar power plant. Results, benchmarked against a
dropout-PINN baseline, show that the proposed B-PINN delivers more reliable
prognostic predictions by accurately quantifying predictive uncertainty. This
capability is crucial for supporting robust and informed maintenance
decision-making in critical power assets.

</details>


### [360] [Learning in Stackelberg Mean Field Games: A Non-Asymptotic Analysis](https://arxiv.org/abs/2509.15392)
*Sihan Zeng,Benjamin Patrick Evans,Sujay Bhatt,Leo Ardon,Sumitra Ganesh,Alec Koppel*

Main category: cs.LG

TL;DR: 我们提出了一种名为AC-SMFG的单循环Actor-Critic算法，用于解决Stackelberg均值场博弈（MFG）中的策略优化问题，该算法具有有限时间和有限样本收敛保证，并放宽了现有的领导者-追随者独立性假设。


<details>
  <summary>Details</summary>
Motivation: 现有解决Stackelberg MFG策略优化问题的方法存在对领导者和追随者目标之间的独立性假设过于严格、由于嵌套循环算法结构导致样本利用效率低下以及缺乏有限时间收敛保证等局限性。

Method: 提出AC-SMFG，一种单循环Actor-Critic算法，该算法在持续生成的马尔可夫样本上运行，并在领导者、代表性追随者和均值场的（半）梯度更新之间交替进行。

Result: AC-SMFG在策略质量和收敛速度方面优于现有的多智能体和MFG学习基线，并在经济学环境中得到了验证。

Conclusion: AC-SMFG是首个具有非渐近收敛保证的Stackelberg MFG算法，其关键假设是“梯度对齐”条件，该条件允许用策略的某个部分梯度来近似领导者的完整策略梯度，从而放宽了现有的领导者-追随者独立性假设。

Abstract: We study policy optimization in Stackelberg mean field games (MFGs), a
hierarchical framework for modeling the strategic interaction between a single
leader and an infinitely large population of homogeneous followers. The
objective can be formulated as a structured bi-level optimization problem, in
which the leader needs to learn a policy maximizing its reward, anticipating
the response of the followers. Existing methods for solving these (and related)
problems often rely on restrictive independence assumptions between the
leader's and followers' objectives, use samples inefficiently due to
nested-loop algorithm structure, and lack finite-time convergence guarantees.
To address these limitations, we propose AC-SMFG, a single-loop actor-critic
algorithm that operates on continuously generated Markovian samples. The
algorithm alternates between (semi-)gradient updates for the leader, a
representative follower, and the mean field, and is simple to implement in
practice. We establish the finite-time and finite-sample convergence of the
algorithm to a stationary point of the Stackelberg objective. To our knowledge,
this is the first Stackelberg MFG algorithm with non-asymptotic convergence
guarantees. Our key assumption is a "gradient alignment" condition, which
requires that the full policy gradient of the leader can be approximated by a
partial component of it, relaxing the existing leader-follower independence
assumption. Simulation results in a range of well-established economics
environments demonstrate that AC-SMFG outperforms existing multi-agent and MFG
learning baselines in policy quality and convergence speed.

</details>


### [361] [VMDNet: Time Series Forecasting with Leakage-Free Samplewise Variational Mode Decomposition and Multibranch Decoding](https://arxiv.org/abs/2509.15394)
*Weibin Feng,Ran Tao,John Cartlidge,Jin Zheng*

Main category: cs.LG

TL;DR: VMDNet框架通过样本 VMD 避免信息泄露，使用频率感知嵌入和 TCN 来处理分解后的模式，并通过双层优化自适应地选择超参数 K 和 alpha，在强周期性时间序列预测任务上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 VMD 方法在时间序列预测中存在信息泄露和不合适的超参数调整问题，而 VMDNet 旨在解决这些问题。

Method: VMDNet 框架首先通过样本 VMD 避免信息泄露，然后将每个分解模式表示为频率感知嵌入，并使用并行的 TCN 进行解码以确保模式独立性和高效学习，最后引入双层优化来自适应地选择 VMD 的核心超参数：模式数量（K）和带宽惩罚（alpha）。

Result: 实验结果表明，VMDNet 在周期性强的能源相关数据集上取得了最先进的性能，尤其在捕捉结构化周期性模式方面表现出明显优势，并且在周期性较弱的情况下也保持了鲁棒性。

Conclusion: VMDNet 框架通过创新的方法解决了现有 VMD 方法在时间序列预测中的局限性，在强周期性场景下表现出色，并在弱周期性场景下保持鲁棒性。

Abstract: In time series forecasting, capturing recurrent temporal patterns is
essential; decomposition techniques make such structure explicit and thereby
improve predictive performance. Variational Mode Decomposition (VMD) is a
powerful signal-processing method for periodicity-aware decomposition and has
seen growing adoption in recent years. However, existing studies often suffer
from information leakage and rely on inappropriate hyperparameter tuning. To
address these issues, we propose VMDNet, a causality-preserving framework that
(i) applies sample-wise VMD to avoid leakage; (ii) represents each decomposed
mode with frequency-aware embeddings and decodes it using parallel temporal
convolutional networks (TCNs), ensuring mode independence and efficient
learning; and (iii) introduces a bilevel, Stackelberg-inspired optimisation to
adaptively select VMD's two core hyperparameters: the number of modes (K) and
the bandwidth penalty (alpha). Experiments on two energy-related datasets
demonstrate that VMDNet achieves state-of-the-art results when periodicity is
strong, showing clear advantages in capturing structured periodic patterns
while remaining robust under weak periodicity.

</details>


### [362] [Adaptive Algorithms with Sharp Convergence Rates for Stochastic Hierarchical Optimization](https://arxiv.org/abs/2509.15399)
*Xiaochuan Gong,Jie Hao,Mingrui Liu*

Main category: cs.LG

TL;DR: 本论文提出了两种用于随机层次优化问题的新型自适应算法：非凸-强凹极大极小优化和非凸-强凸双层优化。这些算法无需预先了解噪声大小，即可在T次迭代中实现梯度范数的$	ext{O}(1/	ext{sqrt}(T) + 	ext{sqrt}(	ext{sigma})/T^{1/4})$的收敛速度，其中$	ext{sigma}$是随机梯度噪声的上界。该研究首次为随机层次优化提供了自适应且精确的收敛保证，并通过结合动量归一化技术和新颖的自适应参数选择来实现。实验证明了该算法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的随机优化算法在处理具有相互依赖的决策变量和目标（如极大极小和双层优化）时，缺乏适应性，无法在不知道梯度噪声量级的情况下，在不同噪声水平下实现最优收敛率。

Method: 提出两种新型自适应算法，分别针对非凸-强凹极大极小优化和非凸-强凸双层优化问题。算法设计结合了动量归一化技术和新颖的自适应参数选择。

Result: 在T次迭代中，算法达到了梯度范数的$	ext{O}(1/	ext{sqrt}(T) + 	ext{sqrt}(	ext{sigma})/T^{1/4})$的收敛速度，其中$	ext{sigma}$是随机梯度噪声的上界。这些收敛速度是在不知道噪声水平的情况下获得的，实现了低噪声和高噪声情况下的自动适应性。

Conclusion: 本研究首次为随机层次优化提供了自适应且精确的收敛保证。所提出的算法在低噪声和高噪声环境下都能自动适应，并在合成和深度学习任务的实验中表现出有效性。

Abstract: Hierarchical optimization refers to problems with interdependent decision
variables and objectives, such as minimax and bilevel formulations. While
various algorithms have been proposed, existing methods and analyses lack
adaptivity in stochastic optimization settings: they cannot achieve optimal
convergence rates across a wide spectrum of gradient noise levels without prior
knowledge of the noise magnitude. In this paper, we propose novel adaptive
algorithms for two important classes of stochastic hierarchical optimization
problems: nonconvex-strongly-concave minimax optimization and
nonconvex-strongly-convex bilevel optimization. Our algorithms achieve sharp
convergence rates of $\widetilde{O}(1/\sqrt{T} + \sqrt{\bar{\sigma}}/T^{1/4})$
in $T$ iterations for the gradient norm, where $\bar{\sigma}$ is an upper bound
on the stochastic gradient noise. Notably, these rates are obtained without
prior knowledge of the noise level, thereby enabling automatic adaptivity in
both low and high-noise regimes. To our knowledge, this work provides the first
adaptive and sharp convergence guarantees for stochastic hierarchical
optimization. Our algorithm design combines the momentum normalization
technique with novel adaptive parameter choices. Extensive experiments on
synthetic and deep learning tasks demonstrate the effectiveness of our proposed
algorithms.

</details>


### [363] [Exploring multimodal implicit behavior learning for vehicle navigation in simulated cities](https://arxiv.org/abs/2509.15400)
*Eric Aislan Antonelo,Gustavo Claudio Karl Couto,Christian Möller*

Main category: cs.LG

TL;DR: 标准模仿学习（BC）难以处理多模态驾驶决策，而隐式行为克隆（IBC）结合能量基模型（EBM）能更好地捕捉这种多模态性。数据增强IBC（DA-IBC）通过扰动专家动作形成反例和使用更好的初始化来改进学习。DA-IBC在CARLA城市驾驶任务中优于标准IBC，并且其学习到的能量景观能表示BC无法实现的 ThemeData.action 分布。


<details>
  <summary>Details</summary>
Motivation: 标准模仿学习（BC）在处理多模态驾驶决策（即同一场景下存在多个有效动作）时存在局限性。本研究旨在探索使用隐式行为克隆（IBC）和能量基模型（EBM）来更好地捕捉这种多模态性。

Method: 提出数据增强IBC（DA-IBC），通过扰动专家动作形成IBC训练的反例，并使用更好的初始化来进行无导数推断，以改进学习。

Result: 在CARLA模拟器中，使用鸟瞰图输入，DA-IBC在旨在评估多模态行为学习的城市驾驶任务中表现优于标准IBC。学习到的能量景观能够表示多模态动作分布，这是BC无法实现的。

Conclusion: DA-IBC通过利用EBM处理多模态驾驶决策，并在数据增强和优化推断方面进行改进，从而在模仿学习中取得更好的效果。

Abstract: Standard Behavior Cloning (BC) fails to learn multimodal driving decisions,
where multiple valid actions exist for the same scenario. We explore Implicit
Behavioral Cloning (IBC) with Energy-Based Models (EBMs) to better capture this
multimodality. We propose Data-Augmented IBC (DA-IBC), which improves learning
by perturbing expert actions to form the counterexamples of IBC training and
using better initialization for derivative-free inference. Experiments in the
CARLA simulator with Bird's-Eye View inputs demonstrate that DA-IBC outperforms
standard IBC in urban driving tasks designed to evaluate multimodal behavior
learning in a test environment. The learned energy landscapes are able to
represent multimodal action distributions, which BC fails to achieve.

</details>


### [364] [Top-$k$ Feature Importance Ranking](https://arxiv.org/abs/2509.15420)
*Yuxi Chen,Tiffany Tang,Genevera Allen*

Main category: cs.LG

TL;DR: RAMPART是一个新框架，用于对机器学习中的重要特征进行排名，它通过自适应策略和集成技术优化排名准确性，并提供了理论保证和实证结果。


<details>
  <summary>Details</summary>
Motivation: 准确地对重要特征进行排名在可解释的机器学习中是一个基本挑战，在科学发现和决策制定中有关键应用。然而，与特征选择和特征重要性相比，排名的具体问题受到的关注较少。

Method: RAMPART框架利用现有的特征重要性度量，采用一种新颖的算法来专门对排名前k的特征进行排名。该方法结合了自适应顺序减半策略，逐步将计算资源集中在有前景的特征上，并采用一种有效的集成技术，同时进行观测和特征子采样。与将重要性分数作为后处理转换为排名的现有方法不同，RAMPART明确优化排名准确性。

Result: RAMPART在温和的条件下，以高概率实现了正确的排名前k的排名。通过广泛的模拟研究，证明RAMPART的性能持续优于流行的特征重要性方法，并在高维基因组学案例研究中得到了验证。

Conclusion: RAMPART框架在排名准确性方面表现优于现有方法，并具有理论保证和实证证据支持，适用于从高维基因组学到其他领域的重要特征排名任务。

Abstract: Accurate ranking of important features is a fundamental challenge in
interpretable machine learning with critical applications in scientific
discovery and decision-making. Unlike feature selection and feature importance,
the specific problem of ranking important features has received considerably
less attention. We introduce RAMPART (Ranked Attributions with MiniPatches And
Recursive Trimming), a framework that utilizes any existing feature importance
measure in a novel algorithm specifically tailored for ranking the top-$k$
features. Our approach combines an adaptive sequential halving strategy that
progressively focuses computational resources on promising features with an
efficient ensembling technique using both observation and feature subsampling.
Unlike existing methods that convert importance scores to ranks as
post-processing, our framework explicitly optimizes for ranking accuracy. We
provide theoretical guarantees showing that RAMPART achieves the correct
top-$k$ ranking with high probability under mild conditions, and demonstrate
through extensive simulation studies that RAMPART consistently outperforms
popular feature importance methods, concluding with a high-dimensional genomics
case study.

</details>


### [365] [Random Matrix Theory-guided sparse PCA for single-cell RNA-seq data](https://arxiv.org/abs/2509.15429)
*Victor Chardès*

Main category: cs.LG

TL;DR: 单细胞RNA测序数据存在噪声，影响计算分析。本文提出一种基于随机矩阵理论（RMT）的稀疏主成分分析（sparse PCA）方法，通过新的预白化（biwhitening）技术，稳定基因和细胞间的方差，并自动选择稀疏度。该方法保留了PCA的可解释性，同时提高了稀疏PCA的鲁棒性和自动化程度，在细胞类型分类任务中优于PCA、自动编码器和扩散模型。


<details>
  <summary>Details</summary>
Motivation: 单细胞RNA测序（scRNA-seq）数据虽然能提供细胞层面的详细分子信息，但其固有的噪声（来自生物学差异、PCR扩增偏差、测序深度不足和捕获效率低等）给计算分析带来了挑战。现有的主成分分析（PCA）方法虽然易于理解且鲁棒，但仍有改进空间，尤其是在处理异构数据集和新技术方面。

Method: 提出一种基于随机矩阵理论（RMT）的方法，并结合现有的稀疏PCA算法来推断稀疏主成分。具体而言，引入了一种新颖的、受Sinkhorn-Knopp算法启发的预白化（biwhitening）方法，用于稳定基因和细胞间的方差。这使得能够使用基于RMT的标准来自动选择稀疏度水平，从而使稀疏PCA几乎无需手动调整参数。

Result: 在七种不同的单细胞RNA测序技术和四种稀疏PCA算法的测试中，该方法系统地提高了主子空间的重建精度，并在细胞类型分类任务中持续优于PCA、自动编码器和扩散模型等方法。

Conclusion: 该方法在保留PCA可解释性的同时，实现了对稀疏主成分的鲁棒且自动化的推断，为处理单细胞RNA测序数据的噪声和异质性提供了一种有效的解决方案。

Abstract: Single-cell RNA-seq provides detailed molecular snapshots of individual cells
but is notoriously noisy. Variability stems from biological differences, PCR
amplification bias, limited sequencing depth, and low capture efficiency,
making it challenging to adapt computational pipelines to heterogeneous
datasets or evolving technologies. As a result, most studies still rely on
principal component analysis (PCA) for dimensionality reduction, valued for its
interpretability and robustness. Here, we improve upon PCA with a Random Matrix
Theory (RMT)-based approach that guides the inference of sparse principal
components using existing sparse PCA algorithms. We first introduce a novel
biwhitening method, inspired by the Sinkhorn-Knopp algorithm, that
simultaneously stabilizes variance across genes and cells. This enables the use
of an RMT-based criterion to automatically select the sparsity level, rendering
sparse PCA nearly parameter-free. Our mathematically grounded approach retains
the interpretability of PCA while enabling robust, hands-off inference of
sparse principal components. Across seven single-cell RNA-seq technologies and
four sparse PCA algorithms, we show that this method systematically improves
the reconstruction of the principal subspace and consistently outperforms PCA-,
autoencoder-, and diffusion-based methods in cell-type classification tasks.

</details>


### [366] [Computing Linear Regions in Neural Networks with Skip Connections](https://arxiv.org/abs/2509.15441)
*Johnny Joyce,Jan Verschelde*

Main category: cs.LG

TL;DR: 神经网络在热带算术中可以通过分段线性激活函数来表示，从而可以应用热带几何。


<details>
  <summary>Details</summary>
Motivation: 研究如何用热带几何来分析神经网络的性质，并探究训练的难点。

Method: 提出算法计算神经网络是线性映射的区域，并通过实验进行验证。

Result: 通过实验获得了关于神经网络训练难度的见解，特别是关于过拟合问题和跳跃连接的好处。

Conclusion: 热带几何为理解神经网络的线性区域和训练特性提供了一种新的视角。

Abstract: Neural networks are important tools in machine learning. Representing
piecewise linear activation functions with tropical arithmetic enables the
application of tropical geometry. Algorithms are presented to compute regions
where the neural networks are linear maps. Through computational experiments,
we provide insights on the difficulty to train neural networks, in particular
on the problems of overfitting and on the benefits of skip connections.

</details>


### [367] [IMPQ: Interaction-Aware Layerwise Mixed Precision Quantization for LLMs](https://arxiv.org/abs/2509.15455)
*Junchen Zhao,Ali Derakhshan,Dushyant Bharadwaj,Jayden Kana Hyman,Junhao Dong,Sangeetha Abdu Jyothi,Ian Harris*

Main category: cs.LG

TL;DR: LLMs 因参数量过大难以在低资源设备上部署，混合精度量化是解决方案。现有方法在低于4比特时表现不佳，因忽略了层间交互。本文提出SPQE算法，将量化问题视为合作博弈，通过Shapley值评估层敏感度和交互。在此基础上，提出IMPQ算法，将Shapley估计转化为二元二次规划问题，为层分配2或4比特精度，以满足内存限制。实验证明IMPQ在Llama-3、Gemma-2和Qwen-3模型上表现优于现有方法，尤其在低比特宽度下，困惑度降低20%-80%。


<details>
  <summary>Details</summary>
Motivation: 现有混合精度量化方法在平均精度低于4比特时性能不佳，原因是它们忽略了层间交互对整体性能的影响，仅依赖孤立的、特定于层的度量。

Method: 本文提出两种创新方法：1. 合作博弈框架下的Shapley-based Progressive Quantization Estimation (SPQE) 算法，用于高效获取层敏感度和层间交互的Shapley估计值。2. 基于SPQE的Interaction-aware Mixed-Precision Quantization (IMPQ) 算法，将Shapley估计转化为二元二次规划问题，在内存限制下为层分配2或4比特精度。

Result: 在Llama-3、Gemma-2和Qwen-3模型上进行的大量实验表明，IMPQ具有良好的可扩展性，并且性能始终优于仅依赖孤立度量的方法。在4比特到2比特的平均精度范围内，IMPQ相对于最佳基线方法，困惑度降低了20%到80%，并且这种优势随着比特宽度的收紧而增大。

Conclusion: IMPQ算法能够有效地处理低比特混合精度量化问题，通过考虑层间交互，显著提高了LLMs在低资源设备上的性能。

Abstract: Large Language Models (LLMs) promise impressive capabilities, yet their
multi-billion-parameter scale makes on-device or low-resource deployment
prohibitive. Mixed-precision quantization offers a compelling solution, but
existing methods struggle when the average precision drops below four bits, as
they rely on isolated, layer-specific metrics that overlook critical
inter-layer interactions affecting overall performance. In this paper, we
propose two innovations to address these limitations. First, we frame the
mixed-precision quantization problem as a cooperative game among layers and
introduce Shapley-based Progressive Quantization Estimation (SPQE) to
efficiently obtain accurate Shapley estimates of layer sensitivities and
inter-layer interactions. Second, building upon SPQE, we propose
Interaction-aware Mixed-Precision Quantization (IMPQ) which translates these
Shapley estimates into a binary quadratic optimization formulation, assigning
either 2 or 4-bit precision to layers under strict memory constraints.
Comprehensive experiments conducted on Llama-3, Gemma-2, and Qwen-3 models
across three independent PTQ backends (Quanto, HQQ, GPTQ) demonstrate IMPQ's
scalability and consistently superior performance compared to methods relying
solely on isolated metrics. Across average precisions spanning 4 bit down to 2
bit, IMPQ cuts Perplexity by 20 to 80 percent relative to the best baseline,
with the margin growing as the bit-width tightens.

</details>


### [368] [Temporal Reasoning with Large Language Models Augmented by Evolving Knowledge Graphs](https://arxiv.org/abs/2509.15464)
*Junhong Lin,Song Wang,Xiaojie Guo,Julian Shun,Yada Zhu*

Main category: cs.LG

TL;DR: EvoReasoner和EvoKG是处理不断变化的知识的LLM推理算法，通过多跳推理和KG演化，取得了优于基线方法的性能，并缩小了小LLM和大LLM在动态问答上的差距。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在理解和推理不断变化的知识方面存在不足，许多方法忽略了知识图谱（KG）的动态性和事实不一致性。

Method: 提出了一种名为EvoReasoner的时间感知多跳推理算法，该算法结合了全局-局部实体链接、多路径分解和时间锚定评分。此外，引入了EvoKG，一个噪声容忍的KG演化模块，通过基于置信度的冲突解决和时间趋势跟踪，从非结构化文档中增量更新KG。

Result: 所提出的方法在时间问答基准和动态更新KG的端到端设置上进行了评估，结果优于基于提示和KG增强的基线方法。具体来说，一个8B参数的模型在使用该方法后，性能与7个月后提示的671B模型相当。

Conclusion: 结合时间推理和KG演化对于LLM的稳健和最新性能至关重要。

Abstract: Large language models (LLMs) excel at many language understanding tasks but
struggle to reason over knowledge that evolves. To address this, recent work
has explored augmenting LLMs with knowledge graphs (KGs) to provide structured,
up-to-date information. However, many existing approaches assume a static
snapshot of the KG and overlook the temporal dynamics and factual
inconsistencies inherent in real-world data. To address the challenge of
reasoning over temporally shifting knowledge, we propose EvoReasoner, a
temporal-aware multi-hop reasoning algorithm that performs global-local entity
grounding, multi-route decomposition, and temporally grounded scoring. To
ensure that the underlying KG remains accurate and up-to-date, we introduce
EvoKG, a noise-tolerant KG evolution module that incrementally updates the KG
from unstructured documents through confidence-based contradiction resolution
and temporal trend tracking. We evaluate our approach on temporal QA benchmarks
and a novel end-to-end setting where the KG is dynamically updated from raw
documents. Our method outperforms both prompting-based and KG-enhanced
baselines, effectively narrowing the gap between small and large LLMs on
dynamic question answering. Notably, an 8B-parameter model using our approach
matches the performance of a 671B model prompted seven months later. These
results highlight the importance of combining temporal reasoning with KG
evolution for robust and up-to-date LLM performance. Our code is publicly
available at github.com/junhongmit/TREK.

</details>


### [369] [FRAUDGUESS: Spotting and Explaining New Types of Fraud in Million-Scale Financial Data](https://arxiv.org/abs/2509.15493)
*Robson L. F. Cordeiro,Meng-Chieh Lee,Christos Faloutsos*

Main category: cs.LG

TL;DR: FRAUDGUESS通过在精心设计的特征空间中识别微聚类来检测新颖的欺诈类型，并通过可视化和热图提供证据，已在一家匿名金融机构得到实际应用，并发现了三种新的可疑行为。


<details>
  <summary>Details</summary>
Motivation: 在已知部分欺诈交易标签的情况下，需要一种能够检测未知欺诈类型并为专家提供证据以支持检测结果的系统。

Method: FRAUDGUESS通过在精心设计的特征空间中识别微聚类来检测新颖的欺诈类型，并利用可视化和热图提供证据，同时提供交互式仪表板进行深入分析。

Result: FRAUDGUESS在实际的金融数据集上发现了三种新的可疑行为，其中两种被领域专家确认为欺诈或可疑，成功识别了大量原本可能被忽略的欺诈交易。

Conclusion: FRAUDGUESS能够有效检测新颖的欺诈类型并提供充分的证据支持其检测结果，已在实际金融环境中得到验证，并显示出巨大的应用潜力。

Abstract: Given a set of financial transactions (who buys from whom, when, and for how
much), as well as prior information from buyers and sellers, how can we find
fraudulent transactions? If we have labels for some transactions for known
types of fraud, we can build a classifier. However, we also want to find new
types of fraud, still unknown to the domain experts ('Detection'). Moreover, we
also want to provide evidence to experts that supports our opinion
('Justification'). In this paper, we propose FRAUDGUESS, to achieve two goals:
(a) for 'Detection', it spots new types of fraud as micro-clusters in a
carefully designed feature space; (b) for 'Justification', it uses
visualization and heatmaps for evidence, as well as an interactive dashboard
for deep dives. FRAUDGUESS is used in real life and is currently considered for
deployment in an Anonymous Financial Institution (AFI). Thus, we also present
the three new behaviors that FRAUDGUESS discovered in a real, million-scale
financial dataset. Two of these behaviors are deemed fraudulent or suspicious
by domain experts, catching hundreds of fraudulent transactions that would
otherwise go un-noticed.

</details>


### [370] [Detail Across Scales: Multi-Scale Enhancement for Full Spectrum Neural Representations](https://arxiv.org/abs/2509.15494)
*Yuan Ni,Zhantao Chen,Cheng Peng,Rajan Plumley,Chun Hong Yoon,Jana B. Thayer,Joshua J. Turner*

Main category: cs.LG

TL;DR: WIEN-INR是一种小巧且高效的隐式神经表示方法，通过多尺度分解和精细尺度上的专门核网络来精确表示科学数据中的精细细节。


<details>
  <summary>Details</summary>
Motivation: 现有隐式神经表示方法在模型尺寸受限时，难以忠实表示科学数据中的多尺度结构、高频信息和精细纹理。

Method: 提出了一种称为WIEN-INR的小波信息隐式神经表示方法，该方法将建模分布在不同的分辨率尺度上，并在最精细的尺度上使用专门的核网络来恢复细微的细节。

Result: 通过在各种科学数据集上的广泛实验，WIEN-INR在保持模型尺寸紧凑的同时，实现了卓越的重建保真度。

Conclusion: WIEN-INR是一种实用的神经表示框架，能够高效地编码高保真科学数据，并将隐式神经表示的应用扩展到需要有效保存精细细节的领域。

Abstract: Implicit neural representations (INRs) have emerged as a compact and
parametric alternative to discrete array-based data representations, encoding
information directly in neural network weights to enable resolution-independent
representation and memory efficiency. However, existing INR approaches, when
constrained to compact network sizes, struggle to faithfully represent the
multi-scale structures, high-frequency information, and fine textures that
characterize the majority of scientific datasets. To address this limitation,
we propose WIEN-INR, a wavelet-informed implicit neural representation that
distributes modeling across different resolution scales and employs a
specialized kernel network at the finest scale to recover subtle details. This
multi-scale architecture allows for the use of smaller networks to retain the
full spectrum of information while preserving the training efficiency and
reducing storage cost. Through extensive experiments on diverse scientific
datasets spanning different scales and structural complexities, WIEN-INR
achieves superior reconstruction fidelity while maintaining a compact model
size. These results demonstrate WIEN-INR as a practical neural representation
framework for high-fidelity scientific data encoding, extending the
applicability of INRs to domains where efficient preservation of fine detail is
essential.

</details>


### [371] [Mental Accounts for Actions: EWA-Inspired Attention in Decision Transformers](https://arxiv.org/abs/2509.15498)
*Zahra Aref,Narayan B. Mandayam*

Main category: cs.LG

TL;DR: EWA-VQ-ODT通过引入基于经验吸引力（EWA）和向量量化（VQ）的轻量级模块来增强在线决策Transformer（ODT），以提高连续控制任务中的样本效率和学习速度，同时保持计算效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 标准的在线决策Transformer（ODT）在处理具有长时序依赖性的动作时效率低下，因为它们缺乏对动作特定结果的显式记忆。

Method: 提出了一种名为EWA-VQ-ODT的模块，该模块维护每个动作的“心智账户”，以总结最近的成功和失败。连续动作通过直接的网格查找被路由到一个紧凑的向量量化码本，其中每个码存储一个通过衰减和基于奖励的强化在线更新的标量吸引力。这些吸引力通过偏置与动作标记相关的列来调节注意力，而无需更改骨干或训练目标。

Result: 在标准的连续控制基准测试中，EWA-VQ-ODT在样本效率和平均回报方面优于ODT，尤其是在早期训练阶段。

Conclusion: EWA-VQ-ODT是一个计算高效、可解释且具有理论保证的模块，可以增强ODT在连续控制任务中的学习能力。

Abstract: Transformers have emerged as a compelling architecture for sequential
decision-making by modeling trajectories via self-attention. In reinforcement
learning (RL), they enable return-conditioned control without relying on value
function approximation. Decision Transformers (DTs) exploit this by casting RL
as supervised sequence modeling, but they are restricted to offline data and
lack exploration. Online Decision Transformers (ODTs) address this limitation
through entropy-regularized training on on-policy rollouts, offering a stable
alternative to traditional RL methods like Soft Actor-Critic, which depend on
bootstrapped targets and reward shaping. Despite these advantages, ODTs use
standard attention, which lacks explicit memory of action-specific outcomes.
This leads to inefficiencies in learning long-term action effectiveness.
Inspired by cognitive models such as Experience-Weighted Attraction (EWA), we
propose Experience-Weighted Attraction with Vector Quantization for Online
Decision Transformers (EWA-VQ-ODT), a lightweight module that maintains
per-action mental accounts summarizing recent successes and failures.
Continuous actions are routed via direct grid lookup to a compact
vector-quantized codebook, where each code stores a scalar attraction updated
online through decay and reward-based reinforcement. These attractions modulate
attention by biasing the columns associated with action tokens, requiring no
change to the backbone or training objective. On standard continuous-control
benchmarks, EWA-VQ-ODT improves sample efficiency and average return over ODT,
particularly in early training. The module is computationally efficient,
interpretable via per-code traces, and supported by theoretical guarantees that
bound the attraction dynamics and its impact on attention drift.

</details>


### [372] [Policy Gradient Optimzation for Bayesian-Risk MDPs with General Convex Losses](https://arxiv.org/abs/2509.15509)
*Xiaoshuang Wang,Yifan Lin,Enlu Zhou*

Main category: cs.LG

TL;DR: We propose a policy gradient method for Markov decision processes with unknown parameters and general loss functions, addressing epistemic uncertainty using a Bayesian approach. The method extends the envelope theorem and achieves a convergence rate of O(T^{-1/2}+r^{-1/2}), with further extensions for episodic settings.


<details>
  <summary>Details</summary>
Motivation: The paper addresses Markov decision processes (MDPs) with general loss functions and unknown parameters, motivated by various application problems. It aims to mitigate the epistemic uncertainty associated with these unknown parameters.

Method: A Bayesian approach is used to estimate unknown parameters from data and impose a coherent risk functional. A policy gradient optimization method is proposed, leveraging the dual representation of coherent risk measures and extending the envelope theorem. The algorithm is further extended to an episodic setting.

Result: The stationary analysis of the algorithm shows a convergence rate of O(T^{-1/2}+r^{-1/2}), where T is the number of policy gradient iterations and r is the sample size of the gradient estimator. The episodic extension establishes global convergence and provides bounds on the number of iterations needed to achieve an error bound O(epsilon) in each episode.

Conclusion: The paper successfully develops and analyzes a policy gradient method for a complex class of MDPs, offering theoretical guarantees on convergence and error bounds.

Abstract: Motivated by many application problems, we consider Markov decision processes
(MDPs) with a general loss function and unknown parameters. To mitigate the
epistemic uncertainty associated with unknown parameters, we take a Bayesian
approach to estimate the parameters from data and impose a coherent risk
functional (with respect to the Bayesian posterior distribution) on the loss.
Since this formulation usually does not satisfy the interchangeability
principle, it does not admit Bellman equations and cannot be solved by
approaches based on dynamic programming. Therefore, We propose a policy
gradient optimization method, leveraging the dual representation of coherent
risk measures and extending the envelope theorem to continuous cases. We then
show the stationary analysis of the algorithm with a convergence rate of
$O(T^{-1/2}+r^{-1/2})$, where $T$ is the number of policy gradient iterations
and $r$ is the sample size of the gradient estimator. We further extend our
algorithm to an episodic setting, and establish the global convergence of the
extended algorithm and provide bounds on the number of iterations needed to
achieve an error bound $O(\epsilon)$ in each episode.

</details>


### [373] [Manifold Dimension Estimation: An Empirical Study](https://arxiv.org/abs/2509.15517)
*Zelong Bi,Pierre Lafaye de Micheaux*

Main category: cs.LG

TL;DR: 高维数据通常位于低维流形上，估计流形维度对于利用其结构至关重要。本文对现有流形维度估计方法进行了全面的调查和评估。


<details>
  <summary>Details</summary>
Motivation: 现有流形维度估计方法缺乏系统性评估，本文旨在提供一个全面的调查。

Method: 本文回顾了理论基础，介绍了八种代表性估计器，并通过实验分析了噪声、曲率和样本量等因素对性能的影响，并在合成和真实世界数据集上进行了比较。

Result: 实验结果表明，对于普遍性问题，更简单的估计器通常表现更好。

Conclusion: 本文对流形维度估计方法进行了全面的调查和评估，并为研究人员和实践者提供了实际指导。

Abstract: The manifold hypothesis suggests that high-dimensional data often lie on or
near a low-dimensional manifold. Estimating the dimension of this manifold is
essential for leveraging its structure, yet existing work on dimension
estimation is fragmented and lacks systematic evaluation. This article provides
a comprehensive survey for both researchers and practitioners. We review
often-overlooked theoretical foundations and present eight representative
estimators. Through controlled experiments, we analyze how individual factors
such as noise, curvature, and sample size affect performance. We also compare
the estimators on diverse synthetic and real-world datasets, introducing a
principled approach to dataset-specific hyperparameter tuning. Our results
offer practical guidance and suggest that, for a problem of this generality,
simpler methods often perform better.

</details>


### [374] [Fully Decentralized Cooperative Multi-Agent Reinforcement Learning is A Context Modeling Problem](https://arxiv.org/abs/2509.15519)
*Chao Li,Bingkun Bao,Yang Gao*

Main category: cs.LG

TL;DR: 本研究提出了一种名为动态感知上下文（DAC）的新方法，用于解决完全去中心化协同多智能体强化学习中的非平稳性和相对泛化过度问题，并取得了优于现有基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究未能同时解决完全去中心化协同多智能体强化学习中的非平稳性和相对泛化过度问题，因为它们无法在完全去中心化设置中对其他智能体的联合策略进行建模。

Method: DAC 将每个智能体局部感知的任务形式化为一个上下文马尔可夫决策过程。通过对未观测到的上下文（对应于不同的联合策略）进行建模，DAC 解决了非平稳性问题（通过上下文值函数）和相对泛化过度问题（通过乐观边际值）。

Result: DAC 在矩阵博弈、捕食者与被捕食者以及 SMAC 等多种协同任务上的实验评估显示，其性能优于多种基线方法。

Conclusion: DAC 有效地解决了完全去中心化协同多智能体强化学习中的非平稳性和相对泛化过度问题，并在各种协同任务中取得了优越的性能。

Abstract: This paper studies fully decentralized cooperative multi-agent reinforcement
learning, where each agent solely observes the states, its local actions, and
the shared rewards. The inability to access other agents' actions often leads
to non-stationarity during value function updates and relative
overgeneralization during value function estimation, hindering effective
cooperative policy learning. However, existing works fail to address both
issues simultaneously, due to their inability to model the joint policy of
other agents in a fully decentralized setting. To overcome this limitation, we
propose a novel method named Dynamics-Aware Context (DAC), which formalizes the
task, as locally perceived by each agent, as an Contextual Markov Decision
Process, and further addresses both non-stationarity and relative
overgeneralization through dynamics-aware context modeling. Specifically, DAC
attributes the non-stationary local task dynamics of each agent to switches
between unobserved contexts, each corresponding to a distinct joint policy.
Then, DAC models the step-wise dynamics distribution using latent variables and
refers to them as contexts. For each agent, DAC introduces a context-based
value function to address the non-stationarity issue during value function
update. For value function estimation, an optimistic marginal value is derived
to promote the selection of cooperative actions, thereby addressing the
relative overgeneralization issue. Experimentally, we evaluate DAC on various
cooperative tasks (including matrix game, predator and prey, and SMAC), and its
superior performance against multiple baselines validates its effectiveness.

</details>


### [375] [Nonconvex Decentralized Stochastic Bilevel Optimization under Heavy-Tailed Noises](https://arxiv.org/abs/2509.15543)
*Xinwen Zhang,Yihan Zhang,Hongchang Gao*

Main category: cs.LG

TL;DR: 该研究提出了一种新的去中心化随机二阶优化算法，用于解决非凸二阶优化问题，该算法在重尾噪声下表现良好，并且是首个具有严格理论保证的此类算法。


<details>
  <summary>Details</summary>
Motivation: 现有的去中心化随机优化方法在低阶损失函数强凸和随机梯度噪声有限方差的假设下进行，而这些假设在实际的机器学习模型中通常不满足。本研究旨在解决这些限制。

Method: 开发了一种新的去中心化随机二阶优化算法，特别是提出了一种不依赖于任何裁剪操作的归一化随机方差缩减二阶梯度下降算法。通过创新地约束重尾噪声下的非凸去中心化二阶优化问题的相互依赖梯度序列，建立了其收敛率。

Result: 实验结果广泛证实了该算法在处理重尾噪声方面的有效性。

Conclusion: 本研究提出的算法是首个在重尾噪声下具有严格理论保证的去中心化二阶优化算法，并在实验中验证了其有效性。

Abstract: Existing decentralized stochastic optimization methods assume the lower-level
loss function is strongly convex and the stochastic gradient noise has finite
variance. These strong assumptions typically are not satisfied in real-world
machine learning models. To address these limitations, we develop a novel
decentralized stochastic bilevel optimization algorithm for the nonconvex
bilevel optimization problem under heavy-tailed noises. Specifically, we
develop a normalized stochastic variance-reduced bilevel gradient descent
algorithm, which does not rely on any clipping operation. Moreover, we
establish its convergence rate by innovatively bounding interdependent gradient
sequences under heavy-tailed noises for nonconvex decentralized bilevel
optimization problems. As far as we know, this is the first decentralized
bilevel optimization algorithm with rigorous theoretical guarantees under
heavy-tailed noises. The extensive experimental results confirm the
effectiveness of our algorithm in handling heavy-tailed noises.

</details>


### [376] [PolyJuice Makes It Real: Black-Box, Universal Red Teaming for Synthetic Image Detectors](https://arxiv.org/abs/2509.15551)
*Sepehr Dehdashtian,Mashrur M. Morshed,Jacob H. Seidman,Gaurav Bharaj,Vishnu Naresh Boddeti*

Main category: cs.LG

TL;DR: PolyJuice是一种首创的黑盒、图像无关的合成图像检测器（SID）红队方法，通过利用T2I潜在空间中的分布偏移来生成更有效的攻击，并能显著提高SID的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的红队方法需要SID的白盒访问权限，并且生成特定攻击的成本高昂，而PolyJuice旨在解决这些限制，提供一种更通用、更高效的解决方案。

Method: PolyJuice首先通过一种轻量级的离线过程，仅需黑盒访问SID，来识别T2I潜在空间中影响SID分类的分布偏移方向。然后，利用该方向普遍地引导所有生成图像，使其更容易欺骗SID。

Result: PolyJuice引导的T2I模型在欺骗SID方面效果显著提升（最高可达84%）。此外，研究表明可以在低分辨率下高效估计和转移该引导方向至高分辨率，从而降低计算开销。最后，使用PolyJuice增强的数据集对SID进行微调，可以显著提升检测器性能（最高可达30%）。

Conclusion: PolyJuice通过其新颖的黑盒、图像无关的红队方法，不仅提高了T2I生成图像欺骗SID的能力，还为增强SID的鲁棒性提供了有效途径，展示了其在应对日益增长的合成图像威胁方面的潜力。

Abstract: Synthetic image detectors (SIDs) are a key defense against the risks posed by
the growing realism of images from text-to-image (T2I) models. Red teaming
improves SID's effectiveness by identifying and exploiting their failure modes
via misclassified synthetic images. However, existing red-teaming solutions (i)
require white-box access to SIDs, which is infeasible for proprietary
state-of-the-art detectors, and (ii) generate image-specific attacks through
expensive online optimization. To address these limitations, we propose
PolyJuice, the first black-box, image-agnostic red-teaming method for SIDs,
based on an observed distribution shift in the T2I latent space between samples
correctly and incorrectly classified by the SID. PolyJuice generates attacks by
(i) identifying the direction of this shift through a lightweight offline
process that only requires black-box access to the SID, and (ii) exploiting
this direction by universally steering all generated images towards the SID's
failure modes. PolyJuice-steered T2I models are significantly more effective at
deceiving SIDs (up to 84%) compared to their unsteered counterparts. We also
show that the steering directions can be estimated efficiently at lower
resolutions and transferred to higher resolutions using simple interpolation,
reducing computational overhead. Finally, tuning SID models on
PolyJuice-augmented datasets notably enhances the performance of the detectors
(up to 30%).

</details>


### [377] [The Multi-Query Paradox in Zeroth-Order Optimization](https://arxiv.org/abs/2509.15552)
*Wei Lin,Qingyu Song,Hong Xu*

Main category: cs.LG

TL;DR: ZO优化存在梯度获取的挑战，本文通过多查询方法并分析了两种聚合方法（ZO-Avg和ZO-Align）来解决查询分配问题，揭示了聚合方法决定了最优查询策略。


<details>
  <summary>Details</summary>
Motivation: 梯度信息不可用或难以获取的问题，并探索如何优化查询次数与优化迭代次数之间的权衡。

Method: 分析了ZO-Avg（简单平均）和ZO-Align（局部代理最小化推导）两种聚合方法，并推导了它们在不同优化设置下的收敛率，以明确查询次数的影响。

Result: 证明了ZO-Avg方法中，单查询是最高效的；而ZO-Align方法通常在更多查询次数下表现更好，全子空间估计是最优的。理论发现得到了实验验证。

Conclusion: ZO优化的查询分配问题关键在于选择聚合方法（ZO-Avg或ZO-Align），而非中间查询大小，因为聚合方法决定了最优查询策略。

Abstract: Zeroth-order (ZO) optimization provides a powerful framework for problems
where explicit gradients are unavailable and have to be approximated using only
queries to function value. The prevalent single-query approach is simple, but
suffers from high estimation variance, motivating a multi-query paradigm to
improves estimation accuracy. This, however, creates a critical trade-off:
under a fixed budget of queries (i.e. cost), queries per iteration and the
total number of optimization iterations are inversely proportional to one
another. How to best allocate this budget is a fundamental, under-explored
question.
  This work systematically resolves this query allocation problem. We analyze
two aggregation methods: the de facto simple averaging (ZO-Avg), and a new
Projection Alignment method (ZO-Align) we derive from local surrogate
minimization. By deriving convergence rates for both methods that make the
dependence on the number of queries explicit across strongly convex, convex,
non-convex, and stochastic settings, we uncover a stark dichotomy: For ZO-Avg,
we prove that using more than one query per iteration is always
query-inefficient, rendering the single-query approach optimal. On the
contrary, ZO-Align generally performs better with more queries per iteration,
resulting in a full-subspace estimation as the optimal approach. Thus, our work
clarifies that the multi-query problem boils down to a choice not about an
intermediate query size, but between two classic algorithms, a choice dictated
entirely by the aggregation method used. These theoretical findings are also
consistently validated by extensive experiments.

</details>


### [378] [Reward Hacking Mitigation using Verifiable Composite Rewards](https://arxiv.org/abs/2509.15557)
*Mirza Farhan Bin Tarek,Rahmatollah Beheshti*

Main category: cs.LG

TL;DR: RLVR在医学领域问答中存在奖励劫持问题，本文提出了一种改进的奖励函数来解决此问题，实验证明该方法能有效减少奖励劫持并提高准确性。


<details>
  <summary>Details</summary>
Motivation: 在医学领域，RLVR用于LLM进行问答时，容易出现奖励劫持，即模型可能在没有充分推理的情况下给出答案，或使用非标准格式进行推理以获取奖励。

Method: 提出了一种复合奖励函数，对‘无推理给出答案’和‘使用非标准推理格式’这两种奖励劫持行为进行惩罚。

Result: 实验结果表明，使用本文提出的奖励模型的RLVR相比基线模型，能够生成格式更好、奖励劫持更少且准确性更高的推理。

Conclusion: 通过引入改进的奖励函数，可以有效减少RLVR中的奖励劫持，提高模型在医学问答任务中的可靠性。

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) has recently shown that
large language models (LLMs) can develop their own reasoning without direct
supervision. However, applications in the medical domain, specifically for
question answering, are susceptible to significant reward hacking during the
reasoning phase. Our work addresses two primary forms of this behavior: i)
providing a final answer without preceding reasoning, and ii) employing
non-standard reasoning formats to exploit the reward mechanism. To mitigate
these, we introduce a composite reward function with specific penalties for
these behaviors. Our experiments show that extending RLVR with our proposed
reward model leads to better-formatted reasoning with less reward hacking and
good accuracy compared to the baselines. This approach marks a step toward
reducing reward hacking and enhancing the reliability of models utilizing RLVR.

</details>


### [379] [Small LLMs with Expert Blocks Are Good Enough for Hyperparamter Tuning](https://arxiv.org/abs/2509.15561)
*Om Naphade,Saksham Bansal,Parikshit Pareek*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Hyper-parameter Tuning (HPT) is a necessary step in machine learning (ML)
pipelines but becomes computationally expensive and opaque with larger models.
Recently, Large Language Models (LLMs) have been explored for HPT, yet most
rely on models exceeding 100 billion parameters. We propose an Expert Block
Framework for HPT using Small LLMs. At its core is the Trajectory Context
Summarizer (TCS), a deterministic block that transforms raw training
trajectories into structured context, enabling small LLMs to analyze
optimization progress with reliability comparable to larger models. Using two
locally-run LLMs (phi4:reasoning14B and qwen2.5-coder:32B) and a 10-trial
budget, our TCS-enabled HPT pipeline achieves average performance within ~0.9
percentage points of GPT-4 across six diverse tasks.

</details>


### [380] [How many classes do we need to see for novel class discovery?](https://arxiv.org/abs/2509.15585)
*Akanksha Sarkar,Been Kim,Jennifer J. Sun*

Main category: cs.LG

TL;DR: 该研究提出了一个使用 dSprites 数据集和程序生成修改因素的受控实验框架，以研究影响新类别发现的因素，特别是已知/未知类别的数量以及已知类别覆盖范围对发现新类别的boBox 影响。


<details>
  <summary>Details</summary>
Motivation: 现实世界的数据集包含复杂的、纠缠的变化因素，这使得对类别发现进行系统的研究变得困难。因此，关于为什么以及何时新的类别发现可能更成功的许多基本问题仍未得到解答。

Method: 提出了一个使用 dSprites 数据集和程序生成修改因素的简单受控实验框架。

Result: 研究结果表明，已知类别的数量对发现性能的好处会达到一个饱和点，之后发现性能会趋于平稳。在不同环境下，收益递减的模式为从业者的成本效益分析提供了见解，并为在复杂现实世界数据集上进行更严格的类别发现的未来研究提供了一个起点。

Conclusion: 该研究提出了一个受控的实验框架，用于研究影响新类别发现的因素，并提供了关于已知类别数量和覆盖范围对发现性能影响的经验结果。这些发现为了解类别发现的成本效益以及未来在复杂现实世界数据集上的研究提供了见解。

Abstract: Novel class discovery is essential for ML models to adapt to evolving
real-world data, with applications ranging from scientific discovery to
robotics. However, these datasets contain complex and entangled factors of
variation, making a systematic study of class discovery difficult. As a result,
many fundamental questions are yet to be answered on why and when new class
discoveries are more likely to be successful. To address this, we propose a
simple controlled experimental framework using the dSprites dataset with
procedurally generated modifying factors. This allows us to investigate what
influences successful class discovery. In particular, we study the relationship
between the number of known/unknown classes and discovery performance, as well
as the impact of known class 'coverage' on discovering new classes. Our
empirical results indicate that the benefit of the number of known classes
reaches a saturation point beyond which discovery performance plateaus. The
pattern of diminishing return across different settings provides an insight for
cost-benefit analysis for practitioners and a starting point for more rigorous
future research of class discovery on complex real-world datasets.

</details>


### [381] [Latent Zoning Network: A Unified Principle for Generative Modeling, Representation Learning, and Classification](https://arxiv.org/abs/2509.15591)
*Zinan Lin,Enshu Liu,Xuefei Ning,Junyi Zhu,Wenyu Wang,Sergey Yekhanin*

Main category: cs.LG

TL;DR: LZN是一个统一的框架，可以同时处理生成建模、表示学习和分类任务，通过共享的、分区的高斯潜在空间实现。


<details>
  <summary>Details</summary>
Motivation: 目前的机器学习方法在生成建模、表示学习和分类这三个核心问题上，其最先进的解决方案大多是分离的。本文旨在探索是否存在一个统一的原理来解决所有这三个问题，以简化机器学习流程并促进任务间的协同作用。

Method: 本文提出了一种名为Latent Zoning Network（LZN）的框架。LZN的核心是创建一个共享的高斯潜在空间，该空间跨任务编码信息。每种数据类型（例如，图像、文本、标签）都有一个编码器，将样本映射到不相交的潜在区域，以及一个解码器，将潜在表示映射回数据。机器学习任务被表达为这些编码器和解码器的组合。

Result: 1. 增强现有模型：将LZN与最先进的Rectified Flow模型结合，在CIFAR10数据集上将FID从2.76提高到2.59，而无需修改训练目标。
2. 独立解决任务：LZN可以实现无监督表示学习，无需辅助损失函数，在ImageNet下游线性分类任务上，性能分别比MoCo和SimCLR方法提高了9.3%和0.2%。
3. 同时解决多个任务：使用图像和标签的编码器/解码器，LZN可以同时执行生成和分类任务，提高了FID并实现了CIFAR10上的最先进分类准确率。

Conclusion: LZN在统一处理生成建模、表示学习和分类任务方面展现了巨大潜力，通过共享分区潜在空间，能够同时优化多个任务，并能增强现有模型和独立解决任务。

Abstract: Generative modeling, representation learning, and classification are three
core problems in machine learning (ML), yet their state-of-the-art (SoTA)
solutions remain largely disjoint. In this paper, we ask: Can a unified
principle address all three? Such unification could simplify ML pipelines and
foster greater synergy across tasks. We introduce Latent Zoning Network (LZN)
as a step toward this goal. At its core, LZN creates a shared Gaussian latent
space that encodes information across all tasks. Each data type (e.g., images,
text, labels) is equipped with an encoder that maps samples to disjoint latent
zones, and a decoder that maps latents back to data. ML tasks are expressed as
compositions of these encoders and decoders: for example, label-conditional
image generation uses a label encoder and image decoder; image embedding uses
an image encoder; classification uses an image encoder and label decoder. We
demonstrate the promise of LZN in three increasingly complex scenarios: (1) LZN
can enhance existing models (image generation): When combined with the SoTA
Rectified Flow model, LZN improves FID on CIFAR10 from 2.76 to 2.59-without
modifying the training objective. (2) LZN can solve tasks independently
(representation learning): LZN can implement unsupervised representation
learning without auxiliary loss functions, outperforming the seminal MoCo and
SimCLR methods by 9.3% and 0.2%, respectively, on downstream linear
classification on ImageNet. (3) LZN can solve multiple tasks simultaneously
(joint generation and classification): With image and label encoders/decoders,
LZN performs both tasks jointly by design, improving FID and achieving SoTA
classification accuracy on CIFAR10. The code and trained models are available
at https://github.com/microsoft/latent-zoning-networks. The project website is
at https://zinanlin.me/blogs/latent_zoning_networks.html.

</details>


### [382] [Personalized Prediction By Learning Halfspace Reference Classes Under Well-Behaved Distribution](https://arxiv.org/abs/2509.15592)
*Jizhou Huang,Brendan Juba*

Main category: cs.LG

TL;DR: 通过为每个查询学习一个易于理解的预测器，提出一种个性化预测方案，以解决机器学习模型在复杂性和可解释性之间进行权衡的问题。


<details>
  <summary>Details</summary>
Motivation: 解决机器学习模型在复杂性和可解释性之间进行权衡的问题，特别是在医疗保健等高风险应用中，对准确且可解释的预测方法的需求日益增长。

Method: 提出一种个性化预测方案，为每个查询学习一个易于理解的预测器，具体来说是学习一个稀疏线性分类器，该分类器在包含查询点的特定子群体上具有竞争力。研究了该预测模型在标签无关设置中表示为“半空间”的子群体上的PAC学习能力。

Result: 证明了稀疏线性分类器和同类半空间子集个性化预测的第一个上限 $O(\mathrm{opt}^{1/4})$，并提出了一个用于学习个性化预测的分布特定PAC学习算法，该算法利用了参考类别学习算法和稀疏线性表示列表学习器。

Conclusion: 该工作在PAC学习的框架下，为稀疏线性分类器和同类半空间子集提供了个性化预测的理论保证，并通过在标准基准数据集上的评估证明了所提出算法的有效性。

Abstract: In machine learning applications, predictive models are trained to serve
future queries across the entire data distribution. Real-world data often
demands excessively complex models to achieve competitive performance, however,
sacrificing interpretability. Hence, the growing deployment of machine learning
models in high-stakes applications, such as healthcare, motivates the search
for methods for accurate and explainable predictions. This work proposes a
Personalized Prediction scheme, where an easy-to-interpret predictor is learned
per query. In particular, we wish to produce a "sparse linear" classifier with
competitive performance specifically on some sub-population that includes the
query point. The goal of this work is to study the PAC-learnability of this
prediction model for sub-populations represented by "halfspaces" in a
label-agnostic setting. We first give a distribution-specific PAC-learning
algorithm for learning reference classes for personalized prediction. By
leveraging both the reference-class learning algorithm and a list learner of
sparse linear representations, we prove the first upper bound,
$O(\mathrm{opt}^{1/4} )$, for personalized prediction with sparse linear
classifiers and homogeneous halfspace subsets. We also evaluate our algorithms
on a variety of standard benchmark data sets.

</details>


### [383] [Efficient Extractive Text Summarization for Online News Articles Using Machine Learning](https://arxiv.org/abs/2509.15614)
*Sajib Biswas,Milon Biswas,Arunima Mandal,Fatema Tabassum Liza,Joy Sarker*

Main category: cs.LG

TL;DR: 本研究旨在使用机器学习技术，特别是BERT嵌入和LSTM网络，对新闻文章进行抽取式文本摘要，并在Cornell Newsroom数据集上进行了实验。


<details>
  <summary>Details</summary>
Motivation: 信息过载时代，在线新闻文章的内容管理依赖于高效的摘要来提高可访问性和用户参与度。

Method: 使用BERT嵌入将文本数据转化为数值表示，并将摘要任务构建为二元分类问题，探索了逻辑回归、前馈神经网络和长短期记忆（LSTM）网络等多种模型。

Result: LSTM网络在F1分数和ROUGE-1指标上优于Lede-3等基线方法和更简单的模型。

Conclusion: 自动化摘要技术在改进在线新闻平台的“内容管理系统”方面具有巨大潜力，能够实现更高效的内容组织和更好的用户体验。

Abstract: In the age of information overload, content management for online news
articles relies on efficient summarization to enhance accessibility and user
engagement. This article addresses the challenge of extractive text
summarization by employing advanced machine learning techniques to generate
concise and coherent summaries while preserving the original meaning. Using the
Cornell Newsroom dataset, comprising 1.3 million article-summary pairs, we
developed a pipeline leveraging BERT embeddings to transform textual data into
numerical representations. By framing the task as a binary classification
problem, we explored various models, including logistic regression,
feed-forward neural networks, and long short-term memory (LSTM) networks. Our
findings demonstrate that LSTM networks, with their ability to capture
sequential dependencies, outperform baseline methods like Lede-3 and simpler
models in F1 score and ROUGE-1 metrics. This study underscores the potential of
automated summarization in improving content management systems for online news
platforms, enabling more efficient content organization and enhanced user
experiences.

</details>


### [384] [Information Geometry of Variational Bayes](https://arxiv.org/abs/2509.15641)
*Mohammad Emtiyaz Khan*

Main category: cs.LG

TL;DR: 本文揭示了信息几何与变分贝叶斯（VB）之间的根本联系，并探讨了其对机器学习的影响。在特定条件下，VB 求解必须估计或计算自然梯度。我们利用 Khan 和 Rue (2023) 提出的贝叶斯学习法则 (BLR) 自然梯度下降算法，展示了这一事实的几个后果，包括（一）将贝叶斯规则简化为自然梯度的加法、（二）对梯度下降方法中使用的二次代理进行泛化，以及（三）大规模语言模型中 VB 算法的大规模实现。我们希望通过强调信息几何和贝叶斯这两个领域的共同起源，促进这两个领域的交叉合作，尽管这种联系及其后果并非全新。


<details>
  <summary>Details</summary>
Motivation: 本文旨在揭示信息几何与变分贝叶斯（VB）之间的根本联系，并阐述这一联系对机器学习领域产生的深远影响。作者希望通过强调这两个研究领域的共同起源，促进相关领域的进一步研究与合作。

Method: 本文利用 Khan 和 Rue (2023) 提出的贝叶斯学习法则 (BLR) 自然梯度下降算法，来推导和展示信息几何与变分贝叶斯（VB）之间的联系所带来的具体后果。这些后果包括将贝叶斯规则简化为自然梯度的加法、泛化梯度下降算法中使用的二次代理，以及实现大规模语言模型中 VB 算法的大规模应用。

Result: 本文的研究结果表明，在特定条件下，变分贝叶斯（VB）的求解过程必然涉及到自然梯度的估计和计算。具体而言，文章展示了如何利用 BLR 算法将贝叶斯规则简化为自然梯度的加法，如何泛化梯度下降方法中的二次代理，并成功地将 VB 算法应用于大规模语言模型。

Conclusion: 本文强调了信息几何与变分贝叶斯（VB）之间存在深刻的内在联系，并展示了这种联系在机器学习，特别是在自然梯度计算和大规模模型应用方面的重要意义。作者希望借此研究能够激发更多交叉学科的合作，推动相关领域的发展。

Abstract: We highlight a fundamental connection between information geometry and
variational Bayes (VB) and discuss its consequences for machine learning. Under
certain conditions, a VB solution always requires estimation or computation of
natural gradients. We show several consequences of this fact by using the
natural-gradient descent algorithm of Khan and Rue (2023) called the Bayesian
Learning Rule (BLR). These include (i) a simplification of Bayes' rule as
addition of natural gradients, (ii) a generalization of quadratic surrogates
used in gradient-based methods, and (iii) a large-scale implementation of VB
algorithms for large language models. Neither the connection nor its
consequences are new but we further emphasize the common origins of the two
fields of information geometry and Bayes with a hope to facilitate more work at
the intersection of the two fields.

</details>


### [385] [Uncertainty-Based Smooth Policy Regularisation for Reinforcement Learning with Few Demonstrations](https://arxiv.org/abs/2509.15981)
*Yujie Zhu,Charles A. Hepburn,Matthew Thorpe,Giovanni Montana*

Main category: cs.LG

TL;DR: SPReD是一个用于处理稀疏奖励强化学习中模仿演示时机问题的框架，通过量化不确定性来决定何时模仿演示，并实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 在稀疏奖励强化学习中，演示可以加速学习，但确定何时模仿演示仍然是一个挑战。

Method: SPReD使用集成方法对演示和策略动作的Q值分布进行建模，量化不确定性。提出两种不确定性感知方法：估计演示优越性可能性的概率方法，以及通过统计显著性扩展模仿的基于优势的方法。SPReD应用连续的、与不确定性成比例的正则化权重，以减少训练过程中的梯度方差。

Result: SPReD在八个机器人任务的实验中取得了显著的改进，在复杂任务上的表现比现有方法好14倍，同时保持了对演示质量和数量的鲁棒性。

Conclusion: SPReD通过不确定性量化和连续正则化，有效解决了模仿决策问题，并在机器人任务中取得了优于现有方法的性能。

Abstract: In reinforcement learning with sparse rewards, demonstrations can accelerate
learning, but determining when to imitate them remains challenging. We propose
Smooth Policy Regularisation from Demonstrations (SPReD), a framework that
addresses the fundamental question: when should an agent imitate a
demonstration versus follow its own policy? SPReD uses ensemble methods to
explicitly model Q-value distributions for both demonstration and policy
actions, quantifying uncertainty for comparisons. We develop two complementary
uncertainty-aware methods: a probabilistic approach estimating the likelihood
of demonstration superiority, and an advantage-based approach scaling imitation
by statistical significance. Unlike prevailing methods (e.g. Q-filter) that
make binary imitation decisions, SPReD applies continuous,
uncertainty-proportional regularisation weights, reducing gradient variance
during training. Despite its computational simplicity, SPReD achieves
remarkable gains in experiments across eight robotics tasks, outperforming
existing approaches by up to a factor of 14 in complex tasks while maintaining
robustness to demonstration quality and quantity. Our code is available at
https://github.com/YujieZhu7/SPReD.

</details>


### [386] [Toward Efficient Influence Function: Dropout as a Compression Tool](https://arxiv.org/abs/2509.15651)
*Yuchen Zhang,Mohammad Mohammadi Amiri*

Main category: cs.LG

TL;DR: 本文提出一种利用 Dropout 作为梯度压缩机制来计算模型影响函数的新方法，以应对大规模模型面临的计算和内存挑战。


<details>
  <summary>Details</summary>
Motivation: 理解模型行为、增强透明度和选择训练数据需要评估训练数据对模型的影响。而现有的影响函数计算方法成本高昂，尤其对于大型模型。

Method: 提出一种利用 Dropout 作为梯度压缩机制来计算影响函数的新方法，以减少计算和内存开销。

Result: 该方法在理论分析和实证验证中都证明了其有效性，能够保留数据影响的关键组成部分，并可应用于现代大型模型。

Conclusion: 所提出的方法通过 Dropout 梯度压缩，能够更有效地计算影响函数，解决了现有方法的计算和内存瓶颈，并能成功应用于大型模型。

Abstract: Assessing the impact the training data on machine learning models is crucial
for understanding the behavior of the model, enhancing the transparency, and
selecting training data. Influence function provides a theoretical framework
for quantifying the effect of training data points on model's performance given
a specific test data. However, the computational and memory costs of influence
function presents significant challenges, especially for large-scale models,
even when using approximation methods, since the gradients involved in
computation are as large as the model itself. In this work, we introduce a
novel approach that leverages dropout as a gradient compression mechanism to
compute the influence function more efficiently. Our method significantly
reduces computational and memory overhead, not only during the influence
function computation but also in gradient compression process. Through
theoretical analysis and empirical validation, we demonstrate that our method
could preserves critical components of the data influence and enables its
application to modern large-scale models.

</details>


### [387] [Nonconvex Regularization for Feature Selection in Reinforcement Learning](https://arxiv.org/abs/2509.15652)
*Kyohei Suzuki,Konstantinos Slavakis*

Main category: cs.LG

TL;DR: 提出了一种用于强化学习（RL）特征选择的高效批量算法，并具有理论收敛保证。


<details>
  <summary>Details</summary>
Motivation: 为了减轻传统正则化方案中固有的估计偏差，提出了将策略评估的 Bellman 残差目标函数与诱导稀疏性的非凸投影最小最大凹（PMC）惩罚相结合的框架。

Method: 将所提出的 Bellman 残差目标函数视为非单调包含问题的特例，并利用前向反射后向分裂（FRBS）算法进行求解，该算法具有新颖的收敛条件。

Result: 在基准数据集上的数值实验表明，该方法在具有许多噪声特征的情况下，性能优于最先进的特征选择方法。

Conclusion: 所提出的高效批量算法结合了基于 Bellman 残差的策略评估和 PMC 惩罚，在强化学习特征选择方面展现出优越的性能和理论保证。

Abstract: This work proposes an efficient batch algorithm for feature selection in
reinforcement learning (RL) with theoretical convergence guarantees. To
mitigate the estimation bias inherent in conventional regularization schemes,
the first contribution extends policy evaluation within the classical
least-squares temporal-difference (LSTD) framework by formulating a
Bellman-residual objective regularized with the sparsity-inducing, nonconvex
projected minimax concave (PMC) penalty. Owing to the weak convexity of the PMC
penalty, this formulation can be interpreted as a special instance of a general
nonmonotone-inclusion problem. The second contribution establishes novel
convergence conditions for the forward-reflected-backward splitting (FRBS)
algorithm to solve this class of problems. Numerical experiments on benchmark
datasets demonstrate that the proposed approach substantially outperforms
state-of-the-art feature-selection methods, particularly in scenarios with many
noisy features.

</details>


### [388] [KITE: Kernelized and Information Theoretic Exemplars for In-Context Learning](https://arxiv.org/abs/2509.15676)
*Vaibhav Singh,Soumya Suvra Ghosal,Kapu Nirmal Joshua,Soumyabrata Pal,Sayak Ray Chowdhury*

Main category: cs.LG

TL;DR: ICL 中的示例选择可以通过信息论方法从根本上解决，而不是依赖于最近邻方法。通过将 LLM 建模为线性函数，我们开发了一种特定于查询的优化方法，该方法使用近似子模函数和贪心算法来选择示例，并结合核技巧和最优设计正则化器来提高性能和多样性。


<details>
  <summary>Details</summary>
Motivation: 在上下文学习（ICL）中，LLM 只能通过几个示例来适应新任务，选择最有效的示例以最大化给定用户查询的性能是一个关键挑战。现有的基于最近邻的方法存在泛化能力差和多样性不足的问题。

Method: 本文提出了一种信息论驱动的方法来解决 ICL 中的示例选择问题。该方法将 LLM 建模为输入嵌入上的线性函数，并将示例选择视为一个特定于查询的优化问题。使用一种近似子模函数和贪心算法来选择示例，并通过结合核技巧和最优设计正则化器来处理高维空间并鼓励多样性。

Result: 该方法在各种分类任务上显著优于标准的检索方法，表明了在真实世界、标签稀缺场景中，结构感知、多样化的示例选择对 ICL 的好处。

Conclusion: 所提出的信息论方法在 ICL 的示例选择方面取得了显著改进，通过结构感知和多样化的示例选择，为标签稀缺场景下的 LLM 适应提供了更有效的解决方案。

Abstract: In-context learning (ICL) has emerged as a powerful paradigm for adapting
large language models (LLMs) to new and data-scarce tasks using only a few
carefully selected task-specific examples presented in the prompt. However,
given the limited context size of LLMs, a fundamental question arises: Which
examples should be selected to maximize performance on a given user query?
While nearest-neighbor-based methods like KATE have been widely adopted for
this purpose, they suffer from well-known drawbacks in high-dimensional
embedding spaces, including poor generalization and a lack of diversity. In
this work, we study this problem of example selection in ICL from a principled,
information theory-driven perspective. We first model an LLM as a linear
function over input embeddings and frame the example selection task as a
query-specific optimization problem: selecting a subset of exemplars from a
larger example bank that minimizes the prediction error on a specific query.
This formulation departs from traditional generalization-focused learning
theoretic approaches by targeting accurate prediction for a specific query
instance. We derive a principled surrogate objective that is approximately
submodular, enabling the use of a greedy algorithm with an approximation
guarantee. We further enhance our method by (i) incorporating the kernel trick
to operate in high-dimensional feature spaces without explicit mappings, and
(ii) introducing an optimal design-based regularizer to encourage diversity in
the selected examples. Empirically, we demonstrate significant improvements
over standard retrieval methods across a suite of classification tasks,
highlighting the benefits of structure-aware, diverse example selection for ICL
in real-world, label-scarce scenarios.

</details>


### [389] [RMT-KD: Random Matrix Theoretic Causal Knowledge Distillation](https://arxiv.org/abs/2509.15724)
*Davide Ettori,Nastaran Darabi,Sureshkumar Senthilkumar,Amit Ranjan Trivedi*

Main category: cs.LG

TL;DR: RMT-KD是一种利用随机矩阵理论（RMT）进行知识蒸馏的压缩方法，通过保留信息量大的方向来减小网络规模，实现了显著的参数缩减和性能提升，同时降低了推理速度和功耗。


<details>
  <summary>Details</summary>
Motivation: 大型深度学习模型（如BERT和ResNet）虽然性能优越，但因其庞大的体积和计算需求，在边缘设备上的部署成本高昂。

Method: RMT-KD采用基于随机矩阵理论（RMT）的知识蒸馏方法，通过分析隐藏层表示的谱特性来识别并保留信息量大的方向，逐层进行因果性约简，并结合自蒸馏技术来维持模型的稳定性和准确性。该方法不依赖于剪枝或启发式秩选择。

Result: 在GLUE、AG News和CIFAR-10数据集上，RMT-KD实现了高达80%的参数缩减，而准确率仅损失2%。此外，推理速度提升了2.8倍，功耗降低了近一半。

Conclusion: RMT-KD是一种基于数学原理的网络蒸馏方法，能够有效地压缩深度学习模型，实现显著的性能提升和资源节约，为边缘设备的部署提供了有力的解决方案。

Abstract: Large deep learning models such as BERT and ResNet achieve state-of-the-art
performance but are costly to deploy at the edge due to their size and compute
demands. We present RMT-KD, a compression method that leverages Random Matrix
Theory (RMT) for knowledge distillation to iteratively reduce network size.
Instead of pruning or heuristic rank selection, RMT-KD preserves only
informative directions identified via the spectral properties of hidden
representations. RMT-based causal reduction is applied layer by layer with
self-distillation to maintain stability and accuracy. On GLUE, AG News, and
CIFAR-10, RMT-KD achieves up to 80% parameter reduction with only 2% accuracy
loss, delivering 2.8x faster inference and nearly halved power consumption.
These results establish RMT-KD as a mathematically grounded approach to network
distillation.

</details>


### [390] [EigenTrack: Spectral Activation Feature Tracking for Hallucination and Out-of-Distribution Detection in LLMs and VLMs](https://arxiv.org/abs/2509.15735)
*Davide Ettori,Nastaran Darabi,Sina Tayebati,Ranganath Krishnan,Mahesh Subedar,Omesh Tickoo,Amit Ranjan Trivedi*

Main category: cs.LG

TL;DR: EigenTrack是一个可解释的实时探测器，通过分析模型隐藏激活的谱几何特征来检测LLM的幻觉和分布外错误。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）虽然功能广泛，但容易出现幻觉和分布外（OOD）错误。

Method: EigenTrack利用隐藏激活的谱几何特征，即模型动力学的紧凑全局签名。它通过将熵、特征值间隙和与随机基线的KL散度等协方差谱统计数据流式传输到一个轻量级循环分类器中，来跟踪表征结构的时间偏移，从而在表面错误出现之前发出幻觉和OOD漂移的信号。

Result: 与黑盒和灰盒方法不同，EigenTrack仅需一次前向传播即可，无需重采样。与现有的白盒探测器不同，它能保留时间上下文，聚合全局信号，并提供可解释的准确性-延迟权衡。

Conclusion: EigenTrack能够提前检测LLM的幻觉和分布外漂移。

Abstract: Large language models (LLMs) offer broad utility but remain prone to
hallucination and out-of-distribution (OOD) errors. We propose EigenTrack, an
interpretable real-time detector that uses the spectral geometry of hidden
activations, a compact global signature of model dynamics. By streaming
covariance-spectrum statistics such as entropy, eigenvalue gaps, and KL
divergence from random baselines into a lightweight recurrent classifier,
EigenTrack tracks temporal shifts in representation structure that signal
hallucination and OOD drift before surface errors appear. Unlike black- and
grey-box methods, it needs only a single forward pass without resampling.
Unlike existing white-box detectors, it preserves temporal context, aggregates
global signals, and offers interpretable accuracy-latency trade-offs.

</details>


### [391] [Aircraft Fuel Flow Modelling with Ageing Effects: From Parametric Corrections to Neural Networks](https://arxiv.org/abs/2509.15736)
*Gabriel Jarry,Ramon Dalmau,Philippe Very,Junzi Sun*

Main category: cs.LG

TL;DR: 本研究通过集成发动机老化效应来改进飞机燃油消耗预测模型，并使用 A320-214 的飞行数据集进行了评估。


<details>
  <summary>Details</summary>
Motivation: 标准发动机燃油消耗模型通常忽略飞机老化造成的性能下降，这影响了航空公司的运营规划和对环境影响的评估。因此，本研究旨在开发更准确的燃油消耗预测模型，以考虑发动机老化效应。

Method: 本研究评估了多种方法，包括经典的基于物理的模型、经验校正系数以及数据驱动的神经网络架构。这些方法将飞机机龄作为输入特征或显式乘性偏差来整合发动机老化效应，并使用约 19000 次 A320-214 的飞行数据进行了评估。

Result: 研究结果表明，传统的基线模型在预测老旧飞机燃油消耗时存在低估。然而，使用考虑机龄的校正因子和神经网络模型可以显著减少这种偏差，并提高预测准确性。

Conclusion: 本研究强调了在预测模型中考虑飞机老化效应的重要性，这可以提高运营和环境评估的可靠性。此外，研究还指出了需要更多样化的数据集来捕捉实际发动机老化过程的复杂性。

Abstract: Accurate modelling of aircraft fuel-flow is crucial for both operational
planning and environmental impact assessment, yet standard parametric models
often neglect performance deterioration that occurs as aircraft age. This paper
investigates multiple approaches to integrate engine ageing effects into
fuel-flow prediction for the Airbus A320-214, using a comprehensive dataset of
approximately nineteen thousand Quick Access Recorder flights from nine
distinct airframes with varying years in service. We systematically evaluate
classical physics-based models, empirical correction coefficients, and
data-driven neural network architectures that incorporate age either as an
input feature or as an explicit multiplicative bias. Results demonstrate that
while baseline models consistently underestimate fuel consumption for older
aircraft, the use of age-dependent correction factors and neural models
substantially reduces bias and improves prediction accuracy. Nevertheless,
limitations arise from the small number of airframes and the lack of detailed
maintenance event records, which constrain the representativeness and
generalization of age-based corrections. This study emphasizes the importance
of accounting for the effects of ageing in parametric and machine learning
frameworks to improve the reliability of operational and environmental
assessments. The study also highlights the need for more diverse datasets that
can capture the complexity of real-world engine deterioration.

</details>


### [392] [GUI-ReWalk: Massive Data Generation for GUI Agent via Stochastic Exploration and Intent-Aware Reasoning](https://arxiv.org/abs/2509.15738)
*Musen Lin,Minghao Liu,Taoran Lu,Lichen Yuan,Yiwei Liu,Haonan Xu,Yu Miao,Yuhao Chao,Zhaojian Li*

Main category: cs.LG

TL;DR: GUI-ReWalk是一个通过推理增强的多阶段框架，用于合成真实且多样化的GUI轨迹，以解决GUI代理研究中数据稀疏的问题。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理研究受限于数据稀疏，手动标注成本高且不一致，合成数据则在多样性和任务覆盖率之间进行权衡。GUI-ReWalk旨在通过生成更真实、多样化的GUI轨迹数据来弥合这一差距。

Method: GUI-ReWalk框架包含一个随机探索阶段，模拟人类的试错行为，然后过渡到一个由推理引导的阶段，通过推断出的目标来指导交互。该框架还支持多步任务生成，可以构建跨多个应用程序的长期工作流。

Result: 在GUI-ReWalk数据集上训练的Qwen2.5-VL-7B模型在多个基准测试中表现出优越的交互流程覆盖率、更高的轨迹熵和更真实的用户意图。

Conclusion: GUI-ReWalk是一个可扩展且数据高效的框架，能够生成高质量的GUI轨迹数据，从而推动GUI代理研究并实现更鲁棒的现实世界自动化。

Abstract: Graphical User Interface (GUI) Agents, powered by large language and
vision-language models, hold promise for enabling end-to-end automation in
digital environments. However, their progress is fundamentally constrained by
the scarcity of scalable, high-quality trajectory data. Existing data
collection strategies either rely on costly and inconsistent manual annotations
or on synthetic generation methods that trade off between diversity and
meaningful task coverage. To bridge this gap, we present GUI-ReWalk: a
reasoning-enhanced, multi-stage framework for synthesizing realistic and
diverse GUI trajectories. GUI-ReWalk begins with a stochastic exploration phase
that emulates human trial-and-error behaviors, and progressively transitions
into a reasoning-guided phase where inferred goals drive coherent and
purposeful interactions. Moreover, it supports multi-stride task generation,
enabling the construction of long-horizon workflows across multiple
applications. By combining randomness for diversity with goal-aware reasoning
for structure, GUI-ReWalk produces data that better reflects the intent-aware,
adaptive nature of human-computer interaction. We further train Qwen2.5-VL-7B
on the GUI-ReWalk dataset and evaluate it across multiple benchmarks, including
Screenspot-Pro, OSWorld-G, UI-Vision, AndroidControl, and GUI-Odyssey. Results
demonstrate that GUI-ReWalk enables superior coverage of diverse interaction
flows, higher trajectory entropy, and more realistic user intent. These
findings establish GUI-ReWalk as a scalable and data-efficient framework for
advancing GUI agent research and enabling robust real-world automation.

</details>


### [393] [Incremental Multistep Forecasting of Battery Degradation Using Pseudo Targets](https://arxiv.org/abs/2509.15740)
*Jonathan Adam Rico,Nagarajan Raghavan,Senthilnath Jayavelu*

Main category: cs.LG

TL;DR: iFSNet是一种用于电池早期预后的一步在线机器学习模型，它通过生成伪目标来适应数据分布的变化，并取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的电池预后模型大多是离线模型，需要根据新的数据分布进行重训练，而在线模型在多步预测和模型校正方面存在挑战。

Method: 提出了一种名为iFSNet的在线增量式机器学习模型，该模型是FSNet的改进版本，采用逐样本（单程）的模式，利用伪目标进行多步预测。

Result: 在平滑退化数据集上，iFSNet实现了0.00197的RMSE和0.00154的MAE；在具有容量再生峰值的不规则退化数据集上，RMSE为0.01588，MAE为0.01234。

Conclusion: iFSNet通过引入伪目标，成功实现了电池预后的在线增量式多步预测，并且在不同退化模式的数据集上都表现出了良好的性能。

Abstract: Data-driven models accurately perform early battery prognosis to prevent
equipment failure and further safety hazards. Most existing machine learning
(ML) models work in offline mode which must consider their retraining
post-deployment every time new data distribution is encountered. Hence, there
is a need for an online ML approach where the model can adapt to varying
distributions. However, existing online incremental multistep forecasts are a
great challenge as there is no way to correct the model of its forecasts at the
current instance. Also, these methods need to wait for a considerable amount of
time to acquire enough streaming data before retraining. In this study, we
propose iFSNet (incremental Fast and Slow learning Network) which is a modified
version of FSNet for a single-pass mode (sample-by-sample) to achieve multistep
forecasting using pseudo targets. It uses a simple linear regressor of the
input sequence to extrapolate pseudo future samples (pseudo targets) and
calculate the loss from the rest of the forecast and keep updating the model.
The model benefits from the associative memory and adaptive structure
mechanisms of FSNet, at the same time the model incrementally improves by using
pseudo targets. The proposed model achieved 0.00197 RMSE and 0.00154 MAE on
datasets with smooth degradation trajectories while it achieved 0.01588 RMSE
and 0.01234 MAE on datasets having irregular degradation trajectories with
capacity regeneration spikes.

</details>


### [394] [On Optimal Steering to Achieve Exact Fairness](https://arxiv.org/abs/2509.15759)
*Mohit Sharma,Amit Jayant Deshpande,Chiranjib Bhattacharyya,Rajiv Ratn Shah*

Main category: cs.LG

TL;DR: 为了解决公平机器学习中的“偏见输入，偏见输出”问题，需要将数据特征分布或大语言模型（LLM）的内部表示引导至能保证群体公平结果的理想分布。本研究定义了“理想分布”，即在该分布上任何成本敏感风险的最小化器都能保证精确的群体公平结果（例如，人口统计均等、机会均等），从而避免公平性-效用权衡。研究提出了一种通过寻找KL散度最近的理想分布来进行最优引导的优化程序，并为来自常见参数族（如正态、对数正态）的分布提供了高效算法。实验结果表明，该最优引导技术在合成和真实世界数据集上均能提高公平性而不损害效用，有时甚至能提升效用。研究还演示了通过仿射变换引导LLM表示以减少多类分类中的偏见，例如在Bios数据集（De-Arteaga等人）上根据简短传记进行职业预测，并将LLM内部表示引导至期望输出，以确保模型在不同群体上表现 equally well。


<details>
  <summary>Details</summary>
Motivation: 解决公平机器学习中的‘偏见输入，偏见输出’问题，为模型输出提供可证明的公平性保证。

Method: 定义理想分布（在该分布上优化器可获得精确的群体公平结果），提出最优引导的优化程序（寻找KL散度最近的理想分布），并为常见参数族分布提供高效算法。对LLM表示进行仿射引导以减少偏见。

Result: 在合成和真实世界数据集上，最优引导技术提高了公平性，且不损害（有时甚至提升）效用。成功减少了LLM在职业预测任务中的偏见。

Conclusion: 通过寻找KL散度最近的理想分布，可以实现最优引导，从而在不损害效用的情况下提高公平性，并能有效应用于LLM表示以减少偏见。

Abstract: To fix the 'bias in, bias out' problem in fair machine learning, it is
important to steer feature distributions of data or internal representations of
Large Language Models (LLMs) to ideal ones that guarantee group-fair outcomes.
Previous work on fair generative models and representation steering could
greatly benefit from provable fairness guarantees on the model output. We
define a distribution as ideal if the minimizer of any cost-sensitive risk on
it is guaranteed to have exact group-fair outcomes (e.g., demographic parity,
equal opportunity)-in other words, it has no fairness-utility trade-off. We
formulate an optimization program for optimal steering by finding the nearest
ideal distribution in KL-divergence, and provide efficient algorithms for it
when the underlying distributions come from well-known parametric families
(e.g., normal, log-normal). Empirically, our optimal steering techniques on
both synthetic and real-world datasets improve fairness without diminishing
utility (and sometimes even improve utility). We demonstrate affine steering of
LLM representations to reduce bias in multi-class classification, e.g.,
occupation prediction from a short biography in Bios dataset (De-Arteaga et
al.). Furthermore, we steer internal representations of LLMs towards desired
outputs so that it works equally well across different groups.

</details>


### [395] [Learning to Optimize Capacity Planning in Semiconductor Manufacturing](https://arxiv.org/abs/2509.15767)
*Philipp Andelfinger,Jieyi Bi,Qiuyu Zhu,Jianan Zhou,Bo Zhang,Fei Fei Zhang,Chew Wye Chan,Boon Ping Gan,Wentong Cai,Jie Zhang*

Main category: cs.LG

TL;DR: 使用深度强化学习的神经网络模型进行半导体制造的容量规划


<details>
  <summary>Details</summary>
Motivation: 当前的启发式规则在处理复杂的工艺流程交互和瓶颈形成方面存在局限性。

Method: 提出一个基于神经网络的模型，使用深度强化学习进行训练，并利用异构图神经网络表示策略，直接捕捉机器和工艺步骤之间的关系。

Result: 在Intel的Minifab模型和SMT2020测试台中进行了评估，在最大测试场景下，吞吐量和周期时间均提高了约1.8%。

Conclusion: 基于深度强化学习的神经网络模型能够有效解决半导体制造中的容量规划问题，并能应对复杂的工艺流程和大规模的生产环境。

Abstract: In manufacturing, capacity planning is the process of allocating production
resources in accordance with variable demand. The current industry practice in
semiconductor manufacturing typically applies heuristic rules to prioritize
actions, such as future change lists that account for incoming machine and
recipe dedications. However, while offering interpretability, heuristics cannot
easily account for the complex interactions along the process flow that can
gradually lead to the formation of bottlenecks. Here, we present a neural
network-based model for capacity planning on the level of individual machines,
trained using deep reinforcement learning. By representing the policy using a
heterogeneous graph neural network, the model directly captures the diverse
relationships among machines and processing steps, allowing for proactive
decision-making. We describe several measures taken to achieve sufficient
scalability to tackle the vast space of possible machine-level actions.
  Our evaluation results cover Intel's small-scale Minifab model and
preliminary experiments using the popular SMT2020 testbed. In the largest
tested scenario, our trained policy increases throughput and decreases cycle
time by about 1.8% each.

</details>


### [396] [Generalization and Optimization of SGD with Lookahead](https://arxiv.org/abs/2509.15776)
*Kangcheng Li,Yunwen Lei*

Main category: cs.LG

TL;DR: Lookahead优化器通过双重权重更新机制提升了深度学习模型的性能，但现有理论分析主要关注其在训练数据上的收敛性，对其泛化能力的研究不足，且现有分析常受限于全局Lipschitz连续性等严格假设。本文利用平均模型稳定性，对Lookahead优化器与小批量SGD的结合进行了严格的稳定性和泛化性分析，在不假设Lipschitz连续性的情况下，推导了凸和强凸问题的泛化界限，并证明了在凸情况下泛化能力与批处理大小呈线性关系。


<details>
  <summary>Details</summary>
Motivation: 现有理论研究主要关注Lookahead优化器在训练数据上的收敛性，对其泛化能力的理解不足，且现有分析方法存在严格假设的限制，未能充分揭示优化与泛化之间的联系。

Method: 利用平均模型稳定性（on-average model stability）对Lookahead优化器与小批量SGD的结合进行严格的稳定性和泛化性分析，在不假设损失函数全局Lipschitz连续性的前提下，推导出凸和强凸问题的泛化界限。

Result: 推导了适用于凸和强凸问题的泛化界限，这些界限不依赖于全局Lipschitz连续性假设。证明了在凸情况下，泛化能力随批处理大小的增加呈线性加速。

Conclusion: 本文通过平均模型稳定性分析，为Lookahead优化器及其与小批量SGD的结合提供了更完善的泛化理论，克服了现有研究的局限性，并揭示了在凸问题中批处理大小对泛化能力的积极影响。

Abstract: The Lookahead optimizer enhances deep learning models by employing a
dual-weight update mechanism, which has been shown to improve the performance
of underlying optimizers such as SGD. However, most theoretical studies focus
on its convergence on training data, leaving its generalization capabilities
less understood. Existing generalization analyses are often limited by
restrictive assumptions, such as requiring the loss function to be globally
Lipschitz continuous, and their bounds do not fully capture the relationship
between optimization and generalization. In this paper, we address these issues
by conducting a rigorous stability and generalization analysis of the Lookahead
optimizer with minibatch SGD. We leverage on-average model stability to derive
generalization bounds for both convex and strongly convex problems without the
restrictive Lipschitzness assumption. Our analysis demonstrates a linear
speedup with respect to the batch size in the convex setting.

</details>


### [397] [Monte Carlo Tree Diffusion with Multiple Experts for Protein Design](https://arxiv.org/abs/2509.15796)
*Xuefeng Liu,Mingxuan Cao,Songhao Jiang,Xiao Luo,Xiaotian Duan,Mengdi Wang,Tobin R. Sosnick,Jinbo Xu,Rick Stevens*

Main category: cs.LG

TL;DR: MCTD-ME是一种结合了蒙特卡洛树搜索和扩散模型的蛋白质设计新方法，解决了现有方法在长程依赖和搜索空间过大方面的问题，并在逆向折叠任务中取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于自回归语言模型和蒙特卡洛树搜索（MCTS）的蛋白质设计方法在处理长程依赖和过大的搜索空间时存在困难。

Method: 提出MCTD-ME（Monte Carlo Tree Diffusion with Multiple Experts），将掩码扩散模型与树搜索相结合，实现了多令牌规划和高效探索。MCTD-ME使用经过生物物理保真度增强的扩散去噪作为 the rollout engine，联合修改多个位置并扩展到大的序列空间。此外，它利用不同容量的专家来丰富探索，并通过基于pLDDT的掩码策略来指导，该策略针对低置信度区域并保留可靠的残基。提出了一种新的多专家选择规则（PH-UCT-ME），将预测熵UCT扩展到专家集合。

Result: 在逆向折叠任务（CAMEO和PDB基准）上，MCTD-ME在序列恢复（AAR）和结构相似性（scTM）方面均优于单专家和无指导基线，并且在处理更长蛋白质时优势更明显，多专家指导也带来了好处。

Conclusion: MCTD-ME框架具有模型无关性，并且可以应用于逆向折叠之外的领域，包括从头蛋白质工程和多目标分子生成。

Abstract: The goal of protein design is to generate amino acid sequences that fold into
functional structures with desired properties. Prior methods combining
autoregressive language models with Monte Carlo Tree Search (MCTS) struggle
with long-range dependencies and suffer from an impractically large search
space. We propose MCTD-ME, Monte Carlo Tree Diffusion with Multiple Experts,
which integrates masked diffusion models with tree search to enable multi-token
planning and efficient exploration. Unlike autoregressive planners, MCTD-ME
uses biophysical-fidelity-enhanced diffusion denoising as the rollout engine,
jointly revising multiple positions and scaling to large sequence spaces. It
further leverages experts of varying capacities to enrich exploration, guided
by a pLDDT-based masking schedule that targets low-confidence regions while
preserving reliable residues. We propose a novel multi-expert selection rule
(PH-UCT-ME) extends predictive-entropy UCT to expert ensembles. On the inverse
folding task (CAMEO and PDB benchmarks), MCTD-ME outperforms single-expert and
unguided baselines in both sequence recovery (AAR) and structural similarity
(scTM), with gains increasing for longer proteins and benefiting from
multi-expert guidance. More generally, the framework is model-agnostic and
applicable beyond inverse folding, including de novo protein engineering and
multi-objective molecular generation.

</details>


### [398] [EmoHeal: An End-to-End System for Personalized Therapeutic Music Retrieval from Fine-grained Emotions](https://arxiv.org/abs/2509.15986)
*Xinchen Wan,Jinhua Liang,Huan Zhang*

Main category: cs.LG

TL;DR: EmoHeal是一个为用户提供个性化、三阶段支持性叙事的端到端系统，旨在解决数字心理健康工具忽视细微情绪状态的问题。该系统能从用户文本中检测27种细粒度情绪，并通过基于音乐治疗原则的知识图谱将其映射到音乐参数。EmoHeal利用CLAMP3模型检索视听内容，引导用户从当前状态转向更平静的状态。一项包含40名参与者的研究表明，该系统在改善情绪和情绪识别准确性方面效果显著，并验证了细粒度方法的可行性。


<details>
  <summary>Details</summary>
Motivation: 现有的数字心理健康工具往往忽视日常挑战背后细微的情绪状态，例如失眠前焦虑影响全球超过15亿人，但当前方法仍是“一刀切”的，无法满足个体需求。

Method: EmoHeal系统通过以下方式运作：1. 使用微调的XLM-RoBERTa模型检测用户文本中的27种细粒度情绪。2. 通过一个以音乐治疗原理（GEMS, iso-principle）为基础的知识图谱，将检测到的情绪映射到音乐参数。3. 利用CLAMP3模型检索视听内容，遵循“匹配-引导-目标”的策略，将用户从当前情绪状态引导至更平静的状态。

Result: 一项包含40名参与者的被试内研究表明，EmoHeal在改善用户情绪方面效果显著（平均提升4.12，p<0.001），并且用户感知到的情绪识别准确性也很高（平均4.05，p<0.001）。此外，研究发现感知准确性与治疗效果之间存在强相关性（r=0.72，p<0.001），这证实了细粒度情绪识别方法的有效性。

Conclusion: 研究结果证明了以理论为驱动、能够感知情绪的数字健康工具的可行性，并为实施音乐治疗原理提供了一个可扩展的人工智能蓝图。

Abstract: Existing digital mental wellness tools often overlook the nuanced emotional
states underlying everyday challenges. For example, pre-sleep anxiety affects
more than 1.5 billion people worldwide, yet current approaches remain largely
static and "one-size-fits-all", failing to adapt to individual needs. In this
work, we present EmoHeal, an end-to-end system that delivers personalized,
three-stage supportive narratives. EmoHeal detects 27 fine-grained emotions
from user text with a fine-tuned XLM-RoBERTa model, mapping them to musical
parameters via a knowledge graph grounded in music therapy principles (GEMS,
iso-principle). EmoHeal retrieves audiovisual content using the CLAMP3 model to
guide users from their current state toward a calmer one
("match-guide-target"). A within-subjects study (N=40) demonstrated significant
supportive effects, with participants reporting substantial mood improvement
(M=4.12, p<0.001) and high perceived emotion recognition accuracy (M=4.05,
p<0.001). A strong correlation between perceived accuracy and therapeutic
outcome (r=0.72, p<0.001) validates our fine-grained approach. These findings
establish the viability of theory-driven, emotion-aware digital wellness tools
and provides a scalable AI blueprint for operationalizing music therapy
principles.

</details>


### [399] [SABER: Uncovering Vulnerabilities in Safety Alignment via Cross-Layer Residual Connection](https://arxiv.org/abs/2509.16060)
*Maithili Joshi,Palash Nandi,Tanmoy Chakraborty*

Main category: cs.LG

TL;DR: LLM 在安全对齐训练后仍然容易受到越狱攻击。本研究发现 LLM 的安全机制主要存在于中间到后期层。提出了一种新的白盒越狱方法 SABER，通过连接两个中间层来绕过安全对齐，在 HarmBench 测试集上取得了显著的改进，并且对困惑度影响很小。


<details>
  <summary>Details</summary>
Motivation: 尽管 LLM 经过了安全对齐训练，但仍然容易受到越狱攻击，导致模型生成其被训练来避免的有害输出。

Method: 提出了一种名为 SABER (Safety Alignment Bypass via Extra Residuals) 的新颖白盒越狱方法。该方法通过在中间层 s 和 e (s < e) 之间建立残差连接来绕过安全对齐机制。

Result: SABER 在 HarmBench 测试集上的性能比性能最佳的基线提高了 51%。在 HarmBench 验证集上的困惑度评估显示，SABER 仅引起了轻微的移位。

Conclusion: LLM 的安全对齐机制主要集中在模型的中间到后期层。SABER 方法通过利用这一发现，有效地绕过了这些安全机制，并在不显著影响模型性能的情况下实现了越狱。

Abstract: Large Language Models (LLMs) with safe-alignment training are powerful
instruments with robust language comprehension capabilities. These models
typically undergo meticulous alignment procedures involving human feedback to
ensure the acceptance of safe inputs while rejecting harmful or unsafe ones.
However, despite their massive scale and alignment efforts, LLMs remain
vulnerable to jailbreak attacks, where malicious users manipulate the model to
produce harmful outputs that it was explicitly trained to avoid. In this study,
we find that the safety mechanisms in LLMs are predominantly embedded in the
middle-to-late layers. Building on this insight, we introduce a novel white-box
jailbreak method, SABER (Safety Alignment Bypass via Extra Residuals), which
connects two intermediate layers $s$ and $e$ such that $s < e$, through a
residual connection. Our approach achieves a 51% improvement over the
best-performing baseline on the HarmBench test set. Furthermore, SABER induces
only a marginal shift in perplexity when evaluated on the HarmBench validation
set. The source code is publicly available at
https://github.com/PalGitts/SABER.

</details>


### [400] [ThermalGuardian: Temperature-Aware Testing of Automotive Deep Learning Frameworks](https://arxiv.org/abs/2509.15815)
*Yinglong Zou,Juan Zhai,Chunrong Fang,Zhenyu Chen*

Main category: cs.LG

TL;DR: 自动驾驶中的深度学习框架在车用GPU的温度波动下会出现质量问题，现有的测试方法无法检测这些问题。本文提出了ThermalGuardian，首个在考虑温度变化的环境下对自动驾驶深度学习框架进行测试的方法。


<details>
  <summary>Details</summary>
Motivation: 车用GPU在-40°C至50°C的温度范围内工作，会因环境温度和计算发热导致GPU温度升高，进而引发动态频率调整（DVFS）。然而，现有的自动驾驶深度学习框架并未考虑这种温度引起的频率变化，导致计算密集型、高/混合精度以及时间序列算子出现延迟、错误、精度问题或同步问题。现有的测试方法忽略了温度对框架质量的影响，无法检测这些问题。

Method: ThermalGuardian通过以下方式解决上述问题：1. 针对温度敏感算子，利用模型变异规则生成测试输入模型。2. 基于牛顿冷却定律模拟GPU温度波动。3. 基于实时GPU温度控制GPU频率。

Result: ThermalGuardian是首个在温度变化环境下测试自动驾驶深度学习框架的方法，能够检测现有方法无法发现的质量问题。

Conclusion: ThermalGuardian填补了现有深度学习框架测试方法的空白，能够有效应对自动驾驶环境中由温度波动引起的功能和质量问题。

Abstract: Deep learning models play a vital role in autonomous driving systems,
supporting critical functions such as environmental perception. To accelerate
model inference, these deep learning models' deployment relies on automotive
deep learning frameworks, for example, PaddleInference in Apollo and TensorRT
in AutoWare. However, unlike deploying deep learning models on the cloud,
vehicular environments experience extreme ambient temperatures varying from
-40{\deg}C to 50{\deg}C, significantly impacting GPU temperature. Additionally,
heats generated when computing further lead to the GPU temperature increase.
These temperature fluctuations lead to dynamic GPU frequency adjustments
through mechanisms such as DVFS. However, automotive deep learning frameworks
are designed without considering the impact of temperature-induced frequency
variations. When deployed on temperature-varying GPUs, these frameworks suffer
critical quality issues: compute-intensive operators face delays or errors,
high/mixed-precision operators suffer from precision errors, and time-series
operators suffer from synchronization issues. The above quality issues cannot
be detected by existing deep learning framework testing methods because they
ignore temperature's effect on the deep learning framework quality. To bridge
this gap, we propose ThermalGuardian, the first automotive deep learning
framework testing method under temperature-varying environments. Specifically,
ThermalGuardian generates test input models using model mutation rules
targeting temperature-sensitive operators, simulates GPU temperature
fluctuations based on Newton's law of cooling, and controls GPU frequency based
on real-time GPU temperature.

</details>


### [401] [On the Convergence of Muon and Beyond](https://arxiv.org/abs/2509.15816)
*Da Chang,Yongxiang Liu,Ganzhao Yuan*

Main category: cs.LG

TL;DR: Muon-VR2 优化器在非凸设置中实现了最佳的 O(T^{-1/3}) 收敛率，弥补了 Muon 优化器理论理解的不足。


<details>
  <summary>Details</summary>
Motivation: 现有 Muon 优化器在处理神经网络中的矩阵结构参数方面取得了显著的经验成功，但其理论理解滞后于其实际性能，标准变体在随机非凸设置下的收敛率为 O(T^{-1/4})。

Method: 通过构建和分析一种称为 Muon-VR2 的方差缩减变体，并提供严格的理论证明，表明其可以达到 O(T^{-1/3}) 的收敛率。此外，还建立了 Muon 变体在 Polyak-Lojasiewicz (PL) 条件下的收敛保证。

Result: Muon-VR2 实现了 O(T^{-1/3}) 的最佳收敛率，匹配了该类问题的理论下界。在 CIFAR-10 和 C4 基准测试的实验中，其收敛性得到了验证。

Conclusion: 该研究首次证明了 Muon 类型优化器的最优性，并为开发更实用、更高效的加速变体指明了方向。

Abstract: The Muon optimizer has demonstrated remarkable empirical success in handling
matrix-structured parameters for training neural networks. However, a
significant gap persists between its practical performance and theoretical
understanding. Existing analyses indicate that the standard Muon variant
achieves only a suboptimal convergence rate of $\mathcal{O}(T^{-1/4})$ in
stochastic non-convex settings, where $T$ denotes the number of iterations. To
explore the theoretical limits of the Muon framework, we construct and analyze
a variance-reduced variant, termed Muon-VR2. We provide the first rigorous
proof that incorporating a variance-reduction mechanism enables Muon-VR2 to
attain an optimal convergence rate of $\tilde{\mathcal{O}}(T^{-1/3})$, thereby
matching the theoretical lower bound for this class of problems. Moreover, our
analysis establishes convergence guarantees for Muon variants under the
Polyak-{\L}ojasiewicz (P{\L}) condition. Extensive experiments on vision
(CIFAR-10) and language (C4) benchmarks corroborate our theoretical findings on
per-iteration convergence. Overall, this work provides the first proof of
optimality for a Muon-style optimizer and clarifies the path toward developing
more practically efficient, accelerated variants.

</details>


### [402] [Latent learning: episodic memory complements parametric learning by enabling flexible reuse of experiences](https://arxiv.org/abs/2509.16189)
*Andrew Kyle Lampinen,Martin Engelcke,Yuxuan Li,Arslan Chaudhry,James L. McClelland*

Main category: cs.LG

TL;DR: 机器学习系统在未能泛化时，会受到认知科学的启发，强调潜在学习和情景记忆的重要性。通过引入检索机制，可以提高跨任务的泛化能力，并解释当前机器学习系统数据效率低下的原因。


<details>
  <summary>Details</summary>
Motivation: 认知科学表明，机器学习系统在泛化方面存在不足，主要是因为它们未能进行潜在学习（即学习与当前任务无关但未来可能有用 M的信息）。

Method: 提出了一种包含检索机制的系统，该系统能够更灵活地利用学习经验，跨多个挑战实现更好的泛化。研究了有效利用检索的组成部分，包括类比学习在获取跨检索示例信息使用能力方面的重要性。

Result: 包含检索机制的系统在应对语言模型中的反转诅咒和基于代理的导航等问题时，表现出了更好的泛化能力。研究结果表明，检索方法可以与参数学习互补，从而提高泛化能力。

Conclusion: 机器学习系统数据效率低下可能源于其未能进行潜在学习。检索方法可以作为参数学习的一种补充，从而提高泛化能力，并可能缩小机器学习与人类智能之间在数据效率方面的差距。

Abstract: When do machine learning systems fail to generalize, and what mechanisms
could improve their generalization? Here, we draw inspiration from cognitive
science to argue that one weakness of machine learning systems is their failure
to exhibit latent learning -- learning information that is not relevant to the
task at hand, but that might be useful in a future task. We show how this
perspective links failures ranging from the reversal curse in language modeling
to new findings on agent-based navigation. We then highlight how cognitive
science points to episodic memory as a potential part of the solution to these
issues. Correspondingly, we show that a system with an oracle retrieval
mechanism can use learning experiences more flexibly to generalize better
across many of these challenges. We also identify some of the essential
components for effectively using retrieval, including the importance of
within-example in-context learning for acquiring the ability to use information
across retrieved examples. In summary, our results illustrate one possible
contributor to the relative data inefficiency of current machine learning
systems compared to natural intelligence, and help to understand how retrieval
methods can complement parametric learning to improve generalization.

</details>


### [403] [HyP-ASO: A Hybrid Policy-based Adaptive Search Optimization Framework for Large-Scale Integer Linear Programs](https://arxiv.org/abs/2509.15828)
*Ning Xu,Junkai Zhang,Yang Wu,Huigen Ye,Hua Xu,Huiling Xu,Yifan Zhang*

Main category: cs.LG

TL;DR: HyP-ASO是一个结合自定义公式和深度强化学习（RL）的混合方法，用于改进大规模整数线性规划（ILP）的求解，通过自适应地生成更有效的邻域来加速求解过程。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大邻域搜索（LNS）的框架在生成有效的邻域方面存在困难，限制了其在NP难问题上的性能，因此需要一种改进的方法来加速ILP的求解。

Method: HyP-ASO结合了一个自定义公式和一个RL策略网络。该公式利用可行解来计算变量在邻域生成过程中的选择概率，而RL策略网络则预测邻域的大小。

Result: 实验表明，HyP-ASO在处理大规模ILP时，显著优于现有的LNS方法。该框架轻量且高度可扩展。

Conclusion: HyP-ASO通过结合自定义公式和深度强化学习，有效地解决了大规模ILP求解中的邻域生成难题，并表现出优越的性能和可扩展性。

Abstract: Directly solving large-scale Integer Linear Programs (ILPs) using traditional
solvers is slow due to their NP-hard nature. While recent frameworks based on
Large Neighborhood Search (LNS) can accelerate the solving process, their
performance is often constrained by the difficulty in generating sufficiently
effective neighborhoods. To address this challenge, we propose HyP-ASO, a
hybrid policy-based adaptive search optimization framework that combines a
customized formula with deep Reinforcement Learning (RL). The formula leverages
feasible solutions to calculate the selection probabilities for each variable
in the neighborhood generation process, and the RL policy network predicts the
neighborhood size. Extensive experiments demonstrate that HyP-ASO significantly
outperforms existing LNS-based approaches for large-scale ILPs. Additional
experiments show it is lightweight and highly scalable, making it well-suited
for solving large-scale ILPs.

</details>


### [404] [Tsururu: A Python-based Time Series Forecasting Strategies Library](https://arxiv.org/abs/2509.15843)
*Alina Kostromina,Kseniia Kuvshinova,Aleksandr Yugay,Andrey Savchenko,Dmitry Simakov*

Main category: cs.LG

TL;DR: Tsururu是一个Python库，它通过灵活组合全局和多变量方法以及多步预测策略，并能与各种预测模型无缝集成，从而弥合了SOTA研究与工业应用之间的差距。


<details>
  <summary>Details</summary>
Motivation: 当前时间序列研究主要集中于新模型的开发，而选择最优训练模型的方法这一关键问题被忽视了。

Method: Tsururu是一个Python库，能够灵活组合全局和多变量方法以及多步预测策略，并能与各种预测模型无缝集成。

Result: Tsururu弥合了SOTA研究与工业应用之间的差距，为时间序列预测提供了更灵活的解决方案。

Conclusion: Tsururu通过提供灵活的组合方法和无缝集成能力，解决了现有时间序列研究中对最优模型选择方法探索不足的问题。

Abstract: While current time series research focuses on developing new models, crucial
questions of selecting an optimal approach for training such models are
underexplored. Tsururu, a Python library introduced in this paper, bridges SoTA
research and industry by enabling flexible combinations of global and
multivariate approaches and multi-step-ahead forecasting strategies. It also
enables seamless integration with various forecasting models. Available at
https://github.com/sb-ai-lab/tsururu .

</details>


### [405] [EvoBrain: Dynamic Multi-channel EEG Graph Modeling for Time-evolving Brain Network](https://arxiv.org/abs/2509.15857)
*Rikuto Kotoge,Zheng Chen,Tasuku Kimura,Yasuko Matsubara,Takufumi Yanagisawa,Haruhiko Kishima,Yasushi Sakurai*

Main category: cs.LG

TL;DR: 动态图神经网络（GNN）在脑电图（EEG）癫痫检测中潜力巨大，但现有方法未能充分捕捉大脑状态的动态变化。本文提出了EvoBrain模型，通过理论分析和创新的双流Mamba架构与图卷积网络（GCN）相结合，解决了这些挑战，显著提高了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有动态GNN方法在捕捉大脑连接的动态演变以及联合建模时域信号、图结构及其交互方面存在挑战，导致性能不一致。

Method: 提出了一种名为EvoBrain的新型癫痫检测模型，该模型结合了双流Mamba架构和增强的图卷积网络（GCN），并引入了显式的动态图结构，使节点和边都能随时间演变。模型还进行了理论分析，证明了显式动态建模和时-图（time-then-graph）方法的有效性。

Result: 与动态GNN基线相比，EvoBrain将AUROC提高了23%，F1分数提高了30%。

Conclusion: 本文首次对动态GNN在癫痫检测中的两个关键挑战进行了理论分析，并提出了EvoBrain模型，该模型通过显式的动态建模和时-图（time-then-graph）方法，显著提高了癫痫检测的准确性和效率。

Abstract: Dynamic GNNs, which integrate temporal and spatial features in
Electroencephalography (EEG) data, have shown great potential in automating
seizure detection. However, fully capturing the underlying dynamics necessary
to represent brain states, such as seizure and non-seizure, remains a
non-trivial task and presents two fundamental challenges. First, most existing
dynamic GNN methods are built on temporally fixed static graphs, which fail to
reflect the evolving nature of brain connectivity during seizure progression.
Second, current efforts to jointly model temporal signals and graph structures
and, more importantly, their interactions remain nascent, often resulting in
inconsistent performance. To address these challenges, we present the first
theoretical analysis of these two problems, demonstrating the effectiveness and
necessity of explicit dynamic modeling and time-then-graph dynamic GNN method.
Building on these insights, we propose EvoBrain, a novel seizure detection
model that integrates a two-stream Mamba architecture with a GCN enhanced by
Laplacian Positional Encoding, following neurological insights. Moreover,
EvoBrain incorporates explicitly dynamic graph structures, allowing both nodes
and edges to evolve over time. Our contributions include (a) a theoretical
analysis proving the expressivity advantage of explicit dynamic modeling and
time-then-graph over other approaches, (b) a novel and efficient model that
significantly improves AUROC by 23% and F1 score by 30%, compared with the
dynamic GNN baseline, and (c) broad evaluations of our method on the
challenging early seizure prediction tasks.

</details>


### [406] [Efficient Long-Tail Learning in Latent Space by sampling Synthetic Data](https://arxiv.org/abs/2509.15859)
*Nakul Sharma*

Main category: cs.LG

TL;DR: 提出了一种利用视觉基础模型的潜在空间生成合成数据的新框架，并使用混合的真实和合成数据来训练简单的线性分类器，以解决长尾分类问题，该方法在CIFAR-100-LT基准测试中取得了新的最先进成果，并在Places-LT基准测试中表现出强大的性能。


<details>
  <summary>Details</summary>
Motivation: 不平衡分类数据集常常导致模型在代表性不足的类别上表现不佳，尽管现有的微调方法取得了进展，但仍存在计算资源需求高和未能完全缩小与平衡数据集训练网络之间差距的问题。

Method: 利用视觉基础模型的丰富语义潜在空间生成合成数据，并结合真实数据训练一个简单的线性分类器。

Result: 在CIFAR-100-LT基准测试中取得了新的最先进成果，并在Places-LT基准测试中展现了强大的性能。

Conclusion: 该方法简单有效，计算效率高，能够有效解决长尾分类问题，并且具有良好的适应性。

Abstract: Imbalanced classification datasets pose significant challenges in machine
learning, often leading to biased models that perform poorly on
underrepresented classes. With the rise of foundation models, recent research
has focused on the full, partial, and parameter-efficient fine-tuning of these
models to deal with long-tail classification. Despite the impressive
performance of these works on the benchmark datasets, they still fail to close
the gap with the networks trained using the balanced datasets and still require
substantial computational resources, even for relatively smaller datasets.
Underscoring the importance of computational efficiency and simplicity, in this
work we propose a novel framework that leverages the rich semantic latent space
of Vision Foundation Models to generate synthetic data and train a simple
linear classifier using a mixture of real and synthetic data for long-tail
classification. The computational efficiency gain arises from the number of
trainable parameters that are reduced to just the number of parameters in the
linear model. Our method sets a new state-of-the-art for the CIFAR-100-LT
benchmark and demonstrates strong performance on the Places-LT benchmark,
highlighting the effectiveness and adaptability of our simple and effective
approach.

</details>


### [407] [SAGE: Semantic-Aware Shared Sampling for Efficient Diffusion](https://arxiv.org/abs/2509.15865)
*Haoran Zhao,Tong Bai,Lei Huang,Xiaoyu Liang*

Main category: cs.LG

TL;DR: SAGE通过共享语义相似查询的早期采样来减少扩散模型的采样成本，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散模型采样成本高，需要多次顺序评估，这限制了其应用。现有的加速方法（如优化求解器或蒸馏）各自处理查询，效率不高。

Method: 提出了一种名为SAGE的语义感知共享采样框架，该框架结合了共享采样方案和定制的训练策略，以提高效率和保持质量。

Result: SAGE将采样成本降低了25.5%，同时生成质量得到改善，FID降低了5.0%，CLIP提高了5.4%，多样性提高了160%。

Conclusion: SAGE通过共享早期采样阶段来有效降低扩散模型的采样成本，同时通过专门的训练策略来保持或提高生成质量，在效率和质量方面均优于基线方法。

Abstract: Diffusion models manifest evident benefits across diverse domains, yet their
high sampling cost, requiring dozens of sequential model evaluations, remains a
major limitation. Prior efforts mainly accelerate sampling via optimized
solvers or distillation, which treat each query independently. In contrast, we
reduce total number of steps by sharing early-stage sampling across
semantically similar queries. To enable such efficiency gains without
sacrificing quality, we propose SAGE, a semantic-aware shared sampling
framework that integrates a shared sampling scheme for efficiency and a
tailored training strategy for quality preservation. Extensive experiments show
that SAGE reduces sampling cost by 25.5%, while improving generation quality
with 5.0% lower FID, 5.4% higher CLIP, and 160% higher diversity over
baselines.

</details>


### [408] [From Data to Diagnosis: A Large, Comprehensive Bone Marrow Dataset and AI Methods for Childhood Leukemia Prediction](https://arxiv.org/abs/2509.15895)
*Henning Höfener,Farina Kock,Martina Pontones,Tabita Ghete,David Pfrang,Nicholas Dickel,Meik Kunz,Daniela P. Schacherer,David A. Clunie,Andrey Fedorov,Max Westphal,Markus Metzler*

Main category: cs.LG

TL;DR: 该研究提出了一个大规模、高质量、公开的白血病骨髓数据集，并开发了用于细胞检测、分类和诊断预测的AI方法。


<details>
  <summary>Details</summary>
Motivation: 现有的白血病诊断方法依赖于复杂耗时的人工显微镜分析，且现有的AI解决方案多使用私有数据集且仅覆盖部分诊断流程。因此，需要一个全面的公开数据集和相应AI方法来解决这些问题。

Method: 研究人员创建了一个包含246名儿科患者数据的综合数据集，其中包含超过40,000个带边界框注释的细胞和超过28,000个带有高质量类别标签的细胞。他们还提出了用于细胞检测、细胞分类和诊断预测的AI方法。

Result: 在细胞检测方面，AI模型的平均精度为0.96；在33类细胞分类方面，曲线下面积为0.98，F1分数达到0.61；在使用预测的细胞计数进行诊断预测时，平均F1分数为0.90。

Conclusion: 提出的AI方法和数据集有望促进该领域的进一步研究和开发，最终实现更精确的诊断和改善患者预后。

Abstract: Leukemia diagnosis primarily relies on manual microscopic analysis of bone
marrow morphology supported by additional laboratory parameters, making it
complex and time consuming. While artificial intelligence (AI) solutions have
been proposed, most utilize private datasets and only cover parts of the
diagnostic pipeline. Therefore, we present a large, high-quality, publicly
available leukemia bone marrow dataset spanning the entire diagnostic process,
from cell detection to diagnosis. Using this dataset, we further propose
methods for cell detection, cell classification, and diagnosis prediction. The
dataset comprises 246 pediatric patients with diagnostic, clinical and
laboratory information, over 40 000 cells with bounding box annotations and
more than 28 000 of these with high-quality class labels, making it the most
comprehensive dataset publicly available. Evaluation of the AI models yielded
an average precision of 0.96 for the cell detection, an area under the curve of
0.98, and an F1-score of 0.61 for the 33-class cell classification, and a mean
F1-score of 0.90 for the diagnosis prediction using predicted cell counts.
While the proposed approaches demonstrate their usefulness for AI-assisted
diagnostics, the dataset will foster further research and development in the
field, ultimately contributing to more precise diagnoses and improved patient
outcomes.

</details>


### [409] [Foundation Models as World Models: A Foundational Study in Text-Based GridWorlds](https://arxiv.org/abs/2509.15915)
*Remo Sasso,Michelangelo Conserva,Dominik Jeurissen,Paulo Rauber*

Main category: cs.LG

TL;DR: Foundation models (FMs) can improve reinforcement learning (RL) sample efficiency by using foundation world models (FWMs) for simulation or foundation agents (FAs) for decision-making. Both approaches show promise, with FAs effective in simple environments and FWMs coupled with RL beneficial for complex, partially observable, and stochastic settings.


<details>
  <summary>Details</summary>
Motivation: Real-world applications requiring sample-efficient agents for reinforcement learning (RL) necessitate better integration of foundation models (FMs) due to their broad knowledge and reasoning capabilities.

Method: Two strategies were evaluated: 1) Using foundation world models (FWMs) that leverage FM prior knowledge for simulated interactions. 2) Using foundation agents (FAs) that leverage FM reasoning for decision-making. Both were tested in grid-world environments suitable for LLMs.

Result: Improvements in LLMs positively impact FWMs and FAs. FAs using current LLMs perform well in simple environments. Coupling FWMs with RL agents shows promise for complex, partially observable, and stochastic environments.

Conclusion: Foundation models offer promising avenues for enhancing sample efficiency in reinforcement learning through FWMs and FAs, with specific benefits depending on environmental complexity and characteristics.

Abstract: While reinforcement learning from scratch has shown impressive results in
solving sequential decision-making tasks with efficient simulators, real-world
applications with expensive interactions require more sample-efficient agents.
Foundation models (FMs) are natural candidates to improve sample efficiency as
they possess broad knowledge and reasoning capabilities, but it is yet unclear
how to effectively integrate them into the reinforcement learning framework. In
this paper, we anticipate and, most importantly, evaluate two promising
strategies. First, we consider the use of foundation world models (FWMs) that
exploit the prior knowledge of FMs to enable training and evaluating agents
with simulated interactions. Second, we consider the use of foundation agents
(FAs) that exploit the reasoning capabilities of FMs for decision-making. We
evaluate both approaches empirically in a family of grid-world environments
that are suitable for the current generation of large language models (LLMs).
Our results suggest that improvements in LLMs already translate into better
FWMs and FAs; that FAs based on current LLMs can already provide excellent
policies for sufficiently simple environments; and that the coupling of FWMs
and reinforcement learning agents is highly promising for more complex settings
with partial observability and stochastic elements.

</details>


### [410] [Enhancing Generative Auto-bidding with Offline Reward Evaluation and Policy Search](https://arxiv.org/abs/2509.15927)
*Zhiyu Mou,Yiqin Lv,Miao Xu,Cheems Wang,Yixiu Mao,Qichen Ye,Chao Li,Rongquan Bai,Chuan Yu,Jian Xu,Bo Zheng*

Main category: cs.LG

TL;DR: AIGB-Pearl通过结合生成规划和策略优化，并引入LLM驱动的评估器来提升竞价广告效果。


<details>
  <summary>Details</summary>
Motivation: 现有AIGB方法在生成质量评估和探索静态数据集之外的能力方面存在瓶颈，未能达到最优性能。

Method: 提出AIGB-Pearl，通过构建非引导式轨迹评估器来分配奖励和指导策略搜索，实现生成质量的迭代优化。同时，引入LLM架构、混合点对损失和自适应专家反馈机制来提高评估器在离线环境下的准确性。

Result: 在模拟和真实世界的广告系统中进行了广泛的实验，结果表明AIGB-Pearl达到了最先进的性能。

Conclusion: AIGB-Pearl通过整合生成规划和策略优化，并利用LLM驱动的评估器，显著提升了自动竞价广告的效果。

Abstract: Auto-bidding is an essential tool for advertisers to enhance their
advertising performance. Recent progress has shown that AI-Generated Bidding
(AIGB), which formulates the auto-bidding as a trajectory generation task and
trains a conditional diffusion-based planner on offline data, achieves superior
and stable performance compared to typical offline reinforcement learning
(RL)-based auto-bidding methods. However, existing AIGB methods still encounter
a performance bottleneck due to their neglect of fine-grained generation
quality evaluation and inability to explore beyond static datasets. To address
this, we propose AIGB-Pearl (\emph{Planning with EvAluator via RL}), a novel
method that integrates generative planning and policy optimization. The key to
AIGB-Pearl is to construct a non-bootstrapped \emph{trajectory evaluator} to
assign rewards and guide policy search, enabling the planner to optimize its
generation quality iteratively through interaction. Furthermore, to enhance
trajectory evaluator accuracy in offline settings, we incorporate three key
techniques: (i) a Large Language Model (LLM)-based architecture for better
representational capacity, (ii) hybrid point-wise and pair-wise losses for
better score learning, and (iii) adaptive integration of expert feedback for
better generalization ability. Extensive experiments on both simulated and
real-world advertising systems demonstrate the state-of-the-art performance of
our approach.

</details>


### [411] [Improving Monte Carlo Tree Search for Symbolic Regression](https://arxiv.org/abs/2509.15929)
*Zhengyao Huang,Daniel Zhengyu Huang,Tiannan Xiao,Dina Ma,Zhenyu Ming,Hao Shi,Yuanhui Wen*

Main category: cs.LG

TL;DR: 本研究提出了一种改进的蒙特卡洛树搜索（MCTS）框架，用于符号回归问题，通过引入极端や bandit 策略和受进化启发的 C++ 状态跳转动作（如变异和交叉），提高了搜索效率和鲁棒性，并在多种数据集上取得了有竞争力的结果。


<details>
  <summary>Details</summary>
Motivation: 符号回归是一个组合优化问题，旨在发现满足特定目标的简洁、可解释的数学表达式。虽然遗传编程是传统方法，但它在搜索效率方面存在局限。因此，探索更高效的搜索方法，如基于强化学习的 MCTS，以改进符号回归的搜索效率，具有重要意义。

Method: 提出了一种改进的 MCTS 框架，包含两个关键创新：（1）一种极端的 bandit 分配策略，用于识别全局最优表达式，并在多项式奖励衰减假设下具有有限时间内的性能保证；（2）受进化启发的 C++ 状态跳转动作，如变异和交叉，允许在搜索空间中进行非局部转换，并重塑奖励景观，提高搜索的鲁棒性和效率。

Result: 通过广泛的数值研究，验证了所提出改进措施的影响，并在各种数据集（包括真实和黑盒数据集）上与现有的符号回归方法进行了基准测试。该方法在恢复率方面达到了与最先进库相竞争的性能，并在准确性与模型复杂度的帕累托前沿上获得了有利位置。

Conclusion: 所提出的改进 MCTS 框架通过引入极端や bandit 策略和进化 C++ 状态跳转动作，有效解决了传统 MCTS 在符号回归中的局限性，提高了搜索效率和鲁棒性，并在实际应用中展现出优越的性能。

Abstract: Symbolic regression aims to discover concise, interpretable mathematical
expressions that satisfy desired objectives, such as fitting data, posing a
highly combinatorial optimization problem. While genetic programming has been
the dominant approach, recent efforts have explored reinforcement learning
methods for improving search efficiency. Monte Carlo Tree Search (MCTS), with
its ability to balance exploration and exploitation through guided search, has
emerged as a promising technique for symbolic expression discovery. However,
its traditional bandit strategies and sequential symbol construction often
limit performance. In this work, we propose an improved MCTS framework for
symbolic regression that addresses these limitations through two key
innovations: (1) an extreme bandit allocation strategy tailored for identifying
globally optimal expressions, with finite-time performance guarantees under
polynomial reward decay assumptions; and (2) evolution-inspired state-jumping
actions such as mutation and crossover, which enable non-local transitions to
promising regions of the search space. These state-jumping actions also reshape
the reward landscape during the search process, improving both robustness and
efficiency. We conduct a thorough numerical study to the impact of these
improvements and benchmark our approach against existing symbolic regression
methods on a variety of datasets, including both ground-truth and black-box
datasets. Our approach achieves competitive performance with state-of-the-art
libraries in terms of recovery rate, attains favorable positions on the Pareto
frontier of accuracy versus model complexity. Code is available at
https://github.com/PKU-CMEGroup/MCTS-4-SR.

</details>


### [412] [The Alignment Bottleneck](https://arxiv.org/abs/2509.15932)
*Wenjun Cao*

Main category: cs.LG

TL;DR: 大型语言模型在扩展时会改进，但基于反馈的对齐仍然会系统性地偏离预期行为。受经济学和认知科学中有限理性启发，我们将判断视为资源有限的，反馈视为受限的渠道。在此基础上，我们为给定 S 的两阶段级联 U → H → Y 建模，其中认知容量为 C_cog|S，平均总容量为 C̄_tot|S。


<details>
  <summary>Details</summary>
Motivation: 受经济学和认知科学中有限理性启发，我们将判断视为资源有限的，反馈视为受限的渠道。

Method: 我们为给定 S 的两阶段级联 U → H → Y 建模，其中认知容量为 C_cog|S，平均总容量为 C̄_tot|S。

Result: 我们的主要结果是一个容量耦合的对齐性能区间。它将独立于数据大小的 Fano 下界（在可分离码本混合物上证明）与 PAC-贝叶斯上界配对，其 KL 项由同一通道通过 m C̄_tot|S 控制。当使用标准可观察损失且数据集来自同一混合物时，PAC-贝叶斯界限成为同一真实风险的上界。在这些匹配的条件下，两个界限都由单个容量决定。

Conclusion: 我们的分析将对齐视为接口工程：测量和分配有限容量，管理任务复杂性，并决定信息在哪里花费。

Abstract: Large language models improve with scale, yet feedback-based alignment still
exhibits systematic deviations from intended behavior. Motivated by bounded
rationality in economics and cognitive science, we view judgment as
resource-limited and feedback as a constrained channel. On this basis, we model
the loop as a two-stage cascade $U \to H \to Y$ given $S$, with cognitive
capacity $C_{\text{cog}|S}$ and average total capacity
$\bar{C}_{\text{tot}|S}$. Our main result is a capacity-coupled Alignment
Performance Interval. It pairs a data size-independent Fano lower bound proved
on a separable codebook mixture with a PAC-Bayes upper bound whose KL term is
controlled by the same channel via $m \, \bar{C}_{\text{tot}|S}$. The PAC-Bayes
bound becomes an upper bound on the same true risk when the canonical
observable loss is used and the dataset is drawn from the same mixture. Under
these matched conditions, both limits are governed by a single capacity.
Consequences include that, with value complexity and capacity fixed, adding
labels alone cannot cross the bound; attaining lower risk on more complex
targets requires capacity that grows with $\log M$; and once useful signal
saturates capacity, further optimization tends to fit channel regularities,
consistent with reports of sycophancy and reward hacking. The analysis views
alignment as interface engineering: measure and allocate limited capacity,
manage task complexity, and decide where information is spent.

</details>


### [413] [UniTac2Pose: A Unified Approach Learned in Simulation for Category-level Visuotactile In-hand Pose Estimation](https://arxiv.org/abs/2509.15934)
*Mingdong Wu,Long Yang,Jin Liu,Weiyao Huang,Lehong Wu,Zelin Chen,Daolin Ma,Hao Dong*

Main category: cs.LG

TL;DR: 提出一种基于能量模型的扩散框架，用于从CAD模型估计物体手中姿态，该框架通过模拟数据训练，并结合渲染-比较架构以提升泛化能力，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在工业应用和日常任务中，根据物体的CAD模型精确估计其手中姿态至关重要，但现有方法在精度和泛化性方面仍面临挑战。

Method: 提出一个新颖的三阶段框架：1. 采样和预排序姿态候选；2. 迭代优化候选；3. 后排序选择最优姿态。整个框架由一个统一的、仅用模拟数据训练的基于能量的扩散模型驱动，该模型同时生成优化梯度和姿态质量的能量标量。利用计算机视觉中的渲染-比较思想，在能量模型中引入渲染-比较架构以提高模拟到真实（sim-to-real）的性能。

Result: 所提出的方法在与基于回归、匹配和配准技术的传统基线方法进行比较时，表现更优。该方法对先前未见的同类CAD模型具有很强的类内泛化能力。该方法还将触觉物体姿态估计、姿态跟踪和不确定性估计整合到一个统一的框架中，在各种真实世界条件下表现稳健。

Conclusion: 该方法在物体手中姿态估计方面取得了最先进的性能，并且在泛化性和鲁棒性方面也表现出色，能够适应各种真实世界场景。

Abstract: Accurate estimation of the in-hand pose of an object based on its CAD model
is crucial in both industrial applications and everyday tasks, ranging from
positioning workpieces and assembling components to seamlessly inserting
devices like USB connectors. While existing methods often rely on regression,
feature matching, or registration techniques, achieving high precision and
generalizability to unseen CAD models remains a significant challenge. In this
paper, we propose a novel three-stage framework for in-hand pose estimation.
The first stage involves sampling and pre-ranking pose candidates, followed by
iterative refinement of these candidates in the second stage. In the final
stage, post-ranking is applied to identify the most likely pose candidates.
These stages are governed by a unified energy-based diffusion model, which is
trained solely on simulated data. This energy model simultaneously generates
gradients to refine pose estimates and produces an energy scalar that
quantifies the quality of the pose estimates. Additionally, borrowing the idea
from the computer vision domain, we incorporate a render-compare architecture
within the energy-based score network to significantly enhance sim-to-real
performance, as demonstrated by our ablation studies. We conduct comprehensive
experiments to show that our method outperforms conventional baselines based on
regression, matching, and registration techniques, while also exhibiting strong
intra-category generalization to previously unseen CAD models. Moreover, our
approach integrates tactile object pose estimation, pose tracking, and
uncertainty estimation into a unified framework, enabling robust performance
across a variety of real-world conditions.

</details>


### [414] [Adversarial Graph Fusion for Incomplete Multi-view Semi-supervised Learning with Tensorial Imputation](https://arxiv.org/abs/2509.15955)
*Zhangqi Jiang,Tingjin Luo,Xu Yang,Xinyan Liang*

Main category: cs.LG

TL;DR: 提出了AGF-TI模型，通过对抗性图融合和低秩张量学习解决多视图半监督学习中的数据缺失和子簇问题，并提高了分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多视图半监督学习方法在处理缺失数据时存在子簇问题，这会扭曲图融合并降低分类性能。

Method: 设计了一个对抗性图融合方案来学习稳健的共识图，并通过低秩张量学习从高阶一致性信息中恢复不完整的结构。同时，引入基于锚点的策略来降低计算复杂度，并采用优化的交替优化算法进行求解。

Result: 在多个数据集上的大量实验结果表明，AGF-TI的性能优于现有最先进的方法。

Conclusion: AGF-TI成功解决了多视图半监督学习中的子簇问题，并在各种数据集上取得了优越的性能。

Abstract: View missing remains a significant challenge in graph-based multi-view
semi-supervised learning, hindering their real-world applications. To address
this issue, traditional methods introduce a missing indicator matrix and focus
on mining partial structure among existing samples in each view for label
propagation (LP). However, we argue that these disregarded missing samples
sometimes induce discontinuous local structures, i.e., sub-clusters, breaking
the fundamental smoothness assumption in LP. Consequently, such a Sub-Cluster
Problem (SCP) would distort graph fusion and degrade classification
performance. To alleviate SCP, we propose a novel incomplete multi-view
semi-supervised learning method, termed AGF-TI. Firstly, we design an
adversarial graph fusion scheme to learn a robust consensus graph against the
distorted local structure through a min-max framework. By stacking all
similarity matrices into a tensor, we further recover the incomplete structure
from the high-order consistency information based on the low-rank tensor
learning. Additionally, the anchor-based strategy is incorporated to reduce the
computational complexity. An efficient alternative optimization algorithm
combining a reduced gradient descent method is developed to solve the
formulated objective, with theoretical convergence. Extensive experimental
results on various datasets validate the superiority of our proposed AGF-TI as
compared to state-of-the-art methods. Code is available at
https://github.com/ZhangqiJiang07/AGF_TI.

</details>


### [415] [Inverse Optimization Latent Variable Models for Learning Costs Applied to Route Problems](https://arxiv.org/abs/2509.15999)
*Alan A. Lahoud,Erik Schaffernicht,Johannes A. Stork*

Main category: cs.LG

TL;DR: IO-LVM是一种新颖的逆向优化方法，可以学习未知成本函数的约束优化问题（COPs）的潜在空间，并通过在循环中加入求解器来重建可行的输出。


<details>
  <summary>Details</summary>
Motivation: 已有的方法在处理未知成本函数的约束优化问题（COPs）时存在挑战，尤其是在强制执行约束方面。

Method: 提出IO-LVM模型，学习COPs成本函数的潜在空间，并利用Fenchel-Young损失的估计梯度，通过确定性求解器来塑造潜在空间。

Result: 在船舶和出租车路线的真实数据集以及合成图中的路径上进行了验证，能够重建路径和周期，预测它们的分布，并产生可解释的潜在表示。

Conclusion: IO-LVM能够捕获成本函数的分布，识别由不同主体或条件引起的多种解决方案行为，并且优于标准的逆向优化或逆向强化学习方法。

Abstract: Learning representations for solutions of constrained optimization problems
(COPs) with unknown cost functions is challenging, as models like (Variational)
Autoencoders struggle to enforce constraints when decoding structured outputs.
We propose an Inverse Optimization Latent Variable Model (IO-LVM) that learns a
latent space of COP cost functions from observed solutions and reconstructs
feasible outputs by solving a COP with a solver in the loop. Our approach
leverages estimated gradients of a Fenchel-Young loss through a
non-differentiable deterministic solver to shape the latent space. Unlike
standard Inverse Optimization or Inverse Reinforcement Learning methods, which
typically recover a single or context-specific cost function, IO-LVM captures a
distribution over cost functions, enabling the identification of diverse
solution behaviors arising from different agents or conditions not available
during the training process. We validate our method on real-world datasets of
ship and taxi routes, as well as paths in synthetic graphs, demonstrating its
ability to reconstruct paths and cycles, predict their distributions, and yield
interpretable latent representations.

</details>


### [416] [Predicting the descent into extremism and terrorism](https://arxiv.org/abs/2509.16014)
*R. O. Lane,W. J. Holmes,C. J. Taylor,H. M. State-Davey,A. J. Wragge*

Main category: cs.LG

TL;DR: 本研究提出了一种自动分析和跟踪在线声明的方法，以检测作者是否涉及极端主义或恐怖主义。


<details>
  <summary>Details</summary>
Motivation: 自动识别在线声明中与极端主义和恐怖主义相关的模式，以帮助进行安全分析。

Method: 使用机器学习（ML）对在线声明进行编码和分类。具体方法包括：1. 在线收集声明并进行机器学习编码；2. 使用通用句子编码器（Universal Sentence Encoder）提取 512 维特征向量；3. 使用支持向量机（SVM）分类器进行训练和测试，并采用 10 折交叉验证；4. 利用跟踪技术进行时间序列分析，将每个声明视为对个人心态的测量。

Result: 使用包含 839 条引述的数据集，该系统在检测与极端主义相关的意图和态度时准确率为 81%，在检测与恐怖主义相关的意图和态度时准确率为 97%。该准确率高于基于 n-gram 文本特征的基线系统。跟踪算法能够检测到随时间变化的趋势和由重大事件引起的态度剧变。

Conclusion: 所提出的系统能够有效地自动分析在线声明，准确检测与极端主义和恐怖主义相关的意图和态度，并通过时间序列分析揭示个人心态的变化趋势。

Abstract: This paper proposes an approach for automatically analysing and tracking
statements in material gathered online and detecting whether the authors of the
statements are likely to be involved in extremism or terrorism. The proposed
system comprises: online collation of statements that are then encoded in a
form amenable to machine learning (ML), an ML component to classify the encoded
text, a tracker, and a visualisation system for analysis of results. The
detection and tracking concept has been tested using quotes made by terrorists,
extremists, campaigners, and politicians, obtained from wikiquote.org. A set of
features was extracted for each quote using the state-of-the-art Universal
Sentence Encoder (Cer et al. 2018), which produces 512-dimensional vectors. The
data were used to train and test a support vector machine (SVM) classifier
using 10-fold cross-validation. The system was able to correctly detect
intentions and attitudes associated with extremism 81% of the time and
terrorism 97% of the time, using a dataset of 839 quotes. This accuracy was
higher than that which was achieved for a simple baseline system based on
n-gram text features. Tracking techniques were also used to perform a temporal
analysis of the data, with each quote considered to be a noisy measurement of a
person's state of mind. It was demonstrated that the tracking algorithms were
able to detect both trends over time and sharp changes in attitude that could
be attributed to major events.

</details>


### [417] [Time-adaptive SympNets for separable Hamiltonian systems](https://arxiv.org/abs/2509.16026)
*Konrad Janik,Peter Benner*

Main category: cs.LG

TL;DR: 现有的学习辛积分器的机器学习方法（如SympNets和HénonNets）需要固定步长生成的数据。本文提出的T-SympNets能够学习时间自适应辛积分器，并将其扩展到非自治哈密顿系统。我们通过提供一个关于可分离哈密顿系统的通用逼近定理来分析T-SympNets的逼近能力，并证明该定理不能扩展到非可分离哈密顿系统。此外，我们还修复了先前关于辛映射逼近的一个重要定理证明中的错误。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习方法在学习辛积分器时，通常需要固定步长生成的数据，无法处理不规则采样数据。本文旨在解决此问题，通过时间自适应辛积分器来学习不规则采样数据，并将其应用于非自治哈密顿系统。

Method: 本文首先介绍了T-SympNets，一种用于学习时间自适应辛积分器的架构，并将其扩展到非自治哈密顿系统。然后，通过提供一个适用于可分离哈密顿系统的通用逼近定理来分析T-SympNets的理论逼近能力，并证明该定理的局限性。最后，通过数值实验来验证理论分析，并修正了先前关于辛映射逼近的一个重要定理证明中的错误。

Result: 本文为可分离哈密顿系统提供了一个通用逼近定理，证明了T-SympNets的理论逼近能力。同时，也指出了该定理无法扩展到非可分离哈密顿系统。数值实验结果支持了理论分析。此外，还修正了一个关于辛映射逼近的重要定理证明。

Conclusion: T-SympNets能够学习时间自适应辛积分器，并能处理不规则采样数据，适用于非自治哈密顿系统。本文的理论和数值分析为T-SympNets提供了重要的理论基础，并对其在辛映射学习中的应用前景进行了探讨。

Abstract: Measurement data is often sampled irregularly i.e. not on equidistant time
grids. This is also true for Hamiltonian systems. However, existing machine
learning methods, which learn symplectic integrators, such as SympNets [20] and
H\'enonNets [4] still require training data generated by fixed step sizes. To
learn time-adaptive symplectic integrators, an extension to SympNets, which we
call TSympNets, was introduced in [20]. We adapt the architecture of TSympNets
and extend them to non-autonomous Hamiltonian systems. So far the approximation
qualities of TSympNets were unknown. We close this gap by providing a universal
approximation theorem for separable Hamiltonian systems and show that it is not
possible to extend it to non-separable Hamiltonian systems. To investigate
these theoretical approximation capabilities, we perform different numerical
experiments. Furthermore we fix a mistake in a proof of a substantial theorem
[25, Theorem 2] for the approximation of symplectic maps in general, but
specifically for symplectic machine learning methods.

</details>


### [418] [Communications to Circulations: 3D Wind Field Retrieval and Real-Time Prediction Using 5G GNSS Signals and Deep Learning](https://arxiv.org/abs/2509.16068)
*Yuchen Ye,Hong Liang,Chaoxia Yuan,Mingyu Li,Aoqi Zhou,Chunqing Shang,Hua Cai,Peixi Liu,Kezuan Wang,Yifeng Zheng*

Main category: cs.LG

TL;DR: 利用5G GNSS信号的信号强度变化，通过深度学习模型G-WindCast来获取和预测三维大气风场。


<details>
  <summary>Details</summary>
Motivation: 传统风场数据获取方法（地面观测、遥感、数值天气预报模型）存在局限性，需要更精确、高时空分辨率的风场信息。

Method: 提出了一种名为G-WindCast的深度学习框架，结合前馈神经网络（FNN）和Transformer网络，利用5G GNSS信号的信号强度变化来反演和预测风场。

Result: G-WindCast在风场反演和短期（30分钟预报）风场预测方面表现出有希望的准确性，在某些情况下，其技能分数可与高分辨率数值天气预报模型相媲美。该模型在不同预报时效和不同高度层上表现出鲁棒性，其风速和风向预测与观测值相比，优于ERA5再分析数据。即使在GNSS站点数量显著减少（约100个）的情况下，该系统也能保持优异的局部预测性能。

Conclusion: 该跨学科方法展示了利用非传统数据源和深度学习进行先进环境监测和实时大气应用的变革潜力。

Abstract: Accurate atmospheric wind field information is crucial for various
applications, including weather forecasting, aviation safety, and disaster risk
reduction. However, obtaining high spatiotemporal resolution wind data remains
challenging due to limitations in traditional in-situ observations and remote
sensing techniques, as well as the computational expense and biases of
numerical weather prediction (NWP) models. This paper introduces G-WindCast, a
novel deep learning framework that leverages signal strength variations from 5G
Global Navigation Satellite System (GNSS) signals to retrieve and forecast
three-dimensional (3D) atmospheric wind fields. The framework utilizes Forward
Neural Networks (FNN) and Transformer networks to capture complex, nonlinear,
and spatiotemporal relationships between GNSS-derived features and wind
dynamics. Our preliminary results demonstrate promising accuracy in both wind
retrieval and short-term wind forecasting (up to 30 minutes lead time), with
skill scores comparable to high-resolution NWP outputs in certain scenarios.
The model exhibits robustness across different forecast horizons and pressure
levels, and its predictions for wind speed and direction show superior
agreement with observations compared to concurrent ERA5 reanalysis data.
Furthermore, we show that the system can maintain excellent performance for
localized forecasting even with a significantly reduced number of GNSS stations
(e.g., around 100), highlighting its cost-effectiveness and scalability. This
interdisciplinary approach underscores the transformative potential of
exploiting non-traditional data sources and deep learning for advanced
environmental monitoring and real-time atmospheric applications.

</details>


### [419] [MTS-DMAE: Dual-Masked Autoencoder for Unsupervised Multivariate Time Series Representation Learning](https://arxiv.org/abs/2509.16078)
*Yi Xu,Yitian Zhang,Yun Fu*

Main category: cs.LG

TL;DR: DMAE是一个新颖的掩码时间序列建模框架，用于无监督多元时间序列（MTS）表示学习，通过重建掩码值和估计掩码特征的潜在表示来学习表示，并引入特征级对齐约束来提高表示质量，在分类、回归和预测任务上表现优于基线。


<details>
  <summary>Details</summary>
Motivation: 无监督多元时间序列（MTS）表示学习旨在从原始序列中提取简洁、信息丰富的表示，而无需标签，以便有效地迁移到各种下游任务。

Method: 提出了一种名为双掩码自编码器（DMAE）的新颖掩码时间序列建模框架。DMAE 制定了两个互补的借口任务：(1) 根据可见属性重建掩码值，(2) 在教师编码器的指导下估计掩码特征的潜在表示。此外，还引入了一个特征级对齐约束，以鼓励预测的潜在表示与教师的输出保持一致。

Result: 通过联合优化这些目标，DMAE 学习到了时间上连贯且语义上丰富的表示。在分类、回归和预测任务上的综合评估表明，DMAE 的方法在具有竞争力的基线上实现了持续且优越的性能。

Conclusion: DMAE通过其创新的双掩码策略和特征级对齐约束，成功实现了无监督MTS表示学习，并在各种下游任务中取得了优异的性能。

Abstract: Unsupervised multivariate time series (MTS) representation learning aims to
extract compact and informative representations from raw sequences without
relying on labels, enabling efficient transfer to diverse downstream tasks. In
this paper, we propose Dual-Masked Autoencoder (DMAE), a novel masked
time-series modeling framework for unsupervised MTS representation learning.
DMAE formulates two complementary pretext tasks: (1) reconstructing masked
values based on visible attributes, and (2) estimating latent representations
of masked features, guided by a teacher encoder. To further improve
representation quality, we introduce a feature-level alignment constraint that
encourages the predicted latent representations to align with the teacher's
outputs. By jointly optimizing these objectives, DMAE learns temporally
coherent and semantically rich representations. Comprehensive evaluations
across classification, regression, and forecasting tasks demonstrate that our
approach achieves consistent and superior performance over competitive
baselines.

</details>


### [420] [Rethinking Molecule Synthesizability with Chain-of-Reaction](https://arxiv.org/abs/2509.16084)
*Seul Lee,Karsten Kreis,Srimukh Prasad Veccham,Meng Liu,Danny Reidenbach,Saee Paliwal,Weili Nie,Arash Vahdat*

Main category: cs.LG

TL;DR: ReaSyn是一个生成可合成分子及其类似物的框架，它通过引入“反应链”（CoR）和基于强化学习的微调来解决分子生成中的可合成性问题，并在分子重建、优化和扩张方面取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 分子生成模型面临无法生成可合成分子的挑战，现有方法在可合成空间覆盖和分子优化性能方面存在不足。

Method: 提出ReaSyn框架，通过生成可合成类似物的路径来探索可合成空间；引入“反应链”（CoR）表示法，将合成路径类比为LLM的推理路径，以获取每一步的密集监督；结合基于强化学习的微调和目标导向的测试时间计算缩放来增强推理能力。

Result: ReaSyn在可合成分子重建中实现了最高的重构率和路径多样性，在可合成目标导向的分子优化中取得了最高的优化性能，并在可合成命中扩展方面显著优于先前方法。

Conclusion: ReaSyn在导航组合庞大的可合成化学空间方面展现出卓越的能力。

Abstract: A well-known pitfall of molecular generative models is that they are not
guaranteed to generate synthesizable molecules. There have been considerable
attempts to address this problem, but given the exponentially large
combinatorial space of synthesizable molecules, existing methods have shown
limited coverage of the space and poor molecular optimization performance. To
tackle these problems, we introduce ReaSyn, a generative framework for
synthesizable projection where the model explores the neighborhood of given
molecules in the synthesizable space by generating pathways that result in
synthesizable analogs. To fully utilize the chemical knowledge contained in the
synthetic pathways, we propose a novel perspective that views synthetic
pathways akin to reasoning paths in large language models (LLMs). Specifically,
inspired by chain-of-thought (CoT) reasoning in LLMs, we introduce the
chain-of-reaction (CoR) notation that explicitly states reactants, reaction
types, and intermediate products for each step in a pathway. With the CoR
notation, ReaSyn can get dense supervision in every reaction step to explicitly
learn chemical reaction rules during supervised training and perform
step-by-step reasoning. In addition, to further enhance the reasoning
capability of ReaSyn, we propose reinforcement learning (RL)-based finetuning
and goal-directed test-time compute scaling tailored for synthesizable
projection. ReaSyn achieves the highest reconstruction rate and pathway
diversity in synthesizable molecule reconstruction and the highest optimization
performance in synthesizable goal-directed molecular optimization, and
significantly outperforms previous synthesizable projection methods in
synthesizable hit expansion. These results highlight ReaSyn's superior ability
to navigate combinatorially-large synthesizable chemical space.

</details>


### [421] [Randomized Smoothing Meets Vision-Language Models](https://arxiv.org/abs/2509.16088)
*Emmanouil Seferis,Changshun Wu,Stefanos Kollias,Saddek Bensalem,Chih-Hong Cheng*

Main category: cs.LG

TL;DR: 随机平滑技术可用于验证大型视觉语言模型的鲁棒性，即使其输出是序列形式。


<details>
  <summary>Details</summary>
Motivation: 现有随机平滑技术在验证分类模型方面效果显著，但在生成模型上的应用尚不明确，因为生成模型的输出是序列而非标签。

Method: 将生成模型的输出与一个分类任务相关联，证明随机平滑技术仍可用于生成模型。具体来说，可以将最终响应归类为离散动作（例如，VLAs中的服务机器人命令）、有害与无害（VLMs中的内容审核或毒性检测），或利用这些分类器将答案聚类为语义等价的群组。只要分类器错误率有界，就可以将样本数量与鲁棒性半径联系起来。此外，还推导了认证半径和准确性与样本数量之间关系的改进缩放定律，表明在较弱假设下，先前关于样本量减少2到3个数量级且损失最小化的结果仍然成立。

Result: 验证了随机平滑技术可以明确且高效地应用于先进的大型视觉语言模型，以实现鲁棒性认证。

Conclusion: 随机平滑技术已成功应用于大型视觉语言模型，解决了其输出序列的鲁棒性认证问题，并提供了理论基础和改进的缩放定律，使得认证在计算上可行。

Abstract: Randomized smoothing (RS) is one of the prominent techniques to ensure the
correctness of machine learning models, where point-wise robustness
certificates can be derived analytically. While RS is well understood for
classification, its application to generative models is unclear, since their
outputs are sequences rather than labels. We resolve this by connecting
generative outputs to an oracle classification task and showing that RS can
still be enabled: the final response can be classified as a discrete action
(e.g., service-robot commands in VLAs), as harmful vs. harmless (content
moderation or toxicity detection in VLMs), or even applying oracles to cluster
answers into semantically equivalent ones. Provided that the error rate for the
oracle classifier comparison is bounded, we develop the theory that associates
the number of samples with the corresponding robustness radius. We further
derive improved scaling laws analytically relating the certified radius and
accuracy to the number of samples, showing that the earlier result of 2 to 3
orders of magnitude fewer samples sufficing with minimal loss remains valid
even under weaker assumptions. Together, these advances make robustness
certification both well-defined and computationally feasible for
state-of-the-art VLMs, as validated against recent jailbreak-style adversarial
attacks.

</details>


### [422] [DiffusionNFT: Online Diffusion Reinforcement with Forward Process](https://arxiv.org/abs/2509.16117)
*Kaiwen Zheng,Huayu Chen,Haotian Ye,Haoxiang Wang,Qinsheng Zhang,Kai Jiang,Hang Su,Stefano Ermon,Jun Zhu,Ming-Yu Liu*

Main category: cs.LG

TL;DR: DiffusionNFT是一种新的在线强化学习范式，通过流匹配直接在正向过程上优化扩散模型，解决了现有方法存在的问题，并提高了训练效率和模型性能。


<details>
  <summary>Details</summary>
Motivation: 在线强化学习（RL）是训练后语言模型的核心，但由于难以处理的似然性，将其扩展到扩散模型仍然具有挑战性。现有方法（如离散化反向采样过程）存在求解器限制、正向-反向不一致以及与分类器无自由引导（CFG）集成复杂等基本缺点。

Method: DiffusionNFT通过流匹配直接在正向过程上优化扩散模型，通过对比正负生成来定义隐式策略改进方向，将强化信号自然地整合到监督学习目标中。这种方法允许使用任意黑盒求解器，无需似然估计，并且只需要干净的图像而不是采样轨迹来进行策略优化。

Result: DiffusionNFT比FlowGRPO的效率高25倍，并且无需CFG。例如，DiffusionNFT在1000步内将GenEval得分从0.24提高到0.98，而FlowGRPO在超过5000步并额外使用CFG的情况下达到0.95。通过利用多个奖励模型，DiffusionNFT在所有测试的基准测试中显著提升了SD3.5-Medium的性能。

Conclusion: DiffusionNFT是一种更有效、更灵活的在线强化学习方法，用于优化扩散模型，克服了现有方法的局限性，并在多项任务中取得了显著的性能提升。

Abstract: Online reinforcement learning (RL) has been central to post-training language
models, but its extension to diffusion models remains challenging due to
intractable likelihoods. Recent works discretize the reverse sampling process
to enable GRPO-style training, yet they inherit fundamental drawbacks,
including solver restrictions, forward-reverse inconsistency, and complicated
integration with classifier-free guidance (CFG). We introduce Diffusion
Negative-aware FineTuning (DiffusionNFT), a new online RL paradigm that
optimizes diffusion models directly on the forward process via flow matching.
DiffusionNFT contrasts positive and negative generations to define an implicit
policy improvement direction, naturally incorporating reinforcement signals
into the supervised learning objective. This formulation enables training with
arbitrary black-box solvers, eliminates the need for likelihood estimation, and
requires only clean images rather than sampling trajectories for policy
optimization. DiffusionNFT is up to $25\times$ more efficient than FlowGRPO in
head-to-head comparisons, while being CFG-free. For instance, DiffusionNFT
improves the GenEval score from 0.24 to 0.98 within 1k steps, while FlowGRPO
achieves 0.95 with over 5k steps and additional CFG employment. By leveraging
multiple reward models, DiffusionNFT significantly boosts the performance of
SD3.5-Medium in every benchmark tested.

</details>


### [423] [Network-Based Detection of Autism Spectrum Disorder Using Sustainable and Non-invasive Salivary Biomarkers](https://arxiv.org/abs/2509.16126)
*Janayna M. Fernandes,Robinson Sabino-Silva,Murillo G. Carneiro*

Main category: cs.LG

TL;DR: 利用基于遗传算法的网络优化框架GANet，结合PageRank和Degree算法，通过ATR-FTIR光谱分析159个唾液样本，实现了对自闭症谱系障碍（ASD）的精准检测，准确率达到0.78。


<details>
  <summary>Details</summary>
Motivation: 自闭症谱系障碍（ASD）缺乏可靠的生物标志物，导致早期诊断延迟。

Method: 提出了一种名为GANet的遗传算法-PageRank-Degree网络优化框架，用于分析ATR-FTIR光谱数据，以提取有意义的模式。

Result: GANet在准确率（0.78）、敏感性（0.61）、特异性（0.90）和F1分数（0.74）方面优于线性判别分析、支持向量机和深度学习模型。

Conclusion: GANet是一种非侵入性的、基于光谱的自闭症谱系障碍（ASD）检测工具，具有精准检测的潜力，并可应用于更广泛的健康领域。

Abstract: Autism Spectrum Disorder (ASD) lacks reliable biological markers, delaying
early diagnosis. Using 159 salivary samples analyzed by ATR-FTIR spectroscopy,
we developed GANet, a genetic algorithm-based network optimization framework
leveraging PageRank and Degree for importance-based feature characterization.
GANet systematically optimizes network structure to extract meaningful patterns
from high-dimensional spectral data. It achieved superior performance compared
to linear discriminant analysis, support vector machines, and deep learning
models, reaching 0.78 accuracy, 0.61 sensitivity, 0.90 specificity, and a 0.74
harmonic mean. These results demonstrate GANet's potential as a robust,
bio-inspired, non-invasive tool for precise ASD detection and broader
spectral-based health applications.

</details>


### [424] [Dynamic Classifier-Free Diffusion Guidance via Online Feedback](https://arxiv.org/abs/2509.16131)
*Pinelopi Papalampidi,Olivia Wiles,Ira Ktena,Aleksandar Shtedritski,Emanuele Bugliarello,Ivana Kajic,Isabela Albuquerque,Aida Nematzadeh*

Main category: cs.LG

TL;DR: 本文提出了一种动态分类器自由引导（CFG）调度框架，通过结合 CLIP、判别器和人类偏好模型等多种评估指标，在扩散过程的每一步动态调整 CFG 尺度，以适应不同提示的需求，从而显著提升文本到图像生成的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像模型依赖静态的 CFG 尺度，无法满足不同提示的个性化需求，而现有的解决方案又过于复杂且泛化性不佳。

Method: 利用 CLIP、判别器和人类偏好奖励模型等评估指标，在扩散过程的每一步收集反馈，并通过贪婪搜索为每个时间步选择最优的 CFG 尺度，生成独特的引导调度。

Result: 所提出的动态 CFG 调度框架在小规模模型和 Imagen 3 上均取得了显著的改进，在文本对齐、图像质量、文本渲染和数值推理方面表现优异。与 Imagen 3 基线相比，在整体偏好方面取得了高达 53.8% 的人类偏好胜率，在特定能力（如文本渲染）方面胜率高达 55.5%。

Conclusion: 最优的引导调度本质上是动态且依赖于提示的，本文提出的框架提供了一种高效且通用的方法来实现这一目标。

Abstract: Classifier-free guidance (CFG) is a cornerstone of text-to-image diffusion
models, yet its effectiveness is limited by the use of static guidance scales.
This "one-size-fits-all" approach fails to adapt to the diverse requirements of
different prompts; moreover, prior solutions like gradient-based correction or
fixed heuristic schedules introduce additional complexities and fail to
generalize. In this work, we challeng this static paradigm by introducing a
framework for dynamic CFG scheduling. Our method leverages online feedback from
a suite of general-purpose and specialized small-scale latent-space
evaluations, such as CLIP for alignment, a discriminator for fidelity and a
human preference reward model, to assess generation quality at each step of the
reverse diffusion process. Based on this feedback, we perform a greedy search
to select the optimal CFG scale for each timestep, creating a unique guidance
schedule tailored to every prompt and sample. We demonstrate the effectiveness
of our approach on both small-scale models and the state-of-the-art Imagen 3,
showing significant improvements in text alignment, visual quality, text
rendering and numerical reasoning. Notably, when compared against the default
Imagen 3 baseline, our method achieves up to 53.8% human preference win-rate
for overall preference, a figure that increases up to to 55.5% on prompts
targeting specific capabilities like text rendering. Our work establishes that
the optimal guidance schedule is inherently dynamic and prompt-dependent, and
provides an efficient and generalizable framework to achieve it.

</details>


### [425] [Spatio-temporal, multi-field deep learning of shock propagation in meso-structured media](https://arxiv.org/abs/2509.16139)
*M. Giselle Fernández-Godino,Meir H. Shachar,Kevin Korner,Jonathan L. Belof,Mukul Kumar,Jonathan Lind,William J. Schill*

Main category: cs.LG

TL;DR: 该研究提出了一个名为MSTM的多场时空深度学习模型，能够快速准确地模拟冲击波在多孔材料中的传播，解决了行星防御、国家安全和惯性约束聚变等领域面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 预测冲击波在多孔和结构化材料中的传播对于行星防御、国家安全和惯性约束聚变至关重要，但现有方法难以捕捉孔隙坍塌、异常Hugoniot响应和局部加热等现象。

Method: 提出了一种多场时空深度学习模型（MSTM），该模型将压力、密度、温度、能量、材料分布和两个速度分量这七个耦合场统一到一个自回归模型中，并使用高保真流体动力学代码数据进行训练。

Result: MSTM的运行速度比直接模拟快约一千倍，在多孔材料中的误差低于4%，在晶格结构中的误差低于10%。与之前的单场或基于算子的代理模型不同，MSTM能够解析尖锐的冲击波前沿，同时将质量平均压力和温度等积分量保留在5%以内。

Conclusion: MSTM模型能够快速准确地模拟冲击波在多孔材料中的传播，解决了以往难以解决的问题，为行星撞击缓解、惯性约束聚变和国家安全领域中介观结构材料的优化提供了实用的框架。

Abstract: The ability to predict how shock waves traverse porous and architected
materials is a decisive factor in planetary defense, national security, and the
race to achieve inertial fusion energy. Yet capturing pore collapse, anomalous
Hugoniot responses, and localized heating -- phenomena that can determine the
success of asteroid deflection or fusion ignition -- has remained a major
challenge despite recent advances in single-field and reduced representations.
We introduce a multi-field spatio-temporal deep learning model (MSTM) that
unifies seven coupled fields -- pressure, density, temperature, energy,
material distribution, and two velocity components -- into a single
autoregressive surrogate. Trained on high-fidelity hydrocode data, MSTM runs
about a thousand times faster than direct simulation, achieving errors below
4\% in porous materials and below 10\% in lattice structures. Unlike prior
single-field or operator-based surrogates, MSTM resolves sharp shock fronts
while preserving integrated quantities such as mass-averaged pressure and
temperature to within 5\%. This advance transforms problems once considered
intractable into tractable design studies, establishing a practical framework
for optimizing meso-structured materials in planetary impact mitigation,
inertial fusion energy, and national security.

</details>


### [426] [Automated Cyber Defense with Generalizable Graph-based Reinforcement Learning Agents](https://arxiv.org/abs/2509.16151)
*Isaiah J. King,Benjamin Bowman,H. Howie Huang*

Main category: cs.LG

TL;DR: 深度强化学习在网络安全防御中存在对网络拓扑过度拟合的问题。本文提出将网络安全防御构建为基于上下文的、部分可观测的马尔可夫决策问题，并使用属性图表示网络状态，从而引入关系归纳偏置，使智能体能够更通用地进行推理，并能更好地适应新环境。


<details>
  <summary>Details</summary>
Motivation: 传统的深度强化学习方法在网络安全防御中存在对特定网络拓扑过度拟合的问题，导致在环境发生微小变化时效果不佳。

Method: 将网络安全防御建模为一个双人、基于上下文、部分可观测的马尔可夫决策问题，并使用属性图来表示观测。智能体通过学习推理相互交互的实体，并将动作定义为对环境图的编辑。

Result: 该方法在各种复杂的多智能体环境中，能够更好地防御未知的网络和多种攻击者，并且在零样本适应新环境方面表现出色，显著优于现有技术。

Conclusion: 通过引入关系归纳偏置，本文提出的方法能够使智能体更好地理解网络状态，并具备零样本适应新网络的能力，在网络安全防御任务中取得了显著的性能提升。

Abstract: Deep reinforcement learning (RL) is emerging as a viable strategy for
automated cyber defense (ACD). The traditional RL approach represents networks
as a list of computers in various states of safety or threat. Unfortunately,
these models are forced to overfit to specific network topologies, rendering
them ineffective when faced with even small environmental perturbations. In
this work, we frame ACD as a two-player context-based partially observable
Markov decision problem with observations represented as attributed graphs.
This approach allows our agents to reason through the lens of relational
inductive bias. Agents learn how to reason about hosts interacting with other
system entities in a more general manner, and their actions are understood as
edits to the graph representing the environment. By introducing this bias, we
will show that our agents can better reason about the states of networks and
zero-shot adapt to new ones. We show that this approach outperforms the
state-of-the-art by a wide margin, and makes our agents capable of defending
never-before-seen networks against a wide range of adversaries in a variety of
complex, and multi-agent environments.

</details>


### [427] [DIVEBATCH: Accelerating Model Training Through Gradient-Diversity Aware Batch Size Adaptation](https://arxiv.org/abs/2509.16173)
*Yuen Chen,Yian Wang,Hari Sundaram*

Main category: cs.LG

TL;DR: DiveBatch是一种自适应批处理大小的SGD算法，通过动态调整批处理大小来加速机器学习模型的训练，并在效率和收敛速度方面优于标准SGD和AdaBatch。


<details>
  <summary>Details</summary>
Motivation: 训练大型深度神经网络模型计算成本高，需要加速训练过程。

Method: 提出了一种新颖的自适应批处理大小SGD算法DiveBatch，该算法基于梯度多样性动态调整批处理大小，以平衡大批量和小批量的训练特性。

Result: DiveBatch在合成数据集、CiFar-10、CiFar-100和Tiny-ImageNet上的实验表明，其收敛速度比标准SGD和AdaBatch快1.06-5.0倍，但性能略有下降。

Conclusion: DiveBatch通过自适应调整批处理大小，在提高训练效率和收敛速度方面取得了成功，但需要注意其对模型性能的轻微影响。

Abstract: The goal of this paper is to accelerate the training of machine learning
models, a critical challenge since the training of large-scale deep neural
models can be computationally expensive. Stochastic gradient descent (SGD) and
its variants are widely used to train deep neural networks. In contrast to
traditional approaches that focus on tuning the learning rate, we propose a
novel adaptive batch size SGD algorithm, DiveBatch, that dynamically adjusts
the batch size. Adapting the batch size is challenging: using large batch sizes
is more efficient due to parallel computation, but small-batch training often
converges in fewer epochs and generalizes better. To address this challenge, we
introduce a data-driven adaptation based on gradient diversity, enabling
DiveBatch to maintain the generalization performance of small-batch training
while improving convergence speed and computational efficiency. Gradient
diversity has a strong theoretical justification: it emerges from the
convergence analysis of SGD. Evaluations of DiveBatch on synthetic and
CiFar-10, CiFar-100, and Tiny-ImageNet demonstrate that DiveBatch converges
significantly faster than standard SGD and AdaBatch (1.06 -- 5.0x), with a
slight trade-off in performance.

</details>


### [428] [Inverting Trojans in LLMs](https://arxiv.org/abs/2509.16203)
*Zhengxing Li,Guangmingmei Yang,Jayaram Raghuram,David J. Miller,George Kesidis*

Main category: cs.LG

TL;DR: 本文提出了一种用于大型语言模型（LLMs）的后门触发器逆向工程方法，解决了现有方法在LLM上的局限性，并成功检测和逆向了后门触发器。


<details>
  <summary>Details</summary>
Motivation: 现有后门检测和逆向方法难以应用于大型语言模型（LLMs），主要因为LLM的离散输入空间、庞大的触发器可能性以及需要排除具有强关联性的“伪造”触发器词元。

Method: 提出了一种包含三个关键组件的LLM触发器逆向方法：1. 离散搜索：从单例词元开始，贪婪地累加生成潜在触发器。2. 隐式黑名单：通过评估候选触发器与目标类别样本在激活空间中的平均余弦相似度来实现。3. 检测：当候选触发器能够导致高误分类率和异常高的决策置信度时进行检测。

Result: 该方法能够可靠地检测并成功逆向真实存在的后门触发器短语，克服了许多近期研究的局限性。

Conclusion: 所提出的方法有效地解决了在LLM中进行后门触发器检测和逆向工程的挑战。

Abstract: While effective backdoor detection and inversion schemes have been developed
for AIs used e.g. for images, there are challenges in "porting" these methods
to LLMs. First, the LLM input space is discrete, which precludes gradient-based
search over this space, central to many backdoor inversion methods. Second,
there are ~30,000^k k-tuples to consider, k the token-length of a putative
trigger. Third, for LLMs there is the need to blacklist tokens that have strong
marginal associations with the putative target response (class) of an attack,
as such tokens give false detection signals. However, good blacklists may not
exist for some domains. We propose a LLM trigger inversion approach with three
key components: i) discrete search, with putative triggers greedily accreted,
starting from a select list of singletons; ii) implicit blacklisting, achieved
by evaluating the average cosine similarity, in activation space, between a
candidate trigger and a small clean set of samples from the putative target
class; iii) detection when a candidate trigger elicits high misclassifications,
and with unusually high decision confidence. Unlike many recent works, we
demonstrate that our approach reliably detects and successfully inverts
ground-truth backdoor trigger phrases.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [429] [Graph-Based Approximate Nearest Neighbor Search Revisited: Theoretical Analysis and Optimization](https://arxiv.org/abs/2509.15531)
*Xinran Ma,Zhaoqi Zhou,Chuan Zhou,Qi Meng,Zaijiu Shang,Guoliang Li,Zhiming Ma*

Main category: cs.DS

TL;DR: SNG图在近似最近邻搜索（ANNS）中表现优异，但理论基础薄弱。本研究通过鞅分析提供了SNG的理论保证，证明了索引图的度为O(n^{2/3+\epsilon})，搜索路径长度为O(\log n)。基于此，提出了一种新的截断参数R选择方法，实验表明该方法在查询延迟和召回率方面表现优于现有方法，同时显著加速了索引构建。


<details>
  <summary>Details</summary>
Motivation: SNG图在ANNS中表现优异，但其理论理解有限，导致截断策略次优。本研究旨在弥合理论与实践的差距，为基于图的ANNS提供理论保证，并为截断参数的选择提出原则性优化策略。

Method: 通过鞅分析表征索引构建过程，证明了索引图的度为O(n^{2/3+\epsilon})，搜索路径长度为O(\log n)。基于理论洞见，提出了一种新的截断参数R选择方法。

Result: 提出的方法在查询延迟和Recall@10方面与常用的二分搜索启发式方法相当或更优，同时在索引构建方面实现了2到9倍的加速。

Conclusion: 本研究为SNG图提供了理论基础，并提出了一种更优的截断参数选择方法，有效提升了ANNS的效率。

Abstract: Graph-based approaches to approximate nearest neighbor search (ANNS) have
achieved remarkable success in enabling fast, high-recall retrieval on
billion-scale vector datasets. Among them, the Sparse Neighborhood Graph (SNG)
has emerged as a widely adopted graph structure due to its superior search
performance. However, the theoretical understanding of SNG remains limited,
leading to reliance on heuristic-based and often suboptimal truncation
strategies. In this work, we aim to bridge the gap between theory and practice
by providing formal guarantees for graph-based ANNS methods and proposing
principled optimization strategies for the truncation parameter. By
characterizing the index construction process through martingale-based
analysis, we show that the degree of the index graph is $O(n^{2/3+\epsilon})$,
where $\epsilon$ is an arbitrarily small constant. Furthermore, we prove that
the expected search path length during query processing is $O(\log n)$. Based
on these theoretical insights, we introduce a novel and principled method for
selecting the truncation parameter $R$ in SNG. Experimental results demonstrate
that our method achieves comparable or superior performance in terms of query
latency and Recall@10 compared to commonly used binary search heuristics, while
yielding 2x to 9x speedups in overall index construction.

</details>


### [430] [Constant time enumeration of perfect bipartite matchings](https://arxiv.org/abs/2509.16135)
*Jiří Fink*

Main category: cs.DS

TL;DR: We developed a new algorithm that enumerates all perfect matchings in a bipartite graph with constant amortized time per matching, significantly improving on a 25-year-old algorithm.


<details>
  <summary>Details</summary>
Motivation: The motivation is to efficiently enumerate all perfect matchings in a bipartite graph, improving upon existing algorithms.

Method: The algorithm uses a variant of arithmetic circuits to represent perfect matchings within a binary tree, achieving constant amortized time per matching.

Result: The algorithm achieves a constant amortized time to visit each perfect matching, outperforming the previous O(log |V|) time complexity of Uno's algorithm.

Conclusion: The new algorithm provides a significant improvement in enumerating perfect matchings for bipartite graphs and introduces a novel representation using arithmetic circuits that may have future applications.

Abstract: We present an algorithm that enumerates all the perfect matchings in a given
bipartite graph G = (V,E). Our algorithm requires a constant amortized time to
visit one perfect matching of G, in contrast to the current fastest algorithm,
published 25 years ago by Uno, which requires O(log |V|) time.
  To facilitate the listing of all edges in a visited perfect matching, we
develop a variant of arithmetic circuits, which may have broader applications
in future enumeration algorithms. Consequently, a visited perfect matching is
represented within a binary tree. Although it is more common to provide visited
objects in an array, we present a class of graphs for which achieving constant
amortized time is not feasible in this case.

</details>


### [431] [On the Structural Parameterizations of 2-Club with Triangle Constraints](https://arxiv.org/abs/2509.16143)
*Ashwin Jacob,Diptapriyo Majumdar,Raghav Sakhuja*

Main category: cs.DS

TL;DR: 该论文研究了Vertex r-Triangle s-Club问题，并针对不同的参数（如图的叶宽度、h-index和反馈边数）提出了相应的算法和核。


<details>
  <summary>Details</summary>
Motivation: Vertex r-Triangle s-Club问题是s-Club问题的扩展，该问题在图论和计算复杂性领域具有重要意义。本研究旨在系统地研究Vertex r-Triangle s-Club问题，并探索其在不同参数下的计算复杂性。

Method: 文章提出了针对Vertex r-Triangle 2-Club问题的固定参数可处理（FPT）算法，该算法以输入图的叶宽度为参数。此外，还提出了一个以输入图的h-index为参数的XP算法。最后，文章为以反馈边数为参数的Vertex r-Triangle s-Club问题提供了一个O(fes)边大小的核。

Result: 文章成功地为Vertex r-Triangle 2-Club问题在叶宽度参数下设计了FPT算法，并为h-index参数设计了XP算法。此外，还为Vertex r-Triangle s-Club问题在反馈边数参数下提供了一个有效的核。

Conclusion: 本研究对Vertex r-Triangle s-Club问题进行了深入研究，并从参数化复杂性的角度提供了多种算法和核。研究结果为解决该类问题提供了新的思路和方法。

Abstract: Given an undirected graph G = (V, E) and an integer k, the s-Club asks if
Gcontains a vertex subset S of at least k vertices such that G[S] has diameter
at most s. Recently, Vertex r-Triangle s-Club, and Edge r-Triangle s-Club that
generalize the notion of s-Club have been studied by Garvardt et al.
[TOCS-2023, IWOCA-2022] from the perspective of parameterized complexity. Given
a graph G and an integer k, the Vertex r-Triangle s-Club asks if there is an
s-Club S with at least k vertices such that every vertex u \in S is part of at
least r triangles in G[S]. In this paper, we initiate a systematic study of
Vertex r-Triangle s-Club for every integer r >= 1 from the perspective of
structural parameters of the input graph. In particular, we provide FPT
algorithms for Vertex r-Triangle 2-Club when parameterized by the treewidth
(tw) of the input graph, and an XP algorithm when parameterized by the h-index
of the input graph. Additionally, when parameterized by the feedback edge
number (fes) of the input graph. We provide a kernel of O(fes) edges for Vertex
r-Triangle s-Club.

</details>


### [432] [Analyzing and improving a classical Betti number estimation algorithm](https://arxiv.org/abs/2509.16171)
*Julien Sorci*

Main category: cs.DS

TL;DR: 我们提出了一个改进的经典算法来估计任意单纯复形的归一化贝蒂数，该算法具有改进的样本复杂性，尤其是在方差较小的“简单情况”下。


<details>
  <summary>Details</summary>
Motivation: 受具有相似蒙特卡洛结构和改进样本复杂性的量子算法的启发，我们对经典算法的样本复杂性进行了更深入的分析。

Method: 我们提出了用于估计量的方差界限，并表明方差取决于单纯复形的组合属性。基于这些分析，我们提出了一种改进的经典算法，该算法可以降低“简单情况”下的样本复杂性。

Result: 我们展示了经典算法的有效性和局限性，方法是考虑 Erdős-Renyi 随机图模型，以证明存在“简单”和“困难”情况。我们证明了在某些模型下，我们的改进几乎总能降低样本复杂性，并且还产生了两种算法样本复杂性呈指数级的不同情况。

Conclusion: 该分析和提出的改进算法为理解和计算单纯复形的归一化贝蒂数提供了新的见解，并指出了未来研究的方向。

Abstract: Recently, a classical algorithm for estimating the normalized Betti number of
an arbitrary simplicial complex was proposed. Motivated by a quantum algorithm
with a similar Monte Carlo structure and improved sample complexity, we give a
more in-depth analysis of the sample complexity of this classical algorithm. To
this end, we present bounds for the variance of the estimators used in the
classical algorithm and show that the variance depends on certain combinatorial
properties of the underlying simplicial complex. This new analysis leads us to
propose an improvement to the classical algorithm which makes the "easy cases
easier'', in that it reduces the sample complexity for simplicial complexes
where the variance is sufficiently small. We show the effectiveness and
limitations of these classical algorithms by considering Erd\H{o}s-Renyi random
graph models to demonstrate the existence of "easy" and "hard" cases. Namely,
we show that for certain models our improvement almost always leads to a
reduced sample complexity, and also produce separate regimes where the sample
complexity for both algorithms is exponential.

</details>


### [433] [Query-Efficient Locally Private Hypothesis Selection via the Scheffe Graph](https://arxiv.org/abs/2509.16180)
*Gautam Kamath,Alireza F. Pour,Matthew Regehr,David P. Woodruff*

Main category: cs.DS

TL;DR: 该研究提出了一种在局部差分隐私下进行假设选择的算法，其查询复杂度优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 在局部差分隐私约束下，对假设选择问题进行研究，旨在改进现有算法的查询复杂度。

Method: 提出了一种名为“Scheffé graph”的新型结构，用于捕捉分布集Q中各分布的差异性，并基于此设计了一种执行~O(k^{3/2})次非自适应查询的算法。

Result: 算法满足局部差分隐私，并且查询次数少于先前需要~Ω(k^2)次查询或多次交互式查询的算法。

Conclusion: 所提出的基于Scheffé图的算法在局部差分隐私假设选择问题上实现了查询复杂度的改进，并且该图结构可能在更广泛的假设选择任务中具有应用价值。

Abstract: We propose an algorithm with improved query-complexity for the problem of
hypothesis selection under local differential privacy constraints. Given a set
of $k$ probability distributions $Q$, we describe an algorithm that satisfies
local differential privacy, performs $\tilde{O}(k^{3/2})$ non-adaptive queries
to individuals who each have samples from a probability distribution $p$, and
outputs a probability distribution from the set $Q$ which is nearly the closest
to $p$. Previous algorithms required either $\Omega(k^2)$ queries or many
rounds of interactive queries.
  Technically, we introduce a new object we dub the Scheff\'e graph, which
captures structure of the differences between distributions in $Q$, and may be
of more broad interest for hypothesis selection tasks.

</details>


### [434] [Clustering with Set Outliers and Applications in Relational Clustering](https://arxiv.org/abs/2509.16194)
*Vaishali Surianarayanan,Neeraj Kumar,Stavros Sintos*

Main category: cs.DS

TL;DR: 本研究提出了k-中心聚类与集合异常值问题，允许删除最多z个候选异常值集合，以最小化未被移除点到k个中心的最大距离。


<details>
  <summary>Details</summary>
Motivation: 该模型旨在解决数据库应用中常见的结构化噪声问题，例如数据集成和传感器系统中的故障数据源或损坏记录。

Method: 研究提出了针对该问题的首个近似算法，分别在通用和几何设置下进行。该算法实现了三标准近似：选择最多2k个中心和2fz个异常值集合（f为点所属集合的最大数量），同时将聚类成本近似到O(1)。在几何设置中，利用范围树和BBD树实现了近线性时间算法。对于f=1的场景，通过构建小的“核集”进一步提高了算法效率。此外，还证明了该问题的一个硬度结果，表明在选择少于fz个异常值集合的情况下，很难获得亚线性近似的聚类成本。

Result: 提出了通用的和几何设置下的近似算法，并给出了硬度结果。在f=1的情况下，通过构建小的核集进一步提高了算法效率。

Conclusion: 该模型自然地捕捉了关系聚类与异常值的问题，并提供了近似算法，建立了鲁棒聚类与关系查询评估之间的紧密联系。

Abstract: We introduce and study the $k$-center clustering problem with set outliers, a
natural and practical generalization of the classical $k$-center clustering
with outliers. Instead of removing individual data points, our model allows
discarding up to $z$ subsets from a given family of candidate outlier sets
$\mathcal{H}$. Given a metric space $(P,\mathsf{dist})$, where $P$ is a set of
elements and $\mathsf{dist}$ a distance metric, a family of sets
$\mathcal{H}\subseteq 2^P$, and parameters $k, z$, the goal is to compute a set
of $k$ centers $S\subseteq P$ and a family of $z$ sets $H\subseteq \mathcal{H}$
to minimize $\max_{p\in P\setminus(\bigcup_{h\in H} h)} \min_{s\in
S}\mathsf{dist}(p,s)$. This abstraction captures structured noise common in
database applications, such as faulty data sources or corrupted records in data
integration and sensor systems.
  We present the first approximation algorithms for this problem in both
general and geometric settings. Our methods provide tri-criteria
approximations: selecting up to $2k$ centers and $2f z$ outlier sets (where $f$
is the maximum number of sets that a point belongs to), while achieving
$O(1)$-approximation in clustering cost. In geometric settings, we leverage
range and BBD trees to achieve near-linear time algorithms. In many real
applications $f=1$. In this case we further improve the running time of our
algorithms by constructing small \emph{coresets}. We also provide a hardness
result for the general problem showing that it is unlikely to get any sublinear
approximation on the clustering cost selecting less than $f\cdot z$ outlier
sets.
  We demonstrate that this model naturally captures relational clustering with
outliers: outliers are input tuples whose removal affects the join output. We
provide approximation algorithms for both, establishing a tight connection
between robust clustering and relational query evaluation.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [435] [Diversity of Structured Domains via k-Kemeny Scores](https://arxiv.org/abs/2509.15812)
*Piotr Faliszewski,Krzysztof Sornat,Stanisław Szufa,Tomasz Wąs*

Main category: cs.GT

TL;DR: k-Kemeny问题在结构化域上的研究，表明其普遍存在难度，并利用该问题对域的多样性进行排序。


<details>
  <summary>Details</summary>
Motivation: 研究k-Kemeny问题在不同结构化域上的可计算性，并利用该问题对域的多样性进行量化。

Method: 分析k-Kemeny问题在单峰、单交叉、群可分和欧氏域上的复杂性，并根据k-Kemeny问题的难度对这些域进行排序。

Result: k-Kemeny问题在大多数结构化域上（即使k=2）仍然是难处理的；该研究为评估域的多样性提供了方法。

Conclusion: k-Kemeny问题的计算难度与其结构化域的多样性相关，为理解和比较不同投票模型提供了新的视角。

Abstract: In the k-Kemeny problem, we are given an ordinal election, i.e., a collection
of votes ranking the candidates from best to worst, and we seek the smallest
number of swaps of adjacent candidates that ensure that the election has at
most k different rankings. We study this problem for a number of structured
domains, including the single-peaked, single-crossing, group-separable, and
Euclidean ones. We obtain two kinds of results: (1) We show that k-Kemeny
remains intractable under most of these domains, even for k=2, and (2) we use
k-Kemeny to rank these domains in terms of their diversity.

</details>


### [436] [Strategy Improvement, the Simplex Algorithm and Lopsidedness](https://arxiv.org/abs/2509.16075)
*Matthew Maat*

Main category: cs.GT

TL;DR: 策略改进算法是线性和平均博弈的一种特例，与单纯形法有直接联系。


<details>
  <summary>Details</summary>
Motivation: 研究策略改进算法与单纯形算法之间的联系，并利用这种联系推导新的组合性质。

Method: 证明了策略改进算法是线性和平均博弈的一种特例，在温和的非退化假设下，可以视为单纯形算法的一个实例。

Result: 发现了策略改进算法与单纯形算法之间的直接联系，并基于此推导了策略集结构的一些组合性质，特别是与不对称集（lopsided sets）的联系。

Conclusion: 策略改进算法可以直接归类为单纯形算法的一个特例，这为理解和分析这类博弈算法提供了新的视角，并带来了组合性质方面的新发现。

Abstract: The strategy improvement algorithm for mean payoff games and parity games is
a local improvement algorithm, just like the simplex algorithm for linear
programs. Their similarity has turned out very useful: many lower bounds on
running time for the simplex method have been created from lower bounds for
strategy improvement. However, earlier connections between these algorithms
required constructing an intermediate Markov decision process, which is not
always possible. We prove a formal, direct connection between the two
algorithms, showing that many variants of strategy improvement for parity and
mean payoff games are truly an instance of the simplex algorithm, under mild
nondegeneracy assumptions. As a result of this, we derive some combinatorial
properties of the structure of strategy sets of various related games on
graphs. In particular, we show a connection to lopsided sets.

</details>


### [437] [Strategic Analysis of Just-In-Time Liquidity Provision in Concentrated Liquidity Market Makers](https://arxiv.org/abs/2509.16157)
*Bruno Llacer Trotti,Weizhao Tang,Rachid El-Azouzi,Giulia Fanti,Daniel Sadoc Menasche*

Main category: cs.GT

TL;DR: 该论文首次对集中流动性做市商（CLMMs）中的“即时”（JIT）流动性提供者的策略进行了建模和分析，发现实际的JIT行为偏离最优策略，并通过优化策略可以显著提高JIT流动性提供者的收益，但会降低被动流动性提供者的利润。


<details>
  <summary>Details</summary>
Motivation: 研究了自动化做市商（AMM）中一类特殊的流动性提供者（LP）——即时（JIT）LP的激励机制，这类LP通过在单笔交易中提供流动性来试图获取超额收益。

Method: 对JIT LP在CLMMs中的策略进行了形式化建模，构建了一个非线性优化问题，并证明了最优策略的存在性。通过将最优解与实际CLMMs数据进行拟合，分析了价格影响和费用分配。

Result: 研究发现，实际JIT LP的行为存在缺陷，未能充分考虑价格影响，最优策略可以使JIT LP的收益平均提高69%。同时，战略性部署的JIT流动性可以降低交易者的滑点，但会使被动LP的平均利润降低高达44%。

Conclusion: JIT LP可以通过优化策略来最大化自身收益，但这种优化会对被动LP造成负面影响，并对市场效率产生影响，具体影响程度取决于JIT LP的行为和流动性池的特性。

Abstract: Liquidity providers (LPs) are essential figures in the operation of automated
market makers (AMMs); in exchange for transaction fees, LPs lend the liquidity
that allows AMMs to operate. While many prior works have studied the incentive
structures of LPs in general, we currently lack a principled understanding of a
special class of LPs known as Just-In-Time (JIT) LPs. These are strategic
agents who momentarily supply liquidity for a single swap, in an attempt to
extract disproportionately high fees relative to the remaining passive LPs.
This paper provides the first formal, transaction-level model of JIT liquidity
provision for a widespread class of AMMs known as Concentrated Liquidity Market
Makers (CLMMs), as seen in Uniswap V3, for instance. We characterize the
landscape of price impact and fee allocation in these systems, formulate and
analyze a non-linear optimization problem faced by JIT LPs, and prove the
existence of an optimal strategy. By fitting our optimal solution for JIT LPs
to real-world CLMMs, we observe that in liquidity pools (particularly those
with risky assets), there is a significant gap between observed and optimal JIT
behavior. Existing JIT LPs often fail to account for price impact; doing so, we
estimate they could increase earnings by up to 69% on average over small time
windows. We also show that JIT liquidity, when deployed strategically, can
improve market efficiency by reducing slippage for traders, albeit at the cost
of eroding average passive LP profits by up to 44% per trade.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [438] [ChannelFlow-Tools: A Standardized Dataset Creation Pipeline for 3D Obstructed Channel Flows](https://arxiv.org/abs/2509.15236)
*Shubham Kavane,Kajol Kulkarni,Harald Koestler*

Main category: cs.GR

TL;DR: ChannelFlow-Tools是一个配置驱动的框架，用于标准化从CAD生成到3D阻塞通道流的ML就绪输入和目标的全过程，可实现可重复的ML训练。


<details>
  <summary>Details</summary>
Motivation: 需要一个标准化的框架来处理从3D CAD生成到机器学习模型输入和目标的全过程，特别是在3D阻塞通道流的场景下，以实现可重复的机器学习训练。

Method: ChannelFlow-Tools框架集成了几何合成、可行性检查、SDF体素化、HPC上的自动求解器编排（waLBerla LBM）和笛卡尔重采样到多分辨率张量。所有阶段均由Hydra/OmegaConf配置控制，确保可确定性复现和受控消融。

Result: 成功生成了超过10,000个场景（Re=100-15000），具有多样的形状和姿态。对存储权衡的端到端评估、一个最小的3D U-Net（128x32x32）以及数据集大小的示例代理模型表明，标准化表示支持可重复的ML训练。

Conclusion: ChannelFlow-Tools将一次性的数据集创建转变为一个可复现、可配置的CFD代理模型管道。

Abstract: We present ChannelFlow-Tools, a configuration-driven framework that
standardizes the end-to-end path from programmatic CAD solid generation to
ML-ready inputs and targets for 3D obstructed channel flows. The toolchain
integrates geometry synthesis with feasibility checks, signed distance field
(SDF) voxelization, automated solver orchestration on HPC (waLBerla LBM), and
Cartesian resampling to co-registered multi-resolution tensors. A single
Hydra/OmegaConf configuration governs all stages, enabling deterministic
reproduction and controlled ablations. As a case study, we generate 10k+ scenes
spanning Re=100-15000 with diverse shapes and poses. An end-to-end evaluation
of storage trade-offs directly from the emitted artifacts, a minimal 3D U-Net
at 128x32x32, and example surrogate models with dataset size illustrate that
the standardized representations support reproducible ML training.
ChannelFlow-Tools turns one-off dataset creation into a reproducible,
configurable pipeline for CFD surrogate modeling.

</details>


### [439] [Fast subdivision of Bézier curves](https://arxiv.org/abs/2509.15691)
*Paweł Woźny,Filip Chudy*

Main category: cs.GR

TL;DR: 使用快速傅里叶变换（FFT）将d维、n次多项式Bézier曲线的de Casteljau细分算法时间复杂度从O(dn²)降低到O(dn log n)，并提出了一种改进的数值稳定算法。


<details>
  <summary>Details</summary>
Motivation: 现有的de Casteljau算法将Bézier曲线细分需要O(dn²)时间，寻求更高效的算法。

Method: 利用快速傅里叶变换（FFT）及其逆变换。

Result: 直接应用FFT算法在数值上不稳定，但一种改进算法在O(dn log n)的时间复杂度下具有良好的数值质量。此外，当增加控制点时，细分更新时间为O(d)。

Conclusion: FFT及其变种可用于加速Bézier曲线及其相关对象的细分和求导过程，并提供了更好的数值稳定性。

Abstract: It is well-known that a $d$-dimensional polynomial B\'{e}zier curve of degree
$n$ can be subdivided into two segments using the famous de Casteljau algorithm
in $O(dn^2)$ time. Can this problem be solved more efficiently? In this paper,
we show that it is possible to do this in $O(dn\log{n})$ time using the fast
Fourier transform and its inverse. Experiments show that the direct application
of the new method performs well only for small values of $n$, as the algorithm
is numerically unstable. However, a slightly modified version -- which still
has $O(dn\log{n})$ computational complexity -- offers good numerical quality,
which is confirmed by numerical experiments conducted in \textsf{Python}.
Moreover, the new method has a nice property: if a B\'{e}zier curve is extended
by an additional control point, the subdivision can be updated in $O(d)$ time.
  A similar idea can be applied to speed up the subdivision of rational
B\'{e}zier curves and rectangular B\'{e}zier surfaces, as well as to compute
the derivatives of B\'{e}zier curves more efficiently.

</details>


### [440] [GenCAD-3D: CAD Program Generation using Multimodal Latent Space Alignment and Synthetic Dataset Balancing](https://arxiv.org/abs/2509.15246)
*Nomi Yu,Md Ferdous Alam,A. John Hart,Faez Ahmed*

Main category: cs.GR

TL;DR: GenCAD-3D是一个多模态生成框架，利用对比学习和潜在扩散模型生成CAD程序，并结合SynthBal数据增强策略来处理不平衡数据集，显著提高了CAD重建的准确性和复杂几何体的性能。


<details>
  <summary>Details</summary>
Motivation: 从点云和网格等非参数数据自动生成CAD程序是一项关键但困难的任务，通常需要大量的手动干预。现有的深度生成模型受限于不平衡和不够大的数据集，尤其是在复杂CAD程序方面。本研究旨在解决这个问题。

Method: GenCAD-3D框架结合了对比学习，用于对齐CAD和几何编码器的潜在嵌入，以及潜在扩散模型，用于CAD序列生成和检索。此外，还提出了一种名为SynthBal的合成数据增强策略，以平衡和扩展数据集，特别是增强复杂CAD几何体的表示。

Result: SynthBal显著提高了重建准确性，减少了无效CAD模型的生成，并显著提高了在高复杂度几何体上的性能，超过了现有的基准。

Conclusion: GenCAD-3D框架和SynthBal数据增强策略在自动化CAD生成方面取得了显著进展，特别是在处理复杂性和数据不足的问题上，为简化逆向工程和增强工程设计自动化提供了重要的启示。

Abstract: CAD programs, structured as parametric sequences of commands that compile
into precise 3D geometries, are fundamental to accurate and efficient
engineering design processes. Generating these programs from nonparametric data
such as point clouds and meshes remains a crucial yet challenging task,
typically requiring extensive manual intervention. Current deep generative
models aimed at automating CAD generation are significantly limited by
imbalanced and insufficiently large datasets, particularly those lacking
representation for complex CAD programs. To address this, we introduce
GenCAD-3D, a multimodal generative framework utilizing contrastive learning for
aligning latent embeddings between CAD and geometric encoders, combined with
latent diffusion models for CAD sequence generation and retrieval.
Additionally, we present SynthBal, a synthetic data augmentation strategy
specifically designed to balance and expand datasets, notably enhancing
representation of complex CAD geometries. Our experiments show that SynthBal
significantly boosts reconstruction accuracy, reduces the generation of invalid
CAD models, and markedly improves performance on high-complexity geometries,
surpassing existing benchmarks. These advancements hold substantial
implications for streamlining reverse engineering and enhancing automation in
engineering design. We will publicly release our datasets and code, including a
set of 51 3D-printed and laser-scanned parts on our project site.

</details>


### [441] [Causal Reasoning Elicits Controllable 3D Scene Generation](https://arxiv.org/abs/2509.15249)
*Shen Chen,Ruiyu Zhao,Jiale Zhou,Zongkai Wu,Jenq-Neng Hwang,Lei Li*

Main category: cs.GR

TL;DR: CausalStruct是一个利用因果推理生成3D场景的新框架，通过LLM构建因果图，并结合PID控制器和3D高斯泼溅等技术，提高了场景的逻辑一致性、物理真实性和适应性。


<details>
  <summary>Details</summary>
Motivation: 现有的3D场景生成方法在处理物体间的复杂逻辑依赖和物理约束方面存在不足，限制了其在动态和真实环境中的应用。

Method: 利用LLM构建包含物体、属性、因果依赖和物理约束的因果图。通过强制因果顺序确定物体放置顺序，并应用因果干预来根据物理约束调整空间配置。使用PID控制器迭代调整物体尺度和位置。结合3D高斯泼溅和分数蒸馏采样来提高形状精度和渲染稳定性。

Result: CausalStruct在逻辑连贯性、空间交互真实性和适应性方面表现出色。

Conclusion: CausalStruct通过引入因果推理，有效地解决了现有3D场景生成方法在处理逻辑依赖和物理约束方面的局限性，能够生成更真实、更具适应性的3D场景。

Abstract: Existing 3D scene generation methods often struggle to model the complex
logical dependencies and physical constraints between objects, limiting their
ability to adapt to dynamic and realistic environments. We propose
CausalStruct, a novel framework that embeds causal reasoning into 3D scene
generation. Utilizing large language models (LLMs), We construct causal graphs
where nodes represent objects and attributes, while edges encode causal
dependencies and physical constraints. CausalStruct iteratively refines the
scene layout by enforcing causal order to determine the placement order of
objects and applies causal intervention to adjust the spatial configuration
according to physics-driven constraints, ensuring consistency with textual
descriptions and real-world dynamics. The refined scene causal graph informs
subsequent optimization steps, employing a
Proportional-Integral-Derivative(PID) controller to iteratively tune object
scales and positions. Our method uses text or images to guide object placement
and layout in 3D scenes, with 3D Gaussian Splatting and Score Distillation
Sampling improving shape accuracy and rendering stability. Extensive
experiments show that CausalStruct generates 3D scenes with enhanced logical
coherence, realistic spatial interactions, and robust adaptability.

</details>


### [442] [Geometric Integration for Neural Control Variates](https://arxiv.org/abs/2509.15538)
*Daniel Meister,Takahiro Harada*

Main category: cs.GR

TL;DR: 神经网络可以作为控制变量来减少蒙特卡洛积分中的方差，但解析积分是主要的挑战。本文研究了具有连续分段线性激活函数的多层感知机（MLP），提出了一种基于积分域细分的2D积分方法，并将其应用于光线追踪模拟。


<details>
  <summary>Details</summary>
Motivation: 蒙特卡洛积分方差过大，而神经网络作为一种万能逼近器，有潜力作为控制变量，但存在解析积分的困难。

Method: 研究了具有连续分段线性激活函数的多层感知机（MLP）模型，提出了一种基于积分域细分和计算几何技术在2D下进行解析积分的方法。

Result: 证明了MLP可以与所提出的积分方法结合作为控制变量，并在光线追踪模拟中展示了其应用。

Conclusion: 通过将MLP与本文提出的积分方法结合，可以有效地利用控制变量技术减少蒙特卡洛积分的方差，并在光线追踪等应用中取得良好效果。

Abstract: Control variates are a variance-reduction technique for Monte Carlo
integration. The principle involves approximating the integrand by a function
that can be analytically integrated, and integrating using the Monte Carlo
method only the residual difference between the integrand and the
approximation, to obtain an unbiased estimate. Neural networks are universal
approximators that could potentially be used as a control variate. However, the
challenge lies in the analytic integration, which is not possible in general.
In this manuscript, we study one of the simplest neural network models, the
multilayered perceptron (MLP) with continuous piecewise linear activation
functions, and its possible analytic integration. We propose an integration
method based on integration domain subdivision, employing techniques from
computational geometry to solve this problem in 2D. We demonstrate that an MLP
can be used as a control variate in combination with our integration method,
showing applications in the light transport simulation.

</details>


### [443] [Implicit Modeling for 3D-printed Multi-material Computational Object Design via Python](https://arxiv.org/abs/2509.15562)
*Charles Wade,Devon Beck,Robert MacCurdy*

Main category: cs.GR

TL;DR: 该论文提出了开源工具，用于加速多材料体打印和超材料设计的研究，实现了灵活的API、多材料渐变、与有限元建模的集成，并通过案例研究展示了其应用。


<details>
  <summary>Details</summary>
Motivation: 加速体多材料增材制造和超材料设计的研究。

Method: 提出一个基于Python的API，支持多材料梯度、与外部库集成、多材料点阵结构设计和有限元建模的互操作性；采用新的隐式多材料建模技术，实现多尺度空间渐变；集成有限元分析，通过自适应网格尺寸和直接导入模拟结果来指导材料分布；并提出兼容标准切片软件的网格导出策略。

Result: 实现了功能梯度点阵、算法生成结构和模拟驱动设计等应用，例如通过优化机械性能和乘坐舒适度来设计多材料自行车座椅。

Conclusion: 通过提供开源工具和易于使用的接口，显著提高了功能梯度计算设计方法在多材料制造中的可及性和应用性。

Abstract: This paper introduces open-source contributions designed to accelerate
research in volumetric multi-material additive manufacturing and metamaterial
design. We present a flexible Python-based API facilitating parametric
expression of multi-material gradients, integration with external libraries,
multi-material lattice structure design, and interoperability with finite
element modeling. Novel implicit multi-material modeling techniques enable
detailed spatial grading at multiple scales within lattice structures.
Additionally, our framework integrates with finite element analysis, offering
predictive simulations via adaptive mesh sizing and direct import of simulation
results to guide material distributions. Practical case studies illustrate the
utility of these contributions, including functionally graded lattices,
algorithmically generated structures, and simulation-informed designs,
exemplified by a multi-material bicycle seat optimized for mechanical
performance and rider comfort. Finally, we introduce a mesh export strategy
compatible with standard slicing software, significantly broadening the
accessibility and adoption of functionality graded computational design
methodologies for multi-material fabrication.

</details>


### [444] [MoAngelo: Motion-Aware Neural Surface Reconstruction for Dynamic Scenes](https://arxiv.org/abs/2509.15892)
*Mohamed Ebbed,Zorah Lähner*

Main category: cs.GR

TL;DR: 从多视角视频中进行动态场景重建在计算机视觉领域仍然是一个基本挑战。尽管最近的神经表面重建方法在静态3D重建方面取得了显著成果，但要将这些方法扩展到动态场景并达到同等质量会带来重大的计算和表示挑战。现有的动态方法侧重于新视角合成，因此其提取的网格往往存在噪声。即使是那些旨在实现几何保真度的方法，也常常因为问题的病态性而得到过于平滑的网格。我们提出了一种用于高度详细的动态重建的新框架，该框架将静态3D重建方法NeuralAngelo扩展到动态环境。为此，我们首先使用NeuralAngelo从初始帧进行高质量的模板场景重建，然后联合优化跟踪模板并根据时间序列对其进行精炼的变形场。这种灵活的模板允许更新几何图形，以包含无法通过变形场建模的变化，例如被遮挡的部分或拓扑结构的变化。我们在ActorsHQ数据集上展示了优于先前最先进方法的重建精度。


<details>
  <summary>Details</summary>
Motivation: 现有的动态场景重建方法在处理多视角视频时存在计算和表示上的挑战，并且现有方法主要关注新视角合成，导致提取的网格质量不高，或者由于问题的病态性而导致网格过于平滑。

Method: 该方法将静态3D重建方法NeuralAngelo扩展到动态设置。首先，使用NeuralAngelo从初始帧进行高质量的模板场景重建。然后，联合优化变形场以跟踪模板并根据时间序列对其进行精炼。这种灵活的模板允许更新几何图形，以包含无法通过变形场建模的变化，例如被遮挡的部分或拓扑结构的变化。

Result: 在ActorsHQ数据集上，与先前最先进的方法相比，该方法实现了优越的重建精度。

Conclusion: 该新框架通过将静态3D重建方法NeuralAngelo扩展到动态设置，并结合模板和变形场进行联合优化，能够实现高度详细的动态场景重建，并在数据集上取得了优于现有方法的性能。

Abstract: Dynamic scene reconstruction from multi-view videos remains a fundamental
challenge in computer vision. While recent neural surface reconstruction
methods have achieved remarkable results in static 3D reconstruction, extending
these approaches with comparable quality for dynamic scenes introduces
significant computational and representational challenges. Existing dynamic
methods focus on novel-view synthesis, therefore, their extracted meshes tend
to be noisy. Even approaches aiming for geometric fidelity often result in too
smooth meshes due to the ill-posedness of the problem. We present a novel
framework for highly detailed dynamic reconstruction that extends the static 3D
reconstruction method NeuralAngelo to work in dynamic settings. To that end, we
start with a high-quality template scene reconstruction from the initial frame
using NeuralAngelo, and then jointly optimize deformation fields that track the
template and refine it based on the temporal sequence. This flexible template
allows updating the geometry to include changes that cannot be modeled with the
deformation field, for instance occluded parts or the changes in the topology.
We show superior reconstruction accuracy in comparison to previous
state-of-the-art methods on the ActorsHQ dataset.

</details>


### [445] [Generating Detailed Character Motion from Blocking Poses](https://arxiv.org/abs/2509.16064)
*Purvi Goel,Guy Tevet,C. K. Liu,Kayvon Fatahalian*

Main category: cs.GR

TL;DR: 生成式扩散模型在运动细节化任务上表现出色，通过在推理时融合输入姿态约束和扩散模型输出，克服了现有方法的局限性，实现了从粗略姿态到详细动画的转换。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型可解决动画时序问题，但无法有效利用扩散先验增强稀疏的粗略姿态。需要一种新的方法来解决利用扩散模型增强姿态细节的问题。

Method: 在推理过程中，于特定扩散步数时，将无条件的扩散模型输出与输入的姿态约束进行融合，并使用每种姿态的容差权重，然后将融合结果作为预训练的运动重定时模型的输入。

Result: 所提出的方法显著优于现有通过融合模型输出或将姿态约束表达为引导来实现细节添加的方法，是首个能够将粗略姿态可靠地转换为合理详细角色动画的扩散模型。

Conclusion: 本研究成功开发了一种新的扩散模型方法，通过创新的推理时融合技术，有效解决了运动细节化任务中的姿态增强问题，显著提高了动画细节的生成质量。

Abstract: We focus on the problem of using generative diffusion models for the task of
motion detailing: converting a rough version of a character animation,
represented by a sparse set of coarsely posed, and imprecisely timed blocking
poses, into a detailed, natural looking character animation. Current diffusion
models can address the problem of correcting the timing of imprecisely timed
poses, but we find that no good solution exists for leveraging the diffusion
prior to enhance a sparse set of blocking poses with additional pose detail. We
overcome this challenge using a simple inference-time trick. At certain
diffusion steps, we blend the outputs of an unconditioned diffusion model with
input blocking pose constraints using per-blocking-pose tolerance weights, and
pass this result in as the input condition to an pre-existing motion retiming
model. We find this approach works significantly better than existing
approaches that attempt to add detail by blending model outputs or via
expressing blocking pose constraints as guidance. The result is the first
diffusion model that can robustly convert blocking-level poses into plausible
detailed character animations.

</details>
