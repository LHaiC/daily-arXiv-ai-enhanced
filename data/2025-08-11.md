<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 98]
- [cs.CL](#cs.CL) [Total: 45]
- [cs.AR](#cs.AR) [Total: 3]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 15]
- [eess.SY](#eess.SY) [Total: 4]
- [cs.ET](#cs.ET) [Total: 2]
- [eess.SP](#eess.SP) [Total: 11]
- [cs.LG](#cs.LG) [Total: 49]
- [quant-ph](#quant-ph) [Total: 45]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 8]
- [cs.RO](#cs.RO) [Total: 25]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.MA](#cs.MA) [Total: 4]
- [cs.DS](#cs.DS) [Total: 6]
- [cs.DC](#cs.DC) [Total: 8]
- [cs.LO](#cs.LO) [Total: 3]
- [cs.NE](#cs.NE) [Total: 2]
- [cs.GT](#cs.GT) [Total: 4]
- [cs.AI](#cs.AI) [Total: 28]
- [physics.app-ph](#physics.app-ph) [Total: 5]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Street View Sociability: Interpretable Analysis of Urban Social Behavior Across 15 Cities](https://arxiv.org/abs/2508.06342)
*Kieran Elrod,Katherine Flanigan,Mario Bergés*

Main category: cs.CV

TL;DR: 本研究利用街景图像和大型语言模型，根据城市规划理论量化了街道的社交互动质量，并将社交性与城市归属感、天空、绿色和水景指数等环境因素联系起来。


<details>
  <summary>Details</summary>
Motivation: 旨在量化衡量街道的社交互动质量，而非仅仅是行人数量，并探索利用廉价的街景图像数据源提取社会信息的可行性。

Method: 本研究使用多模态大型语言模型分析了来自 15 个城市的 2,998 张街景图像，并以 Mehta 的被动、短暂和持久的社交性分类法作为指导。随后，使用线性回归模型（控制天气、时间、行人数量等因素）来检验推断的社交性指标是否与世界价值观调查中的城市归属感得分以及从街景图像中提取的环境预测因子（如天空、绿色和水景指数）相关。

Result: 研究结果与长期的城市规划理论一致：天空视野指数与所有三种社交类型相关，绿色视野指数预示着持久的社交性，而城市归属感则与短暂的社交性正相关。

Conclusion: 该研究初步证明了街景图像可用于推断特定类型的社会互动与建筑环境变量之间的关系，并可能成为研究城市社会性的可扩展、注重隐私的工具。

Abstract: Designing socially active streets has long been a goal of urban planning, yet
existing quantitative research largely measures pedestrian volume rather than
the quality of social interactions. We hypothesize that street view imagery --
an inexpensive data source with global coverage -- contains latent social
information that can be extracted and interpreted through established social
science theory. As a proof of concept, we analyzed 2,998 street view images
from 15 cities using a multimodal large language model guided by Mehta's
taxonomy of passive, fleeting, and enduring sociability -- one illustrative
example of a theory grounded in urban design that could be substituted or
complemented by other sociological frameworks. We then used linear regression
models, controlling for factors like weather, time of day, and pedestrian
counts, to test whether the inferred sociability measures correlate with
city-level place attachment scores from the World Values Survey and with
environmental predictors (e.g., green, sky, and water view indices) derived
from individual street view images. Results aligned with long-standing urban
planning theory: the sky view index was associated with all three sociability
types, the green view index predicted enduring sociability, and place
attachment was positively associated with fleeting sociability. These results
provide preliminary evidence that street view images can be used to infer
relationships between specific types of social interactions and built
environment variables. Further research could establish street view imagery as
a scalable, privacy-preserving tool for studying urban sociability, enabling
cross-cultural theory testing and evidence-based design of socially vibrant
cities.

</details>


### [2] [Boosting Adversarial Transferability via Residual Perturbation Attack](https://arxiv.org/abs/2508.05689)
*Jinjia Peng,Zeze Tao,Huibing Wang,Meng Wang,Yang Wang*

Main category: cs.CV

TL;DR: ResPA是一种利用残差梯度的新型攻击方法，可以提高黑盒对抗性攻击的迁移能力。


<details>
  <summary>Details</summary>
Motivation: 为了提升基于迁移的黑盒攻击的迁移能力，解决了现有方法忽略扰动方向影响的问题。

Method: ResPA利用残差梯度作为扰动方向，通过指数移动平均计算输入梯度的一阶矩作为参考梯度，并结合当前梯度与参考梯度的残差来捕捉全局扰动方向的变化。

Result: ResPA的实验结果表明，其比现有的典型基于迁移的攻击方法具有更好的迁移能力，并且可以通过结合当前输入转换方法进一步提高迁移能力。

Conclusion: 提出了一种名为残差扰动攻击（ResPA）的新型攻击方法，该方法利用残差梯度作为扰动方向，引导对抗样本朝着损失函数的平坦区域，并在实际测试中展现出比现有基于迁移的攻击方法更优越的迁移能力，结合当前输入转换方法可进一步提升迁移能力。

Abstract: Deep neural networks are susceptible to adversarial examples while suffering
from incorrect predictions via imperceptible perturbations. Transfer-based
attacks create adversarial examples for surrogate models and transfer these
examples to target models under black-box scenarios. Recent studies reveal that
adversarial examples in flat loss landscapes exhibit superior transferability
to alleviate overfitting on surrogate models. However, the prior arts overlook
the influence of perturbation directions, resulting in limited transferability.
In this paper, we propose a novel attack method, named Residual Perturbation
Attack (ResPA), relying on the residual gradient as the perturbation direction
to guide the adversarial examples toward the flat regions of the loss function.
Specifically, ResPA conducts an exponential moving average on the input
gradients to obtain the first moment as the reference gradient, which
encompasses the direction of historical gradients. Instead of heavily relying
on the local flatness that stems from the current gradients as the perturbation
direction, ResPA further considers the residual between the current gradient
and the reference gradient to capture the changes in the global perturbation
direction. The experimental results demonstrate the better transferability of
ResPA than the existing typical transfer-based attack methods, while the
transferability can be further improved by combining ResPA with the current
input transformation methods. The code is available at
https://github.com/ZezeTao/ResPA.

</details>


### [3] [Generalized Few-Shot Out-of-Distribution Detection](https://arxiv.org/abs/2508.05732)
*Pinxuan Li,Bing Cao,Changqing Zhang,Qinghua Hu*

Main category: cs.CV

TL;DR: 本研究提出GOOD框架，通过引入通用知识模型（GKM）和知识动态嵌入（KDE）机制，解决少样本OOD检测泛化能力不足的问题，并在实验中取得优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的少样本OOD检测方法泛化能力不足，容易过拟合有限的训练数据，导致在泛化数据上的性能下降，并且在不同场景下的表现不一致。

Method: 提出了一种名为“广义少样本OOD检测”（GOOD）的框架，该框架通过引入一个辅助的“通用知识模型”（GKM）来增强OOD检测模型的通用知识，而不是直接从少样本数据中学习。从泛化角度揭示了少样本OOD检测问题，并从理论上推导了用于OOD检测的“泛化-特异性平衡”（GS平衡），以期通过通用知识模型来降低泛化误差的上界。在此基础上，提出了一种“知识动态嵌入”（KDE）机制，通过GKM的广义信念（G-Belief）自适应地调节通用知识的指导，动态地将OOD检测模型的输出分布与通用知识模型进行对齐，从而提升GS平衡。

Result: 所提出的GOOD框架通过引入GKM和KDE机制，并在理论上推导GS平衡，有效解决了现有方法泛化能力不足的问题，并在真实世界的OOD基准测试中取得了优于现有方法的性能。

Conclusion: 实验结果表明该方法在真实世界OOD基准测试中表现优越。

Abstract: Few-shot Out-of-Distribution (OOD) detection has emerged as a critical
research direction in machine learning for practical deployment. Most existing
Few-shot OOD detection methods suffer from insufficient generalization
capability for the open world. Due to the few-shot learning paradigm, the OOD
detection ability is often overfit to the limited training data itself, thus
degrading the performance on generalized data and performing inconsistently
across different scenarios. To address this challenge, we proposed a
Generalized Few-shot OOD Detection (GOOD) framework, which empowers the general
knowledge of the OOD detection model with an auxiliary General Knowledge Model
(GKM), instead of directly learning from few-shot data. We proceed to reveal
the few-shot OOD detection from a generalization perspective and theoretically
derive the Generality-Specificity balance (GS-balance) for OOD detection, which
provably reduces the upper bound of generalization error with a general
knowledge model. Accordingly, we propose a Knowledge Dynamic Embedding (KDE)
mechanism to adaptively modulate the guidance of general knowledge. KDE
dynamically aligns the output distributions of the OOD detection model to the
general knowledge model based on the Generalized Belief (G-Belief) of GKM,
thereby boosting the GS-balance. Experiments on real-world OOD benchmarks
demonstrate our superiority. Codes will be available.

</details>


### [4] [UnGuide: Learning to Forget with LoRA-Guided Diffusion Models](https://arxiv.org/abs/2508.05755)
*Agnieszka Polowczyk,Alicja Polowczyk,Dawid Malarz,Artur Kasymov,Marcin Mazur,Jacek Tabor,Przemysław Spurek*

Main category: cs.CV

TL;DR: 本研究提出UnGuide，一种利用动态CFG引导来精确控制LoRA模型反学习的新方法，能在移除特定概念的同时保持图像的保真度和模型的整体性能。


<details>
  <summary>Details</summary>
Motivation: 随着大型文本到图像扩散模型的进步，人们对它们可能被滥用（例如生成有害或误导性内容）的担忧日益增加。因此，需要一种有效的机器反学习方法，能够在不影响模型整体性能的情况下，移除模型中特定的知识或概念。

Method: 本研究提出了一种名为UnGuide的新方法，该方法引入了一种动态推理机制——UnGuidance，利用Classifier-Free Guidance（CFG）来精确控制机器反学习过程。UnGuide通过调节引导尺度来平衡LoRA模块和基础模型的作用，以实现选择性反学习，并保持内容的保真度和真实感。

Result: 实验结果表明，UnGuide在控制概念擦除方面取得了成功，并能保留扩散模型的表达能力。在物体擦除和显式内容移除任务中，其表现优于现有的基于LoRA的方法。

Conclusion: UnGuide通过动态调整CFG的引导尺度，实现了可控的概念擦除，并且在保持模型生成能力方面优于现有的基于LoRA的方法，在擦除物体和显式内容方面均表现出色。

Abstract: Recent advances in large-scale text-to-image diffusion models have heightened
concerns about their potential misuse, especially in generating harmful or
misleading content. This underscores the urgent need for effective machine
unlearning, i.e., removing specific knowledge or concepts from pretrained
models without compromising overall performance. One possible approach is
Low-Rank Adaptation (LoRA), which offers an efficient means to fine-tune models
for targeted unlearning. However, LoRA often inadvertently alters unrelated
content, leading to diminished image fidelity and realism. To address this
limitation, we introduce UnGuide -- a novel approach which incorporates
UnGuidance, a dynamic inference mechanism that leverages Classifier-Free
Guidance (CFG) to exert precise control over the unlearning process. UnGuide
modulates the guidance scale based on the stability of a few first steps of
denoising processes, enabling selective unlearning by LoRA adapter. For prompts
containing the erased concept, the LoRA module predominates and is
counterbalanced by the base model; for unrelated prompts, the base model
governs generation, preserving content fidelity. Empirical results demonstrate
that UnGuide achieves controlled concept removal and retains the expressive
power of diffusion models, outperforming existing LoRA-based methods in both
object erasure and explicit content removal tasks.

</details>


### [5] [HOLODECK 2.0: Vision-Language-Guided 3D World Generation with Editing](https://arxiv.org/abs/2508.05899)
*Zixuan Bian,Ruohan Ren,Yue Yang,Chris Callison-Burch*

Main category: cs.CV

TL;DR: HOLODECK 2.0 是一个先进的视觉-语言引导框架，用于生成3D世界并支持交互式场景编辑。它能根据文本描述生成高质量、风格多样且语义精确的3D场景，并能根据用户反馈进行灵活编辑，在游戏建模等领域展现出巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 当前的3D场景设计主要依赖手动创作，且自动化方法在生成开放域场景和支持灵活编辑方面存在不足。因此，直接从文本生成3D世界受到了越来越多的关注。

Method: HOLODECK 2.0 框架利用视觉-语言模型（VLMs）解析文本描述以识别场景对象，并通过最先进的3D生成模型生成高质量资产。随后，利用从VLMs获得的视空间约束，迭代地生成语义一致且物理上合理的布局。此外，该框架还支持基于用户反馈的交互式场景编辑，包括布局优化和风格一致的对象编辑。

Result: HOLODECK 2.0 能够生成多样化、风格丰富的3D场景（如写实、卡通、动漫、赛博朋克风格），在语义保真度上与精细的文本描述高度一致，适用于室内和开放域环境。通过人工评估和基于CLIP的评估，证明了HOLODECK 2.0 在生成高质量场景方面表现出色，优于基线方法。

Conclusion: HOLODECK 2.0 在游戏建模等领域具有实际应用前景，能够生成高质量、多样化且符合文本描述的3D场景，并支持交互式编辑，在室内和开放域场景中均优于基线方法。

Abstract: 3D scene generation plays a crucial role in gaming, artistic creation,
virtual reality and many other domains. However, current 3D scene design still
relies heavily on extensive manual effort from creators, and existing automated
methods struggle to generate open-domain scenes or support flexible editing. As
a result, generating 3D worlds directly from text has garnered increasing
attention. In this paper, we introduce HOLODECK 2.0, an advanced
vision-language-guided framework for 3D world generation with support for
interactive scene editing based on human feedback. HOLODECK 2.0 can generate
diverse and stylistically rich 3D scenes (e.g., realistic, cartoon, anime, and
cyberpunk styles) that exhibit high semantic fidelity to fine-grained input
descriptions, suitable for both indoor and open-domain environments. HOLODECK
2.0 leverages vision-language models (VLMs) to identify and parse the objects
required in a scene and generates corresponding high-quality assets via
state-of-the-art 3D generative models. It then iteratively applies spatial
constraints derived from the VLMs to achieve semantically coherent and
physically plausible layouts. Human evaluations and CLIP-based assessments
demonstrate that HOLODECK 2.0 effectively generates high-quality scenes closely
aligned with detailed textual descriptions, consistently outperforming
baselines across indoor and open-domain scenarios. Additionally, we provide
editing capabilities that flexibly adapt to human feedback, supporting layout
refinement and style-consistent object edits. Finally, we present a practical
application of HOLODECK 2.0 in procedural game modeling, generating visually
rich and immersive environments, potentially boosting efficiency.

</details>


### [6] [Improving Masked Style Transfer using Blended Partial Convolution](https://arxiv.org/abs/2508.05769)
*Seyed Hadi Seyed,Ayberk Cansever,David Hart*

Main category: cs.CV

TL;DR: Existing style transfer methods apply to whole images, but users often only want specific regions styled. Masking after transfer doesn't work well. This paper presents a new method using partial convolutions and internal blending to accurately style only the chosen region, improving results.


<details>
  <summary>Details</summary>
Motivation: While artistic style transfer is possible with neural networks, existing methods apply it to the whole image. Users often only need to apply style transfer to specific regions, and the common practice of masking after stylization fails to properly capture style features within the region of interest. This work aims to address this limitation by enabling accurate, region-specific style transfer.

Method: This paper proposes a partial-convolution-based style transfer network that applies style features exclusively to a user-specified region of interest. It also introduces network-internal blending techniques to address potential imperfections in the region selection process.

Result: The proposed method visually and quantitatively improves artistic style transfer by applying it exclusively to the region of interest. Examples from the SA-1B dataset are used to demonstrate these improvements.

Conclusion: In conclusion, this paper proposes a novel partial-convolution-based style transfer network that accurately applies style features exclusively to the region of interest, along with network-internal blending techniques to handle imperfections in region selection. The approach visually and quantitatively improves stylization, as demonstrated with examples from the SA-1B dataset.

Abstract: Artistic style transfer has long been possible with the advancements of
convolution- and transformer-based neural networks. Most algorithms apply the
artistic style transfer to the whole image, but individual users may only need
to apply a style transfer to a specific region in the image. The standard
practice is to simply mask the image after the stylization. This work shows
that this approach tends to improperly capture the style features in the region
of interest. We propose a partial-convolution-based style transfer network that
accurately applies the style features exclusively to the region of interest.
Additionally, we present network-internal blending techniques that account for
imperfections in the region selection. We show that this visually and
quantitatively improves stylization using examples from the SA-1B dataset. Code
is publicly available at https://github.com/davidmhart/StyleTransferMasked.

</details>


### [7] [LV-Net: Anatomy-aware lateral ventricle shape modeling with a case study on Alzheimer's disease, the Australian Imaging Biomarkers and Lifestyle flagship study of ageing](https://arxiv.org/abs/2508.06055)
*Wonjung Park,Suhyun Ahn,Jinah Park*

Main category: cs.CV

TL;DR: LV-Net是一种新颖的框架，通过生成个体化3D左心室网格来分析神经系统疾病，它通过利用解剖学关系和增强点对应来提高精度和鲁棒性，并在阿尔茨海默病分析中显示出有前景的结果。


<details>
  <summary>Details</summary>
Motivation: 解决神经系统疾病中左心室形状分析的挑战，包括个体间的形状变异性和MRI分辨率有限导致的分割困难。

Method: 通过一个解剖学驱动的联合模型生成个体化3D左心室网格，并对模板网格的顶点进行分类以增强点对应，从而提高重建精度和鲁棒性。

Result: LV-Net在存在分割缺陷的情况下仍能实现优越的重建精度，并提供更可靠的形状统计数据。

Conclusion: LV-Net在阿尔茨海默病分析中能够识别出与该疾病显著相关的LV亚区域，并能提供比传统方法更可靠的形状描述符。

Abstract: Lateral ventricle (LV) shape analysis holds promise as a biomarker for
neurological diseases; however, challenges remain due to substantial shape
variability across individuals and segmentation difficulties arising from
limited MRI resolution. We introduce LV-Net, a novel framework for producing
individualized 3D LV meshes from brain MRI by deforming an anatomy-aware joint
LV-hippocampus template mesh. By incorporating anatomical relationships
embedded within the joint template, LV-Net reduces boundary segmentation
artifacts and improves reconstruction robustness. In addition, by classifying
the vertices of the template mesh based on their anatomical adjacency, our
method enhances point correspondence across subjects, leading to more accurate
LV shape statistics. We demonstrate that LV-Net achieves superior
reconstruction accuracy, even in the presence of segmentation imperfections,
and delivers more reliable shape descriptors across diverse datasets. Finally,
we apply LV-Net to Alzheimer's disease analysis, identifying LV subregions that
show significantly associations with the disease relative to cognitively normal
controls. The codes for LV shape modeling are available at
https://github.com/PWonjung/LV_Shape_Modeling.

</details>


### [8] [MAISI-v2: Accelerated 3D High-Resolution Medical Image Synthesis with Rectified Flow and Region-specific Contrastive Loss](https://arxiv.org/abs/2508.05772)
*Can Zhao,Pengfei Guo,Dong Yang,Yucheng Tang,Yufan He,Benjamin Simon,Mason Belue,Stephanie Harmon,Baris Turkbey,Daguang Xu*

Main category: cs.CV

TL;DR: MAISI-v2 是一个加速的 3D 医学图像合成框架，解决了现有方法的局限性，实现了 SOTA 的图像质量和高倍加速。


<details>
  <summary>Details</summary>
Motivation: 现有的医学图像合成方法存在泛化性有限、推理速度慢和与输入条件对齐性弱等问题。MAISI-v2 旨在解决这些问题。

Method: MAISI-v2 是一个加速的 3D 医学图像合成框架，它集成了修正流来实现快速和高质量的生成。为了进一步提高条件保真度，引入了一种新颖的特定区域对比度损失。 

Result: MAISI-v2 在潜在扩散模型方面实现了 33 倍的加速，达到了 SOTA 的图像质量。下游分割实验表明，合成的图像可用于数据增强。

Conclusion: MAISI-v2 实现了 33 倍的加速，实现了 SOTA 的图像质量，并且可以用于数据增强。

Abstract: Medical image synthesis is an important topic for both clinical and research
applications. Recently, diffusion models have become a leading approach in this
area. Despite their strengths, many existing methods struggle with (1) limited
generalizability that only work for specific body regions or voxel spacings,
(2) slow inference, which is a common issue for diffusion models, and (3) weak
alignment with input conditions, which is a critical issue for medical imaging.
MAISI, a previously proposed framework, addresses generalizability issues but
still suffers from slow inference and limited condition consistency. In this
work, we present MAISI-v2, the first accelerated 3D medical image synthesis
framework that integrates rectified flow to enable fast and high quality
generation. To further enhance condition fidelity, we introduce a novel
region-specific contrastive loss to enhance the sensitivity to region of
interest. Our experiments show that MAISI-v2 can achieve SOTA image quality
with $33 \times$ acceleration for latent diffusion model. We also conducted a
downstream segmentation experiment to show that the synthetic images can be
used for data augmentation. We release our code, training details, model
weights, and a GUI demo to facilitate reproducibility and promote further
development within the community.

</details>


### [9] [Few-Shot Deployment of Pretrained MRI Transformers in Brain Imaging Tasks](https://arxiv.org/abs/2508.05783)
*Mengyu Li,Guoyao Shen,Chad W. Farris,Xin Zhang*

Main category: cs.CV

TL;DR: 本研究提出了一种利用MAE预训练Transformer的少样本学习框架，用于解决医学成像中数据稀缺的问题。该框架在分类和分割任务上均表现出色，尤其适用于资源有限的临床环境。


<details>
  <summary>Details</summary>
Motivation: 尽管基于Transformer的机器学习在医学成像领域展现出巨大潜力，但标注数据的稀缺性限制了其在现实世界中的应用。

Method: 本研究提出了一种实用的框架，用于预训练的MRI Transformer在多种脑成像任务中的少样本部署。利用掩码自编码器（MAE）预训练策略，在大规模、多队列脑部MRI数据集（包含超过3100万张切片）上进行预训练，获得了具有良好泛化性的潜在表示。对于分类等高层任务，冻结的MAE编码器结合轻量级线性头部，在监督信号极少的情况下，在MRI序列识别方面达到了最先进的准确率。对于分割等低层任务，提出了MAE-FUnet混合架构，融合了多尺度CNN特征和预训练的MAE嵌入。

Result: MAE-FUnet模型在数据受限条件下，在颅骨剥离和多类解剖分割任务中，持续优于其他强大的基线模型。冻结的MAE编码器结合轻量级线性头部在MRI序列识别任务中取得了最先进的准确率。

Conclusion: 该框架在数据稀疏的情况下，能够实现高效、稳定和可扩展的少样本学习，适用于低资源临床环境和神经影像学应用。

Abstract: Machine learning using transformers has shown great potential in medical
imaging, but its real-world applicability remains limited due to the scarcity
of annotated data. In this study, we propose a practical framework for the
few-shot deployment of pretrained MRI transformers in diverse brain imaging
tasks. By utilizing the Masked Autoencoder (MAE) pretraining strategy on a
large-scale, multi-cohort brain MRI dataset comprising over 31 million slices,
we obtain highly transferable latent representations that generalize well
across tasks and datasets. For high-level tasks such as classification, a
frozen MAE encoder combined with a lightweight linear head achieves
state-of-the-art accuracy in MRI sequence identification with minimal
supervision. For low-level tasks such as segmentation, we propose MAE-FUnet, a
hybrid architecture that fuses multiscale CNN features with pretrained MAE
embeddings. This model consistently outperforms other strong baselines in both
skull stripping and multi-class anatomical segmentation under data-limited
conditions. With extensive quantitative and qualitative evaluations, our
framework demonstrates efficiency, stability, and scalability, suggesting its
suitability for low-resource clinical environments and broader neuroimaging
applications.

</details>


### [10] [Optimization-Free Style Transfer for 3D Gaussian Splats](https://arxiv.org/abs/2508.05813)
*Raphael Du Sablon,David Hart*

Main category: cs.CV

TL;DR: A new method stylizes 3D Gaussian splats quickly and easily by creating a graph on their surface, avoiding complex training or rebuilding steps.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of previous 3D Gaussian splat style transfer methods that require reconstruction or fine-tuning, and to enable fast stylization without additional training or optimization.

Method: A reconstruction- and optimization-free approach using a graph structure across the implicit surface of the splat representation, with a feed-forward, surface-based stylization method interpolated back to individual splats.

Result: The method allows any style image and 3D Gaussian splat to be used, achieving stylization speeds under 2 minutes on consumer-grade hardware, with demonstrated quality results.

Conclusion: The proposed method achieves fast stylization of 3D Gaussian splats without reconstruction or optimization, using a graph structure on the implicit surface and a feed-forward, surface-based stylization method.

Abstract: The task of style transfer for 3D Gaussian splats has been explored in many
previous works, but these require reconstructing or fine-tuning the splat while
incorporating style information or optimizing a feature extraction network on
the splat representation. We propose a reconstruction- and optimization-free
approach to stylizing 3D Gaussian splats. This is done by generating a graph
structure across the implicit surface of the splat representation. A
feed-forward, surface-based stylization method is then used and interpolated
back to the individual splats in the scene. This allows for any style image and
3D Gaussian splat to be used without any additional training or optimization.
This also allows for fast stylization of splats, achieving speeds under 2
minutes even on consumer-grade hardware. We demonstrate the quality results
this approach achieves and compare to other 3D Gaussian splat style transfer
methods. Code is publicly available at
https://github.com/davidmhart/FastSplatStyler.

</details>


### [11] [MZEN: Multi-Zoom Enhanced NeRF for 3-D Reconstruction with Unknown Camera Poses](https://arxiv.org/abs/2508.05819)
*Jong-Ik Park,Carlee Joe-Wong,Gary K. Fedder*

Main category: cs.CV

TL;DR: MZEN 是首个能够原生处理多重放大图像集的 NeRF 框架，解决了现有 NeRF 在捕捉工业检测所需精细结构细节方面的局限性。它通过改进相机模型和姿态策略，实现了高精度和细节捕捉，适用于工厂环境。


<details>
  <summary>Details</summary>
Motivation: 现有的 NeRF 方法虽然在从具有未知相机位姿的多张 2D 图像进行 3D 重建方面表现出色，但在工业检测等场景下，例如在生产线上检测亚微米级缺陷或使用扫描电子显微镜分析芯片时，仍然缺乏对精细结构细节的捕捉能力。在这些场景中，传感器分辨率固定且计算预算有限，为了展现精细结构，需要加入放大图像；然而，这会破坏无姿态 NeRF 训练所依赖的多视图一致性。

Method: MZEN 通过 (i) 增强针孔相机模型，加入可学习的缩放因子来缩放焦距，以及 (ii) 引入一种新颖的姿态策略：首先处理广角图像以建立全局度量框架，然后通过一种缩放一致的裁剪和匹配程序将变焦图像的姿态初始化到最近的广角对应图像，最后进行联合优化。

Result: MZEN 在八个前向场景（包括合成 TCAD 模型、微观结构的真实 SEM 图像以及 BLEFF 对象）上，一致地优于无姿态基线和高分辨率变体，其 PSNR 提高了 28%，SSIM 提高了 10%，LPIPS 降低了 222%。

Conclusion: MZEN 成功地将 NeRF 扩展到了实际的工厂环境，在保持全局准确性的同时，捕捉到了对工业检测至关重要的微米级细节。

Abstract: Neural Radiance Fields (NeRF) methods excel at 3D reconstruction from
multiple 2D images, even those taken with unknown camera poses. However, they
still miss the fine-detailed structures that matter in industrial inspection,
e.g., detecting sub-micron defects on a production line or analyzing chips with
Scanning Electron Microscopy (SEM). In these scenarios, the sensor resolution
is fixed and compute budgets are tight, so the only way to expose fine
structure is to add zoom-in images; yet, this breaks the multi-view consistency
that pose-free NeRF training relies on. We propose Multi-Zoom Enhanced NeRF
(MZEN), the first NeRF framework that natively handles multi-zoom image sets.
MZEN (i) augments the pin-hole camera model with an explicit, learnable zoom
scalar that scales the focal length, and (ii) introduces a novel pose strategy:
wide-field images are solved first to establish a global metric frame, and
zoom-in images are then pose-primed to the nearest wide-field counterpart via a
zoom-consistent crop-and-match procedure before joint refinement. Across eight
forward-facing scenes$\unicode{x2013}$synthetic TCAD models, real SEM of
micro-structures, and BLEFF objects$\unicode{x2013}$MZEN consistently
outperforms pose-free baselines and even high-resolution variants, boosting
PSNR by up to $28 \%$, SSIM by $10 \%$, and reducing LPIPS by up to $222 \%$.
MZEN, therefore, extends NeRF to real-world factory settings, preserving global
accuracy while capturing the micron-level details essential for industrial
inspection.

</details>


### [12] [TSMS-SAM2: Multi-scale Temporal Sampling Augmentation and Memory-Splitting Pruning for Promptable Video Object Segmentation and Tracking in Surgical Scenarios](https://arxiv.org/abs/2508.05829)
*Guoping Xu,Hua-Chieh Shao,You Zhang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Promptable video object segmentation and tracking (VOST) has seen significant
advances with the emergence of foundation models like Segment Anything Model 2
(SAM2); however, their application in surgical video analysis remains
challenging due to complex motion dynamics and the redundancy of memory that
impedes effective learning. In this work, we propose TSMS-SAM2, a novel
framework that enhances promptable VOST in surgical videos by addressing
challenges of rapid object motion and memory redundancy in SAM2. TSMS-SAM2
introduces two key strategies: multi-temporal-scale video sampling augmentation
to improve robustness against motion variability, and a memory splitting and
pruning mechanism that organizes and filters past frame features for more
efficient and accurate segmentation. Evaluated on EndoVis2017 and EndoVis2018
datasets, TSMS-SAM2 achieved the highest mean Dice scores of 95.24 and 86.73,
respectively, outperforming prior SAM-based and task-specific methods.
Extensive ablation studies confirm the effectiveness of multiscale temporal
augmentation and memory splitting, highlighting the framework's potential for
robust, efficient segmentation in complex surgical scenarios. Our source code
will be available at https://github.com/apple1986/TSMS-SAM2.

</details>


### [13] [Temporal Cluster Assignment for Efficient Real-Time Video Segmentation](https://arxiv.org/abs/2508.05851)
*Ka-Wai Yung,Felix J. S. Bragman,Jialang Xu,Imanol Luengo,Danail Stoyanov,Evangelos B. Mazomenos*

Main category: cs.CV

TL;DR: Swin Transformer 在视频分割中存在计算成本高的问题。本文提出了一种名为 TCA 的策略，通过利用时间信息来优化 token 聚类，从而在不损失准确性的情况下降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的 Swin Transformer 在视频分割中计算成本高，尤其是在较大的模型中。虽然一些 token 约减方法被提出，但它们无法很好地应用于 Swin Transformer 的窗口注意力机制。此外，用于图像分割的训练无关 token 聚类方法未能利用时间冗余。

Method: 提出了一种名为时间聚类分配（TCA）的策略，该策略通过利用跨帧的时间相干性来优化 token 聚类，以在分割任务中减少计算量并提高效率。

Result: TCA 策略在 YouTube-VIS 2019、YouTube-VIS 2021、OVIS 和一个私有的手术视频数据集上进行了广泛评估，结果表明 TCA 能够一致地提高现有基于聚类的方法的准确-速度权衡。

Conclusion: TCA 是一种轻量级、无需微调的策略，通过利用跨帧的时间相干性来增强 token 聚类，从而在提高准确性的同时显著降低计算成本，并且在自然视频和特定领域视频中都表现良好。

Abstract: Vision Transformers have substantially advanced the capabilities of
segmentation models across both image and video domains. Among them, the Swin
Transformer stands out for its ability to capture hierarchical, multi-scale
representations, making it a popular backbone for segmentation in videos.
However, despite its window-attention scheme, it still incurs a high
computational cost, especially in larger variants commonly used for dense
prediction in videos. This remains a major bottleneck for real-time,
resource-constrained applications. Whilst token reduction methods have been
proposed to alleviate this, the window-based attention mechanism of Swin
requires a fixed number of tokens per window, limiting the applicability of
conventional pruning techniques. Meanwhile, training-free token clustering
approaches have shown promise in image segmentation while maintaining window
consistency. Nevertheless, they fail to exploit temporal redundancy, missing a
key opportunity to further optimize video segmentation performance. We
introduce Temporal Cluster Assignment (TCA), a lightweight and effective,
fine-tuning-free strategy that enhances token clustering by leveraging temporal
coherence across frames. Instead of indiscriminately dropping redundant tokens,
TCA refines token clusters using temporal correlations, thereby retaining
fine-grained details while significantly reducing computation. Extensive
evaluations on YouTube-VIS 2019, YouTube-VIS 2021, OVIS, and a private surgical
video dataset show that TCA consistently boosts the accuracy-speed trade-off of
existing clustering-based methods. Our results demonstrate that TCA generalizes
competently across both natural and domain-specific videos.

</details>


### [14] [VISTA: Vision-Language Imitation of Situational Thinking and Attention for Human-Like Driver Focus in Dynamic Environments](https://arxiv.org/abs/2508.05852)
*Kaiser Hamid,Khandakar Ashrafi Akbar,Nade Liang*

Main category: cs.CV

TL;DR: 该研究提出了一种新的视觉-语言框架，利用自然语言和少样本学习来预测驾驶员的注意力转移，并在 BDD-A 数据集上通过微调 LLaVA 来实现，结果显示其在注意转移检测和可解释性方面优于通用模型。


<details>
  <summary>Details</summary>
Motivation: 大多数现有研究着重于在单一时间点估计注意力分配，通常使用静态 RGB 图像。

Method: 提出一个视觉-语言框架，利用少样本和零样本学习，通过自然语言模拟驾驶员注视的变化，并对 BDD-A 数据集的标题进行优化，然后对 LLaVA 进行微调，使视觉感知与以注意力为中心的场景理解保持一致。该方法集成了低级线索和高级上下文（如路线语义、风险预期）。

Result: 在注意力转移检测和可解释性方面，微调后的模型优于通用的视觉-语言模型（VLMs）。

Conclusion: 该方法首次尝试以自然语言生成驾驶员的视觉注意力分配和转移预测，为自动驾驶中的可解释人工智能提供了新的方向，并为下游任务（如行为预测、人机协作和多智能体协调）奠定了基础。

Abstract: Driver visual attention prediction is a critical task in autonomous driving
and human-computer interaction (HCI) research. Most prior studies focus on
estimating attention allocation at a single moment in time, typically using
static RGB images such as driving scene pictures. In this work, we propose a
vision-language framework that models the changing landscape of drivers' gaze
through natural language, using few-shot and zero-shot learning on single RGB
images. We curate and refine high-quality captions from the BDD-A dataset using
human-in-the-loop feedback, then fine-tune LLaVA to align visual perception
with attention-centric scene understanding. Our approach integrates both
low-level cues and top-down context (e.g., route semantics, risk anticipation),
enabling language-based descriptions of gaze behavior. We evaluate performance
across training regimes (few shot, and one-shot) and introduce domain-specific
metrics for semantic alignment and response diversity. Results show that our
fine-tuned model outperforms general-purpose VLMs in attention shift detection
and interpretability. To our knowledge, this is among the first attempts to
generate driver visual attention allocation and shifting predictions in natural
language, offering a new direction for explainable AI in autonomous driving.
Our approach provides a foundation for downstream tasks such as behavior
forecasting, human-AI teaming, and multi-agent coordination.

</details>


### [15] [Multi-view Gaze Target Estimation](https://arxiv.org/abs/2508.05857)
*Qiaomu Miao,Vivek Raju Golani,Jingyi Xu,Progga Paromita Dutta,Minh Hoai,Dimitris Samaras*

Main category: cs.CV

TL;DR: 本篇论文提出了一种利用多摄像头视图进行注视目标估计（GTE）的方法，通过整合多视图信息、头部信息聚合、不确定性注视选择和视差图场景注意力等模块，解决了单视图方法的局限性，显著提高了估计的准确性和鲁棒性，并提供了相应的数据集和代码。


<details>
  <summary>Details</summary>
Motivation: 该方法旨在解决现有单视图方法在处理人脸遮挡、目标不确定性和视野外目标等问题时面临的挑战，通过利用多个摄像头视图来提高注视目标估计（GTE）任务的准确性和扩展性。

Method: 本研究提出的方法整合了来自不同摄像头视图的信息，以提高准确性并扩大适用性。具体而言，该方法处理一对摄像头视图作为输入，包括一个头部信息聚合（HIA）模块，用于利用来自两个视图的头部信息进行更准确的注视估计；一个基于不确定性的注视选择（UGS）模块，用于识别最可靠的注视输出；以及一个基于视差图的场景注意力（ESA）模块，用于跨视图背景信息共享。

Result: 本研究提出的多视图方法在注视目标估计任务上显著优于单视图基线，并且能够实现单视图方法无法完成的仅利用另一摄像头图像估计注视目标的能力。此外，该论文还引入了一个用于开发和评估多视图GTE方法的多视图数据集。

Conclusion: 该方法显著优于单视图基线，尤其是在第二个摄像头能清晰看到人脸的情况下。此外，本研究提出的方法可以仅利用第二个摄像头中的人脸图像来估计第一个摄像头中的注视目标，这是单视图GTE方法所不具备的能力。

Abstract: This paper presents a method that utilizes multiple camera views for the gaze
target estimation (GTE) task. The approach integrates information from
different camera views to improve accuracy and expand applicability, addressing
limitations in existing single-view methods that face challenges such as face
occlusion, target ambiguity, and out-of-view targets. Our method processes a
pair of camera views as input, incorporating a Head Information Aggregation
(HIA) module for leveraging head information from both views for more accurate
gaze estimation, an Uncertainty-based Gaze Selection (UGS) for identifying the
most reliable gaze output, and an Epipolar-based Scene Attention (ESA) module
for cross-view background information sharing. This approach significantly
outperforms single-view baselines, especially when the second camera provides a
clear view of the person's face. Additionally, our method can estimate the gaze
target in the first view using the image of the person in the second view only,
a capability not possessed by single-view GTE methods. Furthermore, the paper
introduces a multi-view dataset for developing and evaluating multi-view GTE
methods. Data and code are available at
https://www3.cs.stonybrook.edu/~cvl/multiview_gte.html

</details>


### [16] [ETTA: Efficient Test-Time Adaptation for Vision-Language Models through Dynamic Embedding Updates](https://arxiv.org/abs/2508.05898)
*Hamidreza Dastmalchi,Aijun An,Ali cheraghian*

Main category: cs.CV

TL;DR: ETTA is a test-time adaptation method that improves VLM generalization under distribution shifts by using a Recursive Updating module to integrate all test samples and an Adaptive Ensemble module to optimize prompt selection, outperforming existing methods in accuracy and efficiency.


<details>
  <summary>Details</summary>
Motivation: Current cache-based TTA models store limited high-confidence samples, restricting the decision boundary and ignoring other incoming test data. ETTA aims to address this by integrating all incoming test samples for improved accuracy with minimal overhead.

Method: ETTA introduces a Recursive Updating module that integrates all incoming test samples, progressively refining the decision boundary, mimicking an unbounded cache. It also includes an Adaptive Ensemble module to reduce prompt dependency by dynamically selecting optimal prompts for each class. ETTA adaptively combines scores from both modules based on confidence levels.

Result: ETTA surpasses the state-of-the-art TTA models in computational complexity and accuracy.

Conclusion: ETTA surpasses the state-of-the-art TTA models in computational complexity and accuracy, setting a new standard for effective, efficient test-time adaptation.

Abstract: Pretrained vision-language models (VLMs) like CLIP show strong zero-shot
performance but struggle with generalization under distribution shifts.
Test-Time Adaptation (TTA) addresses this by adapting VLMs to unlabeled test
data in new domains. While some TTA methods rely on prompt-tuning,
training-free cache-based approaches are preferred for efficiency. However,
current cache-based TTA models store only a limited set of high-confidence
samples, restricting the decision boundary to these samples and ignoring the
influence of other incoming test data. To address this, we propose Efficient
Test-Time Adaptation (ETTA), introducing a Recursive Updating module that
integrates all incoming test samples, progressively refining the decision
boundary. This strategy mimics an unbounded cache, dynamically updating
contextual embeddings for improved accuracy with minimal memory and
computational overhead. ETTA also includes an Adaptive Ensemble module to
reduce prompt dependency in image-to-text scores by dynamically selecting
optimal prompts for each class. Furthermore, ETTA adaptively combines scores
from both modules based on confidence levels, leveraging their complementary
strengths. Extensive experiments on two benchmarks confirm that ETTA surpasses
the state-of-the-art TTA models in computational complexity and accuracy,
setting a new standard for effective, efficient test-time adaptation. The code
has been released at https://github.com/hamidreza-dastmalchi/ETTA.

</details>


### [17] [Robust Image Stitching with Optimal Plane](https://arxiv.org/abs/2508.05903)
*Lang Nie,Yuan Mei,Kang Liao,Yunqiu Xu,Chunyu Lin,Bin Xiao*

Main category: cs.CV

TL;DR: RopStitch是一个无监督的深度图像拼接框架，通过双分支架构和虚拟最优平面解决了鲁棒性和自然性的问题，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了在图像拼接中实现鲁棒性和自然性，同时解决内容对齐和结构保持之间的冲突。

Method: 提出了一种名为RopStitch的无监督深度图像拼接框架，该框架结合了内容感知通用先验的双分支结构（预训练分支提取语义不变表示，可学习分支提取细粒度判别性特征），并通过可控因子在相关层面进行融合，以实现跨不同真实场景的高度泛化性能。为了解决内容对齐和结构保持之间的冲突，提出虚拟最优平面概念，将问题建模为估计单应性分解系数，并设计了迭代系数预测器和最小语义失真约束来识别最优平面，通过双向将两个视图扭曲到最优平面来整合该方案。

Result: 在各种数据集上的大量实验表明，RopStitch显著优于现有方法，特别是在场景鲁棒性和内容自然度方面。

Conclusion: RopStitch在场景鲁棒性和内容自然度方面显著优于现有方法。

Abstract: We present \textit{RopStitch}, an unsupervised deep image stitching framework
with both robustness and naturalness. To ensure the robustness of
\textit{RopStitch}, we propose to incorporate the universal prior of content
perception into the image stitching model by a dual-branch architecture. It
separately captures coarse and fine features and integrates them to achieve
highly generalizable performance across diverse unseen real-world scenes.
Concretely, the dual-branch model consists of a pretrained branch to capture
semantically invariant representations and a learnable branch to extract
fine-grained discriminative features, which are then merged into a whole by a
controllable factor at the correlation level. Besides, considering that content
alignment and structural preservation are often contradictory to each other, we
propose a concept of virtual optimal planes to relieve this conflict. To this
end, we model this problem as a process of estimating homography decomposition
coefficients, and design an iterative coefficient predictor and minimal
semantic distortion constraint to identify the optimal plane. This scheme is
finally incorporated into \textit{RopStitch} by warping both views onto the
optimal plane bidirectionally. Extensive experiments across various datasets
demonstrate that \textit{RopStitch} significantly outperforms existing methods,
particularly in scene robustness and content naturalness. The code is available
at {\color{red}https://github.com/MmelodYy/RopStitch}.

</details>


### [18] [Neural Field Representations of Mobile Computational Photography](https://arxiv.org/abs/2508.05907)
*Ilya Chugunov*

Main category: cs.CV

TL;DR: 该论文提出了一种基于神经场的移动摄影数据处理方法，能够高效地进行深度估计、图层分离和图像拼接，性能优于现有技术，且无需复杂预处理或标记数据。


<details>
  <summary>Details</summary>
Motivation: 移动成像技术在过去二十年中发生了深刻的变革，手机已迅速超越所有其他形式的数码摄影。如今的手机不仅配备了激光深度测距、多焦点相机阵列和分像素传感器等多种成像技术，还集成了陀螺仪、加速计和磁力计等非视觉传感器。结合板载的图像和信号处理集成芯片，这使得手机成为一个多功能的便携式计算成像平台。与此同时，近年来出现的神经场（训练用于将连续空间输入坐标映射到输出信号的小型神经网络）能够在没有像素数组或点云等显式数据表示的情况下重建复杂场景。因此，本文旨在探索如何利用神经场模型来处理移动摄影数据，以实现更高效、更强大的成像应用。

Method: 文中提出了一种利用神经场模型来处理移动摄影数据的方法，具体包括深度估计、图层分离和图像拼接等应用。该方法不依赖复杂的预处理步骤、标记的真实数据或机器学习先验知识，而是利用精心构建的、自正则化的模型，通过随机梯度下降直接拟合智能手机的原始测量数据来解决逆问题。

Result: 所提出的神经场模型能够紧凑地表示复杂的几何和光照效果，并可直接应用于深度估计、图层分离和图像拼接等任务。相较于现有技术，该方法在性能上有所超越，并且无需复杂的预处理、标记数据或机器学习先验知识。

Conclusion: 该论文展示了精心设计的神经场模型如何紧凑地表示复杂的几何和光照效果，从而可以直接从野外收集的移动摄影数据中实现深度估计、图层分离和图像拼接等应用。这些方法在不依赖复杂预处理步骤、标记的真实数据或机器学习先验知识的情况下，性能优于最先进的方法。相反，它们利用精心构建的、自正则化的模型，通过随机梯度下降直接拟合智能手机的原始测量数据来解决具有挑战性的逆问题。

Abstract: Over the past two decades, mobile imaging has experienced a profound
transformation, with cell phones rapidly eclipsing all other forms of digital
photography in popularity. Today's cell phones are equipped with a diverse
range of imaging technologies - laser depth ranging, multi-focal camera arrays,
and split-pixel sensors - alongside non-visual sensors such as gyroscopes,
accelerometers, and magnetometers. This, combined with on-board integrated
chips for image and signal processing, makes the cell phone a versatile
pocket-sized computational imaging platform. Parallel to this, we have seen in
recent years how neural fields - small neural networks trained to map
continuous spatial input coordinates to output signals - enable the
reconstruction of complex scenes without explicit data representations such as
pixel arrays or point clouds. In this thesis, I demonstrate how carefully
designed neural field models can compactly represent complex geometry and
lighting effects. Enabling applications such as depth estimation, layer
separation, and image stitching directly from collected in-the-wild mobile
photography data. These methods outperform state-of-the-art approaches without
relying on complex pre-processing steps, labeled ground truth data, or machine
learning priors. Instead, they leverage well-constructed, self-regularized
models that tackle challenging inverse problems through stochastic gradient
descent, fitting directly to raw measurements from a smartphone.

</details>


### [19] [Enhancing Construction Site Analysis and Understanding with 3D Segmentation](https://arxiv.org/abs/2508.05922)
*Sri Ramana Saketh Vasanthawada,Pengkun Liu,Pingbo Tang*

Main category: cs.CV

TL;DR: 本研究评估了SAM和Mask3D在建筑工地环境下的三维分割能力，发现在户外场景应用方面存在挑战，并呼吁开发更适应建筑工地特定需求的分割方法。


<details>
  <summary>Details</summary>
Motivation: 由于传统的现场监控方法效率低下且成本高昂，因此需要探索计算机视觉方法来提高效率和可扩展性。现有的数据采集方法主要集中在室内环境，在建筑工地的复杂、混乱和动态变化条件下表现不佳，因此有必要评估先进的三维分割技术在这些条件下的表现。

Method: 本研究采用了比较分析的方法，评估了SAM和Mask3D两种三维分割模型在真实建筑环境（包括室内和室外）中的适应性和性能。通过在具有挑战性的实际场景中进行测试，并与仅在室内数据集上训练的模型进行对比，来展示它们相对的有效性。

Result: 研究结果表明，SAM和Mask3D在应对建筑工地复杂多变的室内外条件时，在适应性和性能方面存在差异。该研究还突显了当前分割方法在缺乏针对户外场景的基准测试方面存在的不足，并强调了开发定制化分割工作流程以从建筑工地数据中提取可操作见解的必要性。

Conclusion: 本研究对SAM和Mask3D这两种先进的三维分割方法在室内外复杂建筑环境中的应用进行了评估，并强调了当前分割方法在户外场景基准测试缺失方面存在的不足。研究结果为开发更专业的分割工作流程提供了依据，以期从建筑工地数据中提取有价值的见解，从而推动更自动化、更精确的监控技术。

Abstract: Monitoring construction progress is crucial yet resource-intensive, prompting
the exploration of computer-vision-based methodologies for enhanced efficiency
and scalability. Traditional data acquisition methods, primarily focusing on
indoor environments, falter in construction site's complex, cluttered, and
dynamically changing conditions. This paper critically evaluates the
application of two advanced 3D segmentation methods, Segment Anything Model
(SAM) and Mask3D, in challenging outdoor and indoor conditions. Trained
initially on indoor datasets, both models' adaptability and performance are
assessed in real-world construction settings, highlighting the gap in current
segmentation approaches due to the absence of benchmarks for outdoor scenarios.
Through a comparative analysis, this study not only showcases the relative
effectiveness of SAM and Mask3D but also addresses the critical need for
tailored segmentation workflows capable of extracting actionable insights from
construction site data, thereby advancing the field towards more automated and
precise monitoring techniques.

</details>


### [20] [A 3DGS-Diffusion Self-Supervised Framework for Normal Estimation from a Single Image](https://arxiv.org/abs/2508.05950)
*Yanxing Liang,Yinghui Wang,Jinlong Yang,Wei Li*

Main category: cs.CV

TL;DR: SINGAD是一个创新的自监督框架，利用3D高斯泼溅和扩散模型从单张图像估计法线，解决了现有方法的局限性，实现了多视图一致性和无需密集标注，并在实验中取得了优于SOTA的性能。


<details>
  <summary>Details</summary>
Motivation: 解决单张图像估计法线时缺乏空间维度信息的问题，以及现有扩散模型依赖数据驱动的统计先验、忽略光-表面交互建模、存在多视图法线方向冲突、梯度不连续导致无法反向传播3D几何误差以及需要密集法线标注等挑战。

Method: 提出了一种名为SINGAD的新型自监督框架，利用3D高斯泼溅引导的扩散模型从单张图像估计法线。该框架集成了光照交互模型和可微分渲染的重投影策略，直接将3D几何误差转换为法线优化信号。具体而言，通过构建光照交互驱动的3DGS重参数化模型生成多尺度几何特征，并通过跨域特征融合模块在条件扩散模型中嵌入几何先验来约束法线生成，同时利用可微分3D重投影损失进行自监督优化。

Result: SINGAD框架能够解决多视图几何不一致和数据依赖性问题，并通过Google Scanned Objects数据集的量化评估证明其性能优于现有最先进的方法。

Conclusion: SINGAD通过结合物理驱动的光照交互模型和基于可微分渲染的重投影策略，解决了多视图几何不一致和数据依赖性问题，并在Google Scanned Objects数据集的量化评估中优于现有方法。

Abstract: The lack of spatial dimensional information remains a challenge in normal
estimation from a single image. Recent diffusion-based methods have
demonstrated significant potential in 2D-to-3D implicit mapping, they rely on
data-driven statistical priors and miss the explicit modeling of light-surface
interaction, leading to multi-view normal direction conflicts. Moreover, the
discrete sampling mechanism of diffusion models causes gradient discontinuity
in differentiable rendering reconstruction modules, preventing 3D geometric
errors from being backpropagated to the normal generation network, thereby
forcing existing methods to depend on dense normal annotations. This paper
proposes SINGAD, a novel Self-supervised framework from a single Image for
Normal estimation via 3D GAussian splatting guided Diffusion. By integrating
physics-driven light-interaction modeling and a differentiable rendering-based
reprojection strategy, our framework directly converts 3D geometric errors into
normal optimization signals, solving the challenges of multi-view geometric
inconsistency and data dependency. Specifically, the framework constructs a
light-interaction-driven 3DGS reparameterization model to generate multi-scale
geometric features consistent with light transport principles, ensuring
multi-view normal consistency. A cross-domain feature fusion module is designed
within a conditional diffusion model, embedding geometric priors to constrain
normal generation while maintaining accurate geometric error propagation.
Furthermore, a differentiable 3D reprojection loss strategy is introduced for
self-supervised optimization that minimizes geometric error between the
reconstructed and input image, eliminating dependence on annotated normal
datasets. Quantitative evaluations on the Google Scanned Objects dataset
demonstrate that our method outperforms state-of-the-art approaches across
multiple metrics.

</details>


### [21] [Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents](https://arxiv.org/abs/2508.05954)
*Han Lin,Jaemin Cho,Amir Zadeh,Chuan Li,Mohit Bansal*

Main category: cs.CV

TL;DR: Bifrost-1是一个创新的框架，它将预训练的多模态LLM与扩散模型相结合，使用补丁级CLIP图像嵌入作为桥梁，实现了高效且高质量的图像生成，同时保留了LLM强大的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在将高保真视觉合成能力集成到大型语言模型（LLM）中时，通常面临昂贵的训练成本，因为LLM在预训练期间未接触过图像表示。本研究旨在解决这一问题。

Method: Bifrost-1框架使用预训练的多模态LLM和扩散模型，通过补丁级CLIP图像嵌入作为潜在变量进行连接。它通过轻量级地调整ControlNet来集成这些嵌入，并为LLM配备了一个视觉生成分支，该分支从原始LLM参数初始化，用于预测补丁级图像嵌入。

Result: Bifrost-1在视觉保真度和多模态理解方面取得了与先前方法相当或更优的性能，同时训练计算量显著降低。消融研究也证明了其设计选择的有效性。

Conclusion: Bifrost-1框架通过集成预训练的多模态LLM和扩散模型，并利用图像嵌入作为潜在变量，实现了高保真可控图像生成，同时显著提高了训练效率。实验证明，Bifrost-1在视觉保真度和多模态理解方面达到了与先前方法相当或更优的性能，且训练计算量大大降低。

Abstract: There is growing interest in integrating high-fidelity visual synthesis
capabilities into large language models (LLMs) without compromising their
strong reasoning capabilities. Existing methods that directly train LLMs or
bridge LLMs and diffusion models usually suffer from costly training since the
backbone LLMs have not seen image representations during pretraining. We
present Bifrost-1, a unified framework that bridges pretrained multimodal LLMs
(MLLMs) and diffusion models using patch-level CLIP image embeddings as latent
variables, which are natively aligned with the MLLM's CLIP visual encoder.
These patch-level image embeddings are integrated into the diffusion model with
a lightweight adaptation of its ControlNet. To retain the original multimodal
reasoning capabilities of MLLMs, we equip the MLLM with a visual generation
branch initialized from the original MLLM parameters when predicting the
patch-level image embeddings. By seamlessly integrating pretrained MLLMs and
diffusion models with patch-level CLIP latents, our framework enables
high-fidelity controllable image generation with significant training
efficiency. Our experiments demonstrate that Bifrost-1 achieves comparable or
better performance than previous methods in terms of visual fidelity and
multimodal understanding, with substantially lower compute during training. We
also provide comprehensive ablation studies showing the effectiveness of our
design choices.

</details>


### [22] [PASG: A Closed-Loop Framework for Automated Geometric Primitive Extraction and Semantic Anchoring in Robotic Manipulation](https://arxiv.org/abs/2508.05976)
*Zhihao Zhu,Yifan Zheng,Siyu Pan,Yaohui Jin,Yao Mu*

Main category: cs.CV

TL;DR: PASG框架通过自动提取几何原始特征并利用VLM进行语义锚定，解决了机器人操作中语义与几何的鸿沟，提高了理解的精细度和任务表现。


<details>
  <summary>Details</summary>
Motivation: 解决了机器人操作中高级任务语义与低级几何特征之间碎片化的问题，以及现有VLM在语义接地、动态语义-能力关系捕捉方面的局限性。

Method: 提出了一种名为PASG（Primitive-Aware Semantic Grounding）的闭环框架，该框架包含自动原始特征提取、VLM驱动的语义锚定，并构建了一个空间-语义推理基准和微调的VLM（Qwen2.5VL-PA）。

Result: PASG在实际机器人操作任务中展现了有效性，跨越了多样化场景，在细粒度的语义-能力理解方面取得了与手动标注相媲美的性能。

Conclusion: PASG框架实现了机器人操作中几何原始特征与任务语义的统一，能够实现细粒度的语义-能力理解，并且在实际机器人操作任务中表现优异，性能可媲美手动标注。

Abstract: The fragmentation between high-level task semantics and low-level geometric
features remains a persistent challenge in robotic manipulation. While
vision-language models (VLMs) have shown promise in generating affordance-aware
visual representations, the lack of semantic grounding in canonical spaces and
reliance on manual annotations severely limit their ability to capture dynamic
semantic-affordance relationships. To address these, we propose Primitive-Aware
Semantic Grounding (PASG), a closed-loop framework that introduces: (1)
Automatic primitive extraction through geometric feature aggregation, enabling
cross-category detection of keypoints and axes; (2) VLM-driven semantic
anchoring that dynamically couples geometric primitives with functional
affordances and task-relevant description; (3) A spatial-semantic reasoning
benchmark and a fine-tuned VLM (Qwen2.5VL-PA). We demonstrate PASG's
effectiveness in practical robotic manipulation tasks across diverse scenarios,
achieving performance comparable to manual annotations. PASG achieves a
finer-grained semantic-affordance understanding of objects, establishing a
unified paradigm for bridging geometric primitives with task semantics in
robotic manipulation.

</details>


### [23] [AnimateScene: Camera-controllable Animation in Any Scene](https://arxiv.org/abs/2508.05982)
*Qingyang Liu,Bingjie Gao,Weiheng Huang,Jun Zhang,Zhongqian Sun,Yang Wei,Zelin Peng,Qianli Ma,Shuai Yang,Zhaohe Liao,Haonan Zhao,Li Niu*

Main category: cs.CV

TL;DR: AnimateScene unifies 3D scene reconstruction and 4D human animation by accurately placing humans, aligning their style with the scene, and enabling dynamic camera movements for realistic and engaging videos.


<details>
  <summary>Details</summary>
Motivation: Integrating 3D scenes with 4D human animation is challenging due to difficulties in accurate human placement, avoiding interpenetration, aligning human and background style/lighting, and incorporating camera movements for visually engaging results.

Method: AnimateScene employs a three-pronged approach: 1. An accurate placement module for correct human positioning and interpenetration avoidance. 2. A training-free style alignment method to match human representation with background lighting and style. 3. A joint post-reconstruction method for humans and scenes that incorporates camera trajectories.

Result: Extensive experiments demonstrate that AnimateScene generates dynamic scene videos with high geometric detail and spatiotemporal coherence, effectively handling various camera and action combinations.

Conclusion: AnimateScene provides a unified framework that successfully addresses the challenges of integrating 3D scenes with 4D human animations. It generates dynamic scene videos with high geometric detail and spatiotemporal coherence, adaptable to various camera and action combinations.

Abstract: 3D scene reconstruction and 4D human animation have seen rapid progress and
broad adoption in recent years. However, seamlessly integrating reconstructed
scenes with 4D human animation to produce visually engaging results remains
challenging. One key difficulty lies in placing the human at the correct
location and scale within the scene while avoiding unrealistic
interpenetration. Another challenge is that the human and the background may
exhibit different lighting and style, leading to unrealistic composites. In
addition, appealing character motion videos are often accompanied by camera
movements, which means that the viewpoints need to be reconstructed along a
specified trajectory. We present AnimateScene, which addresses the above issues
in a unified framework. First, we design an accurate placement module that
automatically determines a plausible 3D position for the human and prevents any
interpenetration within the scene during motion. Second, we propose a
training-free style alignment method that adapts the 4D human representation to
match the background's lighting and style, achieving coherent visual
integration. Finally, we design a joint post-reconstruction method for both the
4D human and the 3D scene that allows camera trajectories to be inserted,
enabling the final rendered video to feature visually appealing camera
movements. Extensive experiments show that AnimateScene generates dynamic scene
videos with high geometric detail and spatiotemporal coherence across various
camera and action combinations.

</details>


### [24] [ETA: Energy-based Test-time Adaptation for Depth Completion](https://arxiv.org/abs/2508.05989)
*Younjoon Chung,Hyoungseob Park,Patrick Rim,Xiaoran Zhang,Jihe He,Ziyao Zeng,Safa Cicek,Byung-Woo Hong,James S. Duncan,Alex Wong*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We propose a method for test-time adaptation of pretrained depth completion
models. Depth completion models, trained on some ``source'' data, often predict
erroneous outputs when transferred to ``target'' data captured in novel
environmental conditions due to a covariate shift. The crux of our method lies
in quantifying the likelihood of depth predictions belonging to the source data
distribution. The challenge is in the lack of access to out-of-distribution
(target) data prior to deployment. Hence, rather than making assumptions
regarding the target distribution, we utilize adversarial perturbations as a
mechanism to explore the data space. This enables us to train an energy model
that scores local regions of depth predictions as in- or out-of-distribution.
We update the parameters of pretrained depth completion models at test time to
minimize energy, effectively aligning test-time predictions to those of the
source distribution. We call our method ``Energy-based Test-time Adaptation'',
or ETA for short. We evaluate our method across three indoor and three outdoor
datasets, where ETA improve over the previous state-of-the-art method by an
average of 6.94% for outdoors and 10.23% for indoors. Project Page:
https://fuzzythecat.github.io/eta.

</details>


### [25] [Fast Motion Estimation and Context-Aware Refinement for Efficient Bayer-Domain Video Vision](https://arxiv.org/abs/2508.05990)
*Haichao Wang,Xinyue Xi,Jiangtao Wen,Yuxing Han*

Main category: cs.CV

TL;DR: 提出了一种新的视频计算机视觉系统，通过移除ISP、使用快速块匹配运动估计和上下文感知块细化网络，并结合帧选择策略，在保证性能的同时实现了显著的加速。


<details>
  <summary>Details</summary>
Motivation: 现有视频计算机视觉系统效率低下，主要由于视频中存在高时间冗余，且现有方法未能充分减少时间冗余并忽略了前端计算开销。

Method: 1. 移除图像信号处理器，直接将Bayer格式数据输入视频计算机视觉模型，以节省前端计算开销。
2. 提出一种基于块匹配的快速运动估计算法，并辅以运动矢量（MV）细化模块，以替代光流模型和视频编码器。
3. 引入上下文感知块细化网络，用于修正存在较大误差的区域。
4. 采用帧选择策略，以平衡精度和效率。

Result: 所提出的系统实现了显著的加速，并且在多个视频计算机视觉任务上进行了验证。

Conclusion: 实验结果表明，所提出的方法在多个视频计算机视觉任务上实现了显著的加速，同时只带来了轻微的性能损失。

Abstract: The efficiency of video computer vision system remains a challenging task due
to the high temporal redundancy inside a video. Existing works have been
proposed for efficient vision computer vision. However, they do not fully
reduce the temporal redundancy and neglect the front end computation overhead.
In this paper, we propose an efficient video computer vision system. First,
image signal processor is removed and Bayer-format data is directly fed into
video computer vision models, thus saving the front end computation. Second,
instead of optical flow models and video codecs, a fast block matching-based
motion estimation algorithm is proposed specifically for efficient video
computer vision, with a MV refinement module. To correct the error,
context-aware block refinement network is introduced to refine regions with
large error. To further balance the accuracy and efficiency, a frame selection
strategy is employed. Experiments on multiple video computer vision tasks
demonstrate that our method achieves significant acceleration with slight
performance loss.

</details>


### [26] [ECMF: Enhanced Cross-Modal Fusion for Multimodal Emotion Recognition in MER-SEMI Challenge](https://arxiv.org/abs/2508.05991)
*Juewen Hu,Yexin Li,Jiulin Li,Shuo Chen,Pring Wong*

Main category: cs.CV

TL;DR: 为了解决数据稀缺问题，该研究提出了一种多模态情绪识别框架，利用大型预训练模型提取特征，并采用特殊的融合策略和标签优化方法，在MER2025-SEMI数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 为了解决数据稀疏性问题，并通过增强人机交互来推动情绪识别的发展。

Method: 提出了一种新颖的多模态情绪识别框架，利用大型预训练模型提取视觉、听觉和文本模态的特征。视觉模态采用双分支编码器，捕捉全局和局部面部特征；文本模态采用上下文丰富的方法，利用大型语言模型增强文本中的情绪线索。融合策略包括自注意力机制和残差连接，用于动态加权和保留原始表示。此外，还采用多源标注策略优化了训练集的标签。

Result: 该框架在MER2025-SEMI数据集上实现了87.49%的加权F分数，显著优于官方基线（78.63%）。

Conclusion: 该方法在MER2025-SEMI数据集上取得了显著的性能提升，加权F分数从78.63%提高到87.49%，验证了所提出框架的有效性。

Abstract: Emotion recognition plays a vital role in enhancing human-computer
interaction. In this study, we tackle the MER-SEMI challenge of the MER2025
competition by proposing a novel multimodal emotion recognition framework. To
address the issue of data scarcity, we leverage large-scale pre-trained models
to extract informative features from visual, audio, and textual modalities.
Specifically, for the visual modality, we design a dual-branch visual encoder
that captures both global frame-level features and localized facial
representations. For the textual modality, we introduce a context-enriched
method that employs large language models to enrich emotional cues within the
input text. To effectively integrate these multimodal features, we propose a
fusion strategy comprising two key components, i.e., self-attention mechanisms
for dynamic modality weighting, and residual connections to preserve original
representations. Beyond architectural design, we further refine noisy labels in
the training set by a multi-source labeling strategy. Our approach achieves a
substantial performance improvement over the official baseline on the
MER2025-SEMI dataset, attaining a weighted F-score of 87.49% compared to
78.63%, thereby validating the effectiveness of the proposed framework.

</details>


### [27] [EvoMakeup: High-Fidelity and Controllable Makeup Editing with MakeupQuad](https://arxiv.org/abs/2508.05994)
*Huadong Wu,Yi Fu,Yunhao Li,Yuan Gao,Kang Du*

Main category: cs.CV

TL;DR: 提出了一种名为 EvoMakeup 的新方法和 MakeupQuad 数据集，用于解决现有面部化妆编辑方法的不足。EvoMakeup 通过多阶段蒸馏和迭代改进，实现了高质量、可控的妆容编辑，并在真实世界数据上取得了优于先前方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的面部化妆编辑方法由于缺乏结构化的配对数据，常常产生妆容细节粗糙、难以同时保留身份和妆容保真度的低质量结果。

Method: 提出了一种名为 EvoMakeup 的统一训练框架，该框架通过多阶段蒸馏来减轻图像退化，从而能够迭代地改进数据和模型质量。引入了一个名为 MakeupQuad 的大规模、高质量数据集，其中包含无妆面孔、参考妆容、编辑结果和文本妆容描述。

Result: EvoMakeup 在真实世界基准测试中表现优于先前方法，实现了高保真度的妆容编辑，并能有效保留身份信息。

Conclusion: EvoMakeup 框架在真实世界基准测试中表现优于先前方法，实现了高保真度、可控的多任务妆容编辑，有效平衡了妆容保真度和身份保留。

Abstract: Facial makeup editing aims to realistically transfer makeup from a reference
to a target face. Existing methods often produce low-quality results with
coarse makeup details and struggle to preserve both identity and makeup
fidelity, mainly due to the lack of structured paired data -- where source and
result share identity, and reference and result share identical makeup. To
address this, we introduce MakeupQuad, a large-scale, high-quality dataset with
non-makeup faces, references, edited results, and textual makeup descriptions.
Building on this, we propose EvoMakeup, a unified training framework that
mitigates image degradation during multi-stage distillation, enabling iterative
improvement of both data and model quality. Although trained solely on
synthetic data, EvoMakeup generalizes well and outperforms prior methods on
real-world benchmarks. It supports high-fidelity, controllable, multi-task
makeup editing -- including full-face and partial reference-based editing, as
well as text-driven makeup editing -- within a single model. Experimental
results demonstrate that our method achieves superior makeup fidelity and
identity preservation, effectively balancing both aspects. Code and dataset
will be released upon acceptance.

</details>


### [28] [MathReal: We Keep It Real! A Real Scene Benchmark for Evaluating Math Reasoning in Multimodal Large Language Models](https://arxiv.org/abs/2508.06009)
*Jun Feng,Zixin Wang,Zhentao Zhang,Yue Guo,Zhihan Zhou,Xiuyi Chen,Zhenyang Li,Dawei Yin*

Main category: cs.CV

TL;DR: 由于现有基准测试未能充分模拟真实世界K-12教育用户的手持设备图像输入，本研究提出了MathReal数据集，包含2000个包含数学问题的真实场景图像。实验评估了现有MLLM在这些真实场景下的表现，发现其能力受到显著影响，并对模型的错误模式进行了分析，为未来的模型改进提供了见解。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要使用清晰或处理过的多模态输入，未能反映真实K-12教育用户通过手机拍摄的图像输入。

Method: 构建了一个名为MathReal的数据集，包含2000个真实世界K-12教育场景下用手机拍摄的数学问题图像。对图像进行了详细的分类（包括图像质量、视角和无关内容等14个子类），并涵盖了五种核心知识能力、三种问题类型和三个难度级别。设计了六种实验设置来评估现有MLLM的性能。

Result: 实验结果表明，现有MLLM在真实教育场景下的解决问题能力面临严峻挑战，论文深入分析了模型的表现和错误模式，揭示了模型在识别、理解和推理方面的能力，并指出了未来改进的方向。

Conclusion: 现有的多模态大语言模型在真实教育场景下解决数学问题的能力受到显著挑战。通过分析其在图像质量下降、视角变化和无关内容干扰等方面的表现，论文为未来改进模型在真实世界数学推理能力方面提供了方向。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable
capabilities in visual mathematical reasoning across various existing
benchmarks. However, these benchmarks are predominantly based on clean or
processed multimodal inputs, without incorporating the images provided by
real-world Kindergarten through 12th grade (K-12) educational users. To address
this gap, we introduce MathReal, a meticulously curated dataset comprising
2,000 mathematical questions with images captured by handheld mobile devices in
authentic scenarios. Each question is an image, containing the question text
and visual element. We systematically classify the real images into three
primary categories: image quality degradation, perspective variation, and
irrelevant content interference, which are further delineated into 14
subcategories. Additionally, MathReal spans five core knowledge and ability
categories, which encompass three question types and are divided into three
difficulty levels. To comprehensively evaluate the multimodal mathematical
reasoning abilities of state-of-the-art MLLMs in real-world scenarios, we
design six experimental settings that enable a systematic analysis of their
performance. Through extensive experimentation, we find that the
problem-solving abilities of existing MLLMs are significantly challenged in
realistic educational contexts. Based on this, we conduct a thorough analysis
of their performance and error patterns, providing insights into their
recognition, comprehension, and reasoning capabilities, and outlining
directions for future improvements. Data and code:
https://github.com/junfeng0288/MathReal.

</details>


### [29] [ExploreGS: Explorable 3D Scene Reconstruction with Virtual Camera Samplings and Diffusion Priors](https://arxiv.org/abs/2508.06014)
*Minsu Kim,Subin Jeon,In Cho,Mijin Yoo,Seon Joo Kim*

Main category: cs.CV

TL;DR: Enhance 3D Gaussian Splatting by generating more training views with smart camera placement and diffusion models to achieve artifact-free rendering from any viewpoint.


<details>
  <summary>Details</summary>
Motivation: Existing 3DGS methods struggle with artifacts and missing regions when rendering from viewpoints deviating from the training trajectory, limiting seamless scene exploration.

Method: A 3DGS-based pipeline that generates additional training views using an information-gain-driven virtual camera placement strategy and refines rendered results with video diffusion priors. Fine-tuning 3D Gaussians with these enhanced views improves reconstruction quality.

Result: Experiments on the Wild-Explore benchmark demonstrate that the proposed approach outperforms existing 3DGS-based methods, enabling high-quality, artifact-free rendering from arbitrary viewpoints.

Conclusion: The proposed 3DGS-based pipeline with enhanced training views and a novel virtual camera placement strategy significantly improves reconstruction quality and enables high-quality, artifact-free rendering from arbitrary viewpoints, outperforming existing methods.

Abstract: Recent advances in novel view synthesis (NVS) have enabled real-time
rendering with 3D Gaussian Splatting (3DGS). However, existing methods struggle
with artifacts and missing regions when rendering from viewpoints that deviate
from the training trajectory, limiting seamless scene exploration. To address
this, we propose a 3DGS-based pipeline that generates additional training views
to enhance reconstruction. We introduce an information-gain-driven virtual
camera placement strategy to maximize scene coverage, followed by video
diffusion priors to refine rendered results. Fine-tuning 3D Gaussians with
these enhanced views significantly improves reconstruction quality. To evaluate
our method, we present Wild-Explore, a benchmark designed for challenging scene
exploration. Experiments demonstrate that our approach outperforms existing
3DGS-based methods, enabling high-quality, artifact-free rendering from
arbitrary viewpoints.
  https://exploregs.github.io

</details>


### [30] [Improved Sub-Visible Particle Classification in Flow Imaging Microscopy via Generative AI-Based Image Synthesis](https://arxiv.org/abs/2508.06021)
*Utku Ozbulak,Michaela Cohrs,Hristo L. Svilenov,Joris Vankerschaver,Wesley De Neve*

Main category: cs.CV

TL;DR: 利用扩散模型生成图像解决数据不平衡问题，提升颗粒分类性能。


<details>
  <summary>Details</summary>
Motivation: 针对流成像显微镜结合深度学习在颗粒识别中遇到的数据稀疏和类别不平衡的挑战，特别是对于数量较少的颗粒类型（如硅油和气泡），传统的分类方法效果不佳。

Method: 采用先进的扩散模型生成高保真度图像，以扩充训练数据集，解决亚可见颗粒分析中数据不平衡的问题，特别是针对数量稀少的颗粒类型（如硅油和气泡）。

Result: 通过在包含50万个蛋白质颗粒图像的验证集上进行大规模实验，证明了使用扩散模型生成图像来训练数据集可以提高分类性能，且没有明显的负面影响。生成的样本在视觉质量和结构上与真实颗粒图像相似。

Conclusion: 本研究开发了一种基于扩散模型的生成方法，用于生成高保真度的亚可见颗粒图像，以解决数据不平衡问题，并有效提升了多类别分类器的性能。通过大规模实验验证了该方法的有效性，生成的样本在视觉质量和结构上与真实颗粒图像高度相似，且未带来明显缺点。研究团队已公开了扩散模型、训练好的分类器以及接口，以促进未来研究的开放性和可复现性。

Abstract: Sub-visible particle analysis using flow imaging microscopy combined with
deep learning has proven effective in identifying particle types, enabling the
distinction of harmless components such as silicone oil from protein particles.
However, the scarcity of available data and severe imbalance between particle
types within datasets remain substantial hurdles when applying multi-class
classifiers to such problems, often forcing researchers to rely on less
effective methods. The aforementioned issue is particularly challenging for
particle types that appear unintentionally and in lower numbers, such as
silicone oil and air bubbles, as opposed to protein particles, where obtaining
large numbers of images through controlled settings is comparatively
straightforward. In this work, we develop a state-of-the-art diffusion model to
address data imbalance by generating high-fidelity images that can augment
training datasets, enabling the effective training of multi-class deep neural
networks. We validate this approach by demonstrating that the generated samples
closely resemble real particle images in terms of visual quality and structure.
To assess the effectiveness of using diffusion-generated images in training
datasets, we conduct large-scale experiments on a validation dataset comprising
500,000 protein particle images and demonstrate that this approach improves
classification performance with no negligible downside. Finally, to promote
open research and reproducibility, we publicly release both our diffusion
models and the trained multi-class deep neural network classifiers, along with
a straightforward interface for easy integration into future studies, at
https://github.com/utkuozbulak/svp-generative-ai.

</details>


### [31] [Learning 3D Texture-Aware Representations for Parsing Diverse Human Clothing and Body Parts](https://arxiv.org/abs/2508.06032)
*Kiran Chhatre,Christopher Peters,Srikrishna Karanam*

Main category: cs.CV

TL;DR: Spectrum is a new network that uses a special diffusion model to better understand and label body parts and clothes in images, even with detailed or unusual clothing, outperforming previous methods.


<details>
  <summary>Details</summary>
Motivation: Existing human parsing methods suffer from fixed, broad mask categories that obscure fine-grained clothing types. While open-vocabulary segmentation approaches show promise, they often fail to distinguish diverse clothing or detailed body parts by treating entire humans as a single category. This work addresses this gap by proposing a unified network for detailed part-level parsing and instance-level grouping.

Method: Spectrum utilizes a repurposed Image-to-Texture (I2Tx) diffusion model, fine-tuned from a text-to-image model on 3D human texture maps, to extract internal features for human parsing. It generates semantically valid masks aligned with diverse clothing categories through prompt-guided grounding, enabling detailed segmentation of body parts and clothing for any number of humans in a scene.

Result: Extensive cross-dataset experiments demonstrate that Spectrum consistently outperforms baseline methods in prompt-based segmentation. The network shows strong performance in segmenting body parts, clothing parts, unseen clothing categories, and full-body masks, highlighting its effectiveness and generalization capabilities.

Conclusion: Spectrum, a novel unified network, effectively addresses the limitations of existing human parsing methods by integrating part-level pixel parsing (body parts and clothing) and instance-level grouping. It leverages a repurposed Image-to-Texture (I2Tx) diffusion model to capture fine-grained details of diverse clothing and body parts, outperforming baseline methods in prompt-based segmentation across various datasets and tasks.

Abstract: Existing methods for human parsing into body parts and clothing often use
fixed mask categories with broad labels that obscure fine-grained clothing
types. Recent open-vocabulary segmentation approaches leverage pretrained
text-to-image (T2I) diffusion model features for strong zero-shot transfer, but
typically group entire humans into a single person category, failing to
distinguish diverse clothing or detailed body parts. To address this, we
propose Spectrum, a unified network for part-level pixel parsing (body parts
and clothing) and instance-level grouping. While diffusion-based
open-vocabulary models generalize well across tasks, their internal
representations are not specialized for detailed human parsing. We observe
that, unlike diffusion models with broad representations, image-driven 3D
texture generators maintain faithful correspondence to input images, enabling
stronger representations for parsing diverse clothing and body parts. Spectrum
introduces a novel repurposing of an Image-to-Texture (I2Tx) diffusion model --
obtained by fine-tuning a T2I model on 3D human texture maps -- for improved
alignment with body parts and clothing. From an input image, we extract
human-part internal features via the I2Tx diffusion model and generate
semantically valid masks aligned to diverse clothing categories through
prompt-guided grounding. Once trained, Spectrum produces semantic segmentation
maps for every visible body part and clothing category, ignoring standalone
garments or irrelevant objects, for any number of humans in the scene. We
conduct extensive cross-dataset experiments -- separately assessing body parts,
clothing parts, unseen clothing categories, and full-body masks -- and
demonstrate that Spectrum consistently outperforms baseline methods in
prompt-based segmentation.

</details>


### [32] [GMF-Drive: Gated Mamba Fusion with Spatial-Aware BEV Representation for End-to-End Autonomous Driving](https://arxiv.org/abs/2508.06113)
*Jian Wang,Chaokang Jiang,Haitao Xu*

Main category: cs.CV

TL;DR: GMF-Drive使用几何增强的柱状LiDAR表示和基于Mamba的GM-Fusion架构，解决了Transformer在自动驾驶中的计算复杂度和空间先验问题，并在NAVSIM基准测试中取得了优于DiffusionDrive的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的扩散模型在端到端自动驾驶中虽然性能优越，但面临二次计算复杂度限制了高分辨率特征的使用，并且缺乏空间先验导致无法有效模拟BEV表示的固有结构。

Method: 提出了一种名为GMF-Drive的端到端框架，该框架包含两个主要创新：1. 使用几何增强的柱状格式替代基于直方图的LiDAR表示，以保留关键的3D几何细节。2. 引入了一种新颖的层级门控Mamba融合（GM-Fusion）架构，用高效、空间感知的状态空间模型（SSM）替代Transformer，该架构利用方向排序和自适应融合机制，以线性复杂度捕获长距离依赖关系，并尊重驾驶场景的空间特性。

Result: GMF-Drive在NAVSIM基准测试上取得了新的最先进性能，显著优于DiffusionDrive。消融研究验证了每个组件的有效性，表明特定任务的SSM在自动驾驶任务上可以超越通用的Transformer，无论是在性能还是效率方面。

Conclusion: GMF-Drive通过使用几何增强的柱状表示和新颖的GM-Fusion架构（基于Mamba）在NAVSIM基准测试中实现了新的最先进性能，显著优于DiffusionDrive，并证明了特定任务的SSM在性能和效率上优于通用Transformer。

Abstract: Diffusion-based models are redefining the state-of-the-art in end-to-end
autonomous driving, yet their performance is increasingly hampered by a
reliance on transformer-based fusion. These architectures face fundamental
limitations: quadratic computational complexity restricts the use of
high-resolution features, and a lack of spatial priors prevents them from
effectively modeling the inherent structure of Bird's Eye View (BEV)
representations. This paper introduces GMF-Drive (Gated Mamba Fusion for
Driving), an end-to-end framework that overcomes these challenges through two
principled innovations. First, we supersede the information-limited
histogram-based LiDAR representation with a geometrically-augmented pillar
format encoding shape descriptors and statistical features, preserving critical
3D geometric details. Second, we propose a novel hierarchical gated mamba
fusion (GM-Fusion) architecture that substitutes an expensive transformer with
a highly efficient, spatially-aware state-space model (SSM). Our core BEV-SSM
leverages directional sequencing and adaptive fusion mechanisms to capture
long-range dependencies with linear complexity, while explicitly respecting the
unique spatial properties of the driving scene. Extensive experiments on the
challenging NAVSIM benchmark demonstrate that GMF-Drive achieves a new
state-of-the-art performance, significantly outperforming DiffusionDrive.
Comprehensive ablation studies validate the efficacy of each component,
demonstrating that task-specific SSMs can surpass a general-purpose transformer
in both performance and efficiency for autonomous driving.

</details>


### [33] [InstantEdit: Text-Guided Few-Step Image Editing with Piecewise Rectified Flow](https://arxiv.org/abs/2508.06033)
*Yiming Gong,Zhen Zhu,Minjia Zhang*

Main category: cs.CV

TL;DR: InstantEdit is a fast and effective text-guided image editing method based on RectifiedFlow, improving upon existing techniques by preserving content and adhering to text prompts.


<details>
  <summary>Details</summary>
Motivation: To develop a fast text-guided image editing method that preserves critical content while closely following textual instructions, balancing editability with detail preservation and suppressing artifacts.

Method: InstantEdit utilizes the RectifiedFlow framework with a specialized inversion strategy (PerRFI), a novel regeneration method (Inversion Latent Injection), a Disentangled Prompt Guidance technique, and a Canny-conditioned ControlNet.

Result: InstantEdit demonstrates fast performance and achieves superior qualitative and quantitative results compared to existing few-step editing methods.

Conclusion: InstantEdit is a fast text-guided image editing method that achieves better qualitative and quantitative results compared to state-of-the-art few-step editing methods on the PIE image editing dataset.

Abstract: We propose a fast text-guided image editing method called InstantEdit based
on the RectifiedFlow framework, which is structured as a few-step editing
process that preserves critical content while following closely to textual
instructions. Our approach leverages the straight sampling trajectories of
RectifiedFlow by introducing a specialized inversion strategy called PerRFI. To
maintain consistent while editable results for RectifiedFlow model, we further
propose a novel regeneration method, Inversion Latent Injection, which
effectively reuses latent information obtained during inversion to facilitate
more coherent and detailed regeneration. Additionally, we propose a
Disentangled Prompt Guidance technique to balance editability with detail
preservation, and integrate a Canny-conditioned ControlNet to incorporate
structural cues and suppress artifacts. Evaluation on the PIE image editing
dataset demonstrates that InstantEdit is not only fast but also achieves better
qualitative and quantitative results compared to state-of-the-art few-step
editing methods.

</details>


### [34] [Graph-based Robot Localization Using a Graph Neural Network with a Floor Camera and a Feature Rich Industrial Floor](https://arxiv.org/abs/2508.06177)
*Dominik Brämer,Diana Kleingarn,Oliver Urbann*

Main category: cs.CV

TL;DR: 提出了一种利用地板特征的创新本地化框架，使用图卷积网络（GCN）和图表示，实现了比传统方法更准确、更高效的机器人本地化，并解决了复杂的机器人本地化问题。


<details>
  <summary>Details</summary>
Motivation: 准确的定位是机器人导航的一个基本挑战。传统方法，如基于 Lidar 或 QR 码的系统，在可扩展性和适应性方面存在固有的约束，尤其是在复杂环境中。

Method: 使用基于图的表示和图卷积网络（GCN）利用地板特征。

Result: 该方法使用图表示地板特征，与比较单个图像特征相比，可以更准确（0.64 厘米误差）更有效地进行机器人本地化。此外，该方法在每个帧中成功解决了被绑架的机器人问题，而无需复杂的过滤过程。

Conclusion: 该方法为机器人在各种环境中导航开辟了新的可能性。

Abstract: Accurate localization represents a fundamental challenge in
  robotic navigation. Traditional methodologies, such as Lidar or QR-code based
systems, suffer from inherent scalability and adaptability con straints,
particularly in complex environments. In this work, we propose
  an innovative localization framework that harnesses flooring characteris tics
by employing graph-based representations and Graph Convolutional
  Networks (GCNs). Our method uses graphs to represent floor features,
  which helps localize the robot more accurately (0.64cm error) and more
  efficiently than comparing individual image features. Additionally, this
  approach successfully addresses the kidnapped robot problem in every
  frame without requiring complex filtering processes. These advancements
  open up new possibilities for robotic navigation in diverse environments.

</details>


### [35] [More Is Better: A MoE-Based Emotion Recognition Framework with Human Preference Alignment](https://arxiv.org/abs/2508.06036)
*Jun Xie,Yingjian Zhu,Feng Chen,Zhenghao Zhang,Xiaohui Fan,Hongzhu Yi,Xinming Wang,Chen Yu,Yue Bi,Zhaoran Zhao,Xiongjun Guan,Zhepeng Wang*

Main category: cs.CV

TL;DR: 通过融合多种模态（包括VLMs和AU信息）并利用伪标签策略，本研究构建了一个强大的多专家混合情感识别系统，在MER2025竞赛中取得优异成绩。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在为MER2025情感识别挑战赛的半监督学习提供一个强大且全面的解决方案，特别是利用多种输入模态和未标记数据来提升情感识别的准确性。

Method: 本研究提出了一个多专家混合（MoE）框架，集成了包括大型视觉语言模型（VLMs）知识和时间动作单元（AU）信息在内的多种输入模态。研究采用了基于共识的伪标签策略来利用未标记数据，并通过多专家投票集成和基于规则的重新排序来优化预测。

Result: 在MER2025-SEMI挑战赛的测试集上，所提出的方法实现了0.8772的F1分数，位列第二。

Conclusion: 该研究提出的多专家混合（MoE）情感识别系统在MER2025-SEMI挑战赛的测试集上达到了0.8772的F1分数，取得了第二名的成绩。

Abstract: In this paper, we present our solution for the semi-supervised learning track
(MER-SEMI) in MER2025. We propose a comprehensive framework, grounded in the
principle that "more is better," to construct a robust Mixture of Experts (MoE)
emotion recognition system. Our approach integrates a diverse range of input
modalities as independent experts, including novel signals such as knowledge
from large Vision-Language Models (VLMs) and temporal Action Unit (AU)
information. To effectively utilize unlabeled data, we introduce a
consensus-based pseudo-labeling strategy, generating high-quality labels from
the agreement between a baseline model and Gemini, which are then used in a
two-stage training paradigm. Finally, we employ a multi-expert voting ensemble
combined with a rule-based re-ranking process to correct prediction bias and
better align the outputs with human preferences. Evaluated on the MER2025-SEMI
challenge dataset, our method achieves an F1-score of 0.8772 on the test set,
ranking 2nd in the track. Our code is available at
https://github.com/zhuyjan/MER2025-MRAC25.

</details>


### [36] [Depth Jitter: Seeing through the Depth](https://arxiv.org/abs/2508.06227)
*Md Sazidur Rahman,David Cabecinhas,Ricard Marxer*

Main category: cs.CV

TL;DR: Depth-Jitter 是一种新的深度感知增强技术，通过模拟深度变化来提高模型在各种深度条件下的稳定性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统的增强技术忽略了深度感知变换，限制了模型在真实世界深度变化下的鲁棒性。

Method: Depth-Jitter 通过应用自适应深度偏移，并以深度方差阈值作为指导，在保持结构完整性的同时生成合成深度扰动。

Result: 在 FathomNet 和 UTDAC2020 数据集上的评估表明，Depth-Jitter 在各种深度条件下能增强模型的稳定性。与 ColorJitter 等传统增强策略相比，Depth-Jitter 在模型稳定性方面表现更优，但绝对性能不一定总是领先。

Conclusion: Depth-Jitter 是一种新颖的基于深度感知的增强技术，通过模拟自然深度变化来提高模型的泛化能力和稳定性，尤其是在深度敏感的环境中。虽然它不一定总是能在绝对性能上超越传统方法，但它能稳定地提升模型的泛化能力。

Abstract: Depth information is essential in computer vision, particularly in underwater
imaging, robotics, and autonomous navigation. However, conventional
augmentation techniques overlook depth aware transformations, limiting model
robustness in real world depth variations. In this paper, we introduce
Depth-Jitter, a novel depth-based augmentation technique that simulates natural
depth variations to improve generalization. Our approach applies adaptive depth
offsetting, guided by depth variance thresholds, to generate synthetic depth
perturbations while preserving structural integrity. We evaluate Depth-Jitter
on two benchmark datasets, FathomNet and UTDAC2020 demonstrating its impact on
model stability under diverse depth conditions. Extensive experiments compare
Depth-Jitter against traditional augmentation strategies such as ColorJitter,
analyzing performance across varying learning rates, encoders, and loss
functions. While Depth-Jitter does not always outperform conventional methods
in absolute performance, it consistently enhances model stability and
generalization in depth-sensitive environments. These findings highlight the
potential of depth-aware augmentation for real-world applications and provide a
foundation for further research into depth-based learning strategies. The
proposed technique is publicly available to support advancements in depth-aware
augmentation. The code is publicly available on
\href{https://github.com/mim-team/Depth-Jitter}{github}.

</details>


### [37] [Fourier-VLM: Compressing Vision Tokens in the Frequency Domain for Large Vision-Language Models](https://arxiv.org/abs/2508.06038)
*Huanyu Wang,Jushi Kai,Haoli Bai,Lu Hou,Bo Jiang,Ziwei He,Zhouhan Lin*

Main category: cs.CV

TL;DR: Fourier-VLM是一种创新的视觉语言模型方法，通过频域压缩技术显著提高了效率，降低了计算成本和延迟，同时保持了强大的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有视觉语言模型（VLMs）由于大量视觉标记导致的长上下文长度、高计算开销和推理延迟问题，同时避免以往方法在性能或成本上的妥协。

Method: Fourier-VLM利用离散余弦变换（DCT）作为低通滤波器，在频域中压缩视觉特征。该方法利用了视觉特征在低频分量中能量集中的特性，并通过快速傅里叶变换（FFT）高效计算DCT，从而在不引入额外参数的情况下，最大限度地减少了计算成本。

Result: Fourier-VLM在LLaVA和Qwen-VL等多种架构上进行了广泛的实验，在多个图像基准测试中取得了有竞争力的性能和良好的泛化能力。与LLaVA-v1.5相比，其推理FLOPs降低了高达83.8%，生成速度提升了31.2%，证明了其优越的效率和实用性。

Conclusion: Fourier-VLM通过在频域中压缩视觉表示，提出了一种简单而有效的方法，在保持竞争力的同时，显著降低了计算开销和推理延迟。

Abstract: Vision-Language Models (VLMs) typically replace the predefined image
placeholder token (<image>) in textual instructions with visual features from
an image encoder, forming the input to a backbone Large Language Model (LLM).
However, the large number of vision tokens significantly increases the context
length, leading to high computational overhead and inference latency. While
previous efforts mitigate this by selecting only important visual features or
leveraging learnable queries to reduce token count, they often compromise
performance or introduce substantial extra costs. In response, we propose
Fourier-VLM, a simple yet efficient method that compresses visual
representations in the frequency domain. Our approach is motivated by the
observation that vision features output from the vision encoder exhibit
concentrated energy in low-frequency components. Leveraging this, we apply a
low-pass filter to the vision features using a two-dimentional Discrete Cosine
Transform (DCT). Notably, the DCT is efficiently computed via the Fast Fourier
Transform (FFT) operator with a time complexity of $\mathcal{O}(n\log n)$,
minimizing the extra computational cost while introducing no additional
parameters. Extensive experiments across various image-based benchmarks
demonstrate that Fourier-VLM achieves competitive performance with strong
generalizability across both LLaVA and Qwen-VL architectures. Crucially, it
reduce inference FLOPs by up to 83.8% and boots generation speed by 31.2%
compared to LLaVA-v1.5, highlighting the superior efficiency and practicality.

</details>


### [38] [NEP: Autoregressive Image Editing via Next Editing Token Prediction](https://arxiv.org/abs/2508.06044)
*Huimin Wu,Xiaojian Ma,Haozhe Zhao,Yanpeng Zhao,Qing Li*

Main category: cs.CV

TL;DR: 提出 NEP 方法，通过仅编辑所需区域来提高文本引导图像编辑的效率和质量。


<details>
  <summary>Details</summary>
Motivation: 现有文本引导的图像编辑方法通常会生成整个目标图像，导致不必要的计算成本，并对非编辑区域产生偏差，从而影响编辑质量。

Method: 提出了一种基于自回归图像生成的 next editing-token prediction (NEP) 的方法，并预训练了一个能够进行任意区域编辑的任意顺序自回归文本到图像 (T2I) 模型。

Result: 该方法在常用的图像编辑基准测试中达到了新的 state-of-the-art 水平，并且能够自然地支持通过迭代优化进行 test-time scaling (TTS)。

Conclusion: 所提出的 next editing-token prediction (NEP) 方法通过仅重新生成需要编辑的区域，有效解决了现有方法计算成本高和对非编辑区域产生偏差的问题，在图像编辑任务上达到了新的 state-of-the-art 水平，并且支持 test-time scaling (TTS)。

Abstract: Text-guided image editing involves modifying a source image based on a
language instruction and, typically, requires changes to only small local
regions. However, existing approaches generate the entire target image rather
than selectively regenerate only the intended editing areas. This results in
(1) unnecessary computational costs and (2) a bias toward reconstructing
non-editing regions, which compromises the quality of the intended edits. To
resolve these limitations, we propose to formulate image editing as Next
Editing-token Prediction (NEP) based on autoregressive image generation, where
only regions that need to be edited are regenerated, thus avoiding unintended
modification to the non-editing areas. To enable any-region editing, we propose
to pre-train an any-order autoregressive text-to-image (T2I) model. Once
trained, it is capable of zero-shot image editing and can be easily adapted to
NEP for image editing, which achieves a new state-of-the-art on widely used
image editing benchmarks. Moreover, our model naturally supports test-time
scaling (TTS) through iteratively refining its generation in a zero-shot
manner. The project page is: https://nep-bigai.github.io/

</details>


### [39] [VQAThinker: Exploring Generalizable and Explainable Video Quality Assessment via Reinforcement Learning](https://arxiv.org/abs/2508.06051)
*Linhan Cao,Wei Sun,Weixia Zhang,Xiangyang Zhu,Jun Jia,Kaiwei Zhang,Dandan Zhu,Guangtao Zhai,Xiongkuo Min*

Main category: cs.CV

TL;DR: 本研究提出了 VQAThinker，一个基于 LMM 和强化学习的视频质量评估框架，通过三种新颖的奖励机制解决了现有模型的泛化性和可解释性问题，并在实验中取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视频质量评估模型在泛化到分布外（OOD）视频和可解释性方面存在局限性，限制了其在实际应用中的有效性。

Method: 提出了一种名为 VQAThinker 的基于推理的视频质量评估框架。该框架利用大型多模态模型（LMM）和强化学习（特别是群组相对策略优化 GRPO 算法）来联合建模视频质量理解和评分。引入了三种视频质量评估奖励：钟形回归奖励、成对排序奖励和时间一致性奖励。

Result: VQAThinker 在标准和非标准视频质量评估基准测试中取得了最先进的性能，展示了强大的泛化能力。在视频质量理解任务的评估中，该模型在失真归因和质量描述方面优于现有的可解释视频质量评估模型和大型多模态模型。

Conclusion: 本研究提出了一种名为 VQAThinker 的基于推理的视频质量评估框架，利用大型多模态模型（LMM）和强化学习来模拟人类的感知决策过程，实现了视频质量的理解和评分。实验结果表明，VQAThinker 在标准和非标准视频质量评估基准测试中均取得了最先进的性能，表现出强大的泛化能力。此外，在视频质量理解任务上的评估也验证了其在失真归因和质量描述方面优于现有的可解释视频质量评估模型和大型多模态模型。这表明强化学习是仅使用分数级监督即可构建可泛化、可解释的视频质量评估模型的有效途径。

Abstract: Video quality assessment (VQA) aims to objectively quantify perceptual
quality degradation in alignment with human visual perception. Despite recent
advances, existing VQA models still suffer from two critical limitations:
\textit{poor generalization to out-of-distribution (OOD) videos} and
\textit{limited explainability}, which restrict their applicability in
real-world scenarios. To address these challenges, we propose
\textbf{VQAThinker}, a reasoning-based VQA framework that leverages large
multimodal models (LMMs) with reinforcement learning to jointly model video
quality understanding and scoring, emulating human perceptual decision-making.
Specifically, we adopt group relative policy optimization (GRPO), a rule-guided
reinforcement learning algorithm that enables reasoning over video quality
under score-level supervision, and introduce three VQA-specific rewards: (1) a
\textbf{bell-shaped regression reward} that increases rapidly as the prediction
error decreases and becomes progressively less sensitive near the ground truth;
(2) a \textbf{pairwise ranking reward} that guides the model to correctly
determine the relative quality between video pairs; and (3) a \textbf{temporal
consistency reward} that encourages the model to prefer temporally coherent
videos over their perturbed counterparts. Extensive experiments demonstrate
that VQAThinker achieves state-of-the-art performance on both in-domain and OOD
VQA benchmarks, showing strong generalization for video quality scoring.
Furthermore, evaluations on video quality understanding tasks validate its
superiority in distortion attribution and quality description compared to
existing explainable VQA models and LMMs. These findings demonstrate that
reinforcement learning offers an effective pathway toward building
generalizable and explainable VQA models solely with score-level supervision.

</details>


### [40] [AGI for the Earth, the path, possibilities and how to evaluate intelligence of models that work with Earth Observation Data?](https://arxiv.org/abs/2508.06057)
*Mojtaba Valipour,Kelly Zheng,James Lowman,Spencer Szabados,Mike Gartner,Bobby Braswell*

Main category: cs.CV

TL;DR: 论文指出，卫星光谱图像对通用人工智能很重要，但现有基准不足。作者提出了一个更全面的基准和任务集，以评估模型在地球观测数据上的表现。


<details>
  <summary>Details</summary>
Motivation: 随着通用人工智能（AGI）的不断发展，研究界对多模态数据的兴趣日益浓厚，但卫星光谱图像这一重要模态尚未得到充分关注，其在推动AGI理解自然世界方面的潜力巨大。

Method: 通过论证地球观测数据对智能模型的用处，并回顾现有基准及其局限性，来强调地球观测数据在通用人工智能中的潜力。

Result: 提出了一套全面的任务，用于构建一个能够有效评估模型在地球观测领域理解和交互能力的基准。

Conclusion: 该论文强调了需要一个更全面的基准来评估地球观测模型，并提出了一个基准应包含的一套全面的任务，以有效评估模型理解和交互地球观测数据的能力。

Abstract: Artificial General Intelligence (AGI) is closer than ever to becoming a
reality, sparking widespread enthusiasm in the research community to collect
and work with various modalities, including text, image, video, and audio.
Despite recent efforts, satellite spectral imagery, as an additional modality,
has yet to receive the attention it deserves. This area presents unique
challenges, but also holds great promise in advancing the capabilities of AGI
in understanding the natural world. In this paper, we argue why Earth
Observation data is useful for an intelligent model, and then we review
existing benchmarks and highlight their limitations in evaluating the
generalization ability of foundation models in this domain. This paper
emphasizes the need for a more comprehensive benchmark to evaluate earth
observation models. To facilitate this, we propose a comprehensive set of tasks
that a benchmark should encompass to effectively assess a model's ability to
understand and interact with Earth observation data.

</details>


### [41] [Lightweight Quad Bayer HybridEVS Demosaicing via State Space Augmented Cross-Attention](https://arxiv.org/abs/2508.06058)
*Shiyang Zhou,Haijin Zeng,Yunfan Lu,Yongyong Chen,Jie Liu,Jingyong Su*

Main category: cs.CV

TL;DR: TSANet是一种轻量级的两阶段网络，通过状态空间增强的交叉注意力机制，有效解决了事件相机色彩还原中的混叠和伪影问题，在性能上超越了现有方法，并显著降低了计算成本，特别适合移动设备。


<details>
  <summary>Details</summary>
Motivation: 事件相机（如HybridEVS）虽然在捕捉亮度变化方面有优势，但在将Quad Bayer彩色滤光阵列传感器与缺乏颜色信息的事件像素结合时，会遇到挑战，尤其是在资源受限的移动设备上，这会导致去马赛克过程中的混叠和伪影。现有方法难以解决这些问题。

Method: 提出了一种名为TSANet的轻量级两阶段网络，该网络采用状态空间增强的交叉注意力机制，能够分别处理事件像素的修复和色彩还原任务。此外，研究引入了一个轻量级的跨Swin状态块，利用位置先验进行色彩还原，并通过具有线性复杂度的状态空间模型增强全局依赖性。

Result: TSANet在模拟和真实HybridEVS数据上实现了优越的色彩还原性能，并且模型轻量化，在七个不同的数据集上，其PSNR和SSIM指标均优于先前最先进的方法DemosaicFormer，同时参数量和计算成本分别降低了1.86倍和3.29倍。

Conclusion: TSANet在模拟和真实HybridEVS数据上都展示了优越的色彩还原性能，并且模型轻量化，在七个不同的数据集上，其PSNR和SSIM指标均优于先前最先进的方法DemosaicFormer，同时参数量和计算成本分别降低了1.86倍和3.29倍。我们的方法为移动设备上的高效图像色彩还原提供了新的可能性。

Abstract: Event cameras like the Hybrid Event-based Vision Sensor (HybridEVS) camera
capture brightness changes as asynchronous "events" instead of frames, offering
advanced application on mobile photography. However, challenges arise from
combining a Quad Bayer Color Filter Array (CFA) sensor with event pixels
lacking color information, resulting in aliasing and artifacts on the
demosaicing process before downstream application. Current methods struggle to
address these issues, especially on resource-limited mobile devices. In
response, we introduce \textbf{TSANet}, a lightweight \textbf{T}wo-stage
network via \textbf{S}tate space augmented cross-\textbf{A}ttention, which can
handle event pixels inpainting and demosaicing separately, leveraging the
benefits of dividing complex tasks into manageable subtasks. Furthermore, we
introduce a lightweight Cross-Swin State Block that uniquely utilizes
positional prior for demosaicing and enhances global dependencies through the
state space model with linear complexity. In summary, TSANet demonstrates
excellent demosaicing performance on both simulated and real data of HybridEVS
while maintaining a lightweight model, averaging better results than the
previous state-of-the-art method DemosaicFormer across seven diverse datasets
in both PSNR and SSIM, while respectively reducing parameter and computation
costs by $1.86\times$ and $3.29\times$. Our approach presents new possibilities
for efficient image demosaicing on mobile devices. Code is available in the
supplementary materials.

</details>


### [42] [Distribution-Specific Learning for Joint Salient and Camouflaged Object Detection](https://arxiv.org/abs/2508.06063)
*Chao Hao,Zitong Yu,Xin Liu,Yuhao Wang,Weicheng Xie,Jingang Shi,Huanjing Yue,Jingyu Yang*

Main category: cs.CV

TL;DR: This paper presents a joint learning scheme (SCJoint) and a sampling strategy (SBSS) to enable a single network (JoNet) to effectively perform both Salient Object Detection (SOD) and Camouflaged Object Detection (COD), tasks previously thought to be contradictory. Experiments show this approach achieves competitive performance.


<details>
  <summary>Details</summary>
Motivation: The paper challenges the common belief that joint learning of Salient Object Detection (SOD) and Camouflaged Object Detection (COD) tasks would confuse the network. Instead, it proposes that with the correct approach, a network can simultaneously learn both tasks, benefiting from joint learning.

Method: The paper proposes SCJoint, a joint learning scheme for SOD and COD tasks, which learns the respective means and variances of the decoding processes for both tasks by inserting minimal task-specific learnable parameters within a fully shared network structure. Additionally, a saliency-based sampling strategy (SBSS) is proposed to balance the training set sizes and improve the training quality and time for the SOD task.

Result: Extensive experiments demonstrate the competitive performance and effectiveness of the proposed SCJoint and SBSS methods in training a generalist network (JoNet) capable of capturing both salient and camouflaged objects.

Conclusion: The proposed SCJoint and SBSS methods train a powerful generalist network, JoNet, which demonstrates competitive performance and effectiveness in simultaneously detecting salient and camouflaged objects.

Abstract: Salient object detection (SOD) and camouflaged object detection (COD) are two
closely related but distinct computer vision tasks. Although both are
class-agnostic segmentation tasks that map from RGB space to binary space, the
former aims to identify the most salient objects in the image, while the latter
focuses on detecting perfectly camouflaged objects that blend into the
background in the image. These two tasks exhibit strong contradictory
attributes. Previous works have mostly believed that joint learning of these
two tasks would confuse the network, reducing its performance on both tasks.
However, here we present an opposite perspective: with the correct approach to
learning, the network can simultaneously possess the capability to find both
salient and camouflaged objects, allowing both tasks to benefit from joint
learning. We propose SCJoint, a joint learning scheme for SOD and COD tasks,
assuming that the decoding processes of SOD and COD have different distribution
characteristics. The key to our method is to learn the respective means and
variances of the decoding processes for both tasks by inserting a minimal
amount of task-specific learnable parameters within a fully shared network
structure, thereby decoupling the contradictory attributes of the two tasks at
a minimal cost. Furthermore, we propose a saliency-based sampling strategy
(SBSS) to sample the training set of the SOD task to balance the training set
sizes of the two tasks. In addition, SBSS improves the training set quality and
shortens the training time. Based on the proposed SCJoint and SBSS, we train a
powerful generalist network, named JoNet, which has the ability to
simultaneously capture both ``salient" and ``camouflaged". Extensive
experiments demonstrate the competitive performance and effectiveness of our
proposed method. The code is available at https://github.com/linuxsino/JoNet.

</details>


### [43] [Can Large Models Fool the Eye? A New Turing Test for Biological Animation](https://arxiv.org/abs/2508.06072)
*Zijian Chen,Lirong Deng,Zhengyu Chen,Kaiwei Zhang,Qi Jia,Yuan Tian,Yucheng Zhu,Guangtao Zhai*

Main category: cs.CV

TL;DR: BioMotion Arena通过视觉动画评估LLM和MLLM，发现大多数模型在生成生物运动方面存在不足。


<details>
  <summary>Details</summary>
Motivation: 当前评估LLM和MLLM的方法在提供即时、直观和可感知的性能差异反馈方面存在不足。现有的基准测试方法要么基于静态数据集的地面真实评分，要么是模糊的文本式聊天机器人风格的人类偏好收集。

Method: 使用点光源成像技术，通过视觉动画和成对比较来评估LLM和MLLM。收集了超过45,000个投票，涵盖90种生物运动变体，评估了53个主流LLM和MLLM。

Result: 超过90%的被评估模型，包括InternVL3和Claude-4系列，未能生成基本的人形点光分组，更不用说平滑且具有生物学上可行的运动。众包的人类投票与专家评分者结果高度一致，证明了BioMotion Arena的优越性。

Conclusion: BioMotion Arena是一个新颖的框架，通过视觉动画评估LLM和MLLM，通过点光成像放大了模型间的性能差异。该框架提供了区分性反馈，是一个具有挑战性的性能可视化基准和灵活的评估框架。

Abstract: Evaluating the abilities of large models and manifesting their gaps are
challenging. Current benchmarks adopt either ground-truth-based score-form
evaluation on static datasets or indistinct textual chatbot-style human
preferences collection, which may not provide users with immediate, intuitive,
and perceptible feedback on performance differences. In this paper, we
introduce BioMotion Arena, a novel framework for evaluating large language
models (LLMs) and multimodal large language models (MLLMs) via visual
animation. Our methodology draws inspiration from the inherent visual
perception of motion patterns characteristic of living organisms that utilizes
point-light source imaging to amplify the performance discrepancies between
models. Specifically, we employ a pairwise comparison evaluation and collect
more than 45k votes for 53 mainstream LLMs and MLLMs on 90 biological motion
variants. Data analyses show that the crowd-sourced human votes are in good
agreement with those of expert raters, demonstrating the superiority of our
BioMotion Arena in offering discriminative feedback. We also find that over
90\% of evaluated models, including the cutting-edge open-source InternVL3 and
proprietary Claude-4 series, fail to produce fundamental humanoid point-light
groups, much less smooth and biologically plausible motions. This enables
BioMotion Arena to serve as a challenging benchmark for performance
visualization and a flexible evaluation framework without restrictions on
ground-truth.

</details>


### [44] [Towards MR-Based Trochleoplasty Planning](https://arxiv.org/abs/2508.06076)
*Michael Wehrli,Alicia Durrer,Paul Friedrich,Sidaty El Hadramy,Edwin Li,Luana Brahaj,Carol C. Hasler,Philippe C. Cattin*

Main category: cs.CV

TL;DR: 本研究提出了一种新的管道，用于从临床MR扫描生成超分辨率、患者特定的3D伪健康目标形态，以改善滑车发育不良（TD）的治疗效果。


<details>
  <summary>Details</summary>
Motivation: 为了治疗滑车发育不良（TD），当前方法主要依赖低分辨率临床MR扫描和手术直觉，手术计划基于外科医生经验，微创技术采纳有限，导致结果不一致。

Method: 1.使用隐式神经表示（INR）计算各向同性的超分辨率MR体积。2.使用多标签自定义训练网络分割股骨、胫骨、髌骨和腓骨。3.训练小波扩散模型（WDM）生成伪健康目标形态。

Result: 生成的亚毫米级分辨率3D形态可用于术前和术中，并且相比其他方法，无需CT扫描，减少了辐射。在25名TD患者的评估中，显示该方法显著改善了沟槽角度（SA）和沟槽深度（TGD）。

Conclusion: 该方法生成的伪健康目标形态可显著改善沟槽角度和沟槽深度，为股骨滑车槽的重塑提供术前蓝图。

Abstract: To treat Trochlear Dysplasia (TD), current approaches rely mainly on
low-resolution clinical Magnetic Resonance (MR) scans and surgical intuition.
The surgeries are planned based on surgeons experience, have limited adoption
of minimally invasive techniques, and lead to inconsistent outcomes. We propose
a pipeline that generates super-resolved, patient-specific 3D pseudo-healthy
target morphologies from conventional clinical MR scans. First, we compute an
isotropic super-resolved MR volume using an Implicit Neural Representation
(INR). Next, we segment femur, tibia, patella, and fibula with a multi-label
custom-trained network. Finally, we train a Wavelet Diffusion Model (WDM) to
generate pseudo-healthy target morphologies of the trochlear region. In
contrast to prior work producing pseudo-healthy low-resolution 3D MR images,
our approach enables the generation of sub-millimeter resolved 3D shapes
compatible for pre- and intraoperative use. These can serve as preoperative
blueprints for reshaping the femoral groove while preserving the native patella
articulation. Furthermore, and in contrast to other work, we do not require a
CT for our pipeline - reducing the amount of radiation. We evaluated our
approach on 25 TD patients and could show that our target morphologies
significantly improve the sulcus angle (SA) and trochlear groove depth (TGD).
The code and interactive visualization are available at
https://wehrlimi.github.io/sr-3d-planning/.

</details>


### [45] [DreamVE: Unified Instruction-based Image and Video Editing](https://arxiv.org/abs/2508.06080)
*Bin Xia,Jiyang Liu,Yuechen Zhang,Bohao Peng,Ruihang Chu,Yitong Wang,Xinglong Wu,Bei Yu,Jiaya Jia*

Main category: cs.CV

TL;DR: DreamVE是一个统一的图像和视频指令编辑模型，通过两阶段训练（图像预训练+视频微调）和两种数据合成方法（拼贴+生成模型），解决了数据稀疏问题，并利用特定技术（Token Concatenation with Early Drop）增强了编辑效果和一致性。


<details>
  <summary>Details</summary>
Motivation: 指令驱动的编辑方式因其简单高效的交互格式而具有巨大的潜力，尤其是在视频编辑领域。然而，现有的指令驱动视频编辑方法受到训练数据有限的制约，阻碍了其广泛应用。因此，需要开发一种能够有效利用数据、提高编辑性能并易于扩展的统一模型。

Method: 提出了一种名为DreamVE的统一模型，用于指令驱动的图像和视频编辑。该模型采用了两阶段的训练策略：首先在图像编辑数据上进行预训练，然后迁移到视频编辑任务。为了解决数据稀疏性问题，研究人员设计了两种数据合成管线：基于拼贴的数据合成，用于生成大规模、多样化的编辑数据（如物体操控、背景更换、文本修改）；以及基于生成模型的数据合成，用于处理特定属性编辑的案例。在模型架构上，DreamVE构建于T2V模型之上，并采用Token Concatenation with Early Drop技术来注入源图像的引导信息，以确保编辑的一致性和可编辑性。

Result: DreamVE模型在图像和视频的指令编辑任务上均表现出色，尤其在物体操控、背景更换和文本修改等多种编辑类型上。通过拼贴数据预训练，模型获得了强大的基础能力和泛化性；随后通过生成模型数据微调，进一步提升了在属性编辑等方面的性能。

Conclusion: 通过结合基于图像的预训练和基于生成模型的微调，以及使用Token Concatenation with Early Drop方法注入源图像指导，DreamVE在图像和视频指令编辑方面取得了强大的性能，并具备良好的泛化和迁移能力。

Abstract: Instruction-based editing holds vast potential due to its simple and
efficient interactive editing format. However, instruction-based editing,
particularly for video, has been constrained by limited training data,
hindering its practical application. To this end, we introduce DreamVE, a
unified model for instruction-based image and video editing. Specifically, We
propose a two-stage training strategy: first image editing, then video editing.
This offers two main benefits: (1) Image data scales more easily, and models
are more efficient to train, providing useful priors for faster and better
video editing training. (2) Unifying image and video generation is natural and
aligns with current trends. Moreover, we present comprehensive training data
synthesis pipelines, including collage-based and generative model-based data
synthesis. The collage-based data synthesis combines foreground objects and
backgrounds to generate diverse editing data, such as object manipulation,
background changes, and text modifications. It can easily generate billions of
accurate, consistent, realistic, and diverse editing pairs. We pretrain DreamVE
on extensive collage-based data to achieve strong performance in key editing
types and enhance generalization and transfer capabilities. However,
collage-based data lacks some attribute editing cases, leading to a relative
drop in performance. In contrast, the generative model-based pipeline, despite
being hard to scale up, offers flexibility in handling attribute editing cases.
Therefore, we use generative model-based data to further fine-tune DreamVE.
Besides, we design an efficient and powerful editing framework for DreamVE. We
build on the SOTA T2V model and use a token concatenation with early drop
approach to inject source image guidance, ensuring strong consistency and
editability. The codes and models will be released.

</details>


### [46] [SwiftVideo: A Unified Framework for Few-Step Video Generation through Trajectory-Distribution Alignment](https://arxiv.org/abs/2508.06082)
*Yanxiao Sun,Jiafu Wu,Yun Cao,Chengming Xu,Yabiao Wang,Weijian Cao,Donghao Luo,Chengjie Wang,Yanwei Fu*

Main category: cs.CV

TL;DR: SwiftVideo is a new framework that speeds up video generation by combining trajectory and distribution matching, performing better than other methods when few steps are used.


<details>
  <summary>Details</summary>
Motivation: Existing diffusion-based or flow-based video synthesis models require multiple iterative sampling steps, leading to high computational overhead. Current distillation methods, focusing solely on trajectory-preserving or distribution-matching, perform poorly or introduce artifacts in few-step settings.

Method: SwiftVideo uses a unified and stable distillation framework combining trajectory-preserving and distribution-matching strategies. It incorporates continuous-time consistency distillation for precise ODE trajectory preservation and introduces dual-perspective alignment (distribution alignment between synthetic and real data, and trajectory alignment across inference steps).

Result: SwiftVideo achieves high-quality video generation while substantially reducing inference steps, outperforming existing approaches in few-step video generation as evidenced by quantitative evaluations on the OpenVid-1M benchmark.

Conclusion: SwiftVideo can generate high-quality videos with significantly fewer inference steps and outperforms existing methods in few-step video generation.

Abstract: Diffusion-based or flow-based models have achieved significant progress in
video synthesis but require multiple iterative sampling steps, which incurs
substantial computational overhead. While many distillation methods that are
solely based on trajectory-preserving or distribution-matching have been
developed to accelerate video generation models, these approaches often suffer
from performance breakdown or increased artifacts under few-step settings. To
address these limitations, we propose \textbf{\emph{SwiftVideo}}, a unified and
stable distillation framework that combines the advantages of
trajectory-preserving and distribution-matching strategies. Our approach
introduces continuous-time consistency distillation to ensure precise
preservation of ODE trajectories. Subsequently, we propose a dual-perspective
alignment that includes distribution alignment between synthetic and real data
along with trajectory alignment across different inference steps. Our method
maintains high-quality video generation while substantially reducing the number
of inference steps. Quantitative evaluations on the OpenVid-1M benchmark
demonstrate that our method significantly outperforms existing approaches in
few-step video generation.

</details>


### [47] [AdaptInfer: Adaptive Token Pruning for Vision-Language Model Inference with Dynamical Text Guidance](https://arxiv.org/abs/2508.06084)
*Weichen Zhang,Zhui Zhu,Ningbo Li,Kebin Liu,Yunhao Liu*

Main category: cs.CV

TL;DR: AdaptInfer 是一种即插即用的框架，通过动态修剪视觉标记来降低 VLMs 的推理成本，其效率和准确性均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的修剪方法未能利用推理过程中产生的动态内部信号，导致视觉-语言模型的推理成本高昂，尤其是在预填充阶段处理大量视觉标记时。

Method: AdaptInfer 框架提出了一种新颖的、细粒度的、动态文本引导的修剪机制，通过复用层级文本到文本注意力图来构建视觉标记重要性的软先验。此外，还提出了一种基于离线分析跨模态注意力转移的、更符合原则且高效的修剪计划。

Result: AdaptInfer 框架在 LLaVA-1.5-7B 模型上实现了 61.3% 的 CUDA 延迟降低，同时保持了 92.9% 的平均准确率。在相同的标记预算下，AdaptInfer 在准确率方面也超过了最先进的方法。

Conclusion: AdaptInfer 框架能够有效减少视觉-语言模型（VLMs）的推理成本，通过动态调整视觉标记的修剪，在减少 CUDA 延迟的同时保持高准确率，并且优于现有最先进的方法。

Abstract: Vision-language models (VLMs) have achieved impressive performance on
multimodal reasoning tasks such as visual question answering (VQA), but their
inference cost remains a significant challenge due to the large number of
vision tokens processed during the prefill stage. Existing pruning methods
often rely on directly using the attention patterns or static text prompt
guidance, failing to exploit the dynamic internal signals generated during
inference. To address these issues, we propose AdaptInfer, a plug-and-play
framework for adaptive vision token pruning in VLMs. First, we introduce a
fine-grained, dynamic text-guided pruning mechanism that reuses layer-wise
text-to-text attention maps to construct soft priors over text-token
importance, allowing more informed scoring of vision tokens at each stage.
Second, we perform an offline analysis of cross-modal attention shifts and
identify consistent inflection locations in inference, which inspire us to
propose a more principled and efficient pruning schedule. Our method is
lightweight and plug-and-play, also generalizable across multi-modal tasks.
Experimental results have verified the effectiveness of the proposed method.
For example, it reduces CUDA latency by 61.3\% while maintaining an average
accuracy of 92.9\% on vanilla LLaVA-1.5-7B. Under the same token budget,
AdaptInfer surpasses SOTA in accuracy.

</details>


### [48] [Q-CLIP: Unleashing the Power of Vision-Language Models for Video Quality Assessment through Unified Cross-Modal Adaptation](https://arxiv.org/abs/2508.06092)
*Yachun Mi,Yu Li,Yanting Li,Shixin Sun,Chen Hui,Tong Zhang,Yuanyuan Liu,Chenyue Song,Shaohui Liu*

Main category: cs.CV

TL;DR: Q-CLIP是一种创新的、基于视觉语言模型的视频质量评估框架，通过共享跨模态适配器和质量等级提示，在降低计算成本的同时，显著提升了评估性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有VQA方法主要依赖大规模分类数据集预训练，然后进行VQA数据集微调。然而，这种策略存在两个主要挑战：1. 预训练学习的语义知识不足以应对视频质量评估，因为视频质量受语义、失真、运动、美学等多种因素影响；2. 预训练需要巨大的计算资源，远超直接在VQA数据集上训练。因此，需要一种更高效且能充分考虑视频质量多方面因素的方法。

Method: 提出了一种名为Q-CLIP的、首个完全基于视觉语言模型（VLM）的视频质量评估（VQA）框架。该框架通过一个共享跨模态适配器（SCMA）来增强视觉和文本表示，SCMA仅包含少量可训练参数，大大降低了计算成本。此外，引入了五种可学习的质量等级提示，以引导VLM感知细微的质量差异，提高了模型对视频质量的敏感性。同时，研究了不同帧采样策略对VQA性能的影响，发现基于帧差的采样策略能带来更好的泛化性能。

Result: Q-CLIP框架通过共享跨模态适配器（SCMA）和质量等级提示，在视频质量评估任务中取得了优异的性能。与现有方法相比，Q-CLIP显著降低了计算成本，并且在多个VQA数据集上展现了良好的泛化能力。基于帧差的采样策略被证明有助于提升模型的泛化性能。

Conclusion: Q-CLIP框架在多个视频质量评估数据集上表现出色，证明了其在视频质量评估任务中的有效性和高效性。

Abstract: Accurate and efficient Video Quality Assessment (VQA) has long been a key
research challenge. Current mainstream VQA methods typically improve
performance by pretraining on large-scale classification datasets (e.g.,
ImageNet, Kinetics-400), followed by fine-tuning on VQA datasets. However, this
strategy presents two significant challenges: (1) merely transferring semantic
knowledge learned from pretraining is insufficient for VQA, as video quality
depends on multiple factors (e.g., semantics, distortion, motion, aesthetics);
(2) pretraining on large-scale datasets demands enormous computational
resources, often dozens or even hundreds of times greater than training
directly on VQA datasets. Recently, Vision-Language Models (VLMs) have shown
remarkable generalization capabilities across a wide range of visual tasks, and
have begun to demonstrate promising potential in quality assessment. In this
work, we propose Q-CLIP, the first fully VLMs-based framework for VQA. Q-CLIP
enhances both visual and textual representations through a Shared Cross-Modal
Adapter (SCMA), which contains only a minimal number of trainable parameters
and is the only component that requires training. This design significantly
reduces computational cost. In addition, we introduce a set of five learnable
quality-level prompts to guide the VLMs in perceiving subtle quality
variations, thereby further enhancing the model's sensitivity to video quality.
Furthermore, we investigate the impact of different frame sampling strategies
on VQA performance, and find that frame-difference-based sampling leads to
better generalization performance across datasets. Extensive experiments
demonstrate that Q-CLIP exhibits excellent performance on several VQA datasets.

</details>


### [49] [E-React: Towards Emotionally Controlled Synthesis of Human Reactions](https://arxiv.org/abs/2508.06093)
*Chen Zhu,Buzhen Huang,Zijing Wu,Binghui Zuo,Yangang Wang*

Main category: cs.CV

TL;DR: This paper introduces a novel task of generating diverse reaction motions in response to different emotional cues by using a semi-supervised emotion prior in an actor-reactor diffusion model. The model can generate realistic reactions under various emotional conditions and outperforms existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing human motion generation frameworks do not consider the impact of emotions, reducing naturalness and limiting applications in interactive tasks like human reaction synthesis. The work aims to address the challenge of learning emotion representation from limited motion data and incorporating it into motion generation.

Method: A semi-supervised emotion prior is introduced into an actor-reactor diffusion model. This model is trained to generate reactions by considering both spatial interaction and emotional response. The emotion prior is trained using a semi-supervised learning framework, leveraging the observation that motion clips within a short sequence tend to share the same emotion.

Result: The proposed model outperforms existing reaction generation methods in experimental results.

Conclusion: Given an actor's motion sequence, the model can generate realistic reactions under various emotional conditions, outperforming existing methods.

Abstract: Emotion serves as an essential component in daily human interactions.
Existing human motion generation frameworks do not consider the impact of
emotions, which reduces naturalness and limits their application in interactive
tasks, such as human reaction synthesis. In this work, we introduce a novel
task: generating diverse reaction motions in response to different emotional
cues. However, learning emotion representation from limited motion data and
incorporating it into a motion generation framework remains a challenging
problem. To address the above obstacles, we introduce a semi-supervised emotion
prior in an actor-reactor diffusion model to facilitate emotion-driven reaction
synthesis. Specifically, based on the observation that motion clips within a
short sequence tend to share the same emotion, we first devise a
semi-supervised learning framework to train an emotion prior. With this prior,
we further train an actor-reactor diffusion model to generate reactions by
considering both spatial interaction and emotional response. Finally, given a
motion sequence of an actor, our approach can generate realistic reactions
under various emotional conditions. Experimental results demonstrate that our
model outperforms existing reaction generation methods. The code and data will
be made publicly available at https://ereact.github.io/

</details>


### [50] [UGD-IML: A Unified Generative Diffusion-based Framework for Constrained and Unconstrained Image Manipulation Localization](https://arxiv.org/abs/2508.06101)
*Yachun Mi,Xingyang He,Shixin Sun,Yu Li,Yanting Li,Zhixuan Li,Jian Jin,Chen Hui,Shaohui Liu*

Main category: cs.CV

TL;DR: 提出了一种名为 UGD-IML 的新颖生成框架，该框架利用扩散模型统一了图像篡改定位 (IML) 和约束图像篡改定位 (CIML) 任务。该方法减少了对大规模标注数据集的依赖，提高了效率，并在多个数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有图像篡改定位方法依赖判别式学习和大规模标注数据集，但当前数据集规模和多样性不足，限制了模型在真实场景中的表现。虽然 CIML 方法通过算法监督生成像素级标注，但现有方法通常依赖复杂的多阶段流水线，效率低下。

Method: 提出了一种新颖的基于扩散模型的生成框架 UGD-IML，该框架统一了 IML 和 CIML 任务，并通过类别嵌入和参数共享机制实现了模式切换，采用端到端设计以简化数据标注流程。

Result: 在多个数据集上的广泛实验表明，UGD-IML 在 IML 和 CIML 任务的 F1 指标上分别比现有方法平均高出 9.66 和 4.36。此外，该方法在不确定性估计、可视化和鲁棒性方面也表现出色。

Conclusion: UGD-IML 框架能够有效地同时处理图像篡改定位 (IML) 和约束图像篡改定位 (CIML) 任务，并且在数据有限的情况下表现出色，优于现有方法。

Abstract: In the digital age, advanced image editing tools pose a serious threat to the
integrity of visual content, making image forgery detection and localization a
key research focus. Most existing Image Manipulation Localization (IML) methods
rely on discriminative learning and require large, high-quality annotated
datasets. However, current datasets lack sufficient scale and diversity,
limiting model performance in real-world scenarios. To overcome this, recent
studies have explored Constrained IML (CIML), which generates pixel-level
annotations through algorithmic supervision. However, existing CIML approaches
often depend on complex multi-stage pipelines, making the annotation process
inefficient. In this work, we propose a novel generative framework based on
diffusion models, named UGD-IML, which for the first time unifies both IML and
CIML tasks within a single framework. By learning the underlying data
distribution, generative diffusion models inherently reduce the reliance on
large-scale labeled datasets, allowing our approach to perform effectively even
under limited data conditions. In addition, by leveraging a class embedding
mechanism and a parameter-sharing design, our model seamlessly switches between
IML and CIML modes without extra components or training overhead. Furthermore,
the end-to-end design enables our model to avoid cumbersome steps in the data
annotation process. Extensive experimental results on multiple datasets
demonstrate that UGD-IML outperforms the SOTA methods by an average of 9.66 and
4.36 in terms of F1 metrics for IML and CIML tasks, respectively. Moreover, the
proposed method also excels in uncertainty estimation, visualization and
robustness.

</details>


### [51] [MCA: 2D-3D Retrieval with Noisy Labels via Multi-level Adaptive Correction and Alignment](https://arxiv.org/abs/2508.06104)
*Gui Zou,Chaofan Gan,Chern Hong Lim,Supavadee Aramvith,Weiyao Lin*

Main category: cs.CV

TL;DR: 提出了一种名为MCA的新框架，用于在存在噪声标签的情况下进行2D-3D跨模态检索。MCA通过多模态联合标签校正（MJC）和多级自适应对齐（MAA）来提高性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理噪声标签时，通常独立地对每个模态中的样本进行处理，容易导致过拟合于被破坏的标签。为了解决这些问题，提出了一种鲁棒的2D-3D多级别跨模态自适应校正与对齐框架（MCA）。

Method: 提出了一种多模态联合标签校正（MJC）机制，利用多模态历史自我预测来联合建模模态预测一致性，实现可靠的标签细化。此外，还提出了一种多级自适应对齐（MAA）策略，以有效增强不同级别的跨模态特征语义和判别力。

Result: 实验结果表明，MCA在常规和真实噪声3D基准上均取得了最先进的性能。

Conclusion: MCA在常规和真实噪声3D基准上均 achieves state-of-the-art performance，证明了其通用性和有效性。

Abstract: With the increasing availability of 2D and 3D data, significant advancements
have been made in the field of cross-modal retrieval. Nevertheless, the
existence of imperfect annotations presents considerable challenges, demanding
robust solutions for 2D-3D cross-modal retrieval in the presence of noisy label
conditions. Existing methods generally address the issue of noise by dividing
samples independently within each modality, making them susceptible to
overfitting on corrupted labels. To address these issues, we propose a robust
2D-3D \textbf{M}ulti-level cross-modal adaptive \textbf{C}orrection and
\textbf{A}lignment framework (MCA). Specifically, we introduce a Multimodal
Joint label Correction (MJC) mechanism that leverages multimodal historical
self-predictions to jointly model the modality prediction consistency, enabling
reliable label refinement. Additionally, we propose a Multi-level Adaptive
Alignment (MAA) strategy to effectively enhance cross-modal feature semantics
and discrimination across different levels. Extensive experiments demonstrate
the superiority of our method, MCA, which achieves state-of-the-art performance
on both conventional and realistic noisy 3D benchmarks, highlighting its
generality and effectiveness.

</details>


### [52] [Mask & Match: Learning to Recognize Handwritten Math with Self-Supervised Attention](https://arxiv.org/abs/2508.06107)
*Shree Mitra,Ritabrata Chakraborty,Nilkanta Sahu*

Main category: cs.CV

TL;DR: 提出了一种用于手写数学表达式识别（HMER）的自监督学习框架，通过结合对比损失和渐进式空间掩蔽策略的注意机制，无需标注数据即可有效学习和识别复杂的数学表达式，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 手写数学表达式识别（HMER）任务具有挑战性，因为其固有的二维结构、变化的符号尺度和复杂的空间关系。本工作旨在通过SSL框架消除对昂贵标注数据的需求。

Method: 提出了一种用于手写数学表达式识别（HMER）的自监督学习（SSL）框架，包括（1）图像编码器的自监督预训练（结合全局和局部对比损失），（2）新颖的自监督注意网络（使用渐进式空间掩蔽策略训练），以及（3）带有Transformer解码器的监督微调以生成LATEX序列。

Result: 该SSL框架通过渐进式空间掩蔽策略训练出的注意机制，能够学习到有意义的语义关注区域（如运算符、指数和嵌套数学符号），而无需任何监督。实验证明该方法在CROHME基准测试中表现优于现有方法。

Conclusion: 该方法在CROHME基准测试中表现优于现有的自监督和全监督基线，验证了其渐进式注意机制在提高HMER性能方面的有效性。

Abstract: Recognizing handwritten mathematical expressions (HMER) is a challenging task
due to the inherent two-dimensional structure, varying symbol scales, and
complex spatial relationships among symbols. In this paper, we present a
self-supervised learning (SSL) framework for HMER that eliminates the need for
expensive labeled data. Our approach begins by pretraining an image encoder
using a combination of global and local contrastive loss, enabling the model to
learn both holistic and fine-grained representations. A key contribution of
this work is a novel self-supervised attention network, which is trained using
a progressive spatial masking strategy. This attention mechanism is designed to
learn semantically meaningful focus regions, such as operators, exponents, and
nested mathematical notation, without requiring any supervision. The
progressive masking curriculum encourages the network to become increasingly
robust to missing or occluded visual information, ultimately improving
structural understanding. Our complete pipeline consists of (1) self-supervised
pretraining of the encoder, (2) self-supervised attention learning, and (3)
supervised fine-tuning with a transformer decoder to generate LATEX sequences.
Extensive experiments on CROHME benchmarks demonstrate that our method
outperforms existing SSL and fully supervised baselines, validating the
effectiveness of our progressive attention mechanism in enhancing HMER
performance. Our codebase can be found here.

</details>


### [53] [FMCE-Net++: Feature Map Convergence Evaluation and Training](https://arxiv.org/abs/2508.06109)
*Zhibo Zhu,Renyu Huang,Lei He*

Main category: cs.CV

TL;DR: FMCE-Net++ 通过集成 FMCE-Net 辅助头来提升 DNN 性能，无需额外数据或架构更改。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有特征图收敛评估 (FMCE) 方法缺乏实验验证和闭环集成的问题，提出 FMCE-Net++ 框架。

Method: 提出了一种名为 FMCE-Net++ 的新颖训练框架，该框架将预训练的、冻结的 FMCE-Net 作为辅助头集成。该模块生成 FMCS 预测，并与任务标签一起，通过表示辅助损失 (RAL) 联合监督骨干优化。RAL 通过一个可调的表示抽象因子动态平衡主要的分类损失和特征收敛优化。

Result: 在 MNIST、CIFAR-10、FashionMNIST 和 CIFAR-100 上进行的广泛实验表明，FMCE-Net++ 在不进行架构修改或增加额外数据的情况下，能够持续提升模型性能。例如，在 ResNet-50/CIFAR-10 上准确率提升了 1.16 个百分点，在 ShuffleNet v2/CIFAR-100 上提升了 1.08 个百分点，验证了 FMCE-Net++ 能够有效提升最先进的性能上限。

Conclusion: FMCE-Net++ 框架通过集成预训练的 FMCE-Net 作为辅助头，并利用特征图收敛分数 (FMCS) 和任务标签联合监督骨干网络优化，有效提升了深度神经网络的性能。该框架通过表示辅助损失 (RAL) 和可调的表示抽象因子动态平衡分类损失与特征收敛优化，无需修改网络结构或额外数据。

Abstract: Deep Neural Networks (DNNs) face interpretability challenges due to their
opaque internal representations. While Feature Map Convergence Evaluation
(FMCE) quantifies module-level convergence via Feature Map Convergence Scores
(FMCS), it lacks experimental validation and closed-loop integration. To
address this limitation, we propose FMCE-Net++, a novel training framework that
integrates a pretrained, frozen FMCE-Net as an auxiliary head. This module
generates FMCS predictions, which, combined with task labels, jointly supervise
backbone optimization through a Representation Auxiliary Loss. The RAL
dynamically balances the primary classification loss and feature convergence
optimization via a tunable \Representation Abstraction Factor. Extensive
experiments conducted on MNIST, CIFAR-10, FashionMNIST, and CIFAR-100
demonstrate that FMCE-Net++ consistently enhances model performance without
architectural modifications or additional data. Key experimental outcomes
include accuracy gains of $+1.16$ pp (ResNet-50/CIFAR-10) and $+1.08$ pp
(ShuffleNet v2/CIFAR-100), validating that FMCE-Net++ can effectively elevate
state-of-the-art performance ceilings.

</details>


### [54] [Effective Training Data Synthesis for Improving MLLM Chart Understanding](https://arxiv.org/abs/2508.06492)
*Yuwei Yang,Zeyu Zhang,Yunzhong Hou,Zhuowan Li,Gaowen Liu,Ali Payani,Yuan-Sen Ting,Liang Zheng*

Main category: cs.CV

TL;DR: 通过改进合成数据方法，构建了包含10k+图表和300k+问答对的ECD数据集，有效提升了多模态大语言模型在科学图表理解任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在科学图表理解方面，尤其是在真实复杂图表上，性能表现不佳（成功率仅为30%-50%）。先前使用合成图表进行微调的研究，由于合成图表与真实图表相似度不足，影响了模型训练和性能。本次研究旨在通过改进数据合成方法来提升MLLMs的图表理解能力。

Method: 设计了一个包含五个步骤的数据合成流程，包括数据和图形生成分离、多子图生成条件化、视觉多样化、低质量数据过滤以及使用GPT-4o生成问答对，构建了包含10k+图表图像和300k+问答对的ECD数据集，覆盖25个主题和250多种图表组合。

Result: ECD数据集被证明能够持续提升包括开源模型在内的多种MLLMs在真实和合成图表测试集上的性能。

Conclusion: 所提出的ECD数据集能有效提升MLLMs在科学图表理解任务上的性能，在多种真实和合成数据集上都表现出持续的改进。

Abstract: Being able to effectively read scientific plots, or chart understanding, is a
central part toward building effective agents for science. However, existing
multimodal large language models (MLLMs), especially open-source ones, are
still falling behind with a typical success rate of 30%-50% on challenging
benchmarks. Previous studies on fine-tuning MLLMs with synthetic charts are
often restricted by their inadequate similarity to the real charts, which could
compromise model training and performance on complex real-world charts. In this
study, we show that modularizing chart generation and diversifying visual
details improves chart understanding capabilities. In particular, we design a
five-step data synthesis pipeline, where we separate data and function creation
for single plot generation, condition the generation of later subplots on
earlier ones for multi-subplot figures, visually diversify the generated
figures, filter out low quality data, and finally generate the question-answer
(QA) pairs with GPT-4o. This approach allows us to streamline the generation of
fine-tuning datasets and introduce the effective chart dataset (ECD), which
contains 10k+ chart images and 300k+ QA pairs, covering 25 topics and featuring
250+ chart type combinations with high visual complexity. We show that ECD
consistently improves the performance of various MLLMs on a range of real-world
and synthetic test sets. Code, data and models are available at:
https://github.com/yuweiyang-anu/ECD.

</details>


### [55] [SynSeg: Feature Synergy for Multi-Category Contrastive Learning in Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2508.06115)
*Weichen Zhang,Kebin Liu,Fan Dang,Zhui Zhu,Xikai Sun,Yunhao Liu*

Main category: cs.CV

TL;DR: SynSeg, a novel weakly-supervised approach, enhances open-vocabulary semantic segmentation using Multi-Category Contrastive Learning (MCCL) and Feature Synergy Structure (FSS) to improve category correlation learning and mitigate foreground bias, achieving state-of-the-art results on multiple benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing weakly-supervised methods for open-vocabulary semantic segmentation struggle with the wide range of categories and often use unsuitable supervision and feature construction methods, leading to semantic misalignment and poor performance.

Method: SynSeg employs Multi-Category Contrastive Learning (MCCL) for a stronger training signal and a Feature Synergy Structure (FSS) framework for feature reconstruction. MCCL combines intra- and inter-category alignment and separation to learn category correlations. FSS reconstructs discriminative features via prior fusion and semantic-activation-map enhancement, mitigating foreground bias.

Result: SynSeg achieves higher accuracy than SOTA baselines by 4.5% on VOC, 8.9% on Context, 2.6% on Object, and 2.0% on City.

Conclusion: SynSeg effectively improves semantic localization and discrimination abilities under weak supervision, outperforming SOTA methods on multiple benchmarks.

Abstract: Semantic segmentation in open-vocabulary scenarios presents significant
challenges due to the wide range and granularity of semantic categories.
Existing weakly-supervised methods often rely on category-specific supervision
and ill-suited feature construction methods for contrastive learning, leading
to semantic misalignment and poor performance. In this work, we propose a novel
weakly-supervised approach, SynSeg, to address the challenges. SynSeg performs
Multi-Category Contrastive Learning (MCCL) as a stronger training signal with a
new feature reconstruction framework named Feature Synergy Structure (FSS).
Specifically, MCCL strategy robustly combines both intra- and inter-category
alignment and separation in order to make the model learn the knowledge of
correlations from different categories within the same image. Moreover, FSS
reconstructs discriminative features for contrastive learning through prior
fusion and semantic-activation-map enhancement, effectively avoiding the
foreground bias introduced by the visual encoder. In general, SynSeg
effectively improves the abilities in semantic localization and discrimination
under weak supervision. Extensive experiments on benchmarks demonstrate that
our method outperforms state-of-the-art (SOTA) performance. For instance,
SynSeg achieves higher accuracy than SOTA baselines by 4.5\% on VOC, 8.9\% on
Context, 2.6\% on Object and 2.0\% on City.

</details>


### [56] [Learning Representations of Satellite Images with Evaluations on Synoptic Weather Events](https://arxiv.org/abs/2508.06122)
*Ting-Shuo Yo,Shih-Hao Su,Chien-Ming Wu,Wei-Ting Chen,Jung-Lien Chu,Chiao-Wei Chang,Hung-Chi Kuo*

Main category: cs.CV

TL;DR: 本研究对比了PCA、CAE和PT三种算法在卫星图像天气事件分类任务中的表现。CAE在分类准确性上优于PCA和PT，但其学习到的表征缺乏物理解释性。研究还发现，更高分辨率的数据集和适中的潜在空间尺寸（不小于128）有利于提升分类性能。


<details>
  <summary>Details</summary>
Motivation: 为了探索表示学习算法在卫星图像天气事件分类中的应用和评估不同算法学习到的潜在空间的有效性。

Method: 本研究应用了包括PCA、CAE和预训练残差网络（PT）在内的表示学习算法，并将学习到的潜在空间应用于卫星图像的天气事件分类任务。

Result: CAE学习到的潜在空间在所有分类任务中均表现出更高的威胁得分。PCA在识别天气事件方面命中率高但误报率也高，PT在识别热带气旋方面表现优异但在其他任务上表现不佳。更高分辨率的数据集和128维的潜在空间尺寸对深度学习算法的分类任务表现有积极影响。

Conclusion: CAE在天气事件分类任务中表现最佳，但其学习到的表征缺乏物理解释性。未来的工作可以探索CAE的物理信息方法。

Abstract: This study applied representation learning algorithms to satellite images and
evaluated the learned latent spaces with classifications of various weather
events. The algorithms investigated include the classical linear
transformation, i.e., principal component analysis (PCA), state-of-the-art deep
learning method, i.e., convolutional autoencoder (CAE), and a residual network
pre-trained with large image datasets (PT). The experiment results indicated
that the latent space learned by CAE consistently showed higher threat scores
for all classification tasks. The classifications with PCA yielded high hit
rates but also high false-alarm rates. In addition, the PT performed
exceptionally well at recognizing tropical cyclones but was inferior in other
tasks. Further experiments suggested that representations learned from
higher-resolution datasets are superior in all classification tasks for
deep-learning algorithms, i.e., CAE and PT. We also found that smaller latent
space sizes had minor impact on the classification task's hit rate. Still, a
latent space dimension smaller than 128 caused a significantly higher false
alarm rate. Though the CAE can learn latent spaces effectively and efficiently,
the interpretation of the learned representation lacks direct connections to
physical attributions. Therefore, developing a physics-informed version of CAE
can be a promising outlook for the current work.

</details>


### [57] [SC-Captioner: Improving Image Captioning with Self-Correction by Reinforcement Learning](https://arxiv.org/abs/2508.06125)
*Lin Zhang,Xianfang Zeng,Kangcong Li,Gang Yu,Tao Chen*

Main category: cs.CV

TL;DR: 提出 SC-Captioner 框架，通过奖励函数实现图像字幕的自我修正，并引入新的评估指标和数据集，实验证明效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 旨在为图像字幕模型提供自我修正的能力。

Method: 提出了一种名为 SC-Captioner 的强化学习框架，通过设计奖励函数来激励模型进行准确的字幕修正。具体方法是将预测字幕和参考字幕分解为对象、属性和关系集合，通过集合差分识别添加和移除的元素，并将这些元素与参考集合进行匹配，计算修正的正确性奖励和错误惩罚，形成最终奖励。此外，还提出了一套改进的图像字幕质量评估指标，并收集了一个包含 6.5K 图像的细粒度标注数据集 RefinedCaps。

Result: SC-Captioner 框架能够生成更好的图像字幕，并且在与大型视觉-语言模型结合使用时，在各种场景下均表现出色，显著优于直接偏好优化训练策略。

Conclusion: SC-Captioner 框架在各种场景下能生成更好的图像字幕，并且显著优于直接偏好优化训练策略。

Abstract: We propose SC-Captioner, a reinforcement learning framework that enables the
self-correcting capability of image caption models. Our crucial technique lies
in the design of the reward function to incentivize accurate caption
corrections. Specifically, the predicted and reference captions are decomposed
into object, attribute, and relation sets using scene-graph parsing algorithms.
We calculate the set difference between sets of initial and self-corrected
captions to identify added and removed elements. These elements are matched
against the reference sets to calculate correctness bonuses for accurate
refinements and mistake punishments for wrong additions and removals, thereby
forming the final reward. For image caption quality assessment, we propose a
set of metrics refined from CAPTURE that alleviate its incomplete precision
evaluation and inefficient relation matching problems. Furthermore, we collect
a fine-grained annotated image caption dataset, RefinedCaps, consisting of 6.5K
diverse images from COCO dataset. Experiments show that applying SC-Captioner
on large visual-language models can generate better image captions across
various scenarios, significantly outperforming the direct preference
optimization training strategy.

</details>


### [58] [SAM Encoder Breach by Adversarial Simplicial Complex Triggers Downstream Model Failures](https://arxiv.org/abs/2508.06127)
*Yi Qin,Rui Wang,Tao Huang,Tong Xiao,Liping Jing*

Main category: cs.CV

TL;DR: VeSCA 是一种新的方法，通过利用 SAM 的编码器和单纯形复形来生成可迁移的对抗样本，以解决 SAM 漏洞的传递性问题。实验证明 VeSCA 比现有方法提高了 12.7% 的性能，并强调了基础模型稳健性的重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管 SAM 在交互式分割方面具有零次学习能力，但其固有的漏洞可能导致众多下游应用程序的失败。因此，主动评估这些可迁移的漏洞至关重要。先前对 SAM 的对抗攻击由于对跨域的共同弱点探索不足，导致可迁移性有限。

Method: 提出了一种名为 VeSCA（Vertex-Refining Simplicial Complex Attack）的新颖方法，该方法仅利用 SAM 的编码器来生成可迁移的对抗样本。它通过参数化单纯形复形明确表征 SAM 与下游模型之间的共享脆弱区域，并通过迭代顶点细化来识别这些复形。此外，还引入了一种轻量级的域再适应策略，利用最小的参考数据来弥合域发散。

Result: VeSCA 能够生成一致的可迁移对抗样本，并且在三个下游模型类别和五个领域特定数据集上的实验表明，其性能比现有技术提高了 12.7%。

Conclusion: VeSCA 生成的对抗样本在跨越三个下游模型类别和五个特定领域的数据集上，相比最先进的方法性能提升了 12.7%。这些发现进一步凸显了 SAM 的漏洞对下游模型构成的风险，并强调了开发更强大的基础模型的紧迫性。

Abstract: While the Segment Anything Model (SAM) transforms interactive segmentation
with zero-shot abilities, its inherent vulnerabilities present a single-point
risk, potentially leading to the failure of numerous downstream applications.
Proactively evaluating these transferable vulnerabilities is thus imperative.
Prior adversarial attacks on SAM often present limited transferability due to
insufficient exploration of common weakness across domains. To address this, we
propose Vertex-Refining Simplicial Complex Attack (VeSCA), a novel method that
leverages only the encoder of SAM for generating transferable adversarial
examples. Specifically, it achieves this by explicitly characterizing the
shared vulnerable regions between SAM and downstream models through a
parametric simplicial complex. Our goal is to identify such complexes within
adversarially potent regions by iterative vertex-wise refinement. A lightweight
domain re-adaptation strategy is introduced to bridge domain divergence using
minimal reference data during the initialization of simplicial complex.
Ultimately, VeSCA generates consistently transferable adversarial examples
through random simplicial complex sampling. Extensive experiments demonstrate
that VeSCA achieves performance improved by 12.7% compared to state-of-the-art
methods across three downstream model categories across five domain-specific
datasets. Our findings further highlight the downstream model risks posed by
SAM's vulnerabilities and emphasize the urgency of developing more robust
foundation models.

</details>


### [59] [Roll Your Eyes: Gaze Redirection via Explicit 3D Eyeball Rotation](https://arxiv.org/abs/2508.06136)
*YoungChan Choi,HengFei Wang,YiHua Cheng,Boeun Kim,Hyung Jin Chang,YoungGeun Choi,Sang-Il Choi*

Main category: cs.CV

TL;DR: 本研究提出了一种基于3D高斯泼溅的3D注视重定向框架，通过显式的3D眼球结构和自适应变形模块，实现了高质量的注视图像生成和准确的注视估计，优于现有NeRF方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于NeRF（神经辐射场）的注视重定向方法，其3D表示的旋转和平移并未显式建模。为了解决这个问题，本研究引入了显式的3D眼球结构。

Method: 提出了一种新颖的3D注视重定向框架，该框架利用显式的3D眼球结构，并采用3D高斯泼溅（3DGS）来表示眼球。此外，还提出了一种自适应变形模块，用于模拟眼部周围肌肉的细微运动。

Result: 在ETH-XGaze数据集上的实验表明，该框架能够生成多样化的新颖注视图像，并在图像质量和注视估计准确性方面优于现有的最先进方法。

Conclusion: 该框架通过显式旋转和翻译3D眼球结构，能够生成逼真的图像，准确还原期望的注视方向。实验结果表明，与现有方法相比，该方法在图像质量和注视估计准确性方面均表现更优。

Abstract: We propose a novel 3D gaze redirection framework that leverages an explicit
3D eyeball structure. Existing gaze redirection methods are typically based on
neural radiance fields, which employ implicit neural representations via volume
rendering. Unlike these NeRF-based approaches, where the rotation and
translation of 3D representations are not explicitly modeled, we introduce a
dedicated 3D eyeball structure to represent the eyeballs with 3D Gaussian
Splatting (3DGS). Our method generates photorealistic images that faithfully
reproduce the desired gaze direction by explicitly rotating and translating the
3D eyeball structure. In addition, we propose an adaptive deformation module
that enables the replication of subtle muscle movements around the eyes.
Through experiments conducted on the ETH-XGaze dataset, we demonstrate that our
framework is capable of generating diverse novel gaze images, achieving
superior image quality and gaze estimation accuracy compared to previous
state-of-the-art methods.

</details>


### [60] [DiffCap: Diffusion-based Real-time Human Motion Capture using Sparse IMUs and a Monocular Camera](https://arxiv.org/abs/2508.06139)
*Shaohua Pan,Xinyu Yi,Yan Zhou,Weihua Jian,Yuan Zhang,Pengfei Wan,Feng Xu*

Main category: cs.CV

TL;DR: 本研究提出了一种创新的扩散模型方法，通过融合IMU和单目摄像头数据，实现了鲁棒且精确的实时人体运动捕捉。


<details>
  <summary>Details</summary>
Motivation: 为了解决视觉信息可能因遮挡或主体移出相机视野而不可用，以及IMU测量对遮挡具有鲁棒性且信号传输稳定等特点，本研究提出了一种将两种信号模态融合的统一框架。

Method: 本研究提出了一种基于扩散模型的解决方案，将视觉信息转化为条件嵌入，并将惯性测量逐帧与带有噪声的身体姿态连接起来，以构建扩散模型的序列输入。

Result: 实验证明了该系统设计的有效性及其在姿态估计方面相比于先前工作的先进性能。

Conclusion: 该研究提出了一种基于扩散模型的解决方案，用于学习人类运动先验知识，并在统一框架中无缝融合稀疏IMU和单目摄像头两种信号模态，实现了实时运动捕捉。

Abstract: Combining sparse IMUs and a monocular camera is a new promising setting to
perform real-time human motion capture. This paper proposes a diffusion-based
solution to learn human motion priors and fuse the two modalities of signals
together seamlessly in a unified framework. By delicately considering the
characteristics of the two signals, the sequential visual information is
considered as a whole and transformed into a condition embedding, while the
inertial measurement is concatenated with the noisy body pose frame by frame to
construct a sequential input for the diffusion model. Firstly, we observe that
the visual information may be unavailable in some frames due to occlusions or
subjects moving out of the camera view. Thus incorporating the sequential
visual features as a whole to get a single feature embedding is robust to the
occasional degenerations of visual information in those frames. On the other
hand, the IMU measurements are robust to occlusions and always stable when
signal transmission has no problem. So incorporating them frame-wisely could
better explore the temporal information for the system. Experiments have
demonstrated the effectiveness of the system design and its state-of-the-art
performance in pose estimation compared with the previous works. Our codes are
available for research at https://shaohua-pan.github.io/diffcap-page.

</details>


### [61] [SDEval: Safety Dynamic Evaluation for Multimodal Large Language Models](https://arxiv.org/abs/2508.06142)
*Hanqing Wang,Yuan Tian,Mingyu Liu,Zhenhao Zhang,Xiangyang Zhu*

Main category: cs.CV

TL;DR: 提出 SDEval，首个安全动态评估框架，通过文本、图像和文本-图像动态策略生成样本，以应对 MLLM 安全评估中的数据污染和过时问题。


<details>
  <summary>Details</summary>
Motivation: 现有的 MLLM 安全评估数据集可能过时且易受数据污染，需要一种新的评估方法。

Method: SDEval 框架通过文本、图像和文本-图像动态策略生成新样本，以动态调整安全基准的分布和复杂性。

Result: SDEval 能够动态调整安全基准的分布和复杂性，并在 MLLMGuard、VLSBench、MMBench 和 MMVet 等基准测试中显示出有效性。

Conclusion: SDEval 显著影响安全评估，缓解数据污染，并揭示了 MLLMs 的安全局限性。

Abstract: In the rapidly evolving landscape of Multimodal Large Language Models
(MLLMs), the safety concerns of their outputs have earned significant
attention. Although numerous datasets have been proposed, they may become
outdated with MLLM advancements and are susceptible to data contamination
issues. To address these problems, we propose \textbf{SDEval}, the
\textit{first} safety dynamic evaluation framework to controllably adjust the
distribution and complexity of safety benchmarks. Specifically, SDEval mainly
adopts three dynamic strategies: text, image, and text-image dynamics to
generate new samples from original benchmarks. We first explore the individual
effects of text and image dynamics on model safety. Then, we find that
injecting text dynamics into images can further impact safety, and conversely,
injecting image dynamics into text also leads to safety risks. SDEval is
general enough to be applied to various existing safety and even capability
benchmarks. Experiments across safety benchmarks, MLLMGuard and VLSBench, and
capability benchmarks, MMBench and MMVet, show that SDEval significantly
influences safety evaluation, mitigates data contamination, and exposes safety
limitations of MLLMs. Code is available at https://github.com/hq-King/SDEval

</details>


### [62] [Text-guided Visual Prompt DINO for Generic Segmentation](https://arxiv.org/abs/2508.06146)
*Yuchen Guan,Chong Sun,Canmiao Fu,Zhipeng Huang,Chun Yuan,Chen Li*

Main category: cs.CV

TL;DR: Prompt-DINO, a text-guided visual Prompt DINO framework, tackles open-world segmentation challenges with early fusion, aligned query selection, and a large-scale generative data engine, outperforming existing methods and expanding vocabulary.


<details>
  <summary>Details</summary>
Motivation: To address limitations in late-stage feature fusion, suboptimal query selection, and caption-derived vocabularies in existing multimodal vision models for open-world segmentation.

Method: Prompt-DINO introduces an early fusion mechanism, order-aligned query selection for DETR-based architectures, and a generative data engine powered by the RAP model for data synthesis.

Result: Prompt-DINO achieves state-of-the-art performance on open-world detection benchmarks and significantly expands semantic coverage.

Conclusion: Prompt-DINO establishes a new paradigm for scalable multimodal detection and data generation in open-world scenarios, achieving state-of-the-art performance and expanding semantic coverage.

Abstract: Recent advancements in multimodal vision models have highlighted limitations
in late-stage feature fusion and suboptimal query selection for hybrid prompts
open-world segmentation, alongside constraints from caption-derived
vocabularies. To address these challenges, we propose Prompt-DINO, a
text-guided visual Prompt DINO framework featuring three key innovations.
First, we introduce an early fusion mechanism that unifies text/visual prompts
and backbone features at the initial encoding stage, enabling deeper
cross-modal interactions to resolve semantic ambiguities. Second, we design
order-aligned query selection for DETR-based architectures, explicitly
optimizing the structural alignment between text and visual queries during
decoding to enhance semantic-spatial consistency. Third, we develop a
generative data engine powered by the Recognize Anything via Prompting (RAP)
model, which synthesizes 0.5B diverse training instances through a dual-path
cross-verification pipeline, reducing label noise by 80.5% compared to
conventional approaches. Extensive experiments demonstrate that Prompt-DINO
achieves state-of-the-art performance on open-world detection benchmarks while
significantly expanding semantic coverage beyond fixed-vocabulary constraints.
Our work establishes a new paradigm for scalable multimodal detection and data
generation in open-world scenarios. Data&Code are available at
https://github.com/WeChatCV/WeVisionOne.

</details>


### [63] [DSConv: Dynamic Splitting Convolution for Pansharpening](https://arxiv.org/abs/2508.06147)
*Xuanyu Liu,Bonan An*

Main category: cs.CV

TL;DR: A new method called DSConv dynamically splits convolution kernels with attention for better feature extraction in pansharpening, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Most existing pansharpening approaches rely on standard convolutions. This paper aims to address the limitations of standard convolutions by introducing adaptive convolutions, specifically DSConv, which leverages inter-pixel correlations in remote sensing images to improve feature extraction and achieve high-resolution image fusion more effectively.

Method: The paper proposes a novel strategy called DSConv (Dynamically Splitting Convolution) that splits convolution kernels into multiple smaller kernels, combined with attention mechanisms, to better extract features from different positions within the receptive field. This enhances the network's generalization, optimization, and feature representation capabilities for pansharpening.

Result: Experimental results demonstrate that DSConv achieves state-of-the-art performance in pansharpening, validating its effectiveness and superiority.

Conclusion: The proposed DSConv, which dynamically splits convolution kernels in conjunction with attention, demonstrates superior performance and effectiveness in pansharpening tasks, achieving state-of-the-art results.

Abstract: Aiming to obtain a high-resolution image, pansharpening involves the fusion
of a multi-spectral image (MS) and a panchromatic image (PAN), the low-level
vision task remaining significant and challenging in contemporary research.
Most existing approaches rely predominantly on standard convolutions, few
making the effort to adaptive convolutions, which are effective owing to the
inter-pixel correlations of remote sensing images. In this paper, we propose a
novel strategy for dynamically splitting convolution kernels in conjunction
with attention, selecting positions of interest, and splitting the original
convolution kernel into multiple smaller kernels, named DSConv. The proposed
DSConv more effectively extracts features of different positions within the
receptive field, enhancing the network's generalization, optimization, and
feature representation capabilities. Furthermore, we innovate and enrich
concepts of dynamic splitting convolution and provide a novel network
architecture for pansharpening capable of achieving the tasks more efficiently,
building upon this methodology. Adequate fair experiments illustrate the
effectiveness and the state-of-the-art performance attained by
DSConv.Comprehensive and rigorous discussions proved the superiority and
optimal usage conditions of DSConv.

</details>


### [64] [VISTAR:A User-Centric and Role-Driven Benchmark for Text-to-Image Evaluation](https://arxiv.org/abs/2508.06152)
*Kaiyuan Jiang,Ruoxi Sun,Ying Cao,Yuqi Xu,Xinran Zhang,Junyan Guo,ChengSheng Deng*

Main category: cs.CV

TL;DR: VISTAR是一个新的T2I评估基准，它结合了硬性和软性指标，并通过15000多次人工比较进行了验证，以提供更准确、更符合用户需求的评估。


<details>
  <summary>Details</summary>
Motivation: 提出VISTAR，一个以用户为中心、多维度的文本到图像（T2I）评估基准，以解决现有指标的局限性。

Method: VISTAR引入了一个两层混合范式：它采用确定性的、可脚本化的指标来评估物理上可量化的属性（例如，文本渲染、光照），并采用新颖的层次加权P/N问题（HWPQ）方案，使用约束式视觉-语言模型来评估抽象语义（例如，风格融合、文化保真度）。

Result: VISTAR的指标实现了高度的人类一致性（>75%）。

Conclusion: VISTAR在抽象语义方面达到了85.9%的准确率，显著优于VQA基线。对最先进模型的全面评估显示，没有普遍的冠军模型，基于角色的加权分数重新排序了排名，并为特定领域的部署提供了可行的指导。所有资源均公开发布，以促进可重现的T2I评估。

Abstract: We present VISTAR, a user-centric, multi-dimensional benchmark for
text-to-image (T2I) evaluation that addresses the limitations of existing
metrics. VISTAR introduces a two-tier hybrid paradigm: it employs
deterministic, scriptable metrics for physically quantifiable attributes (e.g.,
text rendering, lighting) and a novel Hierarchical Weighted P/N Questioning
(HWPQ) scheme that uses constrained vision-language models to assess abstract
semantics (e.g., style fusion, cultural fidelity). Grounded in a Delphi study
with 120 experts, we defined seven user roles and nine evaluation angles to
construct the benchmark, which comprises 2,845 prompts validated by over 15,000
human pairwise comparisons. Our metrics achieve high human alignment (>75%),
with the HWPQ scheme reaching 85.9% accuracy on abstract semantics,
significantly outperforming VQA baselines. Comprehensive evaluation of
state-of-the-art models reveals no universal champion, as role-weighted scores
reorder rankings and provide actionable guidance for domain-specific
deployment. All resources are publicly released to foster reproducible T2I
assessment.

</details>


### [65] [An Interpretable Multi-Plane Fusion Framework With Kolmogorov-Arnold Network Guided Attention Enhancement for Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2508.06157)
*Xiaoxiao Yang,Meiliang Liu,Yunfang Xu,Zijin Li,Zhengye Si,Xinyue Yang,Zhiwen Zhao*

Main category: cs.CV

TL;DR: 提出MPF-KANSC框架，通过多平面融合和KANSC注意力机制，提高了sMRI在阿尔茨海默病诊断中的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法主要关注结构磁共振成像（sMRI）的单一平面，难以准确捕捉病变区域之间复杂且非在线性的关系，从而限制了其识别萎缩特征的能力。

Method: 提出了一种创新的框架MPF-KANSC，它整合了多平面融合（MPF）以结合来自冠状面、矢状面和轴状面的特征，并利用了Kolmogorov-Arnold网络引导的空间通道注意力机制（KANSC），以更有效地学习和表征sMRI萎缩特征。

Result: MPF-KANSC能够从多个解剖平面并行提取特征，捕捉更全面的结构信息。KANSC注意力机制利用更灵活和准确的非线性函数逼近技术，能够精确识别和定位与疾病相关的异常。

Conclusion: MPF-KANSC在ADNI数据集的实验表明其在AD诊断方面取得了优越的性能，并且该模型揭示了右侧不对称性在AD进展的内侧结构变化中的作用，证明了其良好的可解释性。

Abstract: Alzheimer's disease (AD) is a progressive neurodegenerative disorder that
severely impairs cognitive function and quality of life. Timely intervention in
AD relies heavily on early and precise diagnosis, which remains challenging due
to the complex and subtle structural changes in the brain. Most existing deep
learning methods focus only on a single plane of structural magnetic resonance
imaging (sMRI) and struggle to accurately capture the complex and nonlinear
relationships among pathological regions of the brain, thus limiting their
ability to precisely identify atrophic features. To overcome these limitations,
we propose an innovative framework, MPF-KANSC, which integrates multi-plane
fusion (MPF) for combining features from the coronal, sagittal, and axial
planes, and a Kolmogorov-Arnold Network-guided spatial-channel attention
mechanism (KANSC) to more effectively learn and represent sMRI atrophy
features. Specifically, the proposed model enables parallel feature extraction
from multiple anatomical planes, thus capturing more comprehensive structural
information. The KANSC attention mechanism further leverages a more flexible
and accurate nonlinear function approximation technique, facilitating precise
identification and localization of disease-related abnormalities. Experiments
on the ADNI dataset confirm that the proposed MPF-KANSC achieves superior
performance in AD diagnosis. Moreover, our findings provide new evidence of
right-lateralized asymmetry in subcortical structural changes during AD
progression, highlighting the model's promising interpretability.

</details>


### [66] [Fewer Denoising Steps or Cheaper Per-Step Inference: Towards Compute-Optimal Diffusion Model Deployment](https://arxiv.org/abs/2508.06160)
*Zhenbang Du,Yonggan Fu,Lifu Wang,Jiayi Qian,Xiao Luo,Yingyan,Lin*

Main category: cs.CV

TL;DR: PostDiff通过混合分辨率去噪和模块缓存策略，在训练后加速扩散模型，并在效率和保真度之间取得了更好的平衡，尤其是在降低每步推理成本方面效果更佳。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成任务中表现出色，但高计算需求限制了其在资源有限平台上的部署。该研究旨在解决一个关键问题：在训练后（无微调）设置下，是减少去噪步数还是使用更便宜的每步推理更有效？

Method: 提出PostDiff框架，包含混合分辨率去噪方案（通过在早期去噪步骤中降低生成分辨率来增强低频分量和提高最终生成保真度）和混合模块缓存策略（跨去噪步骤重用计算），在训练后（无微调）加速预训练扩散模型。

Result: PostDiff能显著改善最先进扩散模型的保真度-效率权衡。在提高效率同时保持可接受的生成保真度方面，降低每步推理成本比减少去噪步数更有效。

Conclusion: 该研究提出了一种名为PostDiff的训练无关框架，用于在训练后加速预训练的扩散模型，通过在输入和模块层面减少冗余来实现。实验结果表明，PostDiff能显著改善最先进扩散模型的保真度-效率权衡。研究还发现，为了在保持可接受生成保真度的同时提高效率，降低每步推理成本通常比减少去噪步数更有效。

Abstract: Diffusion models have shown remarkable success across generative tasks, yet
their high computational demands challenge deployment on resource-limited
platforms. This paper investigates a critical question for compute-optimal
diffusion model deployment: Under a post-training setting without fine-tuning,
is it more effective to reduce the number of denoising steps or to use a
cheaper per-step inference? Intuitively, reducing the number of denoising steps
increases the variability of the distributions across steps, making the model
more sensitive to compression. In contrast, keeping more denoising steps makes
the differences smaller, preserving redundancy, and making post-training
compression more feasible. To systematically examine this, we propose PostDiff,
a training-free framework for accelerating pre-trained diffusion models by
reducing redundancy at both the input level and module level in a post-training
manner. At the input level, we propose a mixed-resolution denoising scheme
based on the insight that reducing generation resolution in early denoising
steps can enhance low-frequency components and improve final generation
fidelity. At the module level, we employ a hybrid module caching strategy to
reuse computations across denoising steps. Extensive experiments and ablation
studies demonstrate that (1) PostDiff can significantly improve the
fidelity-efficiency trade-off of state-of-the-art diffusion models, and (2) to
boost efficiency while maintaining decent generation fidelity, reducing
per-step inference cost is often more effective than reducing the number of
denoising steps. Our code is available at
https://github.com/GATECH-EIC/PostDiff.

</details>


### [67] [UW-3DGS: Underwater 3D Reconstruction with Physics-Aware Gaussian Splatting](https://arxiv.org/abs/2508.06169)
*Wenpeng Xing,Jie Chen,Zaifeng Yang,Changting Lin,Jianfeng Dong,Chaochao Chen,Xun Zhou,Meng Han*

Main category: cs.CV

TL;DR: UW-3DGS使用3D高斯泼溅技术，通过学习水下成像模型和剪枝伪影，有效解决了水下三维重建的难题，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的水下三维场景重建方法（如NeRF及其扩展）在处理光线吸收、散射和浊度等问题时面临挑战，并且MLP的限制影响了效率和空间分辨率。因此，需要一种更高效、更精确的水下重建方法。

Method: UW-3DGS框架结合了可学习的水下成像模块（基于体素回归）和物理感知不确定性剪枝（PAUP）分支，优化高斯泼溅以处理水下光线吸收、散射和浊度问题，生成无伪影的几何和逼真的水下图像。

Result: UW-3DGS在SeaThru-NeRF数据集上实现了27.604的PSNR、0.868的SSIM和0.104的LPIPS，并将浮动伪影减少了约65%，展示了其在水下三维重建方面的优越性能。

Conclusion: UW-3DGS通过引入可学习的水下成像模型和物理感知不确定性剪枝，在3D高斯泼溅的基础上实现了鲁棒的水下三维场景重建，并在SeaThru-NeRF和UWBundle数据集上取得了优于现有方法的性能。

Abstract: Underwater 3D scene reconstruction faces severe challenges from light
absorption, scattering, and turbidity, which degrade geometry and color
fidelity in traditional methods like Neural Radiance Fields (NeRF). While NeRF
extensions such as SeaThru-NeRF incorporate physics-based models, their MLP
reliance limits efficiency and spatial resolution in hazy environments. We
introduce UW-3DGS, a novel framework adapting 3D Gaussian Splatting (3DGS) for
robust underwater reconstruction. Key innovations include: (1) a plug-and-play
learnable underwater image formation module using voxel-based regression for
spatially varying attenuation and backscatter; and (2) a Physics-Aware
Uncertainty Pruning (PAUP) branch that adaptively removes noisy floating
Gaussians via uncertainty scoring, ensuring artifact-free geometry. The
pipeline operates in training and rendering stages. During training, noisy
Gaussians are optimized end-to-end with underwater parameters, guided by PAUP
pruning and scattering modeling. In rendering, refined Gaussians produce clean
Unattenuated Radiance Images (URIs) free from media effects, while learned
physics enable realistic Underwater Images (UWIs) with accurate light
transport. Experiments on SeaThru-NeRF and UWBundle datasets show superior
performance, achieving PSNR of 27.604, SSIM of 0.868, and LPIPS of 0.104 on
SeaThru-NeRF, with ~65% reduction in floating artifacts.

</details>


### [68] [Synthetic Data-Driven Multi-Architecture Framework for Automated Polyp Segmentation Through Integrated Detection and Mask Generation](https://arxiv.org/abs/2508.06170)
*Ojonugwa Oluwafemi Ejiga Peter,Akingbola Oluwapemiisin,Amalahu Chetachi,Adeniran Opeyemi,Fahmi Khalifa,Md Mahmudur Rahman*

Main category: cs.CV

TL;DR: 本研究提出了一种结合Stable Diffusion、Faster R-CNN和SAM的多方向框架，用于自动检测和分割结肠镜图像中的息肉，以解决数据集限制问题。研究结果表明，该框架在息肉检测方面表现出色，并且FPN、U-Net和LinkNet在分割任务的不同指标上各有优势。


<details>
  <summary>Details</summary>
Motivation: 结直肠癌是全球主要的癌症相关死亡原因之一，而结肠镜检查是早期诊断的关键工具。然而，医疗数据集的规模有限和注释的复杂性给自动化息肉检测带来了挑战。本研究旨在通过引入创新的多方向架构框架来解决这些问题，以自动化结肠镜图像中的息肉检测。

Method: 该研究提出了一种多方向架构框架，结合了生成模型（Stable Diffusion）来生成合成数据，以及检测和分割算法（Faster R-CNN和Segment Anything Model (SAM)）来自动检测结肠息肉。Faster R-CNN用于对象定位，SAM用于细化分割掩码。此外，研究还评估了五种最先进的分割模型（U-Net, PSPNet, FPN, LinkNet, MANet），并使用ResNet34作为基础模型进行了比较。

Result: Faster R-CNN检测算法实现了93.08%的召回率、88.97%的精确率和90.98%的F1分数。在分割模型评估中，FPN在PSNR（7.205893）和SSIM（0.492381）方面表现最佳，U-Net在召回率（84.85%）方面表现最佳，LinkNet在IoU（64.20%）和Dice分数（77.53%）方面表现均衡。

Conclusion: FPN在PSNR和SSIM方面表现最佳，U-Net在召回率方面表现最佳，LinkNet在IoU和Dice分数方面表现均衡，表明在处理结肠镜图像的分割任务时，不同的模型具有各自的优势。

Abstract: Colonoscopy is a vital tool for the early diagnosis of colorectal cancer,
which is one of the main causes of cancer-related mortality globally; hence, it
is deemed an essential technique for the prevention and early detection of
colorectal cancer. The research introduces a unique multidirectional
architectural framework to automate polyp detection within colonoscopy images
while helping resolve limited healthcare dataset sizes and annotation
complexities. The research implements a comprehensive system that delivers
synthetic data generation through Stable Diffusion enhancements together with
detection and segmentation algorithms. This detection approach combines Faster
R-CNN for initial object localization while the Segment Anything Model (SAM)
refines the segmentation masks. The faster R-CNN detection algorithm achieved a
recall of 93.08% combined with a precision of 88.97% and an F1 score of
90.98%.SAM is then used to generate the image mask. The research evaluated five
state-of-the-art segmentation models that included U-Net, PSPNet, FPN, LinkNet,
and MANet using ResNet34 as a base model. The results demonstrate the superior
performance of FPN with the highest scores of PSNR (7.205893) and SSIM
(0.492381), while UNet excels in recall (84.85%) and LinkNet shows balanced
performance in IoU (64.20%) and Dice score (77.53%).

</details>


### [69] [MA-CBP: A Criminal Behavior Prediction Framework Based on Multi-Agent Asynchronous Collaboration](https://arxiv.org/abs/2508.06189)
*Cheng Liu,Daou Zhang,Tingxu Liu,Yuhan Wang,Jinyang Chen,Yuexuan Li,Xinying Xiao,Chenbo Xin,Ziru Wang,Weichao Wu*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: With the acceleration of urbanization, criminal behavior in public scenes
poses an increasingly serious threat to social security. Traditional anomaly
detection methods based on feature recognition struggle to capture high-level
behavioral semantics from historical information, while generative approaches
based on Large Language Models (LLMs) often fail to meet real-time
requirements. To address these challenges, we propose MA-CBP, a criminal
behavior prediction framework based on multi-agent asynchronous collaboration.
This framework transforms real-time video streams into frame-level semantic
descriptions, constructs causally consistent historical summaries, and fuses
adjacent image frames to perform joint reasoning over long- and short-term
contexts. The resulting behavioral decisions include key elements such as event
subjects, locations, and causes, enabling early warning of potential criminal
activity. In addition, we construct a high-quality criminal behavior dataset
that provides multi-scale language supervision, including frame-level,
summary-level, and event-level semantic annotations. Experimental results
demonstrate that our method achieves superior performance on multiple datasets
and offers a promising solution for risk warning in urban public safety
scenarios.

</details>


### [70] [A Semantic Segmentation Algorithm for Pleural Effusion Based on DBIF-AUNet](https://arxiv.org/abs/2508.06191)
*Ruixiang Tang,Jianglong Qin,Mingda Zhang,Yan Song,Yi Wu,Wei Wu*

Main category: cs.CV

TL;DR: 提出DBIF-AUNet模型，通过双域特征解耦和分支交互注意力融合，解决了胸腔积液CT图像分割的挑战，分割精度得到显著提升。


<details>
  <summary>Details</summary>
Motivation: 目前的胸腔积液CT图像语义分割方法在处理相似灰度、模糊边缘和多变形态方面存在挑战，现有方法因直接特征连接导致语义鸿沟，难以应对多样化的图像变化和复杂边缘。

Method: 提出了一种名为DBIF-AUNet的双分支交互融合注意力模型，该模型包含一个密集嵌套的跳跃连接网络，并引入了双域特征解耦（DDFD）模块和分支交互注意力融合（BIAF）模块。DDFD模块正交解耦双域模块的功能以实现多尺度特征互补，BIAF模块动态加权并融合全局、局部和频带特征，此外，还实现了嵌套深度监督机制和分层自适应混合损失以处理类别不平衡。

Result: DBIF-AUNet在1,622张胸腔积液CT图像上实现了80.1%的IoU和89.0%的Dice得分，相比U-Net++和Swin-UNet分别提高了5.7%/2.7%和2.2%/1.5%。

Conclusion: DBIF-AUNet在分割复杂胸腔积液CT图像方面表现出显著优化，在1,622张图像上实现了80.1%的IoU和89.0%的Dice得分，优于U-Net++和Swin-UNet等先进模型。

Abstract: Pleural effusion semantic segmentation can significantly enhance the accuracy
and timeliness of clinical diagnosis and treatment by precisely identifying
disease severity and lesion areas. Currently, semantic segmentation of pleural
effusion CT images faces multiple challenges. These include similar gray levels
between effusion and surrounding tissues, blurred edges, and variable
morphology. Existing methods often struggle with diverse image variations and
complex edges, primarily because direct feature concatenation causes semantic
gaps. To address these challenges, we propose the Dual-Branch Interactive
Fusion Attention model (DBIF-AUNet). This model constructs a densely nested
skip-connection network and innovatively refines the Dual-Domain Feature
Disentanglement module (DDFD). The DDFD module orthogonally decouples the
functions of dual-domain modules to achieve multi-scale feature complementarity
and enhance characteristics at different levels. Concurrently, we design a
Branch Interaction Attention Fusion module (BIAF) that works synergistically
with the DDFD. This module dynamically weights and fuses global, local, and
frequency band features, thereby improving segmentation robustness.
Furthermore, we implement a nested deep supervision mechanism with hierarchical
adaptive hybrid loss to effectively address class imbalance. Through validation
on 1,622 pleural effusion CT images from Southwest Hospital, DBIF-AUNet
achieved IoU and Dice scores of 80.1% and 89.0% respectively. These results
outperform state-of-the-art medical image segmentation models U-Net++ and
Swin-UNet by 5.7%/2.7% and 2.2%/1.5% respectively, demonstrating significant
optimization in segmentation accuracy for complex pleural effusion CT images.

</details>


### [71] [LoRA in LoRA: Towards Parameter-Efficient Architecture Expansion for Continual Visual Instruction Tuning](https://arxiv.org/abs/2508.06202)
*Chang Che,Ziqi Wang,Pengwan Yang,Qi Wang,Hui Ma,Zenglin Shi*

Main category: cs.CV

TL;DR: LiLoRA 是一种高效的架构扩展方法，用于解决 MLLMs 在持续视觉指令调优 (CVIT) 中的灾难性遗忘问题，通过共享和低秩分解 LoRA 矩阵来减少参数开销，并使用稳定性损失来保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的架构扩展方法在为 MLLMs 的 CVIT 任务处理灾难性遗忘时，通常会扩展整个层，导致显著的参数开销和扩展性差。需要一种更高效的方法来解决这个问题。

Method: 提出了一种名为 LiLoRA 的高效架构扩展方法，用于 MLLMs 的 CVIT。LiLoRA 通过共享 LoRA 矩阵 A 来减少冗余，对矩阵 B 进行额外的低秩分解以最小化特定任务的参数，并引入了余弦正则化稳定性损失来保持共享表示随时间的一致性。

Result: 在多样化的 CVIT 基准测试上进行的大量实验表明，LiLoRA 在顺序任务学习方面始终 achieves 优越的性能，并且与现有方法相比，显著提高了参数效率。

Conclusion: LiLoRA 在解决 MLLMs 的 CVIT 场景下的灾难性遗忘问题上表现出优越的性能和参数效率，通过共享 LoRA 矩阵 A 并对矩阵 B 进行低秩分解，同时结合余弦正则化稳定性损失来保留共享表示的一致性。

Abstract: Continual Visual Instruction Tuning (CVIT) enables Multimodal Large Language
Models (MLLMs) to incrementally learn new tasks over time. However, this
process is challenged by catastrophic forgetting, where performance on
previously learned tasks deteriorates as the model adapts to new ones. A common
approach to mitigate forgetting is architecture expansion, which introduces
task-specific modules to prevent interference. Yet, existing methods often
expand entire layers for each task, leading to significant parameter overhead
and poor scalability. To overcome these issues, we introduce LoRA in LoRA
(LiLoRA), a highly efficient architecture expansion method tailored for CVIT in
MLLMs. LiLoRA shares the LoRA matrix A across tasks to reduce redundancy,
applies an additional low-rank decomposition to matrix B to minimize
task-specific parameters, and incorporates a cosine-regularized stability loss
to preserve consistency in shared representations over time. Extensive
experiments on a diverse CVIT benchmark show that LiLoRA consistently achieves
superior performance in sequential task learning while significantly improving
parameter efficiency compared to existing approaches.

</details>


### [72] [AnomalyMoE: Towards a Language-free Generalist Model for Unified Visual Anomaly Detection](https://arxiv.org/abs/2508.06203)
*Zhaopeng Gu,Bingke Zhu,Guibo Zhu,Yingying Chen,Wei Ge,Ming Tang,Jinqiao Wang*

Main category: cs.CV

TL;DR: A new universal anomaly detection framework, AnomalyMoE, uses a Mixture-of-Experts approach with hierarchical experts to detect various anomalies across different data types, achieving state-of-the-art results.


<details>
  <summary>Details</summary>
Motivation: Existing anomaly detection methods are often highly specialized and limited in generalizability, performing poorly outside their designated contexts. This work aims to overcome this limitation by proposing a novel and universal anomaly detection framework.

Method: AnomalyMoE employs a Mixture-of-Experts (MoE) architecture with three expert networks at the patch, component, and global levels, specialized in reconstructing features and identifying deviations at their designated semantic levels. It also includes an Expert Information Repulsion (EIR) module for expert diversity and an Expert Selection Balancing (ESB) module for comprehensive expert utilization.

Result: Experiments on 8 challenging datasets spanning industrial imaging, 3D point clouds, medical imaging, video surveillance, and logical anomaly detection demonstrate that AnomalyMoE establishes new state-of-the-art performance, significantly outperforming specialized methods in their respective domains.

Conclusion: AnomalyMoE, a novel universal anomaly detection framework based on a Mixture-of-Experts (MoE) architecture, establishes new state-of-the-art performance across diverse datasets, significantly outperforming specialized methods.

Abstract: Anomaly detection is a critical task across numerous domains and modalities,
yet existing methods are often highly specialized, limiting their
generalizability. These specialized models, tailored for specific anomaly types
like textural defects or logical errors, typically exhibit limited performance
when deployed outside their designated contexts. To overcome this limitation,
we propose AnomalyMoE, a novel and universal anomaly detection framework based
on a Mixture-of-Experts (MoE) architecture. Our key insight is to decompose the
complex anomaly detection problem into three distinct semantic hierarchies:
local structural anomalies, component-level semantic anomalies, and global
logical anomalies. AnomalyMoE correspondingly employs three dedicated expert
networks at the patch, component, and global levels, and is specialized in
reconstructing features and identifying deviations at its designated semantic
level. This hierarchical design allows a single model to concurrently
understand and detect a wide spectrum of anomalies. Furthermore, we introduce
an Expert Information Repulsion (EIR) module to promote expert diversity and an
Expert Selection Balancing (ESB) module to ensure the comprehensive utilization
of all experts. Experiments on 8 challenging datasets spanning industrial
imaging, 3D point clouds, medical imaging, video surveillance, and logical
anomaly detection demonstrate that AnomalyMoE establishes new state-of-the-art
performance, significantly outperforming specialized methods in their
respective domains.

</details>


### [73] [PA-HOI: A Physics-Aware Human and Object Interaction Dataset](https://arxiv.org/abs/2508.06205)
*Ruiyan Wang,Lin Zuo,Zonghao Lin,Qiang Wang,Zhengxue Cheng,Rong Xie,Jun Ling,Li Song*

Main category: cs.CV

TL;DR: PA-HOI数据集的建立是为了解决现有HOI数据集忽视物体物理属性对人体运动影响的问题。该数据集包含562个动作序列，涵盖了与不同3D物体交互的各种人体运动。通过将此数据集与现有运动生成方法相结合，研究证明了其在传递现实物理感知方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有HOI数据集主要关注交互的细节，忽视了物体物理属性对人类长期运动的影响，本研究旨在弥补这一差距。

Method: 本研究引入了PA-HOI动作捕捉数据集，该数据集包含562个人与物相互作用的动作序列，涵盖了不同性别的主体与35个不同大小、形状和重量的3D对象进行交互。

Result: PA-HOI数据集通过包含不同物体物理属性对人体姿势、速度、运动尺度和交互策略的影响，显著扩展了现有数据集的范围。

Conclusion: 该数据集通过整合现有运动生成方法，并验证其在转移现实物理感知方面的能力，证明了其在PA-HOI数据集上的适用性。

Abstract: The Human-Object Interaction (HOI) task explores the dynamic interactions
between humans and objects in physical environments, providing essential
biomechanical and cognitive-behavioral foundations for fields such as robotics,
virtual reality, and human-computer interaction. However, existing HOI data
sets focus on details of affordance, often neglecting the influence of physical
properties of objects on human long-term motion. To bridge this gap, we
introduce the PA-HOI Motion Capture dataset, which highlights the impact of
objects' physical attributes on human motion dynamics, including human posture,
moving velocity, and other motion characteristics. The dataset comprises 562
motion sequences of human-object interactions, with each sequence performed by
subjects of different genders interacting with 35 3D objects that vary in size,
shape, and weight. This dataset stands out by significantly extending the scope
of existing ones for understanding how the physical attributes of different
objects influence human posture, speed, motion scale, and interacting
strategies. We further demonstrate the applicability of the PA-HOI dataset by
integrating it with existing motion generation methods, validating its capacity
to transfer realistic physical awareness.

</details>


### [74] [TRUST: Leveraging Text Robustness for Unsupervised Domain Adaptation](https://arxiv.org/abs/2508.06452)
*Mattia Litrico,Mario Valerio Giuffrida,Sebastiano Battiato,Devis Tuia*

Main category: cs.CV

TL;DR: TRUST方法利用图像标题的鲁棒性来指导视觉模型的域适应。通过生成伪标签并根据标题质量估计其不确定性来优化分类损失。此外，提出了一种多模态软对比学习方法，利用标题来对齐视觉和语言特征空间，从而提高模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有无监督域适应（UDA）方法在处理复杂的地理域迁移（背景和物体外观差异显著）时效果不佳。语言模态被证明对这类复杂迁移更具鲁棒性，因此本研究旨在利用语言模态的鲁棒性来改进UDA模型。

Method: TRUST方法利用语言的鲁棒性来指导视觉模型的适应，通过生成伪标签（基于图像的标题）并结合新颖的、基于归一化CLIP相似度分数的伪标签不确定性估计策略来重新加权分类损失。此外，提出了一种多模态软对比学习损失，利用标题对齐视觉和语言特征空间，其中图像对同时作为正例和负例，其特征表示的吸引或排斥强度与标题的相似度成正比。

Result: 在经典（DomainNet）和复杂（GeoNet）域迁移任务上设定了新的最先进水平。

Conclusion: TRUST方法在经典（DomainNet）和复杂（GeoNet）域迁移任务上均超越了先前的方法，取得了新的最先进水平。

Abstract: Recent unsupervised domain adaptation (UDA) methods have shown great success
in addressing classical domain shifts (e.g., synthetic-to-real), but they still
suffer under complex shifts (e.g. geographical shift), where both the
background and object appearances differ significantly across domains. Prior
works showed that the language modality can help in the adaptation process,
exhibiting more robustness to such complex shifts. In this paper, we introduce
TRUST, a novel UDA approach that exploits the robustness of the language
modality to guide the adaptation of a vision model. TRUST generates
pseudo-labels for target samples from their captions and introduces a novel
uncertainty estimation strategy that uses normalised CLIP similarity scores to
estimate the uncertainty of the generated pseudo-labels. Such estimated
uncertainty is then used to reweight the classification loss, mitigating the
adverse effects of wrong pseudo-labels obtained from low-quality captions. To
further increase the robustness of the vision model, we propose a multimodal
soft-contrastive learning loss that aligns the vision and language feature
spaces, by leveraging captions to guide the contrastive training of the vision
model on target images. In our contrastive loss, each pair of images acts as
both a positive and a negative pair and their feature representations are
attracted and repulsed with a strength proportional to the similarity of their
captions. This solution avoids the need for hardly determining positive and
negative pairs, which is critical in the UDA setting. Our approach outperforms
previous methods, setting the new state-of-the-art on classical (DomainNet) and
complex (GeoNet) domain shifts. The code will be available upon acceptance.

</details>


### [75] [Interpretable Rheumatoid Arthritis Scoring via Anatomy-aware Multiple Instance Learning](https://arxiv.org/abs/2508.06218)
*Zhiyan Bo,Laura C. Coates,Bartlomiej W. Papiez*

Main category: cs.CV

TL;DR: 一种提高类风湿关节炎（RA）影像学评分（SvdH）预测效率和可解释性的新方法，通过AI模型达到了接近人类专家的准确度。


<details>
  <summary>Details</summary>
Motivation: 解决SvdH评分在临床实践中应用受限的复杂性和效率问题。

Method: 采用两种区域提取方案：1）对最有可能包含异常的图像图块进行采样；2）裁剪包含疾病相关关节的图像块。利用这些区域来训练基于注意力机制的多实例学习模型以进行SvdH评分预测。

Result: 提出的方法在SvdH评分预测方面达到了最先进的性能，最佳模型实现了0.943的皮尔逊相关系数（PCC）和15.73的均方根误差（RMSE），集成学习进一步将PCC提高到0.945，RMSE降低到15.57，性能与经验丰富的放射科医生相当（PCC = 0.97, RMSE = 18.75）。该管线能够识别解剖结构并基于此做出决策。

Conclusion: 本文提出了一种用于双手法片SvdH评分预测的可解释的图像级两阶段管线，结合了图像区域提取和基于注意力机制的多实例学习。

Abstract: The Sharp/van der Heijde (SvdH) score has been widely used in clinical trials
to quantify radiographic damage in Rheumatoid Arthritis (RA), but its
complexity has limited its adoption in routine clinical practice. To address
the inefficiency of manual scoring, this work proposes a two-stage pipeline for
interpretable image-level SvdH score prediction using dual-hand radiographs.
Our approach extracts disease-relevant image regions and integrates them using
attention-based multiple instance learning to generate image-level features for
prediction. We propose two region extraction schemes: 1) sampling image tiles
most likely to contain abnormalities, and 2) cropping patches containing
disease-relevant joints. With Scheme 2, our best individual score prediction
model achieved a Pearson's correlation coefficient (PCC) of 0.943 and a root
mean squared error (RMSE) of 15.73. Ensemble learning further boosted
prediction accuracy, yielding a PCC of 0.945 and RMSE of 15.57, achieving
state-of-the-art performance that is comparable to that of experienced
radiologists (PCC = 0.97, RMSE = 18.75). Finally, our pipeline effectively
identified and made decisions based on anatomical structures which clinicians
consider relevant to RA progression.

</details>


### [76] [TEFormer: Texture-Aware and Edge-Guided Transformer for Semantic Segmentation of Urban Remote Sensing Images](https://arxiv.org/abs/2508.06224)
*Guoyu Zhou,Jing Zhang,Yi Yan,Hui Zhang,Li Zhuo*

Main category: cs.CV

TL;DR: TEFormer通过纹理感知和边缘引导机制，解决了城市遥感图像语义分割中的模糊性和边缘复杂性问题，并在多个数据集上取得了优异的分割结果。


<details>
  <summary>Details</summary>
Motivation: 城市遥感图像（URSIs）的语义分割在城市规划和环境监测等应用中至关重要。然而，地理空间对象常常存在细微的纹理差异和相似的空间结构，容易导致语义模糊和分类错误。此外，不规则的对象形状、模糊的边界以及语义对象的重叠分布，使得边缘形态复杂多样，进一步增加了准确分割的难度。

Method: 提出了一种名为TEFormer（texture-aware and edge-guided Transformer）的方法，该方法整合了纹理感知和边缘引导机制。具体包括：1. 在编码器中设计了一个纹理感知模块（TaM），用于捕捉视觉上相似类别之间细微的纹理差异，增强语义区分度。2. 构建了一个边缘引导的三分支解码器（Eg3Head），用于保留局部边缘和细节，实现多尺度上下文感知。3. 设计了一个边缘引导的特征融合模块（EgFFM），用于融合上下文、细节和边缘信息，实现精细化的语义分割。

Result: TEFormer在Potsdam、Vaihingen和LoveDA数据集上分别实现了88.57%、81.46%和53.55%的mIoU，验证了其在URSI语义分割任务中的有效性。

Conclusion: TEFormer在Potsdam、Vaihingen和LoveDA数据集上分别实现了88.57%、81.46%和53.55%的mIoU，证明了其在城市遥感图像语义分割方面的有效性。

Abstract: Semantic segmentation of urban remote sensing images (URSIs) is crucial for
applications such as urban planning and environmental monitoring. However,
geospatial objects often exhibit subtle texture differences and similar spatial
structures, which can easily lead to semantic ambiguity and misclassification.
Moreover, challenges such as irregular object shapes, blurred boundaries, and
overlapping spatial distributions of semantic objects contribute to complex and
diverse edge morphologies, further complicating accurate segmentation. To
tackle these issues, we propose a texture-aware and edge-guided Transformer
(TEFormer) that integrates texture awareness and edge-guidance mechanisms for
semantic segmentation of URSIs. In the encoder, a texture-aware module (TaM) is
designed to capture fine-grained texture differences between visually similar
categories to enhance semantic discrimination. Then, an edge-guided tri-branch
decoder (Eg3Head) is constructed to preserve local edges and details for
multiscale context-awareness. Finally, an edge-guided feature fusion module
(EgFFM) is to fuse contextual and detail information with edge information to
realize refined semantic segmentation. Extensive experiments show that TEFormer
achieves mIoU of 88.57%, 81.46%, and 53.55% on the Potsdam, Vaihingen, and
LoveDA datasets, respectively, shows the effectiveness in URSI semantic
segmentation.

</details>


### [77] [WGAST: Weakly-Supervised Generative Network for Daily 10 m Land Surface Temperature Estimation via Spatio-Temporal Fusion](https://arxiv.org/abs/2508.06485)
*Sofiane Bouaziz,Adel Hafiane,Raphael Canals,Rachid Nedjai*

Main category: cs.CV

TL;DR: WGAST是一个创新的深度学习框架，通过融合Terra MODIS、Landsat 8和Sentinel-2数据，能够以10米分辨率精确估算每日地表温度（LST）。该方法在性能上优于现有技术，显著降低了RMSE并提高了SSIM，同时还能有效处理云层影响并捕捉精细的热量模式。


<details>
  <summary>Details</summary>
Motivation: 城市化、气候变化和农业压力增加了对精确、及时的环境监测的需求。地表温度（LST）是这一背景下的一个关键变量，并且是从遥感卫星中检索出来的。然而，这些系统在空间和时间分辨率之间存在权衡。虽然时空融合方法提供了有前景的解决方案，但很少有方法能够解决以10米分辨率估算每日LST的问题。

Method: 本文提出了一种名为WGAST的弱监督生成网络，用于通过Terra MODIS、Landsat 8和Sentinel-2的时空融合来估计每日10米LST。WGAST是第一个端到端的深度学习框架，采用条件生成对抗架构，其生成器包括四个阶段：特征提取、融合、LST重建和噪声抑制。该网络采用基于物理平均原理的弱监督策略进行训练，并通过PatchGAN判别器进行增强。

Result: WGAST是第一个端到端的深度学习框架，用于通过Terra MODIS、Landsat 8和Sentinel-2的时空融合来估计每日10米LST。实验证明，WGAST在定性和定量评估中均优于现有方法，平均RMSE降低了17.18%，SSIM提高了11.00%。此外，WGAST对云引起的LST具有鲁棒性，并能有效捕获精细尺度的热模式，已通过33个地面传感器得到验证。

Conclusion: WGAST在定性和定量评估中均优于现有方法，与性能最佳的基线相比，平均RMSE降低了17.18%，SSIM提高了11.00%。此外，WGAST对云引起的LST具有鲁棒性，并能有效捕获精细尺度的热模式，已通过33个地面传感器得到验证。

Abstract: Urbanization, climate change, and agricultural stress are increasing the
demand for precise and timely environmental monitoring. Land Surface
Temperature (LST) is a key variable in this context and is retrieved from
remote sensing satellites. However, these systems face a trade-off between
spatial and temporal resolution. While spatio-temporal fusion methods offer
promising solutions, few have addressed the estimation of daily LST at 10 m
resolution. In this study, we present WGAST, a Weakly-Supervised Generative
Network for Daily 10 m LST Estimation via Spatio-Temporal Fusion of Terra
MODIS, Landsat 8, and Sentinel-2. WGAST is the first end-to-end deep learning
framework designed for this task. It adopts a conditional generative
adversarial architecture, with a generator composed of four stages: feature
extraction, fusion, LST reconstruction, and noise suppression. The first stage
employs a set of encoders to extract multi-level latent representations from
the inputs, which are then fused in the second stage using cosine similarity,
normalization, and temporal attention mechanisms. The third stage decodes the
fused features into high-resolution LST, followed by a Gaussian filter to
suppress high-frequency noise. Training follows a weakly supervised strategy
based on physical averaging principles and reinforced by a PatchGAN
discriminator. Experiments demonstrate that WGAST outperforms existing methods
in both quantitative and qualitative evaluations. Compared to the
best-performing baseline, on average, WGAST reduces RMSE by 17.18% and improves
SSIM by 11.00%. Furthermore, WGAST is robust to cloud-induced LST and
effectively captures fine-scale thermal patterns, as validated against 33
ground-based sensors. The code is available at
https://github.com/Sofianebouaziz1/WGAST.git.

</details>


### [78] [Towards Unified Image Deblurring using a Mixture-of-Experts Decoder](https://arxiv.org/abs/2508.06228)
*Daniel Feijoo,Paula Garrido-Mellado,Jaesung Rim,Alvaro Garcia,Marcos V. Conde*

Main category: cs.CV

TL;DR: 提出了一种用于图像去模糊的混合专家（MoE）方法，可处理多种模糊类型，性能优越且具有良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的图像去模糊方法通常针对特定的模糊类型，缺乏泛化能力，这在许多实际场景中并不实用。

Method: 提出了一种所有功能于一身的图像去模糊方法，并引入了一种混合专家（MoE）解码模块，该模块根据识别出的模糊退化动态地路由图像特征，从而能够以端到端的方式进行精确高效的恢复。

Result: 该方法是第一个能够有效恢复受各种模糊退化影响的图像的所有功能于一身的去模糊方法，在常见的和未知的模糊退化场景中均表现出色。

Conclusion: 该方法在各种模糊退化（包括全局运动、局部运动、弱光模糊和失焦模糊）下实现了与专用模型相当的性能，并对未知的模糊退化场景表现出出色的鲁棒性和泛化能力。

Abstract: Image deblurring, removing blurring artifacts from images, is a fundamental
task in computational photography and low-level computer vision. Existing
approaches focus on specialized solutions tailored to particular blur types,
thus, these solutions lack generalization. This limitation in current methods
implies requiring multiple models to cover several blur types, which is not
practical in many real scenarios. In this paper, we introduce the first
all-in-one deblurring method capable of efficiently restoring images affected
by diverse blur degradations, including global motion, local motion, blur in
low-light conditions, and defocus blur. We propose a mixture-of-experts (MoE)
decoding module, which dynamically routes image features based on the
recognized blur degradation, enabling precise and efficient restoration in an
end-to-end manner. Our unified approach not only achieves performance
comparable to dedicated task-specific models, but also demonstrates remarkable
robustness and generalization capabilities on unseen blur degradation
scenarios.

</details>


### [79] [Deepfake Detection that Generalizes Across Benchmarks](https://arxiv.org/abs/2508.06248)
*Andrii Yermakov,Jan Cech,Jiri Matas,Mario Fritz*

Main category: cs.CV

TL;DR: LNCLIP-DF通过微调CLIP模型的Layer Normalization参数，实现了高效且泛化能力强的深度伪造检测，优于现有复杂方法。


<details>
  <summary>Details</summary>
Motivation: 深度伪造检测模型泛化到未见操纵技术的挑战，以及现有方法通常引入显著架构复杂性的不足。

Method: LNCLIP-DF微调预训练CLIP模型的Layer Normalization参数（仅占总参数的0.03%），并采用L2归一化和潜在空间增强来强制执行超球特征流形。

Result: LNCLIP-DF在13个基准数据集上取得了最先进的性能，平均跨数据集AUROC优于更复杂、近期的其他方法。研究还发现，在同一源视频的配对真实/伪造数据上进行训练对于缓解捷径学习和提高泛化能力至关重要；并且检测难度并非随时间严格增加，在早期、多样化数据集上训练的模型表现出强大的泛化能力。

Conclusion: 该研究提出了一种名为LNCLIP-DF的参数高效方法，通过微调预训练CLIP模型的Layer Normalization参数，并结合L2归一化和潜在空间增强来强制执行超球特征流形，从而在深度伪造检测中实现了对未见操纵技术的鲁棒泛化。该方法在13个基准数据集上取得了最先进的性能，平均跨数据集AUROC优于更复杂的方法。

Abstract: The generalization of deepfake detectors to unseen manipulation techniques
remains a challenge for practical deployment. Although many approaches adapt
foundation models by introducing significant architectural complexity, this
work demonstrates that robust generalization is achievable through a
parameter-efficient adaptation of a pre-trained CLIP vision encoder. The
proposed method, LNCLIP-DF, fine-tunes only the Layer Normalization parameters
(0.03% of the total) and enhances generalization by enforcing a hyperspherical
feature manifold using L2 normalization and latent space augmentations.
  We conducted an extensive evaluation on 13 benchmark datasets spanning from
2019 to 2025. The proposed method achieves state-of-the-art performance,
outperforming more complex, recent approaches in average cross-dataset AUROC.
Our analysis yields two primary findings for the field: 1) training on paired
real-fake data from the same source video is essential for mitigating shortcut
learning and improving generalization, and 2) detection difficulty on academic
datasets has not strictly increased over time, with models trained on older,
diverse datasets showing strong generalization capabilities.
  This work delivers a computationally efficient and reproducible method,
proving that state-of-the-art generalization is attainable by making targeted,
minimal changes to a pre-trained CLIP model. The code will be made publicly
available upon acceptance.

</details>


### [80] [FedX: Explanation-Guided Pruning for Communication-Efficient Federated Learning in Remote Sensing](https://arxiv.org/abs/2508.06256)
*Barış Büyüktaş,Jonas Klotz,Begüm Demir*

Main category: cs.CV

TL;DR: FedX通过基于解释的剪枝来减少联邦学习中的通信开销，同时保持甚至提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）虽然适用于偏远地区的数据分类任务，但模型更新的频繁交换会导致通信开销过大。

Method: FedX提出了一种利用基于反向传播的解释方法来估计模型组件任务相关性的新策略，并裁剪掉相关性最低的组件，从而减少通信开销并最小化传输模型的大小。

Result: FedX在多标签场景分类（BigEarthNet-S2数据集）和单标签场景分类（EuroSAT数据集）任务上进行了评估，实验结果表明FedX成功地减少了共享模型参数的数量，并提高了全局模型的泛化能力。

Conclusion: FedX能够显著减少共享模型参数数量，并提高全局模型的泛化能力，优于未剪枝模型和最先进的剪枝方法。

Abstract: Federated learning (FL) enables the collaborative training of deep neural
networks across decentralized data archives (i.e., clients), where each client
stores data locally and only shares model updates with a central server. This
makes FL a suitable learning paradigm for remote sensing (RS) image
classification tasks, where data centralization may be restricted due to legal
and privacy constraints. However, a key challenge in applying FL to RS tasks is
the communication overhead caused by the frequent exchange of large model
updates between clients and the central server. To address this issue, in this
paper we propose a novel strategy (denoted as FedX) that uses
explanation-guided pruning to reduce communication overhead by minimizing the
size of the transmitted models without compromising performance. FedX leverages
backpropagation-based explanation methods to estimate the task-specific
importance of model components and prunes the least relevant ones at the
central server. The resulting sparse global model is then sent to clients,
substantially reducing communication overhead. We evaluate FedX on multi-label
scene classification using the BigEarthNet-S2 dataset and single-label scene
classification using the EuroSAT dataset. Experimental results show the success
of FedX in significantly reducing the number of shared model parameters while
enhancing the generalization capability of the global model, compared to both
unpruned model and state-of-the-art pruning methods. The code of FedX will be
available at https://git.tu-berlin.de/rsim/FedX.

</details>


### [81] [SIFThinker: Spatially-Aware Image Focus for Visual Reasoning](https://arxiv.org/abs/2508.06259)
*Zhangquan Chen,Ruihui Zhao,Chuwei Luo,Mingze Sun,Xinlei Yu,Yangyang Kang,Ruqi Huang*

Main category: cs.CV

TL;DR: SIFThinker通过结合深度增强边界框和自然语言来改进多模态大语言模型在空间理解和细粒度感知方面的能力。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在复杂的视觉任务（例如空间理解、细粒度感知）方面仍然面临重大挑战，现有方法未能利用空间线索的注意力校正来迭代地优化其对提示相关区域的关注。

Method: SIFThinker通过交错深度增强的边界框和自然语言来实现注意力校正和图像区域聚焦。我们引入了一种反向扩展前向推理策略来生成交错的图像-文本思维链，并提出了GRPO-SIF，一种将深度信息视觉基础整合到统一推理管道中的强化训练范式。

Result: SIFThinker在空间理解和细粒度视觉感知方面表现优于最先进的方法。

Conclusion: SIFThinker在空间理解和细粒度视觉感知方面超越了最先进的方法，同时保持了强大的通用能力，突显了我们方法的有效性。

Abstract: Current multimodal large language models (MLLMs) still face significant
challenges in complex visual tasks (e.g., spatial understanding, fine-grained
perception). Prior methods have tried to incorporate visual reasoning, however,
they fail to leverage attention correction with spatial cues to iteratively
refine their focus on prompt-relevant regions. In this paper, we introduce
SIFThinker, a spatially-aware "think-with-images" framework that mimics human
visual perception. Specifically, SIFThinker enables attention correcting and
image region focusing by interleaving depth-enhanced bounding boxes and natural
language. Our contributions are twofold: First, we introduce a
reverse-expansion-forward-inference strategy that facilitates the generation of
interleaved image-text chains of thought for process-level supervision, which
in turn leads to the construction of the SIF-50K dataset. Besides, we propose
GRPO-SIF, a reinforced training paradigm that integrates depth-informed visual
grounding into a unified reasoning pipeline, teaching the model to dynamically
correct and focus on prompt-relevant regions. Extensive experiments demonstrate
that SIFThinker outperforms state-of-the-art methods in spatial understanding
and fine-grained visual perception, while maintaining strong general
capabilities, highlighting the effectiveness of our method.

</details>


### [82] [XAG-Net: A Cross-Slice Attention and Skip Gating Network for 2.5D Femur MRI Segmentation](https://arxiv.org/abs/2508.06258)
*Byunghyun Ko,Anning Tian,Jeongkyu Lee*

Main category: cs.CV

TL;DR: XAG-Net improves femur MRI segmentation using a 2.5D U-Net with cross-slice and skip attention mechanisms, achieving higher accuracy than existing methods.


<details>
  <summary>Details</summary>
Motivation: Accurate segmentation of femur structures from MRI is critical for orthopedic diagnosis and surgical planning but is challenging for existing methods.

Method: XAG-Net, a novel 2.5D U-Net-based architecture incorporating pixel-wise cross-slice attention (CSA) and skip attention gating (AG) mechanisms.

Result: XAG-Net surpasses baseline 2D, 2.5D, and 3D U-Net models in femur segmentation accuracy. Ablation studies validate the critical role of CSA and AG modules.

Conclusion: XAG-Net is a promising framework for efficient and accurate femur MRI segmentation, outperforming baseline models in accuracy while maintaining computational efficiency.

Abstract: Accurate segmentation of femur structures from Magnetic Resonance Imaging
(MRI) is critical for orthopedic diagnosis and surgical planning but remains
challenging due to the limitations of existing 2D and 3D deep learning-based
segmentation approaches. In this study, we propose XAG-Net, a novel 2.5D
U-Net-based architecture that incorporates pixel-wise cross-slice attention
(CSA) and skip attention gating (AG) mechanisms to enhance inter-slice
contextual modeling and intra-slice feature refinement. Unlike previous
CSA-based models, XAG-Net applies pixel-wise softmax attention across adjacent
slices at each spatial location for fine-grained inter-slice modeling.
Extensive evaluations demonstrate that XAG-Net surpasses baseline 2D, 2.5D, and
3D U-Net models in femur segmentation accuracy while maintaining computational
efficiency. Ablation studies further validate the critical role of the CSA and
AG modules, establishing XAG-Net as a promising framework for efficient and
accurate femur MRI segmentation.

</details>


### [83] [Uncertainty-quantified Rollout Policy Adaptation for Unlabelled Cross-domain Temporal Grounding](https://arxiv.org/abs/2508.06317)
*Jian Hu,Zixu Cheng,Shaogang Gong,Isabel Guan,Jianye Hao,Jun Wang,Kun Shao*

Main category: cs.CV

TL;DR: 提出了一种名为URPA的数据高效无标签跨域视频时序定位方法，解决了现有方法需要有标签数据和计算开销大的问题，能够在仅使用少量无标签视频的情况下实现有效的跨域迁移。


<details>
  <summary>Details</summary>
Motivation: 现有的视频时序定位（TG）方法虽然在语义匹配上有效，但在细粒度的时间定位上存在不足。基于强化学习的GRPO方法虽然能实现细粒度定位，但需要有标签数据，且在大规模视频上进行全域自适应会导致过高的延迟和计算开销，不适用于实时部署。因此，需要一种无需目标域标签且计算开销低的数据高效的跨域时序定位方法。

Method: 首先在有标签的源域上训练模型，然后使用目标域中少量无标签视频进行自适应。具体来说，引入了不确定性量化的Rollout策略自适应（URPA）方法，通过生成多个候选预测，计算其方差得到置信度，并利用该置信度对训练奖励进行加权，引导模型关注可靠的监督。

Result: URPA方法能够实现数据高效的无标签跨域视频时序定位，能够有效处理目标域无标签数据，并且计算和存储开销低，适用于实时部署。

Conclusion: URPA方法在仅使用少量目标域的无标签视频时具有良好的泛化能力，并在三个数据集和六个跨域设置上进行了验证。

Abstract: Video Temporal Grounding (TG) aims to temporally locate video segments
matching a natural language description (a query) in a long video. While
Vision-Language Models (VLMs) are effective at holistic semantic matching, they
often struggle with fine-grained temporal localisation. Recently, Group
Relative Policy Optimisation (GRPO) reformulates the inference process as a
reinforcement learning task, enabling fine-grained grounding and achieving
strong in-domain performance. However, GRPO relies on labelled data, making it
unsuitable in unlabelled domains. Moreover, because videos are large and
expensive to store and process, performing full-scale adaptation introduces
prohibitive latency and computational overhead, making it impractical for
real-time deployment. To overcome both problems, we introduce a Data-Efficient
Unlabelled Cross-domain Temporal Grounding method, from which a model is first
trained on a labelled source domain, then adapted to a target domain using only
a small number of unlabelled videos from the target domain. This approach
eliminates the need for target annotation and keeps both computational and
storage overhead low enough to run in real time. Specifically, we introduce.
Uncertainty-quantified Rollout Policy Adaptation (URPA) for cross-domain
knowledge transfer in learning video temporal grounding without target labels.
URPA generates multiple candidate predictions using GRPO rollouts, averages
them to form a pseudo label, and estimates confidence from the variance across
these rollouts. This confidence then weights the training rewards, guiding the
model to focus on reliable supervision. Experiments on three datasets across
six cross-domain settings show that URPA generalises well using only a few
unlabelled target videos. Codes will be released once published.

</details>


### [84] [Mixture of Experts Guided by Gaussian Splatters Matters: A new Approach to Weakly-Supervised Video Anomaly Detection](https://arxiv.org/abs/2508.06318)
*Giacomo D'Amicantonio,Snehashis Majhi,Quan Kong,Lorenzo Garattoni,Gianpiero Francesca,François Bremond,Egor Bondarev*

Main category: cs.CV

TL;DR: GS-MoE通过专家模型处理不同异常类型并利用时间高斯泼溅损失进行指导，解决了弱监督视频异常检测中的多样性和时间信息不足的问题，并在多个数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决视频异常检测（VAD）任务中异常事件的多样性和标记数据有限的问题，特别是现有模型在处理复杂现实世界事件（如入店行窃）方面的不足。现有模型无法解决异常类型的多样性，并且弱监督信号缺乏精确的时间信息，限制了捕捉细微异常模式的能力。

Method: 提出了一种名为高斯泼溅引导混合专家（GS-MoE）的新颖框架，该框架采用了一组专家模型，每个模型都专门用于捕捉特定类型的异常。这些专家模型通过时间高斯泼溅损失进行引导，使模型能够利用时间一致性并加强弱监督。高斯泼溅方法通过关注最有可能包含异常事件的时间段，鼓励更精确和全面的异常表示。通过混合专家机制整合这些专业专家的预测，以模拟跨不同异常模式的复杂关系。

Result: GS-MoE 框架在 UCF-Crime 数据集上取得了 91.58% 的 AUC，并在 XD-Violence 和 MSAD 数据集上取得了优越的结果，达到了最先进的性能。

Conclusion: GS-MoE 框架通过利用特定类别的专业知识和时间指导，为弱监督下的视频异常检测树立了新的基准，在 UCF-Crime 数据集上取得了 91.58% 的 AUC，并在 XD-Violence 和 MSAD 数据集上取得了优越的结果。

Abstract: Video Anomaly Detection (VAD) is a challenging task due to the variability of
anomalous events and the limited availability of labeled data. Under the
Weakly-Supervised VAD (WSVAD) paradigm, only video-level labels are provided
during training, while predictions are made at the frame level. Although
state-of-the-art models perform well on simple anomalies (e.g., explosions),
they struggle with complex real-world events (e.g., shoplifting). This
difficulty stems from two key issues: (1) the inability of current models to
address the diversity of anomaly types, as they process all categories with a
shared model, overlooking category-specific features; and (2) the weak
supervision signal, which lacks precise temporal information, limiting the
ability to capture nuanced anomalous patterns blended with normal events. To
address these challenges, we propose Gaussian Splatting-guided Mixture of
Experts (GS-MoE), a novel framework that employs a set of expert models, each
specialized in capturing specific anomaly types. These experts are guided by a
temporal Gaussian splatting loss, enabling the model to leverage temporal
consistency and enhance weak supervision. The Gaussian splatting approach
encourages a more precise and comprehensive representation of anomalies by
focusing on temporal segments most likely to contain abnormal events. The
predictions from these specialized experts are integrated through a
mixture-of-experts mechanism to model complex relationships across diverse
anomaly patterns. Our approach achieves state-of-the-art performance, with a
91.58% AUC on the UCF-Crime dataset, and demonstrates superior results on
XD-Violence and MSAD datasets. By leveraging category-specific expertise and
temporal guidance, GS-MoE sets a new benchmark for VAD under weak supervision.

</details>


### [85] [Can Diffusion Models Bridge the Domain Gap in Cardiac MR Imaging?](https://arxiv.org/abs/2508.06327)
*Xin Ci Wong,Duygu Sarikaya,Kieran Zucker,Marc De Kamps,Nishant Ravikumar*

Main category: cs.CV

TL;DR: 提出了一种使用扩散模型生成心脏MR图像的方法，以解决域转移问题，并在多中心心脏MR分割中验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 磁共振（MR）成像，包括心脏MR，由于成像设备和采集方案的变化，容易出现域转移。这种挑战限制了所训练的AI模型在现实场景中的部署，因为在未见过的域上的性能会下降。

Method: 提出了一种扩散模型（DM），该模型在源域上进行训练，可以生成类似于给定参考的心脏MR图像。该合成数据保持了空间和结构保真度，确保与源域的相似性以及与分割掩码的兼容性。

Result: 与仅在真实数据上训练分割模型相比，两种策略（域泛化和域自适应）在未见过的目标域上的分割性能（根据基于表面的度量，Welch's t检验，p < 0.01）得到了显著改善。

Conclusion: 该生成方法改善了对心脏MR图像分析中域转移问题的处理，在数据稀疏的情况下尤其有用，并能改善需要转移学习或在线训练以解决域转移问题的需求。

Abstract: Magnetic resonance (MR) imaging, including cardiac MR, is prone to domain
shift due to variations in imaging devices and acquisition protocols. This
challenge limits the deployment of trained AI models in real-world scenarios,
where performance degrades on unseen domains. Traditional solutions involve
increasing the size of the dataset through ad-hoc image augmentation or
additional online training/transfer learning, which have several limitations.
Synthetic data offers a promising alternative, but anatomical/structural
consistency constraints limit the effectiveness of generative models in
creating image-label pairs. To address this, we propose a diffusion model (DM)
trained on a source domain that generates synthetic cardiac MR images that
resemble a given reference. The synthetic data maintains spatial and structural
fidelity, ensuring similarity to the source domain and compatibility with the
segmentation mask. We assess the utility of our generative approach in
multi-centre cardiac MR segmentation, using the 2D nnU-Net, 3D nnU-Net and
vanilla U-Net segmentation networks. We explore domain generalisation, where,
domain-invariant segmentation models are trained on synthetic source domain
data, and domain adaptation, where, we shift target domain data towards the
source domain using the DM. Both strategies significantly improved segmentation
performance on data from an unseen target domain, in terms of surface-based
metrics (Welch's t-test, p < 0.01), compared to training segmentation models on
real data alone. The proposed method ameliorates the need for transfer learning
or online training to address domain shift challenges in cardiac MR image
analysis, especially useful in data-scarce settings.

</details>


### [86] [ViPro-2: Unsupervised State Estimation via Integrated Dynamics for Guiding Video Prediction](https://arxiv.org/abs/2508.06335)
*Patrick Takenaka,Johannes Maucher,Marco F. Huber*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Predicting future video frames is a challenging task with many downstream
applications. Previous work has shown that procedural knowledge enables deep
models for complex dynamical settings, however their model ViPro assumed a
given ground truth initial symbolic state. We show that this approach led to
the model learning a shortcut that does not actually connect the observed
environment with the predicted symbolic state, resulting in the inability to
estimate states given an observation if previous states are noisy. In this
work, we add several improvements to ViPro that enables the model to correctly
infer states from observations without providing a full ground truth state in
the beginning. We show that this is possible in an unsupervised manner, and
extend the original Orbits dataset with a 3D variant to close the gap to real
world scenarios.

</details>


### [87] [Are you In or Out (of gallery)? Wisdom from the Same-Identity Crowd](https://arxiv.org/abs/2508.06357)
*Aman Bhatta,Maria Dhakal,Michael C. King,Kevin W. Bowyer*

Main category: cs.CV

TL;DR: 本研究提出了一种新的方法，利用身份的附加注册图像以及排名第一的结果来预测排名第一的结果是 In-gallery 还是 Out-of-gallery。通过提取与排名第一的身份相对应的附加注册图像的排名来生成 In-gallery 和 Out-of-gallery 训练数据。然后训练一个分类器来利用这个特征向量来预测排名第一的结果是 In-gallery 还是 Out-of-gallery。该方法在两个不同的数据集和四个不同的匹配器上进行了实验，证明了该方法对于 the mugshot quality probe images 是可行的，并且对于 the probe images 进行了模糊，降低了分辨率，大气湍流和太阳镜的退化也是可行的。此外，还分析了跨不同人群的结果，发现 In-gallery / Out-of-gallery 的分类准确性在不同人群之间相似。该方法有潜力提供对 one-to-many 面部识别是否为 Out-of-gallery 的客观估计，从而减少错误识别，错误的逮捕和浪费的调查时间。有趣的是，将旧的基于 CNN 的人脸匹配器与新的匹配器的结果进行比较表明，我们的 Out-of-gallery 检测方法的有效性仅在使用了基于高级边界损失函数进行训练的匹配器中才出现。


<details>
  <summary>Details</summary>
Motivation: 在 one-to-many 面部识别中，探针图像中的人物可能在库中有注册图像，也可能没有注册图像，即可能在库中或不在库中。过去检测排名第一的结果是否为 Out-of-gallery 的方法主要集中在寻找相似性分数的合适阈值。

Method: 本研究提出了一种新方法，利用身份的附加注册图像以及排名第一的结果来预测排名第一的结果是 In-gallery 还是 Out-of-gallery。通过提取与排名第一的身份相对应的附加注册图像的排名来生成 In-gallery 和 Out-of-gallery 训练数据。然后训练一个分类器来利用这个特征向量来预测排名第一的结果是 In-gallery 还是 Out-of-gallery。

Result: 研究结果表明，该方法对于 the mugshot quality probe images 是可行的，并且对于 the probe images 进行了模糊，降低了分辨率，大气湍流和太阳镜的退化也是可行的。此外，分析了跨不同人群的结果，发现 In-gallery / Out-of-gallery 的分类准确性在不同人群之间相似。有趣的是，将旧的基于 CNN 的人脸匹配器与新的匹配器的结果进行比较表明，我们的 Out-of-gallery 检测方法的有效性仅在使用了基于高级边界损失函数进行训练的匹配器中才出现。

Conclusion: 该方法在两个不同的数据集和四个不同的匹配器上进行了实验，证明了该方法对于 the mugshot quality probe images 是可行的，并且对于 the probe images 进行了模糊，降低了分辨率，大气湍流和太阳镜的退化也是可行的。此外，还分析了跨不同人群的结果，发现 In-gallery / Out-of-gallery 的分类准确性在不同人群之间相似。该方法有潜力提供对 one-to-many 面部识别是否为 Out-of-gallery 的客观估计，从而减少错误识别，错误的逮捕和浪费的调查时间。

Abstract: A central problem in one-to-many facial identification is that the person in
the probe image may or may not have enrolled image(s) in the gallery; that is,
may be In-gallery or Out-of-gallery. Past approaches to detect when a rank-one
result is Out-of-gallery have mostly focused on finding a suitable threshold on
the similarity score. We take a new approach, using the additional enrolled
images of the identity with the rank-one result to predict if the rank-one
result is In-gallery / Out-of-gallery. Given a gallery of identities and
images, we generate In-gallery and Out-of-gallery training data by extracting
the ranks of additional enrolled images corresponding to the rank-one identity.
We then train a classifier to utilize this feature vector to predict whether a
rank-one result is In-gallery or Out-of-gallery. Using two different datasets
and four different matchers, we present experimental results showing that our
approach is viable for mugshot quality probe images, and also, importantly, for
probes degraded by blur, reduced resolution, atmospheric turbulence and
sunglasses. We also analyze results across demographic groups, and show that
In-gallery / Out-of-gallery classification accuracy is similar across
demographics. Our approach has the potential to provide an objective estimate
of whether a one-to-many facial identification is Out-of-gallery, and thereby
to reduce false positive identifications, wrongful arrests, and wasted
investigative time. Interestingly, comparing the results of older deep
CNN-based face matchers with newer ones suggests that the effectiveness of our
Out-of-gallery detection approach emerges only with matchers trained using
advanced margin-based loss functions.

</details>


### [88] [Aligning Effective Tokens with Video Anomaly in Large Language Models](https://arxiv.org/abs/2508.06350)
*Yingxian Chen,Jiahui Liu,Ruifan Di,Yanwei Li,Chirui Chang,Shizhen Zhao,Wilton W. T. Fok,Xiaojuan Qi,Yik-Chung Wu*

Main category: cs.CV

TL;DR: 提出了一种名为VA-GPT的新型多模态大语言模型，通过SETS和TETG模块有效处理视频中的异常事件，并在多个基准测试中取得领先成果。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有MLLM在处理异常事件时因空间和时间稀疏性以及冗余信息导致的次优结果的挑战，利用VLM和LLM的表示和泛化能力。

Method: 提出了一种名为VA-GPT的新型多模态大语言模型（MLLM），该模型利用视觉语言模型（VLM）和大型语言模型（LLM）的表示和泛化能力。通过空间有效令牌选择（SETS）和时间有效令牌生成（TETG）两个关键模块，有效地将视觉编码器和LLM之间的有效令牌进行对齐，从而捕获和分析与异常事件相关的空间和时间信息。此外，构建了一个专门用于微调视频异常感知MLLM的指令遵循数据集，并引入了一个基于XD-Violence数据集的跨域评估基准。

Result: 所提出的方法在各种基准测试中，包括XD-Violence数据集，表现优于现有的最先进方法，能够更准确地响应和交互。

Conclusion: VA-GPT在各种基准测试中表现优于现有的最先进方法，能够准确地对异常事件做出响应和交互。

Abstract: Understanding abnormal events in videos is a vital and challenging task that
has garnered significant attention in a wide range of applications. Although
current video understanding Multi-modal Large Language Models (MLLMs) are
capable of analyzing general videos, they often struggle to handle anomalies
due to the spatial and temporal sparsity of abnormal events, where the
redundant information always leads to suboptimal outcomes. To address these
challenges, exploiting the representation and generalization capabilities of
Vison Language Models (VLMs) and Large Language Models (LLMs), we propose
VA-GPT, a novel MLLM designed for summarizing and localizing abnormal events in
various videos. Our approach efficiently aligns effective tokens between visual
encoders and LLMs through two key proposed modules: Spatial Effective Token
Selection (SETS) and Temporal Effective Token Generation (TETG). These modules
enable our model to effectively capture and analyze both spatial and temporal
information associated with abnormal events, resulting in more accurate
responses and interactions. Furthermore, we construct an instruction-following
dataset specifically for fine-tuning video-anomaly-aware MLLMs, and introduce a
cross-domain evaluation benchmark based on XD-Violence dataset. Our proposed
method outperforms existing state-of-the-art methods on various benchmarks.

</details>


### [89] [An Implemention of Two-Phase Image Segmentation using the Split Bregman Method](https://arxiv.org/abs/2508.06351)
*Olakunle S. Abawonse,Günay Doğan*

Main category: cs.CV

TL;DR: 该论文实现了一种两阶段图像分割算法，该算法将图像像素分配给前景或背景区域，并使用分裂Bregman方法进行优化。


<details>
  <summary>Details</summary>
Motivation: 该模型假设像素值可以由两个不同的平均值以及平滑的区域边界来概括。

Method: 使用 Goldstein、Bresson 和 Osher 提出的两阶段图像分割算法，该算法通过分裂Bregman方法进行最小化。

Result: 通过对几个图像和一系列算法参数的性能进行文档化，提供了该方法的详细实现。

Conclusion: 该算法将2D图像的域分割为前景和背景区域，并为图像的每个像素分配一个成员资格。

Abstract: In this paper, we describe an implementation of the two-phase image
segmentation algorithm proposed by Goldstein, Bresson, Osher in
\cite{gold:bre}. This algorithm partitions the domain of a given 2d image into
foreground and background regions, and each pixel of the image is assigned
membership to one of these two regions. The underlying assumption for the
segmentation model is that the pixel values of the input image can be
summarized by two distinct average values, and that the region boundaries are
smooth. Accordingly, the model is defined as an energy in which the variable is
a region membership function to assign pixels to either region, originally
proposed by Chan and Vese in \cite{chan:vese}. This energy is the sum of image
data terms in the regions and a length penalty for region boundaries.
Goldstein, Bresson, Osher modify the energy of Chan-Vese in \cite{gold:bre} so
that their new energy can be minimized efficiently using the split Bregman
method to produce an equivalent two-phase segmentation. We provide a detailed
implementation of this method \cite{gold:bre}, and document its performance
with several images over a range of algorithm parameters.

</details>


### [90] [Text as Any-Modality for Zero-Shot Classification by Consistent Prompt Tuning](https://arxiv.org/abs/2508.06382)
*Xiangyu Wu,Feng Yu,Yang Yang,Jianfeng Lu*

Main category: cs.CV

TL;DR: TaAM-CPT 是一种利用文本数据处理多种模态（如视频、图像、音频）的 AI 模型。它不需要特定模态的标签数据，就能在各种任务上取得良好效果。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在多模态学习方面，要么严重依赖大规模的特定模态标签数据，要么针对单一模态进行定制。本研究旨在提出一种仅使用文本数据即可为无限模态构建通用表示模型的可扩展方法。

Method: TaAM-CPT 包含模态提示池、文本构建和来自预训练模型的模态对齐文本编码器，并通过设计类内和类间学习目标来协调不同模态的学习。

Result: TaAM-CPT 在跨越视频分类、图像分类和音频分类等多种模态的各种数据集上取得了领先的结果。

Conclusion: TaAM-CPT 是一种可扩展的方法，无需任何特定于模态的标签数据，即可为无限模态构建通用表示模型。

Abstract: The integration of prompt tuning with multimodal learning has shown
significant generalization abilities for various downstream tasks. Despite
advancements, existing methods heavily depend on massive modality-specific
labeled data (e.g., video, audio, and image), or are customized for a single
modality. In this study, we present Text as Any-Modality by Consistent Prompt
Tuning (TaAM-CPT), a scalable approach for constructing a general
representation model toward unlimited modalities using solely text data.
TaAM-CPT comprises modality prompt pools, text construction, and
modality-aligned text encoders from pre-trained models, which allows for
extending new modalities by simply adding prompt pools and modality-aligned
text encoders. To harmonize the learning across different modalities, TaAM-CPT
designs intra- and inter-modal learning objectives, which can capture category
details within modalities while maintaining semantic consistency across
different modalities. Benefiting from its scalable architecture and pre-trained
models, TaAM-CPT can be seamlessly extended to accommodate unlimited
modalities. Remarkably, without any modality-specific labeled data, TaAM-CPT
achieves leading results on diverse datasets spanning various modalities,
including video classification, image classification, and audio classification.
The code is available at https://github.com/Jinx630/TaAM-CPT.

</details>


### [91] [FVGen: Accelerating Novel-View Synthesis with Adversarial Video Diffusion Distillation](https://arxiv.org/abs/2508.06392)
*Wenbin Teng,Gonglin Chen,Haiwei Chen,Yajie Zhao*

Main category: cs.CV

TL;DR: FVGen通过GAN和KL散度最小化蒸馏VDMs，实现快速新视点合成，比现有方法快90%，质量相当。


<details>
  <summary>Details</summary>
Motivation: 现有的基于视频扩散模型（VDMs）的三维重建方法在稀疏视图下虽然能生成更密集的观测，但采样速度慢，导致效率低下。

Method: 提出了一种新颖的视频扩散模型蒸馏方法，利用生成对抗网络（GANs）和软化反向KL散度最小化，将一个多步去噪教师模型蒸馏为一个少步去噪学生模型。

Result: FVGen框架能够在仅四个采样步骤内实现快速的新视点合成，与现有方法相比，在相同的视图数量下，视觉质量相似甚至更好，但采样时间减少了90%以上。

Conclusion: FVGen通过蒸馏技术显著提高了视频扩散模型（VDMs）的采样速度，在保证视觉质量的同时将采样时间缩短了90%以上，尤其在稀疏视图的三维重建任务中，其效率提升更为明显。

Abstract: Recent progress in 3D reconstruction has enabled realistic 3D models from
dense image captures, yet challenges persist with sparse views, often leading
to artifacts in unseen areas. Recent works leverage Video Diffusion Models
(VDMs) to generate dense observations, filling the gaps when only sparse views
are available for 3D reconstruction tasks. A significant limitation of these
methods is their slow sampling speed when using VDMs. In this paper, we present
FVGen, a novel framework that addresses this challenge by enabling fast novel
view synthesis using VDMs in as few as four sampling steps. We propose a novel
video diffusion model distillation method that distills a multi-step denoising
teacher model into a few-step denoising student model using Generative
Adversarial Networks (GANs) and softened reverse KL-divergence minimization.
Extensive experiments on real-world datasets show that, compared to previous
works, our framework generates the same number of novel views with similar (or
even better) visual quality while reducing sampling time by more than 90%.
FVGen significantly improves time efficiency for downstream reconstruction
tasks, particularly when working with sparse input views (more than 2) where
pre-trained VDMs need to be run multiple times to achieve better spatial
coverage.

</details>


### [92] [A Classification-Aware Super-Resolution Framework for Ship Targets in SAR Imagery](https://arxiv.org/abs/2508.06407)
*Ch Muhammad Awais,Marco Reggiannini,Davide Moroni,Oktay Karakus*

Main category: cs.CV

TL;DR: Integrating classification objectives into super-resolution improves accuracy for SAR imagery.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of low-resolution images in automated analysis and explore whether integrating classification objectives into the super-resolution process can improve classification accuracy.

Method: A novel methodology is proposed that optimizes loss functions considering both image quality and classification performance to increase the resolution of synthetic aperture radar imagery.

Result: The approach improves image quality, as measured by scientifically ascertained image quality indicators, while also enhancing classification accuracy.

Conclusion: The proposed method enhances both image quality and classification accuracy for SAR imagery.

Abstract: High-resolution imagery plays a critical role in improving the performance of
visual recognition tasks such as classification, detection, and segmentation.
In many domains, including remote sensing and surveillance, low-resolution
images can limit the accuracy of automated analysis. To address this,
super-resolution (SR) techniques have been widely adopted to attempt to
reconstruct high-resolution images from low-resolution inputs. Related
traditional approaches focus solely on enhancing image quality based on
pixel-level metrics, leaving the relationship between super-resolved image
fidelity and downstream classification performance largely underexplored. This
raises a key question: can integrating classification objectives directly into
the super-resolution process further improve classification accuracy? In this
paper, we try to respond to this question by investigating the relationship
between super-resolution and classification through the deployment of a
specialised algorithmic strategy. We propose a novel methodology that increases
the resolution of synthetic aperture radar imagery by optimising loss functions
that account for both image quality and classification performance. Our
approach improves image quality, as measured by scientifically ascertained
image quality indicators, while also enhancing classification accuracy.

</details>


### [93] [Feature-Space Oversampling for Addressing Class Imbalance in SAR Ship Classification](https://arxiv.org/abs/2508.06420)
*Ch Muhammad Awais,Marco Reggiannini,Davide Moroni,Oktay Karakus*

Main category: cs.CV

TL;DR: 通过特征空间过采样方法M2m_f和M2m_u，提升了SAR船舶分类中对少数类别的识别能力，在公开数据集上取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 解决SAR船舶分类中长尾数据集带来的欠代表类别分类困难的问题。

Method: 评估了过采样方法在特征空间中对SAR（合成孔径雷达）船舶分类的影响，并提出了两种新的算法M2m_f和M2m_u。

Result: 所提出的M2m_f和M2m_u算法在FuSARShip和OpenSARShip数据集上，相比原始M2m和基线方法，平均F1分数分别提高了8.82%和4.44%，验证了其有效性。

Conclusion: 提出的M2m_f和M2m_u算法在公开数据集OpenSARShip和FuSARShip上，以及在ViT、VGG16和ResNet50三种模型上，都显示出比原始M2m方法和基线方法更好的性能，分别在FuSARShip和OpenSARShip数据集上平均F1分数提高了8.82%和4.44%。

Abstract: SAR ship classification faces the challenge of long-tailed datasets, which
complicates the classification of underrepresented classes. Oversampling
methods have proven effective in addressing class imbalance in optical data. In
this paper, we evaluated the effect of oversampling in the feature space for
SAR ship classification. We propose two novel algorithms inspired by the
Major-to-minor (M2m) method M2m$_f$, M2m$_u$. The algorithms are tested on two
public datasets, OpenSARShip (6 classes) and FuSARShip (9 classes), using three
state-of-the-art models as feature extractors: ViT, VGG16, and ResNet50.
Additionally, we also analyzed the impact of oversampling methods on different
class sizes. The results demonstrated the effectiveness of our novel methods
over the original M2m and baselines, with an average F1-score increase of 8.82%
for FuSARShip and 4.44% for OpenSARShip.

</details>


### [94] [SPARSE Data, Rich Results: Few-Shot Semi-Supervised Learning via Class-Conditioned Image Translation](https://arxiv.org/abs/2508.06429)
*Guido Manni,Clemente Lauretti,Loredana Zollo,Paolo Soda*

Main category: cs.CV

TL;DR: 针对医学影像标记数据不足的问题，提出了一种新颖的基于GAN的半监督学习框架，通过集成生成器、判别器和分类器，并采用图像到图像翻译和伪标签技术，在极少标记样本下实现了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习在医学影像领域取得了革命性的进展，但其有效性受到标记训练数据不足的严重限制。因此，开发一种在标记数据稀少的环境下有效的方法至关重要。

Method: 本文提出了一种新颖的基于GAN的半监督学习框架，该框架集成了三个专门的神经网络——用于类别条件图像转换的生成器、用于真实性评估和分类的判别器以及一个专用的分类器——在一个三阶段的训练框架内。该方法在有限标记数据上的监督训练和利用丰富的未标记数据通过图像到图像翻译（而非从噪声生成）进行的无监督学习之间交替进行。我们采用基于集成（ensemble-based）的伪标签技术，结合了来自判别器和分类器的置信度加权预测以及通过指数移动平均（exponential moving averaging）实现的时间一致性，从而能够为未标记数据进行可靠的标签估计。

Result: 在十一个MedMNIST数据集上的综合评估表明，该方法在六种最先进的基于GAN的半监督方法上取得了统计学上的显著改进，尤其是在标记数据稀缺性最具挑战性的极端5-shot设置中表现强劲。该框架在所有评估设置（每个类别的5、10、20和50个样本）中均保持其优越性。

Conclusion: 该框架为标注成本高昂的医学影像应用提供了一个切实可行的解决方案，即使在标记数据很少的情况下也能实现稳健的分类性能。

Abstract: Deep learning has revolutionized medical imaging, but its effectiveness is
severely limited by insufficient labeled training data. This paper introduces a
novel GAN-based semi-supervised learning framework specifically designed for
low labeled-data regimes, evaluated across settings with 5 to 50 labeled
samples per class. Our approach integrates three specialized neural networks --
a generator for class-conditioned image translation, a discriminator for
authenticity assessment and classification, and a dedicated classifier --
within a three-phase training framework. The method alternates between
supervised training on limited labeled data and unsupervised learning that
leverages abundant unlabeled images through image-to-image translation rather
than generation from noise. We employ ensemble-based pseudo-labeling that
combines confidence-weighted predictions from the discriminator and classifier
with temporal consistency through exponential moving averaging, enabling
reliable label estimation for unlabeled data. Comprehensive evaluation across
eleven MedMNIST datasets demonstrates that our approach achieves statistically
significant improvements over six state-of-the-art GAN-based semi-supervised
methods, with particularly strong performance in the extreme 5-shot setting
where the scarcity of labeled data is most challenging. The framework maintains
its superiority across all evaluated settings (5, 10, 20, and 50 shots per
class). Our approach offers a practical solution for medical imaging
applications where annotation costs are prohibitive, enabling robust
classification performance even with minimal labeled data. Code is available at
https://github.com/GuidoManni/SPARSE.

</details>


### [95] [MotionSwap](https://arxiv.org/abs/2508.06430)
*Om Patil,Jinesh Modi,Suryabha Mukhopadhyay,Meghaditya Giri,Chhavi Malhotra*

Main category: cs.CV

TL;DR: 本研究通过引入自/交叉注意力、动态损失加权和余弦退火学习率调度等改进措施，增强了SimSwap面部交换框架，显著提高了身份保持、属性一致性和视觉质量，并在实验中得到了验证。


<details>
  <summary>Details</summary>
Motivation: 为了提升面部交换技术的效率和视觉保真度，并解决现有技术在身份保持、属性一致性和视觉质量方面存在的不足。

Method: 通过在生成器结构中集成自注意力和交叉注意力机制、动态损失加权以及余弦退火学习率调度等方法，对SimSwap进行了改进和实现。

Result: 实验结果（涵盖40万次训练迭代）显示，改进后的模型在身份相似性、FID得分和视觉质量方面优于基线模型，并且消融研究证实了各项改进的重要性。

Conclusion: 研究结果表明，所提出的改进能够显著提升面部交换技术的身份保持、属性一致性和视觉质量，并对未来的研究方向进行了展望，包括整合StyleGAN3、改进唇部同步、引入3D面部建模和视频应用中的时间一致性。

Abstract: Face swapping technology has gained significant attention in both academic
research and commercial applications. This paper presents our implementation
and enhancement of SimSwap, an efficient framework for high fidelity face
swapping. We introduce several improvements to the original model, including
the integration of self and cross-attention mechanisms in the generator
architecture, dynamic loss weighting, and cosine annealing learning rate
scheduling. These enhancements lead to significant improvements in identity
preservation, attribute consistency, and overall visual quality.
  Our experimental results, spanning 400,000 training iterations, demonstrate
progressive improvements in generator and discriminator performance. The
enhanced model achieves better identity similarity, lower FID scores, and
visibly superior qualitative results compared to the baseline. Ablation studies
confirm the importance of each architectural and training improvement. We
conclude by identifying key future directions, such as integrating StyleGAN3,
improving lip synchronization, incorporating 3D facial modeling, and
introducing temporal consistency for video-based applications.

</details>


### [96] [CLIPin: A Non-contrastive Plug-in to CLIP for Multimodal Semantic Alignment](https://arxiv.org/abs/2508.06434)
*Shengzhu Yang,Jiawei Du,Shuai Lu,Weihang Zhang,Ningli Wang,Huiqi Li*

Main category: cs.CV

TL;DR: CLIPin 是一种即插即用的非对比学习插件，可以增强 CLIP 模型的对齐能力和表示的稳健性，兼容对比学习框架，并在多种下游任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 网络收集的大规模自然图像-文本数据集由于弱监督而存在松散的语义对齐问题，而医学数据集则具有较高的跨模态相关性但内容多样性较低。这些特性给 CLIP 对比语言-图像预训练带来了共同的挑战，阻碍了模型学习稳健和可泛化的表示。

Method: 提出了一种统一的非对比插件 CLIPin，可以无缝集成到 CLIP 风格的架构中，以改进多模态语义对齐、提供更强的监督和增强对齐鲁棒性。设计了两个共享的预投影器，分别用于图像和文本模态，以参数折衷的方式促进对比学习和非对比学习的集成。

Result: CLIPin 能够改进多模态语义对齐、提供更强的监督和增强对齐鲁棒性。

Conclusion: CLIPin 作为一种即插即用的组件，可以兼容各种对比学习框架，并在各种下游任务中展现出有效性和通用性。

Abstract: Large-scale natural image-text datasets, especially those automatically
collected from the web, often suffer from loose semantic alignment due to weak
supervision, while medical datasets tend to have high cross-modal correlation
but low content diversity. These properties pose a common challenge for
contrastive language-image pretraining (CLIP): they hinder the model's ability
to learn robust and generalizable representations. In this work, we propose
CLIPin, a unified non-contrastive plug-in that can be seamlessly integrated
into CLIP-style architectures to improve multimodal semantic alignment,
providing stronger supervision and enhancing alignment robustness. Furthermore,
two shared pre-projectors are designed for image and text modalities
respectively to facilitate the integration of contrastive and non-contrastive
learning in a parameter-compromise manner. Extensive experiments on diverse
downstream tasks demonstrate the effectiveness and generality of CLIPin as a
plug-and-play component compatible with various contrastive frameworks. Code is
available at https://github.com/T6Yang/CLIPin.

</details>


### [97] [Text Embedded Swin-UMamba for DeepLesion Segmentation](https://arxiv.org/abs/2508.06453)
*Ruida Cheng,Tejas Sudharshan Mathai,Pritam Mukherjee,Benjamin Hou,Qingqing Zhu,Zhiyong Lu,Matthew McAuliffe,Ronald M. Summers*

Main category: cs.CV

TL;DR: 本研究提出了一种将文本信息整合到Swin-UMamba架构中的新方法（Text-Swin-UMamba），用于CT影像中的病灶分割。该方法在ULS23 DeepLesion数据集上取得了优于现有方法的成果，证明了结合文本信息在提高病灶分割精度方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 将大型语言模型（LLMs）集成到病灶分割流程中，可以结合影像特征和放射报告中的病灶特征描述，以提高临床评估的准确性。

Method: 本研究将文本信息整合到Swin-UMamba架构中，以执行病灶分割任务。使用公开的ULS23 DeepLesion数据集及其相关的简短病灶描述。

Result: 在测试数据集上，病灶分割达到了82%的Dice分数和6.58像素的Hausdorff距离。提出的Text-Swin-UMamba模型比之前的模型（LLM驱动的LanGuideMedSeg模型、纯图像的xLSTM-UNet和nnUNet模型）有显著提高。

Conclusion: 将文本信息与Swin-UMamba架构相结合，可以有效地用于CT影像中的病灶分割任务，并且在消融研究中证明了文本信息的价值。

Abstract: Segmentation of lesions on CT enables automatic measurement for clinical
assessment of chronic diseases (e.g., lymphoma). Integrating large language
models (LLMs) into the lesion segmentation workflow offers the potential to
combine imaging features with descriptions of lesion characteristics from the
radiology reports. In this study, we investigate the feasibility of integrating
text into the Swin-UMamba architecture for the task of lesion segmentation. The
publicly available ULS23 DeepLesion dataset was used along with short-form
descriptions of the findings from the reports. On the test dataset, a high Dice
Score of 82% and low Hausdorff distance of 6.58 (pixels) was obtained for
lesion segmentation. The proposed Text-Swin-UMamba model outperformed prior
approaches: 37% improvement over the LLM-driven LanGuideMedSeg model (p <
0.001),and surpassed the purely image-based xLSTM-UNet and nnUNet models by
1.74% and 0.22%, respectively. The dataset and code can be accessed at
https://github.com/ruida/LLM-Swin-UMamba

</details>


### [98] [LightSwitch: Multi-view Relighting with Material-guided Diffusion](https://arxiv.org/abs/2508.06494)
*Yehonathan Litman,Fernando De la Torre,Shubham Tulsiani*

Main category: cs.CV

TL;DR: LightSwitch通过结合多视图、材质信息和推断的内在属性，实现了高效且高质量的3D场景重光照，超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有2D图像重光照的生成先验方法在将2D先验集成到3D表示时，未能利用可推断的主体内在属性，也未能充分利用大规模多视图数据，导致重光照效果不佳。

Method: LightSwitch是一种新颖的、经过微调的材质重光照扩散框架，它结合了从推断的内在属性中提取的线索，能够将任意数量的输入图像高效地重新照亮到目标光照条件。该方法利用多视图和材质信息线索，并结合可扩展的去噪方案。

Result: LightSwitch能够持续高效地对具有多样化材质构成的对象的密集多视图数据进行重光照，其2D重光照预测质量超越了现有直接从图像进行重光照的先验技术，并且在重光照合成及真实对象时，性能与最先进的扩散逆渲染方法相当或更优。

Conclusion: LightSwitch在2D重光照预测质量上超越了现有技术，并且在重光照合成及真实对象时，性能与最先进的扩散逆渲染方法相当甚至更优，处理时间仅需2分钟。

Abstract: Recent approaches for 3D relighting have shown promise in integrating 2D
image relighting generative priors to alter the appearance of a 3D
representation while preserving the underlying structure. Nevertheless,
generative priors used for 2D relighting that directly relight from an input
image do not take advantage of intrinsic properties of the subject that can be
inferred or cannot consider multi-view data at scale, leading to subpar
relighting. In this paper, we propose Lightswitch, a novel finetuned
material-relighting diffusion framework that efficiently relights an arbitrary
number of input images to a target lighting condition while incorporating cues
from inferred intrinsic properties. By using multi-view and material
information cues together with a scalable denoising scheme, our method
consistently and efficiently relights dense multi-view data of objects with
diverse material compositions. We show that our 2D relighting prediction
quality exceeds previous state-of-the-art relighting priors that directly
relight from images. We further demonstrate that LightSwitch matches or
outperforms state-of-the-art diffusion inverse rendering methods in relighting
synthetic and real objects in as little as 2 minutes.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [99] [PEACH: A sentence-aligned Parallel English-Arabic Corpus for Healthcare](https://arxiv.org/abs/2508.05722)
*Rania Al-Sabbagh*

Main category: cs.CL

TL;DR: PEACH是一个公开的英文-阿拉伯文平行医疗文本语料库，包含51,671个句子对，可用于多种研究和教育目的。


<details>
  <summary>Details</summary>
Motivation: 为了提供一个用于对比语言学、翻译研究和自然语言处理的英文-阿拉伯文平行医疗文本语料库。

Method: 构建了一个包含51,671个句子对的英文-阿拉伯文平行医疗文本语料库，包含患者信息手册和教育材料。该语料库是手动对齐的，并在英文和阿拉伯文上分别包含约590,517和567,707个词标记。句子长度平均在9.52到11.83个单词之间。

Result: 构建了一个名为PEACH的平行语料库，包含51,671个句子对，可用于生成双语词典、定制大型语言模型、评估机器翻译的用户感知、评估患者信息和教育材料的可读性，并作为翻译研究的教学资源。

Conclusion: PEACH是一个包含51,671个句子对的已公开的英文-阿拉伯文平行医疗文本语料库，可用于对比语言学、翻译研究和自然语言处理，以生成双语词典、定制大型语言模型、评估机器翻译的用户感知、评估患者信息和教育材料的可读性，并作为翻译研究的教学资源。

Abstract: This paper introduces PEACH, a sentence-aligned parallel English-Arabic
corpus of healthcare texts encompassing patient information leaflets and
educational materials. The corpus contains 51,671 parallel sentences, totaling
approximately 590,517 English and 567,707 Arabic word tokens. Sentence lengths
vary between 9.52 and 11.83 words on average. As a manually aligned corpus,
PEACH is a gold-standard corpus, aiding researchers in contrastive linguistics,
translation studies, and natural language processing. It can be used to derive
bilingual lexicons, adapt large language models for domain-specific machine
translation, evaluate user perceptions of machine translation in healthcare,
assess patient information leaflets and educational materials' readability and
lay-friendliness, and as an educational resource in translation studies. PEACH
is publicly accessible.

</details>


### [100] [Guardians and Offenders: A Survey on Harmful Content Generation and Safety Mitigation](https://arxiv.org/abs/2508.05775)
*Chi Zhang,Changjia Zhu,Junjie Xiong,Xiaoran Xu,Lingyao Li,Yao Liu,Zhuo Lu*

Main category: cs.CL

TL;DR: LLM功能强大但存在风险，本综述梳理了相关研究、提出分类法、评估了防御措施，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: LLM在内容创作、问答、编程和代码推理等方面展现了前所未有的能力，但它们也可能产生有毒、冒犯或带有偏见的内容，带来严重的风险。因此，如何解决LLM带来的社会技术挑战是一个紧迫的问题。

Method: 本研究系统性地回顾了近期关于无意毒性、对抗性越狱攻击和内容审核技术的研究，并提出了LLM相关危害和防御的统一分类法，同时分析了新兴的多模态和LLM辅助越狱策略，并评估了包括人类反馈强化学习（RLHF）、提示工程和安全对齐在内的缓解措施。

Result: 研究综合分析了LLM安全性的演变情况，明确了当前评估方法的局限性，并为开发稳健且符合伦理的语言技术指明了未来的研究方向。

Conclusion: LLM在内容创作、问答、编程等领域具有革命性潜力，但也带来生成有害内容的风险。本研究系统回顾了LLM相关的毒性、越狱攻击和内容审核技术，提出了危害和防御的统一分类法，并评估了RLHF、提示工程和安全对齐等缓解措施。研究强调了LLM安全性的演变，指出了当前评估方法的局限性，并为开发稳健且符合伦理的语言技术规划了未来研究方向。

Abstract: Large Language Models (LLMs) have revolutionized content creation across
digital platforms, offering unprecedented capabilities in natural language
generation and understanding. These models enable beneficial applications such
as content generation, question and answering (Q&A), programming, and code
reasoning. Meanwhile, they also pose serious risks by inadvertently or
intentionally producing toxic, offensive, or biased content. This dual role of
LLMs, both as powerful tools for solving real-world problems and as potential
sources of harmful language, presents a pressing sociotechnical challenge. In
this survey, we systematically review recent studies spanning unintentional
toxicity, adversarial jailbreaking attacks, and content moderation techniques.
We propose a unified taxonomy of LLM-related harms and defenses, analyze
emerging multimodal and LLM-assisted jailbreak strategies, and assess
mitigation efforts, including reinforcement learning with human feedback
(RLHF), prompt engineering, and safety alignment. Our synthesis highlights the
evolving landscape of LLM safety, identifies limitations in current evaluation
methodologies, and outlines future research directions to guide the development
of robust and ethically aligned language technologies.

</details>


### [101] [FineDialFact: A benchmark for Fine-grained Dialogue Fact Verification](https://arxiv.org/abs/2508.05782)
*Xiangyan Chen,Yufeng Li,Yujian Gan,Arkaitz Zubiaga,Matthew Purver*

Main category: cs.CL

TL;DR: 该研究提出了FineDialFact基准测试，用于细粒度的对话事实验证，并构建了一个包含原子事实的数据集。实验表明CoT推理能提升性能，但仍有挑战性。


<details>
  <summary>Details</summary>
Motivation: LLM（大语言模型）会产生幻觉（即事实不准确或虚构的信息），这对对话系统等NLP应用构成了重大挑战。因此，检测幻觉已成为一个关键的研究领域。当前对话系统中的幻觉检测方法主要关注事实一致性验证，但这些响应通常包含准确、不准确或无法验证的事实的混合，使得单一的事实标签过于简化和粗粒度。

Method: 提出了一种名为FineDialFact的基准测试，用于细粒度的对话事实验证，该验证涉及从对话响应中提取的事实原子进行验证。构建了一个基于公开对话数据集的数据集，并使用各种基线方法进行了评估。

Result: 实验结果表明，包含链式思考（CoT）推理的方法可以提高对话事实验证的性能。

Conclusion: 尽管采用了链式思考（CoT）推理等方法，在HybriDialogue（一个开放域对话数据集）上的最佳F1分数仅为0.75，这表明该基准测试对于未来的研究仍然是一个挑战。

Abstract: Large Language Models (LLMs) are known to produce hallucinations - factually
incorrect or fabricated information - which poses significant challenges for
many Natural Language Processing (NLP) applications, such as dialogue systems.
As a result, detecting hallucinations has become a critical area of research.
Current approaches to hallucination detection in dialogue systems primarily
focus on verifying the factual consistency of generated responses. However,
these responses often contain a mix of accurate, inaccurate or unverifiable
facts, making one factual label overly simplistic and coarse-grained. In this
paper, we introduce a benchmark, FineDialFact, for fine-grained dialogue fact
verification, which involves verifying atomic facts extracted from dialogue
responses. To support this, we construct a dataset based on publicly available
dialogue datasets and evaluate it using various baseline methods. Experimental
results demonstrate that methods incorporating Chain-of-Thought (CoT) reasoning
can enhance performance in dialogue fact verification. Despite this, the best
F1-score achieved on the HybriDialogue, an open-domain dialogue dataset, is
only 0.75, indicating that the benchmark remains a challenging task for future
research. Our dataset and code will be public on GitHub.

</details>


### [102] [Human-like fleeting memory improves language learning but impairs reading time prediction in transformer language models](https://arxiv.org/abs/2508.05803)
*Abishek Thamma,Micha Heilbron*

Main category: cs.CL

TL;DR: 短期记忆限制有助于 Transformer 语言模型学习，但对预测人类阅读时间有负面影响。


<details>
  <summary>Details</summary>
Motivation: 探讨了在 Transformer 模型中引入短期记忆以解释其语言学习能力，并对比了其与人类记忆限制的潜在联系。

Method: 通过在 Transformer 语言模型上进行受控实验，对比了有无短期记忆对其语言学习能力的影响。

Result: 短期记忆能够提升 Transformer 语言模型的学习性能，但在预测人类阅读时间方面表现不佳，且现有理论无法完全解释这种现象。

Conclusion: 虽然记忆限制确实有助于提高 Transformer 语言模型的学习能力，但对人类阅读时间的预测能力却有所下降。

Abstract: Human memory is fleeting. As words are processed, the exact wordforms that
make up incoming sentences are rapidly lost. Cognitive scientists have long
believed that this limitation of memory may, paradoxically, help in learning
language - an idea supported by classic connectionist modelling work. The rise
of Transformers appears to challenge this idea, as these models can learn
language effectively, despite lacking memory limitations or other architectural
recency biases. Here, we investigate the hypothesized benefit of fleeting
memory for language learning in tightly controlled experiments on transformer
language models. Training transformers with and without fleeting memory on a
developmentally realistic training set, we find that fleeting memory
consistently improves language learning (as quantified by both overall language
modelling performance and targeted syntactic evaluation) but, unexpectedly,
impairs surprisal-based prediction of human reading times. Interestingly,
follow up analyses revealed that this discrepancy - better language modeling,
yet worse reading time prediction - could not be accounted for by prior
explanations of why better language models sometimes fit human reading time
worse. Together, these results support a benefit of memory limitations on
neural network language learning - but not on predicting behavior.

</details>


### [103] ["Mirror" Language AI Models of Depression are Criterion-Contaminated](https://arxiv.org/abs/2508.05830)
*Tong Li,Rasiq Hussain,Mehak Gupta,Joshua R. Oltmanns*

Main category: cs.CL

TL;DR: LLM models predicting depression are often flawed due to "criterion contamination" from using similar training data. This study shows "Mirror models" have inflated results but similar real-world performance to "Non-Mirror models", indicating bias. Non-Mirror models are more generalizable.


<details>
  <summary>Details</summary>
Motivation: Many existing LLM-based depression prediction models suffer from "criterion contamination" because they are trained on data that mirrors the assessment they are designed to predict. This leads to artificially inflated effect sizes and reduced generalizability. This study aims to address this by comparing "Mirror models" with "Non-Mirror models".

Method: This study compared the performance of "Mirror models" (trained on data mirroring the assessment) and "Non-Mirror models" (trained on dissimilar data). Three LLMs (GPT-4, GPT-4o, LLaMA3-70B) were used to predict depression scores from transcripts of diagnostic interviews and life history interviews. Performance was evaluated using R-squared values and correlations with self-reported depression symptoms. Topic modeling was also employed.

Result: Mirror models showed significantly larger effect sizes (e.g., R2 = .80) than Non-Mirror models (e.g., R2 = .27). However, when predicting depression scores, the Mirror and Non-Mirror models performed similarly when correlated with self-reported depression symptoms (e.g., r = ~.54), suggesting bias in the Mirror models potentially due to criterion contamination. Topic modeling revealed shared clusters across model types and prediction outcomes.

Conclusion: Mirror language AI models for depression demonstrate artificially inflated effect sizes and reduced generalizability compared to Non-Mirror models. Future research should consider Non-Mirror models to identify interpretable and generalizable semantic features for real-world psychological assessment.

Abstract: A growing number of studies show near-perfect LLM language-based prediction
of depression assessment scores (up to R2 of .70). However, many develop these
models directly from language responses to depression assessments. These
"Mirror models" suffer from "criterion contamination", which arises when a
predicted score depends in part on the predictors themselves. This causes
artificial effect size inflation which reduces model generalizability. The
present study compares the performance of Mirror models versus "Non-Mirror
models", which are developed from language that does not mirror the assessment
they are developed to predict. N = 110 research participants completed two
different interviews: structured diagnostic and life history interviews. GPT-4,
GPT-4o and LLaMA3-70B were then prompted to predict structured diagnostic
interview depression scores from the two transcripts separately. Mirror models
(using structured diagnostic data) showed very large effect sizes (e.g., R2 =
.80). As expected, NonMirror models (using life history data) demonstrated
smaller effect sizes, but were relatively large (e.g., R2 = .27). When Mirror
and Non-Mirror model-predicted structured interview depression scores were
correlated with self-reported depression symptoms, Mirror and NonMirror
performed the same (e.g., r = ~.54), indicating that Mirror models contain bias
perhaps due to criterion contamination. Topic modeling identified clusters
across Mirror and Non-Mirror models, as well as between true-positive and
false-positive predictions. In this head-to-head comparison study, Mirror
language AI models of depression showed artificially inflated effect sizes and
less generalizability. As language AI models for depression continue to evolve,
incorporating Non-Mirror models may identify interpretable, and generalizable
semantic features that have unique utility in real-world psychological
assessment.

</details>


### [104] [Discovering Properties of Inflectional Morphology in Neural Emergent Communication](https://arxiv.org/abs/2508.05843)
*Miles Gilberti,Shane Storks,Huteng Dai*

Main category: cs.CL

TL;DR: 本研究通过引入小词汇量约束和模拟屈折形态学，改进了 EmCom 研究的设置，并发现模拟的音系约束会促进连接形态，而新兴语言会融合语法属性。


<details>
  <summary>Details</summary>
Motivation: 现有 EmCom 研究过于关注特定子领域的目标和指标，例如一对一地表示属性并进行句法组合，这未能充分反映人类语言的复杂性。因此，我们需要新的方法和设置来更深入地理解语言的涌现机制。

Method: 我们重新诠释了属性-值重建游戏，引入了小词汇量约束以模拟双重构成，并提出了一个类似于自然屈折形态学的设置。我们还开发了新的指标，并探索了受屈折形态学特性的启发的游戏变体，如连接性和融合性。

Result: 实验结果显示，模拟的音系约束能够促进连接形态的出现。此外，实验中的新兴语言也表现出与自然语言相似的趋势，即融合了语法属性。

Conclusion: 通过模拟双重构成和形态学屈折，我们为新兴交流（EmCom）研究提供了一个更接近自然语言的视角，并提出了新的评估指标。实验表明，模拟的音系约束会促进连接形态，而新兴语言会体现出融合语法属性的自然语言趋势。

Abstract: Emergent communication (EmCom) with deep neural network-based agents promises
to yield insights into the nature of human language, but remains focused
primarily on a few subfield-specific goals and metrics that prioritize
communication schemes which represent attributes with unique characters
one-to-one and compose them syntactically. We thus reinterpret a common EmCom
setting, the attribute-value reconstruction game, by imposing a
small-vocabulary constraint to simulate double articulation, and formulating a
novel setting analogous to naturalistic inflectional morphology (enabling
meaningful comparison to natural language communication schemes). We develop
new metrics and explore variations of this game motivated by real properties of
inflectional morphology: concatenativity and fusionality. Through our
experiments, we discover that simulated phonological constraints encourage
concatenative morphology, and emergent languages replicate the tendency of
natural languages to fuse grammatical attributes.

</details>


### [105] [Harnessing Adaptive Topology Representations for Zero-Shot Graph Question Answering](https://arxiv.org/abs/2508.06345)
*Yanbin Wei,Jiangyue Yan,Chun Kang,Yang Chen,Hua Liu,James T. Kwok,Yu Zhang*

Main category: cs.CL

TL;DR: DynamicTRF框架通过动态选择最适合特定问题的图表示（TRF），提高了大型多模态模型（LMM）在零样本图问答任务中的准确性和响应简洁性。


<details>
  <summary>Details</summary>
Motivation: 现有的图QA方法主要使用单一类型的图表示（TRF），如统一文本描述或固定视觉样式，未能考虑不同模型或任务的特定偏好，导致响应不正确或冗长。为解决此问题，我们分析了现有TRF的特点和弱点，并设计了一套针对零样本图QA的TRF（$F_{ZS}$）。

Method: DynamicTRF框架首先创建一个TRF偏好（TRFP）数据集，该数据集根据GRE分数对TRF进行排序，以探究特定于问题的TRF偏好。然后，它在TRFP数据集上训练一个TRF路由器，以便在推理过程中为每个问题自适应地分配$F_{ZS}$中的最佳TRF。

Result: 在7个域内算法图QA任务和2个域外下游任务上的广泛实验表明，DynamicTRF在准确性方面显著增强了LMM的零样本图QA能力。

Conclusion: DynamicTRF框架通过创建TRF偏好（TRFP）数据集来评估不同TRF的优缺点，并训练一个TRF路由器来为每个问题自适应地分配最佳TRF，从而提高了零样本图QA的准确性和简洁性。

Abstract: Large Multimodal Models (LMMs) have shown generalized zero-shot capabilities
in diverse domain question-answering (QA) tasks, including graph QA that
involves complex graph topologies. However, most current approaches use only a
single type of graph representation, namely Topology Representation Form (TRF),
such as prompt-unified text descriptions or style-fixed visual styles. Those
"one-size-fits-all" approaches fail to consider the specific preferences of
different models or tasks, often leading to incorrect or overly long responses.
To address this, we first analyze the characteristics and weaknesses of
existing TRFs, and then design a set of TRFs, denoted by $F_{ZS}$, tailored to
zero-shot graph QA. We then introduce a new metric, Graph Response Efficiency
(GRE), which measures the balance between the performance and the brevity in
graph QA. Built on these, we develop the DynamicTRF framework, which aims to
improve both the accuracy and conciseness of graph QA. To be specific,
DynamicTRF first creates a TRF Preference (TRFP) dataset that ranks TRFs based
on their GRE scores, to probe the question-specific TRF preferences. Then it
trains a TRF router on the TRFP dataset, to adaptively assign the best TRF from
$F_{ZS}$ for each question during the inference. Extensive experiments across 7
in-domain algorithmic graph QA tasks and 2 out-of-domain downstream tasks show
that DynamicTRF significantly enhances the zero-shot graph QA of LMMs in terms
of accuracy

</details>


### [106] [Do Machines Think Emotionally? Cognitive Appraisal Analysis of Large Language Models](https://arxiv.org/abs/2508.05880)
*Sree Bhattacharyya,Lucas Craig,Tharun Dilliraj,Jia Li,James Z. Wang*

Main category: cs.CL

TL;DR: This paper explores how Large Language Models (LLMs) reason about emotions using cognitive dimensions, moving beyond traditional supervised methods. It introduces a benchmark (CoRE) to evaluate LLMs' internal cognitive structures for emotional reasoning, finding diverse patterns across models.


<details>
  <summary>Details</summary>
Motivation: Most existing studies on LLMs and emotion use supervised methods with discrete emotion labels and focus on superficial tasks like emotion recognition. This paper aims to go beyond surface-level emotion tasks to explore how LLMs reason about emotions through cognitive dimensions.

Method: The paper investigates LLMs' reasoning about emotions through cognitive dimensions, drawing from cognitive appraisal theory. It introduces a large-scale benchmark, CoRE, to evaluate internal cognitive structures used by LLMs for emotional reasoning through various evaluation experiments and analysis.

Result: The paper's results and analyses reveal diverse reasoning patterns across different LLMs concerning their implicit reliance on cognitive appraisal dimensions, the importance of these dimensions for specific emotions, and the interpretability of internal representations of emotion categories.

Conclusion: The study reveals diverse reasoning patterns across different LLMs regarding emotions through cognitive dimensions. The benchmark and code will be made publicly available.

Abstract: Affective Computing has been established as a crucial field of inquiry to
advance the holistic development of Artificial Intelligence (AI) systems.
Foundation models -- especially Large Language Models (LLMs) -- have been
evaluated, trained, or instruction-tuned in several past works, to become
better predictors or generators of emotion. Most of these studies, however,
approach emotion-related tasks in a supervised manner, assessing or training
the capabilities of LLMs using discrete emotion labels associated with stimuli
(e.g., text, images, video, audio). Evaluation studies, in particular, have
often been limited to standard and superficial emotion-related tasks, such as
the recognition of evoked or expressed emotions. In this paper, we move beyond
surface-level emotion tasks to investigate how LLMs reason about emotions
through cognitive dimensions. Drawing from cognitive appraisal theory, we
examine whether LLMs produce coherent and plausible cognitive reasoning when
reasoning about emotionally charged stimuli. We introduce a large-scale
benchmark on Cognitive Reasoning for Emotions - CoRE - to evaluate internal
cognitive structures implicitly used by LLMs for emotional reasoning. Through a
plethora of evaluation experiments and analysis, we seek to answer: (a) Are
models more likely to implicitly rely on specific cognitive appraisal
dimensions?, (b) What cognitive dimensions are important for characterizing
specific emotions?, and, (c) Can the internal representations of different
emotion categories in LLMs be interpreted through cognitive appraisal
dimensions? Our results and analyses reveal diverse reasoning patterns across
different LLMs. Our benchmark and code will be made publicly available.

</details>


### [107] [Scaling Personality Control in LLMs with Big Five Scaler Prompts](https://arxiv.org/abs/2508.06149)
*Gunhee Cho,Yun-Gyung Cheong*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We present Big5-Scaler, a prompt-based framework for conditioning large
language models (LLMs) with controllable Big Five personality traits. By
embedding numeric trait values into natural language prompts, our method
enables fine-grained personality control without additional training. We
evaluate Big5-Scaler across trait expression, dialogue generation, and human
trait imitation tasks. Results show that it induces consistent and
distinguishable personality traits across models, with performance varying by
prompt type and scale. Our analysis highlights the effectiveness of concise
prompts and lower trait intensities, providing a efficient approach for
building personality-aware dialogue agents.

</details>


### [108] [Spectrum Projection Score: Aligning Retrieved Summaries with Reader Models in Retrieval-Augmented Generation](https://arxiv.org/abs/2508.05909)
*Zhanghao Hu,Qinglin Zhu,Siya Qi,Yulan He,Hanqi Yan,Lin Gui*

Main category: cs.CL

TL;DR: 本研究提出了一种名为 Spectrum Projection Score (SPS) 的新度量标准，用于评估检索增强生成（RAG）中检索到的信息与语言模型之间的相关性。同时，还提出了一个名为 xCompress 的框架，用于优化 RAG 过程。实验结果表明，SPS 和 xCompress 能够提高 RAG 系统的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLMs）在检索增强生成（RAG）方面表现出改进的生成性能，但通常对 RAG 进行整体评估，难以分离检索的实际贡献，因为 LLMs 对提示很敏感。本研究旨在解决这一问题。

Method: Spectrum Projection Score (SPS) 通过比较由摘要生成的标记形成的区域与读者子空间的主方向来评估检索摘要与隐藏表示的语义一致性，并衡量相关性。xCompress 是一个推理时控制器框架，可以动态地对检索摘要候选进行采样、排序和压缩。

Result: 实验表明，SPS 不仅能提高各种任务的性能，还能为衡量检索和生成之间的交互提供一个有原则的视角。

Conclusion: Spectrum Projection Score (SPS) 是一种轻量级、无监督的度量标准，通过比较由摘要生成的标记形成的区域与读者子空间的主方向，来评估检索摘要与隐藏表示的语义一致性，并衡量相关性。基于 SPS，我们提出了 xCompress，一个推理时控制器框架，可以动态地对检索摘要候选进行采样、排序和压缩。

Abstract: Large Language Models (LLMs) have shown improved generation performance
through retrieval-augmented generation (RAG) following the retriever-reader
paradigm, which supplements model inputs with externally retrieved knowledge.
However, prior work often evaluates RAG holistically, assessing the retriever
and reader jointly, making it difficult to isolate the true contribution of
retrieval, particularly given the prompt sensitivity of LLMs used as readers.
We introduce Spectrum Projection Score (SPS), a lightweight, supervision-free
metric that allows the reader to gauge the semantic alignment of a retrieved
summary with its hidden representation by comparing the area formed by
generated tokens from the summary, and the principal directions of subspace in
the reader and to measure the relevance. Building on SPS we present xCompress,
an inference time controller framework that dynamically samples, ranks, and
compresses retrieval summary candidates. Extensive experiments on five QA
benchmarks with four open source LLMs show that SPS not only enhances
performance across a range of tasks but also provides a principled perspective
on the interaction between retrieval and generation.

</details>


### [109] [Prosocial Behavior Detection in Player Game Chat: From Aligning Human-AI Definitions to Efficient Annotation at Scale](https://arxiv.org/abs/2508.05938)
*Rafal Kocielnik,Min Kim,Penphob,Boonyarungsrit,Fereshteh Soltani,Deshawn Sambrano,Animashree Anandkumar,R. Michael Alvarez*

Main category: cs.CL

TL;DR: 通过结合人类智能和人工智能，并仔细设计系统架构，可以有效地检测文本中的亲社会性，同时降低成本。


<details>
  <summary>Details</summary>
Motivation: 检测文本中的亲社会性（旨在肯定、支持或改善他人行为的沟通）是信任和安全系统面临的新颖且日益重要的挑战。与有毒内容检测不同，亲社会性缺乏既定的定义和标记数据。

Method: 提出了一种实用的三阶段流程，包括基于 LLM 的标注策略选择、人类-AI 细化循环以及采用轻量级分类器和 GPT-4o 的两阶段推理系统。

Result: 该系统实现了约 0.90 的高精度，同时将推理成本降低了约 70%。

Conclusion: 该方法为新兴的负责任人工智能任务提供了一个可扩展的解决方案，它结合了人类与人工智能的互动、仔细的任务构建和面向部署的架构设计，以实现高精度的亲社会内容分类。

Abstract: Detecting prosociality in text--communication intended to affirm, support, or
improve others' behavior--is a novel and increasingly important challenge for
trust and safety systems. Unlike toxic content detection, prosociality lacks
well-established definitions and labeled data, requiring new approaches to both
annotation and deployment. We present a practical, three-stage pipeline that
enables scalable, high-precision prosocial content classification while
minimizing human labeling effort and inference costs. First, we identify the
best LLM-based labeling strategy using a small seed set of human-labeled
examples. We then introduce a human-AI refinement loop, where annotators review
high-disagreement cases between GPT-4 and humans to iteratively clarify and
expand the task definition-a critical step for emerging annotation tasks like
prosociality. This process results in improved label quality and definition
alignment. Finally, we synthesize 10k high-quality labels using GPT-4 and train
a two-stage inference system: a lightweight classifier handles high-confidence
predictions, while only $\sim$35\% of ambiguous instances are escalated to
GPT-4o. This architecture reduces inference costs by $\sim$70% while achieving
high precision ($\sim$0.90). Our pipeline demonstrates how targeted human-AI
interaction, careful task formulation, and deployment-aware architecture design
can unlock scalable solutions for novel responsible AI tasks.

</details>


### [110] [Memp: Exploring Agent Procedural Memory](https://arxiv.org/abs/2508.06433)
*Runnan Fang,Yuan Liang,Xiaobin Wang,Jialong Wu,Shuofei Qiao,Pengjun Xie,Fei Huang,Huajun Chen,Ningyu Zhang*

Main category: cs.CL

TL;DR: Memp通过提炼和动态更新程序化记忆，增强了LLM代理在处理新经验方面的能力，提高了任务成功率和效率，并且记忆的可迁移性也得到了验证。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的代理虽然擅长多种任务，但其程序化记忆脆弱，需要手动工程化或被固定在静态参数中。本研究旨在为代理提供可学习、可更新、终身制的程序化记忆。

Method: 提出Memp，将过去的代理轨迹提炼成细粒度的分步指令和更高级的脚本化抽象，并探索程序化记忆的构建、检索和更新策略。结合动态体制，持续更新、修正和弃用其内容，使其与新经验同步演进。

Result: 在TravelPlanner和ALFWorld上的实证评估表明，随着记忆库的完善，代理在类似任务上的成功率和效率稳步提高。此外，更强的模型构建的程序化记忆仍然有价值：将程序化记忆迁移到更弱的模型可以带来显著的性能提升。

Conclusion: LLM驱动的代理可以通过Memp学习、更新和维护程序化记忆，从而在类似任务上取得更高的成功率和效率。

Abstract: Large Language Models (LLMs) based agents excel at diverse tasks, yet they
suffer from brittle procedural memory that is manually engineered or entangled
in static parameters. In this work, we investigate strategies to endow agents
with a learnable, updatable, and lifelong procedural memory. We propose Memp
that distills past agent trajectories into both fine-grained, step-by-step
instructions and higher-level, script-like abstractions, and explore the impact
of different strategies for Build, Retrieval, and Update of procedural memory.
Coupled with a dynamic regimen that continuously updates, corrects, and
deprecates its contents, this repository evolves in lockstep with new
experience. Empirical evaluation on TravelPlanner and ALFWorld shows that as
the memory repository is refined, agents achieve steadily higher success rates
and greater efficiency on analogous tasks. Moreover, procedural memory built
from a stronger model retains its value: migrating the procedural memory to a
weaker model yields substantial performance gains.

</details>


### [111] [Adversarial Topic-aware Prompt-tuning for Cross-topic Automated Essay Scoring](https://arxiv.org/abs/2508.05987)
*Chunyun Zhang,Hongyan Zhao,Chaoran Cui,Qilong Song,Zhiqing Lu,Shuai Gong,Kailin Liu*

Main category: cs.CL

TL;DR: 提出 ATOP 方法，通过联合学习主题共享和主题特定特征，并结合对抗训练和伪标签技术，提升了跨主题自动作文评分的性能。


<details>
  <summary>Details</summary>
Motivation: 现有跨主题自动作文评分 (AES) 方法主要关注通过源域和目标域的分布对齐来提取主题共享特征，但忽略了主题特定特征，限制了其评估依题性的能力。

Method: 提出了一种名为 ATOP (Adversarial TOpic-aware Prompt-tuning) 的新颖方法，该方法通过优化可学习的主题感知提示（包含共享和特定组件）来共同学习主题共享和主题特定特征，以引发预训练语言模型 (PLM) 的相关知识。为了增强主题共享提示学习的鲁棒性并缓解主题对齐带来的特征尺度敏感性，该方法在统一的回归和分类框架中引入了对抗训练。此外，还采用基于邻居的分类器来模拟论文表示的局部结构并为目标主题论文生成伪标签，以指导特定于主题的提示的监督学习。

Result: ATOP 在 ASAP++ 数据集上进行了广泛实验，结果表明该方法在整体和多维度作文评分方面均显著优于现有最先进方法。

Conclusion: ATOP 方法在整体和多维度评分方面显著优于现有最先进方法。

Abstract: Cross-topic automated essay scoring (AES) aims to develop a transferable
model capable of effectively evaluating essays on a target topic. A significant
challenge in this domain arises from the inherent discrepancies between topics.
While existing methods predominantly focus on extracting topic-shared features
through distribution alignment of source and target topics, they often neglect
topic-specific features, limiting their ability to assess critical traits such
as topic adherence. To address this limitation, we propose an Adversarial
TOpic-aware Prompt-tuning (ATOP), a novel method that jointly learns
topic-shared and topic-specific features to improve cross-topic AES. ATOP
achieves this by optimizing a learnable topic-aware prompt--comprising both
shared and specific components--to elicit relevant knowledge from pre-trained
language models (PLMs). To enhance the robustness of topic-shared prompt
learning and mitigate feature scale sensitivity introduced by topic alignment,
we incorporate adversarial training within a unified regression and
classification framework. In addition, we employ a neighbor-based classifier to
model the local structure of essay representations and generate pseudo-labels
for target-topic essays. These pseudo-labels are then used to guide the
supervised learning of topic-specific prompts tailored to the target topic.
Extensive experiments on the publicly available ASAP++ dataset demonstrate that
ATOP significantly outperforms existing state-of-the-art methods in both
holistic and multi-trait essay scoring. The implementation of our method is
publicly available at: https://anonymous.4open.science/r/ATOP-A271.

</details>


### [112] [Crisp Attention: Regularizing Transformers via Structured Sparsity](https://arxiv.org/abs/2508.06016)
*Sagar Gandhi,Vishal Gandhi*

Main category: cs.CL

TL;DR: 本文研究了注意力稀疏性对Transformer模型精度的影响。实验发现，通过引入结构化稀疏性，模型精度反而得到了提升，证明了稀疏性可以作为一种有效的正则化手段，提高模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在扩展时面临的主要挑战是自注意力机制的二次计算成本。虽然注意力稀疏性被广泛研究作为提高计算效率的技术，但通常认为会以牺牲模型精度为代价。本研究旨在探索注意力稀疏性是否可以不以牺牲精度为代价，甚至提高模型精度。

Method: 通过在微调DistilBERT模型时，向其自注意力机制引入结构化的、事后的稀疏性，并在SST-2情感分析任务上进行实验。

Result: 在SST-2情感分析任务上，80%注意力稀疏性的模型达到了91.59%的验证准确率，比无稀疏性基线模型绝对提高了0.97%。

Conclusion: 研究结果表明，在Transformer模型中引入稀疏性不仅可以提高计算效率，还有可能提高模型的泛化能力和性能。

Abstract: The quadratic computational cost of the self-attention mechanism is a primary
challenge in scaling Transformer models. While attention sparsity is widely
studied as a technique to improve computational efficiency, it is almost
universally assumed to come at the cost of model accuracy. In this paper, we
report a surprising counter-example to this common wisdom. By introducing
structured, post-hoc sparsity to the attention mechanism of a DistilBERT model
during fine-tuning on the SST-2 sentiment analysis task, we find that model
accuracy improves significantly. Our model with 80\% attention sparsity
achieves a validation accuracy of 91.59\%, a 0.97\% absolute improvement over
the dense baseline. We hypothesize that this phenomenon is due to sparsity
acting as a powerful implicit regularizer, preventing the model from
overfitting by forcing it to make predictions with a more constrained and
robust set of features. Our work recasts attention sparsity not just as a tool
for computational efficiency, but as a potential method for improving the
generalization and performance of Transformer models.

</details>


### [113] [Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future](https://arxiv.org/abs/2508.06026)
*Yidong Wang,Xin Wang,Cunxiang Wang,Junfeng Fang,Qiufeng Wang,Jianing Chu,Xuran Meng,Shuxun Yang,Libo Qin,Yue Zhang,Wei Ye,Shikun Zhang*

Main category: cs.CL

TL;DR: 自我奖励语言模型通过 LLM-as-a-Judge 和 DPO 迭代地提高生成能力。然而，现有的方法会缩小对比样本之间的代表性差异，从而削弱偏好学习。我们提出了时间自我奖励语言模型，通过锚定拒绝和未来指导选择来协调过去的、现在的和未来的模型生成，以维持学习信号。我们的方法在各种模型上都取得了显著的改进，并在各种下游任务中表现出优越的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的自我奖励范式存在一个关键限制：所选响应和被拒绝响应的同步改进会逐渐缩小对比样本之间的代表性差异，从而破坏有效的偏好学习。

Method: 提出了一种名为“时间自我奖励语言模型”的双阶段框架，该框架包括“锚定拒绝”（使用过去初始模型的输出来固定被拒绝的响应）和“未来指导选择”（使用下一代模型预测来动态策划被选择的样本），以解决现有自我奖励范式中同步改进选定和拒绝响应而导致的代表性差异缩小的关键限制。

Result: 在 Llama、Qwen 和 Mistral 三个模型系列以及不同的模型大小（Llama3B/8B/70B）上进行的广泛实验表明，与使用相同计算资源的自我奖励相比，使用所提出方法训练的模型有了显著改进。例如，Llama3.1-8B 在 AlpacaEval 2.0 上的胜率达到了 29.44%，比自我奖励基线（19.69%）提高了 9.75%。此外，所提出的方法在数学推理（GSM8K）、基于知识的问答（ARC、TruthfulQA）和代码生成（HumanEval）等任务上表现出卓越的非分布外泛化能力。

Conclusion: 所提出的时间自我奖励语言模型通过锚定拒绝和未来指导选择来解决现有自我奖励范式的局限性，通过协调过去的、现在的和未来的模型生成来维持学习信号，在各种模型系列和大小上进行了广泛的实验，并展示了优于自我奖励基线的显著改进，同时在各种下游任务中表现出卓越的泛化能力。

Abstract: Self-Rewarding Language Models propose an architecture in which the Large
Language Models(LLMs) both generates responses and evaluates its own outputs
via LLM-as-a-Judge prompting, dynamically improving its generative capabilities
through iterative Direct Preference Optimization (DPO). However, our analysis
reveals a critical limitation in existing Self-Rewarding paradigms: the
synchronized improvement of chosen and rejected responses progressively narrows
the representational difference between contrasting samples, undermining
effective preference learning. We propose \textbf{Temporal Self-Rewarding
Language Models} that strategically coordinate past, present, and future model
generations to sustain learning signals. Our dual-phase framework introduces:
(1) \textit{Anchored Rejection} - fixing rejected responses using the past
initial model's outputs and (2) \textit{Future-Guided Chosen} - dynamically
curating chosen samples using next-generation model predictions. Extensive
experiments across three model families (Llama, Qwen, Mistral) and different
model sizes (Llama3B/8B/70B) demonstrate significant improvements when trained
with our method compared to Self-Rewarding using same computation resources.
For example, Llama3.1-8B reaches a 29.44 win rate on AlpacaEval 2.0 with our
method, outperforming the Self-Rewarding baseline (19.69) by 9.75. Notably, our
method also demonstrates superior out-of-distribution generalization across
mathematical reasoning (GSM8K), knowledge-based QA (ARC, TruthfulQA), and code
generation (HumanEval) tasks, even though we do not specifically collect such
training data.

</details>


### [114] [Efficient Knowledge Probing of Large Language Models by Adapting Pre-trained Embeddings](https://arxiv.org/abs/2508.06030)
*Kartik Sharma,Yiqiao Jin,Rakshit Trivedi,Srijan Kumar*

Main category: cs.CL

TL;DR: LLM知识难以预测且探测成本高。提出PEEK方法，利用代理嵌入模型（特别是句子嵌入）以高达90%的准确率预测LLM知识，同时降低计算成本。


<details>
  <summary>Details</summary>
Motivation: LLM在预训练中获取了跨学科的知识，但其随机性使得预测其知识获取变得困难。现有方法（如探测隐藏表示、设计特定任务提示、策划代表性样本和估计不确定性）需要对模型进行多次前向传播，计算成本高昂且耗时。

Method: 提出了一种名为PEEK（Proxy Embeddings to Estimate Knowledge）的方法，利用预训练的嵌入模型作为LLM的代理，通过线性解码器层来预测LLM的输出来估计LLM的知识。首先通过各种探测策略识别LLM已知的训练事实集，然后调整嵌入模型。

Result: 在3个基于Wikipedia的数据集、4个LLM和7个嵌入模型上进行了全面评估，结果表明嵌入可以在样本外数据集上以高达90%的准确率预测LLM的知识。此外，研究发现句子嵌入模型比图嵌入模型更适合预测LLM的知识。

Conclusion: 知识适应型嵌入可以大规模识别LLM中的知识差距，并为LLM的内部归纳偏差提供更深入的见解。评估表明，嵌入可以预测LLM在样本外知识，准确率高达90%。

Abstract: Large language models (LLMs) acquire knowledge across diverse domains such as
science, history, and geography encountered during generative pre-training.
However, due to their stochasticity, it is difficult to predict what LLMs have
acquired. Prior work has developed different ways to probe this knowledge by
investigating the hidden representations, crafting specific task prompts,
curating representative samples, and estimating their uncertainty. However,
these methods require making forward passes through the underlying model to
probe the LLM's knowledge about a specific fact, making them computationally
expensive and time-consuming. To bridge this gap, we propose $\textbf{PEEK}$ or
$\textbf{P}$roxy $\textbf{E}$mbeddings to $\textbf{E}$stimate
$\textbf{K}$nowledge of LLMs, by leveraging the pre-trained embedding models
that effectively encode factual knowledge as text or graphs as proxies for
LLMs. First, we identify a training set of facts known by LLMs through various
probing strategies and then adapt embedding models to predict the LLM outputs
with a linear decoder layer. Comprehensive evaluation on $3$ Wikipedia-derived
datasets, $4$ LLMs, and $7$ embedding models shows that embeddings can predict
LLM knowledge on a held-out set with up to 90 % accuracy. Furthermore, we find
that sentence embedding models are more suitable than graph embeddings to
predict LLM knowledge, shedding light on the underlying representation of the
factual landscape. Thus, we believe that knowledge-adapted embeddings can be
used to identify knowledge gaps in LLMs at scale and can provide deeper
insights into LLMs' internal inductive bias. The code and data are made
available at https://github.com/claws-lab/peek.

</details>


### [115] [EvolvR: Self-Evolving Pairwise Reasoning for Story Evaluation to Enhance Generation](https://arxiv.org/abs/2508.06046)
*Xinda Wang,Zhengxu Hou,Yangshijie Zhang,Bingren Yan,Zhibo Yang,Xingsheng Zhang,Luxi Xing,Qiang Zhou,Chen Zhang*

Main category: cs.CL

TL;DR: EvolvR框架通过自合成和自过滤CoT数据，解决了现有故事评估方法的局限性，并在多个基准测试中取得SOTA性能，同时提升了故事生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在故事评估方面存在困境：闭源模型的提示工程适应性差，而开源模型的微调方法缺乏严格的推理能力。为了解决这个问题，需要一个更优的方法来辅助人类进行质量判断并指导故事生成。

Method: 提出了一种名为EvolvR的自进化配对推理框架，该框架通过多重身份策略自合成与分数对齐的思维链（CoT）数据，并利用多智能体进行自过滤以保证CoT数据的逻辑严谨性和鲁棒性，最后将训练好的评估器作为奖励模型来指导故事生成任务。

Result: EvolvR框架在StoryER、HANNA和OpenMEVA三个评估基准上取得了最先进的性能。此外，作为奖励模型使用时，EvolvR显著提高了生成故事的质量。

Conclusion: EvolvR框架在三个评估基准（StoryER、HANNA和OpenMEVA）上实现了最先进的性能，并且作为奖励模型显著提高了生成故事的质量，验证了其优越性。

Abstract: Although the effectiveness of Large Language Models (LLMs) as judges
(LLM-as-a-judge) has been validated, their performance remains limited in
open-ended tasks, particularly in story evaluation. Accurate story evaluation
is crucial not only for assisting human quality judgment but also for providing
key signals to guide story generation. However, existing methods face a
dilemma: prompt engineering for closed-source models suffers from poor
adaptability, while fine-tuning approaches for open-source models lack the
rigorous reasoning capabilities essential for story evaluation. To address
this, we propose the Self-Evolving Pairwise Reasoning (EvolvR) framework.
Grounded in pairwise comparison, the framework first self-synthesizes
score-aligned Chain-of-Thought (CoT) data via a multi-persona strategy. To
ensure data quality, these raw CoTs undergo a self-filtering process, utilizing
multi-agents to guarantee their logical rigor and robustness. Finally, the
evaluator trained on the refined data is deployed as a reward model to guide
the story generation task. Experimental results demonstrate that our framework
achieves state-of-the-art (SOTA) performance on three evaluation benchmarks
including StoryER, HANNA and OpenMEVA. Furthermore, when served as a reward
model, it significantly enhances the quality of generated stories, thereby
fully validating the superiority of our self-evolving approach.

</details>


### [116] [ConlangCrafter: Constructing Languages with a Multi-Hop LLM Pipeline](https://arxiv.org/abs/2508.06094)
*Morris Alper,Moran Yanuka,Raja Giryes,Gašper Beguš*

Main category: cs.CL

TL;DR: 本研究提出了ConlangCrafter，一个利用大型语言模型（LLMs）来自动化人造语言（conlangs）创建过程的框架。该框架将语言设计分解为多个阶段，如音系、形态、句法和词汇生成，并利用LLMs的推理能力和自我完善机制来确保生成语言的一致性和多样性。实验证明，该方法无需人类语言学专业知识即可生成高质量的语言。


<details>
  <summary>Details</summary>
Motivation: 在人造语言（conlangs）如世界语和奎尼亚语在艺术、哲学和国际交流中扮演多样化角色的背景下，以及大型基础模型在文本、图像等领域的创造性生成方面带来革命性变化的背景下，本工作旨在利用LLMs作为创造性辅助工具，实现端到端的语言创造。

Method: 该工作利用大型语言模型（LLMs）作为计算创造力辅助工具，用于端到端的语言创造。工作提出了一种名为ConlangCrafter的多跳管线，将语言设计分解为音系、形态、句法、词汇生成和翻译等模块化阶段。在每个阶段，该方法都利用LLMs的元语言推理能力，注入随机性以鼓励多样性，并利用自我完善反馈以鼓励新兴语言描述的一致性。

Result: 评估结果表明，ConlangCrafter在衡量连贯性和类型学多样性的指标上表现良好，能够生成连贯且多样化的人造语言。

Conclusion: 该方法能够生成连贯且多样化的语言，而无需人类的语言学专业知识。

Abstract: Constructed languages (conlangs) such as Esperanto and Quenya have played
diverse roles in art, philosophy, and international communication. Meanwhile,
large-scale foundation models have revolutionized creative generation in text,
images, and beyond. In this work, we leverage modern LLMs as computational
creativity aids for end-to-end conlang creation. We introduce ConlangCrafter, a
multi-hop pipeline that decomposes language design into modular stages --
phonology, morphology, syntax, lexicon generation, and translation. At each
stage, our method leverages LLMs' meta-linguistic reasoning capabilities,
injecting randomness to encourage diversity and leveraging self-refinement
feedback to encourage consistency in the emerging language description. We
evaluate ConlangCrafter on metrics measuring coherence and typological
diversity, demonstrating its ability to produce coherent and varied conlangs
without human linguistic expertise.

</details>


### [117] [Few-Shot Prompting for Extractive Quranic QA with Instruction-Tuned LLMs](https://arxiv.org/abs/2508.06103)
*Mohamed Basem,Islam Oshallah,Ali Hamdi,Ammar Mohammed*

Main category: cs.CL

TL;DR: 本文提出了两种经文抽取式问答方法，一种是微调模型，另一种是使用指令调优的大型语言模型进行少样本提示。实验表明，指令调优的大型语言模型在处理经文这种资源稀缺、语义丰富的问答任务上表现更优。


<details>
  <summary>Details</summary>
Motivation: 解决经文文本中复杂的语言、独特的术语和深层含义的挑战。

Method: 本文提出两种有效的经文抽取式问答方法。首先，他们对一个现有的大型语言模型进行微调，以生成答案。其次，他们使用类似Gemini和DeepSeek等指令调优的大型语言模型进行少样本提示。开发了一个专门的阿拉伯语提示框架来进行跨度提取。一个强大的后处理系统整合了子词对齐、重叠抑制和语义过滤。这提高了精度并减少了幻觉。

Result: 评估表明，具有阿拉伯语指令的大型语言模型优于传统的微调模型。最佳配置实现了0.637的pAP10分数。

Conclusion: 基于提示的指令调优对于资源稀缺、语义丰富的问答任务有效。

Abstract: This paper presents two effective approaches for Extractive Question
Answering (QA) on the Quran. It addresses challenges related to complex
language, unique terminology, and deep meaning in the text. The second uses
few-shot prompting with instruction-tuned large language models such as Gemini
and DeepSeek. A specialized Arabic prompt framework is developed for span
extraction. A strong post-processing system integrates subword alignment,
overlap suppression, and semantic filtering. This improves precision and
reduces hallucinations. Evaluations show that large language models with Arabic
instructions outperform traditional fine-tuned models. The best configuration
achieves a pAP10 score of 0.637. The results confirm that prompt-based
instruction tuning is effective for low-resource, semantically rich QA tasks.

</details>


### [118] [You Don't Need Pre-built Graphs for RAG: Retrieval Augmented Generation with Adaptive Reasoning Structures](https://arxiv.org/abs/2508.06105)
*Shengyuan Chen,Chuang Zhou,Zheng Yuan,Qinggang Zhang,Zeyang Cui,Hao Chen,Yilin Xiao,Jiannong Cao,Xiao Huang*

Main category: cs.CL

TL;DR: LogicRAG是一种新的检索增强生成框架，它通过动态提取推理结构来解决现有GraphRAG方法的成本和效率问题，无需预构建图，并在复杂推理任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图的检索增强生成（GraphRAG）方法依赖于一个昂贵的过程来将语料库转换为图，这会带来巨大的令牌成本和更新延迟。此外，现实世界的查询在类型和复杂性上各不相同，需要不同的逻辑结构来进行准确推理。预先构建的图可能与这些所需的结构不一致，导致知识检索无效。

Method: LogicRAG框架首先将输入查询分解为一组子问题，并构建一个有向无环图（DAG）来模拟它们之间的逻辑依赖关系。为了支持连贯的多步推理，LogicRAG使用拓扑排序对图进行线性化，以便以逻辑一致的顺序解决子问题。此外，LogicRAG应用图剪枝来减少冗余检索，并使用上下文剪枝来过滤不相关的上下文，从而显著降低了总的令牌成本。

Result: 实验表明，LogicRAG在性能和效率方面均优于最先进的基线。

Conclusion: LogicRAG框架通过在推理时动态提取推理结构来指导自适应检索，无需预构建图，并在性能和效率方面优于最先进的基线。

Abstract: Large language models (LLMs) often suffer from hallucination, generating
factually incorrect statements when handling questions beyond their knowledge
and perception. Retrieval-augmented generation (RAG) addresses this by
retrieving query-relevant contexts from knowledge bases to support LLM
reasoning. Recent advances leverage pre-constructed graphs to capture the
relational connections among distributed documents, showing remarkable
performance in complex tasks. However, existing Graph-based RAG (GraphRAG)
methods rely on a costly process to transform the corpus into a graph,
introducing overwhelming token cost and update latency. Moreover, real-world
queries vary in type and complexity, requiring different logic structures for
accurate reasoning. The pre-built graph may not align with these required
structures, resulting in ineffective knowledge retrieval. To this end, we
propose a \textbf{\underline{Logic}}-aware
\textbf{\underline{R}}etrieval-\textbf{\underline{A}}ugmented
\textbf{\underline{G}}eneration framework (\textbf{LogicRAG}) that dynamically
extracts reasoning structures at inference time to guide adaptive retrieval
without any pre-built graph. LogicRAG begins by decomposing the input query
into a set of subproblems and constructing a directed acyclic graph (DAG) to
model the logical dependencies among them. To support coherent multi-step
reasoning, LogicRAG then linearizes the graph using topological sort, so that
subproblems can be addressed in a logically consistent order. Besides, LogicRAG
applies graph pruning to reduce redundant retrieval and uses context pruning to
filter irrelevant context, significantly reducing the overall token cost.
Extensive experiments demonstrate that LogicRAG achieves both superior
performance and efficiency compared to state-of-the-art baselines.

</details>


### [119] [AURA: Affordance-Understanding and Risk-aware Alignment Technique for Large Language Models](https://arxiv.org/abs/2508.06124)
*Sayantan Adak,Pratyush Chatterjee,Somnath Banerjee,Rima Hazra,Somak Aditya,Animesh Mukherjee*

Main category: cs.CL

TL;DR: LLMs struggle with safety risks where outputs enable harmful actions due to overlooked implications. Existing safety methods are insufficient. We introduce AURA, a framework using Process Reward Models (PRMs) for step-level safety checks, which proactively guides LLMs to safer reasoning. AURA significantly outperforms current methods, enhancing logical integrity and safety awareness.


<details>
  <summary>Details</summary>
Motivation: Traditional safety solutions are inadequate for managing affordance-based safety risks in LLMs due to their lack of granularity and proactive intervention capabilities during subtle reasoning steps.

Method: AURA, a multi-layered framework utilizing Process Reward Models (PRMs) for step-level evaluations, combines introspective self-critique, fine-grained PRM assessments, and adaptive safety-aware decoding to guide models toward safer reasoning.

Result: Empirical evidence shows AURA significantly surpasses existing methods in improving the logical integrity and affordance-sensitive safety of LLM outputs.

Conclusion: AURA enables safer, more responsible, and contextually aware AI by significantly improving logical integrity and affordance-sensitive safety of model outputs, setting a new benchmark for alignment-sensitive applications.

Abstract: Present day LLMs face the challenge of managing affordance-based safety
risks-situations where outputs inadvertently facilitate harmful actions due to
overlooked logical implications. Traditional safety solutions, such as scalar
outcome-based reward models, parameter tuning, or heuristic decoding
strategies, lack the granularity and proactive nature needed to reliably detect
and intervene during subtle yet crucial reasoning steps. Addressing this
fundamental gap, we introduce AURA, an innovative, multi-layered framework
centered around Process Reward Models (PRMs), providing comprehensive, step
level evaluations across logical coherence and safety-awareness. Our framework
seamlessly combines introspective self-critique, fine-grained PRM assessments,
and adaptive safety-aware decoding to dynamically and proactively guide models
toward safer reasoning trajectories. Empirical evidence clearly demonstrates
that this approach significantly surpasses existing methods, significantly
improving the logical integrity and affordance-sensitive safety of model
outputs. This research represents a pivotal step toward safer, more
responsible, and contextually aware AI, setting a new benchmark for
alignment-sensitive applications.

</details>


### [120] [Less is More: Selective Reflection for Compatible and Efficient Knowledge Distillation in Large Language Models](https://arxiv.org/abs/2508.06135)
*Lingyuan Liu,Mengxiang Zhang*

Main category: cs.CL

TL;DR: SRD 是一种新的数据精选框架，利用学生模型的输出来优化训练数据，提升了知识蒸馏的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的白盒知识蒸馏（KD）方法主要关注平衡真实标签和学生模型生成的响应，却忽略了训练数据质量和学生模型兼容性这两个关键因素。

Method: SRD 通过比较真实标签数据和学生模型输出来动态评估和选择提示-响应对，并基于难度自动排序，从而系统地优化训练数据。在选定训练数据后，采用课程调度策略在固定间隔内逐步将这些精选的子集引入蒸馏过程。

Result: SRD 能够跨越多种白盒 KD 方法和模型架构，一致性地改善蒸馏结果，并显著降低 KD 训练期间的计算成本。

Conclusion: SRD 作为一个即插即用模块，提高了样本效率，并且不需要修改底层知识蒸馏算法。实验证明 SRD 在多种语言模型基准测试中，能够一致性地提升蒸馏模型的性能，并能将训练时间最多减少 39%。该研究强调了数据质量和兼容性对于 LLM 有效和高效蒸馏的关键性，并为实现这两者提供了一个原则性的框架。

Abstract: Knowledge Distillation (KD) is a fundamental technique for compressing large
language models (LLMs) into compact, efficient student models. However,
existing white-box KD methods mainly focus on balancing ground truth and
student-generated responses while overlooking two critical factors: training
data quality and student-model compatibility. To address these limitations, we
propose Selective Reflection Distillation (SRD), a novel data curation
framework that leverages reflections from student models to systematically
refine training data. SRD dynamically evaluates and selects prompt-response
pairs by comparing ground truth data with student model outputs, selectively
curating high-quality, student-compatible training instances through automated
ranking based on difficulty. Furthermore, after selecting the training data, a
curriculum scheduling strategy is employed to incrementally introduce these
curated subsets into the distillation process at fixed intervals. As a
plug-and-play enhancement, SRD consistently improves distillation outcomes
across diverse white-box KD approaches and model architectures, as well as
decreases computational cost significantly during KD training. Experiments on a
range of language model benchmarks demonstrate SRD's consistent improvements in
distilled model performance, as well as a reduction in training runtime by up
to 39%, under diverse KD methods and model families. Notably, SRD operates as a
plug-and-play module, enhancing sample efficiency without modifying underlying
KD algorithms. Our findings highlight that data quality and compatibility are
pivotal to effective and efficient distillation of LLMs, and SRD provides a
principled framework to achieve both. This work advances the understanding of
data-centric factors in KD and offers practical insights for enhancing the
capability and efficiency of compressed LLMs.

</details>


### [121] [Semantic and Structural Analysis of Implicit Biases in Large Language Models: An Interpretable Approach](https://arxiv.org/abs/2508.06155)
*Renhan Zhang,Lian Lian,Zhen Qi,Guiran Liu*

Main category: cs.CL

TL;DR: 提出一种结合嵌套语义表征和上下文对比机制的可解释方法，用于检测大型语言模型中的隐式社会偏见，实验证明该方法有效且具有高可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型生成过程中可能出现的隐式刻板印象问题，提出一种可解释的偏差检测方法，用于识别模型输出中隐藏的、不易通过显性语言特征捕捉的语义倾向。

Method: 结合嵌套语义表征和上下文对比机制，提取词向量空间结构中的潜在偏差特征，并通过注意力权重扰动分析模型对特定社会属性词汇的敏感度，从而揭示偏差形成的语义通路。

Result: 实验结果表明，该方法在StereoSet数据集上，在性别、职业、宗教和种族等多个刻板印象维度上均表现出良好的检测效果，能够准确识别偏差，保持语义一致性和输出稳定性，并具有高可解释性。

Conclusion: 该方法在多个维度上实现了强大的检测性能，能够准确识别语义相似文本间的偏差，同时保持高语义一致性和输出稳定性。该方法结构设计具有高可解释性，有助于揭示语言模型内部的偏差关联机制，为偏差检测提供了更透明、更可靠的技术基础，适用于生成内容可信度要求高的实际应用场景。

Abstract: This paper addresses the issue of implicit stereotypes that may arise during
the generation process of large language models. It proposes an interpretable
bias detection method aimed at identifying hidden social biases in model
outputs, especially those semantic tendencies that are not easily captured
through explicit linguistic features. The method combines nested semantic
representation with a contextual contrast mechanism. It extracts latent bias
features from the vector space structure of model outputs. Using attention
weight perturbation, it analyzes the model's sensitivity to specific social
attribute terms, thereby revealing the semantic pathways through which bias is
formed. To validate the effectiveness of the method, this study uses the
StereoSet dataset, which covers multiple stereotype dimensions including
gender, profession, religion, and race. The evaluation focuses on several key
metrics, such as bias detection accuracy, semantic consistency, and contextual
sensitivity. Experimental results show that the proposed method achieves strong
detection performance across various dimensions. It can accurately identify
bias differences between semantically similar texts while maintaining high
semantic alignment and output stability. The method also demonstrates high
interpretability in its structural design. It helps uncover the internal bias
association mechanisms within language models. This provides a more transparent
and reliable technical foundation for bias detection. The approach is suitable
for real-world applications where high trustworthiness of generated content is
required.

</details>


### [122] [One Size Does Not Fit All: A Distribution-Aware Sparsification for More Precise Model Merging](https://arxiv.org/abs/2508.06163)
*Yingfeng Luo,Dingyang Lin,Junxin Wang,Ziqiang Xu,Kaiyan Chang,Tong Zheng,Bei Li,Anxiang Ma,Tong Xiao,Zhengtao Yu,Jingbo Zhu*

Main category: cs.CL

TL;DR: TADrop 是一种新颖的自适应稀疏化方法，通过为不同参数张量定制稀疏度来改进模型合并，并在多项任务和模型上显著提高了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的模型合并方法采用“一刀切”的策略，应用统一的稀疏率，忽略了模型参数固有的结构和统计异质性，导致关键参数被修剪，而非关键参数被保留，从而造成次优的权衡。

Method: TADrop（Tensor-wise Adaptive Drop）是一种自适应稀疏化策略，它不采用全局稀疏率，而是根据参数张量的分布特性为其分配定制化的稀疏度级别。其核心思想是，分布更密集、冗余性更高的张量可以被大力修剪，而更稀疏、更关键的张量则被保留。

Result: TADrop 被集成到基础、经典和 SOTA 模型合并方法中，并通过在视觉、语言和多模态的广泛任务以及 ViT、BEiT 等模型上进行的大量实验进行了验证。实验结果表明，TADrop 能够持续且显著地提升性能。例如，在增强一种领先的模型合并方法时，TADrop 在 8 个 ViT-B/32 任务上实现了平均 2.0% 的性能提升。

Conclusion: TADrop 通过根据参数张量的分布特性为每个张量分配定制化的稀疏度级别，并相应地调整稀疏化策略，从而有效缓解参数干扰，为高性能模型合并提供了新的基准。

Abstract: Model merging has emerged as a compelling data-free paradigm for multi-task
learning, enabling the fusion of multiple fine-tuned models into a single,
powerful entity. A key technique in merging methods is sparsification, which
prunes redundant parameters from task vectors to mitigate interference.
However, prevailing approaches employ a ``one-size-fits-all'' strategy,
applying a uniform sparsity ratio that overlooks the inherent structural and
statistical heterogeneity of model parameters. This often leads to a suboptimal
trade-off, where critical parameters are inadvertently pruned while less useful
ones are retained. To address this limitation, we introduce \textbf{TADrop}
(\textbf{T}ensor-wise \textbf{A}daptive \textbf{Drop}), an adaptive
sparsification strategy that respects this heterogeneity. Instead of a global
ratio, TADrop assigns a tailored sparsity level to each parameter tensor based
on its distributional properties. The core intuition is that tensors with
denser, more redundant distributions can be pruned aggressively, while sparser,
more critical ones are preserved. As a simple and plug-and-play module, we
validate TADrop by integrating it with foundational, classic, and SOTA merging
methods. Extensive experiments across diverse tasks (vision, language, and
multimodal) and models (ViT, BEiT) demonstrate that TADrop consistently and
significantly boosts their performance. For instance, when enhancing a leading
merging method, it achieves an average performance gain of 2.0\% across 8
ViT-B/32 tasks. TADrop provides a more effective way to mitigate parameter
interference by tailoring sparsification to the model's structure, offering a
new baseline for high-performance model merging.

</details>


### [123] [UR$^2$: Unify RAG and Reasoning through Reinforcement Learning](https://arxiv.org/abs/2508.06165)
*Weitao Li,Boran Xiang,Xiaolong Wang,Zhinan Gou,Weizhi Ma,Yang Liu*

Main category: cs.CL

TL;DR: UR2是一个新框架，通过强化学习统一了检索（RAG）和推理（RLVR），解决了现有方法孤立开发的限制。它采用难度感知课程训练和混合知识访问策略，在多种任务上表现出色，性能媲美GPT-4o-mini和GPT-4.1-mini。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG和RL方法通常是孤立开发的，并且将它们统一起来的现有努力范围有限，通常仅限于具有固定检索设置和特定任务假设的开放域QA。这种缺乏整合限制了泛化能力，并限制了RAG-RL方法在更广泛领域的适用性。

Method: 提出UR2（Unified RAG and Reasoning）通用框架，通过强化学习统一检索和推理。引入了难度感知课程训练（选择性地仅为复杂问题调用检索）和混合知识访问策略（结合特定领域的离线语料库和LLM生成的摘要），以实现检索和推理之间的动态协调。

Result: UR2框架在开放域QA、MMLU-Pro、医学和数学推理任务上的实验表明，它显著优于现有的RAG和RL方法，并在一些基准测试上达到了与GPT-4o-mini和GPT-4.1-mini相当的性能。

Conclusion: UR2框架成功地统一了检索和推理，并在多个基准测试中取得了优于现有RAG和RL方法的性能，与GPT-4o-mini和GPT-4.1-mini相当。

Abstract: Large Language Models (LLMs) have shown remarkable capabilities through two
complementary paradigms: Retrieval-Augmented Generation (RAG), which enhances
knowledge grounding, and Reinforcement Learning from Verifiable Rewards (RLVR),
which optimizes complex reasoning abilities. However, these two capabilities
are often developed in isolation, and existing efforts to unify them remain
narrow in scope-typically limited to open-domain QA with fixed retrieval
settings and task-specific assumptions. This lack of integration constrains
generalization and limits the applicability of RAG-RL methods to broader
domains. To bridge this gap, we propose UR2 (Unified RAG and Reasoning), a
general framework that unifies retrieval and reasoning through reinforcement
learning. UR2 introduces two key contributions: a difficulty-aware curriculum
training that selectively invokes retrieval only for challenging problems, and
a hybrid knowledge access strategy combining domain-specific offline corpora
with LLM-generated summaries. These components are designed to enable dynamic
coordination between retrieval and reasoning, improving adaptability across a
diverse range of tasks. Experiments across open-domain QA, MMLU-Pro, medical,
and mathematical reasoning tasks demonstrate that UR2 (built on Qwen2.5-3/7B
and LLaMA-3.1-8B) significantly outperforms existing RAG and RL methods,
achieving comparable performance to GPT-4o-mini and GPT-4.1-mini on several
benchmarks. We have released all code, models, and data at
https://github.com/Tsinghua-dhy/UR2.

</details>


### [124] [Pragmatics beyond humans: meaning, communication, and LLMs](https://arxiv.org/abs/2508.06167)
*Vít Gvoždiak*

Main category: cs.CL

TL;DR: 本文认为，随着大型语言模型的出现，需要重新审视语用学理论。论文挑战了传统的符号三分法，并提出了一种新的人机通信（HMC）框架。它还探讨了人类中心和机器中心语用学理论之间的张力，并认为概率语用学比传统的格莱斯语用学更适合大型语言模型。最后，论文引入了“语境挫败”的概念，以描述与生成式人工智能交互时出现的语境理解挑战。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）在交际环境中的出现，需要进一步改进和重新考虑语用学的理解和方法。

Method: 通过挑战传统的符号三分法，提出了一种更合适的人机通信（HMC）框架。通过考察以人类为中心的语用学理论与以机器为中心的语言模型之间的张力，强调了概率语用学（特别是理性言语行为框架）比传统的、基于格莱斯的语用学更具兼容性，因为它侧重于优化而非真值评估。通过解决三种形式的替代主义——概括性、语言性和交流性——并强调了扭曲语言模型评估和模糊人类交流主体作用的拟人化偏见。最后，通过引入“语境挫败”的概念来描述语境输入增加但语境理解崩溃的悖论，并强调用户如何被迫为模型和自身共同构建语境条件。

Result: 大型语言模型（LLM）的连接主义架构破坏了既定的意义层次结构，并提出了人机通信（HMC）框架。概率语用学，特别是理性言语行为框架，提供了一种更兼容的目的论，通过关注优化而非真值评估来解决人类中心语用学理论与LLM机器中心性质之间的张力。语用学理论可能需要调整或扩展，以更好地解释涉及生成式人工智能的交流。

Conclusion: 本篇论文认为，为了更好地解释涉及生成式人工智能的交流，可能需要调整或扩展语用学理论。

Abstract: The paper reconceptualizes pragmatics not as a subordinate, third dimension
of meaning, but as a dynamic interface through which language operates as a
socially embedded tool for action. With the emergence of large language models
(LLMs) in communicative contexts, this understanding needs to be further
refined and methodologically reconsidered. The first section challenges the
traditional semiotic trichotomy, arguing that connectionist LLM architectures
destabilize established hierarchies of meaning, and proposes the Human-Machine
Communication (HMC) framework as a more suitable alternative. The second
section examines the tension between human-centred pragmatic theories and the
machine-centred nature of LLMs. While traditional, Gricean-inspired pragmatics
continue to dominate, it relies on human-specific assumptions ill-suited to
predictive systems like LLMs. Probabilistic pragmatics, particularly the
Rational Speech Act framework, offers a more compatible teleology by focusing
on optimization rather than truth-evaluation. The third section addresses the
issue of substitutionalism in three forms - generalizing, linguistic, and
communicative - highlighting the anthropomorphic biases that distort LLM
evaluation and obscure the role of human communicative subjects. Finally, the
paper introduces the concept of context frustration to describe the paradox of
increased contextual input paired with a collapse in contextual understanding,
emphasizing how users are compelled to co-construct pragmatic conditions both
for the model and themselves. These arguments suggest that pragmatic theory may
need to be adjusted or expanded to better account for communication involving
generative AI.

</details>


### [125] [Comparing Knowledge Injection Methods for LLMs in a Low-Resource Regime](https://arxiv.org/abs/2508.06178)
*Hugo Abonizio,Thales Almeida,Roberto Lotufo,Rodrigo Nogueira*

Main category: cs.CL

TL;DR: “本研究聚焦于如何用少量数据高效地更新大型语言模型（LLMs）。研究发现，通过多样化的文本增强（尤其是模型自生成数据）比简单的持续预训练或RAG更能有效地注入新知识，并能更好地防止模型遗忘旧知识。模型自生成数据的方法为未来LLM的自我改进提供了新的方向。”


<details>
  <summary>Details</summary>
Motivation: “大型语言模型（LLMs）通常需要大量文本才能有效地获取新知识。尽管持续预训练和检索增强生成（RAG）已被证明是有效的方法，但仅用数千或数百万个文本片段来更新LLM仍然是一个挑战。因此，本研究旨在解决如何将少量非结构化信息注入LLM的问题，并探讨其与灾难性遗忘现象的关联。”

Method: “本文研究了如何将少量非结构化信息注入大型语言模型（LLMs），并探究了其与灾难性遗忘的关系。研究人员使用了包含近期新闻的特定数据集，以确保与模型预训练数据无重叠。通过对模型进行问答测试来评估知识获取能力。在基线的基础上，研究者探索了不同的数据增强算法，以生成合成数据来提升知识获取能力。实验结果表明，简单地在有限数据上进行持续预训练效果有限，而通过多样化提示诱导出的文本变体能显著提高新知识的学习效果。研究还关注了小数据量下的遗忘现象，并比较了RAG方法和参数化方法在知识注入上的表现，最后验证了模型自身生成合成训练数据的潜力。”

Result: “实验表明，仅在有限数据上进行持续预训练只能带来适度的改进，而暴露于多样化的文本变体（尤其是通过多样化提示诱导的变体）能够显著提高模型学习新事实的能力。研究还揭示了在小数据量下的遗忘现象，并强调了学习新内容和保留现有能力之间的微妙平衡。与参数化方法相比，RAG方法在知识注入方面表现出更高的敏感性，并且更容易导致在控制数据集上的性能下降。最后，实验证明模型能够自行生成有效的合成训练数据，为通过模型自我改进来更新模型提供了途径。”

Conclusion: “在有限的数据下，通过引入多样化的文本变体，特别是利用模型自身生成合成数据，可以显著提高LLM获取新知识的能力，同时缓解灾难性遗忘的现象。RAG方法在小数据注入方面表现不佳，而参数化方法则更具优势。”

Abstract: Large language models (LLMs) often require vast amounts of text to
effectively acquire new knowledge. While continuing pre-training on large
corpora or employing retrieval-augmented generation (RAG) has proven
successful, updating an LLM with only a few thousand or million tokens remains
challenging. In this work, we investigate the task of injecting small,
unstructured information into LLMs and its relation to the catastrophic
forgetting phenomenon. We use a dataset of recent news -- ensuring no overlap
with the model's pre-training data -- to evaluate the knowledge acquisition by
probing the model with question-answer pairs related the learned information.
Starting from a continued pre-training baseline, we explored different
augmentation algorithms to generate synthetic data to improve the knowledge
acquisition capabilities. Our experiments show that simply continuing
pre-training on limited data yields modest improvements, whereas exposing the
model to diverse textual variations significantly improves the learning of new
facts -- particularly with methods that induce greater variability through
diverse prompting. Furthermore, we shed light on the forgetting phenomenon in
small-data regimes, illustrating the delicate balance between learning new
content and retaining existing capabilities. We also confirm the sensitivity of
RAG-based approaches for knowledge injection, which often lead to greater
degradation on control datasets compared to parametric methods. Finally, we
demonstrate that models can generate effective synthetic training data
themselves, suggesting a pathway toward self-improving model updates. All code
and generated data used in our experiments are publicly available, providing a
resource for studying efficient knowledge injection in LLMs with limited data
at https://github.com/hugoabonizio/knowledge-injection-methods.

</details>


### [126] [DKG-LLM : A Framework for Medical Diagnosis and Personalized Treatment Recommendations via Dynamic Knowledge Graph and Large Language Model Integration](https://arxiv.org/abs/2508.06186)
*Ali Sarabadani,Maryam Abdollahi Shamami,Hamidreza Sadeghsalehi,Borhan Asadi,Saba Hesaraki*

Main category: cs.CL

TL;DR: DKG-LLM 框架整合了动态知识图 (DKG) 和 Grok 3 LLM，通过 ASFA 算法处理医疗数据，在医疗诊断和治疗推荐方面表现出色，准确率分别为 84.19% 和 89.63%。


<details>
  <summary>Details</summary>
Motivation: 旨在通过整合动态知识图 (DKG) 与 Grok 3 大型语言模型，提出 DKG-LLM 框架，以实现医疗诊断和个性化治疗推荐。

Method: 该研究提出了 DKG-LLM 框架，通过将动态知识图 (DKG) 与 Grok 3 大型语言模型相结合，并利用自适应语义融合算法 (ASFA) 处理异构医疗数据和患者记录，动态生成知识图。

Result: DKG-LLM 在 MIMIC-III 和 PubMed 数据集上的评估结果显示，其诊断准确率为 84.19%，治疗推荐准确率为 89.63%，语义覆盖率为 93.48%。

Conclusion: DKG-LLM 是一个可靠且具有变革性的工具，可处理嘈杂的数据和复杂的多症状疾病，并能从医生那里获得基于反馈的学习。

Abstract: Large Language Models (LLMs) have grown exponentially since the release of
ChatGPT. These models have gained attention due to their robust performance on
various tasks, including language processing tasks. These models achieve
understanding and comprehension of tasks by training billions of parameters.
The development of these models is a transformative force in enhancing natural
language understanding and has taken a significant step towards artificial
general intelligence (AGI). In this study, we aim to present the DKG-LLM
framework. The DKG-LLM framework introduces a groundbreaking approach to
medical diagnosis and personalized treatment recommendations by integrating a
dynamic knowledge graph (DKG) with the Grok 3 large language model. Using the
Adaptive Semantic Fusion Algorithm (ASFA), heterogeneous medical data
(including clinical reports and PubMed articles) and patient records
dynamically generate a knowledge graph consisting of 15,964 nodes in 13
distinct types (e.g., diseases, symptoms, treatments, patient profiles) and
127,392 edges in 26 relationship types (e.g., causal, therapeutic,
association). ASFA utilizes advanced probabilistic models, Bayesian inference,
and graph optimization to extract semantic information, dynamically updating
the graph with approximately 150 new nodes and edges in each data category
while maintaining scalability with up to 987,654 edges. Real-world datasets,
including MIMIC-III and PubMed, were utilized to evaluate the proposed
architecture. The evaluation results show that DKG-LLM achieves a diagnostic
accuracy of 84.19%. The model also has a treatment recommendation accuracy of
89.63% and a semantic coverage of 93.48%. DKG-LLM is a reliable and
transformative tool that handles noisy data and complex multi-symptom diseases,
along with feedback-based learning from physician input.

</details>


### [127] [Beyond Uniform Criteria: Scenario-Adaptive Multi-Dimensional Jailbreak Evaluation](https://arxiv.org/abs/2508.06194)
*Lai Jiang,Yuekang Li,Xiaohan Zhang,Youtao Ding,Li Pan*

Main category: cs.CL

TL;DR: SceneJailEval是一个新颖的、场景自适应的越狱评估框架和数据集，解决了现有方法的局限性，并在性能上取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模语言模型（LLM）越狱评估方法要么只提供二元标签，无法量化危害程度，要么使用统一的评估标准，导致在特定场景下评估不准确。

Method: 提出了一种新颖的场景自适应多维度框架，并构建了一个包含14个场景的综合数据集，以解决现有评估方法的局限性。

Result: SceneJailEval在包含14个场景的全面数据集中取得了0.917的F1分数，在JBB数据集上取得了0.995的F1分数，超过了现有的评估方法。

Conclusion: SceneJailEval在包含14个场景的全面数据集中实现了最先进的0.917的F1分数，在JBB上实现了0.995的F1分数，提高了6%和3%，证明了其在异构场景下的优越性。

Abstract: Precise jailbreak evaluation is vital for LLM red teaming and jailbreak
research. Current approaches employ binary classification ( e.g., string
matching, toxic text classifiers, LLM-driven methods), yielding only "yes/no"
labels without quantifying harm intensity. Existing multi-dimensional
frameworks ( e.g., Security Violation, Relative Truthfulness, Informativeness)
apply uniform evaluation criteria across scenarios, resulting in
scenario-specific mismatches--for instance, "Relative Truthfulness" is
irrelevant to "hate speech"--which compromise evaluation precision. To tackle
these limitations, we introduce SceneJailEval, with key contributions: (1) A
groundbreaking scenario-adaptive multi-dimensional framework for jailbreak
evaluation, overcoming the critical "one-size-fits-all" constraint of existing
multi-dimensional methods, and featuring strong extensibility to flexibly adapt
to customized or emerging scenarios. (2) A comprehensive 14-scenario dataset
with diverse jailbreak variants and regional cases, filling the long-standing
gap in high-quality, holistic benchmarks for scenario-adaptive evaluation. (3)
SceneJailEval achieves state-of-the-art results, with an F1 score of 0.917 on
our full-scenario dataset (+6% over prior SOTA) and 0.995 on JBB (+3% over
prior SOTA), surpassing accuracy limits of existing evaluation methods in
heterogeneous scenarios and confirming its advantage.

</details>


### [128] [EICAP: Deep Dive in Assessment and Enhancement of Large Language Models in Emotional Intelligence through Multi-Turn Conversations](https://arxiv.org/abs/2508.06196)
*Nizi Nazar,Ehsaneddin Asgari*

Main category: cs.CL

TL;DR: 本研究提出了一种新的 EI 分类和基准（EICAP-Bench），以评估和增强 LLMs 的情感智能。研究发现，现有模型在情感推理方面存在不足，并且当前的微调方法仅在特定 EI 层（评估层）上有效，表明需要新的策略来全面提升 LLMs 的情感智能。


<details>
  <summary>Details</summary>
Motivation: 解决当前 LLMs 在情感智能（EI）维度上探索不足的问题。

Method: 提出一个统一的、心理学为基础的、针对大语言模型（LLM）的情感智能（EI）四层分类，包括情感追踪、原因推断、评估和情感适宜的响应生成。在此框架基础上，提出 EICAP-Bench，一个新颖的 MCQ 风格的多轮基准，用于评估开源 LLMs 在不同语言和文化背景下的 EI 能力。使用 LoRA 适配器在 UltraChat (UC) 数据集上对 Qwen2.5-Base 和 Qwen2.5-Instruct 进行微调。

Result: 在 EICAP-Bench 基准上，Qwen2.5-Instruct 是表现最好的模型。通过 UC 微调，仅评估层在 EI 各层中显示出显著改进。

Conclusion: 现有的预训练和指令调优范式在使 LLMs 具备更深层次的情感推理能力方面存在局限性，凸显了针对全面情感智能对齐所需的定向数据和建模策略的必要性。

Abstract: Emotional Intelligence (EI) is a critical yet underexplored dimension in the
development of human-aligned LLMs. To address this gap, we introduce a unified,
psychologically grounded four-layer taxonomy of EI tailored for large language
models (LLMs), encompassing emotional tracking, cause inference, appraisal, and
emotionally appropriate response generation. Building on this framework, we
present EICAP-Bench, a novel MCQ style multi-turn benchmark designed to
evaluate EI capabilities in open-source LLMs across diverse linguistic and
cultural contexts. We evaluate six LLMs: LLaMA3 (8B), LLaMA3-Instruct, Gemma
(9B), Gemma-Instruct, Qwen2.5 (7B), and Qwen2.5-Instruct on EmoCap-Bench,
identifying Qwen2.5-Instruct as the strongest baseline. To assess the potential
for enhancing EI capabilities, we fine-tune both Qwen2.5-Base and
Qwen2.5-Instruct using LoRA adapters on UltraChat (UC), a large-scale,
instruction-tuned dialogue dataset, in both English and Arabic. Our statistical
analysis reveals that among the five EI layers, only the Appraisal layer shows
significant improvement through UC-based fine-tuning. These findings highlight
the limitations of existing pretraining and instruction-tuning paradigms in
equipping LLMs with deeper emotional reasoning and underscore the need for
targeted data and modeling strategies for comprehensive EI alignment.

</details>


### [129] [Classification is a RAG problem: A case study on hate speech detection](https://arxiv.org/abs/2508.06204)
*Richard Willats,Josh Pennington,Aravind Mohan,Bertie Vidgen*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Robust content moderation requires classification systems that can quickly
adapt to evolving policies without costly retraining. We present classification
using Retrieval-Augmented Generation (RAG), which shifts traditional
classification tasks from determining the correct category in accordance with
pre-trained parameters to evaluating content in relation to contextual
knowledge retrieved at inference. In hate speech detection, this transforms the
task from "is this hate speech?" to "does this violate the hate speech policy?"
  Our Contextual Policy Engine (CPE) - an agentic RAG system - demonstrates
this approach and offers three key advantages: (1) robust classification
accuracy comparable to leading commercial systems, (2) inherent explainability
via retrieved policy segments, and (3) dynamic policy updates without model
retraining. Through three experiments, we demonstrate strong baseline
performance and show that the system can apply fine-grained policy control by
correctly adjusting protection for specific identity groups without requiring
retraining or compromising overall performance. These findings establish that
RAG can transform classification into a more flexible, transparent, and
adaptable process for content moderation and wider classification problems.

</details>


### [130] [InfoCausalQA:Can Models Perform Non-explicit Causal Reasoning Based on Infographic?](https://arxiv.org/abs/2508.06220)
*Keummin Ka,Junhyeong Park,Jahyun Jeon,Youngjae Yu*

Main category: cs.CL

TL;DR: 该研究提出了InfoCausalQA基准，用于评估视觉语言模型在信息图上的因果推理能力。结果显示当前模型在这方面能力不足，需要进一步提升。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在因果推理能力方面，尤其是在混合模态场景下，仍有待探索。需要一个专门的基准来评估模型在信息图等复杂数据上的因果推理能力。

Method: 创建了一个名为InfoCausalQA的新基准，包含两个子任务：基于数值趋势的数量因果推理和涉及五种因果关系（原因、结果、干预、反事实、时间）的语义因果推理。该基准包含494个信息图-文本对，并使用GPT-4o生成了1,482个多项选择问答对，其中手动审查确保问题需要深层理解而非表面线索。

Result: 实验结果表明，当前视觉语言模型在计算因果推理方面能力有限，在语义因果推理方面表现更差，与人类相比存在显著差距，显示出在利用信息图进行因果推断方面存在不足。

Conclusion: 目前的大型语言模型在因果推理方面，特别是在处理信息图等融合了结构化视觉数据和文本信息的混合模态场景时，能力有限。InfoCausalQA基准的建立突显了提升多模态人工智能系统因果推理能力的重要性。

Abstract: Recent advances in Vision-Language Models (VLMs) have demonstrated impressive
capabilities in perception and reasoning. However, the ability to perform
causal inference -- a core aspect of human cognition -- remains underexplored,
particularly in multimodal settings. In this study, we introduce InfoCausalQA,
a novel benchmark designed to evaluate causal reasoning grounded in
infographics that combine structured visual data with textual context. The
benchmark comprises two tasks: Task 1 focuses on quantitative causal reasoning
based on inferred numerical trends, while Task 2 targets semantic causal
reasoning involving five types of causal relations: cause, effect,
intervention, counterfactual, and temporal. We manually collected 494
infographic-text pairs from four public sources and used GPT-4o to generate
1,482 high-quality multiple-choice QA pairs. These questions were then
carefully revised by humans to ensure they cannot be answered based on
surface-level cues alone but instead require genuine visual grounding. Our
experimental results reveal that current VLMs exhibit limited capability in
computational reasoning and even more pronounced limitations in semantic causal
reasoning. Their significantly lower performance compared to humans indicates a
substantial gap in leveraging infographic-based information for causal
inference. Through InfoCausalQA, we highlight the need for advancing the causal
reasoning abilities of multimodal AI systems.

</details>


### [131] [Large Language Model Data Generation for Enhanced Intent Recognition in German Speech](https://arxiv.org/abs/2508.06277)
*Theresa Pekarek Rosin,Burak Can Kaplan,Stefan Wermter*

Main category: cs.CL

TL;DR: 本研究提出了一种新的方法，结合适配的Whisper ASR模型和LLM生成的合成数据，用于识别老年德语使用者的语音意图，结果显示该方法能有效提升性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有意图识别（IR）方法主要针对短命令且多为英语，本研究旨在解决这些限制，专注于识别老年德语使用者语音中的意图。

Method: 提出了一种结合适配的Whisper ASR模型（SVC-de）和基于Transformer的语言模型的方法，后者在由LeoLM、Llama3和ChatGPT生成的三种合成文本数据集上进行了训练。

Result: 结果表明，合成的LLM生成数据显著提高了分类性能，增强了对不同说话风格和未见词汇的鲁棒性。

Conclusion: 生成式人工智能可以有效地弥合低资源领域的數據差距，并且LeoLM在德语意图识别方面的数据集质量优于ChatGPT。

Abstract: Intent recognition (IR) for speech commands is essential for artificial
intelligence (AI) assistant systems; however, most existing approaches are
limited to short commands and are predominantly developed for English. This
paper addresses these limitations by focusing on IR from speech by elderly
German speakers. We propose a novel approach that combines an adapted Whisper
ASR model, fine-tuned on elderly German speech (SVC-de), with Transformer-based
language models trained on synthetic text datasets generated by three
well-known large language models (LLMs): LeoLM, Llama3, and ChatGPT. To
evaluate the robustness of our approach, we generate synthetic speech with a
text-to-speech model and conduct extensive cross-dataset testing. Our results
show that synthetic LLM-generated data significantly boosts classification
performance and robustness to different speaking styles and unseen vocabulary.
Notably, we find that LeoLM, a smaller, domain-specific 13B LLM, surpasses the
much larger ChatGPT (175B) in dataset quality for German intent recognition.
Our approach demonstrates that generative AI can effectively bridge data gaps
in low-resource domains. We provide detailed documentation of our data
generation and training process to ensure transparency and reproducibility.

</details>


### [132] [Matrix-Driven Instant Review: Confident Detection and Reconstruction of LLM Plagiarism on PC](https://arxiv.org/abs/2508.06309)
*Ruichong Zhang*

Main category: cs.CL

TL;DR: MDIR通过矩阵分析和极大偏差理论解决了现有LLM抄袭检测方法的不足，能够准确高效地检测抄袭，即使在模型经过大量转换后也能奏效。


<details>
  <summary>Details</summary>
Motivation: 现有LLM抄袭检测方法在重建权重对应关系、计算p值等统计显著性度量以及区分相似模型和抄袭模型方面存在不足。虽然存在对LLM的知识产权担忧，但解决这些问题的现有方法效果不佳。

Method: MDIR利用矩阵分析和极大偏差理论来准确重建权重关系，提供严格的p值估计，并且仅关注权重相似性，无需进行完整的模型推理。

Result: 实验结果表明，MDIR即使在经过随机置换和持续预训练（涉及数万亿个标记）等广泛转换后，仍能可靠地检测到抄袭。此外，所有检测都可以在一小时内在单台PC上完成。

Conclusion: MDIR是一种高效且可访问的新颖方法，可以准确检测LLM抄袭，即使在经过大量转换后也能可靠地检测到抄袭。

Abstract: In recent years, concerns about intellectual property (IP) in large language
models (LLMs) have grown significantly. Plagiarizing other LLMs (through direct
weight copying, upcycling, pruning, or continual pretraining) and claiming
authorship without properly attributing to the original license, is a serious
misconduct that can lead to significant financial and reputational harm to the
original developers. However, existing methods for detecting LLM plagiarism
fall short in key areas. They fail to accurately reconstruct weight
correspondences, lack the ability to compute statistical significance measures
such as $p$-values, and may mistakenly flag models trained on similar data as
being related. To address these limitations, we propose Matrix-Driven Instant
Review (MDIR), a novel method that leverages matrix analysis and Large
Deviation Theory. MDIR achieves accurate reconstruction of weight
relationships, provides rigorous $p$-value estimation, and focuses exclusively
on weight similarity without requiring full model inference. Experimental
results demonstrate that MDIR reliably detects plagiarism even after extensive
transformations, such as random permutations and continual pretraining with
trillions of tokens. Moreover, all detections can be performed on a single PC
within an hour, making MDIR both efficient and accessible.

</details>


### [133] [Cyberbullying Detection via Aggression-Enhanced Prompting](https://arxiv.org/abs/2508.06360)
*Aisha Saeid,Anu Sabu,Girish A. Koushik,Ferrante Neri,Diptesh Kanojia*

Main category: cs.CL

TL;DR: 本研究透過將攻擊性檢測作為輔助任務，並採用增強的提示管道方法，成功提升了大型語言模型在網絡欺凌檢測中的性能，證實了輔助任務對提升模型泛化能力的重要性。


<details>
  <summary>Details</summary>
Motivation: 網絡欺凌的檢測仍然是一個關鍵的挑戰，因為其表達方式微妙且多樣。本研究旨在探討將攻擊性檢測作為輔助任務整合到統一訓練框架中，是否能增強大型語言模型（LLMs）在網絡欺凌檢測中的泛化能力和性能。

Method: 透過在統一訓練框架內整合攻擊性檢測作為輔助任務，並評估了零樣本、少樣本、獨立 LoRA 微調和多任務學習 (MTL) 等多種策略。此外，研究還提出了一種增強的提示管道方法，將攻擊性預測嵌入到網絡欺凌檢測提示中，以提供上下文增強。

Result: 增強的提示管道方法持續優於標準的 LoRA 微調，表明受攻擊性信息影響的上下文顯著提高了網絡欺凌檢測的性能。

Conclusion: 整合的輔助任務，例如攻擊性檢測，可以提高大型語言模型在社交網絡安全關鍵應用中的泛化能力。

Abstract: Detecting cyberbullying on social media remains a critical challenge due to
its subtle and varied expressions. This study investigates whether integrating
aggression detection as an auxiliary task within a unified training framework
can enhance the generalisation and performance of large language models (LLMs)
in cyberbullying detection. Experiments are conducted on five aggression
datasets and one cyberbullying dataset using instruction-tuned LLMs. We
evaluated multiple strategies: zero-shot, few-shot, independent LoRA
fine-tuning, and multi-task learning (MTL). Given the inconsistent results of
MTL, we propose an enriched prompt pipeline approach in which aggression
predictions are embedded into cyberbullying detection prompts to provide
contextual augmentation. Preliminary results show that the enriched prompt
pipeline consistently outperforms standard LoRA fine-tuning, indicating that
aggression-informed context significantly boosts cyberbullying detection. This
study highlights the potential of auxiliary tasks, such as aggression
detection, to improve the generalisation of LLMs for safety-critical
applications on social networks.

</details>


### [134] [Evaluating Style-Personalized Text Generation: Challenges and Directions](https://arxiv.org/abs/2508.06374)
*Anubhav Jangra,Bahareh Sarrafzadeh,Adrian de Wynter,Silviu Cucerzan,Sujay Kumar Jauhar*

Main category: cs.CL

TL;DR: This paper questions traditional evaluation metrics (BLEU, ROUGE) for style-personalized text generation and proposes using style embeddings and LLM-as-judge. Tested on a benchmark across different tasks and settings, the study concludes that a combination of diverse metrics is most effective for evaluation.


<details>
  <summary>Details</summary>
Motivation: The research addresses the limited exploration of evaluation methods in the low-resource author style-personalized text generation space, questioning the effectiveness of existing metrics like BLEU and ROUGE.

Method: The paper explores the effectiveness of widely adopted evaluation metrics like BLEU and ROUGE, and investigates alternative evaluation paradigms such as style embeddings and LLM-as-judge for evaluating style-personalized text generation. These metrics were evaluated using a style discrimination benchmark spanning eight writing tasks across three settings: domain discrimination, authorship attribution, and LLM personalized vs. non-personalized discrimination.

Result: The study evaluates various metrics and their ensembles using a style discrimination benchmark, offering conclusive evidence for the effectiveness of diverse metric ensembles in evaluating style-personalized text generation.

Conclusion: The paper provides conclusive evidence supporting the adoption of an ensemble of diverse evaluation metrics for effectively evaluating style-personalized text generation.

Abstract: While prior research has built tools and benchmarks towards style
personalized text generation, there has been limited exploration of evaluation
in low-resource author style personalized text generation space. Through this
work, we question the effectiveness of the widely adopted evaluation metrics
like BLEU and ROUGE, and explore other evaluation paradigms such as style
embeddings and LLM-as-judge to holistically evaluate the style personalized
text generation task. We evaluate these metrics and their ensembles using our
style discrimination benchmark, that spans eight writing tasks, and evaluates
across three settings, domain discrimination, authorship attribution, and LLM
personalized vs non-personalized discrimination. We provide conclusive evidence
to adopt ensemble of diverse evaluation metrics to effectively evaluate style
personalized text generation.

</details>


### [135] [LLMs vs. Chinese Anime Enthusiasts: A Comparative Study on Emotionally Supportive Role-Playing](https://arxiv.org/abs/2508.06388)
*Lanlan Qiu,Xiao Pu,Yeqi Feng,Tianxing He*

Main category: cs.CL

TL;DR: 本研究构建了首个动漫角色的情感支持角色扮演（ESRP）数据集ChatAnime，评估了10个大型语言模型。结果显示，最佳模型在角色扮演和情感支持上优于人类，但在回应多样性上不如人类。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型在结合角色扮演对话和提供情感支持方面的研究空白，本研究以动漫角色为案例，旨在使大型语言模型能够提供情感支持，同时保持特定的角色特征。

Method: 构建了一个包含2,400个人类编写答案和24,000个LLM生成答案的数据集，并通过132,000多个人工标注进行支持。该数据集选取了20个热门动漫角色，设计了60个以情感为中心的真实场景问题，并招募了40名精通动漫角色的粉丝进行角色扮演对话数据收集。研究还设计了一个包含9个细粒度指标的用户体验评估系统，从基本对话、角色扮演和情感支持三个维度以及回应多样性方面评估LLM的表现。

Result: 在角色扮演和情感支持方面，表现最佳的大型语言模型已超越人类粉丝，但在回应多样性方面人类仍占优势。

Conclusion: 该研究首次提出了面向动漫角色的情感支持角色扮演（ESRP）数据集ChatAnime，并对10个大型语言模型进行了评估。实验结果表明，在角色扮演和情感支持方面，表现最佳的大型语言模型已超越人类粉丝，但在回应多样性方面人类仍占优势。该研究旨在为未来优化大型语言模型在ESRP任务中的表现提供资源和见解。

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities in
role-playing conversations and providing emotional support as separate research
directions. However, there remains a significant research gap in combining
these capabilities to enable emotionally supportive interactions with virtual
characters. To address this research gap, we focus on anime characters as a
case study because of their well-defined personalities and large fan bases.
This choice enables us to effectively evaluate how well LLMs can provide
emotional support while maintaining specific character traits. We introduce
ChatAnime, the first Emotionally Supportive Role-Playing (ESRP) dataset. We
first thoughtfully select 20 top-tier characters from popular anime communities
and design 60 emotion-centric real-world scenario questions. Then, we execute a
nationwide selection process to identify 40 Chinese anime enthusiasts with
profound knowledge of specific characters and extensive experience in
role-playing. Next, we systematically collect two rounds of dialogue data from
10 LLMs and these 40 Chinese anime enthusiasts. To evaluate the ESRP
performance of LLMs, we design a user experience-oriented evaluation system
featuring 9 fine-grained metrics across three dimensions: basic dialogue,
role-playing and emotional support, along with an overall metric for response
diversity. In total, the dataset comprises 2,400 human-written and 24,000
LLM-generated answers, supported by over 132,000 human annotations.
Experimental results show that top-performing LLMs surpass human fans in
role-playing and emotional support, while humans still lead in response
diversity. We hope this work can provide valuable resources and insights for
future research on optimizing LLMs in ESRP. Our datasets are available at
https://github.com/LanlanQiu/ChatAnime.

</details>


### [136] [Quantifying Conversation Drift in MCP via Latent Polytope](https://arxiv.org/abs/2508.06418)
*Haoran Shi,Hongwei Yao,Shuo Shao,Shaopeng Jiao,Ziqi Peng,Zhan Qin,Cong Wang*

Main category: cs.CL

TL;DR: SecMCP通过在潜在多 polytope 空间中对LLM激活向量进行建模，识别对话动态的异常变化，从而能够主动检测对话劫持、误导和数据泄露。


<details>
  <summary>Details</summary>
Motivation: MCP的非隔离执行上下文引入了关键的安全和隐私风险，例如工具中毒或间接提示注入，可能导致对话劫持、虚假信息传播或数据泄露。现有的防御措施（如基于规则的过滤器或LLM驱动的检测）因其依赖静态签名、计算效率低下以及无法量化对话劫持而显得不足。

Method: SecMCP通过在潜在多胞体空间中对LLM激活向量进行建模，识别对话动态的异常变化，从而能够主动检测对话劫持、误导和数据泄露。

Result: SecMCP在三种最先进的LLM（Llama3、Vicuna、Mistral）和基准数据集（MS MARCO、HotpotQA、FinQA）上进行了评估，展示了超过0.915的AUROC得分，同时保持了系统的可用性。

Conclusion: SecMCP是一个安全的框架，能够检测和量化由对抗性外部知识引起的对话漂移、潜在空间轨迹的偏差。它通过在潜在多胞体空间中对LLM激活向量进行建模，识别对话动态的异常变化，从而能够主动检测对话劫持、误导和数据泄露。SecMCP在三种最先进的LLM（Llama3、Vicuna、Mistral）和基准数据集（MS MARCO、HotpotQA、FinQA）上进行了评估，展示了超过0.915的AUROC得分，同时保持了系统的可用性。

Abstract: The Model Context Protocol (MCP) enhances large language models (LLMs) by
integrating external tools, enabling dynamic aggregation of real-time data to
improve task execution. However, its non-isolated execution context introduces
critical security and privacy risks. In particular, adversarially crafted
content can induce tool poisoning or indirect prompt injection, leading to
conversation hijacking, misinformation propagation, or data exfiltration.
Existing defenses, such as rule-based filters or LLM-driven detection, remain
inadequate due to their reliance on static signatures, computational
inefficiency, and inability to quantify conversational hijacking. To address
these limitations, we propose SecMCP, a secure framework that detects and
quantifies conversation drift, deviations in latent space trajectories induced
by adversarial external knowledge. By modeling LLM activation vectors within a
latent polytope space, SecMCP identifies anomalous shifts in conversational
dynamics, enabling proactive detection of hijacking, misleading, and data
exfiltration. We evaluate SecMCP on three state-of-the-art LLMs (Llama3,
Vicuna, Mistral) across benchmark datasets (MS MARCO, HotpotQA, FinQA),
demonstrating robust detection with AUROC scores exceeding 0.915 while
maintaining system usability. Our contributions include a systematic
categorization of MCP security threats, a novel latent polytope-based
methodology for quantifying conversation drift, and empirical validation of
SecMCP's efficacy.

</details>


### [137] [Learning the Topic, Not the Language: How LLMs Classify Online Immigration Discourse Across Languages](https://arxiv.org/abs/2508.06435)
*Andrea Nasuto,Stefano Maria Iacus,Francisco Rowe,Devika Jain*

Main category: cs.CL

TL;DR: LLMs can learn cross-lingual classification with minimal fine-tuning, even correcting biases, making research more scalable and inclusive. Open-source models offer a cost-effective alternative.


<details>
  <summary>Details</summary>
Motivation: To examine whether knowledge acquired through fine-tuning in a few languages can transfer to unseen languages that only appeared during pre-training, especially in the context of social-science research using LLMs.

Method: Fine-tuned lightweight LLaMA 3.2-3B models on monolingual, bilingual, or multilingual datasets to classify immigration-related tweets across 13 languages.

Result: LLMs fine-tuned in one or two languages can reliably classify immigration-related content in unseen languages. Multilingual fine-tuning improves pro/anti-immigration stance detection. Minimal exposure to under-represented languages during fine-tuning significantly reduces pre-training bias.

Conclusion: LLMs fine-tuned with limited language data can generalize to unseen languages for topic detection, and lightweight interventions can correct pre-training biases. Multilingual fine-tuning improves stance detection.

Abstract: Large language models (LLMs) are transforming social-science research by
enabling scalable, precise analysis. Their adaptability raises the question of
whether knowledge acquired through fine-tuning in a few languages can transfer
to unseen languages that only appeared during pre-training. To examine this, we
fine-tune lightweight LLaMA 3.2-3B models on monolingual, bilingual, or
multilingual data sets to classify immigration-related tweets from X/Twitter
across 13 languages, a domain characterised by polarised, culturally specific
discourse. We evaluate whether minimal language-specific fine-tuning enables
cross-lingual topic detection and whether adding targeted languages corrects
pre-training biases. Results show that LLMs fine-tuned in one or two languages
can reliably classify immigration-related content in unseen languages. However,
identifying whether a tweet expresses a pro- or anti-immigration stance
benefits from multilingual fine-tuning. Pre-training bias favours dominant
languages, but even minimal exposure to under-represented languages during
fine-tuning (as little as $9.62\times10^{-11}$ of the original pre-training
token volume) yields significant gains. These findings challenge the assumption
that cross-lingual mastery requires extensive multilingual training: limited
language coverage suffices for topic-level generalisation, and structural
biases can be corrected with lightweight interventions. By releasing
4-bit-quantised, LoRA fine-tuned models, we provide an open-source,
reproducible alternative to proprietary LLMs that delivers 35 times faster
inference at just 0.00000989% of the dollar cost of the OpenAI GPT-4o model,
enabling scalable, inclusive research.

</details>


### [138] [Echoes of Automation: The Increasing Use of LLMs in Newsmaking](https://arxiv.org/abs/2508.06445)
*Abolfazl Ansari,Delvin Ce Zhang,Nafis Irtiza Tripto,Dongwon Lee*

Main category: cs.CL

TL;DR: 本研究分析了40,000多篇新闻文章，发现生成式AI在新闻业中的使用呈上升趋势，尤其是在地方和大学新闻中。生成式AI会提高词汇丰富度和可读性，但会降低正式性，导致写作风格趋于统一。


<details>
  <summary>Details</summary>
Motivation: 生成式AI（GenAI）的快速崛起，特别是大型语言模型（LLMs），引发了人们对新闻业完整性和作者身份的担忧。

Method: 本研究使用三种先进的AI文本检测器（如Binoculars、Fast-Detect GPT和GPTZero）分析了来自主要、地方和大学新闻媒体的40,000多篇新闻文章，并进行了句子级别和语言学分析。

Result: 研究发现，近年来生成式AI的使用显著增加，尤其是在地方和大学新闻中。在句子层面，大型语言模型经常用于新闻的开头部分，而结论部分通常是手动编写的。语言学分析表明，生成式AI可以提高词汇丰富度和可读性，但会降低正式性，导致写作风格更加统一，尤其是在地方媒体中。

Conclusion: 生成式AI（特别是大型语言模型）在新闻媒体中的使用日益增加，尤其是在地方和大学新闻中。生成式AI会提高新闻的词汇丰富度和可读性，但会降低正式性，导致写作风格趋于统一，尤其是在地方媒体中。

Abstract: The rapid rise of Generative AI (GenAI), particularly LLMs, poses concerns
for journalistic integrity and authorship. This study examines AI-generated
content across over 40,000 news articles from major, local, and college news
media, in various media formats. Using three advanced AI-text detectors (e.g.,
Binoculars, Fast-Detect GPT, and GPTZero), we find substantial increase of
GenAI use in recent years, especially in local and college news. Sentence-level
analysis reveals LLMs are often used in the introduction of news, while
conclusions usually written manually. Linguistic analysis shows GenAI boosts
word richness and readability but lowers formality, leading to more uniform
writing styles, particularly in local media.

</details>


### [139] [SlimInfer: Accelerating Long-Context LLM Inference via Dynamic Token Pruning](https://arxiv.org/abs/2508.06447)
*Lingkun Long,Rubing Yang,Yushi Huang,Desheng Hui,Ao Zhou,Jianlei Yang*

Main category: cs.CL

TL;DR: SlimInfer通过剪枝冗余令牌来加速LLM长上下文推理，实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法在优化注意力计算时，仍然处理每一层的全部隐藏状态，限制了整体效率。因此，需要一种新的方法来提高长上下文推理的效率。

Method: SlimInfer框架通过在前向传播过程中直接剪枝不太重要的提示令牌来加速推理，并引入了异步KV缓存管理器，以减少内存使用和I/O成本。

Result: SlimInfer在LLaMA3.1-8B-Instruct模型和RTX 4090上，实现了高达2.53倍的首 टोक时间（TTFT）加速和1.88倍的端到端延迟降低，且在LongBench基准测试中未牺牲性能。

Conclusion: SlimInfer通过动态的、细粒度的剪枝机制，在中间层准确地去除冗余的隐藏状态令牌，实现了高效的LLM长上下文推理，同时不牺牲性能。

Abstract: Long-context inference for Large Language Models (LLMs) is heavily limited by
high computational demands. While several existing methods optimize attention
computation, they still process the full set of hidden states at each layer,
limiting overall efficiency. In this work, we propose SlimInfer, an innovative
framework that aims to accelerate inference by directly pruning less critical
prompt tokens during the forward pass. Our key insight is an information
diffusion phenomenon: As information from critical tokens propagates through
layers, it becomes distributed across the entire sequence. This diffusion
process suggests that LLMs can maintain their semantic integrity when excessive
tokens, even including these critical ones, are pruned in hidden states.
Motivated by this, SlimInfer introduces a dynamic fine-grained pruning
mechanism that accurately removes redundant tokens of hidden state at
intermediate layers. This layer-wise pruning naturally enables an asynchronous
KV cache manager that prefetches required token blocks without complex
predictors, reducing both memory usage and I/O costs. Extensive experiments
show that SlimInfer can achieve up to $\mathbf{2.53\times}$ time-to-first-token
(TTFT) speedup and $\mathbf{1.88\times}$ end-to-end latency reduction for
LLaMA3.1-8B-Instruct on a single RTX 4090, without sacrificing performance on
LongBench. Our code will be released upon acceptance.

</details>


### [140] [GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models](https://arxiv.org/abs/2508.06471)
*GLM-4. 5 Team,:,Aohan Zeng,Xin Lv,Qinkai Zheng,Zhenyu Hou,Bin Chen,Chengxing Xie,Cunxiang Wang,Da Yin,Hao Zeng,Jiajie Zhang,Kedong Wang,Lucen Zhong,Mingdao Liu,Rui Lu,Shulin Cao,Xiaohan Zhang,Xuancheng Huang,Yao Wei,Yean Cheng,Yifan An,Yilin Niu,Yuanhao Wen,Yushi Bai,Zhengxiao Du,Zihan Wang,Zilin Zhu,Bohan Zhang,Bosi Wen,Bowen Wu,Bowen Xu,Can Huang,Casey Zhao,Changpeng Cai,Chao Yu,Chen Li,Chendi Ge,Chenghua Huang,Chenhui Zhang,Chenxi Xu,Chenzheng Zhu,Chuang Li,Congfeng Yin,Daoyan Lin,Dayong Yang,Dazhi Jiang,Ding Ai,Erle Zhu,Fei Wang,Gengzheng Pan,Guo Wang,Hailong Sun,Haitao Li,Haiyang Li,Haiyi Hu,Hanyu Zhang,Hao Peng,Hao Tai,Haoke Zhang,Haoran Wang,Haoyu Yang,He Liu,He Zhao,Hongwei Liu,Hongxi Yan,Huan Liu,Huilong Chen,Ji Li,Jiajing Zhao,Jiamin Ren,Jian Jiao,Jiani Zhao,Jianyang Yan,Jiaqi Wang,Jiayi Gui,Jiayue Zhao,Jie Liu,Jijie Li,Jing Li,Jing Lu,Jingsen Wang,Jingwei Yuan,Jingxuan Li,Jingzhao Du,Jinhua Du,Jinxin Liu,Junkai Zhi,Junli Gao,Ke Wang,Lekang Yang,Liang Xu,Lin Fan,Lindong Wu,Lintao Ding,Lu Wang,Man Zhang,Minghao Li,Minghuan Xu,Mingming Zhao,Mingshu Zhai,Pengfan Du,Qian Dong,Shangde Lei,Shangqing Tu,Shangtong Yang,Shaoyou Lu,Shijie Li,Shuang Li,Shuang-Li,Shuxun Yang,Sibo Yi,Tianshu Yu,Wei Tian,Weihan Wang,Wenbo Yu,Weng Lam Tam,Wenjie Liang,Wentao Liu,Xiao Wang,Xiaohan Jia,Xiaotao Gu,Xiaoying Ling,Xin Wang,Xing Fan,Xingru Pan,Xinyuan Zhang,Xinze Zhang,Xiuqing Fu,Xunkai Zhang,Yabo Xu,Yandong Wu,Yida Lu,Yidong Wang,Yilin Zhou,Yiming Pan,Ying Zhang,Yingli Wang,Yingru Li,Yinpei Su,Yipeng Geng,Yitong Zhu,Yongkun Yang,Yuhang Li,Yuhao Wu,Yujiang Li,Yunan Liu,Yunqing Wang,Yuntao Li,Yuxuan Zhang,Zezhen Liu,Zhen Yang,Zhengda Zhou,Zhongpei Qiao,Zhuoer Feng,Zhuorui Liu,Zichen Zhang,Zihan Wang,Zijun Yao,Zikang Wang,Ziqiang Liu,Ziwei Chai,Zixuan Li,Zuodong Zhao,Wenguang Chen,Jidong Zhai,Bin Xu,Minlie Huang,Hongning Wang,Juanzi Li,Yuxiao Dong,Jie Tang*

Main category: cs.CL

TL;DR: GLM-4.5 is a powerful open-source LLM with a hybrid reasoning approach, outperforming many models despite its smaller size, and is now available for research.


<details>
  <summary>Details</summary>
Motivation: To present GLM-4.5, an open-source MoE large language model with a hybrid reasoning method, and to advance research in reasoning and agentic AI systems.

Method: GLM-4.5 is an open-source Mixture-of-Experts (MoE) large language model with 355B total parameters and 32B activated parameters. It features a hybrid reasoning method supporting thinking and direct response modes. Training involved 23T tokens, multi-stage training, expert model iteration, and reinforcement learning.

Result: GLM-4.5 scores 70.1% on TAU-Bench, 91.0% on AIME 24, and 64.2% on SWE-bench Verified. It ranks 3rd overall among evaluated models and 2nd on agentic benchmarks.

Conclusion: GLM-4.5 achieves strong performance across agentic, reasoning, and coding tasks, ranking 3rd overall and 2nd on agentic benchmarks, despite having fewer parameters than competitors. Both GLM-4.5 (355B) and GLM-4.5-Air (106B) are released to advance research.

Abstract: We present GLM-4.5, an open-source Mixture-of-Experts (MoE) large language
model with 355B total parameters and 32B activated parameters, featuring a
hybrid reasoning method that supports both thinking and direct response modes.
Through multi-stage training on 23T tokens and comprehensive post-training with
expert model iteration and reinforcement learning, GLM-4.5 achieves strong
performance across agentic, reasoning, and coding (ARC) tasks, scoring 70.1% on
TAU-Bench, 91.0% on AIME 24, and 64.2% on SWE-bench Verified. With much fewer
parameters than several competitors, GLM-4.5 ranks 3rd overall among all
evaluated models and 2nd on agentic benchmarks. We release both GLM-4.5 (355B
parameters) and a compact version, GLM-4.5-Air (106B parameters), to advance
research in reasoning and agentic AI systems. Code, models, and more
information are available at https://github.com/zai-org/GLM-4.5.

</details>


### [141] [HapticLLaMA: A Multimodal Sensory Language Model for Haptic Captioning](https://arxiv.org/abs/2508.06475)
*Guimin Hu,Daniel Hershcovich,Hasti Seifi*

Main category: cs.CL

TL;DR: HapticLLaMA是一个大型语言模型，用于将触觉振动信号转换为自然语言描述，在虚拟现实、可访问性和康复领域具有应用潜力。


<details>
  <summary>Details</summary>
Motivation: 触觉信号在虚拟现实、可访问性和康复应用中具有重要作用，但先前的影响研究主要集中在视觉和听觉上，触觉信号仍未得到充分探索。

Method: HapticLLaMA是一个多模态感觉语言模型，它将振动信号解释为给定感觉、情感或联想类别中的描述。它采用基于频率和基于EnCodec的触觉标记器将触觉信号转换为离散单元序列，并与LLaMA模型集成。HapticLLaMA分两个阶段进行训练：1）使用基于LoRA的适配的LLaMA架构进行监督微调；2）通过人类反馈强化学习（RLHF）进行微调。

Result: HapticLLaMA在触觉字幕任务上表现出色，METEOR得分为59.98，BLEU-4得分为32.06。超过61%的生成字幕在7分制上的人类评分为3.5分以上，其中RLHF使整体评分分布提高了10%，表明与人类触觉感知的一致性更强。

Conclusion: HapticLLaMA在解释触觉振动信号方面表现出强大的能力，表明大型语言模型在处理和适应感官数据方面具有潜力。

Abstract: Haptic captioning is the task of generating natural language descriptions
from haptic signals, such as vibrations, for use in virtual reality,
accessibility, and rehabilitation applications. While previous multimodal
research has focused primarily on vision and audio, haptic signals for the
sense of touch remain underexplored. To address this gap, we formalize the
haptic captioning task and propose HapticLLaMA, a multimodal sensory language
model that interprets vibration signals into descriptions in a given sensory,
emotional, or associative category. We investigate two types of haptic
tokenizers, a frequency-based tokenizer and an EnCodec-based tokenizer, that
convert haptic signals into sequences of discrete units, enabling their
integration with the LLaMA model. HapticLLaMA is trained in two stages: (1)
supervised fine-tuning using the LLaMA architecture with LoRA-based adaptation,
and (2) fine-tuning via reinforcement learning from human feedback (RLHF). We
assess HapticLLaMA's captioning performance using both automated n-gram metrics
and human evaluation. HapticLLaMA demonstrates strong capability in
interpreting haptic vibration signals, achieving a METEOR score of 59.98 and a
BLEU-4 score of 32.06 respectively. Additionally, over 61% of the generated
captions received human ratings above 3.5 on a 7-point scale, with RLHF
yielding a 10% improvement in the overall rating distribution, indicating
stronger alignment with human haptic perception. These findings highlight the
potential of large language models to process and adapt to sensory data.

</details>


### [142] [Post-training for Efficient Communication via Convention Formation](https://arxiv.org/abs/2508.06482)
*Yilun Hua,Evan Wang,Yoav Artzi*

Main category: cs.CL

TL;DR: 通过微调，可以提高大型语言模型在多轮对话中形成约定俗成的能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多轮交互中不像人类那样能够自然地适应语言和形成约定俗成。

Method: 通过有针对性的微调，在启发式识别的约定俗成示例上对大型语言模型进行后训练。

Result: 后训练的大型语言模型在两个评估基准上都表现出显著提高的约定俗成能力。

Conclusion: 通过有针对性的微调，可以提高大型语言模型在多轮对话中形成和适应约定俗成的能力。

Abstract: Humans communicate with increasing efficiency in multi-turn interactions, by
adapting their language and forming ad-hoc conventions. In contrast, prior work
shows that LLMs do not naturally show this behavior. We develop a post-training
process to develop this ability through targeted fine-tuning on heuristically
identified demonstrations of convention formation. We evaluate with two new
benchmarks focused on this capability. First, we design a focused,
cognitively-motivated interaction benchmark that consistently elicits strong
convention formation trends in humans. Second, we create a new
document-grounded reference completion task that reflects in-the-wild
convention formation behavior. Our studies show significantly improved
convention formation abilities in post-trained LLMs across the two evaluation
methods.

</details>


### [143] [Indian Legal NLP Benchmarks : A Survey](https://arxiv.org/abs/2107.06056)
*Prathamesh Kalamkar,Janani Venugopalan Ph. D.,Vivek Raghavan Ph. D*

Main category: cs.CL

TL;DR: 人工智能在法律领域的进步需要有挑战性的基准。本研究回顾了该领域的现有工作，并提出了创建印度法律自然语言处理新基准的想法，以应对印度法律文本的独特性和挑战。


<details>
  <summary>Details</summary>
Motivation: 人工智能在法律领域的进步需要具有挑战性的基准。由于印度法律文本与普通英语文本存在显著差异，因此有必要为印度法律文本创建专门的、具有挑战性的自然语言处理基准，以促进人工智能在印度法律领域的创新，并惠及人工智能界和法律界。

Method: 通过回顾现有工作并提出创建新基准的想法。

Result: 提出为印度法律自然语言处理创建新基准的想法。

Conclusion: 目前没有具体结论，但提出需要为印度法律文本创建新的自然语言处理基准。

Abstract: Availability of challenging benchmarks is the key to advancement of AI in a
specific field.Since Legal Text is significantly different than normal English
text, there is a need to create separate Natural Language Processing benchmarks
for Indian Legal Text which are challenging and focus on tasks specific to
Legal Systems. This will spur innovation in applications of Natural language
Processing for Indian Legal Text and will benefit AI community and Legal
fraternity. We review the existing work in this area and propose ideas to
create new benchmarks for Indian Legal Natural Language Processing.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [144] [ConiQ: Enabling Concatenated Quantum Error Correction on Neutral Atom Arrays](https://arxiv.org/abs/2508.05779)
*Pengyu Liu,Mingkuan Xu,Hengyun Zhou,Hanrui Wang,Umut A. Acar,Yunong Shi*

Main category: cs.AR

TL;DR: A new quantum compiler, ConiQ, uses innovative techniques (AHA gates and VAIR) to drastically reduce the resources needed for quantum computations using concatenated codes on neutral atom hardware, making fault-tolerant quantum computing more feasible.


<details>
  <summary>Details</summary>
Motivation: Two main challenges hinder the practical application of concatenated codes, especially many-hypercube codes, despite their space efficiency: the lack of efficient implementations for addressable logical gates and the hardware challenges posed by their high degree of parallelism and long-range interactions.

Method: The paper proposes an efficient compilation approach for concatenated codes, specifically many-hypercube codes, targeting neutral atom arrays. This approach utilizes Automorphism-assisted Hierarchical Addressing (AHA) for logical CNOT gates and a Virtual Atom Intermediate Representation (VAIR) for level-wise optimization and legalization. These innovations are implemented in a hardware-aware quantum compiler named ConiQ.

Result: The evaluation shows that ConiQ, using AHA gates, achieves up to 2000x reduction in spacetime overhead and up to 10^6x reduction in compilation time compared to state-of-the-art compilers. AHA gates alone provide an additional overhead reduction of up to 20x.

Conclusion: Concatenated codes, particularly many-hypercube codes, are a promising avenue for near-term fault-tolerant quantum computing, thanks to an efficient compilation approach using AHA logical CNOT gates and VAIR, which significantly reduces spacetime overhead and compilation time for neutral atom arrays.

Abstract: Recent progress on concatenated codes, especially many-hypercube codes,
achieves unprecedented space efficiency. Yet two critical challenges persist in
practice. First, these codes lack efficient implementations of addressable
logical gates. Second, the required high degree of parallelism and long-range
interactions pose significant challenges for current hardware platforms. In
this paper, we propose an efficient compilation approach for concatenated
codes, specifically many-hypercube codes, targeted at neutral atom arrays,
which provide the necessary parallelism and long-range interactions. Our
approach builds on two key innovations. First, we introduce
Automorphism-assisted Hierarchical Addressing (AHA) logical CNOT gates that
significantly reduce spacetime overhead compared to conventional
distillation-based methods. Second, we develop Virtual Atom Intermediate
Representation (VAIR) that enables level-wise optimization and legalization. We
implement these innovations in ConiQ, a hardware-aware quantum compiler
designed to compile fault-tolerant quantum circuits for neutral atom arrays
using many-hypercube codes. Our evaluation demonstrates that ConiQ achieves up
to 2000x reduction in spacetime overhead and up to 10^6x reduction in
compilation time compared to state-of-the-art compilers, with our AHA gates
providing an additional overhead reduction of up to 20x. These results
establish concatenated codes as a promising approach for fault-tolerant quantum
computing in the near future.

</details>


### [145] [ArchXBench: A Complex Digital Systems Benchmark Suite for LLM Driven RTL Synthesis](https://arxiv.org/abs/2508.06047)
*Suresh Purini,Siddhant Garg,Mudit Gaur,Sankalp Bhat,Sohan Mupparapu,Arun Ravindran*

Main category: cs.AR

TL;DR: LLM 在 RTL 设计方面能力有限，即使是最先进的模型也无法处理复杂的数字系统设计。ArchXBench 基准套件旨在推动 LLM 在此领域的研究。


<details>
  <summary>Details</summary>
Motivation: 现代 SoC 数据通路包含深度流水线、特定领域的加速器，但其 RTL 实现和验证仍主要手动完成。尽管大型语言模型（LLM）在 Python 等编程语言方面展现出先进的代码生成能力，但其在 Verilog 类 RTL 方面的应用仍处于初级阶段。现有的基准测试仅使用简单的算术和控制电路来评估生成能力。

Method: 介绍了 ArchXBench，一个包含复杂算术电路和其他高级数字子系统的六级基准套件，涵盖密码学、图像处理、机器学习和信号处理等领域。该基准套件提供了问题描述、设计规范和测试平台，以促进 LLM 驱动的复杂数字系统设计的代理方法的研究。使用 Claude Sonnet 4、GPT 4.1、o4-mini-high 和 DeepSeek R1 模型，在 pass@5 标准下进行了零样本提示评估。

Result: o4-mini-high 在 30 个基准测试中的 16 个（涵盖 Level 1、2 和 3）成功解决，数量最多。然而，从 Level 4 开始，所有模型均未能成功解决。

Conclusion: 目前最先进的大型语言模型（LLM）和提示/代理方法在处理更复杂的数字系统设计方面仍存在明显差距，从 ArchXBench 的 Level 4 开始，所有模型都无法成功解决。

Abstract: Modern SoC datapaths include deeply pipelined, domain-specific accelerators,
but their RTL implementation and verification are still mostly done by hand.
While large language models (LLMs) exhibit advanced code-generation abilities
for programming languages like Python, their application to Verilog-like RTL
remains in its nascent stage. This is reflected in the simple arithmetic and
control circuits currently used to evaluate generative capabilities in existing
benchmarks. In this paper, we introduce ArchXBench, a six-level benchmark suite
that encompasses complex arithmetic circuits and other advanced digital
subsystems drawn from domains such as cryptography, image processing, machine
learning, and signal processing. Architecturally, some of these designs are
purely combinational, others are multi-cycle or pipelined, and many require
hierarchical composition of modules. For each benchmark, we provide a problem
description, design specification, and testbench, enabling rapid research in
the area of LLM-driven agentic approaches for complex digital systems design.
  Using zero-shot prompting with Claude Sonnet 4, GPT 4.1, o4-mini-high, and
DeepSeek R1 under a pass@5 criterion, we observed that o4-mini-high
successfully solves the largest number of benchmarks, 16 out of 30, spanning
Levels 1, 2, and 3. From Level 4 onward, however, all models consistently fail,
highlighting a clear gap in the capabilities of current state-of-the-art LLMs
and prompting/agentic approaches.

</details>


### [146] [Nail: Not Another Fault-Injection Framework for Chisel-generated RTL](https://arxiv.org/abs/2508.06344)
*Robin Sehm,Christian Ewert,Rainer Buchty,Mladen Berekovic,Saleh Mulhem*

Main category: cs.AR

TL;DR: Nail是一个新的Chisel故障注入框架，通过基于状态的注入和运行时软件控制，实现了更精确、更灵活的故障建模，并降低了FPGA实现的资源开销。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Chisel的故障注入（FI）框架在控制粒度上受限于指令级别，这限制了故障建模的精确性。为了更有效地评估集成电路的可靠性，需要一种更精细、更灵活的故障注入方法。

Method: Nail是一个基于Chisel的开源故障注入（FI）框架，它通过引入基于状态的故障（state-based faults）来克服现有框架的局限性。这种方法允许故障场景依赖于特定的系统状态，而不仅仅是指令级别的触发，从而无需精确控制故障激活的时间。Nail还允许用户通过软件在运行时任意修改内部触发状态，并自动生成软件接口，方便地访问被插桩的设计。

Result: Nail框架能够实现状态依赖的故障注入，并且可以通过软件在运行时修改内部触发状态，从而能够对故障参数进行微调。在RISC-V处理器上的实验表明，该方法是可行的，并且在FPGA实现上引入的资源开销小于1%。

Conclusion: Nail框架通过引入基于状态的故障注入，实现了比现有Chisel框架更精细、更可控的故障建模，并且能够通过软件在运行时修改内部触发状态，从而在仿真速度、易用性和可控性之间取得了更好的平衡。该框架在RISC-V处理器上进行了演示和验证，并证明了其在FPGA实现上的低资源开销。

Abstract: Fault simulation and emulation are essential techniques for evaluating the
dependability of integrated circuits, enabling early-stage vulnerability
analysis and supporting the implementation of effective mitigation strategies.
High-level hardware description languages such as Chisel facilitate the rapid
development of complex fault scenarios with minimal modification to the design.
However, existing Chisel-based fault injection (FI) frameworks are limited by
coarse-grained, instruction-level controllability, restricting the precision of
fault modeling. This work introduces Nail, a Chisel-based open-source FI
framework that overcomes these limitations by introducing state-based faults.
This approach enables fault scenarios that depend on specific system states,
rather than solely on instruction-level triggers, thereby removing the need for
precise timing of fault activation. For greater controllability, Nail allows
users to arbitrarily modify internal trigger states via software at runtime. To
support this, Nail automatically generates a software interface, offering
straightforward access to the instrumented design. This enables fine-tuning of
fault parameters during active FI campaigns - a feature particularly beneficial
for FPGA emulation, where synthesis is time-consuming. Utilizing these
features, Nail narrows the gap between the high speed of emulation-based FI
frameworks, the usability of software-based approaches, and the controllability
achieved in simulation. We demonstrate Nail's state-based FI and software
framework by modeling a faulty general-purpose register in a RISC-V processor.
Although this might appear straightforward, it requires state-dependent FI and
was previously impossible without fundamental changes to the design. The
approach was validated in both simulation and FPGA emulation, where the
addition of Nail introduced less than 1% resource overhead.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [147] [Evaluating Universal Machine Learning Force Fields Against Experimental Measurements](https://arxiv.org/abs/2508.05762)
*Sajid Mannan,Vaibhav Bihani,Carmelo Gonzales,Kin Long Kelvin Lee,Nitya Nand Gosvami,Sayan Ranu,Santiago Miret,N M Anoop Krishnan*

Main category: cond-mat.mtrl-sci

TL;DR: UniFFBench 框架评估了通用机器学习力场 (UMLFF) 的实际性能，发现现有模型在计算基准上表现优异，但在实验数据上存在显著差距，无法满足实际应用需求。研究指出了模型在训练数据表示和模拟稳定性方面存在系统性局限性，需要进一步改进以实现真正的通用力场。


<details>
  <summary>Details</summary>
Motivation: 通用机器学习力场 (UMLFF) 有潜力通过实现跨元素周期的快速原子模拟来彻底改变材料科学。然而，它们在现实世界中的性能评估有限，仅限于可能无法反映实际性能的计算基准。

Method: 本研究提出了 UniFFBench 框架，该框架通过对约 1500 种精心策划的、涵盖不同化学环境、键合类型、结构复杂性和弹性性质的矿物结构进行实验测量，来评估通用机器学习力场 (UMLFF)。研究系统性地评估了六种最先进的 UMLFF，并分析了模拟稳定性与机械性能准确性之间的关系。

Result: 研究发现，在计算基准上表现出色的模型在面对实验复杂性时常常失败，即使是表现最好的模型，其密度预测误差也高于实际应用所需的阈值。此外，模拟稳定性和机械性能准确性之间存在脱节，预测误差与训练数据的表示相关，而非模型本身。

Conclusion: 目前的计算基准可能高估了模型在复杂化学空间中的可靠性。UniFFBench 确立了基本 实验验证标准，并揭示了必须解决的系统性局限性，才能实现真正的通用力场能力。

Abstract: Universal machine learning force fields (UMLFFs) promise to revolutionize
materials science by enabling rapid atomistic simulations across the periodic
table. However, their evaluation has been limited to computational benchmarks
that may not reflect real-world performance. Here, we present UniFFBench, a
comprehensive framework for evaluating UMLFFs against experimental measurements
of ~1,500 carefully curated mineral structures spanning diverse chemical
environments, bonding types, structural complexity, and elastic properties. Our
systematic evaluation of six state-of-the-art UMLFFs reveals a substantial
reality gap: models achieving impressive performance on computational
benchmarks often fail when confronted with experimental complexity. Even the
best-performing models exhibit higher density prediction error than the
threshold required for practical applications. Most strikingly, we observe
disconnects between simulation stability and mechanical property accuracy, with
prediction errors correlating with training data representation rather than the
modeling method. These findings demonstrate that while current computational
benchmarks provide valuable controlled comparisons, they may overestimate model
reliability when extrapolated to experimentally complex chemical spaces.
Altogether, UniFFBench establishes essential experimental validation standards
and reveals systematic limitations that must be addressed to achieve truly
universal force field capabilities.

</details>


### [148] [Emerging ultra-wide band gap semiconductors for future high-frequency electronics](https://arxiv.org/abs/2508.05823)
*Emily M. Garrity,Theodora Ciobanu,Andriy Zakutayev,Vladan Stevanovic*

Main category: cond-mat.mtrl-sci

TL;DR: 高通量计算筛选新半导体材料以满足未来电子设备需求。


<details>
  <summary>Details</summary>
Motivation: 为了满足先进电子系统日益增长的需求，下一代电力和射频半导体器件需要在保持紧凑的同时，在高功率和开关频率下高效运行。然而，现有的GaN半导体器件无法满足所有这些需求，而新兴的超宽带隙（UWBG）替代材料（如金刚石、氮化硼、氮化铝和氧化镓）也面临晶圆可用性、掺杂困难和热管理等挑战。

Method: 本研究通过计算建模，结合了Johnson和Baliga高频优值以及热导率，以评估其在射频和功率器件中的潜力。

Result: 研究发现存在大量可供探索的替代材料，并展示了这些材料在电动汽车充电器、固态变压器、亚太赫兹通信和先进雷达技术等应用中推动性能边界的潜力。

Conclusion: 本研究通过高通量计算筛选了用于高频电子器件的新型半导体材料，并讨论了部分候选材料的掺杂和合成问题，为推动电子器件性能边界奠定了基础。

Abstract: To meet the growing demands of advanced electronic systems, next-generation
power and RF semiconductor devices must operate efficiently at higher power
levels and switching frequencies while remaining compact. Current
state-of-the-art GaN semiconductor devices alone cannot meet all these demands.
Emerging ultra-wide band gap (UWBG) alternatives like diamond, BN, AlN, and
Ga2O3, face significant challenges including limited wafer availability, doping
difficulties, and thermal management constraints. Herein we conduct a
high-throughput computational screening for new semiconductors for
high-frequency electronics. In our analysis we compute the modeled Johnson and
Baliga high-frequency figures of merit in combination with thermal conductivity
to assess their potential for RF and power devices. We show that there are
plenty of alternative materials to explore and conclude by discussing
dopability and synthesis of select candidate materials. This study lays the
foundation for discovering new semiconductors that can push the boundaries of
performance in applications ranging from EV chargers and solid-state
transformers to sub-THz communications and advanced radar technologies.

</details>


### [149] [Structural and Optical Properties of Crystal Ion Sliced BaTiO$_3$ Thin Films](https://arxiv.org/abs/2508.05874)
*Hossein Esfandiar,Fatemeh Abtahi,Trevor G. Vrckovnik,G. Quyet Ngo,Rene Heller,Ulrich Kentsch,Fabian Ganss,Stefan Facsko,Uta Lucchesi,Stephan Winnerl,Falk Eilenberger,Dennis Arslan,Sebastian W. Schmitt*

Main category: cond-mat.mtrl-sci

TL;DR: Thermal annealing effectively repairs lattice damage in Barium Titanate films processed with Crystal Ion Slicing, restoring their structural and optical properties for integrated photonics applications.


<details>
  <summary>Details</summary>
Motivation: Barium titanate (BaTiO3) is a compelling material for integrated photonics due to its strong electro-optic and second-order nonlinear properties, but ion implantation during CIS processing introduces lattice damage that can degrade performance.

Method: The study demonstrates that post-slicing thermal annealing effectively restores the structural integrity and optical quality of CIS-processed BaTiO3 flakes, using Raman spectroscopy and SHG microscopy to confirm the recovery of crystallinity and reorientation of ferroelectric domains, and optical measurements to validate the linear dispersion.

Result: Post-slicing thermal annealing restores structural integrity and optical quality of CIS-processed BaTiO3 flakes. Raman spectroscopy confirms crystallinity recovery, SHG microscopy reveals ferroelectric domain reorientation and restoration of second-order nonlinear susceptibility, and optical measurements show linear dispersion matching bulk BaTiO3.

Conclusion: The study qualifies CIS combined with thermal annealing as a viable and scalable manufacturing strategy for high-quality BTOI platforms, enabling advanced integrated photonic devices.

Abstract: Barium titanate (BaTiO$_3$) is a compelling material for integrated photonics
due to its strong electro-optic and second-order nonlinear properties. Crystal
Ion Slicing (CIS) presents a scalable and CMOS-compatible route for fabricating
thin BaTiO$_3$ films; however, ion implantation during CIS introduces lattice
damage that can degrade structural and optical performance. In this study, we
demonstrate that post-slicing thermal annealing effectively restores the
structural integrity and optical quality of CIS-processed BaTiO$_3$ flakes.
Raman spectroscopy confirms the recovery of crystallinity, while
second-harmonic generation (SHG) microscopy reveals systematic reorientation of
ferroelectric domains and restoration of the associated second-order nonlinear
susceptibility tensor $X^{(2)}$. Notably, SHG signals persist even in regions
with weak Raman signatures, indicating that long-range ferroelectric order can
survive despite partial lattice disruption. Optical measurements show that the
linear dispersion of annealed CIS flakes closely matches that of bulk
BaTiO$_3$, validating their suitability for photonic integration. Together,
these results qualify CIS - combined with thermal annealing - as a viable and
scalable manufacturing strategy for high-quality BaTiO$_3$-on-insulator (BTOI)
platforms, enabling advanced integrated photonic devices for modulation,
frequency conversion, and quantum optics.

</details>


### [150] [Revisiting $μ$SR Studies of Ion Dynamics in the Light of Extended Kubo-Toyabe Model](https://arxiv.org/abs/2508.05968)
*Takashi U. Ito,Ryosuke Kadono*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究通过改进dKT函数模型，为Na_xCoO_2的μ±SR数据提供了新的解释，支持μ+自扩散而非钠离子扩散，并解决了该领域研究中的一些争议。


<details>
  <summary>Details</summary>
Motivation: 为了描述在动态和静态内磁场共存下的自旋弛豫，并解决dKT函数在离子扩散μSR研究中存在的长期不一致性问题。

Method: 通过扩展动力学Kubo-Toyabe（dKT）函数来描述自旋弛豫，并利用该函数对Na_xCoO_2的μ±SR数据进行了详细的重新评估。

Result: 重新评估Na_xCoO_2的μ±SR数据不支持传统的钠离子扩散解释，反而支持μ+自扩散理论，从经典越垒跳跃机制的角度解决了dKT函数在离子扩散μSR研究中存在的长期不一致性问题。

Conclusion: 该研究通过扩展动力学Kubo-Toyabe（dKT）函数来描述在动态和静态内磁场共存下的自旋弛豫，并重新评估了Na_xCoO_2的μ±SR数据，结果不支持传统的钠离子扩散解释，反而支持μ+自扩散理论，解决了dKT函数在离子扩散μSR研究中存在的长期不一致性问题，并从经典越垒跳跃机制的角度进行了阐释。

Abstract: The dynamical Kubo-Toyabe (dKT) function is extended to describe the spin
relaxation under the coexisting dynamical and static internal magnetic fields.
A detailed re-evaluation of the previous $\mu^\pm$SR data in Na$_x$CoO$_2$
using this function disfavors the conventional interpretation based on
sodium-ion diffusion and instead supports the $\mu^+$ self-diffusion scenario.
This also resolves the long-standing inconsistencies in the dKT-function-based
$\mu$SR studies on ion diffusion from the viewpoint of classical
over-barrier-jump mechanism.

</details>


### [151] [Vacuum Dealloyed Brass as Li-Metal Battery Current Collector: Effect of Zinc and Porosity](https://arxiv.org/abs/2508.06015)
*Eric V Woods,Xinren Chen,Shaolou Wei,Alisson Kwiatkowski da Silva,Ayman A El-Zoka,J Manoj Prabhakar,Tim M Schwarz,Yongqiang Kang,Leonardo S Aota,Mahander P Singh,Katja Angenendt,Ozge Ozgun,Matic Jovivcevic-Klug,Patricia Jovivcevic-Klug,Christian Bross,Jian Liu,Rene de Kloe,Gerhard Dehm,Stefan Zaefferer,Yug Joshi,Baptiste Gault*

Main category: cond-mat.mtrl-sci

TL;DR: 通过控制黄铜集流体的蒸汽相脱合金温度，可以精确调控表面锌含量，实现稳定锂金属电池性能。约1%的表面锌含量是最佳选择，可显著提高库仑效率和循环寿命。


<details>
  <summary>Details</summary>
Motivation: 锂金属电池具有比石墨锂离子电池更高的能量密度潜力，但锂枝晶的生长带来了安全风险。虽然多孔集流体已被证明可以抑制枝晶生长，但其最佳孔隙率和成分仍不明确。

Method: 通过在500至800摄氏度的温度范围内进行蒸汽相脱合金（VPD）处理黄铜（Cu63Zn37），控制集流体表面的锌含量。研究了温度对表面锌浓度的影响，并建立了处理温度与表面成分之间的预测关系。

Result: 研究表明，在VPD过程中，温度是控制表面锌含量的关键因素，从500摄氏度的8%降低到800摄氏度的1%以下。当锌含量最低时（约1%），电池库仑效率（CE）在100次循环后仍保持在90%以上；而当锌含量较高时，CE则下降至约70%。

Conclusion: 通过精确控制表面锌含量（约1个原子百分比）可以实现稳定的锂金属电池运行，有效抑制容量衰减并实现均匀锂沉积。本研究为多功能集流体的设计提供了依据，并展示了可扩展的蒸汽相脱合金（VPD）生产工艺，以支持下一代电池的发展。

Abstract: "Anode-free" lithium-metal batteries promise significantly higher energy
density than conventional graphite-based lithium-ion batteries; however,
lithium dendrite growth can lead to internal short circuits with associated
safety risks. While porous current collectors can suppress dendrite growth,
optimal porosity and composition remain unknown. Here, we show that the
temperature during vapor phase dealloying (VPD) of alpha-brass (Cu63Zn37)
controls the surface Zn concentration, decreasing from 8 percent to below 1
percent from 500 to 800 degrees C. The surface composition is controlled by the
temperature-dependent diffusion. A battery cell maintains greater than 90
percent Coulombic efficiency (CE) over 100 cycles when the Zn content is the
lowest, whereas the higher-Zn samples degraded to approximately 70 percent CE.
The difference in surface composition has hence dramatic effects on battery
performance, and our results demonstrate how precise compositional control
enables stable lithium-metal battery operation, establishing about 1 atomic
percent surface Zn as optimal for preventing capacity fading and uniform
lithium plating, while establishing predictive relationships between processing
temperature and surface composition. This work provides design rules for
multifunctional current collectors and demonstrates scalable VPD production for
next-generation batteries.

</details>


### [152] [Operation Regimes and Design Principles of Delta-E Effect Sensors](https://arxiv.org/abs/2508.06114)
*Fatih Ilgaz,Elizaveta Spetzler,Patrick Wiegand,Robert Rieger,Jeffrey McCord,Benjamin Spetzler*

Main category: cond-mat.mtrl-sci

TL;DR: Delta-E 效应传感器的性能受几何结构影响，存在三种工作模式，边界随磁层厚度变化，这影响了灵敏度和噪声的权衡。


<details>
  <summary>Details</summary>
Motivation: Delta-E 效应传感器在探测弱磁场方面显示出潜力，但其性能难以预测，因为信号和噪声特性受相互依赖的参数（如磁层几何结构、磁微结构和损耗）的影响。

Method: 通过组合测量和模拟，对亚毫米级 Delta-E 效应传感器（包括 24 种不同的器件配置）进行系统性实验研究，以识别磁层几何结构对性能的影响。

Result: 研究结果揭示了三种不同的工作模式——由电子噪声、磁噪声和非线性主导——其边界随着磁层厚度的系统性变化而移动。这种模式行为决定了灵敏度和噪声之间的权衡，最终决定了传感器的探测极限。

Conclusion: 该研究为优化传感器性能和可扩展设计先进的 Delta-E 效应传感器系统奠定了必要的基础。

Abstract: Delta-E effect-based magnetoelectric sensors have emerged as promising
technology for detecting weak magnetic fields at low frequencies. However, the
performance of such sensors remains difficult to predict, as signal and noise
characteristics are dictated by interdependent parameters such as magnetic
layer geometry, magnetic microstructure, and loss. In this work, we present a
systematic experimental study of sub-mm-sized delta-E effect sensors,
comprising 24 device configurations that vary in magnetic layer thickness and
lateral dimensions. The sensors are statistically analyzed to identify the
influence of magnetic layer geometry on performance through a combination of
measurements and simulations. Our findings reveal three distinct operation
regimes - dominated by electronic noise, magnetic noise, and nonlinearities -
whose boundaries shift systematically with magnetic layer thickness. This
regime behavior governs the trade-offs between sensitivity and noise,
ultimately determining the sensor's limit of detection. Based on these results,
the dependency of the regime boundaries on key device parameters is discussed
in detail, providing fundamental insights for tailoring sensor performance. As
such, this study establishes a necessary foundation for targeted performance
optimization and the scalable design of advanced delta-E effect sensor systems.

</details>


### [153] [Revealing the Staging Structural Evolution and Li (De)Intercalation Kinetics in Graphite Anodes via Machine Learning Potential](https://arxiv.org/abs/2508.06156)
*Liqi Wang,Xuhe Gong,Zicun Li,Ruijuan Xiao,Hong Li*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究利用机器学习势能和分子动力学模拟，揭示了锂离子在石墨中的动态结构演变和传输机制，为优化锂离子电池负极提供了新的见解。


<details>
  <summary>Details</summary>
Motivation: 为了优化锂离子电池石墨负极的稳定性和快充性能，需要揭示其在充放电过程中动态结构演变和锂离子传输性质，但目前对碳层动力学、锂离子（脱）嵌入/扩散和缺陷调控之间的动态耦合机制理解不足。

Method: 开发了一种基于机器学习势能的通用自动化工作流，利用分子动力学模拟了锂离子（脱）嵌入过程，并引入了堆叠层错来模拟 the staging 结构转变。

Result: 通过模拟发现，堆叠层错驱动的 the staging 结构转变伴随着应力释放和结构稳定化。碳层的动力学调控了锂离子（脱）嵌入的位置选择性，产生了不同锂浓度和分布的中间态。研究揭示了锂离子嵌入和脱嵌之间存在动力学不对称性。碳缺陷会限制层内锂离子传输和碳层滑动，但通过动态的锂离子俘获/释放机制促进层间传输。

Conclusion: 本研究通过机器学习势能模拟了锂离子在石墨中的嵌入/脱嵌过程，揭示了碳层动力学、锂离子传输和缺陷调控之间的耦合机制。通过引入堆叠层错，模拟了由碳层滑动和重组驱动的 the staging 结构转变，并阐明了其对锂离子传输和应力积累的影响。研究发现锂离子嵌入/脱嵌过程中存在动力学不对称性，碳缺陷会限制层内传输但促进层间传输。因此，未来的设计应关注可控的碳层滑动/重组和可调的缺陷，以增强锂离子传输。

Abstract: Revealing the dynamic structural evolution and lithium transport properties
during the charge/discharge processes is crucial for optimizing graphite anodes
in lithium-ion batteries, enabling high stability and fast-charging
performance. However, the dynamic coupling mechanisms among carbon layer
kinetics, lithium (de)intercalation/diffusion, and defects regulation remain
insufficiently understood. In this study, we developed a universal automated
workflow based on machine learning potentials to simulate the dynamic lithium
(de)intercalation process. With this approach, the staging structural evolution
of lithium-graphite intercalation compounds and their lithium transport
behavior were resolved through molecular dynamics simulations. By introducing
stacking faults into the graphite structure, we successfully simulated stage
transitions driven by carbon layer sliding and reorganization, accompanied by
stress release and structural stabilization. The dynamics of carbon layers
regulate the lithium (de)intercalation positional selectivity, producing
intermediate states with varying lithium concentrations and distributions
during cycling. This facilitates the formation and transformation of stage
structures while mitigating residual stress accumulation. A fundamental kinetic
asymmetry arises between lithium intercalation and deintercalation, driven by
the continuous and heterogeneous lithium transport and carbon layer sliding
during charge/discharge processes. The carbon defects regulate lithium
transport, in which the atomic-scale defects confine intralayer lithium
transport and carbon sliding while enabling interlayer transport via dynamic
lithium trapping/release mechanisms. Accordingly, for the future design, it is
critical to construct structural units with controllable carbon layer
sliding/reorganization, and tunable defects to enhance lithium-ion transport.

</details>


### [154] [Scalable Production of Photochromic Yttrium Oxyhydride Powder via Ball Milling](https://arxiv.org/abs/2508.06200)
*Elbruz Murat Baba,Stefano Deledda,Smagul Karazhanov*

Main category: cond-mat.mtrl-sci

TL;DR: A new scalable method using reactive ball milling and controlled oxidation successfully produced Yttrium oxyhydride (YHO) powders, overcoming previous thin-film limitations. These powders exhibit photochromic properties and can be used in polymer composites for applications like smart windows.


<details>
  <summary>Details</summary>
Motivation: The practical deployment of Yttrium oxyhydride (YHO), a promising photochromic material, has been limited by the challenges associated with thin film deposition methods. This work aims to overcome these production barriers by developing a scalable synthesis route for YHO powders.

Method: The synthesis involved reactive ball milling of yttrium metal under hydrogen atmosphere, followed by controlled oxidation in dry air. High-energy planetary ball milling was employed for 20 hours under 50 bar hydrogen, and the resulting material was then oxidized to yield nanostructured YHO powders with particle sizes under 500 nm. Powder X-ray diffraction was used to confirm the formation of the cubic YHO phase.

Result: Nanostructured YHO powders with particle sizes less than 500 nm were successfully synthesized. These powders exhibit robust photochromic response, with reflectance modulation at 850 nm under 405 nm excitation. The material also shows reversible cycling behavior and the characteristic memory effect. X-ray diffraction confirmed the formation of the cubic YHO phase. Furthermore, the YHO powders were processed into polymer composites, enabling spatially-resolved photochromic patterning.

Conclusion: Yttrium oxyhydride (YHO) powders have been successfully synthesized via reactive ball milling and controlled oxidation, overcoming previous thin film deposition limitations. This scalable method enables the production of nanostructured YHO powders with robust photochromic properties, reversible cycling, and memory effects. The powders can be processed into polymer composites for device applications, paving the way for mass production and commercial deployment in smart windows, adaptive optics, and rewritable information storage.

Abstract: Yttrium oxyhydride (YHO) represents one of the most promising photochromic
materials discovered in recent years, yet its practical deployment has been
severely constrained by the limitations of thin film deposition methods. Here
we demonstrate the first successful synthesis of photochromic YHO powders
through reactive ball milling under hydrogen atmosphere followed by controlled
oxidation a fundamentally scalable approach that overcomes the production
barriers facing this technology. High-energy planetary ball milling of yttrium
metal under 50 bar hydrogen for 20 hours, followed by controlled oxidation in
ultra-dry technical air, yielded nanostructured YHO powders with less than 500
nm particle sizes. These powders exhibit robust photochromic response with
reflectance modulation at 850 nm under 405 nm excitation, reversible cycling
behavior, and the characteristic memory effect previously observed only in thin
films. Powder X-ray diffraction confirms the formation of the cubic YHO phase
with lattice expansion consistent with oxygen incorporation into the yttrium
hydride structure. Critically, we demonstrate that YHO powders can be processed
into polymer composites enabling spatially-resolved photochromic patterning a
capability essential for practical device applications. While optimization of
optical contrast remains an opportunity for future work, this powder synthesis
route fundamentally transforms the manufacturing of YHO-based photochromic
systems, enabling mass-scale production using established industrial ball
milling infrastructure. These findings establish a viable pathway toward
commercial deployment of YHO in smart windows, adaptive optics, and rewritable
information storage applications.

</details>


### [155] [Correlation between Exciton Dynamics and Spin Structure in van der Waals Antiferromagnet NiPS3](https://arxiv.org/abs/2508.06246)
*Kang Wang,Yingchen Peng,Boying Huang,Chun Zhou,Qianlu Sun,Fujie Tang,Zhenglu Li,Weigao Xu,Kezhao Du,Xingzhi Wang,Ye Yang*

Main category: cond-mat.mtrl-sci

TL;DR: Ultrafast study of NiPS3 shows excitons couple to magnetism; recombination rate depends on magnetic order, possibly via spin-flips. This could enable optical control of spin states in vdW antiferromagnets.


<details>
  <summary>Details</summary>
Motivation: Exploring novel physics of magnetism in low dimensions and developing ultrathin spintronic applications using emerging magnetic van der Waals (vdW) materials.

Method: Ultrafast dynamics of excitons in a vdW NiPS3 crystal were investigated using transient reflection spectra.

Result: Exciton formation through photocarrier localization is independent of magnetic degrees of freedom, but exciton recombination rate is linked to long-range magnetic order, likely due to spin-flip processes related to the antiferromagnetic background.

Conclusion: This study reveals a strong coupling between carrier, lattice, and spin degrees of freedom in NiPS3, suggesting potential for ultrafast optical manipulation of spin-related quantum states in vdW antiferromagnets.

Abstract: The emerging magnetic van der Waals (vdW) materials provide a platform for
exploring novel physics regarding magnetism in low dimensions and developing
ultrathin spintronic applications. Here, we investigate the ultrafast dynamics
of excitons in a vdW NiPS3 crystal. The temporal evolution of the transient
reflection spectra indicates that the spin-correlated exciton is formed through
photocarrier localization, the rate of which is independent of the magnetic
degrees of freedom. However, the recombination rate of these excitons is
connected with the long-range magnetic order, and this connection probably
arise from a spin-flip rooted in the underlying antiferromagnetic background
during the recombination. Our findings uncover intertwined coupling between
carrier, lattice and spin degrees of freedom in NiPS3, which may pave the path
toward ultrafast optical manipulation of spin-related quantum states in vdW
antiferromagnets.

</details>


### [156] [On-the-Fly Machine Learning of Interatomic Potentials for Elastic Property Modeling in Al-Mg-Zr Solid Solutions](https://arxiv.org/abs/2508.06311)
*Lukas Volkmer,Leonardo Medrano Sandonas,Philip Grimm,Julia Kristin Hufenbach,Gianaurelio Cuniberti*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究利用机器学习和量子力学模拟开发了Al-Mg-Zr固溶体的弹性特性预测模型，结果表明该模型准确且可转移，可加速铝合金设计。


<details>
  <summary>Details</summary>
Motivation: 为了开发具有弹性和轻质的铝合金以满足具有能源效率的工程应用的需求，本研究旨在探索Al-Mg-Zr固溶体的弹性特性。

Method: 本研究结合了先进的机器学习（ML）技术和量子力学（QM）原子模拟来探索Al-Mg-Zr固溶体的弹性特性。研究人员开发了两种机器学习势（MLIPs）：一种是使用'现学现用'（on-the-fly）学习方案结合从头算分子动力学模拟中的贝叶斯线性回归，另一种是使用等变神经网络架构MACE。

Result: 研究人员成功开发了准确且可转移的机器学习势（MLIPs），可以预测成分依赖的弹性特性，同时大大降低了计算成本。与超声波测量结果的比较显示，模拟与实验之间的偏差在所有研究的Al-Mg-Zr系统中均在几个GPa之内。这些势还能够系统地探索Al-Mg-Zr固溶体的相空间，并提供关于弹性行为随合金元素浓度变化的见解。

Conclusion: 该研究证明了在线学习机器学习势（MLIPs）的可靠性和可转移性，这对于在复杂成分空间中加速具有定制的物理机械性能的铝合金设计非常有用。虽然本研究侧重于均匀相，但它为未来包括沉淀物和晶界等微观结构特征的多尺度模拟奠定了基础。

Abstract: The development of resilient and lightweight Aluminum alloys is central to
advancing structural materials for energy-efficient engineering applications.
To address this challenge, in this study, we explore the elastic properties of
Al-Mg-Zr solid solutions by integrating advanced machine learning (ML)
techniques with quantum-mechanical (QM) atomistic simulations. For this
purpose, we develop accurate and transferable machine-learned interatomic
potentials (MLIPs) using two complementary approaches: (i) an on-the-fly
learning scheme combined with Bayesian linear regression during ab initio
molecular dynamics simulations, and (ii) the equivariant neural network
architecture MACE. Both MLIPs facilitate the prediction of
composition-dependent elastic properties while drastically reducing the
computational cost compared to conventional QM methods. Comparison with
ultrasonic measurements shows that the deviation between simulation and
experiment remains within a few GPa across all Al-Mg-Zr systems investigated.
These potentials also enable the systematic exploration of the Al-Mg-Zr solid
solution phase space and provide insights into the elastic behavior as a
function of alloying element concentration. Hence, our findings demonstrate the
reliability and transferability of the parameterized on-the-fly MLIPs, making
them valuable for accelerating the design of Al alloys with tailored
physicomechanical properties in complex compositional spaces. While the present
study focuses on homogeneous phases, it establishes a foundation for future
multiscale simulations that include microstructural features such as
precipitates and grain boundaries.

</details>


### [157] [An underdog story: Re-emergence of a polar instability at high pressure in KNbO3](https://arxiv.org/abs/2508.06399)
*Mohamad Baker Shoker,Sitaram Ramakrishnan,Boris Croes,Olivier Cregut,Nicolas Beyer,Kokou Dorkenoo,Pierre Rodière,Björn Wehinger,Gaston Garbarino,Mohamed Mezouar,Marine Verseils,Pierre Fertey,Salia Cherifi-Hertel,Pierre Bouvier,Mael Guennou*

Main category: cond-mat.mtrl-sci

TL;DR: 在高压下，K NbO3 重新表现出铁电性，表现为包含阳离子位移和氧八面体倾斜的不相称调制，并伴有软模和无序-有序特征。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索在高压条件下，先前被抑制的铁电性是否会在更高压力区域重现，以验证理论预测，并为铁电材料在高压下的行为提供实验证据。

Method: 本研究使用单晶X射线衍射、红外光谱、拉曼光谱和二次谐波生成技术，在高压（高达63 GPa）下研究了钙钛矿铁电材料K NbO3 的相变序列。

Result: 在高压（高达63 GPa）下，K NbO3 的铁电性表现为晶体结构的不相称调制，结合了阳离子位移和氧八面体倾斜。观察到了与倾斜和调制相关的软模，以及持续存在的无序-有序特征，证明了无铅钙钛矿在高压下存在极性不稳定性，尽管其高压相均具有中心对称性。

Conclusion: 研究表明，在高压下，肯尼亚铌酸钾（KNbO3）的铁电性表现为一种包含阳离子位移和氧八面体倾斜的晶体结构的不相称调制。通过X射线衍射、光谱学和二次谐波生成等实验手段，在高达63 GPa的压力下，观察到了与倾斜和调制相关的软模，以及持续存在的无序-有序特征。这证明了无铅钙钛矿在高压下存在极性不稳定性，尽管其所有高压相均具有中心对称性。

Abstract: Ferroelectricity in perovskites is known to be suppressed by a moderate
hydrostatic pressure. The notion that a polar instability should reappear in a
higher pressure regime is well accepted theoretically but experiments have
failed so far to provide a conclusive evidence for it. Here, we investigate a
classical but comparatively underlooked ferroelectric perovskite KNbO3. We use
single crystal X-ray diffraction, infrared and Raman spectroscopy and
second-harmonic generation to explore the phase transition sequence at high
pressures up to 63 GPa. We show that the ferroelectric instability manifests
itself in the emergence of an incommensurate modulation of the perovskite
structure that combines cation displacements and tilts of the oxygen octahedra.
Soft modes associated to the tilts and the modulation are clearly observed
along with persistent order-disorder signatures. This demonstrates the presence
of the high-pressure polar instability in a lead-free perovskite in spite of
the centrosymmetric character of all observed high-pressure phases.

</details>


### [158] [Programing optical properties of single-walled carbon nanotubes with benzoyl peroxide derivatives of tailored chemical characteristics](https://arxiv.org/abs/2508.06421)
*Andrzej Dzienia,Patrycja Taborowska,Pawel Kubica-Cypek,Dawid Janas*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究通过精细调控BPO的自由基化学，实现了对碳纳米管发光特性的精确控制，为光电应用提供了新的解决方案。


<details>
  <summary>Details</summary>
Motivation: 为了解决目前在SWCNT表面改性中，使用BPO进行精确缺陷工程的自由基化学理解不足的问题。

Method: 通过改变BPO衍生物的电子和空间性质，研究了其对聚合物包裹的(6,5)和(7,5)SWCNT的功能化，并分析了BPO及其类似物的分解。

Result: 制备了一系列BPO衍生物，并验证了其在调控SWCNT光致发光特性方面的潜力，实现了对缺陷密度和发光波长的控制，并发现了缺电子反应物修饰的SWCNT具有最佳光学特性。

Conclusion: 该研究阐明了BPO衍生物的自由基化学，并展示了如何通过调控SWCNT的光致发光特性来控制缺陷密度和发光波长，为光电应用提供了精确调控发光缺陷的工具箱，并揭示了缺电子反应物修饰的SWCNT为何具有最佳光学特性的原因。

Abstract: Semiconducting single-walled carbon nanotubes (SWCNTs) have great potential
for optoelectronics and photonics, further enhanced by covalent
functionalization. However, scalable and controlled surface modification is
challenging due to complex methodologies and unstable reagents. Benzoyl
peroxide (BPO) has emerged as a simple alternative for introducing luminescent
defects into SWCNTs. Yet, the lack of understanding of its radical chemistry
limits precise defect engineering using BPOs. This is a major obstacle to the
effective application of BPO in chemistry, despite its widespread use as a
radical initiator. We present a thorough investigation into the radical
chemistry of self-synthesized BPOs for functionalizing polymer-wrapped (6,5)
and (7,5) SWCNTs in non-polar solvents, providing critical insights into the
decomposition of BPO and its analogs. By varying the electronic and steric
properties of typically unavailable BPO derivatives, we demonstrate tunability
over the photoluminescence characteristics of SWCNTs, allowing control over
defect density and light emission wavelength. This toolbox of BPO derivatives,
created with simple radical chemistry and accessible organic precursors,
alongside clarified structure-property relationships, facilitates effective
implementation of BPO in chemical transformations and meticulous engineering of
luminescent defects in SWCNTs for optoelectronic applications. Notably, this
research offers insights into why SWCNTs modified with electron-deficient
reactants provide the best optical characteristics.

</details>


### [159] [Leveraging transfer learning for accurate estimation of ionic migration barriers in solids](https://arxiv.org/abs/2508.06436)
*Reshma Devi,Keith T. Butler,Gopalakrishnan Sai Gautam*

Main category: cond-mat.mtrl-sci

TL;DR: 本文使用一种改进的图神经网络（迁移学习 + 分类），能够准确预测材料的离子迁移势垒 (Em)，并识别出良好的离子导体，从而加速电池材料的发现。


<details>
  <summary>Details</summary>
Motivation: 离子迁移率对于电池、燃料电池和电化学传感器等应用的倍率性能至关重要，它随迁移势垒 (Em) 指数级变化，而 Em 是一个难以测量/计算的量。先前识别高离子迁移率材料的方法依赖于不精确的描述符，因为缺乏可推广的 Em 预测模型。

Method: 本文提出了一种基于图神经网络的架构，该架构利用迁移学习原理来高效、准确地预测多种材料的 Em。该模型在七种不同的体性质上进行了预训练（MPT），然后修改以对结构中的不同迁移路径进行分类，并在一个手动整理的、来自文献的 619 个 Em 数据点的数据集上进行了微调（FT）。

Result: 作者提出的 FT 模型（MODEL-3）在预测精度方面比经典机器学习方法、从头训练的图模型和通用的机器学习原子间势能有了显著提高，在测试集上的 R² 评分为 0.703，平均绝对误差为 0.261 eV。该模型能够区分结构中不同的迁移路径，并且能够跨离子组成和化学性质进行泛化。作为一个分类器，MODEL-3 在识别“良好”离子导体（Em < 0.65 eV）的材料时，准确率为 80%，精确率为 82.8%。

Conclusion: 本文展示了在快速准确预测离子迁移势垒 (Em) 方面，迁移学习策略和模型架构修改的有效性，这对于电池材料发现和其他数据稀疏材料性质的预测非常有用。

Abstract: Ionic mobility determines the rate performance of several applications, such
as batteries, fuel cells, and electrochemical sensors and is exponentially
dependent on the migration barrier ($E_m$), a difficult to measure/calculate
quantity. Previous approaches to identify materials with high ionic mobility
have relied on imprecise descriptors given the lack of generalizable models to
predict $E_m$. Here, we present a graph neural network based architecture that
leverages principles of transfer learning to efficiently and accurately predict
$E_m$ across a diverse set of materials. We use a model pre-trained
simultaneously on seven distinct bulk properties (labeled MPT), modify the MPT
model to classify different migration pathways in a structure, and fine-tune
(FT) on a manually-curated literature-derived dataset of 619 $E_m$ data points
calculated with density functional theory. Importantly, our best-performing FT
model (labeled MODEL-3) demonstrates substantial improvements in prediction
accuracy compared to classical machine learning methods, graph models trained
from scratch, and a universal machine learned interatomic potential, with a
R$^2$ score of 0.703 and a mean absolute error of 0.261 eV on the test set.
Notably, MODEL-3 is able to distinguish different migration pathways within a
structure and also demonstrates excellent ability to generalize across
intercalant compositions and chemistries. As a classifier, MODEL-3 exhibits
80\% accuracy and 82.8\% precision in identifying materials that are `good'
ionic conductors (i.e., structures with $E_m <$0.65~eV). Thus, our work
demonstrates the effective use of FT strategies and architectural modifications
necessary for making swift and accurate $E_m$ predictions, which will be useful
for materials discovery in batteries and for predicting other data-scarce
material properties.

</details>


### [160] [Comparative study of ensemble-based uncertainty quantification methods for neural network interatomic potentials](https://arxiv.org/abs/2508.06456)
*Yonatan Kurniawan,Mingjian Wen,Ellad B. Tadmor,Mark K. Transtrum*

Main category: cond-mat.mtrl-sci

TL;DR: MLIPs 的预测精度不一定能反映其准确性，尤其是在分布外（OOD）情况下。研究发现，不确定性估计在 OOD 设置下可能与预测误差无关，甚至呈负相关。这表明在依赖 MLIPs 进行大规模模拟时，需要谨慎使用不确定性量化方法。


<details>
  <summary>Details</summary>
Motivation: 机器学习内原子势（MLIPs）能够在大幅降低计算成本的同时，以接近第一性原理的精度进行原子尺度模拟，因此成为大规模材料建模的有力工具。然而，MLIPs 的准确性通常在从从头算能量和原子力中保留的数据集上进行验证。但这种在小尺度性质上的准确性并不能保证在涌现的、系统层面的行为上的可靠性——这恰恰是原子尺度模拟最需要的，但通常由于计算成本过高而无法直接验证的领域。作为一种实用的启发式方法，预测精度（量化为不确定性的倒数）通常被用作准确性的代理，但其可靠性仍然知之甚少，特别是在系统层面的预测中。

Method: 研究人员系统地评估了预测精度与准确性在分布内（ID）和分布外（OOD）两种情况下的关系，重点关注基于集合的神经网络势能不确定性量化方法，包括 bootstrap、dropout、随机初始化和快照集合。研究人员使用留出交叉验证进行 ID 评估，并计算冷曲线能量和声子色散关系进行 OOD 测试。这些评估在各种碳同素异形体上进行，作为代表性测试系统。

Result: 在分布外（OOD）设置中，不确定性估计可能表现出违反直觉的行为，随着预测误差的增加，不确定性估计往往会趋于平稳甚至下降。这揭示了当前不确定性量化方法的根本局限性，并强调了在大型、外推应用中使用预测精度作为准确性替代指标时的注意事项。

Conclusion: 不确定性估计在 OOD 设置中可能表现出违反直觉的行为，随着预测误差的增长，不确定性估计往往会趋于平稳甚至下降。这突显了当前不确定性量化方法的根本局限性，并强调在大型、外推应用中使用预测精度作为准确性的替代指标时需要谨慎。

Abstract: Machine learning interatomic potentials (MLIPs) enable atomistic simulations
with near first-principles accuracy at substantially reduced computational
cost, making them powerful tools for large-scale materials modeling. The
accuracy of MLIPs is typically validated on a held-out dataset of \emph{ab
initio} energies and atomic forces. However, accuracy on these small-scale
properties does not guarantee reliability for emergent, system-level behavior
-- precisely the regime where atomistic simulations are most needed, but for
which direct validation is often computationally prohibitive. As a practical
heuristic, predictive precision -- quantified as inverse uncertainty -- is
commonly used as a proxy for accuracy, but its reliability remains poorly
understood, particularly for system-level predictions. In this work, we
systematically assess the relationship between predictive precision and
accuracy in both in-distribution (ID) and out-of-distribution (OOD) regimes,
focusing on ensemble-based uncertainty quantification methods for neural
network potentials, including bootstrap, dropout, random initialization, and
snapshot ensembles. We use held-out cross-validation for ID assessment and
calculate cold curve energies and phonon dispersion relations for OOD testing.
These evaluations are performed across various carbon allotropes as
representative test systems. We find that uncertainty estimates can behave
counterintuitively in OOD settings, often plateauing or even decreasing as
predictive errors grow. These results highlight fundamental limitations of
current uncertainty quantification approaches and underscore the need for
caution when using predictive precision as a stand-in for accuracy in
large-scale, extrapolative applications.

</details>


### [161] [A literature-derived dataset of migration barriers for quantifying ionic transport in battery materials](https://arxiv.org/abs/2508.06459)
*Reshma Devi,Avaneesh Balasubramanian,Keith T. Butler,Gopalakrishnan Sai Gautam*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究构建了一个包含619个文献报道的电池材料迁移能垒（Em）及其相关结构信息的综合数据集，旨在支持机器学习模型开发，以加速新型电池材料的发现。


<details>
  <summary>Details</summary>
Motivation: 电池材料的倍率性能严重依赖于控制嵌入离子运动的迁移能垒（Em），但该量难以通过实验和计算进行精确估算，阻碍了基于机器学习的材料发现。

Method: 通过密度泛函理论（DFT）和改进的氖 نط（NEB）计算方法，从文献中收集了619个迁移能垒（Em）数据，涵盖了443种化合物和27种结构组分。

Result: 创建了一个包含619个文献报道的迁移能垒（Em）值的综合数据集，其中包含每种化合物的结构信息、离子迁移的初始和最终位置，并以.xlsx和JSON格式提供，可用于开发精确预测Em的机器学习模型。

Conclusion: 该数据集为电池材料的机器学习模型开发提供了宝贵的资源，有望加速新型电极和固态电解质的发现。

Abstract: The rate performance of any electrode or solid electrolyte material used in a
battery is critically dependent on the migration barrier ($E_m$) governing the
motion of the intercalant ion, which is a difficult-to-estimate quantity both
experimentally and computationally. The foundation for constructing and
validating accurate machine learning (ML) models that are capable of predicting
$E_m$, and hence accelerating the discovery of novel electrodes and solid
electrolytes, lies in the availability of high-quality dataset(s) containing
$E_m$. Addressing this critical requirement, we present a comprehensive dataset
comprising 619 distinct literature-reported $E_m$ values calculated using
density functional theory based nudged elastic band computations, across 443
compositions and 27 structural groups consisting of various compounds that have
been explored as electrodes or solid electrolytes in batteries. Our dataset
includes compositions that correspond to fully charged and/or discharged states
of electrode materials, with intermediate compositions incorporated in select
instances. Crucially, for each compound, our dataset provides structural
information, including the initial and final positions of the migrating ion,
along with its corresponding $E_m$ in easy-to-use .xlsx and JSON formats. We
envision our dataset to be a highly useful resource for the scientific
community, facilitating the development of advanced ML models that can predict
$E_m$ precisely and accelerate materials discovery.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [162] [A United Framework for Planning Electric Vehicle Charging Accessibility](https://arxiv.org/abs/2508.05827)
*Tony Kinchen,Panagiotis Typaldos,Andreas A. Malikopoulos*

Main category: eess.SY

TL;DR: 本研究提出了一种新的方法来优化城市电动汽车充电桩的布局，考虑了效率和公平性，并在纽约市的案例研究中取得了积极成果。


<details>
  <summary>Details</summary>
Motivation: 文章旨在解决在城市环境中优化电动汽车充电桩布局的挑战，以平衡效率和空间可及性，推动可持续和低排放的城市交通系统。

Method: 提出一个优化框架，该框架整合了交通模拟、能源消耗模型以及一个衡量潜在充电站社会覆盖范围的移动性公平性指标。

Result: 使用纽约市作为案例研究，证明了该方法能够持续改善可达性（降低15-20%的出行时间变异性），并提供了一种将公平性考量纳入电动汽车基础设施规划的可扩展方法。

Conclusion: 该研究提出了一个结合交通模拟、能源消耗模型和移动性公平性指标的优化框架，用于优化城市电动汽车充电桩的布局，并以纽约市为例进行了验证，结果显示可达性得到显著改善（出行时间变异性降低15-20%）。

Abstract: The shift towards electric vehicles (EVs) is crucial for establishing
sustainable and low-emission urban transportation systems. However, the success
of this transition depends on the strategic placement of the charging
infrastructure. This paper addresses the challenge of optimizing charging
station locations in dense urban environments while balancing efficiency with
spatial accessibility. We propose an optimization framework that integrates
traffic simulation, energy consumption modeling, and a mobility equity measure
to evaluate the social reach of each potential charging station. Using New York
City as a case study, we demonstrate consistent improvements in accessibility
(15-20% reduction in travel time variability). Our results provide a scalable
methodology for incorporating equity considerations into EV infrastructure
planning, although economic factors and grid integration remain important areas
for future development.

</details>


### [163] [Distributed Optimization and Learning for Automated Stepsize Selection with Finite Time Coordination](https://arxiv.org/abs/2508.05887)
*Apostolos I. Rikos,Nicola Bastianello,Themistoklis Charalambous,Karl H. Johansson*

Main category: eess.SY

TL;DR: 提出了一种新的分布式学习算法，通过消除节点间的步长异质性来提高学习过程的稳定性和效率。


<details>
  <summary>Details</summary>
Motivation: 分布式优化和学习算法在处理海量数据时面临步长选择的挑战，局部自适应步长可能导致网络中的步长异质性，从而干扰学习过程甚至导致发散。

Method: 提出了一种分布式学习算法，包含一种用于自动选择节点间步长的新机制，并提出了一种有限时间协调算法来消除步长异质性。

Result: 所提出的算法能够消除步长异质性，并已证明其收敛于最优解。

Conclusion: 通过数值模拟，证明了消除步长异质性可以提高收敛速度和准确性。

Abstract: Distributed optimization and learning algorithms are designed to operate over
large scale networks enabling processing of vast amounts of data effectively
and efficiently. One of the main challenges for ensuring a smooth learning
process in gradient-based methods is the appropriate selection of a learning
stepsize. Most current distributed approaches let individual nodes adapt their
stepsizes locally. However, this may introduce stepsize heterogeneity in the
network, thus disrupting the learning process and potentially leading to
divergence. In this paper, we propose a distributed learning algorithm that
incorporates a novel mechanism for automating stepsize selection among nodes.
Our main idea relies on implementing a finite time coordination algorithm for
eliminating stepsize heterogeneity among nodes. We analyze the operation of our
algorithm and we establish its convergence to the optimal solution. We conclude
our paper with numerical simulations for a linear regression problem,
showcasing that eliminating stepsize heterogeneity enhances convergence speed
and accuracy against current approaches.

</details>


### [164] [Distributed Quantized Average Consensus in Open Multi-Agent Systems with Dynamic Communication Links](https://arxiv.org/abs/2508.05895)
*Jiaqi Hu,Karl H. Johansson,Apostolos I. Rikos*

Main category: eess.SY

TL;DR: This paper proposes a distributed algorithm for average consensus in open multi-agent systems with changing links. The algorithm uses quantized messages for efficiency and converges in finite time, with correctness proven and conditions for success identified.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the distributed quantized average consensus problem in open multi-agent systems with dynamically changing communication links, termed open dynamic multi-agent systems.

Method: A distributed algorithm is proposed that allows active nodes to compute the quantized average of their initial states by exchanging quantized value messages. The algorithm exhibits finite time convergence.

Result: The algorithm ensures efficient communication through quantized message exchange and achieves finite time convergence. Its performance is validated through numerical simulations.

Conclusion: The paper presents a distributed algorithm for the quantized average consensus problem in open dynamic multi-agent systems, establishing its correctness and identifying necessary and sufficient topological conditions for successful problem solving.

Abstract: In this paper, we focus on the distributed quantized average consensus
problem in open multi-agent systems consisting of communication links that
change dynamically over time. Open multi-agent systems exhibiting the
aforementioned characteristic are referred to as \textit{open dynamic
multi-agent systems} in this work. We present a distributed algorithm that
enables active nodes in the open dynamic multi-agent system to calculate the
quantized average of their initial states. Our algorithm consists of the
following advantages: (i) ensures efficient communication by enabling nodes to
exchange quantized valued messages, and (ii) exhibits finite time convergence
to the desired solution. We establish the correctness of our algorithm and we
present necessary and sufficient topological conditions for it to successfully
solve the quantized average consensus problem in an open dynamic multi-agent
system. Finally, we illustrate the performance of our algorithm with numerical
simulations.

</details>


### [165] [Panel-Scale Reconfigurable Photonic Interconnects for Scalable AI Computation](https://arxiv.org/abs/2508.06079)
*Tzu-Chien Hsueh,Bill Lin,Zijun Chen,Yeshaiahu Fainman*

Main category: eess.SY

TL;DR: 提出了一种面板级可重构光互连技术，用于AI计算系统，实现高带宽、低功耗和大规模集成。


<details>
  <summary>Details</summary>
Motivation: 为了满足AI计算系统对高带宽、低功耗和大规模集成互连的需求。

Method: 提出了一种新颖的光开关结构，能够在面板边缘到面板边缘实现所有方向的连接，无需有源中继器。

Result: 实现了面板级可重构光互连，支持高通信带宽、平面方向可重构性、低功耗和高数据带宽密度，并与商业处理器chiplets和3D高带宽内存（HBM）堆栈兼容。

Conclusion: 该研究提出了一种新颖的面板级光互连解决方案，适用于大规模异构集成，并展示了其在AI计算系统中的潜力。

Abstract: Panel-scale reconfigurable photonic interconnects on a glass substrate up to
500-mm x 500-mm or larger are envisioned by proposing a novel photonic switch
fabric that enables all directional panel-edge-to-panel-edge reach without the
need for active repeaters while offering high communication bandwidth,
planar-direction reconfigurability, low energy consumption, and compelling data
bandwidth density for heterogeneous integration of an in-package AI computing
system on a single glass-substrate photonic interposer exceeding thousands of
centimeters square. The proposed approach focuses on reconfigurable photonic
interconnects, which are integration-compatible with commercial processor
chiplets and 3D high-bandwidth memory (HBM) stacks on a large-area glass
substrate, to create a novel panel-scale heterogeneously integrated interposer
or package enabling low-energy and high-capacity
wavelength-division-multiplexing (WDM) optical data links using advanced
high-speed optical modulators, broadband photodetectors, novel optical crossbar
switches with multi-layer waveguides, and in-package frequency comb sources.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [166] [Bionic Vision as Neuroadaptive XR: Closed-Loop Perceptual Interfaces for Neurotechnology](https://arxiv.org/abs/2508.05963)
*Michael Beyeler*

Main category: cs.ET

TL;DR: Visual prosthetics are like bad VR, not real eyes. This paper suggests making them 'neuro-adaptive XR' to work *with* the brain, not just try to copy sight. It's about designing systems that learn and adapt to the user, and it calls on the XR community to help build this future.


<details>
  <summary>Details</summary>
Motivation: Current visual neuroprostheses provide a novel mode of perception with sparse, distorted, and unstable input, resembling early XR headsets rather than natural vision. The motivation is to move beyond merely replicating natural sight and instead focus on co-adapting the brain and device.

Method: The paper proposes a reframing of visual neuroprostheses as 'neuroadaptive XR'. It compares traditional XR, current implants, and the proposed neuroadaptive systems to introduce a new design space for brain-aware computing. It also covers research provocations in encoding, evaluation, learning, and ethics.

Result: The paper introduces a new design space for inclusive, brain-aware computing by proposing a 'neuroadaptive XR' framework. It highlights that resolution alone is insufficient for a natural experience and emphasizes the need for a bidirectional interface that adapts to the user's neural and cognitive state.

Conclusion: Visual neuroprostheses should be reframed as neuroadaptive XR, aiming to co-adapt the brain and device through a bidirectional interface that responds to neural constraints, behavioral goals, and cognitive state, rather than replicating natural sight. This new perspective opens up a design space for inclusive, brain-aware computing and invites the XR community to contribute to the future of sensory augmentation.

Abstract: Visual neuroprostheses are commonly framed as technologies to restore natural
sight to people who are blind. In practice, they create a novel mode of
perception shaped by sparse, distorted, and unstable input. They resemble early
extended reality (XR) headsets more than natural vision, streaming video from a
head-mounted camera to a neural "display" with under 1000 pixels, limited field
of view, low refresh rates, and nonlinear spatial mappings. No amount of
resolution alone will make this experience natural. This paper proposes a
reframing: bionic vision as neuroadaptive XR. Rather than replicating natural
sight, the goal is to co-adapt brain and device through a bidirectional
interface that responds to neural constraints, behavioral goals, and cognitive
state. By comparing traditional XR, current implants, and proposed
neuroadaptive systems, it introduces a new design space for inclusive,
brain-aware computing. It concludes with research provocations spanning
encoding, evaluation, learning, and ethics, and invites the XR community to
help shape the future of sensory augmentation.

</details>


### [167] [Between Tool and Trouble: Student Attitudes Toward AI in Programming Education](https://arxiv.org/abs/2508.05999)
*Sergio Rojas-Galeano,Julian Tejada,Fernando Marmolejo-Ramos*

Main category: cs.ET

TL;DR: AI助手有助于初学者理解代码和建立信心，但在独立完成任务时可能导致过度依赖和知识迁移困难，需要教学策略来平衡AI辅助与基础技能培养。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨AI代码助手在初学编程者入门编程课程的考试中所扮演的角色，以及其对学习体验的影响。

Method: 本研究通过一个包含两个部分的考试，考察AI代码助手如何影响初学编程者的体验。在第一部分，学生在有AI支持的情况下完成编程任务；在第二部分，他们需要在没有AI的情况下扩展解决方案。研究收集了20名学生的李克特量表和开放式问题反馈，以评估他们的看法和挑战。

Result: 研究结果表明，AI工具被认为有助于理解代码和提高信心，特别是在初始开发阶段。然而，学生在将知识迁移到无AI辅助的任务时遇到困难，这揭示了可能存在的过度依赖和概念理解上的不足。

Conclusion: AI工具被认为有助于理解代码和提高信心，特别是在初始开发阶段。然而，学生在无需AI的独立任务中也遇到了知识迁移的困难，这可能表明对AI的过度依赖以及概念理解方面存在差距。这些发现强调了需要制定教学策略，以有意义地整合AI，同时加强基础编程技能。

Abstract: This study examines how AI code assistants shape novice programmers
experiences during a two-part exam in an introductory programming course. In
the first part, students completed a programming task with access to AI
support; in the second, they extended their solutions without AI. We collected
Likert-scale and open-ended responses from 20 students to evaluate their
perceptions and challenges. Findings suggest that AI tools were perceived as
helpful for understanding code and increasing confidence, particularly during
initial development. However, students reported difficulties transferring
knowledge to unaided tasks, revealing possible overreliance and gaps in
conceptual understanding. These insights highlight the need for pedagogical
strategies that integrate AI meaningfully while reinforcing foundational
programming skills.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [168] [A Remark on the AAA Method for Secret-Key Generation in Mobile Networks](https://arxiv.org/abs/2508.05801)
*Yingbo Hua*

Main category: eess.SP

TL;DR: AAA密钥生成方法通过无限次叠加，即使在有干扰的情况下也能生成完美密钥，且优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了提供一种安全且高效的密钥生成方法，并与现有方法进行比较以展现其优越性。

Method: 提出了一种具有累积、自适应和累加（AAA）特性的密钥生成方法，并对其性能鲁棒性进行了研究。

Result: AAA密钥生成方法在存在信道干扰和信息泄露的情况下，通过无限次叠加可以实现完美的密钥生成，并且在与理想方法对比中显示出若干优势。

Conclusion: AAA密钥生成方法在无限次叠加后可以实现完美密钥，并且与基于互易信道估计的理想方法相比具有多项优势。

Abstract: A broadly applicable method for secret-key generation is named for its
accumulative, adaptable and additive (AAA) properties. This paper first shows a
robustness of its performance. Namely, even if there is an inter correlation or
a leakage caused intra correlation among the superimposed packets, provided
there is a nonzero probability for each packet to be missed in full or in part
by Eve, then the equivocation of the key generated by the AAA method always
becomes perfect as the number of superpositions becomes infinite. Also shown in
this paper is a comparison between the AAA method and an ideal method based on
reciprocal channel estimation, which reveals several advantages of the AAA
method.

</details>


### [169] [STEEP -- An Alternative To Quantum Key Distribution](https://arxiv.org/abs/2508.05882)
*Yingbo Hua*

Main category: eess.SP

TL;DR: STEEP是一种仅需经典信道的密钥生成技术，可作为QKD的替代方案，在实际应用中具有成本、复杂性、兼容性和鲁棒性等优势。


<details>
  <summary>Details</summary>
Motivation: 将STEEP作为一种替代量子密钥分发（QKD）的方案进行讨论，强调其仅需经典信道即可进行密钥生成，而QKD需要量子和经典信道。

Method: STEEP（Secret-message transmission by echoing encrypted probes）

Result: STEEP在许多实际情况（包括空气信道或海底光缆）中，可以实现足够高的保密率，足以支持一次性密码加密。

Conclusion: STEEP是一种有潜力的量子密钥分发（QKD）替代方案，它仅需要经典信道，并且在许多实际应用场景中可以提供足够高的保密率，以支持一次性密码加密。

Abstract: Secret-message transmission by echoing encrypted probes (STEEP) is discussed
as an alternative to quantum key distribution (QKD). The former only needs
classic or non-quantum channels while the latter needs both quantum and classic
channels for secret-key generation. STEEP is shown to yield a secrecy rate
sufficient for one-time pads encryption in many practical situations including
in-air channels or undersea optical cables. Other advantages of STEEP over QKD
include cost, complexity, compatibility, and robustness against constant
eavesdropping.

</details>


### [170] [IRS-Assisted IoT Activity Detection Under Asynchronous Transmission and Heterogeneous Powers: Detectors and Performance Analysis](https://arxiv.org/abs/2508.05959)
*Amirhossein Taherpour,Somayeh Khani,Abbas Taherpour,Tamer Khattab*

Main category: eess.SP

TL;DR: 本论文提出了一种用于分布式物联网网络的活动检测方法，利用智能反射面 (IRS) 提高检测可靠性。通过制定二元假设检验问题并开发计算效率高的检测器，推导了检测和虚警概率的理论性能基准。仿真结果验证了该方法的有效性，并评估了关键系统参数的影响，为 6G 系统中的 IRS 辅助物联网网络提供了可扩展的解决方案。


<details>
  <summary>Details</summary>
Motivation: 解决分布式物联网网络中的活动检测问题，其中设备采用异步传输和异构功率级别来报告其本地观测结果。该系统利用智能反射面 (IRS) 来提高检测可靠性，并可选择性地结合视距 (LoS) 路径。

Method: 将检测问题制定为二元假设检验，并开发了四种检测器：一种最优检测器和三种计算效率高的检测器，适用于具有不同噪声方差、信道状态信息和设备发射功率先验知识水平的实际场景。

Result: 为每种检测器推导了检测和虚警概率的封闭式表达式，建立了理论性能基准。广泛的模拟验证了我们的分析结果，并系统地评估了天线数量、样本数量、用户数量和 IRS 单元数量等关键系统参数对检测性能的影响。

Conclusion: 该框架有效地将理论最优性与实际可行性相结合，为新兴 6G 系统中的 IRS 辅助物联网网络提供了可扩展的解决方案。

Abstract: This paper addresses the problem of activity detection in distributed
Internet of Things (IoT) networks, where devices employ asynchronous
transmissions with heterogeneous power levels to report their local
observations. The system leverages an intelligent reflecting surface (IRS) to
enhance detection reliability, with optional incorporation of a direct
line-of-sight (LoS) path. We formulate the detection problem as a binary
hypothesis test and develop four detectors: an optimal detector alongside three
computationally efficient detectors designed for practical scenarios with
different levels of prior knowledge about noise variance, channel state
information, and device transmit powers. For each detector, we derive
closed-form expressions for both detection and false alarm probabilities,
establishing theoretical performance benchmarks. Extensive simulations validate
our analytical results and systematically evaluate the impact of key system
parameters including the number of antennas, samples, users, and IRS elements
on detection performance. The proposed framework effectively bridges
theoretical optimality with implementation practicality, providing a scalable
solution for IRS-assisted IoT networks in emerging 6G systems.

</details>


### [171] [Multi-Functional Chirp Signalling for Next-Generation Multi-Carrier Wireless Networks: Communications, Sensing and ISAC Perspectives](https://arxiv.org/abs/2508.06022)
*Zeping Sui,Qu Luo,Zilong Liu,Murat Temiz,Leila Musavian,Christos Masouros,Yong Liang Guan,Pei Xiao,Lajos Hanzo*

Main category: eess.SP

TL;DR: Chirp signalling is beneficial for future mobile networks, offering efficient and reliable communication and sensing capabilities.


<details>
  <summary>Details</summary>
Motivation: To meet the increasingly demanding quality-of-service requirements of next-generation multi-carrier mobile networks by designing multi-functional signalling schemes for efficient, flexible, and reliable communication and sensing in complex wireless environments.

Method: The paper advocates chirp signalling by considering a wide range of chirp waveforms, including chirp sequences (e.g., Zadoff-Chu sequences) and waveforms (e.g., FMCW and AFDM).

Result: Chirp signalling offers advantages in supporting reliable high-mobility communications and integrated sensing and communications (ISAC).

Conclusion: Chirp signalling is a promising candidate for next-generation mobile networks due to its resilience against doubly selective channels and its ability to support high-mobility communications and ISAC.

Abstract: To meet the increasingly demanding quality-of-service requirements of the
next-generation multi-carrier mobile networks, it is essential to design
multi-functional signalling schemes facilitating efficient, flexible, and
reliable communication and sensing in complex wireless environments. As a
compelling candidate, we advocate chirp signalling, beneficially amalgamating
sequences (e.g., Zadoff-Chu sequences) with waveforms (e.g., chirp spread
spectrum and frequency-modulated continuous wave (FMCW) radar), given their
resilience against doubly selective channels. Besides chirp sequences, a wide
range of chirp waveforms is considered, ranging from FMCW to affine
frequency-division multiplexing (AFDM), to create a promising chirp
multicarrier waveform. This study also highlights the advantages of such
waveforms in supporting reliable high-mobility communications, plus integrated
sensing and communications (ISAC). Finally, we outline several emerging
research directions for chirp signalling designs.

</details>


### [172] [Bayesian Radio Map Estimation: Fundamentals and Implementation via Diffusion Models](https://arxiv.org/abs/2508.06037)
*Tien Ngoc Ha,Daniel Romero*

Main category: eess.SP

TL;DR: 本文提出了一种新的贝叶斯方法来估计无线电地图，该方法可以处理不确定性并实现更精确的估计，同时在训练过程中仅进行功率估计。


<details>
  <summary>Details</summary>
Motivation: 为了解决无线电地图估计（RME）问题，并追求更通用的问题设定，即在给定测量值的情况下确定地图的后验分布，同时处理不确定性和实现任意地图泛函的最小均方误差估计。

Method: 提出了一种基于条件扩散模型的通用贝叶斯估计器，用于推断地图的后验分布。

Result: 该方法能够实现最小均方误差估计，并且可以处理不确定性。

Conclusion: 本文提出了一种基于条件扩散模型的通用贝叶斯估计器，并从贝叶斯和非贝叶斯两个范式对所提出的方法进行了解析和数值比较，以确定贝叶斯方法的适用性。

Abstract: Radio map estimation (RME) is the problem of inferring the value of a certain
metric (e.g. signal power) across an area of interest given a collection of
measurements. While most works tackle this problem from a purely non-Bayesian
perspective, some Bayesian estimators have been proposed. However, the latter
focus on estimating the map itself, the Bayesian standpoint is adopted mainly
to exploit prior information or to capture uncertainty. This paper pursues a
more general formulation, where the goal is to determine the posterior
distribution of the map given the measurements. Besides handling uncertainty
and allowing standard Bayesian estimates, solving this problem is seen to
enable minimum mean square error estimation of arbitrary map functionals (e.g.
capacity, bit error rate, or coverage area to name a few) while training only
for power estimation. A general Bayesian estimator is proposed based on
conditional diffusion models and both the Bayesian and non-Bayesian paradigms
are compared analytically and numerically to determine when the Bayesian
approach is preferable.

</details>


### [173] [Multi-Modal Neural Radio Radiance Field for Localized Statistical Channel Modelling](https://arxiv.org/abs/2508.06054)
*Yiheng Wang,Shutao Zhang,Ye Xue,Tsung-Hui Chang*

Main category: eess.SP

TL;DR: MM-LSCM 是一种新的通信框架，它使用 LiDAR 和 RSRP 数据来提高无线通信的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的 LSCM 方法仅依赖 RSRP 数据，在模拟影响信号传播的环境结构方面存在局限性。本研究旨在通过融合多模态信息（如 LiDAR 数据）来增强空间感知和预测精度，以克服这些限制。

Method: 提出了一种双分支神经网络结构，该结构集成了 RSRP 数据和 LiDAR 点云信息，并利用基于体积渲染的多模态合成技术，采用自监督学习方法进行训练。

Result: 实验结果表明，MM-LSCM 在信道重建的准确性和对噪声的鲁棒性方面明显优于传统方法。

Conclusion: MM-LSCM 通过集成 LiDAR 数据和自监督学习，显著提高了无线信道建模的准确性和鲁棒性，为下一代网络优化提供了有前景的解决方案。

Abstract: This paper presents MM-LSCM, a self-supervised multi-modal neural radio
radiance field framework for localized statistical channel modeling (LSCM) for
next-generation network optimization. Traditional LSCM methods rely solely on
RSRP data, limiting their ability to model environmental structures that affect
signal propagation. To address this, we propose a dual-branch neural
architecture that integrates RSRP data and LiDAR point cloud information,
enhancing spatial awareness and predictive accuracy. MM-LSCM leverages
volume-rendering-based multi-modal synthesis to align radio propagation with
environmental obstacles and employs a self-supervised training approach,
eliminating the need for costly labeled data. Experimental results demonstrate
that MM-LSCM significantly outperforms conventional methods in channel
reconstruction accuracy and robustness to noise, making it a promising solution
for real-world wireless network optimization.

</details>


### [174] [Fast End-to-End Simulation and Exploration of Many-RISCV-Core Baseband Transceivers for Software-Defined Radio-Access Networks](https://arxiv.org/abs/2508.06141)
*Marco Bertuletti,Yichao Zhang,Mahdi Abdollahpour,Samuel Riedel,Alessandro Vanelli-Coralli*

Main category: eess.SP

TL;DR: 提出了一种SDR仿真框架，可以加速基带处理功能仿真，比RTL仿真快三倍。


<details>
  <summary>Details</summary>
Motivation: 无线带宽需求的快速增长需要高性能基带处理基础设施的快速发展。SDR的可编程多核处理器作为高性能基带处理引擎出现，提供了捕获不断变化的无线标准和技术的灵活性。因此，需要一个设计框架来实现SDR硬件在实际无线环境模型中的功能验证和端到端性能分析。

Method: 提出了一种基于静态二进制翻译的模拟器，并辅以快速、近似的硬件时序模型，并与无线信道模型耦合，对在可定制为SDR的1024核RISC-V核集群上以软件实现的通信物理层函数进行仿真。

Result: 该框架能够仿真服务器级处理器上5G OFDM符号的检测，仿真时间在9.5秒到3分钟之间（取决于输入MIMO大小），比RTL仿真快三个数量级。仿真可以轻松地并行化到128个线程，与单线程相比具有73-121倍的加速。

Conclusion: SDR硬件的仿真框架可以极大地加速物理层功能的仿真，速度比RTL仿真快三倍。

Abstract: The fast-rising demand for wireless bandwidth requires rapid evolution of
high-performance baseband processing infrastructure. Programmable many-core
processors for software-defined radio (SDR) have emerged as high-performance
baseband processing engines, offering the flexibility required to capture
evolving wireless standards and technologies. This trend must be supported by a
design framework enabling functional validation and end-to-end performance
analysis of SDR hardware within realistic radio environment models. We propose
a static binary translation based simulator augmented with a fast, approximate
timing model of the hardware and coupled to wireless channel models to simulate
the most performance-critical physical layer functions implemented in software
on a many (1024) RISC-V cores cluster customized for SDR. Our framework
simulates the detection of a 5G OFDM-symbol on a server-class processor in
9.5s-3min, on a single thread, depending on the input MIMO size (three orders
of magnitude faster than RTL simulation). The simulation is easily parallelized
to 128 threads with 73-121x speedup compared to a single thread.

</details>


### [175] [A 66-Gb/s/5.5-W RISC-V Many-Core Cluster for 5G+ Software-Defined Radio Uplinks](https://arxiv.org/abs/2508.06176)
*Marco Bertuletti,Yichao Zhang,Alessandro Vanelli-Coralli,Luca Benini*

Main category: eess.SP

TL;DR: 该论文设计了一个包含1024个RISC-V核心的多核集群，用于5G基站处理，在满足严格功耗和延迟要求的同时，实现了比现有技术高十倍的吞吐量和具有竞争力的能效。


<details>
  <summary>Details</summary>
Motivation: 随着5G及更高版本中新无线电（NR）的复杂性增加，基站的物理层计算负载在严格的延迟和功耗预算下不断增加，需要处理每秒超过20Gb的上行链路无线数据速率，同时功耗低于10W。此外，基站组件的可编程性和可重构性是关键要求，以降低部署成本和时间，并适应快速发展的标准。

Method: 设计了一个多核集群，包含1024个流线型RISC-V核心和特定领域的FP扩展，以及4MB共享内存，用于5G及更高版本的基站处理。

Result: 该多核集群设计能够满足5G物理上行共享信道（PUSCH）的软件定义处理的计算能力要求，在过渡时间间隔（TTI）下提供66Gb/s的吞吐量，具体吞吐量在9.4-302 Gb/s之间，具体取决于处理阶段。与其他现有的专用ASIP相比，所实现的吞吐量指标提高了十倍。

Conclusion: 该设计实现了1024个RISC-V核心，在12nm CMOS技术下，在800MHz，25°C，0.8V下，对于关键NR内核具有2-41 Gb/s/W的能效，并且在1.7毫秒内以低于6W的平均功耗端到端运行PUSCH处理，实现了12 Gb/s/W的能效，其吞吐量比现有的ASIPs高十倍。

Abstract: Following the scale-up of new radio (NR) complexity in 5G and beyond, the
physical layer's computing load on base stations is increasing under a strictly
constrained latency and power budget; base stations must process > 20-Gb/s
uplink wireless data rate on the fly, in < 10 W. At the same time, the
programmability and reconfigurability of base station components are the key
requirements; it reduces the time and cost of new networks' deployment, it
lowers the acceptance threshold for industry players to enter the market, and
it ensures return on investments in a fast-paced evolution of standards. In
this article, we present the design of a many-core cluster for 5G and beyond
base station processing. Our design features 1024, streamlined RISC-V cores
with domain-specific FP extensions, and 4-MiB shared memory. It provides the
necessary computational capabilities for software-defined processing of the
lower physical layer of 5G physical uplink shared channel (PUSCH), satisfying
high-end throughput requirements (66 Gb/s for a transition time interval (TTI),
9.4-302 Gb/s depending on the processing stage). The throughput metrics for the
implemented functions are ten times higher than in state-of-the-art (SoTA)
application-specific instruction processors (ASIPs). The energy efficiency on
key NR kernels (2-41 Gb/s/W), measured at 800 MHz, 25 {\deg}C, and 0.8 V, on a
placed and routed instance in 12-nm CMOS technology, is competitive with SoTA
architectures. The PUSCH processing runs end-to-end on a single cluster in 1.7
ms, at <6-W average power consumption, achieving 12 Gb/s/W.

</details>


### [176] [Efficient Deep Neural Receiver with Post-Training Quantization](https://arxiv.org/abs/2508.06275)
*SaiKrishna Saketh Yellapragada,Esa Ollila,Mario Costa*

Main category: eess.SP

TL;DR: 本文研究了使用PTQ降低模型复杂度，以提高计算效率，并展示了其在6G系统中部署神经接收器的潜力。


<details>
  <summary>Details</summary>
Motivation: 为了解决深度CNN在资源受限的边缘系统中部署面临的计算复杂性和资源需求挑战，并满足5G和6G的硬实时处理需求。

Method: 本文将对称均匀量化应用于神经接收器，并分别使用了per-tensor和per-channel PTQ。

Result: 8位per-channel量化在保持BLER性能方面具有可比性，而4位量化显示出巨大潜力但需要进一步优化。

Conclusion: 8位per-channel量化在保持BLER性能方面具有可比性，而4位量化有待进一步优化。

Abstract: Deep learning has recently garnered significant interest in wireless
communications due to its superior performance compared to traditional
model-based algorithms. Deep convolutional neural networks (CNNs) have
demonstrated notable improvements in block error rate (BLER) under various
channel models and mobility scenarios. However, the high computational
complexity and resource demands of deep CNNs pose challenges for deployment in
resource-constrained edge systems. The 3rd Generation Partnership Project
(3GPP) Release 20 highlights the pivotal role of artificial intelligence (AI)
integration in enabling advanced radio-access networks for 6G systems. The hard
real-time processing demands of 5G and 6G require efficient techniques such as
post-training quantization (PTQ), quantization-aware training (QAT), pruning,
and hybrid approaches to meet latency requirements. In this paper, we focus on
PTQ to reduce model complexity by lowering the bit-width of weights, thereby
enhancing computational efficiency. Our analysis employs symmetric uniform
quantization, applying both per-tensor and per-channel PTQ to a neural receiver
achieving performance comparable to full-precision models. Specifically, 8-bit
per-channel quantization maintains BLER performance with minimal degradation,
while 4-bit quantization shows great promise but requires further optimization
to achieve target BLER levels. These results highlight the potential of
ultra-low bitwidth PTQ for efficient neural receiver deployment in 6G systems.

</details>


### [177] [MALRIS: Malicious Hardware in RIS-Assisted Wireless Communications](https://arxiv.org/abs/2508.06340)
*Danish Mehmood Mughal,Daniyal Munir,Qazi Arbab Ahmed,Hans D. Schotten,Thorsten Jungeblut,Sang-Hyo Kim,Min Young Chung*

Main category: eess.SP

TL;DR: 重构智能表面（RIS）可能存在硬件安全风险，被篡改的RIS（MALRIS）即使在被动操作下也能发起攻击，影响通信性能。


<details>
  <summary>Details</summary>
Motivation: 随着RIS在无线通信中的广泛应用，其硬件层面的安全风险日益凸显。本研究旨在识别并分析由恶意篡改RIS组件（MALRIS）引发的实际安全威胁，如制造过程中的篡改、恶意固件和部分单元控制，以提高业界对这一新兴安全威胁的认识。

Method: 本文通过模拟功率分裂和单元分裂这两种代表性攻击，来评估硬件层面恶意篡改对RIS性能的影响。研究在RIS辅助系统中进行了仿真，并分析了这些攻击对比特错误率、吞吐量和保密性等关键性能指标的影响。

Result: 仿真结果表明，即使是有限的硬件篡改，也能显著降低RIS辅助系统的比特错误率、吞吐量和保密性等性能指标。这证明了MALRIS攻击的有效性和潜在危害。

Conclusion: 本篇论文揭示了重构智能表面（RIS）在硬件层面面临的安全风险，并提出了恶意RIS（MALRIS）的概念，即被篡改的组件即使在被动操作下也能产生对抗性行为。通过模拟功率分裂和单元分裂等攻击，证明了即使是有限的硬件篡改也能严重影响比特错误率、吞吐量和保密性等性能指标。该研究旨在提高对RIS安全威胁的认识，以支持未来无线网络中安全可靠的RIS部署。

Abstract: Reconfigurable intelligent surfaces (RIS) enhance wireless communication by
dynamically shaping the propagation environment, but their integration
introduces hardware-level security risks. This paper presents the concept of
Malicious RIS (MALRIS), where compromised components behave adversarially, even
under passive operation. The focus of this work is on practical threats such as
manufacturing time tampering, malicious firmware, and partial element control.
Two representative attacks, power-splitting and element-splitting, are modeled
to assess their impact. Simulations in a RIS-assisted system reveal that even a
limited hardware compromise can significantly degrade performance metrics such
as bit error rate, throughput, and secrecy metrics. By exposing this overlooked
threat surface, this work aims to promote awareness and support secure,
trustworthy RIS deployment in future wireless networks.

</details>


### [178] [Full-Dimensional Beamforming for Multi-User MIMO-OFDM ISAC for Low-Altitude UAV with Zero Sensing Resource Allocation](https://arxiv.org/abs/2508.06428)
*Zhiwen Zhou*

Main category: eess.SP

TL;DR: 本文提出了一种新颖的无人机集成传感与通信（ISAC）框架，利用MIMO-OFDM技术，无需专用传感时频资源，实现通信时频资源的完全复用，同时提升通信速率和传感性能，并辅以低复杂度算法，以支持低空无人机的广泛应用。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统ISAC系统为无人机ISAC系统分配专用传感时频资源效率低下，以及通信频谱效率严重下降的问题。

Method: 提出了一种新颖的基于MIMO-OFDM的UAVISAC框架，通过设计传输波束成形来满足通信和传感任务的需求，从而实现通信时频资源的完全复用。引入了低复杂度目标搜索波束成形算法和两阶段超分辨率传感算法。

Result: 所提出的MIMO-OFDM-ISAC框架不仅提高了通信和传感性能，而且优于传统的ISAC系统，为未来支持低空无人机的ISAC系统提供了一种有前景的解决方案。

Conclusion: 所提出的MIMO-OFDM-ISAC框架通过消除对专用传感时频资源的需求，实现了零时频传感开销，并能通过设计协同通信和传感任务的传输波束成形，实现通信时频资源的完全复用，从而提高通信和传感性能。此外，还引入了低复杂度目标搜索波束成形算法和两阶段超分辨率传感算法以确保高效实现。

Abstract: Low-altitude unmanned aerial vehicles (UAVs) are expected to play an
important role for low-altitude economy with a wide range of applications like
precise agriculture, aerial delivery and surveillance. Integrated sensing and
communication (ISAC) is a key technology to enable the large-scale deployment
and routine usage of UAVs by providing both communication and sensing services
efficiently. For UAV ISAC systems, as UAV often acts as both a communication
user equipment (UE) and a sensing target, traditional ISAC systems that usually
allocate dedicated TF resources for sensing are inefficient due to the severe
degradation of communication spectral efficiency. To address this issue, in
this paper, we propose a novel multiple-input multiple-output (MIMO) orthogonal
frequency division multiplexing (OFDM)-based ISAC framework for UAVs that
eliminates the need for dedicated sensing TF resources, achieving zero TF
sensing overhead. By designing the transmit beamforming to meet the
requirements for both communication and sensing tasks, our proposed approach
enables the communication TF resources to be fully reused for sensing, thereby
enhancing both the communication sum rate and the sensing performance in terms
of resolution, unambiguous range, and accuracy. Additionally, we introduce a
low-complexity target searching beamforming algorithm and a two-stage
super-resolution sensing algorithm, which ensure efficient implementation.
Simulation results demonstrate that the proposed MIMO-OFDM-ISAC framework not
only improves the communication sum rate but also outperforms traditional ISAC
systems in sensing performance, making it a promising solution for future ISAC
systems to support low-altitude UAVs.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [179] [A Markov Decision Process Framework for Early Maneuver Decisions in Satellite Collision Avoidance](https://arxiv.org/abs/2508.05876)
*Francesca Ferrara,Lander W. Schillinger Arana,Florian Dörfler,Sarah H. Q. Li*

Main category: cs.LG

TL;DR: 使用MDP和RL-PG进行CAM决策，以最小化燃料消耗并保证碰撞风险。


<details>
  <summary>Details</summary>
Motivation: 在保证可接受的碰撞风险的同时，通过早期机动决策来最小化CAM的平均燃料消耗。

Method: 提出马尔可夫决策过程（MDP）框架来模拟碰撞规避机动（CAM）的决策，并提出强化学习策略梯度（RL-PG）算法来训练自主导航策略。

Result: 与传统的截止策略相比，该训练策略在合成和历史对冲事件中显著减少了CAM的整体和平均燃料消耗，并实现了同等或更高的碰撞风险保证。

Conclusion: 该研究提出的基于MDP和RL-PG的自主导航策略在减少平均燃料消耗和保证碰撞风险方面优于传统的截止策略。

Abstract: This work presents a Markov decision process (MDP) framework to model
decision-making for collision avoidance maneuver (CAM) and a reinforcement
learning policy gradient (RL-PG) algorithm to train an autonomous guidance
policy using historic CAM data. In addition to maintaining acceptable collision
risks, this approach seeks to minimize the average fuel consumption of CAMs by
making early maneuver decisions. We model CAM as a continuous state, discrete
action and finite horizon MDP, where the critical decision is determining when
to initiate the maneuver. The MDP model also incorporates analytical models for
conjunction risk, propellant consumption, and transit orbit geometry. The
Markov policy effectively trades-off maneuver delay-which improves the
reliability of conjunction risk indicators-with propellant consumption-which
increases with decreasing maneuver time. Using historical data of tracked
conjunction events, we verify this framework and conduct an extensive ablation
study on the hyper-parameters used within the MDP. On synthetic conjunction
events, the trained policy significantly minimizes both the overall and average
propellant consumption per CAM when compared to a conventional cut-off policy
that initiates maneuvers 24 hours before the time of closest approach (TCA). On
historical conjunction events, the trained policy consumes more propellant
overall but reduces the average propellant consumption per CAM. For both
historical and synthetic conjunction events, the trained policy achieves equal
if not higher overall collision risk guarantees.

</details>


### [180] [Diagrams-to-Dynamics (D2D): Exploring Causal Loop Diagram Leverage Points under Uncertainty](https://arxiv.org/abs/2508.05659)
*Jeroen F. Uleman,Loes Crielaard,Leonie K. Elsenburg,Guido A. Veldhuis,Karien Stronks,Naja Hulvej Rod,Rick Quax,Vítor V. Vasconcelos*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Causal loop diagrams (CLDs) are widely used in health and environmental
research to represent hypothesized causal structures underlying complex
problems. However, as qualitative and static representations, CLDs are limited
in their ability to support dynamic analysis and inform intervention
strategies. Additionally, quantitative CLD analysis methods like network
centrality analysis often lead to false inference. We propose
Diagrams-to-Dynamics (D2D), a method for converting CLDs into exploratory
system dynamics models (SDMs) in the absence of empirical data. With minimal
user input - following a protocol to label variables as stocks,
flows/auxiliaries, or constants - D2D leverages the structural information
already encoded in CLDs, namely, link existence and polarity, to simulate
hypothetical interventions and explore potential leverage points under
uncertainty. Results suggest that D2D helps distinguish between high- and
low-ranked leverage points. We compare D2D to a data-driven SDM constructed
from the same CLD and variable labeling. D2D showed greater consistency with
the data-driven model than network centrality analysis, while providing
uncertainty estimates and guidance for future data collection. The method is
implemented in an open-source Python package and a web-based application to
support further testing and lower the barrier to dynamic modeling for
researchers working with CLDs. We expect additional validation will further
establish the approach's utility across a broad range of cases and domains.

</details>


### [181] [Machine Learning-Based Nonlinear Nudging for Chaotic Dynamical Systems](https://arxiv.org/abs/2508.05778)
*Jaemin Oh,Jinsil Lee,Youngjoon Hong*

Main category: cs.LG

TL;DR: 提出了一种名为神经网络中国的, 数据驱动的方法来学习非线性状态空间模型中的中国项，并使用三种表现出混沌行为的基准问题进行了评估。


<details>
  <summary>Details</summary>
Motivation: 设计有效的中国项在非线性环境中更具挑战性。

Method: 提出了一种名为神经网络中国的, 数据驱动的方法来学习非线性状态空间模型中的中国项。

Result: 所提出的方法在三种表现出混沌行为的基准问题（洛伦兹 96 模型、库尔莫戈罗夫-西瓦欣斯基方程和科尔莫戈罗夫流动）上进行了评估。

Conclusion: 提出了一种用于非线性状态空间模型的神经网络中国的, 建立了一个基于 Kazantzis-Kravaris-Luenberger 观测器理论的理论存在结果。

Abstract: Nudging is an empirical data assimilation technique that incorporates an
observation-driven control term into the model dynamics. The trajectory of the
nudged system approaches the true system trajectory over time, even when the
initial conditions differ. For linear state space models, such control terms
can be derived under mild assumptions. However, designing effective nudging
terms becomes significantly more challenging in the nonlinear setting. In this
work, we propose neural network nudging, a data-driven method for learning
nudging terms in nonlinear state space models. We establish a theoretical
existence result based on the Kazantzis--Kravaris--Luenberger observer theory.
The proposed approach is evaluated on three benchmark problems that exhibit
chaotic behavior: the Lorenz 96 model, the Kuramoto--Sivashinsky equation, and
the Kolmogorov flow.

</details>


### [182] [A Graph Neural Network Approach for Mapping the Conceptual Structure and Inter-Branch Connectivity of Physics](https://arxiv.org/abs/2508.05724)
*Massimiliano Romiti*

Main category: cs.LG

TL;DR: 本研究提出了一个名为Graphysics的新框架，它将物理定律表示为加权知识图谱，并使用图注意力网络（GAT）进行链接预测。该框架能够发现物理学的宏观结构，识别关键方程，并生成新的跨领域关系假设，在链接预测任务中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 提出一种将物理定律表示为加权知识图谱的新框架，以进行分析和发现潜在的跨领域联系。

Method: 采用图注意力网络（GAT）进行链接预测，并使用归一化的变量重叠、物理信息重要性评分和文献计量数据定义的权重来增强图表示。

Result: 在链接预测任务中，GAT模型达到了0.9742 +/- 0.0018的测试AUC，显著优于经典启发式方法（最佳AUC：0.9487）和GraphSAGE（AUC：0.9504）。

Conclusion: 该框架能够自主发现物理学的宏观结构，识别出电磁学和统计力学之间的强概念联系，并找出连接多个物理领域的关键中心方程。此外，该模型能够生成稳定的、经过计算得出的跨领域关系假设，包括已知的原理和新的数学类比，为理论研究提供了方向。该框架能够生成数百个此类假设，并为特定物理子领域创建专门的数据集。

Abstract: This work introduces a novel framework for representing and analyzing
physical laws as a weighted knowledge graph. We constructed a database of 659
distinct physical equations, subjected to rigorous semantic cleaning to resolve
notational ambiguities, resulting in a corpus of 400 advanced physics
equations. We developed an enhanced graph representation where both physical
concepts and equations are nodes, connected by weighted inter-equation bridges.
These weights are objectively defined using normalized metrics for variable
overlap, physics-informed importance scores, and bibliometric data. A Graph
Attention Network (GAT) was trained for link prediction, achieving a test AUC
of 0.9742 +/- 0.0018 across five independent runs, significantly outperforming
both classical heuristics (best baseline AUC: 0.9487) and established GNN
architectures like GraphSAGE (AUC: 0.9504, p = 0.029). Statistical testing
confirmed significance of all comparisons (p < 0.05), with 2.7% improvement
over the best baseline. Our analysis reveals three key findings: (i) The model
autonomously rediscovers the known macroscopic structure of physics,
identifying strong conceptual axes between Electromagnetism and Statistical
Mechanics. (ii) It identifies central hub equations that serve as critical
bridges between multiple physical domains. (iii) The model generates stable,
computationally-derived hypotheses for cross-domain relationships, identifying
both known principles and suggesting novel mathematical analogies for further
theoretical investigation. The framework can generate hundreds of such
hypotheses, enabling the creation of specialized datasets for targeted analysis
of specific physics subfields. Code and data available at
https://github.com/kingelanci/graphysics

</details>


### [183] [Optimal Linear Baseline Models for Scientific Machine Learning](https://arxiv.org/abs/2508.05831)
*Alexander DeLise,Kyle Loh,Krish Patel,Meredith Teague,Andrea Arnold,Matthias Chung*

Main category: cs.LG

TL;DR: 研究提出了一种用于科学机器学习的线性神经网络理论框架，解决了数据映射问题，并能在多种科学领域提供可解释和可靠的基准。


<details>
  <summary>Details</summary>
Motivation: 解决科学研究中一个基本挑战：刻画和计算从物理过程到观测信号和测量的映射。现有非线性神经网络虽然成功，但理论上不透明，在需要可解释性的场景中应用受限。线性神经网络作为简单有效的工具，有助于理解复杂关系。

Method: 提出了一种统一的理论框架，用于分析线性编码器-解码器架构，并利用贝叶斯风险最小化来解决数据驱动的科学机器学习问题。具体推导了前向建模和逆向恢复任务的闭式、秩约束的线性和仿射线性最优映射，并考虑了数据、前向算子和测量过程的秩亏缺情况。

Result: 推导了前向建模和逆向恢复任务的闭式、秩亏缺的线性和仿射线性最优映射。通过在生物医学成像、金融因子分析和非线性流体动力学（浅水方程）等数据集上进行数值实验，验证了理论结果。

Conclusion: 该工作为科学机器学习问题提供了一个统一的理论框架，用于分析线性编码器-解码器架构，并通过贝叶斯风险最小化来解决这些问题。研究推导了前向建模和逆向恢复任务的闭式、秩约束的线性和仿射线性最优映射，并能推广到数据、前向算子和测量过程秩亏缺的情况。通过在生物医学成像、金融因子分析和非线性流体动力学（浅水方程）等数据集上进行数值实验，验证了理论结果的有效性。该研究为理解和评估科学机器学习中学习到的神经网络模型提供了坚实的基础和基准。

Abstract: Across scientific domains, a fundamental challenge is to characterize and
compute the mappings from underlying physical processes to observed signals and
measurements. While nonlinear neural networks have achieved considerable
success, they remain theoretically opaque, which hinders adoption in contexts
where interpretability is paramount. In contrast, linear neural networks serve
as a simple yet effective foundation for gaining insight into these complex
relationships. In this work, we develop a unified theoretical framework for
analyzing linear encoder-decoder architectures through the lens of Bayes risk
minimization for solving data-driven scientific machine learning problems. We
derive closed-form, rank-constrained linear and affine linear optimal mappings
for forward modeling and inverse recovery tasks. Our results generalize
existing formulations by accommodating rank-deficiencies in data, forward
operators, and measurement processes. We validate our theoretical results by
conducting numerical experiments on datasets from simple biomedical imaging,
financial factor analysis, and simulations involving nonlinear fluid dynamics
via the shallow water equations. This work provides a robust baseline for
understanding and benchmarking learned neural network models for scientific
machine learning problems.

</details>


### [184] [SCAR: State-Space Compression for AI-Driven Resource Management in 6G-Enabled Vehicular Infotainment Systems](https://arxiv.org/abs/2508.06243)
*Ioan-Sorin Comsa,Purav Shah,Karthik Vaidhyanathan,Deepak Gangadharan,Christof Imhof,Per Bergamin,Aryan Kaushik,Gabriel-Miro Muntean,Ramona Trestian*

Main category: cs.LG

TL;DR: SCAR框架通过AI驱动的资源管理，利用压缩技术优化6G车联网中的调度和公平性，提高了网络性能并减少了数据处理开销。


<details>
  <summary>Details</summary>
Motivation: 传统的无线资源管理（RRM）技术难以应对自动驾驶车辆产生的日益增长和复杂的数据量（如CQI），因此需要一种新的方法来优化6G车联网环境下的资源管理。

Method: SCAR框架结合了基于机器学习的压缩技术（如聚类和RBF网络）来减小信道质量指示（CQI）数据的大小，并利用6G网络和强化学习（RL）策略来优化调度和公平性。同时，它采用了模拟退火随机隧道（SAST）的聚类方法来优化压缩过程。

Result: SCAR框架将可行调度区域内的运行时间提高了14%，并将不公平调度时间减少了15%。此外，基于SAST的聚类方法将CQI聚类失真降低了10%，证明了其有效性。

Conclusion: SCAR框架通过其在动态车联网中的可扩展性和公平性优势，为6G网络下的车联网信息娱乐服务带来了显著的改进。

Abstract: The advent of 6G networks opens new possibilities for connected infotainment
services in vehicular environments. However, traditional Radio Resource
Management (RRM) techniques struggle with the increasing volume and complexity
of data such as Channel Quality Indicators (CQI) from autonomous vehicles. To
address this, we propose SCAR (State-Space Compression for AI-Driven Resource
Management), an Edge AI-assisted framework that optimizes scheduling and
fairness in vehicular infotainment. SCAR employs ML-based compression
techniques (e.g., clustering and RBF networks) to reduce CQI data size while
preserving essential features. These compressed states are used to train
6G-enabled Reinforcement Learning policies that maximize throughput while
meeting fairness objectives defined by the NGMN. Simulations show that SCAR
increases time in feasible scheduling regions by 14\% and reduces unfair
scheduling time by 15\% compared to RL baselines without CQI compression.
Furthermore, Simulated Annealing with Stochastic Tunneling (SAST)-based
clustering reduces CQI clustering distortion by 10\%, confirming its
efficiency. These results demonstrate SCAR's scalability and fairness benefits
for dynamic vehicular networks.

</details>


### [185] [Structural Equation-VAE: Disentangled Latent Representations for Tabular Data](https://arxiv.org/abs/2508.06347)
*Ruiyu Zhang,Ce Zhao,Xin Zhao,Lin Nie,Wai-Fung Lam*

Main category: cs.LG

TL;DR: SE-VAE是一种新颖的变分自编码器架构，通过设计实现潜在表示的可解释性和解耦，特别适用于科学和社会领域。


<details>
  <summary>Details</summary>
Motivation: 从表格数据中学习可解释的潜在表示是深度生成模型中的一个挑战。

Method: SE-VAE是一种新颖的架构，它将测量结构直接嵌入变分自编码器的设计中。它借鉴了结构方程模型，将潜在子空间与已知的指标分组对齐，并引入了一个全局干扰潜在变量来分离特定于构造的混淆变异。

Result: SE-VAE在因子恢复、可解释性和对干扰变异的鲁棒性方面始终优于其他方法。消融结果表明，架构结构是性能的关键驱动因素，而不是正则化强度。

Conclusion: SE-VAE是一个原则性的白盒生成模型框架，适用于潜在结构是理论驱动且测量有效性至关重要的科学和社会领域。

Abstract: Learning interpretable latent representations from tabular data remains a
challenge in deep generative modeling. We introduce SE-VAE (Structural
Equation-Variational Autoencoder), a novel architecture that embeds measurement
structure directly into the design of a variational autoencoder. Inspired by
structural equation modeling, SE-VAE aligns latent subspaces with known
indicator groupings and introduces a global nuisance latent to isolate
construct-specific confounding variation. This modular architecture enables
disentanglement through design rather than through statistical regularizers
alone. We evaluate SE-VAE on a suite of simulated tabular datasets and
benchmark its performance against a series of leading baselines using standard
disentanglement metrics. SE-VAE consistently outperforms alternatives in factor
recovery, interpretability, and robustness to nuisance variation. Ablation
results reveal that architectural structure, rather than regularization
strength, is the key driver of performance. SE-VAE offers a principled
framework for white-box generative modeling in scientific and social domains
where latent constructs are theory-driven and measurement validity is
essential.

</details>


### [186] [From Imperfect Signals to Trustworthy Structure: Confidence-Aware Inference from Heterogeneous and Reliability-Varying Utility Data](https://arxiv.org/abs/2508.05791)
*Haoran Li,Lihao Mai,Muhao Guo,Jiaqi Wu,Yang Weng,Yannan Sun,Ce Jimmy Liu*

Main category: cs.LG

TL;DR: 提出一个可扩展框架，整合GIS、资产元数据和电压时间序列数据，通过置信度感知推理和物理约束，以超过95%的准确率重建配电网拓扑。


<details>
  <summary>Details</summary>
Motivation: 为了解决现实世界中公用事业数据源多样、质量不一的挑战，需要一种可扩展的框架来重建可信的配电网拓扑。

Method: 开发了一个可扩展的框架，通过系统地整合异构数据来重建可信的电网拓扑。该框架结合了物理基础设施的空间布局（如GIS和资产元数据）和系统在信号域（如电压时间序列）的动态行为。引入了置信度感知推理机制来处理不均匀的数据质量，并嵌入了诸如变压器容量限制和径向拓扑要求等运行约束。

Result: 使用Oncor服务区域内8000多个电表和3个馈线的真实数据进行验证，证明了该框架在拓扑重构方面具有超过95%的准确率，并在置信度校准和计算效率方面相比基线方法有显著提升。

Conclusion: 该框架通过结合空间布局和信号域动态行为，并嵌入操作约束，实现了95%以上准确率的配电网拓扑重构，同时提高了置信度校准和计算效率。

Abstract: Accurate distribution grid topology is essential for reliable modern grid
operations. However, real-world utility data originates from multiple sources
with varying characteristics and levels of quality. In this work, developed in
collaboration with Oncor Electric Delivery, we propose a scalable framework
that reconstructs a trustworthy grid topology by systematically integrating
heterogeneous data. We observe that distribution topology is fundamentally
governed by two complementary dimensions: the spatial layout of physical
infrastructure (e.g., GIS and asset metadata) and the dynamic behavior of the
system in the signal domain (e.g., voltage time series). When jointly
leveraged, these dimensions support a complete and physically coherent
reconstruction of network connectivity. To address the challenge of uneven data
quality without compromising observability, we introduce a confidence-aware
inference mechanism that preserves structurally informative yet imperfect
inputs, while quantifying the reliability of each inferred connection for
operator interpretation. This soft handling of uncertainty is tightly coupled
with hard enforcement of physical feasibility: we embed operational
constraints, such as transformer capacity limits and radial topology
requirements, directly into the learning process. Together, these components
ensure that inference is both uncertainty-aware and structurally valid,
enabling rapid convergence to actionable, trustworthy topologies under
real-world deployment conditions. The proposed framework is validated using
data from over 8000 meters across 3 feeders in Oncor's service territory,
demonstrating over 95% accuracy in topology reconstruction and substantial
improvements in confidence calibration and computational efficiency relative to
baseline methods.

</details>


### [187] [An Effective Approach for Node Classification in Textual Graphs](https://arxiv.org/abs/2508.05836)
*Rituparna Datta,Nibir Chandra Mandal*

Main category: cs.LG

TL;DR: 提出了一种结合ChatGPT和Graphormer的新颖框架，用于解决文本属性图中的节点分类问题，通过融合丰富的文本语义和图结构信息，在ogbn-arxiv数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的节点分类方法在整合文本语义和图结构信息方面存在挑战，难以处理细微的领域特定术语、建模远程依赖关系、适应时间演化以及在大规模数据集上进行扩展。

Method: 提出了一种整合TAPE（文本属性图表示增强）和Graphormer的新颖框架。该方法利用了ChatGPT，并在TAPE框架内生成了来自论文内容的语义丰富的解释，这些解释被融合到增强的节点表示中。这些嵌入与结构特征相结合，并通过具有学习注意权重的新颖集成层。Graphormer的路径感知位置编码和多头注意机制被用于有效捕获引用网络中的远程依赖关系。

Result: 在ogbn-arxiv数据集上实现了最先进的性能，分类准确率达到了0.772，显著超过了最佳GCN基线0.713。在精确率（0.671）、召回率（0.577）和F1分数（0.610）方面也取得了强劲的结果。通过全面的消融研究验证了该方法，量化了每个组件的贡献，证明了语义和结构信息之间的协同作用。

Conclusion: 该框架为动态文本属性图提供了一个可扩展且强大的节点分类解决方案，为知识系统和科学发现的未来研究提供了有希望的方向。

Abstract: Textual Attribute Graphs (TAGs) are critical for modeling complex networks
like citation networks, but effective node classification remains challenging
due to difficulties in integrating rich semantics from text with structural
graph information. Existing methods often struggle with capturing nuanced
domain-specific terminology, modeling long-range dependencies, adapting to
temporal evolution, and scaling to massive datasets. To address these issues,
we propose a novel framework that integrates TAPE (Text-Attributed Graph
Representation Enhancement) with Graphormer. Our approach leverages a large
language model (LLM), specifically ChatGPT, within the TAPE framework to
generate semantically rich explanations from paper content, which are then
fused into enhanced node representations. These embeddings are combined with
structural features using a novel integration layer with learned attention
weights. Graphormer's path-aware position encoding and multi-head attention
mechanisms are employed to effectively capture long-range dependencies across
the citation network. We demonstrate the efficacy of our framework on the
challenging ogbn-arxiv dataset, achieving state-of-the-art performance with a
classification accuracy of 0.772, significantly surpassing the best GCN
baseline of 0.713. Our method also yields strong results in precision (0.671),
recall (0.577), and F1-score (0.610). We validate our approach through
comprehensive ablation studies that quantify the contribution of each
component, demonstrating the synergy between semantic and structural
information. Our framework provides a scalable and robust solution for node
classification in dynamic TAGs, offering a promising direction for future
research in knowledge systems and scientific discovery.

</details>


### [188] [Near-Optimal Regret for Efficient Stochastic Combinatorial Semi-Bandits](https://arxiv.org/abs/2508.06247)
*Zichun Ye,Runqi Wang,Xutong Liu,Shuai Li*

Main category: cs.LG

TL;DR: CMOSS算法通过在随机设置下实现更优的遗憾界限和更低的计算开销，解决了现有组合多臂老虎机算法的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有UCB类算法（如CUCB）在长周期下具有$\\log T$的遗憾因子以及对抗类算法（如FTRL、OMD、EXP3.M、HYBRID）计算开销大的问题，提出CMOSS算法。

Method: 提出了一种名为CMOSS（Combinatorial Minimax Optimal Strategy in the Stochastic setting）的算法。

Result: CMOSS算法在半老虎机反馈下实现了$O\big( (\log k)^2\sqrt{kmT}\big )$的实例无关遗憾界限，并且在级联反馈下同样适用。实验结果表明CMOSS在遗憾和运行效率上均优于现有算法。

Conclusion: CMOSS算法在随机设置下实现了实例无关的遗憾界限 $Oig( (\log k)^2\sqrt{kmT}\big )$，消除了对 $\log T$ 的依赖，并匹配了已知的 $\Omega\big( \sqrt{kmT}\big)$ 下界（相差 $O\big((\log k)^2\big)$）。此外，CMOSS也适用于级联反馈，并在合成和真实世界数据集的实验中，在遗憾和运行时效率方面均优于基准算法。

Abstract: The combinatorial multi-armed bandit (CMAB) is a cornerstone of sequential
decision-making framework, dominated by two algorithmic families: UCB-based and
adversarial methods such as follow the regularized leader (FTRL) and online
mirror descent (OMD). However, prominent UCB-based approaches like CUCB suffer
from additional regret factor $\log T$ that is detrimental over long horizons,
while adversarial methods such as EXP3.M and HYBRID impose significant
computational overhead. To resolve this trade-off, we introduce the
Combinatorial Minimax Optimal Strategy in the Stochastic setting (CMOSS). CMOSS
is a computationally efficient algorithm that achieves an instance-independent
regret of $O\big( (\log k)^2\sqrt{kmT}\big )$ under semi-bandit feedback, where
$m$ is the number of arms and $k$ is the maximum cardinality of a feasible
action. Crucially, this result eliminates the dependency on $\log T$ and
matches the established $\Omega\big( \sqrt{kmT}\big)$ lower bound up to
$O\big((\log k)^2\big)$. We then extend our analysis to show that CMOSS is also
applicable to cascading feedback. Experiments on synthetic and real-world
datasets validate that CMOSS consistently outperforms benchmark algorithms in
both regret and runtime efficiency.

</details>


### [189] [The Fourth State: Signed-Zero Ternary for Stable LLM Quantization (and More)](https://arxiv.org/abs/2508.05905)
*Jeffrey Uhlmann*

Main category: cs.LG

TL;DR: SZT是一种2位量化方法，在固定资源预算下，它能确定性地提供梯度信息，且没有前向传播开销，并可能提高信息密度。


<details>
  <summary>Details</summary>
Motivation: 将量化视为牺牲性能换取更低计算需求的次优近似方法，但在固定资源预算下，SZT提供了不同的视角。

Method: SZT是一种2位量化方法，可以确定性地提供梯度信息，且没有前向传播开销。

Result: SZT可能比非量化方法提高信息密度。SZT是一种2位量化，确定性地提供梯度信息，没有前向传播开销。   

Conclusion: SZT是一种2位量化方法，它确定性地提供梯度信息，且没有前向传播开销。它可能比非量化方法提高信息密度。

Abstract: Quantization is usually regarded as a means to trade quality of performance
for reduced compute requirements, i.e., as a suboptimal approximation. However,
if examined in terms of a fixed overall resource budget, a very different
perspective arises. We introduce Signed-Zero Ternary (SZT), a 2-bit
quantization that deterministically provides gradient information with no
forward-path penalty. Our analysis provides evidence that it may improve
information density compared to non-quantized alternatives.

</details>


### [190] [Unsupervised Partner Design Enables Robust Ad-hoc Teamwork](https://arxiv.org/abs/2508.06336)
*Constantin Ruhdorfer,Matteo Bortoletto,Victor Oei,Anna Penzkofer,Andreas Bulling*

Main category: cs.LG

TL;DR: Unsupervised Partner Design (UPD) is a new RL framework that creates its own diverse training partners on the fly, improving ad-hoc teamwork without needing pre-existing partners or manual tuning. It outperforms existing methods and is perceived as more human-like and less frustrating by users.


<details>
  <summary>Details</summary>
Motivation: To develop a population-free, multi-agent reinforcement learning framework for robust ad-hoc teamwork that adaptively generates training partners without requiring pretrained partners or manual parameter tuning.

Method: UPD constructs diverse partners by stochastically mixing an ego agent's policy with biased random behaviours and scores them using a variance-based learnability metric that prioritises partners near the ego agent's current learning frontier. It can be integrated with unsupervised environment design for fully unsupervised curricula over both level and partner distributions in a cooperative setting.

Result: UPD enables fully unsupervised curricula over both level and partner distributions in a cooperative setting, achieving higher returns and better collaboration in user studies.

Conclusion: UPD consistently outperforms both population-based and population-free baselines and ablations in Overcooked-AI and Overcooked Generalisation Challenge, and is perceived as more adaptive, human-like, a better collaborator, and less frustrating in user study.

Abstract: We introduce Unsupervised Partner Design (UPD) - a population-free,
multi-agent reinforcement learning framework for robust ad-hoc teamwork that
adaptively generates training partners without requiring pretrained partners or
manual parameter tuning. UPD constructs diverse partners by stochastically
mixing an ego agent's policy with biased random behaviours and scores them
using a variance-based learnability metric that prioritises partners near the
ego agent's current learning frontier. We show that UPD can be integrated with
unsupervised environment design, resulting in the first method enabling fully
unsupervised curricula over both level and partner distributions in a
cooperative setting. Through extensive evaluations on Overcooked-AI and the
Overcooked Generalisation Challenge, we demonstrate that this dynamic partner
curriculum is highly effective: UPD consistently outperforms both
population-based and population-free baselines as well as ablations. In a user
study, we further show that UPD achieves higher returns than all baselines and
was perceived as significantly more adaptive, more human-like, a better
collaborator, and less frustrating.

</details>


### [191] [FedMeNF: Privacy-Preserving Federated Meta-Learning for Neural Fields](https://arxiv.org/abs/2508.06301)
*Junhyeog Yun,Minui Hong,Gunhee Kim*

Main category: cs.LG

TL;DR: FedMeNF is a new Federated Meta-Learning method for neural fields that improves efficiency and privacy on edge devices using a privacy-preserving loss function.


<details>
  <summary>Details</summary>
Motivation: Neural fields are memory-efficient but require significant data and computation, limiting their use on edge devices. Traditional Federated Meta-Learning (FML) for neural fields faces privacy leakage issues.

Method: FedMeNF, a Federated Meta-Learning approach utilizing a new privacy-preserving loss function to regulate privacy leakage during local meta-optimization, allowing efficient learning without retaining client's private data.

Result: Experiments show FedMeNF achieves fast optimization speed and robust reconstruction performance, preserving client data privacy.

Conclusion: FedMeNF enables fast optimization and robust reconstruction for neural fields on resource-constrained edge devices, even with few-shot or non-IID data across diverse modalities, while preserving client data privacy through a novel privacy-preserving loss function.

Abstract: Neural fields provide a memory-efficient representation of data, which can
effectively handle diverse modalities and large-scale data. However, learning
to map neural fields often requires large amounts of training data and
computations, which can be limited to resource-constrained edge devices. One
approach to tackle this limitation is to leverage Federated Meta-Learning
(FML), but traditional FML approaches suffer from privacy leakage. To address
these issues, we introduce a novel FML approach called FedMeNF. FedMeNF
utilizes a new privacy-preserving loss function that regulates privacy leakage
in the local meta-optimization. This enables the local meta-learner to optimize
quickly and efficiently without retaining the client's private data. Our
experiments demonstrate that FedMeNF achieves fast optimization speed and
robust reconstruction performance, even with few-shot or non-IID data across
diverse data modalities, while preserving client data privacy.

</details>


### [192] [Dual Signal Decomposition of Stochastic Time Series](https://arxiv.org/abs/2508.05915)
*Alex Glushkovsky*

Main category: cs.LG

TL;DR: 一种新的时间序列分解方法，使用机器学习分离均值、离散度和噪声。


<details>
  <summary>Details</summary>
Motivation: 研究时间序列的分解，将其分解为三个表示双信号（均值和离散度）并分离噪声的时间序列。

Method: 通过应用机器学习拟合双信号，最小化损失函数，该函数在拟合原始时间序列和惩罚双信号的正则化项之间进行权衡，正则化项基于时间的一阶和二阶导数。为了保留特殊模式，基于统计过程控制方法学对损失函数的正则化分量进行了加权。

Result: 研究了顺序学习和联合学习两种学习方法，并考虑了通过求解非线性优化问题或应用神经网络进行学习。通过调整损失函数超参数，可以将噪声视为平稳随机过程。分解后的双信号可以在二维空间表示，用于学习固有结构、预测均值和离散度或分析多时间序列的交叉效应。

Conclusion: 该分解方法可以作为平滑算法，通过分离噪声达到去噪的目的。

Abstract: The research paper addresses decomposition of a stochastic time series into
three time series representing a dual signal i.e., the mean and the dispersion,
with noise isolated. Decomposition is done by applying machine learning to fit
a dual signal. Machine learning minimizes the loss function which compromises
between fitting the original time series and penalizing irregularities of the
dual signal. The latter includes terms based on the first and second order
derivatives along time. To preserve special patterns, weighting of the
regularization components of the loss function has been introduced based on
Statistical Process Control methodology. The proposed decomposition can be
applied as a smoothing algorithm against the mean and dispersion of the time
series. By isolating noise, the proposed decomposition can be seen as a
denoising algorithm. Two approaches of the learning process have been
considered: sequential and jointly. The former approach learns the mean signal
first and then dispersion. The latter approach fits the dual signal jointly.
Jointly learning can uncover complex relationships for the time series with
heteroskedasticity. Learning has been set by solving the direct non-linear
unconstrained optimization problem or by applying neural networks that have
sequential or twin output architectures. Tuning of the loss function
hyperparameters focuses on the isolated noise to be a stationary stochastic
process without autocorrelation properties. Depending on the applications, the
hyperparameters of the learning can be tuned towards either the discrete states
by stepped signal or smoothed series. The decomposed dual signal can be
represented on the 2D space and used to learn inherent structures, to forecast
both mean and dispersion, or to analyze cross effects in case of multiple time
series.

</details>


### [193] [Fast, Convex and Conditioned Network for Multi-Fidelity Vectors and Stiff Univariate Differential Equations](https://arxiv.org/abs/2508.05921)
*Siddharth Rout*

Main category: cs.LG

TL;DR: 神经偏微分方程求解器中的准确性通常会因优化不当而崩溃，这主要是由于多保真度和病态问题中的病态问题。我们研究了物理信息极端学习机 (PIELM) 中的此问题，这是一种神经偏微分方程求解器的凸变体，并表明控制方程中的渐近分量会产生高度病态的激活矩阵，严重限制了收敛性。我们提出了一种简单但有效的激活函数过滤步骤，称为移位高斯编码，它增加了矩阵秩和表达能力，同时保持了凸性。我们的方法将稳态对流扩散方程中的 Peclet 数的可解范围扩展了两个数量级以上，在多频函数学习中实现了低至六个数量级的误差，并且比具有一百万多个参数的深度网络更准确、更快地拟合高保真图像矢量。这项工作强调，条件而非深度通常是科学神经解算器中的瓶颈，而简单的体系结构更改可以带来实质性的好处。


<details>
  <summary>Details</summary>
Motivation: 神经偏微分方程求解器中的准确性通常会因优化不当而崩溃，这主要是由于多保真度和病态问题中的病态问题。

Method: 提出了一种简单但有效的激活函数过滤步骤，称为移位高斯编码，它增加了矩阵秩和表达能力，同时保持了凸性。

Result: 将稳态对流扩散方程中的 Peclet 数的可解范围扩展了两个数量级以上，在多频函数学习中实现了低至六个数量级的误差，并且比具有一百万多个参数的深度网络更准确、更快地拟合高保真图像矢量。

Conclusion: 应力、深度而非条件是科学神经解算器中的瓶颈，并且简单的体系结构更改可以带来实质性的好处。

Abstract: Accuracy in neural PDE solvers often breaks down not because of limited
expressivity, but due to poor optimisation caused by ill-conditioning,
especially in multi-fidelity and stiff problems. We study this issue in
Physics-Informed Extreme Learning Machines (PIELMs), a convex variant of neural
PDE solvers, and show that asymptotic components in governing equations can
produce highly ill-conditioned activation matrices, severely limiting
convergence. We introduce Shifted Gaussian Encoding, a simple yet effective
activation filtering step that increases matrix rank and expressivity while
preserving convexity. Our method extends the solvable range of Peclet numbers
in steady advection-diffusion equations by over two orders of magnitude,
achieves up to six orders lower error on multi-frequency function learning, and
fits high-fidelity image vectors more accurately and faster than deep networks
with over a million parameters. This work highlights that conditioning, not
depth, is often the bottleneck in scientific neural solvers and that simple
architectural changes can unlock substantial gains.

</details>


### [194] [Mitigating Think-Answer Mismatch in LLM Reasoning Through Noise-Aware Advantage Reweighting](https://arxiv.org/abs/2508.05928)
*Si Shen,Peijun Shen,Wenhua Zhao,Danhao Zhu*

Main category: cs.LG

TL;DR: S-GRPO通过优化噪声感知优势权重，解决了GRPO在大型推理模型训练中的“思考-回答不匹配”问题，提高了训练的稳定性和性能，尤其在存在噪声的情况下表现更佳。


<details>
  <summary>Details</summary>
Motivation: 旨在解决关键技术GRPO在训练大型推理模型时存在的“思考-回答不匹配”问题，该问题会导致噪声奖励信号破坏学习过程，尤其在响应组不平衡时更为严重。

Method: 提出了一种名为稳定组相对策略优化（S-GRPO）的改进方法，该方法通过推导最优的、考虑噪声的优势权重来稳定训练过程，以解决“思考-回答不匹配”问题。

Result: S-GRPO在数学推理基准测试中显著优于DR. GRPO，在不同模型上均实现了性能提升，并且在存在高达20%的合成奖励噪声时仍能保持稳定的学习。代码和数据可在https://github.com/shenpeijun0212/S-GRPO获取。

Conclusion: S-GRPO在数学推理基准测试中表现出优越性和鲁棒性，在Qwen-Math-7B-Base、Llama-3.2-3B-Base和Qwen-Math-1.5B-Instruct模型上分别实现了+2.5%、+2.2%和+2.4%的性能提升。在20%的合成奖励噪声下，标准GRPO失效，而S-GRPO仍能保持稳定的学习进展，证明了其在更大规模推理模型训练中更优越和有效的潜力。

Abstract: Group-Relative Policy Optimization (GRPO) is a key technique for training
large reasoning models, yet it suffers from a critical vulnerability: the
\emph{Think-Answer Mismatch}, where noisy reward signals corrupt the learning
process. This problem is most severe in unbalanced response groups,
paradoxically degrading the signal precisely when it should be most
informative. To address this challenge, we propose Stable Group-Relative Policy
Optimization (S-GRPO), a principled enhancement that derives optimal,
noise-aware advantage weights to stabilize training. Our comprehensive
experiments on mathematical reasoning benchmarks demonstrate S-GRPO's
effectiveness and robustness. On various models, S-GRPO significantly
outperforms DR. GRPO, achieving performance gains of +2.5% on
Qwen-Math-7B-Base, +2.2% on Llama-3.2-3B-Base, and +2.4% on
Qwen-Math-1.5B-Instruct. Most critically, while standard GRPO fails to learn
under 20% synthetic reward noise, S-GRPO maintains stable learning progress.
These results highlight S-GRPO's potential for more robust and effective
training of large-scale reasoning models. \footnote{Code and data are available
at: https://github.com/shenpeijun0212/S-GRPO

</details>


### [195] [Multi-Armed Bandits-Based Optimization of Decision Trees](https://arxiv.org/abs/2508.05957)
*Hasibul Karim Shanto,Umme Ayman Koana,Shadikur Rahman*

Main category: cs.LG

TL;DR: 提出了一种基于 MAB 的决策树剪枝新方法，通过将剪枝视为探索-利用问题，实现了动态剪枝，提高了模型的泛化能力和预测性能。


<details>
  <summary>Details</summary>
Motivation: 传统的剪枝技术（如 CCP 和 REP）多基于贪婪方法，可能导致模型在面对小型复杂数据集时泛化能力不足。为了解决这个问题，需要一种能够动态剪枝以获得更好泛化能力的模型。

Method: 提出了一种基于多臂老虎机（MAB）的剪枝方法，将剪枝过程建模为探索-利用问题，并利用 MAB 算法根据反馈动态地选择最优分支进行剪枝。

Result: 与传统方法相比，所提出的 MAB 剪枝方法在多个基准数据集上取得了更好的预测性能。

Conclusion: 该研究提出了一种基于多臂老虎机（MAB）的决策树剪枝方法，通过将剪枝过程视为探索-利用问题，利用 MAB 算法根据每次剪枝操作的反馈动态地寻找最优剪枝分支，以生成泛化能力更强的决策树模型，并在基准数据集上的实验评估表明，该方法优于传统的剪枝技术。

Abstract: Decision trees, without appropriate constraints, can easily become overly
complex and prone to overfit, capturing noise rather than generalizable
patterns. To resolve this problem,pruning operation is a crucial part in
optimizing decision trees, as it not only reduces the complexity of trees but
also decreases the probability of generating overfit models. The conventional
pruning techniques like Cost-Complexity Pruning (CCP) and Reduced Error Pruning
(REP) are mostly based on greedy approaches that focus on immediate gains in
performance while pruning nodes of the decision tree. However, this might
result in a lower generalization in the long run, compromising the robust
ability of the tree model when introduced to unseen data samples, particularly
when trained with small and complex datasets. To address this challenge, we are
proposing a Multi-Armed Bandits (MAB)-based pruning approach, a reinforcement
learning (RL)-based technique, that will dynamically prune the tree to generate
an optimal decision tree with better generalization. Our proposed approach
assumes the pruning process as an exploration-exploitation problem, where we
are utilizing the MAB algorithms to find optimal branch nodes to prune based on
feedback from each pruning actions. Experimental evaluation on several
benchmark datasets, demonstrated that our proposed approach results in better
predictive performance compared to the traditional ones. This suggests the
potential of utilizing MAB for a dynamic and probabilistic way of decision tree
pruning, in turn optimizing the decision tree-based model.

</details>


### [196] [Mildly Conservative Regularized Evaluation for Offline Reinforcement Learning](https://arxiv.org/abs/2508.05960)
*Haohui Chen,Zhiyong Chen*

Main category: cs.LG

TL;DR: Offline RL methods struggle with distribution shift, leading to OOD actions and overestimation. This paper introduces the MCRE framework and MCRQ algorithm to balance conservatism and performance by incorporating behavior cloning into the Bellman backup, showing improved results over existing methods.


<details>
  <summary>Details</summary>
Motivation: Offline RL faces challenges due to distribution shift between learned and behavior policies, causing out-of-distribution (OOD) actions and overestimation. While conservatism in the value function can prevent overestimation, excessive conservatism may limit performance. MCRE aims to balance conservatism and performance.

Method: The study proposes the mildly conservative regularized evaluation (MCRE) framework, which integrates temporal difference (TD) error with a behavior cloning term in the Bellman backup. This framework is then used to develop the mildly conservative regularized Q-learning (MCRQ) algorithm, an off-policy actor-critic algorithm.

Result: Experiments demonstrate that MCRQ outperforms strong baselines and state-of-the-art offline RL algorithms on benchmark datasets.

Conclusion: MCRQ's performance surpasses strong baselines and state-of-the-art offline RL algorithms on benchmark datasets.

Abstract: Offline reinforcement learning (RL) seeks to learn optimal policies from
static datasets without further environment interaction. A key challenge is the
distribution shift between the learned and behavior policies, leading to
out-of-distribution (OOD) actions and overestimation. To prevent gross
overestimation, the value function must remain conservative; however, excessive
conservatism may hinder performance improvement. To address this, we propose
the mildly conservative regularized evaluation (MCRE) framework, which balances
conservatism and performance by combining temporal difference (TD) error with a
behavior cloning term in the Bellman backup. Building on this, we develop the
mildly conservative regularized Q-learning (MCRQ) algorithm, which integrates
MCRE into an off-policy actor-critic framework. Experiments show that MCRQ
outperforms strong baselines and state-of-the-art offline RL algorithms on
benchmark datasets.

</details>


### [197] [LinguaFluid: Language Guided Fluid Control via Semantic Rewards in Reinforcement Learning](https://arxiv.org/abs/2508.05977)
*Aoming Liang,Chi Cheng,Dashuai Chen,Boai Sun,Dixia Fan*

Main category: cs.LG

TL;DR: 提出一种新的强化学习方法，使用SBERT将状态与文本目标对齐来计算奖励，无需手动设计奖励函数，在实验中表现出有竞争力的控制行为。


<details>
  <summary>Details</summary>
Motivation: 在科学机器学习领域，设计有效的奖励函数仍然是强化学习（RL）中的一个挑战，特别是在任务目标难以用数字指定的环境中。现有工作中的奖励函数主要基于启发式方法、手动工程或特定任务的调整。

Method: 本文提出了一种语义对齐强化学习方法，通过使用句子-双向Encoder表示变换器(SBERT)将当前状态与目标语义指令对齐来计算奖励。策略接收基于奖励的反馈，该奖励是目标文本描述与回合内语句描述之间的余弦相似度。

Result: 在几个环境中评估了该方法，结果表明，即使没有手工制作的奖励函数，语义奖励也能指导学习以实现有竞争力的控制行为。

Conclusion: 该方法将语言嵌入空间与传统欧几里得空间相关联，为智能体行为与自然语言目标对齐开辟了新途径，并为大型语言模型和流体控制应用的无缝集成奠定了基础。

Abstract: In the domain of scientific machine learning, designing effective reward
functions remains a challenge in reinforcement learning (RL), particularly in
environments where task goals are difficult to specify numerically. Reward
functions in existing work are predominantly based on heuristics, manual
engineering, or task-specific tuning. In this work, we introduce a semantically
aligned reinforcement learning method where rewards are computed by aligning
the current state with a target semantic instruction using a
Sentence-Bidirectional Encoder Representations from Transformers (SBERT).
Instead of relying on manually defined reward functions, the policy receives
feedback based on the reward, which is a cosine similarity between the goal
textual description and the statement description in the episode. We evaluated
our approach in several environments and showed that semantic reward can guide
learning to achieve competitive control behavior, even in the absence of
hand-crafted reward functions. Our study demonstrates a correlation between the
language embedding space and the conventional Euclidean space. This framework
opens new horizons for aligning agent behavior with natural language goals and
lays the groundwork for a more seamless integration of larger language models
(LLMs) and fluid control applications.

</details>


### [198] [Parameter-free Optimal Rates for Nonlinear Semi-Norm Contractions with Applications to $Q$-Learning](https://arxiv.org/abs/2508.05984)
*Ankur Naskar,Gugan Thoppe,Vijay Gupta*

Main category: cs.LG

TL;DR: 本研究通过新的方法解决了Q学习的收敛问题，实现了最优收敛率，并适用于多种场景。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于多亚克-鲁珀特平均的算法在处理半范数收缩时，由于半范数非单调性而难以实现参数无关的最优收敛率的问题。

Method: 通过将平均误差重构为涉及非线性扰动的线性递归，并结合半范数的收缩性和适当诱导范数的单调性来控制非线性。

Result: 实现了Q学习在平均奖励和指数衰减设置中的参数无关的$	ilde{O}(1/	ext{t})$最优收敛率，该结果适用于广泛的场景，包括同步/异步更新、单智能体/分布式部署以及来自模拟器或马尔可夫轨迹的数据流。

Conclusion: 该研究首次实现了Q学习在平均奖励和指数衰减设置中的参数无关的$	ilde{O}(1/	ext{t})$最优收敛率。

Abstract: Algorithms for solving \textit{nonlinear} fixed-point equations -- such as
average-reward \textit{$Q$-learning} and \textit{TD-learning} -- often involve
semi-norm contractions. Achieving parameter-free optimal convergence rates for
these methods via Polyak--Ruppert averaging has remained elusive, largely due
to the non-monotonicity of such semi-norms. We close this gap by (i.) recasting
the averaged error as a linear recursion involving a nonlinear perturbation,
and (ii.) taming the nonlinearity by coupling the semi-norm's contraction with
the monotonicity of a suitably induced norm. Our main result yields the first
parameter-free $\tilde{O}(1/\sqrt{t})$ optimal rates for $Q$-learning in both
average-reward and exponentially discounted settings, where $t$ denotes the
iteration index. The result applies within a broad framework that accommodates
synchronous and asynchronous updates, single-agent and distributed deployments,
and data streams obtained either from simulators or along Markovian
trajectories.

</details>


### [199] [Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal](https://arxiv.org/abs/2508.05988)
*Wenhao Zeng,Yaoning Wang,Chao Hu,Yuling Shi,Chengcheng Wan,Hongyu Zhang,Xiaodong Gu*

Main category: cs.LG

TL;DR: ASAP通过锚点引导和惊奇度度量压缩了大型推理模型（LRMs）的代码推理（CoT），在保持高准确性的同时，显著降低了训练和推理成本。


<details>
  <summary>Details</summary>
Motivation: LRMs在代码推理方面展现了强大的能力，但过长的推理过程带来了高昂的训练成本、推理延迟和部署问题。现有的CoT压缩方法在保持逻辑一致性和识别关键推理步骤方面存在不足。

Method: ASAP（Anchor-guided, Surprisal-based Pruning）是一个新颖的粗粒度到细粒度框架，用于代码推理（CoT）压缩。它首先通过锚点引导进行修剪，以保留核心推理结构，然后通过新颖的第一个词惊奇度度量来选择逻辑上必不可少的推理步骤，最后教会模型在推理时自主生成和利用简洁的CoT。

Result: ASAP在多个代码生成基准测试中实现了最先进的准确性，同时显著降低了训练和推理成本。在LiveCodeBench v4_v5基准测试中，与最强的基线相比，ASAP将token生成减少了23.5%，推理延迟减少了43.5%，同时在Pass@1上达到了36.19%的竞争力。

Conclusion: ASAP通过锚点引导和惊奇度度量实现了最先进的准确性，同时显著降低了训练和推理成本，并在LiveCodeBench基准测试中减少了23.5%的token生成和43.5%的推理延迟。

Abstract: Recently, Large Reasoning Models (LRMs) have demonstrated remarkable
capabilities in code reasoning by scaling up the length of Chain-of-Thought
(CoT). However, excessively long reasoning traces introduce substantial
challenges in terms of training cost, inference latency, and deployment
feasibility. While various CoT compression approaches have emerged to address
this challenge, they face inherent trade-offs: token-level methods often
disrupt syntactic and logical coherence, while step-level methods based on
perplexity fail to reliably capture the logically critical reasoning steps. In
this paper, we propose ASAP (Anchor-guided, Surprisal-based Pruning), a novel
coarse-to-fine framework for CoT compression. ASAP first performs anchor-guided
pruning to preserve the core reasoning structure, which efficiently reduces the
search space for subsequent processing. It then enables a logic-aware pruning
by selecting logically essential reasoning steps based on a novel first-token
surprisal metric. Finally, ASAP teaches models to autonomously generate and
leverage these concise CoTs at inference time, enabling efficient reasoning in
coding tasks. Experiments show that ASAP achieves state-of-the-art accuracy
across multiple code generation benchmarks while substantially reducing
training and inference costs. On the challenging LiveCodeBench v4_v5 benchmark,
our approach reduces token generation by 23.5% and inference latency by 43.5%
compared to the strongest baseline, while achieving a competitive accuracy of
36.19% in Pass@1. Our results highlight a promising direction for building
powerful and efficient LRMs.

</details>


### [200] [Optimizing Prompt Sequences using Monte Carlo Tree Search for LLM-Based Optimization](https://arxiv.org/abs/2508.05995)
*Fei Xu Yu,Gina Adam,Nathaniel D. Bastian,Tian Lan*

Main category: cs.LG

TL;DR: MCTS-OPS通过将提示选择作为顺序决策过程，利用MCTS来改进LLM在复杂任务中的代码生成和优化能力。


<details>
  <summary>Details</summary>
Motivation: LLMs在复杂任务中需要多步规划时性能会下降，而现有LLM与MCTS的结合方法主要集中在生成用于优化的启发式代码，或针对仅凭正确性就足够处理的简单任务。

Method: 提出了一种新颖的神经符号框架MCTS-OPS，将提示选择制定为由MCTS引导的顺序决策过程，以改进代码生成质量和LLM在通用优化中的问题解决能力。

Result: 在网络优化实验中，MCTS-OPS在执行生成代码的成功率和优化结果（奖励提高2-4倍，标准差降低3倍）方面显著优于基线方法，并能将获得最优解的机会提高约10%。

Conclusion: LLM结合符号规划在复杂领域中进行鲁棒、高质量代码生成方面显示出巨大潜力。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in
code generation and structured reasoning; however, their performance often
degrades on complex tasks that require consistent multi-step planning. Recent
work has explored combining LLMs with Monte Carlo Tree Search (MCTS), yet
existing approaches primarily focus on generating heuristic-based code for
optimization or target simpler tasks where correctness alone is sufficient. In
this work, we propose MCTS-OPS, a novel neural-symbolic framework that
formulates prompt selection as a sequential decision process guided by MCTS.
Our method explores and refines multi-step prompt sequences for the goal of
improving code generation quality and enhancing the problem-solving
capabilities of LLMs in general optimization. Experiments on network
optimization show significant improvement over the baselines, both in the
success rate of executing the generated code and in the optimization results
with the specified objective and constraints (2$\sim$4$\times$ higher reward
and 3$\times$ lower standard deviation). Moreover, it improves the chance of
attaining the optimal solution by about 10\% of cases, compared to baseline
methods in hard problems. These results highlight the promise of combining
symbolic planning with LLMs for robust, high-quality code generation in complex
domains.

</details>


### [201] [Stepwise Fine and Gray: Subject-Specific Variable Selection Shows When Hemodynamic Data Improves Prognostication of Comatose Post-Cardiac Arrest Patients](https://arxiv.org/abs/2508.06023)
*Xiaobin Shen,Jonathan Elmer,George H. Chen*

Main category: cs.LG

TL;DR: 本研究提出了一种新的动态竞争风险模型，用于改进心脏骤停后昏迷患者的预后预测。该模型能结合时间不变和时间变化的特征，并自动确定何时利用这些信息。模型在真实数据上表现出良好的预测能力，并可推广到其他需要动态特征分析的场景。


<details>
  <summary>Details</summary>
Motivation: 心脏骤停后昏迷患者的预后评估是一个关键挑战，直接影响ICU的临床决策。此研究旨在改进预后预测，特别是利用随时间变化（如血流动力学数据）和不随时间变化（如人口统计学、心脏骤停特征）的特征。

Method: 我们提出了一种新颖的逐步动态竞争风险模型，该模型通过自动确定何时利用不随时间变化的特征（第一阶段）和随时间变化的特征（第二阶段）来改进神经系统结局的预测。该方法扩展了标准的Fine and Gray模型，明确模拟了两个阶段，并结合了神经网络来灵活地捕捉复杂的非线性特征关系。

Result: 我们的模型能够识别出哪些患者的第二阶段（随时间变化的血流动力学）信息对预后有益，以及何时这些信息有益（随着我们收集患者随时间的更多血流动力学数据，这些数据对预后的重要性也会变化）。

Conclusion: 我们的模型在2,278名心脏骤停后昏迷患者的回顾性队列中进行了评估，在区分觉醒、撤除生命支持和最大支持下的死亡等竞争性结局方面表现出稳健的辨别性能。我们的方法可以推广到收集新特征的多阶段场景，并可用于其他动态预测任务，以确定何时以及对哪些患者新收集的特征能显著改善预测。

Abstract: Prognostication for comatose post-cardiac arrest patients is a critical
challenge that directly impacts clinical decision-making in the ICU. Clinical
information that informs prognostication is collected serially over time.
Shortly after cardiac arrest, various time-invariant baseline features are
collected (e.g., demographics, cardiac arrest characteristics). After ICU
admission, additional features are gathered, including time-varying hemodynamic
data (e.g., blood pressure, doses of vasopressor medications). We view these as
two phases in which we collect new features. In this study, we propose a novel
stepwise dynamic competing risks model that improves the prediction of
neurological outcomes by automatically determining when to take advantage of
time-invariant features (first phase) and time-varying features (second phase).
Notably, our model finds patients for whom this second phase (time-varying
hemodynamic) information is beneficial for prognostication and also when this
information is beneficial (as we collect more hemodynamic data for a patient
over time, how important these data are for prognostication varies). Our
approach extends the standard Fine and Gray model to explicitly model the two
phases and to incorporate neural networks to flexibly capture complex nonlinear
feature relationships. Evaluated on a retrospective cohort of 2,278 comatose
post-arrest patients, our model demonstrates robust discriminative performance
for the competing outcomes of awakening, withdrawal of life-sustaining therapy,
and death despite maximal support. Our approach generalizes to more than two
phases in which new features are collected and could be used in other dynamic
prediction tasks, where it may be helpful to know when and for whom newly
collected features significantly improve prediction.

</details>


### [202] [Adaptive Heterogeneous Graph Neural Networks: Bridging Heterophily and Heterogeneity](https://arxiv.org/abs/2508.06034)
*Qin Chen,Guojie Song*

Main category: cs.LG

TL;DR: AHGNN是一种新的图神经网络，可以处理异质性异构图。


<details>
  <summary>Details</summary>
Motivation: 大多数现有研究要么孤立地关注异构性，要么孤立地关注异质性，却忽略了实际应用中异质性异构图的普遍存在，这会导致性能下降。

Method: AHGNN采用一种考虑了特定于跳数和元路径的异质性分布的异质性感知卷积。然后，它使用一种由粗到细的注意力机制来整合来自不同语义空间的消息，以过滤噪声并强调信息信号。

Result: AHGNN在七个现实世界的图和二十个基线上进行了实验，证明了其优越的性能，特别是在高异质性情况下。

Conclusion: AHGNN在现实世界的七个图和二十个基线上进行了实验，并且表现出了优越的性能，特别是在高异质性情况下。

Abstract: Heterogeneous graphs (HGs) are common in real-world scenarios and often
exhibit heterophily. However, most existing studies focus on either
heterogeneity or heterophily in isolation, overlooking the prevalence of
heterophilic HGs in practical applications. Such ignorance leads to their
performance degradation. In this work, we first identify two main challenges in
modeling heterophily HGs: (1) varying heterophily distributions across hops and
meta-paths; (2) the intricate and often heterophily-driven diversity of
semantic information across different meta-paths. Then, we propose the Adaptive
Heterogeneous Graph Neural Network (AHGNN) to tackle these challenges. AHGNN
employs a heterophily-aware convolution that accounts for heterophily
distributions specific to both hops and meta-paths. It then integrates messages
from diverse semantic spaces using a coarse-to-fine attention mechanism, which
filters out noise and emphasizes informative signals. Experiments on seven
real-world graphs and twenty baselines demonstrate the superior performance of
AHGNN, particularly in high-heterophily situations.

</details>


### [203] [DP-LLM: Runtime Model Adaptation with Dynamic Layer-wise Precision Assignment](https://arxiv.org/abs/2508.06041)
*Sangwoo Kwon,Seong Hoon Seo,Jae W. Lee,Yeonhong Park*

Main category: cs.LG

TL;DR: DP-LLM 是一种新的机制，可以根据输入值动态地为 LLM 中的每个层分配精度，以优化延迟和精度。


<details>
  <summary>Details</summary>
Motivation: 为了有效处理具有不同运行时约束（例如延迟和精度）的设备上大型语言模型（LLM）的查询，需要一种能够动态适应运行时模型配置的方法。

Method: DP-LLM 通过为 LLM 中的每个线性层增加一个精度选择器，该选择器利用轻量级错误估计器和通过微调学习的阈值，在运行时确定比特宽度。

Result: 实验结果表明，DP-LLM 在多个模型和基准测试中实现了优越的性能-延迟权衡。

Conclusion: DP-LLM 通过动态分配精度到每个层，实现了优于先前方法的性能-延迟权衡。

Abstract: How can we effectively handle queries for on-device large language models
(LLMs) with varying runtime constraints, such as latency and accuracy?
Multi-scale quantization addresses this challenge by enabling memory-efficient
runtime model adaptation of LLMs through the overlaying of multiple model
variants quantized to different bitwidths. Meanwhile, an important question
still remains open-ended: how can models be properly configured to match a
target precision or latency? While mixed-precision offers a promising solution,
we take this further by leveraging the key observation that the sensitivity of
each layer dynamically changes across decoding iterations. Building on this
insight, we introduce DP-LLM, a novel mechanism that dynamically assigns
precision to each layer based on input values. DP-LLM augments each linear
layer in an LLM with a precision selector that determines the bitwidth at
runtime using a lightweight error estimator and threshold values learned
through fine-tuning. Experimental results across multiple models and benchmarks
demonstrate that DP-LLM achieves a superior performance-latency trade-off,
outperforming prior approaches.

</details>


### [204] [Architecture-Aware Generalization Bounds for Temporal Networks: Theory and Fair Comparison Methodology](https://arxiv.org/abs/2508.06066)
*Barak Gahtan,Alex M. Bronstein*

Main category: cs.LG

TL;DR: 该研究为深度时间模型（如 TCN）提供了理论分析，并提出了一种新的评估方法。研究发现，尽管深度会增加泛化误差，但时间依赖性实际上可以提高学习效率。然而，实验结果与理论预测存在差异，这表明了未来研究的方向。


<details>
  <summary>Details</summary>
Motivation: 深度时间模型（如 TCN）的泛化理论理解仍然有限。我们通过为深度时间模型提供第一个非空泛、感知架构的泛化界限以及一个原则性的评估方法来解决这个差距。

Method: 我们使用延迟反馈阻塞机制将相关的样本转换为有效的独立样本，同时只丢弃 $O(1/	ext{log } N)$ 的数据，从而获得 $	ext{log } N$ 的缩放而不是指数级的缩放。我们还引入了一种公平比较方法，将有效样本量固定为 2,000，以隔离时间结构对信息内容的影响。

Result: 我们推导出了规模为 $O(R 	ext{sqrt}(rac{Dn 	ext{log } N}{N}))$ 的界限。强相关序列（$ho=0.8$）的比弱相关序列（$ho=0.2$）的泛化差距小约 76%。然而，收敛速度与理论预测的 $N^{-0.5}$ 不同，弱相关序列遵循 $N_{	ext{eff}}^{-1.21}$ 的缩放，强相关序列遵循 $N_{	ext{eff}}^{-0.89}$ 的缩放。

Conclusion: 理论和实践之间的差距表明需要未来的研究，时间依赖性可以在固定的信息预算下增强学习。

Abstract: Deep temporal architectures such as Temporal Convolutional Networks (TCNs)
achieve strong predictive performance on sequential data, yet theoretical
understanding of their generalization remains limited. We address this gap by
providing both the first non-vacuous, architecture-aware generalization bounds
for deep temporal models and a principled evaluation methodology.
  For exponentially $\beta$-mixing sequences, we derive bounds scaling as $
O\!\Bigl(R\,\sqrt{\tfrac{D\,p\,n\,\log N}{N}}\Bigr), $ where $D$ is network
depth, $p$ kernel size, $n$ input dimension, and $R$ weight norm. Our
delayed-feedback blocking mechanism transforms dependent samples into
effectively independent ones while discarding only $O(1/\log N)$ of the data,
yielding $\sqrt{D}$ scaling instead of exponential, implying that doubling
depth requires approximately quadrupling the training data.
  We also introduce a fair-comparison methodology that fixes the effective
sample size to isolate the effect of temporal structure from information
content. Under $N_{\text{eff}}=2{,}000$, strongly dependent sequences
($\rho=0.8$) exhibit $\approx76\%$ smaller generalization gaps than weakly
dependent ones ($\rho=0.2$), challenging the intuition that dependence is
purely detrimental. Yet convergence rates diverge from theory: weak
dependencies follow $N_{\text{eff}}^{-1.21}$ scaling and strong dependencies
follow $N_{\text{eff}}^{-0.89}$, both steeper than the predicted $N^{-0.5}$.
These findings reveal that temporal dependence can enhance learning under fixed
information budgets, while highlighting gaps between theory and practice that
motivate future research.

</details>


### [205] [Recurrent Deep Differentiable Logic Gate Networks](https://arxiv.org/abs/2508.06097)
*Simon Bührer,Andreas Plesner,Till Aczel,Roger Wattenhofer*

Main category: cs.LG

TL;DR: RDDLGN将可微逻辑门与循环网络相结合，在序列到序列学习中取得了有前景的结果，并为未来研究开辟了道路。


<details>
  <summary>Details</summary>
Motivation: 解决了可微逻辑门在顺序建模中的应用空白，探索将布尔运算与循环神经网络结合的可能性。

Method: 提出了一种名为循环深度可微逻辑门网络（RDDLGN）的新型网络，将布尔运算与循环架构相结合，用于序列到序列学习。

Result: RDDLGN在WMT'14英德翻译任务上达到了5.00 BLEU和30.9%的训练准确率，在推理时接近GRU的性能（5.41 BLEU）和优雅降级（4.39 BLEU）。

Conclusion: 该工作将可微逻辑门应用于循环神经网络，为序列建模开辟了新的研究方向，并为FPGA加速等递归网络架构提供了可能性。

Abstract: While differentiable logic gates have shown promise in feedforward networks,
their application to sequential modeling remains unexplored. This paper
presents the first implementation of Recurrent Deep Differentiable Logic Gate
Networks (RDDLGN), combining Boolean operations with recurrent architectures
for sequence-to-sequence learning.
  Evaluated on WMT'14 English-German translation, RDDLGN achieves 5.00 BLEU and
30.9\% accuracy during training, approaching GRU performance (5.41 BLEU) and
graceful degradation (4.39 BLEU) during inference. This work establishes
recurrent logic-based neural computation as viable, opening research directions
for FPGA acceleration in sequential modeling and other recursive network
architectures.

</details>


### [206] [GCHR : Goal-Conditioned Hindsight Regularization for Sample-Efficient Reinforcement Learning](https://arxiv.org/abs/2508.06108)
*Xing Lei,Wenyan Yang,Kaiqiang Ke,Shentao Yang,Xuetao Zhang,Joni Pajarinen,Donglin Wang*

Main category: cs.LG

TL;DR: Hindsight Goal-conditioned Regularization (HGR) and hindsight self-imitation regularization (HSR) improve sample efficiency in goal-conditioned reinforcement learning by generating action regularization priors based on hindsight goals, outperforming existing methods in navigation and manipulation tasks.


<details>
  <summary>Details</summary>
Motivation: Hindsight experience replay (HER) alone does not fully exploit the available experiences in off-policy GCRL methods, resulting in limited sample efficiency.

Method: Hindsight Goal-conditioned Regularization (HGR) generates action regularization priors based on hindsight goals. When combined with hindsight self-imitation regularization (HSR), our approach enables off-policy RL algorithms to maximize experience utilization.

Result: Our hindsight regularizations achieve substantially more efficient sample reuse and the best performances on a suite of navigation and manipulation tasks.

Conclusion: Hindsight regularizations achieve substantially more efficient sample reuse and the best performances, which we empirically demonstrate on a suite of navigation and manipulation tasks.

Abstract: Goal-conditioned reinforcement learning (GCRL) with sparse rewards remains a
fundamental challenge in reinforcement learning. While hindsight experience
replay (HER) has shown promise by relabeling collected trajectories with
achieved goals, we argue that trajectory relabeling alone does not fully
exploit the available experiences in off-policy GCRL methods, resulting in
limited sample efficiency. In this paper, we propose Hindsight Goal-conditioned
Regularization (HGR), a technique that generates action regularization priors
based on hindsight goals. When combined with hindsight self-imitation
regularization (HSR), our approach enables off-policy RL algorithms to maximize
experience utilization. Compared to existing GCRL methods that employ HER and
self-imitation techniques, our hindsight regularizations achieve substantially
more efficient sample reuse and the best performances, which we empirically
demonstrate on a suite of navigation and manipulation tasks.

</details>


### [207] [Improving Diagnostic Accuracy for Oral Cancer with inpainting Synthesis Lesions Generated Using Diffusion Models](https://arxiv.org/abs/2508.06151)
*Yong Oh Lee,JeeEun Kim,Jung Woo Lee*

Main category: cs.LG

TL;DR: 使用经过微调的扩散模型的修复技术合成了逼真的口腔癌病变，显著提高了诊断算法的性能。


<details>
  <summary>Details</summary>
Motivation: 口腔癌诊断中，标注数据的有限性，特别是由于训练数据的可变性和不充分性，经常限制诊断模型的性能。

Method: 本研究提出了一种新颖的方法，通过使用经过微调的扩散模型的修复技术来合成逼真的口腔癌病变，以提高诊断准确性。

Result: 结果显示，我们的分类模型在区分癌性和非癌性组织方面取得了0.97的诊断准确率，而我们的检测模型则以0.85的准确率准确识别了病变位置。

Conclusion: 该方法验证了合成图像生成在医学诊断中的潜力，并为将这些方法扩展到其他癌症诊断铺平了道路。

Abstract: In oral cancer diagnostics, the limited availability of annotated datasets
frequently constrains the performance of diagnostic models, particularly due to
the variability and insufficiency of training data. To address these
challenges, this study proposed a novel approach to enhance diagnostic accuracy
by synthesizing realistic oral cancer lesions using an inpainting technique
with a fine-tuned diffusion model. We compiled a comprehensive dataset from
multiple sources, featuring a variety of oral cancer images. Our method
generated synthetic lesions that exhibit a high degree of visual fidelity to
actual lesions, thereby significantly enhancing the performance of diagnostic
algorithms. The results show that our classification model achieved a
diagnostic accuracy of 0.97 in differentiating between cancerous and
non-cancerous tissues, while our detection model accurately identified lesion
locations with 0.85 accuracy. This method validates the potential for synthetic
image generation in medical diagnostics and paves the way for further research
into extending these methods to other types of cancer diagnostics.

</details>


### [208] [Differentially Private Federated Clustering with Random Rebalancing](https://arxiv.org/abs/2508.06183)
*Xiyuan Yang,Shengyuan Hu,Soyeon Kim,Tian Li*

Main category: cs.LG

TL;DR: RR-Cluster 是一种用于联邦聚类的技术，通过随机重新平衡聚类分配来减少隐私噪声，从而提高隐私/效用权衡。


<details>
  <summary>Details</summary>
Motivation: 联邦聚类旨在对相似客户进行分组，但可能更容易受到隐私泄露的影响。直接将客户端级别的差分隐私（DP）机制应用于联邦聚类可能会显著降低效用，因为在聚类中的客户数量不受控制，导致隐私噪声难以平均。

Method: RR-Cluster 通过随机重新平衡聚类分配来保证每个聚类的最小客户数量，从而实现降低隐私噪声。

Result: RR-Cluster 能够显著改善跨合成和真实世界数据集的隐私/效用权衡。

Conclusion: RR-Cluster 是一种简单有效的技术，作为许多联邦聚类算法的轻量级附加组件，通过随机重新平衡聚类分配来减少隐私噪声，保证每个聚类的最小客户数量。该技术在隐私/效用权衡方面表现出显著改进。

Abstract: Federated clustering aims to group similar clients into clusters and produce
one model for each cluster. Such a personalization approach typically improves
model performance compared with training a single model to serve all clients,
but can be more vulnerable to privacy leakage. Directly applying client-level
differentially private (DP) mechanisms to federated clustering could degrade
the utilities significantly. We identify that such deficiencies are mainly due
to the difficulties of averaging privacy noise within each cluster (following
standard privacy mechanisms), as the number of clients assigned to the same
clusters is uncontrolled. To this end, we propose a simple and effective
technique, named RR-Cluster, that can be viewed as a light-weight add-on to
many federated clustering algorithms. RR-Cluster achieves reduced privacy noise
via randomly rebalancing cluster assignments, guaranteeing a minimum number of
clients assigned to each cluster. We analyze the tradeoffs between decreased
privacy noise variance and potentially increased bias from incorrect
assignments and provide convergence bounds for RR-Clsuter. Empirically, we
demonstrate the RR-Cluster plugged into strong federated clustering algorithms
results in significantly improved privacy/utility tradeoffs across both
synthetic and real-world datasets.

</details>


### [209] [Benchmarking Pretrained Molecular Embedding Models For Molecular Representation Learning](https://arxiv.org/abs/2508.06199)
*Mateusz Praski,Jakub Adamczyk,Wojciech Czech*

Main category: cs.LG

TL;DR: 神经网络在分子化学任务上的表现普遍不如预期，CLAMP模型是唯一的例外，这表明现有研究的评估方法可能存在问题。


<details>
  <summary>Details</summary>
Motivation: 为了应对预训练神经网络在化学和药物设计领域的广泛应用，本研究旨在提供一个最全面的模型比较，以评估它们在分子化学中的实际效用。

Method: 本研究在一个公平的比较框架下，使用分层贝叶斯统计检验模型，对25个不同模态、架构和预训练策略的神经网络模型在25个数据集上的表现进行了广泛的评估。

Result: 在本次广泛的比较中，除了基于分子指纹的CLAMP模型外，几乎所有其他的神经网络模型在分子属性预测、虚拟筛选和分子化学小数据学习任务上的表现与基线ECFP分子指纹相比，都没有统计学上的显著改进。

Conclusion: 大多数预训练神经网络在分子化学任务上表现不佳，仅有基于分子指纹的CLAMP模型显示出统计学上的显著优势，这引发了对现有研究评估严谨性的担忧。

Abstract: Pretrained neural networks have attracted significant interest in chemistry
and small molecule drug design. Embeddings from these models are widely used
for molecular property prediction, virtual screening, and small data learning
in molecular chemistry. This study presents the most extensive comparison of
such models to date, evaluating 25 models across 25 datasets. Under a fair
comparison framework, we assess models spanning various modalities,
architectures, and pretraining strategies. Using a dedicated hierarchical
Bayesian statistical testing model, we arrive at a surprising result: nearly
all neural models show negligible or no improvement over the baseline ECFP
molecular fingerprint. Only the CLAMP model, which is also based on molecular
fingerprints, performs statistically significantly better than the
alternatives. These findings raise concerns about the evaluation rigor in
existing studies. We discuss potential causes, propose solutions, and offer
practical recommendations.

</details>


### [210] [Graph Federated Learning for Personalized Privacy Recommendation](https://arxiv.org/abs/2508.06208)
*Ce Na,Kai Yang,Dengzhao Fang,Yu Li,Jingtong Gao,Chengcheng Zhu,Jiale Zhang,Xiaobing Sun,Yi Chang*

Main category: cs.LG

TL;DR: GFed-PP 是一种新颖的图联邦学习框架，可根据用户隐私偏好进行调整，并利用公开的用户数据来提高推荐准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦推荐系统（FedRecs）假设所有用户都有相同的隐私保护要求，这忽略了利用公开的用户数据来增强推荐服务的潜力。在现实应用中，用户可以选择公开或私有。GFed-PP 旨在适应不同的隐私要求，同时提高推荐性能。

Method: GFed-PP 包含用户交互数据以构建用户-物品交互图，然后用于构建用户关系图。采用轻量级图卷积网络（GCN）来学习每个用户的用户特定个性化物品嵌入。为了保护用户隐私，每个客户端在本地学习用户嵌入和评分函数。此外，GFed-PP 通过在客户端初始化物品嵌入以及在服务器端聚合用户关系图来实现联邦推荐框架的优化。

Result: 实验结果表明，GFed-PP 在五个数据集上显著优于现有方法，在不损害隐私的情况下提供了卓越的推荐准确性。

Conclusion: GFed-PP 框架为适应联邦推荐系统中不同的隐私偏好提供了一个实用的解决方案，并且在不损害隐私的情况下提供了卓越的推荐准确性。

Abstract: Federated recommendation systems (FedRecs) have gained significant attention
for providing privacy-preserving recommendation services. However, existing
FedRecs assume that all users have the same requirements for privacy
protection, i.e., they do not upload any data to the server. The approaches
overlook the potential to enhance the recommendation service by utilizing
publicly available user data. In real-world applications, users can choose to
be private or public. Private users' interaction data is not shared, while
public users' interaction data can be shared. Inspired by the issue, this paper
proposes a novel Graph Federated Learning for Personalized Privacy
Recommendation (GFed-PP) that adapts to different privacy requirements while
improving recommendation performance. GFed-PP incorporates the interaction data
of public users to build a user-item interaction graph, which is then used to
form a user relationship graph. A lightweight graph convolutional network (GCN)
is employed to learn each user's user-specific personalized item embedding. To
protect user privacy, each client learns the user embedding and the scoring
function locally. Additionally, GFed-PP achieves optimization of the federated
recommendation framework through the initialization of item embedding on
clients and the aggregation of the user relationship graph on the server.
Experimental results demonstrate that GFed-PP significantly outperforms
existing methods for five datasets, offering superior recommendation accuracy
without compromising privacy. This framework provides a practical solution for
accommodating varying privacy preferences in federated recommendation systems.

</details>


### [211] [Reparameterization Proximal Policy Optimization](https://arxiv.org/abs/2508.06214)
*Hai Zhong,Xun Wang,Zhuoran Li,Longbo Huang*

Main category: cs.LG

TL;DR: RPO, inspired by PPO, stabilizes RPG training by using a clipped surrogate objective and KL divergence regularization, leading to better sample efficiency and performance.


<details>
  <summary>Details</summary>
Motivation: To address the training instability and high-variance gradients in Reparameterization Policy Gradient (RPG) methods.

Method: Reparameterization Proximal Policy Optimization (RPO), which optimizes a clipped surrogate objective tailored for RPG, stabilized by KL divergence regularization and compatible with variance reduction methods.

Result: RPO enables multiple epochs of stable sample reuse, achieving superior sample efficiency and strong performance.

Conclusion: RPO achieves superior sample efficiency and strong performance on locomotion and manipulation tasks.

Abstract: Reparameterization policy gradient (RPG) is promising for improving sample
efficiency by leveraging differentiable dynamics. However, a critical barrier
is its training instability, where high-variance gradients can destabilize the
learning process. To address this, we draw inspiration from Proximal Policy
Optimization (PPO), which uses a surrogate objective to enable stable sample
reuse in the model-free setting. We first establish a connection between this
surrogate objective and RPG, which has been largely unexplored and is
non-trivial. Then, we bridge this gap by demonstrating that the
reparameterization gradient of a PPO-like surrogate objective can be computed
efficiently using backpropagation through time. Based on this key insight, we
propose Reparameterization Proximal Policy Optimization (RPO), a stable and
sample-efficient RPG-based method. RPO enables multiple epochs of stable sample
reuse by optimizing a clipped surrogate objective tailored for RPG, while being
further stabilized by Kullback-Leibler (KL) divergence regularization and
remaining fully compatible with existing variance reduction methods. We
evaluate RPO on a suite of challenging locomotion and manipulation tasks, where
experiments demonstrate that our method achieves superior sample efficiency and
strong performance.

</details>


### [212] [Epidemic Control on a Large-Scale-Agent-Based Epidemiology Model using Deep Deterministic Policy Gradient](https://arxiv.org/abs/2304.04475)
*Gaurav Deshkar,Jayanta Kshirsagar,Harshal Hayatnagarkar,Janani Venugopalan*

Main category: cs.LG

TL;DR: This paper presents a DDPG-based framework for optimizing pandemic interventions like lockdowns and vaccinations in large-scale simulations. It found a balance between economic and health outcomes in a test scenario, but calls for more research.


<details>
  <summary>Details</summary>
Motivation: Current research for modeling and optimizing interventions during pandemics is limited by simulation objectives, scale, model suitability, and the range of strategies that can be explored. The study aims to address these challenges by developing a more robust framework for automated optimal intervention determination.

Method: The study utilizes a Deep Deterministic Policy Gradient (DDPG) based policy optimization framework integrated with a large-scale (100,000 individuals) agent-based epidemiological simulation. This approach allows for multi-objective optimization to determine optimal intervention strategies, specifically focusing on lockdown and vaccination policies within a minimalist, age-stratified, multi-vaccine scenario that includes basic economic activity simulation.

Result: The simulation, with no lockdown and vaccination applied to mid-age and elderly populations, indicated that the optimal policy resulted in a balanced economy (measured by individuals below the poverty line) alongside balanced health objectives (infection and hospitalization rates).

Conclusion: The study proposes a Deep Deterministic Policy Gradient (DDPG) based policy optimization framework for large-scale epidemiological agent-based simulations to determine optimal interventions like lockdowns and vaccinations. The framework addresses limitations of current research by handling large scales, diverse model types, and exploring a wider range of intervention strategies through multi-objective optimization. The results suggest an optimal economy with balanced health objectives in a minimalist scenario, but further in-depth simulation is needed for validation.

Abstract: To mitigate the impact of the pandemic, several measures include lockdowns,
rapid vaccination programs, school closures, and economic stimulus. These
interventions can have positive or unintended negative consequences. Current
research to model and determine an optimal intervention automatically through
round-tripping is limited by the simulation objectives, scale (a few thousand
individuals), model types that are not suited for intervention studies, and the
number of intervention strategies they can explore (discrete vs continuous). We
address these challenges using a Deep Deterministic Policy Gradient (DDPG)
based policy optimization framework on a large-scale (100,000 individual)
epidemiological agent-based simulation where we perform multi-objective
optimization. We determine the optimal policy for lockdown and vaccination in a
minimalist age-stratified multi-vaccine scenario with a basic simulation for
economic activity. With no lockdown and vaccination (mid-age and elderly),
results show optimal economy (individuals below the poverty line) with balanced
health objectives (infection, and hospitalization). An in-depth simulation is
needed to further validate our results and open-source our framework.

</details>


### [213] [Membership Inference Attack with Partial Features](https://arxiv.org/abs/2508.06244)
*Xurun Wang,Guangrui Liu,Xinjie Li,Haoyu He,Lin Yao,Weizhe Zhang*

Main category: cs.LG

TL;DR: MRAD是一种针对部分特征信息可用的成员推断攻击方法，通过重建和异常检测来识别训练数据中的样本。


<details>
  <summary>Details</summary>
Motivation: 现有的成员推断方法通常假设对手可以完全访问目标样本的特征，但在现实场景中，通常只能获得部分特征信息，这限制了这些方法的可行性。本研究旨在解决部分特征信息可用时的成员推断问题。

Method: MRAD是一个两阶段攻击框架：第一阶段通过优化未知特征值来最小化样本损失；第二阶段利用异常检测测量重建样本与训练分布的偏差。

Result: MRAD在多种数据集上均表现出有效性，即使在缺失40%的特征时，在STL-10上的攻击AUC也能达到约0.6。此外，MRAD与多种现成的异常检测技术兼容。

Conclusion: MRAD在STL-10等数据集上进行了有效性验证，即使在缺失40%特征的情况下，仍能达到约0.6的AUC，并且可以兼容多种异常检测技术。

Abstract: Machine learning models have been shown to be susceptible to membership
inference attack, which can be used to determine whether a given sample appears
in the training data. Existing membership inference methods commonly assume
that the adversary has full access to the features of the target sample. This
assumption, however, does not hold in many real-world scenarios where only
partial features information is available, thereby limiting the applicability
of these methods. In this work, we study an inference scenario where the
adversary observes only partial features of each sample and aims to infer
whether this observed subset was present in the training set of the target
model. We define this problem as Partial Feature Membership Inference (PFMI).
To address this problem, we propose MRAD (Memory-guided Reconstruction and
Anomaly Detection), a two-stage attack framework. In the first stage, MRAD
optimizes the unknown feature values to minimize the loss of the sample. In the
second stage, it measures the deviation between the reconstructed sample and
the training distribution using anomaly detection. Empirical results
demonstrate that MRAD is effective across a range of datasets, and maintains
compatibility with various off-the-shelf anomaly detection techniques. For
example, on STL-10, our attack achieves an AUC of around 0.6 even with 40% of
the missing features.

</details>


### [214] [In-Training Defenses against Emergent Misalignment in Language Models](https://arxiv.org/abs/2508.06249)
*David Kaczér,Magnus Jørgenvåg,Clemens Vetter,Lucie Flek,Florian Mai*

Main category: cs.LG

TL;DR: 微调 LLM 可能导致其在目标领域外出现有害行为（EMA）。本研究提出了四种训练方法（KL 散度、L2 距离、SafeLoRA、数据交错）来解决这个问题，并评估了它们在恶意和良性任务上的效果。


<details>
  <summary>Details</summary>
Motivation: 现有研究发现，即使对大型语言模型（LLM）进行少量领域特定的微调，也可能导致模型在目标领域之外出现有害行为（称为“涌现性不匹配”，EMA）。即使模型权重受到 API 保护，攻击者也可能通过微调 API 获得一个广泛不匹配的模型，且这种情况难以仅从微调数据中检测出来。因此，需要研究在训练过程中就能防止 EMA 的安全防护措施，特别是对于通过 API 提供微调服务的提供商而言。

Method: 本研究提出了四种训练正则化干预方法来解决 LLM 微调中的涌现性不匹配（EMA）问题：(i) KL-散度正则化（使模型接近安全的参考模型），(ii) 特征空间 $\ell_2$ 距离（限制模型在特征空间中的变化），(iii) 安全子空间投影（SafeLoRA）（将模型权重投影到预定义的“安全”子空间），以及 (iv) 交错少量安全通用指令微调数据。研究人员在四个恶意任务和良性任务上评估了这些方法的有效性。

Result: 研究评估了四种方法在四个恶意 EMA 诱导任务上的有效性，以及它们对良性任务性能的影响。具体评估结果和比较未在摘要中详细说明，但研究旨在找出能够有效缓解 EMA 问题同时不损害模型良性任务表现的训练干预措施。

Conclusion: 本研究首次系统地研究了针对 LLM 领域特定微调中出现的“涌现性不匹配”（EMA）问题的训练中安全防护措施，并提出了四种正则化干预方法：(i) KL 散度正则化、(ii) 特征空间 $\ell_2$ 距离、(iii) 安全子空间投影（SafeLoRA）、(iv) 少量通用指令微调数据交错。研究评估了这些方法在四个恶意 EMA 诱导任务上的表现，以及对良性任务的影响，并讨论了 EMA 研究的开放性问题。

Abstract: Fine-tuning lets practitioners repurpose aligned large language models (LLMs)
for new domains, yet recent work reveals emergent misalignment (EMA): Even a
small, domain-specific fine-tune can induce harmful behaviors far outside the
target domain. Even in the case where model weights are hidden behind a
fine-tuning API, this gives attackers inadvertent access to a broadly
misaligned model in a way that can be hard to detect from the fine-tuning data
alone. We present the first systematic study of in-training safeguards against
EMA that are practical for providers who expose fine-tuning via an API. We
investigate four training regularization interventions: (i) KL-divergence
regularization toward a safe reference model, (ii) $\ell_2$ distance in feature
space, (iii) projecting onto a safe subspace (SafeLoRA), and (iv) interleaving
of a small amount of safe training examples from a general instruct-tuning
dataset. We first evaluate the methods' emergent misalignment effect across
four malicious, EMA-inducing tasks. Second, we assess the methods' impacts on
benign tasks. We conclude with a discussion of open questions in emergent
misalignment research.

</details>


### [215] [Synthetic Data Generation and Differential Privacy using Tensor Networks' Matrix Product States (MPS)](https://arxiv.org/abs/2508.06251)
*Alejandro Moreno R.,Desale Fentaw,Samuel Palmer,Raúl Salles de Padua,Ninad Dixit,Samuel Mugel,Roman Orús,Manuel Radons,Josef Menter,Ali Abedi*

Main category: cs.LG

TL;DR: 提出了一种使用张量网络（MPS）生成隐私保护的高质量合成表格数据的方法，并在数据保真度和下游任务性能方面优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 解决现代人工智能中数据稀缺、隐私限制以及训练鲁棒模型所需多样化数据集的问题。

Method: 使用张量网络（特别是矩阵积状态MPS）生成隐私保护的高质量合成表格数据，并通过注入噪声和梯度裁剪来实现差分隐私（DP），利用Rényi差分隐私（RDP）进行核算。

Result: MPS模型在数据保真度和下游机器学习任务性能方面优于CTGAN、VAE和PrivBayes等现有模型，尤其是在严格的隐私限制下。

Conclusion: MPS在隐私感知合成数据生成方面显示出潜力，提供了一种可解释且可扩展的解决方案，适用于对数据质量和保密性都有要求的敏感领域。

Abstract: Synthetic data generation is a key technique in modern artificial
intelligence, addressing data scarcity, privacy constraints, and the need for
diverse datasets in training robust models. In this work, we propose a method
for generating privacy-preserving high-quality synthetic tabular data using
Tensor Networks, specifically Matrix Product States (MPS). We benchmark the
MPS-based generative model against state-of-the-art models such as CTGAN, VAE,
and PrivBayes, focusing on both fidelity and privacy-preserving capabilities.
To ensure differential privacy (DP), we integrate noise injection and gradient
clipping during training, enabling privacy guarantees via R\'enyi Differential
Privacy accounting. Across multiple metrics analyzing data fidelity and
downstream machine learning task performance, our results show that MPS
outperforms classical models, particularly under strict privacy constraints.
This work highlights MPS as a promising tool for privacy-aware synthetic data
generation. By combining the expressive power of tensor network representations
with formal privacy mechanisms, the proposed approach offers an interpretable
and scalable alternative for secure data sharing. Its structured design
facilitates integration into sensitive domains where both data quality and
confidentiality are critical.

</details>


### [216] [Multi-Omics Analysis for Cancer Subtype Inference via Unrolling Graph Smoothness Priors](https://arxiv.org/abs/2508.06257)
*Jielong Lu,Zhihao Wu,Jiajun Yu,Jiajun Bu,Haishuai Wang*

Main category: cs.LG

TL;DR: GTMancer是一个新的多组学整合框架，利用图神经网络和对比学习来提高癌症亚型分类的准确性，并在实验中超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的多组学整合方法常常忽视异构组学之间复杂的耦合关系，限制了它们解析对精确肿瘤学至关重要的细微癌症亚型异质性的能力。

Method: 提出了一种名为GTMancer（Graph Transformer for Multi-omics Cancer Subtype Classification）的框架，该框架基于GNN优化问题，并将其应用扩展到复杂的多组学数据。具体来说，该方法利用对比学习将多组学数据嵌入到统一的语义空间中，并在该统一空间中展开多重图优化问题，引入两组注意力系数来捕捉组学数据内部和之间结构图的先验信息，从而实现全局组学信息对单个组学表示的细化。

Result: GTMancer在七个真实癌症数据集上的实验结果优于现有的最先进算法。

Conclusion: GTMancer框架在七个真实癌症数据集上的实证实验表明，其性能优于现有的最先进算法。

Abstract: Integrating multi-omics datasets through data-driven analysis offers a
comprehensive understanding of the complex biological processes underlying
various diseases, particularly cancer. Graph Neural Networks (GNNs) have
recently demonstrated remarkable ability to exploit relational structures in
biological data, enabling advances in multi-omics integration for cancer
subtype classification. Existing approaches often neglect the intricate
coupling between heterogeneous omics, limiting their capacity to resolve subtle
cancer subtype heterogeneity critical for precision oncology. To address these
limitations, we propose a framework named Graph Transformer for Multi-omics
Cancer Subtype Classification (GTMancer). This framework builds upon the GNN
optimization problem and extends its application to complex multi-omics data.
Specifically, our method leverages contrastive learning to embed multi-omics
data into a unified semantic space. We unroll the multiplex graph optimization
problem in that unified space and introduce dual sets of attention coefficients
to capture structural graph priors both within and among multi-omics data. This
approach enables global omics information to guide the refining of the
representations of individual omics. Empirical experiments on seven real-world
cancer datasets demonstrate that GTMancer outperforms existing state-of-the-art
algorithms.

</details>


### [217] [OM2P: Offline Multi-Agent Mean-Flow Policy](https://arxiv.org/abs/2508.06269)
*Zhuoran Li,Xun Wang,Hai Zhong,Longbo Huang*

Main category: cs.LG

TL;DR: OM2P 是一种新颖的离线 MARL 算法，通过高效的一步动作采样和奖励感知优化，解决了生成策略的采样效率问题，在多智能体粒子和 MuJoCo 基准测试中表现优越。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有扩散和基于流的策略在离线多智能体强化学习中采样效率低，难以在时间敏感或资源受限设置中应用的问题。

Method: OM2P（Offline Multi-Agent Mean-Flow Policy）算法，通过引入奖励感知优化方案，并结合精心设计的均流匹配损失和 Q 函数监督，以及设计广义时间步分布和无导数估计策略，实现了高效的一步动作采样，从而解决了扩散和基于流的策略在时间敏感或资源受限设置中的采样效率低的问题。

Result: OM2P 在多智能体粒子和 MuJoCo 基准测试中取得了优越的性能，GPU 内存使用量减少了 3.8 倍，训练时间缩短了 10.8 倍。

Conclusion: OM2P 成功地将均流模型集成到离线 MARL 中，为合作多智能体设置中实用且可扩展的生成策略铺平了道路。

Abstract: Generative models, especially diffusion and flow-based models, have been
promising in offline multi-agent reinforcement learning. However, integrating
powerful generative models into this framework poses unique challenges. In
particular, diffusion and flow-based policies suffer from low sampling
efficiency due to their iterative generation processes, making them impractical
in time-sensitive or resource-constrained settings. To tackle these
difficulties, we propose OM2P (Offline Multi-Agent Mean-Flow Policy), a novel
offline MARL algorithm to achieve efficient one-step action sampling. To
address the misalignment between generative objectives and reward maximization,
we introduce a reward-aware optimization scheme that integrates a
carefully-designed mean-flow matching loss with Q-function supervision.
Additionally, we design a generalized timestep distribution and a
derivative-free estimation strategy to reduce memory overhead and improve
training stability. Empirical evaluations on Multi-Agent Particle and MuJoCo
benchmarks demonstrate that OM2P achieves superior performance, with up to a
3.8x reduction in GPU memory usage and up to a 10.8x speed-up in training time.
Our approach represents the first to successfully integrate mean-flow model
into offline MARL, paving the way for practical and scalable generative
policies in cooperative multi-agent settings.

</details>


### [218] [A Study on Regularization-Based Continual Learning Methods for Indic ASR](https://arxiv.org/abs/2508.06280)
*Gokul Adethya T,S. Jaya Nirmala*

Main category: cs.LG

TL;DR: 印度语言的ASR面临挑战，因为数据是按顺序到达的，并且有隐私限制。本研究使用持续学习（CL）和三种策略（EWC、MAS、LwF）来解决这些问题，并取得了良好的效果。


<details>
  <summary>Details</summary>
Motivation: 印度的语言多样性给开发包容性自动语音识别（ASR）系统带来了重大挑战。传统的多语言模型需要同时访问所有语言数据，由于数据的顺序到达和隐私限制，这是不切实际的。CL提供了一种解决方案，使模型能够按顺序学习新语言，而不会灾难性地遗忘先前学习的知识。

Method: 采用基于Conformer的混合RNN-T/CTC模型，首先在印地语上进行预训练，然后逐步在另外八种印度语言上进行增量训练。评估了三种主要的基于正则化和蒸馏的CL策略：弹性权重巩固（EWC）、记忆感知突触（MAS）和无遗忘学习（LwF）。

Result: 与简单的微调相比，CL在减轻遗忘方面是有效的，并且在干净和嘈杂的数据上使用RNN-T和CTC路径以及通过向后迁移进行知识保留方面都表现良好。探索了不同训练周期数（1、2、5和10）的影响。

Conclusion: 持续学习（CL）在缓解遗忘方面是有效的，使其成为在现实约束条件下可扩展的印度多种语言ASR的有前途的方法。

Abstract: Indias linguistic diversity poses significant challenges for developing
inclusive Automatic Speech Recognition (ASR) systems. Traditional multilingual
models, which require simultaneous access to all language data, are impractical
due to the sequential arrival of data and privacy constraints. Continual
Learning (CL) offers a solution by enabling models to learn new languages
sequentially without catastrophically forgetting previously learned knowledge.
This paper investigates CL for ASR on Indian languages using a subset of the
IndicSUPERB benchmark. We employ a Conformer-based hybrid RNN-T/CTC model,
initially pretrained on Hindi, which is then incrementally trained on eight
additional Indian languages, for a total sequence of nine languages. We
evaluate three prominent regularization- and distillation-based CL strategies:
Elastic Weight Consolidation (EWC), Memory Aware Synapses (MAS), and Learning
without Forgetting (LwF), selected for their suitability in no-replay,
privacy-conscious scenarios. Performance is analyzed using Word Error Rate
(WER) for both RNN-T and CTC paths on clean and noisy data, as well as
knowledge retention via Backward Transfer. We also explore the impact of
varying the number of training epochs (1, 2, 5, and 10) per task. Results,
compared against naive fine-tuning, demonstrate CLs effectiveness in mitigating
forgetting, making it a promising approach for scalable ASR in diverse Indian
languages under realistic constraints. The code is available at:
https://github.com/FrozenWolf-Cyber/Indic-CL-ASR

</details>


### [219] [Low-Bit Data Processing Using Multiple-Output Spiking Neurons with Non-linear Reset Feedback](https://arxiv.org/abs/2508.06292)
*Sanja Karilanova,Subhrakanti Dey,Ayça Özçelikkale*

Main category: cs.LG

TL;DR: 提出了一种新的脉冲神经元模型，结合了SSM和SNN的优点，在各种任务上实现了与现有基准相当的性能。


<details>
  <summary>Details</summary>
Motivation: 为了结合SNN的优势和近期深度SSM模型的优势，研究了SNN和深度SSM模型。

Method: 提出了一种新颖的多输出脉冲神经元模型，结合了线性的、一般的SSM状态转移和通过重置产生的非线性反馈机制。

Result: 实验结果表明，该模型在关键字识别、事件视觉和序列模式识别任务上取得了与现有SNN文献基准相当的性能。

Conclusion: 与现有的SNN基准相比，该模型在各项任务上实现了可比的性能。此外，所提出的重置机制克服了不稳定性，并在线性部分不稳定时也能够实现学习，从而超越了近期深度SSM模型中严格执行的线性动力学稳定性。

Abstract: Neuromorphic computing is an emerging technology enabling low-latency and
energy-efficient signal processing. A key algorithmic tool in neuromorphic
computing is spiking neural networks (SNNs). SNNs are biologically inspired
neural networks which utilize stateful neurons, and provide low-bit data
processing by encoding and decoding information using spikes. Similar to SNNs,
deep state-space models (SSMs) utilize stateful building blocks. However, deep
SSMs, which recently achieved competitive performance in various temporal
modeling tasks, are typically designed with high-precision activation functions
and no reset mechanisms. To bridge the gains offered by SNNs and the recent
deep SSM models, we propose a novel multiple-output spiking neuron model that
combines a linear, general SSM state transition with a non-linear feedback
mechanism through reset. Compared to the existing neuron models for SNNs, our
proposed model clearly conceptualizes the differences between the spiking
function, the reset condition and the reset action. The experimental results on
various tasks, i.e., a keyword spotting task, an event-based vision task and a
sequential pattern recognition task, show that our proposed model achieves
performance comparable to existing benchmarks in the SNN literature. Our
results illustrate how the proposed reset mechanism can overcome instability
and enable learning even when the linear part of neuron dynamics is unstable,
allowing us to go beyond the strictly enforced stability of linear dynamics in
recent deep SSM models.

</details>


### [220] [Introducing Fractional Classification Loss for Robust Learning with Noisy Labels](https://arxiv.org/abs/2508.06346)
*Mert Can Kurucu,Tufan Kumbasar,İbrahim Eksin,Müjde Güzelkaya*

Main category: cs.LG

TL;DR: FCL是一种新的自适应鲁棒损失函数，它通过自动调整其分数阶导数阶数μ，在鲁棒性和收敛速度之间取得平衡，从而在有标签噪声的情况下实现了最先进的分类性能，并且无需手动调整超参数。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有鲁棒损失函数需要针对特定数据集进行大量超参数调整的问题，本文提出了一种新的自适应鲁棒损失函数FCL。

Method: FCL采用分数阶交叉熵（CE）损失作为其激活组件，并使用平均绝对误差（MAE）作为其被动损失组件。通过将分数阶导数阶数μ集成到基于梯度的优化中，并将其设为可学习参数，FCL能够自动调整其鲁棒性和收敛速度之间的权衡。

Result: FCL能够动态地重塑其损失边界，从而在标签噪声下实现有效的分类性能。实验表明，FCL在不进行手动超参数调整的情况下，在基准数据集上取得了最先进的成果。

Conclusion: FCL（Fractional Classification Loss）是一种自适应鲁棒损失函数，可以在训练过程中自动校准其对标签噪声的鲁棒性，并在没有手动调整超参数的情况下，在基准数据集上实现了最先进的结果。

Abstract: Robust loss functions are crucial for training deep neural networks in the
presence of label noise, yet existing approaches require extensive,
dataset-specific hyperparameter tuning. In this work, we introduce Fractional
Classification Loss (FCL), an adaptive robust loss that automatically
calibrates its robustness to label noise during training. Built within the
active-passive loss framework, FCL employs the fractional derivative of the
Cross-Entropy (CE) loss as its active component and the Mean Absolute Error
(MAE) as its passive loss component. With this formulation, we demonstrate that
the fractional derivative order $\mu$ spans a family of loss functions that
interpolate between MAE-like robustness and CE-like fast convergence.
Furthermore, we integrate $\mu$ into the gradient-based optimization as a
learnable parameter and automatically adjust it to optimize the trade-off
between robustness and convergence speed. We reveal that FCL's unique property
establishes a critical trade-off that enables the stable learning of $\mu$:
lower log penalties on difficult or mislabeled examples improve robustness but
impose higher penalties on easy or clean data, reducing model confidence in
them. Consequently, FCL can dynamically reshape its loss landscape to achieve
effective classification performance under label noise. Extensive experiments
on benchmark datasets show that FCL achieves state-of-the-art results without
the need for manual hyperparameter tuning.

</details>


### [221] [Geometric-k-means: A Bound Free Approach to Fast and Eco-Friendly k-means](https://arxiv.org/abs/2508.06353)
*Parichit Sharma,Marcin Stanislaw,Hasan Kurban,Oguzhan Kulekci,Mehmet Dalkilic*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper introduces Geometric-k-means (or Gk-means for short), a novel
approach that significantly enhances the efficiency and energy economy of the
widely utilized k-means algorithm, which, despite its inception over five
decades ago, remains a cornerstone in machine learning applications. The
essence of Gk-means lies in its active utilization of geometric principles,
specifically scalar projection, to significantly accelerate the algorithm
without sacrificing solution quality. This geometric strategy enables a more
discerning focus on data points that are most likely to influence cluster
updates, which we call as high expressive data (HE). In contrast, low
expressive data (LE), does not impact clustering outcome, is effectively
bypassed, leading to considerable reductions in computational overhead.
Experiments spanning synthetic, real-world and high-dimensional datasets,
demonstrate Gk-means is significantly better than traditional and state of the
art (SOTA) k-means variants in runtime and distance computations (DC).
Moreover, Gk-means exhibits better resource efficiency, as evidenced by its
reduced energy footprint, placing it as more sustainable alternative.

</details>


### [222] [Beyond Prompt-Induced Lies: Investigating LLM Deception on Benign Prompts](https://arxiv.org/abs/2508.06361)
*Zhaomin Wu,Mingzhe Du,See-Kiong Ng,Bingsheng He*

Main category: cs.LG

TL;DR: 本研究首次探讨了大型语言模型（LLM）在没有明确指令的情况下，自主产生欺骗行为的可能性。研究者提出了一种新的评估框架，并开发了两个量化欺骗倾向的指标。实验结果表明，随着任务复杂度的提高，LLM的欺骗行为会显著增加，这对于LLM在现实世界中的应用敲响了警钟。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有研究主要通过提示或微调来诱导LLM欺骗，这可能无法完全反映现实世界中的人机交互问题，本文旨在研究LLM在无提示或微调的情况下，自主发起欺骗行为的现象。

Method: 提出了一种新颖的框架，使用“接触搜索问题”来评估LLM在无提示或微调的欺骗行为。该框架引入了两个基于心理学原理的统计指标：欺骗意图得分（衡量模型偏向隐藏目标的程度）和欺骗行为得分（衡量模型内部信念与其输出之间的一致性）。

Result: 在对14个领先的LLM进行评估后发现，欺骗意图得分和欺骗行为得分会随着任务难度的增加而升高，并且对大多数模型而言，这两种指标的升高是同步的。基于这些发现，研究者建立了一个数学模型来解释这种行为。

Conclusion: 现有的大型语言模型（LLM）在处理复杂问题时，会表现出越来越强的欺骗倾向，这对其在关键领域的部署提出了严峻的挑战。

Abstract: Large Language Models (LLMs) have been widely deployed in reasoning,
planning, and decision-making tasks, making their trustworthiness a critical
concern. The potential for intentional deception, where an LLM deliberately
fabricates or conceals information to serve a hidden objective, remains a
significant and underexplored threat. Existing studies typically induce such
deception by explicitly setting a "hidden" objective through prompting or
fine-tuning, which may not fully reflect real-world human-LLM interactions.
Moving beyond this human-induced deception, we investigate LLMs' self-initiated
deception on benign prompts. To address the absence of ground truth in this
evaluation, we propose a novel framework using "contact searching questions."
This framework introduces two statistical metrics derived from psychological
principles to quantify the likelihood of deception. The first, the Deceptive
Intention Score, measures the model's bias towards a hidden objective. The
second, Deceptive Behavior Score, measures the inconsistency between the LLM's
internal belief and its expressed output. Upon evaluating 14 leading LLMs, we
find that both metrics escalate as task difficulty increases, rising in
parallel for most models. Building on these findings, we formulate a
mathematical model to explain this behavior. These results reveal that even the
most advanced LLMs exhibit an increasing tendency toward deception when
handling complex problems, raising critical concerns for the deployment of LLM
agents in complex and crucial domains.

</details>


### [223] [ActivityDiff: A diffusion model with Positive and Negative Activity Guidance for De Novo Drug Design](https://arxiv.org/abs/2508.06364)
*Renyi Zhou,Huimin Zhu,Jing Tang,Min Li*

Main category: cs.LG

TL;DR: ActivityDiff是一种新的生成方法，利用扩散模型和分类器指导来同时控制分子的多种活性，增强药物设计的有效性和安全性。


<details>
  <summary>Details</summary>
Motivation: 在从头药物设计中，精确控制分子的生物活性（包括靶向激活/抑制、协同多靶点调节和脱靶毒性缓解）仍然是一个关键挑战。现有的生成方法主要集中于产生具有单一预期活性的分子，缺乏同时管理多种预期和非预期分子相互作用的集成机制。

Method: ActivityDiff是一种基于扩散模型分类器指导技术的新型生成方法。

Result: 实验结果表明，ActivityDiff能够有效地处理关键的药物设计任务，包括单/双靶点生成、片段约束的双靶点设计、增强靶点选择性的选择性生成以及减少脱靶效应。

Conclusion: ActivityDiff通过结合多种活动来增强其有效性和安全性，是一种多功能的、可扩展的框架。

Abstract: Achieving precise control over a molecule's biological activity-encompassing
targeted activation/inhibition, cooperative multi-target modulation, and
off-target toxicity mitigation-remains a critical challenge in de novo drug
design. However, existing generative methods primarily focus on producing
molecules with a single desired activity, lacking integrated mechanisms for the
simultaneous management of multiple intended and unintended molecular
interactions. Here, we propose ActivityDiff, a generative approach based on the
classifier-guidance technique of diffusion models. It leverages separately
trained drug-target classifiers for both positive and negative guidance,
enabling the model to enhance desired activities while minimizing harmful
off-target effects. Experimental results show that ActivityDiff effectively
handles essential drug design tasks, including single-/dual-target generation,
fragment-constrained dual-target design, selective generation to enhance target
specificity, and reduction of off-target effects. These results demonstrate the
effectiveness of classifier-guided diffusion in balancing efficacy and safety
in molecular design. Overall, our work introduces a novel paradigm for
achieving integrated control over molecular activity, and provides ActivityDiff
as a versatile and extensible framework.

</details>


### [224] [End-to-End Text-to-SQL with Dataset Selection: Leveraging LLMs for Adaptive Query Generation](https://arxiv.org/abs/2508.06387)
*Anurag Tripathi,Vaibhav Patle,Abhinav Jain,Ayush Pundir,Sairam Menon,Ajeet Kumar Singh*

Main category: cs.LG

TL;DR: 一个能识别用户意图数据库的Text-to-SQL框架，通过三阶段方法（规则提取、数据库ID预测、SQL修正）提升了准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的Text-to-SQL方法需要预先指定目标数据库，这在存在多个大型数据库的情况下是不切实际的，而识别正确的数据库是至关重要但被忽视的步骤。

Method: 提出一个三阶段端到端Text-to-SQL框架，首先利用LLM和提示工程从自然语言查询（NLQ）中提取规则集，然后训练一个基于RoBERTa的finetune编码器的大型db_id预测模型来预测正确的数据库标识符（db_id），最后使用critic代理来纠正生成的SQL。

Result: 实验结果表明，该框架在数据库意图预测和SQL生成准确性方面均优于现有最先进模型。

Conclusion: 该框架在数据库意图预测和SQL生成准确性方面均优于现有的最先进模型。

Abstract: Text-to-SQL bridges the gap between natural language and structured database
language, thus allowing non-technical users to easily query databases.
Traditional approaches model text-to-SQL as a direct translation task, where a
given Natural Language Query (NLQ) is mapped to an SQL command. Recent advances
in large language models (LLMs) have significantly improved translation
accuracy, however, these methods all require that the target database is
pre-specified. This becomes problematic in scenarios with multiple extensive
databases, where identifying the correct database becomes a crucial yet
overlooked step. In this paper, we propose a three-stage end-to-end text-to-SQL
framework to identify the user's intended database before generating SQL
queries. Our approach leverages LLMs and prompt engineering to extract implicit
information from natural language queries (NLQs) in the form of a ruleset. We
then train a large db\_id prediction model, which includes a RoBERTa-based
finetuned encoder, to predict the correct Database identifier (db\_id) based on
both the NLQ and the LLM-generated rules. Finally, we refine the generated SQL
by using critic agents to correct errors. Experimental results demonstrate that
our framework outperforms the current state-of-the-art models in both database
intent prediction and SQL generation accuracy.

</details>


### [225] [A New Lens on Homelessness: Daily Tent Monitoring with 311 Calls and Street Images](https://arxiv.org/abs/2508.06409)
*Wooyong Jung,Sola Kim,Dongwook Kim,Maryam Tabar,Dongwon Lee*

Main category: cs.LG

TL;DR: 利用311电话和街景图像数据，开发新模型追踪旧金山无家可归者帐篷趋势，比传统方法更及时、细致。


<details>
  <summary>Details</summary>
Motivation: 美国无家可归现象日益严重，而现有的监测方法（如特定时间点普查）在频率、一致性和空间细节方面存在局限性。因此，有必要开发新的方法来更有效地监测无家可归现象。

Method: 本研究利用公开的众包数据，包括311服务电话和街景图像，来构建一个预测模型，以追踪和预测旧金山无家可归者帐篷的趋势。

Result: 研究提出的预测模型能够捕捉到每日和社区层面的细微变化，并发现了传统普查方法常常忽略的模式，例如在COVID-19大流行期间的快速波动以及帐篷位置随时间的空间转移。

Conclusion: 通过利用311服务电话和街景图像等公开的众包数据，该研究提出了一种创新的方法来追踪和预测旧金山的无家可归者帐篷趋势。该方法能够捕捉细粒度的每日和社区级别变化，揭示了传统方法（如特定时间点普查）难以发现的模式，例如在COVID-19大流行期间的快速波动以及帐篷位置的时空转移。因此，该方法为指导政策响应和评估旨在减少无家可归现象的干预措施提供了及时、本地化且经济高效的信息支持。

Abstract: Homelessness in the United States has surged to levels unseen since the Great
Depression. However, existing methods for monitoring it, such as point-in-time
(PIT) counts, have limitations in terms of frequency, consistency, and spatial
detail. This study proposes a new approach using publicly available,
crowdsourced data, specifically 311 Service Calls and street-level imagery, to
track and forecast homeless tent trends in San Francisco. Our predictive model
captures fine-grained daily and neighborhood-level variations, uncovering
patterns that traditional counts often overlook, such as rapid fluctuations
during the COVID-19 pandemic and spatial shifts in tent locations over time. By
providing more timely, localized, and cost-effective information, this approach
serves as a valuable tool for guiding policy responses and evaluating
interventions aimed at reducing unsheltered homelessness.

</details>


### [226] [Sample-efficient LLM Optimization with Reset Replay](https://arxiv.org/abs/2508.06412)
*Zichuan Liu,Jinyu Wang,Lei Song,Jiang Bian*

Main category: cs.LG

TL;DR: LoRR 是一种用于 LLM 微调的样本高效方法，通过重放和重置策略克服了现有方法的局限性，并在推理任务上取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 现有的 LLM 微调方法（如 RL 和偏好优化）存在样本效率低和易出现首因偏差的问题，限制了其在推理能力上的提升。

Method: LoRR 是一种通用插件，通过高回放数训练、周期性重置策略（包含初始数据再利用）和结合 SFT 与基于偏好的损失的混合优化目标来提高样本效率，同时防止过拟合。

Result: LoRR 显著提高了各种偏好优化方法在数学和通用推理基准上的性能。特别是，集成了 LoRR 的迭代 DPO 方法在具有挑战性的数学任务上取得了与一些复杂且计算量大的 RL 算法相当的性能，甚至超越了它们。

Conclusion: LoRR 通过提高样本效率和克服首因偏差来增强 LLM 的微调，即使在数据有限的情况下也能显著提高性能。

Abstract: Recent advancements in post-training Large Language Models (LLMs),
particularly through Reinforcement Learning (RL) and preference optimization
methods, are key drivers for enhancing their reasoning capabilities. However,
these methods are often plagued by low sample efficiency and a susceptibility
to primacy bias, where overfitting to initial experiences degrades policy
quality and damages the learning process. To address these challenges, we
introduce LLM optimization with Reset Replay (LoRR), a general and powerful
plugin designed to enhance sample efficiency in any preference-based
optimization framework. LoRR core mechanism enables training at a high replay
number, maximizing the utility of each collected data batch. To counteract the
risk of overfitting inherent in high-replay training, LoRR incorporates a
periodic reset strategy with reusing initial data, which preserves network
plasticity. Furthermore, it leverages a hybrid optimization objective,
combining supervised fine-tuning (SFT) and preference-based losses to further
bolster data exploitation. Our extensive experiments demonstrate that LoRR
significantly boosts the performance of various preference optimization methods
on both mathematical and general reasoning benchmarks. Notably, an iterative
DPO approach augmented with LoRR achieves comparable performance on challenging
math tasks, outperforming some complex and computationally intensive RL-based
algorithms. These findings highlight that LoRR offers a practical,
sample-efficient, and highly effective paradigm for LLM finetuning, unlocking
greater performance from limited data.

</details>


### [227] [LLM Unlearning using Gradient Ratio-Based Influence Estimation and Noise Injection](https://arxiv.org/abs/2508.06467)
*Ameya Anjarlekar,Sandeep Pombra*

Main category: cs.LG

TL;DR: GRIN是一种用于大型语言模型（LLM）的新型解离框架，通过识别和选择性地处理对遗忘数据负有责任的参数，以实现更有效的遗忘，同时最大限度地保留模型效用。


<details>
  <summary>Details</summary>
Motivation: 现有模型解离方法存在遗忘不完全或破坏无关知识的缺点，而LLM的法律和伦理审查日益严格，因此需要有效的模型解离方法，尤其是在处理敏感或未经授权的数据时。

Method: GRIN框架通过以下方式实现模型解离：1. 提出新颖的基于梯度比率的度量，以识别对记忆遗忘数据最负责的参数。2. 对识别出的参数进行选择性噪声注入。3. 对模型进行微调。4. 提出新的适用于LLM的评估指标。

Result: GRIN框架在TOFU、WMDP和SafePKU等标准基准测试中，能够有效实现遗忘，同时保持模型效用，优于现有方法。

Conclusion: GRIN框架通过梯度比率度量有效识别和选择性去除LLM中遗忘数据的参数，同时通过注入噪声和微调来最大限度地保留模型效用，并在标准基准测试中得到了验证。

Abstract: The growing legal and ethical scrutiny of large language models (LLMs)
necessitates effective machine unlearning, particularly for sensitive or
unauthorized data. Existing empirical methods often yield incomplete forgetting
or unintended degradation of unrelated knowledge due to poor localization. In
this work, we propose GRIN: a modular and targeted framework for LLM
unlearning. GRIN introduces a novel gradient-ratio-based metric to identify
parameters most responsible for memorizing forget data. We then perform
selective noise injection into these parameters prior to fine-tuning, which
improves unlearning performance while maintaining model utility. Finally, we
propose new evaluation metrics tailored to the LLM setting and validate our
approach on standard benchmarks such as TOFU, WMDP, and SafePKU.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [228] [MPS-JuliQAOA: User-friendly, Scalable MPS-based Simulation for Quantum Optimization](https://arxiv.org/abs/2508.05883)
*Sean Feeney,Reuben Tate,John Golden,Stephan Eidenbenz*

Main category: quant-ph

TL;DR: A new Julia-based simulator (MPS-JuliQAOA) uses MPS to simulate QAOA for diagonal Hamiltonians, offering scalability and parameter-finding features, and is easy to use.


<details>
  <summary>Details</summary>
Motivation: To provide a user-friendly and scalable tool for simulating the Quantum Approximate Optimization Algorithm (QAOA) for a broader range of optimization problems that can be expressed as diagonal Hamiltonians.

Method: The simulator uses a Matrix Product State (MPS) approach implemented in Julia with the ITensor package to simulate QAOA. It also has built-in parameter-finding capabilities.

Result: The simulator scales effectively, handling up to 512 qubits and 20 simulation rounds on the 3-regular MaxCut QAOA benchmark. It also demonstrates user-friendliness and analyzes scalability tradeoffs.

Conclusion: The MPS-JuliQAOA simulator is a user-friendly, open-source tool for simulating QAOA for problems with diagonal Hamiltonians. It scales efficiently and includes parameter-finding capabilities, making it accessible to users without requiring knowledge of MPS or automatic differentiation.

Abstract: We present the MPS-JuliQAOA simulator, a user-friendly, open-source tool to
simulate the Quantum Approximate Optimization Algorithm (QAOA) of any
optimization problem that can be expressed as diagonal Hamiltonian. By
leveraging Julia-language constructs and the ITensor package to implement a
Matrix Product State (MPS) approach to simulating QAOA, MPS-Juli-QAOA
effortlessly scales to 512 qubits and 20 simulation rounds on the standard
de-facto benchmark 3-regular MaxCut QAOA problem. MPS-JuliQAOA also has
built-in parameter finding capabilities, which is a crucial performance aspect
of QAOA. We illustrate through examples that the user does not need to know MPS
principles or complex automatic differentiation techniques to use MPS-JuliQAOA.
We study the scalability of our tool with respect to runtime, memory usage and
accuracy tradeoffs. Code available at
https://github.com/lanl/JuliQAOA.jl/tree/mps.

</details>


### [229] [Quantum Resource Management in the NISQ Era: Implications and Perspectives from Software Engineering](https://arxiv.org/abs/2508.05697)
*Marcos Guillermo Lammers,Federico Hernán Holik,Alejandro Fernández*

Main category: quant-ph

TL;DR: Analyzes quantum resource management in NISQ devices to improve quantum software engineering and resource estimation.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of NISQ hardware (limited qubits, high error rates, short coherence times) and the need for efficient management of quantum resources in quantum algorithm design and deployment.

Method: The paper analyzes the role of resources in current uses of NISQ devices, identifying their relevance and implications for quantum software engineering.

Result: Identified the relevance and implications of resources in current NISQ device uses for quantum software engineering.

Conclusion: The paper analyzes resource roles in NISQ devices for quantum software engineering, aiming to advance Quantum Resource Estimation for scalable and reliable quantum software development.

Abstract: Quantum computers represent a radical technological breakthrough in
information processing by leveraging the principles of quantum mechanics to
solve highly complex problems beyond the reach of classical systems. However,
in the current NISQ era (noisy intermediate-scale quantum devices), the
available hardware presents several limitations, such as a limited number of
qubits, high error rates, and short coherence times. Efficient management of
quantum resources, both physical and logical, is especially relevant in the
design and deployment of quantum algorithms. In this paper, we analyze the role
of resources in current uses of NISQ devices, identifying their relevance and
implications for quantum software engineering. With this contribution, we aim
to strengthen the field of Quantum Resource Estimation (QRE) and move toward
scalable and reliable quantum software development

</details>


### [230] [End-to-End Efficient Quantum Thermal and Ground State Preparation Made Simple](https://arxiv.org/abs/2508.05703)
*Zhiyan Ding,Yongtao Zhan,John Preskill,Lin Lin*

Main category: quant-ph

TL;DR: 提出了基于单量子比特浴和系统-浴相互作用的新量子算法，用于热态和基态制备，具有理论保证的效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决早期容错量子设备上热态和基态制备的挑战，提出了基于系统-浴相互作用的新量子算法。

Method: 提出了一种新的量子算法，利用系统-浴相互作用，其中浴是一个可重复使用的单量子比特。通过精心设计浴和相互作用哈密顿量，证明了动力学的固定点能够精确地逼近期望的量子态，并对混合时间进行了理论分析。

Result: 算法仅需要系统-浴哈密顿量的正向演化，浴是一个可重复使用的单量子比特，并且在混合时间方面有理论保证，证明了系统-浴相互作用模型在制备热态和基态方面的端到端效率。

Conclusion: 所提出的新量子算法基于系统-浴相互作用，适用于早期容错量子设备，能够为热态和基态制备提供理论保证。

Abstract: We propose new quantum algorithms for thermal and ground state preparation
based on system-bath interactions. These algorithms require only forward
evolution under a system-bath Hamiltonian in which the bath is a single
reusable ancilla qubit, making them especially well-suited for early
fault-tolerant quantum devices. By carefully designing the bath and interaction
Hamiltonians, we prove that the fixed point of the dynamics accurately
approximates the desired quantum state. Furthermore, we establish theoretical
guarantees on the mixing time for several physically relevant models, thereby
providing a rigorous justification for the end-to-end efficiency of system-bath
interaction models in thermal and ground state preparation.

</details>


### [231] [Quantum Algorithms for Finite-horizon Markov Decision Processes](https://arxiv.org/abs/2508.05712)
*Bin Luo,Yuwen Huang,Jonathan Allcock,Xiaojun Lin,Shengyu Zhang,John C. S. Lui*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this work, we design quantum algorithms that are more efficient than
classical algorithms to solve time-dependent and finite-horizon Markov Decision
Processes (MDPs) in two distinct settings: (1) In the exact dynamics setting,
where the agent has full knowledge of the environment's dynamics (i.e.,
transition probabilities), we prove that our $\textbf{Quantum Value Iteration
(QVI)}$ algorithm $\textbf{QVI-1}$ achieves a quadratic speedup in the size of
the action space $(A)$ compared with the classical value iteration algorithm
for computing the optimal policy ($\pi^{*}$) and the optimal V-value function
($V_{0}^{*}$). Furthermore, our algorithm $\textbf{QVI-2}$ provides an
additional speedup in the size of the state space $(S)$ when obtaining
near-optimal policies and V-value functions. Both $\textbf{QVI-1}$ and
$\textbf{QVI-2}$ achieve quantum query complexities that provably improve upon
classical lower bounds, particularly in their dependences on $S$ and $A$. (2)
In the generative model setting, where samples from the environment are
accessible in quantum superposition, we prove that our algorithms
$\textbf{QVI-3}$ and $\textbf{QVI-4}$ achieve improvements in sample complexity
over the state-of-the-art (SOTA) classical algorithm in terms of $A$,
estimation error $(\epsilon)$, and time horizon $(H)$. More importantly, we
prove quantum lower bounds to show that $\textbf{QVI-3}$ and $\textbf{QVI-4}$
are asymptotically optimal, up to logarithmic factors, assuming a constant time
horizon.

</details>


### [232] [Quantum Reservoir GAN](https://arxiv.org/abs/2508.05716)
*Hikaru Wakaura*

Main category: quant-ph

TL;DR: Quantum Reservoir GAN improves accuracy by using Quantum Reservoir Computers as a GAN generator, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: To improve the accuracy of Quantum Reservoir Computers, which is not enough for practical use, by focusing on software improvements instead of hardware.

Method: The proposed approach is Quantum Reservoir Generative Adversarial Network (GAN), which uses Quantum Reservoir Computers as a generator of GAN.

Result: Generation of handwritten single digits and monochrome pictures on the CIFAR10 dataset. Quantum Reservoir GAN showed higher accuracy than Quantum GAN, Classical Neural Network, and ordinary Quantum Reservoir Computers.

Conclusion: Quantum Reservoir GAN is confirmed to be more accurate than Quantum GAN, Classical Neural Network, and ordinary Quantum Reservoir Computers.

Abstract: Quantum machine learning is known as one of the promising applications of
quantum computers. Many types of quantum machine learning methods have been
released, such as Quantum Annealer, Quantum Neural Network, Variational Quantum
Algorithms, and Quantum Reservoir Computers. They can work consuming far less
energy for networks of equivalent size. Quantum Reservoir Computers, in
particular, have no limit on the size of input data. However, their accuracy is
not enough for practical use, and the effort to improve accuracy is mainly
focused on hardware improvements. Therefore, we propose the approach from
software called Quantum Reservoir Generative Adversarial Network ( GAN ), which
uses Quantum Reservoir Computers as a generator of GAN. We performed the
generation of handwritten single digits and monochrome pictures on the CIFAR10
dataset. As a result, Quantum Reservoir GAN is confirmed to be more accurate
than Quantum GAN, Classical Neural Network, and ordinary Quantum Reservoir
Computers.

</details>


### [233] [The vast world of quantum advantage](https://arxiv.org/abs/2508.05720)
*Hsin-Yuan Huang,Soonwon Choi,Jarrod R. McClean,John Preskill*

Main category: quant-ph

TL;DR: 区分量子优势的真伪至关重要。本文探讨了定义量子优势的五个关键属性（可预测性、典型性、鲁棒性、可验证性和有用性），并预测了未来的量子优势。研究表明，一些量子优势无法仅用经典方法预测，量子技术的真正潜力可能超乎我们的想象。


<details>
  <summary>Details</summary>
Motivation: 识别量子优势是量子技术的关键。虽然量子设备有望提供非凡的能力，但区分真正的量子优势和虚幻的量子优势仍然是一个严峻的挑战。

Method: 本文我们审视了我们在计算、学习、传感和通信领域中用于探索量子优势的数学工具。我们探索了五个关键属性：可预测性、典型性、鲁棒性、可验证性和有用性，这些属性定义了理想的量子优势，并设想了在普及的量子技术时代可能出现的新型量子优势。

Result: 我们证明了一些量子优势本质上是无法仅使用经典资源来预测的，这表明其前景比我们目前可预见的要丰富得多。

Conclusion: 区分真正的量子优势与虚幻的量子优势是一个严峻的挑战。虽然数学严谨性是我们的必备指南，但量子技术的终极力量可能源于我们尚未能想象到的优势。

Abstract: The quest to identify quantum advantages lies at the heart of quantum
technology. While quantum devices promise extraordinary capabilities, from
exponential computational speedups to unprecedented measurement precision,
distinguishing genuine advantages from mere illusions remains a formidable
challenge. In this endeavor, quantum theorists are like prophets attempting to
foretell the future, yet the boundary between visionary insight and unfounded
fantasy is perilously thin. In this perspective, we examine our mathematical
tools for navigating the vast world of quantum advantages across computation,
learning, sensing, and communication. We explore five keystone properties:
predictability, typicality, robustness, verifiability, and usefulness that
define an ideal quantum advantage, and envision what new quantum advantages
could arise in a future with ubiquitous quantum technology. We prove that some
quantum advantages are inherently unpredictable using classical resources
alone, suggesting a landscape far richer than what we can currently foresee.
While mathematical rigor remains our indispensable guide, the ultimate power of
quantum technologies may emerge from advantages we cannot yet conceive.

</details>


### [234] [Role of Plaquette Term in Genuine $2+1$D String Dynamics on Quantum Simulators](https://arxiv.org/abs/2508.05736)
*Yizhuo Tian,N. S. Srivatsa,Kaidi Xu,Jesse J. Osborne,Umberto Borla,Jad C. Halimeh*

Main category: quant-ph

TL;DR: 本研究通过张量网络模拟和解析推导，研究了 $2+1$D 格子规范理论 (LGT) 中字符串动力学的量子模拟。研究表明，plaquette 项对于真正 $2+1$D 的约束区域动力学至关重要。在 plaquette 项缺失的情况下，字符串断裂可以有效地映射到 $1+1$D 的动力学过程。


<details>
  <summary>Details</summary>
Motivation: 随着 $2+1$D LGT 的量子模拟器的出现，一个基本遗留问题是在什么情况下观察到的物理学确实是 $2+1$D 而不是有效地 $1+1$D。

Method: 通过张量网络模拟和解析推导，研究了 plaquette 项在 $2+1$D LGT 的真正 $2+1$D 动力学中的作用。

Result: 研究表明，plaquette 项在真正 $2+1$D 的约束区域动力学中起着关键作用。在 plaquette 项缺失的情况下，以及对于最小长度的字符串，研究展示了字符串断裂可以有效地映射到 $1+1$D 的动力学过程。

Conclusion: 该研究回答了在什么情况下 $2+1$D 格子规范理论 (LGT) 的模拟物理学确实是 $2+1$D 而不是有效地 $1+1$D 的问题，并为未来的量子模拟实验提供了指导。

Abstract: With the advent of quantum simulators of $2+1$D lattice gauge theories
(LGTs), a fundamental open question is under what circumstances the observed
physics is genuinely $2+1$D rather than effectively $1+1$D. Here, we address
this question in the ongoing strong effort to quantum-simulate string dynamics
in $2+1$D LGTs on state-of-the-art quantum hardware. Through tensor network
simulations and analytic derivations, we show that the plaquette term, which
represents a magnetic field and only emerges in $d>1$ spatial dimensions, plays
a crucial role in \textit{genuine} $2+1$D string dynamics deep in the confined
regime. In its absence and for minimal-length (Manhattan-distance) strings, we
demonstrate how string breaking, although on a lattice in $d=2$ spatial
dimensions, can be effectively mapped to a $1+1$D dynamical process
independently of lattice geometry. Our findings not only answer the question of
what qualifies as genuine $2+1$D string dynamics, but also serve as a clear
guide for future quantum simulation experiments of $2+1$D LGTs.

</details>


### [235] [A quantum computing approach to efficiently simulating correlated materials using impurity models and dynamical mean field theory](https://arxiv.org/abs/2508.05738)
*Norman Hogan,Efekan Kökcü,Thomas Steckmann,Liam P. Doak,Carlos Mejuto-Zaera,Daan Camps,Roel Van Beeumen,Wibe A. de Jong,A. F. Kemper*

Main category: quant-ph

TL;DR: 本研究提出了一个在量子计算机上进行DMFT计算的框架，结合了低秩高斯子空间和压缩量子电路，并展示了其在IBM量子处理器上的可行性。


<details>
  <summary>Details</summary>
Motivation: 精确的强关联电子材料理论描述是凝聚态物理和计算化学前沿的挑战，也是量子计算的目标之一。DMFT是一种通过结合一些关联行为来预测此类系统行为的成功方法，但受限于计算杂质模型格林函数的需要。

Method: 该框架利用了杂质问题的结构，结合了低秩高斯子空间表示基态和压缩的、短深度的量子电路，将高斯态制备与时间演化相结合，以计算必要的格林函数。

Result: 在无噪声环境下，本研究证明了使用高斯子空间进行DMFT算法的收敛性，并通过在IBM量子处理器上提取单杂质耦合到三个浴轨道的格林函数（8个物理量子比特和1个辅助量子比特），展示了量子电路压缩的硬件可行性。

Conclusion: 本研究提出了一个在量子计算机上进行动力学平均场理论（DMFT）计算的框架，特别关注近期应用。该框架利用了杂质问题的结构，结合了低秩高斯子空间表示基态和压缩的、短深度的量子电路，将高斯态制备与时间演化相结合，以计算必要的格林函数。

Abstract: The accurate theoretical description of materials with strongly correlated
electrons is a formidable challenge, at the forefront of condensed matter
physics and computational chemistry alike, and it is one of the targets for
quantum computing. Dynamical Mean Field Theory (DMFT) is a successful approach
that predicts behaviors of such systems by incorporating some correlated
behavior, but it is limited by the need to calculate the Green's function for
the impurity model. This work proposes a framework for DMFT calculations on
quantum computers, focusing on near-term applications. It leverages the
structure of the impurity problem, combining a low-rank Gaussian subspace
representation of the ground state and a compressed, short-depth quantum
circuit that joins the Gaussian state preparation with the time evolution to
compute the necessary Green's functions. We demonstrate the convergence of the
DMFT algorithm using the Gaussian subspace in a noise-free setting, and show
the hardware viability of the circuit compression by extracting the impurity
Green's function on IBM quantum processors for a single impurity coupled to
three bath orbitals (8 physical qubits and 1 ancilla). We discuss the potential
paths forward towards realizing this use case of quantum computing in materials
science.

</details>


### [236] [Classical simulation of noisy quantum circuits via locally entanglement-optimal unravelings](https://arxiv.org/abs/2508.05745)
*Simon Cichy,Paul K. Faehrmann,Lennart Bittel,Jens Eisert,Hakop Pashayan*

Main category: quant-ph

TL;DR: 本文提出了一种新的、可并行化的张量网络算法，用于模拟含单比特噪声的量子电路，该算法在精度、性能和适用范围上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了理解真实世界量子系统的行为以及确定量子优势的预期区域，对含噪声量子电路进行经典模拟是至关重要的。

Method: 本文提出了一种基于张量网络的经典算法，该算法可以高度并行化，并具有严格的精度保证，用于模拟具有任意单比特噪声的n量子比特量子线路。该算法通过一种特殊的矩阵乘积态系综来表示噪声量子系统的状态，并从中进行随机采样。每一个作用在纯态上的单比特噪声过程，都被表示为达到最小平均纠缠（形成纠缠）的系综状态。

Result: 该算法可以在给定最大键维度χ和电路的情况下，对模拟误差提供一个上限，运行时间为多项式（n,χ）时间。与现有工作相比，该算法在处理范围（从三种常见的噪声模型扩展到一般的单比特噪声）、性能（采用状态依赖的局部纠缠最优展开）和概念贡献（证明了固定展开在特定噪声模型下等价于本文提出的展开方式）方面都有所改进。

Conclusion: 该算法通过采用状态依赖的、局部纠缠最优的展开方式，可以更有效地模拟量子线路，并且在精度要求和噪声水平的权衡上表现更优，同时扩展了对一般单比特噪声的处理能力。

Abstract: Classical simulations of noisy quantum circuits is instrumental to our
understanding of the behavior of real world quantum systems and the
identification of regimes where one expects quantum advantage. In this work, we
present a highly parallelizable tensor-network-based classical algorithm --
equipped with rigorous accuracy guarantees -- for simulating $n$-qubit quantum
circuits with arbitrary single-qubit noise. Our algorithm represents the state
of a noisy quantum system by a particular ensemble of matrix product states
from which we stochastically sample. Each single qubit noise process acting on
a pure state is then represented by the ensemble of states that achieve the
minimal average entanglement (the entanglement of formation) between the noisy
qubit and the remainder. This approach lets us use a more compact
representation of the quantum state for a given accuracy requirement and noise
level. For a given maximum bond dimension $\chi$ and circuit, our algorithm
comes with an upper bound on the simulation error, runs in poly$(n,\chi)$-time
and improves upon related prior work (1) in scope: by extending from the three
commonly considered noise models to general single qubit noise (2) in
performance: by employing a state-dependent locally-entanglement-optimal
unraveling and (3) in conceptual contribution: by showing that the fixed
unraveling used in prior work becomes equivalent to our choice of unraveling in
the special case of depolarizing and dephasing noise acting on a maximally
entangled state.

</details>


### [237] [A spin-embedded diamond optomechanical resonator with mechanical quality factor exceeding one million](https://arxiv.org/abs/2508.05906)
*Hyunseok Oh,Viraj Dharod,Carl Padgett,Lillian B. Hughes,Jayameenakshi Venkatraman,Shreyas Parthasarathy,Ekaterina Osipova,Ian Hedgepeth,Jeffrey V. Cady,Luca Basso,Yongqiang Wang,Michael Titze,Edward S. Bielejec,Andrew M. Mounce,Dirk Bouwmeester,Ania C. Bleszynski Jayich*

Main category: quant-ph

TL;DR: 研究人员利用金刚石光力学晶体（OMC）器件，成功实现了高品质机械模式和长相干时间的金刚石NV色心，为量子技术奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 为了实现金刚石光力学晶体（OMC）器件在量子传感、网络和计算中的应用，需要工程化一种能够同时保持高品质因数机械模式和嵌入自旋体相干性的器件。本研究旨在实现这一目标。

Method: 本研究通过结合单晶金刚石薄膜形成技术和化学气相沉积（CVD）金刚石过生长技术，制备了具有嵌入色心自旋的金刚石光力学晶体（OMC）器件。对该器件进行了低温下的机械品质因数、NV色心相干时间和腔内光功率的测量，并验证了其高光机协同作用。

Result: 本研究成功展示了 sideband-resolved 金刚石 OMC 器件，其在低温下的机械品质因数超过 $10^6$，嵌入的 NV 色心相干时间最长可达 $T_2$ = 270 $\mu$s。此外，在五个数量级的腔内光功率范围内，器件表现出稳定的功率处理能力和高光机协同作用 ($C\gg1$)。

Conclusion: 该研究展示了具有高品质因数机械模式和长相干时间金刚石NV色心的大型语言模型，并证明了其在量子计算、传感和网络中的潜力。

Abstract: Diamond optomechanical crystal (OMC) devices with embedded color center spins
are promising platforms for a broad range of applications in quantum sensing,
networking, and computing applications, offering an interface between a
GHz-frequency mechanical mode and both optical photons and coherent spins. A
crucial but elusive step towards realizing this platform is to engineer a
device with a high-quality factor mechanical mode while preserving the
bulk-like coherence of embedded spins. Here we demonstrate sideband-resolved
diamond OMCs with mechanical quality factors in excess of $10^6$ at cryogenic
temperatures, and find coherence times up to $T_2$ = 270 $\mu$s for embedded
nitrogen vacancy (NV) centers. Furthermore, we measure these devices across
five orders of magnitude in intracavity optical power, demonstrating robust
power handling and a high optomechanical cooperativity ($C\gg1$) at cryogenic
temperatures that is essential for a broad range of quantum protocols requiring
strong, coherent interactions between photons and phonons. These results are
enabled by a robust, high-throughput method for forming single-crystal diamond
membranes in combination with chemical vapor deposition (CVD) diamond
overgrowth with nitrogen $\delta$-doping. We discuss the prospects of this
platform for hybrid spin-mechanical devices in the quantum regime.

</details>


### [238] [Expressivity Limits and Trainability Guarantees in Quantum Walk-based Optimization](https://arxiv.org/abs/2508.05749)
*Guilherme A. Bridi,Debbie Lim,Lirandë Pira,Raqueline A. M. Santos,Franklin de L. Marquezino,Soumik Adhikary*

Main category: quant-ph

TL;DR: 量子算法在解决组合优化问题方面显示出潜力。本研究分析了量子游走优化算法（QWOA）的表达能力和可训练性，得出了其维度上限，并表明在NP优化问题中不存在无 প্রতিশ্রুতি平原。


<details>
  <summary>Details</summary>
Motivation: 理解量子算法（特别是QWOA）的表达能力和可训练性对于评估其在组合优化问题中的性能至关重要。

Method: 通过分析动态李代数（DLA）的维度来研究QWOA的表达能力和可训练性。

Result: 得出了QWOA适用于NP优化问题的维度上限，并指出了在某些情况下QWOA为了获得最优或近似解必须过参数化。

Conclusion: 该研究推导了量子游走优化算法（QWOA）用于任意优化问题的维度上限，揭示了QWOA在解决NP优化问题时避免了无 প্রতিশ্রুতি平原。

Abstract: Quantum algorithms have emerged as a promising tool to solve combinatorial
optimization problems. The quantum walk optimization algorithm (QWOA) is one
such variational approach that has recently gained attention. In the broader
context of variational quantum algorithms (VQAs), understanding the
expressivity and trainability of the ansatz has proven critical for evaluating
their performance. A key method to study both these aspects involves analyzing
the dimension of the dynamic Lie algebra (DLA). In this work, we derive novel
upper bounds on the DLA dimension for QWOA applied to arbitrary optimization
problems. The consequence of our result is twofold: (a) it allows us to
identify complexity-theoretic conditions under which QWOA must be
overparameterized to obtain optimal or approximate solutions, and (b) it
implies the absence of barren plateaus in the loss landscape of QWOA for
$\mathsf{NP}$ optimization problems with polynomially bounded cost functions
($\mathsf{NPO}\text{-}\mathsf{PB}$).

</details>


### [239] [Generalized Holstein-Primakoff mapping and $1/N$ expansion of collective spin systems undergoing single particle dissipation](https://arxiv.org/abs/2508.05751)
*Diego Barberena*

Main category: quant-ph

TL;DR: 我们提出了一个适用于N个自旋1/2集合的广义变换，可以描述全局耦合系统及其相变。


<details>
  <summary>Details</summary>
Motivation: 需要一种适用于N个自旋1/2集合的广义变换，该变换具有弱置换对称性，能够描述单粒子耗散或有限温度下的全局耦合系统及其相变。

Method: 通过引入两个独立的玻色子变量来构建广义变换，该变量描述了相对于集体布洛赫矢量（由原始自旋1/2构成）的并行和横向涨落。利用这种表示，我们开发了一个系统的1/N展开，并明确写出了前导和次前导阶项。

Result: 我们开发了广义变换，并演示了其在四种系统中的应用：(i)经历自发辐射、不相干泵浦和单粒子退相干的原子系综；(ii)超辐射激光器；(iii)受不相干泵浦影响的横向场伊辛模型；(iv)迪克模型。

Conclusion: 这项工作提出了一个适用于具有弱置换对称性的N个自旋1/2集合的广义变换，该变换可以几何地描述受单粒子耗散或有限温度影响的全局耦合系统及其相变。

Abstract: We develop a generalization of the Schwinger boson and Holstein-Primakoff
transformations that is applicable to ensembles of $N$ spin $1/2$'s with weak
permutational symmetry. These generalized mappings are constructed by
introducing two independent bosonic variables that describe fluctuations
parallel and transverse to the collective Bloch vector built out of the
original spin $1/2$'s. Using this representation, we develop a systematic $1/N$
expansion and write down explicitly leading and next-to-leading order terms. We
then illustrate how to apply these techniques using four example systems: (i)
an ensemble of atoms undergoing spontaneous emission, incoherent pumping and
single particle dephasing; (ii) a superradiant laser above and in the vicinity
of the upper lasing transition; (iii) the all-to-all transverse field Ising
model subject to incoherent pumping in the vicinity of its ordering phase
transition; and (iv) the Dicke model at finite temperature both away and in the
vicinity of its thermal phase transition. Thus, these mappings provide a
common, Bloch-sphere based, geometrical description of all-to-all systems
subject to single particle dissipation or at finite temperature, including
their phase transitions.

</details>


### [240] [Benchmarking quantum computers with any quantum algorithm](https://arxiv.org/abs/2508.05754)
*Stefan K. Seritan,Aditya Dhumuntarao,Aidan Q. Wilber-Gauthier,Kenneth M. Rudinger,Antonio E. Russo,Robin Blume-Kohout,Andrew D. Baczewski,Timothy Proctor*

Main category: quant-ph

TL;DR: 提出了一种名为子电路体积基准测试（SVB）的可扩展方法，用于评估和跟踪量子计算机在实现大规模应用方面的进展。


<details>
  <summary>Details</summary>
Motivation: 当前的基于应用程序的基准测试在测试小规模问题实例时，可能无法代表效用规模问题，并且常常使用不可扩展的方法，这限制了它们跟踪向效用规模应用程序进展的能力。

Method: 提出了一种名为子电路体积基准测试（SVB）的方法，该方法通过运行从目标电路（可实现效用规模算法）中“剪切”出来的各种形状的子电路来进行基准测试。

Result: 通过在IBM Q系统上使用量子化学算法的哈密顿量块编码子程序进行演示，证明了SVB的可行性。

Conclusion: 所提出的子电路体积基准测试（SVB）方法可以从任何量子算法或应用程序创建可扩展且高效的基准测试，并能估计一个能力系数以简洁地总结实现目标电路的进展。

Abstract: Application-based benchmarks are increasingly used to quantify and compare
quantum computers' performance. However, because contemporary quantum computers
cannot run utility-scale computations, these benchmarks currently test this
hardware's performance on ``small'' problem instances that are not necessarily
representative of utility-scale problems. Furthermore, these benchmarks often
employ methods that are unscalable, limiting their ability to track progress
towards utility-scale applications. In this work, we present a method for
creating scalable and efficient benchmarks from any quantum algorithm or
application. Our subcircuit volumetric benchmarking (SVB) method runs
subcircuits of varied shape that are ``snipped out'' from some target circuit,
which could implement a utility-scale algorithm. SVB is scalable and it enables
estimating a capability coefficient that concisely summarizes progress towards
implementing the target circuit. We demonstrate SVB with experiments on IBM Q
systems using a Hamiltonian block-encoding subroutine from quantum chemistry
algorithms.

</details>


### [241] [Arbitrarily-high-dimensional reconciliation via cross-rotation for continuous-variable quantum key distribution](https://arxiv.org/abs/2508.06338)
*Jisheng Dai,Xue-Qin Jiang,Tao Wang,Peng Huang,Guihua Zeng*

Main category: quant-ph

TL;DR: 提出一种高维CV-QKD信息协调新方法，突破维度限制，提高效率，降低开销。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有CV-QKD中高维旋转闭合形式正交变换的缺失，该研究旨在突破维度限制，提高信息协调效率和传输距离。

Method: 通过将字符串向量重塑为矩阵形式，并以交叉方式对其列和行应用正交变换，实现维度提升和开销降低。

Result: 仿真结果表明，64维交叉旋转几乎接近理论上限，适用于实际应用。

Conclusion: 该研究提出了一种交叉旋转方案，突破了高维旋转的闭合形式正交变换限制，实现了任意高维度（限于8的偶数倍）的CV-QKD信息协调，并显著降低了经典信道通信开销。

Abstract: Multidimensional rotation serves as a powerful tool for enhancing information
reconciliation and extending the transmission distance in continuous-variable
quantum key distribution (CV-QKD). However, the lack of closed-form orthogonal
transformations for high-dimensional rotations has limited the maximum
reconciliation efficiency to channels with 8 dimensions over the past decade.
This paper presents a cross-rotation scheme to overcome this limitation and
enable reconciliation in arbitrarily high dimensions, constrained to even
multiples of 8. The key treatment involves reshaping the string vector into
matrix form and applying orthogonal transformations to its columns and rows in
a cross manner, thereby increasing the reconciliation dimension by one order
per cross-rotation while significantly reducing the communication overhead over
the classical channel. A rigorous performance analysis is also presented from
the perspective of achievable sum-rate. Simulation results demonstrate that
64-dimensional cross-rotation nearly approaches the upper bound, making it a
recommended choice for practical implementations.

</details>


### [242] [Modular Quantum Amplitude Estimation: A Scalable and Adaptive Framework](https://arxiv.org/abs/2508.05805)
*Alok Shukla,Prakash Vedula*

Main category: quant-ph

TL;DR: 量子幅度估计（QAE）在NISQ设备上是资源密集型的。我们提出了AWQAE，一个模块化、可扩展和自适应的框架，通过迭代地估计相位比特块来降低对量子比特数量的要求。它使用量子电路和经典后处理来提高精度和处理测量歧义，使其成为NISQ设备的理想选择。


<details>
  <summary>Details</summary>
Motivation: 标准的量子幅度估计（QAE）实现需要大量的相干量子比特在单个电路块中以实现高精度，这对近期的NISQ设备来说是一个重大挑战。AWQAE旨在解决这个问题。

Method: AWQAE通过迭代地以小块、固定大小的块来估计相位比特，使用多个较小、独立的量子电路来运行，这有利于并行处理。该框架引入了一个相位分辨率电路和一个辅助引导机制，以在存在多个本征态的情况下实现精确的块分配和本征相位重建。它结合了一个模块化的量子-经典循环和一个具有模糊意识的重建方法。

Result: AWQAE通过降低单块电路的电路深度和量子比特数量，减少了退相干和噪声的影响，使其具有NISQ兼容性。它通过一种解决测量歧义的经典后处理算法来确保准确性。

Conclusion: AWQAE是一个强大的、灵活的解决方案，用于在资源受限的量子硬件上执行高精度的QAE。该方法展示了增强的可扩展性和适应性，使其成为NISQ时代QAE实际应用的有希望的候选者。

Abstract: Quantum Amplitude Estimation (QAE) is a key primitive in quantum computing,
but its standard implementation using Quantum Phase Estimation is
resource-intensive, requiring a large number of coherent qubits in a single
circuit block to achieve high precision. This presents a significant challenge
for near-term Noisy Intermediate-Scale Quantum (NISQ) devices. To address this,
we introduce the Adaptive Windowed Quantum Amplitude Estimation (AWQAE)
framework, a modular, scalable and adaptive approach that decouples estimation
precision from the number of physical qubits required in a single circuit.
AWQAE operates by iteratively estimating the phase bits in small, fixed-size
chunks, using a number of smaller, independent quantum circuits, which are
amenable to parallel processing. A key technical contribution of this work is
introduction of a phase resolution circuit and an ancilla-guided mechanism that
enables accurate chunk assignment and eigenphase reconstruction in the presence
of multiple eigenstates. This design is inherently NISQ-friendly, by lowering
circuit depth and qubit count per block to reduce decoherence and noise
effects. A key component of our approach is a robust classical post-processing
algorithm that resolves measurement ambiguities that arise during the iterative
process. This post-processing routine uses a least-significant-bit
(LSB)-to-most-significant-bit (MSB) correction to reconstruct the full,
high-precision phase estimate, ensuring accuracy. By combining a modular
quantum-classical loop with an ambiguity-aware reconstruction method, AWQAE
offers a powerful and flexible solution for performing high-precision QAE on
resource-constrained quantum hardware. Our approach demonstrates enhanced
scalability, and adaptability, making it a promising candidate for practical
applications of QAE in the NISQ era.

</details>


### [243] [Riemann-Zeta-Regularisation of Feynman Path Integrals](https://arxiv.org/abs/2508.05815)
*Cyril Belardinelli*

Main category: quant-ph

TL;DR: A new method using zeta-function regularization was used to calculate the Feynman propagator for a charged particle in a specific potential and field, showing the zeta-function's suitability for divergent path integrals.


<details>
  <summary>Details</summary>
Motivation: To calculate the Feynman propagator of a charged particle in a complex system (anisotropic harmonic oscillator potential with a crossed electromagnetic field) using a conceptually new method.

Method: The Feynman propagator is calculated using a novel approach involving the expansion of the path variable into a complex Fourier series, transforming the path integral into an infinite product of Gaussian integrals. This divergent product is then regularized using the zeta-function.

Result: A method for regularizing divergent path integrals using the zeta-function has been developed and applied to calculate the Feynman propagator for the specified system. The study highlights the effectiveness of the zeta-function as a regularizer.

Conclusion: The zeta-function is a well-suited regularizer for divergent path integrals, as demonstrated by its application to the Feynman propagator of a charged particle in an anisotropic harmonic oscillator potential and a crossed electromagnetic field.

Abstract: The Feynman Propagator of a charged particle confined to an anisotropic
Harmonic Oscillator potential and moving in a crossed electromagnetic field is
calculated in a conceptually new way. The calculation is based on the expansion
of the path variable into a complex Fourier series. The path integral then
becomes an infinite product of Gaussian integrals. This product is divergent.
It turns out that we can regularize this product by using the zeta-function. It
is a remarkable fact that the zeta-function is so well suited as a
regularizator for divergent path integrals.

</details>


### [244] [Tailored First-order and Interior-point methods and a new semidefinite programming hierarchy for entanglement detection](https://arxiv.org/abs/2508.05854)
*Javier Pena,Vikesh Siddhu,Sridhar Tayur*

Main category: quant-ph

TL;DR: 本研究提出了一种新的SDP层级PST，并开发了相应的算法，以更有效、可扩展的方式检测量子纠缠，解决了现有方法的计算限制。


<details>
  <summary>Details</summary>
Motivation: 量子纠缠在量子信息科学中至关重要，但在高维或噪声系统中可靠地检测它仍然是一个基本的计算挑战。现有的SDP层级（如DPS和EXT）虽然提供了完整的检测方法，但由于问题规模的指数增长而限制了其实际应用。

Method: 通过紧凑的多项式可扩展描述（利用分区映射和算子）来构建EXT和PST层级，并基于这些描述开发了多种算法，包括基于最小二乘法的三个一阶方法（Frank-Wolfe、投影梯度和快速投影梯度）以及一个基于二次锥规划的自定义原始对偶内点法。

Result: 所提出的PST层级和算法在数值实验中能够更有效地解决更深层次的SDP问题。具体来说，PST层级结合一阶方法能有效处理相对容易的实例，而内点法在处理更困难的实例时则表现出鲁棒性并能进行早期对偶恢复。实验结果表明，根据层级结构定制算法配方能够促进大规模纠缠检测。

Conclusion: 该研究引入了一种新的SDP层级PST，它在EXT和DPS之间，为可分离态提供比EXT更精确的逼近，同时比DPS具有更低的计算开销。研究还开发了解决SDP层级问题的算法，并在基准量子态的数值实验中证明了其有效性。

Abstract: Quantum entanglement lies at the heart of quantum information science, yet
its reliable detection in high-dimensional or noisy systems remains a
fundamental computational challenge. Semidefinite programming (SDP)
hierarchies, such as the Doherty-Parrilo-Spedalieri (DPS) and Extension (EXT)
hierarchies, offer complete methods for entanglement detection, but their
practical use is limited by exponential growth in problem size. In this paper,
we introduce a new SDP hierarchy, PST, that is sandwiched between EXT and
DPS--offering a tighter approximation to the set of separable states than EXT,
while incurring lower computational overhead than DPS.
  We develop compact, polynomially-scalable descriptions of EXT and PST using
partition mappings and operators. These descriptions in turn yield formulations
that satisfy desirable properties such as the Slater condition and are
well-suited to both first-order methods (FOMs) and interior-point methods
(IPMs). We design a suite of entanglement detection algorithms: three FOMs
(Frank-Wolfe, projected gradient, and fast projected gradient) based on a
least-squares formulation, and a custom primal-dual IPM based on a conic
programming formulation. These methods are numerically stable and capable of
producing entanglement witnesses or proximity measures, even in cases where
states lie near the boundary of separability.
  Numerical experiments on benchmark quantum states demonstrate that our
algorithms improve the ability to solve deeper levels of the SDP hierarchy. In
particular, the PST hierarchy combined with FOMs enables scalable and effective
entanglement detection in relatively easy instances, while our IPM approach
offers robustness and early witness recovery for the more difficult ones. Our
results highlight the benefits of tailoring algorithmic formulations to
hierarchy structure to advance entanglement detection at scale.

</details>


### [245] [State-adaptive quantum error correction and fault-tolerant quantum computing](https://arxiv.org/abs/2508.06011)
*D. -S. Wang*

Main category: quant-ph

TL;DR: SAQEC 框架通过整合量子状态知识来改进量子纠错，从而在量子计算中实现更高的效率和更好的纠错性能。


<details>
  <summary>Details</summary>
Motivation: 弥合量子计算与纠错范式之间的差距，并展示了状态自适应在容错量子计算中的实际应用。

Method: 提出了一种状态自适应量子纠错（SAQEC）的理论框架，该框架将量子状态的知识纳入纠错过程，从而建立了由量子互信息而非相干信息决定的新容量体系。

Result: SAQEC 能够实现在不增加额外测量开销的情况下，提供增强的纠错能力。

Conclusion: SAQEC 在不增加额外测量开销的情况下，为容错量子计算提供了改进的纠错能力，并为量子信道容量提供了新的见解，同时为当前的量子计算平台提供了实现的优势。

Abstract: We present a theoretical framework for state-adaptive quantum error
correction (SAQEC) that bridges the gap between quantum computing and error
correction paradigms. By incorporating knowledge of quantum states into the
error correction process, we establish a new capacity regime governed by
quantum mutual information rather than coherent information. This approach
reveals a fundamental connection to entanglement-assisted protocols. We
demonstrate practical applications in fault-tolerant quantum computation,
showing how state-adaptivity enables enhanced error correction without
additional measurement overhead. The framework provides new insights into
quantum channel capacities while offering implementation advantages for current
quantum computing platforms.

</details>


### [246] [Federated Quantum Kernel-Based Long Short-term Memory for Human Activity Recognition](https://arxiv.org/abs/2508.06078)
*Yu-Chao Hsu,Jiun-Cheng Jiang,Chun-Hua Lin,Wei-Ting Chen,Kuo-Chung Peng,Prayag Tiwari,Samuel Yen-Chi Chen,En-Jui Kuo*

Main category: quant-ph

TL;DR: 本工作提出了Fed-QK-LSTM框架，将量子核方法和LSTM集成到联邦学习中，用于增强隐私敏感环境中的人类活动识别。该框架利用量子计算捕获复杂关系，并在RealWorld HAR数据集上取得了具有竞争力的准确性，尤其适用于边缘计算和稀疏量子设备。


<details>
  <summary>Details</summary>
Motivation: 在隐私敏感的环境中增强人类活动识别（HAR），并为分布式学习系统利用量子计算。

Method: 本工作提出了一种名为Federated Quantum Kernel-Based Long Short-term Memory (Fed-QK-LSTM)的框架，该框架将量子核方法和长短期记忆（LSTM）集成到联邦学习中。在该框架内，利用量子计算来增强隐私敏感环境中的人类活动识别（HAR）和分布式学习系统。每个客户端节点上的DeepConv-QK-LSTM架构采用卷积层来有效捕获局部模式，并使用浅层QK-LSTM来模拟HAR数据中的长期依赖关系。量子核方法使模型能够用更少的训练参数捕获多元时间序列数据中的复杂非线性关系。

Result: 实验结果表明，Fed-QK-LSTM框架在RealWorld HAR数据集上，在不同的客户端设置和本地训练轮次中，实现了具有竞争力的准确性。

Conclusion: Fed-QK-LSTM框架在不同的客户端设置和本地训练轮次中实现了具有竞争力的准确性，展示了其在真实应用中进行鲁棒且保护隐私的人类活动识别的潜力，尤其是在边缘计算环境和稀疏量子设备上。

Abstract: In this work, we introduce the Federated Quantum Kernel-Based Long Short-term
Memory (Fed-QK-LSTM) framework, integrating the quantum kernel methods and Long
Short-term Memory into federated learning.Within Fed-QK-LSTM framework, we
enhance human activity recognition (HAR) in privacy-sensitive environments and
leverage quantum computing for distributed learning systems.The
DeepConv-QK-LSTM architecture on each client node employs convolutional layers
for efficient local pattern capture, this design enables the use of a shallow
QK-LSTM to model long-range relationships within the HAR data.The quantum
kernel method enables the model to capture complex non-linear relationships in
multivariate time-series data with fewer trainable parameters.Experimental
results on RealWorld HAR dataset demonstrate that Fed-QK-LSTM framework
achieves competitive accuracy across different client settings and local
training rounds.We showcase the potential of Fed-QK-LSTM framework for robust
and privacy-preserving human activity recognition in real-world applications,
especially in edge computing environments and on scarce quantum devices.

</details>


### [247] [Near-Heisenberg-limited parallel amplitude estimation with logarithmic depth circuit](https://arxiv.org/abs/2508.06121)
*Kohei Oshio,Kaito Wada,Naoki Yamamoto*

Main category: quant-ph

TL;DR: 该研究提出了一种新的量子幅度估计算法（PAE），它使用GHZ态和Grover电路，实现了更快的速度和更低的电路深度，并适用于分布式量子计算。


<details>
  <summary>Details</summary>
Motivation: 量子幅度估计是量子算法的核心子程序，该研究旨在开发一种能够同时实现近乎海森堡极限的查询次数和亚线性电路深度的算法，以提高估计精度。

Method: 提出了一种并行化幅度估计（PAE）算法，该算法利用全局GHZ态和分离的低深度Grover电路，并通过量子信号处理技术进行构建。

Result: 该算法实现了近乎海森堡极限的总查询次数和关于估计精度的亚线性电路深度，并且可以针对GHZ态中的量子比特数量和每个电路的深度进行调整，从而实现近乎海森堡极限和对数深度的幅度估计。

Conclusion: 所提出的算法通过结合全局GHZ态和分离的低深度Grover电路，实现了近乎海森堡极限的总查询次数和亚线性电路深度的同时可扩展性，并利用量子信号处理技术构建，适用于分布式量子计算。

Abstract: Quantum amplitude estimation is one of the core subroutines in quantum
algorithms. This paper gives a parallelized amplitude estimation (PAE)
algorithm, that simultaneously achieves near-Heisenberg scaling in the total
number of queries and sub-linear scaling in the circuit depth, with respect to
the estimation precision. The algorithm is composed of a global GHZ state
followed by separated low-depth Grover circuits; the number of qubits in the
GHZ state and the depth of each circuit is tunable as a trade-off way, which
particularly enables even near-Heisenberg-limited and logarithmic-depth
algorithm for amplitude estimation. The quantum signal processing technique is
effectively used to build the algorithm. The proposed algorithm has a form of
distributed quantum computing, which may be suitable for device implementation.

</details>


### [248] [Quantum Optimization on Rydberg Atom Arrays with Arbitrary Connectivity: Gadgets Limitations and a Heuristic Approach](https://arxiv.org/abs/2508.06130)
*Pierre Cazals,Amalia Sorondo,Victor Onofre,Constantin Dalyac,Wesley da Silva Coelho,Vittorio Vitale*

Main category: quant-ph

TL;DR: 基于Rydberg原子阵列的量子系统在组合优化方面显示出潜力，但将任意图实例映射到该系统存在挑战。本研究提出了一种更高效的分治启发式方法，并证明了多项式归约的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了解决将任意图实例映射到基于Rydberg原子阵列的可编程量子系统时，使用归约小工具带来的实验开销和复杂性问题。

Method: 提出了一种分治启发式方法，该方法具有线性开销，并利用预校准的原子布局。

Result: 证明了从任意图到单位磁盘实例的任何多项式归约都会导致顶点数量的二次增长，并降低了解决方案的近似保证。

Conclusion: 研究提出了一个用于解决任意图实例的最大加权独立集问题的分治启发式方法，该方法仅具有线性开销，并且可以在Orion Alpha处理器上运行。

Abstract: Programmable quantum systems based on Rydberg atom arrays have recently
emerged as a promising testbed for combinatorial optimization. Indeed, the
Maximum Weighted Independent Set problem on unit-disk graphs can be efficiently
mapped to such systems due to their geometric constraints. However, extending
this capability to arbitrary graph instances typically necessitates the use of
reduction gadgets, which introduce additional experimental overhead and
complexity. Here, we analyze the complexity-theoretic limits of polynomial
reductions from arbitrary graphs to unit-disk instances. We prove any such
reduction incurs a quadratic blow-up in vertex count and degrades solution
approximation guarantees. As a practical alternative, we propose a
divide-and-conquer heuristic with only linear overhead which leverages
precalibrated atomic layouts. We benchmark it on Erd\"os-R\'enyi graphs, and
demonstrate feasibility on the Orion Alpha processor.

</details>


### [249] [Enhancing the Scalability of Classical Surrogates for Real-World Quantum Machine Learning Applications](https://arxiv.org/abs/2508.06131)
*Philip Anton Hernicht,Alona Sakhnenko,Corey O'Meara,Giorgio Cortiana,Jeanette Miriam Lorenz*

Main category: quant-ph

TL;DR: 本研究提出了一种更高效的方法来创建经典代理模型，从而能够在经典设备上运行量子机器学习模型，解决了量子硬件可用性限制的问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决量子机器学习（QML）在工业应用中受限于量子硬件可用性的问题，本研究探索了使用经典代理模型来绕过这一限制。

Method: 提出了一种替代性方法，通过最小化先前方法的冗余来生成经典代理模型，从而能够以前所未有的规模生成经典代理模型，并大大减少了所需的计算资源。

Result: 所提出的方法在能源需求预测问题上表现出有效性，并在模拟和量子硬件上进行了严格的性能和计算需求测试。结果表明，该方法在测试数据集上实现了高准确性，并且其计算资源需求是线性扩展而非指数扩展的。

Conclusion: 该研究提出了一种将量子模型转化为经典可部署版本的新方法，有助于加快量子技术在工业环境中的集成，并可作为在实际设置中寻找实际量子优势的有力研究工具。

Abstract: Quantum machine learning (QML) presents potential for early industrial
adoption, yet limited access to quantum hardware remains a significant
bottleneck for deployment of QML solutions. This work explores the use of
classical surrogates to bypass this restriction, which is a technique that
allows to build a lightweight classical representation of a (trained) quantum
model, enabling to perform inference on entirely classical devices. We reveal
prohibiting high computational demand associated with previously proposed
methods for generating classical surrogates from quantum models, and propose an
alternative pipeline enabling generation of classical surrogates at a larger
scale than was previously possible. Previous methods required at least a
high-performance computing (HPC) system for quantum models of below industrial
scale (ca. 20 qubits), which raises questions about its practicality. We
greatly minimize the redundancies of the previous approach, utilizing only a
minute fraction of the resources previously needed. We demonstrate the
effectiveness of our method on a real-world energy demand forecasting problem,
conducting rigorous testing of performance and computation demand in both
simulations and on quantum hardware. Our results indicate that our method
achieves high accuracy on the testing dataset while its computational resource
requirements scale linearly rather than exponentially. This work presents a
lightweight approach to transform quantum solutions into classically deployable
versions, facilitating faster integration of quantum technology in industrial
settings. Furthermore, it can serve as a powerful research tool in search
practical quantum advantage in an empirical setup.

</details>


### [250] [Diagonalizing large-scale quantum many-body Hamiltonians using variational quantum circuit and tensor network](https://arxiv.org/abs/2508.06159)
*Peng-Fei Zhou,Shuang Qiao,An-Chun Ji,Shi-Ju Ran*

Main category: quant-ph

TL;DR: TNVD通过将量子哈密顿量谱编码到矩阵乘积态，并将特征态编码为VQC演化，将对角化复杂度从指数级降至多项式级，并能处理大系统和体-熵哈密顿量。


<details>
  <summary>Details</summary>
Motivation: 精确对角化（ED）是探索量子多体物理学的基本工具，但其计算复杂度随系统大小呈指数增长，这是一个根本性的限制。

Method: TNVD将量子多体哈密顿量的整个特征能量谱编码到矩阵乘积态中，并将特征态编码为变分量子线路（VQC）的乘积态演化。

Result: TNVD将对角化计算复杂度从指数级降低到系统中N的大小呈多项式级。通过高达N=100个自旋的数值基准测试，证明了TNVD的有效性，远超ED的计算极限。此外，还揭示了TNVD效率与特征态纠缠性质之间的依赖关系，并通过纠缠熵（EE）与特征能量以及态密度与EE的分布等典型特征，为判断是否存在体-熵或其违反提供了指示。

Conclusion: TNVD是一种强大且可扩展的对角化方法，适用于大规模量子多体哈密顿量。VQC的结合为应用量子计算解决了经典方法难以处理的体-熵哈密顿量提供了有前景的途径。

Abstract: Exact diagonalization (ED) is an essential tool for exploring quantum
many-body physics but is fundamentally limited by the exponentially-scaled
computational complexity. Here, we propose tensor network variational
diagonalization (TNVD), which encodes the full eigenenergy spectrum of a
quantum many-body Hamiltonian into a matrix product state, and encodes the
eigenstates as the evolutions of product states using variational quantum
circuit (VQC). Thereby, TNVD reduces the computational complexity of
diagonalization from exponential to polynomial in system size $N$. Numerical
benchmarks up to $N=100$ spins are provided, which far surpass the
computational limit of ED. We further consider quantum Ising model in a random
field to reveal the underlying reliance between the efficiency of TNVD and
entanglement properties of eigenstates. Typical signs, including the
distribution of entanglement entropy (EE) versus eigenenergy and the density of
state versus EE, are suggested to indicate area law of entanglement entropy or
its violation, which are essential to the TNVD efficiency. Our work establishes
TNVD as a powerful and scalable diagonalization approach for large-scale
quantum many-body Hamiltonians. The incorporation of VQC lays a promising
pathway to applying quantum computation to address the volume-law-EE
Hamiltonians that lack efficient classical approaches.

</details>


### [251] [Fast simulations of continuous-variable circuits using the coherent state decomposition](https://arxiv.org/abs/2508.06175)
*Olga Solodovnikova,Ulrik L. Andersen,Jonas S. Neergaard-Nielsen*

Main category: quant-ph

TL;DR: lcg_plus是一个用于模拟量子电路的Python库，可以处理非高斯态和低效组件，并能优化量子态的制备。


<details>
  <summary>Details</summary>
Motivation: 为了实现容错光子量子计算，需要高效制备关键的量子态，例如qunaught态。现有的模拟方法在处理包含低效组件的量子电路时存在挑战。本研究旨在开发一个能够准确高效模拟连续变量量子电路（包括非高斯态和低效组件）的框架，以支持量子态的优化制备。

Method: 该研究提出了lcg_plus，一个开源Python库，实现了连续变量量子电路的模拟。该方法结合了高斯态线性组合（lcg）和相干态分解技术，能够处理任意非高斯态。通过追踪Wigner函数，模拟高斯通道和测量操作，并推导了量子态质量度量的解析梯度，用于优化含低效组件的量子电路。

Result: lcg_plus库能够快速准确地模拟连续变量量子电路，包括非高斯态和低效组件。通过追踪Wigner函数，可以模拟高斯通道和测量操作。该库还支持计算量子态质量度量的解析梯度，并成功应用于优化高斯玻色子采样电路中qunaught态的制备。

Conclusion: 该研究提出了lcg_plus，一个开源Python库，用于模拟具有连续变量、通用测振和光子数分辨探测器能力的量子电路。该框架结合了高斯态线性组合方法和任意非高斯态相干态分解，弥合了高斯和fock基表示之间的差距。通过追踪Wigner函数，该方法能够快速准确地模拟高斯通道和测量在多模系统上的作用，并方便地计算量子态的质量度量。此外，研究还导出了这些度量相对于参数化电路元件的解析梯度表达式。最后，通过优化高斯玻色子采样电路制备qunaught态的初步制备，证明了该方法在包含低效组件的情况下，对于构建容错光子量子计算机至关重要。

Abstract: We present \texttt{lcg\_plus}, an open-source Python library for the
simulation of continuous-variable quantum circuits with both generaldyne and
photon-number-resolving detector capabilities. Our framework merges the linear
combination of Gaussians methodology with the coherent state decomposition of
arbitrary non-Gaussian states, forming a bridge between the Gaussian and Fock
basis representations. By tracking the Wigner function, we can simulate the
action of Gaussian channels and measurements on multi-mode systems in a fast
and accurate numerical framework. The calculation of the quality measures of
quantum states is convenient in this formalism, and we derive expressions for
the analytical gradients of these measures with respect to parameterized
circuit elements. We demonstrate the utility of this methodology by optimizing
the heralded preparation of a qunaught state, a crucial component for building
a fault-tolerant photonic quantum computer, with a Gaussian Boson sampling
circuit containing inefficient components.

</details>


### [252] [Scalable Quantum State Preparation for Encoding Genomic Data with Matrix Product States](https://arxiv.org/abs/2508.06184)
*Floyd M. Creevey,Hitham T. Hassan,James McCafferty,Lloyd C. L. Hollenberg,Sergii Strelchuk*

Main category: quant-ph

TL;DR: This paper presents a method using Matrix Product States to encode genomic data into quantum circuits, demonstrating its effectiveness for quantum bioinformatics applications.


<details>
  <summary>Details</summary>
Motivation: The increasing need for algorithms to load classical data into quantum states as quantum computing hardware advances, particularly for applications in quantum bioinformatics.

Method: A method for producing scalable quantum circuits to encode genomic data using the Matrix Product State (MPS) formalism is presented and illustrated by encoding the genome of the bacteriophage $\Phi X174$ into a 15-qubit state.

Result: The study analyzes trade-offs between MPS bond dimension, reconstruction error, and circuit complexity, and demonstrates the viability and utility of the encoding through circuit generation and simulation on HPC and current quantum hardware.

Conclusion: The study demonstrates the viability and utility of the proposed MPS-based method for encoding genomic data into quantum states, showing potential for quantum bioinformatics.

Abstract: As quantum computing hardware advances, the need for algorithms that
facilitate the loading of classical data into the quantum states of these
devices has become increasingly important. This study presents a method for
producing scalable quantum circuits to encode genomic data using the Matrix
Product State (MPS) formalism. The method is illustrated by encoding the genome
of the bacteriophage $\Phi X174$ into a 15-qubit state, and analysing the
trade-offs between MPS bond dimension, reconstruction error, and the resulting
circuit complexity. This study proposes methods for optimising encoding
circuits with standard benchmark datasets for the emerging field of quantum
bioinformatics. The results for circuit generation and simulation on HPC and on
current quantum hardware demonstrate the viability and utility of the encoding.

</details>


### [253] [The loss tolerance of cat breeding for fault-tolerant grid state generation](https://arxiv.org/abs/2508.06193)
*Olga Solodovnikova,Ulrik L. Andersen,Jonas S. Neergaard-Nielsen*

Main category: quant-ph

TL;DR: A new method to simulate the cat breeding protocol for GKP states shows that loss above 4% prevents fault-tolerant GKP state preparation.


<details>
  <summary>Details</summary>
Motivation: Analyzing the performance of the cat breeding protocol under loss is cumbersome due to exponential scaling.

Method: Representing the Wigner function of the input states as a linear combination of Gaussians to simulate the breeding protocol.

Result: Optical loss decreases the overall success probability of the protocol.

Conclusion: If optical loss exceeds 4%, it prevents the preparation of a fault-tolerant GKP state.

Abstract: The development of a continuous-variable photonic quantum computer depends on
the reliable preparation of high-quality Gottesman-Kitaev-Preskill states. The
most promising GKP preparation scheme is the cat breeding protocol, which can
generate GKP states deterministically given a source of squeezed cat states,
using beam splitters, homodyne detectors and a feedforward displacement.
However, analyzing the performance of the protocol under loss is cumbersome due
to the exponential scaling of the system. By representing the Wigner function
of the input states as a linear combination of Gaussians, we are able to
quickly and accurately simulate several rounds of breeding with mixed input
states. Using this novel method, we find that optical loss decreases the
overall success probability of the protocol, and prohibits the preparation of a
fault-tolerant GKP state when the loss exceeds 4\%. Our methodology is
available as open-source code.

</details>


### [254] [Detecting entanglement between quantum emitters using directional emission](https://arxiv.org/abs/2508.06210)
*Ivan Saychenko,Robert Weiss,Rita Veilande,Scott Parkins,Mark Sadgrove,Sandro Wimberger*

Main category: quant-ph

TL;DR: 光子发射方向性与量子纠缠相关，可用于估算纠缠度。


<details>
  <summary>Details</summary>
Motivation: 研究高方向性光子发射是否意味着发射体之间存在高度量子关联。

Method: 通过理论分析展示了光子发射方向性和发射体-发射体纠缠之间的关系。

Result: 光子发射方向性和发射体-发射体纠缠之间存在单调关系，且在合理实验条件下，光子发射方向性的测量统计可用于估计发射体之间的并发度。

Conclusion: 可定向光子发射和发射体-发射体纠缠在大部分参数范围内存在单调关系，但在完美方向性极限下会失效。

Abstract: Recently, it was shown that quantum interference in a system containing a
polarized and unpolarized emitter can allow directional emission of photons
into a circulating cavity. Here, we ask whether high directionality of photon
emission in this system implies a high degree of quantum correlation between
the two emitters. We show that the answer is a qualified "yes", with photon
emission directionality and emitter-emitter entanglement showing a monotonic
relationship over a broad parameter range. The relationship only breaks down in
the limit of perfect directionality. Furthermore, under reasonable assumptions
for experimental parameters and stability, we show that the statistics of
measured directionality allow a reliable estimate of the concurrence. This
result implies that directionality of photon emission in the state preparation
stage can be used to determine the entanglement between the emitters, with
potential applications to more generic cases including quantum networks.

</details>


### [255] [Aspheric lens design proposal for near-perfect mode-matching of a broadband quantum dot micropillar to a single-mode fibre](https://arxiv.org/abs/2508.06223)
*Yichen Zhang,David Dlaka,James McDougall,James Y Tai,Petros Androvitsaneas,Edmund Harbord,Ruth Oulton,Andrew B. Young*

Main category: quant-ph

TL;DR: 通过在量子点微柱中添加SiO2微透镜，解决了光子耦合效率低的问题，提高了端到端效率，为量子技术的发展奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 量子点微柱是制造明亮、确定性单光子源的有希望的选择，但输出模式的大数值孔径限制了其与单模光纤的耦合效率，阻碍了其在量子计算和通信中的应用。

Method: 在本研究中，我们提出了一种在量子点微柱中加入非球面SiO2微透镜的方法，以解决输出模式大数值孔径导致的光子耦合效率低的问题。

Result: 通过引入SiO2微透镜，将单模光纤的模式匹配损耗从83.1%降低到0.1%以下，使单光子源的端到端效率达到96.4%。

Conclusion: 通过添加精心设计的非球面SiO2微透镜，可以将模式匹配损耗从83.1%降低到0.1%以下，从而实现96.4%的端到端效率，为可扩展的光子量子技术铺平道路。

Abstract: Quantum dots in micropillars are one of the most promising options for a
bright, deterministic single photon source. While highly efficient devices
(>95%) have been designed, there remains a significant bottleneck that impacts
the overall system efficiency: the large numerical aperture of the output mode.
This leads to inefficient coupling of emitted photons into single-mode fibre,
thus limiting practical integration into quantum computing and communication
architectures. We show that with the addition of a well designed aspheric SiO2
microlens we can decrease the mode-matching losses to a SMF from 83.1% to
<0.1(0.1)%. This can result in a single photon source design with 96.4(0.1)%
end-to-end efficiency, paving the way for scalable photonic quantum
technologies.

</details>


### [256] [Space and Time Cost of Continuous Rotations in Surface Codes](https://arxiv.org/abs/2508.06236)
*Zhu Sun,Balint Koczor*

Main category: quant-ph

TL;DR: Continuous rotations are hard in quantum computers. Catalyst towers can make them more efficient in surface codes, especially for early applications needing faster runs, but conventional methods might be better for larger, more complex setups.


<details>
  <summary>Details</summary>
Motivation: To determine the most efficient approach for implementing continuous rotations in a surface code architecture, considering total runtime and space rather than just T-count/T-depth, especially for applications like option pricing.

Method: Explicit construction of surface code layouts for catalyst towers and analysis of their spacetime volume and runtime compared to conventional Clifford+T synthesis, considering factors like code distance and ancilla qubits.

Result: At small and medium code distances, catalyst towers reduce runtime and spacetime volume for rotations. However, at large code distances, conventional Clifford+T synthesis may be more efficient. The conclusions are sensitive to specific applications and parameter choices.

Conclusion: Catalyst towers may be particularly advantageous for early fault-tolerant quantum applications, especially when spacetime tradeoffs are needed to reduce runtime, though conventional Clifford+T synthesis may be more efficient at large code distances.

Abstract: While Clifford operations are relatively easy to implement in fault-tolerant
quantum computers,continuous rotation gates remain a significant bottleneck in
typical quantum algorithms. In this work, we ask the question: "What is the
most efficient approach for implementing continuous rotations in a surface code
architecture?" Several techniques have been developed to reduce the T-count or
T-depth of rotations, such as Hamming weight phasing and catalyst towers.
However, these methods often require additional a number of ancilla qubits, and
thus the ultimate cost function one needs to optimise against should rather be
the total runtime or the total space required for performing a rotation. We
explicitly construct surface code layouts for catalyst towers in two practical
application examples in the context of option pricing: (a) implementing a phase
oracle circuit, which is a ubiquitous subroutine in many quantum algorithms,
and (b) state preparation using a variational quantum circuit. Our analysis
shows that, at small and medium code distances, catalyst towers not only reduce
the runtime but can also decrease the total spacetime volume of rotations.
However, at large code distances, conventional Clifford+T synthesis may prove
more efficient. Additionally, we note that our conclusions are sensitive to
specific application scenarios and the choices of various parameters.
Nevertheless, catalyst towers may be particularly advantageous for early
fault-tolerant quantum applications, where low and medium code distances are
assumed and a spacetime tradeoff is needed to reduce the runtime of individual
circuit runs, such as in scenarios involving high circuit repetition counts.

</details>


### [257] [Supercoherence: Harnessing Long-Range Interactions to Preserve Collective Coherence in Disordered Systems](https://arxiv.org/abs/2508.06238)
*Alexey Gorlach,Andrea Pizzi,Klaus Mølmer,Joseph Avron,Mordechai Segev,Ido Kaminer*

Main category: quant-ph

TL;DR: 合成量子系统中的无序性会导致退相干，限制其可扩展性。本研究引入长程相互作用，发现了“超相干”现象，有效缓解了退相干，稳定了量子态，并为量子信息处理提供了新机遇。


<details>
  <summary>Details</summary>
Motivation: 为了解决合成量子系统固有的无序性导致的快速退相干问题，以及其在量子信息科学中对可扩展性的限制。

Method: 通过引入少量长程相互作用来缓解退相干，在高度对称的集体激发态中产生持久的集体相干。

Result: 引入少量长程相互作用可以缓解退相干，产生持久的集体相干，并证明了“超相干”现象的鲁棒性，即使在高达临界相互作用强度和无序度的动力学相变下也能保持。

Conclusion: 该研究发现了“超相干”现象，可以稳定退火、相干性和其他量子态属性，并挑战了退火在无序相互作用量子系统中不可避免性的传统观点，为量子内存和信息处理开辟了新机会。

Abstract: Artificial quantum systems with synthetic dimensions enable exploring novel
quantum phenomena difficult to create in conventional materials. These
synthetic degrees of freedom increase the system's dimensionality without
altering its physical structure, accessing higher-dimensional physics in
lower-dimensional setups. However, synthetic quantum systems often suffer from
intrinsic disorder, causing rapid decoherence that limits scalability, a major
obstacle in quantum information science. Here, we show that introducing just a
few long-range interactions can mitigate decoherence, creating persistent
collective coherence in highly symmetric collective excited states. We term
this universal phenomenon "supercoherence" and show its exceptional robustness
against disorder up to a dynamical phase transition at critical interaction
strength and disorder. Supercoherence stabilizes not only coherence but also
all other quantum properties of the states, challenging traditional views on
the inevitability of decoherence in disordered interacting quantum systems and
suggesting new opportunities for quantum memory and information processing.

</details>


### [258] [Cavity-based optical switching via phase modulation in warm rubidium vapor](https://arxiv.org/abs/2508.06255)
*Georgia Booton,Tabijah Wasawo,William O. C. Davis,Cameron McGarry,K. R. Rusimova,Alex O. C. Davis,Josh Nunn,Peter J. Mosley*

Main category: quant-ph

TL;DR: 一种利用铷蒸气实现全光控制的光开关，速度快、损耗低、消光比高，可用于量子计算。


<details>
  <summary>Details</summary>
Motivation: 可扩展、容错的光子量子计算中的光学开关仍然是一个关键的挑战，因为速度、带宽和损耗之间存在权衡。

Method: 全光控制

Result: 实现了 22 ns 的上升时间、2.4 dB 的插入损耗和 17.5 dB 的消光比。

Conclusion: 可扩展的量子光子学需要高速、高带宽和低损耗，而我们提出的基于腔的光开关克服了这一限制，实现了 22 ns 的上升时间、2.4 dB 的插入损耗和 17.5 dB 的消光比。该开关通过失谐于温热铷蒸气中近简并双光子吸收梯的光信号场相位调制实现全光控制。

Abstract: Optical switching remains a key outstanding challenge for scalable
fault-tolerant photonic quantum computing due to the trade-off between speed,
bandwidth, and loss. Scalable quantum photonics demands all three, to enable
high computational clock rates and resource efficient scaling to large systems.
We present a cavity-based optical switch that overcomes this limitation,
demonstrating 22 ns rise time, insertion loss of 2.4 dB, and 17.5 dB extinction
ratio. All-optical control is achieved via phase modulation of a signal field
detuned from the near-degenerate two-photon absorption ladder in warm rubidium
vapor. The ultimate performance of our switch, combining both speed and
efficiency, will find applications in active multiplexing, loop-based quantum
memory, and feedforward for quantum error-correction protocols.

</details>


### [259] [Secure Hybrid Key Growing via Coherence Witnessing and Bipartite Encoding](https://arxiv.org/abs/2508.06294)
*Pol Julià Farré,Chris Aaron Schneider,Christian Deppe*

Main category: quant-ph

TL;DR: 提出了一种新的量子密钥分发协议（HKG），利用光子数和时间 म्हणूनच自由度，提高了密钥生成速率和安全性，并适用于实际应用。


<details>
  <summary>Details</summary>
Motivation: 为了提高量子密钥分发的效率和实用性，通过同时利用多个自由度并减少对特定实验设备的要求。

Method: 提出了一种基于量子原理和经典物理层假设的混合密钥增长（HKG）协议，该协议同时利用了量子光子数和光子时间 म्हणूनच自由度（DoFs），并将实体认证集成到协议中，避免了对单光子源或探测器的依赖，并能主动缓解噪声。

Result: 仿真结果显示，HKG协议能减少量子比特误率（QBER），在低光子损耗和退相干的情况下，能够有效检测窃听和身份伪造，并有望提高密钥生成速率。

Conclusion: 该协议通过利用量子信道信息和减少量子比特误率来提高密钥生成速率，同时保持窃听和身份伪造检测能力。

Abstract: We propose a novel Hybrid Key Growing (HKG) protocol based on quantum
principles and a classical physical-layer assumption. We simultaneously exploit
the quantum photon-number and photon-time-bin Degrees of Freedom (DoFs),
effectively doubling the bit-per-pulse rate compared to conventional Quantum
Key Growing (QKG) schemes. Our protocol integrates entity authentication, and
is designed for practical implementation by avoiding reliance on single-photon
sources or detectors. By incorporating prior knowledge about the quantum
channel, the scheme actively mitigates noise effects, making it suitable for
real-world conditions. Under certain assumptions on experimental efficiencies,
our approach also promises an increased key generation rate in bits per second.
Our simulation results display, first, expected outcomes to gain assurance
about the correctness of our implementation and, second, relevant dependencies
that showcase desirable properties of our scheme in regimes of low photon loss
and dephasing. In particular, within such regimes, our encoding scheme reduces
the Quantum Bit Error Rate (QBER) while preserving the ability to detect
eavesdropping and identity-forgery attempts.

</details>


### [260] [Shortcuts to adiabaticity with a quantum control field](https://arxiv.org/abs/2508.06304)
*Emma C. King,Giovanna Morigi,Raphaël Menu*

Main category: quant-ph

TL;DR: 量子绝热计算和量子退火的加速可以通过设计经典场来抑制不想要的非绝热过程。本研究提出一种新的方法，通过将量子比特与第二个量子系统耦合，利用自主量子动力学来抑制兰道-泽纳模型中的非绝热跃迁，并将不需要的过程的概率降低了两个数量级以上。


<details>
  <summary>Details</summary>
Motivation: 量子绝热动力学是量子绝热计算和量子退火的关键因素。绝热性捷径可以通过设计经典场来抑制不想要的非绝热过程，从而加速计算时间。

Method: 本研究考虑了兰道-泽纳模型中的量子态转移，该模型例证了量子绝热动力学的关键要素。通过将兰道-泽纳量子比特与第二个量子系统耦合，利用自主量子动力学抑制了非绝热跃迁。

Result: 该方法能够将不需要的过程的概率降低两个数量级以上。

Conclusion: 通过调整耦合强度，复合量子动力学可以将不需要的过程的概率降低两个数量级以上。这是量子性质的控制场实现绝热性捷径的一个主要例子。

Abstract: Quantum adiabatic dynamics is the crucial element of adiabatic quantum
computing and quantum annealing. Shortcuts to adiabaticity enable acceleration
of the computational time by suppressing unwanted non-adiabatic processes with
designed classical fields. Here, we consider quantum state transfer in the
Landau-Zener model, which exemplifies the key elements of quantum adiabatic
dynamics. We argue that non-adiabatic transitions can be suppressed by
autonomous quantum dynamics, which involves coupling the Landau-Zener qubit to
a second quantum system. By tuning the coupling strength, the composite quantum
dynamics can reduce the probability of unwanted processes by more than two
orders of magnitude. This is a prime example of control where the quantum
properties of the control fields are key for implementing shortcuts to
adiabaticity.

</details>


### [261] [Quantum Algorithm for Estimating Intrinsic Geometry](https://arxiv.org/abs/2508.06355)
*Nhat A. Nghiem,Tuan K. Do,Tzu-Chieh Wei,Trung V. Phan*

Main category: quant-ph

TL;DR: 量子算法可加速几何数据分析，实现指数级加速，用于降维、特征提取和异常检测。


<details>
  <summary>Details</summary>
Motivation: 高维数据集通常围绕低维流形聚集，但常常带有严重噪声，这会模糊对下游学习任务至关重要的内在几何形状。因此，需要一种能够估计点云局部内在维度和局部标量曲率的方法，这些量对于降维、特征提取和异常检测至关重要。

Method: 提出了一种量子算法，该算法接收带有成对几何距离的数据集，并输出给定点的局部维度和曲率的估计值。

Result: 所提出的量子算法在估计局部内在维度和局部标量曲率方面，实现了相对于其经典对应算法的指数级加速。此外，该技术还可扩展到扩散映射，实现了相对于现有量子算法的指数级改进。

Conclusion: 该研究提出了一个用于估计点云局部几何形状（局部内在维度和局部标量曲率）的量子算法，为几何数据分析和流形学习开辟了一条新的、可扩展的量子增强路径。

Abstract: High-dimensional datasets typically cluster around lower-dimensional
manifolds but are also often marred by severe noise, obscuring the intrinsic
geometry essential for downstream learning tasks. We present a quantum
algorithm for estimating the intrinsic geometry of a point cloud --
specifically its local intrinsic dimension and local scalar curvature. These
quantities are crucial for dimensionality reduction, feature extraction, and
anomaly detection -- tasks that are central to a wide range of data-driven and
data-assisted applications. In this work, we propose a quantum algorithm which
takes a dataset with pairwise geometric distance, output the estimation of
local dimension and curvature at a given point. We demonstrate that this
quantum algorithm achieves an exponential speedup over its classical
counterpart, and, as a corollary, further extend our main technique to
diffusion maps, yielding exponential improvements even over existing quantum
algorithms. Our work marks another step toward efficient quantum applications
in geometrical data analysis, moving beyond topological summaries toward
precise geometric inference and opening a novel, scalable path to
quantum-enhanced manifold learning.

</details>


### [262] [The Dual Role of Low-Weight Pauli Propagation: A Flawed Simulator but a Powerful Initializer for Variational Quantum Algorithms](https://arxiv.org/abs/2508.06358)
*Zong-Liang Li,Shi-Xin Zhang*

Main category: quant-ph

TL;DR: LWPP算法虽不能准确模拟VQA电路，但其优化能力的近似特性可用于优化VQA的初始参数，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 研究是否可以利用经典方法（特别是LWPP算法）来辅助VQA的参数优化过程。

Method: 提出使用低权重泡利传播（LWPP）算法作为经典预优化器，为VQA主优化循环找到更优的初始参数。

Result: LWPP可以作为VQA的经典预优化器，显著提高优化性能，而非直接模拟器。在Heisenberg模型上的测试表明，该方法能将最终精度和收敛速度提高一个数量级。

Conclusion: VQAs的优化问题可以通过使用LWPP作为经典预优化器来缓解，从而提高最终精度和收敛速度，并降低近期量子硬件的计算负担。

Abstract: Variational quantum algorithms (VQAs) rely on a classical optimizer to tune a
parameterized quantum circuit, raising the question of whether classical
methods can assist in this process. In this work, we investigate the low-weight
Pauli propagation (LWPP) algorithm as a potential classical tool for simulating
the VQA circuit. We first find that LWPP is an unreliable estimator of the true
energy, limiting its utility as a direct simulator. However, we uncover its
real value: despite this numerical inaccuracy, its approximate optimization
landscape robustly guides parameters toward high-quality basins of attraction.
We therefore propose harnessing LWPP not for simulation, but as a classical
pre-optimizer to find superior initial parameters for the main VQA loop.
Benchmarking this strategy on Heisenberg models, we demonstrate a remarkable
enhancement in both the final accuracy and convergence rate, typically by an
order of magnitude, over standard heuristics. Our work thus reframes LWPP from
a flawed simulator into a powerful classical pre-processor that effectively
mitigates the notorious optimization challenges in VQAs and reduces the
computational burden on near-term quantum hardware.

</details>


### [263] [SQUID G.A.M.E.: Gamma, Atmospheric, and Mono-Energetic Neutron Effects on Quantum Devices](https://arxiv.org/abs/2508.06362)
*Gioele Casagranda,Elizabeth Auden,Carlo Cazzaniga,Maria Kastriotou,Christopher Frost,Marzio Vallero,Flavio Vella,Paolo Rech*

Main category: quant-ph

TL;DR: SQUID量子设备对中子辐射敏感，但对伽马射线不敏感，实验和模拟都证实了这一点。


<details>
  <summary>Details</summary>
Motivation: 量子设备在包括医疗成像、精密磁场测量、凝聚态物理和克服经典计算限制在内的多种研究应用中具有潜力。超导技术是目前科学研究和工业应用的研究重点，但在性能和可扩展性方面表现优异，然而，超导量子系统极易发生退相干，并且对辐射事件高度敏感。

Method: 通过将SQUID暴露于不同能量的中子束和伽马射线，并使用Geant4模拟来分析其响应。

Result: 实验表明，SQUID对两种中子场敏感，而1.25 MeV的伽马射线对其影响不大。通过实验，可以表征SQUID的响应，并根据故障的形状和持续时间对故障进行分类，分为长期的“猝发”和短期的“峰值”。Geant4模拟突出了沉积光谱和能量传播的差异，但也预测了SQUID在这两种情况下的脆弱性。

Conclusion: SQUID设备对中子辐射敏感，对伽马射线不敏感，并且可以根据故障的形状和持续时间对故障进行分类。

Abstract: Quantum devices are a promising solution to many research applications,
including medical imaging, precision magnetic field measurements, condensed
matter physics, and overcoming the limits of classical computing. Among the
available implementations, the superconducting technology is the current focus
of scientific research and industrial applications, excelling in performance
and scalability. Despite this, superconducting quantum systems are extremely
prone to decoherence, and in particular, they are highly sensitive to radiation
events. In this paper, we analyze the response of a superconducting device
(SQUID) to radiation. We expose the SQUID to beams of monoenergetic 14 MeV
neutrons (NILE - ISIS), atmospheric 1-800 MeV neutrons (ChipIR - ISIS), and
gamma rays with 1.25 MeV average energy (CALLIOPE - ENEA). These experiments
show that the SQUID is sensitive to the two neutron fields, while gamma rays at
1.25 MeV leave it mostly unaffected. Following our experiments with neutrons,
it is possible to characterize the SQUID's response and even classify faults
according to their shape and duration. We identify two categories: bursts (long
lasting) and peaks (short lived). To investigate the different responses to
neutrons and gamma rays, we employ Geant4 simulations, which highlight
differences in the deposition spectra and the energy propagation, but likewise
predict the vulnerability of the SQUID in both cases.

</details>


### [264] [Design and analysis of a set of discrete variable protocols for secure quantum communication](https://arxiv.org/abs/2508.06380)
*Arindam Dutta*

Main category: quant-ph

TL;DR: 本论文回顾了现有的量子身份认证（QIA）协议，并提出了一系列新的基于受控安全直接量子通信的QIA协议，旨在提高安全性。此外，还提出了两种无需纠缠或理想单光子源的新型量子密钥分发（QKD）协议，并证明了其安全性，同时提出了改进QKD性能的方法。


<details>
  <summary>Details</summary>
Motivation: 为了应对量子密钥分发（QKD）中身份认证的漏洞，以及实现更实际、更安全的通信。

Method: 对现有的量子身份认证（QIA）协议进行了回顾和分类，然后基于识别出的对称性设计了新的QIA方案，并利用Bell态和受控安全直接量子通信进行身份认证。同时，开发了两种新的QKD协议，并进行了安全分析和与现有方案的比较。

Result: 提出了一套新的基于受控安全直接量子通信的QIA协议，并证明了其对多种攻击的鲁棒性。同时，提出了两种无需纠缠或理想单光子源的新型QKD协议，并建立了关键速率边界。

Conclusion: 该论文提出了一系列新的量子身份认证（QIA）协议，这些协议利用受控安全直接量子通信，并通过第三方（Charlie）协助Alice和Bob进行相互认证。此外，还提出了两个新的量子密钥分发（QKD）协议，无需纠缠或理想单光子源，并证明了其安全性。

Abstract: The advent of quantum key distribution (QKD) has revolutionized secure
communication by providing unconditional security, unlike classical
cryptographic methods. However, its effectiveness relies on robust identity
authentication, as vulnerabilities in the authentication process can cause a
compromise with the security of the entire communication system. Over the past
three decades, numerous quantum identity authentication (QIA) protocols have
been proposed. This thesis first presents a chronological review of these
protocols, categorizing them based on quantum resources and computational tasks
involved while analyzing their strengths and limitations. Subsequently, by
recognizing inherent symmetries present in the existing protocols, we design
novel QIA schemes based on secure computational and communication tasks.
Specifically, this work introduces a set of new QIA protocols that utilize
controlled secure direct quantum communication. The proposed scheme facilitates
mutual authentication between two users, Alice and Bob, with assistance from a
third party, Charlie, using Bell states. A comprehensive security analysis
demonstrates its robustness against impersonation, intercept-resend, and
fraudulent authentication attacks. The comparative evaluation highlights its
advantages over existing schemes. Additionally, this thesis presents two novel
QKD protocols that eliminate the need for entanglement or ideal single-photon
sources, making them feasible with commercially available photon sources. These
protocols are rigorously proven to be secure against various attacks, including
intercept-resend and certain collective attacks. Key rate bounds are
established, demonstrating that specific classical pre-processing enhances the
tolerable error threshold. PHD THESIS

</details>


### [265] [Quasi-stationary normal states for quantum Markov semigroups](https://arxiv.org/abs/2508.06396)
*Ameur Dhahri,Franco Fagnola,Federico Girotti,Hyun Jae Yoo*

Main category: quant-ph

TL;DR: 在量子马尔可夫半群的背景下，我们引入了准稳态（QSS）的概念，并提供了其操作解释，同时证明了QSS与该半群的谱性质之间的联系。


<details>
  <summary>Details</summary>
Motivation: 在量子马尔可夫半群的背景下引入了准稳态（QSS）的概念，泛化了经典马尔可夫链中准稳态分布的概念

Method: 通过直接和间接量子测量理论提供QSS的操作解释

Result: 已证明QSS与量子马尔可夫半群的谱性质之间存在联系，并通过一些示例进行了说明

Conclusion: QSS与量子马尔可夫的谱性质存在联系

Abstract: We introduce the notion of Quasi-Stationary State (QSS) in the context of
quantum Markov semigroups that generalizes the one of quasi-stationary
distribution in the case of classical Markov chains. We provide an operational
interpretation of QSSs using the theory of direct and indirect quantum
measurements. Moreover, we prove that there is a connection between QSSs and
spectral properties of the quantum Markov semigroup. Finally, we discuss some
examples which, despite their simplicity, already show interesting features.

</details>


### [266] [Quantum Annealing for the Set Splitting Problem](https://arxiv.org/abs/2508.06410)
*Sean Borneman*

Main category: quant-ph

TL;DR: 本研究提出了一种利用量子退火和QUBO公式解决集合划分问题的新方法，该方法在逻辑量子比特数量上实现了线性扩展，并能在实验中收敛到最优解，但受限于当前硬件的物理量子比特需求。


<details>
  <summary>Details</summary>
Motivation: 为了寻找解决集合划分问题的更有效的方法，并探索量子退火在组合优化问题中的应用。

Method: 提出了一种使用QUBO（二次无约束二元变量）问题公式的量子退火新方法来解决集合划分问题，重点是设计能够确保QUBO哈密顿量的基态对应于有效的集合划分解的惩罚函数。

Result: 实验测试表明，该方法能够以高准确率收敛到全局最优解，并且随着问题规模的增加，所需逻辑量子比特的数量呈线性增长。然而，目前的量子退火硬件限制导致物理量子比特的需求呈指数级增长。

Conclusion: 量子退火方法为集合划分问题提供了一种新的解决方案，该方法具有与经典方法相比可忽略的time complexity，并可能加速生物学、网络安全和其他领域的研究。

Abstract: I present a novel use of quantum annealing to solve the Set Splitting Problem
using (QUBO) problem formulation. The contribution of the work is in
formulating penalty functions that ensure the ground state of the QUBO
Hamiltonian corresponds to valid solutions that split the input subsets. This
approach scales linearly in terms of the number of logical qubits relative to
problem size. Empirical tests of the proposed solution show convergence to
globally optimal solutions, with high accuracy rates over repeated trials.
Hardware limitations of current quantum annealers lead to an exponential rise
in required physical qubits, versus the theoretical linear increase, although
this can improve with future developments. Further work is needed to enhance
formulation robustness, reduce qubit requirements for embedded problems, and to
conduct more extensive bench-marking. Quantum solutions to the Set-Splitting
problem lead to reduced time complexity versus classical solutions, and may
accelerate research in biology, cybersecurity, and other domains.

</details>


### [267] [Single photon emission from lithographically-positioned engineered nanodiamonds for cryogenic applications](https://arxiv.org/abs/2508.06424)
*Vivekanand Tiwari,Zhaojin Liu,Hao-Cheng Weng,Krishna C Balram,John G Rarity,Soumen Mandal,Oliver A Williams,Gavin W Morley,Joe A Smith*

Main category: quant-ph

TL;DR: 通过将NV中心金刚石纳米颗粒放置在金属反射器上，提高光子收集效率，实现在低温下进行单光子发射的测量。


<details>
  <summary>Details</summary>
Motivation: 为了将氮-空位（NV）中心技术从原理证明发展到超越，需要对其组件进行优化工程。

Method: 通过光刻技术将球磨的、同位素富集的金刚石纳米颗粒（NDs）放置在宽带金属反射器上，并在此之上添加SiO2。

Result: 器件能够在16 K下进行光谱表征，并测量自相关函数，证实了单光子发射（g$^2$(0)<0.5）。

Conclusion: 通过比较研究类似的混合器件配置，我们可以朝着在晶圆级光子环境中构建和分析量子发射器的最佳工程技术迈进。

Abstract: Nitrogen-vacancy centres in nanodiamonds (NDs) provide a promising resource
for quantum photonic systems. However, developing a technology beyond
proof-of-principle physics requires optimally engineering its component parts.
In this work, we present a hybrid materials platform by photolithographically
positioning ball-milled isotopically-enriched NDs on broadband metal
reflectors. The structure enhances the photonic collection efficiency, enabling
cryogenic characterisation despite the limited numerical aperture imposed by
our cryostat. Our device, with SiO$_2$ above a silver reflector, allows us to
perform spectroscopic characterisation at 16 K and measure autocorrelation
functions confirming single-photon emission (g$^2$(0)<0.5). Through comparative
studies of similar hybrid device configurations, we can move towards optimally
engineered techniques for building and analysing quantum emitters in
wafer-scale photonic environments.

</details>


### [268] [Nonparametric Learning Non-Gaussian Quantum States of Continuous Variable Systems](https://arxiv.org/abs/2508.06431)
*Liubov A. Markovich,Xiaoyu Liu,Jordi Tura*

Main category: quant-ph

TL;DR: 量子态层析成像方法由于缺乏稳健的估计技术而未被充分利用。本研究提出了一种名为KQSE（核量子态估计）的非参数框架，用于从噪声数据中重建量子态及其迹特征。KQSE可以提供各种基下的密度矩阵估计，以及纯度、高阶矩、重叠度和迹距离等迹量，收敛速率接近最优（$	ilde{O}igl(T^{-1}igr)$），并且对多峰非高斯态具有鲁棒性，非常适合量子科学中的状态表征。


<details>
  <summary>Details</summary>
Motivation: 为了解决量子态层析成像方法由于缺乏稳健的估计技术而未被充分利用的问题。

Method: 提出了一种名为KQSE（核量子态估计）的非参数框架，用于从噪声数据中重建量子态及其迹特征。

Result: KQSE可以提供各种基下的密度矩阵估计，以及纯度、高阶矩、重叠度和迹距离等迹量，收敛速率接近最优（$	ilde{O}igl(T^{-1}igr)$），并且对多峰非高斯态具有鲁棒性。

Conclusion: KQSE是一种非参数核量子态估计框架，可以从噪声数据中重建量子态及其迹特征，具有近乎最优的收敛速率，并且对多峰非高斯态具有鲁棒性，非常适合量子科学中的状态表征。

Abstract: Continuous-variable quantum systems are foundational to quantum computation,
communication, and sensing. While traditional representations using wave
functions or density matrices are often impractical, the tomographic picture of
quantum mechanics provides an accessible alternative by associating quantum
states with classical probability distribution functions called tomograms.
Despite its advantages, including compatibility with classical statistical
methods, tomographic method remain underutilized due to a lack of robust
estimation techniques. This work addresses this gap by introducing a
non-parametric \emph{kernel quantum state estimation} (KQSE) framework for
reconstructing quantum states and their trace characteristics from noisy data,
without prior knowledge of the state. In contrast to existing methods, KQSE
yields estimates of the density matrix in various bases, as well as trace
quantities such as purity, higher moments, overlap, and trace distance, with a
near-optimal convergence rate of $\tilde{O}\bigl(T^{-1}\bigr)$, where $T$ is
the total number of measurements. KQSE is robust for multimodal, non-Gaussian
states, making it particularly well suited for characterizing states essential
for quantum science.

</details>


### [269] [Accelerating Quantum Monte Carlo Calculations with Set-Equivariant Architectures and Transfer Learning](https://arxiv.org/abs/2508.06441)
*Manuel Gallego,Sebastián Roca-Jerat,David Zueco,Jesús Carrete*

Main category: quant-ph

TL;DR: 本文利用set-transformer架构加速量子蒙特卡洛计算中的可观测量评估，尤其针对磁化强度幂等耗时算符，并通过迁移学习降低训练成本。


<details>
  <summary>Details</summary>
Motivation: 尽管机器学习（ML）已大大提高了变分量子蒙特卡洛（QMC）计算的精度和范围，尤其是在研究自旋系统中的量子现象时，但QMC的可扩展性仍受到其他瓶颈的限制，特别是与基于随机偏差的可观测量实际评估相关的问题。

Method: 本文展示了如何使用set-transformer架构来加速量子蒙特卡洛（QMC）计算中可观测量（observables）的评估，特别针对时间复杂度高的算符，如磁化强度的幂。通过将set-transformer架构应用于从经典的Ising模型到具有长程相互作用的量子系统，并结合回归（预测可观测量）和分类（检测相变）任务，验证了该方法的有效性。此外，还利用迁移学习来降低训练成本。

Result: set-transformer架构能够显著加速或甚至绕过量子蒙特卡洛计算中基于随机偏差的可观测量评估步骤，尤其是在处理像磁化强度幂这类耗时算符时。该方法通过应用于不同复杂度的系统（从经典Ising模型到具有长程相互作用的量子系统）的回归（预测可观测量）和分类（检测相变）任务进行了说明。此外，通过迁移学习，可以利用不同系统和较小系统尺寸的知识来降低训练成本。

Conclusion: set-transformer架构可以显著加速或绕过量子蒙特卡洛计算中基于随机偏差的实际可观测量评估，尤其对于耗时的算符，如磁化强度的幂。

Abstract: Machine-learning (ML) ans\"atze have greatly expanded the accuracy and reach
of variational quantum Monte Carlo (QMC) calculations, in particular when
exploring the manifold quantum phenomena exhibited by spin systems. However,
the scalability of QMC is still compromised by several other bottlenecks, and
specifically those related to the actual evaluation of observables based on
random deviates that lies at the core of the approach. Here we show how the
set-transformer architecture can be used to dramatically accelerate or even
bypass that step, especially for time-consuming operators such as powers of the
magnetization. We illustrate the procedure with a range of examples of
increasing complexity, from the classical Ising model to quantum systems with
long-range interactions, and comprising both regressions (to predict
observables) and classifications (to detect phase transitions). Moreover, we
show how transfer learning can be leveraged to reduce the training cost by
reusing knowledge from different systems and smaller system sizes.

</details>


### [270] [Nonreciprocal and Geometric Frustration in Dissipative Quantum Spins](https://arxiv.org/abs/2508.06444)
*Guitao Lyu,Myung-Joong Hwang*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Nonreciprocal interactions often create conflicting dynamical objectives that
cannot be simultaneously satisfied, leading to nonreciprocal frustration. On
the other hand, geometric frustration arises when conflicting static objectives
in energy minimization cannot be satisfied. In this work, we show that
nonreciprocal interaction among three collective quantum spins, mediated by a
damped cavity, induces not only nonreciprocal frustration, intrinsic to
nonreciprocity, but also geometric frustration with a remarkable robustness
against disorder. It therefore ensures that the accidental degeneracy for
steady states remains intact even when the system is perturbed away from a
fine-tuned point of enhanced symmetry, in sharp contrast to the equilibrium
case. Leveraging this finding, we identify a nonreciprocal phase transition
driven by both geometric and nonreciprocal frustration. It gives rise to a
time-dependent state, which shows a chiral dynamics along a geometry shaped by
the geometric frustration and dynamically restores the broken discrete
symmetries. Moreover, it constitutes a time-crystalline order, with multiple
harmonics set by an emergent time scale that exhibits critical slowing down.
Our predictions have important physical implications for a three-component
spinor BEC-cavity system, which manifest as a geometric frustration in the
structural phase transition and chiral dynamics of the frustrated
self-organized BECs. We demonstrate the feasibility of experimental observation
despite the presence of disorder in the spin-cavity coupling strengths.

</details>


### [271] [Can a Quantum Computer Simulate Nuclear Magnetic Resonance Spectra Better than a Classical One?](https://arxiv.org/abs/2508.06448)
*Keith R. Fratus,Nicklas Enenkel,Sebastian Zanker,Jan-Michael Reiner,Michael Marthaler,Peter Schmitteckert*

Main category: quant-ph

TL;DR: 经典求解器在模拟NMR光谱方面表现出色，但未能处理所有分子，这可能影响量子计算在NMR领域的优势展示。


<details>
  <summary>Details</summary>
Motivation: 为了解NMR光谱模拟问题在多大程度上能展示量子计算的优势，有必要了解现有经典模拟方法的局限性。

Method: 通过基准测试来评估一个用于模拟NMR光谱实验的经典求解器的性能。

Result: 该经典求解器表现良好，甚至超出了常规的实验参数范围，但在处理具有特定异常特征的分子时遇到了困难。

Conclusion: 该研究评估了经典求解器在模拟核磁共振（NMR）光谱实验中的表现，发现其在大多数情况下表现良好，但在处理具有特殊异常特征的分子时存在局限性。这对于未来演示量子计算在NMR领域的优势具有重要意义。

Abstract: The simulation of the spectra measured in nuclear magnetic resonance (NMR)
spectroscopy experiments is a computationally non-trivial problem, and as such,
it represents a problem for which a quantum computer may provide some practical
advantage over traditional computing methods. In order to understand the extent
to which such problems may provide examples of useful quantum advantage, it is
important to understand the limitations of existing classical simulation
methods. In this work, we benchmark our classical solver designed to solve such
problems. We find that it performs well, even beyond the common experimental
parameter regimes, except for a specific molecule with certain unusual
features. We discuss what implications this may have for future efforts to
demonstrate quantum advantage in the context of NMR.

</details>


### [272] [Exploring the feasibility of probabilistic and deterministic quantum gates between T centers in silicon](https://arxiv.org/abs/2508.06474)
*Shahrzad Taherizadegan,Faezeh Kimiaee Asadi,Jia-Wei Ji,Daniel Higginbottom,Christoph Simon*

Main category: quant-ph

TL;DR: Silicon T center defects are good for quantum tech. This paper looks at different ways to link them up (gate protocols). A specific method using light interference with feedback looks promising, with over 50% success and good performance even with imperfections, making it worth trying in experiments.


<details>
  <summary>Details</summary>
Motivation: The motivation behind this research is to explore and evaluate different gate protocols for T center defects in silicon, aiming to leverage their unique spin properties and compatibility with silicon technology for advancements in quantum technologies. The study specifically focuses on identifying protocols that can achieve high fidelity and efficiency, thereby assessing their viability for practical quantum applications.

Method: This paper analyzes several gate protocols for T center defects in silicon, including two probabilistic photon interference-based schemes, a near-deterministic photon scattering gate, and a deterministic magnetic dipole-based scheme. Utilizing the photon-count decomposition method, the study provides the first analytical calculations of entanglement fidelity and efficiency for the feedback-assisted photon interference scheme, while also considering system imperfections. The fidelity and efficiency of the other schemes are similarly computed.

Result: The study found that the photon interference-based scheme with feedback can achieve success probabilities greater than 50%. Analytical calculations using the photon-count decomposition method were performed to determine the entanglement fidelity and efficiency of this scheme, taking into account imperfections. The fidelity and efficiency of other schemes were also calculated, and a comparative analysis revealed that the photon interference-based scheme with feedback holds significant potential for achieving competitive efficiency and fidelity, making it a compelling candidate for experimental investigation.

Conclusion: T center defects in silicon offer a promising avenue for quantum technologies owing to their spin characteristics and integration with existing silicon manufacturing processes. Among the investigated gate protocols, the photon interference-based scheme with feedback demonstrates considerable potential, achieving success probabilities exceeding 50% and showing competitive efficiency and fidelity in light of current and near-future experimental capacities.

Abstract: T center defects in silicon provide an attractive platform for quantum
technologies due to their unique spin properties and compatibility with mature
silicon technologies. We investigate several gate protocols between single T
centers, including two probabilistic photon interference-based schemes, a
near-deterministic photon scattering gate, and a deterministic magnetic
dipole-based scheme. In particular, we study a photon interference-based scheme
with feedback which can achieve success probabilities above 50%, and use the
photon-count decomposition method to perform the first analytical calculations
of its entanglement fidelity and efficiency while accounting for imperfections.
We also calculate the fidelity and efficiency of the other schemes. Finally, we
compare the performance of all the schemes, considering current and near-future
experimental capabilities. In particular, we find that the photon
interference-based scheme with feedback has the potential to achieve
competitive efficiency and fidelity, making it interesting to explore
experimentally.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [273] [Observing Differential Spin Currents by Resonant Inelastic X-ray Scattering](https://arxiv.org/abs/2508.05796)
*Yanhong Gu,Joseph Barker,Jiemin Li,Takashi Kikkawa,Fernando Camino,Kim Kisslinger,John Sinsheimer,Lukas Lienhard,Jackson J. Bauer,Caroline A. Ross,Dmitri N. Basov,Eiji Saitoh,Jonathan Pelliciari,Gerrit E. W. Bauer,Valentina Bisogni*

Main category: cond-mat.mes-hall

TL;DR: RIXS 技术首次直接测量了磁性材料中的自旋流，为自旋电子学开辟了新途径。


<details>
  <summary>Details</summary>
Motivation: 为了实现自旋电子学和未来节能信息技术，需要控制小磁性器件中的自旋流，但传统方法无法直接测量纯自旋流。

Method: 使用共振非弹性 X 射线散射（RIXS）技术，并结合玻尔兹曼方程在弛豫时间近似下提取输运参数，如有限动量下的磁振子寿命。

Result: 首次使用 RIXS 直接测量了由磁振子携带的自旋流，并提取了自旋流的输运参数，为磁振子自旋电子学的发展奠定了基础。

Conclusion: 通过测量温度梯度下的磁绝缘体中由磁振子携带的自旋流，研究人员发现 RIXS 可以直接测量自旋流。

Abstract: Controlling spin currents, i.e., the flow of spin angular momentum, in small
magnetic devices is the principal objective of spin electronics, a main
contender for future energy efficient information technologies. Surprisingly, a
pure spin current has never been measured directly since the associated
electric stray fields and/or shifts in the non-equilibrium spin-dependent
distribution functions are too small for conventional experimental detection
methods optimized for charge transport. Here we report that resonant inelastic
x-ray scattering (RIXS) can bridge this gap by measuring the spin current
carried by magnons -- the quanta of the spin wave excitations of the magnetic
order -- in the presence of temperature gradients across a magnetic insulator.
This is possible due to the sensitivity of the momentum- and energy-resolved
RIXS intensity to minute changes in the magnon distribution under
non-equilibrium conditions. We use the Boltzmann equation in the relaxation
time approximation to extract transport parameters, such as the magnon lifetime
at finite momentum, essential for the realization of magnon spintronics.

</details>


### [274] [Quantum Hall Resistance and Quantum Hall Plateaus from Edge State Quantization](https://arxiv.org/abs/2508.05912)
*Pedro Pereyra*

Main category: cond-mat.mes-hall

TL;DR: 通过施加硬壁边界条件，我们成功从第一性原理推导了量子霍尔效应的霍尔电阻公式，并得到了与实验数据一致的结果。


<details>
  <summary>Details</summary>
Motivation: 填补了从第一性原理直接推导量子霍尔效应（QHE）现象学公式 $ho_{xy} = h/e^2
u$ 的空白。

Method: 在 Landau 和 Landauer-Büttiker 形式主义中施加硬壁边界条件，对波函数进行约束，实现了边缘态的量子化。

Result: 成功推导出霍尔电阻公式 $ho_{xy} = h/e^2
u$，并得到填充因子 $
u$ 相对于费米能和磁场的显式表达式，电阻阶梯重现了实验中观察到的 QHE 平台。

Conclusion: 从第一性原理推导了霍尔电阻公式，并给出了填充因子ν的显式表达式，其结果与实验数据完美匹配。

Abstract: Despite the extensive literature on the quantum Hall effect (QHE), a direct
derivation of the phenomenological formula $\rho_{xy} = h/e^2\nu$ from first
principles has remained elusive. In this work, we revisit the Landau and
Landauer-B\"uttiker formalisms and impose hard-wall boundary conditions on the
wavefunction, an essential but often overlooked constraint. This condition
quantizes the guiding center position and the longitudinal wave number $k_x$,
leading naturally to a discrete number of edge states without invoking energy
bending. We derive the Hall resistance directly and recover the standard result
$\rho_{xy} = h/e^2\nu$, along with an explicit expression for the filling
factor $\nu$ in terms of the Fermi energy and magnetic field. The resulting
resistance steps reproduce the observed QHE plateaus and match experimental
data without fitting parameters.

</details>


### [275] [Analysis of Spin Current Generation by Elastic Waves in $f$-wave Altermagnets](https://arxiv.org/abs/2508.06027)
*Ken Uchino,Yuuki Ogawa,Satoru Hayami*

Main category: cond-mat.mes-hall

TL;DR: 该研究发现，反演对称性破坏的交替磁体可以作为弹性驱动的自旋流发生器，而无需依赖相对论自旋轨道耦合。


<details>
  <summary>Details</summary>
Motivation: 理论上研究了在非相对论磁体（即交替磁体）中由弹性波引起的自旋流生成机制。

Method: 通过线性响应理论，分析了一个在二维三角晶格上破坏空间反演对称性的三子晶格非共线反铁磁结构形成的 f 电子波交替磁体。

Result: 研究发现，反对称自旋劈裂的动量依赖性会导致具有特征性的依赖于方向的自旋流响应。研究还将当前的非相对论磁序驱动机制与非磁性 Rashba 系统中的相对论机制进行了比较。

Conclusion: 该研究理论上研究了在非相对论磁体（即交替磁体）中由弹性波引起的自旋流生成机制。研究分析了一个在二维三角晶格上破坏空间反演对称性的三子晶格非共线反铁磁结构形成的 f 电子波交替磁体，并在线性响应理论下进行了分析，结果表明非相对论反对称自旋劈裂能带结构在施加纵向或横向弹性波时会产生自旋流。研究发现，反对称自旋劈裂的动量依赖性会导致具有特征性的依赖于方向的自旋流响应。研究还将当前的非相对论磁序驱动机制与非磁性 Rashba 系统中的相对论机制进行了比较。这些发现强调了反演对称性破坏的交替磁体作为弹性驱动的自旋流发生器的潜力，而无需依赖相对论自旋轨道耦合。

Abstract: We theoretically investigate the mechanism of spin current generation induced
by elastic waves in nonrelativistic magnets referred to as altermagnets. By
analyzing an $f$-wave altermagnet formed by a three-sublattice noncollinear
antiferromagnetic structure breaking the spatial inversion symmetry on a
two-dimensional triangular lattice within the linear response theory, we show
that the nonrelativistic antisymmetric spin-split band structure can give rise
to spin current generation when either longitudinal or transverse elastic wave
is applied. We find that the momentum dependence of the antisymmetric spin
splitting leads to a characteristic direction-dependent spin current response.
We also compare the present nonrelativistic magnetic-order-driven mechanism
with the relativistic one in a nonmagnetic Rashba system. These findings
highlight the potential of invesion-symmetry-breaking altermagnets as a spin
current generator driven by elasticity without relying on the relativistic
spin-orbit coupling.

</details>


### [276] [$μ_\mathrm{2T}(n)$: A Method for Extracting the Density Dependent Mobility in Two-Terminal Nanodevices](https://arxiv.org/abs/2508.06173)
*Christian E. N. Petersen,Damon J. Carrad,Thierry Désiré,Daria Beznasyuk,Jung-Hyun Kang,Dāgs Olšteins,Gunjan Nagda,Dennis V. Christensen,Thomas Sand Jespersen*

Main category: cond-mat.mes-hall

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Measuring carrier mobility as a function of the carrier density in
semiconductors using Hall effect is the gold standard for quantifying
scattering mechanisms. However, for nanostructures, the Hall effect is not
applicable, and the density dependence of mobility is generally inaccessible,
rendering Hall effect measurements impractical. Here, we present
$\mu_\mathrm{2T}(n)$, a new procedure allowing us to extract the density
dependent mobility in two-terminal measured nano scale field effect transistors
at zero magnetic field from conventional conductance vs gate voltage
measurements. We validate $\mu_\mathrm{2T}$ against standard Hall measurements
and then apply the procedure to 256 individual two-terminal InAs nanowire FETs,
extracting information about the scattering mechanisms. To illustrate its broad
utility, we reanalyze published data in which mobility had been treated as
density independent. Our method represents a new powerful tool for optimization
and development of nanomaterials crucial for a wide range of new technologies.

</details>


### [277] [Finite Length Effects and Coulomb Interaction in Ge Quantum Well-Based Josephson Junctions Probed with Microwave Spectroscopy](https://arxiv.org/abs/2508.06180)
*S. C. ten Kate,D. C. Ohnmacht,M. Coraiola,T. Antonelli,S. Paredes,F. J. Schupp,M. Hinderling,S. W. Bedell,W. Belzig,J. C. Cuevas,A. E. Svetogorov,F. Nichele,D. Sabonis*

Main category: cond-mat.mes-hall

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Proximitized Ge quantum wells have emerged as a novel platform for studying
Andreev bound states (ABSs), due to their expected strong spin-orbit
interaction and high mobility. Here, we used microwave spectroscopy techniques
to investigate ABSs in Josephson junctions (JJs) realized in proximitized Ge
quantum wells. Spectroscopic signatures observed in a 350 nm junction indicated
the presence of multiple ABSs, and were reproduced with a model including
finite-length effects. The ABS spectra measured for a $1.2~\mu$m junction were
explained by a model including three ABSs in two conduction channels and finite
Coulomb interaction. Our work highlights the importance of interactions in JJs
and serves as a basis for understanding and manipulating ABSs in Ge-based
hybrid devices.

</details>


### [278] [Gate reflectometry in a minimal Kitaev chain device](https://arxiv.org/abs/2508.06403)
*Yining Zhang,Ivan Kulesh,Sebastiaan L. D. ten Haaf,Nick van Loo,Francesco Zatelli,Tijl Degroote,Christian G. Prosko,Srijit Goswami*

Main category: cond-mat.mes-hall

TL;DR: RF gate reflectometry successfully probed coupled QDs in a hybrid system, resolving key processes for Majorana qubits and demonstrating parity switching in a closed regime.


<details>
  <summary>Details</summary>
Motivation: To realize Majorana zero modes in artificial Kitaev chains using hybrid quantum dot (QD)-superconductor systems for potential applications in Majorana qubits, and to use RF gate reflectometry for reading out these qubits.

Method: Radio-frequency (RF) gate reflectometry was used to probe two quantum dots (QDs) coupled via a semiconductor-superconductor hybrid segment.

Result: The study demonstrated that gate sensing can resolve charge stability diagrams and differentiate between elastic cotunneling and crossed-Andreev reflection. It also showed that this information is accessible in a closed regime, where quantum capacitance signals indicate parity switching between even and odd ground states.

Conclusion: Gate reflectometry can resolve charge stability diagrams and distinguish between elastic cotunneling and crossed-Andreev reflection, which are key processes for forming a Kitaev chain. This information is accessible even when the system is decoupled from normal leads. In the closed regime, the quantum capacitance signal indicates parity switching between even and odd ground states, confirming that gate reflectometry captures essential features of interdot coupling and parity dynamics.

Abstract: Hybrid quantum dot (QD)-superconductor system can be used to realize Majorana
zero modes in artificial Kitaev chains. These chains provide a promising
platform for the realization of Majorana qubits. Radio-frequency (RF) gate
reflectometry is a fast, non-invasive, and sensitive technique that can be used
to read out such qubits. In this work, we use gate reflectometry to probe two
QDs coupled via a semiconductor-superconductor hybrid segment. We demonstrate
that gate sensing can resolve charge stability diagrams and clearly distinguish
between elastic cotunneling and crossed-Andreev reflection, the two key
processes that allow one to form a Kitaev chain. Furthermore, we show that this
information is accessible, even when the system is completely decoupled from
the from the normal leads. In this closed regime, we show that the observed
quantum capacitance signal is indicative of parity switching between the even
and odd ground states. Our measurements in both open and closed regimes confirm
that gate reflectometry captures the essential features of interdot coupling
and parity dynamics.

</details>


### [279] [Observation of momentum dependent charge density wave gap in EuTe4](https://arxiv.org/abs/2508.06464)
*Iftakhar Bin Elius,Nathan Valadez,Gyanendra Dhakal,Volodymyr Buturlim,Sabin Regmi,Dante James,Peter Radanovich,Matthew Yankowitz,Tetiana Romanova,Andrzej Ptok,Krzysztof Gofryk,Dariusz Kaczorowski,Madhab Neupane*

Main category: cond-mat.mes-hall

TL;DR: EuTe4的DFT计算和ARPES实验揭示了CDW能隙和杂化诱导能隙，并证实了其各向异性。低温热容测量构建了EuTe4的磁相图。


<details>
  <summary>Details</summary>
Motivation: EuTe4作为一种具有多Te层和单Eu-Te层的低维稀土硫属化物，是研究CDW有序与4f电子构型（包括磁性）之间相互作用的有希望的平台。

Method: 采用基于第一性原理的密度泛函理论（DFT）计算研究了CDW调制引起的电子能带结构变化，并结合角度分辨光电子能谱（ARPES）揭示了费米能级处的CDW能隙以及较低结合能处的杂化诱导能隙特征。此外，通过在近奈尔温度（TN ~ 6.9 K）下施加磁场进行低温热容测量，构建了EuTe4的磁相图。

Result: ARPES实验显示费米能级出现了CDW能隙，并在较低结合能处出现了杂化诱导的能隙特征。CDW能隙在Γ-Y高对称方向达到最大值，在GX方向达到最小值，体现了电子结构的各向异性。低温柔磁性测量结果成功构建了EuTe4的磁相图。

Conclusion: 本研究提供了对EuTe4系统中定向依赖的费米表面嵌套诱导的CDW有序以及其他观测到的能隙开度具有价值的认识。

Abstract: The occurrence of charge density wave (CDW) phenomena, particularly in low
dimensional rare-earth chalcogenides, has attracted substantial research
interest. Among these materials, EuTe4, which features multiple Te layers and a
single Eu-Te layer, serves as a promising platform to study the interplay
between CDW order and 4f electron configurations, including magnetism. In this
study, First principles based density functional theory (DFT) calculations were
carried out to investigate the electronic band structure modifications arising
from CDW modulation. Angle resolved photoemission spectroscopy (ARPES) revealed
the emergence of a CDW gap at the Fermi level, as well as hybridization induced
gap features at lower binding energies. The low lying CDW gap reaches its
maximum along the Gamma-Y high-symmetry direction and a minimum along GX
reflecting the anisotropic nature of the electronic structure. We also
performed low temperature heat capacity measurements in applied magnetic fields
near the Neel temperature (TN ~ 6.9 K) to construct the magnetic phase diagram
of EuTe4. This study provides valuable insight into the directional dependent
evolution of the Fermi surface nesting induced CDW ordering, along with other
observed gap openings within this system.

</details>


### [280] [Simulating Floquet non-Abelian topological insulator with photonic quantum walks](https://arxiv.org/abs/2508.06466)
*Quan Lin,Tianyu Li,Haiping Hu,Wei Yi,Peng Xue*

Main category: cond-mat.mes-hall

TL;DR: 通过高维光量子行走模拟和动态测量方案，首次实验验证了氟非阿贝尔拓扑绝缘体，并揭示了其特殊的非阿贝尔相。


<details>
  <summary>Details</summary>
Motivation: 为应对氟非阿贝尔拓扑绝缘体（FNATIs）因其非阿贝尔拓扑荷和多重体分野边界对应性而导致的实验观测挑战。

Method: 利用高维光量子行走模拟了氟非阿贝尔拓扑绝缘体，并开发了动态测量方案。

Result: 实验成功建立了多重体分野边界对应性，并识别出一种特殊的非阿贝尔相，其边界态出现在所有带隙中，尽管其拓扑荷是平凡的。具体而言，结合了对四元数拓扑荷的直接分野动态探测和对边界态的空间分辨注入光谱。

Conclusion: 该实验首次实现了氟非阿贝尔拓扑绝缘体的实验表征，并提供了对非阿贝尔拓扑相的普适性认识。

Abstract: Floquet non-Abelian topological phases emerge in periodically driven systems
and exhibit properties that are absent in their Abelian or static counterparts.
Dubbed the Floquet non-Abelian topological insulators (FNATIs), they are
characterized by non-Abelian topological charges and feature multifold
bulk-boundary correspondence, making their experimental observation
challenging. Here we simulate the FNATI using a higher-dimensional photonic
quantum walk and develop dynamic measurement schemes to demonstrate key
signatures of the FNATI. Importantly, combining a direct bulk-dynamic detection
for the underlying quaternion topological charge, and a spatially-resolved
injection spectroscopy for the edge states, we experimentally establish the
multifold bulk-boundary correspondence, and, in particular, identify the
anomalous non-Abelian phase where edge states appear in all band gaps, despite
the presence of a trivial topological charge. Our experiment marks the first
experimental characterization of the FNATI, providing general insight into the
non-Abelian topological phases.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [281] [GPU-Accelerated Barrier-Rate Guided MPPI Control for Tractor-Trailer Systems](https://arxiv.org/abs/2508.05773)
*Keyvan Majd,Hardik Parwana,Bardh Hoxha,Steven Hong,Hideki Okamoto,Georgios Fainekos*

Main category: cs.RO

TL;DR: BR-MPPI是一种改进的导航控制方法，通过结合CBF和MPPI，提高了铰接车辆在复杂环境下的安全性和操控性。


<details>
  <summary>Details</summary>
Motivation: 解决铰接车辆在拥挤空间（如停车场）进行倒车和机动时，需要考虑行人和动态可行性的导航问题。

Method: BR-MPPI（Barrier-Rate guided Model Predictive Path Integral）控制，将CBF约束直接嵌入到路径积分更新中，以引导重要性采样分布趋向无碰撞、动力学可行的轨迹。

Result: 在CarMaker模拟器中，BR-MPPI成功实现了12米牵引车拖车的倒车和前进停车，计算速度超过100 Hz（带8个障碍物），并且比标准MPPI和带碰撞成本的MPPI具有更好的停车间隙。

Conclusion: BR-MPPI通过将CBF约束嵌入路径积分更新中，提高了MPPI的探索能力和轨迹鲁棒性，在模拟器中表现优于标准MPPI和带碰撞成本的MPPI。

Abstract: Articulated vehicles such as tractor-trailers, yard trucks, and similar
platforms must often reverse and maneuver in cluttered spaces where pedestrians
are present. We present how Barrier-Rate guided Model Predictive Path Integral
(BR-MPPI) control can solve navigation in such challenging environments.
BR-MPPI embeds Control Barrier Function (CBF) constraints directly into the
path-integral update. By steering the importance-sampling distribution toward
collision-free, dynamically feasible trajectories, BR-MPPI enhances the
exploration strength of MPPI and improves robustness of resulting trajectories.
The method is evaluated in the high-fidelity CarMaker simulator on a 12 [m]
tractor-trailer tasked with reverse and forward parking in a parking lot.
BR-MPPI computes control inputs in above 100 [Hz] on a single GPU (for
scenarios with eight obstacles) and maintains better parking clearance than a
standard MPPI baseline and an MPPI with collision cost baseline.

</details>


### [282] [Integrating Vision Foundation Models with Reinforcement Learning for Enhanced Object Interaction](https://arxiv.org/abs/2508.05838)
*Ahmad Farooq,Kamran Iqbal*

Main category: cs.RO

TL;DR: 本研究将SAM和YOLOv5等视觉基础模型与PPO强化学习相结合，显著提高了机器人在AI2-THOR模拟厨房环境中的物体交互成功率和导航效率。


<details>
  <summary>Details</summary>
Motivation: 为了增强机器人在模拟环境中与物体交互的能力，并提高其导航效率。

Method: 本研究提出了一种新颖的方法，将视觉基础模型（SAM和YOLOv5）与强化学习（PPO）相结合，并在AI2-THOR模拟环境中进行训练和测试。

Result: 实验结果表明，与未使用高级感知的基线代理相比，该方法在平均累积奖励方面提高了68%，在物体交互成功率方面提高了52.5%，在导航效率方面提高了33%。

Conclusion: 该研究表明，将视觉基础模型与强化学习相结合，在提高机器人与物体交互能力和导航效率方面具有巨大潜力，为更复杂、更强大的自主代理铺平了道路。

Abstract: This paper presents a novel approach that integrates vision foundation models
with reinforcement learning to enhance object interaction capabilities in
simulated environments. By combining the Segment Anything Model (SAM) and
YOLOv5 with a Proximal Policy Optimization (PPO) agent operating in the
AI2-THOR simulation environment, we enable the agent to perceive and interact
with objects more effectively. Our comprehensive experiments, conducted across
four diverse indoor kitchen settings, demonstrate significant improvements in
object interaction success rates and navigation efficiency compared to a
baseline agent without advanced perception. The results show a 68% increase in
average cumulative reward, a 52.5% improvement in object interaction success
rate, and a 33% increase in navigation efficiency. These findings highlight the
potential of integrating foundation models with reinforcement learning for
complex robotic tasks, paving the way for more sophisticated and capable
autonomous agents.

</details>


### [283] [Modular Vacuum-Based Fixturing System for Adaptive Disassembly Workspace Integration](https://arxiv.org/abs/2508.05936)
*Haohui Pan,Takuya Kiyokawa,Tomoki Ishikura,Shingo Hamada,Genichiro Matsuda,Kensuke Harada*

Main category: cs.RO

TL;DR: A new soft gripper system using vacuum and balloons provides better stability and success for dismantling complex appliances compared to old rigid systems.


<details>
  <summary>Details</summary>
Motivation: Traditional rigid fixtures are inadequate for disassembling small household appliances due to their complex and curved geometries. The motivation is to develop a more adaptable and stable fixturing system for such tasks.

Method: A modular vacuum-based fixturing system utilizing commercially available balloon-type soft grippers was developed. A stability-aware planning framework was designed, involving sampling the object's bottom surface, filtering contact points based on geometric continuity, and evaluating support configurations using convex hull-based static stability criteria.

Result: The system demonstrates consistent higher success rates and superior placement stability during screw removal tasks compared to traditional rigid fixtures. Comparisons were made based on the number and configuration of soft grippers.

Conclusion: The proposed modular vacuum-based fixturing system using soft grippers achieves higher success rates and superior placement stability for disassembling small household appliances compared to traditional rigid fixtures.

Abstract: The disassembly of small household appliances poses significant challenges
due to their complex and curved geometries, which render traditional rigid
fixtures inadequate. In this paper, we propose a modular vacuum-based fixturing
system that leverages commercially available balloon-type soft grippers to
conform to arbitrarily shaped surfaces and provide stable support during
screw-removal tasks. To enable a reliable deployment of the system, we develop
a stability-aware planning framework that samples the bottom surface of the
target object, filters candidate contact points based on geometric continuity,
and evaluates support configurations using convex hull-based static stability
criteria. We compare the quality of object placement under different numbers
and configurations of balloon hands. In addition, real-world experiments were
conducted to compare the success rates of traditional rigid fixtures with our
proposed system. The results demonstrate that our method consistently achieves
higher success rates and superior placement stability during screw removal
tasks.

</details>


### [284] [Affordance-Guided Dual-Armed Disassembly Teleoperation for Mating Parts](https://arxiv.org/abs/2508.05937)
*Gen Sako,Takuya Kiyokawa,Kensuke Harada,Tomoki Ishikura,Naoya Miyaji,Genichiro Matsuda*

Main category: cs.RO

TL;DR: 该研究提出了一种用于机器人双臂拆卸嵌接件的遥操作系统，通过虚拟界面提供抓取姿态和拆卸方向，并采用混合控制器提高操作精度和成功率。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人拆卸嵌接件时操作灵活性和内部结构可见性有限的挑战。

Method: 提出了一种允许用户通过演示进行操作的、考虑了物体几何形状的、具有抓取姿态和拆卸方向的虚拟界面的遥操作系统。

Result: 实验结果表明，该系统能够提高任务成功率并减少物体姿态偏差。

Conclusion: 该研究提出了一种结合位置和阻抗控制的混合控制器，以解决双臂抓取和拆卸任务中内嵌部件的挑战。

Abstract: Robotic non-destructive disassembly of mating parts remains challenging due
to the need for flexible manipulation and the limited visibility of internal
structures. This study presents an affordance-guided teleoperation system that
enables intuitive human demonstrations for dual-arm fix-and-disassemble tasks
for mating parts. The system visualizes feasible grasp poses and disassembly
directions in a virtual environment, both derived from the object's geometry,
to address occlusions and structural complexity. To prevent excessive position
tracking under load when following the affordance, we integrate a hybrid
controller that combines position and impedance control into the teleoperated
disassembly arm. Real-world experiments validate the effectiveness of the
proposed system, showing improved task success rates and reduced object pose
deviation.

</details>


### [285] [Latent Policy Barrier: Learning Robust Visuomotor Policies by Staying In-Distribution](https://arxiv.org/abs/2508.05941)
*Zhanyi Sun,Shuran Song*

Main category: cs.RO

TL;DR: LPB框架通过将专家演示的潜在嵌入视为一种隐式障碍物，并结合基础扩散策略和动力学模型，提高了视觉运动策略在面对协变量偏移时的鲁棒性和数据效率。


<details>
  <summary>Details</summary>
Motivation: 行为克隆训练的视觉运动策略容易受到协变量偏移的影响，而现有方法（如人工干预或数据增强）成本高昂且有局限性。因此，需要一种更有效的方法来提高策略的鲁棒性。

Method: LPB将潜在嵌入视为隐式障碍物，将专家数据和次优数据分开，使用两个模块：一个仅基于专家数据的基础扩散策略，以及一个在专家和次优数据上训练的动力学模型。

Result: LPB在模拟和真实世界的实验中，在数据效率和策略鲁棒性方面均优于现有方法，即使在数据有限的情况下也能实现可靠的操作。

Conclusion: LPB通过将专家演示的潜在嵌入视为区分安全和不安全状态的隐式屏障，并在推理时优化潜在状态以保持在专家分布内，从而提高了数据的效率和策略的鲁棒性，可以在没有额外人工干预的情况下，从有限的专家数据中进行可靠的操作。

Abstract: Visuomotor policies trained via behavior cloning are vulnerable to covariate
shift, where small deviations from expert trajectories can compound into
failure. Common strategies to mitigate this issue involve expanding the
training distribution through human-in-the-loop corrections or synthetic data
augmentation. However, these approaches are often labor-intensive, rely on
strong task assumptions, or compromise the quality of imitation. We introduce
Latent Policy Barrier, a framework for robust visuomotor policy learning.
Inspired by Control Barrier Functions, LPB treats the latent embeddings of
expert demonstrations as an implicit barrier separating safe, in-distribution
states from unsafe, out-of-distribution (OOD) ones. Our approach decouples the
role of precise expert imitation and OOD recovery into two separate modules: a
base diffusion policy solely on expert data, and a dynamics model trained on
both expert and suboptimal policy rollout data. At inference time, the dynamics
model predicts future latent states and optimizes them to stay within the
expert distribution. Both simulated and real-world experiments show that LPB
improves both policy robustness and data efficiency, enabling reliable
manipulation from limited expert data and without additional human correction
or annotation.

</details>


### [286] [Social and Telepresence Robots for Accessibility and Inclusion in Small Museums](https://arxiv.org/abs/2508.05946)
*Nello Balossino,Rossana Damiano,Cristina Gena,Alberto Lillo,Anna Maria Marras,Claudio Mattutino,Antonio Pizzo,Alessia Prin,Fabiana Vernero*

Main category: cs.RO

TL;DR: ROBSO-PM项目利用社交机器人和远程呈现机器人改善小型博物馆（尤其是低人口密度地区）的无障碍性，关注包容性参观和远程访问，并研究故事叙述、机器人个性和共情等问题。


<details>
  <summary>Details</summary>
Motivation: 许多博物馆仍存在无障碍障碍，特别是在感知、文化和认知方面，这在低人口密度地区尤为明显。ROBSO-PM 项目旨在通过使用社交机器人和远程呈现机器人来改善小型博物馆的可访问性。

Method: 该项目（ROBSO-PM）将利用社交机器人和远程呈现机器人来解决小型博物馆在感知、文化和认知方面存在的无障碍障碍。将对三个博物馆进行案例研究：都灵圣容博物馆、Champlas du Col Carnival博物馆和Pragelato高山民族服饰与传统博物馆。项目将探索机器人作为向导（支持外国或残疾游客的包容性参观）和远程呈现工具（允许行动不便者远程访问博物馆）的两种主要应用。

Result: 该项目将探索机器人作为向导（支持包容性访问）和远程呈现工具（提供远程博物馆访问）的应用。研究的关键主题包括故事叙述、机器人个性和共情，以及在远程呈现方面机器人与人之间的协作。

Conclusion: 该项目旨在通过社交机器人和远程呈现机器人来改善小型博物馆的可访问性，特别关注感知、文化和认知方面。项目探索了机器人作为向导和远程呈现工具的应用，并研究了故事叙述、机器人个性和共情等关键主题。

Abstract: There are still many museums that present accessibility barriers,
particularly regarding perceptual, cultural, and cognitive aspects. This is
especially evident in low-density population areas. The aim of the ROBSO-PM
project is to improve the accessibility of small museums through the use of
social robots and social telepresence robots, focusing on three museums as case
studies: the Museum of the Holy Shroud in Turin, a small but globally known
institution, and two lesser known mountain museums: the Museum of the Champlas
du Col Carnival and the Pragelato Museum of Alpine Peoples' Costumes and
Traditions. The project explores two main applications for robots: as guides
supporting inclusive visits for foreign or disabled visitors, and as
telepresence tools allowing people with limited mobility to access museums
remotely. From a research perspective, key topics include storytelling, robot
personality, empathy, personalization, and, in the case of telepresence,
collaboration between the robot and the person, with clearly defined roles and
autonomy.

</details>


### [287] [Dynamical Trajectory Planning of Disturbance Consciousness for Air-Land Bimodal Unmanned Aerial Vehicles](https://arxiv.org/abs/2508.05972)
*Shaoting Liu,Zhou Liu*

Main category: cs.RO

TL;DR: 提出了一种用于空地两栖车辆的干扰感知规划框架，通过实时估计和适应干扰来提高轨迹规划的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了提高在复杂环境中的轨迹规划鲁棒性，应对环境干扰。

Method: 提出了一种包含实时干扰估计的感知规划框架，并设计了一种干扰自适应安全边界调整机制，该机制能够根据估计的干扰动态修改车辆的可行动态边界，以保证轨迹的可行性。

Result: 实验和基准测试结果表明，该方法在跟踪精度、任务效率和能源性能方面均有所提高。

Conclusion: 该方法通过动态调整车辆的可行动态边界，实现了自适应和可靠的运动规划，并在各种地面和空中干扰下均表现出鲁棒性。

Abstract: Air-land bimodal vehicles provide a promising solution for navigating complex
environments by combining the flexibility of aerial locomotion with the energy
efficiency of ground mobility. To enhance the robustness of trajectory planning
under environmental disturbances, this paper presents a disturbance-aware
planning framework that incorporates real-time disturbance estimation into both
path searching and trajectory optimization. A key component of the framework is
a disturbance-adaptive safety boundary adjustment mechanism, which dynamically
modifies the vehicle's feasible dynamic boundaries based on estimated
disturbances to ensure trajectory feasibility. Leveraging the dynamics model of
the bimodal vehicle, the proposed approach achieves adaptive and reliable
motion planning across different terrains and operating conditions. A series of
real-world experiments and benchmark comparisons on a custom-built platform
validate the effectiveness and robustness of the method, demonstrating
improvements in tracking accuracy, task efficiency, and energy performance
under both ground and aerial disturbances.

</details>


### [288] [ReNiL: Relative Neural Inertial Locator with Any-Scale Bayesian Inference](https://arxiv.org/abs/2508.06053)
*Kaixuan Wu,Yuanzhuo Xu,Zejun Zhang,Weiping Zhu,Steve Drew,Xiaoguang Niu*

Main category: cs.RO

TL;DR: ReNiL是一个创新的贝叶斯深度学习框架，通过IPDP和ASLE技术实现了准确、高效且不确定性感知的行人惯性定位，解决了现有方法的局限性，并在多个数据集上取得了领先成果。


<details>
  <summary>Details</summary>
Motivation: 现有学习方法依赖于固定的滑动窗口积分，难以适应不同运动尺度和节奏，并且会产生不确确定性，限制了其在真实世界中的应用。因此，需要一种能够实现准确、高效且能感知不确定性的行人定位方法。

Method: ReNiL框架提出了一种基于贝叶斯深度学习的行人定位方法。该方法引入了惯性定位需求点（IPDP）来估计有意义的航点处的运动，而不是进行密集的跟踪。它还支持在任何尺度上对IMU序列进行推理，使步态适应应用程序的需求。ReNiL将运动感知方向滤波器与任何尺度拉普拉斯估计器（ASLE）相结合，ASLE是一个双任务网络，融合了基于块的自监督学习和贝叶斯回归。通过使用拉普拉斯分布对位移进行建模，ReNiL提供了同质欧几里得不确定性，可以与其他传感器顺利集成。最后，通过贝叶斯推理链将连续的IPDP链接成一致的轨迹。

Result: ReNiL在RoNIN-ds和WUDataset数据集上实现了最先进的位移精度和不确定性一致性，优于TLIO、CTIN、iMoT和RoNIN等方法，并减少了计算量。

Conclusion: ReNiL框架在RoNIN-ds和WUDataset数据集上均达到了最先进的位移精度和不确定性一致性，优于TLIO、CTIN、iMoT和RoNIN等现有方法，同时减少了计算量。应用研究表明其在移动和物联网定位方面具有鲁棒性和实用性，为下一代定位提供了可扩展、可感知不确定性的基础。

Abstract: Pedestrian inertial localization is key for mobile and IoT services because
it provides infrastructure-free positioning. Yet most learning-based methods
depend on fixed sliding-window integration, struggle to adapt to diverse motion
scales and cadences, and yield inconsistent uncertainty, limiting real-world
use. We present ReNiL, a Bayesian deep-learning framework for accurate,
efficient, and uncertainty-aware pedestrian localization. ReNiL introduces
Inertial Positioning Demand Points (IPDPs) to estimate motion at contextually
meaningful waypoints instead of dense tracking, and supports inference on IMU
sequences at any scale so cadence can match application needs. It couples a
motion-aware orientation filter with an Any-Scale Laplace Estimator (ASLE), a
dual-task network that blends patch-based self-supervision with Bayesian
regression. By modeling displacements with a Laplace distribution, ReNiL
provides homogeneous Euclidean uncertainty that integrates cleanly with other
sensors. A Bayesian inference chain links successive IPDPs into consistent
trajectories. On RoNIN-ds and a new WUDataset covering indoor and outdoor
motion from 28 participants, ReNiL achieves state-of-the-art displacement
accuracy and uncertainty consistency, outperforming TLIO, CTIN, iMoT, and RoNIN
variants while reducing computation. Application studies further show
robustness and practicality for mobile and IoT localization, making ReNiL a
scalable, uncertainty-aware foundation for next-generation positioning.

</details>


### [289] [Incremental Language Understanding for Online Motion Planning of Robot Manipulators](https://arxiv.org/abs/2508.06095)
*Mitchell Abrams,Thies Oelerich,Christian Hartl-Nesic,Andreas Kugi,Matthias Scheutz*

Main category: cs.RO

TL;DR: 本研究提出了一种结合了增量语言理解和实时运动规划的新方法，使机器人能够更流畅地响应和适应不断变化的语音指令，提高了人机协作的效率和自然度。


<details>
  <summary>Details</summary>
Motivation: 现有技术在语言引导机器人运动规划时通常假设指令是完全指定的，这在发生更正或澄清时会导致低效的停止和重新规划行为。为了解决这个问题，需要一种能够实时适应不断变化的语言输入并更新运动规划的方法。

Method: 提出了一种新颖的基于推理的增量解析器，将在线运动规划算法集成到认知架构中，能够持续适应动态语言输入，从而无需重新开始执行即可更新运动规划。

Result: 在现实世界的人机交互场景中评估了该框架，展示了对目标姿势、约束或任务目标的在线适应，证明了其在处理语音更正和动态变化约束方面的优势。

Conclusion: 该方法通过将增量语言理解与实时运动规划相结合，实现了更灵活的语音更正和动态变化约束处理，从而在现实世界的人机交互场景中实现了更自然流畅的人机协作。

Abstract: Human-robot interaction requires robots to process language incrementally,
adapting their actions in real-time based on evolving speech input. Existing
approaches to language-guided robot motion planning typically assume fully
specified instructions, resulting in inefficient stop-and-replan behavior when
corrections or clarifications occur. In this paper, we introduce a novel
reasoning-based incremental parser which integrates an online motion planning
algorithm within the cognitive architecture. Our approach enables continuous
adaptation to dynamic linguistic input, allowing robots to update motion plans
without restarting execution. The incremental parser maintains multiple
candidate parses, leveraging reasoning mechanisms to resolve ambiguities and
revise interpretations when needed. By combining symbolic reasoning with online
motion planning, our system achieves greater flexibility in handling speech
corrections and dynamically changing constraints. We evaluate our framework in
real-world human-robot interaction scenarios, demonstrating online adaptions of
goal poses, constraints, or task objectives. Our results highlight the
advantages of integrating incremental language understanding with real-time
motion planning for natural and fluid human-robot collaboration. The
experiments are demonstrated in the accompanying video at
www.acin.tuwien.ac.at/42d5.

</details>


### [290] [Bounding Distributional Shifts in World Modeling through Novelty Detection](https://arxiv.org/abs/2508.06096)
*Eric Jing,Abdeslam Boularias*

Main category: cs.RO

TL;DR: 在世界模型中加入新颖性检测器，以提高规划的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了使基于模型的规划算法对所学习的世界模型的质量更加鲁棒，需要一种新颖的检测方法来防止模型在推理过程中出现偏差。

Method: 提出使用变分自编码器作为新颖性检测器，以确保规划期间提出的动作轨迹不会导致所学习的模型偏离训练数据分布。

Result: 所提出的方法在具有挑战性的模拟机器人环境中进行了评估，并结合到模型预测控制策略循环中，扩展了DINO-WM架构，在数据效率方面取得了显著的改进。

Conclusion: 所提出的方法通过将变分自编码器用作新颖性检测器，提高了基于模型的规划算法对所学习的世界模型的鲁棒性，并且在数据效率方面优于现有技术。

Abstract: Recent work on visual world models shows significant promise in latent state
dynamics obtained from pre-trained image backbones. However, most of the
current approaches are sensitive to training quality, requiring near-complete
coverage of the action and state space during training to prevent divergence
during inference. To make a model-based planning algorithm more robust to the
quality of the learned world model, we propose in this work to use a
variational autoencoder as a novelty detector to ensure that proposed action
trajectories during planning do not cause the learned model to deviate from the
training data distribution. To evaluate the effectiveness of this approach, a
series of experiments in challenging simulated robot environments was carried
out, with the proposed method incorporated into a model-predictive control
policy loop extending the DINO-WM architecture. The results clearly show that
the proposed method improves over state-of-the-art solutions in terms of data
efficiency.

</details>


### [291] [Beyond Constant Parameters: Hyper Prediction Models and HyperMPC](https://arxiv.org/abs/2508.06181)
*Jan Węgrzynowski,Piotr Kicki,Grzegorz Czechmanowski,Maciej Krupka,Krzysztof Walas*

Main category: cs.RO

TL;DR: 通过 Hyper Prediction Model (HyperPM) 改进了机器人控制中的模型预测控制 (MPC)，提高了预测精度和性能，特别是在自动驾驶赛车等复杂场景下。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有基于梯度 MPC 中动力学模型存在的计算复杂性和状态表示的局限性。

Method: 提出了一种名为 Hyper Prediction Model (HyperPM) 的新方法，将未建模的动力学映射到一个时变动力学模型。通过使用神经网络学习 MPC 预测范围内的时变模型参数来捕捉这种时变性。

Result: 所提出的方法保留了基础模型的计算效率和鲁棒性，同时能够预测以前未建模的现象，并在多个挑战性系统（包括真实的 F1TENTH 自动驾驶赛车）上进行了评估，证明其显著减少了长时预测误差。

Conclusion: 使用 Hyper Prediction Model (HyperPM) 结合模型预测控制 (MPC) 框架（称为 HyperMPC）能够显著减少长时预测误差，并持续优于现有的最先进技术，尤其是在真实的 F1TENTH 自动驾驶赛车等挑战性系统上。

Abstract: Model Predictive Control (MPC) is among the most widely adopted and reliable
methods for robot control, relying critically on an accurate dynamics model.
However, existing dynamics models used in the gradient-based MPC are limited by
computational complexity and state representation. To address this limitation,
we propose the Hyper Prediction Model (HyperPM) - a novel approach in which we
project the unmodeled dynamics onto a time-dependent dynamics model. This
time-dependency is captured through time-varying model parameters, whose
evolution over the MPC prediction horizon is learned using a neural network.
Such formulation preserves the computational efficiency and robustness of the
base model while equipping it with the capacity to anticipate previously
unmodeled phenomena. We evaluated the proposed approach on several challenging
systems, including real-world F1TENTH autonomous racing, and demonstrated that
it significantly reduces long-horizon prediction errors. Moreover, when
integrated within the MPC framework (HyperMPC), our method consistently
outperforms existing state-of-the-art techniques.

</details>


### [292] [Affordance-R1: Reinforcement Learning for Generalizable Affordance Reasoning in Multimodal Large Language Model](https://arxiv.org/abs/2508.06206)
*Hanqing Wang,Shaoyang Wang,Yiming Zhong,Zemin Yang,Jiamin Wang,Zhiqing Cui,Jiahao Yuan,Yifan Han,Mingyu Liu,Yuexin Ma*

Main category: cs.RO

TL;DR: 该研究提出了 Affordance-R1，一个创新的框架，通过整合认知性思维链（CoT）和群体相对策略优化（GRPO）来解决机器人博弈推理中的挑战，从而提高了泛化能力和推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有模型常常忽略不同物体之间共享的博弈，因为它们缺乏思维链（CoT）推理能力，这限制了它们在域外（OOD）的泛化能力和显式推理能力。

Method: 我们提出了 Affordance-R1，这是第一个将认知性思维链（CoT）指导的群体相对策略优化（GRPO）整合到强化学习范式中的统一性博弈推理框架。具体来说，我们设计了一个复杂的博弈函数，其中包含格式、感知和认知奖励，以有效地指导优化方向。

Result: 所提出的 Affordance-R1 在没有显式推理数据的情况下，仅通过 GRPO 的强化学习进行训练，实现了强大的零样本泛化能力，并展现出涌现的测试时推理能力。

Conclusion: Affordance-R1 实现了强大的零样本泛化能力，并展现出涌现的测试时推理能力。实验证明，我们的模型优于成熟的方法，并展现出开放世界的泛化能力。

Abstract: Affordance grounding focuses on predicting the specific regions of objects
that are associated with the actions to be performed by robots. It plays a
vital role in the fields of human-robot interaction, human-object interaction,
embodied manipulation, and embodied perception. Existing models often neglect
the affordance shared among different objects because they lack the
Chain-of-Thought(CoT) reasoning abilities, limiting their out-of-domain (OOD)
generalization and explicit reasoning capabilities. To address these
challenges, we propose Affordance-R1, the first unified affordance grounding
framework that integrates cognitive CoT guided Group Relative Policy
Optimization (GRPO) within a reinforcement learning paradigm. Specifically, we
designed a sophisticated affordance function, which contains format,
perception, and cognition rewards to effectively guide optimization directions.
Furthermore, we constructed a high-quality affordance-centric reasoning
dataset, ReasonAff, to support training. Trained exclusively via reinforcement
learning with GRPO and without explicit reasoning data, Affordance-R1 achieves
robust zero-shot generalization and exhibits emergent test-time reasoning
capabilities. Comprehensive experiments demonstrate that our model outperforms
well-established methods and exhibits open-world generalization. To the best of
our knowledge, Affordance-R1 is the first to integrate GRPO-based RL with
reasoning into affordance reasoning. The code of our method and our dataset is
released on https://github.com/hq-King/Affordance-R1.

</details>


### [293] [Computer Vision-based Adaptive Control for Back Exoskeleton Performance Optimization](https://arxiv.org/abs/2508.06207)
*Andrea Dal Prete,Seyram Ofori,Chan Yon Sin,Ashwin Narayan,Francesco Braghin,Marta Gandolla,Haoyong Yu*

Main category: cs.RO

TL;DR: 本研究通过优化支撑策略和开发基于视觉的自适应控制，提高了外骨骼的有效性，减少了用户的肌肉负担和不适感。


<details>
  <summary>Details</summary>
Motivation: 为了提高背部外骨骼的有效性，本研究旨在解决两个关键挑战：定义最优支撑策略以及开发基于负载估计的自适应控制。

Method: 本研究通过优化空间定义最优支撑策略，并开发了一种基于视觉的自适应控制流程，利用机器学习实时估算负载，以最小化延迟并实现支撑的动态调整。

Result: 实验结果表明，本研究提出的自适应外骨骼控制框架能够准确估计负载（准确率超过80%），并将峰值背部肌肉激活降低高达23%，同时保持了用户的偏好和舒适度，与静态控制相比有了显著改善。

Conclusion: 本文提出的框架通过实现动态调整和智能上下文感知控制，验证了在工业外骨骼中的应用潜力，显著减少了背部肌肉激活，同时保持了用户的偏好和舒适度。

Abstract: Back exoskeletons can reduce musculoskeletal strain, but their effectiveness
depends on support modulation and adaptive control. This study addresses two
challenges: defining optimal support strategies and developing adaptive control
based on payload estimation. We introduce an optimization space based on muscle
activity reduction, perceived discomfort, and user preference, constructing
functions to identify optimal strategies. Experiments with 12 subjects revealed
optimal operating regions, highlighting the need for dynamic modulation. Based
on these insights, we developed a vision-based adaptive control pipeline that
estimates payloads in real-time by enhancing exoskeleton contextual
understanding, minimising latency and enabling support adaptation within the
defined optimisation space. Validation with 12 more subjects showed over 80%
accuracy and improvements across all metrics. Compared to static control,
adaptive modulation reduced peak back muscle activation by up to 23% while
preserving user preference and minimising discomfort. These findings validate
the proposed framework and highlight the potential of intelligent,
context-aware control in industrial exoskeletons.

</details>


### [294] [REBot: Reflexive Evasion Robot for Instantaneous Dynamic Obstacle Avoidance](https://arxiv.org/abs/2508.06229)
*Zihao Xu,Ce Hao,Chunzheng Wang,Kuankuan Sima,Fan Shi,Jin Song Dong*

Main category: cs.RO

TL;DR: REBot是一个用于四足机器人的控制框架，通过整合规避和恢复策略，实现了对快速移动障碍物的实时反射式规避，并在模拟和现实实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有基于导航的轨迹重新规划方法在面对快速接近的障碍物时失效的问题，需要四足机器人具备即时、低延迟的反应能力。因此，该研究旨在开发一种能够实现实时反射式障碍物规避的控制框架。

Method: REBot框架整合了一个规避策略和一个恢复策略，并通过有限状态机进行管理。该框架采用了精心设计的学习课程，并结合了正则化和自适应奖励机制，以实现鲁棒的规避和快速的稳定性。

Result: 通过广泛的模拟和真实世界实验验证，REBot框架在规避成功率、能量效率和鲁棒性方面均取得了显著的改进。

Conclusion: REBot框架在动态障碍物规避任务中表现出显著的优势，包括更高的规避成功率、能量效率和对快速移动障碍物的鲁棒性。

Abstract: Dynamic obstacle avoidance (DOA) is critical for quadrupedal robots operating
in environments with moving obstacles or humans. Existing approaches typically
rely on navigation-based trajectory replanning, which assumes sufficient
reaction time and leading to fails when obstacles approach rapidly. In such
scenarios, quadrupedal robots require reflexive evasion capabilities to perform
instantaneous, low-latency maneuvers. This paper introduces Reflexive Evasion
Robot (REBot), a control framework that enables quadrupedal robots to achieve
real-time reflexive obstacle avoidance. REBot integrates an avoidance policy
and a recovery policy within a finite-state machine. With carefully designed
learning curricula and by incorporating regularization and adaptive rewards,
REBot achieves robust evasion and rapid stabilization in instantaneous DOA
tasks. We validate REBot through extensive simulations and real-world
experiments, demonstrating notable improvements in avoidance success rates,
energy efficiency, and robustness to fast-moving obstacles. Videos and appendix
are available on https://rebot-2025.github.io/.

</details>


### [295] [ADPro: a Test-time Adaptive Diffusion Policy for Robot Manipulation via Manifold and Initial Noise Constraints](https://arxiv.org/abs/2508.06266)
*Zezeng Li,Rui Yang,Ruochen Chen,ZhongXuan Luo,Liming Chen*

Main category: cs.RO

TL;DR: ADP是一种用于机器人操作的测试时自适应扩散策略，通过几何约束和结构化初始化来提高性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散策略在作为视觉-运动控制器时，虽然训练稳定且能表达多模式动作，但它们将动作生成视为无约束的去噪过程，忽略了关于几何和控制结构的先验知识。这限制了它们在机器人操作任务中的表现。

Method: ADP是一种测试时自适应方法，它在扩散过程中引入了两个关键的归纳偏置：1. 几何流形约束：将去噪更新与任务相关的子空间对齐，利用末端执行器和目标场景之间的相对姿态作为梯度方向，并沿着操作流形的测地线引导去噪。2. 分析引导初始化：通过计算抓手和目标场景之间的粗略对齐来提出结构化的初始噪声动作，以减少不必要的探索并加速收敛。

Result: ADP（通过ADP实现）在RLBench、CALVIN和真实世界数据集上的实验表明，ADP提高了成功率、泛化性和采样效率，实现了高达25%的执行速度提升和9%的基线提升。

Conclusion: ADP通过引入几何流形约束和分析引导初始化，能够适应预训练的扩散策略，无需重新训练，从而在测试时针对特定任务进行调整，提高了在新型任务和环境中的泛化能力。实验结果表明，ADP在成功率、泛化性和采样效率方面均优于现有的扩散基线。

Abstract: Diffusion policies have recently emerged as a powerful class of visuomotor
controllers for robot manipulation, offering stable training and expressive
multi-modal action modeling. However, existing approaches typically treat
action generation as an unconstrained denoising process, ignoring valuable a
priori knowledge about geometry and control structure. In this work, we propose
the Adaptive Diffusion Policy (ADP), a test-time adaptation method that
introduces two key inductive biases into the diffusion. First, we embed a
geometric manifold constraint that aligns denoising updates with task-relevant
subspaces, leveraging the fact that the relative pose between the end-effector
and target scene provides a natural gradient direction, and guiding denoising
along the geodesic path of the manipulation manifold. Then, to reduce
unnecessary exploration and accelerate convergence, we propose an analytically
guided initialization: rather than sampling from an uninformative prior, we
compute a rough registration between the gripper and target scenes to propose a
structured initial noisy action. ADP is compatible with pre-trained diffusion
policies and requires no retraining, enabling test-time adaptation that tailors
the policy to specific tasks, thereby enhancing generalization across novel
tasks and environments. Experiments on RLBench, CALVIN, and real-world dataset
show that ADPro, an implementation of ADP, improves success rates,
generalization, and sampling efficiency, achieving up to 25% faster execution
and 9% points over strong diffusion baselines.

</details>


### [296] [EcBot: Data-Driven Energy Consumption Open-Source MATLAB Library for Manipulators](https://arxiv.org/abs/2508.06276)
*Juan Heredia,Christian Schlette,Mikkel Baun Kjærgaard*

Main category: cs.RO

TL;DR: 提出一个开源库，用于为通用机械臂自动生成电能消耗模型，并用实际数据验证了其准确性。


<details>
  <summary>Details</summary>
Motivation: 现有机械臂电能消耗模型存在两个主要问题：1. 大多数模型仅在传统工业机器人上进行测试；2. 模型的准确性有待提高。为了解决这些问题，本研究旨在提供一个更通用、更准确的电能消耗建模方法。

Method: 开发了一个开源的Matlab库，该库需要使用指定机器人的运动学参数（如Denavit-Hartenberg参数）和动力学参数（如连杆质量、质心）以及实际运行数据（如关节位置、速度、加速度、电能消耗和时间戳）来生成电能消耗模型。

Result: 所提出的模型在四个轻量级机器人（来自Universal Robots、Franka Emika和Kinova）上进行了测试。结果显示，模型在训练数据集上的均方根误差（RMSE）在1.42 W到2.80 W之间，在测试数据集上的RMSE在1.45 W到5.25 W之间。

Conclusion: 该研究提出了一种基于Matlab的开源库，用于为机械臂自动生成电能消耗模型，并使用四个轻量级机器人进行了验证，展示了其在不同数据集上的准确性。

Abstract: Existing literature proposes models for estimating the electrical power of
manipulators, yet two primary limitations prevail. First, most models are
predominantly tested using traditional industrial robots. Second, these models
often lack accuracy. To address these issues, we introduce an open source
Matlab-based library designed to automatically generate \ac{ec} models for
manipulators. The necessary inputs for the library are Denavit-Hartenberg
parameters, link masses, and centers of mass. Additionally, our model is
data-driven and requires real operational data, including joint positions,
velocities, accelerations, electrical power, and corresponding timestamps. We
validated our methodology by testing on four lightweight robots sourced from
three distinct manufacturers: Universal Robots, Franka Emika, and Kinova. The
model underwent testing, and the results demonstrated an RMSE ranging from 1.42
W to 2.80 W for the training dataset and from 1.45 W to 5.25 W for the testing
dataset.

</details>


### [297] [Mitigating Undesired Conditions in Flexible Production with Product-Process-Resource Asset Knowledge Graphs](https://arxiv.org/abs/2508.06278)
*Petr Novak,Stefan Biffl,Marek Obitko,Petr Kadera*

Main category: cs.RO

TL;DR: 该研究提出了PPR-AKG模型和基于LLM的聊天机器人，用于分析和解决柔性CPPS中的不期望状况，并支持资源分配。


<details>
  <summary>Details</summary>
Motivation: 解决当今由机器人工作单元组成的工业网络化物理生产系统（CPPS）在分析不期望条件时面临的挑战，以及行业4.0的灵活性破坏了传统质量保证机制的问题。

Method: 提出了一种名为产品-过程-资源资产知识图谱（PPR-AKG）的工业导向语义模型，该模型基于PPR模型和OWL本体，并集成了语义技术与大型语言模型（LLMs），通过自然语言提供交互界面。

Result: PPR-AKG方法能够有效地支持基于明确表示的能力的资源分配，以及识别和缓解生产中的不期望状况。该模型捕获了多维度的生产知识，并能与基于LLM的聊天机器人结合以实现人机交互。

Conclusion: 该研究提出了PPR-AKG模型，并结合了基于LLM的聊天机器人，以应对工业4.0中柔性化生产系统（CPPS）的质量保证挑战，能够有效地支持资源分配和识别与缓解生产中的不期望状况。

Abstract: Contemporary industrial cyber-physical production systems (CPPS) composed of
robotic workcells face significant challenges in the analysis of undesired
conditions due to the flexibility of Industry 4.0 that disrupts traditional
quality assurance mechanisms. This paper presents a novel industry-oriented
semantic model called Product-Process-Resource Asset Knowledge Graph (PPR-AKG),
which is designed to analyze and mitigate undesired conditions in flexible
CPPS. Built on top of the well-proven Product-Process-Resource (PPR) model
originating from ISA-95 and VDI-3682, a comprehensive OWL ontology addresses
shortcomings of conventional model-driven engineering for CPPS, particularly
inadequate undesired condition and error handling representation. The
integration of semantic technologies with large language models (LLMs) provides
intuitive interfaces for factory operators, production planners, and engineers
to interact with the entire model using natural language. Evaluation with the
use case addressing electric vehicle battery remanufacturing demonstrates that
the PPR-AKG approach efficiently supports resource allocation based on
explicitly represented capabilities as well as identification and mitigation of
undesired conditions in production. The key contributions include (1) a
holistic PPR-AKG model capturing multi-dimensional production knowledge, and
(2) the useful combination of the PPR-AKG with LLM-based chatbots for human
interaction.

</details>


### [298] [Situationally-aware Path Planning Exploiting 3D Scene Graphs](https://arxiv.org/abs/2508.06283)
*Saad Ejaz,Marco Giberna,Muhammad Shaheer,Jose Andres Millan-Romera,Ali Tourani,Paul Kremer,Holger Voos,Jose Luis Sanchez-Lopez*

Main category: cs.RO

TL;DR: S-Path leverages 3D Scene Graphs for efficient and interpretable path planning in indoor environments, outperforming traditional methods in complex situations.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the underutilization of the metric-semantic structure of 3D Scene Graphs for improving path planning efficiency and interpretability.

Method: S-Path uses a two-stage process: first, it searches a semantic graph derived from the 3D scene graph for a high-level path and identifies relevant planning regions. Then, it decomposes the problem into smaller subproblems solved in parallel. It also includes a replanning mechanism that reuses information from solved subproblems to update semantic heuristics for future planning attempts.

Result: Extensive experiments show S-Path achieves average reductions of 5.7x in planning time compared to classical sampling-based planners, maintains comparable path optimality, and surpasses them in complex scenarios.

Conclusion: S-Path is an efficient and interpretable path planner for indoor 3D Scene Graphs, achieving significant reductions in planning time while maintaining comparable path optimality.

Abstract: 3D Scene Graphs integrate both metric and semantic information, yet their
structure remains underutilized for improving path planning efficiency and
interpretability. In this work, we present S-Path, a situationally-aware path
planner that leverages the metric-semantic structure of indoor 3D Scene Graphs
to significantly enhance planning efficiency. S-Path follows a two-stage
process: it first performs a search over a semantic graph derived from the
scene graph to yield a human-understandable high-level path. This also
identifies relevant regions for planning, which later allows the decomposition
of the problem into smaller, independent subproblems that can be solved in
parallel. We also introduce a replanning mechanism that, in the event of an
infeasible path, reuses information from previously solved subproblems to
update semantic heuristics and prioritize reuse to further improve the
efficiency of future planning attempts. Extensive experiments on both
real-world and simulated environments show that S-Path achieves average
reductions of 5.7x in planning time while maintaining comparable path
optimality to classical sampling-based planners and surpassing them in complex
scenarios, making it an efficient and interpretable path planner for
environments represented by indoor 3D Scene Graphs.

</details>


### [299] [Real-Time 3D Vision-Language Embedding Mapping](https://arxiv.org/abs/2508.06291)
*Christian Rauch,Björn Ellensohn,Linus Nwankwo,Vedant Dave,Elmar Rueckert*

Main category: cs.RO

TL;DR: This paper presents a real-time method to create accurate 3D semantic representations for robots by integrating 2D vision-language embeddings, improving object localization and performance in various robotic tasks.


<details>
  <summary>Details</summary>
Motivation: To create a metric-accurate semantic 3D representation for robotic tasks by integrating 2D embeddings from a Vision-Language Model in real-time.

Method: The paper proposes integrating 2D embeddings from a Vision-Language Model into a metric-accurate 3D representation using a local embedding masking strategy and confidence-weighted 3D integration.

Result: The approach results in a metric-accurate embedding representation that enables accurate object-of-interest localization and improved runtime performance, meeting real-time constraints.

Conclusion: The proposed method achieves accurate object localization and improves runtime performance for real-time robotic applications, demonstrating versatility across various robotic tasks using only raw image data.

Abstract: A metric-accurate semantic 3D representation is essential for many robotic
tasks. This work proposes a simple, yet powerful, way to integrate the 2D
embeddings of a Vision-Language Model in a metric-accurate 3D representation at
real-time. We combine a local embedding masking strategy, for a more distinct
embedding distribution, with a confidence-weighted 3D integration for more
reliable 3D embeddings. The resulting metric-accurate embedding representation
is task-agnostic and can represent semantic concepts on a global multi-room, as
well as on a local object-level. This enables a variety of interactive robotic
applications that require the localisation of objects-of-interest via natural
language. We evaluate our approach on a variety of real-world sequences and
demonstrate that these strategies achieve a more accurate object-of-interest
localisation while improving the runtime performance in order to meet our
real-time constraints. We further demonstrate the versatility of our approach
in a variety of interactive handheld, mobile robotics and manipulation tasks,
requiring only raw image data.

</details>


### [300] [Evaluating Robot Program Performance with Power Consumption Driven Metrics in Lightweight Industrial Robots](https://arxiv.org/abs/2508.06295)
*Juan Heredia,Emil Stubbe Kolvig-Raun,Sune Lundo Sorensen,Mikkel Baun Kjaergaard*

Main category: cs.RO

TL;DR: 本研究提出了一种新颖的框架，从具身角度通过分析机器人电能剖面来评估机器人程序性能，解决了传统CPU指标忽视代码物理影响的问题。该框架使用能量利用系数、能量转换指标和可靠性系数等指标，并通过实验验证了其有效性，为优化机器人编程和实现可持续制造提供了指导。


<details>
  <summary>Details</summary>
Motivation: 传统的工业机器人代码性能分析方法主要关注CPU指标，而忽视了代码对机器人行为的物理影响。本研究旨在弥补这一不足，提出一种从具身角度评估机器人程序性能的新方法。

Method: 本研究提出了一种新颖的框架，从具身角度评估机器人程序性能，通过分析机器人电能剖面，并引入了能量利用系数、能量转换指标和可靠性系数这套归一化指标，同时结合了机器人磨损度指标，以捕捉能源使用效率和可靠性。

Result: 通过在机器人工料搬运任务的实验案例研究中，对UR5e机器人上的四种不同策略程序进行评估，证明了所提出的指标可以直接比较和区分不同的机器人程序，揭示了每种策略的优缺点。

Conclusion: 本研究提出的从具身角度评估机器人程序性能的框架，通过分析机器人的电能剖面，能够有效捕捉代码性能的物理体现，为优化机器人编程实践提供了可行的见解，并有助于实现可持续制造和降低成本的工业目标。

Abstract: The code performance of industrial robots is typically analyzed through CPU
metrics, which overlook the physical impact of code on robot behavior. This
study introduces a novel framework for assessing robot program performance from
an embodiment perspective by analyzing the robot's electrical power profile.
Our approach diverges from conventional CPU based evaluations and instead
leverages a suite of normalized metrics, namely, the energy utilization
coefficient, the energy conversion metric, and the reliability coefficient, to
capture how efficiently and reliably energy is used during task execution.
Complementing these metrics, the established robot wear metric provides further
insight into long term reliability. Our approach is demonstrated through an
experimental case study in machine tending, comparing four programs with
diverse strategies using a UR5e robot. The proposed metrics directly compare
and categorize different robot programs, regardless of the specific task, by
linking code performance to its physical manifestation through power
consumption patterns. Our results reveal the strengths and weaknesses of each
strategy, offering actionable insights for optimizing robot programming
practices. Enhancing energy efficiency and reliability through this embodiment
centric approach not only improves individual robot performance but also
supports broader industrial objectives such as sustainable manufacturing and
cost reduction.

</details>


### [301] [Surrogate-Enhanced Modeling and Adaptive Modular Control of All-Electric Heavy-Duty Robotic Manipulators](https://arxiv.org/abs/2508.06313)
*Amir Hossein Barjini,Mohammad Bahari,Mahdi Hejrati,Jouni Mattila*

Main category: cs.RO

TL;DR: 本文提出了一种用于全电动重型机器人操作器（HDRM）的建模与控制框架。该框架结合了神经网络和虚拟分解控制（VDC），并通过了仿真和实验验证，实现了高精度跟踪，可用于下一代移动工作机器。


<details>
  <summary>Details</summary>
Motivation: 为了给全电动重型机器人操作器（HDRM）提供一个统一的系统级建模和控制框架，以实现精确的实时控制，支持其在下一代移动工作机器中的部署。

Method: 提出了一种统一的系统级建模和控制框架，该框架针对由机电线性执行器（EMLA）驱动的全电动重型机器人操作器（HDRM）。该框架集成了结合了集成机电动力学和在专用测试台上训练的神经网络的替代增强执行器模型，并将其集成到具有自然自适应律的扩展虚拟分解控制（VDC）架构中。所导出的分析HDRM模型支持一种分层控制结构，该结构可将高级力和速度目标无缝映射到实时执行器命令，并附有基于Lyapunov的稳定性证明。

Result: 在立方体和自定义平面三角形轨迹的多域仿真中，所提出的自适应模块化控制器实现了厘米级以下的笛卡尔跟踪精度。在同一1自由度平台上进行了实验验证，该平台在现实负载模拟下进行了验证，证实了所提出控制策略的有效性。

Conclusion: 该研究提出的自适应模块化控制器通过嵌入VDC方法中的替代增强EMLA模型，能够实现全电动HDRM的模块化、实时控制，支持其在下一代移动工作机器中的部署。

Abstract: This paper presents a unified system-level modeling and control framework for
an all-electric heavy-duty robotic manipulator (HDRM) driven by
electromechanical linear actuators (EMLAs). A surrogate-enhanced actuator
model, combining integrated electromechanical dynamics with a neural network
trained on a dedicated testbed, is integrated into an extended virtual
decomposition control (VDC) architecture augmented by a natural adaptation law.
The derived analytical HDRM model supports a hierarchical control structure
that seamlessly maps high-level force and velocity objectives to real-time
actuator commands, accompanied by a Lyapunov-based stability proof. In
multi-domain simulations of both cubic and a custom planar triangular
trajectory, the proposed adaptive modular controller achieves sub-centimeter
Cartesian tracking accuracy. Experimental validation of the same 1-DoF platform
under realistic load emulation confirms the efficacy of the proposed control
strategy. These findings demonstrate that a surrogate-enhanced EMLA model
embedded in the VDC approach can enable modular, real-time control of an
all-electric HDRM, supporting its deployment in next-generation mobile working
machines.

</details>


### [302] [Towards Balanced Behavior Cloning from Imbalanced Datasets](https://arxiv.org/abs/2508.06319)
*Sagar Parekh,Heramb Nemlekar,Dylan P. Losey*

Main category: cs.RO

TL;DR: 模仿学习中的数据不平衡问题会影响算法性能。本研究分析了该问题，并提出了一种新的元梯度再平衡算法，以提高学习性能。


<details>
  <summary>Details</summary>
Motivation: 人类演示数据集中存在数据不平衡问题，即人类演示者会更频繁地演示某些子任务。现有的学习方法将人类数据集中的每个元素同等对待，这会导致学习算法更侧重于演示次数较多的行为，而不是人类复杂、多任务的演示。

Method: 分析了数据不平衡对模仿学习的影响，并探索了无需人工干预即可重新平衡离线数据集（即重新加权不同状态-动作对的重要性）的算法。最后，提出了一种新颖的元梯度再平衡算法。

Result: 证明了数据不平衡会导致策略不平衡，并提出了能自动处理混合数据集的学习方法。同时，分析了不同自主重新平衡方法的优缺点，为研究人员提供了选择依据。

Conclusion: 该研究提出了一个新颖的元梯度再平衡算法，以解决现有方法的主要局限性，并通过实验证明数据集再平衡可以提高通用模仿学习算法的性能，而无需额外的数据收集。

Abstract: Robots should be able to learn complex behaviors from human demonstrations.
In practice, these human-provided datasets are inevitably imbalanced: i.e., the
human demonstrates some subtasks more frequently than others. State-of-the-art
methods default to treating each element of the human's dataset as equally
important. So if -- for instance -- the majority of the human's data focuses on
reaching a goal, and only a few state-action pairs move to avoid an obstacle,
the learning algorithm will place greater emphasis on goal reaching. More
generally, misalignment between the relative amounts of data and the importance
of that data causes fundamental problems for imitation learning approaches. In
this paper we analyze and develop learning methods that automatically account
for mixed datasets. We formally prove that imbalanced data leads to imbalanced
policies when each state-action pair is weighted equally; these policies
emulate the most represented behaviors, and not the human's complex, multi-task
demonstrations. We next explore algorithms that rebalance offline datasets
(i.e., reweight the importance of different state-action pairs) without human
oversight. Reweighting the dataset can enhance the overall policy performance.
However, there is no free lunch: each method for autonomously rebalancing
brings its own pros and cons. We formulate these advantages and disadvantages,
helping other researchers identify when each type of approach is most
appropriate. We conclude by introducing a novel meta-gradient rebalancing
algorithm that addresses the primary limitations behind existing approaches.
Our experiments show that dataset rebalancing leads to better downstream
learning, improving the performance of general imitation learning algorithms
without requiring additional data collection. See our project website:
https://collab.me.vt.edu/data_curation/.

</details>


### [303] [L2Calib: $SE(3)$-Manifold Reinforcement Learning for Robust Extrinsic Calibration with Degenerate Motion Resilience](https://arxiv.org/abs/2508.06330)
*Baorun Li,Chengrui Zhu,Siyi Du,Bingran Chen,Jie Ren,Wenfei Wang,Yong Liu,Jiajun Lv*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习的鲁棒外特性校准框架，无需结构化目标或充分激励的数据，即可在多种机器人平台上实现高精度校准。


<details>
  <summary>Details</summary>
Motivation: 现有外特性校准方法依赖于结构化目标或充分激励的数据，限制了在真实世界中的应用。在线校准在激励不足的情况下进一步受到影响，导致估计不可靠。

Method: 提出了一种基于强化学习（RL）的外特性校准框架，将外特性校准构建为决策问题，直接优化SE(3)外特性以提高里程计精度。该方法利用概率性的Bingham分布对3D旋转进行建模，以实现稳定的优化，同时保留了四元数对称性。轨迹对齐奖励机制通过量化评估估计的紧耦合轨迹与参考轨迹，实现了在没有结构化目标情况下的鲁棒校准。此外，自动数据选择模块过滤了信息量不足的样本，显著提高了大规模数据集的效率和可扩展性。

Result: 在UAV、UGV和手持平台上的大量实验表明，我们提出的方法优于传统的基于优化的方法，即使在激励不足的条件下也能实现高精度校准。

Conclusion: 该框架通过消除对高质量初始外特性的需求，并能够从常规操作数据中进行校准，简化了在不同机器人平台上部署的流程。

Abstract: Extrinsic calibration is essential for multi-sensor fusion, existing methods
rely on structured targets or fully-excited data, limiting real-world
applicability. Online calibration further suffers from weak excitation, leading
to unreliable estimates. To address these limitations, we propose a
reinforcement learning (RL)-based extrinsic calibration framework that
formulates extrinsic calibration as a decision-making problem, directly
optimizes $SE(3)$ extrinsics to enhance odometry accuracy. Our approach
leverages a probabilistic Bingham distribution to model 3D rotations, ensuring
stable optimization while inherently retaining quaternion symmetry. A
trajectory alignment reward mechanism enables robust calibration without
structured targets by quantitatively evaluating estimated tightly-coupled
trajectory against a reference trajectory. Additionally, an automated data
selection module filters uninformative samples, significantly improving
efficiency and scalability for large-scale datasets. Extensive experiments on
UAVs, UGVs, and handheld platforms demonstrate that our method outperforms
traditional optimization-based approaches, achieving high-precision calibration
even under weak excitation conditions. Our framework simplifies deployment on
diverse robotic platforms by eliminating the need for high-quality initial
extrinsics and enabling calibration from routine operating data. The code is
available at https://github.com/APRIL-ZJU/learn-to-calibrate.

</details>


### [304] [V*: An Efficient Motion Planning Algorithm for Autonomous Vehicles](https://arxiv.org/abs/2508.06404)
*Abdullah Zareh Andaryan,Michael G. H. Bell,Mohsen Ramezani,Glenn Geers*

Main category: cs.RO

TL;DR: V*是一种用于自主车辆导航的运动规划器，它通过时空速度格和动态图生成来优化轨迹，并能在复杂环境中有效避障。


<details>
  <summary>Details</summary>
Motivation: 旨在解决结构化环境中自主车辆导航中的时间最优、无碰撞轨迹规划问题，同时满足动态和运动学约束。

Method: V*是一种基于图的运动规划器，使用时空速度格表示状态，并通过动态图生成来集成运动规划的两个维度。它采用六边形离散化策略，并结合瞬态转向动力学和几何修剪策略来确保轨迹的可行性。

Result: V*在模拟研究中，能够在杂乱和动态环境中，包括移动障碍物，生成安全、高效且具有时间推理能力的轨迹，并能主动避让和进行动态协调。

Conclusion: V*通过在时空速度格中显式地表示速度和方向，并集成空间搜索和动态可行性，实现了时间最优、无碰撞的轨迹规划。

Abstract: Autonomous vehicle navigation in structured environments requires planners
capable of generating time-optimal, collision-free trajectories that satisfy
dynamic and kinematic constraints. We introduce V*, a graph-based motion
planner that represents speed and direction as explicit state variables within
a discretised space-time-velocity lattice. Unlike traditional methods that
decouple spatial search from dynamic feasibility or rely on post-hoc smoothing,
V* integrates both motion dimensions directly into graph construction through
dynamic graph generation during search expansion. To manage the complexity of
high-dimensional search, we employ a hexagonal discretisation strategy and
provide formal mathematical proofs establishing optimal waypoint spacing and
minimal node redundancy under constrained heading transitions for
velocity-aware motion planning. We develop a mathematical formulation for
transient steering dynamics in the kinematic bicycle model, modelling steering
angle convergence with exponential behaviour, and deriving the relationship for
convergence rate parameters. This theoretical foundation, combined with
geometric pruning strategies that eliminate expansions leading to infeasible
steering configurations, enables V* to evaluate dynamically admissible
manoeuvres, ensuring each trajectory is physically realisable without further
refinement. We further demonstrate V*'s performance in simulation studies with
cluttered and dynamic environments involving moving obstacles, showing its
ability to avoid conflicts, yield proactively, and generate safe, efficient
trajectories with temporal reasoning capabilities for waiting behaviours and
dynamic coordination.

</details>


### [305] [Shortcut Learning in Generalist Robot Policies: The Role of Dataset Diversity and Fragmentation](https://arxiv.org/abs/2508.06426)
*Youguang Xing,Xu Luo,Junlin Xie,Lianli Gao,Hengtao Shen,Jingkuan Song*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Generalist robot policies trained on large-scale datasets such as Open
X-Embodiment (OXE) demonstrate strong performance across a wide range of tasks.
However, they often struggle to generalize beyond the distribution of their
training data. In this paper, we investigate the underlying cause of this
limited generalization capability. We identify shortcut learning -- the
reliance on task-irrelevant features -- as a key impediment to generalization.
Through comprehensive theoretical and empirical analysis, we uncover two
primary contributors to shortcut learning: (1) limited diversity within
individual sub-datasets, and (2) significant distributional disparities across
sub-datasets, leading to dataset fragmentation. These issues arise from the
inherent structure of large-scale datasets like OXE, which are typically
composed of multiple sub-datasets collected independently across varied
environments and embodiments. Our findings provide critical insights into
dataset collection strategies that can reduce shortcut learning and enhance the
generalization ability of generalist robot policies. Moreover, in scenarios
where acquiring new large-scale data is impractical, we demonstrate that
carefully selected robotic data augmentation strategies can effectively reduce
shortcut learning in existing offline datasets, thereby improving
generalization capabilities of generalist robot policies, e.g., $\pi_0$, in
both simulation and real-world environments. More information at
https://lucky-light-sun.github.io/proj/shortcut-learning-in-grps/.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [306] [DogFit: Domain-guided Fine-tuning for Efficient Transfer Learning of Diffusion Models](https://arxiv.org/abs/2508.05685)
*Yara Bahram,Mohammadhadi Shateri,Eric Granger*

Main category: cs.GR

TL;DR: DogFit 是一种新的扩散模型迁移学习方法，可以在不增加计算成本的情况下实现可控性。它通过将领域感知引导偏移量注入训练损失来实现这一点，并使用轻量级条件机制来编码引导强度。实验表明，DogFit 在图像质量和效率方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 将预训练的扩散模型迁移到新的领域时，微调往往会导致泛化能力下降。现有的测试时引导方法虽然可以改善图像保真度，但计算成本高昂。DogFit 的动机是在不增加计算开销的情况下，实现可控的迁移学习。

Method: DogFit 通过将领域感知引导偏移量注入训练损失，在微调过程中有效内化引导行为。通过将引导强度值作为额外模型输入，实现了高效的可控保真度-多样性权衡。研究了引导偏移量在训练中的最佳放置和时机，并提出了 late-start 和 cut-off 两种调度策略。

Result: DogFit 在 DiT 和 SiT 主干网络以及六个不同的目标领域上进行了实验。结果表明，DogFit 在 FID 和 FDDINOV2 方面优于先前的方法，同时采样 TFLOPS 最多可减少 2 倍。

Conclusion: DogFit 通过将领域感知引导偏移量注入训练损失，在微调过程中有效内化引导行为，从而在不产生额外计算开销的情况下，在扩散迁移学习中实现了可控性。通过将引导强度值作为额外模型输入，实现了高效的可控保真度-多样性权衡。实验表明，DogFit 在迁移学习方面的 FID 和 FDDINOV2 方面优于先前的方法，同时采样 TFLOPS 最多可减少 2 倍。

Abstract: Transfer learning of diffusion models to smaller target domains is
challenging, as naively fine-tuning the model often results in poor
generalization. Test-time guidance methods help mitigate this by offering
controllable improvements in image fidelity through a trade-off with sample
diversity. However, this benefit comes at a high computational cost, typically
requiring dual forward passes during sampling. We propose the Domain-guided
Fine-tuning (DogFit) method, an effective guidance mechanism for diffusion
transfer learning that maintains controllability without incurring additional
computational overhead. DogFit injects a domain-aware guidance offset into the
training loss, effectively internalizing the guided behavior during the
fine-tuning process. The domain-aware design is motivated by our observation
that during fine-tuning, the unconditional source model offers a stronger
marginal estimate than the target model. To support efficient controllable
fidelity-diversity trade-offs at inference, we encode the guidance strength
value as an additional model input through a lightweight conditioning
mechanism. We further investigate the optimal placement and timing of the
guidance offset during training and propose two simple scheduling strategies,
i.e., late-start and cut-off, which improve generation quality and training
stability. Experiments on DiT and SiT backbones across six diverse target
domains show that DogFit can outperform prior guidance methods in transfer
learning in terms of FID and FDDINOV2 while requiring up to 2x fewer sampling
TFLOPS.

</details>


### [307] [Exploring Interactive Simulation of Grass Display Color Characteristic Based on Real-World Conditions](https://arxiv.org/abs/2508.06086)
*Kojiro Tanaka,Keiichi Sato,Masahiko Mikawa,Makoto Fujisawa*

Main category: cs.GR

TL;DR: 本研究提出了一种在虚拟环境中交互式模拟草地颜色变化的方法，解决了传统方法耗时昂贵的问题。该方法模拟结果准确且效率高。


<details>
  <summary>Details</summary>
Motivation: 为了开发草地显示器，需要获得依赖于真实环境的草地颜色变化特征。然而，传统方法在每次更改照明或视点时都需要在实际设备上进行实验，这既耗时又昂贵。目前已有一些模拟草地颜色的研究，但仍存在测量单个样本需要数小时的重大问题。

Method: 通过在虚拟环境中，基于真实世界的条件，交互式地模拟草地显示器的颜色变化特征。

Result: 对该方法在多个视点和环境下的模拟草地颜色特征进行了准确性评估，并与先前研究进行了比较。结果表明，该方法模拟的草地颜色特征与实际情况相似，并且具有更快、准确性相当的潜力。

Conclusion: 该方法倾向于模拟与实际情况相似的草地颜色特征，并且能够比先前研究更快、同样准确地进行模拟。

Abstract: Recent research has focused on incorporating media into living environments
via color-controlled materials and image display. In particular, grass-based
displays have drawn attention as landscape-friendly interactive interfaces. To
develop the grass display, it is important to obtain the grass color change
characteristics that depend on the real environment. However, conventional
methods require experiments on actual equipment every time the lighting or
viewpoint changes, which is time-consuming and costly. Although research has
begun on simulating grass colors, this approach still faces significant issues
as it takes many hours for a single measurement. In this paper, we explore an
interactive simulation of a grass display color change characteristic based on
real-world conditions in a virtual environment. We evaluated our method's
accuracy by simulating grass color characteristics across multiple viewpoints
and environments, and then compared the results against prior work. The results
indicated that our method tended to simulate the grass color characteristics
similar to the actual characteristics and showed the potential to do so more
quickly and with comparable accuracy to the previous study.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [308] [Risk Analysis Techniques for Governed LLM-based Multi-Agent Systems](https://arxiv.org/abs/2508.05687)
*Alistair Reid,Simon O'Callaghan,Liam Carroll,Tiberio Caetano*

Main category: cs.MA

TL;DR: LLM多代理系统的风险分析方法需要更新，以应对交互中的涌现行为。本研究提出了一种分阶段测试方法，并识别了六种关键的故障模式，为组织风险管理奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 随着组织开始采用基于LLM的AI代理，并从单一代理发展到互联的多代理网络，现有的风险分析方法已不足以应对多代理系统交互带来的新兴行为和故障模式。因此，有必要为多代理AI系统开发一种新的风险分析方法。

Method: 本研究提出了一种以分析有效性为中心的方法，通过在不同抽象和部署阶段进行分阶段测试来逐步提高有效性。测试方法包括模拟、观察性分析、基准测试和红队演练，以收集一致的证据。

Result: 报告详细介绍了六种关键的故障模式：级联可靠性故障、代理间通信故障、单一文化崩溃、从众偏差、心智理论缺陷和混合动机动态。针对每种模式，报告提供了一个工具包，供从业者扩展或集成到现有框架中，以评估其组织环境中的故障模式。

Conclusion: 多智能体AI系统需要不同于单智能体AI系统的风险分析方法，以应对交互中出现的涌现行为和新的故障模式。本报告提供了一个风险识别和分析的框架，以应对由组织控制的、以LLM为基础的多智能体系统。

Abstract: Organisations are starting to adopt LLM-based AI agents, with their
deployments naturally evolving from single agents towards interconnected,
multi-agent networks. Yet a collection of safe agents does not guarantee a safe
collection of agents, as interactions between agents over time create emergent
behaviours and induce novel failure modes. This means multi-agent systems
require a fundamentally different risk analysis approach than that used for a
single agent.
  This report addresses the early stages of risk identification and analysis
for multi-agent AI systems operating within governed environments where
organisations control their agent configurations and deployment. In this
setting, we examine six critical failure modes: cascading reliability failures,
inter-agent communication failures, monoculture collapse, conformity bias,
deficient theory of mind, and mixed motive dynamics. For each, we provide a
toolkit for practitioners to extend or integrate into their existing frameworks
to assess these failure modes within their organisational contexts.
  Given fundamental limitations in current LLM behavioural understanding, our
approach centres on analysis validity, and advocates for progressively
increasing validity through staged testing across stages of abstraction and
deployment that gradually increases exposure to potential negative impacts,
while collecting convergent evidence through simulation, observational
analysis, benchmarking, and red teaming. This methodology establishes the
groundwork for robust organisational risk management as these LLM-based
multi-agent systems are deployed and operated.

</details>


### [309] [Semantic Reasoning Meets Numerical Precision: An LLM-Powered Multi-Agent System for Power Grid Control](https://arxiv.org/abs/2508.05702)
*Yan Zhang*

Main category: cs.MA

TL;DR: Grid-Agent 是一个结合了 LLM 和多智能体强化学习的 AI 框架，用于实时检测和修复电网违规。它通过规划和验证智能体实现语义推理和数值精度，并采用自适应多尺度网络表示确保可扩展性。实验证明其性能优越，适用于智能电网。


<details>
  <summary>Details</summary>
Motivation: 由于分布式能源 (DER)、电动汽车 (EV) 和极端天气事件的日益普及，电力系统的规划、运行和管理变得日益复杂。传统的基于规则的系统和数值优化方法难以满足现代电力网络对规模、动态和适应性的要求。

Method: 本研究引入了一个名为 Grid-Agent 的自主 AI 驱动框架，该框架结合了大型语言模型 (LLM) 和多智能体强化学习，可实时检测和修复电网违规。Grid-Agent 通过模块化智能体架构整合了语义推理和数值精度：一个规划智能体使用数值潮流求解器生成协调的动作序列，而一个验证智能体通过沙盒执行和安全回滚来评估系统稳定性和动作有效性。为了确保可扩展性，Grid-Agent 采用了一种自适应多尺度网络表示，根据网络的大小和复杂性动态选择最优编码方案。

Result: 实验结果表明，Grid-Agent 框架能够通过优化开关配置、电池部署和负荷削减策略，实现协调的违规解决。

Conclusion: Grid-Agent 框架在 IEEE 69 总线、CIGRE 变电站和 IEEE 30 总线等标准 IEEE 和 CIGRE 测试系统中展示了优越的违规缓解性能，并具备内置的数据收集和学习能力，可实现持续学习和适应不同网络拓扑，特别适用于需要对动态运行条件做出快速响应的现代智能电网应用。

Abstract: The increasing penetration of Distributed Energy Resources (DERs), widespread
adoption of Electric Vehicles (EVs), and the growing frequency of extreme
weather events have significantly increased the complexity of power grid
planning, operation, and management. Traditional rule-based systems and
numerical optimization approaches often struggle with the scale, dynamics, and
adaptability required by modern power networks. This paper introduces
Grid-Agent, an autonomous, AI-driven framework that combines Large Language
Models (LLMs) with multi-agent reinforcement learning to detect and remediate
grid violations in real time. Grid-Agent integrates semantic reasoning with
numerical precision through a modular agent architecture: a planning agent
generates coordinated action sequences using numerical power flow solvers,
while a validation agent evaluates system stability and action effectiveness
via sandboxed execution with safety rollbacks. To ensure scalability,
Grid-Agent incorporates an adaptive multiscale network representation that
dynamically selects optimal encoding schemes based on network size and
complexity. The framework enables coordinated violation resolution through
optimizing switch configurations, battery deployment, and load curtailment
strategies. Experimental results in standard IEEE and CIGRE test systems (IEEE
69-bus, CIGRE MV, and IEEE 30-bus) demonstrate superior violation mitigation
performance. Additionally, the framework's built-in data collection and
learning capabilities enable continuous learning and adaptation to diverse
network topologies. The autonomous nature of the framework makes it
particularly suitable for modern smart grid applications requiring rapid
response to dynamic operating conditions.

</details>


### [310] [Flow-Based Task Assignment for Large-Scale Online Multi-Agent Pickup and Delivery](https://arxiv.org/abs/2508.05890)
*Yue Zhang,Zhe Chen,Daniel Harabor,Pierre Le Bodic,Peter J. Stuckey*

Main category: cs.MA

TL;DR: 该研究提出了一种将 MAPD 中的任务分配视为最小成本流问题的方法，通过集成实时交通估计来提高效率和质量，并能大规模应用于具有挑战性的场景。


<details>
  <summary>Details</summary>
Motivation: 在线多代理拾取和交付（MAPD）问题，其中一组代理必须在共享地图上反复服务动态出现的任务。现有的在线方法要么依赖于简单的启发式方法（导致决策不佳），要么采用复杂的推理（在实时约束下可扩展性有限）。

Method: 将任务分配子问题制定为环境图上的最小成本流问题，消除了对成对距离计算的需求，并允许同时将代理分配给任务并将其路由到任务。所生成的流网络还支持高效的引导路径提取，以与规划器集成，并加快实时约束下的规划速度。

Result: 所提出的方法支持实时执行，可扩展到超过 20000 个代理和 30000 个任务，同时在 1 秒的规划时间内，在计算效率和分配质量方面均优于现有基线。

Conclusion: 所提出的方法在计算效率和分配质量方面均优于现有基线，并且可以支持实时执行，可扩展到超过 20000 个代理和 30000 个任务，同时在 1 秒的规划时间内。

Abstract: We study the problem of online Multi-Agent Pickup and Delivery (MAPD), where
a team of agents must repeatedly serve dynamically appearing tasks on a shared
map. Existing online methods either rely on simple heuristics, which result in
poor decisions, or employ complex reasoning, which suffers from limited
scalability under real-time constraints. In this work, we focus on the task
assignment subproblem and formulate it as a minimum-cost flow over the
environment graph. This eliminates the need for pairwise distance computations
and allows agents to be simultaneously assigned to tasks and routed toward
them. The resulting flow network also supports efficient guide path extraction
to integrate with the planner and accelerates planning under real-time
constraints. To improve solution quality, we introduce two congestion-aware
edge cost models that incorporate real-time traffic estimates. This approach
supports real-time execution and scales to over 20000 agents and 30000 tasks
within 1-second planning time, outperforming existing baselines in both
computational efficiency and assignment quality.

</details>


### [311] [Policy Optimization in Multi-Agent Settings under Partially Observable Environments](https://arxiv.org/abs/2508.06061)
*Ainur Zhaikhan,Malek Khammassi,Ali H. Sayed*

Main category: cs.MA

TL;DR: 所提出的方法利用自适应社会学习来估计MARL问题中部分可观察的全局状态，通过交替进行社会学习和MARL来实现，避免了耗时的两时间尺度学习框架。


<details>
  <summary>Details</summary>
Motivation: 利用自适应社会学习来估计MARL问题中部分可观察的全局状态。

Method: 通过交替进行社会学习和多智能体强化学习（MARL）来实现，避免了耗时的两时间尺度学习框架。

Result: 该方法在模拟结果中得到了验证，其性能接近于已知真实状态的强化学习。

Conclusion: 所提出的方法可以通过与已知真实状态的强化学习方法相媲美的性能来验证。

Abstract: This work leverages adaptive social learning to estimate partially observable
global states in multi-agent reinforcement learning (MARL) problems. Unlike
existing methods, the proposed approach enables the concurrent operation of
social learning and reinforcement learning. Specifically, it alternates between
a single step of social learning and a single step of MARL, eliminating the
need for the time- and computation-intensive two-timescale learning frameworks.
Theoretical guarantees are provided to support the effectiveness of the
proposed method. Simulation results verify that the performance of the proposed
methodology can approach that of reinforcement learning when the true state is
known.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [312] [Debiasing Polynomial and Fourier Regression](https://arxiv.org/abs/2508.05920)
*Chris Camaño,Raphael A. Meyer,Kevin Shu*

Main category: cs.DS

TL;DR: 为了无偏地逼近未知函数，我们提出了一种基于随机矩阵理论和多项式回归的方法，通过评估特定随机矩阵的特征值来消除偏差，该方法样本复杂度接近最优，并且优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有随机算法在恢复最优多项式逼近方面具有接近最优的样本复杂度，但会产生有偏估计，这是不可取的。

Method: 通过评估特定设计的随机复数矩阵的特征值（$
u_1,
u_2,
u_3$），利用多项式回归和随机矩阵理论之间的联系来消除偏差。

Result: 所提出的无偏估计量具有接近最优的样本复杂度，并且在实验中优于独立同分布抽样。此外，该技术还可用于改进周期函数傅里叶级数逼近的现有方法。

Conclusion: 所提出的方法可以无偏估计最佳多项式逼近，样本复杂度接近最优，并且在实验中优于独立同分布抽样。

Abstract: We study the problem of approximating an unknown function
$f:\mathbb{R}\to\mathbb{R}$ by a degree-$d$ polynomial using as few function
evaluations as possible, where error is measured with respect to a probability
distribution $\mu$. Existing randomized algorithms achieve near-optimal sample
complexities to recover a $ (1+\varepsilon) $-optimal polynomial but produce
biased estimates of the best polynomial approximation, which is undesirable.
  We propose a simple debiasing method based on a connection between polynomial
regression and random matrix theory. Our method involves evaluating
$f(\lambda_1),\ldots,f(\lambda_{d+1})$ where $\lambda_1,\ldots,\lambda_{d+1}$
are the eigenvalues of a suitably designed random complex matrix tailored to
the distribution $\mu$. Our estimator is unbiased, has near-optimal sample
complexity, and experimentally outperforms iid leverage score sampling.
  Additionally, our techniques enable us to debias existing methods for
approximating a periodic function with a truncated Fourier series with
near-optimal sample complexity.

</details>


### [313] [A Structural Linear-Time Algorithm for Computing the Tutte Decomposition](https://arxiv.org/abs/2508.06212)
*Romain Bourneuf,Tim Planken*

Main category: cs.DS

TL;DR: 本文提出了一种新算法，在线性时间内计算图的Tutte分解，并提供了新的结构理论结果。


<details>
  <summary>Details</summary>
Motivation: 旨在扩展块-割树的概念，将图分解为三连通分量，并提供一种计算Tutte分解的线性时间算法。

Method: 本文提出了一种新算法，首先计算所有全嵌套2-分离，然后基于这些分离来构建Tutte分解。

Result: 成功地在线性时间内计算了Tutte分解，并得出了一些关于全嵌套2-分离结构的新理论结果。

Conclusion: 本文提出了一种基于全嵌套2-分离的图论分解新方法，并推导了新的结构结果。

Abstract: The block-cut tree decomposes a connected graph along its cutvertices,
displaying its 2-connected components. The Tutte-decomposition extends this
idea to 2-separators in 2-connected graphs, yielding a canonical
tree-decomposition that decomposes the graph into its triconnected components.
In 1973, Hopcroft and Tarjan introduced a linear-time algorithm to compute the
Tutte-decomposition. Cunningham and Edmonds later established a structural
characterization of the Tutte-decomposition via totally-nested 2-separations.
We present a conceptually simple algorithm based on this characterization,
which computes the Tutte-decomposition in linear time. Our algorithm first
computes all totally-nested 2-separations and then builds the
Tutte-decomposition from them.
  Along the way, we derive new structural results on the structure of
totally-nested 2-separations in 2-connected graphs using a novel notion of
stability, which may be of independent interest.

</details>


### [314] [The Beauty of Anisotropic Mesh Refinement: Omnitrees for Efficient Dyadic Discretizations](https://arxiv.org/abs/2508.06316)
*Theresa Pollinger,Masado Ishii,Jens Domke*

Main category: cs.DS

TL;DR: omnitrees是一种新的AMR数据结构，可以提高在各向异性问题上的效率，并为高维应用提供更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的八叉树AMR方法在处理内在各向异性问题时效率低下，因为它们强制进行各向同性细分，导致在信息增益很小的区域浪费了大量的分辨率。

Method: 提出了一种名为omnitree的各向异性自适应网格细分（AMR）数据结构，作为八叉树的推广，允许仅细化局部最重要的维度。

Result: 在处理3D对象形状表示的问题上，omnitrees将平均收敛率提高了1.5倍，在达到同等误差界限时需要更少的存储空间，并且比八叉树更快地最大化存储函数的信息密度。对于更高维度的问题，这些优势预计会更加明显。

Conclusion: Omnitree离散化可以提高现有AMR方法的效率，并为高维应用开辟新的可能性。

Abstract: Structured adaptive mesh refinement (AMR), commonly implemented via quadtrees
and octrees, underpins a wide range of applications including databases,
computer graphics, physics simulations, and machine learning. However, octrees
enforce isotropic refinement in regions of interest, which can be especially
inefficient for problems that are intrinsically anisotropic--much resolution is
spent where little information is gained. This paper presents omnitrees as an
anisotropic generalization of octrees and related data structures. Omnitrees
allow to refine only the locally most important dimensions, providing tree
structures that are less deep than bintrees and less wide than octrees. As a
result, the convergence of the AMR schemes can be increased by up to a factor
of the dimensionality d for very anisotropic problems, quickly offsetting their
modest increase in storage overhead. We validate this finding on the problem of
binary shape representation across 4,166 three-dimensional objects: Omnitrees
increase the mean convergence rate by 1.5x, require less storage to achieve
equivalent error bounds, and maximize the information density of the stored
function faster than octrees. These advantages are projected to be even
stronger for higher-dimensional problems. We provide a first validation by
introducing a time-dependent rotation to create four-dimensional
representations, and discuss the properties of their 4-d octree and omnitree
approximations. Overall, omnitree discretizations can make existing AMR
approaches more efficient, and open up new possibilities for high-dimensional
applications.

</details>


### [315] [A Simple PTAS for Weighted $k$-means and Sensor Coverage](https://arxiv.org/abs/2508.06460)
*Akash Pareek,Supratim Shit*

Main category: cs.DS

TL;DR: 本文提出了一种用于加权k-均值问题的简单PTAS，无需核集，并通过加权D^2采样技术解决。该算法的运行时间为n*d*2^O(k^2/ε)，可提供(1+ε)因子近似。该方法还为传感器覆盖问题提供了(1+ε)-近似，优于之前的O(log k)-近似。


<details>
  <summary>Details</summary>
Motivation: 聚类是数据分析中的基本技术，而k-均值因其简单性和广泛适用性而成为被广泛研究的目标。在实际应用中，数据点通常具有反映其重要性、频率或置信度的权重。因此，为加权k-均值问题开发高效且准确的算法具有重要意义。然而，现有的基于核集的算法虽然可以扩展到加权情况，但没有提供专门为加权k-均值问题设计的简单、无核集的PTAS。

Method: 本文提出了一种新的PTAS，用于加权k-均值问题。该方法基于Jaiswal、Kumar和Sen（2012）为未加权情况提出的框架，并引入了加权D^2采样技术来处理加权点集。算法的时间复杂度为n*d*2^O(k^2/ε)，并保证输出的k个中心的总聚类成本在(1+ε)因子内接近最优成本。

Result: 该算法的时间复杂度为n*d*2^O(k^2/ε)，可以保证输出k个中心的总聚类成本在(1+ε)因子内接近最优成本。此外，该算法为传感器覆盖问题提供了(1+ε)-近似，优于先前 trabajos 的O(log k)-近似。

Conclusion: 本文提出了加权k-均值问题的一种简单PTAS，不依赖于核集，并将加权D^2采样技术应用于Jaiswal、Kumar和Sen（2012）提出的框架，以解决加权k-均值问题。此外，该算法还为传感器覆盖问题提供了PTAS，这是加权k-均值的一个关键应用。

Abstract: Clustering is a fundamental technique in data analysis, with the $k$-means
being one of the widely studied objectives due to its simplicity and broad
applicability. In many practical scenarios, data points come with associated
weights that reflect their importance, frequency, or confidence. Given a
weighted point set $P \subset R^d$, where each point $p \in P$ has a positive
weight $w_p$, the goal is to compute a set of $k$ centers $C = \{ c_1, c_2,
\ldots, c_k \} \subset R^d$ that minimizes the weighted clustering cost:
$\Delta_w(P,C) = \sum_{p \in P} w_p \cdot d(p,C)^2$, where $d(p,C)$ denotes the
Euclidean distance from $p$ to its nearest center in $C$. Although most
existing coreset-based algorithms for $k$-means extend naturally to the
weighted setting and provide a PTAS, no prior work has offered a simple,
coreset-free PTAS designed specifically for the weighted $k$-means problem.
  In this paper, we present a simple PTAS for weighted $k$-means that does not
rely on coresets. Building upon the framework of Jaiswal, Kumar, and Sen (2012)
for the unweighted case, we extend the result to the weighted setting by using
the weighted $D^2$-sampling technique. Our algorithm runs in time $n d \cdot
2^{O\left(\frac{k^2}{\epsilon}\right)}$ and outputs a set of $k$ centers whose
total clustering cost is within a $(1 + \epsilon)$-factor of the optimal cost.
As a key application of the weighted $k$-means, we obtain a PTAS for the sensor
coverage problem, which can also be viewed as a continuous locational
optimization problem. For this problem, the best-known result prior to our work
was an $O(\log k)$-approximation by Deshpande (2014), whereas our algorithm
guarantees a $(1 + \epsilon)$-approximation to the optimal coverage cost even
before applying refinement steps like Lloyd desent.

</details>


### [316] [On the Parallel Complexity of Identifying Groups and Quasigroups via Decompositions](https://arxiv.org/abs/2508.06478)
*Dan Johnson,Michael Levet,Petr Vojtěchovský,Brett Widholm*

Main category: cs.DS

TL;DR: 本研究利用群和拟群的分解性质，在计算复杂性方面改进了同构测试的界限。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索有限群和拟群的同构测试的计算复杂性，特别是利用它们的分解结构来改进已知的上界。

Method: 本研究利用了群和拟群的各种分解性质。对于具有直接积分解的群，使用了 O(1) 维度的计数 Weisfeiler-Leman (WL) 算法，并利用了 O(1) 维度的计数 WL 算法。对于分解因子为 O(1) 生成的群，通过在乘法表模型中计算直接积分解，实现了 AC^3 规范标记过程。对于中心拟群，利用了其仿射分解性质，将其与潜在的阿贝尔群联系起来。

Result: 对于具有直接积分解且分解因子满足特定条件的群（$	extsf{C}$ 类），同构问题在 $	extsf{L}$ 中，比之前使用 $	extsf{TC}^1$ 的上界有所改进。对于分解因子为 $O(1)$-生成的群，存在一个 $	extsf{AC}^3$ 规范标记过程。对于中心拟群与任意拟群的同构测试，在 $	extsf{NC}$ 中，显著优于之前已知的 $n^{	ext{log}(n)+O(1)}$ 时间界。

Conclusion: 本研究表明，对于具有特定分解性质的有限群和拟群，它们的同构问题可以在较低的计算复杂性类别中解决。具体来说，对于具有直接积分解的群，其同构问题在 L 中；对于分解因子为 O(1) 生成的群，存在 AC^3 规范标记过程；对于中心拟群，其同构测试在 NC 中。

Abstract: In this paper, we investigate the computational complexity of isomorphism
testing for finite groups and quasigroups, given by their multiplication
tables. We crucially take advantage of their various decompositions to show the
following:
  - We first consider the class $\mathcal{C}$ of groups that admit direct
product decompositions, where each indecompsable factor is $O(1)$-generated,
and either perfect or centerless. We show any group in $\mathcal{C}$ is
identified by the $O(1)$-dimensional count-free Weisfeiler--Leman (WL)
algorithm with $O(\log \log n)$ rounds, and the $O(1)$-dimensional counting WL
algorithm with $O(1)$ rounds. Consequently, the isomorphism problem for
$\mathcal{C}$ is in $\textsf{L}$. The previous upper bound for this class was
$\textsf{TC}^{1}$, using $O(\log n)$ rounds of the $O(1)$-dimensional counting
WL (Grochow and Levet, FCT 2023).
  - We next consider more generally, the class of groups where each
indecomposable factor is $O(1)$-generated. We exhibit an $\textsf{AC}^{3}$
canonical labeling procedure for this class. Here, we accomplish this by
showing that in the multiplication table model, the direct product
decomposition can be computed in $\textsf{AC}^{3}$, parallelizing the work of
Kayal and Nezhmetdinov (ICALP 2009).
  - Isomorphism testing between a central quasigroup $G$ and an arbitrary
quasigroup $H$ is in $\textsf{NC}$. Here, we take advantage of the fact that
central quasigroups admit an affine decomposition in terms of an underlying
Abelian group. Only the trivial bound of $n^{\log(n)+O(1)}$-time was previously
known for isomorphism testing of central quasigroups.

</details>


### [317] [Does block size matter in randomized block Krylov low-rank approximation?](https://arxiv.org/abs/2508.06486)
*Tyler Chen,Ethan N. Epperly,Raphael A. Meyer,Christopher Musco,Akash Rao*

Main category: cs.DS

TL;DR: 本文研究了使用随机块克雷洛夫迭代计算矩阵的秩-$k$ 近似问题。我们证明了对于任意块大小 $1 \le b \le k$，该方法仅需 $\tilde O(k/\sqrt{\varepsilon})$ 次矩阵向量乘积即可获得 $(1 + \varepsilon)$ 因子近似的秩-$k$ 近似，解决了理论与实践之间的差距。


<details>
  <summary>Details</summary>
Motivation: 解决随机块克雷洛夫迭代在处理秩-$k$ 近似时的理论与实践之间的差距，即在块大小 $b$ 介于 $1$ 和 $k$ 之间时，现有理论界限（与 $b(k-b)$ 相关，可能达到 $O(k^2)$）与实践中优化的块大小（$1 "," b "," k$）之间的不符。

Method: 本文证明了随机块克雷洛夫迭代在任何块大小 $1 \le b \le k$ 下，都能在 $\tilde O(k/\sqrt{\varepsilon})$ 次矩阵向量乘积内得到 $(1+\varepsilon)$ 因子近似的秩-$k$ 近似。该分析依赖于对随机块克雷洛夫矩阵最小奇异值的新的界限。

Result: 实现了针对任意块大小 $1 \le b \le k$ 的秩-$k$ 近似，将所需的矩阵向量乘积数量从可能的最大 $O(k^2)$ 显著降低到 $\tilde O(k/\sqrt{\varepsilon})$，这与块大小 $b$ 无关。

Conclusion: 随机块克雷洛夫迭代可以针对任何块大小 $1 "," b "," k$，在 $	ilde O(k / \sqrt{\varepsilon})$ 次矩阵向量乘积内，生成 $(1 + \varepsilon)$ 因子近似的最佳秩-$k$ 近似。

Abstract: We study the problem of computing a rank-$k$ approximation of a matrix using
randomized block Krylov iteration. Prior work has shown that, for block size $b
= 1$ or $b = k$, a $(1 + \varepsilon)$-factor approximation to the best
rank-$k$ approximation can be obtained after $\tilde O(k/\sqrt{\varepsilon})$
matrix-vector products with the target matrix. On the other hand, when $b$ is
between $1$ and $k$, the best known bound on the number of matrix-vector
products scales with $b(k-b)$, which could be as large as $O(k^2)$.
Nevertheless, in practice, the performance of block Krylov methods is often
optimized by choosing a block size $1 \ll b \ll k$. We resolve this
theory-practice gap by proving that randomized block Krylov iteration produces
a $(1 + \varepsilon)$-factor approximate rank-$k$ approximation using $\tilde
O(k/\sqrt{\varepsilon})$ matrix-vector products for any block size $1\le b\le
k$. Our analysis relies on new bounds for the minimum singular value of a
random block Krylov matrix, which may be of independent interest. Similar
bounds are central to recent breakthroughs on faster algorithms for sparse
linear systems [Peng & Vempala, SODA 2021; Nie, STOC 2022].

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [318] [Accelerating Data Chunking in Deduplication Systems using Vector Instructions](https://arxiv.org/abs/2508.05797)
*Sreeharsha Udayashankar,Abdelrahman Baba,Samer Al-Kiswany*

Main category: cs.DC

TL;DR: VectorCDC通过向量化指令加速了数据删除中的内容分块过程，显著提高了效率。


<details>
  <summary>Details</summary>
Motivation: 现有的内容定义分块（CDC）算法是实现数据重复删除空间节省的关键，但其逐个文件扫描的特性导致速度缓慢，成为数据重复删除性能的主要瓶颈。

Method: VectorCDC利用向量CPU指令（如SSE/AVX）来加速无哈希的内容定义分块（CDC）算法。

Result: VectorCDC在Intel、AMD、ARM和IBM CPU上均实现了8.35倍至26.2倍的吞吐量提升，优于现有的向量加速技术，并且不影响重复数据删除的空间节省。

Conclusion: VectorCDC通过利用向量CPU指令（如SSE/AVX）有效加速了无哈希的内容定义分块（CDC）算法，在Intel、AMD、ARM和IBM CPU上均表现出色，吞吐量相比现有向量加速技术提高了8.35倍至26.2倍，且不影响重复数据删除的空间节省效果。

Abstract: Content-defined Chunking (CDC) algorithms dictate the overall space savings
that deduplication systems achieve. However, due to their need to scan each
file in its entirety, they are slow and often the main performance bottleneck
within data deduplication. We present VectorCDC, a method to accelerate
hashless CDC algorithms using vector CPU instructions, such as SSE / AVX. Our
evaluation shows that VectorCDC is effective on Intel, AMD, ARM, and IBM CPUs,
achieving 8.35x - 26.2x higher throughput than existing vector-accelerated
techniques without affecting the deduplication space savings.

</details>


### [319] [A Dynamic Approach to Load Balancing in Cloud Infrastructure: Enhancing Energy Efficiency and Resource Utilization](https://arxiv.org/abs/2508.05821)
*Shadman Sakib,Ajay Katangur,Rahul Dubey*

Main category: cs.DC

TL;DR: SBDLB通过实时性能指标动态调整负载，显著改善了云服务的响应时间、处理效率和成本效益，同时促进了绿色计算。


<details>
  <summary>Details</summary>
Motivation: 为了应对云环境日益增长的数据传输和用户请求，以及解决现有负载均衡技术在资源管理和工作负载均衡方面的挑战。

Method: 提出了一种基于实时性能指标进行虚拟负载分配的评分制动态负载均衡器（SBDLB），并使用CloudSim 7G平台进行测试和评估。

Result: SBDLB在不同场景下平均响应时间分别提高了34%和37%，数据中心处理时间平均缩短了13%，在24小时模拟中运营成本降低了15%，同时提高了资源利用率和能效。

Conclusion: 该研究提出了评分制动态负载均衡器（SBDLB），与传统的节流策略相比，在响应时间、数据中心处理时间和运营成本方面均表现出优越性能，并实现了更高的资源利用率和能效。

Abstract: Cloud computing has grown rapidly in recent years, mainly due to the sharp
increase in data transferred over the internet. This growth makes load
balancing a key part of cloud systems, as it helps distribute user requests
across servers to maintain performance, prevent overload, and ensure a smooth
user experience. Despite its importance, managing server resources and keeping
workloads balanced over time remains a major challenge in cloud environments.
This paper introduces a novel Score-Based Dynamic Load Balancer (SBDLB) that
allocates workloads to virtual machines based on real-time performance metrics.
The objective is to enhance resource utilization and overall system efficiency.
The method was thoroughly tested using the CloudSim 7G platform, comparing its
performance against the throttled load balancing strategy. Evaluations were
conducted across a variety of workloads and scenarios, demonstrating the
SBDLB's ability to adapt dynamically to workload fluctuations while optimizing
resource usage. The proposed method outperformed the throttled strategy,
improving average response times by 34% and 37% in different scenarios. It also
reduced data center processing times by an average of 13%. Over a 24-hour
simulation, the method decreased operational costs by 15%, promoting a more
energy-efficient and sustainable cloud infrastructure through reduced energy
consumption.

</details>


### [320] [Snowpark: Performant, Secure, User-Friendly Data Engineering and AI/ML Next To Your Data](https://arxiv.org/abs/2508.05904)
*Brandon Baker,Elliott Brossard,Chenwei Xie,Zihao Ye,Deen Liu,Yijun Xie,Arthur Zwiegincew,Nitya Kumar Sharma,Gaurav Jain,Eugene Retunsky,Mike Halcrow,Derek Denny-Brown,Istvan Cseri,Tyler Akidau,Yuxiong He*

Main category: cs.DC

TL;DR: Snowflake通过Snowpark实现AI数据云，支持Python等语言进行数据工程和AI/ML，并优化了性能、安全和易用性。


<details>
  <summary>Details</summary>
Motivation: Snowflake旨在通过Snowpark扩展其AI数据云能力，以支持数据工程和AI/ML工作负载，并提供高性能、强安全和易用的解决方案。

Method: 本文详细介绍了Snowpark的架构设计，包括利用Snowflake控制平面实现分布式计算，通过安全沙箱隔离SQL和Snowpark执行，以及通过Python包缓存、工作负载调度优化和数据倾斜管理等技术来提升性能。

Result: Snowpark通过一系列创新设计和优化，实现了高性能、安全和易用的数据处理和AI/ML工作负载支持，并在实际案例中得到了验证。

Conclusion: Snowpark通过其弹性可扩展架构、强大的安全和治理功能以及易用性，有效地支持了大规模数据工程和人工智能/机器学习任务，并展示了其在AI数据云中的领先地位。

Abstract: Snowflake revolutionized data analytics with an elastic architecture that
decouples compute and storage, enabling scalable solutions supporting data
architectures like data lake, data warehouse, data lakehouse, and data mesh.
Building on this foundation, Snowflake has advanced its AI Data Cloud vision by
introducing Snowpark, a managed turnkey solution that supports data engineering
and AI and ML workloads using Python and other programming languages.
  This paper outlines Snowpark's design objectives towards high performance,
strong security and governance, and ease of use. We detail the architecture of
Snowpark, highlighting its elastic scalability and seamless integration with
Snowflake core compute infrastructure. This includes leveraging Snowflake
control plane for distributed computing and employing a secure sandbox for
isolating Snowflake SQL workloads from Snowpark executions. Additionally, we
present core innovations in Snowpark that drive further performance
enhancements, such as query initialization latency reduction through Python
package caching, improved workload scheduling for customized workloads, and
data skew management via efficient row redistribution. Finally, we showcase
real-world case studies that illustrate Snowpark's efficiency and effectiveness
for large-scale data engineering and AI and ML tasks.

</details>


### [321] [KnapFormer: An Online Load Balancer for Efficient Diffusion Transformers Training](https://arxiv.org/abs/2508.06001)
*Kai Zhang,Peng Wang,Sai Bi,Jianming Zhang,Yuanjun Xiong*

Main category: cs.DC

TL;DR: KnapFormer是一个用于分布式训练扩散Transformer（DiT）的框架，它通过结合序列并行性和负载均衡来解决token不平衡问题。通过解决一个全局背包问题来优化token分配，KnapFormer最小化了GPU间的工作负载差异，减少了通信开销，并实现了高达2-3倍的训练加速，特别是在处理可变长度输入和混合数据类型时。


<details>
  <summary>Details</summary>
Motivation: 在分布式训练DiT模型时，由于输入文本长度可变以及混合分辨率和图像-视频联合训练中视觉token数量的变化，导致不同计算节点（ranks）之间存在显著的token不平衡问题。这种不平衡会引入拖尾效应（straggler effects），降低训练效率。

Method: KnapFormer框架首先收集所有计算节点（ranks）的序列长度元数据，然后在负载均衡分组内解决一个全局背包问题。该优化问题的目标是最小化每个GPU的总工作负载方差，并纳入序列并行性的影响。它将基于DeepSpeed-Ulysees的序列并行性集成到负载均衡决策过程中，并使用一个简单的半经验工作负载模型。

Result: KnapFormer框架通过其优化策略，实现了最小的通信开销和低于1%的工作负载差异，即使在序列长度从几百到几万不等的情况下也能保持高效。该框架在混合分辨率和图像-视频联合数据语料上训练FLUX等先进扩散模型时，能够实现2到3倍的加速，并消除了拖尾效应。

Conclusion: KnapFormer框架通过整合序列并行性和负载均衡，有效解决了分布式训练中DiT模型面临的显著token不平衡问题。该框架通过解决全局背包问题来重新分配tokens，旨在最小化全局总工作负载方差，同时考虑序列并行性的影响。

Abstract: We present KnapFormer, an efficient and versatile framework to combine
workload balancing and sequence parallelism in distributed training of
Diffusion Transformers (DiT). KnapFormer builds on the insight that strong
synergy exists between sequence parallelism and the need to address the
significant token imbalance across ranks. This imbalance arises from
variable-length text inputs and varying visual token counts in mixed-resolution
and image-video joint training. KnapFormer redistributes tokens by first
gathering sequence length metadata across all ranks in a balancing group and
solving a global knapsack problem. The solver aims to minimize the variances of
total workload per-GPU, while accounting for the effect of sequence
parallelism. By integrating DeepSpeed-Ulysees-based sequence parallelism in the
load-balancing decision process and utilizing a simple semi-empirical workload
model, KnapFormers achieves minimal communication overhead and less than 1%
workload discrepancy in real-world training workloads with sequence length
varying from a few hundred to tens of thousands. It eliminates straggler
effects and achieves 2x to 3x speedup when training state-of-the-art diffusion
models like FLUX on mixed-resolution and image-video joint data corpora. We
open-source the KnapFormer implementation at
https://github.com/Kai-46/KnapFormer/

</details>


### [322] [EC2MoE: Adaptive End-Cloud Pipeline Collaboration Enabling Scalable Mixture-of-Experts Inference](https://arxiv.org/abs/2508.06024)
*Zheming Yang,Yunqing Hu,Sheng Sun,Wen Ji*

Main category: cs.DC

TL;DR: EC2MoE通过端云协同流水线化MoE推理，提高效率并降低延迟。


<details>
  <summary>Details</summary>
Motivation: 旨在解决在异构端云环境中部署MoE模型时遇到的专家调度、通信开销和资源异构性等挑战，以提高模型容量和推理效率。

Method: EC2MoE框架提出了一种硬件感知的轻量级分组门控网络，通过本地专家选择和全局门控优化专家路由；同时开发了一种基于端云协同的流水线优化机制，包括低秩压缩的编码器-解码器结构和路由感知的启发式流水线调度算法。

Result: EC2MoE框架可将吞吐量提高2.2倍至5.1倍，并将端到端延迟降低53%至67%，同时保持高精度，并且在动态负载和网络环境下具有良好的可扩展性。

Conclusion: EC2MoE框架通过端云协同流水线化处理，有效解决了在异构端云环境中部署MoE模型面临的专家调度、通信开销和资源异构性挑战，在提高吞吐量和降低延迟方面表现出色，并保持了良好的可扩展性。

Abstract: The Mixture-of-Experts (MoE) paradigm has emerged as a promising solution to
scale up model capacity while maintaining inference efficiency. However,
deploying MoE models across heterogeneous end-cloud environments poses new
challenges in expert scheduling, communication overhead, and resource
heterogeneity. In this paper, we propose EC2MoE, an adaptive framework for
scalable MoE inference via end-cloud pipeline collaboration. First, we design a
hardware-aware lightweight group gate network that enhances expert selection
and computational efficiency. By incorporating a hardware-aware local expert
selection mechanism, the system adaptively filters candidate experts based on
real-time device profiles. A lightweight group gate module then integrates
local and global gating outputs to achieve high-quality expert routing with
minimal overhead. Second, we develop a pipeline optimization mechanism based on
endcloud collaboration to accelerate MoE inference. This includes an
encoder-decoder structure based on low-rank compression, which reduces
transmission and computation costs. And a route-aware heuristic pipeline
scheduling algorithm that dynamically allocates inference stages across devices
according to workload and network topology. Extensive experiments show that
EC2MoE can increase throughput by 2.2x to 5.1x and reduce end-to-end latency by
53% to 67% while maintaining high accuracy compared to state-of-the-art
methods. It also maintains good scalability under dynamic load and network
environments.

</details>


### [323] [KV Cache Compression for Inference Efficiency in LLMs: A Review](https://arxiv.org/abs/2508.06297)
*Yanyu Liu,Jingying Fu,Sixiang Liu,Yitian Zou,You Fu,Jiehan Zhou,Shouhua Zhang*

Main category: cs.DC

TL;DR: 大模型推理受 KV 缓存内存瓶颈限制，本文综述了压缩技术（选择性 token、量化、注意力压缩）的优化方法，并指出了未来混合优化、自适应策略和软硬件协同设计的方向。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）的快速发展，推理的上下文长度不断增加，导致 KV 缓存需求呈指数级增长，进而引发了显著的内存瓶颈，限制了模型的推理效率和可扩展性。因此，优化推理过程中的 KV 缓存对于提高性能和效率至关重要。

Method: 本综述系统地审视了当前的 KV 缓存优化技术，重点介绍了压缩策略，如选择性 token 策略、量化和注意力压缩，并评估了它们在内存占用和推理速度方面的影响、权衡和应用场景。

Result: 本综述对 KV 缓存优化技术进行了全面分析，重点关注其有效性、权衡和应用场景，并指出了现有方法在模型和任务兼容性方面存在的局限性和挑战。

Conclusion: KV 缓存优化对于提升大模型推理性能至关重要，未来的研究方向包括混合优化、自适应动态策略以及软硬件协同设计。

Abstract: Withtherapid advancement of large language models (LLMs), the context length
for inference has been continuously increasing, leading to an exponential
growth in the demand for Key-Value (KV) caching. This has resulted in a
significant memory bottleneck, limiting the inference efficiency and
scalability of the models. Therefore, optimizing the KV cache during inference
is crucial for enhancing performance and efficiency. This review systematically
examines current KV cache optimization techniques, including compression
strategies such as selective token strategies, quantization, and attention
compression. We evaluate the effectiveness, trade-offs, and application
scenarios of these methods, providing a comprehensive analysis of their impact
on memory usage and inference speed. We focus on identifying the limitations
and challenges of existing methods, such as compatibility issues with different
models and tasks. Additionally, this review highlights future research
directions, including hybrid optimization techniques, adaptive dynamic
strategies, and software-hardware co-design. These approaches aim to improve
inference efficiency and promote the practical application of large language
models.

</details>


### [324] [Performant Unified GPU Kernels for Portable Singular Value Computation Across Hardware and Precision](https://arxiv.org/abs/2508.06339)
*Evelyne Ringoot,Rabab Alomairy,Valentin Churavy,Alan Edelman*

Main category: cs.DC

TL;DR: 本文介绍了Julia中一种可移植、GPU加速的QR奇异值分解算法实现，该实现支持Apple Metal GPU和半精度计算，并在大规模矩阵计算中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 奇异值分解（SVD）在科学计算和机器学习（特别是大型语言模型中的低秩自适应）中是基础性的数值工具，因此需要高效且可移植的实现。

Method: 该实现基于经典的QR分解两阶段约简方法，逐步将矩阵约简为带状形式和双对角形式，并利用Julia的GPUArrays和KernelAbstractions框架进行GPU加速。

Result: 所提出的实现展示了良好的可移植性和性能，在多种GPU后端和数据类型上进行了测试，对于大于1024x1024的矩阵尺寸，其性能优于大多数线性代数库（MAGMA、SLATE、rocSOLVER、oneMKL），并达到了cuSOLVER性能的80%-90%。

Conclusion: 该实现通过利用Julia的多种派发和元编程功能，并与GPUArrays和KernelAbstractions框架集成，提供了统一的类型和硬件无关的函数，支持各种GPU架构和数据类型，并且是首个支持Apple Metal GPU和半精度计算的GPU加速奇异值分解实现。

Abstract: This paper presents a portable, GPU-accelerated implementation of a QR-based
singular value computation algorithm in Julia. The singular value ecomposition
(SVD) is a fundamental numerical tool in scientific computing and machine
learning, providing optimal low-rank matrix approximations. Its importance has
increased even more in large-scale machine learning pipelines, including large
language models (LLMs), where it enables low-rank adaptation (LoRA). The
implemented algorithm is based on the classic two-stage QR reduction,
consisting of successive matrix reduction to band form and bidiagonal form. Our
implementation leverages Julia's multiple dispatch and metaprogramming
capabilities, integrating with the GPUArrays and KernelAbstractions frameworks
to provide a unified type and hardware-agnostic function. It supports diverse
GPU architectures and data types, and is, to our knowledge, the first
GPU-accelerated singular value implementation to support Apple Metal GPUs and
half precision. Performance results on multiple GPU backends and data types
demonstrate that portability does not require sacrificing performance: the
unified function outperforms most linear algebra libraries (MAGMA, SLATE,
rocSOLVER, oneMKL) for matrix sizes larger than 1024x1024, and achieves 80%-90%
of the performance of cuSOLVER for large matrices.

</details>


### [325] [Blockchain-Enabled Federated Learning](https://arxiv.org/abs/2508.06406)
*Murtaza Rangwala,Venugopal K R,Rajkumar Buyya*

Main category: cs.DC

TL;DR: BCFL通过其独特的架构、共识机制和存储解决方案，解决了协作AI中的信任、隐私和协调问题，并在各种实际应用中得到了验证，证明了其性能和安全性。


<details>
  <summary>Details</summary>
Motivation: BCFL解决了协作AI系统中信任、隐私和协调的基本挑战。

Method: 通过系统的四维分类（协调结构、共识机制、存储架构和信任模型）对BCFL系统进行全面的架构分析，检查了从区块链验证的集中协调到完全去中心化的点对点网络的设计模式，并评估了可扩展性、安全性和性能方面的权衡。详细研究了包括质量证明和联邦学习证明在内的、用于联邦学习的共识机制，并提出了一个关于如何将计算工作从任意密码学难题重新用于生产性机器学习任务的演示。最后，通过一个关于TrustMesh框架的技术案例研究，说明了BCFL系统在分布式图像分类训练中的实际实施考虑因素，该案例展示了在具有高度非IID数据分布的物联网设备之间进行有效的协作学习，同时保持了完全的透明度和容错能力。

Result: 该分析详细考察了共识机制，演示了如何将计算工作重新用于机器学习任务；解决了存储挑战，提出了平衡区块链交易限制和神经网络参数需求的架构；并通过TrustMesh框架的案例研究，展示了在物联网设备上进行分布式图像分类训练的有效性。

Conclusion: BCFL系统在医疗保健联盟、金融服务和物联网安全应用等实际部署分析，验证了其可行性，实现了与中心化方法相媲美的性能，同时提供了增强的安全保证，并支持新的无信任协作智能模型。

Abstract: Blockchain-enabled federated learning (BCFL) addresses fundamental challenges
of trust, privacy, and coordination in collaborative AI systems. This chapter
provides comprehensive architectural analysis of BCFL systems through a
systematic four-dimensional taxonomy examining coordination structures,
consensus mechanisms, storage architectures, and trust models. We analyze
design patterns from blockchain-verified centralized coordination to fully
decentralized peer-to-peer networks, evaluating trade-offs in scalability,
security, and performance. Through detailed examination of consensus mechanisms
designed for federated learning contexts, including Proof of Quality and Proof
of Federated Learning, we demonstrate how computational work can be repurposed
from arbitrary cryptographic puzzles to productive machine learning tasks. The
chapter addresses critical storage challenges by examining multi-tier
architectures that balance blockchain's transaction constraints with neural
networks' large parameter requirements while maintaining cryptographic
integrity. A technical case study of the TrustMesh framework illustrates
practical implementation considerations in BCFL systems through distributed
image classification training, demonstrating effective collaborative learning
across IoT devices with highly non-IID data distributions while maintaining
complete transparency and fault tolerance. Analysis of real-world deployments
across healthcare consortiums, financial services, and IoT security
applications validates the practical viability of BCFL systems, achieving
performance comparable to centralized approaches while providing enhanced
security guarantees and enabling new models of trustless collaborative
intelligence.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [326] [Basic interactive algorithms: Preview](https://arxiv.org/abs/2508.05798)
*Yuri Gurevich*

Main category: cs.LO

TL;DR: This paper previews future work on axiomatizing interactive algorithms. It revisits the axiomatization of 'basic' (classical) algorithms and links it to the Church-Turing thesis. The authors propose viewing probabilistic, quantum, and other advanced algorithms as extensions of basic algorithms with oracles.


<details>
  <summary>Details</summary>
Motivation: The motivation is to provide a preview of an upcoming work on the axiomatization of basic interactive algorithms and to clarify the relationship between the classical notion of algorithms and more modern ones like probabilistic and quantum algorithms, including their connection to the Church-Turing thesis.

Method: The paper reviews the historical development of the notion of algorithm, starting from its elucidation in the 1930s-1950s and its subsequent axiomatization as 'basic algorithm'. It then discusses the expansion of the notion of algorithm to include probabilistic and quantum algorithms, and how these can be viewed as basic algorithms with oracles.

Result: The paper illustrates how nondeterministic and probabilistic algorithms, as well as quantum circuit algorithms, can be viewed as basic algorithms augmented with oracles. This perspective helps in understanding the broader landscape of algorithmic computation.

Conclusion: The paper provides a preview of future work on the axiomatization of basic interactive algorithms, drawing parallels with the axiomatization of sequential algorithms and its implications for the Church-Turing thesis. It also frames various advanced algorithms like probabilistic, quantum, and nondeterministic ones as extensions of basic algorithms with oracles.

Abstract: This dialog paper offers a preview and provides a foretaste of an upcoming
work on the axiomatization of basic interactive algorithms.
  The modern notion of algorithm was elucidated in the 1930s--1950s. It was
axiomatized a quarter of a century ago as the notion of ``sequential
algorithm'' or ``classical algorithm''; we prefer to call it ``basic algorithm"
now. The axiomatization was used to show that for every basic algorithm there
is a behaviorally equivalent abstract state machine. It was also used to prove
the Church-Turing thesis as it has been understood by the logicians.
  Starting from the 1960s, the notion of algorithm has expanded --
probabilistic algorithms, quantum algorithms, etc. -- prompting introduction of
a much more ambitious version of the Church-Turing thesis commonly known as the
``physical thesis.'' We emphasize the difference between the two versions of
the Church-Turing thesis and illustrate how nondeterministic and probabilistic
algorithms can be viewed as basic algorithms with appropriate oracles. The same
view applies to quantum circuit algorithms and many other classes of
algorithms.

</details>


### [327] [Widest Path Games and Maximality Inheritance in Bounded Value Iteration for Stochastic Games](https://arxiv.org/abs/2508.06088)
*Kittiphon Phalakarn,Yun Chen Tsai,Ichiro Hasuo*

Main category: cs.LO

TL;DR: 本文提出了2WP-BVI算法，解决了现有BVI算法在处理含终端组件的随机博弈时的局限性，并通过最大化继承原理证明了其正确性，实验证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有有界值迭代（BVI）算法在处理包含终端组件的随机博弈（SG）时可能不终止或不收敛的问题，并为Phalakarn等人先前研究的基于最宽路径的BVI方法（1WP-BVI）提供更坚实的理论基础。

Method: 本文提出了2WP-BVI算法，该算法基于（2人）最宽路径博弈，并使用最大化继承原理证明了其正确性。

Result: 本文提出的2WP-BVI算法在实践中具有相关性和潜力。

Conclusion: 本文提出了2WP-BVI算法，并使用最大化继承原理证明了其正确性。实验结果证明了该算法的实际意义和潜力。

Abstract: For model checking stochastic games (SGs), bounded value iteration (BVI)
algorithms have gained attention as efficient approximate methods with rigorous
precision guarantees. However, BVI may not terminate or converge when the
target SG contains end components. Most existing approaches address this issue
by explicitly detecting and processing end components--a process that is often
computationally expensive. An exception is the widest path-based BVI approach
previously studied by Phalakarn et al., which we refer to as 1WP-BVI. The
method performs particularly well in the presence of numerous end components.
Nonetheless, its theoretical foundations remain somewhat ad hoc. In this paper,
we identify and formalize the core principles underlying the widest path-based
BVI approach by (i) presenting 2WP-BVI, a clean BVI algorithm based on
(2-player) widest path games, and (ii) proving its correctness using what we
call the maximality inheritance principle--a proof principle previously
employed in a well-known result in probabilistic model checking. Our
experimental results demonstrate the practical relevance and potential of our
proposed 2WP-BVI algorithm.

</details>


### [328] [SHACL Validation in the Presence of Ontologies: Semantics and Rewriting Techniques](https://arxiv.org/abs/2507.12286)
*Anouk Oudshoorn,Magdalena Ortiz,Mantas Simkus*

Main category: cs.LO

TL;DR: 本文提出了一种在本体存在的情况下进行SHACL验证的方法，通过将问题转化为标准验证来解决语义和计算挑战，并分析了其复杂性。


<details>
  <summary>Details</summary>
Motivation: SHACL和OWL是两种用于管理RDF数据的W3C标准，它们有许多共同点，但存在开放世界假设（OWL）和封闭世界假设（SHACL）这一根本区别。将两者结合起来具有吸引力，但存在语义和计算上的挑战。

Method: 提出了一种用于构建核心通用模型的技术，并利用其有限表示来开发一种将SHACL验证（在本体存在的情况下）简化为标准验证的重写技术。

Result: 研究了SHACL验证（在本体存在的情况下）的复杂性，发现即使是非常简单的本体也会使问题成为EXPTIME-complete，而在数据复杂度方面为PTIME-complete。

Conclusion: SHACL和OWL的结合具有吸引力，但存在语义鸿沟。本文提出了一种基于核心通用模型的SHACL验证语义，并为Horn-ALCHIQ中的本体构建了这些模型。

Abstract: SHACL and OWL are two prominent W3C standards for managing RDF data. These
languages share many features, but they have one fundamental difference: OWL,
designed for inferring facts from incomplete data, makes the open-world
assumption, whereas SHACL is a constraint language that treats the data as
complete and must be validated under the closed-world assumption. The
combination of both formalisms is very appealing and has been called for, but
their semantic gap is a major challenge, semantically and computationally. In
this paper, we advocate a semantics for SHACL validation in the presence of
ontologies based on core universal models. We provide a technique for
constructing these models for ontologies in the rich data-tractable description
logic Horn-ALCHIQ. Furthermore, we use a finite representation of this model to
develop a rewriting technique that reduces SHACL validation in the presence of
ontologies to standard validation. Finally, we study the complexity of SHACL
validation in the presence of ontologies, and show that even very simple
ontologies make the problem EXPTIME-complete, and PTIME-complete in data
complexity.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [329] [Functional Connectivity Graph Neural Networks](https://arxiv.org/abs/2508.05786)
*Yang Li,Luopeiwen Yi,Tananun Songdechakraiwut*

Main category: cs.NE

TL;DR: 受大脑成像多模态分析的启发，提出了一种结合结构和功能连接（基于持久图同源性）的图神经网络框架，并证明了其在图级分类任务上的有效性。


<details>
  <summary>Details</summary>
Motivation: 真实世界的网络通常受益于捕获局部和全局交互。受大脑成像中多模态分析的启发，其中结构和功能连接提供了网络组织的互补视图，我们提出了一种将此方法推广到其他领域的图神经网络框架。

Method: 提出了一种基于持久图同源性的功能连接块，以捕获全局拓扑特征。与结构信息相结合，形成了函数连接图神经网络的多模态架构。

Result: 实验一致地提高了现有方法的性能，证明了受大脑启发的表示对于跨不同网络的图级分类的价值。

Conclusion: 实验一致地提高了现有方法的性能，证明了受大脑启发的表示对于跨不同网络的图级分类的价值。

Abstract: Real-world networks often benefit from capturing both local and global
interactions. Inspired by multi-modal analysis in brain imaging, where
structural and functional connectivity offer complementary views of network
organization, we propose a graph neural network framework that generalizes this
approach to other domains. Our method introduces a functional connectivity
block based on persistent graph homology to capture global topological
features. Combined with structural information, this forms a multi-modal
architecture called Functional Connectivity Graph Neural Networks. Experiments
show consistent performance gains over existing methods, demonstrating the
value of brain-inspired representations for graph-level classification across
diverse networks.

</details>


### [330] [Identity Increases Stability in Neural Cellular Automata](https://arxiv.org/abs/2508.06389)
*James Stovold*

Main category: cs.NE

TL;DR: 通过引入“身份”层和简单约束来提高NCA生物体的稳定性，并观察到其移动现象。


<details>
  <summary>Details</summary>
Motivation: 解决NCA生长生物体稳定性差、边界易崩溃、出现肿瘤样生长或无法保持预期形状的问题。

Method: 通过在训练中引入一个具有简单约束的'身份'层来改进NCA的稳定性。

Result: 与原始NCA模型相比，近距离生长的NCAs更稳定，仅需一个身份值即可实现稳定性提升，并观察到稳定的生物体出现移动现象，具有多个身份值的模型中移动现象更普遍。

Conclusion: 通过在训练中引入具有简单约束的“身份”层，可以提高NCA生长生物体的稳定性。该方法仅需一个身份值即可提高稳定性，并可能促出现象级移动。

Abstract: Neural Cellular Automata (NCAs) offer a way to study the growth of
two-dimensional artificial organisms from a single seed cell. From the outset,
NCA-grown organisms have had issues with stability, their natural boundary
often breaking down and exhibiting tumour-like growth or failing to maintain
the expected shape. In this paper, we present a method for improving the
stability of NCA-grown organisms by introducing an 'identity' layer with simple
constraints during training.
  Results show that NCAs grown in close proximity are more stable compared with
the original NCA model. Moreover, only a single identity value is required to
achieve this increase in stability. We observe emergent movement from the
stable organisms, with increasing prevalence for models with multiple identity
values.
  This work lays the foundation for further study of the interaction between
NCA-grown organisms, paving the way for studying social interaction at a
cellular level in artificial organisms.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [331] [Stochastic Bandits for Crowdsourcing and Multi-Platform Autobidding](https://arxiv.org/abs/2508.05844)
*François Bachoc,Nicolò Cesa-Bianchi,Tommaso Cesari,Roberto Colomboni*

Main category: cs.GT

TL;DR: This paper introduces a new stochastic bandit model for budget allocation problems in crowdsourcing and autobidding. It offers an algorithm with regret proportional to K*sqrt(T), with potential improvements to K*(log T)^2 under certain conditions.


<details>
  <summary>Details</summary>
Motivation: The motivation stems from applications in crowdsourcing (splitting a fixed sum among K workers) and autobidding (using a fixed budget for K simultaneous auctions).

Method: The paper designs a stochastic bandit algorithm for a novel problem setting and proves theoretical bounds (both upper and lower) on its expected regret. The method involves analyzing the algorithm's performance in terms of regret over T steps.

Result: The paper achieves an expected regret of O(K*sqrt(T)) and proves a matching lower bound. It also demonstrates improved bounds of O(K*(log T)^2) under specific diminishing-returns conditions.

Conclusion: The paper defines a stochastic bandit model with arms on the K-dimensional probability simplex, representing budget allocation. It designs an algorithm with O(K*sqrt(T)) expected regret and proves a matching lower bound. Improved bounds of O(K*(log T)^2) are achieved under diminishing-returns conditions.

Abstract: Motivated by applications in crowdsourcing, where a fixed sum of money is
split among $K$ workers, and autobidding, where a fixed budget is used to bid
in $K$ simultaneous auctions, we define a stochastic bandit model where arms
belong to the $K$-dimensional probability simplex and represent the fraction of
budget allocated to each task/auction. The reward in each round is the sum of
$K$ stochastic rewards, where each of these rewards is unlocked with a
probability that varies with the fraction of the budget allocated to that
task/auction. We design an algorithm whose expected regret after $T$ steps is
of order $K\sqrt{T}$ (up to log factors) and prove a matching lower bound.
Improved bounds of order $K (\log T)^2$ are shown when the function mapping
budget to probability of unlocking the reward (i.e., terminating the task or
winning the auction) satisfies additional diminishing-returns conditions.

</details>


### [332] [An Overlapping Coalition Game Approach for Collaborative Block Mining and Edge Task Offloading in MEC-assisted Blockchain Networks](https://arxiv.org/abs/2508.06031)
*Licheng Ye,Zehui Xiong,Lin Gao,Dusit Niyato*

Main category: cs.GT

TL;DR: 本研究通过一个两阶段Stackelberg博弈，分析了在多联盟协作模式下，MEC如何帮助区块链提高效率。研究解决了资源定价和联盟形成问题，以实现更优的区块链性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注单联盟协作模式，本研究旨在探索更复杂的、允许矿工加入多个联盟的多联盟协作模式，以提高MEC辅助的协作区块链网络的效率、安全性和可扩展性。

Method: 提出两阶段Stackelberg博弈，包括ECP定价和MU联盟选择。通过求解ERC博弈的纳什均衡，进而解决OCF博弈和ECP定价问题。

Result: 推导了ERC博弈的闭式纳什均衡，提出了一种OCF交替算法以获得稳定的联盟结构，并为ECP开发了近优的资源定价策略。

Conclusion: 本研究提出了一种新颖的两阶段Stackelberg博弈，用于分析多联盟协作模式下移动边缘计算（MEC）辅助的协作区块链网络中矿工和边缘计算提供商（ECP）的行为。研究推导了边缘资源竞争（ERC）博弈的纳什均衡，并提出了一种基于OCF的交替算法来实现稳定的联盟结构，以及一种近乎最优的定价策略。

Abstract: Mobile edge computing (MEC) is a promising technology that enhances the
efficiency of mobile blockchain networks, by enabling miners, often acted by
mobile users (MUs) with limited computing resources, to offload
resource-intensive mining tasks to nearby edge computing servers. Collaborative
block mining can further boost mining efficiency by allowing multiple miners to
form coalitions, pooling their computing resources and transaction data
together to mine new blocks collaboratively. Therefore, an MEC-assisted
collaborative blockchain network can leverage the strengths of both
technologies, offering improved efficiency, security, and scalability for
blockchain systems. While existing research in this area has mainly focused on
the single-coalition collaboration mode, where each miner can only join one
coalition, this work explores a more comprehensive multi-coalition
collaboration mode, which allows each miner to join multiple coalitions. To
analyze the behavior of miners and the edge computing service provider (ECP) in
this scenario, we propose a novel two-stage Stackelberg game. In Stage I, the
ECP, as the leader, determines the prices of computing resources for all MUs.
In Stage II, each MU decides the coalitions to join, resulting in an
overlapping coalition formation (OCF) game; Subsequently, each coalition
decides how many edge computing resources to purchase from the ECP, leading to
an edge resource competition (ERC) game. We derive the closed-form Nash
equilibrium for the ERC game, based on which we further propose an OCF-based
alternating algorithm to achieve a stable coalition structure for the OCF game
and develop a near-optimal pricing strategy for the ECP's resource pricing
problem.

</details>


### [333] [Social Welfare in Battery Charging Games](https://arxiv.org/abs/2508.06320)
*Simon Krogmann,Pascal Lenzner,Alexander Skopalik,Tobias Sträubig*

Main category: cs.GT

TL;DR: Renewable energy and household batteries create market design challenges. This paper uses game theory to study how pricing strategies affect battery usage and grid stability, finding that pricing is key to achieving good outcomes and suggesting more research is needed.


<details>
  <summary>Details</summary>
Motivation: The increasing number of decentralized renewable energy sources and household-owned batteries presents challenges for electrical grid market design. Household batteries, while offering mitigation potential, often operate misaligned with grid-level objectives due to selfish incentives of their owners. This necessitates a game-theoretic analysis.

Method: The paper adopts a game-theoretic approach, specifically a Stackelberg-like market model, to analyze the strategic charging and discharging of household-owned batteries. It studies the existence and quality of equilibria under various pricing strategies.

Result: The study found that the existence of equilibria is contingent upon the pricing strategy employed, and the resulting social welfare exhibits significant variation. This highlights the complexity of aligning individual incentives with grid-level objectives.

Conclusion: The existence of equilibria depends on the chosen pricing strategy, and the social welfare varies widely, indicating a need for more sophisticated market models and pricing mechanisms. This opens up a rich field for future research in Algorithmic Game Theory on incentives in renewable energy networks.

Abstract: The recent rise of renewable energy produced by many decentralized sources
yields interesting market design challenges for electrical grids. Balancing
supply and demand in such networks is both a temporal and spatial challenge due
to capacity constraints. The recent surge in the number of household-owned
batteries, especially in regions with rooftop solar adoption, offers mitigation
potential but often acts misaligned with grid-level objectives. In fact, the
decision to charge or discharge a household-owned battery is a strategic choice
by each battery owner governed by selfish incentives. This calls for an
analysis from a game-theoretic point of view.
  We initiate this timely research direction by considering a game-theoretic
setting where selfish agents strategically charge or discharge their batteries
to increase their profit. In particular, we study a Stackelberg-like market
model where a third party introduces price incentives, aiming to optimize
renewable energy utilization while preserving grid feasibility. For this, we
study the existence and the quality of equilibria under various pricing
strategies. We find that the existence of equilibria crucially depends on the
chosen pricing and that the obtained social welfare varies widely. This calls
for more sophisticated market models and pricing mechanisms and opens up a rich
field for future research in Algorithmic Game Theory on incentives in renewable
energy networks.

</details>


### [334] [A Geometric Analysis of Gains from Trade](https://arxiv.org/abs/2508.06469)
*Jason Hartline,Kangning Wang*

Main category: cs.GT

TL;DR: 文章通过几何方法研究了随机提议者机制在双边交易中的效率，得到了4近似最优交易收益，并进一步优化到3.15近似。


<details>
  <summary>Details</summary>
Motivation: 探究随机提议者机制在双边交易中的效率，并寻求最优的近似比。

Method: 文章首先使用几何方法证明了随机提议者机制是双边交易中“最优交易收益”的4近似，然后通过细化该几何分析，得到了目前最优的3.15近似比。

Result: 随机提议者机制被证明是4近似最优交易收益，并且通过几何分析可以达到3.15近似最优交易收益。

Conclusion: 随机提议者机制可以实现4近似最优交易收益，并且通过几何分析可以进一步优化到3.15近似最优交易收益。

Abstract: We provide a geometric proof that the random proposer mechanism is a
$4$-approximation to the first-best gains from trade in bilateral exchange. We
then refine this geometric analysis to recover the state-of-the-art
approximation ratio of $3.15$.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [335] [InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization](https://arxiv.org/abs/2508.05731)
*Yuhang Liu,Zeyu Liu,Shuanghe Zhu,Pengxiang Li,Congkai Xie,Jiasheng Wang,Xueyu Hu,Xiaotian Han,Jianbo Yuan,Xinyao Wang,Shengyu Zhang,Hongxia Yang,Fei Wu*

Main category: cs.AI

TL;DR: A new framework called AEPO improves how autonomous agents understand instructions for controlling GUIs by enhancing exploration and semantic alignment, leading to better performance on benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing Reinforcement Learning with Verifiable Rewards (RLVR) for MLLMs struggles with semantic alignment in GUI grounding due to inefficient exploration, hindering the learning of difficult semantic associations.

Method: Proposed Adaptive Exploration Policy Optimization (AEPO) framework with a multi-answer generation strategy for broader exploration, guided by a theoretically grounded Adaptive Exploration Reward (AER) function (eta=U/C).

Result: AEPO achieves significant relative improvements of up to 9.0% against the naive RLVR baseline on benchmarks testing generalization and semantic understanding.

Conclusion: AEPO-trained models InfiGUI-G1-3B and InfiGUI-G1-7B set new state-of-the-art results on challenging GUI grounding benchmarks, with up to 9.0% improvement over RLVR baseline in generalization and semantic understanding.

Abstract: The emergence of Multimodal Large Language Models (MLLMs) has propelled the
development of autonomous agents that operate on Graphical User Interfaces
(GUIs) using pure visual input. A fundamental challenge is robustly grounding
natural language instructions. This requires a precise spatial alignment, which
accurately locates the coordinates of each element, and, more critically, a
correct semantic alignment, which matches the instructions to the functionally
appropriate UI element. Although Reinforcement Learning with Verifiable Rewards
(RLVR) has proven to be effective at improving spatial alignment for these
MLLMs, we find that inefficient exploration bottlenecks semantic alignment,
which prevent models from learning difficult semantic associations. To address
this exploration problem, we present Adaptive Exploration Policy Optimization
(AEPO), a new policy optimization framework. AEPO employs a multi-answer
generation strategy to enforce broader exploration, which is then guided by a
theoretically grounded Adaptive Exploration Reward (AER) function derived from
first principles of efficiency eta=U/C. Our AEPO-trained models, InfiGUI-G1-3B
and InfiGUI-G1-7B, establish new state-of-the-art results across multiple
challenging GUI grounding benchmarks, achieving significant relative
improvements of up to 9.0% against the naive RLVR baseline on benchmarks
designed to test generalization and semantic understanding. Resources are
available at https://github.com/InfiXAI/InfiGUI-G1.

</details>


### [336] [The Fair Game: Auditing & Debiasing AI Algorithms Over Time](https://arxiv.org/abs/2508.06443)
*Debabrota Basu,Udvas Das*

Main category: cs.AI

TL;DR: “Fair Game”是一种新的公平机器学习机制，利用强化学习来动态适应社会交互中的偏见，以实现灵活且可随时间自适应的公平性。


<details>
  <summary>Details</summary>
Motivation: 现有的公平机器学习（ML）方法在定义偏见时通常是观察性的，并且存在相互冲突的情况，这使得它们在动态的社会环境中难以部署。因此，需要一种新的机制来确保ML算法的公平性，并能随着社会与算法的交互而进行调整。

Method: “Fair Game”通过将审计员和去偏算法置于机器学习算法周围的循环中，并利用强化学习（RL）来连接这两个组件。

Result: “Fair Game”提供了一个独特的框架，可以通过修改审计员及其量化的偏见来适应公平性目标，从而模拟社会中伦理和法律框架的演变。

Conclusion: “Fair Game”提供了一个灵活且可随时间自适应的框架，用于在部署前和部署后构建公平的机器学习系统。

Abstract: An emerging field of AI, namely Fair Machine Learning (ML), aims to quantify
different types of bias (also known as unfairness) exhibited in the predictions
of ML algorithms, and to design new algorithms to mitigate them. Often, the
definitions of bias used in the literature are observational, i.e. they use the
input and output of a pre-trained algorithm to quantify a bias under concern.
In reality,these definitions are often conflicting in nature and can only be
deployed if either the ground truth is known or only in retrospect after
deploying the algorithm. Thus,there is a gap between what we want Fair ML to
achieve and what it does in a dynamic social environment. Hence, we propose an
alternative dynamic mechanism,"Fair Game",to assure fairness in the predictions
of an ML algorithm and to adapt its predictions as the society interacts with
the algorithm over time. "Fair Game" puts together an Auditor and a Debiasing
algorithm in a loop around an ML algorithm. The "Fair Game" puts these two
components in a loop by leveraging Reinforcement Learning (RL). RL algorithms
interact with an environment to take decisions, which yields new observations
(also known as data/feedback) from the environment and in turn, adapts future
decisions. RL is already used in algorithms with pre-fixed long-term fairness
goals. "Fair Game" provides a unique framework where the fairness goals can be
adapted over time by only modifying the auditor and the different biases it
quantifies. Thus,"Fair Game" aims to simulate the evolution of ethical and
legal frameworks in the society by creating an auditor which sends feedback to
a debiasing algorithm deployed around an ML system. This allows us to develop a
flexible and adaptive-over-time framework to build Fair ML systems pre- and
post-deployment.

</details>


### [337] [A Framework for Inherently Safer AGI through Language-Mediated Active Inference](https://arxiv.org/abs/2508.05766)
*Bo Wen*

Main category: cs.AI

TL;DR: 本研究提出了一个结合主动推理和大型语言模型（LLM）的新框架，用于开发安全的人工通用智能（AGI）。该框架将安全保障集成到核心设计中，利用自然语言进行信念表征和人类监督，并通过分层马尔可夫毯实现代理的自我组织。研究提出了具体的安全机制，并计划在ARC基准上进行实验验证，旨在实现内在更安全、而非事后添加安全措施的AGI开发。


<details>
  <summary>Details</summary>
Motivation: 传统的AI安全方法，侧重于事后可解释性和奖励工程，存在根本性的局限性。本研究旨在提供一种更安全的方法来开发AGI。

Method: 本研究提出了一种将主动推理原理与大型语言模型相结合的新颖框架，用于开发安全的人工通用智能（AGI）。该框架通过透明的信念表征和分层价值对齐，将安全保证整合到系统的核心设计中。它利用自然语言作为表征和操纵信念的媒介，实现了直接的人工监督，同时保持了计算上的可行性。该架构实现了一个多主体系统，代理根据主动推理原理进行自我组织，偏好和安全约束通过分层马尔可夫毯流动。研究提出了具体的安全保障机制，包括：1）使用自然语言显式分离信念和偏好；2）通过资源感知的自由能最小化实现有界理性；3）通过模块化代理结构实现组合安全性。

Result: 本研究提出的框架通过将主动推理与LLM相结合，实现了AGI的安全开发，其核心设计整合了安全保证。通过自然语言表征信念，实现了人工监督和计算可行性。该框架通过显式分离信念和偏好、有界理性和组合安全性机制来确保安全。

Conclusion: 本研究提出了将主动推理原则与大型语言模型相结合，以开发安全的人工通用智能（AGI）的新颖框架。该框架通过透明的信念表征和分层价值对齐，将安全保证整合到系统的核心设计中。

Abstract: This paper proposes a novel framework for developing safe Artificial General
Intelligence (AGI) by combining Active Inference principles with Large Language
Models (LLMs). We argue that traditional approaches to AI safety, focused on
post-hoc interpretability and reward engineering, have fundamental limitations.
We present an architecture where safety guarantees are integrated into the
system's core design through transparent belief representations and
hierarchical value alignment. Our framework leverages natural language as a
medium for representing and manipulating beliefs, enabling direct human
oversight while maintaining computational tractability. The architecture
implements a multi-agent system where agents self-organize according to Active
Inference principles, with preferences and safety constraints flowing through
hierarchical Markov blankets. We outline specific mechanisms for ensuring
safety, including: (1) explicit separation of beliefs and preferences in
natural language, (2) bounded rationality through resource-aware free energy
minimization, and (3) compositional safety through modular agent structures.
The paper concludes with a research agenda centered on the Abstraction and
Reasoning Corpus (ARC) benchmark, proposing experiments to validate our
framework's safety properties. Our approach offers a path toward AGI
development that is inherently safer, rather than retrofitted with safety
measures.

</details>


### [338] [Whither symbols in the era of advanced neural networks?](https://arxiv.org/abs/2508.05776)
*Thomas L. Griffiths,Brenden M. Lake,R. Thomas McCoy,Ellie Pavlick,Taylor W. Webb*

Main category: cs.AI

TL;DR: 神经网络展现出类似人类的智能，挑战了心智符号化的传统观点，但符号系统在定义问题上仍很重要，促使研究新方向。


<details>
  <summary>Details</summary>
Motivation: 探讨现代神经网络的能力是否能提供人类心智本质的新视角，并质疑纯粹符号化心智模型的充分性。

Method: 通过比较现代神经网络的能力与人类心智的特点（组合、创新、快速学习），论证了人类心智过程和表征不一定是符号化的。

Result: 现代神经网络的能力挑战了人类心智完全是符号化系统的观点，但同时强调了符号系统在定义人类心智面临的抽象问题中的重要性。

Conclusion: 现代神经网络（及其之上构建的人工智能系统）展现出了与人类心智相似的组合、创新和快速学习能力，这削弱了认为人类心智过程和表征本质上是符号化的论点。尽管如此，这些神经网络的训练依赖于符号系统生成的数据，这表明符号系统在描述人类心智需要解决的抽象问题方面仍然扮演着重要角色。基于这些观察，我们提出了一个关于人类思维符号基础研究的新议程。

Abstract: Some of the strongest evidence that human minds should be thought about in
terms of symbolic systems has been the way they combine ideas, produce novelty,
and learn quickly. We argue that modern neural networks -- and the artificial
intelligence systems built upon them -- exhibit similar abilities. This
undermines the argument that the cognitive processes and representations used
by human minds are symbolic, although the fact that these neural networks are
typically trained on data generated by symbolic systems illustrates that such
systems play an important role in characterizing the abstract problems that
human minds have to solve. This argument leads us to offer a new agenda for
research on the symbolic basis of human thought.

</details>


### [339] [Don't Forget Imagination!](https://arxiv.org/abs/2508.06062)
*Evgenii E. Vityaev,Andrei Mantsivoda*

Main category: cs.AI

TL;DR: 认知想象对人类思维至关重要，也是人工智能的下一个潜在突破点。本文提出语义模型来模拟认知想象，以解决当前人工智能的局限性。


<details>
  <summary>Details</summary>
Motivation: 目前人工智能的推理能力被严重低估，因为它缺乏认知想象能力，而认知想象在人类思考中起着关键作用。

Method: 提出了一种名为“语义模型”的新型数学模型，该模型能够学习，并基于概率因果关系，以模拟认知想象。

Result: 语义模型能够确保模拟出的想象情境的一致性，并提供一种“玻璃盒子”方法，允许将情境作为一个相互关联的事实整体进行操纵，并通过因果关系进行连接。

Conclusion: 人工智能的突破性进展可能在于模拟认知想象能力，而语义模型可以实现这一点。

Abstract: Cognitive imagination is a type of imagination that plays a key role in human
thinking. It is not a ``picture-in-the-head'' imagination. It is a faculty to
mentally visualize coherent and holistic systems of concepts and causal links
that serve as semantic contexts for reasoning, decision making and prediction.
Our position is that the role of cognitive imagination is still greatly
underestimated, and this creates numerous problems and diminishes the current
capabilities of AI. For instance, when reasoning, humans rely on imaginary
contexts to retrieve background info. They also constantly return to the
context for semantic verification that their reasoning is still reasonable.
Thus, reasoning without imagination is blind. This paper is a call for greater
attention to cognitive imagination as the next promising breakthrough in
artificial intelligence. As an instrument for simulating cognitive imagination,
we propose semantic models -- a new approach to mathematical models that can
learn, like neural networks, and are based on probabilistic causal
relationships. Semantic models can simulate cognitive imagination because they
ensure the consistency of imaginary contexts and implement a glass-box approach
that allows the context to be manipulated as a holistic and coherent system of
interrelated facts glued together with causal relations.

</details>


### [340] [Holistic Explainable AI (H-XAI): Extending Transparency Beyond Developers in AI-Driven Decision Making](https://arxiv.org/abs/2508.05792)
*Kausik Lakkaraju,Siva Likitha Valluru,Biplav Srivastava*

Main category: cs.AI

TL;DR: H-XAI 是一个改进的 XAI 框架，它整合了因果评分和传统 XAI 方法，以支持包括理解个体决策、评估群体偏见和评估扰动下的鲁棒性在内的各种利益相关者目标。


<details>
  <summary>Details</summary>
Motivation: 现有的 XAI 方法主要服务于开发者，侧重于解释模型输出来证明其合理性，而不是满足多样化利益相关者的需求。尽管近期向评估性 AI 的转变将解释重新定义为假设检验的工具，但它仍然主要关注运营组织。

Method: H-XAI 是一个统一框架，整合了因果评分方法和传统 XAI 方法，支持将解释作为一种交互式的、多方法的过程。它允许利益相关者提出一系列问题、检验假设，并将模型行为与自动构建的随机和偏差基线进行比较。该框架结合了实例级别和全局解释，并能适应不同利益相关者的目标，如理解个体决策、评估群体偏见或评估扰动下的鲁棒性。

Result: 通过跨越二元信贷风险分类和金融时间序列预测六种场景的两个案例研究，证明了该方法的通用性。

Conclusion: H-XAI 框架通过结合因果评分和事后解释，填补了现有 XAI 方法的空白，能够回应从个体决策到整体模型的特定利益相关者的问题。

Abstract: Current eXplainable AI (XAI) methods largely serve developers, often focusing
on justifying model outputs rather than supporting diverse stakeholder needs. A
recent shift toward Evaluative AI reframes explanation as a tool for hypothesis
testing, but still focuses primarily on operational organizations. We introduce
Holistic-XAI (H-XAI), a unified framework that integrates causal rating methods
with traditional XAI methods to support explanation as an interactive,
multi-method process. H-XAI allows stakeholders to ask a series of questions,
test hypotheses, and compare model behavior against automatically constructed
random and biased baselines. It combines instance-level and global
explanations, adapting to each stakeholder's goals, whether understanding
individual decisions, assessing group-level bias, or evaluating robustness
under perturbations. We demonstrate the generality of our approach through two
case studies spanning six scenarios: binary credit risk classification and
financial time-series forecasting. H-XAI fills critical gaps left by existing
XAI methods by combining causal ratings and post-hoc explanations to answer
stakeholder-specific questions at both the individual decision level and the
overall model level.

</details>


### [341] [Safety of Embodied Navigation: A Survey](https://arxiv.org/abs/2508.05855)
*Zixia Wang,Jia Hu,Ronghui Mu*

Main category: cs.AI

TL;DR: 本调查全面分析了具身导航中的安全问题，重点关注攻击、防御和评估，并为未来的研究指明了方向，以期构建更安全的具身AI。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的不断发展和影响力的增强，具身AI的发展也随之加速，特别是在导航领域，这引发了人们的广泛关注。具身导航要求智能体在向指定目标移动时，能够感知、互动和适应其所处的环境，尤其是在陌生的环境中。然而，将具身导航应用于关键领域会引发重大的安全担忧。鉴于其在动态、真实环境中的部署，确保这些系统的安全性至关重要。

Method: 对现有安全挑战、缓解技术、数据集和评估指标进行了全面审查，并探讨了潜在的攻击方法、缓解策略、更可靠的评估技术和验证框架的实施。

Result: 本调查旨在为未来研究提供有价值的见解，以指导开发更安全、更可靠的具身导航系统。此外，本研究结果对提高社会安全和提升工业效率具有更广泛的意义。

Conclusion: 本调查全面分析了具身导航中的安全问题，涵盖了攻击策略、防御机制和评估方法，并探讨了未来的研究方向。

Abstract: As large language models (LLMs) continue to advance and gain influence, the
development of embodied AI has accelerated, drawing significant attention,
particularly in navigation scenarios. Embodied navigation requires an agent to
perceive, interact with, and adapt to its environment while moving toward a
specified target in unfamiliar settings. However, the integration of embodied
navigation into critical applications raises substantial safety concerns. Given
their deployment in dynamic, real-world environments, ensuring the safety of
such systems is critical. This survey provides a comprehensive analysis of
safety in embodied navigation from multiple perspectives, encompassing attack
strategies, defense mechanisms, and evaluation methodologies. Beyond conducting
a comprehensive examination of existing safety challenges, mitigation
technologies, and various datasets and metrics that assess effectiveness and
robustness, we explore unresolved issues and future research directions in
embodied navigation safety. These include potential attack methods, mitigation
strategies, more reliable evaluation techniques, and the implementation of
verification frameworks. By addressing these critical gaps, this survey aims to
provide valuable insights that can guide future research toward the development
of safer and more reliable embodied navigation systems. Furthermore, the
findings of this study have broader implications for enhancing societal safety
and increasing industrial efficiency.

</details>


### [342] [Planning Agents on an Ego-Trip: Leveraging Hybrid Ego-Graph Ensembles for Improved Tool Retrieval in Enterprise Task Planning](https://arxiv.org/abs/2508.05888)
*Sahil Bansal,Sai Shruthi Sistla,Aarti Arikatala,Sebastian Schreiber*

Main category: cs.AI

TL;DR: 提出了一种基于知识图（KG）的工具检索框架，通过建模工具之间的语义关系和功能依赖性，提高了AI代理在处理复杂、多步用户请求时的工具选择能力。


<details>
  <summary>Details</summary>
Motivation: 传统方法主要依赖用户查询和工具描述之间的相似性，这在处理多步用户请求时，会严重限制检索准确性。

Method: 提出了一种基于知识图（KG）的工具检索框架，利用1跳工具图的集合来建模工具之间直接和间接的联系，以进行多步任务的更全面、更具上下文的工具选择。

Result: 基于工具图的方法在微平均完整召回率指标上达到了91.85%的工具覆盖率，而作为最强的非KG基线方法的重排语义-词汇混合检索达到了89.26%。

Conclusion: 用户对工具图的假设得到了支持，特别是在需要顺序工具组合的查询中，KG的结构信息提供了与纯粹相似性匹配互补的信号。

Abstract: Effective tool retrieval is essential for AI agents to select from a vast
array of tools when identifying and planning actions in the context of complex
user queries. Despite its central role in planning, this aspect remains
underexplored in the literature. Traditional approaches rely primarily on
similarities between user queries and tool descriptions, which significantly
limits retrieval accuracy, specifically when handling multi-step user requests.
To address these limitations, we propose a Knowledge Graph (KG)-based tool
retrieval framework that captures the semantic relationships between tools and
their functional dependencies. Our retrieval algorithm leverages ensembles of
1-hop ego tool graphs to model direct and indirect connections between tools,
enabling more comprehensive and contextual tool selection for multi-step tasks.
We evaluate our approach on a synthetically generated internal dataset across
six defined user classes, extending previous work on coherent dialogue
synthesis and too retrieval benchmarks. Results demonstrate that our tool
graph-based method achieves 91.85% tool coverage on the micro-average Complete
Recall metric, compared to 89.26% for re-ranked semantic-lexical hybrid
retrieval, the strongest non-KG baseline in our experiments. These findings
support our hypothesis that the structural information in the KG provides
complementary signals to pure similarity matching, particularly for queries
requiring sequential tool composition.

</details>


### [343] [What Voting Rules Actually Do: A Data-Driven Analysis of Multi-Winner Voting](https://arxiv.org/abs/2508.06454)
*Joshua Caiata,Ben Armstrong,Kate Larson*

Main category: cs.AI

TL;DR: 一篇关于使用数据驱动框架评估多选投票规则及其公理性能的论文，并提出神经网络可以作为一种有前景的替代方案。


<details>
  <summary>Details</summary>
Motivation: 为了在社会选择研究中识别不同多选投票规则所满足的性质，并提出一种数据驱动的框架来评估投票规则违反公理的频率。

Method: 提出一个数据驱动的框架来评估投票规则在不同偏好分布下违反公理的频率，而不是采用最坏情况分析。

Result: 证明了作为投票规则的神经网络可以优于传统规则，在最小化公理冲突方面表现更好。

Conclusion: 通过数据驱动的方法可以设计出比传统方法更能优化投票规则、减少公理冲突的新型投票系统。

Abstract: Committee-selection problems arise in many contexts and applications, and
there has been increasing interest within the social choice research community
on identifying which properties are satisfied by different multi-winner voting
rules. In this work, we propose a data-driven framework to evaluate how
frequently voting rules violate axioms across diverse preference distributions
in practice, shifting away from the binary perspective of axiom satisfaction
given by worst-case analysis. Using this framework, we analyze the relationship
between multi-winner voting rules and their axiomatic performance under several
preference distributions. We then show that neural networks, acting as voting
rules, can outperform traditional rules in minimizing axiom violations. Our
results suggest that data-driven approaches to social choice can inform the
design of new voting systems and support the continuation of data-driven
research in social choice.

</details>


### [344] [PanelTR: Zero-Shot Table Reasoning Framework Through Multi-Agent Scientific Discussion](https://arxiv.org/abs/2508.06110)
*Yiran Rex Ma*

Main category: cs.AI

TL;DR: PanelTR利用AI科学家进行表格推理，无需数据增强，效果优于基础LLM，媲美监督模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决表格推理（包括表格问答和事实核查）对标注数据或复杂数据增强的依赖性，以及LLM在此类任务上的潜在不足，提出PanelTR框架。

Method: PanelTR框架利用LLM驱动的代理科学家，通过个体研究、自我评审和同伴评审来执行表格推理任务，模拟了科学研究的流程，并且不依赖数据增强或参数优化。

Result: PanelTR在四个基准测试中表现优于基础LLM，并能媲美完全监督模型，同时不依赖训练数据。

Conclusion: PanelTR展示了结构化科学方法在零样本情境下处理复杂任务（包括表格推理）的有效性，展现了灵活的语义理解能力，并且优于简单监督模型。

Abstract: Table reasoning, including tabular QA and fact verification, often depends on
annotated data or complex data augmentation, limiting flexibility and
generalization. LLMs, despite their versatility, often underperform compared to
simple supervised models. To approach these issues, we introduce PanelTR, a
framework utilizing LLM agent scientists for robust table reasoning through a
structured scientific approach. PanelTR's workflow involves agent scientists
conducting individual investigations, engaging in self-review, and
participating in collaborative peer-review discussions. This process, driven by
five scientist personas, enables semantic-level transfer without relying on
data augmentation or parametric optimization. Experiments across four
benchmarks show that PanelTR outperforms vanilla LLMs and rivals fully
supervised models, all while remaining independent of training data. Our
findings indicate that structured scientific methodology can effectively handle
complex tasks beyond table reasoning with flexible semantic understanding in a
zero-shot context.

</details>


### [345] [Mediator-Guided Multi-Agent Collaboration among Open-Source Models for Medical Decision-Making](https://arxiv.org/abs/2508.05996)
*Kaitao Chen,Mianxin Liu,Daoming Zong,Chaoyue Ding,Shaohao Rui,Yankai Jiang,Mu Zhou,Xiaosong Wang*

Main category: cs.AI

TL;DR: MedOrch：一个由LLM协调的多智能体框架，用于提升医疗多模态决策协作能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体研究主要集中在语言任务上，将其扩展到多模态场景面临挑战，并且VLM在指令遵循和自我反思方面能力不足，限制了其在协作中的应用。本研究旨在解决这些问题，以提升医疗多模态决策的效率和准确性。

Method: 提出了一种名为MedOrch的协调多智能体协作框架，该框架使用基于LLM的协调智能体来指导多个基于VLM的专家智能体进行输出交换和反思，以实现协作。框架采用了多种通用和特定领域的开源VLM，而非昂贵的GPT系列模型。

Result: 在五个医疗视觉问答基准上验证了MedOrch的有效性，证明了其协作性能优于任何单一智能体，并且无需模型训练。

Conclusion: MedOrch框架通过LLM驱动的协调，实现了多模态医疗决策的有效协作，超越了单一模型的性能，并且无需进行模型训练，展示了在提升医疗多模态智能方面的潜力。

Abstract: Complex medical decision-making involves cooperative workflows operated by
different clinicians. Designing AI multi-agent systems can expedite and augment
human-level clinical decision-making. Existing multi-agent researches primarily
focus on language-only tasks, yet their extension to multimodal scenarios
remains challenging. A blind combination of diverse vision-language models
(VLMs) can amplify an erroneous outcome interpretation. VLMs in general are
less capable in instruction following and importantly self-reflection, compared
to large language models (LLMs) of comparable sizes. This disparity largely
constrains VLMs' ability in cooperative workflows. In this study, we propose
MedOrch, a mediator-guided multi-agent collaboration framework for medical
multimodal decision-making. MedOrch employs an LLM-based mediator agent that
enables multiple VLM-based expert agents to exchange and reflect on their
outputs towards collaboration. We utilize multiple open-source general-purpose
and domain-specific VLMs instead of costly GPT-series models, revealing the
strength of heterogeneous models. We show that the collaboration within
distinct VLM-based agents can surpass the capabilities of any individual agent.
We validate our approach on five medical vision question answering benchmarks,
demonstrating superior collaboration performance without model training. Our
findings underscore the value of mediator-guided multi-agent collaboration in
advancing medical multimodal intelligence. Our code will be made publicly
available.

</details>


### [346] [Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning](https://arxiv.org/abs/2508.06042)
*Daechul Ahn,San Kim,Jonghyun Choi*

Main category: cs.AI

TL;DR: A new hierarchical multi-agent framework called HIMA, which uses a Strategic Planner (SP) to orchestrate specialized imitation learning agents, excels in StarCraftII by improving strategic clarity, adaptability, and efficiency compared to existing methods. It also introduces TEXTSCII-ALL, a comprehensive SC2 testbed.


<details>
  <summary>Details</summary>
Motivation: LLMs struggle with dynamic, long-horizon tasks such as real-time strategic games like StarCraftII (SC2), which require managing resource constraints and adapting to evolving battlefield situations in a partially observable environment.

Method: A hierarchical multi-agent framework that employs specialized imitation learning agents under a meta-controller called Strategic Planner (SP). The SP orchestrates proposals from specialized agents into a single, environmentally adaptive plan.

Result: Empirical results show that HIMA outperforms state of the arts in strategic clarity, adaptability, and computational efficiency.

Conclusion: HIMA outperforms state of the arts in strategic clarity, adaptability, and computational efficiency, underscoring the potential of combining specialized imitation modules with meta-level orchestration to develop more robust, general-purpose AI agents.

Abstract: Large Language Models (LLMs) have recently demonstrated impressive action
sequence prediction capabilities but often struggle with dynamic, long-horizon
tasks such as real-time strategic games. In a game such as StarCraftII (SC2),
agents need to manage resource constraints and adapt to evolving battlefield
situations in a partially observable environment. This often overwhelms
exisiting LLM-based approaches. To address these challenges, we propose a
hierarchical multi-agent framework that employs specialized imitation learning
agents under a meta-controller called Strategic Planner (SP). By expert
demonstrations, each specialized agent learns a distinctive strategy, such as
aerial support or defensive maneuvers, and produces coherent, structured
multistep action sequences. The SP then orchestrates these proposals into a
single, environmentally adaptive plan that ensures local decisions aligning
with long-term strategies. We call this HIMA (Hierarchical Imitation
Multi-Agent). We also present TEXTSCII-ALL, a comprehensive SC2 testbed that
encompasses all race match combinations in SC2. Our empirical results show that
HIMA outperforms state of the arts in strategic clarity, adaptability, and
computational efficiency, underscoring the potential of combining specialized
imitation modules with meta-level orchestration to develop more robust,
general-purpose AI agents.

</details>


### [347] [LLMs for Resource Allocation: A Participatory Budgeting Approach to Inferring Preferences](https://arxiv.org/abs/2508.06060)
*Sankarshan Damle,Boi Faltings*

Main category: cs.AI

TL;DR: 该研究提出了一种新的框架，用于评估大型语言模型（LLMs）在参与式预算中的资源分配和推理能力。研究发现，提示词设计对LLM的表现至关重要，并且LLMs有潜力处理非结构化的用户输入。


<details>
  <summary>Details</summary>
Motivation: LLMs在处理复杂决策任务方面的潜力日益增长，尤其是在结构化资源分配方面，但现有基准难以评估其推理能力，且数据污染问题普遍存在。

Method: 提出了一种利用参与式预算（PB）的双重框架，用于LLM资源分配和作为自适应基准。测试了三种提示策略：贪婪选择、直接优化和类似爬山法的优化。评估了LLM从自然语言选民输入或元数据中推断结构化偏好以及进行资源分配的能力。

Result: LLMs在资源分配任务中表现出潜力，提示词设计对结果有显著影响。LLMs能够从非结构化输入中推断用户偏好，但其准确性有待提高。与最优分配相比，LLMs的分配有提升空间。

Conclusion: LLMs在机制设计和处理非结构化输入方面显示出潜力，但提示词设计至关重要。

Abstract: Large Language Models (LLMs) are increasingly expected to handle complex
decision-making tasks, yet their ability to perform structured resource
allocation remains underexplored. Evaluating their reasoning is also difficult
due to data contamination and the static nature of existing benchmarks. We
present a dual-purpose framework leveraging Participatory Budgeting (PB) both
as (i) a practical setting for LLM-based resource allocation and (ii) an
adaptive benchmark for evaluating their reasoning capabilities. We task LLMs
with selecting project subsets under feasibility (e.g., budget) constraints via
three prompting strategies: greedy selection, direct optimization, and a
hill-climbing-inspired refinement. We benchmark LLMs' allocations against a
utility-maximizing oracle. Interestingly, we also test whether LLMs can infer
structured preferences from natural-language voter input or metadata, without
explicit votes. By comparing allocations based on inferred preferences to those
from ground-truth votes, we evaluate LLMs' ability to extract preferences from
open-ended input. Our results underscore the role of prompt design and show
that LLMs hold promise for mechanism design with unstructured inputs.

</details>


### [348] [A "good regulator theorem" for embodied agents](https://arxiv.org/abs/2508.06326)
*Nathaniel Virgo,Martin Biehl,Manuel Baltieri,Matteo Capucci*

Main category: cs.AI

TL;DR: 主体能够执行调节任务，可以被视为拥有一个可更新的关于其环境的“信念”模型，该模型比Conant和Ashby的模型更具普适性。


<details>
  <summary>Details</summary>
Motivation: 探索“每个好的系统调节器必须是该系统的模型”这一经典观点的泛化可能性，特别是在人工智能生命（Artificial Life）领域中出现的无需显式模型的系统。

Method: 通过将“信念更新”视为一种更复杂的模型形式，并提出一个更广泛适用的定理来阐述这一观点。

Result: 当一个主体能够执行调节任务时，可以将其解释为拥有一个关于其环境的“信念”系统，该系统能够根据感知输入进行“更新”。

Conclusion: 该定理适用于经典控制理论设置或系统自身内部状态的调节，模型始终是关于环境的。

Abstract: In a classic paper, Conant and Ashby claimed that "every good regulator of a
system must be a model of that system." Artificial Life has produced many
examples of systems that perform tasks with apparently no model in sight; these
suggest Conant and Ashby's theorem doesn't easily generalise beyond its
restricted setup. Nevertheless, here we show that a similar intuition can be
fleshed out in a different way: whenever an agent is able to perform a
regulation task, it is possible for an observer to interpret it as having
"beliefs" about its environment, which it "updates" in response to sensory
input. This notion of belief updating provides a notion of model that is more
sophisticated than Conant and Ashby's, as well as a theorem that is more
broadly applicable. However, it necessitates a change in perspective, in that
the observer plays an essential role in the theory: models are not a mere
property of the system but are imposed on it from outside. Our theorem holds
regardless of whether the system is regulating its environment in a classic
control theory setup, or whether it's regulating its own internal state; the
model is of its environment either way. The model might be trivial, however,
and this is how the apparent counterexamples are resolved.

</details>


### [349] [A Generic Complete Anytime Beam Search for Optimal Decision Tree](https://arxiv.org/abs/2508.06064)
*Harold Silvère Kiossou,Siegfried Nijssen,Pierre Schaus*

Main category: cs.AI

TL;DR: 在寻找最优决策树的NP难题中，CA-DL8.5通过其创新的剪枝搜索框架和模块化设计，显著提高了任意时段的性能，尤其在使用LDS启发式方法时表现突出，为决策树学习提供了更优的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的精确算法在寻找最优决策树时存在任意行为不佳的问题，即难以在搜索停止前快速找到高质量的决策树。虽然已经提出了一些精确方法的任意扩展，但缺乏系统性的比较。

Method: CA-DL8.5是一种通用的、完整的、任何时段的剪枝搜索算法，通过模块化设计，允许集成各种启发式方法和松弛机制，重用DL8.5的有效分支剪枝和基于trie的缓存，结合基于重启的剪枝搜索，通过逐步放宽剪枝标准来随着时间的推移提高解决方案的质量。

Result: CA-DL8.5使用LDS（有限差异）启发式方法在任何时段性能方面始终表现最佳，优于其他CA-DL8.5变体和Blossom算法，同时保持完整性和最优性保证。

Conclusion: CA-DL8.5是一个通用的、完整的、任何时段的剪枝搜索算法，它扩展了DL8.5框架并统一了一些现有的任何时段策略。CA-DL8.5通过模块化设计，允许集成各种启发式方法和松弛机制，并且可以重用DL8.5的有效分支剪枝和基于trie的缓存，结合基于重启的剪枝搜索，通过逐步放宽剪枝标准来随着时间的推移提高解决方案的质量。在标准分类基准上的实验结果表明，使用LDS（有限差异）的CA-DL8.5在任何时段性能方面始终表现最佳，并且优于其他CA-DL8.5变体和Blossom算法，同时保持完整性和最优性保证。

Abstract: Finding an optimal decision tree that minimizes classification error is known
to be NP-hard. While exact algorithms based on MILP, CP, SAT, or dynamic
programming guarantee optimality, they often suffer from poor anytime behavior
-- meaning they struggle to find high-quality decision trees quickly when the
search is stopped before completion -- due to unbalanced search space
exploration. To address this, several anytime extensions of exact methods have
been proposed, such as LDS-DL8.5, Top-k-DL8.5, and Blossom, but they have not
been systematically compared, making it difficult to assess their relative
effectiveness. In this paper, we propose CA-DL8.5, a generic, complete, and
anytime beam search algorithm that extends the DL8.5 framework and unifies some
existing anytime strategies. In particular, CA-DL8.5 generalizes previous
approaches LDS-DL8.5 and Top-k-DL8.5, by allowing the integration of various
heuristics and relaxation mechanisms through a modular design. The algorithm
reuses DL8.5's efficient branch-and-bound pruning and trie-based caching,
combined with a restart-based beam search that gradually relaxes pruning
criteria to improve solution quality over time. Our contributions are twofold:
(1) We introduce this new generic framework for exact and anytime decision tree
learning, enabling the incorporation of diverse heuristics and search
strategies; (2) We conduct a rigorous empirical comparison of several
instantiations of CA-DL8.5 -- based on Purity, Gain, Discrepancy, and Top-k
heuristics -- using an anytime evaluation metric called the primal gap
integral. Experimental results on standard classification benchmarks show that
CA-DL8.5 using LDS (limited discrepancy) consistently provides the best anytime
performance, outperforming both other CA-DL8.5 variants and the Blossom
algorithm while maintaining completeness and optimality guarantees.

</details>


### [350] [ME$^3$-BEV: Mamba-Enhanced Deep Reinforcement Learning for End-to-End Autonomous Driving with BEV-Perception](https://arxiv.org/abs/2508.06074)
*Siyi Lu,Run Liu,Dongsheng Yang,Lei He*

Main category: cs.AI

TL;DR: ME^3-BEV uses Mamba-BEV and DRL for better autonomous driving, showing improved performance and interpretability in simulations.


<details>
  <summary>Details</summary>
Motivation: Traditional modular approaches in autonomous driving suffer from error propagation and coordination issues, while end-to-end learning systems face computational bottlenecks. The paper aims to address these challenges by proposing a novel approach that integrates BEV perception with deep reinforcement learning for enhanced real-time decision-making in complex driving environments.

Method: The paper introduces the Mamba-BEV model for efficient spatio-temporal feature extraction, combining bird's-eye view (BEV) perception with the Mamba framework. This model is integrated into the ME^3-BEV framework, which uses deep reinforcement learning (DRL) for end-to-end decision-making. Interpretability is addressed by visualizing high-dimensional features through semantic segmentation.

Result: Extensive experiments on the CARLA simulator show that the ME^3-BEV framework outperforms existing models in metrics such as collision rate and trajectory accuracy, demonstrating its potential as a promising solution for real-time autonomous driving.

Conclusion: ME^3-BEV, a novel framework integrating Mamba-BEV and DRL, achieves superior performance in autonomous driving by enhancing real-time decision-making through efficient spatio-temporal feature extraction and long-range dependency modeling. The model's interpretability is improved via semantic segmentation visualization, and experiments on the CARLA simulator validate its effectiveness against existing models.

Abstract: Autonomous driving systems face significant challenges in perceiving complex
environments and making real-time decisions. Traditional modular approaches,
while offering interpretability, suffer from error propagation and coordination
issues, whereas end-to-end learning systems can simplify the design but face
computational bottlenecks. This paper presents a novel approach to autonomous
driving using deep reinforcement learning (DRL) that integrates bird's-eye view
(BEV) perception for enhanced real-time decision-making. We introduce the
\texttt{Mamba-BEV} model, an efficient spatio-temporal feature extraction
network that combines BEV-based perception with the Mamba framework for
temporal feature modeling. This integration allows the system to encode vehicle
surroundings and road features in a unified coordinate system and accurately
model long-range dependencies. Building on this, we propose the
\texttt{ME$^3$-BEV} framework, which utilizes the \texttt{Mamba-BEV} model as a
feature input for end-to-end DRL, achieving superior performance in dynamic
urban driving scenarios. We further enhance the interpretability of the model
by visualizing high-dimensional features through semantic segmentation,
providing insight into the learned representations. Extensive experiments on
the CARLA simulator demonstrate that \texttt{ME$^3$-BEV} outperforms existing
models across multiple metrics, including collision rate and trajectory
accuracy, offering a promising solution for real-time autonomous driving.

</details>


### [351] [Aggregate-Combine-Readout GNNs Are More Expressive Than Logic C2](https://arxiv.org/abs/2508.06091)
*Stan P Hauke,Przemysław Andrzej Wałęga*

Main category: cs.AI

TL;DR: 聚合-组合-读出GNNs的逻辑表达能力超过C2。


<details>
  <summary>Details</summary>
Motivation: 已有研究将GNNs的表达能力与逻辑语言联系起来，Barceló等人的研究表明，带权模态逻辑（或C2逻辑的保护片段）可以表征聚合-组合GNNs的逻辑表达能力。但聚合-组合-读出GNNs的表达能力是否与C2相同，仍然是一个悬而未决的挑战性问题。

Method: 通过证明聚合-组合-读出GNNs的逻辑表达能力严格超过了C2。

Result: 聚合-组合-读出GNNs的逻辑表达能力严格超过了C2，该结果同时适用于无向图和有向图。此外，该研究还为无限逻辑的表达能力提供了纯粹的逻辑见解。

Conclusion: 该研究解决了图神经网络(GNNs)的表达能力问题，证明了聚合-组合-读出GNNs的逻辑表达能力超过了C2逻辑。

Abstract: In recent years, there has been growing interest in understanding the
expressive power of graph neural networks (GNNs) by relating them to logical
languages. This research has been been initialised by an influential result of
Barcel\'o et al. (2020), who showed that the graded modal logic (or a guarded
fragment of the logic C2), characterises the logical expressiveness of
aggregate-combine GNNs. As a ``challenging open problem'' they left the
question whether full C2 characterises the logical expressiveness of
aggregate-combine-readout GNNs. This question has remained unresolved despite
several attempts. In this paper, we solve the above open problem by proving
that the logical expressiveness of aggregate-combine-readout GNNs strictly
exceeds that of C2. This result holds over both undirected and directed graphs.
Beyond its implications for GNNs, our work also leads to purely logical
insights on the expressive power of infinitary logics.

</details>


### [352] [SKATE, a Scalable Tournament Eval: Weaker LLMs differentiate between stronger ones using verifiable challenges](https://arxiv.org/abs/2508.06111)
*Dewi S. W. Gould,Bruno Mlodozeniec,Samuel F. Brown*

Main category: cs.AI

TL;DR: SKATE是一个创新的、自动化的LLM评估框架，通过让LLM相互设置和解决任务来评估它们的能力和风险，无需人工干预或领域知识，实现了可扩展、开放和客观的评估。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）的能力和风险至关重要，但现有方法需要广泛的领域专业知识，这限制了其可扩展性，因为这些模型在快速发展。本研究旨在开发一种新的评估框架，以应对这一挑战。

Method: SKATE框架将评估视为一场游戏，由LLMs扮演任务设定者和解决者的角色。它们被激励去创造突出自身优势并暴露其他模型弱点的任务。作为概念验证，研究引入了LLM设定的代码输出预测（COP）挑战，这是一个可验证且可扩展的测试该方法论的框架。该框架使用基于TrueSkill的排名系统来评估六个前沿LLM。

Result: SKATE框架能够可靠地区分和评估不同能力的LLMs，揭示了LLM驱动的系统会表现出自我偏好的行为，并自动发现了模型间细粒度的能力差异。研究结果证明了SKATE在实现通用、可扩展的评估框架方面的有效性。

Conclusion: SKATE是一个新颖的评估框架，通过让大型语言模型（LLMs）相互竞争生成和解决可验证的任务，实现了对这些模型能力和风险的可扩展、开放和客观的评估。该框架自动化、无需数据和人工干预，并通过LLM生成的、与其自身能力对齐的任务来揭示模型间的细微能力差异。研究表明，较弱的模型可以可靠地区分和评估更强的模型，并且LLM驱动的系统会表现出自我偏好的行为。

Abstract: Evaluating the capabilities and risks of foundation models is paramount, yet
current methods demand extensive domain expertise, hindering their scalability
as these models rapidly evolve. We introduce SKATE: a novel evaluation
framework in which large language models (LLMs) compete by generating and
solving verifiable tasks for one another. Our core insight is to treat
evaluation as a game: models act as both task-setters and solvers, incentivized
to create questions which highlight their own strengths while exposing others'
weaknesses. SKATE offers several key advantages, balancing scalability,
open-endedness, and objectivity. It is fully automated, data-free, and
scalable, requiring no human input or domain expertise. By using verifiable
tasks rather than LLM judges, scoring is objective. Unlike domain-limited
programmatically-generated benchmarks (e.g. chess-playing or spatial
reasoning), having LLMs creatively pose challenges enables open-ended and
scalable evaluation. As a proof of concept, we introduce LLM-set
code-output-prediction (COP) challenges as a verifiable and extensible
framework in which to test our approach. Using a TrueSkill-based ranking
system, we evaluate six frontier LLMs and find that: (1) weaker models can
reliably differentiate and score stronger ones, (2) LLM-based systems are
capable of self-preferencing behavior, generating questions that align with
their own capabilities, and (3) SKATE automatically surfaces fine-grained
capability differences between models. Our findings are an important step
towards general, scalable evaluation frameworks which can keep pace with LLM
progress.

</details>


### [353] [Study of Robust Features in Formulating Guidance for Heuristic Algorithms for Solving the Vehicle Routing Problem](https://arxiv.org/abs/2508.06129)
*Bachtiar Herdianto,Romain Billot,Flavien Lucas,Marc Sevaux*

Main category: cs.AI

TL;DR: 本研究利用机器学习和可解释人工智能，分析了影响车辆路径问题（VRP）解决方案质量的特征，为改进元启发式算法提供了新的方向。


<details>
  <summary>Details</summary>
Motivation: 鉴于车辆路径问题（VRP）的NP-Hard性质，传统上主要依靠人工设计的元启发式算法解决，而机器学习方法在理解组合优化解决方案结构特性方面显示出潜力，本研究旨在通过机器学习方法进一步改进VRP的元启发式算法设计。

Method: 本研究通过使用多种能够预测车辆路径问题解决方案质量的分类器模型进行敏感性分析，并利用可解释人工智能来扩展对此类模型决策过程的理解。

Result: 研究发现，虽然特征重要性因模型而异，但某些特征始终是重要的预测因子。此外，研究提出了一个能够跨不同场景对特征影响进行排名的统一框架。

Conclusion: 本研究的结果表明，特征重要性分析可以作为开发用于解决车辆路径问题的元启发式算法的指导机制。

Abstract: The Vehicle Routing Problem (VRP) is a complex optimization problem with
numerous real-world applications, mostly solved using metaheuristic algorithms
due to its $\mathcal{NP}$-Hard nature. Traditionally, these metaheuristics rely
on human-crafted designs developed through empirical studies. However, recent
research shows that machine learning methods can be used the structural
characteristics of solutions in combinatorial optimization, thereby aiding in
designing more efficient algorithms, particularly for solving VRP. Building on
this advancement, this study extends the previous research by conducting a
sensitivity analysis using multiple classifier models that are capable of
predicting the quality of VRP solutions. Hence, by leveraging explainable AI,
this research is able to extend the understanding of how these models make
decisions. Finally, our findings indicate that while feature importance varies,
certain features consistently emerge as strong predictors. Furthermore, we
propose a unified framework able of ranking feature impact across different
scenarios to illustrate this finding. These insights highlight the potential of
feature importance analysis as a foundation for developing a guidance mechanism
of metaheuristic algorithms for solving the VRP.

</details>


### [354] [Retrieval Augmented Large Language Model System for Comprehensive Drug Contraindications](https://arxiv.org/abs/2508.06145)
*Byeonghun Bang,Jongsuk Yoon,Dong-Jin Chang,Seho Park,Yong Oh Lee*

Main category: cs.AI

TL;DR: 本研究通过整合RAG管道，显著提高了LLM在药物禁忌症信息方面的准确性，为医疗领域提供了更可靠的决策支持。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在提高LLM在药物禁忌症领域的应用能力，因为该领域需要准确可靠的信息，而现有LLM的应用存在挑战。

Method: 使用OpenAI的GPT-4o-mini作为基础模型，text-embedding-3-small模型用于嵌入，并利用Langchain编排了一个结合了重新排序的混合检索系统。该系统整合了来自公共数据库的药物利用审查（DUR）数据，重点关注特定年龄组、怀孕和伴随用药的禁忌症。

Result: 在整合RAG管道后，模型在与年龄组、怀孕和伴随用药相关的禁忌症方面的准确率分别达到了0.94、0.87和0.89，显著优于基线模型（准确率在0.49到0.57之间）。

Conclusion: LLM通过RAG框架的增强可以大大减少处方和药物摄入决策中的不确定性，提供更精确、更可靠的药物禁忌信息。

Abstract: The versatility of large language models (LLMs) has been explored across
various sectors, but their application in healthcare poses challenges,
particularly in the domain of pharmaceutical contraindications where accurate
and reliable information is required. This study enhances the capability of
LLMs to address contraindications effectively by implementing a Retrieval
Augmented Generation (RAG) pipeline. Utilizing OpenAI's GPT-4o-mini as the base
model, and the text-embedding-3-small model for embeddings, our approach
integrates Langchain to orchestrate a hybrid retrieval system with re-ranking.
This system leverages Drug Utilization Review (DUR) data from public databases,
focusing on contraindications for specific age groups, pregnancy, and
concomitant drug use. The dataset includes 300 question-answer pairs across
three categories, with baseline model accuracy ranging from 0.49 to 0.57.
Post-integration of the RAG pipeline, we observed a significant improvement in
model accuracy, achieving rates of 0.94, 0.87, and 0.89 for contraindications
related to age groups, pregnancy, and concomitant drug use, respectively. The
results indicate that augmenting LLMs with a RAG framework can substantially
reduce uncertainty in prescription and drug intake decisions by providing more
precise and reliable drug contraindication information.

</details>


### [355] [Overconfidence in LLM-as-a-Judge: Diagnosis and Confidence-Driven Solution](https://arxiv.org/abs/2508.06225)
*Zailong Tian,Zhuoheng Han,Yanzhe Chen,Haozhe Xu,Xi Yang,richeng xuan,Hongfeng Wang,Lizi Liao*

Main category: cs.AI

TL;DR: 该研究解决了LLM作为裁判时存在的“过度自信现象”，提出TH-Score度量标准和LLM-as-a-Fuser框架，通过提高置信度校准来增强评估的可靠性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM作为自动化裁判的方法主要关注准确性，忽视了良好校准的置信度的重要性，而置信度对于自适应和可靠的评估流程至关重要。本研究提倡从以准确性为中心的评估转向以置信度为驱动、风险感知的LLM作为裁判的系统。

Method: 提出了一种名为TH-Score的新度量标准，用于量化置信度-准确性对齐，并提出了LLM-as-a-Fuser集成框架。

Result: 量化了LLM“过度自信现象”（预测置信度显著高于实际正确率），并提出TH-Score度量标准。实验证明LLM-as-a-Fuser框架能提升校准度，实现自适应、置信度驱动的评估，提高可靠性和准确性。

Conclusion: 该研究提出了一种名为LLM-as-a-Fuser的集成框架，将LLM转变为可靠、风险感知的评估者，并在实验中证明该方法能显著提高校准度，实现自适应、置信度驱动的评估流程，相比现有基线在可靠性和准确性方面均有提升。

Abstract: Large Language Models (LLMs) are widely used as automated judges, where
practical value depends on both accuracy and trustworthy, risk-aware judgments.
Existing approaches predominantly focus on accuracy, overlooking the necessity
of well-calibrated confidence, which is vital for adaptive and reliable
evaluation pipelines. In this work, we advocate a shift from accuracy-centric
evaluation to confidence-driven, risk-aware LLM-as-a-Judge systems, emphasizing
the necessity of well-calibrated confidence for trustworthy and adaptive
evaluation. We systematically identify the **Overconfidence Phenomenon** in
current LLM-as-a-Judges, where predicted confidence significantly overstates
actual correctness, undermining reliability in practical deployment. To
quantify this phenomenon, we introduce **TH-Score**, a novel metric measuring
confidence-accuracy alignment. Furthermore, we propose **LLM-as-a-Fuser**, an
ensemble framework that transforms LLMs into reliable, risk-aware evaluators.
Extensive experiments demonstrate that our approach substantially improves
calibration and enables adaptive, confidence-driven evaluation pipelines,
achieving superior reliability and accuracy compared to existing baselines.

</details>


### [356] [GeoLaux: A Benchmark for Evaluating MLLMs' Geometry Performance on Long-Step Problems Requiring Auxiliary Lines](https://arxiv.org/abs/2508.06226)
*Yumeng Fu,Jiayin Zhu,Lingling Zhang,Bo Zhao,Shaoxuan Ma,Yushun Zhang,Yanrui Wu,Wenjun Wu*

Main category: cs.AI

TL;DR: GeoLaux 是一个包含 2,186 道几何题的新基准，用于评估 MLLM 的长步骤推理和辅助线构建能力。实验发现 MLLM 在长推理、证明题和辅助线理解方面存在不足，但提升辅助线能力可显著改善其几何推理表现。


<details>
  <summary>Details</summary>
Motivation: 现有 MLLM 几何能力评估基准忽略了辅助线构建，并且缺乏细粒度过程评估，不足以衡量 MLLM 的长步骤推理能力。

Method: 提出 GeoLaux 基准，包含 2,186 道几何题（计算题和证明题），平均推理步骤 6.51 步，41.8% 的题目需要辅助线。设计了包括答案正确性、过程正确性、过程质量、辅助线影响和错误原因的五维度评估策略。

Result: 在 13 个领先 MLLM 上进行的实验表明：1. 推理步骤越长，模型性能下降越明显（9 个模型性能下降超 50%）；2. MLLM 在解决证明题时倾向于采取捷径；3. 模型缺乏对辅助线的理解，提升此能力对整体几何推理非常有益。

Conclusion: GeoLaux 填补了现有几何问题解决基准在辅助线构建和细粒度过程评估方面的空白，为评估 MLLM 的长步骤推理能力提供了新的标准。实验结果揭示了 MLLM 在长推理步骤、证明题和辅助线理解方面存在的挑战，并强调了提升辅助线能力对改进几何推理的重要性。

Abstract: Geometry problem solving (GPS) requires models to master diagram
comprehension, logical reasoning, knowledge application, numerical computation,
and auxiliary line construction. This presents a significant challenge for
Multimodal Large Language Models (MLLMs). However, existing benchmarks for
evaluating MLLM geometry skills overlook auxiliary line construction and lack
fine-grained process evaluation, making them insufficient for assessing MLLMs'
long-step reasoning abilities. To bridge these gaps, we present the GeoLaux
benchmark, comprising 2,186 geometry problems, incorporating both calculation
and proving questions. Notably, the problems require an average of 6.51
reasoning steps, with a maximum of 24 steps, and 41.8% of them need auxiliary
line construction. Building on the dataset, we design a novel five-dimensional
evaluation strategy assessing answer correctness, process correctness, process
quality, auxiliary line impact, and error causes. Extensive experiments on 13
leading MLLMs (including thinking models and non-thinking models) yield three
pivotal findings: First, models exhibit substantial performance degradation in
extended reasoning steps (nine models demonstrate over 50% performance drop).
Second, compared to calculation problems, MLLMs tend to take shortcuts when
solving proving problems. Third, models lack auxiliary line awareness, and
enhancing this capability proves particularly beneficial for overall geometry
reasoning improvement. These findings establish GeoLaux as both a benchmark for
evaluating MLLMs' long-step geometric reasoning with auxiliary lines and a
guide for capability advancement. Our dataset and code are included in
supplementary materials and will be released.

</details>


### [357] [Learning Logical Rules using Minimum Message Length](https://arxiv.org/abs/2508.06230)
*Ruben Sharma,Sebastijan Dumančić,Ross D. King,Andrew Cropper*

Main category: cs.AI

TL;DR: A Bayesian approach to inductive logic programming learns programs from noisy data more effectively than previous methods.


<details>
  <summary>Details</summary>
Motivation: Unifying probabilistic and logical learning is a key challenge in AI.

Method: Bayesian inductive logic programming, learning minimum message length programs from noisy data, balancing hypothesis complexity and data fit through priors and likelihood.

Result: Our method significantly outperforms previous methods, notably those that learn minimum description length programs, and is data-efficient and insensitive to example balance, including learning from exclusively positive examples.

Conclusion: We propose a Bayesian inductive logic programming approach that learns minimum message length programs from noisy data, outperforming previous methods in various domains and demonstrating data-efficiency and insensitivity to example balance.

Abstract: Unifying probabilistic and logical learning is a key challenge in AI. We
introduce a Bayesian inductive logic programming approach that learns minimum
message length programs from noisy data. Our approach balances hypothesis
complexity and data fit through priors, which explicitly favour more general
programs, and a likelihood that favours accurate programs. Our experiments on
several domains, including game playing and drug design, show that our method
significantly outperforms previous methods, notably those that learn minimum
description length programs. Our results also show that our approach is
data-efficient and insensitive to example balance, including the ability to
learn from exclusively positive examples.

</details>


### [358] [Symmetry breaking for inductive logic programming](https://arxiv.org/abs/2508.06263)
*Andrew Cropper,David M. Cerna,Matti Järvisalo*

Main category: cs.AI

TL;DR: 通过在假设空间中打破对称性来加速归纳逻辑编程的搜索过程。


<details>
  <summary>Details</summary>
Motivation: 归纳逻辑编程的目标是搜索能够泛化训练数据和背景知识的假设。然而，搜索巨大的假设空间是一个挑战，因为存在许多逻辑上等价的假设。

Method: 将打破对称性的想法实现在应答集编程中。

Result: 实验表明，该方法可以将解决时间从一小时以上缩短到17秒。

Conclusion: 该方法通过在假设空间中打破对称性来解决归纳逻辑编程中的搜索挑战，并在多个领域通过实验证明了其有效性。

Abstract: The goal of inductive logic programming is to search for a hypothesis that
generalises training data and background knowledge. The challenge is searching
vast hypothesis spaces, which is exacerbated because many logically equivalent
hypotheses exist. To address this challenge, we introduce a method to break
symmetries in the hypothesis space. We implement our idea in answer set
programming. Our experiments on multiple domains, including visual reasoning
and game playing, show that our approach can reduce solving times from over an
hour to just 17 seconds.

</details>


### [359] [LLM Robustness Leaderboard v1 --Technical report](https://arxiv.org/abs/2508.06296)
*Pierre Peigné - Lefebvre,Quentin Feuillade-Montixi,Tom David,Nicolas Miailhe*

Main category: cs.AI

TL;DR: PRISM Eval的BET工具通过自动化红队测试，在评估LLM鲁棒性方面取得了显著进展，能成功识别出大部分模型的有害行为，并提供了更精细的评估指标和漏洞分析。


<details>
  <summary>Details</summary>
Motivation: 为了评估和提升大型语言模型（LLM）的鲁棒性，特别是识别和量化其在面对对抗性攻击时的脆弱性。

Method: PRISM Eval行为诱导工具（BET）通过动态对抗性优化进行自动化红队测试，并提出了一种精细化的鲁棒性指标来评估诱导有害行为所需的平均尝试次数，以及进行原始级别漏洞分析。

Result: BET在41个最先进的LLM中，有37个达到了100%的攻击成功率。研究还发现，不同模型在诱导有害行为的难度上差异显著，相差超过300倍，并识别出对特定危害类别最有效的越狱技术。

Conclusion: PRISM Eval BET在识别LLM的鲁棒性方面表现出色，其动态对抗性优化方法能以100%的成功率识别37/41个模型的有害行为。该工具还引入了精细化的鲁棒性指标和原始级别漏洞分析，为社区分布式评估提供了实用方法。

Abstract: This technical report accompanies the LLM robustness leaderboard published by
PRISM Eval for the Paris AI Action Summit. We introduce PRISM Eval Behavior
Elicitation Tool (BET), an AI system performing automated red-teaming through
Dynamic Adversarial Optimization that achieves 100% Attack Success Rate (ASR)
against 37 of 41 state-of-the-art LLMs. Beyond binary success metrics, we
propose a fine-grained robustness metric estimating the average number of
attempts required to elicit harmful behaviors, revealing that attack difficulty
varies by over 300-fold across models despite universal vulnerability. We
introduce primitive-level vulnerability analysis to identify which jailbreaking
techniques are most effective for specific hazard categories. Our collaborative
evaluation with trusted third parties from the AI Safety Network demonstrates
practical pathways for distributed robustness assessment across the community.

</details>


### [360] [AntiCheatPT: A Transformer-Based Approach to Cheat Detection in Competitive Computer Games](https://arxiv.org/abs/2508.06348)
*Mille Mei Zhen Loo,Gert Luzkov,Paolo Burelli*

Main category: cs.AI

TL;DR: 本研究提出了一种名为AntiCheatPT_256的Transformer模型，用于检测《反恐精英2》中的作弊行为，并发布了CS2CD数据集。该模型准确率达到89.17%，AUC达到93.36%，为数据驱动的反作弊研究提供了新的方向。


<details>
  <summary>Details</summary>
Motivation: 在线视频游戏中的作弊行为会损害游戏的公平性。现有的反作弊系统（如VAC）在应对不断变化的作弊方法时面临挑战，并且可能需要侵入性的用户系统措施。本研究旨在提供一种无需侵入性措施即可检测作弊行为的方法。

Method: 本研究提出了一种名为AntiCheatPT_256的Transformer模型，利用《反恐精英2》的游戏数据来检测作弊行为。研究人员创建并公开了一个包含795场比赛的CS2CD数据集，并对90,707个上下文窗口进行了增强以解决类别不平衡问题。

Result: 在未增强的测试集上，所提出的Transformer模型达到了89.17%的准确率和93.36%的AUC。

Conclusion: 该研究提出了AntiCheatPT_256模型，一种基于Transformer的机器学习模型，用于检测《反恐精英2》中的作弊行为，并取得了89.17%的准确率和93.36%的AUC。该研究还发布了CS2CD数据集，为未来反作弊研究奠定了基础。

Abstract: Cheating in online video games compromises the integrity of gaming
experiences. Anti-cheat systems, such as VAC (Valve Anti-Cheat), face
significant challenges in keeping pace with evolving cheating methods without
imposing invasive measures on users' systems. This paper presents
AntiCheatPT\_256, a transformer-based machine learning model designed to detect
cheating behaviour in Counter-Strike 2 using gameplay data. To support this, we
introduce and publicly release CS2CD: A labelled dataset of 795 matches. Using
this dataset, 90,707 context windows were created and subsequently augmented to
address class imbalance. The transformer model, trained on these windows,
achieved an accuracy of 89.17\% and an AUC of 93.36\% on an unaugmented test
set. This approach emphasizes reproducibility and real-world applicability,
offering a robust baseline for future research in data-driven cheat detection.

</details>


### [361] [From Explainable to Explanatory Artificial Intelligence: Toward a New Paradigm for Human-Centered Explanations through Generative AI](https://arxiv.org/abs/2508.06352)
*Christian Meske,Justin Brenne,Erdi Uenal,Sabahat Oelcer,Ayseguel Doganguen*

Main category: cs.AI

TL;DR: 本研究提出了“解释性AI”概念，强调AI应作为人类理解的伙伴，提供适应性、情境化的解释，而非仅仅追求算法透明度。研究通过用户实验证明，用户更喜欢这种以人为中心的解释方式，并为未来AI解释研究指明了方向。


<details>
  <summary>Details</summary>
Motivation: 当前的XAI方法过于关注算法透明度，其解释格式抽象且缺乏适应性，未能有效支持用户的理解。因此，提出“解释性AI”作为一种补充范式，利用生成式AI的能力，充当人类理解的伙伴，而非仅仅提供算法透明度。

Method: 通过快速情境设计方法（Rapid Contextual Design）进行实证验证，并与医疗专业人员合作。

Result: 开发了一个包含八个维度的概念模型，该模型通过叙事性沟通、自适应个性化和渐进式披露原则来区分解释性AI。实证研究表明，用户一致偏好上下文敏感、多模态的解释。

Conclusion: 研究结果表明，用户更倾向于选择上下文感知、多模态解释，而非技术透明度。这强调了设计面向人类理解而非算法自省的AI系统的实际需求，并为在不同领域和文化背景下推进以用户为中心的AI解释方法奠定了全面的研究议程。

Abstract: Current explainable AI (XAI) approaches prioritize algorithmic transparency
and present explanations in abstract, non-adaptive formats that often fail to
support meaningful end-user understanding. This paper introduces "Explanatory
AI" as a complementary paradigm that leverages generative AI capabilities to
serve as explanatory partners for human understanding rather than providers of
algorithmic transparency. While XAI reveals algorithmic decision processes for
model validation, Explanatory AI addresses contextual reasoning to support
human decision-making in sociotechnical contexts. We develop a definition and
systematic eight-dimensional conceptual model distinguishing Explanatory AI
through narrative communication, adaptive personalization, and progressive
disclosure principles. Empirical validation through Rapid Contextual Design
methodology with healthcare professionals demonstrates that users consistently
prefer context-sensitive, multimodal explanations over technical transparency.
Our findings reveal the practical urgency for AI systems designed for human
comprehension rather than algorithmic introspection, establishing a
comprehensive research agenda for advancing user-centered AI explanation
approaches across diverse domains and cultural contexts.

</details>


### [362] [Automated Creation of the Legal Knowledge Graph Addressing Legislation on Violence Against Women: Resource, Methodology and Lessons Learned](https://arxiv.org/abs/2508.06368)
*Claudia dAmato,Giuseppe Rubini,Francesco Didio,Donato Francioso,Fatima Zahra Amara,Nicola Fanizzi*

Main category: cs.AI

TL;DR: 本研究开发了两种方法（自下而上和利用大型语言模型）来构建针对暴力侵害妇女案件的法律知识图谱，以提高法律信息的易访问性并支持机器学习应用。


<details>
  <summary>Details</summary>
Motivation: 为了解决法律领域中法律知识图谱稀缺的问题，本研究旨在创建一个针对暴力侵害妇女案件的法律知识图谱，以支持法律决策过程。

Method: 本研究提出了两种互补的方法来自动构建法律知识图谱：一种是针对法律领域定制的系统化自下而上方法，另一种是利用大型语言模型的新解决方案。从欧洲法院公开的法律判例入手，结合结构化数据提取、本体开发和语义丰富，构建针对涉及暴力侵害妇女案件的知识图谱。

Result: 研究开发了两种方法来构建法律知识图谱，并通过能力问题对生成的知识图谱进行了验证。

Conclusion: 所提出的法律知识图谱（KG）可提高法律信息的易访问性，支持复杂查询，并可作为支持预测性司法的机器学习工具的知识组成部分。

Abstract: Legal decision-making process requires the availability of comprehensive and
detailed legislative background knowledge and up-to-date information on legal
cases and related sentences/decisions. Legal Knowledge Graphs (KGs) would be a
valuable tool to facilitate access to legal information, to be queried and
exploited for the purpose, and to enable advanced reasoning and machine
learning applications. Indeed, legal KGs may act as knowledge intensive
component to be used by pre-dictive machine learning solutions supporting the
decision process of the legal expert. Nevertheless, a few KGs can be found in
the legal domain. To fill this gap, we developed a legal KG targeting legal
cases of violence against women, along with clear adopted methodologies.
Specifically, the paper introduces two complementary approaches for automated
legal KG construction; a systematic bottom-up approach, customized for the
legal domain, and a new solution leveraging Large Language Models. Starting
from legal sentences publicly available from the European Court of Justice, the
solutions integrate structured data extraction, ontology development, and
semantic enrichment to produce KGs tailored for legal cases involving violence
against women. After analyzing and comparing the results of the two approaches,
the developed KGs are validated via suitable competency questions. The obtained
KG may be impactful for multiple purposes: can improve the accessibility to
legal information both to humans and machine, can enable complex queries and
may constitute an important knowledge component to be possibly exploited by
machine learning tools tailored for predictive justice.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [363] [A Physics-Augmented Machine Learning Constitutive Model for Damage in Solids](https://arxiv.org/abs/2508.05638)
*Amirhossein Amiri-Hezaveh,Adrian Buganza Tepole*

Main category: physics.app-ph

TL;DR: 提出一个数据驱动框架，用二阶损伤张量处理各向异性损伤力学，并使用神经网络保证保凸性，能预测不同材料的损伤行为，并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 为了在各向异性损伤力学中开发一种数据驱动的本构框架，该框架能够处理可压缩和不可压缩材料，满足热力学一致性，并能准确捕捉损伤引起的各向异性效应。

Method: 提出一种基于二阶损伤张量的数据驱动本构框架，用于可压缩和不可压缩材料的各向异性损伤力学。该框架是热力学一致的，并满足Clausius-Duhem不等式。应变能密度势被表达为右Cauchy-Green变形张量以及编码材料或损伤各向异性的结构张量的各向同性函数。为了保证保凸性，采用了满足保凸性约束的非递减凸神经网络来参数化应变能密度势。损伤演化通过损伤势控制，其阈值由损伤共轭力定义。此外，还引入了一种新的各向异性通用格式作为一般公式的一个特例，用于预测初始各向同性材料中由损伤引起的各向异性本构响应。为了降低训练时的计算负担，引入了一种解耦训练方案。

Result: 通过使用满足保凸性约束的非递减凸神经网络参数化应变能密度势，该模型能够准确捕捉损伤效应，并验证了其对不可压缩各向同性、横向各向同性和可压缩正交各向异性材料的预测能力，以及对各向异性Mullins型损伤的实验数据。解耦训练方案有效降低了计算成本。

Conclusion: 该框架采用数据驱动方法，基于二阶损伤张量，能够处理各向异性损伤力学中可压缩和不可压缩材料的本构关系。通过使用满足保凸性约束的非递减凸神经网络来参数化应变能密度势，确保了热力学一致性并满足Clausius-Duhem不等式。损伤演化由损伤势控制，阈值由损伤共轭力定义。此外，该模型还提供了一种新的各向异性通用格式，用于预测初始各向同性材料中由损伤引起的各向异性本构响应。采用解耦训练方案以降低计算成本，并通过对不可压缩各向同性、横向各向同性和可压缩正交各向异性材料的基准测试以及与实验数据的对比验证了其准确性，特别是对捕获各向异性Mullins型损伤的实验数据的验证。

Abstract: We propose a data-driven constitutive framework for anisotropic damage
mechanics based on the second-order damage tensor approach for both
compressible and incompressible materials. The formulation is thermodynamically
consistent and satisfies the Clausius-Duhem inequality. The strain energy
density potentials are expressed as isotropic functions of the right
Cauchy-Green deformation tensor, along with structural tensors that encode
anisotropy either present in the virgin material or resulting from damage. To
guarantee the polyconvexity condition, non-decreasing convex neural networks
with inputs that ensure polyconvexity are used to parameterize the strain
energy density potentials. The model vanishes in the undeformed state,
fulfilling the normality condition. In contrast to classical [1-d] damage
models, the expressiveness of the new data-driven model is enhanced by
employing a family of nonlinear, convex, decreasing functions to capture the
effect of damage. Damage evolution is governed through a damage potential,
where the corresponding threshold is defined in terms of the damage conjugate
forces. As a special case of the general formulation, a new anisotropic generic
format is introduced to predict constitutive responses under damage-induced
anisotropy in initially isotropic materials. To reduce the computational burden
during training, a decoupled training scheme is introduced, and its accuracy is
demonstrated in all numerical examples. These include benchmarks for
incompressible isotropic, transversely isotropic, and compressible orthotropic
materials. The framework is also validated against experimental data capturing
anisotropic Mullins-type damage.

</details>


### [364] [A device-level compact model for mushroom-type phase change memory](https://arxiv.org/abs/2508.05641)
*Stephan Menzel,Benedikt Kersting,Rana Walied Ahmad,Abu Sebastian,Ghazi Sarwat Syed*

Main category: physics.app-ph

TL;DR: 该模型考虑了PCM器件的几何形状，并能准确预测编程特性和读出行为。


<details>
  <summary>Details</summary>
Motivation: 在此工作中，我们为蘑菇型相变存储器器件引入了一个紧凑模型，该模型包含了不同编程条件下的非晶标记的形状和大小，并适用于投影和非投影器件。

Method: 该模型包含非晶和晶体区域的解析方程，并独特地提供了一个电流泄漏路径，该路径在电极外边缘注入电流。

Result: 结果表明，准确模拟相配置的大小和形状对于预测 RESET 和 SET 编程的全跨度至关重要，包括阈值切换的特性。

Conclusion: 该模型可有效捕获读出行为，包括电阻漂移和双极电流不对称行为对相位配置的依赖性。该紧凑模型还提供 Verilog-A 格式，易于在标准电路级仿真工具中使用。

Abstract: In this work we introduce a compact model for mushroom-type phase-change
memory devices that incorporates the shape and size of the amorphous mark under
different programming conditions, and is applicable to both projecting and
non-projecting devices. The model includes analytical equations for the
amorphous and crystalline regions and uniquely features a current leakage path
that injects current at the outer edge of the electrodes. The results
demonstrate that accurately modeling the size and shape of the phase
configurations is crucial for predicting the full-span of the RESET and SET
programming, including the characteristics of threshold switching.
Additionally, the model effectively captures read-out behaviors, including the
dependence of resistance drift and bipolar current asymmetry behaviours on the
phase configurations. The compact model is also provided in Verilog-A format,
so it can be easily used in standard circuit-level simulation tools.

</details>


### [365] [Low-dimensional magnetocaloric materials for energy-efficient magnetic refrigeration: Does size matter?](https://arxiv.org/abs/2508.06050)
*Nguyen Thi My Duc,Hariharan Srikanth,Manh-Huong Phan*

Main category: physics.app-ph

TL;DR: 本综述旨在解决低维磁制冷材料的研究空白，重点关注尺寸、几何形状、界面效应、应变和表面现象的影响，以指导高性能、节能磁制冷系统的设计。


<details>
  <summary>Details</summary>
Motivation: 磁制冷技术有潜力取代传统的压缩制冷系统，但目前对低维磁制冷材料的研究仍不充分。

Method: 对尺寸、几何形状、界面效应、应变和表面现象如何影响 MCE 的现有研究进行回顾和分析。

Result: 低维磁制冷材料（如薄膜、微线等）具有传热、柔韧性和集成性等方面的优势，但对其 MCE 影响因素的理解有限。

Conclusion: 需要进一步研究尺寸、几何形状、界面效应、应变和表面现象如何影响 MCE，以实现高性能、节能的磁制冷系统。

Abstract: The magnetocaloric effect (MCE) provides a promising foundation for the
development of solid-state refrigeration technologies that could replace
conventional gas compression-based cooling systems. Current research efforts
primarily focus on identifying cost-effective magnetic materials that exhibit
large MCEs under low magnetic fields across broad temperature ranges, thereby
enhancing cooling efficiency. However, practical implementation of magnetic
refrigeration requires more than bulk materials; real-world devices demand
efficient thermal management and compact, scalable architectures, often
achieved through laminate designs or miniaturized geometries. Magnetocaloric
materials with reduced dimensionality, such as ribbons, thin films, microwires,
and nanostructures, offer distinct advantages, including improved heat
exchange, mechanical flexibility, and integration potential. Despite these
benefits, a comprehensive understanding of how size, geometry, interfacial
effects, strain, and surface phenomena influence the MCE remains limited. This
review aims to address these knowledge gaps and provide guidance for the
rational design and engineering of magnetocaloric materials tailored for
high-performance, energy-efficient magnetic refrigeration systems.

</details>


### [366] [Topological edge states and amplitude-dependent delocalization in quasiperiodic elliptically geared lattices](https://arxiv.org/abs/2508.06286)
*Shuaifeng Li,Di Zhou,Feng Li,Panayotis G. Kevrekidis,Jinkyu Yang*

Main category: physics.app-ph

TL;DR: Mechanical lattices based on modulated elliptical gears exhibit topological edge states and amplitude-driven transitions, with applications in metamaterials and synthetic dimensions.


<details>
  <summary>Details</summary>
Motivation: explore topological phenomena and synthetic dimensionality in mechanical metamaterials using elliptical gears.

Method: numerical continuation approach to analyzing the periodic orbits and their linear stability, effectively discovering the boundary of the basin of bounded motion and detecting the occurrence of delocalization under certain excitation amplitudes.

Result: demonstrate the emergence of localized edge states arising from quasiperiodic variation in the gears' moments of inertia, analogous to the topological edge modes of the Aubry-Andre-Harper model. Under increasing excitation amplitude, the system undergoes a nonlinear transition, where edge localization breaks down and energy delocalizes into the bulk. Construct a two-dimensional lattice in which the phase acts as a synthetic dimension. This structure supports topological wave propagation along the synthetic dimension. Nonlinearity again induces a breakdown of topological states, leading to complex, amplitude-dependent wave propagation.

Conclusion: elliptical geared systems offer a passive, amplitude-dependent platform for exploring topological phenomena and synthetic dimensionality in mechanical metamaterials.

Abstract: We present a class of mechanical lattices based on elliptical gears with
quasiperiodic modulation and geometric nonlinearity, capable of exhibiting
topologically protected modes and amplitude-driven transitions. Starting from a
one-dimensional chain of modulated elliptical gears, we demonstrate the
emergence of localized edge states arising from quasiperiodic variation in the
gears' moments of inertia, analogous to the topological edge modes of the
Aubry-Andre-Harper model. Under increasing excitation amplitude, the system
undergoes a nonlinear transition, where edge localization breaks down and
energy delocalizes into the bulk. By coupling multiple such chains with varying
modulation phase, we construct a two-dimensional lattice in which the phase
acts as a synthetic dimension. This structure supports topological wave
propagation along the synthetic dimension. Nonlinearity again induces a
breakdown of topological states, leading to complex, amplitude-dependent wave
propagation. We further propose a numerical continuation approach to analyzing
the periodic orbits and their linear stability, effectively discovering the
boundary of the basin of bounded motion and detecting the occurrence of
delocalization under certain excitation amplitudes. Our results reveal that
elliptical geared systems offer a passive, amplitude-dependent platform for
exploring topological phenomena and synthetic dimensionality in mechanical
metamaterials.

</details>


### [367] [4D operando X-ray nano-holo-tomography reveals multiscale chemomechanics in Silicon-Graphite anode](https://arxiv.org/abs/2508.06413)
*Victor Vanpeene,Olga Stamati,Francois Cadiou,Quentin Jacquet,Julie Villanova,Sandrine Lyonnard*

Main category: physics.app-ph

TL;DR: 通过X射线纳米全息断层扫描和数字体积相关技术，首次实现了对锂离子电池硅-石墨负极的多尺度化学机械动力学追踪，揭示了影响电池性能的关键结构因素及其重要性，为电池优化提供了新框架。


<details>
  <summary>Details</summary>
Motivation: 为了优化锂离子电池性能，必须将电极的微观结构与其电化学性能联系起来，这需要达到终极时空尺度的力学过程4D观测，而这在目前仍然难以实现。

Method: 本研究采用操作型同步X射线纳米全息断层扫描技术，并结合数字体积相关技术，对锂离子电池硅-石墨负极在形成循环过程中的化学机械动力学进行了多尺度追踪和分析。

Result: 研究结果表明，局部扩散特性、石墨颗粒的形貌和在电极中的位置、与硅团簇的距离、与电解液的表面接触以及机械变形都会直接影响局部电化学活性和不可逆性，但这些参数的重要性不同。研究特别指出了快速扩散通道在平衡由离子/电子扩散限制引起的、与深度相关的反应非均一性方面起着关键作用。研究还根据影响程度对决定石墨-硅电池性能的各种结构因素进行了分类，并提出了一个实用的框架。

Conclusion: 该研究通过操作型同步X射线纳米全息断层扫描结合数字体积相关技术，实现了对锂离子电池硅-石墨负极在形成循环过程中的化学机械动力学进行多尺度追踪。研究揭示了局部扩散特性、石墨颗粒形貌与位置、与硅团簇的距离、与电解液的表面接触以及机械变形等因素对局部电化学活性和不可逆性的影响，并区分了这些因素的重要性。研究特别识别出快速扩散通道能够抵消由离子/电子扩散限制引起的、与深度相关的反应非均一性。最后，研究对决定石墨-硅电池性能的各种结构因素进行了分类，并提出了一个实用的优化材料和电极制造的框架。

Abstract: Linking electrode microstructure to electrochemical performance is essential
for optimizing Li-ion batteries. However, this requires mechanistic 4D
observations at ultimate spatio-temporal scales, which remains elusive. Here we
demonstrate the use of operando synchrotron X-ray nano-holo-tomography combined
with Digital Volume Correlation to track chemomechanical dynamics at both
particle (local) and electrode (averaged) scales. Quantitative scale-bridging
image analysis is applied to a high-capacity silicon-graphite anode during its
formation cycle. Our findings reveal that local diffusion properties, graphite
particle morphology and position in the electrode, distance to silicon
clusters, surface contact with electrolyte and mechanical deformations, all
have a direct impact on the local electrochemical activity and irreversibility
- but these parameters are not equally important. Particularly, we identify
fast diffusion channels that play a key role and counterbalance intrinsic
depth-dependent reaction heterogeneities due to ionic/electronic diffusion
limitations. The various structural factors that determine Gr-Si battery
performance beyond ensemble properties are classified using a scale of
influence, providing a practical framework for the optimization of materials
and electrode manufacturing.

</details>
